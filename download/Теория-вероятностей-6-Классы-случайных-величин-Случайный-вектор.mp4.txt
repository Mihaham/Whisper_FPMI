[00:00.000 --> 00:13.040]  так ну что коллеги был звонок да начинаем значит в прошлый раз мы остановились на
[00:13.040 --> 00:18.480]  конкретных типах случайных величин если меня не изменяет памяти мы рассмотрели
[00:18.480 --> 00:26.320]  бернульскую случайную величину равномерную в общем случае на ab они на 0 1 как этот написал
[00:26.320 --> 00:32.480]  и пуассонскую случайную величину с параметром лямбда правильно да
[00:32.480 --> 00:44.000]  так было дело да ну давайте значит двинемся дальше следующая случайная величина из класса
[00:44.000 --> 00:50.960]  дискретных это случайная величина имеющая геометрическое распределение это случайная
[00:50.960 --> 00:59.760]  величина с одним параметром п и задается своими вероятностями вероятность того что
[00:59.760 --> 01:12.800]  геометрическая случайная величина равна к есть к у в степени к на п к принимает значение 0 1 2 и
[01:12.800 --> 01:21.600]  так далее п число от нуля до единицы ку традиционно единица минус п значит мысленный
[01:21.600 --> 01:28.920]  эксперимент соответствующий данной случайной величине это количество неудачных испытаний до
[01:28.920 --> 01:35.000]  первого успеха количество неудачных испытаний до первого успеха то есть если вы проводите
[01:35.000 --> 01:43.920]  независимые испытания значит и как бы на каком-то шаге у вас появляется успех то вот количество
[01:43.920 --> 01:49.560]  неудачных испытаний до этого первого успеха это случайная величина имеющая геометрическое
[01:49.560 --> 01:57.480]  распределение значит наверное правильно теперь вести или может быть до этого надо было ввести
[01:57.480 --> 02:06.440]  биномиальную случайную личину которая имеет два параметра n и p это тоже дискретная случайная
[02:06.440 --> 02:22.280]  величина которая тоже задается своими распределением сочетание а значит того что она равна к это
[02:22.280 --> 02:31.640]  вероятность равна сочетании из n пока п в степени к у в степени n минус к в данном
[02:31.640 --> 02:41.400]  случае к принимает значение 0 1 так далее n то есть это дискретная случайная величина принимающая
[02:41.400 --> 02:51.400]  конечное число значений значит это настолько важная величина что соответствующие мысленные
[02:51.400 --> 02:58.520]  эксперименты имеет даже собственное название и называется схемой испытаний bernoulli или схемой
[02:58.520 --> 03:04.320]  независимых испытаний bernoulli значит речь вот о чем у вас есть некий эксперимент в результате
[03:04.320 --> 03:10.560]  которого ну некое событие либо произошло либо произошло не произошло если оно произошло мы
[03:10.560 --> 03:18.960]  говорим об успехе не произошло о неудаче так вот bernoulli случайная величина это вероятность к
[03:18.960 --> 03:27.240]  успехов в серии независимых испытаний серии n независимых испытаний то есть если вы n раз
[03:27.240 --> 03:34.200]  проводите некий эксперимент примеру подбрасываете кубик и успехом считаете выпадение там шестерки
[03:34.200 --> 03:41.560]  например да то вот количество шестерок выпавших при этих н испытаниях это как раз случайная
[03:41.560 --> 03:47.440]  величина точнее говоря этот мысленный эксперимент описывает случайную величину
[03:47.440 --> 03:56.080]  имеющую биномиальное распределение биномиальное распределение и еще раз повторюсь что в отличие
[03:56.080 --> 04:01.960]  от остальных случайных величин у этого мысленного эксперимента есть собственное имя это прямо
[04:01.960 --> 04:10.120]  называется так схема независимых испытаний bernoulli вот ну что еще мы на что еще можно обратить
[04:10.120 --> 04:18.800]  внимание так если не очень строго можно сказать что биномиальная случайная величина это есть
[04:18.800 --> 04:29.680]  сумма n штук сумма n штук bernoulli случайных величин с параметром p здесь индекс g поставлю
[04:29.680 --> 04:37.560]  поскольку для bernoulli случайной величины экспериментом есть соответствием является
[04:37.560 --> 04:44.400]  проведение эксперимента и фиксация наступила события а или не наступила то bernoulli случайная
[04:44.400 --> 04:56.240]  величина это вот надо n штук сложить так без особой строгости значит дальше как к распределению
[04:56.240 --> 05:02.640]  bernoulli примыкает биномиальное распределение но знаете почему она называется биномиальным понятно
[05:02.640 --> 05:09.280]  да потому что ну точнее говоря не трудно так сказать убедиться вероятность обладает тем свойством что
[05:09.280 --> 05:15.760]  сумма вероятности по всем возможным исходном равна единице так сумма всех вот этих вероятностей как
[05:15.760 --> 05:25.720]  не трудно видеть это п плюс q степени n ну то есть единица вот ну и вот как к биномиальному
[05:25.720 --> 05:33.280]  распределению ну так сказать из него следует или примыкает распределение точнее говоря к
[05:33.280 --> 05:38.400]  распределению bernoulli примыкает биномиальное распределение со схемой независимых испытаний
[05:38.400 --> 05:45.720]  bernoulli так геометрическому распределению в этом смысле примыкает так называемое отрицательно
[05:45.720 --> 05:57.440]  биномиальное распределение которое тоже содержит два параметра n нет p и к задается тоже своими
[05:57.440 --> 06:06.840]  вероятностями вероятность того что отрицательно биномально случайно влечена равна некому n равна
[06:06.840 --> 06:29.720]  c из n плюс к минус 1 по к минус 1 значит q в степени q в степени n п в степени
[06:30.200 --> 06:41.920]  n принимает значение 0 1 2 и так далее выглядит немного страшно но соответствующий этому
[06:41.920 --> 06:50.360]  мысленный эксперимент состоит в проведении независимых испытаний до появления катова
[06:50.360 --> 06:56.600]  успеха и вот количество неудачных опытов это есть случайно влечена имеющие биномиальное
[06:56.600 --> 07:02.880]  распределение то есть для геометрической случайной величины вы проводите испытания
[07:02.880 --> 07:08.960]  до появления первого успеха а для отрицательно биномиально случайной величины вы проводите
[07:08.960 --> 07:16.280]  эксперимент до появления катова успеха и вот количество неудачных опытов это есть случайно
[07:16.280 --> 07:28.800]  влечена имеющая соответствующий распределение события независимые в том смысле как мы говорили
[07:28.800 --> 07:36.480]  о независимых событиях мы же понятие независимых событий вводили с вами или я не понял вопроса
[07:36.480 --> 07:50.240]  а значит понял вопрос спасибо значит в данном случае мы говорим о независимости в совокупности
[07:50.240 --> 08:04.680]  пока вот значит так это мы прошли с вами по дискретным распределениям давайте теперь перейдем к
[08:04.720 --> 08:10.440]  непрерывном к второму классу распределений с которыми мы имеем место значит пока мы из
[08:10.440 --> 08:17.760]  непрерывных распределений с вами познакомились только с равномерном на об следующей класс или
[08:17.760 --> 08:22.540]  следующей случайно влечена имеющий непрерывных непрерывные в из определение это на самом деле
[08:22.540 --> 08:30.320]  вам в общем за так уже знакомая это нормально распределенная случайно влечена который имеет
[08:30.320 --> 08:37.120]  два параметра m и сигма квадрат. m называется пока не очень понятным словом
[08:37.120 --> 08:43.640]  мат ожидания, а сигма квадрат называется дисперсией.
[08:43.640 --> 08:49.880]  Значит, непрерывная случайная, ну вообще любая случайная величина может быть
[08:49.880 --> 08:54.080]  задана своей функцией распределения и должна быть задана. В некотором смысле
[08:54.080 --> 09:00.240]  это она и есть, функция распределения. Но для непрерывных случайных величин
[09:00.240 --> 09:05.360]  она может быть задана своей функцией плотности вероятности. Вот я здесь и
[09:05.360 --> 09:11.120]  записал то, на чем мы вчера, не вчера, на прошлой лекции остановились. Вот,
[09:11.120 --> 09:17.320]  поэтому зададим нормально распределенную случайную величину ее функции плотности.
[09:18.160 --> 09:27.000]  В качестве индекса обычно пишется сама величина. Функция имеет вид единица на
[09:27.000 --> 09:36.160]  сигма корень из двух пи е в степени минус х минус м в квадрате делить на два
[09:36.160 --> 09:49.120]  сигма квадрат. Два сигма квадрат. Ну, знакомая вам вещь, интеграл ошибок, ну и
[09:49.120 --> 09:53.600]  наверное в разных еще и постасяк связывались. Я даже не буду сейчас говорить о
[09:53.600 --> 09:58.320]  эксперименте, соответствующем этой случайной величиной, потому что мы этому
[09:58.320 --> 10:04.160]  посвятим большое количество времени. Это очень важное распределение, потому что
[10:04.160 --> 10:10.720]  она еще предельная. Напомню, что, как бы, если в двух словах пытаться сформулировать
[10:10.720 --> 10:17.160]  про что теория вероятности, это про существование неких предельных мер,
[10:17.160 --> 10:23.720]  концентрации объектов наших, теперь, теперь случайных величин, ну, вокруг
[10:23.720 --> 10:29.160]  каких-то предельных мер. Вот нормальное распределение одна из них. Так,
[10:29.360 --> 10:36.200]  следующая непрерывная случайная величина, которая тесно связана с нормальным
[10:36.200 --> 10:40.960]  распределением, мы ее зададим чуть-чуть другим образом. Значит, пока мы все
[10:40.960 --> 10:45.360]  случайные величины, ну, по сути, задавали их функциями распределения. А теперь мы
[10:45.360 --> 10:49.040]  зададим случайную величину как функцию от случайной величины, как Борелевскую
[10:49.040 --> 11:00.920]  функцию. Давайте введем такую случайную величину log n. Она имеет также два параметра
[11:00.920 --> 11:11.200]  и определяется как е в степени n, m сигма квадрат. Log n, очевидно, случайная величина,
[11:11.200 --> 11:18.440]  потому что экспонента Борелевская функция. Ну и, собственно, можно было бы на этом
[11:18.440 --> 11:22.600]  остановиться, но уж давайте получим для нее какую-нибудь характеристику, например,
[11:22.600 --> 11:28.560]  функцию распределения или, точнее говоря, получить мы сможем функцию плотности. Ну,
[11:28.560 --> 11:35.960]  начнем с функции распределения. Функции распределения вот этой нашей случайной величины.
[11:35.960 --> 11:49.600]  Сам задающий такой вопрос не знаю. Вот, действительно, я надо было бы назвать
[11:49.600 --> 11:56.800]  какой-нибудь экспоненциальный, но вот называется лог нормальный. Значит, итак,
[11:56.800 --> 12:03.120]  функция распределения по определению, это вероятность того, ну, вместо log n сразу
[12:03.120 --> 12:13.680]  поставлю е в степени n, m сигма квадрат меньше х. Ну, здесь отмечу, что х у нас больше нуля,
[12:13.680 --> 12:21.960]  имею как, ну, имеет смысл рассматривать. Вот, и давайте напишем тождественное равенство,
[12:21.960 --> 12:34.120]  это вероятность того, что n, m сигма квадрат будет меньше логарифом х. Ну, вот это по
[12:34.120 --> 12:45.400]  определению. Функция распределения случайной величины нормальной, взятая в точке логарифом х.
[12:45.400 --> 12:56.440]  Ну, чтобы получить плотности, возьмем производную и получим. Функция плотности
[12:56.440 --> 13:09.080]  лог нормальной случайной величины равна, ну, функции плотности нормальной случайной величины,
[13:09.080 --> 13:15.880]  взятой в точке логарифом х, только еще производную от аргумента, от логарифма х. И поэтому получим
[13:15.880 --> 13:32.120]  единица делить на х сигма корень из 2p е в степени минус логарифом х минус m в квадрате делить на 2
[13:32.120 --> 13:43.160]  сигма квадрат. Еще раз повторю, х больше нуля. Вот, значит, вот еще одна непрерывная случайная
[13:43.160 --> 13:50.600]  величина. Ну, на самом деле тоже довольно важная. Ну, еще как бы ее там определенные
[13:50.600 --> 13:59.080]  свойства увидим и поймем. Итак, это пример случайной величины, который мы определили не
[13:59.160 --> 14:06.640]  через введение ее в функции распределения, а как функцию от случайной величины, а потом же,
[14:06.640 --> 14:14.280]  как следствие, получили ее функцию плотности. Значит, следующий целый класс непрерывных
[14:14.280 --> 14:27.360]  случайных величин. Это так называемая гамма распределения имеет два параметра, лямда или
[14:27.360 --> 14:40.200]  альфа и лямда. Альфа и лямда. Определена для альфа, лямда и х больше нуля. Задается своей
[14:40.200 --> 14:52.360]  функцией плотности. Ну, я так не буду длинно писать, г напишу, альфа лямда от х равно лямда в степени
[14:52.360 --> 15:04.720]  альфа делить на гамма от альфа, х в степени альфа минус 1, е в степени минус лямда х. Вот такое
[15:04.720 --> 15:16.040]  гамма распределения. Да, это гамма функция, но она, собственно, потому так и называется. Вот,
[15:16.040 --> 15:31.200]  значит, это функция плотности и давайте выделим два важных класса. Могу. Гамма от альфы это интеграл
[15:31.200 --> 15:46.480]  от нуля до бесконечности, t в степени альфа минус 1, е в степени минус альфа dt. Значит,
[15:46.480 --> 15:52.760]  свойства которыми мы чаще всего пользуемся. Гамма от альфа равно альфа минус 1 факториал,
[15:52.760 --> 16:06.400]  когда целая. И еще такая полезная гамма от одной второй это корень из пи. Ну, или еще вот так
[16:06.400 --> 16:15.320]  от можно записать. Альфа минус 1 на гамма от альфы минус 1, собственно. Так, значит, гамма,
[16:15.400 --> 16:23.360]  случайная личина, имеющая гамма распределения выглядит вот так. И выделяем два как бы частных
[16:23.360 --> 16:33.480]  случая, но настолько важных, что они имеют свои собственные имена. А именно гамма, когда альфа
[16:33.480 --> 16:44.360]  равно единиц, а 1 лямда. Это у нас называется показательное распределение, которое имеет
[16:44.360 --> 17:04.320]  функцию плотности лямда на е в степени минус лямда х. Лямда х больше нуля. Ну,
[17:04.320 --> 17:12.000]  одно из немногих распределений, не то что немногих, но иногда не часто встречается,
[17:12.120 --> 17:22.080]  можем выписать функцию распределения. Функция распределения этой случайной личины равна 1
[17:22.080 --> 17:28.400]  минус лямда на е в степени минус лямда х. Ну, по-разному. Можно проинтегрировать,
[17:28.400 --> 17:38.000]  можно вот это продиференцировать. Ну, и давайте чуть-чуть по это ассоциативное мышление включим.
[17:38.000 --> 17:52.480]  Значит, вероятность того, что эксп, что показательная распределенная случайная личина с параметром
[17:52.480 --> 18:08.120]  лямда будет больше некого t, равна чему? Ой, извините, ошибочка. Лямда не должно быть здесь,
[18:08.120 --> 18:18.960]  поправьте, пожалуйста. Равно чему вот эта вероятность больше t? Ну, коллеги, вот это по
[18:18.960 --> 18:24.720]  определению вероятность того, что она меньше х, а вот это больше t. Значит, это е в степени минус
[18:24.720 --> 18:33.320]  лямда х, лямда t. Я специально тут t ввел, чтобы у вас возник какие-то ассоциации. Так,
[18:33.320 --> 18:49.640]  что такое показательная случайная личина? Мы с вами уже с такими... Черт, не слышу еще раз.
[18:49.640 --> 19:01.880]  Да, ну в смысле можно и так сказать, но если говорить в терминах того, что мы с вами изучали,
[19:02.000 --> 19:08.480]  это вероятность того, что за время t в простейшем пуласоновском потоке не произойдет ни одного
[19:08.480 --> 19:14.720]  события. Можно это интерпретировать как время свободного пробега? Действительно. Вот, значит,
[19:14.720 --> 19:22.920]  это первый частный случай, и второй частный случай гамма распределения, который именной,
[19:22.920 --> 19:36.000]  это когда α равно n пополам, а лямда равно 1 и 2. Вот это распределение называется х квадрат
[19:36.000 --> 19:45.720]  с n степенями свободы. Х квадрат с n степенями свободы. Пожалуйста, это себе пометьте,
[19:45.840 --> 19:54.400]  потому что с этим распределением вы столкнетесь с математической статистики. Пока интерпретации
[19:54.400 --> 20:00.200]  не будут давать, но они у нас будут. Мы разберемся, что ж такое х квадрат с n степенями свободы.
[20:00.200 --> 20:12.440]  Так, ну и еще продолжим с непрерывными распределениями. Вот тут себе позволю я стереть.
[20:15.720 --> 20:40.880]  Так, никто меня не поправил. Минус чего? Минус t. Так, значит,
[20:40.880 --> 21:04.800]  еще одна случайная величина, которую надо знать, и тоже широкий достаточно класс с точки
[21:04.800 --> 21:12.000]  зрения приложений, это так называемое бета-распределение. Имеет два параметра,
[21:12.000 --> 21:28.080]  альфа и бета. Альфа, бета больше нуля. Это вот это? Это бета. Вы это спрашивали?
[21:28.080 --> 21:47.960]  Значит, бета-распределение, зададим его функции плотности, гамма от альфа плюс бета делить на гамма
[21:47.960 --> 22:01.400]  от альфа умножить на гамма от бета. Х в степени альфа минус один, единица минус х в степени
[22:01.400 --> 22:10.360]  бета минус один. Но х здесь от нуля до единицы. Ну, можно равно, наверное, оставить от нуля до единицы.
[22:10.360 --> 22:24.840]  То есть, это случайная величина, определенная на 0.1. Что для нее как бы является мысленным
[22:24.840 --> 22:29.760]  экспериментом? Где можно получить такую случайную величину? Ну, на самом деле,
[22:29.760 --> 22:36.120]  это случайная величина, которая связана с так называемыми ранговыми статистиками. Но для
[22:36.120 --> 22:47.000]  понимания давайте сделаем вот что. Возьмем отрезок 0.1 и на удачу бросим сюда альфа плюс бета
[22:47.000 --> 23:00.120]  минус одну точку. Вот сюда на этот отрезок. Какое-то какое-то значение будет альф,
[23:00.720 --> 23:07.520]  по величине назовут так. И оно даже имеет специальное обозначение. Там каты по величине,
[23:07.520 --> 23:13.160]  это индекс в круглых скобочках. Обратите внимание, традиционно вы этим будете
[23:13.160 --> 23:21.400]  пользоваться. Вот этот альф ты по величине наш случайный бросок, вот он как раз имеет
[23:21.400 --> 23:32.760]  вот такое бета распределение. Вот так. И последнее из непрерывных, ну и, собственно,
[23:32.760 --> 23:40.840]  последнее из тех, которые по курсу нам надо знать. Ну, давайте помещу здесь, на этой доске.
[23:40.840 --> 23:59.840]  Что? Ну, тогда отрицательней будет. Вот это, да? Нет, это я сказал интерпретацию, когда альфа и
[23:59.840 --> 24:07.960]  бета натуральные. Я сказал бросить альфа плюс бета минус одну точку. Моя интерпретация распределения
[24:07.960 --> 24:13.800]  относится, когда альфа и бета натуральные. Ну, может, надо было там м и н взять, чтобы не путаться.
[24:13.800 --> 24:23.760]  Вот, значит, ну, кстати, натолкнули меня на мысль, что вот так давайте уберем, если уж мы будем
[24:23.760 --> 24:32.040]  рассматривать отрицательные степени. Вот, значит, ну и последнее распределение из непрерывных,
[24:32.040 --> 24:39.720]  которым надо познакомиться, это распределение каши. Ну, его иногда по-французски каши, такое длинное
[24:39.720 --> 24:50.360]  получается слово, мы просто к будем обозначать. Оно имеет тоже два параметра, а и сигма. Похоже,
[24:50.360 --> 24:55.960]  как бы в этом смысле, на нормальное. И задается оно своей функцией плотности, это распределение.
[24:55.960 --> 25:16.200]  Единицы делить на пи сигма. Единица плюс х минус а делить на сигма в квадрате. И вот это,
[25:16.200 --> 25:31.800]  собственно, знаменатель. Распределение каши. У него есть свойства, ради которого всегда
[25:31.800 --> 25:36.760]  поминают. Мы еще пока не знаем, что такое мотожидание, но у этого распределения нет
[25:36.760 --> 25:44.680]  мотожидания. Это мы на следующей лекции подготовимся. А с точки зрения эксперимента две... А,
[25:44.960 --> 25:51.800]  еще вот здесь пометьте, пожалуйста. Для нормального распределения отдельно выделяют вот такое
[25:51.800 --> 25:58.400]  распределение с нулевым от ожиданиям единичной дисперсии, и его называют стандартным нормальным
[25:58.400 --> 26:08.280]  распределением. Это тоже термин. Стандартное нормальное распределение. Ну вот, отношение
[26:08.280 --> 26:14.480]  двух стандартных нормальных случайных величин имеет стандартное распределение каши, когда
[26:14.480 --> 26:20.700]  sigma равно единице, а равно нулю. В отличие от нормального распределения, где вот
[26:20.700 --> 26:26.600]  это m называется мат-ожиданием, а на мат-ожиданием не называется, потому что его
[26:26.600 --> 26:32.440]  нет, называется параметром сдвига, а sigma называется
[26:32.440 --> 26:39.280]  параметром масштаба. Но вот чуть-чуть забегая вперед, просто по терминам, здесь
[26:39.280 --> 26:43.600]  у нас мат-ожидание и дисперсия мы это назвали, потому что это две вполне
[26:43.600 --> 26:48.680]  конкретных величины, которые мы определим на следующей лекции, а у распределения
[26:48.680 --> 26:53.360]  коши не отнимат ожидания, не дисперсии, но два параметра есть, поэтому называются
[26:53.360 --> 26:59.360]  они по-другому. Параметры сдвига и параметры масштаба.
[26:59.360 --> 27:09.120]  Так, ну вот на этом мы знакомство с распределениями стандартными, которые вам
[27:09.160 --> 27:16.760]  нужно знать. Заканчиваем и давайте двинемся дальше.
[27:16.760 --> 27:37.840]  Собственно, что нам еще нужно сделать, чтобы уж двинуться в другую тему
[27:37.840 --> 27:43.640]  несколько. Значит, мы с вами в прошлый раз установили, ну не мы установили, скорее
[27:43.640 --> 27:49.280]  Лебек установил, что функция распределения разлагается на две
[27:49.280 --> 27:54.920]  составляющих. Это дискретная функция, которую мы определили, дискретная
[27:54.920 --> 28:00.080]  составляющая, непрерывная составляющая и теоретически есть сингулярная
[28:00.080 --> 28:06.320]  составляющая, мы ей пренебрегли, так считаем, что ее нет, поэтому непрерывная
[28:06.320 --> 28:10.840]  составляющая это абсолютно непрерывная, то есть существует вот такая функция,
[28:11.080 --> 28:16.720]  ядро, так сказать, интегральное, которое носит специальное название, функция плотности
[28:16.720 --> 28:23.360]  вероятности или функция плотности, надо сокращать. Вот, ну теперь надо понять, как
[28:23.360 --> 28:27.720]  же замешать непрерывное дискретное распределение, ну так сказать, с
[28:27.720 --> 28:34.480]  практической точки зрения. Мы к этому вопросу подойдем в таком общий
[28:34.480 --> 28:42.360]  подход, просто рассмотрим понятие смеси, понятие смеси. Давайте введем вот такую
[28:42.360 --> 28:49.440]  функцию, мы ее авансом буквы f большое обозначим, вот тут я поставлю мне такой
[28:49.440 --> 28:56.080]  индекс mix, напишу, которая представляет из себя следующая сумма
[28:56.080 --> 29:10.320]  p житая f житая от x, g от единицы до некого k, где сумма всех p житых от единицы до
[29:10.320 --> 29:18.400]  k равна единице, все p житые больше нуля, ну равно нулю не берем, потому что просто
[29:18.400 --> 29:28.480]  нет соответствующего слаганного, а f ж от x это на самом деле функция распределения
[29:28.480 --> 29:33.040]  некой случайной величины, просто чтобы трехэтажный индекс не таскать, то есть
[29:33.040 --> 29:40.000]  есть у нас случайные величины, x1, xk, вот так обозначимая функцию распределения.
[29:40.000 --> 29:45.400]  Вот смотрите, ввожу вот такую функцию, ну некую линейную комбинацию функций
[29:45.400 --> 29:50.000]  распределения, только не вообще на линейном пространстве, а вот на таких
[29:50.000 --> 29:55.120]  коэффициентах, там такой положительный типа симплекс получается.
[29:55.120 --> 30:00.120]  Что я про эту функцию хочу сказать, эта функция удовлетворяет всем четырем
[30:00.120 --> 30:05.880]  свойствам, которые мы для функции распределения называли, это она от нуля
[30:05.880 --> 30:10.760]  до единицы, в плюс бесконечности она равна единице, в минус бесконечности она
[30:10.760 --> 30:18.080]  равна нулю и она непрерывно слева. Пока никаких ограничений на вот эти
[30:18.080 --> 30:23.240]  функции нет, это могут быть и непрерывные, дискретные, там часть непрерывных, часть
[30:23.240 --> 30:28.160]  дискретных, все дискретные как бы не имеют значения. Вот, так значит эта
[30:28.160 --> 30:33.960]  функция fmix удовлетворяет всем свойствам функции распределения,
[30:33.960 --> 30:38.840]  случайной величины. Я вам в свое время говорил, что эти свойства
[30:38.840 --> 30:43.240]  характеристические, то есть если у меня задана функция с этими
[30:43.240 --> 30:48.080]  свойствами, то я вообще говоря могу построить вероятностное пространство
[30:48.080 --> 30:52.760]  отображения такое, чтобы получалась случайная величина с наперед заданной
[30:52.760 --> 30:59.400]  функцией. Ну давайте мы вот в этом случае, ну можно сказать это и проделаем, а именно
[30:59.400 --> 31:05.480]  опишем мысленный эксперимент, который приводит к вот такой функции распределения.
[31:05.480 --> 31:13.240]  Для этого давайте представим, что у нас есть, ну некая случайная величина,
[31:13.240 --> 31:19.120]  дискретная, которая принимает конечное число значений, ну определимую там какая-нибудь
[31:19.120 --> 31:31.120]  это равная g равно pg, ка значение она принимает, там кубик, например, монета, все что угодно.
[31:31.120 --> 31:50.760]  Это те же самые pg? Ну пока это не важно. Ну там индекс, можно поставить и другой
[31:50.760 --> 31:58.160]  индекс, но давайте считать, что намекаю, что это они и есть. Значит, рассмотрим вот
[31:58.200 --> 32:02.800]  такую случайную величину и представим такой мысленный эксперимент. Сначала в
[32:02.800 --> 32:07.280]  результате некоего эксперимента я получаю значение вот этой случайной величины,
[32:07.280 --> 32:15.560]  например, подбрасываю кубик и получаю 1, 2, 3, 4, 5, 6, а потом взяв этот номер уже,
[32:15.560 --> 32:24.400]  число, беру x, сжитую случайную величину и вот с такой функцией распределения и
[32:24.560 --> 32:29.920]  получаю результат случайного эксперимента. Ну, например, там фантазирую, как бы,
[32:29.920 --> 32:36.000]  к реальной жизни особо значение не имеет. Давайте я поступлю так, я бросаю кубик,
[32:36.000 --> 32:43.200]  если у меня на кубике выпало k, то я бросаю точку на удачу, на отрезок от k до k плюс 1, к примеру.
[32:43.200 --> 32:52.000]  То есть непрерывные величины это равномерные, их распределение зависит от k, k я получаю в
[32:52.000 --> 32:56.080]  результате, так сказать, случайного эксперимента. Так вот, в результате случайного эксперимента,
[32:56.080 --> 33:04.120]  ну, я там, как бы, получаю некую случайную величину. Ну и давайте посмотрим, какое она
[33:04.120 --> 33:15.080]  имеет распределение. Давайте я рассмотрю событие, что вот это ксимикс, я ее так назову, меньше
[33:15.080 --> 33:25.400]  некоторого х. Что это за событие? Оно представляется в виде объединения неприсекающихся событий в результате
[33:25.400 --> 33:34.200]  первого эксперимента единица и х из распределения и кси из распределения номер один. В результате
[33:34.200 --> 33:41.600]  случайного эксперимента двойка и х, ну вот и так далее. Конечное число мы рассматриваем вот этих
[33:41.600 --> 33:52.680]  слагаемых, и поэтому эта вероятность есть сумма вероятностей того, что это равно g, то есть как раз
[33:52.680 --> 34:01.560]  по g, на вероятность того, что случайная величина с номером g окажется меньше х, а это функция
[34:01.560 --> 34:13.400]  распределения fg от х. Вот, то есть таким образом построенная смесь действительно имеет вот такое
[34:13.400 --> 34:21.040]  заданное нами распределение. Ну, собственно, мы закрыли класс тех распределений, которые мы
[34:21.040 --> 34:26.280]  рассматриваем. Мы рассматриваем чисто непрерывные распределения, чисто дискретные распределения и
[34:27.040 --> 34:39.360]  вот все, что мы в нашем курсе, с чем в нашем курсе будем иметь дело. Так, все по этому вопросу. И
[34:39.360 --> 34:52.120]  давайте перейдем к следующей теме. Начну я вот здесь. Следующий объект, который мы с вами рассмотрим,
[34:52.120 --> 35:14.880]  это случайный вектор, случайный вектор. Давайте рассмотрим отображение из омега в некое rk,
[35:14.880 --> 35:28.160]  камерное пространство. Значит, если k равно единицы, то это у нас случайная величина,
[35:28.160 --> 35:36.520]  а если k не равно единицы, а больше, то это у нас случайный вектор. Значит, когда мы определяли
[35:36.520 --> 35:43.400]  случайную величину, мы наложили некоторые требования на вот это вот отображение, на свойство
[35:43.400 --> 35:51.680]  отображения, а именно измеримость. Здесь мы поступим попроще. Мы напишем, что случайный
[35:51.680 --> 36:02.760]  вектор x от омега это просто k штук случайных величин, определенных, естественно, на одном
[36:02.760 --> 36:09.960]  вероятном пространстве, которое, ну, всегда предполагается, не говорю об этом, всегда предполагается.
[36:09.960 --> 36:18.200]  Просто берем k штук случайных величин, как говорится, в описываемых столбиках,
[36:18.200 --> 36:26.800]  вот этот объект получился случайный вектор. Это действительно отображение из омега в rk. С
[36:26.800 --> 36:35.640]  какими свойствами? Ну, вот с таким свойством, которого нам будет достаточно. Омега такие,
[36:35.640 --> 36:50.840]  что x от омега меньше x, и это для всех компонент. Вот это множество, очевидно,
[36:50.840 --> 36:59.760]  принадлежит f измеримо. Понятно, да, почему? Вот это каждое измеримо, потому что мы договорили,
[36:59.760 --> 37:05.080]  что это случайная величина x, ну и пресечение конечного числа измеримых множеств.
[37:05.080 --> 37:16.160]  Это элементарный исход в исходном вероятном пространстве. А это стандартное распределение,
[37:16.160 --> 37:20.280]  в смысле стандартное обозначение. Вы первый раз пришли или как?
[37:20.280 --> 37:29.760]  На семинарах? Между семинарами и лекциями вы хотите сказать, или что?
[37:29.760 --> 37:38.560]  Не, меня просто смущает, что вы там на шестой лекции не знаете, что такое омега.
[37:38.560 --> 37:52.800]  Ну, исход формально тоже событие. Ладно, значит,
[37:52.800 --> 38:00.720]  двинемся дальше. Имеет место вот такое свойство, то есть измеримость в таком смысле. Ну,
[38:00.720 --> 38:06.600]  и поэтому нам ничего не мешает по аналогии определить функцию распределения случайного вектора.
[38:06.600 --> 38:18.080]  Это такая функция от k переменных, от размерности вектора. Ну, давайте вот это как-нибудь обозначим bx.
[38:18.160 --> 38:24.360]  Это собственно вероятность bx вот этого. x вектора, правда, здесь.
[38:24.360 --> 38:34.920]  Ну, в значительной степени по аналогии вводим в функцию распределения случайного вектора.
[38:34.920 --> 38:41.200]  Какие свойства есть у этой функции? Ну, первые четыре свойства аналогичны.
[38:42.200 --> 38:49.920]  Функции распределения случайно влечены, там часть из них тривиальна. Я, ну, когда буду,
[38:49.920 --> 38:54.160]  когда не буду, писать здесь ксид, ну, поскольку имеем в виду, что с одной случайной влечены
[38:54.160 --> 39:00.720]  работаем. Значит, функция распределения от этого вектора x меньше равна единице,
[39:00.720 --> 39:07.040]  больше равна в нуля. Это звонок, да? Ну, давайте отдыхайте и продолжим.
[39:07.920 --> 39:13.520]  Коллеги, давайте я свойства функции распределения случайного вектора вот на этой доске выпишу,
[39:13.520 --> 39:19.480]  чтобы они у нас были немножко перед глазами. Значит, второе свойство тоже совершенно аналогичное,
[39:19.480 --> 39:36.520]  просто по-компонентное. Для любого g функция распределения x1 xg' xk меньше или равно f x1 xg 2' xk
[39:36.520 --> 39:47.120]  для любого xg' меньше xg 2'. Свойства по-компонентной монотонности аналогичны,
[39:47.120 --> 39:51.480]  свойства функции распределения случайно влечены и, собственно, доказывается аналогично,
[39:51.480 --> 39:59.280]  просто индексов побольше. Третье свойство немножко отличается, но, по сути дела, логика та же.
[39:59.280 --> 40:13.240]  Придел, для любого g, предел, когда x, сжитая от n, стремится к минус бесконечности, убывая,
[40:13.240 --> 40:29.600]  этот предел равен нулю, а вот второй, как бы аналогичный, предел, который равен единице,
[40:29.600 --> 40:37.360]  немножко отличается. Здесь уже все x, сжитые от n, должны стремиться к плюс бесконечности.
[40:37.360 --> 40:54.080]  Вот этот предел равен единице. Отличия просто из-за размерности возникают, а так, по сути дела,
[40:54.080 --> 41:00.600]  то же самое свойство. Четвертое свойство тоже аналогичное, это по-компонентной непрерывности
[41:00.600 --> 41:18.120]  слева для любого g. Можно я не буду так подробно расписывать, напишу f x1, так далее, x g минус 0 x kt равно
[41:18.120 --> 41:35.880]  f x1 x g x kt. По-компонентной непрерывности слева аналогично, но у функций распределения
[41:35.880 --> 41:49.120]  случайные векторы выделяют еще одно свойство. Пятое, которое выглядит так. Для любого g предел,
[41:49.120 --> 42:06.280]  когда x, сжитые от n, возрастая, сходится к плюс бесконечности. То есть, когда какая-нибудь
[42:06.280 --> 42:24.720]  компонента стремится к бесконечности, x1 x g минус 1 x g от n x g плюс 1, так далее, x kt равно,
[42:24.720 --> 42:49.680]  равно f x1, так далее, x g минус 1 x g плюс 1, так далее, x kt. Вот такое вот свойство. Все понятно?
[42:54.720 --> 43:23.640]  Ждал то вопроса. Хороший вопрос.
[43:23.640 --> 43:29.920]  Значит, вообще говоря, что здесь написано? Написано, что если мы ограниченные функции с n
[43:29.920 --> 43:37.760]  переменными одну компоненту стремим к 0, получим функцию с n минус 1 переменной. Ну как бы и чего?
[43:37.760 --> 43:47.200]  Стоило ли это того, чтобы это выписывать? Тут вот какая вещь. Это не просто какая-то функция с n
[43:47.200 --> 43:54.320]  минус 1 переменной или k минус 1 переменной. Это функция распределения случайного вектора,
[43:54.320 --> 44:04.000]  который состоит, ну как бы выглядит как этот, но у которого выброшена житая компонента. И именно
[44:04.000 --> 44:09.320]  поэтому это свойство называется свойством согласованности. Свойством согласованности
[44:09.320 --> 44:17.360]  распределений. То есть это не тривиальный с точки зрения мотонализа факт, а это, ну, факт как бы
[44:17.360 --> 44:24.000]  содержательный. То есть если вы какую-то компоненту функции распределения устремите к бесконечности,
[44:24.000 --> 44:31.640]  то вы получите функцию распределения. Не чего-то, не какую-то функцию с k минус 1 переменной, а функцию
[44:31.640 --> 44:39.760]  распределения вектора, который составлен из тех же случайных величин, но нету ксиджитого. Вот поэтому
[44:39.760 --> 44:47.960]  я вот здесь давайте, чтобы это отметить, здесь напишу кси, а здесь напишу кси, давайте с волной
[44:47.960 --> 45:00.440]  поставлю, чтобы было понятно, что это нечто другое. Конечно, получите единицу из права и слева.
[45:01.640 --> 45:13.600]  Вы задаете какие-то вопросы такие. Вообще-то говоря, у нас есть такая случайная величина вырожденная,
[45:13.600 --> 45:21.520]  которая равна константе с вероятностью единица. Не смущает вас-то? У вас пробел какой-то?
[45:21.520 --> 45:36.720]  Вот, ну давайте, но мысль правильная, мысль хорошая. Действительно, устремив группу
[45:36.720 --> 45:43.400]  компонент к бесконечности, чуть-чуть забегая вперед, мы получим функцию распределения любого
[45:43.400 --> 45:50.640]  подножства компонент. Мы этим сегодня воспользуемся. Так, ну давайте пятое свойство
[45:50.640 --> 45:59.660]  покажем, хотя, как бы так сказать, ничего в нем такого-то нету. Значит,
[45:59.660 --> 46:19.300]  функция распределения x1 x g-1, а давайте докажем для g равного k, просто чтобы, ну,
[46:19.300 --> 46:32.500]  сложных сумм не строить, g равно k. Понятно, что доказательство от этого не изменится. x1 xk от n,
[46:32.500 --> 46:50.340]  это вероятность того, что xi gt меньше xg, когда g принимает значение от единицы до k-1,
[46:50.340 --> 47:10.180]  и xi kt меньше xk от n. По и икс каты у нас возрастая стремится к плюс бесконечности. По индексу n вот
[47:10.180 --> 47:19.660]  эти множества монотонно расширяющиеся, да, вот эти множества. Поэтому мы можем, если мы возьмем
[47:19.660 --> 47:29.820]  предел, перейдем к пределу, то вот так напишу стремиться, чтобы много не переписывать.
[47:29.820 --> 47:36.820]  Придел вот этой вероятности под знаком предела стоят расширяющееся множество. Значит, это будет
[47:36.820 --> 47:48.980]  чего? Это будет вероятность, здесь, грубо говоря, общий множитель, а здесь будет объединение
[47:48.980 --> 48:06.180]  xk меньше xk от n, объединение по n. Вот так вот, да. Ну, если уж так как-то уж красивее писать. Вот так
[48:06.180 --> 48:21.340]  пересечение. Вот так вот, да. Вот это что за множество? Мы перешли к пределу, предел вероятности по теореме
[48:21.340 --> 48:27.460]  непрерывности вероятности, если здесь стоят расширяющиеся множества, это вероятность счетного
[48:27.460 --> 48:36.460]  объединения этих множеств. Припоминаете, да? Одна, ну, там одна из форм теоремы непрерывности
[48:36.460 --> 48:44.900]  вероятности. Вот это что за множество в исходном вероятности пространстве? Пусть.
[48:44.900 --> 49:02.740]  Это Омега. Потому что, какой бы вы ни взяли Омега, поскольку xn стремится к бесконечности, а xk от
[49:02.740 --> 49:12.100]  Омега это всегда число, хоть и сколько угодно большое, то найдутся такие индексы, что xk станет
[49:12.100 --> 49:19.420]  меньше, найдется такой n, что xk станет меньше xk от n для любого Омега. Поэтому вот это на самом
[49:19.420 --> 49:28.060]  деле Омега. Ну а что угодно с Омега пересекай, это оно и получается. А вот это, собственно, и есть
[49:28.060 --> 49:38.300]  функция распределения, так его ксис волной обозначили, да, от x1, так далее, xk-1. Вот такое
[49:38.300 --> 49:49.300]  вот свойство. Значит, итак, функция распределения случайного вектора, мы выделяем пять свойств,
[49:49.300 --> 49:54.540]  не четыре, как было функция распределения случайно-чинной, а пять. Но даже эти пять
[49:54.540 --> 50:00.420]  свойств не делают их характеристическими. То есть функция, удовлетворяющая вот этим
[50:00.420 --> 50:05.420]  свойствам, может не быть функцией распределения случайного вектора. В отличие от случайной
[50:05.420 --> 50:11.300]  величины, для которой функция вот с этими четырьмя свойствами является функцией распределения
[50:11.300 --> 50:19.100]  какой-то случайной величины, которую мы даже можем конструктивно построить. Вот, значит, для того,
[50:19.100 --> 50:27.980]  чтобы это подтвердить свое утверждение, я могу или должен привести пример, я его приведу чуть
[50:27.980 --> 50:34.180]  попозже. Мы не ищем легких путей, мы сначала получим такую сложную формулу, не сложную,
[50:34.180 --> 50:40.460]  такую громоздкую, а потом уже, так сказать, вернемся к этому вопросу. Так, с вашего позволения, вот отстираю.
[50:40.460 --> 51:05.460]  Сейчас мы докажем формулу, которую тоже иногда называют формулой включений-исключений для
[51:05.460 --> 51:16.980]  случайных векторов. Докажем ее сначала в несколько диковинном виде. Значит, есть у нас
[51:16.980 --> 51:26.020]  ка штук случайных величин или н штук, ксиджитое меньше некого бжитого больше или равно ажитое,
[51:26.020 --> 51:39.340]  пересекаем это по g от единицы до n, здесь букву используем, k на другое используем, то есть это
[51:39.340 --> 51:47.420]  многомерный такой параллепипед, да, в инмерном пространстве. Вот, и еще здесь это пересечем с
[51:47.420 --> 51:59.260]  некоторым множеством d, с множеством d, который принадлежит исходной сигма-алгебре, тогда для того,
[51:59.260 --> 52:07.380]  чтобы не было путаницы, давайте здесь добавим омега, как бы поработаем чуть-чуть в исходном
[52:07.380 --> 52:14.860]  вероятном пространстве. То есть вот это множество, это параллепипед в пространстве случайных
[52:14.860 --> 52:22.700]  величин, но какое-то там другое сложное множество в исходном вероятном пространстве, и мы его пересекаем
[52:22.700 --> 52:29.660]  с произвольным множеством, но единственные сигма-алгебры. Так вот, я утверждаю, что эта вероятность равна вот такой
[52:29.660 --> 52:44.660]  штуке, минус 1 в степени сумма k житых, k житые это такие штуки k1, k, n, они просто наборы из нулей единиц.
[52:44.660 --> 53:00.860]  Сумма, вероятность объединения событий кси житые меньше х житые в степени k житые,
[53:00.860 --> 53:15.460]  ну немножко некрасиво, извините, пересечение с д, и х житые в степени k житые, это некий специальный индекс,
[53:15.460 --> 53:23.660]  я просто напишу, что он равен, как он определяется, х житые в степени 0, он в двух степенях, 0 и 1
[53:23.660 --> 53:33.100]  может быть, это просто b житые, а и житые в степени 1 это а житые, просто вот ввели такие обозначения,
[53:33.100 --> 53:43.340]  не более того, на самом деле здесь стоят всевозможные события типа кси меньше а или кси меньше б, вот,
[53:43.340 --> 53:51.660]  и сумма по всем вот таким вот наборам из нулей единиц, формула понятна сама, да, вот, ну давайте ее
[53:51.660 --> 53:59.900]  докажем, перво-наперво давайте ее для случая, доказывать будем по индукции, поэтому начнем
[53:59.900 --> 54:09.660]  со случая n равно 1, здесь выпишу такое тривиальное утверждение, если a влечет b, мы даже пару раз
[54:09.660 --> 54:30.860]  сегодня, может быть, попользуемся, то pb минус pa равно pb не а, вот так вот, ну и давайте, значит, рассматриваем
[54:30.860 --> 54:40.860]  случай n равно 1, что этой формуле будет, ну раз единица, значит k житые, ну только 1 индекс, k1 будет,
[54:40.860 --> 54:55.660]  у нас будет вероятность того, что кси 1 меньше b 1 пересечение с d, это когда k1 равно 0, минус вероятность
[54:55.660 --> 55:10.860]  того, что кси 1 меньше a 1 пересечение с d, ну вот так это, давайте события поставим, события, ну, собственно,
[55:10.860 --> 55:21.940]  для чего формула писал, вот это b, вот это a, ну, когда я так пишу, конечно, предполагаю, что a меньше b, да, вот,
[55:21.940 --> 55:34.140]  значит, это b, это a, пользуемся вон той немудрённой формулой и получаем, что это равно вероятности того, что кси 1 меньше b,
[55:34.140 --> 55:50.940]  больше b 1, больше или равно a 1 пересечение с d, правильно? Ну, а это вот оно и есть, то есть, для случая n равно 1,
[55:51.740 --> 55:55.740]  ну, предполагаем, что верна для n минус 1 и доказываем для n.
[55:55.740 --> 56:25.540]  Ведём обозначение, b n равно пересечение a g t меньше или равно кси 1,
[56:25.540 --> 56:38.340]  c g t меньше b g t, пересечение по g от 1 до n. Ну, и, собственно, нам нужно получить выражение для b n d,
[56:39.140 --> 56:52.140]  перепишем его в вероятность, значит, a n меньше или равно кси n меньше b n,
[56:52.140 --> 57:12.140]  на b n минус 1 d. Ну, вот это некая новая d, поэтому можно воспользоваться вот уже полученным результатом и написать, что это равно
[57:12.140 --> 57:22.140]  вероятности того, что кси n меньше b n и одновременно с этим b n минус 1 d,
[57:22.140 --> 57:33.140]  минус вероятность того, что кси 1 меньше a 1 пересечение b n минус 1 d равно.
[57:33.140 --> 57:49.140]  Ну, перепишу, хотя просто для визуализации так-то всё очевидно, b n минус 1 пересечение кси n меньше b n d
[57:49.140 --> 58:13.140]  минус b n минус 1 пересечение кси n меньше a n
[58:13.140 --> 58:15.140]  d.
[58:21.140 --> 58:29.140]  Так, чего бы стереть-то? Ну, вот с вашего позволения вот это тогда сотру.
[58:43.140 --> 58:58.140]  Так, равно. По предположению индукции для b n у нас формула есть, поэтому мы пишем сумма минус 1,
[58:58.140 --> 59:12.140]  сумма к житые, k 1, так далее, k n минус 1 принадлежит 0,1, то есть на наборе индексов n минус 1,
[59:12.140 --> 59:30.140]  на вероятность того, что кси n, на вероятность того, что кси житая меньше х житая в степени k житая,
[59:30.140 --> 59:52.140]  g от 1 до n минус 1 на как бы новое d, которое у нас теперь кси n меньше b n, d минус,
[59:52.140 --> 01:00:12.140]  минус сумма минус 1, сумма к житая, k 1, k n минус 1. На этих наборах рассматриваем на вероятность того, что кси житая меньше х житая в степени k житая,
[01:00:12.140 --> 01:00:31.140]  g от 1 до n минус 1 и, собственно, то же самое, кси n меньше, а n на d.
[01:00:31.140 --> 01:00:44.140]  Так, ну, лень, времени нет по 10 раз переписывать, надеюсь, что вы меня поймете. Смотрите, вот это b n, это на самом деле x n в степени 0,
[01:00:44.140 --> 01:00:55.140]  а вот это x n в степени 1. Если я здесь подставлю x n в степени 0, ничего не изменится, а если я сюда подставлю x n в степени 1,
[01:00:55.140 --> 01:01:05.140]  то надо поменять знак, потому что вот эта единица здесь его поменяет, как только я а n заменю на x n в степени 1.
[01:01:05.140 --> 01:01:21.140]  Поэтому этот искомый результат просто представлен разбитым на две суммы, когда х житая равно 0 и когда k житая равно 0 и k житая равно 1.
[01:01:21.140 --> 01:01:29.140]  Ну, понятно так более-менее. Ну вот, значит, это, собственно, и завершает доказательство.
[01:01:29.140 --> 01:01:41.140]  Тут надо сказать, что формула весьма диковинная и на самом деле редко, когда нужна, но мы ее доказали именно в таком виде,
[01:01:41.140 --> 01:01:51.140]  потому что доказательство получается простое. А на самом-то деле нас будет интересовать, по сути, единственный частный случай,
[01:01:51.140 --> 01:02:11.140]  когда d здесь на равно ω, тогда вот это сотру, подставьте d равно ω, тогда мы получим вот такую формулу.
[01:02:11.140 --> 01:02:29.140]  Вероятность теперь уже будет чисто параллепипид.
[01:02:29.140 --> 01:02:57.140]  Так, пониже чуть-чуть. Сумма по k 1 к n из 0,1 минус единица сумма k житых ж равно от 1 до n, функция распределения в точке x 1 к 1, так далее, x n к n.
[01:02:57.140 --> 01:03:08.140]  Если вот это d равно ω, то это на самом деле просто функция распределения. Вот получили вот такую формулу.
[01:03:08.140 --> 01:03:14.140]  Чаще всего в таком виде она встречается, ну, с точностью до там индексов или обозначений.
[01:03:14.140 --> 01:03:22.140]  И, собственно, она, ну, такой некий аналог формулы включений-исключений для функции распределения.
[01:03:22.140 --> 01:03:28.140]  Я встречал такое название, ну, не знаю, насколько оно, так сказать, там удачное.
[01:03:28.140 --> 01:03:37.140]  Ну, можно никак не называть. В принципе, так сказать, хоть как назовите, хоть горшком назовите, не ставьте в печь.
[01:03:37.140 --> 01:03:46.140]  Так что вот такую формулу получили. Давайте мы чуть-чуть ее один раз используем, просто понять, как она устроена,
[01:03:46.140 --> 01:03:51.140]  для того чтобы показать, что свойства 1 к 5 не являются характеристическими.
[01:03:51.140 --> 01:03:53.140]  Вот это стираю.
[01:03:53.140 --> 01:03:58.140]  Давайте рассмотрим вот такой двумерный вектор.
[01:03:58.140 --> 01:04:08.140]  Давайте рассмотрим вот такой двумерный вектор, ну, точнее говоря, двумерную функцию распределения для двумерного вектора.
[01:04:08.140 --> 01:04:18.140]  Давайте рассмотрим вот такой двумерный вектор, ну, точнее говоря, двумерную функцию распределения для двумерного вектора.
[01:04:18.140 --> 01:04:28.140]  Давайте рассмотрим вот такой двумерный вектор, ну, точнее говоря, двумерную функцию распределения для двумерного вектора,
[01:04:28.140 --> 01:04:50.140]  1, 1, вот здесь она равна 1, а здесь равна 0.
[01:04:50.140 --> 01:04:59.140]  Ну, если вы как бы, ну, и непрерывно там слева или снизу, как бы по второй, по первой компоненте.
[01:04:59.140 --> 01:05:05.140]  Вот, ну, если вы так посмотрите, вы увидите, что она вот этим свойствам 1,5 удовлетворяет.
[01:05:05.140 --> 01:05:19.140]  И давайте найдем вероятность попадания случайной величины вот в такой квадратик.
[01:05:19.140 --> 01:05:23.140]  Сторона 1,3 до 1.
[01:05:23.140 --> 01:05:27.140]  Ну, святое дело воспользуется нашей формулой.
[01:05:27.140 --> 01:05:34.140]  Получим искомую вероятность, не буду как бы писать, то есть вероятность попадания вот в этот квадрат.
[01:05:34.140 --> 01:05:37.140]  Давайте по формуле смотреть, что сюда войдет.
[01:05:37.140 --> 01:05:48.140]  Значит, сюда войдет f в точке 1,1, оба правых конца, значит, с плюсом.
[01:05:48.140 --> 01:06:16.140]  Ну, посмотрите, просто мы это в том числе делаем для того, чтобы понять, как эта формула устроена.
[01:06:16.140 --> 01:06:34.140]  А вот я вот ее нарисовал со стороной 1,3 и 1 по обеим осям.
[01:06:34.140 --> 01:06:39.140]  Ну, вот посмотрите, вот эта формула, вот ее применил для конкретной ситуации.
[01:06:39.140 --> 01:06:43.140]  Ну и смотрим теперь на вот эту как бы функцию распределения.
[01:06:43.140 --> 01:06:50.140]  Вот эта единица, вот эта единица, вот эта единица, вот эта ноль.
[01:06:50.140 --> 01:06:57.140]  Получается равно минус один.
[01:06:57.140 --> 01:07:00.140]  Вероятность у нас отрицательной быть не может.
[01:07:00.140 --> 01:07:01.140]  Отсюда вывод.
[01:07:01.140 --> 01:07:07.140]  Данная функция, несмотря на то, что она удовлетворяет написанным свойством вот здесь,
[01:07:07.140 --> 01:07:09.140]  функция распределения не является.
[01:07:09.140 --> 01:07:13.140]  Просто, так сказать, отложите у себя в памяти этот факт.
[01:07:13.140 --> 01:07:17.140]  Для случайной величины четыре свойства характеристические.
[01:07:17.140 --> 01:07:22.140]  Для случайного вектора мы их выписываем, но характеристическими они не являются.
[01:07:22.140 --> 01:07:34.140]  Так, ну теперь мы должны с вами сделать весьма важный шаг
[01:07:34.140 --> 01:07:39.140]  и ввести понятие независимых случайных величин.
[01:07:39.140 --> 01:07:47.140]  У нас были независимые события, и там у нас вот были попарно независимые, в совокупности независимые.
[01:07:47.140 --> 01:07:49.140]  Вот.
[01:07:49.140 --> 01:07:53.140]  Мы должны нечто аналогичное сделать и для случайных величин.
[01:07:53.140 --> 01:07:58.140]  Сначала определение.
[01:07:58.140 --> 01:08:00.140]  Кси-один, кси-ен.
[01:08:00.140 --> 01:08:04.140]  Случайные величины, кси-один, случайные величины.
[01:08:04.140 --> 01:08:07.140]  Кси-один, кси-ен называются независимыми.
[01:08:07.140 --> 01:08:09.140]  Никаких других слов.
[01:08:09.140 --> 01:08:11.140]  Просто независимыми.
[01:08:11.140 --> 01:08:23.140]  Если вероятность того, что ксиджитэ принадлежит некому множеству изборелевской алгебры,
[01:08:23.140 --> 01:08:36.140]  а так до n, равно произведению вероятностей.
[01:08:53.140 --> 01:08:57.140]  Понятное определение, да?
[01:08:57.140 --> 01:08:59.140]  Бежит элементы алгебры.
[01:08:59.140 --> 01:09:07.140]  А скажите, пожалуйста, что я взял алгебру, а не симма-алгебру?
[01:09:15.140 --> 01:09:17.140]  Другие мысли?
[01:09:17.140 --> 01:09:21.140]  Конечное число включает величины.
[01:09:21.140 --> 01:09:23.140]  Вы меня извините, я немножко глуховат.
[01:09:23.140 --> 01:09:24.140]  Говорите погромче.
[01:09:24.140 --> 01:09:26.140]  Конечное число включает величины.
[01:09:26.140 --> 01:09:27.140]  И что?
[01:09:27.140 --> 01:09:32.140]  Мы же для конечного числа событий вводили независимость совокупности.
[01:09:32.140 --> 01:09:38.140]  Точнее говоря, вводили понятие независимости.
[01:09:38.140 --> 01:09:42.140]  Смотрите, я припоминаю, видимо, вы уже забыли.
[01:09:42.140 --> 01:09:49.140]  Мы с вами доказывали такой красивый очень результат, что свойство независимости
[01:09:49.140 --> 01:09:53.140]  можно продлить по непрерывности с алгебры на симма-алгебру.
[01:09:53.140 --> 01:09:59.140]  То есть если вы имеете независимые алгебры, а это не что иное, как определение независимых алгебр,
[01:09:59.140 --> 01:10:05.140]  то вы можете то же самое утверждать и про элементы симма-алгебры.
[01:10:05.140 --> 01:10:07.140]  Вспоминаете?
[01:10:07.140 --> 01:10:11.140]  Поэтому вот это назовем формулировкой 1.
[01:10:11.140 --> 01:10:19.140]  Аналогичная ей формулировка Bgt принадлежит симма-минимальная от Барелийской алгебры,
[01:10:19.140 --> 01:10:22.140]  собственно, как мы определяли Барелийскую симма-алгебру.
[01:10:22.140 --> 01:10:27.140]  То есть и то, и другое определение эквивалентное.
[01:10:27.140 --> 01:10:28.140]  Но мы взяли алгебру.
[01:10:28.140 --> 01:10:37.140]  Но на самом деле я сразу скажу, мы в этом убедимся, что на самом деле Bgt может иметь вид,
[01:10:38.140 --> 01:10:44.140]  некая Agt, Bgt полуинтервал.
[01:10:44.140 --> 01:10:47.140]  Можно даже так взять.
[01:10:47.140 --> 01:10:50.140]  Это чуть-чуть забегая вперед.
[01:10:50.140 --> 01:10:57.140]  Но просто я хочу сказать, что любое из этих определений независимости эквивалентно.
[01:10:57.140 --> 01:11:03.140]  Можно определить на таких полуинтервалах, можно определить на элементах алгебры,
[01:11:03.140 --> 01:11:06.140]  можно определить на элементах симма-алгебры.
[01:11:06.140 --> 01:11:09.140]  Это эквивалентные определения.
[01:11:09.140 --> 01:11:15.140]  Теперь давайте попробуем с этим поразбираться.
[01:11:23.140 --> 01:11:25.140]  Да что ж такое?
[01:11:25.140 --> 01:11:28.140]  Это элемент алгебры.
[01:11:28.140 --> 01:11:31.140]  Именно ксижитое там просто подкопает?
[01:11:31.140 --> 01:11:34.140]  Ксижитое, ксижитое.
[01:11:34.140 --> 01:11:37.140]  Там подкопает?
[01:11:37.140 --> 01:11:40.140]  А, принадлежит, принадлежит.
[01:11:40.140 --> 01:11:44.140]  Просто вы проходите то, что мы давно уже прошли.
[01:11:44.140 --> 01:11:49.140]  В том смысле, что я коллегам сказал, что я эти значки путаю,
[01:11:49.140 --> 01:11:52.140]  поскольку считаю их там по сути эквивалентными.
[01:11:52.140 --> 01:11:56.140]  Из содержания обсуждения понятно, что имеется в виду.
[01:11:56.140 --> 01:12:00.140]  Вот, ну пусть будет, ну так да, так правильно.
[01:12:00.140 --> 01:12:05.140]  Вот, ну давайте тогда уж и здесь тогда.
[01:12:05.140 --> 01:12:10.140]  Вот, значит, что первое, давайте на что первое обратим внимание.
[01:12:10.140 --> 01:12:15.140]  Ну возьмем, например, определение номер один.
[01:12:15.140 --> 01:12:21.140]  И в качестве бжитого, там же мы любые можем брать,
[01:12:21.140 --> 01:12:26.140]  возьмем элемент минус бесконечность, там x житая.
[01:12:26.140 --> 01:12:31.140]  Тогда во что превратится это определение?
[01:12:31.140 --> 01:12:37.140]  Функция распределения x1, xn, мы взяли индекс,
[01:12:37.140 --> 01:12:46.140]  равно произведению f, ну тут может обозначить, давайте,
[01:12:46.140 --> 01:12:53.140]  здесь вектор, а здесь компонента, x житая от x житого.
[01:12:53.140 --> 01:13:01.140]  То есть, если случайные величины независимы вот в этом смысле,
[01:13:01.140 --> 01:13:06.140]  то тогда их функция произведения разлагается вот в произведение,
[01:13:06.140 --> 01:13:11.140]  то их функция распределения разлагается в произведение,
[01:13:11.140 --> 01:13:13.140]  в функции распределения компонента.
[01:13:13.140 --> 01:13:17.140]  Вот такое свойство, из независимости следует.
[01:13:17.140 --> 01:13:22.140]  Сейчас мы с вами покажем, поймем, мы, собственно,
[01:13:22.140 --> 01:13:25.140]  уже там все результаты практически получили для этого,
[01:13:25.140 --> 01:13:27.140]  просто надо в кучку их собрать.
[01:13:27.140 --> 01:13:30.140]  Сейчас мы поймем, что верно и обратно.
[01:13:30.140 --> 01:13:34.140]  Если функция распределения представима вот в таком виде,
[01:13:34.140 --> 01:13:40.140]  то случайные величины независимы в этом смысле.
[01:13:40.140 --> 01:13:47.140]  Вот, значит, и когда мы это сделаем,
[01:13:47.140 --> 01:13:51.140]  ну, точнее говоря, чуть забегая вперед, мы это сделаем,
[01:13:51.140 --> 01:13:57.140]  скажу сразу, что вот то свойство, на которое я обращал внимание,
[01:13:57.140 --> 01:14:01.140]  когда речь шла о независимости алгебр, а не случайных величин,
[01:14:01.140 --> 01:14:07.140]  здесь у нас отпадает необходимость вводить понятие типа независимости в совокупности,
[01:14:07.140 --> 01:14:12.140]  потому что устремив их житое плюс бесконечности нужные нам компоненты,
[01:14:12.140 --> 01:14:18.140]  мы получим, так его называют иногда, маргинальным распределением,
[01:14:18.140 --> 01:14:24.140]  предельным распределением некой группы, для которой будет верно вот это же свойство.
[01:14:24.140 --> 01:14:29.140]  То есть из вот этого свойства следует аналогичное свойство
[01:14:29.140 --> 01:14:32.140]  для любой подгруппы компонент вектора.
[01:14:32.140 --> 01:14:35.140]  Поэтому, просто повторюсь, я уже об этом говорил,
[01:14:35.140 --> 01:14:42.140]  утверждение о независимости случайных величин в совокупности нам просто не нужно,
[01:14:42.140 --> 01:14:46.140]  оно следует изходного.
[01:14:46.140 --> 01:14:50.140]  Так, значит, прям мало времени.
[01:14:50.140 --> 01:15:16.140]  Значит, давайте сначала рассмотрим ситуацию, когда мы имеем дело с вероятностью параллепипеда.
[01:15:21.140 --> 01:15:31.140]  По нашей формуле включение-исключение, это вот такая штука,
[01:15:45.140 --> 01:15:49.140]  где определили, знаем, что это такое.
[01:15:49.140 --> 01:15:55.140]  Вот смотрите, если верно вот такое свойство,
[01:15:55.140 --> 01:16:15.140]  то тогда это есть произведение f из житых степени К житых g от единицы до n.
[01:16:15.140 --> 01:16:21.140]  Вот так. И я сейчас напишу, и надеюсь, вы меня поймете,
[01:16:21.140 --> 01:16:23.140]  ну точнее говоря, увидите.
[01:16:23.140 --> 01:16:35.140]  Это на самом деле f b gt минус f a gt g от единицы до n.
[01:16:35.140 --> 01:16:38.140]  Смотрите, вот из чего состоят вот эти наборы.
[01:16:38.140 --> 01:16:44.140]  Это f от a и f от b, всевозможные комбинации,
[01:16:44.140 --> 01:16:52.140]  и знак минус возникает тогда, когда взято нечетное число f от a.
[01:16:52.140 --> 01:16:54.140]  Ну и посмотрите это тоже самое.
[01:16:54.140 --> 01:16:59.140]  Когда вы начнете скобки раскрывать, будут абсолютно всевозможные наборы,
[01:16:59.140 --> 01:17:05.140]  и отрицательный знак будут иметь те, где f от a вы возьмете в нечетном числе, когда будете раскрывать.
[01:17:05.140 --> 01:17:09.140]  То есть это вот так сворачивается.
[01:17:09.140 --> 01:17:12.140]  А вот это мы знаем, что такое с вами.
[01:17:12.140 --> 01:17:15.140]  Мы такое свойство с вами выводили,
[01:17:15.140 --> 01:17:18.140]  ну обращали на него внимание, выводили сильно сказано.
[01:17:18.140 --> 01:17:27.140]  Это на самом деле вероятность того, что x gt меньше b gt больше равно a gt.
[01:17:27.140 --> 01:17:30.140]  Согласны?
[01:17:30.140 --> 01:17:36.140]  И мы с вами доказали, что если в качестве множества b gt взять вот такие множества,
[01:17:36.140 --> 01:17:39.140]  то вот это равно вот этому.
[01:17:39.140 --> 01:17:44.140]  То есть на таких множествах свойство выполнено независимости.
[01:17:44.140 --> 01:17:48.140]  Теперь нам нужно сделать еще один шаг.
[01:17:48.140 --> 01:17:54.140]  Я прошу, может на минуту задержаться, чтобы не начинать с начала,
[01:17:54.140 --> 01:17:57.140]  и вы забудете через неделю.
[01:17:57.140 --> 01:18:01.140]  Так я схематично быстро, но надеюсь понятно.
[01:18:01.140 --> 01:18:06.140]  Теперь давайте покажем, что из вот этого свойства,
[01:18:06.140 --> 01:18:10.140]  то есть определение такого типа, следует вот это.
[01:18:10.140 --> 01:18:15.140]  Мы с вами знаем, что Борелевское множество в общем виде
[01:18:15.140 --> 01:18:21.140]  представляет из себя сумму множеств a gt, b gt,
[01:18:21.140 --> 01:18:24.140]  не пересекающихся в конечном числе.
[01:18:24.140 --> 01:18:27.140]  Вот общий вид Борелевской алгебры.
[01:18:27.140 --> 01:18:30.140]  В свое время мы это получали.
[01:18:30.140 --> 01:18:38.140]  Теперь смотрите, у нас вот таких вот множеств будет для каждого из b gt.
[01:18:38.140 --> 01:18:40.140]  Вот множество такого типа.
[01:18:40.140 --> 01:18:46.140]  Обратите внимание, что эти множества между собой не пересекаются несовместно.
[01:18:46.140 --> 01:18:52.140]  И в то же время любое множество для какого-нибудь b первого
[01:18:52.140 --> 01:18:56.140]  независимо от такого же множества b kt.
[01:18:56.140 --> 01:18:59.140]  Ну собственно так сказать, потому что это Борелевские множества.
[01:18:59.140 --> 01:19:01.140]  То есть мы с вами имеем...
[01:19:01.140 --> 01:19:04.140]  Так, тут какой индекс поставить?
[01:19:04.140 --> 01:19:09.140]  Давайте я тут поставлю какой-нибудь l.
[01:19:09.140 --> 01:19:15.140]  Мы с вами имеем веро...
[01:19:15.140 --> 01:19:17.140]  Что?
[01:19:17.140 --> 01:19:18.140]  Вот это?
[01:19:18.140 --> 01:19:22.140]  Ну это объединение, ну я же как бы...
[01:19:22.140 --> 01:19:25.140]  Объединение, сумма, произведение, точка.
[01:19:25.140 --> 01:19:27.140]  То есть точнее как пересечение, точка.
[01:19:27.140 --> 01:19:33.140]  Ну и когда вы писали общий вид Борельского множества, я так и писал, по-моему.
[01:19:33.140 --> 01:19:35.140]  Вот, значит тогда у нас тут...
[01:19:35.140 --> 01:19:41.140]  Я почему сейчас, ну как бы написал сумму, потому что мы результат получали соответствующий.
[01:19:41.140 --> 01:19:43.140]  Тут мы должны написать...
[01:19:43.140 --> 01:19:47.140]  Ну давайте напишу сумма b l.
[01:19:47.140 --> 01:19:53.140]  Точнее говоря, тут как раз произведение будет.
[01:19:53.140 --> 01:19:55.140]  Смотрите, что за структура.
[01:19:55.140 --> 01:20:00.140]  B l t представляет из себя объединение непересекающихся множеств.
[01:20:00.140 --> 01:20:04.140]  Каждое множество для различных b l t независимы.
[01:20:04.140 --> 01:20:07.140]  Вот эти события, что ксиприн лежит вот этому.
[01:20:07.140 --> 01:20:09.140]  И я напоминаю вам результат.
[01:20:09.140 --> 01:20:15.140]  Мы с вами получали, что для множества такой структуры они независимы между собой.
[01:20:15.140 --> 01:20:21.140]  Мы его правда получали для случая двух величин, но как бы по индукции продолжается.
[01:20:21.140 --> 01:20:23.140]  Припоминаете такой результат?
[01:20:23.140 --> 01:20:31.140]  Он выглядел так. Мы писали a равно сумма a k t, b равно сумма b l t,
[01:20:31.140 --> 01:20:36.140]  k на a m равно пустому множеству.
[01:20:36.140 --> 01:20:49.140]  Для любых l и k, вероятность a k b l равно вероятности a k b l.
[01:20:49.140 --> 01:20:51.140]  Припоминаете?
[01:20:54.140 --> 01:20:56.140]  Смотрите записи.
[01:20:56.140 --> 01:21:01.140]  Мы с вами получали такой результат, когда мы получали свойства независимости,
[01:21:01.140 --> 01:21:05.140]  множеств, которые не являются независимыми в совокупности.
[01:21:05.140 --> 01:21:09.140]  Мы в частном случае вот такую штуку с вами получили.
[01:21:09.140 --> 01:21:23.140]  Это когда мы с вами доказывали, что если система множеств независима, то и любые элементы алгебры в ней независимы.
[01:21:23.140 --> 01:21:27.140]  Здесь то же самое, только тут было 2, а тут n.
[01:21:27.140 --> 01:21:30.140]  Значит, вот эти множества все независимы.
[01:21:30.140 --> 01:21:37.140]  Это просто произведение вероятностей b l t.
[01:21:37.140 --> 01:21:42.140]  То есть xy принадлежит xy, l t принадлежит b l t.
[01:21:42.140 --> 01:21:48.140]  Извините задержал вас, но чтобы не начинать сначала.
[01:21:48.140 --> 01:21:51.140]  Итак, кратко итог.
[01:21:51.140 --> 01:21:59.140]  Мы с вами доказали свойства из того, что функция распределения распадается в такое произведение.
[01:21:59.140 --> 01:22:03.140]  Следует свойство независимости для множества такого типа.
[01:22:03.140 --> 01:22:09.140]  А потом доказали, что если верно для множества такого типа, то верно для множества такого типа,
[01:22:09.140 --> 01:22:11.140]  то есть из Борельской алгебры.
[01:22:11.140 --> 01:22:19.140]  И по теореме о продолжении непрерывности то же самое верно и для элементов сигма алгебры.
[01:22:19.140 --> 01:22:23.140]  Ну вот это некая логическая точка.
[01:22:23.140 --> 01:22:25.140]  Все, спасибо.
