[00:00.000 --> 00:02.000]  ,
[00:02.000 --> 00:04.000]  ,
[00:04.000 --> 00:06.000]  ,
[00:06.000 --> 00:08.000]  ,
[00:08.000 --> 00:10.000]  ,
[00:10.000 --> 00:12.000]  ,
[00:12.000 --> 00:14.000]  ,
[00:14.000 --> 00:16.000]  ,
[00:16.000 --> 00:18.000]  ,
[00:18.000 --> 00:20.000]  ,
[00:20.000 --> 00:22.000]  ,
[00:22.000 --> 00:24.000]  ,
[00:24.000 --> 00:26.000]  ,
[00:26.000 --> 00:28.000]  ,
[00:28.000 --> 00:34.260]  произведение v на v. Соответственно, связи могут быть как неориентированными,
[00:34.260 --> 00:39.900]  то есть у нас по сути нет такого, что в этой связи b и c как-то выделены отдельно
[00:39.900 --> 00:44.940]  вершины b или как-то выделены отдельно вершины c, либо рёбра или связи могут быть
[00:44.940 --> 00:50.300]  ориентированными. Мы говорим, что связь проведена из вершины c в вершину b.
[00:50.300 --> 00:53.300]  Соответственно, когда мы будем обсуждать какие-то конкретные алгоритмы,
[00:53.440 --> 00:58.740]  когда вы будете решать конкретные задачи, обычно уточняется, что имеется в виду рёбра
[00:58.740 --> 01:01.980]  ориентированные или неориентированные. Если мы говорим про эти множества,
[01:01.980 --> 01:08.940]  то есть если мы говорим формально про множество v и e, то если у нас граф неориентированный,
[01:08.940 --> 01:13.580]  то эти пары в множестве e не упорядочены. То есть это просто некоторые двойки.
[01:13.580 --> 01:16.940]  Соответственно, если граф ориентированный, то пара упорядочена. Всё достаточно просто.
[01:16.940 --> 01:21.100]  Вот у нас есть связь b-a и, соответственно, вот есть рибро b-a. Пока всё понятно.
[01:21.100 --> 01:27.420]  Ну и соответственно, для чего нужны такие структуры? Почему важно изучать алгоритмы
[01:27.420 --> 01:30.740]  на таких вещах? Вообще говоря, довольно много вещей из реальной жизни.
[01:30.740 --> 01:35.700]  Я уже в процессе общения привёл несколько примеров. Довольно много приложений,
[01:35.700 --> 01:41.340]  так или иначе, на самом деле представляют в виде графов, в виде их взаимодействий и так далее.
[01:41.340 --> 01:44.220]  И, собственно, здесь уже можно придумать много различных постановок.
[01:44.980 --> 01:47.700]  А как быстро можно добраться из одной вершины до другой?
[01:47.700 --> 01:50.460]  А вообще, в принципе, из одной вершины до другой можно добраться или нет?
[01:50.460 --> 01:54.100]  Вообще говоря, можно ли выделить в этом большом графе какой-нибудь кусок,
[01:54.100 --> 01:59.100]  который, условно, сильно связан, в котором между любой парой вершин есть какая-то связь.
[01:59.100 --> 02:02.460]  Или между любой парой вершины можно добраться до любой другой и так далее.
[02:02.460 --> 02:06.380]  То есть эти вопросы, я думаю, вы сами понимаете, что довольно часто в многих приложениях
[02:06.380 --> 02:11.260]  представляют некоторый интерес. Ну вот, соответственно, мы какие-то общие алгоритмы,
[02:11.260 --> 02:15.580]  какие-то общие подходы работаем с такими структурами, мы и, собственно, рассмотрим.
[02:15.580 --> 02:21.580]  Вот. Да, соответственно, ещё продолжаем несколько определений.
[02:21.580 --> 02:26.340]  Соответственно, если у вас в графе допустимые так называемые мультирёбра,
[02:26.340 --> 02:29.620]  то есть между одной парой вершин может проходить сразу несколько ребер,
[02:29.620 --> 02:35.140]  то такой граф называется мультиграф. Соответственно, вот тут между парой 1 и 2,
[02:35.140 --> 02:39.820]  то есть из вершины 1 вершины 2 приведено сразу два ребра, поэтому этот граф – это мультиграф.
[02:39.820 --> 02:48.940]  Вот. Что? Ну смотрите, у вас может быть такая ситуация, что есть вершина 1, есть вершина 2.
[02:48.940 --> 02:56.500]  И, скажем, на одном ребре написано значение, допустим, длина этого пути равна единице,
[02:56.500 --> 03:01.420]  длина этого пути равна двойке. То есть два разных пути.
[03:01.420 --> 03:06.180]  И плюс вы можете ставить различные вопросы типа, а сколькими способами можно из одной вершины
[03:06.180 --> 03:11.220]  добраться к другой. Вот. И если у вас путей несколько, то, соответственно, вы путь из 1 и 2
[03:11.220 --> 03:14.260]  учитываете два раза. То есть, грубо говоря, у вас из единицы двойку есть два пути.
[03:14.260 --> 03:18.500]  И, соответственно, естественно, вот эти кратные ребра влияют длина количества общих путей
[03:18.500 --> 03:21.700]  из какой-то вершины до любой другой. Понятно, да?
[03:21.700 --> 03:27.220]  Такие ситуации вполне могут возникать. Вот. Плюс могут возникать ситуации,
[03:27.220 --> 03:33.220]  при которой у вас связь проведена из одной вершины в саму себя. Вот. Это так называемые петли.
[03:33.380 --> 03:37.780]  Граф с петлями называется псевдографом. Соответственно, если вы в графе разрешаете
[03:37.780 --> 03:43.060]  и петли, и, скажем, микратные ребра, то такой граф называется мульти псевдограф.
[03:43.060 --> 03:46.820]  То есть мульти означает, что между парой вершин может быть проведено несколько ребер.
[03:46.820 --> 03:54.100]  Псевдографы это значит, что у вас в графе допускаются петли. Все понятно? Окей.
[03:57.460 --> 04:02.260]  Дальше. Еще несколько определений. Соответственно, степень вершины в неориентированном графе
[04:02.260 --> 04:05.140]  называется prosnap с количеством ребер, которые торчат из этой вершины.
[04:05.140 --> 04:09.280]  Ну, если у меня ориентированный граф, соответственно, если у меня есть
[04:09.280 --> 04:14.980]  какой-то неориентированный граф, здесь такое, то, соответственно, если я
[04:14.980 --> 04:19.500]  у насмотрю вершину A, то степень этой вершины равна finding point.
[04:19.500 --> 04:23.040]  Степень вершины В – равна 1, степень вершины Ц – это 1.
[04:23.040 --> 04:30.180]  То есть, ровно степень совпадает с количеством ребер, которые торчат из этой вершины.
[04:30.180 --> 04:36.380]  Если у нас граф ориентированный, то тут мы говорим не про степень вершины,
[04:36.380 --> 04:41.220]  а про полустепень вершины. Рёбра в вершину могут как входить, так и выходить.
[04:41.220 --> 04:46.420]  Полустепенью исхода вершины обозначается вот так. Мы будем называть количество исходящих ребер.
[04:46.420 --> 04:50.700]  Количество ребер, у которых в качестве первой координаты выступает сама вершина В.
[04:50.700 --> 04:55.580]  Полустепенью захода вершины – это количество ребер, которые в эту вершину входят.
[04:55.580 --> 04:57.580]  Всё довольно просто.
[04:57.580 --> 05:12.580]  Ну и соответственно довольно очевидно утверждение состоит в том, что если вы возьмёте неориентированный граф и просуммируете все степени вершин,
[05:12.580 --> 05:16.580]  то получите 2e. Это для неориентированного графа.
[05:16.580 --> 05:26.580]  Если возьмёте ориентированный граф, то и просуммируете какую-нибудь полустепень, например, полустепень исхода, то получится g.
[05:26.580 --> 05:32.580]  Это нужно как-то отдельно пояснять? А у вас теория графа уже была?
[05:32.580 --> 05:37.580]  Ну всё, отлично. Давайте кратко просто скажу, что у каждого ребра есть своё начало.
[05:37.580 --> 05:41.580]  То есть тут мы взяли и все начало просуммировали, но соответственно все начало совпадают.
[05:41.580 --> 05:44.580]  У нас есть значение соответственно между ребром и его началом.
[05:44.580 --> 05:50.580]  А тут у нас и начало и конец совпадают, поэтому каждое ребро в этой сумме учитываем два раза.
[05:50.580 --> 05:58.580]  Ну соответственно, если теория графа уже знакома, давайте быстро пробежимся, просто напомним какие-то определения.
[05:58.580 --> 06:01.580]  То есть путём в графе называется простонаобоспоследовательность вершины ребер.
[06:01.580 --> 06:06.580]  Причём каждое ребро соединяет соседние вершины в последовательность.
[06:06.580 --> 06:10.580]  То есть вы говорите, что сначала идём в эту вершину, потом по этому ребру проходим все в эту вершину,
[06:10.580 --> 06:12.580]  потом по этому ребру проходим в другую вершину и так далее.
[06:12.580 --> 06:17.580]  Почему нам важно уточнять ребра? Потому что опять же повторюсь, что у нас могут быть ситуации, при которой
[06:17.580 --> 06:25.580]  соответственно нет.
[06:25.580 --> 06:29.580]  Почему мы уточняем ещё дополнительные ребра?
[06:29.580 --> 06:35.580]  Потому что у нас может быть такая ситуация, что между двумя вершинами может быть несколько ребер.
[06:35.580 --> 06:39.580]  Соответственно мы уточняем по всему конкретному ребру, мы идём из вершины х в вершину у.
[06:39.580 --> 06:45.580]  Хотя если у вас граф не мультиграф, то есть если вы запрещаете кратные ребра,
[06:45.580 --> 06:48.580]  то это просто последовательность вершин.
[06:48.580 --> 06:51.580]  Простой путь — это путь, в котором нет повторяющихся вершин.
[06:51.580 --> 06:55.580]  Грубо говоря, путь без циклов. Путь без циклов — это простой путь.
[06:55.580 --> 07:02.580]  Цикл — это замкнутый путь. Это путь, который начинается и заканчивается в одной и той же вершине.
[07:02.580 --> 07:05.580]  Это довольно просто.
[07:05.580 --> 07:09.580]  Это значит, что касается теории, теперь давайте поговорим больше про алгоритмы.
[07:09.580 --> 07:12.580]  Мы сейчас будем изучать такую штуку как графы.
[07:12.580 --> 07:18.580]  Естественно мы хотим эти самые графы, чтобы это не значило, как-то уметь представлять в памяти компьютера.
[07:18.580 --> 07:21.580]  В зависимости от того, как вы представляете граф в памяти компьютера,
[07:21.580 --> 07:29.580]  это очень сильно влияет на эффективность алгоритмов, в чём мы неоднократно убедимся в процессе следующих лекций.
[07:29.580 --> 07:32.580]  Давайте пока просто обсудим, как можно представлять графы в памяти.
[07:32.580 --> 07:36.580]  Как мы будем представлять вершины, тут всё довольно просто.
[07:36.580 --> 07:41.580]  Мы всегда будем предполагать, что на вершинах задана какая-то естественная нумерация.
[07:41.580 --> 07:46.580]  То есть у нас просто вершины, то есть понятное дело, что мы будем работать с конечными графами.
[07:46.580 --> 07:50.580]  И каждой вершине мы ставим соответственно некоторый индекс.
[07:50.580 --> 07:54.580]  То есть от 0 до v-1.
[07:54.580 --> 08:01.580]  Предполагаем, что все вершины просто-напросто пронумерованы с нулевого элемента по v-1.
[08:01.580 --> 08:06.580]  Самое интересное это то, как мы будем представлять ребра.
[08:06.580 --> 08:10.580]  Тут начинаются всякие разные тонкости, разные всякие интересности.
[08:10.580 --> 08:15.580]  Самый простой способ представлять ребра это просто взять массив или вектор
[08:15.580 --> 08:19.580]  и сохранить в нём последовательность пар.
[08:19.580 --> 08:24.580]  Если у меня есть граф 0,1,2 и в нём такие вот ребра, то соответственно я создаю массив,
[08:24.580 --> 08:28.580]  в котором храню пары 0,1,1,2,0,2.
[08:28.580 --> 08:31.580]  То есть это довольно простой и тупой способ.
[08:31.580 --> 08:35.580]  Давайте поговорим о том, как он работает на практике.
[08:35.580 --> 08:37.580]  Меня будут интересовать 4 штуки всегда.
[08:37.580 --> 08:43.580]  Это памяти, сколько памяти мы занимаем, сколько памяти занимает наш граф в компьютере.
[08:43.580 --> 08:47.580]  Соответственно за сколько времени у нас проходит обход всех ребер.
[08:47.580 --> 08:50.580]  То есть я хочу взять и обойти все ребра графа.
[08:50.580 --> 08:54.580]  Дальше поиск ребра, это значит я хочу взять какое-нибудь конкретное ребро
[08:54.580 --> 08:56.580]  и понять, а есть оно у меня в графе или нет.
[08:56.580 --> 08:58.580]  То есть грубо говоря, у меня есть две вершины 2 и 3.
[08:58.580 --> 09:02.580]  Я хочу понять между ними есть ли бро, между ними есть какая-то связь или нет.
[09:02.580 --> 09:04.580]  И последнее это получение соседей вершины.
[09:04.580 --> 09:08.580]  То есть это тоже будет важная операция, которая будет использоваться многократно в последующих алгоритмах.
[09:08.580 --> 09:12.580]  То есть я хочу взять вершину и узнать все вершины, которые смежены с ней.
[09:12.580 --> 09:14.580]  То есть все вершины, которые являются её соседем.
[09:14.580 --> 09:18.580]  Все вершины, в которые я могу попасть из этой вершины.
[09:18.580 --> 09:21.580]  Давайте обсудим память.
[09:21.580 --> 09:23.580]  От Е, наверное.
[09:23.580 --> 09:25.580]  От модуль Е.
[09:25.580 --> 09:27.580]  Даже тета.
[09:27.580 --> 09:28.580]  Ну понятно.
[09:28.580 --> 09:33.580]  То есть так как я храню массив пар, то у меня каждое ребро один раз встречается в списке.
[09:33.580 --> 09:35.580]  Поэтому тут все понятно.
[09:35.580 --> 09:37.580]  За сколько я могу обойти все ребра?
[09:37.580 --> 09:39.580]  Тоже тета от Е.
[09:39.580 --> 09:42.580]  Тоже прохожусь просто-напросто по массиву и, соответственно,
[09:42.580 --> 09:45.580]  не знаю, печатают на экран, что-то узнаю про них и так далее.
[09:45.580 --> 09:46.580]  Тут все просто.
[09:46.580 --> 09:48.580]  Поиск ребра.
[09:48.580 --> 09:50.580]  Тоже тета от Е.
[09:50.580 --> 09:51.580]  Действительно.
[09:51.580 --> 09:54.580]  Так как я храню просто-напросто неупорядоченный список ребер,
[09:54.580 --> 09:58.580]  то чтобы найти конкретное ребро, в худшем случае мне придется пройти по всему массиву
[09:58.580 --> 10:00.580]  и определить, есть ли он или нет.
[10:00.580 --> 10:04.580]  Ну и наконец получение соседей вершин.
[10:04.580 --> 10:08.580]  Почему Е квадрат?
[10:08.580 --> 10:09.580]  Ну тоже за Е, на самом деле, да.
[10:09.580 --> 10:11.580]  Тоже за линию.
[10:11.580 --> 10:15.580]  То есть все операции выполняются за линию.
[10:15.580 --> 10:18.580]  Почему там, как последний пункт, получение соседей вершин?
[10:18.580 --> 10:21.580]  Ну просто мы проходим по всему списку.
[10:21.580 --> 10:23.580]  И, соответственно, если у нас граф не ориентированный как здесь,
[10:23.580 --> 10:25.580]  точнее, наоборот, ориентированный как здесь,
[10:25.580 --> 10:26.580]  то мы просто смотрим на первую координату.
[10:26.580 --> 10:29.580]  Если первая координата совпала с интересующей нас,
[10:29.580 --> 10:33.580]  то там печатаем ее на экран, что-то с ней делаем.
[10:33.580 --> 10:35.580]  Соседей. Да, есть одна вершина.
[10:35.580 --> 10:39.580]  Получаем в соседе вершину единицы или двойки.
[10:39.580 --> 10:41.580]  Ну тут не интересно.
[10:41.580 --> 10:43.580]  На самом деле эта структура данных нам пригодится.
[10:43.580 --> 10:45.580]  То есть тут она довольно простая.
[10:45.580 --> 10:47.580]  У нее очень мало накладных расходов.
[10:47.580 --> 10:50.580]  Но в большинстве ситуаций бесполезно.
[10:50.580 --> 10:55.580]  Поэтому давайте пока ее оставим и пойдем дальше.
[10:55.580 --> 10:58.580]  Следующая идея заключается в следующем.
[10:58.580 --> 11:04.580]  Смотрите, всякого рода операции поиска, то есть поиск конкретного ребра
[11:04.580 --> 11:07.580]  или поиск соседей вершины занимает долгое время.
[11:07.580 --> 11:11.580]  Поэтому, соответственно, возникает естественное желание как-то ускорить.
[11:11.580 --> 11:14.580]  И вот, собственно, самая простая идея, то, как можно хранить ребра,
[11:15.080 --> 11:18.580]  не просто в виде списка, а в виде сортированного списка.
[11:18.580 --> 11:21.580]  Давайте возьмем наш список ребр
[11:21.580 --> 11:23.580]  и будем поддерживать его от сортированных.
[11:23.580 --> 11:25.580]  То есть будем поддерживать его от сортированных
[11:25.580 --> 11:26.580]  по первой координате
[11:26.580 --> 11:28.580]  и по второй координате.
[11:28.580 --> 11:30.580]  Идея понятна, да?
[11:30.580 --> 11:33.580]  То есть сначала...
[11:33.580 --> 11:37.580]  Спасибо. Сначала по первой координате, то есть откуда идет ребро.
[11:37.580 --> 11:41.580]  А потом внутри вот этого списка.
[11:41.580 --> 11:45.660]  У меня есть все ребра, которые ведут из вершины ноль.
[11:45.660 --> 11:48.860]  Да, соответственно, внутри него сортируется уже по второй координате.
[11:48.860 --> 11:50.860]  Но обычно лексиографическое сравнение пар.
[11:50.860 --> 11:54.860]  Окей? Вот.
[11:54.860 --> 11:56.860]  Чего мы таким образом добиваемся?
[11:56.860 --> 11:58.860]  Со сколько теперь у нас будет работать поиск ребра?
[11:58.860 --> 12:04.860]  Да, поиск ребра теперь будет работать за логарифм D.
[12:04.860 --> 12:10.060]  Ну, обычным бинарным поиском, так как мы знаем, что все пары отсортированы
[12:10.060 --> 12:19.340]  в порядке взрастания или в порядке убывания, соответственно, тут можно спокойно применить бинарный пояс для того, чтобы определить, есть ли данное ребро в нашем графе или нет.
[12:19.340 --> 12:21.340]  Ну и, наконец, получение соседей вершины.
[12:21.340 --> 12:25.340]  Ну, не совсем. Тут более точный ответ.
[12:25.340 --> 12:29.340]  То есть, действительно, за логарифмом что мы можем найти?
[12:29.340 --> 12:33.340]  Да, за логарифм можем найти, ну, скорее, lower bound.
[12:33.340 --> 12:39.340]  То есть, начало того момента, когда у меня начинаются ребра, которые ведут из конкретной вершины.
[12:39.340 --> 12:45.340]  Но чтобы вывести все остальные вершины, естественно, мне нужно еще деговое время, согласна?
[12:45.340 --> 12:51.340]  Ну, я нашел начало, и потом мне нужно пройтись, там, все их вывести, там, все сохранить куда-то и так далее.
[12:51.340 --> 12:57.340]  Вот такая история.
[13:03.340 --> 13:05.340]  С этим тоже проблем нет, тут все понятно.
[13:05.340 --> 13:15.340]  Так, давайте спложнять структуры и перейдем к наиболее, на самом деле, к наиболее применимым на практике.
[13:15.340 --> 13:21.340]  Вот как ни странно, сортированный список ребер используется довольно редко, и нами он тоже, я думаю, практически не будет использоваться.
[13:21.340 --> 13:25.340]  Теперь давайте перейдем к более применимым структуре данных на практике.
[13:25.340 --> 13:27.340]  Первая это матрица смешности.
[13:27.340 --> 13:29.340]  Значит, идея тут очень простая.
[13:29.340 --> 13:33.340]  Давайте заведем двумерную матричку размера В на В.
[13:35.340 --> 13:45.340]  И просто напротив каждой ячейки ИЖ будем хранить либо булевский флаг, либо количество ребер.
[13:45.340 --> 13:55.340]  Ну, в общем, так или иначе, будем хранить некоторую информацию о том, принадлежит ли ребро ИЖ множеству ребер Е.
[13:55.340 --> 13:59.340]  Тут стоит либо единичка, либо ноль.
[13:59.340 --> 14:05.340]  Ну, либо просто количество ребер, если мы говорим про мультиграф.
[14:05.340 --> 14:15.340]  То есть, если у нас есть граф 0,1,2, то, соответственно, в ячейке 2,1 стоит ноль, потому что из вершины 2 в вершины 1 нет ревра.
[14:15.340 --> 14:21.340]  Но при этом в ячейке 1,2 стоит единичка, так как у нас есть ребро из единицы в двойку.
[14:21.340 --> 14:27.340]  Идея понятна, да?
[14:27.340 --> 14:39.340]  Ну, я думаю, сразу не вооруженно взглядом вида, что недостатком такой структуры данных является то, что она в памяти занимает В квадрат.
[14:39.340 --> 14:49.340]  То есть, условно, если вот, скажем, больше тысячи вершин, то уже больше тысячи или больше десяти тысяч вершин, то уже как-то становится все грустно.
[14:49.340 --> 14:52.340]  Да, еще один момент нужно упомянуть.
[14:52.340 --> 14:54.340]  Тут сказано про разреженные графы.
[14:54.340 --> 15:01.340]  Давайте тоже я про это скажу, что мы будем, как правило, рассматривать две ситуации.
[15:01.340 --> 15:04.340]  Первая ситуация – это граф разреженный.
[15:04.340 --> 15:12.340]  Разреженным графом будем называть такой граф, к которому количество ребер не примерно равно, но по порядку величины совпадает с числом вершин.
[15:12.340 --> 15:17.340]  То есть, это означает, что из каждой вершины торчит не очень много ребер, так скажем.
[15:17.340 --> 15:24.340]  Скажем, количество ребра отличается от количества вершин не больше, чем на какую-то константу.
[15:24.340 --> 15:27.340]  Не больше, чем в какую-то констанцию раз.
[15:27.340 --> 15:31.340]  И, значит, будут у нас плотные графы.
[15:31.340 --> 15:35.340]  Плотным графом называется такой граф, у которого есть практически все ребра.
[15:35.340 --> 15:46.340]  Но я думаю, вы понимаете, что если у вас полный граф, то есть, если у вас в графе есть все ребра, то, соответственно, в таком графе, если, опять же, мы не учитываем повторяющиеся ребра,
[15:46.340 --> 15:51.340]  максимум вот столько ребра.
[15:51.340 --> 15:53.340]  Ну, это порядка в квадрат.
[15:53.340 --> 16:03.340]  Соответственно, если у вас из каждой вершины торчат все ребра практически в каждую вершину, то, соответственно, у вас порядка в квадрат ребер.
[16:03.340 --> 16:09.340]  Ну, соответственно, тут сразу понятно, что если у вас граф разреженный, то есть, не очень плотный, то хранить матрицу смежности не очень-то эффективно.
[16:09.340 --> 16:12.340]  Почему? Потому что у вас там очень мало единичек и очень много нулей.
[16:12.340 --> 16:18.340]  Соответственно, вы просто тратите в пустую большое количество памяти просто для того, чтобы сохранить там нули.
[16:18.340 --> 16:20.340]  Ну, не очень приятно.
[16:20.340 --> 16:23.340]  За сколько будет работать обход всех ребер?
[16:27.340 --> 16:29.340]  Так, первый пункт в квадрат, второй.
[16:29.340 --> 16:31.340]  Ну, действительно, тоже в квадрат.
[16:31.340 --> 16:34.340]  То есть, понимаем, как получить все ребра из этих стокпурданов.
[16:34.340 --> 16:36.340]  Ну, нам нужно просто-напросто пройтись по всем ячейкам.
[16:36.340 --> 16:44.340]  И скажем, если в ячейке стоит какое-то не отрицательное, не нулевое число, то, соответственно, мы говорим, что это ребро есть в нашем графе.
[16:44.340 --> 16:46.340]  Поиск ребра.
[16:46.340 --> 16:49.340]  Вот, а поиск ребра работает за единицу, что уже приятно.
[16:49.340 --> 16:57.340]  То есть, тут мы уже, в отличие от предыдущих структур данных, в смысле списка ребер и сертированного списка ребра, мы теперь чисто за единицу можем понимать,
[16:57.340 --> 16:59.340]  а есть ли данное ребро в нашем графе или нет.
[16:59.340 --> 17:01.340]  Ну, просто-напросто так матрица смежности устроена.
[17:01.340 --> 17:04.340]  То есть, идем в соответствующую ячейку, и там стоит либо единичка, либо нолик.
[17:04.340 --> 17:09.340]  Ну, и наконец, получение соседей вершины за линию относительно чего?
[17:09.340 --> 17:11.340]  За В, да.
[17:11.340 --> 17:14.340]  То есть, как получить соседей, например, вершины 1?
[17:14.340 --> 17:19.340]  Нужно просто пройтись по этой строчке и выписать все те столбцы, в которых стоит значение 1.
[17:19.340 --> 17:23.340]  Тоже все. Тоже все, думаю, понятно.
[17:26.340 --> 17:29.340]  Вот такая вот структура данных.
[17:29.340 --> 17:34.340]  Так, ну и наконец, финальная структура данных это списки смежности.
[17:34.340 --> 17:38.340]  Значит, списки смежности устроены довольно интересно.
[17:38.340 --> 17:41.340]  Значит, тут мы будем действовать следующим образом.
[17:41.340 --> 17:44.340]  Давайте просто-напросто заведем массив.
[17:48.340 --> 17:50.340]  Массив размера В.
[17:50.340 --> 18:05.340]  И в каждой ячейке, ну, например, ячейке номер 2, будем хранить список из тех вершин,
[18:05.340 --> 18:10.340]  в которые ведут ребра из вершины 2.
[18:10.340 --> 18:12.340]  Х, Ю, З.
[18:12.340 --> 18:14.340]  То есть, это означает, что у вас есть вершины 2.
[18:14.340 --> 18:17.340]  Из вершины 2 торчат ребра в вершину Х.
[18:17.340 --> 18:19.340]  В вершине Х.
[18:19.340 --> 18:24.340]  вершину х, вершину у и вершину z.
[18:32.340 --> 18:35.340]  Про это мы отдельно поговорим, что если у нас граф неориентированный,
[18:35.340 --> 18:37.340]  как его хранить, это будет отдельный вопрос.
[18:37.340 --> 18:39.340]  Давайте пока рассуждать терминах ориентированного графа.
[18:39.340 --> 18:40.340]  Пока все просто.
[18:40.340 --> 18:42.340]  С неориентированными графами там...
[18:42.340 --> 18:44.340]  В общем, поговорим отдельно.
[18:44.340 --> 18:47.340]  Пока граф ориентированный, все довольно понятно.
[18:47.340 --> 18:49.340]  Вот пример еще одного графа.
[18:49.340 --> 18:51.340]  Тут у меня есть вершина 0,
[18:51.340 --> 18:53.340]  и из нее торчат ребра в единицу и двойку.
[18:53.340 --> 18:56.340]  Соответственно, вот из нуля торчит список.
[18:56.340 --> 18:59.340]  В нулевом списке хранится список из единицы и двойки.
[18:59.340 --> 19:03.340]  Из единицы есть ребро только в двойку, поэтому тут хранится двойка.
[19:03.340 --> 19:07.340]  Соответственно, из двойки никуда пройти нельзя, поэтому тут пустой список.
[19:07.340 --> 19:11.340]  Как устроить список смежности тоже понятно.
[19:13.340 --> 19:15.340]  Кстати, очень похоже на хэш-таблицу.
[19:15.340 --> 19:21.340]  Грубо говоря, у вас ребра с одинаковым началом пронятся в одной и той же ячейке.
[19:21.340 --> 19:24.340]  Ну да, по сути, это оно и есть.
[19:24.340 --> 19:26.340]  Вот.
[19:26.340 --> 19:29.340]  Соответственно, я думаю, понятно, что памяти данной структуры данных
[19:29.340 --> 19:31.340]  занимает вот этот v plus e.
[19:31.340 --> 19:34.340]  То есть просто-напросто линейная память от размера графа.
[19:34.340 --> 19:36.340]  Кстати, граф представляет...
[19:36.340 --> 19:40.340]  Размером графа считается пара из числа вершины и числа ребр.
[19:40.340 --> 19:43.340]  То есть и то и то входит в понятие размера графа.
[19:43.340 --> 19:45.340]  Вот. Ну откуда берется v plus e, понятно?
[19:45.340 --> 19:51.340]  Надо, то есть v это внешний список, ну и суммарная длина внутренних списков равна e.
[19:51.340 --> 19:53.340]  Окей? Окей.
[19:53.340 --> 19:57.340]  Так, значит, теперь я хочу обойти все ребра графа.
[19:57.340 --> 20:01.340]  За сколько у меня получится это сделать?
[20:01.340 --> 20:05.340]  Да, тоже на самом деле v plus e.
[20:05.340 --> 20:07.340]  То есть тут v plus e.
[20:07.340 --> 20:12.340]  И обход всех ребра графа тоже занимает v plus e, ну, по понятным причинам, да, опять же.
[20:12.340 --> 20:14.340]  Ну, мне нужно пройтись по всем спискам,
[20:14.340 --> 20:17.340]  и плюс мне нужно еще дополнительно пройтись по всем элементам этого массива.
[20:17.340 --> 20:21.340]  Но даже если, скажем, какая-то ячейка пустая, мне об этом нужно как-то узнать.
[20:21.340 --> 20:24.340]  Поэтому я прохожусь и по всем ячейкам внешнего массива,
[20:24.340 --> 20:27.340]  и по всем спискам, и по всем внутренним спискам.
[20:27.340 --> 20:30.340]  Окей, теперь мне нужно найти какое-то конкретное ребро.
[20:33.340 --> 20:35.340]  Да, если я хочу найти...
[20:37.340 --> 20:39.340]  Не буду большое.
[20:40.340 --> 20:45.340]  То есть если меня спрашивают какую-то конкретную вершину,
[20:45.340 --> 20:49.340]  точнее, меня спрашивают конкретное ребро v-у,
[20:49.340 --> 20:53.340]  то, соответственно, понять, есть ли данное ребро в моем графе или нет, довольно просто.
[20:53.340 --> 20:57.340]  Я просто иду в соответствующий список для вершины v
[20:57.340 --> 20:59.340]  и прохожусь по нему.
[20:59.340 --> 21:02.340]  Соответственно, работаю за степень v.
[21:02.340 --> 21:06.340]  Вот тут, кстати, можно обсудить сразу же некоторые улучшения списка смешности.
[21:06.340 --> 21:08.340]  Вот, можно ли как-то эту симптотику улучшить?
[21:08.340 --> 21:10.340]  Будут ли какие-то предложения?
[21:12.340 --> 21:14.340]  Нули? Какие нули?
[21:18.340 --> 21:22.340]  Так, да, можно вот эти списки сами внутри хранить сортированными.
[21:22.340 --> 21:24.340]  Окей, что в итоге получим?
[21:24.340 --> 21:34.340]  Глударифом дег v, да, это если мы храним сортированный список.
[21:34.340 --> 21:39.340]  Да, там еще была идея у кого-то хранить бинарное дерево поиска.
[21:39.340 --> 21:41.340]  В самом деле неплохая идея тоже.
[21:41.340 --> 21:43.340]  То есть если мы тут храним...
[21:43.340 --> 21:47.340]  Ну, не важно, просто какое-нибудь сбалансированное бинарное дерево поиска, да.
[21:47.340 --> 21:49.340]  Мы храним какое-то сбалансированное бинарное дерево поиска,
[21:49.340 --> 21:52.340]  и тогда тоже ассимтотика поиска будет вот такой.
[21:52.340 --> 21:56.340]  И более того, мы можем эффективно вставлять элементы вот в эту структуру данных.
[21:56.340 --> 21:58.340]  Вот тоже за алгоритмом.
[21:58.340 --> 22:00.340]  А можно что еще сделать?
[22:04.340 --> 22:06.340]  Последние две лекции, что обсуждали?
[22:06.340 --> 22:08.340]  Хэш, что у нас тогда будет?
[22:11.340 --> 22:13.340]  Ну, единицу в среднем, да.
[22:13.340 --> 22:17.340]  То есть вот тут на самом деле, вот здесь вы можете хранить хэш-таблицу.
[22:17.340 --> 22:21.340]  Вот в этой хэш-таблице хранить все элементы,
[22:21.340 --> 22:25.340]  все вершины, в которые ведет ребро из нулевой вершины.
[22:25.340 --> 22:27.340]  И скажем, если хэш-таблица достаточно хорошая,
[22:27.340 --> 22:31.340]  то в среднем за единицу вы будете как вставлять туда новые ребра,
[22:31.340 --> 22:33.340]  так и удалять новые, удалять ребра.
[22:33.340 --> 22:39.340]  И, соответственно, поиск ребер тоже будет в среднем за единицу выполняться.
[22:41.340 --> 22:45.340]  Нет, это все просто фантазии.
[22:45.340 --> 22:47.340]  Скорее всего, вам это не понадобится.
[22:47.340 --> 22:53.340]  В большинстве ситуаций нам поиск ребра тупо не понадобится.
[22:53.340 --> 22:57.340]  Самая важная операция, которая нам будет нужна, это краски последние.
[22:57.340 --> 22:59.340]  И вот для последней на самом деле плевать, как вы храните.
[22:59.340 --> 23:01.340]  Ну, точнее, с точки зрения константы не плевать,
[23:01.340 --> 23:05.340]  но с точки зрения симптотики все равно, как вы храните.
[23:05.340 --> 23:09.340]  За сколько времени я могу получить соседей вершины?
[23:09.340 --> 23:17.340]  Ну да, тут смотрите, тут есть такие рассуждения,
[23:17.340 --> 23:25.340]  что если вы хотите вернуть отдельный список вершин,
[23:25.340 --> 23:27.340]  то вам нужно потратить степень вершин.
[23:27.340 --> 23:29.340]  Почему? Потому что вы идете в соответствующую ячейку
[23:29.340 --> 23:33.340]  и проходите по этим элементам, выводите их на экран
[23:33.340 --> 23:37.340]  или возвращаете какую-то копию массива.
[23:37.340 --> 23:41.340]  Но тут есть такой момент, что на самом деле,
[23:41.340 --> 23:45.340]  если вы под получением соседей вершины подразумеваете просто-напросто,
[23:45.340 --> 23:47.340]  что вам нужно вернуть какой-то список,
[23:47.340 --> 23:51.340]  то вы на самом деле можете за единицу вернуть уже сразу готовый список, согласны?
[23:51.340 --> 23:57.340]  Ну, допустим, вот если это STD-вектор, то вы можете просто вернуть ссылку на вектор,
[23:57.340 --> 23:59.340]  то есть ссылку на тот же самый список.
[23:59.340 --> 24:04.340]  И тогда вот в этом смысле поиск соседей вершины занимает просто от единицы.
[24:04.340 --> 24:06.340]  Понятно?
[24:06.340 --> 24:10.340]  Поэтому тут можно скобку указать, что вообще это от единицы,
[24:10.340 --> 24:15.340]  если речь идет про возврат либо указателя на этот массив,
[24:15.340 --> 24:19.340]  либо ссылку на этот массив внутренний и так далее.
[24:22.340 --> 24:25.340]  Поэтому в этом смысле списки смежности очень крутые,
[24:25.340 --> 24:28.340]  то есть мы можем и поиск ребра свести к единице,
[24:28.340 --> 24:32.340]  и получение соседей вершины тоже свести код единицы,
[24:32.340 --> 24:35.340]  в случае, если это действительно требуется.
[24:36.340 --> 24:41.340]  Ну и на самом деле списки смежности – это будет самое часто используемое у нас на лекции,
[24:41.340 --> 24:44.340]  то есть у вас на семинарах структура данных.
[24:44.340 --> 24:46.340]  Понятно?
[24:52.340 --> 24:55.340]  Ну да, собственно, вот то, что мы обсудили, что на самом деле вместо массивов и списков
[24:55.340 --> 24:57.340]  можно хранить бинарные деревья поиска или, конечно, таблицы,
[24:57.340 --> 25:02.340]  вот тогда, соответственно, асимпатически третий пункт будет выполняться быстрее.
[25:02.340 --> 25:05.340]  Да, ну, понятное дело, что это асимпатически, в каком смысле?
[25:05.340 --> 25:08.340]  Смотрите, если у вас на самом деле граф достаточно небольшой,
[25:08.340 --> 25:11.340]  или если третий пункт вам на самом деле нафиг не нужен,
[25:11.340 --> 25:15.340]  то, вообще говоря, хранить хэш-таблицу или хранить бинарные деревья поиска не очень поразумно.
[25:15.340 --> 25:19.340]  Да, потому что если у вас размер списочков небольшой,
[25:19.340 --> 25:22.340]  то это означает, что вы храните очень большое количество дополнительных ресурсов,
[25:22.340 --> 25:26.340]  вы тратите гораздо больше лишнего времени на то, чтобы поддерживать эти маленькие списки
[25:26.340 --> 25:29.340]  ассортированными или организовывать хэш-таблицу.
[25:29.340 --> 25:34.340]  Кроме того, если вам пункт 3 не нужен совсем, то есть если вам не нужно искать ребра,
[25:34.340 --> 25:37.340]  а вам нужно, скажем, просто получать список соседей,
[25:37.340 --> 25:42.340]  то тогда вы тратите лишнюю память на хранение всяких разных указателей и так далее.
[25:42.340 --> 25:46.340]  Ну и плюс, я думаю, вы понимаете, что обход дерева занимает гораздо больше времени,
[25:46.340 --> 25:49.340]  чем, скажем, просто обход массива.
[25:49.340 --> 25:54.340]  Поэтому тут надо уступать из принципа разумности.
[25:54.340 --> 25:59.340]  Что в конкретной задаче вам нужно, то есть нужно ли вам осуществлять быстрый поиск или нет.
[25:59.340 --> 26:02.340]  Так, ну и да, перед тем, как пойдем дальше,
[26:02.340 --> 26:05.340]  давайте, собственно, обсудим вопрос, который возник.
[26:05.340 --> 26:11.340]  Вот тут были приведены примеры представления графов для ориентированного случая.
[26:11.340 --> 26:16.340]  Что если у нас в графе все ребра имеют определенное направление?
[26:16.340 --> 26:19.340]  Что можно сказать про неориентированный граф?
[26:19.340 --> 26:22.340]  Какие у вас будут предложения?
[26:22.340 --> 26:27.340]  Ну скажем, вот есть вот такой вот граф.
[26:27.340 --> 26:34.340]  И, допустим, я хочу его хранить в списке смежности.
[26:34.340 --> 26:37.340]  Что будем делать?
[26:37.340 --> 26:56.340]  Ну да, на самом деле более-менее есть два подхода.
[26:56.340 --> 27:03.340]  Можно хранить только то, можно представлять всегда так, что у вас, значит,
[27:03.340 --> 27:06.340]  стартовая вершина всегда является меньшей ребро.
[27:06.340 --> 27:10.340]  То есть тогда мы тут храним 0,1, а 1,0 уже не храним и так далее.
[27:10.340 --> 27:14.340]  Но, возможно, другая ситуация, при которой мы храним одновременно оба ребра.
[27:14.340 --> 27:18.340]  То есть, грубо говоря, у нас такая, то есть заменяем одно ориентированное ребро,
[27:18.340 --> 27:21.340]  точнее одно неориентированное ребро, двумя ориентированными ребрами.
[27:21.340 --> 27:25.340]  И, на самом деле, на практике именно вот такой вот способ он гораздо удобней,
[27:25.340 --> 27:27.340]  ну как правило.
[27:27.340 --> 27:29.340]  Вот такая вот ситуация.
[27:29.340 --> 27:31.340]  Понятно, да?
[27:31.340 --> 27:34.340]  Но тут я сразу должен сказать некоторые замечания
[27:35.340 --> 27:39.340]  Несмотря на то, что это, как правило, удобней,
[27:39.340 --> 27:42.340]  стоит помнить вот о такой проблеме.
[27:42.340 --> 27:48.340]  Понимаете ли вы, что вот такой граф вообще, говоря, не эквивалентен вот такому графу?
[27:59.340 --> 28:03.340]  Так, ну а давайте так, в термине какого-нибудь свойства графа.
[28:03.340 --> 28:07.340]  Какое свойство, что есть у этого графа и чего нет у этого графа.
[28:07.340 --> 28:08.340]  Да, циклы.
[28:08.340 --> 28:11.340]  Вот одна из первых задач, которые мы с вами рассмотрим, это будет поиск циклов.
[28:11.340 --> 28:14.340]  Ну, скорее всего, уже в следующий раз рассмотрим, но так или иначе.
[28:14.340 --> 28:19.340]  Важно помнить, что в этом графе циклы есть, а вот в этом графе циклов нет.
[28:19.340 --> 28:21.340]  Поэтому, если вы изначально работаете с неориентированным графом
[28:21.340 --> 28:23.340]  и пытаетесь в неориентированном графе найти циклы,
[28:23.340 --> 28:27.340]  но при этом представляете вот такой граф, как ориентированный с двумя направленными ребрами,
[28:27.340 --> 28:31.340]  то алгоритм поиска циклов скорее всего даст вам неправильный ответ,
[28:31.340 --> 28:34.340]  он даст вам информацию в том, что тут на самом деле циклы есть.
[28:34.340 --> 28:37.340]  Об этом стоит помнить, окей?
[28:41.340 --> 28:45.340]  Можно, тут скорее будут другие истории,
[28:45.340 --> 28:48.340]  на конкретном алгоритме, что если вы, скажем,
[28:48.340 --> 28:51.340]  прошлись из вершины 1 в вершину 0, то обратно
[28:51.340 --> 28:54.340]  проходить вы будете запрещать просто-напросто.
[28:54.340 --> 28:56.340]  Ну а о конкретных применениях мы просто поговорим,
[28:56.340 --> 28:59.340]  просто я предупреждаю, что если вы храните
[28:59.340 --> 29:02.340]  неориентированный граф как ориентированный,
[29:02.340 --> 29:04.340]  что, как правило, удобнее, но стоит помнить о том,
[29:04.340 --> 29:07.340]  что иногда свойства неориентированного графа не сохраняются.
[29:07.340 --> 29:10.340]  Сейчас вы увидели, что появились лишние циклы.
[29:16.340 --> 29:24.340]  С обсуждением того, как представлять графы в памяти мы покончили.
[29:24.340 --> 29:26.340]  Давайте еще раз напомню, о чем поговорили.
[29:26.340 --> 29:28.340]  Можно хранить граф в виде просто списка ребер,
[29:28.340 --> 29:32.340]  точнее так. С хранением вершин никаких проблем нет.
[29:32.340 --> 29:34.340]  Просто у каждой вершины мы ставим соответственно
[29:34.340 --> 29:37.340]  некоторую учиселку, то есть от 0 до v-1.
[29:37.340 --> 29:40.340]  Главная проблема заключается в том, как мы будем хранить ребр,
[29:40.340 --> 29:44.340]  как мы будем хранить связи в графе.
[29:44.340 --> 29:50.340]  Первый способ это список ребер, дальше сортированный список ребер,
[29:50.340 --> 29:54.340]  дальше соответственно матрица смежности и список смежности.
[29:54.340 --> 29:56.340]  Есть четыре способа.
[29:56.340 --> 29:59.340]  На самом деле обсуждать мы будем, как правило, только последние два.
[29:59.340 --> 30:02.340]  К первому двум будем обращаться в отдельных ситуациях.
[30:10.340 --> 30:12.340]  Как картинку?
[30:12.340 --> 30:14.340]  В смысле, вы имеете в виду...
[30:21.340 --> 30:23.340]  Как бы вам объяснить?
[30:24.340 --> 30:32.340]  Так можно делать, но это крайне неэффективно в том смысле,
[30:32.340 --> 30:39.340]  что я хочу обратиться к вершине номер 10 и узнать ее соседей.
[30:39.340 --> 30:44.340]  Скорее всего, мне придется еще дополнительно отдельно хранить
[30:44.340 --> 30:48.340]  какой-нибудь массив, который будет хранить еще дополнительные указатели
[30:48.340 --> 30:52.340]  на вот эти самые штучки.
[30:52.340 --> 30:56.340]  Тут по сути вы получили список смежности,
[30:56.340 --> 31:00.340]  в котором еще между элементами списка хранят еще дополнительные связи.
[31:00.340 --> 31:04.340]  То есть вы еще сильнее вы сложили структуру.
[31:04.340 --> 31:08.340]  Поэтому так, как правило, никто не делает.
[31:08.340 --> 31:15.340]  Первый алгоритм, который мы рассмотрим, и, наверное, единственный на сегодня,
[31:15.340 --> 31:18.340]  это обход графа ширину.
[31:21.340 --> 31:28.340]  Давайте сначала разберемся с тем, что такое вообще обход графа.
[31:28.340 --> 31:31.340]  Обход графа — это процесс посещения всех вершин и ребер графа.
[31:31.340 --> 31:32.340]  Все очень просто.
[31:32.340 --> 31:34.340]  То есть стоит задача такая, у нас есть граф,
[31:34.340 --> 31:38.340]  нужно просто посетить все вершины и посетить все ребра.
[31:38.340 --> 31:41.340]  Казалось бы, задача очень неинтересная.
[31:41.340 --> 31:45.340]  В цикле проходимся по всем вершинам, в цикле проходимся по всем ребрам.
[31:45.340 --> 31:48.340]  Но, как правило, обходы устроены следующим образом.
[31:48.340 --> 31:56.340]  Обходы осуществляются с учетом того, какая у вас в графе существует структура.
[31:56.340 --> 32:02.340]  Обходы устроены так, что они учитывают локальность графа.
[32:02.340 --> 32:10.340]  Если у вас из вершины 0 есть какие-то ребра в вершины 1 и 2,
[32:10.340 --> 32:13.340]  то, соответственно, из вершины 0 вы можете пройти только в вершины 1 и 2.
[32:13.340 --> 32:16.340]  Если дальше из вершины 1 у вас есть ребра только в вершины 5 и 6,
[32:16.340 --> 32:18.340]  то вы можете пройти только в них и так далее.
[32:18.340 --> 32:22.340]  То есть обход графа — это некоторый процесс посещения вершины ребер такой,
[32:22.340 --> 32:25.340]  что он позволяет выявить какие-то свойства графа,
[32:25.340 --> 32:28.340]  какие-то локальные свойства графа или какие-то глобальные свойства графа.
[32:28.340 --> 32:31.340]  То есть это обход с уважением структуры графа.
[32:31.340 --> 32:35.340]  А не просто-напросто вычисление вершины и ребер.
[32:35.340 --> 32:45.340]  Сегодня знакомимся с обходом графа ширину,
[32:45.340 --> 32:48.340]  и обход графа ширину действует на самом деле очень просто.
[32:48.340 --> 32:52.340]  Вот у нас есть, допустим, какой-то граф.
[32:52.340 --> 33:11.340]  Какие-то вот ребра, пусть 0, 1, 2, 3, 4, 5, 6.
[33:11.340 --> 33:14.340]  Когда мы начинаем обход, мы, как правило, выбираем какой-то стартовый вершин,
[33:14.340 --> 33:17.340]  то есть ту вершину, с которой мы начинаем обход.
[33:17.340 --> 33:21.340]  Давайте предположим, что мы начали обход с вершины 0.
[33:21.340 --> 33:23.340]  Как устроено обход ширину?
[33:23.340 --> 33:28.340]  У нас сначала берет какую-то вершину и просматривает ее соседей.
[33:28.340 --> 33:31.340]  После того, как мы просмотрели соседи одной вершины,
[33:31.340 --> 33:33.340]  мы рассматриваем соседей соседей.
[33:33.340 --> 33:38.340]  То есть по сути мы постепенно увеличиваем область нашей видимости.
[33:38.340 --> 33:42.340]  Таким образом мы открываем все более более новые вершины,
[33:42.340 --> 33:45.340]  все более более удаленные ребра.
[33:45.340 --> 33:47.340]  То есть как устроен обход здесь?
[33:47.340 --> 33:50.580]  То есть как устроен обход здесь? То есть сначала мы находимся в вершине номер 0,
[33:50.580 --> 33:56.780]  дальше, соответственно, мы видим, что соседними нашими являются вершина 3, 4 и 6.
[33:56.780 --> 34:02.340]  То есть порядок обхода у нас примерно следующий. То есть это вершина 0, вершина 3, вершина 4 и вершина 6.
[34:02.340 --> 34:13.340]  То есть вот то, что мы обошли в нулевой момент времени, то, что мы обошли в первый момент времени.
[34:14.340 --> 34:18.340]  Что происходит дальше? Дальше мы берем, соответственно, вершину, которую мы уже пустили,
[34:18.340 --> 34:24.340]  сейчас вершину 3, и обходим ее соседей. То есть идем в вершину номер 1, идем в вершину номер 2.
[34:24.340 --> 34:30.340]  Добавляем x список, вышли вершину 1, 2. Дальше у нас была вершина номер 4, мы обходим ее соседей,
[34:30.340 --> 34:35.340]  в данном случае это вершина номер 3. Идем в вершину номер 6, обходим ее соседей,
[34:35.340 --> 34:40.340]  и увидим, что всех соседей мы уже обошли. То есть это вершина не 3, а 5.
[34:45.340 --> 34:49.340]  Всех соседей вершины 6 мы уже обошли, поэтому мы на нее забиваем, больше ничего не делаем.
[34:49.340 --> 34:52.340]  И, соответственно, вот у нас получился вот такой порядок обхода.
[34:52.340 --> 34:57.340]  Это вот то, что у нас получилось на втором уровне.
[34:57.340 --> 35:02.340]  То есть вот в нулевой момент времени у нас была точна только стартовая вершина 0.
[35:02.340 --> 35:06.340]  Дальше, когда мы обошли ее соседей, мы получили, скажем так, соседей первого уровня,
[35:06.340 --> 35:11.340]  это вершины 3, 4, 6. Дальше на следующий момент времени мы обошли соседей соседей,
[35:11.340 --> 35:14.340]  то есть получили соседей второго уровня. Ну и, понятное дело, что если игра большой,
[35:14.340 --> 35:17.340]  то мы продолжаем действие таким образом.
[35:17.340 --> 35:22.340]  Соответственно, получился вот такой вот порядок обхода.
[35:23.340 --> 35:27.340]  Ну и перерывом давайте ответим на вопрос.
[35:27.340 --> 35:30.340]  Как вы думаете, если мы действуем вот такой вот тактикой,
[35:30.340 --> 35:33.340]  то есть если вот такой тактикой мы пытаемся обойти все вершины и ребра графа,
[35:33.340 --> 35:36.340]  какие свойства мы о графе можем узнать таким образом?
[35:39.340 --> 35:41.340]  Вот, я услышал корочеше расстояние, отлично.
[35:41.340 --> 35:45.340]  Понимаете ли вы, что если я покажу таким образом сначала соседей, потом соседей, соседей и так далее,
[35:45.340 --> 35:48.340]  то я на самом деле для каждой вершины знаю ее расстояние,
[35:48.340 --> 35:52.340]  ну расстояние от нее до стартовой вершины.
[35:52.340 --> 35:56.340]  Вот, то есть отлично, первое применение это кратчайшее расстояние от,
[35:56.340 --> 35:59.340]  ну давайте обозначу S, от стартовой вершины.
[35:59.340 --> 36:02.340]  Так, что еще?
[36:02.340 --> 36:04.340]  Число вариантов дойти.
[36:04.340 --> 36:07.340]  Число вариантов дойти, ну...
[36:11.340 --> 36:14.340]  Ну на самом деле число вариантов скорее всего не получится.
[36:14.340 --> 36:17.340]  Почему? Потому что у нас есть серебра, которые мы просто игнорируем.
[36:17.340 --> 36:19.340]  Вот это ребро, вот это ребро.
[36:23.340 --> 36:27.340]  Ну, возможно, можно, короче, тут все-таки мы предполагаем,
[36:27.340 --> 36:31.340]  что мы отходим только те ребра, которые там ведут в непосеченные вершины.
[36:31.340 --> 36:34.340]  Тут на самом деле есть второе очень хорошее применение,
[36:34.340 --> 36:44.340]  это множество достижимых вершин.
[36:44.340 --> 36:47.340]  И третье это проверка связности.
[36:47.340 --> 36:57.340]  Проверка связности нюорграфа.
[36:57.340 --> 37:00.340]  Понятно, и второй и третий пункты это про что?
[37:00.340 --> 37:03.340]  Ну второй пункт, по сути он похож на первый пункт,
[37:03.340 --> 37:06.340]  мы просто узнаем все те вершины, до которых можно дотянуться из этой вершины.
[37:06.340 --> 37:09.340]  То есть мы узнаем список всех вершин,
[37:09.340 --> 37:12.340]  до которых теоретически есть путь из данной вершины.
[37:12.340 --> 37:16.340]  И третий пункт, проверка связности неориентированного графа.
[37:16.340 --> 37:20.340]  Все понимают, что какой связанный граф, связанный неориентированный граф.
[37:20.340 --> 37:24.340]  Но это просто граф, в котором из любой вершины есть путь до любой другой.
[37:24.340 --> 37:29.340]  Понятно ли, как с помощью вот этого обхода проверить связность графа?
[37:29.340 --> 37:37.340]  Ну да, если мы запустили обход из поля бы вершины и посетили все вершины,
[37:37.340 --> 37:39.340]  то граф соответственно связный.
[37:39.340 --> 37:41.340]  То есть если из одной вершины можно добраться до любой другой,
[37:41.340 --> 37:44.340]  то это означает, что из любой вершины можно добраться и до любой другой.
[37:44.340 --> 37:47.340]  Ну как минимум через вот эту центральную вершину.
[37:47.340 --> 37:50.340]  Ну и наоборот тоже, естественно, верно.
[37:50.340 --> 37:55.340]  Ну окей, давайте...
[37:55.340 --> 37:59.340]  Можно четвертым пунктом найти количество связанных компонентов.
[37:59.340 --> 38:02.340]  Найти компоненты связанных.
[38:02.340 --> 38:05.340]  Ну действительно, если у вас компонент связанности несколько,
[38:05.340 --> 38:10.340]  то соответственно вы запускаете один обход,
[38:10.340 --> 38:11.340]  тогда он находит вам одну компонент,
[38:11.340 --> 38:14.340]  потом из непосещенной вершины запускаете второй обход и так далее.
[38:14.340 --> 38:16.340]  Таким образом вы находите все компоненты связанности.
[38:16.340 --> 38:19.340]  Но опять же повторю, это верно для неориентированного графа.
[38:19.340 --> 38:22.340]  Понятно, что для ориентированного графа этот алгоритм не сработает.
[38:22.340 --> 38:24.340]  Ну на самом деле тут вопрос в другом,
[38:24.340 --> 38:28.340]  что на самом деле непонятно, что означает связанность в ориентированном графе.
[38:28.340 --> 38:31.340]  Ну например...
[38:31.340 --> 38:32.340]  Ну ладно, это мы уже...
[38:32.340 --> 38:34.340]  Ну давайте, в общем, перерыв в любом случае будет.
[38:34.340 --> 38:35.340]  Давайте такой философский вопрос.
[38:35.340 --> 38:37.340]  Вот как вы думаете, этот граф связан или нет?
[38:40.340 --> 38:41.340]  Вот, отлично, да.
[38:41.340 --> 38:44.340]  Если в общем для ориентированного графа есть два понятия связанности,
[38:44.340 --> 38:45.340]  сильный связан, слабый связан,
[38:45.340 --> 38:47.340]  о ней мы тоже поговорим, но не сегодня.
[38:47.340 --> 38:50.340]  Поэтому пока мы когда говорим про связанность,
[38:50.340 --> 38:54.340]  мы имеем в виду именно, собственно, неориентированные графы.
[38:54.340 --> 38:58.340]  Все, перерыв.
[38:58.340 --> 39:03.340]  Такой-нибудь небольшой пример.
[39:08.340 --> 39:11.340]  Два, три, четыре.
[39:16.340 --> 39:18.340]  Вот такой вот.
[39:21.340 --> 39:24.340]  Вот такой вот граф.
[39:24.340 --> 39:27.340]  Значит, что мы будем делать?
[39:27.340 --> 39:30.340]  Ну, то есть мы будем хранить в процессе работы алгоритма
[39:30.340 --> 39:32.340]  последний functions данного алгоритма.
[39:32.340 --> 39:34.320]  Начну, смотрите, так как мы поняли, что с помощью данного алгоритма
[39:34.320 --> 39:36.320]  в принципе можно вычитать кратчайшее расстояние,
[39:36.320 --> 39:40.340]  то давайте заведем специальный мотив,
[39:40.340 --> 39:45.340]  в котором, собственно, будем хранить кратчайшее расстояние до каждой из вершин.
[39:45.340 --> 39:47.340]  Вот, соответственно, если мы будем знать кратчайшее
[39:47.340 --> 39:48.340]  расстояние до каждой из вершин,
[39:48.340 --> 39:50.340]  то, соответственно, и множество до AlongedStoreah в вершин, и так далее,
[39:50.340 --> 39:51.340]  мы, естественно, тоже узнаем.
[39:51.340 --> 39:53.340]  Ну и, собственно, давайте скажем, что изначально,
[39:53.340 --> 39:55.340]  так как мы про вершины ничего не знаем,
[39:55.340 --> 39:59.900]  все, соответственно, расстояния равны бесконечностям.
[39:59.900 --> 40:03.380]  Соответственно, бесконечность, она как раз таки будет нам сообщить о том, что до
[40:03.380 --> 40:07.340]  данной вершины добраться невозможно. Ну, какое-то законечное число шаблов.
[40:07.340 --> 40:14.980]  Вот это нулевая вершина, первая, вторая, третья, четвертая. Вот, дальше, смотрите,
[40:14.980 --> 40:19.100]  чтобы восстановить путь, да, как мы будем восстанавливать путь? Это тоже интересный
[40:19.100 --> 40:23.500]  вопрос. Значит, смотрите, чтобы восстановить путь, я утверждаю, что нам достаточно, на самом деле,
[40:24.100 --> 40:29.300]  для каждой вершины, знать, из какой вершины мы ее посетили.
[40:29.300 --> 40:29.380]  То есть, из какой вершины мы в нее попали. То есть, вы 있으reto скажете,
[40:29.380 --> 40:32.600]  если мы знаем, что с четвертой вершиной вывали из третьей вершины,
[40:32.600 --> 40:36.300]  а из третьей вершины попали из нулевой вершины, то, соответственно, таким образом и путь мы тоже восстановим.
[40:36.300 --> 40:40.420]  Дополнительно мы еще будем хранить массив родителей, массив parents.
[40:40.420 --> 40:46.140]  Ну, parent, собственно, будет как раз таки хранить, из какой вершины мы попали в данную преобходим.
[40:46.140 --> 40:53.300]  Понятно? Ну и везде пока храним.
[40:53.300 --> 41:06.300]  1, 2, 3, 4. Пока тут ничего нет. Ну и, собственно, как работает данный алгоритм.
[41:06.300 --> 41:10.300]  Соответственно, мы выбираем какую-то старую вершину. Ну, например, нам в условии сдачи сказано,
[41:10.300 --> 41:15.300]  что нужно найти кратчайшее расстояние из вершины под номером 2, да, ну и кратчайшее расстояние из вершины под номером 3.
[41:15.300 --> 41:27.300]  Если это неважно, то, скажем, берем какую-то произвольную вершину. Да, мы ищем алгоритм обхода в глубину, в ширину умеет искать кратчайшие пути из данной вершины до всех остальных.
[41:27.300 --> 41:33.300]  То есть есть некоторые отдельно выделенные вершины, из нее мы ищем пути, мы ищем все остальные пути.
[41:33.300 --> 41:39.300]  Ну, в данном случае давайте просто и возьмем просто нулевую вершину, скажем, что нам нужно найти все кратчайшие пути из нулевой вершины.
[41:39.300 --> 41:47.300]  Вот. Что мы делаем? Ну, во-первых, так как мы начинаем с нулевой вершины, мы понимаем, что кратчайшее расстояние из нулевой вершины до нулевой это 0,
[41:47.300 --> 41:59.300]  и, соответственно, ну, редко у нее так и нет. Вот. И что мы сделаем? Мы заведем некоторую очередь, очередь посещения вершин.
[41:59.300 --> 42:05.300]  Ну, и, соответственно, посещать вершины будем в порядке очереди, которой будет задаваться вот эта вот структура данных.
[42:06.300 --> 42:13.300]  Ну, и алгоритм на самом деле очень прост. Пока у нас не опустеет очередь, мы из этой очереди достаем вершины и посещаем их.
[42:13.300 --> 42:19.300]  В чем состоит опот вершины? Значит, вот мы берем вершину, которая находится в очереди, то есть извлекаем ее.
[42:19.300 --> 42:26.300]  В данном случае это была вершина 0. Вот. И дальше проходимся по всем ее соседям. То есть мы достали вершину 0 и идем по всем соседям.
[42:26.300 --> 42:32.300]  Значит, как только мы встречаем соседа, мы проверяем, посещали мы его раньше, как мы узнаем, посещали мы его раньше или нет.
[42:32.300 --> 42:39.300]  Ну просто сравним ее с бесконечности. Понятно? Если до него, до нового соседа расстояние бесконечности, значит мы его раньше не посещали.
[42:39.300 --> 42:46.300]  Окей? Вот проверяем. Ну, соответственно, вот единицу мы раньше не встречали, поэтому мы ее добавляем во первых в очередь,
[42:46.300 --> 42:55.300]  а во-вторых мы говорим, что мы до нее нашли новое расстояние. Да? То есть мы обновляем расстояние тут с бесконечности до единицы.
[42:55.300 --> 43:01.300]  Почему до единицы? Потому что расстояние до вершины 0 это 0, расстояние до вершины 1 стало равно 0 плюс 1, то есть 1.
[43:01.300 --> 43:06.220]  Допустим, мы дальше встречаем вершину под номером 3 в рамках вот этого цикла.
[43:06.220 --> 43:11.100]  А, да, еще забыли, обновить родители. Вот у единицы мы ставим родителя 0.
[43:11.100 --> 43:14.740]  Встречаем вершину под номером 3, добавляем ее в очередь,
[43:14.740 --> 43:19.700]  обновляем до вершины номер 3 расстояние, то есть была бесконечность, стала единица.
[43:19.700 --> 43:24.220]  И, соответственно, родителям вершины 3 стало вершина 0.
[43:24.220 --> 43:27.700]  Дальше встречаем соседа с номером 2.
[43:27.740 --> 43:34.580]  Двойки тоже обновляем расстояние до единицы и обновляем родителя.
[43:34.580 --> 43:38.100]  Добавляем в очередь. Все, на этом цикл завершен.
[43:38.100 --> 43:43.660]  Мы прошли всех соседей. Ну и на этом закончили, понятно.
[43:43.660 --> 43:47.180]  Вот, ну, конкретно этот цикл. Дальше снова приходим вот в этот цикл while.
[43:47.180 --> 43:50.100]  У нас очередь не пустая, поэтому достаем очередную вершину.
[43:50.100 --> 43:53.980]  Очередная вершина — это вершина номер 1. Достаем ее и теперь продолжаем делать то же самое
[43:53.980 --> 43:58.660]  из вершины под номером 1. Вот. То есть в цикле проходим по всем ее соседям и, собственно,
[43:58.660 --> 44:02.260]  проверяем, посещали мы ее соседа или нет. Если не посещали, то, соответственно,
[44:02.260 --> 44:05.660]  делаем все то же самое. Ну давайте посмотрим. Вот есть вершина номер 1.
[44:05.660 --> 44:10.300]  И видим, что у нее есть сосед под номером 2. Но соседа под номером 2 мы уже посещали.
[44:10.300 --> 44:14.220]  Как мы это поняли? Вот мы поняли это с помощью вот этого WI-FI.
[44:14.220 --> 44:18.380]  Мы посмотрели на расстояние до вершины 2 и поняли, что оно было уже когда-то раньше обновлено.
[44:18.380 --> 44:20.700]  Но это значит, что мы когда-то раньше эту вершину уже встречали,
[44:20.700 --> 44:22.700]  поэтому ее заново обрабатывать уже не нужно.
[44:22.700 --> 44:27.580]  Окей, забиваем на вершину номер 2. Смотрим на другого соседа единица.
[44:27.580 --> 44:31.420]  Другой сосед единицы — это четверка. Четверку мы еще не посещали,
[44:31.420 --> 44:35.100]  поэтому мы до четверки обновляем расстояние. Это 2.
[44:35.100 --> 44:38.580]  Да, почему 2? Потому что мы берем расстояние до чекущей вершины,
[44:38.580 --> 44:43.180]  то есть до единицы, и прибавляем единицу. То есть до четверки у нас расстояние на единицу больше,
[44:43.180 --> 44:47.660]  чем до единицы. Ну и, соответственно, до четверки обновляем родителя.
[44:47.660 --> 44:53.660]  До четверки родители — это вершина под номером 1. Вот. Добавляем четверку в очередь.
[44:53.660 --> 45:00.140]  Все, на этом обработку единицы завершили. Снова идем в цикл. Пока очередь не пустая,
[45:00.140 --> 45:03.260]  у нас очередь не пустая. Достаем вершину, достаем вершину под номером 3.
[45:03.260 --> 45:07.140]  Из вершин номер 3 пытаемся обойти соседей. Смотрим, а все ее соседи,
[45:07.140 --> 45:10.900]  все соседи вершины 3, уже посещены. То есть ее соседом является четверка,
[45:10.900 --> 45:14.740]  четверка уже была посещена, поэтому у нас для тройки жизнь завершается.
[45:14.740 --> 45:19.220]  Снова у нас очередь не пустая, достаем двойку. Достали двойку, из двойки вообще нет никаких
[45:19.220 --> 45:23.700]  исходящих ребер, поэтому цикл в принципе не отрабатывает. Завершили. Достаем четверку,
[45:23.700 --> 45:27.780]  из четверки тоже никаких исходящих ребер нет. Завершаем обработку четверки. Все, в этот момент
[45:27.780 --> 45:32.180]  у нас очередь опустела, больше никаких новых непосещенных вершин у нас нет. Соответственно,
[45:32.180 --> 45:35.940]  этот цикл отработал, мы заканчиваем работу алгоритма, то есть возвращаем, что нам нужно,
[45:35.940 --> 45:43.260]  либо массив расстояния, либо массив родителей, либо и то и другое. Понятно, да? Вот, собственно,
[45:43.260 --> 45:52.860]  все в докод алгоритма и то, как он, то, как он устроен. Что? Каким образом?
[45:52.860 --> 46:18.100]  Ну, можно поступить и так. Вообще говоря, мы поговорим про улучшение этого алгоритма,
[46:18.100 --> 46:22.260]  но, смотрите, вообще говоря, посещение вершин оно же в чем заключается? Тут же не обязательно,
[46:22.860 --> 46:26.880]  то есть тут стоит не обязательно просто цикл посещения всех вершин. Процесс
[46:26.880 --> 46:33.140]  посещения вершины может заключаться в том, что мы посещаем вершину и что-то в ней делаем и так далее.
[46:33.140 --> 46:38.720]  В этом случае нам нужно зайти в каждую вершину, то есть добавляем очередь. Когда добавляем
[46:38.720 --> 46:42.300]  очередь, мы говорим, что когда-то мы ее посетим, когда-то мы в ней stupidity сделаем.
[46:42.300 --> 46:45.900]  Или когда-то мы обработаем. И обработка, она не обязательно может заключаться,
[46:45.900 --> 46:51.300]  вы просто обходите соседей. Это просто наиболее общий алгоритм того, как обойти все вершины
[46:51.300 --> 46:53.300]  и обойти все рёбра, окей?
[46:57.300 --> 46:59.300]  Окей, за сколько работает данный алгоритм?
[47:06.300 --> 47:08.300]  Ну, давайте просуждаем.
[47:10.300 --> 47:12.300]  Смотрите, тут есть цикл в цикле.
[47:12.300 --> 47:13.300]  Да?
[47:13.300 --> 47:16.300]  Ну и когда мы говорим про цикл в цикле, вообще говоря, довольно...
[47:16.300 --> 47:19.300]  Не знаю, самое первое желание, которое возникает, какое?
[47:19.300 --> 47:26.300]  Посчитать количество итераций внешнего цикла, посчитать количество итераций внутреннего цикла и перемножить.
[47:26.300 --> 47:27.300]  Да?
[47:28.300 --> 47:31.300]  Но, к сожалению, это будет слишком грубая оценка. Почему?
[47:31.300 --> 47:34.300]  Вот сколько итераций выполняется внешний цикл?
[47:36.300 --> 47:38.300]  Ну, максимум v раз, согласны?
[47:38.300 --> 47:41.300]  Каждая вершина у меня не более одного раза находится в очереди.
[47:41.300 --> 47:45.300]  Соответственно, у меня общее количество итераций цикла while тоже не больше, чем v.
[47:45.300 --> 47:48.300]  А с чему равно количество итераций внутреннего цикла?
[47:48.300 --> 47:50.300]  В худшем случае?
[47:52.300 --> 47:53.300]  Ну, v.
[47:53.300 --> 47:54.300]  Погласны?
[47:54.300 --> 47:58.300]  То есть если вдруг у меня из каждой вершины торчат ребра во все остальные,
[48:00.300 --> 48:02.300]  то вот такая ситуация получается.
[48:04.300 --> 48:05.300]  Погласны?
[48:06.300 --> 48:07.300]  Почему?
[48:11.300 --> 48:13.300]  Каждую вершину обещаем не больше, чем по разу.
[48:13.300 --> 48:15.300]  Так, и что из этого следует?
[48:16.300 --> 48:20.300]  Да. Вот я как раз говорю к тому, что вот это на самом деле очень грубая оценка.
[48:20.300 --> 48:23.300]  То есть, смотрите, действительно, если мы сверху будем оценивать
[48:23.300 --> 48:25.300]  общее количество итераций внешнего цикла,
[48:25.300 --> 48:28.300]  это v, сверху будем оценивать количество итераций внутреннего цикла,
[48:28.300 --> 48:29.300]  тоже v, согласны?
[48:29.300 --> 48:31.300]  Вже в эд подрат.
[48:31.300 --> 48:33.300]  Но это слишком грубая оценка. Давайте под точнее.
[48:33.300 --> 48:35.300]  Что мы делаем на каждой итерации?
[48:35.300 --> 48:40.300]  Давайте же просто просуммируем общее количество работы
[48:40.300 --> 48:42.300]  в этом внешнем цикле.
[48:42.300 --> 48:49.300]  что мы делаем во внешнем цикле? Во-первых, в худшем случае мы действительно пройдем по всем вершинам, поэтому суммируем по всем вершинам, окей?
[48:49.300 --> 48:59.300]  Мы делаем какую-то работу за единицу, например, достаем из очереди вершину. Эта работа занимает единицу условно. Понятно?
[48:59.300 --> 49:09.300]  И плюс, сколько суммарно занимает этот цикл по времени? Сложность этого цикла какая?
[49:12.300 --> 49:23.300]  Согласны, что это просто дег v? Ну дег плюс v, давайте напишу. Полустепень исхода. Согласны?
[49:23.300 --> 49:31.300]  Сложность этого цикла это просто степень вершины v. На самом деле не совсем так.
[49:31.300 --> 49:38.300]  Вот тут важно сделать следующее замечание. Вот тут становится важно то, как мы представляем граф памяти.
[49:38.300 --> 49:45.300]  У нас тут есть операция получения соседей вершины v. А мы как раз об этом на первой части лекции говорили.
[49:45.300 --> 49:57.300]  В зависимости от представления графа, до сколько времени мы получаем всех соседей вершины, время этой операции сильно зависит от того, как мы представляем граф памяти.
[49:57.300 --> 50:06.300]  Давайте предположим, что мы работаем с помощью списков смежности.
[50:06.300 --> 50:15.300]  Вот если мы делаем с помощью списков смежности, то действительно этот цикл работает за дег v.
[50:15.300 --> 50:26.300]  И что в итоге получается? Что будет, если я просуммирую вот такую сумму?
[50:26.300 --> 50:31.300]  Согласны, что сумма единиц это v. Доказывать не будем. Хорошо. Дальше.
[50:31.300 --> 50:38.300]  А сумма степеней? Да, у нас было утверждение, что либо e, либо 2e, если вас грахнете.
[50:38.300 --> 50:45.300]  Ну так или иначе, это просто обольшее от v и e. Понятно?
[50:45.300 --> 50:51.300]  Все, соответственно, алгоритм работает за v и e. Это значит случай списков смежности.
[50:51.300 --> 50:58.300]  Теперь давайте просто обсудим, а что будет, если я, скажем, вместо списка смежности буду использовать матрицу смежности?
[50:58.300 --> 51:06.300]  Изменится ли асимптотика или нет? Как изменится?
[51:06.300 --> 51:11.300]  Да, если мы будем использовать матрицу смежности, то тут нас будет стоять не дег v, а v. Почему?
[51:11.300 --> 51:17.300]  Потому что соседи вершины в матрице смежности мы получаем за линейное время.
[51:17.300 --> 51:24.300]  Поэтому перед тем, как мы начнем цикл, мы за линейное время сначала найдем всех соседей, а потом, соответственно, будет работать цикл.
[51:24.300 --> 51:29.300]  Поэтому тут будет стоять θ от v2.
[51:29.300 --> 51:38.300]  Вот, соответственно, я привел пример, когда списки смежности гораздо эффективнее, чем матрица смежности.
[51:38.300 --> 51:43.300]  Все понятно? Отлично.
[51:43.300 --> 51:50.300]  Так, ну и давайте поговорим про корректность.
[51:50.300 --> 52:00.300]  Смотрите, вроде как все понятно. Да, алгоритм я псевдокод написал, как работает на картинке показал, даже сложности оценили.
[52:00.300 --> 52:10.300]  Но все-таки хочется как-то формально показать, что этот алгоритм работает всегда, а не только на каких-то конкретных картинках, которые я привожу.
[52:10.300 --> 52:19.300]  Давайте, собственно, оставшуюся часть посвятим тому, что докажем корректность.
[52:19.300 --> 52:26.300]  Ну вот, там понадобится две леммы, первая из них утверждает следующее. Вершина в очереди расположена по неубыванию дист, и расстояния отличаются максимум на единицы.
[52:26.300 --> 52:37.300]  То есть это про что? Это про то, что у нас был массив расстояний дист и была очередь.
[52:37.300 --> 52:45.300]  Так вот утверждается, что если я в какой-то момент времени я бы не взял эту очередь, вот у меня есть какая-то очередь.
[52:45.300 --> 52:52.300]  У меня ситуация всегда устроена следующим образом. Вначале идут, вот отсюда я извлекаю вершину, сюда я кладу вершины.
[52:52.300 --> 52:58.300]  Вначале у меня идут вершины с расстоянием d, а дальше у меня идут вершины с расстоянием d плюс один.
[52:58.300 --> 53:10.300]  Причем этих вершин, ну, давайте скажем больше на единицы, этих вершин больше равно нулю. Число вершин.
[53:10.300 --> 53:18.300]  Доказательства тут просто по индукции. Изначально у нас в очереди всего лишь одна вершина, для одной вершины, естественно, это верма.
[53:18.300 --> 53:23.300]  Теперь давайте докажем переход. Допустим, у нас в какой-то момент времени возникла вот такая вот ситуация.
[53:23.300 --> 53:30.300]  Ну, что мы делаем? Мы извлекаем вершину с расстоянием d, а что делаем потом?
[53:30.300 --> 53:38.300]  А потом добавляем в очередь какое-то количество вершин с расстоянием d плюс один. Согласны?
[53:38.300 --> 53:42.300]  Ну, все, то есть к началу следующей итерации у нас сохраняется вот такой вариант.
[53:42.300 --> 53:46.300]  Ну, точнее не такой вариант, то есть тут больше равно нулю, тут тоже больше равно нуля.
[53:46.300 --> 53:51.300]  В общем, так или иначе, тут все вершины расположены в порядке возрастания, то есть в порядке неубывания,
[53:51.300 --> 53:57.300]  и плюс расстояние минимальной вершины и максимальной вершины различается не больше чем на единицу. Понятно?
[53:57.300 --> 53:59.300]  Ну, все довольно просто.
[53:59.300 --> 54:09.300]  Вопросов нет, да? Хорошо.
[54:09.300 --> 54:13.300]  Дальше, вторая лемма. Значит, вторая лемма заключается в том,
[54:13.300 --> 54:19.300]  что если вдруг алгоритм нас обманывает, то есть вдруг алгоритм нашел неправильное расстояние,
[54:19.300 --> 54:24.300]  то брать он может только в большую сторону, то есть в меньшую сторону он обмануть нас не может.
[54:24.300 --> 54:28.300]  То есть если на самом деле кратчаешь расстояние от начальной вершины до какой-то вершины равно 5,
[54:28.300 --> 54:31.300]  то наш алгоритм не может сказать, что на самом деле расстояние равно 3.
[54:31.300 --> 54:34.300]  То есть если алгоритм и врет, то только в большую сторону.
[54:34.300 --> 54:36.300]  Ну, собственно, вот тут используется стандартное обозначение,
[54:36.300 --> 54:43.300]  ρ от s и v, это истинное кратчайшее расстояние от вершины s до вершины v. Понятно, да?
[54:43.300 --> 54:51.300]  Ну, давайте докажем. То есть доказывается на самом деле тоже по индукции.
[54:51.300 --> 54:59.300]  Ну, то есть база такая. Расстояние до начальной вершины равно 0,
[54:59.300 --> 55:06.300]  и оно в точности совпадает, давайте так напишем, больше либо равно, чем расстояние от s до s, которое равно 0.
[55:06.300 --> 55:10.300]  База выполняется, согласны? Очевидно.
[55:10.300 --> 55:12.300]  Теперь переход.
[55:12.300 --> 55:26.300]  Пусть достали вершину v. Что мы про нее знаем?
[55:26.300 --> 55:34.300]  По предположению индукции, у нее d от v больше либо равно, чем r с v.
[55:34.300 --> 55:44.300]  Значит, сосед v – это вершина u.
[55:44.300 --> 55:50.300]  Значит, d от u у нас равно d от v плюс 1.
[55:50.300 --> 55:52.300]  Ну, у нас так алгоритм устроен, да?
[55:52.300 --> 55:57.300]  Когда находим новую вершину, мы говорим, что у нее расстояние равно расстоянию из ее родителя в един... ну, плюс 1.
[55:57.300 --> 55:59.300]  Согласны? Ну, что делаем?
[55:59.300 --> 56:04.300]  Это больше либо равно, чем r с v.
[56:04.300 --> 56:07.300]  r с v плюс 1.
[56:07.300 --> 56:11.300]  И это явно больше либо равно, чем r с u.
[56:11.300 --> 56:13.300]  Так, вот последний переход может быть неочевиден.
[56:13.300 --> 56:17.300]  Понятно, почему последний переход верен.
[56:17.300 --> 56:19.300]  Смотрите, что такое r с u?
[56:19.300 --> 56:24.300]  r с u – это истинное кратчайшее расстояние от s до u.
[56:24.300 --> 56:28.300]  Давайте тут.
[56:28.300 --> 56:34.300]  Зря.
[56:34.300 --> 56:38.300]  Вот у меня есть вершина s, есть вершина u.
[56:38.300 --> 56:41.300]  И вот здесь какое-то истинное кратчайшее расстояние от s до u.
[56:41.300 --> 56:43.300]  А что такое r с v плюс 1?
[56:43.300 --> 56:51.300]  А r с v – это просто кратчайший путь от s до v и плюс 1 ребро v у.
[56:51.300 --> 56:57.300]  Ну, согласны, что какой-то произвольный путь точно никак не короче, чем самый короткий путь.
[56:57.300 --> 56:59.300]  Согласны?
[56:59.300 --> 57:03.300]  Ну, вот r с v плюс 1 – это длина какого-то пути, который мы нашли.
[57:03.300 --> 57:06.300]  Он не обязательно кратчайший.
[57:06.300 --> 57:08.300]  А есть истинный кратчайший путь r с u?
[57:08.300 --> 57:12.300]  Ну, соответственно, какой-то путь не короче, чем самый короткий путь. Согласны?
[57:12.300 --> 57:17.300]  Вот доказали, что d от u больше ребра v, чем r с v.
[57:17.300 --> 57:27.300]  То есть переход доказан.
[57:27.300 --> 57:31.300]  Окей? Нормально?
[57:31.300 --> 57:35.300]  Хорошо.
[57:35.300 --> 57:40.300]  Ну, и, наконец, последняя теорема.
[57:40.300 --> 57:42.300]  Ну, собственно, корректность BFS.
[57:42.300 --> 57:45.300]  Давайте теперь докажем, что мы на самом деле вообще не врём,
[57:45.300 --> 57:48.300]  что у нас на самом деле всё хорошо, все расстояния...
[57:48.300 --> 57:51.300]  То есть после того, как мы у нас отработал BFS, у нас все расстояния найдены корректно.
[57:51.300 --> 58:04.300]  То есть на самом деле в предыдущей леме тут стоит знак небожки-бравно, а стоит точность равенства.
[58:04.300 --> 58:06.300]  Как будем доказывать?
[58:06.300 --> 58:10.300]  Давайте возьмём следующую штуку.
[58:10.300 --> 58:23.300]  Пусть существует v такая, что d от v строго больше, чем r с v.
[58:23.300 --> 58:29.300]  То есть предположим, что в какой-то момент у нас нестрогое неравенство превращается в строгое неравенство.
[58:29.300 --> 58:32.300]  То есть наш алгоритм действительно врёт.
[58:32.300 --> 58:37.300]  Значит, рассмотрим v со звездой вот такую штуку.
[58:37.300 --> 58:58.300]  Аргмин у всем r с v среди вот такого множества, что d от v больше, чем r с v.
[58:58.300 --> 59:01.300]  Рассмотрим все вершины, на которых мы брём.
[59:01.300 --> 59:07.300]  И среди всех таких вершин я возьму вершину, расстояние до которой, истинное расстояние до которой, минимальное.
[59:07.300 --> 59:09.300]  Понятно?
[59:09.300 --> 59:12.300]  У меня есть какое-то множество вершин, на них я соврал.
[59:12.300 --> 59:18.300]  И среди всех этих вершин я ищу самую ближайшую к S-вершину.
[59:18.300 --> 59:21.300]  Вот, ну давайте, давайте просуждаем.
[59:21.300 --> 59:23.300]  Соответственно, что я знаю?
[59:23.300 --> 59:26.300]  Да, пусть, да, ещё давайте так скажем.
[59:26.300 --> 59:38.300]  Пусть, пусть u это parent от v со звездой.
[59:38.300 --> 59:40.300]  У со звездой.
[59:40.300 --> 59:57.300]  А p это истинный предок на кратчайшем пути из S до v со звездой.
[59:57.300 --> 01:00:01.300]  Ну то есть на реальном кратчайшем пути, то есть я рассматриваю реальный кратчайший путь от S до v со звездой.
[01:00:01.300 --> 01:00:05.300]  И вот там предыдущая, ну предыдущая перед v со звездой вершина, это p.
[01:00:05.300 --> 01:00:09.300]  А та предыдущая вершина, которую я нашёл, это вершина u.
[01:00:09.300 --> 01:00:12.300]  Значит, можно писать следующие соотношения.
[01:00:12.300 --> 01:00:19.300]  Во-первых, нам достоверно известно, что d от v больше, чем ρсв.
[01:00:19.300 --> 01:00:21.300]  Это первый момент.
[01:00:21.300 --> 01:00:33.300]  А второй момент нам известно следующее, что ρсв в точности равен ρсp плюс 1.
[01:00:33.300 --> 01:00:38.300]  Так как p это истинный предок v со звездой.
[01:00:38.300 --> 01:00:43.300]  Так как p это истинный предок на кратчайшем пути v со звездой.
[01:00:43.300 --> 01:00:52.300]  А ещё мы знаем, что d от v со звездой на самом деле это d от u плюс 1.
[01:00:52.300 --> 01:00:54.300]  D от u со звездой.
[01:00:54.300 --> 01:00:58.300]  Каждое неравенство и равенство понятно.
[01:00:58.300 --> 01:01:02.300]  Ну смотрите, вот из этого на самом деле следует следующая вещь.
[01:01:02.300 --> 01:01:07.300]  Давайте я просто вот эти равенства ρ от s со звездой поставлю вот сюда, а d от v со звездой поставлю вот сюда.
[01:01:07.300 --> 01:01:19.300]  В итоге я получу, что d от u со звездой у меня больше, чем ρсv.
[01:01:25.300 --> 01:01:29.300]  А ρсv у меня точно совпадает с d от p.
[01:01:29.300 --> 01:01:31.300]  Вот это почему.
[01:01:33.300 --> 01:01:40.300]  Потому что d от v со звездой это вершина до расстояния, на которой я вру, и расстояние до которой минимально.
[01:01:40.300 --> 01:01:47.300]  Ну а понятное дело, что ρсv меньше, чем ρсv со звездой, поэтому до вершины p я нашёл расстояние верно.
[01:01:47.300 --> 01:01:52.300]  А раз я нашёл на неё расстояние верно, соответственно вот тут достигается вот это равенство.
[01:01:52.300 --> 01:01:59.300]  Ну теперь на самом деле я могу утверждать, что я закончил доказательство, почему я пришёл к противоречию.
[01:01:59.300 --> 01:02:08.300]  Смотрите, расстояние до вершины u со звездой, ну точнее d, вот эта d, которую я подсчитываю во время алгоритма, она строго больше, чем расстояние до dp.
[01:02:08.300 --> 01:02:10.300]  Что это означает, до вершины p?
[01:02:10.300 --> 01:02:15.300]  Это означает, что вершину p из очереди я достал раньше, чем вершину u.
[01:02:15.300 --> 01:02:20.300]  Ну тут уже можно сюда перейти. Всё, без спойлеров.
[01:02:20.300 --> 01:02:25.300]  То есть вершину p мы достали из очереди раньше, чем вершину u.
[01:02:25.300 --> 01:02:26.300]  Согласны?
[01:02:26.300 --> 01:02:29.300]  Ну так у неё dp меньше, чем du.
[01:02:29.300 --> 01:02:31.300]  Согласны?
[01:02:31.300 --> 01:02:39.300]  Ну а всё, а так как вершину p мы достали раньше, и плюс из p есть ребро в вершину v, то соответственно и вершину v мы должны были рассматривать раньше, чем вершину u.
[01:02:39.300 --> 01:02:40.300]  Согласны?
[01:02:40.300 --> 01:02:42.300]  Ну тут мы пришли к противоречию. Почему?
[01:02:42.300 --> 01:02:47.300]  Потому что мы подсказали, что u это родители v, ну а u никак не могла быть родителем v.
[01:02:47.300 --> 01:02:51.300]  Потому что v мы достали раньше, чем вершину u.
[01:02:51.300 --> 01:02:53.300]  Согласны?
[01:02:55.300 --> 01:02:57.300]  Вот всё.
[01:03:01.300 --> 01:03:03.300]  Вот такое доказательство.
[01:03:08.300 --> 01:03:09.300]  Есть вопросы?
[01:03:09.300 --> 01:03:11.300]  Какой переход был непонятен?
[01:03:19.300 --> 01:03:21.300]  Так, сейчас я...
[01:03:22.300 --> 01:03:25.300]  Я, возможно, неправильно выразился.
[01:03:25.300 --> 01:03:28.300]  Мы вершину p рассматривали раньше, чем вершину u.
[01:03:28.300 --> 01:03:29.300]  Да?
[01:03:29.300 --> 01:03:32.300]  Раз мы вершину p рассматривали раньше, чем вершину u, то это значит, что мы...
[01:03:33.300 --> 01:03:35.300]  Вот у нас была такая ситуация.
[01:03:35.300 --> 01:03:39.300]  Из вершины u есть ребро в вершину v, и из вершины p есть ребро у вершины v.
[01:03:39.300 --> 01:03:46.300]  Так как мы вершину p рассматривали раньше, чем вершину u, То вершину v мы видели раньше, чем вершину v.
[01:03:46.300 --> 01:03:48.300]  То есть вершину v мы видели ранее.
[01:03:48.300 --> 01:03:53.300]  из вершины p и вершины v увидели раньше, чем из вершины u. Согласны?
[01:03:53.300 --> 01:04:00.300]  Поэтому v, поэтому u никак не могла стать родителем v. То есть v мы обработали гораздо раньше, чем мы обработали вершину u.
[01:04:00.300 --> 01:04:03.300]  Не обработали, в смысле встретили.
[01:04:10.300 --> 01:04:15.300]  Почему вот это? Смотрите. Согласны ли вы, что...
[01:04:16.300 --> 01:04:25.300]  Давайте тут напишу, что rho sv строго больше, чем rho sp.
[01:04:25.300 --> 01:04:28.300]  Но это следует вот отсюда.
[01:04:28.300 --> 01:04:35.300]  Теперь смотрите. Так как rho sv строго больше, чем rho sp, то до rho sp мой алгоритм нашел расстояние точно правильно. Почему?
[01:04:35.300 --> 01:04:39.300]  Потому что v это такая вершина, до которой rho sv минимально.
[01:04:39.300 --> 01:04:42.300]  Для которой я нашел расстояние правильно.
[01:04:42.300 --> 01:04:47.300]  Среди всех вершин, до которых я расстояние нашел неправильно, у v минимальное истинное расстояние.
[01:04:47.300 --> 01:04:52.300]  Но это значит, что для любой вершины, до которой расстояние меньше, я нашел расстояние корректно.
[01:04:52.300 --> 01:04:54.300]  Теперь понятно?
[01:04:58.300 --> 01:05:00.300]  Ну окей.
[01:05:03.300 --> 01:05:05.300]  Так.
[01:05:06.300 --> 01:05:08.300]  Еще есть вопросы?
[01:05:12.300 --> 01:05:20.300]  Ну, в общем-то, рассмотрели алгоритм, алгоритм обхода в ширину, и даже доказали его корректно.
[01:05:20.300 --> 01:05:22.300]  Мне кажется, круто.
[01:05:22.300 --> 01:05:26.300]  Так, теперь за оставшееся время...
[01:05:26.300 --> 01:05:30.300]  Никогда не удается, на самом деле, слайд до конца зачитать, но ничего там.
[01:05:30.300 --> 01:05:32.300]  Сейчас на семинарах, значит, останется.
[01:05:32.300 --> 01:05:34.300]  Обход в глубину для взвешенных графов.
[01:05:34.300 --> 01:05:40.300]  Смотрите, сейчас мы искали кратчащее расстояние для графов, для так называемых невзвешенных графов.
[01:05:40.300 --> 01:05:44.300]  То есть для таких графов, для которых у нас каждая ребра, по сути, равнозначна.
[01:05:44.300 --> 01:05:47.300]  То есть длина каждого ребра, по сути, равна единице.
[01:05:47.300 --> 01:05:50.300]  Но у нас, согласитесь, бывают ситуации, при которых у нас ребра не разназначены.
[01:05:50.300 --> 01:05:54.300]  Например, по одному ребру пройтись дороже, чем по другому, и так далее.
[01:05:54.300 --> 01:05:57.300]  Так вот, в некоторых таких ситуациях BFS тоже может сработать.
[01:05:57.300 --> 01:06:00.300]  Ну вот, часть из них давайте разберем.
[01:06:00.300 --> 01:06:04.300]  Ну, самый простой вариант, который возможен, это 01-граф.
[01:06:04.300 --> 01:06:05.300]  Что такое 01-граф?
[01:06:05.300 --> 01:06:09.300]  01-граф – это такой граф, у которого ребра бывают двух видов.
[01:06:09.300 --> 01:06:13.300]  Первое – это ребро с весом 1, второе – это ребро с весом 0.
[01:06:13.300 --> 01:06:17.300]  То есть по каким-то ребрам нам нужно заплатить, чтобы пройти.
[01:06:17.300 --> 01:06:20.300]  А по каким-то ребрам мы проходим абсолютно бесплатно.
[01:06:20.300 --> 01:06:22.300]  То есть какие-то ребра в кратчащем пути вообще не участвуют.
[01:06:22.300 --> 01:06:25.300]  Ну, в том смысле, что по ним мы проходим бесплатно, абсолютно.
[01:06:25.300 --> 01:06:28.300]  Вопрос, понимаете ли вы, что нужно делать в таких ситуациях?
[01:06:28.300 --> 01:06:31.300]  Как обрабатывать такие графы?
[01:06:33.300 --> 01:06:35.300]  А каким образом?
[01:06:39.300 --> 01:06:47.300]  Ну вот, к сожалению, объединить не получится,
[01:06:47.300 --> 01:06:55.300]  потому что у вас просто-напросто разные наборы ребер торчат из одной вершины и из другой вершины.
[01:07:09.300 --> 01:07:14.300]  Ну, то есть нет, на самом деле я понимаю идею.
[01:07:14.300 --> 01:07:21.300]  Идея стоит в том, что если у вас есть вершины С, вершины У, есть какое-то ребро,
[01:07:21.300 --> 01:07:24.300]  то это означает, ну, и при этом это ребро имеет вес 0,
[01:07:24.300 --> 01:07:30.300]  то по сути вот эти ребра можно отдать в вершине С, да, и по сути будет то же самое.
[01:07:30.300 --> 01:07:33.300]  Вот, я с этим согласен, но мне кажется, что это слишком долго.
[01:07:33.300 --> 01:07:37.300]  Вам как минимум нужно найти, дойти до вершины С, потом пройти по всем,
[01:07:37.300 --> 01:07:43.300]  то есть по всем вершинам, до которых вы можете дотянуться с помощью нулевых ребер,
[01:07:43.300 --> 01:07:46.300]  и все эти ребра засунуть в вершину С.
[01:07:46.300 --> 01:07:49.300]  Ну и так далее сделать, на самом деле, для всех вершин.
[01:07:49.300 --> 01:07:53.300]  То есть кажется, что это, ну, как минимум по Константе не очень эффективно.
[01:07:53.300 --> 01:07:57.300]  Значит, на самом деле предлагается очень простой вариант.
[01:07:57.300 --> 01:08:00.300]  Смотрите, у нас же есть очередь.
[01:08:07.300 --> 01:08:09.300]  Давайте поступать следующим образом.
[01:08:11.300 --> 01:08:15.300]  Х, у. Если до какой-то вершины у меня расстояние 0,
[01:08:15.300 --> 01:08:18.300]  то давайте я эту вершину буду класть в начало очереди.
[01:08:22.300 --> 01:08:25.300]  А если у меня до какой-то вершины расстояние 1, то я буду класть ее в конец очереди.
[01:08:25.300 --> 01:08:28.300]  То есть таким образом у меня утверждение леммы 1 сохранится.
[01:08:28.300 --> 01:08:31.300]  Согласны? То есть у меня по-прежнему будет очередь,
[01:08:31.300 --> 01:08:35.300]  у которой все расстояния будут расположены по неубыванию,
[01:08:35.300 --> 01:08:38.300]  да, все расстояния будут расположены по неубыванию.
[01:08:38.300 --> 01:08:41.300]  И различаться будут максимум на единицу.
[01:08:41.300 --> 01:08:44.300]  Ну и соответственно все остальные рассуждения, естественно, тоже будут сохранены.
[01:08:44.300 --> 01:08:48.300]  То есть история очень простая. Давайте использовать не очередь, а двунаправленную очередь, то есть дек.
[01:08:48.300 --> 01:08:51.300]  Да, и класть вершины как в начало, так и в конец.
[01:08:51.300 --> 01:08:54.300]  То есть если ребро 0, то в начало, если ребро 1, то в конец.
[01:08:56.300 --> 01:09:00.300]  А вы в начало можете класть вектор? Нет.
[01:09:00.300 --> 01:09:03.300]  Даже если бы был, он работал бы за линейное время.
[01:09:03.300 --> 01:09:06.300]  Это не то, что вам нужно явно.
[01:09:06.300 --> 01:09:09.300]  Так, ну и последнее. Давайте, значит,
[01:09:09.300 --> 01:09:12.300]  эффективный способ поставим на семинар.
[01:09:12.300 --> 01:09:15.300]  А сейчас разберем более, значит, простой вариант.
[01:09:15.300 --> 01:09:18.300]  Значит, 0 к граф. Что такое 0 к граф? Вот у вас есть вершины.
[01:09:18.300 --> 01:09:24.300]  Из вершины торчат ребра там 0, 1, 2, 3, ну и так далее.
[01:09:24.300 --> 01:09:27.300]  Максимум к.
[01:09:27.300 --> 01:09:30.300]  То есть у вас ребра имеют некоторый неотрицательный вес.
[01:09:30.300 --> 01:09:33.300]  Но причем не больше, чем к.
[01:09:34.300 --> 01:09:37.300]  Что будем делать?
[01:09:52.300 --> 01:09:55.300]  Это хорошая идея, и она практически приводит
[01:09:55.300 --> 01:09:58.300]  к наиболее эффективному алгоритму, но там есть некоторые тонкости.
[01:09:58.300 --> 01:10:01.300]  Самый тупой способ. Что тут можно сделать?
[01:10:01.300 --> 01:10:04.300]  Как можно вот эту задачу свести к предыдущей?
[01:10:05.300 --> 01:10:08.300]  Нет. Предыдущей в смысле, то, что мы минут назад
[01:10:08.300 --> 01:10:11.300]  обсуждали, а не лекции назад.
[01:10:12.300 --> 01:10:15.300]  Вот у меня есть вершины х и у, между ними ребро размера 3.
[01:10:15.300 --> 01:10:18.300]  Что я могу сделать?
[01:10:18.300 --> 01:10:22.300]  Да, давайте я просто возьму это ребро и разобью на
[01:10:22.300 --> 01:10:25.300]  три фиксивных ребра.
[01:10:25.300 --> 01:10:29.300]  Х штрих, х два штриха, у. Тут один, один, один.
[01:10:29.300 --> 01:10:32.300]  Все-таки можно свести с виду датчик предыдущий,
[01:10:32.300 --> 01:10:36.300]  в который у нас все ребра имеют длину либо 0, либо 1.
[01:10:40.300 --> 01:10:43.300]  Ну и такой алгоритм будет работать за kg плюс v.
[01:10:43.300 --> 01:10:46.300]  Ну почему kg плюс v? Потому что в худшем случае я каждое
[01:10:46.300 --> 01:10:49.300]  ребро разобью на k-1 дополнительное ребро.
[01:10:49.300 --> 01:10:52.300]  Точнее так. У меня максимум появится k-1
[01:10:52.300 --> 01:10:55.300]  умножить на e дополнительных вершин.
[01:10:55.300 --> 01:10:58.300]  Вот у меня появляются дополнительные вершины.
[01:10:58.300 --> 01:11:01.300]  И плюс у меня появляются дополнительные ребра в размере
[01:11:01.300 --> 01:11:04.300]  количества k-e штук.
[01:11:04.300 --> 01:11:07.300]  Соответственно, если я сложу новое количество вершин
[01:11:07.300 --> 01:11:10.300]  с новым количеством ребер, то я получу асимптотику k-e плюс v.
[01:11:10.300 --> 01:11:13.300]  Понятно, да?
[01:11:13.300 --> 01:11:16.300]  Что на самом деле может работать, но
[01:11:16.300 --> 01:11:19.300]  коэффициент перед e-шкой не очень приятен.
[01:11:19.300 --> 01:11:22.300]  Это может быть большим, но как бы и по памяти грустно,
[01:11:22.300 --> 01:11:25.300]  и по времени грустно.
[01:11:25.300 --> 01:11:28.300]  Есть второй способ, который вы, видимо, обсудите на семинаре,
[01:11:28.300 --> 01:11:31.300]  который работает за kv плюс e.
[01:11:31.300 --> 01:11:34.300]  Его обсудите, да, как я сказал, на семинаре.
[01:11:38.300 --> 01:11:41.300]  Ну а пока с алгоритмами все, дальше с плюс плюсом.
