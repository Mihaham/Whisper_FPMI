[00:00.000 --> 00:08.400]  Продолжаем сегодня говорить про кратчайшие пути.
[00:08.400 --> 00:10.040]  Начнем с алгоритма звездочка.
[00:10.040 --> 00:21.640]  Это алгоритм, который решает задачу такую же, как Дейкстра,
[00:21.640 --> 00:24.800]  а именно находит кратчайший путь от одной вершины до
[00:24.800 --> 00:25.800]  другой.
[00:25.800 --> 00:29.120]  Более точно, Дейкстра у нас могла находить от одной
[00:29.120 --> 00:32.320]  вершины до всех, а мы будем решать задачу именно, что
[00:32.320 --> 00:44.200]  от S до T находит расстояние от S до T, т.е. фиксированы
[00:44.200 --> 00:46.320]  стартовая конечная вершина, нам нужно найти минимальное
[00:46.320 --> 00:47.320]  расстояние.
[00:47.320 --> 00:52.720]  И здесь будет работать следующая идея.
[00:52.720 --> 00:55.480]  Смотрите, раньше в алгоритме Дейкстра мы действовали
[00:55.480 --> 00:56.480]  примерно так.
[00:56.480 --> 01:00.520]  У нас была S, мы для каждой вершины находили расстояние
[01:00.520 --> 01:05.760]  до нее, в каком-то массиве DIST, для каждой вершинки
[01:05.760 --> 01:09.480]  мы сохраняли текущее найденное до нее расстояние, минимальную
[01:09.480 --> 01:11.280]  длину пути, которую мы уже нашли.
[01:11.280 --> 01:14.320]  Там их постепенно обновляли, раскрывали вершину с минимальным
[01:14.320 --> 01:17.360]  DIST, которая еще не обработана, рассматривали все рёбра
[01:17.360 --> 01:20.480]  с нее, обновляли DIST вот здесь, и потом брали опять вершину
[01:20.480 --> 01:23.240]  с минимальным DIST, те, которые еще не обработаны.
[01:23.240 --> 01:33.280]  Логично в каком-то смысле DIST еще вклеить оценку остаточной
[01:33.280 --> 01:34.280]  длины пути.
[01:34.280 --> 01:36.840]  Сейчас мы рассматриваем только путь от S до текущей
[01:36.840 --> 01:38.560]  вершинки, до вершинки V.
[01:38.560 --> 01:42.360]  А давайте еще каким-то образом научимся учитывать оставшую
[01:42.360 --> 01:44.120]  длину пути от V до T.
[01:44.120 --> 01:45.800]  Вот как это будет реализовано.
[01:45.800 --> 01:52.640]  Для каждой вершины V у нас будет две функции.
[01:52.640 --> 01:58.880]  Функция G это вот та самая оценка на минимальное расстояние.
[01:58.880 --> 02:14.440]  Ну, давайте так напишу, текущая найденная оценка
[02:14.440 --> 02:18.760]  на DIST SV.
[02:18.760 --> 02:22.440]  Так же как в DX, что у нас не сразу появляется правильное
[02:22.440 --> 02:26.160]  расстояние как же от V, а вот когда мы до нее дойдем,
[02:26.160 --> 02:28.200]  когда мы из кучи извлечем, тогда это будет правильное
[02:28.200 --> 02:29.200]  расстояние.
[02:29.200 --> 02:31.040]  То есть, возможно, вот эта величина, мы ее изначально
[02:31.040 --> 02:33.680]  чему-то положили равной, затем она как-то убывает-убывает,
[02:33.680 --> 02:35.160]  и когда мы ее достаем из кучи, это уже правильный
[02:35.160 --> 02:36.160]  ответ.
[02:36.160 --> 02:39.480]  Ну, например, если у меня есть вот эта S, вот эта V,
[02:39.480 --> 02:44.000]  я нашел там путь длины 10, положил сюда G равно 10, ну
[02:44.000 --> 02:46.920]  или в этом вот понимании, да, 10 от V равно 10.
[02:46.920 --> 02:50.120]  Потом нашел путь покороче, суммарной длины 9, обновил
[02:50.120 --> 02:51.120]  ее, ну и так далее.
[02:51.120 --> 02:52.760]  Много-много раз обновляю этот путь.
[02:52.760 --> 02:57.320]  И когда вот эта вершинка V извлечется из очереди
[02:57.320 --> 02:59.360]  в алгоритме Dijkstra, мы будем считать, что то значение
[02:59.360 --> 03:01.720]  Dist, которое там лежит, это и есть правильное значение.
[03:01.720 --> 03:03.520]  Мы доказывали в прошлый раз, что это будет правильный
[03:03.520 --> 03:04.520]  ответ.
[03:04.520 --> 03:06.200]  Вот так вот, вот эта G от V, она как-то убывает, да,
[03:06.200 --> 03:08.480]  но вот пусть G это текущее найденное расстояние.
[03:08.480 --> 03:12.920]  Вот, и будет вторая функция H от V.
[03:12.920 --> 03:19.160]  Это оценка на, наоборот, остаточную часть пути от
[03:19.160 --> 03:25.000]  V до T, Dist Vt.
[03:25.000 --> 03:28.560]  Понятно, что эту оценку мы не можем взять никак
[03:28.560 --> 03:31.400]  исходя как бы из, из графа, да, потому что чтобы это
[03:31.400 --> 03:34.120]  посчитать, нам нужно как бы ну там от V до T рассматривать
[03:34.120 --> 03:37.040]  как будто бы вот этот вот, ну не знаю, остаток пути
[03:37.040 --> 03:38.600]  как будто обратно до Dijkstra пускать.
[03:38.600 --> 03:40.080]  Мы такого делать не будем.
[03:40.080 --> 03:45.520]  У нас эта H будет браться, ну вот именно что какая-то
[03:45.520 --> 03:46.520]  оценка.
[03:46.520 --> 03:49.160]  Например, если мы знаем, что этот граф лежит на плоскости,
[03:49.160 --> 03:53.000]  то минимальное расстояние от V до T оно явно не меньше
[03:53.000 --> 03:54.760]  чем ефкрида расстояния между этими точками.
[03:54.760 --> 03:57.080]  Да, то есть если мы считаем, что наш граф планарный,
[03:57.080 --> 03:59.400]  в смысле плоский, да, расположен на плоскости, и там есть
[03:59.400 --> 04:01.640]  какие-то ребра по которым можем ходить, то понятное
[04:01.640 --> 04:04.800]  дело, что минимальная длина пути от V до T она не меньше
[04:04.800 --> 04:06.440]  чем ну просто длина этого отрезка.
[04:06.440 --> 04:09.040]  Поэтому в качестве H от V мы, например, будем брать просто
[04:09.040 --> 04:10.640]  ефкрида расстояния между ними.
[04:10.640 --> 04:13.080]  Если, повторюсь, граф у нас уложен на плоскости.
[04:13.080 --> 04:15.120]  То есть это то же самое, если у нас граф там какой-то
[04:15.120 --> 04:17.760]  специфический, тогда в качестве H от V можем брать нам какие-то
[04:17.760 --> 04:18.760]  другие функции.
[04:18.760 --> 04:19.760]  Вот чуть позже рассмотрим пример.
[04:20.760 --> 04:23.800]  Окей, то есть J это то, что находится в нашем алгоритме,
[04:23.800 --> 04:25.800]  а H это какая-то оценка, ну по сути это просто функция
[04:25.800 --> 04:29.200]  от V до T типа расстояния ефкрида между ними, без учета структуры
[04:29.200 --> 04:30.200]  графа.
[04:30.200 --> 04:40.080]  Вот, и тогда мы определяем f как функцию, J и H, и по сути
[04:40.080 --> 04:46.080]  алгоритм-озвездочка это просто dx на f, грубо говоря.
[04:50.080 --> 04:59.080]  А звездочка это алгоритм dx на значениях f.
[05:06.080 --> 05:09.080]  Ну давайте напишем код, как это выглядит.
[05:11.080 --> 05:17.080]  Мне также нужна очередь, ну в смысле куча, из которой
[05:17.080 --> 05:19.480]  я буду доставать значения, только теперь я буду доставать
[05:20.200 --> 05:22.200]  минимальное значение f, вот что значит dx по значениям
[05:22.200 --> 05:23.200]  f.
[05:23.200 --> 05:26.040]  Это значит, что минимум у меня берется из кучи не
[05:26.040 --> 05:28.560]  по значениям g, а по значениям f, то есть в вершинке будут
[05:28.560 --> 05:30.920]  сравниваться внутри кучи по порядке возрастания
[05:30.920 --> 05:33.720]  f, в корне будет минимальное значение f.
[05:33.720 --> 05:36.920]  Ну так вот, давайте мы будем считать, что у меня есть
[05:36.920 --> 05:45.920]  там вектор значений g, ну давайте пусть будет double,
[05:45.920 --> 05:47.920]  если мы говорим, что точки на плоскости лежат, то
[05:48.360 --> 05:51.360]  наверное расстояние у нас вещественное, а не целое.
[05:51.360 --> 05:56.360]  Значит вектор double g, h это какая-то функция, то есть
[05:56.360 --> 05:58.360]  мы не храним значение h, мы можем его вычислить,
[05:58.360 --> 06:00.360]  если нам нужна для какой-то вершинки v почитать расстояние
[06:00.360 --> 06:03.360]  от v до t, ну оценку на расстояние от v до t, тогда мы ее просто
[06:03.360 --> 06:06.360]  там по какой-нибудь формуле считаем, то есть явно мы
[06:06.360 --> 06:07.360]  ее не храним.
[06:07.800 --> 06:21.800]  Ну то же самое нужен вектор double f, нужна куча, давайте
[06:21.800 --> 06:31.800]  я напишу вот так, priority q, вот, есть в плюсах priority
[06:31.800 --> 06:35.800]  q, но там тяжеловато будет с декоризки, там тяжело
[06:36.240 --> 06:39.240]  показывать, какой элемент нужно уменьшить, ну в общем
[06:39.240 --> 06:42.240]  давайте здесь считаем, что тут написана наша куча,
[06:42.240 --> 06:44.240]  в которой мы можем делать все наши операции, там
[06:44.240 --> 06:47.240]  insert, extract, min, декоризки по указателю, то есть вот
[06:47.240 --> 06:49.240]  эта куча, которую мы реализовали.
[06:49.240 --> 06:52.240]  И здесь будут лежать номера вершин, которые упорядочены
[06:52.240 --> 07:01.240]  по f, да, значит куча номеров вершин, куча номеров вершин,
[07:01.240 --> 07:05.680]  упорядоченных по f, по f.
[07:05.680 --> 07:09.680]  Ну и дальше стандартная, стандартный кусок sd extra,
[07:09.680 --> 07:12.680]  что мы сначала вставляем в нашу очередь старту вершинку,
[07:12.680 --> 07:13.680]  так, пардон.
[07:17.680 --> 07:25.680]  Сначала говорим, что g от s это 0, f от s, ну это соответственно
[07:25.680 --> 07:30.680]  h от s, да, потому что g от s понятно 0, расстояние
[07:31.120 --> 07:34.120]  из этого 0, дальше f от s это сумма g плюс h, но если
[07:34.120 --> 07:37.120]  g это 0, то тогда остается просто h, h от s.
[07:37.120 --> 07:42.120]  Ну и в очередь как раз ее добавляем, q insert s.
[07:45.120 --> 07:50.120]  Дальше я напишу следующее wild true.
[07:52.120 --> 07:55.120]  Значит извлекаем из очереди вершину с минимальным f.
[07:55.560 --> 08:00.560]  Значит я напишу v равно q.extract min.
[08:05.560 --> 08:08.560]  Достали и удалили из очереди вершинку с минимальным значением
[08:08.560 --> 08:11.560]  f, которая там есть, и пытаемся ее раскрыть.
[08:11.560 --> 08:14.560]  Дальше наша процедура, что если есть v, мы пытаемся
[08:14.560 --> 08:17.560]  ее раскрыть, то есть обновляем значение g у вот этих вот,
[08:17.560 --> 08:19.560]  у концов этих ребер.
[08:19.560 --> 08:23.560]  Значит делаем цикл по исходящим ребрам, по всем
[08:24.000 --> 08:28.000]  ребрам лежащим, так, ну тут g уже занят, давайте я
[08:28.000 --> 08:34.000]  назову graph, graph от v, ну это так же как раньше, то
[08:34.000 --> 08:37.000]  что было g от v, это список ребер исходящих из v.
[08:38.000 --> 08:41.000]  Ну и нам нужно обновить значение функции g для
[08:41.000 --> 08:44.000]  вот этого, для конца вот этих ребер.
[08:48.000 --> 08:51.000]  Так, сейчас, секунду, подумаю как это написать.
[08:53.560 --> 09:14.000]  Это я посчитал, какая будет длина пути, что мы сначала
[09:14.000 --> 09:17.000]  доходим до v, потом добавляем это ребро, то есть добавляем
[09:17.000 --> 09:21.000]  e.cost, потом если значение g, которое лежало в конце
[09:21.000 --> 09:27.080]  вот эта вот e.tu, оно больше, чем x, тогда нужно его обновить и, соответственно,
[09:27.080 --> 09:34.200]  сделать изменения в очереди. Что g вот e.tu равно x,
[09:34.200 --> 09:41.640]  соответственно, вот здесь должны быть строчки типа там decrease key или insert.
[09:41.640 --> 09:45.480]  Если вершинка e.tu есть в очереди, то нам нужно просто
[09:45.480 --> 09:50.120]  сделать decrease key, потому что у нее было вот такое значение g и, соответственно,
[09:50.120 --> 09:56.520]  такое значение f. Если ее не было, то нам нужно ее туда вставить. Давайте я
[09:56.520 --> 10:06.960]  напишу, что f от e.tu это g от e.tu плюс h от e.tu. Не забываем, что нам
[10:06.960 --> 10:12.160]  нужно добавлять вот эту вот функцию h в конце. Ну и здесь, соответственно, я
[10:12.160 --> 10:21.280]  пишу, что если e.tu находится в очереди q, в смысле, в куче находится в q, то просто
[10:21.280 --> 10:29.920]  надо сделать decrease key. Иначе, если там нет, надо сделать insert.
[10:29.920 --> 10:44.880]  Так, ну вроде всего. Вот и вот здесь вот нужно еще вставить, что если мы из очереди
[10:44.880 --> 10:47.640]  извлекаем вершинку t, до которой мы, собственно, пытались найти расстояние,
[10:47.640 --> 10:51.680]  то мы сразу из этого цикла завершаемся и говорим, что мы нашли ответ. Вот здесь
[10:51.680 --> 11:03.360]  вот надо вставить, что если v это t, тогда break. Вот такой алгоритм. Пока, возможно,
[11:03.360 --> 11:07.880]  какая-то магия, но сейчас поясним, как это работает и когда это корректно работает.
[11:07.880 --> 11:15.120]  Идея очень простая. Вместо того, чтобы насчитывать только оценку от s до v, мы
[11:15.120 --> 11:18.080]  еще добавляем какую-то вот эту вспомогательную функцию h, которая называется
[11:18.080 --> 11:26.720]  эвристика. Эвристика, то есть оценка на расстояние от, где оно, вот она, h, это оценка
[11:26.720 --> 11:31.680]  на расстояние от этой вершинки до конца, до t. Ну и потом, собственно, просто dx по значениям
[11:31.680 --> 11:37.040]  вот этого f, что это значение g, как расстояние от s до этой вершинки, плюс оценка на
[11:37.040 --> 11:40.800]  расстояние от этой вершинки до конца. А дальше просто обычная dx до того момента,
[11:40.800 --> 11:46.520]  пока мы не дойдем, пока мы не извлечем из очереди, из кучи, в смысле, вершину
[11:46.520 --> 11:52.360]  равную t, когда вершина равна t будет иметь минимальное значение f. Вот такой алгоритм.
[11:52.360 --> 12:10.920]  Значит, почему это хоть сколько-то адекватно? Определение. Функция h,
[12:10.920 --> 12:31.920]  которую мы будем называть эвристикой, называется допустимой, если h от v не
[12:31.920 --> 12:38.120]  превосходит настоящего расстояния от v до t. Если для любого v h от v не больше,
[12:38.120 --> 12:47.720]  чем настоящая dist vt. То есть h допустима, если это оценка снизу на истинное расстояние.
[12:47.720 --> 12:54.120]  Оценка снизу. Ну, здесь я неявно предполагаю еще, что h положительно. Давайте я явно здесь
[12:54.120 --> 12:56.920]  пропишу. Но мы рассматриваем, в смысле не отрицательно, мы рассматриваем только
[12:56.920 --> 13:02.440]  не отрицательную эвристику, потому что, ну, логический смысл, что это как бы оценка длины
[13:02.440 --> 13:07.720]  пути от v до конца, и было бы странно, если бы длина vt была отрицательной. Мы пока живем в
[13:07.720 --> 13:11.200]  парадигме, что отрицательных ребер нет, соответственно, путь не может иметь отрицательную длину.
[13:11.200 --> 13:21.320]  Вот это допустимая эвристика. Дальше. Эвристика h называется монотонной. Эвристика h называется
[13:21.320 --> 13:30.840]  монотонной. Если для каждого ребра выполняется неравенство треугольника. Значит, если для
[13:30.840 --> 13:44.000]  любого ребра uv выполнена неравенство треугольника следующего вида, что h от u не больше, чем h от v,
[13:44.000 --> 13:54.440]  плюс e точка кост. Очень логичное предположение, если h это у нас оценка на расстояние от текущей
[13:54.680 --> 14:01.600]  до конца, то уж наверное оценка длины пути отсюда до конца h от u не превосходит оценки
[14:01.600 --> 14:07.200]  отсюда до конца h от v, плюс длина этого ребра. Понятно, что от u можно добраться до t, использовав это
[14:07.200 --> 14:14.280]  ребро, а потом дойдя от v до t. Это условие того, что наша h адекватна, что она по крайней мере
[14:14.280 --> 14:17.040]  учитывает все вот эти ребра и удовлетворяет неравенство треугольника.
[14:34.040 --> 14:41.800]  Очень простое замечание, что монотонный является допустимой. Замечание, монотонная
[14:41.800 --> 14:56.360]  евристика является допустимой. Доказывается очень просто, я не буду это формально прописывать,
[14:56.360 --> 15:06.440]  значит понятно, что надо еще потребовать, здесь нужно еще дополнительно требовать,
[15:06.440 --> 15:13.360]  потому что иначе это будет неверно. Извините, монотонный это когда выполняется треугольник для
[15:13.360 --> 15:20.840]  всех ребер, а также h это 0, вот так. Эти два условия нам нужны. h это вершина до которой
[15:20.840 --> 15:27.480]  аши дает расстояние, конечная вершина, что вот у меня есть s и t, мы хотим для каждой вершинки v
[15:27.480 --> 15:38.200]  оценить вот эту длину пути, длина пути из v в t. Не могу пока, у нас будет зависеть
[15:38.200 --> 15:43.880]  эта симплуатика от того какая у нас аш, поэтому пока что пока что не скажу, итак.
[15:43.880 --> 15:59.160]  Почему? Нет вроде все, ну смотрите логика какая, что если мы пытаемся оценить длину пути от u до t,
[15:59.160 --> 16:03.760]  то мы в частности можем пройти это ребро потом от v до t, но возможно как-то можно более оптимально.
[16:03.760 --> 16:12.940]  Итак, вернусь к факту, почему монотонная допустимая. Ну h от t это 0, значит в вершинке t у меня
[16:12.940 --> 16:19.080]  значение функции 0, дальше рассматриваем скажем все ребра ведущие в t, тогда мы понимаем, что значение
[16:19.080 --> 16:24.320]  h вот в этих вершинках не больше чем длина этого ребра, но поэтому в частности значение h в них не
[16:24.320 --> 16:30.320]  больше расстояния до t. То есть, грубо говоря, если я рассмотрю все кратчайшие пути, то значение
[16:30.320 --> 16:33.920]  функции h здесь из монотонности будет не больше чем длина этого пути. Ну и так далее, что если я
[16:33.920 --> 16:38.400]  рассмотрю произвольный кратчайший путь, то значение h здесь не большим суммой этих ребер,
[16:38.400 --> 16:44.200]  а она равна как раз таки кратчайшему расстоянию, просто расстоянию от вершинка t. Поэтому монотонная
[16:44.200 --> 16:53.720]  всегда допустима. Вот, и следующая теорема, которую мы не полностью докажем, утверждает следующее,
[16:53.720 --> 17:07.880]  что, во-первых, если h это монотонная евристика, вот как раз переходим к асимптотике, то а звездочка
[17:07.880 --> 17:18.560]  не хуже dx и всегда находит правильный ответ, то а звездочка всегда вернет правильный ответ,
[17:24.680 --> 17:43.840]  при этом каждая вершина раскроется не больше одного раза. Каждая вершина раскроется не больше одного
[17:43.840 --> 17:50.760]  раза. Ну, напоминаю, раскрытие это то, что делается у меня вот в этом цикле, что перебор всех ребер и
[17:50.760 --> 17:58.320]  попытка релаксации, то есть обновления g для всех концов всех исходящих ребер, это раскрытие. Ну,
[17:58.320 --> 18:03.040]  а если это верно, то это не хуже чем dx, потому что dx у нас как раз таки раскрывает все вершины
[18:03.040 --> 18:09.160]  по разу и, собственно, в простой реализации за m log n находит кратчайшее расстояние до t.
[18:09.160 --> 18:12.800]  Значит, это делает все то же самое, и раз оно раскрывает все вершины максимум по одному разу,
[18:12.800 --> 18:24.280]  то это не хуже чем dx. Второе, если h допустимая, только допустимая, но не монотонная, то оказывается,
[18:24.280 --> 18:28.960]  что а звездочка тоже всегда вернет правильный ответ, но, возможно, за гораздо большее время,
[18:28.960 --> 18:38.160]  в худшем случае экспедициальное, то а звездочка всегда вернет правильный ответ,
[18:38.160 --> 18:58.680]  но в худшем случае за экспедициальное время. Ну, то есть время больше любого
[18:58.680 --> 19:06.600]  пленома, например, за два в степени n, грубо говоря. То есть это хорошо с точки зрения
[19:06.600 --> 19:11.840]  получения ответа, но непрактично с точки зрения времени работы. Я еще поговорю про все это время
[19:11.840 --> 19:15.720]  работы, на самом деле в этом нет ничего страшного, что в худшем случае экспонента на самом деле
[19:15.720 --> 19:20.800]  часто там гораздо меньше, чем экспонента. Это я еще скажу. Ну и последнее, если h даже
[19:20.800 --> 19:33.800]  недопустимая, то как бы уже ничего нельзя утверждать, что, во-первых, а звездочка может
[19:33.800 --> 19:37.760]  работать долго, во-вторых, может вернуть неправильный ответ. Но давайте напишу так,
[19:37.760 --> 19:50.040]  то если h какая-то адекватная отражает как-то условия нашей задачи, то, возможно,
[19:50.040 --> 19:54.000]  она отработает быстро и вернет, ну, примерно правильное приближение. То есть вот здесь мы
[19:54.000 --> 20:00.000]  отказываемся от точного ответа, а ответ может быть неверным. Но так неформально это будет
[20:00.000 --> 20:11.480]  хорошее приближение к ответу. То а звездочка может вернуть хорошее приближение к ответу.
[20:11.480 --> 20:26.280]  Хорошее приближение к ответу. Ну а в худшем случае, конечно, ответ неверный и при этом еще
[20:26.280 --> 20:41.720]  и работает уже экспоненциально долго. Но в худшем случае неверный ответ плюс экспоненциальное
[20:41.720 --> 20:53.000]  время работы. Вот теперь зачем это может быть нужно? Ну смотрите, первый случай самый-самый
[20:53.000 --> 21:23.000]  случай, который мы делаем, а второй случай самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-самый-с
[21:23.000 --> 21:29.240]  в каком-то смысле можно ожидать, что он быстрее найдет самый короткий путь, что и, грубо говоря, вот он понимает, что там какие-то
[21:29.240 --> 21:38.240]  вершины лучше других за счет оценки, ну и поэтому их будет рассматривать в первую очередь. Это так совсем неформально. Во втором, здесь
[21:38.240 --> 21:47.760]  может быть такое, что если у вас эвристика хоть и допустимая, хоть и не монотонная, то все равно
[21:47.760 --> 21:52.040]  иногда бывает очень быстрое время работы. То есть вот здесь, но это как повезет, то насколько вам
[21:52.040 --> 21:58.960]  получится угадать с эвристикой, что если она действительно вот прям очень хорошо отражает то, как у вас выглядит ваш граф,
[21:58.960 --> 22:07.080]  если вы смогли как-то формулой задать оценку на расстояние, то, возможно, эта штука то есть написана в худшем
[22:07.080 --> 22:14.000]  случае, на самом деле в лучшем случае может быть тоже там очень быстро, лучше, чем DX. Ну наконец последнее, если на h
[22:14.000 --> 22:20.640]  нет никаких ограничений, то, ну то же самое, что если вам повезет, что если h какая-то такая крутая, хоть и не
[22:20.640 --> 22:26.440]  удовлетворяет там каким-то свойствам, но очень адекватно отражает структуру вашего графа, то, возможно, опять-таки она работает
[22:26.440 --> 22:31.760]  быстро, но при этом, возможно, чуть-чуть ошибается. Ну там не знаю, на 10% ошибется. Это, в принципе, хорошее
[22:31.760 --> 22:39.760]  приближение к ответу. Вот, особенно во всяких задачах типа, если у вас есть много задач, не очень больших и при
[22:39.760 --> 22:44.400]  этом вам не обязательно искать там точный ответ. Ну не знаю, вы пишете какую-нибудь игру, а звездочка обычно как раз в
[22:44.400 --> 22:52.680]  разработке игр используется. У вас есть игра, вам нужно там одного юнита переправить в какую-то точку. Понятно, что на пути
[22:52.680 --> 22:59.520]  могут быть препятствия, другие юниты, там какие-нибудь деревья. Вот, ну вы берете просто там а звездочку и, возможно,
[22:59.520 --> 23:05.480]  на хоть не кратчайшее расстояние, ну а там расстояние на 10% больше оптимального. Ну ничего страшного, в принципе, от этого
[23:05.480 --> 23:25.400]  никто, никто сильно грустеть не будет. Так, значит, мы давайте докажем первую часть, остальное мы не будем доказывать.
[23:25.400 --> 23:48.320]  Чтобы это сделать, утверждение такое, если h монотонное, то во звездочке последовательность f от извлекаемых вершин не строго возрастает.
[23:48.320 --> 24:13.560]  Последовательность, я напишу так, f от v1, f от v2 и так далее у извлекаемых вершин не убывает. То есть, есть неравенство, что вот это меньше
[24:13.800 --> 24:28.800]  чем вот это, меньше чем вот это и так далее. Извлекаемые вершины это те, которые я достаю из кучи. Что сначала будет s, потом я ее достал из кучи, раскрыл, посчитал как-то f для всех остальных, потом это будет вершина с минимальным f лежащая в куче и так далее и так далее.
[24:28.800 --> 24:37.800]  Так вот, утверждается, что последовательность, когда я извлекаю эти вершинки, у меня f точно не убывает. f новая вершинка по сравнению с f старой будет только больше либо равно.
[24:38.040 --> 24:51.040]  Ну, доказательство очень простое. Как это работает? Давайте рассмотрим раскрытие вершинки v. Вот мы предположим, что мы ее извлекли, соответственно, здесь было f от v, мы ее раскрываем. То есть, рассмотрим все исходящие ребра.
[24:51.280 --> 25:10.280]  Тогда, что происходит вот с этой, скажем, вершинкой tu? Ну, у нее значение либо остается таким, каким было, f от tu, либо не поменялось, могло не поменяться, если нам не выгодно это ребро использовать.
[25:10.520 --> 25:20.520]  Либо оно могло стать равно, ну, давайте напишем, что это g от v, плюс e-кост, плюс h от tu.
[25:21.520 --> 25:32.520]  Так что мы могли заиспользовать вот этот путь, который мы нашли, от s до v, прибавить это новое ребро и затем с помощью эвристики h оценить расстояние от tu до t.
[25:32.760 --> 25:39.760]  Ну, если мы с вами сможем доказать, что это большее равно f от v, то мы, на самом деле, победим.
[25:39.760 --> 25:50.760]  Потому что это будет означать, что если мы какую-то вершинку раскрываем, то все остальные значения, которые есть у нас в куче, они могут быть только большее равно, чем вот этот извлеченный минимум.
[25:50.760 --> 25:59.760]  То есть, если было, наоборот, с другую сторону неравенства меньше, тогда, смотрите, мы извлекли какое-то значение, значение f, обновили и положили в кучу вершину с меньшим f.
[26:00.000 --> 26:05.000]  Тогда как раз противоречит, что у меня в каком-то месте убывает последовательность извлекаемых вот этих f.
[26:05.000 --> 26:13.000]  Иначе, если неравенство всегда вот такое, то, соответственно, когда мы извлекли вершину, положить мы в нее могли только вершины с большим значением, с большим либо равным.
[26:13.000 --> 26:16.000]  Поэтому, когда мы их будем извлекать, конечно, будет такая цепочка неравенства.
[26:18.000 --> 26:27.000]  Так, ну почему это верно? Здесь нужно просто написать неравенство треугольника для функции h, которая следует из определения монотонности.
[26:27.240 --> 26:33.240]  Значит, давайте напишем такое f от v, это g от v плюс h от v.
[26:36.240 --> 26:43.240]  Ну и h от v я оценю по определению монотонности через h от tu plus e-coast.
[26:46.240 --> 26:49.240]  Потому что что такое h от v? Это оценка на расстояние от v до конца.
[26:49.240 --> 26:54.240]  Понятно, что этот путь не больше, чем стоимость этого ребра плюс расстояние от tu до конца.
[26:54.480 --> 27:02.480]  Ну, собственно, доказали требуемое неравенство, что g от v плюс h от v не больше, чем g от v плюс h от tu plus e-coast.
[27:02.480 --> 27:04.480]  Вот оно в точности здесь написано.
[27:05.480 --> 27:06.480]  Утверждение доказано.
[27:08.480 --> 27:09.480]  Вопросы?
[27:09.720 --> 27:12.720]  Так, что следующее?
[27:26.720 --> 27:28.720]  Ну да, собственно, тогда утверждение...
[27:29.720 --> 27:32.720]  Давайте, скажем, доказать стеорема пункт 1.
[27:32.720 --> 27:34.720]  Доказать стеорема пункт 1.
[27:34.720 --> 27:36.720]  Что озвучка корректно работает, что она не работает.
[27:36.960 --> 27:41.960]  Мы знаем, что последовательность минимумов у нас не строго возрастает.
[27:41.960 --> 27:45.960]  Это в частности означает, что нет смысла вершину раскрывать больше, чем один раз.
[27:45.960 --> 27:49.960]  Потому что, представьте, какой нам может быть резон раскрывать какую-то вершину дважды.
[27:49.960 --> 27:53.960]  То есть мы нашли до нее какой-то путь, раскрыли, обновили вот эти вот расстояния.
[27:53.960 --> 27:56.960]  А потом еще нашли до нее другой какой-то путь, и опять ее раскрываем.
[27:56.960 --> 28:01.960]  То есть она опять добавилась в очередь, мы ее опять извлекли, и, соответственно, опять раскрываем.
[28:02.200 --> 28:05.200]  Но понятно, что это бессмысленно, если у меня последовательность f-ок возрастает.
[28:05.200 --> 28:09.200]  То есть, смотрите, мы в какой-то момент f от v было у нас какое-то, мы ее извлекли.
[28:09.200 --> 28:12.200]  Потом в какой-то другой момент, более поздний, мы опять вы извлекаем.
[28:12.200 --> 28:15.200]  Но это осмысленно делать, только если f от v упало.
[28:15.200 --> 28:19.200]  Если оно было таким же, то нет смысла ее заново рассматривать.
[28:19.200 --> 28:23.200]  Поэтому давайте напишем вершина v.
[28:23.200 --> 28:25.200]  Вершина v.
[28:25.200 --> 28:27.200]  Вершина v.
[28:27.200 --> 28:29.200]  Вершина v.
[28:29.200 --> 28:31.200]  Давайте напишем.
[28:31.200 --> 28:37.200]  Вершина v может быть извлечена дважды.
[28:40.200 --> 28:42.200]  Дважды.
[28:42.200 --> 28:52.200]  Только если f от v уменьшается в промежутке между извлечениями.
[28:52.200 --> 28:54.200]  f от v уменьшилась.
[28:54.200 --> 28:56.200]  Уменьшилась.
[28:57.200 --> 28:59.200]  Между извлечениями.
[29:05.200 --> 29:08.200]  Ну а такого не бывает, потому что мы доказали, что последовательность f,
[29:08.200 --> 29:10.200]  которую мы извлекаем, только нестрого возрастает.
[29:10.200 --> 29:15.200]  А если мы извлекли v, а потом она уменьшилась, то понятно, что нам нужно будет когда-то ее обработать.
[29:15.200 --> 29:19.200]  Значит, получается, что наша последовательность, ну, неверно, что она не убывает.
[29:19.200 --> 29:28.200]  Это значит, что в какой-то момент мы извлекли v, оно было вот такой, а потом в другой момент мы опять извлекли v, и оно упало.
[29:28.200 --> 29:32.200]  Значит, противоречие с тем утверждением.
[29:32.200 --> 29:36.200]  Противоречие с утверждением.
[29:39.200 --> 29:42.200]  Это значит, что каждая вершина рассматривается один раз.
[29:42.200 --> 29:44.200]  Первая часть выполнена. Точнее, вторая.
[29:44.200 --> 29:46.200]  Что каждая вершина рассматривается максимум один раз.
[29:46.200 --> 29:48.200]  Теперь почему вернется правильный ответ?
[30:06.200 --> 30:09.200]  Почему вернем правильный ответ?
[30:09.200 --> 30:11.200]  Ну, смотрите, мы видим, что...
[30:11.200 --> 30:13.200]  Ну, во-первых, там, простой случай.
[30:13.200 --> 30:17.200]  Если t недостижимо из s, то давайте считать, что такого не бывает.
[30:17.200 --> 30:21.200]  Что можно просто исходно было запустить какой-нибудь bfs, проверить, достижимо ли t из s.
[30:21.200 --> 30:23.200]  Считаем, что достижимо.
[30:23.200 --> 30:27.200]  Значит, тогда наш алгоритм завершится только, когда извлечет t из кучи.
[30:27.200 --> 30:30.200]  Алгоритм завершается, когда он извлекает t из кучи.
[30:30.200 --> 30:33.200]  Там было условие, что если текущий вершин равно t, то break.
[30:33.200 --> 30:35.200]  Ну пусть тогда это не верно.
[30:35.200 --> 30:38.200]  То есть мы нашли какой-то путь от s до t.
[30:38.200 --> 30:40.200]  Извлекли t из кучи.
[30:40.200 --> 30:43.200]  То есть мы нашли путь, соответственно, нашли f от t.
[30:43.200 --> 30:46.200]  Какое-то оно было минимально в куче, мы его извлекли и закончились.
[30:46.200 --> 30:49.200]  И пусть это неправильный ответ.
[30:49.200 --> 30:54.200]  Ну, тогда давайте виртуально представим, что мы продолжаем наш алгоритм,
[30:54.200 --> 30:56.200]  до тех пор, пока очередь не опустеет.
[30:56.200 --> 30:59.200]  И если мы вдруг не получаем текущий вершин,
[30:59.200 --> 31:02.200]  то тогда, соответственно, f от t от нее должна была бы упасть.
[31:02.200 --> 31:06.200]  И потом, когда я эту t опять извлекаю, то получается, что последний эффект у меня убывает.
[31:06.200 --> 31:09.200]  Значит, идея такая.
[31:09.200 --> 31:14.200]  Ну, во-первых, давайте заметим, что f от t это просто всегда g, вот t.
[31:14.200 --> 31:17.200]  Потому что h от t это у нас всегда 0.
[31:17.200 --> 31:20.200]  Так как h от t это 0.
[31:20.200 --> 31:23.200]  Ну, то есть мы нашли текущий вершин.
[31:23.200 --> 31:26.200]  То есть мы нашли текущий вершин.
[31:26.200 --> 31:29.200]  Так как h от t это 0.
[31:29.200 --> 31:33.200]  Поэтому, когда мы доходим до вершинки t, для нее f и g это одно и то же.
[31:33.200 --> 31:36.200]  Потому что h 0 для конечной вершинки.
[31:36.200 --> 31:52.200]  Итак, пусть алгоритм нашел неоптимальный путь какой-то длины f от t.
[31:52.200 --> 31:55.200]  Вот он нашел какой-то такой путь.
[31:55.200 --> 31:58.200]  Извлек t из очереди, из кучи и завершился.
[31:58.200 --> 32:01.200]  И пусть это не оптимум.
[32:01.200 --> 32:04.200]  Тогда давайте рассмотрим настоящий оптимум.
[32:04.200 --> 32:07.200]  Вот пусть вот это то, что мы нашли в алгоритме, во звездочках.
[32:07.200 --> 32:10.200]  А это настоящий оптимальный путь. Самый короткий.
[32:10.200 --> 32:13.200]  То есть более короткий, чем то, что мы нашли.
[32:13.200 --> 32:16.200]  Тогда давайте мы виртуально представим, что мы наш алгоритм продолжим запускать.
[32:16.200 --> 32:19.200]  Ну, то есть продолжим реализовывать, пока очередь не опустеет.
[32:19.200 --> 32:22.200]  Ну, тогда смотрите, понятное дело, что в какой-то момент у меня обработается вот эта вершина.
[32:22.200 --> 32:25.200]  После нее обработается вот эта вершина и так далее, и так далее.
[32:25.200 --> 32:30.200]  То есть на самом деле, если мы как бы позволим нашему алгоритму работать бесконечно долго,
[32:30.200 --> 32:36.200]  пока очередь не опустеет, он, конечно, весь вот этот путь раскроет вот в таком порядке.
[32:36.200 --> 32:39.200]  Что сначала раскроет эту вершину, потом эту, потом и так далее, потом вот эту.
[32:39.200 --> 32:44.200]  Здесь легко видеть, что если здесь есть неравенство на h, а g...
[32:45.200 --> 32:52.200]  Ну да, g равно, собственно, сумме вот этих ребер, то они именно в таком порядке будут рассматриваться.
[32:52.200 --> 32:55.200]  Именно в порядке слева-направого в какой-то момент они рассмотрятся.
[32:55.200 --> 32:59.200]  Ну, значит, если мы наш алгоритм позволим работать бесконечно долго,
[32:59.200 --> 33:03.200]  он когда-то пересчитает f от t как какое-то меньшее число.
[33:03.200 --> 33:07.200]  Значит, опять добавит его в очередь и потом извлечет f от t с меньшим значением.
[33:07.200 --> 33:11.200]  Противоречие с тем, что мы не можем такого делать.
[33:11.200 --> 33:25.200]  Значит, если это так, то давайте виртуально продолжим работу алгоритма,
[33:25.200 --> 33:33.200]  пока очередь не опустеет, пока q не опустеет.
[33:33.200 --> 33:50.200]  Значит, тогда он этот алгоритм найдет опыт, уменьшит f от t,
[33:50.200 --> 33:54.200]  ну и соответственно потом ему придется извлечь t с уменьшимся значением,
[33:54.200 --> 33:57.200]  что противоречит опять-таки утверждению.
[33:57.200 --> 34:01.200]  Ну, опять противоречие, f у нас не может падать.
[34:01.200 --> 34:05.200]  Тут немножко неформально, тут нужно аккуратнее объяснить,
[34:05.200 --> 34:09.200]  почему мы когда-то оптимальный путь все-таки рассмотрим.
[34:09.200 --> 34:14.200]  Тут просто можете с вами подумать, я не буду этого требовать.
[34:14.200 --> 34:21.200]  Но те, кто не умеет, они не умеют, они не умеют, они не умеют, они не умеют, они не умеют.
[34:21.200 --> 34:27.200]  Ну, тут просто можете с вами подумать, я не буду этого требовать.
[34:27.200 --> 34:30.200]  Ну, понятно, что s рассмотрится в первую очередь.
[34:30.200 --> 34:34.200]  Затем в какой-то момент эта вершина тоже рассмотрится, причем до нее найдено крышешее расстояние,
[34:34.200 --> 34:36.200]  потому что мы рассмотрели это ребро.
[34:36.200 --> 34:40.200]  Дальше эта вершина тоже рассмотрится, потому что до нее, до вот это найдено крышешее расстояние,
[34:40.200 --> 34:46.200]  и здесь это ребро, ну, в общем, опять по неразрешению треугольника из монотонности,
[34:46.200 --> 34:48.200]  вот эта штука будет больше значима вот эта.
[34:48.200 --> 34:51.200]  Эта штука, как бы, либо рассмотрится раньше, либо это рассмотрится раньше,
[34:51.200 --> 34:54.200]  но тогда до нее f ровно такое, как нужно.
[34:54.200 --> 34:59.200]  Поэтому этот путь мы, ну, не то что обязательно его слева направо пройдем,
[34:59.200 --> 35:02.200]  то есть мы, возможно, нашли там, ну, то есть какой-то такой путь,
[35:02.200 --> 35:05.200]  если он такой же длинный, то, возможно, мы рассмотрели не вот этот путь, а вот этот.
[35:05.200 --> 35:09.200]  Но главное, что мы все-таки, все равно, как бы, эту информацию в этом пути передадим в t,
[35:09.200 --> 35:11.200]  и тем самым f от t уменьшится.
[35:11.200 --> 35:14.200]  Так, ну, вроде с корректностью все. Вопросы?
[35:14.200 --> 35:17.200]  А у меня вопрос, вы предлагали сделать пул,
[35:17.200 --> 35:21.200]  и чего было так просто, на что находится эта вершина?
[35:21.200 --> 35:23.200]  Да, ну, это можно просто булевский флаг хранить.
[35:23.200 --> 35:26.200]  Давайте для каждой вершины хранить булевский флаг, есть она в очереди или нет.
[35:26.200 --> 35:29.200]  Когда мы ее извлекаем, мы этот флаг делаем, что на ней лежит,
[35:29.200 --> 35:31.200]  когда добавляем, делаем, что на ней лежит.
[35:31.200 --> 35:36.200]  Так, ну, значит, из этого всего следует, что асимптотика точно сверху оценивается m-луганом.
[35:40.200 --> 35:43.200]  Так же, как в дэйкстре, да, что мы поняли, что это не хуже, чем дэйкстры,
[35:43.200 --> 35:47.200]  а дэйкстры работают вот на куче, ровно с такой асимптотикой.
[35:47.200 --> 35:50.200]  Ну, и еще раз повторюсь, да, что очень часто мы, на самом деле,
[35:50.200 --> 35:56.200]  делаем флаг хранить в тексте, в тексте, в тексте, в тексте, в тексте, в тексте, в тексте, в тексте.
[35:57.200 --> 36:01.200]  Ну, и еще раз повторюсь, да, что очень часто мы, на самом деле,
[36:01.200 --> 36:04.200]  будем работать сильно лучше, чем вот эта самая наша асимптотика.
[36:04.200 --> 36:06.200]  Например, представьте себе такую картинку.
[36:06.200 --> 36:10.200]  Вот есть у вас та же самая игра, есть у вас юнит, который стоит здесь и прячется попасть сюда.
[36:10.200 --> 36:13.200]  При этом у вас нет никаких ограничений на этом пути.
[36:13.200 --> 36:15.200]  То есть, грубо говоря, есть вот такой путь.
[36:15.200 --> 36:17.200]  Тогда что делает дэйкстра?
[36:17.200 --> 36:23.200]  Ну, давайте, если граф будет как бы невзвешеный, то дэйкстра, по сути, работает как бы ф-эшт.
[36:23.200 --> 36:28.200]  Сначала мы рассмотрим все вершины на расстоянии 0, потом все вершины на расстоянии 1, на расстоянии 2 и так далее.
[36:28.200 --> 36:30.200]  То есть, мы будем вот такими вот расширяющимися квадратиками двигаться.
[36:30.200 --> 36:32.200]  Это дэйкстра или бфс.
[36:32.200 --> 36:33.200]  А звездочка...
[36:33.200 --> 36:37.200]  А давайте напишу, что здесь бфс или дэйкстра.
[36:39.200 --> 36:41.200]  Как будет действовать а звездочка?
[36:44.200 --> 36:47.200]  Если, например, у меня метрика...
[36:47.200 --> 36:57.200]  Здесь у меня, видимо, Манхэттенская, что у меня можно ходить в четырех направлениях за один шаг, за одну единицу стоимости.
[36:57.200 --> 37:02.200]  Тогда, если мы введем, скажем, в качестве эвристики Манхэттенское расстояние...
[37:10.200 --> 37:13.200]  То есть, сумму модулей разности по х и по у,
[37:13.200 --> 37:18.200]  то тогда он просто сразу же найдет вот такой ответ и не будет даже от него отступать.
[37:18.200 --> 37:20.200]  Это мы сейчас покажем.
[37:20.200 --> 37:27.200]  Если h от v равно dist от v до t, то он на самом деле, по сути, просто находит сразу кратчайший путь,
[37:27.200 --> 37:31.200]  без всяких ответвлений, без вот этих вот обработки лишних вершин.
[37:31.200 --> 37:38.200]  Тут не совсем такая картинка будет, но по сути, по крайней мере, мы не будем рассматривать вот эти вот вершины, которые слева снизу находятся.
[37:38.200 --> 37:41.200]  Их вообще наша а звездочка даже не увидит.
[37:41.200 --> 37:46.200]  Это неосимпатическая оптимизация. То есть, тут нельзя гарантированно писать что-то лучшее, чем m log n.
[37:46.200 --> 37:54.200]  Но очень часто, именно там на практике с точки зрения времени работы, это работает сильно лучше, чем всякие вот эти детерминированные, гарантированные алгоритмы.
[37:56.200 --> 37:58.200]  Так, ну и примеры.
[38:04.200 --> 38:06.200]  Того, какого h можно брать.
[38:06.200 --> 38:07.200]  Примеры.
[38:07.200 --> 38:14.200]  Значит, первое. Если мы скажем, что h от v это тождественный ноль, то а звездочка тождественная совпадает с dx.
[38:16.200 --> 38:21.200]  А звездочка вырождается в алгоритм dx.
[38:26.200 --> 38:29.200]  Ну, потому что в этом случае f это то же самое, что g.
[38:29.200 --> 38:36.200]  А если dx у нас работала как куча на g, то есть каждый раз извлекали минимальное значение g, а теперь а звездочка извлекает минимальное значение f.
[38:36.200 --> 38:40.200]  Но это одно и то же просто. Поэтому по этому алгоритму идет ровно то же самое.
[38:40.200 --> 38:46.200]  Поэтому как минимум то, что мы написали, не хуже даже в самом тупом случае, когда эвристика у нас нулевая.
[38:46.200 --> 38:49.200]  Второй случай, наоборот противоположный, идеальный.
[38:49.200 --> 38:56.200]  Если нам получилось угадать такую эвристику, которая для каждой вершины выдает настоящие расстояния,
[38:56.200 --> 39:11.200]  то, ну я вот так напишу тоже неформально, что а звездочка рассмотрит почти только вершины на кратчайшем пути из s в t.
[39:11.200 --> 39:13.200]  Почему это верно? Смотрите.
[39:13.200 --> 39:16.200]  Есть s, есть t.
[39:16.200 --> 39:22.200]  Я знаю, что у нас есть обороты, которые не могут быть на кратчайшем пути.
[39:22.200 --> 39:26.200]  Но мы не можем их перенести на кратчайшем пути.
[39:26.200 --> 39:34.200]  Если мы не будем перенести на кратчайшем пути, то мы не сможем перенести на кратчайшем пути.
[39:34.200 --> 39:51.200]  Почему это верно? Смотрите, есть s, есть t. Я знаю, что h от v это всегда vt, поэтому в частности вот здесь в самом начале, когда я считаю f от s, у меня f будет равно настоящему расстоянию от s до t.
[39:51.200 --> 40:04.200]  Я напоминаю, в самом начале f от s это просто h от s. В самом начале f от s это просто h от s, потому что g0 есть путь длины 0 из s в s. Соответственно, это просто distance, dist от s до t.
[40:04.200 --> 40:13.200]  То есть мы в самом начале положим в нашу кучу вершину с f равным dist. Но мы его пока не знаем, грубо говоря, или не знаем путь.
[40:13.200 --> 40:27.200]  Дальше мы ее раскрываем. Смотрите, что происходит на, скажем, кратчайшем пути. На кратчайшем пути у меня g вырастает на вес этого ребра, а h, наоборот, убывает на вес этого ребра.
[40:27.200 --> 40:42.200]  Поэтому f не меняется. Еще раз, если я рассматриваю ребро кратчайшего пути от s до t, то у меня g увеличится на вес этого ребра, а h уменьшится, потому что g, собственно, я прибавляю, а из h у меня distance, наоборот, уменьшился на вес этого ребра, потому что осталось идти меньше.
[40:42.200 --> 40:51.200]  Значит f не изменится. Вычли и прибавили одно и то же, значит f у меня остается. Поэтому на этом пути f одно и то же всегда и не меняется.
[40:51.200 --> 41:06.200]  Ну а на остальных, если это ребро не лежит на кратчайшем пути, то здесь будет строго больше значения f. Если это ребро, если эта вершина не лежит на кратчайшем пути, то значит этот путь не оптимальный от s до нее, а потом от нее до t, значит здесь f будет больше.
[41:06.200 --> 41:22.200]  Если это не лежит на кратчайшем, то это больше, чем f. Ну а наш алгоритм рассматривает вершины в порядке возрастания f. То есть он сначала добавит в кучу вот это вот со значением f, потом ее удалит, добавит вот это с значением f и много вершин с значением больше, чем f.
[41:22.200 --> 41:30.200]  Потом из них минимально это вот это, опять раскроют ее, добавят вот эту и опять сколько это больше, чем f, ну и так далее. Поэтому по сути он просто сразу идет к кратчайшему пути и все.
[41:31.200 --> 41:41.200]  Здесь небольшая тонкость, что если тут есть какая-то еще вершина на расстоянии тоже f, то есть есть ну например там два кратчайших пути, вот есть такой путь, есть такой путь.
[41:41.200 --> 41:55.200]  Тогда, ну здесь уже да, здесь чуть менее приятно он будет между ними как бы бегать, да, например он сначала рассмотрел s, потом добавил вот эти две, потом скажем вот эти две рассмотрел, добавил вот эти две, потом эти две рассмотрел, добавил вот эти две.
[41:55.200 --> 42:01.200]  И у них у всех будет одно и то же значение f. Вот здесь везде будет f, потому что они все на кратчайшем пути.
[42:01.200 --> 42:14.200]  Ну то есть поэтому в каком-то смысле, а звездочка как бы все кратчайшие пути найдет. Ну это так, тоже не совсем верно. Какие-то рассмотрит только частично, да, потому что вот его рассмотрел, нашел t, этот путь он заканчивать не будет.
[42:14.200 --> 42:26.200]  Но главное, что вершины не лежащие ни в каком кратчайшем пути он точно рассматривать не будет. Вот это главное, что весь этот мусор, вот как здесь был, весь мусор лежащий в неправильной области он даже смотреть не будет.
[42:32.200 --> 42:44.200]  Так, ну это, конечно, утопия. Если у нас есть способ вычислять расстояние от v до t, то, собственно, нам никакая звездочка не нужна. Мы можем просто сразу вывести dist st и все.
[42:44.200 --> 42:51.200]  Ну вот если h как-то к нему близко, то это вот обосновывает, почему азоточка хороша.
[42:51.200 --> 43:00.200]  Ну и третье, какие-то конкретные случаи, что если у меня граф расположен на плоскости, ну давайте я нарисую такую сеточку, да, вот как там у меня была.
[43:00.200 --> 43:06.200]  Есть такая сетка, соответственно, вершины это узлы, и можно двигаться за один шаг вправо, вверх, вниз или влево.
[43:06.200 --> 43:18.200]  Тогда, значит, это как раз, ну, минимально, сейчас, сори, значит, у меня есть вершинки в узлах, ребра, это, соответственно, вот эти вот вертикальные гридонатальные перемычки,
[43:18.200 --> 43:25.200]  и какие-то из них, скажем, удалены, ну там не знаю, здесь там мост разрушен, тут нельзя ходить. Вот такой есть граф какой-то.
[43:25.200 --> 43:32.200]  Мне нужно идти короче же путь отсюда до сюда. Тогда нижней оценкой на расстояние может выступать как раз-таки вот та самая Манхэттенская метрика.
[43:33.200 --> 43:44.200]  Я напишу, что h от v это vx-tx плюс vy-tx, Манхэттенское расстояние.
[43:50.200 --> 43:57.200]  Ну понятно, да, из нашей структуры графа понятно, что кратчайший путь отсюда до сюда не может иметь меньшую длину, чем Манхэттен.
[43:57.200 --> 44:02.200]  Потому что только если в случае, когда здесь нет препятствий, мы можем добиться такого расстояния.
[44:02.200 --> 44:07.200]  Если препятствий есть, то нам придется их обходить, и расстояние подлинно только вырастет.
[44:07.200 --> 44:11.200]  То есть выполняется оценка снизу, а h от v всегда меньше обыночен настоящей дистанции.
[44:13.200 --> 44:21.200]  Четвертое. Это когда у меня вот такая сеточка с диагоналями, значит такая же, только диагонали есть еще везде.
[44:27.200 --> 44:36.200]  То есть я могу за один шаг переместиться либо вверх, либо вправо, либо вниз, либо влево, либо по одной из четырех вот этих диагоналек, тоже за одну единицу стоимости.
[44:36.200 --> 44:41.200]  Тогда здесь подойдет метрика Чебушова, расстояние Чебушова.
[44:47.200 --> 44:58.200]  Ну это максимум из мололей разности. Максимум из vx-tx и vy-ty.
[44:58.200 --> 45:09.200]  Ну тоже понятно, если у нас такая сетка, то даже в оптимальном случае, когда все ребра присутствуют, нет никаких препятствий, нам нужно ровно столько пройти.
[45:09.200 --> 45:17.200]  Потому что, если, скажем, модуль разности х это 10, а модуль разности у это 5, то мы сначала проходимся по диагональкам.
[45:17.200 --> 45:23.200]  Минус 1, минус 1 делаем, и потом х добиваем единичками, чтобы до правильного значения дойти.
[45:23.200 --> 45:27.200]  То есть это оценка снизу, опять монотонная ивристика, поэтому все здорово.
[45:27.200 --> 45:32.200]  Ну и последнее, это просто обычное эвклидовое расстояние.
[45:32.200 --> 45:38.200]  Это в случае, когда у меня, грубо говоря, здесь довольно большая степень дискретизации.
[45:38.200 --> 45:46.200]  То есть вместо 8 направлений, когда я могу ходить в Чебушовской сетке, я могу ходить, грубо говоря, во все стороны.
[45:46.200 --> 45:55.200]  То есть у меня нет, иными словами, очень-очень большая степень дискретизации, здесь очень много вот таких исходящих ребр.
[45:55.200 --> 46:02.200]  Ну тогда это корень из суммы разности квадратов.
[46:08.200 --> 46:15.200]  Тоже, если у меня нет никаких ограничений, я могу ходить в любую сторону, то это минимально возможная длина, собственно, пути, соединяющей вершинки ВИТ.
[46:15.200 --> 46:26.200]  Поэтому в зависимости от того, как у вас выглядит сетка, как у вас выглядит граф, на основе, в общем, какой метрик он построен, вам будут подходить всякие разные аж.
[46:26.200 --> 46:32.200]  Ну и понятно, что если граф не уложен на плоскости, то нужны какие-то еще другие подходы.
[46:32.200 --> 46:41.200]  В контесте будет задача про пятнашки, вот такая задача, что есть у вас доска 4 на 4, одна свободная клетка, в остальных написаны числа от 1 до 15.
[46:42.200 --> 46:52.200]  И вам нужно как-то их так двигать, то есть можно число перемещать в свободную клетку так, чтобы получить какую-то перестановку заданную, скажем, тождественную, 1, 2, 3, 4, 5 и так далее до 15.
[46:52.200 --> 47:01.200]  Ну там тоже нужна какая-то евристика, один из возможных способов, нужна какая-то евристика, ну и так, чтобы азветочка на них хорошо работала.
[47:01.200 --> 47:06.200]  Чем лучше вы евристику сможете подобрать, тем быстрее ваш алгоритм будет.
[47:12.200 --> 47:15.200]  Так, есть вопросы по азветочке еще?
[47:18.200 --> 47:20.200]  Хорошо, тогда едем дальше.
[47:26.200 --> 47:28.200]  Простой алгоритм Флойда.
[47:31.200 --> 47:38.200]  Задача такая, пусть в графе могут быть отрицательные ребра.
[47:41.200 --> 47:47.200]  То есть ребра отрицательного веса. Напомню, что в DX у нас все веса всегда не отрицательные, иначе DX не работает.
[47:47.200 --> 47:52.200]  Так вот пусть в графе могут быть отрицательные ребра, но отрицательных циклов нет.
[47:53.200 --> 47:57.200]  Но нет отрицательных циклов.
[47:59.200 --> 48:04.200]  То есть таких циклов, таких вот замкнутых путей, на которых сумма весов была бы меньше нуля.
[48:05.200 --> 48:10.200]  Значит тогда алгоритм Флойда
[48:16.200 --> 48:23.200]  Находит все попарные кратчайшие расстояния. То есть для каждой пары У и В он найдет расстояние от У до В.
[48:26.200 --> 48:32.200]  Находит все попарные кратчайшие расстояния.
[48:35.200 --> 48:42.200]  То есть для любой пары У и В он найдет расстояние от У до В.
[48:54.200 --> 48:58.200]  И делает это он с помощью очень простой динамики.
[48:58.200 --> 49:03.200]  Пусть считается у меня вершины пронумерованы от одного до N.
[49:05.200 --> 49:08.200]  И заведем следующую динамику.
[49:09.200 --> 49:12.200]  DP IJK
[49:14.200 --> 49:17.200]  Это минимальная длина пути из И в J,
[49:18.200 --> 49:23.200]  который в качестве промежуточных вершин может рассматривать только вершины с номерами не больше чем K.
[49:24.200 --> 49:33.200]  Минимальное расстояние из И в J такое, что в качестве промежуточных, кроме И и кроме J,
[49:34.200 --> 49:39.200]  на пути все остальные имеют номер не больше чем K.
[49:42.200 --> 49:46.200]  Все промежуточные вершины
[49:46.200 --> 49:50.200]  имеют номер не больше чем K.
[49:51.200 --> 49:54.200]  То есть такая вот картинка есть, и есть J.
[49:55.200 --> 50:01.200]  Мы пытаемся найти кратчайший путь, но используя при этом вот здесь посерединке только вершины с номерами не больше чем K.
[50:02.200 --> 50:06.200]  Все вот эти вершины имеют номера не больше чем K.
[50:07.200 --> 50:11.200]  Как это сделать? Как насчитать такую динамику?
[50:11.200 --> 50:14.200]  Во-первых, DP IJT0 это просто вес ребра из И в J.
[50:15.200 --> 50:19.200]  Потому что если K равно 0, то нам вообще нельзя использовать промежуточные вершины.
[50:20.200 --> 50:23.200]  Здесь написано грешение вершины 0, но у меня нет ни одной вершины с номером 0 или меньше.
[50:24.200 --> 50:26.200]  Значит, мне нельзя использовать ничего промежуточного.
[50:27.200 --> 50:32.200]  Мне можно только проверить, есть ли ребро между ними, и тогда написать там вес этого ребра.
[50:33.200 --> 50:36.200]  Равно кост и J.
[50:36.200 --> 50:40.200]  Я считаю, что если И равно J, то кост равен нулю.
[50:41.200 --> 50:44.200]  На все вершины я навешиваю неявно петли веса 0.
[50:45.200 --> 50:47.200]  То есть я могу из вершинки прийти в нее же за 0 стоимости.
[50:48.200 --> 50:51.200]  Если же нет ребра из И в J, то я считаю, что кост равен плюс бесконечности.
[50:52.200 --> 50:59.200]  Если ребра нет, то мы искусственно его создаем и говорим, что стоимость на нем плюс бесконечность.
[51:00.200 --> 51:03.200]  Потому что мы не можем сказать, что кост равен 0.
[51:03.200 --> 51:05.200]  Мы думаем, что стоимость на нем плюс бесконечность.
[51:06.200 --> 51:11.200]  Потому что с точки зрения расстояний отсутствие ребра или наличие ребра бесконечного веса это одно и то же.
[51:12.200 --> 51:13.200]  Мы все равно им не будем пользоваться.
[51:14.200 --> 51:18.200]  Поэтому в этом случае динамика будет корректно определена, что если ребра нет, то кост равен.
[51:19.200 --> 51:20.200]  Вот эта dp равна плюс бесконечности.
[51:21.200 --> 51:22.200]  Ребра нет, dp тоже не определено.
[51:23.200 --> 51:25.200]  Минимум по пустому множеству это плюс бесконечность.
[51:26.200 --> 51:28.200]  Теперь простые переходы.
[51:33.200 --> 51:35.200]  Переход от k до слоя k плюс 1.
[51:36.200 --> 51:40.200]  Представьте, что мне известны все dp и jk при фиксированном k для любых и j.
[51:41.200 --> 51:43.200]  То есть k фиксировано, а и j произвольные я знаю.
[51:44.200 --> 51:50.200]  Теперь я, соответственно, хочу найти dp и jk плюс 1.
[51:53.200 --> 51:58.200]  Как выглядит кратчайший путь из И в J, который в качестве промежуточных может искусствовать.
[51:59.200 --> 52:05.200]  Как выглядит кратчайший путь из И в J, который в качестве промежуточных может использовать вершины с номерами не больше, чем k плюс 1.
[52:06.200 --> 52:08.200]  Здесь есть две простые опции.
[52:09.200 --> 52:14.200]  Первая опция, что они не просто меньше, чем k плюс 1, но еще и все меньше, чем k.
[52:16.200 --> 52:18.200]  То есть мы не используем вершину с номером k плюс 1.
[52:19.200 --> 52:21.200]  Тогда нужно просто взять dp и jk.
[52:29.200 --> 52:33.200]  Этот случай отвечает тому, что мы вообще не берем вершину с номером k плюс 1.
[52:34.200 --> 52:36.200]  Второй случай, когда мы, наоборот, ее берем.
[52:37.200 --> 52:38.200]  То есть вот есть какой-то такой путь.
[52:39.200 --> 52:41.200]  Здесь где-то есть вершина с номером k плюс 1.
[52:42.200 --> 52:48.200]  Тогда я утверждаю, что вот на этих кусочках нет вершин с номерами больше, чем k.
[52:49.200 --> 52:51.200]  То есть если я говорю, что есть вершина с номером k плюс 1, то она максимум одна.
[52:52.200 --> 52:55.200]  Соответственно, вот здесь на этих кусках все промежуточные имеют номер не больше, чем k.
[52:56.200 --> 52:59.200]  Ну это почти очевидно. Нет же смысла посещать одну вершину больше, чем один раз.
[53:00.200 --> 53:02.200]  То есть если мы зашли в k плюс 1, то еще где-то нет смысла ее посещать.
[53:05.200 --> 53:12.200]  Ну и соответственно нам нужно взять dp и k плюс 1k
[53:15.200 --> 53:21.200]  плюс dp k плюс 1j k.
[53:25.200 --> 53:26.200]  Кажется, все.
[53:27.200 --> 53:29.200]  То есть я либо не беру k плюс 1, либо беру.
[53:30.200 --> 53:33.200]  Тогда вот здесь мне нужно просто взять значение предыдущего слоя, скатого слоя.
[53:34.200 --> 53:36.200]  Вот здесь важно, что нет отрицательных циклов.
[53:37.200 --> 53:41.200]  Потому что это предположение, что мы берем вершину номера k плюс 1 только один раз.
[53:42.200 --> 53:43.200]  Ну максимум один раз.
[53:44.200 --> 53:45.200]  Оно верно исключительно в предположении, что нет отрицательных циклов.
[53:46.200 --> 53:49.200]  Потому что если бы они были, то вот этот оптимальный путь, возможно, вершину k плюс 1 содержал бы много раз.
[53:49.200 --> 53:55.200]  То есть ну как можно, скажем, вот если есть у меня какой-то цикл отрицательного веса, скажем, минус 1,
[53:56.200 --> 54:00.200]  есть какой-то путь вот такой вот, который имеет вес ровно минус 1,
[54:01.200 --> 54:05.200]  тогда мы можем сначала дойти и до k плюс 1, потом петляй здесь сколько угодно долго,
[54:06.200 --> 54:07.200]  сколько хотим, столько и петляем, потом доходим даже.
[54:08.200 --> 54:11.200]  И значит distance у меня на самом деле будет сколько угодно большой по модулю отрицательный,
[54:12.200 --> 54:14.200]  сколько угодно маленький, сколько угодно близко к минус бесконечности.
[54:14.200 --> 54:17.200]  И поэтому, во-первых, вот это решение будет неверно, что достаточно взять k плюс 1 один раз.
[54:18.200 --> 54:21.200]  Во-вторых, distance вообще будет не очень корректно определённо.
[54:22.200 --> 54:23.200]  Он будет равен минус бесконечности.
[54:24.200 --> 54:26.200]  Потому что мы можем дойти до k плюс 1, бесконечно долго петлять,
[54:27.200 --> 54:29.200]  наматывая сколько угодно большой по модулю отрицательный вес,
[54:30.200 --> 54:32.200]  и потом добегать даже с произвольным отрицательным весом.
[54:33.200 --> 54:35.200]  Вот, а мы считаем, что такого нету, поэтому цикла нам не нужны.
[54:36.200 --> 54:39.200]  Так, всё вот, по сути, весь алгоритм.
[54:39.200 --> 54:42.200]  Работает это за n куб, потому что у меня динамика трёхмерная,
[54:43.200 --> 54:47.200]  каждый аргумент от одного до n бегает, ну и пересчёт за единицу.
[54:48.200 --> 54:51.200]  А симптотика кубическая.
[54:54.200 --> 54:56.200]  Вот, почти всё.
[54:57.200 --> 55:03.200]  Ну, здесь вот у этого подхода недостаток в том, что он ещё и кубическую память требует.
[55:03.200 --> 55:06.200]  А нет, на самом деле, достаточно квадратичной тоже памяти,
[55:07.200 --> 55:10.200]  потому что мы видим наш старый трюк, что мы видим,
[55:11.200 --> 55:13.200]  что k плюс 1 слои динамики выражаются только через k-тый.
[55:14.200 --> 55:17.200]  Поэтому, чтобы решить задачи, нам достаточно хранить два слоя динамики,
[55:18.200 --> 55:20.200]  k-тый k плюс 1, через k-тый пересчитать k плюс 1,
[55:21.200 --> 55:23.200]  потом на место k-того записать k плюс 1,
[55:24.200 --> 55:26.200]  потом k плюс 2 пересчитывать через k плюс 1,
[55:27.200 --> 55:28.200]  каждый раз хранять только два слоя.
[55:29.200 --> 55:31.200]  Можно сделать всё так же, как мы делали с кубической памяти.
[55:31.200 --> 55:32.200]  И каждый раз хранять только два слоя.
[55:33.200 --> 55:37.200]  Можно сделать так и обойтись квадратичной памятью, но можно сделать ещё проще.
[55:45.200 --> 55:54.200]  Давайте напишем следующее, что пусть g и g – это стоимость ребра из и в ж,
[55:55.200 --> 56:00.200]  стоимость ребра из и в ж, тогда алгоритм Флойда можно написать так.
[56:02.200 --> 56:11.200]  По всем k от 1 до n, по всем i от 1 до n, по всем g от 1 до n.
[56:16.200 --> 56:18.200]  Сделать такое обновление, такую релаксацию.
[56:19.200 --> 56:22.200]  g и t и g и t – это минимумы с вождем лежало,
[56:27.200 --> 56:33.200]  ну и соответственно суммы весов в путей от i до k плюс от k до g.
[56:43.200 --> 56:44.200]  Всё.
[56:45.200 --> 56:48.200]  Даже без dp по сути нам последние измерения не нужны.
[56:49.200 --> 56:54.200]  Я просто убрал последние измерения и сказал, что dp – это g.
[56:55.200 --> 56:56.200]  Всё, сделал такую штуку.
[56:57.200 --> 57:00.200]  В конце, то есть изначально в ж у меня лежали стоимости ребер,
[57:01.200 --> 57:06.200]  а в конце в массиве g будут лежать стоимости расстояний между всеми парами вершин.
[57:08.200 --> 57:10.200]  Тут нужно немножко пояснить, почему это корректно,
[57:10.200 --> 57:13.200]  почему можно вот так втупую отрезать последние измерения.
[57:24.200 --> 57:26.200]  Почему можно отрезать последние измерения?
[57:27.200 --> 57:34.200]  Ну, давайте просто докажем, что после кат-итерации внешнего цикла
[57:34.200 --> 57:36.200]  после кат-итерации внешнего цикла,
[57:37.200 --> 57:41.200]  ну то есть вот того цикла пока как раз внешнего цикла,
[57:42.200 --> 57:49.200]  выполнено, что g и t и g и t равно тому самому dp и t и g и t каты.
[57:56.200 --> 57:58.200]  Вот оказательства индукции пока.
[57:59.200 --> 58:00.200]  База k равна нулю, очевидно.
[58:00.200 --> 58:03.200]  В самом начале до выполнения цикла у меня в массиве g лежат просто веса ребер,
[58:04.200 --> 58:06.200]  а это и есть dp и t и g и t нулевое.
[58:07.200 --> 58:09.200]  База k равна нулю.
[58:10.200 --> 58:12.200]  У меня просто хранится веса ребер, и там всё хорошо, там всё верно.
[58:13.200 --> 58:15.200]  dp совпадает с весами ребер, когда k равна нулю.
[58:16.200 --> 58:18.200]  Ну, теперь давайте сделаем одну итерацию.
[58:19.200 --> 58:22.200]  Значит, фиксируем k, рассматриваем k-тую итерацию.
[58:23.200 --> 58:25.200]  Рассматриваем k-tu-ю итерацию.
[58:25.200 --> 58:28.200]  Давайте нарисуем матрицу нашего, вот эту матрицу g.
[58:30.200 --> 58:37.200]  Замечание первое, что в k-той строке и k-том столце значения в течение этой итерации меняться не будут.
[58:38.200 --> 58:42.200]  Значит, я нарисовал матрицу g, рассматриваю k-тую строку и k-тый столбец.
[58:43.200 --> 58:46.200]  Вот я утверждаю, что значения в этой строке и в этом столце меняться не будут.
[58:46.200 --> 58:47.200]  Давайте сюда посмотрим.
[58:47.200 --> 58:50.200]  Что такое k-той столбец и k-той строка?
[58:50.200 --> 58:52.200]  Это когда i или g равно k.
[58:53.200 --> 58:56.200]  Ну, давайте представим, что в этот момент i равно k.
[58:57.200 --> 59:02.200]  Тогда здесь написано путь из k в g, он релаксируется тем, что там было исходно,
[59:03.200 --> 59:06.200]  или же расстояние от k до k плюс расстояние от k до g.
[59:07.200 --> 59:09.200]  То есть у нас есть путь из k в g,
[59:09.200 --> 59:12.200]  он релаксируется тем, что там было исходно,
[59:13.200 --> 59:16.200]  или же расстояние от k до k плюс расстояние от k до g.
[59:17.200 --> 59:19.200]  Но это 0, а это то, что там лежало.
[59:20.200 --> 59:25.200]  Поэтому если i это k, то у меня в этой строчке не делать ничего ровно, потому что эта штука 0.
[59:26.200 --> 59:30.200]  То же самое, если у меня g это k, наоборот, здесь написано ik,
[59:31.200 --> 59:35.200]  здесь написано опять то старое значение, тут опять ik, а здесь написано kk.
[59:36.200 --> 59:38.200]  Здесь же будет вот это 0, поэтому строчке ничего не делать.
[59:39.200 --> 59:42.200]  Это значит, действительно, в моей матрице, в течение ката итерации,
[59:43.200 --> 59:46.200]  вот эти вот товарищи не изменяются,
[59:47.200 --> 59:50.200]  ну и, соответственно, равны тому же, чему были до этой итерации.
[59:51.200 --> 59:54.200]  Ну потому что понятно, что если у меня одна из конечных вершин, это k,
[59:55.200 --> 59:59.200]  то в dp i g k нет смысла использовать k где-то посередине,
[01:00:00.200 --> 01:00:02.200]  потому что если k это одна из конечных, то сама катовершина в промежуше не участвует,
[01:00:03.200 --> 01:00:06.200]  поэтому для нее что k здесь написано, что k-i будет одно и то же.
[01:00:06.200 --> 01:00:08.200]  Здесь ничего не меняется и остается корректным,
[01:00:09.200 --> 01:00:13.200]  но все остальные просто пересчитываются по той формуле.
[01:00:14.200 --> 01:00:16.200]  То есть для всех остальных мы смотрим, на что получается.
[01:00:17.200 --> 01:00:22.200]  Вот если это i g, то мы смотрим ik и kg.
[01:00:23.200 --> 01:00:24.200]  Посмотрим вот эти две клетки.
[01:00:25.200 --> 01:00:26.200]  Но в них написаны правильные значения из dp,
[01:00:27.200 --> 01:00:31.200]  соответственно, у меня просто все остальное содержимое в матрице
[01:00:32.200 --> 01:00:34.200]  в точности пересчитается по вот этой вот формуле.
[01:00:34.200 --> 01:00:39.200]  Каждое значение заменится на минимум из себя и суммы двух правильных значений dp.
[01:00:40.200 --> 01:00:43.200]  Ну все, значит после всей этой итерации у меня вся матрица будет правильная.
[01:00:44.200 --> 01:00:47.200]  То есть единственная проблема могла быть в этом алгоритме в том,
[01:00:48.200 --> 01:00:51.200]  что единственное плохое здесь потенциально могло бы быть,
[01:00:52.200 --> 01:00:56.200]  что когда я делаю все на одной точке памяти в одном и том же массиве g,
[01:00:57.200 --> 01:01:00.200]  могло быть такое, что я на одной итерации сделал несколько.
[01:01:01.200 --> 01:01:03.200]  То есть представьте, что я вот здесь g и g правильно посчитал,
[01:01:04.200 --> 01:01:05.200]  используя катовую вершину.
[01:01:06.200 --> 01:01:08.200]  А потом для какой-то другой пары из штриха и штриха их пересчитал через и g.
[01:01:09.200 --> 01:01:11.200]  А само и g уже учитывает катовую вершину и якобы, соответственно,
[01:01:12.200 --> 01:01:13.200]  типа две итерации за одну сделал.
[01:01:14.200 --> 01:01:17.200]  Ну вот мы доказали, что такого не бывает, что вот эта строка и столбец,
[01:01:18.200 --> 01:01:20.200]  строка и столбец у меня фиксированы, а все остальные через них пересчитываются,
[01:01:21.200 --> 01:01:24.200]  значит мы вот ровно делаем одну переход с k-1 на катой.
[01:01:25.200 --> 01:01:29.200]  Ну все, значит наша таблица, она как раз ровно то самое dp моделирует.
[01:01:31.200 --> 01:01:32.200]  Вопросы?
[01:01:34.200 --> 01:01:35.200]  Хорошо.
[01:01:39.200 --> 01:01:41.200]  Тогда последнее простое замечание про Флойда,
[01:01:42.200 --> 01:01:45.200]  это как можно восстановить ответ, как можно восстановить сам путь.
[01:01:46.200 --> 01:01:48.200]  То есть сейчас мы знаем корочайшее расстояние,
[01:01:49.200 --> 01:01:50.200]  расстояние между всеми парами вершин,
[01:01:51.200 --> 01:01:52.200]  а вот как узнать прям последовательность вершин на этом пути?
[01:01:54.200 --> 01:01:56.200]  Значит восстановление ответа,
[01:01:56.200 --> 01:01:58.200]  то есть восстановление самих путей.
[01:01:59.200 --> 01:02:02.200]  Не их весов, а прям самих путей, как последовательность вершин.
[01:02:04.200 --> 01:02:06.200]  Здесь все тоже довольно прозрачно.
[01:02:07.200 --> 01:02:09.200]  В случае, когда я обновляю значение g,
[01:02:10.200 --> 01:02:13.200]  g этой житы обновляется, то есть оно было раньше чем-то, а потом уменьшилось.
[01:02:14.200 --> 01:02:15.200]  Когда оно уменьшается?
[01:02:16.200 --> 01:02:19.200]  Когда я нашел в качестве нового оптимального расстояния вершины,
[01:02:20.200 --> 01:02:23.200]  то есть в качестве нового оптимального расстояния вершины,
[01:02:23.200 --> 01:02:24.200]  то оно уменьшается.
[01:02:25.200 --> 01:02:29.200]  Когда я нашел в качестве нового оптимального пути из FG некий путь, проходящий через K.
[01:02:30.200 --> 01:02:32.200]  Давайте тогда сделаем следующее.
[01:02:33.200 --> 01:02:39.200]  Вот когда g и t житы обновляется
[01:02:42.200 --> 01:02:48.200]  через g и t ка т, плюс g ка т житы,
[01:02:48.200 --> 01:02:55.200]  мы для этой пары и g запомним, что k как бы центральная вершина.
[01:02:57.200 --> 01:03:05.200]  Выполним P и t житы равно k.
[01:03:06.200 --> 01:03:09.200]  И соответственно, затем, когда весь алгоритм у нас закончится,
[01:03:10.200 --> 01:03:14.200]  у меня для каждой пары вершин и g будет храниться в этом массиве P и g вспомогательным,
[01:03:14.200 --> 01:03:17.200]  будет храниться какая-то вершина на этом пути.
[01:03:18.200 --> 01:03:21.200]  Центральная вершина на этом пути, в смысле что посередине,
[01:03:22.200 --> 01:03:23.200]  в смысле что она имеет максимальный номер на самом деле,
[01:03:24.200 --> 01:03:27.200]  будет храниться у меня вершина с максимальным номером, которая на этом пути лежит.
[01:03:28.200 --> 01:03:30.200]  Чтобы найти этот самый путь из FG,
[01:03:31.200 --> 01:03:33.200]  я понимаю, что мне нужно сначала из P, потом из K.
[01:03:34.200 --> 01:03:38.200]  Давайте сначала рекурсивно напечатаю путь из P, потом напечатаю K,
[01:03:39.200 --> 01:03:40.200]  потом напечатаю путь из K в G.
[01:03:41.200 --> 01:03:42.200]  Конец.
[01:03:42.200 --> 01:04:09.200]  Тогда путь из И в Ж выглядит так, что это сначала путь из И в П и Т в Ж, потом сама эта вершина П и Т в Ж, потом путь из П и Т в Ж, конец.
[01:04:09.200 --> 01:04:21.200]  Идея очень простая. Я запомнил, когда я в самый последний раз пересчитал Ж и Т и Ж, через какое К, с помощью какой вершины я добрался из И в Ж.
[01:04:21.200 --> 01:04:30.200]  Если я знаю, что я добрался с помощью этой вершинки с номером П и Ж, мне нужно сначала найти вот эту часть пути рекурсивно.
[01:04:30.200 --> 01:04:35.200]  То есть я пишу какую-то функцию, которая принимает две вершины и печатает путь между ними.
[01:04:35.200 --> 01:04:45.200]  Тогда сначала из И до первой половинки, потом саму эту вершину, потом из этой центральной вершины до конца. Тоже рекурсивно печатаю путь.
[01:04:45.200 --> 01:04:57.200]  Время не поменяется, память вырастет в два раза, потому что нужен вспомогательный массив П, поэтому точка не изменится.
[01:04:57.200 --> 01:04:59.200]  Хорошо.
[01:05:10.200 --> 01:05:16.200]  Вот такой флойд работает за куб, очень просто пишется. Находит все кратчащие расстояния между всеми парами вершин.
[01:05:16.200 --> 01:05:22.200]  Если у вас реальная задача такая, что между всеми парами надо найти расстояние, то ничего проще, чем флойды написать.
[01:05:22.200 --> 01:05:27.200]  Я не представляю, что можно, здесь четыре содержательные строчки. 4-4-4 и релаксация через минимум.
[01:05:27.200 --> 01:05:29.200]  Очень простой алгоритм.
[01:05:29.200 --> 01:05:35.200]  Наконец последний алгоритм с хорошейшими путями, это алгоритм Форда Белмана.
[01:05:43.200 --> 01:05:51.200]  Это наконец алгоритм, который адекватно работает в самом плохом случае, когда могут быть и отрицательные ребра, и отрицательные циклы.
[01:05:51.200 --> 01:05:56.200]  В самом деле во флойде тоже можно было научиться работать с отрицательными циклами, но мы не будем это обсуждать.
[01:05:56.200 --> 01:06:08.200]  Давайте считать, что в графе теперь, только теперь, могут быть и отрицательные ребра, и отрицательные циклы.
[01:06:11.200 --> 01:06:13.200]  То есть циклы отрицательного веса.
[01:06:13.200 --> 01:06:15.200]  А задача такая.
[01:06:15.200 --> 01:06:23.200]  Ну, во-первых, надо теперь определить, что такое расстояние от S до T.
[01:06:25.200 --> 01:06:34.200]  Соответственно с нашим обычным определением, что это минимум по всем возможным длинным путей из S в T, оно теперь может быть минус бесконечность.
[01:06:34.200 --> 01:06:44.200]  А именно вот как раз в том самом случае, когда я могу от S добраться до какого-то цикла отрицательного, по нему сколько угодно много впитлять, потом дойти до T.
[01:06:44.200 --> 01:06:48.200]  В таком случае дистанц может быть сколько угодно отрицательным.
[01:06:48.200 --> 01:06:51.200]  Сколько угодно большим по модулю отрицательным.
[01:06:51.200 --> 01:07:03.200]  Поэтому давайте напишем следующее простое соображение, что дистанц это минус бесконечность, если и только если существует цикл С отрицательного веса.
[01:07:03.200 --> 01:07:14.200]  С отрицательного веса такой, что из S достижимо C, из C достижимо S.
[01:07:14.200 --> 01:07:17.200]  Стрелочки я рисую достижимость.
[01:07:20.200 --> 01:07:23.200]  Из C достижимо C, из C достижимо T.
[01:07:26.200 --> 01:07:32.200]  Вообще говоря, это надо доказывать, потому что у меня есть определение, что такое дистанц, как минимальная возможная длина пути.
[01:07:32.200 --> 01:07:37.200]  Почему минус бесконечность для этого минимума равносильно наличию такого цикла?
[01:07:37.200 --> 01:07:40.200]  Давайте как-то это поясним.
[01:07:42.200 --> 01:07:47.200]  Почему только в такой ситуации может быть у нас минус бесконечность в качестве дистанца?
[01:07:47.200 --> 01:07:50.200]  Давайте я скажу следующее.
[01:07:50.200 --> 01:08:05.200]  Пусть кост ИG по модулю не больше, чем X для любого ребра ИG, а вершина у меня ровно N.
[01:08:06.200 --> 01:08:11.200]  Пусть Дист СТ это минус бесконечность.
[01:08:12.200 --> 01:08:15.200]  Я хочу доказать, что есть отрицательный цикл на пути из С в Т.
[01:08:15.200 --> 01:08:22.200]  То есть еще раз, я доказываю ту кв документность, что минус бесконечной расстояния, то же самое, что есть отрицательный цикл.
[01:08:22.200 --> 01:08:25.200]  То это мало.
[01:08:25.200 --> 01:08:29.200]  цикл на пути из s в t. То есть еще раз, я доказываю
[01:08:29.200 --> 01:08:32.200]  ту эквивалентность, что минус бесконечное расстояние,
[01:08:32.200 --> 01:08:34.200]  то же самое, что есть отрезательный цикл, достижим
[01:08:34.200 --> 01:08:37.200]  на пути из s в t. Справа налево очевидно, по картинке
[01:08:37.200 --> 01:08:39.200]  мы просто доходим до него, петляем сколько угодно
[01:08:39.200 --> 01:08:41.200]  долго, потом доходим до t. Теперь слева направо.
[01:08:41.200 --> 01:08:45.200]  Почему, если distance st минус бесконечность, то обязательно
[01:08:45.200 --> 01:08:47.200]  есть такая картинка, что мы доходим, потом петляем
[01:08:47.200 --> 01:08:50.200]  по циклу, потом доходим до t. Так вот, пусть это
[01:08:50.200 --> 01:09:02.200]  бесконечность, тогда рассмотрим, рассмотрим путь из s в t
[01:09:02.200 --> 01:09:11.200]  веса меньше, чем минус xn с минимальным возможным
[01:09:11.200 --> 01:09:19.200]  числом ребер, с минимальным числом ребер. Ну такой путь
[01:09:19.200 --> 01:09:22.200]  понятное дело есть, потому что у меня последовательность
[01:09:22.200 --> 01:09:26.200]  множества длин путей не ограничена снизу, значит есть
[01:09:26.200 --> 01:09:29.200]  сколько угодно отрицательное число, сколько угодно большое
[01:09:29.200 --> 01:09:32.200]  по модуле отрицательное, значит есть вес меньше, чем
[01:09:32.200 --> 01:09:35.200]  минус x. Среди них я могу выбрать путь с минимальным
[01:09:35.200 --> 01:09:39.200]  числом ребер, потому что натуральные числа фундированы,
[01:09:39.200 --> 01:09:44.200]  то есть минимум корректно определен, это какое-то число.
[01:09:44.200 --> 01:09:54.200]  Дальше. Как он выглядит? Какой такой путь? Первое
[01:09:54.200 --> 01:09:58.200]  замечание, что число ребер в нем строго больше, чем n,
[01:09:58.200 --> 01:10:03.200]  потому что если бы их было не больше, чем n, то его вес
[01:10:03.200 --> 01:10:06.200]  никак не мог бы быть меньше, чем минус xn, потому что
[01:10:06.200 --> 01:10:09.200]  каждое ребро имеет вес больше или равно, чем минус x,
[01:10:09.200 --> 01:10:12.200]  значит если бы их было не больше, чем n, то суммарный
[01:10:12.200 --> 01:10:16.200]  вес был бы больше или равно, чем минус xn, значит ребер
[01:10:16.200 --> 01:10:20.200]  больше, чем n, значит есть какой-то цикл, мы какую-то
[01:10:20.200 --> 01:10:24.200]  вершинку посещаем хотя бы два раза, есть по крайней
[01:10:24.200 --> 01:10:30.200]  мере один цикл, значит есть цикл, ну потому что если
[01:10:30.200 --> 01:10:33.200]  цикла нету и каждая вершина приходит в новую вершину,
[01:10:33.200 --> 01:10:38.200]  то значит вершина у меня посещена аж, видимо, n плюс
[01:10:38.200 --> 01:10:43.200]  1, видимо, n плюс 1 вершина получается посещена, или даже
[01:10:43.200 --> 01:10:46.200]  n плюс 2, короче даже n плюс 2, потому что ребер хотя бы
[01:10:46.200 --> 01:10:49.200]  n плюс 1, значит новых вершин хотя бы n плюс 1, с учетом s
[01:10:49.200 --> 01:10:52.200]  и хотя бы n плюс 2, ну короче, точно если вершина посещена
[01:10:52.200 --> 01:10:55.200]  хотя бы дважды, значит есть цикл. Ну и тогда смотрите,
[01:10:55.200 --> 01:10:59.200]  если у этого цикла вес не отрицательный, тогда я
[01:10:59.200 --> 01:11:02.200]  его могу отбросить, и мой путь в состоянии только лучше,
[01:11:02.200 --> 01:11:05.200]  у него вес останется меньше, чем минус xn, а число ребера
[01:11:05.200 --> 01:11:09.200]  уменьшится, значит исходный был не оптимальный, значит
[01:11:09.200 --> 01:11:12.200]  единственная возможность это, что это цикл отрицательного
[01:11:12.200 --> 01:11:15.200]  веса, победа, значит есть путь из s в t содержащий
[01:11:15.200 --> 01:11:19.200]  какой-то отрицательный цикл. Давайте еще раз повторю,
[01:11:19.200 --> 01:11:28.200]  что есть цикл, если он имеет не отрицательный вес,
[01:11:28.200 --> 01:11:38.200]  то его можно отбросить, его можно отбросить, получить
[01:11:38.200 --> 01:11:46.200]  лучший путь, получить лучший путь. Лучший в том смысле,
[01:11:46.200 --> 01:11:49.200]  что будет выполняться и вот это условие, а вот это условие
[01:11:49.200 --> 01:11:51.200]  станет еще лучше, потому что число ребер только уменьшится.
[01:11:51.200 --> 01:11:53.200]  Я выбросил цикл, число ребер уменьшилось, но при этом
[01:11:53.200 --> 01:11:56.200]  неравенство выполнилось, поэтому мой исходный путь был
[01:11:56.200 --> 01:12:00.200]  не оптимальным с точки зрения числа ребер. Ну все, значит
[01:12:00.200 --> 01:12:02.200]  действительно на таком пути есть отрицательный цикл
[01:12:02.200 --> 01:12:08.200]  и мы доказали то, что хотели. Согласны? Это возможно было
[01:12:08.200 --> 01:12:10.200]  даже не нужно доказывать, то есть очевидно, что как
[01:12:10.200 --> 01:12:13.200]  гипотетически можно вот здесь получить внизу бесконечность,
[01:12:13.200 --> 01:12:15.200]  только петлять где-то сколько угодно долго, но вот это
[01:12:15.200 --> 01:12:24.200]  формализация. Так, хорошо, теперь к алгоритму наконец.
[01:12:24.200 --> 01:12:29.200]  Алгоритм находит кратчайшее расстояние от s до всех.
[01:12:29.200 --> 01:12:39.200]  Находит кратчайшее расстояние от s до всех. То есть не все пары
[01:12:39.200 --> 01:12:41.200]  между собой как флойд, а только от s до всех. Так же,
[01:12:41.200 --> 01:12:44.200]  как было в DX-ре, от s до всех. Только теперь могут быть
[01:12:44.200 --> 01:12:48.200]  отрицательные циклы и отрицательные ребра.
[01:12:48.200 --> 01:13:02.200]  Так, опять динамика. dp v k это минимальная стоимость пути
[01:13:02.200 --> 01:13:08.200]  из s в использующей не больше чем k ребер. Минимальный вес
[01:13:08.200 --> 01:13:22.200]  пути из s в использующей не больше k ребер. Такая динамика.
[01:13:22.200 --> 01:13:27.200]  Как она насчитывается? Если карту нулю, то нам нельзя
[01:13:27.200 --> 01:13:30.200]  использовать ребра, и здесь понятно, что лежит. Это либо
[01:13:30.200 --> 01:13:33.200]  0, если v равно s, либо плюс бесконечность, если v не равно
[01:13:33.200 --> 01:13:36.200]  s. Потому что если нам нельзя использовать ребра, то мы
[01:13:36.200 --> 01:13:38.200]  можем только стоять на месте. Значит, нул, собственно.
[01:13:38.200 --> 01:13:41.200]  dps это 0, а dp и все остальные это плюс бесконечность.
[01:13:41.200 --> 01:13:45.200]  Нельзя никуда попасть. Вот, ну переход. Если я хочу
[01:13:45.200 --> 01:13:49.200]  вершину v попасть за k ребер, давайте я переворачиваю
[01:13:49.200 --> 01:13:56.200]  последнее ребро. Тогда выполняется следующее соотношение.
[01:13:56.200 --> 01:14:02.200]  dp v kt это минимум. Ну, во-первых, надо оставить там
[01:14:02.200 --> 01:14:07.200]  dp v k-1, потому что, а вдруг мне не нужно все k ребер
[01:14:07.200 --> 01:14:11.200]  проходить, достаточно k-1. Значит, это случай, когда
[01:14:11.200 --> 01:14:13.200]  я использую не больше, чем k-1 ребро. Теперь нужен
[01:14:13.200 --> 01:14:16.200]  случай, когда я использую k ребер. Тогда нужно перебрать
[01:14:16.200 --> 01:14:19.200]  последнее. То есть я перебираю все возможные ребра у v
[01:14:19.200 --> 01:14:24.200]  в нашем графе. Ну и здесь остается dp u k-1
[01:14:24.200 --> 01:14:26.200]  плюс кост u v.
[01:14:37.200 --> 01:14:40.200]  То есть еще раз. Это случай отвечает тому, когда я беру
[01:14:40.200 --> 01:14:44.200]  не больше, чем k-1 ребро. Это случай, когда беру все k ребер.
[01:14:44.200 --> 01:14:47.200]  Если я беру k ребер, то давайте я переберу последнее.
[01:14:47.200 --> 01:14:52.200]  Перебираю ребро u v, торчащее в v. Тогда что такое путь
[01:14:52.200 --> 01:14:57.200]  использующий k ребер, при этом посещающий последнее ребро?
[01:14:57.200 --> 01:14:59.200]  Значит, нам нужно сначала оптимальным образом добраться
[01:14:59.200 --> 01:15:02.200]  до u за k-1 ребро, потом это ребро приклеить.
[01:15:02.200 --> 01:15:04.200]  Ну, собственно, это здесь не написано, что мне нужно
[01:15:04.200 --> 01:15:07.200]  добраться сначала до u за k-1 ребро, потом взять вот это
[01:15:07.200 --> 01:15:10.200]  последнее ребро u v. Верно?
[01:15:10.200 --> 01:15:23.200]  Вот. Ну так пересчитывается наша динамика.
[01:15:29.200 --> 01:15:31.200]  Тогда я утверждаю, что если у меня нет отрицательных
[01:15:31.200 --> 01:15:35.200]  циклов, то мне достаточно посчитать n-1 слой динамики,
[01:15:35.200 --> 01:15:38.200]  и это будут ответы.
[01:15:38.200 --> 01:15:49.200]  Если уже нет отрицательных циклов, то для любого v dp
[01:15:49.200 --> 01:15:57.200]  vt n-1 равно dist sv.
[01:15:57.200 --> 01:16:00.200]  Ну, это наш любимый аргумент, что если и есть какой-то
[01:16:00.200 --> 01:16:04.200]  путь от s до v, то он содержит не больше n-1 ребро.
[01:16:04.200 --> 01:16:07.200]  Ну, в смысле, если есть какой-то путь, то кратчайший содержит
[01:16:07.200 --> 01:16:09.200]  не больше н-1 ребро, потому что иначе, если он содержит
[01:16:09.200 --> 01:16:12.200]  хотя бы n ребер, то он обязательно какую-то вершину посещает
[01:16:12.200 --> 01:16:16.200]  дважды, значит, входит в цикл, а циклы нам вредны,
[01:16:16.200 --> 01:16:18.200]  потому что нет отрицательных.
[01:16:18.200 --> 01:16:20.200]  Вот в этом предположении, если их нет, тогда циклы нам
[01:16:20.200 --> 01:16:25.200]  не нужны, поэтому достаточно n-1 ребра для нахождения пути.
[01:16:25.200 --> 01:16:35.200]  В этом случае получается асимптотика n на m,
[01:16:35.200 --> 01:16:39.200]  потому что вот этот второй аргумент бегает у меня от 0
[01:16:39.200 --> 01:16:42.200]  до n-1, n слоев в динамике.
[01:16:42.200 --> 01:16:44.200]  Ну, и внутри каждого слоя я для каждой вершины рассмотрю
[01:16:44.200 --> 01:16:46.200]  все входящие в нее ребра.
[01:16:46.200 --> 01:16:48.200]  Это в точности m, потому что для каждой вершины я рассмотрю
[01:16:48.200 --> 01:16:53.200]  все входящие, значит, я рассмотрю все ребра по одному разу.
[01:16:53.200 --> 01:17:04.200]  Значит, это слоев в ДП, но это время обработки одного слоя.
[01:17:04.200 --> 01:17:06.200]  Потому что на каждом слое, префиксированном в втором
[01:17:06.200 --> 01:17:10.200]  аргументе, я для каждой вершины рассмотрю все входящие в нее ребра,
[01:17:10.200 --> 01:17:15.200]  то есть рассмотрю просто все ребра по одному разу.
[01:17:15.200 --> 01:17:17.200]  Асимптотика будет n-m.
[01:17:17.200 --> 01:17:21.200]  Так, ну и здесь память тоже у меня получилась квадратичная,
[01:17:21.200 --> 01:17:23.200]  n на n.
[01:17:23.200 --> 01:17:25.200]  Но на самом деле тот же самый трюк работает,
[01:17:25.200 --> 01:17:29.200]  что нам достаточно хранить два слоя динамики,
[01:17:29.200 --> 01:17:31.200]  потому что видим, что карты перешли через k-1.
[01:17:31.200 --> 01:17:35.200]  Значит, достаточно, опять, ну, просто ДП в предыдущий слой
[01:17:35.200 --> 01:17:37.200]  и ДП в текущий слой сделать.
[01:17:37.200 --> 01:17:39.200]  Достаточно по этому линейной памяти.
[01:17:39.200 --> 01:17:44.200]  Достаточно от n памяти сделать.
[01:17:47.200 --> 01:17:49.200]  С помощью двух слоев динамики.
[01:17:49.200 --> 01:17:51.200]  Ну, на самом деле там можно так же, как во флойде,
[01:17:51.200 --> 01:17:53.200]  вот это вот второй аргумент вообще не хранить,
[01:17:53.200 --> 01:17:58.200]  и просто хранить ДП в это, и как-то их там доставать и проталкивать.
[01:17:58.200 --> 01:18:00.200]  Но давайте на этом не будем.
[01:18:00.200 --> 01:18:02.200]  Давайте считать, что у меня два слоя динамики,
[01:18:02.200 --> 01:18:05.200]  они один через другой пересчитываются.
[01:18:05.200 --> 01:18:07.200]  Вот это простой случай.
[01:18:07.200 --> 01:18:09.200]  Если нету отрицательных ребер, то, понятное дело,
[01:18:09.200 --> 01:18:11.200]  мы найдем всегда правильный ответ.
[01:18:11.200 --> 01:18:13.200]  За n-1 итерацию нашей ДПшки.
[01:18:13.200 --> 01:18:15.200]  Теперь случай интересный, когда есть отрицательные циклы.
[01:18:19.200 --> 01:18:25.200]  Теперь пусть в G есть отрицательные циклы.
[01:18:27.200 --> 01:18:29.200]  Тогда давайте сделаем следующую вещь.
[01:18:29.200 --> 01:18:33.200]  Давайте мы сделаем на одну больше итерацию нашего алгоритма.
[01:18:33.200 --> 01:18:35.200]  То есть вот до этого момента мы сделали,
[01:18:35.200 --> 01:18:38.200]  мы посчитали все ДПшки до n-1 слоя.
[01:18:38.200 --> 01:18:40.200]  Теперь давайте еще один лишний сделаем.
[01:18:40.200 --> 01:18:42.200]  Давайте ДП н-ый слой посчитаем.
[01:18:50.200 --> 01:18:52.200]  Давайте напишу, что не есть, а могут быть.
[01:18:57.200 --> 01:19:02.200]  Тогда найдем ДП вн для любого v,
[01:19:02.200 --> 01:19:04.200]  по тем же формулам.
[01:19:04.200 --> 01:19:06.200]  То есть просто сделаем на одну итерацию больше
[01:19:06.200 --> 01:19:09.200]  в нашем алгоритме динамики.
[01:19:09.200 --> 01:19:13.200]  Тогда я утверждаю следующее утверждение.
[01:19:13.200 --> 01:19:15.200]  На каждом отрицательном цикле
[01:19:15.200 --> 01:19:18.200]  хотя бы у одной вершины значение ДП уменьшилось.
[01:19:20.200 --> 01:19:25.200]  Формально, если C это цикл отрицательного веса,
[01:19:25.200 --> 01:19:28.200]  отрицательного веса,
[01:19:28.200 --> 01:19:30.200]  достиженный из S,
[01:19:30.200 --> 01:19:35.200]  то хотя бы для какой-то его вершины
[01:19:35.200 --> 01:19:41.200]  ДП вн строго меньше, чем ДП вн-1.
[01:19:45.200 --> 01:19:47.200]  Понятно, что если отрицательных циклов нет,
[01:19:47.200 --> 01:19:50.200]  то последняя вот эта итерация n,
[01:19:50.200 --> 01:19:52.200]  она просто не будет быть в нём.
[01:19:52.200 --> 01:19:54.200]  Но если у нас есть отрицательный цикл,
[01:19:54.200 --> 01:19:56.200]  то если у нас есть отрицательный цикл,
[01:19:56.200 --> 01:19:58.200]  то если у нас есть отрицательный цикл,
[01:19:58.200 --> 01:20:00.200]  то, так говоря, последняя вот эта итерация n,
[01:20:00.200 --> 01:20:02.200]  она абсолютно бесполезна,
[01:20:02.200 --> 01:20:04.200]  потому что мы знаем, что все кратчайшие пути
[01:20:04.200 --> 01:20:06.200]  в отсутствие отрицательных циклов
[01:20:06.200 --> 01:20:08.200]  имеют длину максимум n-1 ребро.
[01:20:08.200 --> 01:20:10.200]  Поэтому, если бы их не было,
[01:20:10.200 --> 01:20:12.200]  то это неравенство нигде бы не достигалось.
[01:20:12.200 --> 01:20:14.200]  Но я утверждаю следующее верное обратное,
[01:20:14.200 --> 01:20:16.200]  что если есть отрицательный цикл,
[01:20:16.200 --> 01:20:18.200]  то на каждом отрицательном цикле
[01:20:18.200 --> 01:20:20.200]  хотя бы одной вершинкой ДП уменьшится.
[01:20:20.200 --> 01:20:22.200]  Доказательства.
[01:20:28.200 --> 01:20:30.200]  От противного.
[01:20:38.200 --> 01:20:40.200]  Пусть есть какой-то отрицательный цикл.
[01:20:42.200 --> 01:20:44.200]  С.
[01:20:44.200 --> 01:20:46.200]  Я нарисую все его ребра.
[01:20:50.200 --> 01:20:52.200]  Пусть c1, c2 и так далее, ck,
[01:20:52.200 --> 01:20:54.200]  это их...
[01:20:54.200 --> 01:20:56.200]  Давайте не ck, а c, какой-нибудь l.
[01:20:56.200 --> 01:20:58.200]  Это их стоимости.
[01:20:58.200 --> 01:21:00.200]  Пусть есть отрицательный цикл
[01:21:00.200 --> 01:21:02.200]  с стоимостью ребер c и t.
[01:21:02.200 --> 01:21:04.200]  Тогда сумма c и t
[01:21:04.200 --> 01:21:06.200]  поит от 1 до l меньше 0.
[01:21:06.200 --> 01:21:08.200]  Это условие того, что он у отрицательного веса.
[01:21:10.200 --> 01:21:12.200]  Предположим, что вот это неверно.
[01:21:12.200 --> 01:21:14.200]  Что ни для какого v
[01:21:14.200 --> 01:21:16.200]  у меня не будет здесь неравенства.
[01:21:18.200 --> 01:21:20.200]  То есть, наоборот, для любого v
[01:21:20.200 --> 01:21:22.200]  из c
[01:21:22.200 --> 01:21:24.200]  верное равенство на самом деле.
[01:21:26.200 --> 01:21:28.200]  Здесь не может быть значка
[01:21:28.200 --> 01:21:30.200]  больше,
[01:21:30.200 --> 01:21:32.200]  потому что когда я считаю n-й слой
[01:21:32.200 --> 01:21:34.200]  через n-1, я в частности там сохраняю
[01:21:34.200 --> 01:21:36.200]  старое значение и пытаюсь его еще
[01:21:36.200 --> 01:21:38.200]  релаксировать чем-то поменьше.
[01:21:38.200 --> 01:21:40.200]  Поэтому здесь значка больше быть не может,
[01:21:40.200 --> 01:21:42.200]  потому что для пересчета этого я всегда беру
[01:21:42.200 --> 01:21:44.200]  минимум из вот этого и чего-то там еще.
[01:21:44.200 --> 01:21:46.200]  Поэтому здесь может быть только равенство.
[01:21:46.200 --> 01:21:48.200]  Значка больше быть не может.
[01:21:48.200 --> 01:21:50.200]  Но главное, что из этого следует.
[01:21:50.200 --> 01:21:52.200]  То есть,
[01:21:52.200 --> 01:21:54.200]  так, мне, видимо,
[01:21:54.200 --> 01:21:56.200]  еще нужно будет вершины занумировать.
[01:21:56.200 --> 01:21:58.200]  Пусть это будет v1, v2, v3
[01:21:58.200 --> 01:22:00.200]  и так далее vl.
[01:22:00.200 --> 01:22:02.200]  Главное, что из этого следует.
[01:22:06.200 --> 01:22:08.200]  Сейчас, секунду.
[01:22:20.200 --> 01:22:22.200]  Так, момент, сейчас я немножко
[01:22:22.200 --> 01:22:24.200]  повдупляю, значит, здесь будет, видимо,
[01:22:24.200 --> 01:22:26.200]  vi
[01:22:26.200 --> 01:22:28.200]  плюс один, я хочу написать, здесь будет
[01:22:28.200 --> 01:22:30.200]  dp vi,
[01:22:30.200 --> 01:22:32.200]  это n-1,
[01:22:32.200 --> 01:22:34.200]  плюс ci, вот что я хочу написать.
[01:22:36.200 --> 01:22:38.200]  Вот.
[01:22:38.200 --> 01:22:40.200]  Для каждого i будет выполнено
[01:22:40.200 --> 01:22:42.200]  вот такое вот неравенство.
[01:22:42.200 --> 01:22:44.200]  Почему?
[01:22:44.200 --> 01:22:46.200]  Потому что, смотрите, как у меня считается
[01:22:46.200 --> 01:22:48.200]  dp vi плюс 1,
[01:22:48.200 --> 01:22:50.200]  я рассматриваю
[01:22:50.200 --> 01:22:52.200]  все входящие в нее ребра.
[01:22:52.200 --> 01:22:54.200]  В частности, я рассмотрю вот это ребро из vi,
[01:22:54.200 --> 01:22:56.200]  vi плюс первое, веса ci.
[01:22:56.200 --> 01:22:58.200]  И поскольку я из них всех беру минимум,
[01:22:58.200 --> 01:23:00.200]  то значит, в частности, эта штука меньше
[01:23:00.200 --> 01:23:02.200]  и равна, чем dp vi,
[01:23:02.200 --> 01:23:04.200]  vi t, n-1, то есть дойти сюда,
[01:23:04.200 --> 01:23:06.200]  зайти на одно ребро, и потом приклеить
[01:23:06.200 --> 01:23:08.200]  вот это последнее ребро, веса ci.
[01:23:08.200 --> 01:23:10.200]  Ну, это просто из нашей динамики,
[01:23:10.200 --> 01:23:12.200]  что, что я делаю,
[01:23:12.200 --> 01:23:14.200]  я делаю,
[01:23:14.200 --> 01:23:16.200]  я делаю, я делаю,
[01:23:16.200 --> 01:23:18.200]  ну, это просто из нашей динамики,
[01:23:18.200 --> 01:23:20.200]  что, чтобы посчитать эту штуку, я в частности
[01:23:20.200 --> 01:23:22.200]  рассматриваю такой путь.
[01:23:22.200 --> 01:23:24.200]  Хорошо. Теперь давайте я
[01:23:24.200 --> 01:23:26.200]  сложу все эти неравенства по всем i.
[01:23:28.200 --> 01:23:30.200]  Сложим эти неравенства
[01:23:30.200 --> 01:23:32.200]  по всем i.
[01:23:34.200 --> 01:23:36.200]  Ну, слева получится
[01:23:36.200 --> 01:23:38.200]  перестановка всех вершин,
[01:23:38.200 --> 01:23:40.200]  v2, v3, v4 и так далее, v1,
[01:23:40.200 --> 01:23:42.200]  т.е. это будет просто сумма
[01:23:42.200 --> 01:23:44.200]  по всем вершинам из цикла
[01:23:44.200 --> 01:23:46.200]  dp, vt, n.
[01:23:48.200 --> 01:23:50.200]  Здесь тоже будет сумма
[01:23:50.200 --> 01:23:52.200]  по всем вершинам из цикла, v1, v2,
[01:23:52.200 --> 01:23:54.200]  и так далее vlt,
[01:23:54.200 --> 01:23:56.200]  т.е. сумма будет та же самая,
[01:23:56.200 --> 01:23:58.200]  ну, только как бы со сдвигом, да,
[01:23:58.200 --> 01:24:00.200]  порядок слагами поменяется,
[01:24:00.200 --> 01:24:02.200]  dp, v, n-1.
[01:24:04.200 --> 01:24:06.200]  Так, ну и остается сумма весов всех ребер.
[01:24:06.200 --> 01:24:08.200]  Сумма по житце житая.
[01:24:10.200 --> 01:24:12.200]  Ага, время кончилось.
[01:24:14.200 --> 01:24:16.200]  Вот. Ну и все.
[01:24:16.200 --> 01:24:18.200]  А вот эти штуки тогда сокращаются
[01:24:18.200 --> 01:24:20.200]  и получается, что сумма весов у меня
[01:24:20.200 --> 01:24:22.200]  больше на нуля, противоречие.
[01:24:22.200 --> 01:24:24.200]  Ну, предположим, что цикл отрицательный.
[01:24:26.200 --> 01:24:28.200]  Получилось, неравенство
[01:24:28.200 --> 01:24:30.200]  с той штукой больше равна нуля,
[01:24:30.200 --> 01:24:32.200]  а исходно предположим, что он отрицательный.
[01:24:32.200 --> 01:24:34.200]  Так, давай тогда на этом
[01:24:34.200 --> 01:24:36.200]  закончим, последнюю мысль я скажу в следующий раз.
[01:24:36.200 --> 01:24:38.200]  Спасибо.
