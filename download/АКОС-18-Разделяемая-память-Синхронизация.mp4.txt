[00:00.000 --> 00:10.000]  Так, значит, мы фиксируем, что мы остаемся в этой аудитории,
[00:10.000 --> 00:12.000]  никуда не переезжаем.
[00:12.000 --> 00:14.000]  Техническое решение, которое будет составить разработчик
[00:14.000 --> 00:16.000]  из проекта, найдено.
[00:16.000 --> 00:20.000]  Так, и тема сегодняшней лекции.
[00:20.000 --> 00:22.000]  У нас она не одна.
[00:22.000 --> 00:23.000]  ЦУП.
[00:23.000 --> 00:27.000]  Во-первых, это один из механизмов межпроцессного взаимодействия
[00:27.000 --> 00:29.000]  под названием разделаемая память.
[00:29.000 --> 00:33.000]  Во-вторых, разные средства, которые есть,
[00:33.000 --> 00:37.000]  используют API для механизмов синхронизации.
[00:37.000 --> 00:46.000]  Итак, по поводу различных механизмов межпроцессного взаимодействия.
[00:46.000 --> 00:51.000]  Вы уже изучили, что такое каналы, вы изучили сокеты.
[00:51.000 --> 00:55.000]  Что плохого в этих средствах коммуникации?
[00:55.000 --> 00:59.000]  С одной стороны, достаточно удобный и универсальный способ.
[00:59.000 --> 01:02.000]  Особенно сокеты, которые масштабируют год-весетий.
[01:02.000 --> 01:05.000]  Но есть определенные недостатки.
[01:05.000 --> 01:10.000]  А именно, что вам нужно много раз вызывать системные вызовы.
[01:10.000 --> 01:11.000]  Рит и Врайд.
[01:11.000 --> 01:13.000]  Ну, либо в случае сокетов, Рик и Сэнд.
[01:13.000 --> 01:17.000]  Для того, чтобы передавать данные.
[01:17.000 --> 01:23.000]  Если вы работаете по сети, это вполне смысл.
[01:23.000 --> 01:26.000]  Другое дело, если у вас есть один и тот же компьютер,
[01:26.000 --> 01:30.000]  и вам нужно организовать взаимодействие разных процессов
[01:30.000 --> 01:32.000]  на одной и той же системе.
[01:32.000 --> 01:36.000]  То такой подход становится слишком дорогостоящим.
[01:36.000 --> 01:41.000]  Потому что каждый системный вызов – это переключение из контекста
[01:41.000 --> 01:44.000]  после контекста игра, и затем наоборот.
[01:44.000 --> 01:48.000]  Плюс, вам нужно держать какой-то буфер,
[01:48.000 --> 01:52.000]  и чем занимается игра, значительную часть времени.
[01:52.000 --> 01:56.000]  Тем, что перекладывать данные из одного буфера,
[01:56.000 --> 01:58.000]  который находится в пространстве пользователя,
[01:58.000 --> 02:01.000]  какой-нибудь другой буфер, который находится в пространстве ядра.
[02:01.000 --> 02:03.000]  Ну и в обратную сторону тоже самое.
[02:03.000 --> 02:06.000]  В общем, достаточно затратные операции,
[02:06.000 --> 02:11.000]  просто для того, чтобы передать данные от одного процесса к другому.
[02:11.000 --> 02:14.000]  Что можно в этой ситуации поделать?
[02:14.000 --> 02:17.000]  Для того, чтобы много раз не вызывать
[02:17.000 --> 02:19.000]  системные вызовы Рит и Врайд.
[02:19.000 --> 02:36.000]  Одно из решений – это использовать системный вызов под названием SendFile.
[02:36.000 --> 02:41.000]  На самом деле используется в проде где-нибудь в серверах.
[02:41.000 --> 02:44.000]  В чем смысл этого системного вызова?
[02:44.000 --> 02:48.000]  Он принимает два уже открытых файловых дискриптора
[02:48.000 --> 02:53.000]  и делегирует на ядро задачу по перекладыванию данных
[02:53.000 --> 02:56.000]  из одного открытого файлового объекта в какой-то другой.
[02:56.000 --> 03:03.000]  И тем самым у нас не вовлекается сама программа.
[03:03.000 --> 03:07.000]  То есть вы вызвали SendFile, и дальше ядро уже,
[03:07.000 --> 03:09.000]  используя свои внутренние буферы,
[03:09.000 --> 03:12.000]  просто перекачивает данные из одного места в другое,
[03:12.000 --> 03:15.000]  и не происходит никакого постоянного копирования
[03:15.000 --> 03:19.000]  из одного буфера в другой.
[03:19.000 --> 03:22.000]  В чем недостаток такого подхода?
[03:22.000 --> 03:28.000]  Недостаток в том, что здесь все-таки нужно передавать данные
[03:28.000 --> 03:30.000]  из одного файла дискриптора в другой.
[03:30.000 --> 03:33.000]  То есть это должны быть какие-то файлы подобные объекты.
[03:33.000 --> 03:39.000]  И самое плохое здесь – это то, что есть разные реализации
[03:39.000 --> 03:43.000]  одного и того же системного вызова в разных операционных системах,
[03:43.000 --> 03:47.000]  которые существуют совершенно независимо друг от друга.
[03:47.000 --> 03:52.000]  И кроме того, что у них различаются сигнатуры,
[03:52.000 --> 03:56.000]  разные заголочные файлы, разные типы параметров
[03:56.000 --> 04:01.000]  и возвращаемые значения для систем BSD и Linux,
[04:01.000 --> 04:03.000]  но это еще полбеды.
[04:03.000 --> 04:08.000]  Другая ключевая проблема в том, что вам может понадобиться
[04:08.000 --> 04:13.000]  не только передавать данные из одного файла дискриптора в другое.
[04:13.000 --> 04:16.000]  Например, sendfile хорошо использовать,
[04:16.000 --> 04:19.000]  когда вы реализуете какой-нибудь файловый сервер
[04:19.000 --> 04:24.000]  и вам нужно выдавать уже существующие файлы без модификации.
[04:24.000 --> 04:27.000]  Если вам нужно как-то данные модифицировать
[04:27.000 --> 04:33.000]  либо передавать, генерировать данные на лету,
[04:33.000 --> 04:36.000]  то такой подход вам уже не подойдет.
[04:36.000 --> 04:39.000]  И что можно еще сделать и вообще,
[04:39.000 --> 04:41.000]  где у нас возникают задачи,
[04:41.000 --> 04:44.000]  когда вам нужно обмениваться большими объемами данных
[04:44.000 --> 04:49.000]  между разными процессами таким образом,
[04:49.000 --> 04:54.000]  что у вас возникает большая нагрузка, например,
[04:54.000 --> 04:57.000]  на процессор только из-за счета передачи данных.
[04:57.000 --> 05:04.000]  И один из примеров, если вы используете Unix Desktop,
[05:04.000 --> 05:09.000]  то любой видео-плеер, неважно на движке M-Player, GZine,
[05:09.000 --> 05:12.000]  ну, чаще всего на M-Player,
[05:12.000 --> 05:17.000]  как вообще у нас устроена жизнь в какой-нибудь Unix машине.
[05:17.000 --> 05:20.000]  Вот вы запускаете Gnome, Unity,
[05:20.000 --> 05:22.000]  Unity уже не популярна, это убунтовская,
[05:22.000 --> 05:26.000]  Gnome, KDE, XFCE, что у вас там еще стоит?
[05:26.000 --> 05:29.000]  Кто пользуется Linux на desktop?
[05:29.000 --> 05:31.000]  Именно как виртуал?
[05:31.000 --> 05:34.000]  У вас есть полноценные системы с графическим интерфейсом.
[05:34.000 --> 05:38.000]  Но Gnome либо KDE, либо MATE, либо XFCE.
[05:38.000 --> 05:42.000]  Скорее всего, у вас там стоит программа,
[05:42.000 --> 05:44.000]  которая называется X-Server.
[05:44.000 --> 05:46.000]  А что такое X-Server?
[05:46.000 --> 05:52.000]  X-Server — это процесс, который имеет доступ к вашей видеокарте,
[05:52.000 --> 05:56.000]  имеет доступ к клавиатуре мыши, тачпеду,
[05:56.000 --> 05:59.000]  и как осуществляется взаимодействие с X-Server.
[05:59.000 --> 06:04.000]  Вы запускаете какой-нибудь процесс, который хочет вывести графику.
[06:04.000 --> 06:07.000]  Он через socket просто стучится к X-Server
[06:07.000 --> 06:10.000]  и просит что-то отрисовать.
[06:10.000 --> 06:15.000]  Но заодно обрабатывает сообщение от X-Server в обратную сторону.
[06:15.000 --> 06:17.000]  Это разные события, которые у нас возникают.
[06:17.000 --> 06:19.000]  Клавиатура, мышь и так далее.
[06:19.000 --> 06:26.000]  Так вот, если мы работаем, просто рисуя какие-то окошки,
[06:26.000 --> 06:31.000]  это вполне небольшая нагрузка.
[06:31.000 --> 06:36.000]  А что произойдет, если мы начнем передавать какой-нибудь большой поток данных?
[06:36.000 --> 06:39.000]  Например, видеопоток из Videoplayer.
[06:39.000 --> 06:42.000]  Будет большая нагрузка и непонятно зачем.
[06:42.000 --> 06:46.000]  Потому что вам нужно передавать данные из одного места в другой.
[06:46.000 --> 06:55.000]  Просто, почему бы не скормить X-Orgo ссылку на уже декодированные видео,
[06:55.000 --> 06:57.000]  чтобы он сам это сделал?
[06:57.000 --> 07:02.000]  И вот здесь как раз используется оптимизация,
[07:02.000 --> 07:05.000]  механизм по названиям разделяемая память.
[07:05.000 --> 07:09.000]  Немного забегая вперед, M-Player это консольный Videoplayer,
[07:09.000 --> 07:12.000]  который можно запустить из командной строки.
[07:12.000 --> 07:17.000]  Там есть разные способы вывода, настраивать все из командной строки.
[07:17.000 --> 07:19.000]  То есть совершенно даже не обязательно иметь X-Server.
[07:19.000 --> 07:24.000]  Может работать даже с настроенным frame-буфером, хотя это медленно.
[07:24.000 --> 07:30.000]  Либо он может выводить данные не используя разделяемая память,
[07:30.000 --> 07:33.000]  и при этом у вас будет большая нагрузка на процессор,
[07:33.000 --> 07:36.000]  и какие-нибудь тяжелые видосики будут просто тормозить.
[07:36.000 --> 07:39.000]  Как у нас осуществляется взаимодействие между разными процессами,
[07:39.000 --> 07:43.000]  и сколько насут процессов для запуска обычного мультика?
[07:43.000 --> 07:48.000]  Это, если что, open-source BigBug Bunny с высоким качеством
[07:48.000 --> 07:51.000]  может скачать бесплатно без регистрации SMS.
[07:51.000 --> 07:57.000]  Так вот, можно управлять любой консольной программой,
[07:57.000 --> 07:59.000]  используя механизм пайпов.
[07:59.000 --> 08:02.000]  То есть есть стандартный поток вывода для того,
[08:02.000 --> 08:07.000]  чтобы имитировать нажатие клавиатуры и читать то, что программа выводит.
[08:07.000 --> 08:11.000]  Для взаимодействия с видео между самим M-Player
[08:11.000 --> 08:18.000]  и уже непосредственно X-Server, который рисует вам картинку на экране,
[08:18.000 --> 08:24.000]  используется механизм разделяемой памяти и как устроен этот механизм.
[08:24.000 --> 08:28.000]  Механизмы разделяемой памяти базируются на том знании,
[08:28.000 --> 08:35.000]  что у нас все современные процессоры имеют Memory Management Unit,
[08:35.000 --> 08:42.000]  но современные имеют в виду десктопные, планшетные, телефонные, серверные и так далее.
[08:42.000 --> 08:47.000]  На самом деле бывают современные процессоры без поддержки Memory Management Unit,
[08:47.000 --> 08:54.000]  и как правило это микроконтроллеры, поскольку модуль достаточно тяжелый.
[08:54.000 --> 08:59.000]  Помните, в конце прошлого семестра, когда вы изучали МАП,
[08:59.000 --> 09:07.000]  такую штуку как трансляция из виртуального адресного пространства в физическое адресное пространство.
[09:07.000 --> 09:14.000]  Для 34-убитной архитектуры у нас есть двухуровневая схема трансляции,
[09:14.000 --> 09:19.000]  для 64-убитной архитектуры это уже четырехуровневая.
[09:19.000 --> 09:25.000]  И тот реальный адрес, тот виртуальный адрес, который используется в вашей программе,
[09:25.000 --> 09:31.000]  затем транслируется процессором совершенно прозрачно в настоящий физический адрес.
[09:31.000 --> 09:38.000]  Он может ссылаться либо на участок физической памяти, либо на какой-то файл.
[09:38.000 --> 09:43.000]  И все адресное пространство делится у нас на странице фиксированного раздела.
[09:43.000 --> 09:49.000]  Соответственно, что у нас является записью, характеризующей одну страницу памяти?
[09:49.000 --> 09:54.000]  20 бит. Это старшая часть физического адреса.
[09:54.000 --> 09:58.000]  Три бита не используются, и там есть еще девять разных флагов,
[09:58.000 --> 10:04.000]  которые используются для того, чтобы обозначить, является ли страница доступна для записи,
[10:04.000 --> 10:09.000]  реально ли она находится в физической памяти, или нужно подгрузить из файла, и так далее.
[10:09.000 --> 10:20.000]  И вот механизмы операционных систем, которые позволяют использовать аппаратные возможности процессора,
[10:20.000 --> 10:25.000]  как раз используются для реализации разделяемой памяти.
[10:25.000 --> 10:35.000]  Причем, опять же исторически, поддержка разделяемой памяти была реализована по-разному в разных UNIX-системах.
[10:35.000 --> 10:40.000]  Проблема о том, что у нас есть разные UNIX-системы, она возникла не вчера,
[10:40.000 --> 10:47.000]  не когда MacOS стал популярным, и не когда Linux стал популярным, и развивались они независимо.
[10:47.000 --> 10:52.000]  Раньше существовала система UNIX-System5 и BSD-UNIX.
[10:52.000 --> 11:01.000]  В UNIX-System5 в 88 году появился целый набор разных технологий, которые поддерживаются, в том числе Linux.
[11:01.000 --> 11:10.000]  Он поддерживается FreeBSD и Mac, но во FreeBSD UNIX-System5 механизмы обычно по умолчанию отключены,
[11:10.000 --> 11:14.000]  и нужно пересобрать ядро, чтобы включить.
[11:14.000 --> 11:21.000]  Что это за механизмы? Это API для разделяемой памяти, симфоров и очереди сообщений.
[11:21.000 --> 11:28.000]  И с другой стороны, отдельная реализация в BSD-UNIX, которая называется MMAP,
[11:28.000 --> 11:34.000]  которая вы уже немножко умеете пользоваться, но немножко про System5.
[11:34.000 --> 11:45.000]  System5 разделяемая память подразумевает, что у вас есть какое-то специальное пространство имен разделяемых сегментов памяти.
[11:45.000 --> 11:52.000]  В Linux есть инструменты, которые отображают, какие у вас сегменты есть.
[11:52.000 --> 11:56.000]  С ними можно даже что-то сделать, имея про ворота.
[11:56.000 --> 12:03.000]  Что здесь нехорошего в этом механизме? Он слишком переусложнен.
[12:03.000 --> 12:12.000]  И есть одна опасность, что если вы создали какую-то область разделяемой памяти, забыли потом удалить,
[12:12.000 --> 12:19.000]  то она останется висеть и просто потребляет ресурсы.
[12:19.000 --> 12:27.000]  Механизм сложный и ненадежный, поэтому используется только legacy софтом.
[12:27.000 --> 12:33.000]  Поэтому тянется поддержка совместимости в современных системах.
[12:33.000 --> 12:39.000]  В случае с BSD все намного проще, потому что есть всего лишь один системный вызов,
[12:39.000 --> 12:45.000]  который позволяет вам выделить какую-то память в виртуальном адресном пространстве.
[12:45.000 --> 12:55.000]  Затем вы эту память можете либо наследовать в начальных процессах, либо строить какому-то файлу.
[12:55.000 --> 12:59.000]  Используйте какой-то файл совместный между процессами.
[12:59.000 --> 13:05.000]  С одной стороны, это достаточно простое решение.
[13:05.000 --> 13:14.000]  Напомню, что память у нас бывает с атрибутами либо разделяемая, то есть она доступна разным процессам.
[13:14.000 --> 13:22.000]  То есть когда у вас одни и те же страницы отображаются на виртуальном адресном пространстве разных процессов.
[13:22.000 --> 13:28.000]  Либо приватная, когда страницы могут отображаться на разные процессы,
[13:28.000 --> 13:34.000]  но при первой же попытке в любом из процессов сделать хоть какую-то запись,
[13:34.000 --> 13:39.000]  просто создается ее копия. Результат с парадигмой copy-on-write.
[13:39.000 --> 13:44.000]  Здесь еще можно указать какой-то файл.
[13:44.000 --> 13:48.000]  Если FD у нас отличный от минусе единицы, что это означает?
[13:48.000 --> 13:55.000]  Это означает, что у вас будет отображение не на область физической памяти, а на некоторые файловые системы.
[13:55.000 --> 14:03.000]  В чем ключевая проблема, если вы используете анонимное отображение, то есть без привязки к файлу?
[14:03.000 --> 14:07.000]  У вас взаимодействовать могут только родственные процессы.
[14:07.000 --> 14:15.000]  Если у вас процессы не родственные, то просто взять и подключиться, залезть в память другого процесса, вы никак не сможете.
[14:15.000 --> 14:24.000]  Для того, чтобы можно было это сделать, нужно как-то уметь анонсировать имя, которому другие процессы смогут дальше подключаться.
[14:24.000 --> 14:32.000]  Этот подход используется в механизме POSIX shared memory. Каким образом это делается?
[14:32.000 --> 14:37.000]  Вы просто создаете обычный файл, не важно, где он лежит.
[14:37.000 --> 14:43.000]  Главное, чтобы у него были права на доступ. Необходимо вам либо чтение, либо запись.
[14:43.000 --> 14:47.000]  У другого процесса, который хочет с вами общаться.
[14:47.000 --> 14:52.000]  Дальше вы делаете файл не нулевого размера.
[14:52.000 --> 14:58.000]  Это можно сделать, например, с помощью системы вызова truncate, либо ftruncate.
[14:58.000 --> 15:10.000]  После этого скармливаете файлик уже нашему системе вызову mmap, который приотачивает его содержимое виртуальное адресное пространство нашего процесса.
[15:10.000 --> 15:16.000]  Этот файл теперь можно использовать для межпроцессного взаимодействия очень быстро.
[15:16.000 --> 15:27.000]  Использование разделяемой памяти – это самый быстрый способ межпроцессного взаимодействия, который ядро вообще никак при этом не вовлекает.
[15:27.000 --> 15:30.000]  Какие здесь возникают проблемы?
[15:30.000 --> 15:42.000]  Тут в какой-то момент вам файл станет не нужен, хотя бы по той причине, что взаимодействие закончилось, процессы у вас могут завершиться.
[15:42.000 --> 15:46.000]  И кто этот файл должен удалить?
[15:46.000 --> 15:52.000]  Очевидно, какой-то последний процесс, который его использовал, должен файл удалить.
[15:52.000 --> 15:56.000]  Тут, кстати, h5, не close, а...
[15:56.000 --> 16:05.000]  У вас остается файл, который болтается, он доступен, просто какой-то фантом.
[16:05.000 --> 16:11.000]  Но если у вас процесс, который должен удалять, вдруг сломался, что произойдет?
[16:11.000 --> 16:17.000]  Будет просто болтаться лишний файл, занимать место на диске, что не очень хорошо.
[16:17.000 --> 16:20.000]  Как с этим можно бороться?
[16:20.000 --> 16:23.000]  Совсем это пооборот никак невозможно.
[16:23.000 --> 16:31.000]  Но если вы периодически компьютер хотя бы перезагружаете, либо вы запускаете какие-то контейнеры,
[16:31.000 --> 16:34.000]  что такое слово, докер, вы должны знать,
[16:34.000 --> 16:38.000]  соответственно, контейнеры могут монтировать свою файловую систему,
[16:38.000 --> 16:41.000]  и есть разные типы файловых систем.
[16:41.000 --> 16:45.000]  Одна из них предназначена как раз для временных файлов.
[16:45.000 --> 16:51.000]  Собирается на tmpfs, с этой файловой системой не связаны никакие дисковые устройства,
[16:51.000 --> 16:56.000]  все ее содержимое хранится в физической памяти.
[16:56.000 --> 17:03.000]  Соответственно, все, что находилось в этой файловой системе в момент ее отмонтирования,
[17:03.000 --> 17:08.000]  отмонтирование у нас может происходить либо при перезагрузке и выключении компьютера,
[17:08.000 --> 17:15.000]  либо если вы завершаете работу какой-нибудь докер контейнеров,
[17:15.000 --> 17:19.000]  который имеет свою обособленную файловую систему,
[17:19.000 --> 17:24.000]  то, естественно, он тоже отмонтирует свою внутреннюю файловую систему tmpfs.
[17:24.000 --> 17:27.000]  И все данные у вас пропадают.
[17:27.000 --> 17:32.000]  Исходно эта файловая система имеет некоторый размер, указываемый при ремонтировании,
[17:32.000 --> 17:35.000]  но может быть легко на лету изменен.
[17:35.000 --> 17:40.000]  И реально в памяти он занимает ровно столько места, сколько занимают файлы,
[17:40.000 --> 17:45.000]  которые в этой файловой системе лежат.
[17:45.000 --> 17:48.000]  Если у вас файлов нет, почти ничего.
[17:48.000 --> 17:52.000]  Если много, значит, или файлы большие, значит, занимает места много.
[17:52.000 --> 17:59.000]  Если у вас очень много файлов, либо они тяжелые в файловой системе tmpfs,
[17:59.000 --> 18:07.000]  то происходит то же самое, что при ситуации нехватки памяти они просто сбрасываются в swap-раздел.
[18:07.000 --> 18:16.000]  Какие вообще в типичной линукс-системе могут быть разделы tmpfs?
[18:16.000 --> 18:24.000]  С помощью команды mount можно вывести список всех примонтированных файловых систем.
[18:24.000 --> 18:28.000]  Отдельная строка – это отдельная файловая система.
[18:28.000 --> 18:38.000]  На современной системе systemd тут таких записей будет очень много под линукс,
[18:38.000 --> 18:45.000]  потому что очень много в линукс делается через виртуальный файловый систем.
[18:45.000 --> 18:54.000]  Чтобы из этого мусора извлечь что-то похожее на tmpfs, мы можем воспользоваться
[18:54.000 --> 19:05.000]  утилитой grep, что у нас является в произвольной запущенной файловой системе, временными файловой системе.
[19:05.000 --> 19:15.000]  Возможно, если вы ставили на настоящий компьютер, а не виртуальную машину, это будет slash tmp.
[19:15.000 --> 19:30.000]  Файлы системы slash run, куда все запущенные сервисы запихивают информацию, например,
[19:30.000 --> 19:35.000]  о том, какой у них есть процесс ID в виде обычных файлов.
[19:35.000 --> 19:46.000]  Run log – это катал, в который обычно все запущенные фоновые сервисы засовывают лог-файлы.
[19:46.000 --> 19:55.000]  Run user, дальше user ID. Создается уже при графическом входе в систему, если у вас там где-нибудь болтается xorg,
[19:55.000 --> 19:59.000]  менеджер сеансов, создается уже через systemd.
[19:59.000 --> 20:05.000]  Есть еще одна файловая система, которая подмонтирована к slash dev slash shm.
[20:05.000 --> 20:12.000]  Сокращение shm означает shared memory. Это в линуксе некоторая файловая система,
[20:12.000 --> 20:18.000]  которая используется для хранения сегментов разделяемой памяти.
[20:18.000 --> 20:28.000]  Как работать с этими сегментами разделяемой памяти?
[20:28.000 --> 20:36.000]  В некоторых системах есть системный вызов, в некоторых системах – библиотечная функция.
[20:36.000 --> 20:45.000]  Называется штука shm open, которая имеет все те же самые параметры, что и обычный системный вызов open,
[20:45.000 --> 20:53.000]  то есть имя файла, флаги открытия, чтение, запись, чтение плюс, запись append и так далее, плюс флаг creat.
[20:53.000 --> 20:59.000]  И соответственно, если указан флаг creat, то нужно указывать обязательный режим создания файла.
[20:59.000 --> 21:04.000]  Прямо точная копия системного вызова open. В чем разница?
[21:04.000 --> 21:13.000]  shm open открывает файловый дескриптор, который находится где-то внутри файловой системы dev shm.
[21:13.000 --> 21:21.000]  Причем в линукс что такое shm open? Это самая обычная простая дурацкая функция, которая что делает?
[21:21.000 --> 21:27.000]  Она составляет полное имя файла, приписывает просто к названию slash dev slash,
[21:27.000 --> 21:33.000]  и shm вызывает обычный системный вызов open. Все, больше эта функция ничего не делает.
[21:33.000 --> 21:49.000]  А вот в системах FreeBSD, Mac OS и других BSD-системах реализация разделяемых сегментов памяти сделана в стиле System5,
[21:49.000 --> 21:54.000]  то есть это ортогональная совершенно файловая система пространства имен.
[21:54.000 --> 22:00.000]  То есть у каждого разделяемого сегмента есть свое имя, которое никак не связано с файловой системой.
[22:00.000 --> 22:06.000]  И тут возникают некоторые ограничения, которые нужно соблюдать в том случае,
[22:06.000 --> 22:15.000]  если вы хотите сделать так, чтобы ваш код был портируем на любую систему.
[22:15.000 --> 22:24.000]  Итак, теперь конкретный пример. Вот простенькая программа, которая что делает?
[22:24.000 --> 22:31.000]  Она просто создает разделяемый сегмент памяти, но никак его не использует.
[22:31.000 --> 22:39.000]  Одна и та же программа, запущенная просто с shm open, дальше можно убедиться, что что-то создано,
[22:39.000 --> 22:44.000]  нажать кнопочку ввод и затем удалить используемый сегмент.
[22:44.000 --> 22:54.000]  Итак, первое, что нужно сделать, это скомпилировать нашу программу.
[22:54.000 --> 23:05.000]  Для компиляции под Linux нам требуется еще дополнительно указать библиотеку LRT.
[23:05.000 --> 23:10.000]  На самом деле это часть стандартной сибиблиотеки, но просто в Linux есть фрагментация.
[23:10.000 --> 23:15.000]  Точно так же, как с POSIX threads. Все, скомпилировался.
[23:15.000 --> 23:22.000]  Если мы хотим скомпилировать тот же самый код один в один под FreeBSD или под Mac,
[23:22.000 --> 23:28.000]  то ни с чем больше линковать не нужно.
[23:28.000 --> 23:36.000]  Теперь запустим какой-нибудь разделяемый фрагмент и укажем имя файла в виде A, B, C, D, E, F.
[23:36.000 --> 23:42.000]  Все, создан файл, который мы можем наблюдать.
[23:42.000 --> 23:49.000]  Файлы системе немножко на проекторе не видно.
[23:58.000 --> 24:02.000]  Ls slash dev slash shm.
[24:02.000 --> 24:06.000]  И вот этот файл есть. Это просто самый обычный файл.
[24:06.000 --> 24:08.000]  Никакой магии тут нет.
[24:08.000 --> 24:12.000]  Какие у нас здесь возникают естественные ограничения?
[24:12.000 --> 24:25.000]  Если мы захотим сделать какое-нибудь имя вида A, B, C, D, E, F, что у нас произойдет?
[24:25.000 --> 24:31.000]  Зависит от того, существует ли у нас каталог A, B, C в этом D, F, C, D или не существует.
[24:31.000 --> 24:36.000]  Если вы ручками создадите подкаталог, ну пожалуйста, все хорошо, все замечательно.
[24:36.000 --> 24:40.000]  Если нет, получаем ошибку.
[24:40.000 --> 24:47.000]  Если чем Open вам возвращает минус один, почему нельзя создать файл с таким именем?
[24:47.000 --> 24:52.000]  Потому что здесь подразумевается полный путь, содержащий подкаталог.
[24:52.000 --> 24:57.000]  Если вы вручную его создадите, ну пожалуйста, если нет, значит не судьба.
[24:57.000 --> 25:03.000]  И под FreeBSD Mac OS.
[25:03.000 --> 25:07.000]  Итак, shm, A, B, C, D, E, F.
[25:07.000 --> 25:14.000]  Создали, разделяемся в имя памяти, но вы его нигде не найдете в файловой системе.
[25:14.000 --> 25:18.000]  Давайте мы перейдем куда-нибудь в корень.
[25:18.000 --> 25:23.000]  Посмотрим, что у нас есть файловые системы, slashdef.
[25:23.000 --> 25:27.000]  Тут даже никакого подкаталога shm нет.
[25:27.000 --> 25:32.000]  Кстати, раз уж я заговорил про монтирование и про разные файловые системы,
[25:32.000 --> 25:37.000]  давайте посмотрим, может где-нибудь procfs, tmpfs у нас болтается.
[25:37.000 --> 25:43.000]  Количество файловых систем в BSD обычно меньше, чем в Linux.
[25:43.000 --> 25:48.000]  И нет здесь никакого slashdef, slashshm.
[25:48.000 --> 25:55.000]  И вообще механизм разделяемой памяти у нас, это просто артагонально что-то файловой системе.
[25:55.000 --> 25:58.000]  Как можно получить доступ к этому файлу?
[25:58.000 --> 26:05.000]  Сделать еще один процесс, который откроет тот же самый файл и сможет с ним работать,
[26:05.000 --> 26:08.000]  зная какое-то определенное имя.
[26:08.000 --> 26:13.000]  Зато здесь нет ограничений, связанных с каталогами.
[26:13.000 --> 26:19.000]  Я могу как угодно обозвать наш файл, в пределах разумной длины, естественно.
[26:19.000 --> 26:22.000]  И все хорошо, все замечательно.
[26:22.000 --> 26:26.000]  Будет создан разделяемый сегмент с каким-нибудь диким именем.
[26:26.000 --> 26:33.000]  Даже если оно не является валидным именем файла, ничего плохого с этим не произойдет.
[26:33.000 --> 26:40.000]  Еще одно ограничение, которое есть в системе FreeBSD, надо вначале slash писать.
[26:40.000 --> 26:47.000]  Под Mac это работает и так, а по FreeBSD уже не будет.
[26:47.000 --> 26:51.000]  У нас есть разные ограничения на то, какие есть имена.
[26:51.000 --> 26:57.000]  Но если вы просто аккуратно пишите код и соблюдаете эти ограничения,
[26:57.000 --> 27:02.000]  то у вас будет все работать одинаково на разных платформах.
[27:02.000 --> 27:11.000]  Как можно наблюдать за тем, какие у вас есть открытый разделяемый сегмент?
[27:11.000 --> 27:14.000]  Под Linux можно просто посмотреть содержимое, где в S&Chem.
[27:14.000 --> 27:19.000]  Под FreeBSD есть отдельная команда POSIX S&Chem Control.
[27:19.000 --> 27:23.000]  Под MacS такого нет.
[27:23.000 --> 27:28.000]  Можно, конечно, попробовать перекомпилировать FreeBSD open-source toolzoo,
[27:28.000 --> 27:31.000]  но работать она будет не совсем полноценно.
[27:31.000 --> 27:36.000]  И если вы попытаетесь нагуглить что-то,
[27:36.000 --> 27:43.000]  как все-таки посмотреть под FreeBSD или MacOS список открытых разделяемых страниц,
[27:43.000 --> 27:49.000]  почему-то на стык overflow вылазит использование утилиты IPC-S.
[27:49.000 --> 27:56.000]  Это к тому, что не нужно верить всему, что пишут в Гугле и на стык overflow,
[27:56.000 --> 28:04.000]  потому что IPC-Toolz предназначены для System5 разделяемых сегментов.
[28:04.000 --> 28:08.000]  POSIX это совершенно не то.
[28:08.000 --> 28:13.000]  Вторая тема на сегодня.
[28:13.000 --> 28:16.000]  Здесь все достаточно просто.
[28:16.000 --> 28:20.000]  Что такое MAP? Вы уже использовали это, все знаете.
[28:20.000 --> 28:24.000]  Поэтому проблем у вас при решении задач семинарских возникнуть не должно.
[28:24.000 --> 28:29.000]  А вот проблема гонки данных. Что это такое?
[28:29.000 --> 28:35.000]  Это то, ради чего у вас целый семестровый курс теории, практики и многопроточной синхронизации.
[28:35.000 --> 28:42.000]  На окусе мы рассмотрим только то, что относится к межпроцессовому взаимодействию.
[28:42.000 --> 28:48.000]  Коротко напомню о том, что такое проблема гонки данных и когда она возникает.
[28:48.000 --> 28:56.000]  Есть у вас однопроцессорная система, на которой запущена куча программ.
[28:56.000 --> 29:00.000]  Все-таки операционная система у нас уже много лет как многозадачная.
[29:00.000 --> 29:04.000]  Эти программы могут в свою очередь запускать несколько трэдов.
[29:04.000 --> 29:09.000]  И если у вас процессор одноядерный, не знаю, где вы сейчас найдете, но допустим,
[29:09.000 --> 29:15.000]  то все хорошо, все замечательно. Они будут просто работать не одновременно,
[29:15.000 --> 29:21.000]  а последовательно переключаясь между собой по планировщику заданий.
[29:21.000 --> 29:27.000]  Никаких проблем возникать не будет до тех пор, пока у вас не появится хотя бы двухпроцессорная система или двухядерная.
[29:27.000 --> 29:33.000]  Если у вас система стала уже двухядерной, то возникает настоящая многозадачность,
[29:33.000 --> 29:37.000]  когда у вас одновременно работает больше одной задачи.
[29:37.000 --> 29:45.000]  И если у вас возникает больше одной задачи, то они начинают конкурировать за одни и те же ресурсы,
[29:45.000 --> 29:53.000]  в частности за оперативную память, в том числе в пределах одного процесса,
[29:53.000 --> 29:56.000]  в пределах одного виртуального адресного пространства.
[29:56.000 --> 29:59.000]  И каким эффектом это может производить?
[29:59.000 --> 30:05.000]  Один, допустим, поток либо процесс что-то пишет в общую память,
[30:05.000 --> 30:13.000]  в это время другой процесс либо поток пишет туда же и получаем какие-то невалидные данные,
[30:13.000 --> 30:17.000]  потому что один процесс мог записать часть, а другую-другую часть,
[30:17.000 --> 30:26.000]  и вы можете получить ситуацию, что даже у вас не от первого процесса, не от второго процесса данные, а что-то перемешанное.
[30:26.000 --> 30:34.000]  И вот эта проблема называется проблема гонки данных, как с ней бороться.
[30:34.000 --> 30:42.000]  У вас могут несколько процессов разделять один и тот же сегмент памяти,
[30:42.000 --> 30:52.000]  и что можно сделать для того, чтобы процессом между собой общаться и как-то говорить, что товарищ,
[30:52.000 --> 30:55.000]  вот я сейчас записываю данные, пожалуйста, не трогай.
[30:55.000 --> 31:00.000]  Можно использовать какие-то дополнительные механизмы межпроцессного взаимодействия,
[31:00.000 --> 31:08.000]  например, пайпы, сокеты, но это получается переусложнение нашего взаимодействия,
[31:08.000 --> 31:12.000]  когда у нас и так уже есть разделяемые страницы памяти.
[31:12.000 --> 31:20.000]  Можно использовать сигналы, но сигналы это очень плохой ненадежный способ. Почему?
[31:20.000 --> 31:28.000]  Даже для передачи простой информации, например, о том, что нам нужно предотвратить, заблокировать какой-то участок памяти.
[31:28.000 --> 31:39.000]  Даже дело не в том, что их ограниченное количество, потому что у нас не гарантируется доставка сигналов всех, которые вы отправите.
[31:39.000 --> 31:51.000]  Напомню, что обычный UNIX сигналы у нас проставляют бит в маске сигналов, ожидающих доставку,
[31:51.000 --> 31:59.000]  и если вы отправили несколько сигналов, которые процесс не успел обработать, то обработан будет только один сигнал.
[31:59.000 --> 32:04.000]  И для задач синхронизации это совершенно неприемлемо.
[32:04.000 --> 32:11.000]  Есть, конечно, сигналы реального времени, но, опять же, они поддерживаются не всем операционными системами.
[32:11.000 --> 32:20.000]  В Linux хорошо, а в macOS уже грустно. Можно, конечно, и каналы использовать, но тоже так себе решение.
[32:20.000 --> 32:31.000]  И универсальным решением для межпроцессной синхронизации, и не только межпроцессной синхронизации, но также межпоточной, является симафор.
[32:31.000 --> 32:38.000]  Что такое симафор? Это просто обычный счетчик, целочисленный, без знаков.
[32:38.000 --> 32:45.000]  Операции это увеличить значение счетчика либо уменьшить.
[32:45.000 --> 32:54.000]  Причем если у вас число априори должно быть без знаковым, целочисленным, что значит уменьшить счетчик?
[32:54.000 --> 33:03.000]  Это значит, что вы можете либо его уменьшить, если оно строго больше нуля, либо вы ничего не можете с ним делать, потому что число не бывает отрицательным.
[33:03.000 --> 33:13.000]  И вот в ситуации, когда нельзя ничего с этим числом сделать, у вас текущий поток просто приостанавливается до тех пор, пока это не станет возможным.
[33:13.000 --> 33:17.000]  То есть пока кто-нибудь другой не увеличит этот счетчик.
[33:18.000 --> 33:22.000]  И в чем особенность симафоров? Казалось бы, просто обычное целое число.
[33:22.000 --> 33:35.000]  Почему бы не взять, не использовать обычное целочисленное значение, просто реализовать функции, которые одна делает инкремент, другая делает попытку декремента с возможным ожиданием.
[33:35.000 --> 33:42.000]  Главная особенность симафора в том, что все операции как инкремента, так и декременты являются атомарными.
[33:42.000 --> 33:55.000]  Атомарными это значит, что в процессе выполнения какой-нибудь инкремента, например, у вас никто посередине в клинице не сможет, и не сможет это значение из другого потока другим ядром как-то изменить.
[33:55.000 --> 34:01.000]  Вот что означает вообще атомарность? Атомарность бывает в разных уровнях.
[34:01.000 --> 34:24.000]  Например, с точки зрения сигналов, атомарность гарантируется тем, что вы выполняете какие-то инструкции, в это время прилетает сигнал, вы прерваны, и вы можете сделать запись либо чтение атомарно, только что-то, что заведомо умещается в размер машинного слова.
[34:24.000 --> 34:33.000]  Потому что здесь прервание может возникнуть только аппаратный, значит, процессор не выполнил одну из инструкций.
[34:33.000 --> 34:53.000]  И обычно с точки зрения обработки сигналов либо переключения контекста процессов у вас достаточно условия, что данные у вас не больше, чем размер машинного слова, и обязательно является целочисленным, то есть использует регистр общего назначения.
[34:53.000 --> 35:05.000]  Вот тип данных сигнала к томикте. На самом деле для большинства современных систем это обычный type-dev на int, даже несмотря на то, что называется атомарным.
[35:05.000 --> 35:12.000]  Но такой тип данных не подходит, он не является атомарным с точки зрения многопоточности.
[35:12.000 --> 35:31.000]  Если у вас есть два конкурирующих потока, которые выполняются на разных ядрах процессора, то один из процессоров может быть приостановлен планировщиком заданий, либо выполнять какую-то задачу, и в это время другое ядро имеет полное право вытворять все, что угодно.
[35:31.000 --> 35:36.000]  То есть использование такого типа данных вам еще ничего не гарантирует.
[35:36.000 --> 35:43.000]  И как можно все-таки добиться того, чтобы у вас не было никакой проблемы в гонке данных?
[35:43.000 --> 35:57.000]  Самые распространенные решения это использовать какие-то защитные механизмы для того, чтобы защищать разделяемые участки данных.
[35:57.000 --> 36:02.000]  А в том числе достаточно крупные, которые заведомо больше, чем размер машинного слова.
[36:02.000 --> 36:17.000]  Некоторые из них называются мютексы. Это простой объект, который может быть либо в разблокированном состоянии, либо семафоры, которые являются счетчиками.
[36:18.000 --> 36:29.000]  Итак, семафоры. Это с точки зрения API просто специальный тип данных, над которым предусмотрены операции.
[36:29.000 --> 36:39.000]  Post – это инкремент семафора. Очень простая операция, она просто увеличивает счетчик и все, достаточно быстро работает.
[36:39.000 --> 36:44.000]  Всемвейт – это попытка уменьшить значение семафора.
[36:44.000 --> 36:55.000]  Если его значение у нас строго больше, чем ноль, то семвейт моментально завершается, при этом значение счетчика у вас уменьшается.
[36:55.000 --> 37:02.000]  Если два параллельно работающих потока пытаются одновременно вызвать семвейт, кому-то из них повезет, кому-то не повезет.
[37:02.000 --> 37:14.000]  А может быть и так, что повезет обоим, потому что, в отличие от мютексов, семафоры могут иметь значение не только 0,1, а произвольное без знаков.
[37:14.000 --> 37:23.000]  Если вы изначально семафоры инициализировали значением 10, а потоков у вас всего 2, то они никогда друг другу мешать не будут.
[37:23.000 --> 37:34.000]  Кстати, семафоры могут использоваться в том числе для того, чтобы организовать взаимодействие барьеров между разными потоками или разными процессами.
[37:34.000 --> 37:38.000]  Какие бывают у нас семафоры?
[37:38.000 --> 37:46.000]  Семафоры бывают неименоваными. Что есть общего у именовых и неименовых?
[37:46.000 --> 37:54.000]  У них есть некоторое начальное значение, которое не обязательно бывает 0, или 1.
[37:54.000 --> 38:08.000]  Семафоры неименованы, это те, которые могут быть использованы только родственными процессами, либо могут быть использованы в пределах одного процесса, но разными тредами.
[38:08.000 --> 38:15.000]  Именованные семафоры это по сути те же самые сегменты разделяемой памяти.
[38:15.000 --> 38:31.000]  В линуксе реализация семопон это просто открыть разделяемый сегмент памяти, с помощью семопон дальше создать ммапом одну страничку, в которой помещается семафор, и в общем-то все.
[38:31.000 --> 38:35.000]  Ничем больше не отличается.
[38:35.000 --> 38:42.000]  Есть еще такая штука, как мютекс, у которого есть две операции заблокировать, разблокировать.
[38:42.000 --> 38:51.000]  В чем отличие мютекса от семафоров? В общем случае мютекс имеет только два состояния, хотя на самом деле это не совсем так.
[38:51.000 --> 38:57.000]  Вам рассказывали, что такое рекурсивные мютексы.
[38:57.000 --> 39:12.000]  На самом деле мютексы бывают не только с двумя состояниями, есть такое понятие, как рекурсивный мютекс, когда один и тот же тред может несколько раз захватывать мютекс, и у него это будет получаться.
[39:12.000 --> 39:26.000]  Зачем это бывает нужно? Например, если у вас используется какая-то переменная, которую нужно защищать от других потоков, и эта переменная может быть использована в разных местах кода,
[39:26.000 --> 39:37.000]  и понаставлены везде какие-нибудь проверки, мютекс локи. Если мютекс является рекурсивным, то соответственно вы можете его из одного треда захватить несколько раз.
[39:37.000 --> 39:49.000]  Для того, чтобы его освободить, вы должны его несколько раз освободить. При этом другой тред захватить рекурсивный мютекс не может, если он захвачен уже одним из тредов.
[39:49.000 --> 39:58.000]  У мютексов есть одно существенное ограничение. Кто захватил мютекс, тот и обязан его освободить.
[39:58.000 --> 40:09.000]  Если вы захватили мютекс в одном треде и пытаетесь освободить из другого треда, то ничего у вас не выйдет. Это будет undefined behavior.
[40:09.000 --> 40:19.000]  В некоторых случаях программа у вас грохнется. Иногда она не грохается, но можно сделать так, чтобы она принудительно грохалась.
[40:19.000 --> 40:30.000]  Второе существенное ограничение, почему в курсе о космо мютексы не очень любим, хотя на практике они очень часто используются.
[40:30.000 --> 40:43.000]  Мютексы работают в одном адресном пространстве. Если у вас есть разные треды в одном процессе, мютекс полезная классная штука.
[40:43.000 --> 40:53.000]  Если вы хотите устроить синхронизацию между собой разных процессов, то мютексы уже не подойдут. Единственный способ здесь что-то использовать, это только симафор.
[40:53.000 --> 41:07.000]  Мютексы очень опасная штука. Если вы мютекс захватите и забудете его разблокировать случайно, что у вас произойдет?
[41:07.000 --> 41:19.000]  Да, с большой вероятностью у вас произойдет дедлог, который не всегда воспроизводится случайно. Это трудно воспроизводимые баги, которые трудно отлавливать на практике.
[41:19.000 --> 41:31.000]  Для этого даже существуют специальные отдельные инструменты, чтобы ловить. Всякий Intel Thread Profiler достаточно другой инструмент, не опенсорсный.
[41:31.000 --> 41:43.000]  На C++ есть еще класс по названию LockGuard, который реализован следующим образом. Конструктор захватывает мютекс, деструктор освобождает.
[41:43.000 --> 41:58.000]  Если вы где-то не прописали явное разблокирование мютекса и при этом выходите из какой-то области видимости, где этот мютекс уже не используется, то LockGuard у вас автоматически в деструкторе его освободит.
[41:58.000 --> 42:24.000]  Решает много проблем. Казалось бы, мютекс — это бинарный симафор. Реализовать мютекс можно, сделав обычный симафор с значением 1, но операция Lock — это захват симафора, освобождение, релиз симафора, то есть увеличение счетчика на 1.
[42:24.000 --> 42:36.000]  Но на самом деле мютекс из соображений производительности реализованы через другую конструкцию, которая называется FUTEX.
[42:36.000 --> 42:51.000]  FUTEX работает намного быстрее, чем обычный симафор. В Linux есть стена вызов, которая называется FUTEX, которая как раз используется для манипуляции над FUTEX.
[42:51.000 --> 43:04.000]  У FUTEX есть две основные операции. На самом деле операция чуть больше. Эта операция — ждать, пока кто-нибудь его не разбудит, и операция — разбудить.
[43:04.000 --> 43:17.000]  Что такое FUTEX с точки зрения программного API? Это некоторый системный вызов, для которого даже есть MAN-страница с сишным интерфейсом, как ни странно.
[43:17.000 --> 43:31.000]  То есть вы можете брать MAN, FUTEX, и получите вот такие заголочные файлы, сигнатуру. Но есть одна маленькая приписка в мане.
[43:31.000 --> 43:44.000]  No Gleepsive wrapper for system call. Что это означает? Это означает, что если вы пытаетесь скомпилировать какой-нибудь код с использованием этой функции, с каких-то заголочных файлов, у вас ничего не выйдет.
[43:44.000 --> 43:55.000]  Потому что это фейк. Никого в FUTEX не существует. FUTEX — системный вызов, но предназначенный для внутреннего использования библиотекой POSIX Threads.
[43:55.000 --> 44:11.000]  Вручную его использовать, конечно, можно, если вы просто скопипастите из MAN-а вот это объявление, сделайте свою функцию, которая через функцию syscall будет явным образом делать syscall.
[44:14.000 --> 44:36.000]  А вот в некоторых системах типа FreeBSD, macOS такого системного вызова нет, поскольку там вся реализация взаимодействия между потоками и использованием симафоров, она реализована уже в самом ядре, а не в отдельной библиотеке.
[44:36.000 --> 44:48.000]  То есть в Linux у нас есть один примитив, который реализован в ядре, а дальше все остальные примитивы, это уже надстройки, использующие FUTEX, во FreeBSD, macOS — все у нас находится в ядре.
[44:48.000 --> 45:00.000]  Так, и еще один примитив синхронизации, очень полезный на практике, называется условные перемены. Тоже реализуется через FUTEX.
[45:00.000 --> 45:10.000]  То есть для чего нам нужен FUTEX? FUTEX у нас является базовым кирпичиком для постранения мютексов, условных переменных, симафоров.
[45:10.000 --> 45:23.000]  В свою очередь уже в прикладных применениях, когда вы пишете какой-то реальный софт с нормальной логикой, вы не должны задумываться о том, что вам нужно сделать какой-то спинлок, реализовать.
[45:23.000 --> 45:28.000]  Просто уже берите и пользуйтесь готовым решением. Вот еще одно готовое решение.
[45:28.000 --> 45:40.000]  FUTEX предназначен для того, чтобы защищать какие-то критические секции, чтобы они были одновременно доступны разным тредам.
[45:40.000 --> 45:54.000]  Еще один инструмент — это условная переменная, которая является некоторым барьером. На самом деле, название не очень удачное условная переменная.
[45:54.000 --> 46:04.000]  Это не в том смысле, что переменная, в которой можно записать значение. Нет, это просто некоторый флаг, который может быть либо установлен, либо снят.
[46:04.000 --> 46:13.000]  Разные треды у вас могут ждать, пока возникнет какое-то событие, а другие треды могут сигналить на это событие.
[46:13.000 --> 46:23.000]  Для чего могут использоваться условные переменные? Например, у вас есть какой-то тред, который ожидает данных, тред-потребитель данных.
[46:23.000 --> 46:33.000]  Он ждет, пока какой-то другой тред закончит подготовку данных и скажет о том, что данные готовы, можно их использовать.
[46:33.000 --> 46:42.000]  Вот как это можно организовать? Можно с одной стороны сделать какой-нибудь бульфлаг готовности, который будет доступен обоим тредам.
[46:42.000 --> 46:52.000]  Один тред будет записывать, что флаг готовности, другой его читать. Оба этих флага можно защитить мьютексами, периодически их проверять с определенным интервалом.
[46:52.000 --> 47:01.000]  Но это, во-первых, переусложнение логики, во-вторых, возникает вопрос, с какой периодичностью нужно флаг проверять.
[47:01.000 --> 47:06.000]  Условные переменные как раз это инструмент именно для нотификации.
[47:06.000 --> 47:14.000]  Причем на одну и ту же условные переменные может быть навешано несколько тредов, которые ждут какого-то события.
[47:14.000 --> 47:20.000]  И уведомлять можно либо по одному треды, либо сразу все.
[47:20.000 --> 47:26.000]  Подводим итоги. Что для чего нужно?
[47:26.000 --> 47:34.000]  Если у вас взаимодействие в пределах одного процесса, есть два основных инструмента, которые вы в реальной жизни будете использовать.
[47:34.000 --> 47:41.000]  На самом деле их чуть больше, но в реальной жизни маловероятно, что вы им будете пользоваться.
[47:41.000 --> 47:51.000]  Это мьютексы, которые являются просто замочками для каких-то критических секций, для того чтобы предотвратить гонку данных.
[47:51.000 --> 47:57.000]  И второй из них это условные переменные. Семафоры на самом деле можно использовать тоже.
[47:57.000 --> 48:03.000]  Но возникает вопрос, а зачем, когда у вас есть уже более высокоуровные инструменты.
[48:03.000 --> 48:08.000]  Поэтому на практике они не так часто используются, хотя это тоже возможно.
[48:08.000 --> 48:20.000]  Семафоры удобно использовать в тех задачах, когда у вас есть несколько условий, поскольку этот счетчик целочисленный, может быть больше, чем единица.
[48:20.000 --> 48:26.000]  Зато если вы хотите организовать межпроцессные взаимодействия, то вариантов у вас практически не остается.
[48:26.000 --> 48:30.000]  Это только семафоры, больше ничего.
[48:30.000 --> 48:41.000]  И последнее, о чем хотелось бы сказать, о том, что современные процессоры уже очень многоядерные.
[48:41.000 --> 48:47.000]  Сколько сейчас ядер в каком-нибудь процессоре? Кто знает? Самое большое число.
[48:47.000 --> 48:51.000]  А МД?
[48:51.000 --> 48:55.000]  Да, а МД, там порядка 64. Я за последними новостями о МД не слежу.
[48:55.000 --> 48:58.000]  В общем, есть Зиона, у которых 24 ядра.
[48:58.000 --> 49:05.000]  А вы про это не знаете, и мы про это не должны знать, потому что они паразиты такие.
[49:05.000 --> 49:12.000]  Решили провести последнюю конференцию без нас и даже решили отключить нас от видеороликов.
[49:12.000 --> 49:19.000]  В общем, последний М1, который не МАКС, а Ультра, там 20 ядер.
[49:19.000 --> 49:24.000]  Фигня, посреди Зио МФИ. Так что могли бы не показывать, ничего мы не потеряли.
[49:24.000 --> 49:30.000]  Так вот, 20 ядер. И на самом деле это не предел. Это только на один процессор.
[49:30.000 --> 49:36.000]  В серверах можно ставить по несколько процессоров, каждым из которых там по 20 с лишним ядер.
[49:37.000 --> 49:43.000]  В общем, уже много. Чем больше ядер, тем больше чего, тем больше толкучки.
[49:43.000 --> 49:50.000]  Возникает много потоков, которые начинают уже мешать друг другу.
[49:50.000 --> 49:56.000]  И классическая проблема. 100 000 одновременных подключений.
[49:56.000 --> 50:02.000]  Ну хорошо, 100 000 одновременных подключений, навряд ли вы создаете 100 000 трэдов, которые будут работать одновременно.
[50:02.000 --> 50:10.000]  А вот 20 трэдов, которые работают одновременно с одними теми же данными, это уже вполне себе прилично.
[50:10.000 --> 50:16.000]  И какие тут возникают проблемы? Проблема в том, что они начинают захватывать мьютексы.
[50:16.000 --> 50:23.000]  И захват мьютекса, вообще блокировка, она хоть и не расходует процессорное время,
[50:23.000 --> 50:29.000]  но заставляет все отдельные потоки просто простаивать впустую.
[50:29.000 --> 50:37.000]  Просто ожидая, что какие там мьютексы вдруг внезапно станут свободными и может быть продолжать свое выполнение.
[50:37.000 --> 50:47.000]  И в некоторых задачах, например, обработка большого количества подключений, это становится неприемлемым.
[50:47.000 --> 50:52.000]  Поэтому могут использоваться не блокирующие структуры данных.
[50:52.000 --> 50:57.000]  Например, лог-фри очереди. Это самая распространенная структура.
[50:57.000 --> 51:05.000]  Когда у вас в одну сторону записывают какие-то данные без блокировок, без мьютексов, а с другой стороны не могут читаться.
[51:05.000 --> 51:09.000]  Что они про не блокирующие структуры данных рассказывали?
[51:09.000 --> 51:11.000]  Лог-фри не было. Значит, будет еще.
[51:11.000 --> 51:18.000]  И на самом деле это очень сильно повышает производительность именно в ситуации.
[51:18.000 --> 51:24.000]  Никогда у вас там 2-3 потока. 2-3 потока используете мьютексы, не парьтесь.
[51:24.000 --> 51:29.000]  Если потоков уже становится много, то без лог-фри уже становится сложно.
[51:29.000 --> 51:35.000]  И как у нас реализуются блок-фри структуры данных?
[51:35.000 --> 51:42.000]  Есть атомарные операции во многих процессорах, что ARM, что x86.
[51:42.000 --> 51:49.000]  Но они работают только с целочисленными значениями, не превышающими по размеру машинное слово.
[51:49.000 --> 51:56.000]  Вообще, целочисленные значения, не превышающие по размеру машинного слова, достаточно для чего?
[51:56.000 --> 51:59.000]  Например, для указателя.
[51:59.000 --> 52:09.000]  Как можно, имея атомарные операции над каким-то целочисленными значениями, реализовать не блокирующую очередь?
[52:09.000 --> 52:12.000]  Очередь – это односвязанный список.
[52:12.000 --> 52:19.000]  Соответственно, вы можете параллельно в двух трейдах создавать 2 объекта, которые хотите добавить.
[52:19.000 --> 52:25.000]  Как выполняется добавление? Это просто обмен указателями.
[52:25.000 --> 52:29.000]  Не важно, какой размер у вас данные в этой очереди.
[52:29.000 --> 52:33.000]  Если вы создали какую-то порцию независимо друг от друга, не мешая друг другу,
[52:33.000 --> 52:43.000]  то потом перекинуть указатели на tail или на следующий элемент списка вы тоже можете сделать атомарным образом.
[52:43.000 --> 52:51.000]  Этот сломанный светофор – это очередное творение бота Рудали от Сбербанка.
[52:51.000 --> 52:55.000]  Наш ответ загнивающему западу.
[52:55.000 --> 52:57.000]  На этом все.
