[00:00.000 --> 00:14.560]  Так. На чем мы остановились? Мы жадный алгоритм обсуждали. Что сделали? Жадники же обсуждали.
[00:14.560 --> 00:24.160]  Да, то есть вот мы остановились просто полностью завершив историю про, как называется, жадный алгоритм.
[00:24.160 --> 00:30.560]  Про жадный алгоритм, про то, как можно считать сравнительно быстро хроматически число на случайном графе.
[00:30.560 --> 00:40.720]  Но потом я сформулировал теорему, которая говорит о том, что если вам вложены те графы, которые не попали в почти все, то будет плохо.
[00:40.720 --> 00:44.480]  Там бывают очень скверные графы. Да, на этом я остановился.
[00:45.440 --> 01:14.400]  Но я хочу продолжить на самом деле исследование всех этих характеристик случайного графа и давайте я, наверное, начну все-таки с каких-то вещей, которые с одной стороны относятся к нашей науке, к дискретному анализу, то есть случайный граф, например, что такое, а с другой стороны, немножко напомню вероятность, потому что я все-таки понимаю, что у нас есть разные учебные планы и, например, люди, которые позиционируются как математики,
[01:14.400 --> 01:25.280]  изучают сейчас в большей степени сигма-алгебры, нежели, собственно, вероятность, поэтому надо быть на каком-то общем базисе. Я правильно понимаю ситуацию?
[01:25.280 --> 01:28.480]  Если вы считаете, что это автоматично.
[01:28.480 --> 01:33.600]  Что говорите? Или все знают, например, что такое неранейство Чебышова?
[01:33.600 --> 01:37.920]  Нет, все еще сигма-алгебра.
[01:37.920 --> 01:43.840]  Все еще сигма-алгебра, ну вот я так себе это и представлял. Ничего страшного, мне совершенно не трудно.
[01:44.080 --> 01:48.000]  Давайте так. Что такое случайный граф?
[01:48.000 --> 01:54.720]  Ну, в обычном смысле слова, как мы его до сих пор употребляли, это понимают вроде бы как все.
[01:54.720 --> 02:03.920]  Мы поняли, что это очень полезный объект, потому что вот, например, он работает с точки зрения подсчета каких-то сложно вычислимых характеристик.
[02:03.920 --> 02:10.400]  Работает в том смысле, что демонстрирует возможность вычисления этих характеристик на почти всех графах.
[02:10.640 --> 02:17.760]  Ну давайте чуть более отчет. Я уже не помню, давал я это определение или нет, я вот сейчас напишу.
[02:17.760 --> 02:23.680]  Если оно здесь было в каких-то лекциях, ну я быстро напомню и все, иначе можно чуть подробнее.
[02:23.680 --> 02:32.160]  Значит, модель, с которой мы будем работать, в общем виде называется моделью Эрзо Шейрэнии.
[02:32.160 --> 02:38.320]  Вот скажите мне, такие две фамилии здесь в связке между собой звучали уже или нет?
[02:38.320 --> 02:39.840]  Нет, был потом.
[02:39.840 --> 02:46.000]  Мне кажется тоже, что не звучали пока, что, может где-то в другом месте я их говорил, а на этих лекциях нет.
[02:46.000 --> 02:53.280]  Значит, эта модель, которая появилась на самом деле раньше, чем Эрзо Шейрэнии написали свои знаменитые статьи,
[02:53.280 --> 02:58.080]  ну вот статьи стали знаменитыми, поэтому модель называется так.
[02:58.080 --> 03:05.120]  Физики, между прочим, очень сильно обижаются и говорят, да их там рядом не стояло, мы это придумали за много лет так.
[03:05.120 --> 03:07.520]  И в общем они в какой-то мере правы.
[03:07.920 --> 03:13.360]  По-другому эта модель называется биномиальная и это всех примеряет.
[03:13.360 --> 03:22.560]  Ну и еще иногда говорят, что эта модель классическая в том смысле, что она действительно такая уже старая, наиболее изученная
[03:22.560 --> 03:26.480]  и очень важная с точки зрения в том числе и приложений тоже.
[03:26.480 --> 03:32.640]  Модель очень простая, вот слово бином указывает на ее происхождение очень хорошо.
[03:33.280 --> 03:39.280]  Давайте, так, ну все присутствующие знают, что вероятность определяется так.
[03:39.280 --> 03:50.640]  Есть три объекта, один из которых Омега, это пространство элементарных событий, другой сигма алгебра событий и третья это вероятностная мера.
[03:50.640 --> 03:54.320]  Вот это все ведь присутствующие знают?
[03:54.320 --> 03:55.120]  Да.
[03:55.120 --> 03:55.760]  Правда?
[03:55.760 --> 03:56.320]  Да.
[03:56.320 --> 03:57.280]  Да, ну отлично.
[03:57.360 --> 04:05.840]  То есть в данном случае, ну давайте я пишу, Омега, f и p, как это принято писать, ну вы не пугайтесь.
[04:05.840 --> 04:11.360]  Вот на самом деле все предельно просто можно и без этих, конечно, изысков, без колмогорова скажем так.
[04:11.360 --> 04:21.440]  Значит Омега это множество всех обычных, то есть обыкновенных простых графов на заданном множестве из n вершин.
[04:22.400 --> 04:30.320]  Давайте считать, что я на вершину, у нас просто числа от единицы до n, а вот ребра могут быть какими угодно.
[04:30.320 --> 04:39.920]  Ну то есть мощность Омега, это как много раз у нас уже говорилось, это просто 2 в степени c и z подв.
[04:41.920 --> 04:49.600]  Обобщение по сравнению с тем, что мы делали, скажем, на прошлой лекции, состоит в том, как мы определяем вероятностную меру.
[04:49.760 --> 05:02.240]  f это, конечно, просто 2 в степени Омега, тут нет ничего умного, у нас конечное вероятностное пространство, поэтому кажется нелепым ограничивать себя в рассмотрении событий.
[05:02.240 --> 05:05.680]  Любое множество графов мы считаем событием.
[05:07.680 --> 05:08.640]  Не гоню?
[05:08.640 --> 05:09.680]  Все отлично.
[05:11.680 --> 05:23.680]  Вероятностная мера задается на элементарных событиях, то есть на графах, можно воспринимать ее, конечно, как вероятность того, что g окажется равным.
[05:23.680 --> 05:31.680]  Тут все зафиксировано, вершины не случайные, но вот именно с такими репушками.
[05:31.720 --> 05:38.720]  Но это слишком длинно писать, да в общем и в теории героятностей принято брать просто p от Омега маленького и все.
[05:38.720 --> 05:48.720]  Поэтому вот это я зачеркну, чтобы вас не смущало, и напишу просто p, некоторое p.
[05:48.760 --> 06:06.760]  Давайте его здесь зафиксируем число из отрезка 0.1 в степени мощность E умножить на 1 минус p в степени c из n по 2 минус мощность E.
[06:06.760 --> 06:10.760]  Вот я так по-колмогоровски формально задал вероятностное пространство.
[06:10.800 --> 06:19.800]  Так, дорогие друзья, вот вы, присутствующие здесь, понимаете, что это действительно схема Бернули просто, то есть биномиальная модель.
[06:19.800 --> 06:35.800]  По сути мы что делаем? Мы берем полный граф на n вершинах, я условно нарисую k4, но в общем случае берем полный граф на n вершинах.
[06:35.840 --> 06:45.840]  У нас есть вот эта чиселка p, это условная вероятность успеха, или вероятность того, что монетка ляжет кверху какой-то своей конкретной стороной, скажем, решкой.
[06:45.840 --> 06:56.840]  p это вероятность решки, и если монетка при очередном бросании падает кверху решкой, то мы сохраняем ребро, а если падает кверху орлон, то стираем.
[06:58.840 --> 07:02.840]  Согласны, что получится ровно вот такая вероятность каждого конкретного графа?
[07:02.880 --> 07:06.880]  Можно больше не разжевывать, правильно?
[07:06.880 --> 07:14.880]  Вот это корректно определенное вероятностное пространство, очевидно, что сумма всех таких штук это единица, это просто в чистом виде бином.
[07:16.880 --> 07:26.880]  Ну и частный случай, когда p маленькое равняется 1 и 2, это частный случай, с которым мы до сих пор работали.
[07:27.880 --> 07:31.880]  А вот это вот выражение, то есть что оно выражает?
[07:31.920 --> 07:33.920]  Вот это.
[07:34.920 --> 07:37.920]  Мы таким образом зададем вероятность каждого графа.
[07:37.920 --> 07:39.920]  А p маленькое?
[07:39.920 --> 07:49.920]  p маленькое это вероятность каждого отдельно взятого ребра, если хотите, но это уже пояснение, почему модель называется биномиальная или где там схема испытаний Бернули.
[07:49.920 --> 07:55.920]  Вот это можете считать просто определением, то есть есть модель, которую принято вот так вот обозначать.
[07:55.960 --> 07:59.960]  У нее два параметра, как у любой схемы испытаний Бернули.
[07:59.960 --> 08:08.960]  Один параметр это n, но в данном случае n это не число испытаний, а n это количество вершин графа.
[08:08.960 --> 08:11.960]  Число испытаний здесь c из n по 2.
[08:12.960 --> 08:15.960]  Так, я честно говоря проглядел, кто задавал вопрос, чтобы смотреть на него.
[08:15.960 --> 08:16.960]  Я задавал.
[08:16.960 --> 08:17.960]  А вы задавали.
[08:17.960 --> 08:18.960]  Ну сейчас все стало понятно?
[08:18.960 --> 08:19.960]  Да.
[08:19.960 --> 08:23.960]  То есть вот это вот формальное определение, можно забыть про то, что бросали монетку.
[08:24.000 --> 08:27.000]  А дальше я пояснял, что ну конечно это надо воспринимать так.
[08:27.000 --> 08:29.000]  Очень естественная модель.
[08:29.000 --> 08:36.000]  Знаете, представьте себе такую сеть из серверов, разбросанных по всей стране или по всему миру.
[08:36.000 --> 08:40.000]  И вот каждые два сервера между собой соединены в какой-то линии связи.
[08:40.000 --> 08:45.000]  Тогда вот это p, можно считать даже не p, а 1-p.
[08:45.000 --> 08:50.000]  Можно считать вероятностью возникновения помехи на линии связи.
[08:50.040 --> 08:58.040]  Вот случайный граф, который образуется, это граф связей между серверами,
[08:58.040 --> 09:01.040]  если реализовалось какое-то количество помех.
[09:01.040 --> 09:04.040]  Мы считаем, что реализуются они взаимно независимо.
[09:06.040 --> 09:10.040]  То есть практически смысл этой модели абсолютно по-моему понятен.
[09:10.040 --> 09:15.040]  Больше того, вот эту историю про связность полученного графа,
[09:15.040 --> 09:19.040]  про какие-то компоненты связности, мы обязательно будем рано или поздно обсуждать.
[09:19.080 --> 09:21.080]  Это очень важная вещь.
[09:24.080 --> 09:26.080]  Так, друзья.
[09:28.080 --> 09:30.080]  Вот сейчас больше нет вопросов по модели?
[09:30.080 --> 09:31.080]  Еще один.
[09:31.080 --> 09:32.080]  Да.
[09:32.080 --> 09:36.080]  У нас формы гениального распределения еще перед вот этими p, а 1-p еще ц-шка стоит.
[09:36.080 --> 09:40.080]  Ну естественно, но мы же определяем вероятность конкретного графа.
[09:40.080 --> 09:45.080]  То есть если у вас четыре вершины, и вам дан совершенно конкретный граф,
[09:45.120 --> 09:49.120]  например, вот такой вот цикл, который я сейчас нарисовал,
[09:49.120 --> 09:53.120]  то его вероятность будет просто p в четвертой на 1-p в квадрате.
[09:53.120 --> 09:55.120]  Откуда тут ц-шка возьмется?
[09:55.120 --> 09:59.120]  Другое дело, что если вы будете считать вероятность возникновения цикла,
[09:59.120 --> 10:02.120]  то вам придется умножить на количество циклов,
[10:02.120 --> 10:05.120]  которые можно построить на четырех вершин.
[10:05.120 --> 10:08.120]  Потому что вы сложите все вероятности.
[10:08.120 --> 10:11.120]  А, ну конечно, да, надо знаете что сказать,
[10:11.160 --> 10:15.160]  что если А принадлежит вот этой сигма-алгебре,
[10:15.160 --> 10:18.160]  то, конечно, вероятность определяется, как всегда,
[10:18.160 --> 10:23.160]  как сумма по g принадлежащим А, вероятность этих g.
[10:23.160 --> 10:26.160]  Ну это, я надеюсь, и так понятно.
[10:26.160 --> 10:31.160]  У нас такая дискретная сигма-алгебра, на ней вероятность всегда так определяется.
[10:35.160 --> 10:36.160]  Так.
[10:36.200 --> 10:41.200]  Ну вот раньше я как-то в этом месте начинал рассказывать именно про связность,
[10:41.200 --> 10:45.200]  но вы же услышали, что это практически значимая вещь,
[10:45.200 --> 10:48.200]  связность там какая-то и прочая, серверы соединены,
[10:48.200 --> 10:51.200]  или какие-нибудь, может быть, дороги проходят,
[10:51.200 --> 10:55.200]  которые по какой-то причине могут быть перекрыты случайным образом, и так далее.
[10:55.200 --> 10:58.200]  То есть это, безусловно, важная для приложений вещь.
[10:58.200 --> 11:01.200]  Эту модель очень глубоко изучают,
[11:01.200 --> 11:04.200]  и мы много чего про нее изучим.
[11:04.240 --> 11:08.240]  Но сейчас я хочу сконцентрироваться все-таки на хроматических числах,
[11:08.240 --> 11:11.240]  числах независимости и прочих подобных объектах,
[11:11.240 --> 11:16.240]  потому что мы увидели, что модели случайных графов для них работают,
[11:16.240 --> 11:18.240]  я это уже говорил в начале лекции,
[11:18.240 --> 11:21.240]  и в прошлый раз действительно мы это демонстрируем.
[11:21.240 --> 11:23.240]  Я хочу глубже разобраться в том,
[11:23.240 --> 11:26.240]  как себя ведут вот эти характеристики на случайных графах.
[11:26.240 --> 11:29.240]  Хорошо, товарищи? Будем разбираться.
[11:29.280 --> 11:32.280]  Прежде чем разобраться, я вам расскажу
[11:32.280 --> 11:36.280]  два замечательных неравенства из теории и вероятности,
[11:36.280 --> 11:38.280]  или даже три,
[11:38.280 --> 11:42.280]  которые у вас, ну, два из них точно возникнут в ближайшее время,
[11:42.280 --> 11:44.280]  просто в соответствующем курсе.
[11:44.280 --> 11:47.280]  Мне не кажется, что это дублирование информации,
[11:47.280 --> 11:50.280]  потому что вам расскажут по-другому, я в этом уверен, совершенно,
[11:50.280 --> 11:54.280]  ибо я их буду доказывать только в самом простом дискретном случае.
[11:54.280 --> 11:57.280]  Может быть, это вам даже поможет воспринять то,
[11:57.320 --> 11:59.320]  что я вам рассказываю на общих лекциях.
[11:59.320 --> 12:01.320]  Хорошо?
[12:01.320 --> 12:03.320]  Мне не жалко времени,
[12:03.320 --> 12:05.320]  мне главное, чтобы вы умели этими инструментами
[12:05.320 --> 12:07.320]  действительно пользоваться.
[12:07.320 --> 12:10.320]  Ну, что такое случайная величина, все присутствующие знают, да?
[12:10.320 --> 12:13.320]  Случайная величина в нашем понимании,
[12:13.320 --> 12:16.320]  ну, какая там, х,
[12:16.320 --> 12:21.320]  это просто любая функция из omega w.
[12:21.320 --> 12:24.320]  Наверное, вас учили,
[12:24.320 --> 12:26.320]  что случайная величина это не любая функция,
[12:26.360 --> 12:28.360]  любая измеримая функция.
[12:28.360 --> 12:30.360]  Правильно?
[12:30.360 --> 12:32.360]  Нет, не учили?
[12:32.360 --> 12:35.360]  А, ну, дискретный случай,
[12:35.360 --> 12:37.360]  вот, случай, когда сигмал гипрополная,
[12:37.360 --> 12:40.360]  то есть состоит из всех, вот здесь написано, вот здесь,
[12:40.360 --> 12:42.360]  из всех возможных подмножеств,
[12:42.360 --> 12:44.360]  это любая функция.
[12:44.360 --> 12:47.360]  Можно не заморачиваться никакими страстями.
[12:47.360 --> 12:49.360]  Если вас учили, что она измеримая,
[12:49.360 --> 12:52.360]  не пугайтесь, в данном случае это просто любая.
[12:52.360 --> 12:54.360]  Если вас не учили,
[12:54.400 --> 12:57.400]  что я это сказал, вас еще научат.
[12:57.400 --> 12:59.400]  Нормально?
[12:59.400 --> 13:02.400]  Не кокнул пока что.
[13:02.400 --> 13:05.400]  Так, ну, вот, любая функция называется случайной величиной.
[13:05.400 --> 13:07.400]  То есть она понимается как случайная,
[13:07.400 --> 13:10.400]  не в том смысле, что вот я вызвал случайного человека к доске,
[13:10.400 --> 13:12.400]  измерил его рост,
[13:12.400 --> 13:15.400]  и он получился случайным.
[13:15.400 --> 13:17.400]  Если я уже вызвал человека к доске,
[13:17.400 --> 13:19.400]  рост совершенно определенный,
[13:19.400 --> 13:21.400]  но человека случайно вызывал,
[13:21.400 --> 13:23.400]  поэтому и функция называется случайной.
[13:23.400 --> 13:25.400]  Вот и все.
[13:25.400 --> 13:28.400]  То есть тут такая есть удвоственность, что ли,
[13:28.400 --> 13:30.400]  некоторое...
[13:31.400 --> 13:34.400]  ...заметание пыли под ковер, что ли.
[13:35.400 --> 13:37.400]  Ну, хорошо.
[13:37.400 --> 13:39.400]  Так, любая функция.
[13:39.400 --> 13:43.400]  Теперь, у этой функции есть разные замечательные характеристики.
[13:43.400 --> 13:46.400]  Например, есть вероятность,
[13:46.400 --> 13:51.400]  с которой эта функция принимает какое-нибудь конкретное свое значение,
[13:51.400 --> 13:54.400]  х маленькое, то есть х маленькое это вещественное число.
[13:54.400 --> 13:59.400]  Если у нас ω имеет мощность меньше бесконечности,
[13:59.400 --> 14:01.400]  а мы работаем ровно с такой ситуацией,
[14:01.400 --> 14:03.400]  нам больше ничего не нужно,
[14:03.400 --> 14:05.400]  у нас конечное вероятностное пространство,
[14:05.400 --> 14:08.400]  ну, тогда, конечно, мы должны иметь посчитать вероятность,
[14:08.400 --> 14:11.400]  с которой х принимает любое конкретное свое значение.
[14:11.400 --> 14:13.400]  Это тоже никого не пугает?
[14:14.400 --> 14:16.400]  Все нормально.
[14:16.400 --> 14:19.400]  Я просто действительно не знаю, до чего вам дочитали в разных потоках.
[14:19.400 --> 14:21.400]  Мне трудно судить.
[14:21.400 --> 14:23.400]  Главное, чтобы было понятно, что происходит.
[14:23.400 --> 14:29.400]  Вот, друзья, зачастую вот эту вероятность посчитать крайне трудно для конкретных ситуаций.
[14:29.400 --> 14:33.400]  Чтобы вы почувствовали немножко, насколько это трудно,
[14:33.400 --> 14:36.400]  я вам задам задачку,
[14:36.400 --> 14:39.400]  которая звучит очень просто.
[14:39.400 --> 14:42.400]  Нет, давайте сначала решим простое упражнение.
[14:42.400 --> 14:45.400]  Вот мы работаем со случайным графом.
[14:45.400 --> 14:48.400]  Сейчас давайте считать, что мы живем только в этом мире,
[14:48.400 --> 14:50.400]  вот в том, который там описан.
[14:50.400 --> 14:53.400]  Я вам предложу сначала такую величину.
[14:53.400 --> 15:01.400]  х от g равняется число ребер в графе g.
[15:01.400 --> 15:06.400]  Ну, то есть то, что мы и писали, собственно, как мощность е.
[15:06.400 --> 15:08.400]  Но это же случайная величина, правильно?
[15:08.400 --> 15:10.400]  Это функция от графа.
[15:12.400 --> 15:17.400]  С какой вероятностью х равняется конкретному числу k,
[15:17.400 --> 15:19.400]  где k какое-то целое число?
[15:19.400 --> 15:22.400]  В каких вообще пределах может меняться k?
[15:24.400 --> 15:25.400]  Правильно.
[15:25.400 --> 15:28.400]  k это число от 0 до c из n под 2.
[15:28.400 --> 15:32.400]  Чтобы точно всем было понятно, это число от 0 до c из n под 2.
[15:32.400 --> 15:34.400]  Ну, и с какой же вероятностью х равно k?
[15:34.400 --> 15:37.400]  Вот это как раз будет ответ на вопрос про ц.
[15:37.400 --> 15:39.400]  По-моему, это отсылка к задаче.
[15:39.400 --> 15:44.400]  Ну, ужасно то, что действительно надо написать c из c из n под 2 по k.
[15:44.400 --> 15:47.400]  Почему-то даже наших продвинутых студентов пугает,
[15:47.400 --> 15:50.400]  что из c можно взять тоже c.
[15:50.400 --> 15:52.400]  c из c.
[15:52.400 --> 15:54.400]  Можно с n записать c из n под 2.
[15:54.400 --> 15:56.400]  Ну, можно, конечно.
[15:56.400 --> 15:58.400]  Товарищ, дайте еще скобки!
[15:58.400 --> 15:59.400]  Ну, слушайте!
[15:59.400 --> 16:01.400]  Как можно таким кокнуть?
[16:03.400 --> 16:04.400]  У нас просто испытаний.
[16:04.400 --> 16:05.400]  c из n под 2.
[16:05.400 --> 16:06.400]  Вот их столько.
[16:06.400 --> 16:09.400]  Надо выбрать какие-то k конкретно, в которых реализовался успех.
[16:09.400 --> 16:11.400]  То есть сохранилось ребро.
[16:11.400 --> 16:18.240]  конечно, умножить на 1-p в степени c из n по 2 минус k. Я надеюсь, это совершенно
[16:18.240 --> 16:22.880]  понятно, очень простое упражнение. Вот как раз это и появилось, про которое меня
[16:22.880 --> 16:33.560]  спрашивали, где она? Вот она появилась. Вот, а теперь задачка. Пусть х от g это число
[16:34.560 --> 16:43.640]  треугольников в графе g, ну то есть полных подграфов на трёхмершину.
[16:43.640 --> 16:52.040]  У нас такой недавно был на семинаре. Прекрасно, ну я не знаю. И что, решили что-ли? Вроде да.
[16:52.040 --> 16:59.320]  Я думаю, что вы под ожиданием. А я-то вам чего хочу сказать, вот почитайте
[16:59.320 --> 17:07.440]  например, вероятность того, что x равняется 0. Ну то, что в графе нет треугольников.
[17:08.040 --> 17:14.320]  Нет, ну смотрите, вот может быть пустой граф, в нем нет треугольников, да? А может
[17:14.320 --> 17:20.040]  быть, например, двудольный граф, причем любой, не обязательно полный. В нем ведь
[17:20.040 --> 17:26.000]  тоже нет треугольников. Но согласитесь, что с нашей точки зрения, у этих разных
[17:26.000 --> 17:32.240]  графов совершенно разные вероятности. У двудольного куча ребер, а у пустого не
[17:32.240 --> 17:38.600]  одного ребра, поэтому вероятность, если только p не равно 1 и 2, все разные, правда?
[17:38.600 --> 17:46.600]  А их же потом складывать надо. Вот и подумайте, чтобы почувствовать, насколько все хитро.
[17:46.600 --> 17:52.200]  Ну подумайте, подумайте. Я вас уверяю, что это совсем не просто, но вы это должны
[17:52.200 --> 18:00.600]  сами почувствовать. Вы это должны почувствовать сами. Чуть-чуть я вам скажу, почему это
[18:00.600 --> 18:10.600]  трудно, ладно? Чуть-чуть. Мне обычно говорят х, а давайте это так посчитаем. Это 1 минус
[18:10.600 --> 18:18.560]  вероятность того, что x больше либо равно 1. Почему-то людям кажется, что вот это
[18:18.560 --> 18:23.640]  посчитать проще. Почему людям кажется, что это посчитать проще? Вы, может, зря
[18:23.640 --> 18:29.960]  смеетесь. Что такое x больше либо равно 1? Что значит, что x больше либо равно 1?
[18:29.960 --> 18:36.960]  Это значит, в графе есть треугольники, правда? Люди думают... Сейчас, извините, пожалуйста.
[18:37.360 --> 18:46.360]  Ой, сейчас буквально, секунду. Я могу перезвонить через полчаса? Ага. Так.
[18:46.360 --> 18:49.760]  Но это вероятность объединения, то есть можно считать по параметру, что ничего не случилось.
[18:49.760 --> 18:55.160]  Вот, правильно совершенно. Вот вы совершенно правильно понимаете сложность вопроса. То есть людям
[18:55.160 --> 19:04.960]  почему-то кажется, что вот эта вероятность равна c из n по 3 умножить на p в кубе. Но это чушь.
[19:04.960 --> 19:13.360]  Она этого не превосходит. Но не больше того. Почему кажется? Потому что здесь, на самом деле, вот в этой
[19:13.360 --> 19:21.360]  вероятности, давайте я стрелочку поставлю, вот в ней стоит объединение по i, объединиться до c из n по 3,
[19:21.360 --> 19:30.360]  ну каких-то событий a с индексом i. Каких? Мы нумируем все возможные тройки вершин графа,
[19:30.360 --> 19:41.960]  и it состоит в том, что it по счету тройка образует треугольник. Друзья, такой темп успеваете? Все успевают?
[19:41.960 --> 19:50.960]  Мы еще раз, мы нумируем все тройки вершин нашего графа. Вот у нас вершина от единички до n.
[19:50.960 --> 19:59.160]  Мы их в каком-то произвольном порядке нумируем от единицы до c из n по 3. Событие it состоит в том,
[19:59.160 --> 20:07.560]  что it по счету тройка образует треугольник. Понятно сейчас? Эти события очевидно пересекаются,
[20:07.560 --> 20:14.160]  ну потому что бывают графы, в которых находятся несколько треугольников, товарищи. В чем проблема?
[20:14.160 --> 20:23.560]  Поэтому говорить, что эта вероятность просто равна сумме вероятности этих событий нельзя. Сумма-то,
[20:23.560 --> 20:31.560]  конечно, c из n по 3 на p в кубе, но это всего лишь верхняя оценка. Это не превосходит c из n по 3 на p в кубе,
[20:31.560 --> 20:36.560]  что вероятность каждого из этих товарищей, безусловно, на p в кубе, 3 вебра присутствует и все.
[20:36.560 --> 20:47.360]  Друзья, точно я не очень быстро говорю? Точно? Нормально? Это сложно, тут формулу включения-исключения
[20:47.360 --> 20:59.360]  и фиг напишешь, но попробуйте, может быть у вас получится без. Ну в некоторых ситуациях асимптотику,
[20:59.360 --> 21:07.360]  конечно, точно можно найти. А асимптотику вот этой вероятности при n стремящемся к бесконечности,
[21:07.360 --> 21:14.360]  n число вершины, можно найти. Например, если p константа, можно найти. Ну это я вам сейчас порешаю все.
[21:14.360 --> 21:22.360]  Вот и задачка на 5 минут. А я что сказал, что на 5 минут, я сказал вам напонять, что тут все сложно.
[21:22.360 --> 21:28.360]  То есть если мы хотим найти вероятность того, что какая-то конкретная величина принимает некоторое свое значение,
[21:28.360 --> 21:33.360]  ну это бывает сложно. Вот вы подумайте, увидите, что сложно. Больше я от вас ничего не требую.
[21:33.360 --> 21:38.360]  Это не задача на экзамен, слушайте. Вы меня, наверное, так поняли, что вы сейчас ее порешаете,
[21:38.360 --> 21:44.360]  я на экзамен вам за десятку поставлю. Нет, ну если порешаете, поставлю, может я не знаю.
[21:44.360 --> 21:51.360]  Нет, ну просто понимаете, там можно скачать что-то из интернета, как я проверю, что вы сами решаете.
[21:51.360 --> 21:57.360]  Ну такое не найдешь в интернете. Нет, нет, я просто хочу, чтобы вы задумались и поняли,
[21:57.360 --> 22:03.360]  что искать распределение конкретных случайных величин в комбинатуре бывает совсем непросто.
[22:04.360 --> 22:12.360]  Так, поэтому возникают удобные инструменты типа всяких вероятностных неравенств.
[22:12.360 --> 22:17.360]  Я хочу, чтобы вот до вас просто вся кухня этого дела дошла по максимуму.
[22:17.360 --> 22:24.360]  Вам это обязательно расскажут по бою курсов, которые сейчас читаются по основам вероятностей теории мер.
[22:24.360 --> 22:28.360]  Но я думаю, что могут рассказать достаточно формат.
[22:28.360 --> 22:38.360]  А я сейчас вот для конечного случая расскажу максимально аккуратно именно с точки зрения приложений.
[22:46.360 --> 22:52.360]  Ну вот прямо вот эта вот ситуация про формулу включения и исключения, которая здесь возникла,
[22:52.360 --> 22:56.360]  это и называется по большому счету неравенство Маркова.
[22:56.360 --> 23:03.360]  То есть неравенство Маркова это простая оценка формы включения и исключения и ничего больше.
[23:03.360 --> 23:08.360]  Но оно очень удобное, это мы сегодня увидим.
[23:08.360 --> 23:11.360]  Что такое неравенство Маркова?
[23:11.360 --> 23:15.360]  Я его докажу не только для случайных графов.
[23:15.360 --> 23:20.360]  Давайте считать, что мощность Омега меньше бесконечности, вот это важно.
[23:20.360 --> 23:25.360]  А уж случайный это граф или еще какое-то конечное пространство, это не важно.
[23:25.360 --> 23:36.360]  Так, пусть х из Омега принимает только не отрицательные значения.
[23:36.360 --> 23:44.360]  Р плюс я понимаю так, что там и ноль может быть, но отрицательных там нет.
[23:44.360 --> 23:54.360]  Тогда для любого А большего нуля, вероятность того, что х больше либо равняется А.
[23:54.360 --> 24:01.360]  И тут я вспоминаю, слушайте, а мат ожидания-то все проходили что такое или тоже не все знают?
[24:01.360 --> 24:04.360]  А, ну давайте я быстро напомню.
[24:04.360 --> 24:07.360]  Да, да, что-то мне в голову пришло.
[24:07.360 --> 24:10.360]  Ну так вам построили курс, ничего страшного.
[24:10.360 --> 24:17.360]  Так, дорогие друзья, поднимите руки, кто не знает, что такое мат ожидания случайной величины, формально не знает.
[24:17.360 --> 24:21.360]  Ну, я сейчас быстро вам объясню, я думаю, что вы быстро воспримете.
[24:21.360 --> 24:24.360]  Для конечного случая это совсем очевидно.
[24:24.360 --> 24:31.360]  Если у вас есть случайная величина х на конечном, вероятностном пространстве,
[24:31.360 --> 24:38.360]  то мат ожидания это просто сумма по всем Омега маленьким из Омега большое.
[24:38.360 --> 24:43.360]  Х от Омега умножить на вероятность этого Омега.
[24:43.360 --> 24:47.360]  Проще ничего быть не может, просто такое среднее взвешенное.
[24:47.360 --> 24:52.360]  Может быть, кстати, и другим слушателям будет полезно как-то в этом контексте посмотреть на ситуацию,
[24:52.360 --> 24:55.360]  а то ведь могли дать более общий определение сразу.
[24:55.360 --> 24:57.360]  Ну, наверное, давали такое тоже.
[24:57.360 --> 25:00.360]  Так, ну понятно, просто средне взвешенное.
[25:00.360 --> 25:08.360]  Если все вероятности одинаковые равны 1 по делительной мощности Омега,
[25:08.360 --> 25:10.360]  ну это просто среднеархметическое.
[25:10.360 --> 25:13.360]  Ну, они же могут быть разными.
[25:13.360 --> 25:18.360]  Знаете, я вызываю из этой аудитории случайного человека, но у меня есть любимчики.
[25:18.360 --> 25:23.360]  То есть не каждый вызывается с вероятностью одна, там, условно, 50 или сколько тут сидит народу,
[25:23.360 --> 25:26.360]  а кто-то вызывается с большей вероятностью, кто-то с меньшей.
[25:26.360 --> 25:29.360]  И дальше я у каждого из вызванных измеряю рост.
[25:29.360 --> 25:35.360]  Ну, наверное, средний рост это все-таки надо не на 50 поделить, а вот с этими весами еще взять.
[25:35.360 --> 25:37.360]  Друзья, понятно?
[25:37.360 --> 25:40.360]  Даже тем, кто не знал определение мат ожидания.
[25:40.360 --> 25:42.360]  Его можно переписать по-другому.
[25:42.360 --> 25:47.360]  Сгруппировав слагаемые, на которых Х принимает одно и то же значение,
[25:47.360 --> 25:49.360]  и так тоже определение обычно дают.
[25:50.360 --> 25:59.360]  То есть представьте себе, что Х на своем омега принимает какие-то конкретные различные значения y1 и так далее yk.
[25:59.360 --> 26:01.360]  Это разные действительные числа.
[26:01.360 --> 26:03.360]  y1 и так далее yk.
[26:03.360 --> 26:05.360]  Тогда здесь получится вот так.
[26:05.360 --> 26:16.360]  Сумма по i от 1 до k, yi t умножить на вероятность того, что x равняется yi t.
[26:16.360 --> 26:21.360]  Я тоже надеюсь, что всем, кто поднял руки, понятно, почему так.
[26:21.360 --> 26:24.360]  Перегруппировал просто слагаемые, и все.
[26:24.360 --> 26:26.360]  Совершенно понятно.
[26:26.360 --> 26:29.360]  Вот, ничего больше про мат ожидания знать не нужно.
[26:29.360 --> 26:33.360]  Доказательства абсолютно очевидные.
[26:33.360 --> 26:36.360]  Обычно пишется справа налево.
[26:36.360 --> 26:40.360]  Вот, мы знаем с вами определение мат ожидания.
[26:40.360 --> 26:48.360]  Эта сумма по i от 1 до k, yi t на вероятность того, что x равно yi t.
[26:48.360 --> 26:51.360]  У нас а, не так.
[26:51.360 --> 26:54.360]  Давайте разобьем эту сумму на две части.
[26:54.360 --> 27:00.360]  В одной будут такие i, на которых yi t больше либо равняется а,
[27:00.360 --> 27:06.360]  а в другой будут такие i, на которых yi t меньше, чем а.
[27:06.360 --> 27:09.360]  Успеваете?
[27:09.360 --> 27:12.360]  Разбил сумму на две очевидные части.
[27:12.360 --> 27:17.360]  После того, как я бил суммы на части, которые начинались с n в степени 0,6,
[27:17.360 --> 27:22.360]  такое разбиение кажется детским.
[27:22.360 --> 27:24.360]  Помните n в степени 0,6?
[27:24.360 --> 27:26.360]  А тут-то все понятно.
[27:26.360 --> 27:29.360]  Смотрите, какую я фигню сейчас сделаю.
[27:29.360 --> 27:34.360]  Я замечу, что, поскольку их принимало только положительные, не отрицательные значения,
[27:34.360 --> 27:40.360]  то вот эти все y, которые во второй сумме, они положительные, не отрицательные, правильно?
[27:40.360 --> 27:44.360]  Слушайте, ну вероятность-то это точно не отрицательное число?
[27:44.360 --> 27:49.360]  Я скажу, что вот это все больше либо равно 0.
[27:49.360 --> 27:59.360]  Так, это больше либо равно сумме по i таким, что yi t больше либо равняется а,
[27:59.360 --> 28:05.360]  yi t и t на вероятность того, что x равно yi t.
[28:05.360 --> 28:12.360]  yi t больше либо равно, а тут тоже yi t.
[28:12.360 --> 28:15.360]  Значит, это все больше либо равно, правильно?
[28:15.360 --> 28:17.360]  Больше либо равно.
[28:17.360 --> 28:19.360]  Общее a выносим за скобку.
[28:19.360 --> 28:25.360]  Сумма остается все по тем же i, на которых yi t больше либо равняется а.
[28:25.360 --> 28:29.360]  А тут вероятность того, что x равно yi.
[28:29.360 --> 28:33.360]  Надеюсь, товарищи, вы понимаете, что сумма, которая здесь написана,
[28:33.360 --> 28:38.360]  это и есть в аккурат вероятность того, что x больше либо равняется а.
[28:38.360 --> 28:45.360]  То есть у нас в итоге получается a умножить на вероятность того, что x больше либо равняется а.
[28:45.360 --> 28:50.360]  И читаем это справа-налево, получаем нужное нерадство.
[28:50.360 --> 28:52.360]  Очевидно все?
[28:53.360 --> 28:54.360]  Нужно вопрос.
[28:54.360 --> 28:55.360]  Да.
[28:55.360 --> 29:00.360]  Мы здесь не доказываем для случая, когда мощность не имеет граничности,
[29:00.360 --> 29:02.360]  или это просто неправда, когда мощность не имеет граничности?
[29:02.360 --> 29:04.360]  Это правда.
[29:04.360 --> 29:08.360]  Естественно, нужно, наверное, говорить о том, что мат ожидания должно существовать,
[29:08.360 --> 29:11.360]  иначе просто непонятно, что написано справа.
[29:11.360 --> 29:15.360]  Мат ожидания для бесконечных не всегда определено корректно.
[29:15.360 --> 29:18.360]  Так это верно всегда.
[29:18.360 --> 29:22.360]  То есть это я просто рассказываю совсем понятное такое доказательство,
[29:22.360 --> 29:25.360]  но оно понятное в общем случае тоже.
[29:25.360 --> 29:29.360]  Что вдруг такой интеграл вылезет, а тут сумма.
[29:29.360 --> 29:31.360]  Друзья, понятно все, да?
[29:31.360 --> 29:35.360]  То есть в частном случае, если здесь вместо a поставить единичку,
[29:35.360 --> 29:39.360]  то мы аккурат оказываемся вот в этой ситуации.
[29:39.360 --> 29:43.360]  А если кто-то знает, что математическое ожидание линий,
[29:43.360 --> 29:47.360]  то он и понимает, что вот это вот как раз математическое ожидание
[29:47.360 --> 29:51.360]  числа треугольников в случайном графе.
[29:51.360 --> 29:56.360]  Фактически я здесь написал частный случай неравенства Марков.
[29:56.360 --> 29:59.360]  Но он совсем очевиден.
[29:59.360 --> 30:02.360]  Ну, линейный смарт ожидания-то надо знать.
[30:02.360 --> 30:06.360]  Давайте я напомню, это нам точно пригодится,
[30:06.360 --> 30:12.360]  если мы берем с какими-то коэффициентами две случайные величины складываем,
[30:12.360 --> 30:18.360]  то математическое ожидание можно посчитать вот так.
[30:18.360 --> 30:22.360]  Это свойство линейности, которое, я думаю,
[30:22.360 --> 30:26.360]  знает все, кто знает, что такое мат ожидания.
[30:26.360 --> 30:29.360]  Знаете, да?
[30:29.360 --> 30:32.360]  Линейная комбинация случайных величин в среднем
[30:32.360 --> 30:36.360]  безотносительно того зависима и независима эти величины не важна.
[30:36.360 --> 30:40.360]  Всегда будет комбинация их математических ожиданий.
[30:40.360 --> 30:44.360]  Что очень важно, что никакого значения не имеет зависима
[30:44.360 --> 30:47.360]  или независима эта случайная величина.
[30:47.360 --> 30:52.360]  Так, я пока не произношу никаких слов, которые выходят за рамки общего понимания.
[30:52.360 --> 30:55.360]  Точно? Все хорошо.
[30:55.360 --> 30:59.360]  Все, вот неравенство Маркова и еще неравенство Чебышова.
[30:59.360 --> 31:02.360]  Нужно, а третье это будет на вырост.
[31:02.360 --> 31:05.360]  Оно сразу не понадобится, но будет очень классно.
[31:05.360 --> 31:08.360]  Я его сразу расскажу.
[31:10.360 --> 31:13.360]  Так.
[31:27.360 --> 31:31.360]  Ну, чтобы напомнить неравенство Чебышова, давайте.
[31:31.360 --> 31:35.360]  Я должен сказать, что такое дисперсия случайной величины.
[31:35.360 --> 31:39.360]  Поднимите руки, кто знает, что такое дисперсия.
[31:39.360 --> 31:42.360]  Ну, видимо, опять все, кроме тех, кто намотал.
[31:42.360 --> 31:45.360]  Ну, напоминаю, что такое дисперсия.
[31:45.360 --> 31:52.360]  Это математическое ожидание вот такого вот квадрата разности.
[31:52.360 --> 31:55.360]  То есть, формально уже понятно.
[31:55.360 --> 32:01.360]  А по сути, это среднее квадратичное уклонение случайной величины от своего среднего.
[32:01.360 --> 32:04.360]  Среднее квадратичное это корень дисперсии.
[32:04.360 --> 32:08.360]  Ну, уклонение корень дисперсии, да, строго говоря, корень дисперсии.
[32:08.360 --> 32:13.360]  Ну, я по сути говорю, а не по тем терминам, которые обычно приняты.
[32:13.360 --> 32:16.360]  Да, среднее уклонение это корень дисперсии обычно, да.
[32:16.360 --> 32:18.360]  Ну, не важно.
[32:18.360 --> 32:21.360]  Вот, если раскрыть скобки и воспользоваться вот этой линейностью,
[32:21.360 --> 32:24.360]  но это все вам в курсе вероятности рассказывать,
[32:24.360 --> 32:26.360]  то вы сами можете раскрыть скобки.
[32:26.360 --> 32:28.360]  Это простое упражнение.
[32:28.360 --> 32:30.360]  У вас получится еще вот так.
[32:30.360 --> 32:32.360]  Бывает полезность.
[32:32.360 --> 32:36.360]  Это называется второй момент, а это квадрат мат ожидания.
[32:40.360 --> 32:43.360]  Я не думаю, что надо больше говорить про дисперсию.
[32:43.360 --> 32:45.360]  Ну, дисперсия.
[32:45.360 --> 32:49.360]  Может быть, дурацкий вопрос, почему здесь квадрат?
[32:49.360 --> 32:52.360]  Ну, если снять квадрат, будет 0.
[32:52.360 --> 32:56.360]  Ну, просто по линейности, если квадрат убрать, будет 0.
[32:56.360 --> 33:00.360]  Очевидно, потому что мат ожидания, мат ожидания, это мат ожидания.
[33:00.360 --> 33:02.360]  Мат ожидания – это константа.
[33:02.360 --> 33:05.360]  Значит, его среднее значение – это анаш.
[33:05.360 --> 33:11.360]  Если у всех одинаковый рост, то средний рост будет все равно равен вот этому общему значению.
[33:11.360 --> 33:12.360]  Можно глупого вопроса?
[33:12.360 --> 33:13.360]  Да.
[33:13.360 --> 33:14.360]  А где стоит квадрат?
[33:14.360 --> 33:16.360]  Над ешкой или над скобочкой?
[33:16.360 --> 33:19.360]  Вот так, конечно, да.
[33:19.360 --> 33:20.360]  Конечно, вот так.
[33:20.360 --> 33:22.360]  И здесь тоже вот так.
[33:22.360 --> 33:24.360]  Но обычно просто эти скобки не рисуют.
[33:24.360 --> 33:26.360]  Но смысл именно такой.
[33:26.360 --> 33:29.360]  Да, конечно, конечно.
[33:29.360 --> 33:32.360]  То есть вы смотрите значение случайно лично.
[33:32.360 --> 33:34.360]  Где-то находится мат ожидания.
[33:34.360 --> 33:38.360]  Оно может не совпасть ни с одним значением, конечно же.
[33:38.360 --> 33:41.360]  Мат ожидания может же не совпасть ни с одним значением.
[33:41.360 --> 33:46.360]  А дальше вы измеряете, какой разброс средний возникает.
[33:46.360 --> 33:49.360]  Вот дисперсия, она меряет в каком смысле разброс.
[33:49.360 --> 33:52.360]  Собственно, слово дисперсия означает разброс.
[33:52.360 --> 34:02.360]  Вот, неравенство Чебышова тоже верное всегда.
[34:02.360 --> 34:09.360]  Поэтому я даже не буду писать, что амера конечна, действительно.
[34:09.360 --> 34:14.360]  И больше того, я напишу пуст Икс любая случайная величина.
[34:14.360 --> 34:19.360]  Как бы вы ее не определяли.
[34:22.360 --> 34:27.360]  Тогда не обязательно положительно значить.
[34:27.360 --> 34:39.360]  Тогда вероятность того, что Икс уклонится от своего математического ожидания не меньше, чем на а.
[34:39.360 --> 34:42.360]  Здесь тоже надо написать, для любого а большего нуля.
[34:42.360 --> 34:44.360]  Я что-то забыл.
[34:44.360 --> 34:50.360]  Для любого а большего нуля вероятность вот такого уклонения не превосходит дисперсии.
[34:50.360 --> 34:58.360]  Икс и Икс поделены на а в квадрате.
[34:58.360 --> 35:03.360]  Я утверждаю, что это очевидное следствие из неравенства Маркова.
[35:03.360 --> 35:06.360]  Так, у меня совсем высокая вот есть кусочек.
[35:06.360 --> 35:10.360]  Почему это очевидное следствие из неравенства Маркова?
[35:10.360 --> 35:18.360]  Ну, потому что пишите вот так.
[35:18.360 --> 35:24.360]  И воспользуйтесь неравенством Маркова.
[35:24.360 --> 35:29.360]  Друзья, понятно, эта величина принимает только положительные, не отрицательные значения.
[35:29.360 --> 35:32.360]  А квадрат, естественно, по-прежнему положительно.
[35:32.360 --> 35:39.360]  Значит, по неравенству Маркова мы получаем математическое ожидание вот этой штуки.
[35:39.360 --> 35:42.360]  Икс минус Екс в квадрате.
[35:42.360 --> 35:44.360]  Поделить просто на а квадрат.
[35:44.360 --> 35:47.360]  Ну, так это же есть дисперсия.
[35:47.360 --> 35:49.360]  Вот и все.
[35:54.360 --> 35:58.360]  Любопытно, что в наших комбинаторных исследованиях,
[35:58.360 --> 36:03.360]  несмотря на то, что неравенство Чебышова это следствие неравенства Маркова,
[36:03.360 --> 36:06.360]  они друг друга дополняют.
[36:06.360 --> 36:09.360]  Очень естественным образом.
[36:09.360 --> 36:13.360]  Обычно неравенство Маркова доказывает, что
[36:13.360 --> 36:17.360]  скорее всего, какого-то объекта в случайном графе не существует,
[36:17.360 --> 36:21.360]  а неравенство Чебышова доказывает, что какой-то объект существует.
[36:26.360 --> 36:28.360]  Страстно звучит, да?
[36:28.360 --> 36:30.360]  Или абстрактно слишком?
[36:30.360 --> 36:33.360]  Так, ну оба неравенства понятны?
[36:33.360 --> 36:37.360]  Нет, ну если нормально, давайте я про треугольники немножко расскажу,
[36:37.360 --> 36:39.360]  просто иначе вам будет не очень понятно.
[36:39.360 --> 36:41.360]  Бог с ним, что я в прошлые годы этого не делал,
[36:41.360 --> 36:43.360]  а в этом году сделаю.
[36:43.360 --> 36:45.360]  Меня ж записывают.
[36:45.360 --> 36:47.360]  Все хорошо, не зря значит записывают.
[36:47.360 --> 36:49.360]  Я чуть-чуть все-таки по-разному читаю,
[36:49.360 --> 36:53.360]  особенно в этом году с учетом того, что началось все не так, как в прежние годы.
[36:53.360 --> 36:56.360]  Я же часть прочитал Лукатече.
[36:56.360 --> 36:58.360]  Ты хорошо.
[37:06.360 --> 37:08.360]  Я обещаю, мы перейдем к хроматическим числам,
[37:08.360 --> 37:12.360]  но пока давайте разберемся с сутью происходящего, ладно?
[37:16.360 --> 37:21.360]  А то я вас научу микроскопом гвозди забивать, и это будет не очень хорошо.
[37:21.360 --> 37:24.360]  Вот про треугольники, смотрите.
[37:24.360 --> 37:26.360]  Давайте так.
[37:26.360 --> 37:30.360]  Теорема, с позволения сказать, очень простая.
[37:30.360 --> 37:32.360]  Номер один.
[37:32.360 --> 37:35.360]  Теорема номер один.
[37:35.360 --> 37:42.360]  Пусть в модели эрдоширении
[37:42.360 --> 37:49.360]  В зависит от Н.
[37:49.360 --> 37:52.360]  Ну так, может быть?
[37:53.360 --> 37:55.360]  Это более общий случай.
[37:55.360 --> 37:59.360]  Ну нормально, да, вполне с ростом числа вершин
[37:59.360 --> 38:03.360]  вероятность того, что отдельно взятая связка пропадет,
[38:03.360 --> 38:06.360]  ну, например, возрастает, а почему нет?
[38:06.360 --> 38:09.360]  Может же такое случиться.
[38:09.360 --> 38:16.360]  Чем больше компьютеров в сети, тем легче развалить отдельно взятой ребро этой сети.
[38:16.360 --> 38:18.360]  Такое может быть.
[38:18.360 --> 38:20.360]  Ну вот П зависит от Н.
[38:20.360 --> 38:25.360]  Ну так, что если мы Н умножим на вот это П, на П от Н,
[38:25.360 --> 38:27.360]  ну, хотите я на П от Н здесь напишу,
[38:27.360 --> 38:32.360]  то в пределе получится ноль при Н, стремящемся к бесконечности.
[38:35.360 --> 38:42.360]  Тогда вероятность того, что g от НП, сейчас я допишу и потом устроим перерыв,
[38:42.360 --> 38:46.360]  есть треугольники,
[38:46.360 --> 38:52.360]  ну, это вероятность того, что x больше либо равно единице,
[38:52.360 --> 38:56.360]  ведь x число треугольников.
[38:56.360 --> 39:04.360]  Я утверждаю, что стремится к нулю при Н, стремящемся к бесконечности.
[39:06.360 --> 39:09.360]  Знаете, как это словами называется?
[39:09.360 --> 39:11.360]  Я думаю, не знаете.
[39:11.360 --> 39:15.360]  Ну, может кто-то знает, кому я в коле рассказывал когда-то.
[39:15.360 --> 39:21.360]  Это называется асимпатически, почти, наверное,
[39:21.360 --> 39:24.360]  в случайном графе нет треугольников.
[39:24.360 --> 39:28.360]  Ну, вот такая терминология, я просто о диаскопках и кавычках напишу.
[39:28.360 --> 39:33.360]  А, П, Н, нет треугольников.
[39:36.360 --> 39:39.360]  Вероятность того, что они есть, стремится к нулю,
[39:39.360 --> 39:42.360]  вероятность того, что их нет, стремится к единице,
[39:42.360 --> 39:45.360]  и вот если вероятность какой-то последовательности событий
[39:45.360 --> 39:48.360]  с ростом числа вершин стремится к единице,
[39:48.360 --> 39:52.360]  то мы говорим, что это выполнено асимпатически, почти наверх.
[39:52.360 --> 39:57.360]  Так, можно целиком не писать, уследили, асимпатически, почти наверх.
[39:57.360 --> 40:01.360]  Давайте я докажу эту теорию, мы потом сделаем 5-минутный перерыв.
[40:01.360 --> 40:04.360]  Она настолько очевидная, смотрите,
[40:04.360 --> 40:07.360]  вероятность того, что x больше либо равно единице,
[40:07.360 --> 40:09.360]  не превосходит мат ожиданий x,
[40:09.360 --> 40:14.360]  которые есть в цейзанпотре на П в кубе ввиду линейности.
[40:16.360 --> 40:19.360]  Все-таки все понимают, почему это цейзанпотре на П в кубе?
[40:21.360 --> 40:24.360]  Ну, я не знаю, давайте я поясню, ладно.
[40:24.360 --> 40:28.360]  Это тоже совсем просто, это пригодится на после перерыва.
[40:29.360 --> 40:32.360]  Давайте я вот так представлю x.
[40:32.360 --> 40:35.360]  Товарищ, x это число треугольников.
[40:36.360 --> 40:41.360]  Нумеруем все тройки вершин от единицы до цейзанпотре, как и раньше.
[40:41.360 --> 40:44.360]  Ну там вот было, но уже стерто.
[40:44.360 --> 40:50.360]  Нумеруем и берем в качестве x вот здесь, напишу,
[40:50.360 --> 40:56.360]  на графе то, что называется индикатор единицу,
[40:56.360 --> 41:09.360]  если вот эта итое тройка вершин образует треугольник и ноль иначе,
[41:09.360 --> 41:13.360]  то есть сама скапает случайный граф, все он реализовался,
[41:13.360 --> 41:16.360]  вышел к доске, так сказать, попал сюда,
[41:16.360 --> 41:23.360]  и если на конкретной итое по счету тройки вершин в этом конкретном графе треугольник,
[41:23.360 --> 41:26.360]  мы пишем единичку, а иначе ноль.
[41:26.360 --> 41:30.360]  Такой, знаете, совершенно идиотский программистский подход.
[41:30.360 --> 41:34.360]  Ну умный программистский подход это какой-нибудь красивый алгоритм,
[41:34.360 --> 41:37.360]  который быстро считает число треугольников в графе.
[41:37.360 --> 41:39.360]  А у нас идиотский подход.
[41:39.360 --> 41:44.360]  Давайте переберем все тройки вершин в таком длинном цикле цейзанпотре длиной,
[41:44.360 --> 41:48.360]  и на каждом шаге будем добавлять очередную единичку,
[41:48.360 --> 41:52.360]  если очередная тройка вершин вот в этом графе образует треугольник.
[41:52.360 --> 41:54.360]  Друзья, все понятно?
[41:54.360 --> 41:58.360]  Поскольку мат ожидания линейна, то мат ожидания х,
[41:58.360 --> 42:02.360]  которая нас интересует, это сумма мат ожидания этих товарищей.
[42:02.360 --> 42:07.360]  Но мат ожидания товарищей это просто единицу может на вероятность треугольника,
[42:07.360 --> 42:09.360]  то есть на П в кубе.
[42:09.360 --> 42:12.360]  Вот это последнее понятно?
[42:12.360 --> 42:14.360]  По второму определению в мат ожидания.
[42:14.360 --> 42:16.360]  Ну все вот получилось.
[42:16.360 --> 42:21.360]  Это ведет себя как N в кубе поделить на 6 на П в кубе,
[42:21.360 --> 42:24.360]  а у нас по условиям пострелится к нулю.
[42:24.360 --> 42:26.360]  Ну значит оно стремится к нулю.
[42:26.360 --> 42:29.360]  Все, я теорем доказал?
[42:29.360 --> 42:31.360]  Доказал?
[42:31.360 --> 42:33.360]  Все, перерыв.
[42:33.360 --> 42:35.360]  Так, смотрите, как я уже говорил,
[42:35.360 --> 42:39.360]  неравенство Маркова успело нам ответить на вопрос о том,
[42:39.360 --> 42:43.360]  что каких-то объектов почти наверняка нету.
[42:43.360 --> 42:46.360]  Вот давайте я теперь сформулирую комплементарную,
[42:46.360 --> 42:49.360]  то есть дополнительную теорему по отношению к этой,
[42:49.360 --> 42:54.360]  когда будет видно, что Чебышов доказывает прямо противоположное.
[42:54.360 --> 42:58.360]  Только вы понимали, что действительно неравенство Маркова и неравенство Чебышова
[42:58.360 --> 43:00.360]  дополняют друг друга,
[43:00.360 --> 43:04.360]  и кое-что еще вы поймете, это я вам произнесу обязательно.
[43:04.360 --> 43:07.360]  Может вам это произнесут и в лекциях по теории вероятностей?
[43:07.360 --> 43:08.360]  Не знаю.
[43:08.360 --> 43:10.360]  Но это очень важно.
[43:10.360 --> 43:17.360]  Два. Пусть опять-таки в g от n, p,
[43:17.360 --> 43:22.360]  p равняется p от n,
[43:22.360 --> 43:26.360]  причем n умножить на p от n
[43:26.360 --> 43:30.360]  стремится к плюс бесконечности.
[43:30.360 --> 43:33.360]  При н-то стремящемся к этой самой плюс бесконечности.
[43:33.360 --> 43:35.360]  Бесконечности, понятно.
[43:35.360 --> 43:38.360]  Я не всегда плюс рисовал, но смысл тот же самый.
[43:38.360 --> 43:42.360]  Согласитесь, это такая комплементарная ситуация, да?
[43:42.360 --> 43:46.360]  Ну, конечно, есть еще такая очень тонкая промежуточная ситуация,
[43:46.360 --> 43:48.360]  когда n, p стремится к константе,
[43:48.360 --> 43:51.360]  ну или вообще никуда не стремится.
[43:51.360 --> 43:55.360]  Давайте ее пока не обсуждать.
[43:55.360 --> 43:57.360]  Ну, как бы прямо противоположно.
[43:57.360 --> 44:02.360]  Да, n, p стремится к нулю, а тут n, p стремится к бесконечности.
[44:02.360 --> 44:05.360]  Я утверждаю, что тогда,
[44:05.360 --> 44:09.360]  и могу уже писать вот так, а симпатически почти наверное
[44:09.360 --> 44:17.360]  g от n, p есть треугольники, хотя бы один.
[44:20.360 --> 44:23.360]  Так, согласитесь, что это прямо противоположная ситуация,
[44:23.360 --> 44:26.360]  то есть там а симпатически почти наверное их не было,
[44:26.360 --> 44:29.360]  здесь они а симпатически почти наверное их есть.
[44:29.360 --> 44:32.360]  Все видят, да? Прямо прямую противоположность.
[44:32.360 --> 44:34.360]  Так, как это доказывать?
[44:34.360 --> 44:38.360]  Ну, давайте возьмем x, это опять будет число треугольников,
[44:38.360 --> 44:41.360]  то же самое, которое здесь обсуждалось,
[44:41.360 --> 44:48.360]  число треугольников в случайном графе g, то же самое.
[44:48.360 --> 44:50.360]  Чего нам нужно доказать?
[44:50.360 --> 44:52.360]  Нам нужно доказать, что вероятность,
[44:52.360 --> 44:57.360]  с которой x больше или равно 1, стремится к одному.
[44:57.360 --> 44:59.360]  Правильно?
[44:59.360 --> 45:02.360]  Есть треугольники, x больше или равно 1.
[45:02.360 --> 45:06.360]  Вот хотим доказать, что она стремится к одному.
[45:06.360 --> 45:09.360]  У нас есть только верхняя оценка, вот эта.
[45:09.360 --> 45:13.360]  И из того, что эта верхняя оценка сейчас стремится к плюсу бесконечности,
[45:13.360 --> 45:15.360]  ничего не следует, правда же?
[45:15.360 --> 45:20.360]  Это же верхняя оценка, что с того, что она дурацкая?
[45:20.360 --> 45:23.360]  Может, образ дурацкий?
[45:23.360 --> 45:26.360]  Вот, поэтому мы будем действовать так.
[45:27.360 --> 45:30.360]  Мы напишем, что это 1.
[45:30.360 --> 45:32.360]  Сейчас, подождите, или так оставить?
[45:32.360 --> 45:33.360]  Нет, правильно, да.
[45:33.360 --> 45:38.360]  Минус вероятность того, что x не превосходит нуля?
[45:38.360 --> 45:43.360]  Ну, это вот прямо ход, знаете, тот самый.
[45:43.360 --> 45:45.360]  Помните, как я вам говорил, что люди думают,
[45:45.360 --> 45:48.360]  что проще посчитать вероятность отсутствия треугольника,
[45:48.360 --> 45:52.360]  если из единицы вычислить вероятность его присутствия?
[45:52.360 --> 45:54.360]  Сейчас я сделал ровно то же самое.
[45:54.360 --> 45:58.360]  Но это поможет, потому что я просто хочу подогнать под неравенство Чебышова.
[45:58.360 --> 46:00.360]  Значит, смотрите, я сейчас...
[46:00.360 --> 46:02.360]  А, что еще может вас смущать?
[46:02.360 --> 46:07.360]  x не больше нуля, но оно может быть меньше нуля.
[46:07.360 --> 46:12.360]  Нет, а я в самом деле так оставлю, чтобы неравенство Чебышова было похожим, формальным, правильно?
[46:12.360 --> 46:13.360]  Послаться.
[46:13.360 --> 46:18.360]  Ну да, да, то есть, друзья, вот кто-нибудь потом начнет перечитывать конспект
[46:18.360 --> 46:21.360]  или пересматривать лекции, если я это не скажу,
[46:21.360 --> 46:24.360]  обязательно может возникнуть упытливого, по крайней мере, человека вопрос,
[46:24.360 --> 46:26.360]  о чем я здесь не написал ровно нуля.
[46:26.360 --> 46:29.360]  Я что, считаю, что x может быть отрицательным?
[46:29.360 --> 46:31.360]  Нет, конечно, я так не считаю,
[46:31.360 --> 46:34.360]  но просто я хочу подогнать под вид неравенского Чебышова.
[46:34.360 --> 46:36.360]  Я его специально нестил.
[46:36.360 --> 46:40.360]  Значит, давайте еще одно смешное преобразование сделаем.
[46:40.360 --> 46:42.360]  Вот такое вот.
[46:42.360 --> 46:44.360]  Ха-ха.
[46:46.360 --> 46:49.360]  Видите, людей проканал. Смешно, правда?
[46:49.360 --> 46:50.360]  Хе-хе.
[46:50.360 --> 46:52.360]  Сейчас еще одно такое же смешное.
[46:52.360 --> 46:55.360]  Один минус, но последнее.
[46:56.360 --> 46:58.360]  Вот так напишу.
[47:03.360 --> 47:08.360]  Ну я просто слева справа добавил неравенство константу, равную мотажеданию х.
[47:08.360 --> 47:12.360]  ex это конкретное число, я его просто слева и справа добавил.
[47:12.360 --> 47:17.360]  Но смотрите как хорошо, тут x-ex, тут ex-x,
[47:17.360 --> 47:20.360]  но если сейчас модуль нарисовать, то какая разница, правда?
[47:20.360 --> 47:24.360]  Ну и, конечно, я хочу сказать, что это больше либо равно,
[47:24.360 --> 47:28.360]  один минус, как раз вероятность, под которой уже стоит модуль,
[47:28.360 --> 47:31.360]  ну я могу также оставить, не меняя знак внутри,
[47:31.360 --> 47:34.360]  больше либо равно единице.
[47:35.360 --> 47:39.360]  Так, понятно, почему получилось неравенство в нужную нам сторону.
[47:39.360 --> 47:42.360]  Мы хотим доказать, что вероятность стремится к единице,
[47:42.360 --> 47:45.360]  поэтому оценивать ее надо снизу.
[47:45.360 --> 47:48.360]  Ну, ясно, что вероятность, которая вычитается,
[47:48.360 --> 47:53.360]  если тут нарисован модуль, больше, чем вероятность, которая вычитается тут,
[47:53.360 --> 47:55.360]  по крайней мере не менее.
[47:56.360 --> 47:59.360]  Модуль чаще бывает больше либо равен чего-то,
[47:59.360 --> 48:02.360]  чем это происходит с подмодульной величиной.
[48:02.360 --> 48:04.360]  В общем, это очевидно.
[48:04.360 --> 48:08.360]  Все, применяем неравенство чьи бы шоума, оно что-то меньше либо равно,
[48:08.360 --> 48:12.360]  но со знаком минус, поэтому неравенство в нужную сторону,
[48:12.360 --> 48:17.360]  включаем больше либо равно 1 минус дисперсия х
[48:17.360 --> 48:21.360]  поделить на квадрат математического ожидания.
[48:24.360 --> 48:30.360]  Заметьте, дорогие товарищи, что все выкладки, которые мы проводили,
[48:30.360 --> 48:34.360]  справедливы не только для числа треугольников,
[48:34.360 --> 48:38.360]  а для любой случайной величины,
[48:38.360 --> 48:43.360]  которая на Омега принимает значение 0, 1, 2 и так далее.
[48:43.360 --> 48:46.360]  То есть множество натуральных чисел.
[48:49.360 --> 48:50.360]  Согласны?
[48:50.360 --> 48:53.360]  Нигде в этих выкладках не использовалось ничего,
[48:53.360 --> 49:00.360]  кроме того, что х это целочисто значная, причем неотрицательная случайная величина.
[49:00.360 --> 49:04.360]  Вот здесь использовалось, что она целочисто значная,
[49:04.360 --> 49:06.360]  ну и, собственно говоря, все.
[49:08.360 --> 49:13.360]  То есть эту идею можно использовать не только для числа треугольников,
[49:13.360 --> 49:17.360]  но для любой какой-нибудь счетчика, для любого счетчика на графе.
[49:17.360 --> 49:22.360]  Можно взять число К4, можно взять число независимых множеств какого-то размера,
[49:22.360 --> 49:26.360]  можно взять число цепей или циклов или еще чего-то,
[49:26.360 --> 49:29.360]  и для них и для всех это будет верное неравенство.
[49:29.360 --> 49:30.360]  Поняли, да?
[49:33.360 --> 49:37.360]  Ну что осталось доказать для завершения доказательства теории?
[49:38.360 --> 49:42.360]  Что дисперсия мала по сравнению с квадратом математического ожидания.
[49:42.360 --> 49:43.360]  Верно?
[49:43.360 --> 49:44.360]  Да.
[49:44.360 --> 49:47.360]  Если мы докажем, что эта дробь стремится к нулю,
[49:47.360 --> 49:49.360]  то мы получим стремление к единице.
[49:52.360 --> 49:53.360]  Так, прекрасно.
[49:54.360 --> 49:56.360]  Все, я стираю неравенство Чебышова.
[49:57.360 --> 50:01.360]  Поскольку я про хроматические числа сегодня уже ничего не успею,
[50:01.360 --> 50:06.360]  мне пришлось читать такую лекцию вводную по вероятностным вещам,
[50:06.360 --> 50:08.360]  но случайные графы тоже присутствуют, все хорошо.
[50:09.360 --> 50:11.360]  Давайте я докажу это до конца.
[50:12.360 --> 50:16.360]  Заодно вы поймете очень важную вещь, которую я пока не произнес.
[50:17.360 --> 50:19.360]  И тогда у вас откроются глаза.
[50:23.360 --> 50:25.360]  Это даже не катарсис, это прозрение.
[50:27.360 --> 50:28.360]  Так, ладно.
[50:30.360 --> 50:31.360]  Слушайте, мат ожидания мы знаем.
[50:32.360 --> 50:33.360]  Что такое мат ожидания?
[50:34.360 --> 50:35.360]  Ой, зачем скопки?
[50:35.360 --> 50:38.360]  Мат ожидания это С из Н по 3 на П в кубе.
[50:39.360 --> 50:40.360]  Вот оно еще тут сохранилось.
[50:41.360 --> 50:42.360]  Хорошо?
[50:43.360 --> 50:44.360]  А вот дисперсию надо посчитать.
[50:45.360 --> 50:48.360]  Ну, для дисперсии я писал сегодня удобную формулу.
[50:49.360 --> 50:54.360]  Это е х квадрат минус квадрат ех.
[50:56.360 --> 50:58.360]  То есть фактически нас интересует вот это.
[50:59.360 --> 51:03.360]  Ну видите, я не зря, как я уже говорил, не зря вот это написал.
[51:03.360 --> 51:04.360]  Кому-то было непонятно.
[51:05.360 --> 51:06.360]  Я линейности объяснил.
[51:07.360 --> 51:08.360]  А заодно это сейчас пригодится.
[51:09.360 --> 51:11.360]  Давайте просто вот эту сумму возведем в квадрат.
[51:12.360 --> 51:14.360]  Сейчас вот возведем в квадрат.
[51:15.360 --> 51:17.360]  То есть я считаю второй момент ех квадрат.
[51:18.360 --> 51:20.360]  Беру ех1 плюс и т.д.
[51:21.360 --> 51:22.360]  Плюс х С из Н по 3.
[51:23.360 --> 51:25.360]  Вот эти самые индикаторы, которые там написаны.
[51:26.360 --> 51:27.360]  И возвожу в квадрат.
[51:28.360 --> 51:30.360]  Ну, люди, которые учили в свое время полинамиальные коэффициенты,
[51:30.360 --> 51:33.360]  в квадрат сумму многих величин могут возвести.
[51:34.360 --> 51:35.360]  Правильно?
[51:36.360 --> 51:37.360]  Так, что же у нас получится?
[51:38.360 --> 51:40.360]  Во-первых, будет сумма квадрата.
[51:45.360 --> 51:46.360]  А, будет?
[51:47.360 --> 51:50.360]  А, во-вторых, будет сумма по и неравном ж.
[51:51.360 --> 51:53.360]  х и т на и ж и т.
[51:53.360 --> 52:03.360]  Ну, имеется в виду, что здесь и ж и ж и это разные вещи, поэтому я двойку не рисую.
[52:04.360 --> 52:08.360]  То есть здесь n умножить на n-1 слагаемых, а не С из Н по 2.
[52:09.360 --> 52:13.360]  Раскрываем по линейности и кое-что еще замечаем.
[52:14.360 --> 52:15.360]  Знаете почему?
[52:16.360 --> 52:17.360]  Потому что это 0 и 1.
[52:18.360 --> 52:20.360]  Что в квадрат-то возводить, если 0 и 1?
[52:21.360 --> 52:22.360]  Успеваете?
[52:23.360 --> 52:27.360]  Понятно, это 0 или 1, поэтому в квадрате то же самое, что без квадрата.
[52:28.360 --> 52:32.360]  Тогда вот эта часть по линейности это снова мата ожидания, которая мы знаем.
[52:35.360 --> 52:40.360]  У нас получается мата ожидания, вот оно, я его не буду переписывать.
[52:41.360 --> 52:47.360]  Плюс сумма по и неравно ж, мата ожидания х и т умножить на и ж и т.
[52:48.360 --> 52:53.360]  Ну, бог вас знает до каких высот вы добрались в вашем нематематическом плане.
[52:54.360 --> 52:56.360]  Математическом до этого вы точно не добрались.
[52:57.360 --> 53:02.360]  Но может быть вы знаете, что если бы эти величины были независимы, то мата ожидания было бы равно произведению.
[53:03.360 --> 53:05.360]  Но они независимы, к сожалению.
[53:06.360 --> 53:14.360]  Ну, потому что и т по счету, и т по счету тройка точек может образовывать треугольник, и ж и т по счету, вот смотрите, и т по счету тройка точек.
[53:14.360 --> 53:18.360]  А вот ж и т по счету тройка точек, вершин, да?
[53:19.360 --> 53:26.360]  И т по счету тройка вершин, скажем, один, два, три, и ж и т по счету тройка вершин, скажем, один, три, четыре.
[53:27.360 --> 53:31.360]  Наличие треугольника на этой тройке, наверное, что-то говорит о появлении его здесь.
[53:32.360 --> 53:33.360]  То есть, величины эти зависимы.
[53:34.360 --> 53:38.360]  Ни в коем случае, конечно, нельзя считать, что мата ожидания произведения это произведение мата ожидания.
[53:39.360 --> 53:40.360]  Не гоню?
[53:40.360 --> 53:42.360]  Да, нормально?
[53:43.360 --> 53:46.360]  Ну, так все на картинке дорисовано, как посчитать?
[53:47.360 --> 53:49.360]  Мне придется перерисовать и икс.
[53:52.360 --> 53:54.360]  Надо просто рассмотреть три случая.
[53:55.360 --> 54:00.360]  Может быть, вот такая картина, одна тройка, и другая тройка.
[54:01.360 --> 54:06.360]  Может быть, вот такая картина, одна тройка, и другая тройка, и вот такая.
[54:07.360 --> 54:08.360]  Первая, вторая.
[54:08.360 --> 54:12.360]  Вторая, третий не отличается с точки зрения того, в какую степень П возводить,
[54:13.360 --> 54:16.360]  но с точки зрения подсчета удобно их разделить.
[54:17.360 --> 54:19.360]  Я понятно сказал для всех, да?
[54:20.360 --> 54:22.360]  То есть, что у нас получается?
[54:23.360 --> 54:24.360]  Давайте я вот эти конструкции посчитаю.
[54:25.360 --> 54:26.360]  Совсем просто.
[54:27.360 --> 54:33.360]  Это C из N по три, количество способов выбрать первые три вершины, умножить на C из N минус три по три.
[54:34.360 --> 54:37.360]  Это оставший за оставшихся N минус трех выбрать еще три вершины.
[54:39.360 --> 54:44.360]  Я не делю пополам, потому что пары тройок у меня упорядоченные.
[54:45.360 --> 54:49.360]  Я вот здесь не рисовал коэффициент двойка, соответственно, тут я не делю пополам.
[54:50.360 --> 54:52.360]  Знаю, что это всегда напрягает, но вот так.
[54:53.360 --> 55:00.360]  Так, умножить на P в шестой, но это вероятность того, что и тут треугольник, и тут треугольник.
[55:01.360 --> 55:02.360]  Шесть треугольников, значит, P в шестой.
[55:03.360 --> 55:08.360]  Так, вот здесь тоже будет P в шестой, но количество считается вот так.
[55:11.360 --> 55:15.360]  Так, вот так, на P в шестой.
[55:17.360 --> 55:18.360]  Еще раз, почему так?
[55:19.360 --> 55:21.360]  Три вершины выбираем, C из N по три способами.
[55:22.360 --> 55:24.360]  Общую вершину выбираем, любым из трех.
[55:25.360 --> 55:30.360]  После того, как она выбрана, еще две из N минус трех оставшихся, да выберем.
[55:32.360 --> 55:36.360]  Ну и плюс вот эта как раз ситуация, в которой единственная есть зависимость,
[55:37.360 --> 55:38.360]  поэтому получается не в шестой, а в пятый.
[55:39.360 --> 55:41.360]  Тут пять ребер, это общая, ребер пять.
[55:42.360 --> 55:48.360]  Так, C из N по три, снова на три, потому что вот эти две общие вершины выбираются тремя способами.
[55:49.360 --> 55:55.360]  Так, и на C, ну можно не на C, конечно, просто на N минус три.
[55:56.360 --> 55:58.360]  На C из N минус трех по одному.
[55:58.360 --> 56:02.360]  Вот эту одну четвертую вершину надо выбрать откуда-то из N минус трех оставшихся.
[56:03.360 --> 56:06.360]  И здесь на P в пятой степени.
[56:12.360 --> 56:14.360]  Так, друзья, все понятно?
[56:15.360 --> 56:19.360]  Нужно ли проводить противную выкладку или можно оставить ее вам как упражнение?
[56:20.360 --> 56:21.360]  Какую?
[56:21.360 --> 56:22.360]  Какую?
[56:23.360 --> 56:28.360]  Надо же разделить посчитанную только что дисперсию на квадрат математического ожидания.
[56:29.360 --> 56:31.360]  Провести, наверное, да, ленитесь.
[56:33.360 --> 56:38.360]  Проведите сами эту выкладку, мы все посчитали, смотрите, мы посчитали только что второй момент.
[56:39.360 --> 56:45.360]  Вот он, вот эта вот правая часть, омерзительное длинное выражение, которое полностью вычисляет второй момент.
[56:46.360 --> 56:50.360]  Из него надо вычесть квадрат мат ожидания и поделить на квадрат мат ожидания.
[56:51.360 --> 56:57.360]  И нужно убедиться, что, да, в тех условиях, в которых мы живем, получается в пределе ноль.
[56:58.360 --> 57:00.360]  Можно оставлю как упражнение?
[57:01.360 --> 57:04.360]  Давайте, потому что это как-то не совсем затевая вещь.
[57:05.360 --> 57:07.360]  Но здесь реально важно следующее.
[57:08.360 --> 57:14.360]  Вы понимаете, почему самого факта, что мат ожидания все-таки стремится к бесконечности, недостаточно?
[57:15.360 --> 57:19.360]  Вот есть случайная величина, она принимает какие-то значения.
[57:20.360 --> 57:25.360]  Средняя растет, но разброс может быть настолько большим,
[57:26.360 --> 57:31.360]  что вероятность, с которой случайная величина принимает хоть какое-нибудь разумное значение,
[57:32.360 --> 57:36.360]  ну скажем, больше либо равные единицы, не стремится к одному, можете привести такие примеры.
[57:37.360 --> 57:39.360]  Нам очень важно, что дисперсия маленькая.
[57:40.360 --> 57:43.360]  Вот мы ее там как-то посчитали и убедились, что она маленькая.
[57:44.360 --> 57:47.360]  За счет того, что она маленькая, и получился результат теории М2.
[57:48.360 --> 57:51.360]  А теперь, товарищи, обещанное прозрение.
[57:55.360 --> 57:57.360]  Сейчас, могу вот эту часть стереть?
[57:58.360 --> 57:59.360]  Наверное, да.
[58:00.360 --> 58:02.360]  Ну я не буду считать, поэтому, мне кажется, я могу ее стереть.
[58:03.360 --> 58:04.360]  Так-то все понятно?
[58:17.360 --> 58:18.360]  Вот.
[58:19.360 --> 58:20.360]  Прозрение.
[58:21.360 --> 58:22.360]  Хе-хе.
[58:23.360 --> 58:27.360]  Помните, вероятность х больше либо равно единицы,
[58:28.360 --> 58:31.360]  х от числа треугольника, от задачки, помните, была задачка?
[58:32.360 --> 58:33.360]  Так.
[58:34.360 --> 58:40.360]  Мы сказали, что это вероятность объединения по И от единицы до С из Н по три аито.
[58:41.360 --> 58:44.360]  Аито, товарищи, оно вот здесь присутствует.
[58:44.360 --> 58:49.360]  Вот этот мод, это и есть АИТ, на самом деле.
[58:51.360 --> 58:52.360]  Согласны?
[58:53.360 --> 58:55.360]  Это очень важно. Согласны, что это АИТ?
[58:56.360 --> 58:58.360]  ИТ по счету тройка образует треугольник.
[58:59.360 --> 59:03.360]  Вы мне говорили, что это про формулу включения и исключения, но мы-то с вами ее знаем.
[59:04.360 --> 59:09.360]  Мы даже ее выводили из обобщенного обращения мебиоса.
[59:10.360 --> 59:11.360]  Мы ведь много еще выводили.
[59:11.360 --> 59:12.360]  Нет, ну конечно, да.
[59:13.360 --> 59:17.360]  То есть формула включения и исключения для вас это прямо такое фундаментальное знание.
[59:18.360 --> 59:19.360]  Но она начинается с чего?
[59:20.360 --> 59:21.360]  Ой, Господи, что я нарисовал.
[59:22.360 --> 59:28.360]  Вероятность А1, плюс и так далее, плюс вероятность АС из Н по три.
[59:29.360 --> 59:30.360]  Это что такое?
[59:31.360 --> 59:36.360]  Это С из Н по три умножить на П в кубе, правда?
[59:37.360 --> 59:39.360]  То есть это математическое ожидание Х.
[59:40.360 --> 59:42.360]  Я сейчас ничего не доказываю.
[59:43.360 --> 59:47.360]  Я пытаюсь вам рассказать некую суть, чтобы у вас возникло понимание картины мира.
[59:48.360 --> 59:49.360]  Постарайтесь в этом слушаться.
[59:50.360 --> 59:52.360]  Дальше. Чем она продолжается, эта формула?
[59:53.360 --> 59:56.360]  Надо вычесть всевозможные попарные пересечения.
[59:56.360 --> 01:00:13.360]  А1, А2, минус АС из Н по три, минус 1, АС из Н по три.
[01:00:14.360 --> 01:00:15.360]  Так, правильно написал, да?
[01:00:19.360 --> 01:00:21.360]  А теперь смотрите вот сюда.
[01:00:21.360 --> 01:00:26.360]  Что такое х и т умножить на х ж и т?
[01:00:27.360 --> 01:00:30.360]  Ну даже не сюда, это я чуть-чуть подстер, а вот сюда.
[01:00:31.360 --> 01:00:35.360]  Уже когда мат ожидания занесено внутрь, у нас получается вот так.
[01:00:36.360 --> 01:00:38.360]  Нет? Х и т х ж и т.
[01:00:39.360 --> 01:00:41.360]  Это вот то, что мы посчитали и потом вот тут стерли.
[01:00:42.360 --> 01:00:43.360]  Согласны?
[01:00:44.360 --> 01:00:45.360]  Ну это как раз прояснится того, что...
[01:00:46.360 --> 01:00:49.360]  Друзья, вы понимаете, что это и есть вот эта сумма?
[01:00:49.360 --> 01:00:50.360]  Вот эта сумма.
[01:00:55.360 --> 01:00:56.360]  Все понимают?
[01:00:58.360 --> 01:01:01.360]  Что значит х и т х ж и т равно единице?
[01:01:02.360 --> 01:01:06.360]  Это значит одновременно х и т равно единице, то есть выполнено аи и т,
[01:01:07.360 --> 01:01:09.360]  и х ж и т равно единице, то есть выполнено ажи и т.
[01:01:10.360 --> 01:01:11.360]  То есть это пересечение аи и т в ажи и т.
[01:01:12.360 --> 01:01:19.360]  То есть вот эта штуковина, вычисленная нами в процессе доказательства теоремы 2,
[01:01:20.360 --> 01:01:23.360]  это вычитаемая формуле включения и исключения.
[01:01:24.360 --> 01:01:27.360]  Таким образом, неравенство Маркова, в котором участвует мат ожидания,
[01:01:28.360 --> 01:01:31.360]  отвечает за первую часть формулы включения и исключения,
[01:01:32.360 --> 01:01:35.360]  а неравенство Чебышова, в котором присутствует дисперсия,
[01:01:36.360 --> 01:01:40.360]  выражающаяся фактически через это, если забыть про уже вычисленное мат ожидания.
[01:01:41.360 --> 01:01:44.360]  Это отвечает за вторую часть формулы включения и исключения.
[01:01:49.360 --> 01:01:50.360]  Вы почувствовали смысл, да?
[01:01:51.360 --> 01:01:52.360]  Что смысл?
[01:01:53.360 --> 01:01:56.360]  То есть в принципе можно там дальше еще что-то написать,
[01:01:57.360 --> 01:01:59.360]  и это будут третий момент, четвертый момент,
[01:02:00.360 --> 01:02:03.360]  потому что там будут возникать пересечения трех, четырех событий,
[01:02:04.360 --> 01:02:07.360]  соответствующие произведениям трех, четырех и так далее случайных величин,
[01:02:07.360 --> 01:02:11.360]  то есть возведению в куб, в четвертую степень и так далее исходного количества треугольников.
[01:02:15.360 --> 01:02:17.360]  Вот сейчас по темпу нормально?
[01:02:18.360 --> 01:02:19.360]  Понятен смысл, да?
[01:02:20.360 --> 01:02:23.360]  Это очень важно понимать, что тут ничего такого шумного,
[01:02:24.360 --> 01:02:25.360]  просто формула включения и исключения,
[01:02:26.360 --> 01:02:30.360]  и конечно, если мы ее обрываем здесь, то получается неравенство в одну сторону,
[01:02:31.360 --> 01:02:33.360]  а если мы добавляем минусы, то в другую,
[01:02:34.360 --> 01:02:35.360]  потом добавляем еще какие-то плюсы,
[01:02:35.360 --> 01:02:37.360]  опять будет в одну сторону, вычитаем?
[01:02:38.360 --> 01:02:39.360]  А почему это, конечно?
[01:02:40.360 --> 01:02:41.360]  Почему это очевидно?
[01:02:42.360 --> 01:02:46.360]  Ну может быть и не очевидно, но вот так получилось.
[01:02:47.360 --> 01:02:48.360]  Это очевидно, но...
[01:02:49.360 --> 01:02:51.360]  Не-не, ну смотрите, давайте так, я же сейчас ничего не доказываю,
[01:02:52.360 --> 01:02:53.360]  а просто пытаюсь объяснить суть происходящего.
[01:02:54.360 --> 01:02:56.360]  Вот до второго момента мы это доказали,
[01:02:57.360 --> 01:02:58.360]  а то, что так же будет с третьим и с четвертым,
[01:02:59.360 --> 01:03:02.360]  конечно это надо доказывать, но интуитивно понятно, что так и будет.
[01:03:02.360 --> 01:03:06.360]  Другое дело, что обычно в комбинаторике третьи и четвертые моменты возникают,
[01:03:07.360 --> 01:03:08.360]  на этом мы сейчас закончим лекцию,
[01:03:09.360 --> 01:03:13.360]  в том случае, когда NP не стремится ни к нулю, ни к бесконечности,
[01:03:14.360 --> 01:03:15.360]  потому что вы же все-таки интересуетесь,
[01:03:16.360 --> 01:03:17.360]  а что же будет вот на этой тонкой грани?
[01:03:18.360 --> 01:03:19.360]  У меня очень длитонная красновидность.
[01:03:20.360 --> 01:03:21.360]  Толстая, да?
[01:03:22.360 --> 01:03:23.360]  Все конечные.
[01:03:24.360 --> 01:03:27.360]  Не, ну слушайте, она куда тоньше, чем многообразие функций с этим свойством или противоположным?
[01:03:28.360 --> 01:03:29.360]  Все-таки.
[01:03:29.360 --> 01:03:30.360]  Все-таки.
[01:03:31.360 --> 01:03:33.360]  Ну, посмотрите, NP стремится к нулю, это П может каким угодно,
[01:03:34.360 --> 01:03:37.360]  хоть E в минус N, хоть 1 поделить на N лог N, там, каким хотите.
[01:03:38.360 --> 01:03:39.360]  А если NP стремится к константе,
[01:03:40.360 --> 01:03:43.360]  то вы ограничиваетесь уже П-шками, которые ведут себя как это константа,
[01:03:44.360 --> 01:03:45.360]  поделенная на N, грубо говоря.
[01:03:46.360 --> 01:03:47.360]  А вы, кстати, да.
[01:03:48.360 --> 01:03:50.360]  Это не такое уж жирное множество, это множество всех константов,
[01:03:51.360 --> 01:03:53.360]  а тут множество всех совершенно разнообразных функций.
[01:03:54.360 --> 01:03:55.360]  Ну и так же.
[01:03:56.360 --> 01:03:57.360]  Еще раз, я не рассматриваю случаи,
[01:03:57.360 --> 01:03:58.360]  когда предела нет вообще,
[01:03:59.360 --> 01:04:00.360]  потому что непонятно, что с ним делать,
[01:04:01.360 --> 01:04:02.360]  он мне очень интересен.
[01:04:03.360 --> 01:04:04.360]  Теорема 3.
[01:04:05.360 --> 01:04:06.360]  Я ее не буду доказывать.
[01:04:07.360 --> 01:04:08.360]  В этом курсе,
[01:04:09.360 --> 01:04:11.360]  в этом курсе я ее доказывать не буду,
[01:04:12.360 --> 01:04:13.360]  но это полезная очень вещь,
[01:04:14.360 --> 01:04:15.360]  понимать, что происходит в теореме 3.
[01:04:16.360 --> 01:04:18.360]  Значит, пусть у нас опять
[01:04:20.360 --> 01:04:22.360]  уже от NP,
[01:04:23.360 --> 01:04:26.360]  так я просто напишу, NP стремится к C,
[01:04:27.360 --> 01:04:28.360]  но, естественно, большие нуля.
[01:04:31.360 --> 01:04:32.360]  То есть,
[01:04:34.360 --> 01:04:38.360]  P ведет себя симпатически как C поделенная.
[01:04:39.360 --> 01:04:40.360]  Запомните этот режим,
[01:04:41.360 --> 01:04:42.360]  он еще будет пригождаться нам в дальнейшем.
[01:04:43.360 --> 01:04:44.360]  Это очень важная ситуация,
[01:04:45.360 --> 01:04:46.360]  в которой кое-что происходит,
[01:04:47.360 --> 01:04:48.360]  но это не скоро.
[01:04:49.360 --> 01:04:50.360]  Пойдем.
[01:04:50.360 --> 01:04:51.360]  Попробуем однопропорционально
[01:04:52.360 --> 01:04:53.360]  количество вершин в графе.
[01:04:54.360 --> 01:04:55.360]  Тогда
[01:04:57.360 --> 01:04:58.360]  вероятность того,
[01:04:59.360 --> 01:05:01.360]  что в случайном графе нет треугольников,
[01:05:02.360 --> 01:05:04.360]  х равно нулю, это нет треугольников,
[01:05:07.360 --> 01:05:08.360]  стремится
[01:05:10.360 --> 01:05:11.360]  к Е
[01:05:12.360 --> 01:05:13.360]  в степени,
[01:05:15.360 --> 01:05:16.360]  ага,
[01:05:17.360 --> 01:05:19.360]  нет треугольников, да,
[01:05:20.360 --> 01:05:21.360]  все хорошо.
[01:05:22.360 --> 01:05:23.360]  Е в степени
[01:05:24.360 --> 01:05:25.360]  минус C в кубе на 6.
[01:05:27.360 --> 01:05:28.360]  Нет, ну тут, на самом деле,
[01:05:29.360 --> 01:05:30.360]  для людей, которые смотрят
[01:05:31.360 --> 01:05:32.360]  на левую часть доски,
[01:05:33.360 --> 01:05:34.360]  ничего страшного нет,
[01:05:35.360 --> 01:05:36.360]  потому что, ну давайте, я пройдусь к левой части доски,
[01:05:37.360 --> 01:05:38.360]  смотрите, мат ожидания
[01:05:39.360 --> 01:05:41.360]  х, это вот такая величина всегда,
[01:05:42.360 --> 01:05:43.360]  и в текущей ситуации
[01:05:44.360 --> 01:05:45.360]  она ведет себя симпатически в аккурат
[01:05:46.360 --> 01:05:47.360]  как C в кубе поделить на 6.
[01:05:47.360 --> 01:05:48.360]  Подставьте сюда
[01:05:49.360 --> 01:05:50.360]  P равное C поделить на N.
[01:05:52.360 --> 01:05:53.360]  У вас N в кубе сократится,
[01:05:54.360 --> 01:05:55.360]  а C в кубе на 6 останется.
[01:05:56.360 --> 01:05:57.360]  То есть, вот этот вот показатель
[01:05:58.360 --> 01:05:59.360]  экспоненты со знаком минус,
[01:06:00.360 --> 01:06:03.360]  это просто асимптотика математического ожидания х.
[01:06:04.360 --> 01:06:06.360]  Вот она каким-то боком здесь вылезает.
[01:06:09.360 --> 01:06:10.360]  Ну, я не расскажу, каким.
[01:06:11.360 --> 01:06:12.360]  Я ж не доказываю тебе.
[01:06:14.360 --> 01:06:15.360]  Задача со звездочкой.
[01:06:15.360 --> 01:06:16.360]  Нет, ну это сложная задача,
[01:06:17.360 --> 01:06:18.360]  сами не докажете.
[01:06:19.360 --> 01:06:20.360]  Нет-нет, скорее всего, сами не докажете,
[01:06:21.360 --> 01:06:22.360]  потому что тут надо какое-то,
[01:06:23.360 --> 01:06:24.360]  ну надо посмотреть, как ведет себя
[01:06:25.360 --> 01:06:26.360]  вот эта формула включения-исключения
[01:06:27.360 --> 01:06:28.360]  на всех вообще слаганях.
[01:06:29.360 --> 01:06:30.360]  Вот честно ее вычислить.
[01:06:31.360 --> 01:06:32.360]  Ну это можно.
[01:06:33.360 --> 01:06:35.360]  В данной ситуации это можно сделать.
[01:06:36.360 --> 01:06:37.360]  Друзья, еще раз, это ни в коем случае
[01:06:38.360 --> 01:06:39.360]  не задача на десятку на экзамене.
[01:06:40.360 --> 01:06:41.360]  Это...
[01:06:42.360 --> 01:06:43.360]  Ну нет.
[01:06:44.360 --> 01:06:45.360]  Не надо.
[01:06:46.360 --> 01:06:47.360]  Это просто, чтобы вы понимали,
[01:06:48.360 --> 01:06:49.360]  как мир устроен.
[01:06:50.360 --> 01:06:51.360]  Ну вот я не могу все рассказать в этом курсе,
[01:06:52.360 --> 01:06:53.360]  хоть он и большой.
[01:06:54.360 --> 01:06:55.360]  И вас кокнет, и времени просто не хватит,
[01:06:56.360 --> 01:06:57.360]  даже несмотря на то, что курс большой.
[01:06:58.360 --> 01:06:59.360]  Я думаю, что этот метод мы разбирать
[01:07:00.360 --> 01:07:01.360]  все-таки не станем.
[01:07:02.360 --> 01:07:03.360]  Называется он метод моментов,
[01:07:04.360 --> 01:07:05.360]  что вполне ожидаемо.
[01:07:06.360 --> 01:07:07.360]  Это вот как раз к вопросу Тихона,
[01:07:08.360 --> 01:07:09.360]  ну как доказать?
[01:07:10.360 --> 01:07:11.360]  Вот если доказывать эту теорему,
[01:07:11.360 --> 01:07:12.360]  я думаю, что вот доказано
[01:07:13.360 --> 01:07:14.360]  отвечающими за то, что я сказал.
[01:07:19.360 --> 01:07:20.360]  Так.
[01:07:21.360 --> 01:07:22.360]  Ну, смотрите, мне кажется...
[01:07:23.360 --> 01:07:24.360]  А!
[01:07:25.360 --> 01:07:26.360]  Ну да.
[01:07:27.360 --> 01:07:28.360]  Мне кажется, что я все сказал
[01:07:29.360 --> 01:07:30.360]  для того, чтобы в следующий раз перейти
[01:07:31.360 --> 01:07:32.360]  наконец к раскраскам графов,
[01:07:33.360 --> 01:07:34.360]  как я и обещал.
[01:07:35.360 --> 01:07:36.360]  Мы используем там и неравенство Маркова,
[01:07:37.360 --> 01:07:38.360]  и неравенство Чебышова,
[01:07:39.360 --> 01:07:40.360]  и еще одно неравенство,
[01:07:41.360 --> 01:07:42.360]  и в следующий раз
[01:07:45.360 --> 01:07:46.360]  в следующий раз займемся раскрасками.
[01:07:47.360 --> 01:07:48.360]  Хорошо?
[01:07:49.360 --> 01:07:50.360]  А неравенство, которое я говорил,
[01:07:51.360 --> 01:07:52.360]  помните, говорил третье неравенство,
[01:07:53.360 --> 01:07:54.360]  третье, там люди будут смотреть
[01:07:55.360 --> 01:07:56.360]  запись, а где третье?
[01:07:57.360 --> 01:07:59.360]  А я его сейчас не успел, товарищи.
[01:08:00.360 --> 01:08:01.360]  Это не страшно, потому что
[01:08:02.360 --> 01:08:03.360]  для следующей лекции оно не нужно.
[01:08:04.360 --> 01:08:05.360]  Вот на следующей лекции я расскажу
[01:08:06.360 --> 01:08:07.360]  красивые вещи про хроматические числа,
[01:08:08.360 --> 01:08:09.360]  а потом, если останется время,
[01:08:09.360 --> 01:08:10.360]  вернусь к третьему неравенству.
[01:08:11.360 --> 01:08:12.360]  Всем спасибо.
[01:08:13.360 --> 01:08:15.360]  АПЛОДИСМЕНТЫ
