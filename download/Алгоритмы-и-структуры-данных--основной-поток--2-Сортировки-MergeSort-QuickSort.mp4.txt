[00:00.000 --> 00:16.160]  Сегодня мы начинаем говорить про задачу сортировки.
[00:16.160 --> 00:19.360]  Ну и, наверное, в ближайшие пару лекций будем изучать
[00:19.360 --> 00:20.360]  всякие сортировки.
[00:20.360 --> 00:24.160]  Значит, задача ставится очень простым образом.
[00:24.160 --> 00:28.800]  Представьте себе, что у вас есть массив.
[00:28.800 --> 00:31.360]  Пока не буду уточнять массив чего, давайте считаем, что
[00:31.360 --> 00:32.360]  массив каких-то объектов.
[00:32.360 --> 00:36.440]  И мы считаем, что над этими объектами определена операция
[00:36.440 --> 00:37.440]  сравнения.
[00:37.440 --> 00:39.880]  То есть по двум объектам мы можем однозначно сказать,
[00:39.880 --> 00:43.000]  кто из них больше или меньше, или, может быть, они равны.
[00:43.000 --> 00:47.080]  То есть на объектах определено отношение порядка.
[00:47.080 --> 00:50.280]  Ну и наша задача как-то их так переставить, чтобы
[00:50.280 --> 00:52.160]  они шли в возрастающем порядке.
[00:52.160 --> 01:08.720]  Надо их переставить таким образом, чтобы они шли в формально
[01:08.720 --> 01:09.720]  необувающем порядке.
[01:09.720 --> 01:24.200]  Вот, да, например, если у меня есть какой-нибудь
[01:24.200 --> 01:25.200]  массив.
[01:25.200 --> 01:26.200]  Ну давайте чисел.
[01:26.200 --> 01:30.080]  Там два, десять, семь, девять.
[01:30.080 --> 01:33.760]  Ну это неинтересно, давайте здесь три еще напишу.
[01:33.760 --> 01:36.960]  Да, то понятно, после сортировки мне нужно просто числа расположить
[01:36.960 --> 01:37.960]  в порядке возрастания.
[01:38.440 --> 01:41.480]  Будет два, три, семь, десять.
[01:41.480 --> 01:46.520]  Вот, это простая формулировка задачи о сортировке, надо
[01:46.520 --> 01:49.040]  просто переставить числа, чтобы они шли в порядке
[01:49.040 --> 01:50.040]  возрастания.
[01:50.040 --> 01:53.800]  Чуть более точная формулировка была бы в том, что нам нужно
[01:53.800 --> 01:57.600]  не просто их переставить и вывести результирующий
[01:57.600 --> 02:01.620]  массив, да, просто порядок возрастания, но еще и сказать
[02:01.620 --> 02:04.160]  конкретно, как именно я переставил элементы, так
[02:04.160 --> 02:07.480]  чтобы у меня получилась ровно такой порядок исследования
[02:07.480 --> 02:08.480]  элементов.
[02:08.480 --> 02:11.800]  То есть формально, давайте я напишу расширенная задача
[02:11.800 --> 02:12.800]  сортировки, что ли.
[02:22.400 --> 02:25.160]  Это найти конкретный способ перестановки, то есть как
[02:25.160 --> 02:27.680]  именно вот эти элементы нужно так между собой переставить,
[02:27.680 --> 02:30.760]  то есть формально надо указать на какое место вставит вот
[02:30.760 --> 02:32.960]  эта двойка, на какое место эта десятка, на какое место
[02:32.960 --> 02:34.800]  семерка, на какое место тройка.
[02:34.800 --> 02:36.640]  Формально напишу следующим образом.
[02:36.640 --> 02:38.120]  Нужно найти такую перестановку.
[02:43.120 --> 02:48.320]  Сигма как функция из 1,2 и так далее n в 1,2 и так далее
[02:48.320 --> 02:54.920]  n, что после применения этой перестановки к индексам
[02:54.920 --> 02:57.480]  массива у нас получается неубывающий массив.
[02:57.480 --> 03:00.640]  То есть формально a с индексом сигма от единицы не больше
[03:00.640 --> 03:04.360]  чем a с индексом сигма от двойки и так далее вплоть до
[03:04.400 --> 03:05.800]  a с индексом сигма от n.
[03:10.800 --> 03:13.160]  То есть мне нужно не только результирующим массив в
[03:13.160 --> 03:15.800]  порядке возрастания чисел вывести, в порядке возрастания
[03:15.800 --> 03:18.760]  элементов, но и именно сказать, кто на каком месте стоит.
[03:18.760 --> 03:23.120]  Что первый элемент, ну точнее, на первом месте стоит
[03:23.120 --> 03:25.240]  элемент сигма 1, на втором месте стоит элемент сигма
[03:25.240 --> 03:26.920]  2 и так далее в исходном номерации.
[03:26.920 --> 03:28.520]  То есть как именно переставить элементы, чтобы получить
[03:28.520 --> 03:29.520]  такой порядок.
[03:29.520 --> 03:32.520]  Так, перестановка, вот это никого не пугает, нормально
[03:32.520 --> 03:33.520]  все.
[03:33.680 --> 03:34.680]  Ну хорошо.
[03:40.680 --> 03:45.040]  Давайте начнем со следующего несложного факта, что если
[03:45.040 --> 03:48.680]  мы хотим построить, ну давайте я буду решать вот эту задачу
[03:48.680 --> 03:51.480]  расширенную, она не шибко интереснее, там то же самое
[03:51.480 --> 03:54.880]  всегда получается, давайте решать обычную задачу сортировки
[03:54.880 --> 03:57.840]  просто переупорядочения какого-то переупорядочения
[03:57.840 --> 03:58.840]  элементов.
[03:58.840 --> 04:01.720]  Так вот, я утверждаю, что если мы рассмотрим произвольный
[04:01.720 --> 04:05.560]  алгоритм, который основан на сравнениях, то есть все,
[04:05.560 --> 04:09.120]  что он умеет делать с элементами массива, это только сравнивать
[04:09.120 --> 04:10.120]  их между собой.
[04:10.120 --> 04:12.520]  То есть вот попарно взять два элемента, посмотреть
[04:12.520 --> 04:14.680]  на них, кто из них больше-менше, в зависимости от результатов
[04:14.680 --> 04:17.120]  взвешивания, в зависимости от результатов сравнения,
[04:17.120 --> 04:18.120]  делать что-то дальше.
[04:18.120 --> 04:31.200]  Так вот, давайте нашу любой алгоритм сортировки.
[04:31.720 --> 04:57.440]  Основанный на сравнениях требует омега от n лог n сравнений
[04:57.440 --> 05:08.040]  для массива длины n.
[05:08.040 --> 05:11.000]  То есть в предположении, что наш алгоритм ничего
[05:11.000 --> 05:13.120]  больше не умеет делать с элементами массива, кроме
[05:13.120 --> 05:17.140]  как их попарно сравнивать, вот в таком предположении
[05:17.140 --> 05:19.760]  нам нужно хотя бы столько сравнений.
[05:19.760 --> 05:22.480]  Напоминаю, омега это оценка снизу, то есть здесь написано
[05:22.480 --> 05:26.560]  там большее обравно c умножено n лог n сравнений для какого-то
[05:26.560 --> 05:27.560]  положительного c.
[05:27.560 --> 05:30.800]  Значит, что это за модель, почему мы можем только сравнивать
[05:30.800 --> 05:31.800]  элемент?
[05:31.800 --> 05:33.760]  Ну представьте, что у вас вряд ли лежат там, не знаю,
[05:33.760 --> 05:37.880]  n камушков, и вы про них знаете, скажем, только их цвета,
[05:37.880 --> 05:41.760]  красный, синий, желтый, зеленый и так далее, и вы знаете их
[05:41.760 --> 05:44.760]  исходные номера, но вы не знаете их вес, то есть они
[05:44.760 --> 05:47.720]  с виду все одинаковые по весу, но там изготовлены
[05:47.720 --> 05:48.720]  из разных материалов.
[05:48.720 --> 05:50.280]  Вы не знаете у кого какой вес, вы можете только их
[05:50.280 --> 05:53.660]  попарно сравнивать между собой, и причем эти весы
[05:53.660 --> 05:56.460]  вам не показывают веса, показывают только именно
[05:56.460 --> 05:59.140]  соотношение между ними, кто тяжелее, кто легче.
[05:59.140 --> 06:01.260]  Вот в такой постановке, если вы про эти ваши камушки
[06:01.260 --> 06:03.540]  ничего не знаете, кроме того, что их можно сравнить
[06:03.540 --> 06:06.700]  между собой, вот в такой постановке быстрее, чем
[06:06.700 --> 06:08.900]  за столько сравнений, а значит быстрее, чем за столько
[06:08.900 --> 06:11.580]  действий алгоритм построить не получится.
[06:11.580 --> 06:16.300]  Доказательства.
[06:16.300 --> 06:20.780]  Ну давайте, во-первых, считать, что в массиве, который мы
[06:20.780 --> 06:23.380]  подаем на вход нашему алгоритму, все чисто попарно
[06:23.380 --> 06:24.380]  различны.
[06:24.380 --> 06:31.300]  Считаем, что все элементы, ну, я буду иногда оговариваться
[06:31.300 --> 06:34.320]  вместо элементов говорить числа, ну, как бы, обычно
[06:34.320 --> 06:36.940]  сортировка у нас будет именно на числах, я имею в виду
[06:36.940 --> 06:39.420]  элементы всегда, пока что у меня сортировка каких-то
[06:39.420 --> 06:40.420]  элементов.
[06:40.420 --> 06:47.820]  Так вот, считаем, что все элементы массива А1 и так
[06:47.820 --> 06:50.060]  далее АН попарно различны.
[06:50.060 --> 06:58.620]  Рассмотрим какой-то конкретный алгоритм.
[06:58.620 --> 07:05.500]  Ну, вот тот самый алгоритм сортировки, основанный на
[07:05.500 --> 07:06.500]  сравнениях.
[07:06.500 --> 07:16.900]  Вот, тогда я утверждаю, что протокол его работы
[07:16.900 --> 07:20.540]  на массиве длины N на самом деле описывается с помощью
[07:20.540 --> 07:23.340]  решающего дерева, потому что, как ведет себя алгоритм,
[07:23.340 --> 07:25.460]  он сначала что-то делает, да, там, ну, не знаю, что-то
[07:25.460 --> 07:28.500]  независище от массива, там, что-то предподсчитывает,
[07:28.500 --> 07:30.540]  чем-то занимается сам по себе, потом в какой-то
[07:30.540 --> 07:35.020]  момент он начинает попарно сравнивать вот эти элементы.
[07:35.020 --> 07:38.420]  Ну, понятно, что в зависимости от N там может быть какое-то
[07:38.420 --> 07:40.340]  первое действие, например, там, сравни первый камень
[07:40.340 --> 07:42.700]  и второй, или там, второй и третий, ну, короче, вот
[07:42.700 --> 07:45.500]  есть какое-то первое действие, которое он совершает, давайте
[07:45.500 --> 07:49.780]  я здесь напишу, там, сравни АИ и АЖ, вот я операцию сравнения
[07:49.780 --> 07:52.660]  буду такой галочкой обозначать, ну, есть какое-то первое
[07:52.660 --> 07:57.340]  действие, потом в зависимости от ответа на него, кто из
[07:57.340 --> 08:00.220]  них там тяжелее или легче, да, скажем, здесь АИТОЕ
[08:00.220 --> 08:05.380]  больше, здесь АЖИТОЕ больше, он, ну, начинает делать что-то
[08:05.380 --> 08:08.900]  другое, там, он сделал вот этот запрос, потом в зависимости
[08:08.900 --> 08:12.540]  от результата вот этого взвешивания он, возможно, там, ну, как-то
[08:12.540 --> 08:14.740]  разветвляется, в этом случае он делает тот, в другом случае
[08:14.740 --> 08:19.140]  он делает тот, ну, так или иначе, в каждом, в каждой
[08:19.140 --> 08:22.660]  вот точке, да, в каждом протоколе работы алгоритма, в каждом
[08:22.660 --> 08:26.220]  момент времени алгоритма, он уже сделал какие-то сравнения
[08:26.220 --> 08:27.940]  и вот давайте посмотрим, какое следующее сравнение
[08:27.940 --> 08:30.460]  он сделает, то есть если мы знаем все сравнения, которые
[08:30.460 --> 08:32.860]  он сделал до этого момента, то мы точно знаем, какое
[08:32.860 --> 08:35.060]  будет сравнение сделано следующим, скажем, здесь
[08:35.060 --> 08:40.660]  он сравнивает, не знаю, там, АКТ и АМТ, и опять в зависимости
[08:40.660 --> 08:42.620]  от того, какой здесь значок неравенства, больше или
[08:42.620 --> 08:45.940]  меньше, да, алгоритм как-то дальше себя детерминированно
[08:45.940 --> 08:48.100]  ведет, то есть, зная, что здесь был такой значок, а
[08:48.100 --> 08:51.580]  здесь такой, он на следующем запросе обязательно спросит
[08:51.580 --> 08:54.580]  что-то следующее, то есть мы как бы знаем, какой запрос
[08:54.580 --> 08:57.580]  он задает к нашим камушкам, но я считаю, что алгоритм
[08:57.580 --> 09:00.180]  у меня детерминированный, и нет, пока нет случайности,
[09:00.180 --> 09:03.940]  вот, тогда понятное дело, что вот весь протокол работы
[09:03.940 --> 09:07.140]  на массиве длины n описывается таким вот решающим деревом,
[09:07.140 --> 09:09.540]  где на каждом шаге, в каждом решении мы по факту спрашиваем
[09:09.540 --> 09:13.740]  соотношение каких-то двух элементов, понятно же это,
[09:13.740 --> 09:15.820]  ну просто потому что мы как бы только это и можем
[09:15.820 --> 09:18.340]  при элементах спрашивать, вот каждый такой запрос,
[09:18.340 --> 09:21.180]  каждый вопрос к массиву, каждый запрос в сравнении
[09:21.180 --> 09:23.900]  двух элементов давайте отразим в виде вершины, да, и соответственно
[09:23.900 --> 09:26.980]  каждая вершина раздваивается там, что происходит в обоих
[09:26.980 --> 09:29.660]  случаях, вот, и поскольку я изначально предположу,
[09:29.660 --> 09:32.140]  что все элементы различные, то у меня никогда не бывает
[09:32.140 --> 09:33.860]  случая равенства, то есть всегда либо больше, либо
[09:33.860 --> 09:39.380]  меньше, вот, значит, вот есть такое дерево, у каждой
[09:39.380 --> 09:42.180]  вершины в нем два сына, да, если вершина происходит
[09:42.180 --> 09:44.340]  в вершине, то там есть два сына влево-вправо.
[09:44.340 --> 09:46.820]  Вот, давайте рассмотрим вершину, у которой нет сыновей.
[09:46.820 --> 09:48.740]  Что это значит?
[09:48.740 --> 09:52.340]  Значит, алгоритм как-то дошел до вот этого состояния,
[09:52.340 --> 09:55.020]  задал какие-то вопросы нашему массиву, он что-то узнал
[09:55.020 --> 09:58.260]  про массив, а дальше никаких запросов не задает, да,
[09:58.260 --> 10:01.380]  то есть если из этой вершины нет уже стрелочек, значит,
[10:01.380 --> 10:03.820]  больше нет запросов в ней, то есть мы до сих дошли, больше
[10:03.820 --> 10:05.820]  никаких запросов не задаем.
[10:05.820 --> 10:07.900]  Это должно означать, что поскольку у меня корректный
[10:07.900 --> 10:12.100]  алгоритм сортировки, я же предположу, что А это алгоритм сортировки. Значит вот
[10:12.100 --> 10:16.900]  здесь вот мы уже точно знаем, как нужно правильно переставить элементы.
[10:16.900 --> 10:22.200]  Вот мы задали какие-то вопросы, там их возможно было много, но если в этой
[10:22.200 --> 10:26.060]  вершине больше никаких запросов не задается, значит мы точно знаем, в каком
[10:26.060 --> 10:29.980]  порядке нужно переставить эти элементы, так чтобы они шли в порядке возрастания.
[10:29.980 --> 10:40.420]  Вот. Но при этом, понятное дело, что если вы будете в качестве элементов вот сюда
[10:40.420 --> 10:46.780]  передавать все возможные перестановки каких-то n элементов, то есть вот у вас
[10:46.780 --> 10:51.620]  есть какие-то n элементов по паре различные, если вы их сюда будете всякими
[10:51.620 --> 10:55.940]  различными способами передавать, например там 1, 2, 3, 1, 3, 2, все возможные
[10:55.940 --> 11:05.460]  перестановки n элементов. Вот если все такие передать, так, то алгоритм должен
[11:05.460 --> 11:09.500]  как бы все их корректно обработать и сказать, как именно нужно переставить
[11:09.500 --> 11:14.140]  элементы, чтобы они шли в порядке возрастания. Вот. Поэтому на самом деле каждый
[11:14.140 --> 11:18.660]  вот этот вот лист, каждый вершина, из которой больше нет ветвления, обязательно
[11:18.660 --> 11:21.420]  соответствует какой-то перестановке, как именно нужно переставить элементы. И
[11:21.420 --> 11:26.780]  причем, понятное дело, что все вот эти вот n, точнее все вот эти вот возможные
[11:26.780 --> 11:30.940]  входные массивы, которых на самом деле ровно n факториал по числу перестановок
[11:30.940 --> 11:36.100]  n элементов, все эти n факториал массивов должны закончиться в попарно-различных
[11:36.100 --> 11:40.380]  листьях. Ну, потому что каждый лист на самом деле говорит, что нужно сделать с
[11:40.380 --> 11:43.620]  массивом, чтобы он шел в порядке возрастания. Поэтому не могут два
[11:43.620 --> 11:47.100]  различных вот таких вот массива прийти в один и тот же лист, потому что тогда
[11:47.100 --> 11:49.820]  они бы, тогда бы их нужно было одинаково переставить, чтобы получиться
[11:50.060 --> 11:53.460]  ассортированную перестановку. А такого быть не может, да, потому что они все
[11:53.460 --> 11:57.100]  различны. Нельзя к двум разным перестановкам применить одно и то же, чтобы
[11:57.100 --> 12:01.580]  получить возрастающую перестановку. Вот. Значит, давайте что-нибудь из этого
[12:01.580 --> 12:15.500]  запишем. Лист в решающем дереве, вот в этом решающем дереве отвечает
[12:15.500 --> 12:32.540]  случаю, когда алгоритм понял, ну давайте напишу так, нашел сигма, нашел сигма. То
[12:32.540 --> 12:35.940]  есть он понял вот в этих серверах, как именно нужно переставить элементы, чтобы
[12:35.940 --> 12:42.780]  они шли в порядке возрастания. Дальше различные перестановки, различные
[12:42.860 --> 12:56.740]  перестановки исходного массива должны, должны завершаться в попарно-различных
[12:56.740 --> 13:04.300]  листьях, в различных листьях дерева.
[13:04.300 --> 13:14.780]  Ну, потому что еще раз, лист это в каком порядке нужно переставить входные
[13:14.780 --> 13:18.180]  элементы, чтобы они шли в порядке возрастания? Не может быть такое, что две
[13:18.180 --> 13:21.420]  разные входные перестановки надо переставить одинаковым образом, то есть
[13:21.420 --> 13:24.600]  они могут дойти до одного листа, потому что переставив их одинаковым образом,
[13:24.600 --> 13:30.240]  мы не можем получить в обоих случаях возрастающую перестановку. Только
[13:30.240 --> 13:33.160]  одна из них может, потому что если мы к одной перестановке
[13:33.160 --> 13:35.840]  применили другую и получили возрастающую, то вторая
[13:35.840 --> 13:37.040]  не может получиться такой же.
[13:37.040 --> 13:40.920]  Написываем, когда алгоритм нашел сигму.
[13:40.920 --> 13:43.680]  Да, когда алгоритм нашел сигму.
[13:43.680 --> 13:45.040]  Ну вот в этом плане.
[13:45.040 --> 13:46.360]  То есть он понял, как их надо переставить.
[13:46.360 --> 13:59.840]  Это значит, что листьев в дереве, по крайней мере
[13:59.840 --> 14:00.840]  сколько?
[14:00.840 --> 14:05.000]  Ну n факториал все-таки.
[14:05.000 --> 14:09.320]  Тут я сказал, что различные перестановки входного
[14:09.320 --> 14:11.560]  массива соответствуют различным листьям.
[14:11.560 --> 14:14.280]  Значит листьев хотя бы столько, сколько перестановок.
[14:14.280 --> 14:15.800]  А перестановок в точности n факториал.
[14:15.800 --> 14:22.240]  Так, от никого не пугают, все знают, что такое факториал.
[14:22.240 --> 14:23.240]  Хорошо.
[14:23.240 --> 14:28.840]  Получается, что протокол работы нашего алгоритма
[14:28.840 --> 14:32.920]  на массивах длины n, это вот такое большое бинарное
[14:32.920 --> 14:35.160]  дерево, то есть дерево, у которого у каждой вершинки
[14:35.160 --> 14:39.440]  два сына, кроме листьев, в котором листьев hn факториал.
[14:39.440 --> 14:45.440]  Ну и тогда утверждаю, что глубина этого дерева, по
[14:45.520 --> 14:46.440]  крайней мере, вот такая.
[14:46.440 --> 14:53.440]  Чтобы в бинарном дереве было хотя бы столько листьев,
[14:53.440 --> 14:56.160]  нужно, чтобы его глубина была хотя бы вот такой.
[14:56.160 --> 15:11.160]  Значит, осталось доказать, что если в бинарном дереве,
[15:11.160 --> 15:12.960]  бинарное, это именно такое, что у каждой вершины либо
[15:13.000 --> 15:16.560]  два сына, либо она листовая и дальше никуда не идет.
[15:16.560 --> 15:19.280]  Вот такое дерево, что в таком дереве, что если в таком
[15:19.280 --> 15:26.280]  дереве хотя бы n факториал листьев, то его глубина
[15:27.760 --> 15:28.760]  это омегатенлоган.
[15:28.760 --> 15:35.760]  Ну, если мы это докажем, то значит, что на входных
[15:35.760 --> 15:38.760]  массивах длины n, вот это вот дерево, по крайней мере,
[15:38.760 --> 15:42.760]  на одном из своих путей, имеет глубину омегатенлоган,
[15:42.760 --> 15:45.760]  ну там, c умножено нлоган, ну значит, вот в этой ветке
[15:45.760 --> 15:49.760]  алгоритма, ему нужно хотя бы нлоган сравнений с
[15:49.760 --> 15:51.760]  точностью домножения на константу.
[15:51.760 --> 15:54.760]  Поэтому мы докажем то, что хотим.
[15:54.760 --> 15:56.760]  Почему, если в бинарном дереве n факториал листьев,
[15:56.760 --> 15:58.760]  то глубина хотя бы омегатенлоган?
[15:58.760 --> 16:02.760]  Потому что, если в бинарном дереве н факториал листьев,
[16:03.760 --> 16:05.760]  то глубина хотя бы омегатенлоган.
[16:05.760 --> 16:11.760]  Ну, давайте такую картинку просто нарисуем.
[16:11.760 --> 16:21.760]  Вот, я утверждаю, что если глубина дерева у меня будет
[16:21.760 --> 16:25.760]  k, то листьев в нем будет не больше, чем 2 вкатый.
[16:25.760 --> 16:31.760]  А если вот эта вот глубина, тогда листьев не больше
[16:31.760 --> 16:34.760]  2 в степень k.
[16:34.760 --> 16:39.760]  Ну, потому что вот если есть какая-то вершинка,
[16:39.760 --> 16:42.760]  на глубине меньше, чем k, ей выгодно сначала раздвоиться,
[16:42.760 --> 16:44.760]  потому что она таким образом породит больше листьев.
[16:44.760 --> 16:47.760]  Значит, мне нужно построить такое полно бинарное дерево
[16:47.760 --> 16:49.760]  сверху вниз, то есть каждая вершина раздваивается,
[16:49.760 --> 16:51.760]  раздваивается, вплоть до катого уровня.
[16:51.760 --> 16:54.760]  Ну и тогда понятно, что здесь листьев в точности 2 в степень
[16:54.760 --> 16:58.760]  k, ну да, значит, их максимальное количество не больше,
[16:58.760 --> 17:04.760]  чем 2 в степень k.
[17:04.760 --> 17:13.760]  Листьев не больше, чем 2 в степень k.
[17:13.760 --> 17:17.760]  Вот, то есть если у дерева глубина k, то листьев в нем
[17:17.760 --> 17:18.760]  не больше, чем 2 в степень k.
[17:18.760 --> 17:20.760]  А мне нужно, наоборот, мне нужно листьев хотя бы
[17:20.760 --> 17:21.760]  n-факториал.
[17:21.760 --> 17:32.760]  Значит, чтобы листьев было хотя бы n-факториал,
[17:32.760 --> 17:39.760]  глубина должна быть хотя бы...
[17:39.760 --> 17:41.760]  Ну, видимо, двоичный алгорифм, да, то есть как получается
[17:41.760 --> 17:43.760]  вот отсюда вот это, надо взять двоичный алгорифм.
[17:43.760 --> 17:46.760]  Если у меня фиксировано число листьев, то глубина считается
[17:46.760 --> 17:48.760]  как двоичный алгорифм от этого количества.
[17:48.760 --> 17:50.760]  Поэтому глубина должна быть хотя бы двоичный алгорифм
[17:50.760 --> 17:56.760]  от n-факториала.
[17:56.760 --> 17:58.760]  Окей?
[17:58.760 --> 18:01.760]  Вот, значит, осталось понять, как асимпатически себя
[18:01.760 --> 18:05.760]  ведет алгорифм от n-факториала.
[18:05.760 --> 18:07.760]  Вот, если мы докажем, что это омега от n-луген, то мы
[18:07.760 --> 18:11.760]  победили.
[18:11.760 --> 18:19.760]  Вот это должно быть d.b.
[18:19.760 --> 18:21.760]  Так, то есть, смотрите, мы свели задачу к следующему.
[18:21.760 --> 18:23.760]  Мне нужно доказать, что вот эта вот штука, да, алгорифм
[18:23.760 --> 18:26.760]  от n-факториала, ведет себя как омега от n-луген.
[18:26.760 --> 18:31.760]  Но давайте даже более сильное утверждение докажем.
[18:31.760 --> 18:36.760]  Давайте покажем, что алгорифм от n-факториала есть даже
[18:36.760 --> 18:40.760]  тетта от n-луген.
[18:40.760 --> 18:50.760]  То есть, это не только оценка снизу, но и сверху.
[18:50.760 --> 18:54.760]  Вот.
[18:54.760 --> 18:56.760]  Можно, но давайте руками.
[18:56.760 --> 18:58.760]  Давайте считать, что мы еще первокурсники и не знаем
[18:58.760 --> 19:00.760]  формулу стирлинга.
[19:00.760 --> 19:03.760]  Давайте докажем это совсем элементарными средствами.
[19:03.760 --> 19:06.760]  Значит, смотрите, что такое n-факториал?
[19:06.760 --> 19:11.760]  N-факториал это пред REALLY всех чисел от 1 до n.
[19:11.760 --> 19:17.760]  Вот.
[19:17.760 --> 19:18.760]  Я могу написать, что алгорифма от n-факториала
[19:18.760 --> 19:23.760]  это алгорифм произведения, значит сумма алгорифмов
[19:23.760 --> 19:31.760]  лог единицы, плюс лог двойки, плюс так далее, плюс лог n.
[19:31.760 --> 19:33.760]  Потому что алгорифм произведения – сумма алгорифмов.
[19:33.760 --> 19:34.760]  Вот.
[19:34.760 --> 19:39.760]  Дальше я могу на самом деле каждый логарифм сверху оценить логарифмом n.
[19:39.760 --> 19:44.760]  Потому что логарифм — это возрастающая функция, какое бы я там адекватное основание не взял.
[19:44.760 --> 19:48.760]  Здесь подразумевается двоичный логарифм, но я не пишу, основание какое-то.
[19:48.760 --> 19:51.760]  Мы помним, что основание алгорифма на самом деле нешибко важно,
[19:51.760 --> 19:56.760]  потому что в терминах вот там омеги и тетты все равно все основания съедаются,
[19:56.760 --> 19:58.760]  константы нам не важны.
[19:58.760 --> 20:02.760]  Я могу все алгорифмы оценить по отдельности логарифмом n,
[20:02.760 --> 20:05.760]  ну и таких n слагаемых, поэтому это все не больше, чем n лог n.
[20:08.760 --> 20:12.760]  Мы тем самым доказали, что логарифм n факториала — это от n лог n.
[20:18.760 --> 20:19.760]  Согласны?
[20:20.760 --> 20:21.760]  Чудесно.
[20:22.760 --> 20:24.760]  Теперь снизу оценочка.
[20:33.760 --> 20:34.760]  Давайте.
[20:40.760 --> 20:44.760]  Нет, я доказал, что log n факториал — это от n лог n.
[20:44.760 --> 20:46.760]  Пока сейчас я только это доказал.
[20:49.760 --> 20:50.760]  Еще раз?
[20:53.760 --> 20:55.760]  Вот утверждение. Я хочу доказать, что тетта.
[20:55.760 --> 20:59.760]  Помним, что чтобы доказать тетту, мне нужно доказать и о, и омегу одновременно.
[20:59.760 --> 21:00.760]  Я пока доказал только о.
[21:00.760 --> 21:01.760]  Сейчас буду омегу.
[21:04.760 --> 21:06.760]  Вторая часть. Я хочу доказать омегу.
[21:06.760 --> 21:08.760]  Для этого я напишу следующее.
[21:10.760 --> 21:13.760]  Опять я напишу, что лог n факториал — это сумма логарифмов.
[21:20.760 --> 21:24.760]  И здесь я оставлю только большие слагаемые.
[21:24.760 --> 21:26.760]  Короче, оставлю вторую половину слагаемых.
[21:30.760 --> 21:35.760]  От n пополам до лог n.
[21:40.760 --> 21:42.760]  Тут я неявно предполагаю, что n четное.
[21:42.760 --> 21:44.760]  Если n нечетное, там ничего интересного не будет.
[21:44.760 --> 21:46.760]  Короче, тоже сам будет работать.
[21:49.760 --> 21:51.760]  Качественно я оставляю вторую половину слагаемых.
[21:52.760 --> 21:55.760]  Теперь я их все оцениваю снизу, наоборот, минимальным из них.
[21:56.760 --> 21:59.760]  Я говорю, что все эти логарифмы больше либо равны, чем минимальные из этих логарифмов.
[22:00.760 --> 22:02.760]  Их, видимо, здесь будет ровно n пополам.
[22:07.760 --> 22:08.760]  Согласны?
[22:09.760 --> 22:12.760]  Я оставил большую половину логарифмов.
[22:12.760 --> 22:14.760]  Каждый из них оценил меньшим из них.
[22:14.760 --> 22:16.760]  Ну и здесь n пополам с слагаемых.
[22:16.760 --> 22:18.760]  Потому что n пополам плюс одно, ну бог с ним.
[22:18.760 --> 22:20.760]  Больше оно, чем n пополам.
[22:21.760 --> 22:22.760]  Им более-менее уже победили.
[22:22.760 --> 22:24.760]  Надо только расписать свой логарифм n пополам.
[22:27.760 --> 22:29.760]  Это лог n минус лог 2.
[22:31.760 --> 22:33.760]  Это минус один.
[22:34.760 --> 22:38.760]  Ну да, это минус один, если у меня основная логарифма двоечка.
[22:38.760 --> 22:41.760]  Но на самом деле я даже не буду над этим думать.
[22:41.760 --> 22:43.760]  Потому что что здесь написано?
[22:43.760 --> 22:50.760]  Здесь написано 1 вторая n лог n минус 1 вторая n лог 2.
[22:52.760 --> 22:54.760]  Ну понятно, что это доминирует над этим.
[22:54.760 --> 22:57.760]  Потому что это с точностью константы мультипликативная.
[22:57.760 --> 22:59.760]  Это n лог n, а это n.
[23:01.760 --> 23:04.760]  Если позанутствовать, можно формально доказать, что это
[23:04.760 --> 23:08.760]  больше либо у нас, скажем, чем 1 четверть n лог n.
[23:08.760 --> 23:12.760]  Ну там, либо вообще всегда, либо для n, начиная с 20, например.
[23:15.760 --> 23:18.760]  Число 20 из головы взялось, давайте 100.
[23:22.760 --> 23:24.760]  Короче, я уже знаю, что вот это всегда работает.
[23:24.760 --> 23:26.760]  Если это хочется доказать, как доказать такое неравенство?
[23:26.760 --> 23:28.760]  Но на самом деле здесь написано, что
[23:28.760 --> 23:32.760]  если это туда перенести, что 1 четверть n лог n больше
[23:32.760 --> 23:34.760]  чем 1 вторая n лог 2.
[23:34.760 --> 23:37.760]  Что-нибудь сократили, на n поделили, останется...
[23:37.760 --> 23:41.760]  То есть вот эта неравенство на самом деле равносильна такому.
[23:41.760 --> 23:46.760]  1 четверть лог n больше 1 вторая лог 2.
[23:48.760 --> 23:50.760]  Правду пишу?
[23:50.760 --> 23:54.760]  Перенес сюда, перенес туда, поделил на n.
[23:54.760 --> 23:57.760]  Ясен пень, здесь растущая функция, здесь константы.
[23:57.760 --> 24:00.760]  Понятно, что все х, начиная с какого-то, это верно.
[24:00.760 --> 24:02.760]  Там 100 с запасом хватит.
[24:02.760 --> 24:03.760]  Можно вопрос?
[24:03.760 --> 24:04.760]  Да.
[24:04.760 --> 24:06.760]  Можете, пожалуйста, объяснить?
[24:06.760 --> 24:08.760]  Покажите, помню еще раз.
[24:08.760 --> 24:10.760]  Совсем понятно?
[24:10.760 --> 24:13.760]  Еще раз, вот это или почему мы вообще это доказываем?
[24:13.760 --> 24:14.760]  Нет, вот это.
[24:14.760 --> 24:16.760]  Вот это, хорошо.
[24:16.760 --> 24:18.760]  Вот это понятна строчка?
[24:18.760 --> 24:19.760]  Первая?
[24:19.760 --> 24:20.760]  Ну, разложение...
[24:20.760 --> 24:21.760]  Вторая понятна?
[24:21.760 --> 24:22.760]  Нет.
[24:22.760 --> 24:25.760]  Смотрите, у меня здесь n слагаемых.
[24:25.760 --> 24:27.760]  Все не отрицательные.
[24:27.760 --> 24:30.760]  Давайте оставим только последние n пополам из них.
[24:31.760 --> 24:34.760]  Да, я оставляю последние n пополам в слагаемых.
[24:36.760 --> 24:38.760]  Потому что здесь все слагаемые не отрицательные.
[24:38.760 --> 24:41.760]  a плюс b больше 0, чем b, если a не отрицательная.
[24:42.760 --> 24:46.760]  Если я выбрасываю не отрицательные слагаемые из суммы,
[24:46.760 --> 24:48.760]  у меня сумма только уменьшается, конечно.
[24:49.760 --> 24:51.760]  Открытие, да?
[24:56.760 --> 24:58.760]  Вроде не очень сложный факт.
[24:58.760 --> 25:00.760]  Я ровно его применил.
[25:02.760 --> 25:04.760]  Еще раз, у меня здесь много слагаемых,
[25:04.760 --> 25:06.760]  я просто несколько первых выкину.
[25:06.760 --> 25:08.760]  Сумма только уменьшится могла.
[25:08.760 --> 25:09.760]  Отлично.
[25:09.760 --> 25:11.760]  Дальше у меня есть куча логарифмов.
[25:11.760 --> 25:13.760]  Логарифм растущая функция.
[25:13.760 --> 25:15.760]  Чем больше аргументов, тем больше логарифм.
[25:15.760 --> 25:18.760]  Поэтому я все эти логарифмы оцениваю снизу наименьшим из них.
[25:18.760 --> 25:20.760]  Вот это больше, чем лог n пополам.
[25:20.760 --> 25:22.760]  Вот это и так далее.
[25:23.760 --> 25:25.760]  Да, да, да.
[25:25.760 --> 25:27.760]  Тут, может быть, надо было написать n пополам плюс один.
[25:27.760 --> 25:29.760]  А, вот здесь n пополам плюс один, да.
[25:29.760 --> 25:31.760]  Я их все оцениваю вот этим,
[25:31.760 --> 25:33.760]  и их n пополам.
[25:33.760 --> 25:35.760]  Поэтому вот такая оценка.
[25:35.760 --> 25:37.760]  А дальше уже какая-то арифметика.
[25:37.760 --> 25:39.760]  Вот.
[25:39.760 --> 25:41.760]  Мы вроде все доказали.
[25:41.760 --> 25:44.760]  Сейчас мы показали, что log n факториал больше собрав
[25:44.760 --> 25:47.760]  чем как раз n лог n с точностью до мультипликливной константы,
[25:47.760 --> 25:49.760]  с точностью до умножения на какую-то константу.
[25:52.760 --> 25:54.760]  Вот.
[25:54.760 --> 25:56.760]  Итого, мы показали, что log n факториал
[25:56.760 --> 25:58.760]  это ω от n лог n,
[25:58.760 --> 26:00.760]  а раньше мы доказали, что это o от n лог n,
[26:00.760 --> 26:02.760]  то есть мы доказали утверждение.
[26:02.760 --> 26:04.760]  Но раз мы доказали утверждение,
[26:04.760 --> 26:06.760]  то мы доказали предыдущую теорию,
[26:06.760 --> 26:08.760]  потому что мы свели ее к такому вот утверждению.
[26:12.760 --> 26:14.760]  Вот здесь равно.
[26:14.760 --> 26:16.760]  Ну, значит, если есть значок,
[26:16.760 --> 26:18.760]  то там равно подразумевается всегда.
[26:22.760 --> 26:24.760]  Вот здесь?
[26:24.760 --> 26:26.760]  Ну, смотрите, вот у меня есть одна автора n лог n,
[26:26.760 --> 26:28.760]  из которой я что-то вычитаю.
[26:28.760 --> 26:30.760]  Это, в принципе, что-то не очень большое
[26:30.760 --> 26:32.760]  по сравнению вот с этим,
[26:32.760 --> 26:34.760]  но как бы тем не менее растущее.
[26:34.760 --> 26:36.760]  Мне нужно оценить вот это вот
[26:36.760 --> 26:38.760]  n лог n умножить на какую-то константу.
[26:38.760 --> 26:40.760]  Ну, я бы здесь, на самом деле, мог написать
[26:40.760 --> 26:42.760]  любую константу меньше 1 второй.
[26:42.760 --> 26:44.760]  Например, 1 четвертую.
[26:44.760 --> 26:46.760]  То есть главное, что...
[26:46.760 --> 26:48.760]  Откуда взялось?
[26:48.760 --> 26:50.760]  Ну, типа, если это есть, то мы доказали.
[26:50.760 --> 26:52.760]  Откуда взялось, чтобы это было верно, и все.
[26:52.760 --> 26:54.760]  Это как в Мотоне, там откуда берется epsilon
[26:54.760 --> 26:56.760]  равно 7 в 16 на дельт в четвертой.
[26:56.760 --> 26:58.760]  Ну вот, типа, с ним сходится.
[26:58.760 --> 27:00.760]  Здесь то же самое.
[27:00.760 --> 27:02.760]  Ну и не надо тогда.
[27:04.760 --> 27:06.760]  Понятно все?
[27:06.760 --> 27:08.760]  Ну вот, вроде все доказали тогда.
[27:08.760 --> 27:10.760]  То есть, смотрите, получается,
[27:10.760 --> 27:12.760]  что если алгоритмы над элементами
[27:12.760 --> 27:14.760]  могут произвести только сравнение,
[27:14.760 --> 27:16.760]  то надеяться на что-то лучшее,
[27:16.760 --> 27:18.760]  чем n лог n, с точки зрения симптотики,
[27:18.760 --> 27:20.760]  нельзя.
[27:20.760 --> 27:22.760]  Это уже очень интересный результат.
[27:22.760 --> 27:24.760]  На самом деле, один из очень немногих
[27:24.760 --> 27:26.760]  во всей его теории алгоритмов,
[27:26.760 --> 27:28.760]  одна из очень немногих нижних оценок.
[27:28.760 --> 27:30.760]  Потому что дальше все, что мы будем делать,
[27:30.760 --> 27:32.760]  кажется, там,
[27:32.760 --> 27:34.760]  до конца третьего семестра,
[27:34.760 --> 27:36.760]  это доказывает только какие-то верхние оценки
[27:36.760 --> 27:38.760]  на алгоритмы. То есть мы будем говорить,
[27:38.760 --> 27:40.760]  ага, вот такая задача, вот такой алгоритм
[27:40.760 --> 27:42.760]  ее решает за отом от n квадрата
[27:42.760 --> 27:44.760]  или за от n лог n.
[27:44.760 --> 27:46.760]  А то, что не бывает алгоритма с меньшей
[27:46.760 --> 27:48.760]  симптотикой, это зачастую
[27:48.760 --> 27:50.760]  сильно сложнее доказывается.
[27:50.760 --> 27:52.760]  Ну там, кроме тривиальных случаев,
[27:52.760 --> 27:54.760]  что нельзя обработать массив длины n быстрее,
[27:54.760 --> 27:56.760]  чем за у от n.
[27:56.760 --> 27:58.760]  Но это как бы очевидно, не содержательно.
[27:58.760 --> 28:00.760]  А вот здесь что-то минимально содержательное,
[28:00.760 --> 28:02.760]  и более-менее ничего такого даже не будет.
[28:06.760 --> 28:08.760]  Ну теперь, доказав такую нижнюю оценку,
[28:08.760 --> 28:10.760]  давайте рассмотрим несколько конкретных алгоритмов,
[28:10.760 --> 28:12.760]  на которых эта оценка достигается,
[28:12.760 --> 28:14.760]  которые реально сортируют
[28:14.760 --> 28:16.760]  массив за время n лог n.
[28:22.760 --> 28:24.760]  Так, давайте начнем сортировку с слиянием.
[28:30.760 --> 28:32.760]  По-английски это mergesort.
[28:44.760 --> 28:46.760]  Алгоритм работает следующим образом.
[28:46.760 --> 28:48.760]  Он использует в качестве подпроцедуры,
[28:48.760 --> 28:50.760]  в качестве вспомогательной функции,
[28:50.760 --> 28:52.760]  следующая.
[28:52.760 --> 28:54.760]  Представьте себе, что у вас есть два
[28:54.760 --> 28:56.760]  отсортированных массива.
[28:56.760 --> 28:58.760]  Давайте я их назову a0 меньше
[28:58.760 --> 29:00.760]  либо равно a1 меньше,
[29:00.760 --> 29:02.760]  ну и так далее,
[29:02.760 --> 29:04.760]  там, вплоть до a n-1.
[29:04.760 --> 29:06.760]  И второй отсортированный массив,
[29:06.760 --> 29:08.760]  b0, b1,
[29:08.760 --> 29:10.760]  и так далее, b n-1.
[29:10.760 --> 29:12.760]  Наша задача их слить
[29:14.760 --> 29:16.760]  в один большой отсортированный.
[29:18.760 --> 29:20.760]  Это будет называться процедура merges,
[29:20.760 --> 29:22.760]  и она состоит в следующем.
[29:22.760 --> 29:24.760]  Вот представьте, у вас есть два набора чисел,
[29:24.760 --> 29:26.760]  ашки и бэшки.
[29:26.760 --> 29:28.760]  Причем ашки упорядочены и бэшки упорядочены.
[29:28.760 --> 29:30.760]  Вам их нужно так слить всех вместе,
[29:30.760 --> 29:32.760]  чтобы вот здесь, вот каждый из этих чисел
[29:32.760 --> 29:34.760]  сейчас ровно по одному разу,
[29:34.760 --> 29:36.760]  и они опять-таки шли в порядке возрастания.
[29:36.760 --> 29:38.760]  Например, если у вас есть
[29:38.760 --> 29:40.760]  какой-нибудь массив там, не знаю,
[29:40.760 --> 29:42.760]  1,2,5
[29:42.760 --> 29:44.760]  и там 1,3,7,
[29:44.760 --> 29:46.760]  то после слияния,
[29:46.760 --> 29:48.760]  ну понятно, сортировка будет...
[29:48.760 --> 29:50.760]  Просто мне их нужно расположить опять-таки
[29:50.760 --> 29:52.760]  в порядке возрастания,
[29:52.760 --> 29:54.760]  но уже теперь все вместе,
[29:54.760 --> 29:56.760]  и a и b как-то они там между собой перемешаются.
[29:56.760 --> 29:58.760]  Да, мне нужно два отсортированных массива слить в один отсортированный.
[29:58.760 --> 30:00.760]  Вот ровно таким образом.
[30:00.760 --> 30:02.760]  Значит, как это делать?
[30:04.760 --> 30:06.760]  Вообще, это на самом деле очень простая процедура.
[30:06.760 --> 30:08.760]  Простой алгоритм.
[30:08.760 --> 30:10.760]  Вот есть у вас два отсортированных массива,
[30:10.760 --> 30:12.760]  как их слить в один отсортированный?
[30:12.760 --> 30:14.760]  Давайте сделаем следующее.
[30:14.760 --> 30:16.760]  Давайте мы введем
[30:16.760 --> 30:18.760]  по указателю
[30:18.760 --> 30:20.760]  на оба наши массива, вот здесь вот a и b.
[30:22.760 --> 30:24.760]  И будем просто слева-направо идти
[30:24.760 --> 30:26.760]  по обоим массивам,
[30:26.760 --> 30:28.760]  и каждый раз выписывать минимальные из двух чисел
[30:28.760 --> 30:30.760]  и двигать соответствующий указатель.
[30:30.760 --> 30:32.760]  Вот на примере этого массива.
[30:32.760 --> 30:34.760]  Изначально мы смотрим на единицу-иденицу.
[30:34.760 --> 30:36.760]  Выписываем наименьшую из них,
[30:36.760 --> 30:38.760]  ну если они не одинаковые, то выписываем любую из них.
[30:38.760 --> 30:40.760]  Взяли в эту, например, единицу, записали
[30:40.760 --> 30:42.760]  и её, сдвинули стрелку сюда.
[30:42.760 --> 30:44.760]  Опять, есть единица, и двойка.
[30:44.760 --> 30:46.760]  Кто из них меньше?
[30:46.760 --> 30:48.760]  Ну понятно дело, единица. Взяли ее, записали,
[30:48.760 --> 30:50.760]  сдвинули стрелку направо.
[30:50.760 --> 30:52.760]  Сравниваем, двойку, тройку, кто из них меньше?
[30:52.760 --> 30:54.760]  Понятное дело, двойка, записали, сдвинули стрелку.
[30:54.760 --> 30:56.760]  Сравнили, записали, сдвинули стрелку.
[30:56.760 --> 30:58.760]  Сравнили, записали, сдвинули стрелку.
[30:58.760 --> 31:00.760]  Да, здесь массив кончился,
[31:00.760 --> 31:02.760]  ну и остается здесь
[31:02.760 --> 31:09.200]  элементы дописать, и массив тоже кончится. Вот такой простой алгоритм. То есть на самом деле,
[31:09.200 --> 31:16.960]  что я по факту делаю? Я иду вот по этому массиву, и каждый раз выписываю минимальный из оставшихся
[31:16.960 --> 31:22.720]  элементов. Ну понятно, что изначально минимум это один из них, потому что это минимум своего
[31:22.720 --> 31:27.400]  массива, это минимум своего массива. Я его записал сюда. Понятно дело, что на первом месте либо это,
[31:27.400 --> 31:32.480]  либо это. Потом кто на втором месте? Ну понятно, минимум из оставшихся. На третьем месте минимум из
[31:32.480 --> 31:36.920]  оставшихся и так далее. То есть по факту просто с помощью двух этих указателей я поддерживаю,
[31:36.920 --> 31:41.760]  какие куски массивов я уже выписал, ну и из оставшихся элементов я выбираю самый маленький,
[31:41.760 --> 31:53.520]  записываю ответ. Вот. Ну давайте какой-нибудь псевдокод здесь напишем. Ну вот представьте,
[31:53.520 --> 32:01.160]  что мне нужна процедура Merge, которая берет массив A, массив B и массив C и пытается два
[32:01.240 --> 32:20.800]  массива A и B слить в один большой массив C. Как он будет работать? Сейчас, сейчас, секунду. Что говорите?
[32:20.800 --> 32:35.720]  Мы вводим эти два указателя, здесь будет и здесь будет g. Ну и дальше, давайте сюда перейду,
[32:35.720 --> 32:48.560]  значит дальше пока i меньше n или g меньше m, то есть пока у меня хотя бы один из двух массивов не
[32:48.560 --> 33:01.520]  исчерпался. Давайте напишем условия, когда нужно написать i. Нет, нет, не i. Пока хотя бы один из
[33:01.520 --> 33:12.680]  двух массивов не кончился, да, то есть пока есть что записывать. Нет, не обязательно. Вот я хочу
[33:12.680 --> 33:19.120]  так, чтобы потом не дописывать еще кучу строчек, я хочу так написать. Вот еще раз, вот пусть хотя
[33:19.120 --> 33:24.080]  бы один из них не закончился. Каково условие на то, что мне нужно сейчас написать ai в ответ?
[33:24.080 --> 33:35.960]  Да, ai меньше либо равно чем bg, либо g кончился, либо b кончился, то есть если g равно m или
[33:35.960 --> 33:47.400]  i меньше n и ai меньше либо равно bg. Это будут корректные условия на то, что нужно сейчас
[33:47.400 --> 33:59.760]  выписать ai. Что? Не обязательно. Может быть, что вот это меньше, а это равно. Вот этот значок
[33:59.760 --> 34:03.520]  означает или, то есть либо это, либо это верно, возможно и то и то, но может быть только одно из
[34:03.520 --> 34:08.960]  них. Вот, значит, когда мне нужно писать ai? Либо в случае, когда второй массив кончился, то есть
[34:08.960 --> 34:14.600]  я уже все b выписал, но тогда, понятное дело, здесь g равно m, но i тогда точно меньше, чем n,
[34:14.600 --> 34:23.640]  и можно просто его написать, да, ai-то. Ну, потому что, потому что иначе вот это вот это нельзя
[34:23.640 --> 34:30.120]  сделать, да, потому что если у вас g меньше, чем m, а i, например, кончился, а первый массив кончился,
[34:30.120 --> 34:34.600]  тогда вы не имеете права даже так сравнить, потому что эту массиву нет, просто банально. А только,
[34:34.600 --> 34:40.680]  если у вас и меньше n, только в этом случае вы имеете право сделать сравнение, если оно верно,
[34:40.680 --> 34:47.120]  тогда его нужно дописать. Вот. Ну и все, в этом случае. Давайте тогда напишем, что c и плюс gt
[34:47.120 --> 35:01.440]  это ai. Вот. Значит, и увеличу на единичку. Мы, собственно, разобрали случай, когда нужно
[35:01.440 --> 35:06.320]  писать ai, понятное дело, что он всегда записывается в клетку и плюжи. Всегда все, что мы записываем,
[35:06.320 --> 35:10.760]  идет в клетку и плюжи, потому что это в точности число уже обработанных чисел, да, число,
[35:11.360 --> 35:19.680]  количество чисел, которое мы уже выписали. Вот. Ну и иначе нужно, видимо, сделать c и плюс gt равно
[35:19.680 --> 35:38.000]  bgt, плюс плюжи. Конец. Так. Вот. Действительно, поддерживаю два указателя, здесь и здесь.
[35:38.000 --> 35:44.600]  Проверяю, могу ли я сейчас, в очередной элемент массива c, могу ли записать ai. Могу ровно в этом
[35:44.600 --> 35:49.960]  случае. Либо когда второй массив кончился, либо первый еще не кончился, и там число реально меньше,
[35:49.960 --> 35:55.440]  чем в b. В этом случае я могу его записать и сразу сдвигаю указатель на следующий. Плюс плюс и,
[35:55.440 --> 36:00.920]  значит, увеличение i на единичку. Иначе мне придется написать bg и сдвинуть второй указатель g на
[36:00.920 --> 36:07.600]  единичку. Все. После этого while у меня в массиве c лежит склеенная вот эта вот объединенная версия
[36:07.600 --> 36:18.040]  массива i и b. Понятно? Супер. Ну давайте на всякий случай отмечу, что это работает за, собственно,
[36:18.040 --> 36:23.160]  сумму длин массивов. Если у меня был массив длины n и массив длины m, то это просто алгоритм,
[36:23.160 --> 36:28.400]  работающий за линейное время, да, от суммы их длин. Потому что я по первому массиву пробегаю
[36:28.400 --> 36:32.480]  слева направо, по второму массиву пробегаю слева направо. Понятно вроде, что время работа линейная
[36:32.480 --> 36:41.200]  здесь. Можно, да, в этом случае можно, потому что мы, ну, по крайней мере, по одному разу все
[36:41.200 --> 36:46.000]  элементы пробежим, поэтому можно было бы поставить тетту, да, можно. Но я не буду, потому что как бы
[36:46.000 --> 36:51.040]  мы уже на самом деле доказали все про нижние границы, мы сейчас будем только сверху оценивать. Мы уже
[36:51.040 --> 36:55.920]  знаем, что быстрее, чем за n log n нельзя. Вот. И сейчас я буду всегда всегда все только сверху оценивать.
[36:55.920 --> 37:12.480]  Даже вот этот простой, простой алгоритм merge. Нет, в этом случае, смотрите, если я, если я перешел в, то
[37:12.480 --> 37:17.760]  есть смотрите, у меня либо вот это выполнилось, оператор вот этот палка-палка работает так, что
[37:17.760 --> 37:21.720]  если это выполнилось, то вот это второе слово даже не рассматривается. То есть если g равно m,
[37:21.720 --> 37:28.120]  я сразу перехожу сюда. Сюда я смотрю только в случае, если первый аргумент не верен. Значит,
[37:28.120 --> 37:33.160]  здесь у меня g меньше, чем m, но еще потенциально может быть и равно n. В этом случае вот это нельзя
[37:33.160 --> 37:41.680]  так сразу проверять, потому что а n не определено. Окей? Хорошо. Так, ну merge вроде написали. Теперь
[37:41.680 --> 37:50.640]  остался, собственно, merge sort. Как он работает? Смотрите, вот есть у вас массив длины n, а 0,
[37:50.640 --> 37:58.720]  а 1 и так далее, а n-1. Давайте я его рекурсивно разобью на две половинки, ну, точнее, просто
[37:58.720 --> 38:04.000]  сначала разобью на две половинки. Первые n пополам элементов и вторые n пополам элементов. Дальше,
[38:04.000 --> 38:09.720]  с помощью рекурсивного вызова, то есть с помощью вызова того же самого алгоритма, я посортирую эти
[38:09.720 --> 38:17.120]  две половинки. То есть я вызову merge sort для левой половинки и merge sort для правой половинки. В
[38:17.120 --> 38:25.400]  результате у меня окажется так, что вот эти оба массива будут отсортированными. Вот. Ну а
[38:25.400 --> 38:32.120]  дальше нужно их просто будет слить. Давайте их как-нибудь назову. Давайте кратко опишем,
[38:32.120 --> 38:41.920]  что merge sort от a работает так. Он сначала выделяет левую правую половину, потом вызывает merge sort
[38:41.920 --> 38:55.080]  от l, merge sort от r. Ну и дальше он видимо просто делает merge. Вот эти два массива склеивает на
[38:55.080 --> 39:03.600]  место исходного массива a. Вот что такое. Единственное, здесь нужно еще добавить условия выхода из рекурсии.
[39:03.600 --> 39:13.400]  Скажем, что если массив состоит из одного элемента, то сортировать нечего. То return просто. Ну
[39:13.400 --> 39:18.080]  потому что если мы дошли, если мы вот в этом нашем спуске дошли до массива длины 1, их даже не
[39:18.080 --> 39:23.880]  нужно сортировать, они так уже отсортированы. Дальше спускаться некуда. Вот. То есть картинка будет
[39:23.880 --> 39:28.680]  примерно какая-то такая. Есть у вас изначально весь ваш большой массив, вы его разбили на два
[39:28.680 --> 39:37.880]  куска левой и правой, на две равные половинки. Дальше вы рекурсивно их сортируете. Что такое
[39:37.880 --> 39:43.960]  рекурсивная сортировка? Это применить ту же самую идею к обеим половинкам. Вот скажем, вы запустились
[39:43.960 --> 39:49.440]  слева, давайте сортировать эту штуку. Что такое сортировка? Вы бьете ее пополам, разбиваете на две
[39:49.440 --> 39:55.680]  половины, левую и правую, и опять рекурсивно их сортируете. Что это такое? Давайте здесь посмотрим.
[39:55.680 --> 40:01.880]  Вы его разбиваете на два куска, регурсивно сортируете. Ну и так далее. Потом рано или поздно
[40:01.880 --> 40:06.180]  вот здесь будет лежать отсортированные версии соответствующих массивов. И дальше вы их с
[40:06.180 --> 40:10.540]  помощью мерджа просто склеиваете в один большой отсортированный. То есть вы сначала массив разбили
[40:10.540 --> 40:16.400]  на два куска, отсортировали по кускам, а дальше взяли и склеили обратно в один кусок большой.
[40:16.400 --> 40:20.780]  То есть два отсортированных массива склеили в один большой отсортированный. То же самое здесь.
[40:20.780 --> 40:25.660]  Сначала отсортировали это, это уже отсортировано. Берете их с помощью мерш и опять склеиваете в
[40:25.660 --> 40:31.300]  один большой отсортированный. Если это отсортировано и это отсортировано, то просто с помощью мерш склеиваете
[40:31.300 --> 40:44.780]  два куска в один большой отсортированный. Конец. Понятно? Так, ну хорошо. Осталось, наверное,
[40:44.780 --> 40:52.500]  оценить только время работы. Я утверждаю, что если за t от n обозначить время работы на массиве
[40:52.500 --> 41:04.300]  длины n, то рекурьента у нас получается следующая. Так, давай чуть ниже. Чуть не помещается сюда.
[41:14.780 --> 41:21.740]  Еще раз. Значит, t от n это время работы на массиве длины n. Тогда утверждаю, что t от n это
[41:21.740 --> 41:28.660]  удвоенная t от n пополам плюс линейная добавка o от n. Ну, собственно, вот здесь все написано.
[41:28.660 --> 41:34.060]  Я сначала массив длины n разбил на два массива длины n пополам. Рекурсивно в них вызвал тот же
[41:34.060 --> 41:39.260]  самый алгоритм, то есть с точки зрения времени работы сделал два раза t от n пополам. И потом
[41:39.260 --> 41:44.740]  еще за линейное время, то есть за o от n, склеил два отсортированных массива в один большой
[41:44.740 --> 41:54.380]  отсортированный. Поэтому время работы подчиняется вот такой рекурренте. Да? Но опять, я здесь пропускаю
[41:54.380 --> 41:58.940]  всякие тонкости про то, что если n нечетное, что происходит, потому что если n нечетное,
[41:58.940 --> 42:03.900]  тогда у вас эти два куска имеют на самом деле разные длины. Там типа n пополам округлись вниз
[42:03.900 --> 42:09.260]  и вверх. Но это все всегда несущественно, потому что мы можем, давайте скажем в самом начале,
[42:09.260 --> 42:15.300]  что n равно степени двойки. Если n равно степени двойки, тогда все вот эти деления всегда происходили
[42:15.300 --> 42:20.060]  целочисленно и всегда все половинки были одинаковые. То есть вот эти по длине всегда одинаковые,
[42:20.060 --> 42:25.060]  вот эти по длине одинаковые и так далее. Ну и тогда, если мы решим эту рекурренту для степеней
[42:25.060 --> 42:31.180]  двоек и получим n лог n, то понятно, что на всех остальных n-ках у меня тоже получается порядка n
[42:31.180 --> 42:37.460]  лог n. Потому что каждое n можно, если что, сначала увеличить, добить до ближайшей сверху степени
[42:37.460 --> 42:43.060]  двойки. Если на степени двойки у меня будет n лог n, то значит на этом n время работы не сильно
[42:43.060 --> 42:48.280]  испортится. То есть если что, я могу массив добить каким-нибудь мусором до степени двойки,
[42:48.280 --> 42:53.100]  потом ассортировать и мусор отбросить. Но время работы от этого, видимо, не сильно вырастет,
[42:53.100 --> 42:58.100]  потому что если у меня здесь получатся рекурренты n лог n, то и время работы там вырастет не сильно.
[42:58.580 --> 43:05.580]  По факту я просто n превращаю в 2 вкатый, беру от этого n лог n отсюда, это будет, видимо,
[43:05.580 --> 43:09.860]  2 вкатые на k, тогда время работы здесь, не больше, чем время работы здесь. Если здесь n лог n,
[43:09.860 --> 43:15.660]  то здесь тоже будет n лог n примерно. Это все детали, в которые мы никогда не влезаем, на самом деле,
[43:15.660 --> 43:35.020]  потому что они существенные. Вот если t от n — это время работы мерч сорта на массиве длины n,
[43:35.020 --> 43:42.020]  то оно удовлетворяет такому правенству. Время работы на массиве длины n — это два раза нужно
[43:42.020 --> 43:49.020]  отсортировать массивы длины n пополам. Вот два вызова. Плюс еще потом какая-то линейная добавка,
[43:49.020 --> 43:56.820]  потому что мне нужно два отсортированных массива склеить. Мы сейчас докажем, что это n лог n. Нам
[43:56.820 --> 44:10.420]  осталось доказать. Докажем, что в таком случае t от n равно от n лог n. Ну да,
[44:10.420 --> 44:29.860]  можно, например, сразу воспользоваться мастер-тиоремой, которая, по идее, должна была быть у всех на семинарах.
[44:29.860 --> 44:43.540]  Ну вас обманули нагло. Ну мастер-тиорема, ее нет смысла выносить на лекции, потому что там куча
[44:43.540 --> 44:51.060]  условий. Мы будем пользоваться только один раз ей вот в этом случае. Поэтому давайте докажем
[44:51.060 --> 45:02.700]  опять это руками. Значит, почему в таком случае t от n — это от n лог n? Ну что мне нужно доказать?
[45:02.700 --> 45:08.180]  То есть по факту вот это утверждение означает, что существует какая-то константа C, что t от n не
[45:08.180 --> 45:13.020]  больше, чем C на n лог n. Вот нам надо ее как бы предъявить. Нам надо найти такое C, что t от n не
[45:13.020 --> 45:24.900]  больше, чем C на n лог n. Давайте сначала вот то условие перепишем. Плюс у меня там написано o от n,
[45:24.900 --> 45:34.220]  но мы знаем, что такое o от n. Это не больше, чем Cn для какого-то C. Поэтому здесь я напишу в явном
[45:34.220 --> 45:40.780]  виде, вместо o от n, я напишу Cn для вот того самого C, которое скрыто в константе o от n. Вот так
[45:40.780 --> 45:45.700]  константа, которая скрыта в определении o большого. То есть у нас есть вот это. Есть потому,
[45:45.700 --> 45:55.740]  что o от n — это C, а Cn — для какого-то C. Значит, нужно найти такое, скажем, d. Нужно найти такое d,
[45:55.740 --> 46:08.260]  что t от n не больше dn лог n. Вот. Если мы такое найдем, то мы победили. Мы в точности доказали то,
[46:08.260 --> 46:13.620]  что нужно, потому что вот как раз мультипликативная константа d здесь вылезла, которая в терминах у большого
[46:13.620 --> 46:20.140]  съедается. Вот. Как бы такое d найти? Ну, смотрите, пусть там это верно для всех меньших n. Давайте
[46:20.140 --> 46:29.620]  попробуем индукцию бахнуть. Значит, пусть это верно для t от n пополам. Тогда t от n не больше,
[46:29.620 --> 46:34.940]  чем 2 от n пополам, каждый из которых оценится сверху вот такой штукой. То есть здесь будет
[46:34.940 --> 46:47.660]  удвоенное d, n пополам, лог n пополам. Я считаю, что такое d у меня откуда-то взялось. Дальше я хочу
[46:47.660 --> 46:53.660]  бахнуть индукцию. То есть я хочу, предположив, что вот для этого n пополам верно такое соотношение,
[46:53.660 --> 46:59.620]  то есть что t от n пополам не больше, чем d, n пополам, лог n пополам. Вот то, что здесь написано. Я хочу
[46:59.620 --> 47:04.900]  доказать, это же не равенство для n. То, что, собственно, верно вот это. Ну, давайте это попытаемся
[47:04.900 --> 47:23.420]  доказать. Что? Сейчас, еще раз. Я считаю, что для этого верно. Ну, а дальше просто применяю. То есть я
[47:23.420 --> 47:28.700]  считаю, что для t от n пополам верна вот такая соответствующая оценка. d, n пополам, лог n
[47:28.700 --> 47:35.100]  пополам. А дальше просто использую вот это неравенство. Я пока нигде не обманываю. То есть я считаю,
[47:35.100 --> 47:44.180]  что если вот это вот верно, то тогда это верно, потому что мы это знаем и так. Вот. Ну, здесь надо
[47:44.180 --> 47:50.020]  немножко повозиться, чтобы понять, какое нужно d выбрать, так чтобы это все сошлось. Что здесь будет?
[47:50.020 --> 48:02.140]  Значит, давайте это сократим. Лог n пополам опять распишем как лог n минус лог 2. Ну, и cn остается
[48:02.140 --> 48:18.340]  само по себе. Нет, я вот это просто переписал. Я вот это переписал, используя знания. Ну, я сейчас
[48:18.740 --> 48:24.220]  немножко ищу на самом деле. Мне нужно найти такое d, а я считаю, что я его уже нашел и его использую.
[48:24.220 --> 48:32.140]  Хорошо, да. Давайте доведу, потом еще раз объясню, почему все это работает. Так вот, смотрите. Я
[48:32.140 --> 48:37.260]  сейчас написал, что t от n не больше чем dn лог n. Собственно, то, что мне нужно. Вот оно dn лог n.
[48:37.260 --> 48:44.260]  Минус dn лог 2 плюс cn. Ну, давайте здесь уже придется специфицировать, какой именно логарифм.
[48:44.260 --> 48:51.620]  Давайте считаем, что здесь двоичный логарифм стоит, а здесь везде двоичный. Ну, тогда это просто
[48:51.620 --> 49:01.660]  единица. И чтобы победить, чтобы вот это было не больше, чем dn лог 2n, мне достаточно, чтобы вот
[49:01.660 --> 49:07.220]  это вот было неположительным. Значит, мне достаточно, чтобы d было больше равно, чем c.
[49:07.220 --> 49:25.900]  Еще раз давайте помедленнее. Вот пусть это верно. Пусть верно, что d больше равно, чем c. Тогда что
[49:25.900 --> 49:31.380]  вот здесь написано? Здесь написано cn, а здесь написано минус dn. Ну, потому что двоичный лог
[49:31.380 --> 49:35.900]  грифм двойки это единица. То есть я на самом деле могу это просто скрыть. Но понятное дело, что cn
[49:35.900 --> 49:43.380]  минус dn при таком условии меньше либо равно нуля. Поэтому вот эта вот вся штука после прибавления
[49:43.380 --> 49:53.340]  чего-то неположительного останется меньше равно, чем dn лог n. Вот. Итого. Смотрите. То есть я
[49:53.340 --> 49:59.060]  сейчас показал, откуда мы могли бы взять нужное d. Теперь, чтобы завершить доказательство,
[49:59.060 --> 50:04.100]  я могу написать следующее. Давайте считаем, что просто d равно c. Давайте его таким определим.
[50:04.100 --> 50:09.180]  Пока что я d никак не задавал. Я знаю, что такое c. c это константа из вот того большого,
[50:09.180 --> 50:14.780]  которая нам и так дана. Я хочу найти такое d, чтобы выполнялась вот это. Я хочу сам ее предъявить.
[50:14.780 --> 50:23.100]  Вот предъявляю. d равно c. Теперь я утверждаю, что с таким d все сойдется. Доказываю по индукции. Ну,
[50:23.100 --> 50:27.140]  база как-нибудь там, наверно, сама собой разумеется, потому что если я поставляю n равно,
[50:27.140 --> 50:33.060]  там, ну, двойке, да, для единицы, наверное, не работает. Если n равно двойке, то понятно,
[50:33.060 --> 50:42.100]  что t от двойки не больше, чем c на два на один. Ну, потому что на самом деле можно считать,
[50:42.100 --> 50:52.100]  что t от двойки это просто единица. Вот. Так. Ну, окей, давайте отдельно еще вопрос про базу. Я
[50:52.100 --> 50:58.500]  вот вынесу это. Это тоже всегда надо проговаривать. Давайте считать, что база у меня откуда-то есть.
[50:58.500 --> 51:05.140]  Дальше как делать переход? Ну, вот он на самом деле расписан. Я предполагаю, что верно условие для
[51:05.140 --> 51:10.860]  n пополамо. То есть вот это вот неравенство просто верно, если поставить вместо n пополам. Ну, а дальше
[51:10.860 --> 51:16.380]  используя вот это вот неравенство, которое у меня уже известно, я могу доказать, что t от n не
[51:16.380 --> 51:23.460]  больше, чем dea n log n. То есть просто индукция. Зная условия для меньшего n, я получаю условия для
[51:23.460 --> 51:31.380]  большего n. Вот. Значит, единственное тонкое место здесь — это база. Почему можно считать, что для
[51:31.380 --> 51:37.060]  маленьких n это неравенство выполняется? То есть как бы, ну, вот я так делю, делю пополам, а вплоть
[51:37.060 --> 51:41.380]  до каких-то маленьких значений n. Почему можно считать, что это выполняется для маленьких значений n?
[51:41.380 --> 51:48.940]  Ну, вот здесь опять те же самые рассуждения про то, что вообще считается элементарной операцией.
[51:48.940 --> 51:55.180]  Потому что можно, говоря, сказать, что t от 2 — это, например, 1. Будьте здоровы. Потому что такое
[51:55.180 --> 52:02.380]  t от 2 — это сортировка массива из двух элементов. Ну, понятно, что это занимает какую-то константу
[52:02.380 --> 52:08.580]  действий. Может быть 100, может быть 200, может быть 5. Ну, там это что-то простое. По факту у вас есть
[52:08.580 --> 52:13.260]  два элемента. Они сами по себе уже как половинки уже отсортированы. Вам надо их просто, возможно,
[52:13.260 --> 52:19.100]  переставить, если там один меньше другого. Вот. С точки зрения, как бы, то есть несколько элементарных
[52:19.100 --> 52:23.020]  операций. Константное количество элементарных операций. Поэтому можно считать, что t от 2 просто
[52:23.020 --> 52:28.620]  единица. Потому что, ну, вот опять мы не специфицируем, что именно такая элементарная операция,
[52:28.620 --> 52:36.380]  а любое константное их количество можно считать, что это просто одна простая операция. Вот. Поэтому
[52:36.380 --> 52:42.540]  вот это вот нас ничем не стесняет. Ну и, понятное дело, что если сюда поставить двойку, то t от
[52:42.540 --> 52:45.580]  2 равный единиц и будет не больше, чем d на n log n.
[52:45.580 --> 53:05.020]  Но вот это как раз не проблема. Потому что понятно, что вот здесь вот вы можете c спокойно
[53:05.020 --> 53:10.860]  увеличивать. Потому что если эта штука работает за там n на c, то она работает не больше, чем n
[53:10.860 --> 53:14.860]  умножить на c плюс 2, например. Или там c плюс 100. То есть от того, что вы вот здесь увеличиваете
[53:14.860 --> 53:20.140]  константу по большому, вы точно не проигрываете. Вот. Ну и, соответственно, там тоже это можно сделать.
[53:20.140 --> 53:34.260]  Да, вопрос еще какой-то был. Ну да, да, тоже верно. То есть с базой можно было бы еще по-другому
[53:34.260 --> 53:38.620]  разобраться, что вот я сказал, что мне достаточно вот этого для перехода индукции. Давайте еще
[53:38.620 --> 53:42.580]  выберем d достаточно большим, чтобы это было верно для всех достаточно маленьких n, чтобы база
[53:42.580 --> 53:50.020]  работала. Можно было бы сделать и так, действительно, да. Тут всегда можно и так, и так. Так, еще есть
[53:50.020 --> 53:59.740]  вопросы? Хорошо. Ну что, мы тогда вроде доказали, что хотели. Мы доказали, что этот алгоритм работает
[53:59.740 --> 54:12.380]  от n лог n. Вот. Причем, поскольку он, очевидно, основан на сравнениях, он работает, как мы недавно
[54:12.380 --> 54:17.820]  доказали, за ω от n лог n. Ну, значит, суммарно он работает за θ от n лог n. То есть ни меньше,
[54:17.820 --> 54:24.860]  ни больше. Ровно за такую симпатику. Да, но он основан на сравнениях. Видно, да, что элементы
[54:24.860 --> 54:28.780]  между собой мы можем только сравнивать. Все, что мы делаем между элементами, это только там их
[54:28.780 --> 54:34.740]  перестановки между собой какие-то и сравнение между собой двух элементов. Значит, он основан на
[54:34.740 --> 54:41.460]  сравнениях. Значит, она работает хотя бы ω от n лог n. Но при этом не больше, чем от n лог n. Значит,
[54:41.460 --> 54:57.900]  суммарно будет в точности n лог n. Так, согласны? Хорошо. Еще раз? Ну, про merge sort, да, вот мы сейчас его
[54:57.900 --> 55:02.060]  конкретно рассматриваем. Мы знаем, что все основанные сравнениях работают за ω от n лог n,
[55:02.060 --> 55:15.740]  поэтому он в частности. Вот этот в частности. Ну, и он еще и о от n лог n, поэтому ω. Вот этот? Ну,
[55:15.740 --> 55:22.820]  еще раз, смотрите. Давайте я сотру вот здесь лог 2, потому что лог 2 по основанию 2 это 1. Вот.
[55:22.820 --> 55:32.100]  Дальше написано cn минус dn. Если d равно c, то это просто 0. Все. Остается dn лог n, да.
[55:32.100 --> 55:59.100]  Так, дальше можно? Хорошо. Давайте тогда решим такую задачку. Значит, опять пусть есть массив какой-то.
[56:02.100 --> 56:13.340]  Массив чисел. Значит, инверсия в нем называется такая пара индексов i и j, что i меньше,
[56:13.340 --> 56:23.780]  чем j, а a и t больше, чем aj. Вот. То есть два элемента такие, что один расположен левее,
[56:23.780 --> 56:31.220]  но при этом больше. Это как бы препятствие к тому, что он отсортирован, то есть что слева стоит
[56:31.220 --> 56:35.820]  большее число, а в отсортированном должно было бы быть наоборот. А вот такую пару мы назовем
[56:35.820 --> 56:41.820]  инверсией, если одновременно i меньше, чем j, но а и больше, чем aj. Так вот задача найти число инверсий.
[56:41.820 --> 56:56.020]  Найти число инверсий в массиве. Так, есть ли идеи, как решать?
[56:56.020 --> 57:17.060]  Посчитать, сколько раз будет перестановка. Сколько раз будет перестановка. Ну да, да, да.
[57:17.060 --> 57:32.420]  Все правильно предлагается. Значит, смотрите, давайте реализуем опять мёртвый сорт и посмотрим,
[57:32.420 --> 57:39.580]  что в нем происходит. Вот был массив длины n, я его делю пополам. Давайте мы сначала посчитаем инверсии,
[57:39.580 --> 57:44.540]  которые целиком лежат в одной из половинок. Вот здесь или здесь. Это давайте пусть делается
[57:44.540 --> 57:50.260]  просто рекурсивными запусками в обеих половинках. То есть я сначала, ну по факту,
[57:50.260 --> 57:54.860]  опять запущу рекурсивную какую-то процедуру, которая находит число инверсий строго в левой
[57:54.860 --> 58:00.220]  половине, вот здесь, и строго в правой половине, вот здесь. Ну и ещё заодно по сортируют обе эти
[58:00.220 --> 58:06.740]  части. Останется учесть такие инверсии, которые пересекают этот разрез. То есть вот такие какие-то.
[58:06.740 --> 58:12.780]  Но тогда понятно, что от того, что я переставляю элементы внутри половины, такие инверсии,
[58:12.780 --> 58:18.460]  пересекающие разрез не сломались. Ну потому что здесь неважно в каком порядке их переставить,
[58:18.460 --> 58:23.340]  если этот элемент всегда левее, чем этот, то как бы внутри половин не перемешивать их,
[58:23.340 --> 58:28.580]  у меня все-таки инверсии сохранятся, ну и других не появятся. Поэтому давайте мы посчитаем и число
[58:28.580 --> 58:33.140]  инверсий здесь отсортируем. Посчитаем число инверсий здесь отсортируем, и мне останется теперь
[58:33.140 --> 58:38.620]  вот для этих двух отсортированных половин найти количество инверсий, вот пересекающих этот разрез.
[58:38.620 --> 58:48.340]  Ну на самом деле получится просто такая же рекуррента, а значит n log n.
[58:48.340 --> 58:55.780]  Ну давайте доведем, я еще не до конца рассказал, как мы посчитали число таких инверсий. Смотрите,
[58:55.780 --> 58:59.860]  вот если у меня есть 20 отсортированных массива, как посчитать число инверсий вот пересекающих
[58:59.860 --> 59:07.060]  разрез? Ну это на самом деле можно сделать во время мерч просто. Вот смотрите, у вас есть 20
[59:07.060 --> 59:15.660]  отсортированных массива. Давайте идти по ним слева направо точно так же, как мы шли в алгоритме мерч,
[59:15.660 --> 59:23.540]  и считать инверсии. Вот, например, здесь я нахожусь в каком-то g, здесь я нахожусь в каком-то i.
[59:23.540 --> 59:35.780]  Сколько тогда, например, инверсий образует этот элемент g? Мы видим ровно вот столько. Да,
[59:35.780 --> 59:40.740]  потому что что такое вот эти все числа? То есть как бы, ну вот здесь все элементы уже выписаны,
[59:40.740 --> 59:45.660]  здесь все элементы уже выписаны, то есть они все меньше, чем вот это вот b g. Ну если я буду считать,
[59:45.660 --> 59:50.700]  что i меньше ровно чем b g, тогда мне нужно просто к ответу добавить все вот эти элементы, лежащие
[59:50.700 --> 01:00:02.060]  справа от i. Тем самым я учту все все инверсии затрагивающие житый элемент. Давайте я вот так
[01:00:02.060 --> 01:00:07.580]  буду считать. Тогда у меня все правильно написано, то есть как раз какие инверсии образуют
[01:00:07.580 --> 01:00:21.940]  житый элемент? Только вот эти вот, потому что смотрите, инверсии есть безотносительно вот
[01:00:21.940 --> 01:00:26.340]  этого значка неравенства, ну как бы все такие инверсии точно есть, потому что вот здесь все числа
[01:00:26.340 --> 01:00:33.220]  больше чем, ну окей, если даже a i t больше чем b g t, тогда все эти элементы тоже подавно
[01:00:33.220 --> 01:00:43.020]  больше чем b g t, потому что они правее. Так, и что? Ну все равно все эти, сейчас. Все, все, я понял,
[01:00:43.020 --> 01:01:02.060]  да, я понял. Один момент. Хорошо, да, то есть я хочу найти для вот этого g, когда впервые здесь
[01:01:02.060 --> 01:01:09.020]  здесь, кажется, значок больше, тогда все вот эти вот добавить, да? Да, так, наверное, разумно. Да,
[01:01:09.020 --> 01:01:13.780]  окей, так проще. Так вот, давайте дождемся момента, когда здесь указатель пришел в точку g,
[01:01:13.780 --> 01:01:20.180]  здесь указатель пришел в точку i. И при этом будем считать, что a i t больше b g t. Ну то есть как бы,
[01:01:20.180 --> 01:01:25.340]  если они равны или там, если a i t меньше, давайте просто и левый указатель двигать. Собственно,
[01:01:25.340 --> 01:01:30.620]  так же, как у нас было в мерже. Я двигаю левый указатель, пока он меньше равен чем правый. До
[01:01:30.620 --> 01:01:35.980]  того момента, пока не будет, наоборот, значок больше. Тогда вот сколько сейчас инверсии образует
[01:01:35.980 --> 01:01:40.940]  вот это вот b g t? Ровно вот эти вот все элементы, начиная с i до конца массива, до конца левой
[01:01:40.940 --> 01:01:47.700]  половины. Потому что это больше чем b g, все более правые тоже подавно больше, а все левые вот эти
[01:01:47.700 --> 01:01:52.700]  вот, они уже не будут больше, они будут меньше, ну потому что это как раз первый элемент больше
[01:01:52.700 --> 01:01:58.260]  чем b g, все остальные были меньше или равны. Поэтому каждый раз, когда я дохожу до такого состояния,
[01:01:58.260 --> 01:02:03.380]  и мне нужно переключать b g, то есть я двигаю после этого второй, вот этот вот указатель,
[01:02:03.380 --> 01:02:08.340]  жишечку на единицу. Значит в этот момент времени мне нужно к ответу будет добавить
[01:02:08.340 --> 01:02:16.220]  количество элементов от i до конца левой половины. Вот так вроде будет работать. То есть по факту
[01:02:16.220 --> 01:02:28.300]  у меня здесь просто будет внутри модификация merge. Каждый раз, когда i больше чем b g,
[01:02:28.300 --> 01:02:35.180]  я к ответу добавляю что-то в стиле там, ну давайте я напишу,
[01:02:35.180 --> 01:02:58.100]  мне лень писать. Короче количество элементов в а, минус что? Минус i, да? Да, вроде так правильно
[01:02:58.100 --> 01:03:08.500]  будет, да. Количество элементов в а. Ну вот собственно мне нужно добавить к ответу вот это
[01:03:08.500 --> 01:03:13.940]  вот количество, сколько есть элементов с номерами i или больше. Это в точности все
[01:03:13.940 --> 01:03:31.820]  количество элементов минус i, потому что вот здесь левее него стоит i. Вот просто здесь и здесь. Но
[01:03:31.820 --> 01:03:38.660]  смотрите, на самом деле алгоритм будет работать точно так же как merge short, просто в merge я еще
[01:03:38.740 --> 01:03:45.340]  вклею вот эту вот штуку. Тогда что будет происходить? Смотрите, вот я сначала разделил весь большой
[01:03:45.340 --> 01:03:50.780]  массив на два кусочка, левый и правый. Рекурсивно вызвал в них merge short вместе вот с этим вот
[01:03:50.780 --> 01:03:58.060]  изменением. Что это такое? Это значит, что вот эти две половинки отсортируются и вместе с этим
[01:03:58.060 --> 01:04:03.700]  посчитают число инверсий внутри себя. То есть я сейчас считаю, я так модифицирую merge short,
[01:04:03.700 --> 01:04:09.500]  чтобы он не только сортировал, но и выдавал число инверсий. Так вот он отсортирует этот массив,
[01:04:09.500 --> 01:04:14.940]  выдаст число инверсий, то есть увеличит ответ на число инверсий в нем. Отсортирует этот массив,
[01:04:14.940 --> 01:04:19.100]  увеличит ответ на число инверсий в нем. А дальше у меня есть два отсортированных массива. Я их
[01:04:19.100 --> 01:04:24.260]  склеиваю с помощью моей обычной процедуры merge, которая также увеличивает общее число инверсий,
[01:04:24.260 --> 01:04:45.660]  но каждый раз, когда видит их. Давайте попробуем. Давайте посмотрим, как они склеиваются.
[01:04:45.660 --> 01:04:50.820]  Есть два таких массива. Изначально я просто описываю единицу, пока инверсий не вижу. Дальше пришел
[01:04:50.820 --> 01:04:59.540]  сюда, вижу инверсии. Я вижу инверсии вот такие вот. Добавляю к ответу двойку. Дальше двигаю
[01:04:59.540 --> 01:05:07.460]  эту двойку. Опять вижу те же самые две инверсии. 4,3,7,3. Опять добавляю к ответу двойку. Двигаю
[01:05:07.460 --> 01:05:13.700]  стрелку. Пока инверсий не вижу. 4,8 нормально соотносится. Двигаю стрелку. 7,8 нормально
[01:05:13.700 --> 01:05:19.380]  соотносится. Инверсий не вижу. Двигаю стрелку. Дошел до конца, инверсий больше нет. Если бы
[01:05:19.380 --> 01:05:24.180]  здесь было какой-нибудь 9, то я бы увидел еще вот такую инверсию, добавил единицу к ответу.
[01:05:24.180 --> 01:05:43.220]  Когда я сравнивал 4,3, я двигал вот здесь вот. Потом сравнивал 4,8, 4 меньше чем 8,
[01:05:43.220 --> 01:05:56.340]  сдвигаю с 4 на 7. Потом сравниваю с 7 и 8, сдвигаю стрелку сюда. По факту идея просто мне
[01:05:56.340 --> 01:06:02.100]  нужно внедрить в мой мерч подсчет числа инверсий вот между двумя половинками, между левой и правой
[01:06:02.100 --> 01:06:11.060]  склеиваемой частью. Время работы остается вот таким вот. По крайней мере по-прежнему будет
[01:06:11.060 --> 01:06:16.100]  отвечать такому соотношению рекуррентному, потому что опять я сначала два раза запускаюсь от половины
[01:06:16.100 --> 01:06:22.220]  длины пополам рекурсивным вызовом, а потом за линейное время склеиваю их, ну еще из-за
[01:06:22.220 --> 01:06:26.900]  одного вот это вот подсчитываю, к ответу там что-то добавляю. Это все понятно, делал все еще линейное
[01:06:26.900 --> 01:06:31.660]  время, поэтому в этой рекурренте там разве что испортится константа вот здесь вот во большом.
[01:06:31.660 --> 01:06:39.020]  Там раньше было C, теперь будет там C плюс один может быть. Но от этого симпатика не испортится. В
[01:06:39.020 --> 01:06:43.460]  терминах у большого останется от n-логан. Следующая сортировка называется быстрая сортировка,
[01:06:43.460 --> 01:06:55.020]  она же сортировка ХААРА.
[01:06:55.020 --> 01:07:14.180]  Работает следующим образом. Опять пусть есть большой массив. Давайте выберем в качестве пивота,
[01:07:14.180 --> 01:07:20.460]  в качестве разделяющего элемента случайный элемент нашего массива. Вот пусть давайте х,
[01:07:20.460 --> 01:07:31.580]  это случайный элемент массива. Вот я его буду называть пивот, ну собственно от английского
[01:07:31.580 --> 01:07:38.340]  пивот разделитель. Какой-то разделяющий элемент. Просто давайте случайный элемент из нашего массива
[01:07:38.340 --> 01:07:45.780]  назначим пивотом, разделителем. Что я сделаю дальше? Вот он где-то здесь у меня стоит. Давайте я так
[01:07:45.780 --> 01:07:52.180]  переупорядочу мой массив, так изменю порядок элементов в нем, чтобы сначала шли элементы меньше
[01:07:52.180 --> 01:07:59.580]  пивота, потом все элементы равные пивоту, возможно их там несколько, несколько равных х, а затем
[01:07:59.580 --> 01:08:07.060]  шли бы все элементы больше пивота, больше х. Вот я их так переставил, чтобы массив выглядел ровно
[01:08:07.060 --> 01:08:12.980]  таким образом. Причем внутри блоков они могут как угодно быть переупорядочены. Ну а дальше та же
[01:08:13.020 --> 01:08:25.300]  самая идея, я рекурсивно посортировал здесь и здесь. На рекурсивные запуски. И если у меня этот
[01:08:25.300 --> 01:08:30.100]  кусок после завершения рекурсии будет отсортирован и этот кусок после завершения
[01:08:30.100 --> 01:08:34.840]  рекурсии будет отсортирован, то все вместе будет правильный отсортированный массив. А потому
[01:08:34.840 --> 01:08:38.980]  что у меня сначала в порядке возрастания все элементы меньше х, потом все элементы равны х,
[01:08:38.980 --> 01:08:42.320]  потом в порядке возрастания все элементы больше х. Понятно дело, что это корректный порядок
[01:08:42.320 --> 01:08:47.760]  сжатировки. Все, веселый алгоритм.
[01:08:56.240 --> 01:09:00.960]  Да, именно поэтому мы его выбираем случайным, чтобы такое почти никогда не
[01:09:00.960 --> 01:09:03.520]  происходило.
[01:09:10.880 --> 01:09:16.040]  Вот. Значит, ну давайте я не буду писать псевдокод. Тут единственный вопрос, как
[01:09:16.040 --> 01:09:20.400]  генерирую случайный элемент. Ну, там, в зависимости от, я не знаю, только на
[01:09:20.400 --> 01:09:23.800]  плюсах умею. Вот есть, например, такой довольно хороший генератор случайных
[01:09:23.800 --> 01:09:29.840]  чисел. Вот. Можете, ну прям так и пишется такой тип. Можете погуглить и научиться им
[01:09:29.840 --> 01:09:34.960]  пользоваться, если надо. Вот. Ну, на крайнях всегда есть просто ранд.
[01:09:38.280 --> 01:09:46.800]  Это класс, видимо. Ну, короче, погуглите. Вот. Я в детали не хочу никогда лезть. Это
[01:09:46.800 --> 01:09:51.680]  вопрос реализации всегда. Вот. Значит, алгоритм в точности такой, да. Каждый раз
[01:09:51.680 --> 01:09:54.400]  просто выбираем случайный элемент, по нему разделяемся и рекурсивно ссортим
[01:09:54.400 --> 01:10:00.480]  обе половинки. Значит, утверждается, что... Да.
[01:10:04.480 --> 01:10:08.880]  Потому что, если мы будем выбирать, например, всегда центральный, то несложно
[01:10:08.880 --> 01:10:12.040]  построить пример, когда эта штука всегда будет работать за квадрат. Ну,
[01:10:12.040 --> 01:10:16.080]  представьте. То есть, что, например, плохого может быть? Плохо может быть, если в
[01:10:16.080 --> 01:10:19.760]  качестве х вы, например, выбираете минимальный элемент массива. Тогда у вас
[01:10:19.760 --> 01:10:23.240]  вот этого вообще не будет. Будет минимум, и вы будете ссортировать все кроме
[01:10:23.240 --> 01:10:26.840]  минимума. То есть, по факту, вы просто один элемент отссортировали и ссортируете
[01:10:26.840 --> 01:10:30.840]  массив длины n-1. Так вот, а представьте, что если минимум стоял бы у вас в центре.
[01:10:30.840 --> 01:10:36.920]  То есть, вот здесь единица. Дальше. После как-то... После переупрядущивания у вас,
[01:10:36.920 --> 01:10:40.640]  ну, опять выбирается центральный элемент, но вполне может быть такое, что там стоит
[01:10:40.640 --> 01:10:46.520]  двойка, и вы взяли опять минимум. Да, поэтому в таком... В таком случае всегда
[01:10:46.520 --> 01:10:50.000]  можно подобрать массив так, чтобы такой алгоритм работал за квадратичное время,
[01:10:50.000 --> 01:10:57.600]  за n-квадрат. Это нам не годится, мы хотим за n-лог n. Что он?
[01:11:04.760 --> 01:11:11.560]  Ну, смотрите, еще раз. Плохо, плохо, когда х близок к минимуму или к максимуму
[01:11:11.560 --> 01:11:17.960]  массива. Но если выбираете его случайно, давайте вот такую картинку
[01:11:18.080 --> 01:11:23.560]  нарисуем. Давайте я скажем, разобью массив на три равные части. Здесь минимальные
[01:11:23.560 --> 01:11:26.200]  элементы, здесь максимальные, здесь какие-то центральные. Ну, то есть, я его
[01:11:26.200 --> 01:11:29.000]  отсортировал. Вот здесь минимальные отрезы, здесь максимальные отряд.
[01:11:29.000 --> 01:11:33.440]  Тогда с вероятностью хотя бы одна тресть, вы его неплохо так разобьете. Потому
[01:11:33.440 --> 01:11:37.520]  что если х будет вот отсюда, то у вас обе эти части будут хотя бы одна треть по
[01:11:37.520 --> 01:11:42.320]  размеру. Получается, с вероятностью хотя бы одна треть, то есть, по крайней мере,
[01:11:42.320 --> 01:11:46.520]  на каждом третьем шаге, вот этого, вашего рекурсивного спуска, вы ваш
[01:11:46.520 --> 01:11:52.520]  Массив сплитите не так в тупую один элемент и все остальные, а хотя бы треть массива и две третьи массива.
[01:11:52.520 --> 01:11:54.520]  Это уже хорошо.
[01:11:54.520 --> 01:12:03.520]  В принципе, из того, что массив не отречен, ты же скажешь, что выбор строго центрального элемента вполне смущает?
[01:12:03.520 --> 01:12:09.520]  Ну, это громкое заявление, потому что массив, подаваемый вам на вход, на нем нет распределения вероятности.
[01:12:09.520 --> 01:12:11.520]  Это какой-то конкретный массив.
[01:12:11.520 --> 01:12:18.520]  И если написан какой-то код, который всегда берет центральный элемент и в нем нет случайности,
[01:12:18.520 --> 01:12:22.520]  то спокойно можно построить такой массив длины n, на котором ваш код работает n квадрат.
[01:12:22.520 --> 01:12:28.520]  Потому что вход это случайный массив, это какой-то массив.
[01:12:28.520 --> 01:12:33.520]  Его можно так сгенерировать, чтобы алгоритм работал в квадратичное время.
[01:12:33.520 --> 01:12:38.520]  А вот здесь я утверждаю, что если ваша программа сама самостоятельно генерирует случайные биты,
[01:12:38.520 --> 01:12:44.520]  сама выбирает вот этот элемент x случайно, то какой бы массив на вход не дали,
[01:12:44.520 --> 01:12:47.520]  от ожидания времени работы будет n log n.
[01:12:54.520 --> 01:12:59.520]  Смотрите, вот эта штука на самом деле на практике работает даже быстрее, чем merge sort.
[01:12:59.520 --> 01:13:04.520]  Здесь только теоретическая оценка получается, в худшем случае n квадрат, в среднем n log n.
[01:13:04.520 --> 01:13:06.520]  Но на практике оно даже быстрее merge sort.
[01:13:06.520 --> 01:13:09.520]  Потому что в merge sort вам там надо много памяти выделять.
[01:13:09.520 --> 01:13:15.520]  Когда вы два 24-ронных массива склеиваете в 11 4-ронных, вам там нужно выделить дополнительную память.
[01:13:15.520 --> 01:13:17.520]  А здесь можно без допамяти все это сделать.
[01:13:17.520 --> 01:13:20.520]  Поэтому здесь даже на практике это быстрее работает.
[01:13:23.520 --> 01:13:26.520]  In place merge sort. Я не умею это. А вы умеете?
[01:13:30.520 --> 01:13:35.520]  Что-то я сомневаюсь.
[01:13:35.520 --> 01:13:39.520]  Можете скинуть в чат, я посмотрю, если такое есть.
[01:13:39.520 --> 01:13:49.520]  Мне кажется как раз пафос quick sort и hip sort, который тоже будет через пару лекций, в том, что они именно in place.
[01:13:49.520 --> 01:13:52.520]  А merge sort тяжело сделать in place, если вообще возможно.
[01:13:59.520 --> 01:14:00.520]  Потому что она быстрее.
[01:14:00.520 --> 01:14:06.520]  Я вот только что говорил, что теоретически она в худшем случае работает за квадрат, в среднем только за n log n.
[01:14:06.520 --> 01:14:09.520]  Но на практике она работает быстрее, чем merge sort.
[01:14:09.520 --> 01:14:34.520]  Итак, теорема, значит, математическое ожидание времени работы без доказательства на массиве длины n есть от n log n.
[01:14:34.520 --> 01:14:39.520]  Что?
[01:14:39.520 --> 01:14:44.520]  Поскольку у вас еще год не будет Тиарвера, то я не буду ничего говорить.
[01:14:44.520 --> 01:14:52.520]  Там доказательства элементарные, но требуют каких-то знаний Тиарвера.
[01:14:52.520 --> 01:14:55.520]  Мы не будем сюда лезть.
[01:14:55.520 --> 01:15:00.520]  Смотрите, что здесь хочется сказать, что здесь довольно важно сказать.
[01:15:00.520 --> 01:15:08.520]  Я вот заикнулся уже про то, что merge sort с точки зрения использования памяти весьма неэффективен.
[01:15:08.520 --> 01:15:12.520]  Потому что когда вам нужно в частности решить такую задачу.
[01:15:12.520 --> 01:15:15.520]  Есть два отсорщенных массива, вам нужно их слить в один большой отсортированный.
[01:15:15.520 --> 01:15:18.520]  Вот так их слить.
[01:15:18.520 --> 01:15:24.520]  Эту задачу, говорят, что где-то на нерке написано, но я по крайней мере не умею решать без привлечения до памяти.
[01:15:24.520 --> 01:15:31.520]  Потому что вам нужно идти слева-направо по этим массивам обоим и сливать результат куда-то.
[01:15:31.520 --> 01:15:35.520]  Вы не можете его сливать ни сюда, ни сюда, потому что здесь элементы лежат.
[01:15:35.520 --> 01:15:39.520]  Вы не можете записать результат на место массива A.
[01:15:39.520 --> 01:15:42.520]  Вам нужна отдельная память.
[01:15:42.520 --> 01:15:48.520]  Quick sort хорош тем, что здесь можно без допамяти обойтись.
[01:15:48.520 --> 01:15:53.520]  Кроме поддержки стека рекурсии, это фигня обычно.
[01:15:53.520 --> 01:15:56.520]  Самое сложное это процедура.
[01:15:56.520 --> 01:16:02.520]  По выбранному х разбить массив так, чтобы сначала шли меньше х, потом равный х, потом больше х.
[01:16:02.520 --> 01:16:05.520]  Это называется partition.
[01:16:11.520 --> 01:16:15.520]  А х это в точности разделение массива на три куска.
[01:16:15.520 --> 01:16:18.520]  Меньше х, равный х и больше х.
[01:16:18.520 --> 01:16:28.520]  Давайте научимся с вами сейчас выполнять этот partition без привлечения дополнительной памяти, то есть на месте.
[01:16:28.520 --> 01:16:37.520]  Давайте не создавать новый массив и в него как за счет записывать, а прямо в этом массиве переставим элементы так, чтобы они шли в таком порядке.
[01:16:37.520 --> 01:16:45.520]  Я, видимо, не совсем так сделаю, я сделаю вот так.
[01:16:45.520 --> 01:16:51.520]  Я чуть-чуть испорчу свои данные, но от этого ничего не сломается.
[01:16:51.520 --> 01:16:55.520]  Я расположу сначала меньше х, а потом больше либо равный х.
[01:16:55.520 --> 01:16:58.520]  Х может быть где-то здесь правее, но это неважно.
[01:16:58.520 --> 01:17:04.520]  С точки зрения алгоритма все равно главное, что мы разбили массив на два куска и рекурсивно их посвятировали.
[01:17:04.520 --> 01:17:16.520]  Так вот, идея. Давайте идти по массиву слева направо и поддерживать ровно вот такое разбивание, что сначала идут элементы меньше х, потом больше либо равный х.
[01:17:16.520 --> 01:17:21.520]  Тогда что делать со вновь пришедшим элементом у?
[01:17:21.520 --> 01:17:30.520]  Смотрите, если он больше либо равен х, то делать ничего не нужно, можно просто расширить эту границу.
[01:17:30.520 --> 01:17:35.520]  А если он меньше х?
[01:17:35.520 --> 01:17:40.520]  А вот здесь были меньше х, а здесь были больше либо равный х, у тоже пусть будет меньше, чем х.
[01:17:40.520 --> 01:17:44.520]  Давайте тогда просто возьмем вот эти два элемента, слопнем.
[01:17:44.520 --> 01:17:51.520]  И у меня как раз расширится окно элементов меньше, чем х, а справа будут те, которые больше, чем х.
[01:17:51.520 --> 01:17:53.520]  Вот и все.
[01:17:53.520 --> 01:17:55.520]  Поменяем местами.
[01:17:55.520 --> 01:18:00.520]  Вот у меня есть элементы меньше, чем х. Следующий за ними элемент больше либо равен х.
[01:18:00.520 --> 01:18:07.520]  Следующий за всеми, которые меньше, чем х, я его поменяю местами с у.
[01:18:07.520 --> 01:18:13.520]  И тогда у меня сначала опять-таки будут элементы меньше х, а потом элементы больше либо равны х.
[01:18:13.520 --> 01:18:16.520]  Давайте здесь какой-нибудь код напишем.
[01:18:16.520 --> 01:18:22.520]  Вот это вот, давайте пусть будет l.
[01:18:22.520 --> 01:18:27.520]  l это последний индекс из тех, которые меньше, чем х.
[01:18:27.520 --> 01:18:35.520]  Изначально пусть будет l минус 1, что ли, не знаю.
[01:18:43.520 --> 01:18:50.520]  А нет, можно 0. Нет, нет, нельзя.
[01:18:50.520 --> 01:18:54.520]  Давайте пройдемся по нашему массиву слева направо.
[01:18:54.520 --> 01:18:59.520]  Вот пусть у этот наш текущий элемент, а х это то, с чем мы...
[01:18:59.520 --> 01:19:01.520]  Ну то есть х это наш пилот.
[01:19:01.520 --> 01:19:07.520]  Ну и вот дальше те самые два условия, что если у больше либо равно, чем х,
[01:19:07.520 --> 01:19:10.520]  то тогда делать ничего не нужно, можно просто делать continue,
[01:19:10.520 --> 01:19:15.520]  потому что у меня и так хорошая картинка l остается последним элементом меньше, чем х,
[01:19:15.520 --> 01:19:18.520]  а дальше идет блок элементов больше, равно, чем х. Тут все хорошо.
[01:19:18.520 --> 01:19:28.520]  Теперь второй случай.
[01:19:28.520 --> 01:19:35.520]  Если у меньше, чем х, то его нужно переставить с элементом номер l плюс 1,
[01:19:35.520 --> 01:19:39.520]  потому что l это последний меньший, а первый больше равно, это l плюс 1.
[01:19:39.520 --> 01:19:47.520]  Поэтому я меняю местами a l плюс первая и a it.
[01:19:47.520 --> 01:19:50.520]  Вот, с опытом как раз поменять местами два элемента.
[01:19:50.520 --> 01:19:54.520]  Ну и, видимо, увеличу l на 1, потому что у меня выросло...
[01:19:54.520 --> 01:19:57.520]  Да, у меня выросло количество элементов меньше, чем х.
[01:19:57.520 --> 01:20:01.520]  То есть было вот так, стало вот так.
[01:20:01.520 --> 01:20:06.520]  Все, вот это partition.
[01:20:06.520 --> 01:20:13.520]  В результате выполнения такого цикла у меня все элементы с 0 по l будут меньше, чем х,
[01:20:13.520 --> 01:20:17.520]  все элементы с l плюс 1 по n минус 1 будут больше равны, чем х.
[01:20:17.520 --> 01:20:20.520]  Это не совсем то, что мы хотели вот в той картинке,
[01:20:20.520 --> 01:20:24.520]  потому что элементы равны х где-то вот здесь вот затесались.
[01:20:24.520 --> 01:20:27.520]  Ну если надо, мы можем их вот сюда вот переставить, но на самом деле не надо.
[01:20:27.520 --> 01:20:32.520]  Можно просто так же честно посажировать этот кусок, посажировать этот кусок.
[01:20:32.520 --> 01:20:36.520]  Все равно в среднем эти куски оба будут достаточно большие
[01:20:36.520 --> 01:20:39.520]  и не будет такого, что, скажем, я отщепил всего один элемент,
[01:20:39.520 --> 01:20:43.520]  или там вообще ничего не отщепил, да, и заново запускаюсь рекурсивно от массива большой длины.
[01:20:43.520 --> 01:20:48.520]  В силу того, что х случайная, на каждом таком шаге такое разбиение довольно эффективно.
[01:20:48.520 --> 01:20:52.520]  То есть у меня довольно много элементов будет здесь, довольно много элементов будет здесь.
[01:20:52.520 --> 01:20:53.520]  Да.
[01:20:59.520 --> 01:21:03.520]  Ну вот нет, смотрите, в такой постановке у меня все будет верно.
[01:21:03.520 --> 01:21:06.520]  То есть когда у меня ни один элемент не рассмотрен, я могу считать,
[01:21:06.520 --> 01:21:11.520]  что у меня элементы с 0 по минус 1, то есть никакие, меньше, чем х,
[01:21:11.520 --> 01:21:14.520]  а все остальные, но тоже никакие, потому что еще больше ничего не рассмотрен,
[01:21:14.520 --> 01:21:17.520]  больше равно, чем х. Короче, это тоже работает.
[01:21:17.520 --> 01:21:20.520]  Я вас уже не слышу, подойдите, если что. Все, до свидания.
