[00:00.000 --> 00:23.160]  Сегодня мы поговорим про рандомизированные алгоритмы и
[00:23.160 --> 00:35.160]  вероятностные, вероятностные, сложностные классы.
[00:35.160 --> 00:38.160]  Ну, вообще рандомизированные, вероятностные, это более-менее синонимы.
[00:38.160 --> 00:46.160]  Но вот традиционно в русском языке алгоритмы тоже могут называть вероятностными,
[00:46.160 --> 00:50.160]  но как-то чаще рандомизированными называют, а вот сложностные классы наоборот.
[00:50.160 --> 00:59.160]  Встречались ли вам где-нибудь такие алгоритмы в каких-нибудь других курсах там?
[00:59.160 --> 01:05.160]  Тестную простоту, да, очень хорошо.
[01:05.160 --> 01:09.160]  Тестную простоту, но на самом деле еще быстрая сортировка есть из таких совсем базовых примеров.
[01:09.160 --> 01:18.160]  Но еще есть такой известный метод, называется метод Монте-Карло.
[01:18.160 --> 01:24.160]  Что еще?
[01:24.160 --> 01:32.160]  Но на самом деле метод Монте-Карло есть, есть Лас-Вегас, есть даже Атлантик-Сити,
[01:32.160 --> 01:37.160]  но на самом деле метод Монте-Карло это с одной стороны некоторые конкретные методы,
[01:37.160 --> 01:40.160]  а с другой стороны некоторые классы методов.
[01:40.160 --> 01:45.160]  А Лас-Вегас это в основном класс методов.
[01:45.160 --> 01:57.160]  В общем, давайте поговорим про метод Монте-Карло.
[01:57.160 --> 02:02.160]  Идея рандомизированных алгоритмов стоит в том, что они позволяют сделать что-то,
[02:02.160 --> 02:06.160]  чего не позволяют сделать обычные детерминированные алгоритмы.
[02:06.160 --> 02:14.160]  Вот метод Монте-Карло, который классический, так сказать, the Монте-Карло метод,
[02:14.160 --> 02:23.160]  конкретный метод связан с подсчетом интегралов, то есть площадей, объемов и так далее.
[02:23.160 --> 02:29.160]  Вот пусть у нас есть там какая-то фигура,
[02:29.160 --> 02:37.160]  и мы хотим посчитать ее площадь или ее объем.
[02:37.160 --> 02:43.160]  Вот если фигура двумерная, значит, тогда есть такой школьный метод.
[02:43.160 --> 02:54.160]  Школьный метод заключается в том, что разделить на какие-то клеточки маленькие.
[02:54.160 --> 03:00.160]  Ну и школьный метод стоит в том, чтобы посчитать, сколько клеток целиком попало в фигуру,
[03:00.160 --> 03:06.160]  и еще добавить половину кисла клеток, которые частично попали в фигуру.
[03:06.160 --> 03:15.160]  Ну и вот это, если можно оплочить клетки, то это будет приближение к площади фигуры.
[03:15.160 --> 03:23.160]  Ну и понятное дело, что чем мельче разбивать на клетке, тем ближе будет это приближение.
[03:23.160 --> 03:33.160]  Ну, конечно, предполагает, что фигура какая-то нормальная, с какой-нибудь гладкой границей и так далее.
[03:33.160 --> 03:36.160]  С задним каким-то уравнением, например.
[03:36.160 --> 03:42.160]  Тогда да, можно так считать.
[03:42.160 --> 03:50.160]  Ну, конечно, предполагается, что мы как-то умеем понимать, лежит ли клетка внутри или в ней, или на границе.
[03:51.160 --> 03:59.160]  Ну, например, если мы по одной точке умеем понимать, лежит она внутри или вне, то хорошим приближением будет просто про четыре угла.
[03:59.160 --> 04:02.160]  Посмотреть, лежат они внутри или вне.
[04:02.160 --> 04:04.160]  Ну и понятно, что можно как-то залезть.
[04:04.160 --> 04:08.160]  Вот даже на картинке такого и нету, да.
[04:08.160 --> 04:12.160]  Залезать какую-то клетку.
[04:12.160 --> 04:14.160]  А, ну вот эта вот клетка так похожа.
[04:14.160 --> 04:18.160]  А, нет, неправильно, да, у нее тоже с разных сторон.
[04:18.160 --> 04:21.160]  Да, в общем, я так абстрактно писал, даже нет такого примера.
[04:21.160 --> 04:28.160]  Но понятное дело, что можно придумать так, что она там как-нибудь вот так вот вылезает.
[04:28.160 --> 04:31.160]  Нет, не так.
[04:31.160 --> 04:32.160]  Сейчас.
[04:32.160 --> 04:34.160]  Что нужно сделать?
[04:34.160 --> 04:36.160]  А, вот так, наоборот.
[04:36.160 --> 04:44.160]  Да, тогда вот у этой клетки четыре угла внутри, но она не целиком внутри.
[04:44.160 --> 04:45.160]  Вот.
[04:45.160 --> 04:53.160]  Но опять же ясно, что чем, да, значит, чем меньше разбить, тем меньше такого будет происходить.
[04:53.160 --> 04:56.160]  И в пределе все равно все нормально будет.
[04:56.160 --> 04:59.160]  Соответственно, можно достаточно мелко разбить.
[04:59.160 --> 05:02.160]  По всем углам посчитать, лежат они внутри или вне.
[05:02.160 --> 05:05.160]  Те, где углы лежат внутри, считать, что они целиком внутри.
[05:05.160 --> 05:08.160]  Те, где углы лежат вне, считать, что они целиком вне.
[05:08.160 --> 05:11.160]  А те, где часть так, часть так, считать наполовину.
[05:11.160 --> 05:16.160]  Или можно даже считать, что если у меня там три угла внутри и один вне, то она там на три части лежит внутри.
[05:16.160 --> 05:18.160]  Вот.
[05:18.160 --> 05:21.160]  И вот это вот будет каким-то приближением.
[05:21.160 --> 05:22.160]  Вот.
[05:22.160 --> 05:26.160]  И это даже будет довольно неплохо работать, если фигура двумерная.
[05:26.160 --> 05:37.160]  Но если фигура многомерная, то возникает проблема, что если вы там на n части делите по измерению, а у вас d измерений,
[05:37.160 --> 05:42.160]  то всего у вас будет n в степени d частей.
[05:42.160 --> 05:47.160]  То есть получается, что как бы ваша сложность...
[05:47.160 --> 05:52.160]  Ну, а n как-то связана с точностью приближения.
[05:52.160 --> 05:56.160]  То есть сложность будет вроде бы полиномиальная на степени d.
[05:56.160 --> 05:59.160]  Но она будет полиномиальная по точности приближения.
[05:59.160 --> 06:02.160]  А вот по размерности она будет экспоненциальная.
[06:02.160 --> 06:11.160]  И, соответственно, если d достаточно большое, там 10-мерное, там какое-нибудь 10-мерное, то уже никаким образом это считать нельзя.
[06:11.160 --> 06:14.160]  Будет слишком...
[06:14.160 --> 06:21.160]  Для приемлемой точности будет слишком большое число ячеек, которые все нужно обработать.
[06:21.160 --> 06:22.160]  Вот.
[06:22.160 --> 06:26.160]  Поэтому в чем заключается метод Monte Carlo?
[06:26.160 --> 06:28.160]  Он заключается вот в чем.
[06:28.160 --> 06:34.160]  То вот у нас есть там какая-то такая же фигура.
[06:34.160 --> 06:42.160]  И мы вместо того, чтобы как-то ее целиком охватывать, мы просто занимаемся тем, что случайным образом...
[06:42.160 --> 06:48.160]  Значит, случайным образом кидаем какие-то точки.
[06:48.160 --> 06:50.160]  Да.
[06:50.160 --> 06:54.160]  В общем, каким-то образом случайно кидаем точки.
[06:54.160 --> 06:59.160]  Ну и считаем, какая доля точек попала внутрь фигуры.
[06:59.160 --> 07:15.160]  То есть площадь фигуры примерно равна доля случайно выбранных точек...
[07:15.160 --> 07:25.160]  Значит, попавших внутрь.
[07:25.160 --> 07:31.160]  Ну с номеров, конечно, да, то есть нужно эту...
[07:31.160 --> 07:37.160]  Либо вместо площади считать, что это доля площади внутриобъемлющего прямоугольника,
[07:37.160 --> 07:42.160]  либо, наоборот, вот здесь вот умножить на эту самую площадь объемлющего прямоугольника.
[07:42.160 --> 07:46.160]  Вот.
[07:46.160 --> 07:49.160]  Ну вот это есть метод Monte Carlo.
[07:49.160 --> 07:57.160]  То есть кинем случайно точки, посчитаем, какая доля попала внутрь, нормируем, и это будет ответ.
[07:57.160 --> 08:00.160]  А это почему работает?
[08:00.160 --> 08:04.160]  Ну это работает из предельной сиаремы.
[08:04.160 --> 08:11.160]  Что, смотрите, вероятность того, что точка попала внутрь фигуры...
[08:11.160 --> 08:18.160]  Ну опять же, если нормальная там измеримая фигура, то вероятность равняется доля внутри площади.
[08:18.160 --> 08:24.160]  А у вас уже какой-нибудь вервер был?
[08:24.160 --> 08:27.160]  Да, в общем, почти ничем не отличается.
[08:27.160 --> 08:32.160]  В общем, это и то, и другое это мера.
[08:32.160 --> 08:35.160]  Да, ну вы что-то уже знаете оттуда?
[08:35.160 --> 08:37.160]  Ничего не знаете?
[08:41.160 --> 08:45.160]  Не, ну смотрите, да, у вероятности есть...
[08:45.160 --> 08:50.160]  Ну вот, что там в самом начале изучаю, да, или в школе, что была комбинаторная вероятность,
[08:50.160 --> 08:55.160]  то у нас есть какое-то конечное множество вариантов, и, например, они все равновероятны.
[08:55.160 --> 09:01.160]  Или, может быть, каждому конкретному варианту приписано какое-то число там от меня до единицы, так что они суммируются к единице.
[09:01.160 --> 09:06.160]  И вот это число, это вероятность отдельного варианта для различных элементарных событий.
[09:09.160 --> 09:12.160]  И тогда, действительно, вероятность это...
[09:12.160 --> 09:19.160]  При равномерном распределении вероятности это просто доля множества хороших исходов, множества всех исходов.
[09:19.160 --> 09:23.160]  Ну а при не равномерном там эту долю с весами нужно взять.
[09:23.160 --> 09:30.160]  Вот, а еще будет геометрическая вероятность, когда у вас какое-то там пространство геометрическое,
[09:30.160 --> 09:32.160]  с мерой.
[09:32.160 --> 09:41.160]  И, соответственно, там нечетное число точек, поэтому попасть в конкретную точку можно только сравнению ноль.
[09:41.160 --> 09:47.160]  Но тогда говорят, опять при равномерном распределении говорят, что вероятность попасть в какую-то фигуру
[09:47.160 --> 09:50.160]  действительно пропорциональна площади этой фигуры.
[09:50.160 --> 09:59.160]  Ну а при не равномерном там как раз возникает общий понятие мер, там всякая сигма, алгебра и так далее.
[10:03.160 --> 10:06.160]  И мер тоже были. А, ну тогда вы, наверное, все знаете, что...
[10:06.160 --> 10:11.160]  Вероятность это просто такая мера, у которой по всему пространству мера единица.
[10:14.160 --> 10:16.160]  И, собственно, больше особо ничего.
[10:20.160 --> 10:22.160]  Вот.
[10:23.160 --> 10:29.160]  Ну вот, соответственно, да, действительно можно сказать, что вероятность, если мы берем случайную точку, то вероятность попасть внутрь фигуры
[10:29.160 --> 10:36.160]  действительно более-менее по определению равняется доле площади этой фигуры, в доле площади объявляющих пространства.
[10:37.160 --> 10:40.160]  Вот, а дальше есть предельная теорема.
[10:40.160 --> 10:45.160]  Там они бывают разные, там есть центральная предельная теорема, разные другие предельная теорема.
[10:45.160 --> 10:49.160]  Вот, и это как раз, видимо, будет на Тёрвере, пока особо не было.
[10:49.160 --> 10:52.160]  Но суть в том, что, если вы много раз проводите испытания,
[10:52.160 --> 10:58.160]  то у вас вот эта вот комбинаторная вероятность в том, что вы провели, да, то есть число успехов,
[10:58.160 --> 11:00.160]  поделительное число испытаний,
[11:00.160 --> 11:05.160]  стремится к настоящей вероятности, да, то есть к доле площади, в объявляющей площади.
[11:06.160 --> 11:08.160]  И стремится довольно быстро.
[11:09.160 --> 11:16.160]  Вот. Но при этом, там, как бы, в среднем стремится, да, а так-то, конечно, может быть, вам не повезло, да, и все ваши точки попали внутрь.
[11:16.160 --> 11:20.160]  Да, такое может произойти редко, но может.
[11:21.160 --> 11:26.160]  Вот. Ну, в таком случае вы сильно ошибетесь, да, подсчитывая долю.
[11:27.160 --> 11:29.160]  Вот. Может, наоборот, там все наружу попали.
[11:30.160 --> 11:33.160]  Но, скорее всего, да, там, с очень большой вероятностью,
[11:35.160 --> 11:45.160]  подсчитанная доля будет в небольшом интервале центром в настоящей вероятности, да, в настоящей доле.
[11:46.160 --> 11:56.160]  Вот. Ну, а там разные бывают, там, 95% на верительный интервал, там, 99%, да, это означает, что если у вас,
[11:57.160 --> 12:10.160]  ну, давайте я картинку нарисую, там есть такое колоколообразное распределение, да, оно уже распределение гауссом, да, что вот есть настоящая,
[12:10.160 --> 12:14.160]  настоящая тестота, настоящая вероятность.
[12:15.160 --> 12:17.160]  Вот. И есть то, что у вас получилось.
[12:18.160 --> 12:28.160]  Вот. И подлесно распределение, оно как-то вот так вот выглядит, да, вот такая вот колоколообразная функция.
[12:28.160 --> 12:44.160]  Вот. Ну, то есть тут, как бы, чтобы, если не вдаваться там в детали, прям в тюрвер, то идея такая.
[12:45.160 --> 12:47.160]  Пусть мы вот наши испытания проводим и n раз.
[12:48.160 --> 12:54.160]  И еще вот эти вот n раз, да, как бы, эти n раз тоже еще много раз повторяем.
[12:54.160 --> 13:00.160]  Вот. И вот здесь вот, как бы, по вертикали написано, насколько часто возникает такой вариант.
[13:01.160 --> 13:05.160]  Да, то есть чаще всего будет прямо ровно в настоящем значении.
[13:06.160 --> 13:09.160]  Да, немножко направо, немножко налево будет пореже.
[13:10.160 --> 13:16.160]  А если сильно направо или сильно налево, это будет еще реже, и вот эти вот хвосты, как говорят, легкие.
[13:17.160 --> 13:21.160]  Да, это легкие хвосты, то есть, они экспедиционно маленькие.
[13:21.160 --> 13:23.160]  Да, то есть, они экспедиционно маленькие.
[13:26.160 --> 13:28.160]  Вот. Ну, вот это вот по-простому, да, значит, что означает.
[13:29.160 --> 13:42.160]  Есть такой эксперимент, знаете, можно прямо изготовить, изготовить такую штуку, что, как бы, вот такая вот пирамида, да, из каких-то таких штучек.
[13:42.160 --> 13:52.160]  Да, значит, так что там сверху, ну, и так далее, да, значит, как бы сверху падает шарик, и он равновероятно падает сюда или сюда.
[13:53.160 --> 14:00.160]  Вот. Потом, соответственно, вот эти вот, как бы, глотики так поставлены, что, если он падает сюда, то после этого он тоже еще равновероятно, вот сюда вот или вот сюда, вот.
[14:01.160 --> 14:02.160]  И здесь тоже равновероятно, сюда и сюда.
[14:03.160 --> 14:11.160]  Вот. Ну, и так, вот если сверху много шариков начать сыпать, да, а здесь, в самом низу еще будут как бы такие ловушки для них.
[14:12.160 --> 14:16.860]  то как раз в центральной ловушке будет больше всего шариков, там левее-правее, немножко поменьше,
[14:16.860 --> 14:22.480]  еще левее-правее, еще немножко поменьше, а если сильно, там в самой правой и самой левой почти ничего не будет.
[14:22.480 --> 14:25.040]  И форма будет прямо вот примерно такая.
[14:30.480 --> 14:32.480]  Ну, типа того, да.
[14:32.480 --> 14:36.960]  Да-да-да, да, цешки асимпатические будут вот так вот.
[14:37.880 --> 14:40.760]  Вот, но на самом деле, да, значит вот
[14:41.800 --> 14:48.400]  центральная предельная теорема говорит, что даже не обязательно, чтобы было равновероятно.
[14:49.200 --> 14:57.320]  То есть, например, если мы сделаем так, что у каждого гвоздика, скажем, средство 1 треть падает налево, а 2 третьи направо.
[14:57.880 --> 15:04.240]  Да, вот так как-то немножко подвинем, но так и тут тоже 1 треть налево, там 2 третьи направо, да, и так у каждого гвоздика.
[15:05.240 --> 15:08.120]  Вот, тогда как бы центр сместится,
[15:09.640 --> 15:12.760]  вот самый высокий столбик будет не на середине, а как раз на 2 третьях.
[15:14.640 --> 15:19.120]  Вот, но вокруг этого столбика все равно будет картина прямо такая вот в пределе.
[15:20.920 --> 15:26.880]  Да, то есть он там никуда не будет скошено, а все равно будет вот так вот распределено.
[15:26.880 --> 15:34.880]  Вот, там уже будут не цешки, но там будут цешки с какими-то степенями, да, по биному ньютона, вот, но все равно симпатически это будет вот так вот.
[15:41.200 --> 15:43.200]  Вот,
[15:43.600 --> 15:45.600]  ну и
[15:45.800 --> 15:47.800]  значит, что еще нужно знать про
[15:49.000 --> 15:55.000]  центрально предельную теорему, да, что если у нас n испытаний, да, то тогда как бы ширина
[15:55.480 --> 16:02.720]  типичная ширина вот этого колокола будет порядка 1 делить на корень из m.
[16:09.000 --> 16:11.000]  Вот, но ширина еще есть такое слово дисперсия,
[16:12.520 --> 16:14.880]  насколько, ну дисперсия это как бы разброс,
[16:15.800 --> 16:24.000]  насколько сильно, соответственно, вот чем больше испытаний, тем уже будет этот колокол, да, и тем точнее будет предсказание.
[16:25.000 --> 16:31.440]  Вот, но это очень важно, да, что если мы хотим тут получить точность епсилом,
[16:31.800 --> 16:35.520]  то это означает, что число испытаний должно быть порядка 1 делить на епсилон в квадрате.
[16:38.120 --> 16:45.040]  Вот, а и это не зависит от размерности, да, то есть нам главное было,
[16:45.760 --> 16:47.760]  значит, нам главное уметь
[16:48.120 --> 16:49.480]  подхитать,
[16:49.480 --> 16:51.480]  лежит наша точка внутри фигуры или не лежит,
[16:52.360 --> 16:55.840]  да, то есть, чтобы понять, как бы испытание удалось или не удалось.
[16:56.600 --> 17:02.280]  Вот, и тогда размер не важна, размер не важна, все равно будет полинамиальное число испытаний, чтобы получить
[17:03.920 --> 17:05.920]  точность
[17:06.120 --> 17:08.120]  порядка и епсилон.
[17:10.920 --> 17:17.760]  Да, да, по вертикали насколько часто возникает такая доля, да, по горизонтали сама доля.
[17:18.760 --> 17:22.760]  Вот, но и это гораздо лучше, чем метод разбивания на ячейке,
[17:23.440 --> 17:29.840]  потому что в методе разбивания на ячейке, чтобы получить точность епсилон, нужно порядка 1 делить на епсилон в степени D,
[17:30.760 --> 17:32.760]  испытаний, где D это размерность.
[17:34.360 --> 17:36.360]  А тут порядка 1 делить на епсилон в квадрате,
[17:38.640 --> 17:40.640]  независимо от размерности.
[17:40.920 --> 17:46.720]  Вот, но тем не менее возможны ошибки, да, то есть какой бы тут легкий хвост не был, все равно можно попасть вот сюда.
[17:47.760 --> 17:57.760]  Таким образом, да, значит, это вот конкретный метод Монте-Карло для подсчета объема многомерного.
[17:58.760 --> 18:00.760]  Ну а вообще,
[18:06.760 --> 18:15.760]  в общем случае, методами Монте-Карло
[18:18.760 --> 18:20.760]  называют
[18:26.760 --> 18:28.760]  рандомизированные алгоритмы,
[18:32.760 --> 18:41.760]  значит, которые всегда работают за, ну у которых есть какая-то оценка на время работы
[18:41.760 --> 18:46.760]  гарантированная, да, значит, имеющая
[18:50.760 --> 18:52.760]  гарантированную оценку
[18:55.760 --> 18:57.760]  на время работы,
[18:59.760 --> 19:01.760]  но иногда ошибающаяся,
[19:03.760 --> 19:05.760]  значит, но
[19:06.760 --> 19:08.760]  могущее
[19:11.760 --> 19:13.760]  ошибат.
[19:17.760 --> 19:26.760]  Ну, тут, соответственно, ну и может быть какое-то соотношение между временем работы и вероятностью ошибки, да, что здесь происходит.
[19:28.760 --> 19:30.760]  Так, а теперь действительно есть алгоритмы Лас-Вегаса.
[19:32.760 --> 19:34.760]  Значит, алгоритмы Лас-Вегаса
[19:35.760 --> 19:37.760]  наоборот
[19:41.760 --> 19:46.760]  никогда не ошибаются, но могут работать очень долго иногда.
[19:48.760 --> 19:50.760]  Никогда
[19:52.760 --> 19:54.760]  не ошибаются,
[19:56.760 --> 19:58.760]  но могут
[19:58.760 --> 20:00.760]  работать долго.
[20:08.760 --> 20:10.760]  Вот, ну давайте я так не,
[20:11.760 --> 20:13.760]  приведу пример,
[20:13.760 --> 20:16.760]  значит, он формально не совсем подходит, потому что он
[20:16.760 --> 20:18.760]  не может быть
[20:19.760 --> 20:21.760]  там, что вот есть вход и есть выход,
[20:22.760 --> 20:24.760]  но концептуально будет именно так.
[20:25.760 --> 20:27.760]  Значит, это пример,
[20:28.760 --> 20:30.760]  ну, точнее можно сказать, что там
[20:30.760 --> 20:32.760]  выход есть, но он сам по себе случайный.
[20:33.760 --> 20:35.760]  Значит, пример, как сгенерировать
[20:37.760 --> 20:39.760]  вещество,
[20:40.760 --> 20:42.760]  как сгенерировать
[20:43.760 --> 20:45.760]  вещество,
[20:45.760 --> 20:47.760]  как сгенерировать
[20:49.760 --> 20:51.760]  как сгенерировать
[20:52.760 --> 20:54.760]  бит
[20:55.760 --> 20:57.760]  равный
[20:58.760 --> 21:00.760]  единице со вероятностью
[21:01.760 --> 21:03.760]  1 треть.
[21:03.760 --> 21:05.760]  Ну и, соответственно, и нулю, в принципе, 2 третья.
[21:09.760 --> 21:11.760]  Нулю с
[21:11.760 --> 21:13.760]  вероятностью.
[21:15.760 --> 21:17.760]  Вот, ну а чем это может быть?
[21:18.760 --> 21:20.760]  Ну, может быть так, что это непосредственно где-то
[21:20.760 --> 21:22.760]  используется.
[21:22.760 --> 21:24.760]  Например, вам нужно
[21:24.760 --> 21:26.760]  кинуть кубик.
[21:26.760 --> 21:28.760]  Да, до какой-то игры нужно кинуть кубик.
[21:28.760 --> 21:30.760]  Значит, у кубика 6 вариантов.
[21:32.760 --> 21:34.760]  Ну, вот, соответственно,
[21:35.760 --> 21:37.760]  можно считать, что
[21:37.760 --> 21:39.760]  что получить 11 вариантов
[21:39.760 --> 21:41.760]  нужно
[21:41.760 --> 21:43.760]  кинуть монетку
[21:43.760 --> 21:45.760]  и еще кинуть
[21:45.760 --> 21:47.760]  ну,
[21:47.760 --> 21:49.760]  да, может быть, начиная с такого
[21:49.760 --> 21:51.760]  может быть немножко сложнее, да, но
[21:51.760 --> 21:53.760]  в общем, какую-то монетку
[21:53.760 --> 21:55.760]  с тремя исходами равновероятно.
[21:57.760 --> 21:59.760]  Вот. Ну, вот это не даже более
[21:59.760 --> 22:01.760]  вроде как более простой вариант,
[22:01.760 --> 22:03.760]  что просто единица 171 треть, но и 172 треть.
[22:03.760 --> 22:05.760]  Как такая вкошенная монетка.
[22:07.760 --> 22:09.760]  Ну, или может быть действительно
[22:11.760 --> 22:13.760]  может быть прям такое нужно
[22:13.760 --> 22:15.760]  например, вы, скажем,
[22:15.760 --> 22:17.760]  пишете какую-нибудь компьютерную игру,
[22:17.760 --> 22:19.760]  где там сражаются какие-то силы
[22:19.760 --> 22:21.760]  и соответственно
[22:21.760 --> 22:23.760]  вероятность победы зависит
[22:23.760 --> 22:25.760]  от соотношения сил.
[22:25.760 --> 22:27.760]  И соотношение сил такое, что вероятность
[22:27.760 --> 22:29.760]  как раз вот такая вот.
[22:29.760 --> 22:31.760]  И вам нужно сгенерировать такой бит.
[22:31.760 --> 22:33.760]  Вот. А вы, например, умеете
[22:33.760 --> 22:35.760]  генерировать просто бит.
[22:35.760 --> 22:37.760]  Это вообще, на самом деле, интересный вопрос.
[22:37.760 --> 22:39.760]  Где вообще брать случайные биты?
[22:39.760 --> 22:41.760]  Сейчас, может, обсудим немножко.
[22:41.760 --> 22:43.760]  Вот. Допустим, мы умеем кидать
[22:43.760 --> 22:45.760]  честную монетку, да, и у нас есть
[22:45.760 --> 22:47.760]  источник битов, которые
[22:47.760 --> 22:49.760]  равновероятно нуле единицы, да,
[22:49.760 --> 22:51.760]  и независимы друг от друга.
[22:51.760 --> 22:53.760]  Так. Это вообще все понятные слова
[22:53.760 --> 22:55.760]  говорю, что независимы?
[22:55.760 --> 22:57.760]  Ну да. Да, да, да.
[22:57.760 --> 22:59.760]  Формальное определение,
[22:59.760 --> 23:01.760]  что вероятность
[23:01.760 --> 23:03.760]  пересечения событий
[23:03.760 --> 23:05.760]  это произведение вероятностей.
[23:05.760 --> 23:07.760]  Вот. Ну, на самом деле, можно сказать так, что
[23:07.760 --> 23:09.760]  независимые события
[23:09.760 --> 23:11.760]  означают, что
[23:11.760 --> 23:13.760]  исход одного не влияет
[23:13.760 --> 23:15.760]  на исход другого.
[23:15.760 --> 23:17.760]  Ну, в общем-то,
[23:17.760 --> 23:19.760]  мы можем сказать так, что
[23:19.760 --> 23:21.760]  независимые события
[23:21.760 --> 23:23.760]  означают, что исход одного
[23:23.760 --> 23:25.760]  другого.
[23:25.760 --> 23:27.760]  Да, то есть, вот если у вас есть
[23:27.760 --> 23:29.760]  там две монетки,
[23:29.760 --> 23:31.760]  да, вот мы кинули одну,
[23:31.760 --> 23:33.760]  значит, не важно,
[23:33.760 --> 23:35.760]  как кинули другую.
[23:35.760 --> 23:37.760]  Вот. Ну, например,
[23:37.760 --> 23:39.760]  например, пусть мы там кидаем монетку,
[23:39.760 --> 23:41.760]  монетка, то какой-то ветер дует,
[23:41.760 --> 23:43.760]  и этот ветер как-то так делает,
[23:43.760 --> 23:45.760]  что они чаще там орлом выпадают.
[23:45.760 --> 23:47.760]  Или, например,
[23:47.760 --> 23:49.760]  ветер как-то так
[23:49.760 --> 23:51.760]  дует, что они чаще выпадают
[23:51.760 --> 23:53.760]  вот это одинаково.
[23:53.760 --> 23:55.760]  Что мы не знаем точно,
[23:55.760 --> 23:57.760]  как именно он дует,
[23:57.760 --> 23:59.760]  но он на них как-то одинаково влияет.
[23:59.760 --> 24:01.760]  Вот. И тогда, значит, если мы одну
[24:01.760 --> 24:03.760]  монетку кинули, она выпала орлом,
[24:03.760 --> 24:05.760]  то тогда вторая тоже с большей
[24:05.760 --> 24:07.760]  верности орлом выпадет,
[24:07.760 --> 24:09.760]  потому что он как-то на них одинаково влияет.
[24:09.760 --> 24:11.760]  Вот.
[24:11.760 --> 24:13.760]  Вот это зависимость.
[24:13.760 --> 24:15.760]  Ну, а независимость означает,
[24:15.760 --> 24:17.760]  что ничего такого не происходит, да,
[24:17.760 --> 24:19.760]  и то, что там одна монета как-то выпала,
[24:19.760 --> 24:21.760]  никак не влияет на то, как все остальные выпадут.
[24:23.760 --> 24:25.760]  Вот.
[24:25.760 --> 24:27.760]  Хорошо, значит, пусть у нас такие биты есть,
[24:27.760 --> 24:29.760]  и мы хотим вот так вот делать.
[24:29.760 --> 24:31.760]  А что, может, кто-нибудь
[24:31.760 --> 24:33.760]  знает, как это делать?
[24:35.760 --> 24:37.760]  Да.
[24:45.760 --> 24:47.760]  Ага.
[24:49.760 --> 24:51.760]  Угу.
[24:53.760 --> 24:55.760]  Угу.
[24:55.760 --> 24:57.760]  Да, совершенно верно.
[24:57.760 --> 24:59.760]  Значит, вот предлагается
[24:59.760 --> 25:01.760]  такой алгоритм
[25:01.760 --> 25:03.760]  генерации этого бита.
[25:03.760 --> 25:05.760]  Соответственно, если
[25:05.760 --> 25:07.760]  два нуля,
[25:07.760 --> 25:09.760]  то...
[25:09.760 --> 25:11.760]  Так, мы что хотим?
[25:11.760 --> 25:13.760]  А, мы хотим, чтобы единица была в том числе на треть.
[25:13.760 --> 25:15.760]  Так, давайте тогда...
[25:15.760 --> 25:17.760]  Если две единицы,
[25:17.760 --> 25:19.760]  то тогда
[25:19.760 --> 25:21.760]  исход один.
[25:21.760 --> 25:23.760]  Значит, если
[25:23.760 --> 25:25.760]  ноль один или один ноль,
[25:25.760 --> 25:27.760]  то тогда исход ноль.
[25:27.760 --> 25:29.760]  Значит, а если два нуля,
[25:29.760 --> 25:31.760]  то тогда повтор.
[25:33.760 --> 25:35.760]  То есть кидаем еще,
[25:35.760 --> 25:37.760]  еще раз две монеты кидаем, и все то же самое.
[25:39.760 --> 25:41.760]  Ну и, соответственно, видно, что
[25:41.760 --> 25:43.760]  такой алгоритм
[25:43.760 --> 25:45.760]  вообще может никогда не закончиться.
[25:45.760 --> 25:47.760]  Потому что, в принципе, может быть так,
[25:47.760 --> 25:49.760]  что он все время кидает, да,
[25:49.760 --> 25:51.760]  нули, нули, нули получаются.
[25:51.760 --> 25:53.760]  Да, и вообще ничего другого никогда больше не выпадет.
[25:55.760 --> 25:57.760]  Вот. Ну, такая, конечно,
[25:57.760 --> 25:59.760]  рст ноль бывает.
[25:59.760 --> 26:01.760]  Вот.
[26:01.760 --> 26:03.760]  Ну, а теперь в среднем,
[26:03.760 --> 26:05.760]  да, в среднем это очень быстро закончится.
[26:05.760 --> 26:07.760]  Да, можно там
[26:07.760 --> 26:09.760]  посчитать
[26:09.760 --> 26:11.760]  среднее число бросков, да, то есть у нас
[26:11.760 --> 26:13.760]  в среднем три четрати будет вообще один бросок.
[26:13.760 --> 26:15.760]  Ну, точнее два.
[26:15.760 --> 26:17.760]  С 73 будет два броска,
[26:17.760 --> 26:19.760]  с 73-16-ых будет четыре броска и так далее.
[26:19.760 --> 26:21.760]  В среднем
[26:21.760 --> 26:23.760]  ну,
[26:23.760 --> 26:25.760]  4 третьих умножить на два, да, то есть
[26:25.760 --> 26:27.760]  4 третьих раунда будет.
[26:27.760 --> 26:29.760]  Да, 4 третьих раунда или 8 третьих бросков.
[26:29.760 --> 26:31.760]  Вот. То есть в среднем это быстро,
[26:31.760 --> 26:33.760]  но никакой конкретной
[26:33.760 --> 26:35.760]  верхней оценки нет.
[26:35.760 --> 26:37.760]  Ну и вообще понятно,
[26:37.760 --> 26:39.760]  что если у нас ограничено
[26:39.760 --> 26:41.760]  число бросков,
[26:41.760 --> 26:43.760]  то одну треть и две третьи
[26:43.760 --> 26:45.760]  мы не можем получить. Будут получаться
[26:45.760 --> 26:47.760]  только какие-то дроби
[26:47.760 --> 26:49.760]  со вспоминатием степени у двойки.
[26:51.760 --> 26:53.760]  Да, потому что у нас всегда два степени
[26:53.760 --> 26:55.760]  максимально числа бросков в вариантах.
[26:55.760 --> 26:57.760]  Да, и из них
[26:57.760 --> 26:59.760]  какое-то слово подходит.
[26:59.760 --> 27:01.760]  Соответственно, если мы на каком-то
[27:01.760 --> 27:03.760]  этапе это остановим,
[27:03.760 --> 27:05.760]  и вместо того, чтобы повторять, выдадим там
[27:05.760 --> 27:07.760]  что-то по умолчанию, то у нас вместо
[27:07.760 --> 27:09.760]  одной трети и двух третьей будут какие-то
[27:09.760 --> 27:11.760]  дроби приближенные
[27:11.760 --> 27:13.760]  к одной трети и двум третьям
[27:13.760 --> 27:15.760]  со взнаменателями степень двойки.
[27:17.760 --> 27:19.760]  Ну а симпатически, если
[27:19.760 --> 27:21.760]  нужно никогда не заканчиваться,
[27:21.760 --> 27:23.760]  то тогда будет
[27:23.760 --> 27:25.760]  одна треть и две треть.
[27:25.760 --> 27:27.760]  И в этом смысле он никогда не ошибется.
[27:29.760 --> 27:31.760]  То есть всегда будет
[27:31.760 --> 27:33.760]  точно будет вероятность одна треть и две третьи.
[27:35.760 --> 27:37.760]  Но, значит,
[27:37.760 --> 27:39.760]  оно действительно может работать долго.
[27:43.760 --> 27:45.760]  Так, хорошо.
[27:47.760 --> 27:49.760]  Ну раз как я же говорил,
[27:49.760 --> 27:51.760]  как раз пять минут до перерыва,
[27:51.760 --> 27:53.760]  давайте поговорим про то,
[27:53.760 --> 27:55.760]  откуда брать
[27:59.760 --> 28:01.760]  случайные биты.
[28:07.760 --> 28:09.760]  Конечно, если мы говорим про модель,
[28:09.760 --> 28:11.760]  то можно сказать,
[28:11.760 --> 28:13.760]  что они просто там откуда-то берутся.
[28:13.760 --> 28:15.760]  Да, можно по-разному говорить,
[28:15.760 --> 28:17.760]  что у машины есть команда
[28:17.760 --> 28:19.760]  получить случайный бит.
[28:19.760 --> 28:21.760]  Или есть заранее, где-то они
[28:21.760 --> 28:23.760]  на ленте уже записаны,
[28:23.760 --> 28:25.760]  заранее мы их только читаем.
[28:27.760 --> 28:29.760]  Или она сразу
[28:29.760 --> 28:31.760]  получает аргумент, который считается
[28:31.760 --> 28:33.760]  случайным.
[28:33.760 --> 28:35.760]  В общем, в модели можно
[28:35.760 --> 28:37.760]  разными способами делать,
[28:37.760 --> 28:39.760]  но это не представляет большой проблемы.
[28:39.760 --> 28:41.760]  А откуда на практике их брать?
[28:41.760 --> 28:43.760]  Ну, из каких-то процессов,
[28:43.760 --> 28:45.760]  которые мы считаем случайными.
[28:47.760 --> 28:49.760]  Значит, вот там есть
[28:51.760 --> 28:53.760]  каких-то
[28:53.760 --> 28:55.760]  хаотических процессов.
[29:01.760 --> 29:03.760]  Ну, я бы источники
[29:03.760 --> 29:05.760]  разделил на природные,
[29:05.760 --> 29:07.760]  технически и социальные.
[29:07.760 --> 29:09.760]  То есть природные
[29:09.760 --> 29:11.760]  это какие-нибудь там
[29:11.760 --> 29:13.760]  как облака движутся,
[29:13.760 --> 29:15.760]  или какие-нибудь там космические лучи,
[29:15.760 --> 29:17.760]  или какой-нибудь радиоактивный распад.
[29:17.760 --> 29:19.760]  В общем, какие-то такие
[29:19.760 --> 29:21.760]  природные процессы,
[29:21.760 --> 29:23.760]  которые либо очень сложные,
[29:23.760 --> 29:25.760]  типа как гидродинамика
[29:25.760 --> 29:27.760]  и движение облаков,
[29:27.760 --> 29:29.760]  либо вообще
[29:29.760 --> 29:31.760]  случайные,
[29:31.760 --> 29:33.760]  как нам согласно теории,
[29:33.760 --> 29:35.760]  как с радиоактивным распадом.
[29:37.760 --> 29:39.760]  Ну, техники,
[29:39.760 --> 29:41.760]  это можно питать там
[29:41.760 --> 29:43.760]  температуру процессора,
[29:43.760 --> 29:45.760]  или точное времяобращение
[29:45.760 --> 29:47.760]  к функции,
[29:47.760 --> 29:49.760]  что-нибудь такое можно брать.
[29:51.760 --> 29:53.760]  Время обращения компилятора
[29:53.760 --> 29:55.760]  к данной функции, например.
[29:55.760 --> 29:57.760]  Ну, это считается, что
[29:57.760 --> 29:59.760]  есть операционная система,
[29:59.760 --> 30:01.760]  и в какой конкретный момент
[30:01.760 --> 30:03.760]  будет выполнена эта программа.
[30:03.760 --> 30:05.760]  Это вроде как случайная вещь.
[30:05.760 --> 30:07.760]  Случайная какая-то вещь.
[30:07.760 --> 30:09.760]  Если говорить
[30:09.760 --> 30:11.760]  про социальные процессы,
[30:11.760 --> 30:13.760]  то можно какие-нибудь там биржевые индексы
[30:13.760 --> 30:15.760]  смотреть, какие-нибудь точные значения
[30:15.760 --> 30:17.760]  котировок.
[30:17.760 --> 30:19.760]  Можно смотреть, не знаю, как там люди
[30:19.760 --> 30:21.760]  через транкету в метро проходят,
[30:21.760 --> 30:23.760]  в какой точный момент.
[30:23.760 --> 30:25.760]  Ну и так далее.
[30:25.760 --> 30:27.760]  Есть много
[30:27.760 --> 30:29.760]  процессов,
[30:29.760 --> 30:31.760]  разной степени случайности,
[30:31.760 --> 30:33.760]  которые можно использовать для получения битов.
[30:35.760 --> 30:37.760]  Но дальше возникает вопрос.
[30:37.760 --> 30:39.760]  Возникает вопрос, насколько
[30:39.760 --> 30:41.760]  действительно случайная
[30:41.760 --> 30:43.760]  и насколько случайный бит получится.
[30:43.760 --> 30:45.760]  То есть, если это какое-нибудь движение
[30:45.760 --> 30:47.760]  облаков, то оно же вообще не совсем случайное.
[30:47.760 --> 30:49.760]  Там есть какие-то
[30:49.760 --> 30:51.760]  закономерности.
[30:51.760 --> 30:53.760]  И не повлияют ли эти закономерности
[30:53.760 --> 30:55.760]  на то, что мы будем получать?
[30:55.760 --> 30:57.760]  Если речь идет
[30:57.760 --> 30:59.760]  о квантовых процессах,
[30:59.760 --> 31:01.760]  и мы верим, что они
[31:01.760 --> 31:03.760]  по-настоящему случайные,
[31:03.760 --> 31:05.760]  то все равно стоит вопрос об их измерении.
[31:05.760 --> 31:07.760]  И нет ли какой-то
[31:07.760 --> 31:09.760]  систематической ошибки в приборе,
[31:09.760 --> 31:11.760]  который их измеряет.
[31:13.760 --> 31:15.760]  То есть, так или иначе
[31:17.760 --> 31:19.760]  есть какое-то
[31:19.760 --> 31:21.760]  отклонение,
[31:21.760 --> 31:23.760]  могут быть какие-то неравномерности,
[31:23.760 --> 31:25.760]  но дальше возникает вопрос,
[31:25.760 --> 31:27.760]  что с ними делать.
[31:33.760 --> 31:35.760]  В общем, вопрос,
[31:35.760 --> 31:37.760]  зачем они
[31:37.760 --> 31:39.760]  используются.
[31:39.760 --> 31:41.760]  Если, например,
[31:41.760 --> 31:43.760]  в методе Монте-Карло используется,
[31:43.760 --> 31:45.760]  то нам совершенно не важно,
[31:45.760 --> 31:47.760]  какие они на самом деле,
[31:47.760 --> 31:49.760]  вот эти точки не на самом деле случайные,
[31:49.760 --> 31:51.760]  или у них какая-то такая
[31:51.760 --> 31:53.760]  хактическая закономерность,
[31:53.760 --> 31:55.760]  что ее очень трудно предсказать.
[31:55.760 --> 31:57.760]  Нам важно, чтобы их использование давало правильный ответ,
[31:57.760 --> 31:59.760]  или почти правильный.
[31:59.760 --> 32:01.760]  Чтобы, по крайней мере,
[32:01.760 --> 32:03.760]  ошибка была не сильно больше, чем при естественно случайных.
[32:07.760 --> 32:09.760]  Ну, тогда, на самом деле, если мы так хотим,
[32:09.760 --> 32:11.760]  то можно
[32:11.760 --> 32:13.760]  вообще
[32:13.760 --> 32:15.760]  не особо заботиться,
[32:15.760 --> 32:17.760]  на самом деле, об обычной случайности.
[32:17.760 --> 32:19.760]  То есть, вообще
[32:19.760 --> 32:21.760]  генераторы случайности,
[32:21.760 --> 32:23.760]  генераторы случайности
[32:23.760 --> 32:25.760]  делятся на генераторы
[32:25.760 --> 32:27.760]  истинно случайных битов.
[32:31.760 --> 32:33.760]  Это как раз то, про что я сказал.
[32:35.760 --> 32:37.760]  Какие-то природные
[32:37.760 --> 32:39.760]  или технические
[32:39.760 --> 32:41.760]  процессы.
[32:41.760 --> 32:43.760]  И также будут генераторы
[32:43.760 --> 32:45.760]  псевдослучайных битов.
[32:45.760 --> 32:47.760]  Вот.
[32:47.760 --> 32:49.760]  И вот эти вот псевдослучайные биты,
[32:49.760 --> 32:51.760]  они вообще не случайные.
[32:51.760 --> 32:53.760]  Да, они генерируются
[32:53.760 --> 32:55.760]  сложным, но детерминированным процессом.
[32:57.760 --> 32:59.760]  Но, как раз, если псевдослучайные
[32:59.760 --> 33:01.760]  работают так же хорошо, как
[33:01.760 --> 33:03.760]  по-настоящему случайные
[33:03.760 --> 33:05.760]  мысли вычисления,
[33:05.760 --> 33:07.760]  то вообще было бы очень хорошо именно их использовать.
[33:09.760 --> 33:11.760]  Но дальше возникает вопрос
[33:11.760 --> 33:13.760]  может так сделать или нет.
[33:15.760 --> 33:17.760]  Ну, вот, соответственно,
[33:17.760 --> 33:19.760]  с истинно случайными
[33:19.760 --> 33:21.760]  возникает вопрос
[33:21.760 --> 33:23.760]  о об улучшении
[33:23.760 --> 33:25.760]  случайности.
[33:25.760 --> 33:27.760]  У нас может быть какой-то первичный генератор
[33:27.760 --> 33:29.760]  из случайного,
[33:29.760 --> 33:31.760]  из котического процесса,
[33:31.760 --> 33:33.760]  а мы его выход как-то улучшаем,
[33:33.760 --> 33:35.760]  чтобы там распределение было
[33:35.760 --> 33:37.760]  получше.
[33:37.760 --> 33:39.760]  Таким-то образом.
[33:39.760 --> 33:41.760]  Ну, а про псевдослучайные,
[33:41.760 --> 33:43.760]  их улучшение
[33:43.760 --> 33:45.760]  это
[33:45.760 --> 33:47.760]  какая-то модификация
[33:47.760 --> 33:49.760]  генератора, так, чтобы
[33:49.760 --> 33:51.760]  он обманывал побольше тестов
[33:51.760 --> 33:53.760]  случайности.
[33:53.760 --> 33:55.760]  Так что, то, что это псевдослучайные,
[33:55.760 --> 33:57.760]  а не истинно случайные, никто бы не заметил.
[33:59.760 --> 34:01.760]  Так, ну ладно, сейчас
[34:01.760 --> 34:03.760]  прижим сделаем.
[34:03.760 --> 34:05.760]  Потом
[34:05.760 --> 34:07.760]  перейдем, значит.
[34:09.760 --> 34:11.760]  Так.
[34:15.760 --> 34:17.760]  Так, значит, теперь поговорим про
[34:17.760 --> 34:19.760]  некоторые конкретные
[34:19.760 --> 34:21.760]  рандомизированные алгоритмы.
[34:21.760 --> 34:23.760]  Вот, ну и
[34:23.760 --> 34:25.760]  прям такой классический пример.
[34:25.760 --> 34:27.760]  Это тесты
[34:27.760 --> 34:29.760]  про статуи.
[34:35.760 --> 34:37.760]  Что-то в конце 70-х годов
[34:37.760 --> 34:39.760]  был прям взрыв интерес
[34:39.760 --> 34:41.760]  к этой теме.
[34:41.760 --> 34:43.760]  Связанный, прежде всего, с открытием
[34:43.760 --> 34:45.760]  с открытым ключом
[34:45.760 --> 34:47.760]  криптосистемы RSA.
[34:47.760 --> 34:49.760]  Значит, которая для своей работы
[34:49.760 --> 34:51.760]  требовала простых чисел,
[34:51.760 --> 34:53.760]  довольно больших.
[34:53.760 --> 34:55.760]  И, соответственно,
[34:55.760 --> 34:57.760]  поэтому требовалось
[34:57.760 --> 34:59.760]  проверять простоту.
[35:01.760 --> 35:03.760]  Вот. И
[35:03.760 --> 35:05.760]  детерминированный алгоритм
[35:05.760 --> 35:07.760]  только через 25 лет, начале
[35:07.760 --> 35:09.760]  21-го века
[35:09.760 --> 35:11.760]  игровал Каял и Саксена.
[35:11.760 --> 35:13.760]  Вот.
[35:13.760 --> 35:15.760]  Хотя, ну, в принципе, конечно, математики
[35:15.760 --> 35:17.760]  с 18-го века интересовались
[35:17.760 --> 35:19.760]  проекты простоты,
[35:19.760 --> 35:21.760]  а так еще и в Древней Греции идет всякая
[35:21.760 --> 35:23.760]  решетовая ротосфена и так далее.
[35:23.760 --> 35:25.760]  Вот. Но
[35:25.760 --> 35:27.760]  прям так вот реально понадобилось
[35:27.760 --> 35:29.760]  именно в конце 70-х годов.
[35:29.760 --> 35:31.760]  Вот.
[35:31.760 --> 35:33.760]  Ну и есть
[35:33.760 --> 35:35.760]  такое высказывание,
[35:35.760 --> 35:37.760]  не помню, правда, чье,
[35:37.760 --> 35:39.760]  то если бы тогда в конце 70-х
[35:39.760 --> 35:41.760]  был бы известен
[35:41.760 --> 35:43.760]  полиномиальный алгоритм
[35:43.760 --> 35:45.760]  проверки простоты, детерминированный,
[35:45.760 --> 35:47.760]  то есть как раз
[35:47.760 --> 35:49.760]  АКС-алгоритм, то
[35:49.760 --> 35:51.760]  тогда область
[35:51.760 --> 35:53.760]  верензовых вычислений
[35:53.760 --> 35:55.760]  развивалась бы вовсе не так быстро.
[35:55.760 --> 35:57.760]  Потому что если можно
[35:57.760 --> 35:59.760]  прям точно узнать, то
[35:59.760 --> 36:01.760]  какая разница, что там можно
[36:01.760 --> 36:03.760]  посчитать вероятностью.
[36:07.760 --> 36:09.760]  Вот.
[36:11.760 --> 36:13.760]  Значит,
[36:13.760 --> 36:15.760]  ну тогда вот это не знали,
[36:15.760 --> 36:17.760]  уже нужно было
[36:17.760 --> 36:19.760]  длинный число проверять
[36:19.760 --> 36:21.760]  на простоту.
[36:21.760 --> 36:23.760]  Ну вот придумали
[36:23.760 --> 36:25.760]  несколько разных подходов
[36:25.760 --> 36:27.760]  как посчитать
[36:27.760 --> 36:29.760]  вероятность.
[36:29.760 --> 36:31.760]  Вот. Ну, самый простой,
[36:33.760 --> 36:35.760]  но не совсем корректный
[36:35.760 --> 36:37.760]  на самом деле, значит,
[36:37.760 --> 36:39.760]  это тест фирма.
[36:39.760 --> 36:41.760]  Значит, есть такая
[36:41.760 --> 36:43.760]  малая теория на фирмах,
[36:43.760 --> 36:45.760]  которая говорит,
[36:47.760 --> 36:49.760]  значит,
[36:49.760 --> 36:51.760]  малая теория на фирмах
[36:53.760 --> 36:55.760]  говорит, что
[36:55.760 --> 36:57.760]  если P простое,
[36:57.760 --> 36:59.760]  вот,
[36:59.760 --> 37:01.760]  а,
[37:01.760 --> 37:03.760]  а и P, да,
[37:03.760 --> 37:05.760]  именно просто,
[37:05.760 --> 37:07.760]  да, то есть, ну попросту говоря,
[37:07.760 --> 37:09.760]  они делятся на P.
[37:09.760 --> 37:11.760]  А то тогда, а в степени P-1
[37:11.760 --> 37:13.760]  значит,
[37:13.760 --> 37:15.760]  сравнимо с единицей
[37:15.760 --> 37:17.760]  у моделю P.
[37:19.760 --> 37:21.760]  Вот.
[37:21.760 --> 37:23.760]  И идея заключается в том,
[37:23.760 --> 37:25.760]  давайте брать случайно а и просто
[37:25.760 --> 37:27.760]  проверять.
[37:27.760 --> 37:29.760]  Значит, тест
[37:29.760 --> 37:31.760]  соответственно выбирает
[37:33.760 --> 37:35.760]  случайно а
[37:37.760 --> 37:39.760]  ну и проверяет
[37:43.760 --> 37:45.760]  Так, ну дайте себе, чтобы была другая
[37:45.760 --> 37:47.760]  буква,
[37:47.760 --> 37:49.760]  что а в степени x-1 сравнимо с единицей у моделю x.
[37:51.760 --> 37:53.760]  Вот. Тогда, если оказалось,
[37:53.760 --> 37:55.760]  что неверно,
[37:55.760 --> 37:57.760]  и при этом а на x не делится,
[37:57.760 --> 37:59.760]  то это означает,
[37:59.760 --> 38:01.760]  что точно не простое.
[38:03.760 --> 38:05.760]  То есть, если неверно,
[38:09.760 --> 38:11.760]  то точно,
[38:17.760 --> 38:19.760]  точно не простое.
[38:19.760 --> 38:21.760]  Вот. Однако есть проблема.
[38:23.760 --> 38:25.760]  Знаете ли вы, в чем стоит эта проблема?
[38:25.760 --> 38:27.760]  Да, что есть числа кармаекла.
[38:29.760 --> 38:31.760]  Значит, существует
[38:35.760 --> 38:37.760]  числа кармаекла,
[38:41.760 --> 38:43.760]  значит, для которых
[38:47.760 --> 38:49.760]  тоже
[38:49.760 --> 38:53.760]  всегда в степени x-1
[38:53.760 --> 38:55.760]  сравнимо с единицей
[38:55.760 --> 38:57.760]  по моделю x.
[38:59.760 --> 39:01.760]  Ну, там вот есть теорема Эйлера
[39:01.760 --> 39:03.760]  про то, что а в степени
[39:03.760 --> 39:05.760]  функции Эйлера от x-а
[39:05.760 --> 39:07.760]  сравнимо с единицей.
[39:07.760 --> 39:09.760]  А вот числа кармаекла, это как раз те, для которых
[39:09.760 --> 39:11.760]  вот x-1 делятся на афии от x.
[39:11.760 --> 39:13.760]  Вот. Ну и тогда получается,
[39:13.760 --> 39:15.760]  что мы единицу в какую-то степень возводим, да,
[39:15.760 --> 39:17.760]  остается единицей. Вот.
[39:17.760 --> 39:19.760]  Числа кармаекла не очень много,
[39:19.760 --> 39:21.760]  они довольно редко распределены.
[39:23.760 --> 39:25.760]  Ну и, соответственно,
[39:25.760 --> 39:27.760]  вот. Но, значит, проблема
[39:27.760 --> 39:29.760]  вот в чем, да, что можно было бы сказать,
[39:29.760 --> 39:31.760]  что, ну, ничего страшного, да, у нас
[39:31.760 --> 39:33.760]  просто иногда ошибки возникают,
[39:33.760 --> 39:35.760]  числа кармаекла немного,
[39:35.760 --> 39:37.760]  вот. Но проблема в том, что это ошибки,
[39:37.760 --> 39:39.760]  в смысле, что для некоторых x,
[39:39.760 --> 39:41.760]  независимо от выбора случайного, у нас
[39:41.760 --> 39:43.760]  случается неправильный ответ.
[39:43.760 --> 39:45.760]  Вот. А мы хотеть другую ошибку,
[39:45.760 --> 39:47.760]  что там всегда ответ получается,
[39:47.760 --> 39:49.760]  скорее всего, правильный,
[39:49.760 --> 39:51.760]  но с некоторыми,
[39:51.760 --> 39:53.760]  ну, каким бы ни было x, да,
[39:53.760 --> 39:55.760]  ответ всегда будет правильный,
[39:55.760 --> 39:57.760]  но с небольшой вероятностью неправильный.
[39:59.760 --> 40:01.760]  Вот.
[40:01.760 --> 40:03.760]  Но вот если нас это устроит,
[40:03.760 --> 40:05.760]  да, то есть мы как будем тестировать
[40:05.760 --> 40:07.760]  простоту или принадлежность
[40:07.760 --> 40:09.760]  к числам кармаекла,
[40:09.760 --> 40:11.760]  да, то это будет хороший тест, да,
[40:11.760 --> 40:13.760]  потому что можно сказать,
[40:13.760 --> 40:15.760]  что если, если вот
[40:15.760 --> 40:17.760]  этот раз не всегда верно,
[40:17.760 --> 40:19.760]  то верно не больше, чем в половине случаев.
[40:19.760 --> 40:21.760]  Вот. Ну, и тогда,
[40:21.760 --> 40:23.760]  соответственно, можно,
[40:23.760 --> 40:25.760]  например, не одно случайное a взять,
[40:25.760 --> 40:27.760]  скажем, десять случайных a взять,
[40:27.760 --> 40:29.760]  и тогда, если это всегда
[40:29.760 --> 40:31.760]  верно, то все a пройдут.
[40:31.760 --> 40:33.760]  А если это не всегда верно,
[40:33.760 --> 40:35.760]  тогда, каждая пройдетaca tapi одна вторая,
[40:35.760 --> 40:37.760]  а все a вместе
[40:37.760 --> 40:39.760]  пройдутся по 324,
[40:39.760 --> 40:41.760]  ну, и вот это можно считать маленькой ошибкой
[40:41.760 --> 40:45.760]  и считать, что это вы, скорее всего, правы.
[40:45.760 --> 40:52.760]  Вот. Ну, то есть как бы вот так на коленке такой тест тоже пройдёт.
[40:52.760 --> 40:58.760]  Вот. Но надо понимать природу ошибки, да, что она хоть и редкая,
[40:58.760 --> 41:02.760]  потому что число кармайкла мало или меньше, чем простых.
[41:02.760 --> 41:07.760]  Вот. Но тем не менее уж если число кармайкла попался, там всегда будет ошибка.
[41:07.760 --> 41:13.760]  Вот.
[41:13.760 --> 41:16.760]  Так. Ну ладно, соответственно.
[41:16.760 --> 41:22.760]  Что ж тогда делать?
[41:22.760 --> 41:30.760]  Ну, тест Миллера Рабина на самом деле, так сказать, исправляет ошибку.
[41:37.760 --> 41:48.760]  Значит, тест Миллера Рабина проверяет следующее, да, что, во-первых,
[41:48.760 --> 41:58.760]  а в степени х-1 сравним с единиц по моделю х.
[41:58.760 --> 42:05.760]  Вот. Дальше, но если х было чётным, то оно почти никогда не простое, да,
[42:05.760 --> 42:11.760]  то задача триреальная получается. Вот. А если х нечётная, то тогда
[42:11.760 --> 42:23.760]  должно быть ещё и а в степени х-1 пополам, да, значит, сравнимо с плюс-минус единицей.
[42:23.760 --> 42:30.760]  Да, значит, потому что вот по простому модулю, да, всегда корень двумя способами извлекается,
[42:30.760 --> 42:34.760]  а вот по непростому, может быть, и больше в том способу, да, то есть вот,
[42:34.760 --> 42:40.760]  ну, всегда а в степени х-1 пополам в квадрате равно вот этому, да, то есть равно единице.
[42:40.760 --> 42:44.760]  Вот. По простому модулю будет всего два варианта, плюс-1 и минус-1.
[42:44.760 --> 42:49.760]  По непростому будет какие-нибудь ещё, да, например, модулю 8 и 1 и 3 и 5 и 7 в квадрате
[42:49.760 --> 42:59.760]  даёт остаток 1. Вот. Значит, тоже по модулю х. Вот. Ну, а дальше, если тут плюс-1,
[42:59.760 --> 43:11.760]  да, значит, если тут 1, то тогда, соответственно, а х ещё и, ну, х-1 ещё и на 4 делится, да,
[43:12.760 --> 43:19.760]  да, тогда будет а в степени х-1 на 4 тоже должно быть сравнивать с плюс-минус единицей.
[43:19.760 --> 43:29.760]  Вот. Ну и так далее, так далее, пока не поделена максимальная степень Лойкина,
[43:29.760 --> 43:41.760]  которая надеется, да, значит, и так далее, пока х-1 делить на 2 в степени х не станет
[43:41.760 --> 43:50.760]  ничьётным, ну, или пока в какой-то момент не будет минус единицей, значит, или
[43:50.760 --> 44:00.760]  пока не появится минус единицей. Да, значит, тогда получается, что вот для простого
[44:00.760 --> 44:08.760]  числа ряд из таких остатков будет сначала единицей, а потом возникнет минус единицей,
[44:08.760 --> 44:20.760]  ну, либо до самого конца будет единицей. То есть получается, что для простого числа
[44:20.760 --> 44:32.760]  будет, соответственно, 1, 1, 1 и так далее, потом минус 1, ну, либо уже до конца единицей.
[44:32.760 --> 44:40.760]  Вот. Так вот теорема, которую доказали Миллер и Рабин, мы не будем доказать,
[44:40.760 --> 44:48.760]  она довольно такая сложная теоретика числовая, но, в общем, теорема такая,
[44:48.760 --> 45:14.760]  то если их непростое, то ряд такого вот, такого вот, такого вида будет не более
[45:14.760 --> 45:30.760]  чем для четверти, для четверти иксов, в том числе и для чисел Кармайкла, там всё равно
[45:30.760 --> 45:36.760]  всё будет вот так. Вот. Ну, это получается, что да, и понятно, что это всё можно
[45:36.760 --> 45:41.760]  проверять за полинамиальное время, в том числе и за полинамиальное, конечно же,
[45:41.760 --> 45:50.760]  от еклобитов, да, то есть за логеремическое формовое яйца. Вот. Тут, ну, понятное дело,
[45:50.760 --> 45:54.760]  что мы можем определить максимальную степень двойки, на которой х-1 делится,
[45:54.760 --> 46:02.760]  посчитать все вот эти вот степени, ну, и там ещё нужно алкерить быстрое возведение степени.
[46:02.760 --> 46:10.760]  Да, это вы знаете. Вот. Ну, и тогда получается, что если х-ростое, то проверка пройдётся всегда.
[46:10.760 --> 46:21.760]  Вот. Если х-непростое, то всё равно не больше 1 четверти. Вот. Ну, вот. Так этот тест работает.
[46:21.760 --> 46:31.760]  Вот. Значит, есть разные тесты. Да, значит, есть тест Соловея-Штрассона, который
[46:31.760 --> 46:37.760]  на другом принципе работает, да, он связан с квадратичными вычетами и не вычетами.
[46:37.760 --> 46:45.760]  Вот. Есть ещё более сложные тесты. Например, есть такой тест Эйдл Мана-Хуана.
[46:45.760 --> 46:51.760]  Для нас сейчас важно следующее. Смотрите. Какова природа ошибки? Вот здесь вот.
[46:51.760 --> 47:05.760]  Давайте я прям, наверное, запишу, что если х-ростое, то тогда и тест говорит,
[47:05.760 --> 47:15.760]  то простое. Вот. А если х-составное, то тогда тест, скорее всего, говорит,
[47:15.760 --> 47:23.760]  так, давайте я прям тут допишу, тест точно говорит, что простое. А если х-составное,
[47:23.760 --> 47:33.760]  то тест, скорее всего, говорит, его говорит, что составное, но может сказать,
[47:33.760 --> 47:43.760]  и что простое. Вот. То есть тут ошибка с одной стороны. Ещё важно понимать,
[47:43.760 --> 47:47.760]  следующий, да, это вот, что тест говорит, а ещё можно с другой стороны посмотреть,
[47:47.760 --> 47:53.760]  как интерпретировать результат теста. То есть тогда, если тест говорит,
[47:53.760 --> 47:59.760]  что число составное, тогда оно точно составное. Наоборот получается. Если число
[47:59.760 --> 48:05.760]  простое, то тест точно говорит, что оно простое, а если он говорит, что это
[48:05.760 --> 48:11.760]  составное, значит оно точно составное. А если тест сказал, что простое,
[48:11.760 --> 48:17.760]  тогда может быть простое, может быть составное. Вот. Там ещё нужно пересчитывать
[48:17.760 --> 48:23.760]  вероятности учётом формы bias, да, поскольку простых чисел вообще нет.
[48:23.760 --> 48:29.760]  Ну скажем, если рассмотреть там от одного до там миллиона, да, там один
[48:29.760 --> 48:37.760]  деятель на логариф men, натуральный, да, примерно такая частота. Ну миллион
[48:37.760 --> 48:45.760]  это у нас, ну, в общем-то у нас, в общем-то у нас, в общем-то у нас, в общем-то у нас
[48:45.760 --> 48:53.760]  натуральный, да, примерно такая частота. Ну миллион это у нас E в какой степени,
[48:53.760 --> 48:59.760]  да, это два в двадцатый, да, E в какой-то меньшей, да, там, ну не знаю, в пятнадцатый,
[48:59.760 --> 49:05.760]  например. Вот. То есть, грубо говоря, там одна пятнадцатая числа от одного до
[49:05.760 --> 49:11.760]  миллиона будет простой. Ну так, пример, да, в общем, можно посмотреть, сколько
[49:11.760 --> 49:15.760]  именно, и тогда, смотрите, если мы берём случайное число и запускаем вот прям вот
[49:15.760 --> 49:21.760]  этот вот тест один раз, и тест кажется, что оно простое. Тогда как будет вероятнее,
[49:21.760 --> 49:26.760]  что оно простое или оно составное? На самом деле, всё равно будет, по вкассе
[49:26.760 --> 49:32.760]  может быть вероятность, что оно, да, считается, что одна семнадцатая, да, то есть
[49:32.760 --> 49:38.760]  на одно простое приходится шестнадцать составных. Тогда, как бы, вот этот вот
[49:38.760 --> 49:43.760]  тест, да, он, скажем, для четверти, да, пусть ровно для четверти работает.
[49:43.760 --> 49:49.760]  Вот. А из этих шестнадцати он двенадцать отбросил, а четыре оставил. И теперь у нас
[49:49.760 --> 49:57.760]  на те случаи, когда тест сказал да, у нас получается одно простое и четыре составных.
[49:57.760 --> 50:02.760]  Вот. Но это не беда, потому что можно ещё раз тест запустить заново, тогда из этих
[50:02.760 --> 50:07.760]  четырёх составных уже только одно останется, также будет пятьдесят на пятьдесят.
[50:07.760 --> 50:11.760]  Вот. Но если ещё пару раз запустить, и он все раз и сказал, что простое, тогда уж,
[50:11.760 --> 50:15.760]  наверное, простое. Да, это вот процесс, который называется амплификацией, да,
[50:15.760 --> 50:23.760]  значит, когда уменьшается ошибка. Если тест провести несколько раз, да, то тогда
[50:23.760 --> 50:27.760]  это будет более надежный. Так.
[50:53.760 --> 51:16.760]  Так вот. У теста Эйдл Манахуана устроена ошибка ровно наоборот.
[51:16.760 --> 51:26.760]  Значит, сам тест я не буду рассказывать, да, он довольно сложный.
[51:26.760 --> 51:39.760]  Тест Эйдл Манахуана устроен ровно наоборот. То есть, если число составное,
[51:39.760 --> 51:44.760]  то тогда тест точно говорит, что оно составное, а если число простое, то,
[51:44.760 --> 51:48.760]  соответственно, он большой вероятностью говорит, что оно простое.
[51:48.760 --> 51:53.760]  Да, и там случается ошибка с другой стороны.
[51:53.760 --> 52:00.760]  Ну и, соответственно, такие два теста можно, на самом деле, использовать совместно.
[52:00.760 --> 52:04.760]  Да, то есть, можно один применять, потом другой применять.
[52:04.760 --> 52:11.760]  И рано или поздно, да, рано или поздно один из тестов даст такой результат,
[52:11.760 --> 52:14.760]  который можно говорить безговорочно.
[52:14.760 --> 52:21.760]  Да, то есть, либо первый тест скажет, что число составное, тогда оно точно составное,
[52:21.760 --> 52:24.760]  либо второй тест скажет, что оно простое, тогда оно точно простое.
[52:24.760 --> 52:32.760]  Вот. И вот это, на самом деле, более явный пример алгоритма Лас-Вегаса,
[52:32.760 --> 52:39.760]  который я тут как раз стер.
[52:39.760 --> 52:43.760]  Вот, хорошо.
[52:43.760 --> 52:51.760]  Так, дайте еще один пример задачи.
[52:51.760 --> 52:55.760]  Значит, она, на самом деле, больше важна для теории,
[52:55.760 --> 53:00.760]  но, тем не менее, она довольно поучительна сама по себе.
[53:00.760 --> 53:05.760]  Значит, чем она важна для теории?
[53:05.760 --> 53:09.760]  Потому что, в отличие от редкой простоты, вот для той задачи, которую я сейчас опишу,
[53:09.760 --> 53:14.760]  неизвестна никакого детерминированного алгоритма полиномиального,
[53:14.760 --> 53:17.760]  но известна вероятностью.
[53:17.760 --> 53:23.760]  И вообще, в целом, тут такой же ответный вопрос, как и про PNP.
[53:23.760 --> 53:28.760]  Значит верно ли, что рандомизированный алгоритм мог сделать больше
[53:28.760 --> 53:31.760]  чем детерминированный.
[53:32.760 --> 53:35.760]  Появ Ist, что если вероятность есть, то ее можно не использовать.
[53:35.760 --> 53:40.760]  И все обычные будут так же и тривиально рандомизированными.
[53:40.760 --> 53:44.760]  Поэтому все задачи, которые решаются обычными, решаются рандомизированными.
[53:44.760 --> 53:48.760]  Но вопрос, есть ли такие задачи, которые решаются рандомизированными,
[53:48.760 --> 53:50.760]  ... не решаются обычными.
[53:50.760 --> 53:56.760]  На первый взгляд, ситуация точно такая же, как и с NP, да, есть ряд задач,
[53:56.760 --> 54:01.760]  ну, не такой большой, как для NP, но, тем не менее, есть ряд задач, которые
[54:01.760 --> 54:09.760]  не решаются известными детерминированными алгоритмами, но решаются известными рандомизированными.
[54:09.760 --> 54:15.760]  Вот. И никто там не умеет для них ничего придумывать.
[54:15.760 --> 54:21.760]  Вот. И вот вопрос, должны ли мы на этом основании полагать, что, действительно,
[54:21.760 --> 54:24.760]  рандомизированные могут больше?
[54:24.760 --> 54:30.760]  Ну, вот, оказывается, если поглубже в теорию погрузиться, то, на самом деле,
[54:30.760 --> 54:36.760]  скорее всего, всё-таки, рандомизированные ничего не могут дополнительно.
[54:36.760 --> 54:42.760]  Это просто учёные пока не придумали алгоритмы для вот тех задач.
[54:42.760 --> 54:44.760]  В том числе, для той, которую я сейчас расскажу.
[54:44.760 --> 54:50.760]  Вот. Там довольно глубокая есть теория, в том числе, зависимость между двумя этими фактами,
[54:50.760 --> 54:54.760]  про PNP и силу случайности.
[54:54.760 --> 54:59.760]  Даже там была статья, где это описывалась, очень важная статья,
[54:59.760 --> 55:04.760]  с таким сброским названием Hardness versus Randomness.
[55:04.760 --> 55:07.760]  То есть, оказывается, что не может быть и того, и другого.
[55:07.760 --> 55:14.760]  Либо есть Hardness, то есть, есть сложные задачи, которые решаются только перебором.
[55:14.760 --> 55:24.760]  И тогда, в общем, на самом деле, там Hardness – это не только то, что PNP, несколько более сильное утверждение.
[55:24.760 --> 55:27.760]  В общем, грубо говоря, что если есть достаточно сложные задачи,
[55:27.760 --> 55:32.760]  то тогда, на самом деле, его можно дерандомизировать.
[55:32.760 --> 55:37.760]  То есть, превратить вероятность алгоритма в детерминированное.
[55:37.760 --> 55:49.760]  Вот. Ну, либо есть Randomness, то есть, случайность действительно добавляет вычислительную силу.
[55:49.760 --> 55:57.760]  Ну, вот. Ну, не знаю, может быть, мы немножко подробнее успеем обсудить, но это реально сложная вещь.
[55:57.760 --> 56:02.760]  Я это бывает на спецкурсах читаю.
[56:02.760 --> 56:07.760]  Вот. Ну, значит, что это за задача, которую я несколько раз анонсировал?
[56:07.760 --> 56:22.760]  Значит, это задача о равенстве многочленов.
[56:22.760 --> 56:26.760]  Вот. Ну, на первый взгляд, она какая-то совершенно очевидная.
[56:26.760 --> 56:35.760]  Что вот даны многочлены, значит, даны многочлены P и Q.
[56:35.760 --> 56:41.760]  Вот. И вопрос – это один многочлен и разное.
[56:41.760 --> 56:51.760]  Значит, они одинаковые или нет?
[56:51.760 --> 56:54.760]  Вот. Ну, на первый взгляд, кажется, что вообще в чем вопрос?
[56:54.760 --> 56:59.760]  Просто раним коэффициент, они либо одинаковые, либо нет.
[56:59.760 --> 57:02.760]  Но это верно только при канонической записи.
[57:02.760 --> 57:10.760]  Каноническая записи означает, что мы предчисляем многочлены как сумму одночленов.
[57:10.760 --> 57:14.760]  Конечно, если многочлены – это сумма одночленов, то даже если там в разном порядке их записывать,
[57:14.760 --> 57:19.760]  да, и одночлены, там есть от нескольких переменных, то тоже можно по-разному писать.
[57:19.760 --> 57:22.760]  Тогда мы это, конечно, сможем проверить. Никой задачи нет.
[57:22.760 --> 57:30.760]  Но может многочлен быть задан не как сумму одночленов, а как какое-то арифитическое выражение.
[57:30.760 --> 57:38.760]  Арифитическое выражение, где там перемножаются какие-то многочлены, складываются, квадраты возводятся.
[57:38.760 --> 57:44.760]  Вот. И тогда, на первый взгляд, тоже нет проблем.
[57:44.760 --> 57:48.760]  Можно просто раскрыть все скобки. Да, и после этого их все равно.
[57:48.760 --> 57:53.760]  Но на самом деле тут уже есть проблема, потому что если вы раскрываете все скобки,
[57:53.760 --> 57:57.760]  то у вас слагаемых может быть экспоненциально много.
[57:57.760 --> 58:02.760]  Если у вас, например, произведение n скобок, и в каждой скобке 2 слагаемых,
[58:02.760 --> 58:07.760]  то тогда может получиться экспоненциально много слагаемых в результате.
[58:07.760 --> 58:11.760]  И поэтому так просто вы их уже не сравните.
[58:11.760 --> 58:17.760]  Ну а в общем случае, еще на шаг дальше,
[58:20.760 --> 58:23.760]  дело продвигается,
[58:23.760 --> 58:31.760]  а именно говорит, что даже может быть не выражение, а тоже называются арифитические схемы.
[58:31.760 --> 58:43.760]  Да, значит, тут важно, что вот эти многочлены заданы арифитическими схемами.
[58:45.760 --> 58:49.760]  Но это аналог логических схем, которые мы изучали,
[58:49.760 --> 58:54.760]  только там вместо конъюнкции, дезюнкции, отрицания будет сложение и умножение.
[58:54.760 --> 59:02.760]  То есть это аналог булевых схем,
[59:02.760 --> 59:12.760]  но со сложением и умножением.
[59:12.760 --> 59:15.760]  То есть получается, что у нас есть какие-то переменные.
[59:15.760 --> 59:18.760]  Это, может быть, отращено от нескольких переменных.
[59:18.760 --> 59:21.760]  Мы эти переменные как-то там складываем, перемножаем,
[59:21.760 --> 59:24.760]  результаты тоже можем складывать, перемножать
[59:24.760 --> 59:27.760]  и, соответственно, переиспользовать.
[59:27.760 --> 59:28.760]  То есть одно и то же.
[59:28.760 --> 59:31.760]  Все схемы, в общем, отличаются схемой просто от формулы.
[59:31.760 --> 59:35.760]  Тем, что одно и то же сложные выражения, которые в разные части формулы входят,
[59:35.760 --> 59:39.760]  мы можем сократить и один раз только использовать.
[59:39.760 --> 59:42.760]  И это еще дополнительно уменьшает размер.
[59:42.760 --> 59:48.760]  Соответственно, эти схемы должны быть полинарного размера.
[59:48.760 --> 59:52.760]  Что такое размер схемы? Мы уже изучали?
[59:52.760 --> 59:57.760]  Это тоже вопрос, вот чего?
[59:57.760 --> 01:00:04.760]  Ну, можно сказать так, что как раз размер схемы мы будем считать параметром,
[01:00:04.760 --> 01:00:09.760]  от которого будет пленом браться, который уже во времени работает.
[01:00:09.760 --> 01:00:14.760]  Не, значит, нам, смотрите, что нам нужно?
[01:00:14.760 --> 01:00:16.760]  Есть два подхода.
[01:00:16.760 --> 01:00:19.760]  Один подход, что есть размер входа.
[01:00:19.760 --> 01:00:22.760]  Именно от него все должно быть поленоимеально.
[01:00:22.760 --> 01:00:27.600]  Поленоим arriving с
[01:00:27.600 --> 01:00:30.560]  общий параметр, и от него измерiają все палиномы,
[01:00:30.560 --> 01:00:33.140]  то есть, и размер схемы должен быть палиномиальным от этого
[01:00:33.140 --> 01:00:35.200]  параметра, и время работы должно быть палиномиальным
[01:00:35.200 --> 01:00:38.220]  от этого параметра, и все, что там еще есть, будет
[01:00:38.220 --> 01:00:41.240]  палиномиальным от этого параметра.
[01:00:41.240 --> 01:00:43.140]  Ну, более-менее, одно и то же, да,
[01:00:43.140 --> 01:00:47.200]  потому что полином от полинома, это полином,
[01:00:47.200 --> 01:00:50.200]  вот. Но, бывает так, как удобно,
[01:00:54.000 --> 01:00:57.120]  ну, например, можно считать, что у вас, скажем,
[01:00:57.120 --> 01:01:01.120]  скажем, схема одного размера, n — это размер одной схемы, а не двух.
[01:01:01.120 --> 01:01:05.120]  Или еще там что-нибудь.
[01:01:05.120 --> 01:01:09.120]  Или, например, можно считать, что n — это число элементов в схеме,
[01:01:09.120 --> 01:01:13.120]  а не полной длины записи еще со всеми связями.
[01:01:13.120 --> 01:01:21.120]  В общем, вот такая задача.
[01:01:21.120 --> 01:01:25.120]  Ну что, понятна ли формулировка?
[01:01:25.120 --> 01:01:33.120]  Ну теперь я хочу рассказать, как ее решать вероятно.
[01:01:33.120 --> 01:01:39.120]  Так, идея решения.
[01:01:39.120 --> 01:01:51.120]  Идея решения, что если
[01:01:51.120 --> 01:01:57.120]  п... так, вот я тут тоже три черты использую, но здесь это имеется
[01:01:57.120 --> 01:02:01.120]  тождественно равно.
[01:02:01.120 --> 01:02:05.120]  То это как бы один и тот же многащение. В том смысле, если мы раскроем все скобки
[01:02:05.120 --> 01:02:11.120]  и упорядочим каноническим образом, то будет один и тот же многащение для p и q.
[01:02:11.120 --> 01:02:17.120]  Значит, если p и q — это одно и то же, то, соответственно, для любого x
[01:02:17.120 --> 01:02:23.120]  p от x равно q от x.
[01:02:23.120 --> 01:02:27.120]  Это, на самом деле, не совсем одно и то же,
[01:02:27.120 --> 01:02:31.120]  потому что это зависит от того, над каким полем вы это вычисляете.
[01:02:31.120 --> 01:02:35.120]  То есть, например, если у вас только 0 и единица, то x и x² — это разные
[01:02:35.120 --> 01:02:41.120]  многочлены, но, тем не менее, одна и та же функция.
[01:02:41.120 --> 01:02:45.120]  И, соответственно, вопрос, который здесь ставится, — это именно равны ли
[01:02:45.120 --> 01:02:49.120]  p и q как многочлены? То есть, там есть какие-то переменные,
[01:02:49.120 --> 01:02:53.120]  и если раскрыть все скобки, то будет ли одна и та же сумма
[01:02:53.120 --> 01:02:57.120]  значеных или не одна и та же?
[01:03:01.120 --> 01:03:07.120]  Изначально, не, изначально над натуральными числами.
[01:03:07.120 --> 01:03:11.120]  Не над полем, да. Изначально...
[01:03:11.120 --> 01:03:15.120]  Нет, можно сказать, что там вообще никакого поля нету, а у нас есть просто переменные, есть
[01:03:15.120 --> 01:03:19.120]  сложение и умножение. Но если мы перемену саму собой складываем
[01:03:19.120 --> 01:03:25.120]  много раз, то у нас автоматически получается натуральный коэффициент.
[01:03:25.120 --> 01:03:29.120]  И, соответственно, больше никак коэффициент не получится.
[01:03:29.120 --> 01:03:33.120]  Если у нас нет константа, есть только сложение и умножение,
[01:03:33.120 --> 01:03:37.120]  мы начинаем с переменных, можем их складывать, будут...
[01:03:37.120 --> 01:03:43.120]  но не вычитать и не делить, тем более, мы их можем только складывать и умножать.
[01:03:43.120 --> 01:03:47.120]  От этого у нас будет получаться натуральный коэффициент.
[01:03:49.120 --> 01:03:53.120]  А у нас только сложение и умножение.
[01:03:53.120 --> 01:03:57.120]  Если у нас есть сложение и умножение, то вычитать не получится.
[01:03:59.120 --> 01:04:05.120]  Не, можно рассмотреть другой базер, минус тоже добавить,
[01:04:05.120 --> 01:04:11.120]  будут как бы другие схемы, другая постановка, и решаться будет прямо так же все равно.
[01:04:11.120 --> 01:04:15.120]  Действительно, значит, если p и q одно и то же, то для любого x, p от x равно q от x.
[01:04:15.120 --> 01:04:27.120]  А если p и q это не одно и то же, то для малого,
[01:04:27.120 --> 01:04:35.120]  для малого числа x будет верно, что p от x равно q от x.
[01:04:35.120 --> 01:04:43.120]  Значит, почему? Потому что тогда разность, да, значит, разность p минус q.
[01:04:43.120 --> 01:04:53.120]  Значит, это нетривиальный, то есть не нулевой, не тождественно нулевой многочлен.
[01:04:53.120 --> 01:05:01.120]  И тогда у этой разности не слишком много корней.
[01:05:01.120 --> 01:05:11.120]  Соответственно, у p минус q не может быть слишком много корней.
[01:05:11.120 --> 01:05:19.120]  Вот. Ну, я сейчас покажу, что это значит.
[01:05:19.120 --> 01:05:29.120]  Не может быть слишком много корней.
[01:05:29.120 --> 01:05:37.120]  Ну, например, если там всего одна переменная, то тогда вы, наверное, хорошо понимаете, да,
[01:05:37.120 --> 01:05:41.120]  что многочлены степени D не больше, чем D корней.
[01:05:41.120 --> 01:05:55.120]  Значит, если многочлены вот одной переменной, то тогда, соответственно,
[01:05:55.120 --> 01:06:09.120]  многочлена степени D будет не больше, чем D корней.
[01:06:09.120 --> 01:06:19.120]  Вот. Ну, это какое-то очень простое утверждение, да, но, правда, опять же вопрос над каким?
[01:06:19.120 --> 01:06:25.120]  Ну, над полем. Для поля это верно, да, не важно над каким, над действительными,
[01:06:25.120 --> 01:06:39.120]  над комплексными, над конечным полем, над любым полем.
[01:06:39.120 --> 01:06:49.120]  Вот. А если это не поле, а кольцо, тогда, конечно, может быть и больше, чем D корней.
[01:06:49.120 --> 01:06:59.120]  Вот. Ну, если это кольцо целых чисел или натуральных, то все равно не больше D, да,
[01:06:59.120 --> 01:07:05.120]  потому что над, даже над комплексными будет не больше, чем D корней.
[01:07:05.120 --> 01:07:11.120]  А если мы от комплексных оставили только вообще целые, да, действительные целые,
[01:07:11.120 --> 01:07:17.120]  то тогда, соответственно, их больше не может стать.
[01:07:17.120 --> 01:07:25.120]  Вот. Ну, и, соответственно, идея такая, да, значит, если от многих переменных,
[01:07:25.120 --> 01:07:31.120]  то там несколько сложнее, значит, от нескольких переменных.
[01:07:31.120 --> 01:07:43.120]  Давайте я только ключевые слова скажу. Да, значит, тут Лемма Шварцзиппеля.
[01:07:43.120 --> 01:07:51.120]  Лемма Шварцзиппеля. Да, у вас ее не было?
[01:07:51.120 --> 01:07:59.120]  А, ну, уже здесь на семинарах. Да. Ну, в общем, либо еще будет, либо там.
[01:07:59.120 --> 01:08:05.120]  Поищите где-нибудь. В общем, суть в том, что, суть ее все равно, что не может быть слишком много корней,
[01:08:05.120 --> 01:08:13.120]  но, опять же, да, на самом деле вот тут мы уже переходим, да, значит, переходим к конечному полю,
[01:08:13.120 --> 01:08:19.120]  потому что вообще-то, ну ладно, пусть у нас даже одна переменная, да,
[01:08:19.120 --> 01:08:29.120]  Ради чего мы все вот это изучаем? Ради метода проверки, так что взять случайный х и проверить, равны или нет.
[01:08:29.120 --> 01:08:45.120]  Да, то есть тест получается, тест получается в том, чтобы проверить, что P от х равно Q от х для случайного х.
[01:08:45.120 --> 01:09:01.120]  Соответственно, если не равно, то тогда многочлены точно разные. Вот. Если равно, то, скорее всего,
[01:09:01.120 --> 01:09:11.120]  скорее всего одинаково. Вот. Но есть, с таким применением подходом есть некоторая проблема.
[01:09:11.120 --> 01:09:19.120]  Во-первых, если у нас в цикле любое натуральное число, то нельзя взять случайно натуральное число.
[01:09:19.120 --> 01:09:27.120]  Да, это как, это понятно, наверное, да, что, ну я бы, если мы берем равновероятно, да, то вероятности должны быть сюда одинаковые,
[01:09:27.120 --> 01:09:35.120]  но если она равна нулю, то тогда и вообще сумма равна нулю, а если она больше нуля, то сумма равна бесконечности, да,
[01:09:35.120 --> 01:09:41.120]  поэтому не может быть равноверного распределения на натуральных числах. Вот. Может быть только там какое-то.
[01:09:41.120 --> 01:09:52.120]  Вот. Это первая проблема. А еще есть вторая проблема, немножко более тонкая, в том, что сами значения P от х и Q от х могут быть слишком большими.
[01:09:52.120 --> 01:09:58.120]  Потому что, смотрите, у нас может быть, например, итерированное возведение в квадрат.
[01:09:58.120 --> 01:10:05.120]  Что мы берем там, скажем, двойку, ее возводим в квадрат, результат тоже возводим в квадрат, и так n раз.
[01:10:05.120 --> 01:10:12.120]  И тогда у нас получается дважды экспоненциальное число, которое занимает экспоненциальное число bit.
[01:10:12.120 --> 01:10:17.120]  Вот. Соответственно, просто записать результат тоже не получится.
[01:10:17.120 --> 01:10:26.120]  Вот. Ну вот, и чтобы от этих обеих проблем уйти, да еще и получить лему Шварцзиппеля для случаев нескольких переменных,
[01:10:26.120 --> 01:10:32.120]  от натуральных чисел переходят к остаткам по простому модулю.
[01:10:32.120 --> 01:10:47.120]  Вот. Соответственно, так, в общем, все это нужно, значит, нужно по модулю P.
[01:10:47.120 --> 01:10:52.120]  Для какого-то простого P.
[01:10:52.120 --> 01:11:01.120]  Ну и тогда там можно доказать, что можно взять как раз простое число, не слишком большое,
[01:11:01.120 --> 01:11:06.120]  чтобы можно было работать с остатками по этому модулю.
[01:11:06.120 --> 01:11:12.120]  Но не слишком маленькое, чтобы, тем не менее, слишком много корней не появилось.
[01:11:12.120 --> 01:11:16.120]  То есть вот это простое число должно быть сильно больше, чем степень.
[01:11:16.120 --> 01:11:22.120]  Но при этом экспоненциальное от m.
[01:11:22.120 --> 01:11:26.120]  Но, в общем, это можно все сделать.
[01:11:26.120 --> 01:11:33.120]  Ну, от размера схемы.
[01:11:33.120 --> 01:11:38.120]  Не, смотрите, само число экспоненциальное, а длина его записи полиномиальная.
[01:11:38.120 --> 01:11:46.120]  И поскольку сложение и умножение по модулю это эффективная операция, то это нам подойдет.
[01:11:46.120 --> 01:11:51.120]  То есть проблема была в том, что значение получалось дважды экспоненциальным.
[01:11:51.120 --> 01:11:56.120]  За счет интерированного задения в квадрат.
[01:11:56.120 --> 01:12:03.120]  Ну вот, соответственно, если все эти оговорки сделать, то все сработает.
[01:12:03.120 --> 01:12:06.120]  То есть вот это все равно останется.
[01:12:06.120 --> 01:12:09.120]  Если не равно, то точно не равны.
[01:12:09.120 --> 01:12:14.120]  То есть вот сюда, если мы теперь по модулю считаем, то вот это точно верно.
[01:12:14.120 --> 01:12:16.120]  А вот это вот останется.
[01:12:16.120 --> 01:12:24.120]  Если у нас малое число, будет малой долей в этом поле из поэлементов.
[01:12:24.120 --> 01:12:27.120]  Ну вот, значит, это будет работать.
[01:12:27.120 --> 01:12:31.120]  Ну еще есть вопрос, откуда простое число взять такого размера.
[01:12:31.120 --> 01:12:34.120]  У нас же есть тест простоты.
[01:12:34.120 --> 01:12:38.120]  А еще есть теория о том, что простых чисел довольно много.
[01:12:38.120 --> 01:12:42.120]  Можно просто брать случайно через каком-то интервале, проверять простоту
[01:12:42.120 --> 01:12:46.120]  и в какой-то момент наткнемся на подходящее.
[01:12:48.120 --> 01:12:52.120]  Так, ну вот. Вот такое вот рассуждение.
[01:12:54.120 --> 01:12:59.120]  Ну что ж, у нас в следующий раз будет подробный разговор про веренцевные классы.
[01:12:59.120 --> 01:13:03.120]  Так что всем спасибо за внимание.
