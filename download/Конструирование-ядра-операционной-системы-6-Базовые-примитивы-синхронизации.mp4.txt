[00:00.000 --> 00:10.240]  Тема нашей сегодняшней лекции это примитивы синхронизации и вообще параллельное
[00:10.240 --> 00:20.640]  программирование. С помощью параллельного программирования решается достаточно широкий
[00:20.640 --> 00:26.960]  класс задач, который без него было бы решить достаточно тяжело и в этом смысле без него мы
[00:26.960 --> 00:36.520]  сейчас уже обойтись практически не можем, особенно учитывая, что все современное развитие аппаратуры
[00:36.520 --> 00:44.000]  оно в первую очередь направлено на увеличение количества ядер. По производительности одного ядра
[00:44.000 --> 00:51.040]  мы пробуксовываем, так скажем. Нельзя сказать, что развития в этой области прям совсем нет,
[00:51.040 --> 01:02.600]  но оно совсем не такое быстрое, как некоторое время назад. Но с использованием параллельного
[01:02.600 --> 01:07.680]  программирования есть некоторые проблемы и, пожалуй, основная из них заключается в том,
[01:07.680 --> 01:14.680]  что люди плохо приспособлены для того, чтобы писать параллельные программы. Это отдаётся очень
[01:14.680 --> 01:26.640]  тяжело, а еще тяжелее дается писать параллельные программы без ошибок и, собственно, поэтому
[01:26.640 --> 01:36.280]  появляется много всяких смешных картинок и комиксов в интернете, но, несмотря на проблемы,
[01:36.280 --> 01:48.280]  все равно приходится использовать без этого никуда. Сегодня мы рассмотрим материал в таком
[01:48.280 --> 01:58.800]  порядке. Сначала поговорим про аппаратные возможности по синхронизации в самой платформе и то,
[01:58.800 --> 02:07.160]  как язык C абстрагирует эти возможности. Дальше мы поговорим про блокирующие примитивы
[02:07.160 --> 02:16.080]  синхронизации для создания параллельных программ. Ну, это, по сути, это локи. После этого поговорим
[02:16.080 --> 02:25.560]  немножко про не блокирующие примитивы, это про атомики. Ну, у нас еще в конце, где-то в районе
[02:25.560 --> 02:35.880]  12 лабы будет такая более обширная лекция про атомики и про не блокирующие алгоритмы. Сейчас мы
[02:35.880 --> 02:45.800]  так это пока чуть-чуть затронем. И в конце поговорим про самые такие основные классы ошибок,
[02:45.800 --> 02:54.360]  которые встречаются при использовании разных примитивов синхронизации. Ну и перейдем уже
[02:54.360 --> 03:05.720]  к сдаче лабораторок. Для начала я бы хотел задать вам вопрос. Как вы думаете, если у нас есть
[03:05.720 --> 03:10.800]  программа на языке C, которая считывает одновременно из нескольких потоков глобальную переменную,
[03:10.800 --> 03:29.120]  возможно ли такое и что будет происходить? Нет, ну а если да, если у нас только считывание.
[03:29.120 --> 03:44.800]  Хорошо, а если будем записывать? А что может произойти, если мы не будем этого делать?
[03:44.800 --> 03:58.880]  Ну да, на некоторых архитектурах может быть так, что вообще там записи
[03:58.880 --> 04:09.200]  перемешаются и половина числа от одного потока запишется, вторая половина от другого. Ну и
[04:09.200 --> 04:13.920]  соответственно раз записывать нельзя, то и параллельно считывание записывать тоже.
[04:13.920 --> 04:23.200]  С точки зрения ассемблера в принципе никто вам не запрещает это делать, ни то ни другое. Но
[04:23.200 --> 04:31.200]  с точки зрения именно стандарта языка C, да, чтение в стандарте определены как поток
[04:31.200 --> 04:38.680]  безопасный, операции записи не являются потоком безопасными, то есть если мы только читаем
[04:38.680 --> 04:45.160]  переменную, если она какая-то константная, то в принципе можно даже никаких дополнительных
[04:45.160 --> 04:50.080]  действий не предпринимать, хотя зачем вам считывать константную переменную, ее можно и так в коде
[04:50.080 --> 05:04.480]  записать. Ну бывает конечно иногда случаи. Ну допустим, допустим там, не знаю, когда-то в самом
[05:04.480 --> 05:14.080]  начале записали один раз переменную, а потом мы, после этого мы уверены как бы, что следующие
[05:14.080 --> 05:20.800]  потоки они уже запустились после того как сделана эта запись. Каким-то другим образом мы эту
[05:20.800 --> 05:27.400]  гарантию получаем. В таком случае, да, чтение будет thread-safe. Или, например, если это была
[05:27.400 --> 05:32.720]  проницилизирована переменная заранее, то есть до запуска программы операционная система,
[05:32.720 --> 05:39.840]  когда загружала файл, проницилизировала область и ее можно спокойно считывать после этого.
[05:39.840 --> 05:51.640]  Да, значит, операции записи не потоку безопасные и, соответственно, для того чтобы мы все-таки могли
[05:51.640 --> 06:02.240]  эти операции делать, в C существует специальный набор инструментов. Например, это атомарные
[06:02.240 --> 06:16.320]  операции из header-std-atomic.h. Про них мы поговорим чуть позже. С точки зрения логики, вообще говоря,
[06:16.320 --> 06:24.360]  если у нас есть какой-то разделяемый ресурс, например, участок переменная памяти, то не может
[06:24.360 --> 06:33.560]  быть такого момента, что мы одновременно к ней получаем доступ. Причем, если начтение и записи
[06:33.560 --> 06:43.560]  одновременно еще как-то там может быть, то если это, например, две записи, то одновременно их быть
[06:43.560 --> 06:50.400]  не может. Они в любом случае должны быть как-то упорядочены. Либо внутри на уровне железа,
[06:50.400 --> 07:00.160]  либо уже самим программистам. И здесь появляется такая абстракция, как критическая секция.
[07:00.160 --> 07:11.560]  Что это такое? Таким образом называют участок кода в программе, который предназначен для
[07:11.560 --> 07:19.200]  обращения к какому-то разделяемому ресурсу. И смысл здесь в том, что внутри этого участка кода в
[07:19.200 --> 07:28.400]  один момент времени может находиться только один поток. То есть один поток его выполняет,
[07:28.400 --> 07:39.360]  все остальные ждут. У примитива критической секции, как правило, есть две операции. Это,
[07:39.360 --> 07:47.720]  соответственно, захват секции и освобождение. То есть, как правило, как происходит работа. У нас
[07:47.720 --> 07:54.280]  есть несколько потоков, в котором нужно обращаться к одному ресурсу. Это, в принципе,
[07:54.280 --> 08:05.440]  может быть и область памяти, и какое-то устройство, и там, допустим, порт в процессоре. У нас в
[08:05.440 --> 08:13.880]  процессоре есть память, в интеловской архитектуре, по крайней мере, есть память, есть пространство
[08:13.880 --> 08:23.480]  портов. Вот когда, если кто-то делал четвертую лабораторку, то вы как раз пользовались портами.
[08:23.480 --> 08:36.720]  Соответственно, у нас есть несколько потоков. Какой-то первый поток, допустим, добрался до входа в
[08:36.720 --> 08:42.320]  критическую секцию, он сделал операцию по ее захвату, и после этого, когда остальные потоки
[08:42.480 --> 08:51.400]  делают операцию по захвату секции, они просто ждут, пока она освободится. Первый поток в это время
[08:51.400 --> 08:58.240]  выполняет какую-то свою работу, закончил и вызывает операцию освобождения критической секции. После этого,
[08:58.240 --> 09:07.920]  соответственно, будет выбран следующий поток, который ее выполняет.
[09:07.920 --> 09:33.120]  Здесь критическая секция нужна для того, чтобы синхронизировать доступ к ресурсу. Само по
[09:33.120 --> 09:45.360]  себе именно код, который исполняется, в принципе, не обязательно, что это должен быть один и тот
[09:45.360 --> 09:52.480]  же участок кода, по которому все потоки идут, но у них должно быть какая-то общая сущность,
[09:52.480 --> 09:58.960]  через которую эта синхронизация происходит. Чуть попозже, когда я буду говорить про реализацию
[09:58.960 --> 10:15.760]  критической секции, я думаю, будет понятнее. Про захват и освобождение я уже сказал. Еще в некоторых
[10:15.760 --> 10:23.320]  реализациях таких более продвинутых бывает операция try lock, то есть попробовать захватить,
[10:23.320 --> 10:30.480]  но если не получилось, то не ждать, а вернуть какое-то там ошибочное значение, и тогда можно
[10:30.480 --> 10:37.400]  продолжить программу как-то по-другому. И еще одна операция, которая бывает реализовывать,
[10:37.400 --> 10:44.600]  это проверка из locked, когда мы не хотим захватывать секцию, но просто хотим проверить,
[10:44.600 --> 10:54.680]  захвачена сейчас или нет. Здесь есть один важный момент, это то, каким образом выбирать
[10:54.680 --> 11:05.800]  следующий поток после освобождения критической секции. Зачастую на реальных машинах
[11:05.800 --> 11:16.480]  у нас топология ядер может быть таким образом сделана, что там шина данных, она не совсем
[11:16.480 --> 11:26.480]  одинаковая. Точнее, задержка доступа к памяти, она не совсем одинаковая у разных ядер процессора.
[11:26.480 --> 11:34.560]  Допустим, в современных AMD сервенных процессорах, например, они организованы в блоке ядра в
[11:34.560 --> 11:45.120]  процессоре. И теоретически там на пару секунд у одного ядра может быть больше задержка, чем у
[11:45.120 --> 11:55.600]  другого. И если мы будем просто выбирать следующий поток, который должен войти в секцию просто по
[11:55.600 --> 12:04.760]  принципу, кто первый сумел захватить, тот и продолжает, то мы можем попасть в такую ситуацию,
[12:04.760 --> 12:11.120]  когда один и тот же поток, если он, например, в цикле захватывает критическую секцию, он так и
[12:11.120 --> 12:19.040]  будет один и тот же поток в цикле в нее входить, а все остальные будут бесконечно ждать. Чтобы
[12:19.040 --> 12:25.120]  такого не происходило, почти во всех существующих реализациях, которые работают на практике,
[12:25.120 --> 12:34.120]  применяются те или иные способы, как можно обеспечить, ну, по-русски обычно не говорят
[12:34.120 --> 12:42.080]  справедливость, обычно используют термин fairness. То есть, например, здесь на слайде
[12:42.080 --> 12:50.000]  приведены пары алгоритмов, таких самых простых, как можно это сделать. Ну, алгоритм ticket-lock это
[12:50.000 --> 12:57.040]  просто обычная очередь. То есть, как с бербанки, мы приходим, получаем, когда поток захватывает секцию,
[12:57.040 --> 13:02.400]  он получает там какой-то номер, встает в очередь и, соответственно, в том порядке, в каком они
[13:02.400 --> 13:16.040]  захватывали секции, так они будут в точно таком же порядке, они в нее и войдут.
[13:32.400 --> 13:45.440]  Ну да, есть, действительно, в операционной системе, когда мы пользуемся критическими секциями,
[13:45.440 --> 13:52.280]  действительно реализован такой механизм, что когда поток встает в ожидание, он, как правило,
[13:52.280 --> 14:01.880]  снимается с исполнения в этот момент и процесс переходит в какое-то другое состояние, а-ля спящие,
[14:01.880 --> 14:09.680]  это уже детали реализации, то есть, в зависимости от того, как планировщик реализован в операционной
[14:09.680 --> 14:18.800]  системе, в принципе, это не обязательно. Можно реально просто в цикле ходить, жечь
[14:18.800 --> 14:28.640]  электричества, это с точки зрения именно логики работы, это на это не влияет. Так, ну и вот мы
[14:28.640 --> 14:38.320]  переходим непосредственно к примитивам синхронизации, то есть, критическая секция,
[14:38.320 --> 14:43.440]  это такая абстракция, которая, в принципе, она может существовать не только в софте,
[14:43.440 --> 14:50.160]  она примерно в таком же виде существует и на уровне железа, то есть, в процессоре тоже
[14:50.160 --> 15:01.840]  есть критические секции для доступа к памяти в первую очередь. До того, как появились аппаратные
[15:01.840 --> 15:15.360]  возможности атомарного доступа, примитивы синхронизации были сделаны с помощью какой-нибудь
[15:15.360 --> 15:23.520]  внешней сущности, на которую мы можем временно переключить исполнение, чтобы она проверила,
[15:23.520 --> 15:34.640]  чтобы она проверила, захвачен ли сейчас ресурс, выбрала, если не захвачен, то выбрала,
[15:34.640 --> 15:45.200]  какой поток должен следующим войти в критическую секцию и так далее. Как правило, как это происходило,
[15:45.200 --> 15:51.920]  программа, которая хочет захватить критическую секцию, генерирует прерывания, поскольку контроллер
[15:51.920 --> 15:59.280]  прерываний у нас один в системе, то мы в этот момент можем заблокировать приход других прерываний,
[15:59.280 --> 16:06.760]  после этого мы попадаем в операционную систему, в ядро, и она как раз является такой внешней
[16:06.760 --> 16:12.080]  сущностью, мы можем специально сделать так, чтобы она работала только в однопоточном режиме,
[16:12.080 --> 16:20.840]  чтобы у нас не было никаких проблем. Вот мы выпустили прерывания, попали в операционную систему,
[16:20.840 --> 16:32.360]  в ядро имеется в виду, сделали там какие-то операции, добавили поток в очередь, решили,
[16:32.360 --> 16:40.040]  какой поток нам надо переключиться, уже переключились обратно из ядра, программа
[16:40.040 --> 16:46.920]  делает то, что она хотела сделать в критической секции и снова генерирует прерывания для того,
[16:46.920 --> 16:59.960]  чтобы критическую секцию отпустить, освободить. Да, я как раз про них буду говорить чуть попозже.
[16:59.960 --> 17:11.960]  На прерываниях они как раз уже практически нигде не сделаны, за исключением, ну на одноядерных
[17:11.960 --> 17:20.040]  системах можно делать это через прерывания, но как вы понимаете, процесс генерации прерывания
[17:20.040 --> 17:28.600]  он весьма затратный, и пожалуй единственный его плюс в том, что вот как раз операционная система,
[17:28.600 --> 17:33.000]  поскольку мы в нее, мы попадаем в ядро операционной системы, там мы можем решить,
[17:33.160 --> 17:44.520]  что если потоку нужно ждать, то мы можем его снять вообще с исполнения, чтобы он не тратил в пустую
[17:44.520 --> 17:59.160]  вычислительные ресурсы. Самый классический пример реализации критической секции – это
[17:59.160 --> 18:10.760]  mutex от слов mutual exclusion. Это как раз примитив, который позволяет защищенную им секцию
[18:10.760 --> 18:19.200]  исполнять только одному потоку в определенный момент времени. То есть вот пример кода,
[18:19.200 --> 18:30.280]  у нас есть операция захвата mutex. Дальше здесь зачастую бывает удобно иметь рекурсивный mutex,
[18:30.280 --> 18:37.000]  когда мы можем несколько раз делать в одном и том же потоке захват этого mutex. Как правило,
[18:37.000 --> 18:43.120]  это удобно для реализации всяких библиотечных функций, чтобы тот человек, который их использует,
[18:43.120 --> 18:54.320]  не заморачивался о том, что там надо захватывать, что там не надо. У нас есть операция захвата,
[18:54.320 --> 19:03.440]  внутри после нее сразу можно делать какие-то действия, которые можно делать только одному
[19:03.440 --> 19:12.440]  потоку в один момент, и после этого мы вызываем процедуру unlock и выходим из mutex.
[19:12.440 --> 19:33.040]  Как правило, рекурсивные mutex сделаны таким образом, что повторный lock ничего не делает,
[19:33.040 --> 19:38.240]  он только будет потом в конце считать, чтобы количество локов было одинаково к количеству
[19:38.240 --> 19:53.280]  unlock. Еще один классический пример это симафор, это такое обобщение над mutex скорее. То есть это
[19:53.280 --> 20:02.360]  критическая секция, в которой может быть, которая может одновременно исполнять n потоков. То есть
[20:02.360 --> 20:14.440]  не один, там бывают такие алгоритмы, не так часто они встречаются, в которых допускается
[20:14.440 --> 20:21.680]  исполнение, одновременное исполнение не одним, а несколькими потоками. Симафоры тоже бывают
[20:21.680 --> 20:28.840]  рекурсивными, также в литературе встречается понятие бинарный симафор, это симафор, у которого
[20:28.840 --> 20:50.960]  n равно единице. Это то же самое, что и mutex. Я сейчас рассказывал, как эти все примитивы были
[20:50.960 --> 20:58.280]  реализованы раньше, в то время, когда не было аппаратной возможности атомарного доступа к
[20:58.280 --> 21:10.440]  памяти. После этого, когда это все стало более-менее широко распространяться, эти же примитивы стали
[21:10.440 --> 21:17.200]  реализовывать уже с помощью lock-free механизмов, и внешне они как бы остались такими же для
[21:17.200 --> 21:27.200]  программиста. Но при этом внутри они уже как бы являются не совсем блокирующими, потому что они
[21:27.200 --> 21:33.320]  уже не используют вот эти все механизмы с окруживаниями и всем таким. Но понятие осталось,
[21:33.320 --> 21:40.640]  и здесь существует такая небольшая путаница, что, как правило, алгоритмы, которые используют
[21:40.640 --> 21:47.120]  локи, они являются блокирующими, но они называются блокирующими, но внутри эти локи уже могут
[21:47.120 --> 21:58.440]  быть реализованы и не обязательно с помощью блокирующих примитивов. Так, значит,
[21:58.440 --> 22:10.520]  атомарные операции бывают нескольких видов, то есть самое основное это чтение и запись,
[22:10.520 --> 22:18.760]  и в принципе на их основе уже можно реализовать достаточно много всего. Здесь есть даже целый
[22:18.760 --> 22:26.120]  класс алгоритмов, который называется weight-free алгоритмы, которые используют только атомарное
[22:26.120 --> 22:32.360]  чтение и запись. Как правило, они используются во всяких real-time-системах, в которых
[22:32.360 --> 22:43.480]  обязательно в которых необходимо высчитывать гарантии времени исполнения. То есть мы в любой
[22:43.480 --> 22:52.520]  момент программы должны знать, сколько времени она будет выполняться, даже в худшем случае. Но
[22:52.520 --> 23:00.040]  этого недостаточно для того, чтобы реализовать примитивы синхронизации типа критических секций,
[23:00.040 --> 23:14.640]  и поэтому существует еще как минимум две операции. Это compare and swap и пара load link
[23:14.640 --> 23:28.360]  store conditional. Кто-нибудь встречался из вас с таким? Мало ли, может быть там.
[23:30.040 --> 23:41.040]  Эти две операции, они взаимозаменяемые, их еще в литературе зачастую называют базисными,
[23:41.040 --> 23:49.440]  то есть вот как раз с помощью них можно строить всякие разные лог-free алгоритмы, и при этом,
[23:49.440 --> 23:56.360]  по крайней мере с точки зрения теории, они взаимозаменяемые, то есть можно реализовать
[23:56.360 --> 24:02.680]  одну через другую. Поэтому, как правило, архитектуры реализовывают либо одну,
[24:02.680 --> 24:09.880]  либо другую. У нас есть только одно исключение, это ARM, в которых в последней версии издались и
[24:09.880 --> 24:20.520]  все-таки сделали тоже compare and swap. Я здесь сразу покажу пример, думаю так будет понятнее.
[24:20.520 --> 24:33.240]  Операция compare and swap, здесь на примере указано, как можно реализовать функцию захвата критической
[24:33.240 --> 24:42.440]  секции с помощью одной либо другой операции. Операция compare and swap принимает на вход три
[24:42.440 --> 24:53.560]  аргумента, это переменную, в которую мы хотим записать значение, то значение, которое мы там
[24:53.560 --> 25:01.080]  предполагаем, что оно там сейчас есть, и третий аргумент, это значение, которое мы хотим туда
[25:01.080 --> 25:10.560]  записать. Что делает эта операция? Она считывает переменную, проверяет, сравнивает ее со вторым
[25:10.560 --> 25:20.240]  аргументом. Если сравнение произошло успешно, то мы туда записываем значение по третьему
[25:20.240 --> 25:29.240]  аргументу и возвращаем true, что операция прошла успешно. Если же в переменной оказалось не то,
[25:29.240 --> 25:41.160]  что мы ожидали, то запись не происходит и возвращается false. Эта операция атомарная,
[25:41.160 --> 25:53.920]  то есть это все происходит как бы за одно действие для внешнего наблюдателя. Ну и как бы вот в качестве
[25:53.920 --> 26:02.600]  примера, если мы, допустим, у нас есть флаг, который как раз обозначает захвачен у нас мютекс или нет,
[26:02.600 --> 26:11.680]  то есть если флаг выставим в true, значит он захвачен, если false, то он свободен. И когда мы
[26:11.680 --> 26:20.320]  хотим захватить этот мютекс, мы проверяем с помощью этой операции в цикле захвачен или нет,
[26:20.320 --> 26:30.560]  если он не захвачит, мы туда записываем значение true и возвращаемся из этой функции и мы в
[26:30.560 --> 26:37.200]  критической секции. Если же он в этот момент захвачен, процедура CAS будет возвращать все
[26:37.200 --> 26:42.520]  время false и мы будем крутиться в цикле до тех пор, пока у нас не получится все-таки эту
[26:42.520 --> 26:55.880]  переменную захватить. Здесь понятно, как работает. В операциях load, link, store, conditional операцию
[26:55.880 --> 27:03.320]  чтения и записи были разнесены на две, то есть тут это все прям одной инструкцией выполняется,
[27:03.320 --> 27:14.120]  и как вы можете увидеть, в основном это все CAS реализовано на всяких таких более больших
[27:14.120 --> 27:24.360]  архитектурах, а на тех архитектурах, которые изначально задумывались как строго риск,
[27:24.360 --> 27:31.840]  такие операции, в которых есть три аргумента, это уже слишком много и поэтому там были
[27:31.840 --> 27:45.120]  позеленное разделение их. Что здесь, как здесь происходит операция? Сначала мы с помощью функции
[27:45.120 --> 27:56.760]  load, link считываем значение флага, при этом в отличие от обычной операции чтения у процессора внутри
[27:56.760 --> 28:08.360]  есть специальный регистр, его не видно снаружи, но как правило реализация происходит именно так. Там
[28:08.360 --> 28:14.520]  внутри есть специальный регистр, который после использования операции load, link в нем запоминается
[28:14.520 --> 28:23.000]  значение, которое было считано, и потом, когда мы после этого попробуем сделать store, conditional,
[28:23.000 --> 28:32.840]  в этом процессор проверяет текущее значение этого флага в памяти и у себя вот в этом внутреннем
[28:32.840 --> 28:40.560]  регистре. Если оно не поменялось, то значит все хорошо, мы можем произвести запись, если нет,
[28:40.560 --> 28:53.280]  то соответственно кто-то другой уже захватил секцию и мы возвращаем false. Здесь нужно
[28:53.280 --> 29:01.560]  иметь ввиду, что вот то, что мы считали значение, это не вот этот внутренний регистр, это мы его
[29:01.560 --> 29:08.120]  считали для себя, а внутренний регистр он нам недоступен, поэтому мы должны сами тоже считать
[29:08.120 --> 29:25.000]  это значение и его проверить в условии. Нет, это регистр, который вот всегда есть, он не может
[29:25.000 --> 29:40.440]  закончиться. Это только на время одной операции, то есть он запоминается до следующего store
[29:40.440 --> 30:02.080]  conditional и все. Тутс, понятно, что происходит? Тогда у меня есть парочка вопросов. Допустим,
[30:02.080 --> 30:11.280]  между операцией llsc кто-то записал туда в область памяти точно такое же значение,
[30:11.280 --> 30:17.800]  которое там уже было. Что тогда будет происходить, как вы думаете?
[30:17.800 --> 30:41.200]  Тут как сказать, вот в примере с mutex, да, там если кто-то запишет туда такое же значение,
[30:41.200 --> 30:50.000]  в принципе это не страшно. Но вообще бывают такие алгоритмы, в которых сам факт того,
[30:50.000 --> 30:57.680]  что произошло какое-то изменение, это важно. Ну, точнее не изменение, а что произошла какая-то операция.
[31:11.200 --> 31:26.080]  Тут само по себе запись в memory map устройства можно защитить с помощью mutex,
[31:26.080 --> 31:34.120]  но саму эту запись с помощью атомарных операций делать не стоит. Это обычно,
[31:34.120 --> 31:48.560]  ну, зачастую это даже запрещено архитектурой, потому что это разные вещи. Окей, а если посередине
[31:48.560 --> 32:01.120]  между loadlink и store conditional мы, планировщик, решил нас остановить? Ну, в принципе,
[32:01.120 --> 32:20.920]  на существующих архитектурах мы никак не сможем этот момент отловить. То есть в стандарте C для
[32:20.920 --> 32:33.200]  этого существует операция, это реализовано только через componentswap, и там есть операция componentswap weak
[32:33.200 --> 32:47.400]  и componentswap strong. То есть сильный componentswap, он позволяет такие штуки тоже отлавливать,
[32:47.400 --> 32:54.720]  но он гораздо труднее в реализации, и поэтому его вынесли специально в отдельную функцию и объявили
[32:54.720 --> 33:03.240]  его опциональным. То есть если componentswap weak всегда есть на платформе, если она поддерживает
[33:03.240 --> 33:16.140]  атомики, то componentswap strong он может быть, может не быть. На x86 и на ARMv8 он есть,
[33:16.140 --> 33:26.880]  наверное, есть еще на Power, а где еще, я, честно говоря, не в курсе. Да, в принципе,
[33:26.880 --> 33:39.260]  с переключением контекста примерно такая же история, то есть точно также, если мы используем
[33:39.260 --> 33:46.560]  операции со слабыми гарантиями и произошло переключение контекста и там не поменялось
[33:46.560 --> 33:59.520]  значение, то мы этого не заметим у себя в процессе. И есть еще такая проблема в этих
[33:59.520 --> 34:09.880]  lock-free-алгоритмах, которые называются eba-problem, то есть что будет, если мы сначала туда запишем
[34:09.880 --> 34:16.640]  другое значение, а потом запишем снова то значение, которое там было до этого.
[34:16.640 --> 34:30.200]  Можем ли мы как-то задетектить, что произошла запись?
[34:39.880 --> 34:59.880]  А если у нас есть только операции со слабыми гарантиями? Можем ли мы что-то сделать как
[34:59.880 --> 35:19.840]  программисты с этим? Сейчас, у нас есть поток, который очень часто считывается переменно, хорошо.
[35:29.880 --> 35:41.440]  Тут как? Этот поток будет работать на одном ядре, а на втором ядре, возможно, мы еще не увидели этих
[35:41.440 --> 35:51.720]  сайд-эффектов и как нам нужно как-то успеть сообщить? Вот я приведу пример. Допустим, у нас есть
[35:51.720 --> 36:03.200]  список. Мы взяли, атомарно удалили из него элемент, а потом взяли и сразу же записали туда на его
[36:03.200 --> 36:14.560]  место другой. Как правило, если мы, ну не как правило, зачастую, если мы освобождаем память,
[36:14.560 --> 36:20.680]  а потом снова алоцируем примерно такого же размера, то очень часто может получиться так,
[36:20.680 --> 36:31.760]  что указатель по факту его значение нам выдали такое же. И если это применить к значениям списка,
[36:31.760 --> 36:37.680]  то у нас получается, что, допустим, мы удалили элемент и ссылку на следующий элемент у нас
[36:37.680 --> 36:43.800]  стало ноль, а потом мы туда добавили и снова туда записали точно такой же указатель. По факту,
[36:43.800 --> 36:53.200]  это уже элемент-то другой получился. Как нам задетектить тот факт, что список-то поменялся?
[36:53.200 --> 37:07.680]  Не-не-не. Элемент списка, у него содержимое может быть другое, но мы же когда проходимся по списку,
[37:07.680 --> 37:20.800]  если мы будем заглядывать в содержимое, это будет очень дорого. Как нам можно было бы задетектить изменение?
[37:20.800 --> 37:31.040]  Есть даже для этого фича, что там выставляют как раз, чтобы реанализировать указатель, если между
[37:31.040 --> 37:40.640]  доступами произошло рискезли. В общем, если планировщик, если было зафиксировано, что между
[37:40.640 --> 37:52.640]  последним и последним указателем и тем, что у нас сейчас, планировщик не шел, то указатель нужно, типа,
[37:52.640 --> 38:03.200]  это было про кэши, то есть если мы освободили память, как сделать так, чтобы другие процессоры это тоже
[38:03.200 --> 38:15.760]  заметили. Это было про кэш-трансляции, наверное. А здесь просто память еще раз залоцировали в том же
[38:15.760 --> 38:31.920]  месте, но память то уже другая, то есть туда записали другое значение. Ну ладно, обычно
[38:31.920 --> 38:45.760]  обычно делают так. Вместе со значением новым записывают какой-то тег, который каждый раз был бы
[38:45.760 --> 38:54.320]  уникальный для каждой записи, и таким образом, когда мы должны считывать такой список, то мы
[38:54.320 --> 39:05.040]  должны проверить указатель и сам тег, что он не поменялся. То есть обычно решение
[39:05.040 --> 39:11.360]  этой проблемы называют ABA-штрих, то есть это как бы A, но это уже не совсем тот A, который был в начале.
[39:11.360 --> 39:32.360]  Ну почему? Вот, например, на x86 есть операция Compare and Swap, которая позволяет оперировать 16-байтными
[39:32.360 --> 39:43.040]  значениями. То есть 16-байт – это куда два указателя помещается. И что иногда делают? В одну половину
[39:43.040 --> 39:50.800]  записывают непосредственно указатель, а во второй половине у тебя есть целых 64 бита для того,
[39:50.800 --> 40:01.480]  чтобы реализовать энтропию. То есть можно просто счетчик каждый раз инкриментировать и, ну например,
[40:02.040 --> 40:07.200]  инкриментировать счетчик. В принципе, тегирование может каким-то другим образом быть реализовано,
[40:07.200 --> 40:19.440]  но 64 бита вполне достаточно для того, чтобы там за какое-то обозримое время этот счетчик не
[40:19.440 --> 40:26.760]  переполнился, а если нужно обеспечивать там гарантию на более длительное время,
[40:26.760 --> 40:47.600]  то тут уже есть место для того, чтобы это как-то разрулить. Другие проблемы, связанные с атомиками,
[40:47.600 --> 40:57.800]  можно продемонстрировать на таком примере. Вот здесь у нас есть два потока. Здесь опущен код,
[40:57.800 --> 41:03.480]  который их создает. Ну, допустим, у нас создаются два потока, и они работают строго,
[41:03.480 --> 41:10.200]  каждый на отдельном ядре, на одном и том же. Ни каких там перепланирований не происходит,
[41:10.200 --> 41:15.960]  вот все просто они работают одновременно. Что выведется?
[41:40.200 --> 41:53.800]  Ну, про то, что он может вывести один, здесь, наверное, понятно, да, что вот у нас второй
[41:53.800 --> 41:59.320]  поток будет ждать, пока мы не запишем потом Eq и потом выведем. А может ли вывестись 0?
[41:59.320 --> 42:18.200]  И что должно произойти, чтобы вывелся 0?
[42:18.200 --> 42:24.120]  То есть, запись этой переменной мы увидим, а запись этой переменной мы в кшах не увидим.
[42:24.120 --> 42:35.720]  Нет, вот этот поток на одном ядре работает, а вот этот на другом.
[42:54.120 --> 43:11.760]  Ну, в принципе, такой вариант, конечно, тоже возможен, но если вы напишете такую
[43:11.760 --> 43:20.200]  программу, то вы столкнетесь гораздо быстрее с другим поведением, из-за которого тоже выведется 0,
[43:20.200 --> 43:25.760]  может вывестись 0. Но тут вообще нужно определиться с тем, что мы поднимаем под
[43:25.760 --> 43:35.080]  операции atomic read и atomic write. Если это просто инструкция атомарного записи чтения, то действительно
[43:35.080 --> 43:45.200]  может вывестись и 0 и единичка в конце. Но если у нас здесь под этим подразумевается такая семантика
[43:45.200 --> 43:53.640]  атомарных операций, которая поделена в стандарте из оси, то тогда здесь все строго. Здесь обязательно
[43:53.640 --> 44:04.320]  выведется единица, там никаких вариантов быть не может. Почему так? Здесь у нас вступает в работу
[44:04.320 --> 44:12.240]  две сущности. Это компилятор, который из сишного кода нам генирует ассемблерный код, и процессор,
[44:12.240 --> 44:19.080]  который ассемблерный код потом исполняет. Вообще говоря, с точки зрения стандарта си,
[44:19.080 --> 44:27.320]  если мы видим в одном блоке две переменные, которые между собой никак не взаимодействуют,
[44:27.320 --> 44:34.480]  то есть когда мы компилируем этот поток, то мы видим, что у нас есть в одну переменную
[44:34.480 --> 44:43.120]  запись и в другую переменную запись. Они вообще никак между собой не связаны. И для таких переменных
[44:43.120 --> 44:51.760]  компилятор вполне себе может их сгенировать ассемблерный код в любом порядке. То есть присваивание
[44:51.760 --> 44:59.720]  может быть и вот так, и наоборот, и посередине может быть какая-нибудь еще операция туда вставлена.
[44:59.720 --> 45:14.240]  Здесь у компилятора достаточно большая свобода. Это так происходит из-за того,
[45:14.240 --> 45:25.520]  что он в рамках одной функции не видит взаимодействия между ними. То есть в ассемблерном
[45:25.520 --> 45:35.280]  коде у нас записи могут быть в другом порядке. И уже на следующем уровне это на уровне процессора.
[45:35.280 --> 45:43.400]  Современные процессоры у нас тоже делают много всяких вещей под капотом, таких как спекулятивное
[45:43.400 --> 45:55.320]  исполнение и предсказание переходов и чего там только нет. И он тоже может исполнить инструкции,
[45:55.320 --> 46:06.360]  если между ними нет зависимости в том порядке, в котором он захочет. Что с этим можно сделать?
[46:06.360 --> 46:22.000]  Ну да, почему-то все вспоминают про волатайлы, но волатайл спасет только от одной ситуации,
[46:22.000 --> 46:33.800]  когда мы вот эти две переменные объявим как волатайл, то они не будут переупорядочены компилятором.
[46:33.800 --> 46:41.200]  Но ассемблерный код, если вы посмотрите, что с генерируемым из такого кода, что с волатайлами,
[46:41.200 --> 46:49.520]  он не будет отличаться. То есть у нас все равно остается проблема с процессором. Почему так
[46:49.520 --> 47:04.800]  происходит? Я уже объяснил. Как от этого защищаться? Что он не обязательно может
[47:04.800 --> 47:23.200]  исполнить инструкции в том порядке, в котором они записаны. А как нам тогда определять,
[47:23.200 --> 47:51.480]  какие случаи его включать? В принципе, мысль интересная и даже в некотором смысле в правильную
[47:51.480 --> 48:02.040]  сторону, но отключить конвейер, как мы можем отключить конвейер, а как мы по-другому будем операции доставать?
[48:02.040 --> 48:12.160]  А что делать с тем, что у нас уже там есть конвейер?
[48:12.160 --> 48:37.720]  А если мы делаем как в M1, когда мы параллельно начинаем парсить инструкции,
[48:37.720 --> 48:44.040]  вот просто типа с этого места, потом в другой стадии конвейера, с этого места. То есть мы вот
[48:44.040 --> 49:04.120]  это вот еще не распарсили, а тут была вот эта вот инструкция. Да, давайте просто зайдем на
[49:04.120 --> 49:14.080]  Авито, купим там 386 процессор и будем под него программировать. В принципе, действительно есть
[49:14.080 --> 49:22.240]  специальная операция, которая позволяет избежать такого поведения, чтобы ни компилятор, ни процессор
[49:22.240 --> 49:29.800]  не могли переупорядочить инструкции. И такие операции называются барьерами памяти. То есть это
[49:29.800 --> 49:37.640]  можно себе представить таким образом, что, допустим, вот у нас есть блок, да, и компилятор считает,
[49:37.640 --> 49:42.920]  что здесь можно переупорядочить инструкции. А мы берем и вот здесь вот такую линию чертим и говорим,
[49:42.920 --> 49:49.200]  что типа вот можно вот тут вот переупорядочивать сверху линии и под этой линии можем, а вот за нее
[49:49.200 --> 50:06.080]  переходить нельзя. Так я же говорил, что тут есть две сущности. Здесь есть компилятор, который
[50:06.080 --> 50:26.000]  может сгенерировать уже ассемблерный код. Сейчас объясню. Вот, то есть для этого вводится такое
[50:26.000 --> 50:33.240]  понятие барьера. И барьеры также как, поскольку у нас здесь существует две сущности, барьеры могут
[50:33.240 --> 50:41.760]  быть компиляторные и процессорные. Вот то, что вы говорили, что можно использовать volatile,
[50:41.760 --> 50:48.840]  это по сути будет компиляторный барьер. Мы запретим компилятору переупорядочивать
[50:48.840 --> 50:54.160]  инструкции, а процессора нет. Для того, чтобы запретить еще и процессору переупорядочивать
[50:54.160 --> 51:04.840]  инструкции. Для этого существует специальная инструкция на x86. Она так называется mfence.
[51:04.840 --> 51:26.760]  То есть барьер памяти. Никакой, эта инструкция такая же как. В x86 там барьеры памяти можно
[51:26.760 --> 51:35.000]  реализовывать с помощью такой инструкции. Еще есть вариант добавить prefix log. К некоторым
[51:35.000 --> 51:40.240]  инструкциям позволяется такой префикс добавить. Это будет как бы импевалентно записи сначала
[51:40.240 --> 51:45.840]  mfence, а потом этой инструкции. А также на старых процессорах, на которых еще mfence не было,
[51:45.840 --> 51:58.920]  использовали инструкцию cpoid в качестве барьера. У нее есть такой side-effect, она тоже запрещает
[51:58.920 --> 52:11.400]  переупорядочивать процессоры инструкции до нее и после. Не, ну он в программе есть,
[52:11.400 --> 52:20.040]  то есть вот здесь, что будет означать, если мы поставим здесь барьер. Это будет
[52:20.040 --> 52:26.520]  значить, что нам нужно вот именно в таком порядке исполнить эти команды и по-другому никак.
[52:26.520 --> 52:36.920]  Ну вот эту и вот эту, соответственно, если между ними стоит барьер. Это инструкция,
[52:36.920 --> 52:50.160]  которую генерирует компилятор во время генерации кода. И вообще говоря, почему я говорил,
[52:50.160 --> 53:02.880]  что если мы понимаем atomic-rit и atomic-rite как атомарные операции в языке C, то они по своей
[53:02.880 --> 53:09.760]  семантике выступают сразу как компиляторный и как процессорный барьер. То есть когда мы пишем
[53:09.760 --> 53:21.280]  atomic-rite, используя вот функцию из std atomic.h, она по стандарту C11 должна быть также и барьером,
[53:21.280 --> 53:29.320]  поэтому компилятор не сможет переупорядочивать вот это вот присваивание за atomic-rite.
[53:29.320 --> 53:50.120]  Вот. Да, барьеры в принципе бывают... процессорные барьеры различаются по
[53:50.120 --> 54:01.960]  такому понятию как memory order. Грубо говоря, в том же интеле, например, есть не только инструкция
[54:01.960 --> 54:11.480]  mfence, есть еще sfence и lfence. То есть, соответственно, барьер только на запись или барьер только на
[54:11.480 --> 54:22.200]  чтение. То есть он в зависимости от этого разрешается переупорядочивать либо одни,
[54:22.200 --> 54:30.520]  либо другие операции. Ну, мы к этому вернемся, где-то там в районе 12-й лабораторки, там будет
[54:30.520 --> 54:40.320]  такое более обобщенное представление о том, как все это работает. Для тех, кому интересно,
[54:40.320 --> 54:47.160]  у меня там в конце лекции есть ссылочка на такой интерактивный инструмент,
[54:47.160 --> 54:58.880]  который позволяет играться с моделью памяти языка C. Вот. Ну да, вот здесь важный момент упомянут,
[54:58.880 --> 55:07.480]  что когда мы ставим инструкцию барьера, по сути это означает, что мы хотим, чтобы вот результаты,
[55:07.480 --> 55:14.920]  которые были до этого барьера, они были видны всем процессорам. То есть мы таким образом forсим
[55:14.920 --> 55:30.280]  синхронизацию. Вот. И вернемся к самим примитивам. То есть с помощью вот этих лог-фри операций
[55:30.280 --> 55:40.080]  можно сделать примитив spinLog. Это, по сути, аналог мютекса. Только чем он отличается? Это тем,
[55:40.080 --> 55:54.160]  что он реализуется вот как раз таким образом, как я приводил пример вот здесь. То есть он просто
[55:54.160 --> 56:00.600]  в цикле будет ожидать по... будет в цикле ожидать бесконечно, пока какой-то участок памяти не
[56:00.600 --> 56:10.960]  изменится. И это достаточно затратная операция в том плане, что если он будет ждать мало, то это
[56:10.960 --> 56:18.320]  будет быстрее, чем переключение контекстов в ядро. Но если он будет ждать долго, то мы будем отбирать
[56:18.320 --> 56:27.880]  ресурсы у компьютера на то, чтобы просто ожидать в цикле. В этом минус этого примитива. И поэтому
[56:27.880 --> 56:35.200]  придумали еще такую штуку, как адаптивный мютекс. То есть это мы сначала подождали в горячем цикле
[56:35.200 --> 56:45.640]  какое-то время. И если за это время мютекс не освободился, то мы уже все говорим операционной
[56:45.640 --> 56:59.200]  системе, что все, мы ждем. Можешь нас прибить на время. Также я уже этого касался с помощью
[56:59.200 --> 57:08.400]  лог-фри операцией. С помощью вот этих атомарных операций существуют weight-free и log-free алгоритмы.
[57:08.400 --> 57:20.280]  Это как раз weight-free в первую очередь. Это алгоритмы, в которых вот таких вот конструкций,
[57:20.280 --> 57:30.800]  когда while что-нибудь не равно true, таких там вообще не может быть. Потому что сколько времени они
[57:30.800 --> 57:36.200]  проживут, в смысле сколько времени они будут работать, предсказать заранее невозможно.
[57:36.200 --> 57:54.160]  Так вот мы подошли к ошибкам, которые встречаются при параллельном программировании. Здесь
[57:54.160 --> 58:00.280]  следует рассказать про два понятия. Это потока безопасности и реантерабельность.
[58:00.280 --> 58:07.800]  То есть потока безопасности это такой код, который можно из нескольких потоков одновременно
[58:07.800 --> 58:18.440]  вызывать, и он будет работать корректно. То есть здесь на примере вот этой функции можно видеть,
[58:18.440 --> 58:25.560]  что у нее есть глобальная переменная, но она объявлена как локальная в данном потоке.
[58:25.560 --> 58:33.960]  То есть если мы запустим эту функцию в другом потоке, то переменная tmp у него будет своя
[58:33.960 --> 58:47.720]  собственная. И за счет этого вот эта конкретная переменная, вот эта конкретная функция может
[58:47.800 --> 58:55.600]  быть вызвана из нескольких потоков, все будет нормально, она отработает. Но здесь в этой функции
[58:55.600 --> 59:03.280]  есть другая проблема, и это то, что она не реантерабельная. Например, если после
[59:03.280 --> 59:15.960]  чтения случайного числа операционная система захотела, ну тут даже нет, тут наверное лучше
[59:15.960 --> 59:22.320]  сказать, что например, если у нас вот в этот момент прилетело прерывание, и соответственно мы
[59:22.320 --> 59:29.760]  обязаны закончить исполнение этой функции временно и переключиться на выполнение этого прерывания,
[59:29.760 --> 59:38.520]  то когда мы вернемся обратно, мы уже не можем гарантировать, что значение tmp осталось такое же,
[59:38.520 --> 59:44.640]  как было до этого. Его мог кто-то другой изменить, кто тоже работает в контексте этого потока. И
[59:44.640 --> 59:51.720]  в случае с прерываниями такое как раз возможно, потому что во многих операционных системах прерывание
[59:51.720 --> 59:58.920]  оно исполняется в контексте того потока, который исполнялся в тот момент, когда оно пришло. То есть
[59:58.920 --> 01:00:05.680]  вот эта вот переменная будет там доступна. Если она допустим, обработчик прерывания вызвал
[01:00:05.680 --> 01:00:22.200]  эту функцию getNumber, то tmp поменяется. Тут понятно. Еще один пример нереантерабельной функции
[01:00:22.200 --> 01:00:32.120]  представлен вот здесь. Это в принципе вообще такая не шибко корректная конструкция, но возможно
[01:00:32.120 --> 01:00:41.720]  позволит чуть получше понять саму идею. То есть здесь у нас там допустим в операционной системы
[01:00:41.720 --> 01:00:50.400]  есть функция panic, которая вызывается при какой-нибудь ошибке, когда мы уже не можем из этой ошибки никак
[01:00:50.400 --> 01:00:59.120]  восстановиться и вызываем ее для того, чтобы она просто напечатала причину падения операционки и
[01:00:59.120 --> 01:01:10.320]  спокойно упала. Но в реализации вывода сообщения у нас здесь существует еще одна проверка,
[01:01:10.320 --> 01:01:27.000]  которая сама тоже вызывает функцию panic. Это другой способ как продемонстрировать нереантерабельную
[01:01:27.000 --> 01:01:39.440]  функцию. То есть здесь если вдруг при ее вызове вот эта проверка вернет true, то что произойдет,
[01:01:39.440 --> 01:01:57.080]  произойдет конечно произойдет, но в каком виде он будет понятно не до конца. Я имею в виду если мы вот
[01:01:57.080 --> 01:02:25.880]  по этой ветке пройдем, так мы уже как бы в процессе. Там насколько я помню,
[01:02:25.880 --> 01:02:37.160]  как бы на самом деле функцию panic в многих операционных системах она просто синхронная,
[01:02:37.160 --> 01:02:48.760]  то есть она сделана таким образом, что когда ее можно вызывать, то у нас один всего поток остается
[01:02:48.760 --> 01:03:04.960]  и еще одна популярная к сожалению ошибка это допущение в программе гонок или race condition
[01:03:04.960 --> 01:03:13.640]  по-английски. Вообще этот термин он пришел в программирование из электроники. У них там
[01:03:13.640 --> 01:03:20.320]  бывают случаи, когда нужно один и тот же сигнал получить в разных участках платы,
[01:03:20.320 --> 01:03:34.560]  но например дорожки которые ведут к приемникам этого сигнала на плате, они разные длины и может
[01:03:34.560 --> 01:03:43.840]  получиться такая ситуация, что они настолько разные длины, что задержка между получением сигнала в одной
[01:03:43.840 --> 01:03:53.760]  точке и в другой она уже будет ощутима и плата может, само устройство может работать неправильно
[01:03:53.760 --> 01:04:03.760]  из-за этого. Там это называется гонка сигналов и соответственно в программировании подобная
[01:04:03.760 --> 01:04:13.120]  ситуация тоже называли race condition. То есть идея в том, что такая ситуация возникает в тот
[01:04:13.120 --> 01:04:18.880]  момент, когда в зависимости от того в каком порядке потоки будут обращаться к общему
[01:04:18.880 --> 01:04:30.160]  ресурсу результат будет разный, результат выполнения всей программы и очень часто это
[01:04:30.160 --> 01:04:38.320]  приводит к таким ошибкам, которые тяжело найти, потому что зачастую их воспроизведение
[01:04:38.320 --> 01:04:46.560]  и зачастую воспроизвести их получается только на каком-нибудь конкретном компьютере, только если
[01:04:46.560 --> 01:04:58.960]  мы запустили еще 10 программ это 11 и только в четверг в 3 часа ночи. Все это как бы реальные
[01:04:58.960 --> 01:05:11.800]  случаи, когда люди пытались люди пытались отловить гонку в программе и ладно бы если бы это были
[01:05:11.800 --> 01:05:23.560]  просто ошибки, которые трудно поймать и они достаточно редко стреляют, но такие места в
[01:05:23.560 --> 01:05:35.600]  программе они открывают целый класс уязвимости, который успешно эксплуатируется и позволяет в
[01:05:35.600 --> 01:05:43.520]  принципе любые ну зачастую можно там и удаленное выполнение кода выполнить с помощью эксплуатации
[01:05:43.520 --> 01:05:49.680]  гонки и там привилегии повысить и еще что-нибудь такое, то есть
[01:05:49.680 --> 01:06:19.520]  ну да, то есть как бы собственно именно такой пример у меня здесь и есть. Такие ошибки
[01:06:20.080 --> 01:06:31.880]  такой класс ошибок называется time of check, time of use. Ну почему это ошибки связаны с многопоточностью,
[01:06:31.880 --> 01:06:37.880]  потому что все-таки для того чтобы ее про эксплуатировать нужно одновременно выполнить,
[01:06:37.880 --> 01:06:49.400]  то есть у нас есть исполнение, у нас исполняется атакуемый поток и нам нужен еще один атакующий
[01:06:49.400 --> 01:06:56.760]  если у нас и если мы например находимся в каком-нибудь среде, в которой вообще можно
[01:06:56.760 --> 01:07:04.200]  выполнять только один поток в один момент времени, в принципе такую гонку про эксплуатировать будет
[01:07:04.200 --> 01:07:15.120]  ну как минимум сложнее. Я еще раз проговорю в чем здесь идея, то есть допустим мы хотим
[01:07:15.120 --> 01:07:21.480]  проверить перед запуском файла, мы хотим проверить можем ли мы его запускать там,
[01:07:21.480 --> 01:07:26.600]  это может быть проверка подписей, проверка про доступа или
[01:07:26.600 --> 01:07:53.200]  ну может такое быть, почему нет. Ну сейчас имеется в виду, что пока мы считываем в этот
[01:07:53.200 --> 01:08:01.040]  момент, еще пока мы не успели дойти до конца, еще туда что-то дописать. Ну если смотреть этот
[01:08:01.040 --> 01:08:07.800]  вариант когда мы то есть один из способов как можно таким ошибкам противостоять это
[01:08:07.800 --> 01:08:20.720]  считать сначала файл полностью до конца и только потом его проверить. Так мы проверяем уже после
[01:08:20.720 --> 01:08:27.360]  того как мы его считали, то есть если мы его будем просто дописывать, то у нас операция считывания не
[01:08:27.360 --> 01:08:37.760]  закончится. Когда она закончилась уже то что мы считали поменять будет нельзя, но при условии
[01:08:37.760 --> 01:08:42.840]  что операционная система, ну что есть какая-то область памяти, которая доступна только вот этому
[01:08:42.840 --> 01:08:53.920]  потоку, ее никто больше менять не может. Сейчас я все-таки не сказал в чем заключается ошибка,
[01:08:53.920 --> 01:09:06.520]  мы хотим проверить файл, вызываем функцию его проверки, которая это делает прямо на диске и
[01:09:06.520 --> 01:09:14.560]  после этого уже считываем файл, запускаем и вот в этот момент между проверкой и считыванием может
[01:09:14.560 --> 01:09:22.000]  возникнуть другой поток, может попробовать вклиниться в исполнение первого потока для того чтобы как-то
[01:09:22.000 --> 01:09:29.760]  там подменить файл или еще что-нибудь сделать. Еще один вариант это еще один вариант как можно
[01:09:29.760 --> 01:09:36.200]  защититься от такой проблемы, например если у нас файл большой, мы не можем его полностью в память
[01:09:36.200 --> 01:09:41.280]  считать или это очень медленно будет. Как правило в операционных системах есть возможность
[01:09:41.280 --> 01:09:50.040]  заблокировать файл эксклюзивно, то есть только один какой-то поток может вот к нему обращаться
[01:09:50.040 --> 01:09:57.600]  когда файл заплокирован, но это вот что-то такое типа критической секции получается.
[01:09:57.600 --> 01:10:13.520]  Еще один класс ошибок это deadlocking, взаимоблокировки, здесь наверное проще всего опять же на примере
[01:10:13.520 --> 01:10:25.760]  показать. Допустим у нас есть переменная tmp, которая защищена двумя mutex, lock1 и lock2 и один
[01:10:25.760 --> 01:10:33.880]  поток у нас входит в нее захватывая сначала первый а потом второй, а второй поток захватывает
[01:10:33.880 --> 01:10:42.240]  сначала второй потом первый. Ну и понятно что если мы запустились вот прям строго одновременно,
[01:10:42.240 --> 01:10:48.880]  то вполне возможна такая ситуация когда одновременно оба потока выполнили вот эту и вот эту операцию и
[01:10:48.880 --> 01:11:02.920]  тогда они оба застрянуты здесь будут бесконечно друг друга ждать. Такие такие ошибки в принципе не
[01:11:02.920 --> 01:11:09.920]  так уж сильно страшны, они достаточно легко видны в отладчике, то есть это не такая большая проблема.
[01:11:09.920 --> 01:11:14.760]  Обычно всегда видно что вот какой-то один поток бесконечно простаивает ничего не делает,
[01:11:14.760 --> 01:11:30.960]  можно эту ситуацию отловить. Потом в некоторых местах даже существуют специальные механизмы
[01:11:30.960 --> 01:11:40.160]  для отлавливания этих ошибок именно вот прям в runtime. Я такое видел ну такой наверное самый
[01:11:40.160 --> 01:11:49.240]  простой пример это базы данных, то есть в них всегда ну в современных во всех базах данных есть
[01:11:49.240 --> 01:11:56.480]  специальный процесс который следит за тем чтобы SQL запросы не блокировали друг друга и если
[01:11:56.480 --> 01:12:04.840]  такая ситуация произойдет то транзакция просто откатывается. Ну в базах данных такое возможно они
[01:12:04.840 --> 01:12:09.960]  специально сделаны таким образом что любая операция пока она не закончилась она может
[01:12:09.960 --> 01:12:21.760]  быть откатана до начала и да в общем там за блокировками за дудлоками прям следит отдельный
[01:12:21.760 --> 01:12:35.240]  процесс. Еще один класс ошибок уже гораздо более неприятный это лайфлоки или динамические
[01:12:35.240 --> 01:12:46.360]  взаимоблокировки. Тут на первый взгляд может показаться что вроде бы все нормально функции
[01:12:46.360 --> 01:12:55.200]  работают какой-то код исполняется но по факту по факту ничего не происходит. Ну я думаю пример
[01:12:55.200 --> 01:13:05.840]  который указан на слайде он говорит сам до себя то есть если у нас можно представить что есть у нас
[01:13:05.840 --> 01:13:14.080]  есть узкий коридор в котором может пройти только один человек и два человека с двух его концов
[01:13:14.080 --> 01:13:24.280]  стартуют начинает идти друг напротив друга и они останавливаются в середине и они такие
[01:13:24.280 --> 01:13:31.600]  вежливые люди они просто разворачиваются и идут до начала надежды что кто-то другой пройдет
[01:13:31.600 --> 01:13:35.960]  быстрее. Если они будут двигаться с одинаковой скоростью постоянно то они так и будут ходить
[01:13:35.960 --> 01:13:45.240]  туда-сюда бесконечно и вот такую ситуацию в программе ее отловить уже значительно сложнее
[01:13:45.240 --> 01:13:58.200]  да то есть там в отлачке это так просто не видно это вот нужно именно прям сидеть вникать
[01:13:58.200 --> 01:14:21.240]  в работу чуть не пошагового в уме все это дело исполнять. Такое происходит когда есть какая-то
[01:14:21.240 --> 01:14:30.160]  зависимость циклическая между ресурсами но она не одноуровневая а там значительно
[01:14:30.160 --> 01:14:40.720]  значительно сложнее то есть того чтобы ну какой-то такой пример наверное трудно составить потому что
[01:14:40.720 --> 01:14:50.720]  как правило такие ситуации вот по крайней мере то с чем я сталкивался возникают когда мы
[01:14:50.720 --> 01:14:57.760]  забыли вот часть какую-то зависимость неявную когда писали код забыли что вот он там вызывает
[01:14:57.760 --> 01:15:02.360]  какую-нибудь функцию она там внутри через 10 функций захватывает какой-нибудь вот такой ресурс
[01:15:02.360 --> 01:15:09.240]  а мы об этом не подумали и сами тоже сами тоже пытаемся что-то с этим ресурсом сделать
[01:15:09.240 --> 01:15:30.200]  нет в отлачке обычно видно просто что процесс просто в цикле исполняется все время бесконечно
[01:15:30.200 --> 01:15:41.360]  видно в таком смысле то есть ну как правило как правило видно что вот процесс просто висит
[01:15:41.360 --> 01:15:52.600]  жжет достаточно большое жжет процессор и вот обычно вот этот факт виден в отлачке
[01:15:52.600 --> 01:16:05.720]  так ну на сегодня это все вот тут есть парочка ссылок первые это вот как раз про модель памяти
[01:16:05.720 --> 01:16:16.360]  язык оси но я говорю мы собираемся к этому вернуться я надеюсь в конце там после после
[01:16:16.360 --> 01:16:25.640]  всех лекций по лабораторкам будет еще вот одна поро модели памяти и несколько примеров
[01:16:25.640 --> 01:16:35.600]  уязвимости и атак на них так ну все
