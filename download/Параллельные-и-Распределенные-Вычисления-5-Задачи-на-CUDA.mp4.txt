[00:00.000 --> 00:10.260]  Всем доброго вечера! Мы наконец-таки с вами запустились спустя 15 минут после начала пары,
[00:10.260 --> 00:16.120]  поэтому давайте продолжим изучение АКУДА, и сегодня мы с вами будем говорить про две
[00:16.120 --> 00:20.960]  темы. Первая тема — это сумма чисел массива, мы с вами посчитаем, а вторая задача, которую мы
[00:20.960 --> 00:26.800]  сегодня с вами разберем, — это сумма на префиксе. Задачи интересные, задачи тяжелые. Более того,
[00:26.800 --> 00:35.000]  я скажу, что если их правильно решать, а не теми алгоритмами, которые использовались до определенного
[00:35.000 --> 00:42.200]  момента, можно получить очень сильный импакт, профит в вырешении данных задач. Мы сегодня будем
[00:42.200 --> 00:47.440]  разбирать эти две задачи независимо друг от друга, но в целом, я думаю, мы с вами их успешно разберем.
[00:47.440 --> 00:55.720]  Значит, что мы с вами уже умеем делать? Мы умеем складывать с вами массивы. Согласны? То есть с этим
[00:55.720 --> 01:03.280]  вообще никаких проблем нет. Но в чем проблема будет заключаться задачи подсчета суммы чисел массива?
[01:03.280 --> 01:12.400]  Во-первых, ломается кэш. Во-вторых, это массивное взаимодействие между всеми элементами массива.
[01:12.400 --> 01:19.600]  Вы прекрасно понимаете, что нам нужно делать огромное количество взаимодействия между соседними
[01:19.600 --> 01:27.360]  элементами, потому что нам необходимо сложить все элементы в массивы. Вот, и, значит, ну, собственно,
[01:27.360 --> 01:32.880]  нам надо понять, как решать эту задачу. Значит, в чем заключаются задачи редакшн? Представьте себе,
[01:32.880 --> 01:42.600]  что у нас есть задача массива А, и есть некоторая коммутативно-ассоциативная операция типа плюс с
[01:42.600 --> 01:52.200]  нейтральным элементом. Вот, и нам необходимо посчитать значение всех элементов, значение операции,
[01:52.200 --> 01:56.600]  применимо ко всем элементам нашего массива. В данном случае мы будем считать сумму чисел массива.
[01:56.600 --> 02:04.080]  Значит, давайте разберем классическое решение. Классическое решение это у нас есть n операции
[02:04.080 --> 02:09.120]  сложения и один поток. Да, кажется, ничего сложного в этом нет.
[02:09.120 --> 02:17.960]  Кориком пробежались. Как бы мы решали задачу, если бы у нас был бы MPI?
[02:21.960 --> 02:26.680]  Да, смотрите, мы бы разделили наш элемент массива на отрезки и запустили бы
[02:26.680 --> 02:33.280]  вычисления элементов на отрез. То есть у нас получается, наберем наш массив,
[02:33.280 --> 02:45.840]  ой, черным по черному, наберем наш массив и его раз, два, три, четыре, на ц кусков бьем.
[02:45.840 --> 02:55.080]  В каждом куске складываем элементы, потом складываем все элементы между собой. Спрашиваются,
[02:55.080 --> 03:00.000]  мы получаем асимптотику n делить на ц плюс ц.
[03:06.000 --> 03:12.960]  То есть мы каждый из элементов вычисляем параллельно, плюс еще ц раз вычисляем последовательно.
[03:12.960 --> 03:24.200]  Ну, может быть, там еще каким-то образом. Вопрос, который хочется задать. В куде будет ц равно 4352?
[03:24.200 --> 03:31.480]  Или есть какой-то другой подвох, который нам надо будет решать?
[03:37.160 --> 03:44.800]  А, это количество кудоядер в RTX 2080i, который у нас стоит на кластере. Вряд ли. Почему?
[03:44.800 --> 03:53.560]  Да, смотрите, здесь у нас будет огромное количество элементов взаимодействия. То есть здесь у нас
[03:53.560 --> 04:04.360]  с вами как разбиты элементы между собой. Каждый кусок, как считается, параллельно или последовательно
[04:04.360 --> 04:09.480]  элементы считают? Последовательно, да. Помните, мы в прошлый раз с вами говорили про проблему кэш-линий,
[04:09.480 --> 04:18.240]  что на видеокарте так считать нельзя. Да, мы, кстати, по-моему, на семинарах с нашей группы сделали
[04:18.240 --> 04:24.440]  сложение по 8 элементов массива. Замедление было в 4 раза. По 16 элементов начали складывать последовательно.
[04:24.440 --> 04:32.640]  У нас, по-моему, замедление получилось в 16 раз. Нет, чем просто нормальным лаяутом это все сделать?
[04:32.640 --> 04:41.040]  Здесь не нормальный лаяут. Какой у нас нормальный лаяут в элементах мы должны соблюдать? Мы должны
[04:41.040 --> 04:52.560]  складывать элементы в диапазоне с чем? Размер блока. И давайте попробуем сделать вот такую первую
[04:52.560 --> 05:06.480]  идею нашего решения и обсудить ее. Значит, у нас с вами будет с потоков. С потоков. И каждый поток
[05:06.480 --> 05:21.760]  возьмет свои собственные элементы. 0, c, 2, c, 1, c минус 1, 2, ой, c плюс 1, 2, c плюс 1, 3, c плюс 1 и
[05:21.760 --> 05:26.520]  так далее. Ну и остальные элементы будут складывать между собой. И параллельно мы будем складывать
[05:26.520 --> 05:39.800]  элементы вот здесь. В итоге у нас получится выходной массив размера c, в котором мы получим
[05:39.800 --> 05:54.400]  результат. То есть здесь одна сумма, сумма 0, здесь сумма 1, здесь сумма 2. Кажется, складывать элементы
[05:54.400 --> 05:58.120]  будем с вами последовательно. В чем проблема?
[05:58.120 --> 06:26.320]  Ну да, здесь есть еще одна проблема. Не знаю, увидите вы или нет. А вы знаете c для каждой
[06:26.320 --> 06:38.360]  видеокарты? Нет, c неизвестно для каждой видеокарты. И в каких-то видеокартах у нас c имеет, значит,
[06:38.360 --> 06:48.720]  кратно 64 в каких-то видеокартах, да, кратно 128. Потому что здесь у нас используется 4 варпшедуллера на 1 см,
[06:48.720 --> 07:03.440]  а здесь у нас используется 2 варпшедуллера на 1 стриминг мультипроцессор. И ладно, вы подгадаете
[07:03.440 --> 07:08.320]  даже константу c, но при этом вам нужно будет дергать код на видеокарте, чтобы узнавать эту
[07:08.320 --> 07:16.080]  константу c. Это неудобно. Раз. А второе, что вам нужно будет подбирать, даже если вы подбираете
[07:16.080 --> 07:24.440]  элементы не c, а чуть больше, чтобы выглядеть код грамотно видеокарте, то вы по факту сделаете
[07:24.440 --> 07:40.560]  следующее. Вы сделаете паддинг даже до размера блока. И тут математика процесса сильно усложняется,
[07:40.560 --> 07:46.640]  потому что невозможно правильно посчитать, сколько вам этих строчек алоцировать. То есть,
[07:46.640 --> 07:53.240]  если у вас 68 стриминг мультипроцессоров по 64 элемента, все равно, скорее всего,
[07:53.240 --> 08:02.520]  вам придется добивать это до размера блока порядка 256. То есть, получается 256 на 68 ячеек
[08:02.520 --> 08:08.760]  массива вы должны обрабатывать параллельно. То есть, физическая абстракция, это, казалось,
[08:08.760 --> 08:13.520]  выглядит хорошо, но когда мы переходим в логическую абстракцию, размер блока оптимальный должен
[08:13.520 --> 08:21.920]  быть как можно больше, поэтому здесь уже получается в параллель у вас получается массив не из 64 на 68
[08:21.920 --> 08:30.000]  элементов, а уже 256 на 68 элементов. Чтобы это логически выглядело в коде видеокарте.
[08:30.000 --> 08:39.200]  Ну вот, а симптотика-то, кажется, хорошая, но и, в принципе, так можно делать. И первое как раз
[08:39.200 --> 08:44.360]  одно из заданий, это будет как раз посчитать сумму чисел вот таким образом. То есть, вы берете,
[08:44.360 --> 08:51.680]  говорите, что считаете до размеров блока, а потом их агрегируете. Вот здесь используете
[08:52.280 --> 09:01.400]  сумму. Вот это первый способ, который можно использовать, но он может выстреливать в ногу,
[09:01.400 --> 09:11.360]  и он является неэффективным. Вот это понятно. Что, вопрос какой-то?
[09:11.360 --> 09:20.840]  Вот. То есть, агрегируем по элементам, потом складываем все элементы между собой. Поэтому давайте
[09:20.840 --> 09:26.440]  мы немножечко отойдем от этой задачи и решим другую задачу. Мы можем, второй способ,
[09:26.440 --> 09:34.360]  которым мы можем с вами решить задачу, это параллелизация этого процесса. Давайте я расскажу
[09:34.360 --> 09:40.280]  его тоже на слайде. Значит, смотрите, что вы делаете. Вы бьете массив на набор блоков.
[09:40.800 --> 10:08.040]  В каждом блоке считаете сумму. После этого вы считаете сумму сумм блоков. После этого считаете
[10:08.040 --> 10:25.320]  сумму сумм блоков. И повторяете это до победного. Ну да, то есть, смотрите, здесь у нас размер
[10:25.320 --> 10:31.560]  массива N, здесь у нас размер массива N делить на блок size, здесь у нас получается размер массива N
[10:31.560 --> 10:47.120]  делить на блок size в квадрате и так далее. Вот относительно этого, оно отличается тем, что,
[10:47.120 --> 10:52.480]  во-первых, порядок вычисления элементов другой. Во-вторых, для того, чтобы layout аккуратно работал,
[10:52.480 --> 11:00.560]  C должен быть кратным размером блока, иначе это работать не будет. И для этого нужно как раз
[11:00.560 --> 11:12.160]  сделать padding. То есть, мы берем не C, а берем по факту, так сказать, здесь вот SM размер на блок size.
[11:12.160 --> 11:24.680]  Да? Каждый столбец. Да.
[11:33.240 --> 11:34.080]  Вот там и суть.
[11:34.080 --> 11:50.680]  В смысле? А потому что, я не знаю, но в семинарах рассматривали этот пример, что когда вы берете и
[11:50.680 --> 11:58.240]  одному потоку, закидываете несколько последних элементов подряд для сложения, то второму несколько
[11:58.240 --> 12:05.240]  подряд, третьему несколько подряд и так далее. У вас скорость программы уменьшается в количество раз,
[12:05.240 --> 12:11.360]  пропорциональное тому, сколько элементов вы закинули. То есть, вы считаете по четыре элемента подряд,
[12:11.360 --> 12:15.880]  у вас время программы замедляется в два раза. Восемь подряд начинаете складывать, у вас время,
[12:15.880 --> 12:22.680]  по сравнению с этим layout уменьшается в восемь, в четыре раза. В шестнадцать последних у вас размер
[12:22.680 --> 12:43.920]  программы уменьшается в 16 раз, замедляется. Кошли не ломаются. Наоборот, если мы считаем последним,
[12:43.920 --> 12:58.880]  то у нас кошли не ломаются. Не-не-не, смотрите, еще раз. У нас есть элементы от нуля до 32. Мы говорим
[12:58.880 --> 13:11.640]  следующее, что если нулевой элемент взял нулевой поток, то шестнадцатый поток получит шестнадцатый
[13:11.640 --> 13:30.800]  элемент. Двадцать восьмой поток получит двадцать восьмой элемент и так далее. Не, ну вот так. То есть,
[13:30.800 --> 13:37.320]  это оптимально. Если мы берем последовательно, то у нас происходит боль, потому что у нас с вами
[13:37.320 --> 13:44.320]  есть нулевой элемент, первый, второй. И вот у нас нулевой поток начинает складывать. У него идет
[13:44.320 --> 13:49.840]  сначала сложение с нулевым, потом с первым, потом со вторым, потом с третьим и так далее. У нас
[13:49.840 --> 13:59.280]  получается, что нулевой поток берет значение у первого элемента массива, в то время, как у первого
[13:59.280 --> 14:07.960]  потока, он должен взять элемент под номером, получается пятый. И в итоге нулевой элемент берет
[14:07.960 --> 14:13.360]  первый, первый берет пятый, а первый, по идее, с учетом того, как у нас кашление выстроено,
[14:13.360 --> 14:37.520]  должна взять второй элемент массива. Кашление ломается. Да, да, он пошел в другую линию и у него
[14:37.720 --> 14:53.560]  да, да, да. Что? Значит, мы говорим, что давайте разобьем нашу матрицу на количество элементов
[14:53.560 --> 14:59.560]  массива, на вот такое количество элементов. То есть, количество стримов мультипроцессоров на
[14:59.560 --> 15:08.080]  размер нашего блока. И тогда говорим следующее, что давайте это назовем P. Тогда мы вот сюда,
[15:08.080 --> 15:15.000]  по первой строке, располагаем. Каждый поток будет нумеровать вот эти все элементы. То есть, у нас
[15:15.000 --> 15:20.400]  получается нулевой поток берет нулевой элемент, первый, первый и так далее, до P-1. Потоки именно,
[15:20.560 --> 15:27.920]  некуда ядро. Потом следующие возьмет элементы с P, P плюс один, P плюс два, и так далее. Потом
[15:27.920 --> 15:33.020]  два P, два P плюс один, и так далее. То есть, у нас получается нулевой поток будет складывать
[15:33.020 --> 15:38.200]  элементы 0, P, два P и так далее, первый поток будет складывать элементы один P плюс один, два P плюс один,
[15:38.200 --> 15:43.640]  три P плюс один и так далее. Четвертый параллельно, параллельно- параллельно, то есть они
[15:43.640 --> 15:49.040]  вот будут идти параллельно сверху-вниз и складывать строки. Точнее, складывать себя, столбцы,
[15:49.040 --> 15:54.440]  склапывать. Вот это один способ. Второй из способов — это
[15:54.440 --> 15:57.800]  площное перемножение, точнее, площное сложение элементов.
[15:57.800 --> 16:05.560]  Есть еще третий способ, и, кстати, как ни странно,
[16:05.560 --> 16:14.360]  он работает очень быстро. Вы не поверите, как он выглядит.
[16:14.360 --> 16:23.440]  Еще один способ есть. Вы не поверите. Офигенный способ.
[16:23.440 --> 16:37.320]  Вы вычисляете тит, и дальше пишется следующее, особенно
[16:37.320 --> 16:40.560]  когда вы считаете сумму чисел в блоке. И дальше вы пишете
[16:40.560 --> 16:55.240]  следующее, и птит меньше, чем n, аут блок idxx. Так, стоп.
[16:55.240 --> 17:03.080]  А? Не-не-не, мы хотим выходным массивом аут иметь сумму
[17:03.080 --> 17:06.880]  чисел в блоке, образно говоря. Вы говорите следующее.
[17:06.880 --> 17:11.160]  Да, вообще можно даже проще написать. Вы пишете просто
[17:11.160 --> 17:17.920]  так. Вы выделяете какой-нибудь массив аут и пишете следующее.
[17:36.880 --> 17:43.000]  Можете, кстати, замерить по бычмаркам. Мы просто начали
[17:43.000 --> 17:50.640]  сгружать все в один элемент. Вот, оказывается, что если
[17:50.640 --> 17:54.480]  у вас есть элемент для каждого блока отдельно, вот здесь
[17:54.480 --> 17:59.500]  вот, то есть у вас аут от блока idxx, то это будет работать
[17:59.500 --> 18:02.000]  намного быстрее, чем все первые реализации, которые
[18:02.000 --> 18:08.960]  мы с вами сегодня посмотрим. TIT – это номер потока внутри
[18:08.960 --> 18:17.080]  в нашей сетке. N – это количество элементов в вашей массиве.
[18:17.080 --> 18:20.560]  Atomic Ed – это атомарная операция сложения элементов, объявления
[18:20.560 --> 18:29.480]  элементов. А? Ну нет, не один. То есть каждый поток
[18:29.560 --> 18:34.200]  у нас в видеокарте – это отдельная сущность. Правда,
[18:34.200 --> 18:37.680]  один поток, одно куда ядро может выполнять несколько
[18:37.680 --> 18:46.680]  поток. Так, сейчас зарядник подключу. Вот, и мы с вами
[18:46.680 --> 18:50.640]  сейчас будем решать интересную задачу, а именно считать
[18:50.640 --> 19:03.320]  сумму чисел внутри блока. Чего? Скип. А это означает,
[19:03.320 --> 19:06.560]  что мы выделили, что размер массива наш не делится
[19:06.560 --> 19:10.680]  на размер блока. То есть у нас в массиве допустим
[19:10.680 --> 19:16.120]  258 элементов, а всего мы выделили 512 потоков. То есть у нас
[19:16.120 --> 19:22.440]  получается потоки с 259 под 512 просто ничего не делают.
[19:22.440 --> 19:24.040]  Потому что если они начнут что-то делать, у них будет
[19:24.040 --> 19:29.000]  undefined behavior. В хорошем случае и секвел в плохом случае.
[19:29.000 --> 19:42.960]  Ну тогда мы регламентируем количество блока. Приношу
[19:42.960 --> 19:47.280]  извини, зарядник. То есть у нас 2000 элементов в массиве,
[19:47.280 --> 19:55.400]  тогда мы говорим следующее. 2000 элементов. Не, количество
[19:55.400 --> 20:00.760]  потоков мы сами выделяем. Мы можем сказать, что размер
[20:00.760 --> 20:12.880]  блока 512. Тогда сколько блоков нам надо выделить? 4000
[20:12.880 --> 20:22.800]  или 4000. Тогда у нас trade ID, вот этот тит может принимать
[20:22.800 --> 20:28.160]  значение элементов от 0 до 2047. То есть это мы сами
[20:28.160 --> 20:42.600]  задаем. Входим. Там есть максимальный размер. 2х32 хватит? 2х31.
[20:42.600 --> 20:49.560]  Наверное хватит. Про вот этот, что он на самом деле
[20:49.560 --> 20:51.960]  быстрее, чем те способы, которые мы сначала посмотрели.
[20:51.960 --> 20:57.400]  Впрочем, смотря на то, что мы пишем в один элемент.
[20:57.400 --> 21:09.000]  Ну да, просто синхронизация будет выполнена эффективно.
[21:09.000 --> 21:11.960]  Так, решение задачи. Давайте рассмотрим первое решение
[21:11.960 --> 21:15.880]  задачи и мы докажем, что каждый блок можно обработать
[21:15.880 --> 21:21.400]  за время равной логарифму от блок size. У нас будет вот
[21:21.400 --> 21:24.280]  такое вот пирамидальное сложение. Здесь нулевой
[21:24.280 --> 21:27.600]  элемент отвечает за сложение нулевого элемента и первого.
[21:27.600 --> 21:30.760]  Второй за сложение второго и третьего. Четвертый за
[21:30.760 --> 21:39.680]  сложение четвертого и пятого и так далее. И всего у нас
[21:39.760 --> 21:43.560]  таких циклов будет n поделить на блок size. Ой, логарифм
[21:43.560 --> 21:49.360]  от блок size. То есть у нас асимптотика будет с вами в следующее.
[21:49.360 --> 21:56.640]  Вот это вот все. Ох, это получается. Смотрите, за логарифм блок
[21:56.640 --> 22:05.840]  size мы с вами умеем превращать это все из n в n поделить на
[22:05.840 --> 22:12.240]  блок size. То есть уменьшать количество действий вот
[22:12.240 --> 22:19.520]  таким образом. Вот таким вот способом. А количество
[22:19.520 --> 22:26.800]  операций здесь какое? Здесь надо считать на самом деле.
[22:26.800 --> 22:35.040]  Это сложно. Но можно здесь достигнуть n на c, но в общем
[22:35.200 --> 22:38.480]  возникает здесь есть какие-то проблемы. Давайте как раз мы их
[22:38.480 --> 22:42.880]  разберем и возьмем следующую вещь, что положим, что у нас
[22:42.880 --> 22:48.560]  размер 32 бита, 32 элемента, это нам сейчас будет важно.
[22:48.560 --> 22:54.560]  Значит, понятно ли вот картинка, так как складываем элемента?
[22:54.560 --> 23:05.040]  Н это общий массив. Нет, в этом массиве блок size
[23:05.040 --> 23:09.680]  элементов. То есть наша задача сейчас ввелась в то, что вместо
[23:09.680 --> 23:12.160]  того, чтобы считать сумму всех чисел в массиве, давайте
[23:12.160 --> 23:16.560]  посчитаем сумму чисел в блоке. Каждый блок мы будем
[23:16.560 --> 23:23.920]  запускать параллельно. Вот. И утверждение, что мы вот
[23:23.920 --> 23:27.200]  эту вот штуку можем посчитать за n делить, за от логарифм
[23:27.200 --> 23:33.200]  блок size и террации. Количество действий, которое мы при этом
[23:33.200 --> 23:37.200]  осуществим, тут считается очень сложно. Ну, не сложно,
[23:37.200 --> 23:41.280]  но не поверьте, оно будет порядка от n по всем элементам
[23:41.280 --> 23:50.480]  массива. Не-не-не, тут фишка в том, что здесь асимптотика
[23:50.560 --> 23:56.560]  будет порядка именно n на логарифм блок size для всего.
[23:56.560 --> 24:01.520]  То есть вам не сильно поможет, что вы это распараллели.
[24:01.520 --> 24:15.520]  То есть эффекта от распараллели почти не будет. А? 512. 2000,
[24:15.600 --> 24:21.600]  да. Ну, можно округлить верхнюю сторону. Да, можно считать,
[24:21.600 --> 24:27.600]  что она 2048. Почему это так? Давайте разберем. Здесь
[24:27.600 --> 24:31.600]  нам нужна как раз операция простаивания варпа. Напомним,
[24:31.600 --> 24:35.600]  что мы выполняем операцию в варпе только в том случае,
[24:35.600 --> 24:39.600]  если в этом варпе есть хотя бы один элемент. Да, один
[24:39.600 --> 24:43.600]  trade ID, который работает внутри этого варпа. А теперь давайте
[24:43.680 --> 24:47.680]  посчитаем, что у нас проходит с варпами. Смотрите,
[24:47.680 --> 24:51.680]  на первом шаге у нас взаимодействуют все варпы, потому
[24:51.680 --> 24:55.680]  что у нас сложение идет по четным индексам. То есть у
[24:55.680 --> 24:57.680]  нас нулевой элемент массива, первый элемент массива,
[24:57.680 --> 24:59.680]  второй, ой, нулевой, второй, четвертый занимается
[24:59.680 --> 25:05.680]  сложением. В итоге у нас 8 варпов всего, и в каждом
[25:05.680 --> 25:11.680]  из них есть четный элемент. Раз, раз, раз, раз, раз, раз.
[25:11.760 --> 25:15.760]  Раз, раз, раз, раз, раз. То есть у нас все варпы задействованы.
[25:17.760 --> 25:21.760]  Но при этом сколько у нас по факту элементов складывается?
[25:23.760 --> 25:27.760]  Только половина. У нас складывается только половина
[25:27.760 --> 25:31.760]  элементов, хотя несмотря на это мы простаиваем все варпы.
[25:31.760 --> 25:33.760]  То есть у нас уже этим точку увеличивается два раза
[25:33.760 --> 25:37.760]  от оптимальной. Повторяем дальше. Теперь складывается
[25:37.840 --> 25:41.840]  каждый четвертый элемент, и все равно количество варпов
[25:41.840 --> 25:47.840]  у нас восемь. Еще раз, восемь, еще раз, восемь, восемь,
[25:47.840 --> 25:57.840]  дальше сколько будет? Четыре, да, и один. Всего у
[25:57.840 --> 26:03.840]  нас, смотрите, на сложение 256 элементов было дернуто
[26:03.920 --> 26:11.920]  47 варпов. Оптимально? Нет, не оптимально. Почему?
[26:11.920 --> 26:15.920]  Потому что у нас как минимум здесь у нас простаивало половина,
[26:15.920 --> 26:19.920]  здесь у нас простаивало три четверти, здесь семь восьмых
[26:19.920 --> 26:25.920]  и так далее. Мы практически потеряли все преимущество.
[26:27.920 --> 26:29.920]  Вопрос, как вернуть это преимущество?
[26:33.920 --> 26:35.920]  Да, как?
[26:45.920 --> 26:49.920]  Ну да, смотрите, что у нас получается, что у нас эта
[26:49.920 --> 26:55.920]  структура не сконденсирована, если объяснить. То есть
[26:55.920 --> 26:59.920]  неплохо было бы, чтобы каждый варп, то есть все потоки
[27:00.000 --> 27:06.000]  внутри одного варпа вычисляли сумму. То есть у нас получается
[27:06.000 --> 27:10.000]  следующее, что у нас нулевой элемент складывал сумму
[27:10.000 --> 27:14.000]  двух, дальше второй элемент массива складывал сумму
[27:14.000 --> 27:18.000]  вот этих двух, четвертый элемент массива складывал
[27:18.000 --> 27:24.000]  вот эти два и так далее. Вопрос, вот эту вот сумму
[27:24.000 --> 27:26.000]  какой элемент мог начать складывать?
[27:30.000 --> 27:34.000]  А вот эту сумму какой элемент мог начать складывать?
[27:34.000 --> 27:38.000]  Второй. Так, берем, вот эту всю гармошку сжимаем.
[27:43.000 --> 27:46.000]  Смотрите, что происходит. У нас меняется нумерация
[27:46.000 --> 27:49.000]  поток. То есть теперь нулевой поток складывает первые
[27:49.000 --> 27:53.000]  два элемента, первый, второй, третий, третий, четвертый
[27:53.000 --> 27:57.000]  и так далее. Вопрос, как вернуть это преимущество?
[27:57.080 --> 28:00.080]  Нулевой поток складывает первые два элемента, первый
[28:00.080 --> 28:02.080]  поток складывает дальше элементы, второй поток складывает
[28:02.080 --> 28:04.080]  еще два элемента и так далее.
[28:07.080 --> 28:09.080]  Так, что у нас происходит с количеством операций?
[28:15.080 --> 28:18.080]  Так, смотрите, опять же разбираемся, что с варпами.
[28:18.080 --> 28:20.080]  На первом шаге теперь взаимодействует только четыре
[28:20.080 --> 28:22.080]  варпа, потому что половина потоков у нас просто
[28:22.160 --> 28:26.160]  простаивает. На втором шаге сколько будет?
[28:31.160 --> 28:37.160]  Два. То есть у нас варп с 64 по 96 поток отключается.
[28:39.160 --> 28:40.160]  Дальше сколько?
[28:43.160 --> 28:47.160]  Один. Все, мы находимся в пределах одного варпа.
[28:48.160 --> 28:50.160]  И дальше один, один, один, один, один.
[28:52.160 --> 28:54.160]  Ура!
[28:59.160 --> 29:01.160]  А числа в кружочках?
[29:02.160 --> 29:04.160]  Там числа в кружочках были 0, 2, 4.
[29:05.160 --> 29:07.160]  Здесь числа в кружочках 0, 1, 2.
[29:08.160 --> 29:11.160]  Так что у нас вплюснулось все внутри одного потока
[29:11.160 --> 29:13.160]  и кажется все замечательно.
[29:17.160 --> 29:19.160]  Количество варпов, которые используется.
[29:19.160 --> 29:20.160]  Что такое варп?
[29:20.240 --> 29:22.240]  Это по соответственности 32 потоков.
[29:25.240 --> 29:27.240]  Говорим, что у нас варп работает,
[29:27.240 --> 29:29.240]  если хотя бы один поток внутри варпа
[29:29.240 --> 29:31.240]  задействуется при вычислении.
[29:33.240 --> 29:35.240]  Вот. Значит, смотрите, какие четыре варпа
[29:35.240 --> 29:37.240]  задействуются в первом шаге.
[29:37.240 --> 29:39.240]  Первый варп, это от 0 до 31.
[29:39.240 --> 29:42.240]  Второй от 32 до 63.
[29:42.240 --> 29:47.240]  Третий от 64 до 96.
[29:47.320 --> 29:50.320]  То есть первый варп 0, 31.
[29:50.320 --> 29:52.320]  Потом 32, 63.
[29:52.320 --> 29:56.320]  54, 95.
[29:56.320 --> 29:58.320]  И 96, 127.
[29:58.320 --> 30:00.320]  Все, четыре варпа.
[30:03.320 --> 30:05.320]  Не, блок-сайз 256 у нас.
[30:07.320 --> 30:09.320]  Это количество элементов,
[30:09.320 --> 30:11.320]  которые задействуют первые ячейки при сложении.
[30:13.320 --> 30:15.320]  Да, мы каждый второй складываем.
[30:17.320 --> 30:19.320]  Да, то есть мы 128 потоков сгруппировали вместе.
[30:19.320 --> 30:21.320]  Это четыре варпа.
[30:25.320 --> 30:27.320]  Да, да.
[30:27.320 --> 30:29.320]  Но главное, чтобы они были расположены последовательно.
[30:29.320 --> 30:31.320]  Потому что если они не расположены последовательно,
[30:31.320 --> 30:33.320]  то у нас получается такое решето.
[30:33.320 --> 30:35.320]  Где половина варпов работает только.
[30:37.320 --> 30:39.320]  И вот.
[30:39.320 --> 30:41.320]  И вот.
[30:41.320 --> 30:43.320]  И вот.
[30:43.320 --> 30:45.320]  И вот.
[30:45.400 --> 30:47.400]  И вот.
[30:51.400 --> 30:53.400]  Да ладно, меньшее количество варпов задействуется
[30:53.400 --> 30:55.400]  для вычисления операций.
[30:55.400 --> 30:57.400]  То есть наоборот, хорошо.
[31:01.400 --> 31:03.400]  Меньше тактов процессора будут.
[31:03.400 --> 31:05.400]  То есть мы утверждаем, что нам нужно
[31:05.400 --> 31:07.400]  задействовать 12 варпов
[31:07.400 --> 31:09.400]  для того, чтобы посчитать сумму
[31:09.400 --> 31:11.400]  всех чисел в блоке.
[31:11.400 --> 31:13.400]  Там было 48 варп-операций.
[31:13.480 --> 31:15.480]  Четыре раза лучше стало.
[31:19.480 --> 31:21.480]  Это никто не гарантирует.
[31:21.480 --> 31:23.480]  Внутри одного потока, скорее всего, даже нет.
[31:25.480 --> 31:27.480]  Понятно?
[31:31.480 --> 31:33.480]  Ну, математика просто.
[31:33.480 --> 31:35.480]  Это был наивный алгоритм.
[31:37.480 --> 31:39.480]  Совсем наивный.
[31:39.480 --> 31:41.480]  Вот такой.
[31:41.560 --> 31:43.560]  Не, на самом деле у этого алгоритма есть одно преимущество,
[31:43.560 --> 31:45.560]  которое мы сломали
[31:45.560 --> 31:47.560]  во второй итерации нашего алгоритма.
[31:49.560 --> 31:51.560]  Давайте узнаем.
[31:51.560 --> 31:53.560]  То есть смотрите.
[31:53.560 --> 31:55.560]  Кажется, что этот алгоритм сильно хуже,
[31:55.560 --> 31:57.560]  но вот этот алгоритм, кажется, что
[31:57.560 --> 31:59.560]  лучше.
[31:59.560 --> 32:01.560]  Да?
[32:01.560 --> 32:03.560]  А теперь смотрите.
[32:03.560 --> 32:05.560]  Ну, это не очень тоже реализация.
[32:05.560 --> 32:07.560]  Смотрите, какой подвох.
[32:07.560 --> 32:09.560]  Рассмотрим.
[32:09.640 --> 32:11.640]  На какой-то, на четвертой стадии,
[32:11.640 --> 32:13.640]  у нас возникнет следующая вещь,
[32:13.640 --> 32:15.640]  что у нас берет нулевой поток,
[32:17.640 --> 32:19.640]  складывает элементы номер ноль и шестнадцать
[32:21.640 --> 32:23.640]  и кладет их в элемент.
[32:23.640 --> 32:25.640]  То есть здесь у нас получается сумма
[32:25.640 --> 32:27.640]  с нулевого по пятнадцатый,
[32:27.640 --> 32:29.640]  здесь у него сумма
[32:29.640 --> 32:31.640]  шестнадцатого по тридцать первый.
[32:31.640 --> 32:33.640]  Тогда первый поток,
[32:33.640 --> 32:35.640]  вы смотрите, складывает,
[32:35.640 --> 32:37.640]  какой элемент.
[32:37.720 --> 32:39.720]  Он возьмет значение элемента
[32:39.720 --> 32:41.720]  из тридцать второго варпа
[32:41.720 --> 32:43.720]  и из сорок восьмого варпа,
[32:43.720 --> 32:45.720]  ой, с сорок восьмого потока.
[32:45.720 --> 32:47.720]  Потому что здесь у нас в вами
[32:47.720 --> 32:49.720]  элементы суммы с тридцать второго по сорок седьмой
[32:49.720 --> 32:51.720]  и с сорок восьмого по шестьдесят третий
[32:51.720 --> 32:53.720]  элементы.
[32:53.720 --> 32:55.720]  Причем, если посмотреть
[32:55.720 --> 32:57.720]  на операцию записи,
[32:57.720 --> 32:59.720]  куда они будут писать,
[32:59.720 --> 33:01.720]  то вот этот вот товарищ
[33:01.720 --> 33:03.720]  будет записывать все,
[33:03.720 --> 33:05.720]  что он будет писать.
[33:05.800 --> 33:07.800]  Вот этот вот товарищ будет записывать
[33:07.800 --> 33:09.800]  все в тридцать второй элемент массива,
[33:09.800 --> 33:11.800]  а вот этот будет записывать
[33:11.800 --> 33:13.800]  все в нулевой элемент массива.
[33:17.800 --> 33:19.800]  А теперь смотрите, в чем особенность.
[33:19.800 --> 33:21.800]  Это особенность заключается в том,
[33:21.800 --> 33:23.800]  что все локальные операции мы осуществляем
[33:23.800 --> 33:25.800]  с разделяемой памятью,
[33:25.800 --> 33:27.800]  которой у нас модификатор shared был.
[33:27.800 --> 33:29.800]  То есть это все происходит
[33:29.800 --> 33:31.800]  на уровне или одного кша.
[33:31.800 --> 33:33.800]  И здесь происходит
[33:33.880 --> 33:35.880]  немножко другой фактор,
[33:35.880 --> 33:37.880]  что у нас два потока,
[33:37.880 --> 33:39.880]  раньше они пытались написать в разные линии
[33:39.880 --> 33:41.880]  и ломали кашлению,
[33:41.880 --> 33:43.880]  а здесь происходит еще хуже,
[33:43.880 --> 33:45.880]  потому что у нас два потока
[33:45.880 --> 33:47.880]  в одном варпе, подчеркну,
[33:47.880 --> 33:49.880]  они пытаются написать
[33:49.880 --> 33:51.880]  один и тот же элемент
[33:51.880 --> 33:53.880]  по модулю 32.
[33:53.880 --> 33:55.880]  То есть в итоге у нас происходит
[33:55.880 --> 33:57.880]  вот такой интересный кейс.
[33:59.880 --> 34:01.880]  Смотрите, у нас
[34:01.960 --> 34:03.960]  нулевой поток
[34:03.960 --> 34:05.960]  пытается записать информацию
[34:05.960 --> 34:07.960]  в кашлению,
[34:07.960 --> 34:09.960]  в нулевой элемент кашлении.
[34:11.960 --> 34:13.960]  Что пытается делать первый поток?
[34:15.960 --> 34:17.960]  Первый поток пишет, типа, кажется,
[34:17.960 --> 34:19.960]  в 32 элемент,
[34:19.960 --> 34:21.960]  но по факту
[34:21.960 --> 34:23.960]  он пишет
[34:23.960 --> 34:25.960]  в нулевой элемент кашлении
[34:25.960 --> 34:27.960]  тоже.
[34:28.040 --> 34:30.040]  Вот это вот понятие,
[34:30.040 --> 34:32.040]  которое у нас здесь возникло,
[34:32.040 --> 34:34.040]  это понятие банк.
[34:34.040 --> 34:36.040]  То есть это по факту источник данных,
[34:36.040 --> 34:38.040]  через который идет запись
[34:38.040 --> 34:40.040]  в разделяемую память.
[34:40.040 --> 34:42.040]  И смотрите, что происходит,
[34:42.040 --> 34:44.040]  у нас вот этот элемент,
[34:44.040 --> 34:46.040]  он начинает писать тот же самый поток,
[34:48.040 --> 34:50.040]  тот же самый банк,
[34:50.040 --> 34:52.040]  то есть ту же самую исходную точку.
[34:54.040 --> 34:56.040]  В итоге у нас получается
[34:56.120 --> 34:58.120]  две операции записи,
[34:58.120 --> 35:00.120]  в одном и том же варпе,
[35:00.120 --> 35:02.120]  записывают в одну и ту же банку.
[35:02.120 --> 35:04.120]  В одном ассемблерном такте.
[35:04.120 --> 35:06.120]  Ну, ассемблерная операция.
[35:10.120 --> 35:12.120]  32, но
[35:12.120 --> 35:14.120]  это особенность видеокарты,
[35:14.120 --> 35:16.120]  что когда мы пишем в разделяемую память,
[35:16.120 --> 35:18.120]  мы пишем на самом деле не
[35:18.120 --> 35:20.120]  в элементы отдельности по массиву,
[35:20.120 --> 35:22.120]  а мы делаем это через такую абстракцию
[35:22.120 --> 35:24.120]  под названием банк.
[35:24.200 --> 35:26.200]  То есть они записываются
[35:26.200 --> 35:28.200]  через кэш-линию.
[35:28.200 --> 35:30.200]  А в кэш-линии у нас
[35:30.200 --> 35:32.200]  наполнено 32 элемента.
[35:40.200 --> 35:42.200]  Да, по итогу будет записываться 32,
[35:42.200 --> 35:44.200]  но по факту это идет...
[35:44.200 --> 35:46.200]  Давайте я немножко перерисую картинку,
[35:46.200 --> 35:48.200]  чтобы было понятно.
[35:48.200 --> 35:50.200]  Значит, смотрите, вот у нас
[35:50.200 --> 35:52.200]  нулевой элемент массива, вот у нас
[35:52.280 --> 35:54.280]  они оба друг другу пишут, значит,
[35:54.280 --> 35:56.280]  здесь они пишут нулевой элемент массива,
[35:56.280 --> 35:58.280]  а здесь они пишут 32 элемента.
[35:58.280 --> 36:00.280]  Кажется, все честно.
[36:00.280 --> 36:02.280]  Но, поскольку мы работаем
[36:02.280 --> 36:04.280]  с вами в выразделяемой памяти,
[36:04.280 --> 36:06.280]  то здесь у нас возникает вот такая вот страшная
[36:06.280 --> 36:08.280]  красная штука, называется банка.
[36:10.280 --> 36:12.280]  И запись происходит через банк.
[36:12.280 --> 36:14.280]  Внутри одного варпа,
[36:14.280 --> 36:16.280]  почеркну.
[36:16.280 --> 36:18.280]  Значит, что у нас происходит? У нас нулевой элемент
[36:18.280 --> 36:20.280]  собирается записать вот сюда, в нулевой элемент.
[36:20.360 --> 36:22.360]  В банке 32 элемента.
[36:22.360 --> 36:24.360]  И записывает это сюда просто.
[36:24.360 --> 36:26.360]  Что же делает первый элемент?
[36:26.360 --> 36:28.360]  Первый элемент тоже должен записать именно
[36:28.360 --> 36:30.360]  через вот эту вот абстракцию.
[36:32.360 --> 36:34.360]  Он идет вот сюда
[36:34.360 --> 36:36.360]  и записывает
[36:36.360 --> 36:38.360]  это в 32 элемент.
[36:38.360 --> 36:40.360]  Ручка полетела.
[36:44.360 --> 36:46.360]  То есть у нас два потока
[36:46.360 --> 36:48.360]  в одной ассеблерной инструкции
[36:50.360 --> 36:52.360]  проходят через один и тот же
[36:52.360 --> 36:54.360]  ну и точку синхронизации.
[36:54.360 --> 36:56.360]  По факту можно сказать, что это Mutex
[36:56.360 --> 36:58.360]  на запись.
[36:58.360 --> 37:00.360]  Я знакомый с понятием Mutex.
[37:02.360 --> 37:04.360]  Это блокировка.
[37:04.360 --> 37:06.360]  То есть по факту в этот элемент
[37:06.360 --> 37:08.360]  может зайти только один элемент
[37:08.360 --> 37:10.360]  из варпа.
[37:10.440 --> 37:12.440]  Но такого не случилось.
[37:12.440 --> 37:14.440]  Хотя там тоже есть такое.
[37:14.440 --> 37:16.440]  Там, например, если мы берем
[37:16.440 --> 37:18.440]  да, то есть смотрите,
[37:18.440 --> 37:20.440]  если у нас идет нулевой элемент
[37:20.440 --> 37:22.440]  и 16, то история
[37:22.440 --> 37:24.440]  ровно повторяется.
[37:26.440 --> 37:28.440]  Потому что они опять же будут писать
[37:28.440 --> 37:30.440]  в нулевую банку. Нулевой будет писать сюда
[37:30.440 --> 37:32.440]  и вот здесь.
[37:32.440 --> 37:34.440]  И вот здесь.
[37:34.440 --> 37:36.440]  И вот здесь.
[37:36.440 --> 37:38.440]  И вот здесь.
[37:38.520 --> 37:40.520]  Нулевой банку. Нулевой будет писать сюда.
[37:40.520 --> 37:42.520]  Нулевой.
[37:42.520 --> 37:44.520]  А 16 тоже обратится вот сюда
[37:44.520 --> 37:46.520]  и будет писать 32 элемент массива.
[37:52.520 --> 37:54.520]  Не-не-не. У нас, смотрите, операция
[37:54.520 --> 37:56.520]  как происходит.
[37:56.520 --> 37:58.520]  У нас, типа, говорится, что
[37:58.520 --> 38:00.520]  значит, что делает
[38:00.520 --> 38:02.520]  нулевой поток. Он берет, считает
[38:02.520 --> 38:04.520]  0 плюс 1 и записывает нулевой поток.
[38:04.520 --> 38:06.520]  16 поток считает
[38:06.600 --> 38:08.600]  32 и 33 элемента
[38:08.600 --> 38:10.600]  и записывает результат 32 поток.
[38:10.600 --> 38:12.600]  Это если мы берем два последних
[38:12.600 --> 38:14.600]  элемента, складываем.
[38:16.600 --> 38:18.600]  Та же самая проблема.
[38:20.600 --> 38:22.600]  То есть по факту у нас половине случаев
[38:22.600 --> 38:24.600]  наш параллельный доступ
[38:24.600 --> 38:26.600]  превращается в последованный.
[38:28.600 --> 38:30.600]  Несмотря на то, что даже этот способ будет быстрее,
[38:30.600 --> 38:32.600]  чем предыдущий.
[38:32.680 --> 38:34.680]  А?
[38:36.680 --> 38:38.680]  А почему здесь фигура числа 32?
[38:38.680 --> 38:40.680]  Потому что так устроено кашление
[38:40.680 --> 38:42.680]  на видеокарте. Размер кашления равен
[38:42.680 --> 38:44.680]  размер варпа.
[38:44.680 --> 38:46.680]  Для эффективной записи.
[38:48.680 --> 38:50.680]  А?
[38:54.680 --> 38:56.680]  Да. Ну, пока они придумали
[38:56.680 --> 38:58.680]  видеокарту, где размер варпа 64
[38:58.680 --> 39:00.680]  элемента.
[39:00.760 --> 39:02.760]  Вот.
[39:02.760 --> 39:04.760]  В итоге у нас возникает каш...
[39:04.760 --> 39:06.760]  так называем
[39:06.760 --> 39:08.760]  банконфликт, извините.
[39:08.760 --> 39:10.760]  Это поведение, мы разделяем
[39:10.760 --> 39:12.760]  память, когда два потока внутри одного варпа
[39:12.760 --> 39:14.760]  записывают данные внутри разных кашлений
[39:14.760 --> 39:16.760]  по одному индоксу.
[39:16.760 --> 39:18.760]  Вот. Я как раз нарисовал картинку,
[39:18.760 --> 39:20.760]  как это выглядит.
[39:20.760 --> 39:22.760]  Цель программистов на видеокарте
[39:22.760 --> 39:24.760]  разрешить как можно больше банконфликтов.
[39:24.760 --> 39:26.760]  То есть написать алгоритм,
[39:26.760 --> 39:28.760]  который не зависит от банконфликтов.
[39:30.760 --> 39:32.760]  Далеко не для всех алгоритмов это возможно.
[39:34.760 --> 39:36.760]  Вот.
[39:36.760 --> 39:38.760]  Собственно, вот он конфликт.
[39:38.760 --> 39:40.760]  Как решать?
[39:46.760 --> 39:48.760]  Да. Ну, вот смотрите.
[39:48.760 --> 39:50.760]  Мы хотим, чтобы с вами...
[39:50.760 --> 39:52.760]  Давайте немножко подумаем. Мы хотим, чтобы
[39:52.760 --> 39:54.760]  у нас с вами два элемента вычисляли
[39:54.760 --> 39:56.760]  т.е. у нас
[39:56.760 --> 39:58.760]  с вами
[39:58.840 --> 40:00.840]  нулевой подход. Вот.
[40:00.840 --> 40:02.840]  Представим себе, что вот у нас с вами есть
[40:02.840 --> 40:04.840]  секунду.
[40:04.840 --> 40:06.840]  Вот у нас есть с вами
[40:06.840 --> 40:08.840]  массив из 256 элементов.
[40:08.840 --> 40:10.840]  Мы хотим, чтобы
[40:10.840 --> 40:12.840]  на первую операцию считало половину
[40:12.840 --> 40:14.840]  элементов суммы. Первая половина.
[40:28.840 --> 40:30.840]  Вопрос. Как реализовать операцию
[40:30.840 --> 40:32.840]  сложения, чтобы это работало?
[40:36.840 --> 40:38.840]  Чтобы нулевой элемент занимался сложением,
[40:38.840 --> 40:40.840]  при этом
[40:40.840 --> 40:42.840]  по факту он записал в себе
[40:42.840 --> 40:44.840]  сумму именно нулевого элемента.
[40:44.840 --> 40:46.840]  Смотрите, фишка.
[40:46.840 --> 40:48.840]  Давайте считать, что
[40:48.840 --> 40:50.840]  каждый поток будет складывать
[40:50.840 --> 40:52.840]  в себе свой собственный элемент.
[40:52.840 --> 40:54.840]  Тогда какой второй элемент он будет
[40:54.840 --> 40:56.840]  складывать?
[40:56.920 --> 40:58.920]  Да.
[41:00.920 --> 41:02.920]  Раз.
[41:02.920 --> 41:04.920]  Два.
[41:04.920 --> 41:06.920]  Минус один.
[41:08.920 --> 41:10.920]  И вот это уже будет
[41:10.920 --> 41:12.920]  эффективной реализацией.
[41:14.920 --> 41:16.920]  То есть мы массив бьем пополам
[41:16.920 --> 41:18.920]  и по факту параллельно складываем.
[41:19.000 --> 41:21.000]  Да.
[41:25.000 --> 41:27.000]  Да, любой.
[41:27.000 --> 41:29.000]  Да.
[41:29.000 --> 41:31.000]  Нет, не будет, потому что каждый элемент
[41:31.000 --> 41:33.000]  в массиве записывает,
[41:33.000 --> 41:35.000]  каждый поток записывает именно свою ячейку.
[41:37.000 --> 41:39.000]  Все чисто.
[41:49.000 --> 41:51.000]  Там ифы ставятся и все.
[41:51.000 --> 41:53.000]  Там ифы ставятся.
[41:53.000 --> 41:55.000]  Ну если не делаем,
[41:55.000 --> 41:57.000]  то не складываем. Вот.
[41:57.000 --> 41:59.000]  Вот такая вот красивая реализация получается.
[42:03.000 --> 42:05.000]  Хорошо.
[42:05.000 --> 42:07.000]  Значит,
[42:07.000 --> 42:09.000]  как решить итоговую задачу здесь?
[42:09.000 --> 42:11.000]  Здесь говорится, что можно посчитать сумму
[42:11.000 --> 42:13.000]  в блоке, посчитать сумму между
[42:13.000 --> 42:15.000]  блоками и повторить
[42:15.000 --> 42:17.000]  пока не останется один блок.
[42:17.080 --> 42:19.080]  Но знаете,
[42:19.080 --> 42:21.080]  что я вам скажу?
[42:21.080 --> 42:23.080]  Этот алгоритм устарел.
[42:23.080 --> 42:25.080]  Вот этот алгоритм устарел.
[42:25.080 --> 42:27.080]  То есть он был,
[42:27.080 --> 42:29.080]  он работал хорошо,
[42:29.080 --> 42:31.080]  но там до десятых годов.
[42:31.080 --> 42:33.080]  Сейчас уже
[42:33.080 --> 42:35.080]  есть такая другая интересная особенность,
[42:35.080 --> 42:37.080]  которая заключается в том,
[42:37.080 --> 42:39.080]  что, а давайте-ка подумаем
[42:39.080 --> 42:41.080]  с вами о том, а что же такое
[42:41.080 --> 42:43.080]  видеокарта?
[42:43.080 --> 42:45.080]  То есть мы с вами уже много раз сказали,
[42:45.160 --> 42:47.160]  что 32 элемента
[42:47.160 --> 42:49.160]  в варпе
[42:49.160 --> 42:51.160]  работают с одной
[42:51.160 --> 42:53.160]  ассемблерной инструкцией.
[42:59.160 --> 43:01.160]  Мы пока что работали
[43:01.160 --> 43:03.160]  с ассемблерными инструкциями
[43:03.160 --> 43:05.160]  такими параллельными,
[43:05.160 --> 43:07.160]  что у нас все потоки
[43:07.160 --> 43:09.160]  внутри варпан вычисляют свой собственный элемент массива.
[43:09.160 --> 43:11.160]  Ну и работают с ним.
[43:11.160 --> 43:13.160]  Но вопрос,
[43:13.240 --> 43:15.240]  можно ли создать инструкции в ассемблере
[43:15.240 --> 43:17.240]  видеокарты такие,
[43:17.240 --> 43:19.240]  что они будут каким-то образом
[43:19.240 --> 43:21.240]  вычислять взаимодействие между собой,
[43:21.240 --> 43:23.240]  между элементами внутри одного варпа.
[43:27.240 --> 43:29.240]  То есть сказать, допустим, возьми,
[43:29.240 --> 43:31.240]  вот ты пятый поток,
[43:31.240 --> 43:33.240]  пожалуйста, сложи его
[43:33.240 --> 43:35.240]  с девятым элементом этого варпа.
[43:35.240 --> 43:37.240]  Ты сложи пятый элемент варпа
[43:37.240 --> 43:39.240]  с девятым элементом варпа.
[43:43.240 --> 43:45.240]  Да!
[43:45.240 --> 43:47.240]  Сейчас мы откроем презентацию с вами.
[43:59.240 --> 44:01.240]  Так, шуфлы, инструкция называется
[44:01.240 --> 44:03.240]  это все дело.
[44:07.240 --> 44:09.240]  Инструкция называется shuffledown.
[44:09.320 --> 44:11.320]  Давайте как раз статью
[44:11.320 --> 44:13.320]  от NVIDIA рассмотрим.
[44:17.320 --> 44:19.320]  Смотрите какая красота.
[44:21.320 --> 44:23.320]  Давайте сделаем следующее.
[44:25.320 --> 44:27.320]  Выполним вот такой вот код.
[44:27.320 --> 44:29.320]  Что такое shuffled XOR?
[44:29.320 --> 44:31.320]  Здесь есть разная операция.
[44:31.320 --> 44:33.320]  Вот смотрите.
[44:33.320 --> 44:35.320]  Вот пример на слайде.
[44:35.400 --> 44:37.400]  То есть у нас есть 8 элементов,
[44:37.400 --> 44:39.400]  считаем, в варпе.
[44:39.400 --> 44:41.400]  И тогда мы можем сказать,
[44:41.400 --> 44:43.400]  пожалуйста, а какие элементы
[44:43.400 --> 44:45.400]  ты хочешь сложить?
[44:45.400 --> 44:47.400]  Что делает функция shuffledown?
[44:47.400 --> 44:49.400]  Она берет
[44:49.400 --> 44:51.400]  индекс потока,
[44:51.400 --> 44:53.400]  который у нас есть
[44:53.400 --> 44:55.400]  и указывает,
[44:55.400 --> 44:57.400]  что, допустим,
[44:57.400 --> 44:59.400]  четвертый поток, который у нас есть в варпе,
[44:59.400 --> 45:01.400]  значение,
[45:01.400 --> 45:03.400]  которое у нас здесь получается,
[45:03.480 --> 45:05.480]  оно должно быть в нулевом элементе.
[45:05.480 --> 45:07.480]  Когда мы запрашиваем shuffledown
[45:07.480 --> 45:09.480]  у нулевого элемента варпа,
[45:09.480 --> 45:11.480]  он возвращает значение,
[45:11.480 --> 45:13.480]  которое находится в четвертом элементе варпа.
[45:13.480 --> 45:15.480]  У первого элемента
[45:15.480 --> 45:17.480]  из пятого.
[45:17.480 --> 45:19.480]  Удает пятый.
[45:19.480 --> 45:21.480]  Да, мы это только что делали,
[45:21.480 --> 45:23.480]  но мы раньше делали это
[45:23.480 --> 45:25.480]  на уровне кода.
[45:25.480 --> 45:27.480]  То есть мы там написали,
[45:27.480 --> 45:29.480]  возьми элемент массива,
[45:29.480 --> 45:31.480]  сделай плюс равно чему-то.
[45:31.560 --> 45:33.560]  А здесь есть особенная инструкция,
[45:33.560 --> 45:35.560]  которая делает это внутри варпа.
[45:37.560 --> 45:39.560]  Классно, да?
[45:39.560 --> 45:41.560]  А теперь магия.
[45:41.560 --> 45:43.560]  И мы повторяем это
[45:43.560 --> 45:45.560]  до тех пор, пока мы находимся
[45:45.560 --> 45:47.560]  внутри одного варпа.
[45:47.560 --> 45:49.560]  Теперь математика процесса,
[45:49.560 --> 45:51.560]  которая заключается в том,
[45:51.560 --> 45:53.560]  что, вы не поверите,
[45:53.560 --> 45:55.560]  максимальный размер блока у нас 1024.
[45:57.560 --> 45:59.560]  MaxBlockSize
[46:01.560 --> 46:03.560]  MaxBlockSize
[46:05.560 --> 46:07.560]  Чем число 1024
[46:07.560 --> 46:09.560]  известно?
[46:09.560 --> 46:11.560]  Это степень двойки какая?
[46:11.560 --> 46:13.560]  А можно ли это еще
[46:13.560 --> 46:15.560]  как-то по-другому представить?
[46:17.560 --> 46:19.560]  Да, это 32 в квадрате.
[46:25.560 --> 46:27.560]  Интересно.
[46:27.640 --> 46:29.640]  А что это значит,
[46:29.640 --> 46:31.640]  что у нас 32 в квадрате?
[46:31.640 --> 46:33.640]  Это значит,
[46:33.640 --> 46:35.640]  что в нашем блоке 32 варпа.
[46:37.640 --> 46:39.640]  Поэтому давайте предположим,
[46:39.640 --> 46:41.640]  что у нас с вами есть 32 варпа.
[46:47.640 --> 46:49.640]  В каждом из них
[46:49.640 --> 46:51.640]  внутри варпа мы запустим
[46:51.640 --> 46:53.640]  вот эту пирамидку,
[46:53.640 --> 46:55.640]  которую сверху запустили.
[46:57.640 --> 46:59.640]  Это на уровне варпа.
[46:59.640 --> 47:01.640]  Потом мы все эти элементы
[47:01.640 --> 47:03.640]  сагрегируем в один элемент массива
[47:07.640 --> 47:09.640]  и сделаем еще одну такую же пирамидку.
[47:17.640 --> 47:19.640]  Но мы сделаем это уже
[47:19.640 --> 47:21.640]  на инструкциях именно внутри варпа.
[47:21.720 --> 47:23.720]  Есть разница на самом деле.
[47:23.720 --> 47:25.720]  На обычном коде можно сильно обжечься.
[47:27.720 --> 47:29.720]  Осемблеры инструкция быстрее.
[47:31.720 --> 47:33.720]  Мы явно указываем,
[47:33.720 --> 47:35.720]  что используем инструкцию осемблера для этого.
[47:39.720 --> 47:41.720]  Но мы не будем использовать
[47:41.720 --> 47:43.720]  инструкцию осемблера.
[47:43.720 --> 47:45.720]  Мы будем использовать
[47:45.720 --> 47:47.720]  инструкцию осемблера для этого.
[47:47.800 --> 47:49.800]  Она берет указатель
[47:49.800 --> 47:51.800]  у элемента down
[47:51.800 --> 47:53.800]  и запрашивает значение
[47:53.800 --> 47:55.800]  по этому указателю
[47:55.800 --> 47:57.800]  на 4 потока в варпе выше.
[47:57.800 --> 47:59.800]  То есть у нас получается,
[47:59.800 --> 48:01.800]  смотрите, допустим,
[48:01.800 --> 48:03.800]  у нас были в варпе значения
[48:03.800 --> 48:05.800]  в регистрах.
[48:05.800 --> 48:07.800]  В0, В1, В2, В3.
[48:07.800 --> 48:09.800]  В4, В5.
[48:09.800 --> 48:11.800]  В6, В7.
[48:11.800 --> 48:13.800]  В8, В9.
[48:13.800 --> 48:15.800]  В10, В11.
[48:15.880 --> 48:17.880]  В2, В31.
[48:19.880 --> 48:21.880]  Значит, что сделает shuffledown?
[48:21.880 --> 48:23.880]  Отshuffledown
[48:25.880 --> 48:27.880]  если мы его запросим
[48:27.880 --> 48:29.880]  из В2 и 4.
[48:29.880 --> 48:31.880]  Он нам вернет значение,
[48:31.880 --> 48:33.880]  которое находится в регистре В6.
[48:39.880 --> 48:41.880]  Мы сделали бы то же самое,
[48:41.880 --> 48:43.880]  но суть в том,
[48:43.960 --> 48:45.960]  что, помните, я говорил,
[48:45.960 --> 48:47.960]  что как только мы используем
[48:47.960 --> 48:49.960]  операцию внутри какого-то
[48:49.960 --> 48:51.960]  shared памяти,
[48:51.960 --> 48:53.960]  нам нужно писать синхронизацию.
[48:53.960 --> 48:55.960]  То есть нам нужно
[48:55.960 --> 48:57.960]  указывать везде sync threads.
[48:57.960 --> 48:59.960]  На каждую операцию
[48:59.960 --> 49:01.960]  записи вы разделяем мы память,
[49:01.960 --> 49:03.960]  иначе у нас возникнет гонка данных.
[49:03.960 --> 49:05.960]  То есть у нас
[49:05.960 --> 49:07.960]  это бы выглядело следующим образом,
[49:07.960 --> 49:09.960]  что, пожалуйста,
[49:09.960 --> 49:11.960]  s и t
[49:12.040 --> 49:14.040]  плюс равно
[49:14.040 --> 49:16.040]  s и плюс четыре
[49:16.040 --> 49:18.040]  образно говоря.
[49:18.040 --> 49:20.040]  И тут бы мы ставили всегда sync threads,
[49:22.040 --> 49:24.040]  чтобы у нас операции были синхронизированы.
[49:24.040 --> 49:26.040]  Вот, здесь мы можем отключить
[49:26.040 --> 49:28.040]  эту операцию синхронизации.
[49:28.040 --> 49:30.040]  Потому что это все
[49:30.040 --> 49:32.040]  делается внутри одного варпа.
[49:32.040 --> 49:34.040]  То есть количество синхронизации уменьшится на 5.
[49:38.040 --> 49:40.040]  Да, да.
[49:40.120 --> 49:42.120]  Потому что это делается внутри одного варпа,
[49:42.120 --> 49:44.120]  это одна инструкция сэмблера.
[49:50.120 --> 49:52.120]  Да.
[49:54.120 --> 49:56.120]  Да, ну каждый размером с ворп, да.
[50:02.120 --> 50:04.120]  Да, да, да.
[50:04.120 --> 50:06.120]  Вот такая интересная штука.
[50:06.200 --> 50:08.200]  Какая интересная штука.
[50:08.200 --> 50:10.200]  Какой интересный алгоритм.
[50:10.200 --> 50:12.200]  Понятно суть этого алгоритма?
[50:12.200 --> 50:14.200]  Хорошо.
[50:14.200 --> 50:16.200]  Собственно, это то,
[50:16.200 --> 50:18.200]  к чему люди пришли.
[50:18.200 --> 50:20.200]  Используя вот этот элемент.
[50:20.200 --> 50:22.200]  Точнее, вот эту операцию.
[50:24.200 --> 50:26.200]  Вот, а теперь перейдем ко второй части,
[50:26.200 --> 50:28.200]  если вы не против.
[50:28.200 --> 50:30.200]  Это вычление суммы на префексе.
[50:30.200 --> 50:32.200]  Суть этой штуки заключается в том,
[50:32.200 --> 50:34.200]  что нам нужно посчитать
[50:34.280 --> 50:36.280]  следующую вещь.
[50:36.280 --> 50:38.280]  У нас есть элемент A0, A1.
[50:44.280 --> 50:46.280]  A enter.
[50:46.280 --> 50:48.280]  И нам нужно посчитать элементы вот такие.
[50:48.280 --> 50:50.280]  Обычно две разных задачи бывают.
[50:50.280 --> 50:52.280]  Бывает inclusive scan,
[50:52.280 --> 50:54.280]  бывает задача exclusive scan.
[50:54.280 --> 50:56.280]  Значит, в задачи inclusive
[50:58.280 --> 51:00.280]  наша цель посчитать
[51:00.280 --> 51:02.280]  A0,
[51:02.360 --> 51:04.360]  A0 плюс A1,
[51:04.360 --> 51:06.360]  A0 плюс A1 плюс A2,
[51:08.360 --> 51:10.360]  ну и сумму
[51:10.360 --> 51:12.360]  A it,
[51:12.360 --> 51:14.360]  A it от 0 до n.
[51:14.360 --> 51:16.360]  Значит, что делает задача exclusive?
[51:18.360 --> 51:20.360]  Я, честно, могу перепутать
[51:20.360 --> 51:22.360]  эти термина.
[51:26.360 --> 51:28.360]  0, A0,
[51:28.360 --> 51:30.360]  A0 плюс A1 и то же самое.
[51:32.360 --> 51:34.360]  Нравится или нет?
[51:42.360 --> 51:44.360]  Нравится или нет?
[51:44.360 --> 51:46.360]  За заключением одного элемента.
[51:48.360 --> 51:50.360]  Просто про реализацию поговорить.
[51:50.360 --> 51:52.360]  Нам надо решить обратную задачу.
[51:52.360 --> 51:54.360]  Если задачу вычления сумм чисел массива
[51:54.360 --> 51:56.360]  мы можем считать каким-то образом
[51:56.360 --> 51:58.360]  параллельно,
[51:58.360 --> 52:00.360]  но то с этой задачей
[52:00.440 --> 52:02.440]  как дела обстоят?
[52:02.440 --> 52:04.440]  Вы когда-нибудь писали эту задачу параллельно?
[52:06.440 --> 52:08.440]  Не, но ее можно написать параллельно
[52:08.440 --> 52:10.440]  и не поверите за сколько.
[52:10.440 --> 52:12.440]  Вы ее можете записать параллельно
[52:12.440 --> 52:14.440]  за n лог n.
[52:14.440 --> 52:16.440]  Приблизительно симптотика у вас будет.
[52:20.440 --> 52:22.440]  Но с учетом того, что мы
[52:22.440 --> 52:24.440]  здесь будем приблизительно делить
[52:24.440 --> 52:26.440]  на C,
[52:26.440 --> 52:28.440]  то это окажется быстрее,
[52:28.520 --> 52:30.520]  и считать это за n.
[52:32.520 --> 52:34.520]  Поэтому давайте рассмотрим
[52:34.520 --> 52:36.520]  решение задачи.
[52:36.520 --> 52:38.520]  Вопрос, который я хочу задать,
[52:38.520 --> 52:40.520]  знаете ли вы такую структуру данных,
[52:40.520 --> 52:42.520]  как дерево Фенвика?
[52:42.520 --> 52:44.520]  Дерево Фенвика.
[52:44.520 --> 52:46.520]  Оно здесь используется.
[52:50.520 --> 52:52.520]  Да, да, да, да.
[52:52.520 --> 52:54.520]  Значит смотрите, есть массив,
[52:54.520 --> 52:56.520]  значит мы хотим
[52:56.600 --> 52:58.600]  посчитать такие суммы.
[52:58.600 --> 53:00.600]  Первый алгоритм,
[53:00.600 --> 53:02.600]  который является такой
[53:02.600 --> 53:04.600]  на самом деле достаточно эффективным,
[53:04.600 --> 53:06.600]  и сейчас он используется, и на семинарах
[53:06.600 --> 53:08.600]  вы это тоже посмотрите,
[53:08.600 --> 53:10.600]  мы считаем скан на блоке.
[53:10.600 --> 53:12.600]  Смотрите, что мы делаем.
[53:12.600 --> 53:14.600]  Мы складываем элементы с 0 по 7,
[53:14.600 --> 53:16.600]  ну и дальше складываем себя
[53:16.600 --> 53:18.600]  со следующим, потом себя
[53:18.600 --> 53:20.600]  через двойки, себя через 4,
[53:20.600 --> 53:22.600]  себя через 8.
[53:22.600 --> 53:24.600]  То есть такая пирамидка.
[53:26.600 --> 53:28.600]  Она заключается в том,
[53:28.600 --> 53:30.600]  что образно говоря,
[53:30.600 --> 53:32.600]  чтобы посчитать сумму
[53:32.600 --> 53:34.600]  с 0 по 6 элемент,
[53:34.600 --> 53:36.600]  нам нужно посчитать сумму
[53:36.600 --> 53:38.600]  со 2 по 6, плюс сумму
[53:38.600 --> 53:40.600]  с 0 по 1.
[53:46.600 --> 53:48.600]  То есть мы разбиваем
[53:48.600 --> 53:50.600]  наше число, которое необходимо,
[53:50.600 --> 53:52.600]  на степени двойки, ну и дальше
[53:52.600 --> 53:54.600]  раскладываем его в двоичной системе.
[53:54.680 --> 53:56.680]  То есть у нас 6 в десятичной,
[53:56.680 --> 53:58.680]  это 1, 1, 0 в двоичной.
[54:00.680 --> 54:02.680]  Берем четыре последних
[54:02.680 --> 54:04.680]  и потом еще два предпоследних.
[54:08.680 --> 54:10.680]  То есть видно, как это все дело складывается.
[54:10.680 --> 54:12.680]  Этот алгоритм хороший,
[54:12.680 --> 54:14.680]  но сколько в нем операций осуществляется?
[54:16.680 --> 54:18.680]  Отлагаем.
[54:18.680 --> 54:20.680]  И несмотря на это,
[54:20.680 --> 54:22.680]  этот алгоритм является оптимальным
[54:22.760 --> 54:24.760]  из-за своей константа.
[54:24.760 --> 54:26.760]  То есть константа у него низкая.
[54:26.760 --> 54:28.760]  Но давайте попробуем
[54:28.760 --> 54:30.760]  уменьшить эту константу.
[54:30.760 --> 54:32.760]  И оказывается следующее,
[54:32.760 --> 54:34.760]  что...
[54:34.760 --> 54:36.760]  А, да, у нас еще n лог n ворп
[54:36.760 --> 54:38.760]  операции, потому что мы с вами
[54:38.760 --> 54:40.760]  понимаем, что каждый элемент будет затрагивать
[54:40.760 --> 54:42.760]  свой ворп.
[54:42.760 --> 54:44.760]  То есть видите, тут прямо массивные
[54:44.760 --> 54:46.760]  вычисления идут.
[54:46.760 --> 54:48.760]  Необходимая синхронизация,
[54:48.760 --> 54:50.760]  еще дополнительно, потому что
[54:50.840 --> 54:52.840]  когда вы записываете элементы,
[54:52.840 --> 54:54.840]  вам нужно всегда ставить sync-tracks в конце,
[54:54.840 --> 54:56.840]  чтобы это все работало.
[54:56.840 --> 54:58.840]  Знаете, как проверить,
[54:58.840 --> 55:00.840]  почему нужен sync-tracks?
[55:00.840 --> 55:02.840]  Попробуйте в кодах, которые у нас есть к семинарам
[55:02.840 --> 55:04.840]  закомментировать строчки sync-tracks.
[55:04.840 --> 55:06.840]  Посмотрите, что получится.
[55:06.840 --> 55:08.840]  А? Будет весело.
[55:08.840 --> 55:10.840]  Может у кого-то были семинары,
[55:10.840 --> 55:12.840]  те увидели.
[55:12.840 --> 55:14.840]  Поэтому мы делаем следующую вещь.
[55:14.840 --> 55:16.840]  Сделаем две стадии.
[55:16.840 --> 55:18.840]  Первая мы складываем элемент 0 и 1.
[55:18.920 --> 55:20.920]  Закрываем нитку вот такую, видите?
[55:22.920 --> 55:24.920]  Складываем 2 и 3.
[55:24.920 --> 55:26.920]  4 и 5.
[55:26.920 --> 55:28.920]  Что и что 7.
[55:28.920 --> 55:30.920]  И вот смотрите, на самом деле, здесь у нас получается,
[55:30.920 --> 55:32.920]  если мы посмотрим внимательно на сумму чисел,
[55:32.920 --> 55:34.920]  которые у нас получаются, здесь получается дерев fendvik.
[55:38.920 --> 55:40.920]  Да.
[55:42.920 --> 55:44.920]  И давайте как раз это посмотрим,
[55:44.920 --> 55:46.920]  как это работает.
[55:48.920 --> 55:50.920]  А теперь научимся складывать элементы,
[55:50.920 --> 55:52.920]  имея это дерево fendvik.
[56:00.920 --> 56:02.920]  То есть, а какую задачу решает дерево fendvik?
[56:02.920 --> 56:04.920]  Напомните мне, пожалуйста.
[56:10.920 --> 56:12.920]  Да.
[56:12.920 --> 56:14.920]  Собственно, сумму чисел на припексе,
[56:14.920 --> 56:16.920]  на любом подотреске.
[56:18.920 --> 56:20.920]  Да, оффлайн.
[56:20.920 --> 56:22.920]  Ну, нам нужна оффлайн сумма.
[56:22.920 --> 56:24.920]  Ой, извините.
[56:26.920 --> 56:28.920]  Вот.
[56:28.920 --> 56:30.920]  Сумму чисел на любом подотреске.
[56:30.920 --> 56:32.920]  Ну, понятно, что мы можем решать сумму задачи
[56:32.920 --> 56:34.920]  на префиксе.
[56:34.920 --> 56:36.920]  А?
[56:38.920 --> 56:40.920]  Нет, это вот как раз наверху.
[56:40.920 --> 56:42.920]  А нам надо...
[56:42.920 --> 56:44.920]  Это то, что мы хотим получить.
[56:44.920 --> 56:46.920]  А вот это то, что мы хотим получить.
[56:47.000 --> 56:49.000]  А вот это то, что мы хотим получить.
[56:49.000 --> 56:51.000]  Мы хотим получить пустое множество,
[56:51.000 --> 56:53.000]  ноль,
[56:53.000 --> 56:55.000]  эксклюзивный скан решаем.
[57:07.000 --> 57:09.000]  Так.
[57:09.000 --> 57:11.000]  Давайте действовать.
[57:11.080 --> 57:13.080]  Так, понятно.
[57:13.080 --> 57:15.080]  Понятно.
[57:15.080 --> 57:17.080]  Усломалось.
[57:17.080 --> 57:19.080]  Так.
[57:19.080 --> 57:21.080]  Что мы делаем?
[57:21.080 --> 57:23.080]  Заметьте, пожалуйста,
[57:23.080 --> 57:25.080]  одну закономерность.
[57:25.080 --> 57:27.080]  А она здесь есть.
[57:31.080 --> 57:33.080]  Что такое 0-6?
[57:37.080 --> 57:39.080]  Давайте разложим это.
[57:39.160 --> 57:41.160]  0-3 плюс 4-5 плюс 6.
[57:43.160 --> 57:45.160]  Вот это у нас 0-3 плюс 4-5.
[57:47.160 --> 57:49.160]  Вот это 0-3 плюс 4.
[57:51.160 --> 57:53.160]  Вопрос. Где у нас 0-3 находится?
[57:59.160 --> 58:01.160]  Жух.
[58:05.160 --> 58:07.160]  0-3 находится справа в верхнем углу,
[58:07.240 --> 58:09.240]  находится справа в верхнем углу,
[58:09.240 --> 58:11.240]  в левой части.
[58:11.240 --> 58:13.240]  И нам его нужно распространить в правую часть.
[58:15.240 --> 58:17.240]  Видно, да?
[58:17.240 --> 58:19.240]  Давайте мы его отправим сюда.
[58:21.240 --> 58:23.240]  А 0-7 нам нужен?
[58:25.240 --> 58:27.240]  Не особо.
[58:27.240 --> 58:29.240]  Поэтому мы сделаем следующее.
[58:29.240 --> 58:31.240]  Мы его закроем,
[58:31.240 --> 58:33.240]  точнее мы его запомним,
[58:33.240 --> 58:35.240]  а здесь напишем пустое множество.
[58:35.320 --> 58:37.320]  Вот.
[58:37.320 --> 58:39.320]  И пока что эфемерно сложим это с нулем.
[58:41.320 --> 58:43.320]  А вот это пустое множество,
[58:43.320 --> 58:45.320]  оно здесь находится.
[58:45.320 --> 58:47.320]  Выставим его сюда.
[58:47.320 --> 58:49.320]  В итоге у нас получаются элементы.
[58:49.320 --> 58:51.320]  Смотрите, пустое множество.
[58:51.320 --> 58:53.320]  Ой, нет, подождите.
[58:53.320 --> 58:55.320]  Словно что здесь еще нет.
[58:55.320 --> 58:57.320]  0.
[58:57.320 --> 58:59.320]  0-1.
[58:59.320 --> 59:01.320]  2.
[59:01.320 --> 59:03.320]  Пустое множество.
[59:03.400 --> 59:05.400]  Здесь у нас 4.
[59:05.400 --> 59:07.400]  4-5.
[59:07.400 --> 59:09.400]  6.
[59:09.400 --> 59:11.400]  Пустое множество.
[59:11.400 --> 59:13.400]  Ой, не пустое множество, извините.
[59:13.400 --> 59:15.400]  0-3.
[59:15.400 --> 59:17.400]  Вот так, да?
[59:19.400 --> 59:21.400]  Так, теперь давайте еще одну
[59:21.400 --> 59:23.400]  штуку заметим.
[59:23.400 --> 59:25.400]  Разобьем вот этот массив еще пополам.
[59:27.400 --> 59:29.400]  Смотрите, фишка в чем.
[59:29.400 --> 59:31.400]  Пустое множество нам нужно здесь.
[59:31.480 --> 59:33.480]  0-1 нам нужно здесь.
[59:35.480 --> 59:37.480]  0-1.
[59:39.480 --> 59:41.480]  2.
[59:41.480 --> 59:43.480]  Здесь пустое множество, 0.
[59:49.480 --> 59:51.480]  Теперь смотрите, опять же то же самое
[59:51.480 --> 59:53.480]  перекрестное сложение.
[59:53.480 --> 59:55.480]  Здесь получаем 0-1,
[59:55.480 --> 59:57.480]  здесь получаем 0-2.
[59:57.480 --> 59:59.480]  Перекрестное сложение.
[59:59.560 --> 01:00:01.560]  Пустое 0,
[01:00:01.560 --> 01:00:03.560]  пустое множество, 0.
[01:00:03.560 --> 01:00:05.560]  А здесь что у нас происходит?
[01:00:05.560 --> 01:00:07.560]  Давайте посмотрим здесь, что происходит.
[01:00:07.560 --> 01:00:09.560]  Делаем перекрестное сложение
[01:00:09.560 --> 01:00:11.560]  и получаем сумму элементов 0-5.
[01:00:15.560 --> 01:00:17.560]  А сюда отправляем 0-3.
[01:00:19.560 --> 01:00:21.560]  Еще одно перекрестное
[01:00:21.560 --> 01:00:23.560]  сложение, получаем такую вещь.
[01:00:25.560 --> 01:00:27.560]  Видите, пирамидка такая
[01:00:27.640 --> 01:00:29.640]  получилась красивая.
[01:00:33.640 --> 01:00:35.640]  Кажется, все красиво.
[01:00:37.640 --> 01:00:39.640]  Как вы думаете, в чем проблема этого алгоритма?
[01:00:39.640 --> 01:00:41.640]  Он выполняется
[01:00:41.640 --> 01:00:43.640]  за линию.
[01:00:49.640 --> 01:00:51.640]  Сложный. А если алгоритм
[01:00:51.640 --> 01:00:53.640]  сложный, то что у него большое?
[01:00:53.720 --> 01:00:55.720]  Константа.
[01:00:55.720 --> 01:00:57.720]  Если алгоритм сложный,
[01:00:57.720 --> 01:00:59.720]  у него большая константа.
[01:00:59.720 --> 01:01:01.720]  А если у него большая константа, то
[01:01:01.720 --> 01:01:03.720]  скорее всего эта константа настолько большая,
[01:01:03.720 --> 01:01:05.720]  что она ломает, что она работает хуже
[01:01:05.720 --> 01:01:07.720]  алгоритма, который работает для логин.
[01:01:07.720 --> 01:01:09.720]  Здесь это
[01:01:09.720 --> 01:01:11.720]  на практике и происходит.
[01:01:11.720 --> 01:01:13.720]  Вот она, вторая
[01:01:13.720 --> 01:01:15.720]  стадия еще разок.
[01:01:15.720 --> 01:01:17.720]  Более того, у этого алгоритма есть огромное
[01:01:17.720 --> 01:01:19.720]  количество банк конфликтов.
[01:01:19.800 --> 01:01:21.800]  Те самые, которые
[01:01:21.800 --> 01:01:23.800]  у нас были.
[01:01:23.800 --> 01:01:25.800]  Смотрите, вот даже
[01:01:25.800 --> 01:01:27.800]  вот здесь есть банк конфликт.
[01:01:27.800 --> 01:01:29.800]  0-й поток складывает 0-й и 1-й
[01:01:29.800 --> 01:01:31.800]  и записывает результат в 1-й.
[01:01:31.800 --> 01:01:33.800]  1-й поток складывает,
[01:01:33.800 --> 01:01:35.800]  0-й поток потом складывает элементы 1-й и 3-й.
[01:01:35.800 --> 01:01:37.800]  3-й – 7-й, 7-й – 15-й,
[01:01:37.800 --> 01:01:39.800]  15-й – 31-й.
[01:01:39.800 --> 01:01:41.800]  При этом 16-й поток
[01:01:41.800 --> 01:01:43.800]  параллельно будет складывать 32-й
[01:01:43.800 --> 01:01:45.800]  и 33-й элементы массива.
[01:01:45.880 --> 01:01:47.880]  Банк конфликт,
[01:01:47.880 --> 01:01:49.880]  вот он.
[01:01:49.880 --> 01:01:51.880]  Как его решать?
[01:01:55.880 --> 01:01:57.880]  Идея гениальная.
[01:01:59.880 --> 01:02:01.880]  Не-не-не, помогает.
[01:02:01.880 --> 01:02:03.880]  Так, вы верите в
[01:02:03.880 --> 01:02:05.880]  эзотерику?
[01:02:05.960 --> 01:02:07.960]  Нет, я серьезно говорю,
[01:02:07.960 --> 01:02:09.960]  верите в всякие
[01:02:09.960 --> 01:02:11.960]  эзотерика,
[01:02:11.960 --> 01:02:13.960]  оккультные мистические
[01:02:13.960 --> 01:02:15.960]  всякие вещи?
[01:02:15.960 --> 01:02:17.960]  Хорошо.
[01:02:17.960 --> 01:02:19.960]  Что эзотерического есть
[01:02:19.960 --> 01:02:21.960]  в телеке?
[01:02:25.960 --> 01:02:27.960]  Ну,
[01:02:27.960 --> 01:02:29.960]  что-то есть в телеке.
[01:02:30.040 --> 01:02:32.040]  Нет, почему говорят,
[01:02:32.040 --> 01:02:34.040]  что телевизор плохо смотреть?
[01:02:36.040 --> 01:02:38.040]  Вот там говорят голову
[01:02:38.040 --> 01:02:40.040]  промывает мозги.
[01:02:40.040 --> 01:02:42.040]  Да, бинго, 25-й кадр.
[01:02:44.040 --> 01:02:46.040]  Смотрите, идея состоит в следующем.
[01:02:46.040 --> 01:02:48.040]  Давайте сделаем 25-й кадр,
[01:02:48.040 --> 01:02:50.040]  именно 32-й элемент каждого ворпа будем пропускать.
[01:02:50.040 --> 01:02:52.040]  Ворпу,
[01:02:52.040 --> 01:02:54.040]  ворпу,
[01:02:54.040 --> 01:02:56.040]  ворпу,
[01:02:56.040 --> 01:02:58.040]  ворпу,
[01:02:58.120 --> 01:03:00.120]  мы будем пропускать.
[01:03:02.120 --> 01:03:04.120]  Мы будем говорить следующее,
[01:03:04.120 --> 01:03:06.120]  что у нас элементы массива,
[01:03:06.120 --> 01:03:08.120]  то есть наша память существует,
[01:03:08.120 --> 01:03:10.120]  но мы будем работать с этими элементами массива
[01:03:10.120 --> 01:03:12.120]  следующим образом.
[01:03:12.120 --> 01:03:14.120]  Вот мы записываем с вами
[01:03:14.120 --> 01:03:16.120]  элементы массива с нулевого по 31-й,
[01:03:18.120 --> 01:03:20.120]  потом тот элемент массива,
[01:03:20.120 --> 01:03:22.120]  который по идее должен быть
[01:03:22.120 --> 01:03:24.120]  на 32-м элементе, мы пропускаем,
[01:03:24.120 --> 01:03:26.120]  тут самый 25-й кадр,
[01:03:26.200 --> 01:03:28.200]  дальше элементы массива идут
[01:03:28.200 --> 01:03:30.200]  с 32-го по 63-й,
[01:03:30.200 --> 01:03:32.200]  потом опять пропуск
[01:03:32.200 --> 01:03:34.200]  и так далее.
[01:03:42.200 --> 01:03:44.200]  Ну не, мы просто говорим,
[01:03:44.200 --> 01:03:46.200]  что когда мы обращаемся, смотрите,
[01:03:46.200 --> 01:03:48.200]  в чем фишка, мы обратились
[01:03:48.200 --> 01:03:50.200]  с вами допустим к первому элементу массива,
[01:03:50.200 --> 01:03:52.200]  вот здесь вот.
[01:03:52.200 --> 01:03:54.200]  То есть у нас операция идет следующим образом.
[01:03:54.280 --> 01:03:56.280]  Раз, раз, мы сложили.
[01:04:00.280 --> 01:04:02.280]  А дальше мы обратились,
[01:04:02.280 --> 01:04:04.280]  элемент какой там у нас был?
[01:04:04.280 --> 01:04:06.280]  16-й поток, да, у нас складывал
[01:04:06.280 --> 01:04:08.280]  32-й и 33-й элемент массива.
[01:04:12.280 --> 01:04:14.280]  Это элементы массива,
[01:04:14.280 --> 01:04:16.280]  но если мы посмотрим индексы,
[01:04:16.280 --> 01:04:18.280]  то здесь у нас будет нулевой,
[01:04:18.280 --> 01:04:20.280]  здесь у нас будет первый,
[01:04:20.280 --> 01:04:22.280]  здесь у нас уже будет 33-й элемент массива
[01:04:22.360 --> 01:04:24.360]  и 33-й элемент массива.
[01:04:24.360 --> 01:04:26.360]  Ой, наоборот.
[01:04:26.360 --> 01:04:28.360]  Так, стоп, стоп, стоп, я кажется,
[01:04:28.360 --> 01:04:30.360]  кажется нам уд... А, нет.
[01:04:30.360 --> 01:04:32.360]  Нормально. То есть смотрите, у нас обращение
[01:04:32.360 --> 01:04:34.360]  идет к 33-й и 34-й.
[01:04:34.360 --> 01:04:36.360]  Если здесь мы делали запись первого элемента массива,
[01:04:36.360 --> 01:04:38.360]  то здесь мы делаем запись 34-й элемент массива.
[01:04:40.360 --> 01:04:42.360]  Который не находится в одной банке.
[01:04:42.360 --> 01:04:44.360]  Они развелись по разным индексам
[01:04:44.360 --> 01:04:46.360]  по модулю.
[01:04:46.360 --> 01:04:48.360]  Все, конфликт исчерпан.
[01:04:48.440 --> 01:04:50.440]  Клевая идея.
[01:04:56.440 --> 01:04:58.440]  Не-не, это вот тот алгоритм,
[01:04:58.440 --> 01:05:00.440]  который вот до этого
[01:05:00.440 --> 01:05:02.440]  был наиболее оптимальным.
[01:05:02.440 --> 01:05:04.440]  Но у него константа большая.
[01:05:04.440 --> 01:05:06.440]  Вот.
[01:05:06.440 --> 01:05:08.440]  То есть это модификация вот этого алгоритма,
[01:05:08.440 --> 01:05:10.440]  который позволяет вот это решать
[01:05:10.440 --> 01:05:12.440]  линейным способом. На семинаре посмотрите
[01:05:12.440 --> 01:05:14.440]  код для эстетического удовольствия.
[01:05:14.520 --> 01:05:16.520]  Но давайте вернемся к современным реалиям.
[01:05:18.520 --> 01:05:20.520]  И поэтому я сейчас вам покажу
[01:05:20.520 --> 01:05:22.520]  еще одну картинку.
[01:05:22.520 --> 01:05:24.520]  Так, 32-ю кадр мы его
[01:05:24.520 --> 01:05:26.520]  с вами обсудили.
[01:05:26.520 --> 01:05:28.520]  Это так, так же, как все это складывается.
[01:05:28.520 --> 01:05:30.520]  То есть мы сканируем, потом делаем
[01:05:30.520 --> 01:05:32.520]  скан сканов, а дальше нам нужно
[01:05:32.520 --> 01:05:34.520]  распространение суммы элементов.
[01:05:34.520 --> 01:05:36.520]  Сделать обратное.
[01:05:36.520 --> 01:05:38.520]  Эх, во!
[01:05:40.520 --> 01:05:42.520]  Современный скан.
[01:05:42.600 --> 01:05:44.600]  Современный скан.
[01:05:44.600 --> 01:05:46.600]  Напоминаю, что 1024 это 32
[01:05:46.600 --> 01:05:48.600]  в квадрате.
[01:05:48.600 --> 01:05:50.600]  Поэтому мы можем внутри каждого скана
[01:05:50.600 --> 01:05:52.600]  сделать
[01:05:52.600 --> 01:05:54.600]  shuffle up sync операцию.
[01:05:56.600 --> 01:05:58.600]  Ну, отсложить элементы, получаем
[01:05:58.600 --> 01:06:00.600]  такую красивую. Потом, на уровне
[01:06:00.600 --> 01:06:02.600]  варпов мы ставим барьер.
[01:06:02.600 --> 01:06:04.600]  Перемещаем все
[01:06:04.600 --> 01:06:06.600]  наши элементы в необходимые
[01:06:06.600 --> 01:06:08.600]  суммы и начинаем дальше
[01:06:08.600 --> 01:06:10.600]  повторять операцию. То есть первое
[01:06:10.680 --> 01:06:12.680]  считает у нас сумму на префиксов внутри
[01:06:12.680 --> 01:06:14.680]  каждого варпа, второе уже делает
[01:06:14.680 --> 01:06:16.680]  синхронизацию между всеми варпами.
[01:06:18.680 --> 01:06:20.680]  То есть вот этот элемент массива достается
[01:06:20.680 --> 01:06:22.680]  всем остальным, вот этот элемент массива
[01:06:22.680 --> 01:06:24.680]  складывается со всеми
[01:06:24.680 --> 01:06:26.680]  дальнейшими
[01:06:26.680 --> 01:06:28.680]  и так далее.
[01:06:28.680 --> 01:06:30.680]  Вот он сверху, вот они
[01:06:30.680 --> 01:06:32.680]  индексы.
[01:06:32.680 --> 01:06:34.680]  Да, одна линия.
[01:06:40.680 --> 01:06:42.680]  Где?
[01:06:42.680 --> 01:06:44.680]  А!
[01:06:44.680 --> 01:06:46.680]  А, это редукшн.
[01:06:46.680 --> 01:06:48.680]  То есть это, допустим, мы хотели
[01:06:48.680 --> 01:06:50.680]  посчитать какую-то сумму.
[01:06:54.680 --> 01:06:56.680]  Ну, можно считать, это, на самом деле, картинку
[01:06:56.680 --> 01:06:58.680]  просто со слайда взял.
[01:06:58.680 --> 01:07:00.680]  Можно считать, что, типа, здесь
[01:07:00.680 --> 01:07:02.680]  все кроме одной строки можно обрезать.
[01:07:02.680 --> 01:07:04.680]  То есть вот тут провести вот
[01:07:04.680 --> 01:07:06.680]  такую разделительную линию и считать, что вот это
[01:07:06.680 --> 01:07:08.680]  наш элемент массива.
[01:07:10.680 --> 01:07:12.680]  Не, в остальных уже не по одному.
[01:07:16.680 --> 01:07:18.680]  А, подождите,
[01:07:18.680 --> 01:07:20.680]  здесь секунду, сейчас.
[01:07:28.680 --> 01:07:30.680]  Сейчас, математику процесса
[01:07:30.680 --> 01:07:32.680]  надо понять.
[01:07:40.680 --> 01:07:42.680]  Смотрите, тут идея такая,
[01:07:42.680 --> 01:07:44.680]  вот про верхнюю строку точно не могу
[01:07:44.680 --> 01:07:46.680]  ничего сказать. Идея такая, что
[01:07:46.680 --> 01:07:48.680]  мы сначала агрегируем сумму в каждом скане.
[01:07:52.680 --> 01:07:54.680]  Ну, в каждом варпе получаем
[01:07:54.680 --> 01:07:56.680]  сумму на префиксах.
[01:07:58.680 --> 01:08:00.680]  Ну да, варп это вот эта вертикальная полоса,
[01:08:00.680 --> 01:08:02.680]  которая у нас.
[01:08:02.680 --> 01:08:04.680]  Из четырех.
[01:08:04.680 --> 01:08:06.680]  Да, это один варп.
[01:08:06.680 --> 01:08:08.680]  Дальше мы ставим
[01:08:08.760 --> 01:08:10.760]  барьер,
[01:08:10.760 --> 01:08:12.760]  распределяем значение в варпах
[01:08:12.760 --> 01:08:14.760]  для следующих элементов массива.
[01:08:14.760 --> 01:08:16.760]  То есть говорим, что здесь у нас
[01:08:16.760 --> 01:08:18.760]  идет сложение с этим,
[01:08:18.760 --> 01:08:20.760]  здесь идет сложение с этим и так далее.
[01:08:20.760 --> 01:08:22.760]  Распространяем их.
[01:08:22.760 --> 01:08:24.760]  То есть получаем сумму на префиксах,
[01:08:24.760 --> 01:08:26.760]  которые дальше можно синхронизировать
[01:08:26.760 --> 01:08:28.760]  между собой
[01:08:28.760 --> 01:08:30.760]  для того, чтобы посчитать сумму чисел массиве.
[01:08:32.760 --> 01:08:34.760]  Ну, сумму чисел на префиксе.
[01:08:34.760 --> 01:08:36.760]  То есть алгоритм трехстадейный.
[01:08:36.840 --> 01:08:38.840]  Вот, я предлагаю, поскольку мы сейчас
[01:08:38.840 --> 01:08:40.840]  уже немножко не бум-бум не варим,
[01:08:40.840 --> 01:08:42.840]  да, попытаться
[01:08:42.840 --> 01:08:44.840]  это перенести на следующий раз и
[01:08:44.840 --> 01:08:46.840]  с цифриками там
[01:08:46.840 --> 01:08:48.840]  разрисовать это.
[01:08:48.840 --> 01:08:50.840]  Но это современная реализация, которая
[01:08:50.840 --> 01:08:52.840]  бьет все остальные.
[01:08:58.840 --> 01:09:00.840]  Выглядит весело.
[01:09:00.840 --> 01:09:02.840]  Но работает,
[01:09:02.840 --> 01:09:04.840]  кстати, реализовывать вот эту штуку
[01:09:04.920 --> 01:09:06.920]  лучше, чем вот эту.
[01:09:16.920 --> 01:09:18.920]  Ну, да.
[01:09:26.920 --> 01:09:28.920]  А, ну, здесь для того,
[01:09:28.920 --> 01:09:30.920]  чтобы пар конфликтов,
[01:09:30.920 --> 01:09:32.920]  банк конфликтов избавиться.
[01:09:34.920 --> 01:09:36.920]  Я же говорил, что мы брали
[01:09:36.920 --> 01:09:38.920]  нулевой и первый элемент складывали,
[01:09:38.920 --> 01:09:40.920]  получали первый элемент массива.
[01:09:40.920 --> 01:09:42.920]  Дальше 32 и 33
[01:09:42.920 --> 01:09:44.920]  складываем,
[01:09:44.920 --> 01:09:46.920]  складываем это в 16 потоке.
[01:09:46.920 --> 01:09:48.920]  При этом, смотрите, здесь у нас
[01:09:48.920 --> 01:09:50.920]  запись идет в первый элемент массива.
[01:09:54.920 --> 01:09:56.920]  То есть здесь запись у нас шла в первый элемент массива,
[01:09:56.920 --> 01:09:58.920]  в райд.
[01:09:58.920 --> 01:10:00.920]  А до этого мы
[01:10:00.920 --> 01:10:02.920]  делали в райд в 33 элемент массива.
[01:10:03.000 --> 01:10:05.000]  И в итоге нулевой и 16 поток
[01:10:05.000 --> 01:10:07.000]  писали в два одинаковых потока
[01:10:07.000 --> 01:10:09.000]  в барпу.
[01:10:11.000 --> 01:10:13.000]  Сделали сдвиг.
[01:10:13.000 --> 01:10:15.000]  Теперь вот этот 33 поток,
[01:10:15.000 --> 01:10:17.000]  33 элемент массива, на самом деле,
[01:10:17.000 --> 01:10:19.000]  оказался в 34.
[01:10:21.000 --> 01:10:23.000]  Ну, что сдвиг на один произошел.
[01:10:27.000 --> 01:10:29.000]  Вот, и в итоге
[01:10:29.000 --> 01:10:31.000]  здесь мы делали запись в первый,
[01:10:31.080 --> 01:10:33.080]  а здесь уже окажется запись по второй,
[01:10:33.080 --> 01:10:35.080]  пишем по модулю.
[01:10:35.080 --> 01:10:37.080]  Да,
[01:10:37.080 --> 01:10:39.080]  даже боль.
[01:10:39.080 --> 01:10:41.080]  Да, размер памяти уменьшился на 1,
[01:10:41.080 --> 01:10:43.080]  32.
[01:10:47.080 --> 01:10:49.080]  Ну да.
[01:10:51.080 --> 01:10:53.080]  Да, ну там константы больше
[01:10:53.080 --> 01:10:55.080]  для вычления этих операций возникают.
