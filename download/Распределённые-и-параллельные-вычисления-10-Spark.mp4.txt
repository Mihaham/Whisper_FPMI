[00:00.000 --> 00:07.000]  Дай позвонить, пожалуйста, если видно мой экран.
[00:07.000 --> 00:10.000]  Да, и экраны вам видно.
[00:10.000 --> 00:13.000]  Отлично. Прошу прощения, у меня здесь утренний кофе,
[00:13.000 --> 00:15.000]  только что буквально 7 утра.
[00:15.000 --> 00:18.000]  Я сейчас нахожусь в Северной Америке, именно в Канаде,
[00:18.000 --> 00:22.000]  в Торонто, поэтому у нас разы по времени такой еще.
[00:22.000 --> 00:25.000]  Здесь 7 утра, почти 8.
[00:25.000 --> 00:27.000]  Поэтому для меня будет очень приятно,
[00:27.000 --> 00:29.000]  здесь 7 утра, почти 8.
[00:29.000 --> 00:31.000]  Поэтому для меня сейчас утренний кофе,
[00:31.000 --> 00:33.000]  поэтому прошу внимания, пожалуйста.
[00:35.000 --> 00:37.000]  Давайте познакомимся, наверное.
[00:37.000 --> 00:40.000]  Может быть, я расскажу вам о себе,
[00:40.000 --> 00:43.000]  а вы мне тоже вкратце кто-нибудь расскажете о себе,
[00:43.000 --> 00:46.000]  о ваших интересах, что вообще изучаете,
[00:46.000 --> 00:51.000]  какие у вас интересные направления, которые вам хотелось бы узнать,
[00:51.000 --> 00:54.000]  изучить в плане дата инжиниринга
[00:54.000 --> 00:57.000]  и в принципе про дата.
[00:59.000 --> 01:02.000]  А также со мной здесь мой коллега Юрий,
[01:02.000 --> 01:05.000]  с кем мы работаем в Москве на проекте,
[01:05.000 --> 01:07.000]  в компании в одной,
[01:07.000 --> 01:12.000]  где мы даже помогаем строить платформу Data Lake.
[01:12.000 --> 01:14.000]  Юрий тоже про себя расскажет немного.
[01:14.000 --> 01:17.000]  Поэтому будет здорово, если у нас будет
[01:17.000 --> 01:19.000]  такое интерактивное общение.
[01:19.000 --> 01:20.000]  Мне хотелось бы это делать,
[01:20.000 --> 01:24.000]  почитать, может быть, уже прописано истинно для вас,
[01:24.000 --> 01:28.000]  то, что вы уже другие преподаватели, вы сами изучили.
[01:28.000 --> 01:33.000]  Поэтому начнем просто проходить по слайдам
[01:33.000 --> 01:37.000]  и спело прерывайте меня или Юрия,
[01:37.000 --> 01:39.000]  задавайте вопросы.
[01:39.000 --> 01:41.000]  Можем даже перескотировать.
[01:41.000 --> 01:44.000]  Будет здорово, если будет такое же общение.
[01:44.000 --> 01:46.000]  Вопросы задавайте любые, как я уже сказал.
[01:46.000 --> 01:49.000]  Сразу скажу, что презентация мне на английском языке.
[01:49.000 --> 01:51.000]  Надеюсь, это никого не смутит.
[01:51.000 --> 01:52.000]  Я буду переводить.
[01:52.000 --> 01:54.000]  Я не буду говорить на английском языке.
[01:54.000 --> 01:56.000]  Причина, почему я создал английский язык,
[01:56.000 --> 01:58.000]  потому что самая простая причина,
[01:58.000 --> 02:00.000]  потому что у меня нет русской раскладки.
[02:00.000 --> 02:02.000]  У меня обязательно будет в определенное время
[02:02.000 --> 02:03.000]  писать все русскими буквами.
[02:03.000 --> 02:07.000]  Хоть я могу писать английскую раскладку русскими буквами,
[02:07.000 --> 02:10.000]  но больше меня боится, что у меня будут очень глупые ошибки.
[02:10.000 --> 02:12.000]  Ну и про дата.
[02:12.000 --> 02:14.000]  Тренология IT.
[02:14.000 --> 02:16.000]  Говорите на английском языке.
[02:16.000 --> 02:18.000]  Потому что все книги на английском языке,
[02:18.000 --> 02:20.000]  все статьи интересны на английском языке.
[02:20.000 --> 02:26.000]  Даже если сейчас наблюдаю много очень интересных также
[02:26.000 --> 02:30.000]  лекций, курсов ребят из Москвы,
[02:30.000 --> 02:32.000]  из других городов.
[02:32.000 --> 02:34.000]  Я использую уже такая тренология.
[02:34.000 --> 02:36.000]  Считаю, что это очень интересно.
[02:36.000 --> 02:38.000]  Иногда я даже не понимаю эту тренологию,
[02:38.000 --> 02:40.000]  но все-таки источник, первый источник,
[02:40.000 --> 02:42.000]  остается английским.
[02:42.000 --> 02:44.000]  Английская тренология, она, мне кажется,
[02:44.000 --> 02:46.000]  тоже важна для того, чтобы
[02:46.000 --> 02:50.000]  читать и общаться все-таки на форумах
[02:50.000 --> 02:52.000]  и на слаке.
[02:52.000 --> 02:54.000]  Потому что много очень каналов на слаке,
[02:54.000 --> 02:56.000]  здесь очень много.
[02:56.000 --> 02:58.000]  И это очень интересно,
[02:58.000 --> 03:00.000]  потому что это очень интересно,
[03:00.000 --> 03:02.000]  потому что это очень интересно,
[03:02.000 --> 03:04.000]  потому что это очень интересно,
[03:04.000 --> 03:06.000]  потому что много очень каналов на слаке,
[03:06.000 --> 03:12.000]  здесь тоже третий по датаспейс различных.
[03:12.000 --> 03:16.000]  Поэтому английский.
[03:16.000 --> 03:18.000]  Много себе.
[03:18.000 --> 03:20.000]  Я работаю в IT уже 14 лет.
[03:20.000 --> 03:22.000]  У меня такой опыт, наверное, интересный,
[03:22.000 --> 03:24.000]  с одной стороны.
[03:24.000 --> 03:26.000]  Потому что я начал буквально
[03:26.000 --> 03:30.000]  с простых очень работ,
[03:30.000 --> 03:32.000]  с простых карьер,
[03:32.000 --> 03:34.000]  по крайней мере, просто простая.
[03:34.000 --> 03:36.000]  Начал работать в университете.
[03:36.000 --> 03:38.000]  Сказать, у меня два
[03:38.000 --> 03:40.000]  высших технических образования.
[03:40.000 --> 03:42.000]  Одно в поучиваю средней азии,
[03:42.000 --> 03:44.000]  другое у меня в Москве, в Баманке.
[03:44.000 --> 03:46.000]  Но во время первого университета
[03:46.000 --> 03:48.000]  я начал работать,
[03:48.000 --> 03:50.000]  я, по моему, со второго курса
[03:50.000 --> 03:52.000]  занимался технподдержкой.
[03:52.000 --> 03:54.000]  То есть, администрирование системы,
[03:54.000 --> 03:56.000]  администрирование компов.
[03:56.000 --> 03:58.000]  В то время я очень увлекался
[03:58.000 --> 04:00.000]  FreeBSD, которая, по сути,
[04:00.000 --> 04:06.000]  для меня было всем, хотя я хотел стать, именно, развиваться в плане security.
[04:06.000 --> 04:13.000]  Ну, раньше так получилось, что я начал работать в компаниях различных,
[04:13.000 --> 04:19.000]  когда учился в университете, и у меня на одно из мест работ случилось,
[04:19.000 --> 04:25.000]  так что руководитель мой ушел в другую компанию, меня просили его заменить.
[04:25.000 --> 04:29.000]  Ну, вот с момента началась моя карьера к менеджеру,
[04:29.000 --> 04:35.000]  руководителя сначала группы, отдела, департамента, ну, и так дальше поехал.
[04:35.000 --> 04:40.000]  Потом начал уже работать, был отработал в IT-консалтинге,
[04:40.000 --> 04:47.000]  тоже создавая свою группу, ну, собственную команду и селфи-инженеров,
[04:47.000 --> 04:51.000]  и таких продажников, и разработчиков также.
[04:51.000 --> 04:55.000]  Мы делали custom development, и продавали там outsourcing,
[04:55.000 --> 04:58.000]  и делали строение архитектуры.
[04:58.000 --> 05:04.000]  И потом, когда уже переехал в Канаду, уже здесь тоже так случилось,
[05:04.000 --> 05:08.000]  что моим первым местом работы был банк.
[05:08.000 --> 05:13.000]  На самом деле на банке вообще не ориентировался, мне было как-то неинтересно работать в банке,
[05:13.000 --> 05:21.000]  мне хотелось именно погрузиться в такой мир дата, который здесь сильно бурлит
[05:21.000 --> 05:24.000]  и развивается в небольшую компанию.
[05:24.000 --> 05:28.000]  Ну, так получилось, наверное, сложилось, что я начал работать в банке,
[05:28.000 --> 05:30.000]  и там тоже все взвертелось.
[05:30.000 --> 05:33.000]  Сначала у меня было два разработчика,
[05:33.000 --> 05:38.000]  мы начали делать интеграцию, ну, в общем, простая задача по интеграции
[05:38.000 --> 05:46.000]  с ITSM-системы, с системой распознавания инцидентов,
[05:46.000 --> 05:49.000]  то есть некий такой ML-модель по управлению инцидентами,
[05:49.000 --> 05:53.000]  то есть предректов модели, как управлять инцидентами.
[05:53.000 --> 05:58.000]  Ну, потом приснился в команду Big Data в банке,
[05:58.000 --> 06:03.000]  где вот, соответственно, было тоже три developer, они были на контракте,
[06:03.000 --> 06:06.000]  и задача стояла, думаю, глобально.
[06:06.000 --> 06:13.000]  Мы все должны были данные, которые, все различные источники данных внутри банка,
[06:13.000 --> 06:17.000]  то есть загрузить в Hadoop environment, то есть Hadoop,
[06:17.000 --> 06:21.000]  в то время мы использовали HDP, Hortonworks,
[06:21.000 --> 06:24.000]  который был довольно-таки стильно мощным инструментом,
[06:24.000 --> 06:26.000]  который купил компанию Haudera.
[06:26.000 --> 06:31.000]  И там началось просто реально активное загружение в Data
[06:31.000 --> 06:40.000]  различными proprietary tools, то есть IBM, это Data Stage,
[06:40.000 --> 06:46.000]  это был NPIF, который был, по сути, написан на Spring XD,
[06:46.000 --> 06:50.000]  который уже умер, но до сих пор живет.
[06:50.000 --> 06:55.000]  Были также, когда вот уже уходил из банка,
[06:55.000 --> 07:02.000]  мы назвали миграция всех legacy system framework, ETL frameworks на Talent.
[07:02.000 --> 07:04.000]  Если вы не слышали про Talent, посмотрите,
[07:04.000 --> 07:06.000]  вот довольно-таки очень интересный tool,
[07:06.000 --> 07:11.000]  они развивают его как опенсорсно, так и коммерческое решение.
[07:11.000 --> 07:15.000]  Даже в опенсорсном решении его можно использовать для различных целей.
[07:15.000 --> 07:18.000]  Он написан на Java, поэтому и делает его супермощным,
[07:18.000 --> 07:22.000]  у него очень много коннекторов для различных источников данных,
[07:22.000 --> 07:25.000]  врачных баз данных, включается на УРА,
[07:25.000 --> 07:28.000]  то есть надо делать, например, настройки в опенсорсе.
[07:28.000 --> 07:31.000]  В коммерческой версии там уже все немного подготовлено,
[07:31.000 --> 07:37.000]  но верю, что вы сможете разобраться в опенсорсной версии на УРА.
[07:37.000 --> 07:43.000]  И сейчас, по сути, начал работать в IT компании,
[07:43.000 --> 07:49.000]  мы создаем applications, строим Data Lake, сейчас выбираем ли между IWS и GCP.
[07:49.000 --> 07:54.000]  Выбор непростой, потому что моя команда должна выбрать это решение
[07:54.000 --> 08:00.000]  и защитить острое стратегическое назначение на три года вперед
[08:00.000 --> 08:07.000]  со всеми там утекающими оттуда целями, задачами, как и по деньгам,
[08:07.000 --> 08:13.000]  то есть по финансовому части, так и по всевозможным интеграционным
[08:13.000 --> 08:17.000]  и до различных capabilities, то есть различным функциям, задачам,
[08:17.000 --> 08:19.000]  которым должна выполнять Data Lake.
[08:19.000 --> 08:24.000]  То есть это, конечно же, ML, это AI, который здесь тоже активно развивается,
[08:24.000 --> 08:27.000]  но также в Москве, безусловно.
[08:27.000 --> 08:32.000]  Ну, наверное, все такое длинное, вводное про меня.
[08:32.000 --> 08:39.000]  Если хотите посмотреть или законатиться, здесь моя ссылка, LinkedIn,
[08:39.000 --> 08:43.000]  буду очень рад пообщаться в офлайне.
[08:43.000 --> 08:47.000]  Юра, тебе слово, давай ты про себя.
[08:47.000 --> 08:51.000]  Тебе тоже громадный опыт разработчика, поделись, пожалуйста, этим.
[08:51.000 --> 08:54.000]  Добрый день. Меня зовут Буковский Юрий.
[08:54.000 --> 08:59.000]  Программист, опыт не многим более 20-ти лет.
[08:59.000 --> 09:04.000]  В основном это было веб-роботы и с обратно стороны веб-программирование,
[09:04.000 --> 09:09.000]  интеграционные какие-то решения между различными системами.
[09:09.000 --> 09:17.000]  Даже там были блокчейны новомодные и прочие некуда модные вещи.
[09:17.000 --> 09:22.000]  Ну и решения в области больших объемов данных.
[09:22.000 --> 09:27.000]  То, чем в последнее время больше занимаюсь скорее.
[09:27.000 --> 09:33.000]  В частности, это генетика, которая тоже сейчас набирает популярность.
[09:33.000 --> 09:38.000]  И вот, чуть забегая вперед, один из примеров будет именно из генетики,
[09:38.000 --> 09:41.000]  потому что это характерный пример.
[09:41.000 --> 09:46.000]  Работал в различных организациях, практически все в Москве,
[09:46.000 --> 09:51.000]  парочки только зарубежных. Ну и, пожалуй, все.
[09:51.000 --> 09:56.000]  Хорошо, спасибо. Ребят, может быть, кто-то из вас расскажет про вас,
[09:56.000 --> 10:00.000]  про вашу кафедру, что вы сейчас изучаете.
[10:00.000 --> 10:04.000]  Какие у вас сейчас интересные, наверное, в плане обучения.
[10:04.000 --> 10:08.000]  Ну, немного такую вводную, если бы вы сможете дать, было бы здорово.
[10:18.000 --> 10:21.000]  Есть желающие? Нет?
[10:21.000 --> 10:27.000]  Ну, вот это можно по-разному. Я, в общем, это не студент уже.
[10:27.000 --> 10:33.000]  Я тоже один из семинаристов и, по сути, один из лекторов предыдущей части курса.
[10:33.000 --> 10:37.000]  Вот, поэтому я не знаю, можно ли мне…
[10:37.000 --> 10:41.000]  Конечно, можно. Раз находитесь здесь, конечно, можно.
[10:41.000 --> 10:45.000]  Да, да. Я, на самом деле, тоже заинтересовался, пришел на лекцию,
[10:45.000 --> 10:48.000]  заинтересовался, потому что сам-то работал тоже в EKS.
[10:48.000 --> 10:52.000]  Но я работал в EKS Big Data с точки зрения организации инфраструктуры
[10:52.000 --> 10:55.000]  для преподавания курсов по Big Data.
[10:55.000 --> 10:59.000]  То есть, не связанную с тем, что именно работать на больших данных
[10:59.000 --> 11:02.000]  каким-то специфичным образом, а именно настраиваться так,
[11:02.000 --> 11:05.000]  чтобы люди попытались вкатываться в инфраструктуру,
[11:05.000 --> 11:07.000]  ну, именно в инфраструктуру Big Data.
[11:07.000 --> 11:13.000]  То есть, были опыты сбора кластеров в Docker образах
[11:13.000 --> 11:15.000]  и аргистрация этого всего дела.
[11:15.000 --> 11:19.000]  Ну, для того, чтобы ребята, которые хотели проходить курсы на курсере,
[11:19.000 --> 11:21.000]  это могли сделать.
[11:21.000 --> 11:23.000]  Ну, здорово.
[11:23.000 --> 11:24.000]  Да.
[11:24.000 --> 11:27.000]  Вы используете Databricks как кладное решение?
[11:27.000 --> 11:32.000]  То есть, там, по сути, можно заводить несколько десятков аккаунтов
[11:32.000 --> 11:35.000]  для тестирования, и там все готово, в принципе, вот.
[11:35.000 --> 11:38.000]  По-моему, когда мы это делали, это было несколько лет назад,
[11:38.000 --> 11:40.000]  по-моему, в Docker.
[11:40.000 --> 11:43.000]  По-моему, когда мы это делали, это было несколько лет назад,
[11:43.000 --> 11:46.000]  по-моему, Databricks еще не настолько был раскрученный.
[11:46.000 --> 11:48.000]  Сейчас они мега-раскручены.
[11:48.000 --> 11:50.000]  Сейчас они мега-раскручены.
[11:50.000 --> 11:55.000]  Да, они мега-раскручены сейчас, но тогда, по-моему, там,
[11:55.000 --> 11:58.000]  в то время еще инфраструктура около сырой находилась,
[11:58.000 --> 12:01.000]  поэтому все искали так или иначе решения.
[12:01.000 --> 12:03.000]  Ну, понятно.
[12:03.000 --> 12:05.000]  Ясно.
[12:05.000 --> 12:06.000]  Ну, окей.
[12:06.000 --> 12:09.000]  А еще хотел бы добавить, что я не программист на Spark,
[12:09.000 --> 12:14.000]  потому что у меня такая большая governance часть,
[12:14.000 --> 12:16.000]  натурная часть.
[12:16.000 --> 12:20.000]  Поэтому, Юра, по большей части по программированию,
[12:20.000 --> 12:24.000]  я приступал к изучению программирования на Python,
[12:24.000 --> 12:29.000]  то есть Python Spark Scala, но это не уровень такого разработчика,
[12:29.000 --> 12:33.000]  который может делать какие-то серьезные разработки.
[12:33.000 --> 12:37.000]  Это basic часть, конечно, да, но, точнее basics, да,
[12:37.000 --> 12:39.000]  но просто по разработке.
[12:39.000 --> 12:44.000]  Поэтому я бы хотел с вами поделиться именно своим опытом
[12:44.000 --> 12:49.000]  исходя из своих мест работы,
[12:49.000 --> 12:52.000]  посмотреть, насколько это вам будет интересно
[12:52.000 --> 12:54.000]  поискутировать на различные темы,
[12:54.000 --> 12:58.000]  которые здесь у нас есть в нашем деке презентации.
[12:58.000 --> 13:03.000]  Узнать ваше мнение по Spark,
[13:03.000 --> 13:07.000]  почему именно Spark такой популярный,
[13:07.000 --> 13:10.000]  почему не Flink, почему вот именно Spark?
[13:10.000 --> 13:15.000]  И какие задачи вы планируете решать с помощью Spark?
[13:15.000 --> 13:17.000]  Самое главное.
[13:17.000 --> 13:21.000]  То есть Spark звучит для того, что он сейчас популярный,
[13:21.000 --> 13:23.000]  или потому что все-таки есть конкретные задачи,
[13:23.000 --> 13:25.000]  которые вы знаете, которые он решает?
[13:25.000 --> 13:27.000]  На этот вопрос нужно иметь четкий ответ,
[13:27.000 --> 13:31.000]  потому что Spark не является потенцией от всех,
[13:31.000 --> 13:36.000]  не от всех бед, но не для всех случаев, точно.
[13:36.000 --> 13:40.000]  Нет, ну понятно, давайте тогда я это представлю.
[13:40.000 --> 13:45.000]  У нас такое первое ознакомление именно с миром Big Data на курсе происходит,
[13:45.000 --> 13:50.000]  поэтому, наверное, мы просто посвящаем сейчас всех нас
[13:50.000 --> 13:53.000]  вообще во все сферы, которые есть на текущий момент,
[13:53.000 --> 13:56.000]  для того чтобы, если что, потом можно было углубиться.
[13:56.000 --> 13:59.000]  То есть у нас курс получается и немножко
[13:59.000 --> 14:01.000]  в разработку параллельных систем,
[14:01.000 --> 14:04.000]  то есть всякие MPA, CUDA и прочее.
[14:04.000 --> 14:07.000]  И вот есть такой Big Data Stack.
[14:07.000 --> 14:09.000]  То есть это курс такой, если настраиваться,
[14:09.000 --> 14:11.000]  то это ознакомительный курс.
[14:11.000 --> 14:13.000]  Ну хорошо, да.
[14:13.000 --> 14:15.000]  Ну здорово тогда.
[14:15.000 --> 14:19.000]  Надеюсь, мое присутствие вам как-то поможет
[14:19.000 --> 14:22.000]  углубиться в мир Big Data,
[14:22.000 --> 14:26.000]  посмотреть на него немного с точки зрения
[14:27.000 --> 14:33.000]  через мой угол рассмотрения тех решений
[14:33.000 --> 14:36.000]  и их использования.
[14:36.000 --> 14:40.000]  Ну и подтолкнет вас к изучению каких-то
[14:40.000 --> 14:42.000]  интересных инструментов.
[14:42.000 --> 14:45.000]  В плане того, что Spark, по сути, да,
[14:45.000 --> 14:47.000]  крутой инструмент, можно все делать в Spark,
[14:47.000 --> 14:50.000]  но есть также еще различные другие инструменты.
[14:50.000 --> 14:54.000]  И в частности, я бы призвал посмотреть вас
[14:54.000 --> 14:59.000]  на Apache Flink также как альтернатива.
[14:59.000 --> 15:01.000]  Ладно, давайте начнем.
[15:01.000 --> 15:02.000]  Спасибо большое, Павел,
[15:02.000 --> 15:05.000]  что дали такую вводную небольшую.
[15:05.000 --> 15:08.000]  Если кто-то еще хочет что-то сказать,
[15:08.000 --> 15:11.000]  пожалуйста, не стесняйтесь, давайте общаться.
[15:11.000 --> 15:13.000]  Потому что это интерактивный курс,
[15:13.000 --> 15:17.000]  если нет задач прямо читать без остановки,
[15:17.000 --> 15:21.000]  скажем, вносить вас в какую-то информацию,
[15:21.000 --> 15:23.000]  хотя бы делать это больше интерактивно,
[15:23.000 --> 15:25.000]  через дискуссия.
[15:25.000 --> 15:29.000]  Я бы дополнил по поводу Flink.
[15:29.000 --> 15:32.000]  То есть действительно стоит посмотреть на него,
[15:32.000 --> 15:35.000]  потому что в нем при разработке учитывались
[15:35.000 --> 15:37.000]  болезни Spark.
[15:37.000 --> 15:42.000]  Spark был одним из первых массовых инструментов
[15:42.000 --> 15:45.000]  универсальных инструментов
[15:45.000 --> 15:47.000]  обработки как небольших данных,
[15:47.000 --> 15:49.000]  так и больших распределенных.
[15:49.000 --> 15:53.000]  И во Flink это было, скажем так, учтено,
[15:53.000 --> 15:56.000]  потому, скорее всего, когда он будет
[15:56.000 --> 15:58.000]  наберет такую же популярность, как Spark,
[15:58.000 --> 16:02.000]  он будет, наверное, более удобен в использовании.
[16:02.000 --> 16:06.000]  То есть те же самые потоки в Spark,
[16:06.000 --> 16:08.000]  они устроены микробачами.
[16:08.000 --> 16:12.000]  А во Flink это реальные потоки,
[16:12.000 --> 16:19.000]  которые ориентированы на единичную запись.
[16:19.000 --> 16:21.000]  Вот так же, как, допустим, если кто слышал
[16:21.000 --> 16:23.000]  про такой Apache Storm,
[16:23.000 --> 16:26.000]  он, в принципе, уже не используется.
[16:26.000 --> 16:29.000]  То есть это по сути была комбинация
[16:29.000 --> 16:31.000]  из двух решений.
[16:31.000 --> 16:33.000]  Это относительно Flink.
[16:33.000 --> 16:35.000]  Я с ним, честно говоря, еще не работал,
[16:35.000 --> 16:37.000]  только ознакомился.
[16:37.000 --> 16:39.000]  Но тоже смотрю в эту сторону,
[16:39.000 --> 16:41.000]  и тоже думаю, что у него потенциал будет
[16:41.000 --> 16:43.000]  больше просто потому, что это продукт
[16:43.000 --> 16:46.000]  сделан на основе ошибок другого продукта.
[16:46.000 --> 16:47.000]  Да, совершенно верно.
[16:47.000 --> 16:49.000]  То есть мы должны начать изучать Flink
[16:49.000 --> 16:51.000]  в нашем проекте MAMAM, AWS,
[16:51.000 --> 16:53.000]  по сравнению Data Lake на AWS.
[16:53.000 --> 16:57.000]  И там Apache Flink интересные штуки может делать.
[16:57.000 --> 16:59.000]  Ну ладно, давайте не будем про Flink,
[16:59.000 --> 17:02.000]  давайте сейчас про Spark, про нашу тему.
[17:02.000 --> 17:06.000]  То есть что хотелось сказать этим слайдам?
[17:06.000 --> 17:09.000]  Здесь у нас такая немного историческая
[17:09.000 --> 17:12.000]  вводная экскурсус в историю.
[17:12.000 --> 17:14.000]  Потому что историю тоже надо знать,
[17:14.000 --> 17:16.000]  понимать, с чего началось.
[17:16.000 --> 17:18.000]  Ну, здесь до 2016 года,
[17:18.000 --> 17:20.000]  потому что дальше уже там
[17:20.000 --> 17:22.000]  просто уже вот так пошло все вверх.
[17:22.000 --> 17:26.000]  Разве различные технологии начали,
[17:26.000 --> 17:28.000]  просто, например, бешеный оборот.
[17:28.000 --> 17:30.000]  Ну, началось, конечно, все с Google.
[17:30.000 --> 17:32.000]  1998 год.
[17:32.000 --> 17:34.000]  Первый, наверное, аккаунт, вспомните,
[17:34.000 --> 17:36.000]  на Gmail раздавались приватно.
[17:36.000 --> 17:43.000]  Приватно те, кто получил первые приглашения.
[17:43.000 --> 17:45.000]  У них есть уникальный Gmail аккаунт,
[17:45.000 --> 17:47.000]  имя, фамилия.
[17:47.000 --> 17:49.000]  Все началось оттуда,
[17:49.000 --> 17:52.000]  потому что на Google они были первые открывателями
[17:52.000 --> 17:59.000]  именно distributed data systems,
[17:59.000 --> 18:03.000]  то есть разделение нагрузки на системы,
[18:03.000 --> 18:06.000]  используя commodity software hardware,
[18:06.000 --> 18:10.000]  то есть не используя те proprietary железо,
[18:10.000 --> 18:12.000]  то есть HP, IBM,
[18:12.000 --> 18:14.000]  мегамонстров,
[18:14.000 --> 18:16.000]  тем же самым MainFrame,
[18:16.000 --> 18:18.000]  которые IBM сейчас,
[18:18.000 --> 18:20.000]  если посмотрите на Северную Америку,
[18:20.000 --> 18:22.000]  все сидят здесь, на крупной компании,
[18:22.000 --> 18:24.000]  все сидят на IBM-овских MainFrame.
[18:24.000 --> 18:26.000]  Даже некоторые говорят,
[18:26.000 --> 18:28.000]  что IBM MainFrame это было просто
[18:28.000 --> 18:31.000]  начало самого Cloud решения.
[18:31.000 --> 18:34.000]  То есть они были тоже первыми открывателями,
[18:34.000 --> 18:36.000]  в частности, computation,
[18:36.000 --> 18:39.000]  развлечения computation от storage,
[18:39.000 --> 18:41.000]  потому что их система это совершенно другой
[18:41.000 --> 18:43.000]  параллельный мир, как работа MainFrame.
[18:43.000 --> 18:45.000]  Довольно-таки я хочу сказать,
[18:45.000 --> 18:48.000]  что работа в банке
[18:48.000 --> 18:50.000]  и имея, скажем, контакт с людьми,
[18:50.000 --> 18:52.000]  которые работают с MainFrame,
[18:52.000 --> 18:56.000]  с MainFrame с ними довольно-таки интересно было пообщаться,
[18:56.000 --> 18:58.000]  интересная система,
[18:58.000 --> 19:02.000]  но их развитие, наверное, уже затухает.
[19:02.000 --> 19:05.000]  Но, как я уже говорил,
[19:05.000 --> 19:08.000]  здесь, в Северной Америке, даже в Европе,
[19:08.000 --> 19:10.000]  то есть биржевые все,
[19:10.000 --> 19:13.000]  то есть Nasdaq,
[19:13.000 --> 19:15.000]  европейские,
[19:15.000 --> 19:17.000]  те биржевые не сидят на MainFrame,
[19:17.000 --> 19:19.000]  потому что довольно-таки устойчивая платформа.
[19:19.000 --> 19:21.000]  Так, вернемся к Google.
[19:21.000 --> 19:23.000]  Что он Google нам дал?
[19:23.000 --> 19:25.000]  Ну, в 2003 году вышел MapReduce.
[19:25.000 --> 19:27.000]  Все, наверное, слышали про MapReduce.
[19:27.000 --> 19:29.000]  То есть, как данные читаются,
[19:29.000 --> 19:31.000]  потому что им нужно было
[19:31.000 --> 19:33.000]  быстро иметь доступ к данным,
[19:33.000 --> 19:35.000]  чтобы создать свой Google.
[19:35.000 --> 19:38.000]  Один из таких примеров.
[19:40.000 --> 19:44.000]  Потом вышел сам Hadoop уже через 3 года.
[19:44.000 --> 19:47.000]  Yahoo запустил этот
[19:47.000 --> 19:50.000]  paper про Hadoop.
[19:50.000 --> 19:52.000]  Если интересно, почитайте.
[19:52.000 --> 19:54.000]  Там довольно-таки, я бы сказал,
[19:54.000 --> 19:56.000]  в этих статьях, в этих паперах,
[19:56.000 --> 19:58.000]  то есть white papers про эти времена,
[19:58.000 --> 20:00.000]  там не только рассказано про технологию,
[20:00.000 --> 20:02.000]  как они видят ее,
[20:02.000 --> 20:04.000]  но и как они видят ее развитие.
[20:04.000 --> 20:06.000]  Поэтому, если есть время,
[20:06.000 --> 20:08.000]  обязательно, обязательно почитайте.
[20:08.000 --> 20:10.000]  Там есть много что интересного,
[20:10.000 --> 20:12.000]  можно узнать.
[20:12.000 --> 20:14.000]  Даже если там будет старая версия уже,
[20:14.000 --> 20:16.000]  никто не сваливает на MapReduce уже, по сути.
[20:16.000 --> 20:18.000]  Но взгляд именно с тех разработчиков,
[20:18.000 --> 20:21.000]  которые, по сути,
[20:21.000 --> 20:24.000]  визженеры, инженеров,
[20:24.000 --> 20:26.000]  он довольно-таки интересный.
[20:26.000 --> 20:28.000]  Ну, дальше началось,
[20:28.000 --> 20:30.000]  дальше Маттея Заккери,
[20:30.000 --> 20:32.000]  который тоже выходится из Канады,
[20:32.000 --> 20:34.000]  то есть не тоже,
[20:34.000 --> 20:36.000]  а выходится из Канады,
[20:36.000 --> 20:38.000]  он закончил университет здесь,
[20:38.000 --> 20:40.000]  в Ботталу,
[20:40.000 --> 20:42.000]  потом перешел в Беркли,
[20:42.000 --> 20:44.000]  в Стэнфорде.
[20:44.000 --> 20:46.000]  И вот там началась у него
[20:46.000 --> 20:48.000]  идея создать вот этот Spark.
[20:48.000 --> 20:50.000]  По-моему, это был
[20:50.000 --> 20:52.000]  человек десять,
[20:52.000 --> 20:54.000]  которые участвовали в этом проекте.
[20:54.000 --> 20:56.000]  Он часто проводит
[20:56.000 --> 20:58.000]  много встреч,
[20:58.000 --> 21:00.000]  но до пандемии здесь проводил много встреч
[21:00.000 --> 21:02.000]  по этапов,
[21:02.000 --> 21:04.000]  где он сам принимал участие,
[21:04.000 --> 21:06.000]  находил время, то есть это было здорово,
[21:06.000 --> 21:08.000]  с ним пообщаться.
[21:08.000 --> 21:10.000]  Очень потрясающий тоже человек,
[21:10.000 --> 21:12.000]  у него много очень интересных идей,
[21:12.000 --> 21:14.000]  поэтому если тоже
[21:14.000 --> 21:16.000]  будет вам интересно,
[21:16.000 --> 21:18.000]  посмотрите его записи на YouTube,
[21:18.000 --> 21:20.000]  его точки,
[21:20.000 --> 21:22.000]  его взгляды,
[21:22.000 --> 21:24.000]  его прям, его
[21:24.000 --> 21:26.000]  как бы идеи
[21:26.000 --> 21:28.000]  по развитию дальше
[21:28.000 --> 21:30.000]  датапроцессинга, датинжиниринга
[21:30.000 --> 21:32.000]  и, в общем,
[21:32.000 --> 21:34.000]  в целом, big data.
[21:34.000 --> 21:36.000]  Ну дальше пойдем
[21:36.000 --> 21:38.000]  быстрее, дальше там что?
[21:38.000 --> 21:40.000]  Spark развивался, создался RDD,
[21:40.000 --> 21:42.000]  Resilient Data Distributed Data Sets,
[21:42.000 --> 21:44.000]  то есть то, что лежит в основе
[21:44.000 --> 21:46.000]  на Spark.
[21:46.000 --> 21:48.000]  Потом Spark присоединился уже к Apache
[21:48.000 --> 21:50.000]  и, по сути, с этого момента
[21:50.000 --> 21:52.000]  стал самым популярным, самым
[21:52.000 --> 21:54.000]  востребованным
[21:54.000 --> 21:56.000]  больше всего комитов
[21:56.000 --> 21:58.000]  в этот фондейшн,
[21:58.000 --> 22:00.000]  в Apache Foundation
[22:00.000 --> 22:02.000]  до сих пор в мире
[22:02.000 --> 22:04.000]  осуществляется,
[22:04.000 --> 22:06.000]  то есть самый развивающий проект Apache является он.
[22:08.000 --> 22:10.000]  Ну и дальше уже пошли в развитие Spark
[22:10.000 --> 22:12.000]  в плане ввода по депутатегу,
[22:12.000 --> 22:14.000]  то есть это вот Spark SQL,
[22:14.000 --> 22:16.000]  Graphics,
[22:16.000 --> 22:18.000]  ну и так далее, то есть там
[22:18.000 --> 22:20.000]  Deep Learning, кстати, тоже вот этот 5.1 Deep Learning,
[22:20.000 --> 22:22.000]  который также был разработан
[22:22.000 --> 22:24.000]  профессором,
[22:24.000 --> 22:26.000]  канадский профессором Waterloo
[22:26.000 --> 22:28.000]  по Deep Learning,
[22:28.000 --> 22:30.000]  там чисто математика.
[22:30.000 --> 22:32.000]  Мне кажется, вам это будет очень, тоже
[22:32.000 --> 22:34.000]  интересно и, наверное,
[22:34.000 --> 22:36.000]  больше все будет понятно также.
[22:36.000 --> 22:38.000]  Так, ну, наверное,
[22:38.000 --> 22:40.000]  экскру в истории, наверное, все. Есть ли какие-то вопросы у вас?
[22:40.000 --> 22:42.000]  Есть ли какие-то
[22:44.000 --> 22:46.000]  не знаю,
[22:46.000 --> 22:48.000]  точнее, где вы хотели спросить, что там?
[22:56.000 --> 22:58.000]  Ну, что здесь?
[22:58.000 --> 23:00.000]  Все началось, как я сказал,
[23:00.000 --> 23:02.000]  с Apache,
[23:02.000 --> 23:04.000]  с Hadoop, MapReduce
[23:04.000 --> 23:06.000]  использовался,
[23:06.000 --> 23:08.000]  потрясающая штука была,
[23:08.000 --> 23:10.000]  ну, есть, используется еще в многих компаниях.
[23:10.000 --> 23:12.000]  Было дешево и сердито
[23:12.000 --> 23:14.000]  установить,
[23:14.000 --> 23:16.000]  там, устроить Hadoop.
[23:18.000 --> 23:20.000]  Hadoop был бесплатный,
[23:20.000 --> 23:22.000]  до сих пор бесплатный,
[23:22.000 --> 23:24.000]  если хотите использовать
[23:24.000 --> 23:26.000]  консорсную версию,
[23:26.000 --> 23:28.000]  если это какая-то
[23:28.000 --> 23:30.000]  proprietary, то это только Caldera.
[23:30.000 --> 23:32.000]  То есть Caldera является единственным сейчас таким
[23:32.000 --> 23:34.000]  до сих пор
[23:34.000 --> 23:36.000]  лидером на рынке
[23:36.000 --> 23:38.000]  коммерческого Hadoop,
[23:38.000 --> 23:40.000]  и если
[23:40.000 --> 23:42.000]  хотите как-то
[23:42.000 --> 23:44.000]  врубиться в мир Hadoop,
[23:44.000 --> 23:46.000]  то очень призываю активно
[23:46.000 --> 23:48.000]  только на Caldera,
[23:48.000 --> 23:50.000]  потому что у них
[23:50.000 --> 23:52.000]  просто уже все есть,
[23:52.000 --> 23:54.000]  не надо спать на
[23:54.000 --> 23:56.000]  грабли, которые там другие могут
[23:56.000 --> 23:58.000]  сделать, используя подсорсный Hadoop.
[23:58.000 --> 24:00.000]  Но у них также есть куча материал
[24:00.000 --> 24:02.000]  по изучению их
[24:02.000 --> 24:04.000]  CDP-версии,
[24:04.000 --> 24:06.000]  Caldera Data Platform.
[24:06.000 --> 24:08.000]  Ну, почему у нас все WebReduce?
[24:08.000 --> 24:10.000]  Ну довольно-таки все просто,
[24:10.000 --> 24:12.000]  MapReduce,
[24:12.000 --> 24:14.000]  делаем
[24:14.000 --> 24:16.000]  mapping, делаем
[24:16.000 --> 24:18.000]  reducing, делаем
[24:18.000 --> 24:20.000]  получаем данные,
[24:20.000 --> 24:22.000]  они
[24:22.000 --> 24:24.000]  распределены по различным нодам,
[24:24.000 --> 24:26.000]  датонодам, есть
[24:26.000 --> 24:28.000]  nameNode, которые там 2 nameNodes,
[24:28.000 --> 24:30.000]  на standalone может быть,
[24:30.000 --> 24:32.000]  все это распределяется между собой,
[24:32.000 --> 24:34.000]  контролируется MapReduce
[24:34.000 --> 24:36.000]  по
[24:36.000 --> 24:38.000]  распределению
[24:38.000 --> 24:40.000]  мощностей, как мы
[24:40.000 --> 24:42.000]  сейчас не можем прочитать,
[24:42.000 --> 24:44.000]  Processing Hadoop MapReduce,
[24:44.000 --> 24:46.000]  это MR2, но
[24:46.000 --> 24:48.000]  первый MR в Дульнике был
[24:48.000 --> 24:50.000]  интересный с точки зрения
[24:50.000 --> 24:52.000]  перооткрывателей,
[24:52.000 --> 24:54.000]  потому что он написан полностью на джаве,
[24:54.000 --> 24:56.000]  если кто-то хотел дописать что-то,
[24:56.000 --> 24:58.000]  то он должен быть таким джавистом
[24:58.000 --> 25:00.000]  тамоза костей, чтобы что-то там
[25:00.000 --> 25:02.000]  променять, для
[25:02.000 --> 25:04.000]  собственного
[25:04.000 --> 25:06.000]  доработка MapReduce,
[25:06.000 --> 25:08.000]  что мешало очень сильно
[25:08.000 --> 25:10.000]  использовать
[25:10.000 --> 25:12.000]  MapReduce в качестве
[25:12.000 --> 25:14.000]  каких-то
[25:14.000 --> 25:16.000]  дополнительных функций,
[25:16.000 --> 25:18.000]  в качестве распределения
[25:18.000 --> 25:20.000]  мощностей, то есть распределение
[25:20.000 --> 25:22.000]  ресурсов
[25:22.000 --> 25:24.000]  кластера на
[25:24.000 --> 25:26.000]  определенные задачи.
[25:28.000 --> 25:30.000]  Юра, ты хочешь добавить
[25:30.000 --> 25:32.000]  здесь?
[25:32.000 --> 25:34.000]  Я бы добавил
[25:34.000 --> 25:36.000]  просто из теории,
[25:36.000 --> 25:38.000]  если
[25:38.000 --> 25:40.000]  само понятие MapReduce
[25:40.000 --> 25:42.000]  сложно для
[25:42.000 --> 25:44.000]  понимания, то это понятно
[25:44.000 --> 25:46.000]  просто при образовании, а Reduce это
[25:46.000 --> 25:48.000]  математическая свертка,
[25:48.000 --> 25:50.000]  то есть это применение
[25:50.000 --> 25:52.000]  чистой функции, то есть чистая функция высшего порядка,
[25:52.000 --> 25:54.000]  которая применяется к чистой функции,
[25:54.000 --> 25:56.000]  и нужно это было
[25:56.000 --> 25:58.000]  во-первых, для отсутствия состояния,
[25:58.000 --> 26:00.000]  потому что система была изначально распределена
[26:00.000 --> 26:02.000]  и держать состояние,
[26:02.000 --> 26:04.000]  тем более с блокировками и симфорами,
[26:04.000 --> 26:06.000]  это
[26:06.000 --> 26:08.000]  крайне сложно, есть еще такая
[26:08.000 --> 26:10.000]  каптиорема,
[26:10.000 --> 26:12.000]  которая соответственно
[26:12.000 --> 26:14.000]  обозначает ограничения
[26:14.000 --> 26:16.000]  в таких системах.
[26:20.000 --> 26:22.000]  И плюс еще к тому,
[26:22.000 --> 26:24.000]  что в распределённых системах
[26:24.000 --> 26:26.000]  могут быть сбои,
[26:26.000 --> 26:28.000]  то необходимо
[26:28.000 --> 26:30.000]  перезапуск
[26:30.000 --> 26:32.000]  определенных операций при сбоях.
[26:32.000 --> 26:34.000]  Соответственно, сбои не должны влиять
[26:34.000 --> 26:36.000]  на работу всей системы.
[26:36.000 --> 26:38.000]  Именно это одна из причин,
[26:38.000 --> 26:40.000]  почему использовался именно
[26:40.000 --> 26:42.000]  этот подход MapReduce,
[26:42.000 --> 26:44.000]  и к тому же это просто по себе достаточно простой,
[26:44.000 --> 26:46.000]  легко масштабируемый подход.
[26:46.000 --> 26:48.000]  Он же используется, кстати, и в Spark,
[26:48.000 --> 26:50.000]  но я не буду вперед забегать,
[26:50.000 --> 26:52.000]  пусть Игорь последовательно все расскажет.
[26:52.000 --> 26:54.000]  Да, он там большое различие,
[26:54.000 --> 26:56.000]  он используется в Spark и
[26:56.000 --> 26:58.000]  используется здесь изначально в ходу,
[26:58.000 --> 27:00.000]  потому что
[27:00.000 --> 27:02.000]  все знаете почему,
[27:02.000 --> 27:04.000]  потому что запись происходила на диске,
[27:04.000 --> 27:06.000]  а здесь по Spark все в памяти.
[27:06.000 --> 27:08.000]  То есть
[27:08.000 --> 27:10.000]  чтение с диска, сами понимаете,
[27:10.000 --> 27:12.000]  требует ресурсов, мощностей
[27:12.000 --> 27:14.000]  и времени,
[27:14.000 --> 27:16.000]  поэтому нефиксенно было.
[27:16.000 --> 27:18.000]  Ну, естественно, развитие пошло вперед,
[27:18.000 --> 27:20.000]  начали создавать,
[27:20.000 --> 27:22.000]  думать, как мы можем оптимизировать
[27:22.000 --> 27:24.000]  распределение задач
[27:24.000 --> 27:26.000]  и балансирование нагрузки
[27:26.000 --> 27:28.000]  на кластера, потому что самое,
[27:28.000 --> 27:30.000]  что у нас драгоценное,
[27:30.000 --> 27:32.000]  это computation.
[27:32.000 --> 27:34.000]  Storage уже не так был важен,
[27:34.000 --> 27:36.000]  сами понимаете,
[27:36.000 --> 27:38.000]  сейчас покупают там, не знаю,
[27:38.000 --> 27:40.000]  iPhone, можно уже
[27:40.000 --> 27:42.000]  получить один терабайт данных
[27:42.000 --> 27:44.000]  в одной коробочке, то есть это вообще
[27:44.000 --> 27:46.000]  колоссальное прорыв
[27:46.000 --> 27:48.000]  в технологиях по storage.
[27:48.000 --> 27:50.000]  Ну, а самое, что важно остается,
[27:50.000 --> 27:52.000]  то есть computation, но остается всегда.
[27:52.000 --> 27:54.000]  Поэтому
[27:54.000 --> 27:56.000]  был введен там MR2,
[27:56.000 --> 27:58.000]  то есть это
[27:58.000 --> 28:00.000]  yet another resource negotiator,
[28:00.000 --> 28:02.000]  который, интересно, делает
[28:02.000 --> 28:04.000]  распределение задач
[28:04.000 --> 28:06.000]  между кластикластерами, понимает, какие задачи,
[28:06.000 --> 28:08.000]  к какой ноде
[28:08.000 --> 28:10.000]  отдать для того, чтобы выполнить
[28:10.000 --> 28:12.000]  туальную задачу, когда мы делаем,
[28:12.000 --> 28:14.000]  когда мы называем функцию MapReduce.
[28:14.000 --> 28:16.000]  Вероятно добавить?
[28:16.000 --> 28:18.000]  Давай.
[28:18.000 --> 28:20.000]  Еще такой важный момент
[28:20.000 --> 28:22.000]  нужно обязательно отметить, что система
[28:22.000 --> 28:24.000]  распределенно состоит, собственно,
[28:24.000 --> 28:26.000]  из распределенных компьютеров.
[28:26.000 --> 28:28.000]  У каждого есть свою область памяти,
[28:28.000 --> 28:30.000]  то есть диска и память оперативная,
[28:30.000 --> 28:32.000]  RAM.
[28:32.000 --> 28:34.000]  И задача MapReduce
[28:34.000 --> 28:36.000]  не передавать данные,
[28:36.000 --> 28:38.000]  а передавать вычисления.
[28:38.000 --> 28:40.000]  Это, на самом деле, очень условная,
[28:40.000 --> 28:42.000]  только логическая передача,
[28:42.000 --> 28:44.000]  по факту работает как.
[28:44.000 --> 28:46.000]  На каждом узле есть какая-то порция данных,
[28:46.000 --> 28:48.000]  копии, обычно три копии,
[28:48.000 --> 28:50.000]  на других узлах.
[28:50.000 --> 28:52.000]  И планировщик, вот тот же, к примеру,
[28:52.000 --> 28:54.000]  Yarn или
[28:54.000 --> 28:56.000]  Standalone Mode
[28:56.000 --> 28:58.000]  для распределенного Spark,
[28:58.000 --> 29:00.000]  у него есть такой режим.
[29:00.000 --> 29:02.000]  Они, в первую очередь,
[29:02.000 --> 29:04.000]  отправляют
[29:04.000 --> 29:06.000]  задание выполнять
[29:06.000 --> 29:08.000]  операции над теми данными,
[29:08.000 --> 29:10.000]  которые находятся локально на узлах.
[29:10.000 --> 29:12.000]  И после того, как эти операции будут
[29:12.000 --> 29:14.000]  выполнены, тогда уже
[29:14.000 --> 29:16.000]  производится свертка с другими узлами,
[29:16.000 --> 29:18.000]  с которыми необходимо.
[29:18.000 --> 29:20.000]  То есть, суть всей этой распределенности системы
[29:20.000 --> 29:22.000]  в том, чтобы не гонять по сети данные,
[29:22.000 --> 29:24.000]  которые даже на быстрой сети будут
[29:24.000 --> 29:26.000]  все равно давать большую задержку,
[29:26.000 --> 29:28.000]  как минимум, за коллизии
[29:28.000 --> 29:30.000]  на пути,
[29:30.000 --> 29:34.000]  на сетевых путях.
[29:34.000 --> 29:36.000]  И по максимуму вычислений
[29:36.000 --> 29:38.000]  производится именно локально.
[29:38.000 --> 29:40.000]  То есть, на приходе ФС позволяет определить,
[29:40.000 --> 29:42.000]  на каком узле находится какой блок данных.
[29:42.000 --> 29:44.000]  И, собственно, планировщик это использует.
[29:44.000 --> 29:46.000]  То есть, он дает задание провести
[29:46.000 --> 29:48.000]  ряд операций на узле,
[29:48.000 --> 29:50.000]  имеющем данные данные,
[29:50.000 --> 29:52.000]  данные, набор данных.
[29:54.000 --> 29:56.000]  Такой очень важный момент
[29:56.000 --> 29:58.000]  нужно всегда учитывать.
[29:58.000 --> 30:00.000]  Спасибо, Юра.
[30:00.000 --> 30:02.000]  Так, ну,
[30:02.000 --> 30:04.000]  будем дальше тогда. Прямо придется, мне кажется, достаточно
[30:04.000 --> 30:06.000]  уже ничего интересного.
[30:08.000 --> 30:10.000]  Теперь про Patch Spark. Немного поговорим.
[30:10.000 --> 30:12.000]  Почему именно?
[30:12.000 --> 30:14.000]  Как он возник?
[30:14.000 --> 30:16.000]  Ну, какие у него, в самом деле, преимущества?
[30:16.000 --> 30:18.000]  То есть, в основу Spark
[30:18.000 --> 30:20.000]  лежит тот самый RDD,
[30:20.000 --> 30:22.000]  пищевой компонент,
[30:22.000 --> 30:24.000]  Resilient Distributed Data Set.
[30:24.000 --> 30:26.000]  Поддержка
[30:26.000 --> 30:28.000]  Spark
[30:28.000 --> 30:30.000]  сама написана на скале,
[30:30.000 --> 30:32.000]  но поддержка через API,
[30:32.000 --> 30:34.000]  через и билетеки,
[30:34.000 --> 30:38.000]  не MapReduce, конечно же,
[30:38.000 --> 30:40.000]  но и билетеки ML
[30:40.000 --> 30:42.000]  и SQL
[30:42.000 --> 30:44.000]  поддержка.
[30:44.000 --> 30:46.000]  Но также преимущество основное
[30:46.000 --> 30:48.000]  можно
[30:48.000 --> 30:50.000]  те, кто программирует на Пайтоне,
[30:50.000 --> 30:52.000]  используют Паспарчи,
[30:52.000 --> 30:54.000]  используют Python,
[30:54.000 --> 30:56.000]  Java, Scala.
[30:56.000 --> 30:58.000]  Самое интересное,
[30:58.000 --> 31:00.000]  что можно здесь подчеркнуть,
[31:00.000 --> 31:02.000]  то, что различие Java и Python,
[31:02.000 --> 31:04.000]  то, как они
[31:04.000 --> 31:06.000]  компилируются,
[31:06.000 --> 31:08.000]  то есть, эффективность при компиляции,
[31:08.000 --> 31:10.000]  то, что Python не компилируется,
[31:10.000 --> 31:12.000]  Java компилируется,
[31:12.000 --> 31:14.000]  соответственно, можно отловить плаги
[31:14.000 --> 31:16.000]  уже во время компиляции.
[31:16.000 --> 31:18.000]  Юра,
[31:18.000 --> 31:20.000]  Паспарко, что ты хочешь сказать
[31:20.000 --> 31:22.000]  по этому слайду?
[31:22.000 --> 31:24.000]  Добавить сложно.
[31:24.000 --> 31:26.000]  Единственное, что хотя бы добавить,
[31:26.000 --> 31:28.000]  что такой вот
[31:28.000 --> 31:30.000]  особенность,
[31:30.000 --> 31:32.000]  что если используется Python
[31:32.000 --> 31:34.000]  на каких-то
[31:34.000 --> 31:36.000]  операциях, которые не требуют
[31:36.000 --> 31:38.000]  вычисления, а не памяти,
[31:38.000 --> 31:40.000]  то с ним нужно быть осторожнее,
[31:40.000 --> 31:42.000]  потому что UDF, так называемый
[31:42.000 --> 31:44.000]  User Defined Function
[31:44.000 --> 31:46.000]  на Python, они будут
[31:46.000 --> 31:48.000]  как бы у них КПД ниже,
[31:48.000 --> 31:50.000]  соответственно, это может замедлять
[31:50.000 --> 31:52.000]  вычисление именно при использовании UDF,
[31:52.000 --> 31:54.000]  а так разницы
[31:54.000 --> 31:56.000]  сложно что-то добавить.
[31:56.000 --> 31:58.000]  Да, здесь
[31:58.000 --> 32:00.000]  по сути основные, скажем так,
[32:00.000 --> 32:02.000]  такой
[32:02.000 --> 32:04.000]  высокоуровневый
[32:04.000 --> 32:06.000]  определение Spark
[32:06.000 --> 32:08.000]  и выключение компонентов здесь
[32:08.000 --> 32:10.000]  отражено все на этом слайде.
[32:10.000 --> 32:12.000]  Если хотите знать, что
[32:12.000 --> 32:14.000]  одно определение, одно понятие,
[32:14.000 --> 32:16.000]  что такое Spark,
[32:16.000 --> 32:18.000]  в принципе, можно посмотреть
[32:18.000 --> 32:20.000]  на этот слайд и зафиксировать,
[32:20.000 --> 32:22.000]  дальше уже
[32:22.000 --> 32:24.000]  копаться в деталях.
[32:24.000 --> 32:26.000]  Поехали дальше.
[32:32.000 --> 32:34.000]  Здесь
[32:34.000 --> 32:36.000]  как я уже о ней говорил,
[32:36.000 --> 32:38.000]  здесь у нас идет
[32:38.000 --> 32:40.000]  небольшой экскурс в релизы,
[32:40.000 --> 32:42.000]  как он на
[32:42.000 --> 32:44.000]  наиболее стабил релиз, который сейчас
[32:44.000 --> 32:46.000]  начали использовать,
[32:46.000 --> 32:48.000]  мы здесь дальше в панке,
[32:48.000 --> 32:50.000]  в наших проектах, в List 1.6
[32:50.000 --> 32:52.000]  не три, не два,
[32:52.000 --> 32:54.000]  недавно вышел два,
[32:54.000 --> 32:56.000]  не адаптировали,
[32:56.000 --> 32:58.000]  потому что по различным причинам
[32:58.000 --> 33:00.000]  перепрыгивать
[33:00.000 --> 33:02.000]  версию на версию
[33:02.000 --> 33:04.000]  довольно-таки сложно.
[33:04.000 --> 33:06.000]  Если начали
[33:06.000 --> 33:08.000]  использовать 1.6,
[33:08.000 --> 33:10.000]  перейти на 2, в зависимости от
[33:10.000 --> 33:12.000]  платформы,
[33:12.000 --> 33:14.000]  которая работает Spark,
[33:14.000 --> 33:16.000]  например, Hadoop.
[33:18.000 --> 33:20.000]  Будет
[33:20.000 --> 33:22.000]  для
[33:22.000 --> 33:24.000]  производственных
[33:24.000 --> 33:26.000]  нужд, для
[33:26.000 --> 33:28.000]  проектов, которые уже запущены
[33:28.000 --> 33:30.000]  в продакшене,
[33:30.000 --> 33:32.000]  переход делать не просто.
[33:32.000 --> 33:34.000]  Там нужно
[33:34.000 --> 33:36.000]  делать
[33:36.000 --> 33:38.000]  нагрузочное тестирование, проверять
[33:38.000 --> 33:40.000]  совместимость бюллетек,
[33:40.000 --> 33:42.000]  чтобы сделать
[33:42.000 --> 33:44.000]  переход.
[33:44.000 --> 33:46.000]  Обычно
[33:46.000 --> 33:48.000]  редко делают переход.
[33:48.000 --> 33:50.000]  У нас уже с 1.6 на 2
[33:50.000 --> 33:52.000]  я не сталкиваюсь с этим.
[33:52.000 --> 33:54.000]  Можно делать,
[33:54.000 --> 33:56.000]  но это будет
[33:56.000 --> 33:58.000]  не то что рискованно,
[33:58.000 --> 34:00.000]  но проблематично.
[34:00.000 --> 34:02.000]  Если работает 1.6,
[34:02.000 --> 34:04.000]  достаточно функций, которые
[34:04.000 --> 34:06.000]  выполняют Spark 1.6
[34:06.000 --> 34:08.000]  без
[34:08.000 --> 34:10.000]  добытельных преимуществ Spark 2.
[34:10.000 --> 34:12.000]  Работка
[34:12.000 --> 34:14.000]  у них
[34:14.000 --> 34:16.000]  от
[34:20.000 --> 34:22.000]  пересмотра RDD
[34:22.000 --> 34:24.000]  была.
[34:24.000 --> 34:26.000]  2 версии
[34:26.000 --> 34:28.000]  2 и 3.
[34:28.000 --> 34:30.000]  2 и 3
[34:30.000 --> 34:32.000]  в США
[34:32.000 --> 34:34.000]  были основные
[34:34.000 --> 34:36.000]  изменения
[34:36.000 --> 34:38.000]  с внутренней кухней,
[34:38.000 --> 34:40.000]  а с 1 и 2 я даже не интересовался.
[34:40.000 --> 34:42.000]  С RDD
[34:42.000 --> 34:44.000]  за всю практику
[34:44.000 --> 34:46.000]  сталкивался один раз.
[34:46.000 --> 34:48.000]  Мне он абсолютно не нужен был.
[34:48.000 --> 34:50.000]  Да, RDD
[34:50.000 --> 34:52.000]  изначально был фаундэйшн,
[34:52.000 --> 34:54.000]  но не используют
[34:54.000 --> 34:56.000]  качество таком основного компонента,
[34:56.000 --> 34:58.000]  который являлся
[34:58.000 --> 35:00.000]  в Spark.
[35:04.000 --> 35:06.000]  Задавайте, пожалуйста,
[35:06.000 --> 35:08.000]  вопросы, если что-то
[35:08.000 --> 35:10.000]  непонятное или хотите,
[35:10.000 --> 35:12.000]  чтобы уточнить.
[35:12.000 --> 35:14.000]  Мы сейчас просто идем
[35:14.000 --> 35:16.000]  верхам и верхам проходим.
[35:16.000 --> 35:18.000]  Не хотелось
[35:18.000 --> 35:20.000]  погружаться
[35:20.000 --> 35:22.000]  в детали.
[35:22.000 --> 35:24.000]  Хотелось бы, исходя из ваших вопросов,
[35:24.000 --> 35:26.000]  наверное,
[35:26.000 --> 35:28.000]  что
[35:28.000 --> 35:30.000]  интересно больше
[35:30.000 --> 35:32.000]  рассмотреть про
[35:32.000 --> 35:34.000]  DataSight, DataFrame, RDD,
[35:34.000 --> 35:36.000]  что-то интересное про
[35:36.000 --> 35:38.000]  библиотеки,
[35:38.000 --> 35:40.000]  машин-леннинг библиотеки, либо еще что-то.
[35:40.000 --> 35:42.000]  Пожалуйста, задавайте вопросы.
[35:42.000 --> 35:44.000]  Давайте
[35:44.000 --> 35:46.000]  какую-то дискуссию,
[35:46.000 --> 35:48.000]  может быть, все будет
[35:48.000 --> 35:50.000]  по вашим вопросам.
[35:54.000 --> 35:56.000]  Думаю, было бы здорово уточнить
[35:56.000 --> 35:58.000]  про RDD.
[36:00.000 --> 36:02.000]  А что конкретно?
[36:04.000 --> 36:06.000]  Что это для чего
[36:06.000 --> 36:08.000]  используется?
[36:08.000 --> 36:10.000]  С понятием раньше
[36:10.000 --> 36:12.000]  не сталкивался.
[36:14.000 --> 36:16.000]  С понятием RDD.
[36:16.000 --> 36:18.000]  RDD это Distributed Data Set.
[36:18.000 --> 36:20.000]  Что он делает?
[36:20.000 --> 36:22.000]  Он распределяет
[36:22.000 --> 36:24.000]  сам
[36:24.000 --> 36:26.000]  процессинг данных
[36:26.000 --> 36:28.000]  на микробаче, чтобы делать
[36:28.000 --> 36:30.000]  процессинг данных
[36:30.000 --> 36:32.000]  и
[36:32.000 --> 36:34.000]  memory.
[36:34.000 --> 36:36.000]  У меня сколько нужно memory на каждый
[36:36.000 --> 36:38.000]  микробач.
[36:42.000 --> 36:44.000]  Юра, у тебя есть что добавить по RDD?
[36:44.000 --> 36:46.000]  Есть, да. Я бы немножко вперед
[36:46.000 --> 36:48.000]  забежал, потом можно вернуться к RDD.
[36:48.000 --> 36:50.000]  По факту, вот так называем
[36:50.000 --> 36:52.000]  Batch это набор записей.
[36:52.000 --> 36:54.000]  И набор записей в RDD,
[36:54.000 --> 36:56.000]  это, грубо говоря, таблица прямоугольная.
[36:56.000 --> 36:58.000]  Они не
[36:58.000 --> 37:00.000]  именованы.
[37:00.000 --> 37:02.000]  И если вот как бы чуть-чуть
[37:02.000 --> 37:04.000]  забежать вперед, на самом деле,
[37:04.000 --> 37:06.000]  это я в своей практике.
[37:06.000 --> 37:08.000]  Любая работа с данными,
[37:08.000 --> 37:10.000]  начиная со всем, что больше
[37:10.000 --> 37:12.000]  массива единичных элементов,
[37:12.000 --> 37:14.000]  все уже давно проработано
[37:14.000 --> 37:16.000]  в релиционной алгебре.
[37:16.000 --> 37:18.000]  То есть это то, что SQL,
[37:18.000 --> 37:20.000]  базы данных с релиционной SQL,
[37:20.000 --> 37:22.000]  если все с этим связанное.
[37:22.000 --> 37:24.000]  И по факту,
[37:24.000 --> 37:26.000]  опять же, это из практики,
[37:26.000 --> 37:28.000]  только не из теории,
[37:28.000 --> 37:30.000]  работать с релиционными данными
[37:30.000 --> 37:32.000]  гораздо удобнее. И когда они
[37:32.000 --> 37:34.000]  именованы, то есть колонки не имеют ни номера,
[37:34.000 --> 37:38.000]  а какие-либо имена,
[37:38.000 --> 37:40.000]  с ними работать
[37:40.000 --> 37:42.000]  гораздо проще, используя именно
[37:42.000 --> 37:44.000]  релиционную алгебру. То есть, опять же,
[37:44.000 --> 37:46.000]  повторюсь за забеганием вперед,
[37:46.000 --> 37:48.000]  переход от RDD к DataFrame,
[37:48.000 --> 37:50.000]  DataSet и Spark SQL
[37:50.000 --> 37:52.000]  это был вполне логичный
[37:52.000 --> 37:54.000]  переход, потому что
[37:54.000 --> 37:56.000]  есть уже наработанный
[37:56.000 --> 37:58.000]  математический аппарат,
[37:58.000 --> 38:00.000]  и очень много наработок как
[38:00.000 --> 38:02.000]  в программном плане, так и в теоретическом
[38:02.000 --> 38:04.000]  для работы с данными.
[38:04.000 --> 38:06.000]  То есть любая таблица,
[38:06.000 --> 38:08.000]  имеющая более одной колонки,
[38:08.000 --> 38:10.000]  это уже претендент на
[38:10.000 --> 38:13.000]  релиционную алгебру.
[38:13.000 --> 38:15.000]  Повторюсь, я немножко забежал вперед, но
[38:15.000 --> 38:17.000]  можно вернуться к RDD.
[38:17.000 --> 38:19.000]  Ну, я же говорю, RDD,
[38:19.000 --> 38:21.000]  оно, по сути, лежало в основе,
[38:21.000 --> 38:23.000]  оно оттуда началось,
[38:23.000 --> 38:25.000]  в принципе,
[38:25.000 --> 38:28.000]  помните, до предыдущих слайда
[38:28.000 --> 38:30.000]  начался Spark,
[38:30.000 --> 38:32.000]  то есть Spark Foundation,
[38:32.000 --> 38:34.000]  но там с
[38:34.000 --> 38:36.000]  скажем,
[38:36.000 --> 38:38.000]  с
[38:38.000 --> 38:40.000]  как с появлением
[38:40.000 --> 38:42.000]  открытия, я могу даже сказать,
[38:42.000 --> 38:44.000]  Spark SQL все много
[38:44.000 --> 38:46.000]  попростилось, то есть наверняка
[38:46.000 --> 38:48.000]  SQL сейчас является языком,
[38:48.000 --> 38:50.000]  который все владеют от
[38:50.000 --> 38:52.000]  Малого велика,
[38:52.000 --> 38:54.000]  строит запросы,
[38:54.000 --> 38:56.000]  по сути,
[38:56.000 --> 38:58.000]  это решило
[38:58.000 --> 39:00.000]  просто с него колоссальное количество
[39:00.000 --> 39:02.000]  недочетов,
[39:02.000 --> 39:04.000]  можно так сказать, наверное,
[39:04.000 --> 39:06.000]  и сложность работы RDD.
[39:06.000 --> 39:08.000]  Я бы сказал, сильно снизило
[39:08.000 --> 39:10.000]  пару ходов, потому что с RDD
[39:10.000 --> 39:12.000]  фрагментированными
[39:12.000 --> 39:14.000]  таблицами безымянными
[39:14.000 --> 39:16.000]  работе было неудобно и сложнее.
[39:18.000 --> 39:20.000]  Андрей, мы ответили на ваш вопрос?
[39:22.000 --> 39:24.000]  Да, спасибо.
[39:24.000 --> 39:26.000]  Отлично.
[39:26.000 --> 39:28.000]  Есть у человека вопрос у кого-то?
[39:30.000 --> 39:32.000]  Я, наверное, не то что
[39:32.000 --> 39:34.000]  вопрос сказал, я, может быть, больше
[39:34.000 --> 39:36.000]  понимания привнес, потому что
[39:36.000 --> 39:38.000]  у ребят
[39:38.000 --> 39:40.000]  знакомство с мап-редюсом, по сути,
[39:40.000 --> 39:42.000]  был не через Classic Java,
[39:42.000 --> 39:44.000]  а через стриминг.
[39:44.000 --> 39:46.000]  Поэтому
[39:46.000 --> 39:48.000]  наверное, как раз
[39:48.000 --> 39:50.000]  самая оптимальная абстракция, которая
[39:50.000 --> 39:52.000]  позволяет легко
[39:52.000 --> 39:54.000]  достаточно перейти с концепцией
[39:54.000 --> 39:56.000]  стриминга, когда мы просто берем
[39:56.000 --> 39:58.000]  и там, где лимит от ключей
[39:58.000 --> 40:00.000]  и значений пересылаем,
[40:00.000 --> 40:02.000]  самая оптимальная как раз
[40:02.000 --> 40:04.000]  представить, что каждая строка,
[40:04.000 --> 40:06.000]  которая от дилиметра
[40:06.000 --> 40:08.000]  поля у нас приходит в стриминге,
[40:08.000 --> 40:10.000]  она как раз и представляется
[40:10.000 --> 40:12.000]  в каком-то приближении
[40:12.000 --> 40:14.000]  элемента RDD,
[40:14.000 --> 40:16.000]  строку RDD,
[40:16.000 --> 40:18.000]  чтобы было понимание просто
[40:18.000 --> 40:20.000]  соотношения теории и практики,
[40:20.000 --> 40:22.000]  что это такое.
[40:24.000 --> 40:26.000]  Хорошо.
[40:26.000 --> 40:28.000]  Спасибо за контекст,
[40:28.000 --> 40:30.000]  спасибо за прояснение, Павел.
[40:30.000 --> 40:32.000]  Согласен с вами.
[40:32.000 --> 40:34.000]  Ты, кстати, допомнил бы еще
[40:34.000 --> 40:36.000]  в этом вопросе, что
[40:36.000 --> 40:38.000]  Spark на самом деле данные воспринимает
[40:38.000 --> 40:40.000]  именно как потоки.
[40:40.000 --> 40:42.000]  Идеологически так было задумано,
[40:42.000 --> 40:44.000]  а не как таблицы.
[40:44.000 --> 40:46.000]  Отсюда и плюсы, и ограничения.
[40:46.000 --> 40:48.000]  Об этом мы улучшим позже
[40:48.000 --> 40:50.000]  по ходу слайдов.
[40:50.000 --> 40:52.000]  Тогда давайте двигаться дальше.
[40:54.000 --> 40:56.000]  Но, кстати, по-моему, Юра, сейчас идет
[40:56.000 --> 40:58.000]  твои примеры.
[41:00.000 --> 41:02.000]  Как раз тебе оба, тебе, тебе сейчас.
[41:04.000 --> 41:06.000]  Сейчас тогда сделаю.
[41:06.000 --> 41:08.000]  Попробуй сейчас...
[41:08.000 --> 41:10.000]  Прикачай, расшаривай свой экран.
[41:10.000 --> 41:12.000]  Ты тогда расшаривай свой экран.
[41:12.000 --> 41:14.000]  Так.
[41:16.000 --> 41:18.000]  Весь экран, окно.
[41:18.000 --> 41:20.000]  Вот, кажется.
[41:24.000 --> 41:26.000]  Видно?
[41:28.000 --> 41:30.000]  Да, я вижу.
[41:32.000 --> 41:34.000]  Значит...
[41:34.000 --> 41:36.000]  Вот это один из примеров
[41:36.000 --> 41:38.000]  из реальной практики.
[41:38.000 --> 41:40.000]  И как раз вот
[41:40.000 --> 41:42.000]  из генетики я скажу, почему именно
[41:42.000 --> 41:44.000]  этот пример взял и почему не из генетики.
[41:44.000 --> 41:46.000]  Дело в том, что это такое характерное
[41:46.000 --> 41:48.000]  применение именно Spark.
[41:50.000 --> 41:52.000]  Вот, например,
[41:52.000 --> 41:54.000]  опять же, из практики, когда...
[41:54.000 --> 41:56.000]  Нет, вернее, сейчас
[41:56.000 --> 41:58.000]  чуть откачусь. То есть, что
[41:58.000 --> 42:00.000]  в данном примере
[42:00.000 --> 42:02.000]  используется
[42:02.000 --> 42:04.000]  ДИФ-генома, так называемый
[42:04.000 --> 42:06.000]  ВЦФ-файл, вернее, преобразованный ВЦФ.
[42:06.000 --> 42:08.000]  Это
[42:08.000 --> 42:10.000]  типа этот ЦСВ-формат,
[42:10.000 --> 42:12.000]  в котором
[42:14.000 --> 42:16.000]  есть колонки хромосома,
[42:16.000 --> 42:18.000]  то есть их там
[42:18.000 --> 42:20.000]  22 плюс
[42:20.000 --> 42:22.000]  еще
[42:22.000 --> 42:24.000]  XY и метахондрия
[42:24.000 --> 42:26.000]  и ее позиция,
[42:26.000 --> 42:28.000]  также набор нуклеотидов, которые
[42:28.000 --> 42:30.000]  указаны в референтном геноме,
[42:30.000 --> 42:32.000]  и их замена, то есть так называемые мутации.
[42:32.000 --> 42:34.000]  И этих данных,
[42:34.000 --> 42:36.000]  то есть при полном геномном секвенировании,
[42:36.000 --> 42:38.000]  у каждого человека накапливается
[42:38.000 --> 42:40.000]  ДИФ, получается,
[42:40.000 --> 42:42.000]  именно это ВЦФ-файл,
[42:42.000 --> 42:44.000]  порядка 5 миллионов записей.
[42:44.000 --> 42:46.000]  Это не такие большие данные,
[42:46.000 --> 42:48.000]  не такой большой объем для обработки
[42:48.000 --> 42:50.000]  тем же самым поздросом,
[42:50.000 --> 42:52.000]  или MS SQL, или Oracle.
[42:52.000 --> 42:54.000]  Но есть один серьезный момент,
[42:54.000 --> 42:56.000]  что для того, чтобы закачать их туда,
[42:56.000 --> 42:58.000]  нужно много времени.
[42:58.000 --> 43:00.000]  То есть, чтобы закачать в хранилище поздроса
[43:00.000 --> 43:02.000]  или даже того же клихауса,
[43:02.000 --> 43:04.000]  который достаточно быстро принимает данные,
[43:04.000 --> 43:06.000]  все равно нужно достаточно много времени.
[43:06.000 --> 43:08.000]  И в этом случае
[43:08.000 --> 43:10.000]  проще использовать SQL-движок,
[43:10.000 --> 43:12.000]  то же самое,
[43:12.000 --> 43:14.000]  вернее, в частности Spark SQL,
[43:14.000 --> 43:16.000]  который позволяет
[43:16.000 --> 43:18.000]  использовать внешние хранилища.
[43:18.000 --> 43:20.000]  То есть, вот эти вот tab-separated
[43:20.000 --> 43:22.000]  файлы, они, кстати, зажаты в GZ,
[43:22.000 --> 43:24.000]  в GZIP,
[43:24.000 --> 43:26.000]  причем на него там есть модификация
[43:26.000 --> 43:28.000]  BGZIP,
[43:28.000 --> 43:30.000]  либо просто
[43:30.000 --> 43:32.000]  обычный GZIP.
[43:32.000 --> 43:34.000]  Spark позволяет их читать
[43:34.000 --> 43:36.000]  прямо из источника,
[43:36.000 --> 43:38.000]  так же, как
[43:38.000 --> 43:40.000]  любая
[43:40.000 --> 43:42.000]  релиционная база данных
[43:42.000 --> 43:44.000]  из своего хранилища
[43:44.000 --> 43:46.000]  и воспринимает их как поток.
[43:46.000 --> 43:48.000]  То есть, данные, на самом деле,
[43:48.000 --> 43:50.000]  один раз читаются, обрабатываются, покачаются,
[43:50.000 --> 43:52.000]  производятся какие-то действия
[43:52.000 --> 43:54.000]  и выгружается их в выжимку
[43:54.000 --> 43:56.000]  или обработаны уже
[43:58.000 --> 44:00.000]  преобразованные данные.
[44:00.000 --> 44:02.000]  И вот это вот было
[44:02.000 --> 44:04.000]  одной из причин
[44:04.000 --> 44:06.000]  использования Spark.
[44:06.000 --> 44:08.000]  И по этой же причине он часто используется,
[44:08.000 --> 44:10.000]  в частности, в генетике,
[44:10.000 --> 44:12.000]  потому что данные достаточно объемные,
[44:12.000 --> 44:14.000]  и заливать их в релиционные данные,
[44:14.000 --> 44:16.000]  потом вытаскивать их обратно
[44:16.000 --> 44:18.000]  нерационально.
[44:18.000 --> 44:20.000]  Вот, собственно, один из примеров,
[44:20.000 --> 44:22.000]  он написан на клоджере,
[44:22.000 --> 44:24.000]  если кто знает современный диалект
[44:24.000 --> 44:26.000]  Лиспа, я специально оставил его,
[44:26.000 --> 44:28.000]  как есть, чтобы было понятно
[44:28.000 --> 44:30.000]  контекст,
[44:30.000 --> 44:32.000]  что именно,
[44:32.000 --> 44:34.000]  как они преобразовывались.
[44:34.000 --> 44:36.000]  То есть, также сам можно это написать на питоне,
[44:36.000 --> 44:38.000]  на скале, поясню
[44:38.000 --> 44:40.000]  основные различия,
[44:40.000 --> 44:42.000]  даже не различия, а
[44:44.000 --> 44:46.000]  логику, что здесь происходит.
[44:46.000 --> 44:48.000]  Ну и, собственно, пойдем.
[44:48.000 --> 44:50.000]  То есть, вот есть у нас
[44:50.000 --> 44:52.000]  какие-то набор данных,
[44:52.000 --> 44:54.000]  это вот хромосома позиция,
[44:54.000 --> 44:56.000]  реф хальт, ну еще какая-то
[44:56.000 --> 44:58.000]  информационная информация.
[44:58.000 --> 45:00.000]  Есть база данных на Postgres,
[45:00.000 --> 45:02.000]  где находится так называемый Лис,
[45:02.000 --> 45:04.000]  лабораторная информационная система.
[45:04.000 --> 45:06.000]  И вот в этой задаче, опять же,
[45:06.000 --> 45:08.000]  я скажу,
[45:08.000 --> 45:10.000]  то есть, суть там определилась какая-то
[45:10.000 --> 45:12.000]  фармакинетика, я не знаю, что это такое,
[45:12.000 --> 45:14.000]  потому что я программист,
[45:14.000 --> 45:16.000]  этим занимались биологи, биоинформатики,
[45:16.000 --> 45:18.000]  но эту информацию нужно было
[45:18.000 --> 45:20.000]  сопоставить с тем
[45:20.000 --> 45:22.000]  объемом данных
[45:22.000 --> 45:24.000]  из VCF файлов преобразованных,
[45:24.000 --> 45:26.000]  то есть, здесь они были
[45:26.000 --> 45:28.000]  не в чистом виде, как они
[45:28.000 --> 45:30.000]  подразумевают формат
[45:30.000 --> 45:32.000]  VCF, это опять же тоже
[45:32.000 --> 45:34.000]  мини-кассест, как сказали,
[45:34.000 --> 45:36.000]  так и сделала.
[45:36.000 --> 45:38.000]  И нужно было обогатить эти данные
[45:38.000 --> 45:40.000]  и сагрегировать с данными из Лиса.
[45:40.000 --> 45:42.000]  Ну и вот здесь
[45:42.000 --> 45:44.000]  preparator
[45:44.000 --> 45:46.000]  preparator функция, то есть здесь
[45:46.000 --> 45:48.000]  делаются подготовительные работы,
[45:48.000 --> 45:50.000]  в частности,
[45:50.000 --> 45:52.000]  вот в
[45:52.000 --> 45:54.000]  12 строке
[45:54.000 --> 45:56.000]  переписывается драйвер Позгресса.
[45:56.000 --> 45:58.000]  Я напомню, что Spark
[45:58.000 --> 46:00.000]  это распределенная система,
[46:00.000 --> 46:02.000]  и на каждом узле должен лежать
[46:02.000 --> 46:04.000]  копия
[46:04.000 --> 46:06.000]  jar файлов,
[46:06.000 --> 46:08.000]  которые
[46:08.000 --> 46:10.000]  необходимы для работы в данном узлу.
[46:10.000 --> 46:12.000]  То есть, у нас есть HDFS,
[46:12.000 --> 46:14.000]  Игорь говорил, что это
[46:14.000 --> 46:16.000]  за система, то есть, это распределенная
[46:16.000 --> 46:18.000]  файловая система,
[46:18.000 --> 46:20.000]  имеющая,
[46:20.000 --> 46:22.000]  в которой каждый узел имеет доступ
[46:22.000 --> 46:24.000]  по одному и тому же пути.
[46:24.000 --> 46:26.000]  То есть, в данном случае ходу
[46:26.000 --> 46:28.000]  к мастер-хост это хост, и
[46:28.000 --> 46:30.000]  tmp jar с позгресса или
[46:30.000 --> 46:32.000]  это путь к этому
[46:32.000 --> 46:34.000]  jar файлу, то есть, к драйверу
[46:34.000 --> 46:36.000]  Позгресса. И каждый узел
[46:36.000 --> 46:38.000]  может получить этот
[46:38.000 --> 46:40.000]  jar файл и подгрузить его
[46:40.000 --> 46:42.000]  с помощью класса удара для
[46:42.000 --> 46:44.000]  дальнейшей работы.
[46:44.000 --> 46:46.000]  Чтобы каждый узел мог
[46:46.000 --> 46:48.000]  подключиться к Позгрессу, где находится
[46:48.000 --> 46:50.000]  таблица.
[46:50.000 --> 46:52.000]  Если здесь есть какие-то вопросы,
[46:52.000 --> 46:54.000]  то лучше, наверное, задать их сразу,
[46:54.000 --> 46:56.000]  потому что там я мог достаточно
[46:56.000 --> 46:58.000]  сумбурно объяснить.
[47:04.000 --> 47:06.000]  Продолжим.
[47:06.000 --> 47:08.000]  Собственно, передается вот эта формака.
[47:08.000 --> 47:10.000]  Один это
[47:10.000 --> 47:12.000]  файл с данными,
[47:12.000 --> 47:14.000]  связанный с формакологией.
[47:14.000 --> 47:16.000]  И вот
[47:16.000 --> 47:18.000]  в этой строке, 25,
[47:18.000 --> 47:20.000]  это указание
[47:20.000 --> 47:22.000]  спарку,
[47:22.000 --> 47:24.000]  которая передается на все узлы,
[47:24.000 --> 47:26.000]  какие
[47:26.000 --> 47:28.000]  дополнительные jar файлы,
[47:28.000 --> 47:30.000]  это jar в архиве,
[47:30.000 --> 47:32.000]  на всякий случай напомню,
[47:32.000 --> 47:34.000]  какие jar файлы
[47:34.000 --> 47:36.000]  использовать при работе.
[47:36.000 --> 47:38.000]  И дальше
[47:38.000 --> 47:40.000]  идет непосредственно
[47:40.000 --> 47:42.000]  подготовка.
[47:42.000 --> 47:44.000]  Есть у нас свой файл, разделенный
[47:44.000 --> 47:46.000]  с пербулястой.
[47:46.000 --> 47:48.000]  Это separated
[47:48.000 --> 47:50.000]  CSV файл
[47:50.000 --> 47:52.000]  с заголовки. Вот у нас указан
[47:52.000 --> 47:54.000]  header по поводу синтаксиса.
[47:54.000 --> 47:56.000]  Эта
[47:56.000 --> 47:58.000]  запись, начиная с 51-й строки
[47:58.000 --> 48:00.000]  по 58-й, можно представить
[48:00.000 --> 48:02.000]  к примеру на PySpark,
[48:02.000 --> 48:04.000]  также как spark.read.format
[48:04.000 --> 48:06.000]  в скобках
[48:06.000 --> 48:08.000]  CSV
[48:08.000 --> 48:10.000]  и далее options
[48:10.000 --> 48:12.000]  в скобках
[48:12.000 --> 48:14.000]  slash t.
[48:14.000 --> 48:16.000]  То есть это
[48:16.000 --> 48:18.000]  запись
[48:18.000 --> 48:20.000]  в листовом варианте.
[48:20.000 --> 48:22.000]  Она синтаксически
[48:22.000 --> 48:24.000]  сильно отличается, но по факту это такой же
[48:24.000 --> 48:26.000]  конвейер, как на PySpark.
[48:26.000 --> 48:28.000]  Я не буду на нем застрять внимание,
[48:28.000 --> 48:30.000]  что это второстепенный
[48:30.000 --> 48:32.000]  момент.
[48:32.000 --> 48:34.000]  Вернемся.
[48:34.000 --> 48:36.000]  И что мы делаем здесь?
[48:36.000 --> 48:38.000]  Здесь мы по сути делаем представление,
[48:38.000 --> 48:40.000]  так называемое view
[48:40.000 --> 48:42.000]  в терминологии
[48:42.000 --> 48:44.000]  баз-данных,
[48:44.000 --> 48:46.000]  то есть тех же всех
[48:46.000 --> 48:48.000]  поскрусов, ороклов и так далее.
[48:48.000 --> 48:50.000]  В Spark SQL тоже есть представление.
[48:50.000 --> 48:52.000]  И в данном случае
[48:52.000 --> 48:54.000]  из этого вот формата
[48:54.000 --> 48:56.000]  1.txt
[48:56.000 --> 48:58.000]  делается представление таблиц.
[48:58.000 --> 49:00.000]  Здесь задаются колонки.
[49:00.000 --> 49:02.000]  То есть у нее есть именованные,
[49:02.000 --> 49:04.000]  она уже имеет именованные колонки,
[49:04.000 --> 49:06.000]  но мы их вот
[49:06.000 --> 49:08.000]  в 58-й строке
[49:08.000 --> 49:10.000]  затираем и
[49:10.000 --> 49:12.000]  устанавливаем свои. То есть
[49:12.000 --> 49:14.000]  T0 нам не нужно, это не используется.
[49:14.000 --> 49:16.000]  ID, хромосома, позиция,
[49:16.000 --> 49:18.000]  ref, alt используется. Остальные тоже не используются,
[49:18.000 --> 49:20.000]  но их нельзя отбросить, потому их просто забиваем
[49:20.000 --> 49:22.000]  незначениями значениями.
[49:22.000 --> 49:24.000]  Теперь у нас
[49:24.000 --> 49:26.000]  FKView представляет
[49:26.000 --> 49:28.000]  обычную релиционную таблицу.
[49:28.000 --> 49:30.000]  Она смаплена на
[49:30.000 --> 49:32.000]  текстовый файл, этот файл распределенный,
[49:32.000 --> 49:34.000]  он Spark
[49:34.000 --> 49:36.000]  рубится на определенные кусочки
[49:36.000 --> 49:38.000]  те же сами RDD, они же
[49:38.000 --> 49:40.000]  оборачиваются потом в датафреймы
[49:40.000 --> 49:42.000]  и лежит распределен
[49:42.000 --> 49:44.000]  на кластере.
[49:44.000 --> 49:46.000]  Далее
[49:46.000 --> 49:48.000]  у нас уже есть по сути релиционную таблицу,
[49:48.000 --> 49:50.000]  мы рассмотрим ее именно как
[49:50.000 --> 49:52.000]  таблицу.
[49:52.000 --> 49:54.000]  Дальше тоже
[49:54.000 --> 49:56.000]  выше есть эквивалентная запись.
[49:56.000 --> 49:58.000]  Это тоже самое можно записать одним
[49:58.000 --> 50:00.000]  только SQL.
[50:00.000 --> 50:02.000]  То есть передается
[50:02.000 --> 50:04.000]  Spark, набор SQL
[50:04.000 --> 50:06.000]  и SQL-директив,
[50:06.000 --> 50:08.000]  который выполнен тем же самым первым.
[50:08.000 --> 50:10.000]  В данном случае
[50:10.000 --> 50:12.000]  вот я специально выделю
[50:16.000 --> 50:18.000]  это эквивалентная запись.
[50:18.000 --> 50:20.000]  То есть мы создаем
[50:20.000 --> 50:22.000]  view, то есть KritaReplace,
[50:22.000 --> 50:24.000]  то есть если она существует, она не пересоздается,
[50:24.000 --> 50:26.000]  с этим нужно быть аккуратной,
[50:26.000 --> 50:28.000]  то есть лучше дропать.
[50:28.000 --> 50:30.000]  KritaReplace, tempView, временная view,
[50:30.000 --> 50:32.000]  то есть она существует только в пределах
[50:32.000 --> 50:34.000]  данного соединения,
[50:34.000 --> 50:36.000]  то есть другие
[50:36.000 --> 50:38.000]  сессии ее не видят.
[50:38.000 --> 50:40.000]  Вот так же самое
[50:40.000 --> 50:42.000]  создается таблица, это обычная SQL-синтакс,
[50:42.000 --> 50:44.000]  за исключением вот этой строки,
[50:44.000 --> 50:46.000]  using.csv, это не характерно для
[50:46.000 --> 50:48.000]  SQL-директива.
[50:48.000 --> 50:50.000]  И дополнительные
[50:50.000 --> 50:52.000]  options – это путь
[50:52.000 --> 50:54.000]  к HDFS, который
[50:54.000 --> 50:56.000]  одинаково видит каждый узел Spark.
[50:58.000 --> 51:00.000]  Соответственно, истина,
[51:00.000 --> 51:02.000]  потому что здесь первая строка
[51:02.000 --> 51:04.000]  является заголовком,
[51:04.000 --> 51:06.000]  но мы их переопределим, то есть они будут
[51:06.000 --> 51:08.000]  по сути проигнорированы.
[51:08.000 --> 51:10.000]  Ну и септор разделитель.
[51:10.000 --> 51:12.000]  То есть это эквивалентная запись.
[51:12.000 --> 51:14.000]  Вот того, что мы видим
[51:14.000 --> 51:16.000]  с 51-й по 58-й строку.
[51:18.000 --> 51:20.000]  То же самое можно
[51:20.000 --> 51:22.000]  SparkShell передать
[51:22.000 --> 51:24.000]  SparkSQL, вернее SparkSQL
[51:24.000 --> 51:26.000]  есть такая утилита,
[51:26.000 --> 51:28.000]  можно зайти в нее и прямо так
[51:28.000 --> 51:30.000]  сделать
[51:30.000 --> 51:32.000]  выполнить данную операцию.
[51:34.000 --> 51:36.000]  Соответственно, это
[51:36.000 --> 51:38.000]  farm-file, тоже
[51:38.000 --> 51:40.000]  только это
[51:40.000 --> 51:42.000]  таблица
[51:42.000 --> 51:44.000]  без заголовков
[51:44.000 --> 51:46.000]  и разделенная пробелами.
[51:46.000 --> 51:48.000]  Вот, собственно, так же самое
[51:48.000 --> 51:50.000]  можно сделать как вот выше,
[51:50.000 --> 51:52.000]  replace.tmp-view, либо
[51:52.000 --> 51:54.000]  в данном случае мне было удобнее
[51:54.000 --> 51:56.000]  сделать именно так
[51:56.000 --> 51:58.000]  просто
[51:58.000 --> 52:00.000]  обычным кажур кодом.
[52:00.000 --> 52:02.000]  Так же самое
[52:02.000 --> 52:04.000]  из нее создается таблица sample
[52:04.000 --> 52:06.000]  popgen, это там
[52:06.000 --> 52:08.000]  популяционные геномные исследования.
[52:08.000 --> 52:10.000]  Опять же, я не могу
[52:10.000 --> 52:12.000]  ничего сказать
[52:12.000 --> 52:14.000]  относительно области применения,
[52:14.000 --> 52:16.000]  потому что я не специалист в этом.
[52:16.000 --> 52:18.000]  Вот мы технически создаем еще одно представление.
[52:18.000 --> 52:20.000]  Оно также смаплено на
[52:20.000 --> 52:22.000]  этот farm-file, он может быть
[52:22.000 --> 52:24.000]  кэширован, может
[52:24.000 --> 52:26.000]  браться в определенные фрагменты
[52:26.000 --> 52:28.000]  прямо вот
[52:28.000 --> 52:30.000]  непосредственно из
[52:30.000 --> 52:32.000]  блока
[52:32.000 --> 52:34.000]  размещенного
[52:34.000 --> 52:36.000]  на HDFS.
[52:36.000 --> 52:38.000]  Для нас это такая же таблица,
[52:38.000 --> 52:40.000]  как в реализованной базе данных.
[52:40.000 --> 52:42.000]  Дальше
[52:42.000 --> 52:44.000]  вот здесь немножко другой
[52:44.000 --> 52:46.000]  момент. Здесь мы, начиная
[52:46.000 --> 52:48.000]  с 72-й строки по 76-ю,
[52:48.000 --> 52:50.000]  делаем
[52:50.000 --> 52:52.000]  материализованную
[52:52.000 --> 52:54.000]  запись, то есть у нас есть
[52:54.000 --> 52:56.000]  запрос.
[52:56.000 --> 52:58.000]  В частности, мы используем таблицу
[52:58.000 --> 53:00.000]  fk-view, это она у нас
[53:00.000 --> 53:02.000]  с 51-й по 58-й
[53:02.000 --> 53:04.000]  строку была
[53:06.000 --> 53:08.000]  определена как представление,
[53:08.000 --> 53:10.000]  то есть для нас представление и
[53:10.000 --> 53:12.000]  реальные таблицы с точки зрения
[53:12.000 --> 53:14.000]  реализованной алгебры равнозначны.
[53:14.000 --> 53:16.000]  И здесь мы выполняем
[53:16.000 --> 53:18.000]  на ней запрос, то есть хромосом,
[53:18.000 --> 53:20.000]  там хромосом заданный цифрами,
[53:20.000 --> 53:22.000]  нам необходимо, чтобы у неё был
[53:22.000 --> 53:24.000]  в соответствии с 38-м
[53:24.000 --> 53:26.000]  по референсам,
[53:26.000 --> 53:28.000]  представление было, то есть CHR и цифра,
[53:28.000 --> 53:30.000]  цифра либо XY и
[53:30.000 --> 53:32.000]  М-буква.
[53:32.000 --> 53:34.000]  В частности, тут мы
[53:34.000 --> 53:36.000]  выделим
[53:36.000 --> 53:38.000]  просто вот так же
[53:38.000 --> 53:40.000]  с таким же синтезисом,
[53:40.000 --> 53:42.000]  как в поздросе.
[53:42.000 --> 53:44.000]  Добавляем, делаем конкатинацию,
[53:44.000 --> 53:46.000]  добавляем строку CHR
[53:46.000 --> 53:48.000]  в хромосоме,
[53:48.000 --> 53:50.000]  представим алиас как
[53:50.000 --> 53:52.000]  хромосома.
[53:52.000 --> 53:54.000]  Позицию преобразуем
[53:54.000 --> 53:56.000]  из текста в int,
[53:56.000 --> 53:58.000]  потому что у нас
[53:58.000 --> 54:00.000]  текстовый файл, соответственно,
[54:00.000 --> 54:02.000]  по умолчанию колонки имеет
[54:02.000 --> 54:04.000]  текстовое значение.
[54:04.000 --> 54:06.000]  Так что рефальт остаётся
[54:06.000 --> 54:08.000]  немножко
[54:08.000 --> 54:10.000]  как оптимизируем
[54:10.000 --> 54:12.000]  данную таблицу
[54:12.000 --> 54:14.000]  и убираем лишние, то есть вот эти
[54:14.000 --> 54:16.000]  подчеркнение t0, t1, t2, они нам не нужны,
[54:16.000 --> 54:18.000]  мы их здесь не используем.
[54:18.000 --> 54:20.000]  А далее мы записываем их
[54:20.000 --> 54:22.000]  так же в кластер
[54:22.000 --> 54:24.000]  на HDFS в директории
[54:24.000 --> 54:26.000]  FKSL.
[54:26.000 --> 54:28.000]  Это не файл, это директория.
[54:28.000 --> 54:30.000]  В ней хранятся
[54:30.000 --> 54:32.000]  все секции,
[54:32.000 --> 54:34.000]  так назовём партиции,
[54:34.000 --> 54:36.000]  с каждого узла.
[54:36.000 --> 54:38.000]  То есть они сгружаются в эту директорию,
[54:38.000 --> 54:40.000]  но для нас
[54:40.000 --> 54:42.000]  она также представляет
[54:42.000 --> 54:44.000]  ту же самую таблицу, то есть к ней можно
[54:44.000 --> 54:46.000]  обратиться именно как таблице.
[54:46.000 --> 54:48.000]  И вот я могу даже дописать.
[54:48.000 --> 54:50.000]  Если кому интересно,
[54:50.000 --> 54:52.000]  вот здесь такой момент.
[54:58.000 --> 55:00.000]  И вот эта вот запись
[55:00.000 --> 55:02.000]  паркет, то есть помолчание сохранится
[55:02.000 --> 55:04.000]  в формате паркет.
[55:04.000 --> 55:06.000]  Сейчас не буду на нём останавливаться,
[55:06.000 --> 55:08.000]  это очень интересный и эффективный формат хранения.
[55:08.000 --> 55:10.000]  И к ним
[55:10.000 --> 55:12.000]  в запросе в SQL
[55:12.000 --> 55:14.000]  мы можем таким образом обратиться.
[55:14.000 --> 55:16.000]  То есть паркет.backslash
[55:16.000 --> 55:18.000]  и адрес
[55:18.000 --> 55:20.000]  этой директории
[55:20.000 --> 55:22.000]  на HDFS, где лежат
[55:22.000 --> 55:24.000]  данные
[55:24.000 --> 55:26.000]  из этого результата запроса
[55:26.000 --> 55:28.000]  в нескольких файлов
[55:28.000 --> 55:30.000]  по каждому, по каждой секции.
[55:30.000 --> 55:32.000]  Их, кстати, может быть более, чем
[55:32.000 --> 55:34.000]  один на узел,
[55:34.000 --> 55:36.000]  в зависимости
[55:36.000 --> 55:38.000]  от настроек с парка.
[55:38.000 --> 55:40.000]  Берём.
[55:40.000 --> 55:42.000]  Вот. И эквивалентно это
[55:42.000 --> 55:44.000]  опять же вот такую запись.
[55:44.000 --> 55:46.000]  То есть потому, что сам парк SQL
[55:46.000 --> 55:48.000]  можно выполнить вот такую
[55:48.000 --> 55:50.000]  drop table
[55:50.000 --> 55:52.000]  в Exist я вкосил.
[55:52.000 --> 55:54.000]  То есть удалить
[55:54.000 --> 55:56.000]  её, если она не существует,
[55:56.000 --> 55:58.000]  потому что у нас есть в 74 строке
[55:58.000 --> 56:00.000]  метод
[56:00.000 --> 56:02.000]  mode overwrite. То есть если эти данные есть,
[56:02.000 --> 56:04.000]  то они перезатираются в кластере
[56:04.000 --> 56:06.000]  по данному пути.
[56:06.000 --> 56:08.000]  Либо и то же самое
[56:08.000 --> 56:10.000]  можно сделать в соответствии
[56:10.000 --> 56:12.000]  с ANSI SQL
[56:12.000 --> 56:14.000]  create table using parquet.
[56:14.000 --> 56:16.000]  В данном случае
[56:16.000 --> 56:18.000]  здесь нужно учитывать,
[56:18.000 --> 56:20.000]  указывать формат
[56:20.000 --> 56:22.000]  сохранения.
[56:22.000 --> 56:24.000]  Этот parquet очень широко
[56:24.000 --> 56:26.000]  используется.
[56:26.000 --> 56:28.000]  И location – это
[56:28.000 --> 56:30.000]  путь, где именно будет
[56:30.000 --> 56:32.000]  материализованная эта
[56:32.000 --> 56:34.000]  запись.
[56:34.000 --> 56:36.000]  Да-да.
[56:36.000 --> 56:38.000]  Вот в этом вот
[56:38.000 --> 56:40.000]  FCSL вы сказали, что там
[56:40.000 --> 56:42.000]  по секциям лежат.
[56:42.000 --> 56:44.000]  Будут лежать данные.
[56:44.000 --> 56:46.000]  Что собой секция представляет?
[56:48.000 --> 56:50.000]  Это файл.
[56:50.000 --> 56:52.000]  Обычно у него формат такой.
[56:52.000 --> 56:54.000]  Это OUID формат.
[56:54.000 --> 56:56.000]  То есть OUID формат
[56:56.000 --> 56:58.000]  все знают, я думаю.
[56:58.000 --> 57:00.000]  То есть это
[57:00.000 --> 57:02.000]  от 0 до
[57:02.000 --> 57:04.000]  0 до 9.
[57:04.000 --> 57:06.000]  То есть все цифры
[57:06.000 --> 57:08.000]  и буквенные значения.
[57:08.000 --> 57:10.000]  Не помню, Z там входит или нет.
[57:10.000 --> 57:12.000]  То есть от A до Z разделенные
[57:12.000 --> 57:14.000]  defisами.
[57:14.000 --> 57:16.000]  Четыре символа
[57:16.000 --> 57:18.000]  defis.
[57:18.000 --> 57:20.000]  То есть буквенно-цифровой
[57:20.000 --> 57:22.000]  нечитаемый формат
[57:22.000 --> 57:24.000]  .parquet.
[57:24.000 --> 57:26.000]  Это обычный файл parquet,
[57:26.000 --> 57:28.000]  который имеет один и тот же формат.
[57:28.000 --> 57:30.000]  Подразумевает, что они все имеют
[57:30.000 --> 57:32.000]  одинаковый формат, то есть одинаковая
[57:32.000 --> 57:34.000]  последовательность колонок и их названия.
[57:34.000 --> 57:36.000]  Вот они вот так лежат просто
[57:36.000 --> 57:38.000]  несколькими файлами в этой директории FKView.
[57:38.000 --> 57:40.000]  То есть вы можете
[57:40.000 --> 57:42.000]  сохранить и взять любой запрос,
[57:42.000 --> 57:44.000]  выполнить там в парке в localmod
[57:44.000 --> 57:46.000]  и запустить там, допустим,
[57:46.000 --> 57:48.000]  на компьютере запрос,
[57:48.000 --> 57:50.000]  сохранить его и увидеть
[57:50.000 --> 57:52.000]  скорее всего несколько файлов
[57:52.000 --> 57:54.000]  в данной директории.
[57:54.000 --> 57:56.000]  Можете посмотреть, они бинарные, в них
[57:56.000 --> 57:58.000]  так через просмотры
[57:58.000 --> 58:00.000]  сидеть ничего крайне сложно.
[58:00.000 --> 58:02.000]  Мало того, они еще сжаты,
[58:02.000 --> 58:04.000]  и сжаты достаточно сильно.
[58:04.000 --> 58:06.000]  Есть различные алгоритмы сжатия,
[58:06.000 --> 58:08.000]  по-моему, там LZMA используется.
[58:08.000 --> 58:10.000]  Не буду врать в такие подробности.
[58:12.000 --> 58:14.000]  Собственно, все. Я ответил на вопрос
[58:14.000 --> 58:16.000]  или, может быть, не точно еще.
[58:16.000 --> 58:18.000]  Нужно уточнить.
[58:18.000 --> 58:20.000]  Каждый файл — это информация там колонки
[58:20.000 --> 58:22.000]  условно.
[58:22.000 --> 58:24.000]  Нет, не по колонке, это срез,
[58:24.000 --> 58:26.000]  это так же, как RDD, то есть это все колонки.
[58:26.000 --> 58:28.000]  В данном случае
[58:28.000 --> 58:30.000]  у нас колонки
[58:30.000 --> 58:32.000]  угольные, такие куски таблицы
[58:32.000 --> 58:34.000]  наши. Да, и причем они именованные.
[58:34.000 --> 58:36.000]  То есть первая колонка имеет
[58:36.000 --> 58:38.000]  название ID,
[58:38.000 --> 58:40.000]  вторая — хром, третья — пост,
[58:40.000 --> 58:42.000]  четвертая — реф, пятая — альт.
[58:42.000 --> 58:44.000]  И, что важно,
[58:44.000 --> 58:46.000]  в Spark'е важен порядок
[58:46.000 --> 58:48.000]  этих колонок. То есть если ID
[58:48.000 --> 58:50.000]  будет, допустим, после хромосомы,
[58:50.000 --> 58:52.000]  то при сложении может быть,
[58:52.000 --> 58:54.000]  то есть при чтении
[58:54.000 --> 58:56.000]  всех этих файлов
[58:56.000 --> 58:58.000]  из этой территории может быть
[58:58.000 --> 59:00.000]  непредсказуемое поведение, потому что Spark
[59:00.000 --> 59:02.000]  читает из первого файла
[59:02.000 --> 59:04.000]  название колонок,
[59:04.000 --> 59:06.000]  вот эти ID, хром, пост, реф, альт,
[59:06.000 --> 59:08.000]  а остальные
[59:08.000 --> 59:10.000]  он подразумеет, что они соответствуют,
[59:10.000 --> 59:12.000]  что первая колонка соответствует ID,
[59:12.000 --> 59:14.000]  вторая — хром, третья — пост.
[59:14.000 --> 59:16.000]  И читать
[59:16.000 --> 59:18.000]  он их может в любом порядке.
[59:18.000 --> 59:20.000]  У него какая-то своя логика.
[59:20.000 --> 59:22.000]  Если есть, допустим, 20 файлов,
[59:22.000 --> 59:24.000]  он может прочитать первым, может прочитать
[59:24.000 --> 59:26.000]  какой-то там предпоследний,
[59:26.000 --> 59:28.000]  и какой он выберет —
[59:28.000 --> 59:30.000]  это сложно сказать, но они
[59:30.000 --> 59:32.000]  все должны совпадать.
[59:32.000 --> 59:34.000]  Вот здесь есть
[59:34.000 --> 59:36.000]  какие-нибудь вопросы, или
[59:36.000 --> 59:38.000]  нужно дополнить? — Все ясно.
[59:38.000 --> 59:40.000]  — Спасибо.
[59:40.000 --> 59:42.000]  Тогда продолжим.
[59:42.000 --> 59:44.000]  Вот это эквивалентная запись.
[59:44.000 --> 59:46.000]  То есть мы создаем таблицу,
[59:46.000 --> 59:48.000]  записываем ее по этому пути
[59:48.000 --> 59:50.000]  sselect. То есть это, опять же,
[59:50.000 --> 59:52.000]  дистанции SQL.
[59:52.000 --> 59:54.000]  То есть можно
[59:54.000 --> 59:56.000]  использовать либо этот запрос, либо
[59:56.000 --> 59:58.000]  в частности
[59:58.000 --> 01:00:00.000]  не было удобнее
[01:00:00.000 --> 01:00:02.000]  писать это клажур кодом.
[01:00:04.000 --> 01:00:06.000]  Здесь мы создали уже материализованную
[01:00:06.000 --> 01:00:08.000]  таблицу. То есть
[01:00:08.000 --> 01:00:10.000]  есть такой момент очень важный.
[01:00:10.000 --> 01:00:12.000]  Spark это
[01:00:12.000 --> 01:00:14.000]  использует линеевое вычисление.
[01:00:14.000 --> 01:00:16.000]  То есть когда мы сделали какой-то запрос,
[01:00:16.000 --> 01:00:18.000]  допустим, sselect что-то, потом из него еще что-то
[01:00:18.000 --> 01:00:20.000]  сделали. Сделали sselect из вот этих
[01:00:20.000 --> 01:00:22.000]  FKView, sample, popgen.
[01:00:22.000 --> 01:00:24.000]  И
[01:00:24.000 --> 01:00:26.000]  когда мы получили
[01:00:26.000 --> 01:00:28.000]  DataFrame с результатами, вот, к примеру,
[01:00:28.000 --> 01:00:30.000]  если мы выполним
[01:00:30.000 --> 01:00:32.000]  Spark
[01:00:32.000 --> 01:00:34.000]  SQL, вот до 73
[01:00:34.000 --> 01:00:36.000]  строки, в результате
[01:00:36.000 --> 01:00:38.000]  мы получим определенный объект.
[01:00:38.000 --> 01:00:40.000]  Но при этом никаких
[01:00:40.000 --> 01:00:42.000]  операций чтения на
[01:00:42.000 --> 01:00:44.000]  FKView, в частности по файлу
[01:00:44.000 --> 01:00:46.000]  вот в этой строке
[01:00:46.000 --> 01:00:48.000]  56
[01:00:48.000 --> 01:00:50.000]  формата txt1.txt
[01:00:50.000 --> 01:00:52.000]  и по файлу sample.popgen
[01:00:52.000 --> 01:00:54.000]  в частности
[01:00:54.000 --> 01:00:56.000]  FKView.popgen не используется.
[01:00:56.000 --> 01:00:58.000]  Никакого чтения произведено не будет.
[01:00:58.000 --> 01:01:00.000]  Оно будет только в момент
[01:01:00.000 --> 01:01:02.000]  записи этого файла
[01:01:02.000 --> 01:01:04.000]  либо чтения.
[01:01:04.000 --> 01:01:06.000]  Spark использует линеевое вычисление
[01:01:06.000 --> 01:01:08.000]  и
[01:01:08.000 --> 01:01:10.000]  будет читать файлы только по мере их
[01:01:10.000 --> 01:01:12.000]  необходимости. Это нужно всегда учитывать,
[01:01:12.000 --> 01:01:14.000]  потому что часто будут
[01:01:14.000 --> 01:01:16.000]  странные ошибки, непредсказуемые,
[01:01:16.000 --> 01:01:18.000]  когда
[01:01:18.000 --> 01:01:20.000]  ошибка всплывает позже,
[01:01:20.000 --> 01:01:22.000]  чем она ожидалась.
[01:01:22.000 --> 01:01:24.000]  Потому что, повторюсь, Spark
[01:01:24.000 --> 01:01:26.000]  использует линеевое вычисление.
[01:01:26.000 --> 01:01:28.000]  Вот, в частности,
[01:01:28.000 --> 01:01:30.000]  в 76 строке
[01:01:30.000 --> 01:01:32.000]  будет
[01:01:32.000 --> 01:01:34.000]  после выполнения сейфа, то есть записи
[01:01:34.000 --> 01:01:36.000]  всех данных уже
[01:01:36.000 --> 01:01:38.000]  на HDFS, будет файл
[01:01:38.000 --> 01:01:40.000]  формака 1.txt
[01:01:40.000 --> 01:01:42.000]  будет уже прочитан полностью.
[01:01:42.000 --> 01:01:44.000]  Потому что он
[01:01:44.000 --> 01:01:46.000]  задействован
[01:01:46.000 --> 01:01:48.000]  в представлении FKView,
[01:01:48.000 --> 01:01:50.000]  а здесь мы делаем
[01:01:50.000 --> 01:01:52.000]  на 76 строке чтение из FKView.
[01:01:52.000 --> 01:01:54.000]  И вот когда будем читать
[01:01:54.000 --> 01:01:56.000]  уже записи, то есть
[01:01:56.000 --> 01:01:58.000]  непосредственно постройочно,
[01:01:58.000 --> 01:02:00.000]  только после этого
[01:02:00.000 --> 01:02:02.000]  файл будет читаться.
[01:02:02.000 --> 01:02:04.000]  Это нужно иметь в виду, это важный момент.
[01:02:06.000 --> 01:02:08.000]  Я думаю, здесь понятно,
[01:02:08.000 --> 01:02:10.000]  или все-таки есть какие-то вопросы,
[01:02:10.000 --> 01:02:12.000]  потому что такая вещь
[01:02:12.000 --> 01:02:14.000]  не очевидна, и люди
[01:02:14.000 --> 01:02:16.000]  часто напарываются
[01:02:16.000 --> 01:02:18.000]  на такие ошибки.
[01:02:18.000 --> 01:02:20.000]  Нужно что-нибудь еще пояснить.
[01:02:24.000 --> 01:02:26.000]  Видимо, не нужно.
[01:02:26.000 --> 01:02:28.000]  Значит, продолжим.
[01:02:28.000 --> 01:02:30.000]  Сейчас, секундочку, я включу питание,
[01:02:30.000 --> 01:02:32.000]  а у меня наутро разряжается.
[01:02:36.000 --> 01:02:38.000]  Далее.
[01:02:38.000 --> 01:02:40.000]  Переходим
[01:02:40.000 --> 01:02:42.000]  к строке 77.
[01:02:42.000 --> 01:02:44.000]  Здесь у нас также выполняется запрос
[01:02:44.000 --> 01:02:46.000]  и записывается
[01:02:46.000 --> 01:02:48.000]  в качестве материализованного.
[01:02:48.000 --> 01:02:50.000]  Но здесь мы используем
[01:02:50.000 --> 01:02:52.000]  ANSI SQL,
[01:02:52.000 --> 01:02:54.000]  WAV FK,
[01:02:54.000 --> 01:02:56.000]  SELECT FROM.
[01:02:56.000 --> 01:02:58.000]  Мы берем из той же
[01:03:00.000 --> 01:03:02.000]  у нас есть материализован
[01:03:02.000 --> 01:03:04.000]  представление FK cell.
[01:03:04.000 --> 01:03:06.000]  Вот так мы к нему
[01:03:06.000 --> 01:03:08.000]  обращаемся.
[01:03:08.000 --> 01:03:10.000]  Мы читаем не таблицу,
[01:03:10.000 --> 01:03:12.000]  мы можем прочитать
[01:03:12.000 --> 01:03:14.000]  из HDFS,
[01:03:14.000 --> 01:03:16.000]  Hadoop, Master, Host, MPF,
[01:03:16.000 --> 01:03:18.000]  FK cell данные,
[01:03:18.000 --> 01:03:20.000]  сделать CREED
[01:03:20.000 --> 01:03:22.000]  REPLACE TEMP VIEW,
[01:03:22.000 --> 01:03:24.000]  сделать представление
[01:03:24.000 --> 01:03:26.000]  на непосредственно таблицу
[01:03:26.000 --> 01:03:28.000]  без каких-либо преобразований.
[01:03:28.000 --> 01:03:30.000]  Либо можем прочитать прямо
[01:03:30.000 --> 01:03:32.000]  с HDFS.
[01:03:32.000 --> 01:03:34.000]  Это один из примеров,
[01:03:34.000 --> 01:03:36.000]  который я показывал.
[01:03:36.000 --> 01:03:38.000]  Я выделяю вот так.
[01:03:38.000 --> 01:03:40.000]  Можно обратиться
[01:03:40.000 --> 01:03:42.000]  не указывая, не имяноя
[01:03:42.000 --> 01:03:44.000]  через какую-то промежуточную таблицу.
[01:03:44.000 --> 01:03:46.000]  Здесь есть какие-нибудь вопросы,
[01:03:46.000 --> 01:03:48.000]  потому что тоже такая
[01:03:48.000 --> 01:03:50.000]  нечасто используемая техника,
[01:03:50.000 --> 01:03:52.000]  но она очень сильно
[01:03:52.000 --> 01:03:54.000]  экономит силы и время.
[01:03:54.000 --> 01:03:56.000]  Есть что-нибудь непонятное?
[01:04:00.000 --> 01:04:02.000]  Вроде все понятно.
[01:04:04.000 --> 01:04:06.000]  И дальше.
[01:04:06.000 --> 01:04:08.000]  Это TTE,
[01:04:08.000 --> 01:04:10.000]  Live Statement.
[01:04:10.000 --> 01:04:12.000]  Здесь ничего нового нет,
[01:04:12.000 --> 01:04:14.000]  но есть такой момент,
[01:04:14.000 --> 01:04:16.000]  на который нужно обратить внимание.
[01:04:16.000 --> 01:04:18.000]  В строке 80
[01:04:18.000 --> 01:04:20.000]  у нас там комментарии.
[01:04:20.000 --> 01:04:22.000]  Комментарии C-подобные
[01:04:22.000 --> 01:04:24.000]  и в нем директива Broadcast FK.
[01:04:24.000 --> 01:04:26.000]  В частности,
[01:04:26.000 --> 01:04:28.000]  в качестве FK у нас
[01:04:28.000 --> 01:04:30.000]  результат селекта
[01:04:30.000 --> 01:04:32.000]  по FK cell,
[01:04:32.000 --> 01:04:34.000]  но это
[01:04:34.000 --> 01:04:36.000]  логическое представление
[01:04:36.000 --> 01:04:38.000]  таблицы.
[01:04:38.000 --> 01:04:40.000]  Но дальше у нас
[01:04:40.000 --> 01:04:42.000]  берутся данные
[01:04:42.000 --> 01:04:44.000]  из Multisample Unified.
[01:04:46.000 --> 01:04:48.000]  В этой задачи
[01:04:48.000 --> 01:04:50.000]  было много
[01:04:50.000 --> 01:04:52.000]  переведенных в паркет
[01:04:52.000 --> 01:04:54.000]  вот этих преобразованных
[01:04:54.000 --> 01:04:56.000]  ВЦФ файлов,
[01:04:56.000 --> 01:04:58.000]  где там хромосома, позиция
[01:04:58.000 --> 01:05:00.000]  и так далее.
[01:05:00.000 --> 01:05:02.000]  Их было большое количество,
[01:05:02.000 --> 01:05:04.000]  и с ним производилась
[01:05:04.000 --> 01:05:06.000]  операция Join.
[01:05:06.000 --> 01:05:08.000]  Напомню, что Spark
[01:05:08.000 --> 01:05:10.000]  воспринимает данный как поток
[01:05:10.000 --> 01:05:12.000]  и индексировать он.
[01:05:14.000 --> 01:05:16.000]  Из коробки он
[01:05:16.000 --> 01:05:18.000]  индексировать не умеет.
[01:05:18.000 --> 01:05:20.000]  Есть определенные техники,
[01:05:20.000 --> 01:05:22.000]  использование хайва или секционирование
[01:05:22.000 --> 01:05:24.000]  на уровне сессии Spark,
[01:05:24.000 --> 01:05:26.000]  которая позволяет
[01:05:26.000 --> 01:05:28.000]  сократить сканирование.
[01:05:30.000 --> 01:05:32.000]  Партийцы.
[01:05:32.000 --> 01:05:34.000]  Да, партийцы.
[01:05:34.000 --> 01:05:36.000]  Но
[01:05:36.000 --> 01:05:38.000]  сам по себе Spark
[01:05:38.000 --> 01:05:40.000]  это потоковый движок,
[01:05:40.000 --> 01:05:42.000]  он не разрабатывался
[01:05:42.000 --> 01:05:44.000]  как замена релиционной
[01:05:44.000 --> 01:05:46.000]  СОБД.
[01:05:46.000 --> 01:05:48.000]  И вот эти данные
[01:05:48.000 --> 01:05:50.000]  он читает потоком,
[01:05:50.000 --> 01:05:52.000]  и если происходит необходимость
[01:05:52.000 --> 01:05:54.000]  Join, все знают,
[01:05:54.000 --> 01:05:56.000]  то есть операцию Join
[01:05:56.000 --> 01:05:58.000]  в релиционной алгебре,
[01:05:58.000 --> 01:06:00.000]  это достаточно тяжелая операция.
[01:06:00.000 --> 01:06:02.000]  И вот тут есть такой момент,
[01:06:02.000 --> 01:06:04.000]  мы делаем broadcast в ка,
[01:06:04.000 --> 01:06:06.000]  результат Select
[01:06:06.000 --> 01:06:08.000]  в 79 строке,
[01:06:08.000 --> 01:06:10.000]  это маленький набор данных,
[01:06:10.000 --> 01:06:12.000]  тысячи или миллионы записей,
[01:06:12.000 --> 01:06:14.000]  обычно для кластеров
[01:06:14.000 --> 01:06:16.000]  это очень маленький объем данных.
[01:06:16.000 --> 01:06:18.000]  И вот этой операцией broadcast
[01:06:18.000 --> 01:06:20.000]  мы указываем Spark
[01:06:20.000 --> 01:06:22.000]  раскидать этот результат,
[01:06:22.000 --> 01:06:24.000]  который мы получили,
[01:06:24.000 --> 01:06:26.000]  на все узлы.
[01:06:26.000 --> 01:06:28.000]  Вот параллельно по каждому узлу
[01:06:28.000 --> 01:06:30.000]  блок из вот этой таблицы,
[01:06:30.000 --> 01:06:32.000]  которая у нас указана
[01:06:32.000 --> 01:06:34.000]  строке 81,
[01:06:34.000 --> 01:06:36.000]  нам не придется читать
[01:06:36.000 --> 01:06:38.000]  из других узлов,
[01:06:38.000 --> 01:06:40.000]  из каких-то соседних результат
[01:06:40.000 --> 01:06:42.000]  из 79 строки,
[01:06:42.000 --> 01:06:44.000]  то есть он уже будет записан
[01:06:44.000 --> 01:06:46.000]  на все узлы, и это будут локальные данные.
[01:06:46.000 --> 01:06:48.000]  Как он уже делает там внутри
[01:06:48.000 --> 01:06:50.000]  у себя Join,
[01:06:50.000 --> 01:06:52.000]  это я не настолько хорошо знаю,
[01:06:52.000 --> 01:06:54.000]  но там используются shuffles
[01:06:54.000 --> 01:06:56.000]  и внутри
[01:06:56.000 --> 01:06:58.000]  представление для индексации
[01:06:58.000 --> 01:07:00.000]  данных, потому что сканировать их
[01:07:00.000 --> 01:07:02.000]  постоянно это очень дорогая операция.
[01:07:02.000 --> 01:07:04.000]  Внутри он проводит определенную
[01:07:04.000 --> 01:07:06.000]  индексацию, не полностью,
[01:07:06.000 --> 01:07:08.000]  не каждая запись,
[01:07:08.000 --> 01:07:10.000]  я тонкости не знаю,
[01:07:10.000 --> 01:07:12.000]  но за счет
[01:07:12.000 --> 01:07:14.000]  вот этой техники broadcast
[01:07:14.000 --> 01:07:16.000]  причем обращу внимание,
[01:07:16.000 --> 01:07:18.000]  что плюс должен идти без пробелов
[01:07:18.000 --> 01:07:20.000]  в начале комментариев.
[01:07:20.000 --> 01:07:22.000]  Мы
[01:07:22.000 --> 01:07:24.000]  очень сильно сокращаем
[01:07:24.000 --> 01:07:26.000]  вычисления,
[01:07:26.000 --> 01:07:28.000]  то есть по сути у нас
[01:07:28.000 --> 01:07:30.000]  получается параллельная
[01:07:30.000 --> 01:07:32.000]  обработка вот этой вот таблицы
[01:07:32.000 --> 01:07:34.000]  из multisample.unified
[01:07:34.000 --> 01:07:36.000]  на каждом узле без
[01:07:36.000 --> 01:07:38.000]  каких-то перекрестных
[01:07:38.000 --> 01:07:40.000]  обращений к другим узлам.
[01:07:40.000 --> 01:07:42.000]  Это очень дешевая операция,
[01:07:42.000 --> 01:07:44.000]  и ее нужно иметь в виду,
[01:07:44.000 --> 01:07:46.000]  когда делается Join, потому что, повторюсь,
[01:07:46.000 --> 01:07:48.000]  Spark не умеет в индексы
[01:07:48.000 --> 01:07:50.000]  и воспринимает данные как поток.
[01:07:50.000 --> 01:07:52.000]  Ну и дальше мы также
[01:07:52.000 --> 01:07:54.000]  самозаписываем overwrite
[01:07:54.000 --> 01:07:56.000]  также в директуре.
[01:07:56.000 --> 01:07:58.000]  Это вот там tmp,
[01:07:58.000 --> 01:08:00.000]  просто она бралась в время директуры,
[01:08:00.000 --> 01:08:02.000]  это промежуточное вычисление на случай,
[01:08:02.000 --> 01:08:04.000]  потому что вычисления длились по несколько часов,
[01:08:04.000 --> 01:08:06.000]  иногда по несколько суток,
[01:08:06.000 --> 01:08:08.000]  и если они падали, то
[01:08:08.000 --> 01:08:10.000]  можно было их
[01:08:10.000 --> 01:08:12.000]  не повторять заново,
[01:08:12.000 --> 01:08:14.000]  а взять
[01:08:14.000 --> 01:08:16.000]  промежуточных результатов
[01:08:16.000 --> 01:08:18.000]  данные. Также сам
[01:08:18.000 --> 01:08:20.000]  sp, также
[01:08:20.000 --> 01:08:22.000]  их можно представить в качестве
[01:08:22.000 --> 01:08:24.000]  SQL, мне было удобнее
[01:08:24.000 --> 01:08:26.000]  так, если что-то падало,
[01:08:26.000 --> 01:08:28.000]  то, конечно, проще было дальше повторять
[01:08:28.000 --> 01:08:30.000]  просто SQL, Spark
[01:08:30.000 --> 01:08:32.000]  в Spark SQL консоли.
[01:08:32.000 --> 01:08:34.000]  Записываем
[01:08:34.000 --> 01:08:36.000]  эти данные, ну и дальше.
[01:08:36.000 --> 01:08:38.000]  То есть, вот, собственно,
[01:08:38.000 --> 01:08:40.000]  тоже
[01:08:40.000 --> 01:08:42.000]  похожий запрос, также
[01:08:42.000 --> 01:08:44.000]  сам используется broadcast,
[01:08:44.000 --> 01:08:46.000]  есть такой момент, смотрите,
[01:08:46.000 --> 01:08:48.000]  в 82-й строке,
[01:08:48.000 --> 01:08:50.000]  к примеру,
[01:08:50.000 --> 01:08:52.000]  у нас
[01:08:52.000 --> 01:08:54.000]  данные, ну,
[01:08:54.000 --> 01:08:56.000]  joins по хромосоме, то есть хромосома,
[01:08:56.000 --> 01:08:58.000]  и позиция, в данном случае fkpos,
[01:08:58.000 --> 01:09:00.000]  она int,
[01:09:00.000 --> 01:09:02.000]  а в datapos это и
[01:09:02.000 --> 01:09:04.000]  alias на вот эту большую таблицу,
[01:09:04.000 --> 01:09:06.000]  ну, я так называю, то есть большой директориум,
[01:09:06.000 --> 01:09:08.000]  она там
[01:09:08.000 --> 01:09:10.000]  была строковая,
[01:09:10.000 --> 01:09:12.000]  и оно здесь приводится к int.
[01:09:12.000 --> 01:09:14.000]  То есть, здесь мы джойнили, а здесь,
[01:09:14.000 --> 01:09:16.000]  соответственно,
[01:09:16.000 --> 01:09:18.000]  в джойне используется
[01:09:18.000 --> 01:09:20.000]  вот это преобразование, где
[01:09:20.000 --> 01:09:22.000]  дата хром
[01:09:22.000 --> 01:09:24.000]  числовое,
[01:09:24.000 --> 01:09:26.000]  но в текстом представлении
[01:09:26.000 --> 01:09:28.000]  нужно добавлять
[01:09:28.000 --> 01:09:30.000]  хромосома, и после этого
[01:09:30.000 --> 01:09:32.000]  они уже джойнятся.
[01:09:32.000 --> 01:09:34.000]  Здесь тоже ничего простого,
[01:09:34.000 --> 01:09:36.000]  это обычная вытяжка, по-моему,
[01:09:36.000 --> 01:09:38.000]  из open-source
[01:09:38.000 --> 01:09:40.000]  тысячи геномов,
[01:09:40.000 --> 01:09:42.000]  там, в сравнении, производилось
[01:09:42.000 --> 01:09:44.000]  с образцами
[01:09:44.000 --> 01:09:46.000]  из
[01:09:46.000 --> 01:09:48.000]  репозитория тысячи геномов.
[01:09:48.000 --> 01:09:50.000]  Дальше, собственно,
[01:09:50.000 --> 01:09:52.000]  тоже здесь ничего
[01:09:52.000 --> 01:09:54.000]  нового, также
[01:09:54.000 --> 01:09:56.000]  джойн,
[01:09:56.000 --> 01:09:58.000]  по безымянной таблице,
[01:09:58.000 --> 01:10:00.000]  то есть, прямо обращение к директории
[01:10:00.000 --> 01:10:02.000]  dbsnp, dbsnp
[01:10:02.000 --> 01:10:04.000]  это, по-моему, база
[01:10:04.000 --> 01:10:06.000]  соответствия
[01:10:06.000 --> 01:10:08.000]  хромосом позиции
[01:10:08.000 --> 01:10:10.000]  с непу или гену.
[01:10:10.000 --> 01:10:12.000]  Опять же, этих
[01:10:12.000 --> 01:10:14.000]  подробностей
[01:10:14.000 --> 01:10:16.000]  не сильно знаю, потому что
[01:10:16.000 --> 01:10:18.000]  не моя специфика.
[01:10:18.000 --> 01:10:20.000]  Здесь такая же операция, мы также записываем
[01:10:20.000 --> 01:10:22.000]  это в директорию.
[01:10:22.000 --> 01:10:24.000]  Далее
[01:10:24.000 --> 01:10:26.000]  более сложный запрос, и этот запрос
[01:10:26.000 --> 01:10:28.000]  это обращение к лису, это непосредственно
[01:10:28.000 --> 01:10:30.000]  обращение к позгросу.
[01:10:30.000 --> 01:10:32.000]  Ему можно обратиться либо
[01:10:32.000 --> 01:10:34.000]  к представлению, которое внутри позгроса есть,
[01:10:34.000 --> 01:10:36.000]  либо можно прямо написать
[01:10:36.000 --> 01:10:38.000]  запрос
[01:10:38.000 --> 01:10:40.000]  к каждой таблице.
[01:10:40.000 --> 01:10:42.000]  Вот, допустим,
[01:10:42.000 --> 01:10:44.000]  эта таблица в позгросе,
[01:10:44.000 --> 01:10:46.000]  она почему-нибудь
[01:10:46.000 --> 01:10:48.000]  вернее, эта схема
[01:10:48.000 --> 01:10:50.000]  таблицы у нее там
[01:10:50.000 --> 01:10:52.000]  в таком регистрозависимом
[01:10:52.000 --> 01:10:54.000]  записи.
[01:10:54.000 --> 01:10:56.000]  MSP
[01:10:56.000 --> 01:10:58.000]  это тоже схема
[01:10:58.000 --> 01:11:00.000]  из позгроса, и вот
[01:11:00.000 --> 01:11:02.000]  with и with sample
[01:11:02.000 --> 01:11:04.000]  это представление определенное.
[01:11:04.000 --> 01:11:06.000]  То есть, можно написать прямо запрос,
[01:11:06.000 --> 01:11:08.000]  который уйдет непосредственно в позгрос,
[01:11:08.000 --> 01:11:10.000]  он не будет, Spark не будет
[01:11:10.000 --> 01:11:12.000]  дернуть каждую таблицу и сам выполнять запрос,
[01:11:12.000 --> 01:11:14.000]  он его отправит именно в позгрос и получит
[01:11:14.000 --> 01:11:16.000]  результат. И этот результат будет
[01:11:18.000 --> 01:11:20.000]  скажем так, не записан,
[01:11:20.000 --> 01:11:22.000]  а отображен на представление
[01:11:22.000 --> 01:11:24.000]  pop-view, то есть
[01:11:24.000 --> 01:11:26.000]  популяционное представление
[01:11:26.000 --> 01:11:28.000]  было, по-моему,
[01:11:28.000 --> 01:11:30.000]  в сравнении тасканцы, фины,
[01:11:30.000 --> 01:11:32.000]  британцы
[01:11:32.000 --> 01:11:34.000]  и так далее.
[01:11:34.000 --> 01:11:36.000]  Здесь мы создаем представление, которое
[01:11:36.000 --> 01:11:38.000]  отображено на запрос в позгросе.
[01:11:38.000 --> 01:11:40.000]  Здесь же вот
[01:11:40.000 --> 01:11:42.000]  можно указать ему
[01:11:42.000 --> 01:11:44.000]  юзера, пароля
[01:11:44.000 --> 01:11:46.000]  и вот dbtable либо
[01:11:46.000 --> 01:11:48.000]  query можно указать.
[01:11:48.000 --> 01:11:50.000]  В данном случае никакой причины
[01:11:50.000 --> 01:11:52.000]  было написано dbtable.
[01:11:52.000 --> 01:11:54.000]  Указывается, соответственно, в
[01:11:54.000 --> 01:11:56.000]  options URL, это dsn
[01:11:56.000 --> 01:11:58.000]  позгроса, то есть он
[01:11:58.000 --> 01:12:00.000]  находится по хосту, у него list
[01:12:00.000 --> 01:12:02.000]  host, база данных, list
[01:12:02.000 --> 01:12:04.000]  лабораторная информационная
[01:12:04.000 --> 01:12:06.000]  система.
[01:12:06.000 --> 01:12:08.000]  Так же самое, это
[01:12:08.000 --> 01:12:10.000]  операция можно сделать на обычном SQL
[01:12:10.000 --> 01:12:12.000]  на, например, Spark
[01:12:12.000 --> 01:12:14.000]  Console. Это 11 пример,
[01:12:14.000 --> 01:12:16.000]  что пароли можно
[01:12:16.000 --> 01:12:18.000]  пользовать, пароли можно
[01:12:18.000 --> 01:12:20.000]  задать через set, чтобы
[01:12:20.000 --> 01:12:22.000]  не писать прямо в запросе.
[01:12:22.000 --> 01:12:24.000]  Это 112-113
[01:12:24.000 --> 01:12:26.000]  строка. Так же самое делаем drop
[01:12:26.000 --> 01:12:28.000]  tables.
[01:12:28.000 --> 01:12:30.000]  Это, на самом деле, обозначается
[01:12:30.000 --> 01:12:32.000]  как table, но по факту это является
[01:12:32.000 --> 01:12:34.000]  представлением
[01:12:34.000 --> 01:12:36.000]  запроса, именно уже в другом источнике,
[01:12:36.000 --> 01:12:38.000]  в частности в позорстве.
[01:12:38.000 --> 01:12:40.000]  Так же самое, create table using
[01:12:40.000 --> 01:12:42.000]  gdbc, это формат.
[01:12:42.000 --> 01:12:44.000]  Там у нас выходит Spark, здесь используется gdbc,
[01:12:44.000 --> 01:12:46.000]  то есть
[01:12:46.000 --> 01:12:48.000]  стандартный явский database
[01:12:48.000 --> 01:12:50.000]  connector, options и
[01:12:50.000 --> 01:12:52.000]  URL, query.
[01:12:52.000 --> 01:12:54.000]  Кстати, здесь можно
[01:12:54.000 --> 01:12:56.000]  пробиться, можно равно.
[01:12:56.000 --> 01:12:58.000]  Вот запрос и также
[01:12:58.000 --> 01:13:00.000]  пароль. Здесь
[01:13:00.000 --> 01:13:02.000]  тоже все просто, и его можно
[01:13:02.000 --> 01:13:04.000]  при необходимости закешировать, но вот
[01:13:04.000 --> 01:13:06.000]  в данном случае здесь не было необходимости
[01:13:06.000 --> 01:13:08.000]  закешировать, это просто
[01:13:08.000 --> 01:13:10.000]  добавить метод cache, который
[01:13:10.000 --> 01:13:12.000]  загрузит шафл.
[01:13:12.000 --> 01:13:14.000]  На этом тонкости
[01:13:14.000 --> 01:13:16.000]  я не буду их сейчас касаться.
[01:13:16.000 --> 01:13:18.000]  То есть здесь создаем представление уже,
[01:13:18.000 --> 01:13:20.000]  которое смотрит на подгроз.
[01:13:20.000 --> 01:13:22.000]  Дальше
[01:13:22.000 --> 01:13:24.000]  select из
[01:13:24.000 --> 01:13:26.000]  этого же представления,
[01:13:26.000 --> 01:13:28.000]  у нас там какие-то
[01:13:28.000 --> 01:13:30.000]  sample
[01:13:30.000 --> 01:13:32.000]  не помню,
[01:13:32.000 --> 01:13:34.000]  это уже
[01:13:34.000 --> 01:13:36.000]  операция, посредственная Spark
[01:13:36.000 --> 01:13:38.000]  над представлением
[01:13:38.000 --> 01:13:40.000]  данных из подгроза.
[01:13:40.000 --> 01:13:42.000]  И дальше
[01:13:42.000 --> 01:13:44.000]  уже такие более сложные запросы
[01:13:44.000 --> 01:13:46.000]  идут, это уже
[01:13:46.000 --> 01:13:48.000]  joins
[01:13:48.000 --> 01:13:50.000]  данных
[01:13:50.000 --> 01:13:52.000]  из предварительно подготовленных, допустим
[01:13:52.000 --> 01:13:54.000]  fksp, fk 1000
[01:13:54.000 --> 01:13:56.000]  и
[01:13:56.000 --> 01:13:58.000]  fk
[01:13:58.000 --> 01:14:00.000]  1000
[01:14:00.000 --> 01:14:02.000]  с
[01:14:02.000 --> 01:14:04.000]  нечитаемым
[01:14:04.000 --> 01:14:06.000]  renbc,
[01:14:06.000 --> 01:14:08.000]  это определённые т.е. промежуточные данные
[01:14:08.000 --> 01:14:10.000]  не записывались
[01:14:10.000 --> 01:14:12.000]  на hdfs
[01:14:12.000 --> 01:14:14.000]  потому что, напомню, что Spark
[01:14:14.000 --> 01:14:16.000]  это использует линейные вычисления
[01:14:16.000 --> 01:14:18.000]  и эти данные
[01:14:18.000 --> 01:14:20.000]  в принципе вот, запись на диске это аналог
[01:14:20.000 --> 01:14:22.000]  кэширования, но в случае сбоя
[01:14:22.000 --> 01:14:28.240]  не привез несколько часов или не ждать, пока основы эти данные будут вычислены,
[01:14:28.240 --> 01:14:32.680]  в случае, если мы их запишируем, потому что кишер не пропадет, а материализованная
[01:14:32.680 --> 01:14:46.000]  запись останется. Ну и дальше сложные джойны, это обогащение данными,
[01:14:46.680 --> 01:14:53.080]  вот хромосом, позиция, вот с базы данных, рей, оверлапс, это встроенная функция
[01:14:53.080 --> 01:15:06.080]  Spark, в частности это пересечение при, это джойн при условии, что альты в базе данных,
[01:15:06.080 --> 01:15:19.360]  в базе данных с DBSNP, пересекают хотя бы с одним альтом из обрабатываемых нами данных,
[01:15:19.360 --> 01:15:24.840]  вот с той большой таблицы, то есть это обычный джойн, это очень тяжелая операция, Spark ее не
[01:15:24.840 --> 01:15:35.400]  любит, она требует много ресурсов и занимает большую шафу. Дальше еще более сложный запрос,
[01:15:35.400 --> 01:15:45.160]  это как раз уже определение генотипа, тут скорее мне вопрос к аудитории, здесь нужно объяснять
[01:15:45.160 --> 01:15:51.680]  вот эти тонкости или в основном понятно, что времени уже много, если буду дальше грузить,
[01:15:51.680 --> 01:15:57.240]  ты такими техническими подробностями, то могу упустить что-то более важное.
[01:15:57.240 --> 01:16:09.600]  Весь этот пример посвящен тому, чтобы у нас склеить две базы данных с информацией о динамах, да?
[01:16:09.600 --> 01:16:18.000]  Да, да, да, даже больше двух, то есть есть какая-то база данных, то есть файлы с
[01:16:18.000 --> 01:16:24.960]  какими-то результатами формакологическими, которые зависят как-то от каких-то генов или
[01:16:24.960 --> 01:16:35.720]  рсов, есть у нас отдельно в паркете базы генов, соответственно есть подобные, есть у нас
[01:16:35.720 --> 01:16:42.080]  эталонная база тысячи генов, которая лежит в интернете, и на ее основании нужно получить
[01:16:42.080 --> 01:16:49.440]  чистоту влияния вот этой формакологии в зависимости от определенных генов,
[01:16:49.440 --> 01:16:58.160]  все это по сути происходит в последнем запросе, гетерозиготы, гомозиготы, то есть гетерозиготы это
[01:16:58.160 --> 01:17:04.120]  на одной хромосомии замена, гомозиготы это на двух хромосомах, которые повышают патогенность,
[01:17:04.120 --> 01:17:10.640]  вероятность патогенности, и вот это все, то есть условно вся эта информация сливается в один
[01:17:10.640 --> 01:17:18.120]  движок и обрабатывается обычными SQL-средствами, то есть здесь ничего такого сверхъестественного нет,
[01:17:18.120 --> 01:17:23.000]  но есть определенные особенности, которые повторили, что Spark использует линейного
[01:17:23.000 --> 01:17:29.240]  вычисления и не умеет в индексы, работает с потоками, вот это надо учитывать, а так вот
[01:17:29.240 --> 01:17:36.600]  собственно, вот пожалуй и все, а вот кстати мы дошли до конца файла. Да Юр, спасибо тебе огромное,
[01:17:36.600 --> 01:17:41.280]  мне кажется это было супер интересно, и наоборот, посмотрите на прям это пример,
[01:17:41.280 --> 01:17:49.120]  Spark прямо не брав и глас может привести к сравнению, потому что Spark очень активно используется в
[01:17:49.120 --> 01:17:59.200]  healthcare, то есть в здравоохранении, здесь очень много примеров, можно идти на GitHub, где
[01:17:59.200 --> 01:18:07.120]  в частности там геномное сравнение, влияние, точнее там как развивается, особенно сейчас много
[01:18:07.360 --> 01:18:17.800]  времени, развитие, претращение развития рака, и Spark здесь играет в один из ключевых ролей для
[01:18:17.800 --> 01:18:28.080]  data processing, data, которая используется для этого через EMR, Electronic Medical Records, то есть на записи
[01:18:28.080 --> 01:18:40.320]  всех пациентов, то чтобы строить машинное обучение, ML модель, то для именно вот
[01:18:40.320 --> 01:18:52.000]  претращения, развития рака на первых его стадиях. Если посмотреть статики, посвященные этому
[01:18:52.000 --> 01:19:01.640]  этим изучением, Spark является флагменом и инструментом для процессинга данных, для этого изучения.
[01:19:01.640 --> 01:19:12.400]  Я знаю, что у нас время уже дошло к концу, есть еще у нас пару слайдов, они больше посвящены,
[01:19:12.400 --> 01:19:20.200]  один из слайдов будет посвящен, наверное, про Databricks, я бы хотел сказать, что начните,
[01:19:20.200 --> 01:19:26.000]  если еще не начали смотреть на Databricks, Юра сейчас расшаривает снайпер-экран,
[01:19:26.000 --> 01:19:35.720]  то есть если хотите прямо сейчас начать попытаться, то есть запустить собственные какие-то проекты,
[01:19:35.720 --> 01:19:55.320]  начать изучать, уже, наверное, погрузились в AWS, Azure и JCP. Призваю вас посмотреть на Databricks,
[01:19:55.320 --> 01:20:08.040]  на их решения, на Data Lake House, у них много очень открытых источников книг, которые они публикуют
[01:20:08.040 --> 01:20:18.080]  в этом доступе, которые по сути являются очень интересным для изучения, для чтения, то есть их
[01:20:18.080 --> 01:20:27.640]  подход, Delta Lake, очень-очень интересно, как данные используют, то есть паркетные данные,
[01:20:27.640 --> 01:20:33.520]  как это данные представляются в виде не само, как данных, а некий subset данных,
[01:20:33.520 --> 01:20:40.440]  который нужен именно для процессинга, то есть не стриминг, а именно процессинг данных, такой
[01:20:40.440 --> 01:20:46.200]  layer, который позволяет данным немного абстрагироваться именно от такого storage,
[01:20:46.200 --> 01:20:54.000]  от данных классического и работа на уровне такого subset данных, которые позволяют быстрее данные
[01:20:54.000 --> 01:20:59.480]  обрабатывать. Также у них есть книга сейчас про Lake House, тоже интересно, начало читать,
[01:20:59.480 --> 01:21:07.720]  пока не могу ничего поделиться, к сожалению, только начало изучать. Ну, если будет время,
[01:21:07.720 --> 01:21:13.880]  посмотрите, довольно-таки интересные статьи у них публикуются, и также различные конференции,
[01:21:13.880 --> 01:21:22.200]  которые... вот сейчас будет в ноябре конференция по... так, наверное, экран не видно, да, экран по
[01:21:22.200 --> 01:21:27.400]  side data bricks. Не видно? Видно, что здесь пора презентацию, да?
[01:21:27.400 --> 01:21:30.360]  Нет, видно. Видно?
[01:21:30.360 --> 01:21:31.000]  Да.
[01:21:31.000 --> 01:21:42.280]  Так, я могу показать, learning, learning, yes, no, no.
[01:21:42.280 --> 01:21:56.280]  То есть здесь можно проиграть по AWS, HTTP, заведите себе аккаунт, начните изучать,
[01:21:56.760 --> 01:22:06.120]  параллельно вы будете изучать не только Spark, но и сами сервисы, и инструменты самого колодного
[01:22:06.120 --> 01:22:13.160]  провайдера, там, HTTP и AWS, потому что, ну, это на самом деле будет очень полезно для развития вашей,
[01:22:13.160 --> 01:22:21.320]  как карьер, карьерного развития и профессионального развития. Также хотел еще, наверное, поделиться
[01:22:21.320 --> 01:22:31.160]  в оптимизации Spark, то, что моя предыдущая команда разрабатывала, то, как лучше оптимизировать Spark
[01:22:31.160 --> 01:22:39.160]  в запросах в ходу. Ну, я, наверное, у вас есть эта презентация, не буду уже ваше время много
[01:22:39.160 --> 01:22:45.880]  отнимать. Посмотрите, пожалуйста, если какие-то вопросы будут, я присоединюсь к вам в чат,
[01:22:45.880 --> 01:22:53.640]  в телеграм. Могу ответить на какие-то вопросы, ну, и также поддерживать какую-то связь там,
[01:22:53.640 --> 01:23:03.080]  там через LinkedIn, либо через телеграм. Телец может каким-то интересным тоже, там,
[01:23:03.080 --> 01:23:14.480]  фидбеком по определенным решениям, и либо каким-то опытом, делиться опытом также. Ну,
[01:23:14.560 --> 01:23:21.560]  наверное, на этом все. Большого всем спасибо. Надеюсь, было интересно. Если нет, то будем
[01:23:21.560 --> 01:23:27.520]  работать над тем, что было бы, если сейчас было более интересно. Если опять какие-то вопросы
[01:23:27.520 --> 01:23:35.760]  остались, можно сейчас посвятить этим вопросом. Если нет, то можно тогда уже в оффлайне пообщаться.
[01:23:35.760 --> 01:23:51.280]  Такой достаточно общий вопрос. Я не очень имею представления о том, что такое вообще дат инжиниринг.
[01:23:51.280 --> 01:23:59.360]  Это как раз про обработку данных и агрегирование какое-то, или что это вообще?
[01:23:59.360 --> 01:24:10.400]  Не, вопрос очень хороший, но он такой больше является частью философский. Дат инжиниринг,
[01:24:10.400 --> 01:24:18.720]  знаете, понятие, где же это было у меня, я его удалил. Что такое вообще инжиниринг?
[01:24:18.720 --> 01:24:30.760]  Это ответ на ваш вопрос. Дат инжиниринг, что такое? Это использование всех различных
[01:24:30.760 --> 01:24:36.920]  инструментов. Тоже они могут быть, имеют свои ограничения, имеют свои плюсы и минусы.
[01:24:36.920 --> 01:24:42.840]  Нет такого единого инструмента, который может решить абсолютно все. И я также вас призываю
[01:24:42.840 --> 01:24:53.520]  не использовать подход, потому что это такой подход, когда кто-то что-то разработал,
[01:24:53.520 --> 01:24:59.560]  у него это работало или у нее это работало, значит я это могу переиспользовать, потому что у меня
[01:24:59.560 --> 01:25:05.560]  похожая проблема, задачу похожую решаю. Я вас призываю не использовать такой подход в качестве
[01:25:05.560 --> 01:25:13.280]  изучения примера, да, но не идите по этому пути никогда. То есть всегда пробуйте что-то
[01:25:13.280 --> 01:25:21.080]  собственно дорабатывать, можно даже брать что-то, как я сказал, кто что-то разработал раньше,
[01:25:21.080 --> 01:25:30.160]  но копировать один в один не надо. Это приведет к нарастанию большого и тех долга внутри компании,
[01:25:30.160 --> 01:25:36.040]  ну и никакого прогресса по сути не будет, потому что какое-то решение, то есть какая-то
[01:25:36.040 --> 01:25:40.400]  разработка основана для определенного решения. Она не была уникальна, она была именно конкретно,
[01:25:40.400 --> 01:25:48.000]  точнее она была уникальна, не общая. И дата инжиниринга, он смотрит на разные варианты
[01:25:48.000 --> 01:25:55.120]  развития решения задач по связанным с датой. То есть что такое вообще инженер, инжиниринг,
[01:25:55.120 --> 01:26:05.800]  это вот решение различных проблем, имея какие-то limited resources и limited tools,
[01:26:05.800 --> 01:26:13.360]  наверное. Поэтому в нашем варианте дата инжиниринг позволяет нам решать задачи,
[01:26:13.360 --> 01:26:23.400]  связанные с данными, используя инструменты Spark, Flink, TouchSchool, какие-то proprietary инструменты,
[01:26:23.520 --> 01:26:30.440]  сделать из данных, формировать их ценность в данных, то есть сделать какой-то там есть большой объем
[01:26:30.440 --> 01:26:37.560]  данных. Мы вычисляем какие-то определенные элементы этих данных, которые нам необходимы для
[01:26:37.560 --> 01:26:50.360]  аналитики, для решения задач, связанных с healthcare, допустим, определяя tumor, опухоль, рака, то есть
[01:26:50.360 --> 01:26:57.880]  как формируется он. Это вот именно задача дата инжиниринга. Дальше вот эта фича инжиниринга,
[01:26:57.880 --> 01:27:09.560]  это уже такой более математический подход для создания модели ML и data science, потому что уже
[01:27:09.560 --> 01:27:17.880]  здесь мы определенно берем фичи, фичерсов дата, которые помогают нам строить именно такую целостную
[01:27:17.880 --> 01:27:30.720]  модель ML, но начало всего это лежит в дате инжиниринге. Виктор, ответил наш вопрос или еще
[01:27:30.720 --> 01:27:37.560]  больше вопросов возник? В целом, вообще понимание какое-то появилось, да, спасибо. Пожалуйста,
[01:27:37.560 --> 01:27:43.560]  ну еще раз, если требуется больше какое-то пояснение или у вас возникнут какие-то вопросы,
[01:27:43.880 --> 01:27:52.200]  после некоторого времени, когда вы отойдете от этой лекции, пишите либо мне в LinkedIn,
[01:27:52.200 --> 01:27:58.920]  когда мы присоединимся мы с Юрой, будем поддерживать связь и, надеюсь, мы как-то вам
[01:27:58.920 --> 01:28:07.080]  поможем в вашем развитии в обучении. Ваши преподаватели так, наверное, делают все возможное,
[01:28:07.560 --> 01:28:14.800]  и вы передовой в институте всей России, да и вообще в мире, так что вам очень повезло,
[01:28:14.800 --> 01:28:19.960]  наверное, быть настоящим путешественником, я бы сам хотел стать им, но уже, наверное,
[01:28:19.960 --> 01:28:23.960]  много поздно. Так что всем спасибо еще раз большое и всего доброго.
