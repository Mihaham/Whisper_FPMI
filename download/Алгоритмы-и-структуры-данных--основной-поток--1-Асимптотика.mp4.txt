[00:00.000 --> 00:29.920]  Шестой сегодня, да? Кажется. Вот. Меня зовут Илья Данилович. Мы начинаем курс лекции
[00:29.920 --> 00:39.760]  основного потока. Если вы внезапно не основной поток, то вы не там, короче. Вот. Давайте немножко
[00:39.760 --> 00:44.160]  сначала про структуру курса, про оценивание и все такое, потом перейдем к содержательной части.
[00:44.160 --> 00:49.520]  Значит, у нас будет три семестра. Все оцениваются независимо, все более-менее как бы из независимых
[00:49.520 --> 00:55.480]  каких-то кусков, независимый набор тем. Значит, в этом семестре у нас будут по темам в основном
[00:55.480 --> 01:01.360]  структуры данных. То есть у нас там какой-то префикс просто введения, потом из содержательного кучи
[01:01.360 --> 01:06.440]  хэштаблицы, дерево поиска и дерево отрезков. Ну, такие классические стандартные структуры данных,
[01:06.440 --> 01:13.000]  которые нам понадобятся на протяжении остальных двух семестров. Вот. Я решил как бы вынести такую
[01:13.000 --> 01:19.480]  подготовительную базу в первый семестр, чтобы потом это использовать. У нас в каждом семестре
[01:19.480 --> 01:26.840]  будет и зачет, и экзамен. Оценка за зачет ставится по работе в семестре. У нас будут теоретические
[01:26.840 --> 01:33.960]  домашки и контесты, где надо будет писать решение задач. Вот. Соответственно это проверяют ваши
[01:33.960 --> 01:40.200]  семинаристы и ассистенты помогают с проверком домашек. Они вам расскажут про то, как именно вы
[01:40.200 --> 01:45.080]  их сдаете. То есть там я буду выкладывать ссылку на контест, они вам расскажут как писать код,
[01:45.080 --> 01:49.240]  будут рассказывать про код стайл, будут проверять ваш код, будут проверять ваши домашки и ставить
[01:49.240 --> 01:55.200]  оценки в табличку, которая считает как-то формулу по тому, насколько успешно вы все
[01:55.200 --> 02:01.920]  зарешали. Значит, у каждой задачи будет просто какая-то стоимость и будут какие-то пороги на
[02:01.920 --> 02:07.880]  каждую оценку. Чем больше баллов наберете, тем больше будет итоговая оценка. Вот. Это зачет.
[02:07.880 --> 02:19.000]  Давайте я напишу, что зачет от работы в семестре. И здесь, значит, это теоретические домашки,
[02:19.000 --> 02:25.720]  теоретические задачи, которые вы будете сдавать либо уст на семинаристу, либо, ну там, на бумажке
[02:25.720 --> 02:30.360]  напишите решение. То есть теоретически это в смысле, что вам не нужно кодить, вам нужно описать
[02:30.360 --> 02:34.120]  алгоритм, доказать, что он работает, доказать, что он работает за правильную симптотику. Ну, короче,
[02:34.280 --> 02:40.560]  все кроме кода сделать. Вот. И, соответственно, наоборот, практические задачи, где вам, наоборот,
[02:40.560 --> 02:47.680]  нужно только код написать и сделать так, чтобы оно проходило тесты. Все у каждой задачи свой вес
[02:47.680 --> 02:58.840]  и сумма считается как итоговая оценка. Так. И, соответственно, будет экзамен. Ну, там просто
[02:58.840 --> 03:10.520]  эта независимая оценка, она не зависит от работы в семестре. И просто вот пришли на экзамен,
[03:10.520 --> 03:15.720]  как ответили, такая оценка ставится. Неважно, что вы получили в течение семестра, не влияет на то,
[03:15.720 --> 03:23.400]  что вы работали на экзамене. Кажется, по оцене более-менее все. Есть какие-то вопросы концептуальные?
[03:23.400 --> 03:31.640]  Ну, две отдельные оценки. У вас есть ДИВ-зачет, это одна оценка за, соответственно,
[03:31.640 --> 03:35.720]  за четную неделю ставится, и отдельная оценка за экзамен в экзаменационную сессию, там,
[03:35.720 --> 03:42.760]  декабрь и январь. Вот, просто две оценки будут разные. Хорошо.
[04:05.720 --> 04:13.080]  Окей, давайте тогда переходить к содержательной части, поговорим про асимптотики быстренько.
[04:13.080 --> 04:25.200]  Что мы хотим? Мы хотим вообще сначала договориться о том, что мы будем считать
[04:25.200 --> 04:31.520]  сложностью работы алгоритма. Скажем, для решения одной какой-то конкретной задачи может быть
[04:31.520 --> 04:37.600]  предложено несколько алгоритмов ее решающих, несколько программ, которые отвечают на тот запрос,
[04:37.600 --> 04:42.680]  который в задаче задается. Вот, мы хотим их научиться сравнить между собой, говорить какие более
[04:42.680 --> 04:48.120]  эффективные, какие менее эффективные, и сказать, между какими мы, по крайней мере, с теоретической
[04:48.120 --> 04:52.960]  точки зрения, различия проводить не будем на те, которые для нас примерно одинаково хорошо работают.
[04:52.960 --> 05:01.000]  Вот, и для этого мы вводим следующее определение. Значит, ну давайте я, во-первых, договорюсь,
[05:01.040 --> 05:10.760]  что я сегодня в качестве n большого использую натуральные числа, начиная с 1. Значит,
[05:10.760 --> 05:19.720]  пусть f и g это две функции из n в n, то есть принимают натуральные аргументы,
[05:19.720 --> 05:37.440]  выучают натуральное число. Тогда пишем, что f равно o от g, если, так, давайте сначала словами,
[05:37.440 --> 05:56.240]  существует положительная константа c, такая, что существует n большое, такое, что для любого n
[05:56.240 --> 06:08.760]  маленького больше н большого выполняется следующее соотношение. f от n не превосходит c умножить на g от n.
[06:08.760 --> 06:21.120]  Значит, какой смысл? Смотрите, существует какая-то константа c больше 0, а просто какое число? 10,
[06:21.120 --> 06:27.440]  500, что-то такое. Какое число? Такое, что для всех n, начиная с какого-то, больших и равных
[06:27.440 --> 06:32.560]  какого-то n большого, первая функция не больше, чем вторая умножена константу, где вот эта вот
[06:32.560 --> 06:40.400]  константа как раз в самом начале у нас определено c. f равно o от g, да, o большое. Большая буква o.
[06:40.400 --> 06:50.000]  Мораль. Для всех достаточно больших n, то есть нам вообще говоря не очень интересно, что происходит
[06:50.000 --> 06:54.280]  на каком-то начальном отрезке вот этих маленьких натуральных аргументов. Если n маленькое меньше,
[06:54.280 --> 07:00.080]  чем n большое, то нам на самом деле не очень интересно, как функция между собой взаимодействует,
[07:00.080 --> 07:05.720]  кто больше, кто меньше, потому что на маленьких аргументах всегда, если что, можно задачу как бы
[07:05.720 --> 07:11.240]  заевать. То есть вы можете себе представить, что n это длина входа. Представьте, у вас есть задача,
[07:11.240 --> 07:16.840]  n это длина входа, то есть сколько чисел подается на вход, например. Понятно, что если у вас вход
[07:16.840 --> 07:22.520]  небольшой, n меньше, чем n большое, то, наверное, можно как-нибудь там просто написать программу,
[07:22.520 --> 07:26.680]  которая все случаи перебирает и что-нибудь возвращает. Поэтому нам на самом деле интересно
[07:26.680 --> 07:32.480]  поведение только для больших n, для всех начиная с какого-то, грубо говоря, на бесконечности. И вот
[07:32.480 --> 07:36.560]  собственно для всех этих n, начиная с какого-то, мне нужно, чтобы одна функция была не большим,
[07:36.560 --> 07:45.200]  другая умножена константу. Вот. Ну и мы тогда будем говорить, что, скажем, если есть два алгоритма,
[07:45.200 --> 07:53.040]  решающих задачу, один за время f от n, другой за время g от n, причем f это у большого g, то f как бы
[07:53.040 --> 07:58.000]  более выгодный алгоритм, потому что он для всех содержательных n не больше, чем g, но, возможно,
[07:58.000 --> 08:10.480]  умноженный констант. Давайте это замечание сделаем. Да. Может быть никто не мешает. Еще раз.
[08:10.480 --> 08:21.360]  Тогда она еще, тогда она прям супер крутая, она сильно лучше, чем g. Как раз, если она больше единицы,
[08:21.360 --> 08:46.760]  тогда... Не понял вопрос, короче. Но, тем не менее, между ними соотношение будет какая-то константа.
[08:46.760 --> 08:53.800]  И вот как раз, то есть да, с точки зрения константы, возможно, g будет как бы лучше, но с точки зрения
[08:53.800 --> 08:57.840]  порядка роста они будут одинаковые. Если вот тот случай, который вы имеете в виду, то они как раз
[08:57.840 --> 09:01.960]  будут примерно одинаковые. И мы именно не хотим делать различия между ними, если они отличаются
[09:01.960 --> 09:09.800]  всего лишь в константу раз. Чуть-чуть позже, значит, тоже запишу. Замечание, если f равно у
[09:09.800 --> 09:31.400]  большой вот g, и есть два алгоритма, решающих какую-то задачу. Значит, один за время f от n,
[09:31.400 --> 09:59.480]  другой за время g от n, тот первый считается эффективнее второго. Вот именно потому, что для
[09:59.480 --> 10:04.200]  всех содержательных n, для всех n, начиная с некоторого, функция f не больше, чем g на константу.
[10:04.200 --> 10:11.080]  Вот. И мы для себя считаем, что вот это вот отличие в константу раз для нас несущественно. То есть,
[10:11.080 --> 10:16.960]  если f не больше, чем c на g, тогда f уже нормальная, хорошая, не хуже, чем g.
[10:16.960 --> 10:25.640]  С большой не можем упустить? Ну, поменять всегда определение. Мы хотим именно так, чтобы было. То
[10:25.640 --> 10:54.360]  есть, я хочу, чтобы два... Сейчас, секунду, вот отвечая на ваш вопрос конкретно, я хочу,
[10:54.360 --> 11:02.440]  например, чтобы 100n было от n квадрат. Если я не позволяю себе содержательную константу c,
[11:02.440 --> 11:08.920]  то вот это будет неверно. Потому что, например, при n равно 1, 100... Так, ну, начиная с какого-то,
[11:08.920 --> 11:23.200]  это верно, конечно, да? Я понимаю, да. Окей. Да, я понял, хорошо. Ну, смотрите, это работает,
[11:23.200 --> 11:26.600]  только если действительно первая функция меньше, чем вторая, симпатически. Ну, то есть, там,
[11:26.600 --> 11:30.520]  предел отношения ноль. Если первая, то мало от второй, на самом деле. Вот. Но тогда это не
[11:30.520 --> 11:34.040]  работает на функциях одного порядка. Мы хотим на функциях одного порядка тоже, чтобы они вот так
[11:34.040 --> 11:42.920]  соотносились. Окей. Да. Это нормально. Вот. Сейчас как раз мораль. Почему нам нормально,
[11:42.920 --> 11:48.640]  если две функции отличаются в константу раз, даже если константа большая? Тут есть много
[11:48.640 --> 11:52.840]  объяснений. То есть, смотрите, мы считаем, грубо говоря, вот у нас есть два алгоритма. Например,
[11:52.840 --> 12:00.640]  давайте посмотрим. Есть одна функция, работающая, скажем, за 10n. Есть вторая, работающая, скажем,
[12:00.640 --> 12:10.160]  за 200n. Да, с точки зрения нашего определения, во-первых, f – это у большой от g. Так,
[12:10.160 --> 12:14.400]  значит, с точки зрения нашего определения f – это у большой от g. Ну, потому что, например,
[12:14.400 --> 12:23.520]  можно взять даже ц равную единице просто. У нас всегда 10n не больше чем 1 на 200n. С другой стороны,
[12:23.520 --> 12:32.240]  g – это у от f. Потому что можно, скажем, положить константу 20, и тогда будет верно, что 200n не
[12:32.240 --> 12:52.640]  больше чем 20 на 10 от n. Вот, вроде пока не обманываю. Вот это. Ну, смотрите, здесь написано
[12:52.640 --> 12:57.200]  примерно следующее. Вот представьте, есть два алгоритма, решающие одну и ту же задачу. Один
[12:57.200 --> 13:03.280]  работает за столько, другой за столько. Ну вот, что такое n? n – это, грубо говоря,
[13:03.280 --> 13:16.960]  параметр входа. Представьте себе задачу. У вас есть? Да. Да, одну и ту же задачу решают. Вот,
[13:16.960 --> 13:25.240]  написано же. Нет, просто не совсем понятно. Грубо говоря, в одном моменте мы можем понимать,
[13:25.240 --> 13:31.360]  что f меньше или равно с учетом константы, а в другом моменте… Нет, просто f меньше или
[13:31.360 --> 13:36.120]  равно, чем g с учетом константы. Просто всегда. Для всех n, начиная с некоторого.
[13:36.120 --> 13:44.600]  Так они же имеют одинаковость. Нет, это здесь нигде не написано. Вот,
[13:44.640 --> 13:48.160]  определение. Здесь неравенство не строгое. Здесь не написано, что они имеют одинаковость
[13:48.160 --> 13:53.000]  в сем точках. Здесь написано, что f имеет сем точку не больше, чем g, потому что неравенство.
[13:53.000 --> 14:04.840]  Да, например. Значит так, смотрите. Так вот, почему можно здесь брать, действительно, любую
[14:04.840 --> 14:10.640]  положительную константу? Почему я себе это позволяю? Потому что я хочу не различать такие функции. Вот
[14:10.640 --> 14:18.600]  функции одного порядка роста я не хочу различать между собой. Потому что, во-первых, очень многое вот
[14:18.600 --> 14:24.280]  в этой константе, вот этих десять или двести, зависит от конкретной архитектуры компьютера. Потому
[14:24.280 --> 14:29.600]  что когда мы оцениваем реальное время работы алгоритма, мы на самом деле многое игнорируем. Мы
[14:29.600 --> 14:34.360]  игнорируем то, за сколько обращается, например, происходит доступ в память. То есть представьте,
[14:34.360 --> 14:39.160]  у вас есть какой-то длинный массив, и мы обращаемся к какому-то и тому его элементу. Мы считаем,
[14:39.160 --> 14:44.880]  чтобы работать за единицу. Просто одна итерация. Взять число в какой-то ячейке массива или там
[14:44.880 --> 14:50.320]  просто где-то в памяти, из памяти что-то достать. Мы считаем, как бы в нашей неформальной модели
[14:50.320 --> 14:56.280]  вычислений, что это единица по времени. Одна элементарная операция. На самом деле, конечно,
[14:56.280 --> 15:03.120]  время работы такой операции может варьироваться. Потому что у вас есть на самом деле какие-то там
[15:03.120 --> 15:06.800]  указатели, которые показывают куда-то в вашу память, и вам нужно это указатель куда-то передвинуть и
[15:07.200 --> 15:12.440]  посмотреть, что вот здесь вот лежит. Это, наверное, зависит от того, какое расстояние нужно этому
[15:12.440 --> 15:17.200]  указателю пройти. Если у вас есть какая-то большая память, вам нужно как-то по ней сначала походить,
[15:17.200 --> 15:22.440]  чтобы достать вот этот самый элемент. А мы всегда говорим, что это единица. Один элементарный такт.
[15:22.440 --> 15:28.800]  Поэтому уже эти константы не очень прочные. Потому что зависит от того, какие на самом деле
[15:28.800 --> 15:34.400]  элементарные операции. Дальше мы, например, будем считать, что сложение и умножение это тоже
[15:34.400 --> 15:39.480]  элементарная операция, которая работает за единицу, за один элементарный такт. Вот есть там два числа,
[15:39.480 --> 15:46.080]  будем считать, что команда x плюс y и x умножить на y работает за один такт. Я не говорю за одну
[15:46.080 --> 15:51.880]  наносекунду, за один такт работает процессор. На самом деле, конечно, это тоже не так. Понятно,
[15:51.880 --> 16:00.720]  что умножение более сложно операции, чем сложение. Не говоря про деление и взятие по модулю. Чтобы
[16:00.720 --> 16:06.280]  над этим не заморачиваться, чтобы не думать о том, какие конкретные операции у меня внутри алгоритма,
[16:06.280 --> 16:13.920]  и чтобы вот это все считать за одну операцию, я как раз позволяю себе, чтобы мои функции были равны
[16:13.920 --> 16:20.000]  с точностью домножения на константу. И сравнивать их я буду тоже с точностью домножения на константу.
[16:20.000 --> 16:29.200]  Это первый аргумент. Почему константа перед основным множителем не очень важна? Потому что
[16:29.200 --> 16:33.480]  мы ее на самом деле не можем очень хорошо оценивать. Точнее, как бы можем, но тогда это прям отдельная
[16:33.480 --> 16:39.600]  область, где нам нужно аккуратно разбираться во всем коде, что такое взять какой-то элемент массива,
[16:39.600 --> 16:49.280]  за сколько работает сложение, деление и так далее. Это было бы совсем другое описание всех алгоритмов.
[16:49.280 --> 16:54.320]  Нам нужно было бы формализовывать модель, как у нас устроен компьютер. Мы не хотим это делать,
[16:54.320 --> 17:02.680]  по крайней мере, не в этом курсе. Вторая причина, например, в том, что компьютеры все время довольно
[17:02.680 --> 17:08.600]  быстро ускоряются и ускоряются. Постоянно появляются новые процессоры, которые умеют выполнять все
[17:08.600 --> 17:13.560]  больше и больше элементарных операций в секунду. Поэтому даже если у нас есть вот такой алгоритм,
[17:13.560 --> 17:22.600]  то лет через 15 они будут отрабатывать за такое же время, как вот эти алгоритмы. Поэтому с точки
[17:22.600 --> 17:28.360]  зрения вечной теории нам опять-таки не важно, какая там константа, потому что если сейчас это долго,
[17:28.360 --> 17:37.360]  то через 10 лет это будет быстро. Но это более-менее как минимум две причины, по которым действительно
[17:37.360 --> 17:41.560]  эта константа перед национальным ножетелем не важна, и значит я могу себе позволить здесь отличие
[17:41.560 --> 17:49.720]  в любую положительную константу раз. Так, убедил хоть чуть-чуть? Никто не сказал да,
[17:49.720 --> 18:00.600]  ну вроде нормально. Е-е-е, спасибо. Ну вот, все, мы будем с этой штукой работать. Нам нужны ее
[18:00.600 --> 18:10.200]  небольшие свойства. Утверждение f равно о большой от g, если и только если существует
[18:10.200 --> 18:23.200]  положительная константа, давайте назову ее c с крышкой, такая что для любого n, давайте
[18:23.200 --> 18:35.720]  подчеркну натурального, f не больше, чем c с крышкой на g. Отличие очень простое, я выкинул
[18:35.720 --> 18:41.040]  ограничение на n большое. Я сказал, что то, что написано на второй доске, равносильно тому,
[18:41.040 --> 18:49.240]  что просто для любого n это неравенство верно. Да, там написано для всех, начиная с некоторого,
[18:49.240 --> 18:53.480]  например, с тысячи или с двух тысяч. А здесь вообще всегда, я говорю, но возможно с другой
[18:53.480 --> 19:01.640]  константой. Да, именно так. Мы сейчас как раз докажем, что если вот ту константу c чуть-чуть
[19:01.640 --> 19:13.720]  увеличить, то это неравенство будет верно вообще всегда. C с крышечкой. Просто число. Вот это как
[19:13.720 --> 19:18.840]  обозначать c1, c2, то то же самое c с крышкой, это какое число просто? Могу написать здесь d.
[19:18.840 --> 19:38.360]  Есть, сейчас докажем. Вопрос. Ну, потому что кто-то их еще не знает. Я с какого-то момента
[19:38.360 --> 19:50.120]  начну. Хорошо, значит с какого-то момента в виду, не бойтесь. Доказательства слева направо давайте.
[19:50.120 --> 20:01.040]  Скажите, пожалуйста, какое c с крышкой надо взять, чтобы это было верно. Давайте запишу,
[20:01.040 --> 20:06.000]  пусть. Ну, хорошо, если вы просто в квантрах, давайте напишем. Для всех, начиная с какого-то,
[20:06.000 --> 20:17.640]  на f не больше, чем c на g от n. Так, это убило кого-то? Значит, все уже умеете, да? Не, пусть я не буду,
[20:17.640 --> 20:28.080]  извините, это точно не commonplace так писать. Так, что дальше? Да.
[20:28.080 --> 20:47.960]  Да, все правильно. Давайте я только не буду умничать про верхнюю грань, потому что нам
[20:47.960 --> 20:53.520]  это даже не нужно. Мне достаточно это сделать только на первых n больших натуральных числах. Все,
[20:53.520 --> 20:57.720]  что происходит для n больше, мне не интересно. Так вот, давайте я положу c с крышкой таким,
[20:57.720 --> 21:07.360]  максимум из c вот этого самого и всех дробей вида f поделить на g для маленьких натуральных
[21:07.360 --> 21:16.720]  аргументов, вплоть до n большого. Вот. Значит, в качестве c с крышкой возьму максимальное из
[21:16.720 --> 21:22.840]  вот этих вот чисел. Тогда я утверждаю, что для этого конкретного c с крышкой будет верно это
[21:22.840 --> 21:31.840]  неравенство. Ну почему? Давайте докажем, давайте докажем, что это реально верно всегда. Докажем,
[21:31.840 --> 21:38.960]  что для любого натурального n f не больше, чем c с крышкой на g.
[21:52.840 --> 22:06.080]  Давайте рассмотрим два случая. Случай первый. Пусть n не больше, чем n большое. Ну тогда мы знаем,
[22:06.080 --> 22:13.920]  что c с крышкой точно больше или равно, чем f от n маленькой, делить на g от n маленькой. Просто по
[22:13.920 --> 22:18.520]  определению c с крышкой мы c с крышкой специально взяли таким, чтобы c с крышкой было больше всех
[22:18.520 --> 22:24.080]  таких дробей для маленьких n маленьких. А если n маленькой не больше, чем n большое, то c с крышкой
[22:24.080 --> 22:29.440]  точно больше равно такой дроби. Ну а значит, просто если я домножу обе части на g, то немедленно
[22:29.440 --> 22:36.000]  получу, что f от n не больше, чем c с крышкой на g от n. Победа. В этом случае все доказали.
[22:36.000 --> 22:43.680]  Сейчас второй случай просто. Проблемы нет просто, их надо аккуратно все разобрать.
[22:43.680 --> 22:51.440]  В случае n больше, чем n большое я вот это неравенство не могу сходу написать. Ну по крайней
[22:51.440 --> 22:58.440]  мере не знаю. Здесь то немедленно следует из определения. Вот смотрите, c с крышкой это максимум
[22:58.440 --> 23:03.400]  из c всех таких дробей. В частности там где-то есть, вот давайте здесь напишу, там f от n маленькая,
[23:03.400 --> 23:10.800]  делить на g от n маленькая. Да, конечно. А в этом случае мы знаем, что c с крышкой больше равно, чем c.
[23:10.800 --> 23:18.240]  Потому что опять-таки c с крышкой определится как максимум чего-то там, в чем в частности участвует
[23:18.240 --> 23:29.200]  c. И еще мы знаем, что для таких n f не больше, чем c на g от n. Ну значит подавно не больше,
[23:29.200 --> 23:48.400]  чем c с крышкой на g от n. Кажется доказали. Опросы? Вот это почему? А вот же, вот же,
[23:48.400 --> 23:53.280]  прямо написано. Для всех n больше, чем n большое, верно, вот это неравенство. Я его просто там
[23:53.280 --> 23:59.920]  использую. Просто для всех n, начиная с n большого. Это следует, это просто определение того, что f это у
[23:59.920 --> 24:17.360]  большого g. Да? Можем, конечно, да. Например, n это o мало, это n квадрат. Да, ничему не противоречит.
[24:17.360 --> 24:32.120]  Нет, в смысле, ну можем. А в чем вопрос? Еще раз? Нет, это нормально, это как раз хорошо. Мы хотим,
[24:32.120 --> 24:40.480]  чтобы o отражало, что одна функция не хуже, чем другая. Ну понятно, что n не хуже, чем квадрат.
[24:40.480 --> 24:44.400]  Если у вас есть два алгоритма, один работает за n, другой за n квадрат, то понятно, вы предпочитаете
[24:44.400 --> 24:49.600]  вот этот, потому что это меньше, чем это. Это ровно смысл o большого. Вот этот алгоритм лучше, чем этот.
[24:49.600 --> 25:03.680]  Это ровно смысл ложки. Это доказательство, конечно, вот началось доказательство. Я доказываю слева
[25:03.680 --> 25:14.000]  направо. Я расписал, что такое f это o а g. Вот оно, вот это вот, это вот это просто. Нет, почему же? Что
[25:14.000 --> 25:18.520]  такое доказательство слева направо? Значит, если это верно, то верно вот это. Вот я это, значит,
[25:18.520 --> 25:34.320]  переписываю просто. Вот это верно. Конечно. Можно. Вы торопитесь опять. Давайте я сначала начну,
[25:34.320 --> 25:43.520]  я сначала докажу, а потом вы спросите, в чем смысл. Давайте его докажем сначала. Где? Нет,
[25:43.520 --> 25:56.760]  без крышки. Вот я просто переписал вот это определение туда. Не понял вопрос. Из
[25:56.760 --> 26:01.920]  определения o большого. Вот я еще раз. Что я хочу доказать? Я хочу доказать, что если вот это,
[26:01.920 --> 26:06.960]  то вот это. Но что такое вот это? Вот у меня здесь написано. Что такое f равно o
[26:06.960 --> 26:15.680]  большого g? Я просто переписал и все. Так, я продолжаю. Давайте еще раз сосредоточимся. Идем справа
[26:15.680 --> 26:24.000]  налево. Скажите, пожалуйста, что нужно здесь сделать. Доказательство справа налево. Да, все верно.
[26:24.000 --> 26:34.440]  Значит, просто положим n большой равно единице. Но если мы знаем, что f всегда не больше, чем c с крышкой
[26:34.440 --> 26:42.360]  на g, то значит, в частности, для всех, начиная с единицы, это верно. Доказали то, что хотели.
[26:42.360 --> 26:48.720]  Потому что что? У меня известно вот это всегда, а я хочу доказать, что это выполняется для всех,
[26:48.720 --> 26:51.880]  начиная с некоторого. Вот пусть то самое некоторое, это будет единица.
[26:51.880 --> 27:06.000]  Ну потому что мне что нужно? Мне нужно, чтобы вот это вот выполнялось. А, ну еще надо сказать,
[27:06.000 --> 27:15.240]  что, видимо, c это c с крышкой. Вот. Ну все. А мне что нужно? Мне нужно, чтобы для всех,
[27:15.240 --> 27:26.200]  начиная с n большого, выполнялось f не больше, чем c на g. Но если n большой это единица,
[27:26.200 --> 27:32.800]  это верно всегда, то это тоже получается верно. Потому что c с крышкой равно c. Профит.
[27:32.800 --> 27:52.720]  Вопросы? Давайте. Давайте еще раз. Смотрите, мне известно вот это. Вот это верно всегда. Я
[27:52.720 --> 27:57.680]  доказываю справа налево, то есть, смотрите внимательно, вот это верно всегда. Что мне
[27:57.680 --> 28:02.560]  нужно? Мне нужно вот это вот записать, что для всех n существует какое-то n большое,
[28:02.560 --> 28:07.280]  что для всех n маленьких большое n большое, верно вот это, еще для кого-то c. Ну давайте я
[28:07.280 --> 28:20.840]  определю вот такое c, вот такое n большое, и тогда это будет тривиально верно. Да. Я их просто подобрал,
[28:20.840 --> 28:28.360]  и вот это будет верно по определению. Ничем можно взять тысячу, можно взять какое угодно,
[28:28.360 --> 28:37.160]  но оно тоже существует, все равно. Но этого достаточно. Можно так. Так, едем дальше.
[28:37.160 --> 28:46.640]  Значит опять, давайте я скажу, зачем мы это сделали. Почему мы определили тому большое,
[28:46.640 --> 28:50.600]  для всех n, начиная с некоторого, и доказали эквивалентность тому, что просто для всех n?
[28:50.600 --> 28:55.960]  Ну потому что иногда алгоритм удобно анализировать для всех n, начиная с некоторого. То есть,
[28:55.960 --> 29:00.880]  представьте, у вас алгоритм делает что-нибудь для больших n, а маленький n он как-нибудь
[29:00.880 --> 29:05.120]  отдельно перебирает. Там, например, он отдельно говорит, что если n равно единица, делай то-то,
[29:05.120 --> 29:10.280]  если n равно двойки, делай то-то, а там бла-бла-бла, а вот с десятки начинает уже какой-то там большой
[29:10.280 --> 29:14.680]  алгоритм. Тогда можно вообще не анализировать то, что происходит на маленьких n, там один,
[29:14.680 --> 29:19.000]  два и так далее, там десять, можно не анализировать. Ну потому что мы доказали
[29:19.000 --> 29:24.560]  эквивалентность, что анализ какого-то n, это в общем-то эквивалентно с точностью до вот этой
[29:24.560 --> 29:30.160]  константы, эквивалентно тому, что просто всегда одна функция лучше, чем другая. Поэтому мы себе
[29:30.160 --> 29:37.080]  позволили анализировать алгоритм не всегда, а только для достаточно больших n. Но если вдруг надо будет,
[29:37.080 --> 29:44.480]  то можно будет делать так. Так, едем дальше. Значит опять, сейчас будет просто не равнится
[29:44.480 --> 30:00.040]  в другую сторону. Пусть у меня есть две функции из n в n, пишем, что f это омега от g, если, ну давайте
[30:00.040 --> 30:07.160]  теперь в кванторах напишу. Существует положительное c, существует n большое, такое,
[30:07.160 --> 30:22.760]  что для любого n, начиная с n большого, f это хотя бы c на g. Это символ омега большое. Это не то,
[30:22.760 --> 30:28.040]  что это в худшем случае, это основная ка снизу, если раньше было сверху, то это снизу. Да,
[30:28.040 --> 30:44.200]  да. Простое замечание, f равно омега от g, если и только если g равно от f. Вот это? Это все
[30:44.200 --> 30:49.080]  натуральные числа, 1, 2 и так далее. Ну, у меня сегодня ноль ненатуральная. Если кто-то уже привык,
[30:49.080 --> 30:58.000]  что ноль натуральная, у меня сегодня ноль ненатуральная. Это неважно. Смотрите, f не лучше,
[30:58.000 --> 31:04.360]  чем g. То есть время работы f-ки больше равно, чем g на константу. То есть тут, наоборот,
[31:04.360 --> 31:09.260]  если у меня раньше было f лучше, чем g, то теперь оценка в другую сторону f хуже. Время работы f
[31:09.260 --> 31:14.600]  больше, чем g на константу. Ну, просто оценка в другую сторону. Если раньше у меня было меньше,
[31:14.760 --> 31:25.440]  теперь больше. Так, вот это верно почему? Да, да, можно просто обратить вот эту константу. Ну,
[31:25.440 --> 31:35.800]  давайте я коротко это объясню. Если f это омега от g, значит f больше равно c на g, а значит,
[31:35.800 --> 31:45.780]  ну, тут можно на самом деле эквалентность написать. g не больше, чем 1ц на f. Ну, а это в
[31:45.780 --> 31:51.320]  точности вот это. Ну, просто я вместо c взял 1ц, и все. А мне же не важно, какое именно c. Просто вот
[31:51.320 --> 31:55.960]  оно какое-то существует. Поскольку c больше нуля, я имею право так сделать. Это будет положительное
[31:55.960 --> 31:59.240]  число опять-таки. Ну, и вот получили, что эти две штуки эквалентны.
[31:59.240 --> 32:18.320]  Так, ну и опять-таки утверждение симметричное предыдущему, что одна функция это омега,
[32:18.320 --> 32:23.480]  другой. Если это неравенство, можно написать просто всегда. Не для всех,
[32:23.480 --> 32:44.760]  начиная с некоторого, а просто всегда. Ну, просто вот это вот с точностью до знака неравенства. Да,
[32:44.760 --> 32:48.360]  ну доказывать не буду, доказывать точно так же. Давайте напишу доказательство аналогично.
[32:48.360 --> 32:59.920]  Да, ну я опять-таки просто отбросил вот этот вот ограничитель. Если раньше было для всех,
[32:59.920 --> 33:19.960]  а начиная с некоторого, то теперь просто для всех. Вот это вот я отбросил. Так, ну и последнее
[33:19.960 --> 33:37.480]  определение. Значит, вновь пусть есть две функции из n в n. Пишем, что, так, ну да, да,
[33:37.480 --> 33:49.680]  все правильно. Пишем, что f это θ, вот g, она греческая большая буква θ. Если существует,
[33:49.680 --> 34:00.360]  давайте так напишу, c1, c2 больше нуля, существует n большое, такое, что для любого n больше,
[34:01.000 --> 34:29.640]  верно, следующая цепочка неравенств. Вот, то есть g у меня оказалась заперта, и снизу она больше
[34:29.640 --> 34:35.840]  чем f на константу, и сверху меньше чем f на константу. Да, вот это именно то самое одного
[34:35.840 --> 34:41.840]  порядка. Это ограничение снизу, это ограничение сверху. Если, ну на самом деле, да, наоборот,
[34:41.840 --> 34:47.040]  это неважно, это симметричное определение. Давайте я для красоты здесь поменяю, это неважно,
[34:47.040 --> 34:55.640]  конечно. Да, то есть вот эта функция заперта с обеих сторон другой на константу. Ну они,
[34:55.640 --> 35:01.480]  конечно, разные, скажем, здесь может быть c1 равно 1 сотая, а здесь c2 это 100 просто. Но,
[35:01.480 --> 35:07.080]  тем не менее, это нормально. Если g больше чем f поделить на 100 и меньше чем f умножить на 100,
[35:07.080 --> 35:20.200]  то это хорошо. Мы считаем, что не одного порядка. Ну не о, только θ. Да, n уже не равно θ от n
[35:20.200 --> 35:33.320]  квадрат. Равно только o. А я вот это проговорил, что мы можем не анализировать поведение алгоритма
[35:33.320 --> 35:38.480]  на маленьких входах. Потому что алгоритм может работать так. Если n маленькое, делай что-нибудь,
[35:38.480 --> 35:42.560]  там, не знаю, перебирай, например, все варианты ответа и выведи из них то, что на самом деле ответ.
[35:42.560 --> 35:47.000]  А вот для всех n, начиная с какого-то, он действует там определенным образом. Вот это маленькое начало,
[35:47.000 --> 36:05.440]  когда n маленькое, n меньше чем. Там был вопрос еще. Диапазон чего? Граждане,
[36:05.440 --> 36:14.520]  можно не мешать, пожалуйста, мешайте, я даже не слышу вопрос человека. Не-не, все нормально,
[36:14.520 --> 36:34.920]  сейчас давайте, например, еще это пощупаем. Давайте тоже это запишем, что f равно θ от g
[36:34.920 --> 36:50.040]  равносильно тому, что одновременно верно f это от g и f это омега от g. Мы считаем, что они одинаковые.
[36:50.040 --> 36:57.320]  Вот, значит, это почему, ну, смотрите, я говорю, что f это θ от g, если верно и то, и то, и ошка,
[36:57.320 --> 37:01.720]  и омега. Но потому что одна из них, это вот это вот неравенство, другой это вот это. Их
[37:01.720 --> 37:07.000]  объединение, ну, точнее, их как бы пересечение, их совокупность и есть оценка с точки зрения тетты.
[37:07.000 --> 37:22.560]  Так, ну, смотрите, я не буду повторять определение, которое я записывал уже на доске. Вот это вот f равно
[37:22.560 --> 37:28.480]  от g, значит, что f меньше равно чем c на g. Омега, значит, f больше равно чем c на g,
[37:28.480 --> 37:33.920]  ну, для какой-то возможно другой c. И это здесь ровно и написано, что с одной стороны f не больше
[37:33.920 --> 37:38.760]  чем g на константу, с другой стороны f больше чем g на константу. Возможно, для разных константов.
[37:38.760 --> 37:43.120]  И если верно и то, и то, совокупность, значит, выполняется и то, и то. Ну, это в точности то,
[37:43.120 --> 37:49.880]  что здесь написано в определении тетты. Они считаются одинаковыми. Если они равны с точки
[37:49.880 --> 37:53.040]  зрения тетты, то мы считаем, что это одинаковая поэффективность алгоритмы. Да.
[37:53.040 --> 38:11.400]  Тетта. Вот это то же самое тетта. Кружочек и буква n такая маленькая внутри. Если вы техаете,
[38:11.400 --> 38:26.680]  то это backslash тетта. Примеры. Давайте считать, что a и b это константы какие-то. Рассмотрим
[38:26.680 --> 38:40.560]  две функции, n в степени a и n в степени b. Как это называется, степенные функции или наоборот?
[38:40.560 --> 38:49.080]  Я не шарю. Ну, короче, вот такие функции посмотрим. Скажите, пожалуйста, когда верна вот такая вот
[38:49.080 --> 39:00.080]  запись? Верна вот такая вот запись. Да, когда a меньше или равно b. Ну, там я считаю, давайте на всякий
[39:00.080 --> 39:03.240]  случай скажу, что они положительные. Потому что если отрицательные, то, конечно, наоборот. У нас
[39:03.240 --> 39:10.080]  такого не будет. Понятно, что если вот эта вот степень меньше, чем вот эта, меньше либо равна,
[39:10.080 --> 39:16.520]  то просто эта функция меньше, чем вот эта функция. Значит, этот алгоритм эффективнее вот этого. Ну,
[39:16.520 --> 39:23.000]  вот как раз ровно o большое и это и отражает, что одна функция растет не быстрее, чем другая. Вот если
[39:23.000 --> 39:31.000]  a меньше, чем b, например, n в степени полтора, это o большое от n в степени 1 и 7. То есть, если
[39:31.000 --> 39:35.840]  вдруг у меня есть два алгоритма, один работающий за такую симптотику, другой за такую, то я предпочитаю
[39:35.840 --> 39:52.720]  вот этот. Ну, просто потому что он меньше. Да. Сильно легче стало вам? Ну, на самом деле замечание
[39:52.720 --> 39:59.320]  справедливое, но мы зачастую не будем вот это вот делать. То есть, да, на самом деле мне нужно
[39:59.320 --> 40:04.480]  было бы всегда вот говорить, что у меня там значения целые, всегда. Ну, потому что это на самом
[40:04.480 --> 40:07.680]  деле количество тактов работы. Наверное, количество тактов работы процессора не может быть там
[40:07.680 --> 40:13.920]  дробным каким-то. Вот. Но на самом деле мы это будем зачастую опускать. И вот там округление вниз и вверх
[40:13.920 --> 40:18.760]  всегда с точки зрения симпатического анализа будет несущественное, и я буду всегда себе позволять
[40:18.760 --> 40:27.560]  этого не делать. То есть, округление вниз. Да. Так, едем дальше.
[40:27.560 --> 40:54.720]  Да. У отф это не функция, это семейство функций на самом деле.
[40:54.720 --> 41:04.120]  Можно было бы писать, но так никто не делает. Ну, как бы, с точки зрения теории, возможно,
[41:04.120 --> 41:14.720]  формально было бы это правильно делать, но так никто не делает. Так, пример. Второй. Опять-таки,
[41:14.720 --> 41:21.000]  пусть есть какие-то константы. Давайте вот это считать, что больше одного. Давайте рассмотрим
[41:21.000 --> 41:29.640]  две вот такие вот функции. Логарифмы по разным основаниям. Например, логарифмы по основанию 2,
[41:29.640 --> 41:39.640]  логарифмы по основанию 100. Да, ну, конечно, то есть, формально это f от n, это g от n. Это значит,
[41:39.640 --> 41:44.920]  какой значок я должен написать? TET. Все правильно. Причем независимо от того,
[41:44.920 --> 41:50.440]  какие здесь именно константы стоят. Почему? Ну, потому что переход к другому основанию
[41:50.440 --> 41:55.120]  логарифма это умножение на константу. Я сейчас напишу формулу, вы меня, возможно,
[41:55.120 --> 42:05.600]  подправите, потому что я в этом не уверен. Вроде бы верно следующее. Супер, значит,
[42:05.600 --> 42:15.320]  я закончил старшую школу. Смотрите, вот функция f, вот функция g. Они отличаются ровно в константу
[42:15.320 --> 42:21.120]  раз. Вот он лог a по основанию b. Это константа. Раз а и b какие-то конкретные числа, то это
[42:21.120 --> 42:26.400]  конкретное число. Если две функции отличаются просто умножением на константу, ну, понятно дело,
[42:26.400 --> 42:32.640]  они одного порядка. Можно просто вот эту константу взять в качестве вот этих вот как раз зажимающих
[42:32.640 --> 42:47.880]  c1, c2. Согласны? Чудно. Дальше. Давайте считать, что а и b константы. А больше одного, b больше нуля.
[42:47.880 --> 43:01.800]  Нет, просто вот функция f вот так вот определена. Вот функция g вот так определена.
[43:01.800 --> 43:16.360]  Ещё раз? Можем, можем. Ну, я просто одно из них написал. На самом деле, конечно же, то есть смотрите,
[43:16.360 --> 43:26.360]  я написал, что f это ttg. Но на самом деле, верные и обратные всегда. Это тоже очень легко доказать.
[43:26.360 --> 43:31.440]  То есть я здесь написал, что f это ttg. Конечно, верные и обратные, что g это ttf. Потому что, ну,
[43:31.440 --> 43:35.960]  просто если вот в этих неравенствах там вот это поделить на c1, это поделить на c2, то у меня
[43:35.960 --> 43:42.120]  получится, что, наоборот, f с обеих сторон заключена между там ж. Вот давайте, давайте,
[43:42.280 --> 43:51.120]  давайте я поделю. Вот здесь на c1 получится, что f не больше, чем 1 c1, g вот n. Здесь будет
[43:51.120 --> 43:58.680]  больше и равно, вот если я это поделю на c2, получится 1 c2 на g вот n. Вот. Мы получили ровно того
[43:58.680 --> 44:03.880]  же вида утверждения, что функция 1 заключена между другой, умноженной на разные какие-то константы.
[44:03.880 --> 44:14.200]  Ну как же, вот. По факту при всех, по крайней мере, при всех начинается некоторого. Вот. Значит,
[44:14.200 --> 44:17.320]  это на самом деле всегда, просто если есть одно, то есть другое, а не одного порядка роста.
[44:17.320 --> 44:28.240]  Так, еду дальше. Значит, смотрите, теперь следующие две функции. Логарифом. А, ну так вот,
[44:28.240 --> 44:33.960]  вот я это не договорил. Из этого следует, на самом деле, что я могу впредь не уточнять основание
[44:33.960 --> 44:39.200]  логарифма. Потому что, если я меняю одно основание логарифма на другое, то у меня время работы
[44:39.200 --> 44:44.280]  отличается всего лишь в константу раз, а с точки зрения вот этих всех наших значков, что омега,
[44:44.280 --> 44:50.400]  что о, что тетты, это безразлично. Поэтому я могу основание логарифма никогда не писать. Вот,
[44:50.400 --> 44:55.240]  я впредь это почти никогда делать не буду. Значит, давайте я здесь напишу. Ну, то есть, я там
[44:55.240 --> 45:02.280]  подразумеваю, что логарифм по основанию два, но этого не пишу. Итак, значит, одна функция это
[45:02.280 --> 45:14.320]  логарифм в степени а от n, другая функция это n в степени b. Что можно между ними написать?
[45:14.320 --> 45:34.760]  Да, f это от g. Это верно, а в другую сторону неверно. Ну, да, да, да, да. Нет, это логарифм в степени
[45:34.760 --> 45:37.920]  а основание, вот я проговорю, что основание можно считать, что по основанию два, но я его не пишу
[45:37.920 --> 45:51.560]  никогда. Пример v вроде бы еще. Да, всегда, если есть вот это, то значит есть симметрично
[45:51.560 --> 46:01.200]  противоположное g это омега т. Ну, почему это верно, там, я доказывать не буду, но интуитивно
[46:01.200 --> 46:07.200]  логарифм, в какой бы вы степени не взяли, он растет медленнее, чем n в любой положительной степени.
[46:07.200 --> 46:29.360]  Да, ну это вот, собственно, то же самое, только после логарифмирования, получается. А можете
[46:29.360 --> 46:58.680]  просто это упражнением доказать, если интересно? Да. Так, вопрос? Вот это? Не, не, это оценка
[46:58.680 --> 47:10.080]  сверху, вспоминайте, f не больше, чем c на g. Это снизу, g больше или равно, чем c на f. Тут как раз вот
[47:10.080 --> 47:18.720]  ровно это, а вот это больше, чем вот это. Так, последний пример, давайте такие две функции рассмотрим,
[47:18.720 --> 47:31.520]  но опять для какой-то константы а положительных. А давайте даже вот так вот сделаю, чтобы
[47:31.520 --> 47:47.800]  поинтереснее было. Вот тут очевидно уже, нет? Почему? Что получается? Да, нет. Да, g это у от f.
[47:47.800 --> 48:03.880]  Давайте я не буду брать логарифм, давайте я оставлю функции в своем хорошем виде. Просто я вот это вот
[48:03.880 --> 48:14.160]  запишу в виде 2 на n логарифм n. Ну просто потому что 2 в степени логарифма это как раз n, и оно еще в
[48:14.160 --> 48:20.400]  степени n возведется. Ну и тогда понятно, что вот эта вот штука больше, чем вот это, а значит
[48:20.400 --> 48:24.480]  после потенцирования 2 в этой степени больше, чем 2 в этой степени. Ну по крайней мере для всех
[48:24.480 --> 48:30.200]  начиная с некоторого. Значит я могу написать, что вот эта штука меньше, чем вот это. Ну в терминах
[48:30.200 --> 48:53.040]  асимптотики g это у от f. Ну и соответственно верно обратное f это омега g. Ну хорошо, давайте
[48:53.040 --> 49:01.280]  докажем, что 2 в степени n больше и равно, чем. Так, ну это конечно я, ну давайте попробуем.
[49:01.280 --> 49:18.440]  Верно ли это всегда? Наверное давайте попробуем доказать, что это всегда верно. Давайте
[49:18.440 --> 49:33.080]  про логарифмируем по основанию 2. Будет вот это. Тут вроде уже понятно почему. Тут
[49:33.080 --> 49:40.760]  линейная, а тут там сумма логарифмов каких-то. Вот. Ну как бы я надеюсь, что где-то на мотоне вы
[49:40.760 --> 49:46.280]  вот эти функции хорошенько пощупаете и будете сразу понимать, что одна больше, чем вторая. Там
[49:46.280 --> 49:50.080]  если надо, вот какие-то такие штуки можно логарифмировать. Говори, что линейная больше,
[49:50.080 --> 50:02.040]  чем логарифм. Ну там до всех начиная с некоторого и так далее. Так, ну хорошо. Что по времени? Полчаса
[50:02.040 --> 50:07.840]  есть. Хорошо. Значит все, смотрите, мы теперь получается на самом деле разобрались с тем,
[50:07.840 --> 50:13.040]  как сравнивать по крайней мере два алгоритма. Если у нас есть один алгоритм рабочий за какую-то
[50:13.040 --> 50:19.080]  асимптотику, другой за другую, мы хоть немножко пощупали то, как сравнить функции между собой и
[50:19.080 --> 50:26.280]  какой алгоритм выбирать, если есть несколько. Так, последнее, что скажу вот в этой части,
[50:26.280 --> 50:38.680]  это когда у меня функции от многих аргументов. Функции многих аргументов. Ну здесь на самом деле
[50:38.680 --> 50:44.440]  все очень просто. Значит давайте я сразу на конкретном примере буду писать. Я говорю,
[50:44.440 --> 50:52.400]  что функция f зависит от переменных n и q. Это o. Вот g, которая зависит от переменных n и q. Ну если
[50:52.400 --> 50:59.320]  просто-напросто существует положительная константа, такая что, либо для всех n и q начиная
[50:59.320 --> 51:17.840]  с некоторым, либо как мы знаем просто всегда, f не больше, чем c на g. Нет, мы вводим для функции
[51:17.840 --> 51:22.760]  многих аргументов понятие o. То есть раньше у меня было o только для функции одного аргумента,
[51:22.760 --> 51:28.400]  то теперь для нескольких. Ну на самом деле все то же самое. Просто 1 это o от другой,
[51:28.400 --> 51:37.080]  если 1 не больше, чем c на другую, где c какая-то константа. Ну вот пусть функция f это функция
[51:37.080 --> 51:42.320]  двух аргументов. Ну то есть формально надо было написать, что f и g из n квадрата в n действуют.
[51:42.320 --> 51:51.320]  Логика такая же просто. 1 функция это o от другой, если эта функция не больше, чем c на другую.
[51:51.320 --> 52:16.920]  Да, все правильно. Так, ну теперь наконец давайте какую-нибудь задачу решим. Задача. Представьте
[52:16.920 --> 52:28.600]  себе, что у вас есть массив из n целых чисел. И поступают запросы. Вам нужно по индексам l и r
[52:28.600 --> 52:54.240]  найти сумму чисел с l и r. Это база. Это правда. Да, ну не верю. А если у вас q запросов? Замечательно.
[52:54.240 --> 53:05.520]  Давайте его напишем. Решение 1. Время работы будет n на q. Ну на самом деле нельзя здесь писать
[53:05.520 --> 53:10.800]  t, то давайте только o напишем. Потому что, ну мало ли, а все-таки может эти границы всегда маленькие,
[53:10.800 --> 53:17.160]  это будет именно на самом деле o, а не t. Я буду сейчас только o писать. Ну очень просто в ответ
[53:17.160 --> 53:23.480]  на каждый запрос я прохожусь по этому отрезку, складываю все числа. На просто цикл там по всем
[53:23.480 --> 53:43.040]  и от l до r сложить вот эти элементы. А какая разница? Поэтому написано решение 1, чтобы 8.сравнить.
[53:43.040 --> 53:48.240]  Это понятное решение? Ну просто в тупую для каждого запроса проходимся по вот этому отрезку,
[53:48.240 --> 53:53.360]  складываем все числа. В худшем случае длина этого отрезка n. Ну там может быть n пополам,
[53:53.360 --> 53:59.080]  может быть там n на 3, но точно не больше, чем n. На каждый запрос я делаю максимум n операций,
[53:59.080 --> 54:07.120]  поэтому время работы это от n на q. Опять вот я здесь как раз я игнорирую то, что у меня, как
[54:07.120 --> 54:11.960]  именно внутри устроены там операции сложения, операция пробегания по памяти, я считаю, что все
[54:11.960 --> 54:18.040]  этой элементарной операции, вот эта сумма находится за вот это. Да, куза просов у меня.
[54:18.040 --> 54:36.760]  Дерево отрезки футовый веркил, конечно. Сейчас будет. Рефиксная сумма называется,
[54:36.760 --> 54:45.520]  очень сложный алгоритм. Работает так. Давайте шум погасим, пожалуйста. Кому не интересно,
[54:45.520 --> 54:51.560]  можете, пожалуйста, выйти, я никого здесь не держу, но мешать не надо, окей? Да, спасибо,
[54:51.560 --> 54:57.200]  хоть так. Значит, рефиксная сумма. Давайте заведем следующий нехитрый массив. Давайте для каждого
[54:57.200 --> 55:11.200]  и посчитаем сумму элементов с первого по итой и сохраним это в памяти. Ну, это сделать вроде не
[55:11.200 --> 55:17.720]  очень сложно. Можно сказать, что преф нулевой это ноль, потому что сумма нуля элементов это ноль,
[55:17.720 --> 55:24.480]  а дальше для каждого следующего можно заметить, что преф и плюс первая, это преф предыдущая,
[55:24.480 --> 55:32.480]  плюс а и плюс первая. Значит, можно просто за линейное время пройтись по этому массиву,
[55:32.480 --> 55:37.920]  насчитать вот эти префы по вот этой формуле и тем самым мы будем знать сумму на всех префиксах.
[55:37.920 --> 55:44.360]  Ну, поэтому я и написал префиксную сумму. Вот у меня есть такой мой массив, а1, а2 и так далее,
[55:44.360 --> 55:54.320]  аn. Я вот на всех таких вот кусочках могу посчитать сумму и более того сохранил ее в массиве. И дальше,
[55:54.320 --> 56:01.760]  чтобы мне ответить на запрос суммы с l-th элемента по r-th, я могу просто вывести преф r-th
[56:01.760 --> 56:17.200]  минус преф l-1. Нельзя, конечно, да. Объяснение очень простое. Вот представьте себе отрезок с
[56:17.200 --> 56:23.600]  l-th элемента по r-th, вам нужно найти сумму элементов здесь, а вы взяли вот это и вычли вот это. Осталось
[56:23.600 --> 56:35.760]  ровно то, что нужно. Да? Ну, супер. А симптотика вот такая. Потому что сначала я трачу линейное
[56:35.760 --> 56:43.000]  время на считывание массива и предподсчет массива префиксных сумм. То есть там две линии, там 2n,
[56:43.000 --> 56:48.200]  но извините, я не пишу 2, потому что у меня O и она все константы сразу съедает. Поэтому считывание
[56:48.200 --> 56:54.560]  массива и насчет префиксных сумм у меня будет n, O от n. А дальше на каждый запрос я отвечаю за одну
[56:54.560 --> 56:59.240]  операцию вычитания и две операции обращения к массиву. Но поскольку я считаю, что обращение
[56:59.240 --> 57:03.920]  к массиву и вычитание это элементарные операции, я говорю, что это просто Q. Поэтому время работы
[57:03.920 --> 57:13.200]  будет n плюс Q. Да. Здесь можно, здесь можно. Вот здесь нельзя было, потому что у меня длинные отрезков
[57:13.200 --> 57:18.780]  могли варьироваться, и n это только оценка сверху. Да, то есть, возможно, вот если здесь длинные
[57:18.780 --> 57:24.480]  отрезков маленькие, то это, возможно, было бы просто от Q. Представьте, что в каждом запросе l и r
[57:24.480 --> 57:30.840]  очень близки. Тогда мы примерно за единицу бы отвечали. Можно, но все равно нельзя сказать,
[57:30.840 --> 57:34.400]  что этот алгоритм работает за t от nQ, потому что на некоторых входах работает быстрее.
[57:34.400 --> 57:45.400]  Но вот я не буду так делать, то есть в общем случае нельзя написать, что алгоритм работает за t. То есть
[57:45.400 --> 57:59.280]  на конкретных входах работает, но не всегда. Да, но вот я хочу различать, что то есть на каких-то,
[57:59.280 --> 58:03.720]  то есть эта штука работает по-разному на разных входах. Она не всегда такая, она иногда Q,
[58:03.720 --> 58:09.960]  иногда nQ. Я не хочу себе здесь ставить t и говорить, что она всегда nQ. В худшем случае nQ действительно,
[58:09.960 --> 58:15.840]  но не всегда nQ. Я вот здесь не пишу. То есть там в разных структурах данных, типа, бывают там вот
[58:15.840 --> 58:20.440]  это вот конкретное подразумение в лучшем случае за столько, в худшем за столько. И ну как бы нельзя
[58:20.440 --> 58:24.440]  это в t обезвинить, потому что это это всегда зажатие между вот, просто по определению, да,
[58:24.440 --> 58:28.960]  если бы я написал здесь t, то у меня получилось бы, что этот алгоритм всегда на любом входе работает
[58:28.960 --> 58:37.040]  хотя бы c на nQ. Это неверно. Ну на каких-то входах да, но не всегда. Я вот именно себе не запрещаю
[58:37.040 --> 58:47.760]  работать быстрее. Окей? Так, вроде все. Теперь вопрос, какой из этих двух алгоритмов надо выбрать?
[58:47.760 --> 58:56.600]  Ну, наверное второй, да, потому что, наверное, сумма меньше, чем произведение. Хорошо.
[58:56.600 --> 59:18.880]  Ну, еще сложная задача очень. Представьте себе, что у вас есть отсортированный массив.
[59:18.880 --> 59:29.560]  Числа в нем идут в порядке возрастания. Ну давайте я задам себе такой вопрос. Значит,
[59:29.560 --> 59:49.840]  запрос, есть ли в этом массиве число x. Ну и опять таких пусть будет ку штук.
[59:49.840 --> 01:00:02.720]  Опять первое решение работает наивным образом. Давайте просто при поступлении запроса о поиске
[01:00:02.720 --> 01:00:07.920]  числа x пройдем полностью по этому массиву и проверим каждое число на равенство x. Если хотя
[01:00:07.920 --> 01:00:13.080]  бы один раз нашли x, то значит оно там есть. Если не разумеется, то нет. Давайте я напишу просто
[01:00:13.080 --> 01:00:24.280]  наивный, ну наивный поиск пусть будет, наивный поиск. Значит, это работает опять-таки, в худшем
[01:00:24.280 --> 01:00:31.680]  случае за n-ку, но иногда быстрее, потому что на каких-то конкретных входах, скажем, если x всегда
[01:00:31.680 --> 01:00:37.200]  какой-нибудь супермаленькая, то мне там нет смысла идти дальше, чем a1. Ну или, например, если x это
[01:00:37.200 --> 01:00:42.880]  всегда a1, то я всегда сразу его вижу и возвращаю, что оно там есть. Но в худшем случае мне придется
[01:00:42.880 --> 01:00:52.720]  на каждом из кузапросов пройти весь массив за линейное время, за n. Понятно? Ничего хитрого.
[01:00:52.720 --> 01:01:08.320]  Решение второе называется бинарный поиск. Давайте немножко поменяю задачу. Давайте я буду вместо
[01:01:08.560 --> 01:01:22.120]  проверки существования там x искать, ну скажем, наименьшее число больше либо равно x. Будем искать
[01:01:22.120 --> 01:01:36.560]  наименьшее число, которое есть в нашем массиве, больше либо равно x. Ну и если это самое наименьшее
[01:01:36.560 --> 01:01:42.240]  число больше или равно x равно x, то значит x там есть, иначе его нет. Если я найду такое число,
[01:01:42.240 --> 01:01:48.680]  наименьшее больше или равно x, если оно равно x, значит победа, если оно не равно, значит поражение,
[01:01:48.680 --> 01:01:54.060]  потому что если даже наименьшее больше или равно x больше, чем x, значит x нет. Поэтому это число
[01:01:54.060 --> 01:02:03.200]  найти достаточно. Знаю его, я знаю, есть ли x в нашем массиве. Как это делать? Сейчас, одну секунду.
[01:02:07.320 --> 01:02:18.200]  Давайте я сделаю вот так, правильно? Сейчас, полминутки. Ну да.
[01:02:18.200 --> 01:02:39.520]  Давайте я веду себе следующее предположение, l равно n. Давайте сразу выполню проверку,
[01:02:39.520 --> 01:02:48.920]  что если у меня, а давайте просто n плюс 1 вот так. И я неявно сейчас себе в голове пририсую сюда
[01:02:48.920 --> 01:02:53.920]  число плюс бесконечность. То есть я могу вот сюда вот приписать, что a n плюс первое равно плюс
[01:02:53.920 --> 01:02:59.800]  бесконечность. И соответственно, если что, то есть если вот это вычислом меньше, чем x, то если что,
[01:02:59.800 --> 01:03:05.200]  вот это можно считать ответом. Наименьшее больше на x будет вот это. То есть я могу дополнить каким-то
[01:03:05.200 --> 01:03:11.640]  большим числом. Дальше, ввожу такие границы и сам с собой договариваюсь, что то, что я ищу,
[01:03:11.640 --> 01:03:19.280]  лежит в полуинтервале от l до r. Причем r включительно, l не включительно.
[01:03:19.280 --> 01:03:31.760]  Почему? Все нормально, все нормально. Как раз нулевого у меня нету, а r, если что, n плюс 1.
[01:03:31.760 --> 01:03:38.760]  То есть сейчас ответ точно не потерял. Нет, ну как, надо включать, потому что если все эти числа
[01:03:38.760 --> 01:03:49.600]  меньше, чем x, а это больше, то надо r вернуть. Все нормально. Вот. Значит еще раз, почему в самом
[01:03:49.600 --> 01:03:56.360]  начале такое верно? Почему я могу считать, что то самое число, которое я ищу, лежит в полуинтервале
[01:03:56.360 --> 01:04:04.840]  от l до r включительно. Но потому что r это вот это, и если что, это число точно больше, чем x. Ну а l вот
[01:04:04.840 --> 01:04:08.360]  здесь, вот этот вообще не существующий элемент, то есть по факту я ищу ответ во всем массиве, но он
[01:04:08.360 --> 01:04:17.200]  где-то есть, понятное дело. А пока я себе ответ точно не потерял. Дальше делаю следующее. Пока у меня
[01:04:17.200 --> 01:04:25.080]  длина полуинтервала какая-то содержательная, если полуинтервал большой, я делаю следующее. Смотрите,
[01:04:25.080 --> 01:04:31.880]  вот есть у меня мой большой интервал от l до r. Давайте возьмем его середину, ну там примерно
[01:04:31.880 --> 01:04:38.320]  центральный левой элемент. Мы посчитаем его по формуле l плюс r пополам с округлением вниз и
[01:04:38.320 --> 01:04:55.720]  сравним ам с х. Сравним ам с х. Два случая. Если ам больше или равно х, тогда что можно смело
[01:04:55.720 --> 01:05:15.440]  сделать? Какую? Неправильно, правую. Можно перейти к полуинтервалу от l до m включительно,
[01:05:15.440 --> 01:05:24.400]  потому что еще раз, что я делаю, я ищу самое маленькое число, которое больше равно, чем x. Но при
[01:05:24.480 --> 01:05:30.320]  этом я знаю, что вот здесь вот стоит число больше или равно, чем x. Поэтому самое маленькое точно
[01:05:30.320 --> 01:05:36.000]  где-то вот здесь. Оно неправее, чем m. Потому что вот больше либо равно, а я ищу самое левое
[01:05:36.000 --> 01:05:40.820]  больше либо равно. То есть оно где-то вот здесь. Ну поэтому я имею право перейти к такому полуинтервалу.
[01:05:40.820 --> 01:05:48.760]  Согласны? Вот это больше либо равно, чем х, а я ищу самое левое больше либо равно х, потому что у меня
[01:05:48.760 --> 01:05:53.280]  всё идет порядка возрастания. Наименьшее больше либо равно х, то же самое, что самое левое больше
[01:05:53.280 --> 01:06:01.280]  Если так получится, что нам нужно будет найти первый элемент, вы же L не включили.
[01:06:01.280 --> 01:06:06.280]  А смотрите, у меня L какое? А индексация 1.
[01:06:06.280 --> 01:06:11.280]  Как раз у меня здесь в этом массиве, то есть в самом начале, я ничего не выкинул.
[01:06:11.280 --> 01:06:19.280]  У меня границы корректные, у меня ответ точно здесь в самом начале.
[01:06:19.280 --> 01:06:24.280]  Еще раз, почему больше, а не больше?
[01:06:24.280 --> 01:06:31.280]  А ничего страшного, это вы предлагаете оптимизацию, а я говорю, что и так работает.
[01:06:31.280 --> 01:06:34.280]  Мне лень думать, я утверждаю, что и так работает.
[01:06:34.280 --> 01:06:36.280]  И соответственно, второй случай симметричный.
[01:06:36.280 --> 01:06:42.280]  Если ам меньше, чем х, то я имею право, наоборот, перейти к правой половине отрезка.
[01:06:42.280 --> 01:06:51.280]  Можно перейти к полуинтервалу от m до r.
[01:06:51.280 --> 01:06:57.280]  И опять-таки этот переход будет корректный, потому что, смотрите, если вот это число меньше, чем х,
[01:06:57.280 --> 01:07:02.280]  вот это число меньше, чем х, то понятно, что все, что слева, тоже меньше, чем х.
[01:07:02.280 --> 01:07:08.280]  Потому что у меня идет все в порядке возрастания, если это меньше, чем х, то все левее тоже меньше, чем х.
[01:07:08.280 --> 01:07:14.280]  Значит, ответ, если где-то и лежит, то точно вот здесь вот, причем не включая m.
[01:07:14.280 --> 01:07:17.280]  Это число меньше, чем х, значит, ответ точно правее.
[01:07:17.280 --> 01:07:19.280]  Поэтому левую границу здесь можно выкинуть.
[01:07:19.280 --> 01:07:23.280]  Но правой остается, я знаю, что ответ где-то здесь.
[01:07:23.280 --> 01:07:25.280]  Справедливо?
[01:07:25.280 --> 01:07:29.280]  Ну, вроде верно.
[01:07:29.280 --> 01:07:37.280]  Я утверждаю, что в самом конце у меня получится полуинтервал, содержащий ровно одну точку, являющуюся ответом.
[01:07:38.280 --> 01:07:42.280]  Пока r-l большое, я это делаю.
[01:07:42.280 --> 01:07:45.280]  То есть, по факту, просто разбивая отрезок на две половинки,
[01:07:45.280 --> 01:07:52.280]  перехожу в какую-то из них, либо влево, либо вправо, в зависимости от знака неравенства.
[01:07:52.280 --> 01:08:05.280]  В самом конце, после того, как это закончилось, после этого цикла, имеем r-l равно единице.
[01:08:05.280 --> 01:08:12.280]  То есть, мы имеем на самом деле полуинтервал, вида l, l плюс 1, где левая не включена, а правая включена.
[01:08:12.280 --> 01:08:15.280]  Ну, это, собственно, то же самое, что r.
[01:08:15.280 --> 01:08:25.280]  Значит, а r – это то самое искомое число.
[01:08:25.280 --> 01:08:31.280]  Ну, а если его нет, то r равно n плюс 1.
[01:08:31.280 --> 01:08:37.280]  Ну, в любом случае, мы получили индекс наименьшего числа, больше равного, чем x.
[01:08:37.280 --> 01:08:41.280]  Возможно, r будет равно n плюс 1, но тогда это значит, что все числа здесь были меньше, чем x.
[01:08:41.280 --> 01:08:44.280]  И первое большее равное – это вот это.
[01:08:44.280 --> 01:08:48.280]  Ну, тоже как-нибудь несложно это обработать.
[01:08:48.280 --> 01:08:54.280]  В конце проверяем.
[01:08:54.280 --> 01:08:56.280]  Ну, давайте напишем.
[01:08:56.280 --> 01:09:14.280]  Давайте если r меньше равного, чем n, а r равно x, то тогда x присутствует в массиве.
[01:09:14.280 --> 01:09:23.280]  Иначе не присутствует.
[01:09:23.280 --> 01:09:26.280]  Победа.
[01:09:26.280 --> 01:09:29.280]  Вопросы есть по алгоритму?
[01:09:29.280 --> 01:09:31.280]  Хорошо.
[01:09:31.280 --> 01:09:37.280]  Значит, если кто-то из вас внезапно привык писать бинарный поиск на отрезках,
[01:09:37.280 --> 01:09:41.280]  то чем лучше то, что я рассказал, чем лучший поиск на полуинтервалах,
[01:09:41.280 --> 01:09:43.280]  тем, что вам в конце не нужно два значения проверять.
[01:09:43.280 --> 01:09:48.280]  Вот у меня сразу в конце полуинтервал содержит только одну точку, являющуюся ответом.
[01:09:48.280 --> 01:09:53.280]  Вам не нужно проверять и aL, и aR на равенство x.
[01:09:53.280 --> 01:09:59.280]  У вас всегда ответ, если есть, то это только aR.
[01:09:59.280 --> 01:10:05.280]  Вам достаточно только одну точку проверить.
[01:10:05.280 --> 01:10:07.280]  Он работает?
[01:10:07.280 --> 01:10:09.280]  Он же за алгоритмом работает, да?
[01:10:09.280 --> 01:10:14.280]  Да. Сейчас мы как раз проанализируем симптотику.
[01:10:14.280 --> 01:10:19.280]  Я утверждаю, что эта штука работает за следующее время.
[01:10:19.280 --> 01:10:28.280]  O от n плюс кулог n.
[01:10:28.280 --> 01:10:30.280]  Почему?
[01:10:30.280 --> 01:10:32.280]  Значит, n понятно откуда взялось.
[01:10:32.280 --> 01:10:35.280]  Это время, необходимое на считывание массива.
[01:10:35.280 --> 01:10:39.280]  То есть я сначала считываю все мои n чисел в память, располагаю в массиве.
[01:10:39.280 --> 01:10:42.280]  Это вот первая n операция.
[01:10:42.280 --> 01:10:50.280]  А дальше я говорю, что каждый запрос обрабатывается примерно за алгоритмическое время.
[01:10:50.280 --> 01:10:56.280]  Опять, я не пишу основание алгоритма, потому что какое бы я основание здесь не написал,
[01:10:56.280 --> 01:10:58.280]  то с точки зрения O большого это будет одно и то же.
[01:10:58.280 --> 01:11:01.280]  Я не пишу, здесь осознанно основание алгоритма.
[01:11:01.280 --> 01:11:04.280]  Какое бы ни написал, с точки зрения O все будет одно и то же.
[01:11:04.280 --> 01:11:08.280]  Надо понять, нам остается понять.
[01:11:08.280 --> 01:11:20.280]  А почему в симптотику алгоритма входит ассистентка, за которую он считывает данные?
[01:11:20.280 --> 01:11:24.280]  Можно не учитывать, зависит от постановки.
[01:11:24.280 --> 01:11:31.280]  На практике то, что вы будете делать в течение трех семестров, у вас будет работать так.
[01:11:31.280 --> 01:11:37.280]  В контест, какие задачи вы будете сдавать дан массив чисел, надо с ним что-то сделать.
[01:11:37.280 --> 01:11:39.280]  Вам же надо считать его сначала.
[01:11:39.280 --> 01:11:44.280]  Поэтому я полностью анализирую все действия, которые потенциально надо сделать.
[01:11:44.280 --> 01:11:48.280]  Конечно, иногда это можно дропать, если вам сказано, что массив расположен уже в памяти.
[01:11:48.280 --> 01:11:51.280]  Но в общем случае нельзя это дропать.
[01:11:51.280 --> 01:11:56.280]  Я хочу понять, почему ответ на запрос работает за отлог N.
[01:12:04.280 --> 01:12:06.280]  Тут вроде не хитро.
[01:12:06.280 --> 01:12:12.280]  Идея в том, что мой полуинтервал всегда делится примерно пополам.
[01:12:12.280 --> 01:12:16.280]  Потому что у меня изначально был полуинтервал длины n плюс один.
[01:12:16.280 --> 01:12:21.280]  На каждом шаге я считаю его середину и перехожу либо влево, либо вправо.
[01:12:21.280 --> 01:12:26.280]  Понятно, что если m – это их полусумма, то количество элементов здесь примерно равно
[01:12:26.280 --> 01:12:30.280]  количество элементов здесь примерно равно длине пополам.
[01:12:30.280 --> 01:12:35.280]  На каждом шаге я делю мой отрезок примерно вдвое.
[01:12:35.280 --> 01:12:40.280]  Ну а сколько раз можно n поделить на 2, пока он больше чем один?
[01:12:40.280 --> 01:12:43.280]  Понятно, алгоритмическое количество раз.
[01:12:43.280 --> 01:12:45.280]  Давайте это запишем.
[01:12:45.280 --> 01:12:48.280]  На каждой итерации цикла
[01:12:54.280 --> 01:12:58.280]  длина полуинтервала LR
[01:13:01.280 --> 01:13:04.280]  делится примерно вдвое,
[01:13:04.280 --> 01:13:07.280]  делится примерно
[01:13:08.280 --> 01:13:10.280]  на два.
[01:13:10.280 --> 01:13:13.280]  На самом деле, примерно, потому что в зависимости отчетности, возможно,
[01:13:13.280 --> 01:13:16.280]  но там не пополам поделилось, а пополам с округлением вверх.
[01:13:16.280 --> 01:13:21.280]  Например, если здесь было 9 элементов, вы поделили пополам в одной части 4, в другой 5.
[01:13:21.280 --> 01:13:25.280]  Но все равно примерно пополам.
[01:13:25.280 --> 01:13:28.280]  Каждый шаг примерно пополам.
[01:13:28.280 --> 01:13:31.280]  А количество раз,
[01:13:33.280 --> 01:13:36.280]  которое можно поделить n на 2,
[01:13:36.280 --> 01:13:39.280]  которое можно поделить
[01:13:40.280 --> 01:13:43.280]  n на 2,
[01:13:44.280 --> 01:13:47.280]  пока число больше чем 1,
[01:13:49.280 --> 01:13:52.280]  есть как раз логарифм.
[01:13:52.280 --> 01:13:55.280]  В данном случае двоичный логарифм n.
[01:13:56.280 --> 01:13:59.280]  Логарифм так работает, что
[01:13:59.280 --> 01:14:02.280]  можно было представить в обратную сторону.
[01:14:02.280 --> 01:14:05.280]  Вот если я начинаю с числа 1,
[01:14:05.280 --> 01:14:08.280]  то сколько раз его можно умножить на 2, чтобы достигнуть n?
[01:14:08.280 --> 01:14:11.280]  Примерно логарифмическое.
[01:14:14.280 --> 01:14:17.280]  Получается, что у меня ответ на запрос за логарифм.
[01:14:24.280 --> 01:14:27.280]  Да, здесь можно.
[01:14:27.280 --> 01:14:30.280]  Считывание всегда работает ровно за n,
[01:14:30.280 --> 01:14:33.280]  потому что мне нужно n элементов считать.
[01:14:33.280 --> 01:14:36.280]  Как ни крути, это будет n.
[01:14:36.280 --> 01:14:39.280]  Это правда.
[01:14:39.280 --> 01:14:42.280]  Но если бы я здесь ставил какую-нибудь умную подхачку,
[01:14:42.280 --> 01:14:45.280]  как мне предлагали, что если текущее число равно x,
[01:14:45.280 --> 01:14:48.280]  то сразу прерывай цикл и принт yes.
[01:14:48.280 --> 01:14:51.280]  Тогда уже нельзя было бы.
[01:14:51.280 --> 01:14:54.280]  Если бы я внезапно на каком-то шаге нашел x,
[01:14:54.280 --> 01:14:57.280]  то я бы этот цикл мой забросил сразу же
[01:14:57.280 --> 01:15:00.280]  и из него вышел и пришел к следующему запросу.
[01:15:00.280 --> 01:15:03.280]  Тогда было бы только o от логарифма.
[01:15:03.280 --> 01:15:06.280]  Здесь можно писать это туда.
[01:15:19.280 --> 01:15:22.280]  Потому что у меня задача распадается на 2.
[01:15:22.280 --> 01:15:25.280]  Я сначала считываю весь мой массив.
[01:15:25.280 --> 01:15:28.280]  Это занимает n времени.
[01:15:28.280 --> 01:15:31.280]  А потом я на каждый запрос трачу вот столько времени.
[01:15:31.280 --> 01:15:34.280]  Я заказываю, что время ответа на запрос логарифмическое.
[01:15:34.280 --> 01:15:37.280]  Дальше у меня q запросов.
[01:15:37.280 --> 01:15:40.280]  Поэтому суммарное время ответа на запрос это q log n.
[01:15:40.280 --> 01:15:43.280]  Еще плюс n на время считывания.
[01:15:43.280 --> 01:15:46.280]  Я здесь анализирую одну часть алгоритма, а здесь сумма всего.
[01:15:46.280 --> 01:15:49.280]  Сумма всего, что делает мой алгоритм.
[01:15:52.280 --> 01:15:55.280]  Еще раз, потому что я здесь отвечаю на один конкретный запрос.
[01:15:55.280 --> 01:15:58.280]  Вот один запрос работает столько,
[01:15:58.280 --> 01:16:01.280]  но q запросов столько.
[01:16:18.280 --> 01:16:21.280]  Я это проговаривал, что там 2 n операции,
[01:16:21.280 --> 01:16:24.280]  но 2 с точки зрения o можно убить.
[01:16:24.280 --> 01:16:27.280]  Есть еще вопросы?
[01:16:27.280 --> 01:16:30.280]  Ну окей, раз все хотят уйти, то давайте уйдем.
[01:16:30.280 --> 01:16:33.280]  Спасибо, до следующего раза.
