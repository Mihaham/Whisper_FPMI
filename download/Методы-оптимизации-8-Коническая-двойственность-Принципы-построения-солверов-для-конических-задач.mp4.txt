[00:00.000 --> 00:08.260]  Отлично. Запись поставлена. Сегодня, я надеюсь, мы успеем
[00:08.260 --> 00:12.900]  две темы. Они обе просто не очень большие, и попробуем
[00:12.900 --> 00:16.100]  не растягивать это на две отдельные занятия. Первая
[00:16.100 --> 00:20.340]  коническая двойственность. Посмотрим, чем она отличается
[00:20.340 --> 00:23.580]  от… Точнее, не отличается, а выделяется по сравнению
[00:23.580 --> 00:28.140]  с той двойственностью, которая была в прошлый раз.
[00:28.140 --> 00:30.820]  Мы контролили двойственные функции, получали некоторые
[00:30.820 --> 00:36.340]  результаты по условиям оптимальности. Вкратце, надо бы их напомнить,
[00:36.340 --> 00:41.220]  что если у нас там есть задача с выпуклыми… Наверное,
[00:41.220 --> 00:44.180]  имеет смысл только про выпукло сейчас напомнить, что если
[00:44.180 --> 00:50.620]  мы вот такую задачу решаем, где f и h житые выпуклые,
[00:50.620 --> 00:54.420]  то при выполнении условий слейтера, то есть наличие
[00:54.420 --> 00:59.180]  такой точки, в которой равенства выполнены, а неравенства
[00:59.180 --> 01:04.220]  выполнены как строгие, у нас есть условия к т, найдутся
[01:04.220 --> 01:06.660]  двойственные переменные, которые будут доставлять
[01:06.660 --> 01:09.700]  сильную двойственность. И, собственно, будет выполнено
[01:09.700 --> 01:15.500]  условие к т о том, что 5 штук меньше либо равно 0, а х со звездочкой
[01:15.500 --> 01:20.700]  равно b. Двойственные множители для неравенств не отрицательны.
[01:20.700 --> 01:24.900]  Дополняющая нежесткость, что по элементам равны 0,
[01:24.900 --> 01:29.500]  и сационарность лагерныжана по х, то есть f штрих от х в
[01:29.500 --> 01:33.020]  х со звездочкой плюс… Так, а давайте я сейчас вот так
[01:33.020 --> 01:35.740]  напишу, это нам пригодится впереди еще. Что скалярное
[01:35.740 --> 01:40.420]  произведение лямбда транспонировано на g в х со звездочкой, ну
[01:40.420 --> 01:44.620]  g в х со звездочкой, это понятно, что такое. Ой, я не допишу.
[01:44.620 --> 01:48.260]  У нас же нет никаких g, у нас есть ах со звездочкой
[01:49.260 --> 01:52.460]  плюс мют транспонированный, а вот аш у нас уже есть. То есть
[01:52.460 --> 01:57.540]  аш от х – это как бы вектор функции, который состоит
[01:57.540 --> 02:03.540]  из элементов от х, па-па-па, там b от х, например. Вот
[02:03.540 --> 02:08.180]  такой вот вектор. Так, градиент здесь, градиент… А, тут
[02:08.180 --> 02:12.420]  на самом деле надо бы хорошо вот так по х. Плохо написано,
[02:12.420 --> 02:16.060]  ладно, сейчас я перепишу. А транспонированная лямбда.
[02:16.060 --> 02:20.580]  Вот, выполнены такие условия. Вот, их надо знать, понимать,
[02:20.580 --> 02:24.940]  когда их можно применять, когда нельзя. Вот, и соответственно
[02:24.940 --> 02:29.580]  делать, уметь делать свойствах решения исходя из того, что
[02:29.580 --> 02:32.860]  у вас получается в процессе разрешения этой большой
[02:32.860 --> 02:38.220]  системы с линиейными, с равенствами и неравенствами. Так,
[02:38.220 --> 02:42.020]  это был прошлый разный результат. Вот, сейчас поговорим
[02:42.020 --> 02:45.420]  немножко про то, что важно понимать еще про двойственность.
[02:45.420 --> 02:49.580]  Потом рассмотрим некоторые примеры и контрпримеры. Вот, и
[02:49.580 --> 02:54.620]  потом перейдем уже к второй половине. Значит, что важно
[02:54.620 --> 02:57.820]  понимать? Важно понимать, что если у вас есть одна и
[02:57.820 --> 03:02.220]  та же задача, вот, ну, например, ну, например, мы хотим
[03:02.220 --> 03:07.540]  минимизировать что-то вот такое. Вот. И вам надо по каким-то
[03:07.540 --> 03:10.300]  причинам, бывает, что так на самом деле проще решать,
[03:10.300 --> 03:13.340]  построить для нее двойственную. Но поскольку в задаче нет
[03:13.340 --> 03:16.780]  ограничений, то ничего путного у вас в таком виде не
[03:16.780 --> 03:20.180]  получится. Поэтому ее переформулируют, введя дополнительную
[03:20.180 --> 03:24.060]  переменную и ставя уже вот такую вот задачу по переменам
[03:24.060 --> 03:27.660]  x и y. Тут уже ограничение появляется, лаганожан становится
[03:27.660 --> 03:32.140]  не тривиальным. Вот. И поэтому можно получить какой-то
[03:32.140 --> 03:34.500]  конструктивный результат через строение двойственной
[03:34.500 --> 03:38.940]  задачи. Вот. То есть стандартный прием для рассмотрения, ну,
[03:38.940 --> 03:42.620]  то есть в процессе анализа и исследования некоторых
[03:42.660 --> 03:45.700]  задач бывает полезно вводить новые переменные, которые
[03:45.700 --> 03:49.220]  будут позволять, которые позволяют, собственно, получить
[03:49.220 --> 03:52.420]  ограничения, которые в дальнейшем помогают получить
[03:52.420 --> 03:54.620]  нетрериальную двойственную задачу. Это первый способ. Ну,
[03:54.620 --> 03:57.020]  и второй важный момент, что если у вас, например, была
[03:57.020 --> 03:59.420]  какая-то такая задача линейного программирования, про
[03:59.420 --> 04:03.580]  который мы еще поговорим чуть позже. Вот. Ну, например, x
[04:03.580 --> 04:07.540]  было от 1 до минус 1, то у вас есть как бы два пути. Первый
[04:07.540 --> 04:10.420]  путь смотреть на вот это вот как на ограничения, как мы
[04:10.420 --> 04:14.420]  делали раньше. Тогда у вас там будет лагранжан иметь вид.
[04:14.420 --> 04:18.620]  Так. А вот дальше будет что-то типа мю1 транспонировано
[04:18.620 --> 04:25.220]  x-1 минус мю2 транспонировано. Давайте плюс. Чего? Минус
[04:25.220 --> 04:29.620]  x-1. Это такое. Вы там этот лагранжан как-то анализируете,
[04:29.620 --> 04:33.220]  находите инфимум, выражаете туда-сюда, все получается.
[04:33.220 --> 04:35.420]  Получаете некоторую двойственную задачу в переменах
[04:35.420 --> 04:39.420]  лямбда. Так. Какие тут переменные? Лямбда, мю1, мю2. Вот. При
[04:39.420 --> 04:42.020]  этом понятно, что ограничения в двойственной задаче будут,
[04:42.020 --> 04:45.420]  что мю1 больше либо равно 0, а мю2 тоже больше либо равно 0.
[04:45.420 --> 04:49.020]  Это будут ограничения. Вместе с тем можно поступить иначе.
[04:49.020 --> 04:52.020]  Можно сказать следующее, что наша задача это то же самое,
[04:52.020 --> 04:55.020]  что, ну это буквально то же самое. Вот так вот. При условии,
[04:55.020 --> 04:59.020]  что ax равно b. Тогда лагранжан, который у вас будет, будет
[04:59.020 --> 05:03.220]  выглядеть вот так. Но в процессе поиска двойственной функции
[05:03.220 --> 05:06.220]  вы будете искать инфимум по вот этому множеству. То есть
[05:06.220 --> 05:08.720]  в каком-то смысле, то есть вот эту штуку, если вы решаете,
[05:08.720 --> 05:11.220]  то у вас задача двойственная будет просто максимизация
[05:11.220 --> 05:14.720]  g от лямбды, уже без ограничений. То есть если у вас есть какие-то
[05:14.720 --> 05:17.720]  не очень сложные ограничения, то вы можете их явным образом
[05:17.720 --> 05:21.720]  записать в область определения и посчитать по ним инфимум.
[05:21.720 --> 05:25.420]  В чем плюс? У вас получилась безусловная задача двойственная,
[05:25.420 --> 05:28.220]  то есть безусловная задача, никаких ограничений нет.
[05:28.220 --> 05:31.220]  Решать такие задачи проще. В чем сложность? В том,
[05:31.220 --> 05:35.220]  что находить инфимум, у которого нет никаких ограничений,
[05:35.220 --> 05:38.220]  сильно проще, чем искать инфимум, когда ограничения
[05:38.220 --> 05:41.720]  на x есть. Вот поэтому важно балансировать те ограничения,
[05:41.720 --> 05:45.720]  которые вы выносите в собственно Лагранжан и те, которые вы
[05:45.720 --> 05:50.220]  оставляете внеявным образом, чтобы их в дальнейшем учесть
[05:50.220 --> 05:53.720]  в процессе поиска инфимум. Так, поставьте плюс, если вот
[05:53.720 --> 05:56.220]  было до этого места все понятно или минус, если было
[05:56.220 --> 05:59.720]  что-то непонятно. Так, пять плюсов вижу, примерно половина.
[05:59.720 --> 06:03.720]  Так, у кого возникли какие-то вопросы, сомнения, непонимание
[06:03.720 --> 06:09.220]  того, что происходит, пример 6 и 7. Так, и тишина. Ну ладно,
[06:09.220 --> 06:13.220]  надеюсь, что тем, кто никак не реагирует, тоже все более-менее
[06:13.220 --> 06:16.720]  ясно. Так, ну теперь давайте примеры рассмотрим, примеры.
[06:16.720 --> 06:19.720]  Начнем с простейшей задачи линейного программирования,
[06:19.720 --> 06:22.720]  которая нам некоторые нюансы в состоянии двойственной
[06:22.720 --> 06:26.720]  задачи подсветит, можно так сказать. Так, ах равно b
[06:26.720 --> 06:31.220]  и не отрицательный x. Вот, ну что, строим кишман Лагранжан,
[06:31.220 --> 06:33.220]  давайте напишем его сбоку, чтобы сэкономить немножко
[06:33.220 --> 06:37.220]  место, и все было немножко более компактно. Вот, так,
[06:37.220 --> 06:44.220]  понятно ли, почему здесь минус? Да, потому что x в наших
[06:44.220 --> 06:50.220]  всех построениях было, было что, что функция, которая
[06:50.220 --> 06:53.220]  соответствует неравенству, у нас знак меньше либо равно,
[06:53.220 --> 06:56.220]  тут у нас и больше либо, и мы на минус 1 умножаем, получаем здесь
[06:56.220 --> 07:05.220]  OK, теперь g от λµ это infimum по x от Lx λµ, вот, и несложно
[07:05.220 --> 07:09.220]  заметить, что мы берем infimum по x от вот такой вот замечательной
[07:09.220 --> 07:14.220]  функции, c плюс a t лямбда минус мю спонирана на x минус
[07:14.220 --> 07:18.220]  лямбда tb. Вот, эта функция является линейной, поэтому ее
[07:18.220 --> 07:21.220]  infimum потенциально может улететь в миловесконечность,
[07:21.220 --> 07:25.220]  и что ему не помешает это сделать. Вот, кроме того, если
[07:25.220 --> 07:28.220]  вот этот коэффициент перед x будет равен нулю, поэтому
[07:28.220 --> 07:30.220]  тут есть два варианта, понятно, у нас есть два варианта,
[07:30.220 --> 07:35.220]  минус лямбда tb, если c плюс a t лямбда минус мю ноль, и
[07:35.220 --> 07:40.220]  минус бесконечность иначе. Вот, отсюда получаем стандартный
[07:40.220 --> 07:43.220]  вид двойственной задачи, максимизируем то, что у нас не
[07:43.220 --> 07:46.220]  минус бесконечность, что довольно разумно, при условии,
[07:46.220 --> 07:51.220]  что, во-первых, у нас, ну, это не минус бесконечность, она
[07:51.220 --> 07:54.220]  как бы правомерна, вот, ну и второе, что мю больше либо
[07:54.220 --> 07:57.220]  равно нуля. Понятно, что отсюда можно избавиться от
[07:57.220 --> 08:01.220]  мю, другополучно, и у нас будет максимизация минус
[08:01.220 --> 08:06.220]  лямбда tb при условии, что c плюс a t лямбда больше либо
[08:06.220 --> 08:09.220]  равно нуля. Вот, опять получили, значит, линейное программирование,
[08:09.220 --> 08:13.220]  вот, то есть все довольно прямолинейно, никаких особо
[08:13.220 --> 08:16.220]  проблем здесь как будто бы не наблюдается. Вот, для
[08:16.220 --> 08:18.220]  линейного программирования также можно выписывать условия
[08:18.220 --> 08:22.220]  оптимальности, вот, и заодно понять, в чем будет основная
[08:22.220 --> 08:26.220]  беда, то есть у нас будет a x со звездочкой равно b, x со
[08:26.220 --> 08:29.220]  звездочкой больше либо равно нуля, опять же, мю больше либо
[08:29.220 --> 08:38.220]  равно нуля, мю и t, x и t равно нулю, нежесткость, да, и
[08:38.220 --> 08:41.220]  чего? Да, и, собственно, градиент Лагранжана, который мы,
[08:41.220 --> 08:46.220]  по сути, уже выписали, a t лямбда со звездочкой плюс c
[08:46.220 --> 08:50.220]  минус мю со звездочкой равно нулю. Вот, вот, в принципе,
[08:50.220 --> 08:54.220]  если вы умеете такую систему решать за разумное какое-то
[08:54.220 --> 08:59.220]  время, то вы получаете решение задачи. Вот, давайте посмотрим
[08:59.220 --> 09:01.220]  на это внимательно и поймем, в чем сложность в решении
[09:01.220 --> 09:04.220]  такой системы. Так, ну, матрица A, да, надо сказать заранее,
[09:04.220 --> 09:09.220]  что она там m на n, m меньше n, ну и полного ранга, вот, чтобы
[09:09.220 --> 09:13.220]  не было дополнительных сомнений. Вот, в чем проблема, так вы
[09:13.220 --> 09:15.220]  думаете? Ну, может, то, что последние условия достаточно
[09:15.220 --> 09:18.220]  нетривиальные, то есть, ну, не понятно, как перебрать все
[09:18.220 --> 09:21.220]  такие, а ну, лямбда мю. Ну, смотрите, последние условия
[09:21.220 --> 09:24.220]  это как раз довольно прямолинейно, оно типа линей систем
[09:24.220 --> 09:28.220]  линейных уравнений, то есть у нас A t умножается на какую-то
[09:28.220 --> 09:32.220]  матрицу типа минус единичную, да, вот, и это умножается
[09:32.220 --> 09:35.220]  на блочный вектор лямбда со звездочкой мю со звездочкой,
[09:35.220 --> 09:38.220]  и это равно минус c. Это, на самом деле, система линейных
[09:38.220 --> 09:43.220]  уравнений, она, понятно, что недоопределена, вот, и тут
[09:43.220 --> 09:45.220]  нам как бы, мы видим как бы две системы, одна система
[09:45.220 --> 09:47.220]  нам двойственной переменной, другая система напрямую
[09:47.220 --> 09:51.220]  переменной, они обе недоопределенные, и вот надо понять
[09:51.220 --> 09:55.220]  теперь, как, что позволяет, что может позволить нам как-то
[09:55.220 --> 10:00.220]  отсечь лишние столбцы так, чтобы системы стали с квадратными
[10:00.220 --> 10:02.220]  матрицами и, ну, в отдельной теоремы, которая там будет
[10:02.220 --> 10:04.220]  говорить, что они так будут невыраженными, вот, ну, пока
[10:04.220 --> 10:07.220]  мы этого точно не знаем, это некоторые анонсы, анонс
[10:07.220 --> 10:10.220]  на через там, полтора месяца, наверное, то, что может
[10:10.220 --> 10:14.220]  заметить относительно сложности разрешения подобного
[10:14.220 --> 10:17.220]  рода систем, ну, не конкретно, который я выписал в целом.
[10:17.220 --> 10:19.220]  Так, ну, да, вижу, что какие-то затруднения есть, ну,
[10:19.220 --> 10:21.220]  смотрите, в чем проблема, это основная. Основная
[10:21.220 --> 10:23.220]  проблема, собственно, в условиях дополнительной
[10:23.220 --> 10:26.220]  нежесткости, вот, на этих условиях, потому что они
[10:26.220 --> 10:29.220]  требуют, по сути дела, перебора 2 в степени n вариантов,
[10:29.220 --> 10:33.220]  и, собственно, как только вы определяете, какие иксы
[10:33.220 --> 10:37.220]  у вас не ноль, точнее, какие иксы у вас ноль, вот отсюда
[10:37.220 --> 10:40.220]  вы можете, ну, их там будет правильное количество,
[10:40.220 --> 10:43.220]  ровно столько, сколько нужно для того, чтобы разрешить
[10:43.220 --> 10:46.220]  систему, вот, они будут не ноль, соответствующие
[10:46.220 --> 10:50.220]  mu станут нулями, вот, отсюда сразу вывалится куча всего,
[10:50.220 --> 10:55.220]  вот, ну, и, соответственно, потом вы, да, определите те
[10:55.220 --> 11:00.220]  лямбоды, которые будут соответствовать оставшимся
[11:00.220 --> 11:04.220]  равенствам, вот, то есть здесь идет перебор, кто ноль,
[11:04.220 --> 11:07.220]  кто не ноль, это довольно много, поэтому решать это
[11:07.220 --> 11:10.220]  в явном виде в точности довольно затруднительно,
[11:10.220 --> 11:12.220]  поэтому делать приближенно, и на этом основаны методы
[11:12.220 --> 11:14.220]  внутренней точки, про которые мы тоже будем еще
[11:14.220 --> 11:17.220]  говорить. Так, понятен ли этот момент? Так, ну, каких-то
[11:17.220 --> 11:20.220]  явных минусов я не вижу, верно, верно, в целом понятно.
[11:20.220 --> 11:24.220]  Окей, теперь важный момент, что в случае линейного
[11:24.220 --> 11:27.220]  программирования, подожди, если у нас допустимое
[11:27.220 --> 11:31.220]  множество прямой задачи не пусто, то выполнена сильная
[11:31.220 --> 11:35.220]  двойственность, и это напрямую следует из того, что вот
[11:35.220 --> 11:39.220]  здесь у нас, здесь, вот здесь у нас х лежит в подпространстве,
[11:39.220 --> 11:42.220]  раз он лежит в подпространстве, то какой-то х неотрицательными
[11:42.220 --> 11:47.220]  компонентами точно можно будет найти, в силу, ну,
[11:47.220 --> 11:49.220]  короче говоря, построения подпространств, как он выглядит,
[11:49.220 --> 11:51.220]  вот, поэтому условия сейтера выполнены, поэтому сильная
[11:51.220 --> 11:54.220]  двойственность будет выполнена. Часто этот факт, доказывают
[11:54.220 --> 11:58.220]  изолировано потому что, ну, в общем, можно его доказать
[11:58.220 --> 12:03.980]  просто расписав аккуратно, расписав аккуратно неравенство в двойственности, вот, ну, сейчас
[12:03.980 --> 12:09.300]  просто для экономии времени можно как бы сослаться на более общий факт. Вот, теперь следующая теорема,
[12:09.300 --> 12:17.900]  которая как бы дополняет вот это утверждение, вот, она говорит нам о том, что если, если допустимое
[12:17.900 --> 12:26.500]  множество в прямой задаче пусто, а в двойственных не пусто, будем разбираться, почему это условие
[12:26.500 --> 12:33.780]  важно, то двойственное будет неограничено. Так, то давайте D со звездочкой стремиться к плюс
[12:33.780 --> 12:39.060]  бесконечности. Вот, то есть, смотрите, если тут вот важный момент, что в двойственной задаче,
[12:39.060 --> 12:44.420]  допустим, множество должно быть не пусто. Вот, оно как бы не, пока не до конца, возможно, очевидно,
[12:44.420 --> 12:50.540]  почему тут эта приписка важна. Вот, ну и, собственно, это просто к тому, что до этого мы сказали,
[12:50.540 --> 12:54.580]  что если в прямой задаче не пустое множество, все хорошо, а сейчас смотрим, что будет в пустой
[12:54.580 --> 13:00.580]  случае, если оно пусто. Вот, то вот такая есть связь между неограниченностью и неразрешим,
[13:00.580 --> 13:05.980]  ну и недопустимостью между прямыми и двойственными значениями для инопрограммирования. Вот,
[13:05.980 --> 13:13.180]  соответственно, вы можете... Ну вот, смотрите, давайте посмотрим, вот эти максимумы. Вот,
[13:13.180 --> 13:17.500]  ну, слушайте, можно на минимум спокойно, то есть, я написал, что плюс бесконечности, чтобы как бы
[13:17.500 --> 13:22.500]  было коррелировано с тем, чтобы было перед этим написано. Вот, если сейчас в процессе доказательств
[13:22.500 --> 13:26.340]  нам будет важно поменять, то поменять знак, то там будет просто бесконечности, ничего страшного не
[13:26.340 --> 13:32.260]  произойдет. Вот, ну и доказывается это все дело довольно изящным, вот, потому что мы пользуемся
[13:32.260 --> 13:37.980]  ранее полученным фактом, не зря же мы его получали. Вот, и смотрим на допустимое множество в прямой
[13:37.980 --> 13:43.700]  задаче. Какой вид она имеет? Вот такой. Вот, значит, если это пусто, из этого следует,
[13:43.700 --> 13:50.340]  Малимив Аркаша, напоминаю, был такой факт на втором или третьем занятии, у нас будет
[13:50.340 --> 13:57.580]  существовать некоторый вектор P не нулевой, а такой, что B транспонированное на B будет меньше нуля,
[13:57.580 --> 14:04.100]  а P транспонированное на A будет больше либо равно нуля. Теперь внимательно посмотрим на двойственную
[14:04.100 --> 14:11.180]  задачу. Да, в двойственной задаче мы можем перейти от максимума к минимуму, просто заменив,
[14:11.180 --> 14:19.100]  ну, понятно, λ убрав минус. Вот, то есть, можем сформулировать, что у нас двойственная задача
[14:19.100 --> 14:26.420]  будет минимум λtb, а не максимум минус λtb. При все тех же самых условиях, что a t лямбда плюс
[14:26.420 --> 14:33.220]  c больше либо равно нуля. Вот, теперь, возьмем какую-то допустимую точку в двойственной задаче. Пусть это
[14:33.220 --> 14:41.180]  будет лямбда с чертой, допустимая точка в двойственной задаче. Вот, и стартуя от нее, рассмотрим вот
[14:41.180 --> 14:47.980]  такое вот значение theta p, где theta число больше нуля. Давайте теперь подставим, посмотрим,
[14:47.980 --> 14:53.660]  что произойдет. Во-первых, проверим, что лямбда с крышкой будет все еще допустимая. Это что такое?
[14:53.660 --> 15:02.380]  Это лямбда t, так, плюс c, плюс theta a t p. Раскрыли скобки. Вот эта штука в силу допустимости,
[15:02.380 --> 15:08.260]  она больше либо равно нуля. Далее, a t p тоже больше либо равно нуля, потому что у нас вот выполнено.
[15:08.260 --> 15:14.140]  И это больше нуля, поэтому это все больше либо равно нуля. Теперь, a с крышкой, транспонированной
[15:14.140 --> 15:21.700]  на b, это что такое? Это a с чертой, плюс theta p, множить на b. А это, в свою очередь, равняется,
[15:21.700 --> 15:28.620]  ну, короче говоря, равняется лямбда с чертой, транспонированной b, это какая-то константа,
[15:28.620 --> 15:34.700]  плюс theta, на p, транспонированная b. Вот p, транспонированная b, у нас меньше нуля. Вот,
[15:34.700 --> 15:41.060]  и это константа некоторая. Поэтому это все при тесте theta с тремяющимся плюс бесконечности будет
[15:41.060 --> 15:47.500]  стремиться к милу бесконечности. Вот, получаем неограниченность. Да, ну, учитывая, что у нас d
[15:47.500 --> 15:53.940]  со звездочкой поменял знак, то мы... Ну да, тут на самом деле надо было хорошему написать вот так,
[15:53.940 --> 15:59.860]  вот, и картины, чтобы ничего не поменялось совсем. Вот, ну и поэтому, следовательно, там d со звездочкой
[15:59.860 --> 16:06.620]  будет к плюсу бесконечности стремиться. Понятен ли путь, которым мы все доказывали? Давайте
[16:06.620 --> 16:13.820]  немножко сожму. Ставьте плюс, если понятно. Так, четыре, пять, шесть. Так, что, шесть? Все? Больше
[16:13.820 --> 16:21.100]  никому ничего не понятно? Так, о, семь. Ну все, видимо, силы людей всякие. Ха-ха-ха, ладно. Так,
[16:21.100 --> 16:26.220]  окей. Надеюсь, что все, кто не поставил плюсик, просто не поставили плюсика, ни то, что ничего не
[16:26.220 --> 16:32.580]  понял. Ладно, теперь давайте посмотрим внимательно на то, зачем нам было нужно вот это вот условие
[16:32.580 --> 16:36.340]  дополнительное требовать. Ну, то есть не то, что почему оно было нужно, оно было нужно, чтобы мы
[16:36.340 --> 16:42.020]  могли найти вот эту вот эту вот допустимую точку и от нее отталкиваться. Вот, то есть если бы ее не было,
[16:42.020 --> 16:46.980]  то мы как бы у нас непонятно было, почему можно было бы так делать. Теперь посмотрим, почему это
[16:46.980 --> 16:53.300]  может вообще ломаться. Вот, то есть почему может получиться так, что и допустим, множество их прямой
[16:53.300 --> 16:58.140]  и двойственной задачи окажутся пустыми. Неожиданный поворот. Строили-строили, получили там и там пустое
[16:58.140 --> 17:04.580]  множество. Непорядок. Вот. Ну, давайте для примера рассмотрим простую задачу. Простым там пример
[17:04.580 --> 17:12.220]  пустоты в, неправильно, пример недопустимости, наверное, лучше сформулировать, в прямой и
[17:12.220 --> 17:18.540]  двойственной LP. Вот. Ну, смотрим на такое вот множество. Все будем в 2D делать для
[17:18.540 --> 17:24.300]  простоты обычно. Все такие факты, они чаще всего в маломерном пространстве очень хорошо иллюстрируются.
[17:24.300 --> 17:31.780]  х1 меньше или равно минус единице, х2 больше или равно единице и все они, понятно, дело не
[17:31.780 --> 17:37.660]  отрицательно. Вот. Если приводить все к стандартному виду, то что у нас появится? У нас будет две
[17:37.660 --> 17:42.740]  так называемые слаг-переменные, дополнительные переменные, которые превращают неравенство в
[17:42.740 --> 17:49.060]  равенство. И матрица систем будет выглядеть таким вот образом. Да, кстати, давайте это упражнение,
[17:49.060 --> 17:55.460]  давайте почитайте матрицу системы, что надо сделать, чтобы привести задачу к виду, а х равно b и x
[17:55.460 --> 17:59.660]  больше либо равно 0. Вот. Какой будет матрица, какой будет вектор b? Давайте я вот сейчас a равно,
[17:59.660 --> 18:05.380]  пару минут, в общем-то ничего сложного вроде бы нет. Вот. И давайте вектор b буду сюда записывать.
[18:05.380 --> 18:09.780]  В смысле все не отрицательные? Ну, вот это да, что все переменные, которые у нас будут, будут
[18:09.780 --> 18:14.020]  не отрицательными. Ну, тут уже и так написано, что они частично больше либо равно 0. Вот. Надо
[18:14.020 --> 18:19.420]  будет еще такие же ограничения на дополнительные слаг-переменные добавить, и все будет в себе
[18:19.420 --> 18:27.100]  хорошо. Можно написать матрицу a в чате построчно. Вот. Либо как-то, либо по столбцовой, не знаю,
[18:27.100 --> 18:31.980]  кому больше нравится. Либо проговорить просто в микрофон, из каких элементов будет первая
[18:31.980 --> 18:37.180]  срочка состоять. Извините, а почему мы сначала написали, что x1 меньше либо равно минус 1,
[18:37.180 --> 18:41.740]  а потом сказали, что все x больше либо равно 0? Потому что там был нужен пример пустого
[18:41.740 --> 18:46.860]  множества. Ну, давайте прочитаем заголовок. Мы строим пример недопустимости в прямой и двойственной
[18:46.860 --> 18:51.580]  задачи. Вот. Допусти множество в прямой задачи. Оно пусто, поэтому прямая задача недопустима.
[18:51.580 --> 18:55.780]  Сейчас будем смотреть на двойственную задачу и поймем, почему и двойственная задача тоже может
[18:55.780 --> 19:00.820]  стать недопустимой. Так, отлично. Я жду все еще, чтобы кто-то проговорил, как будет выглядеть матрица
[19:00.820 --> 19:06.220]  и вектор. Стоп. А мы только при этом, ну, матрицу только для условий делаем? Только вот эти три условия
[19:06.220 --> 19:11.220]  переформулируем в виде матрицы? Ну, вот. Вот есть множество, да? Вот вам надо записать это множество,
[19:11.220 --> 19:19.020]  как функциональные ограничения на вида равенства и вида не равен столько, чтобы x был не отрицатель.
[19:19.020 --> 19:27.060]  Ну, x это наш вектор, который новый. А, хорошо, понял. Не, я просто подумал, что там x1, x2 в скобочках это склеронпроизведение.
[19:27.060 --> 19:32.500]  Каких скобочках? И что множество, там, инфинум этого множества или что-нибудь такое. Ну, множество
[19:33.500 --> 19:46.060]  Вот эта штука, это значит, что x1 запятая 2 больше 0. Нет, это r2. Нет, нет, нет, это r2. Давайте я уточню, да.
[19:46.060 --> 19:52.700]  x, давайте вот так, из r2. Все, вообще не было разночтений. Склеронпроизведение в угловых скобочках пишем.
[19:52.700 --> 20:01.620]  В круглых не пишем. Именно по этим причинам. А, ну, давайте в качестве нового x возьмем вектор из r4, x1, x2.
[20:01.620 --> 20:08.980]  Лучше про матрицу давайте скажем. Просто нам надо дополнительные условия на неравенство. Да, ну, давайте сначала матрицу, а потом их добавим.
[20:08.980 --> 20:25.980]  Ну, а матрица, мне казалось, тогда будет только на то, чтобы новые компоненты, минус 1, минус x1 и x2, минус 1, чтобы они были соответствовали компонентам x1 и x2, чтобы, типа, они в сумме или в разъединении.
[20:26.420 --> 20:30.140]  Продиктуйте строки матрицы. Все прекрасно, все правильно. Давайте просто...
[20:30.140 --> 20:34.140]  Просто сначала нужно, чтобы у вас на самом деле какая-то структура x будет, а от этого зависит строки матрицы.
[20:34.140 --> 20:40.460]  Ну, вот вы сначала, давайте писать слева направо, да. Вы сначала нет матрицы, потом нет вектора, потом идет правая часть.
[20:40.460 --> 20:49.900]  Ну, 1, 0, минус 1, 0, кажется. Так, давайте проверю. Нет, 1, 0, 1, 0, похоже все-таки.
[20:49.900 --> 20:53.100]  Давайте сюда единичку поставим. Так, раз, строчка.
[20:53.100 --> 20:56.220]  Минус 1 в векторе. В правой части, да? Да.
[20:56.220 --> 21:01.500]  И ну, 0, 1, 0, минус 1. Что-то не то.
[21:01.500 --> 21:04.060]  Ну, вот я же говорю, нужно сначала на x согласиться.
[21:04.060 --> 21:07.340]  Не, не важно, согласились мы или нет, просто в том...
[21:07.340 --> 21:10.460]  По-разному можно сделать, по-разному можно преобразовать, кажется.
[21:10.460 --> 21:15.340]  Почему? Ну, хорошо, давайте, давайте обсудим, интересно. Так, какой будет вектор здесь? Диктуйте.
[21:15.340 --> 21:21.180]  Ну, x1, x2. Так. А дальше, минус x1, минус 1.
[21:21.180 --> 21:27.900]  Погодите, что это за минус x1, минус 1? У вас же, ну, типа переменная должна быть, какая-то буквка одна.
[21:27.900 --> 21:35.740]  Что там за минус 1 взялся? Да, но, как бы, я описываю преобразование из вектора, ну, xv2 в векторе xv4, как бы.
[21:35.740 --> 21:40.940]  А потом, ну, то есть, а условия нам, ну, вот это вот, как раз условия равенства...
[21:40.940 --> 21:45.500]  Так, еще раз, смотрите, формально вот, вот, вот условия. Вот, надо записать, чтобы было вот так.
[21:45.500 --> 21:47.580]  Можете вот в таком виде предоставить ответ.
[21:47.580 --> 21:50.540]  Там, преобразование, все это дело, можно делать все что угодно.
[21:50.540 --> 21:55.740]  Важно получить вот финальное вот в таком вот виде, чтобы был один вектор, была матрица, была правая часть.
[21:55.740 --> 22:00.540]  Все, ничего больше как бы не требуется. Вот x1, x2. Тут еще какие-то две букурки должны быть.
[22:00.540 --> 22:02.380]  Ну, x3, x4, если так.
[22:02.380 --> 22:07.340]  Так, хорошо, x3, x4, давайте, да. Так, и давайте поймем теперь все реправильно.
[22:07.340 --> 22:10.620]  А здесь какая будет правая часть для второй спроки?
[22:10.620 --> 22:18.220]  Тут был минус 1. Ну, давайте проверим. Умножаем. x1 плюс x3 равняется минус 1.
[22:18.220 --> 22:22.620]  Вроде правильно, потому что у нас изначально было x1 меньше, или, брай, минус единицы.
[22:22.620 --> 22:29.180]  Мы к нему добавили что-то неотрицательное. Тут у нас, соответственно, будет x1, 2, 3, 4. Все неотрицательное.
[22:29.180 --> 22:31.180]  Должно быть, по крайней мере. Все хорошо.
[22:31.180 --> 22:41.020]  Теперь со вторым неравенством, с второй строчкой. x2 минус, почему-то, x4 получается равно минус 1.
[22:41.020 --> 22:47.980]  Что-то не то. Было изначально x2 больше, либо равно единицы, но, по-моему, вот это неправда.
[22:47.980 --> 22:54.620]  Я x4 чуть выше. Вот я поэтому как раз про образование описывал. Ну, можешь чуть выше поднять, а то я не...
[22:54.620 --> 22:56.620]  Могу, конечно, без проблем.
[22:56.620 --> 23:04.540]  Я предполагал, что x3 это минус 1 минус x1. У нас уже есть x1 и x2. Какие мы получаем следующие? x3, x4.
[23:04.540 --> 23:11.820]  А x4 это x2 минус 1. А, да, и тогда там не минус 1, а 1 просто должно получиться.
[23:11.820 --> 23:15.100]  Так, ну давайте 1 поставим. Что, здесь поставим единицы?
[23:15.100 --> 23:15.660]  Да.
[23:15.660 --> 23:17.100]  Так, давайте посмотрим.
[23:17.100 --> 23:34.460]  Так, что получается? x2 минус x4, то есть у нас x2 больше минус единицы. Мы из нее вычитаем что-то положительное и получаем равенство единицы, да?
[23:34.460 --> 23:40.780]  Да, вроде разумно. Так, поставьте плюс, если понятно, что произошло, и минус, если не очень понятно.
[23:40.780 --> 23:47.340]  Так, вижу какие-то плюсы. Появляется хорошо. Раз, два, три, четыре, пять. Так, пока все еще только пять.
[23:47.340 --> 23:53.100]  Так, ну что, кто-то еще хочет спросить по поводу подобных преобразований или может дальше идти? Так, видимо никто не хочет.
[23:53.100 --> 24:00.940]  Окей. Так, давайте я сотру то, что мы тут проверяли. Ну и вот точно такое. Таким образом у нас записывается наше множество, которое пусто.
[24:00.940 --> 24:11.980]  Давайте теперь построим множество для двойственных задач. Оно у нас как выглядит? Внимание на экран, что называется. Оно у нас выглядит как A транспонированное лямбда плюс C больше либо равно нуля.
[24:11.980 --> 24:21.020]  Пока вектор C у нас никакого нет, поэтому давайте сейчас смотреть. A транспонированное лямбда плюс C больше либо равно нуля. Что такое A транспонированное?
[24:21.020 --> 24:39.420]  Ну, в общем, транспонируем матрицу, я думаю никаких проблем тут не возникнет. Значит, это будет C1 плюс лямбда 1 больше либо равно нуля. C2 плюс, да, плюс лямбда 2, правильно же, да, больше либо равно нуля. C3 плюс лямбда 1 больше либо равно нуля.
[24:39.420 --> 24:51.260]  И C4 минус лямбда 4 больше либо равно нуля. Вот такая замечательная система. Вот, и давайте посмотрим внимательно на то, что у нас. Ой, что за лямбда 4? Лямбда 2, простите.
[24:51.260 --> 25:02.060]  Что у нас здесь вырисовывается? Вырисовывается, что одновременно будет выполнено, что лямбда 2 меньше либо равно минус C2 и лямбда 2 больше либо равно C4.
[25:02.060 --> 25:11.900]  Отсюда следует, что может случиться так, что вектор C будет состоять из таких чиселок, что одновременно вот эта штука будет давать постоянную множество.
[25:11.900 --> 25:24.060]  Ну, например, там, что, C2 будет равно C4 равно 1, например, да? То есть лямбда 2 одновременно меньше минус 1, но больше 1. Кажется, это не очень хорошо.
[25:24.060 --> 25:34.060]  Поэтому за счет того, что в допустим множестве для двойственной задачи не последнюю роль играет вектор C, который у нас остался в степени свободы некоторое,
[25:34.060 --> 25:45.100]  который не участвует в определении допустима множества в прямой задаче, то при его как бы некоторым случайном неудачном выборе может получиться так, что в двойственной задаче допустим множество также останется.
[25:45.100 --> 25:52.140]  Понятен ли пример? Так, что-то примера стало понять только двум студентам. Интересно. Интересно, что непонятно остальным.
[25:52.220 --> 25:57.260]  Так, ну что? Какие вопросы вы дали предложение? Ну, вроде вопросов таких громких нет.
[25:57.260 --> 26:03.260]  Да, значит, это были некоторые факты про линейное программирование, мы к ним еще через некоторое время вернемся.
[26:03.260 --> 26:11.260]  Теперь, собственно, давайте перейдем к конической двойственности. Для этого надо сначала поставить задачу исходную, используя общенную неравенство через конусы.
[26:11.380 --> 26:21.380]  Все то же самое, в общем-то. Только теперь h' от x будет не просто меньше либо равно, а меньше либо равно в смысле некоторого конуса.
[26:21.380 --> 26:30.380]  И для такого рода задач, ну, напоминаю, что это значит, что у нас был элемент больше либо равен нуля в смысле конуса, было равносильно тому, что он в этом конусе лежит.
[26:30.500 --> 26:36.500]  Это было там, на втором или на третьем, на третьей лекции, когда мы про конусы начинали, у нас было обсуждение.
[26:36.500 --> 26:43.500]  Вот. Тогда для таких задач все будет то же самое абсолютно, все те же самые условия оптимальности.
[26:43.500 --> 26:49.500]  Погодите, с оптимальностью. Давайте сейчас с грызжаном разберемся. Грызжан будет абсолютно такой же, уже писал сегодня.
[26:49.500 --> 26:58.500]  Вот. А двойственность, значит, изменится чуть-чуть. Вот теперь mu будет больше либо равна в смысле сопряженного конуса.
[26:58.620 --> 27:04.620]  Это будет, это необходимо ровно по тем же причинам, по которым это было необходимо, когда у нас был конус rn+.
[27:04.620 --> 27:10.620]  Вот. Что мы просто подбираем такие коэффициенты, чтобы их скалярное произведение было строго и отрицательно.
[27:10.620 --> 27:14.620]  Вот. А это будет выполнено, когда у нас mu будет лежать в конусе.
[27:14.620 --> 27:20.620]  То есть для, ну, вот у нас типа есть такая вот штука, да. И нам нужно, чтобы это было больше либо равно нуля.
[27:20.620 --> 27:25.620]  Вот. При этом, а, наоборот, меньше, чтобы эта штука была, простите, меньше либо равно нуля.
[27:25.740 --> 27:28.740]  Ну, потому что мы из f должны что-то вычесть. Вот.
[27:28.740 --> 27:34.740]  При этом мы знаем, что минус h от x лежит в k.
[27:34.740 --> 27:38.740]  Это значит, что mu transponable h от x больше либо равно нуля.
[27:38.740 --> 27:41.740]  Только давайте я вот так это запишу, чтобы было попроще.
[27:41.740 --> 27:43.740]  Минус h от x. Вот.
[27:43.740 --> 27:47.740]  И нужно найти такие mu, для которых это будет работать.
[27:47.740 --> 27:52.740]  Ну, раз выполнено вот это, то вот это неравенство будет работать тогда, ну, тогда и только тогда,
[27:52.860 --> 27:55.860]  когда mu будет лежать в сопряженном конусе.
[27:55.860 --> 27:56.860]  Понятен ли этот переход?
[27:56.860 --> 27:58.860]  Все помните, что такое сопряженный конус?
[27:58.860 --> 28:01.860]  Это я тут так терминами бросаюсь, может быть, уже все забыли.
[28:01.860 --> 28:02.860]  Напомните.
[28:02.860 --> 28:04.860]  Повторить, пожалуйста, как называется этот класс задачи?
[28:04.860 --> 28:05.860]  Ну, название.
[28:05.860 --> 28:07.860]  Обобщенное неравенство.
[28:07.860 --> 28:09.860]  Ну, неравенство только обобщенное в смысле конуса.
[28:09.860 --> 28:15.860]  Ну, в смысле, ну, в общем, у него нет какого-то, да, такого, прямо уж названия имени собственного, вот.
[28:15.860 --> 28:19.860]  Но некоторое название, которое подчеркивает отличие от того, что было раньше.
[28:19.860 --> 28:20.860]  Понятно. Спасибо.
[28:20.980 --> 28:26.980]  Мы хотели пояснять более как-то детально, расписывать все переходы, которые были на прошлом занятии,
[28:26.980 --> 28:30.980]  только с учетом того, что у нас теперь есть вот это вот условие,
[28:30.980 --> 28:33.980]  а не просто, что h at x у нас меньше либо равен нуля.
[28:33.980 --> 28:34.980]  Да, нет.
[28:34.980 --> 28:35.980]  Нужно, не нужно.
[28:35.980 --> 28:36.980]  Не нужно.
[28:36.980 --> 28:37.980]  Окей.
[28:37.980 --> 28:41.980]  Ну, и тогда, как at переписывается тоже достаточно прямолинейно,
[28:41.980 --> 28:44.980]  у нас будет там ax со звездочкой равно b,
[28:44.980 --> 28:48.980]  h gt at x со звездочкой меньше либо равно в смысле конуса нуля,
[28:49.100 --> 28:53.100]  mu со звездочкой больше либо в смысле сопряженного конуса нуля,
[28:53.100 --> 28:56.100]  там дополнительная жесткость, как была, так и останется,
[28:56.100 --> 28:58.100]  на все выкладки это не повлияет никак,
[28:58.100 --> 29:00.100]  ну и соц. нарастал граждан тоже не изменится.
[29:00.100 --> 29:03.100]  Вот, то есть единственное отличие, которое происходит, ой,
[29:03.100 --> 29:07.100]  оно происходит вот здесь, вот здесь, ну и все, наверное, да?
[29:07.100 --> 29:10.100]  То есть в том, как неравенство между собой взаимодействует.
[29:10.100 --> 29:17.100]  Вот, ну и отсюда как бы следует у него более-менее универсальный способ построения двойственных задач.
[29:17.220 --> 29:20.220]  То есть если у нас задача вида коническая форма,
[29:20.220 --> 29:24.220]  то есть мы минимизируем линейную функцию с афинными ограничениями,
[29:24.220 --> 29:27.220]  и у нас x больше либо равен нуля в смысле конуса,
[29:27.220 --> 29:29.220]  вот, то опять же, что мы делаем?
[29:29.220 --> 29:32.220]  У нас будет жат лямбда, которая есть инфимум Лагранжана,
[29:32.220 --> 29:35.220]  и тут я активно буду использовать то, что,
[29:35.220 --> 29:37.220]  можно вот так написать,
[29:37.220 --> 29:39.220]  x больше либо равен конусу,
[29:39.220 --> 29:41.220]  больше либо равен нуля в смысле конуса,
[29:41.220 --> 29:43.220]  то, что мы сегодня уже обсуждали.
[29:43.220 --> 29:45.220]  А здесь, соответственно, x и лямбда,
[29:45.340 --> 29:49.340]  мы понимаем, что инфимум для c плюс at лямбда,
[29:49.340 --> 29:51.340]  спонированное x,
[29:51.340 --> 29:53.340]  минус лямбда tb,
[29:53.340 --> 29:55.340]  и это все для такого x,
[29:55.340 --> 29:57.340]  равно минус лямбда tb,
[29:57.340 --> 29:59.340]  плюс инфимум от этой штуковины.
[29:59.340 --> 30:02.340]  Ну, давайте, x лежит в конусе, да?
[30:02.340 --> 30:04.340]  Вот, и тут мы внезапно понимаем,
[30:04.340 --> 30:07.340]  что все это, весь этот инфимум будет конечным,
[30:07.340 --> 30:11.340]  только если эта штука снизу подпереть нулем.
[30:11.340 --> 30:13.340]  Вот, снизу можно подпереть нулем,
[30:13.460 --> 30:15.460]  только если у нас c плюс,
[30:15.460 --> 30:17.460]  то есть это равняется минус лямбда tb,
[30:17.460 --> 30:20.460]  при условии, что c плюс at лямбда
[30:20.460 --> 30:22.460]  лежит в сопряженном конусе.
[30:22.460 --> 30:24.460]  Ну, если лежит в сопряженном конусе,
[30:24.460 --> 30:26.460]  это значит, что выражение под инфимумом
[30:26.460 --> 30:28.460]  больше либо равно нуля,
[30:28.460 --> 30:30.460]  значит, инфимум 0.
[30:30.460 --> 30:32.460]  Если мы рассмотрим какой-то, ну,
[30:32.460 --> 30:34.460]  рассмотрим ситуацию,
[30:34.460 --> 30:37.460]  при которой c плюс at лямбда
[30:37.460 --> 30:39.460]  не лежит в сопряженном конусе,
[30:39.460 --> 30:41.460]  это значит, у какого-то x
[30:41.460 --> 30:47.060]  выражение будет отрицательно, это значит, что умножив этот х на положительное число, мы
[30:47.060 --> 30:53.660]  получим элементы с конуса и минус бесконечности. ну я не знаю, я надеюсь, понятно такое доказательство,
[30:53.660 --> 30:59.980]  почему это в обе стороны работает. и соответственно, минус бесконечности иначе. в итоге двойственная
[30:59.980 --> 31:06.300]  задача формулируется абсолютно прямолинейно. мы максимизируем минус лямбда tb при условии,
[31:06.300 --> 31:13.260]  то c плюс a t лямбда лежит в спряженном конусе. то есть все то, что мы делали до этого, если у
[31:13.260 --> 31:18.580]  вас задача в таком виде, автоматически позволяет строить двойственные задачи. вот зачем это все
[31:18.580 --> 31:25.100]  было надо, в частности конуса, самоспряженные конуса, спряженные конуса, двойственность. ну зачем
[31:25.100 --> 31:29.020]  нужна двойственность, мы прошлый раз обсудили. зачем нужны были конуса и представление задачи
[31:29.020 --> 31:33.940]  в конической форме, вот сейчас я надеюсь понятно. то есть вы по сути дела, один раз проделав общую
[31:33.940 --> 31:41.300]  выкладку, делегируете все вспомогательные операции, которые мы делали до этого, соотношение
[31:41.300 --> 31:46.500]  между конусом и сопряженным к нему. понятно ли это? или есть какие-то вопросы по этой части?
[31:46.500 --> 31:50.900]  на старте плюс, если все понятно, можно идти дальше. пока только четырем человек,
[31:50.900 --> 31:56.340]  людям понятно. если что-то непонятно, в каком-то месте не понимаете, почему мы выполнили то или
[31:56.340 --> 32:03.100]  иное переход, пожалуйста, сообщите об этом. иначе дальше будет не очень приятно со всем этим
[32:03.100 --> 32:08.420]  работать, не понимая почему это все корректно. реакции новой никакой не появилось. раздавительно.
[32:08.420 --> 32:15.180]  так, ну окей. к сожалению, пока нет запроса, очень сложно как-то что-то поменять или дополнить как-то.
[32:15.180 --> 32:19.300]  ладно, давайте теперь рассмотрим задачу полуопределенной оптимизации, которую мы уже
[32:19.300 --> 32:24.100]  частично говорили, и посмотрим какая двойственная будет для нее. а заодно обсудим ситуацию при
[32:24.100 --> 32:30.820]  которой у нас выполнена... у нас и прямая и двойственная сдача имеют решение конечные,
[32:30.820 --> 32:35.140]  но зазор двойственности положительный, хотя сдача в пуку. опять поиграем с тем, что условия
[32:35.140 --> 32:39.860]  сайтера будут нарушаться, только если в прошлый раз оно нарушалось и у нас получалось, что в множестве
[32:39.860 --> 32:44.940]  лагран же просто не существует оптимальных, которые условия как-то удовлетворяют. ну и если там
[32:44.940 --> 32:49.340]  построить двойственную, то там будет она неограничена. сейчас посмотрим на пример, когда все
[32:49.340 --> 32:55.820]  конечное, но зазора не ноль. вот такое тоже бывает. ну начнем с формулировки задачи с dp, с mdefinite
[32:55.820 --> 33:01.460]  programming problem. надеюсь, вы помните обозначение. самый общий тип, наверное, задач, который более
[33:01.460 --> 33:07.420]  или менее на практике встречается. вот и давайте запишем как это все выглядит. минимизация следа
[33:07.420 --> 33:14.060]  произведения матриц при условии, что следы от произведения нашей целевой матрицы на матрицу
[33:14.060 --> 33:22.340]  матрицы b. и сама матрица, понятное положение, полуопределена. вот такая вот задача. все почти
[33:22.340 --> 33:28.740]  так же, как было в линейном программировании. был вектор c, стал матрица c. было скалярное
[33:28.740 --> 33:33.980]  произведение для векторов, стало скалярное произведение для матов. тут обозначено в смысле rn,
[33:33.980 --> 33:41.540]  в смысле sn. были строки матрицы aita и стали отдельными матрицами aita. но вектор b как было,
[33:41.540 --> 33:48.140]  так и остался. был конус rn+, стал конус sn+. аналогия. то есть вот это вот часть lp,
[33:48.140 --> 33:55.980]  это часть sdp. ну и соответственно как двойственно встроить? плюс-минус так же. можно воспользоваться,
[33:56.980 --> 34:02.940]  давайте тоже проделаем все эти манипуляции с угрожаном. поскольку здесь ограничение вида
[34:02.940 --> 34:07.380]  матрицы положить на полуопределена, мы знаем уже, что в этом случае двойственный получается
[34:07.380 --> 34:12.780]  сопряженный конус, то тут может или Lagrange будет тоже некоторая матрица, которая будет положить на
[34:12.780 --> 34:20.220]  полуопределена. сейчас мы это увидим. ну давайте Lagrange на чему будет равен? след плюс сумма лямда
[34:20.220 --> 34:28.660]  it на след от aita x минус bita. ну там минус тоже понятно. минус скалярное произведение x на лямду.
[34:28.660 --> 34:36.420]  теперь если мы как бы соберемся вместе, то будет понятно, что это в точности равно,
[34:36.420 --> 34:43.660]  ну понятно, минус лямда it, bita вынесется. минимум по x большому. останется что? останется плюс
[34:43.660 --> 34:55.300]  сумма след матрицы x умножается на что? на c плюс лямда it aita минус лямда. воспользовались
[34:55.300 --> 35:01.300]  линейностью следа и соединили все, что касается матрицы x в одно выражение. кажется я ничего не
[35:01.300 --> 35:06.780]  забыл. ну и опять мы видим, что вот эта штука она линейна, поэтому потенциально можем улететь в
[35:06.780 --> 35:14.140]  минус бесконечность, поэтому g от лямда маленькой лямда больше получается. будет минус лямда tb при
[35:14.140 --> 35:23.220]  условии, что c плюс aita it минус лямда равно нулю. минус бесконечность иначе. ну и соответственно
[35:23.220 --> 35:36.580]  мы максимизируем минус лямда tb при условии, что c плюс, плюс сумма лямда it aita равны лямде и
[35:36.580 --> 35:42.540]  лямда у нас не отрицательно определяно. давайте я сразу затру. скажу, что вот эта штука вот так.
[35:42.540 --> 35:49.060]  получили вот такую вот задачу, которую первое преобразование, которое можно сделать, это
[35:49.060 --> 35:54.020]  сделал взаимопеременных. а зачем взаимопеременных? просто давайте перепишем это все к минимуму,
[35:54.020 --> 36:00.060]  то есть минимум лямда tb и те же самые условия. вот короче вот так. так сейчас секунду прошу прощения.
[36:00.060 --> 36:06.980]  так все вернулся. при условии, что c плюс лямда it aita будет не отрицательно определено. вот то есть
[36:06.980 --> 36:12.420]  смотри, что произошло. была исходная задача на матрицу двойственно оказывается уже на вектор rm.
[36:12.420 --> 36:18.620]  при этом ограничения сохранились в том, ну ограничения в задаче остались ограничениями в смысле
[36:18.620 --> 36:25.180]  матрицы. все было бы здорово, если бы эта штука не отличалась от линейного программирования в том,
[36:25.180 --> 36:31.180]  что здесь все-таки слабая сильная двойственность не гарантируется. и не гарантируется она ровно
[36:31.180 --> 36:38.180]  потому, что вот это вот условие не всегда выполняется. тут пространство такое вот не получается,
[36:38.180 --> 36:44.420]  как оно было для линейного программирования. поэтому гарантии на то, что найдется такая матрица
[36:44.420 --> 36:48.460]  строго положить на определенную, уже никаких нет. и сейчас мы собственно посмотрим, как это все
[36:48.460 --> 36:55.740]  сломается. вот рассмотрим вот такую вот задачу. пока я тут пишу, если все понятно поставьте плюсик,
[36:55.740 --> 37:00.860]  если есть какие-то вопросы по выкладкам, то пожалуйста поставьте минус или спросите что-нибудь.
[37:00.860 --> 37:09.580]  вижу 5 плюсов. окей, спасибо. вот такая вот задача. мы ее можем благополучно, понятно дело,
[37:09.580 --> 37:17.740]  переписать как там максимизация минус x2, чтобы вернуться к задаче, к которой мы
[37:17.740 --> 37:21.740]  собственно здесь пришли, чтобы потом сказать, что если мы будем строить к ней двойственную,
[37:21.740 --> 37:25.860]  то мы получим исходную. полезное упражнение проверить, что действительно будет так. так давайте
[37:25.860 --> 37:32.020]  я воспользовался тем, что могу все стереть, пишу максимум минус x2. давайте проанализируем,
[37:32.020 --> 37:37.500]  какое здесь допустимое множество. поскольку у нас здесь вот такой вот значок, ой хотел сказать был,
[37:37.500 --> 37:42.180]  да, все еще есть. нам надо проверить не отрицательно определенность такой матрицы
[37:42.180 --> 37:49.460]  по критерии челюсти. давайте проверять. x2 плюс 1 больше либо равно 0, x1 больше либо равно 0,
[37:49.460 --> 37:55.060]  а дальше получается, что если посмотрим на вот этот вот минор, то здесь получается,
[37:55.060 --> 38:01.540]  что минус x2 в квадрате больше либо равно 0, то есть x1 в квадрате меньше либо равно 0.
[38:01.540 --> 38:08.860]  следовательно x2 только 0. то есть p со звездочкой здесь равно 0. это наша получается x2 равно 0,
[38:08.860 --> 38:15.020]  допустимая точка вот такая. и оказывается, что если мы сейчас вот это вот x2 подставим,
[38:15.020 --> 38:21.260]  то у нас в общем начнет ломаться строго положительная определенность. тоже можно это
[38:21.260 --> 38:25.940]  проверить. теперь давайте запишем, как будет выглядеть двойственная задача. сейчас будет
[38:25.940 --> 38:31.380]  следить за руками. не очень просто все эти преобразования проделать, но давайте. так,
[38:31.380 --> 38:37.180]  чтобы это понять, надо выписать какая матрица c и какие матрицы аиты у нас были. матрица c у нас
[38:37.180 --> 38:41.260]  тут вот такая. сейчас вот если будет непонятно откуда берутся эти матрицы, пожалуйста тоже
[38:41.260 --> 38:50.700]  сообщите. a1 будет вот такой, ну и a2 соответственно будет вот такой. а что? вектор b соответственно
[38:50.700 --> 39:00.940]  будет равен 0-1. понятно ли, как я вытащил эти все константные матрицы из постановки задачи
[39:00.940 --> 39:09.780]  двойственной? глядя просто на соотношение между тем, что сейчас будет закрашено в зеленый и того,
[39:09.780 --> 39:14.940]  что окрашено в оранжевой. если нет, поставьте минус. если да, поставьте плюс. похоже на черную
[39:14.940 --> 39:19.500]  магию. никакой магии нет. ну смотрите. вот была у нас вот такая матрица. да, что-то как-то,
[39:19.500 --> 39:28.620]  кажется, в новую тему я не успел начать. ну ладно. x2 плюс 1, 0, 0, 0, x1, x2, 0, x2, 0. вы ее как можете
[39:28.620 --> 39:34.460]  представить? она равна. сначала это константная матрица. это 0. плюс x1 умножается на что-то и плюс
[39:34.460 --> 39:40.420]  x2 умножается на что-то. вот то, что это умножается, это a1, это a2, это c. ну я верю, вы можете как бы
[39:40.420 --> 39:45.100]  соотнести, что на что надо умножить, чтобы получить такие константные матрицы. а b? ну хорошо,
[39:45.100 --> 39:50.780]  смотрим на b. ну и что? максимизируем минус с ляму транспонированной на b. у нас максимизируется
[39:50.780 --> 39:56.420]  минус x2. это значит, что из нашего вектора x1, x2 вырезается вторая компонента. то есть на какой
[39:56.420 --> 40:02.260]  вектор надо умножить, чтобы получился x2? ну на 0, 1, наверное. тут просто смотрим на задачу и
[40:02.260 --> 40:06.340]  явным образом понимаем, из чего она собирается. то есть примерно то же самое делает солвер,
[40:06.340 --> 40:16.780]  который мы не начнем. в следующий раз начнем и закончим. просто разбирает задачу на ингредиенты
[40:16.780 --> 40:21.340]  и правильный образом переупаковывает. для того, чтобы можно было эффективно решить. так,
[40:21.340 --> 40:27.820]  стала ли магия менее черной, скажем так? прекрасно. все, разобрались. ура. ну теперь давайте возвращаться
[40:27.820 --> 40:33.340]  к исходной задаче. то есть мы ищем, будем искать некоторую матрицу, положить на полу
[40:33.340 --> 40:40.620]  определенную. целевая функция это след от c на эту матрицу. ну след от умножения такой матрицы
[40:40.620 --> 40:46.580]  c на другую матрицу. я думаю это очевидно, что пусть будет у. наша целевая переменная, целевая
[40:46.580 --> 40:57.340]  матрица в двойственной. ну будет y1. то есть след от c на y равняется y1,1. потом скалярные
[40:57.340 --> 41:06.020]  следы от a1 на x будут равны b1. поэтому при умножении на a1 получается y2,2. и при умножении
[41:06.020 --> 41:23.700]  на a2 получается y1,1 плюс y3,2. и вроде бы y3,2 плюс y2,3. и это все равно минус 1. ну это будет
[41:23.700 --> 41:30.740]  равно нулю. потому что b1 равен нулю, это b2 равен единице. так, сейчас единицы давайте я еще
[41:30.740 --> 41:40.140]  раз аккуратно проверю. что-то мне не нравится, секунду. так, что мы тут делали? у нас получился
[41:40.140 --> 41:50.340]  минус лямбда ит. и мы это максимизировали. при вот таком условии, да, тут все хорошо. а потом
[41:50.340 --> 41:58.820]  был максимум минус b на лямбда т. и тогда у нас b получился 0,1. ну ладно, вроде все хорошо.
[41:58.820 --> 42:04.980]  давайте тогда продолжим. да, сейчас правда есть риск, что мы получим не тот знак. сейчас она будет
[42:04.980 --> 42:11.780]  внимательно подумать, как так вышло. окей. так ладно, давайте сейчас пока оставим как есть. а
[42:11.780 --> 42:19.540]  нет, не как есть. все, я понял. я немножко напутал, прошу прощения. тут все надо вот так. то
[42:19.540 --> 42:24.900]  сейчас ничего не поменяется принципиально. вот минимум оставим x2 и минимум x2 перепишем как
[42:24.900 --> 42:32.620]  минус максимум. кажется минус x2 должен быть вот так. вот сейчас поймем, почему это будет важно. ну ладно,
[42:32.620 --> 42:41.900]  вроде все плюс-минус честно. вот максимум минус x2 и b у нас тогда 0,1. если мы 0,1 умножаем на x1 x2
[42:41.900 --> 42:46.100]  получаем x. да, тут стоит минус. это соответственно тому, что было выше. да, вроде все в порядке.
[42:46.100 --> 42:55.060]  окей. теперь и тут соответственно единица стоит. давайте теперь посмотрим. то есть и наша матрица
[42:55.060 --> 43:07.420]  y она вот такая. ну и у нас есть эти ограничения. давайте их аккуратненько распишем. y1,3, y2,1,2,2,2,3,3,1,3,2 и 3,3.
[43:07.420 --> 43:13.900]  вот. что мы можем отсюда вытащить? ну во-первых мы можем вытащить, вот посмотрев на вот этот вот
[43:13.900 --> 43:23.100]  минор, то y, да это все вот так. y2,2 умножить на y3,3 минус y2,3. ну тут можно квадрат поставить,
[43:23.100 --> 43:27.900]  потому что там все симметрично должно быть. больше либо равно нуля? это за нуляется, потому что y2,2
[43:27.900 --> 43:38.060]  0. вот. следовательно y2,3 равняется y3,2 тоже 0. отсюда следует, что y1,1 равняется единице. вот из
[43:38.060 --> 43:44.660]  вот этого условия. вот. а мы его как раз таки пытаемся максимизировать. минимизировать неважно.
[43:44.660 --> 43:50.740]  изначально мы его минимизировали. вот. получилось единица. до этого у нас получился 0. вот. и теперь
[43:50.740 --> 43:55.620]  внимание вопрос, где мы потеряли минус? вопрос важный, потому что сейчас у нас получилось что-то,
[43:55.940 --> 44:01.020]  что противоречит общей теории. вот. и давайте сейчас, я думаю, мы это благополучно сейчас
[44:01.020 --> 44:10.900]  разрешим этот вопрос. если внимательно посмотрим на то, как у нас собиралась матрица, видимо,
[44:10.900 --> 44:16.100]  да? то есть, ну не матрица, а как мы вот эти преобразования все делали, потому что видимо
[44:16.100 --> 44:21.940]  что-то здесь со знаком пошло не так. давайте разберемся. это в общем-то кажется несложно.
[44:21.940 --> 44:29.380]  получили вот такой вид. мы максимизируем минус a t лямбда b. вот. если мы сделаем замену
[44:29.380 --> 44:36.140]  переменной, скажем, что минус лямбда у нас то же самое, что лямбда, то это все станет максимум
[44:36.140 --> 44:43.580]  лямбда tb при условии, что c минус му лямбда итых аитых больше либо равно нуля. а дальше,
[44:43.580 --> 44:51.980]  а дальше мы можем вернуть обратно, заменив переменную на, ну воспользуешься тем,
[44:51.980 --> 44:57.380]  что максимум перейти, записать максимум через минимум. вот. и как раз-таки такая запись нам
[44:57.380 --> 45:04.700]  даст минус лямбда tb. только теперь, так где-то что-то потерялось, по-моему. будет здесь,
[45:04.700 --> 45:13.460]  наверное, минус и здесь останется плюс. вот. тогда у нас, короче говоря, задача сделать так,
[45:13.460 --> 45:20.220]  чтобы, то есть все будет работать тогда, когда мы сможем показать, что на самом деле b должен
[45:20.220 --> 45:27.820]  быть равен минус единичке. вот. то есть минимизация чего-то линейного при условии, при тех же самых
[45:27.820 --> 45:33.740]  условиях. вот. просто если как раз-таки b будет равен, тут будет минус единица, то здесь будет
[45:33.740 --> 45:39.620]  тоже минус единица, и у нас все получится. вот. так. 10.21. давайте я тогда, наверное, чтобы все было
[45:39.620 --> 45:47.180]  аккуратно, в следующий раз начну с этого примера и его как-то более аккуратно поясню. вот. и как бы
[45:47.180 --> 45:51.420]  основной результат, который будет до конца получен в следующий раз, будет заключаться в том,
[45:51.420 --> 45:59.140]  что, смотрите, у нас случилось, что, так, где-то я тут что-то решал, что p со звездочкой, которое было
[45:59.140 --> 46:06.100]  изначально, это 0. вот. а мы построили двойственную задачу и получили что-то, что не 0. ну, минус 1 до
[46:06.100 --> 46:10.660]  конца получен в следующий раз. вот. сейчас как-то немножко сумбурно получилось. вот. и таким образом,
[46:10.660 --> 46:17.340]  у нас зазор двойственности d со звездочкой минус d со звездочкой получил строго больше 0. то есть
[46:17.340 --> 46:22.580]  для выпуклой задачи мы построили пример, в котором, в следующий раз до конца доделаем, будет
[46:22.580 --> 46:27.940]  выполнено, что оптимальный зазор между решением прямой двойственной задачи оказывается положительным.
[46:27.940 --> 46:34.500]  понятно ли то, что мы ожидаем получить до конца в следующий раз? вот. это да. или не очень понятно,
[46:34.500 --> 46:39.700]  зачем мы все это делали? вот. то есть отсутствие выполнения условия слейтера может приводить не
[46:39.700 --> 46:44.540]  только там к неограниченности двойственной и отсутствию множества лагранжа, но и к тому,
[46:44.540 --> 46:49.780]  что вы как бы каждую задачу по отдельности можете решить, а решения у вас как бы оптимальные
[46:49.780 --> 46:55.020]  значения совпадать все равно не будут. вот. такое тоже возможно. так. ну что? есть ли вопросы? или
[46:55.020 --> 46:58.660]  все понятно? будет менее. так. если что-то не понятно, тоже, пожалуйста, поставьте минус,
[46:58.660 --> 47:03.580]  я подумаю над тем, как поподробно по понятиям объяснить. так. ну. вроде вопросов нет. тогда
[47:03.580 --> 47:10.380]  давайте на сегодня закончим. всем спасибо за участие и вопросы, которые были. в следующий раз
[47:10.380 --> 47:16.500]  тогда обсудим solver и начнем числые методы уже быстренько. там. градиентная спуска, все такое. вот.
[47:16.500 --> 47:22.540]  в общем перейдем немножко к коду, посмотрим как это все работает на практике, каким образом все
[47:22.660 --> 47:27.500]  применять. ну это будет уже конец октября, два месяца на теорию, ну два месяца на практику. вроде
[47:27.500 --> 47:34.020]  плюс-минус укладываемся в график. вот. все. всем спасибо и до следующей недели.
