[00:00.000 --> 00:06.000]  Вот мы с вами познакомились с понятием массива.
[00:06.000 --> 00:12.000]  У нас, соответственно, разблокировались какие-то новые возможности по алгоритмам.
[00:12.000 --> 00:17.000]  Когда мы говорим про какой-то массив данных, про какой-то набор значений,
[00:17.000 --> 00:20.000]  то первая задача, самая классическая задача, которая в этой связи решается,
[00:20.000 --> 00:22.000]  это, естественно, задача сортировки.
[00:22.000 --> 00:26.000]  Задача просто-напросто упорядочивания элементов в порядке возрастания
[00:26.000 --> 00:28.000]  либо в порядке убывания.
[00:28.000 --> 00:30.000]  Maintenant по этому интересу надеюсь я никому не удивлю.
[00:30.000 --> 00:35.000]  Если скажу, что задача сортировки, это просто задача поиска такой перестановки,
[00:35.000 --> 00:39.000]  которая превращает ваш исходный массив, в котором элементы не упорядочены,
[00:39.000 --> 00:43.000]  в массив, в котором все элементы идут в порядке не убывания.
[00:43.000 --> 00:46.000]  То есть нулевой элемент массива не больше фирмы,
[00:46.000 --> 00:50.000]  первый элемент не больше фирмы, ну и так далее.
[00:50.000 --> 00:54.000]  При этом под упорядочением я понимаю произвольное упорядочение,
[00:54.000 --> 00:57.000]  которое задается некоторым линейным порядком.
[00:57.000 --> 01:02.000]  а если элементы отсортированных в порядке возрастания, то это обычная операция меньше.
[01:02.000 --> 01:06.000]  Если, соответственно, элементы у меня идут в порядке убывания, то это обычная операция больше.
[01:06.000 --> 01:09.000]  Ну и так далее. То есть порядочнее может быть абсолютно произвольным.
[01:09.000 --> 01:12.000]  То есть просто напросто которое задается какой-то специальной операцией.
[01:12.000 --> 01:22.000]  Так, соответственно, наша цель на ближайшие лекции это познакомиться с зоопарком классических алгоритмов
[01:22.000 --> 01:25.000]  для работы с сортировкой и вообще для решения задачи сортировки.
[01:25.000 --> 01:29.000]  Значит, сегодня мы сосредоточимся в основном на самых простых алгоритмов,
[01:29.000 --> 01:32.000]  которые называются козротичными сортировками.
[01:32.000 --> 01:36.000]  Ну и сегодня наш сегодняшний план состоит из того, что мы рассмотрим с вами сортировку выбором,
[01:36.000 --> 01:39.000]  сортировку вставками, сортировку пузырьком.
[01:39.000 --> 01:41.000]  Ну поговорим, возможно, про некоторые модификации, про их преимущества,
[01:41.000 --> 01:44.000]  преимущества по сравнению с более быстрыми сортировками.
[01:44.000 --> 01:47.000]  Ну и так далее.
[01:47.000 --> 01:49.000]  Пословка задачи понятна.
[01:49.000 --> 01:54.000]  Можем начинать. Окей, супер. Давайте поговорим про первую сортировку, сортировка выбором.
[01:54.000 --> 02:00.000]  Давайте напишем какой-нибудь массив. Вот у меня есть некоторая последовательность.
[02:00.000 --> 02:08.000]  Вот у меня есть некоторая последовательность элементов. Допустим, 3, 5, 1, 2, 4.
[02:08.000 --> 02:12.000]  Необходимо сделать так, чтобы этот массив был отсортирован.
[02:12.000 --> 02:17.000]  В чем заключается сортировка выбором? Давайте просто возьмем.
[02:17.000 --> 02:20.000]  Во-первых, мы будем поддерживать два состояния.
[02:20.000 --> 02:24.000]  Вот у нас есть массив, и давайте поддерживать массив в двух состояниях.
[02:24.000 --> 02:28.000]  Состояние слева будет хранить элементы, которые уже отсортированы.
[02:28.000 --> 02:31.000]  То есть наименьшие элементы, которые уже отсортированы.
[02:31.000 --> 02:35.000]  А массив справа, его правая часть, будет хранить еще не отсортированные и не рассмотренные элементы.
[02:35.000 --> 02:38.000]  Изначально у меня массив состоит из двух частей.
[02:38.000 --> 02:42.000]  Пустая часть, которая уже отсортирована, пока ничего не отсортирована.
[02:42.000 --> 02:47.000]  и соответственно правая часть, которая не отсортирована.
[02:47.000 --> 02:50.000]  На самом деле можно это расширить. Давайте лучше так скажем, что у меня есть один элемент,
[02:50.000 --> 02:55.000]  который отсортирован, и оставшийся 7-1 элемент, который не отсортирован.
[02:55.000 --> 03:00.000]  То есть согласны, что один элемент всегда отсортирован. Уже круто, уже можно от чего-то отталкиваться.
[03:00.000 --> 03:08.000]  Пустой массив отсортирован. Тут не отсортирован. Я с другой сортировкой перепутал.
[03:09.000 --> 03:12.000]  Пока у нас ничего не отсортировано. Давайте выполним следующий шаг.
[03:12.000 --> 03:15.000]  Сортировка выборов делаем следующую штуку.
[03:15.000 --> 03:18.000]  У нас есть отсортированный массив. Допустим, его как-то получили.
[03:18.000 --> 03:22.000]  Какой элемент стоит на первом месте? Минимальный.
[03:22.000 --> 03:27.000]  Давайте проведем по неосортированной части и найдем минимальный элемент.
[03:27.000 --> 03:32.000]  Просто проведем 3,5,1. На ходе минимальный элемент.
[03:32.000 --> 03:35.000]  Раз мы нашли минимальный элемент, то мы точно знаем, где он должен находиться.
[03:35.000 --> 03:38.000]  он должен находиться на нулевой позиции массива, да?
[03:38.000 --> 03:40.000]  Все, мы прошлись по всей неотсортированной части,
[03:40.000 --> 03:42.000]  нашли минимальный элемент,
[03:42.000 --> 03:44.000]  и давайте его возьмем и поставим на первое место,
[03:44.000 --> 03:46.000]  вот сюда, в самое начало.
[03:46.000 --> 03:48.000]  Ну Кеорж, мы просто возьмем, например, вот этот элемент
[03:48.000 --> 03:50.000]  и обменяем с этим местами.
[03:50.000 --> 03:52.000]  Сюда запишем единицу, сюда запишем тройку.
[03:52.000 --> 03:54.000]  Нормально?
[03:54.000 --> 03:56.000]  Все, я получил единицу, и теперь я точно знаю,
[03:56.000 --> 03:58.000]  что левая часть, ну как минимум,
[03:58.000 --> 04:00.000]  состоит из одного элемента, который уже отсортирован.
[04:00.000 --> 04:03.000]  То есть единица точно стоит на своем месте, да?
[04:03.000 --> 04:05.000]  Все, таким образом, я увеличил отсортированную часть
[04:05.000 --> 04:07.000]  на единицу, а неосортированную
[04:07.000 --> 04:09.000]  уменьшил на единицу.
[04:09.000 --> 04:11.000]  Что я буду делать дальше?
[04:11.000 --> 04:14.000]  Дальше снова Рассмотрю неосортированную часть
[04:14.000 --> 04:16.000]  и спрошу сам себя.
[04:16.000 --> 04:19.000]  А какой элемент должен идти за единицей?
[04:19.000 --> 04:21.000] ve, Antonik.
[04:21.000 --> 04:23.000]  Да, должен следующим за единицей
[04:23.000 --> 04:25.000]  должен идти следующий по минимальности элемент.
[04:25.000 --> 04:27.000]  Так как сам минимальный элемент у меня уже стоит здесь,
[04:27.000 --> 04:29.000]  то, соответственно, мне осталось в этом массиве,
[04:29.000 --> 04:31.000]  в неотсортированную части,
[04:31.000 --> 04:41.000]  Всё, снова иду лево-направо, ищу минимальный элемент, и вставляю его на ту позицию, на которую он должен стоять.
[04:41.000 --> 04:48.000]  2, 5. Увеличиваю отсортированную часть, не отсортированная часть уменьшилась. Всё. Ну и так далее.
[04:48.000 --> 04:55.000]  Окей? То есть сортировка выбора, по сути, на каждой итерации, на каждом шаге делает выбор минимального элемента.
[04:55.000 --> 05:00.000]  Нашли минимальный элемент, вставили на своё место. Нашли следующий минимальный элемент, вставили на своё место. Всё.
[05:00.000 --> 05:08.000]  Вот такая простая идея. То есть в каждом именовании у нас массив разделён на две части – отсортированную и неотсортированную.
[05:08.000 --> 05:12.000]  Дальше в неотсортированную часть ищу минимум и добавляем в finite в отсортированной части.
[05:12.000 --> 05:16.000]  Таким образом, увеличивая отсортированную часть и уменьшая неотсортированную часть.
[05:16.000 --> 05:21.000]  Ну и продолжаем эту операцию до тех пор, пока весь массив не станет отсортированным. Нормально?
[05:21.000 --> 05:26.000]  Кажется, что звучит очень просто. Ну и реализуется очень просто.
[05:26.000 --> 05:36.580]  очень просто. Что мы делаем? У нас дан массив А, и соответственно в цикле мы перебираем набира
[05:36.580 --> 05:43.040]  не отсортированного элемента, то есть перебираем позицию, на которую будем вставлять очередной
[05:43.040 --> 05:48.840]  элемент. То есть очередной элемент будем вставлять в эту позицию. И соответственно внутри этого цикла
[05:48.840 --> 05:52.760]  просто-напросто ищем индекс минимального элемента. Изначально говорим, что индекс минимального
[05:52.760 --> 05:58.520]  элемента совпадает с этим элементом. Дальше, соответственно, продвигаемся вперед. Вот,
[05:58.520 --> 06:02.000]  как только нашли элемент меньший, обновляем индекс минимального элемента. То есть если очередной
[06:02.000 --> 06:06.320]  элемент g меньше, чем минимальный элемент, говорим, что минимальный элемент находится в позиции g.
[06:06.320 --> 06:11.960]  Все, после внутреннего цикла у нас IDXmin указывает на минимальный элемент в не отсортированной части,
[06:11.960 --> 06:16.800]  согласны? Ну все, остается только взять этот самый минимальный элемент, в данном случае это тройка,
[06:16.800 --> 06:26.880]  и обменять с элементом, который стоит вот не на своем месте. Нормально? Так, ну тут соответственно есть
[06:26.880 --> 06:35.440]  некоторая задачка, точнее три задачки. Вот, то есть расставить пропуски. До каких пор, то есть какой у нас
[06:35.440 --> 06:41.360]  концевой элемент для этого индекса? То есть мы идем по i, с нулевого элемента по какой, и позже мы идем
[06:41.360 --> 06:44.800]  с i плюс 1 элемента по какой элемент? То есть что там нужно расставить вместо многоточий?
[06:44.800 --> 06:57.320]  Так, значит есть два варианта, я слышу, n-1 и n-2. Кто за n-1?
[06:57.320 --> 07:10.840]  Окей, кто за n-2? Хорошо, обосновывать, почему n-2? Да, смотрите, действительно, мы идем, то есть
[07:10.840 --> 07:15.040]  на какие места мы вставляем наши элементы? Элементы мы ставим на нулевую позицию, на первую
[07:15.040 --> 07:20.600]  позицию, вторую позицию, третью позицию, ну а вопрос в следующем. Вот, допустим, у меня есть отсортированная
[07:20.600 --> 07:27.440]  часть, состоящая из n-1 элемента, и тут стоит один элемент не отсортированный. Ну что я знаю про
[07:27.440 --> 07:32.360]  этот элемент? Да, этот элемент ни разу не был минимальным, но, соответственно, он наибольший,
[07:32.360 --> 07:38.920]  он уже стоит на своем месте, поэтому с ним ничего не надо делать, поэтому достаточно пройти по массиву
[07:38.920 --> 07:55.680]  n-2 раза. Окей, так, что дальше? Ну, точнее, до индекса n-2. По g, до каких пор мы идем индексом g?
[07:55.680 --> 08:17.720]  From i plus 1 to, до каких пор? До n-1 индекса, почему до n-1? Да, потому что мы ищем минимальный
[08:17.720 --> 08:21.080]  элемент, ну и минимальный элемент, в принципе, может находиться в любой позиции, да, то есть он
[08:21.080 --> 08:24.560]  может находиться как здесь, так здесь, так и здесь, то есть самый последний элемент мы обязаны тоже
[08:24.560 --> 08:32.440]  смотреть, поэтому последний индекс должен быть n-1. Ну и последний вопрос, который остался, вот там
[08:32.440 --> 08:41.200]  есть какая-то загадочная процедура swap. Своп значений x и y. Что делает swap? Своп просто берет
[08:41.200 --> 08:45.680]  две переменные и обменивает их значениями местами, то есть в x записано значение y, в y записано
[08:45.680 --> 08:53.760]  значение x. Как это реализовать на языке c++? Что? Встроенная функция есть, но пока мы реализуем
[08:53.760 --> 09:06.600]  все вручную. А плюс равно b? А плюс равно b? А если мы, простите, сортируем строки? Да, но обмен
[09:06.600 --> 09:12.000]  классически пишется с помощью использования третьей переменной, мы во временную переменную сохраняем
[09:12.000 --> 09:18.440]  значение x, вот, в x записываем значение y и в y записываем значение временной перемены. Ну, давайте
[09:18.440 --> 09:23.600]  как это выглядит, вот есть x, в ней есть, допустим, значение 0, есть y, в нем значение единица, вот,
[09:24.580 --> 09:29.240]  записываем временная, есть временная переменная. Во временную переменную записываем значение 0,
[09:29.240 --> 09:38.920]  вот, дальше в x записываем значение y, единица, и в y записываем значение временной переменной
[09:38.920 --> 10:07.920]  обменной отсюда. Вот таким вот образом осуществили обмен, все, ну окей, окей, да, ну это понятно, это псевдокод, мы тут не вдаваемся в детали в t++, вам, кажется, на одной лекции говорили, что мы используем псевдокод, но просто для сокращения записей, и так далее.
[10:07.920 --> 10:20.920]  Так, нормально? Ну и давайте поговорим про время работы, про время работы этой сортировки, почему эта сортировка называется квадратичной.
[10:20.920 --> 10:26.920]  Ну, соответственно, как правило, когда мы говорим про алгоритм, мы рассматриваем худшие случаи, потому что в контестах встречаются именно худшие случаи.
[10:27.920 --> 10:37.920]  Соответственно, что мы делаем? Ну, смотрите, на самом деле все очень просто. Мы для каждой позиции, для каждой позиции, ищем минимальный элемент из оставшихся части.
[10:37.920 --> 10:45.920]  То есть, когда мы ищем минимальный элемент, когда мы ищем минимальный элемент, мы выбираем этот минимальный элемент среди всего доступного нам массива.
[10:45.920 --> 10:51.920]  То есть, по сути, мы делаем n шагов, чтобы найти самый минимальный элемент.
[10:51.920 --> 10:57.920]  После того, как мы вставили самый минимальный элемент, мы теперь ищем следующий по минимальности элемент в оставшейся части массива.
[10:57.920 --> 11:03.920]  Оставшаяся часть массива состоит из n-1 элемента. Согласны?
[11:03.920 --> 11:10.920]  После того, как мы вставили второй элемент, у нас остался массив размера n-2, среди которых мы снова ищем минимальный элемент.
[11:11.920 --> 11:15.920]  Ну, и так далее.
[11:15.920 --> 11:19.920]  Почему равна сумма арифитической прогрессии?
[11:19.920 --> 11:25.920]  Ну, типа n на n-1 пополам. Ну, на самом деле, можно просто сказать, что это t от n-2.
[11:25.920 --> 11:29.920]  С точности до константы эта штука пропорциональна.
[11:29.920 --> 11:31.920]  Эта штука пропорциональна n-2.
[11:31.920 --> 11:38.920]  Ну, то есть порядок роста вот этой вот функции, которая стоит слева, это порядка n-2. Согласны?
[11:38.920 --> 11:44.920]  Все. То есть как бы минимальное количество операций, которые мы потратим в данной сортировке, равно n-2.
[11:44.920 --> 11:48.920]  Ну и, собственно, максимальное количество операций тоже пропорционально n-2.
[11:48.920 --> 11:54.920]  В целом, с этой сортировкой, наверное, все. Понятно? Отлично.
[11:54.920 --> 11:57.920]  Ну, давайте теперь поговорим про другой вид сортировки.
[11:57.920 --> 12:00.920]  Соответственно, все сортировки довольно простые.
[12:00.920 --> 12:07.920]  Давайте оговоримся так, что любая сортировка в лучшем случае работает за утверждение математическое.
[12:07.920 --> 12:09.920]  Любая сортировка в лучшем случае работает за n.
[12:09.920 --> 12:13.920]  Доказательства. Давайте пройдемся по массиву. Если он уже отсортирован, то закончим работу.
[12:13.920 --> 12:18.920]  Ну, такие простые случаи мы не рассмотрим, мы все-таки рассмотрим вот именно вот саму суть, да, саму мягкую алгоритму.
[12:18.920 --> 12:24.920]  Окей? Нормально? Вот. Окей.
[12:24.920 --> 12:31.920]  Так. Следующий алгоритм – сортировка вставками.
[12:31.920 --> 12:34.920]  Ну, давайте традиционно обсудим идею.
[12:34.920 --> 12:40.920]  Так. Вот идея теперь такая же, как я вот пытался объяснять до этого.
[12:40.920 --> 12:44.920]  Вот. Давайте побольше.
[12:49.920 --> 12:56.920]  Так. Ну, допустим, 4, 2, 3, 1, 5.
[12:56.920 --> 13:01.920]  Значит, снова, как и в предыдущем алгоритме, мысленно разделим массив на две части.
[13:01.920 --> 13:04.920]  Хороший и плохой. То есть отсортированный и не отсортированный.
[13:04.920 --> 13:06.920]  При этом мы начнем вот с такой вот.
[13:06.920 --> 13:12.920]  Значит, эта часть уже отсортирована, эта часть не отсортирована.
[13:12.920 --> 13:15.920]  Так. Что мы будем делать?
[13:15.920 --> 13:18.920]  Давайте возьмем первый элемент из не отсортированной части.
[13:18.920 --> 13:21.920]  Вот этой.
[13:21.920 --> 13:24.920]  И вставим его в отсортированную часть на свое место.
[13:24.920 --> 13:27.920]  Вот, допустим, у меня есть какая-токої-то отсортированная часть.
[13:27.920 --> 13:34.120]  есть какая-то неотсортированная часть, я взял элемент x, ищу на каком месте он должен стать,
[13:34.120 --> 13:39.600]  и вставляю его на это место. Тем самым у меня отсортированная часть увеличивается,
[13:39.600 --> 13:44.360]  неотсортированная часть уменьшается. Согласны? Вот такая вот...
[13:44.360 --> 13:55.240]  Давайте на примере... Давайте приведем пример. Вообще говоря, найти его место довольно-таки
[13:55.240 --> 14:00.080]  просто. Давайте сначала на абстрактном примере, потом на конкретном. Вот у меня есть элемент x,
[14:00.080 --> 14:07.200]  и есть элемент, который стоит перед ним. Как понять, стоит ли x уже на своем месте или нет? Да,
[14:07.200 --> 14:11.760]  сравнить этот элемент с предыдущим, согласны? Если x меньше, чем предыдущий элемент, то все плохо.
[14:11.760 --> 14:17.040]  Что нужно сделать? Нужно просто обменять его с вот этим элементом, то есть обмениваю их местами.
[14:17.040 --> 14:22.000]  Все, окей, x стал на это место. Теперь обмениваю x с предыдущим элементом. Если x стал больше,
[14:22.000 --> 14:25.320]  чем предыдущий элемент, то все нормально, я нашел x свое место. Почему? Потому что он меньше,
[14:25.320 --> 14:32.240]  чем те, которые идут за ним, и больше, чем те, которые идут слева. Согласны? Но если он меньше,
[14:32.240 --> 14:41.200]  чем предыдущий, то снова обмениваю с ним и так далее. Давайте на примере. Давайте тут напишу 1,
[14:41.200 --> 14:52.640]  4 и 5, а тут стоят элементы 3 и 2. Вот это уже отсортированная часть, а это не отсортированная
[14:52.640 --> 15:01.640]  часть. Я пытаюсь сделать 3 и вставить его в нужную позицию, в отсортированную часть. Давайте
[15:02.000 --> 15:13.600]  вспомним 9, 0, meta-к judging. Обменилась 5, 4 и 3, поэтому проставляем дажеün't cosine.
[15:13.600 --> 15:21.440]  Смотрите, мы на 3 и et. И pike appears. 834. Трое asynchronous Monosizada.
[15:21.440 --> 15:29.020]  Вот fuck happened. videotape you can't even read it.
[15:29.020 --> 15:35.020]  Все, смотрите, вот тут у меня все элементы обязательно меньше тройки, а тут все элементы гарантированно больше тройки.
[15:35.020 --> 15:39.020]  Ну все, тройка встала на свое место. Понятно?
[15:39.020 --> 15:44.020]  Мы обязательно применим, но потом.
[15:44.020 --> 15:49.020]  Да, тут очень хорошо, что вы видите сразу, что тут есть место для улучшений, то есть действительно можно применить бинпоиск.
[15:49.020 --> 15:54.020]  Правда, принципиально мало что изменится, но про это будет.
[15:54.020 --> 15:59.020]  Пока основной алгоритм понятен, да, что мы делаем?
[15:59.020 --> 16:03.020]  Ну вот, собственно, в каждом момент времени массив определенной части, отсортированную и не отсортированную,
[16:03.020 --> 16:08.020]  возьмем первый элемент из не отсортированной части и вставим его в отсортированную.
[16:08.020 --> 16:12.020]  Соответственно, псевдокод тоже выглядит очень просто.
[16:12.020 --> 16:15.020]  Ну, собственно, ровно то, о чем мы и говорили.
[16:15.020 --> 16:20.020]  То есть проходимся по индексам И с первого по N-1, почему с первого?
[16:20.020 --> 16:25.020]  Потому что любой элемент уже гарантированно стоит, грубо говоря, один элемент уже составляет отсортированный нормальный массив.
[16:25.020 --> 16:31.020]  Все, поэтому берем первый элемент, пытаемся его вставить в массив из одного элемента, который идет слева.
[16:31.020 --> 16:38.020]  Заводим счетчик G, G будет хранить себе элемент, с которым мы сравниваем наш текущий элемент.
[16:38.020 --> 16:43.020]  Все, и говорим, что пока мы не вышли за границу массива, то есть пока G больше 0, больше либо равно 0,
[16:43.020 --> 16:54.020]  и пока G, пока предыдущий элемент больше, чем текущий элемент, мы обмениваем их местами.
[16:54.020 --> 16:57.020]  Все, обменяли их местами, G уменьшили на единицу.
[16:57.020 --> 17:02.020]  Ну и так далее, продолжаем до тех пор, пока в цикле условия выполняются. Понятно?
[17:02.020 --> 17:05.020]  Нормально?
[17:05.020 --> 17:09.020]  Так, окей.
[17:09.020 --> 17:14.020]  Ну, примеры, соответственно, на досуге. Вспорить, мы вроде как примеры забрали.
[17:14.020 --> 17:17.020]  Достаточно? Все, супер.
[17:17.020 --> 17:21.020]  Так, давайте снова поговорим про asymptotic. Тут, на самом деле, все довольно-таки просто.
[17:21.020 --> 17:25.020]  Давайте снова рассмотрим какой-нибудь худший случай.
[17:25.020 --> 17:31.020]  Чему тут равен худший случай? Ну, смотрите.
[17:31.020 --> 17:34.020]  Вот, допустим, у меня какая-то такая ситуация.
[17:34.020 --> 17:41.020]  У меня есть начальный кусок размера i и неотсортированный кусок размера n-i.
[17:41.020 --> 17:45.020]  И есть элемент x. Соответственно, что я делаю?
[17:45.020 --> 17:51.020]  Я беру этот элемент x и обмениваю с предыдущими так, чтобы он стал на свое место.
[17:51.020 --> 17:56.020]  Сколько шагов в худшем случае мне придется сделать для x?
[17:56.020 --> 18:01.020]  И да, почему? Потому что в худшем случае x меньше, чем все элементы отсюда.
[18:01.020 --> 18:04.020]  Поэтому, соответственно, мне придется его поменять местами с этим элементом,
[18:04.020 --> 18:06.020]  с этим элементом, с этим, с этим, с этим и так далее.
[18:06.020 --> 18:12.020]  То есть в худшем случае вот в такой ситуации я сделаю, ну давайте так, θ от i шагов.
[18:12.020 --> 18:17.020]  Шагов в худшем случае. Вот.
[18:17.020 --> 18:20.020]  θ от i.
[18:20.020 --> 18:22.020]  Ну и давайте все просуммируем.
[18:22.020 --> 18:29.020]  Соответственно, в начальном этапе, то есть у меня i идет от единицы до n-1.
[18:29.020 --> 18:32.020]  Ну и, соответственно, давайте я просто просуммирую.
[18:32.020 --> 18:36.020]  1, то есть на первом шаге я сделаю в худшем случае 1 шаг,
[18:36.020 --> 18:39.020]  на втором шаге сделаю 2 шага, на третьем 3.
[18:39.020 --> 18:42.020]  Ну плюс и так далее. Плюс n-1.
[18:42.020 --> 18:47.020]  Ну, соответственно, не буду тянуть, просто это у большое, ну, θ от n квадрата.
[18:47.020 --> 18:51.020]  Ну опять же, сумма арифитической прогрессии там от 1 до n-1 или до n,
[18:51.020 --> 18:54.020]  неважно, все равно в симптотике получается n квадрат.
[18:54.020 --> 18:58.020]  Это понятно. Ну, про симптотики, я думаю, уже поговорили достаточно.
[18:58.020 --> 19:00.020]  Окей.
[19:00.020 --> 19:05.020]  Значит, это что касается худшего случая.
[19:05.020 --> 19:07.020]  Вот.
[19:07.020 --> 19:10.020]  Кажется, на первой лекции вы должны были еще говорить,
[19:10.020 --> 19:13.020]  ну или там на первой, на второй вы должны были говорить еще про среднее время, да?
[19:13.020 --> 19:16.020]  Вот. Говорили же?
[19:16.020 --> 19:20.020]  Вот. Давайте на примере сортировки вставками
[19:23.020 --> 19:27.020]  рассмотрим время работы в среднем.
[19:27.020 --> 19:30.020]  Так.
[19:31.020 --> 19:35.020]  Смотрите, в чем тут идея.
[19:35.020 --> 19:38.020]  Идея заключается в следующем.
[19:41.020 --> 19:44.020]  Значит, допустим, нам данный не худший случай,
[19:44.020 --> 19:47.020]  допустим, наши данные приходят просто из случайного распределения.
[19:47.020 --> 19:50.020]  Из случайного распределения на всех массивах.
[19:50.020 --> 19:55.020]  Ну, допустим, массив просто каким-то образом равновероятно перемешан внутри себя.
[19:55.020 --> 20:00.020]  Понятно дело, что если массив как-то равновероятно перемешан внутри себя.
[20:01.020 --> 20:04.020]  Вот есть элемент x.
[20:04.020 --> 20:07.020]  И тут всего и элементов.
[20:07.020 --> 20:10.020]  То возникает вполне себе резонный вопрос.
[20:10.020 --> 20:15.020]  А на какое место, с какой вероятностью может стать элемент x?
[20:15.020 --> 20:18.020]  Ну, смотрите, если массив перемешан равновероятно,
[20:18.020 --> 20:22.020]  то X равновероятно может стать как на максимальное место,
[20:22.020 --> 20:26.500]  как на максимальное место, так и на второе место, на третье, четвертое и так далее.
[20:26.500 --> 20:28.140]  Согласны, да?
[20:28.140 --> 20:31.900]  То есть если у меня нет никаких априорных знаний о том, как устроен мне массив,
[20:31.900 --> 20:34.580]  то если я заранее не знаю в принципе про устройство массива,
[20:34.580 --> 20:37.900]  то в принципе элемент x может стать как на первое место отсортированного массива,
[20:37.900 --> 20:39.180]  на второе, на третье и так далее.
[20:39.180 --> 20:41.780]  И при этом все возможности равновероятны.
[20:41.780 --> 20:44.380]  Окей?
[20:44.380 --> 20:51.060]  Тогда что я могу сказать?
[20:51.100 --> 20:53.820]  Я могу сказать следующее.
[20:53.820 --> 20:54.820]  Что?
[20:54.820 --> 21:07.540]  На и-том шаге среднее время работы...
[21:07.540 --> 21:09.420]  Ну, что значит среднее?
[21:09.420 --> 21:13.620]  Давайте так, чисто с обыденной точки зрения, что значит среднее.
[21:13.620 --> 21:17.300]  Ну, допустим, я провожу эксперимент, сколько в среде у меня работает алгоритм.
[21:17.300 --> 21:18.340]  Что я для этого делаю?
[21:18.420 --> 21:22.420]  Я беру мой алгоритм и соответственно, как-то его случайно перемешиваю,
[21:22.420 --> 21:24.660]  запускаю мой алгоритм, измеряю время,
[21:24.660 --> 21:28.100]  потом снова как-то его случайно перемешиваю, снова сортирую, измеряю время
[21:28.100 --> 21:28.700]  и так далее.
[21:28.700 --> 21:31.500]  У меня получается некоторая выборка, некоторый набор значений.
[21:31.500 --> 21:34.700]  Дальше я просто-напросто суммирую все эти значения и делю на количество запусков.
[21:34.700 --> 21:36.860]  Это. Oppose есть мое среднее время. Согласны?
[21:36.860 --> 21:38.500]  То есть сколько в среднем?
[21:39.140 --> 21:41.060]  То есть это то же самое как с броском кубика.
[21:41.060 --> 21:42.740]  Я бросаю кубик, он выпадает двойкой.
[21:42.740 --> 21:44.260]  Бросаю кубик, выпадает четверть и так далее.
[21:44.260 --> 21:46.460]  Я складываю все значения кубиков и считаю,
[21:46.460 --> 21:52.780]  какое значение в среднем не выпадало. Понятно? Тут тоже самое, только с числом шагов.
[21:52.780 --> 22:01.040]  Так, ну смотрите, элемент x может стать на одну из следующих позиций. Он может стать на
[22:01.040 --> 22:10.260]  позицию под номером 0, а он может стать на позицию под номером 1, 2, 3, ну и так далее и. Согласны?
[22:10.260 --> 22:30.220]  Вот. Соответственно, при этом что я получаю? Так, возможная позиция. Теперь, количество действий
[22:30.220 --> 22:39.380]  с x. Если x может стать на любую позицию 1, 2, 3, какое количество действий мне для этого нужно
[22:39.380 --> 22:44.700]  будет выполнить? Смотрите, чтобы х стал на нулевую позицию, мне нужно выполнить, ну, примерно,
[22:44.700 --> 22:49.560]  и действий, согласны? Чтобы х стал на первую позицию, мне нужно выполнить примерно и-1
[22:49.560 --> 22:55.040]  действие. Чтобы х стал на вторую позицию, мне нужно выполнить и-2 действие. Ну почему?具ить
[22:55.040 --> 23:05.160]  количество обменов. Согласны? Нормально? Всё. Ну и так далее и, до единицы. Вот, а теперь смотрите,
[23:05.160 --> 23:07.980]  Скажите, с какой вероятностью у меня х станет в нулевую позицию
[23:07.980 --> 23:10.180]  в первую позицию, во вторую позицию, в третью и так далее?
[23:10.200 --> 23:14.180]  Какая вероятность станет в третью позицию?
[23:14.180 --> 23:15.180]  1por I OuiSieGl 감사합니다.
[23:15.180 --> 23:16.420]  1pres e1i per plus 1 согласны?
[23:16.420 --> 23:20.220]  В всего позиции доступных у меня а и плюс 1向 каждая позиция равна вероятно.
[23:20.600 --> 23:21.700]  Что это означает?
[23:21.800 --> 23:22.360]  Это означает, что
[23:22.360 --> 23:24.460]  с какой вероятностью я сделаю и действий.
[23:26.760 --> 23:29.160]  с вероятностью 1 по u и плюс 1
[23:29.480 --> 23:34.620]  с той вероятностью я сделаю и минус одно действие тоже с вероятностью 1 на и плюс 1
[23:35.160 --> 23:54.160]  и так далее. Что это означает? Это означает, что среднее количество действий на
[23:54.160 --> 24:08.640]  этом шаге равно следующему. 1 на 1 плюс i и плюс 1 на 1 плюс i умножить на
[24:08.640 --> 24:21.760]  и так далее, и плюс 1 на 1 плюс i умножить на ноль. Согласны? То есть и действие я выполняю с вероятностью
[24:21.760 --> 24:37.040]  1 на 1 плюс i. Давайте и плюс 1 везде писать. Да-да-да. Это количество элементов слева. Вот и. Вот.
[24:37.040 --> 24:41.880]  То есть и действие я выполняю с вероятностью и плюс 1, и плюс одно действие я выполняю с вероятностью
[24:41.880 --> 24:47.040]  и плюс с вероятностью 1 на и плюс 1, ну и так далее. Ну согласны ли вы, что с помощью, что вот так я
[24:47.040 --> 25:07.880]  посчитаю краски среднее число, да? Нормально? Вот. Ну и что получится? Так. Не-не-не. То есть я
[25:07.880 --> 25:16.760]  выполняю и и шагов, либо и минус один шаг, либо ноль шагов. Да. Да, у нас и плюс один вариант,
[25:16.760 --> 25:21.800]  но скажем, смотрите, чтобы попасть в конец, мне нужно и шагов. Чтобы попасть на первую позицию,
[25:21.800 --> 25:25.880]  мне нужно и минус один шаг. И так далее. Чтобы попасть в конец, ну мне, по сути, ничего не
[25:25.880 --> 25:41.280]  нужно делать. Ноль шагов. Да. Смотрите, тут давайте так, два момента. По порядку. Вот есть такая
[25:41.280 --> 25:48.560]  конфигурация. Массив абсолютно случайен. Рандомный. Вот. Ну равный, причем все элементы могут
[25:48.560 --> 25:54.640]  стоять на всех местах равновероятно. Я вас спрашиваю, вот х. С какой вероятностью он станет в третью
[25:54.640 --> 26:05.400]  позицию? Ну один на и плюс один. Всего вариантов и плюс один. Соответственно, он станет в позицию
[26:05.400 --> 26:10.160]  номер 30, с вероятностью один на и плюс один. Так? Так, теперь, если х должен встать в третью
[26:10.160 --> 26:17.920]  позицию, то сколько действий я при этом должен сделать? Ну, кажется, и минус три, да? Ну все,
[26:17.920 --> 26:22.080]  вот тут я как раз-таки считаю, что чтобы встать в нулевую позицию, мне нужно и действий. Это
[26:22.080 --> 26:25.600]  происходит с вероятностью и плюс один. Чтобы встать в первую позицию, мне нужно и минус одно
[26:25.600 --> 26:29.680]  действие. Это происходит с вероятностью тоже и плюс один. Ну и так далее. Я суммирую,
[26:29.680 --> 26:38.880]  все, ну происходит такое усреднение. Согласны? Нормально? Все, ну и что получается? У меня есть
[26:38.880 --> 26:49.360]  общий множитель и плюс один, один на и плюс один. Вот. И, соответственно, сумма по и дает мне и на
[26:49.360 --> 27:01.720]  и плюс один пополам равно и пополам. Вот. Ну кто бы сомневался, казалось бы, да? То есть в среднем
[27:01.720 --> 27:08.720]  на и-том шаге я делаю и пополам действий, да? Ну а теперь давайте просто просуммируем по всем
[27:08.720 --> 27:17.080]  шагам. Всего у меня шагов и от единицы до n минус один и пополам. Ну, кажется, ничего не
[27:17.080 --> 27:22.760]  меняется. Это есть все еще от n квадрат. Да? Ну, одна вторая, это как константа, ее там на нее
[27:22.760 --> 27:26.920]  можно забить. Дальше, если я просуммирую все и от единицы до n минус первой, то я получу как раз-таки
[27:26.920 --> 27:37.720]  порядка n квадрат. Н минус один на n пополам. Согласны? Да. Согласны? Все. Ну то есть в целом неважно,
[27:37.720 --> 27:44.560]  как вы оцениваете сортировку вставками, там неважно в худшем случае или в среднем, все равно
[27:44.560 --> 27:48.320]  получается квадратическая сортировка. То есть даже с помощью рандомизации у вас ничего не
[27:48.320 --> 27:52.520]  получится. Почему этот пример? Ну, это пример, во-первых, для того, чтобы продемонстрировать,
[27:52.520 --> 27:57.520]  как устроена оценка работы в среднем. А во-вторых, ну это, собственно,
[27:57.520 --> 28:01.560]  некоторое такое назидание на то, что на самом деле у нас в будущем, по крайней мере, кажется,
[28:01.560 --> 28:05.280]  на следующей лекции будет сортировка, в которой мы будем что-то рандомизировать,
[28:05.280 --> 28:08.760]  в которой мы будем случайно перемешивать элементы массива, и от этого будет становиться только
[28:08.760 --> 28:13.320]  лучше. Вот тут, к сожалению, это не так. Но при этом существуют сортировки и существуют алгоритмы,
[28:13.320 --> 28:19.000]  которым будем активно пользоваться в нашем курсе, в котором перемешивание данных дает очень
[28:19.000 --> 28:24.640]  хороший результат. Вот. Это первый момент. Второй момент, который хочется отметить, состоит в следующем.
[28:24.640 --> 28:32.080]  Ну, вот смотрите, вот про оценку времени в среднем. Давайте допустим, вот что мы оценили что-то в
[28:32.080 --> 28:36.680]  среднем. Вот отметили, что в среднем, если у меня данные случайные, то все работает довольно-таки
[28:36.680 --> 28:40.560]  быстро. Вот представьте себе, что вот я провел какой-то анализ и получил бы, что сортировка
[28:40.560 --> 28:48.840]  вставками работает за какое-то время, которое быстрее, чем взаимодействие. Вопрос, почему это
[28:48.840 --> 28:58.760]  не очень применимый на практике результат. Почему эта информация в целом мне особо ничего хорошего не дает?
[28:58.760 --> 29:10.720]  Вот смотрите, утверждение такое, допустим, абстрактное утверждение. Если данные случайны,
[29:15.720 --> 29:17.120]  ну, случайны и равновероятны,
[29:17.120 --> 29:21.840]  и равновероятны,
[29:21.920 --> 29:36.080]  то, допустим, время работы на входе размера n равно theta от n. Вот. За линейное время все работает.
[29:36.080 --> 29:42.240]  Почему на самом деле во многих задачах, во многих ситуациях я могу этот результат просто-напросто,
[29:42.240 --> 29:47.880]  не знаю, не принимать во внимание. Это очень слабый результат. Почему?
[29:47.920 --> 29:55.320]  Ну, в каком плане нет ограничений верхнего?
[29:55.320 --> 30:01.440]  Если мы пишем неконтест. Ну, смотрите, хорошо, давайте так. Вы пишете неконтест,
[30:01.440 --> 30:05.680]  вы приходите там, не знаю, на работу. Вот. И вы такие, я проанализировал сортировку,
[30:05.680 --> 30:13.320]  и если к нам приходят случайные данные, то там все за линию сортируется. Почему это плохо?
[30:13.320 --> 30:21.320]  Ну, не то что плохо, а почему это особо никого профита не дает? Да, а кто вам вообще,
[30:21.320 --> 30:25.320]  говоря, сказал, что данные случайны? Тут мы как бы сказали, тут мы предположили,
[30:25.320 --> 30:29.280]  что ну, пусть у меня данные как-то случайны, какие-то случайны и так далее. А кто вам
[30:29.280 --> 30:35.720]  гарантирует, что в реальности вам будут подсовывать случайные данные? В контесте явно не случайные
[30:35.720 --> 30:40.520]  данные. Я вам спойлер так вот кину. В контесте явно подобраны самые худшие, самые мерзкие ситуации.
[30:40.520 --> 30:45.360]  Вот. Поэтому то, что ваша сортировка работает в среднем за линию, нам вообще, говоря,
[30:45.360 --> 30:49.240]  плевать. Потому что мы вам подсовываем худшие случаи, у вас все будет работать за квадрат. Вот.
[30:49.240 --> 30:54.360]  То же самое касается, скажем, всяких реальных алгоритмов. То есть как бы в большинстве ситуаций
[30:54.360 --> 30:58.280]  закладываться на то, что у вас будет какой-то случайный средний случай, ну, как правило,
[30:58.280 --> 31:03.520]  нельзя. Опять же, есть куча, допустим, та же самая криптография, допустим, есть какие-то
[31:03.520 --> 31:07.800]  злоумышленники, которые нарочно захотят посадить ваш сайт, повесить ваш сервис и так далее,
[31:07.880 --> 31:11.640]  будут специально стараться подсовывать вам худшие данные. Вот. Если вам подсовывают худшие
[31:11.640 --> 31:15.160]  данные, ну, специально подобранные, то, соответственно, вот это вот все утверждение просто
[31:15.160 --> 31:20.040]  нам идёт лесом. Вот. То есть, на самом деле, рандомизация по данным имеет очень-очень узкое
[31:20.040 --> 31:26.320]  применение. Вот. И когда мы будем говорить про рандомизированный алгоритм, и мы на самом
[31:26.320 --> 31:30.720]  деле будем иметь в виду не рандомизацию по данным, а рандомизацию самого алгоритма. То есть тот
[31:30.720 --> 31:34.240]  случай, когда мы с вами получим какую-то рандомизацию. Да. То есть, вот если бы утверждение
[31:34.240 --> 31:39.720]  изучал не так, давайте я его перепишу. Вот какое утверждение было бы хорошим. А если не данные,
[31:39.720 --> 31:54.720]  если случайно, а если мы случайно перемешиваем данные, перемешиваем данные, причем равновероятно,
[31:54.720 --> 31:59.320]  то время такое. Вот это утверждение уже классное. Почему? Потому что это уже не зависит от входных
[31:59.320 --> 32:03.120]  данных, согласны? Нам приходят входные данные, и мы сами как угодно можем их перемешать, то есть
[32:03.120 --> 32:07.520]  случайным образом. Вот тут мы уже можем гарантировать, что данные уже перемешаны
[32:07.520 --> 32:13.720]  абсолютно случайно. И тут уже этот анализ может нам помочь. Согласны? Поняли, что я сказал?
[32:13.720 --> 32:28.120]  Да, это был спойлер к быстростатировке. Действительно, у быстростатировки худший случай
[32:28.120 --> 32:36.120]  н квадрат. Но как раз-таки для быстростатировки вот это утверждение верно, что если вы возьмете
[32:36.120 --> 32:41.480]  ваш массив и случайно вам пришли данные и сказали, что пофиг, давайте просто перемешаем данные,
[32:41.480 --> 32:48.560]  и потом запустите сортировку, то в среднем вы получите n луган. За линейное время, кажется,
[32:48.560 --> 32:52.280]  можно перемешать массив. Вы за линейное время перемешиваете массив, а потом за n луган сортируете.
[32:53.280 --> 33:09.280]  Давайте поговорим про небольшое улучшение сортировки вставками,
[33:09.280 --> 33:14.280]  которые на самом деле уже упоминали. Смотрите, на самом деле уже кто-то заметил, что действительно
[33:14.280 --> 33:20.600]  что мы делаем. Мы берем очередной элемент x и пытаемся найти его позицию в отсортированном массиве,
[33:20.600 --> 33:27.600]  в отсортированном массиве. Смотрите, что кажется, что найти нужное место элемента в отсортированном
[33:27.600 --> 33:34.880]  массиве можно довольно-таки быстро, используя бинарный поиск. Согласны? Смотрите, мы до этого,
[33:34.880 --> 33:39.640]  все время до этого, искали нужную позицию для элемента x за линейное время. То есть мы просто
[33:39.640 --> 33:43.240]  проходили сравнение с последним, предпоследним и так далее и так далее. Казалось бы, это можно сделать
[33:43.240 --> 33:47.360]  быстро, просто нам просто бинарным поиском. Ну и действительно так и есть. С помощью бинарного поиска
[33:47.360 --> 33:53.200]  можно найти самый первый элемент, который x. Соответственно, элемент x должен обязательно стоять
[33:53.200 --> 34:00.440]  после этого элемента. То есть в действительности от химологии мы можем немного ускорить алгоритм.
[34:00.440 --> 34:04.840]  Но, к сожалению, на симптотику особо это не повлияет. Почему? Потому что, смотрите, допустим, нам
[34:04.840 --> 34:09.600]  откуда-то сверху известна информация о том, что x на самом деле должен стоять вот в этом месте.
[34:09.600 --> 34:13.920]  Причем даже не с помощью бинарного поиска, а просто озарение алгоритма пришло, что x должен
[34:14.560 --> 34:19.800]  стать вот сюда. Что можем сделать с этой информацией? Можем мы как-то принципиально ускорить алгоритм,
[34:19.800 --> 34:22.980]  можем всехNIE как-то принципиально ускорить ставку элемента x в вот это место.
[34:22.980 --> 34:29.200]  Ну кажется, что нет. Почему? Потому что, чтобы се вставить элемент сюда, что нужноці делать?
[34:29.200 --> 34:33.580]  Нужно, чтобы вот тут появилось некоторое свободное место, согласен? А чтоб тут появилось
[34:33.580 --> 34:37.720]  свободное место, то что нужно делать? Нужно все вот эти элементы все равно подвинуть на одну единицу
[34:37.720 --> 34:43.120]  вправо, то есть элемент x все равно придется как бы обменивать со всеми предыдущими элементами и
[34:43.120 --> 34:47.500]  вставлять в нужную позицию. Согласны? То есть сама вставка элемента x в нужное
[34:47.500 --> 34:52.000]  место сама по себе как минимум занимает линейное время, ну в худшем случае. Вот.
[34:52.000 --> 34:56.040]  Но при этом с этим ничего, к сожалению, нельзя сделать, поэтому
[34:56.040 --> 34:59.640]  асимптоидская н квадрат действительно сохраняется. Но зато мы сэкономим на число
[34:59.640 --> 35:02.200]  сравнений. То есть в предыдущем алгоритме, что мы делали? Мы сравнивали
[35:02.200 --> 35:05.640]  элементы и обменивали. А тут мы всего лишь обмениваем элементы, но при этом число
[35:05.640 --> 35:09.720]  сравнений уменьшается с линейного долога рифмического. Ну такой вопрос,
[35:09.720 --> 35:17.600]  небольшая оптимизация сортировки вставками. Окей? Нормально? Понятно? Хорошо.
[35:17.600 --> 35:23.720]  Так, ну и последнее на сегодня сортировка. Это сортировка пузырьком. Ну снова давайте
[35:23.720 --> 35:28.000]  начнем с идеи. Так, мы хотели поговорить про сортировку пузырьком. Давайте поговорим.
[35:28.000 --> 35:36.080]  А как обосновать название данной сортировки? Ну снова, мне дан какой-то
[35:36.080 --> 35:46.800]  произвольный массив. Ну, допустим, 3, 5, 2, 1, 4. Что я буду делать? Давайте я буду
[35:46.800 --> 35:57.320]  делать каждый раз, ну снова, я N-1 раз, буду делать максимально тупые действия,
[35:57.320 --> 36:03.680]  простите. Давайте я просто-напросто буду идти по массиву, сравниваю два последних
[36:03.680 --> 36:06.920]  элемента друг с другом. И если они друг относительно друга стоят не на правильных
[36:06.920 --> 36:11.600]  местах, буду обменивать их друг с другом. Ну, смотрите, сравниваю 3 и 5. 3 и 5 относительно друг
[36:11.600 --> 36:16.400]  друга стоят на нужном месте. Окей? Все. Идем дальше, сравним вот эти элементы. 5 и 2
[36:16.400 --> 36:21.960]  друг относительно друга стоят не на своем месте. Поэтому я пятерку меняю местами с двойкой.
[36:21.960 --> 36:26.400]  Окей, перехожу к следующей паре. Сравниваю пятерку и единицу. Пятерки и единицы стоят
[36:26.400 --> 36:30.720]  не на своих местах, ну друг относительно друга, обмениваю местами. Сравниваю пятерку и четверку,
[36:30.720 --> 36:40.760]  обмениваю местами, получаю 4 и 5. Окей, завершил на этом работу. Дальше ничего нового,
[36:40.760 --> 36:45.280]  делаю абсолютно то же самое. Теперь сравниваю, ну снова, иду по порядку и сравниваю два последних
[36:45.280 --> 36:49.840]  элемента. Сравниваю тройку и двойку, они стоят не на своих местах, меняю двойку и тройку местами.
[36:49.840 --> 36:56.160]  Ну и так далее. То есть алгоритм максимально простой. Просто хожу по массиву, обмениваю
[36:56.160 --> 37:00.080]  последовательные элементы местами. То есть каждый раз, каждый раз я вроде как делаю массив чуть
[37:00.080 --> 37:05.240]  лучше. В какой-то момент массив станет совсем хорошим, согласны? Вот. Вопрос, почему сортировка
[37:05.240 --> 37:10.080]  пузырьком называется сортировка пузырьком. Давайте обратим внимание на пятерку. Пятерку у меня стояло,
[37:10.080 --> 37:16.720]  по-моему, на второй позиции, вот здесь, да? Ну по-моему, да? Ну вот. И в итоге пятерка оказалась в конце.
[37:16.720 --> 37:22.520]  Смотрите, я делаю такое утверждение. Если я прохожусь вот таким вот алгоритмом, то есть последовательной
[37:22.520 --> 37:26.240]  обмениваю попарные элементы, то у меня в конце массива обязательно окажется самый большой элемент.
[37:26.240 --> 37:32.240]  Согласны ли вы, что это утверждение верно? Да, действительно. Смотрите, если максимальный элемент стоит
[37:32.240 --> 37:37.280]  тут, то при обмени с этим элементом, этот элемент выползет наверх. Дальше обмениваю эти элементы,
[37:37.280 --> 37:41.480]  снова он выползет наверх. Ну и так далее. Он выползет на самое начало. Собственно, в этом заключается
[37:41.480 --> 37:47.920]  типа поднятие пузырька с воздухом с дна воды на поверхность. То есть как бы самые большие
[37:47.920 --> 37:54.000]  элементы, они как бы всплывают наверх. Понятно? В этом аналоге. То есть вы один раз прошлись по массиву,
[37:54.000 --> 37:59.040]  у вас наибольший элемент всплыл наверх. Дальше вы снова прошлись по массиву, у вас следующий
[37:59.040 --> 38:03.520]  повреждение элемент всплыл наверх. Ну и так далее. Пока все элементы не всплывут в нужном порядке.
[38:03.520 --> 38:09.720]  Понятно? Вот и все. То есть идем по массиву от начала до конца и последовательно обмениваем
[38:09.720 --> 38:16.360]  соседние элементы, если они расположены в неправильном порядке. В итоге максимальный
[38:16.360 --> 38:22.800]  элемент всплывет пузырьком в конец массива. Ну и так далее. Вот. Собственно, код еще более
[38:22.800 --> 38:28.240]  простой. Значит, я n-1 раз, как я уже заявлял, просто-напросто прохожу по всему массиву,
[38:28.240 --> 38:36.360]  ну от 0 до n-2, и сравниваю этот элемент g-тый со следующим, с g плюс первым. Если текущий
[38:36.360 --> 38:43.640]  элемент g, давайте вот тут, элемент g, больше, чем g плюс первый элемент, то есть больше,
[38:43.640 --> 38:53.120]  чем следующий элемент. Я обменю выходистами. Все. Очень просто и понятно. Согласны? Ну все,
[38:53.120 --> 38:59.360]  что тут еще можно сказать? Кажется, что все. Вот. Ну и анализ, на самом деле, тут тоже максимально
[38:59.360 --> 39:11.720]  простой. Собственно, я делаю n-1 раз, делаю n-2 сравнения.
[39:11.720 --> 39:21.600]  Если я n-1 раз делаю n-2 сравнению, то что у меня получается? Сколько операций? Ну n-1 умножить на n-2.
[39:21.600 --> 39:35.720]  Кажется, что это O-большое от снова n-2. Ну давайте сначала говорим про это. Вот это алгоритм
[39:35.720 --> 39:41.600]  согласен, что он работает n-1 на n-2. Так, с этим согласны. Все, а вот теперь давайте, собственно,
[39:41.600 --> 39:49.320]  поговорим про улучшение сортировки пузырьком. Собственно, ну явно видно, что в этом алгоритме,
[39:49.320 --> 39:53.440]  который был представлен ранее, существует очень много, ну как очень много, просто существует
[39:53.440 --> 39:59.440]  место для улучшений. Ну, например, смотрите, мы с вами сказали, что после первой итерации алгоритма
[39:59.440 --> 40:05.440]  сортировки пузырьком у меня вот на этом месте, на последнем месте, будет максимальный элемент.
[40:05.440 --> 40:11.840]  Вопрос, имеет ли смысл тогда с ним сравнивать следующие элементы? Ну, кажется, что нет. Кажется,
[40:11.840 --> 40:15.680]  если мы точно знаем, что тут стоит максимальный элемент, то теперь производить вот такие вот
[40:15.680 --> 40:19.040]  сравнения, то есть производить последнее подсравнение нам в принципе не нужно. То есть теперь
[40:19.040 --> 40:24.080]  можем проводить на одно сравнение меньше. Теперь, после того, как мы выполнили вторую итерацию,
[40:24.080 --> 40:28.160]  то есть второй проход по массиву, мы точно знаем, что теперь у нас два элемента стоят на своих местах.
[40:28.620 --> 40:33.280]  Поэтому сравнивать с этим элементом нет никакого смысла. На каждой итерации мы
[40:33.280 --> 40:38.480]  можем сравнивать, ну с каждым разом сможем сравнивать все меньше
[40:38.480 --> 40:45.260]  и меньше количественного элементов. Согласны? Итерация это один проход по массиву.
[40:45.260 --> 40:49.360]  Я один раз прошел, пятерка 승ала в конец, теперь я, с последним элементом не сравниваться.
[40:49.360 --> 40:56.160]  Второйcorn проделал, ну, теперь я могу с предпоследним элементом не сравнивать bones.
[40:56.160 --> 41:00.160]  Если после первой итерации у нас только один наибольший ацетировок...
[41:00.160 --> 41:04.160]  Ну, потому что итерации я нумеру с нуля.
[41:04.160 --> 41:08.160]  Ну, если нулевая итерация, первая итерация, вторая ита, всего и плюс одна итерация.
[41:14.160 --> 41:17.160]  На самом деле улучшение, но опять же это улучшение, оно всего лишь затрагивает константу.
[41:17.160 --> 41:22.160]  То есть, если я раньше говорил, что у меня время работы это n-1 умножить на n-2,
[41:22.160 --> 41:24.160]  то теперь у меня что получается?
[41:24.160 --> 41:28.160]  Теперь на первой итерации я выполняю n-1 сравнение,
[41:28.160 --> 41:30.160]  потом я выполняю n-2 сравнений,
[41:30.160 --> 41:32.160]  потом n-3 сравнений,
[41:32.160 --> 41:34.160]  ну и так далее.
[41:34.160 --> 41:36.160]  И потом в конце одно сравнение.
[41:36.160 --> 41:41.160]  Ну, кажется, что это n на n-1 пополам.
[41:41.160 --> 41:45.160]  Ой, просто n на n-1 пополам.
[41:45.160 --> 41:48.160]  Ну, в общем, тут стоит n квадрат,
[41:48.160 --> 41:51.160]  а тут перед n квадрат стоит множество или 1 вторая.
[41:51.160 --> 41:53.160]  Грубо говоря, в два раза ускорил сортировку.
[41:53.160 --> 41:56.160]  Но при этом порядок роста все еще квадратический.
[41:58.160 --> 42:00.160]  Так, окей, второе улучшение.
[42:00.160 --> 42:03.160]  Второе улучшение, оно более осмысленное.
[42:03.160 --> 42:07.160]  Смотрите, вот представьте себе, что у меня есть какой-то массив,
[42:07.160 --> 42:11.160]  и я делаю очередную итерацию, очередную итерацию прохода по массиву.
[42:11.160 --> 42:14.160]  То есть сравню вот эти элементы, обмена не произошло.
[42:14.160 --> 42:16.160]  Сравню вот эти элементы, обмена не произошло.
[42:16.160 --> 42:18.160]  Вот эти, вот эти и так далее.
[42:18.160 --> 42:19.160]  Что это означает?
[42:19.160 --> 42:22.840]  että у меня ни одного обмена не произошло.
[42:22.840 --> 42:25.840]  Да, это значит, что у меня массив уже отсортирован,
[42:25.840 --> 42:28.160]  ну то есть согласись, что возможно, такая ситуация,
[42:28.160 --> 42:30.160]  что я выполнил, условно, 4 прохода по массиву,
[42:30.160 --> 42:32.160]  и массив уже стал отсортированным.
[42:32.160 --> 42:34.160]  Ну, теоретически, какое возможно.
[42:34.160 --> 42:36.160]  Если у меня это элемент уже меньше
[42:36.160 --> 42:38.160]  и этот менший, этот меньше и этот меньше,
[42:38.160 --> 42:40.160]  значит массив stepping в правильном порядке.
[42:40.160 --> 42:42.160]  Все, если у меня за все время работы алгоритма
[42:42.160 --> 42:44.160]  не произошло ни одного обмена,
[42:44.160 --> 42:48.160]  то это значит, что массив уже отсортирован и на этом можно заканчивать работу.
[42:48.160 --> 42:51.720]  на самом деле такое довольно существенное, довольно-таки существенное улучшение сортировки,
[42:51.720 --> 42:56.160]  потому что в принципе в теории вы можете завершить работу именно в тот момент,
[42:56.160 --> 43:01.680]  когда у вас собственно массив полностью отсортирован. В алгоритм уже встроена проверка
[43:01.680 --> 43:09.360]  на то, что надо заканчивать работу или нет. И как раз таки к вопросу о том, что у нас у
[43:09.360 --> 43:13.280]  сортировки может быть лучший случай, который работает за n. То есть в других сортировках нам
[43:13.280 --> 43:19.320]  бы было необходимо вручную проверять отсортирован уже массив или нет. Сортировки
[43:19.320 --> 43:24.040]  пузырьком этого делать не нужно. Если у вас не произошло ни одного обмена, то массив уже
[43:24.040 --> 43:28.680]  отсортирован, и как бы у вас в лучшем случае, когда массив уже отсортирован, вы по сути не сделаете
[43:28.680 --> 43:40.200]  практически ни одного лишнего действия. Если данные равновероятны и так давят, то все равно будет
[43:40.200 --> 43:47.400]  квазротичная. Давайте просто на пальцах попробуем понять, почему это может быть так.
[43:47.400 --> 43:53.920]  Смотрите, если у меня массив, условно, равновероятен, то что это? Просто так на пальцах,
[43:53.920 --> 43:59.880]  без доказательств особо. Вот есть массив. Раз массив равновероятен, то где у него стоит
[43:59.880 --> 44:06.640]  максимальный элемент? Да где угодно. В среднем случае он стоит где-то посередине. Я так на
[44:06.640 --> 44:09.760]  пальцах объясняю. Раз он стоит посередине, то соответственно я должен сделать как минимум
[44:09.760 --> 44:16.560]  n пополам обмен. Согласны? Все, он стал в конец. В конце стоит правильный массив, правильный
[44:16.560 --> 44:22.840]  элемент. У меня остался массив размера n-1. Где у меня стоит максимальный элемент? Ну тоже
[44:22.840 --> 44:27.280]  примерно n пополам, на самом деле он чуть-чуть всплывет наверх, но на самом деле, опять же,
[44:27.280 --> 44:33.080]  там примерно n-1 пополам. Ну и так далее, если посуммировать, то опять же получите n квадрат.
[44:33.080 --> 44:43.800]  То есть особо ничего там не меняется. Все предыдущие улучшения можно свести в один алгоритм,
[44:43.800 --> 44:52.720]  то есть мы второй цикл пожи можем идти не до n-2 элемента, а до n-1-2 элемента. Это с первым
[44:52.720 --> 44:56.120]  улучшением. А если добавляем второе улучшение, то мы просто заводим дополнительную переменную,
[44:56.120 --> 45:02.400]  в которой храним информацию о том, обменивали ли мы какой-то элемент с каким-то или нет. Если
[45:02.400 --> 45:05.560]  какой-то элемент с каким-то обменивали, то завершаем работу. Если не обменивали,
[45:05.560 --> 45:11.280]  то на этом... Да, если не обменивали, то завершаем работу. Если обменивали, то продолжаем.
[45:11.280 --> 45:26.240]  Окей? Так, есть какие-то вопросы по квадратичным сортировкам? Так, сколько у нас времени осталось?
[45:26.240 --> 45:35.680]  О, довольно много. Так, давайте тогда обсудим вот такие моменты. К бонусу мы перейдем. У нас
[45:35.680 --> 45:44.000]  есть время еще обсудить кое-какие другие моменты. Смотрите, вот мы с вами познакомились с тремя
[45:44.000 --> 45:54.160]  сортировками. Сортировка вставками, сортировка выбором, сортировка пузырьком. У вас должен возникнуть
[45:54.160 --> 46:03.680]  естественный вопрос. Какой? Да, какая круче? Что использовать? Три сортировки, и что? Каждый
[46:03.680 --> 46:08.960]  работает взаимно в квадрат, что мы используем, что использовать на практике и так далее. Давайте я
[46:08.960 --> 46:13.120]  просто поговорю про преимущество каждой сортировок. Про преимущество последней сортировки я уже все
[46:13.120 --> 46:17.640]  сказал. Про преимущество сортировки пузырьком. Там, в принципе, у нее уже по сути встроен такой
[46:17.640 --> 46:21.560]  механизм, как ранняя остановка. То есть, как только у вас массив отсортирован, вы завершаете работу,
[46:21.560 --> 46:24.760]  то есть, по сути, не делаете никаких лишних действий. Давайте сравним сортировку выбором.
[46:24.760 --> 46:49.920]  Сортировка выбором и сортировку вставками. Давайте я попробую подсветить по одному преимуществу одной
[46:49.920 --> 47:01.000]  сортировки и второй сортировки. Давайте обсудим вот такой момент. Вот смотрите, каждая сортировка,
[47:01.000 --> 47:06.120]  она по сути что делает? Каждая сортировка делает два уникальных действия. Первое действие это
[47:06.120 --> 47:10.960]  сравнение элементов. То есть, сравним один элемент со вторым элементом. А второе действие это обмена
[47:10.960 --> 47:15.960]  элементов. То есть, мы какой-то элемент обмениваем со вторым. Что мы можем сказать про количество
[47:15.960 --> 47:21.640]  сравнений одной сортировки, про количество сравнений каждой сортировки и про количество обменов
[47:21.640 --> 47:38.960]  для каждой сортировок? В первой обменов меньше. А именно, сколько обменов? Вот. Количество обменов
[47:38.960 --> 47:51.760]  н. Ну, в самом деле, что-то типа n-1, но неважно. Давайте так напишем. О большое от n. Согласны? Ну,
[47:51.760 --> 47:58.280]  почему? Потому что в сортировке выбора мы просто-напросто сравниваем элементы и ищем минимальный
[47:58.280 --> 48:02.960]  элемент. Дальше берем этот элемент и вставляем в нужное место. Все. То есть, по сути, для каждого
[48:02.960 --> 48:09.640]  элемента мы находим нужное место и вставляем сразу же туда. Все. А сколько обменов у нас
[48:09.640 --> 48:16.760]  в сортировке вставками? Ну, порядка n квадрата. Потому что напоминаю, что в сортировке вставками
[48:16.760 --> 48:21.760]  у нас есть массив x, и мы, соответственно, обмениваем его, чтобы вставить его в свое место,
[48:21.760 --> 48:26.720]  мы обмениваем последовательно с этим элементом и предыдущим. Поэтому суммарно количество обменов
[48:26.720 --> 48:32.320]  может быть квадратичным. И, собственно, в этом заключается преимущество сортировки выбором
[48:32.320 --> 48:38.040]  перед сортировкой вставками. Ну и перед любой другой сортировкой. Потому что сортировка выбором
[48:38.040 --> 48:44.360]  оптимизирует количество обменов. Ну, давайте попробуем придумать ситуацию, в которой это
[48:44.360 --> 48:48.080]  свойство нам очень хорошо поможет. В каком случае нам необходимо минимизировать количество обменов?
[48:48.080 --> 49:00.320]  Да, ну представь себе, что у меня сами переменные содержат внутри себя очень большие данные. Пока мы
[49:00.320 --> 49:03.640]  работаем только с примитивными типами, типа in, double и так далее, но в будущем мы с вами будем
[49:03.640 --> 49:09.920]  рассматривать такие типы, которые занимают много памят. Ну, например, те же самые массивы. Чтобы
[49:09.920 --> 49:14.000]  обменять два массива местами, нужно потратить много времени. Нужно скопировать один массив во
[49:14.000 --> 49:18.560]  второй, второй в первый. Ну, казалось бы, обмена довольно-таки дорогая операция на двух массивах.
[49:18.560 --> 49:23.600]  Соответственно, чтобы отсортировать грубо говоря массивы длинные, использование сортировки
[49:23.600 --> 49:28.920]  выбором хорошо тем, что он минимизирует количество обменов. То есть таких дорогих операций у нас
[49:28.920 --> 49:34.840]  будет маленьким. Ну и в целом, если обменивать два значения дорого, то сортировка выбором
[49:34.840 --> 49:48.760]  это очень хороший вариант. Понятно? Да. Давайте вспомним, как работает сортировка выбором.
[49:48.760 --> 49:55.320]  Сортировка выбором вот и так. У нас есть какой-то отсортированный массив. При этом гарантируется,
[49:55.320 --> 50:00.360]  что вот тут все элементы строго меньше, чем у меня отсортированные части. Поэтому,
[50:00.360 --> 50:05.680]  когда мы находим, вот тут мы ищем минимальный элемент. Вот, допустим, мы нашли минимальный
[50:05.680 --> 50:11.320]  элемент х. Вот тут. Что мы делаем? Мы берем этот элемент и обменяем его вот с этим, с последней. То есть мы
[50:11.320 --> 50:25.160]  вставляем его уже на конкретную позицию. Мы можем обменивать указатели, но про чем проблема указателей?
[50:25.160 --> 50:31.160]  Указатели добавляют некоторый уровень косвенности. В том смысле, что раньше вы обращались к переменной
[50:31.160 --> 50:34.840]  напрямую. А если вы работаете с указателями, то вы теперь, когда обращаетесь к переменной,
[50:34.840 --> 50:39.640]  вы обращаетесь к указателю и только потом указатель обращается к переменной. То есть при каждом
[50:39.640 --> 50:42.680]  обращении к переменной вы тратите в два раза больше времени, чем если вы обращаете к перемене
[50:42.680 --> 50:50.800]  напрямую. Ну и короче, любое обращение к переменной будет занимать два раза больше памяти. То есть
[50:50.800 --> 50:54.680]  действительно, если вы работаете просто с указателями на данные, то это хорошо тем,
[50:54.680 --> 51:00.160]  что действительно обменивание двух указателей всегда быстрое. Но при этом это добавляет вот
[51:00.160 --> 51:08.560]  эти вот проблемы, про которые я только что сказал. Вопрос. Ну да, опять же вопрос. Зависит от задач,
[51:08.560 --> 51:13.040]  которые вы решаете. То есть если вам нужно всего лишь, скажем, отсортировать данные, то есть вы
[51:13.040 --> 51:16.400]  обращаетесь к небольшому количеству элементов, но вам важно, чтобы данные были отсортированы,
[51:16.400 --> 51:21.400]  то в целом норм. А если вам нужно отсортировать данные, а потом вы там, не знаю, две недели с ними
[51:21.400 --> 51:25.080]  водитесь, с ними работаете, то как бы за это время у вас накопится гораздо больше времени,
[51:25.080 --> 51:28.880]  чем если вы там просто взяли и отсортировали нормальные данные без использования указателей.
[51:28.880 --> 51:35.880]  Ну собственно, не знаю, там такой прям сильный офф топ. Ну например, вот почему, блин, языки
[51:35.880 --> 51:41.520]  типа Python, Java и так далее, они, как правило, медленнее, чем те же программы, которые написаны
[51:41.520 --> 51:45.880]  на C и C++. Ну потому что у них как раз таки вот эта вот темантика. Потому что сами там хранятся
[51:45.880 --> 51:50.160]  не объекты, а хранятся указатели и ссылки на объекты. И, собственно, вы там при обращении каждому объекту
[51:50.160 --> 51:56.240]  тратите примерно в два раза больше времени, чем в то же самое время в C или C++. Вот. Ну это так,
[51:56.240 --> 52:08.640]  сильный офф топ. Так, есть ли еще вопросы? Окей. Так, это значит, мы поговорили про преимущество
[52:08.640 --> 52:13.080]  сортировки выбора. Давайте как-нибудь попробуем восстановить, для чего нужна сортировка вставками.
[52:13.080 --> 52:24.480]  Вот тут довольно, тут все довольно интересно. Так, рассказать, не рассказать, давайте расскажу.
[52:24.480 --> 52:38.280]  Смотрите, давайте я введу такое понятие, как инверсия. Инверсии и пассиве называется
[52:38.280 --> 52:55.160]  такая пара индексов и j. Такая, что a i больше, чем a j, а i меньше, чем j. То есть инверсия это просто пара
[52:55.160 --> 52:59.600]  элементов, которые стоят друг относительно друга не на правильных местах. Понятно? То есть элемент
[52:59.600 --> 53:06.720]  аитый больше, чем ожитый, но при этом он находится левее, чем ожитый. Окей? Вот. Давайте назовем такую
[53:06.720 --> 53:10.760]  штуку инверсии. Ну, понятное дело, что любая сортировка из чего состоит? То есть цель любой
[53:10.760 --> 53:15.120]  сортировки это свести число инверсии к нулю. Но если у меня число инверсии равно нулю, то соответственно
[53:16.120 --> 53:39.040]  массив уже сортирован. Так, дано. Массив а из n элементов. Что? Не, мы сравним сортировку. Я сейчас хочу обосновать,
[53:39.040 --> 53:54.960]  чем крута сортировка ставками. Я сейчас вот этот пункт закрываю. Дано. Массив а из n элементов, в котором
[54:10.040 --> 54:30.960]  найти время работы, а сортировки вставками. Ну, как функцию от n. Значит, да, в этом массиве всего
[54:30.960 --> 54:42.520]  k пар, которые стоят друг от друга, не на своих местах. Не, ну, смотрите, вот у меня есть массив. Вот. Да, ну, я просто
[54:42.520 --> 54:57.960]  наоборот собираю возможные пары и смотрю, образуют они инверсию или нет. Ну, t это функция, это время. Вот. Как
[54:57.960 --> 55:24.960]  время зависит от размера массива и числа инверсии k. Вот. Дано массив размера n, известно, что в нем k инверсий. Что? Как будто бы от k. Так, а почему? Ну, действительно, давайте покажем, что tnk есть
[55:24.960 --> 55:42.960]  большое от n плюс k. Что? То есть, сортировка вставками, на самом деле, это линейная сортировка, но от количества инверсий. То есть, если у меня массив, ну, давайте, ладно, потом скажу. В общем, время работы
[55:42.960 --> 55:49.960]  в сортировке вставками, если у меня в массиве мало инверсий, ну, то есть, точнее, если у меня в массиве k инверсий, то время работы сортировки о большое от n плюс k.
[55:49.960 --> 55:59.960]  Ну, давайте небольшое доказательство, просто обоснование, да, не доказательство, а обоснование. Вот. Давайте рассмотрим итерацию алгоритма сортировки вставками.
[55:59.960 --> 56:17.960]  Сортировки, да, сортировки вставками. Вот у меня есть элемент x. Давайте вот эту часть побольше. Значит, что я делаю с этим элементом x? Ну, я беру этот элемент x и,
[56:17.960 --> 56:35.960]  и последовательно обмениваю его с предыдущим, с предыдущим, с предыдущим, и так далее, пока он не встанет в свое место. Согласны? То есть, вот я x обменял с этим элементом, x обменял с этим элементом, с этим элементом, и вот в итоге x стал на свое место.
[56:35.960 --> 56:58.960]  Давайте x перешел отсюда, вот сюда на свое место. Как при этом изменилось число инверсий? Вот если x сделал там t сравнений. Да, согласны ли вы, что число инверсий в моем массиве уменьшилось на t?
[56:58.960 --> 57:10.960]  То есть, каждый раз вставляя элемент, то есть, по сути, сколько обменов я сделал, ровно столько инверсий у меня в массиве ушло. Согласны?
[57:10.960 --> 57:35.960]  Ну, кажется, что из этого следует, что число обменов равно число инверсий. Ну, а так как у меня, по сути, вся сортировка стоит просто из обменов, то из этого следует, что время работы сортировки есть то иное, какое большое, от k плюс n.
[57:35.960 --> 57:47.960]  Ну, n берется просто из того, что я все равно по массиву должен пройтись. Я все равно на каждый элемент хотя бы одно действие потрачу. Вот.
[57:51.960 --> 57:59.960]  Линейно зависит от числа инверсий.
[58:05.960 --> 58:18.960]  Ну, вот с пузырьком, к сожалению, это не правда. Точнее так, с пузырьком правда, что он действительно делает k обменов, то есть число обменов равно числу инверсий.
[58:18.960 --> 58:32.960]  Но пузырек еще делает лишние сравнения. Сортировка вставками, давайте еще напишу число обменов, и при этом это все равно числу сравнений. Вот, да, спасибо.
[58:32.960 --> 58:42.960]  То есть число обменов в сортировке вставками равно числу сравнений, и все равно числу инверсий. То есть все-таки в пузырьке мы еще делаем лишние сравнения. Понятно?
[58:42.960 --> 58:52.960]  А тут мы построили взаимнооднозначное соответствие между числом сравнений, числом обменов и числом инверсий. То есть они как бы относятся один к одному друг к другу.
[58:52.960 --> 59:00.960]  То есть сортировка вставками линией на зависимости от числа инверсий. Давайте подумаем, почему это хорошо.
[59:00.960 --> 59:12.960]  Вот, да, смотрите, допустим, мне дан почти ассортированный массив. Ну, допустим, мне известно, что мне дан массив, и в нем очень мало испорченных элементов.
[59:12.960 --> 59:20.960]  Понятное дело, что если я на этот массив натравлю сортировку пузырьковым или сортировку выбором, то, соответственно, мне придется потратить квадратичное число шагов.
[59:20.960 --> 59:31.960]  А если у меня массив почти ассортирован, то в нем буквально там 3-4 элемента стоят не на своих местах, то у меня алгорsee хочешь сортировки такой- за рим Ms время ассортирует весь массив.
[59:31.960 --> 59:39.960]  Ну, точнее за n Bonjour, проtaaуя время примерно music plus 4 а у вас сортировка выбор используетсяria. Круто? Круто вот.
[59:39.960 --> 59:42.460]  То есть в этом и преимущества использования сортировки вставками
[59:42.700 --> 59:46.160]  То есть сортировка вставками как правило используется в ситуациях, когда у вас массив почти отсортирован
[59:46.500 --> 59:50.060]  Сортировка выбором используется, когда вам важного количества обменов
[59:50.420 --> 59:54.300]  А сортировка пузырьком, ну она в целом просто легко пишется
[59:54.300 --> 59:56.800]  Ну в случае, если вы там ожидаете какой-то лучший случай, когда у вас там
[59:57.260 --> 01:00:01.260]  Ну, в целом массив там достаточно быстро отсортируется, то в целом
[01:00:01.280 --> 01:00:05.260]  Ну сортировка пузырьком встроена так называемой ранней остановкой
[01:00:05.260 --> 01:00:09.820]  которая позволит вам задактировать ситуацию, когда у вас массив уже стал отсортированным.
[01:00:09.820 --> 01:00:14.980]  Давайте рассмотрим произвольную ситуацию. В какой-то момент у меня есть какая-то отсортированная часть,
[01:00:14.980 --> 01:00:19.380]  и есть соответственно какая-то не отсортированная часть. Что делает отсортировка вставками?
[01:00:19.380 --> 01:00:24.380]  Сортировка вставками берет этот элемент, сравнивая с предыдущим.
[01:00:24.380 --> 01:00:30.260]  Если х стоит не на своем месте, то я их обмениваю местами. Снова дальше беру х, обмениваю с предыдущим.
[01:00:30.260 --> 01:00:37.260]  Если х стоит не на своих местах, то я их обмениваю. Каждый такой обмен приводит к тому, что у меня уменьшается одна инверсия.
[01:00:37.260 --> 01:00:44.260]  И ровно одна. Если вот этот элемент с этим элементом образовывали инверсию, то я просто поменял их местами,
[01:00:44.260 --> 01:00:51.260]  минус одна инверсия. Если мне известно, что я в результате таких вот сравнений сделал t обменов,
[01:00:51.260 --> 01:00:58.260]  то это по сути означает, что я уменьшил число инверсий k на t. Согласны?
[01:00:58.260 --> 01:01:04.260]  А теперь смотрите. Получается, что у меня каждый обмен уменьшает количество инверсий на единицу.
[01:01:04.260 --> 01:01:11.260]  Соответственно, сколько у меня всего обменов будет? k. Соответственно, количество сравнений тоже примерно k.
[01:01:11.260 --> 01:01:16.260]  Ну, плюс n. Смотрите, как устанавливается сортировка вставками. Я беру вот этот элемент и пытаюсь его просеять дальше.
[01:01:16.260 --> 01:01:20.260]  Беру этот элемент, пытаюсь его просеять дальше. То есть даже если у меня элемент остается на своем месте,
[01:01:20.260 --> 01:01:23.260]  то как бы все равно я хотя бы одно действие трачу.
[01:01:23.260 --> 01:01:32.260]  Поэтому я по сути пишу еще. Давайте так пишу. t плюс 1. Заканчиваем? В смысле, переходим к концу?
[01:01:32.260 --> 01:01:37.260]  Все, давайте последний набор слайдов. Соответственно, бонус.
[01:01:37.260 --> 01:01:41.260]  Возникает, должен возник, по крайней мере, естественный вопрос.
[01:01:41.260 --> 01:01:44.260]  Вот мы сегодня рассмотрели квадратичные сортировки.
[01:01:44.260 --> 01:01:50.260]  Ну, а можно ли сортировать быстрее? Собственно, да, я уже немного проспойлирую, что действительно сортировать быстрее можно.
[01:01:50.260 --> 01:01:55.260]  Более того, можно сортировать за линию.
[01:01:55.260 --> 01:01:58.260]  Давайте познакомимся с такой сортировкой, как сортировка под счетом.
[01:01:58.260 --> 01:02:03.260]  Давайте представим себе, что у нас есть массив.
[01:02:03.260 --> 01:02:16.260]  И, допустим, нам откуда-то известно, что все элементы массива принадлежат множеству 0, 1, 2 и т.д. к-1.
[01:02:16.260 --> 01:02:21.260]  Ну, просто из какого-то небольшого диапазона. Допустим, это целые числа из небольшого диапазона.
[01:02:21.260 --> 01:02:24.260]  Что я тогда могу сделать?
[01:02:24.260 --> 01:02:33.260]  Если диапазон действительно небольшой, вот у меня есть массив A, который содержит числа.
[01:02:33.260 --> 01:02:44.260]  Что я могу сделать? Я могу завести массив счетчиков размера к.
[01:02:44.260 --> 01:02:48.260]  0, 1, 2 и т.д. к-1.
[01:02:48.260 --> 01:02:56.260]  Изначально я принадлежу его нулями.
[01:02:56.260 --> 01:03:01.260]  Ну и что я сделаю? Давайте я просто пройдусь по массиву.
[01:03:01.260 --> 01:03:03.260]  И буду делать следующую вещь.
[01:03:25.260 --> 01:03:29.260]  То есть просто посчитаю количество элементов каждого типа.
[01:03:29.260 --> 01:03:38.260]  Допустим, нулей всего у меня 5, 1 у меня 3, 2 0, тут допустим 4, тут соответственно 1.
[01:03:38.260 --> 01:03:43.260]  Просто посчитаю количество уникальных элементов.
[01:03:43.260 --> 01:03:47.260]  Точнее, посчитаю количество нулей, количество единиц, количество 2.
[01:03:47.260 --> 01:03:51.260]  Вот у меня есть вот такой массив.
[01:03:51.260 --> 01:03:53.260]  Что делаем дальше?
[01:03:53.260 --> 01:04:07.260]  Так как я знаю, что 0 это самый минимальный элемент, то я могу взять массив A и вставить в него 5 нулей.
[01:04:07.260 --> 01:04:09.260]  Согласны?
[01:04:09.260 --> 01:04:12.260]  Беру массив A, вставляю 5 нулей.
[01:04:12.260 --> 01:04:15.260]  Дальше смотрю, сколько у меня единиц? Всего у меня 3 единицы.
[01:04:15.260 --> 01:04:18.260]  Соответственно дальше в массиве A должны идти 3 единицы.
[01:04:18.260 --> 01:04:21.260]  Все, вставляю 3 единицы.
[01:04:21.260 --> 01:04:23.260]  Дальше в массиве A идет 0.2.
[01:04:23.260 --> 01:04:25.260]  Ну ничего не вставляю и так далее.
[01:04:25.260 --> 01:04:28.260]  Один раз встречается число K-1.
[01:04:28.260 --> 01:04:30.260]  Вставляю K-1, все.
[01:04:30.260 --> 01:04:33.260]  То есть я заполняю массив в соответствии с количеством элементов, которые я насчитал.
[01:04:33.260 --> 01:04:35.260]  Согласны?
[01:04:35.260 --> 01:04:38.260]  Ну и давайте посмотрим, за сколько это добро все работает.
[01:04:38.260 --> 01:04:42.260]  Соответственно, за сколько работает подсчет количеств каждых элементов?
[01:04:42.260 --> 01:04:44.260]  Ну кажется, за N.
[01:04:44.260 --> 01:04:47.260]  То есть я просто-напросто прохожу по массиву A.
[01:04:47.260 --> 01:04:51.260]  И просто-напросто по одному добавляю к счетечку.
[01:04:51.260 --> 01:04:55.260]  А за сколько я добавляю элементов в массив A?
[01:04:55.260 --> 01:04:57.260]  Ну тоже за линию, да?
[01:04:57.260 --> 01:05:00.260]  То есть я просто-напросто смотрю, сколько элементов тут, сколько тут и так далее.
[01:05:00.260 --> 01:05:02.260]  Плюс N.
[01:05:02.260 --> 01:05:04.260]  И еще плюс K.
[01:05:04.260 --> 01:05:06.260]  Вопрос откуда K?
[01:05:11.260 --> 01:05:15.260]  Ну я думаю, вы понимаете, чтобы создать массив размера K, нужно потратить K времени.
[01:05:15.260 --> 01:05:17.260]  Ну как минимум, чтобы занулить все его элементы.
[01:05:17.260 --> 01:05:18.260]  Это первый момент.
[01:05:18.260 --> 01:05:19.260]  Второй момент.
[01:05:19.260 --> 01:05:21.260]  Верно ли, что когда я прохожу по массиву counters,
[01:05:21.260 --> 01:05:23.260]  когда я прохожу по эту массиву и заполняю массив A,
[01:05:23.260 --> 01:05:25.260]  верно ли, что я трачу ровно N времени?
[01:05:25.260 --> 01:05:27.260]  Почему?
[01:05:27.260 --> 01:05:28.260]  Да.
[01:05:28.260 --> 01:05:32.260]  Потому что, представьте себе, что у меня массив counters устроен следующим образом.
[01:05:32.260 --> 01:05:34.260]  Тут N, а тут стоят нули.
[01:05:34.260 --> 01:05:36.260]  Ну или наоборот.
[01:05:36.260 --> 01:05:38.260]  Тут стоят нули, а тут стоят N.
[01:05:38.260 --> 01:05:42.260]  Ну понятно дело, что по этим нулям я все равно должен пройтись, чтобы убедиться, что там реально стоят нули.
[01:05:42.260 --> 01:05:44.260]  Согласны?
[01:05:44.260 --> 01:05:46.260]  Поэтому проход по массиву counters сам по себе занимает K времени.
[01:05:46.260 --> 01:05:48.260]  Все.
[01:05:48.260 --> 01:05:52.260]  Суммируем, получаем O от N плюс K.
[01:05:52.260 --> 01:05:54.260]  Во.
[01:05:54.260 --> 01:05:56.260]  Если K достаточно мало,
[01:05:56.260 --> 01:05:58.260]  ну давайте так скажем, если K,
[01:06:00.260 --> 01:06:02.260]  ну условно меньше либо равно чем N,
[01:06:02.260 --> 01:06:06.260]  то получаем как раз-таки сортировку подсчета от N.
[01:06:06.260 --> 01:06:10.260]  Ну если K на самом деле достаточно большое, то, допустим,
[01:06:10.260 --> 01:06:12.260]  условно вы не можете применить сортировку подсчета,
[01:06:12.260 --> 01:06:14.260]  то есть вы не можете сказать, что
[01:06:14.260 --> 01:06:16.260]  ой, а нам же известно, что int
[01:06:16.260 --> 01:06:18.260]  принимает значение от минус двух миллиардов до плюс двух миллиардов.
[01:06:18.260 --> 01:06:22.260]  А давайте-ка я заведу массив counters размера 4 миллиарда
[01:06:22.260 --> 01:06:24.260]  и применю сортировку подсчета.
[01:06:24.260 --> 01:06:26.260]  Ну тогда у вас алгоритм будет работать за 4 миллиарда,
[01:06:26.260 --> 01:06:30.260]  но это примерно несколько десятков секунд.
[01:06:30.260 --> 01:06:32.260]  Поэтому сортировка подсчета имеет смысл
[01:06:32.260 --> 01:06:37.260]  ровно тогда, когда вы точно знаете, что у вас K достаточно мало.
[01:06:37.260 --> 01:06:39.260]  Ну вот.
[01:06:39.260 --> 01:06:43.260]  Так, ну и что?
[01:06:43.260 --> 01:06:47.260]  Ну это разная операция, но это все равно элементарная операция.
[01:06:47.260 --> 01:06:53.260]  Нет, нет, ну как бы, ну если мы, смотрите, если мы будем, ну давайте так.
[01:06:55.260 --> 01:06:59.260]  Если прям подходить к нему формально, то можно сказать, что ok.
[01:06:59.260 --> 01:07:03.260]  N раз мы выполняем операцию за время a,
[01:07:03.260 --> 01:07:05.260]  плюс K раз мы выполняем операцию за время a,
[01:07:05.260 --> 01:07:07.260]  плюс K раз мы выполняем операцию за время a,
[01:07:07.260 --> 01:07:11.260]  плюс K раз мы выполняем операцию за время b.
[01:07:11.260 --> 01:07:15.260]  Ну согласны ли вы, что просто-напросто имеется равно,
[01:07:15.260 --> 01:07:21.260]  что N плюс K умножить на максимум из a и b?
[01:07:21.260 --> 01:07:25.260]  А это есть O большое от N плюс K.
[01:07:27.260 --> 01:07:29.260]  Поэтому мы на самом деле забиваем на константы
[01:07:29.260 --> 01:07:31.260]  и просто-напросто пишем себя вот так.
[01:07:31.260 --> 01:07:33.260]  То есть как бы в нашей модели, в нашем модели вычислений
[01:07:33.260 --> 01:07:36.260]  мы всегда предполагаем, что каждая элементарная операция
[01:07:36.260 --> 01:07:38.260]  занимает одинаковое количество времени, вот и все.
[01:07:38.260 --> 01:07:42.260]  А если это не так, вдруг, то, ну вот, ограничение все равно верно.
[01:07:45.260 --> 01:07:46.260]  Да.
[01:07:46.260 --> 01:07:49.260]  Мы же даем параметры данных,
[01:07:49.260 --> 01:07:52.260]  а она просто подбирает нам хорошие цифровки
[01:07:52.260 --> 01:07:54.260]  и не надо париться двух поверхностей.
[01:07:54.260 --> 01:07:58.260]  Ну это типа из разряда метапрограммирования,
[01:07:58.260 --> 01:08:00.260]  металгоритмов типа алгоритм, который подбирает алгоритм.
[01:08:00.260 --> 01:08:02.260]  Ну это типа искусственный интеллект,
[01:08:02.260 --> 01:08:04.260]  тогда ну да, в целом возможно.
[01:08:05.260 --> 01:08:07.260]  Ну нет, ну смотрите как бы.
[01:08:07.260 --> 01:08:10.260]  Вы хотите сказать, что давайте посчитаем количество инверсий,
[01:08:10.260 --> 01:08:12.260]  и, тебя как сейчас Neil Morgan, то если количество инверсий мало,
[01:08:12.260 --> 01:08:14.260]  то применяем сортировку вставками.
[01:08:14.260 --> 01:08:16.260]  Почему это не работает?
[01:08:16.260 --> 01:08:18.260]  Потому что количество инверсий может быть огромным.
[01:08:18.260 --> 01:08:20.260]  Ну все, если вы там начитали,
[01:08:20.260 --> 01:08:22.260]  ну тыtalk to me, на самом деле можно сделать это так,
[01:08:22.260 --> 01:08:24.260]  если вы считаете количество инверсий,
[01:08:24.260 --> 01:08:26.260]  если если в какой-то момент количество инверсий
[01:08:26.260 --> 01:08:28.260]  становится достаточно большим,
[01:08:28.260 --> 01:08:30.260]  то вы говорите, окей, danced-бьем подсчет количества инверсий
[01:08:30.260 --> 01:08:32.260]  давайте использую другую сортировку.
[01:08:32.260 --> 01:08:36.760]  Спасибо.
[01:19:02.260 --> 01:19:07.260]  Продолжение в следующей части.
