[00:00.000 --> 00:12.960]  Ну что, мы готовы начать? Давайте начнем сегодня с пулопотоков, которые мы хорошо уже, надеюсь,
[00:12.960 --> 00:20.040]  знаем, которые мы давно уже написали, и вспомним про его метод Submit, который, я напомню, занимался
[00:20.040 --> 00:27.200]  тем, что планировал задачу на исполнение в одном из потоков Worker. И когда мы обсуждали этот
[00:27.200 --> 00:33.120]  Submit, я сразу заметил, что мы вот ничего сложного от него не хотим. Мы хотим, чтобы он просто
[00:33.120 --> 00:40.680]  исполнил рано или поздно задачу. Но мы не хотим усложнять этот метод какой-то дополнительной
[00:40.680 --> 00:46.920]  функциональностью. Ну, что я имею в виду? Вот мы бросаем в ThreadPool задачи, а потом можем дождаться,
[00:46.920 --> 00:53.760]  пока все задачи выполнятся. Для этого у нас есть метод WaitIdle. Ну а скажем, у нас нет возможности,
[00:54.080 --> 01:00.480]  имея просто базовый ThreadPool, каким-то образом дождаться исполнения конкретной задачи. Или
[01:00.480 --> 01:06.080]  получить из нее результат. Вот ThreadPool нам такой возможности не дает, и более того, я говорю,
[01:06.080 --> 01:12.240]  что мы от ThreadPool такой функциональности не хотим даже. Почему не хотим? Потому что оказывается,
[01:12.240 --> 01:18.520]  что вот эту задачу можно решить отдельно от ThreadPool, независимо от ThreadPool, а потом в
[01:18.520 --> 01:26.480]  ThreadPool некоторые инструменты использовать. И решение в нашем курсе, в задаче про future называлось
[01:26.480 --> 01:31.080]  Para-Future-Promise. А закрывайте, пожалуйста, двери за собой, когда вы заходите в аудиторию.
[01:31.080 --> 01:44.880]  Итак, как это решение выглядело? Мы строили такой односторонне направленный одноразовый канал
[01:44.880 --> 01:51.920]  в виде пары promise и future. Promise – это конец канала на запись. В него можно было поместить значение.
[01:51.920 --> 01:57.640]  Future – это конец канала на чтение. Оттуда значение, ну или ошибку, которая с другой стороны возникла,
[01:57.640 --> 02:03.800]  можно было получить. Мы создавали вот эту пару или так, можно сказать, что контракт мы создавали
[02:03.800 --> 02:11.160]  promise и потом из него строили future. И конец канала на запись promise отдавали потоку условно продюсеру,
[02:11.160 --> 02:16.320]  который генерировал данные, который, скажем, вычислял что-то в ThreadPool, а другой конец – future,
[02:16.320 --> 02:22.680]  канал для чтения, мы выдавали клиенту, который задачу дожидался. И вот мы этот канал прокидывали
[02:22.680 --> 02:28.120]  между task в ThreadPool и клиентом и получали возможность заблокироваться до тех пор,
[02:28.120 --> 02:34.440]  пока задача не завершится. Ну и из нее получить значение или ошибку получить. При этом future и
[02:34.440 --> 02:38.480]  promise в ThreadPool ничего не знали, разумеется. Они были полезны и разумны сами по себе,
[02:38.680 --> 02:44.720]  но будучи скомбинированными с полом потоков, мы вот решали задачу, которая у нас была в пуле
[02:44.720 --> 02:50.440]  потоков – дождаться завершения задачи конкретной. Так что вот такой сам по себе разумный инструмент.
[02:50.440 --> 02:59.840]  Но в задаче сразу говорится, что мы делаем такие, очень упрощенные future, мы делаем аналог
[02:59.840 --> 03:06.760]  STD future, но на самом деле вот сегодня лекция про то, что future и promise – это инструмент гораздо
[03:06.760 --> 03:11.040]  более общий, гораздо более сложный, гораздо более интересный и выразительный, чем то,
[03:11.040 --> 03:16.880]  что мы имеем в этой задаче. И сегодня мы поговорим про хорошие future, а не про STD future,
[03:16.880 --> 03:24.960]  которых future на самом деле отношения никакого не имеет. Итак, что мы понимаем под хорошими
[03:24.960 --> 03:33.240]  future? Ну давайте я начну с таких довольно синтактических изменений, которые пока не
[03:33.240 --> 03:40.000]  отражают сути, но уже делают future чуть-чуть аккуратнее. Вот давайте подумаем, что вы могли,
[03:40.000 --> 03:46.320]  если вы решали задачу, что вы могли заметить, чем future не очень удобно вот эти. Ну, например,
[03:46.320 --> 03:53.760]  у STD future, у STD promise вернее есть метод, который называется make future, который строит future по
[03:53.760 --> 03:59.880]  promise. И вот в этом API уже кроется некоторая хрупкость, некоторая уязвимость инструмента,
[03:59.880 --> 04:05.600]  потому что логически у нас такой одноразовый канал, конец на запись, конец на чтение. И
[04:05.600 --> 04:17.480]  продолжаем. Тут просто есть некоторая опасность, что у нас прервется запись
[04:17.480 --> 04:25.440]  скринкаста, когда миграет проектор. Итак, есть логически такой одноразовый канал,
[04:25.440 --> 04:30.560]  при этом у promise есть метод make future, который в принципе неаккуратно невнимательные пользователи
[04:30.560 --> 04:36.800]  может позвать дважды. Это было бы странно, это не имеет никакого смысла. У future и promise есть
[04:36.800 --> 04:40.480]  возможность предыдущего одного значения. Значение можно получить только один раз,
[04:40.480 --> 04:47.720]  потому что в общем случае оно move only. Так что вызвать метод make future дважды смысла не имеет.
[04:47.720 --> 05:04.000]  У нас проблема с проектором. Будем аккуратно, не будем совершать резких движений. Ну вот. Так что,
[05:04.000 --> 05:11.120]  во-первых, мы от этого make future избавимся и скажем, что у наших future promise будет просто функция,
[05:11.120 --> 05:17.160]  которая называется make contract, которая параметризуется типом, и эта функция сразу
[05:17.160 --> 05:23.520]  возвращает нам пару future и promise. Мы строим оба конца канала разом, потому что логически
[05:23.520 --> 05:32.960]  этот канал contract так возникает. Дальше. Смотрите. В наших future для того, чтобы позвать на promise set
[05:32.960 --> 05:39.760]  value или на future get result, но здесь называется get result, а не get, разницу объясню чуть
[05:39.760 --> 05:49.000]  позже. Мы используем вот такую вот форму. Мы говорим set the move promise set value. Зачем мы так делаем?
[05:49.000 --> 05:57.440]  Ну вот логически, физически мы здесь никакой promise, никакую future не перемещаем в памяти. Но
[05:57.440 --> 06:01.920]  с другой стороны, set the move сам по себе тоже ничего не перемещает. Это всего лишь преобразование типа,
[06:01.920 --> 06:09.480]  ссылки. Так вот. Что я здесь хочу таким кодом сказать? Я говорю, что методы set value или get
[06:09.480 --> 06:18.680]  result симметрично на future, они, их можно вызывать только на объекте rvalue. Для того, что и такое
[06:18.680 --> 06:26.120]  определение требует, чтобы мы сгставали ссылку там lvalue к этому самому rvalue, и таким образом я
[06:26.120 --> 06:34.520]  хочу сказать читателю этого кода, что метод ну условно потребляет future значение, которое там
[06:34.520 --> 06:40.640]  было. Или ну так тратит, использует одноразово promise. Ну то есть, если вы пишете в коде move,
[06:40.640 --> 06:46.880]  если вы перемещаете объект в памяти, то, вероятно, объект, из которого вы переместили,
[06:46.880 --> 06:49.960]  он уже для пользователей недоступен. Но его неразумно использовать, потому что там уже
[06:49.960 --> 06:59.440]  ничего нет. Он в каком-то непредсказуемом странном состоянии. Ну вот такой код, он эту мыс, эту идею и
[06:59.440 --> 07:08.160]  выражает. После того, как мы сделали set value на promise, его использовать нельзя. Идея понятна? Вот так мы
[07:08.160 --> 07:11.760]  говорим читателю, ну или в общем случае линтеру, который может автоматически это проверить,
[07:11.760 --> 07:17.440]  что мы, что к promise больше обращаться не надо, что мы его и стратили. Ну и симметрично для future
[07:17.440 --> 07:27.960]  тоже самое. Третье отличие. Что происходило, когда в promise, точнее, когда в продюсере
[07:27.960 --> 07:34.440]  возникало исключение, возникала какая-то ошибка. Мы ее прообразовали через shared state в
[07:34.440 --> 07:42.920]  консьюмера. И консьюмер вызывает get, получал это исключение, оттуда оно вылетало. Вот мы хотим
[07:42.920 --> 07:50.440]  сегодня несколько обобщить механизм обработки ошибок во future и promise и скажем, что когда
[07:50.440 --> 07:59.480]  пользователь вызывает на future метод блокирующий get, то он получает не значение или исключение,
[07:59.480 --> 08:06.600]  он получает результат. Результат, он вот буквально представлен классом result. Result t,
[08:06.600 --> 08:14.920]  который представляет себя или значение типа t или некоторую ошибку, упакованную в специальный
[08:14.920 --> 08:22.920]  контейнер. И эта ошибка, это либо исключение, либо exception pointer, либо это error code. И пользователь
[08:22.920 --> 08:29.640]  уже сам имеет этот result, решает как именно, в каком стиле он собирается с ошибками работать. Он
[08:29.640 --> 08:35.080]  хочет работать с исключениями или он хочет работать с кодами ошибок. Для этого у него есть свобода.
[08:35.080 --> 08:42.680]  Ну вот, скажем, он получает из функции результат типа int и может проверить, верно ли, что в
[08:42.680 --> 08:49.720]  результате есть значение, что оно не пустое. Что там не ошибка, вернее. Ну и там ее как-то
[08:49.720 --> 08:57.320]  обработать. Что важно, главный такой правил обработки ошибок, их нельзя игнорировать. И
[08:57.320 --> 09:02.960]  инструмент не должен позволять игнорировать ошибки. Ну вот, скажем, у вас есть функция foo,
[09:02.960 --> 09:07.600]  которая возвращает result int. Тут у нас такой статический конструктор именованный, который
[09:07.600 --> 09:13.440]  упаковывает значение в этот самый контейнер result. И вот если мы напишем такой код, то он
[09:13.440 --> 09:28.960]  компилироваться, надеюсь, не должен. Почему? Ну потому что result no discard. Он говорит, что значение типа
[09:28.960 --> 09:35.360]  result должно быть обработано. И мы его можем обработать в данном случае двумя способами. Мы
[09:35.360 --> 09:42.840]  можем вызвать throw if error на result. И он нам либо значение распакует, либо бросит exception,
[09:42.840 --> 09:51.160]  если там была внутри ошибка. Или мы можем сказать, что expect value or и некоторый текст. Это assert. Ну
[09:51.160 --> 09:57.800]  или там мы удостоверяемся, что ошибки точно не было. Вот мы считаем, что в этом месте не должно
[09:57.800 --> 10:02.560]  быть ошибки. Не знаю, мы пишем базу данных, добавляем запись в write a headlock, и если ошибка
[10:02.560 --> 10:05.760]  случилась при записи в write a headlock, то у нас нет никакого разумного способа это обработать. Мы
[10:05.760 --> 10:13.120]  просто должны упасть. Вот этот способ сказать, что мы ожидаем здесь успешного завершения, и вот
[10:13.120 --> 10:19.200]  продолжить не готово, если возникла ошибка. Короче говоря, вот у вас есть инструмент, который позволяет
[10:19.200 --> 10:24.920]  работать с ошибками в разном стиле, и чуть позже станет понятно, почему он здесь просто необходим.
[10:24.920 --> 10:35.320]  Ну вот, значит, это еще одно отличие наших фьюч пока от std-future. Мы возвращаем такой вот
[10:35.320 --> 10:42.240]  контейнер, который содержит либо значение, либо ошибку, но не может быть пустым. Но, конечно,
[10:42.240 --> 10:47.640]  это все пока изменения довольно незначительные. Мы хотим чего-то более основательного, и сейчас
[10:47.640 --> 10:54.040]  мы разберемся, а чем же по-настоящему отличаются фьючи от вот наших детских игрушечных фьюч,
[10:54.040 --> 11:01.280]  которые мы писали в домашней работе пока. Они отличаются тем, как фьючу можно, как значение,
[11:01.280 --> 11:07.040]  ну или результат, который попадает во фьючу, можно использовать, можно потребить. Вот для этого,
[11:07.040 --> 11:13.240]  до этого у нас был только блокирующий такой синхронный способ. Заблокировать поток, дождаться,
[11:13.240 --> 11:21.640]  пока значение или ошибка не появится. К нему мы добавляем сейчас асинхронный способ, а именно мы
[11:21.640 --> 11:32.400]  добавляем возможность истратить фьючу асинхронно, повесить на нее обработчик callback.
[11:32.400 --> 11:41.840]  Вот у нас есть контракт, ну здесь он на самом деле скрыт от вас. Мы здесь используем функцию
[11:41.840 --> 11:48.960]  async via, которая берет threadpool, берет лямбду и запускает эту лямбду в пуле потоков, вот в этом
[11:48.960 --> 11:57.320]  вот. Сразу передает задачи в promise, а нам возвращает фьючу. То есть мы превращаем такую
[11:57.320 --> 12:03.920]  синхронную функцию в асинхронную, которая исполняется в пуле и сразу получаем фьючу,
[12:03.920 --> 12:09.240]  которая представляет вот этот самый асинхронный результат вычисления. А дальше мы на нее вешаем
[12:09.240 --> 12:18.200]  обработчик, который будет вызван, когда задача в пуле завершится. И снова мы говорим stdmove
[12:18.200 --> 12:24.640]  subscribe, потому что мы тратим фьючу, после этого ее использовать нельзя. Потратить фьючу можно
[12:24.640 --> 12:32.680]  только один раз. Вот здесь мы используем асинхронные аппелли, то есть subscribe завершается мигом без
[12:32.680 --> 12:39.560]  ожидания и когда асинхронная задача в пуле потоков завершится, в promise попадет значение,
[12:39.560 --> 12:46.720]  на фьючу вызовется обработчик callback и вот он получит результат своим аргументом. И вот тут
[12:46.720 --> 12:51.280]  сразу понятно, что без резалта, в общем-то, жить было нельзя, потому что... Но вот здесь callback,
[12:51.280 --> 12:57.400]  он не может получить аргументом, там, не знаю, исключения, это было бы странно. Исключения он
[12:57.400 --> 13:01.520]  должен разворачивать стэк. Здесь у нас никакого стэка нет, здесь просто какой-то асинхронный
[13:01.520 --> 13:07.040]  вызов и поэтому вот здесь неизбежно возникает необходимость как-то ошибку представить в виде
[13:07.040 --> 13:12.560]  объекта. Ну, вспомните ASIO, про который мы говорили, который сейчас у вас задача slip4, там тоже все
[13:12.560 --> 13:18.400]  callback принимают аргументом ошибку, потому что никакого другого механизма здесь представить
[13:18.400 --> 13:42.200]  невозможно. Ну что ж, идем дальше. Subscribe это первый шаг в сторону разумных фьюч. В разумных
[13:42.200 --> 13:47.160]  фьючах всегда есть способы обработать ошибку синхронный и асинхронный. Ну более того, я даже
[13:47.160 --> 13:54.960]  скажу, что на самом деле, имея вот такой асинхронный способ использовать результат, который подает во
[13:54.960 --> 14:00.160]  фьюч, можно от синхронного вызова get, асинхронного метода get во фьюч избавиться, он вообще-то там
[14:00.160 --> 14:05.560]  не нужен. Если у вас есть subscribe, то вы можете get выразить снаружи, просто как свободную функцию.
[14:05.560 --> 14:13.280]  Ну, возможно у вас еще повод представиться в домашней работе. Ну, а пока мы продолжаем. И вот
[14:13.280 --> 14:20.960]  сейчас с помощью метода subscribe мы можем подойти как раз к... Давайте прежде чем мы подойдем к
[14:20.960 --> 14:31.240]  самой сути. Такое маленькое синтактическое замечание. Если у нас вдруг есть API, которая
[14:31.240 --> 14:39.480]  построена на кулбеках, то всегда можно преобразовать его в API, которая использует фьюч. То есть,
[14:39.480 --> 14:44.840]  если у вас есть какая-то библиотека и там асинхронные операции, и они вызывают кулбеки,
[14:44.840 --> 14:50.840]  то вы всегда можете это API переписать на фьюч, так чтобы у вас код был достаточно однородным. Ну,
[14:50.840 --> 14:57.320]  вот точно так же бросаете в кулбек promise, там вы комплите, и с другой стороны из фьюча достаёте
[14:57.320 --> 15:07.200]  результат. И имея кулбеки, дальше вы можете... Имея кулбеки и такой вот асинхронный subscribe,
[15:07.200 --> 15:17.360]  дальше вы можете добиться... Дальше вы можете выражать с помощью фьюч свои асинхронные мысли,
[15:17.360 --> 15:23.800]  асинхронные обработчики гораздо более декларативно, чем бы вы делали это с помощью кулбек. Ну,
[15:23.800 --> 15:30.840]  представьте себе такую проблему. У вас есть... Давайте я покажу пример из библиотеки Folly. Согласен.
[15:30.840 --> 15:38.680]  Представьте, что у вас есть некоторая асинхронная API. Функции, которые принимают некоторый вход,
[15:38.680 --> 15:44.280]  и вы передаете кулбек, который будет вызван, когда асинхронная функция завершится. А дальше у
[15:44.280 --> 15:51.360]  вас задача. Вы можете... Вы хотите вот эти асинхронные действия выполнить последовательно.
[15:51.360 --> 16:02.400]  Ну, как вы такой код пишете? Вы строите такую пирамиду. Вы пишете вызов первой функции и в
[16:02.400 --> 16:08.200]  обработчик передаете. И в качестве обработчика помещаете код, который вызывает вторую асинхронную
[16:08.200 --> 16:12.000]  функцию. А в качестве обработчика второй асинхронной функции вы вставляете лямбду,
[16:12.000 --> 16:17.920]  которая вызывает третью асинхронную функцию, и вложенность растет. Ну, и у вас получается вот
[16:17.920 --> 16:22.120]  какая-то такая картинка. То есть, в общем случае, пирамида, она такая достаточно глубокая.
[16:22.120 --> 16:32.920]  Фьючи позволяют, трансформируя, ну, избавившись в API от кулбеков, решить такую задачу очень
[16:32.920 --> 16:41.600]  эрегантно. Как запланировать цепочку асинхронных последовательных действий? Ну, вот для того,
[16:41.600 --> 16:47.000]  чтобы понять, как это делается, нужно немного обобщить в своем уме понятие фьючи и промеса,
[16:47.160 --> 16:54.480]  и отказаться от вот той интерпретации, что промес и фьюча — это такой одноразовый канал. Вот не
[16:54.480 --> 16:58.680]  нужно так об этом думать, потому что вы сразу можете задуматься над вопросом, а зачем канал
[16:58.680 --> 17:03.640]  у два конца отдельных, почему не сделать один класс вот всей этой истории. Нет, про фьюч нужно
[17:03.640 --> 17:10.760]  думать иначе. Вот у вас может быть вызов функции обычной в коде, и он возвращает вам некоторое
[17:10.760 --> 17:16.080]  значение. А теперь у вас функции бывают асинхронные, которые исполняются где-то когда-то.
[17:16.280 --> 17:22.940]  И у этих funkций тоже есть результат, только он асинхронный, только он из будущего. И вот
[17:22.940 --> 17:30.280]  это будущее представление, точнее, представление будущего результата и называется фьюч. И вот это
[17:30.280 --> 17:36.080]  значение будущее, оно вот, операция только началась, а вы уже получили это будущее, это
[17:36.080 --> 17:41.680]  представление будущего результата, зачем оно вам? Затем, что им уже сразу можно воспользоваться,
[17:41.680 --> 17:47.120]  а именно, передать в следующий вызов, который ожидает этого самого значения.
[17:47.120 --> 17:52.880]  Правда, не будущего, а обычного. Но, тем не менее, вот смотрите, пусть у вас было это
[17:52.880 --> 17:57.760]  самое будущее значение, и пусть у вас была функция, которая ожидала этого
[17:57.760 --> 18:01.080]  будущего значения. Но, правда, не в виде фьючера, разумеется, а в виде резалта. То есть,
[18:01.080 --> 18:08.080]  либо значение, либо ошибка. И возвращал какое-то свое значение другого типа.
[18:08.080 --> 18:14.760]  И вот мы хотим это будущее значение передать в эту функцию. Но, разумеется,
[18:14.760 --> 18:18.560]  мы буквально это не можем сделать, поэтому мы пишем такой специальный комбинатор,
[18:18.560 --> 18:24.840]  который называется Zen. Вот этот такой способ передать будущее значение в функцию.
[18:24.840 --> 18:31.320]  У нас была первая фьючер, которая занималась каким-то асинхронным
[18:31.320 --> 18:37.600]  вычислением в пуля потоков. И мы к ней вешаем, это называется продолжение,
[18:37.600 --> 18:45.680]  обработчик будущего значения с помощью Zen. И получаем следующую фьючер, в которой уже
[18:45.680 --> 18:49.800]  будет значение, вот которое будет вычислено здесь, когда вот это значение,
[18:49.800 --> 18:56.160]  когда в этой фьюче появится свое значение. Понимаете, что происходит? Вот мы, по сути,
[18:56.160 --> 19:04.080]  запланировали такой маленький конвейер из двух последовательных задач. А дальше мы можем
[19:04.080 --> 19:09.280]  заблокироваться, ну и дождаться, пока значение там появится. Не знаю, давайте примеры запускать,
[19:09.280 --> 19:15.200]  а то что я вам рассказываю и ничего не показываю. Немного странно.
[19:27.120 --> 19:27.840]  Терпение.
[19:43.280 --> 19:50.840]  Ну, 42, 43. Вот мы заблокировались и вычислили это самое 43. Вот здесь, по смыслу, еще раз,
[19:50.840 --> 19:55.640]  мы передали асинхронный результат в следующую функцию. Для этого нам нужно было иметь просто
[19:55.640 --> 20:00.160]  некоторую материализацию представления этого будущего результата. И вот фьючер, она про это и есть.
[20:00.160 --> 20:08.920]  А дальше вы можете делать вещи чуть более сложные, а именно выстраивать прямо конвейеры из таких вот
[20:08.920 --> 20:15.600]  шагов. Вот у нас есть некоторое вычисление, потом умножение на 2, потом плюс 1. Короче,
[20:15.600 --> 20:22.520]  какой-то конвейер. И вот мы делаем первый асинхронный шаг, а потом мы планируем цепочку действий,
[20:22.520 --> 20:29.440]  которые за ним последуют. И вот весь этот код, он исполняется мгновенно, он ничего пока не делает,
[20:29.440 --> 20:34.880]  он просто планирует работу. А потом, по мере готовности вот этого результата, запускается вот
[20:34.880 --> 20:38.600]  этот обработчик, потом следующий, следующий, следующий. Вот эта цепочка задач выполняется.
[20:38.600 --> 20:48.560]  Выполняется. Ну, кстати, вот мы не поговорили и вы не спросили, что довольно невнимательно было
[20:48.920 --> 20:56.120]  со всех наших сторон. Смотрите, вот код, мы подвесили обработчик. Вот давайте задумываемся,
[20:56.120 --> 21:04.600]  где он вообще выполнится, в каком потоке. Ну, у нас есть с фьючерами и промесами работают два
[21:04.600 --> 21:11.000]  потока. Один продюсер, другой консюмер. Один делает сетвейли, другой делает сабскрайп. Ну,
[21:11.000 --> 21:16.880]  и очевидно, чтобы обработчик кулбэк вызвался, нужно иметь и кулбэк, и значение, и результат.
[21:16.880 --> 21:22.520]  Поэтому кулбэк может вызваться тогда, когда случится вот рандеву продюсера и консюмера,
[21:22.520 --> 21:29.840]  когда они оба придут. Вот. Ну, и тогда вот неизбежно возникает ответ. Обработчик будет вызван в том
[21:29.840 --> 21:35.480]  потоке, который придет вторым в shared state. Ну, вы знаете, как фьючи реализованы. Между фьючей и
[21:35.480 --> 21:41.120]  промесом есть shared state, на котором есть синхронизация. И вот тот поток, который придет в него вторым и
[21:41.120 --> 21:48.720]  положит либо кулбэк, либо значение, или там результат, то есть вот тот поток обработчик и вызовет.
[21:48.720 --> 21:56.960]  Ну, вот если мы говорим здесь про зен, то вероятно, что вычисление, оно запланируется быстро, и поэтому
[21:56.960 --> 22:03.360]  вся эта работа будет выполняться в конце концов в пуле потоков. Ну, а где именно она будет выполняться,
[22:03.360 --> 22:07.800]  мы поговорим чуть позже. Это очень важный момент для нас. Но смотрите, что я хочу сейчас показать вам.
[22:07.800 --> 22:16.240]  Что вот мы запланировали такую цепочку работы. И вот такая цепочка из фактически таких маленьких
[22:16.240 --> 22:21.720]  задачек должна у вас вызывать уже достаточно многочисленные ассоциации. Ну, потому что,
[22:21.720 --> 22:28.600]  смотрите, мы говорили про... Мы делаем файбер прямо сейчас, да? И, кстати, сегодня у вас будет
[22:28.600 --> 22:37.480]  очередная задача про файбер. Так вот, файбер — это же, по сути, цепочка задач. Каждая отдельная задача — это
[22:37.480 --> 22:45.600]  такая... Это запуск карутины в пуле потоков. Это очередной такой не блокирующий шаг файбера.
[22:45.600 --> 22:53.080]  Когда он решает остановиться, перепланироваться или заснуть, он карутину останавливает свою. Ну,
[22:53.080 --> 22:57.280]  и вот так вот цепочка задач, они друг друга планируют. Каждая очередная задача, она планирует
[22:57.280 --> 23:02.640]  следующую, то есть продолжение. Ну, и вот так вот файбер бежит. Ну, вот здесь мы, по сути, выразили
[23:02.640 --> 23:11.400]  нечто похожее, тоже цепочку задач. Ну, или мы говорили с вами про ASIO, про Event Loop, про эхо-сервер,
[23:11.400 --> 23:15.920]  и там же тоже был... Там уже была, правда, не цепочка, там был цикл задач — асинхронное
[23:15.920 --> 23:20.560]  чтение, потом E-Poll, потом асинхронная запись, потом E-Poll. Но, в конце концов, вот снова задачи,
[23:20.560 --> 23:26.880]  которые планируют следующую задачу. Так что все это очень похоже, все это про одно и то же,
[23:26.880 --> 23:31.980]  и вот эти мы воспользуемся, ну, уже ближе к концу занятия. Вы должны понимать, что мы,
[23:31.980 --> 23:40.540]  видимо, решаем одну и ту же задачу, но разными способами. К этому я чуть позже приду. Ну, пока
[23:40.540 --> 23:46.980]  мы здесь, я хочу обратить внимание еще вот на что. Ну, на, собственно, самый Zen. Вот я утверждаю,
[23:46.980 --> 23:53.180]  что это не какой-то новый метод Fruge, это всего лишь некоторая обертка над Subscribe. Ну, вот,
[23:53.180 --> 23:59.780]  имея Subscribe, можно делать все остальное в сегодняшней лекции. Вот давайте представим себе,
[23:59.780 --> 24:06.860]  как может быть устроен этот Zen. Что он должен делать? Ну, во-первых, у нас была одна фьюча,
[24:06.860 --> 24:17.140]  вот F1. Ей отвечал некоторый Promise, который клал значение, там, shared status. А дальше мы говорим
[24:17.140 --> 24:22.820]  Zen и передаем продолжение. И мы хотим, видимо, получить новую фьючу, в которой появится результат
[24:23.740 --> 24:29.900]  второй задачи. Ну, видимо, нам нужно построить новый канал, да? Новую пару Promise,
[24:29.900 --> 24:35.380]  фьючу, новый контракт, вернее. Ну, хорошо, а что теперь сделает Zen? Ну, давайте вот порассуждать
[24:35.380 --> 25:00.980]  кто-нибудь. К новой фьюча? Ну, это было бы странно. Которую делает что? Так у нас оно и так уже было,
[25:00.980 --> 25:15.060]  зачем передавать через лишних уп. И где здесь запуск продолжения главное? Ну, смотрите,
[25:15.060 --> 25:22.540]  нам нужно вызвать продолжение, когда во фьюче F1 появится результат. Видимо, это Subscribe. Вот этот
[25:22.540 --> 25:33.340]  Subscribe, он получит что? Результат. Вот здесь вот, да? Он получит Result Future F1. Сможет вызвать
[25:33.340 --> 25:40.380]  продолжение. Вот эту функцию, вот эту вот функцию. Ну, правда, не Result от Т от Т принимается,
[25:40.380 --> 25:49.180]  но разберемся. Он вызовет эту функцию, а что он дальше должен сделать? Он должен теперь передать
[25:49.180 --> 25:54.580]  значение вот второму, ну, второе фьючу, которое мы построили заранее. Так что этот обработчик,
[25:54.580 --> 25:59.460]  который мы вешаем на F1, будет вызывать продолжение и класть значение во второй
[25:59.460 --> 26:07.700]  Promise. А вторую фьючу от этого второго контракта мы сразу отдадим пользователю. Ну, то есть в этом
[26:07.700 --> 26:14.740]  Zen вызывается фактически один Subscribe со специально подготовленным Callback, и вот это весь код работает
[26:14.740 --> 26:20.460]  без ожидания, без блокировок. Сразу возвращает нам новую фьючу, а первую фьючу тратит, потому что
[26:20.460 --> 26:25.500]  он вешает на нее асинхронный обработчик. Ну, все, больше использовать нельзя. Поэтому здесь также Move.
[26:25.500 --> 26:34.420]  И теперь легко понять, кажется, как работает этот код. Вот очередная задача завершается. Она
[26:34.420 --> 26:41.700]  Completed Promise. В результате запускается какой-то обработчик, который вызывает следующую задачу,
[26:42.180 --> 26:49.580]  которая в конце Completed Promise. Ну, и вот так вот получается задачи. Выполняются одна за другой,
[26:49.580 --> 26:58.180]  триггерят одна другую. Вот та же самая ситуация, как у нас была Fiber, как у нас была Vassio. Мы просто,
[26:58.180 --> 27:04.980]  по сути, сейчас меняем средства выразительности. Как именно мы в коде вот такую цепочку задач
[27:04.980 --> 27:12.900]  описываем? Хорошо. Ну ладно, у вас уже, на самом деле, если вы внимательно слушаете,
[27:12.900 --> 27:16.860]  может возникнуть разумный вопрос, а зачем вообще мы все это делаем? Ну, в смысле, зачем мы именно так
[27:16.860 --> 27:22.780]  это делаем? Но прежде чем мы на него ответим, я прокомментирую еще один нюанс важный. Смотрите,
[27:22.780 --> 27:31.940]  вот здесь все шаги, каждый последующий шаг ожидает значения предыдущего шага. Но что,
[27:31.940 --> 27:36.180]  если на предыдущем шаге возникла ошибка? Ну, вот мы пишем какой-то код. Простите,
[27:36.180 --> 27:42.860]  давайте вот здесь. Пишем какой-то код. Снова выстраиваем конвейер, а потом говорим, ну вот,
[27:42.860 --> 28:00.260]  не получилось. Не, давайте сначала получилось. Давайте с хорошего начнем. Смотрите, задача. Мы
[28:00.260 --> 28:06.700]  хотим обрабатывать ошибки. Если мы пишем синхронный последовательный код, то мы обрабатываем ошибки,
[28:06.700 --> 28:12.540]  ну скажем, с помощью исключений. Пишем здесь блок try-catch, в нем три вызова. Ну, если в каком-то
[28:12.540 --> 28:21.180]  возникла ошибка, то вызовется вот этот fallback. Мы бы хотели уметь перекладывать такой вот синхронный
[28:21.180 --> 28:27.740]  код с обработкой ошибок через исключение на вот асинхронный framework наш. Для этого нам
[28:27.740 --> 28:38.180]  нужен какой-то инструмент, который бы заменял нам этот самый catch. Нет. Дело не в том, чтобы
[28:38.180 --> 28:42.140]  передавать его по конвейеру, а в том, чтобы описывать логику удобно. Вот у тебя есть три
[28:42.140 --> 28:48.420]  вызова, они про ошибки не думают, но в этом же смысл этого кода. Ты пишешь этот код, игнорируя ошибки,
[28:48.420 --> 28:54.420]  и обрабатываешь их только здесь. Ты вот отделил одно от другого обработку ошибок, вот обработки
[28:54.500 --> 29:06.140]  хорошего сценария удачного. Ну вот, у нас есть, помимо Зена, который связывает два вычисления подряд,
[29:06.140 --> 29:17.420]  не ожидая там ошибки, есть recover, который получает на вход callback, который принимает на вход уже не
[29:17.420 --> 29:23.900]  значение, а именно только ошибку, и возвращает значение. Его задача восстановить цепочку задач
[29:23.900 --> 29:31.180]  после ошибки. И вот если ошибок никаких нет, то в этом коде будет вызван produce, multiply,
[29:31.180 --> 29:36.780]  increment, и в конце концов эта цепочка терминируется callback-ом subscribe. Ну вот,
[29:36.780 --> 29:39.340]  давайте запустим и посмотрим, что напечатается.
[29:54.820 --> 30:00.260]  Ну вот, то есть здесь хороший сценарий, этот обработчик вообще не был вызван,
[30:00.260 --> 30:05.340]  потому что ошибок не возникало. А теперь мы вот здесь бросим исключение.
[30:23.900 --> 30:30.620]  Вот, increment не был вызван, multiply вообще сломался, и мы сразу прыгнули, ну не то что сразу
[30:30.620 --> 30:37.820]  прыгнули, но в конце концов оказались здесь. Ну то есть вот мы придумали асинхронные API,
[30:37.820 --> 30:44.340]  на которые можно описывать цепочки асинхронных действий и асинхронные обработчики ошибок.
[30:44.340 --> 30:50.420]  Кажется довольно разумно. Ну я еще не сказал, мы можем делать даже чуть больше, у нас Зен,
[30:50.420 --> 30:55.540]  он не только может связывать синхронные действия, он может связывать асинхронные действия. То есть,
[30:55.540 --> 31:01.180]  у нас есть первый вызов, который асинхронный, а за ним мы делаем второй асинхронный вызов,
[31:01.180 --> 31:07.060]  который тоже, который даже не увозращает основы фьючу от у, и нужно их связать,
[31:07.060 --> 31:14.860]  такую цепочку. Ну где это может понадобиться? Вообще, откуда берутся фьючи в коде? Давайте
[31:14.860 --> 31:25.740]  так подумаем. Вот есть очень естественный пример, он довольно сложен, и не то чтобы я сейчас
[31:25.740 --> 31:31.460]  планирую его вам полностью объяснить, но очень естественное место, откуда берутся в коде фьючи,
[31:31.460 --> 31:45.540]  это RPC вызовы. Ну вот представим, что у вас есть, давайте другой пример, у вас есть некоторый ваш
[31:45.540 --> 31:50.940]  сервис, который, не знаю, калькулятор, вот он реализует, по сути, такой интерфейс, есть методы
[31:50.940 --> 31:57.900]  логические multiply, add, и вот это некоторый код, запущенный на машине, там стоит, не знаю, какой-нибудь
[31:57.900 --> 32:07.300]  сервер, в котором запускают, который получает запросы по сети и вызывает вот эти вот логические
[32:07.300 --> 32:15.100]  операции, умножая числа, складывая числа. И вы хотите на своей машине иметь некоторое локальное
[32:15.100 --> 32:22.820]  представление этого удаленного сервиса. Вот где-то на сервере находится код, который удовлетворяет
[32:22.820 --> 32:31.500]  этому интерфейсу, вот он называется RPC сервисом, и в нем есть такие обработчики, и у вас есть клиент,
[32:31.500 --> 32:37.580]  который находится на другой машине, который делает запросы по сети, и вот он хочет послать два
[32:37.580 --> 32:43.300]  своих числа по сети, для этого он должен их серилизовать в байты, потом отправить там по
[32:43.300 --> 32:49.900]  комнате CP, дождаться ответа, декодировать его, десерилизовать, в общем какая-то сложная механика.
[32:49.900 --> 32:55.260]  Вместо этого клиент хочет, чтобы он на своей стороне работал с некоторым, ну это называется
[32:55.260 --> 33:02.420]  стап, некоторым представлением этого удаленного сервиса. И когда он, этот стап тоже реализует
[33:02.420 --> 33:10.100]  интерфейс этого самого сервиса, но когда мы говорим о нем multiply 3.7, то что происходит? Мы
[33:10.100 --> 33:18.140]  делаем RPC вызов, мы вот асинхронно мы посылаем сетевой запрос, в котором лежат имя сервиса,
[33:18.140 --> 33:24.020]  имя методы, которые мы вызываем, аргументы сервизованные, и дожидаемся ответа. Дело не
[33:24.020 --> 33:29.420]  быстрое, разумеется. Вообще говорят, там машина, которой мы отправляем запрос, может вообще уже
[33:29.420 --> 33:34.220]  перезагрузилась, может быть и там некоторое время будет наступно, может быть это вообще выключено,
[33:34.220 --> 33:45.540]  потому что на дата-центр разломался весь. Так что мы получаем от этого вызова представление будущего
[33:45.540 --> 33:51.140]  результата. Его пока нет, дожидаться мы его не можем синхронно, поэтому мы получаем фьючу. Ну а
[33:51.140 --> 33:56.260]  дальше, ну ладно, тут мы можем синхронно ее дождаться, ну в смысле можем, можем так сделать,
[33:56.260 --> 34:04.700]  а можем и не делать. Ну вот в общем, фьючи, RPC вызовы, это RPC просто, удаленный вызов удаленных
[34:04.700 --> 34:10.140]  процедур, кажется так правильно. Это очень естественное место, откуда фьючи в коде
[34:10.140 --> 34:16.300]  прикладном берутся. Ну если вы пойдете осенью слушать спецкурс распределенной системы, то вот
[34:16.300 --> 34:20.740]  распределенные системы состоят из узлов, которые общаются друг с другом как раз по RPC. Ну вот очень
[34:20.740 --> 34:27.180]  частое явление. Практически все так и делают. Это механизм общения узлов в сети. Более
[34:27.180 --> 34:40.500]  выскоуровневый, чем просто такие синхронные сообщения не типизированные. Ну не язык, давай раз уж,
[34:40.500 --> 34:53.060]  я отвечу на твой вопрос просто чуть позже, давай. Не язык, фреймворк. Еще одно, не знаю, насколько вам
[34:53.060 --> 34:58.980]  этот пример покажется близок, пока может быть не очень. Еще одно место, еще один способ получить
[34:58.980 --> 35:05.780]  фьючи, еще один такой источник фьючи, это тайм-ауты. Тоже довольно естественно. Представлять тайм-ауты в
[35:05.780 --> 35:15.900]  своем коде в виде фьючи. Вот. Правда вы получаете уже никакой результат от Т, вы получаете статус
[35:15.900 --> 35:20.380]  и результат от Void, то есть ну никакого значения вы не получаете от таймера, разумеется. Ну вот,
[35:20.380 --> 35:26.460]  callback, будучи подвешен к такому тайм-ауту, сработает тогда, когда вот пройдет нужное время,
[35:26.460 --> 35:42.180]  полторы секунды. И смотрите, что еще, что еще интересно. Ну вот в коде с RPC мы получаем просто
[35:42.180 --> 35:52.180]  фьючо. Но у нас нигде нет промесов. Или скажем, посмотрите на пример, который я вам показывал с
[35:52.180 --> 36:00.220]  Xenomys, то есть с продолжениями с таким конвейером и синхронным. Сколько здесь промесов в коде? Вот
[36:00.220 --> 36:06.420]  здесь нет промесов. Я не помню, спрашивал или кто-то, или я бы хотел, чтобы меня, чтобы кто-нибудь
[36:06.420 --> 36:11.980]  спросил об этом. Но вот возникает вообще разумный вопрос, когда вы видите фьючи и промесы, и вам
[36:11.980 --> 36:17.100]  говорят, что это канал для передачи значения. Зачем канал у два конца отдельных? Ну это логично,
[36:17.100 --> 36:23.220]  потому что у них разные интерфейс и потоки, которые работают с одним концом и с другим,
[36:23.220 --> 36:28.660]  они в разных ролях. Но еще один повод разделить промесы фьючо, просто потому, что в прикладном
[36:28.660 --> 36:37.700]  коде промесов нет. Все промесы спрятаны. Они спрятаны в реализации RPC клиента, там каналы,
[36:37.700 --> 36:45.140]  по которому придается значение. Они спрятаны вот в сервисе, который строит таймауты. Вот где-то
[36:45.140 --> 36:52.500]  здесь. В конце концов, сам zen, вот тут же каждый zen, он приводит к тому, что появляется новая пара
[36:52.500 --> 36:57.860]  фьючо-промес, новый контракт. И вот все эти промесы, которые обслуживают вот эту цепочку,
[36:57.860 --> 37:04.740]  они тоже скрыты от вас. Так что довольно разумно ожидать, что промесов в вашем коде не будет,
[37:04.740 --> 37:09.700]  поэтому мы отделим фьючо. И вот тогда фьючо уже становится действительно не концом канала,
[37:09.700 --> 37:15.300]  которого вообще не видите, а вот они следует думать просто как о будущем значении. Это самая
[37:15.300 --> 37:29.900]  подходящая для нее интерпретация, для фьючо. Да. Ну выше, в смысле ранее, по конвейеру.
[37:29.900 --> 37:43.180]  Ну вот, с помощью фьюч можно и такое сделать, но смотрите, может возникнуть довольно разумный
[37:43.180 --> 37:49.260]  вопрос. Вообще зачем такой, ну зачем так код писать? То есть смотрите, у вас есть некоторые
[37:49.260 --> 37:55.900]  асинхронные действия, некоторые асинхронные шаги, и вы хотите выполнить их последовательно.
[37:55.900 --> 38:05.700]  И вот у вас таких вот асинхронных как бы цепочек шагов в программе, допустим,
[38:05.700 --> 38:13.740]  много для каждого клиента, у вас там свои шаги нужно пройти. Вот как бы вы последовательные
[38:13.740 --> 38:18.540]  действия композировали в своем коде, как бы вы их выразили в коде, с помощью какого инструмента?
[38:18.540 --> 38:24.580]  Ну вот удобно, когда вы вызывает, если у вас шаги последовательные, это удобно разделить их
[38:24.580 --> 38:28.260]  точкой с запятой. Вот пишете, вот ставите точку с запятой, это значит, что вот одно происходит до
[38:28.260 --> 38:34.980]  другого. Но у вас шаги асинхронные, правда, у вас там возникают какие-то фьючи. Но это вообще,
[38:34.980 --> 38:42.580]  говорю, не проблема, потому что, ну что вы делаете в таком случае? Вы говорите, вот у меня был один
[38:42.580 --> 38:52.300]  запрос, вот у меня был другой запрос, давайте я просто сделаю блокирующую операцию, она здесь
[38:52.300 --> 38:58.420]  называется Await, и вот заблокирую Fiber до тех пор, пока в фьюче не появится значение, заблокирую только Fiber.
[38:58.420 --> 39:09.820]  Ну можно даже код запустить и посмотреть, что он работает. Он, правда, много всего выведет,
[39:09.820 --> 39:17.140]  но это отдельный интересный топик, я надеюсь, про него сегодня успею поговорить. Ну вот,
[39:17.140 --> 39:23.900]  у меня первое, у меня есть два сервиса ударенных, который один speed 2 секунды возвращает bar,
[39:23.900 --> 39:28.900]  другой, ну это второй, первый speed 3 секунды возвращает foo, тест почему-то работает в нулевое время,
[39:28.900 --> 39:37.020]  что может показаться странным, но это никакого обмана. Но вот два шага происходят по очереди. Ну и вот,
[39:37.020 --> 39:42.220]  у меня было два асинхронных действия, я мог бы их запланировать через Zen, а мог бы просто написать
[39:42.220 --> 39:49.340]  точку с запятой, вот я написал точку с запятой и все. Просто я дожидаюсь фьюч в фиберах. Заблокировал
[39:49.340 --> 39:56.180]  Fiber, остановил Fiber до тех пор, пока в фьюче не появилось значение. Вот, ну и возникает вопрос,
[39:56.180 --> 40:02.020]  а зачем мы пишем инструмент, у которого есть вот асинхронные аналоги там для точки с запятой,
[40:02.020 --> 40:08.300]  для try catch, когда можно просто пользоваться вот, собственно, точкой с запятой и try catch,
[40:08.300 --> 40:16.580]  и фиберами. И фиберов тоже можно запускать много. Ну ответа здесь никакого положительного нет,
[40:16.580 --> 40:22.140]  потому что, возможно, это не самое полезное применение фьюч. Ну, по крайней мере, не то место,
[40:22.140 --> 40:30.900]  где они подходят лучше всего. Вот эти Zen-ы это последовательная композиция каких-то асинхронных
[40:30.900 --> 40:37.660]  шагов. Вот мы их исполняем друг за другом. Но кажется, что бывает и по-другому, когда мы исполняем
[40:37.660 --> 40:46.740]  шаги параллельно. Ну вот представим себе такую задачу. Мы пишем базу данных. Вот она просто,
[40:46.740 --> 40:52.980]  не знаю, она шардирована. В смысле, в ней хранится много ключей там значений, много строчек, и вот мы
[40:52.980 --> 40:57.780]  на разные машины поместили разные наборы, потому что в одну машину все не помещается. И нам приходит
[40:57.780 --> 41:03.820]  какой-то запрос, в котором нужно агрегировать очень много данных. Это означает, что, видимо,
[41:03.820 --> 41:07.460]  нужно сделать какую-то агрегацию, может быть, и какую-то предобработку, в зависимости от того,
[41:07.460 --> 41:12.540]  как там план запроса построится, оптимизируется, отдельно на разных машинах. И вот мы посылаем три
[41:12.540 --> 41:22.420]  запроса параллельно в разные машины, в разные шарды, а потом собираем все результаты. Ну опять,
[41:22.420 --> 41:33.460]  можно вызвать три запроса, потом в цикле вызвать, в цикле последовательно их дождаться. Ну вот пока
[41:33.500 --> 41:39.180]  опять можно было бы обойтись файберами, но давайте я сразу покажу, что фьючи умеют тоже это делать,
[41:39.180 --> 41:46.020]  и умеют делать это, я бы сказал, более элегантно. Смотрите, что они умеют делать. Вот мы отправили
[41:46.020 --> 41:55.060]  два запроса, а потом написали комбинатор, который называется all. Он получил две фьючи и из них
[41:55.060 --> 42:06.380]  сделал одну фьючу. Это тоже фьючи. Но только здесь каждый из фьюч возвращала, в каждой фьюче
[42:06.380 --> 42:16.380]  должен быть result от стринг, а здесь мы получили фьючу, которая... что возвращает? Result от... ну тут
[42:16.380 --> 42:20.140]  не tuple, тут для простоты вектор, потому что фьюч однородный, можно и tuple было бы себе представить,
[42:20.140 --> 42:39.780]  не важно, действительно. Ну all. All, все. Логично. Что? Ну сейчас any, не понятно, что такое any,
[42:39.780 --> 42:47.180]  как бы нужно чуть конкретнее. Вот смотрите, вот значит, во-первых, all, да, у нас были фьючи от
[42:47.180 --> 42:54.220]  int, а стало фьюча от вектора от int после комбинатора all. Ну и, что важно, этот комбинатор, он опять
[42:54.220 --> 43:00.020]  никого не дожидается, он просто строит фьюч вот моментально. Там что-то... кто-то на что-то
[43:00.020 --> 43:07.060]  подписывается, там какая-то магия происходит, получается такая одна фьюч. Другой пример. Мы
[43:07.060 --> 43:14.580]  пишем там, не знаю, поиск, сервис поиска, нам приходит запрос пользователя, он должен быть быстро
[43:14.580 --> 43:21.460]  обработан, он отправляется на какой-то back-end, где там какие-то инвертированные индексы сканируются.
[43:21.460 --> 43:27.140]  А теперь представим, что запрос попал на машину, на машину, вот наш back-end поиска, которая тормозит,
[43:27.140 --> 43:36.980]  ну вот там диск просто стал в 10 раз медленнее, и вот пользователь страдает. Как там быть? Ну,
[43:36.980 --> 43:42.540]  от медленной машины мы не можем защититься, просто сбои возникают, они возникают неизбежно,
[43:42.540 --> 43:49.780]  так что нужно не пытаться их избежать, а нужно просто сглаживать вот эти проблемы. Ну вот, мы
[43:49.780 --> 43:58.340]  как бы, мы готовы пожертвовать, ну то есть мы готовы взять на себя двойную нагрузку, но зато улучшить
[43:58.340 --> 44:04.700]  опыт пользователя. Мы получаем запрос и отправляем ее на два разных, его на два разных back-end,
[44:04.700 --> 44:10.900]  и просто дожидаемся ответа первого, самого быстрого. То есть там нам не очень подходит,
[44:10.900 --> 44:17.900]  в смысле any по семантике это какой-то, а нам не нужен any, нам нужен первый. Поэтому у нас есть еще
[44:17.900 --> 44:23.620]  один комбинатор для параллельной композиции, он называется first-off. И вот у нас здесь были две
[44:23.620 --> 44:29.020]  фьючи, одна из них отправляла запрос первому сервису, который спал три секунды, другой спал две
[44:29.020 --> 44:35.380]  секунды, и вот если сейчас взять две фьючи и скомбинировать их через first-off и дождаться этого
[44:35.380 --> 44:40.660]  самого first-off, то мы получим, видимо, я забыл, снова кто из них самый быстрый, кто медленный,
[44:40.660 --> 44:51.700]  второй быстрее, да? Тогда навернется bar. А если мы подправим здесь время работы,
[44:51.700 --> 44:57.460]  то видимо теперь будет foo.
[45:05.380 --> 45:19.260]  Это хороший вопрос. Давай чуть позже на него отвечу, если не забуду, конечно. Я уже и так один
[45:19.260 --> 45:32.500]  вопрос должен. Итак, что я хотел всем этим показать? Что есть сценарии, где комбинирование
[45:32.500 --> 45:41.620]  вычисления комбинируется параллельно непоследовательно. И вот first-off означает,
[45:41.620 --> 45:47.740]  что мы запускаем параллельно два запроса, делаем два запроса удаленных и дожидаемся вот первого,
[45:47.740 --> 45:56.380]  кто закончится раньше. И вот кажется, что адекватно такая логика, ну не то что адекватно, удобно,
[45:56.380 --> 46:06.740]  лаконично, ясно, вот такая логика через файберы не выражается. Не находите ли вы? Вот, ну ладно,
[46:06.740 --> 46:13.260]  я сейчас к этому еще вернусь перед тем, как сравнивать файберы и фьючи. Замечание, что вот
[46:13.260 --> 46:19.660]  мы с помощью фьюч научились два типа композиции делать. С одной стороны выполнять действия
[46:19.660 --> 46:25.860]  последовательно, планировать их последовательно. С другой стороны, иногда что-то распараллеливать,
[46:25.860 --> 46:35.100]  если нужно, с помощью all или first-off. First-off и all. И вот теперь мы можем планировать не только
[46:35.100 --> 46:42.780]  цепочки задач, теперь мы можем планировать, вообще говоря, графы задач. Какая-нибудь картинка
[46:42.780 --> 46:51.900]  подходящая, ну вот. И давайте я вам порекомендую просто замечательную, совершенно великолепную
[46:51.900 --> 46:56.300]  статью, которая называется e-server-the-function. Эта статья написана, ну, давным-давно уже на
[46:56.300 --> 47:02.980]  самом деле, но кажется, что она не сильно устояла. Это статья инженера твиттера про то, как они пишут
[47:02.980 --> 47:10.860]  всю свою логику. Вот они используют микросервисную архитектуру, и у них каждый сервис написан на
[47:10.860 --> 47:16.860]  фреймворке с фьючами, который называется finagle. И если что, вы можете пойти и посмотреть его,
[47:16.860 --> 47:23.180]  он, кажется, написан на скале. Там много всего, то есть, конечно же, там не только фьючие и
[47:23.180 --> 47:30.580]  промесы. Там много всякой инфраструктуры вокруг них, там метрики, трейсинг, логирование, контекста,
[47:30.580 --> 47:39.180]  ну вот, если вы знаете, что это. Но не суть. Они говорят, что вот у них вся, весь инфраструктурный
[47:39.180 --> 47:45.260]  код, он декомпозируется очень модульно на три сущности. Вот они говорят, что у них есть фьючи,
[47:45.260 --> 47:50.860]  которые представляют будущие результаты каких-то асинхронных конкурентных действий. У них есть
[47:50.860 --> 47:57.140]  сервисы, и у них есть фильтры. И вот что такое, значит, ну что такое фьючие, мы уже понимаем. Это
[47:57.140 --> 48:03.740]  результат некоторой асинхронной работы. Что такое сервис? Сервис — это асинхронная функция, оно,
[48:03.740 --> 48:11.620]  собственно, в сервисы порождают фьючие. Это локальное представление удаленного endpoint. Ну вот,
[48:11.620 --> 48:16.900]  стабы в RPC, то есть некоторое локальное представление какого-то удаленного компьютера с каким-то
[48:16.900 --> 48:24.500]  набором методов. И у нас есть фильтры, которые позволяют каким-то образом декорировать вот эти
[48:24.500 --> 48:30.220]  асинхронные операции. Там добавлять трейсинг, логирование, что-то, какой-то сбор статистики. Самые
[48:30.220 --> 48:38.660]  разные вещи. И вот вы, комбинируя все вот эти вещи, можете описывать какие-то графы, которые
[48:38.660 --> 48:44.140]  обрабатывают запросы, вызывают там какие-то цепочки вложенных RPC, собирают результаты,
[48:44.140 --> 48:52.620]  там дожидаются первого, еще чего-то такое делает. И при этом вы имеете очень модульный фреймворк из
[48:52.620 --> 48:58.540]  таких вот довольно артагональных, хорошо комбинируемых сущностей. Вот вы в этом фреймворке
[48:58.540 --> 49:06.820]  можете выразить всю свою логику. Я, кажется, ответил на вопрос, который был раньше, да, я забыл. Вот,
[49:07.300 --> 49:18.020]  то есть на фьючах, в принципе, можно все написать. И так некоторые делают. Эта статья еще очень
[49:18.020 --> 49:23.940]  хороша, потому что здесь есть интересные металонаблюдения. Вот одно из них следующее,
[49:23.940 --> 49:33.100]  мне кажется, что оно очень крутое. Смотрите, вот как можно сравнить фьюча и файберы? Ну,
[49:33.100 --> 49:39.180]  с одной стороны, это разные механизмы, да? Синхронный и асинхронный. Ну, просто API разная,
[49:39.180 --> 49:43.020]  то есть под капотом все примерно про одно и то же, про то, чтобы задачки запускать по событию,
[49:43.020 --> 49:48.860]  по мере готовности. Вот, но выглядит они очень по-разному, синхронный и асинхронный. Так вот,
[49:48.860 --> 49:57.020]  говоря про фьюча, автор статьи утверждает, что этот фреймворк, ну, в смысле этот подход,
[49:57.020 --> 50:03.380]  это средство выразительности, оно гораздо более декларативное. Ну, и вообще оно должно напоминать
[50:03.380 --> 50:08.500]  функциональное программирование, функциональный подход. Почему? Потому что, когда вы пишете,
[50:08.500 --> 50:19.100]  ну, вот смотрите, мы вот в этом коде сделали два вызова асинхронных, а потом дождались первого.
[50:19.100 --> 50:28.860]  Где в этом коде синхронизация написана? Ну, в этом коде вообще нету. Она внутри фреймворка,
[50:28.860 --> 50:34.460]  она внутри RPC, она внутри вот этих комбинаторов first-off. Вот в этом коде нет синхронизации. В этом
[50:34.460 --> 50:39.940]  коде только написано то, что мы хотим делать, то, что мы хотим получить. Мы не думаем, вот,
[50:39.940 --> 50:46.260]  утверждение. Если мы пишем на файберах то же самое, то мы думаем про control flow,
[50:46.260 --> 50:50.220]  про поток управления, про то, как файберы запускаются, как там по ним двигаются курсоры,
[50:50.220 --> 50:55.860]  как там они синхронизируются друг с другом. Вот, а в этом коде мы от control flow переходим
[50:55.860 --> 51:00.740]  к data flow, то есть мы думаем про то, как данные, ответы текут по графу. Вот у нас есть некоторый
[51:00.740 --> 51:08.220]  граф запросов, и по нему текут ответы. Собираются там, отбрасываются, что запускается там дальше. Мы
[51:08.220 --> 51:13.180]  не думаем про то, как это синхронизируется, мы не думаем там про какие-то мютексы, колбэки,
[51:13.180 --> 51:19.500]  там какие-то атомики для синхронизации. Ну короче, у нас все этой внутренней машинели здесь нет.
[51:19.500 --> 51:27.460]  Есть только то, что мы хотим сделать. Все эти, вот, все промесы, вся синхронизация, все shared
[51:27.460 --> 51:35.100]  state и все это от нас спятано. Кроме того, ну, future сама по себе, future и Zen, это же, ну,
[51:35.100 --> 51:40.460]  очень функционально. Вот если в императивном программировании мы говорим про мутацию
[51:40.540 --> 51:45.540]  состояния и в файберах мы говорим про мут разделяемое состояние, которое меняется разными потоками, то
[51:45.540 --> 51:54.540]  что происходит здесь? Здесь у нас read-only future, и мы как бы передаем одну future на выход, на вход
[51:54.540 --> 52:00.300]  следующей функции, и она получает нам, она дает другу следующую future. Это вот ровно функциональный
[52:00.300 --> 52:10.220]  способ выражать последовательные действия. Понимаете, о чем я? Вот, мне кажется, что это
[52:10.220 --> 52:16.700]  очень, ну, это очень хорошая, очень содержательная аналогия, и вот она, собственно, подчеркивает
[52:16.700 --> 52:23.020]  сильную сторону future. Но, с другой стороны, некоторые действия все же удобно выражать,
[52:23.020 --> 52:29.740]  ну, разделять точкой запятой, просто потому что они по логике последовательные. Поэтому, в общем
[52:29.740 --> 52:38.620]  случае, я бы сказал так, что есть future, есть файберы, и это просто два разных инструмента,
[52:38.620 --> 52:43.060]  которые не нужно друг другу противопоставлять. Нужно просто их использовать в комбинации,
[52:43.060 --> 52:48.420]  использовать сильные стороны одного и другого. Если у нас действия происходят подряд, асинхронные,
[52:48.420 --> 52:53.860]  ну вот, используйте файбер, точку запятой пишите, блокируйте, останавливайте его. Если у вас
[52:53.860 --> 52:58.540]  композиция параллельная, если вы там отправляете три запроса, дожидаетесь первого или там первых
[52:58.540 --> 53:05.740]  двух, что бывает часто в определенных системах, то вам удобно использовать future и комбинаторы.
[53:05.740 --> 53:12.380]  Вот что вам по смыслу задачи больше подходит, то используйте. Ну и вот осенью мы будем писать там,
[53:12.380 --> 53:18.660]  скажем, алгоритм Paxos на распределённых системах, и там алгоритм с фазами, то есть одно сделать,
[53:18.660 --> 53:23.500]  а потом другое сделать. А внутри фазы параллельная работа. И вот в одном месте нам нужны файберы,
[53:23.500 --> 53:28.340]  нам удобно файберы использовать, в другом месте нам использовать удобно future. Просто мы комбинируем
[53:28.340 --> 53:35.300]  оба подхода в зависимости от того, какой из них в данный момент больше подходит. Теперь к вопросу
[53:35.300 --> 53:43.660]  про first-off и про... То есть ты отправил два запроса, получил первый ответ, второй тебе не нужен. Вот это
[53:43.660 --> 53:48.620]  на самом деле очень тонкая, очень сложная тема, потому что я говорю вам, что вот future позволяет
[53:48.620 --> 53:54.740]  собрать граф в вычислении, по которому текут данные, и у вас здесь есть некоторое такое врожденное
[53:54.740 --> 54:00.940]  ограничение, что данные текут по стрелочкам в одном направлении, от продюсера к консюмеру. Но
[54:00.940 --> 54:06.580]  вообще говоря, вам иногда хочется передать какой-то сигнал в обратную сторону от консюмера к
[54:06.580 --> 54:15.100]  продюсеру. И вот тут уже future в таком вот голом виде вам не помогают. А вам хочется сделать такое,
[54:15.100 --> 54:22.500]  вы отправили два запроса, дождались первого, и вам уже второй не нужен. И вам нужно как-то отменить
[54:22.500 --> 54:36.900]  работу, которая синхронно происходит. Что значит сигнал? У нас действие работает вообще на разных
[54:36.900 --> 54:46.260]  машинах, у нас стек вызовов по разным машинам распределен. Какой сигнал, о чем ты? Если рассуждать
[54:46.260 --> 54:50.140]  на таком низком уровне абстракции, то, конечно, у нас есть инструкции процессора и пакеты в сети,
[54:50.260 --> 54:55.580]  но мы здесь занимаемся действием немного другом масштабе, мы изучаем средства выразительности.
[54:55.580 --> 55:02.100]  И короче, я даже не знаю, как ответить на твой вопрос, я воздержусь пока что. Нам нужен какой-то
[55:02.100 --> 55:10.100]  адекватный инструмент для того, чтобы выражать поток каких-то действий в обратном направлении,
[55:10.100 --> 55:17.620]  против того, как мы передаем от промесов к future. И вот этот сложный вопрос, он называется
[55:17.620 --> 55:27.500]  cancellation, то есть отмена действий асинхронных. Ну вот если все сложится для нас удачно,
[55:27.500 --> 55:32.020]  то мы в конце курса, может быть, в самом конце поговорим про это, про то, как такое писать. Но
[55:32.020 --> 55:39.500]  это очень сложная тема, она вот, мне кажется, не так давно начала развиваться, не так она хорошо
[55:39.500 --> 55:45.660]  развита, как сами вот эти инструменты типа fiber of future. Ладно, к этому мы еще придем. Проблема такая есть.
[55:45.660 --> 56:05.500]  Нет, ну в каком-то смысле да. Контекст, он вообще, можно по-разному его интерпретировать,
[56:05.500 --> 56:13.140]  он достаточно общий, но в том числе для этого. Для того, чтобы представить себе полную картину,
[56:13.140 --> 56:19.700]  вот честную, нужно понимать не только concurrency, нужно понимать RPC, как это все, и там вот и трейсинг
[56:19.700 --> 56:24.780]  распределенный, и как это все друг с другом интегрируется, комбинируется, это сложная задача.
[56:24.780 --> 56:29.500]  Но это скорее про осенье разговор, где мы эти инструменты будем изучать. Пока я просто обозначаю
[56:29.500 --> 56:33.140]  проблему, что нужно передавать данные в обратном направлении, для этого нужно иметь какие-то
[56:33.140 --> 56:41.980]  адекватные высокоуровневые выразительные средства. Вот future нам здесь, нас ограничивают. Ну что,
[56:41.980 --> 56:50.500]  если я объяснил про вот такие вот комбинаторы для последовательной параллельной композиции,
[56:50.500 --> 57:00.180]  про то, как что-то выражать в фьючах, я бы хотел в оставшееся время посвятить не тому,
[57:00.180 --> 57:07.500]  как что-то на фьючах, ну в смысле, как пользоваться фьючами, а тому немного про
[57:07.500 --> 57:14.460]  реализацию поговорить. Вообще говоря, реализация ложится на ваши плечи, ну поскольку домашняя будет
[57:14.460 --> 57:23.500]  про это. Но есть один нюанс, который нужно необходимо разобрать прямо сейчас. Вот вернемся к
[57:23.500 --> 57:36.100]  Subscriber. Значит, у нас есть Threadpool, у нас есть Future Promise, мы кидаем Promise в задачу в Threadpool,
[57:36.100 --> 57:47.660]  и Completing Future отправляем через Promise Set Value. В потоке снаружи Threadpoolа мы подписываемся
[57:47.660 --> 57:59.300]  на результат, вешаем обработчик. И возникает вопрос, а в каком потоке этот обработчик будет
[57:59.300 --> 58:04.580]  вызван? Ну, мы уже, кажется, выяснили, что он может быть вызван либо в одном потоке, либо в другом. Вот
[58:04.580 --> 58:15.260]  давайте это продемонстрируем. Вот у нас есть Threadpool, у нас есть поток, который, ну Main,
[58:15.260 --> 58:24.420]  который вешает обработчик, и вот мы печатаем Thread ID в основном потоке, в потоке, который
[58:24.420 --> 58:32.220]  выполняет Future, и в потоке, который вызывает Callback. Вот что мы ожидаем от этого примера? В
[58:32.220 --> 58:45.260]  каком потоке будет вызван Callback? В этом или в этом? Что значит непонятно? Понятно.
[58:45.260 --> 58:56.180]  Тут вопрос нигде мы хотим, вопрос, где он будет вызван. Вот перед вами код.
[59:03.220 --> 59:14.940]  А можешь рассуждение привести, потому что... Сейчас подожди, мы снова ничего не понимаем. Мы
[59:14.940 --> 59:19.460]  выяснили, когда вызывается Subscribe? Когда будет и Callback, ну, в смысле, когда вызывается
[59:19.460 --> 59:25.620]  обработчик? Когда будет и Callback в SharedState, и значение? То есть кто придет вторым? Кто придет
[59:25.620 --> 59:42.620]  вторым SharedState? Ну, скорее всего, Setfairy, потому что там задача положится в очередь,
[59:42.620 --> 59:47.340]  потому что нужно достать, запустить, а мы пока все это происходит, мы просто вешаем Subscribe
[59:47.340 --> 59:51.460]  довольно быстро. Ну, то есть понятно, что ответы недетерминированы, то есть непонятно,
[59:51.460 --> 01:00:16.420]  что произойдет быстрее. Но можно... Что? Спасибо. Ну вот, Callback вызвался в том же потоке,
[01:00:16.420 --> 01:00:21.380]  где был вызван Setfairy, то есть Streadpool, потому что задача выполнилась, видимо, позже, чем
[01:00:21.380 --> 01:00:29.340]  мы подвесили Callback. Вот. А теперь, что я сделаю? Я раскоммунитирую Slip4. Ну и, видимо, за секунду
[01:00:29.340 --> 01:00:33.420]  задача в Streadpool все-таки выполнится, поставить Setvalue, запускать Callback она не сможет, потому что
[01:00:33.420 --> 01:00:39.620]  его еще нет, а потом я вызову Subscribe здесь, и вот случится рандеву в SharedState, там встретится
[01:00:39.620 --> 01:00:45.220]  и продюсер... Ну, в смысле, знач... Консюмер встретится там со значением, с результатом от продюсера,
[01:00:45.220 --> 01:00:52.180]  и, видимо, сейчас Callback поменяется на... Threadedit поменяется на Subscribe.
[01:00:52.180 --> 01:01:12.580]  Ну, то есть теперь Subscribe был вызван прямо в этом потоке синхронно. Да? Понятно всем? Ну вот,
[01:01:12.580 --> 01:01:19.340]  это проблема, потому что мы не понимаем, где будет выполняться вычисление. Это довольно неприятно,
[01:01:19.340 --> 01:01:24.860]  когда мы что-то не контролируем. Но, в конце концов, зачем мы пишем на C++, чтобы контролировать,
[01:01:24.860 --> 01:01:30.980]  там, не знаю, сколько байт объект занимает, сколько там у нас аллокаций в коде, а тут мы даже не
[01:01:30.980 --> 01:01:35.060]  понимаем, в каком потоке код будет вызван. Это вообще-то проблема, потому что, ну, представьте
[01:01:35.060 --> 01:01:39.460]  себе, вы используете там какую-то стороннюю библиотеку, которая делает там асинхронный
[01:01:39.460 --> 01:01:47.340]  вот-вывод в одном потоке своем, а вы хотите к ней подвесить обработчик, который, не знаю,
[01:01:47.340 --> 01:01:52.380]  там, прочитанные данные возьмет и там будет разжимать какую-то тяжелую операцию делать,
[01:01:52.380 --> 01:01:59.700]  вычислительную. И вот в зависимости от того, как там выстроится планета, у вас этот обработчик
[01:01:59.700 --> 01:02:04.980]  может быть вызван прямо в коде библиотеки, которая однопоточная, а вы какую-то тяжелую работу там
[01:02:04.980 --> 01:02:11.940]  хотите выполнять. И вот все, у вас все застрянет. Ну, представьте, что вы планируете в колбеке ASIO
[01:02:11.940 --> 01:02:17.820]  однопоточного, допустим, какое-то тяжелое вычисление, явно не там они должны выполняться. Поэтому
[01:02:17.820 --> 01:02:23.140]  нам нужен какой-то адекватный механизм, ну, в смысле, адекватный инструмент для управления тем,
[01:02:23.140 --> 01:02:30.180]  где будет вызван обработчик. Поэтому смотрите, что мы сделаем. Мы потребуем, чтобы у Future,
[01:02:30.180 --> 01:02:41.140]  помимо методов subscribe и производных ZenRecover, был метод, который называется via. Мы могли бы
[01:02:41.140 --> 01:02:50.500]  сделать вот так. Мы говорим, что мы потребляем Future здесь, тратим ее значение, но колбек должен
[01:02:50.500 --> 01:02:58.980]  непременно быть вызван вот в этом пуле поток. И вот сейчас обработчик вешается на Future строго
[01:02:58.980 --> 01:03:04.100]  после того, ну, не строго, конечно, но скорее всего после того, как задача в пуле потока выполнится.
[01:03:04.100 --> 01:03:15.660]  Но при этом сейчас трат не будет совпадать с subscribe. Запускаем и проверяем.
[01:03:15.660 --> 01:03:32.300]  Вот вообще эта проблема, вот этот недотерминизм, который я показал, это такая врожденная проблема
[01:03:32.300 --> 01:03:38.660]  Future, хродовая травма. Вот откуда у вас в коде берется Future? Откуда она у вас появляется? Потому
[01:03:38.660 --> 01:03:45.980]  что вы вызвали какую-то асинхронную операцию. Вот если у вас появилась Future на руках, значит,
[01:03:45.980 --> 01:03:52.540]  асинхронная операция уже стартовала. Значит, она там в другом потоке что-то делает, возможно. Значит,
[01:03:52.540 --> 01:03:59.140]  вы уже гоняетесь с продюсером. Значит, непонятно, кто из вас вызовет, кто предыдущий раз стоит первым,
[01:03:59.140 --> 01:04:05.460]  кто вторым. Значит, у вас уже, вот если вы имеете на руках Future, у вас уже недотерминизм появляется.
[01:04:05.460 --> 01:04:15.300]  Где будет вызван callback? Поэтому эту проблему нужно решать. Мы ее решаем с помощью via. Но тут остается
[01:04:15.300 --> 01:04:19.980]  некоторое пространство для неаккуратного применения, потому что можно его и не написать,
[01:04:19.980 --> 01:04:26.260]  и тогда непонятно, чем дело закончится. Но вот скажем, если мы говорим про Future, который написан
[01:04:26.260 --> 01:04:37.020]  на библиотеке Folly, это библиотека общих компонентов Фейсбука, то в их Future два типа, на самом деле.
[01:04:37.020 --> 01:04:58.980]  Вот, там есть semi-future и future. Вот semi-future – это такой объект, который такой… недозрелый,
[01:04:58.980 --> 01:05:05.860]  а future, на которую вы не можете вешать callback. Просто нельзя, нет такого метода у нее.
[01:05:05.860 --> 01:05:15.780]  А метод via, он связывает Future с executioner, стредпулом, допустим, пока, условно. И только после того,
[01:05:15.780 --> 01:05:27.220]  как вы связали Future с некоторым контекстом исполнения… по тонкому льду хожу. Вот только
[01:05:27.220 --> 01:05:32.740]  после этого вы получаете возможность подвесить продолжение. То есть пока вы не укажете,
[01:05:32.740 --> 01:05:38.140]  где будет вызван callback, вы не можете вешать асинхронные продолжения для задач, для Future.
[01:05:38.140 --> 01:05:48.860]  Это называется type-state-correctness, ну, то есть такая игра с аккуратным… когда мы на уровне системы
[01:05:48.860 --> 01:05:57.220]  типов форсируем переходы только между… переходы между правильными разумными состояниями объекта.
[01:05:57.220 --> 01:06:01.860]  Просто система типов проверяет это за нас. Ну, вот мы это делаем, вводя дополнительный класс,
[01:06:01.860 --> 01:06:06.900]  что довольно неэффективно с точки зрения программирования, но все-таки позволяет получить
[01:06:06.900 --> 01:06:11.740]  более безопасное API. То есть если вы пишете библиотеку для продакшена, то она должна
[01:06:11.740 --> 01:06:20.140]  вот заставлять пользователя делать все аккуратно. Поэтому такое разделение разумно. Понятно ли это?
[01:06:20.140 --> 01:06:30.340]  Ну и дальше можно сказать, что via можно в цепочке постоянно перенастраивать, то есть мы исполняемся
[01:06:30.340 --> 01:06:37.180]  то в одном тредпуле, то в другом тредпуле, а вернее даже не в тредпуле. Вот смотрите,
[01:06:37.180 --> 01:06:47.540]  вернемся в прошлое. Мы с вами говорим, что вот здесь вот, что мы можем запланировать цепочку задач,
[01:06:47.540 --> 01:06:55.380]  и она где-то будет выполнена. Ну, там где-то мы подозреваем пул потоков какой-то, пока условно.
[01:06:55.380 --> 01:07:00.540]  С файберами та же самая история. Мы их исполняем в каком-то пуле потоков.
[01:07:00.540 --> 01:07:10.780]  А теперь, ну, то есть в конце концов, вся конкурентность – это исполнение цепочек
[01:07:10.780 --> 01:07:17.820]  задач в некотором тредпуле. А теперь подумаем, а чего же ожидают от тредпула, ну, то есть
[01:07:17.820 --> 01:07:23.380]  какой функциональности? Функциональности ожидают от тредпула и фьюча с их продолжениями,
[01:07:23.380 --> 01:07:34.420]  и там файберы с их синхронными операциями. Но и тот инструмент, и другой – это всего лишь
[01:07:34.420 --> 01:07:40.100]  вот способ выразить конкурентные активности, а исполняются они, в конце концов, в тредпуле,
[01:07:40.100 --> 01:07:48.220]  который умеет единственную операцию Submit. То есть где-то в каком-то потоке когда-то,
[01:07:48.220 --> 01:07:58.020]  когда появится возможность запустить очередную задачу. Вот больше ничего и фьюча, и файберы
[01:07:58.020 --> 01:08:04.820]  про тредпул не знают. Вот они пользуются очень простой гарантией. И вот тут-то можно подумать,
[01:08:04.820 --> 01:08:14.940]  а зачем вообще мы и фьюча, и файберы привязываем к вот некоторому конкретному тредпулу? Принципы
[01:08:15.140 --> 01:08:20.780]  говорят нам, что нужно зависеть от абстракции, не от конкретных классов. Поэтому давайте просто
[01:08:20.780 --> 01:08:29.660]  абстрагируем тот сервис, который запускает задачи. Пусть это будет не тредпул, пусть мы назовем его
[01:08:29.660 --> 01:08:40.300]  экзекьютором. Тут будет некоторый спойлер, но ничего страшного. Экзекьютор – это интерфейс,
[01:08:40.300 --> 01:08:45.340]  у которого есть один метод Execute, который исполняет просто задачи. Думайте о нем вот так вот.
[01:08:45.340 --> 01:08:54.580]  У меня по-другому написано, потому что я чуть-чуть аккуратнее сделал. Но суть вот такая. Все,
[01:08:54.580 --> 01:09:00.860]  что нужно знать и файберам, и фьючам про среду исполнения – это то, что она умеет запускать
[01:09:00.860 --> 01:09:08.500]  задачи. И вот мы эту среду исполнения абстрагируем от конкретных средств выразительности через
[01:09:09.380 --> 01:09:17.660]  такого интерфейса. Гарантия, которую он дает, что вот где-то когда-то задача будет исполнена. Как
[01:09:17.660 --> 01:09:23.660]  именно? Ни фьючам, ни файберам не интересно, не важно. Они не должны для этого зависеть.
[01:09:23.660 --> 01:09:34.820]  Понимаете идею? Мы просто вот проводим такую границу. Мы отделяем runtime среду исполнения от
[01:09:35.020 --> 01:09:40.300]  выразительности. Они теперь полностью развязаны. Граница между ними – это вот такой очень простой
[01:09:40.300 --> 01:09:44.660]  интерфейс. И простые интерфейсы – это всегда хорошо, потому что простые интерфейсы говорят,
[01:09:44.660 --> 01:09:52.100]  что декомпозиция разумная, что вещи не связаны друг с другом почти. Ну а теперь давайте подумаем,
[01:09:52.100 --> 01:10:00.500]  а какие Executers можно было бы представить вот в этом месте. Ну, первое, что приходит в голову –
[01:10:01.140 --> 01:10:09.260]  мы запускаем и файберы в threadpool, и callback, и фьюч в threadpool. Можно представить себе что-то
[01:10:09.260 --> 01:10:18.420]  другое. Вот Executor, который делает следующее. Он, получив задачу, просто сразу ее исполняет.
[01:10:18.420 --> 01:10:28.260]  Ну опять, давайте я напишу вот такой код. Это уже будет вам понятнее. Какой прок в таком Executor?
[01:10:28.260 --> 01:10:39.980]  Ну, непонятно. Вот представьте, что вы пишете фьюча, и мы говорим, что у фьюч… я где-то здесь был…
[01:10:39.980 --> 01:11:02.580]  что у фьюч есть subscribe. Ну, есть метод via, который указывает, в каком Executor будет
[01:11:02.580 --> 01:11:09.940]  вызван callback. Ну а что, если я ничего не написал? Где должен быть вызван callback? Ну, в том потоке,
[01:11:09.940 --> 01:11:15.980]  который пришел вторым. Но я же не хочу специально для этого код писать по дефолту. Я хочу просто
[01:11:15.980 --> 01:11:20.980]  подставить default на Executor. Вот inline Executor, который запускает задачу просто в том потоке,
[01:11:20.980 --> 01:11:25.940]  который вызовут Executor, это и есть дефолтное поведение для фьюч, в которых не указано via.
[01:11:25.940 --> 01:11:32.020]  Вот поток, который пришел вторым, он запланирует задачу, вот этот callback,
[01:11:32.020 --> 01:11:41.380]  на исполнение в inline Executor и просто запустит. Задача получается сам тут же. Ясно? Ну, тут вроде
[01:11:41.380 --> 01:11:48.980]  ничего сложного нет. Гораздо интереснее устроен другой Executor, который называется manual,
[01:11:48.980 --> 01:11:57.300]  ручной. Но он так называется, потому что задача в нем нужно выполнять вручную. Давайте я покажу вам
[01:11:57.300 --> 01:12:11.020]  пример. Очень просто. Встроим Executor, бросаем в него задачу, бросаем вторую задачу. Пока
[01:12:11.020 --> 01:12:17.780]  ничего не выполняется, потому что в Executor вообще нет потоков. Вот к этому моменту ни одной задачи
[01:12:17.780 --> 01:12:25.700]  не выполнена еще. А потом мы говорим, давайте запустим следующую задачу. И вот здесь мы ее
[01:12:25.700 --> 01:12:31.260]  исполняем. То есть этот Executor — это просто очередь задач. А здесь мы достаем задачу из очереди
[01:12:31.260 --> 01:12:40.540]  и исполняем ее. Ну, тут, ладно, сложный какой-то код, не хочу. Вот ровно взяли из очереди одну
[01:12:40.540 --> 01:12:48.300]  задачу и синхронно исполнили ее в этом потоке. Потом положили третью задачу, потом взяли и
[01:12:48.300 --> 01:12:58.460]  исполнили еще три. Ну вот давайте убедимся, что это работает. Ну, начинается.
[01:13:10.540 --> 01:13:29.060]  Вот видите, я запланировал две задачи, они пока не исполнялись. Вот как только я сказал Run next
[01:13:29.060 --> 01:13:35.420]  task, она выполнилась первая. То есть я достал из очереди код и запустил его. Вопрос — зачем это
[01:13:35.420 --> 01:13:51.580]  нужно? Какой толк от такого Executor? Вдруг мы хотим писать тесты для программ? Гораздо более
[01:13:51.580 --> 01:13:56.300]  естественное желание. Мы хотим тестировать код. И мы знаем, что хорошие тесты — это детерминированные
[01:13:56.300 --> 01:14:04.900]  тесты. А еще с нашими задачами проблема, потому что наши задачи — они про конкурентность. Мы
[01:14:04.940 --> 01:14:11.860]  пишем файберы, а они сами по себе, в смысле задумка их, недетерминированно исполняться. Но мы хотим
[01:14:11.860 --> 01:14:17.300]  каким-то образом написать unit-тесты для файберов. Скажем, unit-тесты для yield. Проверить поведение,
[01:14:17.300 --> 01:14:24.180]  что yield работает. Как мы это сделаем? Но мне кажется, что идея очень красивая. И вот мне кажется,
[01:14:24.180 --> 01:14:29.380]  что это может быть даже самое ценное в этом, в этой лекции. Смотрите, что мы можем сделать. Мы
[01:14:29.380 --> 01:14:35.220]  можем запустить файбер. Смотрите, мы запускаем файберы в планировщике. Вот давайте вы в вашем коде
[01:14:35.220 --> 01:14:40.460]  мысленно исправите конкретный shadular, который type alias для tradpool, на интерфейс. Но в самом деле
[01:14:40.460 --> 01:14:47.700]  ничего не поменяется. И будем запускать файберы в manual-executor. Вот мы запустим первые файберы. Тут
[01:14:47.700 --> 01:14:52.100]  нужно Go представить себе. Немного по-другому называется функция. Запускаем первый файбер,
[01:14:52.100 --> 01:14:58.300]  который делает yield. Запускаем второй файбер. И вот к этому моменту никто еще не исполняется,
[01:14:58.300 --> 01:15:06.740]  потому что executor ручной. А дальше мы говорим. Запускаем одну задачу. Эта задача — это шаг
[01:15:06.740 --> 01:15:14.580]  первого файбера. Вот он напечатает step1. А потом мы остановимся, потому что он сделал yield. Но
[01:15:14.580 --> 01:15:20.020]  если он сделал yield, если все правильно написано, то он остановился. А дальше мы напечатаем, что вот
[01:15:20.020 --> 01:15:27.500]  первый шаг сделан. Потом мы запустим еще один шаг. И что будет дальше? Видимо, если у нас код
[01:15:27.500 --> 01:15:31.780]  правильно написан, то дальше выполнится второй файбер. Сделайте свой второй шаг. В смысле свой
[01:15:31.780 --> 01:15:54.980]  первый шаг. Ну и давайте проверим, что это так. Ну вот, мы получили yield-test для файбера. По-моему,
[01:15:54.980 --> 01:16:02.140]  это впечатляюще. А дальше вы можете пойти совсем далеко. Вот про это я расскажу осенью для тех,
[01:16:02.140 --> 01:16:06.980]  кому интересно. Но мне кажется, что это совершенно грандиозная идея, что можно, в принципе,
[01:16:06.980 --> 01:16:13.500]  весь код ваш, прям вот весь продакшн написать поверх вот таких вот абстракций. И дальше
[01:16:13.500 --> 01:16:20.860]  детерминированно, однопоточно симулировать исполнение вот настоящего сложного кода. Вы
[01:16:20.860 --> 01:16:25.820]  пишете RPC framework, вы пишете framework с concurrency. Там очень много кода. Всякие каналы,
[01:16:25.820 --> 01:16:33.900]  future, синхронизация там, ну в смысле каналы RPC и такие, там синхронизация, всякие ритра и сервисы,
[01:16:33.900 --> 01:16:40.300]  огромное количество инфраструктуры. А потом вы пишете код и запускаете его. И вот он работает
[01:16:40.300 --> 01:16:48.460]  в VDE моментально и эмулирует работу двух компьютеров. Детерминированно. Вот почему я здесь запускаю
[01:16:48.460 --> 01:16:56.260]  код, который спит три секунды, а тест выполняется моментно, а пример исполняется моментально? Ну,
[01:16:56.260 --> 01:17:00.780]  потому что у меня все файберы в этом коде, которых там достаточно много, исполняются в
[01:17:00.780 --> 01:17:09.300]  manual executor. И я вот здесь, запуская вот этот код, просто кручу этот цикл руками. А когда у меня
[01:17:09.300 --> 01:17:18.140]  работы нет, то я просто двигаю вперед время. Вот у меня файбер заснул на три секунды, три секунды
[01:17:18.140 --> 01:17:23.620]  ничего не происходит. Я взял, просто часы перевел. Вот. И вот у меня код работает за нулевое время,
[01:17:23.620 --> 01:17:28.780]  в смысле эмулируется здесь за нулевое время. И вот все воспроизводимо и все детерминированно.
[01:17:28.780 --> 01:17:34.860]  Это прям вот, ну и так люди пишут, отдельные люди, которые много сил в это вложили, пишут прям
[01:17:34.860 --> 01:17:40.100]  production. Вот то есть можно написать какой-то очень сложный, очень конкурентный, очень отказоустойчивый
[01:17:40.100 --> 01:17:45.260]  код, а потом его тестировать вот с помощью такой детерминированной симуляции. Это прям безумно
[01:17:45.260 --> 01:17:50.940]  мощная идея. В нее нужно вложить очень много сил. Так делают очень немного людей в мире. Ну вот,
[01:17:50.940 --> 01:17:56.780]  мы, возможно, осенью сделаем прям совсем хорошо. В смысле, мы этим уже пользуемся осенью, а дальше,
[01:17:56.780 --> 01:18:04.340]  ну короче, я расскажу. Через полгода расскажу, кому захочется. Это, в общем, очень-очень такой
[01:18:04.340 --> 01:18:14.540]  большой, сложный, интересный план. Ну ладно, и последний. Я отниму еще три минутки. Это такое,
[01:18:14.540 --> 01:18:23.140]  как бы... То есть это все последствие того, что мы абстрагировали среду исполнения от конкретных
[01:18:23.140 --> 01:18:27.940]  средств выразительности. Вот мы можем их тестировать детерминированно. А теперь такой посторонний,
[01:18:27.940 --> 01:18:37.180]  очень клевый сюжет, мне кажется. Вот смотрите, у нас есть примеры фьюч, и в этих примерах
[01:18:37.180 --> 01:18:55.140]  возникает класс, который называется result. Что это? Что это? Result. Или ошибка, или значение,
[01:18:55.140 --> 01:19:06.460]  или ошибка. Вот есть нечто, что и result, и future объединяет. Вот смотрите, в C++ в стандартной
[01:19:06.460 --> 01:19:11.500]  библиотеке result нет. Но есть... Но он появится в каком-то виде в будущем, и вероятно, он будет
[01:19:11.500 --> 01:19:17.780]  называться expected. Это шаблон, у которого есть значение, ну, первый параметр значения,
[01:19:17.780 --> 01:19:24.900]  второй это тип ошибки, ну и либо одно, либо другое. И зачем этот класс? Ну, вы пишете какое-то
[01:19:24.900 --> 01:19:31.460]  конвейер, который берет картинку и делает из нее милого котика. Мы там сначала кропаем котика,
[01:19:31.460 --> 01:19:36.860]  потом мы там добавляем ему бабочку, потом мы каким-нибудь звездочки добавляем, вот какие-то шаги. И
[01:19:36.860 --> 01:19:42.420]  каждый шаг может завершиться либо успешно, либо ошибкой. Ну, потому что там на картинке, там,
[01:19:42.420 --> 01:19:49.380]  не знаю, тефтерия, а не кот. И в этом случае нам вернется ошибка. Если кот нашелся, нам вернется
[01:19:49.380 --> 01:19:57.140]  вот кусочек с котиком. А дальше мы организуем вот такой конвейер вот этих шагов. И кот пишется,
[01:19:57.140 --> 01:20:03.780]  ну вот как-то, не очень красиво, да? К чему это аналогия? К тому, что вот этот кот с фьючами,
[01:20:03.780 --> 01:20:10.500]  ой, с асинхронными операциями тоже выглядел не очень красиво. Ну, какая-то слабая связь,
[01:20:10.500 --> 01:20:15.580]  конечно, но я объясню, к чему я веду. А дальше смотрите, что можно сделать. А дальше можно
[01:20:15.580 --> 01:20:23.140]  сказать вот так вот, что давайте мы в expected добавим такие вот методы end-to-end. В чем смысл? Вот у
[01:20:23.140 --> 01:20:31.180]  вас предшествующая функция crypto-cat возвращала или значение, или картинку, или ошибку. А следующая
[01:20:31.180 --> 01:20:38.740]  функция ожидает именно картинку, просто картинку, без ошибок всяких. И вот этот комбинатор end-to-end,
[01:20:38.740 --> 01:20:48.060]  он бы пробрасывает значение или скипывает следующий шаг, если была ошибка. Ну, то есть такая
[01:20:48.060 --> 01:20:57.300]  еще один способ последовательно композировать вычисления. Вот map – это вызов, который композирует
[01:20:57.300 --> 01:21:05.060]  функцию, которая может сама вернуть, которая ожидает ошибку и может сама вернуть дальше. Ну, в общем,
[01:21:05.060 --> 01:21:11.300]  вы можете написать это вот так вот. Да? То есть, понимаете, общая задача, что у нас во фьючах есть
[01:21:11.300 --> 01:21:17.340]  zen, что здесь есть zen, и там, и там он возникает не потому, что это какая-то случайность,
[01:21:17.340 --> 01:21:24.260]  потому что это одна общая задача. У нас есть отдельные шаги, и нужно их связывать друг с другом.
[01:21:24.260 --> 01:21:29.460]  Почему это сложно? Потому что предшествующая функция возвращает некоторые не просто значения,
[01:21:29.460 --> 01:21:34.860]  а контейнер, result или future, то есть, будущее значение, или значение, либо ошибку. А следующая
[01:21:35.580 --> 01:21:42.300]  функция, следующий шаг, ожидает просто значения. И вот мы в этом зене прячем логику связывания.
[01:21:42.300 --> 01:21:54.380]  Вот тут можно сказать следующее, что и result, и future – это представление некоторой общей идеи,
[01:21:54.380 --> 01:22:01.300]  которая называется Monado. Слышали про это что-нибудь? Вот Monado, она как раз инкапсулирует в себе
[01:22:01.300 --> 01:22:07.060]  логику связывания. У вас есть некоторый контейнер, у вас есть некоторая функция,
[01:22:07.060 --> 01:22:13.060]  которая ожидает развернутой из контейнера значения, и вы должны определить логику, как функция,
[01:22:13.060 --> 01:22:17.980]  которая ожидает значения, обработает контейнер значения. Контейнер либо result, либо там future,
[01:22:17.980 --> 01:22:25.980]  либо что-то еще. Ну, к сожалению, в C++ нет какого-то адекватного инструмента, чтобы такую абстракцию
[01:22:25.980 --> 01:22:29.420]  выразить в языке, ну, просто в системе типов. Мне кажется, что нет разумного инструмента,
[01:22:29.460 --> 01:22:41.500]  по крайней мере, никто так не пишет. А в хаскере для этого есть инструменты, и… Ну вот, все съехало.
[01:22:41.500 --> 01:23:03.620]  У вас есть этот самый Monado, у которой огромное количество примеров, в смысле, разные объекты,
[01:23:03.620 --> 01:23:08.580]  с которыми вы хорошо знакомы, можно, видимо, надо представить. Ну и зачем я вам рассказываю про это?
[01:23:08.580 --> 01:23:12.780]  Ну, во-первых, про то, что вот все… И future, и result, и можно погрузить некоторый общий
[01:23:12.780 --> 01:23:20.660]  framework, а еще… Ну, зачем я вам это рассказываю? Затем, что… Да, вот как выглядит на хаскере,
[01:23:20.660 --> 01:23:26.940]  то есть в функциональном языке, где… в котором можно было бы жить без Monado, как бы выглядел
[01:23:26.940 --> 01:23:31.820]  код, который экваленствовал этой горе if-ов. Ну, вот в функциональном языке у вас не if,
[01:23:31.820 --> 01:23:36.580]  и у вас pattern matching. И вот как бы выглядел этот код, если бы вы писали его на функциональном
[01:23:36.580 --> 01:23:43.180]  языке. Вот как бы такая странная, развесистая конструкция. А вместо этого вы, спрятав логику
[01:23:43.180 --> 01:23:48.500]  связывания в Monado, можете написать вот такой код. Но все еще не очень понятно, что это такое,
[01:23:48.500 --> 01:23:59.220]  в смысле, не очень понятно. Ну это просто Monado, какая разница? Вот, это, в смысле, еще один
[01:23:59.220 --> 01:24:07.980]  пример, maybe, optional, тоже Monado. Тут про это и речь. Я про то говорю, что хочется иметь в языке какую-то
[01:24:07.980 --> 01:24:14.980]  синтоксическую поддержку для Monado. Чтобы не писать вот эти n-zene, вот здесь не писать zene,
[01:24:14.980 --> 01:24:27.180]  и здесь не писать zene. А чтобы просто сам язык как-то это делал, ну, в смысле, как-то выражал эту
[01:24:27.180 --> 01:24:31.940]  мысль за вас. Ну, в Хаскере это особенно актуально, потому что, ну, собственно, Monado в Хаскере — это
[01:24:31.940 --> 01:24:37.580]  некоторый способ внести императивность в функциональный язык. Собственно, задумка такая изначальная была
[01:24:37.580 --> 01:24:46.300]  в тех самых Monado. И вот в Хаскере есть специальная донотация. Это синтоксическая поддержка Monado. Вот
[01:24:46.300 --> 01:24:52.380]  за ней прячется вызов вот этой процедуры связывания вычислений, которая скрыта в конкретной Monado. В данном
[01:24:52.380 --> 01:24:59.900]  случае maybe. То есть в ней спрятано вот этот самый pattern matching. Так вот, C++, оказывается, тоже
[01:24:59.900 --> 01:25:07.780]  нечто подобное есть, и мы про это поговорим с вами, ну, где-то в апреле, во второй половине, вероятно.
[01:25:07.780 --> 01:25:13.740]  Так что, в принципе, от знания про Monado пользы некоторые имеются. Даже в C++ они в некотором
[01:25:13.740 --> 01:25:17.900]  виде поддержены. Ну что ж, на сегодня все. Спасибо вам большое.
