[00:00.000 --> 00:21.000]  Добрый день, мы продолжаем разбираться с тем, какие свойства есть у инварианта подпространств.
[00:21.000 --> 00:32.000]  Напоминаю на всякий случай, что если у вас есть линейный оператор, давайте определение напомним,
[00:32.000 --> 00:42.000]  то подпространства инварианта это означает, что вверху содержится ванку.
[00:42.000 --> 00:47.000]  И вот такие подпространства мы с вами изучаем.
[00:47.000 --> 01:02.000]  И вот утверждение, которое нам в важном, частном случае в последствии окажется очень полезным такое.
[01:03.000 --> 01:17.000]  Так пусть у нас есть на сей раз два линейных оператора phi и psi на одном и том же пространстве v,
[01:17.000 --> 01:28.000]  два линейных для образования этого пространства, причем эти операторы галнукируют.
[01:28.000 --> 01:34.000]  То есть их композиция не зависит от порядка, в котором мы ее берем.
[01:34.000 --> 01:38.000]  Phi-Psi это то же самое, что Psi-Phi.
[01:38.000 --> 01:59.000]  Тогда оказывается, что образ Psi и ядро Psi второго оператора инвариантное относительно phi.
[01:59.000 --> 02:07.000]  То есть если вы для оператора phi найдете какой-то Psi, который с ним коммутирует,
[02:07.000 --> 02:13.000]  то его образ и ядро окажутся обязательно инвариантными относительно нашего phi.
[02:13.000 --> 02:21.000]  Таким образом мы можем пополнять запас инвариантных относительно phi пространств.
[02:22.000 --> 02:29.000]  В каком важном частном случае нам это в последствии придется применять я скажу чуть попозже,
[02:29.000 --> 02:34.000]  а пока давайте мы докажем вот это вот общее утверждение.
[02:34.000 --> 02:39.000]  Ну что нам нужно проверить, давайте смотреть.
[02:39.000 --> 02:43.000]  Давайте разбираться с образом Psi.
[02:43.000 --> 02:56.000]  Нам нужно проверить следующий факт, что если вектор U лежит в образе Psi,
[02:56.000 --> 03:02.000]  то phi от него тоже лежит в этом самом образе, правильно?
[03:02.000 --> 03:07.000]  Давайте мы возьмем какой-нибудь вектор из образа.
[03:07.000 --> 03:11.000]  Ну что означает, что он лежит в образе?
[03:11.000 --> 03:18.000]  Это означает, что U это Psi от какого-то другого вектора, ну может быть другого вектора A,
[03:18.000 --> 03:21.000]  из нашего пространства.
[03:27.000 --> 03:34.000]  Ну давайте смотреть, что тогда такое будет phi от U.
[03:34.000 --> 03:38.000]  Нас интересует, чтобы он тоже попал в образ Psi.
[03:39.000 --> 03:46.000]  Ну а phi от U это есть, соответственно, phi от Psi от V.
[03:46.000 --> 03:52.000]  И коль скоро нам сказали, что вектораты коммутируют,
[03:52.000 --> 03:58.000]  ну здесь же у нас как раз и написано, композиция phi и psi, примененная к V, правильно?
[03:58.000 --> 04:02.000]  Это означает, что phi и psi мы можем переставить.
[04:02.000 --> 04:07.000]  Получается, что это Psi от phi.
[04:09.000 --> 04:17.000]  Ну а раз это так, то этот вектор несомненно лежит в образе Psi,
[04:17.000 --> 04:20.000]  мы видим, что он есть Psi от кого-то, правильно?
[04:20.000 --> 04:22.000]  Это нам и нужно было открыть.
[04:23.000 --> 04:28.000]  Все, мы выяснили, что если U лежит в образе Psi,
[04:28.000 --> 04:31.000]  то и phi от U тоже лежит в образе Psi,
[04:31.000 --> 04:38.000]  а значит он инвалид относительно phi.
[04:40.000 --> 04:44.000]  Ну ситуация с ядром не намного сложнее.
[04:46.000 --> 04:49.000]  Если мы разбираемся с ядром Psi,
[04:49.000 --> 04:59.000]  то опять же давайте выберем произвольный вектор из ядра.
[05:02.000 --> 05:08.000]  Ну это означает, что Psi от U – это нулевой вектор.
[05:09.000 --> 05:16.000]  Нас интересует, что такое phi от U, правда ли, что оно лежит в ядре Psi?
[05:18.000 --> 05:23.000]  Давайте смотреть, что такое Psi от phi от U.
[05:23.000 --> 05:26.000]  Нам бы хотелось, чтобы это был 0.
[05:27.000 --> 05:32.000]  Ну опять же такие, поскольку наши операторы перестановочные,
[05:32.000 --> 05:36.000]  они коммутируют, мы можем переставить phi и Psi местами
[05:36.000 --> 05:39.000]  и написать, что это phi от Psi от U.
[05:40.000 --> 05:43.000]  Но Psi от U – это 0,
[05:43.000 --> 05:47.000]  поэтому у нас здесь написано phi от 0,
[05:47.000 --> 05:50.000]  и хоть скоро phi – это линейный оператор,
[05:50.000 --> 05:53.000]  phi от 0 обязательно есть 0.
[05:54.000 --> 05:58.000]  И того мы поняли, что Psi обнуляет phi от U,
[05:59.000 --> 06:04.000]  но то есть действительно phi от U лежит в ядре Psi,
[06:04.000 --> 06:10.000]  и оно тоже следовательно инвариантно относительно.
[06:14.000 --> 06:19.000]  Таким образом, наше утверждение уже доказано,
[06:20.000 --> 06:29.000]  и в первую очередь нам будет важно вот какое следствие.
[06:33.000 --> 06:38.000]  Давайте мы возьмем произвольный навяжение над нашим полем.
[06:41.000 --> 06:47.000]  Поле F – это то поле, над которое наше пространство W естественно существует.
[06:50.000 --> 06:57.000]  Тогда мы можем, давайте так скажем,
[06:57.000 --> 07:01.000]  боевого линейного оператора,
[07:01.000 --> 07:05.000]  мы можем взять многочлен от этого оператора,
[07:05.000 --> 07:11.000]  мы с вами уже говорили, что такое понятие определено,
[07:11.000 --> 07:14.000]  ну и естественно этот многочлен от оператора
[07:14.000 --> 07:19.000]  будет коммутировать самим оператором,
[07:19.000 --> 07:28.000]  потому что и то, и другое – это значение на нашем операторе многочлена X умножить на D.
[07:28.000 --> 07:32.000]  Многочлены же X и P от X коммутируют друг с другом,
[07:32.000 --> 07:35.000]  значит и вот эти вот тоже будут коммутировать.
[07:35.000 --> 07:39.000]  Ну и значит, как следствие мы получаем,
[07:39.000 --> 07:45.000]  что ядро P от Phi и образ P от Phi
[07:45.000 --> 07:48.000]  в любом многочлене от нашего Phi
[07:48.000 --> 07:54.000]  инвариантно относительно Phi
[07:54.000 --> 07:57.000]  к нашему предыдущему.
[07:57.000 --> 08:08.000]  Давайте я сделаю сразу одно замечание,
[08:08.000 --> 08:15.000]  у этого следствия самая простая ситуация,
[08:15.000 --> 08:23.000]  самая простая версия будет, когда я возьму в качестве нашего многочлена
[08:24.000 --> 08:27.000]  X минус какое-то ляно.
[08:33.000 --> 08:41.000]  В этом случае P от Phi это будет Phi минус ляно,
[08:41.000 --> 08:45.000]  и кстати давайте я сразу немножко спрошу,
[08:45.000 --> 08:47.000]  а что такое Phi минус ляно?
[08:47.000 --> 08:52.000]  Как я из линейного преобразования вычитаю констант?
[08:57.000 --> 09:00.000]  Ну из матрицы я же тоже не умею вычитать скаля.
[09:05.000 --> 09:09.000]  Ну естественно, ляно имеется в виду,
[09:09.000 --> 09:21.000]  когда мы берем многочлен, скажем, от оператора
[09:21.000 --> 09:24.000]  или от какого-нибудь другого объекта,
[09:24.000 --> 09:29.000]  когда мы берем значение многочлена на каком-то элементе алгебры,
[09:29.000 --> 09:32.000]  у нас там возникает свободный член,
[09:32.000 --> 09:36.000]  который стоит воспринимать как свободный член умноженный на единицу.
[09:36.000 --> 09:43.000]  То есть Phi минус ляно это Phi минус ляно умноженное на дождевственный операт.
[09:43.000 --> 09:47.000]  Если я хочу вот этот же многочлен,
[09:47.000 --> 09:50.000]  P от X равный X минус ляно,
[09:50.000 --> 09:53.000]  применить какую-нибудь квадратную матрицу,
[09:53.000 --> 10:00.000]  то P от A это будет A минус ляно умножить на то,
[10:00.000 --> 10:04.000]  что исполняет роль единицы в алгебре-матрице,
[10:04.000 --> 10:07.000]  а что исполняет роль единицы в алгебре-матрице?
[10:07.000 --> 10:09.000]  Единичная матрица.
[10:09.000 --> 10:13.000]  Значит, я и должен написать A минус ляно умножить на них.
[10:13.000 --> 10:22.000]  В таком смысле, понимается, у нас всегда значение многочлена на матрице или, скажем, на оператора.
[10:22.000 --> 10:26.000]  Мы умножаем на единицу нашей алгебры.
[10:26.000 --> 10:30.000]  Это вполне согласуется с обычными обозначениями,
[10:30.000 --> 10:35.000]  потому что, видите, если я наш линейный оператор Phi минус ляно
[10:35.000 --> 10:39.000]  буду применять к произвольному вектору V,
[10:39.000 --> 10:41.000]  что это будет означать?
[10:41.000 --> 10:47.000]  Это означает, что я должен из Phi от V вычесть лямбда от V,
[10:47.000 --> 10:50.000]  то есть лямбда на дождевственный оператор от V,
[10:50.000 --> 10:54.000]  иначе, говоря просто, я должен вычитать минус лямбда V.
[10:54.000 --> 10:56.000]  Вычитать лямбда.
[10:56.000 --> 11:03.000]  То есть вот таким образом скобки нам тоже можно раскрывать в подобной ситуации.
[11:03.000 --> 11:10.000]  Мы видим, что для вот такого оператора
[11:10.000 --> 11:21.000]  наши соображения тоже работают, то есть ядро его и образ его тоже эмбриатны относительно Phi.
[11:21.000 --> 11:26.000]  Ну вот про этот оператор стоит сказать чуть поподробнее.
[11:26.000 --> 11:31.000]  Давайте я добавлю еще следующие два утверждения.
[11:31.000 --> 11:39.000]  Первое утверждение говорит следующую очень простую вещь.
[11:39.000 --> 11:46.000]  Если у нас Phi – это линейный оператор,
[11:46.000 --> 11:56.000]  то его ядро… Нет, извините, неправду говорю,
[11:56.000 --> 12:00.000]  точнее правду говорю, но я хочу сказать более сильную вещь.
[12:00.000 --> 12:06.000]  Любое подпространство в его ядре
[12:06.000 --> 12:21.000]  и любое надпространство его образа, то есть любое подпространство содержащее его образ
[12:21.000 --> 12:27.000]  инвариантны относительно Phi.
[12:27.000 --> 12:31.000]  То, что его ядро и его образ инвариантны относительно Phi,
[12:31.000 --> 12:35.000]  это просто выяснить, но это следует из предыдущего утверждения,
[12:35.000 --> 12:39.000]  потому что хотя бы Phi коммутирует сам с собой.
[12:39.000 --> 12:45.000]  Я делаю чуть более сильное утверждение, оно тоже простое,
[12:45.000 --> 12:53.000]  но стоит его обозначить для того, чтобы в дальнейшем мы уже могли свободно этим пользоваться.
[12:53.000 --> 12:55.000]  Доказательство очень простое.
[12:55.000 --> 13:03.000]  Еще раз, если у – это подпространство в ядре Phi,
[13:03.000 --> 13:08.000]  то что такое Phi от u?
[13:08.000 --> 13:14.000]  Все ядро переходит в ноль, поэтому и Phi от u, я могу сказать так,
[13:14.000 --> 13:21.000]  что это подмножство Phi от ядра Phi, а это ноль.
[13:21.000 --> 13:26.000]  Нулевое подпространство, ну и нулевое подпространство, естественно, содержится в u.
[13:26.000 --> 13:29.000]  Оно содержится в любом подпространстве.
[13:29.000 --> 13:32.000]  Значит, u – инвариант.
[13:32.000 --> 13:44.000]  Наоборот, если w содержит образ Phi, то что мы можем сказать про Phi от w?
[13:44.000 --> 13:53.000]  Phi от w уж точно содержится в Phi от всего v, от всего нашего пространства, правильно?
[13:53.000 --> 14:00.000]  А это и есть образ Phi, который содержится в w.
[14:00.000 --> 14:11.000]  Значит, Phi от w содержится в w, и оно тоже является инвариантом.
[14:11.000 --> 14:16.000]  Ну и последнее утверждение на эту тему.
[14:16.000 --> 14:28.000]  Как раз про оператор Phi – λ, оно нам говорит вот что.
[14:28.000 --> 14:34.000]  Итак, пусть Phi – это линейный оператор на w,
[14:34.000 --> 14:43.000]  λ – это какой-то скаля, ну а u – это какое-то подпространство uv.
[14:43.000 --> 14:55.000]  Тогда u – инвариантно относительно Phi в том и только в том случае,
[14:55.000 --> 15:00.000]  когда u – инвариантно относительно Phi – линейный оператор.
[15:00.000 --> 15:07.000]  То есть запас инвариантовых пространств для Phi и для Phi – линейного оператора – один и тот же.
[15:12.000 --> 15:18.000]  Доказательства давайте мы докажем в одну сторону.
[15:18.000 --> 15:32.000]  Пусть u – инвариантно относительно Phi, то есть Phi от u содержится в q.
[15:32.000 --> 15:35.000]  Что это означает?
[15:35.000 --> 15:41.000]  Что если я возьму любой вектор из нашего инвариантного пространства
[15:41.000 --> 15:47.000]  и применю к нему Phi – λ, то что же я получу?
[15:47.000 --> 15:50.000]  Я уже эту формулу описал.
[15:50.000 --> 15:56.000]  Это Phi от u – λу.
[15:56.000 --> 16:02.000]  По нашему предположению, Phi от u содержится в q.
[16:02.000 --> 16:09.000]  Лямда u тоже содержится в q, поскольку оно просто подпространство, правильно?
[16:09.000 --> 16:15.000]  Ну и, значит, разностей тоже содержится в q.
[16:15.000 --> 16:27.000]  То есть я доказал, что u – инвариантно и относительно Phi – линейный оператор.
[16:27.000 --> 16:35.000]  Если есть какое-либо пространство инвариантное относительно Phi, то оно инвариантное относительно Phi – линейного оператора.
[16:35.000 --> 16:41.000]  Ну а в обратную сторону можно либо повторить доказательства, либо просто заметить,
[16:41.000 --> 16:54.000]  что Phi получается из Phi – лямды с добавлением лямды, то есть вычитанием – лямды, правильно?
[16:54.000 --> 16:57.000]  И, значит, мы можем повторить то же самое рассуждение,
[16:57.000 --> 17:06.000]  можем повторить тот же самый факт для оператора Phi – лямды и константа – лямды.
[17:06.000 --> 17:09.000]  И получить то же самое, правильно?
[17:09.000 --> 17:19.000]  Если есть подпространство инвариантное относительно Phi – лямды, то оно будет инвариантное и относительно этого оператора тоже.
[17:19.000 --> 17:27.000]  То есть такая вот замена сводит кровь к первому факту.
[17:27.000 --> 17:32.000]  И таким образом наше утверждение уже доказано.
[17:32.000 --> 17:40.000]  Но вот этим фактом, особенно в сочетании с предыдущим, мы через некоторое время будем пользоваться.
[17:40.000 --> 17:51.000]  Обращаю внимание, что связка этих двух фактов нам говорит, что предыдущие утверждения работали не только для ядра и образа Phi,
[17:51.000 --> 17:56.000]  но и для ядра и образа Phi – лямда тоже, правильно?
[17:56.000 --> 18:09.000]  Они будут инвариантные относительно Phi – лямды, а, значит, любое подпространство здесь и на пространство здесь будет инвариантное относительно Phi – лямды, а, значит, и относительно этого.
[18:09.000 --> 18:15.000]  Вот как мы вскоре увидим, это нам будет очень полезно.
[18:15.000 --> 18:25.000]  Ну и вот давайте мы начнем разбираться с той теорией, в которой это оказывается очень полезно.
[18:25.000 --> 18:41.000]  Так, следующая наша тема называется собственные векторы и собственные значения.
[18:46.000 --> 18:52.000]  И источник вот этого понятия очень простой.
[18:52.000 --> 19:08.000]  Давайте мы разберемся, если у нас есть какой-то линейный оператор, что означает, что у него есть какое-то одномерное инвариантное подпространство.
[19:08.000 --> 19:19.000]  У – инвариантное относительно Phi, и размерность У равна единице.
[19:19.000 --> 19:38.000]  Что это означает? Это означает, что У порождено каким-то не нулевым вектором, и при чем Phi от этого вектора содержится в У.
[19:38.000 --> 19:46.000]  Ну, это означает, что Phi от этого вектора просто пропорционально этому.
[19:46.000 --> 19:56.000]  И вот такой вектор и называется собственным для нашего преобразования Phi.
[19:56.000 --> 20:00.000]  То есть в определении у нас звучит так.
[20:00.000 --> 20:26.000]  Пусть Phi – это линейный оператор, тогда не нулевой вектор В, естественно, из нашего пространства,
[20:30.000 --> 20:42.000]  называется собственным вектором оператора Phi.
[20:42.000 --> 21:00.000]  Если для родового таскаля лямда Phi от В есть лямда В.
[21:00.000 --> 21:10.000]  Так, это понятие мы будем употреблять так часто, что давайте мы его будем сокращать до СВ.
[21:10.000 --> 21:14.000]  Собственный вектор.
[21:14.000 --> 21:36.000]  Вот в таком случае, как я сейчас написал, мы будем говорить, что собственный вектор В соответствует скаляру лямда.
[21:36.000 --> 21:48.000]  И вот такие скаляры лямда, для которых найдется соответствующий им собственный вектор, называются собственными значениями нашего оператора.
[21:48.000 --> 22:08.000]  Итак, скаляра лямда называется собственным значением.
[22:08.000 --> 22:30.000]  Это мы будем сокращать для СВ, оператора Phi, если ему соответствует хоть один собственный вектор.
[22:30.000 --> 22:44.000]  Если существует такой, еще раз подчеркиваю, не нулевой вектор В, что Phi от него – это лямда В.
[22:44.000 --> 22:52.000]  Вот оказывается, что это очень важное понятие линейной алгебры.
[22:52.000 --> 23:09.000]  Просто потому, что если у оператора найдется достаточно много собственных векторов, то окажется, что с этим оператором достаточно просто и приятно работать.
[23:09.000 --> 23:19.000]  Скоро вы это увидите.
[23:19.000 --> 23:25.000]  Ну давайте разбираться.
[23:25.000 --> 23:41.000]  Что означает, что В – это собственный вектор с собственным значением лямда.
[23:41.000 --> 23:51.000]  Это означает, что Phi от В равно лямда В.
[23:51.000 --> 24:04.000]  Я могу все это перенести в левую часть и записать, что Phi от В минус лямда В – это ноль.
[24:04.000 --> 24:08.000]  Здесь у нас выражение, о котором мы сегодня уже пользовались.
[24:08.000 --> 24:14.000]  Здесь написано, что Phi минус лямда, примененное к В – это ноль.
[24:14.000 --> 24:22.000]  Лямда воспринимается как лямдонатождественный оператор.
[24:22.000 --> 24:25.000]  А это в свою очередь означает что?
[24:25.000 --> 24:32.000]  Что означает, что оператор Phi минус лямда обнуляет В?
[24:32.000 --> 24:37.000]  Это по-другому у нас можно назвать.
[24:37.000 --> 24:50.000]  В Л лежит в ядре этого самого Phi минус лямда.
[24:50.000 --> 25:07.000]  То есть, по сути дела, вот это вот самое ядро и состоит из всех собственных векторов, соответствующих данному собственному значению лямда.
[25:07.000 --> 25:13.000]  Оно имеет тоже специальное название.
[25:13.000 --> 25:27.000]  Пусть лямда, если лямда – это собственное значение оператора Phi,
[25:27.000 --> 25:52.000]  тогда подпространство, которое мы чаще всего будем обозначать в В с нижним индексом лямда, то есть ядро вот этого самого Phi минус лямда называется собственным подпространством.
[25:52.000 --> 26:02.000]  Ну и естественно соответствующее собственному значению лямда.
[26:02.000 --> 26:09.000]  Итак, у нас появились собственные векторы, собственное значение и собственное подпространство.
[26:09.000 --> 26:12.000]  Здесь нужно сделать маленькую уговорку.
[26:12.000 --> 26:19.000]  Конечно же собственное подпространство состоит почти только из собственных векторов соответствующих лямда,
[26:19.000 --> 26:23.000]  потому что там еще есть ноль, правильно? Он не собственный вектор.
[26:23.000 --> 26:31.000]  Ну собственно все не нулевые векторы в этом собственном подпространстве – это и есть в точности все векторы,
[26:31.000 --> 26:37.000]  ну все собственные векторы собственным значением лямда.
[26:37.000 --> 26:48.000]  Итак, вот на таком языке мы это с вами тоже переформулируем.
[26:48.000 --> 27:01.000]  Так, ну и первым делом давайте мы с вами докажем один теоретический факт, а потом перейдем к практическим вопросам.
[27:01.000 --> 27:15.000]  Ну вот здесь возникает вопрос, оправда ли, что таких лямд таких собственных значений может быть много у одного оператора.
[27:15.000 --> 27:21.000]  Ну и вот сейчас мы несколькими разными способами ответим на этот вопрос, что на самом деле,
[27:21.000 --> 27:27.000]  если у нас есть оператор на каком-то данном линейном пространстве,
[27:27.000 --> 27:37.000]  то мы, не зная ничего об этом операторе, уже можем заранее ограничить количество его собственных значений.
[27:37.000 --> 27:42.000]  То есть таких лямд у нас будет не очень много для данного оператора Фига.
[27:45.000 --> 27:52.000]  Прежде чем искать собственные векторы давайте мы докажем вот такой полезный факт.
[27:52.000 --> 28:01.000]  Итак, пусть Фи это у нас линейный оператор на пространстве В.
[28:01.000 --> 28:11.000]  Напоминаю на всякий случай, что пока что в рамках нашего разговора все пространства считаются конечно верными.
[28:11.000 --> 28:31.000]  И пусть лямда 1, лямда 2 и так далее, лямда kt это некоторые различные собственные значения оператора Фига.
[28:31.000 --> 28:38.000]  В принципе можно эту теорию применять и не ко всем собственным значениям, а лишь некоторыми, если хочется.
[28:38.000 --> 28:55.000]  Тогда у нас для каждого из этих собственных значений возникает собственное подпространство В лямда 1, В лямда 2 и так далее, В лямда kt.
[28:55.000 --> 29:03.000]  И наша теория утверждает, что сумма этих подпространств обязательно является прямой суммой.
[29:03.000 --> 29:09.000]  Я это так напишу.
[29:09.000 --> 29:23.000]  Сумма этих подпространств – это прямая сумма этих подпространств.
[29:23.000 --> 29:31.000]  Ну и отсюда давайте я уже сразу замечу. Мы это сами потом еще явным образом увидим из других собраний.
[29:31.000 --> 29:37.000]  Но уже и отсюда следует, что собственных значений у нас может быть не очень много.
[29:37.000 --> 29:49.000]  Если уж у вас есть собственное значение, это означает, что для него есть какой-то собственный вектор, то есть это подпространство хотя бы одномерно.
[29:49.000 --> 29:59.000]  Ну и не может быть у нас слишком много подпространств размерности хотя бы один, сумма которых прямая.
[29:59.000 --> 30:09.000]  Размерность этой суммы напоминает сумму их размерностей.
[30:09.000 --> 30:17.000]  Итак, давайте доказывать нашу теорию.
[30:17.000 --> 30:31.000]  Ну и для этого мы воспользуемся одним из простых критериев того, что сумма подпространств прямая.
[30:31.000 --> 30:43.000]  Сумма подпространств в Эль-Антаиде прямая, напоминаю.
[30:43.000 --> 30:57.000]  По определению это означает, что любой вектор из этой суммы однозначно раскладывается на слагаемое, каждое из которых лежит в соответствующем подпространстве.
[30:57.000 --> 31:09.000]  А критерии заключаются в том, что нулевой вектор однозначно раскладывается в такую сумму.
[31:09.000 --> 31:29.000]  Ну и существует единственный набор векторов ВИИТа, каждый из которых лежит в Эль-Антаиде, такой, что нулик это сумма этих критерий.
[31:29.000 --> 31:35.000]  Ну и этот единственный набор как он будет выглядеть? Одни нули, правильно?
[31:35.000 --> 31:41.000]  И с каждым от пространства мы должны выбрать ноль. Такое представление у нуля, напоминаю, уже точно есть.
[31:41.000 --> 31:45.000]  И вот нам нужно доказать, что другого нет.
[31:45.000 --> 32:07.000]  Давайте предположим, что это не так, что нулик разложился в сумму таких векторов.
[32:07.000 --> 32:21.000]  ВИИТ лежат в наших подпространствах, и не все ВИИТ нули.
[32:21.000 --> 32:45.000]  Ну, во-первых, давайте мы сразу скажем в этом случае, что можно считать, что все ВИИТ отлично от нуля.
[32:45.000 --> 32:57.000]  Просто если у нас в этой сумме есть какое-то нулевое слагаемое, давайте забудем про него и давайте изключим это подпространство из рассмотрения.
[32:57.000 --> 33:01.000]  Будем разбираться с остальными собственными значениями.
[33:01.000 --> 33:13.000]  То есть мы можем считать, выкинув из этой суммы нули и выкинув из рассмотрения соответствующие подпространства, что все ВИИТы не нули.
[33:13.000 --> 33:33.000]  Более того, давайте мы будем считать, ну вот у нас норма, по сути дела, разложился в сумму к не нулевых собственных векторов, соответствующих разным собственным значениям.
[33:33.000 --> 33:43.000]  И мы будем также считать, что к наименьшее возможно.
[33:43.000 --> 34:09.000]  Ну, то есть сумма к-1 не нулевого собственного вектора, соответствующих разным собственным значениям, уже обязательно не нулевого.
[34:09.000 --> 34:17.000]  Ну, просто мы выбили минимальную лекарь, для которого этого звуки.
[34:17.000 --> 34:25.000]  Давайте тогда смотреть, что это означает.
[34:25.000 --> 34:35.000]  Во-первых, 0 это сумма в 1 и так далее и в экатах.
[34:35.000 --> 34:43.000]  С другой стороны, мы с вами знаем, что фе от нуля это тоже 0.
[34:43.000 --> 34:53.000]  Фе от нуля это сумма фе от в1 и так далее плюс фе от в экатого.
[34:53.000 --> 34:59.000]  И мы знаем, кто все эти слагаемые, потому что ВИИТы это собственные векторы.
[34:59.000 --> 35:11.000]  То есть фе от V1 это лянда первая на V1 и так далее, фе от V экатого это лянда катая на V экат.
[35:11.000 --> 35:17.000]  Скажите, у вас сколько написано нулевая сумма?
[35:17.000 --> 35:25.000]  Сумма к-1 и нулевого собственного вектора с различными собственными значениями уже обязательно будет не нулевая.
[35:25.000 --> 35:31.000]  Просто если у нас найдется такой к-1 вектор, то мы возьмем их.
[35:31.000 --> 35:39.000]  Мы выбрали набор из не меньшего количества собственных векторов с разными собственными значениями, которые равны нулу.
[35:39.000 --> 35:49.000]  Какой-то такой набор есть, мы из всех таких наборов выбрали набор из минимального количества векторов.
[35:55.000 --> 36:15.000]  Для начала, наверное, я должен был сказать, давайте мы сразу заметим, что k больше единицы.
[36:15.000 --> 36:25.000]  Потому что если бы k было равно единице, то у меня здесь было бы написано 0 равно V1, а V1 не нулевой.
[36:25.000 --> 36:35.000]  Иначе 0 равен V1, который не нулевой это быть не может.
[36:35.000 --> 36:37.000]  И там k больше единицы.
[36:37.000 --> 36:51.000]  Ну и давайте мы теперь из той суммы, которая у нас получилась нулевой, вычтем исходную сумму, умноженную на лямбда 1.
[36:51.000 --> 37:01.000]  У нас есть сумма лямбда 1 V1, плюс лямбда k, а из нее я вычитаю лямбда 1.
[37:01.000 --> 37:05.000]  Давайте на лямбда k выучьем.
[37:05.000 --> 37:11.000]  Вычитаю лямбда k умножить на V1, плюс и так далее, плюс Vk.
[37:11.000 --> 37:15.000]  Я из нуля вычил 0 и, естественно, получил 0.
[37:15.000 --> 37:17.000]  А что это такое?
[37:17.000 --> 37:29.000]  Лямбда 1 минус лямбда k на V1, плюс и так далее, лямбда k минус 1 минус лямбда k на Vk.
[37:29.000 --> 37:33.000]  На Vk минус k, естественно.
[37:33.000 --> 37:39.000]  Ну и давайте смотреть, что же у нас получилось.
[37:39.000 --> 37:51.000]  Все эти векторы, катая слагаемая у нас сократилась, лямбда катая Vk сократилась, лямбда катая Vk.
[37:51.000 --> 37:55.000]  У нас получилась сумма из k минус 1 слагаемая.
[37:55.000 --> 37:59.000]  Все эти векторы не долевые.
[38:03.000 --> 38:17.000]  Все эти векторы по-прежнему собственные векторы с собственными значениями лямбда 1 и лямбда k минус 1.
[38:17.000 --> 38:23.000]  Ну потому что они получились из собственных векторов умножением на констант.
[38:23.000 --> 38:29.000]  Да, я не пояснил, наверное, что они не работают, потому что векторы выменили или выменили?
[38:29.000 --> 38:33.000]  И умножаем мы их на не 0. У нас лямбдаитые все различные.
[38:37.000 --> 38:43.000]  Итак, мы получили, что 0 – это сумма k минус 1 слагаемого,
[38:43.000 --> 38:51.000]  каждая из которых не долевой вектор, причем он собственный с собственным значением лямбда 1.
[38:51.000 --> 38:57.000]  Но это противоречит нашему выбору, это противоречит минимальности нашего k.
[38:59.000 --> 39:05.000]  Противоречие с минимальностью k.
[39:09.000 --> 39:19.000]  Мы нашли сумму k минус 1, не долевого собственного вектора с различными собственными значениями, которая долева.
[39:19.000 --> 39:25.000]  Ну и значит наша теорема уже доказана.
[39:25.000 --> 39:31.000]  Потому что они разные формулировки теоремы.
[39:31.000 --> 39:35.000]  Где у меня тут формулировка теоремы?
[39:35.000 --> 39:41.000]  Вот она, лямбда 1 и лямбда k, и я предположу, что это различные собственные значения.
[39:41.000 --> 39:48.000]  Если бы лямбда 1 было равно лямбда 2, то здесь у нас в сумме 2 раза было бы одно и то же собственное подпространство.
[39:48.000 --> 39:52.000]  Естественно сумма бы прямой тогда не была, правильно?
[39:52.000 --> 40:00.000]  Но мы считаем, что у нас лямбда различные, и вот тогда все эти подпространства образуют прямую сумму.
[40:00.000 --> 40:06.000]  Итого наша теорема доказана. Продолжим после перерыва.
[40:06.000 --> 40:10.000]  Итак, давайте двигаться дальше.
[40:10.000 --> 40:24.000]  Я обещал, что мы разберемся с тем, как искать эти самые собственные значения.
[40:24.000 --> 40:32.000]  Ну и на самом деле алгоритм поиска здесь очень простой.
[40:32.000 --> 40:40.000]  Как искать собственные значения, но и собственные векторы.
[40:40.000 --> 40:48.000]  Главный здесь вопрос, естественно, собственные значения, потому что если мы найдем собственные значения лямбда,
[40:48.000 --> 40:52.000]  то кто такие собственные векторы, мы уже знаем.
[40:52.000 --> 40:56.000]  Географ k-d.
[40:56.000 --> 41:06.000]  Вот пусть у нас, если нам оператор дам в ощущениях, он нам чаще всего запомнит какой-то матрицей,
[41:06.000 --> 41:10.000]  пусть у нас E это базис В,
[41:10.000 --> 41:16.000]  phi это по-прежнему линейное преобразование нашего В,
[41:16.000 --> 41:26.000]  и phi имеет базис E, некоторую матрицу А.
[41:26.000 --> 41:34.000]  И тогда давайте смотреть, как мы можем отловить наше собственное значение.
[41:34.000 --> 41:44.000]  Что означает, что лямбда, скаля, это собственное значение phi.
[41:44.000 --> 41:54.000]  Это означает в точности, что существует не нулевой вектор,
[41:54.000 --> 42:02.000]  такой, что phi-лямбда, примененная к этому вектору, это ноль.
[42:02.000 --> 42:06.000]  Вот я на всякий случай подробно это дело расписываю.
[42:06.000 --> 42:16.000]  Это означает, в свою очередь, что ядро phi-лямбда отлично от нуля,
[42:16.000 --> 42:38.000]  или по-другому сказать, что существует не нулевое решение того же самого уравнения, записанного в матричном виде.
[42:38.000 --> 42:42.000]  А как это уравнение будет записано в матричном виде?
[42:42.000 --> 42:46.000]  Вот у нас матрица у оператора phi-лямбда.
[42:46.000 --> 42:56.000]  Матрица phi мы ее обозначили через А, матрица лямбда это естественно лямбда E,
[42:56.000 --> 43:04.000]  потому что лямбда это лямбда на тождественный оператор, матрица тождественного оператора естественная линейная матрица E.
[43:04.000 --> 43:22.000]  Итак, вот такая вот система уравнений имеет не нулевое решение, поскольку матрица а-лямбда E квадратная,
[43:22.000 --> 43:32.000]  это происходит тогда и только тогда, когда матрица а-минус лямбда E вынуждена,
[43:32.000 --> 43:42.000]  а это означает, что ее определение не нулевое.
[43:42.000 --> 43:52.000]  Итого, лямбда является собственным значением нашего оператора phi тогда и только тогда,
[43:52.000 --> 43:58.000]  когда определитель матрица а-лямбда E равен нулю.
[43:58.000 --> 44:04.000]  Давайте поймем, что это в свою очередь значит.
[44:04.000 --> 44:26.000]  Если матрица А имеет элементы А и Ж, как обычно, то определитель матрицы а-лямбда E,
[44:26.000 --> 44:32.000]  нам для этого нужно просто выписать эту матрицу, чтобы на нее посмотреть, давайте мы это сделаем,
[44:32.000 --> 44:38.000]  мы к этой формуле еще будем сейчас в некоторое время обращаться.
[44:38.000 --> 44:40.000]  Что я должен сделать с матрицей А?
[44:40.000 --> 44:44.000]  Я должен из диагональных элементов вычесть по лямбде.
[44:44.000 --> 44:54.000]  Здесь будет А1-1 минус лямбда, А2-2 минус лямбда, вот такие вот элементы будут стоять по диагонали,
[44:54.000 --> 45:02.000]  остальные элементы останутся такими же, как были и в нашей матрице.
[45:02.000 --> 45:10.000]  Вот такой у нас определитель.
[45:10.000 --> 45:20.000]  Ну и если мы посмотрим на него как на выражение, зависище от лямбды,
[45:20.000 --> 45:30.000]  то мы немедленно видим, что это многочлен, зависище от лямбды.
[45:30.000 --> 45:38.000]  Ну хотя бы по формуле полного разложения определителя.
[45:38.000 --> 45:46.000]  Это у нас сумма N-факториал произведений, каждое произведение это многочлен от лямбды, правильно?
[45:46.000 --> 45:50.000]  Значит и все это дело, это многочлен от лямбды.
[45:50.000 --> 45:54.000]  Он носит специальное название.
[45:54.000 --> 46:06.000]  Так если у нас А это, внимание, квадратная матрица над полем F,
[46:06.000 --> 46:16.000]  тогда вот буква Хи греческая отвечает за это.
[46:16.000 --> 46:24.000]  Вот такой вот многочлен.
[46:24.000 --> 46:32.000]  Хи с индексом А от х, это определитель А-хЕ.
[46:32.000 --> 46:38.000]  Это многочлен от нашего поля F.
[46:38.000 --> 47:00.000]  Вот этот многочлен называется характеристическим многочленом матрицы А.
[47:00.000 --> 47:22.000]  Ну и таким образом, вкупе с предыдущим рассуждением, мы с вами получаем, что мы уже доказали следующее утверждение.
[47:30.000 --> 47:44.000]  Пусть Фи это линейный оператор на пространстве В, ну и в некотором базе Фи имеет матрицу А.
[47:44.000 --> 48:06.000]  Когда лямбда скаля из поля является собственным значением Фи, в том же только в том случае, когда лямбда это корень характеристического многочлена нашего матрицы этого оператора.
[48:06.000 --> 48:16.000]  Пока что это характеристический многочлен матрицы.
[48:16.000 --> 48:28.000]  Ну тут, наверное, стоит сразу сказать одну полезную вещь.
[48:28.000 --> 48:46.000]  В принципе, у нас же есть много базисов в нашем пространстве В, и у Фи мы могли взять матрицу в любом из этих базисов, получить разные матрицы, и вроде как мы могли даже получить разные характеристические многочлены.
[48:46.000 --> 49:08.000]  Но на самом деле нет полезного утверждения говорить по сути, что характеристические многочлены матрицы оператора не зависят от того, в каком базисе мы эту матрицу записываем.
[49:08.000 --> 49:36.000]  Ну то есть формально давайте я скажу так, пусть E и E' это базисы В, пусть у нас есть линейное преобразование пространства В, которое в базисе E имеет матрицу А, в базисе E' имеет матрицу H'.
[49:38.000 --> 49:52.000]  Тогда характеристические многочлены этих матриц совпадают.
[49:52.000 --> 50:05.000]  Будя доказательства, давайте вспомним, как связаны матрицы одного и того же оператора в разных базисах.
[50:05.000 --> 50:23.000]  Если E' получается из E до продолжения на матрицу перехода С, то как бы мы помним, H' это С минус 1 на А на С.
[50:23.000 --> 50:36.000]  Ну и давайте мы воспользуемся этим знанием для того, чтобы понять, кто такой характеристический многочлен матрицы H'.
[50:36.000 --> 50:45.000]  Это определитель H'-X на E, просто по определению нашего характеристического многочлена.
[50:45.000 --> 51:07.000]  H' я могу выразить как С минус 1 на А на С, ну и сделаю я всего лишь одну хитрость, вместо E я тоже напишу С минус 1 на E на С.
[51:07.000 --> 51:15.000]  Я имею право это делать, это произведение, естественно, равно H'.
[51:15.000 --> 51:38.000]  Ну теперь вот в этой разности я вполне себе имею право вынести С минус 1 за скобку слева, а С за скобку справа.
[51:38.000 --> 51:48.000]  Ну и дальше мы с вами знаем, что определитель произведения матриц это произведение определителей.
[51:48.000 --> 52:00.000]  И значит здесь у нас написано определитель S минус 1 на определитель A минус XE на определитель S.
[52:00.000 --> 52:10.000]  Но определители S минус 1 и S естественно взаимно обратны друг к другу, потому что произведение этих матриц это E.
[52:10.000 --> 52:22.000]  И значит у нас получился определитель A минус XE, то есть характеристический многочлен матрицы H'.
[52:22.000 --> 52:32.000]  Таким образом наше утверждение доказано.
[52:32.000 --> 52:50.000]  И теперь мы уже можем определить не только характеристический многочлен матрицы, но и характеристический многочлен оператора.
[52:50.000 --> 53:18.000]  Пусть phi это линейный оператор на пространстве V, тогда ему характеристический многочлен, который будет обозначаться his index of phi за X.
[53:18.000 --> 53:33.000]  Это характеристический многочлен любой его матрицы.
[53:33.000 --> 53:49.000]  Мы с вами видим, что он независит от того, в каком именно базе эту матрицу брать, то есть это понятие коллектного определения.
[53:49.000 --> 54:14.000]  Давайте в этот момент мы немножко плотнее посмотрим на нашу формулу для характеристического многочлена матрицы и выясним некоторые его коэффициенты.
[54:14.000 --> 54:27.000]  Тут стоит сразу дать еще одно определение.
[54:27.000 --> 54:54.000]  Пусть A это квадратная матрица над полем F с элементами Aежли, тогда след матрицы A определяется следующим образом.
[54:54.000 --> 55:13.000]  Она обозначается от A под слово trace, и это сумма всех ее диагональных элементов.
[55:13.000 --> 55:33.000]  Так вот давайте мы выясним, как выясним некоторые коэффициенты характеристического многочлена матрицы A.
[55:33.000 --> 55:41.000]  Давайте я сразу поясню, зачем я это делаю.
[55:41.000 --> 55:53.000]  Мы с вами поняли, что если мы взяли любые две матрицы нашего линейного оператора, то у них характеристический многочлен один и тот же.
[55:53.000 --> 56:01.000]  Это значит, что все соответствующие коэффициенты характеристических многочленов A и H3 совпадают.
[56:01.000 --> 56:10.000]  И если мы выясним смысл этих коэффициентов, то мы выясним, какие это сходства матриц A и H3.
[56:10.000 --> 56:15.000]  Это то, чем мы сейчас собираемся заняться.
[56:15.000 --> 56:19.000]  Ну давайте разбираться.
[56:19.000 --> 56:38.000]  Первым делом характеристический многочлен, давайте я еще раз напишу его.
[56:38.000 --> 56:46.000]  Как я уже говорил, эта сумма по формуле полного разложения определителя,
[56:46.000 --> 56:59.000]  эта сумма N факториал слагаемых, каждая из которых произведение N элементов нашей матрицы из разных строк и разных столбцов.
[56:59.000 --> 57:04.000]  Какая стихия будет у нашего многочлена?
[57:04.000 --> 57:15.000]  Каждый из этих сомножителей это либо константы, если он стоит на диагонали, либо линейный многочлен, если он стоит на диагонали.
[57:15.000 --> 57:26.000]  Поэтому степень нашего многочлена не может превосходить R размера нашей матрицы.
[57:26.000 --> 57:38.000]  Ну и более того, мы непосредственно видим, что у нас в нашем многочлене есть единственное место,
[57:38.000 --> 57:45.000]  из которого может получиться именно mn степени, именно xn.
[57:45.000 --> 57:52.000]  Это если мы будем перемножать N линейных сомножителей, которые стоят по диагонали.
[57:52.000 --> 58:02.000]  Значит, у нас появляется единственный член степени R, он не сильно сократится.
[58:02.000 --> 58:08.000]  И значит, вот этот xn у нас обязательно в нашем многочлене будет.
[58:08.000 --> 58:14.000]  Степень характеристического многочлена это именно N.
[58:14.000 --> 58:18.000]  И какой прием будет козицина, давайте смотреть.
[58:18.000 --> 58:26.000]  Еще раз, xv вылезет только из произведения вот этих диагональных сомножителей.
[58:26.000 --> 58:34.000]  a1n-x, a2n-x, a1n-x.
[58:34.000 --> 58:45.000]  То есть в каждой скобке он имеет элицент x-1, значит, элицент будет именно –1v.
[58:49.000 --> 58:52.000]  Давайте двигаться дальше.
[58:52.000 --> 58:59.000]  Вот, видимо, стоит двигаться на соседнюю доску, чтобы далеко не уходить.
[58:59.000 --> 59:22.000]  Итак, откуда характеристическое многочлене нашей матрицы
[59:22.000 --> 59:37.000]  может взяться слагаемая степень N-1.
[59:37.000 --> 59:41.000]  Давайте мы с вами вылезем.
[59:41.000 --> 59:48.000]  Из диагонали, то есть из произведения диагональных элементов.
[59:48.000 --> 01:00:00.000]  И внимание только оттуда, только из произведения диагональных элементов.
[01:00:00.000 --> 01:00:09.000]  Потому что, гляньте, для того чтобы у нас получился член степени N-1,
[01:00:10.000 --> 01:00:17.000]  в нашем произведении N-1 члены должны быть линейными.
[01:00:17.000 --> 01:00:24.000]  То есть N-1 член должен быть взят с диагонали.
[01:00:24.000 --> 01:00:29.000]  Ну а тогда и N-ый член методом исключения,
[01:00:29.000 --> 01:00:34.000]  мы же берем произведение N элементов из разных строк и разных столцов.
[01:00:34.000 --> 01:00:40.000]  Если мы N-1 из них взяли с диагонали, то и оставшийся определяется однозначно,
[01:00:40.000 --> 01:00:47.000]  он тоже будет с диагонали.
[01:00:47.000 --> 01:00:56.000]  То есть из А1-1-х, далее АНМ-х.
[01:00:56.000 --> 01:01:02.000]  Но в этом-то произведении мы знаем, какой коэффициент при ХВ-1.
[01:01:02.000 --> 01:01:10.000]  Здесь у нас будет минус 1 в N на ХВ, по-прежнему, плюс ХВ-1.
[01:01:10.000 --> 01:01:12.000]  Откуда он у нас возьмется?
[01:01:12.000 --> 01:01:18.000]  Мы должны из N-1 скобки взять минус х, правильно?
[01:01:18.000 --> 01:01:23.000]  И поэтому у нас наберется коэффициент минус 1 в N-1.
[01:01:23.000 --> 01:01:28.000]  А из оставшейся скобки взять константу А с индексом ИИ.
[01:01:28.000 --> 01:01:31.000]  И так мы можем сделать с любой скобкой.
[01:01:31.000 --> 01:01:36.000]  Поэтому у нас здесь будет сумма по И на И.
[01:01:36.000 --> 01:01:42.000]  Злые плюсы и так далее, плюс члены меньшего порядка.
[01:01:42.000 --> 01:01:51.000]  Итого, в нашем характеристическом многочлене мы уже знаем следующий член.
[01:01:51.000 --> 01:01:57.000]  Следующий член будет минус 1 в степени R-1.
[01:01:57.000 --> 01:02:05.000]  На след матрицы А, потому что вот это выражение, это и есть след матрицы А.
[01:02:05.000 --> 01:02:10.000]  На х в N-1.
[01:02:10.000 --> 01:02:20.000]  Сейчас я еще раз эту формулу, когда я вычислю еще один коэффициент, сейчас я еще раз ее перебью.
[01:02:20.000 --> 01:02:26.000]  И так, ну и наконец, давайте подберемся с другого кра.
[01:02:26.000 --> 01:02:33.000]  Каким будет свободный член этого многочлена?
[01:02:33.000 --> 01:02:36.000]  Ну это совсем просто.
[01:02:36.000 --> 01:02:47.000]  Свободный член характеристического многочлена, свободный член любого многочлена, это его значение в нуле.
[01:02:50.000 --> 01:02:55.000]  Ну а значение характеристического многочлена в нуле.
[01:02:55.000 --> 01:03:06.000]  Это определение А минус 0 на N, то есть определение А.
[01:03:06.000 --> 01:03:13.000]  Итого, мы с вами получили следующее утверждение.
[01:03:13.000 --> 01:03:20.000]  Характеристический многочлен матрицы А имеет следующий вид.
[01:03:20.000 --> 01:03:25.000]  Минус 1 в N на х в N.
[01:03:25.000 --> 01:03:30.000]  Плюс минус 1 в N-1.
[01:03:30.000 --> 01:03:35.000]  На след матрицы А на х в N-1.
[01:03:35.000 --> 01:03:38.000]  Плюс члены меньшего порядка.
[01:03:38.000 --> 01:03:56.000]  И в качестве свободного члена у нас стоит определение А.
[01:03:56.000 --> 01:04:14.000]  Ну и как немедленное следствие этой формулы
[01:04:14.000 --> 01:04:18.000]  Мы получаем следующее.
[01:04:18.000 --> 01:04:37.000]  Если оператор имеет в двух разных базисах матрицы А и А',
[01:04:37.000 --> 01:04:49.000]  то у этих матриц совпадают следы и совпадают определения.
[01:04:49.000 --> 01:04:57.000]  Ну просто потому что они умноженные на минус 1 в соответствующей степени
[01:04:57.000 --> 01:05:02.000]  есть коэффициенты характеристических многочленов этих матриц,
[01:05:02.000 --> 01:05:11.000]  а характеристические многочлены у них совпадают.
[01:05:11.000 --> 01:05:15.000]  И вот это утверждение у нас уже тоже доказано.
[01:05:15.000 --> 01:05:19.000]  Это соображение порой бывает очень полезным.
[01:05:19.000 --> 01:05:26.000]  Мы через некоторое время еще увидим, как оно бывает, что работает.
[01:05:26.000 --> 01:05:31.000]  Ну а пока что, коль скоро эти понятия, независимо от того,
[01:05:31.000 --> 01:05:36.000]  в каком базисе мы записываем матрицу нашего линейного оператора,
[01:05:36.000 --> 01:05:42.000]  это означает, что эти понятия связаны только с самим оператором.
[01:05:42.000 --> 01:05:50.000]  И мы можем дать, аналогично тому, как мы дали определение характеристического многочлена оператора,
[01:05:50.000 --> 01:05:53.000]  мы можем дать такое определение.
[01:05:53.000 --> 01:06:03.000]  Пусть phi, это линейное преобразование пространства В,
[01:06:03.000 --> 01:06:20.000]  тогда его след trace phi, это след любой его матрицы,
[01:06:20.000 --> 01:06:35.000]  а его определитель, давайте лучше мы будем писать det phi, это определитель любой комнаты.
[01:06:35.000 --> 01:06:49.000]  Это мы только что доказали, что эти понятия не зависят от того,
[01:06:49.000 --> 01:06:53.000]  в каком базисе мы будем эту матрицу записывать,
[01:06:53.000 --> 01:07:01.000]  и поэтому мы имеем право такое определение дать.
[01:07:02.000 --> 01:07:15.000]  Прежде чем верится дальше, я хочу оставить парочку упражнений,
[01:07:15.000 --> 01:07:23.000]  связанных с теми коэффициентами, которые вы с вами уже нашли, а также, которые еще не нашли.
[01:07:23.000 --> 01:07:33.000]  Первое упражнение, просто для того, чтобы немножко поработать со следом,
[01:07:33.000 --> 01:07:47.000]  я предлагаю доказать, что если A и B две квадратных матрицы,
[01:07:47.000 --> 01:07:55.000]  то след их произведения не зависит от того, в каком порядке мы это произведение берем.
[01:07:59.000 --> 01:08:07.000]  Ну и на самом деле я могу сказать, что это упражнение верно даже в более общей постановке.
[01:08:07.000 --> 01:08:13.000]  Если мы даже возьмем не квадратные, а прямоугольные матрицы,
[01:08:13.000 --> 01:08:17.000]  так чтобы их можно было перемножать в порядке,
[01:08:17.000 --> 01:08:23.000]  а это как раз будет означать, что эти произведения оба квадратные будут разными.
[01:08:23.000 --> 01:08:31.000]  Даже если мы возьмем прямоугольные матрицы так, чтобы следы были определены, то они тоже будут равны.
[01:08:31.000 --> 01:08:47.000]  Упражнение второе, желающее осознать, как выглядят остальные коэффициенты характеристического умногочля,
[01:08:47.000 --> 01:08:51.000]  приглашается это сделать.
[01:08:51.000 --> 01:09:11.000]  Найдите формулы для остальных коэффициентов характеристического умногочлена матрицы A,
[01:09:11.000 --> 01:09:29.000]  скажу через что выражать, выразив их через миноры матрицы A,
[01:09:29.000 --> 01:09:35.000]  миноры, напоминаю, это определители под матриц, в матрице A.
[01:09:35.000 --> 01:09:45.000]  Все эти коэффициенты выражаются через миноры матрицы A, но в качестве небольшой подсказки
[01:09:45.000 --> 01:09:55.000]  я скажу, что в нашей формуле все именно так и происходит.
[01:09:55.000 --> 01:09:59.000]  Что такое след матрицы A?
[01:09:59.000 --> 01:10:09.000]  Это сумма некоторых ее миноров размера 1 на 1, определитель под матриц размера 1 на 1, стоящих на диагонали.
[01:10:09.000 --> 01:10:13.000]  Что такое определитель матрицы A?
[01:10:13.000 --> 01:10:17.000]  Это 1 минор определитель всей матрицы NI.
[01:10:17.000 --> 01:10:25.000]  Соответственно остальные коэффициенты будут выражаться через миноры других порядков,
[01:10:25.000 --> 01:10:33.000]  и я предлагаю всем желающим понять, как именно это происходит.
[01:10:39.000 --> 01:10:43.000]  Ну а мы с вами двигаемся дальше.
[01:10:45.000 --> 01:10:53.000]  Поиск собственных значений мы с вами, по сути дела, уже осветили, мы знаем как их искать,
[01:10:53.000 --> 01:10:59.000]  и мы переходим к тому, зачем это все надо.
[01:10:59.000 --> 01:11:05.000]  И вот давайте прежде чем разбираться с общим случаем,
[01:11:05.000 --> 01:11:11.000]  давайте мы сначала разберем некоторый частный случай,
[01:11:11.000 --> 01:11:15.000]  из которого будет видно к чему мы стремимся.
[01:11:15.000 --> 01:11:21.000]  Первым делом давайте сделаем небольшое замечание.
[01:11:21.000 --> 01:11:31.000]  Если размерность В равна N, это как мы с вами видели уже означает,
[01:11:31.000 --> 01:11:37.000]  что степень характеристического многочлена равна N,
[01:11:37.000 --> 01:11:49.000]  и это означает, что у этого характеристического многочлена не более N корней.
[01:11:49.000 --> 01:11:57.000]  Даже с учетом кратности, но давайте пока без кратности.
[01:11:57.000 --> 01:12:05.000]  И вот я утверждаю, что если так вышло, что их корней равна N различных,
[01:12:05.000 --> 01:12:15.000]  то мы сразу можем описать наш линейный оператор, предъявив для него очень хорошие базы.
[01:12:15.000 --> 01:12:25.000]  Теорема, которую мы через некоторое время обобщим, но давайте пока начнем с нее.
[01:12:25.000 --> 01:12:41.000]  Пусть Фи линейный оператор на пространстве В, размерность которого равна N,
[01:12:41.000 --> 01:12:53.000]  и пусть у Фи есть N различных собственных значений.
[01:12:53.000 --> 01:13:01.000]  Давайте мы их сразу обозначим λ1 и так далее.
[01:13:01.000 --> 01:13:07.000]  Но я сразу напоминаю, N различных собственных значений это в точности означает,
[01:13:07.000 --> 01:13:13.000]  что у характеристического многочлена есть N различных корней.
[01:13:13.000 --> 01:13:17.000]  Такая у нас связь, и больше их быть не может.
[01:13:17.000 --> 01:13:39.000]  Тогда в В существует базис, состоящий из собственных векторов оператора Фи.
[01:13:39.000 --> 01:13:47.000]  Давайте мы сначала докажем теорему, а потом осознаем, чем хороша такая базис.
[01:13:47.000 --> 01:13:57.000]  Доказательства? Ну просто давайте вспомним, что мы с вами уже знаем.
[01:13:57.000 --> 01:14:09.000]  Для каждого I от 1 до N мы знаем, что λi,t это собственное значение,
[01:14:09.000 --> 01:14:21.000]  значит у него есть соответствующее собственное подпространство V с индексом λi,t
[01:14:21.000 --> 01:14:25.000]  и размерность этого собственного подпространства, хотя бы единиц,
[01:14:25.000 --> 01:14:31.000]  но поскольку хотя бы один собственный вектор для этого λi,t есть.
[01:14:31.000 --> 01:14:37.000]  Давайте посмотрим на сумму этих подпространств.
[01:14:37.000 --> 01:14:49.000]  Размерность суммы этих подпространств понята на O до N.
[01:14:49.000 --> 01:14:57.000]  Во-первых, она конечно же не больше, чем N, потому что это подпространство в нашем В.
[01:14:57.000 --> 01:15:07.000]  С другой стороны, эта же сумма прямая,
[01:15:07.000 --> 01:15:21.000]  это сумма прямая, а мы с вами знаем, что размерность прямой суммы это сумма размерностей слагаемой.
[01:15:21.000 --> 01:15:39.000]  Ну а значит, она уже как минимум сумма R единиц, то есть N.
[01:15:39.000 --> 01:15:47.000]  Что мы с вами получили? Мы с вами получили неравенство, в котором слева и справа стоят N,
[01:15:47.000 --> 01:15:53.000]  а это значит, что все эти неравенства обращаются в равенство.
[01:15:53.000 --> 01:16:21.000]  Итак, значит, все неравенства обращаются в равенство.
[01:16:21.000 --> 01:16:27.000]  Ну то есть, для ясности давайте я сразу скажу, что размерность каждого собственного подпространства
[01:16:27.000 --> 01:16:33.000]  получилась равной единице, иначе бы здесь неравенство было бы уже строгим.
[01:16:33.000 --> 01:16:45.000]  И размерность вот этой самой прямой суммы равна нему.
[01:16:45.000 --> 01:16:55.000]  Ну а это означает, что В и есть эта самая прямая сумма. У нас В есть только одно пространство размерности N.
[01:16:55.000 --> 01:17:13.000]  Ну а тогда выброс в каждом из наших пространств не нулевой вектор E и T,
[01:17:13.000 --> 01:17:23.000]  но по совместительству я сразу обращаю внимание, этот вектор и будет образовывать базис нашего одноперного подпространства, правильно?
[01:17:23.000 --> 01:17:39.000]  Мы получаем уже базис всего пространства W. Мы с вами знаем, что если пространство есть прямая сумма нескольких подпространств,
[01:17:39.000 --> 01:17:57.000]  то конкотинация их базисов это базис В. E1, E2 и так далее, En это как раз базис в пространстве W.
[01:17:57.000 --> 01:18:09.000]  Ну и он требуемый, потому что он состоит из собственных векторов нашего преобразования W.
[01:18:09.000 --> 01:18:23.000]  Теорему мы таким образом доказали, базис из собственных векторов мы построили, осталось понять, зачем это нужно.
[01:18:23.000 --> 01:18:37.000]  А вот зачем. Давайте мы посмотрим с вами на то, какой вид имеет матрица нашего оператора в этом базисе.
[01:18:37.000 --> 01:18:57.000]  Построенным базисом матрица оператора Fin имеет следующий вид. Давайте смотреть. E1 это собственный вектор собственным значением λ1.
[01:18:57.000 --> 01:19:07.000]  Иначе говоря, Fiat E, ну давайте я сразу, Fiat E1 мы с вами знаем. Это лямбда E1.
[01:19:07.000 --> 01:19:17.000]  А в нашу адресу мы должны записать, скажем, в первом столце разложение Fiat E1 по вот одному базису.
[01:19:17.000 --> 01:19:25.000]  И это разложение выглядит очень просто. Fiat E1 будет иметь координаты лямбда 1 и дальше 0.
[01:19:25.000 --> 01:19:33.000]  Fiat E2, то есть лямбда 2, E2, будет иметь координаты 0, лямбда 2, 0 и так далее.
[01:19:33.000 --> 01:19:41.000]  Ну и так далее. У нас по диагонали нашей матрицы будут написаны лямбда 1 и так далее, лямбда n.
[01:19:41.000 --> 01:19:49.000]  Во всех остальных местах будут 0. То есть матрица нашего оператора в этом базисе просто диагональна.
[01:19:49.000 --> 01:20:06.000]  С одной стороны, с этой матрицы очень просто работать. А с другой стороны, мы можем описать еще и геометрический смысл нашего оператора.
[01:20:06.000 --> 01:20:22.000]  Как он устроит? Вот у нас есть базис E1 и так далее E2, и оператор каждый из этих E-шек доножает на какую-то лямбда, правильно?
[01:20:22.000 --> 01:20:29.000]  То есть в последнее дело растягивают вдоль вот этой вот итой оси в лямбда итой раз.
[01:20:29.000 --> 01:20:44.000]  То есть геометрический смысл нашего оператора Фин, это просто, если мы его записываем вот в этом базисе собственных векторов,
[01:20:44.000 --> 01:20:59.000]  это растяжение я вдоль итой оси в лямбда итой раз.
[01:20:59.000 --> 01:21:06.000]  И так просто устроен наш оператор в случае нашей теории.
[01:21:06.000 --> 01:21:20.000]  Ну и вот после перерыва мы с вами разберемся, а когда еще мы можем матрицу оператора привести вот к такому диагональному мету, ну и получить вот такой же геометрический смысл.
[01:21:20.000 --> 01:21:22.000]  А пока перерыв.
[01:21:23.000 --> 01:21:25.000]  Так, давайте мы продолжим.
[01:21:36.000 --> 01:22:04.000]  Ну вот мы увидели, что в нашем частном случае, в случае этой теории, можно предъявить базис, в котором матрица оператора имеет диагональный вид.
[01:22:04.000 --> 01:22:11.000]  Такой оператор имеет специальное название.
[01:22:11.000 --> 01:22:31.000]  Так, пусть Фин, линейный оператор, линейное преобразование пространства В, тогда Фин называется геометризуемым,
[01:22:31.000 --> 01:22:50.000]  если, ну как раз существует базис Е в пространстве В.
[01:22:50.000 --> 01:23:06.000]  Такой, что матрица Фин в этом базисе диагональна.
[01:23:06.000 --> 01:23:22.000]  Ну то есть это означает, что все элементы кроме диагональных равны нуле. На диагонали тоже в принципе могут стремиться нули, но главное, что кроме диагонали все нули.
[01:23:22.000 --> 01:23:31.000]  Ну и на всякий случай давайте мы сразу дадим соответствующее определение для матрицы.
[01:23:31.000 --> 01:23:54.000]  Аналогично, матрица А, квадратная матрица на поле Ф называется геометризуемой.
[01:24:01.000 --> 01:24:18.000]  Если, ну по сути, если она является матрицей диагонализуемого оператора, то есть если ее можно привести к диагональному виду, вот той вот самой заменой базиса, которую мы уже вели.
[01:24:18.000 --> 01:24:34.000]  На матричном языке это означает, если она подобна диагональной матрице.
[01:24:34.000 --> 01:24:39.000]  Ну то есть давайте расшифруем на всякий случай.
[01:24:39.000 --> 01:25:03.000]  Если существует матрица перехода, то есть невыраздленная матрица МН, такая, что НС минус 1 на АНС ядовна.
[01:25:03.000 --> 01:25:19.000]  И наша ближайшая цель выяснить при каких условиях оператор Ф действительно будет диагонализуем.
[01:25:19.000 --> 01:25:35.000]  С этой целью нам придется дать еще несколько определений, которые на самом деле тесно связаны с теми необходимыми и достаточными условиями, которые у нас сейчас возникли.
[01:25:35.000 --> 01:25:45.000]  Так, первое определение такое, даже несвязанное с оператором.
[01:25:45.000 --> 01:26:01.000]  Пусть П это многочлен над полем Ф, но для определенности давайте будем считать, что степень П хотя бы единица.
[01:26:01.000 --> 01:26:24.000]  Этот многочлен называется линейно-факторизуемым, если он раскладывается на линейное содножие.
[01:26:31.000 --> 01:26:44.000]  На содножителе степени 1.
[01:26:44.000 --> 01:27:02.000]  Ну иначе говоря, если в том самом существенно единственном разложении его негативные содножители, это разложение настолько длинное, насколько возможно, оно состоит из N линейных содножителей, если степень многочлена равна N.
[01:27:02.000 --> 01:27:21.000]  Это определение, мы скоро увидим, что необходимые условия того, чтобы Ф был диагонализуемым, это то, что его характеристический повышен именно что линейно-факторизуем.
[01:27:21.000 --> 01:27:26.000]  Но это не единственное условие.
[01:27:26.000 --> 01:27:28.000]  Давайте двигаться дальше.
[01:27:28.000 --> 01:27:30.000]  Ну вот давайте на минутку.
[01:27:30.000 --> 01:27:36.000]  Слушайте, давайте мы сейчас его сразу убьем.
[01:27:36.000 --> 01:27:45.000]  Давайте мы сделаем такое замечание, прежде чем двигаться дальше, чтобы объяснить смысл этого определения.
[01:27:45.000 --> 01:28:08.000]  Если оператор диагонализуем, то есть в некотором базе E, его матрица имеет диагональный вид.
[01:28:08.000 --> 01:28:14.000]  Давайте я сразу по диагонали поставлю лямбда 1 и так далее лямбда N.
[01:28:14.000 --> 01:28:24.000]  Это уже не обязательно различная скаляра, но какие-то скаляры должны быть.
[01:28:24.000 --> 01:28:37.000]  Давайте мы посмотрим, что же тогда такое его характеристические многочлены.
[01:28:37.000 --> 01:28:40.000]  Это то же самое, что характеристические многочлены.
[01:28:40.000 --> 01:28:54.000]  Матрица A, то есть определитель вот такой вот по-прежнему диагональной матрицы.
[01:28:54.000 --> 01:29:00.000]  Ну а это есть не что ли, но как произведение ее диагональных элементов.
[01:29:00.000 --> 01:29:06.000]  Определитель диагональной матрицы мы с вами хорошо знаем.
[01:29:06.000 --> 01:29:15.000]  То есть он действительно линейно факторизуем.
[01:29:15.000 --> 01:29:29.000]  То есть линейная факторизуемость характеристического многочлена, это действительно не обходимое условие того, чтобы ФИ был диагонализуем, но не достаточно.
[01:29:29.000 --> 01:29:34.000]  Как оно может быть недостаточным?
[01:29:34.000 --> 01:29:44.000]  Если все лямбда 1 и вот здесь вот произведение различные, то мы с вами уже доказали.
[01:29:44.000 --> 01:29:48.000]  В этом случае оператор действительно диагонализуем, правильно?
[01:29:48.000 --> 01:29:54.000]  Мы нашли такой базис, в котором его матрица диагональна.
[01:29:54.000 --> 01:30:07.000]  И это значит, что единственная проблема вот в такой ситуации может быть, если некоторые из лямбда 1 вот в таком вот разложении совпадают.
[01:30:07.000 --> 01:30:15.000]  То есть если у характеристического многочлена появляются кратные курсы.
[01:30:15.000 --> 01:30:23.000]  И вот эта ситуация, которую мы сейчас с вами и собираемся изучить.
[01:30:23.000 --> 01:30:36.000]  С этой целью нам нужны еще два важных понятия.
[01:30:36.000 --> 01:30:55.000]  Итак, усть ФИ линейный оператор, усть лямбда это корень его характеристического многочлена.
[01:30:55.000 --> 01:31:02.000]  Ну то есть то же самое, что его собственное значение.
[01:31:02.000 --> 01:31:19.000]  Тогда алгебравическая кратность собственного значения лямбда.
[01:31:19.000 --> 01:31:35.000]  Это кратность корня лямбда в характеристическом многочлене нашего оператора.
[01:31:35.000 --> 01:31:41.000]  Давайте я на всякий случай сразу напомню.
[01:31:41.000 --> 01:31:57.000]  То есть если характеристический многочлен представляется в виде лямбда минус х в степени какой-то альфа умножить на q.
[01:31:57.000 --> 01:32:16.000]  Где лямбда уже не корень q, то алгебравическая кратность лямбды равна альфе.
[01:32:16.000 --> 01:32:23.000]  Вот я на всякий случай напомнил, расшифровал это определение.
[01:32:23.000 --> 01:32:34.000]  Кроме этого есть геометрическая кратность.
[01:32:34.000 --> 01:32:52.000]  Геометрической кратностью собственного значения лямбда называется просто-напросто размерность собственного подпространства соответствующего этой лямбде.
[01:32:52.000 --> 01:33:01.000]  То есть напоминаю, размерность гидравфия минус х.
[01:33:01.000 --> 01:33:10.000]  Вот такие две кратности у нашего собственного значения возникают.
[01:33:10.000 --> 01:33:16.000]  И мы сейчас выясним, что они друг с другом связаны.
[01:33:16.000 --> 01:33:27.000]  Они не обязательно совпадают, забегая вперед я скажу, но связь между ними есть.
[01:33:27.000 --> 01:33:43.000]  И чтобы прояснить эту связь, давайте я сначала докажу чуть более общее утверждение, чем нам нужно именно сейчас.
[01:33:43.000 --> 01:33:48.000]  Чуть более общее утверждение выглядит так.
[01:33:48.000 --> 01:34:15.000]  Пусть фи, это линейное преобразование пространства В, и пусть у него есть инвариатное подпространство У.
[01:34:15.000 --> 01:34:32.000]  В этом случае мы можем взять ограничение фи на У и рассмотреть его как линейное преобразование пространства У.
[01:34:32.000 --> 01:34:43.000]  Ну и таким образом у нас есть два линейных преобразования, фи и псих, разных пространств.
[01:34:43.000 --> 01:34:48.000]  И у каждого есть характеристический многочлен.
[01:34:48.000 --> 01:34:56.000]  Такое утверждение заключается в том, что характеристический многочлен ограничения на инвариантное подпространство
[01:34:56.000 --> 01:35:01.000]  делит характеристический многочлен самого фи.
[01:35:08.000 --> 01:35:19.000]  Доказательства не очень сложные. Мы с вами характеристический многочлен умеем по нормальному определять через матрицу, правильно?
[01:35:20.000 --> 01:35:29.000]  Ну а мы с вами помним, какая у нас матричная запись того, что У это инвариантное подпространство.
[01:35:29.000 --> 01:35:39.000]  Давайте мы выберем тот самый базис В, согласованный с Ум.
[01:35:40.000 --> 01:35:48.000]  Выберем базис Е1 и т.д. в пространстве В.
[01:35:51.000 --> 01:36:03.000]  Такой, что некоторые его префиксы Е1 и т.д. это базис У.
[01:36:03.000 --> 01:36:24.000]  Тогда, как мы с вами знаем, фи в базисе Е имеет блочно-треугольную матрицу, то есть матрицу вот такого вот вида, с углом 0.
[01:36:24.000 --> 01:36:37.000]  Причем матрица А, как мы с вами уже говорили, это не что иное, как матрица ФС.
[01:36:37.000 --> 01:36:49.000]  Вот в этом самом базисе, в префиксе ФС, в префиксе Е1 и т.д. имеет в точности матрицу А.
[01:36:54.000 --> 01:37:10.000]  Ну а значит, теперь мы можем выписать характеристический многошлем нашего фи при помощи вот этой самой матрицы.
[01:37:10.000 --> 01:37:28.000]  Тогда характеристический многошлем фи это определитель этой матрицы, из которой по диагонали выучили х.
[01:37:28.000 --> 01:37:43.000]  Ну давайте сразу вспомним, что у нас здесь матрица А имеет размер k на k, матрица С имеет размер l-k на l-k, то есть эти матрицы квадратные.
[01:37:43.000 --> 01:37:56.000]  И соответственно, когда я вычитаю х по диагонали этой матрицы, я по сути дела вычитаю х из диагонали матрицы А и из диагонали матрицы С.
[01:37:56.000 --> 01:38:00.000]  То есть в этом определителе она стоит следующая.
[01:38:00.000 --> 01:38:08.000]  A-XE в левом нижнем углу, когда эти вот х вышли как раз из диагонали матрицы А.
[01:38:08.000 --> 01:38:13.000]  C-XE в правом нижнем углу, аналогично.
[01:38:13.000 --> 01:38:21.000]  Матрица В и нулевая подматрица остались метод.
[01:38:21.000 --> 01:38:39.000]  Ну а тогда у нас по-прежнему написан определитель с углом 0, и значит по-прежнему определитель этой матрицы это произведение определителей вот этих вот квадратных матриц.
[01:38:39.000 --> 01:38:46.000]  Обделитель А-XE на определитель целью XE.
[01:38:46.000 --> 01:39:02.000]  Ну а определитель А-XE, коль скоро А это была матрица нашего С, это есть не что иное как характеристический нарешитель С.
[01:39:02.000 --> 01:39:14.000]  Ну и мы с вами победили, мы доказали, что характеристический нарешитель Фи есть характеристический нарешитель Си умножить на какой-то многочлен.
[01:39:14.000 --> 01:39:22.000]  Ну собственно говоря на характеристический нарешитель матрицы С.
[01:39:22.000 --> 01:39:30.000]  Это и означает, что характеристический нарешитель Си делит характеристический нарешитель Фи.
[01:39:30.000 --> 01:39:38.000]  Вот оно частное в этом многочлене.
[01:39:38.000 --> 01:39:45.000]  Как следствие мы получаем следующее.
[01:39:45.000 --> 01:39:57.000]  Пусть лямбда это собственное значение оператора Фи.
[01:39:57.000 --> 01:40:20.000]  Ну и пусть давайте его сразу обозначим, альфа и бета это его алгебраическая и геометрическая кратность в соответствии.
[01:40:20.000 --> 01:40:40.000]  Тогда альфа не меньше чем бета. То есть алгебралическая кратность любого собственного значения не меньше, чем его геометрическая кратность.
[01:40:40.000 --> 01:40:56.000]  Это доказательство. Давайте вспомним, что такое собственное подпространство, соответствующее лямбде.
[01:40:56.000 --> 01:41:07.000]  Собственное подпространство в лямбде это, как мы с вами знаем, ядро Фи-лямбда.
[01:41:07.000 --> 01:41:21.000]  Ну и вот согласно тем фактам, которые мы с вами доказывали в начале сегодняшней лекции, это ядро инвариантно относительно Фи.
[01:41:21.000 --> 01:41:44.000]  Значит, если мы положим в Си ограничение Фи на это самое в лямбда,
[01:41:44.000 --> 01:41:56.000]  то характеристический нагрешлен Си будет делить характеристический нагрешлен Фи.
[01:41:56.000 --> 01:42:10.000]  Но что такое Си? Си, значит, еще раз мы их рассматриваем как линейное преобразование нашего подпространства в лямбде.
[01:42:10.000 --> 01:42:22.000]  Что такое Си? Каждый вектор, который мы ему скармливаем, собственный вектор собственного значения в лямбде.
[01:42:22.000 --> 01:42:30.000]  Значит, Си каждый вектор умножает на лямбда.
[01:42:30.000 --> 01:42:34.000]  Си любой вектор умножает на лямбда.
[01:42:34.000 --> 01:42:40.000]  Ну, для любого вектора из нашего собственного подпространства.
[01:42:40.000 --> 01:42:46.000]  То есть, по сути дела, Си это и есть оператор умножения на лямбда.
[01:42:46.000 --> 01:42:54.000]  Мы рассматриваем только на нашем собственном подпространстве Си и есть оператор умножения на лямбда.
[01:42:54.000 --> 01:43:04.000]  Но тогда в любом базе, какой бы мы ни выбрали в нашем пространстве в лямбда,
[01:43:04.000 --> 01:43:10.000]  матрица Си это лямбда умноженная на е.
[01:43:10.000 --> 01:43:18.000]  Каждый вектор умножается на лямбда, значит там просто по диагонали стоят ямы.
[01:43:18.000 --> 01:43:24.000]  Ну и значит, давайте я все-таки вот сюда, наверное, перейду.
[01:43:24.000 --> 01:43:28.000]  Раз у меня там места немного не хватило.
[01:43:28.000 --> 01:43:48.000]  Значит, характеристический наличлен Си это есть определитель матрица лямбда е-хе.
[01:43:48.000 --> 01:44:04.000]  То есть просто набраться лямбда-е-х в степени бета, разумеется, правильно?
[01:44:04.000 --> 01:44:08.000]  У нас наше пространство в лямбда размерности бета,
[01:44:08.000 --> 01:44:14.000]  геометрическая кратность у нас так и определяется, правильно?
[01:44:14.000 --> 01:44:20.000]  Это ровно лямбда-х в степени бета.
[01:44:20.000 --> 01:44:24.000]  И мы с вами знаем, только что доказали,
[01:44:24.000 --> 01:44:36.000]  что этот самый характеристический наличлен делит характеристический наличлен всего Фи.
[01:44:36.000 --> 01:44:42.000]  Ну, мы с вами видим, что в характеристический наличлен Фи
[01:44:42.000 --> 01:44:48.000]  сомножитель лямбда-х входит хотя бы в беттной степени, правильно?
[01:44:48.000 --> 01:44:52.000]  Это и означает, что альфа хотя бы бета.
[01:44:52.000 --> 01:45:02.000]  Что кратность этого корня лямбда в нашем характеристическом наличлении хотя бы бета.
[01:45:02.000 --> 01:45:08.000]  Контрольный вопрос. Откуда может появиться строгое неравенство?
[01:45:08.000 --> 01:45:16.000]  Вот мы видели, как происходит эта делимость. Откуда может появиться строгое неравенство?
[01:45:16.000 --> 01:45:24.000]  У второй матрицы, вот у этой матрицы С, тоже может оказаться собственное значение лямбда, правильно?
[01:45:24.000 --> 01:45:29.000]  Вот у этого определителя тоже может лямбда оказаться корнем.
[01:45:29.000 --> 01:45:33.000]  И в этом случае неравенство может оказаться строго.
[01:45:35.000 --> 01:45:37.000]  Именно так.
[01:45:40.000 --> 01:45:46.000]  Итого, наше следствие уже доказано.
[01:45:46.000 --> 01:45:51.000]  И мы переходим с вами к основной теореме.
[01:45:51.000 --> 01:45:54.000]  Будем надеяться, что успеем ее доказать.
[01:45:59.000 --> 01:46:16.000]  Итак, мы с вами переходим к следующей теореме,
[01:46:16.000 --> 01:46:29.000]  которая дает нам уже критерии диагонализуемости оператора Ф.
[01:46:34.000 --> 01:46:40.000]  Ну так пусть Ф, но некоторые критерии будут совсем тривиальны.
[01:46:40.000 --> 01:46:43.000]  По сути дела мы это уже проговорили.
[01:46:43.000 --> 01:46:48.000]  Но для полноты я их тоже запишу.
[01:46:48.000 --> 01:47:01.000]  Итак, пусть Ф это линейный оператор, тогда равносильны следующие условия.
[01:47:04.000 --> 01:47:07.000]  Условие первое, к чему мы стремимся.
[01:47:08.000 --> 01:47:10.000]  Ф диагонализуем.
[01:47:14.000 --> 01:47:22.000]  Условие второе, самое полезное для практического использования.
[01:47:23.000 --> 01:47:26.000]  Характеристический многошвед Фи.
[01:47:27.000 --> 01:47:35.000]  Линейно факторизуем, то есть раскладывается на линейные совножики.
[01:47:36.000 --> 01:47:47.000]  И у каждого собственного значения нашего оператора Фи
[01:47:49.000 --> 01:47:56.000]  алгебраическая и геометрическая кратности совпадают.
[01:47:56.000 --> 01:48:04.000]  Ну и мы видели, что всегда алгебраическая не меньше, чем геометрическая.
[01:48:04.000 --> 01:48:10.000]  Для того, чтобы он был диагонализован, нам нужно, чтобы они совпадали.
[01:48:11.000 --> 01:48:25.000]  Третье условие, все пространство В раскладывается в прямую сумму собственных подпространств.
[01:48:25.000 --> 01:48:46.000]  Где лямбда 1 и так далее, лямбда ката, это все различные собственные значения оператора Фи.
[01:48:47.000 --> 01:49:01.000]  Ну и четвертое, практически равносильное первому, как мы уже видели, В, существует базис из собственных векторов операторов.
[01:49:03.000 --> 01:49:09.000]  Вот такие вот четыре условия оказываются, равносильными.
[01:49:16.000 --> 01:49:30.000]  И давайте мы это будем доказывать.
[01:49:35.000 --> 01:49:41.000]  Ну как обычно, доказательство идет по циклу.
[01:49:42.000 --> 01:49:47.000]  Утверждение из первого окружения вытекает второе.
[01:49:47.000 --> 01:50:12.000]  Если Фи диагонализуем, то есть для некоторого базиса Е, Фи имеет матрицу диагональную.
[01:50:12.000 --> 01:50:20.000]  Я обращаю внимание, что здесь на диагонали могут встречаться совпадающие собственные значения.
[01:50:20.000 --> 01:50:25.000]  То, давайте понимать.
[01:50:26.000 --> 01:50:37.000]  Во-первых, характеристики на вершине, как мы уже видели, это произведение х, извините, лямбда ита минус х.
[01:50:43.000 --> 01:50:45.000]  То есть он линейно фонаризует.
[01:50:50.000 --> 01:51:08.000]  Во-вторых, если лямбда это собственное значение нашего оператора Фи, то что такое ее алгебрическая кратность?
[01:51:08.000 --> 01:51:22.000]  То, сколько раз она встретится на диагонали, столько множителей вида лямбда минус х и встретится в этом произведении.
[01:51:22.000 --> 01:51:40.000]  Правильно? Его алгебрическая кратность это количество таких i, что лямбда ита равно i.
[01:51:45.000 --> 01:51:50.000]  Ну и пусть это индексы i1 и так далее и альфа.
[01:51:52.000 --> 01:52:00.000]  Пусть i1 и так далее и альфа, это индексы такие, что лямбда ита равно лямбда.
[01:52:01.000 --> 01:52:18.000]  Тогда из виду нашей матрицы мы получаем, что е с вот этими индексами это собственные векторы с собственным значением лямбда.
[01:52:19.000 --> 01:52:25.000]  Этот вектор при применении нашего оператора просто умножается на лямбда.
[01:52:28.000 --> 01:52:40.000]  Это означает, что в нашем собственном подпространстве уж во всяком случае содержится линейная оборужка этих векторов.
[01:52:40.000 --> 01:52:53.000]  И это означает, что в нем содержится каждая из этих векторов, а значит и вся линейная оболочка.
[01:52:54.000 --> 01:53:07.000]  Поскольку они линейно-независимые, это же векторы базис, это означает, что размерность лямбда, то есть геометрическая кратность, уж не меньше, чем алгебрическая кратность.
[01:53:10.000 --> 01:53:23.000]  Ну а поэтому эта размерность равна альфа, ибо раньше мы доказали, что превосходить она не может.
[01:53:24.000 --> 01:53:29.000]  Ну и таким образом мы проверили оба наши подтверждения.
[01:53:30.000 --> 01:53:37.000]  Характеристические многочлены линейно факторизуем, у каждого собственного значения совпали геометрическое и геометрическое.
[01:53:40.000 --> 01:53:46.000]  Дальше пойдет легче.
[01:53:56.000 --> 01:54:00.000]  Давайте заказывать 2 в 3.
[01:54:03.000 --> 01:54:05.000]  Ну а что мы уже знаем?
[01:54:05.000 --> 01:54:29.000]  Нам сказали, что характеристические многочлены линейно факторизуем, и если λ1, тогда и λк это все различные собственные значения, то это просто означает, что он представляется вот в таком виде.
[01:54:29.000 --> 01:54:38.000]  Это произведение, извините, неправильно написал, лямдониты минус х в степени альфаит.
[01:54:39.000 --> 01:54:48.000]  Во всяком случае, хоть скоро он линейно факторизуем, то он пропорционален вот этому вот произведению, правильно, там все скобки у нас будут линейные.
[01:54:49.000 --> 01:54:57.000]  Но старший инфекцент в этом произведении ровно такой, какой нужно, минус 1 в степени n, поэтому на самом деле они совпадают.
[01:54:59.000 --> 01:55:23.000]  Ну а это означает, что алгебравическая кратность лямдонитова есть альфаит, а это означает, по нашему второму свойству, что и геолитрическая кратность лямдонитова, то есть размеры собственного подпространства, тоже равна альфаитову.
[01:55:23.000 --> 01:55:45.000]  Далее, мы с вами уже знаем, что все собственные подпространства в лямдонитве образуют прямую сумму, и это означает, что размерность этой прямой суммы,
[01:55:45.000 --> 01:56:05.000]  хоть скоро сумма прямая, это опять же, как и сумма размерной степени, слагаемых, она равна сумме альфаитов, ну а сумма альфаитов это степень нашего характеристического маневерства,
[01:56:05.000 --> 01:56:18.000]  равна степени характеристического маневерства, то есть равна размерности пространства. Это мы знаем, что всегда так.
[01:56:18.000 --> 01:56:38.000]  Итого, мы поняли, что наша прямая сумма лежит в В, и ее размерности совпадают с размерностью В, это и означает, что вот эта прямая сумма в лямдонитах совпадает с В,
[01:56:38.000 --> 01:56:54.000]  и наш переход из второго в третью доказан. И с третьего в четвертый переход еще проще, как и раньше.
[01:56:54.000 --> 01:57:10.000]  Выберем в каждом в лямдонитах базис, если мы предположили, что В раскладывается в прямую сумму собственных подпространств, в каждом в лямдонитах мы выберем базис,
[01:57:10.000 --> 01:57:24.000]  и тогда их конкатенация это базис в В. Причем требуемый. Мы выбрали этот базис только из собственных подпространств,
[01:57:24.000 --> 01:57:38.000]  то есть все элементы этого базиса это собственные вещества. Ну и наконец мы выберем базис в В.
[01:57:38.000 --> 01:57:50.000]  Мы выбрали базис в В, и тогда их конкатенация это базис в В.
[01:57:51.000 --> 01:58:10.000]  Ну и наконец, из четвертого свойства В, переход мы по сути дела уже делали, давайте сделаем в всякий случай еще раз.
[01:58:10.000 --> 01:58:31.000]  Если Е, Р, В и так далее Е, это базис из собственных факторов, ну то есть ФИ от ЕИТОВА, это я на ЕИТО и она ЕИТО,
[01:58:31.000 --> 01:58:50.000]  то мы выберем, помадрится ФИ ровно в этом базисе диагонально с лямдами на диагонали. Просто это выникает непосредственно из вот этой вот санэкспрессии.
[01:58:50.000 --> 01:58:58.000]  Таким образом круг мы завершили, и наш критерий вы доказали.
[01:58:58.000 --> 01:59:13.000]  Еще раз я в заключение обращаю ваше внимание, свойство диагонализуемости оператора оно приятное тем, что во-первых с диагональной матрицей работать приятно,
[01:59:13.000 --> 01:59:20.000]  во-вторых тем, что мы понимаем ясный геометрический смысл такого оператора.
[01:59:20.000 --> 01:59:33.000]  Это просто растяжение вдоль оси, ну теперь уже возможно совпадающими факторами, совпадающими капицентными растяжениями, ну какая.
[01:59:33.000 --> 01:59:47.000]  И вот мы сами знаем, что если характеристические многочлены линейно факторизуют и кратности корней совпадают, то автоматически ровно диагонализуют.
[01:59:47.000 --> 01:59:56.000]  Ну в частности, если мы будем работать, например, над полем комплексных чисел, то первое условие выполнится естественно автоматически.
[01:59:56.000 --> 02:00:06.000]  Правильно, мы знаем, что капель многочленов на Ц расправдывается на линейные совножения, и нужно будет проверять только второе дократных кратностей.
[02:00:06.000 --> 02:00:14.000]  Вот на этом на сегодня все, в следующий раз мы поговорим о том, чего можно добиться, мы начнем разговор.
[02:00:14.000 --> 02:00:23.000]  Если хотя бы характеристические многочлены линейно факторизуем, но оператор уже не делан.
[02:00:23.000 --> 02:00:25.000]  На сегодня все.
[02:00:26.000 --> 02:00:28.000]  Спасибо.
