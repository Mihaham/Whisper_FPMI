[00:00.000 --> 00:15.760]  Здравствуйте друзья, я немного привалел, я постараюсь
[00:15.760 --> 00:18.520]  лекцию провести, но если поймешь, что в какой-то момент
[00:18.520 --> 00:23.760]  тяжело, то остановимся, давайте попробуем, на чем
[00:23.760 --> 00:25.200]  мы с вами в прошлый раз остановились.
[00:25.200 --> 00:34.760]  Я сформулировал теорему мавролапласом, и мы с вами
[00:34.760 --> 00:39.280]  разобрали ее с мыслом, примеряя там какую-то задачу.
[00:39.280 --> 00:44.200]  Но, как я говорил, давайте первую часть докажем, второе
[00:44.200 --> 00:46.480]  техническое упражнение, которое следует просто из
[00:46.480 --> 00:52.600]  первой части, представление о вероятности того, что
[00:52.600 --> 00:56.880]  ВК меньше, чем К, через сумму вероятностей, и потом
[00:56.880 --> 01:01.200]  воспользовавшись первой частью, получится большая
[01:01.200 --> 01:05.120]  сумма с растущим качеством слагаемым, но нужно просто
[01:05.120 --> 01:13.520]  прийти к интегралу этой суммы, хорошо, давайте теперь
[01:13.520 --> 01:18.240]  докажем первую часть, то есть локально поделить
[01:18.240 --> 01:23.440]  теорему, что любого К, вероятность того, что бенмярня случайно
[01:23.440 --> 01:26.800]  вечно равна К, она синтетически ведет себя как ознаменатель
[01:26.800 --> 01:33.600]  этой дроби, причем есть равномерность, вот равномерность
[01:33.600 --> 01:38.760]  именно в том смысле, в котором здесь написано, значит,
[01:38.760 --> 01:41.600]  равномерное приближение вероятности того, что их
[01:41.600 --> 01:43.960]  самая равняющая, вот этим выражением ознаменательного,
[01:43.960 --> 01:48.220]  но на самом деле это тоже несложно, достаточно вспомнить
[01:48.220 --> 01:52.620]  как записывается вероятность для бенмярного распределения,
[01:52.620 --> 01:55.380]  и там будет бенмярник, афицент, воспользуется формулой
[01:55.380 --> 02:00.380]  стиры, ну и потом какой-то анализ, давайте этим займемся.
[02:00.380 --> 02:16.780]  Так, ну, по определению бенмярного распределения
[02:16.780 --> 02:31.780]  это есть Цезен ПК, на П-степени К и на 1-1-2 степени Минск,
[02:31.780 --> 02:36.100]  Цезен ПК в свою очередь это Н-факториал, подлетно К-факториал
[02:36.100 --> 02:45.060]  и на Н-минску Факториал, вот, ну и дальше давайте
[02:45.060 --> 02:52.060]  вспомним формулу стиринга, которая говорит, чему асимпатический
[02:52.060 --> 02:53.780]  равен факториал натурального числа.
[02:53.780 --> 03:10.820]  Ну, формул выглядит так, значит, N-факториал, это есть
[03:11.820 --> 03:25.620]  умножить на Н-факторию степени Н, да, и еще умножить на 1
[03:25.620 --> 03:31.860]  плюс некоторую там функцию дельта Т, где дельта Т есть
[03:31.860 --> 03:40.180]  побольшой от 1 до 9, да, то есть дельта Т можно ограничить
[03:40.180 --> 03:45.940]  некоторыми Ц1 поделить на Н снизу и Ц2 поделить на Н сверху.
[03:45.940 --> 03:56.780]  Вот. Месяца 11 и 2 это какие-то константы, это формул
[03:56.780 --> 04:07.180]  с пределами для всех N. Ну, значит, чему-то равна вероятность того,
[04:07.180 --> 04:09.820]  что ихса равняется К, давайте перепишем ее через формулу стиринга.
[04:09.820 --> 04:23.460]  Есть корень из 2ПН, может, на N поделить на E в степени N, на 1 плюс дельта от N.
[04:23.460 --> 04:36.500]  Знаменателя корень из 2ПК может на К поделить на E в степени К, на корень из 2ПН минус К,
[04:36.500 --> 04:48.100]  может, на N минус К поделить на E в степени N. Ну, еще там 1 плюс дельта от K, да, и 1 плюс дельта от N.
[04:59.700 --> 05:01.140]  И остается П в степени К,
[05:01.140 --> 05:13.620]  на 1 минус П в степени N. Вот, давайте теперь вспомним, какое ограничение мы наложили на К.
[05:13.620 --> 05:27.380]  Вот, значит, К не сильно отличается от Np, К отличается от Np не больше,
[05:27.380 --> 05:34.340]  чем на O мало, это степень 2,3. Да, но это значит, что при стремлении N бесконечности,
[05:34.340 --> 05:42.020]  К и N минус К тоже стремятся к бесконечности. Пусть К стремится к бесконечности,
[05:42.020 --> 05:55.300]  и N минус К стремится к бесконечности. Это значит, что вот эти вот множители,
[05:55.300 --> 06:02.820]  1 плюс дельта от N, 1 плюс дельта от K, 1 плюс дельта от N минус К, они стремятся к единице.
[06:02.820 --> 06:09.780]  Причем стремятся равномерно по K, да, так как у нас есть равномерная оценка на функцию дельта по всем
[06:09.780 --> 06:16.060]  N, мы знаем, что дельта от N лежит между C1 и 9 на N. Стремление всех этих множителей к единице,
[06:16.060 --> 06:23.980]  оно равномерное по всем K, и поэтому мы сейчас просто смело можем выкинуть эти множители,
[06:23.980 --> 06:31.140]  и работать с оставшимся выражением, для этого, конечно, равномерно приближается вот тем выражением,
[06:31.140 --> 06:39.340]  которое знаменито было написано. Давайте из выражений перепишем.
[06:39.340 --> 06:47.860]  Во-первых, там что-то сокращается. Остается, значит, один 9 на корень из двух P,
[06:47.860 --> 06:52.980]  может быть, на корень из N поделить на K и на N минус K.
[06:52.980 --> 07:03.980]  Ешки все сокращаются, да, остается N в степне N поделить на K в степне K и на N в степне N в степне K.
[07:03.980 --> 07:10.620]  Еще есть по в степне K и на 1 минус по в степне N в степне N в степне K.
[07:10.620 --> 07:19.660]  Так, это выражение тоже немного преобразуем, вытащим в ознаменатель корень из двух Pm,
[07:19.660 --> 07:31.660]  и перепишем второй множитель следующим образом, как единица поделить на корень из K поделить на N,
[07:31.700 --> 07:35.020]  умножить на 1 минус K поделить на N.
[07:35.020 --> 07:43.140]  Значит, следующее выражение, вот здесь в числе N в степне N стоит,
[07:43.140 --> 07:49.540]  давайте разобьем N в степне N на два множителя, N в степне K и N в степне N минус K.
[07:49.540 --> 08:09.420]  Понятно, что получится вот что, N поделить на K в степне K, умножить на N 1 минус P поделить на N минус K в степне N минус K.
[08:09.420 --> 08:19.500]  Теперь давайте посмотрим на K поделить на N. Я напомню, что K это асимпатически Np,
[08:19.500 --> 08:24.700]  K от Np отличается на умалое от N в степне D3, поэтому вот эта штука стремится к P.
[08:24.700 --> 08:33.700]  Ну а второй множитель стремится к 1 минус P, причем опять же сходимость равномерная по всем K,
[08:33.700 --> 08:41.020]  потому что у нас K равномерно ограничено, то есть мы ограничили модуль разности между K и N,
[08:41.020 --> 08:46.100]  по некоторым умалому от N в степне D3, поэтому эта сходимость к P от 1 минус P тоже равномерная,
[08:46.100 --> 08:53.860]  мы тоже можем смело сейчас заменить эти выражения на P на 1 минус P и работать в составшемся выражении,
[08:53.860 --> 09:01.100]  что и сделаем. Что получается? Получается 1 поделить на корень из 2 P N,
[09:02.620 --> 09:08.260]  P от 1 минус P. Да, это уже в точности то, что стоит у вас в локальной теории.
[09:08.260 --> 09:14.460]  Вот там дрог именно такая, потом некоторые экспоненты, вот значит оставшееся выражение нам
[09:14.460 --> 09:30.260]  нужен экспонент. Так, давайте его и заменим на экспоненту, еще вынесем минус M. Еще вынесем минус M,
[09:30.260 --> 09:39.700]  значит что-то останется. Будет логариф вот этой всей дроби, деленной на N. Если мы берем логариф,
[09:39.700 --> 09:44.180]  у нас получается степень, умноженная на логариф, выражение которой по знакам степени
[09:44.580 --> 09:52.500]  будет вот что будет как поделить на M. Логарифм как поделить на M, деленный на P.
[09:52.500 --> 10:07.620]  Плюс M минус K поделить на M, умножить на логарифм,
[10:07.620 --> 10:25.100]  1 минус K поделить на M, поделить на 1 минус P. Вот, прекрасно. И давайте,
[10:25.100 --> 10:40.300]  значит, ведем функцию f от x равная x лог x поделить на P, плюс 1 минус x лог от 1 минус x поделить на 1 минус P.
[10:40.300 --> 10:50.260]  Кому-то эта функция может быть знакомая из какого-нибудь дискретного анализа. И тогда,
[10:50.340 --> 10:55.980]  видя такой функции, мы можем переписать наше выражение как 1 поделить на корень из 2 P N P 1 минус P,
[11:00.820 --> 11:13.140]  экспонента от минус N умножить на f от K поделить на N. Вот, давайте поведение этой функции следуем.
[11:13.140 --> 11:26.900]  Ну, во-первых, чему равно f от P? f от P очевидно равно нулю. Да, если в оба логарифа поставить
[11:26.900 --> 11:34.740]  текло, у вас получится гайв поделиться, что равно нулю. Значит, я планирую разложить эту функцию в ряд
[11:34.740 --> 11:43.980]  трейлеры, в точке P. Для этого мне еще нужно несколько производов этой точки. Давайте
[11:43.980 --> 12:02.780]  сначала найдем первый продукт функции f. Что-то будет логарифом от x поделить на P, плюс 1,
[12:02.780 --> 12:08.540]  минус логариф от 1 минус x поделить на 1 минус P.
[12:08.540 --> 12:23.140]  А почему плюс 1, а не плюс P? Я дифференцирую второй множитель, умножаю его на x.
[12:23.140 --> 12:33.260]  От этого логарифма. Ну, давайте на него посмотрим, как она разрастает. Да, это же лог x минус лог P.
[12:33.260 --> 12:49.780]  Поэтому производы от него это 1 поделить на x. Умножим на x, получу 1. Ну, проделав то же самое со
[12:49.780 --> 12:55.020]  вторыми слогами, я получу, значит, минус лог от 1 минус x поделить на 1 минус P и минус 1.
[12:55.020 --> 13:02.580]  Единицы сокращаются, остается разность таких логарифов. Понятно, что в точке P это тоже 0.
[13:02.580 --> 13:16.100]  Да, потому что опять по логарифам у вас будет 1. Хорошо, давайте теперь найдем
[13:16.100 --> 13:25.700]  вторую производную. Производная от логарифма, ну опять, значит, лог от x поделить на P это разность
[13:25.700 --> 13:38.260]  логарифов, поэтому получаем просто 1 поделить на x. Плюс 1 поделить на 1 минус x. Ну и что-то
[13:38.260 --> 13:54.340]  же самое, 1 поделить на x, 1 минус x. Туда поставим точку P, мы получаем 1 поделить на P на 1 минус P.
[13:54.340 --> 14:09.420]  Ну, прекрасно, значит, можем попробовать разложить гряд Тейлора и получим вот что, получим что f от x
[14:09.420 --> 14:20.860]  равно, но первых двух слогаемых не будет, да, потому что коэффициент на уровне. Значит, 1,
[14:20.860 --> 14:42.140]  2, x минус P в квадрате умножить на 1 поделить на P минус P. Плюс 1 большое от x минус P в
[14:42.140 --> 14:48.620]  квадрате умножить на 1 поделить на P минус P. Ну, это большое, у всех лиц можно равномерно граничных
[14:48.620 --> 14:56.020]  константов. Вот, то есть, я к чему планирую эти планирую, потому что если мы сейчас поставим
[14:56.020 --> 15:00.940]  его в наше выражение, увидим, что он дает какой-то маленький вклад, тогда, то есть, маленький вклад
[15:00.940 --> 15:08.940]  можно равномерно, опять же, оценивать и на нашу асимфонию. Давайте проделаем. Возвращаемся к нашим
[15:08.940 --> 15:26.380]  выражениям. Один поделить на поре между P и N, P и 1 минус P, экспонента от минус N, f от k поделить на N.
[15:39.900 --> 15:43.900]  Ну, подставив разложение в ряд тейлоры, мы получим вот что.
[15:43.900 --> 16:04.860]  Получим вот что. Экспонента от минус N пополам. Точнее, давайте не так напишем. От минус N может на
[16:04.860 --> 16:17.620]  k поделить на N минус P в квадрате, поделить на 2P и N минус P. Ну вот, еще плюс этого большое,
[16:17.620 --> 16:37.380]  от k поделить на N минус P. Ну и давайте немного преобразуем. В принципе, все уже почти готово.
[16:37.380 --> 16:56.860]  Значит, здесь приведем в числителе разность между k поделить на N, P пополчу на знаменателю,
[16:56.860 --> 17:03.620]  получим k минус N, P в квадрате. А N квадрат пойдет в знаменатель, сократится с N,
[17:03.620 --> 17:14.900]  и останется 2N, P и 1 минус P. Прекрасно, это в точности то выражение, которое у нас написано в
[17:14.900 --> 17:23.300]  формулировке теории. Осталось избавиться от того, что он действительно малов. Если мы точно также
[17:23.300 --> 17:38.960]  запихаем N в числителе, мы получим по большой от дрови k минус N, P в квадрате. Ну вот здесь
[17:38.960 --> 17:49.540]  становится понятно, зачем нам то, что модуль k минус N, P меньше, чем фиатр. Да, значит, вот это
[17:49.540 --> 17:56.540]  O большое, это есть, так как k минус N, P помодуль меньше, чем фиатр, это есть O большое от фиатр N в
[17:56.540 --> 18:07.220]  кубе поделить на N в квадрате. А фиатр N это O мало от N в степени 2 третих. То есть получаем,
[18:07.220 --> 18:13.100]  в результате, O мало от N в степени 2 третих в кубе, 3N в квадрат, то есть O мало от 1.
[18:13.100 --> 18:26.900]  То есть O мало от 1. Ну и опять это равномерно, так как мы при всех N ограничили одной и той же
[18:26.900 --> 18:33.820]  функции фиатр N, то всё заказано. Есть какие-то вопросы?
[18:37.220 --> 18:56.540]  Хорошо. Ну, я ещё под конец напомню, что для общности, что была такая теория МАФРОЛАПЛАССА,
[18:56.540 --> 19:03.740]  она идёт обычно в паре с теорией МАФРОЛАПЛАССА, что будет, если вероятность, здесь вероятность,
[19:03.740 --> 19:09.260]  мы проведем вера константная, на самом деле теория МАФРОЛАПЛАССА можно обобщать и для вероятностей
[19:09.260 --> 19:20.580]  успеха, стремящихся к нулю, и даже там вплоть до чего-то, типа логенку идти на M. То есть
[19:20.580 --> 19:25.900]  теория МАФРОЛАПЛАССА, они друг другу дополняют. Теория МАФРОЛАПЛАССА – это в случае,
[19:25.900 --> 19:32.860]  когда вероятность от цепы 9 на M, я не помню, я там наверное уже доказывал, как минимум я
[19:32.860 --> 19:37.420]  далеко доказывал вам, Генрихович, но это очевидно упражнение, вы сами легко это докажете,
[19:37.420 --> 19:43.420]  просто следует из второго замечательного предела. Я просто напомню формулировку,
[19:43.420 --> 19:52.460]  чтобы видно было сравнение вот этих двух разных ситуаций. В одной ситуации возникает тиримпо
[19:52.460 --> 20:02.660]  сона, а в другой – логенку ЛАПЛАССА. Значит, если хn имеет минимальное расстояние с параметрами n и
[20:02.660 --> 20:17.980]  лямба поделить на n, то тогда вероятность того, что хn равняется k, стремится к вероятности того,
[20:17.980 --> 20:27.500]  что это равняется k, где это поосоновская случайная величина для всех с параметром лямб,
[20:27.500 --> 20:38.460]  а стремление выполнено для всех k, для всех k целых не отрицательных. Дальше на практике,
[20:38.460 --> 20:46.380]  если вы хотите примерно прикинуть, чему равна вероятность того, что хn равняется k. Вот вам
[20:46.380 --> 20:51.300]  даны какие-то параметры совершенно конкретные. Как понять, в каком случае применяется тиримпо
[20:51.300 --> 20:57.700]  сона, в каком случае применяется тиримма логового паса. Вот мы на прошлой лекции в задачке рассмотрели
[20:57.700 --> 21:07.180]  параметры n16, а p – одна вторая. Видите, да? В этом случае произведение n и p велико, n на p будет
[21:07.180 --> 21:15.460]  500000. В нашем случае, в случае тиримпо сона, произведение n на p – это лямб, да? Это констант.
[21:15.460 --> 21:29.780]  Ну вот понятно, что нужно понимать, каково лямб в сравнении с n. Но в целом можно смело,
[21:29.780 --> 21:38.540]  я там не помню, в разных местах по-разному пишут. Ну типа, если лямб меньше 10,
[21:38.540 --> 21:48.100]  то можно применять тиримпо сона, а n большое, хотя бы там 1000. А если лямб да хотя бы 30,
[21:48.100 --> 21:54.220]  и n опять же большое, но не слишком большое. Но для тех, для которых это уже не будет верно,
[21:54.220 --> 22:00.900]  в общем-то такие n обычно не рассматриваются. Можно же применять тиримму, тиримму авролапласа.
[22:00.900 --> 22:07.260]  Ну что, для того, чтобы здесь какие-то точные сделать вычисления, да, при каких именно параметрах
[22:07.260 --> 22:11.900]  можно применять одно и можно применять другое, нужно, во-первых, обобщенную тиримму авролапласа
[22:11.900 --> 22:21.340]  сформулировать, в которой p может нулю стремиться. Во-вторых, понимать, какая скорость сходимости в
[22:21.340 --> 22:25.660]  одном законе, какая скорость сходимости в другом законе их сравнить. Но, тем не менее, это все есть,
[22:25.660 --> 22:30.620]  это можно аккуратно, формально проделать, но, в общем, общий совет совсем неформальный, да,
[22:30.620 --> 22:35.620]  если лямбом маленькая, и если n умножить на p маленькая, то не больше, чем 10, но применять
[22:35.620 --> 22:42.220]  тиримпо сона, если она там хотя бы 30, то применять тиримму авролапласа. Если какие-то вопросы.
[22:42.220 --> 22:54.220]  Наверное, это все, что, так закон же по форму логогипма я сформулирую, я правильно помню,
[22:54.220 --> 23:00.780]  мы же все это ради него в каком-то смысле делали, да. Хорошо, значит, в общем, это все, что я хотел
[23:00.780 --> 23:06.780]  рассказать про случайное блуждание, давайте теперь перейдем к пределам, в котором мы на самом деле уже
[23:06.780 --> 23:15.980]  активно говорили, во-первых, вот был закон большой чисел, в котором утверждалось, что его упрощенный
[23:15.980 --> 23:21.060]  вариант, да, что если вы поделите sn поделить на n, то оно будет почти ноль, то есть вероятность того,
[23:21.060 --> 23:27.700]  что sn поделить на n отличается от epsilon, эта вероятность выставить к нулю. Вот это так называемая
[23:27.700 --> 23:34.100]  сходимость по вероятности. Вот тиримпо сона, на который мы сейчас смотрим, в ней сходимость
[23:34.440 --> 23:38.920]  вероятностей, да, видите, вероятность того, что sn равен nukkah стремится к вероятности того, что sn равна nukkah.
[23:38.920 --> 23:45.260]  Это на самом деле сходимость по распределению. И вот в интегральной теории Мавролапаса, там если вы
[23:45.260 --> 23:49.260]  посмотрите внимательно, вы увидите сходимость функции распределения, да, функции распределения
[23:49.260 --> 23:56.980]  сона в точке k, почему-то там сходится, но здесь конечно k при этом какое-то большое, оно стремиться к
[23:56.980 --> 24:02.120]  sincerности, но тем не менее, эту интегральную теорию Мавролапаса тоже можно переформулировать
[24:02.120 --> 24:07.960]  термо сходимости по распределению. Но это два вида сходимости, с которыми мы не явно сталкивались,
[24:07.960 --> 24:11.680]  сходимость по вероятности и сходимость по распределению, еще мы сталкивались с
[24:11.680 --> 24:16.200]  еще одним видом сходимости, сходимость, почти наверно, когда говорили про тему люб Events
[24:16.200 --> 24:18.100]  а Doc панча в 방법е inherent сходимость prends dear detail была schnell не seating,
[24:18.100 --> 24:27.640]  а с другой стороны там была ещё сходимость мата ожидания модуля разных личных резчин к нулю это
[24:27.640 --> 24:32.680]  так называемая сходимость val1. то есть на самом деле мы сталкивались уже аж с четырьмя видами
[24:32.680 --> 24:40.440]  сходимости. в общем-то это все основные виды сходимости, о которых в курсе теории вероятности мы
[24:40.440 --> 24:52.040]  говорим. давайте четыре виды сходимости я сейчас определю. так сходимость случайных величин
[24:52.040 --> 25:16.960]  последовательности. ну и так у вас все время будет последовательность. первый тип сходимости,
[25:16.960 --> 25:24.680]  сходимость почти наверное. пишем так. ксен стремится почти наверное кси. это верно,
[25:24.680 --> 25:31.840]  если вероятность того, что ксен стремится кси равна единице. давайте еще раз, наверное,
[25:31.840 --> 25:36.760]  проговорим, что это за такой объект вероятности того, что ксен стремится кси. это конечно вероятность
[25:36.760 --> 25:43.160]  некоторого события. это просто множество тех омега, для которых ксен от омега стремится кси от омега.
[25:43.160 --> 25:49.440]  мы с вами в какой-то момент, когда говорили про измеримости всякие, мы с вами доказывали,
[25:49.440 --> 25:58.920]  что такие события, помните мы там говорили про верхний путь и про нижний путь, то есть на самом
[25:58.920 --> 26:06.160]  деле несложно доказать такие множество событий. поэтому здесь все формально верно. это самый
[26:06.160 --> 26:13.440]  сильный будет из четырех типов сходимости. не правильно сказал. будет два самых сильных
[26:13.440 --> 26:18.760]  типа сходимости, почти наверное и ВЛП. они один из другого не следуют, а другие два будут следовать
[26:18.760 --> 26:30.320]  с сходимостью почти наверное, так и с сходимостью ВЛП. итак, что такое сходимость ВЛП. но сходимость
[26:30.320 --> 26:37.320]  ВЛП можно говорить только, если наши величины лежат в пространстве ВЛП. пространство ВЛП это
[26:37.320 --> 26:43.520]  пространство измеримых функций, в котором можно взять интеграл модуля в степени П. если у вас
[26:43.520 --> 26:48.480]  интеграл от модуля ксен в степени П конечен, интеграл от модуля кси в степени П конечен,
[26:48.480 --> 26:56.800]  но я имею в виду гравитации. значит эти функции лежат в метрическом пространстве ВЛП. ну и можно
[26:56.800 --> 27:01.120]  говорить про сходимость в этом пространстве, и она будет выглядеть так. значит, если мы от
[27:01.120 --> 27:08.840]  ожидания модуля кси-минус кси в степени П. да, это расстояние в пространстве ВЛП стремится к нулю.
[27:08.840 --> 27:16.680]  вожание модуля разницы это есть интеграл от модуля разницы этих функций в степени П. вот поэтому это
[27:16.680 --> 27:34.000]  конечно точности расстояние в этом пространстве. третье. ксен сходится по вероятности кси. если это
[27:34.000 --> 27:40.240]  вот та самая сходимость из закона больших чисел. для любого епсом больше нуля вероятность того,
[27:40.240 --> 27:48.400]  что модуля кси-минус кси больше чем епсом стремится к нулю. да, например, в ЗБЧ
[27:48.400 --> 27:54.720]  например, в ЗБЧ утверждается, что
[27:54.720 --> 28:04.160]  СН поделить на Н стремится по вероятности к нулю.
[28:04.160 --> 28:16.880]  да, там как раз бытовал, что модуль СН поделить на Н. а, прошу прощения, мы от ожидания. где А, это мы от ожидания.
[28:16.880 --> 28:26.080]  да, там как раз бытовал, что если вы из модуля отношения СН поделить на Н. вычтем от ожидания, то вероятность того, что
[28:26.080 --> 28:36.720]  отличается от епсом стремится к нулю. так, ну и последний тип сходимости. сходимость по распределению или
[28:36.720 --> 28:45.040]  слабая сходимость. давайте называть сходимость по распределению. откуда взялся термин слабая
[28:45.040 --> 28:49.200]  сходимость, я чуть-чуть поясню. значит, СН сходится по распределению кси, если
[28:49.200 --> 29:06.160]  для любого х и з такого, что функция распределения
[29:06.320 --> 29:10.800]  сучайной величины предельной, то есть кси, непрерывно в точке х,
[29:20.480 --> 29:29.080]  справедливо, что значение этой функции, точнее не этой, а функции распределения к СН в этой точке х
[29:29.080 --> 29:43.080]  стремится к f от х при СН в бесконечности. как бы не взяли точку непрерывности пределения функции распределения,
[29:47.320 --> 29:54.040]  значит, в этой точке значение функции распределения должно стремиться к предельной.
[29:54.120 --> 30:00.160]  функции распределения предельно сучайной величины. вот здесь есть тонкость,
[30:00.160 --> 30:07.240]  откуда берется этот слой, почему не сказать, что вообще для любого х и з распределил такая сходимость.
[30:07.240 --> 30:37.160]  ну, вот эта точка вообще несложно привести пример. когда есть
[30:37.160 --> 30:46.280]  сходимость распределений, я чуть позже сформулирую февалентное определение, и тогда будет проще привести
[30:46.280 --> 30:53.200]  такой пример. несложно привести пример, когда есть сходимость по распределению, но при
[30:53.200 --> 31:01.000]  этом вот именно в точке разрыва происходит нечто странное. что такое точка разрыва? на самом деле
[31:01.000 --> 31:07.200]  в функции распределения могут быть точки, в которых есть предел только справа. и слева тоже есть предел,
[31:07.200 --> 31:12.880]  но предел справа совпадает. именно в этой точке, где предел справа совпадает с значением функции,
[31:12.880 --> 31:21.840]  там может быть какой-то разрыв. давайте оставим видео упражнение. я чуть позже сформулирую критерий
[31:21.840 --> 31:29.040]  сходимость по распределению, и попробую привести пример. когда сходимость по распределению есть,
[31:29.160 --> 31:36.160]  при этом в точке разрыва функции распределения сходимости нет. вот, значит, тебе общее замечание
[31:36.160 --> 31:41.680]  по поводу этих типов сходимости. как я уже сказал, здесь 3 и 4 послабее, чем первые два. на самом
[31:41.680 --> 31:52.000]  деле можно рисовать такую схему, что сходимости почти наверно следует сходимость по вероятности.
[31:52.000 --> 32:00.080]  исходимости в lp тоже следует сходимость по вероятности. сходимость по вероятности
[32:00.080 --> 32:05.000]  в свою очередь сильнее, чем слабая сходимость. проще нечем сходимость по распределению.
[32:10.000 --> 32:17.160]  давайте мы сперва докажем, что действительно верны все эти 3 следствия. давайте мы сперва докажем,
[32:17.160 --> 32:29.640]  что обратные не верны было верно. эсходимости по распределению нет.
[32:29.640 --> 32:34.680]  а вот четвертая по распределению? катерти pathせx.
[32:34.680 --> 32:39.460]  а третья это получилась какие-то все по функции распределения? по вероятности.
[32:47.160 --> 32:50.880]  это по вероятности
[32:55.160 --> 32:58.160]  с определением
[33:07.080 --> 33:10.560]  но это понятно почти наверно
[33:10.800 --> 33:14.240]  еще кстати сходимость почти наверно иногда называют сходимостью с
[33:14.280 --> 33:19.080]  вероятностью 1 не надо путать сход差 вероятности сходим из
[33:19.080 --> 33:22.560]  сippi институтgy
[33:22.560 --> 33:27.800]  вот давайте прежде чем доказывать эти следствия
[33:28.800 --> 33:33.160]  докажем то что обратной до том что исходим из распределения исходим из
[33:33.160 --> 33:38.520]  с Eine тnie то что исходим из по вероятности не следует не сходится
[33:38.520 --> 33:41.520]  1986
[33:41.520 --> 33:50.820]  Сейчас. Да, и исходимость почти наверно, и не следует
[33:50.820 --> 33:54.280]  сходимости в LPL, наоборот. То есть, нам достаточно будет больше доказать.
[33:54.280 --> 34:01.340]  Достаточно будет доказать, что бывает такое, что есть исходимость по вероятности, есть
[34:01.340 --> 34:07.880]  исходимость в LPL, но нет исходимости почти наверно. Из этого будет следовать, конечно,
[34:07.880 --> 34:10.520]  из вероятности не следует почти наверное, и что из
[34:10.520 --> 34:11.840]  РП тоже не следует почти наверное.
[34:11.840 --> 34:13.920]  То есть просто если есть сходимость, если можно
[34:13.920 --> 34:15.960]  представить вот такой пример что сходимость ВРП есть,
[34:15.960 --> 34:18.980]  а сходимость почти наверное нет,
[34:18.980 --> 34:21.980]  то и сходимость вероятности в частности будет,
[34:21.980 --> 34:24.920]  потому что она из РП следует.
[34:24.920 --> 34:26.960]  Но при этом мы умьем в узscale, что мы, во первых,
[34:26.960 --> 34:29.960]  закажем, что сходимость вероятности не следует
[34:29.960 --> 34:31.720]  сходимость почти наверное и
[34:31.720 --> 34:34.960]  сходимость ВРП тоже не следует сходимости почти на vaccine.
[34:34.960 --> 34:37.860]  На самом деле нам нужно Dag起ти три примера Division
[34:37.860 --> 34:43.040]  1. показывающий что исходимость по распределению не следует всходимости,
[34:43.040 --> 34:46.460]  по вероятности, 2. показывает что исходимость
[34:46.460 --> 34:53.040]  в LP не следует сходимости почти, наверное, prescription 4 пример.
[34:53.040 --> 34:58.460]  3. показывающий что исходимости почти, наверное, не следует сходимости в LP
[34:58.460 --> 35:01.960]  4. что бывает так что есть происхожении по вероятности, но нет,
[35:01.960 --> 35:20.480]  не почти, наверное, ни сходимости. Ну хорошо. Сперва докажем, что сходимости по распределению
[35:20.480 --> 35:30.760]  не следует сходимости по вероятности. Но это просто. Мы можем, когда мы говорим
[35:30.760 --> 35:34.960]  про сходимость по распределению, всё, о чём мы думаем, это про распределение случайных величин.
[35:34.960 --> 35:39.400]  Как сами эти случайные величины устроены, неважно. Важно, какие у них распределения. Поэтому
[35:39.400 --> 35:43.640]  можем взять, попробовать вообще одинаковое распределение. Тогда будет, конечно, сходимость.
[35:43.640 --> 35:58.600]  Сами случайные величины могут быть сильно разные при этом. Ну, например, пусть все кси и ксиен
[35:58.720 --> 36:09.160]  это бернульские случайные величины с параметром 1 на 2. Да, у них у всех одинаковое распределение,
[36:09.160 --> 36:12.880]  но раз у них у всех одинаковое распределение, то, конечно, будет сходимость по распределению.
[36:12.880 --> 36:20.040]  Теперь давайте попробуем их задать так, чтобы не было сходимости по вероятности. Ну,
[36:20.040 --> 36:29.280]  положим, просто ксиен все равны друг другу. А кси равно, ну, скажем, 1 минус ксиен.
[36:29.280 --> 36:36.560]  То есть, значит, что такое бернульский случайный величины? Это случайные величины,
[36:36.560 --> 36:42.840]  которые принимают значение в наляде. Если рассмотреть один минус такую случайную величину,
[36:42.840 --> 36:47.280]  у меня всё ещё будет наляде. Да, то есть это всё ещё будет бернульский случайный величина. Поэтому
[36:47.280 --> 36:54.560]  с распределением всё ок. Но при этом 0 и 1 меняется местами. Тогда, когда у кси 0, у кси будет 1.
[36:54.560 --> 37:02.280]  Тогда, когда у кси 1, у кси будет 0. То есть, вообще, модуль разности между кси и ксиеном в точности равен единице.
[37:02.280 --> 37:10.880]  Вообще всегда. Например, это означает, что вероятность того, что модуль кси минус ксиен
[37:10.880 --> 37:18.280]  больше, чем одна вторая, равно единице. И поэтому никакой сходимости по вероятности нет. Потому что такая
[37:18.280 --> 37:27.680]  вероятность должна стремиться к нулю, чтобы была сходимость по вероятности. Значит, нет сходимости по вероятности.
[37:27.680 --> 37:33.960]  Так, есть вопросы.
[37:33.960 --> 37:44.840]  Он должен сходиться, потому что это одно и то же, но одни и те же функции распределения.
[37:44.840 --> 37:52.280]  Да, конечно, функции распределения просто равны. В частности, в точках непрерывности они тоже сходятся.
[37:57.680 --> 38:20.800]  Так, хорошо. Сходимость по вероятности. Давайте, по-моему, попроще. Давайте пример, когда есть сходимость почти, наверное, но нету вльпы.
[38:20.800 --> 38:44.800]  Значит, идея вот в чем. С одной стороны, надо, чтобы по точечной сходимость была, ну, почти везде. То есть, чтобы мера множества точек, на которых нет сходимости, стремилась к нулю.
[38:44.800 --> 39:11.800]  Ну, можно сделать, если ксиенты какие-то тоже типа вернули в стену. То есть, есть какое-то событие, на котором каждый ксен не ноль и константы, скажем, да, то есть, пусть есть какое-то событие, на котором аенты, да, на котором ксены, некоторые константы, ну а тен зависит от константа.
[39:11.800 --> 39:36.800]  И вот эти события аэн, они будут сужаться. Если эти аэн будут сужаться до пустого множества, то вероятность того, что нет сходимости, будет, конечно, ноль. Но при этом, чтобы не было сходимости вльпы, нужно, чтобы на аэнтом значения случайных причин росли, причем стремительно.
[39:36.800 --> 39:42.800]  Да, чтобы они росли гораздо быстрее, чем вероятность аэнтом ослужается.
[39:42.800 --> 39:49.800]  Ну, можно прям какую-нибудь явную конструкцию построить, можно сделать в общем виде, можно не в общем, давайте не в общем для простоты.
[39:49.800 --> 39:54.800]  Значит, пусть омега это отрезок 0.1.
[39:54.800 --> 40:01.800]  А пэй это классическая мера либерли на нём.
[40:01.800 --> 40:06.800]  Вот такое у нас самая вероятностная пространство, но это, скажем, барельская сигма алгебра несутся.
[40:14.800 --> 40:17.800]  Барельский множество на этом отрезке.
[40:17.800 --> 40:40.800]  Значит, зададим ксиэн как индикатор, ну, скажем, от полуинтервала, чтобы вообще пустой множество было от 0 до 1n, умножить на, не знаю, на два степня.
[40:40.800 --> 41:00.800]  Ну, тогда будет, конечно, сходимость ксиэн к нулю почти, наверное.
[41:00.800 --> 41:07.800]  Да, так как вообще для любого омега из отрезка.
[41:07.800 --> 41:22.800]  Ну, кроме нуля, да, наверное, из полуинтервала от 0 до 1 найдётся такое n, нулевое, что для любого n больше значима нулевое ксиэн от омега равно нулю.
[41:22.800 --> 41:30.800]  Да, то есть, какой бы мы ни зафиксировать число между 0 и 1, нулю, начиная с какого-то момента вся пастерность будет нулю.
[41:30.800 --> 41:37.800]  Да, ну, просто одна n зайдёт длибее, чем это омега.
[41:37.800 --> 41:54.800]  С другой стороны, сходимости к нулю нету, потому что от ожидания модуля ксиэн в степени p равно 2 в степени np поделить на n, что стремится к бесконечности.
[41:54.800 --> 42:01.800]  Значит, ксиэн не стремится к нулю. На самом деле, здесь можно даже доказать, что вообще никуда не стремится.
[42:01.800 --> 42:08.800]  Да, из-за того, что мод ожидания неогранично растёт.
[42:08.800 --> 42:14.800]  По этой моменту, ксиэн неогранично растёт. Можно вообще доказать, что никуда не стремится, но чуть-чуть сложнее.
[42:14.800 --> 42:19.800]  Давайте оставим с аккаунтом. Мы в всяком случае доказали, что сходимости почти наверно не следует в lp.
[42:19.800 --> 42:30.800]  Сходимость к нулю есть. Сходимость почти наверно к нулю есть. Сходимость к нулю в lp есть.
[42:30.800 --> 42:35.800]  Хорошо, давайте теперь докажем, что из lp не следует почти наверно.
[42:41.800 --> 42:44.800]  Здесь будет другой трюк.
[42:44.800 --> 42:55.800]  Понятно, что конструкция, подобные конструкции, а именно конструкции, в которых вы задаете ксиэн не нулевой на сужающихся множествах и вложенных,
[42:55.800 --> 43:00.800]  а не сработает, потому что будет сходиться почти наверно.
[43:00.800 --> 43:11.800]  Поэтому, если вы хотите, чтобы была сходимость к нулю в lp, мы хотим, чтобы эти множества всё-таки сужались.
[43:11.800 --> 43:18.800]  У нас два в степени np. Но давайте сделаем не два в степени n значения, а константа.
[43:18.800 --> 43:24.800]  То есть пусть это ксиэн, это индикатор на каком-то множестве n, да может быть константа, которая от этого не зависит.
[43:24.800 --> 43:29.800]  Тогда в осмотре ожидания будет константа поделить на n, но она будет к нулю встанется, то есть будет сходимость в lp.
[43:29.800 --> 43:37.800]  При этом вот эти множества аэнтей, на которых ксиэн не нуль, я могу как угодно выбирать, они совсем не обязаны быть вложены.
[43:37.800 --> 43:39.800]  Если они вложены, то будет сходимость почти наверно.
[43:39.800 --> 43:45.800]  Значит, мне нужно их как-то так двигать, чтобы сходимости почти наверно не было.
[43:45.800 --> 43:49.800]  Ну, за счёт чего можно убить сходимость почти наверно?
[43:49.800 --> 44:00.800]  За счёт того, что какой бы вы ни взяли омега из вашего отрезка, будет сколь угодно много аэнтых, которые это омега пересекают.
[44:00.800 --> 44:03.800]  Ну, то есть для которых омега в это отрезка попадает.
[44:03.800 --> 44:12.800]  То есть вот эти события аэнта, они должны бегать, они должны уменьшаться, они при этом должны бегать по отрезку 0.1.
[44:12.800 --> 44:20.800]  Так, чтобы какой бы мы ни взяли омега, бесконечно много раз события аэнта в это омега возвращалась.
[44:20.800 --> 44:23.800]  Ну, вот это можно сделать, например, следующим образом.
[44:23.800 --> 44:31.800]  Давайте будем дробить отрезок сначала на две части, потом на четыре части, потом на восемь частей и так далее.
[44:32.800 --> 44:45.800]  То есть можно и, в принципе, дробить на меньшее количество.
[44:45.800 --> 44:52.800]  Давайте так, сначала на две части, потом на четыре части, можно было бы сначала на две, потом на три, потом на четыре, потом на пять, неважно.
[44:52.800 --> 45:00.800]  Но мы сейчас для четвертого примера, мы склеим второй и третий пример вместе.
[45:00.800 --> 45:05.800]  И для четвертого примера, видимо, будет удобнее каждый раз делить в два раза, поэтому давайте сделать так.
[45:05.800 --> 45:07.800]  Здесь это не важно абсолютно.
[45:07.800 --> 45:16.800]  Ну, давайте, значит, сначала поделим пополам отрезок 0.1 и, значит, определим кси1 и кси2.
[45:16.800 --> 45:26.800]  Кси1 это пусть будет индикатор от 0 до 1.2.
[45:26.800 --> 45:28.800]  Просто, да.
[45:28.800 --> 45:35.800]  Кси2 это будет индикатор от 1.2 до 1.
[45:35.800 --> 45:38.800]  Потом поделим на четыре части и снова начнем с 0.
[45:38.800 --> 45:43.800]  Кси3 это будет уже индикатор от 0 до 1.4.
[45:43.800 --> 45:49.800]  Кси4 это будет индикатор от 1.4 до 1.2.
[45:53.800 --> 45:56.800]  Неудобствия включая левую отрезок, левая граница все время.
[45:56.800 --> 46:00.800]  Кси5 это будет индикатор от 1.2 до 3.4.
[46:00.800 --> 46:05.800]  Да, это все в рамках тех же самых ОМЕГАФП, которые я в предыдущем примере назвал.
[46:05.800 --> 46:08.800]  То есть они для всех этих примеров общие.
[46:09.800 --> 46:12.800]  Кси6 это индикатор от 3.4 до 1.
[46:13.800 --> 46:19.800]  Давайте я сюда тоже перенесу вот эти линии ОМЕГФП.
[46:43.800 --> 46:45.800]  Ну да.
[46:49.800 --> 46:51.800]  Вот, значит, то же самое ОМЕГФП.
[46:51.800 --> 46:53.800]  Ну да.
[46:53.800 --> 46:55.800]  Ну да.
[46:55.800 --> 46:57.800]  Ну да.
[46:57.800 --> 46:59.800]  Ну да.
[46:59.800 --> 47:01.800]  Ну да.
[47:01.800 --> 47:03.800]  Ну да.
[47:03.800 --> 47:05.800]  Ну да.
[47:05.800 --> 47:07.800]  Ну да.
[47:07.800 --> 47:09.800]  Ну да.
[47:09.800 --> 47:11.800]  Ну да.
[47:11.800 --> 47:13.800]  Вот, значит, то же самое ОМЕГФП.
[47:13.800 --> 47:15.800]  И теперь у вас нарезан бегающий.
[47:15.800 --> 47:17.800]  Ну и так далее.
[47:17.800 --> 47:21.800]  То есть дальше у вас будут кси7, кси8, кси9, кси10 и так далее.
[47:23.800 --> 47:25.800]  Кси14.
[47:25.800 --> 47:27.800]  Это будет 8 штук.
[47:27.800 --> 47:29.800]  Это будет индикатор от 0 до 1.8.
[47:29.800 --> 47:31.800]  Это 1.8 до 1.4.
[47:31.800 --> 47:33.800]  Это 1.4 до 1.8.
[47:33.800 --> 47:37.800]  То есть вы с каждым следующим разом будете уменьшать в два раза ваши отрезки,
[47:37.800 --> 47:39.800]  которые у вас значение с чайной величины равно 1.
[47:39.800 --> 47:41.800]  То есть не 0.
[47:41.800 --> 47:43.800]  Вот это такие мернулисты с чайной величины,
[47:43.800 --> 47:45.800]  которые уменьшаются в параметрах.
[47:45.800 --> 47:47.800]  Понятно, что мы от ожидания
[47:49.800 --> 47:51.800]  модуля ксен
[47:51.800 --> 47:53.800]  степени П.
[47:53.800 --> 47:55.800]  Это есть просто
[47:55.800 --> 47:57.800]  вероятность того,
[47:57.800 --> 47:59.800]  что ксен равно единицы
[47:59.800 --> 48:01.800]  в мощности.
[48:01.800 --> 48:03.800]  Она стремится к 0.
[48:03.800 --> 48:05.800]  Она стремится к 0,
[48:05.800 --> 48:07.800]  она как линия на П.
[48:07.800 --> 48:09.800]  То есть несложно видеть,
[48:09.800 --> 48:11.800]  что первая и вторая величины
[48:11.800 --> 48:13.800]  для них вероятность на вторая.
[48:13.800 --> 48:15.800]  Для третьей, четвертой, пятой, шестой
[48:15.800 --> 48:17.800]  она будет
[48:21.800 --> 48:23.800]  1.4.
[48:23.800 --> 48:25.800]  Для следующих восьми она будет 1.8.
[48:25.800 --> 48:27.800]  То есть это вероятность
[48:27.800 --> 48:29.800]  на самом деле 1.
[48:29.800 --> 48:31.800]  НТ.
[48:31.800 --> 48:33.800]  Надо там какую-то целую часть взять.
[48:33.800 --> 48:35.800]  1 поделить на какую-то целую часть.
[48:41.800 --> 48:43.800]  Видимо, это будет единица
[48:43.800 --> 48:45.800]  делить на 2 в степени целой части
[48:45.800 --> 48:47.800]  от логарифма по основанию 2Т.
[48:47.800 --> 48:49.800]  Но не суть. Понятно, что она к 0 стремится.
[48:49.800 --> 48:51.800]  Чему она вас оборонает, вообще неважно.
[48:51.800 --> 48:53.800]  Важно, что она стремится к 0.
[48:53.800 --> 48:55.800]  Дальше
[48:57.800 --> 48:59.800]  почти наверно не сходится нифига.
[48:59.800 --> 49:01.800]  Почему? Потому что
[49:01.800 --> 49:03.800]  для мега
[49:03.800 --> 49:05.800]  и для любого n0
[49:05.800 --> 49:07.800]  существует
[49:07.800 --> 49:09.800]  n1 и n2 больше,
[49:09.800 --> 49:11.800]  чем n0.
[49:11.800 --> 49:13.800]  Такие, что для любого
[49:13.800 --> 49:15.800]  мега меньше в единицах, кстати.
[49:15.800 --> 49:17.800]  В единицах у нас они все ноль уровны.
[49:17.800 --> 49:19.800]  Но это не суть.
[49:19.800 --> 49:21.800]  Если мы выкроем одну точку, у нас почти наверно
[49:21.800 --> 49:23.800]  рассуждения сохранятся,
[49:23.800 --> 49:25.800]  потому что она имеет мега 0.
[49:25.800 --> 49:27.800]  Какой бы ни взял номер,
[49:27.800 --> 49:29.800]  найдутся большие такие,
[49:29.800 --> 49:31.800]  максимум 1 от мега равно 0,
[49:31.800 --> 49:33.800]  максимум 2 от мега равно 1.
[49:33.800 --> 49:35.800]  Это, в общем-то, очевидно следует
[49:35.800 --> 49:37.800]  из моего обстроения,
[49:37.800 --> 49:39.800]  потому что
[49:39.800 --> 49:41.800]  любые два соседних отрезка не пересекаются.
[49:45.800 --> 49:47.800]  Когда мы переходим
[49:47.800 --> 49:49.800]  от предыдущих отрезков к следующему,
[49:49.800 --> 49:51.800]  то все мега, которые предыдущим принадлежали,
[49:51.800 --> 49:53.800]  они перестают покрываться.
[49:53.800 --> 49:55.800]  Это то, из-за чего
[49:55.800 --> 49:57.800]  бесконечно часто будет 0.
[49:57.800 --> 49:59.800]  То, из-за чего бесконечно часто будет 1,
[49:59.800 --> 50:01.800]  это потому что мы возвращаемся
[50:01.800 --> 50:03.800]  в другую точку,
[50:03.800 --> 50:05.800]  для каждого диаметра разбиения
[50:05.800 --> 50:07.800]  объединение отрезков
[50:07.800 --> 50:09.800]  с соответствующим диаметром
[50:09.800 --> 50:11.800]  заполняет весь отрезок от 0 до 1.
[50:13.800 --> 50:15.800]  Это то, из-за чего
[50:15.800 --> 50:17.800]  бесконечно часто 1 равно значения.
[50:17.800 --> 50:19.800]  Поэтому мне сходимость почти наверно.
[50:27.800 --> 50:29.800]  Вот Кси Н1,
[50:29.800 --> 50:31.800]  как он может представить себя?
[50:31.800 --> 50:33.800]  То есть это же какой-то
[50:33.800 --> 50:35.800]  отрезок интервала?
[50:35.800 --> 50:37.800]  Еще раз повторите вопрос, пожалуйста.
[50:37.800 --> 50:39.800]  Вы как можете представить Кси Н1?
[50:39.800 --> 50:41.800]  Си Н1.
[50:43.800 --> 50:45.800]  Это просто индикатор
[50:45.800 --> 50:47.800]  отрезка соответствующего
[50:47.800 --> 50:49.800]  номеру Н1.
[50:49.800 --> 50:51.800]  Да, Кси Н1,
[50:51.800 --> 50:53.800]  это просто индикатор
[50:53.800 --> 50:55.800]  отрезка соответствующего номеру Н1.
[50:55.800 --> 50:57.800]  Да, Кси Н1 равно ли в единиц
[50:57.800 --> 50:59.800]  либо нолью.
[50:59.800 --> 51:01.800]  Но мне нужно подобрать,
[51:01.800 --> 51:03.800]  нужно подобрать Н1.
[51:03.800 --> 51:05.800]  Вот я взял какой-то омега.
[51:05.800 --> 51:07.800]  И, допустим,
[51:07.800 --> 51:09.800]  это омега, точнее,
[51:09.800 --> 51:11.800]  во-первых, у меня есть 0.
[51:11.800 --> 51:13.800]  Это 0, допустим, миллион.
[51:13.800 --> 51:15.800]  А вы представляете, что 0 – это миллион.
[51:15.800 --> 51:17.800]  Это значит, что у меня должен быть
[51:17.800 --> 51:19.800]  номер больше чем миллион.
[51:19.800 --> 51:21.800]  Ну,
[51:21.800 --> 51:23.800]  мне нужно
[51:23.800 --> 51:25.800]  взять Н1 такой,
[51:25.800 --> 51:27.800]  чтобы ответственная длина
[51:27.800 --> 51:29.800]  отрезка была там меньше, чем миллион.
[51:29.800 --> 51:31.800]  Потому что длина отрезка бывает
[51:31.800 --> 51:34.220]  примерно такой же скоростью, как и нgrounds.
[51:34.220 --> 51:35.800]  Вот я беру
[51:37.800 --> 51:39.800]  соответствующий диаметр взбиения.
[51:39.800 --> 51:41.800]  Или соответствующий
[51:41.800 --> 51:43.800]  уровень.
[51:43.800 --> 51:51.800]  Вот у нас первый уровень – это когда
[51:51.800 --> 51:57.480]  целая часть софтагорифма по основанию 2000, ну и еще для удобства можно прибавить 5,
[51:57.480 --> 52:04.720]  чтобы наверняка попасть в нужный уровень. И там нахожу тот отрезок, который омега не покрывает.
[52:04.720 --> 52:12.920]  Вот там будет некоторый номер, ксен1, такой, что индикатор принадлежности соответствующему
[52:12.920 --> 52:19.960]  промежутку не покрывает омега. Это значит, что на этом омега значение сученовищных ксен1 равно 0.
[52:19.960 --> 52:27.320]  Так как у меня объединение всех отрезков вот на этом уровне, это весь отрезок 0 для единицы,
[52:27.320 --> 52:32.560]  не считай единицы, то я смогу найти какой-то n2 на этом уровне. Такой, что соответствующий
[52:32.560 --> 52:38.760]  отрезок моего омега покроет. Но я тогда беру случайный отрезок ксен2, она будет равна единице
[52:38.760 --> 52:46.480]  на этом омега. Окей? Да, вроде понятно. Можно вопросы? Где здесь случайность?
[52:46.480 --> 52:51.240]  Случайная величина – это просто функция? Случайная величина – да, есть просто функция.
[52:51.240 --> 52:57.720]  Вот я задал вероятностное пространство, видите, неспроста. Что такое случайная величина?
[52:57.720 --> 53:04.680]  Это функция, которая действует за омега ВР, но еще и измеримая должна быть. Я задал омега ФП именно таким
[53:04.680 --> 53:13.240]  образом, чтобы вот эти функции, которые есть, чтобы это были измеримые функции за омега ВР.
[53:13.240 --> 53:18.840]  Элементарный исход это просто точка. Элементарный исход это просто точка соответствующего омега ВР.
[53:18.840 --> 53:32.280]  То есть, ну вот, может быть было понятнее, если бы я там написал вот так. Индикатор того, что омега
[53:32.280 --> 53:41.720]  принадлежит этому. Да, но я именно это имел в виду. То есть, аргумент – это именно омега маленький
[53:41.720 --> 53:53.920]  элементарный исход. Так, есть еще какие-то вопросы? Ну, а не стремится, потому что вероятность не равна единице, правильно?
[53:53.920 --> 54:00.360]  И еще раз повторите вопрос. Ну, не стремится, потому что вероятность не равна единице. Ну, вообще вероятность – ноль.
[54:00.360 --> 54:11.840]  Вероятность того, что ксиан стремится кси равно нулю. То есть, вот так можно написать. Множество тех омега, на которых ксиан стремится кси,
[54:11.840 --> 54:21.960]  это в точности единичка. То есть, только в точке 1 у меня все случайные причины – это ноль. А кси – это кси – это ноль.
[54:21.960 --> 54:29.800]  Я кси написал, кси какой-то. Но вообще ни к чему не будет стремиться, конечно, вообще ни к чему. Но сейчас это к нулю.
[54:29.800 --> 54:35.240]  Да, мы же хотим доказать, что из-за рекламы не следует почти наверно. Вот в ЛП у нас есть сходимость к нулю.
[54:35.240 --> 54:45.760]  Не очень аккуратно пишу, прошу прощения. Да, вот есть сходимость в ЛП к нулю, а почти наверно к нулю сходимости нет.
[54:45.760 --> 54:58.360]  Это связано с тем, что, если я посмотрю на множество тех омег, для которых есть сходимость к нулю, то это просто всего лишь единичка, и вероятность единички – это, конечно, ноль.
[54:58.360 --> 55:05.400]  У нас классическая мера Лебедова – вероятность любого одноточного множества ноль.
[55:05.400 --> 55:17.720]  Но здесь, конечно, не будет сходимости вообще ни к чему. Из-за того, что у нас кси – это ноль, то это 1, то никакой случайночной кси не будет почти наверно кси стремиться.
[55:17.720 --> 55:47.640]  Ну, я думаю, должно быть понятно, как теперь привести пример ситуации, когда есть сходимость по вероятности, но нету не сходимости в ЛП, не сходимости почти наверно.
[55:47.640 --> 56:08.600]  Да, это единственный оставшийся пример. Его надо как-то скомбинировать, на самом деле, из примеров ВЛП 3, потому что в 3 мы делали так, чтобы сходимости почти наверно не было, а в 2 мы делали так, чтобы сходимости в ЛП не было, но при этом нам нужно сохранить сходимость по вероятности.
[56:08.600 --> 56:22.520]  Вот за счет чего и в примерах 2, и в примерах 3 есть сходимость по вероятности за счет того, что размер множества, который под индикатором стоит, стремится к нулю.
[56:22.520 --> 56:38.440]  Да, то есть и в примере 2, и в примере 3 кси происходит с проявленностью к нулю, потому что, на самом деле, эта вероятность, это в точности длина отрезка под знаком индикатора.
[56:38.440 --> 56:56.360]  В примере 2 у нас отрезки были вложены, в примере 3 они бегающие. Если мы хотим, чтобы не было сходимости почти наверно, нам их надо оставить бегающими, вот эта идея с тем, что отрезки бегают, она здесь тоже должна работать.
[56:57.280 --> 57:23.280]  Теперь как нам побороться сходимостью в ЛП? Вот как мы боролись в пункте 2 сходимости в ЛП? Мы делали так, чтобы эти индикаторы внажались на константу, случайная величина принимает значение не 0 и 1, а 0 и какой-то cn, причем эта cn, она с ростом n растет настолько быстро, что стремление вероятности к нулю, этот рост cn к бесконечности не побеждает.
[57:24.200 --> 57:44.200]  Ну и вот несложно видеть, что если просто комбинировать соответствующим образом пункты 2 и 3, вот тоже написать 2 в степени, то есть возьмем просто и умножим каждый индикатор из пункта 3, умножим на 2 в степени, и это должно сработать, давайте проверим.
[57:44.200 --> 58:09.120]  Ну все равно экспоненциальная будет сходимость к нулю, а как я уже сказал, вероятность здесь к нулю бесконечности, как я уже сказал, к нулю здесь вероятность стремится линейно по n, поэтому это должно сработать, давайте это запишем.
[58:14.200 --> 58:44.120]  То же самое омега fp, вот значит ксишки немного иначе, так c1 это будет индикатор отрезка, промежутка от порядка 1-2 на 2 в степени, ну и то же самое со всеми остальными пунктами.
[58:44.200 --> 59:11.120]  Просто предыдущего примера они отличаются в множестве 2 в степени, значит индикатор от 1-2 до 1 в степени умножить на 2 в степени n, по аналогии запишем x3 и x6, x3 это индикатор от 0 до 1 в 4, умножить на 2 в степени n, x4 это индикатор от 1-4 до 1-2.
[59:14.200 --> 59:44.120]  Замечательно, здесь 2 равно 1, здесь n равно 1, здесь n равно 2, 2 в квадрате да, то есть 4, здесь n равно 3, это 2 в кубе и 2 в 4, ну и так далее, x5 индикатор от 1-2 до 3 в 4 умножить на 2 в 5, 32, то есть x6 это индикатор от 3 в 4.
[59:45.120 --> 59:54.120]  1 умножить на 64, ну и так далее, на каждом уровне у нас в два раза будет увеличиваться количество.
[59:59.120 --> 01:00:03.120]  Ну во-первых есть сходимость к сиен по вероятности к нулю.
[01:00:08.120 --> 01:00:10.120]  Так как...
[01:00:11.040 --> 01:00:38.040]  Какой бы вы не взяли эпселом больше нуля, вероятность того, что модуль к сиен, давайте возьмем для удобства от 0 до 1, понятно, что нам достаточно брать маленький эпселом, тогда если то, что написано справа будет правдой, для маленьких эпселом, для больших он будет и подобным.
[01:00:38.960 --> 01:00:47.960]  Вероятность того, что модуль к сиен минус ноль больше чем эпселом, это на самом деле в точности вероятность того, что к сиен равно не ноль.
[01:00:55.960 --> 01:01:05.960]  И вот эта штука стремится к нулю, потому что это ровно вот длина отрезочка, на котором к сиен тянет, мы так задали, что это вероятно, что это длина к нулю стремится.
[01:01:06.880 --> 01:01:29.880]  Поэтому по вероятности к нулю мы сходимся, почти наверное нет сходимости, просто по аналогии с предыдущим пунктом, с пунктом 3, опять есть сколько угодно большие n1, n2, для которых к сиен 1 равно 0 на каждом омега, а к сиен 2 равно 1.
[01:01:29.880 --> 01:01:57.800]  Ну и теперь в lp, почему нет сходимости в lp, давайте посмотрим от ожидания модуля к сиен степени, это в точности 2 в степени np умножить на вероятность того, что к сиен это 2 в степени ноль.
[01:02:00.800 --> 01:02:13.800]  Вот, как я уже сказал, она линейна, бывает по n, поэтому экспонента ее побеждает, эта штука бесконечно стремится, давайте это аккуратно докажем.
[01:02:13.800 --> 01:02:40.720]  Обратите внимание, что к си 6, 6 это 2 плюс 4, это меньше чем 8.
[01:02:44.720 --> 01:03:06.720]  А при этом длина одна четвертая, ну вот что я хочу сказать, я хочу сказать, что у к си 4 длина отрезка больше чем одна восьмая, у к си 8 длина отрезка одна восьмая больше чем одна шестнадцатая, и так далее.
[01:03:07.640 --> 01:03:21.640]  То есть длина отрезка у к си с индексом 2 в степени k больше чем 1 поделить на 2 в степени k плюс 1, на самом деле 1 поделить на 2 в степени k.
[01:03:22.560 --> 01:03:41.560]  Длина отрезка номер 2 в степени k равна 1 поделить на 2 в степени k.
[01:03:42.480 --> 01:04:05.480]  Вот поэтому мы нашу вероятность можем сверху оценить, как 1 поделить на 2 в степени нижняя целая часть от логарифа по основанию 2 от n и минус 1.
[01:04:06.400 --> 01:04:10.400]  То есть если я зайду на один уровень выше, то я точно получу отрезок длиннее.
[01:04:12.400 --> 01:04:29.400]  Но видно, что в частности это еще можно оценить, как скажем 4 поделить на 2 в степени лог 2 от m, да это просто m, то есть получаем 2 в степени np умножить на 4 поделить на m.
[01:04:30.320 --> 01:04:42.320]  Ну я просто подемонстрировал, что стремление к 0 не более чем линейное, аккуратно я доказал.
[01:04:48.320 --> 01:04:50.320]  Так, есть какие-то вопросы?
[01:04:51.240 --> 01:05:01.240]  Мы вроде просто хотели доказать, что lp не будет, она вроде есть или нет?
[01:05:03.240 --> 01:05:05.240]  Бесконечности, извините.
[01:05:09.240 --> 01:05:13.240]  Следовательно, ксения не стремится к 0.
[01:05:14.240 --> 01:05:16.240]  Так нам снизу нужно было оценивать, нет?
[01:05:17.240 --> 01:05:19.240]  Да.
[01:05:21.240 --> 01:05:23.240]  Спасибо, верно говорите.
[01:05:26.240 --> 01:05:28.240]  Снизу тогда оценим, напишем верхнюю целую часть.
[01:05:31.240 --> 01:05:33.240]  И плюс один, туда это будет.
[01:05:35.240 --> 01:05:37.240]  Четыре доминации.
[01:05:51.240 --> 01:05:53.240]  Да, спасибо.
[01:05:54.240 --> 01:05:56.240]  Так, есть еще какие-то вопросы?
[01:06:01.240 --> 01:06:05.240]  Так, ну осталось 17 минут, давайте я начну говорить про доказательство сходимости,
[01:06:05.240 --> 01:06:10.240]  может быть докажу самую простую, точнее не сходимости, а следствия.
[01:06:10.240 --> 01:06:12.240]  Докажу самое простое и на этом закончу.
[01:06:13.160 --> 01:06:19.160]  Ну самое простое это доказать, что из lp следует p, а то, что из почти наверное следует p, из p следует d.
[01:06:19.160 --> 01:06:21.160]  Докажу будем в следующий раз.
[01:06:25.160 --> 01:06:27.160]  Так.
[01:06:28.160 --> 01:06:30.160]  Из lp следует p.
[01:06:36.160 --> 01:06:38.160]  Так.
[01:06:39.080 --> 01:06:41.080]  Ну, это в общем-то не сложное следствие неравенства Маркова.
[01:06:45.080 --> 01:06:47.080]  Давайте возьмем произвольное, что больше 0.
[01:06:51.080 --> 01:06:55.080]  И посмотрим на вероятность того, что моды к 7 и к 7 больше, чем к 7.
[01:07:01.080 --> 01:07:05.080]  Давайте возведем обе части этого неравенства, все пенсионы, все пенсионы.
[01:07:06.000 --> 01:07:10.000]  Давайте возведем обе части этого неравенства, все пенсионы, все пенсионы.
[01:07:10.000 --> 01:07:12.000]  Так она положительная.
[01:07:13.000 --> 01:07:17.000]  Да, я кстати здесь не сказал, это конечно некоторое положительное число.
[01:07:22.000 --> 01:07:26.000]  Да, и по этому параметру сходим, если это положительное число.
[01:07:26.000 --> 01:07:28.000]  Сейчас, а по ней больше либровной единицы?
[01:07:28.000 --> 01:07:30.000]  Нет.
[01:07:30.000 --> 01:07:32.000]  Что потом?
[01:07:32.000 --> 01:07:34.000]  Нет.
[01:07:34.920 --> 01:07:36.920]  Вот.
[01:07:36.920 --> 01:07:38.920]  Значит.
[01:07:38.920 --> 01:07:42.920]  Тогда здесь будет модуль к 7-6 в степени pm.
[01:07:42.920 --> 01:07:46.920]  Больше мы встаем к 7 в степени pm, так как p число положительное,
[01:07:46.920 --> 01:07:50.920]  но монотонная функция, и не право поменить по большей части неравенства.
[01:07:50.920 --> 01:07:52.920]  Вот.
[01:07:52.920 --> 01:07:58.920]  Неравенство Маркова это меньше либровной, чем от ожидания модуля к 7-10 в степени pm.
[01:08:00.920 --> 01:08:02.920]  Ответить на f в степени pm.
[01:08:03.840 --> 01:08:07.840]  Что стремится к нулю?
[01:08:07.840 --> 01:08:13.840]  Да, так как в силу сходимости в lp,
[01:08:13.840 --> 01:08:21.840]  т.к. xe стремится в lp, xe, а значит по определению, как раз числитель дрога стремится к нулю.
[01:08:33.840 --> 01:08:37.840]  Есть еще время, быстро-быстро, начиная заказал.
[01:08:37.840 --> 01:08:40.840]  Ну давайте попробуем, хорошо, nanite попробуем,
[01:08:40.840 --> 01:08:44.840]  сходимость почти наверная, доказать сходимость по вероЯрностям.
[01:08:46.840 --> 01:08:49.840]  Ч serve не запутаться, хоть это вроде очевидно,
[01:08:49.840 --> 01:08:53.840]  но надо аккуратно и формально писать.
[01:08:53.840 --> 01:08:57.840]  Сходимость почти-навернаяollowing сходимость по вероЯрностям.
[01:08:57.840 --> 01:09:01.840]  Ну давайте напишем, что так descrição процентная.?
[01:09:01.840 --> 01:09:10.000]  стремится почти наверно к си, это есть не что иное, как вероятность того, что ксен стремится к си равной 1,
[01:09:10.000 --> 01:09:20.640]  а это есть не что иное, как что такое стремиться, да, ну давайте просто определение по каши запишем,
[01:09:20.640 --> 01:09:32.240]  значит для любого эпсилон большего нуля существует такое ноль, что для любого
[01:09:32.240 --> 01:09:45.320]  н больше либо равно чем ноль, модуль ксен минус кси меньше чем эпсилон, вероятность равна 1.
[01:09:50.640 --> 01:10:02.720]  понятно, что здесь у меня эпсилон, можно сделать сейчас,
[01:10:06.240 --> 01:10:11.880]  даже проще, смотрите, это пересечение каких-то событий, да, вот из меня стоит квантор для
[01:10:11.880 --> 01:10:19.240]  любого, пересечение событий, которые индексированы эпсилоном, оно даже континуальное, но пофигу,
[01:10:19.520 --> 01:10:29.040]  пересечение событий континуальное, неконтинуальное, какое угодно, равно 1 может лишь в случае,
[01:10:29.040 --> 01:10:36.360]  когда все они равны 1, да, то есть из этого сразу следует, чтобы любого эпсилон больше нуля,
[01:10:36.360 --> 01:10:46.960]  а вероятность того, что найдется н0, такое, что начиная с некоторого момента,
[01:10:46.960 --> 01:10:57.080]  модуль ксен минус кси меньше чем эпсилон, равно 1.
[01:11:07.080 --> 01:11:11.800]  вот, хорошо, давайте теперь рассмотрим событие аэнт,
[01:11:12.640 --> 01:11:21.480]  аэнт, который заключается в том, что модуль ксен минус кси меньше вранча эпсилон,
[01:11:21.480 --> 01:11:34.680]  тогда вероятность, которая у нас здесь записана, точнее, вот это событие, существует ноль, такое,
[01:11:34.760 --> 01:11:48.680]  что начинает с него, модуль ксен минус кси меньше чем эпсилон, есть не что иное, как объединение
[01:11:50.680 --> 01:11:53.680]  пересечений события аэнт,
[01:12:00.480 --> 01:12:02.880]  объединение пересечения события аэнт,
[01:12:04.680 --> 01:12:21.080]  окей, тогда, если я возьму дополнение, объединение по всем н0 от единицы бесконечности,
[01:12:21.080 --> 01:12:26.440]  пересечение по всем n от н0 бесконечности,
[01:12:26.440 --> 01:12:37.400]  если я возьму дополнение, а именно вероятность пересечения по всем н0 от единицы бесконечности,
[01:12:37.400 --> 01:12:45.040]  объединение по всем от н от н0 до бесконечности, аэнт с чертой, оно будет равно нулю,
[01:12:51.040 --> 01:12:55.000]  но это есть не что иное, как вероятность аэнт с чертой бесконечности часто,
[01:12:55.000 --> 01:13:15.160]  а мы здесь что, мы из этого не можем сделать, что сумма вероятности конечна, да, у нас наоборот,
[01:13:15.160 --> 01:13:23.400]  у нас наоборот, ну ладно, давайте-то по-другому, не будем через дембар или кантеле, все гораздо
[01:13:23.400 --> 01:13:27.600]  проще здесь, значит, смотрите, почему здесь проще, а здесь проще, потому что события вложены,
[01:13:27.600 --> 01:13:38.320]  то есть вот эти вот события по н0, которые индексированы на ноль, они вложены, да,
[01:13:38.320 --> 01:13:44.840]  если я начинаю увеличивать на ноль, то каждое следующее событие будет вложено в предыдущее,
[01:13:44.840 --> 01:13:54.400]  и по теореме непрерывности вероятностной меры, ну что такое вероятность, что это означает,
[01:13:54.400 --> 01:14:03.040]  это означает, что предел вероятности при н0, стремящемся к бесконечности, вероятность того,
[01:14:03.040 --> 01:14:18.160]  что объединение по n это ноль бесконечности, а n с чертой равно нулю, да, то есть мы знаем,
[01:14:18.160 --> 01:14:22.920]  что когда у нас события вложены, то предел вероятности совпадает с вероятностью пересечения,
[01:14:22.920 --> 01:14:32.800]  раз вероятность пересечения ноль, то и предел вероятности тоже ноль, вот, а это в свою очередь
[01:14:33.120 --> 01:14:38.520]  объединение, оно, конечно, больше либо равно, чем вероятность просто а n0 с чертой,
[01:14:38.520 --> 01:14:51.200]  из этого сразу следует, что предел вероятности а n0 с чертой тоже ноль, правда, ведь объединение
[01:14:51.200 --> 01:15:00.720]  всех этих событий оно же больше, чем только а n0, предел а n0, а это и есть в точности сходимость
[01:15:00.720 --> 01:15:08.560]  вероятности, да, что такое ноль с чертой, если так, что мы доказали, давайте ноль на n заменим,
[01:15:08.560 --> 01:15:19.520]  нам уже, у нас же никого n нету, поэтому n0 просто заменим на n, а n с чертой, а n с чертой это в
[01:15:19.520 --> 01:15:26.600]  точности модуль xn-xy больше, чем epsilon, и эта вероятность равно нулю, а значит, что и требуется
[01:15:27.480 --> 01:15:33.600]  вероятности xn, если к нему вопрос.
[01:15:33.600 --> 01:15:50.040]  Почему это будет отрицание именно xn-7-x? Где, что?
[01:15:50.040 --> 01:15:58.200]  Ну, вот почему а ноль дополнения, оно является xn-x?
[01:15:58.200 --> 01:16:06.720]  Так, что такое а n? А n это событие, которое различается в том, что модуль xn-x меньше,
[01:16:06.720 --> 01:16:14.680]  правильно, чем epsilon. Отрицание этого события, дополнение к этому событию, это множество тех
[01:16:14.680 --> 01:16:18.880]  омега, для которых это не разница не выполнена, да, если а n это множество тех омега, для которых это
[01:16:18.880 --> 01:16:23.640]  не разница выполнена, то с чертой это множество тех омега, для которых это не разница не выполнена,
[01:16:23.640 --> 01:16:26.880]  ну, то есть выполнен разница модуль xn-xy больше, чем epsilon.
[01:16:26.880 --> 01:16:30.040]  Понятно.
[01:16:30.040 --> 01:16:37.920]  Так, какие еще вопросы?
[01:16:37.920 --> 01:16:47.840]  Ну, вот самая сложная часть, это доказать, что исходимость по вероятности следует,
[01:16:47.840 --> 01:16:54.000]  исходимость по распределению, об этом в следующий раз. На сегодня все. Если, может, какие-то общие вопросы.
[01:16:54.000 --> 01:17:01.600]  Ну, если нет, то всем спасибо присутствующим. До встречи в следующую субботу. До свидания.
