[00:00.000 --> 00:13.280]  значит я напоминаю что в прошлый раз мы начали с вами тему непрерывные цепи маркова это марковские
[00:13.280 --> 00:22.120]  процессы у которых время непрерывно множество состояний дискретно но у нас уже есть опыт какой-то
[00:22.120 --> 00:29.400]  анализа дискретных цепей маркова и мы частично его перенесли на непрерывные цепи там какие-то
[00:29.400 --> 00:34.360]  быстрые следствия получили но для того чтобы дальше науку это развивать получать какие-то
[00:34.360 --> 00:43.840]  содержательные результаты нам понадобилось сделать некоторые предположения процессах вот и можно по
[00:43.840 --> 00:52.920]  разному эти предположения базовые как бы вводить класс выделять и я решил вести класс непрерывных
[00:52.920 --> 00:58.200]  справа процесс вот потому что это как бы физически понятно что это такое проверяемо и
[00:58.200 --> 01:04.240]  мы благодаря этому получили множество целое множество следствий которые там справедливая
[01:04.240 --> 01:10.560]  конечных цепях ну и там может быть некоторыми оговорками переносится на счетный тоже случай
[01:10.560 --> 01:18.160]  мы с вами точно также выяснили что непрерывные цепи как они себя ведут вот ты допустим если
[01:18.160 --> 01:23.360]  стартуешь не ты в смысле а цепь если стартует из некоторого состояния она живет в нем показательное
[01:23.360 --> 01:28.800]  время потом она скачет и вот то сколько она живет в этом состоянии это случайно лично у
[01:28.800 --> 01:34.520]  нее показательное распределение обязательно и другого распределения времени жизни в состоянии
[01:34.520 --> 01:44.000]  у непрерывных цепи марков быть не может кроме показательного вот ну при прочих равных
[01:44.000 --> 01:51.120]  предположениях там однородность непрерывной справа траектории вот значит живет показательное
[01:51.120 --> 01:59.600]  время и то какие вероятности перехода в момент скачка все это короче говоря определяется матрица
[01:59.600 --> 02:06.240]  интенсивности q вот это то что мы с вами прошлый раз посмотрели сегодня мы продолжаем изучать
[02:06.240 --> 02:12.760]  непрерывные цепи маркова посмотрим их некоторые особенности ну сначала закроем вот эту вот
[02:13.120 --> 02:18.480]  тему аналогии с дискретными цепями поговорим об органичности непрерывных цепей
[02:18.480 --> 02:22.280]  органичности
[02:22.280 --> 02:36.880]  непрерывных цепей маркова здесь все очень очень похоже будет на часть для органично для дискретных
[02:36.880 --> 02:44.440]  цепей мы с вами выяснили что распределение состояние в моменте п это вектор он для
[02:44.440 --> 02:50.040]  каждого состояния вот стоит и с компонент для каждого состояния распределение это есть п
[02:50.040 --> 03:00.020]  транспонированное т на п от нуля где это есть матрица перехода на интервале времени от 0 до
[03:00.020 --> 03:05.840]  t да мы рассматриваем однородный с вами цепи а это начальное распределение и распределение в
[03:05.840 --> 03:09.360]  произвольный момент времени определяется по этой формуле, ну либо из
[03:09.360 --> 03:15.440]  дифференциального равнения, либо из этой формулы, если вы знаете P от T.
[03:15.440 --> 03:21.600]  Можем вести определение стационарного распределения, то есть то распределение,
[03:21.600 --> 03:26.080]  которое от времени не зависит, оно удовлетворяет этому равнению P0, я его
[03:26.080 --> 03:33.760]  обозначу, P от транспонированного от T равняется P0. Вот если распределение P0
[03:33.760 --> 03:40.120]  обладает вот таким свойством для любых T, то тогда оно называется
[03:40.120 --> 03:49.960]  стационарным распределением. Ну в общем-то такие как бы интуитивно-понятные
[03:49.960 --> 04:01.440]  логичные определения. Так, дальше к чему сходится P от T? Вот таким вопросом зададимся
[04:01.480 --> 04:12.120]  или к чему сходится P от T? Ну как мы на этот вопрос отвечали в дискретных цепях? Мы
[04:12.120 --> 04:21.480]  вели классификацию состояния, да, и вот сформулировали теорему органичности. Ну здесь
[04:21.480 --> 04:27.440]  мы тоже можем ввести, можем классифицировать состояние. В общем, мы будем говорить, что из
[04:27.440 --> 04:37.600]  И следует Ж, если P и Ж от T больше нуля для некоторого Т. Вот, да, мы будем говорить, что они
[04:37.600 --> 04:45.080]  сообщаются, если P и Ж, Т больше нуля и P и Ж для какого-то может быть другого Т тоже больше нуля.
[04:45.080 --> 04:55.440]  Вот, так что вот эти вот вещи как следование, сообщаемость, существенность, нулевость,
[04:55.440 --> 05:02.440]  все это то же самое как здесь, просто мы там писали N, а здесь будет T. Ведь в этих
[05:02.440 --> 05:10.720]  определениях существенности там, сообщаемости, мы нигде не пользовались тем, что время дискретно,
[05:10.720 --> 05:14.640]  на самом деле, если вы посмотрите. Мы просто букву N ее обозначали, но заменить ее на букву T,
[05:14.640 --> 05:21.240]  вообще ничего не поменяется, реально, вы можете сами это проверить. Ну я говорил на прошлой лекции,
[05:21.520 --> 05:28.840]  что, в принципе, мы могли бы про цепи рассказывать как бы в едином стиле, как бы рисовать
[05:28.840 --> 05:32.760]  Нью-Ку букву, но она может быть дискретно, может быть непрерывно, ну где-то какие-то оговорки
[05:32.760 --> 05:39.000]  делать, где-то нет. Ну единственное может быть, что здесь какие вот, что напрямую не переносится,
[05:39.000 --> 05:46.760]  это возвратность, там похитрее формула, но она нам, кстати, не потребуется, нам не потребуется
[05:46.760 --> 05:51.720]  возвратность, не будем мы с ней работать в непрерывных цепях. И вообще нет периодичности,
[05:51.720 --> 05:57.880]  ну периодичность, да, там вот существенно мы пользуемся тем, что время дискретно. Помните
[05:57.880 --> 06:03.000]  там, что такое периодичность? Это наибольший участник чисел, на которых там P и T и T больше нуля,
[06:03.000 --> 06:08.720]  да, но предполагается, что это множество, оно дискретное, время дискретно, здесь время непрерывное,
[06:08.720 --> 06:15.360]  что такое нот для дискретных, непонятно, но не вводится, периодичность состояния для непрерывных
[06:15.360 --> 06:22.680]  цепей не вводится. Все остальные вводятся, возвратность нам не нужна будет, а остальные там вот
[06:22.680 --> 06:33.720]  эти вот сообщаемые следования нулевость, все это у нас остается без изменений, просто букву N,
[06:33.720 --> 06:45.160]  букву M надо заменить на T, T, там, непрерывное время. Так, ну что, какая там, наверное уже пора тяему
[06:45.160 --> 06:55.520]  сформулировать, да? А, вот тут еще добавьте, значит, что национальное распределение, оно, если вот это
[06:55.520 --> 06:59.600]  все продиференцировать, ну в конечной цепи мы можем это точно делать, если вот это мы все
[06:59.600 --> 07:07.520]  продиференцируем, то мы получим тогда Q транспонированная P0 равно нулю, ну это как бы вот
[07:07.520 --> 07:14.600]  откуда мы можем это стационарное распределение искать, то есть либо ты его ищешь как собственный
[07:14.600 --> 07:20.200]  вектор, нормированный на единицу, отвечающий собственному значению лямбда равный единице для
[07:20.200 --> 07:27.640]  любых T вот здесь, ну тогда тебе надо знать вот эту матрицу, либо ты ищешь P0 как собственный вектор,
[07:27.640 --> 07:33.320]  нормированный на единицу, отвечающий собственному значению равную ноль вот здесь, ну вот так вот обычно
[07:33.320 --> 07:40.760]  это и дело. Вот, а мы с вами сформулируем теорему, теорему органичности для непрерывных цепей,
[07:40.760 --> 07:58.160]  которая говорит следующее, что для того чтобы непрерывная цепь Маркова, ну чтобы конечная
[07:58.160 --> 08:12.040]  непрерывная цепь Маркова была органической, то есть P и житая от T сходилась к P и житому больше,
[08:12.040 --> 08:18.640]  но это одно из тех свойств, которые мы сохраняем при переходе к непрерывному времени, при T стремящемся
[08:18.640 --> 08:33.440]  к бесконечности, чтобы вот это было выполнено для любых и жи. Необходимо и достаточно, чтобы
[08:33.440 --> 08:47.920]  она была неразложимая. Все состояния сообщаются. Вот, то есть здесь нам не нужна периодичность,
[08:47.920 --> 08:52.400]  периодичность она не вводится в непрерывных цепях, помните в дискретных неразложимая и
[08:52.400 --> 08:56.960]  непериодическая. Здесь вот периодическое, непериодическое, это все не вводится. Ну,
[08:56.960 --> 09:02.240]  доказательства я прям вот совсем полностью писать не буду, потому что оно по большому счету
[09:02.240 --> 09:07.760]  вообще не отличается от доказательства для дискретных цепей. Вот, ну давайте так вот,
[09:07.760 --> 09:14.240]  просто на словах хотя бы посмотрим. Первая необходимость, необходимость, почему она должна
[09:14.240 --> 09:21.080]  быть неразложимая. Смотрите, если у нас P и T житая от T сходится к P и житому больше нуля, это значит
[09:21.080 --> 09:28.040]  найдется момент времени, когда P и T жита будет положительным. Ну, а так как цепь конечная,
[09:28.040 --> 09:33.800]  то максимум просто берете по всем этим временам, для всех E и G и получаете, что в некоторый момент
[09:33.800 --> 09:38.600]  времени все P и T житые больше нуля, потому что они обязательно сходятся к чему-то, что больше нуля,
[09:38.600 --> 09:44.960]  значит в какой-то момент они будут отделены от нуля по определению предела. Вот, так что P и T
[09:44.960 --> 09:52.400]  житая от T сходится к P и житому больше нуля, следовательно, найдется T такой же для любых E и G,
[09:52.400 --> 10:04.360]  P и G от T больше нуля для любых T, больше либо равных T. Вот, ну в общем-то это то же самое,
[10:04.360 --> 10:18.400]  что мы писали тогда в доказательстве этой теоремы для дискретного случая. А то, что они для любых
[10:18.400 --> 10:24.160]  E и G больше нуля, означает, что они, в том числе и для соподавающих тоже, это означает, что цепь
[10:24.160 --> 10:41.200]  неразложимая. Вот, следовательно, неразложимая. Вот. Второе, ну то-то в обратную сторону,
[10:41.200 --> 10:46.920]  если неразложимая, то вот это, тут все аналогично как там, вы берете просто доказательство,
[10:46.920 --> 10:51.360]  которое у нас было для дискретного случая, выкидываете оттуда все, что связано с периодичностью,
[10:51.520 --> 10:58.560]  что нам нужно? Логика здесь та же самая. Сначала мы доказываем, что P и T, G от T,
[10:58.560 --> 11:07.760]  начиная с некоторого номера, больше нуля. Вот, то есть существует T такой, что P и T, G от T,
[11:07.760 --> 11:16.360]  для любых E и G, что вот эта штука больше нуля для любых T, больше либо равных T. Вот. А потом
[11:16.360 --> 11:21.600]  повторяем, доказав, что начиная с некоторого номера, они все больше нуля, мы там, помните,
[11:21.600 --> 11:28.760]  вводим M маленькую, M большую, везде заменяете эти N, M на какие-нибудь T и T, все. Мы там нигде
[11:28.760 --> 11:35.720]  реально не пользуемся тем, что они дискретные N и M. Вот. Так что вы можете найти N и M, которые у нас
[11:35.720 --> 11:40.040]  там смотреть как на непрерывные моменты времени. То есть единственное все отличие, это то, что нам
[11:40.040 --> 11:45.240]  не нужна теперь лемма, которую мы вводили. Помните там о том, что любое число представляется в виде
[11:45.240 --> 11:51.120]  линейной комбинации взаимопростых чисел. Это нам не нужно, периодически все убираем. И единственное
[11:51.120 --> 11:55.800]  отличие здесь будет вот в этом утверждении. Но на самом деле в непрерывных цепях оно очевидно,
[11:55.800 --> 12:05.080]  потому что, ну, например, смотрите, мы знаем, что наша цепь, как она себя ведет, она живет в состоянии
[12:05.080 --> 12:15.480]  показательное время, а потом скачет дальше. Если у вас состояния соединены, да, вот как-то,
[12:15.480 --> 12:24.640]  ну, это все состояния какие-то, то всегда существует какая-то ненулевая вероятность за любое конечное
[12:24.640 --> 12:32.440]  время попасть отсюда-сюда. Потому что у вас всегда есть какая-то ненулевая вероятность в конечное
[12:32.440 --> 12:42.920]  время побывать здесь, потом побывать здесь, а потом перейти сюда. Вот. Потому что время пребывания в
[12:42.920 --> 12:50.520]  этих состояниях, оно показательное, имеет непрерывное распределение. Так что, если вы хотите попасть из
[12:50.520 --> 12:56.840]  нулевого момента времени отсюда в момент времени ты-сюда, то у вас всегда есть ненулевая вероятность
[12:56.840 --> 13:05.440]  за время t пополам перейти отсюда-сюда. Для этого вы должны жить здесь время t пополам. Ну, и сколько там,
[13:05.440 --> 13:12.360]  допустим, время t треть жить здесь, потом перейти время t треть здесь жить и здесь жить. Ну, в общем,
[13:12.360 --> 13:19.560]  там t на треть либо t пополам, неважно. Вот. Ну, главное то, что в силу того, что распределение непрерывное,
[13:19.560 --> 13:25.960]  от нуля, значит, оно может быть сколь угодно маленьким, так что вы можете попасть отсюда-сюда
[13:25.960 --> 13:32.320]  для любого t сколь угодно малого. Так что, на самом деле, вот в этом втором пункте не просто t существует,
[13:32.320 --> 13:41.240]  t равное нулю существует. Ну, и тогда вот тут вот так вот сделать. То есть, в любой следующий момент
[13:41.240 --> 13:46.920]  времени у тебя p и t сжитое, а t будет больше нуля. Вот такая вот особенность непрерывных цепей.
[13:46.920 --> 13:52.680]  Просто потому что живешь в непрерывное время в каждом состоянии. И ты можешь всегда сделать так,
[13:52.680 --> 13:59.040]  что рассмотреть случаи, когда ты живешь там мало. Ну, пусть мало, но конечное время и вероятность
[13:59.040 --> 14:05.840]  этого не нулевая вполне себе нормальная. Вот. Ну, а потом уже после того, как мы показали,
[14:05.840 --> 14:12.400]  что все p и t сжитое t больше нуля, причем для любого t больше нуля получается в непрерывной цепи.
[14:12.400 --> 14:18.120]  Дальше мы возим вот эти наши m, маленькая m, большая, зажимаем p и t сжитое между ними,
[14:18.120 --> 14:25.000]  ну и так далее. Вот. Там мы уже никак не пользуемся тем, что наша цепь дискретная. Вот. Мы пользовались
[14:25.000 --> 14:32.440]  только здесь, но в непрерывной цепи у нас есть кое-что попроще. Мы опираемся на то, что вот в этом
[14:32.440 --> 14:37.560]  пункте, что мы живем в непрерывное время. Ну, в принципе, если хотите, вы можете на это даже не
[14:37.560 --> 14:46.040]  опираться, а вот повторить выкладки, какие у нас были там для p и t и t, то, что она больше там
[14:46.040 --> 14:52.160]  чего-то, что больше нуля для любого t. Ну, мне кажется, что это в принципе ни к чему. Мы можем
[14:52.160 --> 14:57.880]  здесь вполне опираться на то, что мы уже знаем, что мы живем в показательное время. Вот и все. Так
[14:57.880 --> 15:10.280]  что это нормально. Вот. Так что вот такая вот теорема эргодичности. Значит, у нас там еще было
[15:10.280 --> 15:18.160]  куча свойств после теоремы эргодичности следствия. Все они тоже живут без изменений. Мы нигде не
[15:18.160 --> 15:22.320]  пользуемся дискретностью, кроме, может быть, там какого-то свойства. Я не помню, где мы про
[15:22.320 --> 15:30.860]  периодичность говорим, где мы отремуем. То свойство у нас неверно. Оно, его здесь просто нет. Вот.
[15:30.860 --> 15:41.620]  Теорема о предельном распределении переносится. А, ну, у нас, кстати, там, по-моему, и не было
[15:41.620 --> 15:48.580]  никаких при периодичности ничего. То есть, о чем она говорит? Что вот эти p и g, которые здесь,
[15:48.580 --> 15:55.580]  это не просто какие-то числа. Они, если мы проварьируем g, образуют распределение. Оно
[15:55.580 --> 16:00.420]  стационарное, вот в этом смысле. То есть, оно стационарное в этом смысле, но вы дифференцируете,
[16:00.420 --> 16:05.660]  получаете вот это. То есть, оно стационарное, вот это распределение стационарное, по-житому сходится к
[16:05.660 --> 16:11.780]  нему. И вот это p от, каким бы ни было начальное распределение, при t, стремящемся к бесконечности,
[16:11.780 --> 16:18.980]  сойдется к этому стационарному распределению, которое, опять же, единственно. Все то же самое,
[16:19.380 --> 16:24.860]  абсолютно. Все то же самое. Ну и последнее, что я напишу, это аналог вот этой теоремы
[16:24.860 --> 16:38.660]  о связи между средним временным и средним по пространству, по исходам. Как эта теорема обобщается?
[16:38.660 --> 16:53.020]  Значит, теорема нападет со звездочкой в конечной однородной непрерывной цепи Маркова. Ну там
[16:53.020 --> 17:04.940]  непрерывными право траекториями. Ну это у нас так всегда. Что у нас справедливо? Ну там у нас
[17:04.940 --> 17:11.620]  был ряд, потому что время было дискретно, теперь время непрерывно, у нас интеграл. Индикатора того,
[17:11.620 --> 17:29.300]  что x, наш процесс, t равно g, равно g dt, да, вот это сходится к p-житому, который является
[17:29.300 --> 17:40.020]  пределом p-житых от t для любого i, при t, стремящемся к бесконечности. Вот это наше временное среднее,
[17:40.020 --> 17:43.580]  вот это наше пространственное среднее, потому что это вероятность, вероятность это некое
[17:43.580 --> 17:50.060]  мотожидание. Вот по исходам некоторые там Бернольско случайные величины, поэтому это говорят
[17:50.060 --> 17:54.980]  среднее по пространству, по вероятностям пространства, по пространству исходов. Вот, а это
[17:54.980 --> 18:00.860]  среднее временное, видите, как у нас мы можем быть в этом состоянии g, можем не быть, в какие-то
[18:00.860 --> 18:11.820]  моменты времени мы там есть, в какие-то мы там, нас там нет. Ну вот берем интеграл, как бы регистрируем
[18:11.820 --> 18:17.220]  все случаи, когда мы пребываем в этом состоянии, но еще делим на t, потому что нам среднее нужно,
[18:17.220 --> 18:22.340]  но оказывается, что вот эта вещь сходится вот сюда, но это мы берем без доказательств. Просто такой
[18:22.340 --> 18:35.260]  аналог, что и в непрерывных цепях тоже такая тярема есть. Вот. А, да, нужно, конечно, в конечной
[18:35.260 --> 18:48.420]  оргодической. Спасибо. В неоргодических цепях вот это может не быть, поэтому, да, спасибо. Хорошо.
[18:48.420 --> 19:03.820]  Ну вот это было все, что как бы мы получаем, как в дискретных цепях, аналоги в непрерывном случае.
[19:03.820 --> 19:19.300]  Теперь движемся дальше. Будем переходить к случаям, которые особенные для непрерывных цепей. Ну,
[19:19.300 --> 19:35.340]  а сначала я веду определение процессы гибели и рождения из биологии пришло. Значит, вот такой
[19:35.340 --> 19:50.780]  процесс. Значит, 0, 1, 2, n-1. У меня будет верхой и внизу стрелки. Значит, стрелка мы обозначаем
[19:50.780 --> 19:57.300]  возможный переход, а над стрелкой мы рисуем интенсивность перехода. Лямда 1, по-моему, я ее обозначаю сейчас.
[19:57.300 --> 20:24.060]  Лямда 2, здесь будет лямда минус 1, лямда n. Так, а здесь мил n. Здесь мил n, мил 3, мил 2, мил 1.
[20:24.060 --> 20:33.180]  Все лямды имеют интенсивности переходов. n меньше либо равно бесконечности, натуральное число. То есть, в принципе,
[20:33.180 --> 20:45.020]  может быть цепь бесконечная. Вот. Значит, вот такая цепь Маркова таким графом, она называется процессом
[20:45.020 --> 20:50.580]  гибели и рождения. Просто можете написать. Процессы такого вида называются процессами гибели и рождения.
[20:50.580 --> 20:58.060]  Лямды называются интенсивностями рождения. Они могут быть все одинаковыми, могут быть равными. Какие-то из них
[20:58.060 --> 21:06.060]  они могут быть равны нулю. То есть, где-то перехода может не быть. Вот. Интенсивности рождения,
[21:06.060 --> 21:16.060]  интенсивности гибели. Ну, откуда это берется? Вот. Иногда вводят в биологии где-то такие модели,
[21:16.060 --> 21:27.540]  что ты рассматриваешь размер популяции некоторой. Вот. Популяция, то есть, сколько у тебя видов
[21:27.540 --> 21:36.540]  существует. Ну, не видов, а, как это назвать, экземпляров твоего вида существует в рассматриваемой
[21:36.540 --> 21:42.020]  системе. Это процесс некоторый, да, непрерывно зависящий от времени. И вот это сколько их,
[21:42.020 --> 21:51.700]  короче говоря. И вот есть такие модели, процессы гибели и рождения, которые описывают эволюцию числа
[21:51.700 --> 21:58.300]  экземпляров некоторого вида. Ну, это вот самая общая такая, самый общий вид принимают. Такие модели
[21:58.300 --> 22:05.140]  рассматриваются. Допустим, у тебя никого, допустим, ну да, вот конечно странно, как из нуля может
[22:05.140 --> 22:11.620]  получиться единица, из единицы получится кто-то, да, ну понятно, что там можно начинать, есть интенсивность
[22:11.620 --> 22:16.540]  здесь нулями там расставить, да, там в одну только сторону. Если ты сюда пришел, то, например, из нуля в
[22:16.540 --> 22:22.220]  единицы у тебя не может быть, поэтому и 1 равно нулю. Из одного 2 тоже не может быть, если тогда
[22:22.220 --> 22:27.860]  и 1 и 2 равно нулю. А здесь вот, допустим, у тебя было два, кто-то умер, стал один, кто-то умер,
[22:27.860 --> 22:35.980]  стал ноль и все, и дальше уже стрелка никуда не идет, ну либо ты рисуешь ее как бы на себя. Вот, то есть
[22:35.980 --> 22:45.540]  вот эта вот модель для, в биологии, для эволюции количества экземпляров вида. Это лямбда интенсивности
[22:45.540 --> 22:53.500]  рождения, мил интенсивности гибели. Лямбда ит, мил ит, они больше либо равны нуля. Вот, n меньше либо равно
[22:53.500 --> 23:00.900]  бесконечности. Но здесь одну теорему я сформулирую без доказательства. Стационарное распределение
[23:00.900 --> 23:15.820]  вот в такой цепи, то есть если n меньше бесконечности, то стационарное распределение мы можем записать,
[23:15.820 --> 23:32.700]  пи 0 это вектор. Вот с такими вот компонентами. Значит, пи gt 0, это есть лямбда g разделить на мю,
[23:32.700 --> 23:47.460]  на пи g-1. Для g больше равных единицы, то есть пи первое, пи второе и так далее до конца. И нам здесь
[23:47.460 --> 23:55.420]  не хватает только пи 0 определить. А пи 0 определяется так, чтобы сумма всех пи была равна единице. Так что
[23:55.420 --> 24:06.860]  пи 0, ну там большая формула такая. Я ее напишу, значит 1 плюс лямда 1 мю 1 плюс лямда 1 лямда 2
[24:06.860 --> 24:21.620]  разделить на мю 1 мю 2 плюс и так далее плюс лямда 1 лямда n разделить на мю 1 мю n в минус первой
[24:21.620 --> 24:27.700]  степени. Эта формула, сумма всех них должна быть равна единице.
[24:27.700 --> 24:40.980]  Поэтому пи 0 должен быть вот таким. Ну без доказательства, хотя там по большому счету
[24:40.980 --> 24:45.300]  ничего сложного нет. То есть если вы эту формулу не запомните, тогда вы ее всегда можете вывести.
[24:45.300 --> 24:51.540]  Вы просто пишете матрицу Q для вот этой вещи и ищете пи 0 такой, что Q транспонированная пи 0 равна 0.
[24:51.540 --> 24:57.380]  Ну и там, когда вы посмотрите, вы просто увидите, что эти пи должны быть вот такими, а пи 0
[24:57.380 --> 25:04.260]  должны быть таким, чтобы сумма их всех была равна единице. Вот и все. Вот.
[25:04.260 --> 25:15.500]  Если все мю равны 0, а лямда не 0, это называется процессом рождения или процессом чистого рождения.
[25:15.500 --> 25:23.340]  Если все лямда равны 0, мю не равны 0, это процесс чистой гибели. Бывают там разные варианты,
[25:23.340 --> 25:28.900]  как вы расставите мю. Мю и лямда могут быть одинаковыми, могут быть разными, какими угодно.
[25:28.900 --> 25:38.460]  Вот этот процесс гибели рождения. Хорошо. Это понятие мы вели. Дальше идем.
[25:38.460 --> 25:55.420]  Поговорим про взрывные марковские цепи. Такого нет в дескретных цепях.
[25:55.420 --> 26:10.460]  Значит, еще раз вспоминаем, как ведет себя типичная цепь маркова. Вот я нарисую ось
[26:10.460 --> 26:19.460]  времени. Допустим, здесь 0. Если мы стартуем из какого-то состояния, мы живем в нем показательное
[26:19.460 --> 26:30.620]  время. Когда это время проходит, мы куда-то скачем. Пусть это момент времени t1. Вот. Когда мы куда-то
[26:30.620 --> 26:36.820]  скакнули, мы там тоже живем показательное время. И оттуда мы тоже скакнем в какой-то другой момент
[26:36.820 --> 26:43.220]  времени t2. Потом какой-то момент времени t3 и так далее. Пусть вот эта последовательность t это
[26:43.220 --> 26:53.980]  момент времени скачков. Вот к чему сходится эта последовательность? Таким вопросом зададимся.
[26:53.980 --> 27:07.380]  Вседалее она идет в бесконечность. Может ли она дойти до некоторого предела? В дескретных цепях это
[27:07.380 --> 27:16.820]  невозможно. Вот. А в непрерывных цепях, смотрите, ведь мы живем какое-то время показательно распределенное
[27:16.820 --> 27:25.540]  сначала интенсивности лямбда 1. Вот здесь. Здесь мы живем, вот давайте я тут напишу, лямбда 1, здесь
[27:25.540 --> 27:35.140]  лямбда 2 и так далее. Вот эта лямбда — это интенсивность. И за что она отвечает? 1 делить на лямбду — это
[27:35.140 --> 27:41.580]  среднее время для t1. Помните, математическое ожидание такой случайной величины — это 1 делить на
[27:41.580 --> 27:47.020]  лямбда 1, что называется интенсивностью, потому что обратная к ней величина — это среднее время,
[27:47.020 --> 27:53.420]  среднее время получается. Если t — это время, тогда 1 делить на лямбда — это среднее время, то есть
[27:53.420 --> 28:01.060]  среднее значение того, сколько мы будем жить в каждом состоянии. Так вот, если здесь какая-то
[28:01.180 --> 28:09.580]  лямбда 1, здесь лямбда 2, которая получается больше, чем лямбда 1, а значит 1 делить на лямбда 2
[28:09.580 --> 28:16.380]  меньше, время жизни меньше. Лямбда 2 больше, время жизни меньше. И допустим, что здесь лямбда 1,
[28:16.380 --> 28:21.100]  здесь лямбда 2, здесь лямбда 3, и так далее. И вот эта лямбда n, она очень быстро уменьшается.
[28:21.100 --> 28:29.180]  Может ли получится так, что у тебя за конечное время произойдет бесконечное множество переходов?
[28:29.180 --> 28:37.060]  вот оказывается может такие цепи называются взрывными вот это они характеризуются тем что
[28:37.060 --> 28:43.540]  это лямбда она очень быстро очень быстро увеличивается соответственно 1 делить на лямбда
[28:43.540 --> 28:49.660]  очень быстро уменьшается и у тебя как бы вот это время жизни в каждом состоянии оно очень
[28:49.660 --> 28:55.340]  очень быстро уменьшается и на самом деле цепь производит бесконечную множество переходов за
[28:55.340 --> 29:05.340]  конечное время но давайте поймем как как как так получается и каковы условия когда так получается
[29:05.340 --> 29:19.940]  значит мы будем называть цепь взрывной значит цепь маркова x отт назовем взрывной если вероятность
[29:19.940 --> 29:28.820]  того что тн стремится к бесконечности равна единице вот то есть вероятность множество
[29:28.820 --> 29:35.460]  исходов на которых тн сходится к бесконечности а господи нет не бесконечности а какому-то
[29:35.460 --> 29:43.020]  извините это ноль меньше бесконечности вот ноль кстати тоже плохо да а т ноль у нас нет у нас
[29:43.020 --> 29:48.780]  мы начинаем от единицы ну допустим вот если она равна единице кстати равносильно тому если
[29:48.780 --> 29:56.860]  для любого состояния и у тебя вероятность тн сходится к т ноль при условии что в начальном
[29:56.860 --> 30:02.540]  момент времени это стартовал из и если вот эта вещь равна единице но этот формул следует из
[30:02.540 --> 30:11.340]  этой по формуле полной вероятности вот называется взрывной если но иначе она не взрывная вот иначе
[30:11.340 --> 30:18.460]  она не взрывная если если вероятность вот этого меньше единицы да
[30:18.460 --> 30:35.300]  чего мысли нет ну почему она может стремиться к бесконечности это типичный случай когда она
[30:35.300 --> 30:41.360]  стремится к бесконечности обычно она стремится к бесконечности вот мы рассматриваем такой
[30:41.360 --> 30:46.980]  интересный случай когда она стремится не бесконечности какому-то числу вот не взрывная
[30:46.980 --> 30:51.620]  когда это вероятность меньше единицы она не обязательно равно нулю принципе как бы какая-то
[30:51.620 --> 30:57.100]  мера возможно но я не знаю если там теорема о том что это вероятность может быть только либо
[30:57.100 --> 31:05.140]  0 либо 1, ну взрывные определяют, когда эта вероятность равна единице. Вот, когда почти все
[31:05.140 --> 31:16.100]  траектории, они как бы заканчиваются за конечное время. Сформулирую теорему из теории вероятности и
[31:16.100 --> 31:24.260]  докажу ее, которая поможет определять, является ли цепь взрывного или нет.
[31:24.260 --> 31:53.980]  Значит, теорема. Значит, пусть КСН от Единства Бесконечности это независимые случайные
[31:53.980 --> 32:05.020]  величины с показательным распределением СИТ. Распределено показательно, как лямбда и Т. Лямбда могут
[32:05.020 --> 32:16.540]  быть разными, могут быть одинаковыми. Вот. Пусть. Тогда. Как независимость. Да, это обязательно.
[32:16.540 --> 32:36.540]  Тогда. Значит, если вот такой ряд, если такой ряд сходится, то тогда вероятность сумма КСН меньше
[32:36.540 --> 32:49.100]  бесконечности равно единице. Вот. Тогда вон тот ряд почти наверное сходится. Если этот ряд расходится,
[32:49.100 --> 33:08.220]  то тогда и вот этот ряд расходится. Ну вот. Давайте доказывать теорему.
[33:08.220 --> 33:31.140]  То есть эта теорема как раз следует, как сильно должны увеличиваться лямбды. Как быстро. Доказательства
[33:31.140 --> 33:46.700]  очень простой в этой теоремы. Начнем с первого пункта. То есть пусть сумма сходится. Тогда мы
[33:46.700 --> 34:00.380]  рассмотрим вот такой ряд и математическое ожидание его. Это есть как раз, мы можем
[34:00.380 --> 34:05.940]  математическое ожидание носить внутрь. Это мат. ожидание КСН, а это как раз 1 делит ноль
[34:06.540 --> 34:18.580]  Вот. Ну сходится. По этому предположению. Значит, математическое ожидание вот этой величины
[34:18.580 --> 34:28.180]  конечно. Значит, у нас вероятность единицы принимает конечные значения. То есть вероятность того,
[34:28.180 --> 34:39.380]  что сумма КСН меньше бесконечности равна 1. Потому что если бы была не нулевая вероятность,
[34:39.380 --> 34:46.860]  что она принимает бесконечное значение, то мат. ожидание было бы бесконечным. Правильно? Понятно
[34:46.860 --> 34:53.700]  это? Значение умножить на вероятность. И там среди слагаемых будет значение бесконечность умножить
[34:53.700 --> 34:57.180]  на вероятность, которая не ноль. Значит бесконечность. А мы показали, что мат.
[34:57.180 --> 35:03.700]  ожидания конечна. Все значит с вероятностью единицы она принимает конечные значения. Отлично.
[35:03.700 --> 35:11.100]  Вот. Теперь вон тот случай. Ну немножечко похитрее. Немножечко похитрее. Не знаю,
[35:11.100 --> 35:31.260]  где писать. Давайте здесь попробую уместить. Значит пусть теперь вот эта сумма равна бесконечности.
[35:31.260 --> 35:44.780]  Рассмотрим как бы невзначай математическое ожидание экспоненты от минус суммы бесконечность КСН.
[35:44.780 --> 35:59.940]  По-моему такое. Да. Рассмотрим. Ну экспоненты суммы есть произведение экспонент, так как они
[35:59.940 --> 36:05.540]  независимые, то мат. ожидания произведения экспонент будет равна произведению мат. ожидания. Так?
[36:05.540 --> 36:14.540]  У нас так всегда было. Значит что мы получаем? Произведение математических ожиданий экспонент
[36:14.540 --> 36:23.180]  минус КСН в силу независимости. Ну мы знаем распределение КСН. Мы можем вычислить мат.
[36:23.180 --> 36:29.340]  ожидания экспонента минус КСН. Ну я сразу же напишу чему это равно. Ну просто взять некий
[36:29.340 --> 36:35.340]  интеграл. Получается это элементарно. Получается там 1 разделить на 1 плюс лям ДН в степени минус 1.
[36:35.340 --> 36:43.100]  Вот. Ну просто честно взять интеграл, там почитать на мат. ожидания, получится вот такая вещь.
[36:43.100 --> 36:53.220]  Вот. Ну вот оказывается, что вот это произведение равно нулю. И здесь существенно то, что вот этот ряд
[36:53.220 --> 37:03.740]  расходится. А понять это можно так, что мы докажем, что произведение равно нулю, если логарифм вот этой
[37:03.740 --> 37:11.500]  вещи равен минус бесконечности. Ну либо минус логарифм этой вещи равен плюс бесконечности. Вот.
[37:11.500 --> 37:21.900]  А это означает минус, значит сумма, ну логарифм произведения равно сумме логарифмов. Да. Да.
[37:21.900 --> 37:32.460]  Я это. 1 плюс 1 разделить на лям ДН. Вот. Ну а этот ряд, он сходится и расходится тогда же,
[37:32.460 --> 37:38.620]  когда и вот этот ряд. Ну, например, там по признаку сравнения, да. Вот. Ну здесь мы
[37:38.620 --> 37:43.660]  пользуемся тем, что это положительные величины. Вот. Здесь все хорошо с этим. Там никакие незнаки
[37:43.660 --> 37:50.780]  чередующиеся. Здесь все знака постоянная. Вот. Так что этот расходится, значит этот ряд расходится.
[37:50.780 --> 37:55.580]  С минусом он равен минус бесконечности. Потенцируем обратно. Значит получается,
[37:55.580 --> 38:03.940]  что это произведение равно экспоненте от минус бесконечности. То есть то. Вот. То есть получается,
[38:04.660 --> 38:15.700]  что математическое ожидание не отрицательной величины экспонента равна нулю. Ну никуда не
[38:15.700 --> 38:20.260]  деться, значит она должна быть равна нулю почти всюду. Вот эта экспонента, вот эта сумма,
[38:20.260 --> 38:28.420]  минус суммы. Экспонента равна нулю. Значит, минус сумма равна минус бесконечности. Значит,
[38:28.420 --> 38:33.380]  сумма равна бесконечности. Почти всюду. Вот и все. А это нам и нужно было доказать.
[38:33.380 --> 38:45.020]  Итак, мотожидание неотрицательной величины равно нулю. Тогда и только тогда, когда эта величина
[38:45.020 --> 38:51.580]  почти всюду равна нулю. Это означает, что... а это возможно тогда и только тогда, когда почти
[38:51.580 --> 38:56.820]  всюду вот эта сумма равна плюс бесконечности. С минусом будет минус бесконечности, экспонент
[38:56.820 --> 39:05.460]  минус бесконечности ноль. Вот. Вот такая интересная теорема. Она никак не использует случайный
[39:05.460 --> 39:08.620]  процесс здесь. Это такая теорема из теории вероятности, но она очень такая красивая,
[39:08.620 --> 39:14.340]  поэтому я ее здесь привожу. Ну и мгновенное следствие отсюда. Если вы рассматриваете процесс
[39:14.340 --> 39:20.100]  чистого рождения, то тогда скачки как раз происходят в эти моменты времени,
[39:20.340 --> 39:32.380]  которые равны суммам вот этих кси, где кси показательно распределенные. Так что если процесс
[39:32.380 --> 39:45.020]  чистого рождения, то он взрывной тогда и только тогда, когда вот этот ряд расходится. Процесс
[39:45.020 --> 39:51.660]  чистого рождения взрывной тогда и только тогда, когда ряд вот этот расходится. По-осонненский
[39:51.660 --> 40:01.580]  процесс. Это процесс чистого рождения. У него какой? Граф ноль, один, два и так далее. И здесь стоит
[40:01.580 --> 40:13.660]  лямда везде. Все лямды одинаковые. Так. И ряд один разделить на лямда расходится для по-осонненского
[40:13.660 --> 40:20.420]  процесса. Значит, у нас вот этот случай. Значит, по-осонненский процесс не взрывной.
[40:20.420 --> 40:36.340]  По-осонненского процесса это невозможно. Вот. По-осонненского процесса это невозможно.
[40:36.340 --> 40:40.780]  Чтобы процесс был взрывным, интенсивности должны расти достаточно быстро. Они у него вообще не
[40:40.780 --> 40:57.500]  растут. Так. Следующая тема сегодняшней лекции — потоки событий. Не можем обойти стороной
[40:57.500 --> 41:06.460]  эту тему, потому что она очень прямо и непосредственно связана с непрерывными цепями Маркова. Значит,
[41:06.660 --> 41:11.060]  потоком событий называется последовательность одинаковых событий, которые происходит как-то во
[41:11.060 --> 41:17.780]  времени. Вот здесь числовая ось. Ось времени. И здесь как-то происходят события в какие-то
[41:17.780 --> 41:21.240]  моменты времени. Вот здесь произошло события. Здесь произошло, здесь произошло, здесь произошло,
[41:21.240 --> 41:26.380]  здесь, здесь, ну и так далее. Вот они как-то проходят последовательности одинаковых событий
[41:26.380 --> 41:33.500]  называются потоком — поток событий. Вот давайте немножечко изучим вероятностные свойства таких
[41:33.500 --> 41:40.860]  потоков событий при некоторых предположениях. Первое, что мы сделаем, мы ведем случайную
[41:40.860 --> 41:49.820]  величину n t1 t2. Это сколько произошло событий на интервале времени t1 t2? Это число событий
[41:49.820 --> 41:58.300]  на интервале t1, но там формально надо справа открыто держать, чтобы все было
[41:58.300 --> 42:09.700]  корректно потом. Число событий на t1 t2. Какие мы сделаем предположения? Во-первых, рассмотрим
[42:09.700 --> 42:26.500]  однородный поток событий. Пусть n t1 plus h, t2 plus h и n t1 t2 имеют одинаковое распределение.
[42:26.500 --> 42:37.260]  Пусть они одинаково распределены. Тогда поток называется, как вы уже могли бы догадаться,
[42:37.260 --> 42:47.820]  однородным или стационарным. Сколько событий произойдет, зависит только длина интервала,
[42:47.820 --> 42:55.900]  но не зависит от того, где ты рассматриваешь этот интервал. Бывают, конечно, не однородные
[42:55.900 --> 43:06.300]  потоки событий. Мы пока поговорим про однородные потоки событий. Еще одно предположение ведем.
[43:06.300 --> 43:12.740]  Сколько событий происходит здесь, пусть не зависит от того, сколько событий происходит здесь,
[43:12.740 --> 43:26.660]  то есть на непересекающихся интервалах. Пусть kt есть n tk tk plus 1, где там 0 t1 t2 и так далее.
[43:26.660 --> 43:41.420]  Вот такие вот моменты времени. Пусть kt такие и пусть они независимы в совокупности для любых
[43:41.420 --> 43:51.980]  вот этих вот ткатах. Их может быть конечное, бесконечное множество, счетное. Пусть они все
[43:51.980 --> 43:58.140]  независимы в совокупности. Сколько здесь, сколько здесь происходит, пусть они независимы. Кстати,
[43:58.140 --> 44:05.540]  это напоминает то, когда я вводил полосуновский процесс, помните? Тут все взаимосвязано,
[44:05.540 --> 44:17.220]  абсолютно. Тогда такой поток называется потоком безпоследействия. Такая терминология
[44:17.220 --> 44:43.940]  сформировалась. А вот теперь давайте мы применим наши знания о непрерывных маркетических
[44:43.940 --> 44:52.820]  цепях и изучим вот эту величину n, число событий на интервале времени. Но мы будем говорить только
[44:52.820 --> 45:00.580]  про однородные потоки безпоследействия. И тогда нам неважно рассматривать, где вот эту n,
[45:00.580 --> 45:08.260]  где ее локализовать. Давайте мы для определенности возьмем t1 равный 0, например, и будем рассматривать
[45:08.260 --> 45:21.620]  n0t, то есть это n0t, число событий на интервале от 0 до t. Это процесс. Вот давайте мы его изучим.
[45:21.620 --> 45:29.740]  Что это за процесс такой? Сколько событий произошло на интервале времени от 0 до t. Смотрите.
[45:29.740 --> 45:44.620]  Время непрерывно. Множество состояний дискретно 0, 1, 2 и так далее. Что напрашивает сразу? Не
[45:44.620 --> 45:49.540]  является ли это маркетским процессом, причем непрерывной цепью Маркова? Но является ли он
[45:49.540 --> 46:01.380]  марковским? Он безпоследействия. Значит все вот эти независимые совокупности. А что это такое? Это же
[46:01.380 --> 46:16.940]  есть приращение икса на вот этих интервалах времени. Так? n tk n tk плюс 1 это есть n от tk минус n
[46:16.940 --> 46:30.380]  плюс 1 минус n tk. Вот. Тогда получается, что если они независимы в совокупности, то приращение этого
[46:30.380 --> 46:34.700]  процесса на непересекающихся интервалах независимо в совокупности. А как это называется?
[46:40.700 --> 46:48.140]  Если процесс имеет независимые... Как это называется? Если дан процесс независимыми приращениями,
[46:48.140 --> 46:52.300]  то он марковский. Это процесс независимым приращениями. Да, вы совершенно правильно
[46:52.300 --> 47:04.940]  вспомнили. У нас была теорема. Следовательно, x от t это процесс независимыми приращениями.
[47:04.940 --> 47:16.940]  Следовательно, он марковский. Вот. Была у нас такая теорема. Так что марковский процесс с непрерывным
[47:16.940 --> 47:25.700]  временем и дискретно множеством состояний. Следовательно, это n от t или x от t или n от t это
[47:25.700 --> 47:39.540]  одно и то же. Это непрерывная цепь маркова. Дальше. Для того, чтобы нам как бы подключить
[47:39.540 --> 47:45.220]  всю эту библиотеку знаний, говоря на языке программирования, а непрерывных цепях и просто
[47:45.220 --> 47:56.300]  применить ее к этому. Нам чего не хватает? Самое важное. Что нам? Я вас, я к вам подводил сегодня в
[47:56.300 --> 48:00.580]  начале лекции. Что нам нужно, чтобы вот эту всю науку, которую мы развили на прошлой лекции,
[48:00.580 --> 48:11.020]  применить к этому процессу? Какое? Что нам нужно еще пожелать от этого процесса? Не-не-не-не-не. Еще
[48:11.020 --> 48:17.020]  раньше. Самое первое. Без чего бы мы бы ничего не получили. Главное наше предположение о процессах.
[48:17.020 --> 48:31.580]  Не-не-не-не. Еще самое. Еще. Еще важное. Непрерывность права траекторий. Это ключевая вещь. В этом смысле,
[48:32.580 --> 48:43.100]  непрерывность справа. Это значит, что когда какое-то событие потока произошло, обязательно есть
[48:43.100 --> 48:51.060]  какой-то конечный интервал, пусть и малый, когда больше никаких событий не происходило. Нет такого,
[48:51.060 --> 48:57.300]  что какой бы ты маленькую окрестность не брал, там все равно будут какие-то события. Смотрите,
[48:57.300 --> 49:04.380]  как это. События, как это. Всюду плотно. Такие вот нефизические ситуации мы не будем рассматривать.
[49:04.380 --> 49:12.340]  Так что, да, сделаем дополнительное предположение о том, что когда какое-то событие происходит,
[49:12.340 --> 49:19.580]  обязательно есть какое-то конечное, пусть и малое, но конечное время, когда больше никаких событий
[49:19.580 --> 49:36.500]  не происходит. То есть, пусть между событиями проходит конечное время. Но тогда это будет
[49:36.500 --> 49:48.100]  значить, что вот этот процесс С на Т или Х от Т, он имеет непрерывные справа траектории. Все.
[49:48.140 --> 49:58.220]  Отсюда мы мгновенно получаем всю науку. Всю оставшуюся науку. О существовании, о том,
[49:58.220 --> 50:05.140]  что П непрерывные, дифференцируемые, о том, что матрица Q, о том, что мы живем в каждом состоянии
[50:05.140 --> 50:15.180]  и показательное время и так далее. Мгновенно следует отсюда. Каковы же интенсивности этих переходов?
[50:15.180 --> 50:25.940]  Значит, во-первых, давайте мы так посмотрим. Что нам надо? Граф этой цепи, как он выглядит?
[50:25.940 --> 50:39.740]  Из 0, 1, 2 и так далее. Если мы рассмотрим вероятность перехода из И в И плюс 1 на
[50:39.740 --> 50:51.500]  конечном интервале времени, то это будет означать вероятность того, что N в момент H,
[50:51.500 --> 51:01.540]  ну или так вот, Т плюс H, равняется И плюс 1 при условии, что N, ну для любого Т, потому что процесс
[51:01.540 --> 51:14.540]  однородный. N на T равно I. Вот. И теперь, если мы знаем, что N на T равно I, мы от этой части вычтем N на T,
[51:14.540 --> 51:26.500]  а из этой вычтем I. Они же равны. Тогда мы получим вероятность N. Да, и так как процесс однородный,
[51:26.500 --> 51:40.700]  мы уберем вот эту T. Тогда получается, что NH, как бы тут лучше поступить. NH минус N0, но N0 равно 0.
[51:40.700 --> 51:49.300]  Хотя, если N0 начинать не от 0, то тоже все нормально. Ну ладно, может быть, я пока оставлю T. Давайте
[51:49.300 --> 52:04.740]  попробуем так. N на T равно 1 при условии, что N на T равно I. Вот. Так, вы видите, здесь И пропало. Это тоже
[52:04.740 --> 52:11.940]  важно. И пропало. Но процесс имеет независимые приращения. Вот это приращение не зависит от
[52:11.940 --> 52:26.900]  этого NT минус N0. Поэтому это мы убираем. У нас остается вот это. Вот. А это означает вероятность N
[52:26.900 --> 52:43.460]  ATT плюс H равно 1. Вот. А это означает в силу однородности N0H равно 1. То есть вероятность NH равно 1.
[52:43.460 --> 52:50.780]  Вероятность того, что на интервале 0H произошло одно событие. Это с одной стороны. С другой стороны,
[52:50.780 --> 52:58.060]  мы знаем, что у этой вещи существует производное. Что Pi плюс 1H разделить на H
[52:58.060 --> 53:04.140]  сходится к некоей лямбде. Причем так как вот эта штука убралась, и она от И не зависит, то она от
[53:04.140 --> 53:12.180]  И не зависит. То есть Pi запятая I плюс 1 от H разделить на H сходится к лямбде. И лямба от И не
[53:12.180 --> 53:24.660]  зависит, потому что здесь мы убрали ее. Она убирается. Вот. Это где лямбда и интенсивность
[53:24.660 --> 53:33.060]  перехода. Получается, что они все имеют одинаковую интенсивность перехода. Вот так. А отсюда следует,
[53:33.060 --> 53:38.260]  что если ты теперь рассмотришь И и плюс два, то у тебя там будет порядка H квадрата, и она уже
[53:38.260 --> 53:44.740]  сюда, и такой стрелочки уже нет. Вот. Потому что переход отсюда сидал, но уже порядка H квадрата.
[53:44.740 --> 53:52.260]  Вероятность перехода от H, как H квадрат. Вот. Значит, достаточно, значит, граб действительно такой.
[53:52.260 --> 54:01.620]  Значит, граб действительно такой. Ну вот. Вот эта лямбда называется интенсивностью потока. Она
[54:01.620 --> 54:07.620]  одинаковой у однородного процесса. Мы могли вводить не однородный процесс, тогда она бы зависела от
[54:07.620 --> 54:15.180]  времени. Ну просто потому, что мы бы тогда не смогли вот здесь избавиться от Т. То мы ее убираем,
[54:15.180 --> 54:21.620]  и у нас получается число. Видите? Независище от И, не от времени, от Т, ни от чего независище. А так,
[54:21.620 --> 54:28.460]  если бы процесс был не однородным, мы бы просто не смогли убрать вот это. Все выкладки бы оставались,
[54:28.460 --> 54:33.860]  мы просто не смогли бы убрать вот это. Ну, лямба тогда бы зависела от Т. Была бы лямда от Т. Она не
[54:33.860 --> 54:40.140]  зависела бы от И. То есть, везде вот здесь была бы не просто лямда, а лямда от Т. Вот. Для не однородного
[54:40.140 --> 54:46.340]  потока. Ну, мы для простоты однородным пока ограничимся. Вот. Так что отношение вот этих
[54:46.340 --> 54:54.380]  вероятностей лямбда. И, а эта вероятность, есть вот эта. Значит, получается, что вероятность nH
[54:54.380 --> 55:03.620]  равно единице, это есть лямбда H плюс умалая от H при H, стремящемся к нулю. А вероятность,
[55:03.620 --> 55:15.460]  ну, из этих же выкладок, если мы рассмотрим переход из 0 в 2, мы можем доказать, что вот
[55:15.460 --> 55:24.580]  эта вещь, она тоже умалая от H при H, стремящемся к нулю. Ну, и отсюда следует, что вероятность nH равна
[55:24.580 --> 55:32.820]  нулю. Это есть единица минус лямбда H плюс умалая от H при H, стремящемся к нулю. Вот. Такие формулы.
[55:32.820 --> 55:39.500]  Вообще, потоки, которые обладают вот этими свойствами, которые здесь выписаны, они еще
[55:39.500 --> 55:53.820]  называются ординарными потоками. Нарный поток. Это свойство ординарности, то, что я там написал.
[55:53.820 --> 56:05.300]  Это свойство ординарности. Ну вот. Так что теперь мы все понимаем про нашу цепь. Здесь она стартует
[56:05.300 --> 56:14.380]  из нуля. Она живет в состоянии показательное время интенсивности лямбда. Вот. Потом скачет в единицу.
[56:14.380 --> 56:28.020]  Потом живет в этом состоянии показательное время с лямбдой. И скачет дальше. И так далее. Вот. А это
[56:28.020 --> 56:40.420]  есть не что иное, как полусоновский процесс. Вот. То есть получается, что nT в этих предположениях,
[56:40.420 --> 56:56.300]  которые мы сделали, это полусоновский процесс. Вот мы к нему пришли. Получается, что а соответствующий
[56:56.300 --> 57:01.740]  поток при этих предположениях называется простейшим полусоновским потоком событий. То есть это поток,
[57:01.740 --> 57:13.500]  который однородный, без последствия. Вот. И, например, с непрерывными траекториями вот здесь,
[57:13.500 --> 57:21.940]  или такой, что они не могут быть бесконечно близки, два события. Либо можно без этого,
[57:21.940 --> 57:28.380]  а говорить сразу про ординарность. Вообще, я бы хотел сейчас поговорить с вами вот все оставшееся
[57:28.380 --> 57:34.140]  время, потратить на эквивалентные определения. Если вы откроете разные книжки, вы увидите,
[57:34.140 --> 57:45.100]  что все эти понятия по-разному и всеми вводятся. Вот. Часто сначала вводятся потоки, а потом на их
[57:45.100 --> 57:52.700]  основе вводится определение непрерывных цепей Маркова. Иногда наоборот. Как я поступил? Я
[57:52.700 --> 57:57.860]  сначала ввел вам определение непрерывных цепей Маркова, а потом мы рассмотрели потоки,
[57:57.860 --> 58:03.140]  примитивные свойства, и разобрали эти потоки с точки зрения непрерывных цепей. И мы увидели,
[58:03.140 --> 58:08.220]  что nT это непрерывная цепь с такими-то свойствами, и при этих свойствах она даже совпала с
[58:08.220 --> 58:16.220]  полусоновским потоком. Так. Это вот один путь. Путь номер два. Очень распространенный в учебниках.
[58:16.220 --> 58:24.420]  Цепи потом. Сначала потоки. Дан поток событий, однородностью назовем вот это,
[58:24.420 --> 58:30.580]  без последействия вот это, и ведем ординарность вот таким вот образом. Тогда можно доказать,
[58:30.580 --> 58:39.660]  что nT это полусоновский процесс. Но при таком подходе ты пастулируешь вот это. А откуда это
[58:39.660 --> 58:46.020]  берется? Вот понимаете, это то, что мне не нравится всегда. Не физические предположения. Ну что такое
[58:46.020 --> 58:53.620]  вероятность того, что nT равна единице? Вероятность того, что на интервале 0H произойдет одно событие,
[58:53.620 --> 59:01.180]  если лямбда H плюс ума латаш. Откуда вообще это берется? Что это такое? Почему мы такое предположение
[59:01.180 --> 59:06.820]  унимаем? Зачем нам эта дифференцированность? Что она дает? Откуда она и берется? Ну непонятно. Вот.
[59:06.820 --> 59:17.620]  Но для простоты, тем не менее, такой ход делают. А я же вам по-другому веду. Я сначала вел непрерывные
[59:17.620 --> 59:23.020]  цепи, и мы разобрались с вами, что такое интенсивность? Откуда вообще это появляется? Откуда это
[59:23.580 --> 59:30.460]  интенсивность появляется? Потому что вероятность перехода вот этой житоатаж, она дифференцируема.
[59:30.460 --> 59:34.180]  Она еще так же и непрерывна. Откуда следует непрерывность? Потому что по траектории справа
[59:34.180 --> 59:39.020]  непрерывные. Понимаете, эти все связи вы должны обязательно проследить, и на экзамене должны эти
[59:39.020 --> 59:43.540]  знания показать, как это все взаимосвязано между собой. Что являются причиной для чего? Мы
[59:43.540 --> 59:48.140]  предположили, то есть фундаментальная вещь на самом деле, это то, что между событиями происходит
[59:48.140 --> 59:53.860]  конечное время. Это помогает нам всю эту науку связать с непрерывными цепями Маркового,
[59:53.860 --> 01:00:02.300]  которая очень глубоко проработана. Я хочу, чтобы вы это понимали. Просто так это аксиоматизирует,
[01:00:02.300 --> 01:00:07.100]  непонятно откуда это берется. Но сейчас я вам показал, как это выводится на самом деле. Выводится
[01:00:07.100 --> 01:00:14.620]  из более-более каких-то базовых предположений. Непрерывность траекторий или то, что события не
[01:00:14.620 --> 01:00:22.900]  могут происходить, как бы между событиями обязательно проходит какое-то время. Вот,
[01:00:22.900 --> 01:00:31.420]  когда уже следует вот это. И то, что цепь живет показательное время, это тоже мы получили как
[01:00:31.420 --> 01:00:37.940]  следствие того, что существуют вот эти интенсивности, а эти интенсивности есть производная этих
[01:00:37.940 --> 01:00:43.520]  вероятностей. Вот, и эти интенсивности есть время пребывания. Если ты сразу постулируешь
[01:00:43.520 --> 01:00:49.100]  ординарность, тогда ты не понимаешь физический смысл лямб. Откуда они взялись? У нас лямб
[01:00:49.100 --> 01:00:56.780]  появились как производные П, и мы доказываем, что эти производные П являются временем, ну,
[01:00:56.780 --> 01:01:02.860]  интенсивностью для времени пребывания. То есть ты знаешь физический смысл. Здесь, когда ты
[01:01:02.860 --> 01:01:09.620]  сразу вводишь эти лямбды, ты не понимаешь физического их смысла. Ты должен воспользоваться этим и вывести
[01:01:09.620 --> 01:01:18.420]  отсюда, что ты будешь показательное время жить в состоянии. В принципе, это тоже возможно,
[01:01:18.420 --> 01:01:25.380]  если немножечко напрячься. Но строгих каких-то выкладок по этому поводу я, кстати, не видел. Вот
[01:01:25.380 --> 01:01:31.060]  то, как я вам доказывал, вот это вот максимально строго, строгий подход. Помните, мы там всю
[01:01:31.060 --> 01:01:36.340]  плотную множество брали, строили, вот это вот. Ну, некий формализм навели, но тем не менее. Как
[01:01:36.340 --> 01:01:43.260]  здесь быть? Ну, так вот прям сходу не очевидно. Может быть, только если... Что значит, что время
[01:01:43.260 --> 01:01:50.500]  пребывания больше t? Значит, у нас на интервале от t ничего не происходит. Значит, вот это и это у
[01:01:50.500 --> 01:01:56.700]  нас в любой точке. Тогда мы должны взять вот это в скобочках и в степени порядка того, сколько
[01:01:56.700 --> 01:02:02.220]  точек, порядок один разделить на h. Тогда при h стремящимся к нулю это стремится к экспоненте от
[01:02:02.220 --> 01:02:09.660]  минус лямбда. Может быть, может быть, как-то вот так вот. Может быть, как-то так. Но вы должны
[01:02:09.660 --> 01:02:13.900]  быть готовы к тому, что если вы открываете произвольный учебник, то вы будете увидеть там
[01:02:13.900 --> 01:02:20.780]  совершенно разные способы определить непрерывные цепи Маркова и потоки. Кто-то начинает с одного,
[01:02:20.780 --> 01:02:31.820]  потом другой. Кто-то так, кто-то сяк. Ну, вот я решил вот такой подход устроить. Потому что
[01:02:31.820 --> 01:02:38.940]  иначе то там, то сям будут утверждения, которые мы интуитивно понимаем, но доказать не можем,
[01:02:38.940 --> 01:02:47.380]  потому что нет строгей науки. Для инженерных, для книжек, для инженеров это нормально. Вот,
[01:02:47.380 --> 01:02:56.620]  например, есть очень хорошая на самом деле книжка Венцель, которая ЕС, Венцель Елена
[01:02:56.620 --> 01:03:03.580]  Сергеевна. Знаете, она еще книжки детские писала. Замечательные книжки она пишет. И вот у нее подход,
[01:03:03.580 --> 01:03:11.820]  по-моему, там изначально через потоки. Вот она там не везде, вот формально может быть строго,
[01:03:11.820 --> 01:03:18.860]  но там как-то вот у нее очень удачно построено рассуждение, что ты все интуитивно понимаешь,
[01:03:18.860 --> 01:03:23.060]  и в принципе тебе этого достаточно. Вот, так что можете эту книжку посмотреть, может быть кому-то
[01:03:23.060 --> 01:03:29.220]  она очень понравится, но я здесь все-таки пытаюсь некоторую и формальную науку тоже построить,
[01:03:29.220 --> 01:03:36.100]  хоть какую-никакую. Поэтому мне вот этой книжки недостаточно, к сожалению. Так что мне приходится
[01:03:36.100 --> 01:03:42.940]  искать какой-то другой путь и идти через непрерывные цепи Маркова. Так вот, хорошо,
[01:03:42.940 --> 01:03:48.620]  это про связь потоков и непрерывных цепей. Теперь про плацсоновский поток. Как видите,
[01:03:48.620 --> 01:03:54.820]  мы здесь пришли к плацсоновскому потоку. На самом деле, плацсоновскому процессу, на самом деле,
[01:03:54.820 --> 01:03:58.700]  плацсоновский процесс можно определять через плацсоновский поток. Ну типа, мы ввели поток
[01:03:58.700 --> 01:04:07.260]  с такими-то свойствами, тогда назовем плацсоновским процессом n от t. Он будет
[01:04:07.260 --> 01:04:11.820]  обладать теми же свойствами, как если бы вводили плацсоновский процесс иначе. Вообще,
[01:04:11.820 --> 01:04:15.500]  плацсоновский процесс можно ввести множеством различных способов. Давайте мы их все вместе
[01:04:15.500 --> 01:04:23.220]  соберем. Первый способ, как я изначально сделал, аксиоматический. k от 0 равно 0, независимые
[01:04:23.220 --> 01:04:30.660]  приращения, приращение k, плацсоновская величина от лямбды. Это один способ. Второй способ,
[01:04:30.660 --> 01:04:38.140]  ввести его как процесс восстановления. Ну помните там, supremum n больше нуля, сумма меньше или больше,
[01:04:38.140 --> 01:04:44.460]  меньше по-моему t. Мы доказывали, что они эквивалентные. Можно так ввести плацсоновский
[01:04:44.460 --> 01:04:52.140]  процесс, как пример, как частный случай процесса восстановления. Третье, можно ввести плацсоновский
[01:04:52.140 --> 01:05:01.260]  процесс, как непрерывную цепь Маркова. Вот таким графом, который в нулевом момент времени стартует из нуля,
[01:05:01.260 --> 01:05:07.220]  все интенсивности одинаковые, равные лямбде. Это третий способ ввести плацсоновский процесс. И
[01:05:07.220 --> 01:05:14.580]  четвертый способ ввести плацсоновский процесс. Ввести потоки, значит, ординарные, без последействия,
[01:05:14.580 --> 01:05:19.420]  однородные. Поток ввести, он называется простейший плацсоновский процесс, тогда n от t для него,
[01:05:19.420 --> 01:05:26.980]  это плацсоновский процесс. Вот четыре способа ввести плацсоновский процесс. Вот это запомните,
[01:05:26.980 --> 01:05:32.260]  потому что это будет на экзамене билет такой, значит, рассказать об эквивалентных определениях
[01:05:32.260 --> 01:05:37.900]  плацсоновского процесса. Это важная вещь, потому что они соединяют весь наш курс. Вот плацсоновский
[01:05:37.900 --> 01:05:42.860]  процесс, мы о нем начали говорить когда еще там, на второй лекции. Смотрите, у нас сегодня предпоследняя
[01:05:42.860 --> 01:05:52.620]  лекция, да, мы все еще говорим о плацсоновском процессе. Вообще, как бы, наука, она не про
[01:05:52.620 --> 01:05:58.140]  определения отдельные, да, не про массив определений, массив теорем, а про то, что связывает все эти
[01:05:58.140 --> 01:06:02.860]  определения и понятия. Вот вы должны это знать, вы должны это понимать. Вы должны, когда работаете,
[01:06:02.860 --> 01:06:10.460]  значит, регистрировать для себя все вот эти связи между понятиями, потому что это и есть знание,
[01:06:10.460 --> 01:06:21.220]  что вот для себя все отметим. Как связаны между собой непрерывные марковские процессы с
[01:06:21.220 --> 01:06:26.980]  однородными потоками, что можно по-всякому вводить и так, и так. Вот я выбрал один из таких путей,
[01:06:26.980 --> 01:06:33.780]  потому что мне хочется начинать с чего-то более фундаментального и потом уже практические вещи,
[01:06:33.780 --> 01:06:38.700]  такие как потоки, описывать вот в этих фундаментальных терминах, то есть вести
[01:06:38.700 --> 01:06:43.340]  некую математику такую очень может быть абстрактную, а потом уже рассмотреть какие-то
[01:06:43.340 --> 01:06:50.100]  приложения этого. Вот есть поток, как распределено n от t, число событий, а вот мы применяем наш багаж
[01:06:50.100 --> 01:06:55.500]  знаний, который у нас уже накоплен, и просто применяем к этому, и получаем сразу же кучу
[01:06:55.500 --> 01:07:03.300]  следствий. То, что другие аксиоматизируют, они выводят. Понимаете? А почему они это аксиоматизируют?
[01:07:03.300 --> 01:07:07.900]  Потому что они не хотят раскрывать все детали, потому что это очень много. Видите, у нас целая лекция
[01:07:07.900 --> 01:07:12.280]  же на это ушла. Такая сложная, прошлая, нетривиальная. Вот эти все доказательства,
[01:07:12.280 --> 01:07:19.340]  вот эти все теоремы. Вот, поэтому они аксиоматизируют. Ну а мы не аксиоматизировали,
[01:07:19.340 --> 01:07:30.580]  мы вывели эти свойства. Вот. Ну, все тогда. Наверное, это все, что я хотел рассказать о непрерывных
[01:07:30.580 --> 01:07:40.060]  цепях Маркова. И на следующей лекции вы посмотрите непрерывные марковские процессы. Это когда время
[01:07:40.060 --> 01:07:49.100]  непрерывно и множество состояний непрерывно. Вот там много чего, но что, на мой взгляд,
[01:07:49.100 --> 01:07:57.180]  вот ключевые вещи, какие вы должны оттуда вынести, это то, что марковские процессы с
[01:07:57.180 --> 01:08:03.900]  непрерывным временем и множеством состояний, они тоже не могут быть всякими. И там тоже есть
[01:08:03.900 --> 01:08:12.220]  вероятности переходов, и они тоже определенным образом, на них тоже есть уравнения. У нас было
[01:08:12.220 --> 01:08:19.740]  уравнение для дискретных цепей, рекуррентного виде некоторое записанное. У нас было уравнение для
[01:08:19.740 --> 01:08:25.820]  непрерывных цепей в виде системы обыкновенных дифференциальных уравнений написанных. А вот в
[01:08:25.820 --> 01:08:31.940]  марковских цепях там уравнение в частных производных. Вот уравнение в частных производных,
[01:08:31.940 --> 01:08:38.420]  которые имеют вид уравнений теплопроводности, кстати говоря. Вот вы можете помыть там, ну не то
[01:08:38.420 --> 01:08:43.820]  что прям совсем произвольные, но довольно широкий класс марковских процессов, с которыми обычно
[01:08:43.820 --> 01:08:52.780]  имеют дело. Вот у них матрица перехода и там плотности перехода тоже вы увидите, они удовлетворяют
[01:08:52.780 --> 01:08:58.700]  уравнениям в частных производных, которые оказываются диффузионными уравнениями или уравнениями
[01:08:58.700 --> 01:09:07.980]  теплопроводностями, смотря как ты это интерпретируешь. Вот как. А раз это диффузионные процессы, то это как-то
[01:09:07.980 --> 01:09:13.660]  связано с процессом Винровским, что Винровский процесс, процесс Бронновского движения, чувствуете,
[01:09:13.660 --> 01:09:22.060]  что есть такое? Вот там вы это посмотрите и почитаете у меня. Так что есть тоже некие уравнения,
[01:09:22.060 --> 01:09:28.300]  тоже прямые обратные уравнения Калмогорова, какие-то я там, наверное, доказываю, какие-то я просто
[01:09:28.300 --> 01:09:36.340]  пишу. Вот. Но главное, что они не могут быть всякими и оказывается, что вот они описываются в частных
[01:09:36.340 --> 01:09:44.380]  производных, причем именно уравнения теплопроводности или диффузии. Вот. Что вот интересно. И вот,
[01:09:44.380 --> 01:09:51.060]  например, в дискретных цепях все определяется матрицей перехода за один шаг. В непрерывных цепях
[01:09:51.060 --> 01:09:56.980]  все определяется матрицей Q, производными. Так вот и там тоже есть некоторые, правда уже,
[01:09:56.980 --> 01:10:04.620]  функции. Не матрицы, там какие-то, не числа, а именно функции, которые определяют процесс,
[01:10:04.620 --> 01:10:10.100]  однозначно весь. Причем это свойства локальные. Обратите внимание, вероятность перехода за один
[01:10:10.100 --> 01:10:16.220]  шаг определяет вероятность перехода за любое число шагов. Матрица Q это производная, причем в
[01:10:16.220 --> 01:10:21.260]  начальный момент времени, производная P в начальный момент времени, локальная характеристика,
[01:10:21.260 --> 01:10:30.460]  она определяет процесс всюду через диффур. Так и там вводятся некие матричные там функции,
[01:10:30.460 --> 01:10:37.620]  значит A и B, которые тоже локальные, но оказывается, что они определяют весь процесс всюду. Вот это
[01:10:37.620 --> 01:10:44.700]  тоже вы должны понимать. Это тоже такие ключевые моменты. Ну а все остальное, это уже технические
[01:10:44.700 --> 01:10:51.540]  вещи. Будут тоже теоремы со своими условиями, там предположения там будут определенные вводиться,
[01:10:51.540 --> 01:10:54.780]  но это я думаю, что вы почитаете. Все.
