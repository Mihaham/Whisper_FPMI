[00:00.000 --> 00:10.440]  Рад всех приветствовать на этой нелегальной лекции подпольной. Я злоупотребляю вашим вниманием,
[00:10.440 --> 00:16.760]  спасибо большое, что вы пришли. Сегодня я расскажу вам про последнюю тему,
[00:16.760 --> 00:25.280]  которую мы не успели коснуться. В смысле, тему, некоторый инструмент для выражения
[00:25.760 --> 00:33.480]  коммуникации между какими-то конкурентными активностями, связи их. Мы с вами говорили
[00:33.480 --> 00:40.160]  про Fiber и Mutex, мы говорили про альтернативу Fiber, ну, по сути, такую же, построенную на другом
[00:40.160 --> 00:43.840]  механизме, на стеклоскорутинах против стеклоскорутина, собственно, про корутины,
[00:43.840 --> 00:51.800]  мы говорили с вами про Future, которые с помощью комбинаторов связывают задачи в некоторые графы,
[00:52.120 --> 00:59.040]  и сегодня мы поговорим про подход, который используется в Go, это message passing и это каналы
[00:59.040 --> 01:06.120]  e-select. Ну, у нас есть задача, и я сегодня расскажу частично ее решение, частично расскажу,
[01:06.120 --> 01:12.280]  как можно было бы написать решение лучше, чем это вас требует, ну, и заодно там возникнет
[01:12.280 --> 01:19.520]  некоторая интересная и тривиальная задача, связанная с look-free. Ну, мы до нее доберемся,
[01:19.520 --> 01:24.640]  ладно, давайте начнем с простых соображений, о чем вообще мы говорим. Мы говорим сегодня про
[01:24.640 --> 01:32.080]  Fiber или про корутины, не очень важно, наверное, и мы говорим о том, как они между собой синхронизируются.
[01:32.080 --> 01:37.040]  Понятно, что они могут синхронизироваться через разделяемую память, для этого у вас есть
[01:37.040 --> 01:43.400]  какие-то Mutex, которые вы писали, Mutex могут быть очень хорошими, ну, вот принцип, что вы работаете,
[01:43.400 --> 01:53.320]  вы координируете работу разных Fiber'ов, разных корутин через разделяемые ячейки памяти. В Go вам
[01:53.320 --> 01:59.920]  предлагают использовать другой подход, вместо того, чтобы Fiber'ы, корутины коммуницировали через
[01:59.920 --> 02:06.320]  разделяемые ячейки, они наоборот, они поступают наоборот, они разделяют память через коммуникацию,
[02:06.320 --> 02:14.160]  через каналы, то есть, если вы хотите поговорить с другим Fiber'ом, с другой корутиной, вы отправляете
[02:14.160 --> 02:19.520]  ей сообщение через канал, а с другой стороны, так, корутины сообщение получают, ну, и как-то его
[02:19.520 --> 02:27.080]  обрабатывают. Принцип понятен, и, наверное, должны быть понятны, почему мы хотим делать именно так,
[02:27.080 --> 02:35.240]  то есть, мы хотим Share Memory by Communicating, а не наоборот, потому что, ну, вот я говорю про этот
[02:35.240 --> 02:41.000]  принцип, который лежит, в том числе, в основе дизайна Go. Этот принцип очень разумный, потому что
[02:41.000 --> 02:48.120]  он поощряет паттерн передачи сообщений, который, как мы знаем из лекции про модели памяти, более
[02:48.120 --> 02:55.960]  подпочтительны для процессора, чем обращение к разделяемым ячейкам непосредственно. И в домашней
[02:55.960 --> 03:01.760]  работе вас, во-первых, просят реализовать вот такой вот канал, с помощью которого можно одному
[03:01.760 --> 03:07.760]  файберу отправить сообщение, а другому файберу дождаться его получения, остановиться до тех пор,
[03:07.760 --> 03:16.560]  пока сообщение не появится. В принципе, задача не сложная, но когда вы ее будете решать, если вы
[03:16.560 --> 03:23.160]  ее будете решать, то обратите внимание, что вот на данном этапе нашего курса, ну, он уже закончился,
[03:23.160 --> 03:28.520]  но, тем не менее, на данном этапе, работая с файберами и реализуя какой-то новый примитив
[03:28.520 --> 03:33.720]  синхронизации, вы уже не должны ни в коем случае, конечно, думать про там какие-нибудь фьютексы,
[03:33.720 --> 03:39.120]  кондвары, мьютексы, нечто подобное. Мы с вами прошли длинный путь для того, чтобы понять, что файберам
[03:39.120 --> 03:44.000]  ничего, кроме suspend, не нужно. Ну и, глядя на дизайн карутин, вы там видите, что никакого фьютекса
[03:44.000 --> 03:49.880]  там нет, и быть, кажется, и не может в принципе, в силу некоторых особенностей API. У вас есть
[03:49.880 --> 03:56.520]  просто Awaiter и его операция AwaitSuspend. Ну, также и в нашем случае нет никакой разницы между там
[03:56.520 --> 04:01.000]  или stackless карутином, тут stackful карутины. Вот на данном уровне разницы никакой нет в реализации
[04:01.000 --> 04:06.600]  примитива синхронизации. Мы используем просто suspend, останавливаемся один раз на каждую операцию
[04:06.600 --> 04:12.720]  send, один раз на каждую операцию receive, просыпаемся и там, просыпаемся, когда операция уже завершена.
[04:12.720 --> 04:20.440]  У нас будет только в таком случае. Сама реализация довольно прямолинейная, тут никакой особой
[04:20.440 --> 04:27.640]  сложности нет, скорее такая техническая рутина. Но, тем не менее, нужно с чего-то начать. И я еще
[04:27.640 --> 04:33.520]  пропагандирую и решать вам эту задачу, потому что вот после этой задачи можно гораздо более
[04:33.520 --> 04:38.200]  разнообразные ворклоды строить для хорошего планировщика, который, наверное, многие здесь
[04:38.200 --> 04:45.720]  написали. Здесь будет опять LFO-планирование, здесь будет придача сообщений, здесь одни файберы
[04:45.720 --> 04:51.600]  будет других, и более разнообразным способом они это могут делать, нежели чем работая просто с
[04:51.600 --> 04:56.360]  мютаксами. Поэтому можно гораздо больше сценариев написать и их профилировать, и лучше понять, как
[04:56.360 --> 05:01.240]  планировщик себя ведет. А ведет он себя довольно сложно, потому что сценарии могут быть самыми
[05:01.240 --> 05:11.640]  разнообразными. Но это первый этап задачи. А дальше вы переходите к более нетривиальному,
[05:11.640 --> 05:14.800]  ну, впрочем, не такому же сложному, но все же нетривиальному инструменту — это Select,
[05:14.800 --> 05:23.320]  который позволяет вам заблокироваться в ожидании сообщения одного из двух каналов. То есть,
[05:23.320 --> 05:27.640]  вы остановите... Я говорю «заблокироваться», я каждый раз говорю «неаккуратно», и вообще,
[05:27.640 --> 05:31.920]  мне кажется, я в курсе очень неаккуратно говорил. А стоило поступать так. Если вернуться в прошлое,
[05:31.920 --> 05:38.640]  говорить слово «заблокируется» только в контексте потоков, а в контексте файберов,
[05:39.120 --> 05:43.840]  говорите «останавливается». Это как-то более правильно, чтобы мы не путали два этих понятия.
[05:43.840 --> 05:48.400]  Вот так вот, «станавливать» — это вызывающий Select Fiber до тех пор, пока либо в XS,
[05:48.400 --> 06:00.880]  либо в YS не появится сообщение. На что это похоже? Это похоже на некоторый комбинатор для Future,
[06:00.880 --> 06:07.080]  и я бы сказал чуть шире — это похоже на инструмент для параллельной композиции.
[06:07.080 --> 06:13.800]  Когда мы говорили с вами на лекции про Future, что вот есть композиция последовательная и
[06:13.800 --> 06:19.120]  параллельная, ну и в задачах я об этом писал в условии, я обращал внимание, что да, вы можете
[06:19.120 --> 06:26.200]  описывать цепочки каких-то шагов осинхронных через комбинатор Zen или какие-то подобные,
[06:26.200 --> 06:31.040]  но с другой стороны, гораздо естественнее делать это с помощью блокирующего API,
[06:31.040 --> 06:36.880]  просто писать вызов, точку с запятой, и это синхронного API, и внутри этого вызова,
[06:36.880 --> 06:42.360]  там, не знаю, карутина становится. Это гораздо удобнее, чем вот Zen и писать,
[06:42.360 --> 06:46.400]  и обработчики на них вешать. Но с другой стороны, есть другие сценарии, когда мы
[06:46.400 --> 06:51.960]  распараллеливаем какие-нибудь, не знаю, запросы в какие-то сервисы, и потом хотим дождаться всех,
[06:51.960 --> 06:56.120]  дождаться первого, дождаться Quorum'а какие-то. Разные варианты можно себе представить.
[06:56.120 --> 07:03.640]  И в таком сценарии синхронный API, где там файбер или карутина, или карутина, останавливаются,
[07:03.640 --> 07:09.200]  не очень-то удобно писать. Вот как с синхронным API дождаться первого? Нужен какой-то
[07:09.200 --> 07:13.400]  вспомогательный инструмент, и тут появлялись фьючи и там комбинаторы, которые позволяли
[07:13.400 --> 07:20.960]  из nfuge построить одну с какой-то семантикой. Да? И вспомните, что мы еще говорили про эти
[07:20.960 --> 07:26.480]  фьючи, про то, что на лекции про structured concurrency мы говорили, что в эти фьючи и вот в эти
[07:26.480 --> 07:33.280]  как бы развилки логические можно встроить поддержку обработки ошибок и асинхронные отмены так, чтобы
[07:33.280 --> 07:38.440]  если из одного по дереву приходит ошибка, то в другое по дереву спускалась отмена. Вот очень
[07:38.440 --> 07:48.360]  разумно. Select — это некоторая альтернатива для решения той же задачи, но вот в императивном
[07:48.360 --> 07:54.240]  языке. Мы здесь не занимаем, мы здесь не используем никакие сложные комбинаторы, мы не выстраиваем
[07:54.240 --> 08:00.480]  какие-то там цепочки, по которым текут значения. Вместо этого мы пишем императивный код, где есть
[08:00.480 --> 08:09.320]  грутины, по сути, неотличимые для пользователей от потоков, и они вот останавливаются в... ну, в год.
[08:09.320 --> 08:14.600]  Нет, не вызов Select там, вот конструкция языка, у нас это вызов. Но в общем, Fiber останавливается в
[08:14.600 --> 08:21.640]  Select, дожидается. И это вот опять какая-то такая императивная семантика, что именно происходит.
[08:21.640 --> 08:31.520]  И если вы посмотрите... да, и продолжая эту аналогию, я хочу обратить внимание, что Select,
[08:31.520 --> 08:37.640]  Select Go — это очень выразительный инструмент, который позволяет решать вот все подобные задачи,
[08:37.640 --> 08:43.080]  которые решали комбинаторы фьюч. Ну, правда, менее выразительно, но тем не менее. Вот в Go,
[08:43.080 --> 08:48.240]  вы знаете, есть каналы. И каналы поддержаны на уровне синтаксиса. Ну, давайте, я...
[08:48.240 --> 09:13.920]  Я хочу, конечно, сразу... сразу найти Select.
[09:13.920 --> 09:28.720]  Вот, есть Select, и это, по сути, комбинатор First-off. Что, если, скажем, вы хотите... да,
[09:28.720 --> 09:37.880]  каналы... вот API для каналов в смысле, простите. Каналы поддержаны на уровне языка, на уровне
[09:37.880 --> 09:43.520]  синтаксиса. Вот у вас есть конструкция отправить что-то в канал, достать что-то из канала. А теперь
[09:43.520 --> 09:49.200]  предположим, что вы хотите реализовать... ну, эта операция, она останавливает грудину до тех пор,
[09:49.200 --> 09:58.320]  пока там сообщения в канале не появятся. Так вот, если мы хотим для каналов, которые поддержаны на
[09:58.320 --> 10:05.000]  уровне синтаксиса, скажем, иметь операцию не блокирующей... не блокирующего чтения из канала.
[10:05.000 --> 10:08.080]  То есть, мы хотим попробовать прочесть сообщение, если оно там есть. А если нет,
[10:08.080 --> 10:15.040]  то готовы пойти дальше. Останавливаться не хотим. Вот Select, он решает в том числе и такую задачу.
[10:15.040 --> 10:33.440]  У вас есть вариация Select с кейсом Default, и этот кейс срабатывает, если в этом канале нет
[10:33.440 --> 10:39.880]  сейчас значения. Вам не нужно добавлять... ну, у вас в каналах нет такого метода не блокирующего
[10:39.880 --> 10:46.600]  чтения, у вас есть Select, который просто не блокируется при отсутствии сообщения в каналах.
[10:46.600 --> 10:53.400]  Или, скажем, другая задача. Вот вы пишете на C++ и вы смотрите там какой-нибудь API Condition Variable.
[10:53.400 --> 11:08.240]  Давайте посмотрим. И видите, там разные вариации вейта с тайм-аутами. Вот вы хотите ждать события
[11:08.240 --> 11:16.400]  или стечение тайм-аута. И вот вы поладите такое сложное, избыточное API. С помощью
[11:16.920 --> 11:24.800]  в ГО вы решаете эту проблему очень эрегантно. Если вы хотите чего-то дождаться, но с некоторым
[11:24.800 --> 11:34.040]  тайм-аутом, то вы строите такой специальный канал тикер, куда падают такие сообщения тики. И если
[11:34.040 --> 11:41.120]  ваше ожидание не должно быть бесконечным, то вы берете Select над и вашим каналом с данными,
[11:41.120 --> 11:46.000]  и этим тикером, ну и в зависимости от того, что происходит раньше. Либо тайм-аут срабатывает,
[11:46.000 --> 11:52.440]  либо вы дожидаетесь сообщения. Или, скажем, другой сценарий. Вы пишете какую-то операцию,
[12:06.440 --> 12:12.560]  вы пишете какую-то операцию, которая, скажем, выполняет какую-то полезную работу, но она готова,
[12:12.560 --> 12:19.480]  она должна поддерживать отмену. Потому что это часть обработки запроса, а ответ на запрос уже не
[12:19.480 --> 12:23.320]  нужен, потому что пользователь, ну не знаю, отчаялся, у него там сработал глобальный тайм-аут, и он уже
[12:23.320 --> 12:29.600]  получил ответ с другой ветки. В общем, у вас есть операция, которая должна уметь останавливаться
[12:29.600 --> 12:37.680]  по сигналу отмены. И опять Select для вас эту проблему решает. Вы можете из контекста,
[12:37.680 --> 12:43.880]  который мы обсуждали на одном занятии, по сути является стоп-токеном, в том числе является
[12:43.880 --> 12:50.040]  стоп-токеном, получить такой специальный канал и заблокироваться, остановить гарутину до тех пор,
[12:50.040 --> 12:55.800]  пока либо мы не получим сигнал отмены, либо мы там не получим очередную порцию данных, ну или там
[12:55.800 --> 13:02.520]  какой-то прогресс не настанет. Короче, Select в Go — это инструмент для параллельной композиции,
[13:03.120 --> 13:11.760]  с помощью которого можно решать самые-самые разные задачи. И вот, не знаю, чувствуете вы или нет,
[13:11.760 --> 13:20.560]  этот дизайн, эта декомпозиция, она очень аккуратная, очень точная, потому что один вот тот же Select,
[13:20.560 --> 13:27.800]  он используется в разных вариациях для решения разных задач и везде подходит. То есть сам язык
[13:27.800 --> 13:37.160]  задизайнен так, что вот стоп-токен — это канал, или тайм-аут — это канал. Ну, то есть тут, в принципе,
[13:37.160 --> 13:41.080]  можно углядеть такую аналогию, что вот каналы — это некоторая такая аналогия с фьючами, ну,
[13:41.080 --> 13:45.720]  просто императивная и декларативная, а Select — это такой универсальный инструмент для того,
[13:45.720 --> 13:52.200]  чтобы можно было сооружать какие-то комбинаторы опять в императивной манере. Менее выразительно,
[13:52.200 --> 13:59.000]  ну как, в общем, для языка это идиоматичный подход. Так что инструмент чрезвычайно полезный,
[13:59.000 --> 14:05.880]  и дизайн Go, в общем, построен, вот вся синхронизация в Go построена на каналах и Select-ах. Много что
[14:05.880 --> 14:11.360]  является с каналом, и у вас есть универсальный Select, с помощью которого можно дальше решать
[14:11.360 --> 14:19.200]  очень разные задачи. Вот это чертовски разумный дизайн, и мы в задаче про канал хотим этот Select
[14:19.200 --> 14:22.720]  повторить. Ну, правда, в очень ограниченной манере, потому что мы хотим повторить Select
[14:22.720 --> 14:30.400]  только для двух каналов, но просто потому что так нам проще будет писать, нам меньше нужно будет
[14:30.400 --> 14:37.600]  думать про всякий в ряде шаблоны и больше про содержание задач, то есть синхронизацию. А кроме
[14:37.600 --> 14:45.280]  того, мы себя дополнительно ограничиваем, мы говорим, что на Select мы только читаем. Но если
[14:45.320 --> 14:51.400]  вы используете Select в Go, то вы, конечно, хотите иметь Select такой смешанный, где один кейс может
[14:51.400 --> 14:57.240]  записывать сообщения, а другой может получать. Ну, например, потому что вы опять поддерживаете
[14:57.240 --> 15:02.240]  отмену. Вы отправляете сообщение в канал, он может быть переполнен, там может быть забит буфер,
[15:02.240 --> 15:07.600]  но вы не хотите ждать вещь на появление свободного места там, потому что вас просто могут отменить
[15:07.600 --> 15:15.040]  по тайм-ауту, и вот вы читаете из канала контекста и пишете там какой-то канал с данными. И что случится
[15:15.040 --> 15:21.280]  раньше? Ну вот, мы тоже себе немного задачу упрощаем, но мы себе оставляем такую вариацию,
[15:21.280 --> 15:27.560]  как Tri-Select, почему-то она представляется нам неочевидной. Там есть некоторая тонкость,
[15:27.560 --> 15:31.760]  ну, про которую я сегодня расскажу, я надеялся, что вы сами ее встретите, но поскольку я рассказываю
[15:31.760 --> 15:39.680]  вам раньше, чем вы решаете, то, значит, мне придется раскрыть нюанс. Ну, сначала давайте
[15:39.680 --> 15:43.840]  начнем с канала, просто подумаем, как он может быть реализован. Канал — это очень простая штука,
[15:43.840 --> 15:54.000]  тут очень сложно реализовать его по-разному. Ну, я сейчас покажу какой-то код, он не пресендует
[15:54.000 --> 16:01.920]  название самого лучшего. Да, почему здесь тут написано? Ну, написано. Это буфер с данными,
[16:01.920 --> 16:11.920]  это спинлок, который защищает этот буфер, и это две очереди — сендеры и ресиверы, то есть файберы,
[16:11.920 --> 16:18.480]  которые остановились и ждут сообщения или ждут свободного слота в буфере. Вот, сендеры и ресиверы —
[16:18.480 --> 16:24.280]  это, ну, это опять некоторые узлы интрузивного списка. Короче, опять вы, наверное, представляете,
[16:24.280 --> 16:30.640]  если вы писали в Utex и писали там Utex, это какие-то овейтеры, и файбер, который хочет остановиться,
[16:30.640 --> 16:36.840]  он, файбер, который хочет остановиться, скажем, в ресиве, он реализует такого овейтера,
[16:36.840 --> 16:50.200]  который в Await Suspension отпускает спинлок этого канала и ожидает получить значение от некоторого
[16:50.200 --> 16:55.920]  продюсера. Вот, когда он его получает, файбер готов возобновиться, и вот мы его отправляем в
[16:55.920 --> 17:00.680]  планировщик, и причем говорим ему, что он может проснуться следующим, потому что, ну вот, мы
[17:00.680 --> 17:06.520]  хотим использовать лифо-планирование. В общем, понятная конструкция, да? Ничего сложного. Но
[17:06.520 --> 17:14.600]  нам сразу пригодится такое замечание, оно нам упростит дальше разговор про лог-фри канал. В
[17:14.600 --> 17:23.160]  канале не бывает одновременно и сендеров, и ресиверов. Ну, для простоты можно буфер опустить,
[17:23.160 --> 17:28.840]  можно говорить про небуферизирован канал, и если там кто-то ждет, то, видимо, остановленных
[17:28.840 --> 17:34.360]  отправляющих нет. А если кто-то остановился, потому что не может отправить, то, видимо,
[17:34.360 --> 17:39.760]  у них нет получателей. Вот, так что есть либо сендеры, либо ресиверы, и вот этот код можно
[17:39.760 --> 17:47.640]  было бы упростить, сделав один список некоторых вейтеров, которые могут быть либо сендерами
[17:47.640 --> 17:54.320]  все, либо ресиверами. А сам вейтер — это такая простая структура. Что там будет храниться в этом
[17:54.320 --> 18:03.400]  вейтере? Ну, файбер-хэндл, который должен проснуться, и слот для значения. Если это продюсер,
[18:03.400 --> 18:08.280]  сендер, то там лежит значение, которое нужно отправить, которое он хочет отправить, а если это
[18:08.280 --> 18:13.920]  ресивер, то это просто слот для значения, в который другой сендер должен что-то положить и разбудить
[18:13.920 --> 18:20.120]  этот файбер, ждущий. Вот, так что тут есть такая вот симметрия сильная, и можно ее будет дальше
[18:20.120 --> 18:27.440]  эксплуатировать. Ну, а дальше я, наверное, перестану показывать код и буду показывать картинки,
[18:27.440 --> 18:42.520]  потому что мы хотим поговорить про канал. Ой, про Select, простите. Все сползло. Итак,
[18:42.520 --> 18:51.920]  что, как поддержать в каналах Select? Чем они отличаются? Думали ли вы над этим? Давайте так.
[18:51.920 --> 18:59.360]  На самом деле, опять, задача очень техническая, в ней ничего сложного нет. Вот эти списки,
[18:59.360 --> 19:05.360]  которые нарисованы, это списки, ну, либо сендеров, либо ресиверов. В данном случае у нас два канала,
[19:05.360 --> 19:11.240]  и на них зависли некоторые ресиверы. Каналы тут нарисованы небуферизированные, то есть есть
[19:11.240 --> 19:20.520]  либо сендеры, либо ресиверы, буфера нет. Вот канал XS, в нем ресиверы, которые хотят что-то
[19:20.520 --> 19:28.600]  получить. И эти ресиверы, какие они бывают? Это может быть файбер. Вот я, собственно, его и показал
[19:28.600 --> 19:38.280]  вам уже. Файбер-ресивер — это объект, у которого есть файбер-хэндл, у которого есть слот для
[19:38.280 --> 19:44.600]  значения, который этот файбер хочет дождаться. И когда-то мы кладем в этот слот значения мы сендер
[19:44.600 --> 19:54.440]  и будем файбер. Вот это один из возможных ресиверов в канале. А как бы мог, как бы можно было в эту
[19:54.440 --> 20:02.480]  конструкцию встроить Select? Ну вот Select — это значит встать, как бы по семантике, дождаться сообщения
[20:02.480 --> 20:10.840]  из одного из двух каналов. То есть фактически стать ресивером в каждом канале. Ну вот мы добавим себя
[20:10.840 --> 20:18.320]  в каждый канал. Вот тут красный Select есть, и вот он добавил два своих объекта, два узла в инкрузивные
[20:18.320 --> 20:27.320]  списки ресиверов. Но это такой особенный ресивер, потому что Select представлен в двух каналах,
[20:27.320 --> 20:36.360]  но при этом может получить только одно значение, а от второго он должен отказаться. Вот, поэтому мы
[20:36.360 --> 20:41.160]  устраиваем между ними такой консенс, если вы знаете о чем я, но вы и не знаете, потому что я не
[20:41.160 --> 20:51.760]  прочитал эту реакцию в этот раз. Действительно, Select представлен двумя ресиверами в двух разных
[20:51.760 --> 20:59.440]  каналах, но при этом два этих ресивера, они не то чтобы готовы получить значение оба, они вместо
[20:59.440 --> 21:06.080]  этого ссылаются на некоторый общий объект, где лежит переменная, ну вот Winner или State. Давайте я
[21:06.080 --> 21:14.000]  назову это State. Тут можно немного по-разному писать. И этот State, он кодирует состояние Select. Получил ли
[21:14.000 --> 21:22.920]  он значение или еще нет. И вот, допустим, я Send, я прихожу, и вот у меня есть фиолетовый кружок,
[21:22.920 --> 21:30.960]  я готов его кому-то отдать. Я предлагаю его этому ресиверу. Вот Fiber ресивер, чем он хорош? Он
[21:30.960 --> 21:37.320]  никогда не отказывается. Он принимает значение, просыпается и вот использует его, он дождался его.
[21:37.320 --> 21:42.640]  А вот Select ресивер, он может быть привередливым, то есть он может получить значение и принять его,
[21:42.640 --> 21:49.000]  если это первое значение, которое ему предлагают. И тогда он там переключится в состояние единицы,
[21:49.000 --> 21:56.600]  скажем, да, и получит этот фиолетовый кружочек. А потом в другой канал придут два Send, и вот
[21:56.600 --> 22:05.400]  второй Send достанет из очереди красный ресивер, соответствующий Select, предложит ему значение,
[22:05.400 --> 22:12.480]  оранжевый кружок, а этот красный Select от него уже откажется, потому что у него уже заполнен State.
[22:12.480 --> 22:22.480]  Но у него уже установлен State, что он переключился в состояние выбран. Ну вот именно поэтому ресивер,
[22:22.480 --> 22:28.480]  он не просто, у него есть ресив, у него есть Maybe ресив, потому что вот он может отказаться от того,
[22:28.480 --> 22:33.520]  что его предлагают, потому что это может быть Select. Тут можно немного по-другому написать,
[22:33.520 --> 22:42.760]  совершенно не принципиально. Принцип понятен, да? Все довольно просто. Вот такая задача,
[22:42.760 --> 22:56.640]  довольно техническая. Вопрос, а зачем же в задаче есть не только Select, а Tri-Select? Какую
[22:56.640 --> 23:00.400]  проблему он демонстрирует? На самом деле, тут есть тонкость, которую я, честно, сам не понимаю,
[23:00.400 --> 23:11.560]  ну то есть я понимаю, но наполовину. Тонкость следующая. Вот представьте себе, да, давайте
[23:11.560 --> 23:17.640]  подумаем про Tri-Select, как бы он мог быть реализован. Вот семантика Tri-Select, попробовать все каналы,
[23:17.640 --> 23:25.640]  если нигде ничего нет, то вот сказать, что везде пусто. Вот просто по очереди. То есть казалось бы,
[23:25.640 --> 23:30.760]  операция вообще выражается через цикл с там, если у нас в канале есть операция Tri-Receive,
[23:30.760 --> 23:43.200]  а она у нас кажется по условию есть, да? Если у нас Tri-Receive. Да, то кажется, что вообще зачем
[23:43.200 --> 23:48.040]  Tri-Select должен существовать? Потому что мы пройдемся по каналам, спросим у каждого Tri-Receive,
[23:48.040 --> 23:53.800]  если получим, то хорошо, если не получим, то скажем, что все каналы пусты. Вот оказывается,
[23:53.800 --> 24:02.680]  что так не работает и Tri-Select он, ну в каком-то смысле, в каком-то смысле его лучше сделать частным
[24:02.680 --> 24:09.560]  случаем обычного Select. А сценарий такой, смотрите, он довольно хитрый. Вот он в тестах есть, он
[24:09.560 --> 24:15.200]  проверяет ровно то, что вот вы это заметили. Вот представим себе, что у нас есть два канала,
[24:15.200 --> 24:25.880]  X и Y. И мы сначала в Y положим единицу, в Y положим единицу. Вот у нас канал один пустой,
[24:25.880 --> 24:34.920]  ну такой слот нарисован пустой, а здесь уже единица лежит. А дальше мы запустим два файбера. Один
[24:34.920 --> 24:42.520]  из них вызовет Tri-Select и, ну что он получит, мы увидим чуть позже. А другой файбер запустит
[24:42.520 --> 24:49.840]  две операции. Он в X отправит значение, а потом будет получать сообщение из Y.
[24:55.440 --> 25:01.040]  А мы вот во втором файбере вызываем Tri-Select, который реализован как. Мы идем по циклу,
[25:01.040 --> 25:06.960]  проверяем каналы. Ну и какое себе исполнение можно представить? Вот у нас канал в таком состоянии
[25:07.440 --> 25:19.720]  изначально, вот перед запуском файберов. Мы в Tri-Select проверили канал X, он пуст. Идем дальше.
[25:19.720 --> 25:29.040]  Но перед тем, как мы успели проверить канал Y, файбер F1 положил значение в X и достал значение
[25:29.040 --> 25:37.600]  из Y. После этого мы проверили канал Y и увидели пустое значение. И это какой-то очень сомнительный
[25:37.600 --> 25:43.680]  сценарий, потому что, как мы будем говорить осенью, эта история, она не линеризуется. Ну,
[25:43.680 --> 25:50.040]  то есть, вот такое исполнение невозможно объяснить никаким последовательным, где все операции
[25:50.040 --> 25:55.280]  происходят по порядку. Вот если бы канал был атомарным и если бы Tri-Select был атомарным,
[25:55.280 --> 26:00.880]  в таком обывательском смысле, да, мы могли бы думать, что вот сейчас случилась эта операция,
[26:00.880 --> 26:10.480]  потом случилась эта операция, потом случилась та операция. Я не знаю, что... Смотри, мы хотим
[26:10.480 --> 26:16.880]  сейчас не про Mutex говорить, мы хотим сейчас говорить про семантику. Какова семантика операции
[26:16.880 --> 26:23.440]  Tri-Select? Вот утверждается, что у Tri-Select текущего, как бы он там ни был, с такой реализацией,
[26:23.440 --> 26:33.600]  Tri-Select нарушает семантику свою, потому что вот этот результат, этот вызов с пустым ответом невозможно
[26:33.600 --> 26:39.280]  вписать в эту историю из трёх подряд идущих вызовов. То есть, если бы все было атомарно,
[26:39.280 --> 26:44.760]  где бы мог выполнить Tri-Select? Между этими вызовами, между этими вызовами или после этого вызова?
[26:44.760 --> 26:53.360]  Ну, потому что на то это инициализация, что она выполняется до запуска двух файберов.
[26:53.360 --> 27:01.720]  Вот. Так что места этому Tri-Select нет. Невозможно адекватно объяснить такое исполнение. Но вот наша
[27:01.720 --> 27:06.880]  реализация его порождает. Вот, возможно, наша реализация реализует неатомарный Tri-Select,
[27:06.880 --> 27:16.080]  и, наверное, это довольно печально. Да, ну, вариант простой. В нашем исполнении никогда не было момента,
[27:16.080 --> 27:24.000]  когда оба канала были пустые. Сначала был один не пуст, потом два не пустых, потом снова один,
[27:24.000 --> 27:29.200]  но другой уже был не пуст. И ответ, что два канала оказались пустые, ну, вот это просто не
[27:29.200 --> 27:33.880]  соответствует реальности. Мы понимаем это. Мы просто написали такой сценарий, мы знаем,
[27:33.880 --> 27:39.680]  что такого не может быть, и получаем ответ пуст. Ситуация сомнительная. Что делать?
[27:39.680 --> 27:52.560]  Нужно сказать аккуратнее. Нужно прибегнуть к нашему опыту и вспомнить, что мы не просто так в курсе
[27:52.560 --> 27:58.400]  решаем задачи. У нас была задача очень важная в начале курса. Она называлась «Задача про обедающих
[27:58.400 --> 28:05.560]  философов». И это была такая очень затяжная шутка. Вот сейчас эта задача, эта задача можно
[28:05.560 --> 28:13.680]  воспользоваться. Чтобы проверить атомарно два канала, нужно два этих канала заблокировать.
[28:13.680 --> 28:20.440]  Нужно взять разом два мьютокса. Ну или N мьютоксов, если у вас N каналов. И, как вы,
[28:20.440 --> 28:26.680]  наверное, знаете из «Задачи про философы», это сделать не совсем тривиально, но есть некоторый
[28:26.680 --> 28:31.920]  общий рецепт, а именно нужно вести некоторый порядок на всех блокировках и гарантированно
[28:31.920 --> 28:38.480]  брать их в одном и том же порядке. Во всех селектах, да? Ну вот тогда операция станет атомарной.
[28:38.480 --> 28:46.720]  Ну вот троиселект так и нужно сделать. Нужно взять блоки, а потом проверить каналы. Чего я не
[28:46.720 --> 28:53.320]  понимаю, нужно ли так делать в блокирующем селекте? Вот я, честно, не понимаю. Если кто-то подумает
[28:53.320 --> 29:00.680]  за меня, я буду очень благодарен. Вот можно написать решение, где мы будем брать локи по одному,
[29:00.680 --> 29:05.960]  потому что это, видимо, эффективнее. Мы взяли блокировку на канал, положили туда селектор,
[29:05.960 --> 29:10.120]  отпустили блокировку. Потом взяли блокировку на другой канал, положили туда селектор,
[29:10.120 --> 29:15.080]  отпустили блокировку. Пока мы это делаем, в этом канале уже могло появиться значение, его сюда
[29:15.080 --> 29:21.880]  написали. Тут как бы загорелся стейт, там как бы сработал консенсус, выбрал победителя. Да,
[29:21.880 --> 29:31.240]  мне нравится победитель, мне нравится слово консенсус. И в этом случае, ну я, по крайней
[29:31.240 --> 29:34.720]  мере, такого простого сценария, на котором бы нарушались какие-то очевидные варианты,
[29:34.720 --> 29:41.360]  которые выстрел пользователь не нахожу. С другой стороны, немного странно получается,
[29:41.360 --> 29:46.080]  что у нас есть, скажем, две операции селлект, скажем, три канала, ну две операции селлект,
[29:46.080 --> 29:51.640]  два канала, и две операции селлект по-разному оказались упорядочены в двух каналах.
[29:52.600 --> 30:00.440]  То есть их ресиверы легли в разном порядке, в два канала, да? Ну как-то неаккуратно выглядит. Вот
[30:00.440 --> 30:06.640]  я, честно, не знаю, поломается ли от этого, ну то есть можно ли как-то на это положиться,
[30:06.640 --> 30:12.720]  в смысле на тамарность блокирующего селлекта, и из такой реализации разломать себе какой-то
[30:12.720 --> 30:17.720]  иный вариант. Об этом интересно подумать. Но вот очевидного нет, а для трай-селлекта,
[30:17.720 --> 30:21.320]  не блокирующего, такой сценарий есть, он очень простой, и вот в тестах мы это проверяем.
[30:21.320 --> 30:33.720]  Ну что ж, это такое затяжное вступление про то, почему мы хотим делать селлекты,
[30:33.720 --> 30:38.040]  про то, почему нам нужны каналы. Ну вот селлект, потому что это инструмент для параллельной
[30:38.040 --> 30:46.320]  композиции, это такой императивный заменитель комбинаторов фьюч. Канал — это эффективный для
[30:46.320 --> 30:52.080]  компьютера паттерн коммуникации между конкурентными активностями. Ну и вот мы, наверное, представляем себе,
[30:52.080 --> 30:58.200]  как можно было это сделать на основе спинлока и используя API Fiber, в которой мы так долго с вами
[30:58.200 --> 31:07.000]  разрабатывали. Про тамарность тоже поговорили. Да, не поговорили, откуда взять порядок на мютаксах,
[31:07.000 --> 31:14.320]  но это, в общем, такое дело техническое, вы решая задачу сами это легко придумаете. А теперь мы
[31:14.320 --> 31:25.560]  хотим пойти дальше и улучшить нашу реализацию канала, а именно мы хотим избавиться от спинлока,
[31:25.560 --> 31:33.120]  который этот канал защищает, потому что это может быть нагруженным местом, ну и тут можно было
[31:33.120 --> 31:41.200]  бы улучшить себе гарантию в смысле прогресса, чтобы поток, который вытеснили под спинлоком,
[31:41.200 --> 31:49.080]  не мог помешать другим потокам, другим фиберам на других потоках с каналом работать. И вот мы
[31:49.080 --> 31:57.840]  сейчас будем говорить про то, как реализовать лог-фри канал. Первое наблюдение. Ну вот давайте
[31:57.840 --> 32:10.240]  не думать про сендеры и ресиверы, давайте думать про объекты вейтера. Вот вейтер — это объект,
[32:10.240 --> 32:17.760]  у которого есть поле корутина и объект... есть поле, элемент, в котором лежит ссылка на значение
[32:17.760 --> 32:22.520]  некоторое. Я сейчас буду рассказывать про статью, которая написана для Kotlin,
[32:22.520 --> 32:28.920]  авторами-разработчиками Kotlin, так что у меня будут корутины и ссылки на элементы, как в
[32:28.920 --> 32:35.720]  Kotlin, но тут, в принципе, никакой специфики практически не будет. То есть это всё можно
[32:35.720 --> 32:45.880]  написать и на C++, кажется, без каких-то особенных сложностей. Ну вот, у нас здесь в статье есть
[32:45.880 --> 32:52.240]  вейтер — это корутина и элемент, вот мы его нарисовали. Что из себя будет представлять лог-фри
[32:52.240 --> 33:01.480]  канал? Да, я забыл сказать важное ограничение — мы делаем канал не буферизированным. То есть у нас
[33:01.480 --> 33:06.360]  буфера нет, если в канал приходит сендер, то он встаёт в очередь, когда приходит ресивер,
[33:06.360 --> 33:10.520]  он достаёт сендера из очереди, забирает у него значение, и вот они расходятся, случается рандеву.
[33:10.520 --> 33:20.760]  Но нам нужно поддерживать очередь — либо сендеров, либо ресиверов, либо то, либо другое. Вот мы эту
[33:20.760 --> 33:27.880]  очередь будем строить в виде такого бесконечного массива. У нас будет такая абстракция пока —
[33:27.880 --> 33:34.880]  бесконечный массив со сквозной номерацией, вот он нарисован. И в нём находятся какие-то вейтеры,
[33:34.880 --> 33:43.000]  но в данном случае находятся три вейтера сендера. Они пришли, они хотят отправить значение, но у них
[33:43.000 --> 33:49.160]  не получается, потому что просто очередь уже скопилась, нужно встать в эту очередь. И в этой
[33:49.160 --> 33:57.800]  очереди есть два индекса. Есть индекс DQ-индекс и NQ-индекс, будьте здоровы. DQ-индекс указывает на
[33:57.800 --> 34:04.080]  первый занятый слот, на вейтера, который там находится, видимо. NQ-индекс указывает на
[34:04.080 --> 34:13.880]  первый свободный слот, куда можно встать в очередь. Пока схема понятна, вроде ничего сложного пока нет.
[34:14.800 --> 34:22.520]  Как бы мы могли такую предположение, что у нас есть некий бесконечный массив волшебный,
[34:22.520 --> 34:27.920]  мы пока не заботимся о том, как он устроен. Если он у нас есть, как можно было бы дальше построить
[34:27.920 --> 34:38.000]  канал? Предлагается сделать очень просто. Вот вы — ресивер. Вы приходите в канал и читаете DQ-индекс.
[34:38.000 --> 34:47.120]  Вообще-то для начала вам хорошо бы понять, в каком состоянии находится канал. То есть там
[34:47.120 --> 34:53.000]  сендеры живут или ресиверы сейчас? Потому что если там живут, скажем, сендеры, то нужно взять и
[34:53.000 --> 34:58.400]  первого извлечь, и забрать у него элемент и отпустить его, рандеву сделать. Если же там живут
[34:58.400 --> 35:06.680]  ресиверы, то нужно встать в конец очереди. Ну вот одно из двух. Ну вот предположим, что мы приходим,
[35:06.680 --> 35:14.600]  смотрим на содержимое по индексу DQ и обнаруживаем там сендера. То есть мы понимаем, что есть сендеры,
[35:14.600 --> 35:20.240]  они ждут своих ресиверов, и вот мы пришли. Значит, нужно этого сендера себе забрать,
[35:20.240 --> 35:28.760]  забрать у него значение и отпустить. Ну что значит забрать сендера? Потому что мы же ресивер — один
[35:28.760 --> 35:38.800]  из многих ресиверов. Так что нам нужно конкурировать с другими. Ну вот у нас тут массив с индексами. Да,
[35:38.800 --> 35:46.200]  массив с индексами — это я все следую статье. Вот у нас есть структура канал, и у нее есть
[35:46.200 --> 35:54.080]  поля NQ-индекс и DQ-индекс. Это нас пока не должно волновать все остальное. Что мы сделаем? Мы
[35:54.080 --> 35:59.320]  попытаемся кассом захватить себе индекс для извлечения. То есть мы сделаем касс,
[35:59.320 --> 36:05.120]  попытаемся атомарно передвинуть DQ-индекс на единицу вперед. Если мы смогли это сделать,
[36:05.120 --> 36:13.040]  то мы захватили слот, и можно из этого слота пойти вот к соответствующему вейтеру и забрать оттуда
[36:13.040 --> 36:22.520]  элемент. Да? Если же касс провалился, то мы ретраемся, перечитываем DQ-индекс, пробуем заново.
[36:22.520 --> 36:31.400]  Если мы добавляем значение, мы send. То есть если мы send, и мы приходим в канал и видим,
[36:31.400 --> 36:39.640]  что в DQ-индекс сейчас находятся сендеры, то это означает, что мы должны по NQ-индексу добавить
[36:39.640 --> 36:47.000]  себя. И что мы делаем? Мы опять захватываем слот, инкриментируя с помощью кассы NQ-индекс,
[36:47.000 --> 36:55.200]  и записываем этот слот себя. Вот, ну либо полностью симметричная ситуация, когда в массиве
[36:55.200 --> 37:01.120]  находятся сейчас ресиверы, и вот просто всё переворачивается. Ресиверы добавляются в конец,
[37:01.120 --> 37:09.560]  сендеры достают из начала. В предположении, что у нас есть бесконечный массив, всё довольно просто.
[37:09.560 --> 37:29.160]  Да? Или нет? Или есть подвох? Ну тут прям атомарно. А что сложного-то? Ну в содержимом ячейке можно
[37:29.160 --> 37:35.080]  как-то закодировать, кто там лежит, сендеры или ресиверы. Мне кажется, что это скорее техническая
[37:35.080 --> 37:51.080]  сложность тут. Проблема в другом. Ну оно могло всё поменять. Да, это хороший вопрос, но на самом деле
[37:51.080 --> 37:58.080]  нет. Потому что вот ты прочёл DQ-индекс NQ-индекс, да? И ты вот посмотрел, что очередь состоит из
[37:58.080 --> 38:03.920]  сендеров, а ты сендер нужно встать в конец. Могло ли так получиться, что ты встал в конец в очереди
[38:03.920 --> 38:10.840]  ресиверы уже? На самом деле нет, потому что ты же сейчас вот смотришь в этот слот, а чтобы очередь
[38:10.840 --> 38:16.440]  переключилась в другой режим, ей нужно, чтобы всех достали и положили ещё ресиверы. Так что твой
[38:16.440 --> 38:21.240]  касс просто поломается, потому что DQ-индекс просто уже сдвинулся вперёд. То есть если очередь
[38:21.240 --> 38:26.080]  режим переключила, то ты это заметишь через проваленный касс. И ты перечитаешь DQ-индекс,
[38:26.440 --> 38:31.120]  посмотришь голову и узнаешь, что тебе теперь нужно делать.
[38:31.120 --> 38:41.720]  Ну не обязательно, что-то может разойтись, тут можно аккуратно сделать, чтобы... Кажется,
[38:41.720 --> 38:45.680]  что если ты сначала читаешь NQ, а потом DQ, то ты тоже действуешь безопасно.
[38:45.680 --> 39:01.200]  Секунду. Ну вот, сначала ты читаешь NQ, а потом DQ. Видимо, не просто так.
[39:01.200 --> 39:10.200]  Вернёмся сюда. В Валгритме пока есть белое пятно большое. Я вроде бы рассказал,
[39:10.200 --> 39:16.920]  но так написать нельзя. Вот ещё раз, смотрите, я сэндер, я прихожу, смотрю на голову очереди,
[39:16.920 --> 39:22.240]  узнаю, что там сэнды, я пытаюсь встать в 14-й слот. А для этого что мне нужно сделать?
[39:22.240 --> 39:27.360]  Сначала этот слот захватить, сдвинув NQ-индекс вперёд кассом, а потом записаться туда.
[39:27.360 --> 39:36.800]  Вот кто видит проблему? Да, у нас есть два шага. Мы захватываем слот, то есть двигаем вперёд NQ-индекс,
[39:36.800 --> 39:43.120]  а вторым шагом мы пишем себя в слот. И теперь легко представить сценарий вот такой вот. У нас
[39:43.120 --> 39:52.080]  был сэндер, он пришёл вставать в очередь, он передвинул NQ-индекс вперёд, вот с 11-го слота на 12-й,
[39:52.080 --> 40:06.480]  да, NQ-индекс передвинул с 11-го на 12-й, вот, но не успел записаться в слот. Ну или допустим даже
[40:06.480 --> 40:13.840]  так, было немного иначе. У нас был там 10-й слот, там был сэндер, мы хотим встать в 11-й слот,
[40:13.840 --> 40:17.440]  мы его застолбили за собой, но ещё не успели записать туда содержимое, то есть себя,
[40:17.440 --> 40:25.320]  сослаться на себя, ну вот на объект вейтер. А дальше в очередь встали ещё какие-то сэндеры,
[40:25.320 --> 40:32.560]  а потом NQ-индекс, потом какой-то ресивер достал содержимое 10-го слота, потом перешёл к 11-му
[40:32.560 --> 40:38.000]  слоту, и вот, ну то есть приходит ресивер, NQ-индекс сейчас указывает на 11-й слот,
[40:38.000 --> 40:45.280]  сэндер там до сих пор не сделал второй шаг, то есть он не записал туда ссылку на вейтера,
[40:45.280 --> 40:54.160]  на вейтера своего. И ресивер в замешательстве, он не понимает, что происходит, он не понимает,
[40:54.160 --> 41:01.560]  в каком состоянии очередь, и что ему сейчас сделать. Ну, вариант такой, я бы сказал,
[41:01.560 --> 41:05.320]  относительно практичный, наверное, подождать можно, да, потому что вряд ли мы заснули на
[41:05.320 --> 41:10.480]  бесконечное время всё же, но формально это получится не лог-фри, уже подождать нельзя,
[41:10.480 --> 41:16.360]  и можно поступить как-то разумнее. Вот если у вас идеи, как можно поступить разумнее.
[41:16.360 --> 41:31.040]  Вот, можно отравить слот, чтобы сэнд уже не думал в него что-то писать. Вот смотрите,
[41:31.040 --> 41:36.720]  мы пришли в этот слот, и тут пока пустое место, это некоторое препятствие, такой родблок для нас,
[41:36.720 --> 41:41.680]  мы не можем двигаться дальше, никто не может двигаться дальше. Ну вот нужно
[41:41.680 --> 41:47.040]  от этого препятствия избавиться. Мы не хотим дожидаться сэндера, мы просто хотим ему сказать,
[41:47.040 --> 41:53.080]  что «Сэндер, ты свой шанс упустил занять этот слот». То есть ты попробовал, но на втором шаге ты
[41:53.080 --> 42:00.800]  слишком долго спал, и пока ты спал, мы в этот слот записали специальное, ну вот там могла быть
[42:00.800 --> 42:07.520]  ссылка на объект Waiter, а мы туда записали специальную ссылку, вот такой Poison. Мы отравили
[42:07.520 --> 42:16.760]  слот. И теперь вот сэндер, он действует чуть более сложно. Когда он захватывает слот,
[42:16.760 --> 42:25.560]  двигая DQ Index, он не просто пишет в этот слот что-то с тором, он пишет туда кассом. Он пытается,
[42:25.560 --> 42:31.800]  ну тут ладно, в коде, который мы будем смотреть, там не ссылка на Waiter, там прямо Waiter, у которого
[42:31.800 --> 42:38.400]  есть полик, рутина и ссылка на элемент, и этот элемент либо ссылка, либо специальная ссылка на
[42:38.400 --> 42:47.200]  отравленное значение. И вот мы в Receive'е кассом пытаемся переставить эту ссылку на отравленную,
[42:47.200 --> 42:54.960]  а сэнд пытается переставить эту ссылку изначально null на свое значение. Ну и в зависимости от того,
[42:54.960 --> 43:00.600]  кто раньше успел, тем все и завершилось. Если раньше успел сэндер, то он положит в слот
[43:00.600 --> 43:08.840]  значение, ссылку на значение, мы его достанем и разбудим сэндера. Если же мы раньше успели отравить
[43:08.840 --> 43:16.680]  слот, то сэндер попытается сделать касс перезаписи слота, проиграет, ну и откатится на самое начало,
[43:16.680 --> 43:23.720]  снова перечитает NQ Index, DQ Index, и видимо уже будет работать с этим слотом, то есть откатится вот сюда.
[43:24.960 --> 43:27.160]  Понятно?
[43:27.160 --> 43:38.880]  Ну тут у тебя очередь всегда в каком-то одном режиме. Там либо...
[43:38.880 --> 43:53.200]  Да, это следующий пункт нашего плана. Нужно заметить, что тут есть LiveLog.
[43:53.200 --> 44:01.960]  Вот, предположим, что очередь пустая сейчас. Приходит сэндер и ресивер.
[44:01.960 --> 44:09.080]  Ну и ладно, даже не пустая. В общем, есть сэндер, и он хочет записаться в слот.
[44:09.080 --> 44:19.040]  Есть ресивер, который видит там пустой слот, и кто-то хочет записаться, он двигает вперед NQ Index,
[44:19.040 --> 44:29.200]  другой конкурент его читает этот... Двигает вперед NQ Index, очередь становится не пустой,
[44:29.200 --> 44:35.360]  другая картина пытается по DQ Index прочитать что-то, видит, что там пусто, и отравляет слот.
[44:35.360 --> 44:40.640]  После этого тот, кто хотел записаться в слот, не может этого сделать, он проигрывает и сдвигается
[44:40.640 --> 44:45.960]  вперед на шаг. Пытается положить следующий слот. Снова двигает NQ Index, очередь оказывается не
[44:45.960 --> 44:54.760]  пустой, и его соперник, конкурент симметричный видит, что слот снова пустой, отравляет этот слот.
[44:54.760 --> 45:01.600]  И вот они так, ну в таком LiveLog просто двигаются по этой бесконечной очереди, бесконечную вперед.
[45:01.600 --> 45:06.760]  Ну, к счастью, очередь бесконечная, поэтому они это могут делать, но это не то, что мы хотим,
[45:06.760 --> 45:18.320]  наверное. То есть прогресс у нас как будто бы снова нет. Но с LiveLog все-таки бороться немного
[45:18.320 --> 45:29.120]  проще, и мы с ним поборемся очень остроумным способом. Ну, это можно по-разному было бы рассказывать,
[45:29.120 --> 45:36.360]  но в общем мы поборемся с ним, придумав реализацию бесконечного массива сначала. Вот
[45:36.400 --> 45:42.720]  мы каким-то образом придумаем бесконечный массив, как сделать log-free, а потом мы на основе этого
[45:42.720 --> 45:49.320]  массива, пользуясь алгоритмом, который реализует этот массив, как-то автоматически решим проблему
[45:49.320 --> 45:56.200]  с LiveLog между sender и receiver. Ну, давайте думать, как можно сделать бесконечно растущий массив.
[45:56.200 --> 46:11.000]  Если у вас идея. Ну, от этого же он бесконечно-то не станет. То есть мы не просто двигаемся по
[46:11.000 --> 46:24.680]  индексам, мы же еще добавляем туда файберы. Ну, да, вот это сделать расширяющийся массив log-free.
[46:24.680 --> 46:29.640]  Ну, да, вот мы расширяющийся циклический буфер. А давай просто не расширяющийся сделаем.
[46:29.640 --> 46:34.240]  В смысле не циклический, прости, а расширяющийся. То есть ты предлагаешь что-то более сложную задачу,
[46:34.320 --> 46:54.720]  чем я. Ну, видимо, зависит от того, как ты сделаешь. Не понимаете меня. Вы предлагаете какие-то очень...
[46:54.720 --> 47:02.560]  Вы говорите какие-то слова, но вы не представляете, как это написать. Просто вы говорите, что надо
[47:02.640 --> 47:13.480]  это сделать. А вот придумайте, как вы понимаете, как сделать. А то я такие версии могу генерировать
[47:13.480 --> 47:26.600]  долго. Нет? Смотрите, а мы же с вами делали уже log-free... Ну, мы на лекции разбирали с вами
[47:26.600 --> 47:33.640]  log-free очередь. Мы же, по сути, делаем очередь бесконечно, да? Вот мы же делали log-free очередь.
[47:33.640 --> 47:38.960]  Это называлось у нас очередь Майкла Скотта. Это был односвязанный список, который был
[47:38.960 --> 47:47.120]  ориентирован от головы к хвосту. И когда мы добавляли... Когда мы хотели добавить новый
[47:47.120 --> 47:54.600]  элемент в эту очередь, мы алоцировали узел, пытались его прицепить к хвосту с помощью касса.
[47:54.600 --> 48:02.720]  И если это получалось, то мы двигали pointer tail вперёд. Но опять два шага, мы между ними могли
[48:02.720 --> 48:12.560]  заснуть, поэтому если мы приходим, смотрим на хвост и видим, что этот хвост на самом деле не хвост,
[48:12.560 --> 48:17.800]  то есть за ним есть продолжение, то мы помогали другому потоку, потому что он мог остановиться.
[48:17.800 --> 48:26.400]  Это была техника хелпинг, и мы двигали его... Мы двигали tail на шаг вперёд. Но мы это делали кассом,
[48:26.400 --> 48:32.600]  потому что многие потоки могли разом помогать друг другу. Но кто-то помогал, и в итоге прогресс
[48:32.600 --> 48:37.160]  совершал, в любом случае. То есть сам пуш мог провалить свой касс, потому что ему уже помогли,
[48:37.160 --> 48:42.280]  но это его, в общем, устраивало. А если мы говорили про операцию по извлечению из очереди, то с этой
[48:42.280 --> 48:50.480]  стороны очередь выглядит как stack, и там, в общем, помодули только некоторого нюанса с фиктивным узлом,
[48:50.480 --> 48:57.200]  это всё выглядело как обычное извлечение из stack. Мы читали голову и пытались подвинуть её на шаг
[48:57.200 --> 49:07.480]  вперёд. Какое отношение имеет очередь к нашему массиву? Ну или можно вообще по-другому подойти
[49:07.480 --> 49:13.240]  к этой проблеме, можно спросить так. А вот можно ли как-то сделать очередь Майкла Скотта более
[49:13.240 --> 49:17.160]  эффективной, снизить накладные расходы на добавление нового элемента? А то мы просто каждый раз...
[49:17.160 --> 49:25.120]  Интрузивность ни при чём. Можно ли снизить накладные расходы на добавление одного нового элемента?
[49:25.120 --> 49:40.160]  Вот просто в таком... вот в такой схеме. Ну смотри, что я имею в виду. Вот у тебя есть узел, да,
[49:40.160 --> 49:47.440]  и в нём лежит один элемент и один pointer next. А что если положить сюда два элемента? Три элемента.
[49:47.440 --> 49:54.200]  Ка элементов. Ну то есть сделать то, что называется сегментированная очередь Майкла Скотта,
[49:54.200 --> 50:00.080]  то есть очередь, в котором каждый узел представляет собой не одно значение, а некоторое фиксированное
[50:00.080 --> 50:09.640]  количество значений сегмента. Да? Тогда мы будем реже выполнять какие-то сложные операции, может быть,
[50:09.640 --> 50:16.440]  тогда мы будем чаще работать просто внутри одного узла. Ну так можно уменьшить количество
[50:16.440 --> 50:22.520]  локаций. Собственно, ты же, когда пишешь контейнеры, ты же что делаешь? Ты не всегда довольствующийся
[50:22.520 --> 50:28.280]  обычным эстадаристом. Ты можешь сказать, что вот у тебя есть дек, и это же тоже список, да, только он
[50:28.280 --> 50:33.280]  выполняет меньше локаций, потому что в каждом узле сразу много слотов. Вот мы получим такой
[50:33.280 --> 50:40.320]  локфри дек, можно сказать. Ну как бы не дек, конечно, то есть мы с одного конца добавляем,
[50:40.320 --> 50:47.080]  из другого достаем, но вот такие вот чанки с данными в каждом узле хранятся, они по одному
[50:47.080 --> 50:55.520]  значению. Да? Ну вот это такой разговор, как можно было бы пооптимизировать учёть Майкла Скотта. А теперь,
[50:55.520 --> 51:00.720]  если посмотреть на всю эту конструкцию как-то вот немного под другим углом, то что получится? Мы же
[51:00.720 --> 51:06.160]  сделали расширяющийся массив. У нас есть узлы, в которых есть чанки, давайте просто введём на них
[51:06.160 --> 51:15.120]  сквозную нумерацию. У каждого узла будет индекс, в каждом узле будет некоторое фиксированное
[51:15.120 --> 51:24.160]  количество слотов, и вот тогда очередь Майкла Скотта станет для нас просто-напросто таким вот
[51:24.160 --> 51:31.960]  бесконечно растущим массивом. Ну, сам по себе такой компонент не является, конечно же, тривиальным,
[51:31.960 --> 51:37.920]  то есть нужно подумать о том, управлять памятью в нём, как оба избегать Hazard Pointer и вот вся эта
[51:37.920 --> 51:45.200]  история, которую мы вот в этом году не написали всё же, к моему великому сожалению, но идея должна
[51:45.200 --> 51:52.920]  быть понятна, мне кажется. Вот смотрите, это узел, вот это реализация этого бесконечно растущего
[51:52.920 --> 52:02.840]  массива. В каждом узле есть массив вейтерс, где каждый вейтер — это там хэндлка рутины и элемент,
[52:02.840 --> 52:12.440]  ссылка на элемент. Ну, потому что мы говорим про язык поверх JV. У нас есть ячейка ID, это просто
[52:12.440 --> 52:21.120]  порядковый номер этого блока. Ну, то есть, если у нас размер сегмента 4 и ID 3, то это значит,
[52:21.120 --> 52:26.880]  третий блок, значит, индексы начинаются вот с 8 и по 11, если я, конечно, нигде ничего не напутал,
[52:26.880 --> 52:37.000]  да. В четвёртом, в блоке с четвёртым ID индекс 12-15. И в каждом узле есть ссылка next на следующий
[52:37.000 --> 52:46.960]  узел, большой такой. Это мы продвигаемся по статье. Вот у нас этот узел, есть ID, есть какое-то
[52:46.960 --> 52:55.120]  количество вейтеров и есть ссылка на следующий узел. И вот эти два индекса — это индексы,
[52:55.120 --> 53:01.640]  такие вот логические в нашем массиве, да, начало и конец очереди ожидания. А есть head
[53:01.640 --> 53:15.600]  and tail — это уже детали реализации этого массива. Ну как, справляемся, да? Хорошо, теперь можно
[53:15.600 --> 53:21.080]  просто прочесть ход. Он занимает всего лишь страницу, но страница локфрикода — невеликая
[53:21.080 --> 53:27.680]  сложность. Кажется, что все компоненты нам понятны сейчас. Нужно просто пробраться через какие-то
[53:27.680 --> 53:34.520]  технические подробности, но это вот такое типичная локфри. Смотрите, тут изображена на этой странице
[53:34.520 --> 53:41.560]  только одна операция send, потому что send и receive полностью симметричны. Ну то есть там поменяется
[53:41.560 --> 53:47.720]  в одном месте проверка головы, и вот если там мы проверяем голову и видим там, мы в сэнде проверяем
[53:47.720 --> 53:54.280]  и ожидаем, что если увидели receive, то там одно, иначе другое. В receive будет все просто то же самое,
[53:54.280 --> 53:59.480]  только вот в этом месте перевернут немного. Так что мы разбираем только операцию send, а если
[53:59.480 --> 54:05.400]  очень в другой режим, то для нее там такая же логика. Итак, мы читаем сначала NQ, потом DQ.
[54:05.400 --> 54:13.600]  Ну вот почему в таком порядке? Мы, кажется, тоже уже обсудили. Это может быть принципиально. Но
[54:13.600 --> 54:21.400]  могло так получиться, что NQ оказалось меньше DQ, потому что мы прочли NQ. Да, это все в цикле
[54:21.400 --> 54:27.200]  while находится. То есть это такая попытка сделать операцию send. Если напровалится, то мы повторим.
[54:27.200 --> 54:33.280]  Но может так получиться, что NQ индекс оказался меньше DQ индекса. Почему? Ну потому что мы
[54:33.280 --> 54:39.560]  прочитали NQ, а потом с очередью много всего произошло, и все уехало там вперед по индексам.
[54:39.560 --> 54:45.880]  Поэтому мы вполне могли получить такую несогласованную пару. Ну, значит, мы точно отстали
[54:45.880 --> 54:54.680]  от жизни, и нужно просто перечитать все заново. Отправляемся в начало итерации. Что если DQ индекс
[54:54.680 --> 55:01.280]  равен NQ индекс? Ну, отлично. Мы стали свидетелями пустой очереди. Пытаемся в него добавиться. И
[55:01.280 --> 55:07.000]  если получилось, а опять могло не получиться, потому что мы с кем-то конкурировали и нас тут
[55:07.000 --> 55:15.960]  обогнал. Вот если получилось, то мы запарковали карутину текущую. Тут у нас стеклос карутины,
[55:15.960 --> 55:21.320]  поэтому мы можем запарковаться уже после того, как нас разбудили, потому что это просто ред
[55:21.320 --> 55:25.360]  эко. Но это история про стеклос карутины, вы, наверное, это усвоили, что там гонки никакой нет
[55:25.360 --> 55:32.000]  между установкой и возобновлением. Если не получилось, то опять произошло что-то непонятное,
[55:32.000 --> 55:38.680]  и мы пробуем заново. Хорошо. Значит, у нас теперь есть пара NQ индекс DQ индекс, которые похожи на
[55:38.680 --> 55:45.200]  не противоречащие друг другу. Что нужно дальше сделать? Нужно понять, в каком состоянии сейчас
[55:45.200 --> 55:52.840]  находится канал, да? То есть, кто находится в голове, либо sender, либо receiver. Наша задача
[55:52.840 --> 56:01.960]  прочесть содержимое NQ индекса. А где он находится физически? Он находится в некотором узле. Вероятно,
[56:01.960 --> 56:10.960]  который указывает head. Поэтому мы читаем head. А теперь верно ли, что сегмент, то есть узел,
[56:10.960 --> 56:18.400]  на который указывает head, содержит в себе сегмент, в котором есть нужный индекс? Вот мы это проверяем.
[56:18.400 --> 56:28.920]  Вот узел, в котором находится нужный нам индекс, находится в... имеет ID вот такой вот. А мы смотрим
[56:29.000 --> 56:41.120]  вот такой. На узел с таким ID. Если... простите. Если ожидаемый ID узла оказался меньше,
[56:41.120 --> 56:45.960]  чем актуальный, то это означает, что мы снова отстали от жизни, что head уже убежал вперёд,
[56:45.960 --> 56:52.520]  что наш DQ индекс больше не актуален, и нужно перечитывать всё заново. Да? Но просто пока
[56:52.520 --> 56:59.920]  разбор случаев, мы пытаемся получить такой согласованный снапшот состояния канала. А что,
[56:59.920 --> 57:09.920]  если DQ индекс... что если ID сегмента, в котором находится DQ индекс, оказался больше, чем head ID?
[57:09.920 --> 57:17.360]  Это означает, что просто head ID отстал. Ну, то есть какой-то другой поток добавил новый узел,
[57:17.360 --> 57:22.840]  а почему-то head ID не поправили ещё. Ну, тогда мы пытаемся подтянуть head вперёд и пробуем заново.
[57:22.840 --> 57:30.440]  Ну, это вот некоторое хелпинг. И вот наконец-то, наконец-то мы справились. У нас есть DQ индекс,
[57:30.440 --> 57:36.960]  и у нас есть ссылка на узел, в котором лежит ячейка с этим DQ индексом. И мы наконец можем
[57:36.960 --> 57:45.440]  прочитать содержимое. Ну, вот как мы читаем, разбираемся. У нас есть узел N, у нас там есть
[57:45.440 --> 57:57.520]  индекс E внутри этого узла, и мы должны прочесть эту ячейку. Ну, кажется, кстати, тут... да, мы
[57:57.520 --> 58:05.560]  передаём туда индекс уже внутри сегмента. Вот, мы берём узел, берём его вейтеров и смотрим на
[58:05.560 --> 58:10.480]  элемент. Элемент — это не данные, это вот ссылка. Ну, представьте себе язык, вот какой-нибудь там
[58:10.480 --> 58:16.160]  Java, Kotlin, что-то подобное. У вас есть ссылка, и вы читаете эту ссылку. Если там написано не Null,
[58:16.160 --> 58:23.400]  то вот, значит, слот уже как бы зафиксировал своё состояние. Он либо отравлен, либо там значение
[58:23.400 --> 58:31.240]  лежит, либо туда кто-то встал уже. А если он оказался пуст, то вы хотели что-то прочесть из него,
[58:31.240 --> 58:38.880]  да? А вы не можете, он пуст. И вы не хотите ждать. Поэтому вы отравляете этот слот, чтобы идти дальше.
[58:39.040 --> 58:44.720]  Вы делаете касс. Вы пытаетесь переставить Null на Broken. Если получилось, то уходите и
[58:44.720 --> 58:50.480]  возвращайтесь от Broken. Если не вышло, то, видимо, почему ваш касс провалился? Потому что там уже
[58:50.480 --> 58:57.800]  что-то было не Null. Поэтому вы вернули то, что там сейчас есть. Ну и вот, вы вот с такими небольшими
[58:57.800 --> 59:06.600]  усилиями прочли содержимое DQ-индекса, наконец. Ну, ячейки по индексу DQ-индекс. И теперь смотрите,
[59:06.600 --> 59:11.880]  если слот был отравлен, то нужно его пропустить. Нужно сдвинуть DQ-индекс вперёд. Пробуйте и
[59:11.880 --> 59:22.160]  ретравитесь. Почему вы пробуете кассом? Потому что на него один можете так делать. Вот, а если
[59:22.160 --> 59:34.840]  вы видите ресивера, вот там находится ресивер. Что это означает? А вы же операция Ascent? Ну вот,
[59:34.840 --> 59:45.120]  значит, случилось rendezvous, да? То есть вы застолбили себе индекс? Нет, вы не застолбили ещё
[59:45.120 --> 59:52.540]  индекс. Вы просто увидели ресивера. Вы знаете, что в очереди сейчас ресивер, а вы sender. Так что
[59:52.540 --> 59:59.760]  нужно разбудить этого ресивера, дать ему значение. И вот вы попадаете в Resume Waiter. Вы sender,
[59:59.760 --> 01:00:08.880]  который готов разбудить этого в текущем узле ресивера. Ну, для этого вы пытаетесь захватить
[01:00:08.880 --> 01:00:17.120]  его внимание. Инкрементируете DQ-индекс с помощью кассы. Если получилось, то он ваш,
[01:00:17.120 --> 01:00:26.240]  вы его будете. Кладёте ему значение, берёте, да, вы берёте этого вейтера и будете его,
[01:00:26.240 --> 01:00:31.680]  отдавай ему значение с помощью вот такого API. Ну, это уже какие-то нюансы, не очень важно,
[01:00:31.680 --> 01:00:37.680]  как это написано. Вот, но главное, что вы захватили слот, там был ресивер, и касс, поскольку он
[01:00:37.680 --> 01:00:42.360]  завершился, вы уверены, что в этом слоте по-прежнему есть ресивер, никуда он не денется оттуда. У вас
[01:00:42.360 --> 01:00:49.640]  стоит машина такая, ну, либо в отравленное состояние, либо в ждущего sender-ресивера.
[01:00:49.640 --> 01:00:56.280]  Разбудили. Если не получилось, если касс провалился, то не беда, вы опять откатываетесь
[01:00:56.280 --> 01:01:06.680]  с самого начала цикла while, делаете новую итерацию, пытаетесь всё заново. В Kotlin не сомневаюсь.
[01:01:06.680 --> 01:01:12.520]  Да, не нужно применять C++ к Kotlin, пожалуйста.
[01:01:19.640 --> 01:01:26.320]  Не, ну, подожди, вот ты написал некорректное освобождение памяти и говоришь, что...
[01:01:26.320 --> 01:01:33.680]  Если ты освобождаешь память, которую ещё используют, то у тебя некорректная программа. Давай так.
[01:01:33.680 --> 01:01:41.920]  Ну, во-первых, мы не управляем памятью, во-вторых, вот просто такой код писать не стоит, да, который
[01:01:41.920 --> 01:01:46.800]  читает память, которую вы уже освободили. Это какое-то странное желание немного. Это похоже на
[01:01:47.400 --> 01:01:54.600]  наших разработчиков просто. Итак, разбудили, а если там был не ресивер, то мы пытаемся что сделать.
[01:01:54.600 --> 01:02:01.320]  Мы пытаемся... Если мы прочли DQ-индекс и там оказался sender, а мы sender, то мы пытаемся встать в
[01:02:01.320 --> 01:02:09.480]  конец очереди. Ну, это развилка, что мы делаем, либо одним, либо другим способом. А теперь нам нужно
[01:02:09.480 --> 01:02:15.280]  сильно ускориться. У нас следующая пара, и она, кажется, здесь будет или не будет.
[01:02:15.280 --> 01:02:26.360]  В этой аудитории. А сейчас зачетная неделя, поэтому всякое бывает. Ну ладно, тогда... Ладно,
[01:02:26.360 --> 01:02:36.120]  я не смогу ускориться, если что, перейдем просто в 425. Значит, с этой веткой мы разобрались. То есть,
[01:02:36.120 --> 01:02:43.920]  когда случается рандевуй, когда мы кого-то будем. А сейчас мы увидели, что очередь, что в очереди спят,
[01:02:43.920 --> 01:02:49.600]  крутины, которые выполняют ту же роль, что и мы, то есть sender, и мы хотим встать в очередь.
[01:02:49.600 --> 01:02:57.480]  Ну, для этого мы хотим попасть в какой-то слот. И тут у нас есть такая развилка. Мы берем узел,
[01:02:57.480 --> 01:03:03.280]  ну и снова проверяем, верно ли, что наш... что tail указывает на узел, в котором есть
[01:03:03.280 --> 01:03:10.440]  нужный индекс. Такая же история. Если нет, то откатываемся. А если индекс наш нулевой,
[01:03:10.440 --> 01:03:16.880]  то пропускаем вообще этот индекс. В смысле, нулевой внутри сегмента. Мы его пропускаем об этом чуть
[01:03:16.880 --> 01:03:24.400]  позже. А дальше у нас есть два варианта. Либо мы переполняем слот, либо мы переполняем сегмент,
[01:03:24.400 --> 01:03:29.480]  либо мы не переполняем сегмент. Если мы не переполняем сегмент, то все очень просто. Мы опять
[01:03:29.480 --> 01:03:38.160]  пытаемся увеличить NQ-индекс и просто записать себя вот в ячейку. Ну вот это явная опечатка,
[01:03:38.160 --> 01:03:44.600]  да? Потому что тут не может быть... это глобальная индексация, а нам нужна относительно внутри
[01:03:44.600 --> 01:03:55.400]  сегмента. Но все равно все мы понимаем, что это имелось в виду. Мы пытаемся захватить... мы
[01:03:55.400 --> 01:04:03.360]  пытаемся встать в первый свободный слот текущего сегмента. Если это не получилось,
[01:04:03.360 --> 01:04:10.120]  ну попробуем заново, как обычно. Ну и тут опять два шага. Мы захватываем сначала слот,
[01:04:10.120 --> 01:04:16.920]  если это получилось, мы должны записать туда элемент. Но это может не получиться, потому что
[01:04:16.920 --> 01:04:23.000]  мы конкурируем с читающим, который слоты отравляет. Вот здесь вот. Поэтому у нас здесь тоже касс.
[01:04:23.000 --> 01:04:36.880]  Отлично. А что если у нас чанк переполнился? То нужно алоцировать новый чанк. И это уже просто
[01:04:36.880 --> 01:04:43.400]  добавление в очередь Майкла Скотта. То есть мы добавляем новый узел, мы кладем сюда себя в
[01:04:43.400 --> 01:04:54.120]  нулевую позицию и пытаемся прицепить... ну вернее мы... сейчас, аккуратно. Мы создаем новый узел,
[01:04:54.120 --> 01:05:00.400]  мы пытаемся положить себя в нулевую позицию и мы пытаемся прицепить себя к хвосту очереди Майкла
[01:05:00.400 --> 01:05:07.680]  Скотта. Ну вот так. Типичный для очереди Майкла Скотта касс. Ну иногда мы можем помогать кому-то.
[01:05:07.680 --> 01:05:12.360]  Вдруг мы увидели уже tail next, он оказался не нул, тогда нужно передвинуть tail вперед.
[01:05:12.360 --> 01:05:26.120]  А теперь вопрос на внимание. Мы решили лайфлог сейчас. Лайфлог у нас больше нет. Мы вроде бы
[01:05:26.120 --> 01:05:31.240]  специально ничего не делали, но его больше не существует в нашем коде, в нашей реализации. Вот
[01:05:31.240 --> 01:05:34.880]  когда у нас был бесконечный массив, лайфлог был. Когда у нас есть вот такой вот массив специальный,
[01:05:34.880 --> 01:05:43.120]  у нас лайфлога уже нет. Почему? Вспомним, как он вообще появлялся. То есть у нас была пустая
[01:05:43.120 --> 01:05:51.640]  очередь и мы приходили и вот увеличивали NQ индекс, отравляли слот, потом проваливали запись,
[01:05:51.640 --> 01:05:58.520]  пробовали дальше пойти, да? Ну то есть один поток, одна корутина увеличивала NQ индекс и занимала
[01:05:58.520 --> 01:06:06.160]  слот, делала его не пустым, ну как бы наполовину не пустым, предпустым, да? А другая корутина,
[01:06:06.160 --> 01:06:13.600]  она видела все-таки, что не полон еще стакан и как бы она пессимист, половина отравляла его и
[01:06:13.600 --> 01:06:22.680]  шла вперед. Так вот, на массиве это может работать бесконечно, а на таком массиве из чан,
[01:06:22.680 --> 01:06:28.720]  она списки из чанков не может. Почему? Потому что мы вот так можем этим лайфлогом идти вперед
[01:06:28.720 --> 01:06:35.960]  по массиву до тех пор, пока мы не упремся в границу сегмента. И потом уже сендер,
[01:06:35.960 --> 01:06:41.920]  который увеличивает NQ индекс, что он сделает? Он не просто индекс увеличит, он, чтобы продолжать
[01:06:41.920 --> 01:06:48.680]  движение вперед свое бессмысленное, он должен алоцировать новый чанк. А когда он алоцирует
[01:06:48.680 --> 01:06:55.440]  новый чанк, новый узел, то он там занимает нулевой место сразу успешно. И вместе с публикацией этого
[01:06:55.440 --> 01:06:59.760]  чанка он там уже сразу есть. То есть он два шага делает в другом порядке, теперь атомарно,
[01:06:59.760 --> 01:07:07.920]  получается, для ресивера. Понимаете? Вот, и на границе чанка этот лайфлог обязательно разломается,
[01:07:07.920 --> 01:07:15.360]  ну в смысле, он разрешится. Вот, довольно ловко, да, получилось. Ну то есть этот лайфлог есть,
[01:07:15.360 --> 01:07:19.320]  он очень простой алгоритм, там есть лайфлог, но за счет того, что мы вот таким образом сделали,
[01:07:19.320 --> 01:07:32.040]  сделали очередь, мы можем... мы от лайфлога вот так автоматически избавились. Ну да, нулевые
[01:07:32.040 --> 01:07:35.960]  слоты, поэтому мы скипаем, потому что они всегда не пусты, потому что если сегменты публикованы,
[01:07:35.960 --> 01:07:49.000]  в нем уже есть нулевой... карутина вейтер в нулевом слоте. Довольно простой алгоритм. Вот, в принципе,
[01:07:49.000 --> 01:07:57.800]  весь лог-3-канал написан. Можно его написать и сравнить его с блокирующимся каналом. Мне очень
[01:07:57.800 --> 01:08:02.440]  любопытно, если кто-то попробует сделать, даже без управления памятью, то есть вот мы не освобождаем
[01:08:02.440 --> 01:08:06.920]  память, допустим, для простоты, и вот посмотрим, насколько будет велика разница. Потому что в
[01:08:06.920 --> 01:08:12.760]  профиле у вас там будет торчать спинлог, если вы напишите канал и будете это исследовать. А теперь
[01:08:12.760 --> 01:08:18.280]  мы как бы идем на следующий уровень, и там становится все интереснее, потому что мы хотим
[01:08:18.280 --> 01:08:30.760]  поддержать в этом канале селекты. И селекты, они должны быть... селекты ну и для сендов, и для
[01:08:30.760 --> 01:08:40.800]  ресивов. И смотрите, какая ситуация возможна теперь. Вот, предположим, у вас есть канал, и там
[01:08:40.800 --> 01:08:48.640]  есть... там есть сендеры, и эти сендеры являются селектами. Ну, некоторые сендеры могут являться
[01:08:48.640 --> 01:08:56.480]  селектами. Вот вы приходите с ресивер, вы видите, что в очереди сендеры, значит, нужно захватить
[01:08:56.480 --> 01:09:05.200]  тебе первый слот свобод... первый слот из очереди, и зарезюмить сендеры. Да? Сейчас.
[01:09:10.360 --> 01:09:12.200]  Сейчас я придумаю, что я хочу.
[01:09:17.480 --> 01:09:21.160]  Я хочу, наверное, селект...
[01:09:27.160 --> 01:09:30.880]  Я хочу, наверное, селект, который пишет, и я ресивер, который я хочу.
[01:09:36.880 --> 01:09:40.440]  Сейчас, мне нужен... мне нужен нетривиальный... нетривиальный случай.
[01:09:53.960 --> 01:09:55.760]  Нет, все нормально, в очереди сенды.
[01:09:57.480 --> 01:10:06.360]  А я селект. Я прихожу в канал, и что я делаю? Я хочу забрать оттуда первый слот.
[01:10:06.360 --> 01:10:14.240]  То есть, я посмотрел, там сенды лежат, мне нужны сенды, я увеличил DQ-индекс, достал сендера,
[01:10:14.240 --> 01:10:22.040]  ну, захватил сендера себе, все, он мой. Но я же селект. И я могу... я привередливый, я могу от
[01:10:22.040 --> 01:10:30.360]  значения отказаться иногда. Потому что, ну, вот просто в мой селектор, вот в этот консенсус,
[01:10:30.360 --> 01:10:36.840]  уже кто-то что-то написал. То есть, просто другой канал меня заполнил уже значению. И в итоге
[01:10:36.840 --> 01:10:45.440]  проблема появляется. Я сендер, я селект ресив, пришел в канал забирать значения, захватил себе
[01:10:45.440 --> 01:10:52.280]  слот, там был сендер, которого я вроде бы как бы захватил себе. Но воспользоваться я не могу.
[01:10:52.280 --> 01:11:01.000]  То есть, я хотел бы сделать следующее. Я хотел бы достать из очереди сендера,
[01:11:01.000 --> 01:11:14.880]  только если мой консенсус еще не установлен. Да? То есть, если в одной ячейке что-то, то есть,
[01:11:14.880 --> 01:11:23.440]  я бы хотел посмотреть на две ячейки, и потом эти две ячейки поменять. Если вот у меня консенсус
[01:11:23.440 --> 01:11:30.080]  еще не установлен, и если в DQ индекс указывает... DQ индекс указывает на сендера, то я бы хотел,
[01:11:30.080 --> 01:11:39.320]  там, поглотить этот DQ индекс и установить флажок, что я селектор получил значение. И вот мы
[01:11:39.320 --> 01:11:46.200]  приходим к операции, где мы к потребности для лог-фри канала с селектом иметь лог-фри касс,
[01:11:46.200 --> 01:11:51.520]  который можно выполнить на двух произвольных ячейках памяти. А теперь представим себе,
[01:11:51.520 --> 01:11:59.880]  что сендер в канале, которого мы хотим достать, это не просто сендер, это сендер из селекта. То
[01:11:59.880 --> 01:12:06.720]  есть, у нас был селект с как бы... был селект с ресивом и селект с ресивом и тайм-аутом с одной стороны,
[01:12:06.720 --> 01:12:14.640]  а с другой стороны селект с сендом и тайм-аутом. Вот, и как бы в нашем канале с данными лежит селект
[01:12:14.640 --> 01:12:21.840]  для отправки, мы приходим селект для получения, и нам нужно еще более сложное рандеву, потому что
[01:12:21.840 --> 01:12:34.400]  мы хотим сэнд селект на получение, хочет поглотить узел, ячейку, очереди, только если сам этот...
[01:12:34.400 --> 01:12:42.760]  только если селект текущего ресива еще не заполнился значением, там отмена из другого канала контекста,
[01:12:42.760 --> 01:12:51.560]  и сэндер из селекта на отправку тоже еще не заполнился значением, и селект сэндера,
[01:12:51.560 --> 01:12:56.960]  который уже находится в очереди, еще не заполнился значением. Понимаете меня тут?
[01:12:56.960 --> 01:13:03.480]  Очень путанно говорю. Но вот у нас есть два селекта, и нам нужно и состояние очереди поменять,
[01:13:04.160 --> 01:13:12.520]  условно, и два селекта заполнить, если они пустые до сих пор. Вот, это уже касс на трех ячейках. Вот, и так
[01:13:12.520 --> 01:13:19.000]  мы приходим очень естественно к задаче иметь, как выразился Миша вчера, многословный касс,
[01:13:19.000 --> 01:13:25.280]  который умеет переключить n ячеек памяти, если в них находятся некоторые ожидаемые значения.
[01:13:25.280 --> 01:13:32.720]  Ячейки памяти должны быть произвольными. В смысле, вот у нас, мы знаем, в некоторых процессорах есть
[01:13:32.720 --> 01:13:39.120]  инструкция Compere Exchange 16b, то есть она может посмотреть на два машинных слова, соседних памяти,
[01:13:39.120 --> 01:13:45.080]  и переставить их на новые значения. Ну, то есть касс просто двойной ширины. Вот дело сейчас не в
[01:13:45.080 --> 01:13:49.200]  ширине ячеек, а в том, что это просто разные ячейки, произвольные ячейки. Мы не управляем тем,
[01:13:49.200 --> 01:13:55.960]  где они находятся. Алгоритм работает с произвольными ячейками. И вот мы хотим такую операцию иметь,
[01:13:55.960 --> 01:14:14.080]  Multi-World-Cass, который, Multi-World-Cass, который оперирует сразу несколькими ячейками памяти.
[01:14:14.080 --> 01:14:20.400]  И вот его научились делать, научились делать его, ну вот я поговорю про реализацию, которая даже не
[01:14:20.400 --> 01:14:30.080]  совсем... Это некоторый затейливый алгоритм. Мне он кажется очень симпатичным, очень ловким,
[01:14:30.080 --> 01:14:35.360]  но в то же время вот он используется, используется, в частности, в реализации
[01:14:35.360 --> 01:14:40.880]  корутин в котлене. Вот вы можете посмотреть на статью, на доклад Романа Ивизарова,
[01:14:40.880 --> 01:14:47.280]  кажется, 19-го года, где он рассказывает, как там на основе замороченного двусвязанного
[01:14:47.280 --> 01:14:53.680]  лог-фри списка и вот от такого сиректа можно построить лог-фри каналы сиректа для котлина.
[01:14:53.680 --> 01:14:58.800]  Ну вот, так что то, что мы говорим, это в каком-то смысле даже практично. Ну вот так,
[01:14:58.800 --> 01:15:03.800]  прямо скажем, не многие делают. Это очень-очень сложно, и вопрос даже в том, нужно ли так настолько
[01:15:03.800 --> 01:15:10.240]  хорошо делать. Вот ГО, скажем, находится без этого. В ГО там блокировки. Ну вы можете видеть это,
[01:15:10.240 --> 01:15:17.440]  открыв ссылку в задачу. Итак, наша задача построить мульти ворд касс, который сравнивает
[01:15:17.440 --> 01:15:23.200]  N-ячеек, сравнивает содержимое N-ячеек. Если во всех из них лежит одинаковое значение, то,
[01:15:23.200 --> 01:15:31.000]  не одинаковое, простите, а ожидаемое значение, то переставляет их какие-то новые значения. И это
[01:15:31.000 --> 01:15:35.760]  должен быть алгоритмический мульти касс, то есть аппаратной поддержки у нас нет. У нас есть ячейки
[01:15:35.760 --> 01:15:40.240]  памяти, которые работают, на которых есть все атомарные операции, которые у нас есть,
[01:15:40.240 --> 01:15:45.120]  оперируют отдельными ячейками памяти. Так что мы должны обходиться простыми атомарными операциями,
[01:15:45.120 --> 01:15:50.000]  и, наверное, вы догадываетесь, с помощью чего мы будем решать эту задачу. Мы будем решать ее с
[01:15:50.000 --> 01:15:56.280]  помощью обычной операции Compare Exchange. Но опять же, вы этого не знаете, но у вас наверняка есть уже
[01:15:56.280 --> 01:16:00.560]  интуиция по этому поводу, что, видимо, из всех операций, которые у нас в процессоре есть,
[01:16:00.560 --> 01:16:07.480]  которые есть в атомиках, операция Compare Exchange, она наиболее выразительна, наиболее полезна. Ну,
[01:16:07.480 --> 01:16:11.400]  потому что, хотя бы потому, что с помощью нее можно было бы выразить все остальные, все другие
[01:16:11.400 --> 01:16:20.240]  операции, да, это реально. Вот, у нас есть такой однословный касс, лаконичный касс, и мы с помощью
[01:16:20.240 --> 01:16:29.040]  него хотим реализовать мультиворд касс, который должен быть сам по себе лог-фри алгоритмом. Вот,
[01:16:29.040 --> 01:16:32.760]  мы начнем решать эту задачу с помощью очень странного вспомогательного шага, а именно мы
[01:16:32.760 --> 01:16:40.080]  построим операцию с очень неинтуитивной, на первый взгляд, семантикой, которая называется restricted
[01:16:40.080 --> 01:16:51.840]  double-word single-swap. Семантика такая, у нас есть ячейка A1, ячейка A2, есть ожидаемые значения O1 и O2,
[01:16:51.840 --> 01:17:01.440]  и есть целевое значение N2. И мы хотим, если в A1 находится O1 и в A2 находится O2, записать в A2
[01:17:01.440 --> 01:17:13.960]  N2. Ну, то есть, это такой, мы хотим сделать, по сути, касс на ячейке A2 из O2 в N2, но только если в
[01:17:13.960 --> 01:17:24.880]  ячейке A1 находится O1. Такой дважды условный касс. То есть, даже операция слабее, чем касс 2. Нас не
[01:17:24.880 --> 01:17:29.360]  интересует успех или поражение, нам операция возвращает только то, что было написано в A2,
[01:17:29.360 --> 01:17:42.080]  и все. И операция не перезаписывает A1. Ну вот, если мы решим такую задачу, то мы с помощью нее
[01:17:42.080 --> 01:17:47.200]  можем уже довольно просто построить мультиворд касс. Как мы решим такую задачу? Нам нужно прочесть...
[01:17:47.200 --> 01:17:53.920]  Семантика понятна? Нам нужно каким-то образом прочесть атомарно две ячейки памяти и одну из них
[01:17:53.920 --> 01:17:59.160]  перезаписать, если в двух ячейках ожидаемые значения. Ну, разумеется, мы не можем прочесть
[01:17:59.160 --> 01:18:04.040]  атомарно две ячейки памяти разные. Можем только по очереди прочесть. И вот мы прочли первую,
[01:18:04.040 --> 01:18:12.960]  допустим, A2. Она совпала с O2. Дело идет хорошо. Как теперь прочесть A1? Точнее, как прочесть?
[01:18:12.960 --> 01:18:19.560]  Понятно. Как не потерять гарантию, что ячейка A2 к этому моменту не изменилась? Ну, очень просто,
[01:18:19.560 --> 01:18:27.120]  взять блокировку на ячейку A1. То есть, мы берем блокировку на A1, читаем ее значение, если там все
[01:18:27.120 --> 01:18:33.600]  хорошо, то смотрим на A2. И пока мы не прочитали A2 и не приняли решения, мы блокировку на
[01:18:33.600 --> 01:18:42.880]  пока мы не прочли A1, мы блокировку на A2 не отпустим. А значит, наша проверка не инвалидируется.
[01:18:42.880 --> 01:18:50.480]  Замысел понятен? То, что это не лок-фри, наверное, комментировать не нужно. Вот мы хотим, чтобы
[01:18:50.480 --> 01:18:58.640]  алгоритм стал лок-фри. Поэтому мы хотим некоторую специальную блокировку, которую можно снять за
[01:18:58.640 --> 01:19:04.880]  нас. Ну, потому что если другой поток увидит, что там лежит наша блокировка, то он должен
[01:19:04.880 --> 01:19:12.080]  избавиться, потому что она ему мешает. Но если бы он просто у нас блокировку отнимал, это было бы
[01:19:12.080 --> 01:19:18.040]  странно, потому что какая-то блокировка. Поэтому вместо того, чтобы снимать блокировку, он
[01:19:18.040 --> 01:19:26.760]  может ее снять, только если он помог нам. Он не хочет инвалидировать, он хочет помогать. И смотрите,
[01:19:26.760 --> 01:19:32.040]  что мы сделаем. Мы скажем, что у нас операция вот эта вот restricted double word, double compare,
[01:19:32.040 --> 01:19:41.920]  single swap получает аргументом, получает свои аргументы, не видя там вот A1, O1, вот все
[01:19:41.920 --> 01:19:49.840]  этой пятерки. Она получает некоторый дескриптор. Объект, в котором в полях находятся все аргументы,
[01:19:49.840 --> 01:19:57.440]  адреса, аргументы. Откуда взялся этот дескриптор, операцию не волнует. Ну, то есть нам авторы статьи
[01:19:57.440 --> 01:20:03.840]  намекают, что лучше писать на языке автоматической сборкой мусора здесь. Вот, и это правда. Ну,
[01:20:03.840 --> 01:20:09.200]  то есть писать на C++ — это добавлять себе огромную сложность, перпендикулярный алгоритм, а именно
[01:20:09.200 --> 01:20:15.600]  управление памятью. Вот мы считаем, что у нас дескриптор есть, и вот он... можно хранить на него
[01:20:15.600 --> 01:20:21.240]  указатели, и вот пока указатели живы, объект не разрушается. Такое очень сильное предположение,
[01:20:21.240 --> 01:20:27.080]  предположение, что у нас есть сборка мусора какая-то. Мы на это закрываем глаза сейчас. Так вот,
[01:20:27.080 --> 01:20:37.400]  что мы делаем? Мы сначала читаем ячейку A2 и сразу же автоматически берем на него блокировку,
[01:20:37.400 --> 01:20:47.080]  если содержимое совпало с ожидаемым. Это выражено так. Мы делаем CAS на ячейке A2. Если там лежит
[01:20:47.080 --> 01:20:55.920]  дескриптор O2, то мы туда пишем вместо значения дескриптор, то есть pointer на дескриптор. Вот,
[01:20:55.920 --> 01:21:02.200]  и теперь любая другая операция, которая пришла читать ячейку памяти, если она видит там дескриптор,
[01:21:02.200 --> 01:21:15.160]  то она может пройти по нему и узнать аргументы, собственно, этой операции RDCSS, потому что в ней
[01:21:15.160 --> 01:21:29.560]  все аргументы написаны. Ну вот, смотрите, что происходит. Мы читаем ячейку A2, сравниваем
[01:21:29.560 --> 01:21:34.960]  содержимое этой ячейки с O2, и если совпало, то устанавливаем дескриптор, такую блокировку.
[01:21:34.960 --> 01:21:46.880]  А дальше нам операция CAS возвращает то, что она прочитала из O2. Может быть, значение,
[01:21:46.880 --> 01:21:55.120]  которое там было, являлось ссылкой на дескриптор. Как это понять? Ну, вы там младший битик в адресе
[01:21:55.120 --> 01:22:03.280]  взведете, чтобы отличить просто произвольный pointer от дескриптора. Вот. Ну, это такой неприятный
[01:22:03.280 --> 01:22:08.520]  случай. А может быть, вы сразу прочли O2. Но если вы прочли O2, то вы знаете,
[01:22:08.520 --> 01:22:14.480]  что вы записали дескриптор, и вот первый шаг состоялся. Вы сравнили A2 с O2, совпало,
[01:22:14.480 --> 01:22:23.720]  и вы взяли блокировку. И вы дальше спокойно читаете A1, выполняете шаг COMPLETE.
[01:22:23.720 --> 01:22:40.160]  Читаете A1. И если вы видите в A1 O1, то вы завершаете успешно вашу операцию RDCSS. Вы
[01:22:40.160 --> 01:22:53.600]  переключаете ячейку A2 с D на N2. Понятен принцип? То есть, вы делаете такую цепочку состояния,
[01:22:53.600 --> 01:23:00.280]  у вас A2 сначала указывает на O2, потом на дескриптор, а потом на N2.
[01:23:09.520 --> 01:23:18.640]  Что? Ну, тут можно многие параллели углядели, да. Ну да, но мне сейчас, наверное, не очень полезно,
[01:23:18.640 --> 01:23:30.120]  в смысле, проводить параллели с чем-то другим. Идея понятна? У меня она кажется довольно ловкой.
[01:23:30.120 --> 01:23:35.880]  Ну а если вы прочитаете дескриптор, то что вы делаете? Вам он мешает выполнить вашу операцию.
[01:23:35.880 --> 01:23:42.280]  Вы просто читаете ячейку памяти, а там написан дескриптор другой операции. Вы даже не можете
[01:23:42.280 --> 01:23:46.480]  понять, в каком ячейке состояние. Оно в межуточном состоянии. Оно не определилось еще. То есть,
[01:23:46.480 --> 01:23:50.960]  то ли она переходит в новостей, то ли она не переходит. Поэтому вы просто помогаете завершить
[01:23:50.960 --> 01:23:58.560]  операцию другому потоку. Вызываете complete. Так что complete можно вызвать дважды. Ну и вот поэтому,
[01:23:58.560 --> 01:24:05.800]  когда вы видите в ячейке A1, O1, то вы не просто переводите A2 в N2 слепо, перезаписывая содержимые
[01:24:05.800 --> 01:24:12.040]  ячейки, а вы делаете CAS, потому что в ячейке уже может быть не дескриптор, потому что вам помог
[01:24:12.040 --> 01:24:21.400]  другой поток. Ну, собственно, вот это и называется хелпингом. Есть вопросы?
[01:24:26.120 --> 01:24:28.800]  Вы выглядите так, как будто непонятно ничего, а все, на самом деле, очень просто.
[01:24:34.800 --> 01:24:40.160]  Ну вот рисунок, который, в общем, мне кажется, я не знаю, что проиллюстрировать еще. У тебя было
[01:24:40.160 --> 01:24:46.200]  две ячейки памяти. Ты хотел переключить Y с B на C при условии, что в X находится A. Вот у тебя был
[01:24:46.200 --> 01:24:52.000]  объект, который эту операцию описывал. И вот первым делом, ты переключил CAS в ячейку Y с B на
[01:24:52.000 --> 01:24:59.120]  дескриптор. Вот, а дальше ты уснул. Но не страшно, любой другой поток может прийти, и если он здесь
[01:24:59.120 --> 01:25:07.680]  увидит дескриптор вместо значения, то он пойдет по нему, увидит все аргументы и сможет перевести
[01:25:07.680 --> 01:25:15.880]  либо Y в C, если тут лежит в X все еще A, либо, если он видит в X A, то сбросит дескриптор обратно
[01:25:15.880 --> 01:25:21.200]  в B, потому что в дескрипторе есть второе значение. То есть мы можем как и накатить, и откатить.
[01:25:37.680 --> 01:25:44.320]  Так не страшно, ты всегда делаешь CAS. То есть у тебя есть, смотри, в этом, в этой операции ты делаешь
[01:25:44.320 --> 01:25:53.760]  всего одну мутацию одной ячейки Y, ну то есть A2 из старого в новое. И ты сначала делаешь такую
[01:25:53.760 --> 01:25:58.680]  промежуточную мутацию из старого значения в дескриптор, а потом ты либо откатываешь, либо
[01:25:58.680 --> 01:26:09.180]  накатываешь, при условии, что дескриптор все еще стоит. Вот, ты читаешь A1, принимаешь решение,
[01:26:09.180 --> 01:26:14.320]  а дальше ты либо накатываешь, либо откатываешь, но делаешь это с условием, что до сих пор в ячейке
[01:26:14.320 --> 01:26:20.720]  A2 лежит дескриптор. Если вдруг что-то изменилось, то просто ты не доделаешь свою операцию. Ну,
[01:26:20.720 --> 01:26:31.120]  в смысле она потеряла актуальность, кто-то другой тебе помог уже. Очень просто. Ну,
[01:26:31.120 --> 01:26:38.720]  такой просто двухфазный, двухфазная перезапись. Ну, это вот мы накатываем новое значение, тут мы
[01:26:38.720 --> 01:26:45.280]  убедились, что в A1 лежит не O1, и мы откатываем старое значение. Но мы и накатываем, и откатываем,
[01:26:45.280 --> 01:26:53.320]  только если у нас все еще в ячейке A2 находится указатель на дескриптор. Вот, ну этот комплит мы
[01:26:53.320 --> 01:27:00.400]  выполняем либо сами, либо мы выполняем, либо мы помогаем другому. Не, абсолютно. Тут всего одна,
[01:27:00.400 --> 01:27:07.760]  одна перезапись, по сути. Вот, а теперь, имея такую операцию, очень просто сделать алгоритм для
[01:27:07.760 --> 01:27:16.240]  сразу N ячеек. И он тут написан довольно, выглядит как будто неаккуратный какой-то псевдокод, написанный
[01:27:16.240 --> 01:27:24.720]  на чем-то C подобном. Но идея очень простая. У вас есть теперь N ячеек разных, и вам нужно сравнить
[01:27:24.720 --> 01:27:35.200]  все и все переставить в новое значение. Как вы это сделаете? Вы сделаете это в две фазы. Вы сначала
[01:27:35.240 --> 01:27:45.880]  все ячейки сравните и залочите по очереди, а потом, если вы на все ячейки собрали блокировки и
[01:27:45.880 --> 01:27:52.560]  проверили их содержимое, то вы уверены, что, ну вот, во-первых, вы зафиксировали состояние,
[01:27:52.560 --> 01:27:56.760]  в котором все ячейки совпадают с ожидаемыми значениями, а во-вторых, вы повесили на них
[01:27:56.760 --> 01:28:02.480]  дескрипторы, которые являются, по сути, блокировками, которые мешают другим потоком эти ячейки менять,
[01:28:02.480 --> 01:28:09.000]  не завершив вашу операцию. Поэтому вы действуете в две фазы. Вы накапливаете блокировки, вешаете
[01:28:09.000 --> 01:28:14.200]  дескрипторы на все ячейки, которые вы трогаете, и если операция, если вы на все навесили дескрипторы,
[01:28:14.200 --> 01:28:20.320]  и везде все совпало, то вы на второй фазе просто перезаписываете, ну, либо накатываете значения
[01:28:20.320 --> 01:28:27.680]  новые, либо откатываете старые. Подожди, это пока только общая идея. Ну вот, накатываем и откатываем,
[01:28:27.680 --> 01:28:32.160]  тут уже видно здесь. Вот мы идем по N ячейкам дескриптора, тут снова есть такой магический
[01:28:32.160 --> 01:28:40.640]  дескриптор, который содержит все записи. Вот, у нас есть адрес для каждой записи, и мы смотрим,
[01:28:40.640 --> 01:28:47.680]  если в ячейке все еще дескриптор, то мы накатываем, если у нас операция в целом завершилась успешно,
[01:28:47.680 --> 01:28:55.040]  то мы накатываем новое значение, иначе откатываем старое значение. Ну а теперь чуть подробнее. Вот с
[01:28:55.040 --> 01:29:03.840]  чего мы начинаем? Мы операция CAS N. У нас есть некоторый статус, в котором мы фиксируем. Мы успешны
[01:29:03.840 --> 01:29:14.080]  или мы провалились? Это такая, это локальные переменные пока. Вот наш прогресс. Идем по ячейкам,
[01:29:14.080 --> 01:29:19.680]  ну и пока операция успешна. Если операция провалилась, то зачем идти по остальным? Идем по ячейкам,
[01:29:19.680 --> 01:29:29.280]  берем текущие, идем по ячейкам, берем текущую, которая нас интересует, и вот с помощью такой
[01:29:29.280 --> 01:29:35.600]  операции, то есть пока с помощью CAS можно считать. Пытаемся переключить ячейку с адресом вот таким
[01:29:35.600 --> 01:29:43.360]  вот, с старого значения, с ожидаемого значения, на дескриптор. Если получилось, то идем дальше.
[01:29:43.360 --> 01:29:57.360]  Вернее как, мы пытаемся переключить и смотрим, что в ячейке было до. Вот если, скажем, там было
[01:29:57.360 --> 01:30:03.480]  что-то другое, постороннее, не то, что мы ожидали, то мы операцию фейлим. Просто там было какое-то
[01:30:03.480 --> 01:30:16.480]  странное значение. А может быть, там был дескриптор? Тут есть разные варианты. Возможно,
[01:30:16.480 --> 01:30:23.320]  это дескриптор чужой. Было бы естественно, да? Мы лочили ячейки, увидели чужой дескриптор,
[01:30:23.320 --> 01:30:30.680]  чужой лог. Что делать? Ну, нужно помочь. Мы просто запускаем его CAS. Просто сначала,
[01:30:30.720 --> 01:30:39.240]  с чистого листа. И у нас есть все аргументы. Это просто сам дескриптор. Мы просто стартуем,
[01:30:39.240 --> 01:30:42.720]  ну, продолжаем. Не то, что продолжаем. Мы вот начинаем параллельно чужую операцию.
[01:30:42.720 --> 01:30:58.160]  С первой фазы. По очереди берем все блокировки. А что, если это наш дескриптор? Что? А почему,
[01:30:58.160 --> 01:31:01.840]  вообще, наш дескриптор оказался там? То есть, мы пытались в ячейку записать свой дескриптор,
[01:31:01.840 --> 01:31:08.360]  а там уже наш дескриптор. Но может быть, у нас было пять ячейек. Мы поставили в первые две там
[01:31:08.360 --> 01:31:13.240]  свои дескрипторы. Мы пересеклись по ячейкам с какой-то другой операцией CAS и ей помешали,
[01:31:13.240 --> 01:31:21.560]  и она начала вам помогать и прошла дальше нас. И вот мы увидели, как бы, что нам, мы уже забежали
[01:31:21.560 --> 01:31:25.800]  вперед. Так что такое тоже могло быть, но это, кажется, не беда. Нас то устраивает.
[01:31:25.800 --> 01:31:33.480]  И, допустим, мы доходим до конца этого цикла успешно. Ну, либо с провалом, либо с успехом,
[01:31:33.480 --> 01:31:38.480]  либо мы доходим до конца с успехом. То есть, мы сравнили все ячейки, повесили все локи. Либо
[01:31:38.480 --> 01:31:44.800]  мы где-то провалились. Ну, тогда выходим раньше. И вот момент истины. Мы должны зафиксировать в
[01:31:44.800 --> 01:31:53.400]  дескрипторе статус операции. Но почему-то мы делаем это с помощью CAS. То есть, мы пишем в
[01:31:53.400 --> 01:32:04.160]  дескриптор статус, текущий свой статус, как мы его понимаем. Но CAS, то есть, видимо, возможно
[01:32:04.160 --> 01:32:09.520]  такой сценарий, когда один поток хочет записать в дескриптор одной операции успех, а другое
[01:32:09.520 --> 01:32:16.800]  поражение. Может такое быть? Ну, ответ может, да, я же об этом и говорю. Почему такое может быть?
[01:32:16.800 --> 01:32:24.680]  Ну, вот допустим, у вас было пять ячеек в CAS, и вот у вас было два потока, которые делали этот CAS.
[01:32:24.680 --> 01:32:32.400]  Ну, то есть, один делал, а другой помогал. И вот они прошли по первым четырем ячейкам успешно. И вот
[01:32:32.400 --> 01:32:41.440]  есть пятая ячейка. И поток V, который начал эту операцию, читает, выполняет CAS на последней пятой
[01:32:41.440 --> 01:32:48.080]  ячейке. Ожидает там старое значение, хочет туда поставить блокировку, дескриптор. Но нет, в ячейке
[01:32:48.080 --> 01:32:54.680]  другое значение, неправильное. И этот поток принимает решение, что операция должна зафейлиться.
[01:32:54.680 --> 01:33:03.440]  После этого запускается помощник, он тоже смотрит на пятую ячейку, но когда он на нее смотрит,
[01:33:03.440 --> 01:33:11.800]  ячейка уже поменялась и стала правильной. Ну и все, у второго потока помощника есть момент времени,
[01:33:11.800 --> 01:33:18.360]  когда он видел все пять ячеек в правильном состоянии. И он туда инсталирует дескриптор и хочет
[01:33:18.360 --> 01:33:26.960]  автомарно переключиться теперь, и хочет признать CAS успешно. Ну, то есть, у нас есть как бы две
[01:33:26.960 --> 01:33:37.360]  точки зрения на успешность одной и той же операции CAS. У первого потока есть свидетельство того,
[01:33:37.360 --> 01:33:42.320]  что одна ячейка была в неправильном состоянии, и CAS провален, а другой поток считает, что его
[01:33:42.320 --> 01:33:48.160]  все устраивает, нужно, ну как бы он залучил все ячейки, можно переключиться на успех. И вот просто
[01:33:48.160 --> 01:33:52.640]  они соревнуются, то есть они оба правы, то есть оба ответа валидные, просто в разные моменты
[01:33:52.640 --> 01:33:58.840]  времени. И они с помощью CAS, с помощью консенсуса, про который мы не говорили, решают, кто победит из них,
[01:33:58.840 --> 01:34:08.040]  чье решение будет, чье решение войдет в историю в итоге. Вот они это делают, а потом читают этот
[01:34:08.040 --> 01:34:16.960]  статус и вот узнают, кто же победил. А дальше идут просто по ячейкам на второй фазе и либо накатывают,
[01:34:16.960 --> 01:34:21.880]  либо откатывают. То есть они опираются не на свое решение, а на вот решение консенсуса.
[01:34:21.880 --> 01:34:30.600]  Да, ну у нас была просто локальная переменная, а вот теперь они смотрят на глобальную перемену,
[01:34:30.600 --> 01:34:36.160]  которую писали, это важно. Мы сначала сюда пытаемся записать условно, если еще не записано,
[01:34:36.160 --> 01:34:46.520]  а потом смотрим на принятое решение. Вот, вопрос, а почему не бывает такого, что у нас поток
[01:34:46.600 --> 01:34:56.200]  повесил все локи, успешно установил CAS, заснул на месяц, просыпается и начинает писать что-то в ячейке?
[01:34:56.200 --> 01:35:10.880]  А? Ну нет, это не страшно, он не сможет, потому что дискриптора там уже не будет, я вру. Давайте
[01:35:10.880 --> 01:35:17.640]  по-другому. Вот у нас поток делал CAS, он ставил дискрипторы на ячейке, поставил три из пяти,
[01:35:17.640 --> 01:35:25.480]  и вот тогда заснул на месяц. Просыпается, идет по остальным ячейкам, четвертый, пятый, и вот все
[01:35:25.480 --> 01:35:39.560]  уже давно не валидно, да? А он пытается поставить на них дискрипторы. Ерунда получится. Почему он
[01:35:39.560 --> 01:35:47.120]  считал, что... что? Почему он сферится? Он не сферится. Он посмотрит на четвертую и на пятую, спустя месяц
[01:35:47.120 --> 01:35:57.320]  у них будут правильные значения, он запишет два дискриптора. Ну не важно, но какая разница? Он
[01:35:57.320 --> 01:36:03.120]  увидит здесь успешный... он сделает здесь CAS, увидит в дискрипторе успех и перезапишет ячейки,
[01:36:03.120 --> 01:36:09.000]  которые уже давно перезаписаны. Ну там первые три он не тронет, потому что уже нет дискрипторов,
[01:36:09.000 --> 01:36:23.200]  а вот четвертую и пятую перезапишет. Хотя это бессмыслится. Нет, когда он пошел спать,
[01:36:23.200 --> 01:36:30.240]  он еще даже не посмотрел на две ячейки. У нас было пять ячейок, там ожидали нули. Вот он взял
[01:36:30.240 --> 01:36:36.960]  локи на первые три, заснул на месяц. За это время кто-то увидел эти локи, докатил операцию до конца,
[01:36:36.960 --> 01:36:43.200]  перезаписал все нули на все единицы, а потом какой-то другой CAS откатил обратно единицы в нули. И вот мы
[01:36:43.200 --> 01:36:48.200]  просыпаемся через месяц и читаем четвертую ячейку, там ноль, читаем пятую ячейку, там ноль. Ну то есть
[01:36:48.200 --> 01:36:55.680]  локи там вешаем, дискрипторы вешаем, получаем две блокировки, выполняем CAS на статусе, получаем
[01:36:55.680 --> 01:37:04.520]  успех, потому что там уже был успех, и четвертую и пятую ячейку перезаписываем в ноль. Ой, в единицу,
[01:37:04.520 --> 01:37:18.320]  простите. Понятно проблема? Ответ такой, а где мы использовали CSS? Просто было бы странно,
[01:37:18.320 --> 01:37:24.640]  что мы... Вот мы используем его ровно здесь. Мы не просто CAS делаем, я говорю CAS, потому что так
[01:37:24.640 --> 01:37:32.240]  проще, но мы делаем условный CAS, то есть мы вешаем дискриптор на ячейку с адресом addr, не только если
[01:37:32.240 --> 01:37:39.240]  там старые значения, а если еще статус не установлен. И вот нам вот поэтому нужна была вторая
[01:37:39.240 --> 01:37:46.360]  вспомогательная операция. Нам нужно сделать CAS дважды условной, с одной стороны, по содержимому
[01:37:46.360 --> 01:37:52.760]  ячейки текущей, а с другой стороны, по статусу операции. То есть если хотя бы один поток дошел
[01:37:52.760 --> 01:37:59.640]  до этой строчки и выполнил ее, и может находиться на второй фазе, на первой фазе уже ни одного дискриптора
[01:37:59.640 --> 01:38:11.000]  не повесит. И это очень важно. Вот только вот на этом все и держится, вот на этом restrict double
[01:38:11.000 --> 01:38:21.640]  compare single swap. Ну что, мне кажется, что мы отрубились, да? Это все очень просто. У нас есть контрольный
[01:38:21.640 --> 01:38:26.480]  флажок, который говорит, операция CAS успешна или нет, и мы идем вешаем дискрипторы, а если CAS уже
[01:38:26.520 --> 01:38:30.800]  завершился каким-то потоком, то мы дискрипторы перестанем вешать, потому что они могут быть уже
[01:38:30.800 --> 01:38:38.280]  невалидны. Что? Ну нам пришлось сделать управление памятью.
[01:38:38.280 --> 01:38:44.720]  Дискриптор на куче хранится, почему у нас теки-то?
[01:38:58.720 --> 01:38:59.520]  Повтори, пожалуйста, еще раз.
[01:39:08.280 --> 01:39:18.200]  Никакой поток не сможет повесить ни одного дискриптора, да. Потому что это уже может быть не актуально,
[01:39:18.200 --> 01:39:25.960]  операция могла уже завершиться. Это точка коммита. И на самом деле, ну это вот сейчас, на самом деле,
[01:39:25.960 --> 01:39:31.560]  реклама осеннего курса, потому что вот этот алгоритм, это что по сути? Ну вот я рассказал вам,
[01:39:31.560 --> 01:39:36.680]  все, конец. Ну тут еще есть операция read, потому что когда у нас в яче как дискрипторы, это просто так
[01:39:36.840 --> 01:39:41.960]  читать чеку нельзя уже. Нужно от дискриптов тоже избавляться. Поэтому у нас иногда операция
[01:39:41.960 --> 01:39:51.400]  чтения делает CASN, а под капотом вот эта операция иногда делает, ну короче, ладно. Это все, какая-то
[01:39:51.400 --> 01:39:58.600]  уже машинерия мелкая начинается. Вот двухфазный алгоритм. Сначала вешаем все локи, а потом, ну вешаем
[01:39:58.600 --> 01:40:05.800]  локи, которые можно снять и докатить или откатить. И потом, если повесили все вот такие локи, то можем
[01:40:06.040 --> 01:40:11.880]  выполнить вторую фазу. И вот здесь есть, и с одной стороны, да, вот мы закончили эту историю про локфри канал
[01:40:11.880 --> 01:40:16.520]  и селектор, для которого требовался мультикасс, а с другой стороны, вот совершенно не связан,
[01:40:16.520 --> 01:40:23.080]  например, эта история, но очень в тему. Есть такая распределенная система Bigtable называется. Ее
[01:40:23.080 --> 01:40:28.120]  придумали, написали в Google, начали в 2000-х. Это такое масштабируемое, согласованное киеволью
[01:40:28.120 --> 01:40:35.320]  хранилище. Такое огромное, огромное отображение исключения значения. Автоматически шардируемое,
[01:40:35.320 --> 01:40:41.640]  то есть оно может расширяться по машинам бесконечно, ну да. Представляется себе такую таблицу,
[01:40:41.640 --> 01:40:48.400]  но без особых, без особо сложной функциональности. В частности, это не база данных, потому что в
[01:40:48.400 --> 01:40:54.080]  Bigtable нет транзакций. В Bigtable есть только транзакции однострочные, то есть можно
[01:40:54.080 --> 01:41:00.120]  атомарно посмотреть на поля, на колонки одной строчки, там что-то поменять, но нельзя атомарно
[01:41:00.120 --> 01:41:08.600]  потрогать строчки для разных ключей. Так вот, почему я об этом говорю? Потому что вот этот алгоритм,
[01:41:08.600 --> 01:41:13.080]  это по сути, вот этот алгоритм, это по сути транзакция. Такой ограниченный,
[01:41:13.080 --> 01:41:20.400]  некоторая специальная транзакция. У нас есть n ячеек, и мы сравнили их с ожидаемыми значениями и
[01:41:20.400 --> 01:41:27.200]  перезаписали. Ну транзакции — это более общее явление. Мы хотим просто атомарно посмотреть на какие-то
[01:41:27.600 --> 01:41:32.240]  строчки таблиц на какие-то ячеек памяти и там что-то с ними сделать произвольным образом.
[01:41:32.240 --> 01:41:36.680]  Ну вот в интере пытались сделать аппаратные транзакции, кажется сейчас отказываются от этой
[01:41:36.680 --> 01:41:42.600]  идеи. Это была хорошая идея, вроде бы красивая, простая, но вот почему-то не получилось. Так вот,
[01:41:42.600 --> 01:41:49.680]  в распределённых системах и в распределённых данных частности транзакции — это очень важное
[01:41:49.680 --> 01:41:59.240]  явление. И вот про транзакции поверх Bigtable есть отдельная статья, которую мы осенью разберём,
[01:41:59.240 --> 01:42:05.520]  наверное. И там мотивация такая. Вот мы пишем такой поисковый паук, который обходит интернет,
[01:42:05.520 --> 01:42:14.680]  и он в Bigtable фиксирует, во-первых, документы, ну вот урлы, которые он обходил. Во-вторых,
[01:42:14.680 --> 01:42:22.600]  он для некоторых урлов фиксирует... Ну, у нас есть документы, они адресуются урлам,
[01:42:22.600 --> 01:42:29.760]  и может быть два урла на один тот же документ, и нужно вообще находить дубликаты. Вот мы вычислим
[01:42:29.760 --> 01:42:38.080]  хэш и можем для каждого, для хэша иметь некоторые канонические урлы. Ну, нам не нужны остальные,
[01:42:38.080 --> 01:42:46.280]  грубо говоря. Короче, неважно, забудьте это всё. Мы обходим интернет, и мы хотим на, там,
[01:42:46.280 --> 01:42:54.480]  тысячах, десятках тысяч машин обновлять вот такую большую таблицу, где трогать одновременно
[01:42:54.480 --> 01:43:04.560]  записи, что вот есть такой урл с таким документом, с таким хэшом, и есть и отображение обратное из
[01:43:04.560 --> 01:43:12.120]  хэшей в, там, урлы. Ну, то есть трогать несколько ячеек, несколько строчек гигантские таблицы. Вот.
[01:43:12.120 --> 01:43:18.120]  А, к сожалению, бектейвл, с которым мы работаем, такого API не даёт нам. У него есть только транзакции
[01:43:18.120 --> 01:43:24.560]  на одной строчке. А транзакции на одной строчке — это что-то нечто похожее на касс. И вот мы хотим
[01:43:24.560 --> 01:43:31.560]  выполнить транзакции над разными строчками, имея только транзакции на одной строчке. Причём в
[01:43:31.560 --> 01:43:37.320]  системе транзакций нет, поэтому мы хотим, чтобы делал клиент. А клиент же, он может отказать,
[01:43:37.320 --> 01:43:43.720]  то есть машина, которая делает транзакции, может разломаться. И на что это похоже? Это похоже на
[01:43:43.720 --> 01:43:47.560]  лог-фри. Ну, точнее, не это похоже на лог-фри, а лог-фри — это просто отказоустойчивость,
[01:43:47.560 --> 01:43:52.160]  которую перенесли в shared memory, в компьютер. И вот Google, значит, изобретает протокол, который
[01:43:52.160 --> 01:44:00.680]  выполняет client-site лог-фри транзакции. И вот смотрите, она здесь в комите транзакций,
[01:44:00.680 --> 01:44:07.880]  двухфазный комит. Мы сначала трогаем n ячеек, берём на них локи, потом атомарно трогаем одну из них,
[01:44:07.880 --> 01:44:16.400]  это вот, собственно, вот этот шаг. А потом либо накатываем, либо откатываем. Ну, то есть стираем
[01:44:16.400 --> 01:44:22.840]  локи и пишем значение. Вот одна и та же задача, один и тот же алгоритм, по сути. Но никакой связи
[01:44:22.840 --> 01:44:27.800]  между статями нет. Просто два разных мира. Google, который строит гигантские распределённые системы,
[01:44:27.800 --> 01:44:33.640]  и люди, которые выдумывают странные лог-фри алгоритмы. Но задача одна и та же, поэтому вот люди в
[01:44:33.640 --> 01:44:41.920]  разных местах выдумали одно и то же абсолютно. И вот кому-то касс, такой мульти-касс пригодился
[01:44:41.920 --> 01:44:47.160]  для того, чтобы сделать селект на лог-фри каналах, лог-фри селект на лог-фри каналах, кому-то
[01:44:47.160 --> 01:44:54.440]  пригодился для того, чтобы обходить интернет. Но вот в обоих случаях алгоритм, в общем, довольно
[01:44:54.440 --> 01:45:08.200]  полезный оказался. Хоть и выглядит довольно, ну, таким азотерически. Ну что ж, на этой торжественной,
[01:45:08.200 --> 01:45:18.360]  грустной и радостной ноте мы, наверное, подводим к концу наше занятие, наш семестр. Да. Да, можно.
[01:45:24.440 --> 01:45:38.880]  Да. А результат просто содержимый ячейки А2. Нам не важен результат.
[01:45:38.880 --> 01:45:49.080]  То есть нам не важно, была ли запись. Вообще не важно. Ну потому что вот, смотри, мы пытаемся
[01:45:49.080 --> 01:46:00.400]  повесить дескриптор. Если статус установили, то все операции будут неуспешными. Нужно ли нам
[01:46:00.400 --> 01:46:09.560]  об этом знать прямо сейчас от Амарны? Не особо. Просто если статус установлен уже в дескрипторе,
[01:46:09.560 --> 01:46:21.040]  то ни один RDCSS, то есть ни один CAS, не навесит на ячейку дескриптор. Вот и все. Ну про
[01:46:21.040 --> 01:46:26.520]  ее самой, говорить очень сложно, потому что она не имеет самостоятельного смысла большого. Но давай
[01:46:26.520 --> 01:46:33.760]  еще раз спроси. Вот мы не пытаемся понять, была ли операция успешной. Мы выполняем эту операцию,
[01:46:33.760 --> 01:46:41.320]  и если в А2 была О2, а в А1 была О1, то значение будет перезаписано. И операция вернет то,
[01:46:41.320 --> 01:46:48.400]  что она прочитала из А2. И вот мы только это и используем в мультикасе. Вот такая странная
[01:46:48.400 --> 01:47:02.240]  операция, но вот такой мультикасу достаточно. Мне кажется, в ней ничего такого сложного нет,
[01:47:02.240 --> 01:47:09.720]  она очень прямолинейная и такая странная. Вот рассматривать ее в изоляции сложно,
[01:47:09.720 --> 01:47:15.840]  потому что хочется увидеть, как она работает в общем алгоритме. А там она работает, ну по сути,
[01:47:15.840 --> 01:47:20.680]  как CAS. То есть это такой обычный CAS, как будто бы, который вешает на ячейку с адресом other
[01:47:20.680 --> 01:47:26.780]  дескриптор при условии, что там лежит значение alt сейчас, но только если никакой поток не
[01:47:26.780 --> 01:47:50.940]  дошел до сюда. Вот и все. Вот ее назначение. Не знаю. Не понимаю. Нет, не получилось объяснить?
[01:47:50.940 --> 01:48:05.500]  Как реализован что? Мы повесили, смотри, вот мы находимся в состоянии, вот картинка. Вот мы
[01:48:05.500 --> 01:48:12.380]  в таком состоянии. Это означает, что в ячейке Y было ожидаемое значение. Какое? Смотри здесь,
[01:48:12.380 --> 01:48:23.280]  по ссылке. В ячейке X находится A бы что, и задача complete из этого состояния перейти либо сюда
[01:48:23.280 --> 01:48:32.800]  записать C, либо сюда записать B. То есть либо докатить операцию, либо откатить. Сравнив содержимое
[01:48:32.800 --> 01:48:40.280]  ячейки X с ожидаемым. И вот мы повесили дескриптор. Если повесился, то значит в ячейке Y было
[01:48:40.280 --> 01:48:46.860]  B. А дальше мы спокойно читаем ячейку X, потому что мы знаем, что вот так просто дескриптор не
[01:48:46.860 --> 01:48:54.340]  выбросит. Так просто ячейку Y не поменяют. Мы читаем ячейку X, сравниваем его с A, содержимое
[01:48:54.340 --> 01:49:03.060]  с A. Если совпало, то переключаем Y с дескриптора на C. Если не совпало, то переключаем Y с дескриптора
[01:49:03.100 --> 01:49:17.840]  на B. Вот код. Вот он. У нас есть фаза. То есть мы берем блокировку по сути на ячейку A2,
[01:49:17.840 --> 01:49:26.200]  а потом спокойно смотрим на A1 и принимаем решение. Ну как?
[01:49:33.060 --> 01:49:50.040]  Ну тогда уже тут не будет дескриптора. Мы же докатываем относительно D. То есть мы
[01:49:50.040 --> 01:49:57.120]  пишем N2 в A2, только если там до сих пор был дескриптор, то есть другой поток операцию завершить
[01:49:57.120 --> 01:50:11.740]  не мог в это время. То есть ячейка была замороженная. У нас в дескрипторе есть все операции, есть все
[01:50:11.740 --> 01:50:14.340]  нужное, все необходимое, чтобы операцию завершить, в том числе чужую.
[01:50:14.340 --> 01:50:31.540]  Здесь? Так. Могут поменять, но это неважно. Мы знаем, что был момент, когда в ячейке A2
[01:50:31.540 --> 01:50:40.140]  находилось O2, а в ячейке A1 находился O1. Нам неважно, что нам может поменяться. Нам важно,
[01:50:40.140 --> 01:50:53.300]  что был момент, когда операция могла примениться. Понимаешь? То есть просто был момент и все.
[01:50:53.300 --> 01:51:00.140]  Посмотрели как будто бы атомарно на две ячейки. То есть мы посмотрели не атомарно, мы сначала
[01:51:00.140 --> 01:51:10.700]  посмотрели на A2, потом мы сначала посмотрели на A2, потом посмотрели на A1, а потом, если между
[01:51:10.700 --> 01:51:19.580]  чтением A2 и A1 не было других записей, а мы это поняли вот так вот с помощью этого касса, то мы
[01:51:19.580 --> 01:51:26.860]  переключили A2 в новое значение. То есть вот эта проверка, как будто бы, по сути, проверка
[01:51:26.860 --> 01:51:41.500]  атомарности чтений. Все, один больше не нужно, да. Вот. Ну, эта операция, еще раз повторю, она имеет
[01:51:41.500 --> 01:51:46.220]  довольно странную семантику, не интуитивную, потому что она нужна вот в таком алгоритме.
[01:51:46.220 --> 01:51:51.900]  Сделать касс обычный с дополнительным условием, если вся операция еще не завершена. Чтобы там
[01:51:51.900 --> 01:51:57.540]  у нас какой-то заснувший надолго поток не мог делать первую фазу, когда другие делают вторую фазу.
[01:51:57.540 --> 01:52:02.220]  Или уже сделали вторую фазу. То есть фазы не пересекаются во времени уж точно. Ну, в смысле,
[01:52:02.220 --> 01:52:06.780]  не пересекаются по своим эффектам. Если кто-то делает записи на второй фазе, то на первой
[01:52:06.780 --> 01:52:18.340]  фазе записи быть уже не может. Хватит с нашего мультикасса. Ну, кажется, бонусный уровень был.
[01:52:18.340 --> 01:52:27.740]  Я не рассчитываю, конечно, что кто-то напишет мультикасс в селекции, хотя это было бы впечатляюще.
[01:52:27.740 --> 01:52:33.460]  Было бы крайне впечатляюще. Но если вернуться к каналу, то мне кажется, что канал-то вот
[01:52:33.460 --> 01:52:39.460]  локфри можно написать. Это такое упражнение на очередь Майкла Скотта. Не сильно сложное. Но вот
[01:52:39.460 --> 01:52:45.540]  в самом деле тут псевдокод на страницу, и он довольно… он очень прямолинейный. То есть, в общем,
[01:52:45.540 --> 01:52:51.700]  тут очень простые и ловкие идеи, а всё остальное это просто проверки аккуратные, что мы находимся… мы
[01:52:51.700 --> 01:52:56.620]  понимаем сами, что происходит сейчас. Так что это можно написать, и можно это протестировать,
[01:52:56.620 --> 01:53:03.900]  и можно посмотреть, насколько это сделает ваш… ваши каналы, ваши файберы с хорошим планировщиком
[01:53:03.900 --> 01:53:12.660]  быстрее. Ну всё, спасибо большое, что пришли. Я очень рад, что вы захотели это послушать.
