[00:00.000 --> 00:08.920]  Так, ну, я еще раз формулирую теорему, собственно, Вапника
[00:08.920 --> 00:12.440]  и Червоненкеса, которую нам предстоит доказать.
[00:12.440 --> 00:25.020]  У нас есть пространство, размерность которого равняется
[00:25.020 --> 00:37.380]  Д, у нас есть Эпсилон из 0 и 1.
[00:37.380 --> 00:46.720]  Утверждается, что тогда для любого С из Х, ой, что
[00:46.720 --> 00:57.240]  уж такое-то, из Х мощности меньше бесконечности, существует
[00:57.240 --> 01:11.360]  Эпсилон сеть размера не больше, чем верхняя целая
[01:11.360 --> 01:17.900]  часть от 8D поделить на Эпсилон, лог двоичный 8D поделить
[01:17.900 --> 01:18.900]  на Эпсилон.
[01:18.900 --> 01:23.160]  Вот такое утверждение, правильно, совпадает с тем, что я говорил
[01:23.160 --> 01:28.240]  в прошлый раз?
[01:28.240 --> 01:30.840]  Не равна D, а не больше D, но это не важно, конечно,
[01:30.840 --> 01:32.640]  да, потому что важно только, что она не превосходит
[01:32.640 --> 01:33.640]  чего-то.
[01:33.640 --> 01:38.600]  Могу сказать не больше, это не имеет значения.
[01:38.600 --> 01:43.520]  Так, ну, я не помню, уже обводил я вот это обозначение
[01:43.520 --> 01:46.360]  или нет, пусть буквой М обозначается эта верхняя
[01:46.360 --> 01:47.360]  целая часть.
[01:47.360 --> 01:50.120]  На самом деле, я выкладки подробные с этой целой частью
[01:50.120 --> 01:53.000]  проводить не буду, там все будет понятно и так, но
[01:53.000 --> 01:56.680]  неважно, это пусть будет для краткости М.
[01:56.680 --> 01:59.760]  Доказывать теорему мы будем вероятностным методом.
[01:59.760 --> 02:13.960]  Так, давайте пусть N, это мощность нашего S, оно конечное,
[02:13.960 --> 02:14.960]  в нем N элементов.
[02:14.960 --> 02:19.960]  И давайте будем строить, ну, Эпсилон-сеть, откуда выбирается
[02:19.960 --> 02:23.640]  из S, правда же, потому что что мы делаем?
[02:23.640 --> 02:28.200]  Мы пересекаем R маленький с каким-то с этим S, рассматриваем
[02:28.200 --> 02:31.920]  проекцию R большого на вот это множество S, пересекаем
[02:31.920 --> 02:36.800]  R маленький из R большого с этим S и пытаемся, рассматривая
[02:36.800 --> 02:41.280]  вот такие вот, только пытаемся найти для вот этих подмножек
[02:41.280 --> 02:42.520]  систему общих представителей.
[02:42.520 --> 02:49.120]  Ну, давайте ее выберем случайным образом.
[02:49.120 --> 02:53.840]  Как видите, ну, что надо здесь подчеркнуть, когда
[02:53.840 --> 02:57.880]  мы с вами работали с общим случаем системы представителей,
[02:57.880 --> 03:02.000]  мы верхние оценки делали жадным алгоритмом, и только
[03:02.000 --> 03:05.280]  для нижних оценок вероятностный метод работал интересным
[03:05.280 --> 03:06.280]  образом.
[03:06.280 --> 03:08.800]  Здесь мы делаем верхнюю оценку размера минимальной
[03:08.800 --> 03:13.920]  SOP, которую называем Эпсилон-сетью, и для нее применяем вероятностный
[03:13.920 --> 03:14.920]  метод.
[03:14.920 --> 03:27.640]  Так, ну, вероятностный метод простейший, вытаскиваем
[03:27.640 --> 03:34.680]  из множества S, M элементов, ну, то, что называется с
[03:34.680 --> 03:36.120]  возвращением.
[03:36.120 --> 03:38.560]  Говорит вам о чем-нибудь такой термин или вам такой
[03:38.560 --> 03:39.560]  не употребляли?
[03:39.560 --> 03:43.760]  Ну, то есть, мы строим, как это называется, размещение
[03:43.760 --> 03:45.760]  с повторением случайное.
[03:45.760 --> 03:51.120]  Да, я говорил это слово на алкотече, но, может быть,
[03:51.120 --> 03:54.000]  я не всегда это делаю, да, мы берем, на алкотече точно
[03:54.000 --> 03:56.840]  было размещение с повторением, но, может быть, я действительно
[03:56.840 --> 03:59.560]  сказал на алкотече, что в вероятности вам употребляют
[03:59.560 --> 04:02.520]  термин с возвращением, и вам не употребили, а оно
[04:02.520 --> 04:05.640]  осталось так от меня, так от информации, ну, может
[04:05.640 --> 04:06.640]  быть, да.
[04:06.640 --> 04:09.400]  С возвращением это фактически значит, что мы строим размещение
[04:09.400 --> 04:12.280]  с повторением, то есть, мы вытаскиваем один элемент
[04:12.280 --> 04:15.200]  из S случайным образом с вероятностью единицы поделить
[04:15.200 --> 04:20.640]  на N, каждый конкретный получится, потом, как бы, укладываем
[04:20.640 --> 04:23.440]  его на место и снова из всего множества выбираем случайный
[04:23.440 --> 04:24.440]  элемент.
[04:24.440 --> 04:27.920]  То есть, то, что у нас получится, может получиться мультимножеством,
[04:27.920 --> 04:29.880]  размещением, да, с повторением.
[04:29.880 --> 04:38.440]  Ну, ничего страшного, нам же нужно маленькое множество,
[04:38.440 --> 04:40.800]  если какие-то элементы совпадут, мы их отрождествуем.
[04:40.800 --> 04:43.320]  Это же не должно кого-то смущать.
[04:43.320 --> 04:47.640]  В общем, давайте назовем то случайное мультимножество,
[04:47.640 --> 04:51.640]  которое у нас получится, буквой N.
[04:51.640 --> 04:54.320]  Если хотите, чтобы было предельно понятно, наверное,
[04:54.320 --> 04:57.720]  я так всегда и говорю, это вероятность просто равна
[04:57.720 --> 05:01.480]  1 поделить на N в m-т степени.
[05:01.480 --> 05:04.720]  Сколько есть всевозможных размещений с повторениями,
[05:04.720 --> 05:08.080]  ну, такова в минус первой степени будет вероятность,
[05:08.080 --> 05:11.080]  понятное дело.
[05:11.080 --> 05:14.040]  Наша цель доказать, что с положительной вероятностью
[05:14.040 --> 05:17.520]  вот такая вот штуковина является тем, что нам нужно,
[05:17.520 --> 05:21.680]  то есть, епсалон сетью.
[05:21.680 --> 05:31.600]  Можно N производить от слова net, ну, сеть, так, чтобы запоминалось
[05:31.600 --> 05:32.600]  лучше.
[05:32.600 --> 05:38.160]  Ну, давайте напишем плохое событие, назовем его E1.
[05:38.160 --> 05:41.800]  В чем состоит плохое событие?
[05:41.800 --> 05:44.080]  Событие – это множество элементарных исходов,
[05:44.080 --> 05:45.640]  элементарный исход – это епсалон сеть.
[05:45.840 --> 05:48.640]  То есть, мы все вот эти m-вытаскивания осуществили,
[05:48.640 --> 05:53.560]  получилось случайное элементарное событие N, а событие будет
[05:53.560 --> 06:00.560]  состоять в том, что для случайного множества N существует такое
[06:00.560 --> 06:05.760]  r маленькое из r большого, что оно как нужно пересекается
[06:05.760 --> 06:10.920]  с исходным s, то есть не меньше, чем по епсалон n, но в пересечении
[06:10.920 --> 06:13.800]  с n большим пусто, неприятностей.
[06:13.800 --> 06:19.800]  Так, согласитесь, что это плохое событие, то есть,
[06:19.800 --> 06:22.360]  наверное, наша цель – доказать, что его вероятность меньше
[06:22.360 --> 06:23.360]  единицы.
[06:23.360 --> 06:30.040]  Если вероятность E1 меньше единицы, то ура, мы победили.
[06:30.040 --> 06:33.840]  Существует такое n большое, такая епсалон сеть, что
[06:33.840 --> 06:34.840]  все хорошо.
[06:34.840 --> 06:39.520]  Так, ну, давайте, как ни странно, ведем вспомогательное
[06:39.520 --> 06:40.520]  событие.
[06:40.520 --> 06:43.880]  Это вот здесь наиболее интересный ход, которого нам еще не доводилось
[06:43.880 --> 06:46.640]  встречать, когда мы с вами изучали какие-то вероятностные
[06:46.640 --> 06:49.760]  методы, случайные графы, еще что-нибудь.
[06:49.760 --> 06:53.120]  Интересный ход ввести некую загадочную дополнительную
[06:53.120 --> 06:55.620]  случайность, но именно она сработает, если вы в целом
[06:55.620 --> 06:58.800]  охватите доказательства, а я постараюсь, то у вас
[06:58.800 --> 06:59.800]  будет катарсис.
[06:59.800 --> 07:06.040]  Не, не, сейчас все будет совершенно не мистично, конечно, просто
[07:06.040 --> 07:09.640]  я сейчас напишу явно, что такое E2.
[07:09.640 --> 07:11.880]  Загадочность будет состоять в том, как можно додуматься
[07:11.880 --> 07:14.760]  до того, чтобы вот ввести такую случайность и потом
[07:14.760 --> 07:16.920]  на этом сыграть, но я буду стараться по ходу дела это
[07:16.920 --> 07:17.920]  объяснить.
[07:17.920 --> 07:21.480]  Вот, короче, мы, смотрите, что делаем, мы берем и еще
[07:21.480 --> 07:26.120]  одно такое же мультимножество t строим, каким было n большое,
[07:26.120 --> 07:31.120]  то есть вероятность t, это опять 1 на n в mt, и снова выбираем
[07:31.120 --> 07:33.680]  случайное размещение с повторением просто с помощью
[07:33.680 --> 07:38.080]  возвращения элементов, никак не зависящий от того,
[07:38.080 --> 07:42.120]  как мы до того выбрали n, вот n большое выбрано,
[07:42.120 --> 07:47.280]  а мы еще берем m испытаний, m раз, вытаскиваем элементы,
[07:47.280 --> 07:52.720]  берем, получаем t, вот E2 это событие, которое естественно
[07:52.720 --> 07:55.680]  теперь уже состоит из пар множеств, мультимножеств
[07:55.680 --> 08:01.240]  n и t, пар мультимножеств n и t, таких, что существует
[08:01.240 --> 08:07.320]  r, пока все не загадочное, r пересеченное с s больше
[08:07.320 --> 08:13.320]  либо равно epsilon n, r пересеченное с n пусто, ну то есть ничего
[08:13.320 --> 08:19.040]  нового, но t же появилось, и вот тут вот, мощность
[08:19.040 --> 08:24.520]  r пересеченного с t больше либо равняется epsilon m пополам,
[08:24.520 --> 08:30.480]  вот это вот момент, который сейчас выглядит как загадочный,
[08:30.560 --> 08:33.520]  когда этого можно было додуматься, там вообще что это, зачем
[08:33.520 --> 08:38.960]  это, постепенно будем прояснять, то есть теперь в свете того,
[08:38.960 --> 08:42.360]  что у нас случайными объектами являются пары мультимножеств,
[08:42.360 --> 08:46.280]  пары размещений, мы конечно и E1 можем проинтерпретировать
[08:46.280 --> 08:50.680]  таким же Макаром, то есть тоже здесь написать n и t,
[08:50.680 --> 08:53.720]  но никаких условий на t просто тут не накладывается,
[08:53.720 --> 08:59.160]  t любое. Согласно, что можно считать, что события E1, E2 живут
[08:59.160 --> 09:03.760]  на одном и том же вероятностном пространстве, но просто в случае
[09:03.760 --> 09:07.440]  события E1, E2 не имеет никакого смысла, по тему пробегаем
[09:07.440 --> 09:10.360]  по всем возможным вариантам, никаких условий на него
[09:10.360 --> 09:13.960]  не накладывается, а в случае E2 мы налагаем вот это вот
[09:13.960 --> 09:16.720]  ограничение, которое пока действительно выглядит
[09:16.720 --> 09:22.920]  как нечто абсолютно загадочное, но скоро прояснится. Нет,
[09:22.920 --> 09:25.320]  я не стараюсь вам вскружить голову совсем, вы же меня
[09:25.360 --> 09:29.720]  поймите, но просто если бы я вот так написал и не предпослал
[09:29.720 --> 09:33.080]  этому вот этого кряка, там еще чего-то, то мне кажется,
[09:33.080 --> 09:34.920]  что вас действительно бы проканало и вы бы тогда
[09:34.920 --> 09:43.120]  крякнули, а я заранее крякнул, теперь все понятно. Нет,
[09:43.120 --> 09:45.120]  всегда что-нибудь новенькое, по-моему, я еще ни разу
[09:45.120 --> 09:51.560]  про кря не говорил. Так, ладно, вот такие два события,
[09:51.560 --> 09:55.480]  ну понятно, что из события E2 следует событие E1, оно
[09:55.480 --> 10:02.320]  просто вложено в него, то есть очевидно, что вероятность
[10:02.320 --> 10:09.760]  E2 меньше либо равна вероятности E1, но вот удобство состоит
[10:09.760 --> 10:12.560]  в том, что в обратную сторону оценка почти такая же, то
[10:12.560 --> 10:16.200]  есть вероятности этих событий близкие, но как мы узнаем
[10:16.200 --> 10:20.920]  еще позже, оценивать вероятность E2 гораздо проще за счет вот
[10:20.920 --> 10:23.400]  этого дополнительного условия, как оно сработает,
[10:23.400 --> 10:27.240]  мы позже узнаем. Идея была у товарищей, которые придумали
[10:27.240 --> 10:30.080]  такое доказательство, именно в этом, добавить некоторое
[10:30.080 --> 10:34.000]  дополнительное ограничение, чтобы вот это неравенство
[10:34.000 --> 10:40.560]  не слишком ухудшилось, но при этом использовать
[10:40.560 --> 10:46.680]  его потом для оценки вероятности. Так, LEMma1, я утверждаю, что
[10:46.680 --> 10:53.040]  вероятность E2 не меньше, чем 5 шестых, например,
[10:53.040 --> 10:57.720]  на вероятность E1. Можно здесь написать 1 вторую, этого
[10:57.720 --> 11:01.040]  тоже в итоге хватит, но мы докажем с 5 шестых, что
[11:01.040 --> 11:07.040]  же не написать 5 шестых. Вот это вот ровно то, что
[11:07.040 --> 11:10.440]  я сказал, с одной стороны очевидно, что E2 меньше,
[11:10.440 --> 11:14.320]  чем E1, с другой стороны не сильно меньше, и вот это
[11:14.480 --> 11:22.480]  помогает. Так, ну LEMma1 сейчас докажем. Давайте
[11:22.480 --> 11:31.480]  напишем E2 при условии E1, условную вероятность напишем.
[11:31.480 --> 11:36.080]  Ну это понятно, что такое, это вероятность E2 пересеченного
[11:36.080 --> 11:39.240]  с E1, по определению просто, поделить на вероятность
[11:39.240 --> 11:46.240]  E1. При этом пересечение E2, E1 это что? E2, правильно,
[11:46.240 --> 11:54.240]  это вероятность E2 поделить на вероятность E1. Ну, мы
[11:54.240 --> 11:56.840]  что хотим доказать, что это больше либо равно 5 шестых,
[11:56.840 --> 12:04.840]  правильно же. То есть цель теперь в рамках LEMma1 доказать,
[12:04.840 --> 12:11.840]  что вероятность E2 при условии E1 больше либо равна 5 шестых.
[12:11.840 --> 12:17.840]  Вот, ну на самом деле, если мы знаем, что выполнилось
[12:17.840 --> 12:21.840]  событие E1, то есть что уже нашелся такой R, который
[12:21.840 --> 12:26.840]  в пересечении с s не меньше, чем εn, и который с n большое
[12:26.840 --> 12:32.840]  пуст, то фактически вероятность чего мы считаем? Того, что
[12:32.840 --> 12:38.840]  R пересеченное с t не меньше, чем, правильно? То есть фактически
[12:38.840 --> 12:44.840]  интересующая нас условная вероятность, это есть просто
[12:44.840 --> 12:49.840]  вероятность того, что R пересеченное с t больше либо равняет
[12:49.840 --> 12:58.840]  цепсалон m по полу. Так, друзья, тут вот очень важный
[12:58.840 --> 13:01.840]  момент, которого вы не отследили, никто не спросил,
[13:01.840 --> 13:05.840]  а я не сказал. Поскольку множество t большое равно,
[13:05.840 --> 13:09.840]  как и множество n большое, мы выбираем с кратностями
[13:09.840 --> 13:15.840]  возможными, элементы могут повторяться, то мощность
[13:15.840 --> 13:21.840]  мы считаем ровно в таком же смысле. То есть мы вытягиваем
[13:21.840 --> 13:25.840]  очередной элемент и записываем единичку, если он содержится
[13:25.840 --> 13:29.840]  в R и ноль, если не содержится. Поэтому повторяющиеся
[13:29.840 --> 13:31.840]  элементы мы учитываем столько раз, сколько они туда
[13:31.840 --> 13:37.840]  попадают. Вот эта мощность, это не мощность множества,
[13:37.840 --> 13:40.840]  а мощность мультимножества тоже. Это очень важно для
[13:40.840 --> 13:43.840]  себя пометить, иначе нам будет крайне трудно считать,
[13:43.840 --> 13:46.840]  но мы воспринимаем это именно так. То есть это пометить
[13:46.840 --> 13:49.840]  можно было еще вот здесь, но я забыл про это сказать,
[13:49.840 --> 13:58.840]  а вы не спросили. Сейчас я быстро говорю, что ли, товарищи?
[13:58.840 --> 14:04.840]  Да-да-да, я думаю, что в этот момент действительно вам
[14:04.840 --> 14:08.840]  трудно было это отследить. Это надо было сообразить
[14:08.840 --> 14:11.840]  прям, как это должно было, такая молния. Слушайте, а как
[14:11.840 --> 14:13.840]  вы понимаете мощность, если множество с кратностями?
[14:13.840 --> 14:17.840]  Вот так понимаю. Забыл про это сказать, прошу прощения,
[14:17.840 --> 14:19.840]  но вы себе это обязательно пометите, это очень важно.
[14:19.840 --> 14:22.840]  Как раз это позволит нам легко считать вот здесь все.
[14:22.840 --> 14:25.840]  Потому что давайте я картину нарисую, стандартную
[14:25.840 --> 14:28.840]  сардельку условную, это в данном случае множество
[14:28.840 --> 14:39.840]  s, который у нас имеет мощность n. Мы пересекаем r с s,
[14:39.840 --> 14:44.840]  вот это r с r наше, вот есть какое-то пересечение.
[14:44.840 --> 14:47.840]  Какое это пересечение? Оно мощности не меньше, чем
[14:47.840 --> 14:53.840]  εn по условию, правильно? Вот здесь вот не меньше,
[14:53.840 --> 15:00.840]  чем ε умножить на n элементов. То есть когда мы выбираем
[15:00.840 --> 15:04.840]  очередной элемент при построении множества t большое,
[15:04.840 --> 15:09.840]  он попадает в эту заштрихованную часть с вероятностью не
[15:09.840 --> 15:17.840]  меньше, чем что. Я все подсказал, я сказал не меньше, чем что.
[15:17.840 --> 15:22.840]  Когда мы строим множество t, мы выбираем его из всего s.
[15:22.840 --> 15:25.840]  Мы каждый очередной его элемент выбираем из множества s
[15:25.840 --> 15:31.840]  с вероятностью 1 поделить на n. С какой вероятностью
[15:31.840 --> 15:37.840]  этот элемент оказывается в пересечении r и s? Ну и
[15:37.840 --> 15:46.840]  ε конечно, тут же εn элементов. Давайте я это словами напишу.
[15:46.840 --> 16:06.840]  Каждый элемент из t попадает в r пересеченное с s с вероятностью
[16:06.840 --> 16:16.840]  не меньше, чем ε. Следовательно, вот это пересечение
[16:16.840 --> 16:24.840]  и его мощность, это биномиальная случайная величина
[16:24.840 --> 16:34.840]  вида бином, я не знаю, как вам обозначали, я обычно
[16:34.840 --> 16:42.840]  целиком слово пишу. Вот м, это число испытаний, сколько
[16:42.840 --> 16:47.840]  раз мы вытаскиваем элементы очередной, столько элементов
[16:47.840 --> 16:53.840]  в множестве t и не меньше, чем ε. Число испытаний и
[16:53.840 --> 16:59.840]  вероятность успеха. Успех попали в пересечение r и t,
[16:59.840 --> 17:05.840]  неудача не попали. Т попало в r пересеченное с с или не
[17:05.840 --> 17:11.840]  попало в r пересеченное с с? Успех неудача. И мы м раз
[17:11.840 --> 17:14.840]  бросаем монетку, каждый раз просто проверяем, попало
[17:14.840 --> 17:17.840]  не попало, попало не попало. Сколько раз попало, такова
[17:17.840 --> 17:23.840]  и мощность. Я нормально объясняю, да? Вот это биномиальная
[17:23.840 --> 17:26.840]  случайная величина вот с таким распределением. Ну
[17:26.840 --> 17:30.840]  значит, вероятность того, что она не меньше чего-то,
[17:30.840 --> 17:37.840]  не меньше, чем вероятность того, что бином от м и просто
[17:37.840 --> 17:43.840]  в точности, ε, больше либо равняется того же. Я просто
[17:43.840 --> 17:47.840]  занизил вероятность успеха, если вероятность успеха
[17:47.840 --> 17:52.840]  уменьшить, то и вся вероятность только уменьшится. Вероятность,
[17:52.840 --> 17:55.840]  что успехов будет много, тем меньше, чем меньше
[17:55.840 --> 17:59.840]  чем меньше вероятность успеха, вот так надо сказать.
[17:59.840 --> 18:05.840]  Их много нам нужно, но я занизил и получил неравенство в ту сторону, как мне надо,
[18:05.840 --> 18:11.840]  потому что я 5 шестых доказываю, видите, 5 шестых хочу доказать.
[18:11.840 --> 18:16.840]  Так, ну, слушайте, бином, атем и апсилон как-то много букв.
[18:16.840 --> 18:21.840]  Давайте я буквы это обозначу.
[18:21.840 --> 18:25.840]  Так, к чему равняется математическое ожидание это, товарищи?
[18:25.840 --> 18:27.840]  Но это, я надеюсь, все понимают.
[18:27.840 --> 18:32.840]  Ну, ответьте мне, пожалуйста, это имеет биномиальное распределение.
[18:32.840 --> 18:35.840]  Немо-спытание, апсилон, вероятность успеха.
[18:35.840 --> 18:38.840]  Какое мат ожидания?
[18:38.840 --> 18:40.840]  Скажите, пожалуйста.
[18:40.840 --> 18:43.840]  Забыли, что ли?
[18:43.840 --> 18:47.840]  А линейность слабо?
[18:47.840 --> 18:49.840]  Сколько?
[18:49.840 --> 18:51.840]  Эпсилон М, конечно.
[18:51.840 --> 18:53.840]  Ну, товарищи, ну что ж такое безобразие?
[18:53.840 --> 18:57.840]  Ну, М раз бросаем монетку, 0 или единица, неудача или успех.
[18:57.840 --> 19:00.840]  По линейности, апсилон М, конечно.
[19:00.840 --> 19:02.840]  Ну, давайте я напишу вот так.
[19:02.840 --> 19:09.840]  Вероятность того, что это минус мат ожидания это больше либо равняется
[19:09.840 --> 19:17.840]  Эпсилон М пополам минус мат ожидания это равняется вероятность это
[19:17.840 --> 19:24.840]  минус мат ожидания это больше либо равняется минус Эпсилон М пополам.
[19:24.840 --> 19:27.840]  Потому что это это Эпсилон М.
[19:27.840 --> 19:31.840]  Здесь я сохранил обозначение, ну, конечно, это Эпсилон М.
[19:31.840 --> 19:35.840]  А здесь вот вычел, честно.
[19:35.840 --> 19:38.840]  Я хочу к неравенству Чебышова все это дело свести, товарищи.
[19:38.840 --> 19:40.840]  Это есть единица.
[19:42.840 --> 19:46.840]  Минус вероятность того, что это минус Е.
[19:46.840 --> 19:52.840]  Это не превосходит минус Эпсилон М пополам.
[19:56.840 --> 20:00.840]  И вот к этому я уже могу применить неравенство Чебышова, согласны?
[20:02.840 --> 20:05.840]  Ну, хорошо, я напишу вот так.
[20:05.840 --> 20:08.840]  Так, это больше либо равно один минус вероятность того, что модуль
[20:08.840 --> 20:13.840]  это минус е это на ли это больше либо равняется Эпсилон М пополам.
[20:13.840 --> 20:16.840]  Но просто вот в этом событии два варианта.
[20:16.840 --> 20:19.840]  С одной стороны, может быть, вот это разность больше либо равна.
[20:19.840 --> 20:22.840]  А может быть, вот это же разность меньше либо равна.
[20:23.840 --> 20:25.840]  Со знаком минус, как тут.
[20:25.840 --> 20:28.840]  То есть тут есть два варианта, и оба вычитается под знаком вероятности.
[20:28.840 --> 20:30.840]  А тут только один.
[20:30.840 --> 20:31.840]  И он вычитается, ну, понятно, что соотношение, как я написал,
[20:31.840 --> 20:38.800]  соотношения, как я написал. Больше либо равно. Но уж тут-то вы не можете не узнать
[20:38.800 --> 20:47.240]  неравенство Чебышова. Видите, модуль тут. Получается, больше либо равно 1 минус
[20:47.240 --> 20:54.320]  дисперсия. Это поделить на квадрат вот этой правой части, я писал, n пополам в
[20:54.320 --> 21:00.560]  квадрате. Так, товарищи, ну поскольку у вас трудность вызвала подсчет
[21:00.560 --> 21:05.480]  математического ожидания, то дисперсия, я боюсь, будет еще труднее.
[21:05.480 --> 21:15.200]  Чему равна дисперсия? А у вас были уже какие-то предельные теоремы? Ну там
[21:15.200 --> 21:20.000]  муавролапласа, может быть, что-нибудь такое. Медамиальные, это случайная величина у вас
[21:20.000 --> 21:24.360]  были, правда ж? А предельных теорем про них не было.
[21:24.360 --> 21:28.160]  Пуассона, муавролапласа, этого вам не рассказывали. Я просто не знаю, в каком
[21:28.160 --> 21:33.360]  порядке. А муавролапласа еще не было. Ну, тогда вы, наверное, еще не помните, что
[21:33.360 --> 21:36.960]  бывает такое выражение n, p, q.
[21:37.160 --> 21:41.440]  Не, ну смотрите, обычно же биномиальное распределение, как пишут, n число
[21:41.440 --> 21:45.680]  испытаний, p — вероятность успеха, но это общее место. Или у вас как-то по-другому
[21:45.680 --> 21:51.440]  это делают. n и p, правильно? n, p — это мат ожидания. Вот у нас оно просто получилось
[21:51.440 --> 22:03.520]  m эпсилон, но это n, p, да? А дисперсия n, p, q. Ну, боже мой, это можно посчитать.
[22:03.520 --> 22:14.280]  Дисперсия эта равняется дисперсия это 1, плюс и так далее, плюс это m, где это
[22:14.280 --> 22:18.400]  1 от m — это единичка или нолик, смотря по тому, какой стороной фишка легла, да?
[22:18.400 --> 22:23.440]  Ну, то есть единица с вероятностью эпсилон, ноль с вероятностью 1 минус эпсилон.
[22:23.440 --> 22:27.720]  Ну, счастье в том, что они независимы, поэтому дисперсия суммы — это сумма
[22:27.720 --> 22:31.480]  дисперсий. Так, дорогие товарищи, вы же это знаете, ну что вы мне будете
[22:31.480 --> 22:35.880]  рассказывать? Середина весеннего семестра, вероятность уже в самом разгаре.
[22:35.880 --> 22:43.440]  Там уже и мера была совсем... Сессии не было, ну хорошо, да. Я понимаю, что сессии не было,
[22:43.440 --> 22:47.400]  но это же вы знаете все-таки, что если независимая величина, то дисперсия их
[22:47.400 --> 22:52.800]  суммы — это сумма дисперсий. Вот. Что такое дисперсия величины? Давайте, я вот здесь
[22:52.800 --> 22:59.520]  напишу. Это it, 1 с вероятностью эпсилон и ноль с вероятностью 1 минус эпсилон.
[22:59.520 --> 23:05.480]  Какая дисперсия у такой величины? Ну, надо взять мат ожидания это it в квадрате
[23:05.480 --> 23:11.320]  и вычесть мат ожидания это it в квадрате. Так проще всего. Квадрат случайной
[23:11.320 --> 23:15.920]  величины такого же, как она сама, поэтому мат ожидания вот это — это эпсилон.
[23:16.840 --> 23:23.080]  А тут эпсилон в квадрате получается. Если вынести эпсилон за скобку, то будет, как раз как я
[23:23.080 --> 23:30.480]  сказал, p на q. Эпсилон на 1 минус эпсилон. А тут еще сложить, поэтому получается m эпсилон
[23:30.480 --> 23:37.480]  1 минус эпсилон. Ну, обычно пишут npq. Просто у нас такие обозначения для числа испытаний
[23:37.480 --> 23:43.880]  и вероятности успеха. Так, мы еще заметим, что это, конечно, не больше, чем m эпсилон. Тупо.
[23:43.880 --> 23:52.320]  Вот. Поэтому все больше либо равно. Давайте я это в скобке возьму как пояснение. Дальше выкладку
[23:52.320 --> 24:02.080]  продолжу. Больше либо равно единица минус эпсилон m поделить на эпсилон m пополам в квадрате.
[24:02.080 --> 24:18.240]  Смотрите, как хорошо что-то сокращается. 1 минус 4 поделить на эпсилон m. Так, к m сходить что-ли?
[24:18.240 --> 24:34.000]  Вон оно. Ну ладно, вы посмотрели и будете. Так, теперь пишем эпсилон m. Больше либо равняется,
[24:34.000 --> 24:39.880]  там верхняя целая часть, поэтому я могу ее оценить своим аргументом. m умножить,
[24:39.880 --> 24:52.440]  ой не, m умножить, а эпсилон умножить на 8d на эпсилон лог двоичный 8d на эпсилон. Это я
[24:52.440 --> 24:59.400]  m просто переписал без верхней целой части, но оцениваю снизу. Так, шлёп-шлёп. Слушайте,
[24:59.400 --> 25:05.680]  ну d больше либо равно единицы. Мы же не знаем, какая размерность. Ну, а значит, не меньше единицы,
[25:05.680 --> 25:14.080]  что там. Вот я здесь это не важно, так и напишу. 8d заменил на единицу, здесь эпсилон меньше единицы,
[25:14.080 --> 25:20.120]  а d больше единицы. Ну, значит, d на эпсилон больше единицы. То есть, еще умножить на логарифом
[25:20.120 --> 25:29.720]  двоичный 8. Просто d на эпсилон убрал, грубо оценил. Это 3, это 8, того 24. Получаем,
[25:29.720 --> 25:44.200]  больше либо равно 1 минус 4 на 24. Это 5 шестых. Тяп-ляп. Так, я эпсилон m оценил снизу,
[25:44.200 --> 25:48.960]  но он в дроби, еще со знаком минус. Поэтому дважды перевернулся, все правильно. Неравенство в ту 100.
[25:48.960 --> 25:57.000]  Какую нужно. Все, я доказал. Цель реализована. Но это не вся цель. Это пока только наше понимание,
[25:57.480 --> 26:04.560]  что вероятность E2 на самом деле не сильно меньше вероятности E1. Поэтому, сумеем мы оценить
[26:04.560 --> 26:10.360]  вероятность E2 как-нибудь достаточно хорошо, значит, вероятность E1 мы тоже почти так же хорошо оценим.
[26:10.360 --> 26:16.840]  Вы помните, нам нужно доказать, что вероятность E1 меньше единицы. Если мы сейчас докажем,
[26:16.840 --> 26:25.360]  что вероятность E2 меньше единицы хотя бы в 1,2 раза, то все получится. 6 пятых.
[26:25.360 --> 26:33.840]  На целые две десятых. Но это вот самое интересное. Там как раз будет катарсис, потому что где тут
[26:33.840 --> 26:40.120]  размерность ваплика черваненкиса пока совершенно непонятна. Как она сыграет? Какой момент?
[26:40.120 --> 26:49.160]  Ну все, я пишу лему 2. Это оценка вероятности события E2.
[26:55.360 --> 27:03.360]  Да, ну и, конечно, я думаю, что вы прекрасно понимаете, что стертая мною только что m,
[27:03.360 --> 27:08.840]  оно пока не сработало во всей красе, потому что те оценки, какими мы пользовались,
[27:08.840 --> 27:17.760]  ну они идиотские. Ну что там D больше единицы, E меньше единицы? Неужели бы это так было задумано?
[27:17.760 --> 27:23.840]  Нет, конечно, сейчас это потребуется в большей красоте, но я не буду саму выкладку проводить,
[27:23.840 --> 27:30.080]  сейчас вы все увидите. В общем, лему 2, которую мы предельно аккуратно докажем, это утверждение о том,
[27:30.080 --> 27:38.640]  что вероятность E2 не больше вот такой величины g от 2m запятая D, я сейчас напомню, что это такое,
[27:38.640 --> 27:52.840]  на 2 в степени минус Эпсилон m пополам, где g от nD это есть сумма по k от 0 до D, c из n по k,
[27:52.840 --> 28:03.840]  и мы пользовались тем, что это не больше, чем n в степени D. Помните это то, что фигурирует в лемме 1 из прошлой лекции?
[28:03.840 --> 28:14.760]  В прошлой лекции тоже была лемма 1, она была про то, что если у нас есть пространство данного размера и данной мощности,
[28:14.760 --> 28:24.920]  то количество областей в нем, мощности r большого, ограничено вот этим g, где n это мощность, а D это размерность.
[28:24.920 --> 28:32.160]  Ну и мы пользовались в какой-то момент тем, что это не больше, чем n в степени D. Смотрите, давайте я не
[28:32.160 --> 28:36.720]  доказывать буду эту лему, а сразу поясню, как из этого теорема-то следует. Она следует сразу.
[28:36.720 --> 28:45.920]  Как из этого следует теорема? Мы знаем, что вероятность E2 больше либо равняется 5 шестых вероятностей E1,
[28:45.920 --> 28:57.160]  ну значит вероятность E1 не превосходит 1,2 умножить вот на эту штуку.
[28:57.160 --> 29:11.360]  Дальше мы пишем, это не превосходит 1,2 умножить на n, а на 2m в степени D и умножить на 2 в степени
[29:11.360 --> 29:23.160]  epsilon m пополам. И еще раз вспоминаем, что m это верхняя целая часть 8d на epsilon, лог двоичный 8d на epsilon.
[29:23.160 --> 29:29.160]  Я утверждаю, товарищи, это примерно такое же рассуждение, как тоже на прошлой лекции было, только там
[29:29.160 --> 29:39.160]  была лемма какая-то 2. Я утверждаю, что m подобрано таким образом, чтобы степенная функция 2m в степени D
[29:39.160 --> 29:48.160]  убивалась отрицательной экспонентой 2 в степени минус epsilon m пополам. Просто вот так подобрано.
[29:48.160 --> 29:58.160]  Помните, я в прошлый раз такие же мантры произносил? Я утверждаю, что вот если вы подставите вместо m сюда
[29:58.160 --> 30:07.160]  вот такое выражение, то это будет меньше единицы. Что и требовалось, нам ровно это нужно. Я не буду заставлять вас
[30:07.160 --> 30:13.160]  проводить эту выкладку на экзамене, и всех попрошу не заставлять, потому что это невеликое умение, черт возьми.
[30:13.160 --> 30:18.160]  Ну потратите полчаса, восстановите эту выкладку. Я тоже сейчас помучусь, восстановлю.
[30:18.160 --> 30:27.160]  Но все же понимают, что по параметру m вот эта штука растет как многочлен, а эту убывает как экспонента.
[30:27.160 --> 30:37.160]  То есть совершенно точно существует такое m, зависище только от D, от epsilon, начиная с которого это все меньше единицы.
[30:37.160 --> 30:43.160]  Но утверждает, что вот оно такого вида. А пафос ровно в этом мы с этого начинали нашу дискуссию перед лекцией.
[30:43.160 --> 30:52.160]  Пафос в том, что нет зависимости от мощности s, от n, а есть зависимость только от epsilon и от размерности пространства.
[30:52.160 --> 31:00.160]  Так что все, я еще раз повторяю, эту выкладку мы проводить не будем, не надо. А вот что надо сделать аккуратно,
[31:00.160 --> 31:06.160]  это доказатель m2. Ну она не то что тютелька в тютельку, но очень близко.
[31:06.160 --> 31:12.160]  То есть я думаю, что при каких-то epsilon и D пограничных, это прям в точности.
[31:12.160 --> 31:18.160]  Но единственное, что, знаете, она в тютельку в тютельку скорее подобрана, если здесь писать не одну целую две десятых, а два.
[31:18.160 --> 31:24.160]  Так что она не в тютельку в тютельку. Ну просто вот в оригинальной работе, по которой я рассказываю,
[31:24.160 --> 31:33.160]  там вот это вот было написано не 5 шестых, а одна вторая. И по одной второй уже было подобрано вот такое m.
[31:33.160 --> 31:38.160]  Но поскольку можно сделать лучше 5 шестых, то, наверное, можно еще лучше сделать m.
[31:38.160 --> 31:43.160]  Ну я не считал, мне это как-то не очень интересно. Хотите, посчитайте, порадуйтесь.
[31:43.160 --> 31:49.160]  Ну как бы это правда интересно, ну в принципе. Но мне не особенно, а вам может быть.
[31:49.160 --> 31:51.160]  Лучше поймете, как жизнь устроена.
[31:51.160 --> 31:53.160]  Как машинное обучение?
[31:53.160 --> 31:58.160]  Как машинное обучение, это другой вопрос. Я про статистику, кстати, расскажу потом.
[31:58.160 --> 31:59.160]  Что?
[31:59.160 --> 32:02.160]  А, все, я понял, что это не отражание.
[32:02.160 --> 32:05.160]  Да-да-да, сейчас про другое. Я еще лему-2 не доказал.
[32:05.160 --> 32:10.160]  Не-не-не, теорема еще не закончилась, ей еще жить и жить и радоваться.
[32:10.160 --> 32:16.160]  Лему-2 докажу, вот тогда будем считать, что теорема доказана. Хорошо? Вольная идея, да?
[32:16.160 --> 32:21.160]  Так, ну хорошо, что тут я могу стереть?
[32:21.160 --> 32:29.160]  Ни в коем случае само событие не надо стирать, а вот это можно вполне себе удалить.
[32:29.160 --> 32:32.160]  Нет, про машинное обучение, конечно, не расскажу.
[32:32.160 --> 32:39.160]  Потому что тут много слов нужно. А про статистику расскажу, потому что вы же знаете законы больших чисел в теории вероятности?
[32:39.160 --> 32:45.160]  Уж это было? Какой-нибудь закончик больших чисел? ЗБЧ.
[32:45.160 --> 32:52.160]  Ну вот я вам напомню. Я же не буду доказывать ЗБЧ. Вам его докажут в вероятности или уже доказали?
[32:52.160 --> 32:56.160]  Ладно, давайте действовать. Доказываем лему-2.
[33:04.160 --> 33:09.160]  Для того, чтобы доказать лему-2, нужно сделать хитрый финт.
[33:09.160 --> 33:15.160]  Надо переопределить вероятностное пространство, в котором мы живем.
[33:15.160 --> 33:20.160]  Ну, по-другому просто его задать, так чтобы получилось то же самое пространство.
[33:20.160 --> 33:28.160]  Как мы его сейчас задаем? Мы последовательно выбираем me элементов и потом еще me элементов, независимо от первых me.
[33:28.160 --> 33:34.160]  То есть сначала ne, вот это большое, выбираем, потом te большое, независимо друг от друга получается.
[33:34.160 --> 33:42.160]  И получается 2 me чисел, почему чисел? Элементов, 2 me элементов, которые между собой как угодно могут совпадать.
[33:42.160 --> 33:45.160]  Вот так устроено наше вероятностное пространство.
[33:45.160 --> 34:00.160]  Давайте его зададим по-другому. Давайте сперва выберем 2 me элементов множества s.
[34:00.160 --> 34:05.160]  2 me элементов множества s с возвращением.
[34:09.160 --> 34:13.160]  Но пока не скажем, что такое n большое и что такое t большое.
[34:13.160 --> 34:30.160]  А затем, уже выбрав их, назовем это мультимножество или размещение, назовем это мультимножество и размещение буквой u.
[34:30.160 --> 34:35.160]  Выберем 2 me элементов, вот это мультимножество назовем буквой u.
[34:35.160 --> 34:43.160]  А затем, разобьем u на две части равных.
[34:43.160 --> 34:50.160]  Разобьем u на две равные части.
[34:55.160 --> 35:02.160]  Выбирая половинку разбиения, давайте я все напишу словами.
[35:02.160 --> 35:05.160]  Не совсем мой сейчас стиль, но неважно.
[35:05.160 --> 35:15.160]  Половинку, так понять не будет, разбиение n или t, неважно.
[35:15.160 --> 35:26.160]  С вероятностью 1 поделить на c из 2 mpi, то есть классическим образом.
[35:26.160 --> 35:37.160]  Согласно классическому определению вероятности, то есть половинку выбираем из множества всех половинок.
[35:37.160 --> 35:40.160]  Одну из.
[35:40.160 --> 35:43.160]  Но тут какая опять тонкость, которую надо подчеркнуть.
[35:43.160 --> 35:51.160]  Представьте себе, что вот это u, например, получилось просто состоящим из 2 me одинаковых элементов.
[35:51.160 --> 35:54.160]  Может же такое случиться? Вот такое u выбрали.
[35:54.160 --> 36:00.160]  Все равно каждая половинка выбирается с вероятностью 1 поделить на c из 2 me по me.
[36:00.160 --> 36:07.160]  Хотя любая из них это просто me, раз повторенное.
[36:07.160 --> 36:09.160]  Я понятно говорю, да?
[36:09.160 --> 36:13.160]  То есть у нас могут возникать одинаковые пары n и t.
[36:13.160 --> 36:16.160]  Ну как, собственно, они и здесь могли возникать.
[36:16.160 --> 36:19.160]  Понимаете, что мы получили по сути то же самое.
[36:19.160 --> 36:21.160]  Так сказать, распределение на парах множества.
[36:21.160 --> 36:25.160]  Здесь мы последовательно их выбирали одно, потом другое.
[36:25.160 --> 36:30.160]  А здесь мы их все вот это объединение выбираем, называем его u,
[36:30.160 --> 36:33.160]  и потом разбиваем на две части.
[36:33.160 --> 36:36.160]  Это то же самое.
[36:36.160 --> 36:38.160]  Получаем те же самые n и t.
[36:38.160 --> 36:40.160]  Такой двойной счет, если хотите.
[36:40.160 --> 36:44.160]  То есть если в невероятностных терминах говорить, то это просто двойной счет.
[36:44.160 --> 36:48.160]  Мы по-другому считаем, в другом порядке.
[36:48.160 --> 36:51.160]  Вот так переопределили вероятностное пространство.
[36:51.160 --> 36:53.160]  И теперь будем действовать.
[36:53.160 --> 36:56.160]  Так, но эту всю красоту надо стирать.
[37:18.160 --> 37:36.160]  Так, ну давайте, вот как сделаем.
[37:36.160 --> 37:44.160]  Давайте заметим, что вероятность событий E2, которая нас интересует,
[37:44.160 --> 37:49.160]  может быть, конечно, посчитана по формуле полной вероятности.
[37:49.160 --> 37:57.160]  Следующим образом, можно перебрать все способы выбрать мульти множество u мощности 2m.
[37:57.160 --> 38:02.160]  И для каждого из этих способов посчитать вероятность события E2,
[38:02.160 --> 38:11.160]  при условии, что u зафиксировано, и осталось только его разбить на две непересекающиеся части.
[38:11.160 --> 38:15.160]  Но это формула полной вероятности.
[38:15.160 --> 38:19.160]  Неправильно написал, надо еще на вероятность u умножить.
[38:19.160 --> 38:21.160]  Так, надо еще умножить на вероятность u.
[38:21.160 --> 38:26.160]  Вот это будет формула полной вероятности.
[38:26.160 --> 38:32.160]  Ну, по u, по всем множествам, мульти множествам u мощности 2m.
[38:32.160 --> 38:36.160]  У нас двуступенчатый выбор теперь такой.
[38:36.160 --> 38:40.160]  Мы можем разложить все на способы, как мы выберем u.
[38:40.160 --> 38:45.160]  Вероятность u, ну, там один поделить на n в степени 2m, что-то такое.
[38:45.160 --> 38:52.160]  Но поскольку все вероятности u одинаковые, то нам действительно достаточно теперь доказать ту же самую оценку для условной вероятности.
[38:52.160 --> 39:06.160]  Достаточно доказать, что вероятность E2 при условии u не превосходит g от 2m d на 2 в степени минус epsilon m попало.
[39:06.160 --> 39:16.160]  Если мы это докажем при каждом конкретном у, то мы докажем и для всего E2 такую же оценку вероятности.
[39:16.160 --> 39:20.160]  На самом деле даже не важно, что все вероятности u одинаковые.
[39:20.160 --> 39:29.160]  Если мы условную вероятность вот в этой сумме умеем вот так оценить каждую, то мы вот это все вытаскиваем за знак суммирования,
[39:29.160 --> 39:33.160]  а сумма по u вероятности u это всегда единица.
[39:33.160 --> 39:38.160]  Сумма всех вероятностей всегда единица, не важно совпадающие числа, не совпадающие.
[39:38.160 --> 39:46.160]  В общем, короче, нам достаточно доказать, что для любого u вероятность E2 при условии u вот такая, и больше чем столько.
[39:46.160 --> 39:52.160]  Так, теперь давайте введем событие E2 запятая r.
[39:52.160 --> 39:56.160]  E2 у меня, слава богу, не стертая. Сейчас будем сравнивать.
[39:56.160 --> 40:19.160]  Это множество nt таких, что r пересеченное с s, а, с s не надо, таких, что r пересеченное с c пусто, и r пересеченное с t не меньше, чем epsilon m пополам.
[40:19.160 --> 40:24.160]  Вот сейчас возникнет как раз понимание, зачем нужно было вот это дополнительное условие.
[40:24.160 --> 40:29.160]  Оно возникнет ровно когда мы будем оценивать вероятность E2 r.
[40:29.160 --> 40:34.160]  Но правда не просто его, а при условии u еще.
[40:34.160 --> 40:41.160]  Так, чем отличается E2 r от E2? Смотрите на E2, смотрите на E2 r.
[40:41.160 --> 40:47.160]  В E2 существует r, которое вот так пересекается с s, и дальше, собственно, условия события.
[40:47.160 --> 40:52.160]  Так, друзья, вот очень важный момент. Вы понимаете, что вот это не является условием события?
[40:52.160 --> 40:58.160]  Потому что s это фиксированное, не случайное множество. Условия события, вот они, их два.
[40:58.160 --> 41:05.160]  А вот это, это вот сюда относится.
[41:05.160 --> 41:14.160]  Существует r, которое пересекается с s достаточно сильно, и дальше такое, что наши случайные n и t вот так с ним соотносятся.
[41:14.160 --> 41:18.160]  Важно понимать. То есть я что хочу сказать?
[41:18.160 --> 41:25.160]  Я хочу сказать, что E2, это, конечно, объединение E2 r,
[41:25.160 --> 41:34.160]  по всем r из r большого таким, что мощность r пересеченного с s большим больше либо равняется εn.
[41:34.160 --> 41:44.160]  Ну, с этим, я надеюсь, вы согласны, потому что вот тут у нас по r квантор существует,
[41:44.160 --> 41:48.160]  а квантор существования равносилен взятию объединить.
[41:48.160 --> 41:55.160]  Сейчас будет самый главный, самый тонкий момент, который надо будет осознать.
[41:55.160 --> 42:00.160]  Ну, тоньше меня.
[42:00.160 --> 42:07.160]  Ну, не насколько, но не очень. Да, вот уж прямо тонок вы как-то так переживаете.
[42:07.160 --> 42:11.160]  Ну, я хочу просто вам подсветить ключевые моменты,
[42:11.160 --> 42:17.160]  поэтому вы когда будете, может, пересматривать лекцию или кто-то будет смотреть, кто сюда не дошел, к сожалению,
[42:17.160 --> 42:20.160]  тоже услышат, что вот этот вот важный момент.
[42:20.160 --> 42:25.160]  Понимаете, вот в этом объединении дохренища событий.
[42:25.160 --> 42:37.160]  Но на самом деле при условии U, если U уже зафиксировано, многие из них совпадают.
[42:37.160 --> 42:44.160]  Нас-то что интересует? Нас интересует вероятность E2 при условии U.
[42:44.160 --> 42:48.160]  Вот мы хотим доказать, что выполнено такое неравенство.
[42:49.160 --> 42:55.160]  Там тупо, можно было бы тупо, вот давайте я напишу тупо, можно было бы написать вот так.
[42:55.160 --> 43:10.160]  Это не больше, чем сумма по всем r из r таким, что r пересеченное с s не меньше, чем εn, n не меньше, чем εn.
[43:10.160 --> 43:17.160]  Ну, и здесь написать вероятность E2r при условии U.
[43:17.160 --> 43:24.160]  Это тупое неравенство, мы просто тупо суммируем по всем вообще r-кам, которые обладают вот этим свойством.
[43:24.160 --> 43:28.160]  Их много до чертовой бабки, сейчас ничего не получится.
[43:28.160 --> 43:31.160]  Поэтому я тупое неравенство с вашего позволения сотру.
[43:31.160 --> 43:40.160]  Я хочу гораздо меньшим объединить, это все оценить, убедившись, что когда U зафиксировано, в этих событиях не так много разных.
[43:40.160 --> 43:45.160]  Так, куда я взял тряпку? А, у меня целых две, потрясающе.
[43:45.160 --> 43:52.160]  Тупо не будем оценивать, не хочу тупо, ничего не получится.
[43:52.160 --> 43:59.160]  Так, смотрите, вот U у нас зафиксировано, давайте вот эта сарделька, это U.
[43:59.160 --> 44:08.160]  Но только не забывайте, что U все-таки это мультимножество на самом деле, то есть в этой сардельке могут быть совпадающие элементы, но это не так важно.
[44:08.160 --> 44:14.160]  Не забывайте также, что U состоит из 2m вот этих возможно совпадающих элементов, вот тут написано.
[44:14.160 --> 44:19.160]  Сейчас я это тоже здесь укажу, тут 2m.
[44:25.160 --> 44:32.160]  А, кто-то мне звонит, что ли? Я не слышу сейчас, что-то важное. Ой, сейчас, извините, алло.
[44:33.160 --> 44:40.160]  Да, вообще, ректорат у нас на третьем этаже главного корпуса.
[44:47.160 --> 44:51.160]  Ну да, в общем, я сейчас лекцию просто закончу читать и приду.
[44:56.160 --> 44:57.160]  Да, спасибо.
[44:58.160 --> 45:00.160]  Так, сейчас виноват.
[45:01.160 --> 45:05.160]  Так, так, так. Вот у нас U зафиксировано.
[45:09.160 --> 45:10.160]  Сейчас.
[45:13.160 --> 45:14.160]  Что-то.
[45:16.160 --> 45:17.160]  Секунду.
[45:19.160 --> 45:20.160]  Подождите.
[45:24.160 --> 45:25.160]  Сейчас.
[45:30.160 --> 45:31.160]  Па-па-па.
[45:47.160 --> 45:49.160]  Сейчас, что тут? Подождите.
[45:51.160 --> 45:52.160]  Топлю. Секунду.
[45:54.160 --> 45:57.160]  U зафиксировано, U мы выбирали из S.
[46:00.160 --> 46:01.160]  Что такое-то?
[46:05.160 --> 46:07.160]  Сбился чуть-чуть. Сейчас, извините.
[46:20.160 --> 46:22.160]  Что такое? Подождите, извините.
[46:22.160 --> 46:23.160]  Что такое сейчас?
[46:25.160 --> 46:27.160]  На пустом месте сейчас, на ровном.
[46:28.160 --> 46:29.160]  Это заскок. Сейчас, секунду.
[46:30.160 --> 46:34.160]  Что ж такое? Подождите, я не могу привязаться к этому, секунду.
[46:35.160 --> 46:37.160]  Что-то мы выбирали из S.
[46:39.160 --> 46:40.160]  R пересеченное.
[46:40.160 --> 46:41.160]  Что такое?
[46:43.160 --> 46:44.160]  Подождите.
[46:52.160 --> 46:53.160]  Сейчас, секунду.
[46:54.160 --> 46:55.160]  Ух, ух, ух, ух, ух.
[46:56.160 --> 46:57.160]  И это тоже, конечно.
[46:59.160 --> 47:00.160]  Конечно, это может быть.
[47:01.160 --> 47:02.160]  Ух, ух, ух.
[47:03.160 --> 47:04.160]  Ух, ух, ух, ух.
[47:05.160 --> 47:06.160]  А, ух, ух, ух, ух.
[47:07.160 --> 47:08.160]  Ух, ух, ух.
[47:08.160 --> 47:15.400]  Сейчас, простите, пожалуйста, что-то я сбился в этом месте, не знаю, почему. Вроде совершенно
[47:15.400 --> 47:22.800]  стандартный момент. Я вот, видимо, действительно очень тонкий. Не, ну, никогда не был тонким,
[47:22.800 --> 47:29.800]  что-то я не пойму, что меня сейчас смущает, но почему-то вот меня это смущает. 2м элементов
[47:29.800 --> 47:41.040]  ФС, да, мы с С пересекаемся по Эпсилон Н, Е2Р, а, все, наверное, не, подождите.
[47:41.040 --> 48:01.040]  Сейчас, вот у нас есть Экелес.
[48:01.040 --> 48:21.520]  С у нас мощности N, У у нас мощности 2m.
[48:21.520 --> 48:50.760]  Значит, если R. Что ж такое-то? Что ж я туплю-то? Вот смотрите, пусть у нас R1 какое-то множество,
[48:50.760 --> 49:08.600]  из С, ой, Господи, из R такое, что R1 пересеченное с С имеет мощность не меньше, чем Эпсилон Н. И R2 такое же,
[49:08.600 --> 49:20.600]  причем они оба таковы, что если мы R1 пересечем с У и R2 пересечем с У, то получится одно и то,
[49:20.880 --> 49:28.720]  вот то же. Пусть у нас есть два множества области, которые находятся в этом объединении,
[49:28.720 --> 49:34.440]  по которым берется объединение, по областям, которые с С пересекаются достаточно жирно.
[49:34.440 --> 49:39.420]  Вот пусть у нас есть две таких области, которые с С пересекаются достаточно жирно и при этом
[49:39.420 --> 49:50.520]  их пересечение с У совпадают. Мы же и Суп artists выбираем Н и Т, правильно, мы из У legalized
[49:50.520 --> 49:58.520]  Мы из У выбираем Н и Т, потом уже У зафиксировано, а на Н и Т мы его потом случайно разбиваем.
[50:00.520 --> 50:07.520]  Вот если у нас есть два множества R1 и R2, имеющие одинаковые пересечения с множеством У,
[50:07.520 --> 50:16.520]  я утверждаю, что тогда E2R1, не знаю, что я застрял, все просто,
[50:16.520 --> 50:22.520]  и E2R2 это одинаковые события, просто одинаковые события.
[50:22.520 --> 50:29.520]  Потому что в каждом из них говорится о том, как вот это R пересекается с N,
[50:29.520 --> 50:33.520]  но N само находится внутри У, по определению.
[50:34.520 --> 50:40.520]  Поэтому важно только, как изначально это R с У пересекалось, чтобы потом смотреть,
[50:40.520 --> 50:46.520]  с соответствующим N оно пусто пересекается, с соответствующим T оно жирно пересекается,
[50:46.520 --> 50:49.520]  или что-то из этого не выполнено.
[50:49.520 --> 50:54.520]  Согласны, да, что если вот эти пересечения завпадают, то и события одинаковые.
[50:54.520 --> 50:58.520]  Состоят из одних и тех же N и T пар.
[50:59.520 --> 51:03.520]  Следили за мыслями?
[51:03.520 --> 51:08.520]  Вот это был тонкий момент, я, честно говоря, не понимаю, почему.
[51:08.520 --> 51:12.520]  Я, видимо, специально его затончил, чисто подсознательно.
[51:12.520 --> 51:16.520]  Мне сказали, насколько он тонкий, меняется, вот там перещелкнуло, а вдруг он правда...
[51:16.520 --> 51:19.520]  Ничего, ничего, это как раз хорошо.
[51:19.520 --> 51:23.520]  Всегда полезно задуматься, а что же здесь является, так сказать, центральной пружиной.
[51:23.520 --> 51:25.520]  Ну вот так, конечно, устроено.
[51:25.520 --> 51:29.520]  То есть получается, что в этом объединении различных событий...
[51:29.520 --> 51:32.520]  Сколько?
[51:32.520 --> 51:36.520]  Различных событий вот в этом объединении при условии фиксации U,
[51:36.520 --> 51:42.520]  если U зафиксировано, то различных событий в этом объединении...
[51:42.520 --> 51:44.520]  Дайте я словами, пишу прям.
[51:44.520 --> 52:06.520]  Различных событий в объединении не больше, чем мощность проекции на вот это U нашей системы областей R.
[52:06.520 --> 52:10.520]  Ну что такое проекция на U системы областей R?
[52:10.520 --> 52:17.520]  Это как раз множество всех различных пересечений R маленьких из R большого с вот этим U.
[52:17.520 --> 52:21.520]  Для одинаковых пересечений события одинаковые.
[52:21.520 --> 52:25.520]  Значит, разных событий столько, сколько разных таких пересечений.
[52:25.520 --> 52:31.520]  А эти разные пересечения как раз и образуют проекцию, как мы ее определяли в прошлый раз.
[52:31.520 --> 52:34.520]  Сейчас вроде все аккуратно сказано.
[52:34.520 --> 52:40.520]  Ну а размер проекции как раз и не превосходит g от 2md.
[52:40.520 --> 52:43.520]  Это следствие из лемма-1 прошлой лекции.
[52:43.520 --> 52:49.520]  Потому что у нас размерность пространства d, а мощность U это 2m.
[52:49.520 --> 52:51.520]  С учетом кратности.
[52:56.520 --> 52:59.520]  Ну и все. То есть у нас получается, что вероятность...
[52:59.520 --> 53:01.520]  Ну почти все, еще не все.
[53:01.520 --> 53:03.520]  Еще откуда-то должна вот эта хрень вылезти.
[53:03.520 --> 53:05.520]  Это-то еще не все.
[53:05.520 --> 53:08.520]  Сейчас мы еще хрень откуда-то вытащим.
[53:08.520 --> 53:17.520]  Так, E2, что мы там оцениваем при условии U, не больше, чем g от 2md
[53:17.520 --> 53:25.520]  на вероятность E2 запятая R при условии U.
[53:25.520 --> 53:28.520]  Но это чуть-чуть может быть некорректная запись,
[53:28.520 --> 53:31.520]  потому что кто сказал, что эти все вероятности одинаковые?
[53:31.520 --> 53:33.520]  А никто не сказал.
[53:33.520 --> 53:35.520]  Написать подробнее, наверное, надо.
[53:35.520 --> 53:37.520]  Давайте я напишу подробнее.
[53:37.520 --> 53:41.520]  Это вот так.
[53:41.520 --> 53:50.520]  Сумма по R, вероятность E2RT при условии U,
[53:50.520 --> 53:54.520]  где количество слагаемых не больше, чем вот такое.
[53:55.520 --> 53:59.520]  Что в объединении не больше, чем столько разных элементов,
[53:59.520 --> 54:03.520]  ну значит складывать мы должны не больше, чем столько слагаемых.
[54:03.520 --> 54:06.520]  Ну короче, я хочу доказать, что для любого R,
[54:06.520 --> 54:14.520]  это я хочу доказать, что для любого R вероятность E2RU при условии U
[54:14.520 --> 54:19.520]  не больше, чем 2 в степени −εm½.
[54:19.520 --> 54:22.520]  Если я докажу, что это верно для любого R,
[54:22.520 --> 54:25.520]  то то, что я писал и потом стер, вполне корректно.
[54:25.520 --> 54:29.520]  Действительно, тогда вот по модулю этого, я сейчас докажу,
[54:29.520 --> 54:37.520]  у нас получается не больше, чем g от 2md на 2 в степени −εm½.
[54:37.520 --> 54:39.520]  Это есть ровно утверждение L2.
[54:39.520 --> 54:41.520]  Мы ее доказали.
[54:41.520 --> 54:43.520]  Но доказали по модулю того, что в скобках.
[54:43.520 --> 54:46.520]  То есть осталось еще скобочное рассуждение.
[54:46.520 --> 54:49.520]  Проверьте, утверждение, проверьте.
[54:50.520 --> 54:53.520]  Так, оно несложное, конечно.
[54:56.520 --> 54:59.520]  Ну несложное, несложное, все равно думать надо.
[55:01.520 --> 55:04.520]  Так, самый тонкий момент я стираю с доски.
[55:06.520 --> 55:09.520]  Но он вроде уже свою роль сыграл.
[55:11.520 --> 55:16.520]  Так, так, так, как же это доказать?
[55:16.520 --> 55:19.520]  Ну у нас тут есть картина какая-то.
[55:22.520 --> 55:26.520]  Вот есть r пересеченная sum.
[55:30.520 --> 55:35.520]  Давайте буковкой P обозначим его мощность.
[55:35.520 --> 55:40.520]  Так, P это будет мощность r пересеченного sum.
[55:40.520 --> 55:43.520]  Мощности все понимаем с учетом кратности, как обычно.
[55:43.520 --> 55:45.520]  Значит, r пересекаем sum.
[55:45.520 --> 55:47.520]  Смотрим мощность пересечения.
[55:47.520 --> 55:49.520]  Называем это буковкой P.
[55:49.520 --> 55:55.520]  Смотрите, если P меньше, чем epsilon...
[55:55.520 --> 55:59.520]  Плохо написал, меньше, чем epsilon m пополам,
[56:01.520 --> 56:09.520]  то интересующая нас вероятность E2r при условии у большого,
[56:09.520 --> 56:13.520]  чему равна, давайте вы мне это скажете.
[56:14.520 --> 56:16.520]  Или чего она не превосходит.
[56:17.520 --> 56:19.520]  Значит, смотрите, вот тут мало элементов.
[56:19.520 --> 56:22.520]  Тут элементов меньше, чем epsilon m пополам.
[56:22.520 --> 56:24.520]  А нас интересует вот это событие.
[56:24.520 --> 56:26.520]  В частности, в этом событии есть условие,
[56:26.520 --> 56:30.520]  что r пересеченная step больше либо равняется epsilon m пополам.
[56:30.520 --> 56:34.520]  Но T это живая половинка, так сказать, ату.
[56:34.520 --> 56:37.520]  Помните, там не важно, что элементы совпадают.
[56:37.520 --> 56:39.520]  Вот там пример нарисован.
[56:39.520 --> 56:41.520]  T это мы как-то разрубили пополам.
[56:43.520 --> 56:47.520]  Но как такое может быть, что r пересеченная sum маленькая,
[56:47.520 --> 56:53.520]  мы разрубили u пополам, и вот сюда из множества T
[56:53.520 --> 56:55.520]  попало наоборот больше элементов?
[56:55.520 --> 56:57.520]  То есть я хочу сказать, что это 0, конечно, вероятность.
[56:57.520 --> 56:59.520]  Такого быть не может.
[56:59.520 --> 57:02.520]  Даже с учетом кратности, столько элементов туда попасть не может.
[57:03.520 --> 57:06.520]  Мы разрубили пополам уже классическим образом,
[57:06.520 --> 57:08.520]  учитывая кратность заранее.
[57:09.520 --> 57:15.520]  Но отсюда следует, конечно, что p больше либо равняется epsilon m пополам.
[57:15.520 --> 57:19.520]  И в этом предположении мы теперь будем оценивать нашу условную вероятность.
[57:20.520 --> 57:21.520]  Пишем так.
[57:21.520 --> 57:30.520]  Вероятность E2r при условии u и вот этого, что p не меньше, чем epsilon m пополам.
[57:30.520 --> 57:32.520]  Ну, просто в этом предположении.
[57:32.520 --> 57:35.520]  Ну, она в любом случае, конечно, и в этом предположении,
[57:35.520 --> 57:38.520]  в каком угодно не больше, чем вероятность того,
[57:38.520 --> 57:41.520]  что r пересеченная sn пусто.
[57:42.520 --> 57:43.520]  Согласитесь.
[57:47.520 --> 57:48.520]  Я просто убрал.
[57:48.520 --> 57:52.520]  Вот в этом месте уже убрал условие, что r пересеченная st большое.
[57:52.520 --> 57:57.520]  Я им воспользовался для того, чтобы оценить размер вот этой части.
[57:57.520 --> 57:59.520]  Иначе вероятность совсем ничтожная.
[57:59.520 --> 58:00.520]  Все, оно сработало.
[58:00.520 --> 58:02.520]  Оно свою роль отыграло.
[58:02.520 --> 58:03.520]  Это ружье выстрелило.
[58:03.520 --> 58:06.520]  Теперь, с какой вероятностью r пересеченная sn пусто?
[58:06.520 --> 58:09.520]  Но это значит, что половинка n вот как-то так проходит.
[58:09.520 --> 58:11.520]  Не зацепляет вот это пересечение.
[58:13.520 --> 58:17.520]  r пересеченная su такое, а r пересеченная sn пусто.
[58:19.520 --> 58:22.520]  Ну, какая классическая вероятность у такого события,
[58:22.520 --> 58:24.520]  если n большое состоит из m элементов
[58:24.520 --> 58:27.520]  и выбирается с вероятностью 1 поделить на c из 2m по m?
[58:29.520 --> 58:32.520]  Ну, цшки надо какие-то одну на другую разделить.
[58:32.520 --> 58:33.520]  Какую?
[58:33.520 --> 58:34.520]  На какую понятно?
[58:34.520 --> 58:36.520]  На c из 2m по m.
[58:36.520 --> 58:39.520]  А какую на нее надо разделить цшку?
[58:41.520 --> 58:43.520]  Ну, 2m минус p.
[58:43.520 --> 58:45.520]  По m просто, и все.
[58:46.520 --> 58:48.520]  Товарищи, понятно это?
[58:50.520 --> 58:52.520]  Ну, нам просто надо выпустить это.
[58:53.520 --> 58:55.520]  Ну, нам просто надо выбрать те m элементы,
[58:55.520 --> 58:57.520]  которые с этими p не пересекаются.
[58:57.520 --> 58:59.520]  И они будут благоприятствовать,
[58:59.520 --> 59:02.520]  как в теории вероятностей говорят, нашему исходу.
[59:02.520 --> 59:06.520]  Исход состоит в том, что r пересеченная sn пусто.
[59:06.520 --> 59:09.520]  Какие n этому благоприятствуют?
[59:09.520 --> 59:13.520]  Любые, которые с этими p элементами ничего общего не имеют.
[59:13.520 --> 59:15.520]  Таких c из 2m минус p по m.
[59:15.520 --> 59:18.520]  Ну, и делим на все c из 2m по m.
[59:18.520 --> 59:20.520]  Нет?
[59:20.520 --> 59:22.520]  Сомнения какие-то?
[59:22.520 --> 59:24.520]  Здесь вроде все совсем просто.
[59:24.520 --> 59:27.520]  Ну, и давайте через факториал это перепишем.
[59:27.520 --> 59:34.520]  2m минус p факториал на m факториал на m минус p факториал.
[59:34.520 --> 59:36.520]  Чуть-чуть места не хватает.
[59:36.520 --> 59:37.520]  Ну, ничего.
[59:37.520 --> 59:40.520]  2m факториал.
[59:40.520 --> 59:42.520]  Тут тоже m факториал.
[59:42.520 --> 59:44.520]  И еще раз m факториал.
[59:44.520 --> 59:46.520]  Елки-палки.
[59:46.520 --> 59:47.520]  Так, ну ладно.
[59:47.520 --> 59:49.520]  Один вот это вот сократим.
[59:49.520 --> 59:50.520]  Куда деваться?
[59:50.520 --> 59:52.520]  А дальше будем сокращать крест-накрест.
[59:52.520 --> 59:55.520]  Вот 2m минус p факториал и 2m факториал.
[59:55.520 --> 59:58.520]  А тут m факториал и m минус p факториал.
[59:58.520 --> 01:00:00.520]  Ну, придется подняться сюда наверх.
[01:00:00.520 --> 01:00:02.520]  Чуть-чуть не хватило места.
[01:00:02.520 --> 01:00:05.520]  Но сейчас все получится.
[01:00:07.520 --> 01:00:10.520]  Так, значит, это равно.
[01:00:10.520 --> 01:00:12.520]  Господи, два.
[01:00:12.520 --> 01:00:15.520]  Так, так, так, так, так.
[01:00:15.520 --> 01:00:17.520]  Так, так, так.
[01:00:17.520 --> 01:00:18.520]  Так, так, так.
[01:00:18.520 --> 01:00:20.520]  m тут сверху, да?
[01:00:20.520 --> 01:00:25.520]  m, m минус 1, m минус p плюс 1.
[01:00:25.520 --> 01:00:26.520]  Это я сократил.
[01:00:26.520 --> 01:00:29.520]  m факториал, m минус p факториал.
[01:00:29.520 --> 01:00:32.520]  А 2m минус p и 2m факториал в знаменателе дадут.
[01:00:32.520 --> 01:00:42.520]  2m, 2m минус 1, 2m минус p плюс 1.
[01:00:42.520 --> 01:00:44.520]  Ну и все.
[01:00:44.520 --> 01:00:48.520]  Потому что вот эта одна вторая,
[01:00:48.520 --> 01:00:53.520]  а вот эта уже меньше, чем одна вторая.
[01:00:53.520 --> 01:00:58.520]  Потому что 2m минус 1 больше, чем 2m минус 2.
[01:00:58.520 --> 01:01:01.520]  И вот эта меньше, чем одна вторая,
[01:01:01.520 --> 01:01:04.520]  по той же причине с запасом.
[01:01:04.520 --> 01:01:06.520]  Все меньше и меньше.
[01:01:06.520 --> 01:01:09.520]  Видите, да, что они уменьшаются?
[01:01:09.520 --> 01:01:11.520]  Вот, а их п штук.
[01:01:11.520 --> 01:01:13.520]  То есть получается, что это меньше либо равно
[01:01:13.520 --> 01:01:15.520]  2 в степени минус p.
[01:01:15.520 --> 01:01:18.520]  Но p-то у нас больше либо равно, чем epsilon m пополам.
[01:01:18.520 --> 01:01:23.520]  Значит, это меньше либо равно 2 в степени минус epsilon m пополам.
[01:01:23.520 --> 01:01:27.520]  Все доказано.
[01:01:27.520 --> 01:01:29.520]  Ладно.
[01:01:29.520 --> 01:01:31.520]  Давайте, наверное, на этом мы сегодня завершим.
