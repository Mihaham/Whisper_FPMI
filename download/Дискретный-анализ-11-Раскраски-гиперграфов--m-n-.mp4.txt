[00:00.000 --> 00:11.160]  Так, добрый день, ну давайте продолжим нашу деятельность. Я обещал немножко рассказать
[00:11.160 --> 00:16.400]  про то, как связан вапник черванинкес и задачи, так сказать, теории вероятности или статистики.
[00:16.400 --> 00:24.200]  Вы знаете, конечно, что такое закон больших чисел. А усиленный закон больших чисел?
[00:24.200 --> 00:39.600]  Ну, в анализе данных это важно, конечно, и то, что я сейчас буду рассказывать, это тоже важно.
[00:39.600 --> 00:46.160]  Ну, я так буду просто обзор небольшой делать. Но, тем не менее, прямое следствие конечности
[00:46.160 --> 00:52.640]  размерности вапника черванинкеса, как и в прошлый раз для задачи по треугольнике, так и в этот раз
[00:52.640 --> 00:57.800]  вот для задачи статистики, собственно, вапника черванинкеса с этой задачи начинали. Ну, давайте
[00:57.800 --> 01:14.720]  я напомню, наверное, что это такое. Вот есть закон больших чисел. Давайте, наверное, в какой-нибудь
[01:14.720 --> 01:21.760]  самой простой формулировке, ну, условно говоря, для схемы испытаний Бернуль, то есть не вообще
[01:21.760 --> 01:27.280]  для произвольной последовательности каких-то случайных величин, которые, может быть, Бог знает какой,
[01:27.280 --> 01:32.600]  там совершенно разнообразный, а для случайных величин, которые являются индикаторами некоторых
[01:32.600 --> 01:48.680]  событий. Ну, то есть, как это должно выглядеть? У нас есть какие-то события А1, АН и так до
[01:48.680 --> 01:58.000]  бесконечности, которые, ну, как сказать, отвечают успеху в очередном испытании Бернуль. Мы бросаем
[01:58.000 --> 02:04.320]  монетку, если она выпала решкой кверху, говорим, что успех, но это и будет событие А1. То есть,
[02:04.320 --> 02:10.800]  если случилось событие А1, то говорим, что успех, если не случилось, то говорим, что неудача. Чтобы
[02:10.800 --> 02:17.440]  это была такая настоящая схема испытаний Бернуль, что нужно сказать про эти события? Конечно,
[02:17.440 --> 02:23.120]  они должны быть независимыми в совокупности. Ну, то есть, живут они, по-видимому, на каком-то
[02:23.120 --> 02:29.200]  бесконечном вероятностном пространстве, потому что иначе вы, конечно, не сможете организовать
[02:29.200 --> 02:35.480]  бесконечную последовательность событий независимых в совокупности. Но это вас тоже учили в курсе теории
[02:35.480 --> 02:43.240]  вероятностей, я это напоминать не буду. Учили же. Бесконечную последовательность случайных величин
[02:43.240 --> 02:50.360]  независимых можно задать только на бесконечном пространстве. Я думаю, что учили. Ну вот,
[02:50.360 --> 02:57.560]  независимые в совокупности события. Тогда, если обозначить... Да, давайте еще считать,
[02:57.560 --> 03:05.520]  что для любого И вероятность Аитова, конечно, равняется некоторому П. То есть, иначе это не
[03:05.520 --> 03:12.080]  будет схема Бернуль. Надо, чтобы вероятности все были одинаковые. Равно вероятные события и
[03:12.080 --> 03:21.000]  эти события независимых в совокупности. Тогда закон больших чисел, это что такое? Мы просто берем
[03:21.000 --> 03:35.880]  индикаторы этих событий, первых N штук, вкладываем их, делим на N и говорим, что куда это стремится,
[03:35.880 --> 03:44.320]  и как это стремится, как и куда это стремится. В обычном законе больших чисел, как и куда это
[03:44.320 --> 03:57.480]  стремится. Ну, к мат ожиданию, которое, конечно, равно вероятности Аитова, то есть П. Сама сумма
[03:57.480 --> 04:02.440]  стремится к N, П, но не стремится, а эквивалент на N, П. Когда мы делим на N, да, получается в
[04:02.440 --> 04:13.120]  пределе П. Так, ну и как устроена эта сходимость? Какого вида сходимости тут присутствует? Ну вот,
[04:13.120 --> 04:20.920]  слушайте, закон больших чисел, от усиленного закона больших чисел, отличается тем, что вид сходимости
[04:20.920 --> 04:32.240]  здесь в одном случае по вероятности, это просто закон больших чисел, ну или по мере, как еще говорят,
[04:32.240 --> 04:41.880]  по вероятности. А усиленный закон больших чисел, это когда вот здесь вот вероятность заменяется на
[04:41.880 --> 04:51.480]  почти наверно. Это У, З, Б, Ч. И вам обязательно должны в основном курсе теории вероятности
[04:51.480 --> 04:57.640]  доказать и закон больших чисел в куче разных форм, и усиленный закон больших чисел, как минимум,
[04:57.640 --> 05:06.480]  в двух формах. Но для схемы испытаний Бернули он, конечно, верен, в какой форме его не доказан,
[05:06.960 --> 05:12.760]  но это факт. Так, слушайте, вы помните, в чем отличие сходимости почти наверно от сходимости по
[05:12.760 --> 05:20.580]  вероятности? И помните, что сходимость по вероятности слабее, строго слабее, чем сходимость почти
[05:20.580 --> 05:28.360]  наверно. Потому что из почти наверно и по вероятности следует, но есть пример с бегунком с таким,
[05:28.360 --> 05:35.540]  который показывает, что по мере может сходиться к нулю, например, а почти наверно вообще не сходится
[05:35.540 --> 05:41.540]  просто вообще ни в одной точке не сходится. Не то, что нет почти наверной исходимости, а нет исходимости ни в одной точке.
[05:45.540 --> 05:50.540]  То есть почти наверная гораздо сильнее, поэтому соответствующие законы больших чисел называются усиленными.
[05:50.540 --> 05:56.540]  И именно они нужны на самом деле в анализе данных. Вот уж так сложилось.
[05:56.540 --> 06:01.540]  Например, если вы что-то хотите приблизить с помощью какого-нибудь метода типа Монта-Карла,
[06:01.540 --> 06:04.540]  то, конечно, без усиленного закона больших чисел вам не обойтись.
[06:04.540 --> 06:06.540]  Но здесь он работает.
[06:10.540 --> 06:18.540]  Так вот, каким вопросом задавались товарищи Вапник и Черваненкес,
[06:18.540 --> 06:26.540]  если так совсем поверхностно это сформулировать в твоем 1970 году?
[06:26.540 --> 06:36.540]  Они задавались вопросом, насколько далеко можно это дело обобщить?
[06:42.540 --> 06:44.540]  В каком смысле обобщить?
[06:44.540 --> 06:54.540]  Ну, смотрите, статистики у вас еще не было, конечно.
[06:54.540 --> 07:00.540]  Это я знаю. Вы не думайте, что я не знаю, что у вас статистики не было.
[07:00.540 --> 07:06.540]  Но в статистике есть значимое усиление вот этого усиленного закона больших чисел, дальнейшее,
[07:06.540 --> 07:12.540]  которое на самом деле и позволяет очень многие факты из статистики доказывать.
[07:12.540 --> 07:14.540]  Вот.
[07:14.540 --> 07:22.540]  Значит, называется оно теорема Гливенко-Кантелли.
[07:22.540 --> 07:30.540]  Вам ее обязательно докажут в курсе статистики, какой бы из наших курсов статистики вы не слушали.
[07:30.540 --> 07:39.540]  То есть, неважно вы на потоке условном общем или на потоке, как он там называется.
[07:39.540 --> 07:41.540]  ДС-поток — это как бы ДС-поток.
[07:41.540 --> 07:45.540]  Ну да, да, ДС-поток, да, да, да.
[07:45.540 --> 07:49.540]  Все равно Гливенко-Кантелли — это такая основа основ.
[07:49.540 --> 07:55.540]  Как бы это нам попроще сформулировать?
[07:55.540 --> 08:01.540]  Ну, давайте я как бы попроще сформулировать.
[08:01.540 --> 08:11.540]  Ну, наверное, можно вот так сказать.
[08:17.540 --> 08:21.540]  Сейчас я соображу как лучше.
[08:21.540 --> 08:27.540]  Ну, давайте я сначала не формулировку, а все-таки немножко основу статистики какую-то скажу.
[08:27.540 --> 08:31.540]  Значит, у нас есть выборка.
[08:31.540 --> 08:37.540]  Ну, чтобы было понятно, о чем вообще идет речь, давайте я немножко расскажу про статистику.
[08:37.540 --> 08:41.540]  Есть выборка. Это числа, которые мы просто пронаблюдали в каком-то эксперименте.
[08:41.540 --> 08:43.540]  Ну, какой-то набор вещественных чисел.
[08:43.540 --> 08:47.540]  Не знаю, следили за температурой воздуха каждый день в 12 часов.
[08:47.540 --> 08:51.540]  И вот в первый день мы увидели температуру минус 1, во второй там плюс 2 и так далее.
[08:51.540 --> 08:54.540]  Ну, получилось какая-то последовательность чисел.
[08:54.540 --> 09:00.540]  А мы считаем, что за этими числами стоят какие-то случайные величины.
[09:00.540 --> 09:02.540]  И эти числа служат просто их реализации.
[09:02.540 --> 09:09.540]  То есть у Господа Бога есть такая монетка, которую он подбрасывает, засовывает куда-то в какую-то случайную величину.
[09:09.540 --> 09:13.540]  Батс получается температура сегодня, потом температура завтра.
[09:13.540 --> 09:15.540]  И так в течение месяца.
[09:15.540 --> 09:21.540]  Про эти случайные величины обычно для простоты предполагают, что они не обязательно, это не вся статистика такая,
[09:21.540 --> 09:26.540]  это ее классическая основа независимая и одинаково распределены.
[09:31.540 --> 09:33.540]  Но только распределение мы этого не знаем.
[09:33.540 --> 09:35.540]  И вот это основная проблема статистики.
[09:35.540 --> 09:42.540]  Как оценить распределение вот этих случайных величин, зная только элементы выборки, которые мы пронаблюдали.
[09:42.540 --> 09:50.540]  Ну, как-то вот попробовать, апроксимировать, оценить максимально правдоподобным образом параметры этого распределения
[09:50.540 --> 09:52.540]  или просто все это распределение в целом.
[09:52.540 --> 09:54.540]  Вот мы не знаем.
[09:54.540 --> 09:56.540]  Ну, есть какая-то функция.
[09:56.540 --> 09:59.540]  f, xi, it от x.
[09:59.540 --> 10:03.540]  Это функция распределения каждой из этих случайных величин.
[10:03.540 --> 10:06.540]  Они одинаково распределены, значит, функция одна и та же для всех.
[10:06.540 --> 10:08.540]  Можно f, xi, 1 написать.
[10:08.540 --> 10:11.540]  Но мы ее не знаем, мы хотим ее как-то апроксимировать.
[10:11.540 --> 10:19.540]  Но такой самый тупой способ апроксимировать функцию оказывается при этом гениальным и хорошим.
[10:19.540 --> 10:23.540]  И вот об этом теорема Гливенко-Кантельли сейчас я про это скажу.
[10:23.540 --> 10:27.540]  Значит, как ведет тебя обычная функция распределения?
[10:27.540 --> 10:29.540]  Ну, грубо говоря, как-то так. Правда же?
[10:29.540 --> 10:31.540]  Это вот f, xi, it от x.
[10:31.540 --> 10:35.540]  Конечно, там где-то могут быть ступенечки, какие-то более хитрые, изломы.
[10:35.540 --> 10:39.540]  Но она монотонно не возрастает на всем вот этом промежутке.
[10:39.540 --> 10:41.540]  От нуля до единицы.
[10:41.540 --> 10:43.540]  Непрерывно справа.
[10:43.540 --> 10:46.540]  Ну, здесь я нарисовал просто непрерывно.
[10:47.540 --> 10:52.540]  Ну, давайте попробуем ее апроксимировать просто вот такими ступенечками.
[10:56.540 --> 10:58.540]  Ну, какими ступенечками?
[10:58.540 --> 11:03.540]  Возьмем элементы выборки и просто вот такую функцию рассмотрим.
[11:03.540 --> 11:12.540]  fn, давайте с крышкой ее обычно обозначают, от x1, xn и от x.
[11:12.540 --> 11:19.540]  То есть мы ее по выборке построим, а x это будет обычный вещественный аргумент, такой же, как у теоретической функции распределения.
[11:19.540 --> 11:22.540]  Что определяется, повторяю, это просто ступенчатая функция.
[11:22.540 --> 11:28.540]  Значит, это будет 1n, сумма по i от единицы до n.
[11:28.540 --> 11:33.540]  Индикаторов сравнивайте с тем, что я написал на левой части доски.
[11:33.540 --> 11:38.540]  Индикаторов того, что x, it не превосходит x.
[11:38.540 --> 11:42.540]  Вот такая вот простая функция.
[11:42.540 --> 11:48.540]  Понятно ли, что это за ступенчатая функция, что она действительно выглядит так, как на картинке?
[11:55.540 --> 12:01.540]  Ну, то есть тут есть какие-то специфические события аиты, которые между собой, очевидно, независимы.
[12:02.540 --> 12:06.540]  Вот события аиты, вот это вот. Это события аиты.
[12:06.540 --> 12:09.540]  Сравнивайте с тем, что написано на левой части доски.
[12:09.540 --> 12:12.540]  Они, очевидно, взаимно независимы, эти события.
[12:12.540 --> 12:17.540]  Потому что случайная величина x, it независима по условию.
[12:17.540 --> 12:20.540]  Понимаете за мыслью?
[12:20.540 --> 12:23.540]  Вот эти события независимы по i.
[12:23.540 --> 12:28.540]  Потому что x, it независима и случайная величина, значит, эти события тоже независимы.
[12:29.540 --> 12:32.540]  Ну, такая вот функция.
[12:32.540 --> 12:35.540]  Теорема Гливенко-Кантелли говорит следующее.
[12:35.540 --> 12:38.540]  Давайте так, подождите, теорема Гливенко-Кантелли.
[12:38.540 --> 12:42.540]  ЗБЧ, стало быть, что говорит, или усиленный закон больших чисел,
[12:42.540 --> 12:47.540]  он говорит, что это сходится хоть по вероятности, хоть почти на верное,
[12:47.540 --> 12:50.540]  потому что и усиленный закон больших чисел тоже выполняется.
[12:50.540 --> 12:55.540]  К чему это сходится? Одна n-ная сумма индикатора.
[12:55.540 --> 12:59.540]  К вероятности того, что x, it не превосходит x.
[13:01.540 --> 13:05.540]  К вероятности того, нужно писать, x, it не превосходит x,
[13:05.540 --> 13:09.540]  потому что x, it – это конкретная чиселка, а x, it – это та случайная величина,
[13:09.540 --> 13:12.540]  которая ее породила.
[13:12.540 --> 13:17.540]  Я точно понятно выражаюсь? Не очень быстро. Нормально.
[13:17.540 --> 13:22.540]  Но это что? f x, it от x.
[13:22.540 --> 13:28.540]  Но что здесь утверждается? Здесь утверждается, что если число x вещественное вы зафиксировали,
[13:28.540 --> 13:34.540]  тогда вот эта опроксимирующая ступенчатая функция, взятая в этой точке,
[13:34.540 --> 13:39.540]  ростом объема выборки входит как раз к той функции, которую мы ищем,
[13:39.540 --> 13:42.540]  но опять же, взятой в этой точке.
[13:42.540 --> 13:47.540]  То есть, к каждой конкретной точке есть сходимость числовая.
[13:49.540 --> 13:51.540]  Понятно говорю?
[13:51.540 --> 13:54.540]  А вот теорема Гливенко-Кантелли говорит большее.
[13:54.540 --> 13:57.540]  Она говорит следующее, что вероятность,
[13:57.540 --> 14:04.540]  которой supremum по всем x на вещественной прямой
[14:04.540 --> 14:17.540]  модуля разности fn с крышкой от x1 к xn x – f x1 от x, не важно, они все одинаковые,
[14:17.540 --> 14:25.540]  стремится к нулю, fn стремящимся к бесконечности, равна единице.
[14:25.540 --> 14:30.540]  То есть, это не просто усиленный закон больших чисел,
[14:30.540 --> 14:34.540]  а это равномерная сходимость в усиленном законе больших чисел.
[14:34.540 --> 14:37.540]  Это именно усиленный закон, потому что сходимость почти наверная,
[14:37.540 --> 14:40.540]  вероятность, где сходимость есть, равна единице.
[14:40.540 --> 14:44.540]  Но мы не просто берем для конкретной точки x модуль вот этой разности,
[14:44.540 --> 14:46.540]  как в усиленном законе больших чисел,
[14:46.540 --> 14:49.540]  а мы берем supremum этого модуля по всем x,
[14:49.540 --> 14:54.540]  то есть как бы всю трубку между реальной функцией и той, которая ее приближает.
[14:56.540 --> 14:58.540]  Вот берем всю эту бесконечную трубку,
[14:58.540 --> 15:00.540]  на ней смотрим supremum разности,
[15:00.540 --> 15:04.540]  и даже этот supremum стремится к нулю почти наверно,
[15:04.540 --> 15:06.540]  а не просто модуль разности.
[15:10.540 --> 15:12.540]  Понятно, да?
[15:12.540 --> 15:16.540]  Это не сложная на самом деле теория, мы вам ее обязательно докажем.
[15:16.540 --> 15:19.540]  Но Вапника и Черванинки задались вопросом,
[15:19.540 --> 15:21.540]  а можно ли это еще как-то дальше обобщить?
[15:21.540 --> 15:27.540]  Ну, давайте это, наверное, переформулируем на языке вот этих индикаторов еще разок.
[15:27.540 --> 15:31.540]  Значит, у нас получается вот так.
[15:31.540 --> 15:41.540]  У нас есть последовательности a1х, a2x и так далее, anx и так далее.
[15:41.540 --> 15:51.540]  В которых a, it, x – это есть событие, состоящее в том, что xi, it не превосходит x.
[15:51.540 --> 15:58.540]  При этом it у нас пробегает по счетному множеству чисел от единицы до бесконечности,
[15:58.540 --> 16:01.540]  а x – это любое вещественное число.
[16:01.540 --> 16:07.540]  То есть как бы есть целый континуум последовательностей.
[16:08.540 --> 16:12.540]  Для каждого x своя бесконечная последовательность.
[16:12.540 --> 16:17.540]  При этом внутри каждой последовательности выполняется все то же самое, что написано слева.
[16:17.540 --> 16:26.540]  То есть для любого фиксированного x, a, it и x, взаимно независимое.
[16:26.540 --> 16:40.540]  И вероятность a, it и x равняется просто вот этому числу.
[16:40.540 --> 16:43.540]  Давайте его обозначим px.
[16:43.540 --> 16:48.540]  Это не p в степени x, а p с индексом x.
[16:48.540 --> 16:50.540]  Ну, с верхним.
[16:50.540 --> 16:54.540]  Сейчас пока понятно, что происходит?
[16:56.540 --> 17:04.540]  Ну да, видите, я же написал, для любого x, a, it и x взаимно независимые, не наоборот.
[17:04.540 --> 17:10.540]  То есть если я фиксирую x, то внутри такой последовательности они взаимно независимы.
[17:10.540 --> 17:13.540]  Здесь как раз так и сказано.
[17:13.540 --> 17:19.540]  Они там взаимно независимы, и для этого фиксированного конкретного x вероятность каждого из них,
[17:19.540 --> 17:22.540]  Ну тут, наверное, надо написать вот так.
[17:22.540 --> 17:24.540]  Тут не влезает.
[17:24.540 --> 17:28.540]  Для любого i вероятность a, it и x равняется одному и тому же px.
[17:28.540 --> 17:33.540]  Но от x, конечно, эта вероятность зависит.
[17:33.540 --> 17:35.540]  Вот она.
[17:35.540 --> 17:37.540]  Такая.
[17:37.540 --> 17:43.540]  Замечательная.
[17:43.540 --> 17:47.540]  Каким вопросом задались еще раз товарищи Вапник и Черваненко?
[17:47.540 --> 17:53.540]  А что если у нас не вот так вот порожденные события, а как-нибудь там, бог знает как.
[17:53.540 --> 17:59.540]  Просто есть огромное множество каких-то последовательностей событий в общей случае.
[17:59.540 --> 18:07.540]  У нас есть, опять же, последовательность a, it и x,
[18:07.540 --> 18:15.540]  где i меняется от единицы до бесконечности, а x принадлежит какому-нибудь множеству.
[18:15.540 --> 18:19.540]  x красивое, не обязательно вещественное и прямое, там бог знает чему.
[18:19.540 --> 18:28.540]  И опять известно, что для любого конкретного x, a, it и x взаимно независимы, все то же самое.
[18:28.540 --> 18:31.540]  Просто вот этот x большой может быть очень сложный.
[18:31.540 --> 18:37.540]  Он может там, я не знаю, Rn заполнять или вообще какое-нибудь пространство функций, бог знает что.
[18:37.540 --> 18:43.540]  Вот эти ax взаимно независимы и для любого i опять же все то же самое.
[18:43.540 --> 18:49.540]  Вероятность a, it и x равняется px.
[18:49.540 --> 18:51.540]  Каким индекс?
[18:51.540 --> 18:53.540]  px.
[18:53.540 --> 18:58.540]  Вот при каких условиях, вопрос Вапника и Черваненко,
[18:58.540 --> 19:09.540]  при каких условиях вероятность того, что supremum по x маленькое уже просто из этого x большое,
[19:09.540 --> 19:19.540]  как модуля разности i, a, 1, x+, и т.д.
[19:19.540 --> 19:25.540]  плюс i, a, n, t, x, поделить на n,
[19:25.540 --> 19:28.540]  минус px.
[19:28.540 --> 19:33.540]  Травнивайте с теоремы Гливенко-Контельни, но там буквально то же самое написано.
[19:33.540 --> 19:36.540]  Но только в конкретном случае.
[19:36.540 --> 19:40.540]  Как тремиться к нулю? Вероятностью единицы.
[19:40.540 --> 19:47.540]  То есть какие условия гарантируют наличие равномерной исходимости в усиленном законе больших чисел?
[19:47.540 --> 19:52.540]  На классе последовательств.
[19:52.540 --> 19:55.540]  Я понятно спробовал вопрос?
[19:55.540 --> 20:02.540]  Ну вот, собственно, оказалось, что если вы возьмете вероятностное пространство
[20:02.540 --> 20:06.540]  и в нем рассмотрите все возможные вот такие вот последовательности,
[20:06.540 --> 20:11.540]  ну события там живут, вот ваша омега, в котором живут все эти события.
[20:11.540 --> 20:19.540]  И вот есть такое r, которое состоит из а и тх,
[20:19.540 --> 20:25.540]  по i от единицы до бесконечности, и по x из x красиво.
[20:25.540 --> 20:28.540]  Если вы рассмотрите такое ранжированное пространство,
[20:28.540 --> 20:33.540]  то вопрос о том, конечная или бесконечная его размерность вапника Червоненкеса,
[20:33.540 --> 20:37.540]  равносилен положительному ответу на вот этот вопрос.
[20:37.540 --> 20:40.540]  Если размерность вапника Червоненкеса конечна,
[20:40.540 --> 20:44.540]  то усиленный закон больших чисел работает в равномерной форме.
[20:44.540 --> 20:48.540]  Если бесконечно, то не работает.
[20:48.540 --> 20:54.540]  Ну это доказывается там примерно так же, как мы доказывали теорему про треугольники и более общий случай.
[20:54.540 --> 20:56.540]  Но там чуть по-другому надо рассуждать.
[20:56.540 --> 21:00.540]  Я, конечно, этого делать не буду, никаким упражнениям я это не считаю,
[21:00.540 --> 21:04.540]  это довольно сложно, но это такой вот очень мощный факт,
[21:04.540 --> 21:08.540]  который позволяет в том числе делать некоторые оценки,
[21:08.540 --> 21:11.540]  связанные с качеством машинного обучения, со скоростью.
[21:11.540 --> 21:30.540]  Есть в этом некоторая проблема, когда товарищи стояли у основ очень многих методов машинного обучения,
[21:30.540 --> 21:34.540]  вапника Червоненкеса очень много усилий в это вложили,
[21:34.540 --> 21:38.540]  и действительно цитируются по всему миру лучшими специалистами в этой области.
[21:38.540 --> 21:45.540]  Они получили эту оценку, и она дала теоретический результат, который позволил обосновать кучу методов.
[21:45.540 --> 21:51.540]  Но когда мы смотрим на какие-то конкретные реализации, то мы понимаем, что эти оценки очень завышены, это правда.
[21:51.540 --> 21:55.540]  И куча народу после вапника Червоненкеса, например даже наш Воронцов,
[21:55.540 --> 21:59.540]  знаете Константин Вячеславович, нет, не слышали?
[21:59.540 --> 22:05.540]  Такой очень известный лектор по машинному обучению, мне казалось, один из самых популярных в нашей стране.
[22:05.540 --> 22:10.540]  Ну и в ШАДе он преподает, и здесь на Фистехе тоже, сам выпускник Фистеха.
[22:10.540 --> 22:18.540]  Не слышали, не знаю, почему не слышали, но в общем один из самых таких ярких лекторов по машинному обучению,
[22:18.540 --> 22:23.540]  он как ученый занимался именно уточнением оценок вапника Червоненкеса.
[22:26.540 --> 22:30.540]  Ну не только он там много людей этим занимается,
[22:30.540 --> 22:34.540]  но действительно с практической точки зрения это все-таки только затравка такая,
[22:34.540 --> 22:37.540]  с практической точки зрения там дальше надо возиться.
[22:37.540 --> 22:43.540]  Но тем не менее вот с этого все стартовало, когда в 70-м году это было доказано, это был очень значимый шаг.
[22:48.540 --> 22:54.540]  Ну ладно, наверное на этом я завершу эту тематику, все, в общем, системы представителей покрытия,
[22:54.540 --> 23:01.540]  это все я закончу на этом, и наверное перейду сейчас к еще одной теме,
[23:01.540 --> 23:08.540]  чего у меня по времени-то, а я еще только полчаса рассуждаю, и что-то как я, какой я шустрый.
[23:08.540 --> 23:14.540]  Вот, одна тема.
[23:14.540 --> 23:26.540]  В прошлом году я в этом месте рассказывал немножко такой переход, конечно,
[23:26.540 --> 23:31.540]  наверное мне его надо перенести в какую-то другую часть курса.
[23:31.540 --> 23:38.540]  Тема-то красивая, но она просто немножко, наверное, хотя может и нормально,
[23:38.540 --> 23:43.540]  что она после Вапника-Червоненкеса.
[23:43.540 --> 23:49.540]  Помните когда-то на первом курсе все начиналось с вопроса о том,
[23:49.540 --> 23:54.540]  что будет если у нас 15 пятиэлементных подмножис, 30-элементного множества,
[23:54.540 --> 23:59.540]  нет, уже не помните, ну значит у вас здоровый мозг,
[23:59.540 --> 24:05.540]  потому что он отбрасывает то, что вам хотелось забыть, а я сейчас напомню.
[24:05.540 --> 24:11.540]  На самом деле, ну просто в тот момент вы могли не осознать, насколько это полезная штука,
[24:11.540 --> 24:15.540]  но я этим демонстрировал силу принципа Дерехли.
[24:15.540 --> 24:19.540]  Это прям первая лекция была, и я считаю, что тогда это прям очень важно.
[24:19.540 --> 24:23.540]  Если бы я мог рассказывать прямо тогда то, что я могу рассказывать теперь,
[24:23.540 --> 24:27.540]  я бы прямо тогда рассказал, но потому что это действительно такая вещь,
[24:27.540 --> 24:32.540]  тоже связанная с вероятностными методами, и так просто на первом курсе она не получается.
[24:32.540 --> 24:38.540]  Ну давайте я напомню ту задачу, там было две темы про это, я обе темы сейчас напомню, обе разовью.
[24:55.540 --> 25:00.540]  И гиперграф мы с вами знаем, что такое, сейчас конечно легче это все делать,
[25:00.540 --> 25:05.540]  но давайте я напомню ту задачу, которую вы как выяснилось забыли.
[25:05.540 --> 25:11.540]  Значит задача такая, есть множество, состоящее из 30 элементов,
[25:11.540 --> 25:22.540]  30 чисел от 1 до 30, в нем есть подмножество m1 и так далее m15,
[25:22.540 --> 25:29.540]  такие, что мощность каждого из них равняется 5,
[25:29.540 --> 25:33.540]  и утверждение состояло в том, что как бы это ни было расположено,
[25:33.540 --> 25:38.540]  как бы ни было устроено этот 5 однородный гиперграф на 30 вершинах,
[25:38.540 --> 25:41.540]  его хроматическое число не больше двойки.
[25:41.540 --> 26:09.540]  Ну то есть можно так покрасить в два цвета числа от 1 до 30, чтобы каждая мытая была не одноцветна.
[26:11.540 --> 26:27.540]  Не одноцветным это значит, что содержало элементы хотя бы двух различных цветов,
[26:27.540 --> 26:31.540]  но если цветов всего два, значит вот тех самых двух, которые красили.
[26:31.540 --> 26:36.540]  Что, не помните такое?
[26:36.540 --> 26:40.540]  Помнили, да, что была такая задачка?
[26:40.540 --> 26:47.540]  Я говорил, что это как бы иллюстрация на принцип Дерехле, но скорее это все-таки иллюстрация на вероятностный метод.
[26:47.540 --> 26:53.540]  То есть мы чего делаем? Мы каждый из этих чисел с вероятностью 1 вторая красим в красный цвет,
[26:53.540 --> 27:02.540]  с вероятностью 1 вторая в синий, то есть каждое число вот отсюда присваиваемому цвет К,
[27:02.540 --> 27:08.540]  с вероятностью 1 вторая цвет С, с вероятностью 1 вторая.
[27:08.540 --> 27:24.540]  У нас получается 15 событий, события, в которых каждая аитая состоит в том, что митая одноцветна.
[27:24.540 --> 27:30.540]  Это бредные события, как обычно, вероятность которых хочется минимизировать.
[27:30.540 --> 27:34.540]  Нам-то хочется, чтобы все миты были не одноцветны.
[27:34.540 --> 27:39.540]  Вероятность аитого, это понятное дело, сколько?
[27:39.540 --> 27:43.540]  Скажите мне, пожалуйста, присутствующие здесь слушатели,
[27:43.540 --> 27:53.540]  с какой вероятностью данное конкретное множество из пяти элементов при такой случайной бирнуликской покраске будет целиком одного цвета?
[27:54.540 --> 27:56.540]  2 в минус четвертый, правильно.
[27:56.540 --> 28:04.540]  Ну, я напишу 1 шестнадцатая, хотя 2 в минус четвертая это системнее, если бы там n было, 2 в минус n красиво выглядит.
[28:04.540 --> 28:06.540]  Я напишу 1 шестнадцатая, да.
[28:06.540 --> 28:18.540]  Соответственно, вероятность объединения аитах по i от единицы до 15 меньше или равна 15 шестнадцатых, то есть меньше единицы,
[28:18.540 --> 28:22.540]  ну и значит с положительной вероятностью ни одной из этих событий не выполнена,
[28:22.540 --> 28:27.540]  а, стало быть, существует раскраска, в которой все множества не одноцветны.
[28:30.540 --> 28:38.540]  Я не очень быстро это рассказал, вроде эта идеология уже должна, вот уж она должна сидеть просто в мозгу постоянно.
[28:38.540 --> 28:45.540]  Мы с таким сталкивались. Вы даже можете мне сказать, но у нас же есть локальная лемма ловоса.
[28:45.540 --> 28:50.540]  Ну, проблема в том, что тут очень много зависимости априорий, непонятно, что с этим делать.
[28:50.540 --> 29:00.540]  Ну и даже когда мы иллюстрировали локальную лему ловоса, мы вспоминали эту задачу и говорили, что при этом подходе так ее примить-то не получится,
[29:00.540 --> 29:04.540]  а вот если как-то ограничить степень вершины гиперграфа, тогда получится.
[29:04.540 --> 29:07.540]  Помните, я такой пример приводил? Но кто внимательно слушал, тот помнит.
[29:07.540 --> 29:13.540]  Это было прямо в этом семестре на локальной лемме ловоса. Похожую задачу я рассматривал.
[29:13.540 --> 29:23.540]  Вот. Ну вот я сейчас ее еще глубже хочу изучить вместе с вами, потому что она таким рефреном появляется у нас на протяжении всех этих двух лет.
[29:23.540 --> 29:27.540]  Я вам напомню еще одну историю про эту задачу. Может вы вспомните?
[29:30.540 --> 29:35.540]  Значит, смотрите, на первой лекции ОКТЧ она была вот именно в том виде, как сейчас написано.
[29:36.540 --> 29:43.540]  Там я, правда, объяснял ее не так. Я говорил, давайте просто рассмотрим множество тех раскрасок. Ну какая разница?
[29:44.540 --> 29:47.540]  А сейчас я могу оперировать вероятностным языком.
[29:48.540 --> 29:58.540]  Ну хорошо. Потом она действительно возникала в контексте локальной леммы ловоса, когда я рассматривал тоже однородные гиперграфы с ограниченной степенью вершины.
[29:58.540 --> 30:04.540]  Это второй случай, когда возникала эта задача. Но был еще третий случай, когда эта задача возникала.
[30:04.540 --> 30:06.540]  Может кто-нибудь вспомнит?
[30:08.540 --> 30:10.540]  Матрица Адамара, гениально!
[30:10.540 --> 30:12.540]  Которая у нас была на ОКТЧ.
[30:12.540 --> 30:16.540]  На ОКТЧ, да. У вас это уже было на ОКТЧ, конечно.
[30:16.540 --> 30:19.540]  Да, там была задача про дискрепанс, про уклонение.
[30:22.540 --> 30:28.540]  Ну давайте я сформулирую сначала вот эту задачу в общем виде, а потом в общем виде напомню, что такое дискрепанс.
[30:29.540 --> 30:35.540]  Значит, в общем виде задача, с которой мы столкнулись, понятное дело, как звучит.
[30:36.540 --> 30:49.540]  Давайте рассмотрим произвольный эноднородный гиперграф.
[30:49.540 --> 30:57.540]  Так, из всякой очередной мелок. Ладно, я все-таки не буду больше экономить. Не возьму большой. Тут есть.
[30:57.540 --> 31:01.540]  Это я просто пытался сэкономить для института мел.
[31:01.540 --> 31:05.540]  Так, рассмотрим произвольный эноднородный гиперграф.
[31:05.540 --> 31:12.540]  Давайте назовем его хроматическим числом. Понятно, что? Я, наверное, уже это говорил, да?
[31:12.540 --> 31:14.540]  Я давал это определение?
[31:14.540 --> 31:18.540]  Мне кажется, что давал. Давайте я еще раз повторю, потому что люди забыли.
[31:18.540 --> 31:24.540]  Хроматическое число гиперграфа, ну это как обычно минимальное число цветов, в которые красятся его вершины,
[31:24.540 --> 31:31.540]  все то же самое, как у графа. Но с условием, что в каждом ребре есть вершины хотя бы двух различных цветов.
[31:31.540 --> 31:38.540]  То есть даже если вы краете в десять цветов, не нужно, чтобы в каждом ребре присутствовали все десять цветов.
[31:38.540 --> 31:42.540]  Нужно, чтобы каждое ребро было просто не одноцветным.
[31:42.540 --> 31:44.540]  Я не знаю, нужно что-то писать на доске?
[31:44.540 --> 31:51.540]  Минимальное число цветов, которые можно так покрасить вершины, чтобы каждое ребро получилось не одноцветным.
[31:51.540 --> 31:58.540]  Вот рассмотрим произвольный эноднородный гиперграф H, ну там с каким-то множеством вершин,
[31:58.540 --> 32:03.540]  с каким-то множеством вершин, с каким-то множеством вершин.
[32:04.540 --> 32:10.540]  Вот рассмотрим произвольный эноднородный гиперграф H, там с каким-то множеством вершин,
[32:10.540 --> 32:18.540]  с каким-то множеством ребер. Такой, что его хроматическое число равняется двойке.
[32:18.540 --> 32:23.540]  Он называется такой двудольный эноднородный гиперграф.
[32:23.540 --> 32:28.540]  Прям в классическом смысле слова, двудольный граф, граф, у которого хроматическое число два.
[32:28.540 --> 32:34.700]  два. Ну и здесь тоже двудольный гиперграф, у него хроматическое число два. Всего вершины можно
[32:34.700 --> 32:42.500]  покрасить таким образом в два цвета, чтобы каждое ребро было не одноцветно. Нас интересует вопрос
[32:42.500 --> 32:54.380]  от искания величины наименьшего количества ребер в таком гиперграфе. Наименьшего количества
[32:54.820 --> 33:00.300]  ребер в таком гиперграфе. Нет, сейчас, глупость сказал. Мы говорим, рассмотрим произволенный
[33:00.300 --> 33:07.660]  однородный гиперграф с хроматическим числом два. Наоборот тогда нас интересует, видимо,
[33:07.660 --> 33:18.220]  максимальное количество ребер в этом графе. Насколько большим оно может быть. Ну давайте
[33:18.220 --> 33:23.260]  я по-другому все-таки скажу, просто напишу формальное определение и все станет совершенно
[33:23.620 --> 33:31.220]  понятно. Я только запутаю слушателей. Давайте m от n. Ведем такое обозначение. Это будет
[33:31.220 --> 33:43.500]  все-таки минимум. Треди всех таких k, то существует n однородный гиперграф
[33:43.500 --> 34:03.020]  к ребрами и х больше двойки. Наоборот, больше. Ну то есть найти максимальное количество ребер в
[34:03.020 --> 34:10.740]  гиперграфе, который красятся в два цвета, это с точностью до разницы в единичку, найти минимальное
[34:10.740 --> 34:15.620]  k, при котором существует однородный гиперграф с ребрами и не красящийся в два цвета.
[34:20.820 --> 34:28.260]  Так, я уверен, что не все понимают определение, потому что много кванторов. Это надо осознать. Вот,
[34:28.260 --> 34:36.300]  смотрите, здесь есть конкретное утверждение. Любой 5 однородный гиперграф с 15 ребрами можно
[34:36.300 --> 34:43.180]  покрасить в два цвета. Правда, это утверждение на 30 вершинах, но, товарищи, согласитесь,
[34:43.180 --> 34:50.580]  что никакой же разницы нет. Было бы 50 вершин, что-то бы в том рассуждении, которое я стер,
[34:50.580 --> 34:59.140]  изменилось, да ничего бы не изменилось. Размеры ребер те же самые, 5. Поэтому вероятность как была,
[34:59.140 --> 35:05.260]  одна шестнадцатая, так и останется. Ребер самих 15 штук, 15-16 меньше единицы. Все хорошо.
[35:05.340 --> 35:12.220]  То есть, 30 здесь никакой роли не играет. Ну, короче, что мы можем сказать про m от 5,
[35:12.220 --> 35:29.500]  исходя вот из этого утверждения? Полуторгодичной давности. Не больше? Больше 15, правильно? Больше 15.
[35:29.500 --> 35:40.140]  Любой 5 однородный гиперграф с 15 и менее ребрами красится в два цвета. А чтобы существовал
[35:40.140 --> 35:44.500]  5 однородный гиперграф с к ребрами, который не красится в два цвета,
[35:44.500 --> 35:51.500]  стало быть, требуется больше, чем 15 ребер. Нормально сейчас объяснил? Сейчас понятно,
[35:51.500 --> 36:02.980]  что такое m от n. Так, ну, наверное, теорема 1, это обобщение того, что мы вот здесь написали,
[36:02.980 --> 36:17.820]  можно написать вот так. Больше, чем 2 в степени n-1. Так, плюс один, что ли? Или минус один? Это как-то
[36:17.820 --> 36:27.460]  вот так. 2 в степени n-1-1. Так, дорогие товарищи, понятно, что для произвольного
[36:27.460 --> 36:33.220]  однородного гиперграфа все то же самое рассуждение проходит. Там просто вероятность события будет
[36:33.220 --> 36:41.940]  2 в степени 1-n. И поэтому надо умножать на 2 в степени n-1, чтобы получить меньше единицы.
[36:41.940 --> 36:51.820]  Ну, на что-то меньшее, чем 2 в степени n-1. Вот хотя бы так. Ну, или что то же самое. Мне
[36:51.820 --> 37:01.780]  приятнее писать вот так. m от n больше либо равняется 2 в n-1. Ну, это то же самое. Так,
[37:01.780 --> 37:07.540]  давайте устраивать перерыв, наверное, а потом… Да, для малых n это очень хорошо, действительно,
[37:07.540 --> 37:12.660]  прокомментировать, что будет для малых n с этой величиной. С табличкой все плохо, потому что
[37:12.660 --> 37:18.700]  неизвестно почти ничего. Но для каких-то малых n это полезно посмотреть. Давайте, действительно,
[37:18.700 --> 37:46.860]  посмотрим. Сейчас я все сотру здесь. Так. Ну, смотрите, m от 2 – это, конечно, первое,
[37:47.620 --> 37:53.020]  потому что если n равно единице, то непонятно, как красить два цвета, чтобы ребро получилось
[37:53.020 --> 37:58.820]  неодноцветным. Если n равно единице, то в каждом ребре одна вершина, но это бессмыслится какая-то.
[37:58.820 --> 38:06.300]  Вот. m от 2 – это когда у нас не гиперграф, а обычный граф. В каждом ребре две вершины. Ну,
[38:06.340 --> 38:18.180]  и чему равно m от 2 – это очень просто. Минимальное число ребер в графе,
[38:18.180 --> 38:26.900]  которые не красятся в два цвета. Ребер два, красят же всегда. Три, конечно, треугольник,
[38:26.900 --> 38:32.540]  просто возьмите. И это тот самый пример графа с тремя ребрами, который не красятся в два цвета,
[38:32.540 --> 38:37.340]  хотя бывают, конечно, графы с тремя ребрами, которые и красятся. Но здесь квандросуществование
[38:37.340 --> 38:46.740]  стоит, поэтому m от 2 равняется 3. Уже m от 3 – это нетривиальная задача. Ну, равняется это 7.
[38:48.740 --> 38:52.140]  Можете попробовать самостоятельно. Я не буду сейчас на это время тратить.
[38:52.140 --> 39:03.620]  Но, в общем, это уже не очевидно. m от 4 – боюсь соврать. Посчитали совсем недавно, буквально лет
[39:03.620 --> 39:09.460]  пять, может быть, назад с участием компьютера. По-моему, 2 от 1 получилось, но я напишу под
[39:09.460 --> 39:16.620]  вопросом, потому что могу ошибаться. Вот. Ну, вообще видно, что растет, наверное, все-таки
[39:16.620 --> 39:25.380]  экспоненциально. Ну, так понятно, m от n больше, чем 2 в степени на минус 1, растет экспоненциально.
[39:25.380 --> 39:32.340]  Но как в точности – это уже другой вопрос. m от 5 неизвестно. То есть вот мы с вами знаем,
[39:32.340 --> 39:38.700]  что m от 5 больше либо равняется 16, но можно на это еще посмотреть чуть подробнее потом, попозже.
[39:38.700 --> 39:48.100]  Хорошо. Ну, давайте зададимся вопросом, чему его точно не превосходит m от n. Пусть это будет
[39:48.100 --> 40:01.620]  теорема 2, которая простая совсем. Его m от n не превосходит. Есть очень простой пример n однородного
[40:01.620 --> 40:08.500]  гиперграфа, который нельзя покрасить в два цвета, так чтобы каждый ревро был не одноцветным.
[40:08.500 --> 40:23.620]  Это прямое обобщение треугольника? Нет, полный, да, полный однородный гиперграф на
[40:23.620 --> 40:32.620]  скольких-то вершинах. Конечно, да, треугольник – это полный граф на трех вершинах тривиальным
[40:32.620 --> 40:44.820]  образом. Но я, в общем, утверждаю, что это не больше, чем c из 2n-1 по n, потому что можно взять вот
[40:44.820 --> 40:53.300]  столько вершин и рассмотреть полный однородный гиперграф. Если вы 2n-1 вершину покрасите в
[40:53.300 --> 41:04.260]  два цвета, то какие-то n вершин будут обязательно покрашены в один цвет. Согласны? Если вы 2n-1 вершины
[41:04.260 --> 41:09.380]  тоже принадлежит директе, покрасили в два цвета, то какие-то n из них покрашены в один цвет. А у нас
[41:09.380 --> 41:14.500]  все n-элементные подмножства служат ребрами. Значит, невозможно так покрасить в два цвета,
[41:14.500 --> 41:23.860]  чтобы каждое ребро было не одноцветным. Какое это выбьется? Вот пример с 2n-1 вершинами,
[41:23.860 --> 41:33.460]  с таким количеством ребр. Ну как мы все с вами хорошо знаем, это 2 в степени 2n-1 поделить на
[41:33.460 --> 41:38.940]  корень из pn. Это же прямо про числа Рамсея, можно сказать, оценка. Мы сто раз это писали,
[41:38.940 --> 41:45.140]  поэтому это можно уже наизусть запоминать. Ну в общем, грубо говоря, это 4 в н степени,
[41:45.140 --> 42:01.700]  а тут 2 в н степени. Хреново как-то. Ну давайте теорема 3. Против скрипанс я тогда в другой раз
[42:01.700 --> 42:06.780]  напомню. Сейчас уже так хорошо как-то пошло вот в эту стезю про уклонение напомню в следующий
[42:06.780 --> 42:20.020]  раз. Не успи. Значит, можно доказать вот такую штуку. m от n не превосходит 1 плюс о малой от единицы
[42:20.020 --> 42:31.300]  елогарифом двойки на 4, n квадрат на 2 в степени. То есть на самом деле m от n зажато довольно тесно,
[42:31.300 --> 42:38.260]  а симпатически, в отличие от тех же чисел Рамсея, здесь видите нижняя оценка 2 в н минус 1,
[42:38.260 --> 42:43.780]  ну то есть грубо говоря 2 в н. А верхняя оценка с точностью до константы это n квадрат на 2 в н.
[42:43.780 --> 42:52.180]  Зазор неэкспоненциальный. Но, конечно, здесь это явный пример, а это мы сейчас будем доказывать
[42:52.180 --> 43:01.260]  тоже вероятностным методом. Но что значит доказать верхнюю оценку вероятностным методом? Это значит
[43:01.260 --> 43:10.140]  доказать, что существует гиперграф. Ну значит, гиперграф надо брать случайно. Ну сейчас сделаем.
[43:13.780 --> 43:28.420]  Давайте будем считать для простоты, что n четно. Для нечетного там все так же делается,
[43:28.420 --> 43:35.260]  не хочу морочить голову, пусть n будет четным. Просто упрощаю немножко рассуждение, чтобы лишнего
[43:35.260 --> 43:43.140]  не писать. Возьмем v равное n квадрат пополам. Ну, как до этого додумались, это уже вопрос другой.
[43:43.140 --> 43:48.540]  Ну так вот, додумались. Я вам напишу формулировку в духе числа Рамсея, такую компьютерную,
[43:48.540 --> 43:54.380]  помните? Как перебором там что-то найти. Ну вот люди так и догадались, что это оптимальная ситуация.
[43:54.380 --> 44:03.580]  Возьмем v равное n квадрат пополам и в качестве множества вершин возьмем числа от единицы до v.
[44:03.580 --> 44:12.060]  Наша задача построить гиперграф, у которого вот столько ребер и который в два цвета не красится.
[44:12.060 --> 44:20.140]  Правильно? Такой же нам нужен гиперграф. Множество вершин мы вольны выбирать как угодно,
[44:20.140 --> 44:26.260]  вот выбрали таким загадочным способом. Я утверждаю, что оптимально в качестве количества вершин взять
[44:26.260 --> 44:31.820]  почему-то n квадрат пополам. Но n квадрат пополам делится, поскольку мы предположили, что n четно.
[44:31.820 --> 44:39.700]  А ребра на этом множестве вершин уже будем выбирать случайно. Давайте обозначим просто
[44:39.700 --> 44:45.060]  буквой m количество ребер. Потом наша цель доказать, что m вот такое можно взять.
[44:45.060 --> 45:06.380]  m количество ребер. Цель доказать, что можно взять m асимпатически равным елогарифом
[45:06.380 --> 45:13.100]  двойки на 4n квадрат на 2v. Я думаю, что мы даже с подвигнем сейчас это сделать,
[45:13.100 --> 45:18.460]  потому что это не очень сложно. Вы настолько уже должны были привыкнуть к этим асимпатикам,
[45:18.460 --> 45:26.300]  что кажется это не очень сложно. Ну или как та лошадь цыганская, конечно, привыкли, но сдохли.
[45:26.300 --> 45:37.140]  Будем надеяться на лучшее. Смотрите, давайте ребра выбирать взаимно-независимо. Выбираем
[45:37.140 --> 45:47.340]  ребра взаимно-независимо, то есть с возвращением. Давайте так я скажу. Я, по-моему, уже это употреблял
[45:47.340 --> 45:58.060]  термин, можно не комментировать снова. Выбираем ребра с возвращением, ну согласно классическому
[45:58.060 --> 46:16.500]  определению вероятности. Ну то есть что это значит? Мы берем какое-то ребро, как его обозначить,
[46:16.500 --> 46:25.660]  а1, например, и вероятность того, что мы выбираем именно это конкретное а1, это 1 поделить на c из
[46:25.660 --> 46:32.380]  v по n. Нам же нужен n однородный гиперграф, просто возле этих v вершин выбираем произвольное n
[46:32.380 --> 46:39.340]  случайным образом. Классическое определение вероятности. Потом запоминаем, какое выбрали,
[46:39.340 --> 46:45.500]  возвращаем на место и выбираем еще одно, может быть снова его же. Как повезет. Ну процесс,
[46:45.500 --> 46:49.660]  процесс прямо такой же, как в доказательстве теоремы в аптеке червонемца из прошлой лекции,
[46:49.660 --> 46:57.100]  только там не ребра выбирали, а элементы выбирали. Берем ребро, возвращаем на место,
[46:57.100 --> 47:09.140]  но выбираем еще одно случайное и так далее. Ам тоже выбираем с вероятностью 1 на c из v по n.
[47:09.140 --> 47:14.940]  Ну то есть теоретически они могут все совпасть, но для нас это только хорошо,
[47:14.940 --> 47:23.220]  потому что если у нас в гиперграфе будет мало ребер, нам естественно от этого тем лучше. Понятно
[47:23.220 --> 47:29.900]  говорю? То есть ребра, которые не дай бог совпадут, мы просто отреждествуем. Если мы докажем,
[47:29.900 --> 47:35.020]  что с вероятностью положительной вот такой вот случайный гиперграф не красятся в два цвета,
[47:35.020 --> 47:43.260]  ну все, мы в героях. При вот таком выборе мы. Наша цель доказать, что с положительной вероятностью
[47:43.260 --> 47:49.420]  вот эта штуковина после отреждествления совпадающих ребер не красятся в два цвета.
[47:49.420 --> 48:01.220]  Никак. Ну давайте вот попробуем еще тут что-нибудь пописать. Нам нет мало места. Мало. Поехали стирать.
[48:19.420 --> 48:35.500]  Так, а это тоже. Да, слушайте, пока я не продолжил, я вот здесь вот остановлюсь на секунду. Смотрите,
[48:35.500 --> 48:42.780]  если вот в эту теорему 2 подставить вместо n пятерку, то получится t из 9 по 5, то есть 126,
[48:42.780 --> 48:52.300]  это я помню. То есть для m от пятерки вот здесь мы получаем оценку не больше, чем 126. А как вам
[48:52.300 --> 48:59.700]  зазорчик от 16 до 126? Из этой теоремы в том виде, как она сейчас сформулирована, непонятно,
[48:59.700 --> 49:06.660]  что следует про m от 5, потому что что такое у малой от единицы, я же не конкретизировал. Какая тут
[49:06.660 --> 49:12.060]  функция стоит, тремящееся к нулю. Тем не менее, сейчас вот мы по ходу доказательства вероятности
[49:12.060 --> 49:18.100]  пооцениваем, и я переформулирую теорему 3 не вот в таком асимпатическом виде, а в компьютерном,
[49:18.100 --> 49:25.260]  и будет вам задача найти для пяти самый лучший оценку. Ну просто вот чтобы осознать,
[49:25.260 --> 49:29.780]  что происходит. Прямо на компьютере. Я не знаю, я просто никогда не читал. Мне,
[49:29.780 --> 49:37.820]  например, интересно. Всё, возвращаюсь к доказательству. Так, давайте зафиксируем раскраску.
[49:37.820 --> 49:53.260]  Множество 1, 2 и так далее. В маленькое, в два цвета. Она не случайная. Раскраска какая-то,
[49:53.260 --> 49:57.860]  просто конкретная. Но вы можете, конечно, как принято у молодых людей, сказать рандомная,
[49:57.860 --> 50:02.180]  но это не в том смысле, как мы понимаем, случайность. Случайный у нас, товарищи,
[50:02.180 --> 50:08.420]  гиперграф. Вероятностное пространство состоит из гиперграфов. И мы сейчас просто временно
[50:08.420 --> 50:15.860]  фиксируем какую-то раскраску, чтобы определить события, состоящие из гиперграфов. Какое-то
[50:15.860 --> 50:23.060]  свойство гиперграфа. Ну давайте я эту раскраску как-то в буквы Х обозначу. На всякий случай
[50:23.060 --> 50:29.420]  напомню вам, что всего этих раскрасок, конечно же, 2 в степени В. Но это очевидно,
[50:29.420 --> 50:35.340]  сколько раскрасок в два цвета на множестве из В элементов. 2 в степени В. Вот какую-то одну из
[50:35.340 --> 50:40.860]  этих 2 в степени В раскрасок мы сейчас фиксируем. Давайте попробуем найти вероятность того,
[50:40.860 --> 50:55.340]  что А1, прямо А1, первое ребро одноцветно, именно одноцветно в раскраске Х. Ну что может,
[50:55.340 --> 51:05.540]  здесь вы мне какой-нибудь мудрый вопрос зададите или нет. Вот дана конкретная раскраска, то есть
[51:05.540 --> 51:10.900]  разбиение на две какие-то непересекающиеся части, может быть, разных мощностей вот этого множества.
[51:10.900 --> 51:15.980]  Раскрасили в два цвета, скажем, первый элемент красный, все остальные синие. Там 10 элементов
[51:15.980 --> 51:21.620]  красных каких-то, остальные синие. Вот она дана уже, эта раскраска. Теперь берем случайное подмножество
[51:21.620 --> 51:25.980]  и хотим посчитать, что это подмножество одноцветно вот в этой конкретной раскраске.
[51:25.980 --> 51:34.020]  Чего нам не хватает, чтобы эту вероятность посчитать? Совершенно верно! Надо знать,
[51:34.020 --> 51:43.980]  сколько вершин, например, красного цвета. Одного достаточно, потому что второго В минус первого.
[51:43.980 --> 51:51.460]  Ну, можно, конечно, для симметрии сказать, что пусть К вершин красного, С вершин синего,
[51:51.460 --> 52:03.340]  но понятно, что К плюс С равняется В. Нормально? Буквы ничем не путаются. К, С,
[52:03.340 --> 52:12.060]  вроде тут таких не было. Так, ну вот если нам все-таки дано, что в этой раскраске ХК красных вершин
[52:12.060 --> 52:22.220]  и С синих, то как вероятность устроена? Так, ну в знаменателе очевидно С из В по Н, а в числителе
[52:22.220 --> 52:37.980]  правильно С из К по Н плюс С из С по Н. С из С, понимаете, тут С и С в разных языках. Так,
[52:37.980 --> 52:42.540]  ну, дорогие товарищи, у нас с вами уже было такое свойство в этом году, как выпуклость
[52:42.540 --> 52:47.980]  биномиального коэффициента. Она упоминалась, когда мы доказывали оценки для двудольных чисел
[52:47.980 --> 52:58.060]  рамсе. И она нам говорит, что вот это все не меньше, чем два С из В пополам по Н поделить на С из В по Н.
[52:58.060 --> 53:10.180]  Ну это выпуклость. К плюс С равняется В, поэтому можем вот так написать. А это уже, слава богу,
[53:10.180 --> 53:16.460]  не зависит ни от К, ни от С. Это общее для всех ХИ. Давайте временно вот эту штучку обозначим
[53:16.460 --> 53:22.700]  буквой П маленькая, которую у нас вроде пока не было. Да, буквой П маленькая обозначим.
[53:22.700 --> 53:34.660]  Прекрасно, тогда вероятность того, что А1 не одноцвет на ХИ, ну просто берем отрицание события,
[53:34.660 --> 53:50.100]  не больше, чем один минус П. Согласны? Тогда вероятность того, что для любого И АИТ не одноцветна
[53:50.100 --> 54:03.660]  вот в этой конкретной ХИ, как оценивается? Какой? Сколько ребер, правильно? А ребер М-штук,
[54:03.660 --> 54:09.980]  вот здесь написано. Ребер М-штук. Значит, ввиду независимости их выбора взаимной,
[54:09.980 --> 54:25.060]  получаем один минус П в МТ-степени. Ну тогда вероятность того, что существует раскраска такая,
[54:25.060 --> 54:38.340]  что для любого И АИТ не одноцветна в этой раскраске, которая существует, не больше чего, товарищи,
[54:38.340 --> 54:49.860]  два в степени В, вот здесь написано не в МТ, а в этой, два в степени В на один минус П в степени М.
[54:49.860 --> 55:00.500]  Ну как всегда существует это объединение, перебор в случае. Так, ну и все. Значит, вероятность
[55:00.500 --> 55:11.300]  того, что для любого ХИ найдется и такое, что АИТ одноцветна, снова переворачиваем, рассматриваем
[55:11.300 --> 55:26.000]  отрицание, больше либо равна один минус два в степени В на один минус П в МТ-й. Ну а что такое
[55:26.000 --> 55:32.940]  написано здесь в подкопках? Какова бы ни была раскраска, найдется одноцветное ребро. Вероятность
[55:32.940 --> 55:39.460]  на множество гиперграфов берется, то есть здесь вот здесь в подкопках написано множество таких
[55:39.460 --> 55:48.060]  гиперграфов, для которых любая раскраска находит хреновое ребро, натыкается на хреновое ребро.
[55:48.060 --> 56:03.620]  Если вот здесь меньше единицы, то здесь больше нуля и мы победили. То есть компьютерная формулировка
[56:03.620 --> 56:11.620]  такая. Теорема... Какая она у нас по счету? Три. Вот давайте, теорема три штрих. Компьютерный
[56:11.620 --> 56:38.140]  вариант формулировки. Пусть для данного N, для данного N число В таково... Не понял?
[56:38.140 --> 56:49.420]  Наверное числа М и В таковы. То что? Нет, мы тут его зафиксировали, потому что это я такой умный,
[56:49.420 --> 56:55.220]  а я-то вам хочу оптимальную компьютерную формулировку написать. Не такую, из которой вот эта
[56:55.220 --> 57:01.780]  асимптотика получается, а такую, которую надо применять к М от пяти, например. Там же нет никакой
[57:01.780 --> 57:19.180]  асимптотики. Наверное, да, вы правы. Числа В и М таковы, числа В и М таковы, то существует... А что
[57:19.180 --> 57:29.300]  существует? Что-что? Да-да-да, тут ничего не надо. Существует глупость. Скал таковы, что выполняется
[57:29.300 --> 57:36.380]  неравенство до 2 в степени В на единица минус П в степени М меньше одного, где П вот это вот.
[57:36.380 --> 57:52.180]  Всё. Тогда М от N меньше либо равняется... Вот. Вы берете N равное пяти, и ни в коем случае не берете
[57:52.180 --> 57:59.740]  В равное именно там 25 вторых или целая часть от 25 вторых. А просто бежите в цикле по всем В,
[57:59.740 --> 58:05.500]  там начиная от пяти, наверное, потому что до пяти вообще бессмысленно, но всё-таки на этих вершинах
[58:05.500 --> 58:10.980]  должно умещаться хотя бы одно ребро. Вот. Бежите в цикле по В. Вы там убедитесь в том, что при
[58:10.980 --> 58:16.620]  достаточно больших N, N квадрат пополам примерно и надо брать. Вы это просто увидите, если будете
[58:16.620 --> 58:23.300]  считать на компьютере. Но так просто тупо запускаете цикл по В, и для каждого В ищите
[58:23.300 --> 58:29.260]  самое маленькое М, при котором это выполняется. То есть внутренний цикл, он по М, и вы хотите
[58:29.260 --> 58:36.020]  найти такое минимальное М, что при данном В выполнено вот это неравенство. И потом
[58:36.020 --> 58:44.780]  ищете глобальный минимум по всем В. Ламэ. Так, я понятно сформулировал? Ну, это, знаете,
[58:44.780 --> 58:59.740]  это алгоритм-то не огорвало каяло с аксены, правда? Что-то очень простое. Да-да-да, вот огорвал,
[58:59.740 --> 59:04.820]  каял с аксены, это действительно торжество человеческой мысли. А тут-то чё? Тяп-ляп.
[59:04.820 --> 59:13.660]  Ну, можете попробовать просто для МАТ-5 пооптимизировать, понять при каком В находится самое маленькое М. Какое это
[59:13.660 --> 59:19.340]  будет самое маленькое М? Ну, я уверен, что оно будет меньше, чем 126. Но насколько меньше? Это
[59:19.340 --> 59:23.900]  интересный вопрос. Я не знаю, я не считал никогда. Может кто-то и считал, но я не знаю даже, где это
[59:23.900 --> 59:30.700]  посмотреть. В следующем году расскажу студентам, что вот мои студенты прошлого года, третьекурсники
[59:30.700 --> 59:38.460]  нынешние, нашли это. Вот я вам теперь показываю. Потом они мне расскажут, скажут, что это ошибка была. Так,
[59:38.460 --> 59:44.260]  ну ладно, в общем, вот такая формулировка вполне понятная, обозримая. Но наша задача теперь убедиться
[59:44.260 --> 59:50.500]  в том за оставшееся время, что действительно, если взять В равное n квадрат пополам, как мы и сделали,
[59:50.500 --> 59:56.940]  и М вот такого вот вида, с каким-то подходящему маленьким от единицы, то неравенство будет
[59:56.940 --> 01:00:01.740]  выполнено. Это довольно такая все-таки муторная задача, потому что смотрите, какие тут цешечки
[01:00:01.740 --> 01:00:07.980]  прекрасные. Но мы умеем считать такие цешечки. Можно я посчитаю честно? Ну что ж, позориться-то.
[01:00:07.980 --> 01:00:13.540]  То есть я мог бы на этом остановиться в рамках доказательств и сказать, ну все, все получилось.
[01:00:13.540 --> 01:00:21.300]  Но все-таки тут не так сложно. А у нас анализ с вами дискретный.
[01:00:26.940 --> 01:00:32.380]  Вот тут есть это М.
[01:00:32.380 --> 01:01:01.740]  Так, ой, c из n квадрат пополам по n. Ну давайте c из v по m. Это v на v минус 1.
[01:01:01.740 --> 01:01:08.660]  Стандартная вещь на v минус n плюс 1 на n факториал. Стандартная в том смысле, что мы много раз такие
[01:01:08.660 --> 01:01:16.700]  штуки писали. Они уже приестся даже должны. Это v в степени n поделить на n факториал, 1 минус 1 на v,
[01:01:16.700 --> 01:01:27.980]  1 минус n минус 1 на v. Догоняем в экспоненту v в степени n, n факториал, e в степени,
[01:01:27.980 --> 01:01:38.660]  и раскрываем по Тейлору. Уже делали такое много раз. Не хочу на это подробно заострять внимание.
[01:01:38.660 --> 01:01:50.500]  1 на v квадрат минус 1 квадрат на v квадрат. Вот так. Ну узнаете, конечно. Да, логариф мы просто
[01:01:50.500 --> 01:02:02.100]  раскрывали. Точно это было множество раз. Так, это равно v в степени n на n факториал,
[01:02:02.100 --> 01:02:13.260]  e в степени минус n, n минус 1 на 2v. Просуммировала ритмическую прогрессию. Плюс о большое от n в
[01:02:13.260 --> 01:02:26.380]  кубе на v в квадрате. Ну v тоже можно здесь выписать, равно n квадрат пополам. Здесь стоит пункция
[01:02:26.380 --> 01:02:32.540]  квадратичная, а нет, вот здесь стоит пункция кубическая, а здесь четвертая степень. v в квадрате
[01:02:32.540 --> 01:02:39.860]  это n в четвертый. Поэтому вот эта вся штука стремится к нулю. Мы можем писать это асимптатически
[01:02:39.860 --> 01:02:47.900]  равно v в степени n поделить на n факториал, умножить на e в степени минус n квадрат на 2v
[01:02:47.900 --> 01:02:58.340]  плюс n на 2v. Ну n на 2v снова, конечно, стремится к нулю. Асимптатически равно v в степени n на n
[01:02:58.340 --> 01:03:04.660]  факториал, e в степени просто минус n квадрат на v. Ну и вот так примерно угадывается, конечно,
[01:03:04.660 --> 01:03:09.660]  что v должно быть порядка n в квадрате. Значит, если вы берете v равное n квадрат пополам,
[01:03:09.660 --> 01:03:18.100]  то здесь получается в итоге v в n на n факториал, e в минус 2. Видите, как легко? Ну легко же,
[01:03:18.100 --> 01:03:24.980]  правда. Привычно, обычно, ничего тут такого страшного нет. Совершенно аналогично c из v пополам
[01:03:24.980 --> 01:03:37.620]  по n. Оно же тоже тут присутствует в определении p маленького. Что, потерял где-то двоечку? А вот
[01:03:37.620 --> 01:03:44.860]  весь 2v. Ой, да, это e в минус 1. Обычно, привычно наопечатался. Спасибо большое. Обсчитался.
[01:03:44.860 --> 01:03:57.260]  Так, ну совершенно аналогично. Это асимптатически равно v пополам v на n факториал. Вот на e в какой
[01:03:57.260 --> 01:04:04.300]  степени? Можете сообразить. Но на самом деле легко. Вот здесь просто вместо v будет v пополам. И вот
[01:04:04.300 --> 01:04:11.060]  здесь будет e в минус 2. Вот здесь будет e в минус 2. Совершенно так же считается. Соответственно,
[01:04:11.060 --> 01:04:25.860]  p, который у нас 2c из v пополам по n поделить на c из v по n, это будет что такое? Значит,
[01:04:25.860 --> 01:04:39.940]  v в n сократится, n факториалы сократятся. Останется 1 поделить на 2 в n, но умножить на 2. То есть
[01:04:39.940 --> 01:04:48.660]  это будет 2 в степени 1 минус n. Услеживаете? Не ошибся я нигде. Еще раз, c из v пополам по n. Тут
[01:04:48.660 --> 01:04:57.460]  одна вторая в n, это 2 в минус n. Нет, e сейчас будет. Да, я не говорю, что это все. Еще надо будет
[01:04:57.460 --> 01:05:05.780]  действительно e в минус 2 поделить на e в минус 1. И это будет e в минус 1. Правильно, еще e. Теперь
[01:05:05.780 --> 01:05:15.780]  правильно все? Да, теперь получается e в минус 1, конечно. Теперь возвращаемся к 2 в степени v на 1
[01:05:15.780 --> 01:05:25.100]  минус p в n-ты степени. Это, конечно, не больше, чем 2 в степени v на e в степени минус pm, но тоже
[01:05:25.100 --> 01:05:30.660]  стандартное неравенство. Опять загоняем 1 минус p в показатель экспоненты, там будет логарифма от
[01:05:30.660 --> 01:05:41.420]  1 минус p. Он не больше, чем минус p. Это много раз тоже использовали. Так, ну что, p у нас посчитано.
[01:05:41.420 --> 01:05:53.940]  Сейчас все увидим. Будет катапсис. 2 в степени n квадрат пополам. Это я v переписал. Так, мы,
[01:05:53.940 --> 01:06:01.260]  наверное, сведем все к показателю e. Значит, будет e в степени n квадрат пополам на логарифм
[01:06:01.260 --> 01:06:08.620]  натуральной двойки. Это я 2 в степени v переписал. Видите, да? 2 в степени v это e в степени логарифм
[01:06:08.620 --> 01:06:16.180]  двойки, умноженный на v, а v это n квадрат пополам. Теперь я из этого вычитаю. Где тут у меня p? 2 в
[01:06:16.180 --> 01:06:30.380]  степени 1 минус n на e в минус 1, это минус p. И вот надо умножить на m. Ну что, по-моему,
[01:06:30.380 --> 01:06:40.700]  сейчас все сократится, смотрите. e логарифм 2. Не видно? Ну давайте я вот так перепишу. 2 в степени
[01:06:40.700 --> 01:06:57.020]  1 минус n на e в минус 1, на m это равно 1 плюс о малой от 1. Так, на 2 в степени 1 минус n на e в
[01:06:57.020 --> 01:07:16.580]  минус 1, на e на логарифм 2, о боже мой, на 4 и на 2 в степени n. Хлёп! Хлёп! Хлёп! Хлёп!
[01:07:16.580 --> 01:07:31.340]  Что у меня получилось? А, еще! То есть осталось только логарифм двойки пополам, а n квадрат я
[01:07:31.340 --> 01:07:38.260]  потерял. Осталось логарифм двойки пополам и n квадрат, ну и тут тоже логарифм двойки пополам
[01:07:38.260 --> 01:07:45.900]  и n квадрат. Но просто вот здесь за счет этого 1 плюс о малой от 1 мы можем вычесть так,
[01:07:45.900 --> 01:07:51.180]  чтобы получилось минус что-то, стремящееся к бесконечности. Ну хотите, чтобы было понятнее,
[01:07:51.180 --> 01:07:56.460]  здесь напишу 1 плюс епсилон, как всегда, но так всегда понятнее. Берем просто какое-то
[01:07:56.460 --> 01:08:03.300]  епсилон, большая нуля и вот тут у нас просто n квадрат пополам логарифм двойки, а тут у нас
[01:08:03.300 --> 01:08:10.460]  1 плюс епсилон n квадрат логарифм двойки пополам. Ну ясно, что эта разность это епсилон,
[01:08:10.460 --> 01:08:16.940]  умноженная на n квадрат, умноженная на константу, причем со знаком минус. Ну все,
[01:08:16.940 --> 01:08:25.660]  вероятность меньше единицы, она стремится к нулю даже, довольно порядочным свистом. Вероятность даже
[01:08:25.660 --> 01:08:31.060]  стремится к нулю, ну конечно она меньше единицы, стало быть. Ну а поскольку и епсилон берется
[01:08:31.060 --> 01:08:40.060]  любое, то его можно заменить на у малое от единицы. Стандартное тоже рассуждение, а симпатическое.
[01:08:40.060 --> 01:08:45.580]  Если пугает у малое от единицы сразу, то напишите вместо него епсилон и скажите,
[01:08:45.580 --> 01:08:50.100]  что для этого произвольного епсилона найдется свое n маленькое, начиная с которого это будет
[01:08:50.100 --> 01:08:59.500]  меньше единицы. Ну значит, епсилон можно заменить на у малое от у. Все. Ну смотрите,
[01:08:59.500 --> 01:09:06.540]  как оно прямо впридык-впридык подобное. Значит, последнее, что я скажу, вот эту оценку,
[01:09:06.540 --> 01:09:12.580]  а симпатическую, которую мы сейчас доказали, но стер-то уже это утверждение, вот эту. Вот
[01:09:12.580 --> 01:09:20.740]  оно здесь. Вот эту оценку никто в настоящее время не умеет улучшить. Все, что люди умеют улучшить,
[01:09:20.740 --> 01:09:28.460]  это величину епсилон. Ну малое от единицы вот это. А вот эти константы, даже их не удается
[01:09:28.460 --> 01:09:36.500]  улучшить никакими силами. Это прямо проблема. Верхняя оценка никому не дается. Такое удивительное
[01:09:36.500 --> 01:09:41.460]  дело. Ну в следующий раз я еще немножко продолжу про нижние оценки и поговорю про дискрепанс,
[01:09:41.460 --> 01:09:46.460]  который был в прошлом году и который там был с матрицами Адамара. Я напомню, что это такое,
[01:09:46.460 --> 01:09:52.540]  причем там были матрицы Адамара, и докажу что-то комплементарное к этому. Ну а на сегодня все.
