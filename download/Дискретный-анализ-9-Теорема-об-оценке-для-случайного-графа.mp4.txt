[00:00.000 --> 00:12.200]  Так, товарищи, ну всё, наверное, пора начинать, да?
[00:12.200 --> 00:14.800]  Я написал формулировку теоремы, которой мы, кажется,
[00:14.800 --> 00:15.800]  закончили прошлую лекцию.
[00:15.800 --> 00:19.800]  Я вроде считал, что нам осталось её доказать.
[00:19.800 --> 00:24.720]  Или так не было?
[00:24.720 --> 00:25.720]  Не было такой?
[00:25.720 --> 00:26.720]  Было?
[00:26.720 --> 00:27.720]  Было, конечно.
[00:28.040 --> 00:30.040]  Ну, я вроде ещё не совсем в маразме.
[00:30.040 --> 00:38.480]  Это вы скоро узнаете.
[00:38.480 --> 00:43.160]  Я развлекал первокурсников, но на самом деле вас-то
[00:43.160 --> 00:46.280]  я скоро, прям совсем скоро этим буду развлекать.
[00:46.280 --> 00:49.960]  Есть такое понятие липшитового функции на графе.
[00:49.960 --> 00:55.280]  Вот это написано «липшитс», но я их развлекал как раз
[00:55.280 --> 00:56.280]  именно этим.
[00:56.280 --> 00:57.280]  Это мой почерк такой.
[00:57.400 --> 00:59.400]  И по этому всё одинаково.
[00:59.400 --> 01:01.880]  Потом я сказал, что я могу, конечно, постараться и написать
[01:01.880 --> 01:03.920]  как надо, но вот обычно я так не делаю.
[01:03.920 --> 01:10.640]  Так, друзья, давайте попробуем сразу так собраться и доказать
[01:10.640 --> 01:13.000]  вот эту замечательную теорему.
[01:13.000 --> 01:16.040]  Пафос этой теоремы я произнёс ещё в прошлый раз.
[01:16.040 --> 01:17.600]  Всё моё величие, так сказать.
[01:17.600 --> 01:20.240]  Ну, представляете, абсолютно дырявый граф, у него нет
[01:20.240 --> 01:23.240]  треугольников, нет циклов длины четыре.
[01:23.240 --> 01:26.240]  Самый короткий цикл имеет длину как минимум L плюс
[01:26.240 --> 01:27.240]  один.
[01:27.240 --> 01:30.480]  У него длины L циклов нету, и, тем не менее, он не красится
[01:30.480 --> 01:31.480]  в к цветов.
[01:31.480 --> 01:36.160]  То есть отсутствие раскраски – это не свидетельство тому,
[01:36.160 --> 01:38.680]  что там обязательно большая клика.
[01:38.680 --> 01:41.880]  Там ничего нет, никаких клик, кроме ребер.
[01:41.880 --> 01:47.280]  Ну, ребратохроматическое число два.
[01:47.280 --> 01:48.280]  Откуда?
[01:48.280 --> 01:49.280]  Как?
[01:49.280 --> 01:50.280]  Ну, это вероятностный метод.
[01:50.280 --> 01:52.480]  То есть я же не предъявлю вам граф, а докажу, что он
[01:52.480 --> 01:53.480]  существует.
[01:54.320 --> 01:59.560]  Вот давайте возьмём такую вероятность ребра.
[01:59.560 --> 02:05.480]  Вот такую.
[02:05.480 --> 02:18.160]  Ну, вот нам в формулировке дано число L, ограничение
[02:18.160 --> 02:20.320]  нижнее на длину самого короткого цикла.
[02:21.160 --> 02:26.000]  И давайте через T обозначим 1 поделить на 2 L, но это какое-то
[02:26.000 --> 02:28.240]  строго меньше единица положительное число.
[02:28.240 --> 02:30.080]  L у нас фиксировано.
[02:30.080 --> 02:34.680]  Друзья, вот с самого начала вы должны понимать, что,
[02:34.680 --> 02:38.160]  ещё раз, вот я это говорил в прошлый раз, я это помню,
[02:38.160 --> 02:40.160]  мы вольны выбирать количество вершин.
[02:40.160 --> 02:44.400]  То есть понятно, что чем больше K, чем больше L, тем больше
[02:44.400 --> 02:47.840]  будет то количество вершин, на котором нам удастся доказать
[02:47.840 --> 02:50.240]  существование вот такого графа.
[02:50.240 --> 02:52.760]  То есть понятно, что такой граф будет иметь огромное
[02:52.760 --> 02:53.760]  количество вершин.
[02:53.760 --> 02:57.920]  N это параметр, который мы там подберём, N можно стремить
[02:57.920 --> 02:58.920]  к бесконечности.
[02:58.920 --> 03:02.360]  А T это фиксированная величина равная, может быть, чему-то
[03:02.360 --> 03:05.640]  очень маленькому, если L большое, но это всё-таки положительное
[03:05.640 --> 03:07.640]  число больше единиц, меньше единицы.
[03:07.640 --> 03:12.480]  И вот если вы вот эту единичку вычитаете, получается нечто
[03:12.480 --> 03:15.760]  отрицательное, ну и, стало быть, это можно использовать
[03:15.760 --> 03:16.760]  как вероятность.
[03:16.760 --> 03:20.200]  Так, друзья, я надеюсь, все понимают, что вероятность
[03:20.200 --> 03:24.000]  должна жить на отрезке от 0 до 1.
[03:24.000 --> 03:27.720]  Поэтому мне важно было убедиться в том, что T это минус 1, отрицательное
[03:27.720 --> 03:28.720]  число.
[03:28.720 --> 03:31.680]  Брать вероятность, равная чему-то большему единице,
[03:31.680 --> 03:33.880]  это позорище какое-то.
[03:33.880 --> 03:44.840]  Так, рассмотрим получайный граф G от NP, вот с такой вероятностью
[03:45.480 --> 03:56.280]  Так, давайте на этом случайном графе ведем случайную величину.
[03:56.280 --> 04:05.960]  Кстати, как у вас продвигается история с теорией вероятностей?
[04:05.960 --> 04:12.360]  Как так, никак?
[04:12.360 --> 04:13.960]  Пока еще нету, да, понятно.
[04:14.360 --> 04:17.000]  Ну ладно, я же вам рассказал все, что необходимо, все понятно,
[04:17.000 --> 04:18.000]  что происходит.
[04:18.000 --> 04:20.920]  Ну и хорошо, значит, XL это случайная величина.
[04:20.920 --> 04:25.000]  Ну, раз она случайная величина, значит ее аргументом служит
[04:25.000 --> 04:26.000]  граф.
[04:26.000 --> 04:28.920]  У нас элементарные исходы – это графы, правильно?
[04:28.920 --> 04:31.400]  Значит, давайте ее определим.
[04:31.400 --> 04:40.040]  XLT от G – это количество простых циклов.
[04:40.040 --> 04:43.360]  Нас интересуют простые циклы, когда мы определяем G маленькое
[04:43.360 --> 04:54.560]  вот этот герс, обхват, количество простых циклов длины непревосходящей
[04:54.560 --> 04:57.240]  L в графе G.
[04:57.240 --> 05:01.120]  Ну, то есть, если неформально говорить, это количество
[05:01.120 --> 05:04.600]  тех циклов, которые вредят нашей цели.
[05:04.600 --> 05:09.800]  У нас цель – доказать, что существует граф с обхватом
[05:09.800 --> 05:13.360]  больше, чем L, и хроматическим числом больше, чем K.
[05:13.360 --> 05:16.080]  Ну, то есть, там две цели, как бы, он должен одновременно
[05:16.080 --> 05:19.800]  иметь большой обхват и большое хроматическое число.
[05:19.800 --> 05:22.720]  Но вот такие графы, в которых есть короткие циклы, они
[05:22.720 --> 05:24.360]  вредят нашей цели.
[05:24.360 --> 05:26.480]  И сами циклы эти тоже вредят.
[05:26.480 --> 05:31.440]  Понятно, я говорю, да, неформально?
[05:31.440 --> 05:36.240]  Количество тех циклов, которые вредят нашей цели.
[05:36.240 --> 05:37.240]  Вредные циклы.
[05:40.560 --> 05:44.480]  Да, да, да, конечно, и вот это L, это то L, и вот это L, это то L.
[05:44.480 --> 05:45.480]  Да, да, да.
[05:45.480 --> 05:46.480]  Это именно вредные циклы.
[05:46.480 --> 05:47.480]  Ну, еще раз.
[05:47.480 --> 05:51.480]  Я хочу, чтобы граф имел обхват больше, чем L, то есть,
[05:51.480 --> 05:54.480]  чтобы в нем не было простых циклов длины не больше, чем L.
[05:54.480 --> 05:59.480]  А это вот количество таких циклов, которых хотелось бы, чтобы не было.
[05:59.480 --> 06:03.000]  Вот тут их нет, а тут они, может быть, есть.
[06:03.000 --> 06:06.680]  Вот мы меряем, сколько их, и они, естественно, все вредны.
[06:06.680 --> 06:08.960]  Кем больше их, тем хуже граф.
[06:09.120 --> 06:10.120]  Но граф нам сильно не подходит.
[06:20.120 --> 06:24.320]  Ну, хитрее, на самом деле, то есть, ваша идея правильная.
[06:24.320 --> 06:25.840]  Да, нам нужно доказать, что...
[06:25.840 --> 06:28.120]  Нет, ну, понимаете, какое дело?
[06:28.120 --> 06:33.320]  То, что графы с обхватом больше, чем L существуют,
[06:33.320 --> 06:34.320]  ну это же очевидно.
[06:34.320 --> 06:38.320]  Нарисуйте цикл длины больше, чем L.
[06:38.680 --> 06:40.680]  Просто вот один цикл, что?
[06:40.680 --> 06:43.680]  Но надо, чтобы еще хроматическое число было больше, чем K.
[06:43.680 --> 06:46.680]  Вот как пересечь два события, да?
[06:47.680 --> 06:50.680]  Ну, там хитрее чуть-чуть, там будет более хитрый ход.
[06:50.680 --> 06:53.680]  Но идея, в общем, такая, да, то есть, что...
[06:53.680 --> 06:56.680]  Сейчас я докажу, что такие графы не просто существуют,
[06:56.680 --> 06:58.680]  а что их много.
[06:58.680 --> 06:59.680]  Да.
[07:00.040 --> 07:09.040]  Ж от графа без циклов равно бесконечности.
[07:09.040 --> 07:12.040]  Ну, давайте считать, что равно бесконечности.
[07:12.040 --> 07:13.040]  Это вроде ничему не противоречит.
[07:13.040 --> 07:16.040]  Ну, то есть, можно так это определить,
[07:16.040 --> 07:19.040]  и это не противоречит сложности нашей теории,
[07:19.040 --> 07:22.040]  потому что, если в графе нет циклов, то он двудолий.
[07:23.040 --> 07:26.040]  Нам же надо доказать, что бывает граф с хроматическим
[07:26.040 --> 07:27.040]  числом больше, чем K.
[07:27.400 --> 07:30.400]  Да, давайте считать, что бесконечности.
[07:30.400 --> 07:31.400]  Да?
[07:31.400 --> 07:33.400]  Ну, да, да, да, то есть, ну...
[07:33.400 --> 07:36.400]  Ну, бесконечности, бесконечность, я согласен, можно тогда
[07:36.400 --> 07:37.400]  определить.
[07:39.400 --> 07:41.400]  Так, ну, возвращаемся сюда.
[07:41.400 --> 07:44.400]  Значит, вот просто идейно, чтобы вы понимали, что сейчас
[07:44.400 --> 07:45.400]  будет происходить.
[07:45.400 --> 07:48.400]  Я докажу, что не просто существует граф с обхватом
[07:48.400 --> 07:50.400]  больше, чем L, но он существует.
[07:50.400 --> 07:52.400]  Цикл большой, возьмите, и все.
[07:52.400 --> 07:54.400]  А что таких графов полно.
[07:54.760 --> 07:57.760]  Что мера множества этих графов, вероятность, больше
[07:57.760 --> 07:58.760]  одной-второй.
[07:59.760 --> 08:02.760]  Ну, по крайней мере, начиная с какого-то N, в предостаточно
[08:02.760 --> 08:04.760]  большом количестве вершин.
[08:04.760 --> 08:07.760]  Вот давайте это прежде всего докажем.
[08:07.760 --> 08:12.760]  Если их много, то есть хороший шанс найти среди них и такие,
[08:12.760 --> 08:13.760]  у которых хи большое.
[08:14.760 --> 08:16.760]  Вы идею почувствуете, да?
[08:16.760 --> 08:19.760]  Если окажется, что таких не просто один, а много,
[08:19.760 --> 08:22.760]  то есть, откуда выбирать такие, у которых хи большое.
[08:23.120 --> 08:25.120]  В общем, мы все это проделали.
[08:27.120 --> 08:30.120]  Если бы мы просто могли это доказать, это было бы
[08:30.120 --> 08:32.120]  чуть проще, чем то, что мы сделаем.
[08:32.120 --> 08:34.120]  Но мы почти это сделаем, сейчас увидите.
[08:34.120 --> 08:35.120]  Почти это.
[08:36.120 --> 08:39.120]  В каком-то смысле, да, и тех, и тех больше одной-второй,
[08:39.120 --> 08:40.120]  но не совсем.
[08:45.120 --> 08:46.120]  Все.
[08:47.120 --> 08:48.120]  Чуть-чуть, вот не то, что...
[08:48.120 --> 08:51.120]  Ну, в общем, сейчас вы увидите, я не могу выяснить, что
[08:51.120 --> 08:56.000]  В общем, сейчас вы увидите. Я идею произнес, а сейчас давайте ее аккуратно реализовывать.
[08:56.000 --> 09:02.680]  Ну, во-первых, мат ожидания Excel это, по идее, вопрос к аудитории, потому что это просто
[09:02.680 --> 09:08.800]  линейность, которую мы вроде как заживали в каком-то смысле. И раз вы тут присутствуете,
[09:08.800 --> 09:15.760]  то вы должны уже понимать, как такие штуки считаются. Сколько в среднем есть графов?
[09:15.760 --> 09:24.440]  Но там не просто c, потому что надо перебрать еще вот эти длины. Надо, конечно, просуммировать,
[09:24.440 --> 09:32.280]  во-первых, по r от тройки до l. Мы же не знаем, какой именно длины будет простой цикл. Вот давайте
[09:32.280 --> 09:44.600]  я обозначим r, тогда действительно тут будет c из n, но по r. Умножить на r-1 факториал пополам,
[09:44.600 --> 09:52.200]  и умножить на p в степени r. Друзья, если хоть кому-то что-то здесь непонятно,
[09:52.200 --> 09:57.800]  я, конечно, произнесу подробнее. Значит, c из n, по r я все-таки чуть-чуть произнесу подробнее. Это что?
[09:57.800 --> 10:05.640]  Это количество способов выбрать r-вершин для цикла. Но когда вы зафиксировали r-вершин,
[10:05.640 --> 10:13.400]  циклический порядок на этом множестве фиксируется вот столькими способами. И вот только после этого
[10:13.400 --> 10:18.960]  вы уже считаете мат ожидания индикатора, что вот этот конкретный цикл с этим конкретным
[10:18.960 --> 10:27.680]  порядком вершин в нем присутствует в графе. Это p в степени r. Нормальный темп, все успевают.
[10:27.680 --> 10:35.240]  Так, ну, на самом деле l у нас константа. Я это не устаю напоминать, потому что кажется,
[10:35.240 --> 10:40.280]  может быть, это там Google какой-то или Google в степени Google. Google – раз, что-то жуткое может
[10:40.280 --> 10:45.720]  быть. Но это константа. От n она не зависит. Поэтому я оценивать буду по-идиотски. Я скажу,
[10:45.720 --> 10:57.320]  что это меньше. Ну, давайте пока r от тройки до l. Тут напишу n в степени r на p в степени r. То есть
[10:57.320 --> 11:04.000]  я c из n по r оценю просто как n в r-те поделить на r-факториал. И вот этот вот r-1-факториал,
[11:04.000 --> 11:09.720]  деленный на r-факториал, оценю тупо единицей сверху. То есть я забуду про все эти r-ки,
[11:09.720 --> 11:17.800]  которые там есть. Вспеваете? Вы думаете, я буду суммировать геометрическую прогрессию? Нет.
[11:17.800 --> 11:27.520]  Но я все-таки перепишу. r от тройки до l, np в r-те. Не буду я суммировать геометрическую прогрессию,
[11:27.520 --> 11:36.640]  я еще раз перепишу. Что такое np? Смотрите сюда. Вот p это n в степени θ-1. Поэтому np это n в
[11:36.640 --> 11:43.240]  степени θ, правильно? np это n в степени θ. То есть получается n в степени θ, умноженное на r.
[11:43.240 --> 11:49.360]  Ну, это, конечно, геометрическая прогрессия, да. Но зачем я суммировать, если l это константа?
[11:49.360 --> 12:02.800]  Я вам напишу вот так. Это меньше, чем l на n в степени θ-l. Потому что l это константа,
[12:02.800 --> 12:11.200]  правильно вы смеетесь? Это весело, да. Я вот люблю так, как грублять. Работает, да. Самое
[12:11.200 --> 12:16.480]  большое, слагаемое в этой сумме будет, например, равным l. Это возрастающая геометрическая прогрессия.
[12:16.480 --> 12:22.560]  Ну и ладно. l там, l-3. Да, у меня l-3. Знаете, если это гугл в степени гугл, гугл раз,
[12:22.560 --> 12:32.040]  из него тройку вычитать еще. Но это какое-то просто. Да, правильно. θ-l это 1-2. Я специально так
[12:32.040 --> 12:39.760]  выбрал θ, чтобы было удобно. Это константа корни из n. Правильно, да, это l умножить на корень из n.
[12:39.760 --> 12:47.520]  И теперь пользуемся неравенством Маркова. А именно мы скажем, что xl больше либо равняется
[12:47.520 --> 12:56.680]  n пополам. Ну, например, n пополам. Вы потом поймете, почему это полезно. Меньше либо равно
[12:56.680 --> 13:08.160]  мат ожидания xl. А, по поводу xl, tl и xl. Вот звучит, да, xl extra large. Чувствуете, да, xl. Или вам
[13:08.160 --> 13:18.560]  xl больше напоминает xl как программу. Знаете, xl такой, таблички рисовать, язык такой есть. Вот. Я
[13:18.560 --> 13:24.800]  просто, ну, я люблю пошутить, да. Я вот тут смотрю на экраны, какая-то новость пробегает про фистех
[13:24.800 --> 13:30.560]  экрана с новостями. Вот тут развешано. Там написано, что кто-то там фистехи, что ли, будут
[13:30.560 --> 13:37.560]  участвовать в каком-то мероприятии. И дальше написано xl. Я думаю, что за xl мероприятие? И тут
[13:37.560 --> 13:43.440]  до меня доходит, что это сороковое мероприятие. Латинские цифры, понимаете, вот так вот.
[13:43.440 --> 13:51.960]  xl мероприятие. Какое крутое мероприятие xl. Ну, там мероприятие как-то названо. Я просто не
[13:51.960 --> 14:02.880]  помню какое. Ну, там xl конференция, например. Xl конференция. Она не xl, она сороковая. Так,
[14:02.880 --> 14:12.920]  ладно. Возвращаюсь сюда. О, смотрите. Мат ожиданий xl-того поделить на n на 2, это повторяет
[14:12.920 --> 14:22.200]  просто неравенство Маркова. Значит, это у нас меньше, чем 2l корней из n поделить на n. Ну,
[14:22.200 --> 14:26.480]  и, в общем, это стремится к нулю, примерно, стремящимся к бесконечности. Например,
[14:26.480 --> 14:32.560]  можно сказать, что это меньше, чем 1 вторая, начиная с какого-то n. Давайте я вот здесь вот
[14:32.560 --> 14:39.400]  зафиксирую, что у меня получилось. Значит, я зафиксирую вот что. Существует n1 такое,
[14:39.400 --> 14:49.040]  что для любого n, больше либо равного n1, вероятность того, что xl-т меньше, чем n пополам,
[14:49.040 --> 14:57.880]  больше, чем 1 вторая. Я вот так напишу. То есть, вероятность того, что xl в каком-то смысле
[14:57.880 --> 15:07.760]  большая меньше 1 второй, значит, вероятность отрицания больше 1 второй. Так, друзья,
[15:07.760 --> 15:14.280]  поняли, что я сделал? Ну, это как бы чуть-чуть не то, что я обещал. Не то, что много графов,
[15:14.280 --> 15:24.600]  у которых вообще нет коротких циклов, а много графов, у которых коротких циклов мало. Ну,
[15:24.600 --> 15:29.760]  что значит xl меньше n пополам? Это значит, у графа мало коротких циклов. Короткие — это вот
[15:29.760 --> 15:36.600]  вредные, которые длины не больше, чем l. Вот если у графа xl-т меньше, чем n пополам, значит,
[15:36.600 --> 15:48.040]  в этом смысле меньше, чем n пополам, мало коротких вредных циклов, вот таких. Увидите? Не, ну, хотите
[15:48.040 --> 15:53.560]  я раскрою карты, но это катарсис. Это обалденная, конечно, теорема. Там действительно катарсис. Хотите,
[15:53.560 --> 16:00.480]  сразу скажу, в чем катарсис будет. Ну, может, вы дождетесь его. Много графов, у которых мало
[16:00.480 --> 16:08.120]  плохих циклов. Ну, давайте, наверное, докажем, что много графов, у которых хи большое. Это
[16:08.120 --> 16:19.320]  ожидаемо. Нужно было доказать. Давайте. Я катарсис чуть-чуть отложу, хорошо? Не, ну,
[16:19.320 --> 16:25.400]  пока вы поняли, ведь, что произошло, ничего страшного. Что понятно? Мы доказали, что много графов,
[16:25.400 --> 16:31.440]  которые, если и не такие, как хотелось бы, ну, близки к таким, у них мало коротких циклов. Они
[16:31.440 --> 16:39.920]  есть там, наверное, но их мало. Так, теперь давайте введем такую буковку х, которая будет
[16:39.920 --> 16:50.560]  верхняя целая часть от 3 логарифмен поделить на p. Кохнул сразу. Не, ну ладно, друзья, во-первых,
[16:50.560 --> 16:54.960]  я могу это в шпаргалку записывать, и кажется, мы это и записываем в шпаргалку, то есть запоминать
[16:54.960 --> 17:01.360]  такие вещи не нужно. Вы, главное, поймите, в чем смысл. Но, во-первых, все-таки, как устроена эта
[17:01.360 --> 17:09.320]  величина? Это верхняя целая часть от 3 логарифмен поделить на n в степени theta-1. Ну, потому что p
[17:09.320 --> 17:15.080]  у нас от n в степени theta-1. Так, друзья, куда стремится вот эта функция при n, стремящемся к
[17:15.080 --> 17:25.640]  бесконечности? Конечно, к бесконечности, потому что n в theta-1 меньше единицы. Ну, причем сильно,
[17:25.640 --> 17:32.080]  потому что theta-1 это что-то меньшее нуля. Да, на самом деле, можно перекинуть в числитель. Это
[17:32.080 --> 17:38.120]  стремится к бесконечности. Так, всем понятно, что стремится к бесконечности. Поэтому в частности
[17:38.120 --> 17:46.560]  я могу, например, писать вот так, что x tilde 3 логарифмен на n theta-1. Ну, просто потому,
[17:46.560 --> 17:51.160]  что аргумент стремится к бесконечности, значит, целая часть, которая от него отличается не больше,
[17:51.160 --> 17:57.040]  чем на один, тоже стремится к бесконечности с такой же примерно скоростью. То есть, а симптатика,
[17:57.040 --> 18:06.080]  конечно, имеет место. Так, зачем я ввел x? Сейчас вы увидите. Давайте рассмотрим случайную величину y
[18:06.080 --> 18:15.680]  с индексом x. Y с индексом x от g, это тоже случайная величина, которая определяется,
[18:15.680 --> 18:32.120]  как количество независимых множеств в g мощности x каждая. Мощности x. Сколько в графе g есть
[18:32.120 --> 18:41.240]  независимых множеств на x вершинах? Так, ну, чтобы вам было поспокойнее на душе, а то вы думаете,
[18:41.240 --> 18:49.000]  что вы не понимаете, к чему я клоню, я вот здесь вот напомню вам, есть прекрасное неравенство.
[18:49.000 --> 18:58.680]  И от g больше либо равняется n поделить на альфа от g. Я его доказывал в прошлый раз и комментировал,
[18:58.680 --> 19:06.120]  что оно лучше, чем амега от g, помните, да? То есть, альфа от g это число независимости,
[19:06.120 --> 19:12.760]  количество вершин в самом большом независимом множестве. А тут мы берем количество независимых
[19:12.760 --> 19:17.880]  множеств, у которых дано количество вершин. Сколько независимых множеств в мощности x?
[19:17.880 --> 19:28.600]  Ну, дело в том, что альфа от g меньше, чем x тогда и только тогда, или давайте больше,
[19:28.600 --> 19:40.600]  чем x, тогда это больше либо равно, тогда и только тогда, когда у с индексом x от g больше либо
[19:40.600 --> 19:50.360]  равен единице. Согласны, товарищи? Ну, что это означает? Это означает, что вероятность,
[19:50.360 --> 20:00.440]  с которой альфа от g больше либо равняется x, равна вероятности того, что ух от g больше либо равен
[20:00.440 --> 20:09.800]  единице. Прыгай сюда, чтобы снизу не писать, наверх перемещайся. А это опять, согласно неравенству
[20:09.800 --> 20:20.000]  Маркова, не больше, чем мот ожидания ух. Ну, неравенство Маркова применяю. Так,
[20:20.000 --> 20:26.040]  снова линейность какая теперь? Сколько в среднем независимых множеств на x вершинах, товарищи?
[20:26.040 --> 20:40.440]  Ну, тут совсем просто. c из n по x на 1 минус p пепенит c из x по 2. Так, ну, я, может, много пафоса
[20:40.440 --> 20:48.080]  навел, но это вроде очевидно. Очевидно, да? Независимое множество это значит на x вершинах должны
[20:48.080 --> 20:55.840]  пропасть все ребра. Рёбер на x вершинах c из x по 2 и каждая пропадает с вероятностью 1
[20:55.840 --> 21:07.840]  минус p, а затем суммируем индикатор. c из n по x. Точно не очень быстро, все успеваем. Так,
[21:07.840 --> 21:13.640]  ну, оцениваем стандартным образом. Это меньше либо равно. Слушайте, я совсем расхалявлюсь,
[21:13.640 --> 21:20.120]  c из n по x меньше, чем n в степени x. Но я даже x факториал не буду писать. Почему не буду?
[21:20.120 --> 21:25.680]  Потому что он очень маленький, там логарифом на какую-то фигню. Ну, т.е. этот x факториал нам
[21:25.680 --> 21:30.720]  сильно не поможет. Друзья, я понимаю, что вам с кодов все-таки настолько непривычно еще асимптотики,
[21:30.720 --> 21:35.640]  сколько бы вас ими не грузили. Но победители же не судят, пренебрег с знаменателем, значит,
[21:35.640 --> 21:40.840]  так можно. Если вдруг поняли, почему я решил пренебречь, ну, отлично, не поняли, ничего страшного.
[21:40.840 --> 21:49.280]  Так, а как 1 минус p в степени оценивается? Вот так. E в степени минус p на c из x по 2.
[21:49.280 --> 21:59.240]  Но как обычно, логарифм от 1 минус p не больше, чем минус p. Много-много раз у нас уже было. Хотелось
[21:59.240 --> 22:09.080]  бы, чтобы вы это запомнили. Так, это равняется E в степени x логарифмен, x логарифмен, минус p x,
[22:09.080 --> 22:18.920]  x минус 1 по полов. Ну, все, что я хочу сделать, это доказать, что это дело стремится к нулю. Я думаю,
[22:18.920 --> 22:28.200]  вы догадались. Догадались, что я хочу стремиться к нулю? Что вероятность, с которой независимое
[22:28.200 --> 22:34.240]  множество есть большие, эта вероятность должна стремиться к нулю. Потому что нам нужно доказать,
[22:34.240 --> 22:42.360]  что альфа дже маленькая, тогда и хя дже будет большое. Поняли, да, мысль? Вот, поэтому большое
[22:42.360 --> 22:48.400]  оно должно быть с маленькой вероятностью. Ну, то есть нас интересует на самом деле вот такая разность.
[22:48.400 --> 23:00.000]  Я х выношу за скобку в показателе экспонента x, там общий. В скобках остается логарифм минус
[23:00.000 --> 23:08.280]  p умножить на x минус 1 по полов. Так, то есть получается, смотрите, логарифмен минус, я так напишу,
[23:08.280 --> 23:14.840]  1 плюс о малое от единицы. Ну, потому что x минус 1 асимпатически равен x, а это, в свою очередь,
[23:14.840 --> 23:30.920]  асимпатически равно вот тому, что написано. Я пишу 3 логарифм n на... Что? Что я пишу? Правильно
[23:30.920 --> 23:39.720]  пишу или неправильно? Что? А, ну да, n в степени theta минус 1, это по сути p. Зачем я буду переписывать-то?
[23:39.720 --> 23:46.560]  Действительно, не надо писать n в степени theta минус 1, лучше написать p. Вот это вот, это же p,
[23:46.560 --> 23:55.800]  вот это вот. Все p. Я лучше p здесь напишу, чтобы умножить на p и сделать вот так. Я, конечно,
[23:55.800 --> 24:02.800]  могу и тут, и тут n в theta минус 1 написать, но они чпокнут друг друга все равно. На два разделить
[24:02.800 --> 24:10.720]  нужно. Да, вот на это два, конечно, нужно разделить. Ну, видите, я с запасом взял. Понятно,
[24:10.720 --> 24:16.600]  что если вы из логарифма вы читаете нечто асимпатически равное 3 вторым логарифма,
[24:16.600 --> 24:23.920]  то это стремится к минус бесконечности. Потом умножается на x, который растет,
[24:23.920 --> 24:28.920]  то есть продолжает стремиться к минус бесконечности еще быстрее. А е в этой степени,
[24:29.240 --> 24:39.320]  стало быть, стремится к нулю, как я и хотел. Правильно, да? Вот, поэтому у меня получается в итоге,
[24:39.320 --> 24:48.920]  давайте вывод. Такую же рамочку, как и там, сделаю. Значит, вывод такой, существует n2 такое,
[24:48.920 --> 25:00.600]  что для любого n больше либо равного n2, вероятность которой альфа g меньше x больше 1 второй.
[25:00.600 --> 25:08.360]  Но у меня, конечно, рамочки получились в разных концах света. Одна в Калининграде,
[25:08.360 --> 25:14.800]  другая во Владивостоке. Неудобно на видео показывать, я понимаю, но у меня мертвая зона тут
[25:14.800 --> 25:21.760]  просто. Вот один вывод, это что начиная с некоторого n1, вот эта вероятность больше 1 второй,
[25:21.760 --> 25:29.160]  xl-t меньше, чем n пополам. А с другой стороны, начиная с некоторого n2, альфа маленькая,
[25:29.160 --> 25:36.120]  с большой вероятностью. Ну, значит, начиная с максимума из n1 и n2, события пересекаются,
[25:36.120 --> 25:47.560]  правильно? Так, ну это уже надо где-то написать. Давайте сюда пойдем. Не, ну строго же больше 1
[25:47.560 --> 25:53.040]  и 2, значит, пересекаются. Но больше нуля, понимаете? Больше нуля вероятность, значит,
[25:53.040 --> 25:58.640]  множество не пустое. У нас конечное вероятностное пространство, этого достаточно. Хотите,
[25:58.640 --> 26:04.120]  замените на две трети, никто не будет возражать. Тогда вероятность будет там больше, чем одна
[26:04.120 --> 26:18.600]  треть типа. Кстати, все умеют это доказывать. Простое упражнение на формулы типа Моргана
[26:18.600 --> 26:34.080]  там или чего-то. Как переписать А, объединенное Б с чертой? У нас получается, что для любого n,
[26:34.080 --> 26:44.280]  больше либо равного максимума из n1 и n2, существует граф на n вершинах, существует g
[26:44.280 --> 27:00.720]  на вот этих вот n вершинах. Такое, что ХLT от g меньше, чем n пополам и альфа g меньше, чем х. И вот
[27:00.720 --> 27:06.560]  теперь я обещал катарсис. Вот я не стал уж заранее объяснять. Вот сейчас будет объяснение того,
[27:06.560 --> 27:18.800]  как я с этим борюсь. Вот берем этот граф G, в нем мало плохих циклов вредных. Давайте из каждого
[27:18.800 --> 27:25.160]  вредного цикла, каким бы он ни был, удалим любую его вершину вместе с ребрами, которые к ней
[27:25.160 --> 27:36.560]  примыкают. Удалим из каждого цикла любую вершину. Можно я это не буду писать. Мы удалим сколько
[27:36.560 --> 27:44.000]  вершин в итоге? Меньше, чем n пополам, правда? Но циклов-то меньше, чем n пополам. Не важно,
[27:44.000 --> 27:52.280]  как мы их удаляем, просто тупо удаляем и все. У нас останется граф G штрих. У него количество
[27:52.280 --> 27:59.840]  вершин больше, чем n пополам. Потому что из исходного графа, имевшего n вершин,
[27:59.840 --> 28:10.040]  мы удалили меньше, чем n пополам вершин. Сейчас, секунду, извините. Алло. Не вполне. Я лучше
[28:10.040 --> 28:22.120]  перезвоню минут через десять. Да. Так, слышите, это понятно, да? Теперь, на самом деле, понятно,
[28:22.120 --> 28:28.960]  ну совсем очевидно, по-моему, что ХЛ от G штрих равняется нулю. Ну как могли появиться новые циклы?
[28:28.960 --> 28:36.840]  Мы все циклы, какие были, разорвали. Каждого удалили вершины. И почти очевидно, ну я думаю,
[28:36.840 --> 28:42.680]  что просто очевидно, что альфа тоже не могла вырасти. Потому что, если бы у уменьшенного графа
[28:42.680 --> 28:52.280]  была больше альфа, то у исходного графа она была бы больше тоже. Ребра удаляли вместе с вершинами,
[28:52.280 --> 28:58.440]  конечно, да. Только те ребра, которые примыкают к удаленным вершинам, естественно, имеют их
[28:58.440 --> 29:08.800]  своими конца. Конечно, да. Понятно, что альфа не могла вырасти, да? Всем понятно. Ну что мы можем
[29:08.800 --> 29:14.760]  сказать про этот граф, пользуясь вот этой замечательной формулой, оценкой? Хи от G штрих
[29:14.760 --> 29:26.560]  больше либо равняется N поделить на альфа от G, N пополам. Виноват, N пополам, потому что вершина
[29:26.720 --> 29:33.520]  N пополам. Даже можно больше написать. Это неважно. Больше чем N пополам поделить на альфа от G. Это
[29:33.520 --> 29:44.080]  больше чем N поделить на 2х, что альфа от G штрих меньше чем х. Вот, поэтому получается больше чем N
[29:44.080 --> 29:54.280]  на 2х. Это асимпатически равно N поделить на 2, на 3 логарифм N умножить на N в степени
[29:54.280 --> 29:59.760]  θ-1. Перевернула эту дробь. Видите, попал в знаменатель, знаменатель в числитель.
[29:59.760 --> 30:10.640]  Так, получается N в степени θ поделить на 6 логарифмов N. Ну и, конечно, N в степени θ растет
[30:10.640 --> 30:18.960]  быстрее, чем логарифм, каким бы малым θ это ни было. Оно же фиксировано 1 на 2. Всё, это больше
[30:18.960 --> 30:28.960]  чем K. Ну, формально при N больше либо равном N3. То есть, формально надо взять максимум из N1,
[30:28.960 --> 30:39.000]  N2, N3. Вот такой вот N. И для него уже всё хорошо. ХLT равно нулю, а хроматическое число больше,
[30:39.000 --> 30:50.800]  чем K. Вот так. Поняли, да? Тут, видите, ещё дополнительная хитрость. Такое удаление вершин
[30:50.800 --> 30:55.800]  произошло, по ходу дела. Вот оно создаёт прям катарсис. Не просто мы пересекли два события и
[30:55.800 --> 31:20.160]  получилось мера больше нуля, а ещё надо было подправить что-то. Да, да, да. Тут ещё надо разочек
[31:20.160 --> 31:25.040]  применить вот эту максимизацию, потому что Фик его знает, а вдруг это не больше, чем K. Но мы вольны
[31:25.040 --> 31:37.840]  выбирать N. Чем больше N, тем больше это величина. Да, нам повезло, что настолько мало этих коротких
[31:37.840 --> 31:43.160]  циклов, что тупо удаляя вершину просто из каждого изника, даже не следя за тем, что удаление одной
[31:43.160 --> 31:49.840]  вершины может там привести к удалению нескольких циклов. Плевать. Любое удаляемое всё равно их
[31:49.840 --> 32:01.120]  настолько мало, что количество остающихся вершин всё равно большое. Вот так вот. И хроматическое число
[32:01.120 --> 32:07.240]  в два раза оно хуже, но какая разница? Главное, что вот эта дробь растёт. Вот такой вот совершенно
[32:07.240 --> 32:13.480]  удивительный результат, очень красивый на самом деле. Но я уже говорил, что потом конкретизировали
[32:13.480 --> 32:19.040]  этот граф, сумели его построить явно, но там очень сложная конструкция. Это сделал Ловос,
[32:19.160 --> 32:25.200]  такой совершенно выдающийся человек, который много чего сделал. Я в этом курсе ещё буду доказывать
[32:25.200 --> 32:32.280]  две его теоремы очень важных, ну а пример я его приводить не буду. Всё, значит, эту теорему-то
[32:32.280 --> 32:38.920]  мы доказали. Слушайте, как здорово, как быстро. Точно все всё поняли. Но давайте я теперь дальше
[32:38.920 --> 32:46.600]  буду двигаться. Я ещё вам такое вкрапление важное сделаю, чтобы максимально вас замотивировать
[32:46.600 --> 32:53.080]  заниматься хроматическими числами. Но я уже говорил о том, что эта штука важная с практической
[32:53.080 --> 32:59.480]  точки зрения, и вы сами в какой-то момент включились и сказали, ну хорошо, важная, а задача-то НП трудная.
[32:59.480 --> 33:05.200]  То есть, скорее всего, она за экспоненту только решается и вряд ли существует какой-то алгоритм,
[33:05.200 --> 33:10.880]  который быстро бы находил хроматическое число. Это действительно огромная проблема, которая
[33:10.880 --> 33:15.960]  приводит прямо к вызовам в области, знаете, как говорят, ивристик, то есть придумывают
[33:15.960 --> 33:23.120]  ивристические алгоритмы, которые там как-то приближаются к хроматическому числу. Но оказывается,
[33:23.120 --> 33:33.560]  внимание, товарищи, что даже банальный шадный алгоритм совсем тупой в некотором смысле,
[33:33.560 --> 33:41.560]  что он в каком-то смысле действительно едва ли не лучше всех, но по крайней мере не сильно хуже,
[33:41.560 --> 33:49.440]  чем самые лучшие. Вот про это я сейчас строго математически расскажу. Это вот тема, я не знаю,
[33:49.440 --> 33:57.960]  успею я сегодня все или нет, но это важная тема, в очередной раз свидетельствующая о том, что даже
[33:57.960 --> 34:07.160]  банальный шадный алгоритм для покраски графа хорошо работает. В каком смысле хорошо, это я вам сейчас скажу.
[34:07.160 --> 34:21.360]  Там некий пафос разведу, будет нерешенная проблема. Вдруг кто-нибудь решит, она сложная совсем.
[34:27.960 --> 34:34.160]  Ну типа того, но сейчас вот я все аккуратно скажу. Я не буду рассказывать для простоты про
[34:34.160 --> 34:40.960]  хроматическое число, чуть проще разбираться с числом независимости. Ну понятно, что это связанные
[34:40.960 --> 34:46.000]  величины, то есть если мы разберемся с одним, то наверное и с другим тоже. Так, друзья, что такое
[34:46.000 --> 34:51.760]  шадный алгоритм для покраски графа? Ну я совсем банальную вещь скажу. Представьте себе, что вершины
[34:51.760 --> 34:59.280]  занумерованы. Мы двигаемся по этой нумерации и очередную вершину пытаемся покрасить в цвет
[34:59.280 --> 35:05.560]  маленьким номером, в который ее можно покрасить без противоречия с уже покрашенными вершинами.
[35:05.560 --> 35:15.160]  Если это не удается, присваиваем новый цвет. Так, друзья, понятно? Я думаю, что вы как люди,
[35:15.160 --> 35:19.920]  которые у нас учитесь, быстро это схватываете. Банальный, совершенно простой жадный алгоритм.
[35:19.920 --> 35:32.280]  Вот давайте вот так обозначим соответствующий результат, то есть это же русское написано,
[35:32.280 --> 35:38.720]  жадное. И же это то количество цветов, которые он выдаст. На выходе, если его применить к графу
[35:38.720 --> 35:44.080]  же, вы скажете в какой нумерации вершин, но вот я уже дал какую-то, вот она пусть будет раз и навсегда
[35:44.080 --> 35:49.840]  одна и та же. Неважно, в рандомной, как вы любите говорить, но она не случайная в смысле теории вероятности,
[35:49.840 --> 35:56.280]  просто выбрали какую-то, зафиксировали и больше об этом не думаем. Какую бы ни взяли, вот в ней
[35:56.280 --> 36:06.800]  будем работать. Так, ну то есть, я надеюсь, вы понимаете, что вот это х с индексом же, скорее всего,
[36:06.800 --> 36:14.480]  его больше, чем реальное хроматическое число, правда? Оно, конечно, больше либо равно х и,
[36:14.480 --> 36:22.720]  скорее всего, строго больше. Ну а здесь наоборот. А, кстати, я не сказал, что такое альфа с индексом же,
[36:22.720 --> 36:29.760]  это может быть непонятно. Значит, если вы покрасили жадным образом вершины, на это вы поняли как,
[36:29.760 --> 36:37.680]  да, то там есть вершины покрашенные в один цвет, в другой цвет, в третий цвет, но выберем просто то
[36:37.680 --> 36:43.280]  множество, которое имеет самую большую мощность. И эту мощность обозначим альфа с индексом же.
[36:43.280 --> 36:51.240]  То есть, жадно красим и потом находим цвет, в который покрашено больше всего вершин. Вот это
[36:51.240 --> 36:58.000]  количество вершин покрашенных в данный цвет обозначаем альфа ж от ж. Значит, теорема,
[36:58.000 --> 37:04.040]  которую я докажу, и она, в общем, совершенно элементарная, то есть там тоже не больше,
[37:04.040 --> 37:09.800]  чем неравенство Маркова, но там такая просто рассуждение будет красивое. Теорема утверждает
[37:09.800 --> 37:20.200]  следующее. Если вот такой, ну, то есть мы рассматриваем случайный граф на n вершинах с
[37:20.200 --> 37:28.080]  вероятностью ребра 1 на 2. Фактически это значит, что все графы просто равновероятны. Если мы считаем,
[37:28.080 --> 37:44.880]  что все графы равновероятны, то вероятность, с которой альфа от ж поделить на альфа ж от ж меньше
[37:44.880 --> 37:52.200]  или равняется 2 плюс эпсилон, вот такая вот вероятность, давайте так, для любого эпсилон большего
[37:52.200 --> 37:57.800]  нуля, вероятность того, что отношение реального числа независимости к тому, которое дает жадный
[37:57.800 --> 38:04.240]  алгоритм, что вот это отношение не больше, чем 2 плюс эпсилон, стремится к енице, к примеру,
[38:04.240 --> 38:15.120]  стремящимся к бесконечности. Это мы докажем. Но, то есть, если вы можете считать априорно,
[38:15.120 --> 38:22.040]  что все графы равновозможны, равновероятны, из каких-то там соображений вашей реальности,
[38:22.040 --> 38:27.640]  в которой вы существуете, если у вас нет какого-то априорного распределения, а просто вот все
[38:27.640 --> 38:34.400]  графы равновозможны, и вот капает на вас такой граф, запускаете на нем жадник, скорее всего,
[38:34.400 --> 38:40.640]  если вы ошибетесь, то не больше, чем примерно в два раза, и неважно, сколько у него вершин,
[38:40.640 --> 38:46.160]  миллион, миллиард, квадриллион, а на квадриллионе вершин вы фиг посчитаете число независимости,
[38:46.160 --> 38:52.560]  а жадный алгоритм у вас сработает очень даже. Что, на квадриллионе не сработает? А памяти не
[38:52.560 --> 38:58.880]  хватит? Памяти не хватит? Ну, за полдня посчитает, конечно, то есть, это нормально совершенно на
[38:58.880 --> 39:04.640]  квадриллионе вершин, но на квадриллионе вершин ошибиться в два раза это, в общем, уже не очень
[39:04.640 --> 39:10.840]  страшно. Это я вас агитирую за жадник пока, что я потом буду вам рассказывать, чем это все-таки не
[39:10.840 --> 39:16.560]  так хорошо, но пока агитирую. Сейчас прозвенел звонок, давайте пять минут перерыв, потом я
[39:16.560 --> 39:24.280]  продолжу комментировать. Сейчас я еще прокомментирую, видите, оказывается, что-то не всегда слышно. Я еще
[39:24.280 --> 39:30.800]  раз повторю, чтобы пафот был максимальным. Так, друзья, все тихо, рассаживайтесь, пожалуйста.
[39:30.800 --> 39:35.960]  Значит, смотрите еще раз, вот мне было сделано замечание, что я как-то не максимально четко
[39:35.960 --> 39:42.640]  распараллелил вот эти два факта. Оказывается, это не сразу доходит. Вот видите, ну, конечно,
[39:42.640 --> 39:49.560]  очевидно, что жадное не больше, чем реальное, но мы ищем максимум, как-то его опроксимируем.
[39:49.560 --> 39:55.960]  Естественно, то, что мы нашли, оно может быть максимальным, но может быть и меньше. Вот, а с
[39:55.960 --> 40:02.000]  другой стороны, мы доказываем, что выполнено обратное неравенство. Вот смотрите, здесь альфа ж поделить
[40:02.000 --> 40:11.320]  на альфа ж от ж, оно не больше, чем два плюс эпсимум, а здесь эта дробь, она, наоборот, не меньше единицы,
[40:11.320 --> 40:17.560]  то есть вот если альфа ж разделить на альфа ж, то это больше либо равно единицы. Для любого графа,
[40:17.560 --> 40:23.840]  конечно, вот эта дробь не меньше единицы, а у нас получается, что для почти всех графов она еще и не
[40:23.840 --> 40:31.640]  больше, чем два плюс эпсимум. Вот в этом пафос. А вершина неважно сколько, в сравнении вероятность будет
[40:31.640 --> 40:38.640]  чем больше вершины, тем ближе к единице, но неважно сколько в каком-то смысле. Так, друзья, вот
[40:38.640 --> 40:45.280]  сейчас пафос этого результата понятен, если вы работаете не на всех графах, но на почти всех графах,
[40:45.280 --> 40:53.520]  на почти всех, то очень неплохо апроксимирует жадный алгоритм. Теперь вот я обещал вам нерешенную
[40:53.520 --> 41:00.560]  проблему и дополнительный пафос относительно жадного алгоритма. Друзья, значит вы просто послушайте,
[41:00.560 --> 41:06.480]  ничего сейчас доказывать не буду, доказывать я потом буду вот это, но очень важно почувствовать
[41:06.480 --> 41:17.400]  пафос, вот очень важно в это как-то вникнуть. Смотрите, смотрите. Чем меньше эпсилон, это вы увидите из
[41:17.400 --> 41:25.080]  доказательства даже, тем медленнее стремится вероятность к единице. То есть если вы хотите
[41:25.080 --> 41:30.960]  здесь написать 2,1 квадриллионная, то вот эта вероятность стремится к единице, но очень-очень
[41:30.960 --> 41:40.240]  медленно. Если вы хотите написать 2,1 угольная, 1 поделить на Google, то вероятность тоже будет стремиться
[41:40.240 --> 41:48.740]  к единице, но совсем медленно, еще гораздо медленнее. Поэтому вы увидите это из доказательства. Заменить
[41:48.740 --> 41:57.080]  эпсилон просто нулем нельзя. Квантор стоит извне значка вероятности. Для каждого эпсилон вероятность
[41:57.080 --> 42:05.080]  стремится к единице, но скорость стремления тем ниже, чем ближе к нулю этот эпсилон. И прямо
[42:05.080 --> 42:12.720]  из доказательства вы это увидите. Да, это будет следовать из нашего доказательства. Нет,
[42:12.720 --> 42:18.040]  мы докажем, что он стремится к единице достаточно быстро на самом деле, но заменить эпсилон на 0
[42:18.040 --> 42:26.240]  не получится. Правильно, вот я про это дальше хочу сказать. Значит, нет, к сожалению, продвинутого
[42:26.240 --> 42:32.200]  доказательства. То есть, ну я не буду этого доказывать, но можно показать, что жадный алгоритм в
[42:32.200 --> 42:38.720]  принципе вот здесь эпсилон на 0 не заменяет. Вот ну невозможно. Перевнимание, слушаем дальше.
[42:38.720 --> 42:53.440]  Существуют алгоритмы, не жадные, более сложные. Такие, что вероятность альфа дж поделить на альфа
[42:53.440 --> 43:01.120]  а, а это какой-то там существующий алгоритм просто не превосходит двойке с вероятностью стремящейся к
[43:01.120 --> 43:07.120]  единице. Такие алгоритмы есть. Причем они полинамиальные. Они хуже, конечно, чем жадник,
[43:07.120 --> 43:18.320]  но они полинамиальные. Так понятно говорю, да? А симптотику какую? Не, ну а какая там асимптотика?
[43:18.320 --> 43:24.600]  Ну сколько ребер, столько и работает он. Ну то есть это вот n в квадрате, если считать,
[43:24.600 --> 43:33.240]  что это число вершина. А если ребер мало, то и того лучше. Ну почему про квадриллион было сказано,
[43:33.240 --> 43:39.280]  что это все-таки полдня, потому что квадриллион в квадрате, это так, это много. Да, это уже не
[43:39.280 --> 43:45.080]  полдня, я боюсь, что это я тоже хватил. Вот, квадриллион, наверное, это все-таки много. Ну ладно,
[43:45.080 --> 43:49.720]  но существуют полинамиальные алгоритмы, которые позволяют убрать епсилон. Это, конечно,
[43:49.720 --> 43:55.040]  великое достижение. Сами понимаете, что я это доказывать не буду. Но у нас же достижение
[43:55.040 --> 44:01.160]  совсем ничтожное, такая уже математика-математика. Это скорее подтверждение, сейчас будет великое
[44:01.160 --> 44:08.520]  подтверждение тому, что надо заниматься жадностью, надо жадничать. Утверждение такое,
[44:08.520 --> 44:15.160]  гипотеза, не доказанная никем. Помните, вот я сказал, будет нерешенная проблема. По-видимому,
[44:15.160 --> 44:26.280]  по-видимому не существует полинамиального алгоритма, который вот в этой вот формулировке
[44:26.280 --> 44:37.920]  позволил бы двойку заменить на что-либо меньшее. Нет, я не говорю на 2 минус епсилон, где епсилон
[44:37.920 --> 44:47.440]  стремится к нулю. А я говорю 1 и 99, например. Вот поставить здесь 1, 9, 9, 9, 9. Вот по-видимому
[44:47.440 --> 44:56.120]  нет такого полинамиального алгоритма, чтобы это выполнялось. Нет, в периоде можно. Но если вы
[44:56.120 --> 45:02.360]  зафиксируете любое количество девяток, то по-видимому нет такого. И никто это не может доказать. Но это
[45:02.360 --> 45:07.400]  ладно то, что никто не может доказать. Но если это верно, это означает, что действительно то, что вы
[45:07.400 --> 45:12.160]  говорили в каком-то смысле так и есть. Жадный алгоритм дает практически оптимальный результат.
[45:12.160 --> 45:22.360]  То есть дальше начинаются какие-то изыски, а еще лучше сделать нельзя. Такой вот удивительный факт.
[45:22.360 --> 45:31.000]  Да, совершенно очевидно, но понятно. Поэтому на практике, как правило, конечно, добавляют
[45:31.000 --> 45:35.520]  какие-то евристики. То есть не пользуются только жадными алгоритмами. Практика отличается от этой
[45:35.520 --> 45:41.520]  теории, конечно. Но тем не менее вы должны понимать, что вот такая вот есть очень красивая вещь,
[45:41.520 --> 45:53.600]  которая свидетельствует о том, что жадность можно использовать. Ну чего, я не успею доказать
[45:53.600 --> 46:03.600]  то все за оставшиеся... Время полчаса, да? Давайте начнем. Ну куда деваться-то? Времени-то еще полно,
[46:03.600 --> 46:12.320]  а доказать за оставшуюся часть лекции я вряд ли успею. Оно несложно. Смотрите, на самом деле тут
[46:12.320 --> 46:19.040]  есть элемент лукавства в этом утверждении, конечно. А именно мы уже с вами знаем. Мы знаем. Я начал
[46:19.040 --> 46:39.840]  доказывать, что вероятность вот такого события стремится к единице. Я в прошлый раз доказывал.
[46:39.840 --> 46:47.200]  Помните, когда говорил, что омега и альфа одновременно маленькие, поэтому почти всегда
[46:47.200 --> 46:54.560]  лучше использовать мощность вн альфа в качестве оценки кром-числа, а не омегу. Это теория из прошлого
[46:54.560 --> 47:05.560]  раза. Ну раз мы это уже знаем, значит нам достаточно теперь доказать что? Что достаточно доказать?
[47:05.560 --> 47:14.680]  Что для любого иапселон большего нуля вероятность того, что альфа g от g,
[47:14.680 --> 47:33.200]  пум, пум-пум. Чего? Большая или маленькая? Чего-то туплю. Альфа от g мы знаем, что меньше,
[47:33.200 --> 47:43.840]  чем 2 лог 2 х н. Значит, надо доказать, что она больше. Больше, чем 1 минус
[47:43.840 --> 47:49.160]  епселон. На лог 2 х н. Вот это вероятность стремится к единице.
[47:59.400 --> 48:03.680]  Ну, кстати, да. Я как-то не догадывался так откомментировать. Действительно,
[48:03.680 --> 48:11.600]  это правильное совершенно замечание. Заодно получим. Ну, естественно, да. Но как-то мне не
[48:11.600 --> 48:18.120]  приходило в голову сказать, что вот в этом месте мы уже это делали. Да, действительно. Так,
[48:18.120 --> 48:26.560]  ну вы понимаете, да, почему этого достаточно? Ну как? Альфа от g поделить на альфа g от g,
[48:26.560 --> 48:34.880]  почти всегда числитель меньше, чем 2 лог 2 х н, а знаменатель больше, чем 1 минус
[48:34.880 --> 48:44.640]  епселон на лог двоичный. Что? В смысле, если бы здесь было 2 лога рифма, это было бы хорошо.
[48:44.640 --> 48:54.920]  Не понял. Почему ломается-то?
[49:04.880 --> 49:12.640]  А, ну это тоже да. Ну это я понял, да, из того, что проблема не решенная следует, конечно. Да, да,
[49:12.640 --> 49:19.760]  да. Но зачем сейчас об этом говорить? Понятно, что это осталось доказать? Короче. Сейчас, товарищи,
[49:19.760 --> 49:24.120]  я что-то не пойму. Поднимите руки, кто понимает, почему это осталось доказать? Никто не понимает,
[49:24.120 --> 49:33.800]  да? Или все понимают? Ну буквально дает. Ну как? Ну альфа от g поделить на альфа g от g. Ну дайте,
[49:33.800 --> 49:42.400]  я все-таки произнесу. Меньше, чем 2 лог 2 х н, потому что альфа от g меньше. Поделить на альфа g,
[49:42.400 --> 49:50.840]  которая больше, на 1 минус, минус епселон на лог двоичный н шлеп. Шлеп это 2 поделить на 1
[49:50.840 --> 49:56.960]  минус епселон и это 2 плюс епселон штрих. Но поскольку по епселон стоит квантор для
[49:56.960 --> 50:04.680]  любого, то и по епселон штрих тоже. Да, то есть этого достаточно. Все. Если мы это докажем,
[50:04.680 --> 50:10.040]  мы завершим теорию. Дайте это докажем. Ну тут поступали очень разумные комментарии,
[50:10.040 --> 50:14.400]  что это в свою очередь доказывает действительно, что не только вот такая цена верна,
[50:14.400 --> 50:17.600]  но и почти такая же снизу. Это правда, да.
[50:26.960 --> 50:46.640]  Так, 2 плюс епселон. А вот сюда смотри. А кстати, я говорил, да, слова симпатические,
[50:46.640 --> 50:51.080]  почти наверное. То есть я не обязательно должен писать вероятность стремиться к единице,
[50:51.080 --> 50:56.680]  я могу писать а, п, н, там выполнено вот это. Все ж помните такое. На всякий случай,
[50:56.680 --> 51:04.240]  это может не понадобится. Так, ну давайте как-то двигаться к этому доказательству. Я, естественно,
[51:04.240 --> 51:12.640]  буду доказывать, что наоборот вероятность того, что альфа ж от ж меньше либо равняется,
[51:12.640 --> 51:21.640]  там меньше, строго, неважно, чем 1 минус епселон на лог 2 х н, стремится к нулю. Понятно дело,
[51:21.640 --> 51:26.840]  равносильное утверждение, но обычно как-то удобнее оценивать сверху, чем снизу, поэтому я и буду это
[51:26.840 --> 51:34.960]  доказывать. Вот если хотите, давайте я вот это обозначу сейчас буквой а. Это не алгоритм,
[51:34.960 --> 51:42.000]  это событие. Я обозначу буквой а, событие, которое нас интересует и которое должно иметь меру
[51:42.000 --> 51:53.200]  стремящуюся к нулю. Так, сейчас я нарисую некое довольно страшное следствие из этого. И мне главное,
[51:53.200 --> 51:57.520]  чтобы за оставшееся время вы поняли, что это следствие верно, а оценки можем делать в следующий раз.
[51:57.520 --> 52:10.520]  Смотрите, я хочу сказать, что из а следует нечто. Нечто. Ну нечто будет очень длинным,
[52:10.840 --> 52:17.120]  я его буду долго писать. Я сейчас нарисую картинку, чтобы было гораздо понятнее. Если я докажу это,
[52:17.120 --> 52:22.320]  то я надеюсь все понимают, что чем бы оно ни оказалось, что бы ни было вот это нечто,
[52:22.320 --> 52:31.160]  чем бы оно ни было, то вероятность а, конечно, не больше, чем вероятность этого нечто. А вот
[52:31.160 --> 52:37.160]  и ее мы уже оценим там как-то. Ну если из а следует что-то, значит что-то большее. Правда
[52:37.320 --> 52:45.240]  а следует, значит а вложено в т. Что-то не меньшее, если строго говорить, то что-то не меньшее.
[52:45.240 --> 52:51.600]  Но там будет наверняка большее, но неважно. Нам нужна оценка просто вот такая, меньше либо
[52:51.600 --> 52:57.600]  равно. Нечто может и совпасть с а теоретически, это не жалко. Главное, чтобы импликация была
[52:57.600 --> 53:04.840]  именно в эту сторону. Так, ну я рисую картинку. Есть теновершин, сарделька это как обычно множество
[53:04.840 --> 53:17.640]  вершин нашего случайного графа. Вот смотрите, в чем состоит а. А состоит в том, что жадный
[53:17.640 --> 53:23.400]  алгоритм в каком-то смысле обломался. Ну ладно, обломался, но не нашел большого независимого
[53:23.400 --> 53:30.880]  множества. Но это я говорю банальность, это ну понятно. Все независимые множества, которые
[53:30.880 --> 53:34.880]  ему довелось найти этому жадному алгоритму, они имеют размер не больше, чем вот эта величина.
[53:34.880 --> 53:44.080]  Ну это я произношу тривиальность, правда? Давайте я введу вот такое обозначение. Вот здесь
[53:44.080 --> 53:58.320]  введу m. Это будет целая часть от m поделить на дважды 1-эпсилон налог двоичный. Ну ничего тут
[53:58.320 --> 54:03.720]  такого страшного нет. Это вот величина облома, так сказать, где обломался жадный алгоритм,
[54:03.720 --> 54:10.880]  на чем он остановился, на каком размере. И вот эту величину я ставлю в знаменатель и еще удваиваю.
[54:10.880 --> 54:30.720]  Ну такое вот число. Давайте я нарисую дальше картинку. T1, Tm. Что это такое? Это независимое
[54:30.720 --> 54:37.680]  множество, которое нашел наш жадный алгоритм. Он не нашел больших независимых множеств,
[54:37.680 --> 54:46.360]  но он точно нашел столько маленьких. Если он обломался, вот видите, я же импликацию строю,
[54:46.360 --> 54:52.040]  следствие. Если алгоритм обломался, то есть в целом не нашел ни одного большого независимого
[54:52.040 --> 55:02.640]  множества, то он точно совершенно нашел m штук маленьких независимых множеств. Ну вот,
[55:02.640 --> 55:07.280]  а мне хватит m, понимаете? Я же импликацию строю, вот я в очередной раз повторяю. Мне
[55:07.280 --> 55:12.560]  удобнее сейчас будет оценивать, если я скажу, что их m. Да, наверное, даже 2m, может даже больше.
[55:12.560 --> 55:18.120]  Мы же не знаем, насколько они маленькие, может они вообще по одной вершине кажут. Может же такой
[55:18.120 --> 55:26.240]  быть полный граф? Был бы полный граф, он бы нашел навершин просто отдельных, изолированных,
[55:26.240 --> 55:33.000]  больше ничего. То есть я не знаю, сколько он в точности нашел, но уж железно я понимаю,
[55:33.000 --> 55:39.480]  что не меньше, чем столько. Вот столько нашел. То есть вот это нечто, вот я его сейчас буду записывать,
[55:39.480 --> 55:54.520]  существуют a1 и так далее, а с индексом m, такие, что для любого i аитоя не превосходит 1-эпсилон на
[55:54.520 --> 56:07.640]  лог 2-ичный n. И существуют c1 и так далее, cm, такие, что для любого i жи, уж аккуратно напишу,
[56:07.640 --> 56:17.400]  ситое пересеченное с цежитом пусто. А, ну уж сначала написать, для любого i мощность ситое
[56:17.400 --> 56:26.840]  равняется аитому, и потом уже писать, что они не пересекаются. Которые являются независимыми,
[56:26.840 --> 56:32.480]  но я не буду даже этого писать. Просто существует непересекающееся множество, каждый из которых
[56:32.480 --> 56:40.080]  имеет мощность не большую, чем 1-эпсилон на лог 2-ичный n. То, что они независимы, это правда,
[56:40.080 --> 56:45.440]  но я же пишу импликацию, давайте я не буду упоминать, что они независимые. Вот мне это не нужно.
[56:45.440 --> 56:51.840]  С точки зрения будущей оценки мне плевать, что они независимые, хотя они, конечно, ковыри. Хотите
[56:51.840 --> 56:57.320]  напишите себе вот это те самые маленькие независимые множества, которые точно нашел
[56:57.320 --> 57:04.480]  жадный алгоритм? Точно нашел. Он не мог найти большие. Мы знаем, что он не мог найти большие,
[57:04.480 --> 57:10.240]  следовательно он точно нашел много маленьких. Много, но вот настолько много. Так, друзья,
[57:10.240 --> 57:16.440]  сейчас понятно, что такое мэ, что половина примерно от общего числа вершин. Маленькие
[57:16.440 --> 57:22.760]  сардельчики, они занимают примерно половину от большой. Ну не больше, чем половину от большой.
[57:22.760 --> 57:35.880]  Так, друзья, все уследили, да? Понятно, что происходит? Так, смотрите, для меня важно,
[57:36.560 --> 57:41.760]  вот сейчас вы должны осознать, для меня важно не то, что они независимые, хотя повторяю в третий
[57:41.760 --> 57:51.960]  раз это правда, для меня важно, что жадный алгоритм ни одной из них не смог нарастить.
[57:51.960 --> 58:09.560]  Я напишу вот так, для любого X, вот он X, принадлежащего сардельки без подсарделек,
[58:09.560 --> 58:15.560]  я его специально нарисовал вне вот этих подсарделечек и здесь то же самое написал,
[58:15.560 --> 58:22.880]  для любой вершины, которая не попала ни в один из этих независимых кусочков, для любой вершины
[58:22.880 --> 58:31.720]  X, не попавшей ни в один из этих независимых кусочков, для любого Y, существует Y, принадлежащий
[58:31.720 --> 58:42.440]  циитому, такой, что пара XY является ребром. То есть, какое бы циитое вы не взяли, есть и такое
[58:42.440 --> 58:49.880]  ребро, и такое, и такое, и такое, хотя бы одно. Мы не смогли ни к одному из этих кусочков добавить
[58:49.880 --> 58:56.280]  ни одной вершины, потому что жадный алгоритм так и работает, он двигается по нумерации вершин и
[58:56.280 --> 59:03.840]  выбирая очередную вершину, он не может ее добавить ни к одному из этих маленьких независимых, поэтому
[59:03.840 --> 59:13.800]  они маленькие. Как мы красим? Мы выбираем очередную вершину, мы пытаемся покрасить ее в какой-то из
[59:13.800 --> 59:19.800]  предшествующих цветов. Вот эти независимые множества при раскраске это цвета, разные цвета,
[59:19.800 --> 59:27.640]  и вот мы не можем эту вершину покрасить ни в цвет C1, ни в цвет C2, ни в цвет Cm, не можем
[59:27.640 --> 59:32.280]  ее добавить. Почему? Потому что есть хотя бы одно такое ребро, хотя бы одно такое, и так далее.
[59:32.280 --> 59:42.000]  Ну вы можете, знаете как, совсем, чтобы было максимально в голове укладывалось, максимально
[59:42.000 --> 59:48.840]  понятно. Ведь что такое A? A это просто множество графов, правильно? И тут написано множество
[59:48.840 --> 59:57.080]  графов, на самом деле событие это множество графов. Вот если граф принадлежит A, это значит,
[59:57.080 --> 01:00:05.480]  что на нем жадный алгоритм на этом конкретном графе. Он уже никакой не случайный, просто вот есть
[01:00:05.480 --> 01:00:11.480]  граф, который принадлежит множеству A. Вы на нем, на этом конкретном графе запускаете жадный алгоритм,
[01:00:11.480 --> 01:00:17.840]  и он не может построить большего, чем вот такого размера независимого множества. Но это в
[01:00:17.840 --> 01:00:24.840]  точности означает, что на этом графе найдется как минимум столько независимых кусочков, к которым
[01:00:24.840 --> 01:00:33.680]  жадный алгоритм ничего не сможет прибавить. Мне кажется, вот в таком вот рассуждении совсем
[01:00:33.680 --> 01:00:50.200]  понятно, о чем я сказал. Понятно, да, товарищи? О, как здорово! И у меня остается 15 минут. Не,
[01:00:50.280 --> 01:01:00.120]  ну что-то я могу посчитать. Начать считать? Я думаю, надо начать, иначе... Так, то есть я буду
[01:01:00.120 --> 01:01:05.760]  пользоваться вот этим. Вероятность A не превосходит вероятности того, что я написал в две строчки,
[01:01:05.760 --> 01:01:14.360]  плюс еще чуть не уместилось. Ну что поделать? Вот такая жизнь. Давайте считать с конца. Ну что
[01:01:14.360 --> 01:01:20.840]  значит считать с конца? Это мы зафиксируем какое-нибудь СИТ, вот мы зафиксируем какое-нибудь
[01:01:20.840 --> 01:01:34.200]  СИТ, зафиксируем какую-нибудь вершину Х и попробуем найти вероятность того, что существует
[01:01:34.200 --> 01:01:44.040]  Y из СИТово такой, что пара XY является ребром. Вот самый конец существует Y из СИТово такой,
[01:01:44.040 --> 01:01:55.640]  что XY образует ребро. Так, какова вероятность этого замечательного события? Какой вероятности
[01:01:55.640 --> 01:02:01.480]  данная конкретная вершина соединена хотя бы одним ребром с данным конкретным множеством?
[01:02:01.480 --> 01:02:16.240]  Ну ладно, я вам скажу. Ну, ага. Какое? Три строчки?
[01:02:31.480 --> 01:02:40.160]  Не, никакого потом. Вот нам дан уже совершенно актуальный граф, конкретный граф, принадлежащий множеству
[01:02:40.160 --> 01:02:45.280]  А. Он же не случайный, просто вот есть граф, лежащий этому множеству. Мы знаем, что он ему
[01:02:45.280 --> 01:02:51.760]  принадлежит. Это значит, когда мы запускаем жадный алгоритм, он найдет только маленькие независимые
[01:02:51.760 --> 01:02:57.000]  множества. Вот возьмем какие-то мы из них, почему он их не смог увеличить? Потому что каждая вершина
[01:02:57.000 --> 01:03:09.360]  это необходимое условие, конечно, да. Ну, я не знаю, что значит является достаточным. Я не очень понимаю,
[01:03:09.360 --> 01:03:13.640]  в чем вопрос или комментарий. То есть, если вы взяли конкретный граф, то для него это свойство
[01:03:13.640 --> 01:03:18.440]  выполнено просто. Не то, что необходимо или достаточно, а для него это свойство выполнено.
[01:03:18.440 --> 01:03:23.800]  Для него это свойство выполнено. Вот в нем те независимые множества, которые нашел жадный
[01:03:23.800 --> 01:03:29.760]  алгоритм, любые мы из них, таковы, что если вы возьмете любую вершину извне, то она не сможет быть
[01:03:29.760 --> 01:03:41.280]  прибавлена ни к одному из них. Может быть, но это не помогает улучшить оценку в итоге. Да-да-да,
[01:03:41.280 --> 01:03:46.400]  я не говорю, что это оптимальное следствие, конечно, можно немножко улучшить. Что понятно,
[01:03:46.400 --> 01:03:51.280]  что вот эти вот кванторосуществования, которые написаны тут, но они как бы тоже избыточные.
[01:03:51.280 --> 01:03:56.640]  Ясно, что это объединение фактически каких-то множеств графов. Когда мы берем кванторосуществует,
[01:03:56.640 --> 01:04:01.840]  это значит, что мы объединяем множество графов. Но они же пересекаются между собой. Наверное,
[01:04:01.840 --> 01:04:07.560]  это тоже надо как-то учитывать. Потом мы наплевали на то, что 3-ты независимы, хотя это так. Но это
[01:04:07.560 --> 01:04:13.040]  значит, что это просто не помогает оценке. Но аналитика так устроена, что это не влияет на итоговый
[01:04:13.040 --> 01:04:19.960]  результат. Это дает какое-нибудь там деление на n. Ну, а что с того, что вы экспоненту поделили на n?
[01:04:19.960 --> 01:04:26.320]  От этого ей ни тепло, ни холодно. Вот там смысл такой. Давайте сюда вернемся. Вероятность вот такая.
[01:04:26.320 --> 01:04:40.360]  Вот. 1 минус 1 вторая в степени аи-т. Понятно почему, да? Потому что с вероятностью 1 вторая в степени аи-т
[01:04:40.360 --> 01:04:49.000]  не проведено ни одно ребро. Не проведено ни одно. А хотя бы одно проведено, ну, с противоположной
[01:04:49.000 --> 01:04:56.720]  вероятностью. Ни одно ребро не проведено. Отсутствуют ребра с вероятностью 1 вторая. У нас p равно 1
[01:04:56.720 --> 01:05:03.760]  второй. 1 вторая в степени аи-т это, что все ребра из иксавца и ты отсутствует. Вообще все отсутствуют.
[01:05:03.760 --> 01:05:12.640]  Одно хотя бы присутствует. Это 1 минус вот эта вот штука. Так, чего я еще успею? Слушайте,
[01:05:12.640 --> 01:05:20.200]  я, наверное, успею добавить для любого и. Вот так вот. Если я напишу здесь, смотрите,
[01:05:20.200 --> 01:05:31.120]  я вот буду издеваться. Что изменится, товарищи? Так, друзья, я не хочу издеваться на самом деле.
[01:05:31.120 --> 01:05:35.800]  Я шучу, что я издеваюсь. Если я на самом деле издеваюсь, то срочно меня останавливайте и
[01:05:35.800 --> 01:05:43.000]  переспрашивайте. Ну, я просто не хочу 10 раз одно и то же переписывать. Но вот если не было этой
[01:05:43.000 --> 01:05:48.680]  вставочки, то вероятность мы посчитали. А с какой вероятностью выполнено, что для любого и вот такое?
[01:05:48.680 --> 01:05:56.640]  Что значит для любого? Это пересечение событий, правильно, по всем и. Произведение, потому что они
[01:05:56.640 --> 01:06:02.240]  по и независимы. У нас цииты и не пересекаются. Нам важно, что цииты и цежиты и не пересекаются.
[01:06:02.400 --> 01:06:11.840]  Поэтому вот эти вероятности надо просто перемножить. Перемножить по всем и от единицы до м. Вот эти
[01:06:11.840 --> 01:06:24.640]  вот штуковины. Вот эти штуковины надо перемножить. Так, друзья, поняли? Ну, слушайте, а тут еще есть для любого и.
[01:06:24.640 --> 01:06:37.040]  Ну, я постепенно вот сюда двигаюсь, справа налево. Но опять, а по и они тоже независимы,
[01:06:37.040 --> 01:06:42.360]  правда? Если я для вот этого и посчитал вероятность того, что он с каждой
[01:06:42.360 --> 01:06:48.720]  сарделькой соединен, вот она, произведение, и потом возьму какой-то другой и и посчитаю
[01:06:48.720 --> 01:06:53.480]  для него ту же самую вероятность, то дальше надо эти вероятности снова перемножить.
[01:06:53.480 --> 01:07:07.080]  Согласны? В каком количестве? Надо вот так написать скобка, а тут n-a1- и так далее,
[01:07:07.920 --> 01:07:17.040]  достаточно все успеваю? Это вот сколько вершин x находится вне подсардельщик,
[01:07:17.040 --> 01:07:24.560]  сколько x-ов находится вот в этой разности. Каждая c и t имеет мощность а и t, то есть мощность
[01:07:24.560 --> 01:07:32.320]  вот этого объединения это а1+, а2+, аm, а разность имеет мощность n-a1- и так далее,
[01:07:32.960 --> 01:07:56.560]  может, я успею, но только чтобы понятно было, товарищи. Не, наверное, не успею. Ну ладно,
[01:07:56.560 --> 01:08:09.520]  вот это оценить я успею. Смотрите, а и t, так, а и t, оно не больше вот этой величины.
[01:08:09.520 --> 01:08:20.080]  Одна вторая в степени аи значит не меньше, чем если я вместо аитова напишу вот это. С
[01:08:20.080 --> 01:08:26.480]  минусом снова не больше, а мне нужен знак именно в эту сторону, я хочу устремить к нулю вероятно.
[01:08:27.360 --> 01:08:37.040]  Я пишу не больше, продолжаю вот здесь не больше. Произведение по i единицы до m,
[01:08:37.040 --> 01:08:55.840]  1 минус 1 вторая, тут 1 минус эпсилон на лог двоичный. Так, ну до сюда понятно,
[01:08:55.840 --> 01:09:03.880]  да, что произошло. И теперь мне еще надо вот эту штуку как-то оценить. n пополам. Тумма вот этих
[01:09:03.880 --> 01:09:12.760]  аитов не больше, чем n пополам, но значит разность не меньше, чем n пополам, а поскольку она стоит в
[01:09:12.760 --> 01:09:18.360]  показателе числа меньшего единицы, то значок неравенства в нужную сторону. То есть вот здесь
[01:09:18.360 --> 01:09:33.760]  стоит n попал. Понятно откуда n пополам, да? Потому что каждая аито не больше, чем вот это, значит
[01:09:33.760 --> 01:09:40.920]  надо вот это умножить на m, а мы вот это умножаем на m не больше, чем n пополам.
[01:09:40.920 --> 01:09:50.600]  Так, ну смотрите, у нас от m сейчас вообще ничего не зависит, то есть надо просто в мэтую степень
[01:09:50.600 --> 01:09:56.920]  возвести. Никакого произведения уже по сути нет. Надо вот эту штуку просто всю возвести в мэтую
[01:09:56.920 --> 01:10:05.160]  степень. У нас получается вот так. Т1, я сразу вот это преобразую, 2 в степени лог двоичный,
[01:10:05.160 --> 01:10:16.960]  это n. У меня получается 1 поделить на n в степени 1 минус эпсилон, а тут будет m не пополам. И это
[01:10:16.960 --> 01:10:26.880]  я еще оценю стандартным образом как e в степени минус m не пополам умножить на 1 деленное на n в
[01:10:26.880 --> 01:10:34.920]  степени 1 минус эпсилон. Стандартная оценка 1 минус p не больше, чем e в степени минус p. Сегодня
[01:10:34.920 --> 01:10:48.480]  уже была. Так, ну давайте я еще это перепишу. Это e в степени минус m на n в степени эпсилон пополам.
[01:10:48.480 --> 01:10:58.800]  Ну и давайте еще m как-нибудь внизу оценю. Ну это скажем больше либо равно, нежели n поделить на
[01:10:58.800 --> 01:11:09.000]  4 лог двоичный. Целая часть оценивается половиной своего аргумента. Х не меньше, чем х попало.
[01:11:09.000 --> 01:11:16.800]  Целая часть х не меньше, чем х попало. Тупо оцениваю. У меня получается вот это вот не больше,
[01:11:16.800 --> 01:11:31.000]  чем e в степени минус. Так n в степени 1 плюс эпсилон поделить на 4. Логарифм двоичный.
[01:11:31.000 --> 01:11:39.800]  Вот так. Слушайте, ну это компактненько. Чуть-чуть страшноватенько, но в общем не смертельно.
[01:11:39.800 --> 01:11:41.800]  Согласны?
[01:11:47.800 --> 01:11:57.080]  Нет, оно было на 2. А, еще на 2. Да-да-да, на 8. Правильно, да. Спасибо большое. На 8. Тут было 2,
[01:11:57.080 --> 01:12:05.320]  вот тут было 2. И еще в оценке me у меня 4. Поэтому на 8. Ну это, конечно, никакой роли не играет,
[01:12:05.320 --> 01:12:11.000]  но все-таки давайте. Да, аккуратно, поэтому следите. Спасибо большое. На 8. Это мы не все,
[01:12:11.000 --> 01:12:20.960]  конечно, оценили. Знаете, откуда оценили? Мы оценили вот отсюда. Но нам еще надо
[01:12:20.960 --> 01:12:27.560]  кванторосуществование как-то учесть. Так, дорогие друзья, вот я уже об этом говорил,
[01:12:27.560 --> 01:12:33.640]  я еще раз, помедленнее это повторю. Вы понимаете или нет, что если появляется кванторосуществование,
[01:12:33.640 --> 01:12:41.640]  то это фактически объединение. Или-или-или существует, это значит или-или-или. Существует
[01:12:41.640 --> 01:12:48.960]  С1, это значит хотя бы одно С1 подойдет под вот это условие. То есть надо взять объединение по
[01:12:48.960 --> 01:12:56.440]  всем циитам, которые обладают вот этими свойствами. Вот эта вот вероятность нечто,
[01:12:56.440 --> 01:13:11.960]  она на самом деле не превосходит суммы по А1, суммы по Ам. Ну, естественно, таким,
[01:13:11.960 --> 01:13:22.720]  что они не больше, чем, ну давайте я напишу, 2t не больше, чем 1-эпсилон налог двоичный. И дальше
[01:13:22.720 --> 01:13:32.880]  будет сумма по С1, сумма по См. И здесь будет то, что циитая, пересеченная с циитам, пусто. Что
[01:13:32.880 --> 01:13:41.520]  мощность каждого циитого равняется аитому. А вот тут будет вот эта вот ешечка в отрицательной
[01:13:41.520 --> 01:13:50.840]  степени. Вот это вот вероятность А так оценивается. Так, сумма откуда взялась, но вероятность объединения не
[01:13:50.840 --> 01:14:00.120]  больше, чем сумма вероятности. Непонятно насчет полинома, понимаете? Дело в том,
[01:14:00.120 --> 01:14:11.200]  что каждая циита это выбирается сколькими способами. С из Н по аитому. Так, друзья, до сюда понятно,
[01:14:11.200 --> 01:14:17.040]  что произошло. Все раз, вот эти кванторы существования, они под знаком вероятности
[01:14:17.040 --> 01:14:24.800]  превратились в объединение. А вероятность объединения, она не больше, чем сумма вероятностей. Вот вероятности,
[01:14:24.800 --> 01:14:30.680]  которые суммируются, мы оценили, они не превосходят отрицательные экспоненты. Но теперь они суммируются
[01:14:30.680 --> 01:14:36.960]  по всем возможным способам выбрать вот эти числа А и Т и по всем возможным способам выбрать цииты
[01:14:36.960 --> 01:14:49.800]  соответствующими свойствами. До сюда понятно? Понятно? Нет вопросов. Значит, я вынужден сейчас оборвать
[01:14:49.800 --> 01:14:56.640]  свою речь. Осталось очень немного. Вы видите, что вот эта вот экспонента, она вообще-то от циитового
[01:14:56.640 --> 01:15:02.560]  вообще никак не зависит. То есть, практически нам надо просто посчитать количество слагаемых и
[01:15:02.560 --> 01:15:09.240]  умножить на эту экспоненту. Ну, чуть-чуть я не успеваю, мне надо бежать на защиту, на кандидатскую.
[01:15:09.240 --> 01:15:16.840]  Давайте в следующий раз я минут за 10 это дожму. Запомните, что мы на этом остановились, вдруг я
[01:15:16.840 --> 01:15:21.320]  что-то забуду. Еще раз повторю. Все, спасибо.
