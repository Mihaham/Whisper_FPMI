[00:00.000 --> 00:08.000]  Чистое медло – решение систем линейных уравнений и чистое медло –
[00:08.000 --> 00:13.440]  система нелинейных уравнений. В общем, эта тема очень-очень близкая, особенно вторая тема.
[00:13.440 --> 00:19.000]  При решении систем нелинейных уравнений эта тема совсем близка и даже в какой-то степени
[00:19.000 --> 00:24.240]  аналогична. Медлодоматемизация, все медлодоитерационные, все медлодометоды похожие.
[00:24.240 --> 00:32.800]  Ну, позже мы к этому тоже будем возвращаться. Уже можно говорить, ребят? Уже можно, а?
[00:32.800 --> 00:40.400]  Сегодняшняя тема лекций. Мы продолжаем чистое медло – решение обыкновенных дифференциальных
[00:40.400 --> 00:48.040]  уравнений. Методы решения задач каши основные мы с вами разобрали. То, что мы разобрали – это,
[00:48.040 --> 00:52.840]  что есть самые рабочие методы, которые используются для решения совершенно
[00:52.840 --> 01:00.240]  конкретных реальных задач. Физики, химии, медицины, экономики и так далее. Они везде
[01:00.240 --> 01:07.160]  используются. Я даже не знаю, где они используются, но что могу сказать, что дифференциальные уравнения,
[01:07.160 --> 01:14.920]  особенно нестационарные, это вот такой подход, который позволяет делать модели прогностическими.
[01:14.920 --> 01:21.160]  То есть предсказывать по времени развитие процессов. И вот, к сожалению, на сегодняшний день,
[01:21.160 --> 01:27.120]  пожалуй, что это является, наверное, единственным, наиболее надежным прогностическим методом.
[01:27.120 --> 01:31.720]  Хотя моделей существует много, есть дискретные модели, дискретные отображения, мы с вами о них
[01:31.720 --> 01:39.760]  говорили. Вот эти методы пока наиболее надежны. Хотя, конечно, математики думают и о других моделях.
[01:39.760 --> 01:45.160]  Но вот в плане прогностических моделей пока самые эффективные, самые надежные являются
[01:45.160 --> 01:50.240]  дифференциальные уравнения, нестационарные дифференциальные уравнения. Ну, разумеется,
[01:50.240 --> 01:56.440]  мы будем говорить и о нестационарных, и о стационарных, разумеется. Но вот сегодня мы поговорим
[01:56.440 --> 02:03.100]  о краевых задачах для обыкновенных дифференциальных уравнений. Задачи Каши мы говорили теперь о
[02:03.100 --> 02:09.420]  краевых задачах. Ну, краевые задачи, так условно, можно раздвинуть это обыкновенное дифференциальное
[02:09.420 --> 02:14.140]  уравнение на два класса. Первый класс – это система уравнений первого порядка, это обязательно
[02:14.140 --> 02:20.820]  система уравнений. То есть, если краевая задача, то и уравнение первого порядка, то обязательно,
[02:20.820 --> 02:28.860]  как минимум, два уравнения должно быть. И второй класс, я говорю о тех классах, которые наиболее
[02:28.860 --> 02:33.700]  широко используются для решения совершенно конкретных задач. Второй класс – это задача типа штурма
[02:33.700 --> 02:40.580]  Лиувилля. Это краевые задачи, уже порядка выше первого. Чаще всего это второй порядок,
[02:40.580 --> 02:46.620]  значит, бывает четвертый порядок. Ну, и довольно редкий случай – это шестой порядок дифференциальных
[02:46.620 --> 02:53.180]  уравнений. В нелинейных уравнениях физики встречаются. Такие задачи встречаются. Вообще говоря,
[02:53.180 --> 02:59.020]  нелинейные задачи физики – это отдельный такой пункт не только для физики, а может быть не
[02:59.020 --> 03:05.900]  столько для физики, сколько для математики и для численных методов. Я надеюсь, что у нас
[03:05.900 --> 03:13.380]  будет время на эту тему отдельную лекцию прочитать, поскольку эти задачи на самом деле не только
[03:13.380 --> 03:19.620]  физические. Практически все, я активно взаимодействую со специалистами по экономике,
[03:19.620 --> 03:28.300]  по социологии. Практически все реальные модели берутся из физики. Даже при моделировании
[03:28.300 --> 03:38.420]  ряда процессов в IT-технологиях, в частности распространения информации по разным каналам,
[03:38.420 --> 03:46.500]  тоже используется уравнение математической физики, хотя ряд моделей используется и без них.
[03:46.500 --> 03:55.140]  Давайте начнем с первого типа, о котором я говорил. К методам решения относят метод
[03:55.140 --> 04:04.260]  фундаментальных систем. Сначала я напишу систему уравнений, которую мы будем рассматривать.
[04:04.260 --> 04:14.100]  Я пишу простейшую систему уравнений. Она либо линейная, либо с переменными коэффициентами,
[04:14.100 --> 04:22.540]  в частности Х. Вообще говоря, она может быть и нелинейная и так далее. О нелинейных мы поговорим чуть
[04:22.540 --> 04:28.100]  позже, поскольку методы решений нелинейных задач отличаются от методов решений линейных задач.
[04:28.100 --> 04:34.860]  Часто редуцируется действительно метод решений линейных задач к методам решений линейных. Это
[04:34.860 --> 04:42.660]  часто бывает, но бывает, что это методы совершенно самостоятельные. Итак, у нас система уравнений.
[04:42.660 --> 04:50.180]  Это система уравнений. Как я и говорил, чтобы не заграбождать записи, я не буду ставить в значке векторов.
[04:50.180 --> 05:00.620]  Итак, у нас формы много. У решения f правая часть относится к конвертному евклидовому пространству,
[05:00.620 --> 05:08.860]  а матрица с постоянными коэффициентами квадратная размера n на n. То есть это система уравнений.
[05:08.860 --> 05:17.100]  Ну и коль задача краевая, то мы должны сюда поставить краевые условия. Краевые условия,
[05:17.100 --> 05:28.100]  значит, будем ставить так. х у нас меняется от 0 до, подавайте до n, например, для нашей внутренней
[05:28.100 --> 05:37.380]  задачи. И краевые условия могут быть связаны на обеих концах, могут быть развязаны на обоих концах,
[05:37.380 --> 05:47.260]  простите. Так, ну мы можем записать, например, так. r это тоже матрица на u, 0, u это вектор,
[05:47.260 --> 05:58.980]  плюс s тоже это матрица на u от l правый конец, и равняется q. Ну q это понятно, что это тоже будет
[05:58.980 --> 06:07.340]  вектор, то есть принадлежит n-мерному евклидовому пространству. r и s это матрица, то есть они
[06:07.340 --> 06:15.100]  принадлежат линейному пространству, линейному нормерному пространству матриц размера n на n,
[06:15.100 --> 06:24.900]  то есть это матрица. Ну я думаю, что вы еще не забыли курс дифференциальных уравнений,
[06:24.900 --> 06:34.220]  которые проходили в прошлом году, поэтому я напишу общее решение вот этой системы уравнения.
[06:34.220 --> 06:39.420]  Дальше перейду уже к тому, как оно может быть реализовано численно, но, разумеется,
[06:39.420 --> 06:45.360]  это общее решение хорошо выписывается для случаев линейных систем, либо систем с
[06:45.360 --> 06:50.660]  переменными коэффициентами. Если появляются нелинейности, приходится здесь что-то додумывать.
[06:50.660 --> 06:58.940]  В чистом виде, конечно, нелинейные задачи всегда намного сложнее линейных. Ну а жизнь построена так,
[06:58.940 --> 07:06.580]  что самые интересные процессы и в физике, и в экономике и так далее нелинейные. Поэтому мы
[07:06.580 --> 07:12.700]  будем говорить о линейных задачах как о базе для чистых методов решений нелинейных задач,
[07:12.700 --> 07:20.020]  ну и часто сводить нелинейные задачи, резуцировать к решению нескольких линейных. Итак,
[07:20.020 --> 07:26.340]  если мы захотим общее решение выписать вот этой системы уравнений, только я очень крупно пишу,
[07:26.340 --> 07:34.300]  то это общее решение будет иметь вид, который вы, конечно же, хорошо знаете из курса дифференциальных
[07:34.300 --> 07:46.660]  уравнений. Это частное решение с однородными условиями, с однородными начальниками условий.
[07:46.900 --> 07:54.780]  Я оговорю сейчас. Мы сейчас пытаемся свести краевую задачу к решению n задач каши. Это в этом
[07:54.780 --> 08:04.780]  суть метода фундаментальных систем. Сначала мы ищем общее решение как суперпозицию решения
[08:04.780 --> 08:14.620]  неоднородной задачи с однородными краевыми условиями, начальными условиями и фундаментальная
[08:14.620 --> 08:30.180]  система уравнений линейных. Это запись, которую вы, я думаю, помните. Здесь линейная система
[08:30.780 --> 08:36.980]  однородных уравнений с неоднородными начальными условиями. Это, наверное, вам фраза знакома.
[08:36.980 --> 08:47.580]  Я сейчас напомню, на всякий случай, чтобы точно быть уверен, что вы все это знаете.
[08:47.580 --> 08:55.500]  Что касается линейной системы уравнений, мы можем искать ее решение в таком виде.
[08:55.500 --> 09:07.380]  ДУК по ДХ, это у нас будет АУК. УК, разумеется, это уже компоненты. Здесь у нас однородная
[09:07.380 --> 09:17.260]  система уравнений получается, но начальные данные будут неоднородные. УК от 0, это у нас будет вот
[09:17.260 --> 09:26.060]  такой вектор. Это ОРТ, я его просто расписываю, на всякий случай. Это хорошо вам знакомый вектор ЕК.
[09:26.060 --> 09:45.980]  Это неоднородные ограниченные условия. Сегодня у нас первый день занятия. Чувствуется,
[09:45.980 --> 09:58.380]  тряпка идеально сухая. Как будто ее сушили как минимум месяц. Что касается системы
[09:58.380 --> 10:13.220]  однородных уравнений, то здесь будет следующая система уравнений. Это система уравнений,
[10:13.220 --> 10:20.900]  но у Созвездо это как раз у нас решение неоднородного уравнения. Равняется 0, то есть
[10:20.900 --> 10:27.620]  здесь начальные условия будут неоднородные. Суперпозиция дает нам их точное решение.
[10:27.620 --> 10:39.540]  Но, конечно, в случае задач простейших, то есть линейных. Если мы захотели чисто решать задачу,
[10:39.700 --> 10:46.180]  например, вот эту задачу, мы можем предложить какой-то чистый метод. Поскольку дифференциальный
[10:46.180 --> 10:52.020]  уравнение, я имею в виду метод для решения задачи корши. Мы с вами уже проходили эту тему,
[10:52.020 --> 10:58.780]  мы знаем, как решается задача корши, какими методами. Например, метод иеронгекута, хотя есть целый
[10:58.780 --> 11:05.060]  ряд и других методов. По крайней мере, среди явных методов, конечно, наиболее реальные методы
[11:05.060 --> 11:10.340]  иеронгекута разных по разному порядку аппроксимации. Например, возьмем простейший метод,
[11:10.340 --> 11:19.420]  я специально беру пока простой, чтобы не сильно усложнять ситуацию. Например, вот такой
[11:19.420 --> 11:28.940]  возьмем разностный метод. Первая производная, я аппроксимирую вот это уравнение. Здесь будет,
[11:28.940 --> 11:35.480]  например, ан плюс одна вторая, поскольку коэффициенты матрица могут зависеть от нашей
[11:35.480 --> 11:45.260]  независимой переменной. И здесь, например, так возьмем ун плюс один, унк пополам. Такие формы мы
[11:45.260 --> 11:51.580]  с вами писали. Например, так. Разумеется, это довольно простой чистый метод, можно его сделать
[11:51.580 --> 11:57.780]  более сложным, более точным и так далее. Пока этим заниматься не будем, поскольку сейчас это не
[11:57.780 --> 12:15.180]  очень принципиально. Ну и можно, в принципе, выписать в операторной форме решение этой задачи.
[12:15.180 --> 12:29.420]  Укн плюс один, это будет единичный оператор минус аж пополам, ан плюс одна вторая в минус первой,
[12:29.420 --> 12:44.460]  так и на похожее выражение е плюс аж пополам, ан плюс одна вторая, и здесь екн. То есть, в принципе,
[12:44.460 --> 12:50.740]  можно в операторной форме выписать явное решение. Ну, разумеется, решать ли задачу в операторной
[12:50.740 --> 12:59.300]  форме чисто либо в виде разносной задачи. Практика показывает, что это одно и то же. Поэтому можно
[12:59.300 --> 13:07.660]  решать разносную задачу. При этом можно выписывать в таком операторном виде решение. Что касается
[13:07.660 --> 13:22.060]  вот этой задачи, то есть задачи для уравнения неоднородного, то в общем-то можно поступить
[13:22.060 --> 13:35.700]  аналогичным образом. Аналогичным образом можно также выписать подобную разностную схему для
[13:36.300 --> 13:45.900]  задачи неоднородной. Усо звездой н плюс один, минус усо звездой н, делим на аж, здесь будет а,
[13:45.900 --> 13:59.100]  ан плюс одна вторая, усо звездой н плюс f, давайте n плюс одна вторая. Ну, тоже я довольно простой беру
[13:59.100 --> 14:06.940]  такую аппроксимацию. Не сложно взять более сложную, в смысле более высокого порядка
[14:06.940 --> 14:13.420]  аппроксимации. Ну, мы с вами просто это вопрос уже обсуждали в январе, что есть уже и стандартные
[14:13.420 --> 14:19.820]  программы, есть методы Рунгикута, которые имеют другие названия высокого порядка точности,
[14:19.820 --> 14:26.420]  ну, где-то до десятого порядка точности примерно. Вот так вот реально используется в жизни. Есть,
[14:26.420 --> 14:33.340]  конечно, медные более высоких порядка точности, но там в чем проблема? Можно сделать точность метод
[14:33.340 --> 14:38.700]  таковую, что она будет конкурировать с машиной по грешности, то есть вы будете, как говорится,
[14:38.700 --> 14:45.700]  работать, точнее компьютер будет работать фолостонно на такую точность, на которую он не рассчитан.
[14:45.700 --> 14:54.100]  Вот это такие моменты есть. Ну, тоже можно выписать общий вид решения. В оператном форме он будет
[14:54.100 --> 15:02.980]  похож на то, что мы уже писали, но немного изменится, поскольку у нас есть правая часть,
[15:02.980 --> 15:14.100]  минус первый, здесь у нас Е минус плюс H пополам, Е плюс H пополам, АН плюс 1, вторая,
[15:14.100 --> 15:27.140]  У со звездой N, ну и плюс H на ФН плюс 1, вторая. Ну и если мы вот так выписываем решение,
[15:27.140 --> 15:32.540]  разность, то здесь тот случай, когда разность на уровне тоже имеет решение. Ну, я специально,
[15:32.540 --> 15:37.940]  так сказать, берут задачи такие достаточно простые, чтобы они имели точное решение. Усложить
[15:37.940 --> 15:41.980]  задачу ничего не стоит, достаточно поставить какой-нибудь нелинейный коэффициент и все.
[15:41.980 --> 15:48.860]  Если разумеется, можно задачи линейризовывать, что чаще всего и делают, вообще говоря, в практике,
[15:48.860 --> 15:55.140]  и так далее, по-разному упрощают, чтобы как-то свести вот к этим задачам. Ну и кроме того,
[15:55.140 --> 16:04.620]  у нас есть условия граничные. Нужно их, конечно же, учесть. Граничные условия мы учитываем для
[16:04.620 --> 16:12.060]  вычисления коэффициентов альфа-катых. То есть в фундаментальной системе решений присутствует
[16:12.060 --> 16:16.580]  коэффициент альфа-каты. Откуда их мы можем взять? Только из гранических условий. У нас больше
[16:16.580 --> 16:21.620]  ничего нет. У нас есть уравнение и два краевых условия, на левой и на правой границе, либо одно
[16:21.620 --> 16:28.220]  связанное. Левая и правая границы. Когда связаны условия, давайте я все-таки выпишу. Конечно,
[16:28.220 --> 16:33.700]  ситуация посложнее. Почему? Потому что приходится решать систему линейных алгебраических уравнений.
[16:33.700 --> 16:40.380]  Ну хорошо, если она там десятого порядка, не высокого, проблем нет. Но часто в практике бывают
[16:40.380 --> 16:47.940]  системы линейных уравнений порядка четвертого, пятого, шестого и выше. И тогда левая погрешность
[16:47.940 --> 16:54.020]  тоже сказывается на решение. И нужно быть очень аккуратным. Мы вот об этом с вами где-то в сентябре,
[16:54.020 --> 16:59.900]  на сетябре, в воскреске говорили. Вспоминать об условности задачи и так далее. Иначе все ваши
[16:59.900 --> 17:06.700]  усилия по решению численными задачи могут оказаться неэффективными. То есть получить
[17:06.700 --> 17:15.260]  нефизичное решение задачи, ну либо неэкономичное в зависимости от задачи. Я просто переписываю уже
[17:15.260 --> 17:27.100]  в новом виде. Наши условия усозвездой от 0, плюс система здесь алькфокатой, укатой тоже от 0,
[17:27.100 --> 17:36.100]  сумма покатая и плюс с. Это вторая граница, значит здесь у нас связаны условия усозвездой от l,
[17:36.100 --> 17:44.900]  это правая граница и плюс система фундаментальных решений наших. Увкатая от l,
[17:44.900 --> 17:57.020]  к равняется 0 до n. Ну, равняется 0, конечно, равняется 0. Ну вот эта связная система является
[17:57.020 --> 18:03.300]  системой линейных алгебридических уравнений для определения коэффициентов альфокатых,
[18:03.300 --> 18:12.620]  коэффициентов как раз нашей фундаментальной системы. Ну вот, это вот метод, который называется
[18:12.620 --> 18:21.420]  метод фундаментальных систем. Он хорош чем? Он очень прост, прост для реализации компьютерной,
[18:21.420 --> 18:27.500]  программной и тому подобное. Но вычислительная математика, как я неоднократно говорил,
[18:27.500 --> 18:35.180]  наука не простая. У нее всегда есть подводные камни, не один подводный камень, несколько. Где здесь
[18:35.180 --> 18:41.340]  могут быть подводные камни? Конечно, если все хорошо, то считайте, что вам повезло, вы спокойно
[18:41.340 --> 18:51.060]  решаете систему уравнения. Ну, один подводный камень кроется здесь, то есть система линейных
[18:51.060 --> 18:55.980]  уравнений может оказаться плохо обусловленной. Если система оказывается плохо обусловленной,
[18:55.980 --> 19:03.460]  вам приходится, значит, что-то думать. Я говорил, что есть предобусловленные системы линейных
[19:03.460 --> 19:10.860]  уравнений, они очень активно используются, поскольку одна система уравнений, грубо говоря,
[19:10.860 --> 19:15.900]  заменяется на другую, но такую, чтобы решения оставались одинаковыми. Такими хитростями
[19:15.900 --> 19:23.660]  в линейной алгебре вычислительная пользуется, как говорится, постоянно. Хотя бывают ситуации,
[19:23.660 --> 19:32.220]  когда и это не помогает. Но если система хорошо обусловлена, проблем нет. Ну и второй момент.
[19:32.220 --> 19:41.780]  Давайте второй момент я чуть-чуть разберу подробнее, поскольку это касается уже жесткости систем
[19:41.780 --> 19:47.180]  обыкновенных дифференциальных уравнений. Мы с вами говорили о понятии жесткой системы обыкновенных
[19:47.180 --> 19:55.180]  дифференциальных уравнений для задачи каши. Ну тема эта очень важная, хотя потому что,
[19:55.180 --> 20:03.860]  наверное, все-таки большинство задач реальных предметных областях они а, нелинейные, и б,
[20:03.860 --> 20:09.260]  жесткие. Я не хочу сказать, что все задачи нелинейные, все жесткие, это неправда,
[20:09.260 --> 20:16.900]  но большинство задач, наверное, то, что нелинейные, это точно. Но, в общем-то, я, наверное, буду прав,
[20:16.900 --> 20:22.060]  если скажу, что большинство задач являются и жесткими вещами. Ну что значит жесткость? Это означает,
[20:22.060 --> 20:29.300]  что вы рассчитываете какой-то сложный процесс, в котором присутствует несколько, ну например,
[20:29.300 --> 20:36.380]  динамических процессов с очень разными, очень разными характерными временами протекания. То есть,
[20:36.380 --> 20:46.300]  разность может там достигать очень больших значений, там 10, 6 и больше. И тогда вот стандартные
[20:46.300 --> 20:52.300]  методы решения не проходят, но мы с вами говорили, что здесь используются целые классы неявных
[20:52.300 --> 21:01.420]  чистных методов, вот многошаговых методов и так далее, для решения вот таких задач. На сегодняшний
[21:01.420 --> 21:07.900]  день, наверное, самый популярный метод, ну для задач каши, правда, жесткий задач каши, это является
[21:07.900 --> 21:13.860]  метод Гира, я вам об этом говорил. Ну он имеет шестой порядок точность, шестой порядок опроксимации,
[21:13.860 --> 21:19.900]  ну вполне приличный для решения очень многих, так сказать, практических задач. Ну хотя существует
[21:19.900 --> 21:26.420]  целый класс методов онлегикута неявных, которые тоже могут иметь высокий порядок точности и так
[21:26.420 --> 21:37.300]  далее. Ну здесь приходится выбирать в зависимости от ситуации, в зависимости от задачи. То есть сказать,
[21:37.300 --> 21:43.020]  что существует некий универсальный метод, который вы берете и вот все подряд решаете, нет таких
[21:43.020 --> 21:50.260]  методов. Хотя, конечно, для довольно простых инженерных задач, технических, ну есть такие
[21:50.260 --> 21:54.580]  методы, которые в большинстве своем работают, ну в большинстве своем работают. Существует
[21:54.580 --> 22:02.020]  довольно много интегральных пакетов, вы знаете, да, я, может быть, как-нибудь вам перечислю основные
[22:02.020 --> 22:08.660]  интегральные пакеты, которые созданы в мире для решения тех или иных классов задач, но сказать,
[22:08.660 --> 22:15.300]  что эти пакеты тем не менее решают все задачи, существующие было бы, конечно, большой натяжкой,
[22:15.300 --> 22:21.660]  большой натяжкой. Вот могу сказать по опыту нашей кафедры, конечно, та научная работа,
[22:21.660 --> 22:28.300]  которая ведется в нашу кафедру, там дипломники, которые решают, аспиранты, конечно, это задачи,
[22:28.300 --> 22:35.300]  которые не берут ни наши, ни американские, ни немецкие интегральные пакеты. Таких задач
[22:35.300 --> 22:40.700]  довольно много. Которые пакеты, ну как, они в какой-то степени берут, но получаются довольно
[22:40.700 --> 22:47.900]  неточные решения. Так, ну идем дальше. Итак, это вот мы поговорили о медно-фундаментальных системе,
[22:47.900 --> 22:55.100]  теперь вот простой пример, когда вроде бы очень простая система уравнений, проще я уже не могу
[22:55.100 --> 23:17.340]  придумать всего два уравнения. Вот, они линейные. Вот так. Вот у нас два уравнения, неизвестные у и в,
[23:17.340 --> 23:27.980]  переменная х, ну пусть давайте, чтобы проще было все предельно упростить, х меняется от нуля до единицы,
[23:27.980 --> 23:40.100]  у от нуля равняется единице, в от нуля равняется нулю, ну давайте еще проще сделаем. Пусть у нас система
[23:40.100 --> 23:45.060]  будет однородной, в данном случае это не очень принципиально. Пусть правой части тоже, давайте
[23:45.060 --> 23:52.020]  примерно там положим равную нулю пока. Разумеется, это ничего не меняет, они могут быть и не нулевыми,
[23:52.020 --> 24:03.420]  и не нулевыми. Вот, а вот коэффициенты а и b, ну давайте положим такими, 10 в квадрате, то есть они
[24:03.420 --> 24:09.900]  достаточно довольно большие, скажем так, они уже не о большой от единицы. Ну, я вам говорю, что когда
[24:09.900 --> 24:16.860]  я пишу какие-то коэффициенты и молчу при этом, то я по умолчанию полагаю, что эти коэффициенты порядка
[24:16.860 --> 24:23.820]  у большой от единицы. Вот, если это не так, то я оговариваю, поскольку если мы имеем малый параметр
[24:23.820 --> 24:29.740]  либо большие параметры, ну малый параметр это единица делить на большой параметр, то есть в некотором
[24:29.740 --> 24:38.580]  смысле это одно и то же, то приходится порой менять численный метод, а порой и модель. Вот, то есть
[24:38.580 --> 24:48.900]  малые параметры вносят очень много проблем в числе решения задач. Поэтому я об этом буду говорить.
[24:48.900 --> 24:56.220]  Ну, решение этой задачи, как вы прекрасно видите, тоже мы можем написать так же, как мы и писали раньше,
[24:56.220 --> 25:07.220]  то есть у и в это решение неоднородной системы уравнений и плюс решение однородной системы уравнений,
[25:07.220 --> 25:16.620]  то есть фундаментальная система альфа-1 это у и в, а один и альфа-2, здесь всего-то у нас две переменных,
[25:16.620 --> 25:26.820]  поэтому всё предельно просто, на альфа-2. То есть у нас вот, здесь вот у нас, если положим правую часть нули,
[25:26.820 --> 25:32.260]  то неоднородная система уравнений нулевая, то есть получается две вот таких задачки.
[25:32.260 --> 25:40.900]  Теперь, что такое у и в? Ну, вы прекрасно помните решение этих задач наверняка, это есть сумма экспонентов,
[25:40.900 --> 25:51.300]  но в данном случае сумма двух экспонентов. Ну, например, а и b это коэффициент, который определяется из гранических условий,
[25:51.300 --> 26:06.340]  на е в степени лямбда-1х плюс а и b е в степени лямбда-2х, ну, здесь только давайте единичку поставим, а здесь двойку.
[26:06.340 --> 26:14.740]  То есть сумма двух экспонентов, ну, и то же самое для у и в, то же самое для у и в-2.
[26:15.380 --> 26:25.780]  У и в-2, это есть у нас что такое, а и b, ну, тоже с единицей, только давайте штрих, это уже другие коэффициенты.
[26:25.780 --> 26:40.180]  А вот экспоненты те же самые, лямбда-1х плюс а и b на два экспонента лямбда-2х. Ну, откуда мы берём лямбда-1, лямбда-2?
[26:40.260 --> 26:46.740]  Кто мне подскажет, откуда мы их берём? Чтобы я убедился в том, что вы помните второй курс.
[26:50.740 --> 26:57.220]  Ну, собственные значения матрицы якобы правых частей уравнения, всё правильно.
[26:57.220 --> 27:06.020]  Вот у нас правые части, да, это a, v и b. Вот возьмите от них матрицу якобы, то есть нам нужно решить простенько уравнение.
[27:06.020 --> 27:15.860]  Детерминат вот такой матрицы, минус лямбда, ну, а и b, минус лямбда, равняется нулю.
[27:17.860 --> 27:22.100]  Так здесь надо что-то стирать уже. Равняется нулю.
[27:22.180 --> 27:34.660]  Ну, давайте лямбда-1, либо лямбда-2, это плюс-минус корень из a, b. Из a умножить на b просто, да.
[27:34.660 --> 27:48.660]  Или просто это плюс-минус 10 в квадрате, то есть плюс-минус 100. Я вот так отчерчу, чтобы было понятно, что это отдельный такой кусок.
[27:49.220 --> 28:07.220]  То есть лямбда-1, 2 это плюс-минус 100. И что у нас получается? Понятно, что общее решение, поскольку неоднородное значение мы положили равную нулю, состоит из четырёх экспонентов.
[28:07.220 --> 28:14.260]  Вот здесь имеет смысл, вообще говоря, всегда имеет смысл вспоминать про предметные области, в которых мы работаем.
[28:14.260 --> 28:21.860]  Вот эта задача, это есть сильное упрощение, ну, невероятно сильное упрощение, задачи о безопасности атомных реакторов.
[28:21.860 --> 28:29.860]  Вот, на самом деле эта задача о проникании нейтронов через оболочки, например, бетонные, значит, атомных реакторов.
[28:29.860 --> 28:35.860]  То есть, естественно, при этом эти потоки нейтронов должны ослабляться, а не усиливаться.
[28:35.860 --> 28:47.460]  То есть это означает, что у нас есть две экспоненты с положительными лямбда, то есть плюс 100 и отрицательными экспоненты минус 100.
[28:47.460 --> 28:53.460]  То есть, одни экспоненты у нас очень быстро растут две, а две экспоненты очень быстро падают.
[28:53.460 --> 29:01.460]  Совершенно естественно, предположите, из физических соображений, что те экспоненты, которые быстро растут, должны взаимно уничтожиться.
[29:01.460 --> 29:05.060]  Значит, смысл физической задачи просто будет отсутствовать.
[29:05.060 --> 29:11.060]  Потоки нейтронов либо гамма-частиц будут усиливаться, а не ослабляться.
[29:11.060 --> 29:17.060]  То есть должны остаться две экспоненты, которые быстро падают, быстро падают.
[29:17.060 --> 29:23.060]  Это в точном решении, да, это получить можно, но я предложил очень простую задачу, где есть точное решение.
[29:23.060 --> 29:32.660]  Конечно, в реальных задачах система уровней высокопорядка, нелинейной и так далее, ну и конечно решать нужно чисельные задачи.
[29:32.660 --> 29:44.660]  Ну вот, что получится, если мы пронебрежем машинными ошибками при таких вот больших экспонентах.
[29:44.660 --> 29:56.660]  Представьте себе, что у нас есть решение машинное, это есть решение некое точное, и единица плюс машинная погрешность, единица плюс машинная погрешность.
[29:56.660 --> 30:02.660]  Ну пусть у нас, например, обновится экспонент больший, что это такое будет?
[30:02.660 --> 30:10.660]  Это будет е в степени 100, ну на t, ну пусть t для простоты будет равняться единичке.
[30:10.660 --> 30:18.660]  А здесь единица плюс 10, ну например, машинную точность возьмем 10-12 степени.
[30:18.660 --> 30:22.660]  То есть мы получим, конечно, явно неинтересное решение.
[30:22.660 --> 30:30.660]  Оно будет очень грубым, с огромными ошибками, и к физике задачи отношения иметь не будет.
[30:30.660 --> 30:44.660]  То есть вот здесь мы пришли как раз к моменту, когда нужно дать понятие жесткой краевой задачи для обыкновенных дифференциальных уравнений.
[30:44.660 --> 30:53.660]  То есть если вы возьмете какую-то стандартную программу для решения краевых задач и будете решать задачи с такими вот параметрами,
[30:53.660 --> 31:01.660]  малыми или большими, вы можете получить, в общем-то, совершенно, так сказать, нереальный результат.
[31:01.660 --> 31:04.660]  То есть здесь нужно быть, конечно, очень-очень аккуратным.
[31:04.660 --> 31:09.660]  Обычно перечисленным решением вы не пишете программу.
[31:09.660 --> 31:16.660]  Вам не написали программу, или вы берете ли вы интегральный пакет, чем, кстати говоря, особо опасный интегральный пакет.
[31:17.660 --> 31:23.660]  Там вы можете поставить коэффициент какой-нибудь не тот, и все хорошо будет считать, и гладкое решение получится.
[31:23.660 --> 31:30.660]  Только к задачи они окажутся не имеют никакого отношения.
[31:30.660 --> 31:34.660]  То есть необходимо обязательно априорная проработка задач.
[31:34.660 --> 31:38.660]  Обязательно по устойчивости, по просимации, по точности.
[31:38.660 --> 31:41.660]  Все это необходимо оценивать до числого решения задачи.
[31:41.660 --> 31:49.660]  Иначе вы можете встретиться с большими ошибками, которые могут просто замудить все ваши труды.
[31:49.660 --> 31:58.660]  Что, в общем-то, честно говоря, нередко и встречается, поскольку я часто бываю на конференциях таких по числу моделирования разных процессов,
[31:58.660 --> 32:04.660]  от физики до медицины и экономики, то вот очень часто это встречается.
[32:04.660 --> 32:12.660]  Особенно когда специалисты по тем или иным узким областям предметным плохо знают численные методы.
[32:18.660 --> 32:23.660]  Теперь я даю определение жесткой краевой задачи.
[32:23.660 --> 32:28.660]  Была у нас жесткая задача Каши для обыкновенных дифференциальных уравнений.
[32:28.660 --> 32:33.660]  Мы там выписаны тоже для линии задачи, точные решения.
[32:33.660 --> 32:38.660]  Откуда было понятно, в чем проблема.
[32:38.660 --> 32:45.660]  Здесь проблемы аналогичные, но они несколько проще.
[32:45.660 --> 32:51.660]  Почему? Потому как если в сдаче Каши мы рассматриваем интервалы интегрирования от нуля до бесконечности,
[32:51.660 --> 32:59.660]  то здесь чаще всего рассматриваются интервалы интегрирования порядка у большой единиц.
[32:59.660 --> 33:03.660]  Не всегда, но в большинстве случаев так.
[33:03.660 --> 33:09.660]  Есть задачи с большими областьями интегрирования, в том числе и с краевыми условиями бесконечности,
[33:09.660 --> 33:15.660]  но они сводятся в конечном итоге реальным краевым задачам.
[33:15.660 --> 33:18.660]  Определение жесткой задачи.
[33:18.660 --> 33:24.660]  Пусть у нас будет система дифференциальных уравнений dupdx.
[33:24.660 --> 33:28.660]  Здесь у нас будет матрица Au.
[33:28.660 --> 33:32.660]  У – это опять вектор, я не пишу значки вектора.
[33:32.660 --> 33:35.660]  Плюс fx.
[33:35.660 --> 33:40.660]  Х пусть у нас меняется от нуля до, скажем, l.
[33:40.660 --> 33:43.660]  Для дифференциального уравнения и два краевых условия.
[33:43.660 --> 33:46.660]  Здесь я их давайте развяжу.
[33:46.660 --> 33:51.660]  Условия на левой и на правой границе для простоты понимания ситуации.
[33:51.660 --> 33:54.660]  Их можно и связать, это ничего страшного.
[33:54.660 --> 33:57.660]  Условия на левой границе.
[33:57.660 --> 33:59.660]  Давайте так запишем.
[33:59.660 --> 34:03.660]  α и g на у0 от g.
[34:03.660 --> 34:07.660]  g меняется от нуля до n.
[34:07.660 --> 34:10.660]  Это есть, что это будет q.
[34:10.660 --> 34:14.660]  q – это компоненты вектора, то есть q – это тоже вектор.
[34:14.660 --> 34:17.660]  Левое краевое условие и аналогично правое.
[34:17.660 --> 34:21.660]  Давайте только поставим значок над альфа, над коэффициентами.
[34:21.660 --> 34:27.660]  Разумеется, а и g – это коэффициенты, которые находятся из гранических условий.
[34:27.660 --> 34:33.660]  У g от нуля равняется qi.
[34:33.660 --> 34:38.660]  Здесь и у нас меняется от 1 до k.
[34:38.660 --> 34:43.660]  Это количество краевых условий на левой границе.
[34:43.660 --> 34:49.660]  А здесь и меняется от k плюс 1 до n.
[34:49.660 --> 34:54.660]  Это количество гранических условий на правой границе.
[34:54.660 --> 34:57.660]  Вот это есть задача.
[34:57.660 --> 35:01.660]  Теперь, что такое задача жесткая?
[35:01.660 --> 35:06.660]  Это краевая задача такого же типа, о которых мы говорили.
[35:06.660 --> 35:08.660]  Теперь, что значит жесткая задача?
[35:08.660 --> 35:12.660]  Это вот что означает определение жесткой задачи.
[35:12.660 --> 35:15.660]  Задачу, которую мы сейчас написали,
[35:15.660 --> 35:18.660]  краевую задачу для обыкновенных дифференциальных уравнений,
[35:18.660 --> 35:21.660]  для системы АДУ мы назовем жесткой,
[35:21.660 --> 35:27.660]  если собственные значения матрицы якобы правой части
[35:27.660 --> 35:33.660]  лямбда иты будут меньше или равны некого числа лямбда большого.
[35:33.660 --> 35:35.660]  Сейчас я поясню, что это такое.
[35:35.660 --> 35:40.660]  Причем немная часть этого числа,
[35:40.660 --> 35:48.660]  должна быть меньше или равна реальной части его.
[35:48.660 --> 35:55.660]  И в данном случае меняется от еницы до n1.
[35:55.660 --> 36:02.660]  hdn1 – это количество так называемых жестких собственных значений для данной матрицы.
[36:02.660 --> 36:04.660]  Второй момент.
[36:04.660 --> 36:11.660]  Если вы помните, я буквально скопировал определение жесткой задачи коши
[36:11.660 --> 36:14.660]  для обыкновенного дифференциального уравнения.
[36:14.660 --> 36:16.660]  И можно бы обосновиться.
[36:16.660 --> 36:18.660]  Но нельзя.
[36:18.660 --> 36:21.660]  Для краевой задачи еще в дополнительные условия появляются
[36:21.660 --> 36:28.660]  лямбда иты больше или равно лямбда большое, некое большое число.
[36:28.660 --> 36:33.660]  Это вторая часть собственных значений.
[36:33.660 --> 36:38.660]  Здесь отрицательные, здесь большие положительные числа.
[36:38.660 --> 36:46.660]  Ну и здесь и меняется от n1 плюс 1 до n2.
[36:46.660 --> 36:50.660]  Это количество жестких так называемых собственных значений,
[36:50.660 --> 36:53.660]  но уже положительных.
[36:53.660 --> 36:57.660]  И так называемая не жесткая или мягкая часть.
[36:57.660 --> 37:02.660]  Модуль лямбда иты меньше или равняется лямбда 0.
[37:02.660 --> 37:14.660]  Лямбда 0 – малая и меняется от n2 плюс 1 до n.
[37:15.660 --> 37:21.660]  Ну и вот что очень важно для жестких задач – то, что
[37:21.660 --> 37:27.660]  лямбда большой 0 отношение к лямбда малое много больше единиц.
[37:27.660 --> 37:32.660]  Это большое число, большой параметр.
[37:32.660 --> 37:36.660]  Тогда эта задача будет жесткой.
[37:36.660 --> 37:41.660]  Таким жестким задачем относится та задача, которой я вот тот пример,
[37:41.660 --> 37:46.660]  хотя он очень простой, конечно, но который я вот недавно разобрал.
[37:46.660 --> 37:51.660]  Теперь дальше.
[37:51.660 --> 37:55.660]  Ситуация, конечно, несколько проще, чем для задач каши,
[37:55.660 --> 37:59.660]  именно потому что у нас отрезок интегрирования для большинства задач
[37:59.660 --> 38:03.660]  все-таки порядка большой от единиц краевых задач, он ограничен.
[38:03.660 --> 38:08.660]  Но тем не менее встречаются и задачи с быстрорастущей погрешностью.
[38:08.660 --> 38:17.660]  Поэтому для жестких задач краевых вводится понятие вычислительно-корректная задача.
[38:17.660 --> 38:20.660]  Что такое вычислительно-корректная задача?
[38:20.660 --> 38:23.660]  Это задача, для которой справедливо.
[38:23.660 --> 38:28.660]  Норма У, норма решения меньше или равняется некого числа С.
[38:28.660 --> 38:33.660]  С – это число, как правило, порядка большого от единиц.
[38:33.660 --> 38:38.660]  С – норма вектор F плюс норма вектор Q.
[38:38.660 --> 38:48.660]  С должно быть много меньше экспоненты, умноженные на лямбда, 0 и на L.
[38:48.660 --> 38:53.660]  Вот должно быть много меньше такого большого числа, такой большой экспоненты.
[38:53.660 --> 38:57.660]  Обычно это о большой от единиц, или около того.
[38:57.660 --> 38:59.660]  Тогда задача вычислительно-корректна.
[38:59.660 --> 39:06.660]  Если она вычислительно-корректна, вы можете смело решать, запускать интегральные пакеты и так далее.
[39:06.660 --> 39:10.660]  Почему я говорю об априорном исследовании задач.
[39:10.660 --> 39:19.660]  Если представить себе, что вы про это забыли, то вы можете наткнуться на что угодно.
[39:19.660 --> 39:26.660]  А вот, друзья, хочу один вопрос задать.
[39:26.660 --> 39:32.660]  Кто-нибудь ответит мне, скажем, есть у вас задача каши, обыкновенное дифференциальное уравнение.
[39:32.660 --> 39:37.660]  Как вы будете из таких соображений выбирать шаг интегрирования?
[39:37.660 --> 39:40.660]  Пусть система уравнения будет.
[39:40.660 --> 39:42.660]  Такая же только задача каши.
[39:42.660 --> 39:45.660]  То есть интервал интегрирования от 0 до бесконечности.
[39:45.660 --> 39:51.660]  Кто-нибудь подскажет мне, из каких соображений выбирать шаг интегрирования?
[39:51.660 --> 39:53.660]  Очень практический вопрос.
[39:53.660 --> 39:58.660]  То есть просто парагматический.
[39:58.660 --> 40:01.660]  Молчание, да?
[40:01.660 --> 40:09.660]  Лекции все просматривали по дифференциальному уравнению и по устойчивости методов Рунгикута?
[40:09.660 --> 40:11.660]  Молчание. Понятно.
[40:11.660 --> 40:15.660]  Ладно, я напомню, а вы все-таки посмотрите, пожалуйста, эти лекции.
[40:15.660 --> 40:20.660]  Это слишком важные моменты, поскольку вам придется решать жизненные задачи.
[40:20.660 --> 40:28.660]  Если вы не будете знать таких элементарных вещей, вы просто будете получать абсурдный результат.
[40:28.660 --> 40:30.660]  Я там того обозначал.
[40:30.660 --> 40:34.660]  Это шаг по времени, но это может быть и шаг по координате.
[40:34.660 --> 40:41.660]  Шаг интегрирования умножить на норму матрицы якоби правой части
[40:41.660 --> 40:45.660]  должна быть много меньше у Дениса.
[40:45.660 --> 40:51.660]  Это есть учет правой части обыкновенного дифференциального уравнения для задачи каши.
[40:51.660 --> 40:56.660]  Ну как вы, наверное, догадаетесь, что то же самое справедливо и для краевых задач.
[40:56.660 --> 41:02.660]  Более того, то же самое будет справедливо и для уравнений в частных производных.
[41:02.660 --> 41:07.660]  И для задач каши, и для краевых задач.
[41:07.660 --> 41:12.660]  Ну, конечно же, вы можете к этому условию еще не сказать.
[41:12.660 --> 41:15.660]  Условия точности, разумеется.
[41:15.660 --> 41:25.660]  Условия точности я вам рекомендую вспомнить из лекции, что такое правило рунги оценки точности решения на одном шаге интегрирования.
[41:25.660 --> 41:30.660]  Это прекрасное, очень простое чисто прагматическое правило оценки точности.
[41:30.660 --> 41:37.660]  И выбора интегрирования на следующем шаге.
[41:37.660 --> 41:39.660]  Например, по времени.
[41:39.660 --> 41:44.660]  То есть шаги могут быть неравномерными.
[41:44.660 --> 41:47.660]  Шаги могут выбираться в ходе решения задач.
[41:47.660 --> 41:49.660]  То есть они будут нелинейными.
[41:49.660 --> 41:51.660]  Нелинейный выбор шага.
[41:51.660 --> 41:53.660]  Ну вот, хорошо.
[41:53.660 --> 41:56.660]  Хотя, конечно, немного меня расстроили, но ладно.
[41:56.660 --> 41:57.660]  Вспомните.
[41:57.660 --> 42:03.660]  Я прекрасно понимаю, что целый январь был сессия, поэтому все-таки полистайте в последние лекции.
[42:03.660 --> 42:13.660]  Итак, если у нас задача чуть-чуть некорректная, вы можете хоть сами программу писать, хоть интегральным пакетом пользоваться, все будет нормально.
[42:13.660 --> 42:23.660]  Другое дело, что значит вы, конечно, спросите, почему-то не спрашиваете, а как определить задача будет вычислительно-корректной или не вычислительно-корректной.
[42:23.660 --> 42:28.660]  Ну, не всегда это условие, так запросто можно проверить, которое я написал.
[42:28.660 --> 42:30.660]  Можно, но не всегда.
[42:30.660 --> 42:34.660]  Есть теория, я не буду вам ее доказывать, я просто вам приведу.
[42:34.660 --> 42:39.660]  Она поразительна по своей простоте и своей практичности.
[42:40.660 --> 42:44.660]  Оказывается, задача будет вычислительно-корректной.
[42:44.660 --> 42:47.660]  Это условие вычислительной корректности.
[42:47.660 --> 43:02.660]  Если количество краевых условий на левой границе будет не меньше количества убывающих быстро вправо решений, экспоненциально убывающих вправо решений N1,
[43:02.660 --> 43:14.660]  помните, вот K это количество гранических условий на левой границе, а N1 это количество как раз быстро убывающих экспоненциально убывающих решений на левой границе.
[43:14.660 --> 43:16.660]  И то же самое для правой границы.
[43:16.660 --> 43:32.660]  Количество гранических условий на правой границе должно быть не меньше, чем количество решений быстро экспоненциально убывающих с правой границы влево.
[43:32.660 --> 43:40.660]  Это очень простое условие в практике, но очень просто проверяется.
[43:40.660 --> 43:41.660]  Вот это важный момент.
[43:41.660 --> 43:48.660]  Вообще говоря, условия необходимые, но оно, можно сказать, и почти достаточное.
[43:48.660 --> 43:52.660]  То есть это почти критерия устойчивости задачи.
[43:52.660 --> 43:58.660]  Это очень важный момент, поскольку если задача устойчивая и имеет место быть аппроксимация,
[43:58.660 --> 44:04.660]  аппроксимация для элементов рунгекута всегда существует, то вы можете спокойно решать задачу.
[44:04.660 --> 44:10.660]  Будьте уверены в ее решении с той степенью точности, которую вы сами же и задаете.
[44:10.660 --> 44:32.660]  Ну вот, я пока вот эту подтему, то есть число решения систем уравнений первого порядка для краевых задач, пока вот завершаю.
[44:33.660 --> 44:41.660]  В природе они, разумеется, встречаются довольно часто, но еще чаще встречаются задачи второго класса.
[44:41.660 --> 44:45.660]  Это будет вторая наша подтема лекции.
[44:45.660 --> 44:50.660]  Это уравнение типа штурма или увилия, то есть, точнее, задачи типа штурма или увилия.
[44:50.660 --> 44:54.660]  Это не уравнение, это, правильно говорить, задача типа штурма или увилия.
[44:54.660 --> 44:58.660]  Сейчас я оценю время.
[44:59.660 --> 45:03.660]  Есть. Так, хорошо.
[45:03.660 --> 45:07.660]  Перейдем, значит, вот теперь к этим задачам.
[45:07.660 --> 45:14.660]  То есть, это задачи, которые имеют, которые обладают уже более высоким порядком.
[45:14.660 --> 45:18.660]  То есть, это уравнения второго порядка, четвертого и так далее.
[45:18.660 --> 45:23.660]  В частном пока поговорим об уравнениях второго порядка.
[45:23.660 --> 45:28.660]  Если говорить о физике задач, то это, например, задачи одномерной теплопроводности, одномерной диффузии,
[45:28.660 --> 45:33.660]  вот, одномерной вязкости, если вы имеете в виду какие-то, какие-то вязкие среды.
[45:33.660 --> 45:37.660]  Но они, так сказать, встречаются в физике, в механике.
[45:37.660 --> 45:42.660]  Ну, я в последнее время смотрел задачи экономики, социологии, везде.
[45:42.660 --> 45:49.660]  Например, есть уравнение Калмогорово-Пискунова, третью фамилию, извините, забыл.
[45:49.660 --> 45:52.660]  Это вот уравнение, например, так сказать, как раз второго порядка,
[45:52.660 --> 45:56.660]  которое описывает распределение эпидемии по социальной среде.
[45:56.660 --> 45:59.660]  Ну, очень-очень актуальная задача.
[45:59.660 --> 46:06.660]  Ну, я, правда, не хочу ничего рекламировать, поскольку вот, ну, я знаю уже три команды, очень грамотные команды,
[46:06.660 --> 46:12.660]  которые моделируют распространение ковида по стране и по миру.
[46:12.660 --> 46:17.660]  Очень все хорошо, так сказать, очень грамотно, модели, так сказать, прекрасные берутся.
[46:17.660 --> 46:23.660]  Но одна беда вот таких вещей, как амикрона или дельта, они не предсказали.
[46:23.660 --> 46:26.660]  То есть они предсказали нормальное развитие нормальных вирусов.
[46:26.660 --> 46:31.660]  Ну, например, грипп, как распространяется по Москве, и так далее.
[46:31.660 --> 46:41.660]  А вот такие вот вирусы нетривиальные вот оказались пока вот для моделирования тяжеловато, тяжеловато.
[46:41.660 --> 46:45.660]  То есть там более хитро биологически подоплюк.
[46:46.660 --> 46:50.660]  Ну ладно, теперь давайте, значит, вот к этим задачам.
[46:50.660 --> 46:52.660]  Так, не забуду, я чего.
[46:52.660 --> 46:54.660]  Так, одну секундочку.
[46:56.660 --> 47:04.660]  Давайте сначала вопросы, будет ли у вас вопросы по первой подтеме.
[47:08.660 --> 47:11.660]  Ну да, вот я на самом деле хорошо, что полистал.
[47:11.660 --> 47:15.660]  Вот что бы еще хотел немного проиллюстрировать.
[47:15.660 --> 47:19.660]  Задачи жесткие, я напомню.
[47:19.660 --> 47:26.660]  Если у нас жесткая задача, вот решение независимая переменная, скажем, есть начальное данное.
[47:26.660 --> 47:33.660]  И так есть решения, которые очень быстро уходят практически в ноль, экспоненциальное падение.
[47:33.660 --> 47:37.660]  Вот это я просто напомню.
[47:38.660 --> 47:42.660]  Чисто на пальцах как раз, что такое жесткие задачи.
[47:42.660 --> 47:49.660]  Вот это дельта, расстояние, на котором они уходят в ноль, эти решения, называется пограничным слоем.
[47:49.660 --> 47:55.660]  Слово пограничный слой, так верно, которое имеет место быть как в математике, так и в физике.
[47:55.660 --> 48:03.660]  Ну скажем, если летит самолет, то на его крыло обязательно садится очень-очень тонкий пограничный слой.
[48:03.660 --> 48:09.660]  То есть нельзя его рассчитать, так сказать, об текании крыла без учета теплооборотности газа и вязкости газа.
[48:09.660 --> 48:12.660]  Это называется пограничный слой.
[48:12.660 --> 48:15.660]  Ну и таких примеров можно много привести.
[48:15.660 --> 48:18.660]  Они в электродинамике, эти примеры с пограничным слоем и так далее.
[48:18.660 --> 48:21.660]  Я не буду далеко заходить.
[48:21.660 --> 48:25.660]  Ну и есть решения, которые медленно падают.
[48:25.660 --> 48:31.660]  Первое решение соответствует большим отрицательным собственным числам матрицы Якимы.
[48:31.660 --> 48:35.660]  Вторые небольшие, то есть порядка у большого единицы.
[48:35.660 --> 48:37.660]  Это вот задача каши.
[48:37.660 --> 48:43.660]  Если мы имеем краевую задачу, то есть вот здесь второй край, A большой,
[48:43.660 --> 48:48.660]  то здесь мы имеем падение быстрое решений из правой части.
[48:48.660 --> 48:52.660]  То есть как с левой решение падает, так и с правой.
[48:52.660 --> 48:59.660]  Ну и есть решение какое-то, которое идет медленно от левого до правого края.
[48:59.660 --> 49:05.660]  Это вот такая пальцевая, как говорится, простая характеристика жестких задач,
[49:05.660 --> 49:09.660]  как каши, так и задач краевых.
[49:09.660 --> 49:14.660]  Ну и решение, на самом деле вот задача, о которой я говорил,
[49:14.660 --> 49:19.660]  задача линейная, вы, наверное, знаете, что она имеет решение в виде суммы экспонентов,
[49:19.660 --> 49:23.660]  то можно решение этой задачи, которая как раз жесткая,
[49:23.660 --> 49:27.660]  которую я сказал, ну, выписать, например, в таком виде,
[49:27.660 --> 49:31.660]  когда задача линейная, когда есть, так сказать, n собственных значений и так далее.
[49:31.660 --> 49:35.660]  Значит, γит есть в степени λитх,
[49:35.660 --> 49:41.660]  ωит от единицы до n1 меняется.
[49:41.660 --> 49:51.660]  Это вот λитой от единицы до n1 соответствует левым жестким собственным значениям.
[49:51.660 --> 49:55.660]  То есть жестким значениям, которые соответствуют левой границе
[49:55.660 --> 50:00.660]  и они ведут к падению решений, быстрому падению решений.
[50:00.660 --> 50:04.660]  Это первая сумма. Вторая сумма.
[50:04.660 --> 50:09.660]  Это решение, которое описывает решение, падающее с правой границы.
[50:09.660 --> 50:13.660]  То есть γит е в степени λитх.
[50:13.660 --> 50:21.660]  ωит здесь и меняется от n1 плюс 1 до n2.
[50:21.660 --> 50:27.660]  Значит, это все экспоненты с большими λ.
[50:27.660 --> 50:33.660]  И третья, так сказать, вот такая мягкая, ну, обычно говорят, не жесткая часть решения.
[50:33.660 --> 50:44.660]  Это решение γит на е в степени λитх ωит и n2 плюс 1 до n.
[50:44.660 --> 50:49.660]  То есть три части. Я напомню, что когда я выписывал такое общее решение
[50:49.660 --> 50:53.660]  для такое несложное линейное задаче к закоши, то было две части.
[50:53.660 --> 50:56.660]  Жесткая часть и нежесткая. Здесь три части.
[50:56.660 --> 51:00.660]  Две жестких части и одна нежесткая для краевых задач.
[51:00.660 --> 51:05.660]  Этим и не отличаются.
[51:12.660 --> 51:16.660]  Давайте вопросы, поскольку я эту подтему заканчиваю.
[51:19.660 --> 51:23.660]  Ну ладно, тогда переходим ко второй подтебе.
[51:23.660 --> 51:27.660]  То есть краевые задачи, типа штурма вилля.
[51:30.660 --> 51:55.660]  Так, ну давайте вот в таком достаточно общей виде задачи запишем.
[51:55.660 --> 52:00.660]  Так, здесь уже я буду иметь дело со скалерной величины.
[52:00.660 --> 52:03.660]  То есть неизвестное решение будет скалером.
[52:03.660 --> 52:10.660]  Можно делать решение и вектором, но обычно, если система уравнений
[52:10.660 --> 52:15.660]  нескольких таких задач, скажем, второго, более высокого порядка,
[52:15.660 --> 52:19.660]  ее обычно сводит все-таки к системе уравнений первого порядка.
[52:19.660 --> 52:24.660]  Чаще всего и решает медными для решения уравнений первого порядка.
[52:24.660 --> 52:29.660]  Поэтому сейчас я буду говорить о решении задачи,
[52:29.660 --> 52:32.660]  для которой неизвестное решение является скалером.
[52:32.660 --> 52:37.660]  D2 по D у, по D х дважды.
[52:37.660 --> 52:39.660]  Краевые задачи...
[52:39.660 --> 52:42.660]  Собственно говоря, краевые задачи мы проходили в прошлом году.
[52:42.660 --> 52:44.660]  Не могли не проходить, да?
[52:44.660 --> 52:46.660]  Ладно, конечно.
[52:46.660 --> 52:48.660]  Так, ну давайте так сделаем.
[52:48.660 --> 52:50.660]  Пусть будет f от...
[52:50.660 --> 52:52.660]  Пусть будет у нас f от u.
[52:52.660 --> 52:56.660]  Это простейшая задача, например, простейшее уравнение типа проводов.
[52:56.660 --> 53:00.660]  Здесь вся линейная часть, здесь нелинейная.
[53:00.660 --> 53:03.660]  Сейчас я чуть-чуть сделаю шаг назад
[53:03.660 --> 53:08.660]  и пока уберу нелинейную часть, поскольку решение нелинейных задач
[53:08.660 --> 53:10.660]  от линейных отличается.
[53:10.660 --> 53:14.660]  И напишу, пока поговорим о решении линейных задач
[53:14.660 --> 53:16.660]  либо задач с переменными коэффициентами,
[53:16.660 --> 53:19.660]  то есть в зависимости от независимой перемены.
[53:19.660 --> 53:23.660]  А потом перейдем, естественно, к задачам линейным.
[53:23.660 --> 53:27.660]  Пусть у нас будет такая задача D по D х.
[53:27.660 --> 53:32.660]  Здесь k коэффициент, ну, например, диффузии типа проводности.
[53:32.660 --> 53:35.660]  Вот там в электродинамике другие названия.
[53:35.660 --> 53:39.660]  Количество приложений этих задач огромное.
[53:39.660 --> 53:43.660]  Здесь D у по D х.
[53:43.660 --> 53:46.660]  Это первое слагаемое, второе слагаемое.
[53:46.660 --> 53:49.660]  Часто это слагаемое бывает единственным,
[53:49.660 --> 53:52.660]  но вообще говоря, может быть, и слагаемое такого сорта.
[53:52.660 --> 53:55.660]  Давайте k1 напишем.
[53:55.660 --> 53:59.660]  Здесь D у по D х.
[53:59.660 --> 54:02.660]  Ну, потоки обычно такое слагаемое можно описывать.
[54:02.660 --> 54:09.660]  Здесь k2 у и равняется, например, желт х.
[54:09.660 --> 54:15.660]  Х пусть у нас лежит от 0 до l.
[54:15.660 --> 54:19.660]  То есть это дифференциальный уровень второго порядка.
[54:19.660 --> 54:23.660]  И, разумеется, к нему мы должны добавить краевые условия,
[54:23.660 --> 54:28.660]  чтобы задача была разрешимой.
[54:31.660 --> 54:35.660]  Краевые условия, ну, давайте их тоже в довольно общей виде запишем.
[54:35.660 --> 54:49.660]  Например, а1у'х от 0 плюс β1у от 0 равняется γ1.
[54:49.660 --> 54:51.660]  Х здесь равняется 0.
[54:51.660 --> 54:54.660]  Левое краевое условие и правое.
[54:54.660 --> 55:10.660]  У2у'х от l плюс B2у от l равняется γ2.
[55:10.660 --> 55:14.660]  Х это правая граница, равняется l.
[55:14.660 --> 55:21.660]  В таком виде эта задача уже должна быть разрешимой.
[55:21.660 --> 55:25.660]  Теперь перейдем к аппроксимации.
[55:25.660 --> 55:30.660]  Ну, конечно, в ряде случаев эти задачи имеют, конечно, точное решение.
[55:30.660 --> 55:36.660]  Например, если первую задачу взять, только f будет функцией линейной.
[55:36.660 --> 55:42.660]  Я могу поставить f от x, и задача такая будет иметь точное решение.
[55:42.660 --> 55:45.660]  Решение фурье вы, наверное, помните.
[55:45.660 --> 55:50.660]  Скажем, у нас есть пластинка какая-то, здесь температура T1, снизу T0.
[55:50.660 --> 55:55.660]  Какое распределение будет температуры в пластинке одномерной?
[55:55.660 --> 55:58.660]  Какая функция будет?
[55:58.660 --> 56:00.660]  Разумеется, линейная.
[56:00.660 --> 56:02.660]  Просто будет линейная функция.
[56:02.660 --> 56:05.660]  Интеграл фурье даст прямую.
[56:05.660 --> 56:10.660]  Ну, конечно, в реальной жизни ситуация бывает гораздо более сложная.
[56:10.660 --> 56:15.660]  Пластинки бывают многослойные.
[56:15.660 --> 56:19.660]  Если говорить об арктических задачах с альдами,
[56:19.660 --> 56:22.660]  там вообще ситуация очень непростая.
[56:22.660 --> 56:28.660]  И излучение, и подводное течение, и сезонные перепады температур.
[56:28.660 --> 56:33.660]  Вот как, например, откалываются айсберги от огромных ледовых массивов.
[56:33.660 --> 56:37.660]  На первый взгляд, задача такая вот из области фантастической.
[56:37.660 --> 56:40.660]  Зачем она кому нужна? Ужасно нужна.
[56:40.660 --> 56:43.660]  Всякие Газпромы и Роснефти этими задачами очень сильно интересуются.
[56:43.660 --> 56:46.660]  Им эти айсберги поперек горло стоят.
[56:46.660 --> 56:51.660]  Количество айсбергов, куда они плывут, как они плывут, как они дрейфуют.
[56:51.660 --> 56:55.660]  Потому что айсберги там бывают такие, которые все сносят.
[56:55.660 --> 56:58.660]  Но айсберги, если одиночные с ними как-то борются,
[56:58.660 --> 57:02.660]  то если айсберг впален в какое-нибудь ледовое поле
[57:02.660 --> 57:05.660]  с характерным размером 2-3 километра,
[57:05.660 --> 57:08.660]  то с этим ледовым полем уже ничего не сделаешь.
[57:08.660 --> 57:12.660]  Разве что ракетами под водой его взрывать.
[57:12.660 --> 57:14.660]  То есть бед много.
[57:14.660 --> 57:18.660]  Норвежцы, например, предлагали из вертолета их взрывать.
[57:18.660 --> 57:23.660]  При этом при этом взрыве уничтожается вся около лежащая фауна морская.
[57:23.660 --> 57:25.660]  Ну и так далее.
[57:25.660 --> 57:28.660]  А как и сколько этих айсбергов образуется?
[57:28.660 --> 57:30.660]  Это задача, только, конечно, не одномерная.
[57:30.660 --> 57:33.660]  Это трехмерная динамическая задача Стефана.
[57:33.660 --> 57:35.660]  Нелинейная, вообще говоря.
[57:35.660 --> 57:39.660]  Очень непростая задача с очень сложной областью интегрирования.
[57:39.660 --> 57:43.660]  То есть здесь мы область интегрирования берем простую,
[57:43.660 --> 57:45.660]  одномерная ось.
[57:45.660 --> 57:47.660]  Вот точки у нас.
[57:47.660 --> 57:50.660]  Н, н плюс один, н плюс два.
[57:50.660 --> 57:52.660]  Шаг h и так далее.
[57:52.660 --> 57:54.660]  То есть это простейший случай.
[57:54.660 --> 57:56.660]  Вообще говоря, шаг h может быть приеменным.
[57:56.660 --> 57:58.660]  А вот когда мы берем...
[57:58.660 --> 58:01.660]  Ну вот я привел пример область интегрирования айсберг.
[58:01.660 --> 58:04.660]  Вот представьте себе, как туда нанести расчетную сетку.
[58:04.660 --> 58:06.660]  Как правило, это тетраэдральные сетки.
[58:06.660 --> 58:08.660]  Как правило, неравномерные.
[58:08.660 --> 58:10.660]  Вот и медные решения там очень непростые.
[58:10.660 --> 58:12.660]  Этих задач.
[58:12.660 --> 58:15.660]  Но база этих медов, фундамент, лежит вот.
[58:15.660 --> 58:17.660]  В численных медах решение вот этих одномерных задач.
[58:17.660 --> 58:19.660]  Вот это момент очень важный.
[58:19.660 --> 58:20.660]  Очень важный.
[58:20.660 --> 58:23.660]  Ну, собственно говоря, попозже мы перейдем к многомерным задачам.
[58:23.660 --> 58:24.660]  Но чуть позже.
[58:24.660 --> 58:29.660]  Так, значит, давайте теперь делаем опроксимацию вот этой...
[58:29.660 --> 58:31.660]  Вот этой задачи.
[58:34.660 --> 58:37.660]  Ох, не загадался намочить тряпку в прирыв.
[58:39.660 --> 58:41.660]  Ну, первый день.
[58:41.660 --> 58:44.660]  Как говорят, первый блин, кобан, да?
[58:57.660 --> 58:58.660]  Так.
[58:58.660 --> 59:00.660]  Ну, давайте проведем опроксимацию.
[59:00.660 --> 59:05.660]  Я тоже сейчас специально буду проводить опроксимацию достаточно простую.
[59:05.660 --> 59:06.660]  Вот.
[59:06.660 --> 59:10.660]  Чтобы не списывать по несколько раз все три доски.
[59:10.660 --> 59:15.660]  Разумеется, можно запроксимацию делать и более сложной, более высокого порядка и так далее.
[59:15.660 --> 59:17.660]  Значит, первое.
[59:17.660 --> 59:19.660]  У нас вторая производная.
[59:19.660 --> 59:21.660]  С нелинейной коэффициентой антипопроводности.
[59:21.660 --> 59:23.660]  Что значит нелинейной коэффициентой антипопроводности?
[59:23.660 --> 59:24.660]  На чем меняет?
[59:24.660 --> 59:28.660]  Зависит от независимой переменной, от координаты.
[59:28.660 --> 59:30.660]  Вот я сказал, биметаллическая пластина.
[59:30.660 --> 59:34.660]  Может быть, значит, контактная граница.
[59:34.660 --> 59:37.660]  А может быть, много контактной границы и так далее.
[59:37.660 --> 59:40.660]  Ну, в этом случае делается так.
[59:40.660 --> 59:42.660]  Единица от h.
[59:42.660 --> 59:50.660]  Здесь у нас коэффициентопроводности берется k плюс одна вторая, то есть с правой части.
[59:50.660 --> 59:58.660]  Вот у нас n, n минус 1 и n плюс 1.
[59:58.660 --> 01:00:00.660]  Как сетка наносится, вы помните?
[01:00:00.660 --> 01:00:03.660]  Как сетка обозначается расчетная?
[01:00:03.660 --> 01:00:07.660]  В данном случае это есть ωh.
[01:00:07.660 --> 01:00:10.660]  Расчетная сетка мы обозначали так.
[01:00:10.660 --> 01:00:13.660]  x, это только не kappa, это x.
[01:00:13.660 --> 01:00:15.660]  x, n.
[01:00:15.660 --> 01:00:23.660]  Это есть n на h, где n от 0 до n меняется.
[01:00:23.660 --> 01:00:25.660]  h, это есть шаг интегрирования.
[01:00:25.660 --> 01:00:31.660]  Это есть l, делить на n.
[01:00:31.660 --> 01:00:36.660]  Вот это так мы обозначали расчетную сетку ωh.
[01:00:36.660 --> 01:00:42.660]  Далее, у n плюс 1 минус у n делим на h.
[01:00:42.660 --> 01:00:48.660]  И минус k, n минус одна вторая.
[01:00:48.660 --> 01:00:54.660]  Здесь у n минус у n минус 1 делим на h.
[01:00:54.660 --> 01:01:03.660]  В данном случае удобнее проксимировать, чтобы оградить себя от всяких неприятностей, связанных с контактными разрывами.
[01:01:03.660 --> 01:01:05.660]  Вот таким образом.
[01:01:05.660 --> 01:01:15.660]  Если, разумеется, коэффициенте по проводности везде постояннее, то это просто вторая производная, умноженная на коэффициенте по проводности.
[01:01:15.660 --> 01:01:18.660]  Далее плюс, давайте так k, 1, n.
[01:01:18.660 --> 01:01:21.660]  Это уже совсем другой физический процесс.
[01:01:21.660 --> 01:01:27.660]  Давайте так первую производную вот так опроксимируем.
[01:01:27.660 --> 01:01:30.660]  Есть некий эффективный коэффициент k, 1, n.
[01:01:30.660 --> 01:01:34.660]  И здесь совсем другой физический процесс. Обычно какие-то потоки и так далее.
[01:01:34.660 --> 01:01:42.660]  k, 2, n на u, n и g, n.
[01:01:42.660 --> 01:01:49.660]  n от 1 меняется до n минус 1.
[01:01:49.660 --> 01:01:52.660]  То есть вот опроксимация дифференциального уравнения.
[01:01:52.660 --> 01:01:55.660]  Центральная точка, не граничная.
[01:01:55.660 --> 01:02:01.660]  Разумеется, мы должны еще провести опроксимацию и условий на границах.
[01:02:01.660 --> 01:02:06.660]  Я тоже сделаю упрощение, то есть приведу простейшую опроксимацию.
[01:02:06.660 --> 01:02:10.660]  Можно ее усложнить, более высоко сделать и так далее.
[01:02:10.660 --> 01:02:14.660]  Я пока вот делаю такие простейшие опроксимации,
[01:02:14.660 --> 01:02:21.660]  чтобы у нас вся лекция не ушла на любимый школьный алгебр.
[01:02:21.660 --> 01:02:29.660]  Там очень много будем по гибридическому форму писать.
[01:02:29.660 --> 01:02:33.660]  Первое левое условие, первое условие на левой границе.
[01:02:33.660 --> 01:02:44.660]  Альфа1 у1 минус у0 на h плюс бета1 на u0 равняется гамма1.
[01:02:44.660 --> 01:02:49.660]  x равен 0.
[01:02:49.660 --> 01:02:51.660]  И условие на правой границе.
[01:02:51.660 --> 01:03:07.660]  Альфа2 у0 минус у0 минус 1 на h плюс бета2 равняется гамма2.
[01:03:07.660 --> 01:03:10.660]  x равняется l.
[01:03:10.660 --> 01:03:14.660]  То есть вот такая у нас опроксимирующая разностная задача получилась.
[01:03:14.660 --> 01:03:19.660]  То есть я перешел от одной задачи к другой.
[01:03:19.660 --> 01:03:23.660]  Ну давайте опять задам провокационный вопрос.
[01:03:23.660 --> 01:03:27.660]  А каким образом мы можем показать, что данная опроксимирующая задача,
[01:03:27.660 --> 01:03:33.660]  или разностная моя называемая, имеет отношение к дифференциальной задаче?
[01:03:33.660 --> 01:03:40.660]  Кто мне попробует ответить хотя бы частично, хотя бы намек дать?
[01:03:40.660 --> 01:03:44.660]  Так, я даю намек, а вы попробуйте продолжить.
[01:03:44.660 --> 01:03:47.660]  Определение давал сходимости.
[01:03:47.660 --> 01:03:50.660]  Решение, помните такое или нет?
[01:03:50.660 --> 01:03:53.660]  Опроксимации.
[01:03:53.660 --> 01:03:55.660]  Было определение.
[01:03:55.660 --> 01:03:58.660]  Устойчивости.
[01:03:58.660 --> 01:04:04.660]  Если задача опроксимирует исходную дифференциальную и устойчивую,
[01:04:04.660 --> 01:04:11.660]  какое утверждение отсюда следует?
[01:04:11.660 --> 01:04:17.660]  Что имеет место сходимость решения разностной задачи к решению задачи дифференциальной.
[01:04:17.660 --> 01:04:21.660]  Иногда это тюремло называют очень коротко и просто.
[01:04:21.660 --> 01:04:24.660]  Опроксимация плюс устойчивость равняется сходимости.
[01:04:24.660 --> 01:04:30.660]  Если вы доказали опроксимацию и устойчивость, вы смело можете решать задачу.
[01:04:30.660 --> 01:04:33.660]  То есть вы получите по крайней мере физичное решение.
[01:04:33.660 --> 01:04:36.660]  Правда, с определенной степенью точности.
[01:04:36.660 --> 01:04:41.660]  Точности это то, что всегда присутствует в любых вычительных процессах.
[01:04:41.660 --> 01:04:44.660]  Бесконечно тонких точных задач нет.
[01:04:44.660 --> 01:04:50.660]  Хотя, конечно, в дифференциальных уравнениях высокого порядка
[01:04:50.660 --> 01:04:59.660]  нередко уже точность такова в 8-10 порядке, что она практически можно считать точным решением.
[01:04:59.660 --> 01:05:06.660]  Такой точности, как правило, хватает для любых инженерных и научных целей.
[01:05:06.660 --> 01:05:09.660]  Но все равно есть погрешности.
[01:05:09.660 --> 01:05:12.660]  Теперь посмотрите внимательно на доску.
[01:05:12.660 --> 01:05:17.660]  У меня есть ОН, ОН-1, ОН-1, неизвестное.
[01:05:17.660 --> 01:05:23.660]  Что я написал? Какого типа задачи я на доске написал?
[01:05:23.660 --> 01:05:27.660]  Хотя в таком очень пока разбросанном виде.
[01:05:27.660 --> 01:05:29.660]  Что это за задача?
[01:05:29.660 --> 01:05:31.660]  Хорошо нам известно.
[01:05:31.660 --> 01:05:33.660]  Вы ее прекрасно знаете.
[01:05:33.660 --> 01:05:35.660]  И еще из школы.
[01:05:37.660 --> 01:05:41.660]  Система линейных алгебридических уравнений.
[01:05:41.660 --> 01:05:45.660]  Но здесь всего 3 группы неизвестных.
[01:05:45.660 --> 01:05:49.660]  ОН-1, ОН и ОН-1.
[01:05:49.660 --> 01:05:54.660]  Это что означает? Что матрица этой системы уравнений трехдиагональна.
[01:05:54.660 --> 01:06:03.660]  Давайте, чтобы было более понятно, представим эту задачу в более компактном и понятном виде.
[01:06:03.660 --> 01:06:07.660]  Я в таком видео запишу.
[01:06:07.660 --> 01:06:11.660]  Этот вид называется каноническим видом.
[01:06:11.660 --> 01:06:16.660]  Здесь действительно не совсем понятно, о чем идет речь.
[01:06:16.660 --> 01:06:19.660]  Сейчас будет все понятно.
[01:06:19.660 --> 01:06:23.660]  Уравнений для центральной точки я вот так напишу.
[01:06:40.660 --> 01:06:44.660]  Это я вот переписал верхние уравнения для центральной точки.
[01:06:44.660 --> 01:06:47.660]  Теперь яснее осталась ситуация.
[01:06:47.660 --> 01:06:49.660]  Понятней?
[01:06:51.660 --> 01:06:54.660]  Условия левое, краевое.
[01:06:54.660 --> 01:06:56.660]  Пишу так.
[01:06:56.660 --> 01:07:02.660]  Минус B0 у0 плюс C0 у1 равняется D0.
[01:07:02.660 --> 01:07:09.660]  Здесь N равняется 0.
[01:07:09.660 --> 01:07:11.660]  Условия на правой границе.
[01:07:11.660 --> 01:07:13.660]  Пишу в таком виде.
[01:07:14.660 --> 01:07:18.660]  Уn минус 1 минус Bn.
[01:07:18.660 --> 01:07:23.660]  Уn равняется Dn.
[01:07:23.660 --> 01:07:27.660]  Здесь N малое равняется N.
[01:07:27.660 --> 01:07:33.660]  Отсюда видно, что это не что иное, как система линейных алгебрических уравнений.
[01:07:33.660 --> 01:07:36.660]  Надеюсь, что видно.
[01:07:36.660 --> 01:07:40.660]  Другое дело, что она имеет довольно специфический вид.
[01:07:40.660 --> 01:07:44.660]  Имеет смысл, давайте его, наверное, я все-таки напишу.
[01:07:44.660 --> 01:07:47.660]  Специфический вид.
[01:07:51.660 --> 01:07:53.660]  Я ее могу представить в таком виде.
[01:07:53.660 --> 01:07:59.660]  Вот матрица A с волной умножит на вектор неизвестных функций.
[01:07:59.660 --> 01:08:02.660]  И здесь D.
[01:08:02.660 --> 01:08:07.660]  Матрица A с волной может быть представлена в таком виде.
[01:08:07.660 --> 01:08:09.660]  A минус B0.
[01:08:09.660 --> 01:08:11.660]  Так, A.
[01:08:11.660 --> 01:08:13.660]  C0.
[01:08:13.660 --> 01:08:15.660]  A1 минус B1.
[01:08:15.660 --> 01:08:17.660]  C1 и так далее.
[01:08:17.660 --> 01:08:20.660]  An минус Bn.
[01:08:20.660 --> 01:08:23.660]  Cn многоточие.
[01:08:23.660 --> 01:08:28.660]  An минус 1 минус Bn минус 1.
[01:08:28.660 --> 01:08:30.660]  Plus Cn минус 1.
[01:08:30.660 --> 01:08:32.660]  И краевое условие.
[01:08:32.660 --> 01:08:36.660]  Это будет An и минус Bn.
[01:08:36.660 --> 01:08:38.660]  Так.
[01:08:38.660 --> 01:08:40.660]  Ну вот она такая матрица.
[01:08:40.660 --> 01:08:42.660]  Такого вида будет матрица.
[01:08:42.660 --> 01:08:44.660]  Давайте вот так напишу.
[01:08:44.660 --> 01:08:46.660]  Все остальные элементы нули.
[01:08:46.660 --> 01:08:50.660]  То есть заполненные, не нулевые, только три диагонали у этой матрицы.
[01:08:50.660 --> 01:08:56.660]  Что касается векторов, вектор неизвестных решений U.
[01:08:56.660 --> 01:08:58.660]  Ну это обычный вектор.
[01:08:58.660 --> 01:09:01.660]  U0 до ON.
[01:09:01.660 --> 01:09:03.660]  Ну и вектор правых частей D.
[01:09:03.660 --> 01:09:08.660]  Это от D0 до Dn.
[01:09:08.660 --> 01:09:11.660]  Вот такая система линейных уравнений.
[01:09:11.660 --> 01:09:13.660]  Вот решается она конечно.
[01:09:13.660 --> 01:09:17.660]  Ну можно предложить какой-нибудь метод решения.
[01:09:17.660 --> 01:09:19.660]  Предложите мне какой-нибудь, вспомните метод решения.
[01:09:19.660 --> 01:09:21.660]  Система линейных уравнений.
[01:09:21.660 --> 01:09:23.660]  Какой?
[01:09:23.660 --> 01:09:25.660]  Правильная прогонка.
[01:09:25.660 --> 01:09:27.660]  Правильная прогонка, да.
[01:09:27.660 --> 01:09:30.660]  Я ожидал, что вы можете сказать метод гауса.
[01:09:30.660 --> 01:09:32.660]  Можно и метод гауса.
[01:09:32.660 --> 01:09:36.660]  Это, как говорится, будет стрельба из головы без поворобьем.
[01:09:36.660 --> 01:09:38.660]  Очень много здесь нулей.
[01:09:38.660 --> 01:09:40.660]  Поэтому конечно прогонка.
[01:09:40.660 --> 01:09:42.660]  О прогонке мы сейчас поговорим.
[01:09:42.660 --> 01:09:45.660]  Алгоритм прогонки, я думаю, вам на семинаре сказали.
[01:09:45.660 --> 01:09:49.660]  Вопросы предварительные, то есть устойчивость и так далее.
[01:09:49.660 --> 01:09:51.660]  Мы все-таки немного обсудим.
[01:09:51.660 --> 01:09:53.660]  Алгоритм действительно очень интересный.
[01:09:53.660 --> 01:09:55.660]  Где-то это конец 50-х годов.
[01:09:55.660 --> 01:09:58.660]  Одновременно его предложили.
[01:09:58.660 --> 01:10:00.660]  Сейчас вынесут его в приколную математики.
[01:10:00.660 --> 01:10:02.660]  Это группа Гильфанда.
[01:10:02.660 --> 01:10:06.660]  И в Америке математик Томсенбурга.
[01:10:06.660 --> 01:10:10.660]  Такое практически одновременно предложили.
[01:10:10.660 --> 01:10:12.660]  Это звонок или нет?
[01:10:12.660 --> 01:10:15.660]  Наверное, кажется, еще звонка не было.
[01:10:15.660 --> 01:10:17.660]  Мы о нем поговорим.
[01:10:17.660 --> 01:10:21.660]  Алгоритм обладает прекрасным свойством устойчивости для линейных задач.
[01:10:21.660 --> 01:10:23.660]  Для линейных он не работает.
[01:10:23.660 --> 01:10:26.660]  Для линейных задач приходится по-другому решать.
[01:10:26.660 --> 01:10:28.660]  Либо редуцировать к нему, либо еще что-то делать.
[01:10:28.660 --> 01:10:31.660]  Это я на следующий лекции буду рассказывать.
[01:10:31.660 --> 01:10:35.660]  А вот для задач линейных он поразительно устойчив.
[01:10:35.660 --> 01:10:40.660]  Он порой бывает устойчив даже тогда, когда условия устойчивости не выполняются.
[01:10:40.660 --> 01:10:47.660]  Поэтому это один из самых любимых алгоритмов в всех предметах областей.
[01:10:47.660 --> 01:10:50.660]  И физики, и механики, и экономики, и социологии.
[01:10:50.660 --> 01:10:54.660]  Один из самых любимых алгоритмов.
[01:10:54.660 --> 01:10:57.660]  Мы по этому чуть попозже подробнее его обговорим.
[01:10:57.660 --> 01:11:06.660]  Вы задаете вопрос, какое отношение имеют коэффициент АН, БН и так далее коэффициентом К1, К2 и так далее.
[01:11:06.660 --> 01:11:08.660]  Имеет отношение...
[01:11:08.660 --> 01:11:12.660]  Сейчас только сколько-то времени у нас осталось.
[01:11:12.660 --> 01:11:14.660]  Хватит как раз на этот момент.
[01:11:14.660 --> 01:11:17.660]  Я сейчас его освещу.
[01:11:17.660 --> 01:11:22.660]  Поскольку он нам на следующей лекции потребуется.
[01:11:22.660 --> 01:11:26.660]  На самом деле это, конечно, задача чуть не школьная.
[01:11:26.660 --> 01:11:28.660]  Вы ее и без меня можете решить.
[01:11:28.660 --> 01:11:35.660]  Но я ее все-таки выпишу решение, поскольку оно будет нам чуть позже нужным.
[01:11:35.660 --> 01:11:37.660]  АН это у нас будет следующее.
[01:11:37.660 --> 01:11:46.660]  КН минус одна вторая делим на h квадрат, минус К1Н делим на 2h.
[01:11:46.660 --> 01:11:51.660]  Поскольку здесь делим на h квадрат, это, как правило, число очень маленькое.
[01:11:51.660 --> 01:11:54.660]  Здесь на h можно написать приблизительно.
[01:11:54.660 --> 01:11:57.660]  Это есть К, но N минус одна вторая, это что?
[01:11:57.660 --> 01:12:00.660]  Это ХН минус h пополам.
[01:12:00.660 --> 01:12:03.660]  Здесь h квадрат.
[01:12:03.660 --> 01:12:07.660]  То же самое мы делаем для коэффициента СН.
[01:12:07.660 --> 01:12:09.660]  Вот СН входит.
[01:12:09.660 --> 01:12:11.660]  Точно так же можно расписать.
[01:12:11.660 --> 01:12:23.660]  И будет понятно, что это приблизительно КХН плюс h пополам делим на h квадрат.
[01:12:23.660 --> 01:12:29.660]  Если говорить о ДН, оно просто равно ФН, это одно и то же.
[01:12:29.660 --> 01:12:39.660]  АБН коэффициент, это будет сумма АН плюс СН минус К1Н.
[01:12:39.660 --> 01:12:41.660]  Вот что это такое.
[01:12:41.660 --> 01:12:47.660]  В дальнейшем нам потребуется отношение коэффициентов АН к СН.
[01:12:47.660 --> 01:12:54.660]  Это будет отношение к ХН минус h пополам.
[01:12:54.660 --> 01:12:57.660]  h пополам это всегда малая величина.
[01:12:57.660 --> 01:13:02.660]  КХН плюс h пополам.
[01:13:02.660 --> 01:13:09.660]  Если разложить все это в ряд Тейлора, то мы получим, что это будет до первого члена, разумеется,
[01:13:09.660 --> 01:13:14.660]  единица плюс СН на h.
[01:13:14.660 --> 01:13:18.660]  Это вы уж сами без меня сделаете.
[01:13:18.660 --> 01:13:23.660]  Причем СН будет много меньше единиц.
[01:13:23.660 --> 01:13:29.660]  Много меньше единиц, поскольку h это малая величина, c величина, я не оговариваю.
[01:13:29.660 --> 01:13:31.660]  Чаще всего это о большой единиц.
[01:13:31.660 --> 01:13:36.660]  Хотя бывают исключения с правил, но чаще всего это о большой единиц.
[01:13:36.660 --> 01:13:38.660]  Вот.
[01:13:38.660 --> 01:13:43.660]  Ну вот свиньи мы, короче говоря, задачу к системе линейных уровней.
[01:13:43.660 --> 01:13:48.660]  Задача, которую вы знаете о медленном решении, мы давайте поговорим на следующей лекции,
[01:13:48.660 --> 01:13:53.660]  а то будет у нас кусок разорванный.
[01:13:53.660 --> 01:13:56.660]  Вопросы, пожалуйста.
[01:13:56.660 --> 01:14:03.660]  Какие возникли или не возникли.
[01:14:03.660 --> 01:14:08.660]  Ну ладно, тогда до свидания. Желаю всем ни в коем случае не болеть.
