[00:00.000 --> 00:10.500]  Итак, у меня сегодня нет четкого плана на нашу встречу,
[00:10.500 --> 00:18.300]  но я пообщался с вашим представителем в чате, в общем, на днях про ивент-лупы,
[00:18.300 --> 00:22.300]  про E-Poll и прочее, и кажется, выяснилось, что всё, что происходит, у нас бессмысленно,
[00:22.300 --> 00:25.800]  потому что мы вообще ничего не понимаем, и, возможно, нужно об этом поговорить.
[00:25.800 --> 00:29.600]  Ну, может быть, кто-то один ничего не понимает, а все всё понимают.
[00:29.600 --> 00:31.600]  Но разговор меня встревожил несколько.
[00:31.600 --> 00:33.100]  Был самый сильный представитель от нас.
[00:33.100 --> 00:39.600]  Вот, я поэтому и встревожился, что кажется, что это не последний среди нас человек,
[00:39.600 --> 00:44.600]  поэтому, возможно, мы можем написать задачу, скажем, про Slip4 и вообще ничего не понять,
[00:44.600 --> 00:47.600]  и это был бы, наверное, не слишком полезный опыт.
[00:49.600 --> 00:53.600]  Так что давайте мы ещё раз поговорим, у нас была лекция там,
[00:53.600 --> 00:57.600]  мы решали две задачи, я напомню, на одной лекции недавних.
[00:57.600 --> 01:00.600]  Мы разбирались, как сделать файберы параллельными, выделив крутину,
[01:00.600 --> 01:05.600]  декомпозировав её от пулла и собрав из этого всего файбера, и вы, кажется, это уже сделали.
[01:06.600 --> 01:11.600]  Дальше мы сказали, как можно файберы научить взаимодействовать с внешним миром.
[01:12.600 --> 01:16.600]  Тут у нас возникло понятие ивент-лупа, цикл событий,
[01:16.600 --> 01:21.600]  ну, то есть мы можем просто исполнять задачи, которые что-то делают,
[01:21.600 --> 01:25.600]  но откуда задачи возьмут себе работу? Видимо, она придёт по сети.
[01:25.600 --> 01:29.600]  И есть другое состояние, когда мы не просто разбираем очередь задачи,
[01:29.600 --> 01:32.600]  а когда мы разбираем очередь событий.
[01:32.600 --> 01:35.600]  Эта очередь событий, она реализуется, видимо, в ядре,
[01:35.600 --> 01:42.600]  и нам людям доступна в виде, ну, какого-нибудь еппола, да?
[01:47.600 --> 01:51.600]  Ну, и мы разбирали на лекции так коротко всем этот псевдокод,
[01:51.600 --> 01:58.600]  а потом смотрели, как можно этот псевдокод переписать на чём-то более, наверное, крупном.
[02:03.600 --> 02:05.600]  Нам нужен более крупный шрифт.
[02:08.600 --> 02:10.600]  Получше? Получше.
[02:10.600 --> 02:13.600]  Вот. На чём-то более высоком уровне он, по сути,
[02:13.600 --> 02:21.600]  код работает так же, но при этом всё же мы работаем, ну, с какими-то,
[02:21.600 --> 02:26.600]  ну, какая-то модульность здесь всё же присутствует в отличии вот этого кода.
[02:26.600 --> 02:33.600]  Ну, а дальше тут в нашей очередной домашке, которая прямо сейчас открыта,
[02:33.600 --> 02:37.600]  мы с помощью, мы этот event loop встраиваем файберы, ну, точнее,
[02:37.600 --> 02:41.600]  меняем планировщик файберов с тредпула на вот такой вот event loop,
[02:41.600 --> 02:45.600]  и поддерживаем файберы с крипфо.
[02:45.600 --> 02:49.600]  Но если мы не понимаем, как работает вот этот код,
[02:49.600 --> 02:53.600]  то вряд ли мы понимаем, как работает написанный нами код,
[02:53.600 --> 02:56.600]  потому что, в конце концов, под капотом это выполняется нечто такое,
[02:56.600 --> 03:01.600]  только вместо ассинкрицам у нас задача ассинквоить на таймерах.
[03:01.600 --> 03:08.600]  Вот. Ну, и давайте поговорим про епол и поговорим, что мы о нём знаем, чего мы не знаем.
[03:11.600 --> 03:16.600]  Ну, вот, во-первых, понятно ли вам, что по сути,
[03:16.600 --> 03:20.600]  меняя тредпул на некоторый загадочный его контекст,
[03:20.600 --> 03:23.600]  в котором есть какой-то еполог, какая-то магия,
[03:23.600 --> 03:27.600]  мы, по сути, ничего сложного не делаем, мы просто меняем планировщик.
[03:27.600 --> 03:30.600]  Планировщик, который можно отправить задачу,
[03:30.600 --> 03:34.600]  а ещё можно с ним связать ожидания некоторого события.
[03:34.600 --> 03:38.600]  Ну, вот, в условии мы говорим, что мы просто умеем бросать вот епол
[03:38.600 --> 03:41.600]  плямды, которые там будут исполняться,
[03:41.600 --> 03:44.600]  а ещё мы можем с этим еполом...
[03:44.600 --> 03:48.600]  в его контекст бросать плямды, которые там будут исполняться,
[03:48.600 --> 03:51.600]  а ещё мы можем с этим его контекстом связать объект таймер
[03:51.600 --> 03:53.600]  и вот подвесить на него кулбер.
[03:53.600 --> 03:58.600]  То есть задача выполнится не сразу, а когда реализуется некоторое событие.
[03:58.600 --> 04:05.600]  Вот. Но, как минимум, его контекст умеет просто задачи исполнять.
[04:05.600 --> 04:08.600]  И в его контексте в этом есть два типа задач.
[04:08.600 --> 04:10.600]  Вот есть ваши задачи, которые просто отправили лямбда,
[04:10.600 --> 04:12.600]  которая там должна исполниться,
[04:12.600 --> 04:16.600]  и задачи служебные, которые запускаются, когда реализуется некоторое событие.
[04:16.600 --> 04:20.600]  Ну, в сокете появляются байты, там истекает какой-то тайм-аут,
[04:20.600 --> 04:27.600]  и тогда обработчик, кулбек, запускается его контекстом.
[04:27.600 --> 04:29.600]  Мы это, наверное, понимаем, да?
[04:29.600 --> 04:33.600]  А теперь смотрите, вот если мы понимаем или нет?
[04:33.600 --> 04:34.600]  Ну, значит, плюс-минус.
[04:34.600 --> 04:37.600]  Смотри, вот не бывает плюс-минус понимания.
[04:37.600 --> 04:38.600]  Вот ты говоришь про программирование.
[04:38.600 --> 04:42.600]  Если ты не можешь объяснить, как всё написано, значит, ты чего-то не понимаешь точно.
[04:42.600 --> 04:45.600]  Тот же не вопрос, как оно должно примерно работать.
[04:45.600 --> 04:53.600]  Твоих знаний, мне кажется, что твоя предшествующая жизнь вот здесь, вот в этих стенах,
[04:53.600 --> 04:56.600]  дала тебе все необходимые, ну, должна была по крайней мере,
[04:56.600 --> 05:00.600]  тебе все необходимые знания для того, чтобы ты понимал, как эта штука работает,
[05:00.600 --> 05:04.600]  и просто ей спокойно пользовался, потому что ты уже выучил ей пол-накваси.
[05:04.600 --> 05:07.600]  Так что если ты чего-то не понимаешь, если что-то выглядит теомагическим,
[05:07.600 --> 05:10.600]  то, вероятно, это нужно обсуждать.
[05:10.600 --> 05:15.600]  Вот мы вроде бы в курсе, начали прямо с самого процессора, с атомика.
[05:15.600 --> 05:21.600]  Что такое атомик, что такое мьютекс, что такое фьютекс, мы узнаем вот совсем скоро.
[05:21.600 --> 05:24.600]  Содачка уже вот доваривается.
[05:24.600 --> 05:27.600]  Так что не должно быть ничего, что нам кажется магическим.
[05:27.600 --> 05:29.600]  Приключение контекста тоже разобрали.
[05:29.600 --> 05:32.600]  Вот если что-то кажется магическим, что-то плюс-минус понятно,
[05:32.600 --> 05:34.600]  значит, давайте это обсуждать.
[05:34.600 --> 05:37.600]  Вот что кажется магическим? Можете ли вы написать его контекст своими руками?
[05:37.600 --> 05:39.600]  Давайте так.
[05:39.600 --> 05:41.600]  Нет, а что тебя останавливает?
[05:50.600 --> 05:53.600]  Ну, вот смотрите, его контекст, в него можно бросить лямбду,
[05:53.600 --> 05:56.600]  а потом вызвать ран, и этот ран заблокируется до тех пор,
[05:56.600 --> 05:59.600]  пока там работа в его контексте не кончится.
[05:59.600 --> 06:04.600]  Причем я говорю, что его ран можно запускать из нескольких потоков.
[06:04.600 --> 06:06.600]  Видели такое в условиях?
[06:10.600 --> 06:12.600]  Просто задача у нас файбер параллельная,
[06:12.600 --> 06:15.600]  поэтому задача в его контекст запускается из разных потоков.
[06:16.600 --> 06:19.600]  Ну, на что это похоже? Это же просто тредпул, нет?
[06:21.600 --> 06:25.600]  Мы бросаем в его контекст лямбда, потом из разных потоков завем ран,
[06:25.600 --> 06:28.600]  и, видимо, разбирают очередь задач и запускают их.
[06:29.600 --> 06:33.600]  Вот если убрать таймеры и вот эту магическую привязку таймера к его контексту,
[06:33.600 --> 06:36.600]  то можно подумать, что его контекст этот тредпул и, в принципе, так и есть.
[06:38.600 --> 06:42.600]  И еще раз, что делает таймер? Почему мы вообще его пишем? Я смотрю на лекцию.
[06:44.600 --> 06:46.600]  Ну, в смысле, зачем мы пишем таймер и соки?
[06:46.600 --> 06:50.600]  Ну, потому что это способ взаимодействовать с внешним недопинированным миром.
[06:50.600 --> 06:52.600]  Время, сеть, диск.
[06:52.600 --> 06:55.600]  Это все какие-то внешние обстоятельства.
[07:07.600 --> 07:10.600]  Мне кажется, что вот в этих слайдах нет понятия его сервис.
[07:14.600 --> 07:15.600]  Правда?
[07:23.600 --> 07:25.600]  Вот ты смотрел эти слайды, да?
[07:29.600 --> 07:32.600]  Так вот они вот в условии посередине лежат.
[07:34.600 --> 07:36.600]  Мне кажется, что стоит.
[07:36.600 --> 07:38.600]  А, или это была какая-то ссылка из условия?
[07:38.600 --> 07:40.600]  Видимо, хотят меня чему-то научить, чему-то лишнему.
[07:41.600 --> 07:44.600]  Нет, это ссылка, по которой стоит пойти, почитать.
[07:44.600 --> 07:50.600]  И вот то, что там написано, это буквально одна из очень важных тем,
[07:50.600 --> 07:52.600]  что будет в очередной лекции, который будет в субботу.
[07:52.600 --> 07:54.600]  Все очень связано.
[07:56.600 --> 07:59.600]  Вот ASIO — это не просто event loop и не просто thread pool.
[07:59.600 --> 08:02.600]  Это некоторый вот такой сложный на самом деле очень фреймворк.
[08:02.600 --> 08:05.600]  Мы из него используем только какую-то мизерную часть.
[08:05.600 --> 08:07.600]  Но в нем много всего.
[08:07.600 --> 08:10.600]  И в какой-то степени то, что в нем есть, мы сами сейчас перепредумываем.
[08:12.600 --> 08:15.600]  И там, кажется, вот your service — это понятие...
[08:15.600 --> 08:17.600]  Это старое название его контекста.
[08:17.600 --> 08:19.600]  Его давно перефакторили.
[08:19.600 --> 08:22.600]  Но, мне кажется, в этих слайдах там никакого его сервиса нет.
[08:22.600 --> 08:24.600]  И тут, мне кажется, очень хорошие слайды.
[08:24.600 --> 08:30.600]  И тут все объяснено, в смысле, чем эти три вызова отличаются.
[08:36.600 --> 08:38.600]  Почему это не методы, это свободные функции?
[08:38.600 --> 08:46.600]  Система, в которой было слепка общежира с отсосом, это метод ASIO-диспаче?
[08:46.600 --> 08:50.600]  Это какие-то синтаксические рассуждения.
[08:51.600 --> 08:57.600]  Ну вот в фиберах, которые были у нас на лекции про однопоточные фиберы, был метод диспач.
[08:57.600 --> 08:59.600]  И он занимался диспетчеризацией.
[08:59.600 --> 09:00.600]  Что нужно делать сейчас?
[09:00.600 --> 09:02.600]  Что происходит?
[09:02.600 --> 09:05.600]  Если ты посмотришь на тот код, ты поймешь, зачем он нужен.
[09:05.600 --> 09:09.400]  Но если ты не понимаешь, зачем тебе код, то стирай его.
[09:09.400 --> 09:11.800]  Вот еще раз, смотри, очень большая ошибка в курсе
[09:11.800 --> 09:14.400]  и в жизни ориентироваться на какие-то синтактические
[09:14.400 --> 09:15.400]  сходства.
[09:15.400 --> 09:19.040]  Вот ты пишешь код, который тебе нужен, и вот ты написал
[09:19.040 --> 09:23.720]  код, а потом смотри на него, и если вдруг ты поймешь,
[09:23.720 --> 09:28.600]  где у тебя в твоем коде есть метод, который похож
[09:28.600 --> 09:32.360]  на диспетчеризацию в некотором смысле, то ты его выдержишь.
[09:32.360 --> 09:34.400]  Если нет такого, то ты не выдержишь, просто придешь
[09:34.400 --> 09:35.400]  на защиту, мы с тобой поговорим.
[09:35.400 --> 09:39.720]  Просто в шаблоне есть некоторая заготовка, которая мне кажется
[09:39.720 --> 09:43.160]  разумной, потому что, скажем, у Файбера есть, не знаю,
[09:43.160 --> 09:47.800]  Файбер хочет уметь останавливаться, Файбер должен останавливаться
[09:47.800 --> 09:51.240]  вот здесь, вызовет слиффора, потом возобновляться.
[09:51.240 --> 09:54.600]  Поэтому очень разумно, скажем, чтобы в Файбере были методы
[09:54.600 --> 09:59.400]  suspend и resume, потому что логически Файбер эти шаги совершает
[09:59.400 --> 10:00.400]  в своей работе.
[10:00.400 --> 10:02.840]  Но может быть ты написал так код, что тебе эти методы
[10:03.000 --> 10:08.360]  пока не заполняешь, ты реализуешь свой Файбер, ты открываешь
[10:08.360 --> 10:14.440]  шаблон, видишь там что-нибудь и говоришь, что-то мне не
[10:14.440 --> 10:15.440]  понравилось.
[10:15.440 --> 10:17.520]  И вот вытеряешь все и стираешь, и пишешь что-то свое.
[10:17.520 --> 10:26.360]  Вот так правильно делать, а угадывать, зачем эти были
[10:26.360 --> 10:30.240]  методы, лучше сделать это в конце, то есть необходимо
[10:30.240 --> 10:31.480]  исходить из своих потребностей.
[10:31.480 --> 10:38.880]  То, что следует сделать, написано в условиях, какие-то
[10:38.880 --> 10:41.880]  направления, которым нужно следовать, все важно, условие
[10:41.880 --> 10:42.880]  оговорено.
[10:42.880 --> 10:45.520]  А некоторые вещи ты напишешь сам, и как они тебе получатся,
[10:45.520 --> 10:46.520]  так и получатся.
[10:46.520 --> 10:48.400]  Зависит от твоего опыта, от твоих знаний.
[10:48.400 --> 10:52.920]  Как минимум, у тебя должен код работать, а по вторую
[10:52.920 --> 10:59.680]  очередь, он уже должен быть написан модально, понятно,
[10:59.680 --> 11:02.160]  и это получится, а у тебя сразу не получится, трудно
[11:02.160 --> 11:05.080]  предсказать, и научить тебя этому так насильно невозможно.
[11:05.080 --> 11:10.400]  Все равно потом дальше будешь писать свой код, и будешь
[11:10.400 --> 11:11.400]  писать его по-своему.
[11:11.400 --> 11:16.720]  Вот лучше писать по-своему всегда, и дальше уже мы на
[11:16.720 --> 11:19.880]  ревью обсудим, насколько получилось удачно или неудачно.
[11:19.880 --> 11:25.200]  Так что не подстраивайтесь под шаблон, там, где от вас
[11:25.200 --> 11:26.200]  этого не требуется.
[11:26.200 --> 11:31.920]  В публичном опе его нет теста, про этот файбер, про
[11:31.920 --> 11:34.760]  этот объект ничего не знают, поэтому там может быть написано
[11:34.760 --> 11:35.760]  любой код абсолютно.
[11:35.760 --> 11:49.320]  Так, вернемся к ASIO, это некоторая штука, ее контекст, некоторая
[11:49.320 --> 11:53.400]  штука, которая умеет запускать задачи, которые есть в очереди.
[11:54.400 --> 12:00.400]  А еще можно завести таймер, подвести на него колбэк,
[12:00.400 --> 12:04.400]  завести таймер, который привязан к его контексту,
[12:04.400 --> 12:08.400]  подвести на этот таймер колбэк, и вызвать ран, и ран
[12:08.400 --> 12:11.400]  будет крутиться до тех пор, пока таймер не сработает.
[12:11.400 --> 12:16.400]  Вот как бы вы такую штуку сделали, если вы знаете про
[12:16.400 --> 12:17.400]  ЕПО, конечно.
[12:17.400 --> 12:30.400]  Ну, пока в его контексте есть работа, текущая или
[12:30.400 --> 12:33.400]  будущая, или запланированная на будущее, пока хоть что-то
[12:33.400 --> 12:35.400]  в нем есть, мы не останавливаемся.
[12:35.400 --> 12:39.400]  Собственно, это отдельный вопрос на понимание, вот
[12:39.400 --> 12:42.400]  вы реализовали файберы, вот почему и запустили их,
[12:42.400 --> 12:45.400]  вот когда и уран остановится, потому что файбер же он
[12:45.400 --> 12:48.400]  запускается, работает, работает, потом засыпает, и все.
[12:48.400 --> 12:51.400]  И вот исполнения готового активного нет сейчас.
[12:51.400 --> 12:54.400]  Но почему-то его контекст продолжает крутиться,
[12:54.400 --> 12:57.400]  продолжает чего-то ждать, видимо, потому что задача
[12:57.400 --> 12:59.400]  файбера живая заменилась на заведенный таймер.
[12:59.400 --> 13:02.400]  Когда он сработал, появилась новая живая задача, и вот
[13:02.400 --> 13:03.400]  это все так продолжается.
[13:03.400 --> 13:10.400]  Так вот, как можно строить таймеры?
[13:10.400 --> 13:12.400]  Ну, вот вы можете...
[13:12.400 --> 13:17.400]  E-Poll в Linux поддерживает таймеры.
[13:22.400 --> 13:25.400]  Ну, или вы хотите сделать socket, E-Poll поддерживает socket.
[13:25.400 --> 13:30.400]  А дальше, как бы вы реализовали его контексте, вот этот
[13:30.400 --> 13:31.400]  самый таймер?
[13:31.400 --> 13:33.400]  Что в этом таймере есть?
[13:33.400 --> 13:35.400]  Что в полях этого класса должно быть?
[13:35.400 --> 13:38.400]  Что происходит, когда мы говорим о сингвейт?
[13:38.400 --> 13:40.400]  Ну, вот, пофантазируйте.
[13:40.400 --> 13:42.400]  У вас знаний достаточно для того, чтобы этот код
[13:42.400 --> 13:44.400]  себе представить весь.
[13:47.400 --> 13:50.400]  Ну, может, мы просто, когда закончилось, мы уже
[13:50.400 --> 13:53.400]  закидывали события, то, что...
[13:53.400 --> 13:54.400]  Что оно чуть закончилось.
[13:54.400 --> 13:55.400]  Вот, смотри, вот...
[13:55.400 --> 13:57.400]  У нас даже лямда завершилась, мы не можем просто...
[13:57.400 --> 13:59.400]  Какая лямда завершилась?
[13:59.400 --> 14:01.400]  Которую вы закинули в...
[14:01.400 --> 14:02.400]  Как она завершилась?
[14:02.400 --> 14:03.400]  Я спрашиваю, как тебе...
[14:03.400 --> 14:04.400]  Как сингвейт реализовать?
[14:04.400 --> 14:06.400]  Ты говоришь, лямда уже завершилась.
[14:09.400 --> 14:11.400]  А вы точно писали E-пол?
[14:11.400 --> 14:12.400]  Ну, в смысле...
[14:12.400 --> 14:13.400]  Вы точно им пользовались?
[14:13.400 --> 14:14.400]  Да.
[14:14.400 --> 14:16.400]  У нас не можно писать.
[14:16.400 --> 14:20.400]  Просто в чате мы несколько написали, что вы писали
[14:20.400 --> 14:23.400]  эхо-сервер с одним буфером.
[14:23.400 --> 14:25.400]  Да, а где?
[14:25.400 --> 14:27.400]  Ну, это же чепуха.
[14:27.400 --> 14:30.400]  Это же не имеет смысла абсолютно никакого.
[14:30.400 --> 14:33.400]  Сколько там буферов было, а я писал, и он больше...
[14:33.400 --> 14:34.400]  Нет, ну...
[14:34.400 --> 14:36.400]  Эхо-сервер, который писал человек в чате, не имеет
[14:36.400 --> 14:37.400]  никакого смысла.
[14:37.400 --> 14:39.400]  Его нужно только удалять и не писать.
[14:41.400 --> 14:43.400]  Вот если вы писали такой же эхо-сервер, то нужно
[14:43.400 --> 14:45.400]  беспокоиться.
[14:45.400 --> 14:47.400]  Зная Кирилла, скорее всего, он писал с этой лучше,
[14:47.400 --> 14:49.400]  чем писали мне.
[14:54.400 --> 14:57.400]  Ну, давайте разбираться, потому что, кажется, если
[14:57.400 --> 15:00.400]  мы не знаем E-пол, то это большая проблема для меня.
[15:03.400 --> 15:04.400]  Что такое E-пол?
[15:04.400 --> 15:05.400]  Очередь событий.
[15:05.400 --> 15:08.400]  Вы туда можете положить сокет, зарегистрировать
[15:08.400 --> 15:12.400]  там сокет, и вы можете заблокироваться на сокеты,
[15:12.400 --> 15:16.400]  заблокироваться на вызове E-пол-wait, и дождаться,
[15:16.400 --> 15:20.400]  пока либо события не появятся, либо таймер не пройдет.
[15:20.400 --> 15:22.400]  Ну, тайм-аут не пройдет.
[15:24.400 --> 15:28.400]  И дальше вы получите сокеты, которые готовы к той
[15:28.400 --> 15:30.400]  операции, для которой вы их зарегистрировали.
[15:30.400 --> 15:32.400]  Там чтение, запись.
[15:32.400 --> 15:34.400]  Ну, или просто таймер там готов выполнить.
[15:34.400 --> 15:35.400]  Таймер сработал.
[15:35.400 --> 15:37.400]  Неважно.
[15:37.400 --> 15:40.400]  И дальше, если мы говорим про сокеты, например, то
[15:40.400 --> 15:41.400]  что вы делаете?
[15:41.400 --> 15:44.400]  Вы из них читаете сразу, ну, или в них пишете сразу.
[15:44.400 --> 15:46.400]  И вы делаете это без блокировки, потому что вы
[15:46.400 --> 15:48.400]  установили сокеты в неблокирующий режим сначала,
[15:48.400 --> 15:50.400]  а потом зарегистрировали в E-поле, да?
[15:52.400 --> 15:55.400]  А теперь представим, что мы пишем эхо-сервер.
[15:56.400 --> 15:58.400]  Вот с чего эхо-сервер начинается.
[16:00.400 --> 16:02.400]  Ну, видимо, мы создаем серверный сокет, привязываем
[16:02.400 --> 16:06.400]  его к порту, начинаем слушать и регистрируем сокет
[16:06.400 --> 16:07.400]  в E-поле.
[16:07.400 --> 16:08.400]  Да?
[16:08.400 --> 16:09.400]  С этого же начиналось.
[16:09.400 --> 16:12.400]  Ну, вот давайте я буду код ASIO показывать, который
[16:12.400 --> 16:14.400]  был на лекции.
[16:14.400 --> 16:17.400]  Вот у нас EO-контекст.
[16:17.400 --> 16:20.400]  В нем будет спрятано этот самый E-POL-OD.
[16:20.400 --> 16:22.400]  Очередь событий.
[16:22.400 --> 16:24.400]  И вот мы конструируем сервер.
[16:24.400 --> 16:28.400]  И в конструкторе мы строим объект acceptor.
[16:28.400 --> 16:31.400]  А почему мы в контекст прячем E-POL?
[16:31.400 --> 16:36.400]  В смысле, у нас это представление event loop, кроссплатформенного.
[16:36.400 --> 16:41.400]  E-POL под линуксом есть, под другими ничего другого.
[16:41.400 --> 16:45.400]  Но вот этот самый EO-контекст представляет из себя абстрактный
[16:45.400 --> 16:49.400]  event loop, который использует какой-то конкретный механизм,
[16:49.400 --> 16:53.400]  какую-то конкретную очередь событий для данной операционной системы.
[16:53.400 --> 16:54.400]  Что?
[16:54.400 --> 16:57.400]  Это не pattern adapter.
[16:57.400 --> 16:58.400]  Почему?
[16:58.400 --> 17:01.400]  Ну, вроде как раз самая.
[17:01.400 --> 17:04.400]  Ну, это не...
[17:04.400 --> 17:07.400]  Pattern adapter – это не единый интерфейс.
[17:07.400 --> 17:10.400]  Он к единому интерфейсу не имеет отношения.
[17:10.400 --> 17:13.400]  Pattern adapter адаптирует один интерфейс к другому интерфейсу.
[17:13.400 --> 17:15.400]  Адаптер – это клей.
[17:15.400 --> 17:18.400]  Как одну библиотеку с клеем с другой библиотекой.
[17:18.400 --> 17:20.400]  Здесь мы ничего не клеим.
[17:20.400 --> 17:23.400]  Здесь у нас EO-контекст – самостоятельная сущность.
[17:23.400 --> 17:26.400]  Мы выбираем для него некоторые общие API.
[17:26.400 --> 17:29.400]  Правильно ли я понимаю, что внутри это защит,
[17:29.400 --> 17:33.400]  ну, грубо говоря, за их, на внутренней библиотеке,
[17:33.400 --> 17:36.400]  если это винда, запускаем один уксус ввода,
[17:36.400 --> 17:39.400]  если это винок, запускаем неполностропный диплом?
[17:39.400 --> 17:41.400]  Ну, это называется реактор.
[17:41.400 --> 17:44.400]  В общем случае это называется реактор.
[17:44.400 --> 17:49.400]  Но есть два паттерна асинхронного водовывода – реактор и парактор.
[17:49.400 --> 17:52.400]  Давайте пока не будем об этом.
[17:52.400 --> 17:55.400]  В документации это если время останется, я про это расскажу.
[17:55.400 --> 17:59.400]  Ну вот, у нас есть некоторый механизм для ожидания событий,
[17:59.400 --> 18:03.400]  для регистрации подписки на события и ожидания событий.
[18:03.400 --> 18:05.400]  Вот полиноксом это E-Poll.
[18:05.400 --> 18:07.400]  И вот EO-контекст, он в себе инкапсулирует
[18:07.400 --> 18:10.400]  вот этот самый системный механизм ожидания событий.
[18:10.400 --> 18:14.400]  И смотрите, что мы делаем, когда мы запускаем сервер?
[18:14.400 --> 18:16.400]  Мы конструируем объект-сервер,
[18:16.400 --> 18:22.400]  и в конструкторе мы конструируем аксептор некоторый,
[18:22.400 --> 18:24.400]  привязываем его к EO-контексту и передаем туда порт.
[18:24.400 --> 18:26.400]  Что делает этот аксептор в конструкторе?
[18:26.400 --> 18:29.400]  Ну, видимо, он строит серверный сокет,
[18:29.400 --> 18:31.400]  видимо, он его привязывает к этому порту,
[18:31.400 --> 18:36.400]  и видимо, этот аксептор регистрирует этот сокет в E-Poll.
[18:36.400 --> 18:39.400]  Да, и говорит, какие именно события ждать.
[18:39.400 --> 18:41.400]  Ну да, то есть мы собираемся из этого серверного сокета читать.
[18:41.400 --> 18:43.400]  Вот этот серверный сокет спрятан здесь.
[18:43.400 --> 18:46.400]  Вот аксептор – это, по сути, серверный сокет.
[18:46.400 --> 18:48.400]  Вот некой магии пока, да?
[18:48.400 --> 18:49.400]  Да.
[18:49.400 --> 18:50.400]  Отлично.
[18:50.400 --> 18:52.400]  Что происходит дальше, когда мы пишем махо-сервер?
[18:52.400 --> 18:56.400]  Ну, мы начинаем крутиться в цикле, слушать какие-то события.
[18:56.400 --> 19:00.400]  Надо было написать обработчики разных событий.
[19:00.400 --> 19:06.400]  На самом деле мы зарегистрировали в E-Poll объект аксептора вот примерно здесь.
[19:06.400 --> 19:10.400]  Даже не в конструкторе, а мы сначала создали этот объект,
[19:10.400 --> 19:13.400]  привязали его, создали сокет, привязали его к порту,
[19:13.400 --> 19:20.400]  а потом уже подписались на события чтения в E-Poll.
[19:20.400 --> 19:23.400]  Да? Это понятно?
[19:23.400 --> 19:28.400]  А у нас уже мы считаем, что есть E-Poll внутри аксептора?
[19:28.400 --> 19:30.400]  Нет.
[19:30.400 --> 19:32.400]  Еще раз, что мы делаем?
[19:32.400 --> 19:39.400]  Мы реанимируем ваши знания E-Poll и пытаемся их разложить
[19:39.400 --> 19:44.400]  по каким-то сущностям в библиотеке ASIO, чтобы каждый компонент был сам по себе разумен,
[19:44.400 --> 19:49.400]  чтобы не пришлось писать этот странный голый код на CIS с этими родливыми циклами.
[19:49.400 --> 19:53.400]  Его контекст – это очередь событий.
[19:53.400 --> 19:55.400]  Это E-Poll. В нем E-Poll.
[19:55.400 --> 19:59.400]  Эта сущность представляет собой очередь событий в ядре.
[19:59.400 --> 20:03.400]  Аксептор представляет из себя серверный сокет.
[20:03.400 --> 20:08.400]  И вот тут мы этот серверный сокет связываем с его контекстом,
[20:08.400 --> 20:10.400]  то есть с E-Poll.
[20:10.400 --> 20:13.400]  И вот здесь мы подписываемся на события.
[20:13.400 --> 20:23.400]  Мы вешаем обработчик, который будет вызываться тогда, когда на серверном сокете появится клиент.
[20:23.400 --> 20:27.400]  То есть вот этот обработчик запустится, когда...
[20:27.400 --> 20:30.400]  Вот он, по сути, написан.
[20:30.400 --> 20:35.400]  И вот когда мы говорим Run после конструирования сервера,
[20:35.400 --> 20:39.400]  то начинает крутиться вот этот цикл.
[20:39.400 --> 20:43.400]  И когда-то в нем достается из E-Poll серверный сокет.
[20:43.400 --> 20:46.400]  И вот мы вызываем этот обработчик.
[20:46.400 --> 20:48.400]  Да? Никакой магии.
[20:48.400 --> 20:50.400]  Что этот обработчик делает?
[20:50.400 --> 20:55.400]  Ну, по сути, регистрирует новый сокет E-Poll.
[20:55.400 --> 20:59.400]  Ну, тут уже много кодов написано за вас в ASIO,
[20:59.400 --> 21:04.400]  а тут вы видите, вы в колбейке получаете уже готовый сокет на самом деле.
[21:04.400 --> 21:08.400]  То есть ASIO за вас вызвало Accept,
[21:08.400 --> 21:12.400]  получило сокет, перевела его в не блокирующий режим, не перевела, наверное.
[21:12.400 --> 21:15.400]  И вот вы по обработчике его имеете.
[21:15.400 --> 21:17.400]  А дальше что вы делаете?
[21:17.400 --> 21:24.400]  Вы порождаете объект Sessia, который будет обслуживать одного клиента.
[21:24.400 --> 21:28.400]  И после этого снова вызываете DoAccept.
[21:28.400 --> 21:31.400]  То есть снова подписываете серверный сокет.
[21:31.400 --> 21:35.400]  И тогда снова подписываетесь на события на нем в E-Poll.
[21:37.400 --> 21:39.400]  Понятно, да?
[21:39.400 --> 21:42.400]  То есть это не рекурсия ни в коем случае, это такой цикл из задачек.
[21:42.400 --> 21:45.400]  А он нам учится только один сокет разрешать, да?
[21:45.400 --> 21:51.400]  Ну, то есть в E-Poll мы же можем там массив, мы можем всю массиву произнести.
[21:51.400 --> 21:53.400]  Ну, он может проходиться по массиву,
[21:53.400 --> 21:56.400]  но обработчик, кто он занимается, зачем тебе про массивы думать?
[21:56.400 --> 22:00.400]  Это деталь реализации E-Poll, чтобы минимизировать количество там вызовов.
[22:00.400 --> 22:02.400]  И тут ты работаешь с отдельными сущностями.
[22:02.400 --> 22:04.400]  Acceptor, Socket.
[22:04.400 --> 22:07.400]  Внутри, что происходит внутри раны, тебя вообще мало волнует.
[22:07.400 --> 22:09.400]  Тут, может быть, его контекст получил 10 событий,
[22:09.400 --> 22:11.400]  и потом вызвал 10 обработчиков подряд.
[22:13.400 --> 22:17.400]  Вот, но тебе же вот в этом контексте нужно знать про твой текущую задачу,
[22:17.400 --> 22:19.400]  про то, как принимать клиента.
[22:20.400 --> 22:22.400]  Вот, значит, никакой магии здесь нет, да?
[22:23.400 --> 22:25.400]  А что происходит дальше?
[22:25.400 --> 22:27.400]  Ну, дальше мы, видимо...
[22:28.400 --> 22:31.400]  Ну, что происходит в их сервере? Давайте так.
[22:31.400 --> 22:34.400]  Ну, нам нужно второе событие еще сейчас обработать.
[22:34.400 --> 22:36.400]  Это получение...
[22:36.400 --> 22:40.400]  Ну, когда в E-Poll пришел socket уже не серверный, а...
[22:40.400 --> 22:42.400]  Ну вот, у нас появился клиентский socket.
[22:42.400 --> 22:45.400]  И мы хотим теперь, с одной стороны, ждать события на серверном socket по-прежнему,
[22:45.400 --> 22:47.400]  потому что клиенты все еще приходят.
[22:47.400 --> 22:50.400]  А с другой стороны, у нас появился клиент, нужно его обслуживать.
[22:50.400 --> 22:56.400]  Поэтому мы должны socket этого клиента тоже зарегистрировать E-Poll и ждать на нем ввода-вывода.
[22:56.400 --> 22:59.400]  Поэтому мы здесь конструируем object-session,
[22:59.400 --> 23:02.400]  и после конструирования вызываем этот метод start.
[23:03.400 --> 23:05.400]  А метод start что делает?
[23:05.400 --> 23:07.400]  Говорит socket async.readsum.
[23:07.400 --> 23:15.400]  И вот этот async.readsum регистрирует наш клиентский socket в E-Poll
[23:15.400 --> 23:18.400]  и подвешивает к нему еще callback.
[23:18.400 --> 23:23.400]  Что когда из этого socket, когда на этом socket появятся данные,
[23:23.400 --> 23:30.400]  E-Poll их здесь прочтет и в буфер переданный.
[23:30.400 --> 23:33.400]  И вызовет вот этот callback.
[23:33.400 --> 23:36.400]  Опять все понятно, да?
[23:36.400 --> 23:38.400]  А вот что непонятно?
[23:38.400 --> 23:43.400]  Потому что я просто обсуждаю, как эхо-сервер обернуть в классы.
[23:43.400 --> 23:46.400]  Я понимаю, что обсуждается декомпозиция просто.
[23:46.400 --> 23:49.400]  Не, не декомпозиция.
[23:49.400 --> 23:51.400]  Просто интерфейс меняю.
[23:51.400 --> 23:58.400]  Ну мы просто по сути переводим на более высокий уровень код, который мы видели в мане.
[24:00.400 --> 24:03.400]  Не код, который вы видели в мане, а код, который вы писали.
[24:04.400 --> 24:07.400]  То есть ты писала E-Poll когда-нибудь в своей жизни, использовала E-Poll, то?
[24:07.400 --> 24:10.400]  Я пользовалась E-Poll в двух задачках.
[24:10.400 --> 24:15.400]  Сейчас такое ощущение, что я не пользовалась E-Poll в двух задачках.
[24:15.400 --> 24:18.400]  Я писала их сама.
[24:18.400 --> 24:20.400]  Ну эхо-сервер ты писала?
[24:20.400 --> 24:22.400]  Да, это же эхо-сервер.
[24:22.400 --> 24:28.400]  Вот, и ты получала сокет клиента после того, как у тебя случилось событие на сервенном сокете.
[24:28.400 --> 24:31.400]  Регистрировала E-Poll и ждала события.
[24:31.400 --> 24:37.400]  А что ты делала, когда на сокете клиентском загоралось событие?
[24:37.400 --> 24:40.400]  Что вот он готов к чтению.
[24:40.400 --> 24:42.400]  Вот Асю что делает?
[24:42.400 --> 24:49.400]  Он сам за тебя этот сокет берет в Event Loop, вот здесь вот, и вычитывает данные из сокета.
[24:49.400 --> 24:51.400]  Тот буфер, который ты вот здесь передала.
[24:51.400 --> 24:53.400]  Я вручную вычитывала, да.
[24:53.400 --> 24:55.400]  Ну здесь тебя делает Асю.
[24:55.400 --> 24:57.400]  И дальше вызывается вот этот колбэк.
[24:57.400 --> 24:59.400]  То есть ты прочитала, и дальше вызывается вот этот код.
[24:59.400 --> 25:02.400]  Здесь в данном случае он выполняет DoRight.
[25:02.400 --> 25:09.400]  Я скорее не понимаю, я не особо часто работала с колбэками,
[25:09.400 --> 25:13.400]  и поэтому когда я вижу колбэк, у меня немножко большие ступы каждый раз.
[25:13.400 --> 25:17.400]  Ну колбэк это просто код, который вызывается в обработчике события.
[25:17.400 --> 25:19.400]  Вот у меня есть серверный сокет.
[25:19.400 --> 25:21.400]  Вот у меня есть событие на нем.
[25:21.400 --> 25:23.400]  Вот он готов к чтению.
[25:23.400 --> 25:25.400]  Вот у тебя есть обработка этого события.
[25:25.400 --> 25:27.400]  Ну такая понятная. Принять клиента.
[25:27.400 --> 25:31.400]  А дальше есть твоя логика уже, как ты этого клиента обработаешь.
[25:31.400 --> 25:33.400]  Что ты сделаешь дальше.
[25:33.400 --> 25:41.400]  И вот тут Асю говорит, напиши колбэк, что именно ты собираешься делать сокет, который Acceptor получил.
[25:41.400 --> 25:46.400]  Асю уже не знает, как ты хочешь с этим клиентом работать, поэтому он тебя просит.
[25:46.400 --> 25:48.400]  Вот в AsyncAccept напиши колбэк.
[25:48.400 --> 25:52.400]  Я за тебя, Асю говорит, приму клиента, построю сокет,
[25:52.400 --> 25:57.400]  а дальше вот напиши код, который скажет мне, что дальше с этим сокетом делать.
[25:57.400 --> 26:00.400]  А я понимаю, что это все в одном потоке.
[26:00.400 --> 26:03.400]  Ну а это происходит в том потоке, который вызывает ран.
[26:03.400 --> 26:07.400]  Вот тот поток, который вызывает ран и крутит этот event loop и все это обрабатывает.
[26:07.400 --> 26:10.400]  Вот именно здесь происходит вот это вот.
[26:11.400 --> 26:17.400]  Кстати, есть такой вопрос, почему мы сейчас используем лямбда, а не указательную функцию?
[26:17.400 --> 26:18.400]  Вот да, тот же вопрос.
[26:18.400 --> 26:19.400]  Что?
[26:19.400 --> 26:20.400]  Почему лямбда?
[26:20.400 --> 26:21.400]  А не что?
[26:21.400 --> 26:24.400]  А не указательная функция?
[26:24.400 --> 26:28.400]  Зачем мы пользуемся удобными инструментами, а не едим блины с лопаты?
[26:28.400 --> 26:31.400]  Хороший вопрос, потому что так удобнее.
[26:31.400 --> 26:38.400]  Но причем тут, смотри, указательная функция это указательная функция, а лямбда это, например, замыкание.
[26:38.400 --> 26:41.400]  Как ты реализуешь замыкание через указательную функцию?
[26:41.400 --> 26:42.400]  Никак, наверное, да?
[26:42.400 --> 26:45.400]  Ну, функцию мы уже в метагоге передали.
[26:45.400 --> 26:46.400]  А как?
[26:46.400 --> 26:47.400]  Это есть замыкание.
[26:47.400 --> 26:49.400]  Пойнтер на функцию – это пойнтер на код.
[26:49.400 --> 26:52.400]  А этому коду нужен некоторый контекст для исполнения.
[26:52.400 --> 26:53.400]  Это называется замыкание.
[26:53.400 --> 26:54.400]  Да, но…
[26:54.400 --> 26:56.400]  Функция, захваченная из лексического контекста перемена.
[26:56.400 --> 26:59.400]  Мы не используем звездочку, а во звездочку какого угодно размера сама распасется.
[26:59.400 --> 27:01.400]  А откуда эта во звездочку возьмет данные?
[27:01.400 --> 27:02.400]  В синксисиаре.
[27:02.400 --> 27:06.400]  То есть ты еще заведешь структуру, в нее положишь какие-то объекты,
[27:06.400 --> 27:09.400]  вызовешь функцию, которая эту структуру возьмет, закастит.
[27:09.400 --> 27:11.400]  Ты знаешь, что такое замыкание?
[27:11.400 --> 27:12.400]  Да.
[27:12.400 --> 27:13.400]  C++.
[27:13.400 --> 27:16.400]  Ты знаешь, что компедиатор генирует весь этот код за тебя?
[27:16.400 --> 27:17.400]  В нем.
[27:17.400 --> 27:22.400]  Он за тебя сгенирует класс, у которого будут нужные поля, метод…
[27:22.400 --> 27:23.400]  Вот.
[27:23.400 --> 27:26.400]  У нас что-то есть.
[27:26.400 --> 27:33.400]  Зачем мы пишем много странного, уродливого кода вручную,
[27:33.400 --> 27:37.400]  вместо того, чтобы воспользоваться компедиатором, который может сгенировать его автоматически?
[27:37.400 --> 27:38.400]  Вопрос звучит так.
[27:38.400 --> 27:41.400]  Я даже не знаю, как на него ответить, честно.
[27:41.400 --> 27:44.400]  Ну, потому что компедиатор сгенирует весь этот код сам.
[27:44.400 --> 27:46.400]  Это же удобно.
[27:46.400 --> 27:51.400]  Нет, я, конечно, могу завести структуру, положить туда…
[27:51.400 --> 27:56.400]  Вместо того, чтобы написать такой код вот здесь,
[27:56.400 --> 28:00.400]  я могу завести структуру, в нее сделать поле shared pointer,
[28:00.400 --> 28:04.400]  сделать какой-то оператор круглые скобочки, написать там какой-то код,
[28:04.400 --> 28:06.400]  сконструировать этот класс, передать вот…
[28:06.400 --> 28:07.400]  Ну, зачем?
[28:07.400 --> 28:13.400]  Я вот просто пишу лямбду и говорю, что я хочу захватить в эту функцию такие вот переменные
[28:13.400 --> 28:18.400]  из текущего лексического контекста и выполнить в ней такой код и принять такие аргументы.
[28:18.400 --> 28:23.400]  Ну вот, просто язык мне дает инструмент, который решает эту задачу – построение замыканий.
[28:23.400 --> 28:26.400]  Ну ладно.
[28:26.400 --> 28:28.400]  Звучит так, как будто бы…
[28:28.400 --> 28:32.400]  Смотри, замыкания – это конструкция языковая.
[28:32.400 --> 28:34.400]  В компьютере замыканий нет.
[28:34.400 --> 28:36.400]  И, по крайней мере, в наших компьютерах.
[28:36.400 --> 28:39.400]  Я не понимаю, что просто более высоковыравленный инструмент,
[28:39.400 --> 28:41.400]  к кому-то, наверное, бы удобный.
[28:41.400 --> 28:43.400]  Они удобны всем.
[28:43.400 --> 28:46.400]  Но я не понимаю, что заниматься вручную локацией,
[28:46.400 --> 28:50.400]  писать какой-то boilerplate код, который просто…
[28:50.400 --> 28:53.400]  Как тебе сказать?
[28:53.400 --> 28:56.400]  Ты же не пишешь на Assembler, ты же пишешь классы.
[28:56.400 --> 28:57.400]  А класс – что это такое?
[28:57.400 --> 29:00.400]  Это набор функций, у которых есть дополнительный аргумент, неявный.
[29:00.400 --> 29:02.400]  Пойнтер на объект.
[29:02.400 --> 29:05.400]  Но ты, тем не менее, не пишешь все так, как на C.
[29:05.400 --> 29:06.400]  А пишешь класс.
[29:06.400 --> 29:08.400]  Ну давай не писать классы тогда.
[29:08.400 --> 29:09.400]  Ну потому что зачем?
[29:09.400 --> 29:12.400]  Они же тоже реализуются эквивалентно без классов.
[29:12.400 --> 29:16.400]  Просто вот заводишь функцию, вместо класса, там, не знаю…
[29:16.400 --> 29:23.400]  Вместо класса Vector ты можешь завести структуру Vector.
[29:23.400 --> 29:25.400]  В ней сделать там char…
[29:25.400 --> 29:28.400]  там t звездочка буфер.
[29:28.400 --> 29:30.400]  И потом size t size.
[29:30.400 --> 29:34.400]  И сделать мне функции pushback.
[29:38.400 --> 29:40.400]  Ну ни к чему хорошему не приведут.
[29:40.400 --> 29:41.400]  Ну то есть зачем?
[29:41.400 --> 29:44.400]  Вот у тебя есть языковая конструкция, которая помогает тебе
[29:44.400 --> 29:47.400]  удобно, емко выражать свое намерение.
[29:47.400 --> 29:48.400]  Ты и пользуешься.
[29:48.400 --> 29:50.400]  Так, все, давайте вернемся к происходящему.
[29:51.400 --> 29:52.400]  Что?
[29:55.400 --> 29:56.400]  Такого не было.
[30:02.400 --> 30:06.400]  Ну потому что вот мы подписались на событие, что в socket появилась данное событие,
[30:06.400 --> 30:07.400]  случилось все.
[30:07.400 --> 30:10.400]  Мы второй раз подписываемся на него повторно.
[30:14.400 --> 30:16.400]  Еще раз, мы ничего не понимаем.
[30:16.400 --> 30:18.400]  Что такое oContextRUN?
[30:18.400 --> 30:20.400]  Что такое oContextRUN?
[30:21.400 --> 30:23.400]  Он вызывает этот цикл.
[30:23.400 --> 30:26.400]  В этом цикле из Epoxy достается событие.
[30:26.400 --> 30:29.400]  На серверном socket доступно чтение.
[30:29.400 --> 30:34.400]  Мы в этом цикле понимаем, что это был серверный socket,
[30:34.400 --> 30:38.400]  вызываем на нем accept не блокирующий.
[30:38.400 --> 30:42.400]  Получаем socket, вызываем здесь обработчик пользователя.
[30:42.400 --> 30:44.400]  Этот обработчик пользователя что делает?
[30:45.400 --> 30:47.400]  Он вызывает doAccept.
[30:48.400 --> 30:50.400]  Что делает doAccept?
[30:50.400 --> 30:53.400]  Регистрирует в Epoxy событие.
[30:54.400 --> 30:57.400]  То есть снова регистрирует Epoxy этот серверный socket.
[30:57.400 --> 31:03.400]  Но это не рекурсия, это просто мы здесь, внутри этого кода, еще раз зарегистрировали socket.
[31:04.400 --> 31:06.400]  И все, и вот обработчик завершился.
[31:06.400 --> 31:08.400]  Операция поэтому и асинхронная.
[31:08.400 --> 31:13.400]  Мы не дождаемся пока она завершится, мы просто подписываемся на ее завершение.
[31:13.400 --> 31:15.400]  Так что здесь вот есть цикл.
[31:15.400 --> 31:18.400]  Я показывал картинку на реакции, давайте я сейчас ее реанимирую.
[31:18.400 --> 31:20.400]  Сейчас, секунду, можно я закончу?
[31:24.400 --> 31:28.400]  Вот, это задача, которая вызывает aSyncAccept,
[31:28.400 --> 31:32.400]  после которой когда-нибудь запускается Epoxy,
[31:32.400 --> 31:35.400]  в котором зовется accept.
[31:35.400 --> 31:38.400]  И после этого вызывается снова doAccept,
[31:38.400 --> 31:42.400]  который снова вызовет aSyncAccept, который снова регистрирует.
[31:42.400 --> 31:46.400]  То есть вот мы так, по сути, в этом цикле исполняем поочередно две задачи.
[31:46.400 --> 31:49.400]  aSyncAccept, то есть обработчик пользователя,
[31:49.400 --> 31:59.400]  и Epoxy и accept, который выполняет сам event loop.
[31:59.400 --> 32:02.400]  И вот они так чередуются, эта задача порождает в конце концов эту задачу,
[32:02.400 --> 32:05.400]  эта задача в конце концов запускает эту задачу.
[32:06.400 --> 32:11.400]  И вот они так вот бегают по кругу, и вот соединение приходит, приходит, приходит.
[32:12.400 --> 32:13.400]  Вопрос?
[32:16.400 --> 32:20.400]  У меня вопрос не было, я просто не отдаю, что там еще лекция была.
[32:20.400 --> 32:22.400]  Ну нет, если он сейчас.
[32:22.400 --> 32:25.400]  Ты обесцениваешь наше усилие сейчас.
[32:26.400 --> 32:28.400]  Ладно, я вопрос молчать буду.
[32:29.400 --> 32:34.400]  Нет, ты можешь не молчать, но нам действительно нужно разобраться подробнее.
[32:35.400 --> 32:38.400]  Итак, значит, мы с этим циклом разбрались, да?
[32:39.400 --> 32:43.400]  Теперь мы идем дальше, смотрим на этот код.
[32:45.400 --> 32:49.400]  Здесь у нас, ну не так, давайте не на этот код смотреть,
[32:49.400 --> 32:52.400]  а вспомним, какой код вы писали.
[32:52.400 --> 32:56.400]  Вот у вас есть Epoxy, вы в цикле принимаете соединение.
[32:57.400 --> 33:01.400]  Вот, и вы регистрируете соки клиентские.
[33:02.400 --> 33:07.400]  И вот у вас в цикле Epoxy случилось событие, на клиентском соке доступно чтение.
[33:07.400 --> 33:08.400]  Что вы делаете?
[33:09.400 --> 33:12.400]  Это вот по сути обработчик, вот асинкрица.
[33:13.400 --> 33:16.400]  Что вы в нем пишете в своей реализации эхо-сервера?
[33:17.400 --> 33:18.400]  Что вы там писали?
[33:19.400 --> 33:22.400]  Вы достали сокет, дискриптор, на котором можно читать.
[33:23.400 --> 33:24.400]  Ну, видимо, вы читаете.
[33:25.400 --> 33:29.400]  Читаете в какой-то буфер, читаете без блокировки, потому что вы же знаете, что теперь сокет доступно чтение.
[33:29.400 --> 33:30.400]  Что вы дальше делаете?
[33:34.400 --> 33:36.400]  Какой код написан дальше?
[33:37.400 --> 33:40.400]  Идем дальше по дискрипторам.
[33:41.400 --> 33:43.400]  А куда ты данные прочитала сокета?
[33:43.400 --> 33:45.400]  У меня буфер есть какой-то один.
[33:45.400 --> 33:46.400]  Один буфер, да?
[33:46.400 --> 33:47.400]  Один.
[33:47.400 --> 33:49.400]  А вот теперь представь, что у тебя есть три клиента.
[33:50.400 --> 33:51.400]  Да?
[33:51.400 --> 33:53.400]  Они пришли к тебе конкурентно.
[33:53.400 --> 33:54.400]  У меня три буфера тогда.
[33:54.400 --> 33:57.400]  Ну, вот я просто не понимаю, как ты с одним буфером живешь.
[33:57.400 --> 34:01.400]  Ну, у нас изначально была постановка такая, что у нас клиент один.
[34:01.400 --> 34:04.400]  Ну, в общем, один здесь, один здесь.
[34:04.400 --> 34:05.400]  Все удобно.
[34:05.400 --> 34:08.400]  Как тебе сказать?
[34:09.400 --> 34:12.400]  Даже если ты учишься, ты не должна делать бессмысленные вещи.
[34:13.400 --> 34:16.400]  Ну, потому что зачем учиться бессмысленным вещам, правда?
[34:16.400 --> 34:17.400]  Вот я тоже так думаю.
[34:17.400 --> 34:19.400]  Я не понимаю, как можно с одним буфером.
[34:19.400 --> 34:21.400]  Ну, вот у тебя есть три клиента.
[34:21.400 --> 34:24.400]  Зачем тебе не блокирующий код?
[34:24.400 --> 34:26.400]  Зачем тебе E-Pool, когда у тебя клиент один?
[34:27.400 --> 34:30.400]  Ты с одним трудом прекрасно справишься с блокирующих вызовов.
[34:30.400 --> 34:31.400]  Ну, какая польза от этого?
[34:31.400 --> 34:32.400]  Никакой.
[34:32.400 --> 34:34.400]  Польза есть, когда у тебя клиентов много.
[34:34.400 --> 34:35.400]  А поток все еще один.
[34:36.400 --> 34:39.400]  И вот у тебя есть три события из E-Pool.
[34:39.400 --> 34:41.400]  То есть на трех сокетах загорелась операция чтения.
[34:42.400 --> 34:44.400]  И что вы такого код не описали?
[34:49.400 --> 34:50.400]  Подожди, что значит поток?
[34:50.400 --> 34:51.400]  Поток один тут.
[34:52.400 --> 34:53.400]  Клиентов, может быть, сколько угодно.
[34:56.400 --> 34:57.400]  Надеюсь.
[34:57.400 --> 34:59.400]  Я помню, что я открываю три окошка.
[35:00.400 --> 35:02.400]  Из них писал стопы на сервисе.
[35:02.400 --> 35:04.400]  Ты хочешь три клиента, а мой код обрабатываю?
[35:04.400 --> 35:05.400]  Нет.
[35:05.400 --> 35:07.400]  Ну, если бухер один, то нет.
[35:08.400 --> 35:09.400]  Для каждого клиента.
[35:13.400 --> 35:15.400]  Значит, у вас было много бухеров?
[35:15.400 --> 35:17.400]  Каждого клиента один.
[35:17.400 --> 35:18.400]  Хорошо.
[35:18.400 --> 35:19.400]  А где вы его латировали?
[35:19.400 --> 35:20.400]  На стеке.
[35:20.400 --> 35:22.400]  На каком стеке?
[35:22.400 --> 35:24.400]  Внутри функции отзыва.
[35:26.400 --> 35:27.400]  Ну, вот, значит.
[35:27.400 --> 35:29.400]  Звучит очень плохо уже.
[35:32.400 --> 35:33.400]  Ну, хорошо.
[35:33.400 --> 35:35.400]  Вот у тебя загорелось событие на сокете.
[35:35.400 --> 35:36.400]  Сокет готов к чтению.
[35:36.400 --> 35:38.400]  Ты прочитал, вызвал какую-то функцию.
[35:38.400 --> 35:40.400]  В ней прочитал данные в буфер.
[35:41.400 --> 35:42.400]  На этом стеке.
[35:43.400 --> 35:45.400]  А на стеке этой функции что произошло дальше?
[35:47.400 --> 35:49.400]  Ну, дальше я написал обратно.
[35:49.400 --> 35:50.400]  Как?
[35:54.400 --> 35:56.400]  Ты написал сокет-райт какой-нибудь, да?
[35:56.400 --> 35:57.400]  Да.
[35:57.400 --> 35:59.400]  А почему он не заблокируется?
[36:00.400 --> 36:01.400]  Вот я клиент, я просто...
[36:01.400 --> 36:02.400]  Что?
[36:06.400 --> 36:07.400]  Это не так работает.
[36:07.400 --> 36:11.400]  Сокет в неблокирующем режиме, это не когда он делает запись в неблокирующем.
[36:11.400 --> 36:15.400]  А когда он не может сделать запись, он говорит, что он не может сделать запись.
[36:16.400 --> 36:18.400]  Ну, нельзя просто в сеть писать бесконечно.
[36:18.400 --> 36:20.400]  Ты знаешь, где CP устроено?
[36:22.400 --> 36:23.400]  Подожди.
[36:25.400 --> 36:27.400]  Нельзя писать в сокет бесконечно.
[36:27.400 --> 36:31.400]  Конечно, есть congestion control, есть flow control.
[36:31.400 --> 36:34.400]  То есть ты пишешь в сеть, и с одной стороны ты перегружаешь в сеть,
[36:34.400 --> 36:37.400]  с другой стороны ты перегружаешь получателя данных.
[36:37.400 --> 36:44.400]  И в TCP есть очень много сложных механизмов, которые позволяют вот так децентрализована,
[36:44.400 --> 36:49.400]  принимая локальные решения, контролировать как нагрузку глобальную на всю сеть
[36:49.400 --> 36:52.400]  между многими-многими парами участников.
[36:52.400 --> 36:55.400]  Ну или скажем, вот у тебя есть сервер и клиент.
[36:55.400 --> 36:57.400]  И сервер отвечает клиенту, а клиент просто не читает.
[36:57.400 --> 36:59.400]  Он нашел пить чай.
[36:59.400 --> 37:01.400]  А сервер хочет ему GIGABYTE данных отправить.
[37:01.400 --> 37:03.400]  Но он же не может там отправить все GIGABYTE данных.
[37:03.400 --> 37:05.400]  На клиенте они не поместятся.
[37:06.400 --> 37:08.400]  Почему? Мы отправили, а вот как?
[37:08.400 --> 37:10.400]  Кто уже получает эти наши данные?
[37:10.400 --> 37:12.400]  Сейчас, подожди.
[37:13.400 --> 37:15.400]  Я тебе могу про TCP объяснить?
[37:15.400 --> 37:17.400]  В TCP так не работает, ты говоришь, разумеется.
[37:17.400 --> 37:20.400]  Сеть не передает данные бесконечно.
[37:20.400 --> 37:21.400]  Почему мы ее не видим?
[37:21.400 --> 37:23.400]  Сейчас, подожди.
[37:25.400 --> 37:30.400]  Мир так не работает.
[37:30.400 --> 37:33.400]  Мир так не устроен, как ты говоришь.
[37:33.400 --> 37:36.400]  Если у тебя есть клиент и сервер,
[37:36.400 --> 37:41.400]  то между ними должен быть механизм Flow Control и Backpress, это называется.
[37:41.400 --> 37:44.400]  Если с другой стороны данные не принимают, то отправлять их перестают.
[37:44.400 --> 37:46.400]  Потому что это лишняя нагрузка на сеть.
[37:46.400 --> 37:50.400]  Ну представь, я генерирую данные со скоростью миллиард,
[37:50.400 --> 37:54.400]  не знаю, GIGABYTE данных в секунду, отправляю их в сеть.
[37:54.400 --> 37:55.400]  И так делают много компьютеров.
[37:55.400 --> 37:58.400]  Сеть не сможет такую нагрузку переживать.
[37:58.400 --> 38:01.400]  Должен быть механизм, который обеспечивает обратную связь,
[38:01.400 --> 38:05.400]  который запрещает клиентам, которые работают с сетью, так сеть нагружать.
[38:05.400 --> 38:08.400]  Потому что один клиент убьет всю сеть.
[38:08.400 --> 38:10.400]  Он займет всю пропускную способность.
[38:10.400 --> 38:13.400]  Послушай, пожалуйста.
[38:14.400 --> 38:17.400]  Поэтому на уровне протокола TCP, транспортного протокола,
[38:17.400 --> 38:20.400]  который отвечает за доставку данных между парами клиентов,
[38:20.400 --> 38:23.400]  есть механизм, который делает следующее.
[38:23.400 --> 38:28.400]  Он отправляет данные, и если он не получает вовремя подтверждение,
[38:28.400 --> 38:32.400]  что клиент их получил, если он способен другая страна их вырабатывать,
[38:32.400 --> 38:36.400]  то он снижает скорость, с которой он все данные может писать.
[38:36.400 --> 38:41.400]  У него есть некоторые ограничения, сколько байт он может писать в единицу времени через себя.
[38:41.400 --> 38:46.400]  И ты не можешь просто взять и писать socket, взять и сделать write в socket.
[38:46.400 --> 38:50.400]  Этот запись в socket может также заблокироваться,
[38:50.400 --> 38:52.400]  как может заблокироваться чтение socket.
[38:52.400 --> 38:54.400]  Здесь ситуация абсолютно симметричная.
[38:54.400 --> 39:00.400]  Поэтому если ты получил событие, что socket готов к чтению,
[39:00.400 --> 39:03.400]  то ты, безусловно, можешь без блокировки их прочитать.
[39:03.400 --> 39:08.400]  Но ты не можешь в данном случае без блокировки их записать.
[39:08.400 --> 39:12.400]  Если ты поставил socket в блокирующий режим, то может быть твоя запись случится,
[39:12.400 --> 39:15.400]  а может быть тебе socket ответит, что он не готов сейчас к записи.
[39:15.400 --> 39:17.400]  Он скажет, я был блок.
[39:17.400 --> 39:19.400]  И все, и твой сервер разломается.
[39:19.400 --> 39:22.400]  А если ты поставил блокирующую запись, а не неплокирующую,
[39:22.400 --> 39:28.400]  то ты получил однопоточный сервер, который заблокировался на одном клиенте и других больше не обслуживает.
[39:28.400 --> 39:31.400]  Поэтому, разумеется, так писать код нельзя.
[39:31.400 --> 39:33.400]  Это полная бессмысленность.
[39:33.400 --> 39:43.400]  Когда вы получили данные socket, вы их читаете в какой-то буфер.
[39:43.400 --> 39:49.400]  А после этого вы должны в E-Poll зарегистрировать socket на события, он готов к записи.
[39:49.400 --> 39:54.400]  И когда вы второй раз из этого E-Poll достанете события, socket готов к записи,
[39:54.400 --> 39:58.400]  то вы уже из этого буфера, который где-то находится, запишете данные туда без блокировки.
[39:58.400 --> 40:04.400]  Потому что E-Poll вам сказал операционную систему, что вот сейчас socket готов обслужить вашу запись.
[40:04.400 --> 40:07.400]  И то непонятно всю или не всю.
[40:07.400 --> 40:11.400]  И то вы здесь не знаете, сколько именно байт вы сможете socket записать.
[40:11.400 --> 40:16.400]  Потому что, может быть, клиент с другой стороны сколько-то вычитал данных с socket,
[40:16.400 --> 40:20.400]  но все-таки не все еще, что мог бы.
[40:20.400 --> 40:23.400]  И вы отправитесь туда не 100 байт, которые у вас есть, а 50.
[40:23.400 --> 40:26.400]  А остальные останутся в буфере.
[40:26.400 --> 40:31.400]  То есть клиент должен снова отправить запрос, чтобы он готов столкнуть прочитание?
[40:31.400 --> 40:33.400]  Нет, он не отправляет запрос.
[40:33.400 --> 40:36.400]  Это просто механика TCP-соединения.
[40:36.400 --> 40:40.400]  Там бегают дотограммы туда и сюда, а в одну сторону.
[40:40.400 --> 40:43.400]  То есть не то, что туда и сюда, это же двунаправленный канал.
[40:43.400 --> 40:45.400]  Вот ты отправляешь данные, отправляешь дотограмму,
[40:45.400 --> 40:48.400]  а в обратную сторону ты получаешь подтверждение, что они доставлены,
[40:48.400 --> 40:53.400]  плюс еще некоторую информацию о том, сколько еще данных клиент сейчас готов получить.
[40:53.400 --> 40:56.400]  Вот там есть понятие окна.
[40:56.400 --> 40:58.400]  Вот ты не можешь сказать socket бесконечно.
[40:58.400 --> 41:00.400]  Вот у клиента есть с другой стороны окно.
[41:00.400 --> 41:04.400]  И если окно заполняется в операционной системе, то есть буфер некоторый внутренний,
[41:04.400 --> 41:07.400]  а клиент из него не учитывает, то все, отправка останавливается.
[41:07.400 --> 41:11.400]  И в обратную сторону вылетает сигнал, что все остановилось, хватит отправлять.
[41:11.400 --> 41:14.400]  Вот, и смотрите, что у вас получается теперь.
[41:14.400 --> 41:17.400]  Вы можете из трех socket'ов прочесть данные,
[41:17.400 --> 41:20.400]  а потом некоторое время не сможете их записать.
[41:20.400 --> 41:23.400]  И вот у вас теперь есть три соединения, у вас должно быть три буфера,
[41:23.400 --> 41:27.400]  потому что у вас три соединения находятся между чтением и записью.
[41:27.400 --> 41:32.400]  Вот, но поток у вас всего один, поэтому никаких локальных переменных,
[41:32.400 --> 41:36.400]  никаких глобальных переменных быть не может, вам нужна динамическая локация.
[41:36.400 --> 41:41.400]  Вам буферы нужны на куче, которые живут до тех пор, пока живут ваши соединения.
[41:41.400 --> 41:46.400]  И вот ровно поэтому мы здесь алоцируем структуру session на куче,
[41:46.400 --> 41:50.400]  и в ее поле кладем этот самый буфер.
[41:50.400 --> 41:54.400]  И когда мы принимаем клиента, мы вот этот session конструируем.
[41:54.400 --> 41:58.400]  Вот он, этот объект, он и несет в себе буфер.
[41:58.400 --> 42:01.400]  А когда мы планируем операцию учтения,
[42:01.400 --> 42:06.400]  то мы захватываем в обработчик сильную ссылку на этот объект.
[42:06.400 --> 42:09.400]  То есть мы продляем время жизни class of session, в котором лежит буфер,
[42:09.400 --> 42:15.400]  до тех пор, пока socket не будет готов к чтению, не прочитает данные,
[42:15.400 --> 42:17.400]  и мы их не обработаем.
[42:17.400 --> 42:21.400]  А когда мы их будем обрабатывать, мы снова заведем асинхронную операцию,
[42:21.400 --> 42:24.400]  то есть зарегистрируем socket уже на запись,
[42:24.400 --> 42:29.400]  снова захватим сильную ссылку на текущий объект, чтобы буфер продолжал жить.
[42:29.400 --> 42:33.400]  Ну короче, здесь ситуация симметричная.
[42:33.400 --> 42:37.400]  И вот и чтение, и запись, и это абсолютно симметричные события,
[42:37.400 --> 42:40.400]  и при работе с Epolem они обрабатываются, конечно, однородно.
[42:40.400 --> 42:43.400]  То есть мы и то, и другое кладем в Epole, и читаем, и пишем,
[42:43.400 --> 42:46.400]  только тогда, когда socket, когда Epole нам сказал,
[42:46.400 --> 42:50.400]  что из socket можно читать или в socket можно писать.
[42:50.400 --> 42:53.400]  Вот нам нужно много буферов, и собственно, вот эта программа,
[42:53.400 --> 42:56.400]  она написана так, и ваша программа не может быть написана по-другому принципиально,
[42:56.400 --> 42:59.400]  потому что мы все очень же заворачиваем код класса сейчас.
[42:59.400 --> 43:04.400]  Я вас понял, честно говоря.
[43:04.400 --> 43:07.400]  Просто две вещи.
[43:07.400 --> 43:12.400]  Первое, мне не приходило в голову, что мы не можем просто кидать данные,
[43:12.400 --> 43:16.400]  а вот как они идут, как вы, как они получаются, это не наша проблема, я так думал.
[43:16.400 --> 43:20.400]  А во-вторых, по-моему, мне, ну,
[43:20.400 --> 43:23.400]  я это вот показывал нескольким проверяющим в манере кто из них,
[43:23.400 --> 43:26.400]  и не сказал никаких замечаний.
[43:26.400 --> 43:30.400]  Поверяющие тоже студенты, поэтому...
[43:30.400 --> 43:35.400]  Будь осторожен, не доверяй людям.
[43:35.400 --> 43:38.400]  Мне кажется, ну, есть много мест, где можно про тебя прочитать,
[43:38.400 --> 43:42.400]  есть очень-очень простая статья из очень хорошей книжки,
[43:42.400 --> 43:47.400]  там вот все на пальцах.
[43:47.400 --> 43:51.400]  Ну, эта книжка так называется, High Performance Browser Networking.
[43:51.400 --> 43:55.400]  Ну, давай я просто чат отправлю общий потом, после семинара.
[43:55.400 --> 43:59.400]  Вот тут какие-то очень поверхственные механики TCP,
[43:59.400 --> 44:03.400]  и, по крайней мере, все важные вещи тут описаны.
[44:03.400 --> 44:08.400]  Тут есть Flow Control описан, Congestion Control,
[44:08.400 --> 44:13.400]  ну, то есть TCP, смотрите, это, на самом деле, сложная вещь.
[44:13.400 --> 44:15.400]  Осенью мы с этого спецкурса начнем,
[44:15.400 --> 44:17.400]  с распределенным системам.
[44:17.400 --> 44:19.400]  TCP это распределенная система.
[44:19.400 --> 44:21.400]  Есть вот один участник, другой, если участник не на разных машинах,
[44:21.400 --> 44:23.400]  а между ними есть какая-то общая сеть.
[44:23.400 --> 44:25.400]  И эти участники не понимают глобально, что происходит,
[44:25.400 --> 44:29.400]  в каком состоянии их собеседник,
[44:29.400 --> 44:31.400]  и в каком состоянии сеть.
[44:31.400 --> 44:33.400]  Поэтому они пытаются принимать локальные решения,
[44:33.400 --> 44:37.400]  так чтобы и адресаты не перегрузить данными,
[44:37.400 --> 44:43.400]  и не захватить там всю сеть своим потоком одним.
[44:43.400 --> 44:45.400]  Вот для этого в TCP много разных механика.
[44:45.400 --> 44:47.400]  Это вообще-то очень сложный протокол.
[44:47.400 --> 44:51.400]  И протокол установки, ну, не знаю, если вы когда-нибудь смотрели,
[44:51.400 --> 44:56.400]  как вообще соединение открывается-закрывается.
[44:56.400 --> 45:01.400]  Это очень сложно.
[45:01.400 --> 45:05.400]  Вот какие-то внутренние состояния протокола.
[45:05.400 --> 45:11.400]  Там можно шею себе свернуть.
[45:11.400 --> 45:13.400]  Вот это хитрая штука.
[45:13.400 --> 45:17.400]  И писать в socket просто так нельзя.
[45:17.400 --> 45:23.400]  Мы должны блокироваться и в классе событий регистрироваться в Epoly
[45:23.400 --> 45:29.400]  и ждать, когда из Epoly прилетит событие о готовности socket.
[45:29.400 --> 45:31.400]  И вот я в чате спрашивал и столкнулся с тем,
[45:31.400 --> 45:35.400]  что никто не ответил или человек один не ответил.
[45:35.400 --> 45:39.400]  Но вот смотрите, когда мы регистрируем события в Epoly,
[45:39.400 --> 45:43.400]  точнее не так, когда мы получаем события из Epoly,
[45:43.400 --> 45:47.400]  то нам же отдают структуру некоторую.
[45:47.400 --> 45:53.400]  И в ней есть в частности дискриптер, на котором возникло событие.
[45:53.400 --> 45:59.400]  А еще есть, смотрите, какой-то поинтер.
[45:59.400 --> 46:02.400]  Понимаете ли вы, зачем этот поинтер нужен?
[46:02.400 --> 46:10.400]  Это так называемый непрозрачный указатель, который Epoly ничего не знает.
[46:10.400 --> 46:16.400]  Вот когда вы регистрируете событие в Epoly сейчас,
[46:16.400 --> 46:28.400]  если здесь, когда вы регистрируете событие в Epoly,
[46:28.400 --> 46:31.400]  то вы же этот указатель передаете в Epoly.
[46:31.400 --> 46:34.400]  А когда события наступают, вам его возвращают.
[46:34.400 --> 46:40.400]  То есть сам Epoly никак этот поинтер не интерпретирует.
[46:40.400 --> 46:43.400]  Это какие-то ваши данные.
[46:43.400 --> 46:47.400]  И когда мы регистрируем socket, мы кладем туда какой-то поинтер.
[46:47.400 --> 46:51.400]  Когда мы достаем событие, мы этим поинтером можем воспользоваться.
[46:51.400 --> 46:54.400]  Вот, простое вопрос на понимание.
[46:54.400 --> 46:57.400]  Если вы пишете асинхронный эхо-сервер, нормальный,
[46:57.400 --> 47:00.400]  то как вы будете пользоваться этим поинтером?
[47:00.400 --> 47:04.400]  Ну, вы в этот поинтер при регистрации socket
[47:04.400 --> 47:07.400]  просто положите поинтер на буфер свой,
[47:07.400 --> 47:10.400]  чтобы когда вы получили событие из Epoly,
[47:10.400 --> 47:14.400]  вы взяли этот поинтер, его закастили в чар-звездочек каком-то,
[47:14.400 --> 47:18.400]  и в него прочли данные.
[47:18.400 --> 47:22.400]  Или если вы пишете ASIO, то вы можете через этот поинтер
[47:22.400 --> 47:26.400]  связать события на socket с каким-то объектом таймер,
[47:26.400 --> 47:28.400]  с каким-то объектом socket.
[47:28.400 --> 47:29.400]  Понимаете?
[47:29.400 --> 47:33.400]  То есть найти объект, к которому эти события логически привязаны.
[47:33.400 --> 47:35.400]  Там не нужна никакая мэпа,
[47:35.400 --> 47:38.400]  которая отображает дескрипторы в какие-то таймеры.
[47:38.400 --> 47:40.400]  Вот ровно для этого и существует этот поле.
[47:40.400 --> 47:42.400]  Это достаточно удобно.
[47:42.400 --> 47:46.400]  Его можно по-разному использовать, но все применения примерно такие.
[47:52.400 --> 47:55.400]  Ну, что мне сказать?
[47:55.400 --> 47:57.400]  Мне кажется, что я код разобрал.
[47:57.400 --> 48:00.400]  То есть сейчас должно быть все понятно.
[48:00.400 --> 48:02.400]  Да?
[48:04.400 --> 48:07.400]  То есть я понимаю, что...
[48:07.400 --> 48:09.400]  Его контекст написан, конечно, сложно,
[48:09.400 --> 48:11.400]  и там много всего внутри,
[48:11.400 --> 48:15.400]  много всяких сложных непонятных штук.
[48:15.400 --> 48:22.400]  Но мы, наверное, сейчас не хотим их разбирать.
[48:25.400 --> 48:35.400]  Давайте я другой вопрос задам, лучше.
[48:35.400 --> 48:39.400]  Вот его контекст крутит этот even loop, да?
[48:39.400 --> 48:44.400]  А еще он же может запускать не только...
[48:44.400 --> 48:52.400]  Сейчас давайте вернемся к этому примеру.
[48:53.400 --> 48:56.400]  Вот мы здесь положили... Мы сконструировали таймер.
[48:56.400 --> 49:00.400]  Видимо, здесь мы завели файловый дескриптор для таймера.
[49:00.400 --> 49:05.400]  Здесь мы, видимо, зарегистрировали дескриптор в Epole.
[49:05.400 --> 49:10.400]  А здесь мы крутим Epole и дожидаемся, пока это событие не наступит.
[49:10.400 --> 49:12.400]  Там достаем таймер.
[49:12.400 --> 49:16.400]  По поинтру из события достаем объект таймера, вызываем callback.
[49:16.400 --> 49:20.400]  Как-то так можно было бы себе это представить.
[49:20.400 --> 49:25.400]  А теперь...
[49:25.400 --> 49:28.400]  Вспомним, что его контекст, это же не только Epole,
[49:28.400 --> 49:31.400]  его контекст может исполнить просто задача.
[49:31.400 --> 49:35.400]  И как бы мы одно с другим связали.
[49:35.400 --> 49:40.400]  Но, видимо, в его контексте есть Epole,
[49:40.400 --> 49:43.400]  а еще есть просто очередь задач.
[49:43.400 --> 49:46.400]  И как нам между ними балансировать?
[49:53.400 --> 49:55.400]  Ну, просто смотрите, в чем мой вопрос.
[49:55.400 --> 49:57.400]  Когда мы спим на Epole, мы же блокируемся
[49:57.400 --> 49:59.400]  и можем ждать некоторое время, пока событие не наступит.
[49:59.400 --> 50:01.400]  А у нас же еще задача просто есть.
[50:01.400 --> 50:04.400]  Вот как нам организовать код?
[50:07.400 --> 50:08.400]  Не надо.
[50:08.400 --> 50:11.400]  У нас есть однопоточный код. Его контекст.
[50:11.400 --> 50:14.400]  У него есть очередь задач и есть Epole.
[50:14.400 --> 50:17.400]  Как он будет в Run между ними балансировать?
[50:17.400 --> 50:20.400]  Было бы странно ведь блокироваться на Epole в Wait,
[50:20.400 --> 50:23.400]  когда у нас есть готовые обработчики для запуска.
[50:31.400 --> 50:33.400]  Нет, не будем ничего такого делать.
[50:33.400 --> 50:35.400]  Мы пишем простой однопоточный код.
[50:35.400 --> 50:39.400]  Его контекст с вызовом Run, чтобы запускать его из одного потока.
[50:39.400 --> 50:42.400]  В этот его контекст можно положить просто задачу,
[50:42.400 --> 50:48.400]  а можно сделать Epole Wait внутри.
[50:48.400 --> 50:51.400]  Так вот, смотрите, когда задач нет,
[50:51.400 --> 50:54.400]  его контекст Run должен блокировать поток.
[50:55.400 --> 50:56.400]  Разумно?
[50:56.400 --> 50:57.400]  Да.
[50:57.400 --> 50:58.400]  Вот.
[50:58.400 --> 51:01.400]  Когда задача есть, задачи должны выполняться без ожидания.
[51:03.400 --> 51:05.400]  Так вот. Как же нам такой код написать?
[51:05.400 --> 51:08.400]  А если их надо управлять без ожидания?
[51:08.400 --> 51:10.400]  Без блокировки потока, в смысле.
[51:10.400 --> 51:12.400]  Просто брать и выполнять.
[51:12.400 --> 51:14.400]  Мы пишем. Его контекст однопоточный.
[51:14.400 --> 51:16.400]  Один Run вызывает из одного потока.
[51:26.400 --> 51:29.400]  Ты что-то очень сложное сегодня говоришь.
[51:29.400 --> 51:32.400]  Давайте я расскажу. Что-то не получается.
[51:32.400 --> 51:34.400]  Какой поток? У нас всего один поток.
[51:34.400 --> 51:36.400]  В этом примере всего один поток.
[51:36.400 --> 51:38.400]  Откуда берутся еще потоки? Я не понимаю.
[51:41.400 --> 51:42.400]  Мы пишем. Его контекст.
[51:42.400 --> 51:44.400]  Мы в нем сделали Epole.
[51:44.400 --> 51:47.400]  Умеем там заводить таймеры, умеем там поддерживать сокеты.
[51:47.400 --> 51:49.400]  А теперь мы хотим просто иметь возможность
[51:49.400 --> 51:51.400]  запускать в нем задачи без ожидания.
[51:56.400 --> 51:58.400]  Ну просто чередовать два механизма.
[51:58.400 --> 52:00.400]  Вот если у вас есть задача,
[52:00.400 --> 52:03.400]  вы вызываете задачу, а потом вызываете Epole.
[52:03.400 --> 52:05.400]  И смотрите, когда вы вызываете Epole.
[52:05.400 --> 52:07.400]  Если у вас есть уже готовые задачи,
[52:07.400 --> 52:09.400]  помимо Epole,
[52:09.400 --> 52:12.400]  то вы вызываете Epole Wait без блокировки.
[52:12.400 --> 52:14.400]  Просто берете готовые события,
[52:14.400 --> 52:16.400]  но не блокируетесь.
[52:16.400 --> 52:18.400]  Потому что прямо сейчас у вас есть задачи,
[52:18.400 --> 52:20.400]  которые можно исполнить.
[52:20.400 --> 52:23.400]  А если у вас очередь задач на исполнение пустая,
[52:23.400 --> 52:26.400]  то так уж и быть.
[52:26.400 --> 52:28.400]  Вы заблокируетесь на Epole Wait.
[52:28.400 --> 52:30.400]  Потому что пока из Epole Wait не придет событие,
[52:30.400 --> 52:32.400]  задач не появится.
[52:32.400 --> 52:34.400]  Потому что только задачи порождают новые задачи.
[52:34.400 --> 52:36.400]  Понятная идея?
[52:40.400 --> 52:42.400]  То есть мы в Run засыпаем на Epole,
[52:42.400 --> 52:44.400]  когда вообще делать нечего,
[52:44.400 --> 52:46.400]  но если есть какие-то готовые задачи,
[52:46.400 --> 52:48.400]  и ее положили с помощью пост,
[52:48.400 --> 52:52.400]  то мы в этом Epole блокируемся.
[52:52.400 --> 52:57.400]  То мы, наоборот, в Epole не блокируемся,
[52:57.400 --> 52:59.400]  просто вызываем Epole Wait с нулевым тайм-аутом,
[52:59.400 --> 53:01.400]  получаем готовые события,
[53:01.400 --> 53:02.400]  обрабатываем их,
[53:02.400 --> 53:04.400]  и просто запускаем задачи из очереди,
[53:04.400 --> 53:06.400]  которые рядом лежат.
[53:06.400 --> 53:09.400]  Но на самом деле можно сделать все по-другому.
[53:09.400 --> 53:12.400]  Можно сказать, что его контекст просто запускает задачи,
[53:12.400 --> 53:15.400]  а среди этих задач есть задачи ваши,
[53:15.400 --> 53:17.400]  а есть задачи служебные,
[53:17.400 --> 53:19.400]  которые вызывают Epole.
[53:19.400 --> 53:21.400]  И Epole в этих служебных задачах блокируется,
[53:21.400 --> 53:23.400]  когда других задач нет,
[53:23.400 --> 53:25.400]  и не блокируется, когда другие задачи есть.
[53:25.400 --> 53:29.400]  И вот получается, что он способен и кулбеки запускать,
[53:29.400 --> 53:32.400]  и просто запускать задачи кулбеки,
[53:32.400 --> 53:34.400]  такие без события,
[53:34.400 --> 53:39.400]  и подписывать и заводить кулбеки,
[53:39.400 --> 53:42.400]  которые запускаются по событию там таймера.
[53:42.400 --> 53:48.400]  В смысле, каких два?
[53:48.400 --> 53:50.400]  Я один рассказал.
[53:50.400 --> 53:52.400]  Просто чередуем одно и другое Epole,
[53:52.400 --> 53:54.400]  и запуск задач.
[53:54.400 --> 53:58.400]  Просто тут у нас вопрос только в том,
[53:58.400 --> 54:00.400]  блокироваться или не блокироваться в Epole Wait.
[54:00.400 --> 54:02.400]  Мы блокируемся, если других задач вообще нет,
[54:02.400 --> 54:04.400]  потому что задачи возникают только
[54:04.400 --> 54:06.400]  к реакции на события.
[54:06.400 --> 54:09.400]  То есть мы начали эхо-сервер писать,
[54:09.400 --> 54:11.400]  точнее мы его запустили,
[54:11.400 --> 54:16.400]  мы зарегистрировали в Epole серверный сокет,
[54:16.400 --> 54:18.400]  а потом ничего не происходит,
[54:18.400 --> 54:20.400]  клиентов нет.
[54:20.400 --> 54:22.400]  Но Epole блокируется.
[54:22.400 --> 54:24.400]  Теперь клиент появился,
[54:24.400 --> 54:26.400]  мы его обработали,
[54:26.400 --> 54:28.400]  мы создали для него сокет,
[54:28.400 --> 54:30.400]  создали сэшн, зарегистрировали что-то еще.
[54:30.400 --> 54:34.400]  И теперь...
[54:34.400 --> 54:38.400]  В этом примере, кроме Epole Wait,
[54:38.400 --> 54:40.400]  ничего нет.
[54:40.400 --> 54:42.400]  А в этом примере уже появляется пост,
[54:42.400 --> 54:44.400]  и в нем могут быть независимые задачи,
[54:44.400 --> 54:46.400]  их просто нужно выполнять.
[54:46.400 --> 54:50.400]  Так что не должно быть вопросов,
[54:50.400 --> 54:52.400]  как это реализовано.
[54:52.400 --> 54:54.400]  Можно себе представить целиком этот код,
[54:54.400 --> 54:56.400]  а дальше можно представить себе,
[54:56.400 --> 54:58.400]  что в таком планировщике мы запускаем файберы,
[54:58.400 --> 55:00.400]  и вот эти кулбеки, которые там запускаются,
[55:00.400 --> 55:02.400]  это не что иное, как резюм,
[55:02.400 --> 55:04.400]  корутин файберов.
[55:04.400 --> 55:08.400]  Вот нужно вот эту картинку,
[55:08.400 --> 55:10.400]  ну в смысле наши файберы,
[55:10.400 --> 55:12.400]  встроить вот в эту картинку,
[55:12.400 --> 55:14.400]  и все должно сочетаться.
[55:20.400 --> 55:22.400]  То есть в конце концов,
[55:22.400 --> 55:26.400]  и его контекст и ThreadPool запускают задачи,
[55:26.400 --> 55:28.400]  но в его контексте запускается
[55:28.400 --> 55:30.400]  некоторая служебная специальная задача,
[55:30.400 --> 55:32.400]  которая опрашивает очередь событий
[55:32.400 --> 55:34.400]  операционной системы.
[55:34.400 --> 55:36.400]  И вот мы с ней взаимодействуем
[55:36.400 --> 55:40.400]  с помощью вот всяких этих примитивов,
[55:40.400 --> 55:42.400]  типа таймера или socket.
[55:42.400 --> 55:44.400]  И вот так все это вместе крутится.
[55:52.400 --> 55:54.400]  Понятно, да?
[55:54.400 --> 55:56.400]  На самом деле, конечно, понятно,
[55:56.400 --> 55:58.400]  если ты напишешь шехосевер настоящий
[55:58.400 --> 56:00.400]  на Японии руками,
[56:00.400 --> 56:02.400]  тогда станет понятно.
[56:02.400 --> 56:06.400]  Без этого мы не все понимаем.
[56:06.400 --> 56:08.400]  Ну ладно,
[56:08.400 --> 56:10.400]  я даже не знаю,
[56:10.400 --> 56:12.400]  что еще можно про этот код рассказать.
[56:12.400 --> 56:14.400]  Ну подумай, какие вопросы у тебя еще возникают,
[56:14.400 --> 56:16.400]  или ты еще не делала задачу,
[56:16.400 --> 56:18.400]  которая перед нами.
[56:24.400 --> 56:26.400]  А с карутиной мы...
[56:26.400 --> 56:28.400]  Там вопросов не осталось у нас.
[56:28.400 --> 56:30.400]  В целом, мне понятно,
[56:30.400 --> 56:32.400]  не кто у нее работал.
[56:32.400 --> 56:34.400]  А с карутиной мы...
[56:34.400 --> 56:36.400]  Там вопросов не осталось у нас.
[56:36.400 --> 56:38.400]  А с карутиной мы...
[56:38.400 --> 56:40.400]  А с карутиной мы...
[56:40.400 --> 56:42.400]  Чем должен быть твёрдый уровень гестации?
[56:42.400 --> 56:44.400]  Чем должен быть твёрдый уровень гестации?
[56:56.400 --> 56:58.400]  То есть только из-за того,
[56:58.400 --> 57:00.400]  что мы хотим, чтобы она была видна на бурном файде, да?
[57:10.400 --> 57:18.400]  Ну давайте, набросайте какие-нибудь вопросы.
[57:18.400 --> 57:21.400]  Вообще, меня интересна по поводу локатора.
[57:21.400 --> 57:23.400]  Какого локатора?
[57:23.400 --> 57:30.400]  Ну, нам же в задачах противно нужно написать свой вариант локатора.
[57:30.400 --> 57:32.400]  Локатор астек?
[57:32.400 --> 57:33.400]  Ну, так.
[57:33.400 --> 57:34.400]  Так.
[57:34.400 --> 57:37.400]  Я, конечно, писал что-то, но не самое глупое.
[57:37.400 --> 57:41.400]  Мне кажется, что если бы мы, например, знали...
[57:41.400 --> 57:44.400]  Мог ли эстеку сказать какой-нибудь число?
[57:44.400 --> 57:46.400]  Допустим, он бы его помнил.
[57:46.400 --> 57:50.400]  Может, было бы написать локатор гораздо лучше?
[57:50.400 --> 57:53.400]  Чем он был бы лучше? И причем? Что такое число?
[57:53.400 --> 57:55.400]  Ну, условно говоря, его номер.
[57:55.400 --> 57:58.400]  Я просто честно говоря хотел написать фулл локатор.
[57:58.400 --> 58:01.400]  Но понял, что это, наверное, можно делать.
[58:01.400 --> 58:03.400]  Ну, в смысле, ты про тредлокал говоришь?
[58:03.400 --> 58:05.400]  Нет, ну про стейк.
[58:05.400 --> 58:07.400]  Ты точно понимаешь, что такое тредлокал?
[58:10.400 --> 58:13.400]  Ну, там, в пуре потоков ты использовал тредлокал переменное.
[58:13.400 --> 58:15.400]  Потом ты говоришь про какие-то номера потоков.
[58:15.400 --> 58:17.400]  Номера потоков никому никогда не нужны.
[58:17.400 --> 58:19.400]  Нет, я никогда номера попал.
[58:19.400 --> 58:21.400]  Он говорит про локацию стейка.
[58:21.400 --> 58:22.400]  Про локацию стейка?
[58:22.400 --> 58:23.400]  Да.
[58:23.400 --> 58:24.400]  Ну, ты говори, число какое-то?
[58:24.400 --> 58:25.400]  Размерово.
[58:25.400 --> 58:27.400]  Нет, не номер.
[58:27.400 --> 58:29.400]  Ну, номер. Я хотел написать...
[58:29.400 --> 58:30.400]  Номер чего?
[58:30.400 --> 58:38.400]  Номер локатора, чтобы мы бы много раз не делали допрос к системе, чтобы он выделал нам память.
[58:38.400 --> 58:45.400]  Так мы для этого и пишем локатор стейков для того, чтобы не обращаться к операционной системе и закутываться?
[58:45.400 --> 58:52.400]  Да, я переиспользую старый память, но, тем не менее, прошу я...
[58:52.400 --> 58:56.400]  Мне кажется, что то, как я прошу, я делаю не самым оптимальным.
[58:56.400 --> 58:58.400]  Не очень понимаю.
[58:58.400 --> 59:00.400]  В задаче говорят, сделайте пул стеков.
[59:00.400 --> 59:06.400]  Либо берите стек, который уже использовался, который больше не нужен, либо алоцируйте новое, если в пуле ноль стеков.
[59:06.400 --> 59:08.400]  Мне кажется, можно сделать оптимальный.
[59:08.400 --> 59:09.400]  А как?
[59:09.400 --> 59:11.400]  Что значит оптимальный?
[59:11.400 --> 59:15.400]  Это просто идея. Она может быть реализована оптимальной или неоптимальной.
[59:15.400 --> 59:19.400]  А сама идея пула, она не может быть более оптимальной.
[59:19.400 --> 59:21.400]  Это просто идея пула.
[59:21.400 --> 59:25.400]  Не очень понимаю, что ты имеешь в виду. Что значит неоптимально?
[59:25.400 --> 59:27.400]  Пул означает пулинг.
[59:27.400 --> 59:29.400]  Мы переиспользуем освобожденные объекты.
[59:29.400 --> 59:32.400]  Мы не создаем новое, мы переиспользуем.
[59:34.400 --> 59:38.400]  Ты имеешь в виду, допустим, сразу много выделить и потом кусочки почипывать?
[59:38.400 --> 59:39.400]  Ага.
[59:39.400 --> 59:41.400]  Или как бы другой локатор?
[59:44.400 --> 59:46.400]  Ну, можно такой сделать, никто не мешает.
[59:46.400 --> 59:49.400]  Еще раз, в локаторе стеков очень простой интерфейс.
[59:49.400 --> 59:51.400]  Нет.
[59:54.400 --> 59:56.400]  Ну, неважно, в смысле, ты можешь переписать весь код, который там написан.
[59:56.400 --> 59:58.400]  Это не проблема.
[59:58.400 --> 01:00:04.400]  Если ты говоришь, что тебе хочется вот так сделать, ну, я бы написал вообще вот так.
[01:00:04.400 --> 01:00:06.400]  Если по-хорошему делать.
[01:00:06.400 --> 01:00:10.400]  Почему мне такой локей нестек статик?
[01:00:12.400 --> 01:00:15.400]  Почему мне такой локей нестек статик?
[01:00:15.400 --> 01:00:18.400]  Я в шаблон смотрю, я просто локатор еще не написала.
[01:00:18.400 --> 01:00:20.400]  Ну, неприятно.
[01:00:23.400 --> 01:00:25.400]  Сейчас, можно я вернусь к этому?
[01:00:29.400 --> 01:00:32.400]  Вот, хороший локатор выглядит, конечно, так.
[01:00:36.400 --> 01:00:38.400]  То есть, нам просто отдают диапазон памяти.
[01:00:38.400 --> 01:00:40.400]  Нам не навязывают какую-то структуру.
[01:00:40.400 --> 01:00:42.400]  Просто говорят, что вот кусочек памяти.
[01:00:42.400 --> 01:00:44.400]  И там, не знаю, есть guard page.
[01:00:44.400 --> 01:00:46.400]  Нет guard page, а как ты это сделаешь?
[01:00:46.400 --> 01:00:49.400]  Ты можешь, я наконец понял, что ты имеешь в виду.
[01:00:49.400 --> 01:00:52.400]  Ты можешь аллоцировать через мэп большую арену.
[01:00:52.400 --> 01:00:54.400]  Нарезать ее на кусочки.
[01:00:54.400 --> 01:00:58.400]  Но это тебя спасет только для прогрева.
[01:01:02.400 --> 01:01:04.400]  Что ты, собственно, этим экономишь?
[01:01:04.400 --> 01:01:06.400]  Что ты не так уж сильно экономишь?
[01:01:06.400 --> 01:01:09.400]  Ну, ты вместо двух системных вызовов будешь делать 1nmprotect.
[01:01:09.400 --> 01:01:11.400]  Но это все равно сисколы.
[01:01:11.400 --> 01:01:13.400]  Это все равно очень дорого для старта файбера.
[01:01:13.400 --> 01:01:17.400]  Поэтому тут не сильно тебя это спасет, мне кажется.
[01:01:17.400 --> 01:01:21.400]  Теперь возвращаюсь к твоему вопросу, которого я не понял.
[01:01:21.400 --> 01:01:23.400]  На какой файл мне нужно посмотреть здесь?
[01:01:29.400 --> 01:01:31.400]  Да, вот я здесь.
[01:01:31.400 --> 01:01:33.400]  Тут нет статика.
[01:01:33.400 --> 01:01:35.400]  Ну, cpp.
[01:01:35.400 --> 01:01:37.400]  Так.
[01:01:37.400 --> 01:01:39.400]  Там должен быть.
[01:01:39.400 --> 01:01:41.400]  Так.
[01:01:41.400 --> 01:01:43.400]  Почему он статик?
[01:01:43.400 --> 01:01:45.400]  Какой выигрыш нам это дает?
[01:01:45.400 --> 01:01:47.400]  Это не то, что выигрыш дает.
[01:01:47.400 --> 01:01:49.400]  Это просто аккуратно написанный код.
[01:01:49.400 --> 01:01:52.400]  Функция allocate new stack зависит от состояния аллокатора?
[01:01:52.400 --> 01:01:54.400]  Нет.
[01:01:54.400 --> 01:01:56.400]  Вот, конец.
[01:01:58.400 --> 01:02:01.400]  А почему, например, allocate не статик?
[01:02:01.400 --> 01:02:03.400]  Потому что plus используется.
[01:02:03.400 --> 01:02:05.400]  Plus stack.
[01:02:05.400 --> 01:02:07.400]  Ну, вот и все.
[01:02:07.400 --> 01:02:09.400]  Ну, то есть это могла быть вообще свободная функция.
[01:02:09.400 --> 01:02:11.400]  Но она логически привязана к аллокатору,
[01:02:11.400 --> 01:02:13.400]  поэтому она метод аллокатора.
[01:02:13.400 --> 01:02:15.400]  Но она не использует состояние этого класса,
[01:02:15.400 --> 01:02:17.400]  поэтому она статическая.
[01:02:17.400 --> 01:02:19.400]  Ну, то есть для нее stack аллокатор — это некоторый склуб,
[01:02:19.400 --> 01:02:21.400]  в котором она имеет смысл.
[01:02:21.400 --> 01:02:23.400]  Но при этом она к состоянию не привязана, поэтому она статик.
[01:02:23.400 --> 01:02:25.400]  Но это просто быстро дает понять читателю,
[01:02:25.400 --> 01:02:27.400]  что это такая функция, которая не апеллирует состояние.
[01:02:31.400 --> 01:02:33.400]  Если убрать статик, то ничего, конечно, не сломается,
[01:02:33.400 --> 01:02:35.400]  но и код станет хуже при этом.
[01:02:35.400 --> 01:02:37.400]  Вот еще вопрос.
[01:02:37.400 --> 01:02:39.400]  Зачем мы используем
[01:02:39.400 --> 01:02:41.400]  именно коррутин импл,
[01:02:41.400 --> 01:02:43.400]  а не коррутину?
[01:02:43.400 --> 01:02:45.400]  То есть, ну, это скорее даже может
[01:02:45.400 --> 01:02:47.400]  к названию вопроса.
[01:02:47.400 --> 01:02:49.400]  Потому что такое ощущение,
[01:02:49.400 --> 01:02:51.400]  что как будто коррутин импл,
[01:02:51.400 --> 01:02:53.400]  она как бы не полная коррутина,
[01:02:53.400 --> 01:02:55.400]  какая-то часть.
[01:02:55.400 --> 01:02:57.400]  Ну, это деталь реализации, да.
[01:02:57.400 --> 01:02:59.400]  Да, ну, а почему мы
[01:02:59.400 --> 01:03:01.400]  можем использовать
[01:03:01.400 --> 01:03:03.400]  это коррутину импла?
[01:03:03.400 --> 01:03:05.400]  Ну, за тем, что мы здесь...
[01:03:05.400 --> 01:03:07.400]  А?
[01:03:07.400 --> 01:03:09.400]  То есть, на какой-то разум, то есть, часть
[01:03:09.400 --> 01:03:11.400]  сходится в реализацию, а не...
[01:03:11.400 --> 01:03:13.400]  Не то, что часть.
[01:03:13.400 --> 01:03:15.400]  Задача декопозируется на разные.
[01:03:15.400 --> 01:03:17.400]  Есть переключение контекста и коррутин импл
[01:03:17.400 --> 01:03:19.400]  при переключении контекста.
[01:03:19.400 --> 01:03:21.400]  Есть менеджмент ресурсов. Менеджмент ресурсов — это стэки.
[01:03:21.400 --> 01:03:23.400]  И вот мы одно с другим,
[01:03:23.400 --> 01:03:25.400]  одно другого отвязываем.
[01:03:25.400 --> 01:03:27.400]  Две разные подзадачи,
[01:03:27.400 --> 01:03:29.400]  они решаются двумя разными
[01:03:29.400 --> 01:03:31.400]  компонентами системы.
[01:03:31.400 --> 01:03:33.400]  Вот. Кроме того,
[01:03:33.400 --> 01:03:35.400]  если ты пишешь...
[01:03:35.400 --> 01:03:37.400]  Если ты
[01:03:37.400 --> 01:03:39.400]  пишешь файберы,
[01:03:39.400 --> 01:03:41.400]  то тебе, вероятно, нужно находить текущий файбер.
[01:03:41.400 --> 01:03:43.400]  Ну, тут два отличия.
[01:03:43.400 --> 01:03:45.400]  Почему коррут... Две причины,
[01:03:45.400 --> 01:03:47.400]  по которой этот класс существует такой,
[01:03:47.400 --> 01:03:49.400]  сам по себе. Во-первых,
[01:03:49.400 --> 01:03:51.400]  он не управляет памятью и не пытается
[01:03:51.400 --> 01:03:53.400]  понимать, откуда берутся стэки.
[01:03:53.400 --> 01:03:55.400]  А во-вторых, в нем есть менеджмент
[01:03:55.400 --> 01:03:57.400]  саспенд, который нестатический.
[01:03:57.400 --> 01:03:59.400]  Почему
[01:03:59.400 --> 01:04:01.400]  так сделано? Ну, потому что
[01:04:01.400 --> 01:04:03.400]  вот коррутине такой, разумно
[01:04:03.400 --> 01:04:05.400]  иметь статический метод.
[01:04:05.400 --> 01:04:07.400]  Ну, просто вот мы в коррутине, вот мы
[01:04:07.400 --> 01:04:09.400]  останавливаемся.
[01:04:09.400 --> 01:04:11.400]  Вот такой API, он
[01:04:11.400 --> 01:04:13.400]  менее безопасный,
[01:04:13.400 --> 01:04:15.400]  потому что нужно сначала коррутину найти,
[01:04:15.400 --> 01:04:17.400]  в смысле объект сам, и сделать на нем
[01:04:17.400 --> 01:04:19.400]  саспенд. И можно перепутать.
[01:04:19.400 --> 01:04:21.400]  То есть вызвать саспенд на другой коррутине.
[01:04:21.400 --> 01:04:23.400]  Со статиком
[01:04:23.400 --> 01:04:25.400]  ты всегда вызываешь саспенд
[01:04:25.400 --> 01:04:27.400]  на себе. Вот тогда тебе нужно себя
[01:04:27.400 --> 01:04:29.400]  найти, и у тебя появляется
[01:04:29.400 --> 01:04:31.400]  тридлокал в коррутине.
[01:04:31.400 --> 01:04:33.400]  Но файберу тоже нужен тридлокал, чтобы себя находить.
[01:04:33.400 --> 01:04:35.400]  И зачем тебе делать два тридлокала,
[01:04:35.400 --> 01:04:37.400]  когда тебе один не нужен?
[01:04:41.400 --> 01:04:43.400]  Да? Ну, у тебя же есть вот
[01:04:43.400 --> 01:04:45.400]  в файбере тридлокал-поинтер на себя.
[01:04:45.400 --> 01:04:47.400]  Вот. Тебе получается
[01:04:47.400 --> 01:04:49.400]  не нужен тридлокал, который будет в коррутине.
[01:04:49.400 --> 01:04:51.400]  Если он тебе не нужен, то
[01:04:51.400 --> 01:04:53.400]  было бы странно, если бы он в коде был.
[01:04:53.400 --> 01:04:55.400]  Вот ты по таким соображениям можешь сделать
[01:04:55.400 --> 01:04:57.400]  все аккуратнее. Такие тонкие, на самом деле, вещи.
[01:04:57.400 --> 01:04:59.400]  Тут
[01:04:59.400 --> 01:05:01.400]  я не то чтобы навязываю, я скорее
[01:05:01.400 --> 01:05:03.400]  объясняю логику, в которой
[01:05:03.400 --> 01:05:05.400]  в этом коде они разделены.
[01:05:05.400 --> 01:05:07.400]  То есть есть некоторые вещи, которые
[01:05:07.400 --> 01:05:09.400]  не всем нужны клиентам.
[01:05:09.400 --> 01:05:11.400]  То есть вот есть коррутина как базовый
[01:05:11.400 --> 01:05:13.400]  механизм, и с помощью нее можно делать разные
[01:05:13.400 --> 01:05:15.400]  вещи. И вот
[01:05:15.400 --> 01:05:17.400]  эти разные вещи могут
[01:05:17.400 --> 01:05:19.400]  менять детали
[01:05:19.400 --> 01:05:21.400]  в этой
[01:05:21.400 --> 01:05:23.400]  базовой коррутине некоторые.
[01:05:23.400 --> 01:05:25.400]  В импл осталось только то, что самое
[01:05:25.400 --> 01:05:27.400]  общее про переключение контекста
[01:05:27.400 --> 01:05:29.400]  и про ошибки.
[01:05:29.400 --> 01:05:31.400]  А файбером,
[01:05:31.400 --> 01:05:33.400]  процессором.
[01:05:33.400 --> 01:05:35.400]  А файбер и процессор могут какие-то части
[01:05:35.400 --> 01:05:37.400]  использовать или не использовать.
[01:05:37.400 --> 01:05:39.400]  Добавлять свое, не добавлять.
[01:05:39.400 --> 01:05:41.400]  Ну, короче.
[01:05:41.400 --> 01:05:43.400]  Это такой
[01:05:43.400 --> 01:05:45.400]  общий знаменатель.
[01:05:45.400 --> 01:05:47.400]  Наименьший общий предок
[01:05:47.400 --> 01:05:49.400]  всех реализаций.
[01:05:49.400 --> 01:05:51.400]  Дальше мы из него
[01:05:51.400 --> 01:05:53.400]  уже какие-то детали расти.
[01:05:55.400 --> 01:05:57.400]  Ну так, вот
[01:05:57.400 --> 01:05:59.400]  можно по-разному отнестись.
[01:05:59.400 --> 01:06:01.400]  Зачем нам два Go?
[01:06:01.400 --> 01:06:03.400]  Почему мы не могли сделать один?
[01:06:03.400 --> 01:06:05.400]  Какой?
[01:06:05.400 --> 01:06:07.400]  Я не знаю.
[01:06:07.400 --> 01:06:09.400]  Может это было как
[01:06:09.400 --> 01:06:11.400]  унтер сделать?
[01:06:11.400 --> 01:06:13.400]  Не понимаю. Какую проблему ты решаешь?
[01:06:13.400 --> 01:06:15.400]  Вот у тебя есть два
[01:06:15.400 --> 01:06:17.400]  вызова Go. Один запуск.
[01:06:17.400 --> 01:06:19.400]  Они по сути
[01:06:19.400 --> 01:06:21.400]  повышают ясность.
[01:06:21.400 --> 01:06:23.400]  Что значит повышают ясность?
[01:06:23.400 --> 01:06:25.400]  Не понимаю, что повышают ясность. Они просто
[01:06:25.400 --> 01:06:27.400]  для разных задач.
[01:06:27.400 --> 01:06:29.400]  Не имеют мыслы их пытаться
[01:06:29.400 --> 01:06:31.400]  сделать как один?
[01:06:31.400 --> 01:06:33.400]  Чем ты предлагаешь это заменить?
[01:06:33.400 --> 01:06:35.400]  Получилось бы
[01:06:35.400 --> 01:06:37.400]  через унтер сделать.
[01:06:37.400 --> 01:06:39.400]  Ты говоришь про реализацию.
[01:06:39.400 --> 01:06:41.400]  Проблема, которую
[01:06:41.400 --> 01:06:43.400]  ты хочешь решить.
[01:06:43.400 --> 01:06:45.400]  Какой код ты хочешь?
[01:06:45.400 --> 01:06:47.400]  Неважно, как они реализованы.
[01:06:47.400 --> 01:06:49.400]  Они реализованы одно через другое.
[01:06:49.400 --> 01:06:51.400]  Это же совершенно неважно.
[01:06:51.400 --> 01:06:53.400]  Что ты от API хочешь?
[01:06:53.400 --> 01:06:55.400]  Для меня это наоборот было.
[01:06:55.400 --> 01:06:57.400]  Нет, для меня проблема была.
[01:06:57.400 --> 01:06:59.400]  Потому что код мне не похож.
[01:06:59.400 --> 01:07:01.400]  Если ты дублируешь код, то не дублируй код.
[01:07:05.400 --> 01:07:07.400]  Когда ты дублируешь код,
[01:07:07.400 --> 01:07:09.400]  это не проблема API, скорее всего.
[01:07:09.400 --> 01:07:11.400]  Проблема твоей реализации.
[01:07:11.400 --> 01:07:13.400]  Точно.
[01:07:13.400 --> 01:07:15.400]  В жизни не нужно дублировать код.
[01:07:15.400 --> 01:07:17.400]  Если у тебя код дублируется, значит ты в нем не выделил
[01:07:17.400 --> 01:07:19.400]  нечто общее.
[01:07:19.400 --> 01:07:21.400]  Это конституция факта.
[01:07:21.400 --> 01:07:23.400]  Но ты как будто говоришь про API.
[01:07:23.400 --> 01:07:25.400]  Реализация API это совершенно разные вещи.
[01:07:25.400 --> 01:07:27.400]  Я не знаю.
[01:07:27.400 --> 01:07:29.400]  Я посмотрю и момент,
[01:07:29.400 --> 01:07:31.400]  где меня смущает.
[01:07:31.400 --> 01:07:33.400]  Просто внутри смущает.
[01:07:33.400 --> 01:07:35.400]  Есть же у класса
[01:07:35.400 --> 01:07:37.400]  два конструктора.
[01:07:37.400 --> 01:07:39.400]  Не, я не сполню.
[01:07:39.400 --> 01:07:41.400]  Да при чем здесь перегрузка?
[01:07:41.400 --> 01:07:42.640] cessib Merge уже всеvetna и
[01:07:44.320 --> 01:07:49.440]  reviewing
[01:07:49.440 --> 01:07:52.820]  the
[01:07:52.820 --> 01:07:54.600]  Ну то есть как я могу запустить
[01:07:54.600 --> 01:07:56.600]  файбер в « reproduceEE ».
[01:07:56.600 --> 01:08:00.600]  Их мы не совмещаем.
[01:08:00.600 --> 01:08:02.600]  Они выполняют одну задачу,
[01:08:02.600 --> 01:08:04.600]  они параметризуются.
[01:08:04.600 --> 01:08:06.600]  Они запускают новый файбер,
[01:08:06.600 --> 01:08:08.600]  За Wheat Cosmeticswny
[01:08:08.600 --> 01:08:10.600]  запускают файбер
[01:08:10.600 --> 01:08:15.280]  более тонко настроить запуск, в каком именно планировщике. Другой использует текущий дефолт.
[01:08:21.280 --> 01:08:27.960]  То есть можно было назвать по-разному, я не знаю, как бы можно было их назвать иначе.
[01:08:27.960 --> 01:08:33.000]  Но мне кажется, что они нормально одинаково называются, и реализация одна через другую выражается, так что...
[01:08:36.240 --> 01:08:38.240]  Кажется, проблемы нет.
[01:08:41.600 --> 01:08:45.600]  Еще что-нибудь?
[01:08:48.600 --> 01:08:50.600]  А может, вы спросите что-нибудь?
[01:08:50.600 --> 01:08:52.600]  Я что-нибудь могу спросить?
[01:08:52.600 --> 01:08:53.600]  Да.
[01:08:53.600 --> 01:08:55.600]  О чем угодно?
[01:08:55.600 --> 01:09:03.600]  Вы, если спросите о чем угодно в курсе, то я точно не отвечу, хотя бы по крестности наших обсуждений.
[01:09:03.600 --> 01:09:08.600]  Какое-то хорошее вопросное понимание, чтобы мы упоминали, что мы не понимали.
[01:09:08.600 --> 01:09:14.600]  А мне кажется, не знаю, мне кажется, что мы уже все, что мне было важно, обсудили.
[01:09:16.600 --> 01:09:17.600]  Сейчас подумаю.
[01:09:17.600 --> 01:09:21.600]  Ну, есть еще вот этот субмит мутный и вот вся эта интрузивность.
[01:09:21.600 --> 01:09:23.600]  Я поняла, что хотел спросить.
[01:09:23.600 --> 01:09:26.600]  Вот, но я все равно бы не ответил.
[01:09:26.600 --> 01:09:30.600]  Точнее, такое место, которое можно будет...
[01:09:30.600 --> 01:09:35.600]  Мы будем решать задача, и вот в субботу у нас будут Future Executers.
[01:09:35.600 --> 01:09:42.600]  И там мы еще немного дизайн улучшим, еще там немного что-то декомпозируем.
[01:09:42.600 --> 01:09:48.600]  И задачи можно будет решать, там их написать, а потом можно будет во всех задачах что-то разом исправить,
[01:09:48.600 --> 01:09:51.600]  и везде все продолжит работать, просто будет намного лучше.
[01:09:51.600 --> 01:09:59.600]  Вот этот субмит, и он в будущем там переименуется во что-то другое, это как раз такой задел на будущее.
[01:09:59.600 --> 01:10:06.600]  Но мне хочется, чтобы когда он возник, он возник не потому, что я его навязал.
[01:10:06.600 --> 01:10:08.600]  То есть делайте интрузивность.
[01:10:08.600 --> 01:10:10.600]  Пока вам это не нужно, не делайте интрузивность.
[01:10:10.600 --> 01:10:15.600]  Когда вы поймете, что вы делаете лишнего, когда вы поймете, что у вас какие-то лишние аллокации ненужные происходят,
[01:10:15.600 --> 01:10:23.600]  то, ну, в принципе, с делом Fiber вы могли бы это уже понять, что планировщик поток, планировщик задач,
[01:10:23.600 --> 01:10:28.600]  Тредпул делает немного лишнюю работу в смысле аллокации, когда вы запускаете в нем Fiber.
[01:10:28.600 --> 01:10:31.600]  Вот если вы это чувствуете, то вы можете в эту сторону думать.
[01:10:31.600 --> 01:10:37.600]  А если не чувствуете, то, наверное, пока не обязательно.
[01:10:37.600 --> 01:10:39.600]  Сколько у нас времени осталось?
[01:10:39.600 --> 01:10:40.600]  Три минуты.
[01:10:40.600 --> 01:10:41.600]  Три минуты.
[01:10:41.600 --> 01:10:42.600]  Три минуты.
[01:10:42.600 --> 01:10:43.600]  Три минуты.
[01:10:43.600 --> 01:10:44.600]  Ну, вопрос, наверное, не хватит тоже.
[01:10:44.600 --> 01:10:45.600]  Можно спросить.
[01:10:45.600 --> 01:10:46.600]  Да.
[01:10:46.600 --> 01:10:48.600]  Ну, в описании задачки была.
[01:10:48.600 --> 01:10:49.600]  Какой?
[01:10:49.600 --> 01:10:53.600]  Позвольте заменить Тредпул в Карен, на локальное монополие просто.
[01:10:53.600 --> 01:10:54.600]  Да.
[01:10:54.600 --> 01:10:55.600]  У вас чем это связано?
[01:10:55.600 --> 01:10:57.600]  Ну, суббот, наверное, увидим.
[01:10:58.600 --> 01:11:01.600]  То есть после суббота я смогу объяснить.
[01:11:01.600 --> 01:11:06.600]  Потому что мы хотим абстрагировать понятие планировщика.
[01:11:06.600 --> 01:11:09.600]  Ну, вот сейчас у нас есть конкретно Тредпул.
[01:11:09.600 --> 01:11:11.600]  Вот он прям зашит в API.
[01:11:11.600 --> 01:11:14.600]  Мы приходим сюда и...
[01:11:14.600 --> 01:11:15.600]  Сейчас, где мы?
[01:11:15.600 --> 01:11:17.600]  Вот сюда.
[01:11:17.600 --> 01:11:20.600]  И написано, планировщик – это Тредпул.
[01:11:20.600 --> 01:11:23.600]  Но, с другой стороны, что мы знаем про этот Тредпул?
[01:11:23.600 --> 01:11:24.600]  Мы...
[01:11:24.600 --> 01:11:26.600]  Что Fiber'ом нужно от него?
[01:11:26.600 --> 01:11:29.600]  А от него Fiber'ом нужен только один метод SubmitTask.
[01:11:29.600 --> 01:11:34.600]  То есть задача, запланированная в Тредпул, рано или поздно где-то там будет выполнена.
[01:11:35.600 --> 01:11:39.600]  Ну, вот можно здесь от знания конкретно про Тредпул избавиться
[01:11:39.600 --> 01:11:41.600]  и получить некоторые приятные бонусы.
[01:11:43.600 --> 01:11:45.600]  Вот заменив этот Тредпул абстракцией.
[01:11:45.600 --> 01:11:50.600]  И вот тогда уже не получится просто найти текущую реализацию планировщика,
[01:11:50.600 --> 01:11:51.600]  потому что...
[01:11:51.600 --> 01:11:54.600]  Ну, забегая вперед, это может быть декоратор несомостоятельной Тредпулы,
[01:11:54.600 --> 01:11:57.600]  и там уже никакого Тредлокала разумного не напишешь.
[01:11:57.600 --> 01:12:00.600]  Так что давай я все-таки...
[01:12:00.600 --> 01:12:04.600]  Ну, я смогу через неделю это объяснить, зачем это будет нужно.
[01:12:04.600 --> 01:12:06.600]  Может быть на лекции, но на лекции скорее всего времени не хватит.
[01:12:06.600 --> 01:12:07.600]  Да, у меня большая просьба.
[01:12:07.600 --> 01:12:10.600]  На лекции, мне кажется, я могу очень много рассказать.
[01:12:12.600 --> 01:12:13.600]  Прям хорошие лекции.
[01:12:13.600 --> 01:12:17.600]  Вот я вчера читал и не успел все, и время переполнил.
[01:12:17.600 --> 01:12:21.600]  С вами постараюсь побыстрее, чуть-чуть оптимизировать.
[01:12:22.600 --> 01:12:24.600]  Мне кажется, что очень клевая лекция.
[01:12:24.600 --> 01:12:28.600]  Она мне очень нравится, и она должна многие вещи связать с новым.
[01:12:28.600 --> 01:12:31.600]  Ну, то есть это не то, что там какой-то баловствок модыри памяти.
[01:12:31.600 --> 01:12:34.600]  Вот отдельный топик, который можно в любой момент послушать.
[01:12:34.600 --> 01:12:39.600]  Вот кажется, что следующая лекция, она вот в эту картинку добавит еще такое большое измерение,
[01:12:39.600 --> 01:12:42.600]  которое будет при этом сочетаться со всем текущим.
[01:12:42.600 --> 01:12:46.600]  И мне хочется, чтобы вы пришли и осознали все это.
[01:12:46.600 --> 01:12:48.600]  Это важно.
[01:12:48.600 --> 01:12:54.600]  То есть там разные лог-фри, устройства планировщиков, там все какие-то реализации корутин, потоков.
[01:12:54.600 --> 01:12:56.600]  Это вы все можете в жизни не увидеть.
[01:12:56.600 --> 01:13:01.600]  То, что будет на следующей лекции фьюча, это то, что, вероятно, то, с чем вы будете работать,
[01:13:01.600 --> 01:13:04.600]  скорее всего, в любом языке программирования.
[01:13:04.600 --> 01:13:10.600]  Джаваскрипта и раз-то совершенно неважно, чем вы будете заниматься, и там, и там это будет.
[01:13:10.600 --> 01:13:14.600]  Ну, и я там еще наверну дизайна немножко.
[01:13:14.600 --> 01:13:17.600]  Так что призываю вас прийти.
[01:13:17.600 --> 01:13:20.600]  И через неделю у нас будет гораздо больше поводов поговорить.
[01:13:20.600 --> 01:13:27.600]  А еще я думаю, что в субботу появится новая задачка, которая сейчас у меня приватно валится.
[01:13:27.600 --> 01:13:32.600]  Я ее даже сегодня уже, наверное, выложу в репозиторию ее,
[01:13:32.600 --> 01:13:38.600]  где мы будем делать фьютекс и всякие приметивы синхронизации.
[01:13:38.600 --> 01:13:41.600]  Там много изменений по сравнению с текущей версией.
[01:13:42.600 --> 01:13:47.600]  Я имею в виду собственный фьютекс, который нам понадобится.
[01:13:47.600 --> 01:13:52.600]  Мы искореняем магию.
[01:13:52.600 --> 01:13:54.600]  Можно я еще минутку потрачу? Простите.
[01:13:54.600 --> 01:13:56.600]  Мы искореняем в курсе магию.
[01:13:56.600 --> 01:14:00.600]  Мы фьютексом пользуемся, и фьютекс потом напишем.
[01:14:00.600 --> 01:14:05.600]  Ну, сейчас напишем, в смысле, чтобы не было какой-то странной...
[01:14:05.600 --> 01:14:08.600]  Чтобы искоренить вот наше магическое мышление,
[01:14:08.600 --> 01:14:12.600]  что фьютекс как-то там что-то проверяет, какие-то очереди ставит.
[01:14:12.600 --> 01:14:14.600]  Вот напишем и увидим, что это.
[01:14:14.600 --> 01:14:17.600]  Абсолютно честно получится.
[01:14:17.600 --> 01:14:22.600]  В курсе, наверное, в этом году это уже не улучшить, а в следующем году точно улучшается.
[01:14:22.600 --> 01:14:27.600]  Вот можно как раз и в задачу про Slip4 вставить не ASIO готовый и сложный,
[01:14:27.600 --> 01:14:33.600]  а свою собственную реализацию поверх, ну, не знаю, или E-Polo, или Event Loop.
[01:14:33.600 --> 01:14:36.600]  Тогда вот все, что я говорил, можно будет в коде прочесть,
[01:14:36.600 --> 01:14:39.600]  потому что ASIO слишком сложно, чтобы его читать.
[01:14:39.600 --> 01:14:41.600]  Хедерон или библиотека.
[01:14:41.600 --> 01:14:48.600]  Ну, в общем, все остальное, что у нас есть, мы напишем своими руками.
[01:14:48.600 --> 01:14:52.600]  А ASIO, ну, я вот надеюсь, что вы их и себе написали на E-Polo в своей жизни.
[01:14:52.600 --> 01:14:55.600]  И вот, возможно, не стоит на это рассчитывать больше.
[01:14:58.600 --> 01:15:01.600]  Ладно, давайте тогда через неделю встретимся и продолжим.
[01:15:06.600 --> 01:15:08.600]  Ну что, начнем?
[01:15:11.600 --> 01:15:14.600]  Итак, о чем мы сегодня поговорим, зависит, наверное, от вас,
[01:15:14.600 --> 01:15:19.600]  потому что на прошлой паре я рассказывал про ASIO,
[01:15:19.600 --> 01:15:24.600]  про то, как правильно думать о том, что происходит в ее контексте,
[01:15:24.600 --> 01:15:28.600]  про то, как писать Event Loop, про то, как пользоваться ими.
[01:15:28.600 --> 01:15:35.600]  И мне интересно, наверное, узнать, как вы пользовались сами в своей жизни Event Loop,
[01:15:35.600 --> 01:15:42.600]  в смысле, как вы писали какой-нибудь код на E-Polo в ваше предшествующее семястро обучение,
[01:15:42.600 --> 01:15:45.600]  и насколько вообще нужно подробно про это говорить.
[01:15:45.600 --> 01:15:52.600]  Потому что кажется, что в прошлой группе студентами многие писали какие-то очень странные решения,
[01:15:52.600 --> 01:15:54.600]  ну, в смысле, эхо север, скажем, на E-Polo.
[01:15:54.600 --> 01:15:56.600]  Точно неразумный код.
[01:15:56.600 --> 01:15:58.600]  Не писали?
[01:15:58.600 --> 01:16:00.600]  Не писали.
[01:16:00.600 --> 01:16:03.600]  Ну, давайте тогда начнем с чего-то простого,
[01:16:03.600 --> 01:16:08.600]  а потом по пути выясним, что вы писали, что-то разумное или нет.
[01:16:08.600 --> 01:16:10.600]  Я надеюсь, что что-то разумное.
[01:16:10.600 --> 01:16:15.600]  Итак, у нас задача сделать FiberSleep4,
[01:16:15.600 --> 01:16:19.600]  ну, в широком смысле научить Fiber взаимодействовать с внешним миром.
[01:16:19.600 --> 01:16:22.600]  Время, там, сети, это все проявление какого-то внешнего мира.
[01:16:22.600 --> 01:16:25.600]  И поэтому мы в качестве планировщика Fiber'ов
[01:16:25.600 --> 01:16:33.600]  используем некоторый Event Loop, который в данном случае представлен в виде ее контекста в библиотеке ASIO.
[01:16:33.600 --> 01:16:39.600]  И для того, чтобы разобраться, как ваши Fiber интегрируются в этот самый его контекст,
[01:16:39.600 --> 01:16:42.600]  нужно разобраться вообще, наверное, что это такое.
[01:16:42.600 --> 01:16:44.600]  Вот как, скажем, такой пример работает.
[01:16:44.600 --> 01:16:47.600]  Ну, или как работает тот пример, который был на лекции,
[01:16:47.600 --> 01:16:51.600]  где мы писали эхо-север.
[01:16:51.600 --> 01:16:55.600]  Ну, точнее, не писали, мы разбирали написано эхо-север.
[01:16:55.600 --> 01:17:01.600]  И, ну, это какая-то библиотека, там есть какие-то классы, как-то распределены обязанности,
[01:17:01.600 --> 01:17:07.600]  но, в конце концов, под капотом работает цикл Яполы.
[01:17:07.600 --> 01:17:14.600]  Ну, и давайте вспомним, как вы начинали писать, как вы писали эхо-север, с чего вы начинали там работу.
[01:17:14.600 --> 01:17:17.600]  Видимо, вы конституировали сервер на эхо-севере,
[01:17:18.600 --> 01:17:25.600]  вот, вам нужен серверный сокет, вы его строите, вы его привязываете к какому-то порту,
[01:17:25.600 --> 01:17:28.600]  вы начинаете слушать клиентов, тут все это пропущено.
[01:17:28.600 --> 01:17:31.600]  Ну вот, это первое, что вы делаете.
[01:17:31.600 --> 01:17:38.600]  А дальше вы, видимо, регистируете этот серверный сокет в очереди событий операционной системы в Яполе,
[01:17:38.600 --> 01:17:43.600]  и дальше, видимо, ждете, что в этом Яполе появляются события о том, что сокет готов к чтению,
[01:17:43.600 --> 01:17:45.600]  то есть из него можно понимать клиента.
[01:17:45.600 --> 01:17:47.600]  Вот, как это выглядит на ASIO?
[01:17:47.600 --> 01:17:49.600]  Ну вот, у вас есть EO-контекст.
[01:17:49.600 --> 01:17:53.600]  EO-контекст – это класс, в котором разные вещи, на самом деле, происходят,
[01:17:53.600 --> 01:17:58.600]  но Япол, в конце концов, ну то есть дескриптер Япола, находится внутри.
[01:17:58.600 --> 01:18:05.600]  Вот этот объект представляет собой очередь событий на таймерах, на сокетах.
[01:18:05.600 --> 01:18:07.600]  Дальше, что происходит с этим кодом?
[01:18:07.600 --> 01:18:09.600]  Мы здесь конструируем объект сервера.
[01:18:09.600 --> 01:18:11.600]  Мы конструируем аксептора,
[01:18:11.600 --> 01:18:14.600]  передаем туда EO-контекст и
[01:18:14.600 --> 01:18:17.600]  передаем туда порт, на котором мы собираемся слушать.
[01:18:17.600 --> 01:18:20.600]  Ну вот, внутри этого аксептора конструируется серверный сокет,
[01:18:20.600 --> 01:18:24.600]  который привязывается к порту и вызывает лист.
[01:18:24.600 --> 01:18:28.600]  А дальше мы в конструкторе вызываем doAccept.
[01:18:28.600 --> 01:18:30.600]  Что делает doAccept?
[01:18:30.600 --> 01:18:33.600]  Ну вот, в конструкторе мы вызываем код.
[01:18:34.600 --> 01:18:37.600]  А дальше мы в конструкторе вызываем doAccept.
[01:18:37.600 --> 01:18:39.600]  Что делает doAccept?
[01:18:39.600 --> 01:18:42.600]  На аксепторе вызывает asyncAccept,
[01:18:42.600 --> 01:18:44.600]  передает туда обработчик.
[01:18:46.600 --> 01:18:49.600]  Что происходит вовсе?
[01:18:49.600 --> 01:18:51.600]  Сама себя вызывает в конце.
[01:18:51.600 --> 01:18:54.600]  Сама себя вызывает в конце, да.
[01:18:56.600 --> 01:18:59.600]  Но это же не рекурсия, это event loop.
[01:18:59.600 --> 01:19:01.600]  Это callback и event loop.
[01:19:01.600 --> 01:19:03.600]  Ну сейчас, по очереди.
[01:19:03.600 --> 01:19:06.600]  Вот, в конструкторе мы вызываем doAccept,
[01:19:06.600 --> 01:19:09.600]  в doAccept мы вызываем asyncAccept.
[01:19:09.600 --> 01:19:13.600]  Что происходит, когда мы это делаем?
[01:19:14.600 --> 01:19:17.600]  Вот где этот код написан здесь?
[01:19:21.600 --> 01:19:24.600]  Ну, давайте перейдем к началу.
[01:19:24.600 --> 01:19:26.600]  То есть, раз мы перейдем к чему-нибудь,
[01:19:27.600 --> 01:19:30.600]  в этот фор даже их вытягиваем.
[01:19:32.600 --> 01:19:34.600]  Фор?
[01:19:34.600 --> 01:19:36.600]  Так, какое-то фундаментальное непонимание происходит.
[01:19:36.600 --> 01:19:38.600]  Вот этот фор — это и есть цикл работы, да.
[01:19:38.600 --> 01:19:41.600]  Там мы опрашиваем
[01:19:41.600 --> 01:19:44.600]  епол на предмет готовых,
[01:19:44.600 --> 01:19:47.600]  на предмет событий каких-то и там обслуживаем.
[01:19:47.600 --> 01:19:50.600]  Но в этом коде вот этот код.
[01:19:50.600 --> 01:19:52.600]  Вот здесь мы крутимся,
[01:19:52.600 --> 01:19:55.600]  на еполе достаем вот это событие
[01:19:55.600 --> 01:19:58.600]  и обслуживаем их.
[01:19:58.600 --> 01:20:01.600]  А что же мы делаем здесь тогда?
[01:20:06.600 --> 01:20:08.600]  Наверное, мы задаем...
[01:20:08.600 --> 01:20:10.600]  Что значит асинхронная операция accept?
[01:20:10.600 --> 01:20:13.600]  Ты себе представляешь реализацию асинхронного accept?
[01:20:13.600 --> 01:20:15.600]  Ты можешь вызвать синхронный accept,
[01:20:15.600 --> 01:20:18.600]  просто вызвать сисковый accept и заблокироваться
[01:20:18.600 --> 01:20:21.600]  до тех пор, пока на серверном сокете не появится клиент.
[01:20:21.600 --> 01:20:24.600]  А у нас здесь асинхронный accept.
[01:20:24.600 --> 01:20:26.600]  Что же он должен делать, если мы говорим...
[01:20:26.600 --> 01:20:29.600]  Если мы говорим про асинхронную версию?
[01:20:29.600 --> 01:20:31.600]  В общем, как-то думал...
[01:20:31.600 --> 01:20:32.600]  Как-то?
[01:20:32.600 --> 01:20:35.600]  ...давать заявку на accept и возвращать...
[01:20:35.600 --> 01:20:36.600]  Что значит заявка?
[01:20:36.600 --> 01:20:38.600]  Ну, как-то...
[01:20:38.600 --> 01:20:42.600]  Мы говорим про код на C или C++.
[01:20:42.600 --> 01:20:45.600]  Тут все очень конкретно.
[01:20:50.600 --> 01:20:52.600]  Просто что тогда асинхронная операция?
[01:20:52.600 --> 01:20:54.600]  Получается, мы не понимаем, что это.
[01:21:01.600 --> 01:21:03.600]  Здесь не запускается обработчик.
[01:21:03.600 --> 01:21:05.600]  Здесь стартует синхронная операция.
[01:21:15.600 --> 01:21:18.600]  Что делает асинхронный accept?
[01:21:18.600 --> 01:21:21.600]  Он регистрирует серверный socket в Epoly
[01:21:21.600 --> 01:21:27.600]  и говорит, что мы ждем на этом сокете чтений.
[01:21:33.600 --> 01:21:35.600]  Вот это есть асинхронная операция accept.
[01:21:35.600 --> 01:21:36.600]  Она пока ничего не делает.
[01:21:36.600 --> 01:21:38.600]  Мы просто подписываемся на событие,
[01:21:38.600 --> 01:21:40.600]  что socket готов к чтению.
[01:21:40.600 --> 01:21:42.600]  То есть на нем появился клиент.
[01:21:43.600 --> 01:21:44.600]  Вот.
[01:21:50.600 --> 01:21:52.600]  Так вот же.
[01:21:54.600 --> 01:21:55.600]  Еще раз, мы здесь работаем с Epoly.
[01:21:55.600 --> 01:21:58.600]  Мы сейчас, кажется, не перестали понимать, что такое Epoly даже.
[01:21:58.600 --> 01:22:00.600]  Epoly — очередь событий.
[01:22:00.600 --> 01:22:03.600]  Мы в ней можем зарегистрировать какой-то файловый дескриптор
[01:22:03.600 --> 01:22:05.600]  и дождаться, пока событие реализуется,
[01:22:05.600 --> 01:22:06.600]  потом его достать,
[01:22:06.600 --> 01:22:08.600]  когда оно реализуется и обработать.
[01:22:08.600 --> 01:22:11.600]  Вот, видимо, зарегистрировать дескриптор
[01:22:11.600 --> 01:22:13.600]  здесь асинхронную операцию,
[01:22:13.600 --> 01:22:17.600]  а достать и обработать — это вызвать callback, в том числе.
[01:22:19.600 --> 01:22:21.600]  Ну а listen — это просто,
[01:22:21.600 --> 01:22:23.600]  то есть просто listen.
[01:22:23.600 --> 01:22:26.600]  Мы переводим socket в слушающий режим.
[01:22:28.600 --> 01:22:29.600]  Это же не асинхронный.
[01:22:29.600 --> 01:22:31.600]  То есть она не блокирующая и так.
[01:22:31.600 --> 01:22:33.600]  Тут нечего делать асинхронным.
[01:22:33.600 --> 01:22:35.600]  У нас есть синхронная API,
[01:22:35.600 --> 01:22:36.600]  когда мы блокируем поток.
[01:22:36.600 --> 01:22:38.600]  У нас есть асинхронная API.
[01:22:38.600 --> 01:22:40.600]  И мы отказываемся от синхронного API,
[01:22:40.600 --> 01:22:41.600]  кстати, мы заводим много блоков,
[01:22:41.600 --> 01:22:42.600]  мы пользуемся асинхронным,
[01:22:42.600 --> 01:22:44.600]  теперь нужно понять, что оно из себя представляет.
[01:22:44.600 --> 01:22:47.600]  Ну вот, это, видимо, старт асинхронной операции.
[01:22:49.600 --> 01:22:51.600]  А это — ее обработка.
[01:22:53.600 --> 01:22:55.600]  Ну то есть вот мы вызвали это токсинка accept,
[01:22:55.600 --> 01:22:59.600]  мы зарегистрировали socket серверный
[01:22:59.600 --> 01:23:03.600]  в Яполе в очереди событий,
[01:23:03.600 --> 01:23:05.600]  и все, вызов завершился.
[01:23:06.600 --> 01:23:08.600]  Нам больше ничего уже не делал.
[01:23:09.600 --> 01:23:11.600]  И вот вместе с этим завершился конструктор,
[01:23:12.600 --> 01:23:14.600]  и вот мы перешли дальше к этой строчке.
[01:23:14.600 --> 01:23:17.600]  В этой строчке мы вызываем его context-run,
[01:23:17.600 --> 01:23:20.600]  и, видимо, в цикле мы достаем
[01:23:20.600 --> 01:23:26.600]  из Яполвейта готовые события и обслуживания.
[01:23:27.600 --> 01:23:29.600]  Ну, пока мы сделали только простое действие,
[01:23:29.600 --> 01:23:31.600]  мы зарегистрировали обработчик,
[01:23:31.600 --> 01:23:35.600]  подписались на события на серверном сокете.
[01:23:35.600 --> 01:23:37.600]  Так что здесь мы блокируемся до тех пор,
[01:23:37.600 --> 01:23:39.600]  пока этот серверный socket не станет читаемым,
[01:23:39.600 --> 01:23:41.600]  то есть на нем не появится первый клиент.
[01:23:46.600 --> 01:23:49.600]  Ну, смотри, тут это можно реализовать по-разному.
[01:23:50.600 --> 01:23:52.600]  Пока можно мыслить, что оно одноразовое,
[01:23:52.600 --> 01:23:54.600]  но потому что callback вызовется один раз.
[01:23:57.600 --> 01:23:59.600]  Вот на этом уровне оно одноразовое.
[01:24:01.600 --> 01:24:03.600]  Дальше мы вызываем его context-run,
[01:24:03.600 --> 01:24:05.600]  и происходит какое-то событие.
[01:24:06.600 --> 01:24:09.600]  В смысле, когда-то происходит событие,
[01:24:09.600 --> 01:24:12.600]  что серверный socket готов к чтению,
[01:24:12.600 --> 01:24:15.600]  и тогда, ну вот, в этом примере,
[01:24:15.600 --> 01:24:17.600]  какой код вызывается?
[01:24:21.600 --> 01:24:23.600]  Мы вызываем теперь accept на этом серверном сокете,
[01:24:23.600 --> 01:24:26.600]  потому что теперь он завершится без ожидания.
[01:24:26.600 --> 01:24:27.600]  Мы в этом уверены.
[01:24:27.600 --> 01:24:30.600]  Мы получаем socket клиента,
[01:24:30.600 --> 01:24:32.600]  переводим его в не блокирующий режим.
[01:24:33.600 --> 01:24:36.600]  Тут сразу еще и в Epole его добавляем,
[01:24:36.600 --> 01:24:39.600]  но вот ASIO делает только кусочек этой работы здесь.
[01:24:43.600 --> 01:24:48.600]  То есть, когда вот в этом вызове run socket готов к чтению,
[01:24:48.600 --> 01:24:52.600]  ASIO из него, на нем делает accept,
[01:24:52.600 --> 01:24:54.600]  получает серверный socket,
[01:24:54.600 --> 01:24:56.600]  и после этого вызывает наш обработчик.
[01:24:56.600 --> 01:24:58.600]  Просто по семантике в async-accept
[01:24:58.600 --> 01:24:59.600]  обработчик вызовется,
[01:24:59.600 --> 01:25:04.600]  когда ASIO в этот объект socket уже заполнило
[01:25:04.600 --> 01:25:06.600]  содержимым клиентским сокетом,
[01:25:06.600 --> 01:25:08.600]  дескриптором клиентского сокета.
[01:25:09.600 --> 01:25:11.600]  А дальше что мы делаем в этом обработчике,
[01:25:11.600 --> 01:25:12.600]  который мы запустили?
[01:25:12.600 --> 01:25:17.600]  То есть мы, по сути, вот в это место event-loop
[01:25:17.600 --> 01:25:18.600]  поместили свой код.
[01:25:20.600 --> 01:25:22.600]  Это обработчик, который мы запустили,
[01:25:22.600 --> 01:25:24.600]  и дальше мы в этом обработчике что сделали?
[01:25:24.600 --> 01:25:27.600]  Ну, во-первых, мы стартовали обработку
[01:25:27.600 --> 01:25:28.600]  соединения клиента,
[01:25:28.600 --> 01:25:30.600]  а во-вторых, мы вызвали do accept еще раз.
[01:25:32.600 --> 01:25:34.600]  То есть мы вызвали accept, async-accept,
[01:25:34.600 --> 01:25:36.600]  то есть мы снова подписались
[01:25:36.600 --> 01:25:39.600]  на событие серверный socket
[01:25:39.600 --> 01:25:41.600]  доступен для чтения,
[01:25:41.600 --> 01:25:43.600]  то есть для не блокирующего accept.
[01:25:44.600 --> 01:25:48.600]  Вот. Ну, и это все, что мы делали в этом обработчике.
[01:25:48.600 --> 01:25:50.600]  То есть для не блокирующего accept.
[01:25:51.600 --> 01:25:54.600]  Вот. Ну, и это ни в коем случае не рекурсивная функция,
[01:25:54.600 --> 01:25:56.600]  потому что вот тело функции do accept
[01:25:56.600 --> 01:25:58.600]  это просто async-accept.
[01:25:58.600 --> 01:26:00.600]  И вот на одной итерации
[01:26:00.600 --> 01:26:02.600]  будет вызван этот код,
[01:26:02.600 --> 01:26:05.600]  а на другой итерации будет вызван вот этот код.
[01:26:08.600 --> 01:26:10.600]  И вот так вот задачки они бегут
[01:26:10.600 --> 01:26:12.600]  и там пинают друг друга,
[01:26:12.600 --> 01:26:13.600]  порождают новые задачи.
[01:26:14.600 --> 01:26:16.600]  Ну, помимо того, что мы
[01:26:16.600 --> 01:26:18.600]  сконструировали,
[01:26:18.600 --> 01:26:21.600]  помимо того, что мы повторно запланировали accept на socket,
[01:26:21.600 --> 01:26:24.600]  мы еще сделали вот этот session,
[01:26:24.600 --> 01:26:26.600]  make shared session, start.
[01:26:28.600 --> 01:26:30.600]  Этот объект session, он представляет из себя
[01:26:30.600 --> 01:26:33.600]  обработчик соединения клиента.
[01:26:34.600 --> 01:26:37.600]  И мы, получая socket,
[01:26:37.600 --> 01:26:40.600]  вызываем на этом объекте start,
[01:26:40.600 --> 01:26:42.600]  в нем вызываем do read,
[01:26:42.600 --> 01:26:44.600]  а в этом do read
[01:26:44.600 --> 01:26:47.600]  мы стартуем socket, async, read sum операцию.
[01:26:49.600 --> 01:26:51.600]  Ну, то есть мы вот теперь мы
[01:26:51.600 --> 01:26:55.600]  положили в E-Poll socket клиента
[01:26:55.600 --> 01:26:57.600]  и ожидаем на нем чтения.
[01:26:57.600 --> 01:27:00.600]  То есть мы в обработчике async-accept
[01:27:00.600 --> 01:27:03.600]  вызвали этот start, в нем вызвали do read,
[01:27:03.600 --> 01:27:06.600]  а в нем вызвали socket, async, read sum,
[01:27:06.600 --> 01:27:09.600]  а в нем, по сути, произошел вот этот вот код.
[01:27:10.600 --> 01:27:11.600]  Так?
[01:27:12.600 --> 01:27:15.600]  И после этого do read завершился,
[01:27:15.600 --> 01:27:17.600]  start завершился.
[01:27:19.600 --> 01:27:22.600]  И теперь у нас, получается, в E-Poll
[01:27:22.600 --> 01:27:25.600]  лежит два файловых дескриптора.
[01:27:25.600 --> 01:27:28.600]  Один мы положили вот здесь вот
[01:27:28.600 --> 01:27:30.600]  и ждем события на socket.
[01:27:30.600 --> 01:27:33.600]  Ждем готовности к чтению socket клиентского.
[01:27:33.600 --> 01:27:36.600]  И вот здесь мы второй раз
[01:27:36.600 --> 01:27:39.600]  положили в E-Poll socket серверный.
[01:27:39.600 --> 01:27:41.600]  И дальше мы снова переходим.
[01:27:41.600 --> 01:27:43.600]  Итерация заканчивается, то есть обработчик
[01:27:43.600 --> 01:27:48.600]  завершился, итерация event loop заканчивается.
[01:27:48.600 --> 01:27:50.600]  И мы снова вызываем E-Poll wait
[01:27:50.600 --> 01:27:52.600]  и снова ждем новых событий.
[01:27:52.600 --> 01:27:54.600]  И может быть это событие будет снова
[01:27:54.600 --> 01:27:56.600]  на серверном socket, а может быть это
[01:27:56.600 --> 01:27:58.600]  будет событие на socket клиента.
[01:27:58.600 --> 01:28:03.600]  Тогда здесь сам ASIO прочитает в буфер,
[01:28:03.600 --> 01:28:08.600]  который мы передали в операцию
[01:28:08.600 --> 01:28:12.600]  данные и вызовет этот обработчик.
[01:28:13.600 --> 01:28:15.600]  Что сделать этот обработчик?
[01:28:15.600 --> 01:28:17.600]  Он вызовет do write, то есть он
[01:28:17.600 --> 01:28:19.600]  стартует новую синхронную операцию
[01:28:19.600 --> 01:28:22.600]  записи, то есть зарегистрирует
[01:28:22.600 --> 01:28:26.600]  ASIO socket на события готовых записи.
[01:28:27.600 --> 01:28:29.600]  Ну и вот так вот эти задачки будут
[01:28:29.600 --> 01:28:32.600]  по кругу запускаться, порождать друг друга.
[01:28:32.600 --> 01:28:35.600]  То есть мы начинаем запуск сервера
[01:28:35.600 --> 01:28:39.600]  с вызова do accept. Do accept регистрирует
[01:28:39.600 --> 01:28:43.600]  E-Poll socket, серверный socket на чтение.
[01:28:43.600 --> 01:28:46.600]  Потом, когда из E-Poll этот дискиптор
[01:28:46.600 --> 01:28:48.600]  достается, мы вызываем accept.
[01:28:48.600 --> 01:28:52.600]  И после этого accept-а, с одной стороны,
[01:28:52.600 --> 01:28:54.600]  мы снова вызываем do accept и порождать
[01:28:54.600 --> 01:28:56.600]  еще одна такая задача.
[01:28:56.600 --> 01:28:58.600]  С другой стороны, мы порождаем, мы
[01:28:58.600 --> 01:29:00.600]  стартуем обработку клиента и вызываем
[01:29:00.600 --> 01:29:04.600]  socket async-лица. То есть async-accept
[01:29:04.600 --> 01:29:08.600]  потом сработал accept, потом сработал socket
[01:29:08.600 --> 01:29:12.600]  async-лицам и accept-а async-accept.
[01:29:12.600 --> 01:29:14.600]  И теперь у нас уже в E-Poll два события.
[01:29:14.600 --> 01:29:17.600]  И вот, может быть, мы вызовем E-Poll
[01:29:17.600 --> 01:29:20.600]  и получим событие на серверном
[01:29:20.600 --> 01:29:22.600]  socket и вызовем accept. Может, мы получим
[01:29:22.600 --> 01:29:24.600]  из E-Poll события на клиентском socket
[01:29:24.600 --> 01:29:27.600]  и вызовем read. И тогда появится новая задача
[01:29:27.600 --> 01:29:30.600]  запустить собработчик чтения, в котором
[01:29:30.600 --> 01:29:32.600]  вызовется do write, в котором будет
[01:29:32.600 --> 01:29:35.600]  вызвана async-write, который положит socket.
[01:29:35.600 --> 01:29:37.600]  Ну и так, короче, понятно, да, что происходит.
[01:29:37.600 --> 01:29:39.600]  Вот эта вся конструкция вращается.
[01:29:39.600 --> 01:29:42.600]  Сначала нужно осинхронную запись,
[01:29:42.600 --> 01:29:44.600]  чем она. В принципе, можно просто записать, чтобы
[01:29:44.600 --> 01:29:46.600]  прочитать. То есть вы тоже не писали нормальный
[01:29:46.600 --> 01:29:49.600]  сервер. Да, может быть, тоже мы не осинхронную
[01:29:49.600 --> 01:29:53.600]  запись. Ну а синхронная запись может заблокироваться.
[01:29:53.600 --> 01:29:58.600]  Ну как зачем? Вот зачем ты читаешь
[01:29:58.600 --> 01:30:05.600]  асинхронную? Чтобы... У тебя задача. Ты хочешь
[01:30:05.600 --> 01:30:08.600]  написать эхо-сервер, который обслуживает
[01:30:08.600 --> 01:30:11.600]  многих клиентов. Что ты можешь сделать? Ты можешь
[01:30:11.600 --> 01:30:14.600]  написать его на потоках, использовать блокирующий
[01:30:14.600 --> 01:30:17.600]  IP. Можешь? Можешь. Ну вот пишешь код, запускаешь
[01:30:17.600 --> 01:30:20.600]  там потоки. Потом оказывается, что так ты там, не знаю,
[01:30:20.600 --> 01:30:22.600]  100 тысяч соединений не обработаешь. Ты говоришь,
[01:30:22.600 --> 01:30:24.600]  ну зачем мне делать синхронную IP? Я использую
[01:30:24.600 --> 01:30:28.600]  асинхронную. То есть у меня есть в операционной
[01:30:28.600 --> 01:30:31.600]  системе механизм модификации о событиях. Есть очередь
[01:30:31.600 --> 01:30:34.600]  задач. Япол. Я туда буду сходовать сокета. И потом,
[01:30:34.600 --> 01:30:36.600]  по мере готовности, их вот только обработчики
[01:30:36.600 --> 01:30:38.600]  вызывать. Тогда вся работа упаковывается в один
[01:30:38.600 --> 01:30:42.600]  поток. И вот ты начинаешь вроде бы здраво. Ты слушаешь
[01:30:42.600 --> 01:30:45.600]  серверный сокет, ты регистрируешь его в Яполе,
[01:30:45.600 --> 01:30:47.600]  получаешь событие, что появился клиент. Аксептишь
[01:30:47.600 --> 01:30:50.600]  этого клиента, регистрируешь сокеты на чтение. И вот
[01:30:50.600 --> 01:30:52.600]  у тебя случаются события. Сокет, клиент, ты готов
[01:30:52.600 --> 01:30:56.600]  к чтению. Ты вызываешь ритм на нем, он не блокируется,
[01:30:56.600 --> 01:30:59.600]  потому что сокет готов к чтению. Ты заполняешь данными
[01:30:59.600 --> 01:31:02.600]  какой-то буфер. А дальше что ты делаешь? Ты хочешь
[01:31:02.600 --> 01:31:05.600]  записать обратно сокет. И какой-то код ты пишешь.
[01:31:05.600 --> 01:31:09.600]  Но у нас, видимо, не возникало таких ситуаций,
[01:31:09.600 --> 01:31:13.600]  где запись может блокировать. Ну смотри, ты отрицаешь
[01:31:13.600 --> 01:31:16.600]  реальность. Нет, я не отрицаю. Ну нет, не смысляю. Твое
[01:31:16.600 --> 01:31:18.600]  решение, аккуратно, твое решение отрицает реальность.
[01:31:18.600 --> 01:31:21.600]  Вот твое решение не имеет смысла, потому что оно
[01:31:21.600 --> 01:31:25.600]  заблокируется. Вот. И если твой вызов write заблокируется,
[01:31:25.600 --> 01:31:28.600]  то все твои чтения синхронные тоже заблокируются, у тебя
[01:31:28.600 --> 01:31:31.600]  сервер станет однопоточным. То есть с таким же успехом
[01:31:31.600 --> 01:31:34.600]  ты мог бы написать такой код. Блокируюсь на accept и
[01:31:34.600 --> 01:31:38.600]  получаю сокет. И while true там читаю, пишу. Ну ничем не
[01:31:38.600 --> 01:31:42.600]  лучше особо. Ну мы должны делать точно так же, как мы
[01:31:42.600 --> 01:31:45.600]  поступали с чтениями. Мы должны, во-первых, понятно
[01:31:45.600 --> 01:31:50.600]  и почему в сокет нельзя писать без блокировки.
[01:31:50.600 --> 01:31:54.600]  Непонятно. Ну почему читать нельзя понятно, наверное,
[01:31:54.600 --> 01:31:57.600]  потому что никто не прислал ничего. Ну а теперь
[01:31:57.600 --> 01:32:01.600]  представь, что TCP это очень сложная штука. Я вот не
[01:32:01.600 --> 01:32:04.600]  знаю, что вы будете делать осенью, но вот осенью читать
[01:32:04.600 --> 01:32:07.600]  спецкурс про спрелевленным системам. И там, ну в общем,
[01:32:07.600 --> 01:32:09.600]  начинается все частично с TCP. По крайней мере, на
[01:32:09.600 --> 01:32:12.600]  первом семинаре я об этом рассказываю. TCP – это транспортный
[01:32:12.600 --> 01:32:15.600]  протокол, который помогает, который создает абстракцию,
[01:32:15.600 --> 01:32:17.600]  который дает вам абстракцию прямого провода между двумя
[01:32:17.600 --> 01:32:20.600]  машинами. Вот как будто бы есть, не знаю, дата-центр,
[01:32:20.600 --> 01:32:23.600]  там стоят десятки тысяч машин, между ними какая-то
[01:32:23.600 --> 01:32:25.600]  сложная компутационная фабрика, какая-то бешенная
[01:32:25.600 --> 01:32:28.600]  конструкция из там сетевых коробок, которые там в какие-то
[01:32:28.600 --> 01:32:30.600]  плоскости перпендикулярно организованы, неважно.
[01:32:30.600 --> 01:32:34.600]  Но при этом, каждая, вы одна машина соединяете с другой,
[01:32:34.600 --> 01:32:36.600]  думаете, что как будто бы между вами прямой провод,
[01:32:36.600 --> 01:32:39.600]  по которому просто вы байты отправляете поточно, и
[01:32:39.600 --> 01:32:42.600]  на другой стороне их в таком виде получают. Но прямо
[01:32:42.600 --> 01:32:44.600]  скажем, что эта абстракция довольно сильно отличается
[01:32:44.600 --> 01:32:47.600]  от реальности, потому что под вами есть вот эта сложная
[01:32:47.600 --> 01:32:51.600]  компутационная фабрика из коробок проводов, вы
[01:32:51.600 --> 01:32:55.600]  отправляете ваши данные, не потоков, разумеется, а
[01:32:55.600 --> 01:33:05.600]  TCP датограммами, сегментами, делите кусочки,
[01:33:05.600 --> 01:33:07.600]  положите поток на кусочки, отправляете его кусочками,
[01:33:07.600 --> 01:33:09.600]  эти кусочки могут бегать, вообще говоря, по разным
[01:33:09.600 --> 01:33:13.600]  маршрутам, доставляться в разном порядке, то есть
[01:33:13.600 --> 01:33:17.600]  это все в сериальности сильно сложнее. Кроме того,
[01:33:17.600 --> 01:33:20.600]  смотрите, нет, вы, конечно, можете их получать и
[01:33:20.600 --> 01:33:22.600]  выстраивать в правильном порядке, вы, наверное, все
[01:33:22.600 --> 01:33:27.600]  это понимаете, не понимаете, как организованы. Придется
[01:33:27.600 --> 01:33:32.600]  осенью рассказывать тогда. Но смотрите, какая проблема
[01:33:32.600 --> 01:33:37.600]  есть. Вот у вас много таких логических пар, не то что
[01:33:37.600 --> 01:33:40.600]  даже клиент-сервер, просто два собеседника. В конце
[01:33:40.600 --> 01:33:48.600]  концов, ладно, неважно. И вот эти много-много пар думают,
[01:33:48.600 --> 01:33:50.600]  что они соединены отдельными проводами, а на самом деле
[01:33:50.600 --> 01:33:54.600]  они делят какие-то роутеры, коммутаторы между ними.
[01:33:54.600 --> 01:33:58.600]  И что будет, если какая-то пара начнет отправлять,
[01:33:58.600 --> 01:34:01.600]  посылать друг другу данные с каким-то бешеным рейтом?
[01:34:01.600 --> 01:34:06.600]  Они используют общий ресурс, все эти соединения, все эти
[01:34:06.600 --> 01:34:09.600]  пары, они используют общую сеть, но при этом какая-то
[01:34:09.600 --> 01:34:12.600]  пара может сильно нагружать эту сеть, и тогда она будет
[01:34:12.600 --> 01:34:15.600]  отнимать пропускную способность у других участников.
[01:34:15.600 --> 01:34:21.600]  Ну или, смотри, другая ситуация. У тебя есть, ты клиент,
[01:34:21.600 --> 01:34:24.600]  есть сервер, и ты клиент готов вслать с бешеным рейтом
[01:34:24.600 --> 01:34:26.600]  данные серверу. А сервер не может их в таком рейте
[01:34:26.600 --> 01:34:29.600]  обрабатывать, он не может успевать вычитывать и
[01:34:29.600 --> 01:34:35.600]  процессить данные. Вот. Обе эти проблемы нужно решать.
[01:34:35.600 --> 01:34:39.600]  Нужен какой-то механизм обратной связи. Ну, back pressure
[01:34:39.600 --> 01:34:42.600]  это называется в общем случае. То есть, если ты перегружаешь
[01:34:42.600 --> 01:34:45.600]  общую сеть, то ты должен рано или поздно замедлиться.
[01:34:45.600 --> 01:34:48.600]  То есть, ты не можешь писать в том темпе, в котором ты
[01:34:48.600 --> 01:34:52.600]  мог бы. Себя ограничивать пропускную способность сети
[01:34:52.600 --> 01:34:55.600]  и другие участники, с которыми ты эту сеть делишь.
[01:34:55.600 --> 01:34:58.600]  Кроме того, ты ограничен не только своей скоростью
[01:34:58.600 --> 01:35:00.600]  записи, своим сетевым интерфейсом, ты ограничен
[01:35:00.600 --> 01:35:03.600]  скоростью получателя данных. Если ты будешь
[01:35:03.600 --> 01:35:07.600]  если ты будешь слать данные в бешеном темпе, а сервер
[01:35:07.600 --> 01:35:09.600]  будет их обрабатывать медленно, то у него просто
[01:35:09.600 --> 01:35:12.600]  закончится память. Вряд ли оно так просто в ядре
[01:35:12.600 --> 01:35:14.600]  закончится память. Вот. Мы бы этого не хотели.
[01:35:14.600 --> 01:35:17.600]  И поэтому в TCP есть два механизма. Один называется
[01:35:17.600 --> 01:35:20.600]  congestion control, другой называется flow control. То есть,
[01:35:20.600 --> 01:35:24.600]  первый механизм он про то, чтобы не нагружать сеть
[01:35:24.600 --> 01:35:29.600]  общую для всех пар собеседников. Второй про то, чтобы не
[01:35:29.600 --> 01:35:34.600]  перегружать получателя данных. Вот. Ну, про это есть,
[01:35:34.600 --> 01:35:38.600]  мне кажется, хорошая, хорошая статья, короткая, такая
[01:35:38.600 --> 01:35:42.600]  вводная в книжке High Performance Browser Network. Она про то,
[01:35:42.600 --> 01:35:45.600]  что в целом про сеть, а скорее про HTTP, но поскольку
[01:35:45.600 --> 01:35:50.600]  это транспортный протокол общий, тут есть некоторые
[01:35:50.600 --> 01:35:53.600]  механики. И вот идея в том, что ты посылаешь данные,
[01:35:53.600 --> 01:35:57.600]  посылаешь данные, а потом в какой-то момент ты, ну,
[01:35:57.600 --> 01:36:01.600]  ты посылаешь данные, тебе, как правило, в TCP на каждый
[01:36:01.600 --> 01:36:03.600]  твой сегмент, тебе посылают в ответ, ну не на каждый,
[01:36:03.600 --> 01:36:09.600]  не обязательно, посылают в ответ сегмент, в котором
[01:36:09.600 --> 01:36:12.600]  будет написано, что вот получатель получил твои
[01:36:12.600 --> 01:36:16.600]  данные и вот там достроил поток до какой-то позиции.
[01:36:16.600 --> 01:36:19.600]  Вот. И может быть, ты подтверждения не получаешь,
[01:36:19.600 --> 01:36:24.600]  потому что данные отправлялась, перегружено, и просто какая-то
[01:36:24.600 --> 01:36:26.600]  сетевая коробка, но у нее уже, это же коробка, там
[01:36:26.600 --> 01:36:29.600]  какие-то ограниченные буферы, фиксированная память, она
[01:36:29.600 --> 01:36:31.600]  в какой-то момент стала просто дропать то, что у нее
[01:36:31.600 --> 01:36:34.600]  приходит. Ну, потому что не резиновая. Вот. И тебе
[01:36:34.600 --> 01:36:36.600]  перестали приходить подтверждение с другой стороны от твоего
[01:36:36.600 --> 01:36:39.600]  собеседника, что он данные получает. И ты вот
[01:36:39.600 --> 01:36:42.600]  используя такую потерю подтверждения, как обратную
[01:36:42.600 --> 01:36:45.600]  связь, начинаешь сбавлять скорость. То есть, ты
[01:36:45.600 --> 01:36:49.600]  ограничиваешь рейт записи, ты ограничиваешь в, ну,
[01:36:49.600 --> 01:36:52.600]  в смысле, ты операционная система, которая реализует
[01:36:52.600 --> 01:36:55.600]  TCP, а TCP реализован только на концах провода. То есть,
[01:36:55.600 --> 01:36:58.600]  в сети-то его нет никакого TCP. Вы это понимаете?
[01:36:58.600 --> 01:37:04.600]  Вся сеть про TCP ничего не знает. Вы, операционная
[01:37:04.600 --> 01:37:07.600]  система, которая реализует endpoint TCP-соединения, понимает,
[01:37:07.600 --> 01:37:11.600]  что нельзя больше в таком темпе пользователь данные
[01:37:11.600 --> 01:37:15.600]  принимать на запись, и просто блокирует его вызовы
[01:37:15.600 --> 01:37:20.600]  write. То есть, в ядре уже есть некоторый буфер на запись,
[01:37:20.600 --> 01:37:24.600]  он заполнился, и он не проталкивается в сеть. Поэтому
[01:37:24.600 --> 01:37:26.600]  вызов write блокируется, ну, то есть, просто обратная
[01:37:26.600 --> 01:37:30.600]  связь такая идет. Мы блокируем запись. Поэтому, если ты
[01:37:30.600 --> 01:37:33.600]  вызываешь write просто после чтения из сокета, ну, может
[01:37:33.600 --> 01:37:36.600]  быть, тебе повезет. А может быть, клиент у тебя попался
[01:37:36.600 --> 01:37:39.600]  вредный, он просто шлет тебе данные, но не вычитывает
[01:37:39.600 --> 01:37:41.600]  из сокета. И тогда твой сервер просто застрянет в
[01:37:41.600 --> 01:37:44.600]  этом write. И застрянет все остальное. Поэтому, если
[01:37:44.600 --> 01:37:47.600]  ты пишешь неблокирующий код, ну, в смысле, если ты
[01:37:47.600 --> 01:37:49.600]  пишешь неблокирующую реализацию своего эхо-сервера,
[01:37:49.600 --> 01:37:52.600]  то она неблокирующая не потому, что где-то нет блокирующих
[01:37:52.600 --> 01:37:55.600]  вызовов, потому что их нигде нет. Вот если хотя бы в
[01:37:55.600 --> 01:37:58.600]  одном месте они остаются, то все идет прахом. Так что
[01:37:58.600 --> 01:38:04.600]  ты, когда получаешь сокет, когда ты получаешь
[01:38:04.600 --> 01:38:07.600]  от E-Polo клиентский сокет, который готов к чтению,
[01:38:07.600 --> 01:38:10.600]  ты, конечно, можешь из него прочесть, но ты не должен
[01:38:10.600 --> 01:38:12.600]  ожидать, что ты сразу же можешь сделать запись.
[01:38:12.600 --> 01:38:14.600]  Вот, получается, существует еще какой-то новый тип
[01:38:14.600 --> 01:38:17.600]  эвент, когда пользователь говорит о том, что он сейчас
[01:38:17.600 --> 01:38:23.600]  готов... Ну, как у тебя, смотри, вот есть здесь E-Polo...
[01:38:23.600 --> 01:38:27.600]  Мы просто E-Polo пользовались. Ну, у тебя есть события E-Polo
[01:38:27.600 --> 01:38:29.600]  in, E-Polo out, и ты вот регистрируешь то событие,
[01:38:29.600 --> 01:38:32.600]  которого ты ожидаешь. Вот сокет готов к чтению, сокет
[01:38:32.600 --> 01:38:35.600]  готов к записи. Причем готов к записи, это же не
[01:38:35.600 --> 01:38:38.600]  означает, что ты прочтешь, ты сможешь записать в него
[01:38:38.600 --> 01:38:41.600]  весь буфер. Может быть, ты запишешь какое-то
[01:38:41.600 --> 01:38:43.600]  количество. Вот ровно поэтому, кстати, в этом коде
[01:38:43.600 --> 01:38:49.600]  на ASIO чтение из сокета это метод, а запись в сокет
[01:38:49.600 --> 01:38:51.600]  это функция, потому что она внутри себя итерирует
[01:38:51.600 --> 01:38:54.600]  попытки. То есть там много подписок происходит,
[01:38:54.600 --> 01:38:57.600]  мы подписываемся, потом пишем, если в буфере остаются
[01:38:57.600 --> 01:38:59.600]  данные, мы не смогли все записать, то мы повторно
[01:38:59.600 --> 01:39:03.600]  подписываемся и снова пишем. Вот такая вот история.
[01:39:03.600 --> 01:39:08.600]  Но тут райты, они симметричны ридом, они тоже асинхронные,
[01:39:08.600 --> 01:39:11.600]  и вот поэтому они друг друга вызывают. Вот у нас
[01:39:11.600 --> 01:39:15.600]  получается вот такой цикл из задач, которые пинают
[01:39:15.600 --> 01:39:26.600]  друг друга. Что бы еще нужно было прокомментировать?
[01:39:26.600 --> 01:39:30.600]  Ну, наверное, такой вопрос. Ну, это опять следствие
[01:39:30.600 --> 01:39:34.600]  странного неправильного кода, которое мог написать.
[01:39:34.600 --> 01:39:37.600]  Ты читаешь, у тебя сокет готов к чтению, ты из него
[01:39:37.600 --> 01:39:44.600]  читаешь данные в буфер, а где этот буфер находится?
[01:39:44.600 --> 01:39:46.600]  Ну, вот это работает, потому что ты прочел из буфера,
[01:39:46.600 --> 01:39:48.600]  сразу записал, и все, он тебе больше не нужен. Но в
[01:39:48.600 --> 01:39:50.600]  реальности, конечно, не так. Ты прочел из буфера,
[01:39:50.600 --> 01:39:52.600]  а записать обратно не можешь. А потом появился другой
[01:39:52.600 --> 01:39:55.600]  клиент, из которого ты тоже читаешь, и вот все, у тебя
[01:39:55.600 --> 01:39:58.600]  уже нужно два буфера, а не один. Ну, то есть тебе
[01:39:58.600 --> 01:40:02.600]  нужно для каждого клиента свой собственный буфер.
[01:40:02.600 --> 01:40:05.600]  И вот смотри, в этом коде, что мы делаем, когда заводим
[01:40:05.600 --> 01:40:09.600]  соединение. Мы алоцируем на куче объект сэшн. Этот
[01:40:09.600 --> 01:40:12.600]  объект на куче нужно для того, чтобы в нем разместить
[01:40:12.600 --> 01:40:16.600]  буфер как раз. Вот это динамическая локация буфера.
[01:40:16.600 --> 01:40:20.600]  И мы этот буфер за собой таскаем в виде сильной ссылки
[01:40:20.600 --> 01:40:23.600]  на объект сэшн. То есть мы стартуем синхронную
[01:40:23.600 --> 01:40:26.600]  операцию, но перед этим мы берем сильную ссылку на
[01:40:26.600 --> 01:40:30.600]  себя, ну, через интрузивный указатель, и вот захватываем
[01:40:30.600 --> 01:40:34.600]  ее в лямбду, которая служит обработчиком нашей синхронной
[01:40:34.600 --> 01:40:37.600]  операции. И пока обработчик синхронной операции не
[01:40:37.600 --> 01:40:41.600]  вызван, то есть пока чтение не завершилось, мы удерживаем
[01:40:41.600 --> 01:40:46.600]  ссылку на объект сэшн, то есть на буфер.
[01:40:46.600 --> 01:40:54.600]  — У нас, получается, райды будут все необматывающие,
[01:40:54.600 --> 01:41:00.600]  то есть, я скажу. В любом случае, у нас много лишних буферов
[01:41:00.600 --> 01:41:04.600]  — Что значит «лишних»? Буферы нужны. Мы же не знаем,
[01:41:04.600 --> 01:41:07.600]  когда они понадобятся. Это непредсказуемо, поэтому
[01:41:07.600 --> 01:41:10.600]  да. Ну, а у нас они и раньше были, они у нас и в потоках
[01:41:10.600 --> 01:41:13.600]  были, мы тоже сыруем буферы на каждом потоке, но, правда,
[01:41:13.600 --> 01:41:15.600]  мы делаем это на стейке.
[01:41:24.600 --> 01:41:27.600]  Вот, я на лекции рассказывал, это был очень содержательный
[01:41:27.600 --> 01:41:32.600]  момент, что мы как потом преобразуем вот эту функцию
[01:41:32.600 --> 01:41:36.600]  в синхронное решение? Мы просто берем нашу функцию,
[01:41:36.600 --> 01:41:39.600]  где все жило на стеке, и трансформируем ее в класс,
[01:41:39.600 --> 01:41:42.600]  который мы перемещаем на кучу, и локальные перемены
[01:41:42.600 --> 01:41:45.600]  становятся полями этого класса. Это очень естественное
[01:41:45.600 --> 01:41:48.600]  преобразование, которое следует просто из перехода
[01:41:48.600 --> 01:41:53.600]  к асинхронным интерфейсам. Вот, а теперь вопрос, вы,
[01:41:53.600 --> 01:41:56.600]  возможно, не умеете на него отвечать, потому что вы
[01:41:56.600 --> 01:41:59.600]  писали какой-то альтернативный кон, но все же, вот когда вы
[01:41:59.600 --> 01:42:05.600]  достаете из еполу события, то вам прилетает вот такая
[01:42:05.600 --> 01:42:08.600]  структура, да? В ней есть файловый дескриптор, вы
[01:42:08.600 --> 01:42:11.600]  на него смотрите и там понимаете, что происходит. Ну,
[01:42:11.600 --> 01:42:14.600]  точнее так, вы из этого файлового дескриптора там
[01:42:14.600 --> 01:42:18.600]  читаете, например, данные. А зачем здесь поэнтер есть,
[01:42:18.600 --> 01:42:22.600]  некоторый непрозрачный? Водит звездочка. Вы когда
[01:42:22.600 --> 01:42:25.600]  регистрируете события, вы вместе с дескриптором кладете
[01:42:25.600 --> 01:42:29.600]  этот void звездочка в епол. Когда события наступают
[01:42:29.600 --> 01:42:32.600]  на этом файловом дескрипторе, вы обратно получаете
[01:42:32.600 --> 01:42:35.600]  структурку с этим void звездочка. Епол его никак не
[01:42:35.600 --> 01:42:51.600]  интерпретирует. Нет, ну это, смотри, это какие-то данные
[01:42:51.600 --> 01:42:54.600]  идут в нагрузку с дескриптором, и епол про них ничего
[01:42:54.600 --> 01:43:17.600]  не знает. Так вот зачем? Нет. Сейчас, ну. Ну да, я кажется
[01:43:17.600 --> 01:43:41.600]  вру. Ну да, это, это правда. Я думал, что это возможно
[01:43:41.600 --> 01:44:01.600]  да. Вот это, да, это как раз способ связать события,
[01:44:01.600 --> 01:44:07.600]  ну которые, связать события там, скажем, на сокете с
[01:44:07.600 --> 01:44:11.600]  некоторым объектом, который понимает, как это событие
[01:44:11.600 --> 01:44:13.600]  нужно обслуживать дальше.
[01:44:13.600 --> 01:44:39.600]  Так, ну, что еще про этот код?
[01:44:39.600 --> 01:44:59.600]  Ну да, окей. Что, давайте так, если мы понимаем, почему
[01:44:59.600 --> 01:45:03.600]  такой код, в смысле, как вот такой код матчится в епол,
[01:45:03.600 --> 01:45:09.600]  то дальше, наверное, вопрос такой, ну, про задачу
[01:45:09.600 --> 01:45:14.600]  с липфор вы ее читали, вы ее делали, вы игнорируетесь,
[01:45:14.600 --> 01:45:19.600]  ну тогда это некоторое, некоторое препятствие для нас
[01:45:19.600 --> 01:45:27.600]  сейчас. Не делать не очень полезно. Сложно обсуждать
[01:45:27.600 --> 01:45:30.600]  дальше. Ну, то есть пока ты не подумал, сложно ответить
[01:45:30.600 --> 01:45:39.600]  на твои вопросы. Ну что ж, тогда, наверное, в этом месте
[01:45:39.600 --> 01:45:43.600]  все. Тут нужно задачу решать, и тогда можно будет что-то
[01:45:43.600 --> 01:45:47.600]  обсудить. Ну, задача, мы используем не сокеты, мы используем
[01:45:47.600 --> 01:45:53.600]  таймеры, но суть абсолютно такая же. Вот мы заводим
[01:45:53.600 --> 01:45:56.600]  таймер, он представляется там каким-то файловым
[01:45:56.600 --> 01:45:59.600]  скриптором, допустим, ну, епол уже умеет скрипторы
[01:45:59.600 --> 01:46:04.600]  для таймеров, вы знаете. Вот, здесь мы подписываемся
[01:46:04.600 --> 01:46:09.600]  на какое-то событие, ну, в смысле, подписываемся на
[01:46:09.600 --> 01:46:13.600]  тайм-аут, и, ну, операции другие, таймеры вместо сокетов,
[01:46:13.600 --> 01:46:16.600]  но смысл абсолютно такой же, то есть механика исполнена
[01:46:16.600 --> 01:46:20.600]  такая же. Правда, разве что, вот, в еполе есть еще, в ее
[01:46:20.600 --> 01:46:23.600]  контексте есть еще возможность не только запускать события,
[01:46:23.600 --> 01:46:26.600]  которые, вот, на каких-то скрипторах возникли, но еще
[01:46:26.600 --> 01:46:31.600]  и просто рямды исполнять. И вот в условии пишу, что этот
[01:46:31.600 --> 01:46:35.600]  цикл run в его контексте, который все это делает, можно
[01:46:35.600 --> 01:46:38.600]  запускать несколько поток, и тогда в этом смысле его
[01:46:38.600 --> 01:46:41.600]  контекст в таком узком смысле будет представлять из
[01:46:41.600 --> 01:46:48.600]  себя полпоток. Вот, но среди задач, которые он исполняет,
[01:46:48.600 --> 01:46:52.600]  есть задача вот ваши обработчики, а есть задача служебные,
[01:46:52.600 --> 01:46:57.600]  где опрашивается епол. Вот, и если задача епол запускается
[01:46:57.600 --> 01:47:02.600]  и мы видим, что других задач в планировщике нет, то мы
[01:47:02.600 --> 01:47:05.600]  можем заблокироваться на еполвейте. А если она есть,
[01:47:05.600 --> 01:47:07.600]  то мы просто выполняем не блокирующий еполвейт, сразу
[01:47:07.600 --> 01:47:11.600]  доставим то, что готово, и обслуживаем. Вот, так что это
[01:47:11.600 --> 01:47:16.600]  планировщик, но он, в отличие от трэдпула, блокируется
[01:47:16.600 --> 01:47:19.600]  не на какой-то общей очереди. Ну, в смысле, поток в нем
[01:47:19.600 --> 01:47:22.600]  блокируется не на общей очереди, а поток блокируется
[01:47:22.600 --> 01:47:27.600]  на очереди событий операционной системы. Механика другая,
[01:47:27.600 --> 01:47:33.600]  но, в общем, это все в какой-то степени обобщается. Ну,
[01:47:33.600 --> 01:47:36.600]  а дальше мы, поскольку это все планировщик, он может
[01:47:36.600 --> 01:47:40.600]  запускать лямбды, то мы поверх него можем запустить и
[01:47:40.600 --> 01:47:45.600]  файбера. А дальше нужно все это интегрировать с
[01:47:45.600 --> 01:47:49.600]  таймерами. Ну, то есть через таймеры и асинхронный
[01:47:49.600 --> 01:47:53.600]  асинквейт выразить операцию Slipforge для файбера, которая
[01:47:53.600 --> 01:47:57.600]  блокирует его, но не блокирует поток планировщика, в котором
[01:47:57.600 --> 01:48:06.600]  поток этого event loop, в котором файбер запустился. Такие
[01:48:06.600 --> 01:48:13.600]  пироги. Семинар по моделям памяти будет, да, но
[01:48:13.600 --> 01:48:18.600]  все впереди. Мне кажется, там одним семинарам не
[01:48:18.600 --> 01:48:21.600]  отделаешься. Ну, мне нужно про текущие задачи все же
[01:48:21.600 --> 01:48:25.600]  поговорить. Давайте обсудим, что у вас еще есть, если вы
[01:48:25.600 --> 01:48:31.600]  эту задачу не решали. Есть ли у вас еще вопросы?
[01:48:31.600 --> 01:48:46.600]  Всему свое время. Не знаю. Ну, давай пробуй задать,
[01:48:46.600 --> 01:48:56.600]  я могу, может быть, отвечу. Я говорил это в кавычках
[01:48:56.600 --> 01:49:09.600]  каждый раз. Давай я тебе отвечу на все, что смогу, но я не
[01:49:09.600 --> 01:49:13.600]  хочу говорить про слабые модели памяти. Это вот как
[01:49:13.600 --> 01:49:27.600]  раз тема семинара. Смотри, я это говорил, когда… Ну вот
[01:49:27.600 --> 01:49:30.600]  здесь, что как будто бы… Ну тут не то, что я говорю, а
[01:49:30.600 --> 01:49:33.600]  тут сам процессор Intel говорит, что он как будто бы reordered
[01:49:33.600 --> 01:49:36.600]  инструкции. На самом деле он еще ничего не… На самом
[01:49:36.600 --> 01:49:41.600]  деле он не то что… Но он исполняет их, используя какие-то
[01:49:41.600 --> 01:49:45.600]  свои вристики, типа storebuffer, чтобы сократить время
[01:49:45.600 --> 01:49:50.600]  простоя ядра. То есть внутри он не то чтобы что-то
[01:49:50.600 --> 01:49:53.600]  переупорядочил, он выполнил инструкции по порядку, сначала
[01:49:53.600 --> 01:49:57.600]  store, потом load, просто store положил в этот самый буфер,
[01:49:57.600 --> 01:50:02.600]  и другие ядра про эту запись ничего не знают. Ну, то
[01:50:02.600 --> 01:50:05.600]  есть это скорее вот как ты, пользователь, можешь думать
[01:50:05.600 --> 01:50:08.600]  об этом исполнении, как ты можешь себе объяснить, что
[01:50:08.600 --> 01:50:12.600]  вот такое исполнение, исполнение такой программы завершается
[01:50:12.600 --> 01:50:16.600]  слоем нулями. Что как будто бы store, load, preorder. Ну вот
[01:50:16.600 --> 01:50:19.600]  для этого и нужна операционная модель памяти, которая
[01:50:19.600 --> 01:50:22.600]  объясняет, как правильно об этом думать. Операционная
[01:50:22.600 --> 01:50:25.600]  модель памяти говорит тебе, как моделировать исполнение.
[01:50:25.600 --> 01:50:29.600]  Ну вот так, у тебя есть ядра, у каждого ядра есть storebuffer,
[01:50:29.600 --> 01:50:33.600]  и все записи проваливаются в него, и иногда там проваливаются
[01:50:33.600 --> 01:50:38.600]  вниз, как-то непредсказуемо. Вот отчтения они обслуживаются
[01:50:38.600 --> 01:50:42.600]  либо из памяти, либо, если есть запись соответствующая
[01:50:42.600 --> 01:50:46.600]  в буфере, она берется оттуда. Ну и вот ты уже на этой
[01:50:46.600 --> 01:50:49.600]  абстрактной машине запускаешь свою накопуточную программу
[01:50:49.600 --> 01:50:52.600]  и получаешь все возможное исполнение. То есть здесь уже не про
[01:50:52.600 --> 01:50:55.600]  reordering речь, здесь про вот этот честный ответ, это
[01:50:55.600 --> 01:50:59.600]  операционная модель. Вот она. Упрощенный ответ, что как будто
[01:50:59.600 --> 01:51:06.600]  reordering происходит. Вот это упрощенная модель?
[01:51:06.600 --> 01:51:10.600]  Нет, я про упрощенную модель, когда мы говорим про reordering.
[01:51:10.600 --> 01:51:15.600]  Вот у меня просто возникла проблема. Ну она не нужна,
[01:51:15.600 --> 01:51:18.600]  ты можешь о ней не думать. Я же тебе сразу говорю на этом
[01:51:18.600 --> 01:51:22.600]  слайде, что на самом деле все немного не так.
[01:51:22.600 --> 01:51:49.600]  Ну смотри, как устроены процессоры, трудно сказать.
[01:51:49.600 --> 01:51:53.600]  У них сложные операционные модели. Одно из утверждений,
[01:51:53.600 --> 01:51:58.600]  которое здесь делается в какой-то момент, что с
[01:51:58.600 --> 01:52:04.600]  операционными моделями жить сложно. Они очень
[01:52:04.600 --> 01:52:08.600]  специфичны для процессора, и в них сложно моделировать
[01:52:08.600 --> 01:52:13.600]  исполнение. Вот. Поэтому мы от них вообще отказываемся.
[01:52:13.600 --> 01:52:17.600]  При reordering, ну я не знаю, нигде в лекции не говорилось,
[01:52:17.600 --> 01:52:20.600]  что думай про reordering. Наоборот, говорилось, что не думай
[01:52:20.600 --> 01:52:26.600]  про reordering. Смотри, чем лекция заканчивалась.
[01:52:26.600 --> 01:52:35.600]  Вот. Не думайте про reordering. Ну потому что нет
[01:52:35.600 --> 01:52:38.600]  никакого универсального понятия reordering и барьера.
[01:52:38.600 --> 01:52:41.600]  Это все очень специфично для конкретного процессора,
[01:52:41.600 --> 01:52:46.600]  для его устройства, его операционной модели. Это
[01:52:46.600 --> 01:52:49.600]  не обобщается слишком хорошо, зато обобщается понятие
[01:52:49.600 --> 01:52:54.600]  порядков. А слово reordering я употребляю, потому что
[01:52:54.600 --> 01:53:00.600]  это такой общий способ обозначить всю ту механику,
[01:53:00.600 --> 01:53:02.600]  которая приводит к тому, что нарушается вроде бы
[01:53:02.600 --> 01:53:07.600]  привычный ход исполнения, ожидаемый для нас. Как будто
[01:53:07.600 --> 01:53:11.600]  бы что-то переставилось. Это не точно, но мне кажется,
[01:53:11.600 --> 01:53:15.600]  что все люди примерно это слово используют. И
[01:53:15.600 --> 01:53:20.600]  само по себе в этом ничего плохого нет, пока ты не
[01:53:20.600 --> 01:53:24.600]  думаешь, не доказываешь через него корректность.
[01:53:24.600 --> 01:53:27.600]  Пока ты им не оперируешь, чтобы объяснить, что программы
[01:53:27.600 --> 01:53:31.600]  правильные, то ты можешь на пальцах назвать, что это
[01:53:31.600 --> 01:53:36.600]  reordering. Ну вот там статья на Википедии про
[01:53:36.600 --> 01:53:39.600]  memo reordering, она перечисляет типа reordering, которые могут
[01:53:39.600 --> 01:53:42.600]  быть. Ну то есть это некоторая механика, которая
[01:53:42.600 --> 01:53:46.600]  наблюдается человеком, условно, как reordering. Ну вот
[01:53:46.600 --> 01:53:50.600]  представьте себе программу, у тебя есть два потока,
[01:53:50.600 --> 01:53:53.600]  четыре потока на четырех ядрах, первые два потока
[01:53:53.600 --> 01:53:57.600]  пишут, один пишет в X, один, другой пишет в Y, один, а
[01:53:57.600 --> 01:54:02.600]  два других читают Y, X, X, Y в разном порядке, и видят
[01:54:02.600 --> 01:54:08.600]  оба потока, третий, четвертый, что они читают 1, 0, 1, 0.
[01:54:08.600 --> 01:54:10.600]  Вот скажем такие исполнения, они даже reordering'ом не
[01:54:10.600 --> 01:54:15.600]  объясняются. Ну ладно, объясняются, можно как будто
[01:54:15.600 --> 01:54:18.600]  бы чтение переставить. Но опять, вот механика другая,
[01:54:18.600 --> 01:54:20.600]  просто две записи приехали на два других ядра в разном
[01:54:20.600 --> 01:54:27.600]  порядке. Но это все такая условность.
[01:54:27.600 --> 01:54:31.600]  Еще раз, пока ты говоришь там неформально, что вот
[01:54:31.600 --> 01:54:33.600]  что-то происходит странное, ты говоришь про reordering'и
[01:54:33.600 --> 01:54:36.600]  и про барьеры. Но когда ты начинаешь говорить честно,
[01:54:36.600 --> 01:54:44.600]  то ты говоришь, что вот в X86 на самом деле вот так вот,
[01:54:44.600 --> 01:54:48.600]  а инструкция MFN, которая барьер, она что делает? Она
[01:54:48.600 --> 01:54:51.600]  флажит буфер. Вот это уже честный ответ. Но он просто
[01:54:51.600 --> 01:54:54.600]  очень специфичен для вот конкретного процессора.
[01:54:54.600 --> 01:55:00.600]  Для другого там будет что-то по-другому. Так что мы
[01:55:00.600 --> 01:55:03.600]  неформально про reordering'и говорим, понимаем при этом,
[01:55:03.600 --> 01:55:08.600]  что это действительно все не так. И вот конкретно в каждом
[01:55:08.600 --> 01:55:11.600]  процессоре свои причины. И вот ровно поэтому слайды
[01:55:11.600 --> 01:55:14.600]  вначале объясняют, как именно это произошло, что это
[01:55:14.600 --> 01:55:17.600]  не перестановка инструкции местами. А дальше мы вообще
[01:55:17.600 --> 01:55:20.600]  от этого отказываемся, от такого типа мышления,
[01:55:20.600 --> 01:55:24.600]  и заменяем себе модель операционную в голове на
[01:55:24.600 --> 01:55:27.600]  декларативную, где мы оперируем какими-то гарантиями,
[01:55:27.600 --> 01:55:30.600]  которые у нас точно есть. Что у нас есть некоторые
[01:55:30.600 --> 01:55:33.600]  частичные порядки, и чтение в программе с этими частичными
[01:55:33.600 --> 01:55:40.600]  порядками согласовано. И вот на это мы уже можем полагаться
[01:55:40.600 --> 01:55:45.600]  в своих рассуждениях. Вот замысел был такой.
[01:55:49.600 --> 01:55:52.600]  Ну какие еще вопросы? Миллион вопросов можно задавать.
[01:55:52.600 --> 01:55:55.600]  Там сто пятьсот слайдов.
[01:55:55.600 --> 01:55:59.600]  На самом деле это была самая большая проблема в видео.
[01:55:59.600 --> 01:56:03.600]  Я даже не понимал, что иордэнг просто обобщает
[01:56:03.600 --> 01:56:06.600]  проблемы между всеми.
[01:56:09.600 --> 01:56:14.600]  Смотри, в лекции иордэнг используется почти нигде,
[01:56:14.600 --> 01:56:17.600]  но по крайней мере в той части, где мы говорим про
[01:56:17.600 --> 01:56:20.600]  тресвой замысел. Мы сначала демонстрируем, что
[01:56:20.600 --> 01:56:23.600]  исполнение программы отличается от наших наивных
[01:56:23.600 --> 01:56:26.600]  ожиданий. Что у нас есть компедиатор, который может
[01:56:26.600 --> 01:56:29.600]  представить местами две строчки. У нас есть процессор,
[01:56:29.600 --> 01:56:32.600]  который может две строчки даже в правильном порядке
[01:56:32.600 --> 01:56:35.600]  написанные исполнить как-то альтернативно.
[01:56:41.600 --> 01:56:44.600]  Но они так исполняются. Мы делаем запись, и про нее
[01:56:44.600 --> 01:56:47.600]  не знают другие процессоры. Это не похоже на запись
[01:56:47.600 --> 01:56:49.600]  памяти все же.
[01:56:49.600 --> 01:56:53.600]  Нет, мы этого всего не видим, но еще раз. Этот слайд
[01:56:53.600 --> 01:56:56.600]  про то, чтобы объяснить, как оно работает. А то,
[01:56:56.600 --> 01:56:59.600]  что мы видим, тут говорится в мануале, что как будто
[01:56:59.600 --> 01:57:02.600]  бы мы преордали две инструкции для наблюдателей, ну
[01:57:02.600 --> 01:57:06.600]  в смысле, мы процессор. Но поинт всего этого совсем
[01:57:06.600 --> 01:57:09.600]  не в том, что как именно инструкции упорядочиваются,
[01:57:09.600 --> 01:57:12.600]  а в том, что мы просто не можем полагаться на модели
[01:57:12.600 --> 01:57:15.600]  чередования. А дальше мы разбираемся, а как же
[01:57:15.600 --> 01:57:19.600]  тогда вообще жить, как можно прогнозировать, как
[01:57:19.600 --> 01:57:22.600]  можно предсказывать, как процессор будет исполнять
[01:57:22.600 --> 01:57:26.600]  наш код. Вот нам нужна для этого модель памяти. И вот
[01:57:26.600 --> 01:57:31.600]  можно говорить про операционные модели памяти, вот такие,
[01:57:31.600 --> 01:57:35.600]  а можно говорить про декларативные вот такие. И вот мы
[01:57:35.600 --> 01:57:38.600]  двумя способами объясняем, как же все происходит. И
[01:57:38.600 --> 01:57:41.600]  вот тут уже слово «реордеринг» нигде не проходит.
[01:57:41.600 --> 01:57:44.600]  Потому что вот есть один стиль, другой стиль, и
[01:57:44.600 --> 01:57:48.600]  как бы ты пользуешься тем, который, ну там, тебе в данной
[01:57:48.600 --> 01:57:51.600]  задаче больше подходит. Если ты пишешь на C++ какое-то
[01:57:51.600 --> 01:57:53.600]  кроссплатформенное приложение, то ты пользуешься декларативным
[01:57:53.600 --> 01:57:57.600]  моделем памяти языка. Если ты пишешь там, не знаю,
[01:57:57.600 --> 01:58:01.600]  что-то прямо для конкретного процессора там на каком-нибудь
[01:58:01.600 --> 01:58:06.600]  древнем C, то ты используешь операционный модель процессора.
[01:58:06.600 --> 01:58:09.600]  Оно тебя предсказывает, что может пойти не так.
[01:58:09.600 --> 01:58:12.600]  К сожалению, как все будет исполняться на самом деле.
[01:58:12.600 --> 01:58:20.600]  — Когда у меня еще один вопрос, может, существует еще
[01:58:20.600 --> 01:58:24.600]  и проживутся в доступной и другие там…
[01:58:24.600 --> 01:58:27.600]  — Да. — …меморы и ордеры, и мы можем
[01:58:27.600 --> 01:58:31.600]  в них воспользоваться только из атомика.
[01:58:31.600 --> 01:58:34.600]  — Да. — То есть, если мы пишем обычные
[01:58:34.600 --> 01:58:37.600]  переменные, возможно, что мы получим какая-либо
[01:58:37.600 --> 01:58:40.600]  неиспользованная атомика, там везде используются
[01:58:40.600 --> 01:58:43.600]  ассоциации на системе? — Нет, ты ничего не понял,
[01:58:43.600 --> 01:58:51.600]  к сожалению. Смотри, тут 150 слайдов, и тут нет почти
[01:58:51.600 --> 01:58:54.600]  неважных. Каждый из них сообщает какую-то мысль,
[01:58:54.600 --> 01:58:57.600]  сложно в углу держать аппарат.
[01:58:57.600 --> 01:59:01.600]  В чем вообще была идея нашей модели памяти,
[01:59:01.600 --> 01:59:05.600]  которую мы строили? Вот sequential consistency, мы говорили,
[01:59:05.600 --> 01:59:07.600]  что для того, чтобы все было хорошо, нам нужно
[01:59:07.600 --> 01:59:10.600]  расставить много барьеров. Значнее, у нас есть
[01:59:10.600 --> 01:59:12.600]  простая модель, которую мы хотим получить, sequential
[01:59:12.600 --> 01:59:15.600]  consistency. То есть, как будто бы все происходит
[01:59:15.600 --> 01:59:18.600]  в глобальном порядке, потоки иногда переключаются
[01:59:18.600 --> 01:59:21.600]  друг на друга. То есть, у нас есть простые модели,
[01:59:21.600 --> 01:59:24.600]  которые мы хотим получить, sequential consistency.
[01:59:24.600 --> 01:59:30.600]  Но беда в том, что процессор так не работает, он не
[01:59:30.600 --> 01:59:34.600]  sequential consistent, и нам нужно расставить барьеры.
[01:59:34.600 --> 01:59:38.600]  Опять, момент неформальный, нужно помнить слайды как
[01:59:38.600 --> 01:59:41.600]  формальные и неформальные, строгие и нестрогие.
[01:59:41.600 --> 01:59:44.600]  Это опять нестрогий слайд, что упрощенно барьеры,
[01:59:44.600 --> 01:59:47.600]  написано, что упрощенно, барьеры запрещают отдельно
[01:59:47.600 --> 01:59:52.600]  идти при ордерингах. К твоей неточной модели есть
[01:59:52.600 --> 01:59:57.600]  неточный инструмент, упрощенный модели с реордерингом,
[01:59:57.600 --> 02:00:01.600]  есть упрощенный инструмент барьеры, который помогает
[02:00:01.600 --> 02:00:06.600]  упорядочивать что-то. Дальше вопрос, где эти барьеры
[02:00:06.600 --> 02:00:10.600]  ставить? У нас получается проблема. С одной стороны,
[02:00:10.600 --> 02:00:14.600]  мы хотим быструю программу, с другой стороны, мы хотим
[02:00:14.600 --> 02:00:17.600]  программу последовательно согласованную, поэтому нам
[02:00:17.600 --> 02:00:22.600]  нужно много барьеров. Мы не можем себе позволить
[02:00:22.600 --> 02:00:27.600]  ставить барьеры между каждой парой соседних инструкций.
[02:00:27.600 --> 02:00:32.600]  Это важный момент, переломный момент лекции, где решения
[02:00:32.600 --> 02:00:36.600]  принимаются, что же мы делаем. Мы не хотим ни оптимизациями
[02:00:36.600 --> 02:00:39.600]  жертвовать, не ставить много барьеров между всеми
[02:00:39.600 --> 02:00:43.600]  инструкциями, не терять простую семантику для программ
[02:00:43.600 --> 02:00:45.600]  многопроточных. Поэтому мы говорим, что мы просто
[02:00:45.600 --> 02:00:49.600]  отказываемся от некоторых программ и обеспечиваем
[02:00:49.600 --> 02:00:52.600]  видимость последовательного исполнения только для
[02:00:52.600 --> 02:00:56.600]  разумных программ без гонок. И вот почему... Ещё один
[02:00:56.600 --> 02:01:00.600]  важный слайд. Они все одинаково важны. Почему это
[02:01:00.600 --> 02:01:03.600]  должно нам помочь? Потому что если программа
[02:01:03.600 --> 02:01:07.600]  корректно синхронизирована, то окажется, что в ней
[02:01:07.600 --> 02:01:10.600]  для видимости последовательного исполнения достаточно
[02:01:10.600 --> 02:01:14.600]  будет расставить только очень немного барьеров. И вот
[02:01:14.600 --> 02:01:18.600]  эти барьеры будут в тех местах, где выполняется
[02:01:18.600 --> 02:01:23.600]  синхронизация, то есть в атомиках. Весь наш замысел
[02:01:23.600 --> 02:01:26.600]  состоит в том, что мы, отказываясь от произвольной программы,
[02:01:26.600 --> 02:01:29.600]  ограничивая себя только хорошими в некотором смысле,
[02:01:29.600 --> 02:01:34.600]  можем в итоге расставить барьеры памяти только там,
[02:01:34.600 --> 02:01:39.600]  где выполняется синхронизация. А синхронизацию мы
[02:01:39.600 --> 02:01:44.600]  обозначаем явно в виде атомиков. Вот. И дальше
[02:01:44.600 --> 02:01:46.600]  оказывается, что к империатору, но в самом конце
[02:01:46.600 --> 02:01:54.600]  оказывается, что к империатору нужно вот ставить
[02:01:54.600 --> 02:01:57.600]  барьеры только здесь. Что вот здесь он может творить
[02:01:57.600 --> 02:02:00.600]  с этими записями всё, что хочет. Буферизировать их,
[02:02:00.600 --> 02:02:03.600]  там не отравить память. Пока он не встретил запись
[02:02:03.600 --> 02:02:08.600]  в атомик и барьер, он может копить записи в своём
[02:02:08.600 --> 02:02:11.600]  storebuffer. Но когда он встретит барьеры, он всё-таки должен
[02:02:11.600 --> 02:02:15.600]  их сбросить так, чтобы здесь, код, который прочёл
[02:02:15.600 --> 02:02:20.600]  эту запись, увидел и вот эти записи тоже. И вот здесь
[02:02:20.600 --> 02:02:22.600]  никаких барьеров больше не нужно. Барьеры нужны
[02:02:22.600 --> 02:02:26.600]  вот где-то вот в этих местах, точка синхронизации.
[02:02:26.600 --> 02:02:29.600]  Поэтому их будет очень мало, и ровно поэтому memory
[02:02:29.600 --> 02:02:33.600]  order существует именно в атомике. Поэтому memory order
[02:02:33.600 --> 02:02:36.600]  — это аргумент атомика. Потому что вот ровно в этих
[02:02:36.600 --> 02:02:39.600]  местах ставятся барьеры, и ты с помощью memory order
[02:02:39.600 --> 02:02:42.600]  регулируешь, насколько они, условно говоря, должны
[02:02:42.600 --> 02:02:46.600]  быть сильными. Вот. А в других функциях никаких
[02:02:46.600 --> 02:02:50.600]  барьеров, конечно же, нет. Но потому что компилиратор
[02:02:50.600 --> 02:02:53.600]  же компилирует эти функции просто вот как отдельные
[02:02:53.600 --> 02:02:56.600]  кусочки. И, представь, что он бы там пихал барьеры,
[02:02:56.600 --> 02:02:59.600]  он тогда и в однопоточной программе барьеры бы пихал,
[02:02:59.600 --> 02:03:02.600]  это было бы очень странно. Нет, ему нужна наша помощь,
[02:03:02.600 --> 02:03:05.600]  в смысле ему компилиатору, чтобы мы сказали явно,
[02:03:05.600 --> 02:03:10.600]  при обращении к каким ячейкам происходит синхронизация.
[02:03:10.600 --> 02:03:13.600]  Вот мы эти ячейки обозначаем атомиками, и компилиатор
[02:03:13.600 --> 02:03:17.600]  вот именно там разбрасывает барьеры. Где-то про это
[02:03:17.600 --> 02:03:20.600]  тоже был слой.
[02:03:35.600 --> 02:03:39.600]  Вот это был наш замысел, вот так и оказалось. То есть
[02:03:39.600 --> 02:03:42.600]  вот мы ограничились, конечно, синхронизированными
[02:03:42.600 --> 02:03:45.600]  программами, потому что барьеры нужны только там.
[02:03:45.600 --> 02:03:48.600]  Во всех остальных не нужны, и, например, мы получаем
[02:03:48.600 --> 02:03:51.600]  видимость последовательного исполнения. Это ли не успех
[02:03:51.600 --> 02:03:58.600]  для нас? То есть барьеров в программе будет мало, они
[02:03:58.600 --> 02:04:01.600]  будут только в атомиках. Ну и если нам очень хочется,
[02:04:02.600 --> 02:04:07.600]  то мы еще можем их оптимизировать, если мы понимаем
[02:04:07.600 --> 02:04:10.600]  как, если мы умеем пользоваться формальными гарантиями.
[02:04:22.600 --> 02:04:24.600]  Ну, продолжай задавать вопросы. Мне кажется, что
[02:04:24.600 --> 02:04:27.600]  чем больше ты говоришь, тем больше мы проясняем
[02:04:27.600 --> 02:04:37.600]  картины. Я объясню немного замысел лекции. Лекция
[02:04:37.600 --> 02:04:39.600]  почти ничего не говорит про Memory Order, что, возможно,
[02:04:39.600 --> 02:04:44.600]  нам... Можно было бы представить, что вам полезнее всего
[02:04:44.600 --> 02:04:47.600]  знать Memory Order, расставить, в конце концов. Вам это
[02:04:47.600 --> 02:04:49.600]  хочется сделать, программу оптимизировать. Но с другой
[02:04:49.600 --> 02:04:51.600]  стороны, чтобы разумно пользоваться материю памяти,
[02:04:51.600 --> 02:04:54.600]  нужно понимать на таком глубоком интуитивном уровне,
[02:04:54.600 --> 02:04:57.600]  почему она такая, почему она такими вообще сущностями
[02:04:57.600 --> 02:05:01.600]  оперирует, как в порядке вот эти Happens Before. Вот лекция
[02:05:01.600 --> 02:05:03.600]  про то, как построить материю памяти, в принципе, чтобы
[02:05:03.600 --> 02:05:05.600]  она казалась интуитивной, чтобы было понятно, почему
[02:05:05.600 --> 02:05:08.600]  все, откуда все это берется. Пользоваться ей без вот
[02:05:08.600 --> 02:05:13.600]  этой интуиции, без того, соотношение ее с реальностью
[02:05:13.600 --> 02:05:18.600]  очень сложно. Это все выродится в какие-то такие наивные
[02:05:18.600 --> 02:05:21.600]  рецепты. А мы хотим понимать по существу.
[02:05:24.600 --> 02:05:32.600]  Если мы в той программе, где, в принципе, в том процессоре,
[02:05:32.600 --> 02:05:38.600]  где мы читаем из векса Y и пишем в первый день этого,
[02:05:38.600 --> 02:05:44.600]  мы заменим на оптиминге, и не будем передавать отдельную
[02:05:44.600 --> 02:05:47.600]  версию. Сейчас, но вот есть программа такая.
[02:05:47.600 --> 02:05:51.600]  Да, если мы не релиз, а мы так поставим, то у нас,
[02:05:52.600 --> 02:05:56.600]  ну да, потому что одно из требований, которые мы выдвинули,
[02:05:56.600 --> 02:05:59.600]  это глобальный сквозной порядок на всех обращениях
[02:05:59.600 --> 02:06:04.600]  к атомикам. Он назывался Synchronization Order. Это была
[02:06:04.600 --> 02:06:06.600]  последняя гарантия, которую мы потребовали.
[02:06:10.600 --> 02:06:13.600]  Вот, мы требуем упорядочить все обращения ко всем
[02:06:13.600 --> 02:06:14.600]  Тамарным переменным.
[02:06:14.600 --> 02:06:20.600]  В этой программе это гарантируется. А для программы,
[02:06:20.600 --> 02:06:26.600]  где атомиков нет, там ничего не гарантируется.
[02:06:26.600 --> 02:06:31.600]  Там процессор выполняет storebuffering, то есть бюферизирует
[02:06:31.600 --> 02:06:35.600]  записи в кошах процессора, перед кошами процессора,
[02:06:35.600 --> 02:06:39.600]  перед кошами процессора, перед протоколом гириантности,
[02:06:39.600 --> 02:06:41.600]  и в итоге программа разваливается.
[02:06:44.600 --> 02:06:49.600]  Ну, он нужен для того, чтобы, то есть мы ставим барьеры, тем самым
[02:06:49.600 --> 02:06:52.600]  говорим, что вот компилятор точно расставил эти записи
[02:06:52.600 --> 02:06:56.600]  в таком порядке, в смысле, что компилятор не переставил
[02:06:56.600 --> 02:06:58.600]  дверить строчки, потому что тогда было непонятно, кто
[02:06:58.600 --> 02:07:02.600]  виноват. Но вот виноват точно процессор. Ну, смотри, тут
[02:07:02.600 --> 02:07:08.600]  можно раскомментировать mfence, вот, и все, по идее, должно
[02:07:08.600 --> 02:07:09.600]  работать, действительно.
[02:07:14.600 --> 02:07:18.600]  Ну, потому что там atomic store, он, ну, напишет там либо
[02:07:18.600 --> 02:07:21.600]  exchange, либо этот mfence, напишет в зависимости от того,
[02:07:21.600 --> 02:07:25.600]  компилятор ты используешь. То есть мы это написали
[02:07:25.600 --> 02:07:30.600]  руками, а за нас это сделает компилятор в виде там
[02:07:30.600 --> 02:07:38.600]  атомарной операции. В C++, вообще говоря, есть некоторые
[02:07:38.600 --> 02:07:41.600]  совсем темные места, я про них мало что знаю, на самом
[02:07:41.600 --> 02:07:45.600]  деле, потому что они прям очень... ладно, не получилось.
[02:07:45.600 --> 02:07:56.600]  Потому что это прям совсем тонко. Вот там прямо есть
[02:07:56.600 --> 02:08:08.600]  некоторые функции барьеры. Вот, и, ну, короче, и такое
[02:08:08.600 --> 02:08:15.600]  там тоже есть. Ну, вот, если хочешь, да, ты можешь
[02:08:15.600 --> 02:08:22.600]  спуститься вот на самое дно этого ада, и, ну, к сожалению,
[02:08:22.600 --> 02:08:25.600]  в C++ там есть свои какие-то несогласованности в этой
[02:08:25.600 --> 02:08:27.600]  модели памяти, поэтому сложно сказать, что насколько
[02:08:27.600 --> 02:08:30.600]  хорошо это работает. Тут смотри какая ситуация, что
[02:08:30.600 --> 02:08:34.600]  с одной стороны, ну, замысел в слабых модели памяти, он
[02:08:34.600 --> 02:08:39.600]  очень разумен. Это тоже было, тоже был еще один важный
[02:08:39.600 --> 02:08:44.600]  слайд, еще один среди череды ста важных слайдов, что
[02:08:44.600 --> 02:08:48.600]  задумка слабых memory-order в том, чтобы ты, оптимизируя
[02:08:48.600 --> 02:08:52.600]  программу в них, в декларативной модели, то есть минимизируя
[02:08:52.600 --> 02:08:54.600]  порядки, которые в твоей декларативной, ну, в графе
[02:08:54.600 --> 02:08:58.600]  появляются, ты тем самым бы оптимизировал программу
[02:08:58.600 --> 02:09:02.600]  на конкретном процессоре. То есть ты оптимизируешь
[02:09:02.600 --> 02:09:05.600]  программу в теории, в декларативной модели, а потом
[02:09:05.600 --> 02:09:07.600]  компилятор для нее генерирует, оказывается, оптимальный
[02:09:07.600 --> 02:09:14.600]  код. Вот. Ну, вот это работает, на самом деле, не всегда,
[02:09:14.600 --> 02:09:18.600]  но, по крайней мере, просто потому что есть вот физическая
[02:09:18.600 --> 02:09:21.600]  реальность, есть математическая модель, и не то чтобы
[02:09:21.600 --> 02:09:24.600]  математическая модель вот прям идеально вписывается
[02:09:24.600 --> 02:09:28.600]  в эту вот странную произвольную, порожденную человеком
[02:09:28.600 --> 02:09:32.600]  физическую, ну, реальность. Где-то не очень вписывается.
[02:09:32.600 --> 02:09:35.600]  Ну, и тогда возникают какие-то вот странные, странные
[02:09:35.600 --> 02:09:39.600]  штуки. Вот фенс это как раз вот такой способ, когда
[02:09:39.600 --> 02:09:42.600]  модели не совсем хватает, нужно вот ее докрутить, чтобы
[02:09:42.600 --> 02:09:44.600]  можно было сделать еще оптимально.
[02:09:44.600 --> 02:09:47.600]  — Как получается, мы ждем, пока приданут для этой модели
[02:09:47.600 --> 02:09:50.600]  памяти все процессоры?
[02:09:50.600 --> 02:09:54.600]  — Ну, тут двусторонний процесс, с одной стороны,
[02:09:54.600 --> 02:09:57.600]  модель памяти придумывают, чтобы она лучше описывала
[02:09:57.600 --> 02:10:00.600]  процессоры и как бы лучше вписывалась в их оптимизации,
[02:10:00.600 --> 02:10:03.600]  в оптимизации компилиатора. А с другой стороны, компилиаторы
[02:10:03.600 --> 02:10:06.600]  и процессоры тоже должны как-то учитывать, что их пытаются
[02:10:06.600 --> 02:10:09.600]  описать математически и тоже не делать совсем уж диких
[02:10:09.600 --> 02:10:14.600]  вещей. Вот мир в этом направлении движется такими
[02:10:14.600 --> 02:10:19.600]  итерациями. Вот две эти реальности, математическая
[02:10:19.600 --> 02:10:24.600]  и аппаратная, они влияют друг на друга каким-то образом.
[02:10:24.600 --> 02:10:30.600]  Но про это есть хорошая статья в референсах. Вот первая,
[02:10:30.600 --> 02:10:40.600]  вторая. Правда, кажется, по его образовался посылки.
[02:10:47.600 --> 02:10:49.600]  Медленно.
[02:10:55.600 --> 02:10:58.600]  У нас просто сломался интернет.
[02:11:16.600 --> 02:11:20.600]  Ну вот, как раз про то, почему модели памяти такие,
[02:11:20.600 --> 02:11:24.600]  как они пытаются текущая железа описать.
[02:11:35.600 --> 02:11:38.600]  Ну да, мы причем на лекции даже это показывали.
[02:11:45.600 --> 02:11:48.600]  Сейчас нет, на армах там все.
[02:11:50.600 --> 02:11:59.600]  На армах там сложные сценарии реализуются, какие-то
[02:11:59.600 --> 02:12:03.600]  очень подозрительные. Все потому, что у тебя там целая
[02:12:03.600 --> 02:12:06.600]  иерархия кэшей, у них еще есть какие-то общие старбаферы
[02:12:06.600 --> 02:12:10.600]  и все это как-то. Ну короче, там в операционной модели
[02:12:10.600 --> 02:12:17.600]  предлагается думать про то, что записи и чтения, ну то
[02:12:17.600 --> 02:12:20.600]  у нас будет дерево, и записи и чтения ползут к памяти
[02:12:20.600 --> 02:12:23.600]  вверх по этому дереву, до корня, ну и могут иногда
[02:12:23.600 --> 02:12:26.600]  встречаться, и вот чтение тогда прочтет запись, которая
[02:12:26.600 --> 02:12:29.600]  еще до памяти не доехала. И вот они все это в разных
[02:12:29.600 --> 02:12:31.600]  поддеревьях работают, как-то странно перемешиваются
[02:12:31.600 --> 02:12:33.600]  друг с другом, и получается какие-то маргинальные
[02:12:33.600 --> 02:12:37.600]  исполнения. Ну вот еще один пример операционной модели,
[02:12:37.600 --> 02:12:41.600]  которая по-другому устроена, позволяет больше таких
[02:12:41.600 --> 02:12:44.600]  странных поведений, ну больше ревордерингов, так условно
[02:12:44.600 --> 02:13:08.600]  нет. Нет, но модели памяти мало кто понимает, в основном
[02:13:08.600 --> 02:13:12.600]  пользуются какими-то рецептами, такими наивными,
[02:13:12.600 --> 02:13:16.600]  какими-то готовыми паттернами, ну либо рассуждают, ну я
[02:13:16.600 --> 02:13:18.600]  объясню на следующем семинаре, ну или на каком-то
[02:13:18.600 --> 02:13:22.600]  семинаре, как рассуждают несколько наивно. Вот можно
[02:13:22.600 --> 02:13:26.600]  себе позволить такую модель, ну это не модель памяти,
[02:13:26.600 --> 02:13:29.600]  то есть модель рассуждений, которая в принципе разумна
[02:13:29.600 --> 02:13:34.600]  сама по себе, но не точна, и вот лучше бы ее запретить.
[02:13:35.600 --> 02:13:40.600]  Ну короче, люди как-то пользуются этим. Ну вот ты читал
[02:13:40.600 --> 02:13:43.600]  себе перереференс про memory orders, наверное, до лекции,
[02:13:43.600 --> 02:13:48.600]  и вряд ли, ну скорее всего на лекции я тебе по-другому
[02:13:48.600 --> 02:13:51.600]  что-то рассказывал, очень сильно по-другому, потому
[02:13:51.600 --> 02:13:54.600]  что непонятно откуда все это берется иначе. Ну вот
[02:13:54.600 --> 02:13:56.600]  если человек будет просто читать перереференс или
[02:13:56.600 --> 02:14:00.600]  еще хуже стандарт языка, то я боюсь, что там никакого
[02:14:00.600 --> 02:14:05.600]  понимания точно не сложится. Но рядовому программисту
[02:14:05.600 --> 02:14:09.600]  это и не нужно, если, опять про это тоже был слайд,
[02:14:09.600 --> 02:14:13.600]  последний слайд вообще в лекции, про то, что вот
[02:14:13.600 --> 02:14:15.600]  просто не нужно делать ничего сложного, и тогда можно
[02:14:15.600 --> 02:14:18.600]  об этом не думать. Ну а если ты используешь Atomic все-таки
[02:14:18.600 --> 02:14:22.600]  со слабыми моделями, то у тебя должны быть на это
[02:14:22.600 --> 02:14:25.600]  какие-то основания, ты должен хорошо понимать, как все
[02:14:25.600 --> 02:14:28.600]  работает. То есть ты просто так в беду не попадешь, пока
[02:14:28.600 --> 02:14:32.600]  ты сам не захочешь себе выстрелить в ногу вот таким
[02:14:32.600 --> 02:14:36.600]  образом, ты, с тобой ничего плохого не случится. Так что
[02:14:36.600 --> 02:14:40.600]  Atomic тебе, ну то есть как бы Default Memory Order защищает
[02:14:40.600 --> 02:14:43.600]  человека, который не понимает, как это все работает, от
[02:14:43.600 --> 02:14:46.600]  потенциальных проблем. Ну а если ты решаешь оптимизировать,
[02:14:46.600 --> 02:14:48.600]  то ты видимо разбираешься, что происходит.
[02:14:52.600 --> 02:14:56.600]  Нет, еще раз, у нас была гарантия, ну смотри, чем мы
[02:14:56.600 --> 02:15:00.600]  делали всю лекцию. Мы строили такой набор требований,
[02:15:00.600 --> 02:15:04.600]  которые в совокупности давал бы видимость
[02:15:04.600 --> 02:15:07.600]  последовательного исполнения. И вот, мы построили такую
[02:15:07.600 --> 02:15:11.600]  штуку, в которой если мы используем, если программа
[02:15:11.600 --> 02:15:15.600]  корректно синхронизирована, и если в ней используются
[02:15:15.600 --> 02:15:21.600]  только Atomic с Default Memory Order, на которых в итоге получается
[02:15:21.600 --> 02:15:24.600]  Synchronization Order, то есть сквозной порядок всех обращений,
[02:15:24.600 --> 02:15:27.600]  то для человека это все выглядит как просто
[02:15:27.600 --> 02:15:30.600]  исполнение программы, где потоки просто чередуются.
[02:15:39.600 --> 02:15:44.600]  Нет, зачем? Ну если ты пишешь однопоточный код,
[02:15:44.600 --> 02:15:49.600]  то у тебя есть... Ну я, кстати, субботы реакции немного
[02:15:49.600 --> 02:15:52.600]  поменял, я вышки читал в понедельник и сделаю немного лучше.
[02:15:52.600 --> 02:15:57.600]  С чего мы начинали? Мы начинали строить модели памяти
[02:15:57.600 --> 02:16:11.600]  с... вот с Modification Order потом, Happens Before потом...
[02:16:11.600 --> 02:16:13.600]  Вот нужно начинать с Program Order, конечно.
[02:16:13.600 --> 02:16:16.600]  Вот Program Order — это такая базовая гарантия, которая
[02:16:16.600 --> 02:16:18.600]  дается тебе компилиатором даже. То есть компилиатор
[02:16:18.600 --> 02:16:22.600]  может что-то переставить местами, но он гарантирует,
[02:16:22.600 --> 02:16:27.600]  что даже если он что-то переставит местами, то
[02:16:27.600 --> 02:16:31.600]  чтения будут согласованы с порядком обращения просто
[02:16:31.600 --> 02:16:34.600]  в тексте программы. Если ты сделал запись, а потом
[02:16:34.600 --> 02:16:37.600]  сделал чтение своей записи, то ты должен ее, разумеется,
[02:16:37.600 --> 02:16:47.600]  увидеть. Ну давай я сейчас покажу тебе, что я имею в виду.
[02:16:47.600 --> 02:16:49.600]  Это вот базовая гарантия, на которую ты полагаешься
[02:16:49.600 --> 02:16:52.600]  и которая тебе дается бесплатно. То есть ее не нужно как-то
[02:16:52.600 --> 02:16:56.600]  форсировать с помощью барьеров или чего-то подобного.
[02:16:56.600 --> 02:16:59.600]  Но сегодня ничего не работает.
[02:17:09.600 --> 02:17:12.600]  Было бы приятно это показать.
[02:17:17.600 --> 02:17:21.600]  Так, и мы выберем какой-нибудь.
[02:17:48.600 --> 02:17:53.600]  Ну вот, мы сначала записали в B, потом записали в A.
[02:17:53.600 --> 02:17:58.600]  Да? Видно? Вот. Ну компилиатор так мог сделать, потому
[02:17:58.600 --> 02:18:03.600]  что кажется он не ломает. Мы тут вообще ничего не
[02:18:03.600 --> 02:18:06.600]  читаем по сути. Точнее мы читаем B перед записью B,
[02:18:06.600 --> 02:18:08.600]  и конечно тут чтение перед записью выполняется.
[02:18:08.600 --> 02:18:11.600]  Все это компилиатор соблюдает. Ну а теперь мы сделаем
[02:18:11.600 --> 02:18:14.600]  что-нибудь такое.
[02:18:17.600 --> 02:18:24.600]  И кажется, если он переставит снова, то программа наша
[02:18:24.600 --> 02:18:27.600]  поломается.
[02:18:35.600 --> 02:18:41.600]  Вот, теперь он пишет сначала в A, а потом он пишет в B.
[02:18:41.600 --> 02:18:51.600]  Увидим. Ну он стер вызов, да, и теперь снова пишет
[02:18:51.600 --> 02:18:55.600]  неправильно в порядке.
[02:18:55.600 --> 02:18:59.600]  А что если мы напечатаем только A?
[02:18:59.600 --> 02:19:01.600]  Сейчас, только...
[02:19:01.600 --> 02:19:04.600]  А, ну нет, чтобы мы не напечатали, он все равно должен
[02:19:04.600 --> 02:19:07.600]  перестать.
[02:19:07.600 --> 02:19:10.600]  Да неважно.
[02:19:10.600 --> 02:19:14.600]  Не знаю, я не понял, что ты имеешь в виду, в смысле зачем?
[02:19:24.600 --> 02:19:27.600]  Но он не может здесь в B написать единицу, потому что
[02:19:27.600 --> 02:19:31.600]  он же должен ожидать там ноль.
[02:19:31.600 --> 02:19:35.600]  Вот. Так что вот этот программ order — это бесплатная
[02:19:35.600 --> 02:19:38.600]  для нас гарантия, самая базовая, которую мы имеем
[02:19:38.600 --> 02:19:42.600]  У нас чтение согласовано с порядком обращения в...
[02:19:42.600 --> 02:19:45.600]  У нас порядок исполнения не обязательно совпадает.
[02:19:45.600 --> 02:19:48.600]  Порядок исполнения в отдельном потоке не обязательно
[02:19:48.600 --> 02:19:50.600]  совпадает с программом order, то есть с тем
[02:19:50.600 --> 02:19:53.600]  порядком, который мы написали. Но чтение согласовано
[02:19:53.600 --> 02:19:56.600]  с ним. То есть чтение читает, как минимум, последнюю
[02:19:56.600 --> 02:20:00.600]  запись программ order. Не может что-то другое прочесть.
[02:20:00.600 --> 02:20:03.600]  Вот. А дальше мы этот программ order обобщаем
[02:20:03.600 --> 02:20:06.600]  на разные потоки через synchronize this with на
[02:20:06.600 --> 02:20:10.600]  happens before. То есть у нас есть причинность в одном
[02:20:10.600 --> 02:20:14.600]  потоке, она достигается бесплатно. А есть причинность
[02:20:14.600 --> 02:20:17.600]  между разными потоками. И она уже достигается вот
[02:20:17.600 --> 02:20:21.600]  с помощью там барьеров в атомиках для синхронизации.
[02:20:21.600 --> 02:20:26.600]  При синхронизации. Вот-вот. Вот здесь вот.
[02:20:26.600 --> 02:20:30.600]  И вот эта бесплатная гарантия, потому что она есть в...
[02:20:30.600 --> 02:20:32.600]  она соблюдается для однопоточных программ просто.
[02:20:32.600 --> 02:20:34.600]  Ты компьютируешь код, и она у тебя есть, потому что
[02:20:34.600 --> 02:20:43.600]  И вот эта бесплатная гарантия, потому что она соблюдается для однопоточных программ просто.
[02:20:43.600 --> 02:20:49.600]  Ты компьютируешь код, и она у тебя есть, потому что компилятор просто знает, что он уважает зависимости.
[02:20:49.600 --> 02:20:59.600]  Вот у тебя есть запись в A, а потом есть чтение A. И вот между двумя инструкциями есть зависимость.
[02:20:59.600 --> 02:21:07.600]  Вторая инструкция, которая читает A, зависит от предшествующей записи в A.
[02:21:07.600 --> 02:21:16.600]  Ну вот порядок между ними сохранен. Или ты, не знаю, читаешь ячейку памяти, а потом читаешь регистр,
[02:21:16.600 --> 02:21:22.600]  а потом сравниваешь значения в этом регистре с каким-то... Ну короче, делаешь условный переход или не делаешь.
[02:21:22.600 --> 02:21:28.600]  Ну опять там... А дальше внутри делаешь запись B. И вот у тебя есть снова зависимость по контролю
[02:21:28.600 --> 02:21:32.600]  между двумя этими обращениями. Ты тоже их не можешь иордрить.
[02:21:32.600 --> 02:21:41.600]  Вот компилятор это все уважает. Процессор тоже тут ничего не ломает, кажется, так что...
[02:21:41.600 --> 02:21:45.600]  Для однопоточных программ все бесплатно. Ну то есть однопоточные программы – это первое,
[02:21:45.600 --> 02:21:51.600]  на что ориентируется процессор, и они и процессоры компилятора из коробки однопоточной программы не ломают.
[02:21:51.600 --> 02:21:55.600]  Но их оптимизации становятся видны тогда, когда программа становится многопоточной.
[02:21:55.600 --> 02:22:00.600]  И тогда уже мы видим вот какие-то эвристики, которые раньше работали, а теперь...
[02:22:00.600 --> 02:22:03.600]  Раньше были незаметные, а теперь стали наблюдаемыми.
[02:22:15.600 --> 02:22:20.600]  Давайте продолжим серию вопросов. Пока все идет хорошо.
[02:22:32.600 --> 02:22:40.600]  Так а зачем по-твоему эта лекция нужна? Вот с этого момента ты видишь атомик, ты можешь там memory-order писать.
[02:22:40.600 --> 02:22:47.600]  Ну это же просто инструмент, как вот ты пишешь синхронизацию в курсе, и ты знаешь про там бьюток, секундвары.
[02:22:47.600 --> 02:22:53.600]  Ты им пользуешься, когда тебе нужно. Вот ты пишешь атомик, ты можешь в нем не писать memory-order,
[02:22:53.600 --> 02:22:58.600]  можешь написать memory-order, если ты умеешь объяснить, как именно, почему ты именно такое выбрал.
[02:22:58.600 --> 02:23:03.600]  Но мы по сути, мы пока не упражнялись в выборе, поэтому я бы тебе предостерег.
[02:23:03.600 --> 02:23:08.600]  Вот я через, ну не знаю, может быть на следующей неделе, может быть через две недели объясню,
[02:23:08.600 --> 02:23:16.600]  как эти гарантии, то есть чтобы применять memory-order, нужно хорошо понимать,
[02:23:16.600 --> 02:23:21.600]  во-первых, гарантии, которые они дают, во-вторых, как именно ими пользоваться.
[02:23:21.600 --> 02:23:27.600]  Вот мы через некоторое время поупражняемся в этом, то есть возьмем какие-то небольшие примеры,
[02:23:27.600 --> 02:23:32.600]  и в них будем рассуждать, какие гарантии нам нужны, чего мы ожидаем,
[02:23:32.600 --> 02:23:36.600]  и как с помощью вот memory-orders эти гарантии обеспечить.
[02:23:36.600 --> 02:23:41.600]  Какие оставшиеся четыре?
[02:23:41.600 --> 02:23:51.600]  Ну есть Consume и есть Aquari-Release. Consume это, Consume не нужен, но он Deprecate тоже.
[02:23:51.600 --> 02:23:58.600]  Это очень, Consume это неудачная попытка улучшить модель памяти.
[02:23:58.600 --> 02:24:06.600]  Она провалилась, Consume бесполезен, но, к сожалению, он сильно изуродовал математическую модель с собой.
[02:24:06.600 --> 02:24:09.600]  Но про это я расскажу, когда будет повод.
[02:24:09.600 --> 02:24:16.600]  И есть Aquari-Release, это всего лишь комбинация релиза Acquire для операций, которые выполняют чтение и запись.
[02:24:16.600 --> 02:24:21.600]  Если у тебя операция выполнена чтением и запись, то она может быть Acquire-чтением и Release-записью.
[02:24:21.600 --> 02:24:28.600]  Внимание, это не означает, что если у тебя операция и чтение и запись, то в них должны быть два memory-orders таких комбинаций.
[02:24:28.600 --> 02:24:30.600]  Просто могут быть.
[02:24:30.600 --> 02:24:36.600]  Но по смыслу это просто комбинация этих двух, то есть она не добавляет никаких новых гарантий.
[02:24:37.600 --> 02:24:45.600]  Тут все ортогонально, если ты понимаешь это и это, то ты просто комбинируешь с разных сторон.
[02:24:49.600 --> 02:24:52.600]  Ну, Acquire-чтение и Release-запись, что надо говорить.
[02:24:52.600 --> 02:25:00.600]  На семинаре про слабые модели мы это разберем и увидим, когда это нужно или когда не нужно, наоборот.
[02:25:01.600 --> 02:25:08.600]  Может быть еще какие-то общие вопросы есть не про слабые модели, потому что про них я сегодня ленюсь говорить.
[02:25:08.600 --> 02:25:11.600]  Мне нужно много времени.
[02:25:11.600 --> 02:25:18.600]  А про саму большую конструкцию, есть ли в ней что-то, что еще нужно пояснить.
[02:25:18.600 --> 02:25:46.600]  Ну вот нужно как-то схитриться и разом себе все представить, все эти 150 слайдов как-то в свое сознание загрузить, чтобы все было очень естественно, чтобы все было как-то на своих местах.
[02:25:46.600 --> 02:25:47.600]  Не знаю, как объяснить.
[02:25:51.600 --> 02:25:53.600]  У всего, что происходит, есть какая-то разумная мотивация.
[02:25:53.600 --> 02:26:00.600]  Каждый шаг, который мы здесь совершаем, он очень естественный, он очень интуитивен, потому что мы что делаем?
[02:26:00.600 --> 02:26:05.600]  Просто придумываем гарантии, причем придумываем гарантии, на которые мы и так уже полагались.
[02:26:06.600 --> 02:26:18.600]  Вот мы пишем такую программу, мы ожидаем, что чтение увидит предшествующие записи в одном потоке. Разумно? Ну и разумно.
[02:26:18.600 --> 02:26:24.600]  Вот мы придумали гарантию программ-ордер, ну в смысле придумали программ-ордер и сказали, что чтение согласовано с программ-ордером.
[02:26:24.600 --> 02:26:36.600]  Потом мы говорим, ну вот есть ячейки памяти, которые используют для синхронизации, и вот на них все записи упорядочены, тоже разумная гарантия, разумная.
[02:26:36.600 --> 02:26:41.600]  Потом мы говорим, нам причинность нужна. Вот если мы здесь читаем из буфера, то мы ожидаем, что здесь записали буфер.
[02:26:41.600 --> 02:26:45.600]  Снова формализуем в виде happens before и видимости через happens before.
[02:26:46.600 --> 02:26:52.600]  Опять все очень естественно. Так мы пишем нашу программу, это мы ожидаем.
[02:26:52.600 --> 02:27:03.600]  А дальше мы говорим, что вот есть еще одна неприятность, вот есть такие странные сценарии с атомиками, ну давайте мы для них еще потребуем некоторого сквозного порядка.
[02:27:03.600 --> 02:27:09.600]  Вот и его получили, а дальше все. Мы построили теперь исполнение, которое из этих порядков состоит.
[02:27:09.600 --> 02:27:20.600]  И показываем, что эти частичные порядки в сумме дают нам видимость последовательного исполнения.
[02:27:20.600 --> 02:27:34.600]  Ну так вот же он, ну вот она.
[02:27:34.600 --> 02:27:41.600]  Ну вот Лок Петерсон, мы пишем, что мы хотим пройти.
[02:27:41.600 --> 02:27:59.600]  А я не помню, запускал ли там так, чтобы оно не работало или нет. Мне кажется я прямо этот пример запускал.
[02:27:59.600 --> 02:28:07.600]  Ну сейчас не помню, честно говоря. Нет, ну если напишет Лок Петерсон вот такой наивный, то он разломается, да.
[02:28:07.600 --> 02:28:19.600]  Ну а почему бы он не разломался? Ты просто вокруг этого всего напишешь какие-то ифы, ну и там код как-то обернешь, но суть от этого не поменяется, суть сценария.
[02:28:19.600 --> 02:28:26.600]  Ну там было без атомиков, да.
[02:28:26.600 --> 02:28:31.600]  Ну и собственно поэтому я говорил на первой лекции, что я не могу вам объяснить, зачем мы пишем атомики, потому что нужны они.
[02:28:31.600 --> 02:28:39.600]  А объяснение вот, объяснение занимает вот три часа, зачем нам нужны атомики. Чтобы компедиатор знал, где ему расставлять барьеры.
[02:28:39.600 --> 02:28:48.600]  Чтобы он мог дать вам видимость глобального порядка, в положении которого вы пишете этот самый Лок Петерсон, если этого не написать.
[02:28:48.600 --> 02:28:59.600]  Ну то есть формально там ячейки памяти такие же в памяти, но дальше рассуждать у корректности Лока вот модель чередования будет просто нельзя.
[02:28:59.600 --> 02:29:09.600]  Вот так что мы все это время жили с атомиками, просто с некоторой данностью, что без них будет УБ.
[02:29:09.600 --> 02:29:19.600]  А сейчас можно объяснить, что такое УБ. УБ – это то, что вы начинаете, что в программе просвечивает модель памяти конкретного процессора.
[02:29:19.600 --> 02:29:33.600]  То есть теперь вы видите все эти store-buffer, видите store-buffer, эффекты от них, что что-то условно переупорядочилось, как будто бы в этом состоит УБ.
[02:29:33.600 --> 02:29:38.600]  Не то чтобы что-то страшное, но просто думать об исполнении в простой модели чередования нельзя.
[02:29:38.600 --> 02:29:52.600]  Ну и вот видишь, можно спокойно жить и не знать про модели памяти, а использовать атомики с таким простым правилом.
[02:29:52.600 --> 02:29:58.600]  Читаешь несинхронизированно, там читаешь, пишешь несинхронизированно, сделает атомик, и все, бед не знать.
[02:29:58.600 --> 02:30:08.600]  Именно поэтому это default модели памяти, если ты ничего сложного не хочешь делать, не хочешь оптимизировать программу сильно, то у тебя будет простая семантика.
[02:30:08.600 --> 02:30:13.600]  Ну какое-то количество оптимизации, все-таки мы не все упорядочим.
[02:30:28.600 --> 02:30:40.600]  Нет, там просто volatile есть, которые... Atomic Sequentially Consistent и все.
[02:30:48.600 --> 02:30:56.600]  Но я не знаю, можно ли там совсем на низкий уровень спускаться, но в самом языке там слабых моделей памяти нет, они появились.
[02:30:56.600 --> 02:30:58.600]  Вот в C++ они и появились.
[02:31:01.600 --> 02:31:09.600]  Но на всякий случай, да, наверное, это на лекции я не говорил, можно про это слайд добавить, что вот все эти вещи, они не специфичны для C++.
[02:31:09.600 --> 02:31:19.600]  То есть это просто мы перечисляем наши ожидания от программ. Happens before, порядок на атомиках, порядок на отдельном атомике, программ order.
[02:31:19.600 --> 02:31:24.600]  Это все просто естественное ожидание, это исполнение любой программы на любом процессоре.
[02:31:24.600 --> 02:31:30.600]  Поэтому, в общем, не удивительно, что разные современные языки программирования просто переиспользуют модели памяти C++.
[02:31:30.600 --> 02:31:36.600]  Потому что уже просто разработанный аппарат, а свойства программы нет, языка мало зависит.
[02:31:38.600 --> 02:31:42.600]  Что? Да, в 11.
[02:31:47.600 --> 02:31:51.600]  В Java это появилось, не знаю, сильно раньше, где-то в середине 2000-х, или?
[02:31:54.600 --> 02:31:59.600]  Ну, там у тебя, наверное, были какие-то интринитики в комператорах, то есть вряд ли бы ты это все руками делал.
[02:31:59.600 --> 02:32:09.600]  Но декларативной модели не было, и какого-то разумного способа рассуждать об исполнении тоже не было.
[02:32:11.600 --> 02:32:18.600]  Ну, как вот, пока мы не привели пример, очень сложно, как именно пользоваться моделями памяти?
[02:32:18.600 --> 02:32:21.600]  Как именно эти слабые memory orders расставлять?
[02:32:21.600 --> 02:32:25.600]  Вот чтобы их расставлять, нужно пользоваться математической моделью.
[02:32:25.600 --> 02:32:29.600]  Нужно придумать, какие гарантии данному коду нужны, и как мы их обеспечим.
[02:32:29.600 --> 02:32:36.600]  Вот здесь эти порядки помогают. В такой задачи порядки помогают.
[02:32:36.600 --> 02:32:40.600]  А если ты живешь просто с какими-то интринистиками или ассамблярными вставками,
[02:32:40.600 --> 02:32:46.600]  то непонятно, как тебе что-то доказывать про твой алгоритм, что тебе нужно, как это обеспечить.
[02:32:46.600 --> 02:32:49.600]  Ты скорее пытаешься избавиться от reordering.
[02:32:49.600 --> 02:32:54.600]  То есть ты думаешь, как гарантировать, что ты хороший, а как избежать всего плохого.
[02:32:54.600 --> 02:32:59.600]  Ну, это сложно, потому что непонятно, как ты уверен, что ты всего плохого избежал.
[02:33:02.600 --> 02:33:06.600]  Как люди жили? Ну, люди жили очень просто.
[02:33:06.600 --> 02:33:15.600]  Вообще редко, когда людям нужно писать очень производительный код для произвольного процессора.
[02:33:15.600 --> 02:33:20.600]  Ну, даже если мы говорим условно про места, где люди часто пишут производительный код,
[02:33:20.600 --> 02:33:25.600]  это там какие-то большие компании, где пишут распределенные системы инфраструктуры,
[02:33:25.600 --> 02:33:33.600]  то чаще всего дата-центры в таких компаниях – это какое-то предсказуемые машины.
[02:33:33.600 --> 02:33:38.600]  Не то, что десяток разных архитектур. Мы покупаем только Intel или только ARM,
[02:33:38.600 --> 02:33:43.600]  или только две такие архитектуры. Поэтому до C++11 люди вполне писали под Intel.
[02:33:43.600 --> 02:33:47.600]  Они знают, что у них парк машин – это Intel, и оптимизируют код под них.
[02:33:49.600 --> 02:33:53.600]  Код не кроссплатформенный, но просто и не нужно в этом месте кроссплатформенный код иметь.
[02:33:53.600 --> 02:33:58.600]  Он не планирует запускаться на произвольных устройствах, на утюгах.
[02:34:01.600 --> 02:34:07.600]  Но сейчас есть инструмент, с помощью которого можно отказаться от знания про конкретный процессор
[02:34:07.600 --> 02:34:10.600]  и все равно оптимизировать под него.
[02:34:14.600 --> 02:34:20.600]  Вот так вот. Давайте последний вопрос, потому что 4 минуты осталось.
[02:34:20.600 --> 02:34:23.600]  Или уже закончилось?
[02:34:25.600 --> 02:34:28.600]  Мы и позже начали на 5 минут, поэтому не знаю.
[02:34:28.600 --> 02:34:33.600]  Нет? Ну вот мы дойдем до практики, и там, наверное, они появятся.
[02:34:33.600 --> 02:34:38.600]  То есть я расскажу про слабые мемориордеры подробнее, и тогда уже вопросов больше будет.
