[00:00.000 --> 00:10.800]  Сегодня мы с вами будем говорить о двух вещах, а второй если успеем. Надеюсь, что мы успеем,
[00:10.800 --> 00:15.000]  значит все будет очень грустно. Первое, это линейные контейнеры.
[00:26.560 --> 00:33.320]  Вы уже успели насладиться контестом, вот его красоте. В этом виде всякие сдачи по типу
[00:33.320 --> 00:40.000]  реализовать стек, реализовать очередь, бла-бла-бла. Собственно, это вот сюда. Те, кто сдали,
[00:40.000 --> 00:50.920]  конечно молодцы. Вот, но я удивлен. Окей, но кто такие линейные контейнеры? В общем-то это
[00:50.920 --> 00:59.360]  контейнер, это нечто, что хранит в себе, ну просто хранит в себе данные и что-то там делать с ними.
[00:59.360 --> 01:06.840]  Обычно не модифицировать, а там что-нибудь типа искать и контейнер можно видоизменять путем вставок,
[01:06.840 --> 01:12.680]  удалений и так далее. Собственно, линейный контейнер это тот, кто хранит данные линейно.
[01:12.680 --> 01:18.640]  Вот, если вы когда-то слышали всякие деревья, типа деревья в поисках, вот это не линейный контейнер.
[01:18.640 --> 01:35.720]  И начнем мы с списка. Вот, ну у вас, видимо, существуют лекции по C++, вот, и скорее всего
[01:35.720 --> 01:50.240]  вы знаете, что массив это какая-то вот такая вот штука. Как-то вот так вот выглядит. Ну тут
[01:50.240 --> 01:56.680]  какие-то ячеечки. Физически вам представляется чаще всего это как непрерывный кусок памяти,
[01:56.680 --> 02:08.800]  ну в целом даже не чаще всего, а так и есть. Вот, это непрерывный кусок памяти фиксированного размера.
[02:08.800 --> 02:27.800]  Что? А, ну это ноут по-английски, замечание. Давайте по-русски напишу, да. Я... Привычка, назовем это так.
[02:27.800 --> 02:37.720]  Вот, ну не всегда нам нужен непрерывный кусок памяти, то есть не всегда у нас есть такая потребность,
[02:38.120 --> 02:43.720]  чтобы уметь обращаться к произвольному элементу очень быстро за вот единицы. Ну, как мы привыкли,
[02:43.720 --> 02:52.440]  что это работает в нашей жизни. Физически это, конечно, не так, но ладно. Доброе утро, Илья Рудольфович. Вот.
[02:52.440 --> 02:58.200]  Ну, физически мы привыкли, что это просто указатель на нулевой элемент, и по сдвигу мы
[02:58.200 --> 03:03.480]  понимаем, куда мы обращаемся. Вот, не всегда нам это нужно, иногда нам нужны такие структуры,
[03:03.480 --> 03:09.840]  где мы хотим просто уметь что-то искать и там что-то быстро делать с данными. Вот. Массив,
[03:09.840 --> 03:15.560]  он немножко неудобен тем, что он не позволяет вам взять. Если у вас есть вот этот элемент,
[03:15.560 --> 03:21.040]  ну как-то вы в этом получили там указатель на него или что-то такое. Вот. Вы его взять и просто удалить,
[03:21.040 --> 03:29.560]  сдвинув при этом индексацию, допустим. Вот. В общем случае мы так быстро делать не умеем,
[03:29.560 --> 03:33.680]  это будет делаться за линейное время, потому что нам придется создать новый массив и перекопировать
[03:33.680 --> 03:39.680]  все элементы в него. Ну, это плохо. Где-нибудь к концу этого семестра мы научимся делать за алгорифм
[03:39.680 --> 03:44.560]  с помощью деревьев, но это нам не важно пока что. Просто великая магия, что массив у нас будет
[03:44.560 --> 03:52.400]  деревья представляться. Вот. Окей. Иногда нам хочется уметь быстро удалять из середины элементы,
[03:52.400 --> 03:55.960]  но примеров и приводить не буду, они потом возникнут естественно.
[03:55.960 --> 04:03.240]  Собственно, кто такой список? Определение это сложно, поэтому просто напишем,
[04:03.240 --> 04:18.840]  что, точнее это не потянет на определение, что список это просто набор узлов, где каждый знает
[04:18.840 --> 04:37.560]  своего соседа. Вот. Ну, вообще непонятно, что за этой надписью кроется, но давайте я нарисую.
[04:37.560 --> 04:46.560]  То есть у нас здесь какой-то узел. Да, узел мы будем означать узлов и будем называть нодами.
[04:46.560 --> 04:56.200]  От английского note и почти все время это будут ноды. Ну, такой жаргон сложился. Собственно,
[04:56.200 --> 05:04.680]  этот элемент знает своего соседа. Этот знает своего соседа. Ну, есть один обделенный, у которого
[05:04.680 --> 05:14.400]  как бы есть сосед, но он указывает в никуда. Это односвязанный список. Вот. Собственно,
[05:14.400 --> 05:28.480]  односвязанный, потому что связь одна. Односвязанный. Что уметь делать односвязанный список?
[05:28.480 --> 05:36.440]  Ну, по-хорошему мы храним в памяти у себя где-то там в коде только указательный этот элемент.
[05:36.440 --> 05:44.840]  Вот. Это мы будем называть head. Ну, от английского голова. Вот. Мы храним в себе head. Ну, и там,
[05:44.840 --> 05:50.520]  допустим, мы еще поддерживаем размер, когда нам надо узнавать размер нашего списка. Собственно,
[05:50.520 --> 06:00.320]  как здесь выполняются операции? Ну, поиск это просто проход по всему. Списку вы умеете
[06:00.320 --> 06:07.680]  получать по хеду его следующий элемент, ну и так далее ходить по ним. Вот. Ставка в этот список
[06:07.680 --> 06:15.520]  осуществляется обычно вот в этот конец, да, в голову, грубо говоря. Делается на как-то вот так вот.
[06:15.520 --> 06:22.880]  Вы берете, говорите, вот у меня есть новый элемент. Говорю, что его сосед это текущая голова и
[06:23.240 --> 06:33.640]  переписаю его голову сюда. Ну, собственно, как-то так. Больше здесь ничего нет интеллектуального.
[06:33.640 --> 06:43.600]  Что нам это позволяет делать? Во-первых, мы умеем делать вставку бесконечно много, ну, физически
[06:43.600 --> 06:48.880]  конечно много. В общем случае, если у нас в вам память бесконечно, то бесконечно много раз. Вот.
[06:48.880 --> 06:53.840]  Причем достаточно быстро, потому что нам не нужно тут как-то что-то тут перевыделять целый кусок
[06:53.840 --> 06:59.680]  памяти непрерывной. Бла-бла-бла. Это очень долго. Мы сегодня докажем, что это недолго на самом деле. Но
[06:59.680 --> 07:10.760]  пока что для нас это очень долго. Вот. Соответственно, давайте напишем односвязанный список.
[07:10.760 --> 07:28.880]  Операция. Какую табличку заведем? Время. И примечание у нас здесь будет. Ну, раздену его
[07:28.880 --> 07:37.320]  я не буду, потому что иначе это будет некрасиво, если мы не влезем. Вот. Окей, операция. Это,
[07:37.320 --> 07:47.520]  первое, это будет вставка в конец. Ну, обычно она называется push. Вот. Делается на золоте единицы,
[07:47.520 --> 07:58.760]  и примечаний здесь, ну, никаких нет, здесь пусто. Также у нас есть операция с удалением. Как она
[07:58.760 --> 08:06.720]  делается? Вы говорите, ага. Типа скажи, что вот этот элемент, а этот забудь. Ну, на коде это
[08:06.720 --> 08:19.600]  чуть сложнее выражается, но не сильно. Его мы еще с вами попишем сегодня. Ну, какой-нибудь метод size,
[08:19.600 --> 08:25.680]  там узнаете размер. Ну, он тоже быстро делается, если вы хрените размер. Иначе вам придется
[08:25.680 --> 08:39.760]  проходить по всему этому списку и считать, сколько у вас элементов есть. Окей. Теперь вопрос,
[08:39.760 --> 08:51.680]  за сколько будет делаться удаление произвольного элемента? Вот, давайте подумаем сами. Так, удаление.
[08:51.680 --> 09:04.160]  Произвольного элемента. Ну, например, по значению нам говорят, удали там первую пятерку. Ну,
[09:04.160 --> 09:12.360]  просто идем фором по всем. Ну, здесь скорее вайлом, пока у вас не дойдет вот этого отсутствующего
[09:12.360 --> 09:24.400]  соседа. Вот, в коде на плюсах у нас будет выражаться через 0ptr, скорее всего. Ну, не принципиально,
[09:24.400 --> 09:36.080]  на самом деле. Давайте по индексу давайте. Так, мне нужна стиражка. Здесь все будет одинаково.
[09:36.080 --> 09:46.400]  По значению, по индексу. Давайте по индексу. Окей. Понятное дело, что в худшем случае это будет от n.
[09:46.400 --> 10:02.240]  Ну, n это размер списка. Ну, есть еще дюанс. Если у вас есть указатель на этот элемент уже,
[10:02.320 --> 10:09.840]  ну, допустим, вы его где-то сохраняли. Ну, типичный пример. Я не помню, у вас в контесте есть задача
[10:09.840 --> 10:15.880]  про гоблинов, где они в сердинку встают и так далее? Нет? Ну, вот есть, короче, такая классная задача,
[10:15.880 --> 10:26.080]  где у вас нужно рисовать контейнер, который умеет делать что? Умеет делать уш, умеет делать поп
[10:26.080 --> 10:31.640]  с другой стороны и поп из середины. Вот, например, вы можете просто поддерживать этот указатель на
[10:31.640 --> 10:40.280]  середину при всевозможных наборах операций. И, собственно, примечание здесь такое. Если есть
[10:40.280 --> 10:54.520]  указатель на элемент, то за от единицы будет делаться на самом деле. Почему? Ну, потому что
[10:54.520 --> 11:00.440]  если у вас есть указатель конкретно на вот этот вот элемент, то как сделать удаление? Ну, сказать
[11:00.440 --> 11:10.680]  типа, что? Ну, давайте мы скажем, что мы удаляем следующий за каким-то элементом. Вот, вот так вот.
[11:10.680 --> 11:16.080]  Вот такая вот нотация. То есть мы узнаем указатель на этот элемент, да, и мы хотим удалить этот, то есть
[11:16.080 --> 11:22.400]  следующий за ним. Тогда скажем, что следующий для вот этого вот, это вот этот вот. То есть, ну,
[11:22.400 --> 11:33.440]  совсем рисунок умрет, поэтому будем представлять это виртуально. Точнее, методом копирования рисунка.
[11:33.440 --> 11:41.880]  Вот. Допустим, у нас есть указатель на этот элемент, а мы хотим удалить этот. Пока что неважно,
[11:41.880 --> 11:47.640]  как это сделать. Допустим, что так получилось. Вот, потом мы поймем, что этот контейнер бесполезен,
[11:47.640 --> 11:56.880]  если что. Ну, так. Ну, не бесполезен, но не то чтобы, как нужно будет. Вот. Что мы тогда делаем? Мы говорим,
[11:56.880 --> 12:03.840]  что следующий для этого, это вот этот вот элемент. То есть, следующий следующего. И забываем вот этот
[12:03.840 --> 12:13.400]  вот. Ну, просто его удаляем. Ну, там как-то. Победа. То есть, можно зовут единицы, на самом деле.
[12:13.400 --> 12:18.680]  То есть, у нас есть такой набор операций. Существуется здесь. Допустим, говоря, проблема удаления в том, что
[12:18.680 --> 12:34.720]  вам нужно сделать индексация, это назовем. Вот, индексация. Вот и будет делаться, где идет ваш индекс.
[12:34.720 --> 12:53.920]  Окей. Так, давайте. Ну, вы хотите удалить элемент по этому индексу. Вам нужно допрыгать до этого
[12:53.920 --> 12:59.360]  элемента. То есть, вы сделаете вот и прыжков. Ну, и дальше от единицы операции, так у вас уже есть
[12:59.360 --> 13:08.920]  указательный элемент. Вот. Так, давайте здесь поставим пункт А, как односвязанный список. И перейдем на эту
[13:08.920 --> 13:24.200]  доску. Пункт Б. Это будет был связанный список. Собственно, им обычно мы и будем пользоваться,
[13:24.200 --> 13:33.520]  до поры до времени. Вот. Здесь как бы скажем так. Мы изучим с вами кучу контейнеров сегодня. Вот.
[13:33.520 --> 13:38.680]  Поговорим про, ну, их сравним как-нибудь. И, соответственно, исходя из этого, будем понимать,
[13:38.680 --> 13:43.120]  какой ситуации, что нам конкретно, какой набор операции нужен. И исходя из этого, выбирать то,
[13:43.120 --> 13:49.720]  что нам будет оптимальным по времени, памяти, работы и там. И еще там, смотря, что вам будет нужно.
[13:49.720 --> 13:53.680]  Был связанный список, представьте себе вот такую вот штуку.
[14:06.680 --> 14:07.560]  Давайте вот так вот.
[14:07.560 --> 14:16.600]  И здесь для гармонии, вот так вот.
[14:16.600 --> 14:28.680]  Вот что-то такое. То есть мы храним связи в обе стороны. То есть у нас для каждого элемента известен
[14:28.680 --> 14:39.440]  его сосед справа, сосед слева. И храним мы в этом всем деле голову и, ну, что противоположно голове,
[14:39.440 --> 14:51.080]  давайте. Вот, да, молодцы. Пистеха, элита, интеллектуальная все-таки. Отлично. Голова и хвост.
[14:51.080 --> 14:57.560]  Ну и все. Тобственно, набор операции не изменяется относительно этого, только у вас появляется
[14:57.560 --> 15:01.520]  ориентация у Пуши и Попа в плане того, что вы умеете делать как спереди, так и сзади.
[15:01.520 --> 15:16.160]  А это в зависимости от того, как, что вы назовете. Это абстракция. Вы можете его называть хоть лево-право
[15:16.160 --> 15:20.280]  и разворачивать как хотите. Вы можете там читать его справа-налево. Ну, как вам удобно.
[15:20.280 --> 15:37.280]  Хед и тейл вообще принятые. Обычно говорят хед. Обычно просто если идет речь об односвязанном
[15:37.280 --> 15:42.480]  списке, то всем понятно в какую сторону вы добавляете. Там просто Пуш. Потому что в другую сторону вы не
[15:42.480 --> 15:47.480]  умеете добавлять. Потому что у вас просто нет указательного на последний элемент.
[15:47.480 --> 15:54.200]  Ну и там, короче говоря, проблем много будет, и это всем лень делать.
[15:54.200 --> 16:12.440]  Вот. Окей, теперь поговорим о Попапам. Второй раздел. Это контейнеры-адаптеры, так называемые.
[16:12.440 --> 16:28.320]  Сразу скажу, что слово адаптер здесь в целом не общеприменимое, но здесь возникает не из теоретических
[16:28.320 --> 16:36.920]  соображений, а из практических. Вот. Есть такая штука в программировании, когда вы там что-то пишете,
[16:36.920 --> 16:42.200]  пишете, пишете, и вам нужно вырезать функционал чего-либо и назвать это по-другому. Ну, сейчас возникнет,
[16:42.200 --> 16:50.560]  понятно будет, почему и откуда это берется. Вот. Это называется адаптером. Ну, адаптируется. Вот.
[16:50.560 --> 16:56.080]  Ну или еще это можно будет назвать как такими несамостоятельными структурами данных, потому
[16:56.080 --> 17:02.800]  что их можно реализовывать поверх чего вы хотите. Вот. И первый из таких чуваков это стэк, собственно.
[17:02.800 --> 17:10.240]  Ваш любимый стэк, который вы должны были реализовать после этой лекции, но часть из вас справилась уже.
[17:10.240 --> 17:20.360]  С чем я их и поздравляю, конечно. Вот. Кто такой стэк? От стэка мы хотим следующих операций. Да,
[17:20.360 --> 17:27.680]  мы будем определять эти структуры данных с точки зрения не реализации, а с точки зрения API. Ну,
[17:27.680 --> 17:36.880]  API это просто набор операций, которые мы хотим уметь делать. Вот. Такое определение. Вот.
[17:36.880 --> 17:49.560]  Мы будем просто расписывать операции. Ставим ничего. Мы хотим делать push. Мы хотим делать pop.
[17:49.560 --> 18:00.240]  Мы хотим делать size. И мы хотим делать top. Ну, top это взглянуть на элемент. Собственно,
[18:00.240 --> 18:07.280]  стэк это вот такая вот штука. Я его люблю рисовать как такой стакан. Ну, можно еще назвать это стопкой
[18:07.280 --> 18:19.440]  какой-нибудь. Типа стопкой тарелок, например. Вы умеете добавлять вот в эту сторону и извлекать
[18:19.440 --> 18:27.160]  из этой стороны. Вот. Такой вот контейнер интересный. Ну, собственно, здесь мы должны
[18:27.160 --> 18:32.280]  были сказать, как же так внезапно его подносятся операции. Это подносятся операции односвязанного
[18:32.280 --> 18:46.600]  списка. Есть такая мысль? Как-то не очень воодушевленные у вас лица. Вот. Ну да, это мы умеем
[18:46.600 --> 18:54.800]  делать. Мы умеем, по сути дела, добавлять и удалять отсюда. Все. Этому можно будто бы вот
[18:54.800 --> 19:01.760]  нарисовать вот такую вот ограничивающую рамку и понятно, откуда, куда не ноги растут, а элементы.
[19:01.760 --> 19:17.840]  Вот. Вот. И, соответственно, он удовлетворяет парадигме, так называемая парадигма, ну или
[19:17.840 --> 19:36.840]  принцип. Если вам слово парадигма кажется слишком пафосным. Лифо. Расшифровывается как last in, first out.
[19:36.840 --> 19:46.600]  Вот. Это все, если что, просто умные слова, которые вам на практике особо не пригодятся
[19:46.600 --> 19:53.720]  для осознания, но для чтения литературы будут полезными. Тобственно, последним вошел, первым
[19:53.720 --> 20:01.200]  вышел. Вот. Ну, например, мы добавляли один, два, три, четыре, пять. Соответственно, первой будет
[20:01.200 --> 20:10.880]  извлечена пятерка, которой мы добавили последний. Ну, собственно, стэк можно реализовывать, а, на
[20:10.880 --> 20:16.040]  списке, б, внезапно на массиве. Если вы знаете максимальный размер стэка, вы можете просто
[20:16.040 --> 20:23.040]  завести такой массив и урезать его функционал до того, что вы умеете обращаться не к произвольному
[20:23.040 --> 20:31.080]  элементу, а лишь к последнему. Поэтому и адаптер. Он как бы адаптирован под вот такую вот штуку,
[20:31.080 --> 20:42.600]  под вот такой вот протокол работы. Так, вопросы. А отдельным исключением, ну не то чтобы исключением,
[20:42.600 --> 20:50.160]  но, скажем так, что нам может пригодиться в этой жизни? Это такая штука, как MinStack,
[20:50.160 --> 21:02.920]  назовем ее. Кто такой MinStack? Это стэк, да, по-английски он пишется вот так вот,
[21:03.240 --> 21:15.800]  плюс Min. То есть операция минимума еще в стэке он умеет делать за вот единицу. Такая вот мощная структура.
[21:15.800 --> 21:31.160]  Ну как это реализовать? Давайте еще хранить не только элемент, который мы добавили, но еще
[21:31.240 --> 21:40.520]  минимум во всем стэке, в каждой точке истории, назовем это так. Ну, например, здесь на место хватит.
[21:50.520 --> 21:59.280]  Ну и здесь давайте мы будем хранить value какой-нибудь, а здесь Min. Ну и давайте у нас
[21:59.400 --> 22:11.240]  будут операции типа, не знаю, push от пятерки какой-нибудь, push от тройки. Да, соответственно,
[22:11.240 --> 22:16.400]  минимум мы храним минимум во всей истории. Если стэк пуст, то это просто элемент, который мы
[22:16.400 --> 22:27.400]  добавили. Дальше идет push от тройки. Ну окей, минимум из тройки и пятерки это тройка. Давайте push
[22:27.400 --> 22:34.960]  от четверки. Ну здесь, понятное дело, значение будет четверка, а минимум во всем стэке это тройка.
[22:40.960 --> 22:52.640]  Давайте push от двойки еще сделаем. 2, 2, push. Ну не знаю, чего-нибудь такого нам точно хватит.
[22:52.640 --> 23:00.880]  Окей, вот вопрос. Давайте мы не знаем, что здесь сидим. Вот мы знаем вот такое вот состояние,
[23:00.880 --> 23:06.840]  у нас структура. Как понять, какое значение надо написать сюда? Как найти минимум во всем стэке?
[23:06.840 --> 23:14.280]  Ну внезапно, да, минимум во всем стэке это минимум из вот этих вот двух элементов. Так плохо
[23:14.280 --> 23:24.480]  получилось. Сейчас. Эта единичка здесь была. Это минимум из вот этой вот и вот этой вот. Потому
[23:24.480 --> 23:34.000]  что эта штука хранит минимум во всей истории. Соответственно, вот этот пересчет минимума,
[23:34.000 --> 23:41.200]  он позовет, что делать. Точнее, как его делать. Если у вас стэк пустой, то вы добавляете минимум,
[23:41.240 --> 23:47.800]  просто текущий элемент, который вы добавили. Иначе вы сравниваете добавленный элемент с минимум в
[23:47.800 --> 23:54.720]  вершине. Ну и пишете минимум из них. Например, вот здесь вот из четверки и тройки минимум тройка,
[23:54.720 --> 24:02.040]  поэтому писалось тройка. И утверждается, что в каждый момент времени, если вы спросите у стэка
[24:02.040 --> 24:12.120]  минимум, то минимум будет лежать вот здесь. На верхушке, на вершине. Доказывать это можно,
[24:12.120 --> 24:18.880]  не знаю, по индукции, например. Рассмотреть каждую операцию. Предполагайте, что состояние стэка
[24:18.880 --> 24:24.480]  корректно. Дальше применяйте любую из операций и доказывайте, что корректность сохраняется.
[24:24.480 --> 24:33.000]  Ну, например, скажем, что здесь мы сделали поп. Забыли вот эти вот.
[24:38.000 --> 24:44.560]  Ну тогда у вас минимум хранится здесь корректно, это двойка. Дальше делаете поп. Давайте здесь буду
[24:44.560 --> 24:55.360]  дальше писать. Снова делаете поп. У вас удаляется снова элемент. И у вас все еще
[24:55.360 --> 25:01.840]  корректно хранится минимум в стэке. Ну как раз-таки просто по индукции того,
[25:01.840 --> 25:10.080]  что у вас все было корректно на этом состоянии. Окей. Ну, наверное, вы встречали такие
[25:10.080 --> 25:14.680]  целосочетания, как Stack Overflow. Но Stack Overflow это общий сайт, образованный целосочетанием
[25:14.680 --> 25:25.280]  Stack Overflow. Overflow это переполнение по-русски. Вот. Собственно, откуда оно берется? Наверное,
[25:25.280 --> 25:31.120]  вы, возможно, слышали о такой вещь, как Stack Recursion. Было такое? Нет? Окей. Ну,
[25:31.120 --> 25:34.240]  давайте напишем такую элементарнейшую программу.
[25:45.560 --> 25:58.880]  Классно, да? Ну, там в мейне вызовем просто f. Ваши идеи, что произойдет? Что? А дальше?
[25:58.880 --> 26:07.880]  Вот. Она будет все время вызывать себя. Соответственно, и как бы по сути, мы же можем
[26:07.880 --> 26:12.320]  записывать какие-то аргументы. И по-хорошему, мы хотим уметь откатываться в какое-то состояние.
[26:12.320 --> 26:33.040]  Ну, давайте, например, что-нибудь такое, да? Давайте n больше 0. Там f от n минус 1. Там,
[26:33.040 --> 26:41.520]  так вот, перед вами, например, факториал. Ну, только здесь надо еще какое-то значение. Вот. Ну,
[26:41.520 --> 26:50.400]  давайте здесь вызовем f от, не знаю, от 20. Вот. Она сделала 20 рекурсивных вызовов. Причем
[26:50.400 --> 26:56.760]  внутри в памяти это будет храниться, как мы вызывали f от 20, дальше мы вызвали f от 19, f от
[26:56.760 --> 27:04.800]  18, бла-бла-бла-бла-бла. f от единицы. И попытались вызвать f от 0. И каждый раз компьютер вынужден
[27:04.800 --> 27:11.280]  хранить то, что было в памяти на текущий момент. Логично, да? Потому что вы хотите все-таки
[27:11.280 --> 27:19.040]  когда вы вернетесь обратно, будете подниматься вверх по этому стеку вызовов, то у вас произойдет
[27:19.040 --> 27:25.000]  то, что вы хотите на текущий момент знать все-таки, что было, причем именно в тот момент. Поэтому это
[27:25.000 --> 27:30.480]  все хранится в стеке, причем там хранится, ну, физически я не буду описывать, как хранится вот
[27:30.480 --> 27:37.560]  этот вот f. Хранится все, что было внутри f. Вот. И у вас так хранится сказки, как стек, потому что
[27:37.560 --> 27:43.040]  там что нужно мне делать? Добавлять в конец, то есть новый рекурсивный вызов функции, или откатываться
[27:43.040 --> 27:52.320]  на 1 назад, когда у вас рекурсивный вызов закончился и вы вернулись на уровень выше. Вот. И это все
[27:52.320 --> 27:56.760]  хранится в специальной стековой памяти, про которую вам расскажут на плюсах, ну, плюсах,
[27:56.760 --> 28:01.680]  по крайней мере, так. Ну, в других сказках, скорее всего, тоже. Просто я там не знаю, куда именно пишут
[28:01.680 --> 28:08.400]  стек рекурсии. И stackoverflow возникает, когда у вас переполнение стека возникает. То есть,
[28:08.400 --> 28:12.840]  когда вы вызвали кучу раз функции f, и у вас закончилась память на рекурсивный вызов. Ну,
[28:12.840 --> 28:18.600]  бывает такое. Обычно это проблема краски с тем, что у вас вечная рекурсия. Отсюда и stackoverflow
[28:18.600 --> 28:29.480]  возникло совсочетание. Это такая историческая научпопная справка, назовем это так. Вот.
[28:29.480 --> 28:35.520]  Про стыки поговорили, теперь про очередь. Или есть вопросы?
[28:43.680 --> 28:48.280]  Ну, вообще, есть опции у компилятора, которые говорят ему, что прими stack таким-то. Но
[28:48.280 --> 28:57.760]  безгранично это тоже сделать нельзя. Вот. Я не помню, как там флаг этот называется, к сожалению.
[28:57.760 --> 29:04.680]  Скажем так, если у вас возникает необходимость увеличить стек, скорее всего, вы делаете что-то
[29:04.680 --> 29:18.680]  не то. В частности, например, ваш DFS, его можно переписать по-другому, просто явно храняя стек.
[29:18.680 --> 29:26.160]  Вот. Можно так сделать. То есть, не пользоваться стеком, которым предоставляет ваше физическое
[29:26.160 --> 29:32.520]  устройство, а как бы явно его создавать и явно в нем что-то хранить. Так тоже можно делать,
[29:32.520 --> 29:50.200]  и все будет ок. Окей. Так, B это очередь. А кто такая очередь? По-английски это вот такое вот
[29:50.200 --> 29:59.680]  неудобоваримо произносимое слово, Q. Вот. Ну или, по-моему, она звучит как Q, просто Q и все.
[29:59.680 --> 30:07.960]  Не Q-U-E-U-E. Вот. Вот, пожалуйста, не говорите Q-U-E-U-E, вас никто не поймет. Не знаю, скажите,
[30:07.960 --> 30:16.080]  очередь или Q. Ну еще, в американском варианте очередь это line называется, вот, но вас так тоже
[30:16.080 --> 30:24.600]  никто не поймет, если вы будете в гугле вводить вопрос там, how to blah blah blah in line, то он не
[30:24.600 --> 30:32.000]  поймет, что вы от него хотели. Вот. Или там какой-нибудь whiz line, например. Можете писать это вот страшное
[30:32.000 --> 30:42.440]  слово, просто запомните, как оно пишется. Но очередь, у нее операция следующая. Так как нам здесь будет
[30:42.440 --> 30:55.200]  важна уже ориентация пушев и попов, мы здесь пропишем вот так вот push front, pop back. Ну,
[30:55.200 --> 31:08.280]  front и там size какой-нибудь. Ну, для органичности, чтобы всем совпадало. Вот. Ну, очередь, она ведет
[31:08.280 --> 31:15.760]  себя внезапно, как очередь реальной жизни. Вот. Ну, конечно, не как в больницах, где-то можно
[31:15.760 --> 31:21.280]  только спросить. Мы верим в то, что мы живем в светлом мире будущего, где очереди все прекрасно
[31:21.280 --> 31:28.640]  работают. Вот. То есть, у вас человек может зайти в конец очереди и выйти из начала. Ну,
[31:28.640 --> 31:44.840]  например. Будем называть это front. Это back. Ну, видите, я опять перепутал ориентацию очереди.
[31:44.840 --> 31:56.760]  Тобственно, здесь как бы, назовем это так, что обычно всем понятно из контекста, и вы будете
[31:56.760 --> 32:01.400]  говорить, типа там push в очередь, добавляем в очередь. Никто не говорит push front в очередь. Ну,
[32:01.400 --> 32:12.880]  потому что это A долго, B как-то не звучит. Вот. И нет такого вот, нет такого фонетического
[32:12.880 --> 32:22.240]  единообразия с стэком. Вот. Парадигма у нее, соответственно, противоположная. Я верю, что вы догадаетесь.
[32:22.800 --> 32:44.360]  Типа, да. First in, first out. Ну, давайте подумаем, в смысле чего можно резать очередь.
[32:44.360 --> 32:57.920]  Так. Нет, два стэка это для умных. Мы пока что не обладаем таким секретным знанием.
[32:57.920 --> 33:07.280]  Ну, с помощью стэка не получится одного. Вроде бы направление стрелочек не совпадает,
[33:07.280 --> 33:14.600]  скажем так. Вот. И как-то адаптировать ему не получится. Да, с помощью двухсвязанного списка,
[33:14.600 --> 33:23.240]  например. Вот тут вот у нас. Напомним этого чувака. Вот. Причем, ну, я здесь специально не буду
[33:23.240 --> 33:31.800]  предать front и back, потому что понятно, что они здесь равнозначны. А здесь нет. Ну, с помощью, да,
[33:31.800 --> 33:36.160]  можно еще с помощью двухсвязанного списка. С помощью чего еще можно? Можно с помощью кольцового
[33:36.160 --> 33:44.000]  буфера, так называемого. Вот. У вас спойлер. Ну, те, кто не на первом курсе иностранцы,
[33:44.000 --> 33:49.920]  у вас будет задача реализовать кольцовый буфер. Вот. А у тех, кто умещен, у нас, скорее всего, нет.
[33:49.920 --> 34:01.520]  Ну, и так вот. Кто такой кольцовый буфер? Это обычный кусок массива. Ну ладно, просто массив,
[34:01.520 --> 34:13.360]  который хранит себе указатели front и back. И дальше, если у вас идет push, вы front просто
[34:13.360 --> 34:18.920]  сдвигаете сюда и говорите, что здесь будет какой-то элемент. Что-нибудь такое. Изначально там на один
[34:18.920 --> 34:26.180]  указывают. Вот. То есть push, он будет вслед за счет того, чтобы вы записали сюда элемент и front
[34:26.180 --> 34:33.180]  переместили вот сюда. Ну pop, наоборот, то, что вы back сюда будете перемещать. То есть забывать
[34:33.180 --> 34:36.620]  значение этого элемента и сюда перемещать. На самом деле его даже можно не звать, просто back
[34:36.620 --> 34:45.780]  переместить и все. Вот. А как делать, если вы там расширились до конца? Берете и закольцовываете
[34:45.780 --> 34:52.460]  его. То есть считаете, что следующий индекс там по модулю берется. И все, и пишете вот так вот.
[34:52.460 --> 34:59.660]  То есть, по сути, у вас получается не то чтобы массив, а вот такая вот, не знаю, вублик назовем это.
[34:59.660 --> 35:09.100]  Это какое-то подобие солнышка, в котором вы так вот пишете.
[35:09.100 --> 35:24.700]  Ну там направление обхода выбирайте сами. Кольцевой буфер, чтобы очередь писать.
[35:24.700 --> 35:34.100]  Ну не всегда прикольно писать очередь на дусязном списке. Причина чистая физическая, потому что,
[35:34.100 --> 35:40.460]  давайте оставим это на семинар все-таки. Я попрошу семинаристов объяснить, почему физически списки
[35:40.460 --> 35:51.700]  медленнее, чем вот такие вот, интересно загогулины. Ну смотри, вот у меня сюда указывает фронт,
[35:51.700 --> 36:01.420]  и мне нужно делать пуш, да? Я пишу сюда элемент и говорю, теперь фронт у меня указывает вот сюда вот.
[36:01.420 --> 36:10.620]  Все. Ну то есть, как понятное дело, что это не очень очевидно, что это то же самое, что и это.
[36:10.620 --> 36:16.980]  Вот, ну кому-то удобнее так представить, если вам это неудобно, то представьте это вот так вот просто.
[36:16.980 --> 36:30.580]  Вот. Окей. Тобственно, казалось бы, зачем нам... Ну понятно, эта штука очевидная, а зачем мы вообще
[36:30.580 --> 36:35.180]  разбирали? Если мы говорим про какие-то линейные контейнеры, то еще какие-то минимумы внезапно
[36:35.180 --> 36:39.820]  добавляются. Ну, иногда бывает в жизни огорчение, и вам нужно писать вот такую вот штуку.
[36:39.820 --> 36:49.660]  Очередь с поддержкой минимума. И проблема в том, что здесь, на двухстороннем списке,
[36:49.660 --> 36:58.460]  вы никак не отдуетесь, чтобы сделать минимум в золоте единицы. Ну почему, казалось бы,
[36:58.460 --> 37:04.100]  давайте минимум хранить, да и все. Просто в свою личную очередь хранить минимум. Проблема в том,
[37:04.100 --> 37:11.380]  что если вы храните очередь и просто минимум, и у вас в какой-то момент на запрос SpotDoc удалился
[37:11.380 --> 37:25.580]  этот минимум, вам нужно внезапно искать за линию. Это очень грустно. И еще мы, ну понятное дело,
[37:25.580 --> 37:31.100]  можно построить контртест, такой, что у вас каждая операция минимум будет выполнена за ОТ, за линию.
[37:31.100 --> 37:39.540]  Это совсем печально, потому что вас деградируют все до квадрата, а квадрат это нечто, что для
[37:39.540 --> 37:45.860]  линейных контейнеров неприемлемо, потому что все-таки, ну, линейное от слова линия, вот,
[37:45.860 --> 37:55.020]  линейное время, линейный контейнер. Нет-нет, мы хотим за ОТ единицы. Это вот наша великая мечта.
[37:55.020 --> 38:02.580]  Пока что, если мы пользуемся подходом на той вот доске, продусязный список, у нас ОТ единицы как-то не
[38:02.580 --> 38:15.420]  работают. Ну, куда ты торопишься? Я тоже могу сказать два стека, ну и что? Вот, да, нам нужны два стека.
[38:15.420 --> 38:25.660]  Давайте, наверное, передумаем эту доску. Очередь на двух стеках.
[38:25.660 --> 38:38.220]  Ну, на собеседовании в приемку, ну, в приемной комиссии, не чтобы работать в приемной комиссии,
[38:38.220 --> 38:43.420]  чтобы вы, короче говоря, сюда поступили в приемной комиссии, у вас там собеседование со студентами
[38:43.420 --> 38:49.860]  проходит, да? Ну, у иностранцев я не знаю, как это конкретно происходит, я знаю про обычные программы, вот.
[38:49.860 --> 38:57.380]  Соответственно, там есть задачи у этих, от этих студентов, которые вас там валят и ненавидят всеми
[38:57.380 --> 39:04.060]  кибрами души. Ну, как вы можете догадаться, нет, на самом деле. Вот, ну, вы все такими, ну, не все, там
[39:04.060 --> 39:08.620]  кто-то из вас такими точно будет, кто пойдет в приемку, вот, и, пожалуйста, не отыгрывайтесь на абитуриентах
[39:08.620 --> 39:15.300]  за вашей абита. Вот, и там как бы дают задачу реализовать очередь на двух стеках. То есть,
[39:15.300 --> 39:19.740]  когда вам говорят, что есть стек, это вот такой вот стаканчик, ну, или такая вот стопка тарелок,
[39:19.740 --> 39:28.420]  придумайте с помощью двух таких стопок, как реализовать очередь. Ну, давайте, вот гений сидит,
[39:28.420 --> 39:48.380]  очереди на двух стеках. Ну, да, в общем-то, конструкция будет выглядеть примерно так.
[39:48.380 --> 39:58.220]  Ох, получилось.
[39:58.220 --> 40:10.660]  Вот так нормально. Мы как бы умеем, в этом стеке мы умеем делать вот так вот и вот так вот.
[40:10.660 --> 40:26.900]  А в очереди мы хотим что-то вот такое вот. Какие две стрелки надо соединить, чтобы получить вот такие вот дуги.
[40:26.900 --> 40:35.820]  Ну, да, то есть нам нужно сделать вот такую вот штуку. Тут у нас план реализовать что-то вот такое вот.
[40:35.820 --> 40:46.340]  Вот, картинка ясна, она пока останется на доске для того, чтобы просто было
[40:46.340 --> 40:56.100]  графически понятно, что мы делаем. Давайте я напишу здесь вот такой прекрасной функции,
[40:56.100 --> 41:13.500]  которая объясню, что она потом делает. Уж простите меня мои одноуквенные переменные и не соблюдение
[41:13.500 --> 41:26.740]  Код Стайла. Все-таки я пишу на доске, вот, и у меня здесь место ограничено. Да, у вас 80 символами, но у меня
[41:26.740 --> 41:34.020]  здесь меньше на самом деле, так что не бессудьте. Мы потом с вами будем проходить какую-нибудь структуру,
[41:34.020 --> 41:55.860]  где я нормально напишу код на доске. Пока что как-то так. While L size больше нуля, R push от l.top, l.pop.
[41:55.860 --> 42:02.740]  Ну, совсем плохо. Это еще хоть как-то похоже.
[42:02.740 --> 42:18.060]  Ну, я скажу сразу, что в STL, в C++ стандартный стэк, он на pop ничего не возвращает, он void.
[42:18.060 --> 42:29.660]  Как фронт в стэке. Мы там ток написали, где стэк. Это получение верхнего элемента.
[42:29.660 --> 42:44.220]  Функция shift осуществляет этот перенос. Сразу скажем, что это будет l.push здесь, а здесь будет
[42:44.220 --> 42:57.780]  l.r.pop. Окей, когда вызывать этот shift? Этот shift вам надо вызывать, когда у вас надо извлечь
[42:57.780 --> 43:08.060]  элемент, а здесь пусто. Или посмотреть на верхний элемент, а здесь пусто. Вот такое бывает. То есть
[43:08.060 --> 43:30.740]  код push у вас вообще не изменится. От стэк s. Давайте мы пишем здесь l.r, как для единообразия.
[43:30.740 --> 43:47.300]  Здесь будет просто l.push от… А, ну еще мы все означение перейдем кое-что. int val от val.
[43:47.300 --> 44:16.100]  Здесь совсем все просто. Давайте я здесь напишу pop от stacr. И здесь мы будем проверять,
[44:16.100 --> 44:24.580]  что если вот этот r, давайте это l, это r. Но вообще по-хорошему их надо обозначать in-out,
[44:24.580 --> 44:31.380]  stac-in, stac-out. Stac-in – это в которых мы добавляем элемент out, из которого извлекаем. Но я забыл
[44:31.380 --> 44:37.140]  об этом, когда писал shift, и сейчас уже поздно переписывать. Так сказать, задумывайтесь о
[44:37.140 --> 44:54.340]  нейминге с самого начала, чтобы не исправлять потом код style. Если все-таки он пустой,
[44:54.340 --> 45:20.100]  то мы делаем следующее. Делаем shift от lr. Ну и дальше вы делаете pop. Заметьте,
[45:20.100 --> 45:26.260]  я сразу не пишу, что у вас там в случае пустых стэков происходит, как работает pop от пустого
[45:26.260 --> 45:35.740]  стэка. Вот это уже вы сами будете решать, как вам это делать. Вот. Ну и все,
[45:36.740 --> 45:56.780]  достаточно долго на нашей доске. А, уже перерыв прошел. Ну, что поделать? Что? Да нет, сейчас
[45:56.780 --> 46:19.860]  сделаем. Тобственно, тогда вопрос, как сделать min? Почему о втором? Да, нам нужно два минимума
[46:19.860 --> 46:35.900]  взять. Нам нужно сделать return minimum из l-min r-min. И это уже на ваше усмотрение. Я считаю,
[46:35.900 --> 46:45.300]  что у меня стэки хорошие, не пустые. Вот, если какой-то из стэков пустой, он возвращает страшную
[46:45.300 --> 46:54.300]  вещь, скажем так. Ну, да, пока что для вас страшная вещь называется бесконечностью. Потом,
[46:54.300 --> 47:04.300]  когда вы больше узнаете C++, у вас это будет называться вот такой вот штукой. Option. Вот.
[47:04.300 --> 47:09.860]  Но пока что я сотру, чтобы не дай бог Илья Семирыч не посмотрел ему лекцию и не обнаружил,
[47:09.860 --> 47:13.500]  что он рассказывает что-то к Option. Вот, иначе он будет очень расстроен, что я отбираю у него
[47:13.500 --> 47:21.220]  хлеб. Ну, или там у кого-то Даниил Альбертович. Вот. И пока что обработку крайних случаев я ставлю
[47:21.220 --> 47:26.980]  на вас целиком. Вот. Потому что у нас все-таки лекция, не семинары. Мы пишем код на доске,
[47:26.980 --> 47:38.420]  а доска прощает многое. Даже ошибки компиляции за код стайла. Ну, зря ты туда отошел, ну ладно.
[47:38.420 --> 47:43.020]  Собственно, тогда минимум вы золотые единицы получаете, потому что в стейках минимум вы золотые
[47:43.020 --> 47:54.340]  единицы получаете умеете. Собственно, где вам это может быть полезно? Кто-нибудь может придумать
[47:54.340 --> 48:04.620]  хоть какое-то адекватное применение очереди с минимумом? А если быть более, скажем так,
[48:04.620 --> 48:14.180]  реалистичным человеком? Окей. Ну, применение вообще такое. Ну, давайте вместо минимум возьмем какую-то
[48:14.180 --> 48:19.500]  произвольную ассоциативную операцию, на самом деле. Потому что здесь важна только ассоциативность.
[48:19.500 --> 48:25.820]  Допустим, у вас есть какие-то данные, которые к вам приходят в режиме онлайн. Напомню онлайн,
[48:25.820 --> 48:30.300]  это значит, что вы их не знаете, не он как-то приходит со временем. Ну, например, там у вас есть,
[48:30.300 --> 48:37.020]  не знаю, приложение, какое-нибудь приложение, и вы там ведете его логи. Сколько там? Кролов,
[48:37.020 --> 48:45.620]  кликов, лайков, бла-бла-бла. Вот. И у вас есть такая вот огромная-огромная-огромная история. И вы хотите,
[48:45.620 --> 48:50.700]  ну, понятное дело, что, допустим, для анализа текущего состояния приложений вам не очень важно,
[48:50.700 --> 48:57.740]  что происходило год назад. Вам нужно какое-то окно, ну там, не знаю, недель две, например. И вы хотите
[48:57.740 --> 49:05.780]  узнавать минимум за две недели минимальную оценку. Ну, что-нибудь такое. Вот тогда у вас что вы
[49:05.780 --> 49:12.060]  хотите уметь делать? Вы хотите уметь, ваша очередь прекрасная, вы хотите уметь добавлять в нее новые
[49:12.060 --> 49:18.740]  данные. То, что вам пришел новый отзыв, допустим. Уметь из нее извлекать данные, потому что этот
[49:18.740 --> 49:26.300]  отзыв уже успел состариться. И в придачу вы хотите уметь извлекать там минимальную оценку. Чтобы это
[49:26.300 --> 49:32.220]  делать быстро, вы используете очередь с минимумом. Вот. То есть как бы она здесь применяется как такое
[49:32.220 --> 49:37.140]  скользящее окно в некотором плане. Она вот так вот скользит по всей вашей истории, забывает что-то
[49:37.140 --> 49:43.580]  старое, запоминает что-то новое, что только что пришло, и при этом поддерживает все минимум быстро. Вот.
[49:43.580 --> 49:51.100]  Вот как-то так. Ну, там, не знаю, допустим, у вас от этого минимума там что-нибудь зависит,
[49:51.100 --> 49:59.980]  типа там вы рекомендуете это приложение или нет. Вот. Ну, понятное дело, что минимум здесь не очень
[49:59.980 --> 50:07.300]  интересно брать. Вот. Там есть более такая классная штука как медианное сглаживание, но про нее мы поговорим,
[50:07.300 --> 50:15.220]  когда изучим такое медианное деревье поиска, про похожий подход. Вот. А пока давайте перерыв. А последний
[50:15.220 --> 50:21.660]  контейнер-адаптер это... Давайте я по-русски напишу. Мы ж по-русски сначала писали их. Это дек.
[50:21.660 --> 50:29.980]  Ну, еще дек называют двусторонней очереди, но двусторонняя очередь это долго, поэтому это
[50:29.980 --> 50:52.340]  просто дек. По-английски дек. Операция. Это набор из пушей, попов, бреков, пронтов, то есть во
[50:52.340 --> 51:01.900]  все стороны. То есть вы умеете делать... Выбирайте любое слово отсюда. Любое слово отсюда он умеет. То есть он умеет делать
[51:01.900 --> 51:15.980]  push-back, push-front, pop-back, pop-front. Ну, там front-back умеет делать. И size. Ну, внезапно, вау,
[51:15.980 --> 51:33.180]  перед вами двусторонний список в гриме. А сразу нюанс. Давайте напишу здесь замечание. Есть такая штука,
[51:33.180 --> 51:44.780]  как STD. Deque в плюсах. Он умеет делать очень интересную операцию, помимо всего этого. Он еще умеет
[51:44.780 --> 52:07.420]  это вот наш дек, я назовем его, плюс индексация. За от единицы. Обычная. То есть умеете по индексу
[52:07.420 --> 52:21.260]  брать элементы. Что? Ну, он так умеет. Как он реализован внутри, вы хотите узнать? Я не скажу.
[52:21.260 --> 52:28.740]  Ну, я скажу так, что в первом приближении это кольцевой буфер внутри, но только в первом.
[52:28.740 --> 52:39.820]  Там на самом деле все гораздо сложнее. Это кольцевой буфер страничек определенной направленности. А дальше,
[52:39.820 --> 52:44.940]  что за этой фразой кроется, я оставлю вашим векторам по плюсам, которые это разберут где-нибудь во втором
[52:44.940 --> 52:57.020]  семестре. Если не разберут, то скажите мне, я там напишу в чат, как это работает. Потому что все-таки
[52:57.020 --> 53:05.900]  нам вот такая вот штука не понадобится. И обычно STD-дек используют как вот такой вот дек. То есть
[53:05.900 --> 53:12.220]  индексация в нем требуется редко достаточно в практических применениях, но под любую задачу
[53:12.220 --> 53:24.060]  можно придумать практически кейс, если очень сильно повоображать. Все. Прилинейные контейнеры
[53:24.540 --> 53:35.740]  адаптера закончили. Прилинейные контейнеры у нас как бы остаются, но мы напишем заголовок 3. Это
[53:35.740 --> 53:55.900]  амортизационный анализ. Собственно, вот ко мне подошел один человек во время перерыва и спросил,
[53:55.900 --> 54:01.420]  что если мы делаем вот такую вот архитектуру в очереди на двух стэках, то почему это POP работает
[54:01.420 --> 54:11.180]  за от единицы, если нам нужно вызвать shift в некоторой ситуации. А вызов shift это линия. Вопрос,
[54:11.180 --> 54:18.660]  почему POP работает за от единицы. И скажу так, я не слухаю, потому что не говорю, что здесь работает
[54:18.660 --> 54:26.700]  за от единицы, справедливости ради. Но мы сейчас будем с вами доказывать, что амортизированное время
[54:26.700 --> 54:33.500]  это от единицы. Давайте определим, что такое амортизированное время. Определение. Пусть
[54:33.500 --> 54:47.580]  с структурой данных. С структурой проводят операции
[54:47.580 --> 55:04.500]  а1, аn. Где аи-то это какая-то операция типа push или pop в нашем случае. В общем случае там
[55:04.500 --> 55:11.980]  больше операции, если такая-то другая структура. И практическое время работы
[55:11.980 --> 55:38.380]  равно ты и тому соответственно. Вот. Ну ты и то это время выполнения операции аи-то. Ну аи-то операция,
[55:38.380 --> 55:52.420]  и ты операции. Нет. Ну ладно, проехали. Вот тогда t звездочка равная
[55:52.420 --> 56:22.260]  это амортизированное время. Время. Операции. Операции. Операции аи-то. Вот. Ну
[56:22.260 --> 56:30.340]  мы будем чаще всего рассматривать когда у нас тип операции а1. Вот например здесь это всякие
[56:30.340 --> 56:39.060]  в нашем случае где очередь на двух стэх это попа. Вот. Будем рассматривать время работы кучей попов.
[56:39.060 --> 56:50.140]  То есть если я вызову n раз pop, то как бы сколько, какое у меня будет время? Вот. Да. Ну средне
[56:50.140 --> 57:02.980]  рифметическое взял. То есть смотрите, здесь нам важно то, что мы переходим от одной операции конкретной,
[57:02.980 --> 57:08.620]  вот физически конкретный вызов, ну там функции какой-то, да, к последовательности операции. Потому
[57:08.620 --> 57:13.060]  что все-таки, как правило, вы совершаете последовательности операции на структуры и
[57:13.060 --> 57:22.820]  принято усреднять, скажем так. Вот. И мы будем рассматривать с вами несколько методов, а именно
[57:22.820 --> 57:31.380]  два. Как считать амортизационный анализ проводить. Вот. И мы будем рассматривать его на примере динамического
[57:31.380 --> 57:40.300]  массива, а не очереди на двух стэках. Для очереди на двух стэках проведете на семинарии анализ.
[57:40.300 --> 57:52.500]  Динамический массив-то все-таки большая классика. Ну и в целом для очереди на двух стэках применимо
[57:52.500 --> 57:59.860]  следующее утверждение, что с каждым элементом за его время жизни, его push до его pop, может
[57:59.860 --> 58:09.220]  случиться три вещи. Его запушили, его один раз перенесли и его pop-нули. Вы не можете переносить
[58:09.220 --> 58:14.020]  один и тот же элемент кучу раз. Поэтому суммарно с ним совершается константное количество операций.
[58:14.020 --> 58:27.780]  Вот. Какое вот заявление. Выводы делайте сами. Окей. А динамический массив. А в скобочках это
[58:27.780 --> 58:37.380]  всеми любимый забавенный std-вектор. Будем обсуждать, как он внутри реализован,
[58:37.380 --> 58:45.500]  именно что алгоритмически, не с точки зрения плюсов. Он делает следующее. Храним две переменных.
[58:45.500 --> 58:59.020]  Храним, собственно, массив. Указатель на массив. Указатель на нулевый элемент.
[58:59.020 --> 59:11.460]  То есть там int звездочка, короче говоря, он храним. Вот. Размер. Фактически. То есть сколько в нем
[59:11.460 --> 59:30.580]  элементов находится сейчас. И capacity. По-русски вместимость. Емкость. Вместимость. Например,
[59:30.580 --> 59:39.900]  когда вы делаете в коде, типа вы делаете массив на тысячу элементов, а дальше в него добавили только
[59:39.900 --> 59:50.220]  один элемент, то его сайз это один, а capacity тысяча. И что происходит когда? Вот вы все пишете
[59:50.220 --> 59:55.220]  прекрасно массивы в коде, потому что вы, когда алгоритмы решаете, потому что вы знаете максимальный
[59:55.220 --> 59:59.980]  размер. Вы знаете, что у вас там больше десяти в пятый чисел не введут, например. Значит, понятно,
[59:59.980 --> 01:00:09.180]  можно взять да и выделить на десять в пятый. Ну и победа. Это плохо. Плохая идея, потому что все-таки
[01:00:09.180 --> 01:00:13.940]  в реальной жизни вы не знаете таких пределов. Вам лучше иметь что-то, что умеет там расширяться.
[01:00:13.940 --> 01:00:37.700]  Автоматически причем. Поэтому в случае push. И сайз. Отпалась capacity. Когда у вас
[01:00:37.700 --> 01:00:59.700]  массив заполнен. Что вы делаете? Вы говорите увеличим capacity в два раза. Ну каким образом?
[01:00:59.700 --> 01:01:27.860]  Выделив новый массив и копируем в него старый. Понятное дело за от size.
[01:01:27.860 --> 01:01:44.260]  Такая вот идея, что если у вас, ну давайте на примере. Допустим, изначально у нас массив,
[01:01:44.260 --> 01:02:02.980]  на три элемента мы выделим. На два. Выделить там push 1, push 2. Получается единичка. Push от двойки.
[01:02:02.980 --> 01:02:11.100]  Вы делаете двойку. Дальше push от тройки. Что происходит? Эта штука превращается в
[01:02:11.100 --> 01:02:20.740]  массив два раза большего размера. То есть на четыре элемента. В него копируется единичка,
[01:02:20.740 --> 01:02:37.620]  двоечка. И дальше вы в него уже делаете push как обычно. Идея понятна? Утверждается,
[01:02:37.620 --> 01:02:48.820]  что если я делаю n push, то амортизированное время от единицы. Давайте это доказывать,
[01:02:48.820 --> 01:02:56.740]  по определению мы этого не будем. Уж так никто не делает. Мы рассмотрим два метода, как такое
[01:02:56.740 --> 01:03:10.980]  доказывают. Как оценивают амортизационное время. Ну да, амортизированное время. Почему амортизированное
[01:03:10.980 --> 01:03:18.860]  вообще называется? Что такое амортизатор? Кто не знает? Здесь вы тоже как бы сглаживаете
[01:03:18.860 --> 01:03:30.740]  эффекты тяжелых операций и как бы разносите их на более легкие. И первый метод. Давайте это.
[01:03:30.740 --> 01:03:45.740]  У нас был пункт A, пункт B. Начнем с самого сложного для понимания, но самого практически
[01:03:45.740 --> 01:04:05.820]  применимого. Метод потенциалов. Определение. Пусть phi, пусть s. Пусть s это структура данных.
[01:04:05.820 --> 01:04:29.340]  s и t это ее состояние после операции дексировали с единицы. Не важно. После этой операции.
[01:04:29.340 --> 01:04:52.380]  Операции. Тогда phi at s это потенциал, если и выполнено будет несколько свойств. Давайте подумаем,
[01:04:52.620 --> 01:05:08.100]  первое свойство оно плюс-минус очевидное. phi at s0 равно 0. Мы заранее фиксируем точку отсчета,
[01:05:08.100 --> 01:05:13.500]  что s0 это какое-то начальное состояние структуры данных. Мы будем верить, что это пустая структура
[01:05:13.500 --> 01:05:26.380]  данных, например, пустой динамический массив. phi at s0 равно 0. Второй тезис. Для любого i phi at s и t больше
[01:05:26.380 --> 01:05:33.500]  либо равно 0. Физики понимают, что это похоже на потенциальную энергию, что в любой момент энергия
[01:05:33.500 --> 01:05:39.220]  не отрицательна и вы выбираете заранее себе нулевой уровень. Те, кто не физики, но физику в школе
[01:05:39.220 --> 01:05:46.900]  проходили, тоже должны понимать. Ну, если не понимать, ничего страшного. Окей. Вроде бы это все.
[01:05:46.900 --> 01:06:11.500]  Тогда я тестопотенциал, если определение. Сейчас. А время через потенциалы
[01:06:16.900 --> 01:06:34.580]  и и т операции, это t и i t. Ну, давайте t phi его обозначим как-нибудь так.
[01:06:34.580 --> 01:06:42.620]  phi i t. Вот так вот. То есть через потенциал phi в момент операции и, как оно вычисляется?
[01:06:42.620 --> 01:06:51.820]  Давайте даже без phi вот. Так, t i t звездочка. Вот так вот будем обозначать. Это фактическое время операции плюс
[01:06:51.820 --> 01:07:01.260]  phi at s i t минус phi at s i t минус 1.
[01:07:04.580 --> 01:07:11.780]  Тогда я утверждаю, что вот такая вот, если я так буду складывать, то я получу верхнюю оценку на амортизированное время.
[01:07:11.780 --> 01:07:25.980]  Вот если я через такие стоимости буду определять. Утверждение, что t звездочка,
[01:07:25.980 --> 01:07:34.460]  которую мы там определяли, меньше либо равно, чем сумма t i t звездочка, деленная на n.
[01:07:34.460 --> 01:07:42.940]  Давайте доказывать. Наказательство здесь. Доказывать будем на твой доске.
[01:07:42.940 --> 01:08:00.820]  Давайте уберем эту штуку и докажем здесь. Что такое 1 деленное на n от суммы t i t звездочкой?
[01:08:00.820 --> 01:08:09.460]  Что? Не-не-не, у нас t i t звездочка. Видите, как блядь, как t i t звездочка?
[01:08:09.460 --> 01:08:24.660]  Ну сейчас посмотрим, что это такое. На сумму t i t плюс phi at s i t минус phi at s i t минус 1.
[01:08:24.660 --> 01:08:33.900]  Я здесь введу индекс, чтобы было понятно. Вот так. Закрываем скобку. Дальше расписываем это. Что такое?
[01:08:33.900 --> 01:08:50.740]  Закинем под одну дробь. Сумма t i t плюс сумма от i от 1 до n phi at s i t минус phi at s i t минус 1.
[01:08:50.740 --> 01:09:00.980]  Вот они, по-моему, называются телескопический ряд. То есть какая у него сумма будет?
[01:09:00.980 --> 01:09:05.420]  Все промежуточные склопнутся. Останется phi at s n, а здесь phi at s 0.
[01:09:05.420 --> 01:09:32.100]  Phi at s 0 равно нулю. Согласны? Это ноль. Что равно t звездочка по определению просто на той доске,
[01:09:32.300 --> 01:09:44.100]  сумма t i t делить на n. Это вот t звездочка. Плюс phi at s n поделенное на n.
[01:09:44.100 --> 01:09:51.980]  Но phi at s n больше либо равно 0 всегда. Это свое второе свойство. Поэтому это больше либо равно, чем t звездочка.
[01:09:52.460 --> 01:09:55.900]  Так эта штука больше 0. Доказали.
[01:09:58.500 --> 01:10:05.500]  Тогда мы можем через такую интересную величину просто выводить амортизированную верхнюю цинку на амортизированное время.
[01:10:07.420 --> 01:10:11.860]  Мы будем всегда считать, что у нас амортизированное время.
[01:10:11.860 --> 01:10:17.420]  Мы будем просто так делать, что у нас все время было через о-большое амортизированное оценивание.
[01:10:17.420 --> 01:10:25.460]  То есть у нас будет амортизированное время операции, как о-большое от чего-то.
[01:10:25.460 --> 01:10:33.860]  Остается вопрос, как вести потенциал для динамического массива.
[01:10:33.860 --> 01:10:44.860]  Пример. Пусть s это размер, c это вместимость.
[01:10:44.860 --> 01:11:00.860]  Тогда введем phi at s как вот такую формулю. 2s-c. Удвойный размер минус вместимость.
[01:11:03.860 --> 01:11:25.860]  С0 обозначим, что это пустой массив, который при пуше превращается в массив из одного элемента, дальше при пуше в массив из двух элементов, массив из четырех и так далее.
[01:11:25.860 --> 01:11:30.860]  Идем по степьям двойки. Давайте распишем изменения потенциалов.
[01:11:34.860 --> 01:11:50.860]  Рассмотрим, уж если s меньше c строго, если размер строго меньше к пассите. Что тогда?
[01:11:50.860 --> 01:11:53.860]  Тогда давайте рассмотрим его время.
[01:11:53.860 --> 01:12:08.860]  t и t звездочка равно t и t плюс phi at s и t минус phi от s и t минус 1.
[01:12:08.860 --> 01:12:15.860]  Вот оно. То есть время через потенциал определяется вот так вот.
[01:12:15.860 --> 01:12:24.860]  Что это фактическое время операции t и t плюс разность потенциалов, потраченная на изменение структуры.
[01:12:24.860 --> 01:12:33.860]  Мы его просто так определили с бухты Барахта. Доказали, что определение корректно, что с помощью него мы можем получать верхнюю оценку на амортизированное время в среднем.
[01:12:33.860 --> 01:12:36.860]  Просто амортизированное время.
[01:12:46.860 --> 01:12:56.860]  Что происходит здесь? Если у нас размер строго меньше вместимости, значит у нас размер просто увеличится на один и больше ничего не происходит. Согласны?
[01:12:56.860 --> 01:13:04.860]  Поэтому мы можем сказать, что здесь-то по сути структура вообще никак не меняется, мы просто описываем элемент.
[01:13:04.860 --> 01:13:07.860]  Не знаю, давайте скажем, что это один, да?
[01:13:08.860 --> 01:13:13.860]  Тогда t и t равно единичке.
[01:13:13.860 --> 01:13:18.860]  Просто запись элемента.
[01:13:23.860 --> 01:13:27.860]  Равно один плюс два равно три.
[01:13:27.860 --> 01:13:32.860]  Еще раз понятно, почему здесь лойка берется?
[01:13:32.860 --> 01:13:40.860]  Потому что у вас капасти не меняется и только размер увеличивается на единичку, а здесь как бы удвоенное просто.
[01:13:40.860 --> 01:13:49.860]  Хорошо, то есть показали с вами, что у нас амортизированное время пуш, когда он не вызывает реаллокации, назовем это так.
[01:13:49.860 --> 01:13:54.860]  Переводеление памяти или на прогерском реаллокация.
[01:13:54.860 --> 01:13:57.860]  Здесь три, ну константа.
[01:13:57.860 --> 01:14:00.860]  Хорошо, теперь пуш.
[01:14:00.860 --> 01:14:06.860]  Если s равно равно c.
[01:14:11.860 --> 01:14:14.860]  Ну давайте распишем фето с и то, да?
[01:14:14.860 --> 01:14:19.860]  Это 2s минус c.
[01:14:19.860 --> 01:14:22.860]  Не так.
[01:14:25.860 --> 01:14:30.860]  Ну на момент этого пуша, ну ладно, пускай будет вот так вот, да?
[01:14:30.860 --> 01:14:35.860]  Что у вас был размер s стало s плюс 1, вот так вот напишем.
[01:14:35.860 --> 01:14:38.860]  Согласны?
[01:14:38.860 --> 01:14:42.860]  До пуша у вас было вот такое вот.
[01:14:42.860 --> 01:14:47.860]  Потому что у вас размер был s, на момент пуша он увеличился на единичку.
[01:14:47.860 --> 01:14:54.860]  Ну здесь я думаю понятно, если вычислить одно из другого, получится двойка.
[01:14:54.860 --> 01:14:59.860]  Потому что, смотрите, вот пример.
[01:14:59.860 --> 01:15:02.860]  Давайте вот здесь вот я допишу, да?
[01:15:02.860 --> 01:15:05.860]  Пуша 4.
[01:15:05.860 --> 01:15:08.860]  У меня здесь не произойдет реаллокации.
[01:15:08.860 --> 01:15:13.860]  У меня здесь не произойдет реаллокации, то есть мне не нужно будет выделять новый массив и копировать.
[01:15:13.860 --> 01:15:14.860]  Все.
[01:15:14.860 --> 01:15:19.860]  Мне достаточно будет сделать тот же самый абсолютно массив на 4 элемента,
[01:15:19.860 --> 01:15:22.860]  просто дописать ему в конец четверку.
[01:15:22.860 --> 01:15:25.860]  Поэтому переуделения памяти не происходят.
[01:15:28.860 --> 01:15:30.860]  Да.
[01:15:30.860 --> 01:15:35.860]  Ну, собственно, сложность метапотенциала в том, чтобы подобрать потенциал, вау.
[01:15:35.860 --> 01:15:37.860]  Ну и показать, что он корректен.
[01:15:37.860 --> 01:15:40.860]  Корректность мы чуть позже покажем.
[01:15:40.860 --> 01:15:42.860]  Окей.
[01:15:42.860 --> 01:15:45.860]  Пуша s и s равно равно c.
[01:15:45.860 --> 01:15:53.860]  Тогда s и t минус первая имеет пару s и c.
[01:15:53.860 --> 01:15:57.860]  То есть размер s, капасти c, да?
[01:15:57.860 --> 01:16:00.860]  Тогда какое состояние у s и t будет?
[01:16:00.860 --> 01:16:03.860]  Какой у нее будет размер?
[01:16:03.860 --> 01:16:05.860]  s плюс 1, 2c.
[01:16:05.860 --> 01:16:09.860]  Давайте посмотрим, фея от s и t минус 7, что такое?
[01:16:11.860 --> 01:16:14.860]  Это просто 2s минус c.
[01:16:14.860 --> 01:16:22.860]  И от s и t это дважды s плюс 1 минус 2c.
[01:16:22.860 --> 01:16:26.860]  Вычтем, что мы получаем?
[01:16:26.860 --> 01:16:33.860]  2s минус c минус дважды s плюс 1 минус 2c.
[01:16:33.860 --> 01:16:36.860]  Смотрим.
[01:16:36.860 --> 01:16:45.860]  Это 2s минус c минус 2s минус 2 плюс 2c.
[01:16:45.860 --> 01:16:53.860]  Что равно уходит уходит c минус 2.
[01:16:53.860 --> 01:17:03.860]  То есть у вас получается, что фея от s и t минус фея от s и t минус 1 равно 2 минус c.
[01:17:06.860 --> 01:17:09.860]  Согласны?
[01:17:09.860 --> 01:17:12.860]  Ну потому что я здесь вычитал просто наоборот.
[01:17:12.860 --> 01:17:14.860]  Так получилось.
[01:17:14.860 --> 01:17:17.860]  Поэтому здесь с минусом пошел.
[01:17:17.860 --> 01:17:21.860]  Так, вопросов по этим вычтениям нет, я сейчас сотру.
[01:17:21.860 --> 01:17:25.860]  Так, не волнуйтесь, мы сейчас буквально еще две минутки и мы закончим.
[01:17:28.860 --> 01:17:31.860]  Это не проблема.
[01:17:31.860 --> 01:17:33.860]  Ну смотрите.
[01:17:33.860 --> 01:17:35.860]  Вот вы PMF, да?
[01:17:35.860 --> 01:17:37.860]  Отлично.
[01:17:37.860 --> 01:17:41.860]  Как изменилась потенциальная энергия этой штуки?
[01:17:41.860 --> 01:17:43.860]  Ну вот.
[01:17:43.860 --> 01:17:49.860]  Попросы?
[01:17:56.860 --> 01:18:00.860]  А теперь рассмотрим эта звездочка, которая мы хотели с вами.
[01:18:00.860 --> 01:18:02.860]  Таита и звездочка, да?
[01:18:05.860 --> 01:18:10.860]  Таита здесь нам нужно потратить на то, чтобы внезапно что сделать?
[01:18:10.860 --> 01:18:12.860]  Перекопировать n элементов.
[01:18:12.860 --> 01:18:18.860]  Давайте будем искренне верить, что массив выделяется в золоть единицы длины 2с.
[01:18:18.860 --> 01:18:24.860]  Ну иначе там просто будем чуть-чуть более по-другому перепишем потенциал.
[01:18:24.860 --> 01:18:28.860]  Но я верю, что память выделяется в золоть единицы у нас.
[01:18:28.860 --> 01:18:30.860]  Тогда Таита и звездочка, это что такое?
[01:18:30.860 --> 01:18:32.860]  Это s, так как нам нужно s элементов скопировать.
[01:18:32.860 --> 01:18:34.860]  У вас же s размер, да?
[01:18:35.860 --> 01:18:40.860]  Плюс один элемент на то, чтобы дописать новый элемент, который вы запушили.
[01:18:40.860 --> 01:18:42.860]  Логично, да?
[01:18:42.860 --> 01:18:44.860]  Это вот Таита.
[01:18:48.860 --> 01:18:52.860]  Ну, потому что здесь можно везде ошки навешивать, это правда.
[01:18:52.860 --> 01:18:57.860]  Ну, давайте мы не будем их навешивать, просто так будет меньше писать, и это все еще корректно.
[01:18:57.860 --> 01:18:59.860]  Потому что мы так просто определяем стоимости.
[01:18:59.860 --> 01:19:06.860]  Здесь нам важно соблюсти не сколько константность соотношения, сколько порядка.
[01:19:06.860 --> 01:19:08.860]  Но при этом константность тоже важна.
[01:19:08.860 --> 01:19:15.860]  То есть если вы говорите, что в операции, которые выполняют два действия, я буду говорить, что это будто одно, это неправда.
[01:19:15.860 --> 01:19:17.860]  Поэтому я все-таки...
[01:19:17.860 --> 01:19:21.860]  Все-таки в амортизационном анализе, когда вы определяете именно вот эти вот Таиты,
[01:19:21.860 --> 01:19:23.860]  вы же по сути что определяете?
[01:19:23.860 --> 01:19:25.860]  Вы определяете ФИ и Таиты.
[01:19:25.860 --> 01:19:27.860]  А дальше считаете просто.
[01:19:27.860 --> 01:19:31.860]  Вот Таиты, они должны соотноситься с реальностью все-таки, так или иначе.
[01:19:31.860 --> 01:19:33.860]  Причем чем точнее, тем лучше ваш амортизационный анализ.
[01:19:33.860 --> 01:19:35.860]  Значит, можно прийти к неверным выборам.
[01:19:35.860 --> 01:19:37.860]  Вот.
[01:19:38.860 --> 01:19:40.860]  И плюс эта разница.
[01:19:40.860 --> 01:19:42.860]  Плюс два, минус С.
[01:19:44.860 --> 01:19:46.860]  Внимание, вопрос. Чему это равно?
[01:19:47.860 --> 01:19:49.860]  Это равно 3.
[01:19:51.860 --> 01:19:54.860]  Так как С равно равно С в нашем случае.
[01:19:54.860 --> 01:19:56.860]  Видите, мы же рассматриваем ситуацию вот эту вот.
[01:19:57.860 --> 01:19:59.860]  Это равно 3.
[01:19:59.860 --> 01:20:01.860]  Тоже констант.
[01:20:01.860 --> 01:20:03.860]  Все, мы показали, что амортизационное время от единицы.
[01:20:03.860 --> 01:20:05.860]  Амортизированное время.
[01:20:05.860 --> 01:20:07.860]  Даже для Пуши с реаллокацией.
[01:20:07.860 --> 01:20:09.860]  Вот.
[01:20:09.860 --> 01:20:11.860]  Математически все сошлось.
[01:20:11.860 --> 01:20:14.860]  Есть еще один метод, который я, к сожалению, не успел рассказать.
[01:20:16.860 --> 01:20:18.860]  Потому что мы на перерыве завержались.
[01:20:18.860 --> 01:20:20.860]  Нам бы пяти минут хватило бы.
[01:20:20.860 --> 01:20:22.860]  Ну окей. Не судьба.
[01:20:22.860 --> 01:20:24.860]  Я напишу просто его название.
[01:20:24.860 --> 01:20:26.860]  И на семинарах вы его разберете.
[01:20:26.860 --> 01:20:28.860]  На этом же примере.
[01:20:29.860 --> 01:20:31.860]  Я напишу здесь.
[01:20:31.860 --> 01:20:33.860]  Замечание.
[01:20:35.860 --> 01:20:37.860]  Есть еще.
[01:20:37.860 --> 01:20:39.860]  Метод монеток.
[01:20:43.860 --> 01:20:45.860]  Его называют методом бухучета.
[01:20:45.860 --> 01:20:47.860]  Но.
[01:20:49.860 --> 01:20:51.860]  Привычнее метод монеток.
[01:20:51.860 --> 01:20:53.860]  Оба названия эквивалентны.
[01:20:53.860 --> 01:20:55.860]  По-английски это будет
[01:20:55.860 --> 01:20:57.860]  accounting methods.
[01:21:01.860 --> 01:21:05.860]  А этот потенциал он через potentials метод.
[01:21:07.860 --> 01:21:11.860]  Бухучета чуть проще для восприятия, с одной стороны.
[01:21:11.860 --> 01:21:13.860]  Но у него есть проблема.
[01:21:13.860 --> 01:21:16.860]  Потому что когда у вас амортизированное время внезапно не от единицы.
[01:21:16.860 --> 01:21:19.860]  Там становится все очень-очень грустно.
[01:21:19.860 --> 01:21:21.860]  Доказывать очень-очень сложно.
[01:21:21.860 --> 01:21:24.860]  И там нужно будет больше передумывать гораздо.
[01:21:24.860 --> 01:21:26.860]  В этом плане метод потенциалов оптимален,
[01:21:26.860 --> 01:21:28.860]  когда вы доказываете,
[01:21:28.860 --> 01:21:30.860]  что амортизированное время не от единицы.
[01:21:30.860 --> 01:21:32.860]  Например, логариф амортизированный.
[01:21:32.860 --> 01:21:34.860]  У нас, скорее всего, будет структура данных,
[01:21:34.860 --> 01:21:36.860]  где будет возникать амортизированный логарифом.
[01:21:36.860 --> 01:21:39.860]  Но, скорее всего, мы ее доказывать просто не будем.
[01:21:39.860 --> 01:21:42.860]  Потому что иначе мы потратим на это поллегция.
[01:21:42.860 --> 01:21:44.860]  Это сплей дерева называется такая штука.
[01:21:44.860 --> 01:21:46.860]  Кто слышал, тот испугался.
[01:21:48.860 --> 01:21:50.860]  Кто не слышал, тот тоже испугался.
[01:21:50.860 --> 01:21:52.860]  Вот.
[01:21:52.860 --> 01:21:54.860]  Так, вопросы.
[01:21:56.860 --> 01:21:58.860]  О, да, это верный вопрос.
[01:21:58.860 --> 01:22:00.860]  Так, все, тихо, не собираемся.
[01:22:00.860 --> 01:22:02.860]  У вас перерыв 20 минут, я знаю.
[01:22:02.860 --> 01:22:04.860]  Как доказывать корректность потенциала?
[01:22:06.860 --> 01:22:08.860]  Мы должны с вами сказать,
[01:22:08.860 --> 01:22:10.860]  что фет s0 равно 0.
[01:22:10.860 --> 01:22:12.860]  Мы с вами определили s0 как пустой массив.
[01:22:12.860 --> 01:22:14.860]  У него размер 0,
[01:22:14.860 --> 01:22:16.860]  капасти 0, фет s0 равно 0.
[01:22:16.860 --> 01:22:18.860]  Это правда, да?
[01:22:18.860 --> 01:22:20.860]  И самое интересное.
[01:22:20.860 --> 01:22:22.860]  Как доказывать, что потенциал корректен
[01:22:22.860 --> 01:22:24.860]  с точки зрения второго требования?
[01:22:24.860 --> 01:22:26.860]  Утверждается, что в любой момент времени
[01:22:26.860 --> 01:22:28.860]  у вас массив хотя бы наполовину полон.
[01:22:28.860 --> 01:22:30.860]  Вот есть наполовину пуст,
[01:22:30.860 --> 01:22:32.860]  наполовину полон.
[01:22:32.860 --> 01:22:34.860]  У нас оптимистичность для одной вещи.
[01:22:34.860 --> 01:22:36.860]  Потому что мы потенциал уже подгадали.
[01:22:36.860 --> 01:22:38.860]  Вот.
[01:22:38.860 --> 01:22:40.860]  Если у нас размер,
[01:22:40.860 --> 01:22:42.860]  то есть у нас в любой момент времени
[01:22:42.860 --> 01:22:44.860]  s больше либо равно, чем c пополам.
[01:22:44.860 --> 01:22:46.860]  Тогда 2s-c больше либо равно 0.
[01:22:46.860 --> 01:22:48.860]  Собственно,
[01:22:48.860 --> 01:22:50.860]  из этого наблюдения
[01:22:50.860 --> 01:22:52.860]  внезапно формируется этот потенциал.
[01:22:54.860 --> 01:22:56.860]  То есть можно сказать, что
[01:22:56.860 --> 01:22:58.860]  действительно мы его подгадали
[01:22:58.860 --> 01:23:00.860]  из ниоткуда с бухты-барахты.
[01:23:00.860 --> 01:23:02.860]  Но обычно потенциал возникает
[01:23:02.860 --> 01:23:04.860]  из физических ограничений задачи.
[01:23:04.860 --> 01:23:06.860]  А именно, например, из такого,
[01:23:06.860 --> 01:23:08.860]  что у вас есть вариант,
[01:23:08.860 --> 01:23:10.860]  что s больше либо равно c пополам.
[01:23:10.860 --> 01:23:12.860]  Поэтому просто переносите это
[01:23:12.860 --> 01:23:14.860]  Вот.
[01:23:18.860 --> 01:23:20.860]  Подождите.
[01:23:20.860 --> 01:23:22.860]  Про уменьшение я еще ничего не говорю.
[01:23:22.860 --> 01:23:24.860]  Стандартный STD-вектор
[01:23:24.860 --> 01:23:26.860]  он не делает уменьшений.
[01:23:26.860 --> 01:23:28.860]  На семинаре у вас будет задача
[01:23:28.860 --> 01:23:30.860]  придумать, какой потенциал нужно сделать,
[01:23:30.860 --> 01:23:32.860]  чтобы у вас еще при уменьшениях все работало.
[01:23:32.860 --> 01:23:34.860]  И как это делать.
[01:23:34.860 --> 01:23:36.860]  Вот.
[01:23:36.860 --> 01:23:38.860]  Ну там будет модуля 2s-c потенциал.
[01:23:38.860 --> 01:23:40.860]  Ну я, скажем так, точно скажу
[01:23:40.860 --> 01:23:42.860]  семинаристам, чтобы они
[01:23:42.860 --> 01:23:44.860]  понимали, что происходит.
[01:23:44.860 --> 01:23:46.860]  Вот.
[01:23:46.860 --> 01:23:48.860]  Если вопросов больше нет, то все.
