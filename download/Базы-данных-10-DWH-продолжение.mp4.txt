[00:00.000 --> 00:13.000]  У нас сегодня с вами 10-я лекция, посвященная хранилищам данных.
[00:13.000 --> 00:18.000]  В принципе, концептуально мы с вами уже говорили на прошлой лекции о том, что это такое.
[00:18.000 --> 00:21.000]  Сегодня поговорим чуть более подробно.
[00:21.000 --> 00:35.000]  И, в принципе, наверное, на этой лекции мы с вами завершаем такую большую тему, как SQL, база данных.
[00:35.000 --> 00:43.000]  У нас еще будет одна или, может быть, две лекции на тему нерелиционных баз данных,
[00:43.000 --> 00:47.000]  какими особо они представлены и в чем их особенности.
[00:47.000 --> 00:54.000]  Сейчас, соответственно, закончу с вами тему хранилища масштабируемости законов Андела и Густавсона Барриса.
[00:54.000 --> 01:01.000]  Также на прошлой лекции был небольшой вопрос по B-деревьям.
[01:01.000 --> 01:07.000]  Буквально пару слайдов им посвятим сейчас вначале. Проговорим еще раз, что это и как это.
[01:07.000 --> 01:14.000]  Индексы B-деревья, как мы с вами говорили, это индекс по умолчанию, используемый позгрессом.
[01:14.000 --> 01:26.000]  И он в первую очередь употреблен вместе с операциями сравнения, показанными на слайде.
[01:26.000 --> 01:35.000]  Ну, также, если у нас локаль C, мы можем еще и в запросах с операторами сравнения по шаблону использовать этот индекс.
[01:35.000 --> 01:38.000]  Ну, или он будет по умолчанию использован.
[01:38.000 --> 01:46.000]  Технически можно и уйти за пределы локали C, но для этого нужно будет дорабатывать процесс создания индекса, скажем так.
[01:46.000 --> 01:52.000]  И, ну, определенные технические сложности в этом есть.
[01:52.000 --> 02:13.000]  Тогда как с символами нативными, а с ангоязычными, да, с работой, ну, и с кодировкой ASCII, ну, или ASCII работает у нас B3-деревья индексовые, индексные по умолчанию.
[02:13.000 --> 02:23.000]  Ну, что такое B3, наверное, вернее, B-деревья, я думаю, вы, в принципе, представляете кратко, просто в двух словах.
[02:23.000 --> 02:35.000]  У нас на B-деревья есть, ну, что важно, да, что, наверное, наиболее важно, у нас есть условия на количество потомков.
[02:35.000 --> 02:43.000]  И от количества потомков зависит количество ключей в каждом из узлов дерева, в каждом из узлов дерева.
[02:43.000 --> 02:54.000]  И за счет того, чтобы количество потомков не будет, не может превышать заданное, у нас появляется свойство балансировки.
[02:54.000 --> 03:16.000]  И мы, соответственно, можем таким образом тоже гарантировать время отработки алгоритма поиска по B-деревью за счет того, что у нас до каждого листа есть конечная длина пути, ну, варьируемая на единицу.
[03:16.000 --> 03:32.000]  А что касается, ну, на примере, да, опять же, приведено B-деревье с числом потомков 3, то есть каждый узел может содержать один или два ключа и, соответственно, два или три потомка.
[03:32.000 --> 03:50.000]  Понятно, что у нас в зависимости от того, какие ключи в узле, в левую или правую ветвь дерева или ветвь каждого из узлов пойдут значения там больше-меньше или между конкретными ключами.
[03:50.000 --> 04:05.000]  Ну и, соответственно, от четверки у нас с левой и справа при добавлении от единицы до 9 значений до вершины дерева оказалось четверка, и от четверки на левой и направо пошли ключи меньше и больше, чем она.
[04:05.000 --> 04:34.000]  Ну, понятно, это не 3 и 5 получилось, потому что у нас последовательное добавление происходило, и поэтому у нас постепенное такое рекурсивное движение по дереву, когда ключи по узлам распределяются и узлы добавляются в зависимости от того, какое значение добавляется очередное в дерево.
[04:34.000 --> 04:58.000]  Ну, от слов до больших, собственно говоря, не то, что к действиям, а к результатам, к выводам. Вопрос был на прошлой лекции про сравнение в лексикографическом порядке, а если говорить про индексы, про то, что у нас происходит под капотом,
[04:58.000 --> 05:16.000]  там более сложная система представлений данных, и там сравниваться будут не значения, а ссылки на значения внутри страниц, файлов, которые содержат, собственно, информацию, хранящуюся в данных.
[05:16.000 --> 05:33.000]  Поэтому там не обязательно будет лексикографический порядок, но некоторый количественный порядок, предполагающий возможность сравнения больше, меньше или равно, будет иметь место.
[05:33.000 --> 05:49.000]  Просто не для каждого, там не будет значений в виде слов, не обязательно они будут использоваться в виде слов, когда у нас будет последовательное сравнение с каждой буквой слова, каждой буквой какого-то другого сравниваемого слова.
[05:49.000 --> 06:00.000]  То, чем характеризуется лексикографический. У нас есть массив строка в виде массива, и каждый элемент массива – это буква, и при лексикографическом мы сравниваем порядок каждой буквы.
[06:00.000 --> 06:09.000]  При, условно говоря, количественном сравнении мы не будем сравнивать каждый разряд числа, мы сравним одно число с другим, будет скорее сравнение одного числа с другим.
[06:09.000 --> 06:36.000]  Ну хорошо, из интересного, что можно по Бодеревиям посмотреть, почитать в разрезе Позгресса именно, ссылки приведены, есть хорошая статья на Хабре, к ней я отсылаю за, собственно, ее исчерпываемостью, наверное, ссылка приведена там с выкладками о том, как это все представляется, в том числе на системном уровне.
[06:36.000 --> 07:04.000]  Также, это, конечно, документация, ну и, помимо документации, есть еще прям для очень глубокого погружения, то, что реализовано под капотом Позгресса под названием B3Index, это последняя ссылка в разделе «Почитать», ссылка на документацию Позгресса, ну, ссылка, вернее, на файл в репозитории Позгресса, где подробно описывается вопрос реализации B3.
[07:04.000 --> 07:26.000]  И, опять же, вот про визуализацию, ссылка в разделе «Посмотреть». В университет Сан-Франциско, утилитовую, небольшую создал, браузерную, где можно в режиме реального времени просто подобавлять, поудалять в некое дерево.
[07:26.000 --> 07:44.000]  Это, конечно, не совсем уже в разрезе Позгресса, это просто для интереса может поиграться, кому-то будет поиграться с B-деревьями, как они работают при добавлении, удалении, поиске элементов.
[07:44.000 --> 07:54.000]  Хорошо, хранилища данных. Проговорим еще раз кратенько. Предпосылки мы с вами, в принципе, уже упоминали.
[07:54.000 --> 08:08.000]  Еще раз основная предпосылка заключается в том, что данных становилось все больше. Анализировать их приходилось все чаще.
[08:08.000 --> 08:31.000]  Соответственно, нам нужно куда-то эти данные для удобного обращения системе сливать в одно место, в одно хранилище, и из этого хранилища как-то их оттуда изымать, как-то распределять по конечным узлам, с которыми будут взаиводействовать наши бизнес-пользователи.
[08:31.000 --> 08:50.000]  И все это, в принципе, решается в рамках концепции хранилищ данных или в рамках аналогичных концепций, ну, по сути дела, произрастающих хранилищ данных, просто уже не так привязанных к нормализации какой-то структуры.
[08:50.000 --> 08:58.000]  Тоже об этом проговаривали мы. Это океаны данных, болота данных, озера данных и так далее.
[08:58.000 --> 09:15.000]  Но, что интересно еще отметить, хранилища данных стали появляться в рамках систем принятия бизнес-решений.
[09:15.000 --> 09:25.000]  Первые такие попытки стали появляться, ну, по агрегации какой-то более или менее интеллектуальной обработки, стали появляться вот в 80-х годах.
[09:25.000 --> 09:54.000]  Это все несколько условно, поскольку что такое бизнес-анализ, математически строго сформулировать нельзя, но можно считать, что в 85-м году Проктор и Энгембл такую систему для них была разработана для того, чтобы анализировать информацию о продаже и данные розничных сканеров.
[09:54.000 --> 10:09.000]  Business Data Warehouse, термин 88-го года из статьи, ну и первая система управления базами данных, предназначенная для работы с большими данными, с хранилищами данных.
[10:09.000 --> 10:37.000]  Здесь уже опять, это 91-й год, здесь уже упоминаются имена Кимбала и Инмана, Ральфа Кимбала и Инмана, повторюсь, это основные такие вот, ну, в кавычках теоретики, концепции хранилищ данных, в кавычках они, потому что, строго говоря, в базах, в классических базах данных не так много какой-то глубокой подлежащей математической теории.
[10:37.000 --> 11:02.000]  Ну, она, безусловно, есть связанная с реализационной моделью, с нормализацией, но это лишь часть, опять же, до того, что вы с вами проходили, и по нашему курсу можете сами судить, сколько мы лекции посвятили чему-то такому, приближенному к математике и теории множеству, и сколько мы лекции посвятили синтаксису SQL и каким-то продвинутым свойствам.
[11:02.000 --> 11:22.000]  Большая часть лекций у нас была посвящена не математике, к сожалению, пожалуй, что, а в хранилищах данных, в принципе, математики не остаются как таковой, там чистые концепции качественные о том, как лучше взаимодействовать с большими объемами данных.
[11:22.000 --> 11:44.000]  Ну, напомню, что Уильям Инман выступает за нормализацию данных в хранилище, за такой подход сверху вниз, за entity relationship model при проектировании, за, в принципе, глубокое проектирование хранилищ
[11:44.000 --> 11:55.000]  по тем же принципам и закономерностям, которые характерны для проектирования революционных баз данных, которые мы с вами проходили.
[11:55.000 --> 12:06.000]  Грубо говоря, Уильям Инман – это апологет концепции, ну тоже, повторюсь, грубо концепции, согласно которой хранилища данных – это просто одна общая большая база данных.
[12:06.000 --> 12:18.000]  Соответственно, к ней применимы все те оговорки, которые применены для любой революционной базы данных вне зависимости от того, какие данные, какие объемы в ней хранятся.
[12:18.000 --> 12:34.000]  Ральф Кимбелл в этом смысле пошел несколько дальше. Он придумал качественную схему звезда, разработал концепцию dimensional modeling, моделирование измерений.
[12:34.000 --> 12:55.000]  Мы с вами об этом говорили кратко, когда обсуждали вопрос о медленноменяющихся измерениях, как вы помните, вопрос версионирования данных или версионности данных, того, как эту версионность, версионирование поддерживать и оптимально хранить.
[12:55.000 --> 13:19.000]  Соответственно, напомню вам, что вы тогда говорили, но сейчас, в общем, напоминаю, получается, что измерительное моделирование, моделирование измерений – это термин, имеющий смысл с точки зрения структурного паттерна проектирования данных под названием звезда,
[13:19.000 --> 13:37.000]  когда у нас есть разделение между таблицами измерений и таблицами фактов, и в таблице фактов записываются данные об измерениях, данные об измерениях фактов хозяйственной жизни компании.
[13:37.000 --> 14:06.000]  При этом таблицы измерений записываются не в метрике, т.е. в таблице измерений в них речь не о том, что мы что-то измеряем, а о том, что у нас есть некоторые объекты и события, которые мы считаем измерениями по аналогии с пространственными измерениями в 2D пространстве, в 3D пространстве.
[14:06.000 --> 14:14.000]  То есть целые оси считаются измерениями, а не факт замера по линейке какого-то расстояния.
[14:14.000 --> 14:42.000]  Вот так же и здесь, т.е. в таблицах фактов мы фиксируем именно нашу метрическую активность, что происходит измерительная активность, что происходит с компанией, что происходит с продуктом, что происходит на кассе с товаром или на складе с товаром, а в таблице измерения мы записываем данные о товаре, о кассе, о складе, о продавце, о магазине, о поставщике, о покупателе и т.д.
[14:43.000 --> 15:02.000]  То есть факты, то, что происходит, измерения, то, чем это происходит и то, что участвует в том, что происходит. Такие немножко может быть очень абстрактные описания, но я думаю в контексте сказанного это должно быть понятно.
[15:02.000 --> 15:21.000]  Структурно хранилище, соответственно, проектируется с помощью схемы звезда. И схема звезда, как вы, возможно, помните из прошлых лекций, выглядит, условно выглядит примерно так.
[15:21.000 --> 15:44.000]  Звезда здесь пунктируема, обозначена, по сути дела, неважно сколько у нее лучей. Смысл в том, что у нас в грубом приближении простая примитивная схема звезда, это когда у нас одна таблица фактов, может быть их несколько, но нас это не особо интересует, они по сути дела равноуровневые, равноправные.
[15:44.000 --> 16:12.000]  И когда у нас от этой таблицы фактов отходят лучи и появляются на концах этих лучей таблицы измерений. То есть, грубо говоря, у нас такое двухуровневое дерево, где один корневой узел и какое-то количество листов, соединяемых с корневым узлом всего одной дугой каждый.
[16:12.000 --> 16:41.000]  Таблица измерений может быть разделена или аугментирована, улучшена, дополнена таблицами суп-измерений. И в таком случае у нас появится схема снежинки, тогда у нас корневого узла от нашей таблицы фактов уже будет непонятно.
[16:42.000 --> 17:11.000]  Путь длиной не в одну дугу, соединять ее с листом, с концевым узлом А, а может быть несколько дуг, то есть может быть суп-суп-суп-суп измерения у каждой таблицы измерений, и тогда у нас получается такое в противовесбой деревьям опять же несбалансированное дерево, где может быть у нас у таблицы фактов какое-то измерение просто измерений без дополнительных таблиц,
[17:12.000 --> 17:41.000]  но каких-то измерений может быть, как вы видите, либо два суп-измерения, либо суп-суп-суп измерения, и такое более сложное ветвление, но опять же структурно, графически оно появляется с точки зрения наших операций по поиску и излечению данных принципиального различия здесь, пожалуй, нет, потому что все эти буги они репрезентуют собой, констатируют собой только.
[17:42.000 --> 18:09.000]  Функциональные, по сути дела, зависимости и с точки зрения операций по работе с данными, а я напомню, мы здесь все еще находимся в SQL таком, что ли, пространстве, в SQL-логике, то есть все о чем мы здесь говорим, это все еще не обязательно релиционные, может быть прям такие в классическом понимании схемы баз данных,
[18:09.000 --> 18:31.000]  но это все еще данные, хранимые таким образом, что к ним применимо синтаксис SQL и соответствующие операции поддерживаемые, так что это все то, что мы видим, это по сути дела отражает просто некую логическую структуру.
[18:31.000 --> 18:57.000]  Что еще можно сказать про схему Снежинка, что здесь, в отличие от классической схемы, условно классической, первой просто схемы, схемы звезды, таблицы измерений становятся нормализованными, и вот эти вот взаимосвязи рисунки, они не просто
[18:57.000 --> 19:16.000]  не просто какую-то содержательную логику представляют собой, а в том числе некие релиционные ограничения, в них все-таки поддерживаются, то есть это такой шаг к больше формализации, что ли, схемы звезды.
[19:16.000 --> 19:35.000]  Да, вот, ну и как во втором будете написано, схемы звезды, таблицы измерений полностью динарбализованы с каждым измерением, представленным в виде единой таблицы, ну опять же, это по такой вот прям, по классике, по классике, вот прям, что называется, при буквальном следовании текста первоисточника.
[19:35.000 --> 19:49.000]  Конечно, на практике ни схемы, ни схемы звезды, там ни какой-то классической нормализации в схеме снежинки может не быть, поэтому к этому нужно относиться, да, вот, к таким вырежденным, что ли, случаем, как крайнего рода примерам, но тем не менее, отталкиваясь от них, можно как-то анализировать многообразие его,
[20:05.000 --> 20:31.000]  реально сущего. Чем больше степень нормализации таблиц измерений, тем сложнее выглядит структура схемы снежинки, создаваемый эффект снежинки затрагивает только таблицы измерений и неприменим, что важно к таблицам фактов, то есть таблицы фактов у нас не нормализуются, они записываются, исходя из сугубо бизнес-логики, из реальных бизнес-процессов.
[20:31.000 --> 20:54.000]  Общая концепция с вами тоже на прошлом занятии, на прошлой лекции к этому слайду уже обращались, но давайте тоже немножко повторим, то есть о чем идет речь в хранилищах данных, в теме хранилищей данных, что у нас есть некоторое количество внешних источников, которые нам поставляют данные, поставляют фактические данные.
[20:54.000 --> 21:24.000]  Речь не о каких-то вендорах, не о чем-то, что гуляет по сети, речь о том, что где-то сидит начальник склада и оцифровывает ведомости или следит за тем, чтобы цифровые ведомости, электронные УПД правильно заносились, ну условно начальник склада, скорее какой-то IT-специалист, администратор местной базы следит за тем, чтобы
[21:24.000 --> 21:32.000]  действительно внешних источников, напрямую внешних, там бумажных документов, электронных документов данные заносились в базу.
[21:32.000 --> 21:44.000]  Базы у нас распределены, и это часто бывает, и это прям часто проблема, реальные проблемы распределены по департаментам, по, может быть, даже отделам.
[21:44.000 --> 22:02.000]  Еще интереснее, когда у нас разные департаменты имеют разные, не просто даже базы, а разные ДВХ-решения, такое тоже бывает, если организации крупные, и эти разные ДВХ-решения еще и могут быть от разных вендоров.
[22:02.000 --> 22:24.000]  То есть системы напрямую могут не относиться друг с другом, и мы не сможем слить данные из одного департамента с другим, какой-то удобной, единой командой нам придется что-то промежуточное делать,
[22:24.000 --> 22:34.000]  какую-то промежуточную стадию хранения создавать, отдельный сервер, отдельные процедуры, отдельная поддержка и так далее и тому подобное.
[22:34.000 --> 22:47.000]  Ну так вот, ладно, операционные приложения, то есть приложения, которые непосредственно берут данные из внешних источников и их складируют в местные, условно говоря, базы данных по отделам, по департаментам.
[22:47.000 --> 22:56.000]  Дальше все это посредством некоторых, неких процессов, которые на слайде объединены аббревиатурой ETL, переправляется в ДВХ.
[22:56.000 --> 23:17.000]  Из ДВХ уже, собственно, зачем нам нужна агрегация? Из ДВХ мы уже можем эти данные извлекать для бизнес-пользователей, представлять в каком-то удобном для анализа, для визуализации в виде,
[23:17.000 --> 23:39.000]  извлекать там, проводить какую-то аналитику, на них строить какие-то зависимости, выявлять, вернее, что здесь, опять же, подчеркну важно, в первую очередь, это ETL, потому что важно оно потому, что на самом деле оно неважно, неважно в том плане, в каком оно нарисовано.
[23:39.000 --> 24:09.000]  Повторюсь, на прошлой лекции я вам уже говорил, и на практике такое встречается часто, хотя на собеседовании у вас могут спросить, а что такое ETL, и как бы по классике, вот ETL это экстракт transform load, извлечь, очистить, или очистить, и преобразовать, и загрузить, то есть промежуточный шаг между операционными приложениями и ДВХ-хранилищем, но, по сути дела, в реальности могут быть какие-то отдельные процессы, которые вообще
[24:09.000 --> 24:09.600]  в
[24:11.600 --> 24:17.000]  в лапку бы закидывать в какие-то приложения для отчетности, в витрины данных.
[24:17.000 --> 24:25.900]  Могут быть по-разному настроенные процессы внутри ETL стека, и
[24:25.900 --> 24:35.500]  И в разном порядке они могут происходить, и не факт, что этот разный порядок...
[24:35.500 --> 24:43.180]  Ну, то есть говорят, что есть EL, говорят, что есть ELT, то есть Extract, Load и Transform,
[24:43.180 --> 24:47.100]  когда мы сначала загружаем, а потом уже начинаем трансформировать.
[24:47.100 --> 24:55.860]  И говорят, что вот ELT, оно может возникать после стадии DWH, то есть после стадии хранения.
[24:55.860 --> 25:04.420]  Ну, или там Transform будет, этап очистки и преобразования будет после стадии хранения в хранилище и так далее.
[25:04.420 --> 25:12.820]  На практике все это перемешано, все это проблемно, неоднозначно, и с другой стороны, наверное, все-таки эффективно,
[25:12.820 --> 25:18.260]  потому что каждая компания делает это под себя и делает так, как и удобно.
[25:18.260 --> 25:23.860]  И с учетом того, что, повторюсь, у нас за концепцией хранилищ и данных не стоит никакой глубокой математики,
[25:23.860 --> 25:28.660]  какой-то формализованной модели, в принципе, ограничений на это нет, кроме вот концептуальных.
[25:28.660 --> 25:34.740]  Поэтому здесь кто во что гораздо, кому что ближе, кому что эффективнее с точки зрения его процесса.
[25:37.300 --> 25:45.860]  Так что вот так. Поэтому классическую схему надо себе представлять, но понимать, что, может быть,
[25:45.860 --> 25:50.180]  все там неоднозначно и по-разному, и, возможно, на этапе предсобеседования, как-то,
[25:50.180 --> 25:55.300]  посмотрите на компанию какую-то, посмотреть вообще на том же хабре, может быть, какие-то статьи
[25:55.300 --> 26:01.300]  о том, что эти ребята используют у себя на практике при хранении данных.
[26:01.300 --> 26:08.660]  Очень может быть, что для крупных работодателей, крупных компаний вы какие-то интересные заметки найдете,
[26:08.660 --> 26:12.820]  и, опять же, сможете соотнести с тем, о чем мы с вами говорим.
[26:12.820 --> 26:18.100]  Окей, давайте немножко поподробнее посмотрим на ITL-процесс.
[26:18.100 --> 26:26.580]  Вот на слайде набор процессов, неразрывно связанных с хранилищами данных и основным назначением которых,
[26:26.580 --> 26:32.340]  является наполнение заранее спроектированной физической модели данных с учетом ограничений логической модели.
[26:32.340 --> 26:41.860]  Ну, понятно, то есть внутри DWH у нас есть какая-то своя логика хранения, какое-то представление наших
[26:41.860 --> 26:56.260]  вот этих вот таблиц с данными, и, с другой стороны, у нас есть некоторое количество
[26:56.260 --> 27:02.500]  несогласующихся между собой данных из наших операционных приложений по разным департаментам.
[27:03.060 --> 27:13.220]  Разные департаменты, скорее всего, возможно, создавали свои базы данных до того, как компания приняла решение
[27:13.220 --> 27:20.260]  создать корпоративные хранилища, поэтому здесь данные могут быть совершенно разрозненные,
[27:20.260 --> 27:32.100]  ну, из того, что вот прям, что ли, в некотором роде классический тоже пример, когда разные форматы
[27:32.100 --> 27:38.260]  даты времени, и, особенно, если разные часовые пояса, в разных часовых поясах компания операционную
[27:38.260 --> 27:47.220]  деятельность осуществляет, у вас, если данные не хранятся в каком-то усредненном, в каком-то
[27:47.300 --> 27:55.540]  нейтральном часовом поясе, вам придется работать с тем, чтобы данные эти все привести к единому
[27:55.540 --> 28:04.580]  знаменателю, чтобы они хранились в ДВХ, в какой-то реальной, скажем так, последовательности, ну,
[28:04.580 --> 28:11.300]  или в какой-то заранее выбранной последовательности. Но окей, давайте посмотрим чуть подробнее.
[28:11.300 --> 28:19.540]  ИТЛ-извлечение. Здесь речь о том, что происходит инкрементальное извлечение, то есть мы данные
[28:19.540 --> 28:27.420]  выгружаем не массово, постоянно, каждый раз, а мы стараемся оптимизировать работу на всех наших
[28:27.420 --> 28:35.940]  систем, и операционных систем, и систем корпоративного хранения, поэтому мы, в первую очередь,
[28:35.940 --> 28:48.180]  выгружаем только то, что меняется. Очевидно, что у нас здесь происходит выигрыш по времени и по
[28:48.180 --> 29:01.620]  загрузке. Мы, соответственно, должны при этом как-то этот механизм обеспечивать, то есть мы либо храним
[29:01.620 --> 29:08.260]  дату последнего изменения записи, либо некий условный инкрементальный идентификатор. Опять же,
[29:08.260 --> 29:13.420]  да, как я и говорил, что мы должны учитывать особенности базы источника, это как раз дата
[29:13.420 --> 29:21.540]  последнего изменения записи, в каком виде эта дата будет храниться в базе источника. При этом
[29:21.540 --> 29:32.060]  входные данные нам тоже нужно согласовывать, нужно их очищать и трансформировать, ну и так далее,
[29:32.060 --> 29:42.620]  в общем, делать то, что делается в процессе ETL, в принципе. Что мы на этапе очистки, ну то есть это
[29:42.620 --> 29:50.860]  уже на этапе после извлечения, что мы на этапе, который представлен в аббревиатуре буквой T,
[29:50.860 --> 29:57.940]  делаем. Ну, например, очистка, то есть мы приводим к какому-то общему знаменателю то, что у нас есть.
[29:57.940 --> 30:07.420]  Вот на левой картинке на слайде показаны номера телефонов, мы их проверяем, мы пытаемся навалидность
[30:07.420 --> 30:12.780]  проверить. Понятно, что с одной стороны, а с другой стороны, да, вот привести к общему знаменателю.
[30:12.780 --> 30:17.140]  Понятно, что последние три записи у нас превращаются в нул, потому что они не имеют
[30:17.140 --> 30:25.460]  какого-то содержания в контексте телефонного номера. Ну, разве что последнюю запись можно было
[30:25.460 --> 30:34.620]  бы пофантазировать и попытаться московский код дополнить и, может быть, в конкретном юскейзе это
[30:34.620 --> 30:43.540]  было бы действительно осмысленно, но в общем случае мы это просто удаляем, а первые пять записей мы,
[30:43.540 --> 30:49.860]  соответственно, очищаем. На пятую обратите внимание, мы и очищаем в том числе от опечаток в виде вот
[30:49.860 --> 30:57.940]  знака равно и с правой закрывающей скобки. И на правом слайде мы тоже пытаемся записи как-то
[30:57.940 --> 31:05.860]  провалидировать, как-то их привести к общему знаменателю, ну, либо в виде налов пометить
[31:05.860 --> 31:14.580]  как отсутствующую запись о адресе электронной почте, если пользователь ввел неправильный какой-то
[31:14.580 --> 31:24.380]  домен, ошибся в написании почты, ввел почту, которая, ну, очевидно, является какой-то вот
[31:24.380 --> 31:33.740]  массовой почтой адресом регистрации, ну, типа a.sabaka.gmail.com, то есть a.gmail.com это адрес,
[31:33.740 --> 31:41.500]  который с очень большой долей вероятности был одним из первых, которые вообще были созданы
[31:41.500 --> 31:45.100]  и зарезервированы за кем-то. И сейчас может быть даже вообще не используется, потому что
[31:45.100 --> 31:56.340]  адрес такой похожий на технический и несодержательный. А дедупликация, ну, понятно,
[31:56.340 --> 32:05.260]  приводим все это в какой-то удобоваримый вид записи, особенно релевантно, когда у нас какие-то
[32:05.260 --> 32:12.860]  смежные отделы, там, условно говоря, HR и бухгалтерия ведут разные записи, разные, почему-то, записи
[32:12.860 --> 32:20.500]  о сотрудниках. Ну, как пример, вот у нас появляется, что где-то у нас просто первые буквы имени и
[32:20.500 --> 32:29.580]  отчества, где-то у нас нет отчества, где-то у нас есть данные паспорта, где-то нет, а где-то есть
[32:29.580 --> 32:35.540]  данные телефонного номера, где-то нет. Нам это все нужно сопоставить, понять, что это данные об одном
[32:35.540 --> 32:44.940]  лице, и нам нужно понять, какие данные отбросить, какие данные сохранить. А с чего мы решили, что у
[32:44.940 --> 32:53.860]  него номер телефона с девятки начинается, не с восьмерки? Да, вопрос как бы концептуально
[32:53.860 --> 33:01.660]  интересный, к теме он наше не относится, но здесь можно следующую провести, следующий такой анализ.
[33:01.660 --> 33:14.180]  Во-первых, коды 800 это коды, как правило, бесплатных номеров, ну, таких вот, бесплатных для звонящего
[33:14.180 --> 33:24.460]  номеров, когда платят именно адреса звонка, технические всякие службы, либо какие-то
[33:24.460 --> 33:35.540]  сервисы у компании по жалобам, по поддержке и так далее. То есть код 800 изначально он не похож
[33:35.540 --> 33:40.260]  на реальный код, то есть это не код населенного пункта, это код технически, повторюсь, это не код
[33:40.260 --> 33:48.940]  оператора сотовой связи. У них у всех с девятки, возможно, я, правда, в этом могу ошибаться,
[33:48.940 --> 33:58.300]  но, по-моему, у всех внутренний код трех цифр, из трех цифр, цифр с девятки начинается. Поэтому
[33:58.300 --> 34:03.860]  800 это, скорее всего, либо ошибка, либо номер, по которому вы никогда не дозвонитесь реальному
[34:03.860 --> 34:10.580]  человеку, позвоните в какой-нибудь службу поддержки. Так что вот так. Ну и, соответственно,
[34:10.580 --> 34:18.300]  нам нужно это все закладывать, нужно проводить какой-то анализ данных, какой-то скрининг вообще того,
[34:18.300 --> 34:23.420]  что происходит, чтобы выявлять вот эти шумовые данные или данные ошибочные. Ну, это уже вопрос
[34:23.420 --> 34:33.380]  скорее даже, да, либо конкретных систем, которые функционируют на этапе ETL, либо вопросы конкретных
[34:33.380 --> 34:44.860]  случаев, каких-то массовых ошибок, систематических ошибок. Это не предмет для разговора с точки
[34:44.860 --> 34:52.660]  зрения проектирования баз данных или чего-то подобного. Преобразование этап, опять же,
[34:52.660 --> 35:01.060]  transform. Что происходит? Ну, матинг входных данных в физическую модель. То есть, да, опять же,
[35:01.060 --> 35:12.860]  мы, не знаю, преобразуем int в, не знаю, numeric или наоборот, условно говоря, временные данные
[35:12.860 --> 35:22.700]  трансформируем в какую-то часовую зону общую для компании, принятую за единую для компании и так
[35:22.700 --> 35:27.100]  далее. То есть соблюдаем все те ограничения, которые у нас наложены. Ну, помните, что такое
[35:27.100 --> 35:31.940]  физическая модель, да, по теме проектирования. Вот мы наши данные в эту физическую модель
[35:31.940 --> 35:38.380]  пытаемся втиснуть. Интегрируем данные из разных источников, фиксируем алгоритмы. Ну,
[35:38.380 --> 35:46.500]  фиксация алгоритмов бизнес правила здесь такая, да, несколько абстрактная формулировка. Здесь
[35:46.500 --> 35:58.740]  может быть даже не с точки зрения, не с точки зрения базы данных или хранилища, а здесь скорее
[35:58.740 --> 36:07.700]  вот вопрос тоже в каком-то предварительном анализе. То, о чем мы говорили про номер телефона,
[36:07.700 --> 36:13.980]  просто масштабируем это не на номер телефона, не на ошибочную номер телефона, условно говоря,
[36:14.140 --> 36:22.980]  на сумма транзакций. И какие-то транзакции большие, мы данные по ним, мы, может быть,
[36:22.980 --> 36:29.900]  будем хранить в отдельной таблице, потому что бизнес-пользователи на этапе аналитики,
[36:29.900 --> 36:41.180]  прошу прощения, на этапе аналитики, который графический был, в такой правой части нашего
[36:41.180 --> 36:46.740]  слайда концептуального, бизнес-пользователи на этапе аналитики, может быть, захотят к
[36:46.740 --> 36:53.180]  транзакциям на очень большие суммы выше какого-то порога обращаться чаще, или, наоборот,
[36:53.180 --> 36:59.500]  на транзакции на суммы ниже этого порога обращаться чаще, к транзакциям ниже этого порога
[36:59.500 --> 37:05.180]  обращаться чаще, и так далее. По загрузкам в хранилища данных, собственно говоря,
[37:05.180 --> 37:13.260]  сложность определяется, это соответственно буквка L, сложность определяется применяемым
[37:13.260 --> 37:17.820]  алгоритмом обобновления. Существует несколько разных типов обновляемых данных, определяемых
[37:17.820 --> 37:27.340]  термин с ССД, Slowly Changing Dimensions, и чаще всего используется ССД1, ССД2. Ну это, в общем,
[37:27.340 --> 37:38.100]  то, о чем мы с вами уже сильно раньше говорили. Здесь единственное, что здесь можно добавить,
[37:38.100 --> 37:44.540]  что тоже в ДВХ могут свои таблицы ССД, свои таблицы версионирования быть, и, более того,
[37:44.540 --> 37:52.940]  они будут как элемент, во всяком случае, концептуальный про того тех этапов проектирования,
[37:52.940 --> 38:05.580]  за которые наступает Ральф Кимбл. Понятно, там нужно все это загрузить, распределить по нашим
[38:05.580 --> 38:12.980]  отношениям, которые у нас в ДВХ есть, хранить изменения, загружать последовательно, следить
[38:12.980 --> 38:20.260]  за тем, чтобы у нас не было перехлестов между тем, что мы выгрузили и трансформировались,
[38:20.260 --> 38:30.260]  тем, что мы загружаем, и так далее. Здесь может быть довольно большое количество проблем,
[38:30.260 --> 38:39.140]  так и довольно понятные варианты их решения, но, опять же, концептуально. Если бы хотим
[38:39.140 --> 38:46.460]  версионировать, мы создаем ССД таблицы соответствующих типов. Если мы выгружаем
[38:46.460 --> 38:50.940]  данные, их трансформируем и пытаемся загрузить нашу физическую модель, мы должны загружать
[38:50.940 --> 38:58.220]  правильно, в правильные колонки, правильные типы данных и так далее. В общем-то,
[38:58.220 --> 39:06.940]  наверное, вот резюмируя все это, можно сказать следующее, что, повторюсь, все, о чем мы сейчас
[39:06.940 --> 39:12.100]  с вами говорим в рамках хранилищ, это вопросы концептуальные, математической теории за этим
[39:12.100 --> 39:19.540]  нет. Мы можем выделять процессы ИТЛ и можем даже говорить о том, что они у нас происходят между
[39:19.540 --> 39:28.020]  хранением данных в операционных приложениях и хранением данных в хранилище компании, но по
[39:28.020 --> 39:34.500]  большому счету нам никто не мешает менять порядок того, что у нас происходит в рамках ИТЛ, а говорить
[39:34.500 --> 39:44.580]  о том, что мы в базу, в наше хранилище, загружая наши данные, мы используем только экстракт и лот,
[39:44.580 --> 39:53.020]  а трансформ мы делаем уже извлекая данные из хранилища, то есть ИЛТ. Пожалуйста, никто не
[39:53.020 --> 39:59.460]  запрещает. Вопрос в том, что за оборудование вы используете, способно ли оно поддержать те массивы
[39:59.460 --> 40:05.700]  данных, которые у вас будут без трансформации загружаться в хранилище, хотя это уже скорее будет
[40:05.700 --> 40:13.340]  какое-то там болото, океан и так далее, озеро, и насколько эффективен будет и быстрый поиск
[40:13.340 --> 40:27.940]  среди такого рода агрегации данных. И вот ИТЛ, ВИС, ИЛТ, то о чем мы с вами, опять же,
[40:27.940 --> 40:40.500]  говорили устно, но теперь немножко графически. Здесь у нас ИТЛ, что называется по классике,
[40:40.500 --> 40:47.700]  для него выделяется отдельный какой-то процесс, ну там сервер, да, как правило, структурно,
[40:47.700 --> 40:53.980]  физически понятно, как это реализуется, это очевидно сервер некий, на котором отдельные
[40:53.980 --> 41:06.540]  процессы, все это в себя загружают, перерабатывают и выдают. С точки зрения ИЛТ можно представлять,
[41:06.540 --> 41:16.260]  что у нас трансформация может происходить внутри DWH, внутри DWH процесса, но это такое,
[41:16.260 --> 41:26.220]  как разделение условное на уровне, что ли, по принципу, на каком сервере у нас крутится тот
[41:26.220 --> 41:31.820]  или иной процесс. Повторюсь, здесь можно говорить, что трансформ, стадия трансформации будет идти
[41:31.820 --> 41:39.820]  вообще за пределами DWH, и у нас будет сервер, Т-сервер, в рамках этих аббревиатур, трансформ,
[41:39.820 --> 41:46.060]  трансформейшн сервер будет где-то справа стоять, и из него уже будет аналитика какая-то,
[41:46.060 --> 41:54.100]  лэп-приложение, и так далее, и так далее, еще проверить, будет располагаться такой условной схеме.
[41:54.100 --> 42:03.940]  А какие проблемы с DWH возникают? В общем-то, проблема ожидаемая, что у нас данные большие,
[42:03.940 --> 42:15.980]  их надо хранить много, ресурсы всегда ограничены, стоимость увеличения растет не всегда линейно,
[42:15.980 --> 42:21.060]  ну и в принципе не линейно, кстати говоря, да, это отдельные вот у нас законы сейчас будут,
[42:21.060 --> 42:28.780]  и масштабирование системы требует существенных финансовых вложений, как с точки зрения там
[42:28.780 --> 42:36.380]  подсупки серверов, так и с точки зрения того, что это еще нужно просто физически как-то
[42:36.380 --> 42:43.860]  проектировать, располагать где-то, подключать, связывать, и так далее. И с точки зрения
[42:44.060 --> 42:50.980]  масштабируемости можно говорить, что она у нас бывает в нескольких видах, во-первых,
[42:50.980 --> 42:56.220]  горизонтально и вертикально, очевидно. Во-первых, что такое самопо себе масштабируемость? То есть,
[42:56.220 --> 43:01.700]  говорят, что система масштабируема, если она способна увеличивать производительность
[43:01.700 --> 43:08.140]  пропорционально дополнительным ресурсам. И масштабируемость можно оценить через отношение
[43:08.140 --> 43:13.060]  прирост, производительность системы к приросту используемых ресурсов. Чем ближе это отношение
[43:13.060 --> 43:21.060]  к единице, тем, очевидно, лучше. И если у нас масштабируемость плохая, то добавление ресурсов
[43:21.060 --> 43:27.940]  приводит лишь к незначительному повышению порога производительности, а с некоторого порогового
[43:27.940 --> 43:34.820]  момента добавление ресурсов не дает никакого полезного эффекта. И по этому поводу есть даже
[43:34.820 --> 43:44.860]  вот парочка таких несложных математически формализованных законов буквально через пару
[43:44.860 --> 43:49.940]  слайдов. Вертикальная масштабируемость. Вертикальная масштабируемость – это увеличение
[43:49.940 --> 43:53.540]  производительности каждого компонента системы с целью повышения общепроизводительности.
[43:53.540 --> 44:01.060]  Масштабируемость в этом контексте у нас означает, что мы можем заменять компоненты внутри
[44:01.060 --> 44:08.540]  системы более мощными. И это, соответственно, самый простой способ масштабирования, потому что мы
[44:08.540 --> 44:17.540]  никак не меняем распределение нагрузки по имеющимся ресурсам. Ресурсы мы сами меняем,
[44:17.540 --> 44:24.140]  но то, как они у нас балансируются в нашей сети, у нас, скорее всего, останется таким же. Ну либо
[44:24.140 --> 44:32.980]  мы там какие-то коэффициенты, условно говоря, какие-то чиселки в нашей инжинкс-конфигурации
[44:32.980 --> 44:39.260]  поменяем, может быть, но принципиально не будем заниматься тем, чтобы будем добавлять сервера и
[44:39.260 --> 44:47.020]  так далее. А горизонтально мы разбиваем систему на более мелкие структурные компоненты и
[44:47.020 --> 44:53.420]  разносим их по отдельным физическим машинам или кластерам таких машин, увеличивая
[44:53.420 --> 44:59.140]  количество серверов, параллельно выполняющих одну и ту же функцию, хранящих, может быть,
[44:59.140 --> 45:05.660]  даже одни и те же данные в контексте базданных. И масштабируемость тогда мы понимаем как
[45:05.660 --> 45:16.580]  добавление новых физических компонентов к нашей системе. И это уже очевидно требует не просто,
[45:16.580 --> 45:25.780]  не просто, повторюсь, в инжинкс-конфигурации поменять одни числа на другие, а это уже
[45:25.780 --> 45:30.820]  требует дописывания новых конфиг-файлов, ребалансировки, может быть, нашей системы.
[45:30.820 --> 45:40.500]  Более того, помимо каких-то балансиров, балансёров, речь идёт о том, что возможно нам
[45:40.500 --> 45:48.340]  потребуется иначе реплицировать данные на тех или иных узлах. В общем, теоретически это более
[45:48.340 --> 45:54.540]  сложный, даже, наверное, может быть, практически это более сложный, очевидно, процесс по сравнению
[45:54.540 --> 46:00.260]  с вертикальной масштабируемостью. У нас есть, повторюсь, математически формализованный
[46:00.260 --> 46:07.820]  способ оценки того, насколько система масштабируемая, насколько нет. И, соответственно,
[46:07.820 --> 46:16.820]  у нас законом дало выглядеть следующим образом, то есть, что теоретическое ускорение выполнение
[46:16.820 --> 46:36.580]  всей программы можно оценить, как показано по формуле. И, соответственно, у нас применимое
[46:36.580 --> 46:48.020]  более к вопросу горизонтальной масштабируемости видзакона. Он показан на слайде. Альфа – это доля
[46:48.020 --> 46:53.500]  вычислений, которые могут выполняться только последовательно, единицы минус альфа, соответственно,
[46:53.500 --> 47:01.780]  то, что может быть распараллелено, и пи – это число задействованных узлов. Зависимость у нас
[47:01.780 --> 47:12.380]  получается примерно следующее. То есть, если у нас альфа равна единице, то у нас вне зависимости
[47:12.380 --> 47:16.900]  от числа узлов, изначально, если альфа равна единице, вне зависимости от числа узлов, у нас альфа всегда
[47:16.900 --> 47:22.380]  будет равна единице. Если альфа равна нулю, то все процессы распараллеливы ЕМ и Е. Соответственно,
[47:22.380 --> 47:30.300]  условно говоря, по вот этому математическому приближению у нас чем больше узлов, тем больше
[47:30.300 --> 47:41.100]  будет этих самых процессов. Увеличение идет линейно. И при значениях альфа в диапазоне от нуля до единицы,
[47:41.100 --> 47:50.220]  как вы видите, у нас идет нелинейное изменение производительности системы. Вот на предыдущем
[47:50.220 --> 48:03.780]  слайде, соответственно, оно у нас хорошо показано, когда, соответственно, чем у нас больше
[48:03.780 --> 48:12.980]  процент распараллеливаемости задачи, вот зеленая линия на графике, тем больше ускорение в зависимости
[48:12.980 --> 48:22.580]  от числа ядер процессоров. Но все равно на некотором этапе у нас наш график приближается
[48:22.580 --> 48:33.820]  к некой асимпатите и дальше за нее скорее всего не выходит. Вот у нас опять же лимит,
[48:33.820 --> 48:43.700]  предел, к которому будет стремиться наш s-latency, показан на слайде внизу в фигурной скобке,
[48:43.700 --> 48:53.100]  последним уравнением единицы, деленное на альфа, предел при количестве процессов,
[48:53.100 --> 49:03.180]  стремящимся к бесконечности. То есть у нас максимально, всегда будет некое ограничение.
[49:03.180 --> 49:17.540]  Ну и да, соответственно, реальность такова, чем не всегда у нас будет, поскольку у нас в
[49:17.540 --> 49:27.140]  любом случае наша программа на отдельных шагах не сможет быть распараллелена, у нас всегда будет
[49:27.140 --> 49:41.380]  некий предел, выше которого эффективность горизонтального масштабирования не поднимется.
[49:41.380 --> 49:49.780]  Так что, в принципе, ее можно прикинуть на некой абстрактной модели вычислений,
[49:49.780 --> 49:55.340]  если ее сформулировать для той или иной задачи, и даже численно попытаться это все оценить,
[49:55.340 --> 50:05.260]  если сильно задуматься, если сильно постараться, если сильно захотеть. Но как минимум это просто
[50:05.260 --> 50:16.620]  нужно знать качественно, что в реальности у нас любое масштабирование текущего алгоритма упрется
[50:16.620 --> 50:27.060]  в некий теоретический потолок. Вот то, о чем мы с вами говорили,
[50:27.060 --> 50:35.900]  усно на слайде предложено письменно. Важно, пожалуй, отметить то, что законом Далла не
[50:35.900 --> 50:43.980]  учитывает время, затрачиваемое на взаимодействие параллельных процессов. И, как вы, наверное,
[50:43.980 --> 50:55.740]  знаете, у нас при распараллеливании задачи, при последующем ее сведении воедино в неком родительском
[50:55.740 --> 51:04.420]  процессе отдельно будет затрачиваться время на это сведение. Создание, может быть, процессов
[51:04.420 --> 51:09.140]  здесь не очень актуальны с точки зрения того, что у нас там где-то отдельные сервера стоят,
[51:09.140 --> 51:16.460]  там всегда крутятся некие процессы. Но время на взаимодействие между процессами будет
[51:16.460 --> 51:26.380]  действительно дополнительно отнимать какое-то количество временного ресурса. Так же есть закон
[51:26.380 --> 51:33.740]  Густавсона Бариса. Барсиса, прошу прощения. И в чем он важен? Законом Далла у нас оценивает
[51:33.740 --> 51:38.540]  ускорение выполнения задачи фиксированного объема. Закон Густавсона Бариса оценивает
[51:38.540 --> 51:44.540]  ускорение с точки зрения объемов задач, которые можно решать за то же самое время. И S в данном
[51:44.540 --> 51:50.500]  случае это доля последовательных расчетов в программе N, количество процессов. И у нас
[51:50.500 --> 52:01.340]  соответственно, чем больше процессов, тем теоретически больше скорость. Но опять же в
[52:01.340 --> 52:13.340]  реальности надо смотреть на то, какая у нас доля. То есть чем больше доля распараллеливаемых
[52:13.340 --> 52:23.340]  задач, тем больше скорость, тем больше выигрыш от того, прошу прощения, от того, что мы добавляем
[52:23.340 --> 52:37.540]  каждый новый процесс. Еще с точки зрения масштабируемости горизонтальной. Это стало
[52:37.540 --> 52:50.180]  особенно актуально во второй половине девяностых нулевых годах. А вот первые решения по распределенным
[52:50.180 --> 52:58.380]  таким хорошо масштабируемым хранилищем данных. Но опять же это уже даже не совсем про базы,
[52:58.380 --> 53:07.140]  как вы видите. Это распределенная файловая система и хранилища K-value. Но важно то,
[53:07.140 --> 53:17.340]  что это хорошо программные решения, которые хорошо взаимодействовали с данными в условиях
[53:17.340 --> 53:23.460]  горизонтальной масштабируемости систем хранения данных.
[53:23.460 --> 53:44.060]  Ну и собственно говоря, о чем еще стоит сказать. Это о том, каким образом у нас в рамках хранилищ
[53:44.060 --> 54:00.260]  решаются вопросы и задачи обработки данных в случае, когда мы имеем дело с вертикально,
[54:00.260 --> 54:05.620]  с одной стороны, распределенной системой, а с другой стороны, с системой, которая испытывает
[54:05.620 --> 54:13.340]  на себе нагрузки от частых, с одной стороны, запросов. Ну возможно частых запросов от
[54:13.340 --> 54:20.460]  пользователей, а с другой стороны, постоянно в нее добавляются данные. Ну здесь, с одной стороны,
[54:20.460 --> 54:26.180]  можно сказать, что не затрагивая вот эти вот варианты многопроцессорной обработки,
[54:26.180 --> 54:32.300]  можно говорить, что одним из вариантов такого решения, это можно считать витрины данных. То
[54:32.300 --> 54:43.780]  есть такие субагрегации данных по интересам бизнес-пользователей, грубо говоря. Ну о чем
[54:43.780 --> 54:49.780]  идет речь? То есть у нас внизу цепочки, грубо говоря, склад или там склады и магазины, из них
[54:49.780 --> 54:58.460]  данные в ДВХ подтягиваются, из ДВХ данные у нас могут пойти в финдиректору по продажам и покупкам,
[54:59.020 --> 55:08.540]  директору по персоналу, данные по работе, собственно говоря, персонала складов, персонала магазинов,
[55:08.540 --> 55:18.460]  данные, не знаю, может быть, директору по безопасности, данные по утерю, утрате товара,
[55:18.460 --> 55:25.060]  порчи товара. Хотя порча, наверное, не совсем для безопасников интересна, но вот как-то так.
[55:25.060 --> 55:34.340]  Нам эти данные смысла предоставлять в рамках всего хранилища напрямую вот этим вот директорам,
[55:34.340 --> 55:43.620]  их секретариату, помощников смысла нет. Это лишняя нагрузка, лишние данные, дополнительные
[55:43.620 --> 55:49.660]  вопросы по формулированию запросов к хранилищу данных и так далее и так далее. Нам проще
[55:49.660 --> 55:58.540]  сделать тем или иным образом интерфейс, в котором данные по промежуточку агрегировались,
[55:58.540 --> 56:06.900]  интересные только для соответствующих групп. Вот такого рода интерфейс это не обязательно просто
[56:06.900 --> 56:12.580]  набор программ, это может быть какая-то база данных на выходе из хранилища, небольшая база
[56:12.580 --> 56:21.380]  данных. Поэтому интерфейс-то в широком смысле, это не просто точки входа. Нам удобно сделать
[56:21.380 --> 56:26.580]  какой-то интерфейс, вернее, удобно получить какой-то интерфейс для того, чтобы взаимодействовать
[56:26.580 --> 56:33.060]  с данными, которые интересны только для них, строить аналитику по таким данным, принимать
[56:33.060 --> 56:40.940]  какие-то решения. Вот поэтому хранилища данных тоже как вариант свержения нагрузки на, прошу
[56:40.940 --> 56:49.140]  прощения, витрины данных, конечно же, как снижение нагрузки на сервера хранилища. Ну а с точки
[56:49.140 --> 56:54.700]  зрения того, что под капотом происходит, можно выделить несколько вариантов. Некоторые из них
[56:54.700 --> 56:58.980]  представлены на слайде. Это SMP, симметричная многопроцессорная обработка. То есть множество
[56:58.980 --> 57:04.860]  процессов выполняют разные задачи, используют общую память. SMP это симметричная многопроцессорная
[57:04.860 --> 57:10.420]  обработка процессора сравнимой производительности, используют общую память и выполняют одни и те же
[57:10.420 --> 57:16.940]  функции. И MPP, массивно-параллельная обработка. Каждый узел системы физически независимо
[57:16.940 --> 57:24.060]  содержит собственные процессоры и оперативную память. На текущем этапе MPP наиболее общепризнанный
[57:24.060 --> 57:33.780]  вариант архитектуры решения для аналитической обработки больших объемов данных. Дальше здесь
[57:33.780 --> 57:39.100]  несколько слайдов по тому, как это опять же структурно может выглядеть. То есть у нас есть
[57:39.100 --> 57:46.500]  какой-то мастер процесс и несколько процессов ему, словно говоря, подчиненных. Мы соответственно
[57:46.500 --> 57:59.580]  внутри наших подчиненных процессов можем сделать таблицу, распределенную за счет команды
[57:59.580 --> 58:06.580]  distributed by, распределенную по узлам и распределенную определенным образом. То есть опять же мы можем
[58:06.580 --> 58:13.900]  равномерно распределять по ID-шнику, неравномерно распределять по иным каким-то полям нашей
[58:13.900 --> 58:27.460]  таблицы. И дальше у нас мы будем, ну не мы уже, а сама система за счет внутренних алгоритмов
[58:27.460 --> 58:38.020]  соединения таблиц. А сливание данных будет у нас выдавать результаты из разных узлов внутри мастер
[58:38.020 --> 58:48.540]  процесса. Опять же, да, мы, зная, как распределены наши данные по серверам, по узлам системы,
[58:48.540 --> 58:57.140]  можем делать чуть более расширенные и продвинутые запросы, можем конкретно указывать узлы либо
[58:57.140 --> 59:02.100]  полагаться на автоматическое распределение запросов в рамках какой-то статистики нашей
[59:02.100 --> 59:19.060]  системы. И таким образом у нас оптимально получается обрабатывать данные из разных узлов. Есть
[59:19.060 --> 59:25.460]  определенные проблемы, связанные с тем, что есть проблемы и положительные стороны, то есть с одной
[59:25.460 --> 59:35.540]  стороны у нас может быть положительная сторона в том, что данные распределены и данные у нас будут
[59:35.540 --> 59:44.860]  подтягиваться из, там, не знаю, 99% узлов при отказе одного узла. То есть мы корректно на
[59:44.860 --> 59:52.820]  99% данные получить сможем, а с другой стороны, если будут отказывать какие-то мастер процессы,
[59:52.980 --> 01:00:00.420]  то возникают проблемы с точки зрения получения результата. Но, опять же, это все применимое
[01:00:00.420 --> 01:00:05.780]  к отдельно существующим базам данных. Если мы их крутим на одном сервере, на одном процессе,
[01:00:05.780 --> 01:00:21.820]  это все может полететь или не полететь, если у нас что-то друг откажет. Дублирование процессов,
[01:00:22.540 --> 01:00:31.060]  не только на нижнем уровне, но и на уровне мастер процессов происходит и в рамках МПП,
[01:00:31.060 --> 01:00:45.380]  за счет того, что у нас отдельные процессы, отдельная память, мы не получаем каких-то проблем,
[01:00:45.380 --> 01:00:55.860]  связанных с дошумлением общего пространства в случае отказа тех или иных узлов. У нас,
[01:00:55.860 --> 01:01:05.540]  тем не менее, остальные узлы работают независимо, и если какие-то узлы отказали,
[01:01:05.540 --> 01:01:14.020]  остальная система теоретически должна поддерживать независимую работу и работать
[01:01:14.020 --> 01:01:22.860]  корректно. Возвращаемся к нашей схеме. Мы уже подошли к этапу составления отчетности
[01:01:22.860 --> 01:01:36.180]  ОЛЭП-приложений, то есть к крайней правой части слайдов. Для конечных пользователей,
[01:01:36.180 --> 01:01:42.580]  соответственно, в рамках концепции хранилищ разрабатываются user-friendly, что называется,
[01:01:42.580 --> 01:01:49.820]  какие-то интерфейсы, где не факт, что пользователи даже будут работать с SQL языком запросов,
[01:01:49.820 --> 01:01:57.140]  может быть, там просто будут реализованы кнопочные, скажем так, запросы или запросы
[01:01:57.140 --> 01:02:07.420]  из каких-то содержательных форм, содержательных для пользователей форм. Приложение ОЛЭП,
[01:02:07.420 --> 01:02:20.900]  это, по большому счету, то, что относится к витринам данных, то есть это приложение
[01:02:20.900 --> 01:02:30.420]  для онлайн, вернее, analytical processing, то есть аналитическая обработка в режиме онлайн.
[01:02:30.420 --> 01:02:36.460]  Там они характеризуются такого рода приложения небольшим количеством одновременных операций,
[01:02:36.460 --> 01:02:43.340]  но операция одновременно затрагивает большое количество объектов базы данных,
[01:02:43.340 --> 01:02:50.020]  запросы могут выполняться при этом сколь угодно долго. Почему так? Потому что нам, может быть,
[01:02:50.020 --> 01:02:58.060]  не очень важно, скорее всего, при обработке данных, быстрота. Мы можем, грубо говоря,
[01:02:58.060 --> 01:03:07.980]  отчет наш запланировать, а запланировать внесение данных, внесение транзакций в базу несколько
[01:03:07.980 --> 01:03:11.820]  сложнее. Конечно, тоже есть статистика, когда пользователи активны или когда рабочий день
[01:03:11.820 --> 01:03:19.980]  начинается и заканчивается и так далее, но на практике OLTP, то есть антипод ОЛЭП,
[01:03:19.980 --> 01:03:30.380]  OLTP онлайн, прошу прощения, transaction processing, он характеризуется именно большим количеством
[01:03:30.380 --> 01:03:39.380]  операций, большим количеством одновременно совершаемых операций и их небольшими объемами,
[01:03:39.380 --> 01:03:48.140]  что ли, скажем условно говоря. А ОЛЭП, наоборот, одновременно мы вряд ли будем часто обращаться
[01:03:48.300 --> 01:03:57.220]  к серверу DWH, мы, скорее всего, возьмем выкраску какую-то по срезу, возможно, по большому срезу,
[01:03:57.220 --> 01:04:07.460]  и будем ее как-то вертеть внутри нашего ОЛЭП-приложения. И что еще? Новые данные не
[01:04:07.460 --> 01:04:12.500]  создаются у нас при этом, данные у нас не могут удаляться, создаются новые расчетные атрибуты,
[01:04:12.500 --> 01:04:17.060]  создаются историчные издачения атрибутов, данные статичны. То есть,
[01:04:17.060 --> 01:04:22.260]  получается, что версионность у нас происходит тоже и в ОЛЭП-приложениях может иметь место
[01:04:22.260 --> 01:04:30.740]  быть, но эта версионность такая вот по интересантам. Мы взяли срез, повторюсь, из нашего DWH по
[01:04:30.740 --> 01:04:40.500]  продажам и по ставкам срез в количественном и стоимостьном выражении, отдали его финдиректору,
[01:04:40.500 --> 01:04:49.220]  он со своими помощниками что-то в ОЛЭП-приложении своем смотрит, крутит, вертит, через какие-то
[01:04:49.220 --> 01:04:59.340]  алгоритмы пропускает, строит модели, тестирует их на основе этих данных. Понятно, что он их не
[01:04:59.340 --> 01:05:04.940]  меняет, он к ним ничего не дописывает, он в DWH не отправляет информацию о своих операциях,
[01:05:04.940 --> 01:05:11.460]  потому что ему этого не нужно, у его операции это построение чудностей, построение планов,
[01:05:11.460 --> 01:05:20.860]  которые меняются на основании этих данных, которые он получает и так далее. И многомерный анализ
[01:05:20.860 --> 01:05:31.220]  ОЛЭП, что это значит, что это позже мы возвращаемся трефреном к Ральфу Кимбалу с его концепцией
[01:05:31.220 --> 01:05:39.500]  Dimensional Modeling, то есть измерение в данном случае, вернее многомерность в данном случае,
[01:05:39.500 --> 01:05:46.300]  речь идет о том, что вот эти вот данные в какой-то таблице, это по сути дела некое измерение и
[01:05:46.300 --> 01:05:54.140]  многомерный анализ, речь о том, чтобы исследуем данные из множества возможно таблиц. Опять же у
[01:05:54.140 --> 01:06:02.700]  нас в DWH не обязательно, повторюсь, какая-то одна таблица фактов и там, не знаю, пять таблиц измерения,
[01:06:02.700 --> 01:06:07.740]  у нас может быть куча таблиц, таблиц фактов, и у каждой может быть некоторое количество измерений,
[01:06:07.740 --> 01:06:12.500]  и у каждой может быть, если эта схема снежинка условная, большое количество суп измерений,
[01:06:12.500 --> 01:06:19.740]  а если мы вообще не используем концепцию Кимбала, а идем от Инмана или вообще строим что-то свое,
[01:06:19.740 --> 01:06:26.020]  у нас может быть сколько угодно сложное внутри хранилища данных, сколько угодно много таблиц,
[01:06:26.020 --> 01:06:39.020]  сколько угодно много различных данных в хранилище может храниться. Олэп-приложения,
[01:06:39.020 --> 01:06:43.980]  они направлены на повышение производительности при работе с данными, на уменьшение нагрузки на
[01:06:43.980 --> 01:06:49.500]  хранилище соответственно, а на создание, ну, единая версия правды, это такая вот условно тоже
[01:06:49.500 --> 01:06:58.620]  концептуальная вещь, что в рамках Олэпа у нас какой-то срез наших данных, который на данный
[01:06:58.620 --> 01:07:08.740]  момент правдив истинен, и мы можем на этой основе формировать осмысленные отчеты и строить планы.
[01:07:08.740 --> 01:07:12.260]  Реализация семантического слоя, то есть мы предоставляем конечному пользователю,
[01:07:12.260 --> 01:07:23.820]  как администратор системы, мы предоставляем конечному пользователю не окно, с которым он
[01:07:23.820 --> 01:07:33.660]  может SQL-запрос написать, как вот, не знаю, в pg-админе, например, если брать утилиту,
[01:07:33.660 --> 01:07:38.940]  позыгры со стандартную, а мы предоставляем вот то, что было на картинке раньше на слайде
[01:07:38.940 --> 01:07:45.980]  представлено, какой-то вот более юзер-френдли, более интересный там графический и более понятный
[01:07:45.980 --> 01:07:51.060]  неспециалисту интерфейс, которым он может там какие-то кнопочки отжать, какие-то поля выбрать,
[01:07:51.060 --> 01:07:57.380]  и таким образом сделать запрос, который трансформируется уже, возможно, и скорее
[01:07:57.380 --> 01:08:05.460]  всего в SQL запрос под капотом системы. Да, ну вот тоже такое графическое изображение,
[01:08:05.460 --> 01:08:11.180]  что такое семантический слой, то есть хочу посмотреть текущий баланс в разбивке по типу
[01:08:11.180 --> 01:08:22.580]  счета, и вот как это все приложение OLAP переводит в семантику SQL. В основе OLAP лежит понятие
[01:08:22.580 --> 01:08:33.620]  гиперкуба, но это тоже больше концепции, чем какая-то структура прям четко выверенная. Каждая
[01:08:33.620 --> 01:08:42.620]  грань здесь, это, как вы уже могли догадаться, это та самая табличка, пресловутая в понимании
[01:08:42.620 --> 01:08:49.180]  релиционных баз данных, пресловутая наше отношение. По сути дела, просто отношения,
[01:08:49.180 --> 01:09:04.220]  соединенные по каким-то атрибутам, пересечению каких-то атрибутов, каких-то данных, и вот
[01:09:04.220 --> 01:09:09.740]  формирует такой, в данном случае трехмерный показан куб, но пересечений по данным может
[01:09:09.740 --> 01:09:14.780]  быть сильно больше, поэтому гиперкуб, то есть не ограничен трехмерным измерением.
