[00:00.000 --> 00:16.440]  Итак, добрый день. Мы с вами в прошлый раз выяснили следующий факт. Давайте я его немножко напомню,
[00:16.440 --> 00:24.800]  потому что мы его сейчас обобщим. Факт был такой, что если у нас phi линейный оператор на
[00:24.800 --> 00:38.360]  пространстве, P его аннулирующий многочлен, и он разложен в произведение двух взаимнопростых
[00:38.360 --> 00:57.560]  сомножителей, то тогда всё пространство раскладывается в прямую сумму следующих двух ядер.
[00:57.560 --> 01:07.240]  Ядро P1 от phi и ядро P2 от phi. Вот это мы с вами вроде как доказали в прошлый раз, правда?
[01:07.240 --> 01:17.720]  Ну и нам потребуется обобщение, естественно, на случай, когда сомножителей больше двух,
[01:17.720 --> 01:27.920]  то есть следствие, которое мы сейчас докажем, то же самое, но с несколькими слагаемыми. Итак,
[01:27.920 --> 01:44.880]  если у нас phi линейный оператор на V, P это его по-прежнему какой-то аннулирующий многочлен,
[01:44.880 --> 02:00.960]  а P раскладывается в произведение ка-сомножителей, которые, внимание, попарно взаимнопросты. То есть нот
[02:00.960 --> 02:15.520]  P1 и P2 равен единице при и неравном ж. Неравном, конечно. Тогда всё пространство раскладывается
[02:15.520 --> 02:28.120]  в прямую сумму ядер соответствующих многочленов, то есть ядро P1 от phi плюс и так далее, плюс ядро
[02:28.120 --> 02:37.520]  PkT от phi, или, напоминаю, вот так же как со значком суммирования, можно писать вот таким вот образом.
[02:37.520 --> 02:51.760]  Прямая сумма по и от 1 до k, ядер поитого от phi. Здесь и здесь написано буквально одно и то же,
[02:51.760 --> 02:58.080]  просто вот я то ли напоминаю, то ли, может быть, ввожу это обозначение, которым удобно пользоваться.
[02:58.080 --> 03:08.640]  Ну и если утверждение для двух многочленов у нас уже есть, то следствие получается, естественно,
[03:08.640 --> 03:23.720]  практически непосредственной индукцией по k. База для k равна 2, это в точности вот наше утверждение
[03:23.720 --> 03:36.400]  с предыдущей лекции. База по k равном 2 уже доказана, и давайте мы докажем переход.
[03:36.400 --> 03:47.200]  Ну и для этого, естественно, мы можем опять же таки применить наш базовый случай,
[03:47.200 --> 03:56.960]  поскольку у нас есть разложение нашего многочлена, вот в каком виде,
[03:56.960 --> 04:11.560]  p1 и так далее, pk-1 умножить на pkT, и вот эти вот два уже сомножителя также взаимно простые,
[04:11.560 --> 04:23.640]  нод вот такого произведения икатова многочлена равен единице. Почему это так, на всякий случай,
[04:23.640 --> 04:31.040]  например, это следует, конечно же, из основной теоремы об арифметике, правильно? Что мы говорим,
[04:31.040 --> 04:40.400]  когда мы говорим, что нод двух многочленов равен единице? Это означает, что если мы разложим каждый
[04:40.400 --> 04:46.400]  из них на непреводимые сомножители, то среди этих сомножителей здесь и здесь не найдется общего,
[04:46.400 --> 04:52.640]  правильно? Ну точнее не общего, а ассоциированных не найдется, потому что у нас разложение с точностью
[04:52.640 --> 05:00.800]  замены до ассоциированного. Ну и тогда, мы можем вот эти вот многочлены разложить на непреводимые
[05:00.800 --> 05:05.740]  сомножители, и вот этот многочлен разложить на непреводимые сомножители, у нас получится опять же
[05:05.740 --> 05:10.000]  таки два разложения без общих сомножителей. А это и означает, что многочлены взаимно
[05:10.000 --> 05:22.740]  простые. Вот, итак, нот этих двух товарищей равен единице, ну и следовательно мы можем
[05:22.740 --> 05:35.500]  разложить В в прямую сумму двух ядер. Первое ядро будет оператора, полученного подстановкой вот в этот
[05:35.500 --> 05:46.340]  многочлен нашего phi, то есть P1 от phi, P2 от phi и так далее, Pk-1 от phi. Вот ядро вот такого
[05:46.340 --> 05:57.300]  вот большого оператора композиции вот этих вот всех плюс ядро Пкатова от phi. Давайте я вот это
[05:57.500 --> 06:10.020]  первое ядро обозначу через U. Ну и тогда, чтобы нам применить предположение индукции, давайте мы
[06:10.020 --> 06:22.380]  сделаем вот что. Давайте мы рассмотрим ограничение нашего оператора на подпространство U. Чем оно
[06:22.380 --> 06:32.180]  хорошо? Оно хорошо тем, что, смотрите, что у нас написано здесь. Ну, во-первых, конечно же, давайте
[06:32.180 --> 06:40.780]  я напомню, мы с вами это говорили. Вот эти вот ядра, разумеется, являются инвариантными относительно
[06:40.780 --> 06:47.520]  phi, то есть мы такое ограничение рассматривать можем, правильно? Значит, это U, в частности,
[06:47.520 --> 06:56.040]  инвариантно относительно phi, и рассматривать такое ограничение мы имеем право. А во-вторых,
[06:56.040 --> 07:08.400]  глядите, раз U это ядро вот такого вот товарища, если мы подействуем на любой вектор из U вот этим
[07:08.400 --> 07:15.040]  вот оператором P1 от phi и так далее, Pk-1 от phi, получится 0, правильно? Ну это то же самое,
[07:15.040 --> 07:23.200]  что сказать, что если мы подействуем для любого вектора из U, если мы подействуем на него P1 от
[07:23.200 --> 07:33.520]  psi и так далее, Pk-1 от psi, то получится нулевой вектор, потому что psi это как раз вот ограничение
[07:33.520 --> 07:40.840]  phi на U, и когда мы действуем всеми вот этими вот операторами, мы за пределы U, естественно,
[07:40.840 --> 07:52.080]  не выходим, правильно? Замечательно, это означает, что просто-напросто P1 от psi и так далее,
[07:52.080 --> 08:04.320]  Pk-1 от psi, это нулевой оператор, он каждый вектор отправляет в ноль, ну то есть P1 и так далее,
[08:04.320 --> 08:17.560]  Pk-1 это аннулирующий многочлен для нашего оператора psi, Pk ты уже не нужен, потому что мы работаем
[08:17.560 --> 08:26.960]  только вот в этом вот ядре произведения первых многочленов от phi, ну и коль и так, то вот теперь
[08:26.960 --> 08:40.240]  мы можем применить предположение индукции к нашему оператору psi, применяя предположение индукции к
[08:40.240 --> 08:51.760]  psi и к вот этому вот аннулирующему его многочлену, получаем, что U раскладывается в прямую сумму
[08:51.760 --> 09:02.920]  ядер P1 от psi, обратите внимание, прямая сумма, конечно, уже до k-1, правильно? Потому что у нас
[09:02.920 --> 09:21.480]  произведение k-1 многочленов. На самом деле я могу сказать, что ядро пыитого от psi, это то же самое,
[09:21.480 --> 09:29.800]  что ядро пыитого от phi, ну естественно при i меньше, чем k, то есть при наших i, эти ядра это
[09:29.800 --> 09:40.520]  на самом деле ядра пыитого от phi всего. Почему это так? Если какой-то вектор, давайте вот я так скажу,
[09:40.520 --> 09:54.360]  вектор лежит в ядре пыитого от phi, это означает, что Pt от phi, применённый к этому вектору, это нулевой
[09:54.360 --> 10:07.280]  вектор, ну а значит, тем более, если я применю весь вот этот вот оператор к нашему вектору,
[10:07.280 --> 10:14.360]  то я тоже получу ноль, потому что что такое этот оператор? Это произведение пыитого от phi,
[10:14.360 --> 10:21.000]  умноженного на ещё какие-то операторы, правильно? Более того, все они попарно коммутируют, мы с вами
[10:21.000 --> 10:26.480]  об этом говорили, потому что любые многочлены от phi друг с другом коммутируют перестановочно,
[10:26.480 --> 10:33.240]  и поэтому мы можем этот Pt вытянуть как бы в самый конец, то есть я могу сказать, что если я применю,
[10:33.240 --> 10:43.240]  давайте вот так вот, Pa1 от phi и так далее, Pi-1 от phi, Pi-1 от phi и так далее, pkt от phi,
[10:43.240 --> 10:51.160]  я взял произведение всех, кроме it, а затем применю Pt от phi, ну точнее, затем напишу Pt от phi,
[10:51.160 --> 10:57.800]  применю это к V, вот такое вот произведение, это что такое? Сначала, наоборот, я применяю к V
[10:57.800 --> 11:03.760]  Pt от phi, получаю ноль, затем я применяю все остальные операторы, получаю тем более ноль,
[11:03.760 --> 11:17.120]  конечно же, правда? Это ноль, то есть V лежит в U, ну и значит, конечно же, V лежит в ядре
[11:17.120 --> 11:28.760]  Pt уже от psi. Разница этих ядер заключается только в том, что phi и psi действуют на разных пространствах,
[11:28.760 --> 11:35.600]  правильно? Здесь у нас сидят все векторы из U, которые обнуляются Pt от psi, ну или Pt от phi,
[11:35.600 --> 11:43.840]  здесь у нас сидят все векторы из всего пространства V, которые обнуляются Pt от phi. И вот я объясняю,
[11:43.840 --> 11:50.160]  что если вектор обнуляется этим товарищем, то он на самом деле всегда в U лежит, ну и значит,
[11:50.160 --> 12:04.880]  эти ядра совпадают. Ну и таким образом мы получаем уже то, что нам нужно. Наше пространство V раскладывалось
[12:04.880 --> 12:18.040]  в прямую сумму U и ядра Pt от phi, U, в свою очередь, раскладывается в прямую сумму вот этих вот ядер,
[12:18.040 --> 12:28.880]  Pt от 1 до k-1, ядер Pt, здесь я могу написать не psi, а phi, потому что я это только что доказал,
[12:28.880 --> 12:39.400]  и все это плюс ядро Pt от phi по-прежнему. Ну а это то, что нам нужно, это как раз та самая прямая сумма,
[12:39.400 --> 12:54.120]  которую мы и хотели получить. Это уже прямая сумма по I от 1 до k-1, ядер Pt от phi. Всё,
[12:54.120 --> 13:01.280]  таким образом наше следствие доказано, ну и вот это вот на самом деле и есть то,
[13:01.280 --> 13:10.040]  что нам в первую очередь хотелось получить, то на что мы дальше будем опираться. Итак,
[13:10.040 --> 13:18.200]  мы с вами поговорили об аннулирующих многочленах, и вот, по сути дела, главное утверждение,
[13:18.200 --> 13:24.120]  которое нам в дальнейшем потребуется, ну кроме некоторых вспомогательных, это именно вот это
[13:24.280 --> 13:37.600]  следствие, и мы можем переходить к следующей части, собственно говоря, как эти аннулирующие
[13:37.600 --> 13:48.560]  многочлены нам сейчас помогут. Я обещал, что если характеристический многочлен оператора раскладывается
[13:48.560 --> 13:55.560]  на линейные сомножители, то мы сейчас, то мы сможем его привести к достаточно удобному виду,
[13:55.560 --> 14:03.520]  найти базис, в котором матрица имеет хороший вид. И вот мы добрались до того пункта, когда мы можем
[14:03.520 --> 14:09.600]  сформулировать этот самый вид, ну и сейчас постепенно будем доказывать эту теорему.
[14:09.600 --> 14:20.080]  Жарданова нормальная форма, следующая тема. Эти слова мы будем употреблять часто, они часто
[14:20.080 --> 14:33.560]  сокращаются до gnf. Почему она нормальная, я через некоторое время тоже поясню. Ну и давайте я сразу
[14:33.560 --> 14:46.440]  определю, к какому виду мы будем приводить нашу матрицу. Итак, определение, самый базовый объект,
[14:46.440 --> 15:00.440]  кирпичик, из которого мы будем все строить, это жарданова клетка размера n с собственным значением
[15:00.440 --> 15:17.360]  лямда. Такой вот объект. Это вот какая матрица, мы ее будем обозначать через gn от лямда, g как раз от
[15:17.360 --> 15:27.560]  фамилии жардана. Следующая матрица размера n на n. Давайте я сразу скажу, что она размера n на n.
[15:27.560 --> 15:37.800]  По диагонали у нее стоят лямды, по главной диагонали. Непосредственно над этой диагональю,
[15:37.800 --> 15:51.240]  вот в этих вот n-1 клетках, стоят единички. Все остальные элементы равны нулю. В частности,
[15:51.240 --> 16:04.480]  давайте я сразу скажу, что gn от 0 мы будем обозначать просто через gn, и это матрица,
[16:04.480 --> 16:14.760]  в которой всего n-1 не нулевой элемент. Единички над главной диагональю, нули везде в остальных
[16:14.760 --> 16:29.960]  местах. Вот из этих кирпичей у нас будет строиться наша жарданова форма. Прежде чем двигаться дальше,
[16:29.960 --> 16:37.720]  давайте я сделаю небольшое замечание и скажу, что не зря я говорю, что у этой клетки собственное
[16:37.720 --> 16:44.280]  значение лямда, она верхнетреугольная. Поэтому ее характеристически многочлен
[16:44.280 --> 16:53.120]  написать очень просто. Характеристический многочлен gn от лямды, это лямда минус x в n-й,
[16:53.120 --> 16:58.360]  потому что мы x по диагонали вычтем, возьмем определитель, этой верхнетреугольной матрице
[16:58.360 --> 17:07.600]  получим как раз лямда минус x в n-й. Вот это у нас жарданова клетка, а жарданова матрица,
[17:07.600 --> 17:21.840]  это матрица, у которой на диагонали стоят жардановые клетки. Сейчас я более формально это скажу.
[17:21.840 --> 17:42.360]  Жарданова матрица, я продолжаю определение. Это так называемая
[17:42.360 --> 17:58.760]  блокнодиагональная матрица. Сейчас я скажу, что это такое. Блоки которой это жардановы клетки.
[17:58.760 --> 18:11.840]  То есть жарданова матрица имеет следующий вид. Мы по диагонали друг за другом
[18:12.240 --> 18:22.320]  выстраиваем несколько жардановых клеток. Здесь вот наверное стоит многоточие поставить.
[18:22.320 --> 18:34.640]  Здесь какая-то одна клетка, здесь какая-то другая клетка и так далее. Все остальные элементы этой
[18:34.640 --> 18:52.040]  матрицы равны нулю. Обратите, пожалуйста, внимание, что означает, например, что оператор в каком-то
[18:52.040 --> 19:02.120]  базисе будет иметь вот такую вот матрицу. Это означает, если у меня здесь клетка размера n1,
[19:02.120 --> 19:11.200]  что первые n1 векторов порождают инвариантное подпространство. и матрица ограничения на это
[19:11.200 --> 19:16.280]  инвариантное подпространство это именно вот эта жарданова клетка. Они переходят линейные
[19:16.280 --> 19:21.160]  комбинации из себя и там на этом пространстве организуется вот эта жарданова клетка. Следующие
[19:21.160 --> 19:29.060]  n2 векторов базиса также порождают инвариантное подпространство, матрица, ограничения на которое,
[19:29.060 --> 19:32.060]  Это вот вторая Жарданова клетка и так далее.
[19:32.060 --> 19:40.060]  Пространство на языке линейных операторов, если оператор имеет...
[19:40.060 --> 19:44.060]  Давайте мы это опять же оформим в качестве замечания.
[19:44.060 --> 19:57.060]  Если оператор в некотором базе имеет Жарданову матрицу,
[19:57.060 --> 20:16.060]  то мы получаем, что все пространство В распадается в прямую сумму
[20:16.060 --> 20:35.060]  инвариантных подпространств, порожденных как раз вот последовательными
[20:35.060 --> 20:40.060]  кусками этого базиса, инвариантных подпространств.
[20:40.060 --> 20:56.060]  И матрица ограничения на каждая, естественно, в соответствующем базисе,
[20:56.060 --> 21:02.060]  в базисе, составленном из фрагмента нашего вот этого базиса,
[21:02.060 --> 21:07.060]  это Жарданова клетка.
[21:07.060 --> 21:17.060]  Ну и вот на самом деле мы утверждаем, что к такому виду матрицу любого оператора,
[21:17.060 --> 21:23.060]  если характеристический многочлен хороший, можно привести.
[21:23.060 --> 21:35.060]  Точнее давайте я сформулирую теорему о Жардановой нормальной форме.
[21:35.060 --> 21:41.060]  Она звучит следующим образом.
[21:41.060 --> 21:48.060]  Пусть Фи, линейный оператор на каком-то пространстве В,
[21:48.060 --> 21:54.060]  ну и характеристический многочлен этого Фи раскладывается на линейные
[21:54.060 --> 21:58.060]  сомножители. Вот нам обычная формула.
[21:58.060 --> 22:03.060]  Лямда ИТ минус Х в степени альфа ИТ.
[22:03.060 --> 22:09.060]  Давайте я ее снова обозначу через звездочку.
[22:09.060 --> 22:32.060]  Тогда существует базис, в котором матрица Фи – это Жарданова матрица.
[22:32.060 --> 22:41.060]  Более того, есть утверждение о единственности.
[22:41.060 --> 22:53.060]  Давайте мы его сейчас грамотно сформулируем и поймем, что оно означает.
[22:53.060 --> 23:03.060]  Если матрица оператора в некотором базисе Жарданова,
[23:03.060 --> 23:10.060]  естественно мы можем привести его к такому Жарданову виду немножко по-другому.
[23:10.060 --> 23:16.060]  Например, мы можем первые два фрагмента базиса переставить местами,
[23:16.060 --> 23:21.060]  и тогда вот эти клетки на диагонали тоже поменяются местами.
[23:21.060 --> 23:28.060]  Так вот, это единственное, что может случиться с Жардановой матрицей.
[23:28.060 --> 23:33.060]  Точнее я формулирую так.
[23:33.060 --> 23:59.060]  Более того, если А и А' – это две Жардановых матрицы оператора Фи в разных базисах,
[23:59.060 --> 24:24.060]  то эти матрицы отличаются лишь перестановкой клеток на диагонали.
[24:24.060 --> 24:30.060]  Обратите, пожалуйста, внимание. Сейчас я написал точную формулировку,
[24:30.060 --> 24:37.060]  потому что когда я немножко махал руками, я не совсем четко все сформулировал.
[24:37.060 --> 24:45.060]  Я не утверждаю, что если вы в каком-то базисе получили Жардановую матрицу А,
[24:45.060 --> 24:49.060]  а в другом базисе получили Жардановую матрицу А',
[24:49.060 --> 24:53.060]  я не утверждаю, что эти базисы отличаются только перестановкой векторов.
[24:53.060 --> 24:57.060]  Эти базисы могут отличаться гораздо более существенным образом.
[24:57.060 --> 25:04.060]  Но, тем не менее, таких базисов может быть великое множество,
[25:04.060 --> 25:10.060]  а вот Жарданова матрица получится всегда одна и та же с точностью до перестановки клеток.
[25:10.060 --> 25:15.060]  Вот такое у нас большое утверждение, большое теоремы,
[25:15.060 --> 25:19.060]  которую мы сегодня, наверное, полностью еще не докажем,
[25:19.060 --> 25:23.060]  но будем уже двигаться в эту сторону.
[25:23.060 --> 25:28.060]  Здесь стоит сделать сразу много замечаний.
[25:34.060 --> 25:41.060]  Базис, который мы получаем, то есть базис, в котором Фи имеет Жардановую матрицу,
[25:41.060 --> 25:59.060]  естественно, называется Жардановым базисом для Фи.
[25:59.060 --> 26:05.060]  Матрица, которую мы получаем, вот эта вот Жарданова матрица,
[26:05.060 --> 26:23.060]  называется как раз Жардановой нормальной формой
[26:23.060 --> 26:31.060]  оператора И, оператора Фи.
[26:31.060 --> 26:37.060]  Жардановой понятно почему? Слово «нормальная» как раз говорит нам,
[26:37.060 --> 26:42.060]  что эта матрица единственная, что каждый Фи мы можем привести
[26:42.060 --> 26:50.060]  путем правильной замены базиса лишь к одной такой вот Жардановой форме с точностью до перестановки клеток.
[26:50.060 --> 26:56.060]  Слово «нормальная» часто отвечает именно, когда мы говорим про нормальную форму,
[26:56.060 --> 27:02.060]  и отвечает именно за вот такую вот единственность.
[27:02.060 --> 27:10.060]  Замечательно, это было первое замечание.
[27:10.060 --> 27:22.060]  Давайте я сразу для ясности сделаю второе замечание, чтобы избежать недомоловок и кривотолков.
[27:22.060 --> 27:30.060]  Как вы думаете, что такое Жарданова клетка размера 1 собственным значением лямбда?
[27:30.060 --> 27:38.060]  Матрица 1 на 1, в которой только лямбда и стоит, правильно?
[27:38.060 --> 27:50.060]  Поэтому в Жардановой нормальной форме могут появиться вот такие клетки 1 на 1, в которых стоят лямбда, правильно?
[27:50.060 --> 28:10.060]  В частности, если оператор оказался диагонализуем, то есть в некотором базисе он имеет там вид лямбда 1 и так далее, лямбда n,
[28:10.060 --> 28:14.060]  то это и есть его ЖНФ.
[28:14.060 --> 28:22.060]  Мы с вами написали блоксно-диагональную матрицу, в которой каждый блок имеет размер 1, правильно?
[28:22.060 --> 28:32.060]  Это и есть его ЖНФ. Нам больше ничего искать не нужно.
[28:32.060 --> 28:46.060]  Но бывает, как мы знаем, недиагонализуемые операторы, и для них конструкция будет немножко более тяжелой.
[28:46.060 --> 28:56.060]  Здесь стоит обратить внимание на какую деталь.
[28:56.060 --> 29:02.060]  Даже уже из этого соображения понятно следующее.
[29:02.060 --> 29:14.060]  Если мы приводим оператор к диагональному виду, у нас вполне может быть, что одна и та же лямбда, одно и то же собственное значение, встретится несколько раз на диагонали, правильно?
[29:14.060 --> 29:22.060]  Мы с вами знаем, что бывают собственные подпространства размерности больше чем 1, тогда эта лямбда встретится больше чем один раз.
[29:22.060 --> 29:32.060]  То есть в этих разных клетках жардановой матрицы одно и то же собственное значение, одна и та же лямбда, вполне может повторяться несколько раз.
[29:32.060 --> 29:50.060]  Одна и та же лямбда, одно и то же собственное значение, может участвовать в нескольких клетках.
[29:50.060 --> 29:56.060]  Давайте я это для ясности сразу скажу.
[29:56.060 --> 30:06.060]  Ну что ж, теорему мы с вами сформулировали, и даже вроде как что-то немножко сказали.
[30:06.060 --> 30:14.060]  Через некоторое время, когда мы будем искать жардановую форму, станет немножко яснее, в чем смысл этой жардановой формы.
[30:14.060 --> 30:22.060]  Ну вот давайте мы об этом поговорим чуть позже, когда мы придем к соответствующей тематике.
[30:22.060 --> 30:32.060]  А пока что мы начинаем постепенно доказывать нашу большую теорему.
[30:32.060 --> 30:44.060]  Давайте вот что я сделаю, граждане.
[30:44.060 --> 30:52.060]  Давайте, чтобы нам не путаться, я на всякий случай где-нибудь в углу доски, вот например здесь,
[30:52.060 --> 31:02.060]  напишу, пока мы все это до конца не запомнили, напишу как выглядит жарданова матрица,
[31:02.060 --> 31:10.060]  чтобы иметь возможность к ней апеллировать и не напоминать, что это такое.
[31:10.060 --> 31:16.060]  Это блочно-диагональная матрица, состоящая из вот таких вот клеток.
[31:16.060 --> 31:26.060]  Первая клетка какого-то размера лямбда 1 на диагонали единички над диагональю, все что я не пишу это нули,
[31:26.060 --> 31:34.060]  потом следующая клетка и так далее.
[31:34.060 --> 31:44.060]  Лямбды в разных клетках не обязательно различны, чтобы можно было туда посмотреть я это выписал.
[31:44.060 --> 31:54.060]  Мы с вами начинаем с первой части теоремы, мы собираемся выяснить, что жарданова нормальная форма
[31:54.060 --> 32:10.060]  у любого оператора, вылитворяющего звездочки естественно, то есть характеристический многошлен какой нам нужно, существует.
[32:10.060 --> 32:18.060]  Я забыл сказать, но давайте я сейчас скажу. Какие у жардановой матрицы собственные значения?
[32:18.060 --> 32:22.060]  Те же самые лямбды в тех же самых количествах, правильно?
[32:22.060 --> 32:28.060]  На самом деле, если вы внимательно посмотрите на эту матрицу, ну или даже вот лучше на эту матрицу,
[32:28.060 --> 32:33.060]  она по-прежнему верхнетриугольная, правильно? Она по-прежнему верхнетриугольная,
[32:33.060 --> 32:41.060]  и поэтому все ее собственные значения написаны на диагоналях ровно в количествах равных алгебравическим кратностям, правильно?
[32:41.060 --> 32:47.060]  Вот эти лямбды, это и есть ее собственные значения, так будет всегда.
[32:47.060 --> 32:55.060]  Так, давайте мы будем доказывать существование нашей формы,
[32:55.060 --> 33:02.060]  и первым делом мы сведем этот вопрос к более простому,
[33:02.060 --> 33:08.060]  используя то самое следствие, которое мы сегодня доказали.
[33:08.060 --> 33:16.060]  Итак, пусть у нас выполнена звездочка.
[33:16.060 --> 33:28.060]  Мы с вами более того знаем, что характеристический многочлен Фи является аннулирующим для Фи.
[33:28.060 --> 33:36.060]  Это теория Магамельта на Келли, и в этом частном случае мы ее уже точно доказали, правильно?
[33:36.060 --> 33:42.060]  Значит, мы имеем право воспользоваться следствием,
[33:42.060 --> 33:50.060]  и взаимно простые многочлены, здесь у нас уже выписаны, взаимно простые многочлены, на которые раскладывается наш многочлен,
[33:50.060 --> 33:54.060]  вот они, вот эти вот сомножители.
[33:54.060 --> 34:04.060]  Значит, характеристический многочлен аннулирующий, и он представлен в виде, давайте я это еще раз даже напишу,
[34:04.060 --> 34:12.060]  лямбда катой минус Фи, минус, извините, х, конечно же, да, минус х в альфа катой,
[34:12.060 --> 34:22.060]  где сомножители попарно-взаимно просты.
[34:22.060 --> 34:44.060]  Значит, по нашему следствию, с которого мы сегодня начали, пространство В раскладывается в прямую сумму,
[34:44.060 --> 34:54.060]  давайте я их обозначу подпространств, нет, давайте я лучше сразу введу нормальное обозначение для этих подпространств,
[34:54.060 --> 35:02.060]  эти подпространства обозначаются вот таким вот образом, В с индексом лямбда ИТ сверху,
[35:02.060 --> 35:08.060]  В лямбда ИТ, это те, кто помнит следствие, уже знают, что это такое,
[35:08.060 --> 35:22.060]  это ядро одного сомножителя, в который вы подставили Фи, то есть ядро лямбда ИТ минус Фи в альфаитой степени,
[35:22.060 --> 35:34.060]  ну или давайте я сразу уж сменю знак, потому что нам так будет удобнее работать, это ядро Фи минус лямбда ИТ в степени альфаиты,
[35:34.060 --> 35:42.060]  понятно, что эти операторы либо не тем не отличаются, либо отличаются знаком, ядра у них в любом случае совпадают.
[35:42.060 --> 36:00.060]  Итак, эти подпространства достаточно важны, В лямбда ИТ называется корневым подпространством,
[36:00.060 --> 36:26.060]  соответствующим собственному значению лямбда ИТ, соответствующим собственному значению лямбда ИТ.
[36:26.060 --> 36:38.060]  Так, ну давайте мы сразу сделаем замечание, вот у нас было два обозначения, мы ввели обозначение В с нижним индексом лямбда ИТ,
[36:38.060 --> 36:47.060]  это собственное подпространство, правильно, и В с верхним индексом лямбда ИТ это корневое подпространство, вот такое вот.
[36:47.060 --> 36:59.060]  Как эти два подпространства соотносятся друг с другом? Какое вложено в какое? Левое вправое или правое в левое?
[36:59.060 --> 37:16.060]  Геометрическая кратность меньше либо равна алгебравической, говорят нам, но тут пока не понятно, какая размерность у вот этого товарища,
[37:16.060 --> 37:33.060]  но на самом деле вы правы, левое подпространство вложено вправое, почему? Потому что В с нижним индексом лямбда ИТ это ядро просто фи минус лямбда ИТ, правильно?
[37:33.060 --> 37:45.060]  А здесь ядро какой-то степени этого товарища, то есть если вектор лежит здесь, он обнуляется фи минус лямбда ИТ, и тем более он обнуляется какой-то степенью,
[37:45.060 --> 37:52.060]  а может быть, что некоторые векторы обнуляются только степенью, но еще не первой степенью фи минус лямбда ИТ, правильно?
[37:52.060 --> 38:02.060]  Поэтому оно вложено в ядро фи минус лямбда ИТ в какой-то степени альфаитой, а это уже В лямбда ИТ верхний.
[38:02.060 --> 38:14.060]  Итак, собственные подпространства являются подпространствами корневых, ну и на самом деле это можно было увидеть еще и из вот этой вот формулы.
[38:14.060 --> 38:19.060]  Мы с вами знаем, что собственные подпространства образуют прямую сумму, правильно?
[38:19.060 --> 38:28.060]  Но в случае, когда оператор не диагонализуем, эта прямая сумма еще не В, поэтому там больше они быть не могут, а меньше они быть могут.
[38:28.060 --> 38:41.060]  То есть как раз может так случиться, что собственные подпространства, действительно подпространства здесь, и их прямая сумма это еще не В, а вот прямая сумма корневых это уже В.
[38:41.060 --> 38:54.060]  Так, прежде чем двигаться дальше, давайте я чуть-чуть скажу про то, что такое корневое подпространство, несколько элементарных свойств корневых подпространств.
[38:54.060 --> 39:01.060]  Сразу выясним, чтобы после этого на них уже не останавливаться.
[39:01.060 --> 39:17.060]  Так, ну для начала давайте я напомню обозначения, которые мы уже вводили, потому что нам сейчас будет очень удобно ими пользоваться.
[39:17.060 --> 39:30.060]  Если у нас есть преобразование фи, то вот это вот фи минус лямбда, которое у нас сейчас будет появляться частенько с различными скалярами лямбда, мы сокращаем до фи лямбда.
[39:30.060 --> 39:34.060]  Ну лямбда это естественно скаляр, правильно?
[39:34.060 --> 39:58.060]  Ну а матрица вот этого товарища, если фи имеет в некотором базисе матрицу А, то, разумеется, фи лямбда в этом же самом базисе будет иметь матрицу А минус лямбда Е, правильно?
[39:58.060 --> 40:10.060]  Матрица оператора умножения всего на лямбду это лямбда Е, и эта матрица естественно тоже будет обозначаться через А с индексом лямбда.
[40:10.060 --> 40:23.060]  Вот так, первым делом давайте я некоторое количество совсем базовых свойств вынесу даже прямо в замечание.
[40:23.060 --> 40:35.060]  Переходим к корневым подпространствам. Корневое подпространство естественно является инвариантным относительно фи.
[40:35.060 --> 40:43.060]  Ну просто потому что это вот это вот ядро, мы как раз говорили, что в этой прямой сумме все подпространства инвариантны, правильно?
[40:43.060 --> 40:53.060]  Оно инвариантно относительно фи, ну и следовательно оно инвариантно относительно любого оператора вида фи лямбда.
[40:53.060 --> 41:02.060]  Мы говорили, что у фи и у фи минус лямбда запас собственных подпространств, извините, инвариантных подпространств одинаковый.
[41:02.060 --> 41:25.060]  Значит, более того, если мы рассмотрим оператор ограничения нашего фи на вот это вот корневое подпространство,
[41:25.060 --> 41:39.060]  то что мы будем понимать, то фи минус лямбда ит в степени альфа ит будет нулем.
[41:39.060 --> 41:48.060]  Раз корневое подпространство это ядро вот такого вот оператора, точно так же как мы сегодня с вами уже делали,
[41:48.060 --> 41:58.060]  мы скажем, что фи минус лямбда ит в альфа ит, если мы его применим к любому вектору из нашего в лямбда ит, то получим ноль, правильно?
[41:58.060 --> 42:02.060]  Значит, это нулевой оператор.
[42:02.060 --> 42:22.060]  Таким образом, х минус лямбда ит в альфа ит это аннулирующий многочлен для вот этого вот псиитова, извините, тут псиитое должно быть, правильно?
[42:22.060 --> 42:39.060]  А мы с вами говорили в свое время, что если, ну да, извините, еще один шаг, это аннулирующий многочлен, значит, минимальный многочлен тоже имеет такой же вид, может быть, с меньшей степенью, правильно?
[42:39.060 --> 43:03.060]  Если минимальный многочлен для нашего оператора псиитова делит любой аннулирующий, его минимальный многочлен также имеет вид х минус лямбда ита в какой-то, может быть, меньшей степени, правильно?
[43:03.060 --> 43:17.060]  В частности, мы с вами говорили, что у минимального многочлена корнями являются все собственные значения преобразования, правильно?
[43:17.060 --> 43:38.060]  Значит, поэтому у псиитова есть единственное собственное значение лямбда ита. Если бы было какое-то другое собственное значение, то оно тоже было бы корнем минимального многочлена, а это не так.
[43:38.060 --> 43:57.060]  Значит, собственное значение у нас единственное.
[43:57.060 --> 44:12.060]  Мы этот шаг уже сегодня делали в другой ситуации с общим многочленом. Глядите, в корневое подпространство, в лямбда ита, это ядро вот такого вот оператора, правильно?
[44:12.060 --> 44:39.060]  То есть если мы фи минус лямбда ита в степени альфа ита, ну давайте я это еще раз напишу, если есть какой-то вектор из нашего корневого подпространства, то просто по определению фи минус лямбда ита в степени альфа ита, примененный к этому вектору, это ноль, правильно?
[44:39.060 --> 45:00.060]  Ну а это и значит, что фи минус лямбда ита в альфа ите, примененная к нему, это ноль, правда? То есть фи минус лямбда ита в альфа ите, примененная к любому вектору из пространства, на котором фи ита определено, дает нам ноль.
[45:00.060 --> 45:19.060]  Так, замечательно, еще пара свойств наших корневых подпространств, которые нам пригодятся в дальнейшем, такое вот утверждение.
[45:19.060 --> 45:47.060]  Если мы возьмем два различных собственных значения лямбда иты неравная лямбда житому, то оператор фи лямбда ита действует невырожденным образом, сейчас я расшифрую, что это такое.
[45:47.060 --> 46:08.060]  На корневое подпространство, соответствующее лямбда житому, то есть формально, если я возьму фи лямбда ита, ограничу его на В лямбда жита, напоминаю, сделать я это могу, потому что подпространство является инвариантным для вот этого товарища, правильно?
[46:08.060 --> 46:25.060]  Так вот, этот оператор, это у нас действительно преобразование нашего корневого подпространства, и это невырожденный оператор.
[46:25.060 --> 46:44.060]  Ну а что такое невырожденный оператор? Мы с вами уже давно знаем, что оператор невырожден тогда, когда его ядро нулевое, если его ядро нулевое, образ получается всем оператором, и он осуществляет биекцию на этом подпространстве.
[46:44.060 --> 47:03.060]  Образ является всем пространством естественным. Ну так и давайте докажем, что ядро этого оператора невырожденное, значит ядро оператора фи лямбда итого, ограниченного на В лямбда жита.
[47:03.060 --> 47:20.060]  Такого вот ограничения. Что это такое? Это все векторы из нашего подпространства, которые при действии этим оператором переходят в ноль, правильно?
[47:20.060 --> 47:39.060]  Ну это значит, что это все векторы из вот этого вот подпространства, которые лежат в ядре просто фи лямбда итого. Я как раз и написал то, что я сказал. Векторы из подпространства, которые он обнуляет.
[47:39.060 --> 47:54.060]  Ну а это что такое? Это корневое подпространство, соответствующее лямбда итому пересечь с, кто такой 2й член? Даже не корневое?
[47:54.060 --> 48:00.060]  Это собственное подпространство, соответствующее лямдоитому, правильно?
[48:00.060 --> 48:04.060]  Пересечь собственное подпространство, соответствующим лямдоитому.
[48:04.060 --> 48:07.060]  Ну, собственное лежит в корневом.
[48:07.060 --> 48:14.060]  Так что это точно содержится в пересечении двух корневых.
[48:14.060 --> 48:21.060]  А мы с вами знаем, что корневые подпространства образуют прямую сумму.
[48:21.060 --> 48:26.060]  Поэтому это пересечение нулевое.
[48:26.060 --> 48:30.060]  Итак, что мы получили? Мы получили, что ядро нашего оператора нулевое.
[48:30.060 --> 48:37.060]  Это и означает, что он невырожденный.
[48:37.060 --> 48:50.060]  Так, ну и на всякий случай...
[48:50.060 --> 48:56.060]  Так, Жерданову форму, Жерданову матрицу я не стираю.
[48:56.060 --> 49:03.060]  На всякий случай еще одно техническое утверждение, чтобы у нас не возникало после этого вопросов.
[49:03.060 --> 49:11.060]  Глядите, мы с вами сказали, что корневое подпространство, соответствующее лямдоитому,
[49:11.060 --> 49:18.060]  это все векторы, которые переводятся в ноль вот такой вот степенью фи лямдоитого, правильно?
[49:18.060 --> 49:25.060]  На самом деле, конечно же, мы можем эту степень заменить на любую большую.
[49:25.060 --> 49:29.060]  То есть, давайте я это формулой напишу.
[49:29.060 --> 49:42.060]  Корневое подпространство это множество всех векторов из В, для которых существует хоть какое-нибудь Т.
[49:42.060 --> 49:50.060]  Такое, что фи лямдоиты в этой степени обнуляют наш вектор.
[49:50.060 --> 49:57.060]  Понятно, вот здесь нам говорят, что мы полагаем Т равное альфаитому, ну или меньше, правильно?
[49:57.060 --> 50:05.060]  На самом деле ничего кроме этого не будет, даже если мы степень будем повышать.
[50:05.060 --> 50:27.060]  Ну, для доказательства достаточно, опять же таки, воспользоваться вот каким соображением.
[50:27.060 --> 50:45.060]  Давайте мы возьмем какое-нибудь натуральное число Т, может быть большее, чем альфаит, и возьмем ядро фи лямдоитого в этой степени.
[50:45.060 --> 50:51.060]  Нам хочется доказать, что это ядро лежит в нашем корневом, правильно?
[50:51.060 --> 51:01.060]  То, что нам утверждается, правда ли, что оно лежит в нашем корневом подпространстве?
[51:01.060 --> 51:12.060]  Если мы это поймем, то мы поймем, что правая часть лежит в левой, ну а левая часть лежит в правой, понятно, потому что по определению В лямдоитого, правильно?
[51:12.060 --> 51:18.060]  Ой, извините, тут, конечно же, тоже итое, правильно? Здесь везде итое и житое нигде не должно быть.
[51:18.060 --> 51:30.060]  Нам достаточно доказать, что это ядро содержится в лямдоитом.
[51:30.060 --> 51:44.060]  Давайте мы посмотрим на ограничение нашего фи на подпространство У.
[51:44.060 --> 51:52.060]  Оно, естественно, тоже инвариантно. Ядро любого подобного оператора инвариантно относительно фи, мы с вами это в свое время доказывали.
[51:52.060 --> 51:57.060]  У инвариантно мы смотрим на его ограничение.
[51:57.060 --> 52:06.060]  Тогда ψ аннулируется следующими двумя многочленами.
[52:06.060 --> 52:17.060]  Во-первых, ψ аннулируется многочленом х-лямдоиты в тетой степени просто потому, что У это ядро вот ровно такого оператора, правильно?
[52:17.060 --> 52:23.060]  Вот это мы два раза с вами это рассуждение уже применяли.
[52:23.060 --> 52:29.060]  А также оно аннулируется, естественно, характеристическим многочленом фи.
[52:29.060 --> 52:39.060]  Потому что все фи аннулируется характеристическим многочленом фи, а значит и наша ψ тоже.
[52:39.060 --> 53:01.060]  Следовательно, ψ аннулируется их нодом, нодом многочленов, характеристическим многочленом фи, и х-лямдоит в т, в этой степени.
[53:01.060 --> 53:08.060]  Давайте мы даже предположим, что t не меньше, чем αi t, потому что для меньших будет понятно все, правильно?
[53:08.060 --> 53:15.060]  Если t меньше, чем αi t, то векторы этого ядра обнуляются даже меньшей степенью нашего оператора.
[53:15.060 --> 53:19.060]  И уж тем более альфаиты степени тоже обнуляются.
[53:19.060 --> 53:23.060]  Ну тогда этот нод, что это такое?
[53:23.060 --> 53:28.060]  Характеристический многочлен у нас раскладывается на линейные совмножители вот так вот.
[53:28.060 --> 53:41.060]  Второй многочлен это просто х-лямдоит в т, степень t не меньше, чем αi t, поэтому здесь будет х-лямдоит в альфаиты.
[53:41.060 --> 53:47.060]  Ну что это означает? Это означает таким образом,
[53:47.060 --> 53:54.060]  ψ-лямдоит в альфаиты это уже ноль, а это и есть то, что нам нужно.
[53:54.060 --> 54:04.060]  То есть, если мы ψ-лямдоит применим к любому вектору нашего подпространства у альфаиты раз, то уже получим ноль.
[54:04.060 --> 54:14.060]  Значит, это и говорит, что наше подпространство есть подпространство v-лямдоитова.
[54:14.060 --> 54:31.060]  Итак, корневое подпространство – это подпространство всех векторов, которые хоть какой-то степенью ψ-лямдоитова обращаются в ноль.
[54:31.060 --> 54:43.060]  Ну и всё это даёт нам возможность, даёт нам право изучать действия phi на каждое корневое подпространство по отдельности.
[54:43.060 --> 54:54.060]  Мы сейчас это сделаем, но перед этим, чтобы у нас в голове была некоторая связь с тем, что мы доказываем,
[54:54.060 --> 55:05.060]  как вы думаете, если матрица оператора, вот такая вот Жарданова, я взял базис, в котором матрица оператора Жарданова,
[55:05.060 --> 55:11.060]  где здесь находится корневое подпространство, соответствующее, скажем, лямбдо первому?
[55:11.060 --> 55:19.060]  Не обязательно один, может быть, несколько блоков вот с этим вот самым лямбдо первым.
[55:19.060 --> 55:31.060]  Все векторы, которые участвуют в блоках именно с этим собственным значением лямбдо первое, оно у нас будет собственным значением ограничения на этот блок, правильно?
[55:31.060 --> 55:38.060]  И корневое подпространство будет порождаться именно этими самыми векторами.
[55:38.060 --> 55:46.060]  То есть, по сути дела, когда мы с вами разложили пространство в прямую сумму корневых подпространств,
[55:46.060 --> 55:54.060]  мы с вами сказали, что мы разделили наши пространства на прямые слагаемые,
[55:54.060 --> 56:00.060]  из каждого из которых будут получаться вот эти блоки с фиксированным значением лямбдо итого.
[56:00.060 --> 56:10.060]  Сейчас я скажу это еще немножко на другом языке, то же самое, может быть, станет яснее.
[56:10.060 --> 56:21.060]  Давайте я сделаю еще одно полезное для нас сегодня определение.
[56:21.060 --> 56:42.060]  Для ясности давайте я скажу, что оператор PSI называется нельпатентным,
[56:42.060 --> 57:10.060]  вроде теперь все буквы отчетливо назвал, это N, это P.
[57:10.060 --> 57:20.060]  Ну, по сути дела, от латинской корней нулевая степень, если у него есть нулевая степень.
[57:20.060 --> 57:31.060]  То есть, если существует такое T, что PSI в тетой это ноль.
[57:31.060 --> 57:40.060]  Так вот, все эти слова мы с вами уже сказали.
[57:40.060 --> 57:47.060]  Вот у нас написано, что PSI it-лямдо it в степени альфа it это ноль.
[57:47.060 --> 58:03.060]  То есть, оператор phi-лямдо it, то есть phi-лямдо it, ограниченный на корневое подпространство,
[58:03.060 --> 58:08.060]  но это то же самое, что PSI it-лямдо it, правильно?
[58:08.060 --> 58:22.060]  Ну, по сути дела, я два раза написал одно и то же, он как раз нельпатентный.
[58:22.060 --> 58:29.060]  И вот мы сейчас приступим к изучению как раз таких операторов.
[58:29.060 --> 58:35.060]  Ну, давайте я сразу сделаю еще одно замечание для ясности.
[58:35.060 --> 58:43.060]  Замечание второе.
[58:43.060 --> 58:47.060]  Нам это даже может быть не потребуется, но полезно это понимать.
[58:47.060 --> 58:53.060]  Глядите, у PSI it-ого мы с вами говорили, все собственные значения равны лямдо it-ому, правильно?
[58:53.060 --> 58:57.060]  То есть, у PSI it-ого минус лямдо it-ого, вот у этого нельпатентного оператора,
[58:57.060 --> 59:05.060]  все собственные значения будут равны...
[59:05.060 --> 59:11.060]  Нет, еще раз, у PSI it-ого собственное значение лямдо it-ое, а сейчас я это лямдо it-ое вычел.
[59:11.060 --> 59:16.060]  Что произойдет с оператором, если вы из него вычтете константу?
[59:16.060 --> 59:19.060]  Из собственных значений тоже вычтется константа, правильно?
[59:19.060 --> 59:23.060]  Поэтому все его собственные значения будут равны нулю.
[59:23.060 --> 59:28.060]  И это общее свойство всех нельпатентных операторов.
[59:28.060 --> 59:38.060]  Все собственные значения любого нельпатентного оператора нулевые.
[59:38.060 --> 59:48.060]  Потому что если у нас есть какой-то вектор v, что PSI от v это лямдо v,
[59:48.060 --> 59:53.060]  то тогда мы знаем, что будет, если к v применить степень нашего PSI.
[59:53.060 --> 59:58.060]  Каждый раз мы будем получать вектор, умноженный на еще одну лямду, правильно?
[59:58.060 --> 01:00:05.060]  PSI в тетой от v это будет лямдо в тетой на v.
[01:00:05.060 --> 01:00:10.060]  Ну и коль скоро PSI в тетой, это 0, мы берем тот самый показатель нельпатентности,
[01:00:10.060 --> 01:00:14.060]  как он называется, равен нулю.
[01:00:14.060 --> 01:00:20.060]  Ну а значит, если v не был нулевым, если v был собственным вектором,
[01:00:20.060 --> 01:00:23.060]  то и лямдо в тетой равно нулю.
[01:00:23.060 --> 01:00:29.060]  Это случается только тогда, когда лямдо равна нулю в поле.
[01:00:29.060 --> 01:00:34.060]  Так что у нельпатентного оператора все собственные значения нулевые.
[01:00:34.060 --> 01:00:37.060]  И вы видите, что мы с вами сделали.
[01:00:37.060 --> 01:00:44.060]  Мы с вами сказали, что наше пространство разбилось в прямую сумму корневых.
[01:00:44.060 --> 01:00:49.060]  На каждом корневом ограничении нашего оператора, если мы из него вычтем
[01:00:49.060 --> 01:00:52.060]  лямдоитую, получится нельпатентным.
[01:00:52.060 --> 01:00:57.060]  И на самом деле это означает, что нам достаточно каждой из этих ограничений
[01:00:57.060 --> 01:01:03.060]  суметь привести к жардановую виду, для того чтобы и весь phi привести
[01:01:03.060 --> 01:01:05.060]  к жардановую виду.
[01:01:05.060 --> 01:01:09.060]  Это мы сейчас с вами и будем делать.
[01:01:09.060 --> 01:01:13.060]  Итак, нам остался последний ингредиент.
[01:01:13.060 --> 01:01:19.060]  После этого все эти ингредиенты мы соберем в теоремовом существовании gnf.
[01:01:21.060 --> 01:01:31.060]  Итак, нам осталось понять, давайте так, gnf нельпатентного оператора.
[01:01:31.060 --> 01:01:37.060]  И мы с вами доказываем вот какую теорему.
[01:01:37.060 --> 01:01:43.060]  Мы ее даже, наверное, через некоторое время двумя способами докажем.
[01:01:43.060 --> 01:02:08.060]  Если psi нельпатентный оператор, то у него есть жарданова форма.
[01:02:08.060 --> 01:02:18.060]  То есть в некотором базе его матрица приобретает нужный нам вид.
[01:02:18.060 --> 01:02:23.060]  Обратите, пожалуйста, внимание, когда я формулирую эту вспомогательную теорему,
[01:02:23.060 --> 01:02:27.060]  я ничего не говорю про характеристический многочлен нашего опси,
[01:02:27.060 --> 01:02:30.060]  он нам уже будет не нужен.
[01:02:30.060 --> 01:02:35.060]  То есть вот это условие о том, что характеристический многочлен раскладывается
[01:02:35.060 --> 01:02:41.060]  на линейные сомножители, у нас сейчас будет следствием из того, что оператор нельпатентен.
[01:02:41.060 --> 01:02:46.060]  У любого нельпатентного оператора на самом деле характеристический многочлен раскладывается
[01:02:46.060 --> 01:02:52.060]  на линейные сомножители, и мы даже знаем на какие, потому что все собственные значения равны нулю.
[01:02:52.060 --> 01:02:56.060]  Характеристический многочлен – это просто плюс-минус степень х.
[01:02:56.060 --> 01:02:59.060]  Вот это мы сейчас с вами докажем.
[01:02:59.060 --> 01:03:03.060]  Теперь после того, как мы корневое подпространство выделили,
[01:03:03.060 --> 01:03:08.060]  характеристический многочлен нам больше не нужен.
[01:03:08.060 --> 01:03:14.060]  Итак, если пси нельпатентный, то у него есть жарданова форма.
[01:03:14.060 --> 01:03:17.060]  Так, как она будет выглядеть?
[01:03:17.060 --> 01:03:21.060]  Конечно же, раз нам сказали, что все собственные значения нули,
[01:03:21.060 --> 01:03:25.060]  то значит у нас вот в этой матрице будут нули по диагонали
[01:03:25.060 --> 01:03:29.060]  и время от времени единички на следующей диагонали.
[01:03:29.060 --> 01:03:37.060]  Она имеет вид следующий.
[01:03:44.060 --> 01:03:49.060]  Клетки могут быть разного размера, может быть просто клетка из нуля, правильно, и так далее.
[01:03:49.060 --> 01:03:56.060]  Эта жарданова форма будет иметь вот такой вот, разумеется, вид.
[01:03:56.060 --> 01:04:02.060]  Ну и давайте мы сразу, прежде чем доказывать это, выясним,
[01:04:02.060 --> 01:04:10.060]  какой должен быть базис для того, чтобы в этом базисе матрица имела жарданов вид.
[01:04:10.060 --> 01:04:14.060]  Но для этого нам достаточно понять, какой должен быть базис
[01:04:14.060 --> 01:04:18.060]  для того, чтобы матрица в этом базисе была жардановой клеткой.
[01:04:18.060 --> 01:04:24.060]  Потому что из таких фрагментов мы составим весь жарданов базис.
[01:04:24.060 --> 01:04:28.060]  Давайте вот мы, давайте даже не в качестве замечания,
[01:04:28.060 --> 01:04:32.060]  а просто ответим на такой вопрос.
[01:04:32.060 --> 01:04:36.060]  Каким должен быть базис?
[01:04:36.060 --> 01:04:42.060]  Ну может быть какого-нибудь подпространства, правильно?
[01:04:42.060 --> 01:04:48.060]  И так далее.
[01:04:48.060 --> 01:05:00.060]  Чтобы оператор, некоторые фи, в этом базисе имел в качестве матрицы жардановую клетку жс.
[01:05:00.060 --> 01:05:04.060]  Я напоминаю, что это как раз жарданова клетка собственным значением ноль.
[01:05:04.060 --> 01:05:08.060]  То есть нули по диагонали, единички над диагональю,
[01:05:08.060 --> 01:05:14.060]  в длинных местах нули, размер этой клетки с.
[01:05:14.060 --> 01:05:20.060]  Ну а что у нас здесь такое написано? Давайте посмотрим.
[01:05:20.060 --> 01:05:28.060]  У нас здесь написано, как действует наша ψ на элементы этого базиса.
[01:05:28.060 --> 01:05:35.060]  И написано у нас следующее, что ψ от Е1 есть 0,
[01:05:35.060 --> 01:05:38.060]  0 столбец 0, правильно?
[01:05:38.060 --> 01:05:46.060]  ψ от Е2 есть Е1, единичка у нас стоит в первой строке, правильно?
[01:05:46.060 --> 01:05:52.060]  И так далее, ψ от Еs, это Еs-1.
[01:05:52.060 --> 01:06:02.060]  Ну то есть по сути дела, оператор должен на эти векторы действовать просто с двигом индекса на 1, правильно?
[01:06:02.060 --> 01:06:07.060]  Еs-3 должен под действием нашего ψ переходить в Еs-1,
[01:06:07.060 --> 01:06:17.060]  тот должен под действием ψ переходить в Еs-2 и так далее до Е1, который уже должен обращаться в ноль.
[01:06:17.060 --> 01:06:29.060]  Если мы хотим получить жардановую клетку, то наш фрагмент базиса должен получиться вот такой вот.
[01:06:29.060 --> 01:06:39.060]  Весь жардановый базис должен быть объединением нескольких вот таких вот цепочек, правильно?
[01:06:39.060 --> 01:07:03.060]  Такая, давайте даже скажем, система векторов называется жардановой цепочкой.
[01:07:03.060 --> 01:07:09.060]  И таким образом, если мы хотим построить жардановый базис для нашего нельпотентного оператора,
[01:07:09.060 --> 01:07:18.060]  то этот жардановый базис должен просто состоять из нескольких жардановых цепочек, каждая цепочка соответствует какой-то клетке.
[01:07:18.060 --> 01:07:33.060]  Жардановый базис должен состоять из нескольких таких цепочек.
[01:07:33.060 --> 01:07:39.060]  Может быть и одной, конечно.
[01:07:39.060 --> 01:07:55.060]  Ну и вот для того, чтобы как бы удобно об этом говорить, давайте мы сразу ведем определение.
[01:07:55.060 --> 01:08:07.060]  Значит, это определение порой работает не только для нельпотентных операторов, поэтому я его дам сейчас в общем виде,
[01:08:07.060 --> 01:08:15.060]  но применять мы его будем только к нельпотентному оператору.
[01:08:15.060 --> 01:08:29.060]  Пусть psi это некоторый оператор, u это подпространство v.
[01:08:29.060 --> 01:08:47.060]  Так вот это самое подпространство u называется циклическим относительно psi.
[01:08:47.060 --> 01:09:03.060]  Если существует такой вектор v в нашем u, что у есть линейная оболочка вот каких векторов v,
[01:09:03.060 --> 01:09:12.060]  psi от v, psi квадрат от v и так далее. Что значит и так далее?
[01:09:12.060 --> 01:09:20.060]  Вообще говоря, я должен дойти до бесконечности, я должен взять все возможные итерации.
[01:09:20.060 --> 01:09:26.060]  Но понятное дело, что в некоторый момент, поскольку мы сидим все-таки в конечномерном пространстве,
[01:09:26.060 --> 01:09:33.060]  в некоторый момент у нас какой-то вектор вот этой последовательности выразится через предыдущее,
[01:09:33.060 --> 01:09:41.060]  тогда и дальнейшие векторы будут выражаться через предыдущее, поэтому вот на этом месте можно будет оборвать этот ряд.
[01:09:41.060 --> 01:09:48.060]  Итак, циклическое подпространство относительно psi это подпространство, порожденное таким вот вектором.
[01:09:48.060 --> 01:09:59.060]  Что это на самом деле такое? Это я взял вектор v и построил самое маленькое инвариантное подпространство, которое содержит v.
[01:09:59.060 --> 01:10:27.060]  Давайте я это напишу. Иначе говоря, у это наименьшее инвариантное относительно psi подпространство, содержащее v.
[01:10:27.060 --> 01:10:42.060]  Просто потому, что если я хочу построить подпространство инвариантное относительно psi и содержащее v, то кроме v я туда обязан включить psi от v.
[01:10:42.060 --> 01:10:52.060]  Если v лежит в подпространстве, то psi от v там тоже должен лежать. Если этот товарищ лежит в u, то psi квадрат от v тоже должен туда включить.
[01:10:53.060 --> 01:10:58.060]  Так что все эти векторы обязаны лежать в инвариантном подпространстве, содержащем v.
[01:10:58.060 --> 01:11:08.060]  Ну и значит, если я ими породил подпространство, то оно как раз и будет самым маленьким. Ну и инвариантным оно естественно тоже будет.
[01:11:08.060 --> 01:11:26.060]  Общее определение вот такое вот. В нашем случае, обратите, пожалуйста, внимание, эту цепочку мы точно можем оборвать, потому что наш оператор нельпотентен.
[01:11:26.060 --> 01:11:32.060]  Пси в тетой равно нулю, поэтому в некоторый момент в этой цепочке появится ноль, правильно?
[01:11:32.060 --> 01:11:52.060]  Значит, давайте я сделаю замечание. В случае, когда psi нельпотентен, но оператор нельпотентен,
[01:11:52.060 --> 01:12:09.060]  у это будет линейной оболочкой v, psi от v и так далее, psi в k-1, скажем, от v, где psi в k-t от v, это уже нулевой вектор.
[01:12:09.060 --> 01:12:15.060]  В некоторый момент там начнутся нули, и вот в этом месте мы и оборвемся.
[01:12:15.060 --> 01:12:25.060]  Ну и глядите, если у нас вот такое вот подпространство есть, хотелось бы сразу сказать, что это и есть жардановая цепочка.
[01:12:25.060 --> 01:12:37.060]  Что мы возьмем вот эти вот векторы в качестве базиса нашего u, и они будут вести себя ровно так же, как написано в жардановой цепочке.
[01:12:37.060 --> 01:12:45.060]  Каждый из них под действием psi переходит в следующий, правильно? Ну а последний переходит уже в ноль.
[01:12:45.060 --> 01:12:57.060]  Правильный вопрос. Почему они линейно-независимы? Сейчас мы докажем, что на самом деле это автоматом будет так для нельпотентного оператора.
[01:12:57.060 --> 01:13:08.060]  Точнее мы сделаем вот что. Давайте вот я чуть-чуть преждевременно ввел вот это вот k.
[01:13:08.060 --> 01:13:34.060]  Значит пусть psi это нельпотентный оператор, v это вектор в нашем v, тогда высота вектора v это наименьшее k.
[01:13:34.060 --> 01:13:51.060]  Ну давайте я скажу наименьшее целое не отрицательное k. Такое, что если я применю к нашему вектору psi в k, то уже получу 0.
[01:13:51.060 --> 01:14:13.060]  Чтобы понять, кто такие векторы высоты 0?
[01:14:13.060 --> 01:14:25.060]  Высоту 0 имеет нулевой вектор и никто кроме, правильно? psi в ноликовает тождественный оператор, как обычно.
[01:14:25.060 --> 01:14:44.060]  Высоту 1 имеет лишь 0. Высоту 1 имеют те векторы, которые при однократном применении psi переходят в 0, правильно?
[01:14:44.060 --> 01:15:03.060]  То есть не нулевые векторы из ядра psi, но или по-другому сказать собственные векторы нашего psi. У нас собственное значение это как раз 0, правильно?
[01:15:03.060 --> 01:15:22.060]  И вот полезное утверждение, которое нам сейчас часто будет пригождаться, заключается в следующем.
[01:15:22.060 --> 01:15:43.060]  Пусть v1 и т.д. выкатые не нулевые векторы по парноразличных высот.
[01:15:43.060 --> 01:15:52.060]  То есть нам нужно разное количество раз применить psi к ним, чтобы в первый раз получить 0.
[01:15:52.060 --> 01:16:05.060]  Тогда они линейно независимы. Вся эта система векторов будет линейно независима.
[01:16:05.060 --> 01:16:16.060]  Для доказательства давайте мы обозначим эти высоты. Все высоты этих векторов натуральные числа, потому что векторы не нулевые, правильно?
[01:16:16.060 --> 01:16:36.060]  Пусть h1 и т.д. это высота вектора v1 и т.д. Естественно мы можем упорядочить по высоте. То есть мы можем считать, что h1 и т.д. упорядочены по возрастанию.
[01:16:36.060 --> 01:16:50.060]  Ну и давайте мы предположим, что наши векторы оказались линейно зависимыми.
[01:16:50.060 --> 01:17:04.060]  Если v1 и т.д. выкатые линейно зависимы, то у нас нашлась их линейная комбинация, которая равна 0 и при этом нетривиальная.
[01:17:04.060 --> 01:17:26.060]  То существует нетривиальная линейная комбинация, сумма αi и vi и т.д. равная 0.
[01:17:26.060 --> 01:17:36.060]  Линейная комбинация нетривиальная, это значит, что у нее есть хотя бы один не нулевой коэффициент.
[01:17:36.060 --> 01:17:49.060]  Давайте мы будем считать, что последний коэффициент не нулевой. Если это не так, то мы просто откинем несколько последних слагаемых и перейдем к меньшей системе.
[01:17:49.060 --> 01:18:07.060]  Тоже векторов попарены различными высотами. Мы можем считать, что αкт не 0.
[01:18:07.060 --> 01:18:19.060]  Давайте мы применим тогда к этому равенству ψ в подходящей степени, а подходящая степень это hkt-1.
[01:18:19.060 --> 01:18:25.060]  Давайте уже закончим доказательство, потом пойдем на перерыв.
[01:18:25.060 --> 01:18:35.060]  Альфа и т ψ в степени hkt-1 от vi. Что это означает?
[01:18:35.060 --> 01:18:51.060]  Когда я применяю вот этого товарища к vi при i меньше, чем k, то я применяю ψ хотя бы в степени hk-1.
[01:18:51.060 --> 01:18:57.060]  И значит должен получить 0.
[01:18:57.060 --> 01:19:15.060]  ψ в hkt-1 от vi это 0 при i меньше, чем k, потому что hi-1 не превосходит вот этого товарища, и значит у нас уже должен получиться 0.
[01:19:15.060 --> 01:19:23.060]  Здесь у нас будет всего-то навсего альфа катоя на ψ в степени hkt-1 от vi.
[01:19:23.060 --> 01:19:37.060]  Ну а это не 0, потому что коэффициент не нулевой, и вот этот вот вектор еще не нулевой, потому что мы применили ψ в степени на 1 меньше, чем высота нашего вектора.
[01:19:37.060 --> 01:19:57.060]  Значит это не 0. Ну и естественно это противоречие с тем, что мы применили наша ψ в hkt-1 к вот этому равенству, то есть должны были получить естественно тоже 0.
[01:19:57.060 --> 01:20:05.060]  Итак, утверждение мы с вами доказали, давайте на этом месте устроим перерыв.
[01:20:05.060 --> 01:20:19.060]  Доказали, что векторы различных высот не нулевые, естественно линейно независимые, ну и как следствие мы получаем то, что я обещал.
[01:20:19.060 --> 01:20:35.060]  Давайте я так это скажу, пусть v это вектор высоты t, ну и давайте мы возьмем линейную оболочку v,
[01:20:35.060 --> 01:20:50.060]  ψ от v, ψ квадрат от v и так далее до какой степени? t-1 конечно же, правильно? Вот оно, это циклическое подпространство.
[01:20:50.060 --> 01:21:09.060]  Тогда естественно v, ψ от v и так далее, ψ в t-1 от v, это базис в u.
[01:21:09.060 --> 01:21:19.060]  То есть если мы берем вот такое вот циклическое подпространство, действительно мы получаем фрагмент, который можно использовать в железновом базисе.
[01:21:19.060 --> 01:21:27.060]  Ну можно было бы, не всякий такой фрагмент получится использовать на самом деле, как мы через некоторое время увидим, но тем не менее.
[01:21:27.060 --> 01:21:45.060]  Тогда это будет базисом в u. Доказательство теперь уже очень простое, просто высота вектора ψ в i t от v равна естественно t-i, правильно?
[01:21:45.060 --> 01:21:54.060]  Если к v нам нужно t раз применить ψ, чтобы получить 0, то к этому осталось ψ применить t-i раз, правильно?
[01:21:54.060 --> 01:22:08.060]  Поэтому эти векторы линейно независимы, ну и кроме того они естественно порождают u, потому что мы ровно так и написали, правильно?
[01:22:08.060 --> 01:22:13.060]  u это циклическое, оно порождено ими, и они линейно независимы.
[01:22:13.060 --> 01:22:31.060]  Еще раз, это мы и сказали, да. Мы именно это и доказали, любые векторы разных высот будут lnz, но здесь мы применяем это к векторам просто последовательных высот, правильно?
[01:22:31.060 --> 01:22:40.060]  От t до 1. Ну и теперь мы уже можем двигаться к доказательству нашей теоремы.
[01:22:40.060 --> 01:22:57.060]  Итак, мы собираемся доказать вспомогательную теорему, правильно, о существовании, напоминаю, gnf у нелепотентного оператора ψ.
[01:22:57.060 --> 01:23:26.060]  Ну, как мы с вами видим, если мы сейчас поняли, что произошло про циклические подпространства, нам достаточно разложить v в прямую сумму циклических подпространств.
[01:23:26.060 --> 01:23:34.060]  Я это еще раз поясню в конце, но давайте пока что скажем так.
[01:23:34.060 --> 01:23:45.060]  Если мы v разложим в прямую сумму циклических подпространств, то каждое циклическое подпространство нам даст как раз одну клетку в жардановой матрице.
[01:23:45.060 --> 01:23:59.060]  Как это сделать?
[01:23:59.060 --> 01:24:13.060]  Итак, ψ, да, но напоминаю, что у нас ψ – это линейный оператор на пространстве v, он нелепотентен, у него есть какая-то степень, в которой, если его возвести, то получится 0.
[01:24:13.060 --> 01:24:27.060]  Давайте мы выберем, давайте я даже леммус сформулирую, чтобы было понятнее, что произойдет дальше.
[01:24:27.060 --> 01:24:46.060]  Пусть v – это вектор наибольшей высоты. У нас существуют векторы различных высот, тогда мы выбираем наибольшую из них.
[01:24:46.060 --> 01:24:58.060]  Так, наибольшей высоты, скажем, t, и давайте мы возьмем циклическое подпространство, порожденное этим вектором.
[01:24:58.060 --> 01:25:14.060]  Тогда у этого подпространства существует прямое дополнение, которое является инвариантным относительно ψ.
[01:25:14.060 --> 01:25:32.060]  То есть тогда существует инвариантное подпространство относительно ψ такое, что v – это прямая сумма u и w.
[01:25:32.060 --> 01:25:46.060]  Ну, собственно говоря, если мы это сейчас докажем, то нам останется просто провести индукцию, поэтому давайте мы это будем доказывать.
[01:25:46.060 --> 01:25:52.060]  Итак, мы выбрали вектор наибольшей высоты. Обратите, пожалуйста, внимание, это существенно.
[01:25:52.060 --> 01:26:11.060]  Если бы я выбрал не вектор наибольшей высоты, а просто какой-то вектор, скажем, не нулевой, породил бы им циклическое подпространство, совершенно не обязательно у него бы нашлось инвариантное прямое дополнение.
[01:26:11.060 --> 01:26:15.060]  Прямое дополнение есть, а вот инвариантного среди них может не найти.
[01:26:15.060 --> 01:26:24.060]  Если я выбираю в качестве v вектор наибольшей высоты, то вот Лемма нам говорит, что это обязательно будет.
[01:26:24.060 --> 01:26:48.060]  Ну, для доказательства давайте мы выберем к u, то есть давайте мы взяли вектор v, породили подпространство u,
[01:26:48.060 --> 01:26:58.060]  и давайте мы попытаемся выбрать инвариантное подпространство наибольшей размерности, которое образует еще прямую сумму с u.
[01:26:58.060 --> 01:27:21.060]  То есть выберем инвариантное подпространство w наибольшей размерности, такое, что они попросту пересекаются по нулю.
[01:27:21.060 --> 01:27:27.060]  Ну, то есть их сумма – это прямая сумма.
[01:27:27.060 --> 01:27:38.060]  Естественно, мы хотим доказать, что w – это именно то, что нам нужно, то есть что эта прямая сумма будет все наше пространство v.
[01:27:38.060 --> 01:27:42.060]  Но почему мы такое подпространство можем выбрать?
[01:27:43.060 --> 01:27:51.060]  Нам нужно для этого сказать, что хоть какое-то инвариантное подпространство, пересекающее с u по нулю, есть, но это просто 0, правильно?
[01:27:51.060 --> 01:27:55.060]  То есть если такого не нулевого подпространства нет, то мы возьмем просто 0.
[01:27:55.060 --> 01:28:02.060]  Если не нулевое есть, то опять же такие вот выбираем подпространство наибольшей размерности.
[01:28:02.060 --> 01:28:22.060]  И давайте мы предположим, что вот эта прямая сумма еще не есть все v, и, следовательно, есть какой-то вектор v вне этой суммы.
[01:28:22.060 --> 01:28:26.060]  Так, давайте мы эту прямую сумму на всякий случай каким-то образом обозначим.
[01:28:26.060 --> 01:28:29.060]  Это будет у нас v'.
[01:28:32.060 --> 01:28:38.060]  Выберем произвольный вектор x из v без v'.
[01:28:43.060 --> 01:28:47.060]  Сейчас мы собираемся это привести к противоречию.
[01:28:50.060 --> 01:28:54.060]  Но первым делом давайте мы x немножко улучшим.
[01:28:56.060 --> 01:29:15.060]  Давайте мы посмотрим на последовательность применения psi к нашему вектору x.
[01:29:15.060 --> 01:29:21.060]  Посмотрим на последовательность x, psi от x, psi квадрат от x.
[01:29:28.060 --> 01:29:30.060]  Когда-то в ней встретится 0, правильно?
[01:29:30.060 --> 01:29:33.060]  psi у нас нелепотентный оператор, поэтому когда-то все сойдется к нулю.
[01:29:34.060 --> 01:29:38.060]  Вектор x у нас еще не лежит в v'.
[01:29:39.060 --> 01:29:46.060]  Когда мы придем в 0, этот вектор уже, конечно, будет лежать в v', правильно?
[01:29:46.060 --> 01:29:56.060]  Значит, в некоторый момент у нас наступит такая ситуация, что очередной член еще не лежит в v', а следующий член уже лежит.
[01:29:56.060 --> 01:30:06.060]  То есть у нас будет такая ситуация, что psi в i-1 от x еще не лежит в v', а psi в i-t уже лежит в v'.
[01:30:09.060 --> 01:30:23.060]  Так вот давайте мы сразу заменим наш x на вот этого товарища, на psi в i-1 от x.
[01:30:23.060 --> 01:30:28.060]  Мы же выбрали вектор просто так, чтобы он лежал в v', но не в v', правильно?
[01:30:28.060 --> 01:30:36.060]  Вот этот вот товарищ тоже, конечно, будет лежать в v' без v', мы выбрали его таким, что он не лежит в v'.
[01:30:36.060 --> 01:30:41.060]  А psi от него уже будет лежать в v'.
[01:30:42.060 --> 01:30:55.060]  Тогда, если мы применили к нему psi, то он уже лежит в v', в нашей прямой сумме, у плюс w.
[01:30:58.060 --> 01:31:00.060]  Что это означает?
[01:31:00.060 --> 01:31:11.060]  Это означает, что он у нас раскладывается в следующую сумму.
[01:31:11.060 --> 01:31:17.060]  Ну, раз он лежит в v', то он раскладывается в сумму вектора из u и вектора из w.
[01:31:17.060 --> 01:31:27.060]  А вектор из u у нас, конечно же, раскладывается по вот этим вот векторам, правильно?
[01:31:27.060 --> 01:31:42.060]  То есть x – это вот что такое, вектор из u, сумма по i от 0 до t-1, какие-то коэффициенты, скажем, гамма, it на psi в it от v,
[01:31:42.060 --> 01:31:51.060]  и плюс некоторый вектор y, содержащийся уже в подпространстве w.
[01:31:51.060 --> 01:31:55.060]  Вот я применил нашу прямую сумму.
[01:31:56.060 --> 01:32:02.060]  Да, спасибо. Разумеется, это psi от x – это важно.
[01:32:11.060 --> 01:32:23.060]  Важное соображение. Давайте мы вспомним, что t – это у нас была наибольшая высота вектора.
[01:32:23.060 --> 01:32:32.060]  Это что означает? Если я вот к этому вектору сейчас применю еще psi в t-1, то получу уже 0, правильно?
[01:32:32.060 --> 01:32:40.060]  Мы знаем, что t – это наибольшая высота вектора. То есть если я применю psi в t к x, то я получу 0.
[01:32:40.060 --> 01:32:58.060]  Это psi в t-1 от psi от x, и это означает, что я psi в t-1 могу применить к каждому члену этой формулы по отдельности.
[01:32:58.060 --> 01:33:14.060]  Сумма по i от 0 до t-1, гамма, it, psi в степени t-1 плюс i от v, и плюс psi в t-1 от y.
[01:33:14.060 --> 01:33:24.060]  Что здесь может быть не нулевым?
[01:33:24.060 --> 01:33:32.060]  Пси в тетой мы уже знаем. Это 0, он любой вектор переводит в 0.
[01:33:32.060 --> 01:33:42.060]  Значит, все вот эти слагаемые у нас обратятся в 0, кроме одного. Кроме слагаемого при i равном 0.
[01:33:42.060 --> 01:33:52.060]  То есть из первой суммы у нас может не обнулиться только гамма ноликовая, psi в t-1 от v.
[01:33:52.060 --> 01:33:58.060]  Он еще не 0, а при i равном 1 у нас здесь будет уже гамма первая на psi в тетой от v, то есть 0.
[01:33:58.060 --> 01:34:05.060]  И еще плюс psi в t-1 от y.
[01:34:05.060 --> 01:34:12.060]  Ну, глядите, какая петрушка. 0 разложился в сумму вот этих вот двух векторов.
[01:34:12.060 --> 01:34:19.060]  При этом первый вектор у нас, конечно же, лежит в u, просто по определению.
[01:34:19.060 --> 01:34:30.060]  А второй вектор у нас лежит в w, потому что w у нас было инвариантным.
[01:34:31.060 --> 01:34:40.060]  Как такое может быть? Мы с вами знаем, что если у нас есть прямая сумма,
[01:34:40.060 --> 01:34:48.060]  то 0 единственным образом раскладывается по векторам из этих двух подпространств.
[01:34:48.060 --> 01:34:56.060]  Как 0 плюс 0. Если 0 разложился в сумму вектора из u и вектора из w, а сумма была прямой,
[01:34:56.060 --> 01:35:07.060]  то мы понимаем, что гамма 0, psi в t-1 от v и psi в t-1 от y, хотя это нам не нужно, равно 0.
[01:35:07.060 --> 01:35:14.060]  Ну а первый вектор может обратиться в 0, ровно тогда, когда гамма ноликовая равно 0, правильно?
[01:35:14.060 --> 01:35:21.060]  Потому что psi в t-1 от v это еще не 0. То есть мы поняли, что гамма ноликовая это 0.
[01:35:21.060 --> 01:35:29.060]  Это и есть то, что нам хотелось. Вот почему.
[01:35:29.060 --> 01:35:42.060]  Глядите, что у нас получается. У нас получается, что psi от x теперь это такая сумма,
[01:35:42.060 --> 01:35:46.060]  в которой каждый раз хотя бы 1 psi применяется.
[01:35:46.060 --> 01:35:54.060]  То есть здесь у нас написано вот в этой вот сумме теперь, когда гамма ноликовая равен 0,
[01:35:54.060 --> 01:36:02.060]  то есть когда коэффициент при v 0, в этой сумме каждый раз написано psi от кого-нибудь, правильно?
[01:36:02.060 --> 01:36:07.060]  И значит вот этого кого-нибудь мы сейчас можем из x вычесть.
[01:36:07.060 --> 01:36:17.060]  Положим, скажем, x' это x минус вот эта вот самая сумма как бы прообразов этих векторов.
[01:36:17.060 --> 01:36:28.060]  Сумма, внимание, по i от 1 до t-1, гамма i t на psi в i-1 от v.
[01:36:28.060 --> 01:36:36.060]  Поскольку гамма ноликовая у нас равен 0, то мы имеем право это сделать.
[01:36:36.060 --> 01:36:44.060]  Тогда psi от x'. Давайте мы формально это напишем.
[01:36:44.060 --> 01:36:52.060]  Это сумма, по i от 0 до t-1, гамма i t, psi в i t от v. Извините, я здесь напишу,
[01:36:52.060 --> 01:36:57.060]  по i от 1, потому что гамма ноликовая 0, правда?
[01:36:58.060 --> 01:37:08.060]  Плюс y и минус psi, примененная к этому, то есть снова сумма, по i от 1 до t-1,
[01:37:08.060 --> 01:37:14.060]  гамма i t, psi уже в i t, я еще раз psi применю от v.
[01:37:14.060 --> 01:37:22.060]  И эти суммы замечательным образом сокращаются, это y, лежит в w.
[01:37:22.060 --> 01:37:27.060]  Теперь глядите, что у нас получилось.
[01:37:27.060 --> 01:37:30.060]  Давайте посмотрим на наши три подпространства.
[01:37:30.060 --> 01:37:42.060]  У, w и подпространство, порожденное x-штрихом.
[01:37:42.060 --> 01:37:47.060]  Обратите внимание, что я сделал с x-штрихом?
[01:37:47.060 --> 01:37:52.060]  Я из x вычел какой-то вектор из u, правда?
[01:37:52.060 --> 01:37:55.060]  Вот эта вот линейная комбинация, это вектор из u.
[01:37:55.060 --> 01:38:04.060]  Значит, я из вектора вне нашей прямой суммы вычел вектор, который лежит в прямой сумме, правда?
[01:38:04.060 --> 01:38:10.060]  Следовательно, x-штрих тоже не содержится в v-штрих.
[01:38:10.060 --> 01:38:13.060]  Вот этот вектор не содержится в v-штрих,
[01:38:13.060 --> 01:38:23.060]  поэтому сумма вот этого подпространства, это v-штрих плюс x-штрих,
[01:38:23.060 --> 01:38:29.060]  сумма v-штрих и вот этого одномерного подпространства является прямой.
[01:38:29.060 --> 01:38:35.060]  Понятное дело, раз x-штрих там не лежит, то их пересечение нулевое.
[01:38:35.060 --> 01:38:40.060]  Значит, у нас здесь написана прямая сумма вот таких вот трех подпространств.
[01:38:48.060 --> 01:38:50.060]  Давайте я ее вот так вот напишу.
[01:38:58.060 --> 01:39:02.060]  И обозначу вот этого кадра через w-штрих, то, что в скобках.
[01:39:05.060 --> 01:39:09.060]  Обратите, пожалуйста, внимание, что такое w-штрих?
[01:39:09.060 --> 01:39:11.060]  Это инвариантное подпространство.
[01:39:14.060 --> 01:39:19.060]  w-штрих, инвариантное подпространство,
[01:39:19.060 --> 01:39:25.060]  потому что psi от w содержится в w, w было инвариантным, правильно?
[01:39:26.060 --> 01:39:35.060]  psi от x-штриха тоже содержится, тоже лежит в w, мы этого тщательно добивались.
[01:39:40.060 --> 01:39:45.060]  Значит, оно порождено векторами, которые переходят при применении psi в w-штрих.
[01:39:45.060 --> 01:39:52.060]  Значит, w-штрих инвариантно образует прямую сумму с u
[01:39:52.060 --> 01:39:56.060]  и имеет большую размерность, чем w.
[01:39:58.060 --> 01:40:02.060]  А мы выбирали w максимальной размерности.
[01:40:02.060 --> 01:40:05.060]  Итого мы получаем противоречие.
[01:40:07.060 --> 01:40:13.060]  Размерность w-штрих, конечно же размерность w плюс один,
[01:40:13.060 --> 01:40:20.060]  и это противоречит выбору w.
[01:40:22.060 --> 01:40:29.060]  И таким образом лему мы с вами доказали.
[01:40:29.060 --> 01:40:34.060]  Еще раз давайте мы пробежимся по шагам доказательства, самые главные леммы.
[01:40:34.060 --> 01:40:39.060]  Мы выбрали инвариантное пространство наибольшей размерности,
[01:40:39.060 --> 01:40:44.060]  которое пересекается с u по нулю, которое с u образует прямую сумму.
[01:40:44.060 --> 01:40:51.060]  Предположили, что их прямая сумма это еще не все пространство w,
[01:40:51.060 --> 01:40:54.060]  а какое-то под пространство v-штрих.
[01:40:54.060 --> 01:41:02.060]  Нашли вне этого v-штриха вектор, который переходит в вектор w под воздействием psi.
[01:41:02.060 --> 01:41:08.060]  И поняли, что тогда этот вектор можно добавить к нашему w так,
[01:41:08.060 --> 01:41:12.060]  чтобы оно осталось инвариантным, увеличило размерность
[01:41:12.060 --> 01:41:16.060]  и продолжило образовывать прямую сумму с u, то есть продолжило пересекаться с u по нулю.
[01:41:16.060 --> 01:41:19.060]  Противоречие с выбором w.
[01:41:19.060 --> 01:41:23.060]  На самом деле в некотором роде это доказательство даже конструктивно,
[01:41:23.060 --> 01:41:27.060]  потому что мы это самое w можем таким образом по шагам строить.
[01:41:27.060 --> 01:41:31.060]  Другое дело, что существуют гораздо более экономные конструкции.
[01:41:31.060 --> 01:41:33.060]  Мы о них еще поговорим.
[01:41:33.060 --> 01:41:36.060]  Итак, лему мы с вами доказали.
[01:41:40.060 --> 01:41:43.060]  Нам осталось доказать теорему.
[01:41:43.060 --> 01:41:47.060]  Возвращаемся к теореме.
[01:41:55.060 --> 01:42:01.060]  Итак, мы уже говорили, мы зашли в самую глубь.
[01:42:01.060 --> 01:42:04.060]  Сейчас всплываем постепенно. Возвращаемся вверх.
[01:42:04.060 --> 01:42:08.060]  Итак, докажем, что w вверх.
[01:42:08.060 --> 01:42:11.060]  Докажем постепенно. Возвращаемся вверх.
[01:42:11.060 --> 01:42:18.060]  Итак, докажем, что w раскладывается в прямую сумму
[01:42:26.060 --> 01:42:29.060]  циклических подпространств.
[01:42:30.060 --> 01:42:38.060]  Индукции по, разумеется, размерности w.
[01:42:38.060 --> 01:42:43.060]  Если размерность w нулевая, то доказывать нечего.
[01:42:43.060 --> 01:42:50.060]  База при размерности w равна 0.
[01:42:50.060 --> 01:42:55.060]  Тривиально.
[01:42:55.060 --> 01:43:02.060]  Просто у нас уже все разложено в прямую сумму 0 циклических подпространств.
[01:43:02.060 --> 01:43:13.060]  Для перехода давайте мы выберем вектор v наибольшей высоты.
[01:43:13.060 --> 01:43:25.060]  Породим этим вектором циклическое подпространство.
[01:43:32.060 --> 01:43:42.060]  И из леммы, давайте я его даже u1 обозначу для ясности,
[01:43:42.060 --> 01:43:48.060]  из леммы мы получаем, что v представляется в виде прямой суммы нашего u1
[01:43:48.060 --> 01:43:58.060]  и какого-то инвариантного подпространства w.
[01:43:59.060 --> 01:44:05.060]  Теперь нам осталось применить предположение индукции
[01:44:13.060 --> 01:44:17.060]  к оператору psi, ограниченному на w.
[01:44:17.060 --> 01:44:23.060]  Мы старались изо всех сил, чтобы w оказалась инвариантным относительно psi.
[01:44:23.060 --> 01:44:33.060]  Значит, ограничение psi на w это тоже, конечно же, оператор и тоже, естественно, нельпотентный.
[01:44:33.060 --> 01:44:42.060]  Мы получим, что w раскладывается в прямую сумму каких-то циклических.
[01:44:42.060 --> 01:44:48.060]  Где это циклические подпространства?
[01:44:48.060 --> 01:44:54.060]  Циклические подпространства относительно ограничения, то есть относительно psi, конечно, тоже.
[01:44:54.060 --> 01:45:02.060]  Ну а тогда и w разложилась в прямую сумму циклических подпространств.
[01:45:02.060 --> 01:45:12.060]  И мы доказали то, что нам нужно было. Мы разложили w в прямую сумму циклических подпространств.
[01:45:12.060 --> 01:45:20.060]  И я на всякий случай обращаю ваше внимание, как этот процесс будет идти, если мы залезем немножко глубже.
[01:45:20.060 --> 01:45:30.060]  Вот мы в v выбрали вектор наибольшей высоты t, породили им т-мирное подпространство у1 циклическое.
[01:45:30.060 --> 01:45:34.060]  Выбрали для него инвариантное прямое дополнение.
[01:45:34.060 --> 01:45:38.060]  В w совершенно необязательно найдутся векторы высоты t.
[01:45:38.060 --> 01:45:44.060]  Вот так случится, что в w все векторы имеют уже меньшую высоту.
[01:45:44.060 --> 01:45:54.060]  Там мы выберем вектор максимальной высоты из имеющихся в w, отрежем снова вот такое вот циклическое подпространство и продолжим процесс.
[01:45:54.060 --> 01:46:02.060]  Если мы вот так вот будем все выстраивать, то у нас высота векторов будет все время не увеличиваться.
[01:46:02.060 --> 01:46:07.060]  Размерности вот этих вот циклических подпространств.
[01:46:07.060 --> 01:46:11.060]  Ну а тогда давайте уж мы еще раз это дело проговорим.
[01:46:11.060 --> 01:46:35.060]  Значит, если у it это циклическое подпространство, порожденное v it, psi от v it и так далее,
[01:46:35.060 --> 01:46:41.060]  давайте я напишу t it-1 от v it.
[01:46:41.060 --> 01:46:51.060]  Ну то есть если у it циклическое подпространство, порожденное вектором v it и высота у него t it,
[01:46:51.060 --> 01:47:00.060]  то мы знаем, что в u it есть жарданов базис.
[01:47:00.060 --> 01:47:04.060]  Как он будет выглядеть, кстати?
[01:47:04.060 --> 01:47:10.060]  Как написать базис, чтобы матрица в этом базисе получилась жардановой клеткой?
[01:47:10.060 --> 01:47:16.060]  Неправда.
[01:47:16.060 --> 01:47:19.060]  Нам нужно начинать наоборот, правильно?
[01:47:19.060 --> 01:47:23.060]  У нас вектор e1, напоминаю, в жардановой клетке переходил в ноль.
[01:47:23.060 --> 01:47:26.060]  То есть это должен быть последним вектором из вот этих вот.
[01:47:26.060 --> 01:47:28.060]  Их надо написать в обратном порядке.
[01:47:28.060 --> 01:47:42.060]  psi в t it-1 от v, psi в t it-2 от v и так далее v it.
[01:47:42.060 --> 01:47:45.060]  У it есть жарданов базис вот такой вот.
[01:47:45.060 --> 01:47:49.060]  Каждый вектор этого базиса переходит в предыдущий при действии psi,
[01:47:49.060 --> 01:47:55.060]  а самый первый вектор переходит в ноль.
[01:47:55.060 --> 01:48:01.060]  Давайте я его назову e it.
[01:48:01.060 --> 01:48:05.060]  То есть если я возьму ограничение psi на u it,
[01:48:05.060 --> 01:48:08.060]  оно, конечно же, инвариантно напоминает,
[01:48:08.060 --> 01:48:14.060]  то в этом вот самом базисе его матрица будет жардановой клеткой.
[01:48:14.060 --> 01:48:17.060]  Просто потому, как мы его выбираем.
[01:48:17.060 --> 01:48:21.060]  Еще раз напоминаю, это базис, мы это в свое время с вами доказали.
[01:48:21.060 --> 01:48:26.060]  Правильно, что векторы эти все линейно независимы.
[01:48:26.060 --> 01:48:46.060]  Значит, объединяя эти базисы, получаем жарданов базис для всего psi.
[01:48:46.060 --> 01:48:56.060]  Просто потому, давайте я сюда перейду,
[01:48:56.060 --> 01:49:03.060]  что матрица как раз и окажется блочно диагональной.
[01:49:03.060 --> 01:49:09.060]  Давайте я еще раз это дело на всякий случай проговорю.
[01:49:09.060 --> 01:49:18.060]  Вот у меня пространство разложилось в прямую сумму наших циклических подпространств.
[01:49:18.060 --> 01:49:22.060]  Они все инвариантны относительно psi.
[01:49:22.060 --> 01:49:24.060]  Правильно, раз они циклические.
[01:49:24.060 --> 01:49:27.060]  В каждом из них мы выбрали вот такой вот жарданов базис.
[01:49:27.060 --> 01:49:33.060]  Если мы объединим эти базисы,
[01:49:33.060 --> 01:49:38.060]  получим базис E.
[01:49:38.060 --> 01:49:43.060]  Сюда поставим сначала фрагмент E1, потом фрагмент E2 и так далее.
[01:49:43.060 --> 01:49:47.060]  Мы получим, естественно, базис V,
[01:49:47.060 --> 01:49:52.060]  поскольку V разложилась в прямую сумму этих самых циклических.
[01:49:52.060 --> 01:49:59.060]  И psi в этом базисе как раз имеет нужный нам вид.
[01:49:59.060 --> 01:50:01.060]  Блочно диагональный вид.
[01:50:01.060 --> 01:50:06.060]  Здесь стоит жарданова клетка размера T1,
[01:50:06.060 --> 01:50:10.060]  здесь стоит жарданова клетка размера T2 и так далее.
[01:50:19.060 --> 01:50:26.060]  Для любого нелепотентного оператора мы жарданов базис нашли.
[01:50:26.060 --> 01:50:31.060]  Ну и давайте, как следствие, за оставшиеся 10 минут,
[01:50:31.060 --> 01:50:36.060]  как раз поймем, что жарданова форма всегда существует.
[01:50:36.060 --> 01:50:41.060]  GNF всегда существует.
[01:50:41.060 --> 01:50:46.060]  Ну и, естественно, в предположениях звездочка.
[01:50:46.060 --> 01:50:48.060]  В предположениях напоминаю, как обычно,
[01:50:48.060 --> 01:50:53.060]  что характеристический многочлен раскладывается на линейное сомножителе.
[01:50:53.060 --> 01:50:58.060]  Итак, давайте вспоминать все то, что мы сегодня наговорили,
[01:50:58.060 --> 01:51:02.060]  и поймем, что это соберется в доказательстве нашего следствия.
[01:51:12.060 --> 01:51:17.060]  Значит, если характеристический многочлен phi раскладывается
[01:51:17.060 --> 01:51:26.060]  на линейное сомножителе лямда Ит минус х в степени альфа Ит,
[01:51:26.060 --> 01:51:34.060]  то мы с вами знаем, что В раскладывается в прямую сумму корневых подпространств.
[01:51:34.060 --> 01:51:42.060]  Фи, да?
[01:51:42.060 --> 01:51:54.060]  Значит, далее, если мы возьмем ограничение нашего фи, давайте,
[01:51:54.060 --> 01:52:02.060]  лямда Ит на В лямда Ит, давайте мы его оба значим через ψ ит.
[01:52:02.060 --> 01:52:17.060]  Мы с вами знаем, что это нильпотентный оператор на корневом подпространстве.
[01:52:21.060 --> 01:52:31.060]  То есть в В лямда Ит существует база.
[01:52:31.060 --> 01:52:35.060]  Здесь давайте я, чтобы не путаться с еитом, который у нас был только что,
[01:52:35.060 --> 01:52:46.060]  назовем его еит верхнее, такой, что если я возьму ограничение ψ ит,
[01:52:46.060 --> 01:52:52.060]  то есть фи с индексом лямда Ит, ограниченное на корневое подпространство,
[01:52:52.060 --> 01:52:57.060]  он будет иметь матрицу Жарданову.
[01:52:57.060 --> 01:53:04.060]  Вот мы с вами говорили, что здесь Ж с индексом Т1, Ж с индексом Т2 и так далее получается.
[01:53:04.060 --> 01:53:11.060]  Это базис фи с индексом лямда Ит.
[01:53:11.060 --> 01:53:20.060]  А что будет, если мы посмотрим на фи, ограниченное на наше корневое подпространство?
[01:53:20.060 --> 01:53:29.060]  Ну это просто-напросто что означает, что я должен вычесть из фи лямда Ит,
[01:53:29.060 --> 01:53:33.060]  а потом добавить лямда Ит, правда?
[01:53:33.060 --> 01:53:42.060]  Вот у этого товарища матрица Жарданова с нулевыми собственными значениями,
[01:53:42.060 --> 01:53:48.060]  когда мы добавляем лямда Ит, мы к нашей матрице добавляем лямда Ит на Е, правильно?
[01:53:48.060 --> 01:53:53.060]  То есть просто-напросто добавляем лямда Ит по диагонали нашей матрицы
[01:53:53.060 --> 01:54:04.060]  и получаем матрицу, которая тоже Жарданова, но уже собственными значениями лямда Ит.
[01:54:04.060 --> 01:54:09.060]  Ж Т2 от лямда Ит и так далее.
[01:54:09.060 --> 01:54:19.060]  Просто по диагонали добавились у нас лямда Ит в этом же самом базисе ЕИТ.
[01:54:19.060 --> 01:54:25.060]  Ну и наконец, глядите, что мы сказали. Мы сказали, что мы наше пространство
[01:54:25.060 --> 01:54:30.060]  разложили в прямую сумму инвариантных подпространств, вот этих вот корневых, правильно?
[01:54:30.060 --> 01:54:34.060]  Они все инвариантны. В каждом из них мы нашли Жарданов базис.
[01:54:34.060 --> 01:54:39.060]  В каждом из них мы нашли базис такой, что в этом базисе матрица имеет такой вид.
[01:54:39.060 --> 01:54:43.060]  Но теперь нам осталось объединить этот базис в одно.
[01:54:43.060 --> 01:55:11.060]  Объединяя полученные базисы
[01:55:11.060 --> 01:55:34.060]  получаем требуемый Жарданов базис Е1 в первом корневом пространстве, Е2 во втором корневом пространстве
[01:55:34.060 --> 01:55:38.060]  и так далее до Яката.
[01:55:38.060 --> 01:55:44.060]  Просто если мы на ФИ посмотрим вот в этом базисе, то матрица получится блокно-диагональной
[01:55:44.060 --> 01:55:56.060]  с блоками вот такого вот вида, правильно? Это и есть Жарданова матрица.
[01:55:56.060 --> 01:56:04.060]  И таким образом теорему о существовании Жардановой формы мы с вами уже доказали.
[01:56:11.060 --> 01:56:22.060]  Наверное, стоило бы поговорить сейчас о других подходах к этому построению, в частности о более конструктивных.
[01:56:22.060 --> 01:56:29.060]  Но если я сейчас это дело начну, то я боюсь, что я ничего существенного не успею сказать.
[01:56:29.060 --> 01:56:38.060]  Поэтому давайте мы на этом чуть пораньше сегодня и закончим.
[01:56:38.060 --> 01:56:43.060]  Оставим время на вопросы, если они возникают по какой-то части вот этого доказательства.
[01:56:43.060 --> 01:56:47.060]  Доказательства сложные, в нем, естественно, стоит разобраться.
[01:56:47.060 --> 01:56:51.060]  Ну вот я призываю это сделать.
