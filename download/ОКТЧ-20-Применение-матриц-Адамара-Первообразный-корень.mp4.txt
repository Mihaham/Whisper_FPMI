[00:00.000 --> 00:09.320]  Так, товарищи, ну что, продолжаем нашу деятельность, да?
[00:09.320 --> 00:10.320]  Матрица Адамара.
[00:10.320 --> 00:11.320]  А?
[00:11.320 --> 00:17.000]  Да, да, было такое, Матрица Адамара, но мы не закончили
[00:17.000 --> 00:19.480]  некое доказательство, тут надо вот вернуться как-то
[00:19.480 --> 00:21.840]  к пониманию того, на чем мы остановились в прошлый
[00:21.840 --> 00:22.840]  раз.
[00:22.840 --> 00:25.520]  Там же не просто Матрица Адамара, а Матрица Адамара
[00:25.520 --> 00:28.720]  в применении к некоторой задаче о раскраске.
[00:28.720 --> 00:32.800]  Я очень не хочу напоминать все определения, конечно,
[00:32.800 --> 00:36.120]  то есть я предполагаю, что вы их как бы помните, да?
[00:36.120 --> 00:38.160]  Или я зря это предполагаю?
[00:38.160 --> 00:41.520]  Ну я зря это предполагаю, я знаю, я человек вполне
[00:41.520 --> 00:42.520]  реалистичный.
[00:42.520 --> 00:43.520]  Вот.
[00:43.520 --> 00:50.560]  Я, конечно, очень люблю мотивировать, да, но я прекрасно все понимаю.
[00:50.560 --> 00:55.440]  Там многоматно одноименных определений.
[00:55.440 --> 00:57.360]  Это дело даже не в этом, но они все-таки такие, не
[00:57.360 --> 00:58.360]  очень простые.
[00:58.360 --> 01:03.160]  То есть, что мы утверждали, теоремат, какую мы доказываем,
[01:03.160 --> 01:09.600]  в чем состоит, то существует такая совокупность, состоящая
[01:09.600 --> 01:14.680]  из множеств М1 и так далее МН?
[01:14.680 --> 01:20.720]  Все по-другому обозначали, да?
[01:20.720 --> 01:27.280]  А, ну да, я написал там N, пусть S равно N, но можно
[01:27.280 --> 01:29.840]  я недословно буду воспроизводить теорему, вы же ее можете
[01:29.840 --> 01:30.840]  не записывать.
[01:30.840 --> 01:34.200]  Я сейчас просто напоминаю, чтобы вы как-то включились.
[01:34.200 --> 01:36.800]  Вы вот это можете не записывать, чтобы не запутаться в разных
[01:36.800 --> 01:37.800]  формулировках.
[01:37.800 --> 01:41.120]  Но если я хочу неформально читать, а так, чтобы вы понимали
[01:41.120 --> 01:45.880]  в процессе, то мне кажется, это не страшно совершенно.
[01:45.880 --> 01:49.920]  Такая, что диск, то есть уклонение этой совокупности
[01:49.920 --> 01:54.920]  больше либо равняется корень из N на 2, но я опять
[01:54.920 --> 01:57.640]  забыл сказать, но я так и писал, кстати, в прошлый
[01:57.640 --> 02:00.960]  раз, коль скоро N в порядок матрицы Адамара.
[02:00.960 --> 02:08.480]  Что-то длинное какое-то у меня получилось, давайте
[02:08.480 --> 02:11.600]  я вот так вот сделаю, у меня будет кусок доски.
[02:11.600 --> 02:17.060]  Уклонение M больше либо равняется корень из N пополам, коль
[02:17.060 --> 02:19.980]  скоро N, это порядок матрицы Адамара.
[02:19.980 --> 02:25.100]  Вот, и мы в принципе некоторую конструкцию осуществили,
[02:25.100 --> 02:28.180]  а именно мы взяли матрицу H, это матрица Адамара в
[02:28.180 --> 02:31.460]  нормальной форме, вы лучше не записывайте, а слушайте
[02:31.460 --> 02:34.340]  и смотрите, чем заканчивалась прошлая лекция, так будет
[02:34.340 --> 02:35.340]  понятнее.
[02:35.340 --> 02:38.060]  Мы взяли матрицу H, это матрица Адамара в нормальной
[02:38.060 --> 02:43.460]  форме, к ней прибавили матрицу G, которая состояла из сплошных
[02:43.460 --> 02:48.620]  единиц, такая суперединичная матрица, и разделили пополам.
[02:48.620 --> 02:55.340]  У нас получилась какая-то матрица размера N на N, у которой
[02:55.340 --> 03:00.780]  все элементы, ну не важно как их обозначить, АИТ,
[03:00.780 --> 03:04.060]  ЖИТ, АИТ, ЖИТ, принадлежат 0,1.
[03:04.060 --> 03:11.260]  И вот я успел сказать, по-моему, в конце, что трочки этой
[03:11.700 --> 03:12.860]  и будут формировать множество m1, m2, m3, и будут формировать
[03:12.860 --> 03:17.460]  множество m1, m2, m3, и т.д.
[03:17.460 --> 03:21.540]  Так, друзья, а все остальные помнишь, что я на этом совершил?
[03:21.540 --> 03:22.940]  Как строчки формируют?
[03:22.940 --> 03:26.140]  Значит, первая строчка состоит из сплошных единиц,
[03:26.140 --> 03:30.620]  то есть множество m1 – это множество 1, 2, и т.д. N.
[03:30.620 --> 03:33.260]  Вторая строчка состоит из половины единиц, половины
[03:33.260 --> 03:37.300]  нулей, но это будет множество, соответственно, m2, которое
[03:37.300 --> 03:41.540]  состоит из чисел, отвечающих номерам единичных позиций.
[03:41.660 --> 03:42.660]  Ну и так далее.
[03:42.660 --> 03:45.620]  Вот будет такие N множество, первая жирная прям все
[03:45.620 --> 03:47.860]  заполняет, а остальные – пополовинки.
[03:50.620 --> 03:52.100]  Сейчас я понятно изъясняюсь?
[03:52.100 --> 03:55.060]  Вот, ну вот теперь это надо как-то доказать.
[03:55.060 --> 03:56.500]  Давайте… Ну что доказать?
[03:56.500 --> 03:59.740]  Доказать, что это совокупность и уклонение такое.
[03:59.740 --> 04:04.020]  Ну давайте сначала… Да, что надо для этого доказать?
[04:04.020 --> 04:06.220]  Не сначала, вот что надо доказать?
[04:06.340 --> 04:22.380]  Я утверждаю, что фактически надо доказать, что для любого
[04:22.380 --> 04:36.180]  вектора V координатами v1 и т.д. vN и принадлежащего
[04:36.180 --> 04:44.100]  0, 1, а плюс 1 и минус 1 в N степени… Я сейчас напишу,
[04:44.100 --> 04:45.100]  а потом буду пояснять.
[04:45.100 --> 04:48.940]  Вы с кодом можете не понять, а можете понять.
[04:48.940 --> 04:51.060]  Фактически надо доказать, что для любого вектора
[04:51.060 --> 05:01.580]  из плюс-минус единиц h плюс g пополам, вот такая матрица,
[05:01.580 --> 05:06.780]  умноженная на этот вектор… Ну, наверное, если уж совсем
[05:06.780 --> 05:10.340]  стараться писать, как алгебраисты делают транспонированный,
[05:10.340 --> 05:13.300]  я не знаю, насколько вас формализовано это учат.
[05:13.300 --> 05:17.220]  Я бы, честно, t не писал, но вы, наверное, хотите.
[05:17.220 --> 05:19.780]  Ну имеется в виду, что, конечно, я умножаю на столбец
[05:19.780 --> 05:25.220]  справа, значит, что вот это вот вектор получится…
[05:25.220 --> 05:27.340]  Да, это же получится вектор, правильно?
[05:28.340 --> 05:43.340]  Ум вектора вот такого вот есть координата, модуль
[05:43.340 --> 05:50.100]  которой, абсолютная величина которой не меньше, чем корень
[05:50.100 --> 05:51.100]  из N пополам.
[05:51.100 --> 05:55.260]  Я утверждаю, что это в точности то, что нам теперь алгебраически
[05:55.260 --> 05:56.260]  нужно доказать.
[05:56.260 --> 06:01.780]  Если мы эту матрицу умножим на любой вектор из плюс-минус
[06:01.780 --> 06:06.660]  единиц, то у полученного вектора найдется координата,
[06:06.660 --> 06:08.460]  абсолютная величина которой не меньше, чем корень из
[06:08.460 --> 06:09.460]  N пополам.
[06:09.460 --> 06:14.340]  Так, ну давайте попробуем понять, почему это так.
[06:14.340 --> 06:19.460]  Ну смотрите, вот здесь по строчкам, как я уже несколько
[06:19.460 --> 06:22.860]  раз повторил, написаны фактически вот эти множества,
[06:22.860 --> 06:24.260]  просто по своему определению.
[06:24.260 --> 06:32.460]  Да, теперь вот вы берете и строчку этой матрицы, то
[06:32.460 --> 06:36.380]  есть какое-то множество, умножаете на вектор из
[06:36.380 --> 06:39.580]  плюс-минус единиц, что у вас происходит?
[06:39.580 --> 06:44.260]  У вас на единичке, которые стоят на позициях с номерами
[06:44.260 --> 06:48.140]  из множества, умножаются как раз плюс и минус единицы,
[06:48.140 --> 06:51.140]  то есть цвета.
[06:51.140 --> 06:54.980]  Помните, что цвет это плюс или минус единицы, там
[06:54.980 --> 06:57.980]  нули умножаются, не важно, что они умножаются, мы
[06:57.980 --> 07:01.820]  фактически красим вот это множество плюс-минус единичные
[07:01.820 --> 07:02.820]  цвета.
[07:02.820 --> 07:14.860]  Вектор В это наша раскраска, для любого вектора В это
[07:14.860 --> 07:17.700]  и значит для любой раскраски плюс-минус единичные цвета.
[07:18.700 --> 07:23.020]  То есть вектор В состоит из цветов элементов 1 и так
[07:23.020 --> 07:24.020]  далее n.
[07:24.020 --> 07:29.700]  И вот мы говорим, для любого набора этих цветов, если
[07:29.700 --> 07:35.140]  мы на эти цвета поумножаем единички из множества, то
[07:35.140 --> 07:38.500]  где-нибудь на одной из координатных позиций получится не меньше,
[07:38.500 --> 07:39.500]  чем столько.
[07:39.500 --> 07:44.220]  То есть как ни красть, а какое-то множество будет
[07:44.220 --> 07:47.220]  выпадать из хорошего дискрепанса.
[07:47.220 --> 07:50.940]  Будет получать большое уклонение.
[07:50.940 --> 07:59.140]  Не знаю, можно это воспринять?
[07:59.140 --> 08:01.900]  Руки поднимите, пожалуйста, те, кто честно воспринял.
[08:01.900 --> 08:02.900]  Но это хорошо.
[08:02.900 --> 08:06.180]  Потому что сейчас можно действовать чисто алгебраически,
[08:06.180 --> 08:10.180]  уже все, у нас комбинаторная задача практически исчезла.
[08:10.180 --> 08:11.860]  Теперь надо просто это проверять.
[08:11.860 --> 08:15.060]  Ну совсем легко разобраться с h, умноженным на v.
[08:15.060 --> 08:24.180]  Вот давайте начнем с этого, на v транспонент.
[08:24.180 --> 08:26.580]  Потом добавим g, поделим пополам в самом конце.
[08:26.580 --> 08:31.580]  Значит h, умноженное на v, давайте просто обозначим
[08:31.580 --> 08:38.580]  координаты этого вектора l1 и ln.
[08:38.580 --> 08:40.540]  Просто обозначим так эти координаты.
[08:40.540 --> 08:43.300]  Наша цель доказать, что для какого-то e модуль l и т.
[08:43.660 --> 08:45.220]  не меньше, чем корень и зан пополам.
[08:45.220 --> 08:48.020]  Знаете, что мы сделаем?
[08:48.020 --> 08:54.300]  Ну давайте здесь все-таки, мы hv, колярно умножим на
[08:54.300 --> 08:55.300]  hv.
[08:55.300 --> 08:59.180]  Ну то есть рассмотрим с колярный квадрат этого
[08:59.180 --> 09:00.180]  вектора.
[09:00.180 --> 09:09.100]  Колярный квадрат этого вектора.
[09:09.100 --> 09:10.100]  Ну конечно так.
[09:10.100 --> 09:17.580]  Сейчас друзья, вариантов нет по-моему, если мы обозначили
[09:17.580 --> 09:20.660]  координаты этого вектора так, то сколярный квадрат
[09:20.660 --> 09:23.500]  этого вектора вы внесли в новом сколярном произведении.
[09:23.500 --> 09:25.980]  Это сумма квадратов, этих координат.
[09:25.980 --> 09:31.460]  С другой стороны, давайте я возьму нашу матрицу h и
[09:31.460 --> 09:36.700]  ее векторы столбцы обозначу ну как-нибудь вот так.
[09:37.540 --> 09:42.820]  h1, hn, ну пусть транспонированные, неважно, но в общем это векторы
[09:42.820 --> 09:43.820]  столбцы.
[09:43.820 --> 09:51.100]  Это их обозначу… правда, да, сказав, что это векторы
[09:51.100 --> 09:52.100]  столбцы.
[09:52.100 --> 09:56.740]  Ну хорошо, не буду писать, мне тоже кажется, что может.
[09:56.740 --> 10:00.820]  Вот, давайте так действительно оставим, как в терминах
[10:00.820 --> 10:04.540]  этих векторов столбцов написать сколярное произведение.
[10:04.620 --> 10:13.500]  Ну очень просто, это v1, h1, плюс и так далее, плюс vn, hn.
[10:16.060 --> 10:20.940]  Так, v1, vn – это координаты вектора v, ну как умножают
[10:20.940 --> 10:31.020]  матрицу, где сколярное произведение, а-а-а, я понял, да-да-да, это
[10:31.020 --> 10:33.020]  я не дописал, виноват.
[10:34.540 --> 10:37.740]  Да, конечно, конечно, это я просто написал, что такое
[10:37.740 --> 10:39.740]  h умножить на v транспонированное.
[10:39.740 --> 10:42.340]  h умножить на v транспонированное в терминах обозначений
[10:42.340 --> 10:43.980]  для столбцов матрицы h такое.
[10:43.980 --> 10:48.900]  Сейчас, что-то не успеваете спросить, лучше у меня.
[10:48.900 --> 10:51.260]  Не, нормально всё.
[10:51.260 --> 10:59.900]  Ну-ну-ну, но видите, полезно же, всё полезно.
[11:00.860 --> 11:04.460]  Так, слушайте, ну сколярное произведение, конечно,
[11:04.460 --> 11:05.460]  линейно.
[11:05.460 --> 11:13.780]  У нас получится v1 квадрат h1 на h1, что так далее, плюс
[11:13.780 --> 11:29.420]  vn квадрат hn на hn, и плюс сумма по i неравным j, v i t, v j t на h i t,
[11:29.500 --> 11:36.220]  здесь i t, h j t, и вот здесь, ну уж я не знаю, катарсис
[11:36.220 --> 11:39.500]  или не катарсис, но суть происходящего, это всё нули.
[11:42.780 --> 11:46.300]  По определению матрицы Адамара, вот это всё ноль.
[11:49.420 --> 11:53.420]  Конечно, и неравно j, значит, h i t на h i t сколярно даёт ноль.
[11:53.420 --> 12:00.620]  Сама на себя, это не строчка, это столбец, да, сам на
[12:00.620 --> 12:05.900]  себя столбец даёт n, здесь тоже n, вектор с плюс-минус
[12:05.900 --> 12:09.100]  единицу, умноженный сам на себя, размерность n, конечно,
[12:09.100 --> 12:12.220]  даёт в сколярном произведении, в сколярном квадрате, даёт
[12:12.220 --> 12:13.220]  n.
[12:13.220 --> 12:17.420]  Итого мы получаем v1 в квадрате, vn в квадрате, это единицы,
[12:17.420 --> 12:25.420]  конечно же, это 1, это 1, итого мы получаем n квадрат,
[12:25.420 --> 12:29.420]  а с другой стороны это сумма квадратов элитых, ну значит,
[12:29.420 --> 12:32.620]  какое-то элите в квадрате не меньше, чем n, а значит,
[12:32.620 --> 12:37.420]  какое-то элите не меньше, чем корень z, следовательно,
[12:37.420 --> 12:43.420]  существует, существует, и такое, что элите по модулю
[12:43.420 --> 12:45.420]  не меньше, чем корень z.
[12:47.420 --> 12:49.420]  О, а?
[12:49.420 --> 12:51.420]  Да.
[12:51.420 --> 12:53.420]  Да.
[12:53.420 --> 12:55.420]  Да.
[12:55.420 --> 13:03.420]  Да, остальные с плюс-минус 1 за половиной там, да.
[13:03.420 --> 13:07.420]  А неважно, где вот здесь используется, чтобы…
[13:07.420 --> 13:09.420]  Что?
[13:09.420 --> 13:11.420]  Где вот здесь?
[13:11.420 --> 13:15.420]  Нет, смотрите, у нас строчка какая-то из плюс-минус
[13:15.420 --> 13:19.420]  где-то минус единицы, где-то плюс, но они все время умножаются
[13:19.420 --> 13:22.420]  вот так, она же сама на себя умножается, то есть везде
[13:22.420 --> 13:25.420]  получаются единицы, неважно, сколько там минус единиц
[13:25.420 --> 13:29.420]  в этой строчке, важно, что она есть плюс-минус единиц.
[13:29.420 --> 13:32.420]  В этом месте неважно, что она в нормальной форме,
[13:32.420 --> 13:35.420]  мы этим еще воспользуемся, но не сейчас, здесь все получилось.
[13:35.420 --> 13:39.420]  То есть в принципе уже вся суть понятна, если мы там
[13:39.420 --> 13:42.420]  не гонимся за какой-то мелочью, но корень z пополам
[13:42.420 --> 13:45.420]  получился, надо как-то zhi побороться.
[13:45.420 --> 13:51.420]  То есть, друзья, вы понимаете, что h пополам, вот именно
[13:51.420 --> 13:56.420]  h пополам умноженное на… вот h пополам умноженное на v,
[13:56.420 --> 13:59.420]  все, она уже обладает вот этим свойством, все замечательно.
[13:59.420 --> 14:01.420]  Надо zhi еще как-то разобраться.
[14:01.420 --> 14:06.420]  Да, надо, чтобы zhi это свойство не испортило, да.
[14:06.420 --> 14:11.420]  Ну, сходу ясно, что сильно не испортит, но сейчас докажем,
[14:11.420 --> 14:13.420]  что вообще не испортит.
[14:13.420 --> 14:23.420]  Так, что такое h плюс zhi на v транспонируем?
[14:23.420 --> 14:30.420]  Ну, это, конечно, l1, а плюс что?
[14:30.420 --> 14:35.420]  Но тут единицы сплошные умножаются на v1 и так далее vn.
[14:35.420 --> 14:39.420]  Вот тут единицы, а тут v1 vn.
[14:40.420 --> 14:43.420]  Правда ли, что получится просто сумма v1?
[14:43.420 --> 14:45.420]  Ну, давайте я так и напишу.
[14:45.420 --> 14:52.420]  Сумма p i от единицы до n v1, l2 тоже будет сумма p i от единицы
[14:52.420 --> 15:01.420]  до n v1 и так далее, ln плюс сумма p i от единицы до n v1.
[15:01.420 --> 15:07.420]  Так, сейчас, друзья, есть какой-нибудь вопрос по этому?
[15:07.420 --> 15:09.420]  Понятно?
[15:09.420 --> 15:14.420]  Так, ну, для краткости обозначим эту сумму буквкой лямбда.
[15:14.420 --> 15:17.420]  Просто обозначим.
[15:17.420 --> 15:20.420]  И, кстати, заметим, что лямбда это четное число.
[15:20.420 --> 15:24.420]  Все ли понимают, что лямбда это четное число?
[15:24.420 --> 15:30.420]  Это сумма плюс-минус единицы в векторе, у которого четное число координат.
[15:31.420 --> 15:34.420]  Очевидно, что это четное число.
[15:34.420 --> 15:37.420]  Давайте я это где-нибудь здесь напишу, это пригодится.
[15:37.420 --> 15:40.420]  Лямбда четная.
[15:40.420 --> 15:45.420]  Так, ну и, наверное, сейчас будем снова смотреть квадрат, скалярный квадрат.
[15:45.420 --> 15:49.420]  Так, берем скалярный квадрат, я уже так напишу.
[15:49.420 --> 15:52.420]  Снова берем скалярный квадрат.
[15:52.420 --> 15:57.420]  Так, у нас получается l1 в квадрате плюс и так далее плюс ln в квадрате.
[15:57.420 --> 16:04.420]  Плюс два лямбда один на сумму по i от единицы до n литых.
[16:04.420 --> 16:07.420]  И плюс лямбда квадрат на n.
[16:07.420 --> 16:10.420]  Правильно?
[16:10.420 --> 16:13.420]  Скалярный квадрат вот этого нового вектора.
[16:13.420 --> 16:16.420]  Это надо в квадрат возвести каждую штуковину.
[16:16.420 --> 16:22.420]  Ну как раз будет l i t в квадрате плюс два лямбда l i t плюс лямбда квадрат.
[16:22.420 --> 16:25.420]  Ну складываем, слагаем их, получаем так.
[16:28.420 --> 16:30.420]  Так, здесь мы кое-что знаем.
[16:30.420 --> 16:33.420]  Вот это вот мы уже считали.
[16:33.420 --> 16:40.420]  Получается n в квадрате плюс два лямбда на сумму l i t.
[16:40.420 --> 16:43.420]  И плюс лямбда квадрат на n.
[16:46.420 --> 16:48.420]  Давайте найдем сумму l i t.
[16:48.420 --> 16:52.420]  Вот сейчас мы воспользуемся нормальностью формы матрицы.
[16:52.420 --> 16:55.420]  Для нахождения суммы l i t.
[16:55.420 --> 17:00.420]  Сумма по i от единицы до n l i t.
[17:00.420 --> 17:03.420]  Здесь удобно вернуться вот на нить.
[17:03.420 --> 17:08.420]  Сумма по i от единицы до n l i t.
[17:08.420 --> 17:13.420]  Здесь удобно вернуться вот, наверное, сюда к определению l i t.
[17:13.420 --> 17:17.420]  И сказать, что давайте еще вот так вот напишем.
[17:17.420 --> 17:23.420]  h i t ж i t это будет обозначение для элемента матрицы Адамара.
[17:23.420 --> 17:26.420]  То есть у нас было обозначение для столбца матрицы Адамара.
[17:26.420 --> 17:28.420]  Со стрелочкой, с одним индексом.
[17:28.420 --> 17:32.420]  А с двумя индексами это просто элемент матрицы Адамара.
[17:33.420 --> 17:37.420]  Вот что значит сложить l i t?
[17:37.420 --> 17:40.420]  Если мы знаем элементы матрицы Адамара.
[17:40.420 --> 17:42.420]  Что такое l 1?
[17:42.420 --> 17:45.420]  Это мы берем, складываем по столбцам пожи.
[17:45.420 --> 17:50.420]  h i t ж i t умножить на v ж i t, соответственно.
[17:51.420 --> 17:56.420]  То есть я хочу сказать, что когда мы еще потом все эти l i t складываем,
[17:56.420 --> 17:58.420]  то, наверное, получается вот так.
[17:58.420 --> 18:00.420]  Сумма по i от 1 до n.
[18:00.420 --> 18:04.420]  Сумма по ж от 1 до n.
[18:04.420 --> 18:08.420]  h i t ж i t на v ж i t.
[18:12.420 --> 18:15.420]  Вот это вот внутреннее суммирование это l i t.
[18:15.420 --> 18:19.420]  Вот мы складываем l i t и по i от 1 до n.
[18:19.420 --> 18:21.420]  Вроде просто.
[18:21.420 --> 18:26.420]  Так, а теперь мы еще переставим тут, наверное, какие-то порядки суммирования.
[18:26.420 --> 18:28.420]  И вот так напишем.
[18:28.420 --> 18:37.420]  Сумма пожи от 1 до n v ж i t умножена на сумму по i от 1 до n h i t ж i t.
[18:39.420 --> 18:43.420]  И вот тут возникает нормальность формы.
[18:44.420 --> 18:53.420]  Потому что сумма по i от 1 до n h i t ж i t это сумма элементов внутри столбца матрицы Адамара.
[18:56.420 --> 18:59.420]  Это n в начале, а дальше сплошные нули.
[18:59.420 --> 19:02.420]  Правильно, за счет нормальности формы.
[19:02.420 --> 19:05.420]  То есть это плюс-минус n.
[19:05.420 --> 19:09.420]  Мы не знаем, чему равно v1, который умножается на n.
[19:09.420 --> 19:11.420]  То ли плюс, то ли минус единица.
[19:11.420 --> 19:14.420]  Но вот как-то так, в зависимости от v1.
[19:14.420 --> 19:19.420]  Плюс-минус n, а потом уже ж равного двойки здесь стоят нули.
[19:19.420 --> 19:23.420]  Поэтому больше ничего прибавлять не нужно.
[19:23.420 --> 19:32.420]  Итого у нас вот тут получается n квадрат плюс-минус 2 лямбда n плюс лямбда квадрат на n.
[19:33.420 --> 19:36.420]  Вот какая квадратичная форма.
[19:37.420 --> 19:40.420]  Такая парабола и по n и по лямбда.
[19:42.420 --> 19:46.420]  Так, ну по лямбда это парабола.
[19:46.420 --> 19:48.420]  Точно такая, да?
[19:49.420 --> 19:52.420]  Я, понятно, собираюсь.
[19:54.420 --> 19:57.420]  Вы понимаете, нам хочется это оценить снизу.
[19:57.420 --> 20:00.420]  Или забыли, что нам хочется это оценить снизу.
[20:00.420 --> 20:05.420]  Но раз парабола такая, надо смотреть, где у нее минимум достигается, чтобы оценить снизу.
[20:06.420 --> 20:09.420]  Ну да, конечно.
[20:09.420 --> 20:11.420]  Ну как?
[20:11.420 --> 20:13.420]  Где эта вершинка?
[20:13.420 --> 20:15.420]  То есть это что?
[20:15.420 --> 20:17.420]  Это минус b поделить на 2a, да?
[20:18.420 --> 20:20.420]  Я не знаю, вас так учили или нет.
[20:20.420 --> 20:23.420]  Может, я повторяю какие-то мантры, которые вам не знакомы.
[20:23.420 --> 20:25.420]  Ну, производная, да?
[20:25.420 --> 20:27.420]  Где производная равняется нулю?
[20:27.420 --> 20:31.420]  Когда многочлен записывается в виде ax квадрат плюс bx плюс c,
[20:31.420 --> 20:34.420]  то там получается минус b поделить на 2a.
[20:34.420 --> 20:39.420]  В плохих школах учат просто запоминать, что это в точке минус b поделить на 2a.
[20:39.420 --> 20:44.420]  В математических школах люди, конечно, понимают, откуда это берется, и не запоминают мантры.
[20:44.420 --> 20:46.420]  А в плохих прямо так и учат.
[20:46.420 --> 20:49.420]  Минус b на 2a, минус b на 2a, не дай бог забыть.
[20:49.420 --> 20:50.420]  Вот.
[20:50.420 --> 20:52.420]  Ну, короче, здесь надо минус...
[20:52.420 --> 20:56.420]  Давайте я лямбда мин возьму много болтовней.
[20:56.420 --> 20:59.420]  Это минус плюс, ой, минус плюс.
[20:59.420 --> 21:02.420]  Ну, потому что минус b поделить на 2a.
[21:02.420 --> 21:06.420]  Так, это минус плюс 2n поделить на 2n.
[21:06.420 --> 21:09.420]  То есть внимание, это минус плюс 1.
[21:09.420 --> 21:11.420]  Смотрите сюда.
[21:11.420 --> 21:17.420]  Ну, то есть те реальные лямбды, которые есть в нашем распоряжении, которые у нас возникают,
[21:17.420 --> 21:21.420]  они глобально минимизировать, конечно, эту параболу не могут.
[21:21.420 --> 21:28.420]  Но, то есть, если здесь ожидается минус 1, то наши кандидаты – это минус 2 и 0.
[21:28.420 --> 21:34.420]  А если здесь ожидается плюс 1, то наши кандидаты – это 0 и 2.
[21:34.420 --> 21:38.420]  Я быстро говорю или понятно?
[21:38.420 --> 21:42.420]  Не очень?
[21:42.420 --> 21:44.420]  А?
[21:44.420 --> 21:46.420]  На минимизацию.
[21:46.420 --> 21:48.420]  Лямбда мин.
[21:48.420 --> 21:50.420]  Хорошо, я еще раз повторю.
[21:50.420 --> 21:51.420]  Смотрите.
[21:51.420 --> 21:57.420]  Вы согласны, да, с тем, что вот эта парабола по лямбда минимизируется в точках минус или плюс 1
[21:57.420 --> 22:01.420]  в зависимости от того, v1 равнялась плюс или минус единице.
[22:01.420 --> 22:06.420]  Если v1 было плюс 1, то точка, в которой достигается минимум, будет со знаком минус,
[22:06.420 --> 22:09.420]  если там был минус, то будет плюс.
[22:09.420 --> 22:13.420]  Но у нас лямбда – обязательно четное число.
[22:13.420 --> 22:18.420]  Поэтому ни минус единицы, ни плюс единицы у нас, в принципе, возникнуть не может.
[22:18.420 --> 22:20.420]  И тогда я говорю так.
[22:20.420 --> 22:23.420]  Вот если v1 равняется плюс единицы,
[22:23.420 --> 22:30.420]  тогда те точки лямбда, которые реально минимизируют в нашем случае эту параболу,
[22:31.420 --> 22:36.420]  это не минус 1, а ноль или два.
[22:36.420 --> 22:46.420]  А если v1 равняется единице, то лямбда мин, в нашем случае,
[22:46.420 --> 22:50.420]  но лямбда минимальная, четная, если хотите, можете прерисовать,
[22:50.420 --> 22:54.420]  это будет не минус 1, а ноль и два.
[22:54.420 --> 22:56.420]  Вот они минимизируют.
[22:56.420 --> 22:59.420]  А если v1 равно минус единицы,
[22:59.420 --> 23:02.420]  кандидат на минимизацию этой функции, просто так я выразился,
[23:02.420 --> 23:07.420]  то получится лямбда мин, реальный равняется,
[23:07.420 --> 23:10.420]  но вокруг плюс единички надо прыгнуть.
[23:10.420 --> 23:13.420]  А, наоборот, что ли?
[23:13.420 --> 23:19.420]  Уд, ноль и минус два, а здесь ноль и два.
[23:19.420 --> 23:27.420]  Ну и еще раз, если v1 равно единице, то реальный лямбда мин это минус 1.
[23:27.420 --> 23:31.420]  Минус 1 не бывает, ближайший четный это ноль и минус два.
[23:31.420 --> 23:37.420]  А тут плюс один, но ближайший четный это ноль и два.
[23:37.420 --> 23:43.420]  Парабол, монотонная функция, но ясно, что там все симметрично к тому же.
[23:43.420 --> 23:46.420]  Сейчас я понятно сказал или нет?
[23:47.420 --> 23:51.420]  Раскокнулись, да?
[23:51.420 --> 23:54.420]  Ну я, может быть, произнес какие-то страшные слова, ну извините,
[23:54.420 --> 23:57.420]  но сейчас я все подробно написал.
[23:57.420 --> 24:01.420]  Раскокнулись, да? Нормально?
[24:01.420 --> 24:04.420]  Не, ну все, давайте подставлять.
[24:04.420 --> 24:09.420]  То есть, если v1 равно единице, то у нас здесь стоит минус.
[24:09.420 --> 24:12.420]  Сейчас, минус или плюс? Плюс, да?
[24:12.420 --> 24:16.420]  То у нас получается, давайте где-нибудь, все-таки побольше места надо.
[24:22.420 --> 24:26.420]  Слушайте, я думаю, что все очевидно. Я и раньше думал, что все очевидно.
[24:26.420 --> 24:29.420]  Но когда я вот эти слова произнес, народ кокнулся.
[24:29.420 --> 24:32.420]  Поэтому я решил подставлять. Может зря.
[24:32.420 --> 24:35.420]  Вы правильно все говорите?
[24:35.420 --> 24:38.420]  Друзья, ну если все очевидно уже теперь, то и слава Богу.
[24:38.420 --> 24:41.420]  Просто я хотел сказать прямо тупо совершенно,
[24:41.420 --> 24:44.420]  но возьмите там v1 равно единице, тогда будет плюс.
[24:44.420 --> 24:47.420]  Подставьте туда 0 или минус 2 вместо лямбда,
[24:47.420 --> 24:50.420]  и в обоих случаях очевидно получится n квадрат.
[24:50.420 --> 24:53.420]  Ну вот, можно так сказать.
[24:53.420 --> 24:56.420]  В любом случае 0 подставить и радоваться, потому что все симметрично.
[24:56.420 --> 24:59.420]  Правильно, да.
[24:59.420 --> 25:02.420]  В обоих случаях минус 2 симметрично нулю,
[25:02.420 --> 25:05.420]  2 симметрично нулю х,
[25:05.420 --> 25:08.420]  минус 2 симметрично нулю,
[25:08.420 --> 25:11.420]  2 симметрично нулю,
[25:11.420 --> 25:14.420]  подставили сюда 0, получили n квадрат.
[25:14.420 --> 25:17.420]  Ну то есть это больше либо равно n в квадрате по-любому.
[25:17.420 --> 25:20.420]  И мы возвращаемся к старому рассуждению.
[25:20.420 --> 25:23.420]  Отсюда, конечно, следует, что существует и такое,
[25:23.420 --> 25:26.420]  что уже иt плюс лямбда
[25:26.420 --> 25:29.420]  больше либо равняется корень из n.
[25:29.420 --> 25:32.420]  Ну а дальше все делим пополам и получаем результат теоремы.
[25:33.420 --> 25:36.420]  Это мы с h плюс 4 разобрались,
[25:36.420 --> 25:39.420]  а нас интересует пополам.
[25:39.420 --> 25:42.420]  Ну пополам будет корень из n пополам.
[25:46.420 --> 25:49.420]  Нормально, ничего не нужно повторить, всем все понятно.
[25:49.420 --> 25:52.420]  Я не хочу занудствовать, я хочу, чтобы было интересно
[25:52.420 --> 25:55.420]  в темпе, но если вдруг непонятно,
[25:55.420 --> 25:58.420]  я с удовольствием объясню.
[25:58.420 --> 26:01.420]  Так.
[26:01.420 --> 26:04.420]  Теперь про кодирование.
[26:04.420 --> 26:07.420]  Очень так поверхностно, но все-таки кое-что расскажу.
[26:31.420 --> 26:34.420]  Так, чуть-чуть про теорию кодирования
[26:34.420 --> 26:37.420]  и где здесь матрица Адамара.
[26:46.420 --> 26:49.420]  Ну, друзья, смотрите, я, конечно, в этом месте обожаю
[26:49.420 --> 26:53.420]  рассказывать такую анекдотическую, конечно, формулировку задачи.
[26:53.420 --> 26:56.420]  Не анекдот ни в коем случае, но веселую формулировку
[26:56.420 --> 26:59.420]  я не буду рассказывать.
[26:59.420 --> 27:02.420]  Я хочу рассказать, конечно, очень, но веселую формулировку
[27:02.420 --> 27:05.420]  в духе того, как я рассказывал про пьяниц,
[27:05.420 --> 27:08.420]  которые взвешивают водку там и еще чего-то.
[27:08.420 --> 27:11.420]  Вот здесь тоже есть интерпретация с пьяницами.
[27:11.420 --> 27:14.420]  И некоторые из вас наверняка слышали.
[27:14.420 --> 27:17.420]  Потому что я очень люблю это рассказывать,
[27:17.420 --> 27:20.420]  и школьникам, конечно, тоже рассказываю.
[27:20.420 --> 27:23.420]  Значит, смотрите, я не буду писать на доске,
[27:23.420 --> 27:26.420]  и вы можете не писать, но если осознаете связь,
[27:26.420 --> 27:29.420]  я не сняюсь это на камеру снять.
[27:29.420 --> 27:32.420]  Это снято столько раз и лежит в интернете в таком количестве,
[27:32.420 --> 27:35.420]  что мне уже стесняться нелепо.
[27:35.420 --> 27:38.420]  Значит, история такая, есть N пьяниц.
[27:38.420 --> 27:41.420]  N пьяниц.
[27:41.420 --> 27:44.420]  Могу написать пьяниц.
[27:44.420 --> 27:47.420]  Так, и каждый вечер они соображают на троих.
[27:47.420 --> 27:50.420]  Знаете, что пьяницы иногда соображают на троих.
[27:50.420 --> 27:53.420]  Ровно на троих.
[27:53.420 --> 27:56.420]  Каждый вечер они идут в кабак втроем.
[27:56.420 --> 27:59.420]  Какие-то трое из вот этих N напиваются
[27:59.420 --> 28:02.420]  и бьют друг другу морду.
[28:02.420 --> 28:05.420]  Результатом служит тот факт,
[28:05.420 --> 28:08.420]  что никакие двое из этих бывших друзей
[28:08.420 --> 28:11.420]  больше в кабак вместе не пойдут.
[28:14.420 --> 28:17.420]  Но у каждого душа алчат,
[28:17.420 --> 28:20.420]  поэтому в принципе каждый пойти может.
[28:20.420 --> 28:23.420]  Главное, чтобы не с тем, с кем уже подрался.
[28:23.420 --> 28:26.420]  И так каждый вечер.
[28:26.420 --> 28:29.420]  Спрашивается, как долго может продолжаться это безобразие.
[28:29.420 --> 28:32.420]  Не забывайте, что пьяниц N.
[28:32.420 --> 28:35.420]  То есть, как можно организовать им
[28:35.420 --> 28:38.420]  такие визиты ежевечерние,
[28:38.420 --> 28:41.420]  чтобы вечеров было как можно больше?
[28:41.420 --> 28:44.420]  Ну и все.
[28:44.420 --> 28:47.420]  Представьте себе, что N равно 9,
[28:47.420 --> 28:50.420]  чтобы было понятно.
[28:50.420 --> 28:53.420]  В первый день можно отправить туда 1, 2, 3.
[28:53.420 --> 28:56.420]  Потом во второй день можно отправить 4, 5, 6.
[28:56.420 --> 28:59.420]  Видите, они вообще не пересекаются.
[28:59.420 --> 29:02.420]  Все хорошо. Новая партия свежая поступила.
[29:02.420 --> 29:05.420]  Потом 7, 8, 9.
[29:05.420 --> 29:08.420]  Но на этом процесс не останавливается,
[29:08.420 --> 29:11.420]  потому что каждый побитый может пойти в кабак,
[29:11.420 --> 29:14.420]  лишь бы не с другим, кому он бил морду.
[29:14.420 --> 29:17.420]  Может пойти с 3, но вполне может пойти с 4.
[29:17.420 --> 29:20.420]  И тогда у нас четвертый вечер
[29:20.420 --> 29:23.420]  составляют товарищи с номерами 1, 4, 7.
[29:23.420 --> 29:26.420]  Надеюсь, вы понимаете, как действовать дальше.
[29:26.420 --> 29:29.420]  Видно, что этот процесс, вообще говоря, потенциально долгий.
[29:29.420 --> 29:32.420]  И может быть зависит от того,
[29:32.420 --> 29:35.420]  как именно мы строим последовательно эти тройки.
[29:35.420 --> 29:38.420]  Но здесь мы их взяли не пересекающиеся.
[29:38.420 --> 29:41.420]  А может, надо было их сразу как-то пересекать.
[29:41.420 --> 29:44.420]  Я понимаю, что задача комбинаторна.
[29:44.420 --> 29:47.420]  Звучит следующим образом.
[29:47.420 --> 29:50.420]  Просто найти максимальное количество трех-элементных
[29:50.420 --> 29:53.420]  под множество n-элементного множества,
[29:53.420 --> 29:56.420]  при условии, что каждые два из них пересекаются
[29:56.420 --> 29:59.420]  не больше, чем по одному элементу.
[29:59.420 --> 30:02.420]  Это я могу написать явно.
[30:02.420 --> 30:05.420]  Максимальное число
[30:05.420 --> 30:08.420]  трех-элементных
[30:08.420 --> 30:11.420]  под множество
[30:12.420 --> 30:15.420]  n-элементного множества
[30:20.420 --> 30:23.420]  любые или каждые два из которых,
[30:23.420 --> 30:26.420]  наверное, лучше каждые два из которых,
[30:26.420 --> 30:33.420]  имеют не больше одного общего элемента.
[30:38.420 --> 30:41.420]  Я утверждаю, что эта задача
[30:41.420 --> 30:46.420]  является задачей о кодах исправляющих ошибки.
[30:46.420 --> 30:49.420]  Стандартный каламбур, что это задача
[30:49.420 --> 30:52.420]  не теории кодирования от пьянства,
[30:52.420 --> 30:55.420]  а именно про коды исправляющие ошибки.
[30:55.420 --> 31:00.420]  Ну давайте про коды исправляющие ошибки.
[31:00.420 --> 31:03.420]  Вот у нас есть
[31:03.420 --> 31:06.420]  источник,
[31:07.420 --> 31:10.420]  а есть приемник.
[31:12.420 --> 31:15.420]  А вот эта стрелочка это канал связи,
[31:15.420 --> 31:18.420]  по которому передаются сообщения.
[31:18.420 --> 31:21.420]  Там есть масса разных вариантов того,
[31:21.420 --> 31:24.420]  что может случиться на канале,
[31:24.420 --> 31:27.420]  но давайте считать так.
[31:27.420 --> 31:30.420]  Сообщение состоит из слов.
[31:30.420 --> 31:33.420]  Ну, фактически слов, например, русского языка,
[31:33.420 --> 31:36.420]  закодирован. То есть было слово мама,
[31:36.420 --> 31:39.420]  например, а мы его закодировали,
[31:39.420 --> 31:42.420]  видите, что-нибудь вот такого.
[31:46.420 --> 31:49.420]  Всего N позиций,
[31:49.420 --> 31:52.420]  три из них единичные, остальные нулевые,
[31:52.420 --> 31:55.420]  ну, например. Ну, так вот захотелось.
[31:55.420 --> 31:58.420]  Было слово папа,
[31:58.420 --> 32:01.420]  мы его закодировали вот так.
[32:01.420 --> 32:04.420]  Дальше все нули,
[32:04.420 --> 32:07.420]  и так тоже N.
[32:07.420 --> 32:10.420]  Ну и так далее.
[32:12.420 --> 32:15.420]  Так, друзья, я понятно и изъясняюсь.
[32:15.420 --> 32:18.420]  Сейчас объясню.
[32:18.420 --> 32:21.420]  Да-да-да, на самом деле вопросы правильные,
[32:21.420 --> 32:24.420]  я сейчас собираюсь все сказать.
[32:24.420 --> 32:27.420]  Когда? Значит, у нас есть словарь
[32:27.420 --> 32:30.420]  из слов, которые мы хотим научиться передавать
[32:30.420 --> 32:33.420]  по этому каналу. Мама, папа там,
[32:33.420 --> 32:36.420]  кто хотите.
[32:36.420 --> 32:39.420]  Нам, конечно, хочется, чтобы этот словарь был в итоге
[32:39.420 --> 32:42.420]  побогаче.
[32:42.420 --> 32:45.420]  Мы каждому слову сопоставляем последовательность
[32:45.420 --> 32:48.420]  из нулей единиц, но вот в рамках этого примера мы считаем,
[32:48.420 --> 32:51.420]  что единиц три, а всего позиция N штук,
[32:51.420 --> 32:54.420]  где N подлежит подбору. N мы вольны выбирать так,
[32:54.420 --> 32:57.420]  как нам захочется. А единиц всегда будет три.
[32:57.420 --> 33:00.420]  Заранее всем вообще людям на планете,
[33:00.420 --> 33:03.420]  кто желает об этом быть в курсе,
[33:03.420 --> 33:06.420]  известны и вот эти слова,
[33:06.420 --> 33:09.420]  и соответствующие кодовые слова.
[33:09.420 --> 33:12.420]  Всем все известно, это не шифрование.
[33:12.420 --> 33:15.420]  То есть мы не пытаемся скрыть информацию
[33:15.420 --> 33:18.420]  от какого-нибудь злонравного товарища, который собирается
[33:18.420 --> 33:21.420]  до нее добраться. Мы передаем совершенно открытую
[33:21.420 --> 33:24.420]  информацию по каналу связи, и мы просто хотим,
[33:24.420 --> 33:27.420]  чтобы при наличии шумов на этом канале
[33:27.420 --> 33:30.420]  тот товарищ, который сидит на приемнике,
[33:30.420 --> 33:33.420]  смог восстановить информацию.
[33:33.420 --> 33:36.420]  Если кто-то еще проникнет к этому источнику,
[33:36.420 --> 33:39.420]  ну, к этому каналу связи, ну, пожалуйста, пусть он тоже
[33:39.420 --> 33:42.420]  восстановит информацию. Нам не жалко.
[33:42.420 --> 33:45.420]  Вот именно это называется кодами, исправляющими ошибки,
[33:45.420 --> 33:48.420]  то есть шумы на канале, а не какое-то шифрование,
[33:48.420 --> 33:51.420]  то не догадался, враг не догадался.
[33:51.420 --> 33:54.420]  Вот, значит,
[33:54.420 --> 33:57.420]  вопрос такой. Представим себе,
[33:57.420 --> 34:00.420]  что мы передаем слово «мама»,
[34:00.420 --> 34:03.420]  передаем слово «папа», не важно какое слово,
[34:03.420 --> 34:06.420]  в общем, нашу последность из нуле единиц.
[34:06.420 --> 34:09.420]  И мы знаем откуда-то заранее,
[34:09.420 --> 34:13.420]  что канал может исказить не более одного символа
[34:13.420 --> 34:16.420]  в каждом из передаваемых слов.
[34:16.420 --> 34:19.420]  То есть если мы передавали «мама»,
[34:19.420 --> 34:22.420]  лишь один нолик может превратиться в единицу,
[34:22.420 --> 34:25.420]  или лишь одна единица может превратиться в ноль.
[34:25.420 --> 34:28.420]  Если ноль превратился в единицу,
[34:28.420 --> 34:31.420]  все, уже никакая единица в ноль не превратится.
[34:31.420 --> 34:34.420]  Мы знаем, что только одна ошибка.
[34:34.420 --> 34:37.420]  И ошибка это состоит в замене единицы на ноль
[34:37.420 --> 34:40.420]  или замене нуля на единицу,
[34:40.420 --> 34:43.420]  то есть превращение знаков в противоположные,
[34:43.420 --> 34:46.420]  в два, так скажем.
[34:46.420 --> 34:49.420]  Ну такой очень хороший канал.
[34:49.420 --> 34:52.420]  Всего одну ошибку допускает на каждом слове.
[34:52.420 --> 34:55.420]  А может быть и не одно.
[34:55.420 --> 34:58.420]  Вот смотрите, если бы мы передавали изначальная «мама»
[34:58.420 --> 35:01.420]  и изначальная «папа» каким-то образом,
[35:01.420 --> 35:04.420]  не нолики и единички, а сами вот эти буквы русского алфавита,
[35:04.420 --> 35:07.420]  то даже при одной ошибке
[35:07.420 --> 35:10.420]  мы могли бы не суметь восстановить информацию.
[35:10.420 --> 35:13.420]  Потому что «мама» может превратиться в «мапу»,
[35:13.420 --> 35:16.420]  и «папа» может превратиться в «мапу».
[35:16.420 --> 35:19.420]  У «мамы» для этого должна вот эта буква исказиться, превратиться в «п»,
[35:19.420 --> 35:22.420]  а у «папы» наоборот вот эта.
[35:22.420 --> 35:25.420]  И все, получил приемник «мапу», даже при одной ошибке
[35:25.420 --> 35:28.420]  он знать не знает, это «мама» или «папа».
[35:28.420 --> 35:31.420]  Я понятно изъясняюсь?
[35:31.420 --> 35:34.420]  А вот если мы передаем две таких последовательности,
[35:34.420 --> 35:37.420]  как я нарисовал, то, по-моему, очевидно, что все хорошо.
[35:37.420 --> 35:40.420]  Очевидно, что все хорошо.
[35:40.420 --> 35:43.420]  Нет.
[35:43.420 --> 35:46.420]  Тут же пересечение только по одному вот этому элементу.
[35:46.420 --> 35:49.420]  Мы не можем так исказить,
[35:49.420 --> 35:52.420]  делая только одно искажение тут и одно искажение тут,
[35:52.420 --> 35:55.420]  чтобы слова склеились в «мапу», условно.
[35:55.420 --> 35:58.420]  Не можем?
[35:58.420 --> 36:01.420]  Или считается, что можем?
[36:01.420 --> 36:04.420]  Но не можем, конечно.
[36:04.420 --> 36:07.420]  Если я геометрически нарисую максимально наглядно,
[36:07.420 --> 36:10.420]  тогда будет совсем понятно.
[36:10.420 --> 36:13.420]  Слушайте, ну, по-моему, вообще понятно, какая связь между пьяницами
[36:13.420 --> 36:16.420]  и вот этой задачей про построение кодов, исправляющих ошибки.
[36:16.420 --> 36:19.420]  Почему не случилось искажения?
[36:19.420 --> 36:22.420]  Ой, слепание.
[36:22.420 --> 36:25.420]  Почему они не слиплись?
[36:25.420 --> 36:28.420]  Потому что пересечение вот этих троек позиций
[36:28.420 --> 36:31.420]  всего лишь по одному элементу.
[36:32.420 --> 36:35.420]  Вот если бы они пересекались по двум элементам вот так,
[36:35.420 --> 36:38.420]  0, 1, 1, дальше все нули,
[36:38.420 --> 36:41.420]  а «папа» был бы вот таким,
[36:41.420 --> 36:44.420]  это «мама» и «папа»,
[36:44.420 --> 36:47.420]  то прекрасно, здесь ноль превращается в единицу,
[36:47.420 --> 36:50.420]  здесь ноль превращается в единицу, все одно и то же.
[36:50.420 --> 36:53.420]  То есть такие слова в качестве кодовых брать нелепо,
[36:53.420 --> 36:56.420]  потому что они впадают в ту же дурь,
[36:56.420 --> 36:59.420]  в которой находились исходные слова «мама».
[36:59.420 --> 37:02.420]  А если взять вот такие кодовые слова, то уже хорошо,
[37:02.420 --> 37:05.420]  потому что они достаточно далеко в каком-то смысле
[37:05.420 --> 37:08.420]  отстоят друг от друга.
[37:08.420 --> 37:11.420]  Это прямо правильная терминология,
[37:11.420 --> 37:14.420]  сейчас я ее буду писать.
[37:14.420 --> 37:17.420]  Ну то есть какая возникает задача?
[37:17.420 --> 37:20.420]  Нам же хочется передавать как можно более разумные сообщения,
[37:20.420 --> 37:23.420]  как можно больше словарь заранее зафиксировать.
[37:23.420 --> 37:26.420]  Ну вот ровно вот это,
[37:26.420 --> 37:29.420]  максимизации количества троек,
[37:29.420 --> 37:32.420]  которые попарно пересекаются не больше, чем по одному элементу.
[37:36.420 --> 37:39.420]  Да, при том, что мы примкнули, конечно, именно к такому способу,
[37:39.420 --> 37:42.420]  поэтому я сейчас это вложу в более общий контекст,
[37:42.420 --> 37:45.420]  но сначала нарисую картинку.
[37:45.420 --> 37:48.420]  Конечно, кодировать можно по-разному,
[37:48.420 --> 37:51.420]  я говорю, что это прямо самая вершинка айсберга,
[37:51.420 --> 37:54.420]  но с этого начинается теория кодирования в каком-то смысле.
[37:54.420 --> 37:57.420]  А дальше там масса, конечно, есть разных методов,
[37:57.420 --> 38:00.420]  идей, подходов, задач и так далее.
[38:07.420 --> 38:10.420]  Значит, картинку я хотел нарисовать вот такую.
[38:10.420 --> 38:13.420]  Я могу взять вот это слово «мама», например,
[38:13.420 --> 38:16.420]  и интерпретировать его как точку в инмерном пространстве,
[38:16.420 --> 38:19.420]  ну или даже просто как такую точку,
[38:19.420 --> 38:22.420]  в абстрактном таком пространстве, елки-палки,
[38:22.420 --> 38:25.420]  картинку не дали нарисовать.
[38:25.420 --> 38:28.420]  Ну чего, устраиваем перерыв?
[38:28.420 --> 38:31.420]  А то я долго может ее рисовать буду.
[38:31.420 --> 38:34.420]  Давайте перерыв устроим, потом будет картинка.
[38:34.420 --> 38:37.420]  Так, друзья, давайте продолжать. Все.
[38:37.420 --> 38:40.420]  Смотрите, я собирался нарисовать шарики.
[38:40.420 --> 38:43.420]  Шарики нарисовать.
[38:43.420 --> 38:46.420]  Ну, серьезно, смотрите, вот слово «мама»,
[38:46.420 --> 38:49.420]  это нарисовано такой последовательностью из нулей единиц.
[38:49.420 --> 38:58.420]  Давайте введем вообще на словах такое расстояние.
[38:58.420 --> 39:03.420]  Называется «расстояние Хэйминга».
[39:09.420 --> 39:12.420]  Кого? Нет, ну бывает Элевенштейна.
[39:12.420 --> 39:15.420]  Да, я хочу Хэйминга.
[39:15.420 --> 39:18.420]  Там их много разных бывает.
[39:18.420 --> 39:21.420]  Не, ну на 0.1 это одно и то же, конечно,
[39:21.420 --> 39:24.420]  а в общем случае это разные вещи.
[39:24.420 --> 39:27.420]  Расстояние Хэйминга – это очень простая вещь.
[39:27.420 --> 39:30.420]  Между двумя последовательностями из нулей единиц
[39:30.420 --> 39:33.420]  расстояние Хэйминга – это просто количество
[39:33.420 --> 39:36.420]  несовпадающих координат.
[39:36.420 --> 39:39.420]  Количество несовпадающих координат.
[39:39.420 --> 39:42.420]  Ну, то есть вот между нашей нынешней мамой
[39:42.420 --> 39:45.420]  и нынешним папой, закодированными от пьянств,
[39:45.420 --> 39:50.420]  расстояние Хэйминга составляет раз, два, три, четыре.
[39:50.420 --> 39:53.420]  Так, друзья, понятно говорю?
[39:53.420 --> 39:56.420]  Но это фактически эвклидовое расстояние,
[39:56.420 --> 39:59.420]  просто возведенное в квадрат.
[39:59.420 --> 40:02.420]  Можно так сказать.
[40:02.420 --> 40:05.420]  Знаете, что такое эвклидовое расстояние в отмерном пространстве?
[40:05.420 --> 40:08.420]  Ну, вот квадрат, его это Хэйминговое расстояние
[40:08.420 --> 40:11.420]  для 0.1 и 0.1.
[40:11.420 --> 40:14.420]  Для 0.1 векторов все очень просто.
[40:14.420 --> 40:17.420]  Ну так вот, я могу нарисовать такой шарик.
[40:17.420 --> 40:20.420]  Что такое шарик?
[40:20.420 --> 40:23.420]  Это множество тех кодовых последовательностей,
[40:23.420 --> 40:26.420]  тех слов из нулей единиц,
[40:26.420 --> 40:29.420]  которые в Хэйминговой метрике,
[40:29.420 --> 40:32.420]  по Хэйминговому расстоянию,
[40:32.420 --> 40:35.420]  отстоят от этого центра не больше, чем на какую-то величину.
[40:35.420 --> 40:38.420]  Вот здесь вот D.
[40:38.420 --> 40:41.420]  Радиус этого шара,
[40:41.420 --> 40:44.420]  это максимальное расстояние Хэйминга
[40:44.420 --> 40:47.420]  от вот этого центра.
[40:47.420 --> 40:50.420]  Слушайте, очень простой вопрос.
[40:50.420 --> 40:53.420]  А сколько слов вот в этом шаре?
[40:53.420 --> 40:56.420]  Это же шар комбинаторный.
[40:56.420 --> 40:59.420]  Он определен на последовательностях из нулей единиц.
[40:59.420 --> 41:02.420]  В нем конечное множество точек.
[41:02.420 --> 41:05.420]  То есть, это условная картинка с шаром.
[41:11.420 --> 41:14.420]  Конечно, да. То есть, суммарно, здесь просто вот столько точек.
[41:14.420 --> 41:17.420]  C и Z по нулю и так далее.
[41:17.420 --> 41:20.420]  C и Z по D. C и Z по D лежат уже на границе,
[41:20.420 --> 41:23.420]  на сфере, которая как бы условно ограничивает этот шар.
[41:26.420 --> 41:29.420]  Есть у нас слово папа.
[41:29.420 --> 41:32.420]  Если мы вот здесь вот его нарисуем.
[41:32.420 --> 41:35.420]  1, 1, 0, 0.
[41:35.420 --> 41:38.420]  1 дальше все нули.
[41:38.420 --> 41:41.420]  И тоже нарисуем такой шарик.
[41:41.420 --> 41:44.420]  Ну вот если это D, к чему равняется?
[41:44.420 --> 41:47.420]  Если это D равняется единице,
[41:47.420 --> 41:50.420]  количество ошибок,
[41:50.420 --> 41:53.420]  и здесь тоже D равняется единице,
[41:53.420 --> 41:56.420]  то эти шарики просто не пересекаются.
[41:56.420 --> 41:59.420]  Ну или по-другому можно сказать, что
[41:59.420 --> 42:02.420]  расстояние между этими кодовыми словами не меньше 2.
[42:02.420 --> 42:05.420]  И только тогда, когда шарики не пересекаются,
[42:05.420 --> 42:08.420]  им можно исправить одну ошибку, соответственно.
[42:08.420 --> 42:11.420]  Больше двух строго.
[42:11.420 --> 42:14.420]  Иначе они границами пересекутся.
[42:14.420 --> 42:17.420]  Больше двух строго.
[42:17.420 --> 42:20.420]  Оговорился, виноват.
[42:20.420 --> 42:23.420]  Ну то есть, такая вот задача получается.
[42:23.420 --> 42:26.420]  В этих терминах знаете, как в коробку упаковывают апельсины.
[42:26.420 --> 42:29.420]  Вот здесь тоже надо
[42:29.420 --> 42:32.420]  так упаковать эти шары, чтобы они не пересекались,
[42:32.420 --> 42:35.420]  но поплотнее упаковывали все множество 0,1 в n-ной степени.
[42:35.420 --> 42:38.420]  Ну или C и Zn по 3, если мы только 3 единицы допускаем.
[42:38.420 --> 42:41.420]  Такая типичная задача теории кодирования,
[42:41.420 --> 42:44.420]  это задача упаковки таких вот
[42:44.420 --> 42:47.420]  комбинаторных шаров заданного радиуса
[42:47.420 --> 42:50.420]  в хеммингово пространство, то есть в 0,1
[42:50.420 --> 42:53.420]  дискретное множество в n-ной степени,
[42:53.420 --> 42:56.420]  в булиф клуб там по-другому, как угодно.
[42:56.420 --> 42:59.420]  Вот в этой 0,1 в n-ной степени запихать
[42:59.420 --> 43:02.420]  как можно больше шаров данного радиуса,
[43:02.420 --> 43:05.420]  так чтобы они попарно не пересекались.
[43:05.420 --> 43:08.420]  Тогда центры могут служить кодовыми словами,
[43:08.420 --> 43:11.420]  и вы, соответственно, большой исходный словарь сумеете докодировать.
[43:11.420 --> 43:14.420]  Так, я понятно объяснил.
[43:14.420 --> 43:17.420]  Успели записать? Все нормально записывается?
[43:17.420 --> 43:20.420]  Достаточно информации на доске,
[43:20.420 --> 43:23.420]  чтобы это все тебе зафиксировать?
[43:23.420 --> 43:26.420]  Ну хорошо. Ну давайте теперь
[43:26.420 --> 43:29.420]  общее определение дадим некоторое, чтобы увязать это
[43:29.420 --> 43:32.420]  одним из возможных вариантов с матрицами Адамара.
[43:32.420 --> 43:35.420]  Это не единственная, конечно, увязка, там их масса,
[43:35.420 --> 43:38.420]  но вот одну из них я сейчас расскажу.
[43:47.420 --> 44:15.420]  Давайте вот так вот обозначим n, m, d код.
[44:15.420 --> 44:26.420]  Это код, которым m слов,
[44:26.420 --> 44:39.420]  в каждом слове n нулей и единиц.
[44:39.420 --> 44:44.420]  Тут мы никак не фиксируем количество единиц как раз,
[44:44.420 --> 44:47.420]  то есть не увязываемся стройками пьяниц,
[44:47.420 --> 44:50.420]  может быть, сколько угодно, но суммарно n,
[44:50.420 --> 44:53.420]  длина каждого вектора, которое означает слово,
[44:53.420 --> 44:56.420]  это n нулей и единиц,
[44:56.420 --> 45:02.420]  и d это минимальное
[45:02.420 --> 45:13.420]  хемминговое расстояние между словами.
[45:13.420 --> 45:22.420]  Ну то есть такой код может исправить
[45:22.420 --> 45:26.420]  кто-то типа не более, чем d пополам минус одну ошибку.
[45:26.420 --> 45:33.420]  Значит, n, m, d код – это любой набор
[45:33.420 --> 45:36.420]  векторов из нулей и единиц,
[45:36.420 --> 45:39.420]  в каждом векторе n нулей или единиц,
[45:39.420 --> 45:42.420]  всего векторов должно быть m штук,
[45:42.420 --> 45:48.420]  и d – это минимальное хемминговое расстояние между векторами.
[45:48.420 --> 45:51.420]  Да, здесь количество единиц не фиксируем.
[45:51.420 --> 45:58.420]  Можно его дополнительно зафиксировать, но мне сейчас это не потребуется.
[45:58.420 --> 46:01.420]  Ну то было просто для затравки, чтобы было понятно,
[46:01.420 --> 46:07.420]  в чем задача состоит, но можно сразу вот про это говорить.
[46:07.420 --> 46:10.420]  Так, понятно, что такой код, если он существует
[46:10.420 --> 46:15.420]  при данных параметрах, то он исправляет не больше, чем d пополам без единицы ошибок.
[46:15.420 --> 46:18.420]  Вот мы специально это все рисовали.
[46:18.420 --> 46:23.420]  Если расстояние не меньше, чем d, значит, радиусы вот этих вот шаров,
[46:23.420 --> 46:27.420]  если они не пересекаются, должны не превосходить d пополам без единицы.
[46:27.420 --> 46:31.420]  Если они равны d пополам, тогда они, как вот я оговорился,
[46:31.420 --> 46:33.420]  они все-таки коснутся границами.
[46:33.420 --> 46:37.420]  Ну, не больше, чем d пополам минус один ошибок мы исправим.
[46:44.420 --> 46:47.420]  Да, d может быть нечетным, но я держал в голове,
[46:47.420 --> 46:50.420]  что пусть d четный, я согласен.
[46:50.420 --> 46:54.420]  Да, если более аккуратно говорить, то так.
[46:58.420 --> 47:01.420]  Но смысл понятен.
[47:01.420 --> 47:08.420]  То есть, если мы зафиксировали n и d, то, конечно, задача состоит в максимизации величины m.
[47:08.420 --> 47:14.420]  Если n и d зафиксированы, то нас интересует n-md код из как можно большим m.
[47:14.420 --> 47:20.420]  Если зафиксировано только d, то мы можем, например, выбирать такие n, которые нам удобны,
[47:20.420 --> 47:23.420]  чтобы при этих удобных n максимизировать, соответственно, m.
[47:23.420 --> 47:29.420]  Но в конечном счете нас интересует, как можно больше кодовых слов научиться передавать,
[47:29.420 --> 47:33.420]  исправляя, соответственно, вот это количество ошибок.
[47:33.420 --> 47:44.420]  Значит, в теории кодирования есть огромное количество верхних оценок для вот этого m в зависимости от n и d.
[47:44.420 --> 47:48.420]  Есть граница Хэминга, там есть граница Лайца-Басалыга.
[47:48.420 --> 47:53.420]  Не буду я сейчас в это вообще вдаваться, это огромная наука, я вам ее сейчас не рассказываю.
[47:53.420 --> 47:58.420]  Я немножко ее рассказываю, чтобы привязать к матрице Мадамара как к абсолютно классическим объектам.
[47:58.420 --> 48:02.420]  Так вот, есть такая граница Плоткина. Одна из.
[48:04.420 --> 48:07.420]  Сейчас я ее объясню. Она очень проста.
[48:13.420 --> 48:17.420]  Верхняя граница для величины m при заданных n и d.
[48:18.420 --> 48:20.420]  Говорится так, пусть...
[48:28.420 --> 48:33.420]  2d больше чем n. То есть мы хотим исправить вообще очень много ошибок.
[48:33.420 --> 48:38.420]  2d больше чем n. Представляете? Изрядное количество ошибок.
[48:38.420 --> 48:41.420]  Пусть 2d больше чем n.
[48:41.420 --> 48:45.420]  Тогда, естественно, мы слишком много слов не сможем передать.
[48:45.420 --> 48:54.420]  Вот утверждается, что m не превосходит целой части от 2d на 2d-n.
[48:58.420 --> 49:03.420]  Но это мало, да. Ну понятно, мы хотим исправить безумно много ошибок.
[49:03.420 --> 49:07.420]  Вот если их безумно много, тогда можно сказать такую простую границу. Сейчас я ее докажу.
[49:12.420 --> 49:14.420]  Доказательства.
[49:17.420 --> 49:25.420]  Ну, давайте пусть a1 и так далее, a с индексом m, это какие-то кодовые слова.
[49:25.420 --> 49:28.420]  Ну, то есть последовательности из нулей и единиц.
[49:28.420 --> 49:38.420]  Кодовые слова, то есть последовательности из нулей и единиц длины n.
[49:43.420 --> 49:47.420]  Ну, которые исправляют d ошибок. Ну, не d, понятно.
[49:48.420 --> 49:52.420]  Которые соответствуют нашему nmd-коду. Ну, короче, пусть это nmd-код.
[49:52.420 --> 49:58.420]  Давайте нарисуем такую матрицу опять. Ну, это не матрица Адамара будет, просто нарисуем пока такую матрицу.
[49:58.420 --> 50:08.420]  Вот так a1, a2, am. По строчкам расположим вот эти кодовые слова, расположим по строчкам матрицы.
[50:08.420 --> 50:17.420]  То есть это будет матрица размера n на m. У нее m-строчек и n столбцов.
[50:17.420 --> 50:22.420]  В каждом кодовом слове n символов. Такая матрица из нулей и единиц.
[50:22.420 --> 50:27.420]  Давайте организуем очень простой двойной счет.
[50:27.420 --> 50:41.420]  А именно просуммируем по всем, вот так вот, i меньше, чем j, меньше, чем, не n, конечно, а m.
[50:41.420 --> 50:57.420]  И по всем k от единицы до n, индикаторы того, что аит kt, да, правильно, не равняется а житому k тому.
[50:57.420 --> 51:07.420]  Ну, я, наверное, не сказал. Давайте считать, что элементы этой матрицы, в свою очередь, обозначаются как аиты и житы, конечно.
[51:07.420 --> 51:21.420]  Матрица, составленная из строчек, которые являются кодовыми словами, имеет элементы аит и житы, и меняется от единицы до м, а жи меняется от единицы до н.
[51:21.420 --> 51:27.420]  Да, так вот. Вроде правильно.
[51:27.420 --> 51:36.420]  Да, просто рассматриваем. Ну, оно очень понятно, для чего рассматривать. Сейчас мы поймем.
[51:36.420 --> 51:43.420]  Просто пока вот принимаете, да, ой, какой ужас на нас спустился с неба. Двойная сумма. Просто рассматриваем такое выражение.
[51:43.420 --> 51:47.420]  Все очень и очень просто. Значит, во-первых, не все могут понимать вот это обозначение.
[51:47.420 --> 51:57.420]  Что такое индикатор чего-то, написанного в фигурных скобках?
[51:57.420 --> 52:06.420]  Ну, я, как всегда, перепутал порядок, как пишут в алгебре. Ну, извините. Я просто перепутал.
[52:07.420 --> 52:16.420]  Так, теперь все-таки смотрим сюда. Что такое индикатор? Это единица, если выполнена, и ноль, если не выполнена.
[52:20.420 --> 52:27.420]  Вот в такой записи совершенно верно. Это сумма всех попарных расстояний, просто между этими кодовыми словами.
[52:27.420 --> 52:36.420]  Потому что если мы зафиксировали И и Ж во внешнем суммировании, это значит мы зафиксировали кодовое слово аитое и кодовое слово ожитое.
[52:36.420 --> 52:43.420]  И когда мы суммируем пока от единицы до н вот эти не совпадения, мы просто считаем хемминговое расстояние между этими словами.
[52:46.420 --> 52:54.420]  Вот это вот все. Это хемминговое расстояние между словом аитое и словом ожитое. Понятно?
[52:55.420 --> 53:06.420]  Вот это хемминговое расстояние от аитое там до ожитое.
[53:10.420 --> 53:18.420]  Ну, у нас оно по условию не меньше, чем D. Хемминговое расстояние не меньше, чем D, потому что D это минимальное расстояние в коде.
[53:18.420 --> 53:31.420]  Значит, мы получаем не меньше, чем m на m-1 пополам на D. Вроде получаем.
[53:31.420 --> 53:36.420]  Ну, каждая внутренняя сумма не меньше, чем D, потому что это хемминговое расстояние.
[53:36.420 --> 53:42.420]  А складывается C из m по два величины, но это m на m-1 пополам. Каждая не меньше, чем D.
[53:42.420 --> 53:50.420]  Ну, теперь давайте переставим порядки суммирования. Пойдем справа налево. Шарик-то сотрем.
[54:01.420 --> 54:11.420]  Наоборот напишем. Сумма пока от 1 до m. То есть сначала будем фиксировать столбец, а потом уже будем суммировать по строчкам.
[54:12.420 --> 54:24.420]  И меньше, чем j меньше, чем m, а нет индикаторов того, что аитое катае не равно ожитому катому.
[54:24.420 --> 54:36.420]  Так, то есть вот мы еще раз эту матрицу нарисуем. Мы фиксируем катый столбец. Вот там какие-то нолики, единички, единички нолики.
[54:36.420 --> 54:48.420]  Вот мы зафиксировали катый столбец. Дорогие друзья, мы знаем сколько в нем единиц, а сколько нулей? Вопрос на засыпку.
[54:48.420 --> 55:02.420]  Нет, конечно. Мы знаем сколько единиц в строчке, может быть, и то не знаем, потому что мало ли, мы же не писали равновесный код, как в задачке про тройки.
[55:02.420 --> 55:08.420]  Мы ничего не знаем. Мы не знаем ни сколько единиц в строчке, ни сколько единиц в столбце.
[55:08.420 --> 55:16.420]  Весело. Ну хорошо, давайте обозначим буквы x число единиц в столбце.
[55:16.420 --> 55:18.420]  А как вам это?
[55:18.420 --> 55:30.420]  Нет, ну вы можете сказать x катае, потому что x не одинаковый для всех, конечно. Но я зафиксировал k, давайте считать, и x это число единиц вот именно в этом катом столбце.
[55:30.420 --> 55:36.420]  Ну чему равна тогда вот эта вот внутренняя сумма?
[55:36.420 --> 55:42.420]  Гениально, да. Вот эта внутренняя сумма равняется x на m минус x, правильно, совершенно.
[55:42.420 --> 55:46.420]  Но это сколько есть пар? 0,1.
[55:46.420 --> 55:50.420]  Не совпадающих элементов. x на m минус x.
[55:50.420 --> 56:00.420]  Опять пользуемся сакральным знанием, который мы сегодня применяли, что минимум парабола достигается в точке минус b поделить на 2a, или там, где производная равна нулю.
[56:00.420 --> 56:10.420]  Ну короче, очевидно, что это больше либо равняется m квадрата на 4, минимум достигается, когда x равно m пополам. Это абсолютно очевидно.
[56:10.420 --> 56:16.420]  Ой, да. Почему минимум-то? Максимум, да, она с минусом, все, глупости опять сказал.
[56:16.420 --> 56:20.420]  Да, конечно, у нее вот так теперь, вот так теперь все направлено, да.
[56:20.420 --> 56:25.420]  Минус x квадрат меньше либо равняется, конечно, m в квадрате на 4, извините.
[56:25.420 --> 56:29.420]  Зарапортовал. Так радовался, так радовался, что зарапортовался.
[56:29.420 --> 56:36.420]  Ну меньше либо равняется. Смотрите, какая прекрасная оценка. Она от k не зависит, а от x не зависит.
[56:36.420 --> 56:46.420]  Чудное дело, получаем не больше, чем n раз m квадрат на 4. Все, у нас все готово.
[56:46.420 --> 56:55.420]  Значит, мы получили, что m на m минус 1, на m минус 1, куда пишешь 2?
[56:56.420 --> 57:07.420]  Диверсия какая-то просто. На d меньше либо равно, да, n на m в квадрате на 4.
[57:07.420 --> 57:15.420]  Так, шлеп, шлеп. Что-то такое получилось-то.
[57:15.420 --> 57:22.420]  Ну ладно, неприятно. На m надо как-то выразить. А, еще можно сделать один шлеп.
[57:23.420 --> 57:34.420]  Так, ну ладно. Значит, у нас получается 2 m минус 1 на d меньше либо равняется n на m.
[57:34.420 --> 57:38.420]  Следите внимательно, я что-то иногда лажаю. Но вроде правильно.
[57:38.420 --> 57:42.420]  Ну что, надо m вынести за скобку теперь как-нибудь.
[57:42.420 --> 57:44.420]  М...
[57:46.420 --> 57:51.420]  В какой стороны его лучше написать? Наверное, вот с этой, да?
[57:55.420 --> 58:01.420]  Во-во-во, да, я хочу 2d написать, да. 2d минус n, правильно?
[58:01.420 --> 58:06.420]  Да, m на 2d минус n меньше либо равняется 2d.
[58:06.420 --> 58:09.420]  Опа! И вот, по-моему, все получилось.
[58:09.420 --> 58:15.420]  m не превосходит 2d поделить на 2d минус n, потому что 2d больше чем n и делить можно.
[58:15.420 --> 58:19.420]  Ну, целая часть, потому что m это целое число.
[58:21.420 --> 58:25.420]  Успех, да. Не налажал.
[58:25.420 --> 58:27.420]  Так.
[58:34.420 --> 58:36.420]  Вот.
[58:36.420 --> 58:38.420]  Теперь смотрите.
[58:38.420 --> 58:41.420]  Ну, хорошо бы понять, это вообще граница идиотская.
[58:41.420 --> 58:44.420]  Вот она так просто получена двойным суммированием.
[58:44.420 --> 58:46.420]  Или не идиотская?
[58:46.420 --> 58:50.420]  Она совсем не идиотская, потому что берем матрицу Адамара.
[58:50.420 --> 58:52.420]  В нормальной форме.
[58:52.420 --> 58:56.420]  Ну, матрица Адамара, да. В нормальной форме.
[58:56.420 --> 59:00.420]  Не буду писать аж, это известно, что в нормальной.
[59:00.420 --> 59:04.420]  Так, отбрасываем левый столбец.
[59:07.420 --> 59:10.420]  Который из сплошных единиц.
[59:14.420 --> 59:17.420]  n на n, конечно, да. Ну а какого еще n?
[59:18.420 --> 59:22.420]  При котором знаем, что она существует, или верим, что существует, как хотите.
[59:22.420 --> 59:24.420]  Ну, понятно, n на n.
[59:24.420 --> 59:26.420]  Отбрасываем левый столбец.
[59:26.420 --> 59:28.420]  Отбрасываем левый столбец.
[59:28.420 --> 59:31.420]  Потом заменяем все минус единицы на нули.
[59:31.420 --> 59:33.420]  Просто заменяем.
[59:33.420 --> 59:35.420]  Ну, как можно вот так?
[59:35.420 --> 59:39.420]  Прибавить матрицу из сплошных единиц, разделить пополам.
[59:39.420 --> 59:43.420]  Заменяем все минус один на ноль.
[59:43.420 --> 59:53.420]  И рассматриваем код из строчек полученной матрицы.
[59:59.420 --> 01:00:01.420]  Вот какой это код.
[01:00:01.420 --> 01:00:03.420]  Какими параметры?
[01:00:03.420 --> 01:00:09.420]  Ну, n-1 первый параметр, потому что мы отбросили левый столбец.
[01:00:09.420 --> 01:00:12.420]  Значит, длина каждой строчки теперь n-1.
[01:00:13.420 --> 01:00:16.420]  Так, кодовых слов. n штук.
[01:00:17.420 --> 01:00:21.420]  Осталось понять, какое минимальное расстояние между словами.
[01:00:25.420 --> 01:00:27.420]  n пополам, правильно.
[01:00:27.420 --> 01:00:29.420]  Ну, я могу нарисовать, конечно.
[01:00:29.420 --> 01:00:35.420]  Там есть единицы, есть минус единицы.
[01:00:35.420 --> 01:00:38.420]  А дальше они вот так как-то пересекаются.
[01:00:43.420 --> 01:00:48.420]  Но у них общих вот этих n на 4 и вот этих n на 4.
[01:00:48.420 --> 01:00:50.420]  Ну, значит, n пополам.
[01:00:51.420 --> 01:00:55.420]  А можно было сказать, что сверху единицы расстояния все одинаковые,
[01:00:55.420 --> 01:00:59.420]  потому что скалярное произведение и скалярный квадрат одинаковые.
[01:00:59.420 --> 01:01:03.420]  Все же знают формулу, которая как теорема косинусов.
[01:01:03.420 --> 01:01:08.420]  Модуль х-у в квадрате это х на х плюс у на у минус 2ху.
[01:01:08.420 --> 01:01:12.420]  Ну все, значит, если скалярный квадрат n-1 фиксирован,
[01:01:12.420 --> 01:01:16.420]  скалярное произведение фиксировано, там минус единицы, ну все.
[01:01:18.420 --> 01:01:22.420]  Ну, повлиял он на то, что левый столбец из единиц был,
[01:01:22.420 --> 01:01:26.420]  поэтому как было минус единиц, а расстояние осталось, да.
[01:01:26.420 --> 01:01:29.420]  Да, расстояние осталось тем же.
[01:01:29.420 --> 01:01:32.420]  Именно расстояние скалярное произведение изменилось,
[01:01:32.420 --> 01:01:34.420]  а расстояние осталось тем же.
[01:01:34.420 --> 01:01:36.420]  Ну, в общем, n пополам здесь.
[01:01:36.420 --> 01:01:41.420]  Ну, то есть, если мы сейчас подставим вот в эту оценку,
[01:01:41.420 --> 01:01:46.420]  в которую у нас возникло эти параметры,
[01:01:46.420 --> 01:01:52.420]  как мы их подставим, значит, то такое d,
[01:01:52.420 --> 01:01:59.420]  d это у нас n пополам, m это у нас n,
[01:01:59.420 --> 01:02:03.420]  а n виноват, это у нас n-1.
[01:02:04.420 --> 01:02:08.420]  Ну, что я могу сделать, я хочу вот сюда подставить.
[01:02:08.420 --> 01:02:12.420]  2d, соответственно, это n, это 2d,
[01:02:12.420 --> 01:02:17.420]  2d-n это n, минус, но не n, а n-1.
[01:02:17.420 --> 01:02:21.420]  Ха-ха, получилось, ха-ха, получилось n.
[01:02:21.420 --> 01:02:26.420]  Вакурат m. То есть, коды, которые естественным образом
[01:02:26.420 --> 01:02:30.420]  получаются из матрицы Адамара, вот как я сейчас описал,
[01:02:30.420 --> 01:02:35.420]  они оптимальны с точки зрения границы Плоткина, они её достигают.
[01:02:37.420 --> 01:02:44.420]  Мы подставили вот в эту дробь параметры, которые у матрицы Адамара получились.
[01:02:44.420 --> 01:02:48.420]  n заменилось на n-1, потому что такова размерность сейчас,
[01:02:48.420 --> 01:02:52.420]  d это n пополам, но вот подставили и получили вакурат n.
[01:02:52.420 --> 01:02:56.420]  То самое, которое у нас здесь получилось, если матрица Адамара существует.
[01:02:56.420 --> 01:03:03.420]  То есть, существование матрицы Адамара эквивалентно достижимости границы Плоткина при данном n.
[01:03:08.420 --> 01:03:10.420]  Опять я сказал что-то лишнее.
[01:03:13.420 --> 01:03:16.420]  Вылетела птичка, всё записано, да.
[01:03:16.420 --> 01:03:19.420]  Эквивалентность, конечно, не очевидна.
[01:03:19.420 --> 01:03:22.420]  Но и существование следует, по крайней мере.
[01:03:22.420 --> 01:03:26.420]  Да, да, что-то я тороплюсь иногда, извините.
[01:03:26.420 --> 01:03:28.420]  Не, ну, конечно, не эквивалентно, да.
[01:03:28.420 --> 01:03:31.420]  То есть, это может и эквивалентно, но это уже надо доказывать.
[01:03:31.420 --> 01:03:33.420]  Это теперь с меня спросят.
[01:03:33.420 --> 01:03:36.420]  Да, задача с тремя звёздочками.
[01:03:36.420 --> 01:03:39.420]  И с одной решёточкой.
[01:03:39.420 --> 01:03:41.420]  Да, да.
[01:03:47.420 --> 01:03:51.420]  Первый человек на пистехе, получивший 11 баллов на экзамен.
[01:03:52.420 --> 01:03:58.420]  Так, ну что, у меня ещё есть время.
[01:03:58.420 --> 01:04:03.420]  Ещё время, значит, с матрицами Адамара я считаю, что мы на этом покончим.
[01:04:03.420 --> 01:04:06.420]  Тема неисчерпаемая, как и все, которые я рассказываю.
[01:04:06.420 --> 01:04:11.420]  Но я стараюсь довести до какого-то такого состояния, когда хоть понятно зачем, как это работает.
[01:04:11.420 --> 01:04:14.420]  Но дальше это надо разбираться глубже.
[01:04:14.420 --> 01:04:15.420]  Это понятно.
[01:04:15.420 --> 01:04:21.420]  Короче, я хочу сейчас перейти к теме, которая тоже очень важна и которую многие встречали.
[01:04:21.420 --> 01:04:26.420]  Это то, что называется первообразные корни и индексы.
[01:04:26.420 --> 01:04:31.420]  Это следующая естественная тема из теории чисел.
[01:04:31.420 --> 01:04:35.420]  Она ещё и в том смысле очень естественна.
[01:04:35.420 --> 01:04:42.420]  Вот мы только что говорили про кодирование, а она в каком смысле про шифрование.
[01:04:43.420 --> 01:04:52.420]  Первообразные корни и индексы.
[01:04:59.420 --> 01:05:05.420]  Так, ну времени у меня не так много, поэтому давайте я попробую начать какие-то общие определения.
[01:05:05.420 --> 01:05:08.420]  А там посмотрим, что я сегодня успею.
[01:05:08.420 --> 01:05:13.420]  Так, смотрите, вот пусть есть какое-то натуральное число m.
[01:05:16.420 --> 01:05:19.420]  Есть какое-то натуральное число m.
[01:05:19.420 --> 01:05:26.420]  А есть какое-нибудь число a такое, что a и m взаимно простые.
[01:05:26.420 --> 01:05:31.420]  Есть какое-то число a из приведённой системы вычетов по модулю m.
[01:05:31.420 --> 01:05:34.420]  Из приведённой системы вычетов.
[01:05:34.420 --> 01:05:42.420]  Понятное дело, что если a возвести в степень phi от m, то по модулю m получится единица.
[01:05:42.420 --> 01:05:44.420]  Это теорема Эйлер.
[01:05:44.420 --> 01:05:47.420]  Это все знают.
[01:05:47.420 --> 01:05:53.420]  Но, вообще говоря, вы, наверное, знаете, что бывают и меньшие, чем phi от m числа,
[01:05:53.420 --> 01:05:58.420]  такие, что a, возведённая в степень этих чисел, даёт тоже единицу по модулю m.
[01:05:58.420 --> 01:06:00.420]  Такое бывает.
[01:06:00.420 --> 01:06:03.420]  Например, если a равно 1.
[01:06:03.420 --> 01:06:06.420]  Мне очень нравится этот конструктив.
[01:06:06.420 --> 01:06:10.420]  Друзья, понятно, да? Такое бывает. Наверняка у вас примеры уже были.
[01:06:10.420 --> 01:06:16.420]  В общем, давайте обозначим дельта.
[01:06:16.420 --> 01:06:21.420]  Минимальное число.
[01:06:21.420 --> 01:06:27.420]  Ну, естественно, больше либо равные единицы такое, что a в степени...
[01:06:27.420 --> 01:06:29.420]  Хрень нарисовал.
[01:06:29.420 --> 01:06:33.420]  ...а в степени дельта сравнимо с единицей по модулю m.
[01:06:33.420 --> 01:06:37.420]  Ну, дельта – это дельта а та, конечно. Дельта зависит от а.
[01:06:37.420 --> 01:06:39.420]  Да?
[01:06:39.420 --> 01:06:42.420]  Да, это называется по-разному.
[01:06:42.420 --> 01:06:47.420]  Значит, в алгебре это действительно называется порядком элемента a в группе.
[01:06:47.420 --> 01:06:55.420]  Ну, или там... Понятно, значит, дельта называется порядок.
[01:06:55.420 --> 01:06:57.420]  Элемента a.
[01:06:57.420 --> 01:07:02.420]  А теоретико-числовики обычно говорят показатель a по модулю m.
[01:07:02.420 --> 01:07:06.420]  Ну, то же самое.
[01:07:09.420 --> 01:07:11.420]  Синонимичный термин.
[01:07:11.420 --> 01:07:16.420]  Показатель a по модулю m.
[01:07:16.420 --> 01:07:21.420]  Ну, это действительно порядок.
[01:07:21.420 --> 01:07:28.420]  В мультипликативной группе нашего кольца, которая образована числами взаимно простыми с вот этим m.
[01:07:37.420 --> 01:07:42.420]  Так, ну, есть очевидное утверждение.
[01:07:42.420 --> 01:07:45.420]  Вот уж точно упражнение без всякой звездочки, но могу доказать.
[01:07:45.420 --> 01:07:48.420]  Давайте даже докажу, хотя оно абсолютно тривиальное.
[01:07:48.420 --> 01:07:53.420]  Дельта является делителем числа phi от m.
[01:07:53.420 --> 01:07:58.420]  У любого числа a, его показатель или порядок, это делитель phi от m.
[01:07:58.420 --> 01:08:07.420]  Ну, если это не так, то есть phi от m равняется delta там какой-нибудь k плюс r,
[01:08:07.420 --> 01:08:14.420]  то, конечно, a в степени delta k плюс r сравнимо с a в степени r,
[01:08:14.420 --> 01:08:19.420]  потому что a в степени delta сравнимо с единицей, ну, значит, это будет a в степени r,
[01:08:19.420 --> 01:08:24.420]  ну а r меньше чем delta, потому что это остаток отделения.
[01:08:24.420 --> 01:08:27.420]  Ну и получается хрень.
[01:08:27.420 --> 01:08:34.420]  Потому что вот это, это a в степени phi от m, это сравнимо с единицей по теориями Эйлера,
[01:08:34.420 --> 01:08:38.420]  получается, что а в r тоже сравнимо с единицей, и вот это хрень.
[01:08:38.420 --> 01:08:41.420]  Так быть не может, потому что r меньше чем delta, где delta минимум.
[01:08:41.420 --> 01:08:45.780]  В общем, это стандартное, очень простое рассуждение.
[01:08:45.780 --> 01:08:48.220]  Дельта, конечно, является делителем числа Фиатэм.
[01:08:48.220 --> 01:09:00.220]  Вот, ну давайте назовем А первообразным корнем.
[01:09:00.220 --> 01:09:05.100]  Вот теоретика числовики ставит именно так, ударение
[01:09:05.100 --> 01:09:08.260]  всегда, то есть не первообразно, а именно первообразно.
[01:09:08.260 --> 01:09:10.500]  Хотя, в принципе, люди уже по-разному говорят.
[01:09:10.500 --> 01:09:21.820]  Первообразный корень по модулю М тогда и только тогда,
[01:09:21.820 --> 01:09:27.700]  когда дельта от А таки равняется Фиатэм.
[01:09:27.700 --> 01:09:38.100]  Ну, почему такой корень хорош чисто математически?
[01:09:38.100 --> 01:09:43.700]  Наверное, понятно, если такое число вообще существует,
[01:09:43.700 --> 01:09:46.460]  это интересный вопрос, самый главный вопрос, существует
[01:09:46.460 --> 01:09:51.540]  ли оно, но если оно такое существует, то оно порождает
[01:09:51.540 --> 01:09:55.140]  все элементы приведенной системы вычетов, своими
[01:09:55.140 --> 01:10:13.180]  возведениями в степени.
[01:10:13.180 --> 01:10:18.420]  Ну, приведенная система вычетов, да, это по сути
[01:10:18.420 --> 01:10:23.900]  мультипликативная группа просто этого кольца АЗМ.
[01:10:23.900 --> 01:10:32.980]  Полная система вычетов, ага, ну ничего-ничего, да,
[01:10:32.980 --> 01:10:35.500]  приведенную, конечно, порождает, потому что нам, конечно,
[01:10:35.500 --> 01:10:38.580]  все время важно соблюдение вот этого условия, иначе
[01:10:38.580 --> 01:10:39.580]  ничего не получится.
[01:10:39.580 --> 01:10:48.780]  Ну, просто, если мы рассмотрим числа, там, единица А, А квадрат
[01:10:49.780 --> 01:10:54.220]  степени Фиатэм, давайте без единиц, потому что А в степени
[01:10:54.220 --> 01:10:58.100]  Фиатэм, это снова единица, если мы такие числа рассмотрим,
[01:10:58.100 --> 01:11:01.660]  то это все разные числа по модулю М.
[01:11:01.660 --> 01:11:05.020]  Это понятно почему?
[01:11:05.020 --> 01:11:10.700]  Ну, это тоже верно, да, но я не знаю, мне показалось
[01:11:10.700 --> 01:11:13.940]  полезнее понять, что вот это все разные числа, а значит
[01:11:13.940 --> 01:11:17.140]  их Фиатэм, они разные, они все взаимно просты с М,
[01:11:17.140 --> 01:11:18.940]  то есть они действительно порождают приведенную
[01:11:18.940 --> 01:11:19.940]  систему вычетов.
[01:11:19.940 --> 01:11:25.260]  Так, друзья, то, что разные сами докажут, это очевидно.
[01:11:25.260 --> 01:11:30.260]  Вот, то есть это такой порождающий элемент, опять же, математически
[01:11:30.260 --> 01:11:33.260]  кажется замечательным следующий факт, раз они
[01:11:33.260 --> 01:11:38.860]  порождают все числа взаимно просты с М, значит, можно,
[01:11:38.860 --> 01:11:41.260]  внимание, товарищи, вот это уже ключевой момент,
[01:11:41.260 --> 01:11:44.820]  значит, можно определить в некотором смысле логорифом
[01:11:44.820 --> 01:11:48.700]  по основанию такого А от любого числа из приведенной
[01:11:48.700 --> 01:11:53.700]  системы вычетов.
[01:11:53.700 --> 01:11:54.700]  Правда же, да?
[01:11:54.700 --> 01:11:59.700]  Ну так, логорифом по основанию А от какого-то, какую там
[01:11:59.700 --> 01:12:03.580]  букву использовать Б, Б имеется в виду взаимно
[01:12:03.580 --> 01:12:07.740]  просто с М, то есть из приведенной системы вычетов, это и есть
[01:12:07.740 --> 01:12:14.020]  как раз та степень И, нет, это и есть такое И, то А в
[01:12:14.020 --> 01:12:22.700]  степени И сравнимо с Б по модулю М.
[01:12:22.700 --> 01:12:23.700]  Про логорифмировать можно.
[01:12:23.700 --> 01:12:28.900]  Тоже непонятно, а зачем, для чего, вот вообще ничего
[01:12:28.900 --> 01:12:29.900]  непонятно.
[01:12:29.900 --> 01:12:33.220]  Да, чтобы интересно было, красиво, можно построить
[01:12:33.220 --> 01:12:38.420]  такой вот анализ на конечных полях, если М, например,
[01:12:38.420 --> 01:12:41.180]  это простое число, тогда у нас получается не кольцо,
[01:12:41.180 --> 01:12:43.100]  а поле, там возникает красивый анализ.
[01:12:43.100 --> 01:12:47.780]  Это бы все, может быть, даже и хрень, но это, знаете,
[01:12:47.780 --> 01:12:50.260]  как я все время пропагандирую, что не потому математика
[01:12:50.260 --> 01:12:52.820]  прекрасна, что у нее есть приложение, а потому у нее
[01:12:52.820 --> 01:12:54.740]  есть приложение, что прекрасно.
[01:12:54.740 --> 01:12:56.740]  Вот это прекрасно.
[01:12:56.740 --> 01:12:59.580]  И это оказалось очень прикладной вещью, как некоторые из вас
[01:12:59.580 --> 01:13:00.580]  наверняка знают.
[01:13:00.580 --> 01:13:05.140]  Вот это как раз основа для шифрования.
[01:13:05.140 --> 01:13:06.140]  Почему?
[01:13:06.140 --> 01:13:08.700]  Потому что выяснилось в какой-то момент, что операция
[01:13:08.700 --> 01:13:14.540]  нахождения вот этого логарифма, это что-то ужасное.
[01:13:14.540 --> 01:13:19.040]  В том смысле, что уже десятилетиями никто не может придумать
[01:13:19.040 --> 01:13:24.020]  полинамиальный по сложности алгоритм.
[01:13:24.020 --> 01:13:26.660]  Одна из труднейших проблем современной дискретной
[01:13:26.660 --> 01:13:29.660]  математики и криптографии.
[01:13:29.660 --> 01:13:31.900]  Как найти такой логарифм?
[01:13:31.900 --> 01:13:35.580]  Ну, давайте я вообще-то его переобозначу, все-таки
[01:13:35.580 --> 01:13:39.260]  принято писать не логарифм, а инд, называется это индекс
[01:13:39.260 --> 01:13:43.100]  в теории чисел, хотя действительно в криптографии слова индекс
[01:13:43.100 --> 01:13:47.020]  не употребляют, а говорят дискретный логарифм, дискретное
[01:13:47.020 --> 01:13:48.020]  логарифмирование.
[01:13:48.020 --> 01:13:53.060]  Ну, это просто постулат такой, никто не может придумать.
[01:13:53.060 --> 01:13:56.220]  Я знал нескольких людей, причем очень серьезных,
[01:13:56.220 --> 01:14:00.060]  неферматистов, которые заявляли, что они знают
[01:14:00.060 --> 01:14:03.980]  алгоритм, но никому не скажут, потому что там их типа убьют.
[01:14:04.100 --> 01:14:07.660]  Ну, вы знаете, хорошие математики тоже иногда сходят с ума,
[01:14:07.660 --> 01:14:09.820]  поэтому я не исключаю, что они были просто сумасшедшими
[01:14:09.820 --> 01:14:12.260]  уже на тот момент, но они были хорошими математиками,
[01:14:12.260 --> 01:14:13.260]  известными.
[01:14:13.260 --> 01:14:16.060]  Может быть, действительно, кто-то там им платил за это,
[01:14:16.060 --> 01:14:17.060]  я ничего не знаю.
[01:14:17.060 --> 01:14:19.820]  Я не видел, конечно, ни одного алгоритма, который
[01:14:19.820 --> 01:14:22.020]  бы дискретно логарифмировал за полином.
[01:14:22.020 --> 01:14:25.460]  Так, теперь вопрос, товарищи, поднимите, пожалуйста, руки,
[01:14:25.460 --> 01:14:28.100]  кто понимает, что я имею в виду, когда говорю за полином.
[01:14:28.100 --> 01:14:31.980]  Хорошо, это круто.
[01:14:31.980 --> 01:14:34.820]  А теперь скажите мне, вот в данном случае, если
[01:14:34.820 --> 01:14:40.260]  вам дано число А и дано число Б, вернее, дано число А,
[01:14:40.260 --> 01:14:41.260]  что значит за полином?
[01:14:41.260 --> 01:14:48.180]  Совершенно верно, именно за какую-то степень обычного
[01:14:48.180 --> 01:14:50.380]  логарифма числа А, ну, двоичного, например.
[01:14:50.380 --> 01:15:00.100]  Ой, М, конечно, да, М, М, М, не А, конечно, М.
[01:15:00.100 --> 01:15:02.860]  По какому модулю мы работаем?
[01:15:02.860 --> 01:15:05.580]  Так, вы понимаете, да, что сложность числа – это
[01:15:05.580 --> 01:15:07.540]  всё-таки количество цифр в нём, то есть логарифм
[01:15:07.540 --> 01:15:08.540]  дистичный.
[01:15:08.540 --> 01:15:12.700]  Поэтому, если мы хотим полином, то полином должен быть именно
[01:15:12.700 --> 01:15:14.060]  от дистичного логарифма.
[01:15:14.060 --> 01:15:17.540]  Я надеюсь, что когда все поднимали руки, имели в виду
[01:15:17.540 --> 01:15:18.540]  именно это.
[01:15:18.540 --> 01:15:22.380]  Ну, полином – это как-то многочлен какой-то степени.
[01:15:22.380 --> 01:15:25.180]  Конечно, опять, с практической точки зрения, если многочлен
[01:15:25.180 --> 01:15:28.020]  имеет 25-ую степень, то, наверное, это не очень хорошо.
[01:15:28.020 --> 01:15:32.020]  Но, тем не менее, математики, вот они так разделяют – полином
[01:15:32.020 --> 01:15:33.020]  не полино.
[01:15:33.020 --> 01:15:37.700]  Но в бесконечной перспективе очень даже, но пока до компьютера
[01:15:37.700 --> 01:15:41.860]  не считают даже до 10% нормально, ну, как-то вот, да, пока не
[01:15:41.860 --> 01:15:42.860]  повезло.
[01:15:42.860 --> 01:15:43.860]  Вот.
[01:15:43.860 --> 01:15:48.860]  К сожалению, через одну минуту прозвенит звонок,
[01:15:48.860 --> 01:15:53.620]  поэтому рассказать вам, во-первых, как это действительно
[01:15:53.620 --> 01:15:55.940]  используется в шифровании для тех, кто не знает, а
[01:15:55.940 --> 01:15:59.380]  многие не знают, я уверен, я сегодня не успеваю.
[01:15:59.380 --> 01:16:02.100]  Хотя это 5 минут буквально, но не успел.
[01:16:02.100 --> 01:16:03.100]  Вот.
[01:16:03.100 --> 01:16:05.860]  Ну и кроме того, мы, конечно, будем доказывать, что такие
[01:16:05.860 --> 01:16:09.140]  первообразные корни на самом деле существуют.
[01:16:09.140 --> 01:16:12.700]  Например, они существуют по простому модулю, по модулю
[01:16:12.700 --> 01:16:16.860]  степени любого простого числа, кроме 2-ки любого
[01:16:16.860 --> 01:16:18.660]  нечетного простого числа.
[01:16:18.660 --> 01:16:21.860]  Там по модулю 2-ки, 4-ки, ну, а начиная с 8-ки уже их
[01:16:21.860 --> 01:16:22.860]  нет.
[01:16:22.860 --> 01:16:25.500]  Вот это мы все аккуратно докажем и про шифрование
[01:16:25.500 --> 01:16:26.500]  я расскажу.
[01:16:26.500 --> 01:16:27.000]  Ну это, видимо, в следующий раз все.
