[00:00.000 --> 00:08.140]  Так, ну мы занимаемся с вами числами рамсея, мы установили
[00:08.140 --> 00:12.460]  верхнюю оценку порядка 4 в степени s, ну там поделить
[00:12.460 --> 00:17.100]  на корень из PS, но это мелочи, и мы выяснили связь между
[00:17.100 --> 00:21.340]  числами рамсея и задачей, которую мы когда-то в прошлом
[00:21.340 --> 00:24.080]  семестре обсуждали про соотношение между оценками
[00:24.080 --> 00:27.240]  хроматического числа через кликовое число и число
[00:27.240 --> 00:30.160]  независимости, что это на самом деле связанные между
[00:30.160 --> 00:31.160]  собой задачи.
[00:31.160 --> 00:35.660]  Ну вот давайте я буду уточнять оценку, которая из той связи
[00:35.660 --> 00:40.640]  получалась, а именно оценка получалась вот такая, больше
[00:40.640 --> 00:44.380]  либо равно, или больше даже строго, чем корень из
[00:44.380 --> 00:50.120]  двух в этой степени, начиная с какого-то s, вот такая оценка
[00:50.120 --> 00:52.660]  она сразу вытекает из той теории, которая у нас была
[00:52.660 --> 00:56.880]  в прошлом году, и соответственно мы это в понедельник обсуждали.
[00:57.000 --> 00:59.560]  Поднимите пожалуйста руки те из вас, кто был в понедельник
[00:59.560 --> 01:00.760]  или слушал это в записи.
[01:00.760 --> 01:04.200]  А, записи еще нет.
[01:04.200 --> 01:05.200]  Понятно.
[01:05.200 --> 01:06.200]  То есть не все, да?
[01:06.200 --> 01:10.120]  Ну я думаю, что ничего страшного, потому что, ну, запись-то
[01:10.120 --> 01:13.360]  она будет последовательная, те кто, если что-то не будут
[01:13.360 --> 01:16.040]  понимать, но вы спрашиваете, ну вроде должно быть понятно,
[01:16.040 --> 01:17.480]  что такое число рамсея.
[01:17.480 --> 01:18.480]  Все знают.
[01:18.480 --> 01:22.040]  Не помните, что такое, кто из присутствующих не помнит
[01:22.040 --> 01:25.360]  определение числа рамсея?
[01:25.360 --> 01:26.360]  Не помните, да?
[01:26.360 --> 01:29.560]  Давайте я быстренько определю еще раз, придется все детали
[01:29.560 --> 01:34.960]  конечно слушать по записи, которая была в понедельник.
[01:34.960 --> 01:40.560]  Значит, r-a-t-s-t в одном из вариантов своего определения, в таком
[01:40.560 --> 01:44.480]  наиболее коротком, наши обозначения этому соответствуют.
[01:44.480 --> 01:48.480]  Минимальное натуральное число такое, что для любого
[01:48.480 --> 01:58.920]  графа, у которого n вершин, либо его кликовое число
[01:58.920 --> 02:04.580]  не меньше чем s, либо его число независимости не меньше
[02:04.580 --> 02:05.580]  чем t.
[02:05.580 --> 02:09.240]  Ну такая абсолютно классическая величина, очень важная мы
[02:09.240 --> 02:13.080]  это будем обсуждать, уже немножко обсуждали, но вот
[02:13.080 --> 02:14.080]  такая вот штука.
[02:15.080 --> 02:17.720]  К сожалению, повторять прошлую лекцию я точно не буду.
[02:17.720 --> 02:24.080]  Значит, давайте, наверное, сформулируем такую теорему.
[02:24.080 --> 02:28.840]  Ну, пусть она выглядит явным образом как уточнение
[02:28.840 --> 02:32.640]  оценки, которая светится в левом верхнем углу доски,
[02:32.640 --> 02:37.840]  а именно утверждение вот какое r-a-t-s-s больше либо
[02:37.840 --> 02:40.000]  ровняется, ну или хотите строго больше, сейчас вы
[02:40.000 --> 02:42.360]  увидите, что это неважно.
[02:42.440 --> 02:48.280]  Я вот так напишу, 1 плюс 1 маленькое от единицы, s поделить
[02:48.280 --> 02:55.000]  на e корней из 2 умножить на 2 в степени с пополам.
[02:55.000 --> 02:57.440]  Ну то есть, грубо говоря, оценка улучшена в s поделить
[02:57.440 --> 03:03.760]  на e корней из 2 керас, оценка, которая в левом углу, 2 в
[03:03.760 --> 03:06.520]  степени с пополам и корень из 2 в степени с, это, конечно,
[03:06.520 --> 03:07.520]  одно и то же.
[03:07.520 --> 03:10.800]  Я надеюсь, это все быстро понимают, но вот 2 в степени
[03:10.800 --> 03:13.640]  с пополам и корень из 2 в степени с, но вот вместо
[03:13.640 --> 03:17.280]  роста корней из 2 в степени с тут появилась еще растущая
[03:17.280 --> 03:20.600]  вот такая вот величина s поделить на e корней из 2,
[03:20.600 --> 03:22.520]  ну с точностью до поправки.
[03:22.520 --> 03:26.120]  Напоминаю, что когда я пишу о малой от единицы, я из
[03:26.120 --> 03:30.600]  соображений чисто мат-аналитической корректности пишу плюс,
[03:30.600 --> 03:34.040]  но очевидно, что если x в равно, то это реально скорее
[03:34.040 --> 03:37.040]  всего минус.
[03:37.040 --> 03:39.120]  Я понятно говорю, то есть о малой от единицы это
[03:39.120 --> 03:41.960]  некоторая функция, которая может принимать в том числе
[03:41.960 --> 03:45.400]  отрицательные значения, и она видимо здесь при малых
[03:45.400 --> 03:47.200]  s уж во всяком случае какая-то.
[03:47.200 --> 03:51.680]  Если вы понимаете, что, например, вот в такую запись укладывается
[03:51.680 --> 03:57.120]  ситуация, когда вы r от ss оцениваете при всех s, например,
[03:57.120 --> 04:02.000]  меньше миллиона нулем просто снизу, ну r от ss очевидно
[04:02.000 --> 04:03.000]  больше нуля.
[04:03.000 --> 04:07.760]  И вот, например, вы имеете право в рамках этой записи
[04:07.760 --> 04:12.640]  оценить r от ss нулем снизу при всех s меньше миллиона,
[04:12.640 --> 04:15.040]  ну а дальше уже чем-то более разумным, близким к вот
[04:15.040 --> 04:16.040]  этому.
[04:16.040 --> 04:18.160]  То есть вот этого малая от единицы, например, может
[04:18.160 --> 04:20.720]  равняться минус один при всех достаточно маленьких
[04:20.720 --> 04:21.720]  s.
[04:21.720 --> 04:24.240]  Это ничему не противоречит.
[04:24.240 --> 04:27.200]  Я сейчас не конкретизирую, насколько этого малая реально
[04:27.200 --> 04:29.200]  малая при маленьких s.
[04:29.200 --> 04:31.960]  Поэтому это улучшение той оценки, но непонятно при
[04:31.960 --> 04:33.480]  каких s нулем.
[04:33.480 --> 04:35.960]  Из доказательств будет видно при каких, и там будет
[04:35.960 --> 04:38.440]  вполне конкретный рецепт, как можно вычислять вот
[04:38.440 --> 04:41.960]  этого маленькой от единицы при каждом конкретном s.
[04:41.960 --> 04:46.680]  Но с точки зрения асимптотики, с точки зрения роста s, конечно,
[04:46.680 --> 04:50.040]  эта оценка лучше, чем то, что в левом верхнем углу.
[04:50.040 --> 04:52.840]  Так, друзья, я понятно сказал, нет?
[04:52.840 --> 04:57.680]  Я говорил красиво, быстро, но точно понятно.
[04:57.680 --> 05:02.920]  Ну, видите, здесь тоже какое-то с нулемое, потому что я
[05:02.920 --> 05:07.400]  сейчас ссылался на теорему прошлого года, ну, наверное,
[05:07.400 --> 05:09.400]  там с четырех это верно.
[05:09.400 --> 05:12.320]  На самом деле это можно доказать, начиная с s равного четырем,
[05:12.320 --> 05:15.600]  но я не доказывал это в прошлый раз, я просто вывел это как
[05:15.600 --> 05:18.480]  следствие из теоремы прошлого года, в которые t с нулевой
[05:18.480 --> 05:19.480]  никак не конкретизируется.
[05:19.480 --> 05:23.400]  Ну, здесь мы сейчас все поймем, вот вы можете забыть про
[05:23.400 --> 05:26.200]  ту оценку и воспринимать так, как будто мы начинаем
[05:26.200 --> 05:32.560]  прямо с нуля, вот первая оценка, вот она.
[05:32.560 --> 05:35.720]  Ну, давайте прежде всего прямо из определения поймем,
[05:35.720 --> 05:39.100]  что значит, что r от ss вообще больше какого-то n.
[05:39.100 --> 05:42.320]  Нам дано какое-то натуральное число, вот что означает
[05:42.320 --> 05:44.040]  установить такое неравенство?
[05:44.040 --> 05:47.720]  Что означает доказать, что r от ss строго больше чем
[05:47.720 --> 05:48.720]  n?
[05:48.720 --> 05:51.720]  Я тебе в скобке напишу такое утверждение, да?
[05:51.720 --> 05:54.620]  Оно равносильно, вот это все утверждение в скобках
[05:54.620 --> 05:58.000]  о том, что число рамсея строго больше чем n, глядим на
[05:58.000 --> 06:01.040]  определение, глядим на это определение, даже те, кто
[06:01.040 --> 06:03.280]  его не видел раньше, вот они на него могут смотреть.
[06:03.280 --> 06:05.800]  Что значит, что r от ss больше чем n?
[06:05.800 --> 06:08.480]  Это значит, что вот это условие, которое написано
[06:08.480 --> 06:11.240]  после первого двоеточия, оно нарушается при этом
[06:11.240 --> 06:12.240]  n.
[06:12.240 --> 06:13.240]  Согласны?
[06:13.240 --> 06:18.760]  Минимальное n, при котором выполнено, это число рамсея.
[06:18.760 --> 06:22.960]  Если число рамсея больше какого-то n, ну, значит,
[06:22.960 --> 06:25.120]  при таком n это условие нарушается.
[06:25.720 --> 06:35.840]  Существует граф, у которого n вершин, и у которого ω от
[06:35.840 --> 06:42.120]  g меньше чем s, и α от g меньше чем s.
[06:42.120 --> 06:45.440]  Ну, в прошлый раз-то я это все комментировал, но сейчас
[06:45.440 --> 06:47.840]  повторяю просто заново, поскольку есть люди, которые
[06:47.840 --> 06:49.720]  сходу вот это могли не понять.
[06:49.720 --> 06:52.760]  Ну, все, просто написал отрицание от того условия, которое
[06:52.760 --> 06:54.680]  задает определение числа рамсея.
[06:54.760 --> 06:56.160]  Вот оно отрицание.
[06:56.160 --> 06:59.840]  Есть контрпример, существует граф на n вершинах, в котором
[06:59.840 --> 07:04.520]  и клика самая большая, маленькая, и дырка самая большая, тоже
[07:04.520 --> 07:05.520]  маленькая.
[07:05.520 --> 07:06.520]  Дырка, в смысле, независимое множество.
[07:06.520 --> 07:11.120]  Вот, ну, как доказывать существование какого-то
[07:11.120 --> 07:12.120]  объекта?
[07:12.120 --> 07:16.680]  Вероятностным методом, правильно, да, нет, но конечно
[07:16.680 --> 07:19.360]  это потом приведет нас к главному вопросу современной
[07:19.360 --> 07:21.840]  компьютерсайенс, как это дирандомизировать.
[07:21.840 --> 07:24.560]  Я еще раз повторяю, мы это обязательно обсудим.
[07:24.640 --> 07:27.120]  Но пока все будет только с помощью вероятностного
[07:27.120 --> 07:30.520]  метода, то есть никакого алгоритмического подхода
[07:30.520 --> 07:32.160]  здесь не просматривается.
[07:32.160 --> 07:35.000]  Мы сейчас переберем все графы на каком-то количестве
[07:35.000 --> 07:39.840]  вершин и убедимся в том, что, да, вот, обязательно
[07:39.840 --> 07:43.080]  найдется среди них такой, который устроен так, как
[07:43.080 --> 07:44.080]  надо.
[07:44.080 --> 07:46.240]  Слушайте, а на каком количестве вершин?
[07:46.240 --> 07:48.920]  Вы понимаете, что в качестве n я в итоге хочу взять вот
[07:48.920 --> 07:50.600]  эту величину, правда же?
[07:50.840 --> 07:54.840]  То есть мы хотим в итоге перебрать графы вот с таким
[07:54.840 --> 07:56.200]  количеством вершин.
[07:56.200 --> 07:58.200]  Вы понимаете, сколько их?
[07:58.200 --> 08:02.080]  Ну примерно 2 в степени 2 в степени s, да?
[08:02.080 --> 08:04.400]  Что-то такое, ну жесть полная.
[08:04.400 --> 08:06.880]  Конечно, потом надо будет обсуждать алгоритмы, но
[08:06.880 --> 08:08.360]  пока вероятностный метод.
[08:08.360 --> 08:11.080]  Так, как работает вероятностный метод?
[08:11.080 --> 08:12.880]  Давайте рассмотрим случайный граф.
[08:15.880 --> 08:18.320]  Мы очень хорошо с вами знаем, что это такое, мы много
[08:18.320 --> 08:22.040]  чего изучили про случайный граф в прошлом семестре.
[08:22.040 --> 08:25.200]  Естественно, это будет граф опять Керда Шейрени
[08:25.200 --> 08:29.320]  на n вершинах, и в данном случае, поскольку мы работаем
[08:29.320 --> 08:32.520]  с симметричным числом Рамсе, с диагональным числом
[08:32.520 --> 08:35.640]  Рамсе, то, конечно, надо брать вероятность ребра
[08:35.640 --> 08:36.640]  одна-вторая.
[08:38.640 --> 08:42.560]  Ну конечно, да, нам все равно принять в граф ребро
[08:42.560 --> 08:45.560]  или исключить его из него, все равно оценка должна
[08:45.560 --> 08:46.560]  быть одинаковая.
[08:46.800 --> 08:48.800]  Вероятность логично брать одной-второй.
[08:49.800 --> 08:57.160]  Так, ну чего, давайте перечислим как-нибудь, вот так вот,
[08:57.160 --> 09:07.720]  а1 и так далее, а с индексом c из n по s, все под множество
[09:07.720 --> 09:08.720]  вершин.
[09:11.720 --> 09:16.120]  Вершины это, ну, хотите числа от единицы до n, как обычно.
[09:16.680 --> 09:19.560]  Вершины нас n штук, можно считать, что v это числа от единицы
[09:19.560 --> 09:20.560]  до n.
[09:20.560 --> 09:25.120]  Ну, я обычно вот такую картину рисую, говорю, что это сарделька,
[09:25.120 --> 09:27.000]  она состоит из n чисел.
[09:27.000 --> 09:32.000]  Вот, что такое а1 и так далее, аc из n по s?
[09:32.000 --> 09:34.440]  Это все возможные s-элементные подсардельки.
[09:34.440 --> 09:37.520]  Вот это вот какая-то а с индексом u.
[09:40.520 --> 09:44.240]  Так, понятно сказал, да, просто перечисляю все s-элементные
[09:44.240 --> 09:45.240]  под множеством.
[09:45.360 --> 09:50.640]  И давайте, как обычно, буква a кратила с индекса мы, обозначать
[09:50.640 --> 09:52.600]  событие, то есть множество уже графов.
[09:52.600 --> 10:03.000]  Событие такое, что a it – это либо клика, либо независимое
[10:03.000 --> 10:04.000]  множество.
[10:09.000 --> 10:12.000]  Ну, понятное дело, что в конкретном графе одновременно
[10:12.000 --> 10:15.200]  не может так случиться, что данная конкретная a it образует
[10:16.160 --> 10:17.160]  и кликую независимое множество.
[10:19.160 --> 10:20.160]  Я думаю, понятно.
[10:20.160 --> 10:23.040]  Но в каких-то графах оно образует клику, в каких-то
[10:23.040 --> 10:26.840]  графах оно образует независимое множество, и вот совокупность
[10:26.840 --> 10:31.640]  всех тех графов, в которых то ли так, то ли сяк, мы обозначаем
[10:31.640 --> 10:34.640]  a красиво it.
[10:34.640 --> 10:36.520]  Событие – это множество графов, поэтому я могу
[10:36.520 --> 10:38.800]  говорить просто совокупность тех графов, в которых вот
[10:38.800 --> 10:41.480]  эта штука либо в дырку, либо наоборот клика.
[10:41.480 --> 10:51.280]  Так, ну смотрите, объединение a it по i от единицы до c из
[10:51.280 --> 10:55.600]  n по s – это совсем стандартная вещь, уже прямо должна выскакивать
[10:55.600 --> 10:59.200]  от зубов, отскакивать от зубов, что вот это объединение
[10:59.200 --> 11:02.520]  значит, что хотя бы одно множество образует то
[11:02.520 --> 11:03.800]  ли клику, то ли независимое.
[11:03.800 --> 11:09.000]  То есть наша цель просто убедиться в том, что вероятность
[11:09.000 --> 11:13.720]  меньше одного, если она меньше одного, то с положительной
[11:13.720 --> 11:16.760]  вероятностью нет ни одной клики ни одного независимого
[11:16.760 --> 11:17.760]  множества.
[11:17.760 --> 11:23.240]  Если вот эта вероятность меньше одного, то вероятность
[11:23.240 --> 11:31.160]  отрицания строк больше нуля.
[11:31.160 --> 11:37.400]  Ну а что такое отрицание, что нет ни одной клики на
[11:37.560 --> 11:40.440]  вершинах и нет ни одного независимого множества?
[11:40.440 --> 11:42.880]  Ну то есть в точности омега меньше s а альфа меньше
[11:42.880 --> 11:43.880]  s.
[11:43.880 --> 11:48.200]  Если вероятность положительна, значит такие графы существуют.
[11:48.200 --> 11:50.600]  Ну а обычный вероятостный метод, это для вас должно
[11:50.600 --> 11:54.120]  быть уже прям вот совсем знакомым, привычным, не
[11:54.120 --> 11:55.120]  страшным.
[11:55.120 --> 11:57.480]  Почему эта вероятность меньше единицы?
[11:57.480 --> 12:05.480]  Ну давайте ее тупо пока что оценим.
[12:05.480 --> 12:11.560]  Просто суммой по i от единицы до c из n по s, вероятность
[12:11.560 --> 12:15.560]  этих а красивых этых.
[12:15.560 --> 12:16.560]  Внимание, вопрос!
[12:16.560 --> 12:19.080]  К аудитории, чтобы она не расслаблялась.
[12:19.080 --> 12:21.840]  Чему равна вероятность а красиво?
[12:21.840 --> 12:25.080]  С какой вероятностью либо все ребра отсутствуют,
[12:25.080 --> 12:29.480]  либо все ребра присутствуют?
[12:29.480 --> 12:32.080]  На данных s-вершинах.
[12:32.080 --> 12:34.120]  Сколько всего ребер на данных s-вершинах?
[12:34.120 --> 12:35.120]  Начнем с этого.
[12:35.320 --> 12:37.400]  C из s по 2, да?
[12:37.400 --> 12:40.960]  Так, какая вероятность, что они все, например, присутствуют?
[12:40.960 --> 12:43.800]  Ну 1 вторая в степени c из s по 2, правда?
[12:43.800 --> 12:46.320]  И такова же вероятность того, что они все отсутствуют?
[12:46.320 --> 12:47.320]  Я вот так напишу.
[12:47.320 --> 12:52.560]  C из n по s на 2 в степени 1 минус c из s по 2.
[12:52.560 --> 12:56.680]  Но 2 в степени минус c из s по 2, это 1 вторая в степени
[12:56.680 --> 13:00.120]  c из s по 2, еще умножаем на это.
[13:00.120 --> 13:03.340]  Поскольку слагаемые одинаковые, просто умножаем на их количество,
[13:03.340 --> 13:09.700]  вот такую штуку. Дорогие друзья, давайте я вот сразу, чтобы потом не повторять, а то вдруг я
[13:09.700 --> 13:14.780]  сотру. Это не нужно, внимание, для продолжения доказательства. Мы, в принципе, уже все сделали.
[13:14.780 --> 13:21.420]  Надо просто в качестве n взять вот эту штуку и сейчас убедиться в том, что будет меньше одного.
[13:21.420 --> 13:28.340]  Правильно? Но прежде чем это сделать, сделаем одно небольшое замечание. Представьте себе,
[13:28.420 --> 13:34.900]  что x от g. Это повторяю. Не нужно для доказательства этой теоремы, но мы этим воспользуемся позже.
[13:34.900 --> 13:51.700]  Пусть x от g это случайная величина, которая равна числу s клик и s независимых множеств
[13:51.700 --> 14:04.340]  в этом графе g. Вот мне хотелось бы верить, что все присутствующие и отсутствующие понимают,
[14:04.340 --> 14:09.620]  что написанное вот здесь, это просто мат ожидания этой случайной величины x. Но я уж столько там
[14:09.620 --> 14:14.780]  про это комментировал в прошлом семестре. Про формулы включения и исключения, что мат ожидания
[14:14.780 --> 14:20.180]  это как раз вот начало этой формулы. Как формула включения и исключения пишет здесь равно,
[14:20.180 --> 14:25.340]  сначала идет вот этот как раз мат ожидания, потом вычитается там второй факториальный момент,
[14:25.340 --> 14:34.260]  еще что-то. Мы все доказывали. Поэтому, конечно, вот это вот равняется мат ожидания x. Просто
[14:34.260 --> 14:39.700]  по линейности и вообще мы это очень много обсуждали. Вспоминайте это, это очень важно,
[14:39.700 --> 14:45.860]  полезно. Вот если вы чувствуете связь между прошлым семестром и этим, это очень хорошо. Ну
[14:45.860 --> 14:50.020]  ладно, сейчас-то это не нужно. Сейчас надо взять вот такую штуку в качестве n и,
[14:50.020 --> 14:59.220]  давайте я чуть подробнее скажу, и убедиться, что при правильном подборе вот этого маленького от
[14:59.220 --> 15:05.700]  единицы, то есть при правильном выборе функции, которая стремится к нулю, мы действительно вот
[15:05.700 --> 15:16.700]  здесь получим строго меньше одного. Поняли, да, человек? Что малая от единицы в нашей власти. Вот не
[15:16.700 --> 15:26.940]  любое подойдет, а некоторое. Ну давайте, значит, c из n по s на 2 в степени 1 минус s пополам. Это
[15:26.940 --> 15:37.460]  что такое? Значит, это меньше либо равно n в степени s поделить на s факториал, умножить на 2 в
[15:37.460 --> 15:46.340]  степени 1 минус s, s минус 1 пополам. C из s подывает s на s минус 1 пополам. Ну а c из n по s
[15:46.340 --> 15:51.860]  традиционно оцениваем как n в s и поделить на s факториал. Это осмысленно при маленьких s,
[15:51.860 --> 15:57.940]  как может быть вы помните, но у нас s маленькая по сравнению с n. s логарифмическая мы это в
[15:57.940 --> 16:05.620]  прошлый раз обсуждали. s это удвоенный логарифм двоичный от n, поэтому лучше такой оценки вы
[16:05.620 --> 16:22.500]  все равно не сделаете. Так, ну давайте сейчас подставим. Это равно. Самое противное это n в s-той.
[16:22.500 --> 16:29.900]  Ну давайте 1 плюс o малая от единицы в s-той, где o малая от единицы, которая здесь написана, это
[16:29.900 --> 16:34.860]  некоторая функция, какую мы можем подобрать. Вот мы ее будем потом подбирать, обсуждать. Надо
[16:34.860 --> 16:40.980]  я вообще подбирать, может я просто нулем взять равный. Так, дальше будет s в s-той степени,
[16:40.980 --> 16:53.060]  е в степени s, корень из двух в степени s и 2 в степени s квадрат пополам. Так, товарищи,
[16:53.060 --> 16:57.100]  вы поняли, как я n возвел в s-той степени? Думаю, что да. Вон там.
[16:59.900 --> 17:08.900]  Что просто возвел. Ничего умного, да? Так, ну и надо умножить. Вот на эту часть я ее раскрою,
[17:08.900 --> 17:16.020]  в скобке раскрою. s квадрат пополам плюс s пополам. Ну и сейчас у меня этот тетрис провалится
[17:16.020 --> 17:23.020]  благополучно, прямо как в знаменитом ролике, где я там тяп-ляп-тяп-ляп. Сейчас все провалит. Но
[17:23.020 --> 17:31.340]  не сразу, потому что я забыл факториал написать. Вот тут вот где-то надо еще нарисовать s факториал,
[17:31.340 --> 17:37.060]  иначе не все провалится. s факториал я потерял просто, который был слева. s факториал, конечно,
[17:37.060 --> 17:43.660]  надо нарисовать. Давайте я совсем уж аккуратно напишу. Итак, вот тут 1 плюс о малой от единицы
[17:43.660 --> 17:51.180]  в s-той, s в s-той. Так, слушайте, ну кое-что уже провалилось. Ну что это, так сказать, за собой,
[17:51.180 --> 17:57.540]  видите как? Все хорошо подобрано. s квадрат пополам. Главное, так сказать, член азимтотики уже
[17:57.540 --> 18:04.900]  пропал. Нам в единицу все это надо свернуть, но вот s квадрат пополам уже пропал. Главное. Так,
[18:04.900 --> 18:11.980]  ну хорошо. Что у меня осталось? У меня осталось 2 в степени 1. Прибавить s пополам вот отсюда,
[18:11.980 --> 18:20.540]  а в знаменателе у меня будет е в степени s. 2, можно скобки не рисовать, можно вот так,
[18:20.540 --> 18:27.020]  на 2 в степени s пополам в корене с 2 в s-той. А s факториал, который я чуть был не потерял,
[18:27.020 --> 18:33.580]  я напишу по стирлингу. То есть будет 1 плюс о малой от единицы в корене с 2 пи с.
[18:33.580 --> 18:46.660]  S поделить на е в s-той степени. Согласны? Просто стирлинг. Ну вот тут начинается стетвис. То есть
[18:46.660 --> 18:54.100]  вот эта штука сокращается вот с этой. Чпок, провалились. Тут у нас, если хотите, я перечеркну
[18:54.100 --> 18:58.500]  в другую сторону, чтобы было понятно, что с чем сокращается. Вот эти s-ки сокращаются в s-той
[18:58.500 --> 19:03.740]  степени. Ну что у нас тут еще провалилось? А, смотрите, е в s-той степени. Тут е в s-той,
[19:03.740 --> 19:08.300]  тут е в s-той, но только они в разных местах. То есть я как-нибудь вот так сейчас. Чпок,
[19:08.300 --> 19:13.860]  чпок. Ну и сразу вот этот тоже зачерикаю, потому что оно пропало вместе со всеми сократившимися.
[19:13.860 --> 19:22.780]  Так, что ж у меня осталось-то? У меня осталось 1 плюс о малой от единицы в s-той на 2. Просто
[19:22.780 --> 19:30.660]  двойка осталась в первой степени, а в знаменателе осталось 1 плюс о малой от единицы на коренец 2ps.
[19:30.660 --> 19:40.820]  По-моему, так. Дорогие друзья, смотрите, какая казуистика идиотская. Вот вы только прочувствуете,
[19:40.820 --> 19:46.020]  пожалуйста, какая идиотская казуистика. Ну, во-первых, не приведи господи, вы мне сейчас
[19:46.020 --> 19:50.340]  сократите вот это и скажете, что это 1 плюс о малой от единицы в s-той степени.
[19:50.340 --> 19:57.900]  Значит, внимание, вот это о малой от единицы нам дано свыше. Это конкретная функция,
[19:57.900 --> 20:03.260]  которая присутствует в формуле стиринга. Мы ее не помним, но она нам дана, и мы не вольны ее
[20:03.260 --> 20:09.180]  перевыбрать. Это конкретная какая-то функция, стремящаяся к нулю. А вот это о малой от единицы,
[20:09.180 --> 20:14.740]  оно в нашей власти. Мы можем хоть минус 1 взять, например, при маленьких s, помните? Мы любое о
[20:14.740 --> 20:20.500]  малой от единицы тут можем выбрать. А вот это оно конкретное, поэтому никаких сокращений тут точно
[20:20.500 --> 20:26.100]  не приходится делать. Дальше вы мне скажете, ну слушайте, ну чем вы вообще занимаетесь? Тут 2 делится
[20:26.100 --> 20:34.500]  на корень из 2 ps. Вроде как это очевидно меньше единицы. Ну, понимаете, я, конечно, могу сапеллировать
[20:34.500 --> 20:41.540]  к какому-то более, скажем так, аккуратному виду формулы стирлинга, то есть вот этого малой от
[20:41.540 --> 20:46.940]  единицы, конечно, можно конкретизировать. Если его конкретизировать, постараться, то, наверное,
[20:46.940 --> 20:54.060]  окажется, что, в общем, вот это вообще не нужно. Ну не исключено, что 2 на корень из 2 ps вот это вот
[20:54.060 --> 21:00.180]  забьет. Но поскольку я не знаю, заранее не говорил вам соответствующий вид формулы стирлинга какое,
[21:00.180 --> 21:07.660]  тут о малой от единицы. Но вы понимаете, что теоретически может, например, случиться,
[21:07.660 --> 21:13.540]  что при s не превосходящих миллиона, ну там, например, я говорю идиотскую вещь, но представьте,
[21:13.540 --> 21:18.780]  что при s не превосходящих миллиона, вот это данное нам с высшего малой от единицы,
[21:18.780 --> 21:25.500]  присутствующее в формуле стирлинга, вдруг окажется равным, ну я не знаю, минус, сейчас я напишу,
[21:25.500 --> 21:35.260]  минус 0, 9, 9, 9, 9. Ну что есть вот такое? Ну может оно оказаться таким, покуда не сказано иного,
[21:35.260 --> 21:40.220]  но почему нет, это правда. Потому что хотите, чтобы вы понимали вот этот анализ. Если вдруг
[21:40.220 --> 21:45.580]  такое несчастье случается, то когда вы к единице вот это прибавляете, вы получаете что-то типа 0,
[21:45.580 --> 21:51.820]  там много нулей, ну в конце единичка, много нулей, в конце единичка. Но когда вы на это делите,
[21:51.820 --> 21:59.260]  у вас же дофига в числитель вылезает, и оно уже может корнемых 2 ps не компенсироваться. Вот
[21:59.260 --> 22:06.140]  за этим я только и написал вот этого малой от единицы. Ну там, где вот этого малой от единицы вот
[22:06.140 --> 22:10.260]  так, не дай бог, навредит, я его просто выберу минус единицы, у меня все будет правильно.
[22:10.260 --> 22:19.700]  Поняли, да, где нужен подбор вот этого малого от единицы, теоретически. Все, это конечно меньше
[22:19.700 --> 22:26.660]  одного при всех s. Если мы достаточное количество раз вот этого малой от единицы положим равным,
[22:26.660 --> 22:32.700]  например, минус один, все будет все хорошо. Конечно, начиная с какого-то момента эта штука
[22:32.700 --> 22:39.180]  перестанет парить точно, и тогда, ну мы до этого момента положим где-то 1, а начиная с этого момента
[22:39.180 --> 22:56.100]  просто выехали. До момента, пока эта штука парит. Когда парка закончилась,
[22:56.420 --> 23:06.060]  так понятно. В общем, это такая чисто аналитическая казуистика, которая в данной оценке прям ну так
[23:06.060 --> 23:11.460]  натягом. Проще, наверное, было сказать формулу стиринга в более явном виде, успокоиться,
[23:11.460 --> 23:15.980]  никакого малого от единицы вообще не писать. Мне хотелось просто, чтобы вы дальше тоже это
[23:15.980 --> 23:23.700]  воспринимали адекватно, дальше это уже будет по делу. Слушайте, но на самом деле мы доказали,
[23:23.700 --> 23:32.420]  как я и обещал в сущности, чуть больше. Мы доказали теорему «давайте штрих»,
[23:32.420 --> 23:58.900]  который утверждает, что если для данного s число n таково, что c из n по s на 2 в степени 1
[23:58.900 --> 24:09.780]  минус c из s по 2 меньше единицы, то r от ss больше чем n. То есть теорема, которая выше,
[24:09.780 --> 24:14.740]  она является просто следствием. Мы подставили вот такое конкретное n, и у нас получилось,
[24:14.740 --> 24:21.460]  что это неравенство выполняется. Сейчас, друзья, понимаете, почему эта теорема верна? Мы же вроде
[24:21.460 --> 24:26.460]  этим ровно и пользовались. Нам нужно было просто, чтобы вот эта величина была меньше единицы. Мы это
[24:26.460 --> 24:29.980]  проверили, и у нас получилось, что r от ss больше чем n, чем вот эта величина.
[24:33.980 --> 24:40.460]  И уж то из доказательства не видно. Видно, да? Видно, конечно. Ну, давайте я тут все сотру.
[24:40.460 --> 24:59.140]  Ну, грешно. А? Видно, да? Вы понимаете, да, как этим походиться? Ну, это такой слепой
[24:59.140 --> 25:04.620]  программистский совсем подход. Такой совсем быдло подход. То есть это не ФПМИшный подход,
[25:04.620 --> 25:11.420]  конечно. Это даже не знаю, чей, не хочу никого обижать, но точно не ФПМИшный. Ну,
[25:11.420 --> 25:17.820]  просто допускайте цикл тупой. Ищете максимальное n, при котором для данного s все еще выполняется
[25:17.820 --> 25:25.220]  вот это неравенство. То есть для каждого s такой подход, конечно, даст лучшее n, чем то,
[25:25.220 --> 25:30.420]  что написано здесь, потому что фиг знает, что это за умалые от единицы. А вот мы можем прямо
[25:30.420 --> 25:35.700]  при каждом s вычислить оптимальное n в рамках такого подхода. Другое дело, что мы доказали,
[25:35.700 --> 25:40.180]  что в качестве этого оптимального n подойдет вот такая функция от s, и это здорово с точки
[25:40.180 --> 25:46.820]  зрения вечности. Не с точки зрения конкретики, там, которая вот на обозримом горизонте возникает,
[25:46.820 --> 25:53.660]  а в вечности там, ну, где-то после миллиарда становится вот так. Да, ну, математика,
[25:53.660 --> 25:58.700]  она же про вечности в конечном-то счете, а не только про сию минуту. Но сию минуту, вот,
[25:58.700 --> 26:11.260]  пожалуйста, такой общий подход. Так, теперь новая теорема. Ну, можно было даже вот так сделать,
[26:11.260 --> 26:16.820]  сказать, что это теорема 1, а вот будет теорема 2, и у нее тоже будет свой штрих. Нет, я лучше не
[26:16.820 --> 26:23.060]  так сделаю. Я напишу теорему 2 штрих сразу, а потом наоборот, как следствие, выведу из нее теорему.
[26:23.060 --> 26:38.180]  Можно? Значит, теорема 2 штрих звучит так. Для любых n и s, r от ss больше чем c из n,
[26:38.180 --> 26:50.580]  не так, чем n, минус c из n по s на 2 в степени 1 минус c из s. Сейчас, нам надо сначала осознать
[26:50.580 --> 26:56.180]  интуитивно, почему это вообще лучше, чем то, что было. Ну, что вот утверждается? Вам дано какое-то
[26:56.180 --> 27:05.980]  число s, и вы опять занимаетесь быдло кодингом? Вы просто подбираете такое n, при котором вот эта
[27:05.980 --> 27:12.860]  разность максимальна, правда? Для данного s подбираете такое n, для которого разность максимальна.
[27:12.860 --> 27:19.020]  Нет, ну, мы пока не доказали, откуда вытекает теорема. Ну, пусть она верна, но вот вы верите,
[27:19.020 --> 27:26.740]  что она верна. Если она верна, вы понимаете, что надо вот так вот сделать, да? Почему теоретически
[27:26.740 --> 27:32.220]  следствие, которое я пока не писал, должно быть лучше? Почему оно может оказаться лучше, скажем так?
[27:32.220 --> 27:39.700]  Потому что здесь мы использовали неравенство c меньше единицы, да? Но представьте, что здесь c
[27:39.700 --> 27:48.380]  меньше единицы. Ну, круто, да? Все замечательно. Вот для такого n, вот эта штука будет меньше единицы,
[27:48.380 --> 27:53.260]  мы возьмем вот этот n, сюда напишем, вычтем из него единицу, а от н-ка по-прежнему останется
[27:53.260 --> 28:03.700]  такого вида, согласны? То есть отсюда вот это точно следует. Вы понимаете, почему, да? Беря в качестве n
[28:03.700 --> 28:09.780]  вот такую величину и подставляясь туда, вы тут получаете меньше единицы, то есть будет больше,
[28:09.780 --> 28:19.820]  чем n-1, а n само оно такое. То есть отсюда вот это следует. Но может быть следует больше, потому что,
[28:19.820 --> 28:25.820]  понимаете, здесь-то мы хотели, чтобы это было меньше единицы, а здесь нам хватит, чтобы это было
[28:25.820 --> 28:34.220]  меньше, чем n пополам, например. Чувствуете разницу? Ну, то есть можно n увеличить, наверное,
[28:34.220 --> 28:40.580]  чуть-чуть хотя бы, чтобы это было меньше единицы, а n пополам, и за счет этого тут может какая-то
[28:40.580 --> 28:45.940]  оптимальность появиться. Короче, следствие я вам напишу сразу, а потом докажу и то и другое.
[28:45.940 --> 28:55.540]  Следствие трагическое. Правда, что... Но, тем не менее, все идеи нам нужно изучить. Тут,
[28:55.540 --> 29:03.100]  скорее, важны идеи, но следствие тоже важно, хотя они трагические. Следствие трагическое,
[29:03.100 --> 29:12.820]  вот такое. 1 плюс о малое от единицы s поделить на e, 2 в степени s попало. Ха-ха. Пропал корень из
[29:12.820 --> 29:20.620]  2, знаменатель. Что, конечно, хорошо. Почти в полтора раза лучше. Но, понятно, что это трагедия,
[29:20.620 --> 29:25.340]  потому что мы же до 4 в степени s отнюдь не дотянули. 4 в степени s — это верхняя граница,
[29:25.340 --> 29:31.900]  которую мы доказывали в прошлый раз. Ну, вот те, кто не был в прошлый раз, не помнят, но дайте
[29:31.900 --> 29:40.460]  я вот тут напишу. В прошлый раз мы доказали, что r от ss не превосходит 4 в s, будет 1 на корень
[29:40.460 --> 29:48.260]  из ps, ну и тоже, конечно, 1 плюс о малое от единицы. Вот так. Ну, там формула Стирлинга. Мы доказали,
[29:48.260 --> 29:57.340]  что это не больше, чем c из 2s-1 по s, а оно вот имеет такую асимптотику — 2s-2 по s. А 1 плюс
[29:57.340 --> 30:04.700]  о малое от единицы — какая разница? Понимаете, ну, ну, подправьте на единичку, от этого малость-то
[30:04.700 --> 30:08.780]  не изменится, будет просто другое у малого от единицы. Вот привыкните к тому, что у малого — это
[30:08.780 --> 30:15.900]  значит, существует какая-то функция. В анализе говорят, что писать о малой от единицы в неравенствах
[30:15.900 --> 30:22.700]  неграмотно. Ну, как бы да. Но я же объяснил, что это значит. Вот дословно это значит,
[30:22.700 --> 30:27.420]  что существует функция, стремящаяся к нулю, такая, что если сюда подставить, то неравенство будет
[30:27.420 --> 30:32.420]  выполнить. Но если выполнено такое, то и строгое тоже. С какой-то чуть-чуть другой функцией будет
[30:32.420 --> 30:38.420]  выполняться. Ладно, это просто вам для сравнения. То есть, улучшение предыдущей оценки в корень из
[30:38.420 --> 30:44.060]  двойки раз — это ничто по сравнению с тем продвижением, которое хотелось бы сделать,
[30:44.060 --> 30:48.620]  если мы желаем достичь верхней границы. Но при этом мы понятия не имеем. Может, надо, наоборот,
[30:48.620 --> 30:55.260]  верхнюю границу тянуть сюда. Понимаете, да? То есть, кто знает. Поэтому вот пытаемся что-то сделать.
[30:55.260 --> 31:04.220]  Значит, теорема два штрих, как доказывается. Гениально, но мы уже такую идею воспринимали
[31:04.220 --> 31:08.060]  с вами в прошлом семестре. Это называется альтернирование, когда вы что-то выбираете
[31:08.060 --> 31:17.700]  случайно, а потом исправляете грехи этой случайности. Ну что, мы снова выбираем случайный граф G от N1
[31:17.700 --> 31:24.340]  вторая. Вот прямо с этим N, которое фигурирует в формулировке теоремы. Выбираем случайный граф,
[31:24.340 --> 31:30.780]  берем вот эту величину X, которая равна количеству вредных подмножестных свершинок, то есть,
[31:30.780 --> 31:36.620]  тех, которые образуют либо клику, либо независимое множество. Знаем, что ее
[31:36.620 --> 31:42.540]  математическое ожидание. Ну вот оно. C из N по S на 2 в степени 1 минус C из S по 2,
[31:42.540 --> 31:49.500]  правильно? Вот. Что отсюда следует? Отсюда следует, что существует граф на N вершинах,
[31:49.500 --> 31:59.660]  пока что. Граф на N вершинах, давайте я подчеркну, на N вершинах. Такой, что его... Ой, какое
[31:59.660 --> 32:13.260]  его. Его вот эта X от G не превосходит C из N по S на 2 в степени 1 минус C из S по 2. Согласно?
[32:13.260 --> 32:18.020]  Но если среднее равно этому, то есть какой-то конкретный объект, на котором сама величина не
[32:18.020 --> 32:27.260]  превосходит это. Ну это вроде очевидно. Вот. Не превосходит чего? Что за величина? Это вот еще
[32:27.260 --> 32:35.700]  раз. Количество плохих S вершинных подмножестных. Оно вот такое небольшое. Давайте возьмем вот в
[32:35.700 --> 32:40.500]  этом графе G, который мы нашли. Ну, ярко бы нашли он существует, значит, мы его найдем полным перебором.
[32:40.500 --> 32:47.820]  Вот давайте в этом найденном нами графе из каждого вредного множества на S вершинах
[32:47.820 --> 32:56.700]  удалим одну вершину, любую. То есть возьмем и из G, из G выкинем
[32:59.060 --> 33:04.100]  по любой вершине одной из каждого
[33:04.100 --> 33:09.260]  S множества,
[33:11.260 --> 33:14.820]  которое образует либо клику, либо антиклику,
[33:14.820 --> 33:20.300]  которое, давайте так скажем, либо образует клику,
[33:25.260 --> 33:29.140]  либо является независимым, чтобы не употреблять слово антиклика,
[33:29.140 --> 33:33.140]  который не очень официальный, либо является независимым.
[33:33.140 --> 33:39.540]  Ну, то есть из графа G мы удалим не больше, чем столько вершин.
[33:39.540 --> 33:45.620]  Но у нас останется вот столько вершин, как минимум.
[33:45.620 --> 33:52.620]  Ну, когда мы из G удалили по вершине из каждого S клики, из каждого S антиклики,
[33:52.620 --> 33:55.700]  но, естественно, в новом графе новые клики не появились.
[33:55.700 --> 34:04.580]  То есть, получилась игра в G штрих, у него количество вершин больше,
[34:04.580 --> 34:10.180]  чем N-C из N по S на 2 в степени 1-C из S по 2,
[34:10.180 --> 34:18.460]  у него больше, чем столько вершин, и уже в нем вообще нет ни одной S клики,
[34:18.460 --> 34:23.020]  и вообще нет ни одного независимого множества на S вершинах,
[34:23.020 --> 34:27.580]  что нам и хотелось, согласно определению числа Рамсе.
[34:27.580 --> 34:35.340]  Мы доказали теорему два штриха. Понятно?
[34:39.340 --> 34:43.060]  Мы сначала выбрали случайный граф, в нем мало плохих объектов,
[34:43.060 --> 34:48.140]  мы совсем их кокнули, остался уже не совсем случайный граф,
[34:48.140 --> 34:52.620]  а случайный, из которого что-то убрали. И вот уже этот подправленный граф,
[34:52.620 --> 34:58.020]  он такой, как нам нужно. У него вроде как меньше вершин, чем в исходном,
[34:58.020 --> 35:01.100]  но вот мы понимаем, что из этого должно быть чуть лучшее следствие.
[35:01.100 --> 35:05.620]  И мы сейчас его докажем. Мне кажется, что вот здесь тоже
[35:05.620 --> 35:13.780]  достаточно информации, чтобы его доказать. Так, доказательства теоремы два.
[35:18.780 --> 35:22.140]  Как следствие из теоремы два штрих.
[35:22.140 --> 35:29.140]  Не, ну что, мы просто берем в качестве N вот эту самую величину.
[35:29.140 --> 35:35.140]  Ну давайте возьмем просто S делить на E умножить на 2 в степени S пополам.
[35:35.140 --> 35:38.140]  Потому что, друзья, я чуть-чуть недокомментировал, может быть,
[35:38.140 --> 35:43.140]  когда говорил про теорему один. Вот здесь она еще светится.
[35:43.140 --> 35:51.140]  Вот вы поняли, что в теореме один ничего лучшего даже в плане константы сделать нельзя.
[35:51.140 --> 35:57.140]  Тут все впритык получилось. Ну то есть, если вы попробуете вот тут что-то улучшить
[35:57.140 --> 36:03.140]  в рамках теоремы один, умножить на что-нибудь, на одну целую, не знаю, там одну тысячную.
[36:03.140 --> 36:11.140]  Она вот в этом месте возведется в S-ую степень. Попадет сюда, ни с чем не сократившись,
[36:11.140 --> 36:16.140]  и ни фига у вас не будет меньше единицы. Я забыл про это сказать, но вы понимаете теперь, да?
[36:16.140 --> 36:22.140]  То есть, константа вот в этой теореме один реально подобрана оптимально с точки зрения метода,
[36:22.140 --> 36:25.140]  с помощью которого эта теорема доказана.
[36:25.140 --> 36:30.140]  Сейчас мы увидим, что и вот эта константа подобрана оптимально, но уже в рамках вот этого подхода.
[36:30.140 --> 36:35.140]  Значит, мы берем просто в качестве, ну я не знаю, нам можно целую часть нарисовать,
[36:35.140 --> 36:41.140]  чтобы было все-таки целое число. Понятно. Ну, в общем, берем N вот какого-то такого вида.
[36:41.140 --> 36:48.140]  Что у нас получается? У нас получается, что вычитаемая вот эта C из N по S на 2 в степени 1
[36:48.140 --> 36:54.140]  минус C из S по 2, чем оно отличается от той величины, которой у нас была?
[36:56.140 --> 37:01.140]  Вот на что оно отличается, во что, во сколько раз?
[37:01.140 --> 37:06.140]  Я почему стал комментировать теорему один? Это имеет отношение к тому, что сейчас происходит.
[37:06.140 --> 37:11.140]  Мы убрали вот этот корень из двойки в знаменателе, правильно?
[37:11.140 --> 37:18.140]  Следите. Да, вот мы убрали корень из двойки. Вот тут он был, а тут его уже нет.
[37:19.140 --> 37:30.140]  Ну, то есть, как можно написать? Это равно, ему равно 2 на корень из двойки в S,
[37:30.140 --> 37:37.140]  поделить на 1 плюс о малой от единицы, и на корень из 2 S.
[37:38.140 --> 37:43.140]  Так, давайте на секунду еще на это поглядим, чтобы точно понимать, почему все правильно.
[37:43.140 --> 37:48.140]  Во-первых, вот этого нет, потому что здесь его нет.
[37:48.140 --> 37:53.140]  Вот тут оно было, 1 плюс о малой от единицы, а тут мы его не пишем.
[37:53.140 --> 37:58.140]  Ну, может оно и есть, конечно, потому что я ж целую часть...
[37:58.140 --> 38:01.140]  Ну ладно, ну давайте я напишу.
[38:01.140 --> 38:05.140]  Но это уже очень конкретно, о малой от единицы, которая просто получается
[38:05.140 --> 38:10.140]  заменой целой части на свой аргумент. Ну хорошо, пусть будет.
[38:10.140 --> 38:15.140]  Ну вот, ну это все не имеет значения. Вот мы целую часть просто
[38:15.140 --> 38:19.140]  возвели в S той степени, мы получили примерно вот это.
[38:19.140 --> 38:23.140]  Вот, почему? Потому что здесь был корень из двойки в степени S в знаменателе,
[38:23.140 --> 38:26.140]  а тут его уже нету, и он перекочевал, стало быть, в числитель.
[38:26.140 --> 38:30.140]  Он уже не сокращается. Числитель, как был корень из двойки в S-той,
[38:30.140 --> 38:33.140]  вот этот вот так и остался, ему не с чем сократиться.
[38:33.140 --> 38:41.140]  Вот, но это не страшно, потому что мы вычитаем вот эту величину.
[38:41.140 --> 38:45.140]  Сейчас вы понимаете, что мы ее вычитаем, да?
[38:48.140 --> 38:52.140]  Мы вычитаем вот эту величину из вот этой величины.
[38:54.140 --> 38:59.140]  Тут стоит S поделить на E корень из двойки в степени S,
[38:59.140 --> 39:04.140]  но там на 1 плюс о малое от единицы, потому что целая часть.
[39:04.140 --> 39:09.140]  А тут стоит корень из двойки в степени S, но отсутствует вот это S.
[39:15.140 --> 39:20.140]  Это уменьшаемое, а это вычитаемое. Вычитаемое бесконечно мало
[39:20.140 --> 39:25.140]  по сравнению с уменьшаемым, и тут и тут корень из двойки в S-той одинаковый,
[39:25.140 --> 39:29.140]  но тут S в числителе, а тут корень из двойки в знаменателе.
[39:29.140 --> 39:33.140]  Ну а вот эта вот фигня, она фигня, потому что целая часть, она отличается
[39:33.140 --> 39:36.140]  от своего аргумента на самом деле только на единичку,
[39:36.140 --> 39:39.140]  и когда вы это в S-той степени возведете, можно вот так написать,
[39:39.140 --> 39:41.140]  все равно будет правильно.
[39:44.140 --> 39:49.140]  Целая часть от быстрорастущей функции настолько мало отличается
[39:49.140 --> 39:52.140]  от самой этой быстрорастущей функции, что даже когда вы это возводите
[39:52.140 --> 39:55.140]  в S-той степени, а симптатика не меняется.
[39:58.140 --> 40:00.140]  Нужно пояснять, или это понятно?
[40:04.140 --> 40:07.140]  Ну просто вынести вот этот вот заскоп, там будет что-то 1 плюс 1
[40:07.140 --> 40:11.140]  поделить на 2 в степени S пополам, и вот это все в S-той степени.
[40:11.140 --> 40:13.140]  Ну понятно, что это стремится к единице.
[40:14.140 --> 40:17.140]  Это же не е, это очень быстро стремится к нулю.
[40:18.140 --> 40:24.140]  В общем, да, вычитаемое бесконечно мало по сравнению с уменьшаемым
[40:24.140 --> 40:28.140]  значит, а симптатика всей разности такая же, как а симптатика N.
[40:30.140 --> 40:32.140]  Ну а это то, что мы обещали.
[40:33.140 --> 40:36.140]  Вот получается уже 1 плюс O малое от единицы,
[40:36.140 --> 40:39.140]  и вот это 1 плюс O малое от единицы обусловлено тем,
[40:39.140 --> 40:41.140]  что мы отсюда вычитаем вот это еще.
[40:41.140 --> 40:45.140]  O малое от единицы уходит вот это после того, как мы вот это выносим за скобку.
[40:46.140 --> 40:51.140]  А в скобках остается там 1 поделить на S в степени 3 вторых что-то такое,
[40:51.140 --> 40:53.140]  в качестве O малого от единицы.
[40:55.140 --> 40:57.140]  Не знаю, понятно объясню?
[40:58.140 --> 41:00.140]  Вот, видите, как здорово, чуть-чуть улучшили.
[41:00.140 --> 41:04.140]  Ну, конечно, не очень здорово, но метод, вот этот метод альтернирования,
[41:04.140 --> 41:06.140]  он сам по себе интересен.
[41:06.140 --> 41:07.140]  Так.
[41:07.140 --> 41:11.140]  Для того, чтобы еще немножко улучшить оценку и оказаться на переднем крае науки,
[41:12.140 --> 41:16.140]  мы окажемся на переднем крае науки в отношении нижних оценок числа Рамсе
[41:17.140 --> 41:18.140]  в конечном счете.
[41:19.140 --> 41:21.140]  То есть, вот для того, чтобы на нем оказаться,
[41:22.140 --> 41:26.140]  надо изучить гораздо более, на самом деле, общезначимый метод,
[41:27.140 --> 41:29.140]  который работает, как мы увидим во многих заданиях,
[41:30.140 --> 41:34.140]  в том числе и в том числе и в том числе и в том числе и в том числе.
[41:34.140 --> 41:36.140]  Который работает, как мы увидим во многих задачах,
[41:37.140 --> 41:39.140]  не только для оценивания чисел Рамсе,
[41:40.140 --> 41:42.140]  это так называемая локальная лемма-ловоса.
[41:43.140 --> 41:46.140]  И ей будет посвящено много времени,
[41:47.140 --> 41:49.140]  как самостоятельному инструменту, в том числе,
[41:50.140 --> 41:54.140]  дающему вот современный рубеж знаний
[41:55.140 --> 41:57.140]  с точки зрения нижних оценок чисел Рамсе.
[41:58.140 --> 42:01.140]  Давайте сделаем вот отступление на эту историю.
[42:05.140 --> 42:08.140]  Локальная лемма.
[42:12.140 --> 42:15.140]  Ну, вам повезло, в отличие от многих ваших предшественников,
[42:16.140 --> 42:19.140]  и ловос у вас встречается прям очень плотно.
[42:20.140 --> 42:23.140]  Но многие ваши предшественники слушали топологический метод
[42:24.140 --> 42:25.140]  в конце первого семестра,
[42:26.140 --> 42:29.140]  и за сессией успевали забыть, что там был ловос.
[42:30.140 --> 42:32.140]  А у нас ловос был буквально на прошлой лекции.
[42:34.140 --> 42:35.140]  Это тот же самый ловос.
[42:36.140 --> 42:38.140]  Он придумал топологический метод,
[42:39.140 --> 42:41.140]  который позволил доказать гипотезу Кнезера,
[42:42.140 --> 42:45.140]  но он же доказал и локальную лемму в теории веронятностей,
[42:46.140 --> 42:47.140]  которая позволяет решать очень многие задачи
[42:48.140 --> 42:49.140]  комбинаторного дискретного анализа.
[42:50.140 --> 42:51.140]  Графов там и так далее.
[42:52.140 --> 42:53.140]  Гиперграфов.
[42:54.140 --> 42:55.140]  О чем идет речь?
[42:56.140 --> 42:57.140]  Давайте я сначала попробую на пальцах,
[42:58.140 --> 42:59.140]  а потом уже будут точные формулировки.
[43:00.140 --> 43:02.140]  Вот у нас есть эта известная история про то,
[43:02.140 --> 43:04.140]  что мы оцениваем вероятность
[43:05.140 --> 43:07.140]  какого-то объединения событий
[43:08.140 --> 43:09.140]  по суммой.
[43:13.140 --> 43:16.140]  А нау радость оказывается меньше единицы,
[43:17.140 --> 43:20.140]  и мы до этого делаем вот, что интересующий нас объект существует.
[43:21.140 --> 43:22.140]  Понятно в таком темпе, да?
[43:23.140 --> 43:24.140]  Но вот ровно сейчас мы так действовали.
[43:25.140 --> 43:27.140]  Вероятность объединения каких-то событий меньше одного,
[43:28.140 --> 43:30.140]  значит, существует, ну, например, такой граф,
[43:30.140 --> 43:31.140]  который обладает нужными нам свойствами,
[43:32.140 --> 43:35.140]  или существует еще что-нибудь, раскраска там какая-то и так далее.
[43:36.140 --> 43:37.140]  Вот это вот наш стандартный подкод,
[43:38.140 --> 43:39.140]  который позволяет избежать
[43:40.140 --> 43:42.140]  выписывания всей формулы включения и исключения,
[43:43.140 --> 43:45.140]  которая зачастую просто невычислима.
[43:46.140 --> 43:47.140]  Не в смысле логики, да?
[43:48.140 --> 43:50.140]  Невычислима в смысле, что фиг ее вычислишь.
[43:51.140 --> 43:52.140]  Ну так, с банальной точки зрения,
[43:53.140 --> 43:55.140]  найти формулу включения и исключения невозможно.
[43:56.140 --> 43:57.140]  Даже вот для этой задачи, про число Рамсе,
[43:57.140 --> 43:59.140]  но представляете, пересекать между собою события,
[44:00.140 --> 44:03.140]  одно из которых состоит в присутствии такой клики,
[44:04.140 --> 44:05.140]  а другое в присутствии секой клики.
[44:06.140 --> 44:07.140]  А как эти клики пересекаются,
[44:08.140 --> 44:10.140]  и там начнется куча случаев, как они могут пересекаться,
[44:11.140 --> 44:12.140]  мы умрем уже на этапе второго слагаемого.
[44:13.140 --> 44:14.140]  То есть вот это первая слагаемая,
[44:15.140 --> 44:17.140]  а второе – это там пересечение вот этих аитах попарные.
[44:18.140 --> 44:20.140]  Мы умрем на этапе вычисления этого второго слагаемого.
[44:21.140 --> 44:22.140]  Ну, а вот, например,
[44:22.140 --> 44:23.140]  как-то с этим хотелось бы бороться.
[44:24.140 --> 44:26.140]  Вот давайте я сейчас сформулирую
[44:27.140 --> 44:28.140]  так называемый симметричный случай,
[44:29.140 --> 44:30.140]  локальный леммо.
[44:31.140 --> 44:32.140]  Он гораздо более понятен для восприятия.
[44:33.140 --> 44:35.140]  И вы поймете, чем он как минимум теоретически лучше.
[44:36.140 --> 44:38.140]  Для того, чтобы его сформулировать,
[44:39.140 --> 44:42.140]  надо немножко договориться о терминологии вероятностной.
[44:43.140 --> 44:44.140]  Вы ее, конечно, знаете, но я не знаю,
[44:45.140 --> 44:46.140]  как это сделать.
[44:47.140 --> 44:48.140]  Ну, как это сделать?
[44:48.140 --> 44:50.140]  Немножко договориться о терминологии вероятностной.
[44:51.140 --> 44:53.140]  Вы ее, конечно, знаете, но я все-таки ее напомню.
[44:54.140 --> 44:58.140]  Значит, вот пусть у нас есть какое-нибудь событие А,
[44:59.140 --> 45:03.140]  а событие на каком-то там вероятностном пространстве,
[45:04.140 --> 45:08.140]  не важно, есть какие-то события B1 и так далее,
[45:09.140 --> 45:11.140]  B на том же пространстве.
[45:12.140 --> 45:15.140]  Есть А, и есть еще события B1B.
[45:15.140 --> 45:26.140]  Вот что значит А не зависит от совокупности этих событий?
[45:27.140 --> 45:29.140]  А не зависит от совокупности вот этих событий?
[45:36.140 --> 45:38.140]  Ну, по-простому я бы сказал так,
[45:38.140 --> 45:45.140]  что для любого I из I и так далее N,
[45:46.140 --> 45:52.140]  вероятность А при условии пересечения по I маленьким из I большого
[45:53.140 --> 45:56.140]  в БАИТах равняется вероятности А.
[45:58.140 --> 46:03.140]  То есть, по какому бы под множество, множество исходных событий
[46:03.140 --> 46:08.140]  мы не обуславливали, получится вероятность исходного события.
[46:09.140 --> 46:12.140]  Ну, вас, наверное, учили гораздо более продвинутым понятиям,
[46:13.140 --> 46:16.140]  типа независимость от сигма-алгебры там событий, что-нибудь такое.
[46:17.140 --> 46:18.140]  Нет? Не было такого.
[46:19.140 --> 46:21.140]  Ну, если не было, то и забейте, мне вот это вот определение достаточно.
[46:22.140 --> 46:26.140]  Если было, ну да, вот это более общее просто определение у вас было,
[46:27.140 --> 46:28.140]  а это гораздо более частный случай его же.
[46:33.140 --> 46:37.140]  Значит, такое вот, такое определение.
[46:38.140 --> 46:41.140]  То есть нам важно не просто, чтобы от каждого из них оно не зависело,
[46:42.140 --> 46:45.140]  а от пересечения любых двух, от пересечения любых трех там и так далее.
[46:46.140 --> 46:49.140]  Вот тогда мы говорим о независимости в совокупности, от совокупности.
[46:50.140 --> 46:53.140]  Так, что мне еще надо? Больше ничего не нужно.
[46:54.140 --> 46:59.140]  Значит, локальная лемма Ловеса, давайте теорема симметричной случай.
[46:59.140 --> 47:05.140]  Случай, симметричный случай, локальный лемма Ловес.
[47:06.140 --> 47:08.140]  Ставим lll, вполне стандартно.
[47:09.140 --> 47:13.140]  Она и по-английски lll, потому что все слова начинаются с l и по-английски тоже.
[47:14.140 --> 47:17.140]  Так, что отверждение такое?
[47:18.140 --> 47:20.140]  Вот у нас есть какие-то события по-прежнему.
[47:21.140 --> 47:22.140]  Их тоже.
[47:23.140 --> 47:25.140]  Штука, как вот в этой затравке. Тут затравка, да?
[47:25.140 --> 47:29.140]  Мы просто тупо оцениваем сумму и не можем выписать никакие больше слога.
[47:30.140 --> 47:31.140]  Ну, какие-то события.
[47:32.140 --> 47:42.140]  Давайте предположим, что зависимости между этими событиями, зависимости между этими событиями в каком-то смысле локализованы.
[47:43.140 --> 47:47.140]  Откуда термин локальная лемма? Они локализованы в следующем смысле.
[47:47.140 --> 47:54.140]  А, ну, сначала мы предположим, что для любого i вероятность аитова не больше, чем некоторое p.
[47:55.140 --> 47:59.140]  Из 0 давайте 1 выколем. Из 0 и 1.
[48:00.140 --> 48:04.140]  Ну, то есть, поверьте, вероятность каждого аитова меньше единицы, меньше либо равна единице.
[48:05.140 --> 48:07.140]  Но нам, конечно, хочется как можно лучше оценить их все.
[48:08.140 --> 48:09.140]  И вот мы их одинаково оценили.
[48:10.140 --> 48:13.140]  Понятно, что если вероятности сильно разные, то это не слишком хороший подход.
[48:13.140 --> 48:17.140]  Но это намек на то, что в конечном счете мы что-то похожее будем делать.
[48:18.140 --> 48:23.140]  Ну, тут же все вероятности всегда, вот в конкретных примерах, тут все вероятности были одинаковы.
[48:24.140 --> 48:27.140]  Ну, вот на самом деле мы как бы предполагаем, что они в общем одинаковые.
[48:28.140 --> 48:30.140]  Ну, не больше какого-то. Одного и того же p.
[48:31.140 --> 48:32.140]  Локализация зависимости.
[48:32.140 --> 48:52.140]  Значит, пусть опять же для любого и, аито не зависит ото всех остальных событий.
[48:53.140 --> 48:58.140]  Надо было сказать от совокупности всех остальных событий, потому что я напомнил именно это определение.
[48:58.140 --> 49:03.140]  Ну, когда я говорю не зависит ото всех остальных, это и предполагает, что не зависит от совокупности.
[49:04.140 --> 49:06.140]  Не зависит от совокупности всех остальных событий.
[49:07.140 --> 49:13.140]  Ну, естественно, не всех, а кроме не более d.
[49:15.140 --> 49:17.140]  D опять же общая для всех и.
[49:18.140 --> 49:25.140]  То есть существует такое общее число d, что для каждого и, аито если и зависит от чего-то,
[49:25.140 --> 49:30.140]  то вот количество этих зависимости не больше чем d. Они так вот локализованы.
[49:34.140 --> 49:36.140]  То есть можно себе представлять как бы такой граф.
[49:37.140 --> 49:38.140]  Вот мы потом графом и перейдем.
[49:39.140 --> 49:48.140]  Вот у вас какое-то аито, есть некоторое небольшое количество событий, их не больше чем d, которые могли бы повредить зависимость.
[49:48.140 --> 49:56.140]  Если мы рассмотрим все остальные, их там n-d-1 штука, вот этих вот оставшихся событий будет n-d-1.
[49:57.140 --> 49:59.140]  Тут d, тут 1 и вот тут n-d-1.
[50:00.140 --> 50:03.140]  Так вот ото всех этих событий в совокупности аито не зависит.
[50:05.140 --> 50:06.140]  Это условие.
[50:07.140 --> 50:08.140]  И так для каждого и.
[50:09.140 --> 50:16.140]  Здесь вот какие-то в окрестности аито небольшое количество событий, которые вредят, а остальные уже не вредят совсем.
[50:17.140 --> 50:19.140]  Тогда, а да, сейчас, пусть еще.
[50:22.140 --> 50:29.140]  Самое смешное, e на d, на d плюс 1, на p не превосходит единицы.
[50:31.140 --> 50:34.140]  А вот что такое e, число ребер в этом графе.
[50:35.140 --> 50:36.140]  Шучу, это число e.
[50:37.140 --> 50:39.140]  271, то самое.
[50:40.140 --> 50:41.140]  e это то самое e.
[50:42.140 --> 50:43.140]  Смотрите, основание натурального логарифма.
[50:44.140 --> 50:45.140]  Вот это не шучу.
[50:46.140 --> 50:49.140]  Значит, пусть e на d плюс 1, на p не превосходит единицы.
[50:51.140 --> 50:52.140]  Тогда вероятность.
[50:53.140 --> 51:02.140]  Ну, я могу вот так написать объединение по e от единицы до n аито меньше одного, чтобы была прям полная параллель с тем, что было в затравке.
[51:07.140 --> 51:08.140]  Давайте сравним.
[51:09.140 --> 51:12.140]  Вот смотрите, у нас в условии сказано, что вероятность аито не больше, чем p.
[51:12.140 --> 51:16.140]  То есть, вот здесь получилось бы вот так, не больше, чем pn, да?
[51:17.140 --> 51:26.140]  Если пользоваться вот этим предположением, то тривиальный подход, который мы с вами всегда использовали, он говорит о том, что вероятность объединения, она, конечно, не больше, чем pn.
[51:27.140 --> 51:30.140]  Вот если это, в свою очередь, меньше единицы, тогда все хорошо.
[51:31.140 --> 51:32.140]  Мы этим пользовались.
[51:33.140 --> 51:37.140]  А тут говорится, что надо с единицей не вот это pn сравнивать.
[51:38.140 --> 51:40.140]  А сравнивать только вот эти локальные зависимости.
[51:41.140 --> 51:43.140]  p умножить на d надо сравнивать с единицей.
[51:45.140 --> 51:49.140]  Ну, оно не то что и красоты, оно нужно, оно будет участвовать.
[51:50.140 --> 51:53.140]  Но согласитесь, что p и d гораздо важнее, чем e.
[51:54.140 --> 51:59.140]  Но это какие-то функции от нашего там какого-то общего параметра могут быть, какой есть задачи.
[52:00.140 --> 52:02.140]  Помните, как число Рамсея, там общий параметр, тс.
[52:03.140 --> 52:06.140]  Вот эти p и d, они могут быть какими-то сложными функциями от s.
[52:07.140 --> 52:09.140]  А е это константа, ну подумаешь, ну один на е или...
[52:10.140 --> 52:15.140]  В общем, это как раз неважно, если d гораздо меньше, чем n, как функция от того параметра.
[52:16.140 --> 52:22.140]  Ну, я не знаю, там n это 2 в степени s всего событий, 2 в степени s, например.
[52:23.140 --> 52:25.140]  А зависимости локальных, s.
[52:26.140 --> 52:33.140]  Ну, представляете, сравнить 2 в степени s на p с единицей или s на p, вот тут, s на p с единицей.
[52:34.140 --> 52:39.140]  Ну, наверное, это даст нам гораздо большую свободу по выбору p и s в конечном счете.
[52:41.140 --> 52:43.140]  Не, непонятно?
[52:44.140 --> 52:45.140]  Вот, по-моему, это очень круто.
[52:46.140 --> 52:51.140]  То есть, если зависимости локально мало, в окрестности каждого события мало зависимости,
[52:52.140 --> 52:56.140]  все остальное образует море вот этих событий, от которых аито и независит в совокупности.
[52:57.140 --> 53:01.140]  Если их локально мало, вот этих зависимости, то это, конечно, гораздо более сильный результат,
[53:01.140 --> 53:03.140]  чем тот, который дает обычный подход.
[53:04.140 --> 53:08.140]  Вот в этом смысл я хочу, чтобы вы его просто так сразу почувствовали.
[53:09.140 --> 53:20.140]  Так, но, но, но, давайте я чуть-чуть вас разочарую.
[53:21.140 --> 53:26.140]  Задача прочисла, задача, давайте так, задача прочисла Рамсея слишком зубастая.
[53:26.140 --> 53:30.140]  И даже вот этот мегаинструмент, который, как мы увидим, много чего дает на самом деле,
[53:31.140 --> 53:33.140]  конкретно в задаче про Рамсея дает мало.
[53:34.140 --> 53:36.140]  По крайней мере, про диагонального Рамсея.
[53:37.140 --> 53:40.140]  Вообще в задаче про Рамсея он дает много, мы это узнаем в следующий раз.
[53:41.140 --> 53:45.140]  Но в задаче про диагонального Рамсея гора порождает мыр.
[53:46.140 --> 53:50.140]  Это гора, мы это увидим, но конкретно для Рамсея это все-таки, к сожалению, мышь.
[53:50.140 --> 53:54.140]  Потому что теорема с номером 3, так, она какая?
[53:55.140 --> 53:57.140]  Она со штрихом, наверное, должна быть, если со симптотикой.
[53:58.140 --> 54:00.140]  Там, где асимптотика, там штрих вписался? Нет.
[54:01.140 --> 54:03.140]  По-моему, просто теорема, да?
[54:04.140 --> 54:06.140]  Где асимптотическая оценка, там штриха не было, правильно?
[54:07.140 --> 54:09.140]  Да, значит, теорема 3, которая без штриха, чтобы было понятно.
[54:10.140 --> 54:14.140]  Из локальной леммы самое лучшее, что можно вывести, к сожалению,
[54:14.140 --> 54:18.140]  это что Р от СС больше либо равняется 1 плюс о малое от единицы, но это как? Всегда.
[54:19.140 --> 54:25.140]  Так, тут будет корень из двух, поделить на Е, на С и на два в степени, С пополам.
[54:28.140 --> 54:31.140]  Чувствуете, как жизнь устроена трагично?
[54:33.140 --> 54:35.140]  Видите, как это работает?
[54:36.140 --> 54:38.140]  Вот так вот.
[54:38.140 --> 54:42.140]  Чувствуете, как жизнь устроена трагично?
[54:43.140 --> 54:46.140]  Еще раз на корень из двойки умножили, понимаете, да?
[54:47.140 --> 54:52.140]  То есть мат ожидания с выкидыванием, оно нам позволило умножить на корень из двойки тривиальный подход,
[54:53.140 --> 54:57.140]  а локальная лемма еще подчистила, еще на корень из двойки умножила,
[54:58.140 --> 55:01.140]  и опять вот основная симптотика, какая была, такая и осталась.
[55:01.140 --> 55:07.140]  Ну, естественно, да, надо еще вот сколько там, 2 С раз примерно.
[55:09.140 --> 55:13.140]  Или 3 С, да, 3 С раз надо еще на корень из двойки умножить.
[55:14.140 --> 55:19.140]  Для каждого С нужно доказать 3 С результатов, хорошо.
[55:22.140 --> 55:24.140]  Ой, какой кошмар.
[55:25.140 --> 55:29.140]  Это придется стереть, наверное, хотя оно могло бы помочь, но я, скорее всего, все равно не успею.
[55:29.140 --> 55:31.140]  Давайте слушайте, что я сделаю.
[55:32.140 --> 55:35.140]  Во-первых, план дальнейшей жизни на сегодня и на следующий раз,
[55:36.140 --> 55:38.140]  просто чтобы вы понимали, что мы будем делать.
[55:39.140 --> 55:45.140]  Сейчас я из вот этой вот локальной леммы, внимание, из вот этой, не доказываю ее,
[55:46.140 --> 55:48.140]  я не успеваю ее сейчас доказать, но я ее докажу потом.
[55:49.140 --> 55:52.140]  Значит, вот сейчас из этой локальной леммы, в симметричном виде,
[55:52.140 --> 55:54.140]  я выведу не вот это, а теорему со штрихом.
[55:55.140 --> 55:57.140]  Наверное, это максимум, что я успею.
[55:58.140 --> 56:00.140]  На сегодня.
[56:01.140 --> 56:04.140]  В следующий раз я из теоремы со штрихом выведу теорему 3.
[56:05.140 --> 56:07.140]  Ну, в общем-то, надо доказать.
[56:08.140 --> 56:12.140]  А потом приступлю, в некотором смысле, к доказательству симметричного случая.
[56:13.140 --> 56:15.140]  Я же обещал, что я его докажу, это все не без доказательства.
[56:15.140 --> 56:17.140]  Но я сделаю это хитро.
[56:18.140 --> 56:20.140]  Я сначала обобщу на несимметричную ситуацию,
[56:21.140 --> 56:23.140]  потом поясню, почему она крута, важна,
[56:24.140 --> 56:26.140]  и мы оценим очень мощно, оценим R3t, 3.5t.
[56:27.140 --> 56:29.140]  Помните, то, которое не найдено.
[56:30.140 --> 56:33.140]  И только после этого я уже докажу несимметричный случай,
[56:34.140 --> 56:36.140]  выведу из него локальную.
[56:37.140 --> 56:39.140]  Это в следующий раз.
[56:40.140 --> 56:42.140]  Вот, давайте посмотрим.
[56:42.140 --> 56:44.140]  Это в следующий раз.
[56:45.140 --> 56:48.140]  Давайте попробуем понять, как работает симметричный случай локальный леммо,
[56:49.140 --> 56:51.140]  чтобы получить теорему 3 штрих.
[56:52.140 --> 56:54.140]  Но чего, у нас аи-то это те же самые.
[56:55.140 --> 56:57.140]  Понимаете, мы снова берем g от n одна вторая.
[56:58.140 --> 57:00.140]  Тут-то ничего умного нет.
[57:01.140 --> 57:03.140]  Мы как брали случайный граф на n вершинах, так и берем.
[57:04.140 --> 57:06.140]  Это утверждение о том, что r от ss больше, чем n,
[57:07.140 --> 57:09.140]  коль скоро нечто.
[57:09.140 --> 57:11.140]  Ну как теорема 1 штрих, помните?
[57:12.140 --> 57:15.140]  c из n по s на 2 в степени 1 минус c из s под 2 меньше 1,
[57:16.140 --> 57:18.140]  следовательно, r от ss больше, чем n.
[57:19.140 --> 57:21.140]  Вот мы хотим что-то такое доказать.
[57:22.140 --> 57:24.140]  Берем опять случайный граф на n вершинах,
[57:25.140 --> 57:27.140]  как во всех предыдущих доказательствах, двух, да?
[57:28.140 --> 57:30.140]  Берем случайный граф на n вершинах.
[57:31.140 --> 57:35.140]  Там есть события те же самые, a1 и так далее, a c из n по s.
[57:36.140 --> 57:38.140]  Ну, товарищи, ну вы помните, что это за события аи-то?
[57:39.140 --> 57:41.140]  Аи-то состоит в том, что it по счету множество
[57:42.140 --> 57:44.140]  либо клика, либо независим.
[57:45.140 --> 57:47.140]  Так, живы?
[57:48.140 --> 57:50.140]  Хорошо, да?
[57:51.140 --> 57:53.140]  Сейчас будет еще лучше.
[57:54.140 --> 57:56.140]  Это же вы тоже помните, правда?
[57:57.140 --> 57:59.140]  Это вот то, что у нас было.
[58:00.140 --> 58:02.140]  Вероятность каждого it-ого 2 в степени 1 минус c из s под 2.
[58:03.140 --> 58:05.140]  Какая прелесть.
[58:05.140 --> 58:08.140]  То есть вот это вот, это у нас играет роль p.
[58:09.140 --> 58:11.140]  Вот этого p из теоремы.
[58:12.140 --> 58:14.140]  Все вероятности равны одному и тому же числу.
[58:15.140 --> 58:17.140]  Не превосходят, равны слова. Они вообще все одинаковые, слава богу.
[58:18.140 --> 58:20.140]  Вот они такие. Это p.
[58:21.140 --> 58:23.140]  Давайте поймем, что такое d? Чего оно не больше?
[58:24.140 --> 58:26.140]  Или чему оно равно?
[58:27.140 --> 58:29.140]  Чему оно равно в точности?
[58:30.140 --> 58:32.140]  Вот смотрите, вот мы взяли большую сардельку.
[58:32.140 --> 58:34.140]  У этого множества вершин.
[58:35.140 --> 58:37.140]  Взяли какую-то подсардельку, а прямое и тяно на s вершинах.
[58:38.140 --> 58:40.140]  Ей соответствует событие, состоящее из графов,
[58:41.140 --> 58:43.140]  у которых вот здесь либо клика, либо независимое множество.
[58:44.140 --> 58:51.140]  От каких оставшихся событий, для каких сардельчик размера s?
[58:52.140 --> 58:54.140]  Вот это конкретное зависит.
[58:55.140 --> 58:59.140]  Если они пересекаются по одной вершине,
[58:59.140 --> 59:04.140]  то, очевидно, зависимости не будет, потому что нет общего ребра.
[59:05.140 --> 59:07.140]  Друзья, вот это понятно?
[59:08.140 --> 59:11.140]  Надо, чтобы было общее ребро, иначе зависимости точно нет.
[59:12.140 --> 59:15.140]  Ну, зависимость нас интересует совокупная, вот в этом смысле.
[59:16.140 --> 59:19.140]  Поэтому, как только ребро общее появляется, она, конечно, появляется тоже.
[59:20.140 --> 59:24.140]  То есть, для того, чтобы появилась зависимость, достаточно, чтобы появилось общее ребро.
[59:24.140 --> 59:42.140]  То есть, это равно сумма по t от двойки до s-1 c из s по t на c из n-s по s-t.
[59:43.140 --> 59:45.140]  Вот так.
[59:46.140 --> 59:48.140]  Так, поняли, что я сделал, да?
[59:49.140 --> 59:52.140]  Я просто для данного множества мощности s посчитал количество других множеств мощности s,
[59:52.140 --> 59:55.140]  которые его пересекают хотя бы по двум элементам.
[59:56.140 --> 59:58.140]  Хотя бы по двум.
[59:59.140 --> 01:00:02.140]  Сначала выбрал, да, общие элементы, а потом выбрал те, которые снаружи.
[01:00:03.140 --> 01:00:06.140]  Сейчас, друзья, ну, это простая комбинаторика, это понятно, да?
[01:00:07.140 --> 01:00:09.140]  То есть, d, вот оно такое, да.
[01:00:10.140 --> 01:00:15.140]  Ну, видите, тут суммирование почти от нуля, то есть, ну, конечно, получается очень много зависимостей.
[01:00:16.140 --> 01:00:20.140]  Вот это вот мое пояснение про то, что p на d меньше, чем p на n, оно правильное.
[01:00:20.140 --> 01:00:22.140]  Оно меньше, чем p на n.
[01:00:23.140 --> 01:00:26.140]  Но не сильно меньше из-за того, что суммирование начинается почти с нуля.
[01:00:27.140 --> 01:00:28.140]  Я понятно говорю?
[01:00:29.140 --> 01:00:33.140]  Вот, поэтому, собственно, гора рождает мышь в конечном счете, и в этом мы убедимся.
[01:00:34.140 --> 01:00:39.140]  Ну, то есть, теорема три штрих, она выглядит вот так.
[01:00:39.140 --> 01:01:07.140]  Пусть для данного s число n таково, то e на сумма по t от двойки до s минус один.
[01:01:07.140 --> 01:01:15.140]  T из s по t на c из n минус s по s минус t плюс один.
[01:01:16.140 --> 01:01:29.140]  Умножить на два в степени 1 минус c из s по 2 меньше либо равно единице, тогда r от ss больше это v.
[01:01:30.140 --> 01:01:33.140]  И приступаем к выдлу кодингу.
[01:01:34.140 --> 01:01:35.140]  Понятно, как приступаем.
[01:01:35.140 --> 01:01:38.140]  Понятно, как приступаем, гоним опять по циклу и все.
[01:01:39.140 --> 01:01:44.140]  Вот, наша цель доказать в следующий раз, что отсюда вытекает вот это.
[01:01:45.140 --> 01:01:49.140]  Я, поскольку у меня еще пять минут есть, я немножко вот эту бяку упрощу.
[01:01:50.140 --> 01:01:53.140]  Так, друзья, все поняли, как формулировка получилась, да?
[01:01:54.140 --> 01:01:58.140]  Ну, e на d плюс 1 на p, вон как там прям точность.
[01:01:59.140 --> 01:02:06.140]  Зависимости посчитали, вероятность посчитали, теперь осталось проверить, что при данном выборе n получается не больше единицы.
[01:02:07.140 --> 01:02:09.140]  Я немножко ухудшу оценку.
[01:02:10.140 --> 01:02:16.140]  Смотрите, товарищи, я скажу, что d, оно на самом деле не большее.
[01:02:17.140 --> 01:02:19.140]  Воспринимаете еще, нет?
[01:02:20.140 --> 01:02:22.140]  Сейчас вот это было понятно, нет?
[01:02:23.140 --> 01:02:24.140]  Не понятно откуда это?
[01:02:25.140 --> 01:02:26.140]  Сейчас вот что d такое, это понятно?
[01:02:27.140 --> 01:02:34.140]  Ну, все, вот у нас локальная лемма, она говорит, пусть у нас вероятность событий чем-то ограничена, вот каким-то p, вот у нас это p, а?
[01:02:35.140 --> 01:02:37.140]  Они же ограничены этим, равны даже этому.
[01:02:38.140 --> 01:02:43.140]  Пусть зависимости не больше, чем d, вот мы посчитали количество зависимости, их точно не больше, чем столько, да?
[01:02:44.140 --> 01:02:52.140]  Вот, подставляем в e на d плюс 1 на p не превосходит единицы, вот это основное условие, из которого вытекает то, что нам нужно.
[01:02:52.140 --> 01:03:04.140]  Нужно нам именно, чтобы вероятность была меньше 1, а если вероятность меньше 1, то r, s, s больше, чем n, то есть вот эта вот теорема, все она, я считаю, доказана как следствие из LLL.
[01:03:05.140 --> 01:03:06.140]  Да?
[01:03:07.140 --> 01:03:10.140]  Вот, я хочу чуть-чуть упростить вот эту биаку сейчас, вот чем я занимаюсь.
[01:03:11.140 --> 01:03:16.140]  Я хочу сказать, что d не только этому равно, оно действительно этому равно, можно написать попроще.
[01:03:17.140 --> 01:03:20.140]  Смотрите, чего не превосходит d, чтобы потом считать было легче.
[01:03:20.140 --> 01:03:22.140]  Чего точно d не больше?
[01:03:23.140 --> 01:03:30.140]  Нам нужно как-то оценить количество множеств мощности s, которые с данным имеют хотя бы две общих вершины.
[01:03:31.140 --> 01:03:47.140]  Давайте оценим так, выберем эти две общих вершины, просто две, а потом добавим любые s в минус 2, любые из оставшихся на минус 2.
[01:03:47.140 --> 01:03:52.140]  То есть вот смотрите, мы выбрали две вершины, все, у нас уже пересечение по двум есть.
[01:03:53.140 --> 01:04:05.140]  А оставшиеся s в минус 2, чтобы набрать s в сумме, мы выбираем не отсюда, а может быть и отсюда тоже, вот эти две, и потом любые s в минус 2, в том числе, возможно, цепляющие наше множество.
[01:04:07.140 --> 01:04:10.140]  Понимаете, что это именно оценка уже сверху.
[01:04:10.140 --> 01:04:15.140]  Ну потому что мы некоторые s-элементные множества таким образом посчитаем по несколько раз.
[01:04:17.140 --> 01:04:22.140]  Зафиксировали эти две вершины, потом сколько-то, или наоборот вот эти две вершины, потом сколько-то.
[01:04:24.140 --> 01:04:30.140]  То есть мы как бы автоматом получаем такую оценку, что вот эта величина не больше, чем вот эта.
[01:04:31.140 --> 01:04:34.140]  Увидеть это непосредственно не каждому дано.
[01:04:34.140 --> 01:04:36.140]  Это действительно непосредственно не очевидно.
[01:04:37.140 --> 01:04:40.140]  Ну я же доказал это неравенство, значит это не больше этого.
[01:04:43.140 --> 01:04:44.140]  Понятно говорю, да?
[01:04:45.140 --> 01:04:54.140]  Вот, поэтому я вот это трансформирую вот в это, c из s под 2, на c из n минус 2 по s в минус 2.
[01:04:55.140 --> 01:04:58.140]  И в следующий раз я буду проверять, что у нас есть в этой вершине.
[01:04:59.140 --> 01:05:01.140]  На c из n минус 2 по s в минус 2.
[01:05:02.140 --> 01:05:07.140]  И в следующий раз я буду проверять, что беря в качестве n вот эту вот величину,
[01:05:08.140 --> 01:05:14.140]  и подставляя ее именно вот в этот вариант пиоремы, мы таки получим не больше единицы.
[01:05:17.140 --> 01:05:22.140]  Ну а значит автоматом в этом варианте тем более получим не больше единицы, потому что это не больше этого.
[01:05:26.140 --> 01:05:27.140]  Вот.
[01:05:28.140 --> 01:05:29.140]  На сегодня все.
