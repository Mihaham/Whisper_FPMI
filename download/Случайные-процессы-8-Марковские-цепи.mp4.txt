[00:00.000 --> 00:14.240]  Так, давайте начинать. Значит, мы с вами в прошлый раз закончили первое задание. Приступаем ко второму
[00:14.240 --> 00:24.160]  заданию. Мы во втором задании будем изучать с вами очень важную тему, называется Марковские
[00:24.160 --> 00:43.240]  случайные процессы. Это чрезвычайно важный класс процессов. На основе этих моделей,
[00:43.240 --> 00:49.320]  то есть на основе них построены очень многие модели, которые встречаются, ну трудно назвать
[00:49.320 --> 00:57.480]  области приложений, математики, где бы ни встречались марковские случайные процессы. Это тебе и физика
[00:57.480 --> 01:08.080]  с матфизикой, это биология, химия, это экономика, финансовая математика, айти-технология, машинное
[01:08.080 --> 01:15.400]  обучение построено, искусственный интеллект. Чрезвычайно важная вещь, будем это изучать
[01:15.400 --> 01:24.120]  все оставшееся время до середины мая. Значит, мы с вами уже до этого изучили случайные процессы,
[01:24.120 --> 01:31.440]  ну разные классы случайных процессов. Стационарные, эргодические, гауссовские процессы, крупные классы у
[01:31.440 --> 01:41.240]  нас были, да, мы изучали их свойства. И чем по сути отличаются все эти классы? Классы отличаются тем,
[01:41.240 --> 01:47.360]  как соотносятся между собой сечения. Вот у гауссовских процессов, у них сечение образует нормальные
[01:47.360 --> 01:53.240]  векторы, вот такое как бы ограничение на сечение, да, там, эргодичность там одного, стационарности там
[01:53.240 --> 01:59.360]  другое, как-то эти множества могут пересекаться между собой. Вот есть марковские случайные процессы,
[01:59.360 --> 02:07.880]  здесь как, какая связь между сечениями придумана. Значит, марковские процессы это естественное
[02:07.880 --> 02:18.520]  обобщение динамических систем на стахастику. Вот в динамических системах, если все детерминировано,
[02:18.520 --> 02:26.520]  то у тебя начальное состояние полностью определяет будущую траекторию, которая часто описывается в
[02:26.520 --> 02:34.240]  виде дифференциальных уравнений, ну там в частных или прямых производных. Случайные процессы, у них не
[02:34.240 --> 02:41.400]  всегда состояние описывает однозначно будущее, но как правило это не так, потому что процесс случайный,
[02:41.400 --> 02:49.000]  и зная настоящее ты не знаешь будущее. Так вот, марковские процессы это процессы, в которых
[02:49.000 --> 02:56.920]  настоящее состояние, оно может быть и не определяет однозначно траекторию, но оно однозначно
[02:56.960 --> 03:04.540]  определяет распределение будущего, то есть как поведет себя. То есть оно однозначно определяет
[03:04.540 --> 03:13.120]  распределение будущей траектории, начиная от этого момента, то есть это однозначный детерминизм
[03:13.120 --> 03:20.360]  на распределение не на поведение траектории, а на распределение ее поведения. Вот давайте мы перейдем
[03:20.360 --> 03:27.360]  к некоторому определению. Он более формальным. Значит, определение первое, что случайный
[03:27.360 --> 03:46.360]  процесс x от t, t из t большого, называется Марковским или процессом Маркова, если вероятность
[03:46.360 --> 03:55.160]  x от t, n плюс 1 принадлежать к какому-то множеству, ну бареллевскому множеству, да, потому что
[03:55.160 --> 04:00.600]  это событие должно быть измеримым. Например, здесь может стоять меньше x какого-то или принадлежность
[04:00.600 --> 04:09.560]  к какому-то отрезку. Ну в общем случае бареллевское множество. x от t, n равняется x, n запятая и так далее,
[04:09.560 --> 04:21.040]  x от t, 0 равна x, 0. Если вот эта вероятность условная равна вот такой, вероятности x, t, n
[04:21.040 --> 04:30.720]  плюс 1 принадлежность к тому же самому b при условии x, t, n равняется x, n. Видите, ну там для
[04:30.720 --> 04:39.320]  любых, для любых n, значит, больше либо равных, не знаю чего, единицы, наверное, или нуля, ну да,
[04:39.320 --> 04:51.760]  содержательные единицы, для любых t1 и так далее, t, n из t, для любых b, бареллевское множество из r,
[04:51.760 --> 05:05.840]  для которых вот эти условные вероятности определены. И смотрите, что эта формула нам, о чем она говорит.
[05:05.840 --> 05:14.960]  Вероятность того, что в будущем процесс попадет в это множество при условии того, что в эти моменты
[05:14.960 --> 05:23.440]  он побывал в этих состояниях, равно вероятности попасть туда же при условии, что в ближайший
[05:23.440 --> 05:29.760]  к этому момент времени он побывал в этом состоянии. То есть мы игнорируем то, что мы называем прошлое,
[05:29.760 --> 05:41.640]  вот это прошлое, это прошлое, это настоящее, это будущее. Вероятность в будущем попасть сюда при
[05:41.640 --> 05:48.240]  известном настоящем и прошлом равна вероятности попасть сюда при известном настоящем. Прошлое
[05:48.240 --> 05:57.800]  игнорируется. Вот не у всех процессов это так, но если это так, то процесс называется марковским.
[05:57.800 --> 06:06.960]  Распределение в его будущем зависит только от настоящего, но не от будущего. Сразу предупреждаю,
[06:06.960 --> 06:13.520]  что вот эти слова, будущее, прошлое, настоящее, это как бы наша интуиция, но нельзя трактовать эти
[06:13.520 --> 06:21.720]  слова слишком вольно. Например, нельзя в этом определении вот сюда приписать принадлежность,
[06:21.720 --> 06:30.400]  скажем, БН. Здесь стоит равно ХН конкретному какому-то состоянию. Здесь нельзя писать
[06:30.400 --> 06:36.640]  принадлежность Б, потом это выкидывать и здесь оставлять принадлежность Б. То есть настоящая,
[06:36.960 --> 06:44.280]  принадлежность процесса целому множеству. Это будет неравносильно этому и вообще неверно,
[06:44.280 --> 06:50.720]  это не марковские процессы. Здесь стоит именно равно. То есть, вероятностная будущая процесса
[06:50.720 --> 06:58.400]  определяется конкретным состоянием в этот момент времени. Если это выполнено для любых N,
[06:58.400 --> 07:08.800]  для любых T, для любых B, процесс называется марковским. Вот такое вот обобщение. Как я сказал,
[07:08.800 --> 07:15.880]  это чрезвычайно важная модель, она используется очень много где. По себе могу сказать, например,
[07:15.880 --> 07:23.040]  что такая крупная область, как искусственный интеллект, по части принятия решений, теория
[07:23.040 --> 07:30.920]  ихр, экономика. Вот они построены на этих моделях. Машины обучения с подкреплением вообще целиком и
[07:30.920 --> 07:40.200]  полностью основывают свой фундамент на этой вещи. Так что тех из вас, кто будет заниматься машинным
[07:40.200 --> 07:45.840]  обучением с подкреплением, принятием решением, искусственным интеллектом, это модель номер один.
[07:45.840 --> 07:54.880]  С этого все начинается. Так что это очень важная вещь. Значит, сразу же напишем теорему у нас будет.
[07:54.880 --> 08:03.080]  Без доказательства она пойдет. Она довольно техническая. Значит, всякий процесс независимыми
[08:03.080 --> 08:28.560]  приращениями является марковским. Висимыми приращениями является марковским процессом.
[08:28.560 --> 08:34.520]  Например, Винеровский процесс. Он марковский. Давайте сразу напишу. Винеровский, то есть
[08:34.520 --> 08:49.360]  следовательно, Винеровский процесс, марковский. Плассоновский процесс, тоже марковский. Обратное,
[08:49.360 --> 09:04.000]  вообще говоря, неверное. Не всякий марковский процесс имеет независимые приращения. Из того,
[09:04.000 --> 09:21.240]  что процесс марковский не следует, что у него независимые приращения. Но у вас будет много задач
[09:21.240 --> 09:27.720]  на марковские процессы. Там вы увидите, и эти примеры легко получаются. Там вы увидите,
[09:27.720 --> 09:34.800]  когда процесс марковский, но у него приращения не являются независимыми. Но в эту сторону точно
[09:34.800 --> 09:40.600]  верно. Этим вы можете пользоваться. Теорему даю вам без доказательства. Значит, как же
[09:40.600 --> 09:47.000]  классифицируются марковские случайные процессы? То есть, оказывается, есть классификация. Очень
[09:47.000 --> 09:55.560]  понятная, простая классификация марковских процессов. Дело в том, что вот эти состояния,
[09:56.520 --> 10:03.880]  значения, которые принимает процесс, называются множеством состояний. И есть еще множество,
[10:03.880 --> 10:09.720]  которое принимает время. И вот в зависимости от того, какие эти множества, состояния и времени,
[10:09.720 --> 10:23.800]  различают несколько классов марковских процессов. То есть, пустес — это множество значений марковского
[10:23.800 --> 10:36.080]  процесса X. T — это множество времен марковского процесса. Ну да, множество времен T. Множество
[10:36.080 --> 10:47.120]  времен, на котором определен процесс. Первое. Если S дискретно, принимает какое-то конечное
[10:47.120 --> 10:55.840]  или счетное число значений дискретно, и T дискретно, например, 0, 1, 2, да, вот так вот,
[10:55.840 --> 11:07.360]  то тогда такие процессы называются дискретными цепями маркова, дискретные цепи маркова,
[11:07.360 --> 11:19.800]  которые мы начнем изучать уже сегодня. Второе. Если S дискретно, T непрерывно — это называются
[11:19.800 --> 11:32.600]  непрерывные цепи маркова. Мы их тоже будем изучать чуть позже. То есть цепи — это когда S множество
[11:32.600 --> 11:37.720]  состояний дискретно. Вот это первое слово — дискретно-непрерывно — относится ко времени.
[11:37.720 --> 11:50.240]  Третье. Бывает, когда S непрерывно, T дискретно. Вот. Такие процессы мы специально изучать не
[11:50.240 --> 12:01.040]  будем, но примером являются, например, случайные блуждания. Пример случайные блуждания. То есть,
[12:01.040 --> 12:08.720]  когда время дискретно, то есть 0, 1, 2, 3, и в каждый момент времени случайный процесс может принимать
[12:08.720 --> 12:16.320]  значение прыгать на какую-то случайную величину с непрерывным распределением. Поэтому ты не по
[12:16.320 --> 12:22.240]  дискретной какой-то сетке прыгаешь, а по непрерывной шкале. Так что это вот пример таких процессов.
[12:22.240 --> 12:29.360]  Случайные блуждания. Помните, у нас на какой-то лекции было доказательство того, что случайные
[12:29.360 --> 12:34.240]  блуждания определенного вида, они сходятся к Винеровскому процессу. Вот эти случайные
[12:34.240 --> 12:44.960]  блуждания, они вот в этом ножице держатся. Вот. И четвертое, когда S непрерывно и T непрерывно. Вот.
[12:44.960 --> 12:51.780]  Ну, такие, я не знаю, названия существуют для таких или нет. Я называю их просто непрерывные
[12:51.780 --> 13:04.620]  марковские процессы или марковские функции. Все, когда непрерывно. Непрерывные марковские
[13:04.620 --> 13:17.700]  процессы, функции. Такой класс мы будем с вами тоже изучать. Это будет последняя наша лекция в
[13:17.700 --> 13:25.700]  этом курсе, случайные процессы. Мы ее целиком и полностью, скорее всего, посвятим вот этим вот
[13:25.700 --> 13:36.780]  процессам марковским. Вот. Значит, мы приступаем к изучению дискретных цепей Маркова. Значит,
[13:36.780 --> 13:44.940]  эта модель вам должна быть близкая, понятна. Она близка к модели конечного автомата. Помните,
[13:44.940 --> 13:50.260]  что это такое? Такой граф с кружочками, стрелочками. Да, и мы перемещаемся по нему. Вот тут сейчас то
[13:50.260 --> 13:56.620]  же самое начнется. Только все это в стахастике. Вот. Будем изучать как бы случайные прыжки по
[13:56.620 --> 14:04.020]  таким графам и какими свойствами такие графы обладают. Вот. Значит, на основе марковских
[14:04.020 --> 14:10.140]  цепей строится теория машинного обучения, динамическое программирование. Работают различные
[14:10.140 --> 14:17.820]  алгоритмы. Очень полезный, например, алгоритм ранжирования страницы гуглом. Когда вы в поисков
[14:17.820 --> 14:23.460]  вбиваете, он вам страницы ранжирует. Вот. То, как он это делает, мы будем это проходить на основе
[14:23.460 --> 14:27.780]  закона больших чисел для дискретных цепей марков. У нас теория такая будет, мы ее доказывать будем.
[14:27.780 --> 14:34.300]  Вот. На основе этого работает алгоритм гугла ранжирования. Об этом можно почитать, например,
[14:34.300 --> 14:41.580]  в книжке под редакцией Гастинькова Александра. Ну, и там много авторов, нассоавторов. Лекции
[14:41.580 --> 14:51.100]  по случайным процессам. Вот. Сейчас, кстати, вышло новое издание этой книжки буквально недели две
[14:51.100 --> 15:02.220]  назад в издательстве в РСС. Вот. Ну, можно найти старую версию, которая была напечатана в РИО МФТИ.
[15:02.220 --> 15:14.060]  Итак, тема. Начинаем дискретные
[15:14.060 --> 15:30.480]  марковские цепи. Дискретные цепи маркова. Значит, первое, что мы сделаем, мы сформулируем для этого
[15:30.480 --> 15:36.160]  класса марковских процессов эквивалентное определение, с которым просто проще работать и проще
[15:36.160 --> 15:43.160]  исследовать. Во-первых, давайте мы будем считать для простоты, что t, так как множество t дискретно,
[15:43.160 --> 15:58.080]  что t это 0, 1, 2 и так далее. Вот. Ну, натуральный число с нулем. Вот. И, по-моему, я тоже самое делаю
[15:58.080 --> 16:09.040]  для s. Нет? А, нет, не обязательно. То есть, будем считать вот так. Так. Ну, хорошо. Значит,
[16:09.040 --> 16:16.480]  определение давайте введем, что последовательность. Ведь если t дискретно, значит, процесс это
[16:16.480 --> 16:22.400]  последовательность. Вспоминаем первую самую лекцию. Если t дискретно, значит, процесс это последовательность.
[16:22.400 --> 16:32.240]  Значит, последовательность xn. Ну, то есть, там будет удобно писать xn. Не x, а t в скобочках n,
[16:32.240 --> 16:42.360]  где t равно n, а xn, как последовательность мы обозначаем. Давайте от нуля. А, я тут от нуля
[16:42.360 --> 16:47.840]  начинаю. Давайте от нуля. Спасибо. Значит, последовательность называется... Ну, я буду
[16:47.840 --> 16:57.680]  сокращать дискретной Марковской цепью. Дискретной цепью Маркова. Если... Значит, тут такая вероятность
[16:57.680 --> 17:09.840]  xmn... Сейчас. Мне бы как-нибудь... Нет. Давайте здесь. Или не важно. Ну ладно. Пусть будет mn. Поменьше
[17:09.840 --> 17:22.040]  обозначения. Значит, x маленькое mn при условии, что xmn-1 равняется xmn-1, запятая и так далее,
[17:22.040 --> 17:31.960]  x большое m0 равняется x0 равно... Ну, это вот наш момент, вот эти t, но так как они целые, поэтому я
[17:31.960 --> 17:45.240]  использую буквы для целых чисел. mn. Вероятность xmn равняется xmn при условии, что xmn-1 равняется
[17:45.240 --> 17:53.400]  xmn-1. Вот x большое это наш процесс, случайная величина, а x маленькое это значение этого x
[17:53.400 --> 18:01.000]  большого, а не из множества состояний. Если вот это верно для любых n, каких там больше либо равно
[18:01.000 --> 18:12.520]  2 получается для любых там x0 и так далее xmn из s множество состояний. Ну и для любых вот
[18:12.520 --> 18:20.560]  этих вот времен, правда упорядоченных, естественно, m0 меньше либо равно m1 меньше либо равно и так далее
[18:20.560 --> 18:26.680]  mn. Какие-то могут совпадать, но тогда, правда, x должны соответствующий совпадать. В принципе,
[18:26.680 --> 18:31.640]  можно здесь и строгие неравенства написать, все эквивалентно. Вот для любых вот этих всех,
[18:31.640 --> 18:40.360]  для которых вот эти условные вероятности существуют или определены. Дело в том,
[18:40.360 --> 18:48.240]  что, в принципе, процесс не обязан в момент m0 проходить через x0. Может быть, он так хитро
[18:48.240 --> 18:54.520]  устроен, что ни при каких условиях в момент m0 он не пройдет через это состояние. Ну, значит,
[18:54.520 --> 18:59.840]  такого равенства для него не будет. То есть это равенство, но справедливо для всех случаев,
[18:59.840 --> 19:05.040]  когда вот эти вероятности определены существуют. То есть реально, когда x может пройти через
[19:05.040 --> 19:17.920]  эти состояния в эти моменты времени. Вот такая вот оговорка. Так, ну вот. Значит, вот эти m0,
[19:17.920 --> 19:23.680]  m1 и так далее, они могут быть совершенно произвольными числами вот отсюда. Ну,
[19:23.680 --> 19:33.560]  например, m0 может быть 5, m1 может быть 10, какая-нибудь mn-1-100, mn может быть там 200. Они
[19:33.560 --> 19:40.120]  не обязательно упорядоченные, увеличиваются на единичку. Они могут быть просто вот произвольными,
[19:40.120 --> 19:46.680]  лишь бы вот такими. Вот. И это определение, значит, если они вот произвольные и упорядоченные,
[19:46.680 --> 19:51.640]  тогда это называется дискретной цепи Маркова. Это эквивалентно тому, что у нас было для общих
[19:51.640 --> 19:57.960]  марковских процессов, но просто вот переформулированное для дискретной ситуации,
[19:57.960 --> 20:05.480]  для дискретных цепей Маркова. Но на самом деле вот эта вещь, это можно показать, вот это
[20:05.480 --> 20:13.320]  определение, оно эквивалентно другому определению. Это уже содержательное замечание, что последовательность
[20:13.320 --> 20:29.280]  xn называется дискретной цепью Маркова, если вот что, смотрите, вероятность xn равно xn при
[20:29.280 --> 20:42.160]  условии, что xn-1 равно xn-1 и так далее, x0 равняется x0, равно xn равняется xn при условии,
[20:42.160 --> 20:54.560]  что xn-1 равняется xn-1, но там для любых n иксов, вот, для любых n иксов, для которых это все
[20:54.560 --> 21:01.200]  определено. Но здесь, смотрите, моменты времени идут по порядку, 0, 1, 2 и так далее, а здесь,
[21:01.200 --> 21:06.960]  то есть увеличиваются на единицу моменты времени, а здесь они не увеличиваются на единицу,
[21:06.960 --> 21:16.200]  что m0 может быть 5, m1 может быть 100, вот здесь, а здесь идут по порядку. Вот это является частным
[21:16.200 --> 21:22.840]  случаем вон того, так это очевидно, но вот оказывается, это можно доказать, и это будет
[21:22.840 --> 21:29.440]  задачей в вашем втором задании, это легко доказать, что на самом деле, если выполнено вот это для
[21:29.440 --> 21:38.520]  любых x и n, то тогда выполнено вон то, для любых вот этих вот штук, то есть отсюда следует вот это,
[21:38.520 --> 21:44.720]  хотя вот это кажется как бы частным случаем того, но на самом деле это эквивалентно, если это выполнено
[21:44.720 --> 21:52.680]  для любых n иксов, то выполнено и то определение, то есть определение штрих равносильно просто
[21:52.680 --> 22:06.640]  определению, это задача из второго задания, вот это вы сами сделаете, вот, а мы когда как,
[22:06.640 --> 22:12.840]  иногда нам будет удобно вот это считать, иногда нам будет удобно то считать, это мы уже будем сами
[22:12.840 --> 22:20.560]  смотреть, как нам удобно, ну хорошо, мы сейчас дальше чем определение не продвинулись, какие же все-таки
[22:20.560 --> 22:27.640]  есть свойства теперь, давайте их изучать, ну первое, что мы сделаем вообще, когда мы изучаем какие-то
[22:27.640 --> 22:32.040]  случайные процессы, первое, что надо сделать, изучить семейство конечномерных распределений,
[22:32.040 --> 22:38.320]  потому что это самая главная характеристика любого случайного процесса, знаешь семейство
[22:38.320 --> 22:48.080]  распределений, знаешь все про процесс, вот мы давайте посмотрим, какова структура этих семейства
[22:48.080 --> 22:53.960]  конечномерных распределений, то есть мы рассмотрим вот такую вероятность, вероятность того,
[22:53.960 --> 23:05.000]  что xm0 равен x0, кстати еще говорят, что в момент m0 процесс находится в состоянии x0, такие слова еще
[23:05.000 --> 23:12.880]  используются, xm1 равняется x1 и так далее, можно писать m0, можно писать 0, здесь кстати точно не важно,
[23:12.880 --> 23:25.200]  ну x0, x1 они тут произвольны, xmn равняется xn, вот взяли произвольные сечения xm0, xm1, xmn,
[23:25.200 --> 23:34.000]  для, ну без потери общности считаем, что m0 меньше чем m1, меньше чем mn, то есть они упорядочены,
[23:34.000 --> 23:43.400]  вот чему будет равна такая вероятность, давайте поймем, значит, смотрите, что мы сделаем, мы вот так
[23:43.400 --> 23:47.960]  запишем, то есть, ну а что у нас есть, у нас есть просто определение, ну что мы можем еще сделать,
[23:47.960 --> 23:54.320]  нам нужно сводить к условным вероятностям и пользоваться определением, выкидывать прошлое,
[23:54.320 --> 24:00.440]  оставляя только настоящее, ну давайте это будем делать, возьмем самый последний, самый последний
[24:00.440 --> 24:06.200]  момент времени, сечение в самый последний момент времени, нарисуем черту, а все остальное выкинем в
[24:06.200 --> 24:20.000]  условия, xmn-1 равно xn-1 и так далее, xm0 равно x0, вот и умножить на вероятность того, что мы в условия
[24:20.000 --> 24:34.120]  выбросили, mn-1 равняется xn-1 и так далее, xm0 равно x0, вот, всем понятно, что я сделал, вероятность
[24:34.120 --> 24:41.920]  A при условии B умножить на вероятность B, это есть вероятность их пересечения, то есть вероятность
[24:41.920 --> 24:47.480]  того, что вот это все через запятую записано, понятно, это просто формула условной вероятности,
[24:47.480 --> 24:55.560]  здесь записано, но смотрите, с чем фишка-то, в том, что так как процесс Марковский, вот это все прошлое,
[24:55.560 --> 25:03.360]  мы отсюда выкидываем и вероятность не изменится, так что у нас будет вероятность xmn равно xn при
[25:03.360 --> 25:12.560]  условии mn-1 равно xn-1 и все остальное, а все остальное это в общем-то то же самое, что у нас было,
[25:12.560 --> 25:22.640]  но только на 1x меньше и мы для него можем то же самое сделать и получим вероятность xmn-1 равняется
[25:22.640 --> 25:36.640]  xn-1 при условии, что xmn-2 равно xn-2 и у нас останется вероятность уже начиная от xmn-2 и вот так мы
[25:36.640 --> 25:44.080]  будем продолжать до самого последнего p, а какой будет? вот такой, здесь уже не для чего черту рисовать,
[25:44.080 --> 25:57.160]  мы на нем остановимся, вот мы с вами получили формулу для распределения произвольного вектора
[25:57.160 --> 26:09.600]  из сечений и что мы видим по этой формуле, то что конечномерное распределение определяется
[26:09.600 --> 26:21.280]  двумя вещами, это одномерным распределением и вероятностями перехода между состояниями в
[26:21.280 --> 26:27.960]  различные моменты времени, вот как, но это логично, если у тебя все определяется настоящим,
[26:27.960 --> 26:33.400]  тогда как находить вероятность того, что процесс куда-то попадет в будущее, ты берешь вероятность
[26:33.400 --> 26:38.680]  того, что находится в таком-то настоящем, умножаешь его на вероятность перейти из этого настоящего в
[26:38.680 --> 26:43.520]  какое-то новое настоящее, потом на вероятность перехода из этого настоящего в новое настоящее
[26:43.520 --> 26:52.400]  и так далее и так далее, как бы по цепочке, поэтому цепи, вот, итак, конечномерные распределения
[26:52.400 --> 26:57.600]  определяются двумя вещами, одномерными распределениями и вероятностями перехода,
[26:57.600 --> 27:03.320]  и в связи с тем, что здесь возникает одномерное распределение вероятности перехода, мы с вами
[27:03.320 --> 27:22.200]  введем два вспомогательных обозначения, значит, P и T G T от M N, значит, по определению будем считать,
[27:22.200 --> 27:36.280]  что это вероятность того, что X в момент N равен G при условии, что в момент M он был равен I, вот,
[27:36.280 --> 27:50.360]  то есть это вероятность перехода из состояния I в момент M в состояние G в момент N, вот, вот такую
[27:50.360 --> 27:55.640]  вещь ведем, ну, соответственно, можно там тогда эту формулу написать вот в этих терминах, это понятно,
[27:55.640 --> 28:06.200]  но главное то, что вот такая штука нам потребуется, еще мы ведем P и от N, это будет просто вероятность
[28:06.200 --> 28:20.800]  того, что процесс в момент N находится в состоянии I, вот, вектор из этих P называется распределением
[28:20.800 --> 28:29.840]  в момент N, потому что он будет содержать в себе несколько компонент, это будет вероятность того,
[28:29.840 --> 28:36.880]  что он принимает значение 0 в момент N, состояние 1 в момент N, ну, и так далее, ну, какие там состояния,
[28:36.880 --> 28:43.720]  если они 0, 1, 2 и так далее, то такие, вот, главное то, что как бы совокупность таких P для разных I,
[28:43.720 --> 28:51.120]  для разных состояний, она определяет распределение на множество состояний в момент N, вот, а это
[28:51.120 --> 28:58.160]  вероятность перехода, значит, мы будем с вами работать только с ситуациями, когда вот эти
[28:58.160 --> 29:05.680]  вероятности условные, они существуют для всех M и N, ну, естественно, M меньше либо равно N,
[29:05.680 --> 29:12.880]  или любых E и G, как я оговорился в самом начале, конечно, могут быть такие процессы, которые,
[29:12.880 --> 29:19.200]  например, не могут в момент M проходить через I, но мы не будем с вами рассматривать такие ситуации,
[29:19.200 --> 29:25.920]  хотя это никакое несодержательное препятствие на самом деле, то есть теоремы, которые мы будем
[29:25.920 --> 29:31.640]  доказывать, они с небольшой оговоркой все равно остаются верны, но не хотелось бы сейчас вот
[29:31.640 --> 29:37.520]  зацикливаться на этом техническом, на технической проблеме, давайте мы будем просто для простоты
[29:37.520 --> 29:46.920]  считать, что в любой момент M мы можем быть в принципе в E, вот, ну, а если это для каких-то
[29:46.920 --> 29:54.520]  процессов не так, то их можно рассмотреть отдельно и, в общем-то, все равно большинство
[29:54.520 --> 30:00.200]  утверждений, которые мы сделаем, они будут все равно справедливыми, вот, а так рассматривать их
[30:00.200 --> 30:05.160]  просто отдельно нужно. Хорошо, значит, мы вели вот эти обозначения, теперь смотрите,
[30:05.160 --> 30:13.000]  P и T житое, вот я не зря так сделал, сразу что хочется делать? Матрицу составить, да? Что-то
[30:13.000 --> 30:20.800]  и T житое, A и T житое, B и T житое, давайте матрицу составим вот из этих чисел, матрица P, это матрица
[30:20.800 --> 30:29.000]  из P и T житых МН, но, видите, тут еще МН есть, поэтому эта матрица зависит от пары, то есть паре МН
[30:29.000 --> 30:37.000]  сопоставляется матрица, которая содержит вот это для всех И и жи, вот, это матрица перехода,
[30:37.000 --> 31:01.560]  от момента М к моменту Н, матрица перехода. Ну и сразу же ведем P от N как вектор,
[31:01.560 --> 31:13.800]  вектор, значит, вектор P, ну там кто, если они занумерованы, вот эти И, скажем, 0, N, P1, N, если
[31:13.800 --> 31:20.440]  S состояние тоже состоит из чисел 0, 1, 2 и так далее, вот так проще всего, это будет распределение
[31:20.440 --> 31:30.560]  вероятностей на S в момент N, вектор P, значит, векторы по умолчанию считаем столбцами,
[31:30.560 --> 31:37.240]  матрицами-столбцами, дальше у нас будут некие векторно-матричные вид принимать формулы,
[31:37.240 --> 31:42.520]  не зря же я матрицу ввел, значит, где-то здесь уже линейная алгебра должна появиться,
[31:50.440 --> 31:59.240]  так, ну давайте поизучаем эти вещи, как они взаимосвязаны, что это вообще такое, значит,
[31:59.240 --> 32:06.360]  смотрите, вот это матрица, давайте посмотрим, что такое вообще, во-первых, ее компоненты это
[32:06.360 --> 32:15.080]  вероятности, так, вероятности принадлежат значениям от 0 до 1, значит, все числа этой матрицы лежат
[32:15.080 --> 32:30.040]  от 0 до 1, дальше, вот такая сумма вероятность того, что x в момент N равно g, по всем g из S,
[32:30.040 --> 32:40.520]  при условии, что m равно i, вот эта вещь равна единице, согласны, что тут стоит вероятность, сумма
[32:40.520 --> 32:45.760]  вероятностей событий, которые не пересекаются, либо ты в момент N находишься там, скажем, в нуле,
[32:45.760 --> 32:51.840]  либо в единице, либо в двойке и так далее, сумма по всем это единица, ну где-то-то ты находишься
[32:51.840 --> 33:00.280]  в момент N, правильно, где-то ты находишься, значит, вероятность равна единице, но это есть P и gt mn,
[33:00.280 --> 33:10.120]  значит, получается сумма по всем g, P и gt равна единице, это означает, что сумма чисел в каждой строке равна
[33:10.120 --> 33:17.120]  единице, сумма чисел в первой строке равна единице, во второй строке равна единице и так далее, вот такая
[33:17.120 --> 33:26.920]  матрица, у нее все компоненты от 0 до 1 и сумма чисел в каждой строке равна единице, такие матрицы
[33:26.920 --> 33:34.240]  с такими свойствами называются, ну или мы будем называть стахастическими матрицами, матрица
[33:34.240 --> 33:41.920]  называется стахастической, если все ее компоненты от 0 до 1, включая, возможно, 0 и 1 и сумма компонентов
[33:41.920 --> 33:49.960]  в каждой строке от 0 до 1, у нас может оказаться так, что счетное число состояний, ну матрица, вы понимаете,
[33:49.960 --> 33:55.520]  будет такая бесконечная, бесконечная матрица, а вот эта сумма, это ряд тогда получается, ну вот он
[33:55.520 --> 34:03.600]  обязательно сходится и его сумма равна единице, хорошо, дальше едем, теорема очень полезная,
[34:03.600 --> 34:12.200]  которую мы будем пользоваться, значит для любых n больше либо равно k, больше либо равно m, верно,
[34:12.200 --> 34:23.960]  что матрица вероятности перехода от момента n к моменту n, это есть произведение матрицы
[34:23.960 --> 34:31.960]  перехода от момента m к моменту k умножить на матрицу перехода от момента k к моменту n,
[34:31.960 --> 34:41.120]  вот какая формула интересная, вот так связаны вероятности перехода, значит доказательства,
[34:41.120 --> 34:52.720]  доказательства, ну доказательства практически очевидные, давайте мы возьмем итоизжитую
[34:52.720 --> 35:01.520]  компоненту вот этой матрицы слева, p, i, t, ж, t, m, n, что это такое по определению, это есть вероятность
[35:01.520 --> 35:12.760]  xn равно g при условии что xm равно i, и давайте мы запишем формулу полной вероятности для этой вещи,
[35:12.760 --> 35:21.000]  что условная вероятность это тоже вероятность, это тоже вероятность, а для всякой вероятности есть
[35:21.000 --> 35:29.400]  формула полной вероятности, давайте мы ее запишем, значит сумма, значит как там, какую я букву
[35:29.400 --> 35:42.400]  использую, l, пусть будет l, по всем l и z, вероятность того, что xn равняется g при условии xk равняется
[35:42.400 --> 35:59.880]  l, на xm равняется и, и умножить, я дальше продолжаю вот сюда, и умножить на вероятность того,
[35:59.880 --> 36:07.560]  что xk равно l, и не забываем, что эта вероятность при этом условии была, она никуда не пропадает,
[36:07.560 --> 36:16.280]  условная вероятность это тоже вероятность, вот таким образом мы обусловили, как говорят,
[36:16.280 --> 36:23.880]  по всем значениям вот этого промежуточного состояния между m и n, видите, k между m и n находится
[36:23.880 --> 36:30.800]  в момент времени, вот это просто формула полной вероятности, но процесс-то марковский,
[36:30.800 --> 36:37.520]  значит мы можем прошлое забыть, вот это прошлое в данном случае, и у нас получится,
[36:37.520 --> 36:48.400]  видите, что условная вероятность отсюда-сюда, а там оттуда-туда, значит если мы перейдем к нашим
[36:48.400 --> 36:56.760]  обозначениям, p и j, которые я сейчас стер, то мы получаем, значит что, ну давайте так,
[36:56.760 --> 37:09.400]  следовательно, p и j от m и n равняется сумме l из s, вероятность, а нет, не надо вероятности,
[37:09.400 --> 37:19.800]  в терминах значит p, откуда-куда, из, так-так-так-так-так, сейчас-сейчас, давайте вот с этой вероятностью
[37:19.960 --> 37:32.880]  из i в l от момента m к моменту k умножить на вероятность, теперь вот этот множитель,
[37:32.880 --> 37:47.840]  который здесь был первым, от l к j, от момента k к моменту n, получилось, ну а это и по формуле
[37:47.840 --> 37:56.680]  матричного умножения то, что здесь написано, все, классная теорема, да, очень легко доказывается,
[37:56.680 --> 38:04.040]  а таких в дискретных цепях и будет уйма, у нас будет мало таких вот больших сложных теорем здесь,
[38:04.040 --> 38:10.240]  в основном вот, по крайней мере, начало вот из таких вот будет стоять, в общем-то, ну знаете,
[38:10.240 --> 38:16.160]  основной инструмент это формула условной вероятности, формула полной вероятности и
[38:16.240 --> 38:20.840]  марковское свойство, ну вот это то, что можно прошлое выкидывать, все, если ты не знаешь,
[38:20.840 --> 38:25.320]  как решать задачу, ты берешь вот эти три вещи и комбинаторишь их там между собой,
[38:25.320 --> 38:31.000]  пока не доберешься до ответа, ну как бы, ну реально, вот все доказывается только с
[38:31.000 --> 38:41.760]  помощью этих трех, трех вещей, по большому счету, так, хорошо, значит, это мы доказали,
[38:41.760 --> 38:51.160]  так, да, значит, вот эта равенство, оно, конечно же, носит название, называется уравнением
[38:51.160 --> 39:13.760]  Колмогорова-Чепмана. Уравнением оно называется потому, что оно и может использоваться для
[39:13.760 --> 39:22.760]  нахождения вот этой вот матрицы вероятности перехода между произвольными m и n, если известны
[39:22.760 --> 39:29.760]  вероятности перехода перед более близкими по времени событиями, видите, mk и kn, то есть она
[39:29.760 --> 39:36.000]  используется для нахождения p, то есть это как бы формула, как бы, функциональное уравнение, если хотите, на p.
[39:36.000 --> 39:46.760]  Так, что из него следует, во-первых, смотрите, то, что вероятность, что вероятности перехода от
[39:46.760 --> 39:54.320]  нулевого к n-тому моменту времени, сейчас я напишу и будет перерыв, это есть, что такое, это есть p от 0-1,
[39:54.320 --> 40:11.520]  потом p-1-2, и так далее, p-n-1-n. Так что, если ты знаешь матрицы перехода от момента 0 к 1, от 1 к 2,
[40:11.520 --> 40:20.640]  и так далее, n-1-n, это могут быть разные матрицы, то тогда ты их перемножаешь в этом порядке и находишь
[40:20.640 --> 40:29.480]  матрицу перехода от момента 0 к моменту n. Вот эта формула, она, понимаете, чрезвычайно важна для
[40:29.480 --> 40:34.720]  практики, ну потому что, представляете, вот допустим, вам дали задачу, вам дали цепь маркового, как-то ее
[40:34.720 --> 40:42.600]  описали, неважно, там, может, в виде графа или чего-то, и вам задают вопрос, вот в момент нулевой было
[40:42.600 --> 40:49.080]  такое это распределение, или даже вам говорят, в каком конкретном состоянии была цепь, а потом
[40:49.080 --> 40:58.240]  спрашивают, а вот в момент n, который там, скажем, не 1 или 2, а 100, в каком состоянии будет находиться цепь,
[40:58.240 --> 41:03.120]  или какого будет распределение, где она будет находиться, ну и как вы себе представляете такую
[41:03.120 --> 41:09.160]  задачу, значит, вы такое говорите, ага, в начальный момент она была в нуле, в следующий момент она может
[41:09.160 --> 41:15.840]  оказаться в нуле, в единице, в двое, там, в тройке, значит, потому что есть переходы из 0 в 1 в 2 и в 3,
[41:15.840 --> 41:24.400]  а, скажем, из состояния 1 есть переход в состоянии 0, 2 и 3, ну короче, вот если вы начнете вот рисовать
[41:24.400 --> 41:30.520]  все эти переходы, то для простейших случаев вы что-то напишете, но для немножечко более сложной
[41:30.520 --> 41:37.680]  ситуации, когда n не 2, 3, а, скажем, 10, вот следить за всеми этими переходами и вероятностями и
[41:37.680 --> 41:43.560]  перемножать эти вероятности, вы умрете, короче, ну что можно сделать, можно записать матрицы
[41:43.560 --> 41:50.360]  перехода за один шаг, матрица перехода за один шаг, это простая вещь, и просто перемножить эти
[41:50.360 --> 41:54.840]  матрицы, перемножить их можно не обязательно вручную, а на компьютере, вы получите какую-то
[41:54.840 --> 42:01.000]  матрицу, вот она будет показывать вероятность перехода между либо ими состояниями от момента 0
[42:01.000 --> 42:08.120]  к моменту n, то есть вы одна формула и при этом вы находите вероятности всех переходов между
[42:08.120 --> 42:13.520]  этими моментами времени, вот, то есть для практики это великая вещь, вот то, что здесь написано,
[42:13.520 --> 42:23.400]  значит это было то, как связаны матрицы перехода, а как это все связано с распределением вероятностей,
[42:23.400 --> 42:32.400]  ведь допустим мы хотим знать, с какой вероятностью система будет находиться в том или ином состоянии по
[42:32.400 --> 42:40.920]  прошествии какого-то времени, для этого есть у нас другая теорема, которая вот какая, вероятность,
[42:40.920 --> 42:52.920]  вектор вероятности в этот момент времени, это есть п транспонированная переход от n-1 к n на p
[42:52.920 --> 43:01.200]  n-1, то есть если тебе известно распределение в этот момент времени и матрица перехода, то тогда
[43:01.200 --> 43:07.040]  вот так умножай с транспонированием здесь и ты получишь вектор в этот момент времени,
[43:07.040 --> 43:13.680]  доказательство, тоже доказательство практически очевидное, значит мы записываем то, что стоит справа,
[43:13.680 --> 43:23.960]  p и t от n, и ту компоненту берем, что это такое, это есть вероятность того, что xn равно i, дальше
[43:23.960 --> 43:31.560]  пользуемся формулой полной вероятности, сумма по всем g из s, обуславливаем по всем настояниям,
[43:31.560 --> 43:43.760]  вероятность xn равно i при условии, что xn-1 равно g, вот и умножаем на вероятность того, что xn-1
[43:43.760 --> 43:58.040]  равно g, вот, а это есть, что такое, это есть сумма, g принадлежит s, p значит it gt n-1 n умножить
[43:58.040 --> 44:11.360]  на p gt от n-1, вот, а нет, подождите, не i g, а g i, да, получается, на первом месте идет то,
[44:11.360 --> 44:19.960]  откуда куда, вот, g i, ну и видите, здесь мы пробегаемся не по второму индексу, как матрица,
[44:19.960 --> 44:27.600]  а по первому, как будто мы ее транспонировали, и умножаем уже вот так, но все, отсюда следует вот эта вещь.
[44:41.360 --> 44:54.880]  Так, хорошо, хорошо, ну, соответственно, если нас интересует p от n, то, а мы знаем распределение в
[44:54.880 --> 45:01.240]  начальном момент времени, то можно вот так написать, это p транспонированная n-1 n на p
[45:01.240 --> 45:11.240]  транспонированная n-2 n-1 и так далее, до b транспонированная, так, нет, сейчас, а, ну да,
[45:11.240 --> 45:19.960]  0, 1, p, 0, вот, потому что если вы знаете распределение в начальном момент времени,
[45:19.960 --> 45:32.080]  то вы, умножая на матрице перехода за один шаг, вот так вот, получаете распределение в конечном
[45:32.080 --> 45:41.920]  момент времени. Вот, хорошо, теперь мы с вами ограничимся только некоторым под классом, под
[45:41.920 --> 45:50.520]  классом цепей Маркова дискретных, однородными цепями Маркова мы ограничиваемся. Определение,
[45:50.520 --> 46:18.240]  значит, если p m, n равняется p, давайте так, m плюс k, n плюс k, вот, ну, для любых, для любых m,
[46:18.240 --> 46:26.400]  n, k, m плюс k, n плюс k, больше либо равных нуля, вот, ну, понятно для каких, для любых m, n, k, так я короче
[46:26.400 --> 46:42.760]  просто напишу, то дискретную цепь Маркова называют однородной. Ну, то есть, вероятность перейти из
[46:42.760 --> 46:54.360]  нулевого в первого состояния, не так, вероятность перейти из нуля сегодня в единицу завтра точно такая же,
[46:54.360 --> 47:03.960]  как перейти из нуля завтра в единицу послезавтра. Вероятности перехода, они не зависят от абсолютных
[47:03.960 --> 47:10.680]  значений вот этих вот m и n моментов времен, только от их относительного зависит. Такая вот однородность
[47:10.680 --> 47:18.120]  по времени. Тогда, кстати говоря, много всего упрощается в однородных цепях, тогда вероятность
[47:18.120 --> 47:26.680]  перейти из 0 в 1 на самом первом шаге точно такая же, как перейти из 0 в 1 на втором шаге, на третьем
[47:26.680 --> 47:32.960]  шаге и так далее. И в однородных цепях все вот эти вероятности становятся одинаковыми. То есть,
[47:32.960 --> 47:52.920]  в однородных цепях, цепях P01 равняется P12, вот, равняется и так далее, равняется Pn-1n. Вот,
[47:52.920 --> 48:05.040]  что еще можно сказать? Вообще P0n равняется P1n-1, равняется, так далее, равняется P, скажем там,
[48:05.040 --> 48:13.800]  k, n плюс k. Вот, еще что можно написать? Ну, я по максимуму пишу, просто чтобы у вас
[48:13.800 --> 48:28.600]  при глазами были все эти формулы, мы будем им пользоваться, например, 0n-m. Вот. Мы будем дальше
[48:28.600 --> 48:36.280]  работать только с однородными цепями. Тогда, как все упрощается в однородных цепях, давайте посмотрим.
[48:36.280 --> 48:47.920]  Теперь конкретно для однородных цепей. В однородных цепях вот эта формула, это что получается? Pn
[48:47.920 --> 49:01.520]  равняется P, транспонированная от нуля до единицы в степени n на P0. Вот. Потому что все матрицы
[49:01.640 --> 49:07.520]  становятся одинаковыми, они все совпадают с P01. Вот такая вот формула справедлива.
[49:07.520 --> 49:15.320]  По этому поводу, кстати, мы можем вести даже обозначение, просто P, просто, без всяких скобок,
[49:15.320 --> 49:28.840]  просто P. Мы будем это считать P01, вероятность перехода за один шаг. Вот. Значит, распределение
[49:28.840 --> 49:35.840]  в произвольный момент времени, оно зависит только от распределения в начальный момент времени и матрица
[49:35.840 --> 49:53.920]  перехода за один шаг. Дальше, что еще можно сказать? Значит, не помню, это теорема или не теорема? Нет,
[49:53.920 --> 50:01.560]  не теорема. Значит, у нас есть формула Калмогорова-Чепмана. Давайте я вам напомню. Mn равняется
[50:01.560 --> 50:13.240]  Pmk на Pkn. Это у нас в любых цепях, в том числе и в однородных. Но для однородных мы можем это
[50:13.240 --> 50:38.880]  упростить. Что мы получаем? 0n-m равняется P0k-m на P0n-k. Вот. Если мне так вообще надо.
[50:43.240 --> 51:06.520]  Или мне эта формула не нужна. Сейчас, секундочку. Pn равно Pn-1. А, ну в принципе можно и так, да.
[51:06.520 --> 51:18.320]  Ну вот. В однородных цепях. Ну и если мы вместо m подставим 0, если m равно нулю. Ну да, пусть так
[51:18.320 --> 51:33.880]  будет, например. Пусть 0. Тогда P0n равняется P0k на P0n-k. Видите, у нас здесь получается матрица P0 что-то.
[51:33.880 --> 51:38.840]  Вот очень хочется какое-то обозначение вести, да. Потому что раз все, все сводится к ней. Давайте мы
[51:38.840 --> 51:48.480]  обозначим P от n по определению. Вот тут там тоже определение. P0n. Вот такое будем использовать. То есть
[51:48.480 --> 51:55.840]  P от единицы это просто P. А P от n это вот эта вещь. Тогда вот эта штука переписывается. То есть в
[51:55.840 --> 52:18.720]  однородных цепях тогда P от n равняется P от k на P от n-k. Значит так, хорошо. И это для любого
[52:18.720 --> 52:25.200]  k. Видите, здесь слева есть k. Точнее слева нет k, а справа есть. Как это разрешить? Это для любого
[52:25.200 --> 52:34.280]  k справедливо. И для k равного 0, 1, 2, 3 и так далее. Вот это справедливо. То есть это справедливо
[52:34.280 --> 53:00.600]  для любых k и n. Ну n больше либо равно k. Ну да, здесь вот столько всяких следствий получается.
[53:00.600 --> 53:08.840]  Да, значит вот это первое следствие. Мы вводим вот эти два обозначения. Получаем вот эту формулу.
[53:08.840 --> 53:15.440]  Давайте я даже выделю здесь главные формулы. То есть вот эту формулу можете выделить в рамочку.
[53:15.440 --> 53:23.160]  Основные формулы какие? Вот это. Значит следствие той Pn равняется P транспонированное в степени n
[53:23.160 --> 53:34.280]  P от 0. Вот это еще одна выделяете. Так, дальше. Следствие вот этой формулы, что отсюда можно
[53:34.280 --> 53:56.600]  получить. Смотрите. P от n это есть P от n1, P от n2 и так далее. P от nk, где k произвольно, а n1
[53:56.600 --> 54:05.400]  плюс и так далее, плюс nk равно n. Вот. То есть вот эта n это сумма вот этих n здесь. Это прямое
[54:05.400 --> 54:11.400]  следствие вот этой формулы. Ну потому что ты берешь, например, k равное n1. Здесь получаешь n
[54:11.400 --> 54:19.400]  минус n1. Потом вот эту формулу применяешь вот к этой P. Там n2 умножить на P от n минус n1 минус n2
[54:19.400 --> 54:30.960]  и так далее. Вот. Но P от 0 это единичная матрица. P от 0 это единичная матрица. Потому что что это
[54:30.960 --> 54:39.840]  такое? Ее элемент это перейти из i в g от момента 0 в момент 0. Вот. То есть это есть вероятность того,
[54:39.840 --> 54:48.720]  что x0 равняется g при условии, что x0 равняется i. Видите, здесь один и тот же момент времени. Так что
[54:48.720 --> 54:57.320]  если i равно g, то эта вероятность равна единице. А если i не равно g, эта вероятность равна 0. Вот
[54:57.320 --> 55:02.600]  почему вот эта штука это есть единичная матрица. Но здесь это тоже используется. Вот это тоже выделите.
[55:02.600 --> 55:15.440]  Вот это тоже важная формула в однородных цепях. Мы будем ей пользоваться. И если вот эту вещь мы
[55:15.440 --> 55:22.640]  распишем, ну в терминах сумм, смотрите, что мы получим. Там будет очень важная формула для нас.
[55:22.640 --> 55:37.560]  Если мы вот эту формулу распишем в виде сумм, получается, что P i t j t от n, ну то есть 0 n мы
[55:38.360 --> 55:48.680]  будем обозначать просто P i t j t от n. По определению. По определению. То есть что такое? Это здесь
[55:48.680 --> 56:01.080]  произведение стоит. Здесь много-много разных сумм. То есть это суммы. Какие? P значит i t, ну какая-то
[56:01.080 --> 56:17.640]  l единица. За сколько шагов? За n один шаг. Потом P l 1 l 2 за n два шага и так далее. До P l не
[56:17.640 --> 56:38.280]  знаю сколько. K минус один что ли. А последний кто? Это j. Значит от n k. Правильно?
[56:38.280 --> 56:52.720]  Или что-то не так. Здесь должен был бы стоять l k и n k. А здесь суммы идут по l 1 из s и так далее,
[56:52.720 --> 57:00.520]  l k минус 1 из s. Ну короче говоря, я просто расписал произведение k матрицы в виде вот таких
[57:00.520 --> 57:13.920]  сумм. И важное следствие отсюда. Вот какое. То что P i t j t от n. Вероятность перейти из i в j за n шагов.
[57:13.920 --> 57:27.080]  Она больше либо равна, чем вероятность перейти из i в какой-то l 1 за n один шаг. Из этого l 1 в
[57:27.080 --> 57:40.840]  какой-то l 2 за n два шага и так далее. l k минус 1 j за n k шагов. Для любых l 1 l 2 и так далее.
[57:40.840 --> 57:52.160]  Любых l 1 l 2 и так далее. l k минус 1 из s. Вот эту формулу тоже выделите. Очень много у нас будет
[57:52.160 --> 57:57.960]  теорем, которые опираются на эту формулу. Много задач решается с помощью этой формулы. В общем,
[57:57.960 --> 58:08.000]  очень много раз мы будем прям ссылаться на нее. Это очень важная вещь. Потому что P i t j t это сумма
[58:08.000 --> 58:14.360]  по всем вот этим l 1 l 2 и так далее. Вот таких произведений. Это сумма по ним всем. Но все они
[58:14.360 --> 58:20.760]  не отрицательны. Значит она больше либо равна каждого слагаемого здесь. Может быть иногда даже равна
[58:20.760 --> 58:31.160]  в каком-то выраженном случае. Но вообще говоря она больше либо равна. Вероятность перейти. Ни в коем случае
[58:31.160 --> 58:35.880]  здесь в общем случае нельзя ставить равенство. А то вы так можете придумать. Ага, нам надо попасть из
[58:35.880 --> 58:42.120]  i в j за n шагов. Какова будет эта вероятность? И вы такой начинаете. Ага, я могу попасть из
[58:42.120 --> 58:47.720]  i в l 1 за столько шагов, из l 1 в l 2 за столько шагов. Вы такое равенство пишете? Произведение
[58:47.720 --> 58:54.000]  вероятности нет. Потому что попасть из i в j вы можете разными путями. Не только вдоль этого конкретного
[58:54.000 --> 59:14.000]  пути, но разными путями. Вот. Но разными путями. Так что так. Такая формула. Так что у нас там еще?
[59:18.120 --> 59:28.240]  И еще какое можно сделать следствие? Смотрите. Следствие вот этой формулы еще одно. Если мы возьмем k
[59:28.240 --> 59:36.680]  равно n, n1 равно 1, n2 равно 1 и так далее. Тогда получается что p от n это p от 1 умножить на p от 1,
[59:36.680 --> 59:45.480]  на p от 1 и так далее n раз. То есть отсюда также следует что p от n это есть p от 1 в степени n. То
[59:45.480 --> 59:53.920]  есть просто p в степени n по нашим обозначениям. Значит, матрица перехода за n шагов это есть
[59:53.920 --> 01:00:04.880]  n степень матрица за один шаг. Вы как? Получается интересно. Вот эту формулу тоже можете выделить.
[01:00:04.880 --> 01:00:11.960]  Ну да, я понимаю формула много, но когда вы начнете решать задачи, то вы к этим формулам быстро
[01:00:11.960 --> 01:00:17.600]  привыкнете и на самом деле ничего сверх такого за этим не стоит. Мы будем в основном работать с
[01:00:17.600 --> 01:00:25.040]  однородными цепями. Вот. Так что придется эти формулы запомнить. Ну они все очень легко выводятся,
[01:00:25.040 --> 01:00:30.080]  потому что даже если вы какие-то формулы не знаете, а будете применять формулу полной вероятности,
[01:00:30.080 --> 01:00:35.840]  марковское свойство и формулу условной вероятности, вы будете сами за один шаг, за один-два шага к этим
[01:00:35.840 --> 01:00:39.560]  формулам сами приходить в конце концов, кстати говоря. Потому что видите все вот эти теоремы,
[01:00:39.560 --> 01:00:48.520]  которые сейчас были, они все доказываются элементарно. Ну и эту лекцию я закончу
[01:00:48.520 --> 01:01:00.480]  некими интерпретациями на графах. Очень удобно вводить вот такие графы. Кстати,
[01:01:00.480 --> 01:01:05.080]  может быть даже с этого и начать надо было. Вот представьте себе такой граф. Допустим у нас
[01:01:05.080 --> 01:01:11.720]  С это тоже состоит из 0, 1, 2 и так далее. Может быть конечное, может бесконечное число. И Т у нас
[01:01:11.720 --> 01:01:19.960]  тоже равно 0, 1, 2 и так далее. Тогда вот какой должен быть у вас образ в голове о цепи? Это вот такой
[01:01:19.960 --> 01:01:26.120]  граф. Есть нольковое состояние, есть состояние единичка, есть состояние двойка, там ну состояние
[01:01:26.120 --> 01:01:38.240]  тройка. Допустим вот такой нам далее. Значит, если П и Т житое за один шаг больше нуля, то мы рисуем
[01:01:38.240 --> 01:01:45.720]  между ними стрелочку. И над стрелочкой рисуем вероятность перехода за один шаг. Потому что в
[01:01:45.720 --> 01:01:52.280]  однородных цепях все определяется вероятностью перехода за один шаг. Только матрицы П. Видите,
[01:01:52.280 --> 01:01:59.640]  П от Н это есть П за один шаг в степени Н. Значит это любого Н. Мы знаем вероятность перехода за
[01:01:59.640 --> 01:02:06.280]  любой шаг. Все, зная вероятность перехода за один шаг. То есть вообще однородные дискретные цепи
[01:02:06.280 --> 01:02:11.320]  Маркова определяются двумя вещами. Это начальным распределением, начальный момент времени и
[01:02:11.320 --> 01:02:21.080]  вероятностью перехода за один шаг. Все. То есть вектором и матрицей. Ну допустим вот такую ситуацию
[01:02:21.080 --> 01:02:29.840]  рассмотрим. Что мы можем попасть из 0 в 1 за один шаг с вероятностью 1-2. Либо попасть вот сюда с
[01:02:29.840 --> 01:02:36.400]  вероятностью 1-2. Ну как бы сумма вероятности выхода должна быть единицей. Куда ты деваешься? Ты
[01:02:36.400 --> 01:02:41.720]  можешь как бы обратно вернуться. Например, давайте здесь нарисуем. Когда ты в единице,
[01:02:41.720 --> 01:02:49.520]  ты можешь попасть в себя с вероятностью 1-2. Ну допустим вот в 3 тоже с вероятностью 1-2. Ну и
[01:02:49.560 --> 01:02:55.360]  какой-нибудь нетривиальный давайте рассмотрим. Допустим из 3 в 1 с вероятностью 1 треть, из 3 2 в
[01:02:55.360 --> 01:03:04.400]  состоянии 2 третье. Так и двойку надо рассмотреть. А 2 в себя с вероятностью 1. Вот такие графы
[01:03:04.400 --> 01:03:13.800]  называются стахастическими графами. То есть у них вершины это обозначение для состояний. В данной цепи
[01:03:13.800 --> 01:03:22.200]  4 состояния 0 1 2 3. Стрелочки означают, что вероятность перехода за один шаг не нулевая. Вот.
[01:03:22.200 --> 01:03:29.400]  Например, из 0 в 3 нет стрелочки. Значит за один шаг из 0 в 3 не попасть. Хотя можно попасть за два
[01:03:29.400 --> 01:03:37.000]  шага. Видите? Вот. А над стрелочкой мы рисуем вероятность перехода за один шаг. Вот давайте
[01:03:37.000 --> 01:03:52.400]  мы для этой ситуации все нарисуем и распишем. Что здесь будет? Что такое? Вероятность. Давайте
[01:03:52.400 --> 01:04:04.000]  начнем. Вероятность перехода за один шаг. Значит это будет матрица 4 на 4. Значит вот здесь будет
[01:04:04.000 --> 01:04:12.800]  стоять P00. Попасть из 0 в 0. Нельзя за один шаг. Вероятность 0. Дальше идем по строчке. Вероятность
[01:04:12.800 --> 01:04:21.560]  попасть из 0 в 1. 1 вторая. Значит вот сюда рисуем 1 вторую. Дальше из 0 в 2 попасть. Тоже вероятность
[01:04:21.560 --> 01:04:31.120]  1 вторая. Здесь рисуем 1 вторую. А из 0 в 3 за один шаг не попасть. Значит здесь рисуем 0. Вот мы первую
[01:04:31.120 --> 01:04:37.080]  строчку заполнили. Смотрите сумма чисел в первой строке равна единице. Я вас не обманул. Дальше едем.
[01:04:37.080 --> 01:04:43.920]  Теперь осматриваем единичку. Из единички в нолик мы не попадем. Нолик. Из единички в единичку мы
[01:04:43.920 --> 01:04:52.440]  попадем. Одна вторая. Из единички в двойку мы не попадем. Нолик. Из единички в тройку мы попадем.
[01:04:52.440 --> 01:05:04.760]  Одна вторая. Вот. Теперь осматриваем двойку. В нолик не попасть. Вот. Из 2 в 1 не попасть.
[01:05:04.760 --> 01:05:12.960]  Из 2 в 2 попасть с вероятностью единица. Из 2 в 3 не попасть. Ну когда я говорю не попасть, я имею
[01:05:12.960 --> 01:05:19.920]  в виду за один шаг естественно. Мы пишем матрицу за один шаг перехода. Вот теперь вероятность для
[01:05:19.920 --> 01:05:28.280]  третьего состояния. Из 3 в 0 не попасть за один шаг. Из 3 в 1 мы попадем с вероятностью одна треть.
[01:05:28.280 --> 01:05:37.600]  Из 3 в 2 с вероятностью две трети. Из 3 в 3 нет пути. Вот. Это матрица перехода за один шаг.
[01:05:37.600 --> 01:05:48.200]  Все очень просто. Начальное распределение может быть какое угодно. Например, можно вот такое
[01:05:48.200 --> 01:05:56.200]  начальное распределение задать. Что ты находишься с вероятностью одна вторая в состоянии 0,
[01:05:56.200 --> 01:06:03.880]  с вероятностью одна вторая в состоянии 1, а в других тогда с вероятностью 0 ты находишься. Вот
[01:06:03.880 --> 01:06:11.400]  просто пример. Пример начального распределения. Это порождает одну цепь Маркова. Вот такую вот.
[01:06:12.320 --> 01:06:18.060]  Если будет какое-то другое начальное распределение это другая цепь Маркова. Формально говоря,
[01:06:18.060 --> 01:06:22.120]  другая цепь Маркова будет. Потому что цепь Маркова это две вещи. Однародный цепь Маркова
[01:06:22.120 --> 01:06:28.660]  это две вещи. Начальное распределение и вероятность перехода за один шаг. Если что-то из этого меняется,
[01:06:28.660 --> 01:06:34.240]  значит цепь меняется. То есть последовательности ее вероятностные свойства они меняются. Ну,
[01:06:34.240 --> 01:06:40.360]  может быть так что в начальный момент времени мы стартуем с какого-то состояния, например мы
[01:06:40.360 --> 01:06:48.640]  стартуем из 0. В этом случае распределение будет такое 1, 0, 0, 0. Вот это означает,
[01:06:48.640 --> 01:06:53.960]  что мы как бы детерминированно стартуем из 0 в начальном момент времени. Но в следующий
[01:06:53.960 --> 01:07:01.200]  момент времени мы попадем куда-то, это уже будут какие-то случайные числа. То есть вот в этом
[01:07:01.200 --> 01:07:08.280]  случае у нас это означает, что x0 для нашей случайной последовательности это как бы тождественная
[01:07:08.280 --> 01:07:13.440]  единица. То есть выраженная такая случайная величина, которая с вероятностью 1 принимает значение,
[01:07:13.440 --> 01:07:20.880]  ой, принимает значение 0, принимает значение 0, с вероятностью 1. А вот x1, x2 и так далее,
[01:07:20.880 --> 01:07:30.960]  это уже будут какие-то случайные величины. Ну как найти распределение в следующий момент
[01:07:30.960 --> 01:07:36.120]  времени? Допустим, вот для этой ситуации. Давайте мы вот эту ситуацию простейшую рассмотрим,
[01:07:36.120 --> 01:07:41.480]  и допустим я хочу найти распределение над вероятностями состояний в следующий момент времени,
[01:07:41.480 --> 01:07:49.640]  в единичку. Допустим, я вообще ничего не знаю про эту науку. Вот чисто и здравого смысла. Что бы
[01:07:49.640 --> 01:07:56.280]  я здесь должен был написать? Но если я нахожусь в нуле, то на следующем шаге я либо буду в единице
[01:07:56.280 --> 01:08:02.560]  с вероятностью 1, 2, либо в двойке с вероятностью 1, 2. В нуле и в тройке я точно быть не могу на
[01:08:02.560 --> 01:08:16.280]  следующем шаге. Так что, в принципе, я могу сразу написать, значит, 0, 1, 2, 1, 2, 0. А на втором шаге,
[01:08:16.280 --> 01:08:24.040]  опять же, если бы я не знал всю эту науку, а вот тут хитрее. Смотрите, ведь я здесь с вероятностью 1,
[01:08:24.040 --> 01:08:31.720]  2 и здесь с вероятностью 1, 2. Значит, на втором шаге с какой вероятностью я буду в нуле? Ну,
[01:08:31.760 --> 01:08:36.880]  если я ушел в двойку или в единичку, я уже обратно не вернусь. Поэтому, в принципе, я могу здесь сразу
[01:08:36.880 --> 01:08:47.440]  написать 0. Вот. Если я попал в двойку, а нет, в единичку, тогда на следующем шаге я обратно
[01:08:47.440 --> 01:08:53.720]  не вернусь, но я могу здесь остаться с вероятностью 1, 2, либо пойти в 3 с вероятностью 1, 2. Поэтому,
[01:08:53.720 --> 01:09:00.120]  ну, чувствуете, да, что начинается? Какая-то комбинаторика начинается. Я должен рассматривать все
[01:09:00.120 --> 01:09:05.480]  вот эти всевозможные случаи. Одна вторая, одна вторая, там, короче, это все. Вот, знаете,
[01:09:05.480 --> 01:09:13.200]  здесь я уже все. Вот чуть-чуть о чем-то задумался, о, снежок пошел, и все. И у тебя обнулилась память.
[01:09:13.200 --> 01:09:20.960]  И ты опять напрягаешься. То есть даже, знаете, для простейших ситуаций вот этот вот анализ
[01:09:20.960 --> 01:09:28.440]  стрелочек без этой науки и ты все, и ты закопался, ты ничего не сделаешь. Какую-нибудь стрелочку,
[01:09:28.440 --> 01:09:33.480]  знаете, обратно нарисовать, все, сразу же все усложняется. Но у нас есть формула. Что нам
[01:09:33.480 --> 01:09:41.240]  голову ломать? У нас есть формула, что π от n, это есть p транспонированная в степени n, p от 0.
[01:09:41.240 --> 01:09:48.520]  Так? Значит, получается, что распределение в произвольный момент времени мы можем получить
[01:09:48.520 --> 01:09:55.880]  таким образом. Например, p, давайте от единицы начнем. Как бы по науке, по науке, как мы должны
[01:09:55.880 --> 01:10:02.400]  делать? p от единицы равно. Это p транспонированная на p от нуля. Значит, мы транспонируем вот эту
[01:10:02.400 --> 01:10:07.640]  матрицу. Это в принципе легко сделать. Это не такое напряжение ума. Вычислений-то нет. Просто
[01:10:07.640 --> 01:10:12.720]  переставить что-то местами. И умножить на p ноликовое. p ноликовое это один и все нули. То есть,
[01:10:12.720 --> 01:10:19.520]  по сути, нам нужно вытащить первый столбец вот этой матрицы. А первая столбец этой матрицы
[01:10:19.520 --> 01:10:25.680]  первая строка этой матрицы. Ноль, одна вторая, одна вторая ноль. Опа. Видите? Что происходит-то?
[01:10:25.680 --> 01:10:33.960]  Ноль, одна вторая, одна вторая ноль. Вот это мы получили вообще бесплатно. Без всякого анализа.
[01:10:33.960 --> 01:10:42.120]  А теперь p2. Это что такое? Это p1. Ну, можно так, смотрите, можно вот так написать, а можно
[01:10:42.120 --> 01:10:50.240]  вот так написать. p транспонированная умножить на p1. Так? Значит, нам надо просто взять вот эту
[01:10:50.240 --> 01:11:02.560]  матрицу и умножить на p1. Ну транспонировать и умножить на p1. Вот. Тогда эта операция сводится
[01:11:02.560 --> 01:11:12.120]  к умножению, к транспонированию. Давайте так. Ноль, одна вторая, одна вторая ноль. Ноль, одна
[01:11:12.120 --> 01:11:25.800]  вторая. Ноль, одна вторая. Ноль, ноль, один ноль. И ноль, одна треть, две трети, ноль. Вот. И это мы умножаем на
[01:11:25.800 --> 01:11:37.400]  ноль, одна вторая, одна вторая ноль. Всё. И дальше мы умножаем. Здесь будет ноль, и мы действительно могли это...
[01:11:37.400 --> 01:11:44.720]  Видите, мы здесь вот этот ноль написали. Это действительно так. А здесь, смотрите, что получается, ноль, одна четвертая,
[01:11:44.720 --> 01:11:59.240]  ноль, ноль, одна четвертая. Здесь ноль, ноль, одна вторая, ноль, одна четвертая. Всё. Спинным мозгом просто
[01:11:59.240 --> 01:12:07.840]  посчитал. Понимаете? Как всё резко упростилось. И я не ломал себе голову с этими стрелочками,
[01:12:07.840 --> 01:12:15.840]  куда мы там, по каким путям пойдём. Так что, пользуйтесь этими формулами. Мы можем также считать p3 и так далее.
[01:12:15.840 --> 01:12:23.400]  Ну вручную, конечно, тяжело считать, но компьютер есть для этого. Компьютер-то может умножить матрицу на вектор.
[01:12:23.400 --> 01:12:32.280]  Очень быстро. Вот так вот всё делается. Мы можем находить распределение в произвольном момент времени.
[01:12:32.280 --> 01:12:48.480]  Вот. Так. Ещё замечание, какое можно сделать. Как видите, распределение подчиняется некоторому
[01:12:48.480 --> 01:12:59.600]  уравнению. p от n равняется p транспонированное n p0. И вот то, чему будет равен p и n, и его асимпатические
[01:12:59.600 --> 01:13:05.840]  характеристики, когда n стремится к бесконечности, это будет определяться собственными значениями матрицы p,
[01:13:05.840 --> 01:13:17.400]  матрица перехода. Вот такой вот подход к изучению свойств дискретных цепей через собственные значения
[01:13:17.840 --> 01:13:24.200]  матрицы перехода. Он имеет место быть, этот подход. Известны даже какие-то содержательные результаты
[01:13:24.200 --> 01:13:36.120]  этого подхода, но он очень ненаглядный. И некоторые утверждения, которые позволяют получить труднопроверяемые
[01:13:36.120 --> 01:13:41.000]  эти свойства, то есть надо собственные числа искать. Если матрица большая, там миллион на миллион, p,
[01:13:41.000 --> 01:13:51.760]  то непонятно, например, непонятно, как находить эти собственные числа с большой вероятностью там,
[01:13:51.760 --> 01:13:58.240]  с большой точностью. В общем, этот подход довольно неудобный. Вместе с тем в приложениях встречаются
[01:13:58.240 --> 01:14:03.880]  большие p. Например, представьте себе интернет или какую-то локальную сеть. Много компьютеров,
[01:14:03.880 --> 01:14:08.560]  это много вершин. Пользователи, когда приходят в эту систему, он заходит на какой-то сайт,
[01:14:08.560 --> 01:14:14.880]  потом перемещается, кликая куда-то на другой сайт и так далее. То есть пользователь, как марковская
[01:14:14.880 --> 01:14:20.200]  цепь, перемещается между сайтами с какой-то вероятностью. И много пользователей перемещается.
[01:14:20.200 --> 01:14:29.120]  Интернет большой. И допустим, тебе хочется понять, как вся эта ситуация устаканится в пределе,
[01:14:29.120 --> 01:14:33.880]  когда ты запустишь много пользователей или когда один пользователь будет очень долго перемещаться,
[01:14:33.880 --> 01:14:40.600]  на каких сайтах он будет, в какие сайты он будет приходить чаще, чем другие. А тебе это может быть,
[01:14:40.600 --> 01:14:45.280]  например, нужно как раз для ранжирования страниц. Если человек вбивает что-то в поиск,
[01:14:45.280 --> 01:14:50.960]  нужно праранжировать по вероятности того, что человек будет посещать те или иные сайты.
[01:14:50.960 --> 01:14:59.600]  То есть тебе нужно как-то сопоставить вероятность посещения каждому сайту. Для этого тебе нужно
[01:14:59.600 --> 01:15:03.560]  асимпатические свойства исследовать. То есть как бы запустить такого виртуального человека,
[01:15:03.560 --> 01:15:08.560]  позволить ему бесконечное раз перемещаться, потом посчитать в среднем, где он бывает,
[01:15:08.560 --> 01:15:15.640]  и частоты праранжировать. И тогда выдавать сайты в соответствии с этими частотами,
[01:15:15.640 --> 01:15:21.880]  которые получились. Но для того, чтобы так делать, ты должен понимать асимпатические свойства марковских
[01:15:21.880 --> 01:15:27.440]  цепей. Когда ты увеличиваешь время, что происходит с цепью, как вообще формируется это предельное
[01:15:27.440 --> 01:15:32.880]  распределение. Так вот я и говорю, что если матрица P большая, а ты пытаешься найти ее собственные числа,
[01:15:32.880 --> 01:15:37.440]  то это тяжело. Ты должен находить собственные числа с большой точностью. Ты должен возводить P в большую
[01:15:37.440 --> 01:15:43.160]  степень N. Что там будет проходить? Какие ошибки? Это будет совершенно ненаглядно. Но что если я вам
[01:15:43.160 --> 01:15:49.400]  скажу, что на самом деле ничего это не надо делать? На самом деле мы с вами научимся на следующей уже
[01:15:49.400 --> 01:15:59.760]  лекции просто посмотрев, ну даже не на следующей, а еще через лекцию, просто посмотрев на картинку,
[01:15:59.760 --> 01:16:09.200]  сразу про нее все сказать, что будет в пределе. Ничего не вычисляя вообще, просто посмотрев на
[01:16:09.200 --> 01:16:15.480]  картинку. Никакие умножения матриц на вектор, никакие собственные числа, ничего этого. Просто
[01:16:15.480 --> 01:16:21.840]  посмотрев, сразу можно сказать, что будет. Вот. Но для того, чтобы уметь это делать, нам нужно будет
[01:16:21.840 --> 01:16:28.040]  классифицировать состояние. Оказывается, состояния дискретной цепи обладают разными свойствами.
[01:16:28.040 --> 01:16:34.680]  Бывают существенные и несущественные состояния, нулевые и ненулевые, возвратные и невозвратные,
[01:16:34.680 --> 01:16:40.440]  эргодические, периодические. Вот на следующей лекции мы с вами классифицируем эти состояния.
[01:16:40.440 --> 01:16:46.160]  Это будет как бы тот инструментарий, который нам позволит анализировать цепи и потом говорить
[01:16:46.160 --> 01:16:50.800]  сразу же, посмотрев на цепь, что в ней будет происходить в пределе при стремящемся к
[01:16:50.800 --> 01:16:59.280]  бесконечности. Вот. Это суперважная наука. Вот. Очень легко, удобная. И мы будем с вами учить это
[01:16:59.280 --> 01:17:03.120]  следующего раза. Всё. У меня на сегодня всё.
