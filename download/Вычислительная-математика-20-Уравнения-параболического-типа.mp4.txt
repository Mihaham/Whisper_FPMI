[00:00.000 --> 00:14.000]  Есть ли вопросы по прошлой лекции? Если нет, то по ходу дела. Смотрите, какие вопросы будут, по ходу дела
[00:14.000 --> 00:20.040]  задавайте. Поэтому я некоторые вещи буду, естественно, обращаться с некоторыми вопросами
[00:20.040 --> 00:26.160]  прошлой лекции, прошлой и так далее. У нас все лекции, на самом деле, завязаны. Сегодня мы будем
[00:26.160 --> 00:37.320]  учиться решать уравнения параболического типа. Задач таких прикладных этого типа уравнений
[00:37.320 --> 00:47.400]  очень много. Это и физика, и механика, теория диффузии, фильтрации в геофизике, это и динамика
[00:47.400 --> 01:01.120]  популяций, то есть это изменить численности стадо, саранчи, олени, волков. Это модели социодинавики,
[01:01.120 --> 01:07.080]  в экономике они используются, ну и так далее. Ну, значит, пришли они, конечно, из физики, это
[01:07.080 --> 01:12.920]  процессы типа проводности, диффузии, вязкости, то есть как бы такие десепативные процессы. Ну,
[01:12.920 --> 01:20.400]  это действительно так, но если уравнение параболического типа имеет явно выраженный
[01:20.400 --> 01:29.320]  нелинейный вид, то там могут быть и необязательно десепативные процессы, скажем так. Почему
[01:29.320 --> 01:35.480]  десепативные процессы? Поскольку в этих уравнениях присутствует вторая производная по координате.
[01:35.480 --> 01:43.640]  По координате. Это обычно описывает описание таких десепативных процессов. Ну, я начну с
[01:43.640 --> 01:50.600]  простейшего уравнения. Значит, простейшее линейное уравнение имеет такой вид. Мы с вами его записали,
[01:50.600 --> 02:01.160]  поэтому я подробно не буду устанавливать. Ну, например, вот так пусть будет а константа,
[02:01.160 --> 02:11.040]  то есть это линейное уравнение, а t зависит от координата. Время мы будем полагать вот в
[02:11.040 --> 02:17.400]  таком промежутке. Правильно написать вместо t большую бесконечность, но у нас бесконечностью быть
[02:17.400 --> 02:28.120]  не может. В вычислениях x меняется от 0 до x большого, то есть координата. Ну, и начальные
[02:28.120 --> 02:43.400]  ограниченные условия всегда обязательно задаются. То есть у от 0 до x, начальные условия,
[02:43.400 --> 02:56.040]  ну пусть будет такой psi от x, то начальные условия при t равном уню у от t 0. Левое
[02:56.040 --> 03:08.040]  ограниченное условие phi1 от t и правое ограниченное условие u от tx большое, ну пусть будет phi2 от t.
[03:08.040 --> 03:16.040]  Ну, это вот такая постановка исходной дифференциальной задачи. Мы ее обозначали вот таким образом.
[03:16.040 --> 03:25.040]  L u равняется f. Это исходная дифференциальная задача. Так, ну напомню, что
[03:25.040 --> 03:33.040]  аппроксиммирующие уравнения мы обозначали l tau u tau равняется f tau в операторной форме.
[03:33.040 --> 03:41.040]  Удобная такая. В alt x, вообще говоря, переменная, и вообще говоря, коэффициент может быть разрывный.
[03:42.040 --> 03:48.040]  Тогда дифференцировать мы просто не можем. Поэтому здесь в таком виде делается.
[03:48.040 --> 04:00.040]  Ну и нелинейные уравнения. Ну, записывается вот в таком виде d u d t, это d d x. Здесь a от u,
[04:00.040 --> 04:08.040]  то есть коэффициент типа проводности уже может зависеть от решения. Здесь d u d x.
[04:08.040 --> 04:17.040]  Ну и плюс правая часть, которая тоже в случае нелинейных уравнений может зависеть от самого решения.
[04:17.040 --> 04:25.040]  Ну что, вот нелинейное уравнение, оно, конечно, физически наиболее интересным.
[04:25.040 --> 04:33.040]  Оно используется очень часто и в физике плазмы, физике космоса, и в квантовом механике,
[04:33.040 --> 04:41.040]  и динамике популяции и так далее. И вот когда коэффициенты зависят от решения,
[04:41.040 --> 04:47.040]  возможны очень такие неожиданные физические эффекты. То есть вот я говорил, что вот уравнение
[04:47.040 --> 04:52.040]  типа проводности при постоянном коэффисенте, оно вот такой десепативный вид имеет.
[04:52.040 --> 04:58.040]  Ну действительно, если бы возьмем какую-то тепловая волна, это не совсем физический термин,
[04:58.040 --> 05:04.040]  но если мы будем нагревать, например, вот нашу поверхность какую-то, например, на доску,
[05:04.040 --> 05:11.040]  то мы знаем прекрасно, вы решаете такие задачки, то волна будет вот так вот как бы расползаться.
[05:11.040 --> 05:17.040]  Ну это, ну тепловая волна, это такой условный термин, тепло.
[05:17.040 --> 05:24.040]  На самом деле, если вот коэффициенты и правая часть будут зависеть от решения,
[05:24.040 --> 05:32.040]  то возможны разные эффекты. Возможно, например, что тогда уже тепловая волна может появиться.
[05:32.040 --> 05:38.040]  Например, в плазме появляются тепловые волны, которые также описываются такими параболичными уравнениями.
[05:38.040 --> 05:44.040]  Они вот так распространяются, даже здесь вот бесконечная производная.
[05:45.040 --> 05:54.040]  Возможно, другие варианты. Возможно, что вот где-то мы нагрели, ну, например, какой-то кусочек,
[05:54.040 --> 05:59.040]  это тоже эффекты, которые в таких сильно нагретых средах типа плазмы.
[05:59.040 --> 06:09.040]  И вот начинается рост, резкий рост температуры. Подобные эффекты в плазме называются пинч-эффектами.
[06:09.040 --> 06:16.040]  Возможно, не один такой эффект, а несколько вот таких структур. Их называют контрастными структурами.
[06:16.040 --> 06:21.040]  Все это нелинейные эффекты. Это очень важно. Нелинейные эффекты.
[06:21.040 --> 06:29.040]  То есть, нелинейные эффекты не всегда, но чаще всего предсказуемы, скажем так, в своем качественном поведении.
[06:29.040 --> 06:34.040]  Вот линейные решения более-менее предсказуемы. Ну, качественно, конечно.
[06:34.040 --> 06:40.040]  Количественно нужно все честно решать. На коленке мало какие задачи решается.
[06:40.040 --> 06:43.040]  В основном все решается на компьютерах численно.
[06:43.040 --> 06:49.040]  А вот нелинейные задачи, там бывают такие эффекты совершенно неожиданные.
[06:49.040 --> 06:51.040]  Совершенно неожиданные.
[06:51.040 --> 07:00.040]  Например, вот задача при коэффициенте типа проводности равна, ну, скажем так, некая константа на
[07:00.040 --> 07:05.040]  У в степени К, где К больше единицы больше двух.
[07:05.040 --> 07:10.040]  Что характерно, например, для плазмов, для задач в детонациях.
[07:10.040 --> 07:14.040]  Ну, вот как раз и приводил к таким эффектам.
[07:14.040 --> 07:18.040]  К образованию тепловых волн, диагоничному росту.
[07:18.040 --> 07:21.040]  Вот в плазме пинч-эффектов, флагм, и так далее.
[07:21.040 --> 07:23.040]  Это все было.
[07:23.040 --> 07:29.040]  Ну, а вот если у будет вот такой функции правая часть, то это вот такие процессы.
[07:29.040 --> 07:32.040]  Например, имеет место будет детонация.
[07:32.040 --> 07:35.040]  То есть процессы детонации описываются вот такими уравнениями.
[07:35.040 --> 07:38.040]  Но это все существенно нелинейные задачи.
[07:38.040 --> 07:41.040]  Они, конечно, самые интересные, самые красивые.
[07:41.040 --> 07:48.040]  И не всегда предсказуемо поведение вот таких решений.
[07:48.040 --> 07:51.040]  Ну, вот физика есть мощная наука.
[07:51.040 --> 07:56.040]  Поэтому, как правило, если корректно сформулировать даже нелинейную задачу,
[07:57.040 --> 08:02.040]  с экспериментов совпадение чаще всего вполне приличное.
[08:05.040 --> 08:07.040]  Чистое решение с экспериментом.
[08:07.040 --> 08:11.040]  Ну, вот это о задачах, о которых мы сегодня будем говорить.
[08:11.040 --> 08:15.040]  Ну, разумеется, еще задача есть неодномерные.
[08:15.040 --> 08:18.040]  Мы о них тоже обязательно будем говорить.
[08:20.040 --> 08:24.040]  Уравнения такие линейные вы, наверное, разбирали,
[08:24.040 --> 08:27.040]  либо будете разбирать в уравнениях математической физики.
[08:27.040 --> 08:38.040]  Например, на кодке PdO PdT равняется D2U PdX дважды плюс D2U PdEbD дважды.
[08:38.040 --> 08:41.040]  Ну, и это записывается вот в такой виде.
[08:41.040 --> 08:44.040]  Видела пассиану коротко, в операторном виде.
[08:44.040 --> 08:47.040]  Ну, проходили уже, наверное, или еще не проходили.
[08:47.040 --> 08:50.040]  Многомерные уравнения.
[08:50.040 --> 08:54.040]  То есть, линейные уравнения многомерные имеют точные решения.
[08:57.040 --> 08:59.040]  Но они бывают разные.
[08:59.040 --> 09:02.040]  Они бывают линейные, бывают с переменными коэффициентами,
[09:02.040 --> 09:05.040]  бывают нелинейные, бывают они затропные.
[09:05.040 --> 09:09.040]  То есть, коэффициенты могут быть в разных направлениях разные.
[09:09.040 --> 09:12.040]  Ну, такие задачи, конечно, решаются только чистым путем.
[09:12.040 --> 09:15.040]  Очень часто так и так все не бывает.
[09:15.040 --> 09:17.040]  Ну, идем дальше.
[09:17.040 --> 09:20.040]  Что касается опроксимирующих уравнений.
[09:20.040 --> 09:26.040]  То есть, мы имеем исходную дифференциальную задачу
[09:26.040 --> 09:30.040]  и будем как-то ее опроксимировать
[09:30.040 --> 09:35.040]  с помощью некого вот такого операторного уравнения.
[09:35.040 --> 09:39.040]  Я не уточняю какого, поскольку опроксимировать задачу дифференциальную
[09:39.040 --> 09:43.040]  можно по разным, можно разными медленами, разными способами.
[09:43.040 --> 09:46.040]  Мы об этом с вами говорили и будем говорить.
[09:46.040 --> 09:52.040]  И для каждого класса задач существует свой класс опроксимирующих уравнений.
[09:52.040 --> 09:55.040]  И это очень важно.
[09:55.040 --> 10:00.040]  Ну, потому как можно, разумеется, решать и другими медленами,
[10:00.040 --> 10:04.040]  ну, вы будете получать менее точные либо менее физические результаты и так далее.
[10:04.040 --> 10:12.040]  Поэтому здесь надо знать, какие классы методов, вот какие классы задач нам подходят.
[10:12.040 --> 10:14.040]  Вот давайте так.
[10:14.040 --> 10:18.040]  Я вам показывал, что такое двухслойная схема.
[10:18.040 --> 10:21.040]  Ну, двухслойная схема, грубо говоря, имеет...
[10:21.040 --> 10:26.040]  Пусть будет вот такой у нас шаблон.
[10:26.040 --> 10:31.040]  Здесь n слой, здесь слой n плюс 1.
[10:31.040 --> 10:40.040]  Ну, здесь у нас будут координатные слои или лучи m, m плюс 1, m минус 1.
[10:40.040 --> 10:44.040]  Такие схемы имеют название двухслойной.
[10:44.040 --> 10:48.040]  Ну, ещё бывают трёхслойные, если ещё один слой по времени добавляем.
[10:48.040 --> 10:52.040]  Большее количество слоёв обычно не используется.
[10:52.040 --> 10:56.040]  То есть либо схемы обычно используются либо двух-либо трёхслойные.
[10:56.040 --> 11:02.040]  Количество лучей по координатам не обязательно 3, может быть и больше.
[11:02.040 --> 11:08.040]  Если мы хотим уточнить, увеличить порядок опроксимации нашей схемы,
[11:08.040 --> 11:11.040]  мы можем увеличить расширять шаблоны.
[11:11.040 --> 11:16.040]  Это даёт возможность увеличивать точность или порядок опроксимации схемы.
[11:16.040 --> 11:20.040]  Ну, давайте остановимся пока на двухслойных схемах.
[11:20.040 --> 11:23.040]  В общем виде мы их можем записать вот в таком виде.
[11:23.040 --> 11:28.040]  уn плюс 1, это есть такая двойная сумма, уi, уj.
[11:28.040 --> 11:31.040]  Здесь коэффициент у нас будет α и gt.
[11:31.040 --> 11:36.040]  Это коэффициенты разности схемы, которые зависят от tau и h.
[11:36.040 --> 11:44.040]  И здесь уn плюс i, m плюс n плюс g.
[11:44.040 --> 11:53.040]  Вот такой вид опроксимирующей разности схемы, двухслойная.
[11:53.040 --> 12:03.040]  То есть здесь вот i у нас будет либо 0, либо 1, либо n, либо n плюс 1.
[12:03.040 --> 12:12.040]  А g может меняться от m до m.
[12:12.040 --> 12:15.040]  То есть шаблон мы можем расширить.
[12:15.040 --> 12:28.040]  Не обязательно делать три точки, можно и шаблон расширять.
[12:28.040 --> 12:35.040]  Теперь о личных методах решения и как можно их уточнять.
[12:35.040 --> 12:38.040]  Но давайте это восстановимся.
[12:38.040 --> 12:42.040]  Я на самом деле уже останавливаюсь на разности схеме,
[12:42.040 --> 12:46.040]  которые обычно называют схемой типа Кранко-Никольсена,
[12:46.040 --> 12:49.040]  либо просто схемой Кранко-Никольсен.
[12:49.040 --> 12:55.040]  Для решения давайте пусть будет линейное уравнение.
[12:56.040 --> 13:01.040]  Соединический коэффициент для простоты.
[13:01.040 --> 13:07.040]  И мы предложим такую схему, самую простую.
[13:07.040 --> 13:14.040]  Производную по времени мы опроксимируем
[13:14.040 --> 13:17.040]  со отношением первого порядка точности.
[13:17.040 --> 13:21.040]  Производную по координате давайте я в левую часть унесу.
[13:21.040 --> 13:25.040]  Пусть будет схема...
[13:25.040 --> 13:29.040]  Давайте так сначала я ту схему напишу,
[13:29.040 --> 13:32.040]  которую мы с вами уже однажды писали.
[13:32.040 --> 13:38.040]  Xi это параметр схемы, которая меняется от 0 до 1 единицы.
[13:38.040 --> 13:46.040]  Здесь у нас будет лямбда х, х у n плюс 1 на m.
[13:46.040 --> 13:58.040]  И плюс единица минус кси на лямбда х, х у n, m.
[14:00.040 --> 14:03.040]  Вот такую схему мы с вами писали.
[14:03.040 --> 14:07.040]  Давайте уточним ее свойства.
[14:07.040 --> 14:14.040]  Первое, если кси равняется 0, то мы имеем просто явную...
[14:14.040 --> 14:16.040]  Я напоминаю, что лямбда х, х...
[14:16.040 --> 14:19.040]  Помните, что это за оператор или нет?
[14:19.040 --> 14:22.040]  Но давайте напишу на всякий случай.
[14:22.040 --> 14:24.040]  Может быть, не все помнят.
[14:24.040 --> 14:27.040]  Например, лямбда х, х у n, m.
[14:27.040 --> 14:31.040]  Это, собственно говоря, прощемация второй производной по координате.
[14:31.040 --> 14:34.040]  Это у n, m минус 1.
[14:34.040 --> 14:37.040]  Минус 2 у n, m.
[14:37.040 --> 14:43.040]  Плюс у n, m плюс 1.
[14:43.040 --> 14:46.040]  На h квадрат.
[14:46.040 --> 14:49.040]  Такой оператор мы с вами писали.
[14:49.040 --> 14:52.040]  Я просто вам напомню.
[14:52.040 --> 14:55.040]  Ой, чуть ровнее.
[14:57.040 --> 15:00.040]  А, кси зачем водится? Сейчас объясню.
[15:00.040 --> 15:02.040]  Вопрос совершенно законный.
[15:02.040 --> 15:05.040]  Зачем нужно параметр кси?
[15:05.040 --> 15:07.040]  Да, да, да.
[15:07.040 --> 15:09.040]  Сейчас объясню.
[15:09.040 --> 15:11.040]  Это совершенно законный вопрос.
[15:11.040 --> 15:14.040]  Зачем нам нужно кси? Значит, мы смотрим сюда.
[15:14.040 --> 15:19.040]  Если кси равняется 0, то мы имеем только явную схему.
[15:19.040 --> 15:22.040]  Явную схему.
[15:22.040 --> 15:27.040]  Кстати говоря, производную по времени часто записывают так.
[15:27.040 --> 15:29.040]  В таком тоже сокращенном виде.
[15:29.040 --> 15:33.040]  Дельта тау у n, m делим на тау.
[15:33.040 --> 15:39.040]  И мы получаем схему лямбда х, х на у n, m.
[15:39.040 --> 15:42.040]  В таком виде оператору приятнее писать.
[15:42.040 --> 15:45.040]  Просто меньше писать.
[15:45.040 --> 15:51.040]  Свойства я немного разверну на ваш вопрос, но он совершенно верный.
[15:51.040 --> 15:54.040]  Свойства явной схемы.
[15:54.040 --> 15:59.040]  Как исследовать схему на порядок аппроксимации находить, мы с вами проходили.
[15:59.040 --> 16:04.040]  Поэтому я вам сразу напишу, что порядок аппроксимации этой схемы
[16:04.040 --> 16:06.040]  у от тау плюс h квадрат.
[16:06.040 --> 16:10.040]  Первый порядок по времени и второй порядок аппроксимации по координате.
[16:10.040 --> 16:13.040]  Явная схема.
[16:13.040 --> 16:18.040]  Что касается исследования схемы на устойчивость.
[16:18.040 --> 16:24.040]  То, что мы с вами говорили, мы представляем решение по нейману
[16:24.040 --> 16:31.040]  в виде разделяющихся переменных лямбда п на e в степени i альфа м.
[16:31.040 --> 16:34.040]  И находим лямбда.
[16:34.040 --> 16:37.040]  Если вы это аккуратно сделаете и поставите в схему,
[16:37.040 --> 16:40.040]  ну это уже чисто такая техническая работа,
[16:40.040 --> 16:43.040]  которую вы без меня без проблем сделаете,
[16:43.040 --> 16:47.040]  то получите, что условия устойчивости выглядят так.
[16:47.040 --> 16:52.040]  Тау меньше или равняется h квадрат делить на 2.
[16:52.040 --> 16:57.040]  Вот так по ходу замечу, что если у нас здесь будет стоять коэффициент,
[16:57.040 --> 17:02.040]  например, а константа, то здесь будет внизу на 2а.
[17:02.040 --> 17:05.040]  У нас коэффициент единица, поэтому так.
[17:05.040 --> 17:12.040]  Что здесь, на ваш взгляд, не очень хорошо в этом условии?
[17:12.040 --> 17:15.040]  Посмотрите.
[17:15.040 --> 17:18.040]  Все мне здесь нравится или не все?
[17:18.040 --> 17:21.040]  В принципе, формальные условия можно макнуть рукой и сказать,
[17:21.040 --> 17:23.040]  ну вот мы выполнили и задача будет.
[17:23.040 --> 17:26.040]  Можно писать программу, да, действительно, программу можно писать.
[17:26.040 --> 17:29.040]  При выполнении условий все будет работать.
[17:29.040 --> 17:33.040]  А что все-таки здесь нехорошо на ваш взгляд?
[17:33.040 --> 17:37.040]  Или все хорошо?
[17:37.040 --> 17:42.040]  Ну, смотрите, h квадрат для одномерной задачи,
[17:42.040 --> 17:47.040]  это, как правило, число малое либо очень малое.
[17:47.040 --> 17:53.040]  Даже для вашего компьютера, который следит в общежитии, учебном зале,
[17:54.040 --> 18:02.040]  больше чем 10 минус 4, 10 минус 5, даже брать как-то нехорошо для одномерной задачи.
[18:02.040 --> 18:06.040]  Тогда какое будет у нас тал?
[18:06.040 --> 18:09.040]  Тал будет соответственно совсем маленькое,
[18:09.040 --> 18:13.040]  то есть шаг по времени будет просто очень маленьким, просто очень малым.
[18:13.040 --> 18:16.040]  Поэтому все хорошо, но шаг по времени,
[18:16.040 --> 18:20.040]  ограниченный шаг по времени очень жесткий.
[18:20.040 --> 18:23.040]  Теперь давайте другое возьмем.
[18:23.040 --> 18:27.040]  То есть вот что для кси равного нулю мы изучили.
[18:27.040 --> 18:30.040]  Теперь кси равное единичке.
[18:30.040 --> 18:35.040]  Что получится? Мы получим неявную, просто неявную схему.
[18:35.040 --> 18:40.040]  Здесь у нас будет n плюс 1 в правой части.
[18:40.040 --> 18:45.040]  Если мы будем, опять же, следовать на порядок опроксимации,
[18:45.040 --> 18:47.040]  мы получим без проблем.
[18:47.040 --> 18:50.040]  Но это, в общем-то, и так видно. Вот такой результат.
[18:50.040 --> 18:53.040]  То есть порядок опроксимации у оттал плюс h квадрат.
[18:53.040 --> 18:57.040]  Здесь никаких, как говорится, загадок нет.
[18:57.040 --> 19:01.040]  Что касается исследований на устойчивость полной эману,
[19:01.040 --> 19:07.040]  я говорю, чаще всего именно это условие используется, хотя есть и другие.
[19:07.040 --> 19:11.040]  То мы получим здесь результат намного более оптимистичный.
[19:11.040 --> 19:17.040]  Схема окажется в линейном случае устойчивой для любых таллаж.
[19:17.040 --> 19:21.040]  То есть любой шаг по времени вы можете выбирать.
[19:21.040 --> 19:24.040]  Ну, конечно, не слишком усердце,
[19:24.040 --> 19:29.040]  поскольку чем больше шаг вы будете брать, тем меньше точность вы будете получать.
[19:29.040 --> 19:33.040]  В соответствии с вот этим.
[19:33.040 --> 19:39.040]  Поэтому здесь нужно оценивать, знать точность, хотя бы примерно,
[19:39.040 --> 19:42.040]  какой вы хотите получить численный результат.
[19:42.040 --> 19:48.040]  И, соответственно, с этим выбирать шаги по времени и по координату.
[19:48.040 --> 19:52.040]  То есть большие шаги по таллу тоже брать нехорошо.
[19:52.040 --> 19:55.040]  Просто будет у вас падать точность решения задач.
[19:55.040 --> 20:00.040]  Тем более, что для данной схемы порядок по времени первый.
[20:00.040 --> 20:02.040]  Невысокий порядок.
[20:02.040 --> 20:09.040]  Далее идем. Пусть у нас кси теперь будет равно 1 и 2.
[20:09.040 --> 20:13.040]  То есть здесь будет одна вторая, здесь будет одна вторая.
[20:13.040 --> 20:17.040]  Такую схему я вам на прошлой лекции писал.
[20:17.040 --> 20:21.040]  И более того, мы доказали ее критерию ее устойчивости.
[20:21.040 --> 20:25.040]  Критерию по Самарскому, которую предложил академик Самарский.
[20:25.040 --> 20:29.040]  Оказалось, что если мы ее выпишем в канонической форме,
[20:29.040 --> 20:33.040]  в которой предложил академик Самарский Александр Ильич,
[20:33.040 --> 20:36.040]  то в общем-то исследовать ничего не нужно.
[20:36.040 --> 20:42.040]  Прямо в канонической форме дает нам критерию устойчивости этой схемы.
[20:42.040 --> 20:46.040]  Поэтому можно ее не исследовать в этом смысле,
[20:46.040 --> 20:52.040]  но можно ее исследовать и по фонейму, и по критерийной.
[20:52.040 --> 20:58.040]  В любом случае мы получим, что схема будет устойчива для любых таваш.
[20:58.040 --> 21:00.040]  И схема будет абсолютно устойчива.
[21:00.040 --> 21:05.040]  Но что важное для этого случая, кси равно 1 и 2, здесь у нас будет стоять квадрат.
[21:05.040 --> 21:08.040]  То есть схема поднимает свой порядок по времени.
[21:08.040 --> 21:12.040]  Второй порядок по времени и по координате.
[21:12.040 --> 21:17.040]  Это, собственно говоря, обуславливает ее довольно большую популярность.
[21:17.040 --> 21:24.040]  Именно эта схема ее называют схемой Кранко-Никольсон в шведской математике.
[21:25.040 --> 21:29.040]  Действительно, она весьма популярна.
[21:29.040 --> 21:33.040]  Но забегая вперед, скажу, у нее есть только один некий недостаток.
[21:33.040 --> 21:35.040]  Есть понятнее.
[21:35.040 --> 21:39.040]  Скорее всего, я на следующей лекции дам определение монотонности схемы.
[21:39.040 --> 21:44.040]  Это важное такое свойство апоксидирующих уравнений.
[21:44.040 --> 21:46.040]  Немонотонность.
[21:46.040 --> 21:53.040]  То есть схемы разностной схемы могут обладать таким не очень хорошим свойством, как немонотонность.
[21:53.040 --> 21:57.040]  То есть решение истинное должно быть монотонным.
[21:57.040 --> 22:01.040]  А вот апоксидирующие уравнения дает решение немонотонным.
[22:01.040 --> 22:03.040]  То есть дает ассоляция.
[22:03.040 --> 22:07.040]  Вот схема Кранко-Никольсон не является монотонной схемой.
[22:07.040 --> 22:10.040]  То есть она может давать, но ассоляция где дает?
[22:10.040 --> 22:12.040]  В области больших градиентов решения.
[22:12.040 --> 22:15.040]  То есть на гладких решениях ассоляция не появляется.
[22:15.040 --> 22:23.040]  Поэтому слоиство монотонности оно актуально, но для, скажем, уравнений параболических,
[22:23.040 --> 22:26.040]  и особенно близких к линейным оно не очень актуально.
[22:26.040 --> 22:29.040]  Из-за его дезапротивных свойств, из-за второй производной.
[22:29.040 --> 22:35.040]  Но, тем не менее, в случае больших градиентов мы можем получить нефизичную ассоляцию.
[22:35.040 --> 22:37.040]  Вот это некий недостаток.
[22:37.040 --> 22:43.040]  Кстати говоря, если кси равна единице, то схема будет монотонной.
[22:43.040 --> 22:48.040]  То есть вот свойство схемы при кси равную единице, чисто неявная схема,
[22:48.040 --> 22:53.040]  она будет не монотонной, но за это мы будем расплачиваться
[22:53.040 --> 22:57.040]  чем порядком опроксимации по времени.
[22:57.040 --> 23:02.040]  Но обе эти схемы на самом деле рабочие.
[23:02.040 --> 23:09.040]  В случае гладких решений, конечно же, используется обычно схема Кранко-Никольсона.
[23:09.040 --> 23:12.040]  То есть при кси равно 1 и 2.
[23:12.040 --> 23:15.040]  Поэтому я дал развернутый ответ на ваш вопрос.
[23:15.040 --> 23:18.040]  Но, в общем-то, это все вопрос правильный.
[23:18.040 --> 23:22.040]  И время я не потерял, поскольку, действительно, эта схема используется очень часто.
[23:22.040 --> 23:26.040]  Для решения такого сорта задач.
[23:26.040 --> 23:28.040]  Теперь вопрос вот какой.
[23:28.040 --> 23:31.040]  У нас такой порядок опроксимации.
[23:31.040 --> 23:33.040]  Вопрос в следующем.
[23:33.040 --> 23:37.040]  Можно ли его увеличить?
[23:37.040 --> 23:42.040]  Действительно, вы сами понимаете, что если вы увеличиваете порядок опроксимации схемы,
[23:42.040 --> 23:46.040]  то вы можете делать более грубую сетку.
[23:46.040 --> 23:48.040]  Шаг сетки можно увеличивать.
[23:48.040 --> 23:50.040]  При этом не теряя в точности.
[23:50.040 --> 23:54.040]  Поэтому, в общем-то, есть целое направление в численных методах.
[23:54.040 --> 23:58.040]  Это построение высокоточных методов.
[23:58.040 --> 24:03.040]  Особенно это актуально для решения задач 3D.
[24:03.040 --> 24:06.040]  Либо 4D. Это не социальная 3D задача.
[24:06.040 --> 24:13.040]  Вы сами понимаете, что для компьютера, который у вас стоит в общежитии или в учебном зале,
[24:13.040 --> 24:17.040]  вы в 4D случае подробную сетку не сделаете.
[24:17.040 --> 24:24.040]  Ну, представьте себе, что даже если вы захотите взять сетку 10 в кубе на 10 кубе на 10 в кубе,
[24:24.040 --> 24:26.040]  по трех координатам.
[24:26.040 --> 24:28.040]  А там у вас еще есть четвертая координата время.
[24:28.040 --> 24:30.040]  Какая сетка будет?
[24:30.040 --> 24:32.040]  Десять-девятая.
[24:34.040 --> 24:37.040]  То есть вы сами понимаете, что это уже не игрушка.
[24:37.040 --> 24:45.040]  Не всякому компьютеру это миллиард узлов подвластен.
[24:45.040 --> 24:48.040]  Для этого уже используются суперкомпьютеры и так далее.
[24:48.040 --> 24:52.040]  Разумеется, суперкомпьютеры имеют большие возможности.
[24:52.040 --> 24:54.040]  Но там у них беда другая, что их немного.
[24:54.040 --> 24:56.040]  Даже не их немного.
[24:56.040 --> 24:58.040]  В стране еще меньше.
[24:58.040 --> 25:00.040]  Я могу их все перечислить.
[25:00.040 --> 25:04.040]  Все суперкомпьютеры, которые есть в нашей стране, просто знаю лично.
[25:04.040 --> 25:08.040]  Знаю их хозяев и так далее.
[25:08.040 --> 25:14.040]  Наиболее мощные компьютеры стоят, как вы догадываетесь, в Китае, Японии и в США.
[25:14.040 --> 25:22.040]  У нас тоже есть очень приличные компьютеры, которые позволяют решать очень-очень широкие классы задач.
[25:22.040 --> 25:25.040]  Там можно сетки делать еще более подробные.
[25:25.040 --> 25:30.040]  Но, конечно, персональный компьютер или подробный сеток не позволяет делать.
[25:30.040 --> 25:35.040]  Но есть задача, которую можно решать и на персоналках, на грубых сетках.
[25:35.040 --> 25:39.040]  В частности, в том числе, используя высокоточные методы.
[25:39.040 --> 25:41.040]  То есть методы высокого порядка аппроксимации.
[25:41.040 --> 25:43.040]  Как, например, это можно делать?
[25:43.040 --> 25:45.040]  Сейчас я покажу один из вариантов.
[25:45.040 --> 25:48.040]  Но это один из вариантов на самом деле.
[25:48.040 --> 25:55.040]  Другие способы или методы увеличения точности методов.
[25:55.040 --> 26:02.040]  Один из таких методов, наиболее понятных, я уже об этом как-то только что намекал,
[26:02.040 --> 26:05.040]  это расширение шаблона по координарии.
[26:05.040 --> 26:11.040]  Действительно, расширяя шаблон, мы можем добиться увеличения порядка точности.
[26:11.040 --> 26:15.040]  Давайте знакомить с самым простым примером, чтобы много не писать.
[26:15.040 --> 26:18.040]  Здесь мне не хватило доски.
[26:18.040 --> 26:24.040]  Пусть будет у нас опять та же линейное уравнение типа проводности.
[26:24.040 --> 26:28.040]  И для простоты явно разностая схема, чтобы не писать очень много.
[26:28.040 --> 26:33.040]  А то мы будем заниматься школьной алгеброй.
[26:33.040 --> 26:39.040]  Берем, пишем разностую схему простейшую.
[26:39.040 --> 26:43.040]  Ту, которую мы только что уже на самом деле писали.
[26:43.040 --> 26:46.040]  Пусть будет так.
[26:46.040 --> 26:51.040]  Производную по времени я аппроксимирую обычным образом.
[26:51.040 --> 26:54.040]  Только что мы это делали, поэтому я не поясняю.
[26:54.040 --> 26:57.040]  Производная по координации.
[26:57.040 --> 27:03.040]  Тоже я ее только что писал, поэтому не комментирую.
[27:03.040 --> 27:09.040]  Это аппроксимация вторая, производная по координации.
[27:09.040 --> 27:15.040]  То есть это у нас есть не что иное, как λ уравняется f.
[27:15.040 --> 27:17.040]  Вот это уравнение.
[27:17.040 --> 27:21.040]  Я переношу вторую производную в левую часть.
[27:21.040 --> 27:25.040]  А правую часть у нас просто в данном случае ноль.
[27:25.040 --> 27:27.040]  То же самое здесь.
[27:27.040 --> 27:32.040]  Здесь у нас λт ут равняется f.
[27:32.040 --> 27:34.040]  f tau.
[27:34.040 --> 27:38.040]  Здесь я тоже в правую часть переношу в левую.
[27:38.040 --> 27:43.040]  Это у нас будет как раз аппроксимирующий оператор.
[27:43.040 --> 27:46.040]  А правая часть будет просто ноль.
[27:46.040 --> 27:49.040]  То есть я сделал предельно простой случай.
[27:49.040 --> 27:53.040]  Давайте, чтобы совсем было просто, так и сделаем.
[27:53.040 --> 27:56.040]  Пусть будет вот так.
[27:56.040 --> 28:00.040]  Ут минус у два штриха между стороны производной ноль.
[28:00.040 --> 28:02.040]  Здесь тоже будет минус.
[28:02.040 --> 28:04.040]  А здесь будет ноль.
[28:04.040 --> 28:06.040]  Тогда будет совсем всё понятно.
[28:06.040 --> 28:09.040]  В левой части стоит оператор L.
[28:09.040 --> 28:11.040]  Либо нефилициальные, либо разности.
[28:11.040 --> 28:13.040]  В правой части правая часть.
[28:13.040 --> 28:17.040]  Но она в данном случае пусть будет нолью для простоты.
[28:17.040 --> 28:22.040]  Теперь мы хотим поделять порядок аппроксимации схемы.
[28:22.040 --> 28:24.040]  Как мы это можем делать?
[28:24.040 --> 28:28.040]  Вот один из простейших способов.
[28:28.040 --> 28:32.040]  Если мы хотим исследовать схему на аппроксимацию,
[28:32.040 --> 28:36.040]  то мы что, в наш разностный оператор или не аппроксимирующий оператор
[28:36.040 --> 28:41.040]  более правильно ставим решение, которое пока условно назовём точным.
[28:41.040 --> 28:46.040]  У большое это проекция точного решения на нашу разностную сетку.
[28:46.040 --> 28:50.040]  Как мы говорим, равняется f, t.
[28:50.040 --> 28:57.040]  Функцию r-tau, которая есть разница l-tau на u-tau минус f-tau,
[28:57.040 --> 29:00.040]  мы называем, как вы помните, невязкой.
[29:00.040 --> 29:05.040]  Невязкой, если норма невязки меньше равняется,
[29:05.040 --> 29:08.040]  c1 мы обозначили на t в степени p,
[29:08.040 --> 29:13.040]  то мы говорим, что схема имеет по этому порядку точности.
[29:13.040 --> 29:15.040]  Правда, для одной переменной.
[29:15.040 --> 29:18.040]  Если у нас две переменных, то у нас невязка будет оцениваться
[29:18.040 --> 29:22.040]  как t-tau в степени p плюс h в степени q.
[29:22.040 --> 29:29.040]  T-tau, то есть p, это порядок опроксимации по времени, q порядок опроксимации по координате.
[29:29.040 --> 29:35.040]  Ну а если три переменных, то у нас здесь будут три шага по трёх координатам.
[29:35.040 --> 29:38.040]  Но я не буду сейчас забегать вперёд, мы сегодня до этого дойдём.
[29:38.040 --> 29:41.040]  Так, давайте вот так и сделаем.
[29:41.040 --> 29:43.040]  Давайте так и сделаем.
[29:43.040 --> 29:49.040]  Ну здесь, в общем-то, это сделать довольно просто.
[29:49.040 --> 29:54.040]  То есть я на самом деле здесь уже вам выписал эту схему.
[29:54.040 --> 30:02.040]  Давайте, чтобы экономить место на доске, здесь у малой давайте заменим на у большой.
[30:02.040 --> 30:12.040]  То есть будем исследовать наше апроксимирующее уравнение вот таким образом.
[30:12.040 --> 30:20.040]  А здесь я пока пишу равно. То есть я как бы в наше апроксимирующее уравнение поставил точное решение,
[30:20.040 --> 30:25.040]  точнее проекцию точного решения на нашу разницу в сетку. Зачем?
[30:25.040 --> 30:30.040]  Затем, чтобы исследовать это уравнение на апроксимацию.
[30:30.040 --> 30:33.040]  Я напомню вам, мы это делали уже.
[30:33.040 --> 30:38.040]  Например, что такое ун плюс один? Ун плюс один большой.
[30:38.040 --> 30:48.040]  Это есть ун плюс тау на у. Два штриха по времени нм.
[30:48.040 --> 30:54.040]  Плюс тау квадрат пополам на у.
[30:55.040 --> 31:01.040]  Здесь у нас уже будет три штриха по времени унм.
[31:01.040 --> 31:07.040]  И плюс у большой, у тау фубе.
[31:07.040 --> 31:11.040]  Это мы просто брали с вами и разлагали в ряд Эвера.
[31:11.040 --> 31:14.040]  Да, действительно точки нм.
[31:14.040 --> 31:23.040]  То же самое я могу написать для ун плюс один и ум минус один.
[31:23.040 --> 31:26.040]  У нас есть ун плюс один и ум минус один.
[31:26.040 --> 31:29.040]  Мы относительно точки нм тоже можем разлагать.
[31:29.040 --> 31:33.040]  Давайте вопрос.
[31:33.040 --> 31:37.040]  Так, сейчас здесь. А, я специально ноль убрал.
[31:37.040 --> 31:42.040]  У нас был ноль, когда здесь была умалая.
[31:42.040 --> 31:44.040]  Сейчас мы хотим что сделать?
[31:44.040 --> 31:49.040]  Подставить вот это уравнение, ну это операторное наше уравнение, апроксимирующее,
[31:49.040 --> 31:51.040]  вот эти разложения в ряд Эвера.
[31:51.040 --> 31:53.040]  Понятно, поэтому я ноль убрал.
[31:53.040 --> 31:58.040]  Это как раз то, что мы на самом деле делали и на прошлой лекции,
[31:58.040 --> 32:00.040]  и на позапрошлой лекции.
[32:00.040 --> 32:06.040]  То есть техника исследования апроксимирующего уравнения на порядок апроксимации,
[32:06.040 --> 32:10.040]  это разложение в ряд Тейлора.
[32:10.040 --> 32:14.040]  Если мы это все аккуратно поставим сюда, в это уравнение,
[32:14.040 --> 32:16.040]  то получим следующее.
[32:16.040 --> 32:24.040]  То есть мы получим Lt U-F в точке нм.
[32:24.040 --> 32:30.040]  То есть мы получим наш дифференциальный оператор просто-напросто.
[32:30.040 --> 32:34.040]  Ну это мы с вами делали, и это вы будете делать и на упражнениях,
[32:34.040 --> 32:36.040]  на семинарах и в заданиях.
[32:36.040 --> 32:39.040]  Это чисто такой технический вопрос.
[32:39.040 --> 32:41.040]  Да, давайте.
[32:41.040 --> 32:55.040]  Это верно, это я слишком много поставил.
[32:55.040 --> 33:00.040]  Здесь будет вторая производная и так далее.
[33:00.040 --> 33:01.040]  Конечно.
[33:01.040 --> 33:04.040]  Но это мы с вами все уже делали.
[33:04.040 --> 33:08.040]  И теперь, значит, что у нас получится?
[33:08.040 --> 33:11.040]  А у нас получится следующее.
[33:11.040 --> 33:14.040]  Как раз это первая производная, что вы правильно заметили,
[33:14.040 --> 33:17.040]  войдет сюда, в дифференциальный оператор.
[33:17.040 --> 33:18.040]  Почему здесь?
[33:18.040 --> 33:21.040]  У нас получится следующее, tau пополам.
[33:21.040 --> 33:28.040]  Здесь у нас будет tau пополам, а здесь будет как раз вторая производная.
[33:28.040 --> 33:37.040]  Вторая производная, нм, и минус h квадрат на 12.
[33:37.040 --> 33:44.040]  Давайте здесь сотрем.
[33:44.040 --> 33:53.040]  Здесь у нас будет четвертая производная по х, в точке нм.
[33:53.040 --> 33:59.040]  И плюс обольшое tau квадрат, плюс h в четвертой степени.
[33:59.040 --> 34:03.040]  Вот что у нас получится после того, как мы все разложим в ряд нм,
[34:03.040 --> 34:06.040]  относительно точки нм.
[34:06.040 --> 34:07.040]  Но здесь что?
[34:07.040 --> 34:12.040]  Давайте я напомню.
[34:12.040 --> 34:14.040]  К нашему дифференциальному уравнению,
[34:14.040 --> 34:18.040]  кстати говоря, в данном случае у нас просто ноль.
[34:18.040 --> 34:24.040]  l u минус f у нас просто ноль в нашем случае,
[34:24.040 --> 34:30.040]  поскольку это l u равняется нолью.
[34:30.040 --> 34:38.040]  Здесь вот все это выражение, это есть наша невязка r tau.
[34:38.040 --> 34:43.040]  Это невязка r tau, которую мы, прежде чем решать задачу, должны найти.
[34:43.040 --> 34:53.040]  Но решающее значение в погрешности, решающий вклад дает функция,
[34:53.040 --> 34:59.040]  которую мы называем обычно главным членом ошибки аппроксимации, r1 tau.
[34:59.040 --> 35:06.040]  Это вот как раз слагаемые с минимальными степенями при tau и h.
[35:06.040 --> 35:07.040]  Что это означает?
[35:07.040 --> 35:16.040]  Это означает, что наша схема, r1 tau, это есть обольшой tau плюс h квадрат.
[35:16.040 --> 35:20.040]  То есть схема имеет первый порядок по tau и второй по координате.
[35:20.040 --> 35:22.040]  Это мы с вами уже получали.
[35:22.040 --> 35:25.040]  Это мы с вами закрепили.
[35:25.040 --> 35:27.040]  А вот теперь такой вопрос.
[35:27.040 --> 35:31.040]  А здесь у нас tau квадрат плюс h4.
[35:31.040 --> 35:33.040]  Теперь вот такой вопрос.
[35:33.040 --> 35:35.040]  Несколько секунд для размышления.
[35:35.040 --> 35:39.040]  Мне очень хотелось бы поднять порядок аппроксимации схемы,
[35:39.040 --> 35:44.040]  в частности, до второго по времени и четвертого по координате.
[35:44.040 --> 35:48.040]  Что я, имея вот это исследование на аппроксимации, должен сделать,
[35:48.040 --> 35:53.040]  чтобы получить вот этот порядок, повышенный порядок аппроксимации?
[35:53.040 --> 35:56.040]  Что мне нужно для этого сделать?
[35:56.040 --> 35:58.040]  Давайте пять секунд для размышления.
[35:58.040 --> 36:00.040]  Какие идеи будут?
[36:03.040 --> 36:08.040]  Первая идея, конечно, самая экстремальная, радикальная.
[36:08.040 --> 36:12.040]  Занудить. Прекрасно.
[36:12.040 --> 36:18.040]  Но на самом деле, если мы занудим, то мы получим некие функции.
[36:20.040 --> 36:23.040]  А это четвертое производное.
[36:26.040 --> 36:37.040]  Отсюда, когда мы разлагаем вот это второе производное,
[36:37.040 --> 36:43.040]  если вы честно разложите у m-1, у m-1 в ряда Тейлора,
[36:43.040 --> 36:46.040]  поставите в эту аппроксимацию второй производной,
[36:46.040 --> 36:49.040]  то вы получите второе и четвертое производное.
[36:49.040 --> 36:53.040]  Просто здесь эти третьи производные симметрично сократятся.
[36:53.040 --> 36:56.040]  Здесь m-1, здесь m-1.
[36:56.040 --> 37:02.040]  Ну, на самом деле, посмотрите, то ли на поздно прошлой лекции мы это делали,
[37:02.040 --> 37:04.040]  ну или на семинарах будете делать.
[37:04.040 --> 37:07.040]  Просто честно возьмите, разложите и получите как раз,
[37:07.040 --> 37:11.040]  что минимальное производное четвертое будет.
[37:16.040 --> 37:18.040]  Сгущать сетку, прекрасная идея.
[37:18.040 --> 37:22.040]  Сгущение сетки это всегда хорошее дело, это всегда увеличение точности.
[37:22.040 --> 37:27.040]  Но, как я говорил, здесь не всегда удается ее сгустить до такой степени.
[37:27.040 --> 37:32.040]  Ну, в случае задач, скажем, одномерно, где t и x есть,
[37:32.040 --> 37:39.040]  это реально, действительно, там можно сгустить сетку до 10 в 9 степени и так далее.
[37:39.040 --> 37:41.040]  То есть сделать очень мелкую сетку,
[37:41.040 --> 37:45.040]  получить результат очень близко к точному решению одномерной задачи.
[37:45.040 --> 37:49.040]  Но когда вы переходите на задачи двух, особенно трехмерные,
[37:49.040 --> 37:53.040]  здесь уже это все будет намного сложнее.
[37:53.040 --> 37:56.040]  Нужно будет поднимать точность метода.
[37:59.040 --> 38:01.040]  Таука, кашка, водорад.
[38:01.040 --> 38:03.040]  Так, ладно.
[38:03.040 --> 38:08.040]  Нет, ну это все, вы идете потому, что давайте занудим этот член.
[38:08.040 --> 38:11.040]  Не удастся его так просто занудить.
[38:11.040 --> 38:15.040]  Не удастся, у вас будет очень сложная зависимость между Тау и Аш,
[38:15.040 --> 38:17.040]  если вы просто будете занудить.
[38:17.040 --> 38:19.040]  Ну, я подсказываю идею.
[38:19.040 --> 38:23.040]  Смотрите, у нас есть в левой части...
[38:23.040 --> 38:26.040]  Давайте я вот это затру, да, разложение в ряд Тейлор.
[38:26.040 --> 38:29.040]  Это вы без меня все сделаете.
[38:33.040 --> 38:41.040]  Вот у нас вот эта левая часть, есть не что иное, как разностный оператор.
[38:41.040 --> 38:43.040]  Разностный оператор.
[38:43.040 --> 38:50.040]  Что он опроксимирует нашу задачу с порядком точности о Тау плюс Аш квадрат.
[38:50.040 --> 38:54.040]  Теперь, смотрите, я беру и вот этот главный член ошибки опроксимации
[38:54.040 --> 39:00.040]  перетаскиваю в левую часть уравнения к нашему разностному оператору.
[39:00.040 --> 39:04.040]  Это подсказка, что дальше нужно сделать.
[39:04.040 --> 39:08.040]  Тогда если я перетащу, у нас в правой части останется вот это.
[39:08.040 --> 39:10.040]  Тау квадрат и Аш четвертый.
[39:10.040 --> 39:12.040]  Но перетащить мало.
[39:12.040 --> 39:14.040]  Нужно еще что-то сделать.
[39:14.040 --> 39:16.040]  Что?
[39:16.040 --> 39:18.040]  Что?
[39:20.040 --> 39:24.040]  Вот главный член ошибки опроксимации.
[39:24.040 --> 39:26.040]  Вот его.
[39:29.040 --> 39:31.040]  Перетаскиваю в левую часть.
[39:32.040 --> 39:37.040]  И если я правильно опроксимирую этот главный член ошибки опроксимации,
[39:37.040 --> 39:41.040]  то у меня получится вот схема с таким порядком точности.
[39:41.040 --> 39:43.040]  С повышенным порядком точности.
[39:43.040 --> 39:45.040]  Тау квадрат плюс Аш четвертый.
[39:45.040 --> 39:49.040]  А как мы опроксимировать будем?
[39:49.040 --> 39:53.040]  Да, чтобы такое получилось.
[39:53.040 --> 39:55.040]  Хорошо, смотрите.
[39:55.040 --> 40:03.040]  Итак, что у нас будет у второй производной по времени?
[40:03.040 --> 40:05.040]  Так, смотрите.
[40:05.040 --> 40:07.040]  Теперь мы смотрим сюда.
[40:08.040 --> 40:14.040]  Из этого уравнения мы можем выразить вторую производную по времени
[40:14.040 --> 40:17.040]  через четвертую производную по координате.
[40:17.040 --> 40:19.040]  Как это сделать?
[40:20.040 --> 40:22.040]  Дважды продифференцировать.
[40:22.040 --> 40:26.040]  И окажется, что в данном случае у Т, Т, вторая производная,
[40:26.040 --> 40:32.040]  это есть не что иное, как четвертая производная по координате.
[40:32.040 --> 40:35.040]  То есть продифференцируйте ее дважды.
[40:35.040 --> 40:38.040]  По Т, потом по Х, вычтите и получите вот.
[40:38.040 --> 40:40.040]  То же самое мы получали.
[40:44.040 --> 40:47.040]  Получаем, чтобы вторая производная по времени
[40:47.040 --> 40:51.040]  для данного уравнения равняется четвертой производной по координате.
[40:51.040 --> 40:54.040]  Вот возьмите это и сделайте, продифференцируйте.
[40:54.040 --> 40:59.040]  Уравнение по Т, потом по Х, вычтите и получите.
[40:59.040 --> 41:02.040]  То же самое мы делаем, кстати, для уравнения переноса, если помните.
[41:02.040 --> 41:04.040]  Помните, у по Т минус у по Х.
[41:04.040 --> 41:09.040]  И оказалось, что производные все по Т равняются производным по Х.
[41:09.040 --> 41:11.040]  Но здесь похитрее.
[41:11.040 --> 41:15.040]  Разумеется, если я поставлю коэффициент какой-то,
[41:15.040 --> 41:21.040]  типа коэффициент и по проводности, то здесь будет еще коэффициент входить.
[41:21.040 --> 41:29.040]  Поэтому я вот эту вот вторую производную
[41:29.040 --> 41:35.040]  могу вместо нее написать производную по четвертую производную по Х.
[41:35.040 --> 41:39.040]  У нас здесь четвертая производная и здесь четвертая производная.
[41:45.040 --> 41:47.040]  Хорошая идея.
[41:49.040 --> 41:54.040]  Конечно, потому что схема, я взял явную,
[41:54.040 --> 41:58.040]  но вы точно то же самое можете сделать со схемой неявной.
[41:59.040 --> 42:02.040]  А если схема явная, вам тау придется брать маленькая,
[42:02.040 --> 42:07.040]  а если схему возьмете неявную, то схема будет устойчива при любом тау и аж.
[42:07.040 --> 42:09.040]  Понятно, да?
[42:09.040 --> 42:12.040]  Но я просто взял для простоты схему явную, чтобы меньше писать.
[42:12.040 --> 42:14.040]  Неявную вы без меня распишите.
[42:14.040 --> 42:16.040]  Там просто больше писать придется.
[42:16.040 --> 42:20.040]  Итак, я беру вот этот вот главный член ошибки аппроксимации
[42:20.040 --> 42:22.040]  и переношу в левую часть.
[42:22.040 --> 42:25.040]  Давайте я это сделаю.
[42:26.040 --> 42:30.040]  Как бы здесь нам лучше это написать?
[42:33.040 --> 42:35.040]  Давайте я еще раз припишу.
[42:37.040 --> 42:39.040]  Вот у нас левая часть.
[42:41.040 --> 42:44.040]  Это у нас просто в силу нашего уравнения ноль.
[42:44.040 --> 42:46.040]  l2-f это просто ноль.
[42:46.040 --> 42:53.040]  Я могу его просто убрать, чтобы меньше было записей.
[42:55.040 --> 43:03.040]  А вот эту вот часть я пишу минус, а здесь плюс.
[43:03.040 --> 43:05.040]  И перенес в левую часть.
[43:05.040 --> 43:08.040]  Тогда здесь у нас будет не плюс, а равно.
[43:08.040 --> 43:11.040]  То есть элементарная алгебраическая операция.
[43:11.040 --> 43:14.040]  Перенес главный член ошибки аппроксимации в левую часть.
[43:14.040 --> 43:17.040]  Это уже совсем близкая подсказка.
[43:17.040 --> 43:19.040]  Что дальше я делаю?
[43:19.040 --> 43:23.040]  Мне нужно сделать, чтобы получить повышенный порядок точности.
[43:26.040 --> 43:29.040]  Ой, да, у нас все правильно.
[43:29.040 --> 43:31.040]  У по х.
[43:31.040 --> 43:36.040]  Давайте я возьму и напишу более аккуратно.
[43:36.040 --> 43:38.040]  Tau пополам.
[43:40.040 --> 43:43.040]  Минус Tau пополам, минус h квадрат.
[43:43.040 --> 43:47.040]  Я переписываю главный член ошибки аппроксимации на 12.
[43:47.040 --> 43:49.040]  И на У.
[43:49.040 --> 43:54.040]  И четвертая производная по У.
[43:55.040 --> 44:06.040]  Ну, и равняется O.
[44:06.040 --> 44:10.040]  Tau квадрат плюс h в четвертой.
[44:10.040 --> 44:16.040]  То есть если мы аппроксимируем вот этот главный член ошибки аппроксимации
[44:16.040 --> 44:18.040]  с нужной степенью точности,
[44:18.040 --> 44:21.040]  то мы получим разноцветную схему вот такого порядка.
[44:21.040 --> 44:24.040]  Второго по времени и четвертого по h.
[44:24.040 --> 44:26.040]  Что нам осталось сделать?
[44:26.040 --> 44:30.040]  Нам осталось расписать четвертую производную по точкам.
[44:30.040 --> 44:33.040]  То есть аппроксимировать четвертую производную.
[44:33.040 --> 44:36.040]  Ну, у меня есть сомнения в том, что вы помните,
[44:36.040 --> 44:39.040]  как аппроксимируется четвертая производная.
[44:39.040 --> 44:42.040]  Или я не прав, кто-нибудь может расписать,
[44:42.040 --> 44:45.040]  как четвертая производная аппроксимируется.
[44:45.040 --> 44:47.040]  Как?
[44:47.040 --> 44:49.040]  Абсолютно верно.
[44:49.040 --> 44:54.040]  Любую производную мы можем выразить через площадь бинома Ньютона.
[44:54.040 --> 44:58.040]  Но давайте я не буду расписывать бином Ньютона,
[44:58.040 --> 45:00.040]  а то мы далековато уйдем.
[45:00.040 --> 45:03.040]  Просто вы пишу, как аппроксимируется четвертая производная.
[45:03.040 --> 45:09.040]  Четвертая производная аппроксимируется по 5 точкам следующим образом.
[45:09.040 --> 45:35.040]  И делим на h в четвертой степени.
[45:35.040 --> 45:38.040]  Это будет аппроксимация четвертой производной
[45:38.040 --> 45:42.040]  с четвертым порядком точности.
[45:42.040 --> 45:45.040]  Если мы так делаем, то мы получаем,
[45:45.040 --> 45:49.040]  то есть вставим вот эту аппроксимацию сюда.
[45:49.040 --> 45:52.040]  То есть мы берем и пишем следующую.
[45:52.040 --> 45:54.040]  Ну, давайте двойку вынесем.
[45:54.040 --> 46:01.040]  Одна вторая tau минус h квадрат на 6.
[46:01.040 --> 46:04.040]  А здесь вот такой оператор четвертая производная.
[46:04.040 --> 46:07.040]  Аппроксимация четвертая производная обычно пишется так.
[46:07.040 --> 46:13.040]  λ4х, у, н, н.
[46:13.040 --> 46:17.040]  Разнообразная аппроксимация четвертой производной.
[46:17.040 --> 46:22.040]  Если мы так делаем, то мы получаем схему повышенного порядка точности.
[46:22.040 --> 46:26.040]  Все здорово, но какая расплата за повышенный порядок точности?
[46:26.040 --> 46:30.040]  Всегда нужно чем-то расплачиваться приходится за улучшение метода.
[46:30.040 --> 46:32.040]  Шаблону, конечно, да.
[46:32.040 --> 46:35.040]  То есть у нас шаблон получится следующего вида.
[46:38.040 --> 46:40.040]  У нас будет вот такой шаблон.
[46:40.040 --> 46:43.040]  Он будет действительно двухслойный.
[46:43.040 --> 46:48.040]  То есть слой n и слой n плюс 1.
[46:48.040 --> 46:53.040]  Здесь точка m, m плюс 1, m плюс 2.
[46:53.040 --> 46:58.040]  Здесь у нас m минус 1 и m плюс 2.
[46:58.040 --> 47:02.040]  То есть у нас уже шаблон не трех, а пятипотечный.
[47:02.040 --> 47:06.040]  Ну а мы же можем сделать как?
[47:06.040 --> 47:08.040]  Это у меня явная схема.
[47:08.040 --> 47:10.040]  Мы можем сделать неявную схему.
[47:10.040 --> 47:16.040]  Поскольку ясно, что явная схема будет иметь жесткое ограничение на шаг по времени.
[47:16.040 --> 47:18.040]  Тогда можно сделать неявную схему.
[47:18.040 --> 47:23.040]  То есть вот сюда перенести наши точки.
[47:23.040 --> 47:25.040]  Неявная схема будет абсолютно устойчива.
[47:25.040 --> 47:27.040]  Для любых того и ваше.
[47:27.040 --> 47:29.040]  Но это вы уже без меня сделаете.
[47:29.040 --> 47:35.040]  Получите неявную схему, высокого порядка точности и так далее.
[47:35.040 --> 47:38.040]  Но здесь какие будут у вас дополнительные задачи?
[47:38.040 --> 47:40.040]  Какая еще возникнет?
[47:40.040 --> 47:42.040]  С краевыми условиями.
[47:42.040 --> 47:47.040]  То есть нужно будет опроксивировать краевые условия с тем же порядком точности.
[47:47.040 --> 47:50.040]  Эту задачу нужно будет тоже решить.
[47:50.040 --> 47:54.040]  То есть опроксивация краевых условий.
[47:54.040 --> 47:57.040]  Но это один из вариантов.
[47:57.040 --> 48:01.040]  Есть другие, но не все сразу.
[48:01.040 --> 48:07.040]  Схема самой высокой порядка точности, которую я знаю,
[48:07.040 --> 48:11.040]  это получил профессор Толстых Андрей Игоревич.
[48:11.040 --> 48:13.040]  Это мой старший товарищ.
[48:13.040 --> 48:18.040]  Он еще ученик великого академика биоцерковского,
[48:18.040 --> 48:21.040]  который создал не только нашу кафедру, но и весь вестих.
[48:21.040 --> 48:23.040]  Андрей Игоревич Толстых.
[48:23.040 --> 48:27.040]  Он предложил схему 32-го порядка опроксивации.
[48:27.040 --> 48:29.040]  Понятно, да?
[48:29.040 --> 48:33.040]  Но там просто встает немного другой вопрос такой, деликатный.
[48:33.040 --> 48:35.040]  Какой компьютер нужно подбирать?
[48:35.040 --> 48:38.040]  Поскольку там и double precision, и все прочее.
[48:38.040 --> 48:46.040]  То есть там уже точность метода начинает быть точнее от точности компьютера.
[48:46.040 --> 48:50.040]  На это просто он отвечает очень оптимистично.
[48:50.040 --> 48:52.040]  Для будущих компьютеров.
[48:52.040 --> 48:56.040]  Будущие компьютеры действительно будут еще более точны,
[48:56.040 --> 48:59.040]  еще больше разрядность иметь и так далее.
[48:59.040 --> 49:01.040]  Ну, здесь пока вот так.
[49:01.040 --> 49:03.040]  Все, я вот так.
[49:03.040 --> 49:05.040]  Сколько у нас времени?
[49:05.040 --> 49:07.040]  Я показал пример.
[49:07.040 --> 49:10.040]  Время у нас есть еще.
[49:10.040 --> 49:12.040]  Теперь идем дальше.
[49:12.040 --> 49:15.040]  То есть как строить схему, как увеличивать порядок
[49:15.040 --> 49:18.040]  с помощью расширения шаблона, вы уже знаете.
[49:18.040 --> 49:20.040]  Теперь идем дальше.
[49:20.040 --> 49:23.040]  Давайте рассмотрим, как мы будем работать
[49:23.040 --> 49:26.040]  с уравнением параболического типа одномерным,
[49:26.040 --> 49:34.040]  если у нас есть схемы с переменными коэффициентами.
[49:34.040 --> 49:38.040]  То есть коэффициенты зависят от независимых переменных tau х
[49:38.040 --> 49:40.040]  и с нелинейными задачами.
[49:40.040 --> 49:44.040]  То есть когда коэффициент, его правая часть может зависеть
[49:44.040 --> 49:48.040]  от самого решения.
[49:48.040 --> 49:50.040]  От самого решения.
[49:50.040 --> 49:56.040]  На первый вопрос на самом деле мы уже с вами частично отвечали,
[49:56.040 --> 50:00.040]  когда говорили о краевых задачах для обыкновенных дифференциальных уравнений.
[50:00.040 --> 50:02.040]  Ну, давайте я напомню.
[50:02.040 --> 50:10.040]  Итак, пусть у нас будет опять же уравнение типа проводности одномерное.
[50:10.040 --> 50:19.040]  Это вот линейное уравнение.
[50:19.040 --> 50:24.040]  Нам нужно сделать так, чтобы у нас коэффициенты были переменные.
[50:24.040 --> 50:30.040]  То есть d под x, а здесь a, например, от xt на d под x,
[50:30.040 --> 50:37.040]  плюс f от xt, плюс x.
[50:37.040 --> 50:43.040]  Я напомню, что-то подобное с чем-то подобным мы сталкивались,
[50:43.040 --> 50:47.040]  когда говорили о краевых задачах с переменными коэффициентами.
[50:47.040 --> 50:49.040]  В чем был вопрос?
[50:49.040 --> 50:55.040]  Дело в том, что если у нас есть три точки, скажем, m, m плюс один и m минус один,
[50:55.040 --> 50:57.040]  но в данном случае на координатной оси,
[50:57.040 --> 51:02.040]  то, например, мы в точке m можем поместить контактный разрыв.
[51:02.040 --> 51:05.040]  Ну, скажем, биметаллическая пластинка, алюминий вайфрам,
[51:05.040 --> 51:08.040]  и в точку m мы помещаем контактный разрыв.
[51:08.040 --> 51:11.040]  Какой коэффициент брать в этой точке?
[51:11.040 --> 51:13.040]  Алюминий или вайфрам?
[51:13.040 --> 51:15.040]  Трудно сказать.
[51:15.040 --> 51:19.040]  Поэтому лучше всего коэффициент брать здесь алюминий, а здесь вайфрам.
[51:19.040 --> 51:22.040]  А эту точку не трогать.
[51:22.040 --> 51:28.040]  Поэтому опроксимация этого уравнения имеет такой вид.
[51:28.040 --> 51:32.040]  Давайте так ОНМ.
[51:32.040 --> 51:37.040]  Это я сокращенную опроксимацию производной по времени пишу.
[51:37.040 --> 51:39.040]  А здесь у нас будет так.
[51:39.040 --> 51:41.040]  Единица делить на h.
[51:41.040 --> 51:44.040]  Так, здесь у нас что?
[51:44.040 --> 51:50.040]  Коэффициент a, m плюс одна вторая.
[51:50.040 --> 51:52.040]  Здесь у нас u.
[51:52.040 --> 51:55.040]  Ну, давайте схему неявную уже для разнообразия напишем.
[51:55.040 --> 52:00.040]  Обычно чаще всего, как вы, видимо, догадались, для этих уравнений явные схемы используются.
[52:07.040 --> 52:15.040]  Так, минус u, n плюс 1, m делим на h и минус a.
[52:15.040 --> 52:18.040]  Давайте возьмем a, n.
[52:18.040 --> 52:25.040]  М минус одна вторая, u, n плюс 1, m.
[52:25.040 --> 52:31.040]  Минус u, n плюс 1, m минус 1 на h.
[52:31.040 --> 52:37.040]  Ну и плюс f от u, n, m.
[52:37.040 --> 52:42.040]  Ну вот в таком виде, если мы помещаем в точку m наш контактный разрыв,
[52:42.040 --> 52:50.040]  мы можем решать задачу, не задумываясь о решении задачи, так называемой задачи, контактного разрыва.
[52:50.040 --> 52:53.040]  То есть, вообще говоря, если у нас есть какие-то разрывы в решениях,
[52:53.040 --> 52:58.040]  то в этих разрывах обычно решается отдельная система уравнений, как правило, гибридических.
[52:58.040 --> 53:04.040]  Но можно, оказывается, делать такие схемы, которые называются схемой бегущего счета.
[53:04.040 --> 53:09.040]  То есть схема, в которой проходят все разрывы и их корректно описывают.
[53:09.040 --> 53:12.040]  Это вот такая схема.
[53:12.040 --> 53:17.040]  На самом деле мы с вами об этом уже говорили в декабре, когда говорили о задачах краевых.
[53:17.040 --> 53:21.040]  Или в январе, по-моему.
[53:21.040 --> 53:24.040]  Алгоритм решений, только вы меня помните.
[53:24.040 --> 53:27.040]  Вот я здесь не дописал, а вы не заметили.
[53:27.040 --> 53:33.040]  Чего я здесь не дописал? Подскажите.
[53:33.040 --> 53:38.040]  Что-то я здесь не дописал.
[53:38.040 --> 53:40.040]  Плюс единичка.
[53:40.040 --> 53:43.040]  Но я не специально. Торопился, наверное.
[53:43.040 --> 53:49.040]  Ну вот теперь, если мы на каком-то слое n плюс 1 остановились,
[53:49.040 --> 53:56.040]  какое алгоритм решения вот этой задачки у нас будет, если мы на слое n плюс 1 остановились?
[53:56.040 --> 54:01.040]  Это система линейных уравнений у нас получилась, да?
[54:01.040 --> 54:06.040]  Как мы будем их решать? Каким алгоритмом или методом?
[54:07.040 --> 54:11.040]  Смотрим. У нас есть три неизвестных.
[54:11.040 --> 54:19.040]  Ум минус 1, ум плюс 1.
[54:19.040 --> 54:26.040]  Так, давайте, чтобы было совсем понятно, я вот сокращенную аппроксимацию беру
[54:26.040 --> 54:29.040]  и напишу не сокращенную, а полную.
[54:29.040 --> 54:35.040]  Аппроксимацию в производной по времени, в первом порядке точности.
[54:35.040 --> 54:37.040]  Теперь давайте отвечайте.
[54:37.040 --> 54:43.040]  У нас в нашей системе линейных уравнений есть три неизвестных.
[54:43.040 --> 54:45.040]  Остальные другие.
[54:45.040 --> 54:52.040]  Если мы выпишем эту систему в матричном виде, то матрица у нас будет какой?
[54:52.040 --> 54:55.040]  Трехдиагональная, то есть прогонка.
[54:55.040 --> 54:58.040]  Или по американски алгоритм Тобсона, либо так, либо так.
[54:58.040 --> 55:02.040]  И так, и так, верно, но мы обычно называем прогонкой.
[55:02.040 --> 55:07.040]  И одновременно этот алгоритм был предложен в конце 50-х годов прошлого века
[55:07.040 --> 55:12.040]  в Америке Тобсоном, у нас в Гельфандом.
[55:12.040 --> 55:16.040]  Гельфандом, вы не судите про рекламную математику.
[55:16.040 --> 55:20.040]  То есть алгоритм решения на каждом временном условии прогонка.
[55:20.040 --> 55:23.040]  И так мы идем по временным слоям и решаем эту задачу,
[55:23.040 --> 55:28.040]  имея, конечно же, краевые условия, имея начальные данные.
[55:28.040 --> 55:30.040]  Хорошо.
[55:30.040 --> 55:34.040]  Так, посмотрите, что непонятно может быть.
[55:34.040 --> 55:36.040]  Давайте.
[55:36.040 --> 55:41.040]  Почему мы на n плюс 1 берем производную?
[55:41.040 --> 55:47.040]  Давайте вспомним нашу разностную сетку, кардината ТХ.
[55:47.040 --> 55:54.040]  По времени мы разбиваем нашу ось по слоям.
[55:54.040 --> 56:00.040]  Ну, слой там m, n плюс 1, n минус 1 и так далее.
[56:00.040 --> 56:03.040]  То есть это по времени мы по слоям разбиваем.
[56:03.040 --> 56:05.040]  По координатам, по лучам.
[56:05.040 --> 56:11.040]  Ну, слои и лучи, это такая неофициальная, но признанная терминология.
[56:11.040 --> 56:14.040]  По времени слои, по координатам лучи.
[56:14.040 --> 56:20.040]  Ну, например, m луч, этот m плюс 1 луч, этот m минус 1.
[56:20.040 --> 56:26.040]  Здесь у нас дается при х равно 0 одно левое краевое условие.
[56:26.040 --> 56:32.040]  Здесь при х, равном х большое, правое краевое условие ставится.
[56:32.040 --> 56:35.040]  Правое краевое условие ставится.
[56:35.040 --> 56:37.040]  Вот у нас, например, слой n.
[56:37.040 --> 56:40.040]  Ну, пусть будет n плюс 1 и n.
[56:40.040 --> 56:43.040]  На слое n мы все знаем.
[56:43.040 --> 56:47.040]  Ну, например, на n равно 0, это просто начальные данные будут.
[56:47.040 --> 56:52.040]  Ну, потом мы поднялись до слоя n, и на слое n нам все решения известны.
[56:52.040 --> 56:56.040]  Тогда нам нужно определить решение на слое n плюс 1.
[56:56.040 --> 57:01.040]  Что мы получаем? Мы имеем три точки на слое n плюс 1 и одну точку,
[57:01.040 --> 57:05.040]  соответственно с этой системой уравнения, на слое n.
[57:05.040 --> 57:08.040]  Эта точка решений нам известна.
[57:08.040 --> 57:12.040]  В этой точке решения, это краевое условие наше, оно дано.
[57:12.040 --> 57:15.040]  У нас нет решений в двух точках.
[57:15.040 --> 57:18.040]  Что мы можем сделать, чтобы их определить?
[57:18.040 --> 57:25.040]  Только одно, решить систему линейного уравнения вдоль всего этого слоя, n плюс 1.
[57:25.040 --> 57:29.040]  А здесь у нас будет краевое условие опять заодно.
[57:29.040 --> 57:32.040]  То есть это та же самая прогонка, о которой мы с вами говорили,
[57:32.040 --> 57:35.040]  когда разбирали решения краевых задач.
[57:35.040 --> 57:39.040]  Только тогда у нас была одна прогонка, от 0 до х большое,
[57:39.040 --> 57:42.040]  а здесь у нас n большой прогонок.
[57:42.040 --> 57:46.040]  Сколько сладёв, столько прогонок мы и делаем.
[57:46.040 --> 57:49.040]  Ну подумайте ещё, задавайте вопрос.
[57:53.040 --> 57:56.040]  Сейчас ещё раз.
[57:56.040 --> 57:59.040]  А, хороший, правильный вопрос.
[57:59.040 --> 58:05.040]  Мы, конечно, описали любая функция в узле n плюс 1 на 2,
[58:06.040 --> 58:13.040]  это есть fm плюс fm плюс 1 делим пополам.
[58:13.040 --> 58:19.040]  То есть это просто точка посередине, двух узлов.
[58:19.040 --> 58:24.040]  Если нам нужны другие функции между узлами,
[58:24.040 --> 58:28.040]  мы используем оператор интерполяции, о которых мы говорили.
[58:28.040 --> 58:33.040]  Но если мы линейный оператор интерполяции возьмём, это и получим.
[58:33.040 --> 58:37.040]  Но если мы захотим, скажем, какой-то более точный оператор второго порядка точности,
[58:37.040 --> 58:42.040]  то для этого нам потребуется 3 узла, чтобы правого построить.
[58:42.040 --> 58:46.040]  Тогда у нас будет более точный порядок интерполяции,
[58:46.040 --> 58:48.040]  и количество узлов будет увеличиваться.
[58:48.040 --> 58:50.040]  То есть для всего нужно платить.
[58:50.040 --> 58:54.040]  В данном случае я писал именно так.
[58:54.040 --> 58:57.040]  Ну посмотрите и подумайте, что вот здесь непонятно.
[59:03.040 --> 59:05.040]  А, да, конечно, конечно.
[59:05.040 --> 59:09.040]  А давайте тогда, если есть вопросы, начнём с самого начала.
[59:09.040 --> 59:11.040]  Пусть у нас будет так.
[59:11.040 --> 59:15.040]  Вот этот слой n равняется нулю, начальный данный.
[59:15.040 --> 59:19.040]  Слой начальных данных весь нам известен, вот за одну задачу.
[59:19.040 --> 59:22.040]  То есть нам известно всё здесь,
[59:22.040 --> 59:28.040]  нам известно всё вот здесь, правое краевое условие, всё здесь, левое краевое условие.
[59:28.040 --> 59:32.040]  Нам не известно решений в этих узлах, о которых мы говорим.
[59:32.040 --> 59:36.040]  Давайте пусть у нас будет n равна единице.
[59:36.040 --> 59:39.040]  То есть вот оно, n равна единице.
[59:39.040 --> 59:43.040]  Как мы ищем решение при n равной единице?
[59:43.040 --> 59:48.040]  Нам известно решение во всех точках вот этого нижнего слоя.
[59:48.040 --> 59:50.040]  Это у нас начальные данные.
[59:50.040 --> 59:52.040]  Ну давайте пометим крестиком.
[59:52.040 --> 59:54.040]  Вот оно, да.
[59:54.040 --> 59:56.040]  Всего у нас какие точки?
[59:56.040 --> 59:58.040]  Вот я их обозначил.
[59:58.040 --> 01:00:03.040]  M минус 1, M и M плюс 1.
[01:00:03.040 --> 01:00:07.040]  Решение вот в этих точках нам не известно,
[01:00:07.040 --> 01:00:09.040]  а вот в этих двух известно.
[01:00:09.040 --> 01:00:12.040]  Краевое данное и начальное данное.
[01:00:14.040 --> 01:00:17.040]  И здесь нам известно решение.
[01:00:17.040 --> 01:00:20.040]  Краевое условие и так далее.
[01:00:20.040 --> 01:00:26.040]  И вот для всех этих точек мы выписываем систему уравнений.
[01:00:26.040 --> 01:00:29.040]  Ау равняется f.
[01:00:29.040 --> 01:00:31.040]  Вот эта система уравнений.
[01:00:31.040 --> 01:00:36.040]  Поскольку здесь M у нас меняется от 0 до M большого.
[01:00:36.040 --> 01:00:40.040]  Вот система уравнений получается вдоль слоя n.
[01:00:40.040 --> 01:00:44.040]  Ну первого слоя в данном случае, первого слоя.
[01:00:44.040 --> 01:00:46.040]  Поэтому на первом слое мы все решаем.
[01:00:46.040 --> 01:00:48.040]  И переходим на второй слой.
[01:00:48.040 --> 01:00:50.040]  n равняется 2.
[01:00:50.040 --> 01:00:53.040]  Тоже самое, прогонку сделаем при n равняется 2.
[01:00:53.040 --> 01:00:55.040]  Потом при n равняется 3.
[01:00:55.040 --> 01:00:57.040]  Поднимаемся по шагам.
[01:01:00.040 --> 01:01:03.040]  Подумать несколько секунд, что может быть еще непонятно.
[01:01:06.040 --> 01:01:08.040]  Но чтобы окончательно было понятно,
[01:01:08.040 --> 01:01:11.040]  можете вспомнить нашу лекцию по краевым задачам.
[01:01:11.040 --> 01:01:13.040]  Мы это подробно разбирали.
[01:01:13.040 --> 01:01:17.040]  Там все то же самое, только там одну прогонку мы делаем.
[01:01:17.040 --> 01:01:21.040]  А здесь мы делаем прогонку на каждом слой по времени.
[01:01:21.040 --> 01:01:23.040]  Так все одно и то же.
[01:01:23.040 --> 01:01:28.040]  Помните метод стрельбы, метод прогонки, метод простых итераций.
[01:01:28.040 --> 01:01:30.040]  Это все для краевых задач.
[01:01:30.040 --> 01:01:32.040]  Все то же самое здесь.
[01:01:32.040 --> 01:01:34.040]  Только n большой раз мы делаем.
[01:01:35.040 --> 01:01:36.040]  Идем дальше.
[01:01:36.040 --> 01:01:38.040]  Теперь пусть у нас задача нелинейная.
[01:01:38.040 --> 01:01:42.040]  То есть коэффициенты правой части могут зависеть от решения.
[01:01:43.040 --> 01:01:51.040]  В данном случае я чуть изменю ситуацию.
[01:01:51.040 --> 01:01:58.040]  У нас правая часть от u и коэффициент от u зависит от решения.
[01:02:02.040 --> 01:02:04.040]  Давайте осмотрем.
[01:02:06.040 --> 01:02:08.040]  Сколько у нас времени осталось?
[01:02:10.040 --> 01:02:11.040]  Сейчас?
[01:02:11.040 --> 01:02:12.040]  20 минут?
[01:02:12.040 --> 01:02:14.040]  Нет, осталось 20.
[01:02:14.040 --> 01:02:15.040]  Осталось 20?
[01:02:15.040 --> 01:02:17.040]  Это же куча времени.
[01:02:17.040 --> 01:02:18.040]  Отлично.
[01:02:18.040 --> 01:02:20.040]  Тогда мы успеем это сделать.
[01:02:20.040 --> 01:02:22.040]  Идем дальше.
[01:02:22.040 --> 01:02:36.040]  Итак, у нас коэффициент зависит от решения.
[01:02:36.040 --> 01:02:37.040]  Вот решение.
[01:02:37.040 --> 01:02:44.040]  Я предложу пока ту же схему, которую я предлагал.
[01:02:44.040 --> 01:02:48.040]  Производную по времени опроксимирую.
[01:02:48.040 --> 01:02:51.040]  А здесь сделаю следующую единицу от h.
[01:02:53.040 --> 01:02:55.040]  Пусть будет an.
[01:02:55.040 --> 01:02:57.040]  n плюс 1.
[01:02:57.040 --> 01:02:58.040]  Вторая.
[01:02:58.040 --> 01:03:00.040]  Ун плюс 1.
[01:03:00.040 --> 01:03:01.040]  m.
[01:03:01.040 --> 01:03:03.040]  Минус ун.
[01:03:03.040 --> 01:03:06.040]  Здесь m.
[01:03:06.040 --> 01:03:08.040]  На h.
[01:03:08.040 --> 01:03:10.040]  Минус an.
[01:03:10.040 --> 01:03:12.040]  m минус 1.
[01:03:12.040 --> 01:03:13.040]  Вторая.
[01:03:13.040 --> 01:03:16.040]  Здесь ун плюс 1.
[01:03:16.040 --> 01:03:19.040]  Минус ун плюс 1.
[01:03:19.040 --> 01:03:21.040]  Здесь у нас m.
[01:03:21.040 --> 01:03:22.040]  Здесь m минус 1.
[01:03:22.040 --> 01:03:24.040]  Делим на h.
[01:03:24.040 --> 01:03:29.040]  Ну и плюс f от u, n, m.
[01:03:29.040 --> 01:03:32.040]  Смотрите, с первого взгляда.
[01:03:32.040 --> 01:03:35.040]  То же самое, что и раньше.
[01:03:35.040 --> 01:03:41.040]  Я написал буквально один к одному то, что было написано на доске и раньше.
[01:03:41.040 --> 01:03:46.040]  На самом деле есть некая разница.
[01:03:46.040 --> 01:03:47.040]  Мы смотрим.
[01:03:47.040 --> 01:03:51.040]  Действительно, у нас в правой части мы берем решение с нижнего слоя.
[01:03:51.040 --> 01:03:56.040]  Это называемая нелинейность с нижнего слоя.
[01:03:56.040 --> 01:04:00.040]  А на верхнем слое, n плюс 1, у нас опять тоже три точки.
[01:04:00.040 --> 01:04:02.040]  Ум минус 1.
[01:04:02.040 --> 01:04:04.040]  n плюс 1.
[01:04:04.040 --> 01:04:05.040]  Ум.
[01:04:05.040 --> 01:04:06.040]  n.
[01:04:06.040 --> 01:04:07.040]  Ум.
[01:04:07.040 --> 01:04:08.040]  Плюс 1.
[01:04:08.040 --> 01:04:10.040]  n плюс 1.
[01:04:10.040 --> 01:04:12.040]  То есть опять среднеизвестная прогонка.
[01:04:12.040 --> 01:04:16.040]  Прямо один к одному, как вот до этого.
[01:04:16.040 --> 01:04:19.040]  Это верно, но почти верно.
[01:04:19.040 --> 01:04:29.040]  Что на самом деле может нас затормозить в быстром программировании этой задачи?
[01:04:29.040 --> 01:04:31.040]  Коэффициента.
[01:04:31.040 --> 01:04:35.040]  Коэффициента, правая часть.
[01:04:35.040 --> 01:04:37.040]  Обращаю внимание на правую часть.
[01:04:37.040 --> 01:04:47.040]  Помните, когда мы говорили о решении нелинейной краевой задачи, у нас было некое условие.
[01:04:47.040 --> 01:04:57.040]  Берем гипотон на шаг по времени, которое связано было с правой частью, точнее с ее производной.
[01:04:57.040 --> 01:05:00.040]  Вот-вот-вот, прекрасно.
[01:05:00.040 --> 01:05:07.040]  Это, друзья, есть вещи, которые называются в педагогике рекерные точки.
[01:05:07.040 --> 01:05:09.040]  Это рекерная точка.
[01:05:10.040 --> 01:05:17.040]  Вот такую норму много меньше денег.
[01:05:17.040 --> 01:05:26.040]  То есть у нас, на самом деле, при наличии нелинейности опять появляется это условие.
[01:05:26.040 --> 01:05:32.040]  Ну, на самом деле, если функция правой части меняется очень медленно, то ничего страшного.
[01:05:32.040 --> 01:05:35.040]  Тау будет достаточно большим, и мы можем решать задачу.
[01:05:35.040 --> 01:05:43.040]  Но часто это может быть и функция быстрорастущая, например, для решения задач детонации, физики плазмы.
[01:05:43.040 --> 01:05:49.040]  Это, как правило, экспоненты, либо степенные функции, либо экспоненты, либо степенные функции.
[01:05:49.040 --> 01:05:53.040]  И там уже вот это условие, придется с ним считаться.
[01:05:53.040 --> 01:06:02.040]  Поэтому нелинейность нижнего слоя можно делать, но имея в виду, что мы получим ограничение на шаг по времени.
[01:06:02.040 --> 01:06:07.040]  А что если у нас функция в правой части растет быстро?
[01:06:07.040 --> 01:06:13.040]  Экспоненты какая-нибудь, степенная функция, плазмы, например, степенная функция, детонация экспонента и так далее.
[01:06:13.040 --> 01:06:16.040]  Что нам делать?
[01:06:16.040 --> 01:06:20.040]  Сделать неявную схему, то есть здесь поставить n плюс 1.
[01:06:20.040 --> 01:06:26.040]  А если мы поставим n плюс 1, то что мы получим за задачу?
[01:06:26.040 --> 01:06:30.040]  Что эта задача на n плюс 1 слое будет у нас?
[01:06:30.040 --> 01:06:36.040]  N-ный слой задан, а на n плюс 1 слой у нас вот такие три неизвестные.
[01:06:36.040 --> 01:06:40.040]  Прогонка пройдет или не пройдет?
[01:06:43.040 --> 01:06:48.040]  Вопрос на два балла. Друзья, пройдет здесь прогонка или не пройдет?
[01:06:48.040 --> 01:06:52.040]  Ответ правильный, вроде не должна. Почему вроде? Можно уточнить?
[01:06:52.040 --> 01:06:57.040]  Ну конечно, у нас вот нелинейный член, какая же это прогонка?
[01:06:57.040 --> 01:07:02.040]  Прогонка работает только для линейных задач, либо для задач с переменными коэффициентами.
[01:07:02.040 --> 01:07:07.040]  Для линейных она в принципе не может пройти. То есть нам что-то нужно из хитриса сделать,
[01:07:07.040 --> 01:07:11.040]  чтобы все-таки редуцировать задачу к алгоритму прогонки.
[01:07:11.040 --> 01:07:16.040]  Слушайте, вот вы радуете меня уже. Значит, чему-то все-таки научились.
[01:07:16.040 --> 01:07:26.040]  Конечно, линейно-резовать. Линейно-резация, это процесс великолепный, правда, физики его порой используют не всегда справедливо.
[01:07:26.040 --> 01:07:34.040]  Для быстрого решения задач линейизуют задачи, которые в принципе нельзя линейизовать.
[01:07:34.040 --> 01:07:40.040]  Но на самом деле, если числые методы применять, то линейно-резовать все можно.
[01:07:40.040 --> 01:07:45.040]  И что при этом будет использоваться? Метод итерации.
[01:07:45.040 --> 01:07:51.040]  Какой метод, кстати говоря, наиболее быстрый итерационный метод?
[01:07:51.040 --> 01:07:56.040]  Ньютона, правильно. Ну, друзья, вы меня сегодня радуете. Я просто, так сказать, в накрылих или чем-то.
[01:07:56.040 --> 01:08:02.040]  Подсказываете мне, так сказать, постоянно. Это меня радует. Значит, чему-то вы обучились.
[01:08:02.040 --> 01:08:07.040]  Метод Ньютона, правильно. То есть мы берем и мы должны построить итерационный процесс.
[01:08:07.040 --> 01:08:13.040]  Что это означает? Это означает, что вместо индексов n я вставлю итерационный индекс.
[01:08:13.040 --> 01:08:18.040]  И плюс один, и. Ну, здесь давайте я n вставлю.
[01:08:18.040 --> 01:08:28.040]  И, и, и, и. И здесь тоже и.
[01:08:28.040 --> 01:08:41.040]  Так, итерационный процесс. Ну, разумеется, если я так сделал, то я должен сказать, что у меня у ноль я должен задать начальные данные.
[01:08:41.040 --> 01:08:49.040]  Но у нас здесь с начальными данными, к счастью, все просто. Что у нас является начальными данными для данного итерационного процесса?
[01:08:49.040 --> 01:08:57.040]  Точнее начальным приближением. Решение на n-м слое. У, н, н.
[01:08:57.040 --> 01:09:05.040]  То есть начальные приближения нам всегда заданы. Это облегчает решение.
[01:09:05.040 --> 01:09:15.040]  Более того, если функции не очень сильно растущие, то мы прекрасно понимаем, что решения на n-м слое и на n-м слое отличаются не сильно.
[01:09:15.040 --> 01:09:19.040]  А это означает что? Что итерации надо делать, как правило, много не нужно.
[01:09:19.040 --> 01:09:24.040]  Часто там удается обладиться двумя-тремя итерациями.
[01:09:24.040 --> 01:09:28.040]  Это хорошо, так. Ну, это хорошо. Ну, что плохо, опять же?
[01:09:28.040 --> 01:09:33.040]  Плохо то, что я ничего не изменил. У меня, опять же, прогонка не проходит.
[01:09:33.040 --> 01:09:36.040]  Но вот здесь, так сказать, ваша идея. Линьеризация.
[01:09:36.040 --> 01:09:42.040]  Это означает, что вот эту функцию нам нужно линьеризовать. То есть сделать линейной.
[01:09:42.040 --> 01:09:46.040]  Давайте так и сделаем. Линьеризуем эту функцию в правой части.
[01:09:46.040 --> 01:09:52.040]  И построим процесс, который называется процесс Ньютона в функциональных пространствах.
[01:09:52.040 --> 01:09:57.040]  Либо процесс в базе линьеризации.
[01:09:57.040 --> 01:10:02.040]  В чем мы отличаемся от процесса Ньютона для нахождения решений нелинейного уравнения?
[01:10:02.040 --> 01:10:07.040]  Там мы ищем одну точку. Нелинейное уравнение.
[01:10:07.040 --> 01:10:11.040]  А здесь мы ищем N точку. То есть мы ищем всю функцию.
[01:10:11.040 --> 01:10:14.040]  Причем и по координатам, и по времени.
[01:10:14.040 --> 01:10:20.040]  А если у нас три координата, то это, сами понимаете, мы ищем функцию, в которых не одно пространство.
[01:10:20.040 --> 01:10:29.040]  Поэтому такой математический аппарат этих методов – это функциональная анализ.
[01:10:29.040 --> 01:10:32.040]  То есть мы работаем в функциональных пространствах.
[01:10:32.040 --> 01:10:46.040]  Итак, f от ui плюс 1 мы представим как f от ui t плюс ui плюс 1 минус ui t.
[01:10:46.040 --> 01:10:49.040]  А это давайте линейеризуем.
[01:10:49.040 --> 01:10:57.040]  Это будет f от ui t плюс f' по u.
[01:10:57.040 --> 01:11:04.040]  А здесь уi плюс 1 минус ui.
[01:11:04.040 --> 01:11:10.040]  Для корректности давайте везде поставим еще индекс m.
[01:11:10.040 --> 01:11:13.040]  Вот, пожалуйста, ваше предложение. Очень хорошее.
[01:11:13.040 --> 01:11:17.040]  Нашу функцию я представил в виде функции линейеризованной.
[01:11:17.040 --> 01:11:20.040]  Какой бы она ни была.
[01:11:20.040 --> 01:11:26.040]  А теперь мысленно представьте себе весь полный итерационный процесс, который мы с вами построили.
[01:11:26.040 --> 01:11:30.040]  То есть процесс Ньютона, нашего великого Ньютона.
[01:11:30.040 --> 01:11:32.040]  Который и здесь руку приложил.
[01:11:32.040 --> 01:11:34.040]  Ну, правда, здесь, может быть, он не прилагал.
[01:11:34.040 --> 01:11:37.040]  Он для линейного ровнения прилагал руку.
[01:11:37.040 --> 01:11:38.040]  Но это тоже линейеризация.
[01:11:38.040 --> 01:11:41.040]  А линейеризация – это вот процесс Ньютона.
[01:11:41.040 --> 01:11:44.040]  Так что это тоже метод Ньютона.
[01:11:44.040 --> 01:11:45.040]  Ну, он так и называется.
[01:11:45.040 --> 01:11:48.040]  Метод Ньютона в функциональных пространствах.
[01:11:48.040 --> 01:11:50.040]  Либо метод квазилинейеризации.
[01:11:50.040 --> 01:11:55.040]  То есть мы вместо вот этой функции сейчас берем и пишем f.
[01:11:55.040 --> 01:12:10.040]  f от u и m плюс f' по u и m на u и плюс 1 m минус u и m.
[01:12:10.040 --> 01:12:13.040]  Это я стираю.
[01:12:13.040 --> 01:12:15.040]  Это я стираю.
[01:12:15.040 --> 01:12:18.040]  Вот он наш итерационный процесс, друзья.
[01:12:18.040 --> 01:12:20.040]  Так, только что-то здесь не хватает.
[01:12:20.040 --> 01:12:22.040]  А, нет, нет, у нас здесь все нормально.
[01:12:22.040 --> 01:12:26.040]  Равно здесь и правая часть линейеризованная.
[01:12:26.040 --> 01:12:27.040]  Вот наш итерационный процесс.
[01:12:27.040 --> 01:12:31.040]  К нему, естественно, надо добавить начальное приближение.
[01:12:31.040 --> 01:12:32.040]  То есть функции начального приближения.
[01:12:32.040 --> 01:12:35.040]  Ну, как я сказал, функции начального приближения –
[01:12:35.040 --> 01:12:38.040]  у нас это есть решение на Н-м слое.
[01:12:38.040 --> 01:12:40.040]  Вопрос, которого мне задавали.
[01:12:40.040 --> 01:12:44.040]  Откуда брать решение на Н-м слое?
[01:12:44.040 --> 01:12:46.040]  На Н-м слое решение нам известно.
[01:12:46.040 --> 01:12:53.040]  С нолью н идем по слоям и находим решение.
[01:12:53.040 --> 01:12:56.040]  Но здесь уже у нас итерационный процесс получается.
[01:12:56.040 --> 01:13:02.040]  Итерационный процесс на каждом н-м слое мы заканчиваем при выполнении условий.
[01:13:02.040 --> 01:13:10.040]  Норма ui плюс 1 минус ui меньше некой заданной точности епсилон.
[01:13:10.040 --> 01:13:13.040]  Ну, как обычно, во всех итерационных процессах задается точность.
[01:13:13.040 --> 01:13:20.040]  Ну, а норма разности, например, это может быть максимум модуля между двумя решениями.
[01:13:20.040 --> 01:13:24.040]  Ну, если обномерная задача, то это, как правило, так и есть.
[01:13:24.040 --> 01:13:26.040]  Евклидову норму можно взять.
[01:13:26.040 --> 01:13:31.040]  Либо максимум по координатной оси.
[01:13:31.040 --> 01:13:36.040]  Подумайте над вопросами.
[01:13:36.040 --> 01:13:45.040]  Самый лучший метод понять и задать самые острые вопросы,
[01:13:45.040 --> 01:13:49.040]  это взять и попробовать саморос писать алгоритм для программы.
[01:13:49.040 --> 01:13:54.040]  А еще лучше программу написать для решения уравнения.
[01:13:54.040 --> 01:13:57.040]  Тогда все вопросы тут же снимаются.
[01:13:57.040 --> 01:14:03.040]  Ну, подумайте сейчас, сколько у нас времени осталось на вопросы.
[01:14:03.040 --> 01:14:08.040]  Так, ну, у нас еще немного времени есть.
[01:14:16.040 --> 01:14:18.040]  Почему? А, сейчас, секундочку.
[01:14:18.040 --> 01:14:26.040]  То есть, когда вот здесь вместо линии резону функции, я писал функции просто, да?
[01:14:26.040 --> 01:14:31.040]  Да, то есть, чуть-чуть раньше у меня было вот такое написано.
[01:14:31.040 --> 01:14:34.040]  Ф и плюс один М.
[01:14:34.040 --> 01:14:36.040]  Да, почему вот это нехорошо?
[01:14:36.040 --> 01:14:43.040]  Так, ладно, кто ответит на этот вопрос?
[01:14:48.040 --> 01:14:50.040]  Ну, прогонка не проходит в этом случае.
[01:14:50.040 --> 01:14:59.040]  То есть, прогонка у нас проходит, когда у нас есть три неизвестных матрица
[01:14:59.040 --> 01:15:02.040]  системы линейных уравнений трехдиагонально.
[01:15:02.040 --> 01:15:07.040]  Вот три диагонали не нулевые, остальные все элементы нулевые.
[01:15:07.040 --> 01:15:10.040]  Здесь у нас есть три элемента.
[01:15:10.040 --> 01:15:13.040]  У М минус один, М плюс, вот они.
[01:15:13.040 --> 01:15:15.040]  Три элемента есть.
[01:15:15.040 --> 01:15:21.040]  То есть, прогонка это чисто решение линейной системы уравнений, линейной.
[01:15:21.040 --> 01:15:26.040]  Пока эти три слагаемых неизвестных у нас есть, у нас система линейная.
[01:15:26.040 --> 01:15:31.040]  Вот здесь мы раз и наталкиваемся на нелинейные функции.
[01:15:31.040 --> 01:15:33.040]  Все, прогонка летит.
[01:15:33.040 --> 01:15:39.040]  Единственный способ ее решения, ну, на самом деле лучший способ это линейная.
[01:15:39.040 --> 01:15:44.040]  Но, в принципе, мы можем, конечно, вспомнить про метод простых итераций.
[01:15:44.040 --> 01:15:45.040]  Это не мета ньютна.
[01:15:45.040 --> 01:15:50.040]  Это означает, что вот здесь мы берем, ставим не И плюс один, а И.
[01:15:50.040 --> 01:15:53.040]  Тогда тоже прогонка проходит.
[01:15:53.040 --> 01:15:57.040]  Поскольку нам у ИТ известно, с нижнего слоя мы можем снять.
[01:15:57.040 --> 01:16:01.040]  Но это будет то же на то же.
[01:16:01.040 --> 01:16:08.040]  Опять же, у нас здесь встретится вот это условие.
[01:16:08.040 --> 01:16:11.040]  То есть, мы опять будем ограничены шагом по времени.
[01:16:11.040 --> 01:16:19.040]  Ну, и хотя мет простых итераций можно использовать, но он будет, естественно, медленный.
[01:16:19.040 --> 01:16:22.040]  Поэтому можно, конечно, использовать мет простых итераций,
[01:16:22.040 --> 01:16:27.040]  но мет ньютна, как вы знаете, как правило, быстрее работает.
[01:16:27.040 --> 01:16:28.040]  То есть, количество итераций меньше.
[01:16:28.040 --> 01:16:30.040]  Поэтому лучше линеризовать функции.
[01:16:30.040 --> 01:16:31.040]  Давайте.
[01:16:31.040 --> 01:16:34.040]  Какую функцию?
[01:16:34.040 --> 01:16:37.040]  А, начальную?
[01:16:37.040 --> 01:16:41.040]  А, при линеризации.
[01:16:41.040 --> 01:16:44.040]  Ну, смотрите, у нас здесь я пока...
[01:16:44.040 --> 01:16:46.040]  Это не всегда так хорошо, конечно, бывает.
[01:16:46.040 --> 01:16:49.040]  Я считаю, что у нас правая часть задана аналитически.
[01:16:49.040 --> 01:16:51.040]  Ну, например, экспонента E в степени х.
[01:16:51.040 --> 01:16:53.040]  Ну, и в степени U.
[01:16:53.040 --> 01:16:59.040]  Тогда вот F это экспонента в степени U будет, например.
[01:16:59.040 --> 01:17:02.040]  Или sin в степени U, например.
[01:17:02.040 --> 01:17:06.040]  И дальше вот по ряду Тейлора.
[01:17:06.040 --> 01:17:10.040]  Первый член ряда Тейлора.
[01:17:10.040 --> 01:17:13.040]  То есть, здесь функция вам задана, короче говоря.
[01:17:13.040 --> 01:17:17.040]  Та, которая вас интересует, функция задана.
[01:17:18.040 --> 01:17:21.040]  То есть, мы здесь добиваемся опять чего?
[01:17:21.040 --> 01:17:23.040]  Редуцирования к меддопрогонке.
[01:17:23.040 --> 01:17:24.040]  Почему к меддопрогонке?
[01:17:24.040 --> 01:17:25.040]  Мы его любим.
[01:17:25.040 --> 01:17:27.040]  А любим не просто так.
[01:17:27.040 --> 01:17:29.040]  Длиннее случаев он очень устойчив.
[01:17:29.040 --> 01:17:35.040]  Ну, мы условия устойчивости меддопрогонки с вами выводили.
[01:17:35.040 --> 01:17:42.040]  В случае переменных коэффициентов можно найти очень экзотический случай,
[01:17:42.040 --> 01:17:45.040]  когда прогонка вдруг, конечно, неустойчивая.
[01:17:45.040 --> 01:17:49.040]  Такой экзотический случай можно привести, например,
[01:17:49.040 --> 01:17:53.040]  если в правой части стоит очень сильно аксолирующая синусоида,
[01:17:53.040 --> 01:17:57.040]  которая пересекает ось Х в каждом узле сетки.
[01:17:57.040 --> 01:18:00.040]  Вот такая функция.
[01:18:00.040 --> 01:18:03.040]  Действительно, прогонка для такой функции может оказаться неустойчивой.
[01:18:03.040 --> 01:18:06.040]  Но эта функция, сами понимаете, уже очень экзотическая.
[01:18:06.040 --> 01:18:12.040]  А так очень даже для быстрорастущих функций, это быстрорассолирующие все нормально.
[01:18:12.040 --> 01:18:16.040]  Если либо линейный, либо переменный коэффициент.
[01:18:16.040 --> 01:18:19.040]  Для нелинейных задач прогонка не проходит.
[01:18:19.040 --> 01:18:24.040]  Их нужно линияризовывать, чтобы прошла прогонка.
[01:18:24.040 --> 01:18:26.040]  Ну, еще давайте подумайте.
[01:18:26.040 --> 01:18:28.040]  Это я вам рассказываю, как говорится.
[01:18:28.040 --> 01:18:31.040]  С одной стороны, можно назвать это теорией,
[01:18:31.040 --> 01:18:35.040]  но это теория такая, по которой программу можно писать.
[01:18:35.040 --> 01:18:38.040]  Здесь писать программу.
[01:18:38.040 --> 01:18:43.040]  Может быть, у вас первый такой предмет над этим функцией появился,
[01:18:43.040 --> 01:18:47.040]  который одновременно и теоретический, и математики много,
[01:18:47.040 --> 01:18:50.040]  и все это математика можно тут же в программу.
[01:18:50.040 --> 01:18:53.040]  То есть он одновременно и прикладной получается.
[01:18:53.040 --> 01:19:00.040]  Причем методы, я рассказываю, рабочие, которым можно решать реальные задачи.
[01:19:00.040 --> 01:19:02.040]  Ну, посмотрите, что еще.
[01:19:02.040 --> 01:19:09.040]  Здесь мы, получается, на каждом слое будем считать ньютона.
[01:19:09.040 --> 01:19:12.040]  Да.
[01:19:12.040 --> 01:19:18.040]  То есть мы на каждом n раз решаем систему по ньютону.
[01:19:18.040 --> 01:19:23.040]  Сколько у нас слоев по времени, столько мы и решаем.
[01:19:23.040 --> 01:19:29.040]  Но не хочу вас пугать, для одномерной задачи и персонального вашего компьютера,
[01:19:29.040 --> 01:19:30.040]  для вашего ноута.
[01:19:30.040 --> 01:19:33.040]  Эта задача очень посильная.
[01:19:33.040 --> 01:19:39.040]  Когда вы переберетесь на многомерные задачи, там это будет намного сложнее.
[01:19:39.040 --> 01:19:47.040]  То есть там время решения, память намного, все возрастает.
[01:19:47.040 --> 01:19:50.040]  Одномерная задача решается на ваших персональных компьютерах.
[01:19:50.040 --> 01:19:53.040]  Так что ничего страшного в этом плане нет.
[01:19:53.040 --> 01:19:58.040]  Количество итераций по ньютону, мы смотрим, у нас был криптон.
[01:19:58.040 --> 01:20:01.040]  Это было выражение, которое описывает.
[01:20:01.040 --> 01:20:03.040]  Точно, что-то я помню.
[01:20:03.040 --> 01:20:05.040]  Вы, получается, его примерно делаете?
[01:20:05.040 --> 01:20:08.040]  Вы метнютное имеете для нелинейного уравнения?
[01:20:08.040 --> 01:20:10.040]  Да.
[01:20:10.040 --> 01:20:16.040]  Да, там действительно было выражение, можно его выписать.
[01:20:16.040 --> 01:20:18.040]  Мы с вами много раз выписывали.
[01:20:18.040 --> 01:20:19.040]  Но оно откуда идет?
[01:20:19.040 --> 01:20:22.040]  Оно идет из того, что мы брали функцию,
[01:20:22.040 --> 01:20:29.040]  ну там f от u, и ее линеризовали.
[01:20:29.040 --> 01:20:32.040]  И оттуда брался ньютон.
[01:20:32.040 --> 01:20:36.040]  Просто из самой простой линеризации функции нелинейной.
[01:20:36.040 --> 01:20:38.040]  Здесь, на самом деле, все то же самое.
[01:20:38.040 --> 01:20:41.040]  Только явной такой формы здесь не получается.
[01:20:41.040 --> 01:20:43.040]  Ее нереально явную форму написать,
[01:20:43.040 --> 01:20:47.040]  поскольку здесь получается система линейных алгебрических уравнений.
[01:20:47.040 --> 01:20:51.040]  И от этой системы вы как не хотите уйти, не уйдете.
[01:20:51.040 --> 01:20:53.040]  Нужно решать вот такую.
[01:20:53.040 --> 01:20:59.040]  На каждом слое нужно будет решать систему нелинейных уравнений.
[01:20:59.040 --> 01:21:03.040]  То есть на каждом слое нужно будет несколько итераций делать там.
[01:21:03.040 --> 01:21:06.040]  Обычно это 2-3, максимум 4 итерации.
[01:21:13.040 --> 01:21:16.040]  Обычно выбираются вот так, как я написал.
[01:21:16.040 --> 01:21:18.040]  То есть вы задаете точность.
[01:21:18.040 --> 01:21:23.040]  Ну, например, 10-6.
[01:21:23.040 --> 01:21:27.040]  Ну, например, 10-6.
[01:21:27.040 --> 01:21:32.040]  И смотрите на норму разности.
[01:21:38.040 --> 01:21:40.040]  Вот это точность?
[01:21:40.040 --> 01:21:44.040]  Нет, не обязательно.
[01:21:44.040 --> 01:21:49.040]  Порядок аппроксимации мы все-таки напомним.
[01:21:49.040 --> 01:21:53.040]  Это есть c tau в степени p.
[01:21:53.040 --> 01:21:57.040]  Это разность между точным решением и численным решением.
[01:21:57.040 --> 01:21:59.040]  c на tau в степени p.
[01:21:59.040 --> 01:22:06.040]  Если мы уменьшаем tau к нулю, то мы получаем точное решение.
[01:22:06.040 --> 01:22:10.040]  Здесь мы вообще-то итерационный процесс используем.
[01:22:10.040 --> 01:22:12.040]  Это немного другое.
[01:22:12.040 --> 01:22:15.040]  Я точность схемы уже задал.
[01:22:15.040 --> 01:22:18.040]  То есть данная схема, вы помните, какая точность?
[01:22:18.040 --> 01:22:22.040]  Первый порядок по времени и второй по координате.
[01:22:22.040 --> 01:22:28.040]  Ну, мы можем уменьшать шаг и получать достаточно точное решение.
[01:22:28.040 --> 01:22:30.040]  А вот количество итераций...
[01:22:30.040 --> 01:22:36.040]  Либо вы задаете его каким-то стабильным, скажем, 5 итераций задали все.
[01:22:36.040 --> 01:22:41.040]  Но обычно все-таки количество итераций обусловлено точностью.
[01:22:41.040 --> 01:22:47.040]  Норма разности между решениями на ита итерации и и плюс первой.
[01:22:47.040 --> 01:22:51.040]  Это мы тоже делали, когда говорили о методном ньютном.
[01:22:51.040 --> 01:22:53.040]  А то есть они никак не связаны?
[01:22:53.040 --> 01:22:57.040]  Нет, они не связаны.
[01:22:57.040 --> 01:23:05.040]  То есть порядок метода и точность решений вообще говоря не связаны.
[01:23:05.040 --> 01:23:08.040]  Вообще говоря, не связаны.
[01:23:08.040 --> 01:23:13.040]  Другое дело, что вас может смущать, что вы можете задать такую точность,
[01:23:13.040 --> 01:23:18.040]  скажем, 10 минус 16, которые просто ваши итерации не достигнут.
[01:23:18.040 --> 01:23:20.040]  Ну, это верно.
[01:23:20.040 --> 01:23:25.040]  Надо задавать точность реальную, которую вы можете достигнуть.
[01:23:25.040 --> 01:23:31.040]  Поэтому я и говорю, что повышение порядка, апроксимация метода –
[01:23:31.040 --> 01:23:34.040]  это задача важная и нужная.
[01:23:34.040 --> 01:23:40.040]  Чем более высокий порядок метода, тем более грубую сетку мы можем использовать.
[01:23:40.040 --> 01:23:43.040]  А для задач многомерных это момент важно.
[01:23:43.040 --> 01:23:46.040]  Для одномерных не очень важно, скажем так.
[01:23:46.040 --> 01:23:49.040]  Вы можете очень мелкую сетку задать для первого порядка,
[01:23:49.040 --> 01:23:55.040]  а для многомерных задач, когда у вас там 4 переменных, с этим надо считаться.
[01:23:55.040 --> 01:23:58.040]  Мы об этом говорили с вами.
[01:24:04.040 --> 01:24:11.040]  Мы знаем, насколько наше решение будет примерно отличаться от действительного.
[01:24:11.040 --> 01:24:15.040]  Да, при заданных шагах.
[01:24:15.040 --> 01:24:20.040]  Но также наше решение мы ищем с помощью Newton.
[01:24:20.040 --> 01:24:23.040]  Это уже итерационное решение, понимаете, в чем дело.
[01:24:23.040 --> 01:24:25.040]  Смотрите, понимаете, в чем дело.
[01:24:25.040 --> 01:24:29.040]  Здесь вот в чем, что вас может смущать.
[01:24:29.040 --> 01:24:32.040]  Здесь вот эта схема выписана.
[01:24:32.040 --> 01:24:35.040]  На самом деле это есть нелинейное уравнение.
[01:24:35.040 --> 01:24:37.040]  Здесь заданы и tau h, все.
[01:24:37.040 --> 01:24:40.040]  Это нелинейное уравнение мы решаем.
[01:24:40.040 --> 01:24:42.040]  tau h мы менять не можем.
[01:24:42.040 --> 01:24:45.040]  И решаем его с той точностью, которая нам нужна.
[01:24:45.040 --> 01:24:49.040]  А точность задается только вот этим условием, больше ничего.
[01:24:49.040 --> 01:24:53.040]  Это просто уже рассматривайте как систему нелинейных уравнений,
[01:24:53.040 --> 01:24:57.040]  которую мы решаем по меду ньютона, линеризации.
[01:24:57.040 --> 01:25:00.040]  А tau h здесь уже задано, все.
[01:25:00.040 --> 01:25:03.040]  То есть вы его менять не можете tau h.
[01:25:03.040 --> 01:25:09.040]  Вы их задаете так, как позволяет ваш компьютер,
[01:25:09.040 --> 01:25:13.040]  и разумная ваша точность.
[01:25:13.040 --> 01:25:17.040]  Мы же не сможем задать настолько маленькое, чтобы переключить?
[01:25:17.040 --> 01:25:20.040]  Можно задать, да, вот столь малое эпсиум,
[01:25:20.040 --> 01:25:26.040]  что вы можете этой точности не достигнуть.
[01:25:26.040 --> 01:25:28.040]  Поэтому здесь точность тоже...
[01:25:28.040 --> 01:25:32.040]  Я говорю, если вы задаете там 10 в минус двадцатой степени,
[01:25:32.040 --> 01:25:36.040]  вы этой степени, скорее всего, точность не достигнете.
[01:25:36.040 --> 01:25:40.040]  Поэтому точность нужно задавать разумно.
[01:25:40.040 --> 01:25:42.040]  Давайте.
[01:25:49.040 --> 01:25:52.040]  Кстати, вопрос тонкий.
[01:25:52.040 --> 01:25:54.040]  Очень хороший вопрос.
[01:25:54.040 --> 01:25:56.040]  Что делать с коэффициентами?
[01:25:56.040 --> 01:25:59.040]  Они ведь тоже, вообще говоря, зависят от у.
[01:25:59.040 --> 01:26:02.040]  Я как-то этот вопрос промолчал.
[01:26:02.040 --> 01:26:05.040]  Но на самом деле вы совершенно правы.
[01:26:05.040 --> 01:26:07.040]  Есть два варианта.
[01:26:07.040 --> 01:26:11.040]  Первое, поставить здесь значки ита итерации.
[01:26:11.040 --> 01:26:13.040]  Это первое.
[01:26:13.040 --> 01:26:20.040]  Но можно ины поставить, итерации взять с нижнего слоя.
[01:26:20.040 --> 01:26:23.040]  Но наиболее корректно вы сказали совершенно верно.
[01:26:23.040 --> 01:26:29.040]  Наиболее корректно сделать тоже эти коэффициенты линеризованными.
[01:26:29.040 --> 01:26:35.040]  Но просто здесь практика численного решения таких задач
[01:26:35.040 --> 01:26:37.040]  говорит о том, что в первую очередь
[01:26:37.040 --> 01:26:42.040]  на скорость решения влияет линеризация правой части.
[01:26:42.040 --> 01:26:46.040]  Коэффициенты тоже влияют.
[01:26:46.040 --> 01:26:49.040]  Их действительно нужно делать либо итами,
[01:26:49.040 --> 01:26:54.040]  либо и плюс первыми брать.
[01:26:54.040 --> 01:26:56.040]  Вот тогда линеризовать.
[01:26:56.040 --> 01:27:01.040]  И плюс первыми, если вы возьмете, то вы так тоже в прогонке лежать.
[01:27:01.040 --> 01:27:04.040]  Но если вы линеризуете вот так же, как я это сделал,
[01:27:04.040 --> 01:27:08.040]  то, пожалуйста, вы можете делать прогонку.
[01:27:08.040 --> 01:27:12.040]  Но, вообще говоря, здесь чаще всего, если из практики брать,
[01:27:12.040 --> 01:27:14.040]  чаще всего делать так.
[01:27:14.040 --> 01:27:17.040]  То есть берут на сытые итерации.
[01:27:17.040 --> 01:27:22.040]  Просто практика показывает, что правая часть больше влияет на решение.
[01:27:35.040 --> 01:27:37.040]  Вот это хороший вопрос.
[01:27:37.040 --> 01:27:43.040]  Дело в том, что действительно это условие появляется для правой части.
[01:27:43.040 --> 01:27:54.040]  Для достаточно гладких функций вот этих коэффициентов a и nm такого условия нет.
[01:27:54.040 --> 01:27:59.040]  Правда, конечно, всегда можно придумать какой-нибудь очень крутой коэффициент.
[01:27:59.040 --> 01:28:02.040]  Ну там, я не знаю, e в степени u, в степени u и так далее.
[01:28:02.040 --> 01:28:05.040]  Когда ваш метод развалится.
[01:28:05.040 --> 01:28:09.040]  То есть всегда можно придумать какой-то экстремальный коэффициент.
[01:28:09.040 --> 01:28:13.040]  Но чаще всего это все-таки какая-то экзотика.
[01:28:13.040 --> 01:28:22.040]  Обычно коэффициенты себя не так портят в решении задачи, как правая часть.
[01:28:22.040 --> 01:28:23.040]  Ну то есть не портят.
[01:28:23.040 --> 01:28:25.040]  Портить – это нехорошее слово.
[01:28:25.040 --> 01:28:30.040]  Портить может исследователь, программист, который составил плохую задачу.
[01:28:30.040 --> 01:28:32.040]  А физика природа не портит.
[01:28:32.040 --> 01:28:34.040]  Природа она такая, какая есть.
[01:28:34.040 --> 01:28:38.040]  Мы ее можем изучать, решать задачи и так далее.
[01:28:38.040 --> 01:28:43.040]  Так что здесь вот с коэффициентами вопрос менее острый, чем с второй части.
[01:28:43.040 --> 01:28:47.040]  Я, собственно, по этой причине о них не сказал.
[01:28:47.040 --> 01:28:52.040]  То есть часто берут просто на слой n их.
[01:28:52.040 --> 01:28:55.040]  Но более правильно брать так.
[01:28:55.040 --> 01:29:00.040]  То есть в итерационный процесс их вгонять.
[01:29:00.040 --> 01:29:02.040]  Это правильно.
[01:29:02.040 --> 01:29:04.040]  Какие еще идеи есть?
[01:29:04.040 --> 01:29:09.040]  По ускорению итерационного процесса.
[01:29:09.040 --> 01:29:11.040]  Ну ладно.
[01:29:11.040 --> 01:29:12.040]  Так, слушайте.
[01:29:12.040 --> 01:29:13.040]  Ну вот, скажем, задавал вопрос.
[01:29:13.040 --> 01:29:15.040]  А почему мы линеризуем функцию?
[01:29:15.040 --> 01:29:21.040]  А если мы возьмем не первый член линейный, а второй член квадратичный,
[01:29:21.040 --> 01:29:25.040]  почему бы нам квадратичные функции не сделать?
[01:29:25.040 --> 01:29:28.040]  Еще лучше будет.
[01:29:28.040 --> 01:29:36.040]  Да, мы теряем линейность, конечно.
[01:29:36.040 --> 01:29:37.040]  Это первое.
[01:29:37.040 --> 01:29:44.040]  А во-вторых, если помните, метод ньютный имеет второй порядок скорости сходимости.
[01:29:44.040 --> 01:29:46.040]  И больше его не увеличивает, как правило.
[01:29:46.040 --> 01:29:49.040]  Редко бывает, берут выше.
[01:29:49.040 --> 01:29:55.040]  То есть его можно есть метод Чебышова, метод n порядка сходимости.
[01:29:55.040 --> 01:29:58.040]  То есть ни второго, ни третьего n порядка сходимости.
[01:29:58.040 --> 01:30:01.040]  Ну там проблема какая?
[01:30:01.040 --> 01:30:04.040]  Попробуйте вспомнить, какие там проблемы возникают.
[01:30:04.040 --> 01:30:07.040]  Почему все-таки дальше ньютна чаще всего не идут?
[01:30:07.040 --> 01:30:12.040]  Ну идут, но в реке случаев.
[01:30:12.040 --> 01:30:16.040]  Там начальные данные нужно брать с такой точностью,
[01:30:16.040 --> 01:30:22.040]  что мы можем чуть ли не решение должны найти.
[01:30:22.040 --> 01:30:25.040]  Очень близко приблизиться к решению точному.
[01:30:25.040 --> 01:30:31.040]  Поэтому даже в метод ньютна, если вы помните,
[01:30:31.040 --> 01:30:35.040]  есть ограничения на начальные приближения.
[01:30:35.040 --> 01:30:40.040]  На второй порядок от третьей там еще более жесткие приближения.
[01:30:40.040 --> 01:30:44.040]  Поэтому обычно ограничиваются линейнеризации.
[01:30:44.040 --> 01:30:50.040]  Другое, что я нередко видел, просто физики делают еще проще.
[01:30:50.040 --> 01:30:53.040]  Говорят, функции линейизуют и так с ней работают.
[01:30:53.040 --> 01:30:56.040]  Вот это не есть правильно.
[01:30:56.040 --> 01:31:00.040]  Мы можем получить в нелинейном процессе чисто линейную задачу.
[01:31:00.040 --> 01:31:05.040]  Нужно честно итерировать.
[01:31:05.040 --> 01:31:08.040]  То есть честно решать нелинейную задачу.
[01:31:08.040 --> 01:31:11.040]  Темы медными, которые у нас есть.
[01:31:11.040 --> 01:31:15.040]  Давайте еще есть вопросы?
[01:31:15.040 --> 01:31:19.040]  Все, все, да.
