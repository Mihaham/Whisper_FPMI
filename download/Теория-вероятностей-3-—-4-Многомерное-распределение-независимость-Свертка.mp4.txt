[00:00.000 --> 00:17.760]  У нас сегодня будет две лекции. Одна сейчас, вторая в 3.30, кажется. После этой лекции сделаю
[00:17.760 --> 00:22.520]  ссылку сразу на вторую лекцию, пришлю, чтобы она была заранее. Прошу прощения,
[00:22.520 --> 00:28.960]  что я протормозил с первой. И уже со следующего раза в аудитории, видимо,
[00:28.960 --> 00:37.680]  если ничего не произойдет экстравзионарного. На чем мы с вами в прошлый раз остановились? Мы
[00:37.680 --> 00:45.120]  говорили про многомерное распределение. Я только начали говорить. Что я сказал? Я сказал,
[00:45.120 --> 00:52.280]  что такое функция распределения и сказал, что если есть функция распределения, то по ней
[00:52.280 --> 00:58.960]  однозначным образом восстанавливается распределение целиком. Теперь давайте по
[00:58.960 --> 01:06.640]  аналогичному плану как-то было в одномерном случае поговорим про свойства функции многомерного
[01:06.640 --> 01:19.720]  распределения. Свойств тоже три. Они аналогичны, но в силу специфики многомерной они немного
[01:19.720 --> 01:24.600]  отличаются. Во-первых, было свойство неубывания. Как свойство неубывания будет выглядеть в многомерном
[01:24.600 --> 01:35.560]  случае? Но откуда бралось у нас неубывание? Мы говорили, что возьмем вычтемость функции
[01:35.560 --> 01:40.120]  распределения в точке B, функции распределения в точке A, и мы получим вероятность отрезка между
[01:40.120 --> 01:44.760]  аипами. Здесь мы делаем совершенно то же самое, только вместо отрезка мы говорим про параллель
[01:44.760 --> 01:50.200]  пипи. То есть нам нужно из функции распределения какими-то арифметическими операциями, из ее
[01:50.200 --> 01:59.080]  значений получить вероятность параллель пипи. Давайте с вершинами определимся. Пусть у нас есть
[01:59.080 --> 02:14.760]  а1 меньше, чем b1, меньше либо равно, и т.д., ак меньше 0, чем bkt. Следующая должна быть выполнена,
[02:14.760 --> 02:26.520]  я сейчас напишу и поясню. Дельта 1, 1b1, и т.д., дельт k, ak, bk от f, а у нас n, н-мерная функция.
[02:26.520 --> 02:41.000]  Давайте будет n-мерная функция. f от x1 до xn не отрицает. Что такое вот эти дельты? Вот это такие
[02:41.000 --> 02:48.360]  операторы, которые мы будем применять в нашей функции. Значит, дельты it, a it, b it от функции,
[02:48.360 --> 02:56.720]  давай напишем f маленькая, от x1 до xn. Это есть следующее. Мы берем просто it-ую позицию, вот у
[02:56.720 --> 03:03.600]  нас аргумент n-мерный, мы берем it-ую позицию, на эту позицию ставим b it и a it и оставляем разность.
[03:03.600 --> 03:08.640]  То есть это будет следующее. Все аргументы остаются без изменений, кроме it-ого.
[03:19.360 --> 03:29.560]  На место it-ого аргумента подставляется b it и a it, оставляясь разностью. Но, значит, если применить
[03:29.560 --> 03:36.360]  по очереди, начиная, скажем, с внутренней операции к внешней операции, применить по очереди вот эти
[03:36.360 --> 03:41.560]  вот дельты, то мы в результате получим, конечно, некоторую линейную комбинацию. Я здесь написал f
[03:41.560 --> 03:45.280]  маленькая, а не f большая, потому что каждый раз, когда мы будем применять, у нас функция будет
[03:45.280 --> 03:51.880]  меняться. Мы сначала к этому аргумент применим. У нас будет, в результате получится разность f от
[03:51.880 --> 04:00.240]  x1 и так далее bm, минус f от x1 и т.д. И мы уже вот к этой новой функции будем применять дельты
[04:00.240 --> 04:07.440]  n-1. Получится такая линейная комбинация, и это, значит, несложно видеть, это по индукции,
[04:07.440 --> 04:14.440]  можно доказать, что это есть не что иное, как как раз вероятность параллепипеда с вершинами вот
[04:14.440 --> 04:26.160]  в этих точках 1a и 1b. То есть 1a и 1b это левый нижний угол от параллепипеда, 1b это верхний
[04:26.160 --> 04:34.320]  правый угол, если можно так сказать. Есть какие-то вопросы по первому свойству? Второе свойство.
[04:34.320 --> 04:46.040]  Есть вопрос? Да. А вот вторая строчка это условие или что? Ну то есть где куча дельт? Смотрите,
[04:46.040 --> 04:54.200]  вот это определение дельты, да вот это определение операции дельты, а вот это само условие. Само
[04:54.200 --> 04:59.480]  условие звучит так, что для любых 1 меньше чем b1, tln меньше чем bn выполнено вот это нералист.
[04:59.480 --> 05:09.600]  А да, понятно. Смотри, где дельта определяется вот таким вот образом. Хорошо, значит, что у нас там
[05:09.600 --> 05:15.320]  еще было? У нас там была еще непрерывная справа, да, вот, но здесь тоже будет непрерывная справа,
[05:15.320 --> 05:20.480]  только что мы будем подразумевать под непрерывная справа, мы будем иметь в виду, что любой
[05:20.480 --> 05:26.120]  последовательности, которая стремится, зафиксируем какую-то точку, мы рассматриваем любую последовательность,
[05:26.120 --> 05:30.800]  которая стремится справа в том смысле, что все ее координаты должны убывать. Да, то есть давайте
[05:30.800 --> 05:39.240]  вот так вот напишем, что если у нас есть дваимерных векторов, будем писать, вот у нас есть вектор y,
[05:39.240 --> 05:48.120]  скажем, y1, ym. Будем писать, что он больше либо равен, чем вектор x, составленный из координат x1, xn.
[05:48.120 --> 05:56.280]  Если есть координатное неравенство, да, если для всех и, yt больше ночи, чем xt.
[06:06.280 --> 06:13.000]  Теперь рассмотрим просто любую точку x и последовательности x, которые к этой
[06:13.000 --> 06:16.840]  точке сходятся вот именно так, что каждый следующий меньше либо ранее, чем предыдущий.
[06:16.840 --> 06:23.600]  Давайте будем писать следующим образом. У нас есть последовательность xкт векторов,
[06:23.600 --> 06:39.840]  которая стремится справа, в каком-то смысле, к x. Если для любого k, xk
[06:39.840 --> 06:48.320]  x1 меньше либо равно, чем xкт, ну и x это предел, x равняется предел при касты
[06:48.320 --> 06:54.040]  мячностей бесконечности xкт. Вот, значит, рассмотрим последовательность, которую так сходится, и для этой
[06:54.040 --> 07:02.240]  последовательности должна быть непрерывность. Значит, предел любой последовательности xкт,
[07:02.240 --> 07:10.320]  который стремится к x справа, предел при касты мячностей бесконечности f от xкт равно f от x.
[07:10.320 --> 07:24.160]  Есть вопросы? Нет, прекрасно. Третий. Значит, третий, это предел в минус бесконечности и плюс
[07:24.160 --> 07:31.680]  бесконечности, тоже будет отличие. Отличие будет вот какое. Смотрите, откуда бралось свойство,
[07:31.680 --> 07:37.280]  что предел в плюс бесконечности равен единице, но оттуда что из непрерывности вероятности меры.
[07:37.280 --> 07:49.320]  Да, то есть при устремлении xкт плюс бесконечности, куда стремится функция
[07:49.320 --> 07:55.160]  распределения в точке x, ну она равна просто, устремляется к вероятности объединения всех
[07:55.160 --> 07:59.440]  тех норгов, так как эти множества, выдающиеся в лучи, они вложены, и все их объединение дает все r,
[07:59.440 --> 08:04.080]  то в пределе мы получаем единицы. Тоже самое должно произойти в многомерном случае, мы тоже должны
[08:04.080 --> 08:09.080]  в пределе получить все rm. Но чтобы это сделать, нужно чтобы каждый аргумент, конечно, стремился к
[08:09.080 --> 08:14.960]  плюс бесконечности. То есть стремление к плюс бесконечности должно быть одновременно по всем
[08:14.960 --> 08:29.120]  аргументам. Вот, а с минус бесконечности будет по-другому. Значит, что там должно происходить? Мы
[08:29.760 --> 08:35.880]  должны посмотреть на предел пересечения ложных множеств, и пересечение вот всей этой счетной
[08:35.880 --> 08:40.800]  последовательности ложных множеств должно быть пустым. Да, это был случай r. И, конечно, это будет,
[08:40.800 --> 08:46.040]  если просто хотя бы один из аргументов стремится к минус бесконечности, то пересечение всех этих
[08:46.040 --> 08:53.120]  ложных множеств будет пустым. Поэтому вторая часть этого свойства выглядит так. Любого i предел
[08:53.120 --> 09:04.040]  при x и том, стремящемся к минус бесконечности f от x1, тогда xm равно 0. Так, есть ли вопросы?
[09:04.040 --> 09:12.720]  Мы доказывать будем эти свойства? Да, сейчас докажем. Давайте докажем.
[09:12.720 --> 09:37.800]  Ну, давайте первое свойство докажем, наверное, по индукции, по индукции пока. Первое свойство.
[09:42.840 --> 09:43.920]  Докажем, что...
[09:57.200 --> 10:06.800]  Сейчас. Ну, давайте так, с дельта Каттву начнем. И на дельта Энтом закончим.
[10:12.720 --> 10:22.760]  Ну, то есть самый первый Ка, который надо рассмотреть, это Ка равно n. При Ка равно n мы имеем
[10:22.760 --> 10:36.600]  просто дельта N aN bN от f от x1 до xn. И по определению это есть просто f от x1 и так далее bN минус f от x1
[10:37.200 --> 10:48.160]  Ну, значит, что мы делаем? Мы из функции распределения вот в этой точке, то есть из вероятности декартового
[10:48.160 --> 10:54.240]  произведения вот таких вот лучей от минус бесконечности dx1, от минус бесконечности dx2, от минус бесконечности
[10:54.240 --> 10:59.520]  bN, мы учитаем вероятность декартового произведения вот лучей, соответствующих вот этим агументам.
[10:59.520 --> 11:05.640]  И понятно, что внутри этих двух декартовых произведений все лучи будут одинаковы, кроме
[11:05.640 --> 11:11.660]  последнего. В первом случае будет луч от минус бесконечности dbN, а во-втором случае будет луч
[11:11.660 --> 11:16.720]  от минус бесконечности daN. Поэтому когда вы вы honorary, в силу аддитивности меры, ну,
[11:17.780 --> 11:22.020]  короче, вот этот множество, вот этот декартовый произведение в этом влож았�. Поэтому когда мы вычитаем
[11:22.020 --> 11:26.840]  вероятность, вы получите просто вероятность разности двух этих множеств, ребята, это
[11:26.840 --> 11:32.040]  будет ничто иное как вероятность декартового произведения всех лучей до n-о 1-го.
[11:32.040 --> 11:53.560]  и последний луч от аэнтэ до бэнтэ да теперь значит ну предположим что для ка мы доказали
[11:53.560 --> 12:07.120]  для какого-то ка и попытаемся доказать для ка плюс один то есть для ка минус один
[12:07.120 --> 12:11.000]  мы в обратную сторону идем то есть мы рассматриваем дельта ка минус один а
[12:11.000 --> 12:26.280]  сейчас давайте знаете даже я по-другому немного пишу давайте докажем мы не это здесь а докажем
[12:26.280 --> 12:32.200]  на самом деле вот что докажем что это в точности вероятность декартового произведения лучей
[12:32.200 --> 12:42.480]  вплоть до ка минус первого то есть прямо явно напишем чему равно это множество чему
[12:42.480 --> 12:49.920]  равно вероятности чему равно это линейная комбинация функций распределения значение
[12:49.920 --> 12:57.360]  функции распределения значит это будет первый каменус одна координата дадут просто лучи а
[12:57.360 --> 13:11.000]  остальные дадут полу интервалы от а до б вот и на самом деле мы действительно для ка равно
[13:11.000 --> 13:16.240]  мы уже доказали да мы получили в точности вот такую вот вероятность теперь докажем
[13:16.240 --> 13:23.320]  переход индукции значит для ка доказано это да мы рассматриваем вот такую вот штуку
[13:31.320 --> 13:39.960]  и значит здесь у нас следующая дельта имеет индекс ка и поэтому начиная со следующей дельты
[13:39.960 --> 13:45.480]  мы уже умеем поменять их кф мы по индукции знаем что мы должны получить да значит тогда
[13:45.480 --> 13:54.120]  в силу определения дельта это будет дельта каменус 1 каменус 1 б ка минус 1 примененная к
[13:54.120 --> 14:00.520]  вот всему что осталось что по индукции по предположения индукции равно просто вероятности
[14:00.520 --> 14:10.520]  от милых бесконечности дэкс один и так далее от милых бесконечности дэкс каменус один а ка
[14:10.520 --> 14:23.120]  т б ка т так далее а н т б м т вот ну и теперь по определению дельты мы просто применяем
[14:23.120 --> 14:31.920]  к этой функции вот у нас есть аргумент да и к каменус каменус 1 когда мы применяем мы получаем
[14:31.920 --> 14:48.560]  следующее мы получаем f извиняюсь вероятность от того же самого да только на место и к каменус
[14:48.560 --> 14:52.240]  1 мы подставляем соответственно сначала б ка минус 1
[15:00.400 --> 15:08.720]  а потом подставляем а ка минус 1 и видим что эти два декарта предведения отличается только
[15:08.720 --> 15:17.320]  в одной координате и соответственно второе множество просто вложено в первое поэтому
[15:17.320 --> 15:23.960]  разность их вероятности это точности вероятность разности этих множеств то есть в точности то что
[15:23.960 --> 15:34.840]  нам нужно было получить данный каменус первом месте стоит интервал от а ка минус 1 дабы ка минус
[15:34.840 --> 15:47.200]  1 и на всех остальных тоже стоят такие интервалы вот ну все значит по индукции мы действительно
[15:47.200 --> 15:55.800]  доказали что наша вещь при применении этих дельт откатый до янтый дают такую вероятность а значит
[15:55.800 --> 16:06.200]  в частности пика равно единица что мы получаем да то есть пика ровно единица это именно тот
[16:06.200 --> 16:09.080]  номер дельт который нам нужен то есть все дельты от первой до энтой
[16:09.080 --> 16:22.640]  значит получается просто вероятность некоторого множества дай декарта у произведения лучей
[16:22.840 --> 16:33.160]  этих интервалов от 1 до б1 так далее м тв м т и она не отрицательно что тревоз если вопросы
[16:33.160 --> 16:44.880]  можете по-быстрому прокрутить на самый верх на самый верх это вот сюда да все спасибо
[16:44.880 --> 17:00.000]  так хорошо теперь второе свойство ну здесь уже доказательств не ничем не отличается вот
[17:00.000 --> 17:06.800]  доказательства свойств для одномерной вероятности давайте быстренько вспомним как мы это делали
[17:06.800 --> 17:16.400]  значит итак у нас есть последователь скаты который стремится с права к и мы
[17:16.400 --> 17:20.320]  смотрим на предел приказ стремящимися бесконечности афотекс карты
[17:20.320 --> 17:30.080]  по определению функции распределения это есть просто вероятность декарта у произведения лучей
[17:30.080 --> 17:45.680]  от минус бесконечности до x к 1 и так далее от минус бесконечности до x к n эти в силу того
[17:45.680 --> 17:50.080]  как ведет себя последователь скаты до у нас последовательность мит с права в том смысле
[17:50.080 --> 17:54.440]  что каждый следующий член последовательсти не превосходит предыдущий это означает что вот эти
[17:54.440 --> 17:59.040]  все множества не просто вложены друг в друга каждое следующее содержится предыдущим и значит
[17:59.040 --> 18:04.080]  по теореме непрерывности вероятности меры можем перейти к пределу под вероятностью да то есть
[18:04.080 --> 18:09.360]  это будет вероятность просто пересечение когда множество так ложно что каждое следующее содержится
[18:09.360 --> 18:22.320]  предыдущим и говорим про пересечение пересечение по всем к наших лучей ну и в силу сходимости
[18:22.320 --> 18:27.720]  до сходимость вектов а здесь ничто виноват как сходимость как компонент этого вектора мы
[18:27.720 --> 18:37.520]  получаем в пределе то есть вероятность всех этих множеств это в точности лучи соответствующей
[18:37.520 --> 18:44.960]  иксу да то есть это вероятность декарта у произведения лучей от минус бесконечности до x к 1 и
[18:45.560 --> 18:51.600]  так далее без конечности до x м что есть функции распоряжения в точке икс
[18:51.600 --> 18:56.480]  точно также в третьем пункте
[18:56.480 --> 19:01.920]  если все аргументы стремятся к плюс бесконечности
[19:01.920 --> 19:22.240]  то но опять значит мы пользуемся определением функции распределения да это значит вероятность
[19:22.240 --> 19:30.560]  такого декарта произведения лучей вот и теперь эти лучи увеличиваются они растут и
[19:30.880 --> 19:37.040]  значит опять же можно считать да здесь стоит сказать о том что можно считать что
[19:37.040 --> 19:48.080]  это сходимость что все иксы возрастают то есть можно писать вот так и это будет без ограничения
[19:48.080 --> 19:57.160]  общности в силу того что есть не обувание функции распределения да то есть вот такой вот
[19:57.160 --> 20:01.800]  предельный переход когда вы здесь рассматриваете возрастающую последовательность или когда
[20:01.800 --> 20:10.640]  вы берете произвольную последовательность они равносильны поэтому когда поэтому
[20:10.640 --> 20:16.960]  вы можете воспользоваться теоремой непрерывности вероятности меры да и перейти к пределу множеств
[20:16.960 --> 20:21.720]  то есть так как они все будут ложен друг другу каждое следующее содержится предыдущие вы в итоге
[20:21.720 --> 20:33.680]  получите вероятность объединения этих множеств что есть рм опять же при стремлении хотя бы одной
[20:33.680 --> 20:38.280]  координате к минус бесконечности по аналогичным причинам вы можете вы можете считать что это
[20:38.280 --> 20:44.840]  координата просто убывает это будет равносильно рассмотрение любой последовательности в силу
[20:44.840 --> 20:55.920]  не убывание функ? по аргументно поэтому опять же можно перейти к пределу и
[20:55.920 --> 21:03.200]  значит когда вы перейдете к пределу вы просто получите де-карту произведения всех лучей вплоть
[21:03.200 --> 21:16.200]  до и минус первого на месте на месте этого луча будет просто пустое множество в пределе
[21:16.200 --> 21:23.840]  ну а де-картового произведения с пустым множеством это пустое множество поэтому
[21:23.840 --> 21:30.920]  это есть вероятность пустого множества что равно 0. есть ли вопросы? а может еще раз повторить
[21:31.200 --> 21:37.240]  почему можем возрастающую толпу последовательность рассматривать? да, смотрите мы предположим что у нас
[21:37.240 --> 21:42.880]  есть произвольная последовательность немозрастающой почему мы можем для неё вывод сделать
[21:42.880 --> 21:48.820]  из того что у нас есть всевозможные возрастающие последовательности? ну что означает что все x
[21:48.820 --> 21:55.680]  стер DES-конечности? да это значит что начиная с некоторого.. как бы вы не зафиксировали уровень
[21:55.680 --> 22:01.260]  начиная с некоторого номера, вообще Frog-ексы будут выше этого уровня.
[22:01.260 --> 22:04.500]  Вы можете выбрать какие-то
[22:04.500 --> 22:08.680]  уровни, не знаю, единицы, двойка, тройка и так далее,
[22:08.680 --> 22:12.200]  и рассматривать подпоследовательность. То есть брать не все последовательность
[22:12.200 --> 22:15.500]  эксов, а первый момент, когда sciences geratum контролирует
[22:15.500 --> 22:17.320]  вашу последовательность, trustworthy minutenus,
[22:17.320 --> 22:20.060]  и ты смотришь на первый момент,隱 zwdoor,
[22:20.060 --> 22:22.720]  а потом смотришь на первый момент, когда части höherа тройки.
[22:22.720 --> 22:29.720]  то у вас есть какая-то ваша последовательность, которая как-то себя невозрастающе ведет, но стремится к людям бесконечности.
[22:29.720 --> 22:37.720]  И вы из Тьи вы из неё достанете подпоследовательность, которая возрастает, стремится к людям бесконечности.
[22:37.720 --> 22:40.720]  Для этой подпоследности у вас есть пределия единицы.
[22:40.720 --> 22:45.720]  Ну, значит, и для всей последовательности тоже, конечно, в пределе единицы,
[22:45.720 --> 22:51.360]  конечно, в пределе единицы, потому что, какой бы вы достаточно большую точку вашей последовательности
[22:51.360 --> 22:58.360]  не взяли, она будет больше какого-то уровня, который вы зафиксировали. И это правда для любого
[22:58.360 --> 23:05.400]  уровня. То есть для любого уровня вы найдете момент, начиная с которого вообще все точки
[23:05.400 --> 23:10.440]  выше этого уровня. Поэтому если под последовательность у вас в пределе один, то для всей последовательности
[23:10.440 --> 23:18.520]  у вас тоже в пределе один. Да, понятно, спасибо. Возможно вы хотите в нижней строчке написать
[23:18.520 --> 23:22.640]  x и t плюс один справа. Спасибо, очень хочу.
[23:22.640 --> 23:41.440]  Так, ну хорошо, со свойствами разобрались. Да, теперь давайте, давайте немножко я еще скажу пару
[23:41.440 --> 23:47.520]  слов о связи между многомерной функцией распределения. А, да, я должен сказать, конечно,
[23:47.520 --> 23:51.400]  что если есть функция распределения с этими тремя свойствами, то она является функцией
[23:51.400 --> 24:05.400]  распределения. То есть полностью аналогичная ситуация с одномерным случаем. Значит, если f из Rn в 0.1
[24:05.400 --> 24:23.360]  обладает свойствами 1,2,3, то найдется распределение вероятности, для которого f это функция распределения.
[24:35.400 --> 24:54.000]  Да, ну конечно по аналогичным причинам, как и в одномерном случае. То есть у вас тоже есть,
[24:54.000 --> 24:59.840]  благодаря на самом деле этому первому свойству, благодаря не отрицательности всех таких дельту,
[24:59.840 --> 25:10.760]  вы можете положить вероятность всех параллепипедов равной вот такой вот величине,
[25:10.760 --> 25:22.600]  и потом продолжить эту меру на всю сигналы. Но давайте все-таки это оставим без технических
[25:22.600 --> 25:27.840]  подробностей. И теперь хочется сказать про связь между многомерной функцией распределения
[25:27.840 --> 25:43.400]  одномерно. Во-первых, вот что. Представьте, что у вас есть функция распределения многомерная,
[25:43.400 --> 25:49.800]  и у нее есть маргинальные распределения. То есть как будто бы вы можете спроектировать на каждую
[25:49.800 --> 25:54.880]  из осей. Вот у вас есть функция распределения, скажем, на плоскости, и вы можете сказать,
[25:54.880 --> 26:02.720]  какая у этой функции распределения проекция, как на ось absys, так и на ось ординат. Как это сделать?
[26:02.720 --> 26:11.840]  Эти распределения будут называться маргинальными распределениями. Пусть П распределение ВРН,
[26:11.840 --> 26:30.480]  и возьмем координату, зафиксируем, и от 1 до N. И определим распределение теперь ВР следующим
[26:30.480 --> 26:43.360]  образом. PIT от B равно просто вероятности декартового произведения R в степени I-1 на B,
[26:43.360 --> 26:51.320]  на R в степени N-I. То есть вы делаете любого орлевского множества в R. То есть вы берете
[26:51.320 --> 26:57.200]  просто и смотрите, какое распределение индуцируется именно на IT координате,
[26:57.200 --> 27:03.080]  на всех остальных позициях вы ставите все действительные числа, и ставите на IT позицию
[27:03.080 --> 27:08.080]  орлевского множества, и получите на самом деле распределение вероятности ВР. Это будет распределение
[27:08.080 --> 27:17.240]  вероятностей. Простое упражнение проверить, что это действительно будет распределение вероятностей.
[27:17.240 --> 27:31.800]  И оно называется маргинальным. Маргинальное распределение вероятностей. Понятно,
[27:31.800 --> 27:36.040]  что если у вас есть все маргинальные распределения, это еще не значит, что вы знаете,
[27:36.040 --> 27:42.880]  как устроено ваше распределение целиком. То есть проекции на оси недостаточно для того,
[27:42.880 --> 27:50.040]  чтобы восстановить распределение. Тем не менее, вы можете, в принципе, если у вас есть маргинальные
[27:50.040 --> 27:53.960]  распределения, вы можете с помощью них распределение на СМРН задать. Единственным образом,
[27:53.960 --> 27:59.000]  но вот самый естественный, на первый взгляд, способ, как это можно сделать, он следующий.
[27:59.000 --> 28:19.680]  Значит, пусть P1, Pn это одномерное распределение. Да, можно просто задать многомерное
[28:19.680 --> 28:30.840]  распределение P следующим образом. На всех декартовых произведениях баррельских множеств
[28:30.840 --> 28:41.160]  определим его просто как произведение распределений соответствующих. P1 от B1
[28:41.160 --> 28:48.520]  умножено тогда на Pn от Bn. Мы получим, конечно, многомерное распределение. То есть оно единственным
[28:48.520 --> 28:52.720]  образом продолжится на всю сигму. Его задать распределение на декартовых произведениях баррельских
[28:52.720 --> 28:57.440]  множеств достаточно. Более того, его достаточно задать на декартовых произведениях лучей,
[28:57.440 --> 29:03.480]  как мы только что выяснили. То есть можно было бы просто сказать, что это верно для лучей. То есть
[29:03.480 --> 29:07.440]  функцию распределения задать, и функция распределения однозначно сдала бы распределение целиком.
[29:07.440 --> 29:25.680]  Оно называется декартовым произведением распределений P1 del Pn.
[29:25.680 --> 29:34.920]  Понятно, что у него функция распределения будет равна произведению функции распределений.
[29:34.920 --> 29:48.480]  Соответствующих этим распределениям P1 del Pn. И повторюсь, что это не единственный способ задать
[29:48.480 --> 29:52.240]  распределение, когда у вас маргинально есть. Мы скоро будем говорить про случайные величины,
[29:52.240 --> 29:56.680]  про случайные векторы, и там будет понятие независимости случайных величин. Вот эта вот
[29:56.680 --> 30:01.800]  ситуация, когда вы рассматриваете декартовое произведение распределения, она отвечает в случае,
[30:01.800 --> 30:06.360]  когда случайные величины независимы. Но они могут быть в принципе независимы,
[30:06.360 --> 30:11.840]  тогда совокупное распределение будет другим. Есть ли какие-то вопросы?
[30:11.840 --> 30:21.680]  Хорошо, теперь типы распределения. Значит, как и в случае одномерного,
[30:21.680 --> 30:25.200]  здесь можно говорить про дискретные распределения, и можно говорить про абсолютно
[30:25.200 --> 30:28.520]  неприятные распределения, и определение абсолютно аналогичное.
[30:28.520 --> 30:49.120]  Здесь опять есть какое-то множество носитель распределения, которое является не более чем
[30:49.120 --> 31:05.120]  счётом. И если мы нашли такое множество, что его вероятность пространной единицы,
[31:05.120 --> 31:21.320]  то распределение называется дискретным. Ну я не буду здесь, наверное, долго об этом говорить,
[31:21.320 --> 31:26.720]  приводить кучу примеров, потому что на самом деле все важные примеры, мы о них уже сказали,
[31:26.720 --> 31:30.000]  они получаются из одномерного случая. Вы можете просто брать там какие-нибудь
[31:30.000 --> 31:36.560]  вернулевские распределения, биномиальные, равномерные по-асоновски, дискретно их перемножать,
[31:36.560 --> 31:42.760]  ой, прошу прощения, декартовых перемножать, вот как я здесь говорил. Возьмём два, перемножим два
[31:42.760 --> 31:49.800]  равномерных распределения декартовых, мы получим многомерное равномерное распределение. Но,
[31:49.800 --> 31:54.960]  значит, что здесь важно подчеркнуть, это то, что по аналогии с одномерным случаем распределение
[31:54.960 --> 32:00.920]  просто восстанавливается по значениям вероятностей на множестве х. То есть,
[32:00.920 --> 32:05.280]  здесь на самом деле вы можете просто говорить про какие-то индивидуальные точки, такие атомы
[32:05.280 --> 32:08.880]  распределения, которые единственным образом все распределение задают, и будет не более,
[32:08.880 --> 32:13.280]  чем счётное количество. Если множество х конечное, будет конечное количество этих точек,
[32:13.280 --> 32:17.840]  которых вероятность не ноль, и которые просто целиком сдают всё распределение. А в случае,
[32:17.840 --> 32:27.920]  если х счётно, то их тоже будет бесконечный счёт. Итак, если мы рассмотрим такую функцию,
[32:27.920 --> 32:39.040]  х маленькая, которая действует из х большое в 0,1 и ставит х в соответствии значения его
[32:39.040 --> 32:46.280]  вероятность просто, то тогда эта функция однозначно восстанавливает распределение.
[32:46.280 --> 32:53.040]  Её ещё называют функцией вероятности, дискретной плотностью, по-разному называют,
[32:53.040 --> 32:59.080]  но смысл понятия. Смысл в том, что очень удобно искать вероятности, потому что,
[32:59.080 --> 33:08.000]  очевидно, для любого баррельского множества b, его вероятность – это просто сумма по всем
[33:08.000 --> 33:20.200]  хам, которые из х большого пересечения с b по x. Давайте назовём дискретной плотностью.
[33:20.200 --> 33:37.120]  Можно называть её функцией вероятности. Но на самом деле мне больше нравится дискретная плотность,
[33:37.800 --> 33:42.480]  потому что когда мы говорим про абсолютно непрерывное распределение, говорим про обычную плотность,
[33:42.480 --> 33:48.420]  то мы имеем в виду, что распределение является абсолютно непрерывной мерой относительно
[33:48.420 --> 33:54.200]  классической меры하세요 бибибелка. Здесь распределение будет являться абсолютно непрерывной мерой относительно
[33:54.200 --> 34:03.760]  такой так называемой считающей меры. Это когда вы просто в целых числах, ну в множестве х – если
[34:03.760 --> 34:09.920]  их не обязаны быть множество целых чисел, вы на множестве их говорите, что мера равна единице на
[34:09.920 --> 34:16.520]  каждом из элементов множества х, а во всех стыдных местах она ноль, вот это будут считающие меры,
[34:16.520 --> 34:22.480]  и это дискретное распределение будет абсолютно непрерывно относительно нее, и значит вот эта
[34:22.480 --> 34:27.120]  дискретная плотность это есть не что иное, как плотность Радонны-Никодима. Плотность Радонны-Никодима
[34:27.120 --> 34:33.160]  определяется вообще для любых пар абсолютно непрерывных мер, но мы об этом поговорим
[34:33.160 --> 34:36.680]  еще в курсе чуть позже, я пока просто хочу сказать, что слово плотность здесь на самом деле
[34:36.680 --> 34:42.760]  существует. Это не просто какая-то видимая аналогия с абсолютно непрерывным случаем,
[34:42.760 --> 34:47.000]  а аналогия полная. Так, абсолютно непрерывные распределения.
[34:47.000 --> 35:07.120]  Ну, значит, здесь должна быть просто многомерная плотность. По аналогии с намерным случаем мы делаем
[35:07.120 --> 35:17.120]  следующее. Мы говорим, что если существует такая функция, p маленькая, которая действует из rn
[35:17.120 --> 35:35.200]  в r плюс, множество действительно неотрицательных чисел, что любого х из rn, f от x это есть интеграл
[35:35.200 --> 35:42.800]  от минус бесконечности до x1 и так далее, от минус бесконечности до xn, от плотности
[35:49.960 --> 35:58.560]  вот этой вот функции, p, то соответствующий этой функции распределение, а распределение
[35:58.560 --> 36:20.040]  называется абсолютно непрерывным, а p называется его плотностью. Вот, ну и верны все те же самые
[36:20.040 --> 36:31.560]  утверждения, о которых мы говорили. В намерном случае, значит, во-первых, для любого барреля
[36:32.560 --> 36:54.520]  его вероятность, это просто интеграл по b от p. Интеграл, конечно, в смысле обычный интеграл
[36:54.520 --> 37:11.520]  лебедя по классическим лебедям. Во-вторых, что еще? Значит, если p, какая-то функция, которая действует из rn в r плюс,
[37:11.520 --> 37:28.520]  такова, что интеграл от нее по rn равен единице, то она является плотностью для некоторого
[37:28.520 --> 37:52.520]  распределения вероятностей. Возьмите просто совершенно любую функцию, не отрицательную интегралу, которая единица, и вы по ней восстановите какой-нибудь распределение вероятностей.
[37:52.520 --> 37:58.520]  Я здесь не буду подробно останавливаться, здесь все полностью аналогично, в одномерном случае, никакого никаких отличий нет.
[38:01.520 --> 38:10.520]  Ну и, наконец, можно еще добавить, что если функция f является хорошей, в том смысле она дифференцируема по каждому аргументу,
[38:10.520 --> 38:31.520]  то распределение вероятностей является абсолютно неправильным, и плотность можно найти как производную по каждому аргументу.
[38:40.520 --> 39:07.520]  Да, вот такое вот кино. Но опять, если хочется привести какие-то примеры абсолютно непрерывных распределений, можно взять абсолютно непрерывные распределения одномерно и составить из них дикартовое произведение.
[39:07.520 --> 39:26.520]  Это тоже важный момент, который я сейчас запишу. Значит, если у вас есть одномерные распределения P1, Pn, которые являются абсолютно непрерывными с плотностями P1, Pn,
[39:26.520 --> 39:40.520]  с плотностями P1, Pn. Так, распределение в одномерном случае, то есть это одномерное распределение.
[39:40.520 --> 40:04.520]  С плотностями P1 маленькое, это далее Pn маленькое, то дикартовое произведение этих распределений, вот так оно обозначается, является абсолютно непрерывным,
[40:04.520 --> 40:17.520]  уже многомерным, да, на rn, bt, rn, с плотностью, равной произведению плотностей.
[40:17.520 --> 40:40.520]  Ну почему так? Ну смотрите, давайте просто проверим, давайте просто проверим, что это так.
[40:40.520 --> 41:08.520]  Вот возьмем вот эту функцию, обозначенную за P, и увидим, что это действительно будет плотность дикартового произведения наших распределений.
[41:08.520 --> 41:14.520]  Ну как это увидеть? Надо взять, значит, вот, должен быть выполнен вот это вот определение.
[41:14.520 --> 41:20.520]  То есть давайте возьмем интеграл, который написан справа, и посмотрим просто, чему рано.
[41:20.520 --> 41:32.520]  Интеграл от минус бесконечности dx1, и так далее, от минус бесконечности dxn, наши вот функции P, которые мы определили.
[41:32.520 --> 41:45.520]  Ну раз она распадается в произведение плотностей, и тем самым все аргументы разделяются, то это будет произведение интегралов.
[41:45.520 --> 41:54.520]  Это будет вот такое вот произведение интегралов.
[41:54.520 --> 42:05.520]  И так как P1, P2 на этой плотности, то каждая из этих интегралов, это просто соответствующая функция распределения в соответствующей точке.
[42:06.520 --> 42:15.520]  Что и требовалось. Да, это действительно определение, функция распределения дикартового произведения.
[42:15.520 --> 42:29.520]  Есть ли вопросы?
[42:29.520 --> 42:31.520]  Если вопросов нет, то давайте...
[42:31.520 --> 42:42.520]  У вас там единственная маленькая описка, в том, где плотность выражаете через производную, там последняя у вас D, прямая вместо загнутой.
[42:42.520 --> 42:48.520]  Это почему-то похоже на F, а не на T. Сейчас исправим все.
[42:48.520 --> 42:57.520]  Так лучше.
[42:57.520 --> 43:07.520]  Так, ну хорошо. В общем, вот это все, что я хотел сказать по многомерным распределениям.
[43:07.520 --> 43:16.520]  Мы с вами можем двигаться дальше, наконец-то, и перейти к случайным величинам, случайным векторам.
[43:16.520 --> 43:20.520]  Семинар, который уже давно сделан, но еще мы догоним.
[43:20.520 --> 43:27.520]  Давайте немного порассуждаем на тему того, что такое случайное величине, случайный вектор, какие-то случайные объекты.
[43:27.520 --> 43:32.520]  Мы не обязаны говорить на самом деле про числовую случайность.
[43:32.520 --> 43:35.520]  У нас случайность может быть и на каких-то других множествах.
[43:35.520 --> 43:41.520]  Например, бывают случайные графы, случайные матрицы, много всего разного случайного бывает.
[43:41.520 --> 43:45.520]  Но смысл вот какой. Давайте поговорим про случайные величины.
[43:45.520 --> 43:51.520]  Мы имеем в виду случайность на множестве действительных чисел, и неспроста мы перед этим говорили про распределение.
[43:51.520 --> 43:55.520]  Сейчас верну экран.
[43:55.520 --> 44:05.520]  Вот когда мы говорим про какой-то эксперимент в физике или еще где-нибудь, который связан с некоторыми числовыми характеристиками.
[44:05.520 --> 44:09.520]  Мы можем измерить температуру в данный момент времени, мы получим какое-то число.
[44:10.520 --> 44:13.520]  Потом мы измерим в другой момент времени, температуру изменится.
[44:13.520 --> 44:17.520]  То есть это вот изменение этой температуры, это некоторые случайные процессы.
[44:17.520 --> 44:25.520]  Мы можем в разные моменты времени просто посмотреть, как реализуется этот случайный процесс.
[44:25.520 --> 44:34.520]  На эти случайные процессы как можно смотреть в терминах нашей аксиоматики вероятности?
[44:34.520 --> 44:42.520]  Да, я напомню, что у нас есть вероятностное пространство, которое состоит из множества элементарных исходов.
[44:42.520 --> 44:45.520]  И на нем зная вероятность.
[44:45.520 --> 44:51.520]  Думайте об этом вероятностном пространстве, как о некотором хаосе, который следит по основе вещей, по основе случайности.
[44:51.520 --> 44:58.520]  В принципе, у того факта, что температура равна 10-15 градусов или еще сколько-то, есть какие-то причины.
[44:58.520 --> 45:02.520]  Да, это на самом деле не просто так. В природе что-то происходит, какие-то процессы происходят.
[45:02.520 --> 45:10.520]  Именно из-за них, как функция всех этих факторов, температура будет равна 10-15 градусам.
[45:10.520 --> 45:19.520]  Соответственно, вы можете думать про вот эту всю совокупность факторов, которые влияют на те или иные измеряемые вами величины, как про вероятностное пространство.
[45:19.520 --> 45:25.520]  Вот случился такой расклад, вот такая температура, случился какой-то другой расклад, какая-то другая температура.
[45:26.520 --> 45:32.520]  И вот после этой мысли, кажется, естественно, смотреть на случайную величину как на функцию от элементарного исхода.
[45:32.520 --> 45:36.520]  То есть тому или иному элементарному исходу вы ставите соответствие числу.
[45:36.520 --> 45:39.520]  Мы с вами так и сделаем.
[45:50.520 --> 45:54.520]  Значит, случайная величина.
[45:55.520 --> 46:02.520]  Ну, давайте начнем с общей ситуации.
[46:02.520 --> 46:09.520]  Как я уже сказал, нам не обязательно говорить, что случайность у нас будет во множестве действительных чисел, да, может быть, где угодно.
[46:09.520 --> 46:13.520]  Поэтому давайте считать, что есть помимо нашего вероятного пространства мега ФП.
[46:13.520 --> 46:29.520]  Мы будем говорить еще про некоторое измеримое пространство Есигма.
[46:29.520 --> 46:34.520]  Ну, измеримое в том смысле, что просто Сигма – это сигнал-агиталоник.
[46:34.520 --> 46:39.520]  То есть есть некоторое множество, есть система измеримых множеств.
[46:39.520 --> 46:42.520]  Зачем нам нужно второе измеримое пространство?
[46:42.520 --> 46:48.520]  Ну, вот как раз для того, чтобы случайность из вероятностного пространства перенести на него.
[46:48.520 --> 46:55.520]  То есть мы вот, например, будем сейчас говорить о том, что мы можем измерить второе измеримое пространство.
[46:56.520 --> 47:05.520]  Когда мы там думаем про температуру, нам, в принципе, не очень уместно думать в терминах, какая вероятность, что температура там ровно 10 градусов.
[47:05.520 --> 47:12.520]  Мы когда строим прогнозы, мы всегда хотим какой-то, конечно, маленький иметь интервал, но вероятность попадания в этот интервал большой.
[47:12.520 --> 47:19.520]  То есть мы хотим сделать какой-то прогноз в духе пространства.
[47:19.520 --> 47:27.520]  Вероятность того, что температура будет в интервале от 9,5 до 10,2 градусов, равна 0,98.
[47:27.520 --> 47:35.520]  То есть мы тем самым хотим измерять вероятность событий, которые будут связаны с действительными числами.
[47:35.520 --> 47:44.520]  Ну или если это какие-нибудь случайные графы или какие-то случайные матрицы, то это будут события, которые ассоцииированы соответственно с графами или смартфонами.
[47:44.520 --> 47:58.520]  То есть у вас есть некоторое множество, на нем знана некоторая сим-алгебра, и вы хотите вот эту вероятность, ее перейти сюда, чтобы уметь измерять события из сим-а, то есть элементы сим-а.
[47:58.520 --> 48:08.520]  Рассмотрим функцию х, которая действует изомегаве, которая является измеримой.
[48:08.520 --> 48:22.520]  Ф-палочка сигма-измеримый. Там называется случайным элементом.
[48:22.520 --> 48:42.520]  Я напомню, что значит ф-палочка сигма-измеримая. Это просто означает, что для любого b из сигма его прообраз полный принжет f.
[48:42.520 --> 48:52.520]  Ну и понятно, конечно, зачем это условие нужно, оно нужно для того, чтобы вы могли говорить про вероятность попадения в любое измеримое множество.
[48:52.520 --> 49:06.520]  То есть, коль скоро у вас есть такое определение, вы можете сказать оно окей, тогда, когда я пишу вероятность того, что х помежит множество b, я имею в виду не что иное, как вероятность, что х помежит множество b,
[49:06.520 --> 49:16.520]  что х помежит множество b, я имею в виду не что иное, как вероятность множества тех омега, которые по действиям х перешли в b.
[49:16.520 --> 49:26.520]  То есть, это есть как раз полный прообраз множества b, который лежит в f, как мы знаем, а раз он лежит в f, мы можем померить его вероятность.
[49:26.520 --> 49:36.520]  И поэтому вот эта штука, это событие, от него можно найти вероятность, и для удобства его обозначают вот так, чтобы не писать вот эти фигурные скобочки омеги.
[49:36.520 --> 49:46.520]  Зачем об этом думать? Можно писать просто вот так. А еще можно записать вот так, psnxmx от b.
[49:46.520 --> 50:00.520]  Что это будет значить? Это будет значить, что вы на самом деле с помощью вашего случайного элемента х можете уже забыть про то, что у вас там было какое-то вероятное пространство, у вас теперь вероятность здесь.
[50:00.520 --> 50:08.520]  И вот эта вот px, это вероятностная мера, уже заданная на измеримом пространстве e sigma.
[50:08.520 --> 50:27.520]  Несложно видеть, что px, это вероятность на e sigma, и она называется распределением вероятностей случайного элемента х.
[50:27.520 --> 50:42.520]  И вот это вероятность, которая еще раз каждому множеству измеримого e sigma ставит в соответствие просто изначальная вероятность, исходная вероятность p, его правообразы.
[50:42.520 --> 50:56.520]  И, значит, эта мера, она оказывается, является вероятностью меры и называется распределением вероятностей х. Есть какие-то вопросы?
[50:56.520 --> 51:04.520]  Значит в частности,
[51:04.520 --> 51:08.520]  называется усилием вероятностей X. Есть какие-то вопросы?
[51:15.520 --> 51:17.520]  Значит, в частности,
[51:24.520 --> 51:27.520]  если E это R,
[51:27.520 --> 51:37.520]  а sigma это баррельская сигнал URW, то X называется случайной величиной.
[51:45.520 --> 51:50.520]  Но я бы сказал, что в англоязычной лизературе вообще часто случайно величиной подразумевают случайный элемент,
[51:50.520 --> 51:59.520]  то есть не различают и говорят, что не важно число, это граф или матрица, будем называть random variable.
[51:59.520 --> 52:04.520]  Но в русской языческой лизературе, как правило, когда мы говорим с членами, мы имеем в виду именно вот эту функцию,
[52:04.520 --> 52:08.520]  которая применяется в члене ver, и мы с вами ее так и будем считать для удобства.
[52:08.520 --> 52:12.520]  Все это понятно, просто вопрос терминологии.
[52:13.520 --> 52:16.520]  Значит, если же E это Rn,
[52:18.520 --> 52:24.520]  sigma это, соответственно, баррельская сигнал URW Rn, то X называется случайным вектором.
[52:24.520 --> 52:34.520]  Давайте поговорим про какие-то важные свойства случайных величин и случайных векторов.
[52:34.520 --> 52:44.520]  Ну, во-первых, давайте критерии измеримости, о котором поговорили наверняка с Иваном Емельевичем, поэтому просто напомню.
[52:44.520 --> 52:53.520]  Значит, вот это свойство измеримости, которое лежит в определении случайного элемента, его можно ослабить.
[52:53.520 --> 52:55.520]  Оно останется от этого.
[52:56.520 --> 53:20.460]  Что я имею в виду?
[53:20.460 --> 53:26.820]  все возможное множество из сигма, проверять то, что их прообразы лежат в веб,
[53:26.820 --> 53:36.700]  достаточно смотреть какую-то образующую систему. Если есть какая-то система множеств m в сигма,
[53:36.700 --> 53:43.300]  такая, что наименьшая сигма алгебра, которая содержит m, просто сигма совпадает?
[53:43.300 --> 53:51.940]  Да, например, когда мы говорим про баррельские множества, но возьмем множество интервалов,
[53:51.940 --> 53:57.380]  или множество лучей, они, как известно, порождают всю сигму алгеброна, то тогда
[53:57.380 --> 54:14.540]  когда функция x является f сигма измеримой, тогда и только тогда, когда свойство измеримости справедливо
[54:14.540 --> 54:23.620]  не для всего сигма, а достаточно только для m, то есть любого множества b из m, x-1 от b,
[54:23.620 --> 54:34.500]  нж-дэф. Насколько понимаю, вы с Ваном Генриховичу это обсуждали, доказательства не сложные,
[54:34.500 --> 54:51.620]  но я его опущу, если есть вопросы. Так, хорошо, значит, еще один важный момент.
[54:51.620 --> 55:01.860]  Еще один важный момент. Можно посмотреть на, нам это понадобится очень сильно, когда мы будем
[55:01.860 --> 55:10.100]  говорить про условные математические ожидания, сразу это здесь скажу, значит, когда мы рассматриваем
[55:10.100 --> 55:18.540]  события, порожденные случайной величиной. Что это значит? Вот рассмотрим такое множество событий
[55:18.540 --> 55:26.620]  f сигма. Так, у нас случайный вектор, случайный элемент, давайте будем вытяжить их. f с индексом x.
[55:26.620 --> 55:35.500]  Значит, вот это сигма алгебра, которая порождена случайным элементом x. Что это такое? Это есть
[55:35.500 --> 55:52.420]  просто множество всех прообразов, множество всех прообразов, всех множеств из сигма. Вот утверждается,
[55:52.420 --> 56:05.700]  что это сигма алгебра. Ну, давайте проверим, это тоже очень простое упражнение. Воспринимать это,
[56:05.700 --> 56:11.140]  важно очень понимать, что это такое, вот эту вещь нужно воспринимать как все события,
[56:11.140 --> 56:21.460]  которые соответствуют вашему случайному объекту. Какие-то события могут не иметь никакого
[56:21.460 --> 56:26.980]  отношения к вашему случайному объекту. У вас масса разных факторов в мире, которые на те или иные
[56:26.980 --> 56:34.020]  процессы влияют. На температуру влияют только некоторые из них. Эта вся совокупность процессов,
[56:34.020 --> 56:39.100]  которые имеют отношение к температуре, они образуют сигму алгебру, порожденную вашей температурой.
[56:39.100 --> 56:56.740]  Почему это сигма алгебра? Ну, во-первых, x-1 от всего e, это конечно все омега. Поэтому омега принадлежит
[56:56.740 --> 57:09.260]  нашего множества fx. Во-вторых, надо проверить, что дополнение принадлежит. То есть, если возьмем
[57:09.260 --> 57:24.020]  какой-то элемент из нашего fx, а его обозначим. Почему x-1 от e равно омега? Потому что x большое
[57:24.020 --> 57:39.980]  это функция, которая действует из-за мега ве. Поэтому к каждому элементу из-за мега мы поставили
[57:39.980 --> 57:44.100]  соответственно этот элемент. Поэтому полный прообраз всех элементов из-за е это все омега.
[57:44.100 --> 57:57.740]  Если a принадлежит fx, то по определению fx найдется такое множество из сигмы,
[57:57.740 --> 58:12.780]  что это его прогресс от точности a. Возьмем тогда дополнение к этому множеству. Мы знаем,
[58:12.780 --> 58:19.380]  что дополнение к множеству b, так как сигма это сигма алгебра, дополнение к множеству b тоже принадлежит
[58:19.380 --> 58:30.500]  сигму. А значит, x-1 от дополнения к b должно принадлежать fx. Потому что fx принадлежат
[58:30.500 --> 58:38.860]  вообще все прообразы, в частности это. Но прообраз дополнения это дополнение к прообразу. То есть,
[58:38.860 --> 58:49.340]  x-1 от b с чертой это в точности дополнение к x-1 от b, что есть дополнение к a. А значит,
[58:49.820 --> 58:56.620]  дополнение k принадлежит fx, что и требуется. Ну и со счетным объединением тоже, конечно,
[58:56.620 --> 59:18.580]  все просто. Если у вас есть счетный набор множеств, то найдутся их образы, найдутся
[59:18.820 --> 59:32.900]  b1, b2 и так далее из сигма. Такие, что их прообразы это соответствующие a. Ну и дальше мы что говорим?
[59:32.900 --> 59:42.380]  Мы говорим, ну хорошо, давайте объединим наши аиты. Это будет не что иное, как x-1 от объединения
[59:42.380 --> 59:50.980]  быитых. Раз все быиты принадлежат сигма, то в частности их объединение, так как сигма это
[59:50.980 --> 59:59.900]  сигма, а у евро тоже принадлежит сигма. Значит, по определению fx прообраз этого объединения принадлежит
[59:59.900 --> 01:00:11.100]  сигма. Господи, принадлежит f, что и требовалось. Есть какие-то вопросы.
[01:00:11.100 --> 01:00:21.500]  Теперь еще важный объект, бареллевская функция. Ну вы знаете прекрасно, что это такое, я напомню.
[01:00:21.500 --> 01:00:25.260]  Значит, функция f из rn в rk называется бареллевской,
[01:00:33.660 --> 01:00:37.580]  если прообраз у всех бареллевских множеств является бареллевскими множествами.
[01:00:37.580 --> 01:00:52.540]  То есть она просто измерима относительно двух бареллевских сигмал. f-1 от b принадлежит бареллевскому
[01:00:52.540 --> 01:01:05.340]  сигму rn. Значит, очевидно, что если у вас есть случайный вектор, и вы примените к нему бареллевскую
[01:01:05.340 --> 01:01:13.980]  функцию, то вы снова получите случайный вектор. На самом деле это в каком смысле равносильные вещи?
[01:01:13.980 --> 01:01:27.900]  Я это утверждение тоже оставлю без доказательства. Значит, в каком смысле равносильные? В том смысле,
[01:01:27.900 --> 01:01:40.620]  что пусть у вас есть, сейчас, пусть есть кси-энмерный случайный вектор,
[01:01:50.620 --> 01:01:56.220]  а это, ну это какая-то пусть функция, которая действует из омега rk.
[01:01:56.220 --> 01:02:19.980]  Тогда это является f-кси-измеримым случайным вектором. Тогда и только тогда,
[01:02:19.980 --> 01:02:36.380]  когда существует бареллевская функция f, которая действует из rn-vrk, такая, что это равняется f от кси.
[01:02:36.380 --> 01:02:49.900]  Ну, в одну сторону это очевидно, в другую сторону не очень. Давайте я в очевидную
[01:02:49.900 --> 01:02:55.900]  сторону быстро поясню, почему это так. Значит, понятно, что если это бареллевская функция от кси,
[01:02:55.900 --> 01:03:09.020]  то тогда верно, что это f-кси-измеримый случайный вектор. То есть справа налево легко можно доказать.
[01:03:09.020 --> 01:03:18.140]  Значит, смотрите, что нам нужно проверить? Нам нужно проверить определение f-кси-измеримости.
[01:03:18.140 --> 01:03:23.820]  То есть нам нужно проверить, что для любого бареллевского множества, в данном случае,
[01:03:23.820 --> 01:03:29.980]  f-кси-измеримости из rk, ее прообраз принадлежит f-кси. Ну, вот возьмем произвольное бареллевское множество из rk
[01:03:29.980 --> 01:03:40.940]  и посмотрим на это в минус первое от b. Мы предположили, что это, это есть бареллевская функция f от кси.
[01:03:40.940 --> 01:03:47.100]  Да, и мы, значит, эту штуку убьем в минус первую степень и применяем в b.
[01:03:47.100 --> 01:04:06.140]  Да, значит, что это значит? Это значит, что мы сначала применяем f-1 к b, а потом к этому мы применяем кси в минус 1.
[01:04:06.140 --> 01:04:17.340]  Но f – бареллевская функция, а b – бареллевское множество. Это значит, что f-1 от b – это бареллевское множество, но из rm.
[01:04:17.340 --> 01:04:25.100]  А так как кси – это случайный вектор, то по определению f-кси эта штука должна ему принадлежать.
[01:04:25.100 --> 01:04:32.700]  Что ей требовалось? Да, то есть в одну сторону понятно, в другую сторону я опущу, но это некоторая, да,
[01:04:32.940 --> 01:04:39.580]  это некоторая на самом деле задачка предъявить эту бареллевскую функцию по имеющимся случайным векторам кси.
[01:04:39.580 --> 01:04:44.300]  И это, если Иван Геннадьевич не рассказывал, но может попробовать сами доказать.
[01:04:44.300 --> 01:04:55.020]  Время хоть это занимает, я от лекции не очень хочу вынимать все-таки эту вещь из теории функций, а не из теории вероятности непосредственно.
[01:04:55.020 --> 01:04:59.020]  Есть ли какие-то вопросы? Что означает f-кси измеримый случайный вектор?
[01:04:59.980 --> 01:05:08.460]  А, ну это как f-измеримый случайный вектор, да, то есть мы здесь вместо множества событий f рассматриваем множество событий f-кси.
[01:05:08.460 --> 01:05:11.900]  Ну то есть я имею в виду обычное определение измеримости.
[01:05:11.900 --> 01:05:13.900]  Ну да, понятно, спасибо.
[01:05:13.900 --> 01:05:17.660]  Да, на всякий случай напишу, раз возник вопрос.
[01:05:17.660 --> 01:05:26.220]  Значит, для любого b из бареллевского сигмала Геннадьевича ворка, это минус 1 от b принадлежит f-кси.
[01:05:27.180 --> 01:05:33.580]  Я бы мог здесь сказать, что это просто случайный вектор, но это было бы более слабое утверждение,
[01:05:33.580 --> 01:05:45.100]  потому что мы даже можем сузить нашу сигмал Геннадьевич событие f и говорить только про событие, которое связано со случайным вектором кси.
[01:05:45.100 --> 01:05:47.100]  Ну здесь на самом деле все логично.
[01:05:47.980 --> 01:05:49.980]  Вот это, это функция от кси.
[01:05:49.980 --> 01:05:59.420]  Это означает, что по тем событиям, которые определяют кси, они точно так же определяют и это, тем более, раз это функция от кси, да.
[01:05:59.420 --> 01:06:03.420]  То есть на самом деле вот эта равносильность, она интуитивно очевидна.
[01:06:03.420 --> 01:06:07.420]  И в одну сторону она легко оказывается, в другую, но не очень.
[01:06:07.420 --> 01:06:13.420]  Так, еще один, значит, важный момент, который из этого следует.
[01:06:13.740 --> 01:06:19.740]  Следующее утверждение, которое мы сейчас легко докажем,
[01:06:19.740 --> 01:06:25.740]  что вектор является случайным тогда и только тогда, когда его компоненты от случайной величины.
[01:06:25.740 --> 01:06:33.740]  Да, то есть кажется понятно, что если вектор случайный, то его компоненты случайной величины оказываются верно и обратно.
[01:06:33.740 --> 01:06:37.740]  То есть случайный вектор можно определять не так, как мы это только что сделали,
[01:06:38.060 --> 01:06:42.060]  сказав, что это функция измеримая, которая действует в Rn,
[01:06:42.060 --> 01:06:48.060]  а сказать, что просто случайный вектор, это вектор, который состоит из случайных величин.
[01:07:00.060 --> 01:07:06.060]  Значит, кси, вектор составный с компанией x1, t, xn является случайным вектором.
[01:07:06.380 --> 01:07:10.380]  Тогда и только тогда, когда x1, t, xn это случайное величине.
[01:07:18.380 --> 01:07:20.380]  Вот, ну давайте докажем.
[01:07:24.380 --> 01:07:28.380]  Ну, хоть слева направо кажется очевидно, но доказывать надо.
[01:07:28.380 --> 01:07:30.380]  Давайте докажем, сначала слева направо.
[01:07:30.700 --> 01:07:36.700]  Значит, возьмем какое-то произвольное i, докажем, что xit это случайная величина.
[01:07:38.700 --> 01:07:42.700]  Ну, по определению случайной величины, возьмем любое баррелевское множество b
[01:07:46.700 --> 01:07:50.700]  и поймем вообще, что такое x-1 от b, xit-1 от b.
[01:07:51.020 --> 01:07:53.020]  Что это такое?
[01:07:53.020 --> 01:08:01.020]  Ну, это есть множество тех омега, которые под действием xit и t переходят в b.
[01:08:05.020 --> 01:08:07.020]  Это, конечно же, в точности множество тех омега,
[01:08:07.020 --> 01:08:13.020]  которые под действием xit переходят в декартовое произведение R и минус 1 раз,
[01:08:13.020 --> 01:08:17.020]  потом b, потом еще декартовое произведение R и t.
[01:08:17.340 --> 01:08:19.340]  Понятно, что i и t координата принадлежит множеству b.
[01:08:19.340 --> 01:08:23.340]  Это то же самое, что весь вектор принадлежит вот такому декартовому произведению.
[01:08:23.340 --> 01:08:25.340]  Это просто одно и то же.
[01:08:25.340 --> 01:08:29.340]  А так как это множество является баррелевским,
[01:08:29.340 --> 01:08:35.340]  то по определению случайного вектора его прообраз принадлежит f.
[01:08:35.340 --> 01:08:37.340]  Значит, действительно xit это случайная величина.
[01:08:37.660 --> 01:08:39.660]  В обратную сторону.
[01:08:39.660 --> 01:08:43.660]  Пусть теперь есть x1, t, xn, случайные величины.
[01:08:47.660 --> 01:08:49.660]  Ну, возьмем, что нам надо проверить?
[01:08:50.620 --> 01:08:53.360]  Нам надо проверять, что xit это случайная ве treateddoctor.
[01:08:53.360 --> 01:08:56.360]  Ну, теперь мы будем пользоваться критериями измеримости.
[01:08:56.360 --> 01:08:58.360]  У нас есть благо критерия измеримости.
[01:08:58.360 --> 01:09:00.360]  Вот он.
[01:09:02.360 --> 01:09:07.460]  Которое говорит что нам не обязательно свойствуют измер película или деп seineεις非,
[01:09:07.460 --> 01:09:10.460]  ведь на самом деле их Whoa OH wasza ting!!!
[01:09:10.500 --> 01:09:12.500]  Вот.
[01:09:12.960 --> 01:09:14.980]  Итак, moving on.
[01:09:14.980 --> 01:09:21.820]  который говорит, что нам не обязательно свойство измеримости приобретать вообще для всех множества
[01:09:21.820 --> 01:09:27.100]  сигма-алгебра, в нашем случае это баррельско-сигма-алгебра ВРМ, а нам достаточно взять какую-нибудь систему
[01:09:27.100 --> 01:09:34.180]  образующих множество этой сигма-алгебры и для неё проверить. Ну, например, возьмём декартовое произведение.
[01:09:34.180 --> 01:09:40.420]  Мы знаем, что все декартовые произведения являются системой, которая образует всю сигму-алгебру,
[01:09:40.420 --> 01:09:54.180]  да, то есть, если я рассмотрю множество всех декартовых произведений, то на меньше сигма-алгебра,
[01:09:54.180 --> 01:09:57.340]  которое это множество содержит, это в точности баррельско-сигма-алгебра ВРМ.
[01:09:57.340 --> 01:10:05.860]  Поэтому мне достаточно рассматривать декартовое произведение для проверки на измеримости. Я это
[01:10:05.860 --> 01:10:17.380]  сейчас и сделаю. Я беру кси в минус 1, это какого-то декартового произведения, и понимаю, что это
[01:10:17.380 --> 01:10:24.860]  множество тех омега, которые под действием кси перешли в это декартовое произведение. Что значит
[01:10:24.860 --> 01:10:30.620]  перешли в декартовое произведение? Это значит, что первая координата должна перейти в первое
[01:10:30.620 --> 01:10:36.460]  множество, то есть кси первое от омега. Должно попасть в первое множество, кси второе от омега в
[01:10:36.460 --> 01:10:47.020]  второе, и так далее, кси nt от омега должно попасть в это множество. Ну и понятно, что если я просто
[01:10:47.020 --> 01:10:52.780]  отдельно рассмотрю прообразы В1, Вn, то их пересеку и получу то же самое. То есть, это есть не что
[01:10:52.780 --> 01:10:59.180]  иное, как пересечение по всем и от единицы до m множество омега таких, что кси и т от омега попало в
[01:10:59.180 --> 01:11:10.700]  Вt. Ну а это как раз прообразы Вt от действия кси и т. А кси и т это случайная величина.
[01:11:10.700 --> 01:11:16.620]  Значит, каждый из прообразов принжит f, то и все пересечение принжит f, что и требуется.
[01:11:21.260 --> 01:11:22.900]  Так, есть ли какие-то вопросы?
[01:11:29.180 --> 01:11:38.740]  То есть, основное, что нужно доказать, это просто измеримость этих функций. То есть,
[01:11:38.740 --> 01:11:42.500]  основное, что нужно доказать, это просто измеримость функций кси и т или кси.
[01:11:42.500 --> 01:11:56.180]  Ну да. Ну это есть определение случайного вектора. Так, хорошо. Теперь давайте поговорим про
[01:11:56.180 --> 01:12:00.340]  арифметические операции над случайными величинами. То есть, мы поняли, что если есть случайный вектор,
[01:12:00.340 --> 01:12:04.700]  то его компонент это случайная величина. Это оправдывает арифметические операции.
[01:12:04.700 --> 01:12:11.860]  Да, почему это оправдывает арифметические операции? Ну возьмем две случайные величины и сложим их.
[01:12:11.860 --> 01:12:18.260]  Правда ли, что мы получим слово случайную величину? Конечно, правда, потому что последующие формальные
[01:12:18.260 --> 01:12:25.060]  причины. Значит, если мы возьмем вектор из этих двух случайных величин, составим. Это просто вектор
[01:12:25.260 --> 01:12:28.700]  из двух случайных величин. Вот подоказано только что утверждение. Он является случайным вектором.
[01:12:28.700 --> 01:12:36.660]  А потому, что я сказал перед этим, если мы применим к нему баррельскую функцию, мы получим снова
[01:12:36.660 --> 01:12:42.300]  случайный вектор. В частности, если мы сложим компоненты вектора, сложение этой баррельской
[01:12:42.300 --> 01:12:47.160]  функции, мы получим случайную величину. А значит, там сумма случайных величин – это случайная
[01:12:47.160 --> 01:12:52.980]  величина. Разность случайных величин, произведение, отношение. То есть, все арифметические операции,
[01:12:52.980 --> 01:12:58.980]  которые можно делать с числами, их можно делать как с функциями, со случайными величинами,
[01:12:58.980 --> 01:13:08.020]  и вы получите снова случайные величины. Итак, следствие. Хотя давайте еще одну
[01:13:08.020 --> 01:13:11.380]  утверждение с перерасформируем. Любая непрерывная функция является баррельской.
[01:13:11.380 --> 01:13:15.980]  То есть арифметические операции являются баррельским, потому что они являются непрерывными функциями.
[01:13:15.980 --> 01:13:23.380]  Ну или кусочно-непрерывные функции тоже являются баррельскими.
[01:13:23.380 --> 01:13:37.220]  Кусочно-непрерывные функции.
[01:13:37.220 --> 01:13:42.860]  Почему я сказал про кусочно-непрерывные? Но если нам надо будет разделить
[01:13:42.860 --> 01:13:49.660]  одну случайную величину на другую, мы должны в нуле как-то, если знаменитая
[01:13:49.660 --> 01:13:55.460]  может обращаться в ноль, мы должны как-то с этим поворотиться, вот поэтому нам должна
[01:13:55.460 --> 01:14:07.020]  в этом случае будет кусочек непрерывности. Ну и очевидное следствие это, что если есть две
[01:14:07.020 --> 01:14:16.020]  случайные величины, вы их смело можете. Что буду с ними делать? Значит, если x это случайные величины,
[01:14:16.020 --> 01:14:31.940]  то их сумма, разность, произведение, частное, ну тут можно умножить данный индикатор того,
[01:14:31.940 --> 01:14:38.820]  что это не равно нулю, чтобы выколоть эту точку, являются случайными величинами.
[01:14:45.620 --> 01:14:55.700]  Вот, ну и последнее на сегодня, нет, не на сегодня, на вот эту лекцию, на первую лекцию утверждение,
[01:14:55.700 --> 01:15:03.540]  которое мы с вами докажем, это то, что можно не только делать технические операции,
[01:15:03.540 --> 01:15:16.340]  но еще и к пределу переходить. Значит, если есть последовательность x1, x2 и так далее случайных
[01:15:16.340 --> 01:15:24.700]  величин, ну вообще говоря, предела может и не существовать, конечно, но если он существует,
[01:15:24.700 --> 01:15:29.260]  то он будет являться случайными величинами. Более общего можно сформулировать следующее утверждение.
[01:15:29.260 --> 01:15:46.780]  Ну во-первых, можно брать infinum, supremum, если они существуют, а можно брать нижние пределы и
[01:15:46.780 --> 01:15:55.460]  верхние пределы, опять же, если они конечные. И это все будут случайными величинами.
[01:15:55.460 --> 01:16:09.100]  Вот, ну давайте начнем наказывать. Докажем, я думаю, попробуем успеть доказать для infinum
[01:16:09.100 --> 01:16:13.340]  и для supremum, а с нижними и верхними пределами на следующий кусок лекции,
[01:16:13.340 --> 01:16:22.140]  которая в 15-30 начнется. Так, ну давайте supremum, с infinum просто аналогично.
[01:16:22.140 --> 01:16:34.180]  Рассмотрим функцию, которая равна supremu. Что значит supremum? Еще раз, у нас есть последовательность
[01:16:34.180 --> 01:16:41.300]  функций, конечно, а не чисел, а именно функций, и мы просто для каждого
[01:16:41.300 --> 01:16:45.940]  аргумента находим свой supremum. Если мы какой-то омега маленький, какой бы мы аргумент не
[01:16:45.940 --> 01:16:49.980]  зафиксировали, мы получим последовательность чисел, то есть значение нашей функции на этом
[01:16:49.980 --> 01:16:56.220]  аргументе. Вот, и мы берем для каждого аргумента свой supremum, и у нас получается новая функция.
[01:16:56.220 --> 01:17:00.540]  Мы для каждого аргумента нашли свое собственное значение, получили новую функцию xi, и вы задержали,
[01:17:00.540 --> 01:17:05.300]  что она будет случайной величиной. Значит, чтобы проверить, что она является случайной величиной,
[01:17:05.300 --> 01:17:11.740]  нам нужно проверить измеримость. Возьмем прообраз
[01:17:11.740 --> 01:17:25.300]  луча от минус бесконечности до x. Ну, то есть это множество таких омега, что xi от омега меньше
[01:17:25.300 --> 01:17:33.940]  чем x. Так как xi это supremum, то это есть не что иное, как множество таких омега, что для любого n,
[01:17:33.940 --> 01:17:42.380]  xi и n меньше, чем x. Это есть, конечно, пересечение по всем n, xi и n в минус первый от луча от
[01:17:42.380 --> 01:17:53.500]  минус бесконечности до x, что является элементом f. Что является элементом f, так как все эти
[01:17:53.500 --> 01:18:03.820]  прообразы f принадлежат, f это сигма-агебра, то есть счетное пересечение тоже подходит. Из этого,
[01:18:03.820 --> 01:18:11.580]  конечно, все следует, потому что вот эти лучи, они порождают всю сигму-агебру. По критерию измеримости,
[01:18:11.580 --> 01:18:18.260]  так как множество лучей является образующей системой множеств, то достаточно только для этих лучей
[01:18:18.260 --> 01:18:23.580]  проверить свойства измеримости. Мы это сделали, а значит, xi действительно случайно начинает. Аналогично с
[01:18:23.580 --> 01:18:35.220]  инфинумом рассмотрим лучи, которые в другую сторону смотрят. Рассмотрим луч от x до плюс
[01:18:35.220 --> 01:18:40.500]  бесконечности. Имеем право, эти лучи тоже образуют всю сигму-агебру, то есть это тоже система,
[01:18:40.500 --> 01:18:51.380]  которая порождает всю сигму-агебру. И по аналогичным причинам, это множество амек таких,
[01:18:51.380 --> 01:18:56.820]  что все ксии больше либо равны чему. В данном случае будет пересечение по всем n, ксии n в
[01:18:56.820 --> 01:19:01.860]  минус 1, луча от x до плюс бесконечности, и опять это элемент f, что и требуется.
[01:19:01.860 --> 01:19:14.820]  Время осталось мало, давайте с нижним пределом и с верхним пределом чуть сложнее разберемся
[01:19:14.820 --> 01:19:17.900]  после перерыва, а именно в 15.30. Если какие-то вопросы,
[01:19:17.900 --> 01:19:34.020]  если вопросов нет, то на этом все. Спасибо всем присутствующим, увидимся через 3.5 часа.
[01:19:34.020 --> 01:19:45.180]  Прекрасно. Давайте продолжим. На чем мы остановились? Мы с вами сформулировали
[01:19:45.180 --> 01:19:50.460]  подтверждение про пределы и выяснили, что инфину у нас в правом последовательстве действительно
[01:19:50.460 --> 01:19:56.100]  случайная величина. Давайте теперь разберемся с тем, почему нижний верхний предел — это тоже
[01:19:56.100 --> 01:20:08.100]  случайная величина. Давайте с верхнего начнем, чтобы ознать верхний предел за ксии. Как и выше,
[01:20:08.100 --> 01:20:14.660]  нам нужно взять какую-то систему множеств, которая образует всю сигму-агебру, показать,
[01:20:14.660 --> 01:20:21.580]  что для нее есть измеримость, верхний предел. Что значит, что верхний предел больше какого-то
[01:20:21.580 --> 01:20:30.100]  х? То есть, по москвальму, на ксии минус 1 от луча от х до плюс бесконечности х не включает. То есть,
[01:20:30.100 --> 01:20:37.100]  что верхний предел больше, чем х. Верхний предел больше, чем х, это означает, что найдется сколь
[01:20:37.100 --> 01:20:42.980]  угодно большой член последовательности, который больше, чем х. Чтобы верхний предел был больше,
[01:20:42.980 --> 01:20:49.060]  чем х, должна быть под последовательность, которая в пределе дает нечто большее, чем х. То есть,
[01:20:49.060 --> 01:20:59.180]  на самом деле, это множество таких омега, что для любого к найдется n больше, чем равное, чем k,
[01:20:59.180 --> 01:21:06.420]  такое, что ксен больше, чем х. Да, это в точности условие заключается в том, что верхний предел
[01:21:06.420 --> 01:21:20.500]  больше, чем х. Нет, я не прав. Верхний предел может быть равен х, и, тем не менее,
[01:21:20.500 --> 01:21:26.860]  может находиться сколь угодно большой член последовательности, который больше, чем х. Но,
[01:21:26.860 --> 01:21:37.660]  то есть, тут должно быть нечто более сложное условие. Ксен должен быть больше, чем х плюс
[01:21:37.660 --> 01:21:51.340]  некоторое эпсилум. То есть, на самом деле, правильно писать вот так. Это пересечение по всем
[01:21:51.340 --> 01:22:08.980]  эпсилум больше нуля. Вот таких вот событий. Если поставить квадратную скобку, то тоже не очень
[01:22:08.980 --> 01:22:16.580]  понятно, потому что если верхний предел равен х, то тогда это может означать в принципе, что и все
[01:22:16.580 --> 01:22:22.940]  члены последовательности могут быть меньше, чем х, но при этом верхний предел будет равен х. Нам
[01:22:22.940 --> 01:22:32.580]  именно нужно, чтобы было больше, чем х с некоторым запасом. То есть, даже если мы потребуем больше
[01:22:32.580 --> 01:22:38.620]  оно, чем х, нам в целом придется что-то умудрить вот в таком же духе. То есть, так вот просто обойтись
[01:22:38.620 --> 01:22:44.060]  без этого эпсилума, короче, не получится. То есть, нам нужно три квадра, на самом деле, не два, три.
[01:22:44.060 --> 01:22:54.580]  Теперь понятно, что мы можем объединять не по всем положительным эпсилумам, а по любой
[01:22:54.580 --> 01:22:58.660]  подпоследовательности положительных эпсилум, которая стремится к нулям. То есть, мы можем
[01:22:58.660 --> 01:23:04.780]  взять, например, написать вместо этого сумму по всем натуральным м, объединение, прошу прощения,
[01:23:04.780 --> 01:23:15.940]  по всем натуральным м. А здесь написать вместо эпсилум, написать х плюс 1мт. Это будет просто
[01:23:15.940 --> 01:23:22.740]  равносильным условием. Ну и все, это уже есть объединение по всем м, пересечение по к, объединение
[01:23:22.740 --> 01:23:32.580]  по м больше, чем к, событий кси-н больше, чем х плюс 1мт. Вот теперь, так как си-н это случайная
[01:23:32.580 --> 01:23:39.620]  величина, прообразы вот этих всех, вот этих всех лучей являются барреллерскими множествами. Здесь
[01:23:39.620 --> 01:23:47.620]  у нас счетное объединение-пересечение, значит, это тоже барреллерское множество. Господи, это тоже
[01:23:47.620 --> 01:23:55.820]  событие, да, элементы f, так как f это сигнал гибра, что и требуется. Да, ну раз мы доказали вот для всех
[01:23:55.820 --> 01:24:01.420]  таких лучей, то значит, мы доказали, что кси-это случайная величина. Действительно. Вопросы.
[01:24:05.420 --> 01:24:07.340]  Ну и по аналогии с нижним пределом,
[01:24:15.340 --> 01:24:23.620]  с нижним пределом, ну прям можно по аналогии, то есть взять теперь, чтобы долго не думать,
[01:24:23.620 --> 01:24:31.420]  что есть луч от минус бесконечности до х, не включая х, да, и тогда события, заключающиеся в том,
[01:24:31.420 --> 01:24:36.260]  что нижний предел ниже, чем х, это события, которые заключаются в том, что для некоторого
[01:24:36.260 --> 01:24:43.420]  епселон найдется бесконечно много членов последовательности, которые меньше, чем х-эпселон.
[01:24:43.420 --> 01:24:54.940]  То есть это объединение опять по всем положительным епселон. Событие. Для любого k найдется такой
[01:24:54.940 --> 01:25:03.340]  номер, превосходящий k, что ксен меньше, чем х-эпселон. Ну и опять это есть объединение по всем
[01:25:03.340 --> 01:25:11.060]  m, пересечение по всем k, объединение по всем n больше, чем k, событие ксен меньше, чем х-1mt,
[01:25:11.060 --> 01:25:13.940]  которое принадлежит f, что и требуется.
[01:25:20.980 --> 01:25:21.860]  Есть какие-то вопросы?
[01:25:28.700 --> 01:25:38.900]  Так, хорошо, ну с этим вроде всё. Давайте я напоследок еще раз скажу то, что я уже сказал в начале.
[01:25:38.900 --> 01:25:48.100]  А именно, что у нас есть какой-то случайный элемент, будь то случайный величина или случайный
[01:25:48.100 --> 01:25:55.340]  вектор, то ему соответствует вероятность, которую он индуцирует во множестве, в которое действует.
[01:25:55.340 --> 01:26:01.380]  Мы его обозначили здесь по х и сказали, что это на самом деле распределение вероятностей
[01:26:01.380 --> 01:26:12.060]  случайного элемента х. Понятно, что все определения, все понятия, которые мы связывали с понятием
[01:26:12.060 --> 01:26:17.540]  распределения, они просто переносится на случайную величину и случайный вектор. То есть мы можем
[01:26:17.540 --> 01:26:23.220]  говорить про функцию распределения случайного вектора или случайной величины. Можем говорить про
[01:26:23.220 --> 01:26:29.980]  абсолютно непрерывный случайный вектор, если его распределение является... Он точно так же может
[01:26:29.980 --> 01:26:34.220]  быть дискретным. Можем говорить про плотность случайного вектора или случайной величины,
[01:26:34.220 --> 01:26:39.780]  имея в виду плотность соответствующего распределения вероятностей. Давайте это запишем.
[01:26:39.780 --> 01:26:47.860]  Давайте считать тогда, что х это случайный вектор
[01:26:47.860 --> 01:27:04.260]  для общности, а по х это его распределение вероятностей. То есть это та самая мера,
[01:27:04.340 --> 01:27:14.820]  которая порождает этот случайный вектор. То есть это такая мера, которая действует из баррельского
[01:27:14.820 --> 01:27:32.620]  сигмала URM01, что по х от B это есть вероятность события, х принадлежит B. Это распределение х.
[01:27:32.620 --> 01:27:44.060]  Распределение х. Ну и тогда мы будем говорить заодно и про функцию распределения х. То есть fх,
[01:27:44.060 --> 01:27:55.940]  которая действует из RRM01, функция распределения, соответствующая распределению по х,
[01:27:55.940 --> 01:28:00.900]  мы будем называть ее функцией распределения самого вектора.
[01:28:00.900 --> 01:28:16.740]  Функция распределения х. Ну и если по х дискретно,
[01:28:16.740 --> 01:28:23.420]  то мы будем говорить, что х это дискретный случайный вектор.
[01:28:23.420 --> 01:28:43.460]  Ну и если по х абсолютно непрерывно,
[01:28:43.460 --> 01:28:49.020]  то мы будем говорить, что х это абсолютно непрерывный случайный вектор.
[01:28:53.420 --> 01:29:09.860]  Вот. Ну и соответственно, если в этот раз у нас тут непрерывно,
[01:29:09.860 --> 01:29:14.100]  у него есть плотность, мы будем называть плотностью вектора.
[01:29:14.100 --> 01:29:19.700]  По маленькой х. Плотность по большому х.
[01:29:19.700 --> 01:29:26.620]  А мы будем ее называть плотностью случайного вектора.
[01:29:26.620 --> 01:29:46.340]  Так, ну все, теперь давайте подойдем поближе к тому, чтобы что-нибудь посчитать,
[01:29:46.340 --> 01:29:53.020]  какие-нибудь вероятности соответствующие случайным векторам.
[01:29:53.020 --> 01:30:02.460]  Ну там скажем, какая вероятность? Вот есть две независимых случайных величины.
[01:30:02.460 --> 01:30:06.260]  Как нам посчитать вероятность того, что их сумма попала в какое-нибудь множество?
[01:30:06.260 --> 01:30:10.020]  Подобные задачи мы с вами научимся решать, но вот как раз, чтобы их решать,
[01:30:10.020 --> 01:30:15.900]  нам нужно поговорить про независимость. Независимость случайных величин,
[01:30:15.900 --> 01:30:19.100]  это такой очень важный частный случай совместных распределений.
[01:30:19.100 --> 01:30:26.060]  Но вот есть у вас случайный вектор. У каждой случайной величины этого вектора есть какое-то
[01:30:26.060 --> 01:30:30.540]  распределение вероятностей. Как мы сегодня говорили, это называется маргинальное распределение.
[01:30:30.540 --> 01:30:35.220]  То есть у случайного вектора есть распределение в РН, распределение всего этого вектора целиком.
[01:30:35.220 --> 01:30:39.300]  У каждой кардиналты есть свое распределение в Р, которое называется маргинальным распределением.
[01:30:39.300 --> 01:30:43.780]  И знать маргинальное распределение недостаточно для того, чтобы восстановить распределение целиком.
[01:30:43.780 --> 01:30:51.220]  Ну вот, например, если вы скажете, что давайте распределение вектора, это будет произведение,
[01:30:51.220 --> 01:30:55.540]  декартовое произведение распределения его компонента. Вот это как раз означает,
[01:30:55.540 --> 01:31:01.980]  что компоненты в случайном векторе независимы. Но если вы там измеряете температуру, грубо говоря,
[01:31:01.980 --> 01:31:07.620]  здесь и в Австралии, но, наверное, это какие-то похожие на независимые случайные величины.
[01:31:07.620 --> 01:31:12.420]  То есть это те величины, что наступление одних не влияет на наступление других.
[01:31:12.420 --> 01:31:19.780]  Давайте поговорим про независимость случайных величин и случайных векторов.
[01:31:19.780 --> 01:31:26.500]  Понятно, что это очень важное понятие, которое является вообще центральным в
[01:31:26.500 --> 01:31:30.140]  серии вероятности, понятие независимости. Мы с вами уже говорили про независимость событий,
[01:31:30.140 --> 01:31:39.060]  и из этого определение вытекает независимость случайных величин. В частности, я в начале,
[01:31:39.820 --> 01:31:43.620]  о впоминал, что есть такое физическое определение вероятности и математическое определение вероятности,
[01:31:43.620 --> 01:31:48.860]  то есть вероятность можно понимать как частотность наступления событий,
[01:31:48.860 --> 01:31:54.340]  если вы могли бы это событие реализовывать независимо много раз. То есть проводить
[01:31:54.340 --> 01:31:57.960]  какой-либо эксперимент, в рамках которого это событие может произойти. Если вы могли
[01:31:57.960 --> 01:32:01.240]  бы делаться без конечного много раз независимо, то тогда бы оказалось,
[01:32:01.240 --> 01:32:06.480]  что частота наступления вашего события, она в пределе была бы равна вероятности.
[01:32:06.480 --> 01:32:15.120]  И чтобы проводить рассуждения, связаны не только события, но и случайные величины,
[01:32:15.120 --> 01:32:18.880]  нужна независимость. Закон больших чисел, центральная предельная теорема, о которых мы
[01:32:18.880 --> 01:32:23.280]  будем говорить в курсе, они все опираются на понятие независимости. Они работают именно для независимых
[01:32:23.280 --> 01:32:29.760]  случайных величин. Для зависимого бывает всё, что угодно. Но понятно, что зависимости могут слабы
[01:32:29.760 --> 01:32:34.600]  быть. То есть вот эти предельные теоремы, о которых мы будем говорить, их можно обобщать на какие-то
[01:32:34.600 --> 01:32:38.280]  зависимые ситуации. Мы этого делать не будем. Мы будем ограничиваться независимым случаем. Но,
[01:32:38.280 --> 01:32:44.040]  тем не менее, можно. Если не требовать никакой независимости, то бывает всё, что угодно. И все
[01:32:44.040 --> 01:32:50.520]  предельные теоремы работают только по модулю какой-то независимости или слабой зависимости.
[01:32:50.520 --> 01:33:02.480]  Итак, ну, во-первых, независимость двух случайных величин. Независимость часто обозначают вот так.
[01:33:02.480 --> 01:33:14.560]  Значит, случайная величина xi это независимая, если для любых баррельских множеств, ну или это
[01:33:14.560 --> 01:33:19.000]  случайный вектор, пусть это был случайный вектор. Пусть, например, xi имеет размерность n, а это имеет
[01:33:19.000 --> 01:33:32.000]  размерность k. То есть любых баррельских множеств в одном случае zrn, b1 и b2 из rk. Вероятность того,
[01:33:32.000 --> 01:33:41.280]  что x1 принадлежит b1, это принадлежит b2 равна произведению вероятности.
[01:33:53.880 --> 01:33:59.420]  Вот. Ну, по аналогии можно говорить про независимость, на самом деле, любого
[01:33:59.420 --> 01:34:05.900]  набора случайных причин. Давайте начало конечного. Пусть у нас есть, скажем, случайные векторы.
[01:34:05.900 --> 01:34:25.100]  Ксиодинт или ксен. Мы будем говорить, что они независимые. Если для любых баррельских множеств, ну,
[01:34:25.100 --> 01:34:30.200]  из соответствующих размерностей, да, понятно, что давайте мы будем считать, что итый вектор имеет
[01:34:30.200 --> 01:34:43.880]  размерность, скажем, k итая. То есть для любых b1 из b от rk1 и так далее bn из b от rkn выполнена
[01:34:43.880 --> 01:34:52.680]  вероятность совместная, потому что x1 принадлежит b1 и так далее xn принадлежит bn равна произведению
[01:34:53.060 --> 01:35:05.140]  вероятностей. Вот понятно, что есть тоже попарная независимость. Можно говорить про попарную
[01:35:05.140 --> 01:35:09.220]  независимость случайных величин, просто когда каждая пара в совокупности является независимой.
[01:35:09.220 --> 01:35:15.280]  И из попарной независимости, как обычно, не следует простая независимость, независимость
[01:35:15.280 --> 01:35:20.260]  в совокупности, если хотите. Можно говорить про независимость целой произвольной системы
[01:35:20.260 --> 01:35:30.440]  случайных величин, то есть можно рассмотреть там какой-нибудь набор, индексированный индексом
[01:35:30.440 --> 01:35:34.780]  alpha, может быть любой мощности, он не обязан быть счетным, он может быть больше, тогда говорят,
[01:35:34.780 --> 01:35:45.100]  что случайная величина, которая в нем находится независимая, если независим любой конечный
[01:35:45.100 --> 01:35:58.060]  поднабор, то есть если для любого n и для любых alpha 1, alpha n различных,
[01:35:58.060 --> 01:36:05.380]  различных, кси alpha 1 и так далее, кси alpha n независима.
[01:36:05.380 --> 01:36:15.860]  можно вопрос? да. а что это означает? вот в третьей строке сверху вероятность того,
[01:36:15.860 --> 01:36:27.540]  что кси принадлежит b1, запятая это принадлежит b2. а это типа расписывается через элементарные
[01:36:27.540 --> 01:36:36.580]  сходы что ли? вы про эту строчку, да я правильно понял? да. ну смотрите, вот я выше говорил,
[01:36:36.580 --> 01:36:44.420]  что такое px, помните? вот я сказал, что давайте, когда у нас есть некоторое событие,
[01:36:44.420 --> 01:36:48.340]  ну в любом случае у нас вероятность задана изначально на множестве элементарных сходов,
[01:36:48.340 --> 01:36:53.220]  именно там она и существует. когда мы говорим про букву именно p, да, у него мог появиться индекс,
[01:36:53.220 --> 01:36:58.340]  это вероятность, которая уже перенеслась в другие множества, вот. когда мы именно пишем букву
[01:36:58.340 --> 01:37:05.060]  p, то мы имеем в виду событие, которое лежит в f. вот это, это просто сокращение вот такой записи,
[01:37:05.060 --> 01:37:11.820]  то есть событие, это множество омега, которые в некотором условии подчиняются, да, в данном
[01:37:11.820 --> 01:37:17.900]  случае множество таких омега, что их 100 мега принадлежит b. соответственно, если я пишу вот так,
[01:37:17.900 --> 01:37:22.700]  да, я могу там через запятую тоже перечислять какие-то условия, то это означает все то же самое,
[01:37:22.700 --> 01:37:30.020]  это просто множество тех омега, что все от омега принадлежит b1, и одновременно это от омега принадлежит b2.
[01:37:30.020 --> 01:37:37.100]  понятно, спасибо. так, еще какие-нибудь вопросы?
[01:37:37.100 --> 01:37:45.420]  можно в определении говорить просто что? не для всех баррелевских, а только для порождающего?
[01:37:45.420 --> 01:37:55.660]  да, спасибо за вопрос, сейчас я к нему отвечу. нет, нельзя, но можно для некоторых систем порождающих множеств,
[01:37:55.660 --> 01:38:05.740]  и для этого можно использовать критерии независимости, которые мы еще с вами сформулируем.
[01:38:05.740 --> 01:38:15.660]  этот критерий, его можно формулировать для случайных векторов и для случайных величин,
[01:38:15.660 --> 01:38:25.460]  все то же самое. доказывать давайте точно для случайных величин, чтобы не громоздить много
[01:38:25.460 --> 01:38:31.340]  буков, а формулировать, ну сформулировать давайте для случайных векторов, почему нет?
[01:38:31.340 --> 01:38:42.940]  пусть у нас есть случайные векторы x1, тогда xn, тогда они являются независимыми,
[01:38:42.940 --> 01:38:54.380]  тогда и только тогда, когда функция распределения случайного вектора составленного из этих
[01:38:54.380 --> 01:39:04.020]  случайных подвекторов. ну вот если бы это были случайные величины, то я бы сказал, что функция
[01:39:04.020 --> 01:39:09.340]  случайного вектора составленного из этих случайных величин просто равна произведению функции
[01:39:09.340 --> 01:39:17.380]  распределения. значит для случайных векторов это в принципе все равно то же самое, только вот
[01:39:17.380 --> 01:39:25.820]  эти x здесь они имеют разметность, то есть x1 принадлежит rk1, и тогда xn принадлежит rkn.
[01:39:25.820 --> 01:39:30.500]  вот никакой проблемы нет, когда я пишу вот так, я просто имею ввиду, что я записал все эти векторы
[01:39:30.500 --> 01:39:34.540]  просто подверг. то есть это вот один длинный вектор, который составлен из-под векторов x1,
[01:39:34.540 --> 01:39:39.660]  то ли xn, и то же самое здесь, вот это вот длинный случайный вектор, который составлен из-под
[01:39:39.660 --> 01:39:50.100]  векторов x1, то ли xn. вы его в индексе просто записали, да? кого? вот этот вектор? а где мне
[01:39:50.100 --> 01:39:55.580]  его еще писать? только в индексе. это функция распределения случайного вектора. да, я напомню,
[01:39:55.580 --> 01:40:01.580]  что у нас случайный вектор порождает распределение вероятностей, которую мы обозначали по x,
[01:40:01.580 --> 01:40:06.460]  по x, и у него есть функция распределения. то есть это есть на самом деле не что иное,
[01:40:06.460 --> 01:40:12.140]  я поясню на всякий случай. да, это есть не что иное, как просто вероятность того,
[01:40:12.140 --> 01:40:20.140]  что x1 меньше значим x1, и тогда xn меньше значим xn. вот, ну а это соответственно произведение
[01:40:20.140 --> 01:40:29.740]  вероятности того, что x1 меньше значим x1, и так далее. xn меньше значим xn. вот, то есть на самом деле
[01:40:29.740 --> 01:40:34.300]  то, что здесь написано, это как раз то, о чем вы спросили, что вместо всех бороться, можно
[01:40:34.300 --> 01:40:41.740]  достаточно рассмотреть некоторую порождающую систему, но не а во какую. вот подходят лучи,
[01:40:41.740 --> 01:40:49.460]  которые в определении функции распределения. вот, ну давайте, чтобы просто не городить, не думать о
[01:40:49.460 --> 01:40:54.340]  том, что у нас на самом деле эти x это тоже векторы, давайте будем, когда доказывать, будем думать о
[01:40:54.340 --> 01:40:58.820]  том, что это случайные величины. хотя доказать никак не зависит от случайных величин или случайных векторов,
[01:40:59.020 --> 01:41:07.260]  чтобы было проще воспринимать. значит, смотрите, идея доказательства это так называемый принцип
[01:41:07.260 --> 01:41:16.740]  подходящих множеств. это так называемый принцип подходящих множеств. значит, то, что нам нужно
[01:41:16.740 --> 01:41:28.500]  доказать, это что... ну что нужно доказать? нужно доказать вот это. то есть у нас вот такое
[01:41:28.500 --> 01:41:35.100]  равенство есть для лучей, а нам нужно доказать для всех баррельских множеств. и вот давайте мы скажем,
[01:41:35.100 --> 01:41:39.780]  что все баррельские множества, которые этому равенству удовлетворяют, они являются подходящими,
[01:41:39.780 --> 01:41:50.460]  вот рассмотрим систему всех подходящих множеств, которые предподстановкивают равенство, дают
[01:41:50.460 --> 01:41:59.060]  верное равенство, и докажем, что оно просто совпадает с баррельской сигмалкой. то есть идея в том,
[01:41:59.060 --> 01:42:03.100]  что возьмем всех систем множеств, которые нам подходят, и докажем, что они являются сигмалкой.
[01:42:03.100 --> 01:42:13.420]  вот как это аккуратно сделать? значит, во-первых, будем доказывать наше утверждение по индукции,
[01:42:13.420 --> 01:42:20.540]  то есть вот это равенство будем доказывать по индукции не по N, а по количеству баррельских
[01:42:20.540 --> 01:42:27.020]  множеств здесь внутри. мы часть из вот этих условий оставим в виде лучей, а часть в виде
[01:42:27.020 --> 01:42:35.700]  произвольных баррельских множеств. значит, давайте докажем по индукции,
[01:42:35.700 --> 01:42:57.100]  что для любого k от 1 до n, для любых b1 это далее bk баррельских,
[01:42:57.100 --> 01:43:13.020]  и для любых xk плюс 1 xn действительных верно, что вероятность того, что кси1 принадлежит b1,
[01:43:13.020 --> 01:43:22.460]  и так далее, ксиk принадлежит bk, ксиk плюс 1 меньше, чем xk плюс 1, и так далее,
[01:43:22.460 --> 01:43:29.620]  ксиn меньше, чем xm равно произведению этих вероятностей, вероятность того, что кси1 принадлежит b1,
[01:43:29.620 --> 01:43:40.620]  и так далее, вероятность того, что ксиk принадлежит bk, вероятность того, что ксиk плюс 1 меньше, чем xk плюс 1,
[01:43:40.620 --> 01:43:46.740]  и так далее, вероятность того, что ксиn меньше, чем xm.
[01:43:52.700 --> 01:44:06.780]  По индукции пока это будем доказывать. Прикар равно единице, надо доказать, что вероятность того,
[01:44:06.780 --> 01:44:17.300]  что кси1 принадлежит b1, кси2 меньше, чем x2, это далее ксиn меньше, чем xm, рана произведению всех этих вероятностей.
[01:44:23.300 --> 01:44:35.340]  Ну и вот давайте рассмотрим все баррельские множества, которые нам подходят. Допустим, скажем, m – это множество таких b.
[01:44:35.340 --> 01:44:42.540]  Простите, а не проще будет начать с кар в нулю тривиальной базы, чтобы не повторять просто одни и те же рассуждения в шаге?
[01:44:46.540 --> 01:44:50.540]  Наверное, вы правы, да. Наверное, вы правы.
[01:44:52.540 --> 01:45:04.540]  Ну хорошо, наверное, так получится. Давайте считать, что база – это кар в нулю, и для нее это равенство является тривиальным,
[01:45:04.540 --> 01:45:10.540]  потому что это просто то, что дано. Да, для кара в нулю получается просто, что все эти множества – это лучи.
[01:45:22.540 --> 01:45:27.540]  Так, теперь предположим, что доказано для k.
[01:45:38.540 --> 01:45:42.540]  Для k. И хотим доказать для k плюс 1.
[01:45:42.620 --> 01:45:56.620]  Вот. Ну тогда, значит, тогда что мы хотим? Мы хотим, чтобы были равны такие вероятности, ну, где вместо k, k плюс 1, на самом деле, написано.
[01:45:56.620 --> 01:46:07.620]  Давайте мы, не буду переписывать это равенство, мы хотим, чтобы были равны такие вероятности, ну, где вместо k, k плюс 1, на самом деле, написано.
[01:46:07.700 --> 01:46:13.700]  Давайте мы, не буду переписывать это равенство, давайте я сразу поясню, что мы делаем.
[01:46:13.700 --> 01:46:26.700]  Мы рассматриваем систему множеств m, баррелявских, таких, что, значит, давайте еще зафиксируем прямо все, кроме…
[01:46:26.700 --> 01:46:32.700]  Вот на k плюс 1 позицию у меня будет стоять это баррелявское множество b, а все остальные баррелявские множества и числа мы зафиксируем.
[01:46:32.780 --> 01:46:46.780]  То есть фиксируем баррелявские множества b1, bk и фиксируем числа xk плюс 2, это до lxm.
[01:46:46.780 --> 01:46:54.780]  А вот на k плюс 1 месте у меня будет стоять вот это множество, множество b, которое здесь в b.
[01:46:54.860 --> 01:47:02.860]  Значит, m это множество всех таких баррелявских множеств, что вероятность того, что x1 принадлежит b1,
[01:47:02.860 --> 01:47:19.860]  и т.д. xk принадлежит bk, xk плюс 1 принадлежит b, xk плюс 2 меньше, чем x2, xk плюс 2, и т.д. xn меньше, чем xm, ну, равна просто произведению вероятностей.
[01:47:24.860 --> 01:47:48.860]  Вот, смотрите, значит, что мы знаем про m? Мы знаем, что как минимум все лучи принадлежат m.
[01:47:48.940 --> 01:47:56.940]  То есть множество вида от минус бесконечности до x, свящая x, в m, конечно, лежат, ну, это дано.
[01:47:56.940 --> 01:48:04.940]  Нам дано по предположению индукции, что мы доказали наше условие для k.
[01:48:04.940 --> 01:48:08.940]  Наше условие для k это как раз, если вот это баррелявское множество, это луч.
[01:48:08.940 --> 01:48:13.940]  Это как раз получается условие, которое мы якобы доказали для k.
[01:48:14.020 --> 01:48:18.020]  Поэтому все такие множества лежат m.
[01:48:24.020 --> 01:48:30.020]  Поэтому мы знаем, что наименьшее сигма алгебра, которое содержит m,
[01:48:36.020 --> 01:48:39.020]  она совпадает с баррелявской сигма алгеброй.
[01:48:44.020 --> 01:48:50.020]  Ну, так как m это подножство баррелявской сигма алгебры, и в нем належат все лучи,
[01:48:50.020 --> 01:48:58.020]  но как минимум, значит, наименьшее сигма алгебра, которое содержит m, является баррелявской сигмалгеброй.
[01:48:58.020 --> 01:49:04.020]  Поэтому если мы докажем, что m это сигма алгебра,
[01:49:08.020 --> 01:49:12.020]  что она сама сигма алгебра, сама по себе, то это будет сразу следовательно,
[01:49:12.100 --> 01:49:14.100]  что совпадает с баррелявской сигмалгеброй.
[01:49:17.100 --> 01:49:20.100]  Вот, в принципе, можно доказывать, что это сигма алгебра, но, на мой взгляд,
[01:49:20.100 --> 01:49:24.100]  чуть проще доказывать, что это лямбда-система.
[01:49:24.100 --> 01:49:29.100]  Давайте я для широты кругозора, поэтому расскажу, что такое лямбда-система,
[01:49:29.100 --> 01:49:31.100]  как это можно сиспользовать.
[01:49:36.100 --> 01:49:37.100]  Что такое лямбда-система?
[01:49:37.180 --> 01:49:39.180]  concerts ? У нас есть некоторая система множеств сигмы.
[01:49:42.180 --> 01:49:44.180]  Мне понадобится понятие p-системы.
[01:49:46.180 --> 01:49:47.180]  Во-вторых, лямбда-система.
[01:49:47.180 --> 01:49:51.180]  Значит, система множества сигмы называется p-системой banksigmalgibra.
[01:49:51.180 --> 01:49:53.580]  audience. sichmalgibreinnen.
[01:49:53.580 --> 01:49:57.580]  Это система множества, которая замкнута относительно некоторых операций.
[01:49:57.580 --> 01:50:02.100]  Значит, система множества сигмы называется p-система, если она просто замкнута относительно пересечение.
[01:50:02.100 --> 01:50:11.620]  пересечения. Если принадлежность множеством множество ab sigma вылечет принадлежность
[01:50:11.620 --> 01:50:20.500]  сигме их пересечения, тогда система называется по системе. Значит, она называется лямбда системой,
[01:50:20.500 --> 01:50:35.860]  лямбда системой, если выполнено несколько свойств. Во-первых, всё множество e. Вот у нас есть
[01:50:35.860 --> 01:50:45.580]  единица, это некоторое множество e. Одно должно принадлежать этой лямбда системе. Во-вторых,
[01:50:45.580 --> 01:50:59.420]  если два множества содержатся в e и они вложены, то их разность тоже содержится в sigma.
[01:50:59.420 --> 01:51:10.860]  Ну, наконец, приход к пределу. Значит, если есть вложенная последовательность множества 1 на 2,
[01:51:10.860 --> 01:51:17.900]  каждый из которых принадлежит sigma, то их объединение тоже принадлежит sigma.
[01:51:17.900 --> 01:51:30.900]  Ну и такое утверждение, техническое, оставим его без доказательства, что если есть какая-то
[01:51:30.900 --> 01:51:44.660]  P-система, то наименьшее sigma-алгебра, которое это P-система содержит, совпадает с наименьшей
[01:51:44.660 --> 01:51:54.940]  лямбдой системы, которую эта P-система содержит. Вот. В связи с этим, так как мы знаем, что наша
[01:51:54.940 --> 01:52:03.780]  система M содержит P-систему, множество всех лучей от минус бесконечности до x – это P-система.
[01:52:03.780 --> 01:52:12.100]  Можете объяснить, в чем различие лямбдосистемы и просто sigma-алгебра?
[01:52:12.100 --> 01:52:17.940]  Ну, вообще говоря, лямбдосистема совсем не обязана быть замкнута относительно
[01:52:17.940 --> 01:52:20.660]  пересечения событий или объединения событий.
[01:52:20.660 --> 01:52:28.860]  Но наш замкнут относительно объединения и пересечения – это как разность?
[01:52:28.860 --> 01:52:33.620]  Где вы видите назад? Назад относительно объединения вложенных множеств.
[01:52:33.620 --> 01:52:35.420]  Понятно.
[01:52:35.420 --> 01:52:38.060]  Это вложенные множества, да, то есть можно перейти к пределам.
[01:52:38.060 --> 01:52:42.900]  Можно еще вопрос?
[01:52:42.900 --> 01:52:43.460]  Да.
[01:52:43.980 --> 01:52:51.700]  Когда M вводили, вот B без индекса, мы по нему строим, и оно – это то, куда вложено x от k плюс 1, правильно?
[01:52:51.700 --> 01:53:07.100]  Когда вводили M, B без индекса, да, они играют роль на самом деле множества B k плюс 1. В этом вопрос?
[01:53:07.100 --> 01:53:11.900]  Да, типа одно и то же B. И по нему мы строим.
[01:53:12.340 --> 01:53:18.940]  Да. Мы думаем, у нас все фиксировано, мы думаем исключительно про k плюс первое множество.
[01:53:18.940 --> 01:53:23.500]  Поэтому, так как у нас вот все эти позиции фиксированы, первые k из k плюс второй по n,
[01:53:23.500 --> 01:53:28.460]  то я в это множество индекс не стал ставить, мы просто зафиксировали.
[01:53:28.460 --> 01:53:34.060]  И, значит, для вот этих всех вещей фиксированных мы меняем множество B.
[01:53:34.060 --> 01:53:36.340]  Так, хорошо, спасибо.
[01:53:36.780 --> 01:53:45.980]  Да, значит, так как множество всех лучей – это и система, и она является под множеством V,
[01:53:45.980 --> 01:53:59.660]  то если мы докажем, что M – это лямбда-система, то она и сигма логибра.
[01:53:59.660 --> 01:54:08.540]  Да, значит, еще раз мы знаем, что наименьшая лямбда-система, которая содержит P-систему,
[01:54:08.540 --> 01:54:11.580]  совпадает с наименьшей сигма логиброй, которая содержит эту P-систему.
[01:54:11.580 --> 01:54:18.380]  Значит, у нас M P-систему содержит, поэтому если M – это лямбда-система сама по себе,
[01:54:18.380 --> 01:54:26.940]  то она и сигма логибра почему? Потому что она, конечно, наименьшая,
[01:54:27.740 --> 01:54:30.740]  она не может быть никакой другой.
[01:54:30.740 --> 01:54:35.860]  Мы знаем, что наименьшее сигма логиброй, которая содержит наша P-система – это бареллевская
[01:54:35.860 --> 01:54:37.060]  сигма логибра.
[01:54:37.060 --> 01:54:42.020]  Пр想 파, наша P-система содержится в самой маленькой возможной сигма логибройlynn tego,
[01:54:42.020 --> 01:54:43.380]  которая содержится – это в бареллевской сигмала.
[01:54:43.380 --> 01:54:48.380]  И M там же находится, все множества, которые лежат от V, они бареллевские.
[01:54:48.380 --> 01:54:54.940]  Поэтому, если же M – это лямбда-система, она не может быть меньшая, чем бареллевское сигма логибр.
[01:54:54.940 --> 01:55:00.140]  тогда именно это баррельская сигма-алгебра, с которой она просто совпадает. Поэтому всё,
[01:55:00.140 --> 01:55:04.780]  что нам осталось доказать, это то, что m – это лямбисистема. То есть, короче, проверить вот эти
[01:55:04.780 --> 01:55:16.620]  три свойства. Давайте это сделаем. Первое. Значит, e принадлежит сигма, e – это в данном случае r.
[01:55:16.620 --> 01:55:27.860]  Отверждается, что r принадлежит m. Давайте это проверим. Возьмём, но подставляем вместо b
[01:55:27.860 --> 01:55:33.620]  вот это r и проверяем равенство. Значит, нам нужна вероятность того, что кси1 принадлежит b1,
[01:55:33.620 --> 01:55:44.660]  и так далее, ксиK принадлежит bK, ксиK плюс 1 принадлежит r, ксиK плюс 2 меньше 0, чем xK плюс 2,
[01:55:44.660 --> 01:55:50.300]  и так далее, ксен меньше 0, чем xN. Нам нужно, чтобы она распалась по зрению вероятности.
[01:55:50.300 --> 01:55:56.460]  Как это сделать? Давайте заметим вот что. Давайте заметим, что потеремия непрерывности вероятности – это
[01:55:56.460 --> 01:56:03.300]  есть не что иное, как предел при x, стремящемся к плюсбесконечности, вероятности того, что кси1
[01:56:03.300 --> 01:56:13.580]  принадлежит b1, и так далее, ксиK принадлежит bK, ксиK плюс 1 меньше 0, чем x, ксиK плюс 2
[01:56:13.580 --> 01:56:31.220]  меньше 0, чем xK плюс 2, ксен меньше 0, чем xN. Да, понятно, что если мы стремляем к плюсбесконечности, то вот
[01:56:31.220 --> 01:56:35.300]  эти вот события, они становятся вложены, и поэтому можем перейти к пределу и получить в точности
[01:56:35.300 --> 01:56:39.980]  вероятность объединения всех этих событий, то есть вероятность того, что ксиK плюс 1 принадлежит r.
[01:56:39.980 --> 01:56:52.260]  Вот, в силу независимости, то есть я имею в виду, что в силу предположений индукции,
[01:56:52.260 --> 01:56:58.460]  по предположению индукции мы знаем, что для K наше утверждение доказано, то есть вот мы умеем
[01:56:58.460 --> 01:57:04.420]  писать такое ранение, это в точности оно. У нас до K позиции стоит принадлежность к множеству,
[01:57:04.420 --> 01:57:18.980]  а начиная с К плюс первой лучу, и значит поэтому по предположению индукции мы вылучаем, что это
[01:57:18.980 --> 01:57:26.220]  просто предел при х, стремляющейся к плюсбесконечности произведения вероятностей. Вероятность того,
[01:57:26.220 --> 01:57:36.940]  что ксиK принадлежит b1, ксиK принадлежит bk, ксиK плюс 1 меньше, чем x, ксиK плюс 2 меньше,
[01:57:36.940 --> 01:57:46.420]  чем xk плюс 2, и так далее, ксиK меньше, чем xn. Ну и вот, значит, предел у нас при х,
[01:57:46.420 --> 01:57:50.700]  стремляющейся к бесконечности, только один из множеств, этот в эксазовист, вот этот. Опять,
[01:57:50.700 --> 01:57:54.860]  переходя к пределу, мы получаем, что это вероятность стремляющейся к единице, да, но это есть
[01:57:54.860 --> 01:57:59.180]  не что иное, как предел функции распределения, на самом деле, это х, и он, конечно, равен единице,
[01:57:59.180 --> 01:58:05.900]  и мы получаем в результате вероятность того, что кси1 принадлежит b1. Вместо единицы напишем
[01:58:05.900 --> 01:58:12.980]  для удобства вероятность того, что ксиK плюс 1 принадлежит r. Да, мы же явно хотим показать,
[01:58:12.980 --> 01:58:21.500]  что мы получили произведение вероятностей, но вот мы его и получили. Значит, действительно,
[01:58:21.500 --> 01:58:30.940]  первое свойство из определения лямбли системы выполнено. Второе, значит, если a и b вложены,
[01:58:30.940 --> 01:58:42.540]  то b-a должно принадлежать sigma. Значит, итак, пусть a и b вложены множество, и они принадлежат m.
[01:58:42.540 --> 01:58:52.860]  Мы, значит, берем разность этих множеств и хотим показать, что эта разность будет
[01:58:52.860 --> 01:58:58.940]  принадлежать m. Ну, значит, то есть мы берем вероятность того, что кси1 принадлежит b1,
[01:58:58.940 --> 01:59:09.580]  и далее ксиK принадлежит bK. КсиK плюс 1 принадлежит разности b и a. КсиK плюс 2 меньше,
[01:59:09.580 --> 01:59:19.980]  чем xK плюс 2, далее ксиN меньше, чем xN. Вот, но теперь, так как вероятность адитивна,
[01:59:19.980 --> 01:59:24.180]  мы тут имеем на самом деле разность двух множеств. То есть мы вот на это все,
[01:59:24.180 --> 01:59:30.180]  можно смотреть как на разность двух множеств, где первые там k и последние n-k-1 координаты
[01:59:30.180 --> 01:59:35.420]  являются фиксированными, а здесь в одном случае будет b, в другом случае будет a. Так,
[01:59:35.420 --> 01:59:40.500]  эти множества вложены, и вероятность функции адитивная, то мы получаем разность вероятностей.
[01:59:40.500 --> 01:59:49.860]  Вероятность того, что кси1 принадлежит b1, и далее ксиK принадлежит bK. КсиK плюс 1 принадлежит b.
[01:59:49.860 --> 01:59:57.260]  КсиK плюс 2 меньше, чем xK плюс 2, и так далее ксиN меньше, чем xN.
[01:59:57.260 --> 02:00:03.380]  Минус, точно такая же вероятность, но только вместо b надо написать a.
[02:00:03.380 --> 02:00:24.380]  Вот, только здесь нужно b исправить на a. И, собственно, все, потому что по предположению в нашем пункте мы
[02:00:24.380 --> 02:00:30.180]  считаем, что множество a и b принадлежат к m, это означает не что иное, как то, что обе вероятности
[02:00:30.180 --> 02:00:47.260]  распадутся в произведение. Распадутся в произведение, что мы и сделаем. И точно так же со
[02:00:47.260 --> 02:01:00.700]  второй вероятностью. Минус. Точно такая же вторая вероятность, только вместо b будет стоять a.
[02:01:00.700 --> 02:01:12.700]  Здесь будет стоять a. Вот, ну и последнее, что осталось сделать, это увидеть, что в обоих произведениях
[02:01:12.700 --> 02:01:20.540]  все множества одинаковы, кроме вот этих. Их, соответственно, можно вынести за скобки,
[02:01:20.540 --> 02:01:24.860]  получим разность двух вероятностей. Вот это минус вот это. И так как b содержится в a,
[02:01:24.860 --> 02:01:32.180]  мы получим вероятность разности множества. То есть окончательно получаем то, что хотели.
[02:01:32.180 --> 02:01:46.220]  То, что хотели. Вот, поэтому пункт два тоже доказан. Следовательно, b-a принадлежит m.
[02:01:46.220 --> 02:01:56.860]  Пункт три. Пункт три. Значит, здесь нам нужно перейти к пределу. У нас здесь вложено множество.
[02:01:56.860 --> 02:02:09.580]  Ну, понятно, что все то же самое. Значит, пусть есть вот эти вот 1, 2 и так далее. И они все
[02:02:09.580 --> 02:02:20.260]  принадлежат m. Значит, и мы хотим... Ну и давайте за a обозначим их объединение. Если объединение
[02:02:20.260 --> 02:02:26.340]  а, надо доказать, что он тоже принадлежит m. Ну опять, значит, берем вероятность того,
[02:02:26.340 --> 02:02:38.220]  что x1 принадлежит b1 и так далее. xk принадлежит bk. xk плюс 1 принадлежит a. xk плюс 2 меньше
[02:02:38.220 --> 02:02:55.660]  на xk плюс 2. Далее xn меньше на xn. Вот, ну напоминаю, что множество вложенное. Поэтому можно считать,
[02:02:55.660 --> 02:03:01.140]  что вот эти множество, вот эти события целиком, они являются множество, они являются вложенными.
[02:03:01.140 --> 02:03:06.980]  То есть они отличаются только вот этим куском, вот этим условием, а это условие является вложенным.
[02:03:06.980 --> 02:03:13.980]  Ну, значит, все события целиком являются вложенными. Мы можем перейти к пределу при
[02:03:13.980 --> 02:03:20.980]  стремящемся... Так, только не n давайте, а то у нас m до количества координат. При m стремящемся к
[02:03:20.980 --> 02:03:32.180]  бесконечности вероятности того, что x1 принадлежит b1 и так далее. xk принадлежит bk. xk плюс 1 принадлежит
[02:03:32.180 --> 02:03:42.420]  am. xk плюс 2 меньше на xk плюс 2 и так далее. xn принадлежит xm. А так как по нашему предположению
[02:03:42.420 --> 02:03:51.260]  все множество am являются элементами m, из этого означает, что вероятность распадается к произведениям.
[02:03:51.260 --> 02:04:01.660]  Мы получаем произведение этих всех вероятностей того, что x1 принадлежит b1, xk принадлежит bk,
[02:04:01.660 --> 02:04:14.140]  xk плюс 1 принадлежит am, xk плюс 2 меньше на xk плюс 2 и так далее. xn меньше на xm.
[02:04:14.140 --> 02:04:28.540]  Вот, и вот эта вероятность, она в пределе, конечно, 1. Она в пределе, конечно, 1, потому что мы снова
[02:04:28.540 --> 02:04:34.140]  переходим к пределу, мы засовываем внутрь вероятности за счет того, что вот эти множества am вложены,
[02:04:34.140 --> 02:04:40.940]  ну и соответственно, это означает, что эти события тоже вложены. Вот, и в пределе получаем вероятность
[02:04:40.940 --> 02:04:56.460]  принадлежности множества a. Вероятность того, что xk плюс 1 принадлежит множеству a на все остальные
[02:04:56.460 --> 02:05:07.260]  вероятности. Ну вот, собственно, и всё. Из этого сходу следует, что a принадлежит m, что и требовалось.
[02:05:07.260 --> 02:05:16.740]  Значит, действительно, так как мы доказали, что все три свойства лямблесистемы выполнены, то наша m
[02:05:16.740 --> 02:05:25.740]  это лямблесистема, а значит, она является сигмалгебой и совпадает со всей барреллесской сигмалгебой.
[02:05:25.740 --> 02:05:35.780]  И это завершает, конечно, доказательство нашего утверждения, да, потому что я напомню, что m это
[02:05:35.780 --> 02:05:40.660]  система подходящих множеств, то есть всех тех множеств, которые дают, чтобы вероятность пересечения
[02:05:40.660 --> 02:05:45.540]  на произведение вероятностей, но, конечно, это вообще все множества нам подходят, тем самым по индукции мы
[02:05:45.540 --> 02:05:50.540]  доказали наше утверждение, и в частности, при k равно n, мы получаем требуемое.
[02:05:50.540 --> 02:05:55.540]  Итак, значит, утверждение по индукции доказано.
[02:05:55.540 --> 02:06:19.540]  По индукции доказано, в частности, при k равно n, мы получаем требуемое, то есть вероятность того, что
[02:06:19.540 --> 02:06:27.540]  кси1 принадлежит b1, и так далее, ксен принадлежит bn, равна произведению вероятностей.
[02:06:37.540 --> 02:06:38.540]  Есть какие-то вопросы?
[02:06:38.540 --> 02:06:54.540]  Так, вопросов нет. Прекрасно. Ну, что тогда? Тогда давайте поговорим еще немножечко про какие-то простейшие
[02:06:54.540 --> 02:07:02.540]  свойства, важные с точки зрения независимости, потом я скажу о том, как сворачивать распределение,
[02:07:02.540 --> 02:07:10.540]  то есть как находить, в частности, распределение суммы независимо случайных величин, чего не посчитаем мы на этом закончим.
[02:07:10.540 --> 02:07:21.540]  Так. Ну, какие-то простейшие умозаключения, которые мы с вами в курсе будем использовать.
[02:07:21.540 --> 02:07:24.540]  Давайте их будем называть утверждениями.
[02:07:24.540 --> 02:07:34.540]  Во-первых, такое утверждение, что если у вас есть случайные векторы, которые являются независимыми,
[02:07:34.540 --> 02:07:42.540]  вот пусть у вас есть независимый блок, если у вас есть независимые случайные величины, и вы из них
[02:07:42.540 --> 02:07:50.540]  нас составляете случайные векторы. Понятно, что вы получите независимые случайные векторы.
[02:07:50.540 --> 02:08:02.540]  Значит, если есть набор независимых случайных величин,
[02:08:02.540 --> 02:08:20.540]  если вы из них делаете векторы, да, там как мы их называем,
[02:08:20.540 --> 02:08:30.540]  кси к1, потом кси к1, плюс 1 и так далее, кси к2 и так далее.
[02:08:30.540 --> 02:08:34.540]  Ну, вы заставляете из них векторов, но при этом эти векторы не будут пересекаться по компонентам.
[02:08:34.540 --> 02:08:39.540]  Понятное дело, то они снова будут независимыми.
[02:08:39.540 --> 02:08:44.540]  То есть, если у вас есть куча компонентов, вы из них насовираете случайные векторы,
[02:08:44.540 --> 02:08:48.540]  так чтобы они не пересекались по компонентам, вы получите независимые случайные векторы.
[02:08:48.540 --> 02:08:54.540]  Более-менее очевидно, но давайте, наверное, докажем.
[02:08:54.540 --> 02:09:00.540]  Ну, например, следует из критерий, которые я только что написал.
[02:09:00.540 --> 02:09:11.540]  Если вы возьмете просто функцию распределения вот этого вашего вектора, сложно составленного,
[02:09:11.540 --> 02:09:21.540]  то есть, возьмете вектор, который состоит из кусков размера k1, размера k2 минус k1 и так далее,
[02:09:21.540 --> 02:09:34.540]  в точке x1, x2 и так далее, то что это такое на самом деле, что это за функция?
[02:09:34.540 --> 02:09:37.540]  Ну, у вас вектор составлен из-под векторов.
[02:09:37.540 --> 02:09:43.540]  Если вы берете все эти вектора вместе, получаете на самом деле просто функцию изначального вашего случайного вектора.
[02:09:43.540 --> 02:09:49.540]  То есть, вот этот вектор, который в индексе написан, это просто изначальный случайный вектор.
[02:09:49.540 --> 02:09:57.540]  А вот эти x это тоже векторы, длина которых просто соответствует соответствующей длине самого случайного вектора.
[02:09:57.540 --> 02:10:01.540]  То есть, в частности, у этого вектора длина k1.
[02:10:01.540 --> 02:10:04.540]  Но понятно, что они состоят из компонентов.
[02:10:04.540 --> 02:10:08.540]  Поэтому, если вы все эти векторы выписали, вы получили один длинный вектор.
[02:10:08.540 --> 02:10:14.540]  Можно его обозначить 1,0tm. У него будет, конечно, ровно столько же координат, сколько у вас случайных величин.
[02:10:14.540 --> 02:10:25.540]  И в силу того, что ваша случайная величина независимая, вы получите, что это просто произведение функции распределения.
[02:10:25.540 --> 02:10:32.540]  А дальше вы эти множители просто сгруппируете теми же самыми кусками, которые у вас были.
[02:10:32.540 --> 02:10:36.540]  То есть, кусок размера k1, потом кусок размера k2-k1.
[02:10:36.540 --> 02:10:41.540]  И сделайте здесь соответствующие группы из множителей.
[02:10:41.540 --> 02:10:51.540]  И дальше вы увидите, что в силу независимости ваших случайных величин каждое такое произведение это в точности функция распределения соответствующего вектора.
[02:10:51.540 --> 02:11:05.540]  То есть, внутри этих групп, вы эти произведения свернете в функции распределения, вы получите как раз исходные вот эти вот векторы размера k1, k2-k1 и так далее.
[02:11:05.540 --> 02:11:15.540]  То есть, вы получите все вот эти вот векторы и им соответствующие функции распределения.
[02:11:15.540 --> 02:11:20.540]  В общем-то, что и требуется.
[02:11:20.540 --> 02:11:27.540]  Так, есть ли вопросы?
[02:11:27.540 --> 02:11:29.540]  Еще одно утверждение.
[02:11:29.540 --> 02:11:35.540]  В следующем перейдем к сверткам.
[02:11:35.540 --> 02:11:49.540]  Значит, так, пусть у вас есть независимые случайные векторы.
[02:11:49.540 --> 02:11:59.540]  k1, k2, независимые случайные векторы.
[02:11:59.540 --> 02:12:03.540]  И есть соответствующих размерностей.
[02:12:03.540 --> 02:12:09.540]  Пусть их будет n штук.
[02:12:09.540 --> 02:12:13.540]  И соответствующим их размерностям параллельский функции.
[02:12:13.540 --> 02:12:23.540]  То есть, если у it и случайной величины размерность, скажем, k it, то функция будет действовать из r в степени k it.
[02:12:23.540 --> 02:12:27.540]  То есть, есть вот f1, который действует из r в степени k1.
[02:12:27.540 --> 02:12:32.540]  Размерность образа не имеет значения. Какое-то m1 и так далее.
[02:12:32.540 --> 02:12:37.540]  fnt из rkn в rmn.
[02:12:37.540 --> 02:12:41.540]  И все они параллельские.
[02:12:41.540 --> 02:12:46.540]  То есть, еще раз, размерность аргумента совпадает с размерностью соответствующего случайного вектора.
[02:12:46.540 --> 02:12:51.540]  То есть, у x1 размерность k1, у xn размерность kn.
[02:12:51.540 --> 02:12:54.540]  То есть, мы сейчас будем применять эти функции к случайным векторам.
[02:12:54.540 --> 02:13:08.540]  Значит, тогда f1 от x1 и так далее, fn от xn является независимым.
[02:13:08.540 --> 02:13:14.540]  Ну это, в общем-то, тоже очевидное упражнение. Давайте быстренько докажем.
[02:13:14.540 --> 02:13:24.540]  Так понятно, что это должно быть так, потому что независимость это, на самом деле, о том, как устроено совместное распределение.
[02:13:24.540 --> 02:13:34.540]  Если вы знаете, что они независимы от того, что там разные функции будете применять, они независимо останутся.
[02:13:34.540 --> 02:13:42.540]  Хорошо. Ну, любой параллельский может, наверное, взять правильных размерностей.
[02:13:42.540 --> 02:13:54.540]  То есть, первый будет из r степени m1 и так далее. nt будет из r степени mn.
[02:13:54.540 --> 02:14:08.540]  И берем вероятность того, что f1 от x1 принадлежит b1 и так далее, fn от xn принадлежит bn.
[02:14:08.540 --> 02:14:13.540]  И дальше берем полные прообразы, в смысле, вот этих параллельских функций.
[02:14:13.540 --> 02:14:25.540]  То есть, это будет x1 принадлежит f1 в минус 1 от b1 и так далее, xn принадлежит fn в минус 1 от bn.
[02:14:31.540 --> 02:14:42.540]  Далее, в силу независимости мы получим, что это есть произведение вероятностей того, что x1 принадлежит f1 в минус 1 от b1 и так далее.
[02:14:43.540 --> 02:14:50.540]  xn принадлежит fn в минус 1 от bn. Ну и теперь обратно применим эти функции и получим то, что нам нужно.
[02:14:50.540 --> 02:15:00.540]  Вероятность того, что f1 от x1 принадлежит b1 и так далее, fn от xn принадлежит bn.
[02:15:00.540 --> 02:15:06.540]  Да, то есть, это действительно независимость, что и требуется.
[02:15:07.540 --> 02:15:10.540]  Так, есть ли какие-то вопросы?
[02:15:24.540 --> 02:15:27.540]  Нет, хорошо, тогда, собственно, переходим к свертке.
[02:15:27.540 --> 02:15:36.540]  Итак, какая у нас задача? Ну вот, предположим, что у вас есть независимость случайной величины, мы хотим понять, какое распределение у их суммы.
[02:15:36.540 --> 02:15:39.540]  Да, ну или у разности, или у произведения, это все делается точно так же.
[02:15:39.540 --> 02:15:46.540]  И здесь ключевым инструментом является тремофубини. Вы знаете прекрасно, что такое тремофубини, но давайте я напомню.
[02:15:46.540 --> 02:15:52.540]  Свертка – это про распределение суммы. Мы именно на примеры распределения суммы будем решать эту задачу,
[02:15:52.540 --> 02:15:57.540]  но потом вы по аналогии сможете решать такие же задачи для любых альфинитических операций,
[02:15:57.540 --> 02:16:02.540]  то есть брать разность случайных причин произведения отношений, неважно.
[02:16:02.540 --> 02:16:06.540]  Так, напоминаю, что такое тремофубини.
[02:16:06.540 --> 02:16:15.540]  Ну, давайте в терминах наших вероятностных пространств, очень неважно, можно для любых мер то же самое делать,
[02:16:15.540 --> 02:16:20.540]  но будем ее применять только в таком случае.
[02:16:20.540 --> 02:16:29.540]  Значит, пусть у нас есть дикартовое произведение, то есть мы будем использовать это,
[02:16:29.540 --> 02:16:34.540]  и, соответственно, дикартовое произведение сигмалью, которая на этих двух омек задана,
[02:16:34.540 --> 02:16:39.540]  и дикартовое произведение мер.
[02:16:39.540 --> 02:16:48.540]  Значит, это есть дикартовое произведение двух вероятностных мер.
[02:16:48.540 --> 02:17:00.540]  Значит, это есть дикартовое произведение двух вероятностных пространств.
[02:17:00.540 --> 02:17:11.540]  Омега-1, f1 и p1, и омега-2, f2 и p2.
[02:17:23.540 --> 02:17:29.540]  Сейчас мы будем применять, ну да, мы будем применять для вероятностных вещей.
[02:17:29.540 --> 02:17:33.540]  Хорошо.
[02:17:33.540 --> 02:17:39.540]  Я напомню, что такое дикартовое произведение.
[02:17:39.540 --> 02:17:43.540]  Значит, дикартовое произведение множество мега-1 и мега-2 – это обычное дикартовое произведение.
[02:17:43.540 --> 02:17:47.540]  Дикартовое произведение сигмаль slice, это просто минимальная сигма-алгебра,
[02:17:47.540 --> 02:17:52.540]  которая содержит все дикартовые произведения множеств из этих сигмалгебр.
[02:17:52.540 --> 02:18:01.980]  сигма-алгебр, и декарта произведения мер мы уже тоже о нём говорили, то есть
[02:18:01.980 --> 02:18:13.540]  P1 крест P2 от A1 крест A2, это есть произведение вероятностей, а на всю сигма-алгебру оно
[02:18:13.540 --> 02:18:18.380]  продолжается единственным образом. Вот, значит, есть декарта произведения двух вероятностных
[02:18:18.380 --> 02:18:27.500]  пространств, и есть какая-то случайная величина, и предположим, что интеграл от неё конечен,
[02:18:27.500 --> 02:18:37.980]  значит, пусть интеграл по мега один креста мега два от модуля кси на dP1 крест P2, он конечен,
[02:18:37.980 --> 02:18:50.620]  да, где кси это какая-то случайная величина на нашем декартовом произведении. Вот, тогда
[02:18:50.620 --> 02:18:57.980]  можно переставлять местами, да, можно сначала там по мега один, по мега два интегрировать,
[02:18:57.980 --> 02:19:07.420]  либо наоборот, то есть вот этот вот интеграл от кси dP1 крест P2, это есть интеграл по
[02:19:07.420 --> 02:19:20.860]  мега один от интеграла по мега два кси dP2 dP1, либо наоборот, сначала по мега два, потом по мега один.
[02:19:20.860 --> 02:19:33.340]  Вот, значит, как это нам помогает? Ну, давайте возьмём теперь, собственно,
[02:19:33.340 --> 02:19:36.780]  к нашей задаче. Пусть у нас есть две независимых случайных величины.
[02:19:36.780 --> 02:19:57.820]  И спрашивается, каково распределение суммы? Каково распределение кси плюс это?
[02:19:57.820 --> 02:20:08.220]  Ну, давайте напишем функцию распределения. И вспомним, что это есть не что иное, как вероятность
[02:20:08.220 --> 02:20:24.620]  того, что эта сумма меньше, чем x. То есть, на самом деле, можно на это посмотреть ещё
[02:20:24.860 --> 02:20:34.220]  по иначе, как на распределение вектора, да, вы можете взять распределение вектора составным из кси это,
[02:20:34.220 --> 02:20:53.180]  на множестве таких точек уv, что у плюс v меньше, чем x. Да, вы просто в R2, вы берёте такую, вот у вас есть R2.
[02:20:53.180 --> 02:21:04.620]  Такая плоскость. Значит, вы берёте множество всех пар уv, таких, что они там суммейшены, чем x,
[02:21:04.620 --> 02:21:12.940]  да, то есть такая вот прямая. И вас интересует множество всех точек, которые находятся под этой прямой,
[02:21:12.940 --> 02:21:21.020]  и у вас задано распределение вероятностей, которые соответствуют вашему вектору. И на самом деле,
[02:21:21.980 --> 02:21:27.500]  вот смысл этого распления вероятностей, мера вот этой полуплоскости, это в точности, на самом деле,
[02:21:27.500 --> 02:21:37.900]  ваша изначальная функция распределения. Чему равна мера множества? Ну, она равна интегралу
[02:21:41.740 --> 02:21:45.260]  от индикатора этого множества, правда ведь?
[02:21:51.020 --> 02:21:57.660]  Да, то есть, если вы берёте индикаторную функцию, просто воинтегрируете и вы получаете просто в
[02:21:57.660 --> 02:22:06.780]  точности меру соответствующего множества. То есть, если я вот этот индикатор проинтегрирую по
[02:22:06.780 --> 02:22:13.420]  распределению вероятностей нашего случайного вектора, я в точности получу, конечно, нужную мне
[02:22:13.420 --> 02:22:22.620]  вероятность. А это в точности интеграл из теремофубии. Благодаря тому, что этот интеграл не
[02:22:22.620 --> 02:22:30.220]  превосходит единицы, то есть, он конечен. Я могу менять местами, интегрировать по очереди, то есть,
[02:22:30.220 --> 02:22:36.620]  например, написать так. Сначала по u проинтегрировать, а потом по v. Но если я u зафиксировал,
[02:22:36.620 --> 02:22:50.100]  то v будет от минус бесконечности до x-у. Да, значит, и я должен сначала проинтегрировать по
[02:22:50.100 --> 02:23:03.260]  распределению случайного вечноэта, а потом уже кси. Что это за внутренний интеграл такой? Я
[02:23:03.260 --> 02:23:11.460]  интегрирую, на самом деле, индикатор принадлежности множеству от минус бесконечности до x-у. То есть,
[02:23:11.460 --> 02:23:25.860]  это в точности p-эта от множества от минус бесконечности до x-у dpc. А это есть функция
[02:23:25.860 --> 02:23:34.860]  распределения. Я получил функцию распределения это в точке x-у dpc. Вот это называется формула сверки.
[02:23:34.860 --> 02:23:45.300]  Давайте я ее выпишу ярко посередине. Функция распределения x-у в точке x. Это есть интеграл по r.
[02:23:45.300 --> 02:23:56.860]  Функция распределения это в точке x-у dpc. Ну а дальше тут можно еще заметить важную вещь. Во-первых,
[02:23:56.860 --> 02:24:09.540]  если так вышло, что кси является абсолютно непрерывной случайного вечноэта, то интеграл по
[02:24:09.540 --> 02:24:14.740]  соответствующему распределению вероятности можно свести к классической мере либега. То есть,
[02:24:14.740 --> 02:24:24.740]  функция распределения кси плюс эт в точке x будет просто равна интегралу по r от f-эта от x-у плотность
[02:24:24.740 --> 02:24:32.140]  кси в точке u du. То есть, случай, когда случайная вечноэта является абсолютно непрерывной,
[02:24:32.140 --> 02:24:36.940]  мы получаем просто обычный интеграл либега по классической мере либега от произведения
[02:24:36.940 --> 02:24:41.340]  функции распределения плотности в точке u. Давайте внимательно посмотрим на эту формулу и увидим,
[02:24:41.340 --> 02:24:51.380]  что у нее есть понятная интуиция. Вероятность того, что сумма не превосходит x, это есть интеграл по
[02:24:51.380 --> 02:24:55.460]  u. Про интеграл мы думаем на самом деле как про сумму. То есть, это как бы сумма по всем возможным
[02:24:55.460 --> 02:25:04.620]  значениям u. Когда мы думаем про интеграл как про сумму, мы про плотность можем думать как
[02:25:04.620 --> 02:25:09.020]  про вероятность попадания в точке u. То есть, если бы мы заменили абсолютную непрерывную
[02:25:09.020 --> 02:25:14.500]  дискретность, то есть, если бы кси была дискретной, мы бы здесь написали сумму по всем возможным u,
[02:25:14.500 --> 02:25:20.340]  а здесь это было бы вероятностью того, что кси равняется u. И это была бы очень естественная формула,
[02:25:20.340 --> 02:25:28.140]  она бы нам говорила, что, ну, понятно, что если кси равняется u, то мы получаем вероятность того,
[02:25:28.140 --> 02:25:33.700]  что это не превосходит x-у. То есть, конечно, функция распределения суммы в точке x,
[02:25:33.700 --> 02:25:38.980]  это просто сумма, функция распределения at в точке x-у, умножить на вероятность того,
[02:25:38.980 --> 02:25:43.380]  что кси равняется u. Да, вот эта формула, то есть, для случая, когда кси дискретно,
[02:25:43.380 --> 02:25:48.500]  она является очевидной. И оказывается, она естественным образом переносится на
[02:25:48.500 --> 02:25:58.700]  абсолютно непрерывный случай, вот как мы увидели. Более того, если ещё и это абсолютно непрерывно,
[02:25:58.700 --> 02:26:13.300]  то тогда можно найти плотность суммы, тогда сумма тоже будет абсолютно непрерывна. Её плотность,
[02:26:13.300 --> 02:26:20.020]  ну, смотрите, если бы всё было дифференцировано по x, то вы могли просто обе части этого равенства
[02:26:20.020 --> 02:26:35.260]  продиференцировать по x, вы получили вот что. Вы получили вот что. Ну, не факт, конечно,
[02:26:35.260 --> 02:26:39.420]  что функция распределения является дифференцированной, но, тем не менее, всё равно
[02:26:39.420 --> 02:26:45.380]  это райстудент. Тем не менее, всё равно плотность суммы равна такому интегралу. Ну, это надо
[02:26:45.380 --> 02:26:50.260]  доказывать просто из определения плотности. Вот давайте предположим, что она равна такому
[02:26:50.260 --> 02:26:54.980]  интегралу, поставим функцию распределения, увидим, что это действительно так. Давайте это проделаем.
[02:26:54.980 --> 02:27:10.020]  То есть, найдём интеграл от минус бесконечности до x от вот этой вот плотности, которую мы
[02:27:10.020 --> 02:27:19.140]  предположили, что является плотностью, от этой функции, которую мы предположили, что является
[02:27:19.140 --> 02:27:38.220]  плотностью. То есть, это будет двойная интеграл. Ну и дальше, опять же, потеряем фубинию, мы можем
[02:27:38.220 --> 02:27:43.380]  поменять местами пределы интегрирования и написать, что это есть интеграл по r,
[02:27:43.380 --> 02:28:00.540]  по x от u, на интеграл от минус бесконечности до x, по это от t-у, dt, du. Вот. Ну, в силу того,
[02:28:00.540 --> 02:28:09.580]  что вот эта p-eta, это есть плотность, случайная величина eta, вот этот интеграл, это, конечно,
[02:28:09.580 --> 02:28:16.500]  в точности функция распределения. Смотрите, можно замену сделать, можно написать это как,
[02:28:16.500 --> 02:28:32.540]  значит, если t-у заменить на y, мы получим тут плотность от точки y до y, а пределы интегрирования
[02:28:32.540 --> 02:28:51.940]  будут от минус бесконечности до x-у. Вот. Ну и тогда видно теперь, что это в точности функция
[02:28:51.940 --> 02:28:56.820]  распределения. Это функция распределения at в точке x-у по определению плотности. И,
[02:28:56.820 --> 02:29:05.060]  значит, мы получаем произведение по x от u на функцию распределения at в точке x-у du. А это и есть,
[02:29:05.060 --> 02:29:10.500]  собственно, наш функция распределения к c плюс at. По формуле свёртки это действительно функция
[02:29:10.500 --> 02:29:15.220]  распределения к c плюс at в точке x, что и требовалось. Значит, да, действительно, даже когда не
[02:29:15.220 --> 02:29:21.660]  дифференцируем всё хорошо, мы можем считать, что вот именно по такой формуле считается плотность
[02:29:21.660 --> 02:29:28.940]  суммы независимо случайных причин. Есть какие-то вопросы? Давайте разберём задачку
[02:29:28.940 --> 02:29:43.460]  на применение формулы свёртки, на этом закончим. Ну, я не люблю сложные задачи решать. Это вы любите
[02:29:43.460 --> 02:29:50.580]  сложные задачи решать. Я буду решать простые задачи. Значит, пусть x-и это равномерные на
[02:29:50.580 --> 02:30:01.780]  отрезке 0,1. Значит, хотят от меня плотность суммы. Как вообще сумма распределена? Какая у неё плотность?
[02:30:01.780 --> 02:30:06.660]  Ну, смотрите, вот складываем мы две независимо случайных величины равномерно сплённых на отрезке
[02:30:06.660 --> 02:30:11.740]  0,1. Они, конечно, станут распределены на отрезке от 0 до 2. Ну, то есть, вот эта сумма,
[02:30:11.740 --> 02:30:17.740]  она будет принимать значение от 0 до 2. Вы спросите, а равномерно ли? Ну, конечно же,
[02:30:17.940 --> 02:30:25.160]  неравномерно. Да, потому что с краёв. Принять значение 0 можно только, когда обеи случайно
[02:30:25.800 --> 02:30:31.540]  равны 0. Принять значение 2 можно только, когда обеи случайно равны 1. То есть, понятно,
[02:30:31.540 --> 02:30:36.660]  что чем ближе мы к центру этого отрезка, тем больше дуэль, тем больше плотность. The density
[02:30:36.660 --> 02:30:41.240]  по идее плотности должна как-то вести себя так. Она должна к концу этого отрезка 0,2 уменьшаться,
[02:30:41.240 --> 02:30:45.260]  а к середине отрезка увеличиваться. Давайте увидим, что это действительно так.
[02:30:45.260 --> 02:30:56.860]  Но у нас есть формула, которая говорит, что плотность xi плюс et в точке x, это есть интеграл по r от
[02:30:56.860 --> 02:31:10.540]  плотности это в точке x минус u, плотность xi в точке u du. Ну а плотность равномерноспределения
[02:31:10.540 --> 02:31:15.380]  это просто индикатор принадлежности соответствующему отрезку по длину отрезка. У нас
[02:31:15.380 --> 02:31:20.860]  отрезок имеет длину 1, поэтому плотность это это будет просто индикатор того, что x минус u
[02:31:20.860 --> 02:31:27.580]  лежит в отрезке от 0 до 1. Ну а вторая плотность это индикатор того, что u лежит в отрезке от 0 до 1.
[02:31:27.580 --> 02:31:36.460]  Ну и сразу становится понятно, что x должен попасть в отрезок от 0 до 2, иначе тут все индикаторы
[02:31:36.460 --> 02:31:47.180]  внуляться. Значит, поэтому получаем... так, что получаем? Во-первых, интеграл будет от 0 до 1
[02:31:47.180 --> 02:32:04.140]  от индикатора того, что x лежит между u и u плюс 1. Это если x от 0 до 2 и 0 иначе.
[02:32:04.140 --> 02:32:13.220]  И 0 иначе. Ну и вот давайте, если x от 0 до 2...
[02:32:13.220 --> 02:32:23.260]  Сейчас.
[02:32:23.260 --> 02:32:34.180]  Давайте x сначала от 0 до 1, рассмотрим две ситуации. Да, сначала x от 0 до 1.
[02:32:34.180 --> 02:32:49.380]  Тогда u плюс 1 и так больше забраен, чем x. То есть вот это условие, оно выполнено автоматически,
[02:32:49.380 --> 02:32:55.180]  потому что u лежит от 0 до 1, значит, у плюс 1 лежит от 1 до 2. То есть у нас имеет смысл только вот
[02:32:55.180 --> 02:33:13.020]  это условие. У нас получается, на самом деле, интеграл от 0 до x в точности x. Если же x лежит
[02:33:13.020 --> 02:33:21.420]  в отрезке от 1 до 2, то тогда уже x будет больше равно, чем u. То есть вот это условие будет
[02:33:21.420 --> 02:33:27.740]  выполнено автоматически, потому что u от 0 до 1. И, значит, интересовать нас будет только второе условие,
[02:33:27.740 --> 02:33:36.740]  а именно u больше либо равно, чем x минус 1. То есть плотность будет равна интегралу от x минус 1 до 1
[02:33:36.740 --> 02:33:47.900]  d u, что равно 2 минус x. Теперь мы можем нарисовать плотность. Мы можем посмотреть, как она выглядит.
[02:33:47.900 --> 02:33:57.620]  И выглядит она будет вот так. Ну, как я и сказал. То есть вот есть точки 0, 1 и 2, и она ведется
[02:33:57.620 --> 02:34:09.860]  следующим образом. То есть до точки 0 она, понятно, 0 равна. Дальше она равна, просто идет под углом 45
[02:34:09.860 --> 02:34:17.300]  градусов и потом обратно к нулю. Потом снова равна нулю. Вот такая вот плотность будет у суммы двух
[02:34:17.300 --> 02:34:25.500]  независимо случайных величин, равномерных на отрезке 0 и 1. Все на этом. Есть ли какие-то вопросы?
[02:34:25.500 --> 02:34:41.940]  Вопросов нет. Хорошо, работайте. Увидимся, дай бог, в аудитории в следующую субботу в
[02:34:41.940 --> 02:34:44.460]  наше обычное время. До свидания. Всем спасибо, до свидания.
