[00:00.000 --> 00:12.600]  Ну вроде бы уже время начинать. Давайте начнем. Я напомню, что в прошлый раз я начал рассказывать про
[00:12.600 --> 00:22.680]  задачу восстановления информации и даже успел сформулировать задачу построения корректирующих
[00:22.680 --> 00:26.880]  кодов комбинаторно. Но сейчас я это напомню, потому что дальше мы с ней будем иметь дело.
[00:26.880 --> 00:36.160]  Я напомню, как устроено блокчное кодирование. Мы берем сообщение, какую-то строку двоичной длины
[00:36.160 --> 00:43.080]  K, отправляем ее в некоторое устройство, которое называется кодером, и на выходе получаем,
[00:43.080 --> 00:57.160]  вообще говоря, более длинную строку из n-битов. Кодер это просто функция, которая по уса поставляет
[00:57.160 --> 01:02.120]  вот какое-то такое значение. И вот эта вот более длинная строка отправляется в канал связи,
[01:02.120 --> 01:12.640]  на выходе из которого получается нечто. В канале возможны ошибки. Я сразу зафиксирую модель
[01:12.640 --> 01:36.280]  ошибок. Возможны только инвертирование битов, и их количество ограничено. То есть y это тоже
[01:36.280 --> 01:45.040]  некоторая строка длины n. И наша цель состоит в том, чтобы по этому y понять, что передавалось.
[01:45.040 --> 01:57.480]  Поэтому мы отправляем эту строку в устройство, которое называется декодер, и оно выдает нечто,
[01:57.480 --> 02:06.880]  х'. Значит, основное определение, которое нам нужно, код исправляет
[02:06.880 --> 02:35.440]  r ошибок. Если x' равняется x для всех y, которые отличаются от x,
[02:35.440 --> 02:46.360]  не более чем r-битах. Ну то есть, если у нас в канале случилась какая-то катастрофа,
[02:46.360 --> 02:52.520]  испортилось очень много битов, мы не гарантируем правильного восстановления. Но если выполнены
[02:52.520 --> 02:57.840]  условия, которые у нас есть в модели ошибок, что случилось не больше r-инвертирования битов,
[02:57.840 --> 03:06.440]  то мы на выходе декодера получаем то сообщение, которое было передано. Ну это немножко неформально.
[03:06.440 --> 03:12.640]  В частности, я говорю про код, но а что во всей этой схеме код, а что не код? Давайте я сейчас
[03:12.640 --> 03:19.360]  дам более формальные определения, и посмотрим вначале вообще на всю эту комбинаторную ситуацию.
[03:19.880 --> 03:30.320]  Код это просто-напросто у нас будет любое подмножество двоичных строк длины n. n будет
[03:30.320 --> 03:45.000]  называться длина кода. Размерность кода. Почему используется слово размерность, станет ясно
[03:45.000 --> 03:54.120]  чуть позже. Оно тут не случайно. Но по определению размерность это просто двоичный логарифм количества
[03:54.120 --> 04:03.120]  элементов в коде. То есть если в коде 2 в степени k элементов, то это в точности размерность k.
[04:03.240 --> 04:22.080]  Значит k размерность. Ну понятно, как это пристроить к этой схеме. Смотрите, если у нас есть код,
[04:22.080 --> 04:27.520]  это то, что получается на выходе из кодера. Но мы можем себе представить какую-то схему,
[04:27.600 --> 04:33.960]  как к битов закодировать вот этими словами. Нам их хватит. Отдельная история, насколько
[04:33.960 --> 04:45.360]  легок алгоритм кодирования, я чуть позже про это скажу, но вот так. Теперь третий основной
[04:45.360 --> 04:55.600]  параметр для кода, это кодовое расстояние. И тут мне нужно ввести расстояние, которое я буду
[04:55.600 --> 05:11.360]  использовать на двоичных словах. Это расстояние называется расстояние Хэминга. И определено оно
[05:11.360 --> 05:22.160]  очень просто. Значит x и y это какие-то двоичные слова. Ну давайте длины n. И расстояние это
[05:22.160 --> 05:32.920]  количество тех позиций, в которых слова различаются. Ну вот, например, давайте возьмем
[05:32.920 --> 05:49.040]  x 1 0 1 0 1 0 1, а y 1 0 0 0 1 1 1. Какое расстояние между этими словами? Ну надо отметить различающиеся
[05:49.040 --> 05:56.960]  позиции. Вот первая различающаяся позиция, и вот вторая различающаяся позиция. Во всех остальных
[05:56.960 --> 06:08.920]  позициях стоят одни и те же биты. Поэтому расстояние в данном случае равно 2. Слово расстояние здесь
[06:08.920 --> 06:18.600]  совершенно не случайно. Это нам будет важно, и я сейчас докажу очень простую лему, которая называется
[06:18.600 --> 06:26.760]  неравенство треугольника. Это главное свойство для функции, которая претендует называться расстоянием.
[06:26.760 --> 06:34.240]  Ну, строго говоря, расстояние или метрика это такая не отрицательная функция, что выполняет
[06:34.240 --> 06:40.680]  с неравенства треугольника, что она симметрична, если она равна 0 и x равен y. Это уже строгое
[06:40.680 --> 06:49.160]  определение метрики. Для расстояния Хэминга это все выполнено, потому что если нет различающихся
[06:49.160 --> 06:54.640]  позиций, то конечно слова совпадают, а расстояние не отрицательно, естественно оно симметрично,
[06:54.640 --> 07:00.640]  потому что мы считаем позиции, которые различаются. Единственное, что нетривиально, это проверить
[07:00.640 --> 07:07.920]  неравенство треугольника. Но это тоже очень просто. Вот давайте посмотрим на множество позиций от 1 до n.
[07:07.920 --> 07:24.000]  Пусть a это множество позиций, в которых различаются x и y. Я рисую его сплошняком, но это совершенно
[07:24.000 --> 07:31.320]  не обязательно сплошь, это как вот здесь могут быть какие-то разобранные части. Мне просто удобнее
[07:31.320 --> 07:41.360]  рисовать сплошняком. В доказательстве я этого использовать не буду, что это интервал. B это множество
[07:41.360 --> 07:55.000]  позиций, в которых y отличается от z. Заметьте, что вне объединения множества a и b у нас x и t равняется
[07:55.000 --> 08:05.560]  y и тому, а y и t равняется z и тому. То есть в частности x и t равняется z и тому. Значит, если я определю множество
[08:05.560 --> 08:15.560]  позиций, в которых различаются x и z, то какой вывод мы можем сделать? Оно находится где-то вот здесь,
[08:15.560 --> 08:24.920]  то есть это множество лежит в объединении a и b. Ну а теперь это неравенство становится очевидным.
[08:24.920 --> 08:34.120]  Сколько у нас элементов в объединении a и b? Не больше, чем сумма количества элементов a и
[08:34.120 --> 08:39.440]  количества элементов b, а c лежит внутри, то есть там тоже еще не больше. Поэтому получаем вот это
[08:39.440 --> 08:47.480]  вот самое неравенство. И теперь я возвращаюсь к определению кодового расстояния. Это по
[08:47.480 --> 08:57.400]  определению минимум по словам, принадлежащим коду, но различный. Расстояние между x и y.
[08:57.400 --> 09:11.440]  Сейчас я объясню, какое отношение кодовое расстояние имеет к исправлению ошибок. Пока вот три параметра.
[09:11.440 --> 09:33.360]  И основная задача теории корректирующих кодов. Даны три числа n, k, d. Существует ли код двоичный?
[09:33.360 --> 09:37.280]  На самом деле рассматривается не только двоичные коды, я для простоты буду говорить только о
[09:37.280 --> 09:47.600]  двоичных кодах. Нам интересно, существует ли код длины n, размерности k и кодового расстояния d.
[09:47.600 --> 09:55.480]  Ну все тройки нам не интересны, конечно мы хотим, чтобы k и d были побольше. Почему мы хотим,
[09:55.480 --> 10:01.480]  чтобы d было побольше? Сейчас я докажу на этот счет лему. Давайте, наверное, где-нибудь вот
[10:01.480 --> 10:17.720]  здесь. Мне пока ничего из этого стирать не хочется. Пусть d больше, чем 2r, то есть не меньше,
[10:17.720 --> 10:42.640]  чем 2r плюс 1. Тогда c исправляет r ошибок. Как это доказать? Смотрите, нам понадобится понятие
[10:42.640 --> 10:57.240]  шара. Шар радиуса r, ну, с центром какой-то точки a. Это множество таких точек, что расстояние от a до x не
[10:57.240 --> 11:03.000]  превосходит r. Совершенно обычное определение шара. Так шары определяются в любом метрическом
[11:03.000 --> 11:08.760]  пространстве, в обычном эвкалидовом пространстве они также определяются. Ну и вот в случае метрики
[11:08.760 --> 11:17.760]  Хэминга на двоичных словах, определение такое же. Что существенно. Смотрите, если у меня есть два
[11:17.760 --> 11:34.560]  разных слова, вот это вот условие на кодовое расстояние говорит, что из кода. Говорит,
[11:34.560 --> 11:46.320]  что шары соответствующего радиуса не пересекаются. Почему? Ну, смотрите, возьмем любую точку в шаре
[11:46.320 --> 11:57.480]  с центром в x. Вот тут расстояние не больше, чем r по определению шара. Вот тут расстояние не меньше,
[11:57.480 --> 12:04.040]  чем 2r плюс 1. Что мы можем сказать про третью сторону треугольника? У нас должно выполняться
[12:04.040 --> 12:10.720]  неравенство. Вот это плюс вот это не меньше, чем вот это. Но тут не больше, чем r, а должно
[12:10.720 --> 12:16.640]  получиться число, которое не меньше, чем 2r плюс 1. Значит вот здесь заведомо больше либо равно r
[12:16.640 --> 12:26.400]  плюс 1. То есть больше r. Значит, если я взял точку в одном шаре, то до другого шара, то в другой
[12:26.400 --> 12:32.480]  шар она не попадет. То есть про каждую точку мы знаем, что она либо вообще не попадает ни в один
[12:32.480 --> 12:40.720]  шар с центрами в кодовых словах радиуса r, либо попадает ровно в 1. И давайте теперь смотреть на
[12:40.720 --> 12:50.760]  картинку декодирования. Я ее после этого сотру. Вот мы получили, мы передаем вначале какое-то
[12:50.760 --> 13:00.240]  слово u, потом какое-то слово v. У нас тут получились кодовые слова какие-то. И когда мы их передали
[13:00.240 --> 13:06.560]  по каналу, получились какие-то слова. Но мы точно знаем, что слова лежат в шаре. Потому что,
[13:06.560 --> 13:12.800]  смотрите, что значит, что расстояние не больше, чем r? По определению расстояния, это означает как
[13:12.800 --> 13:18.440]  раз в точности, что слова различаются не больше, чем в r-позициях. А у нас модель ошибок такая,
[13:18.440 --> 13:24.080]  что инвертирование случилось не больше, чем в r-позициях. Значит, из того слова, которое мы
[13:24.080 --> 13:31.040]  передавали, может получиться только слово, которое лежит в шаре радиуса. Собственно,
[13:31.040 --> 13:36.960]  вот это понятие хэмингового расстояния, оно фиксирует свойства нашей модели ошибок.
[13:36.960 --> 13:44.200]  Ну и теперь уже алгоритм декодирования понятен. Если мы получили какое-то слово,
[13:44.200 --> 13:52.760]  мы смотрим в шар с центром в какой кодовой точке оно попадает, и выдаем этот центр. Если
[13:52.760 --> 13:58.720]  слово не попало, не выделилось шаров, мы можем выдать просто сообщение об ошибке, можем выдать
[13:58.720 --> 14:05.800]  любое кодовое слово. Нас это не интересует, потому что слова вне объединения этих шаров в нашей
[14:05.800 --> 14:12.360]  модели получиться не могут. Мы рассматриваем только ошибки вида, когда происходит не больше r-инвертирования
[14:12.360 --> 14:18.960]  битов. Конечно, для реальной жизни это немножко искусная модель, и если у вас есть такой код,
[14:18.960 --> 14:25.360]  который вы используете, все равно может так случиться, что пришла какая-то ерунда. И там есть
[14:25.360 --> 14:31.360]  отдельная история, это отдельная задача, теория кодирования очень большая. Я, конечно, даже самое
[14:31.360 --> 14:37.640]  начало не успею рассказать, я только несколько конструкций смогу вам показать, чтобы стало
[14:37.640 --> 14:46.680]  вообще понятно, почему что-то интересное здесь может быть. Ну, если говорить о реальных алгоритмах
[14:46.680 --> 14:50.840]  декодирования, в этом случае декодирование происходит по максимуму правдоподобия,
[14:50.840 --> 14:59.560]  что бы это ни значило. В общем, есть некоторые средства, как для конкретных кодов, как указывать.
[14:59.560 --> 15:05.560]  Но там, чтобы что-то доказывать, нужна какая-то более сложная модель ошибок, например, вероятностная,
[15:05.560 --> 15:13.520]  это я все пропускаю. То есть, в нашем случае я хочу заметить, что у меня модель ошибок вот она. То
[15:13.560 --> 15:19.240]  есть, меня вообще не интересуют случаи, когда ошибок случилось больше r, и тогда этот код исправляет
[15:19.240 --> 15:33.520]  эти r ошибок, если шары не пересекаются. Ну, это такой вот пересказ, пересказ вот этой вот конструкции в
[15:33.520 --> 15:39.960]  виде комбинаторной задачи. Вот она комбинаторная задача. Теперь понятно, почему я хочу, чтобы d
[15:39.960 --> 15:45.720]  было побольше. Чем больше d, тем больше ошибок код исправляет. Но понятное дело, что k и d
[15:45.720 --> 15:51.080]  увеличивать одновременно затруднительно. Это противоречивое требование, чтобы точек было побольше,
[15:51.080 --> 15:59.720]  а шары с центрами в этих точках не пересекались. Давайте рассмотрим два простых случая. Первый
[15:59.720 --> 16:11.560]  простой случай. Код повторения. Это просто-напросто два двоичных слова. Одно состоит только из нулей,
[16:11.560 --> 16:20.240]  другое только из единиц. Ну n у нас, вот оно написано. Чему равна размерность? Слов 2, значит,
[16:20.240 --> 16:26.120]  размерность равна единице. Код повторения позволяет кодировать один бит. Ну понятно, каким способом.
[16:26.320 --> 16:31.040]  Если мы хотим передать 0, мы передаем n нулей. Хотим передать единицу, передаем n единиц.
[16:31.040 --> 16:40.840]  А расстояние кодовое очень хорошее. n. Потому что, если я возьму n нулей, n единиц, они различаются
[16:40.840 --> 16:47.920]  во всех позициях. Код совершенно замечательен с точки зрения исправления ошибок, но он совершенно
[16:47.920 --> 16:55.400]  плох с точки зрения экономии ресурса. Чтобы передать один бит, мы передаем n битов. Вот это называется
[16:55.400 --> 17:00.280]  скорость передачи. Значит, я особо не буду злоупотреблять этим термином.
[17:06.280 --> 17:12.080]  Смысл совершенно понятен. Мы хотим уже передавать вот эти информационные, как говорят, биты, а передаем кодовые.
[17:12.080 --> 17:20.880]  Если, вот как в этом случае, k равно единице, то чтобы передать сколько-то информационных битов,
[17:20.880 --> 17:30.400]  мы должны передать в n раз больше кодовых. Получается так, что плата за то, что мы исправляем примерно n пополам ошибок,
[17:30.400 --> 17:39.040]  очень большая. Мы платим падением скорости в n раз. И возникает вопрос, обязательно ли такое падение необходимо.
[17:39.040 --> 17:44.520]  Я сразу скажу, что не обязательно. На самом деле, есть гораздо более экономные коды. Некоторые примеры появятся.
[17:44.520 --> 17:58.600]  Ну, второй код тривиальный. Это просто-напросто все двоичные слова длины n. Тут с размерностью все хорошо,
[17:58.600 --> 18:07.320]  но с кодовым расстоянием все плохо. Он исправляет ноль ошибок. Ну, это понятно почему, потому что если вы
[18:07.320 --> 18:13.000]  передаете слово никак, то есть просто все информационные биты прямо посылаете в канал,
[18:13.000 --> 18:17.280]  если у вас что-то испортилось, то вы уже это не сможете восстановить. У вас получится снова кодовая слуха.
[18:17.280 --> 18:26.520]  То есть вы видите из этих двух примеров, что k и d, они в каком-то смысле противоположны. То есть если мы
[18:26.520 --> 18:32.560]  хотим k взять побольше, то d совсем маленьким взять нельзя. И наоборот, возникает вопрос,
[18:32.560 --> 18:40.400]  каковы же более-менее оптимальные соотношения между k и d. Мы сейчас его обсудим. Последнее,
[18:40.400 --> 18:48.320]  что я хочу сказать, прежде чем стереть вот эту вот доску с базовой задачей исправления ошибок,
[18:48.320 --> 18:59.200]  я хочу заметить, что вот я вот так вот зафиксировал свою главную задачу, при каких n, k и d существует
[18:59.200 --> 19:08.880]  код. Но на самом деле, конечно, нам хочется больше. Чего нам хочется? Давайте посмотрим на эту картинку.
[19:08.880 --> 19:18.600]  Мы хотим, чтобы у нас был достаточно эффективный кодер и достаточно эффективный декодер. Сейчас,
[19:18.600 --> 19:26.240]  конечно, есть компьютеры, вы можете кодер реализовать в виде процессора, который будет вычислять какую-то
[19:26.240 --> 19:31.800]  очень сложную функцию. Но нужно понимать, что то, что я сейчас рассказываю, это, в общем-то,
[19:31.800 --> 19:39.800]  очень старая история. Она происходила в конце сороковых, в начале 50-х годов прошлого века. То есть
[19:39.800 --> 19:47.240]  радио уже было, компьютеров не было, и были радиолампы. И вот на радиолампах вы могли собрать какое-нибудь
[19:47.240 --> 19:53.600]  устройство, напоминающее компьютер, которое могло что-то вычислить. Но чем больше лампы использовали,
[19:53.600 --> 19:59.240]  тем менее надежным оно становилось. Поэтому, если учесть, что заказчиками к тому же были в основном
[19:59.240 --> 20:04.520]  военные, им хотелось, чтобы все это работало надежно, если это состоит в машине, которая едет
[20:04.520 --> 20:09.920]  где-то по бездорожью, а лампы обладают таким свойством, что у них нити накаливания рвутся и
[20:09.920 --> 20:16.600]  так далее. Хотелось как можно проще реализовывать и вот эту, и вот эту вот часть, и кодер, и декодер.
[20:16.600 --> 20:24.720]  Я буду обсуждать только проблему кодирования. Проблема декодирования, она труднее, на самом деле.
[20:24.720 --> 20:30.720]  Для тех кодов, про которые я рассказываю, есть хорошие алгоритмы декодирования, но в общем случае их
[20:30.720 --> 20:38.080]  нет. То есть можно придумать замечательный код, хороший там в разных отношениях, но который вы не
[20:38.080 --> 20:45.920]  сможете декодировать эффективно. Эффективно даже в современном смысле, то есть у вас будет там длина
[20:45.920 --> 20:53.200]  кода 10 тысяч, и вы не сможете восстановить сообщение просто потому, что алгоритм восстановления
[20:53.200 --> 20:59.800]  слишком сложный. Но про декодирование я говорить не буду. Это все очень похоже на то, что я буду
[20:59.800 --> 21:05.560]  рассказывать, но требует просто у меня времени на это нет. Моя цель показать, как можно кодировать.
[21:05.560 --> 21:12.280]  Причем не просто вот что существует код, а существует код, который достаточно легко задать. То есть
[21:12.280 --> 21:21.680]  вот это меня заботить будет, чтобы задать код было достаточно легко. Но прежде чем задавать код каким-то
[21:21.680 --> 21:26.960]  эффективным способом, давайте посмотрим какие вообще есть комбинаторные ограничения. Вот в духе вот
[21:26.960 --> 21:34.720]  этого вопроса. Если забыть о конструктивности, то ответ далекий от окончательного. Окончательный
[21:34.720 --> 21:40.120]  ответ не получен до сих пор, и это считается очень трудной задачей. Там время от времени происходит
[21:40.120 --> 21:50.440]  продвижение, но они с течением времени становятся все более и более загадочными. Последние продвижения
[21:50.440 --> 21:57.880]  я вам даже не смогу сформулировать. Я, честно говоря, их до конца и не понимаю. Там уже утверждение
[21:57.880 --> 22:03.760]  формулируется на очень сложном математическом языке, хотя вроде бы речь идет о комбинаторике.
[22:03.760 --> 22:13.040]  Но я расскажу два базовых факта, которые очень простые, которые люди сразу сообразили, когда
[22:13.040 --> 22:18.040]  начали интересоваться корректирующими кодами, и которые, по сути дела, лежат в основе всех
[22:18.040 --> 22:25.000]  дальнейших построений. Они задают некоторые естественные границы. Вот у нас есть два примера,
[22:25.000 --> 22:31.600]  но они не очень показательные на самом деле. Показательные будут другие оценки. Первая оценка
[22:31.600 --> 22:47.240]  называется по традиции «граница хэминга». Тут слово «граница» нужно понимать как слово «оценка».
[22:47.240 --> 22:53.600]  Просто по-английски это «haming bound» все равно, а по-русски в какой-то момент это перевели как
[22:53.600 --> 23:09.480]  «граница», но так и прижилось. Пусть у нас есть код с параметрами n, k, 2r плюс 1. Тогда
[23:09.480 --> 23:23.000]  2 в степени k, то есть количество кодовых слов, не превосходит 2 в степени n разделить на
[23:23.000 --> 23:33.320]  нечто такое слегка загадочное, на сумму биномиальных коэффициентов. Биномиальные коэффициенты
[23:33.320 --> 23:44.640]  из n по i, где i пробегает значение от 0 до r. Чтобы это стало менее загадочным, давайте я,
[23:44.640 --> 23:58.360]  ну вот эту лему я уже доказал, я здесь оставлю, чтобы это было полезно иметь перед глазами. Вот
[23:58.360 --> 24:05.600]  давайте посмотрим. Значит, ясно, что количество точек в шаре радиуса r не зависит от, давайте я
[24:05.600 --> 24:14.120]  вот просто напишу br, это у меня brn. Это будет количество точек в шаре радиуса r с центром,
[24:14.120 --> 24:20.600]  ну пусть будет в нуле, но на самом деле в любой точке. Понятно, почему не зависит, потому что если
[24:20.600 --> 24:29.200]  я, ну сейчас мы посчитаем и давайте тут, ну давайте я напишу 0, а потом объясню просто,
[24:29.200 --> 24:36.120]  что счет от этого не зависит. Это как раз вот та самая сумма биномиальных коэффициентов,
[24:36.120 --> 24:43.680]  которая написана. Откуда она берется? Ну давайте я еще раз нарисую этот шар. Вот у нас есть центр,
[24:43.680 --> 24:54.200]  пусть нулевая точка. Что входит в этот шар? Входят такие x, что количество единиц не больше,
[24:54.200 --> 25:03.280]  чем r. Значит, вот норма x, это по определению расстояние от нуля до x. Еще такое обозначение
[25:03.280 --> 25:10.640]  используется, норма. Хеминговая норма. А сколько же здесь точек? Ну смотрите, если у нас единиц и,
[25:10.640 --> 25:19.320]  сколько у нас точек из нулей единиц, которых и единиц. Ну как раз биномиальный коэффициент по
[25:19.320 --> 25:24.680]  определению. И дальше мы должны взять сумму. Нас устраивает любое значение и от нуля до r.
[25:24.680 --> 25:30.440]  Теперь почему это не зависит от центра? Мне удобнее было считать от нуля, но представьте,
[25:30.440 --> 25:38.320]  что я считаю от какой-то точки. Тогда все, что мне нужно сделать, это считать, смотреть,
[25:38.320 --> 25:45.120]  сколько у меня позиций, в которых центр и данная точка различаются ровно в и-позициях. Это будет,
[25:45.120 --> 25:50.000]  опять-таки, под множество размера и n элемент на множество. То есть их тоже биномиальный коэффициент.
[25:50.000 --> 26:01.560]  Ну чуть позже у нас даже появится более веское объяснение, вот такой вот формуле. Ну сейчас,
[26:01.560 --> 26:08.840]  что не зависит точнее от положения центра, но сейчас этого достаточно. То есть фактически я
[26:08.840 --> 26:24.840]  напишу вот теперь, тут у меня граница Хэминга написана, я напишу ее теперь вот так. И теперь
[26:24.840 --> 26:30.440]  она становится практически очевидной. Ну вспомним лемма, которая у меня была. Шары
[26:30.440 --> 26:42.480]  радиуса r не пересекаются. Если у меня есть код, это точки из кода, шары радиуса r с центрами
[26:42.480 --> 26:49.760]  в этих точках не пересекаются. Ну что это означает? Это означает, что если я возьму и
[26:50.000 --> 26:57.840]  посчитаю количество точек в этих шарах, в каждом шаре одинаковое количество точек, вот та самая
[26:57.840 --> 27:03.040]  сумма биномиальных коэффициентов. У меня не может получиться больше, чем 2 в степени n,
[27:03.040 --> 27:08.040]  потому что 2 в степени n это общее количество двоичных слов, длины n. А шары не пересекаются. Я
[27:08.040 --> 27:13.680]  каждую точку могу посчитать не больше, чем по разуму. Но это и есть та оценка, которая написана. То
[27:13.680 --> 27:21.520]  есть мы видим, что код не может быть очень большим. Вот это ограничение. С другой стороны,
[27:21.520 --> 27:30.040]  если сравнивать вот с этими крайними случаями, то он существенно лучше, чем эти крайние случаи,
[27:30.040 --> 27:36.600]  вот эта оценка. Смотрите, что у меня есть. Допустим, я хочу исправлять константу ошибок,
[27:36.600 --> 27:53.520]  ну там не знаю, две. Тогда brn это примерно n квадрат. Это означает о большое и омега большое. То
[27:53.520 --> 28:01.440]  есть точно сюда констант и это n квадрат. Ну и теперь смотрите, нас же интересует логарифм. То
[28:01.440 --> 28:09.600]  есть k получается такая величина n минус там удвоенный логарифм n. Посмотрите на то,
[28:09.600 --> 28:18.280]  что у нас написано. Я исправляю две ошибки, это не тривиально. И при этом плачу очень низкую цену.
[28:18.280 --> 28:25.880]  Вот тут у меня в тривиальном коде k равнялась n, а теперь у меня k чуть меньше. Но меньше
[28:25.880 --> 28:31.120]  намножитель, который логарифмичный по n. То есть я плачу логарифмическую цену за то,
[28:31.120 --> 28:37.960]  чтобы исправлять две ошибки. Чуть более сложные подсчеты, которые я пропущу, желающие могут их
[28:37.960 --> 28:42.200]  найти в книжках или сделать самостоятельно, если вы знаете формулу Стирлинга, это вы можете написать
[28:42.200 --> 28:48.560]  самостоятельно. Говорят следующее, что даже если количество исправляемых ошибок линейно по n,
[28:48.560 --> 28:57.120]  у нас вот эта величина скорость передачи, она все равно будет, ее можно сделать константной,
[28:57.120 --> 29:04.360]  если мы достигли границы Хэминга. Граница Хэминга, вот если здесь считать, что r это там,
[29:04.360 --> 29:10.840]  не знаю, одна сотая от n, мы хотим исправлять один процент ошибок. То есть нам разрешается в одном
[29:10.840 --> 29:20.160]  проценте позиции, чтобы случиться ошибка. Ну тогда k будет, уже конечно мы не логарифмическую цену
[29:20.160 --> 29:26.040]  должны платить, а линейную, и она будет какая-то константа на n. Какая это вот там некоторые
[29:26.040 --> 29:30.680]  вычисления, которые я пропускаю? То есть граница Хэминга на самом деле очень оптимистическая,
[29:30.680 --> 29:48.440]  но она верхняя. Давайте я сразу напишу сюда список. Это не конкретный пример, это определение.
[29:48.440 --> 30:02.520]  Бывают коды, которые достигают границы Хэминга. Такие коды называются совершенными. То есть вот эта
[30:02.520 --> 30:07.000]  вот оценка достигается. Бывают такие коды, в которых достигается. Что это, кстати, означает,
[30:07.000 --> 30:12.200]  если у нас здесь равенство? Посмотрите на доказательства. Это означает, что кодовые шары,
[30:12.200 --> 30:18.360]  шары радиуса r, не просто не пересекаются, задают разбиение, у нас ничего лишнего. Мы все
[30:18.360 --> 30:25.880]  двоичные слова длины n утилизируем, они все используются как возможные результаты передачи
[30:25.880 --> 30:33.400]  информации. Вопрос, существуют ли совершенные коды с данными параметрами, довольно сложный,
[30:33.400 --> 30:37.680]  но ответ на него известен, в отличие от этой общей задачи. Совершенные коды, ответ известен.
[30:37.680 --> 30:44.040]  Их не очень много. Если говорить о двоичных кодах, о которых я только говорю, это будет серия,
[30:44.040 --> 30:49.400]  которая у меня сейчас появится через некоторое время, и еще один код, который я надеюсь в следующий
[30:49.400 --> 30:55.400]  раз рассказать. Я не буду вам доказывать, что других совершенных кодов нет. Это требует довольно
[30:55.400 --> 30:59.600]  кропотливого анализа, доказательства не очень простые, но все примеры совершенных кодов я вам
[30:59.600 --> 31:07.120]  надеюсь продемонстрировать. И все они укладываются в некоторую общую идеологию, которую я хочу
[31:07.120 --> 31:16.760]  рассказать. Но вот, к сожалению, бесконечная серия исправляет одну ошибку, просто при разных длинах
[31:16.760 --> 31:25.120]  передачи, а единственный конечный код исправляет три ошибки. То есть, если вы хотите исправлять хотя
[31:25.120 --> 31:35.320]  бы четыре ошибки, на совершенные коды уже надежды нет. А на что же надежда есть? Ну давайте тут,
[31:35.320 --> 31:40.760]  ну давайте ладно, я оставлю, это все-таки очень важное определение. Может быть, стоило переписать
[31:40.760 --> 31:49.680]  куда-то в бок, чтобы не стирать, ну пусть будет. Есть другая оценка, которая называется граница
[31:49.680 --> 32:07.680]  Варшамова Гилберта. Гилберта. Тут я, честно говоря, даже не помню, как он пишется по-английски,
[32:07.680 --> 32:14.240]  но по-русски его без мягкого знака. Есть великий немецкий математик Гильберт, а есть вот этот
[32:14.240 --> 32:23.360]  Гилберт, который американский математик, и он пишется точно не так, потому что первая буква J,
[32:23.360 --> 32:32.000]  а у знаменитого немецкого Гилберта первая буква H, но не важно. Значит, что я хочу сказать? Я хочу
[32:32.000 --> 32:55.600]  сказать, что существует код с параметрами n, k и 2r плюс 1, для которого 2 в степени k по-прежнему,
[32:55.600 --> 33:05.360]  то есть количество кодовых слов, не меньше, чем 2 в степени n поделить, а вот тут написано немножко
[33:05.360 --> 33:13.680]  другое число. Там у меня в верхней оценке было написано радиус r, а здесь написано радиус 2r.
[33:13.680 --> 33:25.560]  Это тоже очень хорошо, потому что, ну скажем, если r константа, то у меня все равно получается
[33:25.560 --> 33:32.160]  объем шара полиномиальный, и те же самые оценки показывают, что мы можем заплатить только
[33:32.160 --> 33:38.400]  алгоритмическую цену. Как доказать? Это очень хорошая оценка. Как ее доказать? Доказывается
[33:38.400 --> 33:45.800]  на самом деле очень просто. Доказательство состоит в том, что я буду просто постепенно строить
[33:45.800 --> 34:02.680]  кодовые слова, поддерживая такой вариант цикла, что x и t не принадлежит объединению шаров радиуса
[34:02.680 --> 34:13.800]  2r с центрами в остальных точках. То есть вот представьте, первую точку я могу взять произвольно,
[34:13.800 --> 34:19.240]  вторую точку я должен взять так, чтобы она не попадала в шар радиуса 2r с центром первой точки,
[34:19.240 --> 34:28.000]  и так далее. То есть если у меня уже построено k точек, и вот это вот объединение шаров еще не
[34:28.000 --> 34:34.920]  покрыло все двоичные слова, я просто могу добавить следующую точку. Инвариант сохранится,
[34:34.920 --> 34:43.120]  потому что эта точка лежит вне объединения всех шаров радиуса 2r, ну и это будет выполняться для
[34:43.120 --> 34:51.080]  всех предыдущих точек, расстояние же симметрично. Сколько же мы можем так проработать? Ну понятно,
[34:51.560 --> 34:59.560]  если у меня m, ну вот k точнее, k у меня, давайте я тут m напишу, потому что k у меня же параметр
[34:59.560 --> 35:11.800]  кода. Если m умножить на объем шара 2r меньше, чем 2 в степени n, то вот я могу добавить следующую
[35:11.800 --> 35:19.560]  точку. Потому что в таком количестве шаров радиуса 2r вот столько всего точек, если это меньше,
[35:19.560 --> 35:29.760]  чем общее количество двоичных слов, то у меня есть запас. Ну и очевидно, что полученный код,
[35:29.760 --> 35:35.680]  то есть точки x и t, имеет кодовое расстояние больше, чем 2r, потому что между кодовыми словами мы
[35:35.680 --> 35:46.360]  специально контролируем, чтобы расстояние было больше, чем 2r. Ну в общем и все. И возникает
[35:46.360 --> 35:52.120]  вопрос, а зачем вообще нужно какое-то продолжение? Мы доказали хорошую оценку. Как я сказал,
[35:52.120 --> 35:57.760]  она нас почти что устраивает. То есть разница между этими двумя границами не очень большая,
[35:57.760 --> 36:05.440]  и уже 70 лет люди сражаются за то, чтобы как-то ее улучшить. Улучшения там происходят очень небольшие,
[36:05.440 --> 36:11.240]  сложные, не при всех значениях параметров. Но это две базовые оценки. И в сущности,
[36:11.240 --> 36:18.760]  если мы достигаем оценки Варшамова-Гилберта, это считается хорошо. И скажете, а зачем тогда
[36:18.760 --> 36:25.400]  что-то еще делать? Ну вот мы доказали. Проблема в том, что эта конструкция неявная, хотя она
[36:25.400 --> 36:38.840]  описана алгоритмом. Но смотрите, вот мне дали параметры 32, кодовое расстояние должно быть 5,
[36:38.840 --> 36:45.960]  и вот мне надо ка побольше. Ну вот отсюда я получу какое-то ка. Но чтобы построить соответствующий
[36:45.960 --> 36:52.280]  код, я должен взять 32-мерный шар, то есть миллиард точек, даже не миллиард, а 4 миллиарда,
[36:52.280 --> 37:02.200]  и строить вот эту вот конструкцию. Пять таки скажете вы, ну что такое 4 миллиарда? Это как-то
[37:02.200 --> 37:07.080]  сейчас даже не то, что в оперативную память помещается, в кэш-память помещается. То есть это
[37:07.080 --> 37:15.760]  немного по нынешним временам. Но я напомню, что вся эта история развивалась тогда, когда для 32 битов
[37:15.760 --> 37:23.360]  нужно было 32 лампы, и они могли сгореть в любой момент, то есть все было очень плохо. И вот такой
[37:23.360 --> 37:28.840]  вот способ реализовать инженеры просто не брались, потому что формально мы можем написать такой
[37:28.840 --> 37:34.480]  алгоритм, но чтобы его реализовать нужно было устройство, которое просто нереально было
[37:34.480 --> 37:39.200]  реализовать. Даже в конце 50-х годов, когда появились компьютеры, где в принципе такое
[37:39.200 --> 37:45.040]  реализовать было можно, но и было ясно, что эти компьютеры занимали гигантскую площадь. Воткнуть
[37:45.040 --> 37:52.200]  в любое устройство, которое передает и принимает, было явно невозможно. То есть вот это вот,
[37:52.200 --> 38:00.840]  с точки зрения техники, нехорошо. Хотелось бы каких-то явных конструкций, но хотя бы чтобы
[38:00.840 --> 38:05.760]  мы кодировать могли достаточно просто, чтобы мы могли кодовые слова как-то очень легко. То есть
[38:05.760 --> 38:09.960]  вот мы хотим передавать какие-то биты, чтобы мы могли предъявлять, какое слово мы передаем. Ну и
[38:09.960 --> 38:16.400]  декодировать тоже хотелось. Понятно, что если мы не сможем просто кодировать, то даже если очень
[38:16.400 --> 38:24.880]  хороший алгоритм декодирования, это нас не спасет. И здесь, возможно, впервые, я не поручусь, это надо
[38:24.880 --> 38:29.120]  историю математики более внимательно изучить, но, возможно, впервые возникла ситуация, которая за
[38:29.120 --> 38:35.000]  эти 70 лет повторялась многократно. Ситуация такая. Мы из некоторых компенаторных соображений,
[38:35.000 --> 38:42.320]  либо мощностных, вот как здесь, либо вероятностных каких-то, доказываем, что есть некий объект. В данном
[38:42.320 --> 38:52.960]  случае хороший код. Иногда какой-нибудь хороший граф, иногда еще что-нибудь хорошее. Но мы не
[38:52.960 --> 39:00.280]  имеем примера этого графа. У нас просто есть голая теорема существования. А нам хочется,
[39:00.280 --> 39:05.560]  хочется иметь какой-то явный пример. По самым разным причинам хочется. В фундаментальной науке
[39:05.560 --> 39:10.600]  тоже есть задачи такого же типа, где мы можем доказать, что что-то существует, но ни одного
[39:10.600 --> 39:15.280]  явного примера построить не можем, и это фундаментальнейшая проблема теоретической
[39:15.280 --> 39:27.040]  информатики. А что делать? Вот все успешные примеры, ну почти все, я извиняюсь, почти все
[39:27.040 --> 39:34.400]  успешные примеры такого рода, основаны, как ни странно, на такой идее. Нужно из комбинаторной
[39:34.400 --> 39:40.440]  задачи сделать алгебрическую. Вот зачем нам нужна алгебра? Если у нас есть, мы уже знаем,
[39:40.440 --> 39:47.000]  что что-то существует, но мы хотим увидеть это явно. Вот для того, чтобы увидеть что-то явно,
[39:47.000 --> 39:53.600]  нам нужна алгебра. Иногда более сложная, иногда менее сложная. То есть, вот скажем, я говорил про
[39:53.600 --> 39:58.360]  графы, есть такие графы-экспандеры, там в начале доказательства использовали очень сложную алгебру.
[39:58.360 --> 40:08.000]  И не только алгебру, теорию модулярных форм, с помощью которой гипотезу Ферма доказали, а потом
[40:08.000 --> 40:13.880]  была придумана очень практичная схема, более комбинаторная, но в основе которой все равно лежит
[40:13.880 --> 40:19.200]  алгебра, только линейная алгебра. Но там довольно нетривиальные рассуждения, связанные с линейной
[40:19.200 --> 40:24.760]  алгеброй, собственными числами, и так далее. То есть, совсем от алгебры не избавиться, а как минимум
[40:24.760 --> 40:32.280]  нужна линейная алгебра. Но иногда нужны вот конечные поля. Ну вот я начну тоже с линейной алгебры,
[40:32.280 --> 40:37.320]  но давайте, наверное, в этот момент я сделаю перерыв, как раз сейчас самое время, давайте прервемся
[40:37.320 --> 40:44.320]  на 5 минут, и после перерыва я начну реализовывать эту ивристику. То есть, мы хотим более явные
[40:44.320 --> 40:50.200]  конструкции для кода, и я буду постепенно подливать алгебру, чтобы конструкции становились полов.
[40:50.200 --> 41:00.800]  Да, ну давайте начинать. Постепенно рассаживайтесь. Звонков я как-то не слышу. Итак, пока вы
[41:00.800 --> 41:05.960]  рассаживайтесь, я напомню, ничем я остановился. Я остановился на той идее, что нужно для построения
[41:05.960 --> 41:13.240]  явных хороших кодов, хороших, которые достигают границы Варшавма-Гилдерта или вообще садятся на
[41:13.240 --> 41:22.920]  границу Хэминга. Это уж не просто хорошие, а совершенные коды. Нам нужна алгебра. И первый шаг
[41:22.920 --> 41:28.920]  состоит в том, чтобы использовать линейную алгебру. И возникает то, что называется линейные коды.
[41:28.920 --> 41:46.040]  У нас есть такая объекция между словами длины n двоичными и координатным векторным пространством
[41:46.040 --> 41:50.600]  над полем из двух элементов. Ведь что такое координатное векторное пространство над полем из
[41:50.600 --> 41:57.600]  двух элементов? Два элемента это как раз 0,1. И нам нужно, чтобы у нас есть вектор размерности n,
[41:57.600 --> 42:02.920]  то есть у нас фиксирован базис, координатное пространство. И вот на каждой позиции написан 0 или 1,
[42:02.920 --> 42:12.200]  но это и получается двоичное слово. И код называется линейным, если он под пространство.
[42:12.200 --> 42:34.440]  Смотрите, мы странным образом себя связываем руки. Из комбинаторных соображений можно
[42:34.440 --> 42:39.240]  рассматривать любое множество. Мы говорим, давайте мы будем рассматривать только под пространство.
[42:39.240 --> 42:47.040]  Но это лишние условия. Тем не менее, эти лишние условия нам позволяют легче строить явные конструкции,
[42:47.040 --> 42:53.000]  и вообще всякие улучшения сделать в той комбинаторной картине, которая у меня есть.
[42:53.000 --> 43:04.560]  И тогда заметьте, что слово размерность приобретает очень естественный смысл. Потому что сколько в
[43:04.560 --> 43:13.680]  подпространстве точек? Ну, количество элементов поля в степени размерность пространства. То есть два в
[43:13.680 --> 43:20.600]  степени как, как раз. Поэтому и слово размерность, дело в том, что большую часть теории корректирующих
[43:20.600 --> 43:27.640]  кодов составляет изучение именно линейных кодов, потому что у них есть разные достоинства и
[43:27.640 --> 43:35.680]  конструкций много. А с нелинейными кодами все гораздо сложнее. Ну, в общем, линейные коды – это
[43:35.680 --> 43:45.760]  основная часть этой теории. Какие возникают упрощения? Во-первых, кодовое расстояние. Для него
[43:45.760 --> 43:54.520]  теперь можно написать более простую формулу. Я напомню, что норма х – это количество единиц в
[43:54.520 --> 44:00.640]  х. И кодовое расстояние линейного кода – это просто минимум нормы по всем ненулевым векторам.
[44:00.640 --> 44:07.600]  Ну, фактически это здесь вот написано. Дело в том, что давайте я прям здесь это напишу. Что такое
[44:07.600 --> 44:18.600]  расстояние от х до у? Это норма разности. Смотрите, если я возьму разность, ну, по модулю 2, что разность
[44:18.600 --> 44:23.120]  у суммы – это одно и то же, конечно. Но что у меня в разности останется? Где будут стоять единицы? Там,
[44:23.120 --> 44:30.320]  где х и у различаются. Там, где х и у одинаковые, будут стоять нули. Поэтому количество позиций,
[44:30.320 --> 44:35.680]  в которых различаются х и у – это количество позиций, в которых в их разности, ну, или сумме,
[44:35.680 --> 44:46.160]  как вам угодно, стоят единицы. Ну, а дальше понятно. Если код линейный, то из того, что х принадлежит
[44:46.160 --> 44:52.720]  С, следует, что х-у тоже принадлежит С. Поэтому, если у меня минимум достигается на какой-то паре,
[44:52.720 --> 44:58.720]  он обязательно будет достигаться на паре 0 и этот х. Это, кстати, и объясняет, почему радиус,
[44:58.720 --> 45:08.520]  в смысле, объем шара радиуса r не зависит от центра, потому что у нас, ну, есть вот такое вот сдвиг
[45:08.520 --> 45:15.080]  в линейном пространстве. Мы просто добавим вектор из нуля в точку а. И это будет биекция,
[45:15.080 --> 45:20.760]  которая сохраняет расстояние. Ну, это мелкое техническое упрощение. Я просто дальше,
[45:20.760 --> 45:24.520]  когда буду говорить про кодовое расстояние, буду все время его измерять вот таким вот способом.
[45:24.520 --> 45:32.640]  Вольная существенная вещь – задание кода. Есть два важных способа задания кода.
[45:32.640 --> 45:50.160]  Я думаю, что, поскольку вы линейную алгебру учите,
[46:02.640 --> 46:15.400]  ну, пусть над r, но, как я уже говорил, до некоторого момента линейная алгебра над любым полем одинакова,
[46:15.400 --> 46:22.200]  как задать подпространство? Первый способ, самый важный для линейной алгебры подпространство
[46:22.200 --> 46:27.480]  задается как множество решений системы однородных линейных уравнений. Вот я их написал. У меня есть
[46:27.480 --> 46:33.000]  некоторая матрица h, и множество решений системы уравнений hх равняется нулю. Это подпространство.
[46:33.000 --> 46:44.240]  Это легко проверить, потому что если h от x равно нулю, h от y равно нулю, h от x плюс y тоже равно нулю
[46:44.240 --> 46:50.360]  из обычных свойств матричного умножения. Но есть другой способ. Мы можем задать подпространство
[46:50.360 --> 47:01.000]  базисом. Этот базис будет задаваться тем, что называется порождающая матрица. Обычно мы считаем тогда,
[47:01.000 --> 47:13.040]  что у нас кодовые векторы являются строками, и вот мы выписываем этот базис как строки некоторой
[47:13.040 --> 47:20.400]  матрицы. Она называется порождающая. Переход от проверочной к порождающей матрицы осуществляется
[47:20.400 --> 47:24.480]  обычными алгоритмами линейной алгебры, то есть решение системы линейных уравнений. Там все над
[47:24.480 --> 47:32.080]  любым полем одинаково. Всключение гауса, все будет работать. Какие-то более экзотические алгоритмы
[47:32.080 --> 47:38.240]  может работать не будут, но стандартные, которые вам рассказывали, все будут работать. Чем удобна
[47:38.240 --> 47:45.160]  такая вещь? Теперь у нас появляется очень простой алгоритм кодирования. Все, что нам нужно, это
[47:45.160 --> 47:52.680]  создать вот эту порождающую матрицу. Если мы хотим передать ка битов, мы должны просто взять сумму
[47:52.680 --> 47:59.760]  по модулю 2 соответствующих базисных векторов, умножить на порождающую матрицу и вот сунуть в
[47:59.760 --> 48:07.800]  канал то, что получилось. И вот это уже даже в теплые ламповые времена было технически посильно.
[48:07.800 --> 48:15.960]  То есть инженеры могли, если им говорили, что вот у нас будет передаваться там, не знаю, 11 битов,
[48:15.960 --> 48:25.120]  а кодовых битов 15, они брались сделать соответствующую схему, которая будет реализовывать
[48:25.120 --> 48:31.200]  вот такое умножение на матрицу. Умножение на матрицу это все-таки очень простая операция. Поэтому
[48:31.200 --> 48:42.040]  ее выполнение было разумно. То есть с самого начала было ясно, что вот такие проверки,
[48:42.040 --> 48:48.600]  они хорошие. То есть такие коды, они хорошие. И проверять их легко. То есть смотрите, если мы
[48:48.600 --> 48:54.720]  на выходе получили точку не из кода, у нас hx, то есть когда у нас есть проверочная матрица,
[48:54.720 --> 49:00.480]  она будет не ноль. То, что получается, называется синдромом. И все алгоритмы декодирования линейных
[49:00.480 --> 49:06.400]  кодов так или иначе завязаны на работу в синдром. Другое дело, что в общем случае задача декодирования
[49:06.400 --> 49:13.120]  линейного кода очень трудна. Вот кодировать все хорошо, а декодировать уже плохо. Но про декодирование
[49:13.120 --> 49:20.240]  я практически ничего говорить не буду. Я буду говорить про кодирование. И вот теперь первый
[49:20.240 --> 49:27.440]  нетривиальный пример кода. Пока я про совершенные коды только сказал, но это по сути дела и будет.
[49:27.440 --> 49:30.840]  Пример из этой области.
[49:39.720 --> 49:52.960]  Это знаменитый код Хэмин. Он конечно не только используется в задачах передачи и восстановления
[49:52.960 --> 49:59.040]  информации, но поскольку конструкция очень простая и изящная, у него есть много приложений и в
[49:59.040 --> 50:05.840]  комбинаторике, в теоретической информатике. Что такое код Хэмин? Параметры у него такие. Длина кода
[50:05.840 --> 50:21.880]  N. Степень двойки без единицы. Размерность еще на S меньше. То есть вот у нас N это 2 в степени S-1,
[50:21.880 --> 50:30.800]  а размерность это 2 в степени S-1-S. И я сейчас задам порождающую матрицу для этого кода. Он
[50:30.800 --> 50:37.080]  линейный. Конечно код Хэминга можно задавать очень по-разному, как все по-настоящему интересные
[50:37.080 --> 50:42.560]  конструкции. Он допускает много описаний, но я вот выберу то, которое мне наиболее удобно.
[50:42.560 --> 50:57.120]  Значит смотрите, как устроена порождающая матрица. Она имеет квадратный блок размера 2 в степени S-1-S,
[50:57.120 --> 51:04.000]  состоящий из единичной матрицы. И добавочку, она прямоугольная, потому что смотрите,
[51:04.000 --> 51:19.680]  мне нужно, чтобы у меня было K-строк и N-столбцов. Добавочка состоит из всех векторов двоичных
[51:19.680 --> 51:34.560]  длины S, у которых хотя бы две единицы. Сколько таких векторов? Ну проще посчитать дополнение,
[51:34.560 --> 51:41.800]  сколько векторов, которых не больше одной единицы. Но это как раз Хэминга в шар радиуса 1. То есть
[51:41.800 --> 51:49.280]  одна точка, и еще N, это биномиальный квитцент из N по единице. То есть вот здесь у нас получится
[51:49.280 --> 52:01.240]  всего у нас два в степени S минус, ну вот это вот самое, то есть это объем шара радиуса,
[52:01.240 --> 52:15.320]  S-мерного шара радиуса 1. И это ровно столько, сколько нам нужно, это и есть наш параметр K. Вот из
[52:15.320 --> 52:21.760]  чего состоит код Хэминга. Он состоит из S-слов, двоичных слов длины N, которые являются стуммами
[52:21.760 --> 52:27.360]  строк этой матрицы. То есть мы можем взять произвольное под множество строк этой матрицы,
[52:27.440 --> 52:33.800]  взять сумму по модулю 2 и послать. Это и будет код соответствующего сигнала. То есть если у меня
[52:33.800 --> 52:40.760]  здесь есть какое-то сообщение, то мне надо вот просто взять сумму вот этих вот.
[52:40.760 --> 52:54.040]  Строк, сложить их по модулю 2, и это и будет элемент кода Хэминга. Давайте я его сразу вот так вот
[52:54.040 --> 53:02.560]  отошел. Ну я еще не определил кодовое расстояние. Какое кодовое расстояние у кода Хэминга?
[53:02.560 --> 53:14.360]  Утверждается, что оно равно 3. То есть код Хэминга исправляет одну ошибку при любом N. То есть если N
[53:14.360 --> 53:22.800]  поменьше, то цена одной ошибки, она как бы выше. Если N совсем большое, то платим мы совсем мало,
[53:22.800 --> 53:33.560]  заметьте, у нас K и N отличаются на вагарифм N. Платим мы совсем мало, но и исправляем не очень
[53:33.560 --> 53:40.200]  много. Но на самом деле код Хэминга очень хорош. Давайте я докажу сейчас, что D равно 3, а потом
[53:40.200 --> 53:46.160]  обсудим насколько хорош код Хэминга. Ну смотрите, любое кодовое слово, что мне нужно доказать?
[53:46.160 --> 53:52.840]  Мне нужно доказать, что в любом ненулевом кодовом слове хотя бы 3 едини. Любое кодовое слово
[53:52.840 --> 54:13.000]  сумма ну каких-то Q строк. Давайте смотреть, если Q равно единицы, тогда по построению в каждой
[54:13.000 --> 54:18.520]  строке не меньше трех единиц. Смотрите, есть единица в том блоке, который отвечает единичной
[54:18.520 --> 54:24.920]  матрице, а вот здесь в каждой строке я специально выбрал только те слова двоичные, в которых хотя
[54:24.920 --> 54:33.160]  бы две единицы. Значит здесь больше либо равно 3. Теперь если Q равно 2, тогда смотрите, вот я взял
[54:33.160 --> 54:38.640]  две какие-то строки. У меня в этой части, когда я беру сумму по модулю 2, здесь же стоит единица,
[54:38.640 --> 54:45.160]  здесь ноль, здесь единица, здесь ноль. У меня две единицы уже будут. А в правой части будет хотя бы
[54:45.160 --> 54:53.440]  одна единица. Почему? Потому что здесь написаны разные двоичные слова. Дума по модулю 2,
[54:53.440 --> 55:00.720]  два разных слов не может равняться нулю. Поэтому у меня получается, что единиц не меньше чем 2
[55:00.720 --> 55:07.720]  плюс 1. Ну и наконец, если я беру сумму больше чем трех строк, то у меня вот в левой части уже
[55:07.720 --> 55:16.680]  будет хотя бы три единицы. Всё, я доказал, что кодовое расстояние 3, но оно реализуется, естественно,
[55:16.680 --> 55:22.120]  потому что у меня просто есть строки, в которых всего три единицы. То есть я сразу вижу из порождающей
[55:22.120 --> 55:28.600]  матрицы, что больше чем 3 кодовое расстояние быть не может. Ну и меньше оно быть не может,
[55:28.600 --> 55:41.960]  как вот я сейчас показал. И теперь смотрите, я где-нибудь здесь напишу. Давайте сравним с границей
[55:41.960 --> 55:58.960]  Хемминга. Значит у меня вот столько кодовых слов, а с другой стороны граница Хемминга говорит мне,
[55:58.960 --> 56:08.520]  что их не больше, чем два степенен поделить на b, ну у меня r равно единице n, то есть на самом деле
[56:08.520 --> 56:17.560]  здесь написано n плюс 1. Давайте подставим n, который у меня есть. Это получается 2 в степени 2 в степени s
[56:17.560 --> 56:24.760]  минус 1 поделить, n это 2 в степени s минус 1, плюс 1 это 2 в степени s. Ну смотрите, это то же самое,
[56:24.760 --> 56:30.920]  2 в степени 2 в степени s минус 1, да еще поделить на 2 в степени s. Это 2 в степени s минус 1 минус s.
[56:30.920 --> 56:41.000]  Это и есть количество слов коди Хемминга. Значит мы получили пример совершенного кода,
[56:41.000 --> 56:46.880]  причем бесконечно много примеров.
[57:00.920 --> 57:12.040]  Но при фиксированном кодовом расстоянии, то есть примеров бесконечно много, но все они дают нам только исправление одной ошибки.
[57:12.040 --> 57:23.520]  Зато лучше не бывает, то есть мы достигли максимума возможного. Код Хемминга дает нам разбиение
[57:23.520 --> 57:36.280]  соответствующего булева куба на шары радиуса 1. Ну а если нам хочется исправлять больше ошибок,
[57:36.280 --> 57:49.080]  две, три, пять, десять, код Хемминга нам не поможет. Ну вот если три ошибки исправлять,
[57:49.080 --> 57:56.720]  это знаменитый код Галлея, я в следующий раз о нем скажу, но у него фиксированные значения параметра.
[57:56.720 --> 58:14.120]  N 23, 11 или 12, по-моему все-таки 11. Тут я могу ошибиться, может быть 12, а D7. Но это мы в следующий раз проверим.
[58:14.120 --> 58:25.280]  Тут исправляются три ошибки, но при конкретном значении блочной длины. Для техники это не так плохо,
[58:25.280 --> 58:30.560]  потому что обычно и нужна какая-то фиксированная длина. В частности, код Галлея использовался реально при
[58:30.560 --> 58:38.120]  кодировании информации на компакт-дисках. Других совершенных кодов двоичных нет, вот это весь список.
[58:38.120 --> 58:45.800]  Теорема, я говорю, она довольно трудная, я не буду ее доказывать, но это так. А если хотите
[58:45.800 --> 58:52.200]  справлять другое количество ошибок или на другой длине, что делать? Тут нужно больше алгебр.
[58:52.200 --> 59:03.400]  Нам не хватит только линейные алгебры. На самом деле, точнее так, бывают конструкции линейных кодов,
[59:03.400 --> 59:12.280]  основанные уже на линейной алгебре и некоторой нетривиальной комбинаторике, которая не требует
[59:12.280 --> 59:16.680]  больше алгебры в том смысле, в который я в это вкладываю. Там нужна только линейная алгебра.
[59:16.680 --> 59:21.400]  Но линейная алгебра нужна нетривиально, это те самые графы и экспандеры, о которых я упоминал.
[59:21.400 --> 59:26.080]  Я про эти коды рассказывать не буду, опять-таки, за недостатком времени. Это очень остроумная
[59:26.080 --> 59:29.840]  конструкция, но там надо вначале объяснить, что такое экспандеры, иначе ничего не понятно.
[59:29.840 --> 59:39.920]  А я расскажу по сути дела примеры кодов, в частности, там будет код Галлея среди этих примеров,
[59:39.920 --> 59:47.280]  но там будут коды, которые почти достигают границы хемминга, если количество ошибок фиксировано.
[59:47.280 --> 59:54.080]  Блочная длина большая, а количество ошибок фиксировано. То есть, скажем, n стремится к
[59:54.080 --> 59:59.080]  бесконечности, а количество ошибок фиксировано. Тогда эти коды очень хороши. Но это я в следующий
[59:59.080 --> 01:00:14.120]  раз буду обсуждать, пока я хочу сделать следующий шаг. Что такое координатное векторное пространство?
[01:00:14.120 --> 01:00:32.040]  Его можно отождествить с кольцом вычета. Я буду такое кольцо называть циклическим,
[01:00:32.040 --> 01:00:38.760]  для краткости. Это вычеты кольцам многочленов с коэффициентами в поле из двух элементов по
[01:00:38.760 --> 01:00:47.560]  модулю многочлена х в степени n без единицы. И из чего оно состоит? Мы знаем, что в каждом
[01:00:47.560 --> 01:00:57.360]  классе вычетов есть ровно один многочлен в степени меньше n. То есть, фактически у нас
[01:00:57.360 --> 01:01:07.680]  базисом будут вот такие вычеты, содержащие степени х до n-1. Это общее явление, тут пока я
[01:01:07.680 --> 01:01:16.600]  не использую вот то, что у меня многочлен вот такой. И у нас получается координатное пространство.
[01:01:16.600 --> 01:01:23.960]  То есть, когда я буду говорить о этом кольце, в принципе, это векторное пространство над полем из
[01:01:23.960 --> 01:01:29.920]  двух элементов, там может быть много базисов, но в контексте кодирования мне нужно зафиксировать
[01:01:29.920 --> 01:01:35.280]  базис. И фиксировать я его буду всегда именно вот так. То есть, у меня базис это просто степень х.
[01:01:35.280 --> 01:01:50.240]  Самый естественный базис. Но зачем мне нужна эта структура? Смотрите, тут я связал себе руки не
[01:01:50.240 --> 01:01:55.320]  очень сильно. Я потребовал только, чтобы код был в линейном пространстве. Это недостаточно сильно.
[01:01:55.320 --> 01:02:00.560]  Нужно еще кляв в рот воткнуть или там, я не знаю, приковать кандалы на ноги. Нужно потребовать,
[01:02:00.560 --> 01:02:16.080]  чтобы код был идеалом в этом кольце. И будет нам счастье. То есть, я хочу подчеркнуть, что это на
[01:02:16.080 --> 01:02:21.120]  самом деле некоторая общая евристика. То есть, когда вы строите явную алгебрическую конструкцию,
[01:02:21.120 --> 01:02:26.320]  нужно догадаться до того, какие условия нужно дополнительно наложить на вашу комбинаторику.
[01:02:26.440 --> 01:02:31.440]  Комбинаторика слишком рыхлая. Там с одной стороны все есть, с другой стороны непонятно, как строить.
[01:02:31.440 --> 01:02:37.200]  А если вы добавляете какие-то жесткие алгебрические условия, у вас остается меньше свободы. И если вы
[01:02:37.200 --> 01:02:43.400]  угадали, если вы правильно добавили условия, у вас все получается. Но вот тут вся хитрость состоит в том,
[01:02:43.400 --> 01:02:53.800]  что нужно правильно добавить. То есть, циклическим кодом я буду называть идеал. Идеал, конечно,
[01:02:53.800 --> 01:02:58.600]  подпространство. Это мы знаем. Это подгруппа аддитивной гуглы. Но замкнуто еще относительно
[01:02:58.600 --> 01:03:05.200]  умножения. И слово циклический связано с тем, что вот это свойство быть идеалом имеет еще
[01:03:05.200 --> 01:03:22.240]  другую интерпретацию. Давайте рассмотрим сдвиг на нашем базисе. S это оператор сдвига. То есть,
[01:03:22.240 --> 01:03:31.440]  если у меня есть вектор 0, 1, 1, 0, скажем, то S на него подействует так. Это будет 0, 0, 1, 1. Смотрите,
[01:03:31.440 --> 01:03:43.080]  я х нулевой отправляю в х1. Это вот это вот. х1 в х2, х2 в х3, х3 в нулевую, потому что у меня
[01:03:43.080 --> 01:03:48.120]  код имеет длину n. Так вот, лемма.
[01:04:13.080 --> 01:04:26.920]  Подпространство я называю циклическим, если оно замкнуто относительно оператора сдвига. То есть,
[01:04:26.920 --> 01:04:33.200]  если у вас есть вектор из пространства, то сдвигая его координаты, вы снова получаете вектор из этого
[01:04:33.200 --> 01:04:40.440]  же пространства. Так вот, идеал вот в этом циклическом кольце, это в точности циклическое
[01:04:40.440 --> 01:04:47.920]  пространство. То есть, пока мы могли бы обойтись линейной алгеброй, просто используя оператор
[01:04:47.920 --> 01:04:53.800]  сдвига. Его же можно просто определить без всяких вычетов. Ну вот, у меня есть координаты там 0, 1,
[01:04:53.800 --> 01:05:00.800]  там n-1. Оператор сдвига переносит эту координату в плюс первую пазису. Дальше мне, конечно,
[01:05:00.800 --> 01:05:06.200]  алгебра будет существенно нужна. Но давайте докажем эту лему. Она нам будет полезна.
[01:05:06.200 --> 01:05:22.680]  В доказательстве этой леммы я фактически использую ровно одно соображение. Как действует оператор
[01:05:22.680 --> 01:05:29.080]  сдвига на произвольный вектор в нашем пространстве? Он умножает на x его. И это достаточно очевидно.
[01:05:29.080 --> 01:05:34.280]  Смотрите, произвольный вектор – это сумма вот таких степеней. Если я действую оператором сдвига,
[01:05:34.360 --> 01:05:39.520]  он линейный, значит, я каждую степень сдвигаю на единицу, координаты не меняются. Поэтому
[01:05:39.520 --> 01:05:47.920]  это получается умножение на x. Отсюда что следует? Если у меня есть идеал. Пусть у меня это идеал.
[01:05:47.920 --> 01:06:00.920]  Давайте рассмотрим, подействуем до f какой-то элемент этого идеала. Давайте подействуем
[01:06:00.920 --> 01:06:11.680]  оператором сдвига на f. Это получится x на f от x. И это снова принадлежит идеалу,
[01:06:11.680 --> 01:06:16.320]  потому что оператор сдвига – это умножение на x. А мы знаем, что идеал замкнут относительно
[01:06:16.320 --> 01:06:22.520]  умножения на любой элемент кольца. Но я доказал включение, а у меня там равенство.
[01:06:22.520 --> 01:06:33.440]  Это следует просто из того, что s-1 обратимо. Если у меня есть сдвиг вправо, то у меня есть
[01:06:33.440 --> 01:06:41.480]  сдвиг влево, который i-ую координату переводит v-1, то есть i-ую степень v-1. И понятно,
[01:06:41.480 --> 01:06:46.200]  что эти два оператора взаимно обратны. А раз они взаимно обратны, то смотрите,
[01:06:46.200 --> 01:06:56.760]  я отправил, у меня получилось, что s-j лежит в j, но раз s-1 обратимый оператор, то размерность
[01:06:56.760 --> 01:07:02.200]  этого пространства совпадает с размерностью j, значит они должны совпадать. Не может быть
[01:07:02.200 --> 01:07:06.360]  строгого включения пространства одинаковой размерности. Ну хотя бы потому, что количество
[01:07:06.360 --> 01:07:14.840]  точек – это два в степени размерности. Таким образом мы получаем, отсюда мы получаем уже
[01:07:14.840 --> 01:07:24.680]  строгая равенство. Ну и наоборот, если у меня есть равенство, то отсюда сразу следует, что x
[01:07:24.680 --> 01:07:30.120]  умножить, значит если у меня есть элемент циклического пространства, x умножить на f,
[01:07:30.120 --> 01:07:41.400]  тоже принадлежит этому пространству. Ну а тогда, если я умножаю на какой-то многочлен, который
[01:07:41.400 --> 01:07:52.360]  является суммой степеней x, то понятно, что получится. У меня получится сумма, когда я умножаю на x
[01:07:52.360 --> 01:07:58.880]  степени i, это я то же самое, что применяю оператор с двига и раз. Поэтому у меня каждый раз будет
[01:07:58.880 --> 01:08:03.960]  сохраняться вектор в этом пространстве, потом я возьму сумму, сумма векторов из-под пространства
[01:08:03.960 --> 01:08:10.680]  тоже лежит под пространстве, поэтому мы получаем, что умножение на любой элемент кольца оставляет
[01:08:10.680 --> 01:08:23.680]  нас внутри этого кольца, значит мы получаем в обратную сторону включение. Итак, мы доказали вот
[01:08:23.680 --> 01:08:30.520]  такое интересное свойство. Причем, заметьте, что я на самом деле специфику модуля 2 здесь не
[01:08:30.520 --> 01:08:36.120]  использовал. То есть, если вас интересует, представьте, что вас интересует над r под
[01:08:36.120 --> 01:08:42.960]  пространство, 9-мерного пространства, которое замкнуто относительно циклических сдвигов. То есть,
[01:08:42.960 --> 01:08:53.320]  если входит вот x1, x2, x9, то x2, x3, x9, x1 тоже входят. Это обязательно должен быть идеал только и того,
[01:08:53.320 --> 01:08:59.200]  что у вас вот здесь будет не поле из двух элементов, а поле действительных чисел. И алгебрические
[01:08:59.200 --> 01:09:04.920]  свойства у таких колец будут разными, потому что многочлен один и тот же x степени n без единицы,
[01:09:04.920 --> 01:09:13.680]  но в разных, над разными полями он будет раскладываться по-разному. Но, в принципе,
[01:09:13.680 --> 01:09:18.240]  циклические пространства иногда бывают нужны и для r, они ищутся примерно таким же способом.
[01:09:18.240 --> 01:09:36.560]  Таким образом, мы видим, что то, что нас интересует, вот это такая довольно симметричная
[01:09:36.560 --> 01:09:42.720]  конструкция, но теперь я хотел бы немножко конкретизировать, какие вообще бывают циклические
[01:09:42.720 --> 01:10:11.000]  коды. Первое замечание, давайте я его где-нибудь здесь напишу, rn кольцо главных идеалов. Это не
[01:10:11.000 --> 01:10:15.320]  столь очевидно, потому что оно не является эвклидовым кольцом, но у нас есть сюръективный
[01:10:15.320 --> 01:10:21.840]  гаммарфизм. Канонический гаммарфизм, это же кольцо вычетов, есть канонический гаммарфизм из кольцам
[01:10:21.840 --> 01:10:27.280]  многочленов с коэффициентами из поля из двух элементов наших, кольцо rn. Он сюръективный,
[01:10:27.280 --> 01:10:34.920]  если у меня здесь есть какой-то идеал, ну давайте я его как-нибудь фи обозначу, прообраз этого идеала
[01:10:34.920 --> 01:10:40.400]  тоже идеал, и он порожден каким-то одним многочленом, и тогда уже нетрудно доказать,
[01:10:40.400 --> 01:10:47.880]  что g, поскольку это сюръективный гаммарфизм, порожден образом этого многочлена. Это легко
[01:10:47.880 --> 01:10:58.760]  проверяется обычными вычислениями. Таким образом, первое наблюдение, которое можно сделать,
[01:10:58.760 --> 01:11:04.000]  циклический код еще лучше, чем просто линейный. Линейный код мы матрицей должны задавать,
[01:11:04.000 --> 01:11:11.520]  а здесь мы можем задать, я сейчас попробую правильно написать, но если не получится,
[01:11:11.520 --> 01:11:38.440]  я поправлю в следующий раз. Смотрите, как я думаю, что вот я написал двоичное слово длины 15. Оно
[01:11:38.440 --> 01:11:44.400]  задает некоторый циклический код. Каким способом? Ну понятно каким. Я буду брать просто все циклические
[01:11:44.400 --> 01:11:51.880]  сдвиги этого вектора и их сумму. Другими словами, я могу сказать так, у меня есть многочлен единица
[01:11:51.880 --> 01:12:08.800]  плюс 1, 2, 3, 4, x4, x5, x7, x8. И я порождаю этим многочленам, точнее классам вычетов в кольце
[01:12:08.800 --> 01:12:14.680]  вычета, вот таком циклическом кольце, когда x15 равняется единице, я порождаю идеал. То есть
[01:12:14.680 --> 01:12:18.720]  беру все кратные этого многочлена в этом кольце вычета. Не в кольце многочена, в этом кольце
[01:12:18.720 --> 01:12:24.800]  вычета. И это то же самое, как я только что показал, что суммы циклических сдвигов такого кольца,
[01:12:24.800 --> 01:12:31.720]  такого вектора. То есть совсем хорошо. У нас порождающая матрица совсем простая. Она вот,
[01:12:31.720 --> 01:12:38.360]  она вообще задается даже не матрицей, а вот одной строкой. Это инженеров вообще приводило
[01:12:38.360 --> 01:12:46.280]  в бешеный восторг, потому что нужно еще меньше радиоламп. Но, конечно, совершенно непонятно,
[01:12:46.280 --> 01:12:52.600]  какая размерность и какое кодовое расстояние у такого кода. Вот это тут нужна еще математика.
[01:12:52.600 --> 01:13:08.440]  И для начала давайте докажем такую лемму. Если у меня есть идеал в кольце Rn, то существует
[01:13:08.440 --> 01:13:25.960]  делитель многочлена х-1 такой, что он порождает тот же самый идеал. То есть когда эта лемма очень
[01:13:25.960 --> 01:13:31.320]  ограничивает нас в количестве разных циклических кодов, в сущности мы должны посмотреть, какие есть
[01:13:31.320 --> 01:13:37.760]  делители у многочлена х-1. Вот только они порождают, могут порождать какие-то разные коды. Все остальные
[01:13:37.760 --> 01:13:42.080]  многочлены будут порождать что-то то же самое. Ну, доказательство на самом деле очень простое.
[01:13:42.080 --> 01:13:56.560]  Смотрите, давайте возьмем наибольший общий делитель fх в n-1-1.
[01:13:56.560 --> 01:14:17.760]  И тогда f делится на g с тильдой и дополнительный делитель как раз вот тот самый g. Почему? Потому
[01:14:17.760 --> 01:14:24.240]  что я хочу сказать, что g с тильдой обратим в нашем циклическом кольце. Почему он обратим?
[01:14:24.240 --> 01:14:45.080]  Потому что он взаимнопрост с x в степени n-1. Ой, только тут все-таки g, да, я извиняюсь,
[01:14:45.080 --> 01:14:53.520]  а вот g с тильдой тогда взаимнопрост. То есть я беру наибольший общий делитель xn-1 f,
[01:14:53.520 --> 01:14:59.280]  а g с тильдой это дополнительный делитель. И вот дополнительный делитель взаимнопрост
[01:14:59.280 --> 01:15:16.320]  с x в n-1. Почему? Потому что, ну, смотрите, f это g с тильдой g, а x в n-1 это что-то то же g,
[01:15:16.320 --> 01:15:21.360]  но тут что-то написано, какой-то h. Вот это вот должны быть взаимнопростые,
[01:15:21.360 --> 01:15:29.120]  потому что g это наибольший общий делитель. Ну, значит g с тильдой будет
[01:15:29.120 --> 01:15:53.120]  взаимнопрост с xn-1. Непонятно, да? Это тонкое место, давайте его сейчас обсудим более аккуратно.
[01:15:53.120 --> 01:16:14.960]  Значит, вот смотрите, я нашел наибольший общий делитель fxn-1-1. Тогда, вот если я смотрю на g с тильдой,
[01:16:14.960 --> 01:16:20.240]  предположим, что g с тильдой xn-1-1 имеют общий делитель, но тогда g не будет наибольшим
[01:16:20.240 --> 01:16:26.320]  общим делителем, потому что этот делитель могу убрать, добавить в g. Значит, они должны быть
[01:16:26.320 --> 01:16:34.720]  взаимнопросты. Но вот это вот означает, что, вот как раз вот это, что g с тильдой обратим. Это общее
[01:16:34.720 --> 01:16:42.560]  свойство, раз с g с тильдой взаимнопросто, мы это уже много раз разбирались, тогда у нас есть
[01:16:42.560 --> 01:16:49.840]  какой-то многочлен h1, умноженный на g с тильдой, плюс xn-1 умножить на h2, так что это равняется
[01:16:49.840 --> 01:16:59.440]  единице, и мы видим, что по модулю многочлена xn, xvent и минус 1, g с тильдой имеет обратный. Но
[01:16:59.440 --> 01:17:07.400]  общая наука, которую мы изучали, говорит, что f отличается от g на обратимый элемент кольца,
[01:17:07.400 --> 01:17:13.280]  но тогда идеалы, которые порождают, совпадают. Умножение на обратимый элемент не меняет
[01:17:13.280 --> 01:17:24.840]  идеала, мы это обсуждали. Ну и все, мы получили вот это вот утверждение. Оно мало того, что
[01:17:24.840 --> 01:17:31.840]  ограничивает репертуар циклических кодов, но оно и позволяет очень быстро найти размерность
[01:17:31.840 --> 01:17:39.240]  циклического кода. Вот пусть у меня есть теперь делитель какой-то, то есть если я циклический
[01:17:39.240 --> 01:17:45.440]  код представляю не просто идеалом каким-то, а идеалом, порожденным делителем xvent и минус 1,
[01:17:45.440 --> 01:17:52.040]  предыдущая лемма гарантирует, что так всегда можно сделать. Тогда, значит, вот у нас код,
[01:17:52.400 --> 01:18:06.840]  он порожден этим делителем, когда размерность равна n минус степень вот этого вот самого
[01:18:06.840 --> 01:18:19.880]  делителя. И это тоже очень легко. Ну смотрите, я опять рассматриваю дополнительный множитель,
[01:18:19.880 --> 01:18:26.320]  вот это вот, это на самом деле степень дополнительного множителя. По обычному
[01:18:26.320 --> 01:18:32.720]  свойству степени. Тут степень n, тут степень g, плюс степень g с тильдой. Предположим,
[01:18:32.720 --> 01:18:39.760]  что у меня есть два разных многочлена, таких что их степени меньше, чем степень g с тильдой.
[01:18:39.760 --> 01:18:58.760]  Тогда давайте посмотрим на соответствующие элементы идеала. Я утверждаю, что они не равны.
[01:18:58.760 --> 01:19:08.560]  Ну почему? Предположим, что они равны. Это бы означало, что h1 минус h2 умножить на g нулевой
[01:19:08.560 --> 01:19:20.440]  идеал. То есть в кольце многочлена в это бы означало, что h1 минус h2 умножить на g делится на
[01:19:20.440 --> 01:19:33.320]  x в n-t минус 1. Это g означает, что это нулевой. Но вот здесь степень меньше, чем степень
[01:19:33.320 --> 01:19:37.760]  дополнительного множителя. Ну а здесь степень это степень g. А в сумме вот тут равно n. То есть
[01:19:37.760 --> 01:19:46.760]  тут степень n, а тут степень меньше. Пришли к противоречию. Таким образом, я уже нашел ну вот
[01:19:46.760 --> 01:19:56.840]  там два в степени n минус степень g различных элементов в моем идеале. Нужно доказать,
[01:19:56.840 --> 01:20:03.280]  что больше не бывает. Это совсем легко. Предположим, что у меня есть какой-то
[01:20:03.280 --> 01:20:14.720]  элемент из идеала. То есть кратный g с f. Я f могу поделить на g стильной состатком.
[01:20:14.720 --> 01:20:37.920]  И тогда смотрите f g будет равняться q на g g с тильдой плюс r g. Но вот это g g с тильдой
[01:20:37.920 --> 01:20:43.480]  это x в n-t минус 1. Это ноль в нашем циклическом кольце, потому что вот это произведение это
[01:20:43.480 --> 01:20:52.760]  уже x в n-t минус 1. А у нас мы рассматриваем вычеты по модулю этого многочлена. Значит в кольце rn это
[01:20:52.760 --> 01:20:59.800]  просто-напросто r g. То есть это ровно те многочлены, которые я перед этим построил, потому что нулевой или
[01:20:59.800 --> 01:21:07.280]  в многочлен степени меньше, чем g стиль. Таким образом, вот это равенство доказано. Значит,
[01:21:07.280 --> 01:21:13.720]  ну у меня время вышло, я подведу итог. Значит циклические коды мы с ними довольно хорошо разобрались.
[01:21:13.720 --> 01:21:19.760]  Во-первых, чтобы их строить нам нужно знать, какие бывают делители у x в n-t минус 1. Во-вторых,
[01:21:19.760 --> 01:21:25.400]  если мы это знаем, мы уже знаем размерность. Третий параметр, самый интересный, кодовое расстояние.
[01:21:25.400 --> 01:21:31.200]  Вот с ним сложно. Общего хорошего способа найти кодовое расстояние для произвольного циклического
[01:21:31.200 --> 01:21:37.920]  кода. Вот выписали мне вектор и говорите, а какое будет кодовое расстояние? Его нету. То есть вот такое
[01:21:37.920 --> 01:21:41.680]  вот порождающее найти легко, потому что вы видите, нам нужно просто приймать алгоритмы вклида,
[01:21:41.680 --> 01:21:47.960]  чтобы найти. Размерность находится быстро, а кодовое расстояние нет. Но в некоторых случаях
[01:21:47.960 --> 01:21:53.680]  его удается найти. И вот про это я буду рассказывать в следующий раз. На сегодня все.
