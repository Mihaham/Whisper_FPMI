[00:00.000 --> 00:20.000]  Данил задал вопрос в телеграмме насчёт этого места в доказательстве.
[00:20.000 --> 00:45.000]  Первое возражение было, что грузы в последней группе имеют веса не меньше епсилона.
[00:45.000 --> 00:53.000]  Давайте посмотрим, что мы здесь имеем.
[00:53.000 --> 00:59.000]  Просто не очень понятно, откуда ты берёс умножить 1 на епсилон.
[00:59.000 --> 01:23.000]  Он берётся оттуда, что в одну корзину влезает не более чем единица на епсилон грузов.
[01:23.000 --> 01:35.000]  Так, поэтому что?
[01:35.000 --> 01:56.000]  Значит грузы все не меньше епсилона.
[01:56.000 --> 02:19.000]  Значит, корзина должна образовываться на последнюю группу не меньше,
[02:19.000 --> 02:40.000]  чем n епсилон в квадрат делить на епсилон.
[02:40.000 --> 02:48.000]  Каждую корзину влезает не больше, чем единица на епсилон грузов.
[02:48.000 --> 02:55.000]  Так, окей.
[02:55.000 --> 03:01.000]  Нет, тогда всё равно получается n епсилон в кубе, да?
[03:01.000 --> 03:07.000]  Действительно так, но нам бы даже это не испортило рассуждение, если бы мы могли утверждать, что последняя корзина,
[03:07.000 --> 03:11.000]  ну вернее последний блок в нашем разбиении, он полный.
[03:11.000 --> 03:15.000]  Иначе нельзя оценить снизу их количество на епсилон в квадрате.
[03:15.000 --> 03:20.000]  Ну потому что последний блок, он может там любого размера быть, сколько угодно маленького,
[03:20.000 --> 03:23.000]  потому что ему не хватило просто объектов.
[03:23.000 --> 03:27.000]  Да, слушайте, а давайте мы может быть вот так вот сделаем.
[03:27.000 --> 03:39.000]  Вот здесь у нас вместо n епсилон в квадрате я напишу просто количество грузов в последнем блоке, да?
[03:39.000 --> 03:47.000]  Потому что мы выяснили, что наркоблоки отличаются только вот максимум, как максимум отличаются последним блоком.
[03:47.000 --> 03:56.000]  И вот этот оптимум не больше, чем вот этот оптимум плюс количество грузов в последнем блоке.
[03:56.000 --> 04:07.000]  Давайте я поэтому сюда поставлю число грузов в правом крайнем, как политический блок,
[04:07.000 --> 04:12.000]  прям крайне правый блок грузов в последнем блоке.
[04:12.000 --> 04:23.000]  Вот так, хорошо.
[04:23.000 --> 04:31.000]  И нам осталось показать, что число грузов в последнем блоке не больше, чем епсилон помножить на опт.
[04:31.000 --> 04:43.000]  Соответственно, давайте вот это вот мы тогда обозначим через q, да, какое-нибудь.
[04:43.000 --> 04:52.000]  И тогда вот здесь вот у нас будет не единица на епсилон, а по-видимому епсилон на q.
[04:52.000 --> 05:02.000]  Эпсилон на q. Следовательно, опт больше равен епсилон на q.
[05:02.000 --> 05:12.000]  Так, следовательно, q меньше или равняется опт или на епсилон? Нет.
[05:12.000 --> 05:18.000]  Мне не очень нравится.
[05:18.000 --> 05:28.000]  Так, что же хочется сказать?
[05:28.000 --> 05:38.000]  Что же хочется сказать?
[05:38.000 --> 05:44.000]  Его у нас грузов.
[05:44.000 --> 05:51.000]  Ну, условно будем считать порядка.
[05:51.000 --> 06:01.000]  Да, значит оптимум больше или равен, чем m делит на епсилон.
[06:01.000 --> 06:07.000]  Больше или равен, чем m делит на епсилон.
[06:07.000 --> 06:11.000]  Так.
[06:11.000 --> 06:19.000]  А у нас будет не единица на епсилон.
[06:19.000 --> 06:27.000]  Больше или равен, чем m делит на епсилон.
[06:27.000 --> 06:31.000]  Так.
[06:31.000 --> 06:45.000]  А вот эта штука q у нас меньше или равняется чем n на епсилон в квадрате.
[06:45.000 --> 07:09.000]  Значит сумма всех грузов больше или равняется чем епсилон помножит на m.
[07:09.000 --> 07:15.000]  Вот.
[07:15.000 --> 07:19.000]  Кажется, это тоже неправда.
[07:19.000 --> 07:27.000]  Это количество всех грузов, включая тех, которые меньше епсилона были.
[07:27.000 --> 07:35.000]  Давайте мы знаете, что сделаем.
[07:35.000 --> 07:45.000]  Я думаю, что мы вот здесь, вот здесь, когда убираем все грузы маленького веса,
[07:45.000 --> 07:55.000]  давайте считать, что вот это n, это уже количество грузов большого веса.
[07:55.000 --> 07:59.000]  Потому что с маленьким весом мы разбираемся совсем особым образом.
[07:59.000 --> 08:05.000]  И у нас в случае, когда мы маленькие веса докидываем, все равно жадно.
[08:05.000 --> 08:13.000]  И вот это рассуждение, кажется, что н нигде вообще не содержит.
[08:13.000 --> 08:19.000]  Если у нас хотя бы одна корзина открыта за счет маленьких грузов.
[08:19.000 --> 08:23.000]  Здесь просто никак н не фигурирует.
[08:23.000 --> 08:27.000]  А вот дальше уже вот это рассуждение с округлением.
[08:27.000 --> 08:31.000]  Здесь давайте считать, что n, это количество уже больших грузов.
[08:31.000 --> 08:35.000]  Здесь нам все равно абсолютно на маленькие грузы.
[08:35.000 --> 08:38.000]  Они никак не повлияли на количество корзин.
[08:38.000 --> 08:42.000]  Поэтому что считать, что они есть, что их нет?
[08:42.000 --> 08:45.000]  Вот здесь у нас получается...
[08:45.000 --> 08:51.000]  Вот представим, что временно хотя бы, что n, это количество больших грузов.
[08:51.000 --> 09:00.000]  Тогда количество, тогда сумма весов всех грузов у нас не меньше, чем ε на n.
[09:00.000 --> 09:08.000]  Да, с другой стороны, число грузов, ну и это соответственно нижняя оценка на оптимум.
[09:08.000 --> 09:13.000]  Получается у нас оптимум больше ли равен, чем ε на n.
[09:13.000 --> 09:27.000]  А вот у меньше ли равняется, чем n на ε в квадрате?
[09:27.000 --> 09:39.000]  Ну да, то есть получается, что у меньше ли равняется, чем ε на опт.
[09:39.000 --> 09:49.000]  Тут даже сразу получается, потому что у не больше, чем n на ε в квадрате.
[09:49.000 --> 09:53.000]  У больше ли равен, чем ε на n?
[09:53.000 --> 09:59.000]  И отсюда сразу следует вот это.
[09:59.000 --> 10:04.000]  Ну как вам такое?
[10:04.000 --> 10:09.000]  Да, теперь вроде все получается.
[10:09.000 --> 10:24.000]  Давайте я вот здесь тогда напишу, что будем считать,
[10:24.000 --> 10:38.000]  что n, это количество грузов, веса больше ли равных, чем ε.
[10:38.000 --> 10:42.000]  Больше ли равных, чем ε.
[10:42.000 --> 10:47.000]  Да, не упустил я этот момент.
[10:47.000 --> 10:58.000]  Сам упустил, что вот это разбегение должно происходить относительно оставшихся грузов.
[10:58.000 --> 11:07.000]  Кажется, что на анализ первого случая это совсем не влияет.
[11:07.000 --> 11:17.000]  Ну а оценка времени, поскольку мы работаем алгоритмом поиска точного решения только со оставшимися грузами,
[11:17.000 --> 11:22.000]  то вроде тоже все хорошо работает.
[11:22.000 --> 11:35.000]  Спасибо за уточнение и наблюдение, которое нам пришлось разрулить.
[11:35.000 --> 11:47.000]  Значит, следующее, что мы с вами будем делать, мы, по-моему, не трогали вообще никак, пока камевые жоры, так особо.
[11:47.000 --> 12:03.000]  Сегодня я хотел бы им заниматься и рассмотреть алгоритмы, ну такие жадные алгоритмы для камевых жоров.
[12:03.000 --> 12:13.000]  Мы с вами рассматриваем же матроиды, по-моему. Да, матроиды же у нас были, позапрошлый раз.
[12:13.000 --> 12:20.000]  Ну и сегодня тоже такая жадная тема, но немного другого.
[12:20.000 --> 12:34.000]  Значит, такие жадные ибристики в задаче ТСП.
[12:34.000 --> 12:51.000]  Задача камевые жора рассматривается в разных вариантах, в общем варианте, в метрическом варианте, в котором мы с вами на самом деле и будем работать,
[12:51.000 --> 13:06.000]  и в евклидовом варианте, чем они отличаются? В общем, у нас есть произвольный граф, произвольные функции весов.
[13:06.000 --> 13:11.000]  В метрическом варианте функция весов удовлетворяет неравенство треугольника обязательно.
[13:11.000 --> 13:29.000]  Вес каждого ребра не больше, чем вес АС плюс вес СВ для любой троицы, вершин А, В и С. Пройти напрямик между вершинами всегда не дороже, чем ходить через какую-то промежуточную.
[13:29.000 --> 13:40.000]  Причем вот это неравенство предполагает, что вообще ребро АВ всегда существует, если существует пара ребер АС и ЦВ.
[13:40.000 --> 13:49.000]  И из этого следует сразу, что граф должен быть, если он связанный вообще, то он должен быть полным.
[13:49.000 --> 14:04.000]  Все поголовно приближенные алгоритмы для задачек многоежёра рассматриваются именно в метрическом случае, в частности потому, что в общем случае ответ может быть нестандартный.
[14:04.000 --> 14:09.000]  То есть типа того, что давайте найдем гамильтонов цикл минимального веса.
[14:09.000 --> 14:13.000]  А ответ такой, что бабаха, этого цикла вообще и нет в графе.
[14:13.000 --> 14:20.000]  И непонятно, как в задаче с вот таким бинарным ответом вообще приближать решение.
[14:20.000 --> 14:24.000]  А вот в задаче метрической очевидно, что гамильтоновых циклов куча.
[14:24.000 --> 14:31.000]  Любая перестановка вершин – это гамильтонов цикл, но граф предлагаем связанному, то есть полному стало быть.
[14:31.000 --> 14:33.000]  Значит вопрос существования не стоит.
[14:33.000 --> 14:47.000]  То есть вот перед тем, как вообще задачу конвертировать в такую приближабельную, мы ее конвертируем в задачу, в которой во всяком случае решение всегда существует.
[14:47.000 --> 14:51.000]  Вот поэтому мы в частности рассматриваем только метрический случай.
[14:51.000 --> 15:03.000]  А еклида в случае – это ситуация, в которой вершина графа, вершина графа – это просто точки еклидового пространства.
[15:03.000 --> 15:21.000]  И вес. Другие – это норма. Ну не знаю, может тогда норма А-Б еклидова.
[15:21.000 --> 15:41.000]  Когда мы с вами рисуем какие-то иллюстрации, то конечно очень удобно рисовать их для еклидового случая, чтобы не подписывать вообще веса ребер в графе и не рисовать сам граф, как полный граф, на каком-то большом числе вершин.
[15:41.000 --> 15:50.000]  То есть рисуем просто точки какие-то на плоскости и сразу видим, какое ребро там дешевле, какое дороже, просто какое расстояние больше-меньше.
[15:50.000 --> 15:55.000]  Все примеры мы с вами будем рисовать как бы для еклидового случая.
[15:55.000 --> 16:06.000]  Но все алгоритмы, которые мы будем рассматривать, и анализ этих алгоритмов, во всяком случае сегодня, у нас будет соответствовать более общему метрическому случаю.
[16:06.000 --> 16:21.000]  Метрический случай – это в принципе не так плохо, потому что, например, любой граф, у которого веса ребер принадлежит множеству 1 и 2, он метрический.
[16:21.000 --> 16:30.000]  Потому что у нас в правой части будет всегда не меньше двойки, а в левой части будет всегда не больше двойки.
[16:30.000 --> 16:46.000]  Ну и понятно, что метрические графы, пожалуй, в жизни встречаются довольно часто, чаще всего не метрически.
[16:46.000 --> 16:57.000]  Плюс к тому, можно сконвертировать произвольный связанный граф в метрический граф, построив метрическое замыкание.
[16:57.000 --> 17:07.000]  Когда вы берете исходный граф, решаете для него задачу APSP, для карты пары вершин, ищете кратчайший путь.
[17:07.000 --> 17:16.000]  И метрическое замыкание, ну давайте я здесь такую волну нарисую.
[17:16.000 --> 17:30.000]  Подпишу, что это метрическое замыкание G. В метрическом замыкании вы просто рисуете ребро уже напрямик,
[17:30.000 --> 17:40.000]  и вес этого ребра равняется расстоянию в графе G между соответствующими парами вершин.
[17:40.000 --> 17:46.000]  Вот такой граф по парных расстояниях получается.
[17:46.000 --> 17:56.000]  Ну и по определению просто, расстояние в графе, это метрика, расстояние между вершинами образует метрику,
[17:56.000 --> 18:06.000]  и поэтому вот такой граф, который уже очевидно будет полным, он, по сути, это метрика.
[18:06.000 --> 18:12.000]  Любые задачи, для которых у нас есть хороший алгоритм.
[18:12.000 --> 18:20.000]  В метрическом случае можно сконвертировать все эти задачи.
[18:20.000 --> 18:30.000]  В метрическом случае можно сконвертировать этот алгоритм в алгоритм решения задачи,
[18:30.000 --> 18:40.000]  но с некой оговоркой в нейметрическом случае, но с некоторым недоизменением того, что вы понимаете под результатом.
[18:40.000 --> 18:50.000]  Потому что можно взять, например, граф, для этого графа построить метрическое замыкание.
[18:50.000 --> 18:58.000]  На метрическом замыкании приближенно решить задачу камевой жора.
[18:58.000 --> 19:06.000]  И дальше в исходном графе посмотреть, как прошел путь камевой жора.
[19:06.000 --> 19:16.000]  То есть цикл в метрическом замыкании, и для каждого ребра восстановить соответствующий кратчайший путь.
[19:16.000 --> 19:24.000]  То есть перейти справа налево заменой отдельных ребер на кратчайшие пути между вершинами.
[19:24.000 --> 19:34.000]  Это уже будет обход, который посещает каждую вершину не ровно один раз, а как минимум один раз.
[19:34.000 --> 19:44.000]  Но по-прежнему это будет, скорее всего, далеко не самый плохой способ обойти все вершины хотя бы по одному разу.
[19:44.000 --> 19:54.000]  Это тоже тому, что рассмотрение метрических случаев нас не слишком на практике ограничивает.
[19:54.000 --> 20:04.000]  На практике в логистических всяких задачах далеко не всегда нам нужно соблюдать это правило, что нельзя оставаться в вершину больше одного раза.
[20:04.000 --> 20:14.000]  Почему? Курьер может проезжать мимо одного и того же дома несколько раз, просто один раз он сбежит к клиенту,
[20:14.000 --> 20:24.000]  а другой раз он просто мимо этого дома проедет, потому что ему так короче всего добираться до какого-то другого клиента.
[20:24.000 --> 20:32.000]  Давайте рассмотрим две еврестики жадного типа для метрического случая.
[20:32.000 --> 20:40.000]  Одна называется кратчайшие вставки и другая называется ближайший сосед.
[20:40.000 --> 20:46.000]  Сейчас коллеги секундочку, мне на две минуты надо отойти виноват.
[20:46.000 --> 20:50.000]  И второй.
[20:50.000 --> 20:56.000]  Второй алгоритм называется ближайший сосед.
[20:56.000 --> 21:02.000]  Нирест инсершн и нирест нейбер.
[21:02.000 --> 21:10.000]  Сейчас коллеги секундочку, мне на две минуты надо отойти виноват.
[21:10.000 --> 21:18.000]  Второй алгоритм называется ближайший сосед. Нирест нейбер.
[21:24.000 --> 21:38.000]  Оба алгоритма я, конечно, скорее на наборе точек в евридовом случае буду демонстрировать.
[21:38.000 --> 21:44.000]  Давайте что-нибудь такое сделаем.
[21:44.000 --> 21:56.000]  Замечательно, что можно этот набор взять и откопировать.
[21:56.000 --> 22:03.000]  Упс, это интересно.
[22:03.000 --> 22:12.000]  Нормально откопироваться не может.
[22:12.000 --> 22:16.000]  Ну и ну.
[22:16.000 --> 22:21.000]  Вот это странно.
[22:21.000 --> 22:25.000]  Нет, не может нормально откопироваться, потрясающе.
[22:25.000 --> 22:30.000]  Ну ладно.
[22:30.000 --> 22:32.000]  Удивительное дело.
[22:32.000 --> 22:37.000]  Еще придется видимо по новой рисовать.
[22:37.000 --> 22:40.000]  Кратчайшие вставки.
[22:40.000 --> 22:46.000]  Алгоритм кратчайших вставок, его можно в разных деталях реализовать,
[22:46.000 --> 22:50.000]  но нам для того, чтобы проанализировать качество его работы,
[22:50.000 --> 22:54.000]  нужно будет сформулировать его в следующем виде.
[22:54.000 --> 22:58.000]  Первый шаг алгоритма мы выбираем кратчайшее ребро графа.
[22:58.000 --> 23:01.000]  Это вот это вот ребро.
[23:01.000 --> 23:04.000]  Ближайшая пара точек на картинке.
[23:04.000 --> 23:08.000]  Дальше мы выбираем вершину ближайшую к этому ребру.
[23:08.000 --> 23:12.000]  То есть ближайшую к ближнему к ней концу ребра.
[23:12.000 --> 23:16.000]  Ну из всех вершин, пожалуй, вот это вот ближайшее к ребру.
[23:16.000 --> 23:22.000]  И мы находим такую вершину и образуем из ребра этой вершины треугольник.
[23:22.000 --> 23:24.000]  Вот эти первые два шага.
[23:24.000 --> 23:30.000]  На каждом из остальных шагов мы будем делать совершенно одна типную процедуру.
[23:30.000 --> 23:36.000]  Мы будем сначала находить вершину ближайшую к текущему циклу.
[23:36.000 --> 23:40.000]  Ну вот, например, вот эта вот вершина, она ближайшая к этому циклу.
[23:40.000 --> 23:44.000]  И эту вершину на цикл вставлять наиболее оптимальным образом.
[23:44.000 --> 23:49.000]  Вставлять вершину на цикл мы будем удаляя ребро из цикла какое-то
[23:49.000 --> 23:53.000]  и добавляя эту вершину вместе с парой инцидентных и ребр.
[23:53.000 --> 23:59.000]  То есть вот здесь у нас возникнет тогда вот такой вот цикл сначала.
[23:59.000 --> 24:02.000]  Потом мы к этому циклу ищем кратчайшую вершину.
[24:02.000 --> 24:04.000]  Ну, скорее всего, вот эту вот.
[24:04.000 --> 24:08.000]  И вставляем ее оптимальным образом на цикл.
[24:08.000 --> 24:11.000]  Потом к этому циклу ищем кратчайшую вершину.
[24:11.000 --> 24:13.000]  Это вот эта вершина.
[24:13.000 --> 24:15.000]  Вставляем ее оптимальным образом.
[24:15.000 --> 24:17.000]  Ну и так далее.
[24:17.000 --> 24:21.000]  Вот эту вершину вставляем.
[24:21.000 --> 24:27.000]  Дальше, наверное, вот эту вершину вставляем.
[24:27.000 --> 24:30.000]  Bumps, bumps.
[24:30.000 --> 24:35.000]  Дальше, ну может быть, вот эту вставляем.
[24:35.000 --> 24:37.000]  Вот так вот.
[24:37.000 --> 24:41.000]  Дальше вот эту, например.
[24:41.000 --> 24:42.000]  Bumps, bumps.
[24:42.000 --> 24:46.000]  И, наконец, вот эту.
[24:46.000 --> 24:51.000]  Ну, получается, что-то не самое ужасное.
[24:51.000 --> 24:55.000]  Что-то совсем не самое плохое.
[24:55.000 --> 24:56.000]  Сейчас посмотрим.
[24:56.000 --> 25:04.000]  Может быть, в таком виде он у меня копировался.
[25:04.000 --> 25:15.000]  Значит, кратчайший, ближайший сосед будет действовать по-другому.
[25:15.000 --> 25:17.000]  Мы встанем.
[25:17.000 --> 25:19.000]  Наверное, даже еще проще.
[25:19.000 --> 25:21.000]  Мы встанем в любую вершину.
[25:21.000 --> 25:24.000]  Ну, например, вот в эту сначала.
[25:24.000 --> 25:30.000]  И будем идти каждый раз в ближайшего еще не посещенного соседа.
[25:30.000 --> 25:32.000]  Сначала сюда.
[25:32.000 --> 25:35.000]  Потом, повидимо, сюда.
[25:35.000 --> 25:37.000]  Потом, повидимо, сюда.
[25:37.000 --> 25:38.000]  Потом сюда.
[25:38.000 --> 25:39.000]  Сюда.
[25:39.000 --> 25:40.000]  Сюда.
[25:40.000 --> 25:41.000]  Вот.
[25:41.000 --> 25:42.000]  И так далее.
[25:42.000 --> 25:43.000]  Сюда.
[25:43.000 --> 25:44.000]  Сюда.
[25:44.000 --> 25:45.000]  Сюда.
[25:45.000 --> 25:46.000]  Сюда.
[25:46.000 --> 25:47.000]  Сюда.
[25:47.000 --> 25:52.000]  Начало две еврестики.
[25:52.000 --> 25:57.000]  Обе такого жадного типа, пошаговые.
[25:57.000 --> 26:06.000]  И забавно, что качество работы этих еврестик гарантированное.
[26:06.000 --> 26:08.000]  Оно получается немножко разным.
[26:08.000 --> 26:15.000]  Вот approximation ratio для кратчайших вставок, nearest insertion.
[26:15.000 --> 26:21.000]  Мы докажем, что на метрическом графе, а я напоминаю, что мы сегодня рассматриваем только метрические графы.
[26:21.000 --> 26:29.000]  На метрическом графе мы докажем, что коэффициент апроксимации у нас не больше двух.
[26:29.000 --> 26:45.000]  А у ближайшего соседа коэффициент апроксимации не больше, чем побольше от логарифма числа вершин в графе.
[26:46.000 --> 27:00.000]  То есть, алгоритм ближайшего соседа даже не имеет константного показателя апроксимации.
[27:00.000 --> 27:07.000]  Хотя так вроде не скажешь, что эти алгоритмы так сильно отличаются.
[27:07.000 --> 27:16.000]  Давайте начнем с кратчайших всталок, поскольку анализ этого алгоритма чуть попроще.
[27:16.000 --> 27:24.000]  И для того, чтобы алгоритм проанализировать, нам с вами нужно будет вспомнить про алгоритм прима.
[27:24.000 --> 27:34.000]  Алгоритм прима для построения кратчайшего основного дерева.
[27:34.000 --> 27:44.000]  Давайте я напомню, что у нас алгоритм прима из себя представляет.
[27:48.000 --> 27:53.000]  Алгоритм прима сначала выбирает кратчайшее ребро в графе.
[27:53.000 --> 28:00.000]  Кстати, заметьте, что первый шаг алгоритма кратчайших вставок тоже выбрал кратчайшего ребра в графе.
[28:00.000 --> 28:09.000]  А затем алгоритм прима на каждом шаге выбирает пару вершин ближайшего.
[28:09.000 --> 28:19.000]  Такую, что одна из вершин принадлежит под графу, который построен на текущий момент, а другая вершина не принадлежит.
[28:19.000 --> 28:22.000]  То есть алгоритм работает с двумя множествами.
[28:22.000 --> 28:28.000]  Ищет пару вершин из разных множеств ближайшего друг к другу.
[28:28.000 --> 28:33.000]  И соединяет эти две вершины ребром.
[28:33.000 --> 28:39.000]  Вот опять-таки берем теперь вот это множество вершин.
[28:39.000 --> 28:42.000]  Версус все остальное.
[28:42.000 --> 28:45.000]  Соединяем ребром кратчайшие вершины.
[28:45.000 --> 28:48.000]  Берем вот эти вершины, версус все остальное.
[28:48.000 --> 28:51.000]  Ищем кто поближе.
[28:51.000 --> 28:56.000]  Это так случайно получается, что здесь какой-то цикл пока что.
[28:56.000 --> 29:00.000]  Надеюсь, что он solitary.
[29:00.000 --> 29:03.000]  То что в итоге превратится все-таки во что-то нециклическое.
[29:03.000 --> 29:06.000]  Берем вот такую пару соединяем.
[29:06.000 --> 29:11.000]  Берем такую пару множеств, соединяем.
[29:11.000 --> 29:18.000]  Давайте я здесь немножко дальше подоворчу, дальше вот так может мы соединим?
[29:18.000 --> 29:20.000]  Дальше вот так соединим.
[29:20.000 --> 29:23.000]  Дальше вот так соединим.
[29:23.000 --> 29:25.000]  Дальше вот так соединим.
[29:25.000 --> 29:34.000]  То есть каждый шаг – это добавление листа в текущее дерево в графе.
[29:34.000 --> 29:39.000]  И когда все вершины оказываются в этом дереве, естественно, перед нами островное дерево,
[29:39.000 --> 29:47.000]  и можно доказать, что это дерево минимальное, островное дерево.
[29:47.000 --> 29:59.000]  Как видно, алгоритм прима на самом деле каждый раз имеет дело с двумя такими противопоставленными друг другу множествами.
[29:59.000 --> 30:06.000]  Множество охваченное под графом, множество всех еще неохваченных вершин.
[30:06.000 --> 30:11.000]  И алгоритм кратчайших вставок точно такой же.
[30:11.000 --> 30:21.000]  Вот это множество охваченных вершин, у нас не дерево на них, а цикл на каждом шаге.
[30:21.000 --> 30:28.000]  И мы вставляем вершину на цикл, а в приме мы вставляем дополнительный диск в дерево.
[30:28.000 --> 30:33.000]  Но параллелизм здесь очень такой сильный.
[30:33.000 --> 30:48.000]  Если взять кратчайшие вставки и алгоритм прима, то на первом шаге мы берем ближайшие друг другу вершины и в кратчайших вставках, и в приме.
[30:48.000 --> 30:55.000]  И по сути то, что у нас после первого шага абсолютно идентичны у этих алгоритмов.
[30:55.000 --> 31:10.000]  На втором шаге мы берем вершину ближайшую к вот этому вот ребру и добавляем вершину ближайшую к этому ребру.
[31:10.000 --> 31:18.000]  А в приме мы добавляем ту же самую вершину, просто нам не нужен треугольник, у нас дерево такое на трех вершинах получается.
[31:18.000 --> 31:32.000]  И мы заметим, что длина рёбер этого треугольника не превосходит удвоенного веса вот такой конструкции.
[31:32.000 --> 31:35.000]  Просто потому что у нас есть неравенство треугольника.
[31:35.000 --> 31:39.000]  Эта вот сторона не превосходит суммы двух других сторон.
[31:39.000 --> 31:47.000]  И, следовательно, сумма всех трех отрезков не превосходит удвоенной суммы двух из них.
[31:47.000 --> 31:52.000]  Так что у нас есть с вами на первом шаге точное совпадение.
[31:52.000 --> 31:59.000]  На втором шаге можно сказать, что такое неравенство с коэффициентом 2.
[31:59.000 --> 32:05.000]  А на каждом из последующих шагов давайте посмотрим, что у нас происходит.
[32:05.000 --> 32:11.000]  У нас сначала есть какое-то множество вершин, охваченное.
[32:11.000 --> 32:19.000]  Причём в обоих алгоритмах по индукции мы можем проверить, что оно абсолютно одно и то же.
[32:19.000 --> 32:24.000]  Просто слева цикл, а справа какое-то дерево на этом множестве.
[32:24.000 --> 32:26.000]  Что происходит в кратчайших вставках?
[32:26.000 --> 32:30.000]  Берётся вершина, ближайшая ко множеству охваченных вершин.
[32:30.000 --> 32:33.000]  Вот это расстояние минимального.
[32:33.000 --> 32:37.000]  Но во множестве приме происходит абсолютно то же самое.
[32:37.000 --> 32:39.000]  Берётся та же самая вершина.
[32:39.000 --> 32:47.000]  Приме дальше из всех реберс, которые между этой вершиной можно провести и охваченными, берётся вообще кратчайшая.
[32:47.000 --> 32:53.000]  Давайте я эту вершину назову x, а её соседа y здесь.
[32:53.000 --> 32:59.000]  Здесь это тоже вершина x, но мы её на цикл будем вставлять.
[32:59.000 --> 33:05.000]  То есть мы будем брать некие две вершины на цикле, и совсем не факт, что одна из них будет y,
[33:05.000 --> 33:08.000]  то там уж как получится.
[33:08.000 --> 33:13.000]  И будем искать фактически такой аргмин.
[33:13.000 --> 33:23.000]  Аргмин по всем парам a, b, w, x, a,
[33:23.000 --> 33:34.000]  плюс w, x, b, минус w, a, b, потому что ребро a, b мы удаляем.
[33:34.000 --> 33:40.000]  А эти два ребра добавляем при вставке.
[33:40.000 --> 33:52.000]  Но давайте заметим, что вот этот аргмин, он, конечно, не меньше, не больше,
[33:52.000 --> 33:57.000]  чем вот эта вот величина для фиксированного некоторого выбора.
[33:57.000 --> 34:03.000]  Вот здесь же где-то на цикле, который живёт у нас тут, есть вершина y.
[34:03.000 --> 34:05.000]  И у этой вершины y есть какой-то сосед.
[34:05.000 --> 34:14.000]  Так вот, если бы мы вставили вершину x вместо ребра y и какой-нибудь там y',
[34:14.000 --> 34:20.000]  то есть вот где-то здесь у нас всё равно есть y, у него есть какой-то сосед на цикле y',
[34:20.000 --> 34:23.000]  у нас получилась бы вот такая штука.
[34:23.000 --> 34:41.000]  Давайте заметим, что вот конкретно такая вставка у нас привела бы к увеличению длины цикла
[34:41.000 --> 34:46.000]  не больше, чем на 2wxy.
[34:46.000 --> 34:57.000]  То есть за один шаг алгоритма кратчайших вставок мы увеличиваем вес конструкции,
[34:57.000 --> 35:05.000]  который у нас есть, не больше, чем на удвоенное увеличение веса конструкции,
[35:05.000 --> 35:08.000]  которая в алгоритме примо происходит.
[35:08.000 --> 35:13.000]  Но почему вот это вот неравенство выполнено?
[35:13.000 --> 35:17.000]  Ну потому что можно перенести вот эту штуку в правую часть,
[35:17.000 --> 35:23.000]  можно избавиться вообще от wxy слева, а справа избавиться от вот этой двойки,
[35:23.000 --> 35:29.000]  и это будет с точностью неравенства треугольника w от xy' не больше, чем w от xy,
[35:29.000 --> 35:32.000]  плюс w от yyy'.
[35:32.000 --> 35:38.000]  То есть это прямое следствие было бы неравенства треугольника.
[35:38.000 --> 35:43.000]  Но вот как нам важно, чтобы граф был метрический.
[35:43.000 --> 35:50.000]  Ну и следовательно, вес алгоритма кратчайших вставок,
[35:50.000 --> 35:55.000]  вес цикла, который строится алгоритмом кратчайших вставок,
[35:55.000 --> 36:02.000]  не больше, чем удвоенный вес минимального оставного дерева,
[36:02.000 --> 36:07.000]  потому что алгоритм примо же строит минимальное оставное дерево.
[36:07.000 --> 36:14.000]  И осталось заметить, что у нас всегда справедливо такая оценка.
[36:17.000 --> 36:26.000]  Вес минимального оставного дерева не превосходит веса любого гамильтонного цикла,
[36:26.000 --> 36:29.000]  в том числе и оптимального.
[36:30.000 --> 36:37.000]  Понятно почему. Да, на любом графе с положительными весами, не только на метрическом.
[36:37.000 --> 36:44.000]  Почему? Потому что мы можем представить себе произвольный гамильтонов цикл,
[36:44.000 --> 36:51.000]  из него удалить любое ребро, и мы получим гамильтонову цепь.
[36:51.000 --> 36:54.000]  Но гамильтоновая цепь – это дерево.
[36:54.000 --> 36:58.000]  Просто это весьма специальное дерево, но это тем не менее оставное дерево.
[36:58.000 --> 37:02.000]  Ну и минимальное оставное дерево, стало быть,
[37:02.000 --> 37:07.000]  оно не превосходит по весу вот этой вот гамильтоновой цепи.
[37:07.000 --> 37:12.000]  А если мы эту гамильтоновую цепь получим, выкидывая ребро из оптимального гамильтонного цикла,
[37:12.000 --> 37:14.000]  то тем лучше.
[37:14.000 --> 37:20.000]  Мы с вами покажем, что МСТ не больше по весу, чем оптимальный гамильтонов цикл.
[37:20.000 --> 37:24.000]  Больше того, мы даже можем эту оценку немножко улучшить.
[37:24.000 --> 37:31.000]  Можно сказать, что МСТ не больше, чем оптимальный гамильтонов цикл,
[37:31.000 --> 37:35.000]  ну, например, минус минимальный вес ребра в графе.
[37:35.000 --> 37:39.000]  То есть дать какую-то низнюю оценку можно на то, что мы выкидываем,
[37:39.000 --> 37:45.000]  и будет небольшое совсем усиление вот такого вот соотношения.
[37:46.000 --> 37:57.000]  И стало быть, мы можем это продолжить, и сказать, что мы можем сравниться
[37:57.000 --> 38:05.000]  с оптимальным панележером с коэффициентом 2.
[38:06.000 --> 38:16.000]  Теперь мы понимаем, почему в таком классическом описании алгоритма кратчайших вставок
[38:16.000 --> 38:19.000]  здесь все выполняется в два этапа.
[38:19.000 --> 38:22.000]  Мы именно сначала находим, какую вершину вставлять,
[38:22.000 --> 38:26.000]  и потом только находим оптимальный способ ее вставить.
[38:26.000 --> 38:32.000]  Это нужно для того, чтобы множество вершин, которые охвачены кратчайшими вставками,
[38:32.000 --> 38:36.000]  в каждом импремне совпадало со множеством вершин охваченным примом,
[38:36.000 --> 38:41.000]  и, следовательно, у нас проходила бы вот такая индукция.
[38:41.000 --> 38:46.000]  Но понятно, что на практике вы можете выполнять вставку в один шаг.
[38:46.000 --> 38:52.000]  То есть сразу брать аргумент здесь по тем тройкам возможным.
[38:52.000 --> 39:01.000]  А, В и Х, где Х вершина из вне цикла, а А и В – это пара соседних вершин на текущем цикле.
[39:01.000 --> 39:06.000]  И на практике, естественно, вы можете получить что-то лучшее.
[39:06.000 --> 39:13.000]  Но проанализировать такой алгоритм будет уже, конечно, было бы существенно сложнее.
[39:13.000 --> 39:18.000]  Я даже не знаю, есть анализ такой версии кратчайших вставок или нет.
[39:21.000 --> 39:30.000]  Ну а дальше давайте посмотрим на ближайшего соседа.
[39:31.000 --> 39:36.000]  Здесь анализ у нас будет совсем другой, совсем-совсем.
[39:36.000 --> 39:43.000]  Мы не будем использовать связь между гамильтоновыми циклами и минимально вставленными деревьями.
[39:43.000 --> 39:50.000]  Хотя сама эта связь нам еще пригодится, видимо, в следующий раз,
[39:50.000 --> 39:57.000]  когда мы будем рассматривать с вами некоторые нижние оценки на стоимость оптимального гамильтонного цикла.
[39:57.000 --> 40:07.000]  Давайте займемся анализом алгоритма ближайшего соседа.
[40:07.000 --> 40:18.000]  В алгоритме ближайшего соседа мы последовательно проходим по вершинам графа.
[40:18.000 --> 40:21.000]  И для каждой вершины добавляем некое ребро.
[40:21.000 --> 40:31.000]  Торчащиеся из этой вершины и ведущие в ближайшего к ней непосещенного соседа.
[40:31.000 --> 40:35.000]  Давайте мы обогнатим длину этого ребра с L.
[40:35.000 --> 40:45.000]  Пусть L от V – это длина ребра взятого алгоритм ближайшего соседа.
[40:46.000 --> 41:04.000]  Взятого алгоритм ближайшего соседа в момент, когда мы в вершине V.
[41:04.000 --> 41:11.000]  Мы из вершины V пошли куда-то еще, пройдя как раз при этом ребро такой длины.
[41:11.000 --> 41:27.000]  Очевидно, что длина цикла, который мы в итоге строим, это просто сумма L от V по всем вершинам графа.
[41:27.000 --> 41:33.000]  Давайте мы эту сумму попытаемся хорошо оценить.
[41:33.000 --> 41:38.000]  Оценивать мы такую сумму будем не тривиально.
[41:38.000 --> 42:01.000]  Мы эту сумму разобьем на некоторое количество подсум и докажем, что внутри каждой такой подсумы эти L в общей сложности не превосходят все вместе длины,
[42:01.000 --> 42:05.000]  все вместе длины оптимального гаметонного цикла.
[42:05.000 --> 42:15.000]  Ну и тогда у нас получится, что вот у нас такая сумма разбивается на несколько сумм.
[42:15.000 --> 42:22.000]  Внутри каждой суммы L не превосходит опто.
[42:22.000 --> 42:32.000]  А число таких подсум у нас как раз окажется логарифмичным по числу вершин графа.
[42:32.000 --> 42:47.000]  Отсюда будет следовать оценка заявленная, то есть показатель репроцимации по порядку, равный логарифму числа вершин.
[42:47.000 --> 42:56.000]  Ну поехали. Давайте докажем такую лему простую.
[42:56.000 --> 42:58.000]  Она нам понадобится.
[42:58.000 --> 43:04.000]  Простая лемма.
[43:04.000 --> 43:19.000]  Для любого ребра графа, давайте я напишу даже для любых A и B вершин, потому что у нас между любой парой вершин есть ребро.
[43:19.000 --> 43:43.000]  Для любых двух вершин вес ребра A-B, или от A не больше, чем вес ребра A-B, или или от B не больше, чем вес ребра A-B.
[43:43.000 --> 43:53.000]  Хотя бы одно из двух неравенств имеет место. Может быть оба, но хотя бы одно из двух.
[43:53.000 --> 43:56.000]  Почему это так?
[43:56.000 --> 44:01.000]  Посмотрим на любую пару вершин в графе A и B.
[44:01.000 --> 44:06.000]  Вот мы допустим начали с какой-то вершины строить цикл ближайшего соседа.
[44:07.000 --> 44:17.000]  Если первая вершина по порядку, в которую мы зашли, это вершина A, то находясь в этой вершине, мы потенциально можем взять ребро A-B.
[44:17.000 --> 44:21.000]  Ну может мы его берем. Может мы берем какое-то ребро еще получше.
[44:21.000 --> 44:33.000]  В этом случае то ребро, которое мы возьмем, при любом раскладе имеет длину не больше, чем вес ребра A-B.
[44:33.000 --> 44:43.000]  Капинка получается такая, что вот эта штука не больше, чем W-A-B по определению нашего жадного подхода.
[44:43.000 --> 44:54.000]  Ну и наоборот, если первая вершина, в которую мы пришли, это было A-B, то значит гарантирована L от B не больше, чем вес ребра A-B.
[44:54.000 --> 45:02.000]  То есть это на самом деле вытекает из определения нашей жадной стратегии.
[45:02.000 --> 45:06.000]  В этом как раз наша жадность.
[45:06.000 --> 45:16.000]  Давайте теперь рассмотрим множество легких ребер в графе.
[45:17.000 --> 45:31.000]  Значит рассмотрим E'. Множество легких ребер.
[45:31.000 --> 45:35.000]  Значит уже такое легкое ребро.
[45:35.000 --> 45:45.000]  Мы представим, что у нас в графе есть зафиксированный какой-то оптимальный гамильтонов цикл.
[45:48.000 --> 45:54.000]  Давайте даже запишу перед тем, как рассматривать множество легких ребер.
[45:54.000 --> 46:09.000]  Значит зафиксируем оптимальный гамильтонов цикл и рассмотрим множество легких ребер.
[46:17.000 --> 46:20.000]  И рассмотрим множество легких ребер.
[46:21.000 --> 46:24.000]  Что такое легкое ребро?
[46:24.000 --> 46:27.000]  А давайте я его скрышкой.
[46:30.000 --> 46:48.000]  Значит это такие ребра, что вес этих ребер не превосходит удвоенного среднего веса ребер в оптимальном гамильтоновом цикле.
[46:48.000 --> 46:56.000]  Но в оптимальном гамильтоновом цикле у нас столько же ребер, сколько вершин в графе.
[46:56.000 --> 47:02.000]  Поэтому средний вес ребра в оптимальном гамильтоновом цикле равен OPT делить на n.
[47:02.000 --> 47:05.000]  n число вершин.
[47:06.000 --> 47:19.000]  Давайте заметим, что по такому дискретному неравенству Маркова можно утверждать, что количество легких ребер, вероятность события,
[47:20.000 --> 47:34.000]  вероятность события, состоящего в том, что случайная величина не превосходит удвоенного мат ожидания, больше ли равняется, чем троллям-троллям.
[47:34.000 --> 47:38.000]  Мат ожидания поделить на удвоенное ожидание.
[47:38.000 --> 47:40.000]  Это одна вторая.
[47:40.000 --> 47:52.000]  Мы получаем, что мощность множества е с крышкой не меньше, чем половинка от количества всех ребер.
[47:52.000 --> 47:58.000]  Это просто типичная конструкция, что в неравенстве Маркова.
[47:58.000 --> 48:08.000]  Если бы оказалось, что выполнено неравенство в противоположную сторону, то есть легких ребер было бы мало,
[48:08.000 --> 48:12.000]  значит тяжелых ребер было бы много, строго больше половинки от n.
[48:12.000 --> 48:22.000]  Но тогда сумма весов всех тяжелых ребер была бы строго больше, чем половинка от n помножить на 2 делить на n,
[48:22.000 --> 48:26.000]  помножить на OPT, то есть строго больше, чем половинка от n.
[48:26.000 --> 48:36.000]  Но тогда сумма весов всех тяжелых ребер была бы строго больше, чем половинка от n помножить на 2 делить на n,
[48:36.000 --> 48:39.000]  помножить на OPT, то есть строго больше OPT.
[48:39.000 --> 48:46.000]  А это было бы странно, как это у нас тут сумма какого-то подможества ребер на оптимальном гаметоновом цикле
[48:46.000 --> 48:50.000]  строго больше, чем вес этого оптимального гаметонного цикла.
[48:51.000 --> 48:58.000]  Ну, просто можно про себя так отметить, что это дискретный аналог неравенства Марковой, не больше, не меньше.
[49:03.000 --> 49:05.000]  Я здесь напишу.
[49:06.000 --> 49:18.000]  Neymetrolyan это такой аналог неравенства Маркового комбинаторного.
[49:21.000 --> 49:24.000]  Ну вот, смотрите, что получается.
[49:24.000 --> 49:33.000]  Мы с вами понимаем, что оценить нам надо сумму всех вот таких элиптов.
[49:33.000 --> 49:39.000]  С другой стороны, у нас есть лемма, которая связывает эльки с длинами каких-то ребер.
[49:39.000 --> 49:47.000]  Мы понимаем, что для каждого ребра элька одного из его концов, как минимум, не превосходит вес этого ребра.
[49:47.000 --> 49:56.000]  А еще мы с вами выделили множество ребер, которые как-то связаны с весом оптимального гаметонного цикла.
[49:57.000 --> 50:06.000]  И вот мы с вами сейчас возьмем вот эти ребра легкие, которые как-то можно сравнить с оптом.
[50:06.000 --> 50:14.000]  Для этих ребер возьмем те их концы, эльки которых можно выразить через вес ребра.
[50:14.000 --> 50:20.000]  И только сумму вот таких вот вершин мы пока что рассмотрим.
[50:20.000 --> 50:25.000]  Вот как мы сейчас организуем под сумму вот этой вот суммы по всем вершинам.
[50:27.000 --> 50:38.000]  Значит, давайте обозначим через V от E.
[50:38.000 --> 51:00.000]  Пусть это тот из концов ребра E, для которого выполнено неравенство из леммы.
[51:01.000 --> 51:09.000]  Вот хотя бы один из концов ребра, хотя бы у каждого ребра,
[51:09.000 --> 51:12.000]  хотя бы для одного из концов выполнено вот такое неравенство.
[51:12.000 --> 51:19.000]  Вот возьмем тот любой из концов, для которого оно выполнено, и обозначим его через V от E.
[51:19.000 --> 51:24.000]  По каждому ребру у нас в графе можно выделить один из его концов.
[51:25.000 --> 51:30.000]  И вот теперь давайте наконец рассмотрим под множество вершин V'.
[51:30.000 --> 51:41.000]  Это такие вершины в графе, которые являются хорошими концами легких ребер.
[51:44.000 --> 51:46.000]  Так надо было записать.
[51:46.000 --> 51:52.000]  Это V от E, где E с крышкой.
[51:52.000 --> 51:58.000]  То есть мы берем все легкие ребра, для каждого из них берем хороший конец этого ребра.
[51:58.000 --> 52:06.000]  И вот множество всех хороших концов обозначаем через V'.
[52:06.000 --> 52:14.000]  Заметим, что вот это множество E с крышкой это все-таки какое-то подножество ребер Гамильтонного цикла.
[52:14.000 --> 52:21.000]  То есть у каждой вершины графа инцидентными ей оказываются не более, чем два легких ребра.
[52:21.000 --> 52:37.000]  Ну или можно сказать по-другому, что одна и та же вершина может встретиться не более, чем дважды как конец какого-то ребра Гамильтонного цикла,
[52:37.000 --> 52:39.000]  ну в том числе легкого ребра.
[52:39.000 --> 52:48.000]  Поэтому когда мы с вами вот здесь в определении множества перебираем легкие ребра и для каждого ребра берем его конец,
[52:48.000 --> 52:54.000]  никакая вершина графа больше, чем два раза у нас как бы не повторится вот в этом определении.
[52:54.000 --> 53:06.000]  И поэтому множество таких хороших вершин V', мощность множества V', она не меньше, чем половинка от мощности E с крышкой.
[53:06.000 --> 53:11.000]  Потому что вот как раз каждая вершина инцидентны не более, чем двум легким ребрам.
[53:11.000 --> 53:14.000]  И это ставится у нас в номинате.
[53:14.000 --> 53:19.000]  Ну а множество легких ребер у нас само не меньше, чем половинка от N.
[53:19.000 --> 53:32.000]  Следовательно, мы с вами построили множество вершин хороших, которые имеют мощность не меньше, чем четверть от всех вершин графа.
[53:32.000 --> 53:36.000]  Ну отлично. Теперь мы с вами можем сказать вот что.
[53:36.000 --> 54:00.000]  Что сумма или от V' по всем V' из множества V1 меньше или равна, чем что?
[54:00.000 --> 54:08.000]  Те вершинки, которые попали во множество V1, их L' не превосходит веса ребра соответствующего.
[54:08.000 --> 54:11.000]  А ребра мы здесь берем только легкие.
[54:11.000 --> 54:30.000]  То есть каждая L' в этой сумме не превосходит вот этой величины.
[54:30.000 --> 54:40.000]  Не больше, чем сумма 2 или на N на OPT по V из V1.
[54:40.000 --> 54:52.000]  Ну и все-таки V1 по мощности не больше N, поэтому это точно не больше, чем 2 помножить на OPT.
[54:52.000 --> 55:03.000]  Чудесно. Нам как раз с вами удалось реализовать первый шаг нашего плана, и все остальные шаги будут ровно такие же.
[55:03.000 --> 55:15.000]  Но для того, чтобы сделать этот переход, нам нужна еще одна такая лемма.
[55:15.000 --> 55:19.000]  Что нам удалось сделать?
[55:19.000 --> 55:30.000]  Мы в множестве вершин графа откусили такой кусочек V1, который содержит довольно много вершин, как минимум четверть.
[55:30.000 --> 55:38.000]  И сказали, что у Элик этих вершин, значит, сумма Элик по этим вершинам какая-то очень разумно ограничиваемая.
[55:38.000 --> 55:45.000]  Но дальше мы, понятное дело, должны разобраться с остальными вершинами.
[55:45.000 --> 55:49.000]  И вот теперь нам потребуется вот такая лемма.
[55:49.000 --> 56:08.000]  По любому обходу графа гамильтонового, можно построить гамильтоновый обход под графа так, чтобы вес не увеличился.
[56:08.000 --> 56:11.000]  Давайте я порисую здесь картинку.
[56:11.000 --> 56:20.000]  Давайте красную я нарисую обход всего графа.
[56:21.000 --> 56:39.000]  Естественно, этот обход заходит иногда во множество V1, выходит из него.
[56:39.000 --> 56:45.000]  Ну вот какой-то такой обход гамильтонов, ну, допустим, даже оптимальный.
[56:45.000 --> 57:00.000]  Значит, мы можем по этому обходу построить обход гамильтонов только вот этих вот вершин, не увеличивая при этом вес.
[57:00.000 --> 57:03.000]  Ну и понятно, как это будет происходить.
[57:03.000 --> 57:10.000]  Мы идем, идем, идем, идем и понимаем, что вот мы заходим во множество V1.
[57:10.000 --> 57:12.000]  Но V1 нам больше не нужно.
[57:12.000 --> 57:25.000]  Мы просто берем и дожидаемся момента, когда мы выходим из этого множества V1 и удаляем тогда вот этот весь кусочек и идем, например, по вершину ни из V1.
[57:25.000 --> 57:28.000]  Дальше опять, вот какой-то момент, в котором мы зашли в V1.
[57:28.000 --> 57:37.000]  Мы спокойно дожидаемся, пока мы в следующий раз выйдем из V1 и идем, например, и получаем вот такой обход.
[57:37.000 --> 57:42.000]  Мы просто пропускаем все вершины множества V1.
[57:42.000 --> 57:56.000]  Поскольку граф метрический, то нам не надо думать о том, что так можно сделать, потому что сериалы есть, можно всегда пойти напрямик между вершинами, пропустив какие-то там в середине.
[57:56.000 --> 58:10.000]  И кроме того, в метрическом графе по индукции мы получаем, что поход напрямик между парой вершин всегда не дороже, чем поход по произвольному пути между этими вершинами.
[58:10.000 --> 58:29.000]  То есть мы сначала ни разу треугольника к этой троице вершин применяем, говорим, что можно это заменить ребром, потом к этой троице вершин, говорим, что можно заменить ребром, потом к этой троице, потом уже к этой троице и все.
[58:29.000 --> 58:49.000]  Это не последний раз нам это понадобится, утверждение о том, что можно спрямлять маркруты в метрических графах, при этом не увеличивая общую длину маркрута.
[58:49.000 --> 58:53.000]  Очень удобное свойство метрических графов.
[58:53.000 --> 59:22.000]  Ну и вот теперь мы с вами можем продолжить уже. То есть мы что делаем? Мы откусили множество v1, мы покусируемся на множестве v без v1, и мы строим по оптимальному гаментонову циклу некий циклический обход вершин в множестве v без v1, который имеет вред не больше опта.
[59:23.000 --> 59:44.000]  Дальше мы понятно, что возьмем. Мы возьмем множество легких ребер, но легких уже вот как бы здесь, то есть множество ребер вот этого красного обхода, которые по величине не больше, чем удвоенное среднее тоже для этого уже красного обхода.
[59:44.000 --> 01:00:04.000]  Дальше мы абсолютно также определим множество v2, v2 это множество легких вершин, то есть множество вершин, для которых их льда оценивается весом какого-то легкого ребра соответствующего, и будет выполнена абсолютно та же самая оценка.
[01:00:04.000 --> 01:00:21.000]  То есть дальше мы говорим, что множество v2 мы рассматриваем совершенно аналогично. Мощность множества v2 больше равна, чем четверть на мощность v без v1.
[01:00:21.000 --> 01:00:34.000]  И по абсолютно тем же соображениям сумма по всем v из v2, l от v не больше, чем 2 на опт.
[01:00:34.000 --> 01:01:00.000]  Вот этот опт на самом деле, это вот этот красный. Можно даже сюда было бы поставить вместо опта длину красного цикла, но сам он по длине не больше, чем исходный оптимальный гаметонов цикл в ГРАТе, поэтому нам же важно в конце концов сравниться с исходным оптом не больше того.
[01:01:00.000 --> 01:01:05.000]  И так дальше, и так дальше, и т.д.
[01:01:05.000 --> 01:01:33.000]  Мы с вами пришли к такому заключению, что сумма по всем вершинам равняется сумма по v из v1, l от v, плюс сумма l по v из v2, плюс и т.д.
[01:01:33.000 --> 01:01:47.000]  Плюс сумма pv из vm, l от v. До какого момента мы вообще так можем делать?
[01:01:47.000 --> 01:02:00.000]  Но можем делать мы так до момента, когда в принципе можно провести какой-то обход, предложить между вершинами.
[01:02:00.000 --> 01:02:05.000]  Наверное, последний этап, это когда там у нас две вершины есть.
[01:02:05.000 --> 01:02:19.000]  Формально можно сказать, что две вершины, какие-то в графе, между ними тоже можно обход сделать, просто повторив дважды ребро между этими вершинами.
[01:02:19.000 --> 01:02:28.000]  На этом у нас точно все заканчивается, возможность применять вот это вот, ну, спрямление гаметонового цикла.
[01:02:28.000 --> 01:02:43.000]  И когда у нас остается одна вершина, вот здесь во множестве vn, ну все, здесь мы должны закончить.
[01:02:43.000 --> 01:03:02.000]  Значит, когда остается одна вершина, мы уже там не выбираем никакие, конечно, легкие ребра, легкие вершины, потому что по одной вершине мы не можем никакой обход с вами построить разумной.
[01:03:02.000 --> 01:03:06.000]  У нас же петель к графе нету.
[01:03:06.000 --> 01:03:20.000]  Но заметим, что любая отдельная LF, любая отдельная LF, она не превосходит половинки от веса оптимального гаметонного цикла.
[01:03:20.000 --> 01:03:28.000]  Вот вообще любое ребро в графе, в метрическом, абсолютно любое.
[01:03:29.000 --> 01:03:33.000]  У нее есть какое-то ребро, как раз на котором достигается вот это LF.
[01:03:33.000 --> 01:03:43.000]  Но любое ребро в графе не превосходит половинки веса оптимального гаметонного цикла, потому что можно себе представить гаметонов цикл по графу идущий.
[01:03:43.000 --> 01:03:52.000]  И если мы рассмотрим часть этого цикла по левую сторону ребра на картинке, да,
[01:03:52.000 --> 01:04:01.000]  и скажем, что вот это ребро, оно не превосходит длины какого-то пути между вершинами V и V'.
[01:04:01.000 --> 01:04:04.000]  То есть в частности длины вот этого пути.
[01:04:04.000 --> 01:04:09.000]  С другой стороны, вот это же ребро V и V' не превосходит вот такого пути.
[01:04:09.000 --> 01:04:19.000]  И получается, что удвоенная длина вот этого ребра не превосходит веса всего гаметонного цикла по графу.
[01:04:19.000 --> 01:04:25.000]  Ну, стало быть, само ребро не больше, чем половинка от веса гаметонного цикла.
[01:04:25.000 --> 01:04:31.000]  Так что каждая отдельная LF в любом случае не больше, чем половинка от опта.
[01:04:31.000 --> 01:04:40.000]  И когда у нас остается сумма, в которой всего одно слагаемое, дальше мы с ней не работаем таким способом, как выше.
[01:04:40.000 --> 01:04:46.000]  Дальше мы просто говорим тривиально, что всё, когда у нас сумма из одного или двух слагаемых,
[01:04:46.000 --> 01:04:53.000]  мы каждое слагаемое оцениваем просто как половинка от опта и успокаиваемся на этом точном.
[01:04:53.000 --> 01:05:01.000]  Ну а общее количество сумм у нас здесь получается каким?
[01:05:02.000 --> 01:05:10.000]  Не больше, чем логарифм по основанию 4 третьих от N.
[01:05:10.000 --> 01:05:17.000]  Потому что каждый раз мы откусываем одну четверть, оставляя максимум три четверти от вершин.
[01:05:17.000 --> 01:05:24.000]  Ну и значит количество откусываний последовательных не больше, чем логарифм по основанию 4 третьих от N.
[01:05:24.000 --> 01:05:29.000]  В каждой сумме у нас всё оценивается двумя оптами.
[01:05:29.000 --> 01:05:39.000]  И следовательно, вот это всё не больше, чем логарифм по основанию 4 третьих от N.
[01:05:39.000 --> 01:05:44.000]  Целая часть сверху, помножить на 2, помножить на 1.
[01:05:44.000 --> 01:06:02.000]  Ну вот, такое рассуждение.
[01:06:02.000 --> 01:06:08.000]  Пожалуйста, сейчас можно обсудить на своём вопросе по двум этим алгоритмам.
[01:06:08.000 --> 01:06:20.000]  Дальше, наверное, мы поговорим с вами о двух алгоритмах.
[01:06:20.000 --> 01:06:32.000]  Для гамильтонового цикла один, ну нет, в принципе можно сказать, что похожие они.
[01:06:32.000 --> 01:06:36.000]  Один из них алгоритм Кристофидеса.
[01:06:36.000 --> 01:06:48.000]  Ну один из самых лучших алгоритмических на сегодняшний день, который на практике, правда, не очень используется.
[01:06:48.000 --> 01:07:02.000]  Ну давайте, давайте пойдём тогда дальше.
[01:07:02.000 --> 01:07:13.000]  Вот эта идея, которую мы использовали при анализе ближайшего соседа, о том, что можно брать маршрут и его спрямлять.
[01:07:13.000 --> 01:07:21.000]  По-английски эта идея называется short-cutting, да, short-cutting, спрямление такое.
[01:07:21.000 --> 01:07:35.000]  Значит, можно на основе этой идеи предложить ещё один алгоритм, который будет иметь показатель практимации 2, также как кратчайшие вставки.
[01:07:43.000 --> 01:07:53.000]  Давайте мы этот алгоритм назовём MST plus short-cutting.
[01:07:53.000 --> 01:07:57.000]  Минимально остывное дерево плюс спрямление углов.
[01:07:57.000 --> 01:08:01.000]  Алгоритм будет выглядеть так.
[01:08:01.000 --> 01:08:15.000]  Для графа, для метрического графа, в котором нужно построить гаментону в циклу, мы строим сначала минимальное остывное дерево.
[01:08:15.000 --> 01:08:22.000]  Затем мы это остывное дерево обходим в глубину.
[01:08:22.000 --> 01:08:30.000]  Входим это MST в глубину.
[01:08:33.000 --> 01:08:43.000]  Так, давайте мы вот куда-нибудь возьмём, например, вот отсюда.
[01:08:52.000 --> 01:08:56.000]  Раз, два, три.
[01:09:10.000 --> 01:09:20.000]  Значит, минимально остывное дерево, да, но как оно может выглядеть здесь?
[01:09:20.000 --> 01:09:24.000]  Допустим, что вот так оно выглядит.
[01:09:34.000 --> 01:09:38.000]  Обходим это дерево в глубину, из любой вершины.
[01:09:38.000 --> 01:09:43.000]  Ну, допустим, из вот такой вершины будет корень обхода.
[01:09:43.000 --> 01:09:58.000]  Обход дерева в глубину, но это графически можно представить как такой поход вдоль этого дерева по контуру, как будто мы вдоль стены замка обходим.
[01:09:58.000 --> 01:10:04.000]  Да, вот таким вот способом, и бамс, возвращаемся в исходную вершину.
[01:10:04.000 --> 01:10:14.000]  При обходе в глубину мы движемся по картному ребру дважды, один раз в сторону от корня и другой раз к корню.
[01:10:14.000 --> 01:10:29.000]  И поскольку это остывное дерево мы обошли в глубину, то каждую вершину графа мы при этом очевидно посетили как минимум один раз.
[01:10:29.000 --> 01:10:33.000]  А каждое ребро остывного дерева посетили ровно дважды.
[01:10:33.000 --> 01:10:38.000]  Ну, теперь давайте просто применим идею спрямления.
[01:10:38.000 --> 01:10:46.000]  Вот мы с вами пошли из корня обхода в вот эту вот вершину.
[01:10:46.000 --> 01:10:56.000]  Дальше пошли вот сюда, дальше пошли вот сюда, дальше сюда, дальше сюда.
[01:10:56.000 --> 01:11:04.000]  Ну, дальше мы пошли бы по вот этому ребру опять ближе к корню, но мы так попадем в вершину, в которой мы уже были.
[01:11:04.000 --> 01:11:07.000]  Давайте дождемся, пока мы не попадем в новую вершину.
[01:11:07.000 --> 01:11:11.000]  Ага, ну после вот этой вот вершины мы бы пошли в ее соседу, вот сюда.
[01:11:11.000 --> 01:11:15.000]  Давайте в ее соседу пойдем просто напрямик вот так.
[01:11:15.000 --> 01:11:23.000]  Дальше мы бы вернулись снова вот в эту вершину, погуляли бы по вершинам, в которые мы уже были.
[01:11:23.000 --> 01:11:27.000]  А вот дальше мы бы пошли вот сюда, в новую вершину.
[01:11:27.000 --> 01:11:31.000]  Давайте сразу в нее пойдем напрямик.
[01:11:31.000 --> 01:11:40.000]  Дальше мы вернулись сначала вот сюда, потом в корень, потом пошли бы, например, вот сюда.
[01:11:40.000 --> 01:11:42.000]  Давайте пойдем сюда напрямик.
[01:11:42.000 --> 01:11:51.000]  Потом мы бы пошли, очевидно, сюда, потом мы бы пошли сюда, ну и потом остается только замкнуться.
[01:11:51.000 --> 01:11:53.000]  Получается вот такой цикл.
[01:11:53.000 --> 01:11:59.000]  Он немножко странновато выглядит для этой картинки.
[01:11:59.000 --> 01:12:11.000]  Видно, что это Гамильтонов цикл, и в каждый рак мы спрямляли какой-то кусочек нашего первоначального обхода.
[01:12:11.000 --> 01:12:20.000]  А наш первоначальный обход имел суммарную длину, равную удвоенной длине минимально восторгного дерева.
[01:12:20.000 --> 01:12:23.000]  Ну, потому что это был обход глубину.
[01:12:23.000 --> 01:12:27.000]  Обход глубину карты ребро минимально восторгного дерева посещал ровно 2 арты.
[01:12:27.000 --> 01:12:45.000]  Значит, спрямляем этот обход, обход глубину, получаем вес не больше, чем удвоенный вес восторгного дерева,
[01:12:45.000 --> 01:12:48.000]  а оно у нас выбиралось минимальным восторгным деревом.
[01:12:48.000 --> 01:12:55.000]  Ну и дальше мы знаем, что минимальное восторгное дерево по весу никогда не превосходит весы оптимального Гамильтонова цикла.
[01:12:55.000 --> 01:12:58.000]  В любом графе, не только в метрике.
[01:12:58.000 --> 01:13:05.000]  Ну, в общем-то, это одно из немногих неравенств, которое работает для произвольного графа.
[01:13:05.000 --> 01:13:15.000]  А вот идея спрямления, она только для метрического графа позволяет дать какую-то контролируемую такую оценку.
[01:13:15.000 --> 01:13:24.000]  Это сразу тоже, значит, мы понимаем, что как и в алгоритме, например, ближайшего соседа,
[01:13:24.000 --> 01:13:34.000]  в котором цикл может быть сильно разного качества в зависимости от того, из какой вершины вы начали строить цикл.
[01:13:34.000 --> 01:13:44.000]  Здесь тоже, если в графе несколько минимально восторгных деревьев, то тоже, значит, можно использовать разные.
[01:13:44.000 --> 01:13:48.000]  И можно ведь по-разному обходить одно и то же минимальное восторгное дерево.
[01:13:48.000 --> 01:13:56.000]  Соответственно, у нас получается много разных возможностей вот таким способом построить Гамильтоновы циклы.
[01:13:56.000 --> 01:14:07.000]  И я вам рекомендую на практике посмотреть, насколько сильно могут отличаться циклы в зависимости от обхода
[01:14:07.000 --> 01:14:14.000]  восторгного дерева, в зависимости от обхода восторгного дерева.
[01:14:14.000 --> 01:14:22.000]  Можете подумать, как выбирать ибристический порядок ветвей вот этого дерева,
[01:14:22.000 --> 01:14:31.000]  так, чтобы в цикле у нас получалось, например, поменьше вот таких вот пересечений, скрещиваний.
[01:14:31.000 --> 01:14:39.000]  Потому что очевидно, что геометрически, например, каждое скрещивание – это некая субоптимальность.
[01:14:39.000 --> 01:14:52.000]  Потому что можно скрещивание внутри какого-то обхода заменить на пару других ребер.
[01:14:53.000 --> 01:15:04.000]  И это будет лучше, потому что сумма противоположных сторон четырехугольника не превосходит суммы длин его диагонали.
[01:15:04.000 --> 01:15:16.000]  И скрещивание мы всегда можем в таком Евклидовом случае удалять и понимать, что мы точно улучшаем картину.
[01:15:16.000 --> 01:15:29.000]  Ну и последнее алгоритм такого типа – это алгоритм Кристофидеса,
[01:15:29.000 --> 01:15:50.000]  алгоритм Кристофидеса, который основан на абсолютно такой же идее – построить маршрут и спрямить углы.
[01:15:50.000 --> 01:16:04.000]  Только маршрут строится чуть более вдумчиво, чем просто удвоением ребер минимального оставного дерева.
[01:16:04.000 --> 01:16:13.000]  Давайте начнем с того, что построим минимальное оставное дерево.
[01:16:13.000 --> 01:16:22.000]  И, наверное, я даже возьму это оставное дерево из нашего с вами примера. Пусть будет.
[01:16:30.000 --> 01:16:37.000]  Заодно посмотрим, сильно ли отличается геометрически то, что мы с вами построим.
[01:16:37.000 --> 01:16:51.000]  Значит, сильно ли это отличается от предыдущего подхода? Удаляйся.
[01:16:51.000 --> 01:16:59.000]  Удаляться не хочется. Удаляйся, удаляйся.
[01:16:59.000 --> 01:17:03.000]  Так, строим минимальное оставное дерево.
[01:17:03.000 --> 01:17:17.000]  А дальше давайте выделим вершины в этом оставном дереве, которые имеют нечетные степени.
[01:17:17.000 --> 01:17:23.000]  Во-первых, это все листья, конечно.
[01:17:23.000 --> 01:17:29.000]  И во-вторых, в нашем дереве у нас еще есть вершины степени 3.
[01:17:29.000 --> 01:17:34.000]  Остальные вершины четных степеней мы трогать не будем.
[01:17:34.000 --> 01:17:46.000]  Давайте вспомним лему о рукопожатиях, которая утверждает, что в любом графе количество вершин нечетной степени – четно.
[01:17:46.000 --> 01:17:52.000]  Кроме того, вспомним, что у нас граф полный, потому что мы метрическую задачу решаем,
[01:17:52.000 --> 01:17:56.000]  граф полный, и мы можем теперь решить такую задачку.
[01:17:56.000 --> 01:18:00.000]  Но мы алгоритмы для нее не рассматривали.
[01:18:00.000 --> 01:18:09.000]  Вот это мы принесем без доказательств, что в полном графе начетном количестве вершин
[01:18:09.000 --> 01:18:19.000]  Можно за полинамиальное время построить совершенное паросочетание минимального веса.
[01:18:19.000 --> 01:18:25.000]  Вот мы его строим.
[01:18:25.000 --> 01:18:47.000]  Дерево само я обозначу через «т», и дальше запишу «строим минимальное по весу mean weight perfect matching
[01:18:47.000 --> 01:18:57.000]  на вершинах нечетной степени «т».
[01:18:57.000 --> 01:19:05.000]  Давайте мы этих товарищей обозначим через «м».
[01:19:05.000 --> 01:19:09.000]  Какое паросочетание? Допустим, такое.
[01:19:09.000 --> 01:19:20.000]  То, что ребро, кстати говоря, вошло в дерево «т», мешает ему входить в совершенное паросочетание на вершинах нечетной степени «т».
[01:19:20.000 --> 01:19:25.000]  Вот здесь, например, вот это ребро тоже добавим.
[01:19:25.000 --> 01:19:31.000]  Потом может быть такое зеленое ребро и вот такое вот ребро.
[01:19:31.000 --> 01:19:35.000]  Так, ну что у нас получилось?
[01:19:35.000 --> 01:19:42.000]  Получилось дерево и паросочетание.
[01:19:42.000 --> 01:19:51.000]  Давайте теперь заметим, посмотрим на граф «т» в объединении с «м».
[01:19:51.000 --> 01:20:02.000]  Это как бы даже не под граф исходного графа, это получается мультимножество ребер.
[01:20:02.000 --> 01:20:08.000]  Значит, некоторые ребра у нас в двойном экземпляре, некоторые нет.
[01:20:08.000 --> 01:20:17.000]  Но что можно сказать про объединение «т» и «м» с учетом кратности ребер?
[01:20:17.000 --> 01:20:27.000]  Что у каждой вершины в этом объединении степень четная, потому что мы не зря брали вот это паросочетание «м».
[01:20:27.000 --> 01:20:36.000]  Мы его брали как раз, чтобы вершины нечетной степени в дереве «т» исправить, чтобы добавить к их степени единичку.
[01:20:36.000 --> 01:20:43.000]  И получается, что вот это такой мультиграф у которого степень всех вершин четная,
[01:20:43.000 --> 01:20:51.000]  а связанность есть автоматически за счет того, что «т» это дерево.
[01:20:51.000 --> 01:20:56.000]  Получается, что это эйлеров граф.
[01:20:56.000 --> 01:21:02.000]  Или даже такой эйлеров мультиграф.
[01:21:02.000 --> 01:21:14.000]  Эйлеров мультиграф, в нем существует эйлеров обход.
[01:21:14.000 --> 01:21:27.000]  Ну и давайте мы рассмотрим спрямление эйлерового обхода вот в этом объединении.
[01:21:27.000 --> 01:21:35.000]  Эйлеров обход проходит каждое ребро ровно по одному разу, ну а каждую вершину как минимум один раз.
[01:21:35.000 --> 01:21:47.000]  Стало быть, спрямление этого обхода по весу не превосходит сумму всех ребер, входящих в этот мультиграф исходный.
[01:21:47.000 --> 01:21:56.000]  И мы получаем вес не больше, чем вес дерева «т».
[01:21:57.000 --> 01:22:08.000]  А вес дерева «т» – это вес минимально выставного дерева в графе, плюс вес паросочетания «м».
[01:22:08.000 --> 01:22:17.000]  То есть мы с вами имеем гамильтонов цикл в графе, вот спрямляя эйлеров обход, по весу не больше, чем вот такой.
[01:22:17.000 --> 01:22:26.000]  Мы с вами уже знаем, что вес МСТ – это не больше, чем вес оптимального гамильтонного цикла.
[01:22:26.000 --> 01:22:40.000]  И осталось заметить, что вес любого паросочетания совершенно на некотором подможестве вершин.
[01:22:41.000 --> 01:22:54.000]  Но у нас с вами есть рассуждение, что для любого подможества вершин графа можно построить гамильтонов обход этого подможества,
[01:22:54.000 --> 01:23:02.000]  которые по весу не превосходят оптимального гамильтонного обхода во всем графе целиком.
[01:23:02.000 --> 01:23:06.000]  Следовательно, здесь можно сказать вот что.
[01:23:06.000 --> 01:23:13.000]  Вот мы имели с вами весь граф, в нем был у нас гамильтонов обход оптимальный.
[01:23:13.000 --> 01:23:20.000]  Вот мы взяли множество вершин, которые в минимальном оставляемом дереве имели нечетные степени.
[01:23:20.000 --> 01:23:28.000]  И дальше мы на этих вершинах строили как-то паросочетание минимального веса, совершенного.
[01:23:28.000 --> 01:23:38.000]  Но вот мы можем с вами построить для начала гамильтонов обход этих вершин.
[01:23:38.000 --> 01:23:41.000]  Его вес точно не больше, чем опт.
[01:23:41.000 --> 01:23:50.000]  И дальше гамильтонов обход по четному количеству вершин разбивается на два паросочетания.
[01:23:50.000 --> 01:24:08.000]  Мы просто берем ребра через одно и получаем некое паросочетание.
[01:24:08.000 --> 01:24:13.000]  Берем дополнение этого паросочетания, получаем другое паросочетание.
[01:24:13.000 --> 01:24:21.000]  Вот у нас есть два паросочетания на этом множестве вершин, которые в сумме дают не больше опта.
[01:24:21.000 --> 01:24:28.000]  Значит, лучшее из этих паросочетаний не превосходит половинки от опта.
[01:24:28.000 --> 01:24:36.000]  И получается вот что вес m не больше, чем половинка на опт.
[01:24:36.000 --> 01:24:46.000]  А стало быть, мы имеем с вами алгоритм с показателем проксимации полтора.
[01:24:46.000 --> 01:24:50.000]  И это лучше, чем все, что мы с вами видели до сих пор.
[01:24:50.000 --> 01:24:55.000]  МСП и шорткатинг. Показатель проксимации два.
[01:24:55.000 --> 01:24:58.000]  Прочайшие вставки показателя проксимации два.
[01:24:58.000 --> 01:25:02.000]  Вообще не константные показатели проксимации.
[01:25:02.000 --> 01:25:06.000]  Алгоритм Кристофидеса показатель проксимации три, второй.
[01:25:06.000 --> 01:25:11.000]  Что можно сказать еще про все перечисленные алгоритмы?
[01:25:11.000 --> 01:25:24.000]  Во-первых, все найденные нами показатели проксимации в ближайшем соседе это по порядку точная величина алгоритма.
[01:25:24.000 --> 01:25:31.000]  На всех остальных алгоритмах, там, где у нас константы, это достижимые, асинтетически достижимые константы.
[01:25:31.000 --> 01:25:34.000]  В том числе и в Кристофидесе.
[01:25:34.000 --> 01:25:46.000]  И еще надо сказать, что то, что у алгоритма формально получше показатели проксимации,
[01:25:46.000 --> 01:25:51.000]  не делает его на практике однозначно лучше, чем какой-то другой алгоритм.
[01:25:51.000 --> 01:25:54.000]  Вот ближайший сосед.
[01:25:54.000 --> 01:25:59.000]  Вот совсем не факт, что на практике для конкретного графа
[01:25:59.000 --> 01:26:05.000]  ближайший сосед отработает хуже, чем прочайшие вставки или даже хуже, чем Кристофидес.
[01:26:05.000 --> 01:26:06.000]  Вот совсем не факт.
[01:26:06.000 --> 01:26:13.000]  При том, что Кристофидес, алгоритм, если кодировать, то придется напрягаться и писать алгоритм
[01:26:13.000 --> 01:26:19.000]  для поиска совершенного парасочетания минимального веса в недвудольном графе.
[01:26:19.000 --> 01:26:22.000]  А это то еще удовольствие.
[01:26:22.000 --> 01:26:32.000]  С другой стороны, на практике никто не призывает решать точно какие-то трудные вход-задачи.
[01:26:32.000 --> 01:26:36.000]  Но минимально восстановленное дерево мы с вами всегда найдем нормальный.
[01:26:36.000 --> 01:26:39.000]  Быстро заходим, алгоритм быстрый получается.
[01:26:39.000 --> 01:26:44.000]  А вот парасочетания можно искать приближенно.
[01:26:44.000 --> 01:26:52.000]  И можно вполне для трудных шагов каких-то крутых алгоритмов, теоретически крутых,
[01:26:52.000 --> 01:26:56.000]  эти трудные шаги тоже решать приближенно.
[01:26:56.000 --> 01:27:05.000]  Получается аппроксимационное такое решение под задачей внутри алгоритма аппроксимации.
[01:27:05.000 --> 01:27:08.000]  Такая аппроксимация второго порядка.
[01:27:08.000 --> 01:27:12.000]  Но это ничего, это вполне нормально.
[01:27:12.000 --> 01:27:22.000]  Ну и наконец еще раз скажу, что некоторые из алгоритмов, рассмотренных нами,
[01:27:22.000 --> 01:27:26.000]  на самом деле это целое такое семейство алгоритмов,
[01:27:26.000 --> 01:27:34.000]  потому что в алгоритме МФП и шорткатинг мы можем обходить дерево одно и то же,
[01:27:34.000 --> 01:27:41.000]  из разных корней, по-разному выбирать корень, и по-разному упорядочивая ветви обхода.
[01:27:41.000 --> 01:27:50.000]  И в ближайшем соседе мы тоже произвольно выбрать вершину, из которой мы начинаем строить обход.
[01:27:50.000 --> 01:27:56.000]  Даже если дальше у нас все детерминировано, вот первый шаг ближайшего соседа совершенно не детерминирован.
[01:27:56.000 --> 01:28:13.000]  Ну вот. Дальше мы с вами рассмотрим дополнительную тему,
[01:28:13.000 --> 01:28:18.000]  а именно как мы можем снизу оценивать вот этот самый опт.
[01:28:18.000 --> 01:28:25.000]  Вот мы с вами запустились, решаем задачку мегалежауры, запустили какой-то хороший приближенный алгоритм,
[01:28:25.000 --> 01:28:31.000]  и мы получили нечто. Мы понимаем, что на практике показатель аппроксимации нашего алгоритма
[01:28:31.000 --> 01:28:40.000]  может быть гораздо лучше, чем два. Может он там 1.05, мы всего на 5% больше по весу построили цикл.
[01:28:40.000 --> 01:28:51.000]  Для того, чтобы это понимать и гордиться, мы должны иметь хорошие нижние оценки на опт.
[01:28:51.000 --> 01:28:58.000]  И тогда вот если мы говорим, что для этого конкретного входного графа опт больше 100,
[01:28:58.000 --> 01:29:10.000]  а ближайший сосед нам дал 110, то это значит, что мы уже не больше, чем на 10% отклонились минимального значения.
[01:29:10.000 --> 01:29:20.000]  Так что вот дальше мы с вами рассматриваем нижние оценки на длину гамильтонного цикла в графе.
[01:29:20.000 --> 01:29:25.000]  Ну и опять-таки мы ограничиваем симметрическими графами.
[01:29:31.000 --> 01:29:37.000]  Так, я как всегда не слежу за временем. Во сколько мы с вами должны заканчивать?
[01:29:37.000 --> 01:29:40.000]  Вот сколько у нас всё есть времени?
[01:29:45.000 --> 01:29:47.000]  Верхняя оценка 12.10.
[01:29:47.000 --> 01:29:49.000]  А, 12.10, супер.
[01:29:49.000 --> 01:29:55.000]  Супер, тогда мы с вами это успеем. Всё успеем.
[01:29:56.000 --> 01:30:15.000]  А, значится, нижние оценки, нижние оценки на длину гамильтоновых циклов
[01:30:15.000 --> 01:30:25.000]  в метических графах.
[01:30:25.000 --> 01:30:35.000]  Но на самом деле я здесь пишу для метических графов, но вы можете сами проследить, какие из этих рассуждений вложатся на общий случай.
[01:30:35.000 --> 01:30:38.000]  Ну и в всяком случае хотя бы на полный граф.
[01:30:38.000 --> 01:30:55.000]  Мы с вами выяснили, что есть такая оценка, что opt больше ли равен, чем mst.
[01:30:55.000 --> 01:30:59.000]  Это мы с вами знаем.
[01:30:59.000 --> 01:31:13.000]  Но мы с вами сказали тут же, что на самом деле эта оценка берётся из того, что мы рассматриваем гамильтонов обход оптимальный
[01:31:13.000 --> 01:31:16.000]  и удаляем из этого обхода ребро.
[01:31:16.000 --> 01:31:27.000]  И поэтому мы правы сказать, что исходный обход не меньше, чем нижняя оценка на такую гамильтоновую цепную часть обхода,
[01:31:27.000 --> 01:31:33.000]  плюс какое-то ребро дополнительное, которое в этом обходе всё-таки изначально было.
[01:31:33.000 --> 01:31:39.000]  И поскольку мы вольно удалять любое ребро, чтобы получить гамильтоновую цепь,
[01:31:39.000 --> 01:31:51.000]  то понятно, что лучше удалить ребро весом как можно больше, чтобы потом в эту оценку в правую часть добавить обратный вес этого ребра.
[01:31:51.000 --> 01:32:04.000]  Ну и если мы удаляем ребро, то как мы можем как-то получше оценить снизу вес такого ребра?
[01:32:04.000 --> 01:32:12.000]  Понятно, что можно оценить сам в таком консервативном варианте.
[01:32:12.000 --> 01:32:18.000]  Это просто как минимальный вес ребер по всем ребрам графа.
[01:32:18.000 --> 01:32:23.000]  Ну да, это будет справедливо.
[01:32:23.000 --> 01:32:32.000]  С другой стороны, может быть быть так, представим с такой картиной, что какая-нибудь вершина, какой-нибудь клиент у нас,
[01:32:32.000 --> 01:32:39.000]  задача о развозе пиццы, он живёт где-нибудь на отдалении.
[01:32:39.000 --> 01:32:49.000]  И тогда мы понимаем, что вот эта вершина графа, вообще любой способ до неё добраться, он довольно долгий.
[01:32:49.000 --> 01:32:56.000]  То есть минимальное по весу ребро, торчащее из конкретной вершины вот этой, оно большое.
[01:32:56.000 --> 01:33:01.000]  И оно гораздо больше, чем вообще минимальный вес ребер по всему графу.
[01:33:01.000 --> 01:33:10.000]  Так давайте мы из этой вершины как раз возьмём в кумилитоновом цикле, воображаемом оптимальном,
[01:33:10.000 --> 01:33:14.000]  именно какой-нибудь из ребер инцидентных этой вершины удалим.
[01:33:14.000 --> 01:33:20.000]  Тогда наша оценка вот здесь, она может быть немного улучшена.
[01:33:20.000 --> 01:33:29.000]  И мы можем написать, что Opt больше ли равен, чем MST, плюс максимум по всем вершинам графа.
[01:33:29.000 --> 01:33:36.000]  Но здесь по-прежнему будет минимум вес ребер инцидентных этой вершины.
[01:33:36.000 --> 01:33:42.000]  Я напоминаю, что через дельта от V обозначается множество всех ребер инцидентных вершине V.
[01:33:42.000 --> 01:33:49.000]  Ну и конечно, максимин – это лучше, чем просто мин по всему множеству ребер графа.
[01:33:49.000 --> 01:33:52.000]  Может оказаться существенно лучше.
[01:33:53.000 --> 01:33:59.000]  Дальше можно пойти ещё дальше и сказать, что если у нас есть клиент на ошибе,
[01:33:59.000 --> 01:34:05.000]  то это значит, что нам нужно до него дойти, а потом надо ещё вернуться в город, в центр города,
[01:34:05.000 --> 01:34:08.000]  если у нас там основная масса клиентов.
[01:34:08.000 --> 01:34:15.000]  И как бы нам сюда добавить тогда два ребра?
[01:34:15.000 --> 01:34:23.000]  Ну окей, говорим мы. Если взять из гамильтонового цикла вытащить не одно ребро,
[01:34:23.000 --> 01:34:29.000]  а вытащить сразу вершину и пару инцидентных ей ребер.
[01:34:29.000 --> 01:34:33.000]  То, что останется, это ведь будет гамильтоновой цепью.
[01:34:33.000 --> 01:34:39.000]  Но правда, это будет гамильтоновой цепью уже не во всём графе, а в графе без одной вершины.
[01:34:39.000 --> 01:34:44.000]  Но давайте мы возьмём вершину тогда так, чтобы оценка получалась получше.
[01:34:44.000 --> 01:34:52.000]  Тогда мы понимаем теперь, что мы можем максимизировать по всем вершинам графа вот такую вот штуку.
[01:34:52.000 --> 01:34:55.000]  Удаляем мысль на вершину.
[01:34:55.000 --> 01:35:04.000]  Мы понимаем, что если эту вершину удалять из гамильтонового обхода, то то, что остаётся,
[01:35:04.000 --> 01:35:09.000]  это гамильтоновая цепь нам нужно сделать в большое без в маленького.
[01:35:09.000 --> 01:35:19.000]  То есть МСТ от В без В маленького.
[01:35:19.000 --> 01:35:27.000]  Длину этой гамильтоновой цепи можно оценить вот таким вот весом минимального уставного дерева для под графа.
[01:35:27.000 --> 01:35:37.000]  Ну а дальше мы можем добавить сюда уже веса двух ребер, торчащих из этой вершины.
[01:35:37.000 --> 01:35:55.000]  Дальше мы можем взять и сказать, что давайте возьмём минимум по всем парам E1, E2 из дельта от В,
[01:35:55.000 --> 01:36:05.000]  где это различные ребра, конечно, W от E1 плюс W от E2.
[01:36:05.000 --> 01:36:18.000]  Ещё более интересная такая оценка получается, в которой мы можем учесть в этой оценке наличие таких вершин, которые на отшибе.
[01:36:18.000 --> 01:36:22.000]  То от них далеко до всех других вершин графа.
[01:36:22.000 --> 01:36:32.000]  И тогда мы практически одно большое число в этой предыдущей оценке можем заменить на плюс два каких-то больших числа.
[01:36:32.000 --> 01:36:37.000]  Ещё тем самым лучшим картинам.
[01:36:37.000 --> 01:36:43.000]  Ну дальше возникает вот такое соображение.
[01:36:43.000 --> 01:36:52.000]  Представим, что вот мы, например, решаем задачу такую вспомогательную, чтобы оценить снизу вес гамильтонного цикла.
[01:36:52.000 --> 01:37:03.000]  Задачу минимального уставного дерева для под графа В там без В маленькой, для какой-то там вершинки В маленькой.
[01:37:03.000 --> 01:37:07.000]  Для какой-то вершины В маленькой.
[01:37:07.000 --> 01:37:15.000]  И получаем какое-нибудь вот такое минимальное уставное дерево.
[01:37:15.000 --> 01:37:19.000]  Ну я дал воду своему воображению.
[01:37:19.000 --> 01:37:22.000]  Так, получаем вот такое уставное дерево.
[01:37:22.000 --> 01:37:26.000]  Очень какое-то ветвящиеся раскидки.
[01:37:26.000 --> 01:37:29.000]  Поднимаем, поднимаем, поднимаем.
[01:37:29.000 --> 01:37:34.000]  И вот, как я уже говорил, мы получаем вот такое уставное дерево.
[01:37:35.000 --> 01:37:39.000]  Ну я дал воду своему воображению.
[01:37:39.000 --> 01:37:42.000]  Так, получаем вот такое уставное дерево.
[01:37:42.000 --> 01:37:46.000]  Очень какое-то ветвящиеся, такое раскидистое.
[01:37:46.000 --> 01:37:56.000]  И мы понимаем, что, ну конечно, да, вес этого дерева это оценка снизу для весов гамильтонной цепи в графе.
[01:37:56.000 --> 01:37:58.000]  Для веса гамильтонной цепи любой.
[01:37:58.000 --> 01:38:02.000]  Но ведь это дерево совсем не похоже на гамильтонную цепь.
[01:38:02.000 --> 01:38:12.000]  И по всей видимости, раз оно структурно совсем не похоже на гамильтонную цепь, то и оценка далека вот реалистичной.
[01:38:12.000 --> 01:38:25.000]  То есть в идеале, конечно, мы хотели бы решить как-то вот задачу о том, чтобы построить в графе, ну, уставное дерево, которое по весу как можно меньше,
[01:38:25.000 --> 01:38:29.000]  но при этом оно как можно больше похоже на гамильтонную цепь.
[01:38:29.000 --> 01:38:34.000]  Но как это сделать все-таки?
[01:38:34.000 --> 01:38:42.000]  Если мы построим в графе какой-то вообще уже не минимального оставного дерева с какими-то дополнительными структурными ограничениями,
[01:38:42.000 --> 01:38:51.000]  то не факт совершенно, что это дерево будет давать нижнюю оценку полноценным на вес гамильтонной цепи.
[01:38:51.000 --> 01:38:58.000]  Но вот интуиция как-то, она ясна, что когда оцениваешь вес одного объекта другим,
[01:38:58.000 --> 01:39:05.000]  если структура этих объектов выясняется, что они очень какие-то разные по виду, то, наверное, эта оценка не там и лучшая.
[01:39:05.000 --> 01:39:10.000]  Тогда направляется такая идея.
[01:39:10.000 --> 01:39:19.000]  А давайте мы попробуем граф модифицировать так, чтобы в нем автоматически просто минимального оставного дерева получалось похожим на гамильтонную цепь.
[01:39:19.000 --> 01:39:23.000]  Но в том у нас непохожесть бывает.
[01:39:23.000 --> 01:39:34.000]  Непохожесть бывает в том, что у дерева может быть много вершин степени 1, а в гамильтоновой цепи у нас всего две вершины степени 1 в конце этой цепи.
[01:39:34.000 --> 01:39:40.000]  Еще у дерева могут быть вершины, наоборот, степени больше, чем нужно, степени больше двух.
[01:39:40.000 --> 01:39:47.000]  И вот от таких ситуаций нам надо бы избавляться.
[01:39:47.000 --> 01:39:52.000]  Давайте рассмотрим такую идею.
[01:39:52.000 --> 01:40:01.000]  Возьмем граф, и в этом графе возьмем вершину,
[01:40:01.000 --> 01:40:09.000]  и всем ребрам инцидентным этой вершине добавим кто-нибудь.
[01:40:09.000 --> 01:40:17.000]  Давайте добавим плюс и эпсилон на каждое ребро,
[01:40:17.000 --> 01:40:25.000]  где эпсилон не обязательно маленькая константа, ну какая-то константа, а может быть она даже отрицательная.
[01:40:25.000 --> 01:40:37.000]  Главное, чтобы веса всех ребер у нас сохранялись не отрицательными.
[01:40:37.000 --> 01:40:46.000]  Берем такую константу, добавляем ко всем ребрам инцидентным этой вершины.
[01:40:46.000 --> 01:40:51.000]  Что у нас происходит с любым гамильтоновым циклом?
[01:40:51.000 --> 01:41:01.000]  Любой гамильтонов цикл проходит через вершину ровно один раз, то есть он использует ровно два ребра инцидентных этой вершины.
[01:41:01.000 --> 01:41:15.000]  При таком локальном преобразовании в одной вершине графа мы получаем, что любой гамильтонов цикл увеличивается по весу ровно на 2 эпсилон.
[01:41:15.000 --> 01:41:21.000]  А раз мы все гамильтоновые циклы в графе одинаково изменили,
[01:41:21.000 --> 01:41:31.000]  веса всех циклов изменились одинаково, объективно, над 2 эпсилон, то значит оптимальные циклы остались оптимальными.
[01:41:31.000 --> 01:41:42.000]  Множество оптимальных циклов как под графов у нас вообще никак не поменялось при таком локальном преобразовании.
[01:41:43.000 --> 01:41:53.000]  Соответственно, давайте представим, что мы в новом графе, точнее в графе с новыми весами, получили какую-то оценку.
[01:41:54.000 --> 01:42:00.000]  Оптимум для этого графа, такой оптимум штрих, больше ли равен t?
[01:42:00.000 --> 01:42:12.000]  Но тогда мы понимаем, что для исходного графа оптимум, он в точности равен оптимум штрих минус 2 эпсилон,
[01:42:12.000 --> 01:42:20.000]  и мы можем сказать, что окей, тогда вот этот оптимум больше ли равен, чем t, минус 2 эпсилон?
[01:42:20.000 --> 01:42:29.000]  То есть от оценки для графа с измененными весами мы можем перейти к оценке для исходного графа.
[01:42:29.000 --> 01:42:43.000]  Ну и можно эту конструкцию обобщить.
[01:42:43.000 --> 01:42:53.000]  Ведь мы можем не у одной вершины изменить все веса всех ребер, а скорее эту картину понимать вот так.
[01:42:53.000 --> 01:43:05.000]  Давайте мы у каждой вершины просто введем такую вот величину, эпсилон с индексом v.
[01:43:05.000 --> 01:43:16.000]  И вот будем считать, что у нас веса в графе новые, они вычисляются вот так.
[01:43:16.000 --> 01:43:27.000]  Новый вес ребра uv, это старый вес ребра uv, плюс эпсилон u, плюс эпсилон v.
[01:43:27.000 --> 01:43:32.000]  Тогда нетрудно видеть, что преобразование оценок...
[01:43:32.000 --> 01:43:39.000]  Не трудно видеть, что, во-первых, оптимальный гамильтоновый цикл опять-таки остается оптимальными после такого преобразования весов.
[01:43:39.000 --> 01:43:51.000]  А изменения будут равны пыклых вот такой величине, удвоенной сумме всех эпсилонов, по всем вершинам графа.
[01:43:51.000 --> 01:44:00.000]  По ровной той же причине, потому что в каждой вершине инцидентно ровно два ребра гамильтонового цикла.
[01:44:00.000 --> 01:44:05.000]  Вот она получается, константная такая объективная добавка.
[01:44:05.000 --> 01:44:21.000]  И следовательно, мы можем опять-таки вот оценки для вот такого графа измененного перейти к оценке для исходного графа для веса оптимального цикла.
[01:44:21.000 --> 01:44:35.000]  Два сумма эпсилон с индексом v для исходного графа.
[01:44:35.000 --> 01:44:49.000]  Но теперь, казалось бы, можем поменять вот так веса и получить такой пересчет оценок.
[01:44:49.000 --> 01:45:02.000]  Но зачем мы это делаем? А вот мы это как раз можем сделать для того, чтобы заставить минимальное островное дерево в новом графе выглядеть как можно ближе к гамильтоновой цепи.
[01:45:02.000 --> 01:45:17.000]  Просто автоматически. Вот, допустим, мы в исходном графе островное дерево какое-то имеем, и оно у нас получается сильно каким-то ветвящимся неправильным, не похоже на гамильтоновую цепь.
[01:45:17.000 --> 01:45:23.000]  Ну вот есть вершины, которые не в степень больше, чем нужно.
[01:45:23.000 --> 01:45:36.000]  Значит, такие вершины мы с вами берем и говорим, что, ага, вот для этих вершин эпсилон с индексом v давайте сделаем меньше нуля.
[01:45:36.000 --> 01:45:49.000]  Немного уменьшим веса рёбер инцидентных этой вершине для того, чтобы было выгодно брать не одно ребро минимального островного дерева, а парочку.
[01:45:49.000 --> 01:46:05.000]  А другие вершины, у которых наоборот ветвление больше, чем нужно, здесь мы эпсилон v у такой вершины берем больше нуля, чтобы рёбра, торчащие из этой вершины, потяжелели.
[01:46:05.000 --> 01:46:11.000]  И эти рёбра надо было бы брать этих рёбер поменьше, минимального островного дерева.
[01:46:11.000 --> 01:46:21.000]  И вот мы вот так изменяем веса, пересчитываем минимальное островное дерево с новыми весами.
[01:46:21.000 --> 01:46:27.000]  Если оно сильно не похоже на гамильтоновую цепь, мы еще раз пересчитываем веса.
[01:46:27.000 --> 01:46:41.000]  Можно представить такой итеративный процесс, который ищет, подбирает такой набор весов на вершинах,
[01:46:41.000 --> 01:46:52.000]  при котором минимальное островное дерево в графе автоматически приближается по структуре к гамильтоновой цепи.
[01:46:58.000 --> 01:46:59.000]  Давайте я.
[01:47:04.000 --> 01:47:05.000]  Вот у меня есть.
[01:47:07.000 --> 01:47:08.000]  Здесь в этой книжке.
[01:47:17.000 --> 01:47:18.000]  252 страница.
[01:47:24.000 --> 01:47:25.000]  252 страница.
[01:47:27.000 --> 01:47:31.000]  Вот здесь приведен алгоритм.
[01:47:31.000 --> 01:47:34.000]  Это называется оценка Гельда Карпа.
[01:47:36.000 --> 01:47:39.000]  Или оценка 1-3, 1-3 bound.
[01:47:40.000 --> 01:47:47.000]  Здесь приведен полный такой алгоритм подбора хороших константов.
[01:47:48.000 --> 01:47:58.000]  Для графа с весами ребер С, Е и вершины В1.
[01:47:58.000 --> 01:48:11.000]  В1 – это та вершина, которую мы из графа удаляем, когда рассматриваем гамильтоновую цепь по всем остальным вершинам графа.
[01:48:17.000 --> 01:48:23.000]  Веса на вершинах здесь обозначены не епсилон с индексом В, а у с индексом В.
[01:48:27.000 --> 01:48:29.000]  Процесс итеративный получается.
[01:48:31.000 --> 01:48:34.000]  Берется минимальное островное дерево.
[01:48:38.000 --> 01:48:40.000]  Здесь, правда, с минусом берутся епсилон.
[01:48:40.000 --> 01:48:41.000]  Не важно.
[01:48:47.000 --> 01:48:59.000]  Если это дерево соответствует гамильтоновой цепи, то есть если добавление в это дерево вершины В1 дает нам гамильтонов цикл,
[01:48:59.000 --> 01:49:04.000]  то тогда можно останавливаться, тогда мы имеем оптимальную оценку.
[01:49:04.000 --> 01:49:08.000]  В противном случае мы пересчитываем веса.
[01:49:08.000 --> 01:49:10.000]  Как они пересчитываются?
[01:49:10.000 --> 01:49:12.000]  Здесь написано.
[01:49:12.000 --> 01:49:24.000]  Пересчитываются они, как видите, исходя из разницы между
[01:49:24.000 --> 01:49:30.000]  целевой степенью вершины в минимальном островном дереве и реальной.
[01:49:30.000 --> 01:49:39.000]  Почти все вершины в минимальном островном дереве нам хотелось бы, чтобы они имели степень 2, чтобы она была похожа на гамильтоновую цепь.
[01:49:40.000 --> 01:49:45.000]  Если больше двойки, меньше двойки, значит надо корректировать веса-рёбер при этой вершине.
[01:49:45.000 --> 01:49:49.000]  Ну вот, здесь можно посмотреть псевдопод.
[01:49:49.000 --> 01:49:58.000]  Вот в этом разделе книжки Укра-Кангема, Вали-Баленка, Схривера, точнее, Схарайра.
[01:49:58.000 --> 01:50:08.000]  Это голландец, а голландцы интересно произносят сочетание хр.
[01:50:08.000 --> 01:50:18.000]  На идее самой мы здесь и остановимся таким образом.
[01:50:18.000 --> 01:50:22.000]  Такой takeaway.
[01:50:22.000 --> 01:50:24.000]  В чем у нас takeaway здесь?
[01:50:24.000 --> 01:50:32.000]  Во-первых, я думаю, что не стоит лениться с получением коротких нижних оценок,
[01:50:32.000 --> 01:50:42.000]  потому что вот эти конструкции предполагают решение задачи о минимальном островном дереве не сильно больше того.
[01:50:42.000 --> 01:50:48.000]  А мы задачу о минимальном островном дереве и так уже, скорее всего, порешаем много раз,
[01:50:48.000 --> 01:51:04.000]  хотя бы разочек порешаем, когда диаграфы будем запускать или алгоритмы Кристофидеса,
[01:51:04.000 --> 01:51:12.000]  вот это у нас всё будет. Игра стоит свечей здесь.
[01:51:12.000 --> 01:51:18.000]  Такая оценка выглядит, конечно, посложнее, чем просто взять и оценить вот так.
[01:51:18.000 --> 01:51:28.000]  Ну и веса подбирать это выглядит посложнее, чем их не подбирать, но оценка, правда, получится сильно лучше.
[01:51:28.000 --> 01:51:32.000]  Так, сейчас народ, одну секундочку.
[01:51:32.000 --> 01:51:44.000]  И постановки. Что если мы задачу камевые жора решаем с помощью ЦЛП?
[01:51:44.000 --> 01:51:46.000]  Вот мы пока что рассматривали.
[01:51:46.000 --> 01:51:48.000]  Комбинаторные какие-то подходы.
[01:51:48.000 --> 01:51:58.000]  Давайте мы ЦЛП формулировки для задачи камевые жора посмотрим.
[01:51:58.000 --> 01:52:04.000]  Какие можно ЦЛП модели ставить?
[01:52:04.000 --> 01:52:12.000]  Ну, первая модель, оказывается, это цилиндровая.
[01:52:12.000 --> 01:52:22.000]  Такая стандартная модель с самым стандартным выбором решающих переменных.
[01:52:22.000 --> 01:52:26.000]  X и T, житая.
[01:52:26.000 --> 01:52:32.000]  Для каждого ребра возьмем переменную.
[01:52:32.000 --> 01:52:38.000]  Даже не для каждого, для каждой пары вершин в график, потому что мы по-прежнему, давайте считать, что граф,
[01:52:38.000 --> 01:52:48.000]  у нас полный, хотя это, в общем, не обязательно уже в ЦЛП модели, но давайте для пары вершин возьмем переменную равную единице,
[01:52:48.000 --> 01:52:56.000]  если в камельтоновом цикле мы из вершины и идем в вершину.
[01:52:56.000 --> 01:53:02.000]  Причем будем считать наш камельтонов цикл ориентированным.
[01:53:02.000 --> 01:53:08.000]  Нам будет удобно так делать.
[01:53:08.000 --> 01:53:16.000]  Вот, значит, считать камельтонов цикл ориентированным, то есть у нас в постановке будут и переменные X и T, житая,
[01:53:16.000 --> 01:53:22.000]  и переменная X, житая, и T.
[01:53:22.000 --> 01:53:28.000]  Вот, в обе стороны.
[01:53:28.000 --> 01:53:34.000]  То мы можем с неравенствами написать.
[01:53:34.000 --> 01:53:40.000]  Ну, сначала неравенство на степени вершин, наверное.
[01:53:40.000 --> 01:53:46.000]  Значит, из каждой вершины выходит и входит ровно по одной дуге.
[01:53:46.000 --> 01:53:54.000]  Это значит, что сумма X и g по всем i, давайте, по всем j, по всем j от единицы до n,
[01:53:54.000 --> 01:54:02.000]  значит, у нас есть неравенство на степени вершины.
[01:54:02.000 --> 01:54:08.000]  Давайте, по всем j, по всем j от единицы до n.
[01:54:08.000 --> 01:54:18.000]  Значит, у нас равняется сумма X и j по всем i.
[01:54:18.000 --> 01:54:30.000]  X, житая, и T тоже по всем j от единицы до n, равняется единичке, равняется единице.
[01:54:30.000 --> 01:54:34.000]  Задает ли вот такой набор соотношений?
[01:54:34.000 --> 01:54:39.000]  Естественно, что это содержательное определение переменных,
[01:54:39.000 --> 01:54:48.000]  но когда мы формулируем задачу CLP, у нас просто будут некие переменные от нуля до единицы,
[01:54:48.000 --> 01:54:54.000]  целочисленные, и плюс набор вот этих вот соотношений.
[01:54:54.000 --> 01:55:01.000]  Кодирует ли нам набор таких соотношений в точности гамильтоновой циклы или нет?
[01:55:01.000 --> 01:55:04.000]  Возникает вопрос.
[01:55:04.000 --> 01:55:11.000]  Ну, видно, что нет, не обязательно.
[01:55:11.000 --> 01:55:24.000]  У нас могут быть наборы, например, дуг, которые образуют непересекающиеся циклы.
[01:55:24.000 --> 01:55:31.000]  Да, это будет множество непересекающихся циклов, покрывающих все вершины графа,
[01:55:31.000 --> 01:55:46.000]  но даже могут быть вот такие казусы, что одно и то же ребро просто пройдено в двух направлениях,
[01:55:46.000 --> 01:55:52.000]  и получается тоже такой цикл на двух вершинах.
[01:55:52.000 --> 01:55:57.000]  Но только что петель нет, ладно, и то хорошо.
[01:55:57.000 --> 01:56:03.000]  Вот такая загвоздка.
[01:56:03.000 --> 01:56:13.000]  Тем не менее, даже такая целочисленная модель и даже ее релаксация,
[01:56:13.000 --> 01:56:20.000]  представьте, что вы даже определение целочисленности опустили и взяли просто вот такую задачу,
[01:56:20.000 --> 01:56:27.000]  задачу с действительными переменными и вот с этими соотношениями.
[01:56:27.000 --> 01:56:32.000]  Ведь это релаксация, задача минимизации.
[01:56:32.000 --> 01:56:38.000]  И сама эта задача минимизации является релаксацией задачи камевы и жора.
[01:56:38.000 --> 01:56:45.000]  Потому что мы понимаем, что любой гамильтонов цикл, он удовлетворяет вот этим условиям,
[01:56:45.000 --> 01:56:52.000]  но не обязательно любое решение этой задачки является гамильтоновым циклом.
[01:56:52.000 --> 01:57:01.000]  Получается, что сама эта задача, поставленная, является релаксацией задачи о гамильтоновом цикле.
[01:57:01.000 --> 01:57:11.000]  И оптимальное значение целевой функции, а целевая функция у нас это,
[01:57:11.000 --> 01:57:15.000]  вот это то, что я сейчас забыл написать, конечно, то, что мы минимизируем.
[01:57:15.000 --> 01:57:25.000]  Мы минимизируем сумму х и т, ж и т на w и g.
[01:57:25.000 --> 01:57:34.000]  Значение целевой функции в релаксированной задаче у нас будет нижней оценкой на значение целевой функции в исходной задаче.
[01:57:34.000 --> 01:57:41.000]  То есть получается, что можно решить быстро достаточно вот такую задачку,
[01:57:41.000 --> 01:57:49.000]  и это будет тоже нижней оценкой в дополнении к вот таким комбинаторным нижним оценкам,
[01:57:49.000 --> 01:57:54.000]  которые у нас уже есть, на решение задачи камевы и жора.
[01:57:54.000 --> 01:57:59.000]  А вот пригодится. Да, вот такая оценка получится лучше.
[01:57:59.000 --> 01:58:07.000]  Но можно ведь еще пойти дальше, да?
[01:58:07.000 --> 01:58:22.000]  Можно пойти еще дальше и сказать, что на самом деле вот такая задачка
[01:58:22.000 --> 01:58:27.000]  это задача о пароточитании в вдольном графе.
[01:58:27.000 --> 01:58:34.000]  Потому что мы можем с вами такой граф нарисовать, в котором верхние и нижние доли
[01:58:34.000 --> 01:58:45.000]  содержат по n вершин, и ребра имеют те веса, которые у нас были в исходной.
[01:58:45.000 --> 01:58:53.000]  Вот здесь вот, да, и у нас есть и такое ребро, и j, и ребро j и j.
[01:58:53.000 --> 01:58:59.000]  Естественно, что веса этих двух ребер одинаковые, если исходный граф был неориентированный.
[01:58:59.000 --> 01:59:09.000]  Но ничего. У нас получается вот такие условия для целочисленных переменных
[01:59:09.000 --> 01:59:12.000]  на самом деле задают в графе пароточитание.
[01:59:12.000 --> 01:59:17.000]  То есть мы из каждой вершины верхней доли проводим ровно одно ребро вниз,
[01:59:17.000 --> 01:59:21.000]  и в каждую вершину нижней доли тоже у нас входит ровно одно ребро.
[01:59:21.000 --> 01:59:24.000]  Вот мы можем это понимать так.
[01:59:24.000 --> 01:59:30.000]  А у нас с вами уже есть алгоритм, который решает задачу о совершенном пароточитании
[01:59:30.000 --> 01:59:36.000]  минимального веса.
[01:59:36.000 --> 01:59:46.000]  Задача о назначениях.
[01:59:46.000 --> 02:00:03.000]  Так что мы с вами сейчас выясняем, что не только задача о минимальном островном дереве,
[02:00:03.000 --> 02:00:08.000]  не только вот такой объект связан с гамильтоновыми циклами.
[02:00:08.000 --> 02:00:13.000]  И можно считать, что задача о минимальном островном дереве – это такая релаксация задача
[02:00:13.000 --> 02:00:15.000]  о минимальной гамильтоновой цепи.
[02:00:15.000 --> 02:00:23.000]  Потому что гамильтоновая цепь – это цепь в графе, проходящая через все вершины.
[02:00:23.000 --> 02:00:26.000]  В частности, она связана.
[02:00:26.000 --> 02:00:31.000]  А островное дерево – это задача об островном дереве – это поиск по более широкому множеству объектов.
[02:00:31.000 --> 02:00:37.000]  То есть можно считать, что задача МСТ – это релаксация задачи о гамильтоновой цепи.
[02:00:37.000 --> 02:00:42.000]  Но точно так же мы можем считать, что задача о назначениях, например,
[02:00:42.000 --> 02:00:46.000]  это такая релаксация задачи Камевы и Жора.
[02:00:46.000 --> 02:00:52.000]  Потому что задача о назначениях – это просто другой взгляд немножко,
[02:00:52.000 --> 02:00:58.000]  с точки зрения двудольного такого графа, на ту же самую систему соотношений,
[02:00:58.000 --> 02:01:07.000]  которую можно тратить как поиск в заданном графе набора не пересекающихся циклов минимального веса.
[02:01:07.000 --> 02:01:11.000]  Но задача о гамильтоновом цикле более сильная.
[02:01:11.000 --> 02:01:16.000]  Нам требуется ровно один цикл в графе, покрывающий все вершины.
[02:01:16.000 --> 02:01:24.000]  А сейчас у нас пока здесь произвольный набор не пересекающихся циклов, покрывающих все вершины.
[02:01:25.000 --> 02:01:30.000]  Вот, смотрите, сколько у нас возможностей для того, чтобы релаксировать задачи Камевы и Жора,
[02:01:30.000 --> 02:01:36.000]  чтобы получить нижние оценки на реликват оптимального гамильтонового цикла.
[02:01:39.000 --> 02:01:45.000]  Я напишу, что это фактически задача о назначениях.
[02:01:46.000 --> 02:01:50.000]  Задача о назначениях.
[02:01:50.000 --> 02:01:55.000]  А как же все-таки сделать ее задачей о Камевы и Жоре?
[02:01:55.000 --> 02:02:02.000]  Ну, придется как-то связанность здесь дополнить, задачи требованиями на связанность.
[02:02:02.000 --> 02:02:11.000]  И первый вариант, это то, что называется sub-tour constraints.
[02:02:16.000 --> 02:02:28.000]  То есть условия, которые исключают такой вариант, что у нас цикл какой-то отваливается,
[02:02:28.000 --> 02:02:35.000]  чтобы вообще все разваливается на не пересекающиеся циклы sub-tour constraints.
[02:02:35.000 --> 02:02:47.000]  Давайте просто запретим нашему набору циклов быть несвязанным.
[02:02:47.000 --> 02:02:53.000]  То есть скажем, что как бы мы ни разбили множество вершин графа на два подможества,
[02:02:53.000 --> 02:03:00.000]  у нас обязательно вот этот набор х содержит какой-то х не нулевой,
[02:03:00.000 --> 02:03:04.000]  соответствующей дуге справа налево, слева направо.
[02:03:04.000 --> 02:03:09.000]  Ну и очевидно, что если есть дуга слева направо, то будет дуга справа налево тоже.
[02:03:09.000 --> 02:03:12.000]  Но мы можем это записать каким образом?
[02:03:12.000 --> 02:03:24.000]  Что для любого подможества вершин не пустого, можно даже написать так,
[02:03:24.000 --> 02:03:31.000]  что вершин не пустого, а с другой стороны содержащего не более половинки от всех вершин,
[02:03:31.000 --> 02:03:34.000]  потому что ясно, что картина симметричная,
[02:03:34.000 --> 02:03:42.000]  и можно считать всегда, что слева мы нарисовали меньшее из компонентов разбегения.
[02:03:42.000 --> 02:03:59.000]  У нас будет сумма х ежитая, где i из v', а j из v' и мы скажем, что это больше 1.
[02:03:59.000 --> 02:04:09.000]  Слева направо идет хотя бы одна дуга.
[02:04:09.000 --> 02:04:15.000]  Проблема этих саптур constraints очевидна, что их слишком много, экспоненциально много.
[02:04:15.000 --> 02:04:22.000]  Но на самом деле, на практике, конечно, никогда их не добавляют в задачу целиком.
[02:04:22.000 --> 02:04:28.000]  Скорее, здесь происходит что-нибудь такое.
[02:04:28.000 --> 02:04:37.000]  Вот опять-таки, если мы понимаем, что у нас на отшибе вот здесь что-нибудь такое, район какой-нибудь, и город,
[02:04:37.000 --> 02:04:45.000]  и нам нужно в гамильдионных обходs проводщику пиццы построить, которому приходится заезжать вот в этот окраин.
[02:04:45.000 --> 02:04:54.000]  Вот тогда как раз и имеет смысл из множества вот этого экспоненциального саптур constraints выбрать
[02:04:54.000 --> 02:05:03.000]  ну хотя бы условия, что вот отсюда-сюда есть хотя бы одна дуга, и отсюда-сюда тоже есть хотя бы одна дуга.
[02:05:04.000 --> 02:05:15.000]  Уже будет profit, уже будет лучшая оценка на решение, чем вообще без вот этих условий.
[02:05:15.000 --> 02:05:23.000]  А так вообще бывает интерактивное использование вот этих саптур constraints.
[02:05:23.000 --> 02:05:31.000]  То есть мы запускаем решение вот этой вот задачки без вот этих условий и смотрим просто, что получится.
[02:05:31.000 --> 02:05:40.000]  Если получается набор непересекающихся циклов, то мы добавляем конкретное какое-нибудь вот из этих условий,
[02:05:40.000 --> 02:05:45.000]  так чтобы вот конкретно от такого набора непересекающихся циклов избавиться.
[02:05:45.000 --> 02:05:56.000]  И как правило, недостаточно небольшого количества последовательно добавляемых ограничений хватает для того,
[02:05:56.000 --> 02:06:05.000]  чтобы получить решение задачки, уже полноценное решение задачки Камивы и Жора.
[02:06:05.000 --> 02:06:16.000]  Ну, что я здесь допишу, что ограничений много, но они добавляются интерактивно.
[02:06:16.000 --> 02:06:23.000]  Ограничений много, но все сразу не добавляем.
[02:06:23.000 --> 02:06:43.000]  Все сразу на практике не добавляют. Вводят их интерактивно, перезапуская протеп.
[02:06:43.000 --> 02:06:55.000]  Ну, либо вводят, глядя просто на задачу, на входные данные, сразу понимая, что вот такие-то ограничения добавить имеют смысл.
[02:06:55.000 --> 02:07:15.000]  Ну и второй вид ограничений, которые называются МТЗ-ограничения, от фамилий просто Миллера, Такера и Землина.
[02:07:15.000 --> 02:07:30.000]  И это ограничение уже комбинаторного такого характера. Все ограничения до сих пор имеют мощностной характер.
[02:07:30.000 --> 02:07:36.000]  Здесь у нас не больше, чем столько ребер, здесь не меньше, чем столько ребер.
[02:07:36.000 --> 02:07:44.000]  А условия МТЗ имеют другую природу, не мощностную.
[02:07:44.000 --> 02:07:48.000]  Давайте введем такие переменные.
[02:07:48.000 --> 02:07:52.000]  Переменная УИ.
[02:07:52.000 --> 02:08:02.000]  Переменная УИ будет означать номер шага, смысл этой переменной.
[02:08:02.000 --> 02:08:19.000]  Это номер шага, на котором посещена вершина с номером И.
[02:08:19.000 --> 02:08:30.000]  Если считать, что Гамильтонов цикл начит из вершин с номером 1.
[02:08:30.000 --> 02:08:36.000]  Нам такие переменные понадобятся для всех И от двойки до Н.
[02:08:36.000 --> 02:08:43.000]  Для всех таких вот номеров вершин мы введем соответствующую переменную УИ.
[02:08:43.000 --> 02:08:53.000]  И рассмотрим для всех пар И и Ж у двойки до Н вот такие вот ограничения.
[02:08:53.000 --> 02:09:08.000]  УИТ минус УЖТ плюс НхИТЖТ меньше или равно, чем Н-1.
[02:09:08.000 --> 02:09:20.000]  Давайте заметим, что если набор переменных Иксов задает нам действительно Гамильтонов цикл,
[02:09:20.000 --> 02:09:27.000]  если переменные УЖКи определены согласно вот такому содержательному смыслу,
[02:09:27.000 --> 02:09:32.000]  то тогда все такие ограничения действительно выполняются.
[02:09:32.000 --> 02:09:42.000]  Потому что УЖКи у нас от единицы до Н получаются.
[02:09:42.000 --> 02:09:49.000]  И разность двух чисел, каждая из которых от одного до Н, она не превосходит Н-1.
[02:09:49.000 --> 02:09:59.000]  И если ребра между вершиной И и Ж у нас нету, то тогда здесь у нас получается нолик,
[02:09:59.000 --> 02:10:05.000]  здесь получается что-то не больше, чем Н-1, ну и неравенство выполняется.
[02:10:05.000 --> 02:10:11.000]  Если же у нас дуга как раз в Гамильтоновом цикле между вершинами И и Ж есть,
[02:10:11.000 --> 02:10:15.000]  тогда здесь у нас получается Н.
[02:10:15.000 --> 02:10:20.000]  Но тогда УЖТ как раз на единицу больше, чем УИТ, потому что получается,
[02:10:20.000 --> 02:10:26.000]  что вершина Ж посещена ровно на шаг позже, чем вершина И.
[02:10:26.000 --> 02:10:37.000]  И вот у нас получается, что здесь минус единичка, здесь Н, и опять-таки неравенство выполняется.
[02:10:37.000 --> 02:10:50.000]  Стало быть, мы введя такие ограничения и сказав, что у ИТ от единички до Н,
[02:10:50.000 --> 02:10:59.000]  и УИТ это целое число при каждом, и введя вот такой набор ограничений, мы с вами ничего не потеряли.
[02:10:59.000 --> 02:11:09.000]  То есть Гамильтонов цикл, любой, он по-прежнему удовлетворяет тем дополнительно введенным ограничениям
[02:11:09.000 --> 02:11:17.000]  при подходящем выборе значений переменных у И.
[02:11:17.000 --> 02:11:23.000]  Теперь я хотел бы доказать, что этот набор ограничений решает задачку.
[02:11:23.000 --> 02:11:31.000]  То есть он устраняет все такие наборы ИКСов, которые не задавали нам Гамильтонов цикл.
[02:11:31.000 --> 02:11:46.000]  Ну и давайте рассмотрим набор ИКСов, Задающих объединение нескольких непересекающихся циклов.
[02:11:46.000 --> 02:11:54.000]  Объединение нескольких циклов, не менее двух.
[02:11:54.000 --> 02:12:11.000]  Циклов, один из которых, ну такой, и один, и два, и так далее, и с индексом А.
[02:12:11.000 --> 02:12:19.000]  Причем очевидно, что если у нас есть хотя бы два цикла, то мы можем,
[02:12:19.000 --> 02:12:26.000]  среди них, найти какой-то цикл, который не содержит единицу, не содержит вершину с номером один.
[02:12:26.000 --> 02:12:54.000]  То есть будем считать, что все вот эти Ишки, они не равны единице, не равны единице.
[02:12:54.000 --> 02:13:02.000]  Давайте рассмотрим тогда, среди всех наших ограничений, вот как раз набор ограничений, соответствующих парам.
[02:13:02.000 --> 02:13:11.000]  И 1, и 2, плюс там n на х, и 1, и 2, меньше или равняется, чем n-1.
[02:13:11.000 --> 02:13:23.000]  И так далее, у и к, минус у и 1, плюс n на х, и к, и 1, меньше или равен, чем n-1.
[02:13:23.000 --> 02:13:28.000]  Вот у нас среди прочих ограничений есть в том числе и вот такие.
[02:13:28.000 --> 02:13:35.000]  Если мы с вами их сложим все, то что за ограничения мы получим?
[02:13:35.000 --> 02:13:49.000]  Ну вот даже второе ограничение, у и 2, минус у и 3, плюс n на х, и 2, и 3, меньше или равняется, чем n-1.
[02:13:49.000 --> 02:13:57.000]  Складываем, что получаем? Вот эти вот Ушки у нас уходят, потому что они с разными знаками.
[02:13:57.000 --> 02:14:05.000]  И даже вот эти вот Ушки в итоге уйдут. Значит все У, они вообще ушли.
[02:14:05.000 --> 02:14:10.000]  Ну и остается слева n на сумму х.
[02:14:10.000 --> 02:14:16.000]  А заметим, что раз у нас набор х задает вот такой вот гамильтонов цикл,
[02:14:16.000 --> 02:14:21.000]  не виноват, вот такой вот просто цикл в графе, как раз не гамильтонов,
[02:14:21.000 --> 02:14:24.000]  то тогда все эти х у нас равны единице.
[02:14:24.000 --> 02:14:33.000]  И получается, что n слева по факту, а справа n помножить на к,
[02:14:33.000 --> 02:14:44.000]  а справа n-1 помножить на х. И это противоречие.
[02:14:44.000 --> 02:14:50.000]  То есть невозможно на самом деле, чтобы вот такой набор их слов,
[02:14:50.000 --> 02:14:58.000]  который числе прочего образовал цикл, не проходящий через вершину с номером 1,
[02:14:58.000 --> 02:15:03.000]  и он удовлетворил всем и нашим условиям.
[02:15:03.000 --> 02:15:09.000]  Ну а раз у нас никакой цикл не обходит вершину с номером 1,
[02:15:09.000 --> 02:15:16.000]  вот каждый цикл проходит через нее, значит у нас цикл равный 1.
[02:15:16.000 --> 02:15:22.000]  Стало быть, х задает гамильтонов цикл.
[02:15:22.000 --> 02:15:27.000]  Вот такой у нас получилась такая модель.
[02:15:27.000 --> 02:15:33.000]  Тоже можно, конечно, снимать вот это ограничение на целочисленность
[02:15:33.000 --> 02:15:44.000]  и использовать линейную релаксацию вот такой вот постановки вместо subtour constraints,
[02:15:44.000 --> 02:15:50.000]  брать mtz плюс вот этот вот костяк ограничений
[02:15:50.000 --> 02:15:57.000]  и тоже брать минимальное значение целевых функций в задачи линейного программирования
[02:15:57.000 --> 02:16:05.000]  как нижнюю оценку на оптимальное значение цикла камневого ежора.
[02:16:05.000 --> 02:16:11.000]  Сегодня мы с вами довольно много поговорили о задачах камневого ежора.
[02:16:11.000 --> 02:16:16.000]  Мы посмотрели жадные ивристики для метрической задачи,
[02:16:16.000 --> 02:16:26.000]  выяснили, что кратчайшие вставки при некоторой постановке,
[02:16:26.000 --> 02:16:31.000]  если мы выбираем вершину в два пресеста, то есть сначала выбираем саму вершину,
[02:16:31.000 --> 02:16:35.000]  которую вставляем, и только потом выбираем, как именно ее вставить,
[02:16:35.000 --> 02:16:39.000]  можно проанализировать кратчайшие вставки с помощью алгоритма prima,
[02:16:39.000 --> 02:16:45.000]  взяв между ними как бы проведя параллели такие структурами.
[02:16:45.000 --> 02:16:48.000]  Ближайший сосед мы его анализировали по-другому,
[02:16:48.000 --> 02:16:52.000]  с использованием искренно-манированного маркова и так далее.
[02:16:52.000 --> 02:16:56.000]  И надо иметь в виду, что на практике это не значит,
[02:16:56.000 --> 02:17:01.000]  что надо запускать там всегда кратчайшие вставки и никогда не запускать ближайшего соседа.
[02:17:01.000 --> 02:17:06.000]  На самом деле надо запустить скорее всего и то и другое и посмотреть, что лучше окажется.
[02:17:06.000 --> 02:17:12.000]  Мы рассмотрели с вами затем еще два алгоритма,
[02:17:12.000 --> 02:17:23.000]  основанных на спрямление обходов в глубину минимально воздовного дерева
[02:17:23.000 --> 02:17:29.000]  и алгоритм Кристофидеса, который вместо обхода в глубину дерева
[02:17:29.000 --> 02:17:37.000]  начинает цели обхода мультиграфа, построенного на дереве, плюс некоторым паросочетанием.
[02:17:37.000 --> 02:17:41.000]  Алгоритм Кристофидеса является наилучшим на сегодняшний день
[02:17:41.000 --> 02:17:46.000]  нерандомизированным алгоритмом для решения задачи МСТ.
[02:17:46.000 --> 02:17:51.000]  Буквально пару лет назад там были сделаны некоторые подвижки,
[02:17:51.000 --> 02:17:55.000]  но это рандомизированный алгоритм, насколько мне известно.
[02:17:55.000 --> 02:18:03.000]  И его анализ 100 раз более продвинутый, чем алгоритм Кристофидеса.
[02:18:03.000 --> 02:18:08.000]  Вы можете поискать в интернете, что сейчас умеет делать.
[02:18:08.000 --> 02:18:18.000]  Эта константа чуть-чуть была улучшена на какие-то маленькие доли, 10 в минус какой-то.
[02:18:19.000 --> 02:18:27.000]  Дальше мы с вами занимались разными оценками нижними на верт оптимального гаметонного цикла.
[02:18:27.000 --> 02:18:33.000]  Сначала структурные такие оценки, которые пытаются улучшить вот эту вот оценку.
[02:18:33.000 --> 02:18:39.000]  И кульминацией такого типа оценок была оценка Гельда Карпа,
[02:18:39.000 --> 02:18:45.000]  когда мы доводим граф специальным образом до того, чтобы минимальное основное дерево в нем
[02:18:45.000 --> 02:18:50.000]  было максимально похоже на гаметонную цепь.
[02:18:50.000 --> 02:18:59.000]  Но делаем это контролируемым образом, чтобы можно было как-то все-таки сопоставить гаметонную циклу
[02:18:59.000 --> 02:19:03.000]  и веса их в измененном графе и в исходном.
[02:19:03.000 --> 02:19:10.000]  А дальше посмотрели с вами возможности для использования линейной релаксации для такой нижней оценки
[02:19:10.000 --> 02:19:19.000]  или просто поговорили, можно считать, про целочисленные линейные постановки задачи канавеажёра.
[02:19:19.000 --> 02:19:25.000]  Выяснилось, что костяк этой задачки оказывается просто задачей о назначениях,
[02:19:25.000 --> 02:19:29.000]  задачей о совершенном просочетании минимального веса в выдольном графе,
[02:19:29.000 --> 02:19:37.000]  которая может быть решена как задача о потоке минимальной стоимости.
[02:19:37.000 --> 02:19:46.000]  Дальше посмотрели, как все-таки довести вот эту задачу о назначениях до именно задачи о канавеажёре,
[02:19:46.000 --> 02:19:50.000]  либо за счет вот таких ограничений, которых очень много.
[02:19:50.000 --> 02:19:55.000]  Но на практике, если ограничений много, это не значит, что мы должны добавлять все сразу.
[02:19:55.000 --> 02:19:58.000]  На практике мы их можем добавлять интерактивно.
[02:19:58.000 --> 02:20:02.000]  И посмотрели на еще один такой интересный вид ограничений,
[02:20:02.000 --> 02:20:07.000]  которые уже используют не булевские, не бинарные переменные.
[02:20:07.000 --> 02:20:12.000]  Совершенно другой смысл переменных у нас вдруг появляется в такой задачи.
[02:20:12.000 --> 02:20:17.000]  Наверное, первая ситуация, когда мы используем какие-то переменные,
[02:20:17.000 --> 02:20:27.000]  такие сильно комбинаторные по смыслу, номер шага, не количество какой-нибудь, не мощность, а именно номер шага.
[02:20:27.000 --> 02:20:32.000]  И можно использовать такие ограничения.
[02:20:32.000 --> 02:20:35.000]  И это на сегодня все.
[02:20:35.000 --> 02:20:41.000]  В следующий раз мы с вами будем заниматься, может быть, задачками из теории расписаний,
[02:20:41.000 --> 02:20:46.000]  а может быть, поговорим про методы перебора.
[02:20:46.000 --> 02:20:55.000]  Там всякие A-star и разные другие способы обхода дерева и дерева перебора.
[02:20:55.000 --> 02:21:03.000]  А может быть, поговорим про задачи о прочайших путях, всякие библистические средства.
[02:21:03.000 --> 02:21:06.000]  Посмотрим. На сегодня все.
[02:21:06.000 --> 02:21:12.000]  Пожалуйста, если есть вопросы, замечания, пожелания, сейчас можно их вызвать.
[02:21:15.000 --> 02:21:20.000]  Если нет, то прощаюсь с вами до следующей недели.
[02:21:20.000 --> 02:21:26.000]  Все, расстаемся. Всем спасибо и счастливо увидимся.
