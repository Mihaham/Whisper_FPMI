[00:00.000 --> 00:12.760]  Всем доброго дня! Мы теперь встречаемся в немножечко другом формате, именно в
[00:12.760 --> 00:20.520]  дистанционном. Я не знаю, куда отрендерится видео со мной, но если что, потом будем редактировать.
[00:20.520 --> 00:27.120]  Сразу говорю, первая такая организационная вещь — берегите себя, потому что ситуация очень
[00:27.320 --> 00:36.240]  плачевная и по официальной статистике как минимум тысяч человек с нашей страны пошло в иной мир.
[00:36.240 --> 00:41.880]  Ситуация очень страшная, поэтому, пожалуйста, соблюдайте дистанцию, носите маски,
[00:41.880 --> 00:48.240]  ну и старайтесь поменьше контактировать друг с другом, берегите себя, особенно если вы,
[00:48.240 --> 00:54.760]  допустим, живете с родителями, так тем более, потому что они сейчас более уязвимая группа
[00:54.760 --> 01:02.840]  населения. Вот такой небольшой спойлер в начале, авто в начале, который очень важно рассказать,
[01:02.840 --> 01:07.920]  а сейчас мы с вами поговорим именно про лекцию. Значит, в прошлый раз мы с вами не закончили
[01:07.920 --> 01:13.680]  говорить про лему о разрастании, точнее ее сформулировали, но сегодня нам еще она
[01:13.680 --> 01:16.760]  понадобится. Давайте вспомним, что мы учились делать в прошлый раз.
[01:25.760 --> 01:28.880]  Что мы на прошлой лекции научились с вами делать?
[01:28.880 --> 01:39.680]  Нормальную форму Фомского находить и поэтому парсить.
[01:39.680 --> 01:46.440]  Да, мы научились строить нормальную форму Фомского, показали почему это так и научились, построили
[01:46.440 --> 01:51.680]  первый парсер, построили алгоритм Кока Янгера Кассами, который работает, напоминаю, за симптотику
[01:51.680 --> 01:59.560]  о большое от длины слова в кубе на количество правил. Это достаточно большая симптотика,
[01:59.560 --> 02:09.880]  но что поделать с ней? Пока что мы ничего с ней не можем сделать, и сегодня мы применим нормальную
[02:09.880 --> 02:17.600]  форму Хомского для того, чтобы доказать один из алгоритмов, точнее одну из теорем. Давайте вспомним,
[02:18.240 --> 02:23.680]  что такое нормальная форма Хомского. Грамматика у нас находится в форме Хомского, КС-грамматика,
[02:23.680 --> 02:30.000]  контекст свободный. Если у нее все правила имеют такой и только такой вид. Первое, из не терминала
[02:30.000 --> 02:35.200]  мы можем вывести терминал, то есть напоминаю, что большими буквами у нас обозначаются не
[02:35.200 --> 02:42.640]  терминальные символы, то есть символы, порождающие, не то что порождающие, а специальные символы,
[02:42.640 --> 02:47.520]  из которых могут выводиться какие-то правила. А терминальными символами мы называем символы
[02:47.520 --> 02:52.240]  алфавит. Да, если есть какие-то вопросы, по ходу дела задавайте, будем разбираться. Наша цель не
[02:52.240 --> 03:01.000]  прогнать какой-то материал достаточно быстрой скоростью, а именно посмотреть какие-то вещи,
[03:01.000 --> 03:09.280]  разобрать более детально. Второе правило, которое у нас имеет вид, это правило из А следует БС,
[03:09.280 --> 03:18.200]  где БС у нас являются не терминалами, но при этом мы не позволяем циклы в стартовый не терминал,
[03:18.200 --> 03:29.600]  то есть у нас Б не С и С не С. Кстати, мышку видно? Вложу. Хорошо. И третье правило, если у нас
[03:29.600 --> 03:35.520]  внезапно из грамматики выводится пустое слово, то мы должны добавить правило из стартового не
[03:35.520 --> 03:41.520]  терминала, выводится пустое слово. И теперь давайте попробуем при помощи этого доказать
[03:41.520 --> 03:55.080]  следующую лему. Значит, это лемма о разрастании. Опять же, мы ее называем Pumping Lema. В чем ее суть
[03:55.080 --> 04:02.120]  состоит? Опять же, пусть у нас есть некоторый контекстно-свободный язык, тогда существует
[04:02.120 --> 04:14.080]  такое П, такое, что для любого слова, длина которого достаточно большая, существует разбиение на Н слов,
[04:14.080 --> 04:24.320]  Н в данном случае пять-пять, и смотрите, что происходит. У нас X, Y, Z. Наш слово представляется
[04:24.320 --> 04:33.920]  в виде X, Y, V, Z, но при этом смотрите, что важно, что длина УВ больше чем ноль, то есть у нас,
[04:33.920 --> 04:40.080]  давайте я даже буду подчеркивать, то есть у нас на вот эти вот слова есть ограничение, что это
[04:40.080 --> 04:53.120]  слово не пустое. И есть ограничение на УВ, что длина УВ не больше чем П. То есть в отличие от
[04:53.120 --> 04:59.240]  леммы разрастание для автоматных языков, у нас разрастание, у нас есть ограничение на начало,
[04:59.240 --> 05:07.120]  здесь идет ограничение на середину. Вот. И благодаря этому мы немножечко с вами, у нас
[05:07.120 --> 05:15.320]  усложняется работа, потому что если мы раньше могли придумать слово с каким-то хорошим началом,
[05:15.320 --> 05:23.040]  то здесь надо обычно разбирать намного больше случаев. Если мы хотим доказать, что у нас какой-то
[05:23.040 --> 05:28.800]  язык не является контекст свободным, а именно в этой концепции мы с вами будем применять ее.
[05:28.800 --> 05:37.480]  И тогда смотрите, что у нас выполняется. Для любого камы, по сути, можем разрастать розовую часть. То есть
[05:37.480 --> 05:51.720]  х, давайте я даже буду писать у вкатой. Так, какое там? У вкатой, да? У вкатой. Дальше у, в вкатой,
[05:51.720 --> 06:02.280]  z будет лежать в нашем языке. Вот такая формулировка леммы. Разрастается второе и четвертое
[06:02.280 --> 06:11.080]  слово. Пятое остается неизменным. Первое, третье тоже является, остается неизменным. Теперь давайте
[06:11.080 --> 06:19.600]  попробуем эту историю доказать. Как эту историю доказывать? Ну, давайте возьмем грамматику и
[06:19.600 --> 06:37.960]  рассмотрим ее в нормальной форме хомского. Тогда смотрите, что мы с вами можем заметить. Что,
[06:37.960 --> 06:46.280]  если мы с вами попытаемся построить дерево вывода грамматики, то на самом деле у нас эта
[06:46.280 --> 06:51.480]  история увеличивается не более чем в два раза. То есть, если мы посмотрим на первый уровень,
[06:51.480 --> 06:59.600]  нулевой уровень, это s. Дальше посмотрим на первый уровень дерева грамматики. Допустим,
[06:59.600 --> 07:07.880]  из него выводится какое-то a или b. Это первый уровень. То есть, зафиксируем уровни. Там из этого
[07:07.880 --> 07:16.640]  какой-то cd, а из этого ef. Из-за того, что у нас грамматика в нормальной форме хомского, то каждый
[07:16.640 --> 07:24.480]  уровень у нас разрастается не более чем вдвое. Но в нем могло уйти ответвление в чисто пустое
[07:24.480 --> 07:32.160]  слово. То есть, в итоге у нас получается здесь количество символов не более чем 2 в нулевой,
[07:32.160 --> 07:38.360]  здесь у нас количество символов не более чем 2 в первой, здесь не более чем 2 в второй. И тогда,
[07:38.360 --> 07:50.240]  что мы можем с вами сказать из этого? Мы можем тогда сказать, что на каком-то уровне,
[07:50.240 --> 08:09.200]  там, если обозначим, там у нас есть какое-то слово w, то у нас длина этого слова. Сейчас,
[08:09.200 --> 08:12.120]  давайте подумаем, чем она у нас с вами ограничена.
[08:20.240 --> 08:35.200]  В общем, мы можем получить оценку от высоты уровня. Теперь смотрите, вот эта идея понятна,
[08:35.200 --> 08:41.880]  что каждый уровень дерева вывода увеличивает длину слова не более чем вдвое. То есть,
[08:41.880 --> 08:48.720]  если у нас максимальный уровень второй, и после него вывод идет слово, то в слове не более чем
[08:48.720 --> 08:58.760]  4 символа. Вот. А что это нам позволяет делать? Давайте рассмотрим. Слово, точнее, обозначим
[08:58.760 --> 09:04.800]  p, равное 2 в степени количества не терминалов нашей грамматики, которые в нормальной форме
[09:04.800 --> 09:14.960]  Хомского. Так, давайте это отделю. Тогда, если у нас слово w будет больше или равно, чем p,
[09:14.960 --> 09:28.320]  2 в степени n. Тогда скажите мне, пожалуйста, какая минимальная высота дерева?
[09:28.320 --> 09:45.560]  Можем ли мы ее оценить каким-нибудь образом?
[09:45.560 --> 10:07.400]  Смотрите, существует ветка уровня больше равно, чем количество не терминалов. Потому что,
[10:07.400 --> 10:13.720]  если у нас длина слова достаточно большая, то как минимум уровень такой мы должны задействовать.
[10:13.720 --> 10:31.600]  А это значит, следовательно, давайте рассмотрим последовательность, рассмотрим ветку максимального
[10:31.600 --> 10:55.760]  уровня, максимальной глубины. И тогда в ней количество не терминалов на 1 больше. Потому что у
[10:55.760 --> 11:02.120]  нас с вами есть еще нулевой уровень, обращу внимание. Нулевой уровень плюс хотя бы n, это значит,
[11:02.120 --> 11:11.080]  что количество не терминалов хотя бы n плюс 1. Тогда давайте поймем, что мы можем сказать с вами
[11:11.080 --> 11:28.680]  про эту ветку и про то, какие не терминалы у нас там с вами встречаются. Есть как минимум два не
[11:28.680 --> 11:38.800]  терминала, которые повторяются хотя бы два раза.
[11:38.800 --> 12:02.160]  Вот, давайте рассмотрим эту ветку. И важное замечание среди
[12:02.160 --> 12:21.760]  таких А выберем такой, который находится глубже всех, то есть он ниже всех.
[12:21.760 --> 12:33.880]  И тогда смотрите, что у нас с вами получается. Я нарисую с вами дерево вывода, ну я его пока
[12:33.880 --> 12:43.080]  продублирую. Вот, я сейчас нарисую на картинке. Смотрите, что у нас получается. У нас из С нашли
[12:43.080 --> 12:49.440]  это первую встречу этого А, то есть предпоследнюю встречу этого А. Посмотрим в ту самую ветку.
[12:49.440 --> 12:55.560]  Дальше у нас с вами идет некоторое ХЗ, ну потому что слева и справа от него мог
[12:55.560 --> 13:02.480]  выводиться какой-то контекст. Дальше ниже от него тоже мог выводиться какой-то контекст АВ.
[13:02.480 --> 13:10.200]  И дальше у нас из А могло вывести на терминал У. Тогда у нас что получается? У нас получается
[13:10.200 --> 13:25.760]  как раз цепочка выводов из С, ХАЗ, ХУАВЗ, ХУЙВЗ. И смотрите, внимание, у нас появляется вот
[13:25.760 --> 13:33.280]  такая вот вещь. Как раз из этого у нас будет с вами разрастание. Из того, что из А выводится УАВ.
[13:33.280 --> 13:46.000]  А теперь давайте поймем, что нам надо доказать, для того чтобы доказать, что лемма работает.
[13:46.000 --> 14:10.540]  Да, первый факт, который нам нужно показать, что длина УВ не больше, чем П. Которая у нас,
[14:10.540 --> 14:18.580]  напоминаю свою очередь, равен 2 в степени N. Давайте понимать, почему это так. Ну на самом деле,
[14:18.580 --> 14:32.900]  если внимательно посмотреть на картинку, если вдруг длина УВ больше, чем П, а это равно 2 в степени N,
[14:33.060 --> 14:55.080]  тогда для дерева со стартом ВА мы можем проделать ту же самую операцию. Вот в это. То есть тыкаем
[14:55.080 --> 15:01.900]  в дерево, которое находится здесь, проделываем те же самые операции, но при этом не считаем
[15:01.900 --> 15:13.980]  терминал А. И тогда в нем количество узлов, как минимум, 2 в степени N. Даже больше,
[15:13.980 --> 15:28.220]  чем 2 в степени N. Следовательно, уровень есть, давайте я буду подчеркивать, то есть со стартом ВТА,
[15:28.220 --> 15:39.580]  есть уровень даже больше, чем N. То есть не меньше, а больше, чем модуль N. Это значит,
[15:39.580 --> 15:57.020]  что мы даже ниже спустясь можем найти пару В, и из нее выводится В. В вот этом вот под дерево.
[15:57.020 --> 16:06.300]  Вот давайте я вот так выделю. То есть в этом под дереве есть пара В,
[16:06.300 --> 16:18.380]  которая и находится ниже, чем этот не терминал А. Вопрос, к какому противоречию мы с вами
[16:18.380 --> 16:46.060]  приходим здесь? То, что А не самое глубокое. Да, вывод А не самое глубокое. Ну и это противоречие.
[16:46.180 --> 16:54.700]  Ага, а второй факт, который нам надо с вами показать, какой здесь. То есть в первую штуку мы проверили
[16:54.700 --> 17:16.780]  с вами. УВ не пусто. Да, нам нужно проверить, что длина УВ больше нуля. Смотрите, из какого это
[17:16.780 --> 17:33.980]  факта следует. У нас мы знаем, что для любого, давайте напишем так, для любого не терминала,
[17:33.980 --> 17:46.620]  давайте С его обозначим. С не терминал, у нас С не эпсилон порождающий. Это важно. То есть для этого
[17:46.620 --> 17:59.180]  мы с вами убивали эти штуки. А это значит, что как только у нас, давайте напишем так, рассмотрим,
[17:59.180 --> 18:14.340]  там я не знаю, символ В, давайте я его напишу где-нибудь, давайте не В, пусть будет Д. Вот этот
[18:14.340 --> 18:23.580]  вот Д, вот я его вот тут вот сюда воткну, из которого за один раз мы получили А. То есть за один
[18:23.580 --> 18:31.860]  шаг мы получаем А. Но он может быть слева, может быть справа. Ну давайте предположим, не ограничивая
[18:31.860 --> 18:38.580]  общности, что у нас он появился слева. Причем он мог появиться только по такому правилу. И тогда у нас,
[18:38.580 --> 18:52.860]  что мы можем с вами сказать? Мы можем с вами сказать, что из этого АК вывелся какое-то, какое-то
[18:52.860 --> 19:12.380]  слово, я не знаю, Р. Но тогда Р у нас будет являться суффиксом У. Суффикс У. И при этом заметим,
[19:12.380 --> 19:20.060]  что длина Р у нас обязательно больше нуля. Следовательно, у нас длина УВ будет больше
[19:20.060 --> 19:31.780]  равна чем длина У, это в свою очередь больше равна чем длина Р, а это больше чем ноль. Вот. Если,
[19:31.780 --> 19:39.700]  опять же, у нас Д порождало не таким образом, а образом АК, то история точно такая же, просто мы
[19:39.700 --> 19:50.740]  рассматриваем это для слова В. Вот. Ну и дальше мы видим, что вот это вот правило, напоследок, что вот
[19:50.740 --> 20:02.460]  это правило, мы можем поставлять К раз, и у нас получается х у вкаты, y вкаты, z. А может быть равно 0? Да,
[20:02.460 --> 20:09.860]  конечно же. Как и в прошлые разы, К может быть равно 0. Спасибо за замечание, оно очень важное. Вот.
[20:09.860 --> 20:17.740]  Можно еще вопрос в втором пункте? Мы там какую А используем? А с двумя подчеркиваниями? Нет,
[20:17.740 --> 20:24.780]  нет, давайте я ее обведу, пусть она у нас А розовая будет. Вот эту А розовую. Вот я тут D
[20:24.780 --> 20:34.940]  как раз написал, что D вот вводится, она здесь где-то. Да, понятно. Хорошо. Вот такое доказательство,
[20:34.940 --> 20:41.300]  оно более муторно, чем время разрастания для автоматных языков, но вроде сложность относительно
[20:41.300 --> 20:49.820]  его похожая. Давайте для того, чтобы понять, как эту штуку применять, если есть вопросы по
[20:49.820 --> 20:54.540]  доказательству задавайте, в принципе мы доказательство закончили этого факта. Чтобы
[20:54.540 --> 21:05.460]  понять, как это применить, давайте напишем отрицание лемма разрастании. Для этого что мы делаем? Мы
[21:05.460 --> 21:13.740]  говорим, что для любого P существует такое слово из L, такое, что его длина больше равно P, что для
[21:13.740 --> 21:25.660]  любых X, U, Y, V, Z из сигма со звездой. Существует для любого разложения слово в таком виде.
[21:25.660 --> 21:39.220]  U, V больше нуля, Y, U, V не больше, чем P. Любого K, принадлежащего натуральному. X, U в катой,
[21:39.220 --> 21:47.300]  Y, V в катой, Z не лежит в языке L. То есть нам нужно найти такое слово, такое разбиение, чтобы
[21:47.300 --> 21:58.900]  это не работало. Вот. Так, это доказательство. Давайте пример разберем. Пример такой. Слово язык
[21:58.900 --> 22:17.140]  A-venti, B-venti, C-venti. Опять же, смотрите, нам для любого P рассмотрим фиксированное P. Давайте
[22:17.140 --> 22:27.100]  придумаем слово, длина которого хотя бы P. Я сейчас попробую окно закрыть, потому что кто-то решил
[22:27.100 --> 22:48.220]  стучать. О, там по дворе забор прибивают. Какое слово рассмотрим? Длина которого хотя бы P.
[22:57.100 --> 23:15.980]  Какое слово рассмотрим? Мы хотим взять слово вида A-venti, B-venti, C-venti так, чтобы у него длина была хотя бы P.
[23:15.980 --> 23:36.900]  Ну да. A-venti, B-venti, C-venti. Вот. Тогда смотрите. Давайте попробуем для него доказать отрицание.
[23:37.740 --> 23:48.340]  Что у нас получается? У нас получается, что слово W представляет в виде X, U, Y, V, Z. При этом что мы знаем?
[23:48.340 --> 24:00.540]  Что длина U-V больше нуля, а длина U-Y-V не больше, чем P. Да? И тут самое важное замечание, которое можно сделать.
[24:00.540 --> 24:27.580]  Заметим, что в Y-U-V не может быть трех разных букв из A-B-C. Вот не может быть, потому что если бы
[24:27.620 --> 24:40.780]  они были бы, то включалось бы A, включалось бы C первое и расстояние между ними уже больше, чем P, а длина Y-U-V не больше, чем P. Вот.
[24:40.780 --> 24:55.380]  И теперь это. Теперь смотрите, что у нас с вами происходит. Тогда, не умоляя общности,
[24:55.380 --> 25:07.620]  неважно каких, пусть у нас количество букв в C равно нулю. Там неважно какое рассматривать, но мы знаем,
[25:07.620 --> 25:16.020]  что не может быть трех разных букв. Длина Y-V-A-C меньше нуля, а количество букв там, не зная B,
[25:16.020 --> 25:22.260]  больше нуля. Там в зависимости от ситуации может быть разные варианты. Но тогда если мы рассмотрим
[25:22.260 --> 25:34.060]  кару на двойке и посчитаем, сколько у нас с вами, чему у нас равняется количество букв B в этой штуке,
[25:34.060 --> 25:53.260]  мы получим, что это количество. Ой, сейчас, секунду. Y-V-Z количество букв B плюс U-V количество букв B. Так.
[25:53.260 --> 26:02.660]  Но тут, смотрите, еще важно замечание, что на самом деле мы можем сказать то же самое и для
[26:02.660 --> 26:18.820]  U-V. Вот. Поэтому давайте я тут немножечко пошаманю. Вот так. Тогда смотрите, что у нас получается.
[26:18.820 --> 26:29.540]  Чему эта штука равна? Эта штука у нас равна P, потому что у нас B в этой P плюс количество букв U-V-B. А при
[26:29.540 --> 26:44.500]  этом количество букв C, U-quadrat Y-V-quadrat C, будет равняться P плюс количество букв C. Это нулю,
[26:44.500 --> 26:54.100]  а это больше чем. Так. Получается 0 плюс P равняется P, а это будет больше чем P. В итоге количество
[26:54.100 --> 27:04.180]  букв B у нас оказалось больше чем количество букв C. И это нас приводит к противоречию. Вот.
[27:04.180 --> 27:28.620]  Вот такой факт. Вот давайте теперь немножечко поговорим, если понятно,
[27:28.620 --> 27:33.460]  пример не контекст свободного языка. То есть лемма о разрастании, тут более сложные немножечко
[27:33.460 --> 27:40.700]  рассуждения идут, чем лемма о разрастании для автоматных языков. И теперь, смотрите, есть два
[27:40.700 --> 27:47.020]  важных факта, которые мы должны обсудить. Это следствие леммы о разрастании, а именно следствие о
[27:47.020 --> 27:56.580]  том, что это язык не является контекстно свободным. Следствие номер раз. Первый пример. Это следствие,
[27:56.580 --> 28:02.660]  то что контекстные свободные языки не заднуты относительно пересечения. Да, давайте приведем
[28:02.660 --> 28:13.460]  пример, который говорят нам про это. То есть первый пример. Это пусть у нас язык A вентой,
[28:13.460 --> 28:25.260]  B вентой, C вентой, а язык L2 это у нас A вентой, B вентой, C вентой. Каждый из них, в принципе,
[28:25.260 --> 28:29.900]  является контекстом свободным. Это несложно проверить. Нам достаточно задать количество букв
[28:29.900 --> 28:35.660]  B равное количеству букв C и количество букв A равное количество букв B. Например, мы можем это
[28:35.660 --> 28:46.700]  сделать вот для, например, для этого языка. Мы можем сделать такую вещь. ИЗСАТ, ИСТВБТЦ и ИСТВЭПСУМ.
[28:46.700 --> 28:52.820]  Пример грамматики. Прям привести, может доказать, что он задает именно такие языки. А скажите,
[28:52.820 --> 28:54.820]  чему равняется пересечение этих двух языков?
[29:17.820 --> 29:20.820]  В предыдущем языке, в котором доказалось, что он не контекст свободный.
[29:20.820 --> 29:27.820]  Да, он равен как раз предыдущему языку, который не является контекстом свободным. Поэтому у нас как раз
[29:27.820 --> 29:32.820]  контекстом свободные языки, не знаю, куда точить перечень. Мы берем два контекста свободных языка,
[29:32.820 --> 29:40.580]  пересекаем их, получаем неконтекстно свободный язык. Это важное замечание. Контекстно свободные
[29:40.580 --> 29:47.260]  языки нельзя пересекать с чем попало. В следующий раз или в один из следующих разов мы покажем,
[29:47.260 --> 29:51.820]  что контекстно свободные языки можно пересекать с регулярными языками, и это будут контекстно
[29:51.820 --> 29:58.780]  свободные языки. Но для этого нам нужно перейти на другую абстракцию. Сегодня мы начнем, а в следующий
[29:58.780 --> 30:07.340]  раз мы с вами это покажем. Так, это первое следствие. Второе следствие чуть сложнее. Его нужно будет
[30:07.340 --> 30:14.340]  показывать. Вот, это у нас неконтекстный язык. Второй язык такой. Они не замкнуты относительно
[30:14.340 --> 30:25.500]  дополнения. Если мы с вами посмотрим. Язык L равно A в ent и B в ent и C в ent. И рассмотрим дополнение
[30:25.500 --> 30:38.900]  языка L. Это там можно в принципе его посмотреть. Он является неконтекстом свободным языком. Почему?
[30:38.900 --> 30:47.420]  Там надо убедиться, либо чтобы как-то буквы A и B были перепутаны местами где-то. Это легко
[30:47.420 --> 31:01.460]  той же самой регуляркой задается. Либо у нас язык имеет вид afkat и bv. Давайте я напишу какие-то
[31:01.460 --> 31:18.660]  easy cases объединить с языками вида afkat и bv и cv. Где K не равно L или L не равно M или K не равно M.
[31:18.660 --> 31:27.140]  Каждый этих случаев по отдельности K не равно L, L не равно M и K не равно M можно задать. А объединение
[31:27.140 --> 31:32.700]  двух контекстов свободных языков построить достаточно просто. Нужно просто объединить эти
[31:32.700 --> 31:42.100]  грамматики. Мне кажется, возможно на семинаре у вас подобные задачки уже разбирались. В своей
[31:42.100 --> 31:57.420]  группе разбирал, где использовалась идея объединения двух языков. Почему еще раз дополнение
[31:57.420 --> 32:05.140]  не замкнуто? Из дополнения следует? Нет, тут изо всех скобочек следует. Мы рассмотрим язык вот
[32:05.140 --> 32:13.780]  такой вот. Дальше у нас смотрим чему равняется дополнение. У нас это либо такой язык afkat и bv
[32:13.780 --> 32:31.660]  и cv. Либо у нас тут какие-то простые кейсы идут. Типа в духе, не знаю, перед B идет C. Тогда у нас
[32:31.660 --> 32:41.100]  этот язык уже ломают зависимость. Да, потому что C, а потом B. Это уже явно не afkat и bv, а cvmt.
[32:41.100 --> 32:46.940]  Ну и подобные порядковые истории мы смотрим. А это вообще задается регуляркой.
[32:54.940 --> 32:59.180]  Да, то есть мы это просто берем, задаем регуляркой. Регулярку можно задать той же
[32:59.340 --> 33:06.540]  правлении на грамматикой. А объединение грамматика – это грамматика. Для объединения языков можно
[33:06.540 --> 33:09.340]  грамматику построить, если каждый из них является контекстом свободы.
[33:29.340 --> 33:41.900]  Вот. Понятно вот эти вот факты? Ну то есть они такие фундаментально важные, что контекстные
[33:41.900 --> 33:47.980]  свободные языки себя ведут сложнее, чем регулярные. Потому что в регулярных мы
[33:47.980 --> 33:53.300]  устроили дополнение через PDK, напоминая пересень, мы строили через построение
[33:53.300 --> 34:05.780]  грамматикартового произведения автоматов. Так, товарищи, давайте решать. Я предлагаю
[34:05.780 --> 34:09.660]  сейчас сделать перерывчик на 5 минут, а дальше перейти уже к следующей теме.
[34:09.660 --> 34:31.100]  Так, всем доброго дня. Еще раз мы продолжаем. Вот, сегодня мы рассматриваем тему новую.
[34:31.100 --> 34:36.060]  Посмотрим, сколько успеем доказать. Посмотрим, сколько успеем посмотреть.
[34:36.060 --> 34:43.660]  Это тема автоматы с магазиной памяти или mp-автоматы. Значит, определение у нас такое.
[34:43.660 --> 34:55.140]  mp-автомата мы будем называть шестерку, q, сигма, гамма, дельта, q0 и f, где q множество
[34:55.140 --> 35:01.660]  состояний, множество q конечное, алфавит конечный. Есть еще специальный алфавит,
[35:01.660 --> 35:05.820]  он называется стековый. Мы его будем обозначать гамма, символы стека алфавита будем обозначать
[35:05.820 --> 35:14.060]  большими буквами. Честно, это не совпадение. Вот, гамма меньше бесконечности, и тут важное
[35:14.060 --> 35:19.340]  замечание, его можно в принципе соблюдать, можно не соблюдать, но особой роли у нам играть не будет,
[35:19.340 --> 35:27.420]  в отличие от катей свободного грамматика. Давайте считать, что они зачастую не пересекаются эти
[35:27.420 --> 35:34.060]  алфавиты стековые и обычные алфавиты. Дальше у нас с вами идет множество переходов, это страшный
[35:34.060 --> 35:40.860]  термин, что-то q на сигму со звездой на гамма, на q на гамма со звездой. Опять же, количество переходов
[35:40.860 --> 35:49.620]  у нас всегда конечно, q0 стартовое состояние, q, f множество завершает состояние. Вопрос, кто лишний, кто
[35:49.620 --> 36:01.700]  добавился? Ну, стек. Да, стек добавился, это раз. А второе, что еще добавилось? Переходы какие у нас?
[36:01.700 --> 36:11.460]  Ну, соответственно, переходы теперь изменяют состояние стека. Да, переходы изменяют состояние
[36:11.460 --> 36:17.700]  стека. Нам нужно представить себе ситуацию, что у нас есть автомат, и к нему приделан стек,
[36:17.700 --> 36:22.420]  то есть, когда вы идете по пути в автомате, вы пытаетесь либо добавлять буквы на стек,
[36:22.420 --> 36:30.980]  точнее, делаете плату за переход по состоянию. Для того, чтобы заплатить по состоянию, вам нужно
[36:30.980 --> 36:41.220]  снять со стека какие-то буквы, перейти по либру, и потом вам обратную дадут положить что-то в стек,
[36:41.220 --> 36:49.860]  премию за то, что вы перешли этот переход. Вот, и наша цель понять, как выглядит переход. А
[36:49.860 --> 36:57.420]  переходы мы будем означать вот таким вот образом, что пусть у нас есть, мы находили состояние q1,
[36:57.420 --> 37:08.180]  мы находили слове w, снимаем со стека альфа, потом мы с вами переходим в состояние q2 и кладем на
[37:08.180 --> 37:16.380]  стек бета. Неформально. Ну, я написал неформально, но важное замечание. Вот, смотрите, если у нас
[37:16.380 --> 37:26.500]  написано q1, a, b, c, a, b, c, я не знаю, дальше мы переходим в состояние q2 и на стек кладем x,
[37:26.500 --> 37:36.020]  то если мы с вами отобразим состояние этого стека, там какие-то последовательности,
[37:36.020 --> 37:40.660]  не терминала находятся. Так вот, что важно нам замечать, что для того, чтобы перейти по
[37:40.660 --> 37:47.300]  этому переходу, у нас буквы a, b, c должны находиться именно в таком порядке. Да, то есть мы снимаем
[37:47.300 --> 37:58.660]  a, b, c, это значит мы снимаем вот эту вот последовательность. Если что, стек растет в ту сторону. Не в обратном
[37:58.660 --> 38:09.780]  порядке, а именно в таком. То есть мы с вами снимаем со стека a, b, c и кладем x сверху. Вот,
[38:09.780 --> 38:17.540]  теперь эту историю нам надо формализовать, потому что мы, конечно, молодцы, ребята, мы можем сказать,
[38:17.540 --> 38:25.540]  вот стек работает так, вот, пожалуйста. Поэтому, опять же, нам нужно задать набор конфигурации.
[38:25.540 --> 38:44.180]  Значит, смотрите, конфигурация. Это тройка Q, слово U и гамма. Q лежит в состоянии Q,
[38:44.180 --> 38:50.460]  U из набора всех слов, а гамма находится гамма со звездой.
[38:50.460 --> 38:57.220]  Давайте понимать, что означают эти символы.
[39:04.820 --> 39:09.180]  Давайте вспоминать сначала определение конфигурации для обычного автомата,
[39:09.180 --> 39:12.260]  а потом попробовать перенести на mp-автомат.
[39:20.460 --> 39:29.260]  Видимо, Q – это текущее состояние, U – это слово, а гамма – это стек.
[39:29.260 --> 39:35.540]  Да, смотрите, Q – это текущее состояние, U – это слово, которое нам надо прочитать в последствии,
[39:35.540 --> 39:43.500]  да, но то, что у нас в очереди лежит на обработку, а гамма – это текущий стек. Вот, да. То есть
[39:43.500 --> 39:49.300]  формально находимся в состоянии Q, неформально. Осталось прочесть слово U, и в стеке расположено,
[39:49.540 --> 39:57.940]  лежит слово гамма. Вот, теперь как это задать? Задается это таким образом, что если у нас есть
[39:57.940 --> 40:02.740]  отношение в выводимости, это наименьшее рефлексивно-транзитивное отношение,
[40:02.740 --> 40:15.100]  опять же, что для любого перехода, я давайте запишу это Q1, U альфа, а я, кажется, с кубочку
[40:15.100 --> 40:22.540]  не поставил все-таки дельта. Смотрите, что получается. Для любого слова W, которое мы
[40:22.540 --> 40:29.740]  в последствии хотим прочитать, и для любого наполнения стека, это, по сути, у нас наполнение стека,
[40:29.740 --> 40:53.300]  а мы делаем следующее. Q1, U, V, это альфа, выводит, Q2, V, это бета. То есть у нас,
[40:53.300 --> 41:02.900]  смотрите, на стеке располагалось слово это, мы снимаем альфа, это у нас стек, снимаем альфа,
[41:02.900 --> 41:12.220]  пойдем бета. Ну, а при этом, в этом переходе, если у нас находилось какое-то слово U, вот у нас
[41:12.220 --> 41:20.740]  находился Q1, здесь это слово V, это слово U и слово V. Мы передвигаем каретку сюда, при этом делаем
[41:20.740 --> 41:29.260]  операцию со стеком. Именно такое. То есть снимаем альфа, вкладем бета. Вот. И тогда, смотрите,
[41:29.260 --> 41:34.820]  что мы можем сказать, что язык задаваем по автоматам, это множество всех слов,
[41:34.820 --> 41:44.020]  или это равно множество всех слов, такие, что мы начинаем в стартовом состоянии,
[41:44.020 --> 41:54.180]  нам надо прочитать слово W, при этом стек пустой, и мы выводим с вами Q,
[41:54.180 --> 42:04.660]  Epsilon, Epsilon. То есть мы очищаем все то, что мы хотели прочитать, мы все прочитали,
[42:04.660 --> 42:11.780]  при этом на стеке у нас ничего не лежало, и мы заканчиваем только с пустым стеком. Это важно.
[42:11.780 --> 42:24.420]  Вот такое определение. Если непонятное определение, задавайте вопросы, это важно.
[42:24.420 --> 42:31.620]  Я сейчас хочу рассмотреть один пример, связанный с этим. Это пример правильных скобочных последовательностей.
[42:31.620 --> 42:41.700]  Для правильных скобочных последовательностей важно, значит, следующее,
[42:41.700 --> 42:44.740]  а нам нужно эмулировать скобочный баланс.
[42:44.740 --> 43:02.260]  Вот, и мы будем сохранять инвариант, то есть у нас с вами здесь хватает одного состояния,
[43:02.260 --> 43:10.780]  которое является завершающим, и у него переходы видом. Мы снимаем со стека, точнее мы, первый переход,
[43:10.820 --> 43:20.380]  мы берем с вами открывающую скобку, со стека снимаем Epsilon, на стек кладем A.
[43:20.380 --> 43:26.900]  А здесь мы говорим обратную вещь, что мы снимаем A со стека кладем Epsilon.
[43:26.900 --> 43:36.700]  Да, нотация правил. Для того чтобы упрощение написать на стеке перехода, мы на стрелочке
[43:36.700 --> 43:44.100]  пишем следующее, что мы снимаем, что мы, точнее, какое слово читаем, что мы снимаем стек,
[43:44.100 --> 43:53.540]  и что кладем на стек. А здесь наоборот. Давайте поймем, какой инвариант у нас выполняется,
[43:53.540 --> 44:00.020]  как понять, какой текущий скобочный баланс, какой балансу префиксу.
[44:06.700 --> 44:20.220]  Размер стека. Да, количество буква на стеке.
[44:29.820 --> 44:35.500]  Давайте проэмулируем какую-нибудь скобочную последовательность, я не знаю, вот такую вот.
[44:35.500 --> 44:46.060]  Давайте я их буду обозначать буковками, то есть это пусть у нас буковка A, это буковка B.
[44:46.060 --> 45:00.540]  Вот, смотрим, что у нас получается. Сначала Q0, A, B, A, B, B. Стек у нас пустой. Потом мы читаем
[45:00.540 --> 45:11.180]  букву A, у нас получается Q0, A, B, A, B, B. На стек мы кладем A. Видите, скобочный баланс 1. После этого,
[45:11.180 --> 45:17.300]  как только мы читаем букву A со стека, точнее, следующая у нас буква A, это у нас правило,
[45:17.300 --> 45:25.220]  опять же нам нужно снять пустое слово и положить A на стеке. Видите, скобочный баланс у нас 2,
[45:25.220 --> 45:34.740]  вот здесь вот. Потом снимаем Q0, A, B, B. Чтобы пройти по B, нам нужно со стека снять A.
[45:34.740 --> 45:46.820]  Q0. Так, дальше у нас идет B, B. Со стека нам на стек нужно положить A, A. Ну и дальше за два
[45:46.820 --> 45:54.900]  перехода мы с вами можем сделать Q0, B, A и очистить стек следующим шагом.
[45:54.900 --> 46:03.860]  Все. То есть мы проверили, что правильные скобочные последствия у нас задаются автоматами,
[46:03.860 --> 46:12.900]  МП-автоматом. Но на одном примере можно, опять же, показывать вариантом, что скобочный баланс
[46:12.900 --> 46:21.420]  от количества букв A на стеке. Этим как раз мы с вами будем на семинарах заниматься по аналогии того,
[46:21.420 --> 46:34.260]  как мы делали это с КС-громатиками. Окей, если этот пример понятен, давайте двигаться к следующим
[46:34.260 --> 46:41.820]  фактам. Вот давайте вспоминать, что мы с вами делали с автоматами, когда мы их ввели.
[46:41.820 --> 47:05.820]  Упрощали. Упрощали. Вот здесь нам тоже самое надо сделать с вами как раз. Ну давайте это делать.
[47:05.820 --> 47:18.300]  Как мы это с вами будем делать? Первое упрощение. Оно такое. Оно касается правил в правилах
[47:18.300 --> 47:24.380]  грамматики. Ну и правил МП-автомат. Значит, смотрите, пусть у нас правила будут иметь Q1,
[47:24.380 --> 47:33.660]  Q альфа и это переходит в какой-то Q2b. Первое упрощение, которое мы с вами можем получить,
[47:33.660 --> 47:44.580]  это что все переходы не более чем однобуквенные, а количество букв, снимаемых со стека плюс
[47:44.580 --> 47:52.980]  добавляемых на стекель, не больше единиц. Это вот этот вот факт. Ну я его заглавил,
[47:52.980 --> 47:57.580]  что для любого МП-автомата существует эквивалентный МП-автомат, для которого выполнено вот такое вот
[47:57.580 --> 48:03.300]  соотношение. Давайте я картинками покажу, как это доказывать. На самом деле нам нужно просто все
[48:03.300 --> 48:10.780]  переходы разбить на куски. Смотрите, вот у нас есть такой переход, в котором есть последний символ
[48:10.780 --> 48:16.980]  от A1 до A2. Замечу, что символы здесь расположены в обратном порядке для того, чтобы мы со стека
[48:16.980 --> 48:23.580]  могли снимать. И потом добавляется B1 и так далее. Смотрите, что мы делаем. Тут, к сожалению, нет
[48:23.580 --> 48:29.900]  дорисовки, но суть понятна. Значит, смотрите, мы берем сначала, читаем все буквы алфавита,
[48:29.900 --> 48:35.180]  добавляем буквы на переходы, читаем все буквы по одной. При этом у нас модуль альфа плюс
[48:35.180 --> 48:42.380]  модуль бета равняется единице. Раз. А вторая штука, мы начинаем снимать все, что у нас находится
[48:42.380 --> 48:48.540]  сверху со стека. Мы сначала снимаем A1, потому что оно на стеке у нас находится наверху,
[48:48.540 --> 49:01.620]  потому что, сейчас у меня переключится, вот. То есть у нас стек с вами находился, у него находил,
[49:01.620 --> 49:19.380]  было что-то. Потом было ANT, AMT, AM-1 и так далее, A1. Ровно по этой причине мы сначала снимаем
[49:19.380 --> 49:26.100]  букву A1 со стека, потом снимаем AM со стека. Ну а кладем в порядке в том,
[49:26.100 --> 49:35.820]  которым нам нужен. То есть мы кладем B1, потом кладем B2 и так далее кладем Bкат.
[49:35.820 --> 49:52.540]  Все достаточно просто здесь. Мы просто берем и делаем. Давайте попробуем, если это понятно. Ну,
[49:52.580 --> 49:57.860]  я не буду формально это показывать, можно это сделать, но, мне кажется, смысла в этом нет.
[49:57.860 --> 50:07.180]  Второе упрощение. Давайте посмотрим, как хорошо у вас развита интуиция.
[50:07.180 --> 50:29.500]  Эпсилон-переходы можно удалить. Откуда? Ну, из автомата. Эпсилон-переходы почему? По стеку,
[50:29.500 --> 50:40.260]  либо по обеим. Смотрите, один из фактов, такой более общий, он будет доказан после. То есть для
[50:40.260 --> 50:46.420]  этого нам нужно будет перейти в другую нормальную форму. А первое упрощение, которое делается,
[50:46.420 --> 50:52.740]  это, замечу, что давайте мы сделаем вот такую вот вещь. Модуль альфа плюс модуль бета равно единиц.
[50:52.740 --> 50:58.660]  То есть при каждой операции мы с вами либо платим монетку за то, чтобы сойти со стека,
[50:58.740 --> 51:09.500]  вот. Либо мы кладем монетку, точнее, либо мы снимаем монетку, либо нам дают монетку за проход.
[51:09.500 --> 51:18.340]  Вот. Смотрите, в чем идея заключается. Вот у нас есть, нам надо смотреть, нам нужны рассмотреть те
[51:18.340 --> 51:24.340]  переходы, в которых модуль альфа плюс модуль бета равняется нулю, потому что у нас изначально тут
[51:24.340 --> 51:29.100]  ограничение на не больше единицы, значит, оно либо равно нулю, либо равно единице. Ну сделаем
[51:29.100 --> 51:35.940]  ограничение на ноль. Да, вот, значит, у нас есть такой переход. Тогда смотрите, что мы с вами можем
[51:35.940 --> 51:41.300]  сделать. Мы по сути можем сказать, а давайте-ка мы сначала положим монетку, а потом заберем.
[51:41.300 --> 51:49.740]  Такая эффективная банковская система у нас. Этот. Есть классический пример из мульти-индустрии,
[51:50.140 --> 51:59.300]  как этот губка-боб пытался продать продажу мыльных пузырей. Вот. Он там, по сути, сам у себя там,
[51:59.300 --> 52:06.980]  там что было? Там, короче, губка-боб продавал их, а Патрик занимал у губки-боба, и губка-боб потом
[52:06.980 --> 52:13.980]  это, возвращал обратно. В общем, нулевой цикл получается. Вот такая история. То есть мы сначала
[52:13.980 --> 52:24.620]  кладем Z на символ, потом его снимаем. Ну, а тоже вроде бы эта история понятна. То есть,
[52:24.620 --> 52:39.020]  ну, вот этим ограничением мы с вами будем как раз пользоваться. Сегодня. Да, все. Нам этого будет
[52:39.020 --> 52:58.820]  достаточно. Так, с упрощениями понятно, что произошло? Ну, то есть тут ничего сверх сложного
[52:58.820 --> 53:06.980]  нет. А теперь один из самых главных фактов, который, к сожалению, некоторые забывают,
[53:06.980 --> 53:16.460]  как доказывается, но мы с вами их посмотрим. Это то теорема большая, что класс языков распознаваемых
[53:16.460 --> 53:23.220]  МП-автоматов совпадает с классом языков, которые распознаются контекст свободными грамматиками.
[53:23.220 --> 53:30.140]  Вот. И эта теорема состоит из нескольких пунктов. Возможно, что мы еще не успеем сегодня ее показать,
[53:30.140 --> 53:42.220]  но мы с вами постараемся. Давайте я ее оформлю. То есть у нас получается КС-эквивалентный МП-автомат.
[53:49.340 --> 53:56.820]  И первый факт, который мы с вами будем показывать, это то, что из МП-автоматов
[53:56.820 --> 54:18.260]  можно получить КС-грамматику. Вот, смотрите. Давайте идею расскажу, чтобы она у нас была. А давайте
[54:18.260 --> 54:27.380]  предположим. Так, только тут небольшая стрелочка, тут вывод у нас. Пусть у нас В лежит в языке,
[54:27.380 --> 54:37.820]  задаваемом автомат. Давайте посмотрим. Q0. Нам надо прочитать слово. В эпсилон. В какой-то
[54:37.820 --> 54:47.420]  момент мы с вами прочитаем Q эпсилон эпсилон. И в какой-то промежуточке давайте QF. А здесь у нас
[54:47.420 --> 54:56.340]  есть какое-то Q, здесь у нас слово U, а здесь у нас на стеке гамма. Давайте построим график,
[54:56.340 --> 55:09.060]  который будет показывать следующий длину стека относительно того, сколько мы прочли. То есть мы,
[55:09.540 --> 55:30.460]  я сразу скажу, что у символов мы прочли. Давайте нарисуем этот график. Так, это у нас длина гамма,
[55:30.460 --> 55:44.820]  это у нас длина слова. Давайте U префикса, то есть префикс. Скажите, какие две точки мы точно с
[55:44.820 --> 56:10.580]  вами знаем на этом графике. 0, 0 и U, 0. Первое, отсюда мы начинаем, это 0, 0. А здесь длина слова
[56:10.580 --> 56:18.340]  V и 0. Ну то есть мы должны опустошить стек в конце. И давайте посмотрим, как себя этот график ведет.
[56:18.340 --> 56:25.860]  Он, во-первых, не падает ниже оси нулевой, потому что иначе у нас стек пустой. Но давайте посмотрим,
[56:25.860 --> 56:37.780]  давайте я нарисую где-нибудь картинку. Вот, пирамидка. И давайте внимательно. А потому что у нас
[56:37.780 --> 56:44.140]  стек не может быть менее чем пустой. Ну то есть он может до нуля упасть где-то, но ниже нуля он
[56:44.140 --> 56:53.980]  не провалится. Потому что это длина стек. Вот, и давайте посмотрим, что происходит на моменте,
[56:53.980 --> 57:01.500]  вот этот вот момент зафиксируем и посмотрим, что происходит на этом переходе. Напоминаю,
[57:01.500 --> 57:06.940]  что все переходы у нас имеют вид, что либо мы на стек что-то кладем, либо мы со стека что-то
[57:06.940 --> 57:17.020]  снимаем. Поэтому, когда у нас стек поднимается наверх, мы сюда кладем А. Ну какой-то символ А на стек.
[57:17.020 --> 57:26.340]  Давайте посмотрим первое пересечение этого уровня с текущим. То есть первый раз,
[57:26.340 --> 57:39.220]  когда мы пробили эту планку. Там еще и еще. Давайте поймем, можем ли мы понять,
[57:39.220 --> 57:48.060]  что происходило вот на операции, которая привела к этому уровню? Что со стеком происходило?
[57:48.060 --> 58:05.780]  Да, мы сняли, причем именно букву А. Это важно, то есть то, что мы положили на стек,
[58:05.780 --> 58:13.260]  то мы снимаем. И теперь важная особенность. Давайте мы предположим, что здесь мы находились
[58:13.260 --> 58:27.860]  в состоянии каком-то Qit, а здесь мы находились Qjit. И по сути нам нужно с вами сделать такой
[58:27.860 --> 58:35.820]  сложный автомат, который будет правило грамматики, которое будет отслеживать пары состояний. То есть
[58:35.820 --> 58:45.180]  допустим, здесь мы находились в Qf, в каком-то Q0, а вот это Q0. Тогда заведем пары состояний A0f.
[58:45.180 --> 58:59.260]  Ну то есть A0f это получается мы ставим в соответствие пару Q0Qf. Это соответствие.
[58:59.260 --> 59:06.540]  Теперь нам надо с вами продумать правила, как эти штуки у нас с вами будут отслеживаться. Я
[59:06.540 --> 59:14.860]  сейчас попробую пояснить все эти правила Пашу Пахшагова. Во-первых, первое правило,
[59:14.860 --> 59:23.940]  которое нам нужно из A и I, мы выводим епсилон. То есть если мы находимся в одном и том же
[59:23.940 --> 59:32.700]  состоянии, то есть мы находимся по сути в паре QeQe и то, что нам нужно пройти на пути от Qe до Qe,
[59:32.700 --> 59:38.180]  не меняя стэк, ну что мы можем сделать? В принципе, можем вывести пустое слово. Нам никто этого не
[59:38.180 --> 59:43.580]  мешает сделать. То есть мы находимся в точке и ничего не делаем. Мы выводим пустое слово.
[59:43.580 --> 59:53.260]  Дальше давайте сделаем переход такой, что из стартового состояния мы выходим пирамиду.
[59:53.260 --> 01:00:01.300]  Где Qgt принадлежит конечному состоянию. То есть это по сути означает следующее,
[01:00:01.300 --> 01:00:07.340]  что из стартового состояния, не терминала, в нашей грамматике мы с вами будем выводить,
[01:00:07.340 --> 01:00:15.700]  ну по сути раскрывать эту картинку. Вот так вот. То есть мы говорим раз, кусок, два кусок. Ну а
[01:00:15.700 --> 01:00:26.220]  дальше из него что-то выводится. И дальше сложный факт, который нам говорит следующее, что из A и
[01:00:26.220 --> 01:00:41.940]  житого мы будем вывозить следующую вещь. A, Ars, B, Atgt. То есть смотрите, давайте я это нарисую на
[01:00:41.940 --> 01:00:50.780]  картинке. Мы находимся в состоянии и. Вот это у нас состояние Qgt. Это в нашем графике где-то.
[01:00:50.780 --> 01:00:57.980]  И у нас и состояние Qgt, которое находится на самом деле на том же самом уровне. Потому что A и житое
[01:00:57.980 --> 01:01:06.300]  это то, что нам вводится на пути, не меняя stack. И тогда смотрите, что это означает. Как мы можем
[01:01:06.300 --> 01:01:14.700]  пойти из этой стрелки? Мы можем пойти на самом деле только вверх. Не меняя stack это значит,
[01:01:14.700 --> 01:01:21.540]  что не выкидывая из него что-то. Да, не меняя stack, не выкидывая что-то. Это просто важно,
[01:01:21.540 --> 01:01:27.940]  я забыл это указать. Извините, пожалуйста. Смотрите, что мы делаем. Значит у нас добавляется какой-то
[01:01:27.940 --> 01:01:38.580]  символ A. Мы переходим при этом в некоторое состояние QR. А здесь мы переходим, опять же,
[01:01:38.580 --> 01:01:45.740]  все чтобы было согласовано. Мы говорим, что здесь для того чтобы это согласовать,
[01:01:45.740 --> 01:01:53.060]  мы должны снять этот же символ A. И это делаем в состоянии Qs. Значит вот эта вот история,
[01:01:53.060 --> 01:02:07.420]  это у нас с вами A и житое. А нет, стоп, нет, извините, сейчас я сотру. Я сотру, я объясню,
[01:02:07.420 --> 01:02:14.580]  почему я стер. Потому что давайте найдем первый уровень, когда мы пересекли эту полосу. Потому
[01:02:14.580 --> 01:02:23.060]  что мы могли ее пересечь именно в кружитом, а могли раньше. То есть мы берем, пересекаем,
[01:02:23.060 --> 01:02:38.180]  это минус A. Я напишу, что это первый момент, первый момент пересечения. И пусть это у нас
[01:02:38.180 --> 01:02:53.020]  состояние s, а вот это состояние t. Тогда это Qt, это Qs. Тогда вот это у нас, что с вами такое? Это у
[01:02:53.020 --> 01:03:06.980]  нас A и ж по нашему обозначению. Вот это у нас с вами Atg, а вот это у нас с вами Ars. Ну потому что мы
[01:03:06.980 --> 01:03:11.740]  тут уже не добавляем, не выкидываем что-то из тек, потому что если мы опускаемся ниже,
[01:03:11.740 --> 01:03:22.700]  то мы получаем в этот уровень. Мы получаем с вами, что у нас и A и жт выводятся. Здесь пусть
[01:03:22.700 --> 01:03:30.620]  какой-то символ A был. Здесь у нас был с вами этот Ars, B, который снимает отсюда символ. Видите,
[01:03:30.620 --> 01:03:39.020]  скоро B, а мы снимаем всего, приходим в состояние. Так, а печатка здесь, здесь t, здесь t, Qt,
[01:03:39.020 --> 01:03:58.420]  Эпсилон. Давайте напишу. Так, значит это если у нас Qea, Эпсилон, Qra. А здесь у нас с
[01:03:58.420 --> 01:04:19.820]  вами получается Qrba, Qgt, Эпсилон. Вот так вот. Ой, не Qgt, а Qtt. И теперь нам надо это все
[01:04:19.820 --> 01:04:24.940]  формально показать, почему это работает. Главная лемма, которая здесь у нас с вами появляется,
[01:04:24.940 --> 01:04:35.580]  она заключается в следующем. Она говорит, что если мы A из A и житого выводим w тогда и только тогда,
[01:04:35.580 --> 01:04:46.700]  тогда выполнно следующее соотношение QeTv Эпсилон, выводится QeT, Эпсилон, Эпсилон.
[01:04:46.700 --> 01:04:58.260]  Здесь у нас это в грамматике, это в автомате, это в грамматике. Вот. То есть если мы это показываем,
[01:04:58.260 --> 01:05:09.340]  то на самом деле уже победа. Потому что тогда мы из S заходим в Q0 в A0 житая, ну и дальше мы
[01:05:09.340 --> 01:05:22.060]  выводим все слово целиком. То есть это лемма, которую нам надо будет с вами показать. Ну,
[01:05:22.060 --> 01:05:28.380]  давайте начнем. Хотя бы один пункт из двух разберем здесь. На сегодня уже будет победа.
[01:05:28.380 --> 01:05:37.540]  Так, смотрите. Давайте я правила буду держать при себе. Давайте докажем слева направо сначала.
[01:05:37.540 --> 01:05:42.300]  Здесь у нас опять же классическая индукция, индукция по длине вывода в грамматике.
[01:05:42.300 --> 01:05:52.180]  Не вывода в грамматике.
[01:05:52.180 --> 01:06:06.140]  Скажите базов, какая у нас с вами. За сколько шагов мы можем вывести что-то из этой грамматики?
[01:06:06.140 --> 01:06:15.580]  Вот в этих правилах.
[01:06:15.580 --> 01:06:37.820]  Можем ли мы что-то вывести за ноль шагов?
[01:06:37.820 --> 01:06:51.940]  Ну, если и равно жи, то да. А как? Как мы можем что-то за ноль шагов?
[01:06:51.940 --> 01:07:00.780]  Нет, это за один шаг. Да, за один шаг. Если мы возьмем A и ИТ эпсилон. То есть один шаг.
[01:07:00.780 --> 01:07:10.260]  Тогда мы с вами из A и ИТ выводим эпсилон. Только у нас вот это вот правило есть.
[01:07:10.260 --> 01:07:25.220]  Следовательно, у нас с вами и равно жи, w равно эпсилон. Ну, из этого будет следовать, что qi эпсилон эпсилон мы выводим qi эпсилон эпсилон.
[01:07:25.340 --> 01:07:26.340]  Ну, вроде честно.
[01:07:26.340 --> 01:07:45.540]  Теперь переход. Мы с вами допустим из A и из ж вывели какое-то слово w за к шагов.
[01:07:45.540 --> 01:07:56.140]  Тогда смотрите внимательно. Какое правило у нас может раскрывать меньшее количество шагов? Только вот это вот.
[01:07:56.140 --> 01:08:23.140]  Тогда замечу, что A и ж раскрывается в A, A rs, B, A and jt. Только по такому правилу у нас что-то могло раскрываться.
[01:08:23.140 --> 01:08:43.140]  При этом qi, a эпсилон выводится. Есть переход, точнее qr, a.
[01:08:43.140 --> 01:08:58.140]  А здесь у нас qrt. Так, извините, пожалуйста, я еще одну, еще один бак у себя нашел. Давайте его пофиксим.
[01:08:58.140 --> 01:09:08.140]  Здесь везде qst, видите? То есть мы из qs должны в qt переходить. Приношу извинения.
[01:09:14.140 --> 01:09:24.140]  Из qst по B, A. Снимаем его и переходим в qt эпсилон.
[01:09:24.140 --> 01:09:45.140]  Но мы знаем, что существует тогда, смотрите, слово w раскрывается в виде A, U, B, V.
[01:09:45.140 --> 01:10:03.140]  Опять же, просто строим дерево вывода. При этом, что хочу сказать, что из A rs у нас выводится U, из A jt у нас выводится V.
[01:10:03.140 --> 01:10:17.140]  И по предположению индукции каждого, потому что это будет сделано за меньше что шагов, то мы с вами получаем следующую вещь.
[01:10:17.140 --> 01:10:39.140]  Что у нас из qrt у эпсилон мы можем вывести qst эпсилон, а здесь у нас из qt в эпсилон мы можем вывести qjt эпсилон.
[01:10:39.140 --> 01:10:47.140]  Это по предположению индукции работает. Вот с этого факта.
[01:10:47.140 --> 01:10:59.140]  Ну теперь давайте собирать все по цепочке. Если мы из qt, A, U, B, V и берем и раскрываем эпсилон.
[01:10:59.140 --> 01:11:21.140]  Первый шаг, который у нас будет, давайте я их буду пояснять. Вот это первый шаг. У нас получается мы снимаем, читаем букву A, здесь мы переходим в R, здесь у нас получается U, B, V и на стэк кладем A.
[01:11:22.140 --> 01:11:40.140]  Потом пользуемся вторым правилом. Здесь у нас второй переход. Мы получаем qr, U снимаем со входа, переходим в qs, при этом стэк у нас не меняется, B, V, а здесь у нас получается A.
[01:11:40.140 --> 01:11:48.140]  Потом мы пользуемся третьим правилом. Вот этим вот.
[01:11:48.140 --> 01:11:58.140]  Получаем, что у нас с вами. Мы из qs по B вход, A снимаем со стэка, получаем qt, V, эпсилон.
[01:11:58.140 --> 01:12:19.140]  Ну и осталось четвертым шагом воспользоваться. Мы получаем с вами U, эпсилон, эпсилон. Все. Чистота, как говорится, мои руки чистые в этой штуке.
[01:12:19.140 --> 01:12:38.140]  Вот. В обратную сторону чуть-чуть сложнее, но давайте как раз мы с вами в следующий раз и продолжим, потому что мне кажется, что лучше оставить время на вопросы.
[01:12:38.140 --> 01:12:43.140]  Сейчас мы просто уже не успеем эту вещь ничего доказывать.
[01:12:43.140 --> 01:12:58.140]  Ну там надо рассмотреть, типо, первый шаг, который нам нужно сделать здесь.
[01:12:58.140 --> 01:13:06.140]  Так, давайте задавайте вопросы. Говорите, понятно было или нет.
[01:13:06.140 --> 01:13:10.140]  А еще раз, как из LEM будет следовать теорияма?
[01:13:10.140 --> 01:13:15.140]  Да, давайте тогда вот как раз на этот момент, как из LEM исследовать теорияма.
[01:13:15.140 --> 01:13:28.140]  Это на самом деле не очень сложно. Смотрите, мы знаем, что, значит, нам что нужно показать, что любой mp-автомат распознается mk-автоматом.
[01:13:28.140 --> 01:13:41.140]  Смотрите, из S выводится W. В обе стороны будем говорить. Что значит из S выводится W?
[01:13:41.140 --> 01:13:59.140]  Это значит, что существует какое-то a и gt. Вот смотрите, вот у нас, точнее, видите, из S есть переходы только a0gt, в котором идет переход A0gt.
[01:13:59.140 --> 01:14:14.140]  То есть у нас существует a0gt, для qgt принадлежит f. Такое, что S у нас выводят за один шаг a0gt, из этого выводится W.
[01:14:14.140 --> 01:14:34.140]  Дальше, что это значит? Опять же, переписываем, что существует a0gt для некоторого qgt из f. Такое, что, иду с внимания,
[01:14:34.140 --> 01:14:54.140]  у нас вот эта вот лемма. Эта вот лемма здесь используемся. Что из q0wε мы выводимся в qgt εε.
[01:14:54.140 --> 01:15:13.140]  А это что у нас получается? Существует qgt из f. Такое, что q0wε выводится в qgt εε.
[01:15:13.140 --> 01:15:27.140]  Но вот эта штука, тут надо сказать, что это у нас объективное преобразование из qgt в a0gt. А вот это означает, что W принадлежит языку, задаваемую автоматом.
[01:15:27.140 --> 01:15:41.140]  Потому что мы, по сути, с вами сняли стэк, получили то, что получили. А здесь у нас получается, что это у нас W принадлежит языку, задаваемую грамматикой.
[01:15:41.140 --> 01:16:01.140]  То есть самый тонкий момент, это просто, что у нас вместо из qgt мы можем сделать b.
[01:16:01.140 --> 01:16:25.140]  Можно вопрос? Да.
[01:16:25.140 --> 01:16:35.140]  По поводу второго упрощения, это уже даже не эта теорема, где мы на стэке либо забираем, либо отдаем хотя бы.
[01:16:35.140 --> 01:16:43.140]  Да, да, да. Почему мы получим эквивалентную? У нас же получается, на стэке остается вот этот z?
[01:16:43.140 --> 01:16:49.140]  Да, мы его сразу снимаем. Мы кладем и сразу снимаем его.
[01:16:49.140 --> 01:17:01.140]  Когда мы пишем справа, это кладем, а слева забираем, да? Да, да. То есть слева плата за вход, а справа премия за переход.
[01:17:01.140 --> 01:17:17.140]  Спасибо.
[01:17:17.140 --> 01:17:25.140]  Ну ладно, давайте тогда. Все, всем спасибо, всем здоровья, всем не болеть.
