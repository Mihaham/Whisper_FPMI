[00:00.000 --> 00:12.780]  Всем доброго вечера! Вот мы снова встретились, я не знаю, в какой раз уже. На сегодня и вообще
[00:12.780 --> 00:18.800]  за любое время. Мы с вами сегодня будем говорить про куду. Это как раз, вы не поверите, из тех
[00:18.800 --> 00:24.360]  историй, которые я у вас веду, это наиболее приближенные, кто лучше на работе занимается,
[00:24.360 --> 00:31.880]  наконец-таки в какой-то веке. И у нас будут четыре блока занятий, четыре занятия, будут четыре лекции,
[00:31.880 --> 00:38.120]  четыре семинара. Сегодня мы с вами поймем, почему люди пишут на видеокартах, а на практике мы с
[00:38.120 --> 00:46.000]  вами уже будем рассматривать какие-то решения именно задач. Возможно, кстати, что задачи можно
[00:46.000 --> 00:52.600]  будет писать как на плюсах, так и на питоне. Это будет некоторым большим преимуществом.
[00:52.600 --> 01:05.520]  Что, там все в порядке? А, просто камера кодит, не то смотреть. Господи, как же странно она. Ну ладно.
[01:05.520 --> 01:14.480]  В общем, давайте вопрос такой. Кто-нибудь пытался хоть когда-нибудь разбираться с тем,
[01:14.480 --> 01:24.320]  как работает код на видеокарте? Соусов, да? То есть, было такое. Ну вот, ну мы с вами все-таки научимся
[01:24.320 --> 01:29.360]  немножко пробовать на видеокарте, плюс, возможно, успеем посмотреть какие-то дополнительные библиотеки,
[01:29.360 --> 01:33.520]  то есть, если мы на лекциях будем двигаться достаточно быстро, возможно, я принесу даже
[01:33.520 --> 01:40.200]  что-то интересное. Значит, что мы узнаем сегодня? Чем процессоры отличаются от видеокарт? Тема
[01:40.200 --> 01:47.080]  нашей сегодняшней вещи. Дальше. Знаете такую вещь под названием закон Мура? Вот. Поймем,
[01:47.080 --> 01:53.480]  как он преобразовался для видеокарт. То есть, вот. И дальше мы поймем, как ускорять программу
[01:53.480 --> 01:59.440]  на видеокарте так, чтобы они работали быстрее. И последняя вещь, которую мы знаем из всего того,
[01:59.440 --> 02:04.640]  что происходит, как использовать всю мощность на видеокарте. Я сразу скажу, что всю мощность на
[02:04.640 --> 02:08.680]  видеокарте тяжело использовать, если особенно вы не понимаете, как устроена архитектура
[02:08.680 --> 02:15.080]  видеокарты. То есть, если вы можете писать на обычных процессорах код и не задумываться,
[02:15.080 --> 02:20.120]  как там все устроено, хотя все равно выравнивание так или иначе нужно, то для видеокарты нужно
[02:20.120 --> 02:29.440]  разбираться, как это все работает. Вот. То есть, это очень важно. Вот. Это наш блог. Значит, и мы с вами,
[02:29.440 --> 02:42.760]  мы этим занимаемся 4 недели. Так. Давайте начнем с того, что поймем, что такое GPU. Кто может
[02:42.760 --> 02:53.240]  попробовать сформулировать? Да. Ну, замечательно. Аббревиатуру мы умеем расшифровывать. Что это такое?
[02:53.240 --> 03:07.000]  Да, гениально вообще. Теперь посуществует. Да, процессор, отвечающий за графику, если грубо
[03:07.000 --> 03:12.360]  говорить. Давайте сначала сформулировать определение центра Processing Unit. Это электронная
[03:12.360 --> 03:17.120]  схема, разработанная для определения операций в произвольной компьютерной программе. То есть,
[03:17.120 --> 03:22.840]  это процессор общего назначения. Что такое GPU? Это Graphic Processing Unit. Это специальная
[03:22.840 --> 03:27.320]  электронная схема, разработанная для выводов изображений на экран преимущественно. Так
[03:27.320 --> 03:33.800]  называемый рендеринг. Вот. В компьютерах за вывод информации на экран занимается отдельное
[03:33.800 --> 03:46.320]  устройство. Как мы обычно его называем? Огромче. Да, молодцы. Видеокарта. Или по-другому еще ее
[03:46.320 --> 03:55.720]  называют видюхой. Или GPU. Вот. Ну, давайте поймем, с чего все началось. Сейчас будут первые
[03:55.720 --> 04:01.960]  вычисления. Не переживайте. Разберемся с ними. Значит, с чего все началось? 2D отрисовка объектов
[04:01.960 --> 04:09.960]  занимает немного ресурсов. То есть, представьте себе, вы пишете инди-игрушку в 2D. Давайте
[04:09.960 --> 04:15.160]  поймем, почему отрисовка 2D графики не очень тяжелая задача и может быть выполнена на центральном
[04:15.160 --> 04:25.560]  процессоре. Давайте прикинем это. Да, давайте посчитаем. Количество пикселей по каждому, по каждой
[04:25.560 --> 04:31.680]  измеренности, это о большое отн. Наверное, все согласны. То есть, всего количество пикселей у нас
[04:31.680 --> 04:36.720]  о отн квадрат. Давайте посчитаем количество памяти, которое нам необходимо перегонять на
[04:36.720 --> 04:44.040]  видеокарте. Ну, за единицу времени. За одну секунду. И поймем, соотносится это с высшительной
[04:44.040 --> 04:50.080]  мощностью процесса. Значит, все это началось в 80-х годах. Вы, возможно, слышали, есть такая
[04:50.080 --> 04:56.880]  приставка Nintendo Entertainment System. Она уже у нас называется Dendy. Так вот, если мы с вами говорим про
[04:56.880 --> 05:03.120]  Dendy, то разрешение экрана, которое она позволяет выводить, это 320 на 240. То есть, тогда такие
[05:03.120 --> 05:10.560]  мониторы были. Это сейчас у нас уже вот эти вот устройства имеют разрешение 1920 на 1080. А вот тогда
[05:10.560 --> 05:23.200]  еще не было такого. Ну и, в общем, давайте считать. У нас с вами 320 на 240. Хорошо. Это количество
[05:23.200 --> 05:31.360]  пикселей. Дальше нам нужно посчитать, что нам необходимо посчитать, чтобы оценить объем памяти,
[05:31.360 --> 05:46.960]  который нам нужно перегонять за одну секунду. А что это такое? Это сейчас так. Это сейчас так.
[05:46.960 --> 05:57.800]  Смотрите, у нас сейчас каждый цвет, это по факту RGB, он занимает 8 бит или 1 байт. Тогда процессоры
[05:57.800 --> 06:06.080]  были такие, что они максимально умели отображать 256 цветов. То есть, на самом деле у нас здесь 8 бит.
[06:06.080 --> 06:18.720]  То есть, это у нас с вами получается, да, 256 цветов я напишу. Так, дальше. Ну, что еще умножить надо?
[06:18.720 --> 06:36.760]  Да, на частоту. Как вы думаете, частота какая? Вы не поверите. Ну, сколько FPS? Ну, зависит от
[06:36.760 --> 06:49.480]  экрана. Ну, вообще, не поверите. Не поверите, в те времена тоже было 60 FPS. I'm believable. Просто там
[06:49.480 --> 06:59.200]  каждый второй кадр пропускался. Да, да, да. Ну, что? Давайте считать. Рубрика калькулятор. В уме мы не
[06:59.200 --> 07:07.200]  будем считать. Ну да, как раз с этим и связано, что нам нужно было отрисовывать экран. То есть, у него
[07:07.200 --> 07:13.080]  была передняя стенка и у него есть задняя стенка. То есть, пока за один кадр отображается, на заднем
[07:13.080 --> 07:21.160]  кадре рецентризуется изображение. Только VGA, экран первый, который появился в 87-м году, у него было
[07:21.160 --> 07:31.200]  разрешение 640 на 480. Так, блин, короче, это все было сделано для одного курса, поэтому давайте
[07:31.200 --> 08:00.840]  посчитаем. 320 на 240. На сколько? На 60. Получаем 4608. Мегабайт в секунду. Это биты,
[08:00.880 --> 08:17.240]  если что. Я в биты перевел сразу. Ну, что? 4 мегабайта в секунду. 80-е годы. Так, вопрос, какой мне запрос
[08:17.240 --> 08:43.560]  Google отдать, чтобы понять, нормально это или нет. Не, все просто. Процессор деньги.
[08:47.240 --> 09:08.440]  Частота процессора. Да, мы приблизительно в этих объемах работаем. В целом, говорим, что один байт
[09:08.440 --> 09:16.600]  за такта перегонять мы сможем. То есть, в принципе, получаются одинаковые числа по порядку. То есть,
[09:16.600 --> 09:21.780]  возможно, где-то лагает. Ну, наверное, если тут вместо 60 поставить 24, у нас приблизительно
[09:21.780 --> 09:29.160]  сойдется. Но, опять же, не надо воспринимать это как истинно в последней инстанции. Не, ну,
[09:29.160 --> 09:37.720]  просто мы отрисовку делаем в 24 кадра в секунду. То есть, мы здесь положили все в 60. Все, отлично.
[09:37.720 --> 09:57.360]  Но. Тут есть одно но. Это было 80-е годы. Переходим в 90-е. Что у нас появилось в 90-х? Ну, ладно,
[09:57.360 --> 10:06.560]  геймбой. Плейстейшн появилась. Сега появилась в 87-м, 80-м. Появились Плейстейшн 1. Значит,
[10:06.560 --> 10:13.160]  всякие замечательные приставки, которые. Ну, у нас же мощный процессор. Давайте в 3D. Ну,
[10:13.160 --> 10:24.400]  что? Давайте в 3D. Как у нас с объектов 3D отрисовываются? У нас есть сфера. Как
[10:24.400 --> 10:35.480]  она отрисовывается? Полигон треугольничками. То есть, нам нужно покрыть всю сферу треугольничками
[10:35.480 --> 10:41.320]  маленькой частоты. Ну, чтобы сферу отрисовать. И представьте себе, что эта сфера у нас во весь
[10:41.320 --> 10:46.000]  экран. То есть, нам нужно для каждой точки сферы определить, трисуется она или нет. То есть,
[10:46.000 --> 10:53.920]  нам нужно переднюю половину сферы отрисовать, а заднюю половину сферы убрать. А? Ой,
[10:53.920 --> 11:00.080]  рейтрейсинг сейчас появился только в современных видеокартах. До этого рейтрейсинг это вообще была
[11:00.080 --> 11:08.280]  неподъемная задача. То есть, она алгоритмически была сложно разрешена. Ну вот, смотрите, что у
[11:08.280 --> 11:13.080]  нас получается. У нас получается следующая вещь, что нам нужно отрисовать площадь сферы,
[11:13.080 --> 11:23.200]  приблизительно пикселей. Площадь сферы чему равняется? Четыре пер квадрата.
[11:29.520 --> 11:38.960]  Сделаем мысленную замену. Сфера у нас весь экран зафигаичен. То есть, каждый пиксель должен
[11:38.960 --> 11:45.200]  отрисовывать это всем изображением. Ну давайте считать, что у нас получается. У нас с вами еще
[11:45.200 --> 11:51.600]  происходит фазовый переход на то, что мы все-таки хотим играть с вами на VGA экранах. То есть,
[11:51.600 --> 12:00.520]  у нас получается 640 на 480. Процессоры у нас какие с вами? Восьми битные или какая частота битности?
[12:00.520 --> 12:12.360]  Здесь уже 32-битные процессоры появились. Сега 16-битная. Умножаем на 60 кадров в секунду.
[12:12.360 --> 12:21.640]  А, еще на 4, на 3, на 3,14 надо умножить, потому что мы хотим отрисовывать эти объекты. Так,
[12:21.640 --> 12:33.040]  ну что, считаем. 640 на 480, на 4, на сколько?
[12:51.640 --> 13:13.240]  Почти гигабайт. Так, ну чего, что делать? Так, какой запрос нам нужно задать в интернете для того,
[13:13.240 --> 13:28.760]  чтобы... Так, еще один запрос. Зайдем в PDWQ.
[13:28.760 --> 13:58.720]  34 МГц. Упс. Ну, смотрите, зато хоть что-то
[13:58.720 --> 14:06.840]  у нас совпало. Видите, пропускная способность шины. Ну, в мегабитах, правда, здесь мы в мегабайтах
[14:06.840 --> 14:15.040]  посчитали. Поэтому, как вы думаете, я, к сожалению, не знаю, видно тут сверху или нет, как выглядят
[14:15.040 --> 14:41.520]  первые 3D-игры. Так, контент... Да, ну, то есть вот так вот выгляделы раньше игры. Не поверьте,
[14:41.520 --> 14:47.680]  я даже играл в нее, в детстве, когда был. Да, то есть нам нужно какое-то отдельное устройство,
[14:47.680 --> 14:55.520]  которое отрисовывает все на экран. Трехмерные модели. Это, смотрите, это мы еще не считали все
[14:55.520 --> 15:04.080]  по вокселям. Там порядка куба получается. Нам надо сделать проекцию в 2D, хотим 32-битную систему.
[15:04.080 --> 15:12.760]  Да, видите, тут еще разрешение экрана 320 на 240. А так бы нам надо было все гонять это все на таких
[15:12.760 --> 15:22.240]  экранах. Вы не поверите, кстати, у Кармака в 2001 году уже был FullHD-экран. Ну, у создателя DOOM или Quake,
[15:22.240 --> 15:31.680]  я не помню. Ну, вот известный. А? А, да. У него был реально FullHD-экран с электронной трубкой в 2001 году,
[15:31.680 --> 15:40.760]  на котором XP стояла. Да, то есть тогда уже такие мониторы были. И, соответственно, мы понимаем с
[15:40.760 --> 15:44.480]  вами, что у нас возникают проблемы, и нам нужны графические ускорители, то есть отдельные
[15:44.480 --> 15:51.520]  программы, которые вычисляют мощность нашего процессора. Вот, значит, и тут возникает следующая
[15:51.520 --> 15:58.520]  вещь, что возникает такая популярная видеокарта, называется графический ускоритель, который ставился
[15:58.520 --> 16:05.440]  отдельно под ПК. И этот ускоритель называется, по-моему, Voodoo оно называется. Я точно всегда забываю.
[16:05.440 --> 16:11.800]  Типа 3DFix это компания или видеокарта. По-моему, 3DFix это компания, да. 3DFix компания. Значит,
[16:11.800 --> 16:19.680]  я не знаю, вижу на слева, значит, на экране изображена игра Need for Speed.HotPirates 3. Это по факту
[16:19.680 --> 16:28.120]  первая игра NTS, в которой появились копы. До этого их не было. Вот. И из-за того, что эта игра появилась,
[16:28.120 --> 16:35.120]  она сделала небольшой фурор. И вот смотрите, как выглядит слева картинка без видеокарты,
[16:35.120 --> 16:41.440]  без использования этого чипа, а справа то, как она выглядит с использованием чипа. Найдите 10 отличий.
[16:41.440 --> 16:54.520]  Это, да, это один и тот же кадр, просто слева левая половина без ускорителя, справа с ускорителем.
[16:54.520 --> 17:04.920]  Освещение лучше, видите, модельки более прозрачные, деревья лучше отрисованы и так далее.
[17:04.920 --> 17:13.680]  Да, к сожалению, плохо видно. Давайте я в чат скину презентацию после, там можно будет
[17:13.680 --> 17:20.320]  увидеть более детально картинку. Тут, видимо, из-за того, что экран светит, и возможно,
[17:20.320 --> 17:25.120]  это плохо видно. Мы, конечно, можем поправить экран, но свет, освещение...
[17:34.920 --> 17:53.680]  Видите, прямо явная разница между этими. Я тоже, как сказать, обалдел,
[17:53.680 --> 18:01.040]  когда это все поставилось. Правда, у меня эта игра уже была в 2006 году или 2007, не помню. И тогда
[18:01.040 --> 18:06.040]  там реально был патч, но суть в том, что тогда центральные процессоры уже были достаточно мощны,
[18:06.040 --> 18:10.440]  и уже можно было на каких-то дискретных видеокартах это гонять. Ну, не дискретно,
[18:10.440 --> 18:15.680]  но в встроенных видеокартах. Ну, я, типа, когда я поставил этот патч, увидел, такой, вау,
[18:15.680 --> 18:26.480]  оказывается, эта игра такая крутая, а не полигональная, заговаривающая, извините. В общем,
[18:26.480 --> 18:34.040]  компания 3dfx была очень популярной. Вот, чтобы вы понимали это, представьте себе, что если бы
[18:34.040 --> 18:40.440]  сейчас на рынке видеокарт был бы еще один игрок, крупный игрок. Ну, и сейчас у нас два крупных игрока
[18:40.440 --> 18:49.600]  на видеорынке. Значит, конкуренты догоняли, появилась компания, такая называется NVIDIA. Она
[18:49.600 --> 18:55.880]  придумала механизм шейдеров. Что такое шейдер? Это программированные модули на видеокарте. Модуль
[18:55.880 --> 19:02.920]  для вычтения света и цвета. Вот. И была другая компания, Silicon Graphics. Возможно,
[19:02.920 --> 19:16.560]  кто-то из нее, принес, слышал. Никто не слышал? Ага, Пелевина читали? Ага, оно самое. На, в поколении
[19:16.560 --> 19:23.760]  EP прочитайте, там очень большой опус, ну, небольшой там такой, есть опус про Silicon Graphics. Это стандарт
[19:23.760 --> 19:31.440]  OpenGL, Open Graphical Language. В общем, они дали API для доступа к функциям рендеринга к GPU. То есть,
[19:31.440 --> 19:39.120]  раньше можно было написать код на OpenGL и все начало работать. Ну, в общем, появились два крупных
[19:39.120 --> 19:44.760]  конкурента, которые в итоге вытеснили эту компанию на рынке, потому что они начали по факту
[19:44.760 --> 19:50.960]  предоставлять аналог Open Source решений, а 3dfx начала выпускать карточку Voodoo, Voodoo 2, Voodoo 3,
[19:50.960 --> 19:58.680]  а дальше они решили, что-то у них пошло не так. Да, а еще какое время на рынке было? Это было
[19:58.680 --> 20:09.320]  начало нулевых годов. Экскурс в историю. Что было в начале нулевых годов? Да, Crack.com был.
[20:09.320 --> 20:15.680]  Собственно, это кризис, который был вызван тем, что компании, которые были на рынке, на финансовом,
[20:15.680 --> 20:24.260]  и пузырились тогда. То есть, любой сайт с тем номинованием dot.com там поднимал капитализацию
[20:24.260 --> 20:31.440]  вашей компании очень сильно. В итоге понятно, что за этим мало что стояло. Там были финансовые
[20:31.440 --> 20:36.800]  скандалы и так далее. В итоге финансирование резко сократилось. Собственно, понятно,
[20:36.800 --> 20:43.960]  что такой проект уже был неинтересен, когда вырастали другие гиганты. Кстати, такой тоже
[20:43.960 --> 20:49.360]  экскурс в историю. Как вы думаете, NVIDIA на чем зарабатывает сейчас? Большую часть своей прибыли?
[20:49.360 --> 21:09.800]  Нет. Это есть. Просто они сейчас уже ушли в другую сферу тоже. Они пытаются прорабатывать именно
[21:09.800 --> 21:15.680]  решение для искусственного интеллекта. За этим, скорее всего, будущее. Вот как ни странно,
[21:15.680 --> 21:21.120]  год назад я еще не мог такого сказать, когда я вел занятия, но, сами понимаете,
[21:21.120 --> 21:27.520]  развитие современных технологий сильно изменил этот тренд. То есть, видели,
[21:27.520 --> 21:33.320]  то есть, там, ЧАД-GPT появился модель. Дальше появился всякие диффузионные модели,
[21:33.320 --> 21:41.000]  которые красиво рисуют изображения. Да, они самые. И они очень сильно сбустонули этот рынок.
[21:41.000 --> 21:47.440]  То есть, реально сейчас генерация изображений по факту уходит уже на это дело. Вы сейчас можете
[21:47.440 --> 21:53.120]  видеть уже, что некоторые обложки и так далее генерируются уже при помощи нейросетей на видео.
[21:53.120 --> 22:02.240]  Вот. Так что, видите, уход в другое направление сильно активно развивает. Ну, в итоге 3D
[22:02.240 --> 22:07.680]  Fx Mankrot, ну, это как бы часть истории, при помощи которой появились вот эти графические
[22:07.680 --> 22:15.760]  ускорители. То есть, у нас есть две компании, NVIDIA и Echelon Graphics, OpenGL. И здесь мы должны
[22:15.760 --> 22:23.280]  немножко поговорить про компьютерную графику. Совсем немного. Это процедура рендеринга экранов
[22:23.280 --> 22:30.480]  в OpenGL, в первом примитивном формате. То есть, у нас, смотрите, подается набор вершин треугольника
[22:30.480 --> 22:37.880]  для того, чтобы отрендерить их. То есть, нам нужно карту нормальной понять и отрисовать по факту
[22:37.880 --> 22:42.800]  поверхность треугольника таким образом, чтобы поверхность фигуры, чтобы она отрисовывалась.
[22:42.800 --> 22:49.520]  Вот. Дальше, после того, как мы определяем это все дело, смотрите, здесь синий слайд на экране. Он
[22:49.520 --> 22:54.600]  говорит о том, что этот модуль программируемый. То есть, мы можем написать код на языке шейдеров,
[22:54.600 --> 23:03.280]  который сделает у нас всю эту процедуру. Дальше у нас возникает растеризатор. Он по факту,
[23:03.280 --> 23:11.360]  у вас вот эта вот градица фигуры, вы берете и примените заливку черным цветом. После этого у вас
[23:11.360 --> 23:16.240]  есть фрагментный процессор, который говорит, что для каждого кусочка этого пикселя вы можете
[23:16.240 --> 23:23.040]  либо наклеить свой цвет какой-то, либо наклеить какую-то текстуру. И это вы делаете руками.
[23:25.560 --> 23:33.560]  А после этого вы берете эти фрагменты и проецируете на 2D картинку с определенным
[23:33.560 --> 23:38.240]  кропом. Вот такая процедура. То есть, у нас есть два модуля, которые позволяют выполнять какие-то
[23:38.240 --> 23:48.720]  операции. При этом программируемый модуль работает с матрицами 4х4. Почему это так? Я не знаю,
[23:48.720 --> 23:55.440]  насколько у вас был масштабный курс по геометрии. Знакомы ли вы с таким понятием,
[23:55.440 --> 24:06.640]  как проективная геометрия? Небольшой экскурс. Мы работаем с вами в оптической среде. У нас
[24:06.640 --> 24:33.640]  экскурс кольную физику. Так, узнаете тему? Что с этими? Они попадут в одну точку.
[24:37.640 --> 24:50.720]  Это собственно линза. Мы знаем, что параллельные лучи, которые идут в прямую, при перещении линзы
[24:50.720 --> 25:00.360]  попадает фокус. Это фокальная прямая. Нам нужна тип геометрии, которая умеет справляться с этими
[25:00.360 --> 25:07.880]  всякими преобразованиями. Нам нужно сделать так, чтобы параллельные прямые все-таки пересекались.
[25:07.880 --> 25:17.040]  Желательно, чтобы еще одни пересекались в одной точке. И этим занимается как раз проективная
[25:17.040 --> 25:26.520]  геометрия, которая говорит некоторые постулаты, что все прямые пересекаются между собой. При этом
[25:26.520 --> 25:34.160]  существует, если у нас есть пучок параллельных прямых и в клидовой геометрии, то они пересекаются
[25:34.160 --> 25:49.680]  в одной точке. Обязательно. Зачем нам нужна проективная геометрия? А вот он пример. У нас
[25:49.680 --> 25:56.360]  параллельные прямые пересекаются в одной точке. Чтобы у нас
[25:56.360 --> 26:03.040]  картинка слева была отождественна с картинкой, которая справа. При этом важно, что все параллельные
[26:03.040 --> 26:20.000]  прямые пересекаются на... смотрите. Где вот эти лучи пересекутся? Ну, давайте я не буду проводить.
[26:20.000 --> 26:25.640]  В общем, они тоже пересекутся на фокус. То есть любые два пучка параллельных прямых, точки перещения
[26:25.640 --> 26:33.880]  всех параллельных прямых, лежат тоже на одной прямой. И вот эта прямая здесь называется покальной.
[26:33.880 --> 26:40.720]  А вот эта прямая, с другой стороны, называется бесконечно удаленная прямая.
[26:40.720 --> 26:57.640]  Вот. И оказывается интересное свойство, что вот эта геометрия с этими двумя постулатами,
[26:57.640 --> 27:02.880]  их на самом деле может быть больше, ультворяет следующее свойство, что преобразование в этой
[27:02.880 --> 27:20.360]  геометрии можно задать четверкой. Здесь она, вот она. Вот. То есть это вот такая вот набор четверки
[27:20.360 --> 27:28.800]  координат, где они эквивалентны следующим свойствам. Альфа х, альфа у, альфа з, альфа т. Ну, если мы
[27:28.800 --> 27:39.480]  говорим про тракт нервную плоскость. То есть количество координат здесь будет в 4, а не 3. Вот. Я,
[27:39.480 --> 27:46.880]  честно, не помню, вот сейчас вылетел из головы, t равное нулю или t неравное нулю отвечает за бесконечно
[27:46.880 --> 27:55.440]  удаленную прямую. Но она здесь есть. То есть здесь как раз два случая, t равняется нулю и t не равняется нулю.
[27:55.440 --> 28:11.900]  Да. Да, да, да. Все, я как раз вы задали вопрос, я вспомнил. Смотрите, значит t неравное нулю это
[28:11.900 --> 28:29.540]  обычно Евклидова, а t равное нулю это бесконечно удаленное. Да, это по факту флаг. Смотрите,
[28:29.540 --> 28:34.780]  почему не наоборот, потому что мы можем домножить всегда на такой коэффициент, чтобы вот эта штука
[28:34.780 --> 28:42.300]  равняется единице. То есть когда мы фиксируем канонический вид этой точки, то здесь единичка и здесь
[28:42.300 --> 28:50.780]  у нас получаются координаты. Вот. А иначе, если мы t равное нулю, ну, типа эти, получается, бесконечно
[28:50.780 --> 28:55.620]  удаленные прямые будут находиться на плоскости. То есть там будет кодироваться бесконечно удаленная
[28:55.620 --> 29:01.100]  плоскость. Ладно, не суть важна, это просто экшверт геометрию. Мы с вами понимаем, что любое
[29:01.100 --> 29:08.540]  линейное преобразование в Евклидовой геометрии, в Евклидовом пространстве, это матрица 3 на 3.
[29:08.540 --> 29:14.260]  Перемножение на матрицу 3 на 3. В проективном пространстве это будет перемножение на матрицу 4 на 4.
[29:14.260 --> 29:26.020]  А? Это коэффициент, типа, который позволяет нам показать, мы переходим в бесконечно удаленную
[29:26.020 --> 29:41.540]  прямую или не бесконечно удаленную прямую? Или что? А? Ну, там ломается немного геометрия, то есть там
[29:41.540 --> 29:48.780]  нужен относительный эффект. Ну, можно воспринимать как вот такой флаг, типа, t равное единица это
[29:48.780 --> 29:53.660]  бесконечно удаленная, t равное нулю бесконечно удаленная. Наоборот, t равное единица это не бесконечно
[29:53.660 --> 29:58.220]  удаленная, t равное нулю бесконечно удаленная. Просто там точки будут соотноситься, то есть на
[29:58.220 --> 30:06.380]  бесконечно удаленную прямую точка 0,1,4,0 это будет привязать такая же точка, как 0,2,8,0. Вот и все. То есть это
[30:06.380 --> 30:20.220]  будут равные точки по координатам. Ну, а как бы, а что у нас происходит? Мы изображение снимаем в камере.
[30:20.220 --> 30:27.180]  Дальше нам нужно то, что мы сняли на камеру, образно говоря, отрендерить на экран.
[30:27.180 --> 30:38.180]  Ну, вот. Ну, камера собрала, то есть она снимает какое-то пространство, и дальше нам
[30:38.180 --> 30:41.100]  нужно его спроецировать на плоскость для того, чтобы вывести его на экран.
[30:41.100 --> 30:51.060]  В смысле? Ну, мы же через камеру это все попускаем.
[31:00.620 --> 31:09.620]  Ну да, вот пример. Кубик. Вот они, пучки параллельных прямых.
[31:11.900 --> 31:19.420]  Здесь мы их проецируем на плоскости. Вот мы получаем вот этот кубик. Так-то там прямые параллельные,
[31:19.420 --> 31:29.900]  а здесь они вот не параллельные. Вот, смотрите, поставим сюда сериент по физике. Ставим пульт.
[31:29.900 --> 31:38.500]  Хотим пульт отрендерить на экран. Ну, с небольшим поворотом. Да, что у нас происходит? Мы берем,
[31:38.500 --> 31:44.860]  и вот эти вот лучи, вот у нас тут источник света, вот тот камера, которая стоит, и вот этот источник
[31:44.860 --> 31:52.340]  света у нас проецирует все на экран. Вот, это проективное преобразование, которое выполнит
[31:52.340 --> 32:00.420]  проекцию на доску. Собственно, вот этот луч, пучок параллельных прямых, который проходит,
[32:00.420 --> 32:07.860]  он должен пройти как раз вот с этими параллельными, грамотно обработать параллельные прямые для
[32:07.860 --> 32:13.660]  того, чтобы у нас было записано преобразование. Опять же, я рассказываю это немножко на
[32:13.660 --> 32:20.860]  дилетантском уровне, возможно. Там за деталями нужно идти на курс компьютерной графики. Там про это
[32:20.860 --> 32:45.700]  детали расскажут. Ну да. Сейчас. Вскречу все время хороший вопрос. Надо почитать,
[32:45.700 --> 32:52.340]  что с ними происходит. Возможно, это, как эти прямые называются, которые в одной плоскости лежат?
[32:52.340 --> 33:01.900]  Забыл. А, компланарные, да? Ну, по крайней мере, можно попросить, что любые две компланарные
[33:01.900 --> 33:08.500]  прямые пересекаются. Ну вот, скречу все, это хороший вопрос, кстати, его можно задать даже
[33:08.500 --> 33:19.620]  Google. Там, я думаю, ответить на этот вопрос. А? Так, ладно, смотрите, то есть мы поняли,
[33:19.620 --> 33:25.420]  что у нас преобразование это матрица четыре на четыре. Более того, смотрите, как можно использовать
[33:25.420 --> 33:31.540]  матрицу. Здесь пайплайн преобразования этого всего. То есть мы снимаем объект на камеру,
[33:32.500 --> 33:38.900]  точнее, мы располагаем объект на плоскости в какой-то точке, да? При этом у нас есть какая-то
[33:38.900 --> 33:47.340]  камера, которая находится здесь. Что мы делаем? Мы с вами обращаем объект, после этого мы располагаем
[33:47.340 --> 33:54.540]  камеру на экране, и нам нужно перевести наш кубик из пространства локального в пространство глобальное,
[33:54.540 --> 34:00.380]  в общую систему координат. Это некоторое проективное преобразование, которое записывается матрицей четыре на
[34:00.380 --> 34:07.020]  четыре. Дальше, что у нас происходит? У нас мы должны переключиться в пространство, в начало координат
[34:07.020 --> 34:16.180]  камеры. Это еще одна матрица четыре на четыре. Дальше мы должны сделать проекцию, и это тоже матрица
[34:16.180 --> 34:24.100]  четыре на четыре. Ну и дальше мы делаем кроп нашего изображения, который оставляет нам наш объект.
[34:24.100 --> 34:35.180]  Кажется. Зачем я это рассказываю? Включаем смекалку.
[34:35.180 --> 34:48.900]  Ну да, ну центр камеры, то есть у нас камера направлена вот на меня. Мы переходим в пространство
[34:48.900 --> 34:55.820]  координат камеры, которая сейчас меня снимает. Вот и дальше вот сейчас что-то там показывается.
[34:55.820 --> 35:10.320]  А? Да, для наших целей. Да, перемножение матрицы долго, но видеокарты сделаны так,
[35:10.320 --> 35:18.240]  что эти матрицы быстро перемножаются. То есть у нас с вами была, ну я надеюсь, что была,
[35:18.240 --> 35:27.920]  классификация по флину. Было такое? Это буковки с, и, э, м, д.
[35:38.800 --> 35:40.160]  Так, instruction
[35:40.160 --> 36:02.960]  data. Было? Ой. Так, смотрите. Кто где находится? Вот сразу давайте еще раз уточним. Здесь
[36:02.960 --> 36:09.640]  находится цепу однопоточная. А кто находится в multiple instruction single data?
[36:17.840 --> 36:19.880]  Много инструкций на один источник данных.
[36:19.880 --> 36:40.880]  Ну, я бы так сказал, это Critical Runtime OS. То есть точки, в которых нужно, это операционный
[36:40.880 --> 36:47.640]  системы реального времени, в которых событие должно приходить по расписанию. То есть этих
[36:47.640 --> 36:54.120]  команд может быть много, они должны приходить сюда. Так, что относится к multiple instruction,
[36:54.120 --> 37:07.600]  multiple data? По стеку технологий? А? Нет. А? Да, так, вопрос. Почему дедлайн? В какой домашке у
[37:07.600 --> 37:20.000]  нас дедлайн? Ага, M5 сюда нах... Кадуб сюда идет. Ну и, в общем, все, что происходит здесь. Вопрос,
[37:20.000 --> 37:29.680]  где видеокарта? Угу. Видеокарта находится здесь. Мы можем взять набор треугольничков маленьких и
[37:29.680 --> 37:43.160]  параллельно перемножать их. А? Все, хорошо. А теперь рубрика смекалка. Она заключается в том,
[37:43.160 --> 37:52.720]  как мы это можем использовать в наших целях. Видеокарта умеет быстро перемножать матрицы.
[37:52.720 --> 38:01.800]  Да, если нам нужно перемножить матрицы, давайте выводить пиксели на экраны, ну, грубо говоря,
[38:01.800 --> 38:08.120]  флоты на экраны. Положим огромный болт на то, что у нас будет выводиться на экране, зато матрицы
[38:08.120 --> 38:24.640]  посчитаются. А? Кто поможет перемножить? Ну, есть, просто... Сколько у нас процессоров обычно? Ядер?
[38:24.640 --> 38:40.200]  8, да? Так, кто знает какую-нибудь видеокарту? Хорошо, РТХ 4090, number of course.
[38:40.200 --> 39:03.680]  Мне кажется, я ответил на вопрос. Ага. Да, мы, кстати, будем считать максимальную пропускную
[39:03.680 --> 39:14.760]  способность видеокарты, но это не сегодня. Так, сейчас звонок пойдет. Так, ну, собственно, до этой идеи мы
[39:14.760 --> 39:21.840]  догадались. Давайте ничего не изображать, а использовать матрицы для вычислений. Ну, как говорится,
[39:21.840 --> 39:27.280]  сим для нас есть как раз. Эта одна векторная инструкция выполняется на векторе значений в один
[39:27.280 --> 39:33.880]  такт времени. Когда мы будем смотреть архитектуре видеокарты, мы прямо это увидим. Так, ну, сказано,
[39:33.880 --> 39:39.680]  сделано, как говорится. Появилась специальная обездка, она называлась в свое время Bruck,
[39:39.680 --> 39:47.400]  которая позволяет выполнять векторные операции. Даже если мы с вами опять же перемотаем, есть
[39:47.400 --> 39:59.960]  специальная статья даже. Кстати, вы умеете искать? Да. Давайте даже Сколер Гугл откроем.
[39:59.960 --> 40:07.280]  Это специальный сайт для поиска статей.
[40:07.280 --> 40:17.080]  Сейчас, я надеюсь тут.
[40:23.920 --> 40:25.400]  Что, нас в Гугле забанили?
[40:25.400 --> 40:38.920]  Мы ищем статью оригинальную. Ну, про этот инструмент. Да, нас в Гугле забанили.
[40:38.920 --> 40:46.200]  Вот оно.
[40:46.200 --> 40:57.080]  Bruck for GPU. Ну, и здесь можно почитать, как это все делалось и как выглядит код.
[40:57.080 --> 41:05.080]  Что выдает нам, что это обертка над графической памятью?
[41:05.080 --> 41:23.760]  Смотрите, тип, который используется. Float 4. Да, да, да, как раз. И видите,
[41:23.760 --> 41:28.920]  сколько тогда уже можно было сделать гигафлопсов. Это количество операций в секунду.
[41:28.920 --> 41:42.480]  Ну, кажется, что сейчас 4 ГБ это не очень много, ой, 4 ГГц. Но статья была написана в 2002 году, ну или 2003 году.
[41:42.480 --> 41:56.040]  Да, а тогда процессоры, ну, по-моему, у нас в семье был Intel 3 Pentium, у которого частота была 566 МГц.
[41:56.040 --> 42:05.720]  А тут выдают 4 ГФлопса. Ну, и как бы здесь вот бенчмарки получаются с ИЦПУ,
[42:05.720 --> 42:14.120]  которые выдаются. То есть видите, на каких-то, даже на матричных перемножениях, типа в полтора,
[42:14.120 --> 42:21.360]  в два раза есть ускорение. Ну и что, как вы думаете? Дальше все поперло после этого. Значит,
[42:21.360 --> 42:27.360]  Брук это программируемый интерфейс. И как он выглядел в свое время, это был аналогичный
[42:27.360 --> 42:38.680]  компилятор а-ля MPICC. Все, я надеюсь, с ним уже все познакомились. Ну и, как говорится, закон Мура
[42:38.680 --> 42:45.160]  изменился. Значит, раньше количество схемов транзисторы увеличилось в два раза. Ну, то есть,
[42:45.160 --> 42:53.200]  и это работало до Pentium-ов четвертых, по-моему. То, что частота процессора увеличилась в два раза
[42:53.200 --> 43:02.040]  за 24 месяца. А сейчас частота процессоров меняется или нет? Практически не меняется,
[43:02.040 --> 43:08.920]  все пошли многоядерность. Так вот, для видеокарт закон Мура до сих пор еще выполняется по скорости
[43:08.920 --> 43:16.160]  вычислений. Возможно, что скоро это изменится. Вот в бенчмарке, пожалуйста, количество операций
[43:16.160 --> 43:22.800]  перемножений в секунду, как менялась эта динамика для CPU, для Pentium A4, как это менялось для видеокарты
[43:22.800 --> 43:31.600]  вида ATY и как это менялось для видеокарты NVIDIA в свое время. Кто знает, что такое ATY?
[43:35.600 --> 43:47.720]  Да, который выкупил AMD. Молодцы, историю знаю. Вот, и здесь понятно, что у нас появился фреймворк,
[43:47.720 --> 43:53.440]  который позволяет быстро вычислять все это дело. А компания NVIDIA подсуетилась и решила,
[43:53.440 --> 44:00.960]  а почему бы нам не сделать это все как задачу общего назначения. Давайте сделаем это все как
[44:00.960 --> 44:08.720]  задачу общего назначения. Первая модель данных у нас была в том, что у нас были с вами наборы
[44:08.720 --> 44:16.040]  входных регистров и была фрагментная программа Shader, который вычислял этот цвет для изображения.
[44:16.040 --> 44:22.040]  Еще на него вход подавался. На него подавались на вход текстура, константы и регистры. На выходе
[44:22.040 --> 44:28.120]  мы выдавали некоторые выходные регистры. Ну, как эту модель можно изменить? Давайте скажем,
[44:28.120 --> 44:35.960]  что вообще входные регистры нам не особо важны, нам важны передать элементы массива. И для каждого
[44:35.960 --> 44:42.640]  элемента массива у нас должен быть свой индекс. Сделали. Значит, у нас появился на вход,
[44:42.640 --> 44:52.720]  каждый программе приходит номер потока. Номер потока вам это что-нибудь напоминает? В MPI rank
[44:52.720 --> 45:01.560]  процессор. Здесь такой же механизм, поточная программа. Ну, дальше понимаем, что нам нужно
[45:01.560 --> 45:07.200]  куда-то выводить всю память, поэтому давайте мы вместо выходных регистров напишем здесь
[45:07.200 --> 45:12.520]  глобальную память, то есть создадим память видеокарты, в которой мы будем скидывать массивы. При этом
[45:13.000 --> 45:19.960]  выходные регистры, тут есть обратная совместимость для того, чтобы отрисовывать графику. При этом мы с
[45:19.960 --> 45:24.600]  вами понимаем, что некоторые опции, которые нам нужны, они должны отрисовывать какие-то
[45:24.600 --> 45:29.880]  локальные участки памяти, то есть вычислять локальную операцию, например, сложение соседних
[45:29.880 --> 45:36.520]  элементов или вычисление произвонок. Производно это взять себя, вычесть, как сказать, и следующего
[45:36.520 --> 45:41.640]  момента времени, вычесть текущий момент времени, поделить на время. То есть нам нужно соблюдать
[45:41.640 --> 45:46.400]  свойство локальности, что если мы берем данные из соседнего куска, то они должны браться намного
[45:46.400 --> 45:53.200]  быстрее, чем из текущего. Вот для этого возник механизм разделяемой памяти. Так сказать, не путать
[45:53.200 --> 46:00.680]  с разделяемой памяти в курсе операционных систем. Это немножко другая вещь. Вот, и в итоге вот
[46:00.680 --> 46:06.480]  такая архитектура нам позволила соорудить куда. То есть вот как раз вот в такой парадигме мы с
[46:06.480 --> 46:13.200]  вами будем работать. В нашем курсе, правда, мы не будем рассматривать текстуры. Наша цель все-таки
[46:13.200 --> 46:19.200]  для вычисления это все использовать, но в целом можно загружать текстуру. В итоге у нас появилась
[46:19.200 --> 46:26.960]  куда. Расшифровывается это как Compute Unified Device Architecture. То есть это архитектура процессоров,
[46:26.960 --> 46:37.600]  как сказать, унифицированная архитектура для задач общего назначения. То есть мы говорим
[46:37.600 --> 46:41.680]  следующее, что это архитектура, которая позволяет использовать графические процессоры, как а
[46:41.680 --> 46:53.800]  процессоры общего назначения. Вот первая версия куда вышла в 2007 году. То есть эта технология уже
[46:53.800 --> 47:10.240]  16 лет. Тут можно узнать последняя версия. Ой, извините, это не то. Куда Latest Version.
[47:10.240 --> 47:23.160]  Последняя версия куда 12.2. Вот, 12.2. При этом максимальная версия куда зависит от драйвера
[47:23.160 --> 47:30.400]  видеокарты, который у вас стоит. То есть ставите драйвер видеокарты. Если у вас там драйвер не слишком
[47:30.400 --> 47:38.000]  новый, то новую версию куда вы не поставите. Последняя версия куда 12. Она вышла в 2002 году для
[47:38.000 --> 47:43.920]  поддержки карт а-ля RTX 40 что-то там. Понятно, что у них есть Compute Capability, то есть архитектура
[47:43.920 --> 47:54.600]  пронумерована ID-шниками. Вот, сейчас последний Compute Capability, который есть, это 8.9. То есть тоже
[47:54.600 --> 48:04.680]  можно открыть это все дело, посмотреть. То есть 8.9 это Latest, 8.6 это Ампер. Архитектура Ампер,
[48:04.680 --> 48:13.680]  которая 30.90. Ну и так далее. То есть у них вот это Compute Capability есть разные свойства,
[48:13.680 --> 48:21.360]  которые можно отслеживать. Вот. И в зависимости от этого некоторые алгоритмы, кстати, будут меняться
[48:21.360 --> 48:26.880]  на практике. Реализация алгоритм будет меняться на практике. Сейчас секунду, я достану зарядник,
[48:26.880 --> 48:31.720]  чтобы у нас тут презентация не накрылась. Пока можно вопросы задать какие-нибудь.
[48:31.720 --> 48:46.280]  Хороший вопрос, но на видеокарте нельзя все вычислять. То есть там вычисляются непроизвольные
[48:46.280 --> 48:52.960]  действия, грубо говоря. Вот то, что я сейчас мышкой навел на определенную часть экрана, допустим,
[48:52.960 --> 49:03.760]  сломал проектов. Ну как? Как это не значит, что совсем точно. Она будет эмулировать большую
[49:03.760 --> 49:10.340]  часть операций. То есть вы не поверите, что если использовать CUDA как процессор общего
[49:10.340 --> 49:17.920]  назначения, вот прямо как есть, то скорость будет в 20 раз медленнее, чем на обычной CPU. То есть мы
[49:17.920 --> 49:24.680]  делаем достаточно большое количество маленьких ядер, которые вместе дают кумулятивный эффект,
[49:24.680 --> 49:32.320]  а не один. Процессор дает такой эффект. Вы же не пишете код на конкарнте каждый раз?
[49:32.320 --> 49:43.360]  Ну вы же не пишете код, учитывая то, что у вас куча ядер сразу параллельно будет запускать его?
[49:43.360 --> 49:50.120]  Ну он там не слишком сильно оптимизирует.
[49:50.120 --> 50:03.640]  Ну вот, значит это не дает профита. То есть это специфичные задачи. То есть это векторные
[50:03.640 --> 50:09.040]  преимущественные задачи. Вот вам надо два массива сложить. Вот, пожалуйста, пишите на видеокарте,
[50:09.040 --> 50:15.600]  это будет в разы быстрее. Ну как в разы быстрее? Вам нужно будет еще скопировать, правда, память
[50:15.600 --> 50:23.440]  центрального процессора в память видеокарты. Ну это уже такая тяжелая операция. Так,
[50:23.440 --> 50:28.920]  так, мы выяснили про CUDA. Давайте теперь поговорим про базовое понятие, которое есть в CUDA.
[50:28.920 --> 50:38.240]  То есть у нас есть память. И тут сразу нужно некоторые терминологи вводить, потому что она
[50:38.240 --> 50:51.000]  на самом деле есть в коде. Значит первое понятие это host. Host память это run. Это оперативная память
[50:51.000 --> 51:01.480]  процессора. Она именно называется host память. Два, device memory это память видеокарты.
[51:08.360 --> 51:18.720]  То есть когда вы видите вот такое понятие D to H или device to host, куда мы копируем информацию?
[51:23.280 --> 51:31.880]  Из видеокарты в оперативную память. Host to device либо H to D это у нас рама на видеокарту.
[51:31.880 --> 51:43.080]  Понятно, да? Просто вот вы прямо увидите, что образно говоря есть в коде CUDA memcpy. То есть
[51:43.080 --> 51:46.680]  есть вот такая вот константа, которая говорит, куда именно копировать память.
[51:46.680 --> 51:56.720]  Янам, так сказать. Потоки. Вот с потоками тут вообще интересно. Значит давайте поговорим
[51:56.720 --> 52:02.480]  следующее. Тут на самом деле не точное определение. Я буду немножечко разносить это все дело тоже
[52:02.480 --> 52:15.320]  на слайде. Значит есть логическая абстракция, есть физическая абстракция. Значит первое,
[52:15.320 --> 52:24.000]  что есть это CUDA ядро. Иногда еще называют их CUDA попугаями, потому что не понятно,
[52:24.000 --> 52:31.720]  что это такое. Это одна единичка, которая может вычислять что-то. Что такое поток? Это абстракция,
[52:31.720 --> 52:39.880]  которая лежит логически за вот этой железкой. То есть это одни и те же понятия. Значит дальше
[52:39.880 --> 52:46.800]  с точки зрения физики мы движемся дальше. Возникает такое понятие, как ворб. Вот это самая
[52:46.800 --> 52:51.720]  важная вещь, которую на самом деле нужно понимать, которую нет в классических процессорах.
[52:51.720 --> 53:01.400]  Что такое ворб? Это физическая сущность, которая выполняет несколько потоков как одно целое.
[53:01.400 --> 53:12.840]  То есть что это означает? Это означает, что вы на одну команду, на некоторый набор потоков,
[53:12.840 --> 53:20.800]  которые у вас есть, посылаете одну регистровую команду одновременно. То есть вы посылаете,
[53:20.880 --> 53:27.440]  если вы посылаете команду в ассемблерную команду, в видеокарту, вы посылаете на самом деле ее не
[53:27.440 --> 53:41.920]  одному потоку, а сразу 32. Вот в одном ворпе 32 CUDA-ядра в вытекущих архитектурах. То есть если вы
[53:41.920 --> 53:48.880]  берете пятый элемент массива, то одновременно вы делаете ту же самую операцию на уровне регистров
[53:48.880 --> 54:00.760]  из 10, из 25 и с пятым регистром. Вот, поэтому IF с нависанием на одно на одно ядро, это не очень
[54:00.760 --> 54:07.600]  хорошая затея. Потому что у вас один поток будет выполнять задачу, а остальные 30 его будут ждать.
[54:07.600 --> 54:17.480]  Вот, а они потом приходят в барьерную точку. Значит, стриминг, мультипроцессор, это аналог нашего
[54:17.480 --> 54:27.960]  классического ядра. Вот, это вот такая вот абстракция, которая здесь есть. То есть,
[54:27.960 --> 54:36.440]  по факту, когда у нас говорят 4 ядра, 8 потоков, это по факту такой же аналог, как 4 стриминга
[54:36.440 --> 54:44.120]  мультипроцессора и так далее. Вот. Стриминг мультипроцессора стоит CUDA-ядер, способный
[54:44.120 --> 54:49.120]  выполнять инструкции параллельно. И при этом один стриминг мультипроцессор содержит несколько варпу.
[54:49.120 --> 55:04.000]  Да. Да. Не, это CUDA-ядра называется. А вот это называется стриминг мультипроцессор. То есть,
[55:04.000 --> 55:13.880]  аналог вот этого в CPU это ядро. Просто у нас в ядре может быть несколько поток на CPU.
[55:13.880 --> 55:23.640]  Обычно два. Хайпертренинг это называется. Так, ну что, давайте решим задачу. Да,
[55:23.640 --> 55:33.960]  правда задачу надо уже обновлять, потому что одну GTX 1080 Паша уже сдал. А? Одна, одна еще осталась.
[55:33.960 --> 55:42.240]  Итак, у Паши есть GTX 1080. Он прочитал, что в нем находится 2560 CUDA-ядер. В общем, сидел,
[55:42.240 --> 55:48.600]  разбирался. Он узнал, что в этой видеокарте 20 стриминг мультипроцессоров, а размер варпа
[55:48.600 --> 55:57.520]  равняется 32. Вопрос, который задается в этой задаче. Сколько варпов находится в одном стриминг
[55:57.520 --> 56:10.440]  мультипроцессора? Да. Смотрите, здесь у нас получается 2560. Здесь у нас получается стриминг
[56:10.440 --> 56:23.320]  мультипроцессоров 32. Варпов 32. В варпе получается 32 CUDA-ядра, поэтому у нас получается что?
[56:30.680 --> 56:32.280]  Не, мы получим сколько варпов?
[56:41.440 --> 56:53.160]  Сколько будет 2560 на 32? 80, да. Вот. И оказывается, что в одном SM 4 варпа.
[56:56.160 --> 57:05.480]  И вот это уже на самом деле ограничение. Причем очень жесткое. Представьте себе,
[57:05.560 --> 57:12.560]  что вы готовите какой-нибудь, я не знаю, ужин, либо еще что-то. И вот у вас есть сковородка.
[57:12.560 --> 57:26.000]  На сковороде помещаются четыре котлета. Да. Это видеокарта ограничения, то есть это архитектурно
[57:26.000 --> 57:36.680]  так выглядит. То есть больше оно не переваривает. Сейчас картинка будет просто. Вот такая вот картинка,
[57:36.680 --> 57:45.920]  я не знаю, видно ее или нет. Это один стриминг мультипроцессор. То есть, видите, вот они
[57:45.920 --> 57:51.760]  четыре слота. В каждом из них находится вот такая инструкция под названием ворпшедулер.
[57:51.760 --> 57:59.320]  Собственно, что такое ворпшедулер? Это вот эта вот такая штука, забыл уже, 8 часов вечера.
[57:59.320 --> 58:07.360]  Юнит, давайте назовем так, которая раскидывает задачи на все потоки внутри варпа одновременно.
[58:07.360 --> 58:15.560]  Вот там оранжевая-оранжевая прослойка есть. А вот это вот это кудоядр и кудоядр. При этом сейчас,
[58:15.560 --> 58:21.720]  помимо классических ядер, есть еще и тензорные ядра, которые умеют блюстроматрицу перемножить.
[58:21.720 --> 58:27.960]  Сейчас современные сети, они гоняются на тензорных ядрах, но это появилось только в
[58:27.960 --> 58:35.640]  недавних версиях. При этом здесь есть кудоядра, которая умеет работать с числами с одинарной
[58:35.640 --> 58:42.680]  точностью флотами, а есть те, кто работает с даблами. И запомните, если вы будете работать в даблах,
[58:42.680 --> 58:47.600]  а не в флотах, ваша скорость программы уменьшится не в два раза, а в 64.
[58:47.600 --> 58:59.280]  Флотами. Пользуются только флотами на видеокартах. Ну потому что особенности архитектуры такие.
[58:59.280 --> 59:05.480]  Короче, про даблы забываем.
[59:05.480 --> 59:15.160]  У нас по куде контроля не будет.
[59:15.160 --> 59:23.840]  Да. Как-то я не любитель устраивать контрольные по практически предметам.
[59:23.840 --> 59:30.520]  Вот, ладно. Теперь давайте по физике понятно процессы, что у нас происходит.
[59:30.520 --> 59:36.520]  Теперь по логике. Почему нам важна логика? Потому что в логике программы будем писать.
[59:36.520 --> 59:42.880]  Логическая абстракция. Значит, ворб это набор потоков, которые физически отрабатывают за один так
[59:42.880 --> 59:49.360]  времени. А здесь возникает другая абстракция, которая называется блок. И она состоит из набора
[59:49.360 --> 59:57.640]  потоков. Причем, смотрите, тут именно важно по высоте. То есть ворб, блок обычно бьется на несколько ворпов.
[59:57.640 --> 01:00:06.400]  Логики, да. Но когда логика перекладывается на физику, блок будет
[01:00:06.840 --> 01:00:16.640]  развиваться на наборы ворпов. То есть у нас, грубо говоря, есть массив размера 256, значит его будут выполнять за 8 тактов.
[01:00:16.640 --> 01:00:21.680]  За первый такт обработается первый ворп, за второй такт второй ворп, третий, четвертый и так далее.
[01:00:21.680 --> 01:00:33.920]  То есть у нас в размере блока 256 элементов. У нас вот этот выполнится за один такт времени,
[01:00:33.920 --> 01:00:38.960]  вот этот пойдет на второй такт времени, вот этот пойдет на третий, на четвертый и так далее на восьмой.
[01:00:38.960 --> 01:00:49.120]  Да, тут одна ассемлерная инструкция пришлется на вот эти 32 элемента сразу.
[01:00:49.120 --> 01:01:01.960]  Потому что есть регистры, есть память и там еще модели управления памяти будут. Ну про это мы
[01:01:02.000 --> 01:01:08.440]  в следующий раз уже будем говорить. Там сложные модели управления памятью. Вот,
[01:01:08.440 --> 01:01:15.080]  значит при этом это блок. Блоки делятся на ворпы в физическом исполнении, как мы с вами сказали.
[01:01:15.080 --> 01:01:22.800]  И дальше возникает еще одно понятие. Грит это набор из блоков. И грит находится обычно где-то здесь.
[01:01:22.800 --> 01:01:30.960]  То есть грит состоит из блоков. При этом один из блоков выполняется на одном стриме в мультипроцессоре.
[01:01:30.960 --> 01:01:39.360]  Это чисто логическая абстракция, чтобы самому не распределять задачи по этим всем вещам.
[01:01:39.360 --> 01:01:46.440]  То есть вы даете, грубо говоря, набору плашек, а она самостоятельно будет
[01:01:46.440 --> 01:01:52.760]  распределять их по стриме в мультипроцессор. Ну да, чтобы ручками не занимать это все дело,
[01:01:52.760 --> 01:01:57.600]  и чтобы вы, грубо говоря, сказали, что у вас в процессоре 20 стримов мультипроцессоров,
[01:01:57.600 --> 01:02:02.040]  поэтому объем на 40. Вы переходите на другую архитектуру. У вас там не 20 стримов мультипроцессоров,
[01:02:02.040 --> 01:02:08.600]  а 86. И у вас вся логика ломается. То есть вы планировали свою программу на 20 стримов мультипроцессоров,
[01:02:08.600 --> 01:02:15.480]  а у вас 86. В итоге у вас просто видеокарта будет простаивать по три четверти своих ресурсов.
[01:02:15.480 --> 01:02:21.480]  Да-да, то есть когда мы задаем грит, мы задаем количество блоков, которые мы. Их можно сделать
[01:02:21.480 --> 01:02:25.320]  сильно больше, чем количество стримов мультипроцессоров. И он самостоятельно будет их раскидывать.
[01:02:25.320 --> 01:02:32.160]  Я не знаю, вы смотрели, видимо, вы смотрели примеры с MMP, где, ой, с OpenMP, где был параллел-4?
[01:02:32.160 --> 01:02:39.160]  Где есть опция «Шедуль», и в зависимости от того, какую опцию «Шедуль» вы поставите,
[01:02:39.160 --> 01:02:46.320]  у вас там перфоманс будет сильно скакать. Там можно «Шедул» поставить статик, можно поставить динамик,
[01:02:46.320 --> 01:02:52.520]  поставить гайдят и так далее. Если их попереключать, то там видно, что в максимальном режиме намного
[01:02:52.520 --> 01:03:00.040]  быстрее работать, чем в статике. Потому что статик вы вручную алоцируете задачи. Поэтому вручную
[01:03:00.040 --> 01:03:07.480]  локацию задач не занимаемся. При этом, в логическом исполнении у нас с вами всегда для блока задается
[01:03:07.480 --> 01:03:14.760]  блок IDX, а для грита задается, для потока создается thread IDX. То есть у вас каждый по факту,
[01:03:14.760 --> 01:03:25.440]  вы запускаете программу, следующая вещь, вы запускаете количество блоков, количество потоков,
[01:03:25.440 --> 01:03:32.080]  вы передаете это в параметры. И тогда у вас по факту создается количество юнитов,
[01:03:32.080 --> 01:03:37.920]  которое равняется количеству блоков и количеству потоков. Вот это характеризуется блок IDX,
[01:03:37.920 --> 01:03:42.080]  вот это характеризуется thread IDX.
[01:03:42.080 --> 01:03:54.480]  Нет, мы с физикой не хотим работать, мы хотим просто понимать, что она есть.
[01:03:54.480 --> 01:04:12.160]  Но кудо-ядро это железка, которая вот это все вычисляет. Ну один к одному можно сказать.
[01:04:12.160 --> 01:04:21.640]  Нет, потоков у нас сильно больше. Один к одному это означает, что когда у нас есть кудо-поток,
[01:04:21.640 --> 01:04:26.560]  то он потом в какое-то время попадает на какой-то кудо-ядро и вычисляется.
[01:04:26.560 --> 01:04:32.040]  Да, потоков сильно больше, чем кудо-ядер.
[01:04:32.040 --> 01:04:47.600]  Грит настраивается, это типа у нас есть несколько блоков.
[01:04:47.600 --> 01:04:56.000]  Ну за распределение, то есть у нас каждый блок вычисляется на стриме в мультипроцессоре,
[01:04:56.000 --> 01:05:01.160]  чтобы мы сами не занимались вот этим вот распределением, мы даем вот такую огромную
[01:05:01.160 --> 01:05:15.400]  пачку, говорю, на раскидай сам. Да, количество блоков, количество потоков. Вот,
[01:05:16.400 --> 01:05:29.320]  это вот грит. Грит состоит из наборов блоков. Да, мы по факту считаем, что у нас с вами один грит,
[01:05:29.320 --> 01:05:38.680]  ну это вот все, все наше вот железо, так сказать. И по факту, ну не железо, а вот наше вот огромное
[01:05:38.680 --> 01:05:45.480]  по факту сетка для вычислений. Да, и мы говорим, что в этой сетке у нас будет по факту сколько-то блоков,
[01:05:45.480 --> 01:05:57.800]  то есть вот это у нас блокс, а вот это у нас третс. И каждый квадратик здесь будет отвечать за определенное
[01:05:57.800 --> 01:06:09.680]  вычисление. Да, да, то есть у нас возникнет ID-шник вот здесь вот для вот этого элемента,
[01:06:09.680 --> 01:06:19.920]  который мы можем использовать в программе. Ну, на разных стримах и процессорах, конечно же.
[01:06:19.920 --> 01:06:35.520]  Нет, это вот, это вот весь этот квадрат. Нет, вот количество блоков здесь много.
[01:06:40.520 --> 01:06:49.520]  Нет, вот это вот все, вот это вот это грит все. Грит состоит из набора блоков, то есть блок это вот этот вот,
[01:06:49.520 --> 01:06:58.360]  вот этот вот прямоугольчик. Вот это блок. Так, здесь перечеркнули один блок. Так, моя любимая.
[01:06:58.360 --> 01:07:07.720]  Собственно, давайте на примере огорода разберемся, как вот это вот все связано с огородом.
[01:07:07.720 --> 01:07:27.200]  Да. Да. Да, Винга. Да, да, да. Так, вопрос. Что здесь стримит в мультипроцессор?
[01:07:27.200 --> 01:07:36.680]  Блин, да вы, да вы гений, я скажу. На ростении от рэд, ряд в грядке, плюс-минус, можно считать за форб,
[01:07:36.680 --> 01:07:43.820]  потому что мы будем проливать их. Ну, если кто поливал, там типа, линейно происходит. Грядка это блок,
[01:07:43.820 --> 01:07:52.560]  ряд из грядок. Ну, собственно, весь огород наш, это грит. Так, кто играет тролля Сэма и ворпшедулера?
[01:07:52.560 --> 01:08:05.520]  Ну, собственно, вот он вам стримит мультипроцессор. Ассинизатор. Вот, отлично. Да, некоторое характерное
[01:08:05.520 --> 01:08:10.640]  число стримит мультипроцессоров на видеокарте и максимальную мощность вычислений,
[01:08:10.640 --> 01:08:26.120]  которое можно достичь на них. Много, но. Ну, 10-12 операции в секунду. Да, с плавающими точками флота.
[01:08:26.120 --> 01:08:46.000]  Лотинг операции в секунду. Ну что, 10-14. Можно выжать. Стримит мультипроцессор и блоки. Один блок
[01:08:46.000 --> 01:08:50.520]  выполняется на одном стриминг мультипроцессоре. То есть, стриминг мультипроцессор на вход берет блок
[01:08:50.520 --> 01:09:06.160]  и вычисляет на нем все. Ну, пожалуйста, мы вычисляем их параллельно. Вот у нас есть 86 стримок мультипроцессора,
[01:09:06.160 --> 01:09:14.640]  мы можем выполнять 82 блока одновременно. Ну да, пока ждут. То есть, они по факту в очередь кладутся на
[01:09:14.640 --> 01:09:29.920]  исполнение. Ну да, потоки запакованы в блоке. То есть, у нас блок идет в очередь, в которой у нас есть стриминг
[01:09:29.920 --> 01:09:38.480]  мультипроцессора. Ну, типа вот задачу. Сборку на CMake вспоминаю. Что у нас там? У нас есть очередь
[01:09:39.160 --> 01:09:47.760]  компиляции линковки файлов. У нас есть с вами четыре блоковые исполнения. Мы выполняем по четыре. Возможно,
[01:09:47.760 --> 01:09:54.600]  у кого есть понятие threadpool. Знакомое такое? Ну, по факту у вас есть аналог threadpool, в котором
[01:09:54.600 --> 01:10:05.120]  есть 82 по факту воркера. Каждый воркер умеет обрабатывать один блок. Вот. Так, последнее,
[01:10:05.120 --> 01:10:13.680]  значит, что я хочу сказать? Есть ли аналог CUDA в аналоге а-ля OpenGL? Есть. OpenCL,
[01:10:13.680 --> 01:10:22.880]  Open Compute Language называется. Он работает на мобилках, на CPU, на AMD-шных видеокартах. CUDA – это
[01:10:22.880 --> 01:10:29.760]  все-таки анвидиевская технология. Ну и напоследок я оставлю этот слайд. И если кому будет интересно,
[01:10:29.760 --> 01:10:41.720]  вот аналогия всех соответствий, которые здесь есть. Это память видеокарты вся. Вы массивки
[01:10:41.720 --> 01:10:49.760]  даете в видеокарту? Вот он. А shared мы будем говорить. Это кусок, который, это на самом деле память,
[01:10:49.760 --> 01:10:59.320]  которая видна внутри одного блока. Про это мы тоже будем говорить. Да, есть такое.
[01:10:59.760 --> 01:11:06.680]  Ну мы про это в следующий раз уже будем говорить. На этом все. Давайте вопросы, наверное.
[01:11:19.040 --> 01:11:29.240]  Потому что у нас есть ворпы, у нас есть локальность данных, которые необходимо учитывать. Тут я, наверное,
[01:11:29.240 --> 01:11:35.720]  скажу, что нужно, когда мы будем говорить в следующий раз про shared memory, давайте детальнее
[01:11:35.720 --> 01:11:41.560]  как раз остановимся на этот момент и посмотрим на самом деле, как, зачем вот эта вот вся абстракция
[01:11:41.560 --> 01:11:47.440]  нужна. Потому что сейчас я не смогу в двух словах ответить. Но образно говоря, от модели данных просто
[01:11:47.440 --> 01:12:07.240]  все будет зависеть. Вулкан – это ниже уровня OpenGL. Это низкоуровневый аналог OpenGL. Metal – это,
[01:12:07.240 --> 01:12:14.040]  по факту, отдельный framework, параллельно с кудой, которая позволяет вычислять на iOS
[01:12:14.040 --> 01:12:22.080]  устройствах. То есть это, по факту, та же самая вещь, только вот оптимизированная под iOS. Ну или
[01:12:22.080 --> 01:12:27.520]  Abacost и так далее. То есть вот эти, вот у них там своя архитектура processing unit в ГРЭ.
[01:12:27.520 --> 01:12:38.440]  Ну, наверное, да, если вы почитаете код библиотеки TensorFlow Lite, то вы увидите прекрасно, что,
[01:12:38.440 --> 01:12:45.480]  собственно, там есть огромный EFIG, точнее, огромный набор Define, который определяет,
[01:12:45.480 --> 01:12:59.440]  что вы делаете. OpenCL, OpenGL и так далее. Да, конечно же, все то же самое, только название второе. То
[01:12:59.440 --> 01:13:12.120]  есть это второй столбец, по факту. Ну что? Ну тогда все, наверное, это. Спасибо большое.
[01:13:12.120 --> 01:13:14.360]  Вроде бы все разобрали. Все отлично.
