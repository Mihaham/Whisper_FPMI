[00:00.000 --> 00:15.200]  тогда мы, наверное, начинаем. Давайте начнем с текущих задач, с того положения в курсе,
[00:15.200 --> 00:19.920]  где мы оказались. Я сначала, пока мы не разошлись, там, к концу третьей пары,
[00:19.920 --> 00:28.640]  прорекламирую важное. Вот у нас сейчас май, и где-то в конце мая наша лекция закончится,
[00:28.640 --> 00:32.320]  наша встреча закончится, поэтому мне хочется, чтобы у вас останется еще некоторое время,
[00:32.320 --> 00:38.800]  чтобы задачу дорешать. Но мне кажется, что было бы разумно, если бы за май мы от меня получили
[00:38.800 --> 00:42.800]  максимальную пользу, извлекли которую только возможную. А для этого нам нужно успеть что-то
[00:42.800 --> 00:48.440]  решить и обсудить. Ну, скажем, я вот сегодня лекцию читаю одну, а не другую, потому что мне хочется,
[00:48.440 --> 00:55.240]  чтобы мы дорешали, скажем, мы прорешали задачу про канал. Ну и вообще, вот данный момент курса у
[00:55.240 --> 01:00.240]  нас есть. Ну, ради вот этого месяца и ради текущих задач, в общем-то, курс затевался,
[01:00.240 --> 01:06.040]  потому что это была некоторая подготовительная работа. А сейчас у нас есть три, ну, четыре большие
[01:06.040 --> 01:22.160]  задачи. Это планировщик, это канал для файберов и селект, это фьючи и это картина. И я хочу,
[01:22.160 --> 01:29.960]  чтобы мы как-то синхронизировали свое понимание и важность этого момента. Но вот есть еще какие-то
[01:29.960 --> 01:35.080]  другие задачи, какие-то там про лог-фри, что-то, но это быловство на самом деле. На самом деле у нас
[01:35.080 --> 01:40.760]  есть три больших инструмента, которые мы хотим изучить. Три задачи, которые на самом деле означают
[01:40.760 --> 01:48.000]  три очень разных подхода к конкарнси. Как выведет ГО, как выведет в функциональные языки, скажем,
[01:48.000 --> 01:58.400]  скала и как его видит C++. Это, соответственно, канал, фьючи и картина. И, ну, разумеется,
[01:58.400 --> 02:01.720]  для того, чтобы получить какую-то хорошую оценку, вам не нужно решать все. Но с другой стороны,
[02:01.720 --> 02:06.360]  чтобы пользу извлечь, а не оценку получить, что в конце концов имеет значение единственное,
[02:06.360 --> 02:11.040]  разумно попробовать все подходы, разумно разобраться, как они работают, причем как они
[02:11.040 --> 02:18.800]  выстроены изнутри. Ну вот, скажем, задача про фьючи мне представляется, наверное, в данный момент
[02:18.800 --> 02:26.880]  самой важной, потому что это то, что мы меньше всего еще и спробовали. Это декларативный подход,
[02:26.880 --> 02:32.680]  когда мы работаем с асинхронными операциями не в императивном стиле, когда мы там запускаем,
[02:32.680 --> 02:39.600]  что-то думаем про то, какие интерливинги случаются, как потоки синхронизируются. Вместо этого мы
[02:39.600 --> 02:45.240]  думаем про асинхронные операции, как представляем асинхронные операции в виде некоторых объектов,
[02:45.240 --> 02:51.040]  а дальше комбинируем их с помощью специальных функций комбинаторов, которые позволяют выстраивать
[02:51.040 --> 02:56.480]  цепочки, обрабатывать ошибки, параллельно композировать вычисления с помощью all of our
[02:56.480 --> 03:01.120]  stuff комбинаторов. Но про них сегодня мы как-то будем говорить. Ну и все это вписывается в некоторую
[03:01.120 --> 03:09.800]  общую концепцию функциональных явлений, разных там функторов и монат. Мне кажется, это очень
[03:09.800 --> 03:14.320]  полезно изучить, тем более, что это все не то, чтобы какой-то совершенно параллельный мир. Нет,
[03:14.320 --> 03:22.840]  это мир, который прекрасно сочетается с обычными файберами. Ну и вот в частности в следующем
[03:22.840 --> 03:30.680]  семестре, когда мы будем говорить про распределенные системы, то мы с вами будем постоянно пользоваться
[03:30.680 --> 03:36.960]  фьючами, потому что мы будем постоянно пользоваться RPC, потом как-то комбинировать их ответы от RPC
[03:36.960 --> 03:44.960]  вызовов. Ну в общем, это то, что нужно, это то, что нам будет полезно осенью, и я предлагаю не пропускать
[03:44.960 --> 03:50.000]  это. То есть формально можно решать другие задачи, набрать там полный балл, но мне кажется, что мне
[03:50.000 --> 03:55.440]  представляется, что функциональная композиция, она очень важна для понимания конкуренции. Это
[03:55.440 --> 04:00.360]  подход, который говорит вам, что в общем не нужно думать про то, как консинхронизируется в конце концов.
[04:00.360 --> 04:06.080]  Вот когда вы напишите фьюч, вы увидите, что никаких промесов там в коде нет, некой синхронизации явной
[04:06.080 --> 04:16.240]  в коде нет, просто комбинаторы и графы. Вот это довольно любопытный подход, как сместить фокус
[04:16.240 --> 04:22.080]  своего внимания полностью, вот с контрол флоу, с интерливингов, на просто описание того, что мы
[04:22.080 --> 04:26.400]  хотим сделать. А потом с другой стороны, как это изнутри сделать так, чтобы это работало максимально
[04:26.400 --> 04:32.640]  эффективно. Вот, ну про то, как это выглядит, вы почувствуете уже, читая условия, про то,
[04:32.640 --> 04:37.280]  как это устроено внутри, как это можно делать максимально эффективно, это как раз то, что мне
[04:37.280 --> 04:44.480]  с вами хотелось бы обсудить. Потому что, кажется, я сам научился фьюч делать очень хорошими. Вот,
[04:44.480 --> 04:54.360]  и хотел бы поговорить с кем-то об этом. Дальше, карутины. Это тоже чертовски важная задача,
[04:54.360 --> 05:02.080]  потому что вот так видится автором C++ наше светло-синхронное будущее. И это будущее,
[05:02.080 --> 05:07.280]  оно как-то не очень безоблачно, честно говоря, потому что, с одной стороны, инструмент максимально
[05:07.280 --> 05:14.600]  эффективен, а с другой стороны, в нем есть некоторые то ли изъяны, то ли какие-то такие
[05:14.600 --> 05:20.560]  фундаментальные ограничения, особенности, не знаю, как назвать. У меня вообще по плану на следующем
[05:20.560 --> 05:27.840]  занятии устроить такую лекцию про критику дизайна карутины. То есть, что с ними не так,
[05:27.840 --> 05:33.960]  или что можно было бы сделать по-другому, или что в них неудобно. Вот, если вы напишете
[05:33.960 --> 05:40.880]  lock-free mutex в файберах, что мы сегодня, кстати, делаем на последней паре на семинаре, а потом
[05:40.880 --> 05:46.800]  попытаетесь его перенести, хороший lock-free mutex, а потом попытаетесь его перенести в карутины,
[05:46.800 --> 05:52.760]  или просто напишете lock-free mutex группу для карутин, то вы, в общем, увидите, что там есть
[05:52.760 --> 06:00.840]  некоторое довольно большое неудобство. Ну ладно, не буду навязывать в свою точку зрения не то,
[06:00.840 --> 06:05.880]  что неудобство, но вы столкнетесь с некоторым нюансом, и опять, вот про него хочется поговорить,
[06:05.880 --> 06:10.320]  а чтобы о нем говорить, нужна мотивация ваша, в первую очередь, чтобы это вам было нужно,
[06:10.320 --> 06:16.080]  чтобы вы видели этот нюанс сами. Ну и вообще, все наши файберы и все вот эти авейторы, которые
[06:16.280 --> 06:22.400]  мастерим, и вся эта история про то, что фьютекс не нужен, а нужна вейт-группа, ой, вейт-группа тоже не
[06:22.400 --> 06:30.120]  нужна, нужен suspend. Это же как раз вот просто такая длинная дорожка к дизайну карутин. Вот в
[06:30.120 --> 06:34.960]  карутинах никакого фьютекса обычного и не напишешь, в принципе. Там есть только suspend, то есть только
[06:34.960 --> 06:42.760]  avatars, co-avatars, avatars и avatars suspend, и в любой операции, которая останавливает карутину, карутина
[06:42.760 --> 06:46.840]  останавливается строго один раз, ну, точнее, не более одного раза. Вот вы не можете циклу с
[06:46.840 --> 06:53.840]  ожиданиями писать. Это про то, что фьютекс не нужен, фьютекс фундаментально ограничен и бесполезен,
[06:53.840 --> 06:59.480]  гораздо лучше иметь другой IP. Ну и вот вся эта цепочка задач про файберы, она в том числе про
[06:59.480 --> 07:04.080]  то, чтобы лучше почувствовать дизайн карутина, поэтому, опять же, чтобы вся наша работа не
[07:04.080 --> 07:10.560]  прошла напрасно, нужно эту задачу тоже сделать. Ну и давайте я рекламирую еще канал, потому что
[07:10.560 --> 07:19.360]  это моя любимая задача, потому что, реализовав канал и реализовав Select, можно почувствовать,
[07:19.360 --> 07:28.760]  как, что, во-первых, в фьюче, ну, что вот комбинаторы всякие декларативные в фьючах, всякие эти
[07:28.760 --> 07:38.200]  all-in-firsts, вот Select это аналогия некоторая, такая императивная для всего этого. Select это
[07:38.200 --> 07:44.200]  инструмент, с помощью которого Go решает задачу комбинирования параллельного. На Select в Go
[07:44.200 --> 07:50.600]  построено огромное количество идиом, такой, ну, каналы плюс Select. Буквально из всего этого
[07:50.600 --> 07:56.520]  все остальное строится, вообще все строится. И это же чертовски клевый дизайн, чертовски
[07:56.520 --> 08:02.760]  согласованный дизайн, очень точный, продуманный. Вы берете, не знаю, какую-нибудь джаву, в которой
[08:02.760 --> 08:07.640]  очень большое историческое наследие, читайте, библиотеку там, утиль кон карант. И там просто вот
[08:07.640 --> 08:13.400]  огромное количество, ну, не то, что барахла, но вот очень неточных, очень неаккуратных интерфейсов,
[08:13.400 --> 08:19.480]  которые просто исторически как-то эволюционировали, мутировали, и в итоге вот вышло что-то. Go — чертовски
[08:19.480 --> 08:26.480]  продуманный язык в этом смысле, в нем все, вот все идиомы, как бы все сценарии покрываются. Ну,
[08:26.480 --> 08:30.360]  неудивительно, собственно, Google писала его на основе своего опыта, как писать распределенные
[08:30.360 --> 08:37.120]  системы, как сделать язык для того, чтобы потом их писать. И вот все паттерны, все какие-то сценарии,
[08:37.120 --> 08:43.640]  которые нужно в них выражать в распределенных алгоритмах, в Go поддержаны с помощью очень маленького,
[08:43.640 --> 08:48.960]  очень компактного, очень эртагонального набора инструментов. Вот решая эту задачу, можно об этом
[08:48.960 --> 08:58.680]  подумать и вот связать это все тоже в какое-то понимание. Плюс, что мне особенно ценно, вот только
[08:58.680 --> 09:05.720]  написав каналы и селекты, можно по-настоящему профилировать планировщик, который мы пишем сейчас.
[09:05.720 --> 09:11.120]  Надеюсь, что вы пишете его. То есть, решив эту задачу, можно будет уже какие-то нетривиальные
[09:11.120 --> 09:15.800]  ворклоды делать, там действительно лифо будет играть, там действительно какие-то более сложные
[09:15.800 --> 09:20.720]  сценарии возникают, чем Mutex, потому что Mutex можно заоптимизировать вообще без планировщика. То есть,
[09:20.720 --> 09:23.720]  можно написать Mutex так, что он будет работать очень быстро, потому что планировщик там вообще
[09:23.720 --> 09:28.800]  не участвовать не будет. Ну это такой некоторый обман, но все же, так можно сделать. А вот с
[09:28.800 --> 09:33.080]  каналами и селектами, там действительно будет взаимодействие с планировщиком более интенсивно,
[09:33.080 --> 09:41.560]  и вот только так можно все это померить. Короче, лучше сделать все, вот тогда вот полностью весь
[09:41.560 --> 09:47.560]  замысел курса раскроется. Так что, пожалуйста, призываю вас попытаться, по крайней мере,
[09:47.560 --> 09:53.000]  ну и вот желательно в течение майя нам побольше успеть, чтобы была возможность это обсудить.
[09:53.000 --> 09:56.880]  Ну и вообще задачка клевая. У нас вообще-то следующая лекция по плану это про то,
[09:56.880 --> 10:07.320]  как сделать хороший супер лог-фри канал и селект. Его так написали в код-лине. Возможно,
[10:07.320 --> 10:12.280]  не даже переборщили, то есть даже не стоило так сильно стараться. Но тем не менее, это очень,
[10:12.280 --> 10:17.600]  там очень нетривиальные вещи, там какой-то хитрый лог-фри. Вот я через неделю про него расскажу.
[10:17.600 --> 10:30.840]  Итак, надеюсь, реклама удалась. Сегодня наша тема — это, наконец, новая для курса тема — это
[10:30.840 --> 10:41.240]  structured concurrency и cancellation и обработка ошибок. Как жить с отменой синхронных операций. И вот
[10:41.240 --> 10:48.560]  эта лекция, это занятие сегодня, оно будет в каком-то смысле рекламой осеннего курса про
[10:48.560 --> 10:52.520]  определенным системам, потому что я буду рассказывать про то решение, которое в голове у меня
[10:52.520 --> 10:58.920]  сложилось, которое, мне кажется, ну если я нигде не ошибся, мне кажется, очень согласованным,
[10:58.920 --> 11:04.640]  очень встроенным и которое мы должны осенью использовать. Ну вообще все, что мы пишем,
[11:04.640 --> 11:11.960]  мы будем осенью использовать. Ну, в частности, отмену. И это особенно важно привязывать к
[11:11.960 --> 11:14.840]  распределенным системам, потому что в распределенных системах просто без этого
[11:14.840 --> 11:21.600]  жить невозможно. Ну и давайте мы, собственно, перейдем к нашей сегодняшней теме про cancellation
[11:21.600 --> 11:37.240]  и про обработку ошибок. Отлично. Итак, представьте себе, что мы пишем распределенную систему.
[11:37.240 --> 11:42.720]  Распределенная система — это, ну давайте считать, что это набор каких-то сервисов,
[11:42.720 --> 11:47.400]  которые живут потенциально на разных машинах, и вот есть некоторый клиент снаружи, который с
[11:47.400 --> 11:53.280]  этой системой общается. Вся коммуникация, давайте считать, что она устроена через RPC. Мы посылаем
[11:53.280 --> 11:58.440]  запрос, мы ожидаем ответ. Работаем в модели клиент-север, но осенью это еще раз подробно
[11:58.440 --> 12:04.240]  обсудим. Вы, конечно, что-то знаете уже, но еще поговорим. Но детали нам пока не важны. Мы вот
[12:04.240 --> 12:09.320]  просто представляем себе, что клиент посылает запрос на какой-то сервис. В этом сервисе запускается
[12:09.320 --> 12:13.800]  какой-то обработчик этого запроса. Ну, можно тут нафантазировать себе разные представления этого
[12:13.800 --> 12:18.240]  обработчика. Это может быть коррутина, это может быть какие-то там pipelines-fuge, это может быть
[12:18.240 --> 12:22.320]  файбер, который запустился там что-то делать. Ну короче, какой-то конкарнс начинает шевелиться,
[12:22.320 --> 12:29.920]  и возможно при обработке этого запроса нужно будет в свою очередь отправить запросы в какие-то
[12:29.920 --> 12:36.320]  другие сервисы. Вот у нас получается такая логическая развилка. У нас там был один файбер, а потом он
[12:36.320 --> 12:43.080]  сделал, не знаю, два RPC-запроса в разные стороны. И запустил два других файбера. И вот полетели
[12:43.080 --> 12:52.000]  запросы сюда. Ну и в итоге выстраивается такое дерево запросов. И нас интересуют сегодня две вещи.
[12:52.000 --> 13:01.680]  Что будет, если где-то в этом конвейере, чтобы уже не конвейере, в этом дереве обработки запроса
[13:01.680 --> 13:09.800]  клиентского, возникла ошибка. И что, если где-то в этом дереве какой-то сервис просто недоступен,
[13:09.800 --> 13:15.960]  потому что там машина, на которой он запущен, отказала. Ну тут, конечно, вы скажете, что у нас
[13:15.960 --> 13:21.200]  есть балансировщик нагрузки. Если одна машина отказала, то возьмем другую машину. Но представьте
[13:21.200 --> 13:25.160]  себе, если вы что-то знаете про определенную систему, что в этом какие-то кворы мы собираете,
[13:25.160 --> 13:29.640]  отправляете три запроса, вам нужно получить два любых ответа. Вот какая-то машина может быть
[13:29.640 --> 13:35.320]  недоступна, а запрос мы туда отправили. А что такое запрос? Ну опять же, вот я буду показывать осенью,
[13:35.320 --> 13:40.720]  но можно себе представить, наверное, что машина, которая отправляет запрос, заводит у себя в памяти
[13:40.720 --> 13:47.000]  какую-то структуру, которая материализует этот запрос. И там, не знаю, ретроит что-то,
[13:47.000 --> 13:54.920]  ждет чего-то. Короче, память какую-то тратит, по крайней мере. В общем, на каждый запрос отводятся
[13:54.920 --> 14:01.640]  какие-то ресурсы. И если вдруг мы дождемся двух ответов из трех, а третий просто забудем,
[14:01.640 --> 14:06.360]  а он будет там где-то бесконечно ретроит, то это довольно печальная история. Не то, что он не
[14:06.360 --> 14:11.080]  завершится, ну и бог с ним. Машина отказала навсегда. Но он просто ресурсы отъедает,
[14:11.080 --> 14:19.920]  он время отъедает, он память отъедает, а запросы мы обрабатываем постоянно 24 на 7. Ну или мы задаем
[14:19.920 --> 14:26.760]  HTTP запрос просто. Давайте вот совсем к простому примеру перейдем. Мы говорим request get. Вы знаете,
[14:26.760 --> 14:34.120]  нам реквест. Такая самая известная библиотека для того, чтобы эти запросы задавать. Вот HTTP для
[14:34.120 --> 14:41.720]  людей, кто-то написано. И смотрите, ну вот в продакшн коде, конечно, такого никогда не будет
[14:41.720 --> 14:56.080]  вот такой строчки. Почему? Потому что нет гарантии, что такой запрос вообще завершится. Поэтому давайте
[14:56.080 --> 15:09.560]  мы разные ссылки откроем. Поэтому в самом реквесте написано, что невозможно ставить запросы без
[15:09.560 --> 15:18.400]  тайм-аутов. И просто во всем, в любом промышленном коде, в любом коде, который обрабатывает запрос
[15:18.400 --> 15:23.240]  пользователей в продакшн, должны быть установлены тайм-ауты, потому что запрос может не завершиться
[15:23.240 --> 15:34.400]  никогда. Ну или сколь угодно долго не завершаться и отъедать ресурс. Поэтому фокус установлю. Мы сейчас,
[15:34.400 --> 15:39.240]  в первую очередь, говорим не про обработку ошибок, которые где-то возникают. У нас два топика. Есть
[15:39.240 --> 15:47.520]  обработка ошибок и отмена. Вот мы хотим, чтобы операции наши не длились бесконечно. Мы хотим
[15:47.520 --> 15:54.160]  их отменять. Ну и вот самый простой повод отмены операций, отмены вот этих всех вот запросов в
[15:54.160 --> 16:03.280]  учислении, там обработки операции пользователя, это просто тайм-аут на стороне клиента. Вот вы,
[16:03.280 --> 16:10.720]  наверное, подозреваете, что если вы приходите в систему с своим запросом, то система не должна
[16:10.720 --> 16:16.960]  эти запросы складывать просто в какую-то очередь, а потом обрабатывать. Вот если она делает прямо так,
[16:16.960 --> 16:27.360]  то, а я не знаю, вот быстро мы найдем подходящую ссылку. Но про это мы тоже обязательно осенью
[16:27.360 --> 16:39.440]  поговорим, если... Вот, да, отличный доклад про то, что нельзя обрабатывать все запросы.
[16:46.960 --> 16:59.440]  Нам нужен какой-то впечатляющий график. Нельзя обрабатывать все запросы, потому что в какой-то
[16:59.440 --> 17:04.760]  момент, если просто складывать в очередь и потом процессить, то при перегрузке системы... Ну,
[17:04.760 --> 17:10.080]  система может быть перегружена просто потому, что пользователи пришли. Ну, потому что все наши
[17:10.080 --> 17:15.840]  конкурентные активности — это пользователи их запроса. Если все обрабатывать, то в конечном итоге
[17:16.600 --> 17:21.120]  время обработки улетит в бесконечность. Поэтому мы должны где-то привести горизонтальную черту и
[17:21.120 --> 17:25.520]  сказать, что вот просто есть тайм-аут, и после тайм-аута мы запрос отвергаем, и клиент должен
[17:25.520 --> 17:30.720]  прийти попозже. Это очень... Это необходимо делать в любой продакшн-системе. Опять эта тема следующего
[17:30.720 --> 17:38.080]  курса. Но пока вот просто представим себе, что у нас есть у пользователя тайм-аут, и после
[17:38.080 --> 17:45.880]  пересечения этого тайм-аута мы должны операцию всю... Весь граф как-то отменить. Ну, вот мы говорим
[17:45.880 --> 17:54.040]  про тайм-ауты теперь и сталкиваемся с тайм-аутами вот в таком вот виде. Довольно пока разумный опи.
[17:54.040 --> 17:59.640]  Передаем тайм-аут вот в секундах, видите? Но смотрите, тут даже вот к такому опи уже есть довольно
[17:59.640 --> 18:07.280]  смешной комментарий, на мой взгляд, что тайм-аут, здесь параметр, это... У него семантика довольно
[18:07.280 --> 18:14.960]  странная, потому что это не тайм-аут на весь запрос. Это тайм-аут, который передается в сокет при
[18:14.960 --> 18:22.760]  ожидании начтений. Ну, то есть этот запрос может выполняться сколь угодно долго. Просто если вот
[18:22.760 --> 18:28.040]  каждую там одну миллисекунду приходит очередной байт, то чтение продолжается. И все это может
[18:28.040 --> 18:35.040]  тянуться годы, но вот, тем не менее, этот тайм-аут у него такая странная семантика. Очень сложно ее...
[18:35.720 --> 18:43.560]  Сложно о таком коде думать. Сложно думать, какие гарантии он дает. Поэтому как правильно поступить?
[18:43.560 --> 18:52.160]  Вот что сделать вместо тайм-аутов? Может быть, есть инструмент получше? Да, вот другой пример,
[18:52.160 --> 18:58.480]  почему тайм-ауты могут быть не самые удачные идеи. Вот вы делаете... Вы получаете запрос от
[18:58.480 --> 19:03.400]  пользователя, и вам, чтобы его обработать, нужно задать запросы последовательно у два других
[19:03.400 --> 19:09.000]  сервиса. В сервис A и в сервис B. И у вас есть глобальный ваш тайм-аут, временной бюджет на
[19:09.000 --> 19:19.240]  обслуживание всего запроса пользователя. Там 500 миллисекунд. И вот вы эти 500 миллисекунд
[19:19.240 --> 19:26.880]  отправили, ограничили им запрос в сервис A. А что делать с сервисом B потом? Ну, видимо,
[19:26.880 --> 19:32.120]  нужно как-то перевычислить тайм-аут, потому что вы какую-то часть его и стратили уже при запросе в
[19:32.120 --> 19:39.520]  сервис A, когда вы синхронно дожидались от него ответа. Ну, не то чтобы это было невозможно делать,
[19:39.520 --> 19:46.600]  но это просто неудобно делать. Если у вас вот есть такой сложный граф, где есть какие-то шаги
[19:46.600 --> 19:51.880]  последовательные, где вы чего-то дожидаетесь, потом делаете следующий ход, то в этом случае вам
[19:51.880 --> 19:58.560]  нужно постоянно пересчитывать тайм-ауты, потому что тайм-аут, он всегда относительно нау. И вот
[19:58.560 --> 20:06.000]  для каждого запроса нау разный. Время старта разный. Поэтому вот такой опи с тайм-аутами это...
[20:06.000 --> 20:10.560]  Ну, тайм-аут в каком-то виде должны быть, но может быть они должны быть не в виде тайм-аутов.
[20:10.560 --> 20:14.840]  Для ограничения времени должны быть, но, возможно, не в виде тайм-аутов. Может быть,
[20:14.840 --> 20:24.640]  нужно придумать какой-то другой опи. Что бы вы предложили? Можно дедлайн ставить. Вот.
[20:24.640 --> 20:31.520]  Гораздо лучше представить тайм-аут дедлайнами. То есть у нас есть ограниченный бюджет времени.
[20:31.520 --> 20:36.800]  Он отчитывается от момента, когда пользователь пришел в нашу систему, перестег эту границу,
[20:36.800 --> 20:43.160]  попал вот сюда. Ну, вот давайте мы возьмем нау вот здесь, прибавим к нему бюджет времени,
[20:43.160 --> 20:49.480]  который, допустим, мог сам клиент сообщить. Ну, или мы за него решили. И вот полученный дедлайн мы
[20:49.480 --> 20:55.960]  будем пропагетить дальше. Вот если мы задаем два запроса, то дедлайн для них не меняется.
[20:55.960 --> 21:03.520]  Просто так код композируется лучше. Вот. Это первое, что нужно заметить. Что дедлайны,
[21:03.520 --> 21:11.880]  кажется, лучше тайм-аутов. Но, опять, есть некоторый нюанс. Вот. Кажется, что дедлайны довольно
[21:11.880 --> 21:18.480]  тяжело передавать между машинами. Потому что, как мы осенью опять поговорим, есть задача
[21:18.480 --> 21:25.320]  синхронизации часов, и она довольно скверно решается. И часы, в общем случае, но, наверное,
[21:25.320 --> 21:29.400]  можно считать на практике, что они довольно близки друг к другу, довольно аккуратно синхронизированы.
[21:29.400 --> 21:34.240]  Но, все же, формальной гарантии нет. И, как мы увидим, их формальной гарантии быть не может.
[21:34.240 --> 21:42.000]  Есть некоторые нижние границы, лучше которых нельзя. Поэтому, если вы передаете дедлайн,
[21:42.000 --> 21:48.000]  то формально вы поступаете не совсем корректно. Потому что дедлайн проверяется относительно
[21:48.000 --> 21:56.280]  других локальных часов, других локальных wall-time часов. Они могут быть немного смещены
[21:56.280 --> 22:02.800]  относительно друг друга на разных машинах. Поэтому, может быть, на границах нужно делать все-таки
[22:02.800 --> 22:06.720]  тайм-ауты между машинами, а не дедлайны. То есть пересчитать все обратно в тайм-ауты,
[22:06.720 --> 22:10.600]  потом дедлайны. И, может быть, немножко пессимизировать. Но это не страшно. То есть,
[22:10.600 --> 22:15.040]  можно делать здесь работу чуть дольше, чем здесь хотелось бы. Но, в конце концов, тогда мы просто
[22:15.040 --> 22:24.360]  здесь ее бросим. Ладно, к этому нюансу мы опять вернемся через несколько месяцев. А пока подумаем,
[22:24.360 --> 22:32.080]  вот над чем. Что вообще такое дедлайн? Когда мы проверяем дедлайн, мы смотрим,
[22:32.080 --> 22:39.600]  он истек или нет. Мы получаем такой бинарный сигнал. Дедлайн истек или у нас все еще есть
[22:39.600 --> 22:48.880]  время. Вот почему бы нам каким-то образом не абстрагировать этот самый дедлайн до более
[22:48.880 --> 23:02.160]  общего понятия? И это понятие называется stop-token. Это довольно универсальный термин. stop-token или
[23:02.160 --> 23:07.840]  cancellation-token можно такие названия встретить. Суть одно и то же. Это объект, у которого можно
[23:07.840 --> 23:17.280]  спросить, верно ли, что пора завершиться. Этот stop-token может представлять дедлайн,
[23:17.280 --> 23:27.880]  или же этот stop-token может представлять сигнал отмены, который спровоцирует вручную,
[23:27.880 --> 23:35.920]  вызвав request-stop. Есть stop-source, который порождает stop-tokens, и на котором можно сказать
[23:35.920 --> 23:42.760]  stop-request-stop. Есть stop-token, с помощью которого можно проверить, что через stop-source сказали
[23:42.760 --> 23:49.560]  stop-request-stop. Понятная идея. То есть тот, кто хочет отменить какую-то асинхронную деятельность,
[23:49.560 --> 24:01.000]  он говорит на stop-source request-stop. Тот, кто выполняет какую-то асинхронную операцию,
[24:01.000 --> 24:10.360]  он проверяет stop-request. И тут, смотрите, важно, что мы себе сейчас задачу сильно упростим. Мы
[24:10.360 --> 24:18.280]  скажем, что да, мы хотим поддерживать отмену асинхронных операций, да, вот никакой промышленный
[24:18.280 --> 24:26.280]  код без этого не мыслим, но мы согласны на то, чтобы наша асинхронная отмена вот всех этих
[24:26.280 --> 24:36.720]  графов была кооперативной. То есть, смотрите, вот у нас есть такие учисления, и снизу вверх
[24:36.720 --> 24:44.960]  по этому графу текут результаты, ошибки или ответы, а сверху вниз пропагетится сигнал отмены. И вот
[24:44.960 --> 24:54.320]  два этих встречных сигнала, они, конечно, гоняются между собой. И мы, в общем, готовы к тому, что мы
[24:54.360 --> 25:03.840]  вычисления завершаем где-то, а на самом деле оно уже не нужно. Нас это не тревожит. Наша отмена
[25:03.840 --> 25:12.840]  будет кооперативной. То есть, ну, представьте себе, что вы стартовали вычисления, чтение из сокета,
[25:12.840 --> 25:20.920]  и вот вы сейчас прямо читаете данные. Вот, а вам сверху прилетает сигнал отмены. Ну, нужно ли прямо
[25:20.920 --> 25:26.920]  сейчас все отменить? Вот не всякую операцию можно в любой момент отменить. Вы запустили вычисления,
[25:26.920 --> 25:33.760]  то есть вы там, не знаю, откуда-то читаете данные, там их разжимаете в каком-то третпуле, а сверху вам
[25:33.760 --> 25:38.560]  прилетает сигнал отмены. Можете ли вы распаковку данных в третпуле сейчас отменить каким-то образом?
[25:38.560 --> 25:44.480]  Ну нет, там код запустился, он будет работать еще какое-то время. Вас это не беспокоит. Вы готовы
[25:44.480 --> 25:51.320]  периодически просто проверять, что можно отмениться. То есть вы выполняете работу и иногда проверяете
[25:51.320 --> 25:57.840]  вот этот самый дедлайн или вы проверяете стоп-токен, что, ну, ваша работа больше не нужна. Тогда вы ее
[25:57.840 --> 26:04.680]  отменяете. Тогда вы бросаете то, что вы делаете прямо вот сейчас. Но какой-то вот прям мгновенной
[26:04.680 --> 26:09.640]  реакции не требуется. Ровно поэтому у нас здесь не какие-то кулбеки, хотя кулбеки тоже нет.
[26:09.640 --> 26:16.120]  На самом деле кулбеки были бы важны, но с другой стороны это СТД стоп-токен, от него каких-то
[26:16.120 --> 26:22.120]  хороших вещей ждать, наверное, не стоило. В общем, в первую очередь проверка — это полинг. Просто
[26:22.120 --> 26:29.160]  проверяем флажок. Пора ли остановиться. Вот это такое наше ограничение, ну, есть ограничение,
[26:29.160 --> 26:39.960]  соглашение на все наше занятие и весь наш дизайн. Остановка кооперативная. Ну вот, стоп-токены.
[26:39.960 --> 26:46.720]  Про это все написана отличная статья в одном прекрасном блоге, про который я расскажу чуть
[26:46.720 --> 26:51.560]  позже. Тут как раз начинается с того, что вот есть тайм-ауты, потом есть дедлайны, и все это
[26:51.560 --> 26:59.640]  можно потом заменить на стоп-токены. Ну это, в общем, стандартное решение. А теперь
[26:59.640 --> 27:15.840]  посмотрим, как эта идея выражена в, ну скажем, в ГО. Есть ли в ГО стоп-токены? В ГО есть понятие
[27:15.840 --> 27:30.280]  контекста. В ГО есть, есть, конечно, контекст. И контекст, ну, это некоторая штука, которая похожа
[27:30.280 --> 27:39.000]  на стоп-токен, она на самом деле чуть более общая. Ну вот тут есть, смотрите, with cancel. Вы
[27:39.000 --> 27:44.120]  говорите, что теперь есть контекст, который можно, в который можно отправить сильного отмена. И есть
[27:44.120 --> 27:51.520]  вот ручка для того, чтобы это отмена спровоцировать. Но в общем случае контекст — это более общая
[27:51.520 --> 27:57.800]  источность, потому что она передает именно сигналы отмены, какие-то дополнительные там поля,
[27:57.800 --> 28:02.960]  какие-то записи, которые нужны для логинга, для трейсинга. Опять про это поговорим, и этим
[28:02.960 --> 28:09.800]  будем пользоваться. Но вот в первом приближении для нас сегодня контекст — это именно сигнал
[28:09.800 --> 28:15.600]  отмены. И смотрите, как ГО идиоматически предлагает его использовать. Ну, с помощью селектора.
[28:15.600 --> 28:23.800]  Вот. Иногда вам мало просто проверить, что сигнал отправлен. Может быть, вы хотите
[28:23.800 --> 28:29.400]  сблокироваться на канале. Но вы хотите заблокироваться и дождаться сообщений с каналу,
[28:29.400 --> 28:34.240]  только если у вас просто отмена не произошла. И вот здесь вы опять идиоматически с помощью,
[28:34.240 --> 28:40.120]  ну у вас контекст представляет вам сигнал отмены не просто в виде флажка или дедлайна,
[28:40.120 --> 28:48.080]  а еще и в виде канала. И вы можете все это, на все это навесить селект и остановить
[28:48.080 --> 28:53.520]  грудину до тех пор, пока либо не придет сигнал отмены, либо не завершится обработка чего-то.
[28:53.520 --> 29:05.920]  Ну вот, мы этим контекстом пользуемся. Только есть беда. Беда с этим самым контекстом и беда
[29:05.920 --> 29:12.500]  с дизайном ГО в том, что, ну как вам говорят пользоваться всем этим? Ну, вам говорят,
[29:12.500 --> 29:21.800]  что если у вас есть какой-то там граф вычисления, граф каких-то асинхронных шагов, который нужно
[29:21.800 --> 29:29.560]  которые порождается запросом, то, пожалуйста, когда вы там запускаете какую-то новую активность в
[29:29.560 --> 29:36.040]  этом графе, порождаете новый дочерний узел, то вот функцию, которая, собственно, отвечает за этот,
[29:36.040 --> 29:41.160]  ну, которая представляет этот узел, первым аргументом передавайте контекст, чтобы было видно,
[29:41.160 --> 29:48.680]  что вот эта функция, она может сигнал получить и отмениться. Вот, ну и предлагается этот контекст
[29:48.680 --> 29:57.160]  с собой таскать везде. Почему это плохо? Ну, это такой очевидный дурной запах, очевидный симптом
[29:57.160 --> 30:06.240]  плохого дизайна, потому что, с одной стороны, вам говорят, вот здесь вам говорят, что в любом
[30:06.240 --> 30:13.120]  продакшн коде должна быть поддержка отмены, то есть вам говорят, что всегда будьте готовы к
[30:13.120 --> 30:21.040]  отмене операции, всегда поддерживайте такой сценарий. И вместе с этим вам говорят, каждый раз руками
[30:21.040 --> 30:28.840]  таскайте контекст, то есть есть некоторая забота, которая нужна, есть этот контекст, который нужен
[30:28.840 --> 30:35.880]  всегда, но почему-то вы заставляем пользователя руками каждый раз его таскать. Выглядит как-то
[30:35.880 --> 30:44.480]  не очень эргономично. Понимаете проблемы, да? То есть понятно, что можно, но не очень удобно. Но давайте
[30:44.480 --> 30:56.120]  я вот, кстати, уже примеры какие-то покажу про стоп токен. Вот мы, в принципе, можем им пользоваться,
[30:56.120 --> 31:02.840]  чтобы отменить файберы. Вот мы запускаем планировщик, вот мы создаем стоп сорс,
[31:02.840 --> 31:10.160]  вот мы запускаем файбер, вот мы захватываем в нем стоп токен, этот файбер собирается бесконечно
[31:10.160 --> 31:16.920]  долго работать, но мы вот спим три секунды, тут на всякий случай мы спим, не то чтобы мы slip
[31:16.920 --> 31:26.880]  зовем трэдовый, мы зовем slip файберный, а slip файберный это await на future, который нам
[31:26.880 --> 31:35.960]  строит некий таймер сервис. Он строит фьюч от юнита, которые заполняются юнитом, когда проходит
[31:35.960 --> 31:45.000]  заданное время, а await это, кстати, вот то, что мы можем еще после того, как вы решите файберы,
[31:45.000 --> 31:50.040]  и после того, как вы решите future, можно будет в нашем коде написать такой свой собственный await,
[31:50.040 --> 31:56.560]  который компилятор пишет C++ за нас, а мы можем для стекла с файберов его написать сами. И вот
[31:56.560 --> 32:03.840]  склеить future и файберы через await, но так мы делаем это все C++. Короче, вот этот код он блокирует,
[32:03.840 --> 32:09.880]  останавливает файбер на три секунды, а потом говорит request stop, и видимо этот файбер должен
[32:09.880 --> 32:15.320]  отмениться, но можно это проверить. Давайте мы будем эти примеры запускать.
[32:15.320 --> 32:30.040]  Это стиль, в котором нам предлагают писать весь код в Go, и стиль, который, наверное,
[32:30.040 --> 32:45.080]  нам не очень нравится. Ну вот, мы поработали три секунды, потом, видимо, через этот request
[32:45.080 --> 32:57.400]  stop сюда прилетел флажок, и мы прекратили крутиться. Хотелось бы теперь решать задачу отмены более
[32:57.400 --> 33:04.320]  прозрачно для пользователя. Если пользователю всегда что-то нужно, и пользователю, если пользователю
[33:04.320 --> 33:11.240]  нужно что-то делать всегда, то было бы хорошо, если бы инфраструктура сама поддерживала этот
[33:11.240 --> 33:16.200]  сценарий прозрачно для пользователя, чтобы в коде пользователя явно никаких вот этих проверок не
[33:16.200 --> 33:22.760]  было. Поэтому что мы хотим? Мы хотим писать вот такой вот код. Мы хотим запустить файбер,
[33:22.760 --> 33:29.720]  вот, который выполняет функцию foo. Тут есть некоторые nursery. nursery здесь пока не очень важен.
[33:29.720 --> 33:37.360]  Просто запускаем файбер. Этот файбер вызывает функцию foo. В этой функции foo вызывается функция
[33:37.360 --> 33:42.680]  bar. В этой функции bar вызывается функция bus. В этой функции bus написано в бесконечном цепле slip4,
[33:42.680 --> 34:02.600]  тот же самый. Вот, но тем не менее мы хотим, чтобы этот код он остановился. То есть пользователь
[34:02.600 --> 34:10.840]  написал какой-то код, и он сразу из коробки поддерживает асинхронную отмену.
[34:22.640 --> 34:29.600]  Ну что, похоже, пример завершается. Давайте теперь думать, а как же это произошло? Как этот
[34:29.600 --> 34:39.840]  файбер умудрился остановиться? Как можно было бы сделать отмену файберов прозрачной для
[34:39.840 --> 34:48.720]  пользователей? И тут два вопроса на самом деле скрыты. Первый вопрос. Сейчас аккуратно. Механика
[34:48.720 --> 34:57.960]  отмена такая же. Где-то под капотом есть стоп токен, есть стоп сорс. Вот вопрос, где же стоп токен
[34:57.960 --> 35:09.240]  проверяется в файбере тогда, в этом коде? И второй вопрос. Как нам, собственно, файбер отменить? Что мы под
[35:09.240 --> 35:19.560]  этим понимаем? Ну, файберы это потоки, которые с одной стороны это потоки, а с другой стороны это
[35:19.560 --> 35:25.440]  потоки, которые должны больше времени спать, ждать чего-то. Именно поэтому мы их можем много завести в
[35:25.440 --> 35:34.360]  программе. Так вот, если они часто засыпаются, значит они часто, еще раз, файбер, когда он работает,
[35:34.360 --> 35:40.560]  он выполняет код пользователя. И мы на него влиять не можем, и мы не можем просто, точнее, можно себе
[35:40.560 --> 35:46.200]  было бы это представить, но мы так не хотим. Мы не можем взять и прервать файбер в любой момент
[35:46.200 --> 35:51.520]  времени. Но с другой стороны, файбер сам по себе, по своей природе, должен часто останавливаться,
[35:51.520 --> 35:58.120]  часто переходить в runtime, то есть реализацию свою. И вот в этом случае почему бы нам просто не
[35:58.120 --> 36:08.360]  вставить проверку? Почему бы нам не связать просто каждый файбер с некоторым стоп токеном? То есть,
[36:08.360 --> 36:14.400]  если мы создаем файбер, у него должен быть стоп токен. Это просто требование. Файбер без стоп
[36:14.400 --> 36:27.080]  токена немыслим. И мы у файбера сделаем метод, который будет называться isCancelled, который будет
[36:27.080 --> 36:38.000]  проверять этот самый стоп токен. Где мы будем этот метод вызывать? В suspend, я не знаю, там,
[36:38.000 --> 36:50.720]  где мы попадаем в runtime. Ну вот, например, я проснулся, и в suspend... Нет, не в suspend,
[36:50.720 --> 36:59.480]  в том-то и дело. Чтобы это объяснить, нужно ответить на второй вопрос. Вот у меня есть функция
[36:59.480 --> 37:07.560]  checkpoint. Вот checkpoint — это вызов, который нужно вставлять повсюду в коде, где файбер ходит в runtime,
[37:07.560 --> 37:12.000]  вот нужно поставить checkpoint, и вот ровно в этом месте, то есть там, где файбер мог бы отмениться,
[37:12.000 --> 37:19.840]  нужно поставить этот вызов, а он внутри проверит стоп токен файбера. Второй вопрос — что значит
[37:19.840 --> 37:27.640]  файбер отмениться? Вот файбер работал, он там сделал какой-то вызов, в этом вызове он какие-то,
[37:27.640 --> 37:36.960]  не знаю, mutex взял, потом пошел в какой-то другой вызов, а потом внутри отменился. Вот что мы понимаем
[37:36.960 --> 37:54.640]  под отменой файбера. Ну да, как этого добиться? Вот, да, поэтому, когда мы проверяем в checkpoint
[37:54.640 --> 38:01.580]  стоп токен, мы, если он оказался установлен, мы бросаем exception. Этот exception разворачивает
[38:01.580 --> 38:15.180]  стэк, вызывает деструкторы, и в конце концов он прилетает в корень файбера и где-то здесь написан
[38:15.180 --> 38:22.620]  вот такой вот catch. Вот файбер отменился. Это специальное исключение, видимо, перехватывать его
[38:22.620 --> 38:29.220]  не стоит, обрабатывать его точно не стоит, это такой clean-up файбер автоматический. Тут некоторые
[38:29.220 --> 38:37.140]  супервизоры появляются, об этом чуть позже. Значит, с файбером вроде понятно все, да? То есть можно
[38:37.140 --> 38:42.620]  его так вот прозрачно останавливать, не таская с собой топ токен явно, просто храняя его,
[38:42.620 --> 38:52.200]  по сути, сделать watered local, ну по своей сути. Хорошо, это одна часть истории. Другая часть
[38:52.200 --> 39:01.640]  истории это фьючи, потому что... Ну мы же хотим... Когда мы говорили про фьючи, мы говорили, что зачем
[39:01.640 --> 39:07.800]  нужно фьючи? Затем, что иногда мы хотим делать вещи параллельно, делать с вещами последовательно,
[39:07.800 --> 39:13.960]  тогда это файберы. То есть мы хотим сделать два запроса подряд. Кажется, что здесь файберы подходят
[39:13.960 --> 39:18.640]  нам. Сделали один запрос, дождались, потом сделали второй запрос, дождались. Ну ладно, тут другой
[39:18.760 --> 39:29.320]  написан. Понимаете, о чем я. Что если нам нужно распараллельно два запроса и получить первый
[39:29.320 --> 39:37.720]  ответ? Ну, кажется, это first-off. Вот нам хочется такой комбинатор иметь. Мы комбинируем две фьючи,
[39:37.720 --> 39:47.080]  потом дожидаемся. И, значит, у нас есть файберы, и у нас есть равноправные, равнополезные,
[39:47.080 --> 39:53.480]  ну правда, в другом контексте, фьючи. И для них тоже нужно поддерживать отмену.
[39:53.480 --> 40:07.640]  И для того, чтобы... Да, и вот смотрите. Давайте откроем даже домашню.
[40:07.640 --> 40:14.920]  Вот, что мы понимаем под отменой фьюч?
[40:14.920 --> 40:27.080]  Вот у нас было вычисление, потом было другое, потом был Zen. Мы получили фьючи G. Что мы
[40:27.080 --> 40:32.920]  хотим? Что мы понимаем под отменой? Мы бы хотели каким-то образом... То есть у нас фьюча — это
[40:32.920 --> 40:39.720]  представление какой-то ассинхронной деятельности, операции, вычисления. И мы бы хотели через эту
[40:39.720 --> 40:44.600]  фьючу, потому что это единственное, что у нас осталось, это вычисление, эту операцию отменять. Ну,
[40:44.600 --> 40:55.800]  или целый граф отменять. Поэтому мы бы хотели, чтобы у фьючи был, видимо, метод, который... Давайте
[40:55.800 --> 41:05.480]  мы сейчас его найдем. У фьючи был метод, который назывался бы cancel, который бы в обратную сторону
[41:05.480 --> 41:14.200]  отменял весь граф, который на фьючах выстроен. И чтобы увидеть, как это можно сделать,
[41:14.840 --> 41:20.520]  очень красиво, на мой вкус, давайте подумаем, что вообще такое stopToken и stopSource.
[41:29.960 --> 41:40.280]  Смотрите, в чем замысел stopSource и stopToken? stopSource — это сущность, которая находится у
[41:40.360 --> 41:45.440]  консьюмера, который чего-то ждет и который может решить перестать ждать, передумать,
[41:45.440 --> 41:51.520]  потому что там устегнут line. И у нас есть продюсер, который делает что-то полезное для консьюмера и у
[41:51.520 --> 41:57.920]  которого есть stopToken, через который продюсер проверяет, что его работа все еще нужна.
[41:57.920 --> 42:08.400]  И каким-то образом от stopSource к stopToken нужно передать сигнал отмены. Где его хранить? Вот,
[42:08.440 --> 42:15.440]  его нельзя хранить в stopSource, потому что консьюмер может отменить асинхронную операцию и просто
[42:15.440 --> 42:23.320]  завершиться. А отмена кооперативная, поэтому stopToken пока еще может не провериться. Аналогично
[42:23.320 --> 42:27.400]  нельзя хранить единицу в stopToken, не потому что операция уже может завершиться, а мы только ее
[42:27.400 --> 42:32.200]  сейчас собрались отменять. Где-то вы такое уже, наверное, видели, если вы решали фьючи,
[42:32.200 --> 42:37.000]  если вы решаете фьючи. Поэтому что мы делаем? Мы строим sharedState, который называется здесь stopState,
[42:37.000 --> 42:45.400]  и в этом stopState хранится флажок, нужно отмениться или нет. И stopSource и stopToken
[42:45.400 --> 42:49.920]  держат просто сильную ссылку на этот объект. То есть этот объект живет до тех пор, пока жив
[42:49.920 --> 43:01.520]  либо stopSource, либо stopToken. Ну и stopToken может быть много. В коде мы хотим это немного обобщить,
[43:01.520 --> 43:11.160]  сказав, что stopState это не просто конкретная реализация, где лежит флажок отомарный.
[43:11.160 --> 43:18.240]  На всякий случай иногда им рекомендуется скверный код, однажды он станет лучше,
[43:18.240 --> 43:30.480]  но в орган прогресс. В stopState лежит флажок stopRequested, но вообще-то stopToken это sharedPointer не
[43:30.480 --> 43:40.640]  на... sharedPointer тоже не нужен, нужен интуизивный pointer. Он хранит stopToken и stopSource хранят
[43:40.640 --> 43:50.640]  ссылку на stopState не на конкретный, а на интерфейс. Почему? Потому что stopState и можно представить
[43:50.640 --> 43:56.800]  себе очень разными и скажем, вот мы говорим, что у каждого файбера есть stopState, а какой должен
[43:56.800 --> 44:00.880]  быть... у каждого файбера есть stopToken? Какой должен быть токен у файбера, который мы просто
[44:00.880 --> 44:09.200]  запускаем через go? Мы говорим файбер, go, и он там летит. Очевидно, его никто не собирается отменять,
[44:09.200 --> 44:16.480]  просто сигнатура такая. Поэтому мы скажем, что у него будет свой собственный токен, который устроен
[44:16.480 --> 44:25.640]  вот так вот. Он всегда говорит false и вот просто ничего не делает, с максимальной легкой реализацией.
[44:25.640 --> 44:30.120]  Короче, можно представить себе разные реализации stopState для разных сценариев,
[44:30.120 --> 44:38.600]  которые специализированы. Ну вот, к чему я это все рассказываю? К тому, что, глядя на эту картинку,
[44:38.600 --> 44:48.400]  можно догадаться, как можно интегрировать прозрачно отмену в фьючи. Вот и давайте
[44:48.400 --> 44:53.160]  проверим вашу интуицию, потому что это очень красиво, мне кажется. Прямо очень красиво.
[44:53.160 --> 45:03.520]  В случае с файбером, мы просто в объект файбер запоминали stopToken, таскали его с собой. А как быть
[45:03.520 --> 45:11.280]  с фьючами? Как быть с этими конвейерами, которые мы там ассинхронно строим? Вот.
[45:11.280 --> 45:19.720]  Мы не можем в sharedState добавлять проверку? Не отменился ли stopToken?
[45:19.720 --> 45:25.200]  Смотри, ты не чувствуешь пока красоту. Ну давай я покажу тебя, чтобы, может быть,
[45:25.200 --> 45:35.320]  она была лучше видна. Что такое фьюч и promise? Этот sharedState, где лежит результат потенциальный
[45:35.320 --> 45:42.240]  будущий. И есть promise – это сильная ссылка на sharedState у продюсера, и future – сильная ссылка на
[45:42.240 --> 45:50.440]  sharedState у консюмера. И консюмер и продюсер передает результат консюмеру через этот sharedState.
[45:50.440 --> 46:03.760]  Но вот тут вопрос не в том, как можно поддержать фьюч во фьючах cancel, а в том, что нужно просто
[46:03.760 --> 46:11.840]  увидеть некоторую двойственность между двумя этими картинками. И тут не просто так эта картинка
[46:11.840 --> 46:17.160]  нарисована. Тут вот есть этот граф, и мы снизу и вверх отправляем результаты, сверху вниз cancellation.
[46:17.160 --> 46:26.560]  Это какие-то, ну, как бы, ну, смотрите, мне нравится такая аналогия с кровеносной системой. У нас
[46:26.560 --> 46:35.680]  есть артерии и вены, и они просто противоположные цели выполняют, противоположные функции выполняют.
[46:35.680 --> 46:43.480]  И они как бы дублируют друг друга в некотором смысле. Если есть в одну сторону, то есть в другую
[46:43.480 --> 46:57.320]  сторону. Ну что ж, получается, что с одной стороны продюсер-консюмер им нужен два объекта для того,
[46:57.320 --> 47:00.760]  чтобы передавать результат в одну сторону, а с другой стороны им нужен такой же разделенный
[47:00.760 --> 47:06.200]  объект, чтобы передавать отмену в другую сторону. И может быть, это не просто как бы
[47:06.200 --> 47:11.720]  каких-то два отдельных механизма, две параллельные сущности. Может быть, это вот как бы просто
[47:11.720 --> 47:18.960]  future и promise, они по своей природе двойственные такие. Вот мы от promise к future передаем результат,
[47:18.960 --> 47:35.440]  а от future к promise передаем сигнал отмены. И поэтому давайте так и напишем код. Давайте мы в... где же
[47:35.440 --> 47:44.480]  мы были? Мы хотим попасть в future, в shared state. Давайте мы скажем, что shared state он наследуется от
[47:44.480 --> 47:51.400]  stop state. Ну то есть shared state это в том числе и stop state. Или можно было бы даже красивее сделать,
[47:51.400 --> 47:58.600]  сказать, что у нас есть stop state, есть как бы result state, а shared state он наследует и то и другое.
[47:58.600 --> 48:07.800]  Это, наверное, было бы самым красивым выражением в коде этой идеи. И поэтому,
[48:07.800 --> 48:21.400]  как наша API future доработается в связи с этим? Мы скажем, что у future есть операция cancel,
[48:21.400 --> 48:29.440]  а у promise есть операция stop requested. Ну потому что promise это... Здесь promise,
[48:29.440 --> 48:35.000]  он как бы и promise для отправки результата, и как бы stop token для проверки флажка отмены,
[48:35.000 --> 48:42.800]  а future она одновременно и для получения результата, и для отмены. То есть она и
[48:42.800 --> 48:52.720]  как бы future и stop source разом. То есть здесь вот future она похожа на stop source, а promise здесь
[48:52.720 --> 49:03.840]  похож на stop token. Понятная идея? Вот, мне кажется, очень красиво, но это только начало.
[49:03.840 --> 49:16.560]  Двигаемся дальше. Что я, наверное, упустил? Я упустил следующую картинку, и мне она сейчас
[49:16.560 --> 49:23.800]  пригодится. Такая незамысловатая. Смотрите, контекст или stop token представляет собой
[49:23.800 --> 49:33.600]  некоторые сигналы отмены. Например, deadline. Но если вы пишете какую-то композитную операцию,
[49:33.600 --> 49:39.840]  у вас есть сначала запрос в сервис A, потом строго после запроса в сервис B, который использует
[49:39.840 --> 49:47.240]  ответы сервиса A, то вообще говоря, может быть, у вас есть общий deadline, а может быть, у вас есть
[49:47.240 --> 49:56.800]  какие-то вложенные дедлайны, вложенные лимиты. И тогда у вас такая система дедлайнов получается,
[49:56.800 --> 50:07.120]  или система каких-то причин, по которым вы отменяете операцию. И вот эта иерархия, она может быть
[50:07.120 --> 50:14.520]  выражена прямо через иерархию на самих stop token, на самих контекстах. Вот, скажем, в Go,
[50:14.600 --> 50:19.720]  вы когда оборачиваете контекст, вы... У меня сейчас, наверное, нет под рукой кода.
[50:19.720 --> 50:44.280]  Найду я сейчас что-нибудь быстро. Нет, это вообще не то, что подсылывают какие-то плохие сумки.
[50:44.520 --> 50:53.400]  А контекст разве в рантайме? Это же сторонний библиотект, кажется.
[50:53.400 --> 51:09.080]  Ну, сейчас, не в рантайме, да. Я просто так говорю, потому что для меня это логически часть рантайма,
[51:09.080 --> 51:13.920]  потому что в Go это как бы снаружи, потому что мы таскаем руками, а у нас сейчас это внутри,
[51:13.920 --> 51:26.040]  потому что мы не хотим таскать руками все. В Go у нас контексты, они связаны отношением вот ребенок
[51:26.040 --> 51:37.920]  родителей. И к чему я это говорю? К тому, что буквально такая картинка, во-первых,
[51:37.920 --> 51:43.320]  появляется на самом деле в контекстах. А во-вторых, как это относится к нам? Это относится к нам
[51:43.320 --> 51:49.920]  самым прямым способом, потому что смотрите, что мы делаем здесь. Мы в этом примере же не просто
[51:49.920 --> 51:58.040]  запустили, построили Future, построили пару контракт Future Promise, Promises отправили в Threadpool,
[51:58.040 --> 52:03.920]  и там проверяем отмену, а на Future говорим cancel. Мы вообще-то на Future сделали ZEN еще,
[52:03.920 --> 52:12.400]  и вот мы сделали cancel здесь, и он пролетел сквозь эту построенную цепочку вот сюда,
[52:12.400 --> 52:26.400]  в корень. Как мы этого добились? В этом вся соль. Как это все композируется? Потому что пока мы
[52:26.400 --> 52:32.280]  просто буквально пронесли стоп-токен руками, мы пока ничего особенного интересного не сделали.
[52:32.280 --> 52:39.320]  Вот красота где-то здесь появляется, потому что вот здесь никакого кода пользователи не написал,
[52:39.320 --> 52:44.880]  он ни синхронизации не написал, ни прокидывания токенов не написал, а все автоматически работает.
[52:44.880 --> 52:49.720]  Вот это наша цель. Как же это произошло? Как же мы это добились?
[52:59.720 --> 53:00.220]  Что?
[53:00.220 --> 53:07.760]  Должны, да. Ну вот смотри, что такое ZEN?
[53:07.760 --> 53:15.920]  Вот ZEN – это комбинатор, который берет Future и который запускает лямбду,
[53:15.920 --> 53:24.440]  когда Future заполнится значением. Как реализовать ZEN? Ну, нужно подписаться на Future и в колбеке
[53:24.440 --> 53:35.120]  вызвать эту лямбду. Но нужно же еще каким-то образом, когда, если случится отмена,
[53:35.160 --> 53:43.360]  протянуть сигнал отмены. Так вот, где складывает, где происходит связывание? Ну, это не знаю,
[53:43.360 --> 53:55.280]  по-моему, это очень красиво. По-моему, это очень красиво. Это не то, это... Вот что я хочу. Смотрите,
[53:55.360 --> 54:05.960]  ну или даже по-другому скажу. Любая операция на Future, просто любая. Ну вот, берем API Future.
[54:05.960 --> 54:19.240]  У нас в синхронных Future был очень простой API и очень скверный API. У Promisable Set с ним все
[54:19.240 --> 54:28.080]  нормально. У Future был блокирующий GET. В хороших Future никакого блокирующего GET у самой Future
[54:28.080 --> 54:37.000]  нет. У Future есть только subscribe. Вот то есть поглотить значение, результат вычисления синхронного,
[54:37.000 --> 54:44.160]  можно, операция синхронная, можно только через subscribe. Если вы хотите заблокироваться, то вы
[54:44.160 --> 54:53.040]  можете использовать какую-то внешнюю функцию. Сейчас у меня где-то написано условия.
[55:02.480 --> 55:09.360]  Да, если вам нужно заблокироваться во Future, то вы используете внешнюю функцию GET RESULT,
[55:09.360 --> 55:16.480]  а сама Future блокироваться не умеет, потому что это для нее ненормально. Future, они для того,
[55:16.480 --> 55:24.000]  чтобы исполнять что-то в третпуле, а в третпуле выблокировать потоки не хотим. Поэтому, поэтому,
[55:24.000 --> 55:30.640]  есть только subscribe и смотрите какая семантика у subscriber. Мы подписываемся на результат.
[55:30.640 --> 55:44.760]  А как это связано с отменой? Вот была некоторая синхронная операция, она представлялась Future.
[55:44.760 --> 55:55.400]  Пока Future это такая невостребованный результат, пока никто его не дожидается. А значит,
[55:55.400 --> 56:03.480]  его пока некому отменять. Но, если вдруг вы подписываетесь на Future, а любой код,
[56:03.480 --> 56:09.160]  который хочет что-то с Future делать, в конце концов подписывается, то вы сразу получаете
[56:09.160 --> 56:18.040]  Stop Source. Вот вы подписались, повесили колбэк свой, ну тогда вот вы ответственны за отмену. Вот вам
[56:18.920 --> 56:30.680]  Stop Source, разбирайтесь. Как это реализовано? Ну, очень просто. Subscribe, Future держит ссылку на
[56:30.680 --> 56:35.880]  стейт. Этот стейт, он является и Stop Source в том числе. Поэтому просто берем Stop Source,
[56:35.880 --> 56:43.360]  строим, который хранит shared pointer на I-stop-state. А shared-state это в том числе и I-stop-state,
[56:43.360 --> 56:52.120]  поэтому в общем полная гармония. То есть просто Future теряет свой стейт, она уже как бы использована,
[56:52.120 --> 57:00.160]  но пользователь этот стейт дается в виде stop-state, чтобы операцию можно было отменить. И когда я
[57:00.160 --> 57:07.400]  говорю Zen, вот в этом примере, то я с одной стороны подписываюсь на выполнение Future F1,
[57:07.400 --> 57:21.680]  а с другой стороны я свой токен, в смысле Future F2, связываю со Stop Source Future F1. Вот Stop
[57:21.680 --> 57:35.520]  Token коннектится к Stop Source, я могу их связать всегда. У меня просто в Stop Token есть операция
[57:35.520 --> 57:55.280]  связать с Stop Source. То есть я буду вот так вот отправлять сигнал отмены. Понятно? Красиво, да? И
[57:55.280 --> 58:02.200]  все это сплетается внутри runtime. То есть мы пишем Future F2 с комбинаторами, и вот оно так плетется,
[58:02.680 --> 58:08.240]  то есть смотрите, когда я выстраиваю граф с помощью Future, вот почувствуйте это,
[58:08.240 --> 58:22.000]  я с одной стороны выстраиваю граф снизу вверх, откуда будут течь результаты, и параллельно я
[58:22.000 --> 58:27.720]  выстраиваю синхронный граф сверху вниз, по которому будет течь отмена. Это вот буквально
[58:27.720 --> 58:34.680]  такие две кровеносные системы, в смысле две части кровеносной системы, и они абсолютно
[58:34.680 --> 58:45.480]  параллельны, они друг без друга не могут быть. Вот, очень красиво. Сам себя не похватишь.
[58:45.480 --> 58:54.720]  Так, в какой момент мы отменяем Stop Source? Мы Stop Source не ринкуем, это довольно странная
[58:54.720 --> 59:03.360]  симматическая операция была бы. Мы Stop Token и Stop Source линкуем всегда. Stop Token Future,
[59:03.360 --> 59:16.720]  которую мы порождаем в зене, и Stop Source Future, которую мы консюмим в зене. Вот, еще раз,
[59:16.720 --> 59:26.120]  мы здесь подписываемся на Future F1 и в ней запускаем Callback. Подписываемся на Future F1 и
[59:26.120 --> 59:32.880]  в обработчике запускаем лямду. Следующий шаг вычисления. Вот в этом зене мы связываем
[59:32.880 --> 59:59.280]  Stop Token F2 со Stop Source F1. Так, чтобы, когда я сказал на F2 Stop Cancel, то этот cancel бы,
[59:59.280 --> 01:00:13.120]  вот так, наверное, было бы симпатичнее написать. Пожалуйста. Не то чтобы у Promise есть
[01:00:13.120 --> 01:00:21.000]  там какой-то поле Stop Token, потому что он в том числе и Stop Token сам по себе. То есть,
[01:00:21.000 --> 01:00:28.680]  Promise 2, который Stop Token, соединяется с Future F1, который Stop Source. Вот, и дальше сигнал
[01:00:28.680 --> 01:00:34.280]  прилетает вот по цепочке. Дальше, если я наворачиваю новые и новые зены, ну, это легко делать. Дальше,
[01:00:34.280 --> 01:00:40.080]  потом я скажу на конце цепочки cancel, и он развернется и долетит до вот самого источника. И
[01:00:40.080 --> 01:00:49.640]  здесь мы, ну, если хотим, проверим и отменим. Итак. Если у нас длинный pipeline какой-то,
[01:00:49.640 --> 01:00:58.160]  ну, там несколько зенов, мы можем где-то в середине cancel отправить? Ну, как, если мы на Future
[01:00:58.160 --> 01:01:07.680]  подписались, то вообще говоря нет. Ну, то есть, если мы сделали zen, то значит за cancel отвечает
[01:01:07.680 --> 01:01:12.360]  кто выше находится теперь. А здесь мы просто пропагетим. Но можно, на самом деле, по-разному делать.
[01:01:12.360 --> 01:01:20.080]  Можно делать по-разному. Можно еще и внутрь задачи, внутрь кулбека прокидывать контекст. Это
[01:01:20.080 --> 01:01:29.840]  это можно делать, и это, наверное, стоит делать. И это чуть более общий вопрос. Тут пока для него
[01:01:29.840 --> 01:01:39.920]  код не написан, но я могу идею, кажется, рассказать. Секунду. Это уже про экзекьюторы разговор. И я хочу
[01:01:39.920 --> 01:01:47.680]  сказать, что, наверное, в экзекьюторах у каждой задачи просто должен быть свой контекст. У любой
[01:01:47.680 --> 01:01:52.520]  задачи, которая запускается, должен быть контекст для трейсинга, для логинга, чтобы можно было в
[01:01:52.520 --> 01:01:58.720]  других библиотеках этот контекст читать. И в том числе оттуда можно было бы забрать stop
[01:01:58.720 --> 01:02:07.320]  токен текущий. Ну или даже там, не знаю, отменить что-то. Ну в первую очередь проверить,
[01:02:07.320 --> 01:02:17.320]  все же, а не отменить. Тут можно еще глубже все это интегрировать. Вопрос разумный. Да,
[01:02:17.320 --> 01:02:22.960]  можно было бы. Кажется, что фундаментальных препятствий к этому опять нет.
[01:02:22.960 --> 01:02:35.080]  Нет, у нас, смотри, у нас stop. Тут нужно не про stop токенные сорсы говорить, потому что это
[01:02:35.080 --> 01:02:39.400]  всего лишь такие обертки, которые поинтеры держат на stop стейт. У нас каждая фьюча это,
[01:02:39.400 --> 01:02:46.760]  ну каждая новая фьюча это новый shared state. Каждый shared state это stop стейт. И мы вот их связываем в
[01:02:46.760 --> 01:02:53.880]  граф. То есть у нас вот здесь граф строится для вычислений и в обратную сторону, то есть строится
[01:02:53.880 --> 01:03:01.960]  противоположно направленный граф для отмены. Так, секунду, у нас садится ноутбук и это не
[01:03:01.960 --> 01:03:14.880]  помогает быстро работать. Вот это работа. Вот такой вопрос про семантику канцела. Он предотвращает только
[01:03:14.880 --> 01:03:19.360]  будущие вычисления. Но он кооперативный, то есть он говорит, что вот если что-то не вычислилось еще,
[01:03:19.360 --> 01:03:25.600]  то и не нужно больше, а если уже успело, то ну ничего не поделать. А если прямо сейчас что-то делается,
[01:03:25.600 --> 01:03:31.720]  то возможно можно еще отменить, еще не поздно отменить. Ага, ясно. Вот в этом и смысл кооперативности,
[01:03:31.720 --> 01:03:37.400]  то есть мы не можем каким-то магическим образом отменить там, не знаю, вычисления, там разжатие
[01:03:37.400 --> 01:03:45.400]  данных в пуле. Вот оно запустилось и будет работать пока не завершится. Вот, но если что-то можно отменить,
[01:03:45.400 --> 01:03:54.400]  то кто-то, кто потом этот стоп токен смотрит, может быть он согласится бросить свою работу. Да,
[01:03:54.400 --> 01:04:01.400]  я не договорил еще такой нюанс, очень красивый мне кажется. Смотрите, у нас есть, мы говорим,
[01:04:01.400 --> 01:04:08.680]  что вот стоп сорс, стоп токен и future promise это какие-то очень просто одно и то же названные иначе,
[01:04:08.680 --> 01:04:12.680]  да, потому что просто коммуникация в противоположные стороны. И мы говорим,
[01:04:12.680 --> 01:04:21.680]  что future она потребляется как подписка и кулбэка. Вот на самом деле вопрос в чат.
[01:04:25.280 --> 01:04:33.200]  Хорошо бы развернуть вопрос, потому что я не понимаю вопроса пока, ну точнее замечания.
[01:04:33.200 --> 01:04:43.760]  А, это шутка? Тогда поясни шутку. Ужасная ситуация, да, когда не понял шутку. Ну, такое случается,
[01:04:43.760 --> 01:04:53.640]  к сожалению. А, я понял, это... К чему я веду? К тому, что подписываться можно на future,
[01:04:53.640 --> 01:04:58.280]  но с другой стороны подписываться на стоп токен, ой, на стоп токен, да, с другой стороны,
[01:04:58.280 --> 01:05:03.000]  это тоже разумно. То есть кажется, что если у нас есть promise и он представляет собой стоп токен,
[01:05:03.000 --> 01:05:08.640]  в том числе, то операция подписки на promise, она не выглядит так уж безумно. Ну, в смысле,
[01:05:08.640 --> 01:05:13.320]  она вообще не выглядит безумно, это разумная идея. Чего я так говорю? Потому что, ну, представьте
[01:05:13.320 --> 01:05:19.760]  себе RPC. Вот это еще, у нас осенью будет RPC, он будет интегрирован с этим фреймворком конкарнси,
[01:05:19.760 --> 01:05:24.960]  и вот это то, что я еще не написал в нем, а мне, наверное, хочется, ну, по крайней мере,
[01:05:24.960 --> 01:05:34.440]  попробовать хочется. Вот что, если вы фреймворк RPC, и вы там породили запрос, отправили его в сеть,
[01:05:34.440 --> 01:05:43.160]  и вы, библиотека RPC, держите promise, future даете пользователю, а promise держите у себя, чтобы,
[01:05:43.160 --> 01:05:53.840]  когда придет ответ, вы бы отправили во future результат. Но что, если пользователь сам сказал cancel
[01:05:53.840 --> 01:06:01.280]  на future? Что мог бы сделать RPC framework? Он мог бы повесить callback на promise,
[01:06:01.280 --> 01:06:12.640]  и в этом callback отправить на другую машину специальные служебные сообщения,
[01:06:12.960 --> 01:06:20.800]  что вот сворачиваетесь, вы больше не нужны, вычисления ниже. И это было бы все реактивно,
[01:06:20.800 --> 01:06:26.080]  вот с помощью подписки на подписки вот здесь, вот с этой стороны, то есть на стороне продюсеров,
[01:06:26.080 --> 01:06:50.600]  понимаете? Красивая идея. Вопрос? А мы ничего не ожидаем, это же best effort, мы просто попробуем,
[01:06:50.600 --> 01:06:54.800]  и все. Может быть, на этой машине запрос уже завершится к этому времени, когда сообщение дойдет,
[01:06:54.800 --> 01:07:06.200]  может быть, так не нужно делать вообще. Да, я понял, да. Вот, вообще про это есть... Я уже многократно
[01:07:06.200 --> 01:07:14.840]  рекламировал статью про future в твиттере, вот если вы решаете задачу, а даже если вы не решаете,
[01:07:14.840 --> 01:07:22.840]  вот необходимо ее прочесть, она великолепна, она про дизайн, про то, как вот сделать хорошие
[01:07:22.840 --> 01:07:31.440]  фьючи. И эти фьючи, они зарелизили твиттер в виде библиотеки, в которой очень много всего,
[01:07:31.440 --> 01:07:40.200]  и вот на которой написан, собственно, весь твиттер. И я сейчас хочу найти... Тут много всякой
[01:07:40.200 --> 01:07:44.000]  инфраструктуры, все эти контексты, трейсинги, ну короче, вот все, что нужно, не просто вот как бы
[01:07:44.000 --> 01:07:50.280]  future promise, этого очень мало, нужна вот вся сопутствующая инфраструктура, всякие там балансеры,
[01:07:50.280 --> 01:08:12.640]  ретрои, метрики, трейсинг. Опять про это осенью. Секундочку. У меня где-то спрятана ссылка,
[01:08:12.640 --> 01:08:41.840]  я сейчас хочу ее найти и порекламировать. Да, есть чудесный доклад одного из инженеров,
[01:08:41.840 --> 01:08:53.000]  который над этими фьючами работает, где он рассказывает, что вот фьюч в твиттере,
[01:08:53.000 --> 01:09:08.880]  они так делают. Они умеют пропагетить консолейшн в... Где-то это должно здесь быть. Ладно,
[01:09:08.880 --> 01:09:16.320]  это или... Ладно, это в твиттере, его точно есть, совсем недавно написал про то, что фьюч у них
[01:09:16.320 --> 01:09:20.640]  очень клевый, про то, что они вот все это умеют делать, они лучше, чем скала фьюча, ну то есть
[01:09:20.640 --> 01:09:26.400]  биоретика написана на скале, вот в скале тоже есть фьюч, но вот они этого не умеют, а вот у них
[01:09:26.400 --> 01:09:32.800]  умеют и уже много лет умеют. И, скажем, у IT яндекс и фьюч тоже умеют такую отмену делать.
[01:09:32.800 --> 01:09:40.400]  Вот, ну потому что, ну по-моему, кстати, они, я не уверен, что они умеют, по-моему, Паша Сушин,
[01:09:40.400 --> 01:09:45.000]  я не помню, что он рассказывал, умеют ли они пропагетить, пропагетят ли они сигнал прямо отмены
[01:09:45.000 --> 01:09:52.840]  через служебные сообщения, ну вот в твиттере пропагетят. И вот это все связано с возможностью
[01:09:52.840 --> 01:09:58.080]  повесить, ну если смотреть на все это как на двойственную сущность, то вешать callback на
[01:09:58.080 --> 01:10:02.040]  фьюч так же разумно, как вешать callback на promise. Вешать callback на promise так же разумно,
[01:10:02.040 --> 01:10:05.960]  как на фьюч, только с противоположным назначением, с целью противоположной,
[01:10:05.960 --> 01:10:14.600]  чтобы подписываться на отмены и вот посылать сообщения вниз по этому графу к дочерним сервисам.
[01:10:14.600 --> 01:10:22.520]  Итак, это понятно все, да? А теперь мы переходим к теме реакции, собственно, ну,
[01:10:23.000 --> 01:10:32.040]  к основному ключевому содержанию, как все это объединить в совсем выстроенную систему,
[01:10:32.040 --> 01:10:42.560]  встроенный фреймворк. Для этого нужно поговорить про несколько другой топик,
[01:10:42.560 --> 01:10:49.880]  которого мы сейчас, в общем-то, избегали. Мы пока говорим, что, ну, почему вообще случать отмена,
[01:10:49.880 --> 01:10:53.280]  потому что вот есть клиент, он приходит, у него есть бюджет времени, вот он истекает,
[01:10:53.280 --> 01:11:00.840]  и все, вниз полетело отмена. Но это не единственная причина, по которой отмена может случиться.
[01:11:00.840 --> 01:11:10.280]  И есть еще второй аспект — это обработка ошибок. И чтобы к этой теме выйти, нужно
[01:11:10.280 --> 01:11:23.800]  подойти вот довольно очень издалека, я бы так сказал. Нужно вернуться в 1968 год и прочитать
[01:11:23.800 --> 01:11:33.920]  просто величайшую статью. Ну, это как бы одна из заметок, на самом деле, но стоит того,
[01:11:33.920 --> 01:11:42.040]  чтобы прочесть. Это Сэ Дэйкстры про то, что, ну, с критикой оператора Гоу Ту — Considered Harmful.
[01:11:42.040 --> 01:11:48.360]  Вот она таким названием известна. Именно поэтому в шаблоне задач везде было написано, что Гоу
[01:11:48.360 --> 01:11:57.800]  Considered Harmful. И забегая вперед, некоторый спойлер, мы хотим сказать, что... Ладно,
[01:11:57.800 --> 01:12:03.920]  давайте пока без спойлеров. Всему свое время. Итак, мы говорим про обработку ошибок, и для этого
[01:12:03.920 --> 01:12:10.320]  нам нужно вернуться в глубокое прошлое, в 68 год, и подумать о том, как выглядела обработка ошибок,
[01:12:10.320 --> 01:12:18.360]  как вообще выглядели программы в те далекие времена. Это вообще, не знаю, скан манускрипта,
[01:12:18.360 --> 01:12:24.360]  набранного на печатной машинке, наверное. Ну, и такие статьи тоже полезны читать, особенно сейчас.
[01:12:24.360 --> 01:12:31.040]  Да, всё-таки я покажу картинку. Она как раз из статьи, которая называется Go Considered Harmful.
[01:12:31.040 --> 01:12:36.720]  Потому что утверждается, что Гоу и Гоу Ту — это очень похожая вещь, Симонтич. Ну, вот в некотором
[01:12:36.720 --> 01:12:42.560]  смысле очень похожие вещи. Эта аналогия, она очень глубокая и ведет к очень чертовски разумным
[01:12:42.560 --> 01:12:50.760]  выводам. Всё, на этом закончу. Итак, утверждается, что... Ну, не то, что утверждается, в глубоком
[01:12:50.760 --> 01:13:00.400]  прошлом, в далеком-далеком прошлом программы выглядели как-то так. Ну, можно себе представить
[01:13:00.400 --> 01:13:12.280]  там разные программы, но суть в том, что они были плоскими. Вот это некоторый текст в плоскими,
[01:13:12.280 --> 01:13:20.200]  и если мы думаем про исполнение такой программы, то мы думаем про вот буквально перемещение
[01:13:20.200 --> 01:13:27.280]  некоторого курсора, про перемещение управления по этому плоскому тексту. И перемещаемся мы по этому
[01:13:27.280 --> 01:13:34.000]  тексту преимущественно с помощью оператора Гоу Ту. Вот мы прыгаем из одного места в другое. Ну,
[01:13:34.000 --> 01:13:42.800]  и понятно, что так можно в принципе любой логику выразить, что еще нужно. Кроме того, Гоу Ту — он
[01:13:42.800 --> 01:13:49.240]  и в современных языках есть, но, правда, в каком-то ограниченном виде, но и компилиаторы, когда они
[01:13:49.240 --> 01:13:58.420]  компилируют ваш код, они могут переписывать все ваши конструкции, все эти ифы, циклы и там
[01:13:58.420 --> 01:14:06.400]  интерацию на Гоу Ту. Но вот все-таки в нашем современном языке этого всего нет. Почему? Отвечает
[01:14:06.400 --> 01:14:19.240]  Дэкстра. Он говорит, что если вы думаете про исполнение вашей программы, то если ваша программа
[01:14:19.240 --> 01:14:25.400]  плоская и в ней передача управления происходит с помощью Гоу Ту, то очень сложно думать про
[01:14:25.400 --> 01:14:34.000]  динамику исполнения вашей программы. Дэкстра говорит, что человеческий мозг, он хорошо работает
[01:14:34.000 --> 01:14:41.840]  со статическими структурами, и он плохо работает с какими-то очень динамичными системами. Ну,
[01:14:41.840 --> 01:14:48.040]  собственно, далеко за примером ходить не нужно. Мы в этом курсе говорим про потоки, которые там
[01:14:48.040 --> 01:14:52.880]  переключаются друг на друга, и вот нам нужно представлять себе все возможные интерливинги,
[01:14:52.880 --> 01:14:58.800]  и это неестественно для человека, это сложно для человека, он легко там ошибается. Вот сложно об
[01:14:58.800 --> 01:15:05.640]  этом думать. И если мы говорим про Гоу Ту, тут точно такая же идея, что вот мы пришли в какую-то точку
[01:15:05.640 --> 01:15:11.600]  программы, а как мы там оказались, не очень понятно. Что предлагается? Предлагается заменить вот эту
[01:15:11.600 --> 01:15:18.320]  сложную динамику на какую-то очень простую статическую структуру, которую можно визуализировать.
[01:15:18.320 --> 01:15:22.880]  Для этого предлагается сделать следующее, воспользоваться идеей, которая называется
[01:15:22.880 --> 01:15:33.800]  structured programming. Фундаментальная идея, которая изменила программирование давным-давно.
[01:15:33.800 --> 01:15:43.240]  Идея в том, что не нужно думать про вот такие сложные динамические сценарии, нужно представить
[01:15:43.240 --> 01:15:48.920]  себе управление в программе, выразить передачу управления в программе однопоточной, обычной,
[01:15:48.920 --> 01:16:02.160]  через ограниченный набор конструкций. Во-первых, это последовательная композиция, когда мы сначала
[01:16:02.160 --> 01:16:10.400]  выполняем там не знаю, шаг A, шаг B, вызываем под программу A, под программу B. Итерация в виде циклов
[01:16:10.400 --> 01:16:21.160]  while for и витление. Вот тогда исполнение, тогда нашу программу можно представить себе в виде графа.
[01:16:21.160 --> 01:16:28.320]  Есть всегда точка входа, есть точка выхода, и вот этот граф имеет структуру некоторую,
[01:16:28.320 --> 01:16:33.640]  и эта структура, она тактически выражена просто, ну не знаю, вы наблюдаете ее в виде отступа в
[01:16:33.640 --> 01:16:39.560]  программе, отступов и пустых строк. Это в общем-то отражение этой структуры. И вам гораздо легче думать
[01:16:39.560 --> 01:16:45.400]  о том, что происходит. Вообще, идея под программой, она очень мощная, потому что она абстрагирует
[01:16:45.400 --> 01:16:51.080]  содержимое. Вам не нужно думать, что внутри происходит, вы просто знаете сигнатуру, и все. И это не
[01:16:51.080 --> 01:16:57.200]  только вам упрощает жизнь, это упрощает жизнь и даже в первую очередь, ну не то, что в первую
[01:16:57.200 --> 01:17:04.560]  очередь, в равной степени это упрощает жизни компилятору, потому что компилятор, вот то,
[01:17:04.560 --> 01:17:12.560]  что мы рисуем, компилятор строит явно, и эта конструкция называется, где-то у меня должна быть
[01:17:12.560 --> 01:17:25.040]  ссылка, и где же она. Эта сущность называется control flow graph. Вот компилятор, он парсит текст вашей
[01:17:25.040 --> 01:17:32.240]  программы и строит по ней control flow graph. То есть вот все вот эти ваши там блоки и передачу управления
[01:17:32.240 --> 01:17:37.120]  между ними, он отражает в виде графа с понятной структурой. А потом, пользуясь этим графом,
[01:17:37.120 --> 01:17:47.520]  он просто доказывает некоторые свойства вашей программы. Ну вот скажем, Borrow Checker в Rust
[01:17:47.520 --> 01:17:55.360]  использует Liveness Analysis. Ничего здесь не написано про Liveness, черт возьми. Но Liveness Analysis для
[01:17:55.360 --> 01:18:00.800]  того, чтобы определять, какие перемены, к каким переменным дальше, ниже по тексту могут обращаться.
[01:18:00.800 --> 01:18:07.480]  Но не ниже по тексту, а вот как бы дальше в исполнении. Вот компилятору Rust нужен для Borrow
[01:18:07.480 --> 01:18:13.760]  Checking этот самый control flow graph. Это называется data flow analysis. Как по графу текут результаты.
[01:18:13.760 --> 01:18:23.040]  Или скажем, ну такая привычная вещь, как распространение константов. Вот у вас есть одна
[01:18:23.040 --> 01:18:27.440]  константа в коде, другая константа в коде, потом вы там между ними что-то вычисляете,
[01:18:27.520 --> 01:18:32.560]  вычисляете новую переменную, где там переносите две константы. Вот компилятор что пытается сделать?
[01:18:32.560 --> 01:18:36.920]  Он пытается от переменных избавиться, не аллоцировать там память, а просто понять,
[01:18:36.920 --> 01:18:41.760]  что вот в этой точке, вот этой переменной, хоть и тут написано какое-то вычисление,
[01:18:41.760 --> 01:18:46.440]  но на стадии компиляции будет известно, что здесь будет некоторая фиксированная константа. Поэтому
[01:18:46.440 --> 01:18:52.000]  я ее просто вычислю и напишу в текст программе сразу ее, не аллоцируя переменные, не там вычисления.
[01:18:52.920 --> 01:19:00.400]  Вот все это работает, потому что у вас есть структура. Ну это такие общие вещи, а теперь конкретно
[01:19:00.400 --> 01:19:09.080]  про нас. Почему структура важна? Потому что эта структура позволяет легче обрабатывать ошибки.
[01:19:09.080 --> 01:19:17.600]  Ну вот представьте себе, у вас есть, давайте вернемся на картинку, на вот эту картинку,
[01:19:17.600 --> 01:19:24.600]  у вас есть некоторый граф, по которому вы двигаетесь в своей программе. То есть у вас есть развилки
[01:19:24.600 --> 01:19:30.760]  здесь, но на самом деле вы идете только по одной ветке, конечно. И вот ваше исполнение это некоторая
[01:19:30.760 --> 01:19:40.680]  цепочка в этом графе, и она представлена в физических виде Callstack. А теперь где-то с вами
[01:19:40.680 --> 01:19:48.680]  происходит неприятность, возникает ошибка, и вам нужно ее обработать. Ну обрабатывать вы будете,
[01:19:48.680 --> 01:19:53.400]  скорее всего, и не здесь, где она возникла, а где-то выше, где вот можно ее обработать. И вам нужно
[01:19:53.400 --> 01:20:02.080]  ее передать наверх. И вот смотрите, здесь мы пользуемся тем, что у нас есть структура,
[01:20:02.080 --> 01:20:09.200]  что координаты в исполнении программы представлены Callstack.
[01:20:09.200 --> 01:20:17.440]  И тут возникает механизм исключений. Исключения позволяют передать ошибку до места обработки,
[01:20:17.440 --> 01:20:25.720]  при этом скрыть всю внутреннюю механику. Это ведь, ну я вот говорю пока про довольно абстрактные
[01:20:25.720 --> 01:20:30.760]  вещи, которые как-то с конкарнцией не связаны, но вот сейчас их нужно связать хотя бы вот формально.
[01:20:30.760 --> 01:20:38.600]  У нас была проблема со стоп-токенами, что мы их таскали вручную. Вот, а потом мы подумали,
[01:20:38.640 --> 01:20:45.360]  что можно как-то хитрее сделать. И вот сейчас с исключениями та же самая история. Не нужно таскать
[01:20:45.360 --> 01:20:51.640]  ошибки вручную, можно довериться runtime, который сам пронесет ошибку в нужное место, потому что
[01:20:51.640 --> 01:20:56.480]  есть структура. И что самое важное, за счет того, что у нас есть структура, за счет того, что у нас
[01:20:56.480 --> 01:21:03.800]  есть деструкторы, то вместе с обработкой, вместе с передачей этой ошибки выше, мы сможем и ресурсы
[01:21:03.800 --> 01:21:10.280]  освободить. А нам это важно. Мы говорили, что нам нужно обеспокоиться про ресурсы, когда мы
[01:21:10.280 --> 01:21:17.720]  отправляем там два параллельных запроса. Вот exception. Механизм, конечно, несовершенный, у механизма
[01:21:17.720 --> 01:21:21.640]  большой overhead. Вы про это знаете, что некоторые проекты оптимизируют exception и не используют их
[01:21:21.640 --> 01:21:26.920]  вообще. Вот Google стал гадить, что они запрещены. Но сейчас вопрос не о максимальной эффективности,
[01:21:26.920 --> 01:21:32.400]  а о том, что структура позволяет такие вещи делать, скрывать эту внутреннюю механику,
[01:21:32.400 --> 01:21:40.560]  от пользователей делать прозрачной все это. Делать ее прозрачной. А теперь, собственно,
[01:21:40.560 --> 01:21:52.720]  имея этот контекст, можно перейти к нашим баранам, а именно к Go. Вот в чем проблема Go2? В том,
[01:21:52.720 --> 01:22:00.960]  что структура передачи управления становится какой-то произвольной. Go — это такой асинхронный
[01:22:00.960 --> 01:22:07.880]  Go2, где мы продолжаем сами бежать, но просто запускаем еще какой-то асинхронный управление,
[01:22:07.880 --> 01:22:15.280]  асинхронный поток, который там тоже как-то дальше двигается. Совершенно хаотично. Почему это проблема?
[01:22:15.280 --> 01:22:28.560]  Потому что вот в этом Go могут возникать ошибки. И ошибки, когда мы что-то распараллеливаем — это
[01:22:28.560 --> 01:22:40.040]  вообще беда. Потому что представьте себе, что вы пишете обработчик запроса, где вы параллельно
[01:22:40.040 --> 01:22:46.880]  задаете два подзапроса в разные сервисы на разные машины. А дальше вам нужно дождаться оба этих ответа.
[01:22:46.880 --> 01:22:58.320]  И, допустим, вот запросы тяжелые, они долго работают, отнимают какие-то ресурсы у подсистем,
[01:22:58.320 --> 01:23:16.200]  но оказывается так, что вот в поддереве А что-то пошло не так. И оттуда прилетела... и там
[01:23:16.200 --> 01:23:25.240]  случилась ошибка. Что бы мы хотели сделать? Мы бы хотели отменить B. Ну, то есть смотрите,
[01:23:25.240 --> 01:23:33.040]  дело немного сложнее. Вот я на этих рисунках говорил, что вот просто либо сверху отменяем,
[01:23:33.040 --> 01:23:39.040]  либо снизу собираем результаты. Но вообще-то бывают и более сложные сценарии, когда у нас
[01:23:39.040 --> 01:23:43.280]  просто где-то в середине нашего графа возникла такая ситуация, что вот здесь возникла ошибка,
[01:23:43.280 --> 01:23:49.120]  и поэтому здесь нужно отменить. То есть отмена, она случается не прямо в корне. То есть она может
[01:23:49.280 --> 01:23:54.480]  случиться в корне, разумеется, но не обязательно там. Она может случиться где-то здесь. Точнее,
[01:23:54.480 --> 01:23:58.800]  она логически может случиться где-то здесь, потому что вот тут отменится... тут случится ошибка.
[01:23:58.800 --> 01:24:10.200]  Но нужно же как-то вот из ошибки здесь, в этом поддереве, получить отмену здесь, в этом поддереве.
[01:24:10.200 --> 01:24:23.400]  А для этого нужно воспользоваться той же самой идеей, что была здесь, а именно структурировать
[01:24:23.400 --> 01:24:31.080]  нашу асинхронность. Вот в таком графе всегда очень просто всё. Есть точка входа и точка выхода.
[01:24:31.080 --> 01:24:38.360]  Вот чтобы там в середине не случалось, есть одна точка входа, и потом всё это как бы
[01:24:38.360 --> 01:24:44.240]  смыкается. Даже если есть развилка логическая, то всегда есть один выход после неё. Или вызов
[01:24:44.240 --> 01:24:52.040]  под программу. Мы хотим сделать следующее. Мы хотим сделать то, что называется structured
[01:24:52.040 --> 01:25:03.720]  programming, а мы сейчас хотим structured concurrency. Собственно, это тема нашей лекции. Мы хотим,
[01:25:03.720 --> 01:25:11.000]  чтобы если что-то распараллеливается в нашей программе, то дальше обязательно была бы точка,
[01:25:11.000 --> 01:25:16.760]  где был бы написан join. То есть если мы что-то запускаем параллельно, то мы в будущем обязательно
[01:25:16.760 --> 01:25:24.840]  явно дожидаемся завершения этих параллельностей. Если мы запускаем файбер, то мы должны явно
[01:25:24.840 --> 01:25:30.480]  сделать join всегда. Если мы запускаем три файбера, то мы всегда должны сделать join всех трёх файберов.
[01:25:31.440 --> 01:25:38.160]  Поэтому мы го хотим запретить в принципе. Почему это важно? Смотрите, давайте сначала на примере
[01:25:38.160 --> 01:25:53.200]  фьюч. Тут сразу всё станет понятно. Вот у нас есть комбинатор all. Давайте я покажу пример сейчас.
[01:25:53.200 --> 01:26:02.680]  Вот у нас есть два RPC вызова параллельных, две фьюча. И вот есть два кода. Дожидаемся синхронно одного
[01:26:02.680 --> 01:26:08.880]  ответа, дожидаемся синхронно другого ответа. Блокируем, останавливаем файбер. А есть вот такой код,
[01:26:08.880 --> 01:26:17.600]  где мы сначала строим одну фьючу из двух, а потом синхронно дожидаемся её. Вот выглядит так как будто
[01:26:17.600 --> 01:26:22.000]  бы одно и то же, потому что мы дожидаемся в любом случае двух ответов. Какая разница как, да?
[01:26:22.000 --> 01:26:31.200]  Зачем нам лишнее фьюча? С точки зрения успешного сценария разницы нет. А с точки зрения сценария,
[01:26:31.200 --> 01:26:37.440]  где возникают ошибки, разницы есть. Почему? Потому что если эта операция тяжёлая, а здесь возникла
[01:26:37.440 --> 01:26:45.440]  ошибка, то мы в любом случае эту операцию завершим. А если бы у нас был комбинатор all,
[01:26:45.440 --> 01:26:51.040]  который и является таким join, то есть точка, где мы соединяем. Вот мы здесь сделали что-то
[01:26:51.040 --> 01:26:59.120]  параллельно, разветвили граф, а в эти точки мы его соединяем обратно. И вот в этом комбинаторе мы
[01:26:59.120 --> 01:27:08.320]  можем написать вот такую логику. Если из-под дерева А прилетела ошибка, то с одной стороны мы её
[01:27:08.320 --> 01:27:15.920]  пропагетим наверх, ну потому что all разломан, а с другой стороны мы можем отменить другого ребёнка,
[01:27:15.920 --> 01:27:23.600]  который всё ещё работает. И если посмотреть на код, как это можно написать в комбинаторах,
[01:27:23.600 --> 01:27:26.920]  то там буквально так и будет написано.
[01:27:26.920 --> 01:27:43.960]  Файберы, фьючи, комбинатор, all. Вот, пожалуйста, если возникла ошибка, то я с
[01:27:43.960 --> 01:27:52.440]  одной стороны отправляю её наверх, а с другой стороны я отправляю сигнал отмены вниз.
[01:27:57.400 --> 01:28:03.560]  Очень красивый код получается, он буквально отражает эту картинку. А если у нас комбинатор first
[01:28:03.560 --> 01:28:09.520]  off, то похожая история. Если мы получили хотя бы один результат, нам второй уже не нужен, и мы
[01:28:09.520 --> 01:28:15.320]  отправляем отмен. Вот, и можно этим всем воспользоваться и написать уже пример.
[01:28:15.320 --> 01:28:19.720]  Посмотреть на пример.
[01:28:19.720 --> 01:28:23.720]  Вот first off.
[01:28:23.720 --> 01:28:35.240]  Секундочку.
[01:28:47.080 --> 01:28:50.320]  Почему... А, я написал где-то комментарий, он теперь пересобирается в библиотеку. Понятно.
[01:28:50.320 --> 01:29:01.920]  Я здесь запускаю, получаю две фьючи, которые делают какую-то работу в трейдпуле, спят там
[01:29:01.920 --> 01:29:10.320]  периодически секунду и проверяют стоп токен. И я говорю на этих фьючах first off, а потом дожидаюсь
[01:29:10.320 --> 01:29:19.560]  синхронно. И вот этот код, он мог бы работать... Ну, он будет работать, понятно, как бы время
[01:29:19.560 --> 01:29:25.880]  меньшее из двух задач. Здесь мы делаем спин три секунды, здесь мы спим десять секунд, в
[01:29:25.880 --> 01:29:31.800]  лучшем случае. И у меня в конце кода написано wait idle, то есть я все-таки дожидаюсь всех запущенных
[01:29:31.800 --> 01:29:38.440]  задач. Но, тем не менее, код будет работать только три секунды, потому что первая выполнится эта
[01:29:38.440 --> 01:29:47.240]  фьюча, она заполнит результат, и после этого set value в комбинаторе first off, через комбинатор,
[01:29:47.240 --> 01:29:53.080]  который стоит за этой фьючей, отправится сигнал отмены в эту операцию, и она тоже отменится,
[01:29:53.080 --> 01:29:59.320]  и вычисления десять секунд идти не будет. Ну, представьте себе в этом месте два RPC вызова и
[01:29:59.320 --> 01:30:03.720]  вот какие-то развесистые графы в распыленной системе, все это понятно.
[01:30:03.720 --> 01:30:18.120]  Сейчас, подожди, здесь проверка вообще явная. Здесь мы явно проверяем.
[01:30:18.120 --> 01:30:31.080]  Здесь никакой скрытой механики нет. Ну ладно, к концу минут пять и соберется все это. Пока это,
[01:30:31.080 --> 01:30:40.880]  например, запускается, речь про файберы. Вот статья про structured concurrency, вот эта вот
[01:30:40.880 --> 01:30:49.000]  знаменитая, она не про фьюч, тут про фьюча ничего нет, она про файберы. Ну, точнее, про
[01:30:49.000 --> 01:30:55.880]  про гоуту, то есть про такую, про там крутины, про файберы, и тут вводится понятие nursery,
[01:30:55.880 --> 01:31:09.840]  nursery или yasli. Идея такая, тут даже картинка есть, сейчас я ее покажу. Все, что мы запускаем в
[01:31:09.840 --> 01:31:14.680]  nursery должно, то есть nursery, он связан с некоторым скопом лексическим, то есть мы в блоке
[01:31:14.680 --> 01:31:21.640]  создаем nursery, при выходе из блока мы должны явно дождаться завершения всех активностей внутри
[01:31:21.640 --> 01:31:28.200]  nursery, всех файберов, которые мы там запустили. То есть всегда мы дожидаемся файберов. Это после
[01:31:28.200 --> 01:31:32.640]  его выглядит довольно неинтуитивно, но да, вот кстати, можно, например, запустить теперь и
[01:31:32.640 --> 01:31:45.600]  посмотреть, что он работает. Там 3 секунды 301, 302, 303, 304. Готово. Не 10 секунд. После go это выглядит
[01:31:45.600 --> 01:31:50.400]  довольно неинтуитивно, что мы дожидаемся каждой запущенной активности, но вот нам говорят,
[01:31:50.400 --> 01:32:00.320]  это structured concurrency, так нужно делать. И как это будет работать, как это будет выглядеть сначала?
[01:32:00.320 --> 01:32:08.920]  Вот так вот. Мы берем nursery, в нем запускаем две задачи. Одна из них работает 2 секунды,
[01:32:08.920 --> 01:32:20.240]  потом взрывается, другая работает бесконечно. И вот мы говорим nursery join. За счет этого nursery
[01:32:20.240 --> 01:32:29.600]  опять пример будет работать 2 секунды, потому что этот файбер взорвется, в нем вылетит ошибка.
[01:32:29.600 --> 01:32:43.280]  Эта ошибка пролетит до самого корня файбера. Нет, не сюда. Вот сюда она пролетит. То есть мы
[01:32:43.280 --> 01:32:54.640]  вызвали здесь крутина резюм, и в этом резюме случился exception. Этот exception пролетел сюда,
[01:32:54.640 --> 01:33:02.720]  это был не cancel, и нам вроде нужно упасть. Но это раньше бы мы упали, если бы просто файбер
[01:33:02.720 --> 01:33:10.360]  запущенный через go, мы бы упали. Но теперь мы не знаем, что делать, и мы поручаем это решение
[01:33:10.360 --> 01:33:18.160]  супервизору. Супервизор решает, как обработать нашу ошибку. Когда мы запускаем файбер, мы ему
[01:33:18.160 --> 01:33:27.800]  отдаем супервизор. Это компонент, который следит за файберами и обрабатывает их завершение,
[01:33:27.800 --> 01:33:36.080]  либо успешное, либо отмененное, либо ошибка. И nursery для файберов является супервизором. И что там
[01:33:36.080 --> 01:33:43.920]  написано? Ну, во-первых, когда мы... во-первых, у nursery есть stop token. Точнее, у nursery есть stop
[01:33:43.920 --> 01:33:56.840]  source. Все файберы, которые запускаются в nursery... вот мы запускаем... аккуратнее... вот мы запускаем...
[01:33:56.840 --> 01:34:09.680]  запускаем... очень медленно... вот мы запускаем файбер. Мы строим токен от своего stop source. И
[01:34:09.680 --> 01:34:17.480]  если вдруг файбер решит сломаться в нашем nursery какой-то, то в этом случае мы на stop source
[01:34:17.480 --> 01:34:23.680]  этого nursery скажем request stop, и он отменит все файберы, которые в данном скопе выполнялись.
[01:34:23.680 --> 01:34:32.680]  И тут можно писать какие-то, не знаю, более сложные ивристики. Писать там, не знаю,
[01:34:32.680 --> 01:34:38.160]  буквально... почему супервизор? Эта идея, вообще, она из... откуда? Знаете ли вы, откуда она?
[01:34:45.320 --> 01:34:48.760]  Есть ли у меня должна быть где-то хорошая ссылка?
[01:34:53.680 --> 01:35:02.940]  Из Erlang, конечно. Потому что Erlang — это язык, который разрабатывался с идеей, что вот нужно
[01:35:02.940 --> 01:35:08.200]  думать про отказы устойчивость прямо на уровне там дизайна самого языка, дизайна конкурентности в
[01:35:08.200 --> 01:35:13.280]  нём. И вот супервизор — это компонент, который наблюдает как бы за дочерними подзадачами и
[01:35:13.280 --> 01:35:17.720]  перезапускает их, если они ломаются. Вот у нас nursery отменяет, а могла бы перезапускать. Ну,
[01:35:17.720 --> 01:35:23.120]  то есть вот можно любую логику писать. И опять, у нас есть join — это nursery. nursery — это объект,
[01:35:23.120 --> 01:35:26.320]  который представляет собой join запущенных параллельных файберов. И за счёт того,
[01:35:26.320 --> 01:35:29.680]  что этот join есть, мы в нём можем покэнцелить соседей.
[01:35:38.520 --> 01:35:47.560]  Да, давайте я вот ещё пример не показал. Покажу его. Это... ну, можно делать это рекурсивно. Это ладно.
[01:35:47.560 --> 01:35:49.120]  Можно...
[01:35:57.560 --> 01:36:02.080]  Можно делать вообще сложные вещи. Вот давайте я покажу, как всё это можно комбинировать. Вот всё,
[01:36:02.080 --> 01:36:07.320]  что я рассказал, прости, можно комбинировать в один пример. Но он довольно замороченно написан,
[01:36:07.320 --> 01:36:13.600]  не слишком аккуратно. Но я объясню, что происходит здесь. Смотрите, у нас есть пара future promise.
[01:36:13.600 --> 01:36:28.880]  Мы здесь создаём задачу в пуле, где мы что-то вычисляем, пока не отмениться. Потом мы на эту
[01:36:28.880 --> 01:36:37.400]  future наворачиваем с помощью zena продолжение. Потом мы строим nursery. В нём мы запускаем файбер,
[01:36:37.400 --> 01:36:47.200]  который синхронно блокируется в ожидании future. То есть у нас есть такие разные точки связывания.
[01:36:47.200 --> 01:36:55.000]  Есть zen, есть await, есть nursery. А потом мы говорим nursery cancel. И что происходит?
[01:36:55.000 --> 01:37:10.440]  nursery cancel cancels its stop source. Этот stop source, когда мы спаунили файбер, этот stop source
[01:37:10.440 --> 01:37:19.720]  породил токен, который мы отдали этому файберу. Когда мы говорили файбер await future, то... ну,
[01:37:19.720 --> 01:37:27.920]  это не здесь написано, это написано в коде await для future. Когда мы ждали future, то мы, подписавшись
[01:37:27.920 --> 01:37:35.080]  на возобновление себя, подписавшись на future, чтобы возобновить себя, мы после этого заодно
[01:37:35.080 --> 01:37:49.520]  склинковали собственный токен с stop source future. Вот. Этот stop source future был склинкован с stop state
[01:37:49.520 --> 01:37:56.200]  future, был склинкован со stop state future f1. И в конце концов это всё здесь проверялось. И вот когда я сделал
[01:37:56.200 --> 01:38:04.600]  cancel, то я вот по такой цепочке спустил отмену h вот сюда. Эта операция завершилась. Она закомплетила
[01:38:04.600 --> 01:38:13.840]  эту future. Эта future закомплетила эту future. Эта future отпустил этот файбер. Этот файбер наконец
[01:38:13.840 --> 01:38:25.280]  завершился, и в destructory nursery завершился join. И пример доработал. Вот. На мой вкус довольно
[01:38:25.280 --> 01:38:34.920]  впечатляющая конструкция, потому что в этом коде нет никаких аннотаций для отмены. Нигде
[01:38:34.920 --> 01:38:44.200]  нет явного пропагейта. Вот вся механика скрыта, всё работает. Ну, тут можно было ещё first-off и
[01:38:44.200 --> 01:38:50.680]  какие-то навернуть. Ну, в общем, всё это работает абсолютно прозрачно для пользователя, и ему нужно
[01:38:50.680 --> 01:38:55.320]  лишь поддержать отмену там, где он готов к этому. В смысле там, где он готов что-то отменить, он
[01:38:55.320 --> 01:39:03.480]  проверяет токен, и... А дальше всё распространяется автоматически. Ну вот, всё поотменялось.
[01:39:03.480 --> 01:39:17.760]  Пример завершился. И ключевая идея здесь... Ну, тут... Что? Хочешь закончить уже, да? Пять минут
[01:39:17.760 --> 01:39:21.880]  осталось. Пять минут осталось, честно. Но я не хочу это разрывать. Это очень сложный доклад,
[01:39:21.880 --> 01:39:28.920]  но рассказ, он очень долго у меня выдумывался, я хочу довести его до логического конца честно,
[01:39:28.920 --> 01:39:38.040]  пять минут. Какие ключевые идеи здесь были? Ну, во-первых, мне кажется, что вот эта идея довольно
[01:39:38.040 --> 01:39:44.360]  любопытна, что нужно посмотреть на фьюч и на промесы как на просто двойственную сущность и вот
[01:39:44.360 --> 01:39:52.360]  как на две системы противонаправленные кроме нас. А вторая идея в том, что вот нужно такую картинку
[01:39:52.360 --> 01:39:58.200]  понять, что вот не просто сверху вниз и снизу вверх, а вот как-то более сложно течут эти сигналы
[01:39:58.200 --> 01:40:05.040]  по графам. И для того, чтобы... То есть что Structural Concurrency нам говорит сейчас? Что если у вас за
[01:40:05.040 --> 01:40:12.440]  любой развилкой есть join, то где бы ошибка не возникла, она распространяется наверх,
[01:40:12.440 --> 01:40:19.160]  распространяется... Она, распространяясь наверх, распространяет сигнал отмены и в стороны. И вот
[01:40:19.160 --> 01:40:25.400]  поднимаясь как бы от ошибки вверх до корня, вы гарантированно покроете отменами весь граф.
[01:40:25.400 --> 01:40:34.000]  За счет того, что у вас есть join, и вот ничто не потеряется. Вот где бы в графе ошибка не возникла,
[01:40:34.000 --> 01:40:43.400]  весь граф может автоматически отмениться с помощью вот этих норсерей и комбинаторов. Очень красивая
[01:40:43.400 --> 01:40:49.560]  идея, которая берется совершенно из глубокого прошлого. Тут нужно было это увидеть, это почувствовать,
[01:40:49.560 --> 01:40:58.160]  связать. Идея очень простая, очень естественная, но как бы придумана была она не сразу. Есть чудесная
[01:40:58.160 --> 01:41:03.880]  статья, в которой это написано. Это Structural Concurrency. Честно говоря, я читал ее давно, ничего не понял,
[01:41:03.880 --> 01:41:10.480]  потому что акценты там как-то по-другому совершенно расставлены. Но попробуйте,
[01:41:10.480 --> 01:41:15.040]  прочитайте. Мне кажется, что ключевые идеи... Вот нужно вот такие картинки нарисовать. Нужно
[01:41:15.040 --> 01:41:20.960]  сделать сначала Future, понять вот это, потом сделать для Future вот такие вот комбинаторы,
[01:41:20.960 --> 01:41:27.240]  которые умеют такие штуки делать, а потом уже идея вот здесь, она станет полностью понятна.
[01:41:27.240 --> 01:41:37.040]  И эта идея очень мощная, и она повлияла буквально на весь современный мир, потому что... Ну смотрите,
[01:41:37.040 --> 01:41:46.920]  вот DesignDoc файберов, которые делают в джабе. Делают Structural Concurrency. Вот DesignDocSwift.
[01:41:46.920 --> 01:41:58.360]  Делают Structural Concurrency. Ну или сделали уже, по-моему. Есть очень классный доклад Романа Иризарова
[01:41:58.360 --> 01:42:04.400]  про Kotlin, про то, как они делали конкуренции, карутины. И он рассказывает не просто, к чему они
[01:42:04.400 --> 01:42:12.480]  пришли, а вот то, как они над этой задачей бились. И вот в это же время был придуман термин для нее,
[01:42:12.480 --> 01:42:19.200]  и вот у них все сошлось, в общем. Это то, что делать научились совсем недавно, и вот сейчас во всех
[01:42:19.200 --> 01:42:25.680]  местах. Ну, как недавно. Вот в Скале сделали давно уже. Вот в IT, в Яндексе тоже Future's Council,
[01:42:25.680 --> 01:42:33.440]  кажется, давно. Ну вот как бы лексику и какое-то распространение этой идеи получила совсем-совсем
[01:42:33.520 --> 01:42:39.120]  недавно. А идея кажется очень важной, потому что без нее, в самом деле, невозможно представить
[01:42:39.120 --> 01:42:46.600]  себе некую продакшн. Ну что, мы закончили. Спасибо большое, что вы пришли сегодня,
[01:42:46.600 --> 01:42:53.360]  послушали. Для меня это очень важно. Я долго это все переваривал сам. Если было понятно, то здорово.
[01:42:53.360 --> 01:42:54.720]  Значит, у нас получилось.
