[00:00.000 --> 00:11.600]  У меня с прошлого раза остался долг. Мы закончили на форд-белмане. Давайте
[00:11.600 --> 00:20.200]  напомню лему, которую мы доказали в конце прошлого раза, что если сделать
[00:20.200 --> 00:32.960]  n итераций в алгоритме форд-белмана, то для каждого отрицательного цикла,
[00:32.960 --> 00:38.480]  достижимого из той s, из которой мы запускаем форд-белмана, хотя бы у одной вершинки уменьшится значение dp.
[00:38.480 --> 00:51.080]  То для любого отрицательного цикла, достижимого из с, из той вершинки,
[00:51.080 --> 00:56.880]  от которой мы считаем все расстояния, существует некоторая вершинка, до которой dp уменьшится.
[00:56.880 --> 01:10.680]  Вот это мы доказали в прошлый раз. Теперь, как это использовать? Зачем нам это нужно?
[01:10.680 --> 01:17.520]  Использовать очень просто. Смотрите, если у нас на каждом цикле есть вершина, на которой dp уменьшилось,
[01:17.520 --> 01:20.600]  значит, мы в каком-то смысле нашли все отрицательные циклы. По крайней мере,
[01:20.600 --> 01:24.880]  на каждом отрицательном цикле у нас хотя бы одна вершинка выделена. Та, на которой dp уменьшилась,
[01:24.880 --> 01:33.200]  для той она обязана лежать на отрицательном цикле. Мы показали, что на каждом отрицательном цикле
[01:33.200 --> 01:36.600]  такая есть, но в обратную сторону тоже вернут. То есть, если для какой-то вершины это верно,
[01:36.600 --> 01:41.600]  такое неравенство верно, то она, конечно, лежит на отрицательном цикле. Или, по крайней мере,
[01:41.600 --> 01:45.520]  достижимой из отрицательного цикла. Потому что если здесь такое неравенство,
[01:45.520 --> 01:51.320]  значит, используя n ребер, можно найти более короткий путь, более дешевый путь, чем займаться
[01:51.320 --> 01:54.480]  с одной ребро. Значит, обязательно в этом пути есть циклы, значит,
[01:54.480 --> 01:59.160]  она достижима из s, используя хотя бы один цикл. Давайте замечание обратную сторону тоже верно.
[01:59.160 --> 02:21.040]  Если dp в n меньше, чем dp в n-1, то, ну, я такую картинку нарисую. И вот это
[02:21.040 --> 02:28.520]  отрицательный цикл. Это мы обсуждали в прошлый раз. То есть, если вдруг путь длины n оказался
[02:28.520 --> 02:34.120]  дешевле пути длины n-1, значит, ну, в этом пути обязательно есть какой-то цикл, и он обязательно
[02:34.120 --> 02:37.840]  отрицательный. Ну, в смысле, есть отрицательный цикл, потому что, если бы он был не отрицательным,
[02:37.840 --> 02:43.360]  мы бы могли обрезать, получить более короткий путь, и тогда dp не уменьшилось. Поэтому тем самым
[02:43.360 --> 02:48.440]  для всех вершинок, у которых это неравенство выполняется, они либо сами лежат на отрицательном
[02:48.440 --> 02:52.720]  цикле, причем на каждом таком цикле мы найдем хотя бы одну, либо они достижены из отрицательного
[02:52.720 --> 02:58.000]  цикла. Поэтому, если мы хотим найти все вершины, до которых расстояние минус бесконечность, то есть,
[02:58.000 --> 03:02.480]  ну, на самом деле, сколь угодно сильно его можно уменьшать, вот так вот, мотаясь по отрицательному
[03:02.480 --> 03:06.920]  циклу, это делать очень просто. Давайте просто из всех вершинок, у которых это dp-шка уменьшилось,
[03:06.920 --> 03:13.640]  запустим dfs, обойдем все, что из них можно, как бы, ну, достичь, обойдем все, что можно достичь,
[03:13.640 --> 03:17.840]  тогда для них для всех distance это минус бесконечность. А для всех остальных, кого мы не
[03:17.840 --> 03:23.080]  достигли, соответственно, таким dfs, dp, у нас найденное, ну, вот равное на ином слое минус первым,
[03:23.080 --> 03:36.160]  это есть ответ. Итак, для любой вершинки u, чему равно dist su? Значит, первый случай,
[03:36.160 --> 03:45.760]  dist su равно минус бесконечности, если существует какая-то v, вот с таким условием,
[03:45.760 --> 04:11.120]  и u достижимо из v. Ну, это очевидно, да, что если вдруг мы можем из v попасть в u, и при этом
[04:11.120 --> 04:15.400]  до v, ну, v сама лежит либо на отрицательном цикле, либо достижимо из отрицательного цикла,
[04:15.400 --> 04:19.120]  значит, мы можем сколь угодно много раз промотаться по этому отрицательному циклу,
[04:19.120 --> 04:23.000]  и, значит, до u дойти со сколь угодно маленьким расстоянием, ну, сколь угодно большим, по-моему,
[04:23.000 --> 04:28.080]  отрицательным. Значит, distance будет минус бесконечность. Ну, и второй, наоборот, если она не достижима ни
[04:28.080 --> 04:31.680]  из одной такой вершинки, то расстояние, соответственно, равно просто тому, чему мы посчитали на
[04:31.680 --> 04:47.920]  n-1-ой итерации. dist su равно dp u n-1 иначе. Потому что если мы понимаем, что эта вершина недостижима ни из
[04:47.920 --> 04:54.600]  одного отрицательного цикла, значит, самый короткий путь из s в u, он таких циклов не содержит,
[04:54.600 --> 04:58.960]  значит, он вообще циклов не содержит, поэтому это просто какой-то простой путь, содержащий
[04:58.960 --> 05:11.720]  не больше m-1-ое ребро. Иначе так как в этом пути нет циклов. Но раз в пути нет циклов, то мы знаем,
[05:11.720 --> 05:18.800]  что его длина не больше m-1, не больше m-1-ое ребро в нем. Отсюда рождается алгоритм. Если мы хотим
[05:18.800 --> 05:23.520]  для каждой вершины посчитать расстояние, вот в этом смысле, как dist, то есть либо какое число,
[05:23.520 --> 05:28.480]  либо минус бесконечность, тогда давайте просто запустим Форда Белману на n итерации. Дальше из
[05:28.480 --> 05:34.040]  всех вершин, для которых у меня расстояние уменьшилось на n итерации по сравнению с n-1,
[05:34.040 --> 05:39.200]  я запущу произвольный обход типа dfs или bfs, от чего угодно. Какой-нибудь обход,
[05:39.200 --> 05:44.840]  который пометит минус бесконечностями все вершины, которые из них достижимы. Значит,
[05:44.840 --> 05:50.560]  в них будет ответ, понятно, такой, ну а все которые мы не достигнем, у них ответ просто равен dp на
[05:50.560 --> 05:57.920]  n-1 итерации. Ну и оно же на самом деле равно на n итерации, но это уже не важно. В итоге алгоритм.
[05:57.920 --> 06:17.240]  Форд Белман на n итерации, дальше dfs из всех вершин, с тем самым неравенством.
[06:17.240 --> 06:26.280]  Посещенные вершины имеют расстояние минус бесконечности.
[06:26.280 --> 06:44.520]  Вот, ну а остальные, как я сказал, из dp-шки берутся на n-1 слое. Вот, получается, что здесь,
[06:44.520 --> 06:49.320]  что самое сложное. Конечно, самое сложное от Форд Белман, потому что он работает за nm. Дальше
[06:49.320 --> 06:54.880]  просто dfs, который работает за n плюс m, потому что нужно просто из многих вершин запуститься,
[06:54.880 --> 07:00.960]  пометить минус бесконечностями все достижимое. И, соответственно, после этого мы корректно
[07:00.960 --> 07:05.640]  знаем все дисты, потому что если там на самом деле должна была быть минус бесконечность, то она
[07:05.640 --> 07:09.520]  достижима из кого-то цикла, а на каждом цикле мы хотя бы одну вершинку пометили, значит ее тоже
[07:09.520 --> 07:14.800]  увидим. А если не минус бесконечность, значит циклов нету на пути, ну поэтому просто нам
[07:14.800 --> 07:20.720]  значение dp-шки у нас правильно посчитано. Вот, тем самым Форд Белман нам позволяет найти все
[07:20.720 --> 07:24.600]  расстояния корректно. Вопросы?
[07:39.520 --> 07:48.960]  Хорошо. Тогда переходим к сегодняшней теме. Это минимальная остовая.
[07:48.960 --> 08:05.680]  Начну сначала с пара определений. Во-первых, если у нас есть неориентированный граф,
[08:05.680 --> 08:15.880]  значит ну сегодня работаем только с неориентированными, сегодня только неориентированные.
[08:15.880 --> 08:26.360]  Значит пусть g неориентированный граф, тогда его под граф называется остовным,
[08:26.360 --> 08:46.680]  если он содержит все вершины графа g. Если v от h равно v от g. Вот, ну что такое,
[08:46.680 --> 08:52.200]  значит, что такое вот это выложение, что такое граф является под графом? Ну это в самом простом
[08:52.200 --> 08:56.240]  понимании, что у нас множество вершин графа h это какое-то под множество v, множество рёбер
[08:56.240 --> 09:02.880]  графа h это тоже какое-то под множество рёбер графа e. Короче, мы можем взять под множество вершин,
[09:02.880 --> 09:07.680]  под множество рёбер. Вот, и под граф называется остовным, если на самом деле мы взяли все вершины,
[09:07.680 --> 09:12.680]  если множество вершин графа h совпадает с множеством вершин исходного графа g. То есть если все
[09:12.680 --> 09:18.880]  вершинки оставили и подаляли только какие-то рёбра, это остовный под граф. Ну и соответственно,
[09:18.880 --> 09:22.440]  остовное дерево, это остовный под граф, который сам является деревом.
[09:22.440 --> 09:34.640]  Тогда остовный под граф
[09:34.640 --> 09:51.680]  называется остовным деревом, если он дерево.
[09:51.680 --> 10:13.360]  Так, ну дерево для нас это связанный граф без циклов, связанный граф без циклов.
[10:21.680 --> 10:44.360]  Ну, пример какой-нибудь нарисую. Вот был исходный g. Какой-нибудь такой. И в качестве
[10:44.360 --> 10:57.840]  остовного дерева можно взять, давайте обведу, вот, например, такой под граф. Я взял рёбра, понятно,
[10:57.840 --> 11:01.040]  что я тогда, соответственно, беру все вот эти вершины. То есть множество вершин совпадает
[11:01.040 --> 11:05.880]  с множеством вершин графа g, я все вершинки взял. Ну и взял ещё какие-то рёбра, вот эти вот четыре,
[11:05.880 --> 11:09.960]  так чтобы они образовывали дерево. То есть мы как бы обеспечиваем связанность между всеми вершинами,
[11:09.960 --> 11:14.640]  между всеми нашими пяти вершинами. И при этом циклов в нашем графе нет. То есть это вот в каком-то
[11:14.640 --> 11:18.640]  смысле какое минимальное число ребер можно оставить, чтобы оставить связанность, чтобы между
[11:18.640 --> 11:28.320]  любыми вершинами можно было добраться по ребрам графа h. Так, ну и соответственно, задача у нас
[11:28.320 --> 11:34.920]  на сегодня такая. По данному взвешенному, неориентированному графу найти остов минимального веса. То есть
[11:34.920 --> 11:45.720]  выбрать какой-то остов, в котором сумма весов ребер минимально возможна. В данном взвешенном графе
[11:45.720 --> 11:58.400]  найти остов. Ну я буду писать остов, потому что не лень писать остовное дерево, одно и то же
[11:58.400 --> 12:02.200]  минимального веса.
[12:15.720 --> 12:28.920]  Все алгоритмы, которые мы сегодня рассмотрим, они базируются на лемме безопасном ребре,
[12:28.920 --> 12:41.800]  который разрушусь следующим образом. Значит, смотрите, пусть мы строили-строили наш как-то
[12:41.920 --> 12:46.480]  минимальный остов, по ребрам ребра как-то к нему добавляли, и вот в какой-то момент мы получили некое
[12:46.480 --> 12:51.560]  подножие минимального остова. То есть мы как-то действовали и знаем, что текущее положение, когда мы
[12:51.560 --> 12:56.560]  набрали какой-то под граф, это под множество какого-то минимального остова. Тогда вот существует
[12:56.560 --> 13:00.280]  какое-то ребро, которое можно гарантированно добавить, и мы по-прежнему останемся под множество
[13:00.280 --> 13:21.680]  какого-то минимального остова. Значит, пусть g это граф, t это под граф g, являющийся также под множеством
[13:21.680 --> 13:32.880]  какого-то минимального остова. Ну, под графом давайте тоже скажу, под графом какого-то миностова.
[13:32.880 --> 13:48.280]  Давайте еще для удобства считаем, что t это дерево. Тогда если я рассмотрю самое дешевое ребро,
[13:48.280 --> 13:54.200]  соединяющего вершинку из t с произвольной вершиной не из t, то его можно будет добавить к t, оставив
[13:54.200 --> 13:58.960]  при этом все это подножие минимального остова. То есть картинка такая, вот было t, тут какое-то
[13:58.960 --> 14:04.000]  дерево нарисовано. Такое, что его можно продлить до ответа, до минимального остова. И есть все
[14:04.000 --> 14:10.240]  остальное, есть оставшийся граф g без t. Тогда если я рассмотрю самое дешевое ребро, соединяющие t
[14:10.240 --> 14:16.760]  вот с этим дополнением, то его можно будет добавить в t, это будет по-прежнему подножие
[14:16.760 --> 14:20.800]  минимального остова. То есть якобы мы подножие увеличил, сохранив свойство, что мы все еще,
[14:20.800 --> 14:29.160]  как бы, что текущий, текущий дерево можно продолжить до ответа. Так вот, пусть e это ребро
[14:29.160 --> 14:49.080]  минимального веса, соединяющие t и g-t. Тогда t плюс e тоже под граф минимального остова.
[14:59.160 --> 15:23.880]  Доказательства. Давайте рассмотрим вот тот минимальный остов, который является над графом
[15:23.880 --> 15:39.000]  для t. Как-нибудь бы его назвать s. Это миностов, содержащий t. В первом случае, если s содержит
[15:39.000 --> 15:49.920]  ребро e, то доказывать нечего. Если e принадлежит s, то доказывать нечего. Потому что понятно,
[15:49.920 --> 15:55.920]  что если мы рассмотрим t и добавим к этому графу ребро e, то мы по-прежнему останемся подножием
[15:55.920 --> 16:04.520]  минимального остова. Вот оно, собственно. Вот этот самый минимальный остов s. Иначе, пусть e
[16:04.520 --> 16:14.560]  соединяет вершинки u и v. Опять нарисую картинку. Вот есть дерево t, есть какое-то ребро e. Так,
[16:14.560 --> 16:36.960]  чуть побольше я хочу нарисовать. Пусть он соединяет вершинки u и v. Давайте считать,
[16:36.960 --> 16:43.360]  что e не лежит в s. Если e не лежит в s, то тем не менее, поскольку s это у меня остов, то есть
[16:43.360 --> 16:48.160]  дерево, то есть связанный граф, все равно есть некий путь между вершинками u и v. И причем он не
[16:48.160 --> 16:54.760]  совпадает с e, потому что ребра e в нашем s нет. Так вот, давайте рассмотрим путь между u и v.
[16:54.760 --> 17:08.880]  Рассмотрим путь между u и v в s. Мы знаем, что s это дерево, u и v это какие-то его две вершинки,
[17:08.880 --> 17:13.120]  значит между ними точно есть какой-то путь. Просто из-за связанности. Как может этот путь
[17:13.120 --> 17:19.200]  выглядеть? Ну, главная мысль в том, что этот путь когда-то пересекает этот разрез. То есть он
[17:19.200 --> 17:23.760]  обязательно когда-то перемещается из t в g-t. Ну, действительно, если он начинается в u, то он не
[17:23.760 --> 17:28.320]  может петлять здесь и попасть в v. Понятное дело, что ему нужно когда-то переместиться из одной доли
[17:28.320 --> 17:32.720]  в другую. Давайте я там что-нибудь нарисую. Вот он как-то так попетлял, пришел сюда. Возможно,
[17:32.720 --> 17:37.840]  тут еще походил, вернулся сюда, тут походил, вернулся сюда и здесь дошел до v. Короче, главное,
[17:37.840 --> 17:43.560]  что мы по крайней мере несколько раз пересечем вот это вот разделение между t и g-t. Тут я нарисовал
[17:43.560 --> 17:49.840]  когда три раза. Главное, что хотя бы один раз мы пересечем. Так, ну и что у меня получилось? У меня
[17:49.840 --> 17:54.480]  на самом деле получился некий цикл в исходном графе. У меня есть цикл, который содержит ребро
[17:54.480 --> 18:00.880]  e и несколько вот еще других ребер, которые пересекают разрез. Давайте рассмотрим произвольное
[18:01.000 --> 18:10.680]  ребро e', которое пересекает разрез и в этом цикле лежит. Пусть e' какое-то
[18:10.680 --> 18:29.960]  ребро на этом пути, причем e' пересекает разрез. Пересекает разрез, то есть его концы в разных
[18:29.960 --> 18:38.840]  половинках. Одна в t, другая в g-t. Дальше, где очень простая, мы знаем, что e по формулировке
[18:38.840 --> 18:44.640]  леммы, e это самый дешевый ребро, соединяющий t с g-t. Значит, вес e по крайней мере не больше,
[18:44.640 --> 18:52.320]  чем вес этого ребра e'. Значит, если мы просто ребро e' удалим, а вставим e, то наш остов как бы
[18:52.320 --> 18:55.880]  останется деревом, то есть мы связываемся и восстановим, а при этом стоимость могла только
[18:55.880 --> 18:59.880]  уменьшиться. Ну, не увеличится, потому что мы более тяжелое ребро поменяли на более легкое.
[18:59.880 --> 19:24.920]  Значит, есть остов, содержащий e. Ну и так, конечно. Рассмотрим наш остов s без ребра e',
[19:24.920 --> 19:41.680]  но с ребром e'. Вес не увеличился, так как e это самый дешевый ребро пересекающий разрез по условию.
[19:41.680 --> 19:49.040]  Ну и при этом у нас остается дерево, потому что, смотрите, число ребер у нас не поменялось,
[19:49.040 --> 19:53.800]  у нас мы одно убрали, одно добавили, и при этом связанность у нас сохранилась. То есть у нас,
[19:53.800 --> 19:59.040]  как бы, ну, представьте, да, вот я рассматриваю этот цикл, содержащий e и e', я одно ребро цикла
[19:59.040 --> 20:03.040]  удаляю, одно ребро цикла вставляю. Поэтому понятно, что все вершинки, лежащие на этом цикле,
[20:03.040 --> 20:08.920]  по-прежнему друг с другой достижимы, ну а все остальные достижимые, потому что, собственно,
[20:08.920 --> 20:13.280]  были достижимы друг с другом в s. То есть якобы мог сломать только что-то на этом цикле, но я
[20:13.280 --> 20:20.000]  его этот цикл чиню, да, добавив ребро e, поэтому связанность тоже никуда деться не могла. Вес не
[20:20.000 --> 20:31.720]  увеличился, а связанность не пропала, связанность сохранилась. Ну, собственно, все, значит, вот есть
[20:31.720 --> 20:38.440]  какое-то другое остовное дерево, веса, возможно, даже меньшего, которое содержит ребро e, победа.
[20:38.440 --> 20:47.640]  Это вот тот самый остов, который мы искали. Это остов, веса, ну, на самом деле он будет
[20:47.640 --> 20:51.120]  ровно такого же веса, потому что, если s был минимальный остов, то это не может быть веса
[20:51.120 --> 20:55.240]  меньше, значит, у них вес, ну, вес у него такой же, как у s. Получается, вот вам минимальный остов,
[20:55.240 --> 21:13.040]  который содержит e и при этом содержит t. Этот остов содержит t плюс e. Из этой леммы мы
[21:13.040 --> 21:20.960]  сразу можем реализовать алгоритм прима, который находит минимальный остов в графе. Собственно,
[21:20.960 --> 21:24.240]  просто многократно эту лему применить. Давайте считать, что у меня сначала дерево — это одна
[21:24.240 --> 21:28.520]  вершинка без ребер. Добавляем самое дешёвое ребро, которое из неё торчит во внешность графа.
[21:28.520 --> 21:34.120]  Добавили. Теперь дерево — это одно ребро. Опять рассматриваем все исходящие ребра, добавляем их
[21:34.120 --> 21:37.440]  самое дешёвое. Теперь у нас есть два ребра в остове и так далее. Просто по одному ребру
[21:37.440 --> 21:51.640]  добавляем, пока не получим n минус одно ребро. Алгоритм прима. Сначала мы считаем, что t — это
[21:51.640 --> 22:01.400]  одна вершина произвольная. И дальше просто n минус один раз применяем лему обезопасным
[22:01.400 --> 22:08.520]  ребрем. Просто каждый раз есть у нас t, есть у нас g без t. Среди всех этих ребер рассматриваем
[22:08.520 --> 22:30.960]  самое дешёвое и добавляем его к t. Применяем лему обезопасным ребре. Так, ну вот такой алгоритм.
[22:30.960 --> 22:39.200]  Что тут можно сделать с симпточками? Давайте поймём, как мы это будем делать
[22:39.200 --> 22:48.600]  за квадрат сначала. Чтобы находить минимальное ребро, пересекающее такой вот разрез,
[22:48.600 --> 22:52.960]  то есть среди всех таких ребер, мне нужно найти самое дешёвое, самое дешёвое по весу.
[22:52.960 --> 22:59.760]  Давайте я для этого, для каждой вершины вот в этой вот части, в g без t, буду хранить самое дешёвое
[22:59.760 --> 23:16.080]  ребро в неё торчащее. Пусть d от v — это минимальная стоимость ребра у v, такая, что ух ты, ну а у v — это ребро.
[23:16.080 --> 23:23.600]  У v — это ребро. То есть для каждой вершины вот в той вот части, которую я ещё не обработал, в g без t,
[23:23.600 --> 23:28.640]  я храню минимальное торчащее в неё ребро. То есть вот для этой вершинки я, скажем, храню такое
[23:28.640 --> 23:32.840]  ребро, для этой вот такое, для этой, ну короче, для каждой вершинки храню минимальный вес ребра.
[23:32.840 --> 23:40.320]  Дальше, если мне нужно выбрать самое дешёвое входящее сюда ребро, то я просто по ним про всем
[23:40.320 --> 23:44.840]  пробегаюсь и нахожу минимальное значение d. Если у меня есть минимальное входящее в каждую вершину,
[23:44.840 --> 23:48.520]  то просто беру из них минимум, это будет минимальное входящее во всю вот эту долю.
[23:48.520 --> 23:53.720]  Осталось научиться это пересчитывать при расширении t.
[23:58.640 --> 24:11.960]  Ну это делается так же, как на самом деле в алгоритме dxt. Потому что, смотрите, вот у меня было t.
[24:11.960 --> 24:17.400]  Дальше, я какое-то ребро нашёл самое дешёвое исходящее из него. Давайте я назову это u.
[24:17.400 --> 24:24.440]  И t расширил моим новым ребром. По сути, я добавил одну новую вершинку. Тогда вопрос,
[24:24.440 --> 24:29.840]  как выглядят d от v для всех вершинок, лежащих в g без t. То есть вот я t расширил, как поменялись d.
[24:29.840 --> 24:34.640]  Ну понятно, мне достаточно просто рассмотреть ребра исходящие из u и попробовать обновить
[24:34.640 --> 24:40.520]  дешки, как бы пререлаксировать d для каждой вершины через стоимость вот этих ребр исходящих из u.
[24:40.520 --> 24:46.600]  Потому что других ребр не появилось в входящих в вершинке g без t. Ну собственно, мы просто их все
[24:46.600 --> 24:58.960]  обрабатываем и насчитываем правильно d от v. Если u добавляется в t, то мы делаем следующее.
[24:58.960 --> 25:07.280]  Для любого ребра uv мы выполняем обновление, что d от v это минимум из того, что там уже лежало,
[25:07.280 --> 25:18.800]  и стоимость этого ребра. Потому что вот если я какую-то вершинку v рассмотрю, то для нее какие
[25:18.800 --> 25:24.120]  есть в нее входящие ребра? Они либо раньше вели из t, ну то есть из вот этой части v, но они уже
[25:24.120 --> 25:28.480]  и так учтены. Единственное новое ребро, которое могло появиться, это ребро из u в v. Ну давайте я
[25:28.480 --> 25:41.440]  просто им мою дешку обновлю. Поэтому алгоритм очень похож на алгоритм dx. У меня есть для каждой
[25:41.440 --> 25:47.680]  вершинки какое значение d, есть вершинки, которые я уже обработал, которые уже лежат в t, есть
[25:47.680 --> 25:52.480]  необработанные. Тогда я на каждом шаге, среди всех необработанных, нахожу вершинку с минимальным
[25:52.480 --> 25:58.560]  d, отношу ее в множество обработанных, то есть как бы добавляю в дерево, а затем вот это вот у,
[25:58.560 --> 26:03.960]  я ее отнес в t, и дальше рассматриваю все ребра, исходящие из u, и обновляю значение d для
[26:03.960 --> 26:08.360]  концов всех этих ребер. Прям супер как в dx, ровно так же, только здесь немножко другая формула
[26:08.360 --> 26:14.680]  пересчета для d, для вот этого самого дешевого ребра, входящего в вершинку v. Вот, ну и отсюда
[26:14.680 --> 26:25.000]  собственно получается симптатика n квадрат, потому что мне нужно n-1 раз найти самое дешевое
[26:25.000 --> 26:30.320]  ребро, вершинку с минимальным вот этим вот значением d, это n квадрат, то есть мне нужно n раз найти
[26:30.320 --> 26:34.840]  минимум среди n элементного множества. И затем еще вот эти обновления, но понятно, что обновления
[26:34.840 --> 26:41.000]  суммарно работают за m, за от m, потому что каждая вершина ровно один раз добавится в t, значит
[26:41.000 --> 26:46.520]  каждое такое ребро просмотрится ровно один раз, ну окей, два раза, потому что у нас граф не
[26:46.520 --> 26:50.520]  ориентированный, то есть мы рассмотрим ребро вот так вот и вот так вот, ну ничего страшного,
[26:50.520 --> 26:56.520]  за два m это будет работать. Поэтому все эти обновления работают за время от m, ну и мы считаем,
[26:56.520 --> 27:00.920]  что если в графе нет кратных ребер, то конечно m меньше чем n квадрат, поэтому это главное слагаемое.
[27:00.920 --> 27:21.240]  Вот, алгоритм за квадрат. Вопросы. Так, ну и тогда здесь же можно сказать, что давайте мы вместо вот
[27:21.240 --> 27:27.160]  этого тупого алгоритма за квадрат можем делать что-нибудь с кучей. За m лог n, так же как в dx-3,
[27:27.160 --> 27:37.680]  можно сделать с помощью кучи, бинарная куча. Потому что, повторюсь, нам нужна структура,
[27:37.680 --> 27:45.760]  которая хранит в себе вот эти вот дэшки, умеет извлекать минимум и уменьшать значение. А именно,
[27:45.760 --> 27:53.040]  что мне нужно n раз сделать экстракт мин, ну там n-1, n раз сделать экстракт мин и m раз сделать
[27:53.040 --> 28:05.120]  криски. Ну это вот в точности бинарная куча. Либо же, опять, если мы вдруг умеем писать себе
[28:05.120 --> 28:29.560]  на чую кучу, то здесь будет симптомика m плюс n лог. Потому что, смотрите, каждая вишина u добавится в t
[28:29.560 --> 28:33.600]  ровно один раз. Значит, когда у меня вообще происходят декризы, когда я добавляю какую-то
[28:33.600 --> 28:37.920]  вишинку в t, и мне нужно рассмотреть все исходящие из нее ребра и для них, для всех,
[28:37.920 --> 28:43.320]  попробовать обновить d от v. Значит, вдоль каждого ребра декриз будет проходить ровно один раз,
[28:43.320 --> 28:48.840]  когда один из его концов первым попал в t. Значит, декризов с небольшими ребер.
[28:48.840 --> 29:09.840]  Так, хорошо, тогда едем к следующему алгоритму, алгоритму Крускала. Тоже еще один алгоритм просто
[29:09.840 --> 29:19.720]  поиска минимального астова. Он работает следующим образом. Давайте мы сначала все ребра отсортируем в
[29:19.720 --> 29:30.120]  порядке возрастания весов. Отсортируем все ребра в порядке возрастания весов.
[29:39.840 --> 29:47.440]  Дальше будем проходиться в этом порядке по ним и считать, что изначально у нас подграф пустой,
[29:47.440 --> 29:52.160]  то есть у нас есть все вишинки, нет ни одного ребра, то есть не взято ни одно ребро. Дальше я
[29:52.160 --> 29:55.920]  прохожусь по этому списку и добавляю ребро в наш подграф, если оно не образует циклов.
[29:55.920 --> 30:00.640]  То есть вот изначально у меня есть такая картинка, скажем, я изначально добавляю
[30:00.640 --> 30:06.360]  самое дешевое ребро, ну просто первое в этом порядке. Потом вижу второе ребро, добавляю его,
[30:06.360 --> 30:12.640]  потом вижу третье ребро. Если оно вдруг образует цикл, то я его не беру. Нам нет смысла брать в астов
[30:12.640 --> 30:17.840]  ребра, образующие циклы. Поэтому если ребро такое, то я его просто скипаю. Третье пропускаю,
[30:17.840 --> 30:22.120]  смотрю четвертое. Четвертое, например, такое, оно опять не образует циклов, то есть соединяет
[30:22.120 --> 30:27.040]  какие-то две несвязанные вершинки до этого. Вот и в момент, когда мы, собственно, связали все вершинки
[30:27.040 --> 30:40.560]  в одну компоненту, мы заканчиваемся. Ну давайте напишем так. Добавляем ребра в этом порядке,
[30:40.560 --> 31:02.960]  не допуская циклы. Вот, и тут вопрос, как это делать, как проверять, что то ребро,
[31:02.960 --> 31:09.520]  которое я сейчас рассматриваю в списке всех ребер, оно хорошее, оно не образует циклы,
[31:09.520 --> 31:15.040]  если его добавлю в мой текущий подграф. Для этого нам нужна будет вспомогательная структура данных,
[31:15.040 --> 31:21.760]  системы не пересекающихся множеств, которая нам позволит на все эти запросы быстро отвечать.
[31:21.760 --> 31:28.520]  По-русски это СНМ, по-английски это ДСУ.
[31:52.360 --> 32:01.920]  Значит, это структура, которая умеет отвечать на следующие запросы. Первый запрос это... Так, момент.
[32:07.920 --> 32:12.920]  Ну давайте так, нам нужно, нам нужно что сделать? Вот давайте приметно к нашей задаче. Нам нужно уметь
[32:12.920 --> 32:16.880]  проверять, вот если у меня пришло какое-то ребро, ребро, которое там образует или не образует цикл,
[32:17.080 --> 32:22.160]  мне нужно понять лежат ли вот эти две вершины, лежат ли концы этого ребра в одной компоненте связаности?
[32:22.160 --> 32:27.920]  Потому что ребро как раз добавляет циклы, если только если они и так были в одной компоненте связаности.
[32:27.920 --> 32:33.880]  Мне нужно по двум вершинкам моменты определять в одной они компоненте или нет, во-первых, а, во-вторых
[32:33.880 --> 32:38.040]  если в разных, то нужно объединить эти компоненты, потому что если было две компоненты связаности,
[32:38.040 --> 32:43.560]  я прогружу между ними ребро, то теперь эти два множества объединяются в одно и получается одна
[32:43.560 --> 32:47.680]  большая компонента связанности. Поэтому с точки зрения нашей задачи нужно
[32:47.680 --> 32:57.720]  уметь делать две вещи. Во-первых, проверить, лежат ли два элемента в одном множестве,
[32:57.720 --> 33:08.000]  два элемента в одном множестве. Второе, объединить два данных множества.
[33:18.000 --> 33:24.920]  Два данных множества. Если мы на этом научимся быстро отвечать, то и, собственно, алгоритм
[33:24.920 --> 33:30.480]  Крускала мы тоже реализуем и закончим быструю асимптотику. И мы сейчас это сделаем.
[33:30.480 --> 33:48.480]  Итак, давайте пока абстрагируемся от графов, от астолов, забудем вообще про алгоритм Крускала.
[33:48.480 --> 33:53.920]  Просто сфокусируемся на этой задаче. Есть у меня изначально n элементов. Изначально
[33:53.920 --> 33:58.540]  все, каждый в своем множестве. Первый элемент это отдельное множество, второй элемент это
[33:58.540 --> 34:03.320]  отдельное множество. И так далее n элементы это отдельное множество. И поступают такие запросы.
[34:03.320 --> 34:10.480]  Проверить в одном или не в одном и объединить два. Тогда давайте сделаем следующее. Давайте мы
[34:10.480 --> 34:14.800]  каждое множество, каждое вот это вот множество которое с остальными не пересекается. Будем
[34:14.800 --> 34:31.680]  представлять в виде дерева. Каждое множество в SNM представляем в виде корневого дерева.
[34:31.680 --> 34:41.440]  То есть изначально понятно, что каждая вершинка просто сама себе корень,
[34:41.440 --> 34:48.080]  дерево из одной вершинки, и ничего не происходит. Ну а там на какой-нибудь следующей стадии алгоритма
[34:48.080 --> 34:52.720]  может быть какое-нибудь вот такое дерево, например. То есть некая вершинка является корнем, давайте
[34:52.720 --> 34:59.360]  назову R, и у меня есть вот такое дерево. Значит, что все эти вершинки лежат в одном множестве,
[34:59.360 --> 35:06.000]  и в каком-то смысле их лидером выступает вот эта вершинка R. И тогда я буду как-то так это дерево
[35:06.000 --> 35:17.200]  хранить. Лидер множества. Тогда, чтобы, например, проверить, лежат ли два элемента в одном множестве,
[35:17.200 --> 35:22.640]  достаточно просто у обоих элементов найти их лидера, найти корень просто дерева, и проверить
[35:22.640 --> 35:27.800]  равны или неравны. Потому что если они в одном множестве, скажем, вот эти два элемента, я для
[35:27.800 --> 35:32.840]  них обоих нахожу корня, то есть просто прохожусь вверх по дереву, пока они не ведут до корня. Если
[35:32.840 --> 35:36.640]  они совпали, закончатся в одной вершинке, значит они в одном множестве, в одном дереве лежали просто.
[35:36.640 --> 35:41.360]  Если они не совпали, то есть у них разные лидеры, разные корни деревьев, значит это и деревья различные.
[35:41.360 --> 35:49.520]  Поэтому нам достаточно в ответ на первый запрос как-то вот найти корень в том дереве, в котором данная
[35:49.520 --> 35:53.800]  вершинка лежит. Для этого будем просто, давайте просто ориентировать наше дерево снизу вверх,
[35:53.800 --> 36:06.480]  и для каждой вершинки храните родителя в этом дереве. Для любой v храним p от v, это родитель вершинки
[36:06.480 --> 36:19.000]  v в соответствующем дереве. Родитель v в дереве. Ну родитель, то есть следующая вершинка на пути до корня,
[36:19.320 --> 36:27.280]  тот, кто непосредственно выше расположен, предыдущая вершина на этом пути, первая снизу верха слетит,
[36:27.280 --> 36:34.200]  это первая вершина. Вот я просто в нее буду соваться. Если же вершинка v является сама корнем, то понятно,
[36:34.200 --> 36:42.480]  где у нее нет родителя, некуда идти выше. Давайте хранить минус 1. p от v это минус 1, если только
[36:42.480 --> 36:54.920]  если v это корень своего дерева. Если только если v корень. Тогда повторюсь, если мне нужно для
[36:54.920 --> 37:00.800]  двух вершин понять в одном они множестве или нет, я просто вместо v беру p от v, p от p от v,
[37:00.800 --> 37:06.400]  ну и так далее, навешиваю p столько раз, пока не приду в вершинку, у которой нету родителя,
[37:06.400 --> 37:11.160]  то есть пока не приду в корень. И так делаю и для v, и для u, для двух данных вершинок. Если они
[37:11.160 --> 37:13.720]  пришли в одну вершинку, то значит они в одном дереве, если нет, то в разных.
[37:13.720 --> 37:30.640]  Поэтому процедуру get, давайте я, а нет, не готов написать. Ну ладно, пока давайте идею оставим
[37:30.640 --> 37:35.960]  такую. А дальше, дальше мне нужно как-то научиться объединять, объединять два множества. Вот есть
[37:35.960 --> 37:42.760]  одно дерево есть другое, я хочу как-то как-то их слить в одно дерево, в одном множестве. Давайте
[37:42.760 --> 37:52.360]  у этих деревьев найдем корни, а и б их назову, и подвесим меньшее дерево к большему. Значит,
[37:52.360 --> 37:56.280]  а именно, что я буду в каждом корне хранить размер этого дерева, то есть сколько здесь есть вершин,
[37:56.280 --> 38:01.880]  то есть я буду знать там size от b, сколько здесь есть вершин, и буду знать size от a, сколько здесь
[38:01.880 --> 38:08.240]  есть вершин, и подвешивать буду меньшее к большему. То есть я в любом случае хочу объединить два дерева
[38:08.240 --> 38:12.760]  в одно, это можно, например, сделать проведением такого ребра, то есть я могу назначить p от b равно
[38:12.760 --> 38:19.000]  a, провести по сути такое ребро, подвесить все вот это дерево как бы к a, в качестве правого сына,
[38:19.000 --> 38:25.120]  к вершинке a, ну одного сына к вершинке a. И буду делать это подвешивая меньшее дерево к большему,
[38:25.120 --> 38:41.760]  тогда у меня будет хорошая симпатика. Итак, пусть size от v это размер под дерево вершины v,
[38:41.760 --> 39:01.640]  пусть a и b это корни, и при этом size от a больше равно size от b. Тогда, чтобы два множества объединить,
[39:01.640 --> 39:11.240]  мне достаточно написать две строчки. Во-первых, p от b равно a, во-вторых, size от a плюс равно size
[39:11.240 --> 39:24.200]  от b. Все. Я провел это ребро, назначив родителя вершинки b. Раньше p от b было минус 1, раньше оно
[39:24.200 --> 39:29.760]  было корнем и не было у него родителя, теперь назначаем. Ну и size пересчитали, потому что к a
[39:29.760 --> 39:37.680]  подвесилось целиком по дереву b, мы должны size увеличить. Так, вот то, что я написал,
[39:37.680 --> 39:45.240]  да, вот эта вот штука условия на size, это так называемая эвристика по рангу, ну или по размеру.
[39:45.240 --> 39:53.240]  То есть, ну здесь как бы под рангом подразумевается размер под дерево, и мы подвешиваем меньше к дереву
[39:53.240 --> 39:57.160]  к большему всегда. Тогда у меня будет, сейчас будет логарифм. Вот давайте напишем какой-то код,
[39:57.160 --> 40:15.080]  первое приближение. Ну давайте сначала get напишем. Get это получение корня дерева,
[40:15.080 --> 40:20.520]  получение лидера. Пишется очень просто, поднимаемся по p, пока не дойдем до вершинка с p равно
[40:20.520 --> 40:32.840]  минус 1. Значит, если p от v равно минус 1, тогда return v, а иначе return get от p от v.
[40:32.840 --> 40:46.920]  Да, если мы уже в корне, то нам надо его вернуть, иначе нам нужно вернуть get от родителя. Вот, ну и void
[40:46.920 --> 40:59.960]  unite для двух вершинок u и v. Есть две вершинки, мы хотим провести ребро между ними. Ну, во-первых,
[40:59.960 --> 41:12.680]  можно сразу заменить u на get от u и v на get от v, ну то есть подняться в лидеров. Да, вот здесь,
[41:12.680 --> 41:19.760]  ну давайте считать, что у меня уже гарантированно они различны. Давайте сейчас теперь u не равно v,
[41:19.760 --> 41:25.200]  иначе нам не надо провести ребра, они и так в одной компоненте, ничего добавлять не нужно. Ну или там
[41:25.200 --> 41:30.480]  запрос некорректный. Так вот, если они не равны, тогда нужно в соответствии с тем, какие у них
[41:30.480 --> 41:39.600]  сайзы пересчитать, ну возможно их свопнуть. Давайте напишу так, что если size от u меньше,
[41:39.600 --> 41:51.320]  чем size от v, тогда своп u v. Ну а дальше u это тот из корней, который имеет больший size,
[41:51.320 --> 41:58.720]  значит надо просто подвесить v к u. Пишем вот те самые строчки, что p от v равно u и size от u
[41:58.720 --> 42:24.880]  плюс равно size от v. Вот так можно реализовать наш S&M. Ну и на вопрос, за сколько это работает,
[42:25.800 --> 42:30.960]  каждый запрос за логарифм у нас будет, потому что глубина дерева будет всегда максимум логарифм.
[42:30.960 --> 42:35.320]  Потому что смотрите, когда я делаю такой переход, когда я выполняю подвешивание одного дерева к
[42:35.320 --> 42:41.440]  другому, у меня размер текущего поддерева по сравнению с размером всего, то есть когда я
[42:41.440 --> 42:46.520]  перехожу от поддерева к над деревом, у меня размер рассвета хотя бы вдвое, потому что это было
[42:46.520 --> 42:53.280]  меньше, чем это, значит это меньше, чем половина всего. Когда я перехожу от b к p от b,
[42:53.280 --> 42:58.920]  к родителю, я размер текущего поддерева увеличу хотя бы вдвое, значит подъемов по родителям у
[42:58.920 --> 43:04.400]  меня будет максимум логарифм. Вот это условие, увеличение размера, оно всегда гарантирует,
[43:04.400 --> 43:12.040]  что подъем вдоль ребра, вдоль p, оно увеличивает размер текущего поддерева хотя бы вдвое. Значит
[43:12.040 --> 43:20.680]  глубина всех деревьев будет всегда максимум логарифм. Глубина всех деревьев всегда не больше
[43:20.680 --> 43:31.640]  чем логарифм. Так как, давайте восстановим эту картинку, когда у меня появляются ребра,
[43:31.640 --> 43:36.840]  только когда я объединяю два дерева, только в юнайте, а когда я их объединяю, это значит,
[43:36.840 --> 43:41.520]  что размер этого меньше, чем размер этого, значит размер этого меньше, чем половина размера всего.
[43:41.520 --> 43:51.720]  Так как, когда я перехожу от b к p от b, размер поддерева растет хотя бы вдвое.
[43:51.720 --> 44:09.080]  Ну и понятно, если здесь у меня хотя бы единица сначала, то здесь хотя бы два, хотя бы четыре,
[44:09.080 --> 44:15.720]  хотя бы восемь и так далее, поэтому глубина всегда максимум логарифм. Ну и значит у меня есть там
[44:15.720 --> 44:21.560]  несколько деревьев, каждое множество это какое-то дерево, у каждого дерева глубина логарифм,
[44:21.560 --> 44:25.400]  значит get всегда работает максимум за логарифм, потому что мне нужно просто взять вот вишенки
[44:25.400 --> 44:30.280]  дойти до корня. Это время ограничено глубиной дерева, она растет на логарифм, значит get
[44:30.280 --> 44:35.280]  работает за логарифм. Ну а size, юнайт тогда вообще работает за единицу, если get игнорировать,
[44:35.280 --> 44:44.200]  то юнайт работает за единицу, там swap, присвоение и плюс равно. Значит ответ на запрос за логарифм.
[44:44.200 --> 45:02.800]  Ответ на запрос от логарифма. Согласны? Хорошо. Ну здесь есть еще одна идея, которая позволит
[45:02.800 --> 45:20.800]  еще ускорить это решение, называется еврестика сжатия путей. Идея следующая, смотрите, вот если у
[45:20.800 --> 45:26.080]  меня есть какое-то ветвистое там длинное дерево, вот например там есть какой-то корень, есть такой
[45:26.080 --> 45:31.720]  путь из него длинный, и пусть я в какой-то момент сделал get от v, вот после этого я в какой-то момент
[45:31.720 --> 45:37.360]  запустил get от v. Ну в каком-то смысле понятно, что структура дерева нам не нужна. Вообще я ввожу
[45:37.360 --> 45:42.000]  дерево только для того, чтобы компонента связанности, какое-то дерево, соответствовало
[45:42.000 --> 45:45.560]  однозначно множеству. Поэтому как бы структура дерева мне не очень важна, я ее какой угодно
[45:45.560 --> 45:52.560]  могу делать. Поэтому если я запускаю get от v, давайте я весь этот длинный путь замню вот, ну как бы в
[45:52.560 --> 45:57.600]  такое дерево превращусь, корень у меня остается, а все остальные вышники, которые я прошел в течение
[45:57.600 --> 46:04.240]  этого пути, теперь становятся непосредственными детьми r. То есть я их просто все переподвешиваю в
[46:04.240 --> 46:09.720]  качестве детей к r. Это выгодно, потому что теперь если в следующий раз у меня захочется найти get от v,
[46:09.720 --> 46:13.960]  или get от этой вершинкой, или get от этой, или get от этой, мне не придется весь этот путь заново
[46:13.960 --> 46:19.040]  проходить. У меня уже сразу весь известный ответ. Ну по крайней мере этот кусок пути точно сокращен
[46:19.040 --> 46:26.240]  до r. Это вот как раз жатие пути, что если я для каких-то вершин в какой-то момент нашел значение,
[46:26.720 --> 46:37.160]  корня, то я их просто всех переподвешу к корню. Это нам ничего не сломает, потому что мы нигде не
[46:37.160 --> 46:41.720]  пользуемся структурой дерева. Нам не важно, что вот здесь именно такой путь. Нам важен только
[46:41.720 --> 46:46.080]  представитель. От каждого дерева нам важен только корень. Единственное, что мне нужно в этих процедурах,
[46:46.080 --> 46:51.320]  это чтобы для вершинок из одного дерева они возвращали одного и того же корня. У них был один
[46:51.320 --> 46:55.480]  тот же корень. Вершины из разных деревьев имеют разный корень. Ну понятно, что здесь сохраняется. Я не
[46:55.480 --> 47:01.360]  нарушаю. Корень всегда остается на месте. А если кто-то был корнем, то он им и останется.
[47:01.360 --> 47:09.360]  То есть я в каком-то смысле просто облегчаю себе работу на будущее, переподвешиваю все их к r. И все,
[47:09.360 --> 47:18.040]  юна никак не меняется. Гет, соответственно, можно будет переписать так. Давайте я прямо здесь его
[47:18.040 --> 47:47.960]  перепишу. Первую строчку я оставляю. Вот, а вторая будет так.
[47:47.960 --> 48:04.200]  Возможно, это не очень хорошо с точки зрения стиля кода, но если мы зачем-то стремимся писать как
[48:04.200 --> 48:12.360]  можно меньше символов, можно писать так. Мы сначала рекурсивно находим гет от p от v,
[48:12.360 --> 48:17.640]  то есть поднимаемся в родителя ищем для него корни. Вот эта штука находит нам корень. Дальше
[48:17.640 --> 48:23.120]  выполняем присваивание, что p от v равно корню. И это присваивание еще опять возвращает значение,
[48:23.120 --> 48:30.240]  равное корню, мы его возвращаем. То есть вот эта строчка составлена из двух операций.
[48:30.240 --> 48:36.000]  Мы сначала родителя v переназначаем равной корню и затем возвращаем то самое значение корню.
[48:36.000 --> 48:44.400]  Вот хорошо. Теперь за сколько это работает? Тут мне нужна шпаргалка.
[49:06.000 --> 49:17.360]  Значит, рассматриваем такую функцию.
[49:36.000 --> 49:49.400]  Это какая-то функция, принимающая целые неотрицательные аргументы.
[49:49.400 --> 49:55.520]  Рассмотрим обратную функцию.
[49:55.520 --> 50:12.080]  Альфа от k это минимальная неотрицательная n, такое, что а, n, n хотя бы k. Так вот тогда
[50:12.080 --> 50:20.960]  наши запросы работают у звездочка от этой альфы. Смысл такой, что эта функция очень быстро растет,
[50:20.960 --> 50:26.960]  соответственно, эта функция как обратная, наоборот, очень медленно растет. Так вот тогда
[50:26.960 --> 50:34.160]  вот эта эвристика жатия путей вместе с эвристикой жатия по рангу,
[50:34.160 --> 50:49.600]  эвристики жатия путей плюс жатия плюс по рангу, отвечают на запрос за у звездочка от альфы.
[50:49.600 --> 51:06.280]  Звездочка от альфы. И почему это хорошо? Нужно написать какие-то значения.
[51:19.600 --> 51:45.120]  Вот. Уже А4,4 такое огромное. Ну, я даже, типа это что-то огромное, это, не знаю, точно там
[51:45.120 --> 51:51.960]  10 тысяч знаков точно в этом есть. Скорее даже больше. Ну, поэтому понятно, что альфа от всего
[51:51.960 --> 51:56.720]  адекватного, не знаю, от всего интернета, наверное, будет меньше, чем 4. Но я на всякий
[51:56.720 --> 52:03.720]  случай там напишу, типа 10,20 точно не больше, чем 4. Потому что даже уже на точке 4,4 это что-то
[52:03.720 --> 52:11.320]  очень просто астрономически большое. Значит, наоборот, если мы фиксируем вот это вот значение и
[52:11.320 --> 52:16.360]  хотим найти минимальное n такое, что а,n,n больше, чем вот это, то для всех чисел, если здесь в
[52:16.360 --> 52:21.960]  аргументе что-то не больше, чем вот это, там 10,20 точно, то это будет не больше, чем 4. А значит,
[52:21.960 --> 52:27.600]  то есть хоть это и растущая функция, то есть это бесконечно растущая функция, значит это тоже
[52:27.600 --> 52:33.320]  будет бесконечно растущей, как обратно к ней. То есть, по сути, это бесконечно растущая функция,
[52:33.320 --> 52:43.040]  но на всем адекватном это 4. Ну, то есть вот 1. Вот, и в этом, в общем-то, и прелесть этих двух евристий,
[52:43.040 --> 52:47.360]  что они работают практически за вот 1 на запрос. Ну, тут еще звездочка амортизированная, но,
[52:47.360 --> 52:54.160]  по сути, по сути, вот 1. Так, давайте я скажу, что это называется функция Кирмана. Вот это вот
[52:54.160 --> 53:06.560]  а, это функция Кирмана. Это, соответственно, обратная функция Кирмана. Обратная функция Кирмана.
[53:06.560 --> 53:12.560]  Вот, я, к сожалению, не знаю, откуда это все берется, поэтому, поэтому без доказательства,
[53:12.560 --> 53:16.600]  но главное для нас, что вот просто есть какая-то супер-быстро растущая функция, соответственно,
[53:16.600 --> 53:27.440]  обратной к ней очень медленно растет, и асимплатика будет вот такая. Вот. Так, что осталось сказать? Да,
[53:27.440 --> 53:35.400]  почему, почему, о, звездочка, да, почему амортизированная? Ну, здесь, ну, как бы в
[53:35.400 --> 53:38.760]  каком-то смысле важно, что амортизированная. То есть, не каждая операция будет там за вот
[53:38.760 --> 53:42.240]  1 работать, а вот именно амортизированная, потому что в худшем случае может быть такое,
[53:42.240 --> 53:49.280]  что я подвешиваю, подвешиваю, подвешиваю, подвешиваю и ни разу не вызываю здесь гета, ни разу не сжимаю
[53:49.280 --> 53:53.280]  путь. То есть, скажем, сначала я подвесил эту вершинку к этой, потом эту, ну, там вот к этому
[53:53.280 --> 53:57.760]  по дереву, эту вот к этому и так далее, и, соответственно, здесь не произведено ни одного сжатия. Для них
[53:57.760 --> 54:03.120]  гет не вызывался. И вот когда-то потом, в будущем, когда запустится гет от этой вершинки, мне
[54:03.120 --> 54:07.000]  придется весь этот путь пройти. То есть, может быть такое, что какая-то конкретная операция работает
[54:07.000 --> 54:12.840]  дольше, чем альфа. Ну, то есть, логарифм в худшем случае, если я весь этот путь не сжимал ни разу,
[54:12.840 --> 54:18.600]  тогда мне придется сделать здесь логарифм шагов, чтобы дойти до корня. Но зато, когда я сделаю
[54:18.600 --> 54:25.160]  логарифм шагов, у меня для них, для всех, сразу известен, известен корень. Типичная идея из
[54:25.160 --> 54:29.200]  амортизованного анализа, что если у меня там даже есть какая-то тяжелая операция, то в будущем она
[54:29.200 --> 54:34.480]  сильно мне упрощает жизнь, потому что, если я одну сделал, то я сразу для многих вершинок знаю правильный
[54:34.480 --> 54:39.760]  ответ. Ну, возможно, он там обновится, когда я буду еще переподвешивать, но, в любом случае, для них,
[54:39.760 --> 54:44.880]  для всех, я сильно сократил наш путь. Поэтому амортизированный вот этот вот обратный керман.
[54:44.880 --> 54:55.680]  Вопросы? Окей, вот какая-то такая магия. Ну и, соответственно, отсюда алгоритм Крускала работает
[54:55.680 --> 54:59.840]  уже очень просто. Если у нас есть такой механизм, который позволяет поддерживать разбиение на
[54:59.840 --> 55:03.840]  компоненты связанности и объединять их, то, соответственно, за сколько работает Крускал. Ну,
[55:03.840 --> 55:11.240]  давайте посчитаем. Во-первых, у нас там была изначально сортировка ребер. Сортировка ребер. Ну,
[55:11.240 --> 55:20.240]  давайте я напишу, что это m log m. Сортировку в порядке возрастания весов. А дальше мне
[55:20.240 --> 55:34.200]  нужно m раз, то есть пройтись по всем ребрам, и м раз запустить get и unite. М раз, get и unite. То есть
[55:34.200 --> 55:40.720]  я просто прохожусь по всем ребрам, запускаю для концов ребра get. Если они в одной компоненте,
[55:40.720 --> 55:45.280]  то я их игнорирую, перехожу к следующему ребру. Если не в разных компонентах, то я делаю unite.
[55:45.280 --> 55:50.080]  В итоге у меня будет в худшем случае m раз get. На самом деле unite будет максимум n, потому что
[55:50.080 --> 55:56.960]  объединение не больше, чем n. Ну, давайте тоже сверху оценим m. И мы знаем, что все вот эти
[55:56.960 --> 56:10.640]  вот товарищи работают за амортизированную α от n. Значит, итог будет такой. m log m плюс m на
[56:10.640 --> 56:18.040]  α от n. Потому что вспоминаем, если у меня есть амортизационная оценка, и я делаю m итерацией,
[56:18.040 --> 56:23.200]  то это означает, что суммарно время работы ограничено такой штукой. Это есть определение
[56:23.200 --> 56:28.720]  амортизационного анализа. Если каждая штука работает за α амортизационно, то суммарно все
[56:28.720 --> 56:34.800]  работают за m умножить на α. Ну и да, эта штука какая-то очень маленькая. Здесь, конечно,
[56:34.800 --> 56:40.880]  основная слагаемая это сортировка. Здесь можно поговорить про то, насколько быстро можно ребр
[56:40.880 --> 56:46.080]  сортировать. Потому что, например, если вам известно, что веса ребра маленькие целые числа,
[56:46.080 --> 56:51.400]  то здесь вместо m log m можно писать m с помощью сортировки подсчетом. Ну и вообще про сортировку
[56:51.400 --> 56:55.040]  мы много что знаем. В зависимости от того, насколько быстро мы это можем сделать, соответственно,
[56:55.040 --> 57:00.240]  у меня вот эта вот штука, основная слагаемая, можно уменьшать. Поэтому к русскал в каком-то смысле,
[57:00.240 --> 57:05.720]  если у вас там, скажем, веса ребер маленькие целые числа, от 0 до 100, например, тогда эту
[57:05.720 --> 57:11.400]  сортировку можно сделать за m, а это за m на α. То есть практически линия алгоритма получается. Ну тут
[57:11.400 --> 57:15.720]  какая-то константа растущая, но для всех нормальных n она маленькая. Поэтому в каком-то смысле
[57:15.720 --> 57:18.240]  даже линия алгоритм. Ну так, с натяжкой.
[57:30.240 --> 57:43.960]  Вот, хорошо, хорошо. Так, тогда последний алгоритм того же самого. Это алгоритм барувки.
[57:43.960 --> 57:59.280]  Здесь короткая идея такая. Давайте мы для каждой вершины в нашем графе найдем самое дешевое входящее
[57:59.280 --> 58:08.680]  в нее ребро. В каком-то смысле понятно, что ответ, если в эту вершину входит ребро веса там 10,
[58:08.680 --> 58:15.680]  и все остальные только большего веса, то понятно, что в ответе здесь нужно хотя бы 10. То есть в ответе
[58:15.680 --> 58:20.600]  этой вершины хоть с кем-то связано, хотя бы одним ребром, и вес этого ребра хотя бы 10. Поэтому в
[58:20.600 --> 58:24.800]  каком-то смысле это ребро нам нужно взять, по крайней мере его вес точно нужно взять. Так вот давайте
[58:24.800 --> 58:29.640]  тогда сделаем следующее. Для каждой вершины находим самое дешевое исходящее ребро. Что-нибудь такое
[58:29.640 --> 58:41.800]  я нарисую. Добавляю эти ребра в ответ. Говорю, что вот я их взял. Самое дешевое для каждой вершинки
[58:41.800 --> 58:49.000]  взял и положил их в миностов. Ну а дальше сжимаю компоненты связанности, которые получились,
[58:49.000 --> 58:58.400]  и запускаю алгоритм рекурсивно на том, что получилось после сжатия. Итак, как бы это написать,
[58:58.400 --> 59:25.760]  для каждой вершины выделяем самое дешевое исходящее ребро. Дальше все выделенные ребра
[59:25.760 --> 59:37.120]  добавляем в остов и сжимаем компоненты связанности. Все выделенные ребра добавляем в остов,
[59:37.120 --> 59:57.840]  сжимаем компоненты связанности и рекурсивный запуск. Я сжал наш граф, получил какие-то,
[59:57.840 --> 01:00:03.040]  уже какие-то ребра добавил в миностов, и теперь у меня есть граф поменьше, и мне нужно в нем решить
[01:00:03.040 --> 01:00:07.040]  опять задачу о минимальном остове. То есть вот здесь скажем, я сожму вот это в одну вершинку,
[01:00:07.040 --> 01:00:10.360]  вот это в одну вершинку, это в одну вершинку, останутся какие-то ребра между вершинами,
[01:00:10.360 --> 01:00:15.800]  вот эти вот. Ну и опять у меня есть та же самая задача, что есть несколько вершинок, есть ребра
[01:00:15.800 --> 01:00:23.040]  между ними, нужно найти миностов. Потому что чтобы связать вот эти вот кусочки, мне нужно найти
[01:00:23.040 --> 01:00:35.000]  какой-то дерево их соединяющий минимального веса. Вот такой алгоритм. Тут есть как минимум,
[01:00:35.000 --> 01:00:41.680]  как минимум одна ловушка, что нужно немножко уточнить про вот это минимальное исходящее
[01:00:41.680 --> 01:00:46.360]  ребро. Его нельзя брать произвольным, потому что, например, рассмотрим такой случай,
[01:00:46.360 --> 01:00:55.080]  когда у меня есть треугольник, и веса всех ребр в нем это единица. Тогда если я никак не
[01:00:55.080 --> 01:01:04.520]  специфицирую, какое из минимальных ребр я беру, то, например, я мог взять для этой вершинки это
[01:01:04.520 --> 01:01:09.400]  ребро веса 1, для этой вершинки это ребро, для этой вершинки это ребро. И тем самым я как бы цикл
[01:01:09.400 --> 01:01:15.880]  добавил в свой остов, это плохо. Так вот, чтобы избежать циклов, можно сказать следующее, что если
[01:01:15.880 --> 01:01:23.440]  из В исходит несколько ребер минимальных одного и того же веса, исходит несколько
[01:01:23.440 --> 01:01:32.760]  минимальных ребер, то давайте выберем то из них, которое вьет вершину с минимальным номером.
[01:01:45.880 --> 01:02:03.160]  С минимальным номером. Тогда в этом случае, в случае этого треугольника что получится? Ну давайте
[01:02:03.160 --> 01:02:10.240]  я как-нибудь их пронумеру 1, 2, 3. Тогда для единички есть два исходящих ребра одного и того же веса
[01:02:10.240 --> 01:02:16.680]  минимального. Я выбираю вот это ребро, потому что оно ведет вершинку номер 2. Дальше для двойки
[01:02:16.680 --> 01:02:23.520]  есть опять два исходящих. Я выбираю вот это опять же, потому что один меньше чем три. И для тройки
[01:02:23.520 --> 01:02:28.200]  я выбираю вот это ребро. То есть я какое-то ребро выбрал дважды, это у меня всегда так будет на
[01:02:28.200 --> 01:02:33.120]  самом деле. Я вот это ребро выбрал дважды, но при этом циклов не образовалось. Я как бы имею в
[01:02:33.120 --> 01:02:39.200]  виду, что если я какое-то ребро назначил дважды в минимальном, то я беру его один раз. Ну понятно,
[01:02:39.200 --> 01:02:45.880]  нельзя взять ребро два раза, я беру его один раз. Вот, получится такая штука, и циклов я не добавлю,
[01:02:45.880 --> 01:02:49.960]  по крайней мере в этом случае. Давайте докажем, что так будет всегда.
[01:03:04.520 --> 01:03:05.160]  Докажем.
[01:03:09.200 --> 01:03:15.760]  Что в таком случае циклов не появится.
[01:03:25.680 --> 01:03:33.160]  Ну действительно, давайте мы договоримся, что если я для какой-то вершинки v выбираю исходящее
[01:03:33.160 --> 01:03:40.480]  из нее ребро e, то я это ребро вот так ориентирую, нарисую в нем стрелочку. Что если я из-за v взял
[01:03:40.480 --> 01:03:47.200]  ребро e, то я нарисую на нем такую стрелку. Может быть такое, что я взял какое-то ребро два раза, то
[01:03:47.200 --> 01:03:52.200]  есть я его выбрал для u и для v. Это самое минимальное ребро для u и минимальное ребро для v. Тогда я буду
[01:03:52.200 --> 01:03:58.280]  рисовать стрелки в обе стороны. Так вот, что у меня получается за граф, если я выбираю для каждой
[01:03:58.280 --> 01:04:06.960]  вершинки какое-то исходящее из нее ребро. Это так называемый функциональный граф. Это ориентированный
[01:04:06.960 --> 01:04:12.200]  граф такой, что у каждой вершинки исходящей степени ровно один, потому что у каждой вершины ровно
[01:04:12.200 --> 01:04:24.160]  одно ребро из нее торчит. Я напишу out degree для каждой вершинки равно 1. Из каждой вершины исходит
[01:04:24.160 --> 01:04:33.120]  ровно одно ребро. Как такой граф выглядит? Следующим образом, это обязательно некий цикл,
[01:04:33.120 --> 01:04:54.000]  к которому подвешены деревья. Точнее несколько циклов может быть. Вот как-то так. Почему граф
[01:04:54.000 --> 01:05:01.680]  выглядит именно так? Это легко доказать. Давайте начнем в произвольной вершинке v и начнем исходить
[01:05:01.680 --> 01:05:08.480]  по нему, по тому самому ребру e. Вот я нашел исходящее ребро, нарисовал его, нашел еще ребро,
[01:05:08.480 --> 01:05:13.160]  еще ребро, еще ребро. В какой-то момент, понятное дело, я не могу бесконечно долго посещать новые
[01:05:13.160 --> 01:05:18.240]  вершинки, в какой-то момент я вынужден буду посетить одну из вершин, которая была раньше. Вот она
[01:05:18.240 --> 01:05:23.000]  где-то здесь, например, будет. То есть это либо v, либо какая-то более правая вершинка. Значит, из каждой
[01:05:23.000 --> 01:05:27.480]  вершины мы достижем некий цикл. Из каждой вершины мы идем, идем, идем. Понятно, что мы рано или поздно
[01:05:27.480 --> 01:05:34.240]  зациклимся. Поэтому если я теперь выделю вот этот цикл, скажу, что это вот такой кусок, то получается,
[01:05:34.240 --> 01:05:41.520]  что все остальные вершинки, из которых достижем этот цикл, они в каком-то смысле образуют деревья,
[01:05:41.520 --> 01:05:46.560]  подвешенные к этому циклу. Потому что если из вершинки достижем опять этот цикл, из u опять
[01:05:46.560 --> 01:05:51.840]  достижем этот цикл, то мы как-то шли-шли-шли-шли-шли и попали в этот цикл. Ну да, то есть мы сначала
[01:05:51.840 --> 01:05:58.040]  прошли некий путь, однозначно определяемый до вот этого цикла, и затем в этот цикл вклинились. То
[01:05:58.040 --> 01:06:03.360]  есть если я теперь все подвешу в каком-то смысле за этот цикл, у меня будут вот эти вот пути, восходящие
[01:06:03.360 --> 01:06:12.480]  к этому циклу, ну значит у меня получается некие деревья с корнями в вершинках цикла. И так
[01:06:12.480 --> 01:06:20.000]  может быть несколько циклов, если вот эти циклы различны для нескольких разных вершин. Вот, то есть у
[01:06:20.000 --> 01:06:26.160]  меня есть такой граф, и алгоритм Боровки объединяет вот это вот в отдельную компоненту, сжимает ее,
[01:06:26.160 --> 01:06:31.600]  сжимает вот это в отдельную компоненту, и потом рекурсивно запускает задачу, рассматривая вот это
[01:06:31.600 --> 01:06:37.520]  как одну большую вершинку. Так вот, я утверждаю, что циклов не появятся. То есть когда я нахожу
[01:06:37.520 --> 01:06:42.160]  вот эти вот самые дешевые ребра, то у меня на самом деле не будет такой картины, что длина этого цикла
[01:06:42.160 --> 01:06:48.240]  будет хотя бы 3. Потому что если длина хотя бы 3, то будет цикл, а тут 4 будет цикл. А вот если
[01:06:48.240 --> 01:07:05.600]  была длина 2, то цикла бы не было. Потому что что такое цикл длины 2? Это две вершины, которые друг
[01:07:05.600 --> 01:07:10.360]  у друга ссылаются. Вот так, что самый дешевый исходящий из них ребро ведет вот в противоположную.
[01:07:10.360 --> 01:07:18.440]  И здесь какие-то деревья подвешены к нему. Тут дерево, и тут дерево. Понятно, что это означает
[01:07:18.440 --> 01:07:23.000]  просто-напросто, что я беру одно ребро между ними. То есть здесь не два ребра, а одно. Опять,
[01:07:23.000 --> 01:07:27.960]  я считаю, что кратных ребр нету. Значит, между вот этими двумя вершинками ребро однозначно определено.
[01:07:27.960 --> 01:07:32.480]  Если я говорю, что самый дешевый исходящий из этой вершинки ведет сюда, а самый дешевый из
[01:07:32.480 --> 01:07:37.680]  этой ведет сюда, то это одно и то же ребро, по сути, описываю. Поэтому вот здесь как раз цикла не
[01:07:37.680 --> 01:07:42.280]  появится. Если я все эти ребра добавлю в минимальный остов, то циклам, ну, собственно,
[01:07:42.280 --> 01:07:46.080]  нет куда будет взяться. Здесь деревья, здесь деревья, здесь еще перемычка между деревьями.
[01:07:46.080 --> 01:07:53.080]  Цикла нет. А вот там были бы. Так вот нам достаточно доказать, что все вот эти, ну, как бы,
[01:07:53.080 --> 01:07:57.520]  компоненты связанности в кавычках, все вот эти вот облачка функционального графа, ведущие в циклу,
[01:07:57.520 --> 01:08:16.440]  они имеют циклы длины ровно 2. Достаточно доказать, что все циклы имеют длину 2. Тогда как раз таки при
[01:08:16.440 --> 01:08:23.480]  объединении, ну, при добавлении этих ребер в остов у меня циклов не появится. Так, ну, хорошо.
[01:08:23.480 --> 01:08:31.920]  Хорошо. Давайте, чтобы доказать, заметим сначала следующее. Давайте рассмотрим два последовательных
[01:08:31.920 --> 01:08:40.800]  ребра исходящих. E и E'. То есть для этой вершинки кратчайшее минимальное ребро это E, а для вот
[01:08:40.800 --> 01:08:45.760]  этого конца этого ребра кратчайшее ребро это E', причем это какие-то разные ребра. Тогда понятное
[01:08:45.760 --> 01:08:56.800]  дело, что кост от E больше равен, чем кост от E'. Ну, потому что, смотрите, я вот когда нахожусь в этой
[01:08:56.800 --> 01:09:03.400]  вершинке, что такое E', это ребро минимального веса, торчащее из нее. Ну, тогда понятное дело,
[01:09:03.400 --> 01:09:09.680]  что E имеет вес больше равный, чем вес E', потому что если E' это минимальное, то E имеет вес
[01:09:09.680 --> 01:09:14.680]  больше равный. Поэтому дополнительное свойство нашего вот этого функционального графа в том,
[01:09:14.680 --> 01:09:20.440]  что при проходе сверху вниз по нему, вес ребра только уменьшаться может. Ну, не строго,
[01:09:20.440 --> 01:09:26.840]  не увеличивается. Что я прохожусь по ребру выше-выше-выше, и текущий вес ребра, кост,
[01:09:26.840 --> 01:09:32.880]  он может только уменьшиться. Ну, или остаться таким, как был. Поэтому в частности, если у меня есть
[01:09:32.880 --> 01:09:41.480]  некий цикл длины больше равной, чем 3, пусть есть цикл длины больше, но чем 3, то на нем все
[01:09:41.480 --> 01:09:46.920]  ребра имеют один и тот же вес. Потому что когда я иду по ребру, я понимаю, что у меня кост не
[01:09:46.920 --> 01:09:52.560]  увеличивается. Значит, кост этот меньше равен, чем кост этот. Дальше, кост здесь еще меньше равен,
[01:09:52.560 --> 01:09:58.040]  кост здесь еще меньше равен, и еще кост этот меньше равен вот этому. Поэтому у меня есть цепочка
[01:09:58.040 --> 01:10:07.360]  неравенства меньше или равно, значит, они все равны. Все веса ребра на цикле одинаковые.
[01:10:07.360 --> 01:10:12.920]  Одинаковые.
[01:10:12.920 --> 01:10:22.360]  Хорошо, но как же так вышло, что веса одинаковые, а мы выбрали цикл. Давайте
[01:10:22.360 --> 01:10:42.280]  поймем, как это может быть. Давайте нарисуем. Вот есть некий цикл длинный v1, v2, v3, v4, vn,
[01:10:42.280 --> 01:10:55.280]  и здесь, соответственно, e1, e2, e3, en. Я знаю, что веса всех ребер одинаковые, веса всех ребер,
[01:10:55.280 --> 01:11:02.800]  которые я взял в цикл одинаковые. При каком условии я для вершинки v1 выбрал вот это
[01:11:02.800 --> 01:11:12.000]  исходящее ребро v2. Но это означает, что v2 меньше, чем vn. Потому что из v1 есть как минимум два
[01:11:12.000 --> 01:11:17.920]  этих ребра одного и того же веса, и я предпочитаю ребро, исходящее в v2, а не vn. Значит, у этой вершинки
[01:11:17.920 --> 01:11:25.520]  номер меньше, чем у vn. Так, тогда мне нужно будет продолжить в эту сторону.
[01:11:25.520 --> 01:11:37.400]  Тогда давайте для вершинки номер vn-1 посмотрим, что тут написано. Почему для... тяжело, да? Давайте
[01:11:37.400 --> 01:11:53.400]  какой-нибудь цикл понятный длинный нарисуем, потому что иначе мы не поймем. Цикл на пяти вершинах.
[01:11:53.400 --> 01:12:01.080]  Итак, для v1 я предпочел v2 в вершинке v5. Значит, v2 меньше, чем v5. Теперь для v4 тоже сам посмотрю.
[01:12:01.080 --> 01:12:07.160]  Я для v4 выбираю v5, а не v3, хотя они одного и того же веса. Значит, v5 строго меньше, чем v3.
[01:12:07.160 --> 01:12:18.120]  Для v2 я предпочел v3, а не v1. Значит, v3 имеет номер меньше, чем v1. Ну, вы понимаете, к чему я
[01:12:18.120 --> 01:12:24.560]  клоню? Значит, сейчас я продолжу, получу, что v2 меньше, чем v2. Для v5 я могу написать, что я
[01:12:24.560 --> 01:12:34.040]  раз выбрал v1, а не v4, значит v1 меньше, чем v4. Для v3 v4 меньше, чем v2. И все. Получилось, что v2
[01:12:34.040 --> 01:12:42.160]  меньше, чем v2. То есть, по сути, у меня будут вот такие вот скачки на два назад. То есть, если я
[01:12:42.160 --> 01:12:47.000]  рассмотрю произвольную вершинку и говорю, что я вот эту вершинку предпочел предыдущей, значит,
[01:12:47.000 --> 01:12:51.760]  вот когда я так возвращаюсь на два по циклу назад, я уменьшаю значение вершинки. Ну и понятно,
[01:12:51.760 --> 01:12:56.400]  что я как бы так вот, так еще уменьшил на два, еще уменьшил на два, еще на два, еще на два. Таким
[01:12:56.400 --> 01:13:02.520]  образом, я рано или поздно зациклюсь и получу, что x меньше, чем x. Вот. Значит, в случае, когда,
[01:13:02.520 --> 01:13:12.400]  например, у меня было бы 6, значит, тут было бы еще проще. 6 вершин v4, v5, v6. Значит, если бы я
[01:13:12.400 --> 01:13:18.040]  тоже самое написал, у меня получил, что v2 меньше, чем v6, v6 меньше, чем v4, v4 меньше, чем v2. То есть,
[01:13:18.040 --> 01:13:22.960]  мы бы еще быстрее нашли противоречие. Ну короче, мы все равно рано или поздно так зациклимся и получим
[01:13:22.960 --> 01:13:32.960]  противоречие вида x меньше, чем x. Это значит, что циклов длины хотя бы 3 не бывает. Единственный
[01:13:32.960 --> 01:13:39.600]  возможный цикл, когда вот я завершаю вот этот вот цикл, может иметь длину только 2. Ну длины 1
[01:13:39.600 --> 01:13:43.800]  быть не может, потому что у меня нет петель. Мы не можем выбрать вот такое ребро. Нет петель у
[01:13:43.800 --> 01:13:50.160]  меня в графе. Может быть только цикл длины 2, как вот на этой картинке. Поэтому, действительно, циклов
[01:13:50.160 --> 01:14:03.000]  не появится. Согласны? Так, ну хорошо. Циклов не появится. Ну теперь надо еще доказать корректность,
[01:14:03.000 --> 01:14:11.280]  что мы найдем обязательно минимальный остов, но это несложно. То есть, мы поняли, что циклов не
[01:14:11.280 --> 01:14:15.520]  появится, значит у нас всегда дерево. То есть, мы найдем какой-то остов. Вопрос, у чего он минимального
[01:14:15.520 --> 01:14:36.640]  веса? Докажем, что находимое дерево, находимое остов имеет минимальный вес. Так, ну здесь наша любимая
[01:14:36.640 --> 01:14:44.160]  лемма о безопасном ребре. Только ее нужно немножко аккуратно приложить, потому что как у нас
[01:14:44.880 --> 01:14:49.640]  работает лемма. У нас было было что-то, я добавляю одно ребро и получаю подножие
[01:14:49.640 --> 01:14:55.680]  минимального остова. Так вот здесь некоторая неприятность в том, что я добавляю сразу
[01:14:55.680 --> 01:14:59.840]  много ребер с копом. У меня есть подножие минимального остова, я добавляю сразу много
[01:14:59.840 --> 01:15:05.480]  ребер и говорю, что это опять подножие минимального остова. Не по одному, а с
[01:15:05.480 --> 01:15:11.240]  копом сразу группу. Так вот, почему же это верно? Давайте нарисую какую-нибудь компоненту.
[01:15:11.240 --> 01:15:22.480]  Вот, например, вот эта вот штука, этот кусок функционального
[01:15:22.480 --> 01:15:24.920]  графа, описывает, какие ребра я добавляю на очередном
[01:15:24.920 --> 01:15:25.920]  этапе.
[01:15:25.920 --> 01:15:29.620]  Значит, смотрите, понятно, что эта вершина является
[01:15:29.620 --> 01:15:32.280]  подножием минимального астова, вершина это всегда
[01:15:32.280 --> 01:15:33.280]  подножие астова.
[01:15:33.280 --> 01:15:36.960]  Дальше, я знаю, что это ребро, вот исходящее из него,
[01:15:36.960 --> 01:15:40.120]  которое я выбрал, это ребро минимального веса, из него
[01:15:40.120 --> 01:15:41.120]  торчащее.
[01:15:41.120 --> 01:15:43.440]  Если бы я применил лему о безопасном ребре к этому
[01:15:43.440 --> 01:15:46.540]  множеству, если бы я сказал, что это Т, тогда она бы мне
[01:15:46.540 --> 01:15:48.720]  сказала, что это ребро можно безопасно добавить, потому
[01:15:48.720 --> 01:15:51.140]  что это просто самое дешёвое ребро.
[01:15:51.140 --> 01:15:53.600]  Значит, это ребро точно можно добавить.
[01:15:53.600 --> 01:15:59.680]  Дальше, для этой вершинки я знаю, что вес этого ребра
[01:15:59.680 --> 01:16:03.680]  меньше равен веса этого ребра.
[01:16:03.680 --> 01:16:08.680]  Кост Е штрих меньше равно кост Е.
[01:16:08.680 --> 01:16:10.680]  вес этого меньше равен весу этого.
[01:16:10.680 --> 01:16:12.680]  Мы это уже замечали, что если для
[01:16:12.680 --> 01:16:14.680]  этой вишенки я выбрал ребро e' а не e,
[01:16:14.680 --> 01:16:16.680]  значит у него вес меньше равен, чем у ребра e.
[01:16:16.680 --> 01:16:20.680]  Поэтому, если я скажу, что вот это текущее
[01:16:20.680 --> 01:16:24.680]  подмножство 100, то это ребро будет
[01:16:24.680 --> 01:16:26.680]  самой дешевой из него торчащей.
[01:16:26.680 --> 01:16:28.680]  Потому что смотрите, как выглядит самый дешевый
[01:16:28.680 --> 01:16:30.680]  ребро торчащий из этого множества.
[01:16:30.680 --> 01:16:32.680]  Это либо ребро из этой вишенки, либо из этой.
[01:16:32.680 --> 01:16:34.680]  Но мы знаем, что самое дешевое ребро торчащее
[01:16:34.680 --> 01:16:36.680]  из нее было e, и мы его уже взяли,
[01:16:36.680 --> 01:16:38.680]  значит все остальные весы еще большего.
[01:16:38.680 --> 01:16:40.680]  А из этой вишенки
[01:16:40.680 --> 01:16:42.680]  какие-то новые ребра появляются,
[01:16:42.680 --> 01:16:44.680]  и вот у ребра веса меньше,
[01:16:44.680 --> 01:16:46.680]  Schw copyrightfect Bunun tz explicit, значит оно будет минимfficiency.
[01:16:46.680 --> 01:16:48.680]  То есть, когда я обьединяю вот это в одну компоненту связанности,
[01:16:48.680 --> 01:16:50.680]  то самое дешевое исходящее ребро будет
[01:16:50.680 --> 01:16:52.680]  ровно вот это вот. Потому что все исходящие из этой вишенки
[01:16:52.680 --> 01:16:54.680]  более низкой, имеют вес больше,
[01:16:54.680 --> 01:16:56.680]  имеют вес больше ночьем e,
[01:16:56.680 --> 01:16:58.680]  значит больше ночьем e'.
[01:16:58.680 --> 01:17:00.680]  Поэтому я могу объединить вот это все
[01:17:00.680 --> 01:17:02.680]  в одну компоненту связанности.
[01:17:02.680 --> 01:17:04.680]  То есть, считать, что это подм�ба balanced rule.
[01:17:04.680 --> 01:17:08.680]  Ну и так, что мы дальше по дереву делаем, давайте еще раз это рассуждение проведу.
[01:17:08.680 --> 01:17:13.680]  Вот есть подножие минимального астова, и есть самое дешевое ребро, исходящее из этой вершинки.
[01:17:13.680 --> 01:17:20.680]  Ребро E2'H. Я знаю в силу моего вот этого подъема, снизу вверх поднимаюсь,
[01:17:20.680 --> 01:17:24.680]  я знаю, что ребро E2'H дешевле, чем E' и чем E.
[01:17:24.680 --> 01:17:29.680]  Поэтому, если я буду считать вот это вот все одной, ну как бы, неделимой сущностью,
[01:17:29.680 --> 01:17:33.680]  и находить самое дешевое ребро, торчащие из нее во внешность графа,
[01:17:33.680 --> 01:17:36.680]  то, конечно, это самое дешевое ребро будет E2'H, потому что оно самое дешевое,
[01:17:36.680 --> 01:17:41.680]  торчаще из нее, и оно недороже, чем торчаще из этих и из этих, из-за этих неравенств.
[01:17:41.680 --> 01:17:44.680]  Значит, я могу объединить вот это вот в одну компоненту.
[01:17:44.680 --> 01:17:48.680]  Ну и то же самое я просто для всех делаю, что для этой вершинки я могу добавить это ребро,
[01:17:48.680 --> 01:17:50.280]  потому что оно самое дешевое.
[01:17:50.280 --> 01:17:54.280]  Для вот этой вершинки я могу добавить это ребро, потому что для всей этой компоненты это ребро самое дешевое,
[01:17:54.280 --> 01:17:56.780]  потому что он меньше от ps, чем все остальные. Ну и так далее.
[01:17:56.780 --> 01:18:01.780]  Это означает, что в конце я просто, многократным применением нашей леммы,
[01:18:01.780 --> 01:18:04.780]  получаю, что все эти ребра можно добавить в остов,
[01:18:04.780 --> 01:18:07.780]  тем самым я никогда ничего не делаю незаконного.
[01:18:07.780 --> 01:18:10.780]  На каждом шаге я добавляю ребро, которое можно добавить.
[01:18:13.780 --> 01:18:18.780]  Так, ну, многократное применение
[01:18:21.780 --> 01:18:26.780]  леммы о безопасном земле.
[01:18:31.780 --> 01:18:34.780]  Вот, значит, алгоритм действительно корректный.
[01:18:34.780 --> 01:18:37.780]  Получает минимальный остов.
[01:18:37.780 --> 01:18:40.780]  Осталось понять, за сколько он это делает.
[01:18:46.780 --> 01:18:50.780]  Я утверждаю, что асимптотика здесь будет m log n,
[01:18:56.780 --> 01:18:59.780]  потому что всего итерации в рекурсе будет log n.
[01:18:59.780 --> 01:19:02.780]  Это следует из того, что на каждом шаге,
[01:19:02.780 --> 01:19:05.780]  когда я сжимаю компоненты связности,
[01:19:05.780 --> 01:19:08.780]  вот эта функциональная мемографа,
[01:19:08.780 --> 01:19:11.780]  у меня число компонент уменьшается хотя бы вдвое.
[01:19:11.780 --> 01:19:14.780]  Потому что, представьте, изначально было n вершин.
[01:19:14.780 --> 01:19:17.780]  Дальше я для каждой нашел исходящее ребро самое дешевое
[01:19:17.780 --> 01:19:20.780]  и сжал компоненты связности из тех самых дешевых ребер.
[01:19:20.780 --> 01:19:23.780]  Тогда понятно, что после сжатия,
[01:19:23.780 --> 01:19:26.780]  то есть тут будут какие-то вот такие объединения,
[01:19:26.780 --> 01:19:29.780]  компонент связности будет не больше, чем n пополам.
[01:19:29.780 --> 01:19:32.780]  Потому что размер каждой компоненты будет хотя бы 2.
[01:19:35.780 --> 01:19:38.780]  Так как в каждой компоненте
[01:19:44.780 --> 01:19:47.780]  хотя бы две вершины.
[01:19:47.780 --> 01:19:50.780]  Хотя бы две, потому что из каждой вершины что-то выходит,
[01:19:50.780 --> 01:19:53.780]  поэтому она не работает, и она не работает,
[01:19:53.780 --> 01:19:56.780]  хотя бы две, потому что из каждой вершины что-то выходит,
[01:19:56.780 --> 01:19:59.780]  поэтому она не одна в своей компоненте.
[01:19:59.780 --> 01:20:02.780]  Значит, все компоненты имеют размер хотя бы 2.
[01:20:02.780 --> 01:20:05.780]  А значит, их количество не больше, чем n пополам.
[01:20:05.780 --> 01:20:08.780]  Поэтому число вершин после сжатия уменьшается хотя бы вдвое.
[01:20:08.780 --> 01:20:11.780]  Если тут было n, то здесь не больше, чем n пополам.
[01:20:11.780 --> 01:20:14.780]  Значит, суммарно глубина рекурсии,
[01:20:14.780 --> 01:20:17.780]  сколько раз я сжимаю, сжимаю, сжимаю,
[01:20:17.780 --> 01:20:20.780]  не больше, чем логарифм.
[01:20:20.780 --> 01:20:23.780]  Немного уменьшается, поэтому глубина рекурсия максимум логарифм.
[01:20:23.780 --> 01:20:26.780]  Ну а m нужно для того, чтобы для каждой вершинки
[01:20:26.780 --> 01:20:29.780]  определить, какое самое дешевое входящее в нее ребро.
[01:20:29.780 --> 01:20:32.780]  Я просто все ребра просматриваю и определяю из них самое дешевое.
[01:20:36.780 --> 01:20:39.780]  Log n это глубина рекурсии,
[01:20:45.780 --> 01:20:48.780]  m это поиск самых дешевых ребер.
[01:20:50.780 --> 01:20:53.780]  Самый дешевый ребер.
[01:20:53.780 --> 01:20:56.780]  Вот, кажется, все.
[01:20:59.780 --> 01:21:02.780]  Так, ну алгоритм Барувки
[01:21:02.780 --> 01:21:05.780]  он с точки зрения симптотики не выглядит
[01:21:05.780 --> 01:21:08.780]  сильно лучше, чем Прим или Крускал.
[01:21:08.780 --> 01:21:11.780]  Но, во-первых, насколько я понимаю,
[01:21:11.780 --> 01:21:14.780]  он просто исторически самым первым был придуман.
[01:21:14.780 --> 01:21:17.780]  Поэтому, я думаю, что это очень хорошо.
[01:21:17.780 --> 01:21:20.780]  И еще, если его совместить с алгоритмом Прима,
[01:21:20.780 --> 01:21:23.780]  то можно получить новый алгоритм с еще более
[01:21:23.780 --> 01:21:26.780]  ну, в общем, с еще более быстрой симптотикой.
[01:21:26.780 --> 01:21:29.780]  На семинаре посмотрите, там что-то типа вот здесь можно написать
[01:21:29.780 --> 01:21:32.780]  log log вместо логарифм, можно написать повторный алгоритм,
[01:21:32.780 --> 01:21:35.780]  если совместить Барувку и Прима.
[01:21:35.780 --> 01:21:38.780]  Так, ну а на этом, наверное, давайте закончим.
[01:21:38.780 --> 01:21:41.780]  Спасибо за внимание.
[01:21:47.780 --> 01:21:50.780]  До свидания.
