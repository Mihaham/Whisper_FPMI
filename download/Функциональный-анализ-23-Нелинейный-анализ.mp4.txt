[00:00.000 --> 00:10.180]  Продолжаем нашу работу. Сначала одно замечание к теореме Гильбетта Шмидта,
[00:10.180 --> 00:15.140]  которую мы доказали в прошлый раз. Поскольку мы все равно будем сейчас ее обсуждать,
[00:15.140 --> 00:36.980]  я еще раз ее повторю. Есть сепарабельное гильбертово пространство, есть а-компактный
[00:36.980 --> 00:56.260]  оператор сопряженный само. Теорема говорит, что тогда ваше найдется ортонормированный
[00:56.260 --> 01:11.500]  бодис, состоящий из собственных векторов оператора А. Замечание относится к тому,
[01:11.500 --> 01:21.540]  что я там и рассказывал. Там были введены элементы, ортонормированный бодис во всех
[01:21.540 --> 01:29.060]  собственных пространствах, плюс ортонормированный бодис в возможном бесконечномерном пространстве
[01:29.060 --> 01:37.340]  ядре оператора, лямбда равняется нулю. И вот когда мы обозвали всю эту совокупность ортонормированную
[01:37.340 --> 01:47.220]  через Е, утверждалось, что линейная оболочка этого семейства плотна Ваш, и мы это доказывали.
[01:47.220 --> 01:56.660]  Идея доказательств в том, что если это обознатить через М и написать разложение М плюс аннулятор
[01:56.660 --> 02:03.020]  равняется А, то надо просто доказать, что вот этот кусок тривиальный, нулевой. И идея в том,
[02:03.020 --> 02:10.100]  что если он нулевой, то во всех вариантов, вариантов было два, такие сужение оператора А,
[02:10.100 --> 02:18.100]  рассматривалось обозначение с волной А на вот этот аннулятор. Дело в том, что здесь,
[02:18.100 --> 02:24.780]  поскольку все собственные векторы, это инвариантное пространство, понятным образом, по леймитрии
[02:24.780 --> 02:30.740]  нашей, тогда аннулятор ортогональный, тоже вариант. И вот мы его там рассматривали,
[02:30.740 --> 02:37.060]  и я говорю, есть два варианта. И в обоих случаях, если предположить, что это пространство не нулевое,
[02:37.060 --> 02:45.060]  в обоих случаях таком и таком мы приходим к противоречию. Так вот в этом варианте я
[02:45.060 --> 02:51.460]  ссылался, посмотрел записи на лему 1, она должна быть лему 4. Вот и всё. Про то,
[02:51.460 --> 02:56.740]  что у нетривиального компактного самосопряжённого оператора всегда есть не нулевой собственный вектор.
[02:56.740 --> 03:05.060]  Мы её доказывали с помощью теоремы основной про спектры самосопряжённых операторов,
[03:05.060 --> 03:11.660]  что наибольшее, наименьшее значение квадратичной формы лежат в спектре, а потом лему 1,
[03:11.660 --> 03:16.260]  там ещё присоединённое давало результат, что это раз не ноль, и в спектре, значит,
[03:16.260 --> 03:21.700]  это собственное значение. Понятно. Вот это маленькое уточнение, просто в записи,
[03:21.700 --> 03:27.980]  почему-то там я торопился, что-то прошло. Несколько следствий к этой теореме, такое обсуждение небольшое.
[03:27.980 --> 03:39.380]  Следствия. Я сейчас буду даже подсматривать свои записи, чтобы ни в коем случае не перепутать
[03:39.380 --> 03:46.340]  порядок или что-то ещё. Следствие первое. Значит, я буду находиться в условиях этой теоремы, есть
[03:46.340 --> 03:51.900]  сепарабельное гильбертого пространство, есть компактный самосопряжённый оператор, есть утверждение
[03:51.900 --> 03:58.220]  теоремы, что есть ортонаромерные байты со собственных векторов. Первое утверждение такое, что для любого
[03:58.220 --> 04:12.180]  x из h образ этого элемента может быть представлен в виде сумма лямбда n, x, e, n, e, n, где суммерами идётся
[04:12.180 --> 04:20.540]  по всем собственным значениям, наверное, отличным от нуля. Но в математической физике это называется
[04:20.540 --> 04:28.340]  столькообразная представимая функция. Там операторы, это всегда операторы такого вида в стандартной
[04:28.340 --> 04:37.580]  технике, связанной с обоснованием методов. Сразу запишу. А от f в точке х есть интеграл от а до b, как x, t,
[04:37.580 --> 04:49.060]  f от t до t, где функция k произойдёт л2 на вот этой кляксе в квадрате, а b в квадрате вот так вот так.
[04:49.060 --> 05:02.660]  Является ядром таким, что к, х, t с чертой есть k, t, x. Получается в результате самосопряжённый оператор,
[05:02.660 --> 05:10.660]  и вот для него как раз когда применяется тирема Дюбетта Шмидта, то происходит нечто связанное с обоснованием
[05:10.660 --> 05:18.820]  метода Фурьер. Об этом я ещё потом поговорю. Поэтому вот там, например, а от х, а от f это вот такие функции, как раз которые
[05:18.820 --> 05:26.820]  рассматриваются очень важным образом в связи с этой всей деятельностью. Ну а тут у нас, попросту говоря,
[05:26.820 --> 05:37.580]  произвольный х, я представил в виде суммы х, ен, ен, по лямбде неравному нулю, плюс е нулевое, элемент из вот этого ядра,
[05:37.580 --> 05:43.740]  оператора. Ну и когда я подействую оператором, то получится просто эта формула. Тут ничего мудренного для нас сейчас уже нет.
[05:43.740 --> 05:52.820]  Следствие 2. Практическое. Вот представьте себе, что мы решаем наше стандартное уравнение, а минус лямбде,
[05:52.820 --> 06:01.620]  я даже полностью на себе раз напишу, равняется y, и лямбда у меня принадлежит резолентовому множеству. То есть это такая лямбда,
[06:01.620 --> 06:09.780]  что при любом y, какой бы я в правой части ни взял, решение существует, единственное неправильно зависит от правой
[06:09.780 --> 06:18.500]  части. Такой случай мечта для всякого решателя. Так вот спрашивается, а как технически искать?
[06:18.500 --> 06:34.740]  Очень просто. Если я буду этот элемент x трактовать как сумму ряда Фуриеса, то я его
[06:34.740 --> 06:40.700]  буду знать, если я буду знать эти коэффициенты. Правда? Ну вот если я подставлю такое выражение
[06:40.700 --> 06:57.460]  сюда, вот это x, вот в такой формуле, у меня превратится в сумму по лямбда к атом неравным нулю лямбда к х ек ек.
[06:57.460 --> 07:10.180]  Здесь у меня получится минус сумма лямбда х все ек ек. Ну и понятное дело, что вот если я соберу коэффициенты,
[07:10.180 --> 07:18.980]  при каком-то таком коэффициенте Фурия здесь, то получится формула лямбда к минус лямбда в знаменателе,
[07:18.980 --> 07:34.460]  у ек вот здесь, у ек вот здесь и х ек вот здесь. То есть попросту говоря, ну там где нулевое значение,
[07:34.460 --> 07:42.700]  просто добавок никаких нет. И вот у меня получится формула элементарная, представляющая собой коэффициенты
[07:42.700 --> 07:48.580]  будущего решения x, выражающие эти коэффициенты Фурия через коэффициенты Фурия правой части.
[07:48.580 --> 07:56.180]  Это, ну если это лямбда вот такая хорошая, одно из толкований этой формулы совершенно замечательное
[07:56.180 --> 08:02.220]  стоит в том, что вот эту резолвенту r лямбда, я в духе теории функций комплексного переменного,
[08:02.220 --> 08:08.620]  когда вы помните, может быть вы это делали, может нет, не знаю, номероморфные функции, вы представляли
[08:08.620 --> 08:14.180]  в виде суммы таких простых слагаемых, в данном случае это разложение будет выглядеть так. Сумма
[08:14.180 --> 08:26.980]  лямбда ката минус лямбда, оператор P ката, проектирование на соответствующий. Это вот выражение
[08:26.980 --> 08:33.020]  просто того же самого обстоятельства, который сидит в этой форме. Вот если рассматривать r лямбда
[08:33.020 --> 08:41.220]  как функцию оператор назначенного комплексного аргумента лямбда, то вот эта функция раскладывается
[08:41.220 --> 08:49.620]  в сумму с функциями с такими простыми полюсами. Видите? Была эта теория про разложение мироморфной
[08:49.620 --> 08:56.940]  функции. Не помните? А что такое мироморфная функция? Все. Короче говоря, я не буду тогда
[08:56.940 --> 09:04.660]  опираться на ассоциации которых, но тем не менее это понятно. Следствие 3. А как вот решать уравнение,
[09:04.660 --> 09:13.780]  если лямбда совпадает с одним из этих лямбда как? Ну не разных нулевым. Ну ответ очень простой,
[09:13.780 --> 09:21.820]  не буду даже писать. По всем отличным этот лямбда будет такая же формула. А вот если я
[09:21.820 --> 09:27.780]  решаю ведь уравнение вот такое, лямбда у меня сейчас вот такая, лямбда ката, то это означает,
[09:27.780 --> 09:35.180]  что у этого уравнения когда здесь 0, есть нетривиальные решения. И вот берется соответствующее пространство
[09:35.180 --> 09:42.340]  вот это, собственно отвечающее данным на лямбда ката. Мы с вами знаем, что если это не 0, это конечно
[09:42.700 --> 09:49.300]  пространство. И вот общее решение этого однородного уравнения добавляется к слагаемым такого вида по остальным
[09:49.300 --> 09:56.220]  всем коэффициентам. И получается не единственное решение. Можно там условия разрешимости опять
[09:56.220 --> 10:00.300]  написать с терем Фредгольма, можно наоборот с помощью этих терем, теремы Фредгольма получить,
[10:00.300 --> 10:06.500]  что тоже важно и полезно. Помните как у нас развивается событие, когда мы сначала доказали терему
[10:06.500 --> 10:12.260]  Рисофреше про общий вид функционала линейного гильвертного пространства. Потом появилась
[10:12.260 --> 10:20.020]  терема Банаха, Хана Банаха, извиняюсь. Отдельно доказали, но ее можно вывести в Гильвертом
[10:20.020 --> 10:25.300]  случае из теремы Рисофреше как элементарное совершенно утверждение. Вот так примерно и здесь.
[10:25.300 --> 10:34.460]  Из вот этих всех терем, которые у нас появились, можно терема Фредгольма,
[10:34.460 --> 10:39.420]  о котором мы отдельно доказывали в общем случае, в сепарабиум случае гильвертового
[10:39.420 --> 10:44.420]  комплексного пространства, терем Фредгольма можно получить из терем Гильверта Шмита и вот этих
[10:44.420 --> 10:51.260]  всех следствий. Делать этого не буду и писать тоже не буду. Следствия 4. Очень полезная практическая.
[10:51.260 --> 11:06.860]  Структура спектра компактного самосопряженного оператора в сепарабиум гильвертом пространства.
[11:06.860 --> 11:15.260]  Тут сейчас подумаю, что мне можно стереть, да вот это можно стереть и на этом месте что-нибудь нарисовать.
[11:15.260 --> 11:29.780]  Так лучше, наверное, стирать той машинкой. Нет, просто как совет. Нет, я говорю, видно? А,
[11:29.780 --> 11:40.900]  ну тогда все, я только про это. Значит следствие сформулирую так. Я просто сейчас напишу всевозможные
[11:40.900 --> 11:52.340]  варианты. Ну вот так, пожалуй, вилку возможностей. Продолжение разговора следствия 4. Значит две
[11:52.340 --> 12:03.660]  возможности. Бесконечно много собственных значений неравных нулю и конечное число собственных
[12:03.660 --> 12:16.300]  значений неравных нулю. Понятно. Может быть и так и так. Вот что будет собой представлять спектр и в том
[12:16.300 --> 12:25.940]  и в другом случае подумайте немножко. Первый вариант у меня бесконечно много, вот как я здесь написал.
[12:25.940 --> 12:35.660]  И второй вариант их конечно множество. Вот второй вариант более простой, потому что здесь
[12:35.660 --> 12:40.860]  автоматически ноль принадлежит спектру. Ну как и всегда, впрочем, в этом бесконечном случае. И
[12:40.860 --> 12:49.020]  более того, если их конечное число вообще не нулевых и кратность каждого конечного, то ноль
[12:49.020 --> 12:59.820]  становится собственным значением бесконечной кратности. Правда? Это один вариант. А вот здесь
[12:59.820 --> 13:10.620]  два под варианты. Вариант А и вариант В. Какие? Вот их бесконечно много. Ноль может быть предельной
[13:10.620 --> 13:16.820]  точкой, а может не быть предельной точкой этой последности. Или обязательно он будет предельной
[13:16.820 --> 13:26.100]  точкой, когда их бесконечно много. Вот здесь он не будет предельной точкой, понятное дело, он сам по себе.
[13:26.100 --> 13:32.220]  А здесь он будет, конечно, к нему они будут стягиваться по неволе, потому что деваться некуда. Но,
[13:32.220 --> 13:40.500]  тем не менее, вот есть два варианта. Ноль является собственным значением. Спектр принадлежит
[13:40.500 --> 13:49.260]  собственным значениям, и он не собственным значением. Но вот в этом случае весь спектр,
[13:49.260 --> 13:55.020]  есть точный спектр, понятное дело, но есть не нулевые собственные значения, есть ноль,
[13:55.020 --> 14:03.900]  тоже собственное значение. Правда? А вот в этом варианте есть структура такая. Сигма, есть
[14:03.900 --> 14:13.980]  точный спектр, сигма П, и еще вот этот самый ноль, который попадает в непрерывный спектр. Ну раз он
[14:13.980 --> 14:19.780]  не собственное значение. Вот, собственно говоря, от вас требуется одно по вот этому всему следствию
[14:19.780 --> 14:30.020]  4. Упражнения. Это простое упражнение какой-то нумерации В2. Соорудитель диагональные операторы,
[14:30.020 --> 14:44.020]  мы их рассматривали, такие, чтобы реализовывались все случаи. Один А, один B и два. Все вот эти
[14:44.020 --> 14:52.340]  возможности, чтобы вы себе представляли в виде такой механики. Еще одно замечание, вот очень
[14:52.340 --> 15:00.340]  важно, я еще к нему потом вернусь и, пожалуй, напишу его сейчас в виде упражнений 10, то есть
[15:00.340 --> 15:07.660]  такого занумерованного, серьезного. Но это не будет упражнение, адресованное вам, потому что в
[15:07.660 --> 15:13.460]  одной из следующих лекций мы его разберем. Слишком важная эта вещь. А я пока что в расчете на
[15:13.460 --> 15:21.660]  вашу любопытство, даже не любознательность, вам его предлагаю, предлагаю подумать. Упражнение 10.
[15:21.660 --> 15:31.260]  Значит, дело происходит в Гильбертовом пространстве L2, ну скажем на отрезке АВ. Мы вот в одной из последующих
[15:31.260 --> 15:37.060]  глав, параграфов точнее, будем подробно говорить про жизнь в интегральных вот этих пространствах и
[15:37.060 --> 15:43.620]  про преобразование фурье там, и про преобразование свертки там. Это интересно и важно для ваших
[15:43.620 --> 15:52.340]  аналитических дел в той же дискретной математике, статистики и прочее. Так вот, есть у меня такое
[15:52.340 --> 16:01.380]  пространство, где рассматривается оператор, я его сегодня уже писал. Ат в точке х, есть интеграл
[16:01.380 --> 16:16.780]  от А до В, К, Х, Т, Ф от Т, ДТ. И функция К принадлежит L2, А, В в квадрате, вот так. Надо доказать, что тогда
[16:16.780 --> 16:28.540]  оператор А является компактным. Что вот если вот это ядро приличное, интегрированное во второй
[16:28.540 --> 16:36.540]  степени по модуле функция на декарту произведения АВАВ, то это компактный оператор. Такие операторы,
[16:36.540 --> 16:44.620]  вот когда такое слово выполнено, носят особое название, операторы Гильберта Шмита. Это тот самый
[16:44.620 --> 16:51.660]  Гильберт, тот самый Шмит, который в теореме. Так что не мудрено, что такая задача оказывается по
[16:51.660 --> 16:59.340]  соседству с формлёвкой этой теремы. Вопрос к вам. Какие способы у нас есть доказательства компактности
[16:59.340 --> 17:06.500]  оператора? Давайте с вас начнём. По определению. Для этого надо располагать критериям компактности
[17:06.500 --> 17:13.100]  L2, предкомпактности, точнее. Правильно? По определению, это образ ледничного шара, предкомпакта. Вы знаете
[17:13.100 --> 17:22.460]  критерии предкомпактности L2? Скорее всего нет. Мы не обсуждали. Так что при вашем способе решения,
[17:22.460 --> 17:29.500]  оно разбивается на две части. Вы где-то добываете критерии предкомпактности L2 и потом проверяете.
[17:29.500 --> 17:36.460]  Что значит добываете? Сами придумываете, какие-то справочники читаете. Неважно. Второй вариант. Вот мы
[17:36.460 --> 17:43.260]  им воспользуемся. Это терема, которую мы обсуждали. Если есть по сравнению компактных операторов,
[17:43.260 --> 17:49.300]  которые по норме сходятся к этому, то и этот предельный оператор тоже компактный. Вот в этих
[17:49.300 --> 17:55.380]  делах, в всех всепарабельных пространствах Гильбертовых, где байсы есть, второй путь всегда
[17:55.380 --> 18:03.260]  предпочтительнее, удобнее и стандартнее. Хотя можно идти по первым пути, если вы раздобудете
[18:03.260 --> 18:09.380]  критерии предкомпактности. Они есть, это все в справочниках имеется. Пожалуйста, конечно. Но мы
[18:09.380 --> 18:18.100]  разберем именно этот второй вариант. И я еще в заключение скажу такую вещь. Вот где это все возникает,
[18:18.100 --> 18:26.060]  в том, то ли читаем вам, то ли не читаем вам в курсе уравнений математической физики. Читают вам
[18:26.060 --> 18:32.300]  курс? Какой-то читают. Там есть метод Фурье. Выясняется, что для многих типов уравнений,
[18:32.300 --> 18:37.460]  вот решаете в уравнении вместе с какими-то кровыми условиями, решаете на задачах какого-то класса
[18:37.460 --> 18:44.540]  главкости. Ну, функция дважды непременно дифференцируемая, там еще что-то, граничные условия.
[18:44.540 --> 18:50.860]  Вырезается тем самым некое многообразие внутри такого самого Гильбертового льдва. И вот вы в
[18:50.860 --> 18:58.500]  процессе решения методом Фурье выходит на построение неких простых кирпичей, соответствующих
[18:58.500 --> 19:03.780]  структуре этого дифференциального выражения. А решение, скажем, в случае эволюционном,
[19:03.780 --> 19:08.140]  если зависит это от t, это будут какие-то функции, зависящие от t, как коэффициенты,
[19:08.140 --> 19:13.940]  которые будут умножаться на эти кирпичи в виде таких рядов. В каждой точке t свое разложение.
[19:13.940 --> 19:23.460]  И теоремы Гильберта Шмита там появятся таким образом. Вы с помощью теоремы Гильберта Шмита
[19:23.460 --> 19:28.340]  будете получать представление какой-то функции по вот этому базе своих собственных векторов.
[19:28.340 --> 19:34.620]  Но в метрике льдва, хотя вам для решения уравнения нужно, чтобы там можно было дифференцировать
[19:34.620 --> 19:40.020]  по членам и так далее. Минимальная сходимость, которая хороша в этих дифференциальных задачах,
[19:40.020 --> 19:46.500]  это так называемая регулярная сходимость. Это когда ряды из модуля сходятся равномерно,
[19:46.500 --> 19:51.660]  а даже не только в самой функции, но и в производной. Так вот, представьте себе,
[19:51.660 --> 19:56.260]  что у меня какой-то ряд сходится регулярно. То есть, скажем, равномерно ряд из модуля.
[19:56.260 --> 20:02.380]  Ясное дело, что оттуда будет следовать сходимость по метрике льдва более слабой. Ну, из равномерной
[20:02.380 --> 20:11.500]  сходимости. Это стандартная в математике кухня, когда чтобы найти какой-то объект в виде суммы
[20:11.500 --> 20:18.060]  сильно сходящегося, например, ряда, по какой-то сильной норме или какой-то спецификой связанной
[20:18.060 --> 20:25.580]  с дифференцированием, находят предел, сумму, в виде более слабо сходящегося, ряда,
[20:25.580 --> 20:30.580]  по сходимости и так далее. Но поскольку это необходимые условия той сильной сходимости,
[20:30.580 --> 20:37.300]  то после этого бросаются силы на то, чтобы доказать, что в слабом смысле предел оказывается на самом
[20:37.300 --> 20:44.180]  деле сильным пределом. Но есть уже конкретный кандидат. Вот у вас есть ряд по метрике льдва
[20:44.180 --> 20:49.780]  сходящегося, какой-то функции. Вы его берете, потом учителям долго доказываете на страницах
[20:49.780 --> 20:54.420]  учебников по матфизике, что на самом деле этот ряд сходится не только в льдва, но и вот так, что
[20:54.420 --> 21:00.940]  можно его почти дифференцировать, подставлять. Вот вся философия методов Ирье. Цепочка там такая,
[21:00.940 --> 21:10.340]  если вы уже достаточно вникли. Мы решаем кривую задачу. Мы идем так называемым методом разделения
[21:10.340 --> 21:16.580]  переменных. Получаем, ну скажем, вот таком одномерном случае на отрезке для уравнения второго порядка,
[21:16.580 --> 21:23.580]  какую-то задачу на собственное значение. Ее с помощью функции гринопростроения мы сводим к
[21:23.580 --> 21:30.860]  интегральному уравнению. И получается уже вот задачи про оператора такого вида. Для тех это
[21:30.860 --> 21:35.900]  называется теорема Стеклова. Еще для дифференциального значения. Здесь это теорема Гильберта Шмита. Но она в
[21:35.900 --> 21:42.020]  конце вот этой цепочки обоснования того, почему каждый раз чудодейственным образом, когда вы
[21:42.020 --> 21:47.820]  решаете задачу методом Фырье, получается базис, без разложений по которому находится вот эта
[21:47.820 --> 21:55.740]  самая искомая функция. Вот теорема Гильберта Шмита в конце этой, выражаясь биологическим языком,
[21:55.740 --> 22:03.700]  пищевой цепочки, неважно, кто кого тут съест, важно, что вот обоснование методов Фырье это как раз вот
[22:03.700 --> 22:10.220]  эта самая магистраль. Я об этом еще поговорю, когда мы на одной из следующих лекций будем говорить про
[22:10.220 --> 22:16.180]  компактность этих операторов. Потому что про L2 и L1 мы отдельно будем говорить. Раз это очень
[22:16.180 --> 22:22.460]  важны для вас миры, в которых вам как аналитикам надо уметь пользоваться и преобразованием Фырье и так
[22:22.460 --> 22:29.500]  далее. Договорились? А я сейчас вместе с вами перейду к следующему параграфу,
[22:29.500 --> 22:44.620]  такому веселому. Как это делается? Мне на что надо нажать, чтобы отжать ее? Вот эту наверх?
[22:44.620 --> 22:56.460]  Здорово. Я буду стирать и одно время он сами разговаривает. Вот давайте задумаемся.
[22:59.500 --> 23:07.540]  Что такое дифференциальное счисление? Вы им занимались на первых, ну в первых двух
[23:07.540 --> 23:13.340]  семестрах реально вашего курса математического анализа. Сначала в одномерном варианте, потом
[23:13.340 --> 23:21.100]  многомерном. Были какие-то странные теоремы, были дифференциалы, были частные производные,
[23:21.100 --> 23:27.340]  заметношения были непростые. Можно было иметь частные производные во всех точках и не быть
[23:27.340 --> 23:33.780]  непрерывной функцией. В общем, какая-то странность такая была. Ну хотя в одной точке я имею частные
[23:33.780 --> 23:38.860]  производные, а непрерывности нет. Не говоря, что дифференциальности. Были какие-то с довесками
[23:38.860 --> 23:44.500]  теоремы, что если частные производные есть, а они непрерывные, то там появляется дифференцируемость.
[23:44.500 --> 23:54.300]  Ну вот мы сейчас с вами давайте так другую задачу. Вот я хочу создать в банховом пространстве
[23:54.860 --> 24:00.820]  дифференциальное исчисление. Но, например, для решения задач вариационного исчисления мне надо,
[24:00.820 --> 24:06.700]  вот как там, когда мы на экстремуме исследовали функции, теорема Ферма, угладкой функции,
[24:06.700 --> 24:11.780]  необходимые условия локального экстремума, это равенство нулю производной и так далее.
[24:11.780 --> 24:21.820]  Так ведь? Вот хотя бы для этого. С точки зрения науки под названием теория управления. А что здесь в этих
[24:21.820 --> 24:31.180]  пространствах? И вот сейчас, когда мы поймем правильно азы дифференциального исчисления в самом
[24:31.180 --> 24:41.140]  общем случае, мы поймем, что мы уже отчасти подготовлены к созданию структур, которые можно
[24:41.140 --> 24:48.860]  условно назвать дифференциальными исчислениями. Итак, параграф 13, следующий за предыдущим 12,
[24:48.860 --> 25:10.900]  и назваться он будет так. Элементы нелинейного анализа. Ну, когда пишут слово элемента, дают сразу
[25:10.900 --> 25:19.100]  понять, что это будет какая-то такая не очень сильно структурированная, разотленная масштабная
[25:19.100 --> 25:28.500]  деятельность, какие-то фрагменты. Понятно. Тем не менее. Вот давайте сначала погрузимся в воспоминания.
[25:28.500 --> 25:44.700]  Воспоминания. Вы изучаете отображение, действующее там, скажем, из Rn в какой-то Rn. Как вы
[25:44.700 --> 25:49.580]  определяете, что это отображение дифференцируемо в точке х нулевой, о котором принадлежит вот
[25:50.300 --> 26:01.340]  дифференцируемости. Помните свое определение, что означает, что отображение f большое дифференцируемо в точке х нулевой.
[26:01.340 --> 26:10.620]  Дело безответственное, параграф называется элементы, поэтому это ни на чем не отразится.
[26:19.580 --> 26:25.540]  Вот мне очень не нравится фраза, которую вы принесли, но замечательно, что вы принесли. Не
[26:25.540 --> 26:30.620]  нравится, потому что с самого начала вы погружаетесь в какие-то арифметические взаимоотношения,
[26:30.620 --> 26:38.500]  толком еще ничего не описав. Если бы это был одномерный вариант из R1 в R1. Вот в R1 есть
[26:38.500 --> 26:45.820]  удивительным образом два определения. Существование производной и совершенно другие слова
[26:45.820 --> 26:56.580]  связаны со словом дифференцируемости. Наличие производной это существование предела f от x минус f от
[26:56.580 --> 27:05.900]  x нулевое, поделить на x минус x нулевое, вот при этом x стремящимся к этому x нулевому. На языке
[27:05.900 --> 27:12.100]  производной. Есть совершенно другое внешнее определение, когда превращение дельта f можно
[27:12.100 --> 27:18.380]  записать в виде a на дельта x плюс епсел на дельта x, которые епсел на дельта есть,
[27:18.380 --> 27:24.580]  умалые от этого самого дельта x. То есть это поделить на модуль дельта x стремиться к нему. И вот
[27:24.580 --> 27:31.060]  в одномерном варианте совершенно замечательным образом это оказывается эквалентным. Когда вы
[27:31.060 --> 27:37.380]  выходите вот сюда, здесь мы начинаем идти по дороге, ну в стандартном наложении частных
[27:37.380 --> 27:42.100]  производных, здесь появляется пани дифференцируемости, и они уже вовсе не эквалентны.
[27:42.100 --> 27:49.200]  Был еще у вас один случай, когда эквалентность такая была и совсем недавно, в курсе комплексного
[27:49.200 --> 27:56.100]  анализа. На комплексной плоскости, когда вы изучали функции комплексного аргумента, были даны оба
[27:56.100 --> 28:02.220]  определения, и вот выяснилось, что в комплексном варианте это опять же одно и то же. Но это и не
[28:02.220 --> 28:08.420]  мудрено, потому что комплексный вариант тоже по сути одномерный. Просто в качестве этого
[28:08.420 --> 28:14.500]  одномерного линейного нормированного пространства выступают поликомплексных чисел, которые на
[28:14.500 --> 28:20.380]  этом языке одномерны. Так что ничего удивительного нет. А вот здесь, если говорить о дифференцируемости,
[28:20.380 --> 28:27.940]  было такое определение, вот я смотрю сюда, дельта f представляется в виде а на дельта x плюс
[28:27.940 --> 28:34.780]  epsilon на дельта x, где вот это опять же добавка, она такова, что модуль epsilon дельта x поделить на
[28:34.780 --> 28:44.440]  модуль дельта x, стремится к нему пред дельта x, а здесь некая матрица, которая у вас называлась
[28:44.440 --> 28:52.380]  матрица Якоби, вы ударение куда ставите? Якоби, Якоби или Якоби? А? Правильно, абсолютно. В данном
[28:52.380 --> 29:01.540]  случае это Якоби. Якоби есть венгерский математик, Якоби есть с французскими корнями, но все нормальные
[29:01.540 --> 29:10.900]  из германских земель Якоби, а не Якоби. Вот так. И там потом выяснится, что если она дифференцирована,
[29:10.900 --> 29:17.060]  то там есть все частные производные и так далее. Но дорога односторонняя. В обратную сторону есть
[29:17.060 --> 29:23.180]  всякие примеры, мы сейчас часто еще вспомним, но была та же теорема, что если есть неприводные
[29:23.180 --> 29:28.980]  частные производные, то дифференцируем. Помните? Прекрасно. Вот теперь представьте себе ситуацию
[29:28.980 --> 29:40.580]  такую. Значит, определение 1. Есть два вещественных, я буду считать банок в пространство, чтобы ни о чем потом не думать.
[29:40.580 --> 29:49.700]  Есть, да, вещественных банок в пространстве. Есть область D из E1, есть отображение F из D в E2.
[29:49.700 --> 29:58.020]  Какой природы, линейный, нелинейный, ничего не знаю. Даже про непривычность ничего не знаю. Тем не менее,
[29:58.020 --> 30:07.380]  даю определение. Отображение большое, называется дифференцируемым. Сейчас подчеркну потом,
[30:07.380 --> 30:18.340]  скажу почему. По фрише в точке x0 принадлежащей D. Ну D давайте считать, что это открытое множество,
[30:18.340 --> 30:24.700]  чтобы было веселее, чтобы можно было любую точку там рассматривать вместе с некоторым шариком в
[30:24.700 --> 30:31.740]  этом нормированном пространстве. Так вот, F называется дифференцируем по фрише в точке x0. Если, смотрим сюда,
[30:31.740 --> 30:41.580]  найдется линейный ограниченный оператор, действующий из E1 в E2. Такой, что дельта F,
[30:41.580 --> 30:51.660]  ну напишу даже, F от x0 и plus h, минус F от x0. Я вот от прощения дельта Х сейчас заменю на h,
[30:51.660 --> 31:01.340]  чтобы природу как-то подчеркнуть разную точку x0 и h функционально. Есть A от h плюс и epsilon от h,
[31:01.340 --> 31:09.780]  где epsilon от h по норме взят и определить на норм h, стремится к нулю, когда к нулю стремится норм h.
[31:09.780 --> 31:16.580]  Как видите, максимально близко к этому я взял определение. Но там была матрица,
[31:16.580 --> 31:25.940]  числовой объект, а теперь это оператор линейно-ограниченный. В этом случае,
[31:25.940 --> 31:40.220]  если это такое представление есть, A называется производной фрише, ну отображение F в точке x0,
[31:40.220 --> 32:02.460]  обозначение F штрих в точке x0. А дифференциал фрише, обозначение вот такое D, F, x0 и надо
[32:02.460 --> 32:13.300]  ставить точку, надо запятую, надо точку запятую, x0 и h, это есть F штрих, x0 и h. И вот главное для меня
[32:13.300 --> 32:20.580]  сейчас, чтобы мы, это будет ваш главный элемент развития сегодняшнего дня, манематическую,
[32:20.580 --> 32:27.580]  вот вы потом из физики что-то узнаете или что-то еще. Когда я говорю про определение дифференциалности
[32:27.580 --> 32:33.940]  в одномерном случае числовых функций и так далее, там вот эта, например, группа производная F штрих
[32:33.940 --> 32:44.040]  в точке x0, умноженная на дельта х, это число, это число и произведение тоже число. И вот очень
[32:44.040 --> 32:50.780]  трудно понять, кто же это все по своей природе. Вот сейчас, благодаря вот этому разделению, у нас,
[32:50.780 --> 33:01.980]  вот глядя на эту формулу, все мы начинаем понимать правильно. Это элемент из E1, это элемент из L
[33:01.980 --> 33:16.140]  E1E2, а весь дифференциал, вот этот, ну вот здесь можно писать, это элемент из E2. Аргумент h из E1,
[33:16.140 --> 33:22.860]  производный оператор, действующий из E1E2, а дифференциал, это значение оператора,
[33:22.860 --> 33:29.100]  производный на аргументе вращения. Вот я когда-то с своим коллегой, замечательным математиком,
[33:29.100 --> 33:35.860]  Дмитрий Викторович, я вам разговаривал над тем лет, 15 назад с лишним, и мы вот сошлись просто
[33:35.860 --> 33:40.740]  во мнении, что, грубо говоря, мы не понимаем, как правильно понимать даже в одномерном случае,
[33:40.740 --> 33:46.740]  что такой дифференциал, когда все числа, и что такое производное, если не рассматривать,
[33:46.740 --> 33:53.100]  в голове держать вот этот уже отвлеченный абстрактный вариант. Природа совершенно разная,
[33:53.100 --> 33:59.460]  дифференциал значение оператора на элементе, а производный это оператор. И вот теперь тогда
[33:59.460 --> 34:04.540]  никаких проблем уже моральных, даже в одномерном случае, при рассмотрении дифференциалов и прочего,
[34:04.540 --> 34:13.660]  вас не будет, я надеюсь. Это производное по Фреше, это такое определение. Кстати,
[34:13.660 --> 34:23.500]  Фреше у нас в нашем курсе где встречался? Раз. Я еще в сентябре вам говорил одну вещь,
[34:23.500 --> 34:29.580]  но вы могли забыть, потому что это давно было. Практика богатства ваше воспоминание, они имеют
[34:29.580 --> 34:36.700]  небольшой горизонт. Фреше, Марис Фреше, французский математик, придумал понятие метрического
[34:36.700 --> 34:42.700]  пространства. Он один из создателей топологии. У него была замечательная длинная математическая
[34:42.700 --> 34:53.660]  жизнь, 97 лет, чего он только не делал. Вот это тот самый Марис Фреше. Хорошо. Чем замечательное
[34:53.660 --> 34:58.220]  это определение? В случае вот этого, конечно, мерного варианта, но полностью совпадает с тем,
[34:58.220 --> 35:04.700]  которое было. Понимаете, это одна из постоянных забот в математике, когда расширяется какое-то
[35:04.700 --> 35:11.020]  понятие, какая-то среда термологическая. Она в хорошем варианте, разумеется, должна
[35:11.020 --> 35:18.500]  корректно сопрягаться с тем, что уже было, правда? Вот в данном случае мы все это получили, мы об этом
[35:18.500 --> 35:23.980]  позаботились. Я сейчас на доске напишу вам несколько простых упражнений. Сотру вот это,
[35:23.980 --> 35:42.100]  здесь мне уже вывеска это не нужна. Серия утверждений, а ниже упражнения. Без всякой
[35:42.100 --> 35:53.100]  нумерации. Очень важно. Первое. Если f от x, есть некая константа, но в данном случае константа
[35:53.220 --> 36:04.780]  не число только, а элемент еда, разумеется, это вы понимаете, то тогда производная, ну из d,
[36:04.780 --> 36:14.540]  где-то в d он такой постоянный. Чему будет равна производная? Конечно, нулевая ператомоцифер.
[36:14.540 --> 36:23.300]  Довольно естественно, я бы сказал, правильно. Второй вариант. f от x это линейно-ограничный
[36:23.300 --> 36:36.060]  оператор, действующий из y1 в y2. Что будет собой представлять его производная в любой точке x0 из y1?
[36:36.060 --> 36:47.780]  Чуть более хитрый вопрос. Он сам, конечно, что тоже замечательно. Просто представьте себе,
[36:47.780 --> 36:52.860]  что мы находимся в мире функций z1, y1. Линейный оператор, это линейная функция y,
[36:52.860 --> 36:58.100]  оказывается kx. Опять же, здесь числа и всё запутывается, но вот этот сам оператор,
[36:58.100 --> 37:03.180]  это вот оператор умножения на константу k. И производный такой оператор, это есть он сам,
[37:03.180 --> 37:08.300]  такое же умножение на константу k. Но там не очень понятно, а здесь абсолютно понятно и
[37:08.300 --> 37:17.100]  легко доказывается. Итак, это есть он сам. Замечательно. Пункт 3. Элементарные совершенно из
[37:17.100 --> 37:24.940]  жизни дифференцирования. Если есть дифференцируемое отображение, и мы берем их комбинацию в какой-то
[37:24.940 --> 37:34.420]  точке, то это будет альфа1 ф1 штрих плюс альфа2 ф2 штриха. Но чем вот хочется еще дополнить вот эту
[37:34.420 --> 37:46.060]  подборку таких элементарных? Какие были у вас дифференцирования, сложные функции? Вот представьте
[37:46.060 --> 37:53.740]  себе, что у меня есть суперпозиция дифференцируемых отображений. Не буду даже писать. Как вы думаете,
[37:53.740 --> 38:06.700]  что есть производный этой функции? Мир есть х, мир у, мир z. Вот здесь f, здесь g. Будет равна
[38:06.700 --> 38:15.820]  производная вот этого отображения, действующего отсюда-сюда в точке х0. Ответ замечательный. Если
[38:15.820 --> 38:24.700]  вы помните ту формулу, то вы напишите эту. Если вот обозначить эту суперпозицию через h,
[38:24.700 --> 38:37.620]  g и f, то h штрих в точке х0 есть суперпозиция f штрих в точке х0, это некий линейный ограниченный
[38:37.620 --> 38:51.900]  оператор. И g штрих в точке y0, где понятным образом через y0 я обозначил f от x0. Вот эту теорему нам
[38:51.900 --> 39:00.100]  придется доказать, потому что некая хитрость есть, кухня интересная. Короче говоря, вот это пока
[39:00.100 --> 39:08.380]  можете не трогать, а это докажите. Но вот уже сейчас дальше я буду пользоваться этим утверждением,
[39:08.380 --> 39:14.580]  потому что мне хочется вместе с вами увидеть, как это все реально работает на каком-нибудь
[39:14.580 --> 39:19.140]  простом примере. В следующий раз мы продолжим разговор. Вот давайте проведем вопрос общественного
[39:19.140 --> 39:29.620]  мнения с салоги. С вашей точки зрения, какая терема является главной в первом семестре первого
[39:29.620 --> 39:38.380]  курса в дифференциальном исчислении? Поехали. Самая главная терема, самая важная по применимости,
[39:38.380 --> 39:46.220]  значения и так далее. Так, вы задумались, хорошо. Первый семестр, первый курс, дифференциальное
[39:46.220 --> 39:57.540]  исчисление? Не знаю, так. Не знаю, раз, не знаю, два. Что-что? Нет, нельзя.
[40:05.060 --> 40:14.220]  Хорошо, сложно. Так. Ничего не ставим, нет. Вот я сейчас произнесу слово и скажете. Ну, конечно.
[40:14.220 --> 40:23.900]  Терема лагранжа. Терема средняя. На самом деле, да, это самый универсальный инструмент в том
[40:23.900 --> 40:31.220]  элементарном анализе функции одной переменной, если они дифференцируемы, конечно. Развитие
[40:31.220 --> 40:36.860]  теремы фирма, необходимые условия экстремума, шапочки такой-ли такой, равенство нулепроизводное,
[40:36.860 --> 40:43.660]  а здесь уже можно провести вот эту касательную. Согласились? Терема лагранжа, терема средняя.
[40:43.660 --> 40:50.860]  Вот терема средняя, когда начинаешь переносить в многомерие, возникают всякие проблемы. Но даже
[40:50.860 --> 40:56.860]  писать не хочу. В комплексной плоскости вы изучали дифференцируемые функции? Только что
[40:56.860 --> 41:01.900]  сдали курс. Там вот в таком банальном варианте, что если функция дифференцируема на какой-то
[41:01.900 --> 41:07.420]  области, то, скажем, для любых двух функций, ну, вы область выпуклая, чтобы отрезок может быть.
[41:07.420 --> 41:15.780]  Что разность значений функ. в точках z1 и z2, есть значение производной в какой-то точке там, ну,
[41:15.780 --> 41:23.740]  скажем, внутри этого отрезочка, соединяющего z1 и z2, умножено z1 – z2. Вот верно в таком виде теоремы?
[41:23.740 --> 41:34.020]  Верно не равенство. Да. Вот смысл вообще такой, при переходе к многомерию, терема лагранжа,
[41:34.020 --> 41:40.860]  перестает обычно называться теремой лагранжа, обычно называется теремой средним, и формулируется в виде
[41:40.860 --> 41:48.500]  неравенства. Ну, вот в мире комплексного переменного, скажем, я беру функции e в степени z и беру две
[41:48.500 --> 41:54.900]  точки 0 и 2π. Разность значений – это 0, потому что тут один и тут один. Но это нельзя представить,
[41:54.900 --> 42:01.140]  этот 0 в виде f' в какой-то точке e в степени z, e в степень x, умножить на эту разность 2π.
[42:01.140 --> 42:06.260]  А в виде неравенства, как вот нам подсказывают, это всегда будет. Вот сейчас мы как раз такую терему
[42:06.260 --> 42:13.660]  с фрурлином докажем, и она вот на самом деле еще будет очень хорошо связываться с темой комплексного
[42:13.660 --> 42:20.540]  анализа. Когда в параграфе 7 я вам так как-то небрежно сказал, это символ небрежности, да?
[42:20.540 --> 42:26.180]  Небрежность, не знаю, сейчас так почему-то вот небрежность превратилась в такое, по-моему,
[42:26.180 --> 42:33.780]  химини. Это небрежность состоит в том, что я сказал. Вот курс комплексного переменного
[42:33.780 --> 42:40.660]  для функций, принимающих значения в мире операторов, можно построить по аналогии с тем,
[42:40.660 --> 42:47.940]  но просто вот с места не сходя. На самом деле там, конечно, в каких-то случаях возникнут какие-то
[42:47.940 --> 42:54.100]  проблемы. Просто-напросто вообще аккуратно все это заново проделывать – это большая работа.
[42:54.100 --> 43:00.100]  А вот есть один прием, который состоит в том, чтобы все это по возможности просто переселять
[43:00.100 --> 43:06.260]  сразу в мир обычных функций комплексного аргумента и комплексно-значных с помощью специальных
[43:06.260 --> 43:12.540]  функционалов. И вот сейчас мы этой идеей воспользуемся. Каких-то специальных функционалов,
[43:12.540 --> 43:17.820]  которые бы учитывали особенности задачи. Какое у нас есть утверждение замечательное, которое
[43:17.820 --> 43:22.620]  позволяет не просто говорить о том, что функционалов в сопряженном пространстве всегда много, но и
[43:22.620 --> 43:29.580]  можно находить функционалов по всяке специальные нужды. Теорема Ханнабанах и ее четыре замечательные
[43:29.580 --> 43:35.700]  следствия. Вот сейчас мы так в точности вот это все как раз и увидим. И на самом деле, если быть
[43:35.700 --> 43:42.100]  честным вот в том разделе про функции оператора назначения комплексного аргумента, тоже в
[43:42.100 --> 43:49.260]  нескольких случаях выгодно и полезно эту теорему применять, чтобы сразу переброситься на достаточно
[43:49.260 --> 43:55.260]  серьезные вещи, которые в этом комплексном анализе сидят. Даже технически. И не мучатся их
[43:55.260 --> 44:05.540]  повторения. Сейчас вы видите. Значит так, надо все стереть. Что у нас со временем? Ровно полпара.
[44:05.540 --> 44:15.660]  Но как всегда, перерыв никому из нас не нужен. Я правильно говорю? Но вот прежде чем я перейду
[44:15.660 --> 44:24.740]  к этому, еще одна деталь только. Я сейчас думаю, где все стереть? Вот здесь стереть. Можно. Я вот,
[44:24.740 --> 44:31.220]  когда вместе с вами погрузился в воспоминания вот эти, я не коснулся одной темы. Кроме частных
[44:31.220 --> 44:37.460]  производных, были еще производные по направлению, помните? Вот интересно, какова здесь судьба? Есть
[44:37.460 --> 44:41.860]  еще один предмет, которого, к сожалению, у вас, как и выяснится, тоже до сих пор не было порядок причин.
[44:41.860 --> 44:47.700]  Теоретическая механика. Но, возможно, вы листаете какие-то книжки по механике. Например,
[44:47.700 --> 44:53.900]  замечательный курс, который одни когда-то в этих стенах. Книжка Гандмахера, лекции по аналитической
[44:53.900 --> 45:06.380]  механике. Не листали? Ладно. Там есть такой, понятно, первый вариант цепелогранжу и так далее. В общем,
[45:06.380 --> 45:11.180]  сейчас вот увидим. Давайте, прежде чем вот к Тереме пойдем, об этом тоже поговорим. Я вот
[45:11.180 --> 45:24.540]  это определение оставлю. А здесь напишу еще одно. О, прекрасно. Это тоже оставлю, потому что будет
[45:24.540 --> 45:34.780]  оттенять обозначение, которое сейчас тоже появится. Определение два. Рядом с этим.
[45:34.780 --> 45:46.740]  Ситуация та же самая. E1, E2, вещественная баннахова, область открытая какая-то D и отображение F,
[45:46.740 --> 46:03.340]  действующие из D в E2. F рассматриваем в точке х0 из этой самой области D. Можно рассмотреть вот такое
[46:03.340 --> 46:11.940]  выражение. Давайте сразу для его обозначения напишу. D, F, х0, h, так же, как и там, только там
[46:11.940 --> 46:23.300]  была маленькая буква, да, теперь большая. Это есть предел при T, стремящемся к нулю, D,
[46:23.300 --> 46:37.300]  F от х0, плюс TH при, нет, ну просто не предел даже, просто, я все же так, я пишу без предела,
[46:37.300 --> 46:46.380]  просто при Т равно нулю. Вот представьте себе, что обстоятельства позволяют продиференцировать
[46:46.380 --> 46:55.580]  по вот вещественному аргументу T вот такое образование. Что под этим будет пониматься?
[46:55.580 --> 47:09.660]  Ну F большое, это там из образцов мира 2, то есть F от х0, плюс TH, минус F от х0, делимся на T,
[47:09.660 --> 47:20.140]  смотрим предел, чтобы производная появилась при T, стремящемся к нулю, правильно? Так или не так?
[47:20.140 --> 47:34.420]  А тогда какое смысл, вот там я написал, T равняется нулю? Ну, на самом деле, надо просто
[47:34.420 --> 47:39.460]  понимать, что вот если T стремится к нулю, это вообще-то, говоря, производная какая-то,
[47:39.460 --> 47:47.060]  ну, в точке х0, да? Ну, связанная вот с этим фиксированным направлением. Вот спрашивается,
[47:47.060 --> 47:52.020]  здесь аж я зафиксировал, да, наверно, зафиксировал. Вот зафиксировал направление аж какой-то вектор,
[47:52.020 --> 48:02.100]  смотрю, такой предел будем, буду его называть вот таким, производная. И вот беру эту производную
[48:02.100 --> 48:10.020]  при T равную нулю. Это логично? Производная по T вообще. Производная по T, может,
[48:10.020 --> 48:15.180]  не обязательно, когда T куда-то стремляется к нулю, что-то такое-то, я не понимаю, может,
[48:15.180 --> 48:24.180]  еще куда-то. Короче говоря, беру пока производную. Получается какой-то элемент тоже из E2,
[48:24.180 --> 48:33.300]  как и в том дифференциале, верно? Ну, вот в том случае, когда существует такой оператор,
[48:33.300 --> 48:41.980]  который обозначается f' слабое в точке х0, что вот это все можно представить f' слабое х0 аж,
[48:41.980 --> 48:50.220]  вот если такой оператор существует, что вот этот блок, вот этот дифференциал можно в такой
[48:50.220 --> 48:57.460]  виде представить. Я говорю, что у меня отображение в большое дифференцируемое по Гато. Гато это
[48:57.460 --> 49:06.100]  очень интересный французский математик. Сколько у меня он прожил? 1889, это кажется правильно,
[49:06.100 --> 49:13.700]  потому что погиб в октябре 14 года, ну, в первой мировой войне. Он был очень талантливый,
[49:13.700 --> 49:19.180]  способный. Сначала учился во Франции, потом его послали Квиц Вальтера. Помните, я вам упоминал
[49:19.180 --> 49:24.260]  итальянского математика, одного из родоначальников функционального анализа, и послали его как раз учиться
[49:24.260 --> 49:30.100]  уже вот этому. Там я какое-то письмо вчера перетитал, написанное то ли Адамаром кому-то,
[49:30.100 --> 49:34.540]  то ли Кентом Адамаром, где фигурировал вот это выражение функционального исчисления,
[49:34.540 --> 49:40.780]  Calculus. Вот его послали учиться, он там поучился, написал некую работу замечательную, вернулся
[49:40.780 --> 49:48.140]  в апреле 14-го года, прям, короче говоря, под самую войну попал и погиб вот уже осенью 14-го года.
[49:48.140 --> 49:56.140]  И, ну, остался вот в истории, как автор этого важного понятия. Готов. Не буду писать в французский,
[49:56.140 --> 50:12.300]  там совершенно всё непонятно. Я даже вот не помню, где здесь буква ещё присутствует. Да,
[50:12.380 --> 50:18.900]  наверное, вот так. Да, для человека, не знаю, что в французском, вспоминать должна быть буква или нет,
[50:18.900 --> 50:32.340]  это проблема. Короче говоря, лучше его просто готовить. Хорошо. Так вот, как вы думаете,
[50:32.340 --> 50:37.380]  какое взаимоотношение производной готов и производной по фреше? Ну, очень простые.
[50:37.380 --> 50:44.020]  Производной фрешей надо называть сильной производной. Вот здесь слабый или производной готов,
[50:44.020 --> 50:53.460]  а там производной фрешей или сильной. Есть простое здоровое упражнение, что если f дифференцируемо по
[50:53.460 --> 51:16.700]  фреше в точке x0, то f в точке x0 дифференцируемо по готову, и f' слабое и f' сильное совпадают.
[51:16.700 --> 51:26.780]  И на самом деле это открывает дорогу в некоторых ситуациях к тому, что вы ищете производную по
[51:26.780 --> 51:32.260]  фреше сильную, но её надо как-то угадать, подобрать. А вот здесь производная по параметру t,
[51:32.260 --> 51:37.460]  какая-то техническая в интеграле, что-то там под нахинтеграл залез, продеференцировал. А потом
[51:37.460 --> 51:42.100]  надо только доказать, что это найденный слабый производной является ещё сильной. Автоматически
[51:42.100 --> 51:47.620]  этого не будет, но идеология простая и понятна. Здесь ещё я в одном месте писал, дифф потерпел.
[51:47.620 --> 51:55.660]  Анастасия, вы у нас человек самый грамотный. Как надо сокращать слово дифференцированное,
[51:55.660 --> 52:04.660]  дифференциал с одним f или с двумя? Да вот и мне тоже кажется. Нет, просто понимаете,
[52:04.660 --> 52:12.260]  вот есть два правила в русском языке. Первый говорит, что надо перед гласной какую-то точку
[52:12.260 --> 52:17.460]  всё достать. Но есть и второй правил, что если согласно повторяется, то надо писать дифф.
[52:17.460 --> 52:25.740]  Но я вот не могу писать дифф просто так. Я пишу дифф вот так. Но я тут себе вчера специально номер
[52:25.740 --> 52:30.740]  ГОСТа выписал, чтобы сказать, что я прав, когда надо писать с одним, но писать тут с двумя.
[52:30.740 --> 52:36.820]  Хорошо? Так вот, вот пример, вообще показывающий, что в обратную сторону всё конечно не действует,
[52:36.820 --> 52:43.140]  это классический ваш пример. Если на плоскости r2, ну то есть f у меня действует из r2 в r1,
[52:43.140 --> 52:49.940]  я рассмотрю такую функцию. Вот парабола y равнеет x квадрат на кардинатоплоскость x вверх.
[52:49.940 --> 52:56.060]  И я беру отображение в большое, которое в точках вот здесь-сюда это единичка, а здесь-сюда нули,
[52:56.060 --> 53:04.900]  нули, нули. И вот я беру точку x нулевой такую, нуль-нуль. Так вот, у меня производная по любому
[53:04.900 --> 53:11.220]  направлению существует равно нулю. Я рано или поздно приодыгаюсь к точке нуль-нуль. Параболу
[53:11.220 --> 53:17.060]  пересеку и уйду уже в нулевую область. У меня все вот эти производные по всем направлениям одинаковые
[53:17.060 --> 53:21.820]  есть, нулевые. Но понятное дело, что они о какой дифференцированности такой функции,
[53:21.820 --> 53:27.900]  которая даже непрерывной не является, речь не идет. Вот такой пример из нашего славного
[53:27.900 --> 53:33.180]  первокурсного прошлого, но показывающий, что здесь такие же, разумеется, все эффекты
[53:33.180 --> 53:39.220]  сохраняются. А вот это простое упражнение, что если по фрише я дифференцирую, и так далее. Мы о ней еще
[53:39.220 --> 53:45.540]  поговорим в следующий раз об этой производной. В частности, вот про дифференцирование сложной
[53:45.540 --> 53:53.020]  функции, там есть всякие хитрости. Но пока что я сказал, что вот еще полезное упражнение,
[53:53.020 --> 54:03.420]  пожалуй, такое вычислительное упражнение. Значит, у меня есть E1, это вещественное гильберто-пространство,
[54:03.420 --> 54:15.620]  у меня есть E2, это просто R, и есть функционал F от X, это норма X. Вопрос, где дифференцируем по
[54:15.620 --> 54:31.500]  фрише и по ГТО. Понятно? Как будете решать, не знаю. Это тоже хороший вопрос. Но это, грубо говоря,
[54:31.900 --> 54:38.220]  научиться дифференцировать функцию модул X в одномерном случае, а теперь так хуже. Это даже
[54:38.220 --> 54:47.060]  не конус такой многомерный, а вообще неизвестно, что. Интуиция что говорит? Где она дифференцируема
[54:47.060 --> 55:00.060]  по фрише? Вот эта функция, это отображение большое. Где по фрише дифференцируем? Ну да, функцию модул
[55:00.060 --> 55:05.020]  X. Видели? Только в нуля она дифференцируема в всех других, она либо X, либо минус X. Ну и что,
[55:05.020 --> 55:11.940]  смеются что ли? Кроме нуля, все дифференцируем. И найдем что-нибудь там такое. А по ГТО, вот в нуля
[55:11.940 --> 55:26.580]  она дифференцируема или нет? Что вы мне скажете? Еще раз. Кажется, что все равно. Вот тут еще есть одна
[55:26.580 --> 55:32.260]  вещь, которую я пока с вами не обсуждал. Вот этот дифференциал ГТО, он как бы всегда, грубо говоря,
[55:32.260 --> 55:39.020]  есть. В хорошем смысле. А вот представить его в таком виде тоже можно далеко не всегда. И вот тут надо
[55:39.020 --> 55:46.340]  разделить на две части. Вот дифференциал ГТО в нуле есть или нет? Производное ГТО есть или нет?
[55:46.340 --> 55:53.780]  Вот в следующий раз сравним ваши ответы и результаты. А я сейчас все-таки в конце концов перейду наконец
[55:53.780 --> 56:01.940]  к теореме. Но еще одну скажу. Вот понимаете, трудности вот в чем состоят. Вот такой дифференциал,
[56:01.940 --> 56:08.980]  как выражение вот так нашел, он не обязательно линейный ПАШ даже. Вот он может не быть линейный
[56:08.980 --> 56:15.660]  ПАШ. И это порождает невероятную кучу проблем. Поэтому когда я говорю, что есть такой оператор,
[56:15.660 --> 56:24.180]  что такой дифференциал вот записывается в таком виде, это уже очень серьезная линейнеризация устройства
[56:24.180 --> 56:33.060]  в смысле ПАШ. И это, пожалуй, самое главное, что тут надо сказать. Все. Теперь теорема. Так, опять же,
[56:33.060 --> 56:40.260]  придется все стереть. Теорема Лагранжа. Я вот просто хотел, чтобы мы какую-то такую теорему
[56:40.260 --> 56:47.900]  узнаваемую, эмоционально окрашенную. Ну раз я вас уломал, мы признали теорему Лагранжа одним из
[56:47.900 --> 56:54.100]  полезных изобретений человеческого разума. Пока стираю Лагранж, когда жил у нас и где.
[56:54.100 --> 57:06.420]  Не слышу ответа. 19 век. Ой, хорошо. Вторая попытка.
[57:10.260 --> 57:24.980]  Хорошо. Где жил Лагранж? Во Франции 19 века. Ну, на самом деле, все-таки, это математика 18 века,
[57:24.980 --> 57:35.340]  он там на стыках жил. Ну, если вы это знаете, я соглашусь, конечно. Но, понимаете, важно не когда
[57:35.340 --> 57:52.660]  жил, а когда основные работы все-таки были написаны. В этой науке это... Вот, скажем,
[57:52.660 --> 58:03.380]  вы, Шекспира, считаете писателем 16 века или 17 века? Только 17 века. Ну, понимаете, с одной
[58:03.380 --> 58:09.420]  стороны, действительно, главные вот эти его поздние пьесы, это король Лиры, это Макбет, это Гамлет,
[58:09.420 --> 58:15.260]  это все начало 17 века. Но с другой стороны, он уже вскоре умер после этого. Поэтому это хитрый дел.
[58:15.260 --> 58:21.340]  Сервантс тоже самое. Они умерли в один год в 16 году, но Сервантс написал, скажем, Дон Кихотта в
[58:21.340 --> 58:27.500]  пятом году первом, в пятнадцатом, втором. Ну, в общем, это хитрый дел. Вот можно действительно по основным
[58:27.500 --> 58:34.380]  результатам брать. Вот как здесь можно по дате смерти. Газу оставляю пока, пусть висит теорема.
[58:34.380 --> 58:43.340]  Теорема, раз у нас тринадцатый параграмм, значит, это первая теорема. Теорема средняя.
[58:43.340 --> 58:52.540]  Вот в виде неравенства, как меня Константин говорил, мы сейчас придумаем теорему, ну и
[58:52.540 --> 59:04.620]  докажем заодно. Итак, пусть E1 и E2, это вещественное банаховое пространство. Мне, может быть,
[59:04.620 --> 59:10.740]  это банаховое пространство где-то и не нужно, но я просто хочу исключить всякие неприятности. Хотя
[59:10.740 --> 59:22.740]  не будет этого на самом деле. Да, вещественных банаховых пространств. D в E1. Это выпуклая область.
[59:22.740 --> 59:29.700]  Ну, что такое выпуклая? Это вы понимаете. Это когда вместо двумя точками отрезок,
[59:29.700 --> 59:37.220]  отрезок соединяющей точки x0 и x1 это точки вида, в естественном случае, x0 плюс t на x1 минус x0,
[59:37.220 --> 59:45.820]  где t пробегает отрезок в 0, так? Прекрасно. Значит, это выпуклая область. Есть отображение f,
[59:45.820 --> 01:00:03.380]  действующие из D в E2. И оно отображение f дифференцируемое в области D. Теперь вы меня
[01:00:03.380 --> 01:00:14.700]  должны придумать. Что, что, что? По фреше. Вот когда говорят просто дифференцируемо без уточнения,
[01:00:14.700 --> 01:00:24.580]  это всегда означает, ну, хорошо. В следующий раз мы сами посмотрим. Вернали от этой ремы,
[01:00:24.580 --> 01:00:30.100]  если брать дифференцируемо с поготой. Я вот не хочу сразу грузить вас какими-то детальками,
[01:00:30.500 --> 01:00:36.460]  вот сначала все хорошо. Дифференцируемо по фреше и так далее. Мне важно, чтобы вы сейчас
[01:00:36.460 --> 01:00:48.260]  придумали теорему. Тогда что? Ну, вот, в одном и том случае, там как теорема лограмма поможет?
[01:00:48.260 --> 01:00:57.900]  Пусть функция f большое, дифференцируемо на интервале a, b и непрерывно на отрезке b. Тогда f от b
[01:00:57.900 --> 01:01:05.020]  минус f от a есть значение производной f штрих этого отображения в какой-то точке кси на интервале b,
[01:01:05.020 --> 01:01:11.700]  умноженной на b минус a. Я сейчас буду не b и a писать, а буду использовать точки x0 и x1.
[01:01:11.700 --> 01:01:16.700]  Мне так удобнее вот в привязке к будущему t, который по 0 и 1 будет бегать. И так,
[01:01:16.700 --> 01:01:29.900]  подождите. Итак, для любых точек x0 и x1 из d справедливо следующее неранство. Мы договорились,
[01:01:29.900 --> 01:01:35.180]  что будем на языке неранства оформлять, потому что вот я специально вас предостерег. Справедливо
[01:01:35.180 --> 01:01:45.540]  такое неранство f от x1 минус f от x0. Значит, f это у меня отображение из e1 и e2. Значит,
[01:01:45.540 --> 01:01:52.740]  тут немодуль надо писать, а норма не превосходит. Если вот в Тереми-Лагренда взять Супрем с
[01:01:52.740 --> 01:02:00.340]  множителей, то мы придем, естественно, к такому. Супрем, модуль f штрих, только уже не модуль теперь,
[01:02:00.340 --> 01:02:09.500]  а норма, y бегает по интервалу x0 и x1, что-то такое мы поняли, и умножит на, опять же таки,
[01:02:09.500 --> 01:02:22.860]  норму равность x0 и x1. Придумали? Продоподобно. Вот теперь тот самый прием, о котором я вам
[01:02:22.860 --> 01:02:32.020]  говорил. Значит, смотрите, что у нас пока что есть. Есть мир e1, есть отображение f. Тут оно определено
[01:02:32.020 --> 01:02:40.180]  какой-то области, да, неважно. Есть мир e2, куда мы забросились. Я говорю, что я мечтаю свести эту
[01:02:40.180 --> 01:02:49.180]  терему к обычной числовой тереме Лагранжа. А на та терема у меня действует вот из r в r,
[01:02:49.180 --> 01:02:58.660]  причем здесь вообще надо какой-то интервальчик взять. Вот я сейчас этот мир здесь и возьму. Это
[01:02:58.740 --> 01:03:09.340]  отрезок 0,1, кусок r, и здесь еще один r, в который мы будем забрасываться отсюда с помощью функционала
[01:03:09.340 --> 01:03:17.300]  из e2 со звездой. Вот я в прошлом году, когда это рассказывал, придумал такое минимотехническое
[01:03:17.300 --> 01:03:22.660]  пояснение. Вы знаете, что такое седвич? Словарное определение. Практически это вы все понимаете,
[01:03:22.660 --> 01:03:29.620]  что такое. Взял, положил, шлёпнул, съел. Вот это седвич есть. А словарное определение?
[01:03:29.620 --> 01:03:47.660]  Так, очень интересно. Понимаете, тут на самом деле надо понять. Вот в определении седвича у вас
[01:03:47.660 --> 01:03:54.620]  главное будет начинка там какая-то, типа котлета, или вот два куска хлеба. Молодец,
[01:03:54.620 --> 01:04:01.260]  правильно, серьезно. Итак, словарное определение такое. Если брать, это восходит к английским
[01:04:01.260 --> 01:04:09.700]  словарям всяким. Два куска хлеба, соединенных начинкой. Вот у нас здесь сначала появилась начинка,
[01:04:09.700 --> 01:04:18.580]  вот она. И мы сейчас придумаем два ломтя хлеба, два куска. И в результате получится седвич,
[01:04:18.580 --> 01:04:25.340]  вот такая конструкция, в которой уже будет некоторое отображение x, a, t, t живет вот на этом
[01:04:25.340 --> 01:04:31.140]  промежутке. Потом с помощью отображения мы переселяемся в e2, и наконец с помощью функционала,
[01:04:31.140 --> 01:04:36.700]  пока что произвольно везет нас из e2, а потом мы выберем тот, который нам понадобится, захочется,
[01:04:36.780 --> 01:04:44.020]  мы переселяемся туда. В результате отображение phi, a, t, который представляет собой суперпозицию
[01:04:44.020 --> 01:04:53.980]  отображения x, a, t, потом f, и потом f, получаем вот такое отображение, действующее из мира чисел
[01:04:53.980 --> 01:05:03.540]  в мир чисел. Так? Теперь давайте смотреть. x, a, t у меня, это будет просто-напросто x0,
[01:05:03.540 --> 01:05:12.260]  f плюс t, x1 минус x0. Это дифференцируемое отображение? Да, оно линейное по t,
[01:05:12.260 --> 01:05:21.060]  все тут вот. f по условию дифференцируемо. f, помните у нас набор вот этих все был простеньких
[01:05:21.060 --> 01:05:34.820]  утверждений. Вот получается, что phi будучи суперпозицией f и вот этого x будет дифференцируемо
[01:05:34.820 --> 01:05:40.980]  по тереме о дифференцируемости сложной функции, сложного отображения, которую мы пока не доказали,
[01:05:40.980 --> 01:05:49.300]  мы докажем потом. Значит у меня итоговое отображение будет вот такое. Давайте посмотрим,
[01:05:49.300 --> 01:05:54.820]  что собой представляет в соответствии с той теремой phi штрих в какой-то точке производной.
[01:05:54.820 --> 01:06:04.020]  Ну производная вот этого отображения по t, даст мне просто вот эту дельту x минус x0,
[01:06:04.020 --> 01:06:17.820]  я так ее здесь в хвосте и напишу, дельта x, потом на нее навалится вот это f штрих,
[01:06:17.820 --> 01:06:25.020]  который надо будет считать производную в точке, в которую вот перешла какая-то точка t, вот она
[01:06:25.020 --> 01:06:35.860]  здесь. Значит так и напишу f штрих в точке x t и наконец здесь совсем просто, это сам функционал f,
[01:06:35.860 --> 01:06:49.060]  потому что он линейный и при этом функционал. Верно все? Теперь давайте посмотрим. Так или не так?
[01:06:49.060 --> 01:07:05.300]  Хорошо, значит phi штрих от t у меня, это вот такая суперпозиция f, ну можно вот дать еще написать,
[01:07:05.300 --> 01:07:14.700]  раз что дельта x стоит, вот это я напишу в виде x0 плюс t на дельта x, ну чтобы как-то унифицировать все
[01:07:14.700 --> 01:07:25.940]  обозначения там используем, ну и потом стоит вот этот x. Вот что это означает? Мы берем произвольный
[01:07:25.940 --> 01:07:35.700]  аргумент t, на него наваливаемся множество x1-x0, потом на этот элемент полученный действуем
[01:07:35.700 --> 01:07:41.660]  оператором производной, а потом действуем еще вот функционалом. В результате получаем тот самый число.
[01:07:41.660 --> 01:07:57.980]  Вот теперь смотрите, у меня есть функция phi, если я напишу разность phi минус phi от нуля,
[01:07:57.980 --> 01:08:06.900]  это будет просто-напросто здесь значение вот таких всех штуковин, каких? Что такое x от нуля?
[01:08:06.900 --> 01:08:18.420]  Это x0, так? Значит это будет f от x0, это какой-то элемент из E2, и на него мы действуем функционалом f.
[01:08:18.420 --> 01:08:26.660]  Это вот со знаком минус вот этот второй кусочек, а первый кусочек как будет выглядеть? Ну аналогичным
[01:08:26.660 --> 01:08:39.300]  образом. f маленькая от f, вот x1, все вместе вот так. Я просто написал сначала более простую
[01:08:39.300 --> 01:08:59.380]  куску. f у меня какой функционал? Линейный, непрерывный. Так? Так. Значит что говорит теория Малагранджа,
[01:08:59.380 --> 01:09:06.660]  примененной вот к этой функции phi от 0? phi 1 минус phi от нуля есть phi штрих в какой-то
[01:09:06.660 --> 01:09:16.620]  точке x промежуточной, умноженную на длину вот этого самого промежутка. Что такое phi штрих в какой-то
[01:09:16.620 --> 01:09:28.500]  точке x? Ну вот, вот, пожалуйста. Что получается тогда? Вот это равно вот этому, это равно тому,
[01:09:28.500 --> 01:09:36.420]  но это равно и вот этому. И я сейчас припишу в следующем виде, который мне нужен. Я напишу,
[01:09:36.420 --> 01:09:45.940]  стало быть. Так, это я не стираю, потому что это... Сколько у меня? А? Ну много. Столько и не нужно.
[01:09:45.940 --> 01:10:00.340]  Теперь стеряю ГТО, который терпеливо сушил все наши выкрытки. Значит еще раз. Получаем,
[01:10:00.340 --> 01:10:08.900]  что... Войдем теперь в модули все вот эти. Значит f штрих в точке кси, которое есть,
[01:10:08.900 --> 01:10:20.540]  и вот тут надо как-то это все записать. Это есть f штрих. Вот лучше пока пожалуй... Во-первых,
[01:10:20.540 --> 01:10:26.820]  phi. phi штрих в точке кси, это есть. Вот я просто хочу сейчас переписать вот то, что тут у меня было
[01:10:26.820 --> 01:10:33.660]  написано, но только используя вот этого самого кси вместо t, правильно? Потому что я сейчас беру
[01:10:33.660 --> 01:10:49.540]  какой-то кси из интервальчика 0,1. Так, значит, это есть f штрих в точке x нулевой плюс кси дельта x.
[01:10:49.540 --> 01:11:01.020]  Вот так. Так, так. Здесь дельта x. Правильно? Вот этот оператор производный навалился на этот
[01:11:01.020 --> 01:11:06.580]  аргумент. Получили нечто из E2 под действием функционала. И это равно в то же время,
[01:11:06.580 --> 01:11:11.700]  вот как тут я писал, phi от единицы минус phi от 0. Я просто продублировал все,
[01:11:11.700 --> 01:11:18.820]  что было в правой части доски. Ну все, вот торжественный момент. Теперь перехожу к неравенствам.
[01:11:18.820 --> 01:11:40.020]  Вот пишу модуль. Модуль phi 1 минус phi от 0 не превосходит супремого модуля phi штрих кси на
[01:11:40.020 --> 01:11:47.620]  вот эту самую разность 1. Это с одной стороны. Чему вот это равно? phi 1 минус phi от 0. Вон там
[01:11:47.620 --> 01:11:59.620]  написали сами. Это модуль f от x1 минус f от x0. И это все не превосходит того, что вот здесь,
[01:11:59.620 --> 01:12:07.780]  что, разумеется, превратится у меня сейчас вот во что. Смотрю сюда. Не превосходит нормы
[01:12:07.780 --> 01:12:17.060]  функционала f. Ну как всегда, когда сложное отображение. Потом норма вот этого f штрих в точке x0
[01:12:17.060 --> 01:12:33.100]  плюс кси дельта х. И еще умножается это все на норму аргумента дельта х. Так? Так. И вот торжественный
[01:12:33.100 --> 01:12:45.740]  момент. Это все верно. Пока что написано для любого f из Е2 со звездой. Так ведь? А я сейчас выберу
[01:12:45.740 --> 01:12:52.260]  с помощью следствия 2 теремы Ханнабанаха специальный элемент f, штуковое следствие 2.
[01:12:52.260 --> 01:13:08.980]  Листаем записи они же. Итак, следствие 2 теремых Ханнабанах. Я вот здесь сотру подвал под вот этим
[01:13:08.980 --> 01:13:32.180]  нерандеством. Я сэндвич тоже сотру, хотя и жалко. Правда? Сэндвич хорош. Пишу. Последствие 2 0 терема Ханнабанаха
[01:13:32.180 --> 01:13:43.260]  для элемента. Какого элемента? А вот этого, в скобках стоящего, вот этого элемента из Е2, найдется функционал из
