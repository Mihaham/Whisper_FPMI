[00:00.000 --> 00:07.000]  Смотрите, сегодня мы говорим про ускоренные методы.
[00:07.000 --> 00:09.000]  Для того, чтобы понять, что это за ускоренные методы,
[00:09.000 --> 00:12.000]  нас сейчас понять, относительно чего мы их ускоряем.
[00:12.000 --> 00:19.000]  И для этого я все-таки хочу привести аккуратное доказательство
[00:19.000 --> 00:23.000]  необходимости гарнитного метода для просто выпуклой задачи,
[00:23.000 --> 00:28.000]  чтобы вы примерно понимали, почему в случае, когда мы выпуклые с ней,
[00:28.000 --> 00:31.000]  используем у нас была просто сходимость на стороны точки.
[00:31.000 --> 00:33.000]  А когда мы выпуклые сначала использовали,
[00:33.000 --> 00:39.000]  то у нас внезапно появилась сходимость к решению с определенной скоростью.
[00:39.000 --> 00:41.000]  Я вижу три включенных микрофона.
[00:41.000 --> 00:43.000]  Вы хотите что-то спросить?
[00:43.000 --> 00:45.000]  Или так случайно получилось?
[00:45.000 --> 00:46.000]  Случайно.
[00:46.000 --> 00:47.000]  Окей.
[00:47.000 --> 00:49.000]  Ну давайте еще раз второе утверждение.
[00:49.000 --> 00:53.000]  Утверждение такое, что если у нас есть выпуклая или гладкая функция,
[00:54.000 --> 00:58.000]  и размер шага, который мы используем меньше единиц на L,
[00:58.000 --> 01:01.000]  тогда будет вот такая скорая сходимость.
[01:03.000 --> 01:06.000]  То есть это все у большой единиц на K.
[01:06.000 --> 01:11.000]  Почему здесь возникла K и из чего это будет следовать,
[01:11.000 --> 01:12.000]  сейчас пытаемся разобраться.
[01:12.000 --> 01:17.000]  Для этого сначала вспомним, что у нас было прекрасное неравенство,
[01:17.000 --> 01:23.000]  следующее только из-за L-гладкости.
[01:23.000 --> 01:25.000]  Липшица власти градиента.
[01:25.000 --> 01:29.000]  Мы его в прошлый раз достаточно быстро и не очень сложно получить.
[01:29.000 --> 01:31.000]  Теперь давайте внимательно посмотрим на вот это
[01:31.000 --> 01:34.000]  и будем его оценивать немножко по-другому в сравнении с тем,
[01:34.000 --> 01:36.000]  как мы это делали в прошлый раз.
[01:36.000 --> 01:39.000]  Оцениваем только компоненту, который с вынесенной альфой.
[01:39.000 --> 01:41.000]  Эта штука меньше либо равна,
[01:41.000 --> 01:45.000]  ну вообще понятно, что она просто равняется L альфа пола минус 1.
[01:45.000 --> 01:49.000]  Ну а раз у нас альфа ограничена сверху величиной 1 с на L,
[01:49.000 --> 01:53.000]  то эта штука меньше либо равна, чем на вторая минус 1,
[01:53.000 --> 01:55.000]  то есть минус одна вторая.
[01:55.000 --> 01:58.000]  Дальше мы это все подставляем в оценку.
[01:58.000 --> 02:03.000]  Получаем, что у нас и плюс один меньше либо равно, чем f от x и
[02:03.000 --> 02:05.000]  минус альфа пополам норму градиента.
[02:05.000 --> 02:08.000]  Это пока первое важное неравенство.
[02:08.000 --> 02:10.000]  Дальше вспоминаем, что у нас есть выпуклость,
[02:10.000 --> 02:12.000]  которая есть в критерии первого порядка.
[02:12.000 --> 02:16.000]  Запишем его для точек х со звездочкой и x и.
[02:16.000 --> 02:17.000]  Вот, то есть вот так.
[02:17.000 --> 02:21.000]  Дальше идет градиент и х со звездочкой минус x и.
[02:21.000 --> 02:23.000]  До этого момента все понятно?
[02:23.000 --> 02:24.000]  Или какие-то вопросы есть?
[02:24.000 --> 02:25.000]  Ставьте плюс, есть все понятно.
[02:25.000 --> 02:27.000]  Окей, вроде вопросов пока нет.
[02:27.000 --> 02:31.000]  Значит, описали критерии первого порядка для выпуклой функции,
[02:31.000 --> 02:35.000]  а дальше подставляем его, да, ну в общем, можно переписать,
[02:35.000 --> 02:37.000]  перефразируем, что называется,
[02:37.000 --> 02:41.000]  что f от x и-то меньше либо равно, чем f от x со звездочкой
[02:41.000 --> 02:46.000]  плюс скалярное произведение x и-то минус x со звездочкой.
[02:46.000 --> 02:48.000]  То есть перенесли знак, поменяли в скалярном произведении,
[02:48.000 --> 02:50.000]  вроде ничего не сломалось.
[02:50.000 --> 02:52.000]  Потом подставляем вот это вот сюда,
[02:52.000 --> 02:55.000]  и получаем прекрасное выражение о том,
[02:55.000 --> 02:59.000]  что у нас оказывается x от x и плюс первое меньше либо равно
[02:59.000 --> 03:02.000]  чем f от x со звездочкой
[03:02.000 --> 03:05.000]  плюс вот это вот прекрасное скалярное произведение
[03:05.000 --> 03:09.000]  и плюс, точнее, минус полам нормы нашего градиента.
[03:09.000 --> 03:11.000]  Вот, то есть подставили, все хорошо.
[03:11.000 --> 03:16.000]  Теперь, собственно, введем разность наших функций в одну сторону,
[03:16.000 --> 03:18.000]  все остальное в другую сторону,
[03:18.000 --> 03:20.000]  и если вы внимательно посмотрите,
[03:20.000 --> 03:22.000]  то здесь можно заметить, что вот эта штука очень сильно
[03:22.000 --> 03:24.000]  напоминает неполный квадрат.
[03:24.000 --> 03:25.000]  Сейчас будем к нему стремиться.
[03:25.000 --> 03:26.000]  Что у нас есть?
[03:26.000 --> 03:30.000]  У нас есть f от x и плюс один минус f от x со звездочкой,
[03:30.000 --> 03:32.000]  а тут меньше либо равно мы еще вот так сделаем.
[03:32.000 --> 03:36.000]  Поделим на, ну то есть вынесем единицы делить на два алифа,
[03:36.000 --> 03:40.000]  чтобы у нас тут заодно правильные коэффициенты начали появляться.
[03:40.000 --> 03:43.000]  То есть идея очень простая – получить полный квадрат.
[03:43.000 --> 03:44.000]  Сейчас мы его и получим.
[03:44.000 --> 03:45.000]  Вот так.
[03:45.000 --> 03:46.000]  То это такое.
[03:46.000 --> 03:49.000]  То есть если у нас тут альфа на…
[03:49.000 --> 03:50.000]  А что?
[03:50.000 --> 03:52.000]  Альфа на градиент – это первый множитель,
[03:52.000 --> 03:53.000]  то есть что получается?
[03:53.000 --> 03:54.000]  Что мы…
[03:54.000 --> 03:58.000]  Ну, наверное, тут будет минус стоять, раз тут с минусом, да?
[03:58.000 --> 04:00.000]  Альфа на градиент – это первый множитель,
[04:00.000 --> 04:02.000]  а тут дальше противоположный знак,
[04:02.000 --> 04:04.000]  поэтому будет идти минус.
[04:04.000 --> 04:05.000]  Минус что?
[04:05.000 --> 04:08.000]  Минус x со звездочкой,
[04:08.000 --> 04:10.000]  а минус x со звездочкой,
[04:10.000 --> 04:12.000]  плюс x и т.
[04:12.000 --> 04:14.000]  Понятно ли, откуда взялось это выражение?
[04:14.000 --> 04:17.000]  Или нужно подробнее расписать, что куда мы прибавили?
[04:17.000 --> 04:18.000]  Если выражение понятно откуда взялось,
[04:18.000 --> 04:20.000]  поставьте плюс, пожалуйста,
[04:20.000 --> 04:22.000]  чтобы я мог синтироваться,
[04:22.000 --> 04:24.000]  насколько подробнее нужно переписывать.
[04:24.000 --> 04:25.000]  М?
[04:25.000 --> 04:26.000]  Окей, спасибо.
[04:26.000 --> 04:27.000]  Ну и соответственно что?
[04:27.000 --> 04:29.000]  Раз мы там добавили квадрат нормы разности,
[04:29.000 --> 04:30.000]  то его надо будет чистить.
[04:30.000 --> 04:31.000]  Вот.
[04:31.000 --> 04:32.000]  Поэтому…
[04:32.000 --> 04:34.000]  Наоборот, там, когда выносился минус,
[04:34.000 --> 04:36.000]  давайте я его вынесу,
[04:36.000 --> 04:38.000]  появляется плюс и появляется минус.
[04:38.000 --> 04:39.000]  Вот.
[04:39.000 --> 04:40.000]  Соответственно…
[04:40.000 --> 04:42.000]  Да, мы прибавляем и вычитаем.
[04:42.000 --> 04:43.000]  Вот.
[04:43.000 --> 04:45.000]  Но поскольку мы учитываем вот это вот
[04:45.000 --> 04:47.000]  1 на 2 альфа здесь уже с плюсом,
[04:47.000 --> 04:48.000]  тут появится минус.
[04:48.000 --> 04:49.000]  То есть плюс.
[04:49.000 --> 04:52.000]  Квадрат нормы x и t – минус x со звездочкой.
[04:52.000 --> 04:53.000]  Вот.
[04:53.000 --> 04:55.000]  Смотрим теперь сюда и понимаем, что…
[04:55.000 --> 04:56.000]  Что мы понимаем?
[04:56.000 --> 04:58.000]  Ой, я минус не там поставил, извините.
[04:58.000 --> 04:59.000]  Так и вот так.
[04:59.000 --> 05:00.000]  Хорошо.
[05:00.000 --> 05:03.000]  Понимаем, что вот это и вот это вместе
[05:03.000 --> 05:06.000]  образует не что иное, как x и плюс первое.
[05:06.000 --> 05:08.000]  Есть на 2 альфа.
[05:08.000 --> 05:11.000]  Здесь будет норма x и минус x со звездочкой.
[05:11.000 --> 05:14.000]  Минус норма x и плюс первое,
[05:14.000 --> 05:15.000]  минус x со звездочкой.
[05:15.000 --> 05:16.000]  Вот.
[05:16.000 --> 05:18.000]  Получаем вот такое выражение.
[05:18.000 --> 05:20.000]  То есть слева у нас стоит разность функций,
[05:20.000 --> 05:23.000]  справа у нас стоит разность норм
[05:23.000 --> 05:25.000]  по отношению к x со звездочкой.
[05:25.000 --> 05:26.000]  Теперь.
[05:26.000 --> 05:28.000]  То, что понимает про такие неравенства
[05:28.000 --> 05:30.000]  и что с ними можно сделать.
[05:30.000 --> 05:31.000]  Это телекопическое неравенство.
[05:32.000 --> 05:33.000]  Именно так.
[05:33.000 --> 05:34.000]  Именно так, да.
[05:34.000 --> 05:36.000]  Надо все дело просуммировать.
[05:36.000 --> 05:37.000]  Вот.
[05:37.000 --> 05:40.000]  Ну там по i от нуля до, например, там k-1,
[05:40.000 --> 05:41.000]  чтобы было ровно k.
[05:41.000 --> 05:42.000]  Вот.
[05:42.000 --> 05:43.000]  Просуммируем вот это.
[05:43.000 --> 05:45.000]  Какое еще не телескопическое неравенство.
[05:45.000 --> 05:46.000]  Вот.
[05:46.000 --> 05:48.000]  А вот при суммировании того, что стоит справа,
[05:48.000 --> 05:50.000]  останется только…
[05:50.000 --> 05:51.000]  Что останется только?
[05:51.000 --> 05:53.000]  x0 минус x со звездочкой
[05:53.000 --> 05:56.000]  минус xk минус x со звездочкой.
[05:56.000 --> 05:59.000]  Все остальное благополучно взаимно уничтожится.
[05:59.000 --> 06:00.000]  Вот.
[06:00.000 --> 06:02.000]  Ну и раз тут мы вычитаем из них
[06:02.000 --> 06:03.000]  чего-то положительно,
[06:03.000 --> 06:05.000]  вот это меньше либо равно,
[06:05.000 --> 06:07.000]  чем 1 на 2 альфа
[06:07.000 --> 06:09.000]  норма x0 минус x со звездочкой.
[06:09.000 --> 06:11.000]  Теперь осталось с едой частью разобраться,
[06:11.000 --> 06:12.000]  чтобы получить то, что нам нужно.
[06:12.000 --> 06:14.000]  Ну, для этого мы воспользуемся тем,
[06:14.000 --> 06:15.000]  что мы знаем,
[06:15.000 --> 06:19.000]  знаем, что мы каждый раз хотим убивать,
[06:19.000 --> 06:22.000]  что на каждой итерации у нас значение функций меньше.
[06:22.000 --> 06:24.000]  Поэтому распишем f от x
[06:24.000 --> 06:27.000]  k-t минус f от x со звездочкой
[06:27.000 --> 06:28.000]  следующим образом.
[06:28.000 --> 06:30.000]  Это то же самое, что 1 на k
[06:30.000 --> 06:33.000]  сумма по i от 0 до k-1
[06:33.000 --> 06:35.000]  этого же самого выражения.
[06:35.000 --> 06:37.000]  Ну, то есть умножили и поделили на k,
[06:37.000 --> 06:39.000]  просто потом занеся выражение с функциями,
[06:39.000 --> 06:41.000]  которые от i никак не зависят.
[06:41.000 --> 06:42.000]  А дальше мы узнаем,
[06:42.000 --> 06:45.000]  что f от x k-t у нас всегда меньше либо равно,
[06:45.000 --> 06:47.000]  чем f от x it для всех i
[06:47.000 --> 06:50.000]  от 0 до k-1 получается.
[06:50.000 --> 06:52.000]  Ну, и до k в том числе.
[06:52.000 --> 06:53.000]  Вот.
[06:53.000 --> 06:56.000]  Поэтому эта штука меньше либо равна
[06:57.000 --> 07:00.000]  f от x i плюс 1
[07:00.000 --> 07:02.000]  минус f от x со звездочкой
[07:02.000 --> 07:05.000]  и от 0 до k-1.
[07:05.000 --> 07:06.000]  Вот.
[07:06.000 --> 07:08.000]  И это, в общем, вот это выражение,
[07:08.000 --> 07:09.000]  которое мы тут получили,
[07:09.000 --> 07:11.000]  в точности совпадает с вот этим выражением.
[07:11.000 --> 07:12.000]  То есть мы теперь знаем,
[07:12.000 --> 07:14.000]  что на самом деле это выражение
[07:14.000 --> 07:16.000]  снизу можно дополнительно оценить,
[07:16.000 --> 07:18.000]  как a умножить на вот эту разность.
[07:18.000 --> 07:20.000]  Вот, а значит, сама
[07:20.000 --> 07:21.000]  вот эту разность.
[07:21.000 --> 07:22.000]  Значит, сама эта разность
[07:22.000 --> 07:25.000]  f от x k-t минус f от x со звездочкой
[07:25.000 --> 07:26.000]  будет меньше либо равна,
[07:26.000 --> 07:28.000]  чем то, что мы здесь получили,
[07:28.000 --> 07:30.000]  делить на 2 альфа умножить на k.
[07:30.000 --> 07:31.000]  Вот, получили такое самое.
[07:31.000 --> 07:33.000]  Понятно ли процедура,
[07:33.000 --> 07:35.000]  которую мы исследовали
[07:35.000 --> 07:36.000]  и финальный результат?
[07:36.000 --> 07:38.000]  Поставьте плюс, если все понятно,
[07:38.000 --> 07:40.000]  и минус, если есть какие-то вопросы.
[07:40.000 --> 07:42.000]  Пока вижу два плюса,
[07:42.000 --> 07:44.000]  дела у остальных три,
[07:44.000 --> 07:45.000]  видимо, не плюс.
[07:45.000 --> 07:46.000]  Окей.
[07:46.000 --> 07:47.000]  Так, здорово.
[07:47.000 --> 07:49.000]  Тогда давайте так, с этим разобрались.
[07:49.000 --> 07:51.000]  Значит, про градиентный метод все доказано,
[07:51.000 --> 07:52.000]  все замечательно.
[07:52.000 --> 07:53.000]  Теперь давайте обсудим,
[07:53.000 --> 07:55.000]  что происходит,
[07:55.000 --> 07:57.000]  не что происходит,
[07:57.000 --> 07:59.000]  как, в принципе, можно
[07:59.000 --> 08:02.000]  пытаться сравнить методы
[08:02.000 --> 08:04.000]  независимо от
[08:04.000 --> 08:05.000]  конкретной функции,
[08:05.000 --> 08:07.000]  для которых они применяются.
[08:07.000 --> 08:09.000]  Для этого следует такой
[08:09.000 --> 08:10.000]  немного, может быть,
[08:10.000 --> 08:11.000]  странной конструкции.
[08:11.000 --> 08:12.000]  Сейчас я попытаюсь ее
[08:12.000 --> 08:13.000]  понятнее объяснить.
[08:13.000 --> 08:15.000]  Вот, это всегда некоторые вызов
[08:15.000 --> 08:16.000]  объяснить эту конструкцию,
[08:16.000 --> 08:17.000]  но мы сейчас разберемся.
[08:17.000 --> 08:18.000]  Значит, что говорят?
[08:18.000 --> 08:21.000]  Говорят, что мы, поскольку,
[08:21.000 --> 08:22.000]  да, нижние оценки
[08:22.000 --> 08:24.000]  сейчас можно сказать,
[08:24.000 --> 08:26.000]  поскольку мы хотим понять,
[08:26.000 --> 08:28.000]  как у нас все работает
[08:28.000 --> 08:30.000]  в концепте черного ящика,
[08:30.000 --> 08:32.000]  то есть мы не знаем,
[08:32.000 --> 08:33.000]  какая у нас функция конкретная.
[08:33.000 --> 08:34.000]  Мы знаем такое свойство,
[08:34.000 --> 08:36.000]  то есть f там l гладкой, например,
[08:36.000 --> 08:38.000]  или там f l гладко
[08:38.000 --> 08:40.000]  плюс mu сильно выпала.
[08:40.000 --> 08:43.000]  И хочется понять в лучшем случае
[08:43.000 --> 08:45.000]  метод из определенного класса.
[08:45.000 --> 08:46.000]  То есть что такое класс метода?
[08:46.000 --> 08:48.000]  То есть мы будем рассматривать методы,
[08:48.000 --> 08:50.000]  которые имеют вот такой вот вид сейчас.
[08:50.000 --> 08:52.000]  То есть у нас xk плюс 1 – это x0
[08:52.000 --> 08:55.000]  плюс линейная комбинация градиентов
[08:55.000 --> 08:56.000]  во всех предыдущих точках.
[08:56.000 --> 08:57.000]  Это класс методов.
[08:57.000 --> 08:58.000]  Любой метод,
[08:58.000 --> 09:00.000]  какой бы мы из этого класса не взяли,
[09:00.000 --> 09:03.000]  он как-то в каком-то интервале
[09:03.000 --> 09:05.000]  будет лежать в его сходимости.
[09:05.000 --> 09:07.000]  И концепция нижних оценок
[09:07.000 --> 09:08.000]  говорит нам о том,
[09:08.000 --> 09:09.000]  что если мы представим
[09:09.000 --> 09:12.000]  такую функцию, какую-то f крышкой,
[09:12.000 --> 09:14.000]  какую, что для f с крышкой
[09:14.000 --> 09:17.000]  будет выполнено такое вот ограничение,
[09:17.000 --> 09:19.000]  тут o от чего-то.
[09:19.000 --> 09:20.000]  Видите, тут вот важно
[09:20.000 --> 09:22.000]  подчеркиваю, что тут оценка
[09:22.000 --> 09:23.000]  в другую сторону.
[09:23.000 --> 09:24.000]  Она говорит не о том,
[09:24.000 --> 09:26.000]  что мы будем как минимум
[09:26.000 --> 09:27.000]  такими же быстрыми, как что-то.
[09:27.000 --> 09:29.000]  Вот было вот здесь.
[09:29.000 --> 09:30.000]  Она говорит наоборот,
[09:30.000 --> 09:33.000]  что лучше чем что-то мы не будем.
[09:33.000 --> 09:36.000]  Достаточно предъявить одну такую функцию,
[09:36.000 --> 09:38.000]  чтобы можно было заключить,
[09:38.000 --> 09:40.000]  что если мы возьмем,
[09:40.000 --> 09:43.000]  что для этого класса функций
[09:43.000 --> 09:45.000]  и этого класса методов справедливо,
[09:45.000 --> 09:48.000]  что если мы ничего про функцию не знаем,
[09:48.000 --> 09:50.000]  то в худшем случае
[09:50.000 --> 09:51.000]  можем рассчитывать только
[09:51.000 --> 09:53.000]  на вот ту скорость сходимости,
[09:53.000 --> 09:54.000]  которая вот здесь.
[09:54.000 --> 09:55.000]  То есть грубо говоря,
[09:55.000 --> 09:56.000]  смотрите, что если там
[09:56.000 --> 09:57.000]  рисовать картинку,
[09:57.000 --> 09:59.000]  вот у нас есть число итерации,
[09:59.000 --> 10:01.000]  вот у нас есть там гэп какой-то.
[10:01.000 --> 10:02.000]  Вот у нас была сходимость
[10:02.000 --> 10:04.000]  гридиентного спуска вот такая.
[10:04.000 --> 10:05.000]  Это был гридиентный спуск.
[10:05.000 --> 10:07.000]  А вот оценка скорости сходимости
[10:07.000 --> 10:09.000]  на эти глотки функции,
[10:09.000 --> 10:10.000]  она вот так идет.
[10:10.000 --> 10:11.000]  То есть это вот lower bound.
[10:11.000 --> 10:13.000]  Соответственно, если мы видим,
[10:13.000 --> 10:15.000]  что между оценкой сверху нашего метода
[10:15.000 --> 10:17.000]  и оценкой снизу
[10:17.000 --> 10:19.000]  для всего класса методов
[10:19.000 --> 10:21.000]  и класса функций есть зазор,
[10:21.000 --> 10:22.000]  это значит, что мы можем
[10:22.000 --> 10:23.000]  что-то улучшить.
[10:23.000 --> 10:26.000]  Если мы видим, что зазора нет
[10:26.000 --> 10:27.000]  и они совпадают,
[10:27.000 --> 10:28.000]  это значит, что мы нашли
[10:28.000 --> 10:30.000]  в смысле нижних оценок
[10:30.000 --> 10:31.000]  оптимальный метод.
[10:31.000 --> 10:33.000]  Понятна ли логика построения?
[10:33.000 --> 10:34.000]  Ставьте плюс, если понятно,
[10:34.000 --> 10:36.000]  минус, если непонятно.
[10:36.000 --> 10:37.000]  Саможнежер оранжевая,
[10:37.000 --> 10:38.000]  это какая теоретическая оценка?
[10:38.000 --> 10:40.000]  Которую я пока еще не написал.
[10:40.000 --> 10:41.000]  Просто некоторая оценка снизу,
[10:41.000 --> 10:43.000]  которая вот здесь вот сидит.
[10:43.000 --> 10:45.000]  Вроде пишут, что более-менее понятно.
[10:45.000 --> 10:46.000]  То есть на самом деле,
[10:46.000 --> 10:48.000]  если уже переходить к конкретике,
[10:48.000 --> 10:52.000]  по оценке для l-гладких функций,
[10:52.000 --> 10:53.000]  выпуклых функций,
[10:53.000 --> 10:56.000]  такие, что f каплюс первое
[10:56.000 --> 10:57.000]  минус f со звездочкой
[10:57.000 --> 10:58.000]  больше либо равно,
[10:58.000 --> 11:01.000]  чем там 3l на норму
[11:01.000 --> 11:03.000]  x0 минус x со звездочкой
[11:03.000 --> 11:05.000]  делить на k плюс 1 в квадрате.
[11:05.000 --> 11:06.000]  То есть это на самом деле
[11:06.000 --> 11:08.000]  от 1 на k квадрат.
[11:08.000 --> 11:10.000]  А для л-гладких,
[11:10.000 --> 11:11.000]  имиусильно выпуклых,
[11:11.000 --> 11:13.000]  там немножко похитрее,
[11:13.000 --> 11:15.000]  там примерно то же самое,
[11:15.000 --> 11:16.000]  что у нас было
[11:16.000 --> 11:19.000]  в оценках на вариантный спуск,
[11:19.000 --> 11:20.000]  только тут корень
[11:20.000 --> 11:22.000]  и часа обусловленности 2, как у нас.
[11:22.000 --> 11:24.000]  И x0 минус x со звездочки тоже в квадрате.
[11:24.000 --> 11:26.000]  То есть эти нижние оценки,
[11:26.000 --> 11:28.000]  я сейчас, наверное,
[11:28.000 --> 11:30.000]  не буду детально их выводить,
[11:30.000 --> 11:31.000]  потому что это типа еще
[11:31.000 --> 11:33.000]  плюс-минус 40, наверное, час.
[11:33.000 --> 11:35.000]  В слайдах, в принципе,
[11:35.000 --> 11:37.000]  будет приведен детальный вывод
[11:37.000 --> 11:39.000]  для l-гладких функций.
[11:39.000 --> 11:40.000]  Можете увидеть, какая там плохая функция,
[11:40.000 --> 11:41.000]  как она строится.
[11:41.000 --> 11:43.000]  Если будут какие-то вопросы,
[11:43.000 --> 11:44.000]  мы в следующий раз можем обсудить.
[11:44.000 --> 11:47.000]  Там действительно все не очень просто
[11:47.000 --> 11:49.000]  и не очень быстро делать.
[11:49.000 --> 11:51.000]  И, соответственно, что получается?
[11:51.000 --> 11:53.000]  Получается, что для градиентного спуска
[11:53.000 --> 11:57.000]  у нас сходимость только 1 на k,
[11:57.000 --> 11:58.000]  а оценка снизу говорит нам,
[11:58.000 --> 12:00.000]  что можно, в общем-то,
[12:00.000 --> 12:02.000]  и ускориться до 1 на k квадрат.
[12:02.000 --> 12:04.000]  Ну и для сильного выпукового случая
[12:04.000 --> 12:05.000]  та же самая история,
[12:05.000 --> 12:07.000]  что мы сначала говорим про
[12:07.000 --> 12:09.000]  сходимость вида по минус 1
[12:09.000 --> 12:11.000]  делить на k в плюс 1.
[12:11.000 --> 12:12.000]  Здесь мы видим, что начинает
[12:12.000 --> 12:13.000]  фигурировать уже корень,
[12:13.000 --> 12:14.000]  что, оказывается,
[12:14.000 --> 12:16.000]  действительно существенно быстрее.
[12:16.000 --> 12:17.000]  Наверное, надо показать,
[12:17.000 --> 12:19.000]  почему это будет существенно быстрее.
[12:19.000 --> 12:21.000]  То есть, смотрите,
[12:21.000 --> 12:24.000]  если у нас кап для простоты 10 четвертый,
[12:24.000 --> 12:26.000]  то коэффициент q,
[12:26.000 --> 12:27.000]  который будет в градиентном спуске,
[12:27.000 --> 12:29.000]  это 10 четвертый минус 1
[12:29.000 --> 12:30.000]  на 10 четвертый плюс 1.
[12:30.000 --> 12:31.000]  Но можете представить,
[12:31.000 --> 12:33.000]  насколько это близко к единице
[12:33.000 --> 12:34.000]  градиентной спуске.
[12:34.000 --> 12:36.000]  А q со звездочкой
[12:36.000 --> 12:38.000]  это всего лишь 0,99.
[12:38.000 --> 12:40.000]  И для того, чтобы получить
[12:40.000 --> 12:42.000]  нужную точность ε,
[12:42.000 --> 12:43.000]  вот такой вот,
[12:43.000 --> 12:45.000]  таким вот нужно, по-моему,
[12:45.000 --> 12:46.000]  в разы меньше итерации,
[12:46.000 --> 12:47.000]  чем вот такой.
[12:47.000 --> 12:49.000]  Понятно ли, почему корень
[12:49.000 --> 12:50.000]  так сильно ускоряет,
[12:50.000 --> 12:52.000]  или нужно подробнее это расписать
[12:52.000 --> 12:53.000]  и показать реально,
[12:53.000 --> 12:54.000]  на реальных числах,
[12:54.000 --> 12:55.000]  как это будет выглядеть?
[12:55.000 --> 12:57.000]  Или понятно, что вот это гораздо
[12:57.000 --> 12:58.000]  в разы лучше, чем вот это?
[12:58.000 --> 12:59.000]  Вроде понятно.
[12:59.000 --> 13:00.000]  Окей.
[13:00.000 --> 13:02.000]  Вот вижу, что Марка и Андрею понятно.
[13:02.000 --> 13:04.000]  Как дела у них?
[13:04.000 --> 13:05.000]  Что-то тишина.
[13:05.000 --> 13:07.000]  Наверное, давайте я все-таки
[13:07.000 --> 13:08.000]  пропишу подробнее.
[13:08.000 --> 13:10.000]  Переживаю, что, может быть,
[13:10.000 --> 13:11.000]  не очень понятно,
[13:11.000 --> 13:13.000]  что это я прописал.
[13:13.000 --> 13:14.000]  Ну, смотрите,
[13:14.000 --> 13:15.000]  что происходит на самом деле.
[13:15.000 --> 13:17.000]  На самом деле нам нужно сравнить
[13:17.000 --> 13:18.000]  две оценки сверху.
[13:18.000 --> 13:20.000]  Одна оценка сверху вида,
[13:20.000 --> 13:22.000]  вот так, в степени 2k,
[13:22.000 --> 13:23.000]  на норму.
[13:23.000 --> 13:24.000]  Другая у нас была,
[13:24.000 --> 13:25.000]  типа вот такая, по-моему,
[13:25.000 --> 13:26.000]  в степени 2k,
[13:26.000 --> 13:28.000]  на ту же самую норму.
[13:28.000 --> 13:30.000]  И мы хотим, чтобы
[13:30.000 --> 13:31.000]  и там, и там был меньше ε.
[13:31.000 --> 13:32.000]  Для одного и того же ε.
[13:32.000 --> 13:33.000]  Ну, например, ε мы хотим,
[13:33.000 --> 13:35.000]  чтобы был 10-5.
[13:35.000 --> 13:37.000]  Чтобы мы были близки
[13:37.000 --> 13:39.000]  с оптимальным значением функции
[13:39.000 --> 13:40.000]  на уровне 10-5.
[13:40.000 --> 13:41.000]  Тогда что надо сделать?
[13:41.000 --> 13:43.000]  Надо взять, выразить,
[13:43.000 --> 13:45.000]  ну, то есть это будет q в степени 2k,
[13:45.000 --> 13:47.000]  потом просто разные q подставим,
[13:47.000 --> 13:48.000]  получим разные числа.
[13:48.000 --> 13:49.000]  Меньше либо равно
[13:49.000 --> 13:51.000]  ε делить на вот эту норму.
[13:51.000 --> 13:52.000]  Вот, про логарифмировав.
[13:52.000 --> 13:53.000]  Стоп, неправильно.
[13:53.000 --> 13:54.000]  Вот, ну и, соответственно,
[13:54.000 --> 13:56.000]  если k выражать, то что будет?
[13:56.000 --> 13:58.000]  k меньше либо равно,
[13:58.000 --> 14:00.000]  чем ε делить на 2,
[14:00.000 --> 14:01.000]  на две вот этих нормы.
[14:01.000 --> 14:03.000]  И тут еще логарифм q.
[14:03.000 --> 14:04.000]  То есть, соответственно,
[14:04.000 --> 14:05.000]  то, что здесь,
[14:05.000 --> 14:07.000]  а, и больше либо равно, наверное.
[14:07.000 --> 14:08.000]  Потому что логарифм q
[14:08.000 --> 14:09.000]  у нас отрицательный,
[14:09.000 --> 14:10.000]  мы на него делим,
[14:10.000 --> 14:11.000]  получаем, и знак меняется.
[14:11.000 --> 14:12.000]  Ну, и это он
[14:12.000 --> 14:14.000]  с логарифм q дает нам...
[14:14.000 --> 14:16.000]  Все неправильно, простите.
[14:16.000 --> 14:17.000]  Сейчас.
[14:17.000 --> 14:18.000]  Что-то я немножко напортачил.
[14:18.000 --> 14:20.000]  Да, но вот логарифм вот здесь стоит
[14:20.000 --> 14:23.000]  и будет идти уже не так все легко
[14:23.000 --> 14:25.000]  и непринужденно.
[14:25.000 --> 14:26.000]  Будет отношение логарифм.
[14:26.000 --> 14:27.000]  Отлично.
[14:27.000 --> 14:29.000]  Ну и, соответственно, что?
[14:29.000 --> 14:30.000]  k больше либо равно,
[14:30.000 --> 14:31.000]  чем такая величина?
[14:31.000 --> 14:32.000]  В первом случае,
[14:32.000 --> 14:34.000]  когда у нас был градиентный спуск,
[14:34.000 --> 14:37.000]  у нас q равняется, короче,
[14:37.000 --> 14:38.000]  просто отношение этих штук.
[14:38.000 --> 14:39.000]  Посчитайте все.
[14:39.000 --> 14:40.000]  Да.
[14:40.000 --> 14:41.000]  То есть, давайте посчитаем
[14:41.000 --> 14:43.000]  отношение минимального чела и тараса
[14:43.000 --> 14:44.000]  для градиентного спуска
[14:44.000 --> 14:46.000]  и для оптимального метода.
[14:46.000 --> 14:49.000]  Два логарифма q со звездочкой,
[14:49.000 --> 14:50.000]  ну и тут будет то же самое.
[14:50.000 --> 14:51.000]  В общем, это все сократится,
[14:51.000 --> 14:54.000]  останется просто отношение логарифмов.
[14:54.000 --> 14:55.000]  А это, понятно будет,
[14:55.000 --> 14:57.000]  что такое, можно даже посчитать.
[14:57.000 --> 14:58.000]  То есть, в одном случае будет
[14:58.000 --> 15:00.000]  логарифм 0,99 сверху будет.
[15:00.000 --> 15:01.000]  А в другом будет логарифм
[15:01.000 --> 15:02.000]  от 10 в четвертый,
[15:02.000 --> 15:03.000]  минус один,
[15:03.000 --> 15:04.000]  10 в четвертый плюс один.
[15:04.000 --> 15:05.000]  У кого по другой калькуляторе,
[15:05.000 --> 15:06.000]  у кого по другой калькуляторе,
[15:06.000 --> 15:08.000]  давайте попробуем это посчитать
[15:08.000 --> 15:09.000]  и скажите, какие значения
[15:09.000 --> 15:10.000]  у вас получат.
[15:10.000 --> 15:11.000]  Примерно 50.
[15:11.000 --> 15:12.000]  Ну вот, да, примерно 50.
[15:12.000 --> 15:14.000]  То есть, в 50 раз
[15:14.000 --> 15:15.000]  тараси будет меньше.
[15:15.000 --> 15:16.000]  Чувствуете разницу?
[15:16.000 --> 15:17.000]  То есть, условно,
[15:17.000 --> 15:19.000]  градиентному спуску нужно
[15:19.000 --> 15:20.000]  порядка тысячи,
[15:20.000 --> 15:22.000]  нужно будет порядка 100.
[15:22.000 --> 15:23.000]  Это действительно существенное
[15:23.000 --> 15:24.000]  получается ускорение.
[15:24.000 --> 15:25.000]  Гуд.
[15:25.000 --> 15:27.000]  Есть ли какие-то вопросы
[15:27.000 --> 15:29.000]  по этой теме про нижние отцам?
[15:29.000 --> 15:30.000]  Сейчас к мне уже перейдем.
[15:30.000 --> 15:32.000]  Ну, вопросов вроде бы нет.
[15:32.000 --> 15:33.000]  Тогда давайте сейчас
[15:33.000 --> 15:35.000]  немножко я поправлю
[15:35.000 --> 15:36.000]  последовательность.
[15:36.000 --> 15:38.000]  Начнем с общих методов.
[15:38.000 --> 15:39.000]  Если останется время,
[15:39.000 --> 15:40.000]  рассмотрим один частный,
[15:40.000 --> 15:41.000]  но очень важный.
[15:41.000 --> 15:42.000]  Итак, первый называется метод
[15:42.000 --> 15:43.000]  тяжелого шарика,
[15:43.000 --> 15:45.000]  который, наверное, самый простой
[15:45.000 --> 15:46.000]  для понимания
[15:46.000 --> 15:47.000]  и в то же время
[15:47.000 --> 15:48.000]  достаточно эффективный.
[15:48.000 --> 15:50.000]  Идея была очень простая.
[15:50.000 --> 15:52.000]  Это Борис Садорович Поляк,
[15:52.000 --> 15:54.000]  1964 год.
[15:54.000 --> 15:56.000]  Соответственно, там,
[15:56.000 --> 15:57.000]  если найти оригинальную,
[15:57.000 --> 15:58.000]  есть открытым доске.
[15:58.000 --> 16:00.000]  Вот так.
[16:00.000 --> 16:01.000]  Да, идея была очень простая.
[16:01.000 --> 16:02.000]  Давайте мы перепишем
[16:02.000 --> 16:04.000]  наш замечательный градиент
[16:04.000 --> 16:06.000]  из пуск, добавив в него
[16:06.000 --> 16:07.000]  некоторые слагаемые
[16:07.000 --> 16:08.000]  дополнительные, которые нам
[16:08.000 --> 16:10.000]  еще трение будет учитывать.
[16:10.000 --> 16:11.000]  Если думать об этом,
[16:11.000 --> 16:13.000]  как о моделировании
[16:13.000 --> 16:15.000]  динамической системы трения.
[16:15.000 --> 16:16.000]  Поэтому тяжелый шарик.
[16:16.000 --> 16:17.000]  То есть, есть некоторая
[16:17.000 --> 16:18.000]  индационность, которая
[16:18.000 --> 16:20.000]  позволяет сглаживать
[16:20.000 --> 16:22.000]  плохо обусловленные
[16:22.000 --> 16:24.000]  линии уровня.
[16:24.000 --> 16:25.000]  То есть у нас был как?
[16:25.000 --> 16:26.000]  Если было вот так,
[16:26.000 --> 16:27.000]  то градиент из пуск
[16:27.000 --> 16:29.000]  у нас прыгал вот так,
[16:29.000 --> 16:30.000]  тихонько оближаясь.
[16:30.000 --> 16:31.000]  То вот эта штуковина
[16:31.000 --> 16:33.000]  из-за вот этого коэффициента.
[16:33.000 --> 16:34.000]  Сделай следующее.
[16:34.000 --> 16:35.000]  Она прыгнет вот так.
[16:35.000 --> 16:37.000]  Потом ей захочется прыгнуть.
[16:37.000 --> 16:38.000]  Направление одно будет
[16:38.000 --> 16:39.000]  сюда вести.
[16:39.000 --> 16:40.000]  Но мы будем помнить,
[16:40.000 --> 16:42.000]  что до этого мы шли сюда.
[16:42.000 --> 16:44.000]  И с коэффициентами альфа и бета
[16:44.000 --> 16:45.000]  у нас итоговое направление
[16:45.000 --> 16:47.000]  будет каким-то вот таким.
[16:47.000 --> 16:49.000]  То же самое будет происходить
[16:49.000 --> 16:50.000]  и из этой точки.
[16:50.000 --> 16:51.000]  То есть видите,
[16:51.000 --> 16:52.000]  тут как бы для картины,
[16:52.000 --> 16:54.000]  конечно, не так,
[16:54.000 --> 16:56.000]  чтобы супер-хорошая.
[16:56.000 --> 16:58.000]  Но здесь понятно, что мы
[16:58.000 --> 17:00.000]  за счет вот этого учета
[17:00.000 --> 17:01.000]  предыдущего направления
[17:01.000 --> 17:03.000]  вместо двух итераций
[17:03.000 --> 17:04.000]  как бы сделали одну.
[17:04.000 --> 17:06.000]  Ну если сравнить количество палочек,
[17:06.000 --> 17:07.000]  которые получилось нарисовать.
[17:07.000 --> 17:09.000]  Ну и из этой точки аналогично.
[17:09.000 --> 17:11.000]  Мы хотели прыгнуть вот сюда.
[17:11.000 --> 17:13.000]  У нас предыдущее направление,
[17:13.000 --> 17:15.000]  оно нас двигает вот сюда.
[17:15.000 --> 17:16.000]  И поэтому суммарно
[17:16.000 --> 17:18.000]  мы прыгнем куда-нибудь сюда.
[17:18.000 --> 17:19.000]  И таким образом
[17:19.000 --> 17:20.000]  мы взгладим нашу траекторию
[17:20.000 --> 17:22.000]  и сойдемся к точке минимум
[17:22.000 --> 17:23.000]  гораздо быстрее.
[17:23.000 --> 17:25.000]  Понятно ли, почему это работает?
[17:25.000 --> 17:27.000]  И почему, по идее,
[17:27.000 --> 17:28.000]  должно работать быстрее.
[17:28.000 --> 17:30.000]  Ставьте плюс, если понятно.
[17:30.000 --> 17:32.000]  Вроде нормально.
[17:32.000 --> 17:34.000]  Ну, собственно, теперь надо понять,
[17:34.000 --> 17:35.000]  как эта штука будет сходиться.
[17:35.000 --> 17:37.000]  А ну важно сказать, что
[17:37.000 --> 17:38.000]  да, самое главное
[17:38.000 --> 17:39.000]  это, наверное, не сказал.
[17:39.000 --> 17:40.000]  Первое, свойство метода,
[17:40.000 --> 17:41.000]  что он двухшаговый,
[17:41.000 --> 17:42.000]  в отличие от одношагового
[17:42.000 --> 17:43.000]  гранитного спуска.
[17:43.000 --> 17:45.000]  То есть тут мы дополнительно
[17:45.000 --> 17:46.000]  еще вынуждены хранить
[17:46.000 --> 17:47.000]  предыдущую точку,
[17:47.000 --> 17:48.000]  xk-1,
[17:48.000 --> 17:49.000]  для того, чтобы посчитать
[17:49.000 --> 17:50.000]  предыдущую, ну,
[17:50.000 --> 17:51.000]  принять в внимание
[17:51.000 --> 17:52.000]  предыдущие направления.
[17:52.000 --> 17:53.000]  И второе, он не монотонный.
[17:53.000 --> 17:55.000]  То есть мы отказываемся
[17:55.000 --> 17:56.000]  от требования того,
[17:56.000 --> 17:57.000]  чтобы на каждой итерация
[17:57.000 --> 17:58.000]  без этого бывали.
[17:58.000 --> 17:59.000]  Потому что здесь может
[17:59.000 --> 18:00.000]  что-нибудь произойти по дороге
[18:00.000 --> 18:01.000]  так, что мы будем
[18:01.000 --> 18:03.000]  как-то стилировать немножко.
[18:03.000 --> 18:04.000]  Ничего страшного.
[18:04.000 --> 18:07.000]  Значит, как это теперь доказывается?
[18:07.000 --> 18:08.000]  Ну, вот я сейчас
[18:08.000 --> 18:09.000]  драфт некоторой
[18:09.000 --> 18:10.000]  оказательства сформулирую.
[18:10.000 --> 18:12.000]  А дальше, в общем,
[18:12.000 --> 18:14.000]  есть некоторые нюансы в том,
[18:14.000 --> 18:16.000]  как именно это доводится до конца.
[18:16.000 --> 18:17.000]  И формулы, которые
[18:17.000 --> 18:18.000]  получаются на выходе,
[18:18.000 --> 18:19.000]  они получаются довольно
[18:19.000 --> 18:20.000]  не очень приятные.
[18:20.000 --> 18:22.000]  В общем, сходимость доказана
[18:22.000 --> 18:23.000]  только для сильного
[18:23.000 --> 18:24.000]  упакового случая.
[18:24.000 --> 18:25.000]  Вот так, сходимость.
[18:25.000 --> 18:26.000]  Так, сходимость
[18:26.000 --> 18:28.000]  для сильного упакового функции.
[18:28.000 --> 18:29.000]  Вот.
[18:29.000 --> 18:30.000]  И для того, чтобы
[18:30.000 --> 18:31.000]  получить все результаты,
[18:31.000 --> 18:32.000]  надо сделать следующее.
[18:32.000 --> 18:33.000]  Переписать этот метод
[18:33.000 --> 18:34.000]  в блочном виде.
[18:34.000 --> 18:35.000]  Странно это мне казалось
[18:35.000 --> 18:36.000]  на первый взгляд.
[18:36.000 --> 18:37.000]  То есть, а именно,
[18:37.000 --> 18:38.000]  блочный вектор у нас
[18:38.000 --> 18:39.000]  будет xk плюс 1 и xk.
[18:39.000 --> 18:40.000]  Вот.
[18:40.000 --> 18:41.000]  И мы попытаемся сейчас
[18:41.000 --> 18:43.000]  вытащить все линейное
[18:43.000 --> 18:45.000]  и отправить все нелинейное
[18:45.000 --> 18:47.000]  в буквально слагаемое.
[18:47.000 --> 18:49.000]  То есть тут у нас будет
[18:49.000 --> 18:50.000]  x, соответственно, k
[18:50.000 --> 18:52.000]  и xk минус 1.
[18:52.000 --> 18:53.000]  Так.
[18:53.000 --> 18:54.000]  Ну и там, например,
[18:54.000 --> 18:55.000]  геечная матрица 0,
[18:55.000 --> 18:57.000]  минус альфа к на градиент.
[18:57.000 --> 18:59.000]  Ну и здесь будет просто 0.
[18:59.000 --> 19:00.000]  То есть, просто записали
[19:00.000 --> 19:01.000]  вот первая строчка.
[19:01.000 --> 19:03.000]  Это наше исходное равенство.
[19:03.000 --> 19:04.000]  Вот.
[19:04.000 --> 19:05.000]  А вторая строчка
[19:05.000 --> 19:06.000]  просто тождественная равенство.
[19:06.000 --> 19:07.000]  Не сложно перемножить
[19:07.000 --> 19:09.000]  и убедиться в этом.
[19:09.000 --> 19:10.000]  Значит, это первый шаг.
[19:10.000 --> 19:11.000]  Далее мы сделаем
[19:11.000 --> 19:13.000]  следующий небольшой трюк.
[19:13.000 --> 19:14.000]  А именно, возьмем
[19:14.000 --> 19:17.000]  и припишем эту штуку.
[19:17.000 --> 19:18.000]  То есть, вычтем
[19:18.000 --> 19:19.000]  из обеих частей
[19:19.000 --> 19:20.000]  и к созвездочке.
[19:20.000 --> 19:21.000]  Чтобы получить, собственно,
[19:21.000 --> 19:24.000]  наши обычные искомые разности
[19:24.000 --> 19:26.000]  между текущим положением
[19:26.000 --> 19:27.000]  и x-озвездочкой.
[19:27.000 --> 19:28.000]  Но, помимо этого,
[19:28.000 --> 19:29.000]  помимо этого,
[19:29.000 --> 19:30.000]  мы еще и учтем,
[19:30.000 --> 19:31.000]  что в x-озвездочке
[19:31.000 --> 19:32.000]  у нас градиент 0.
[19:32.000 --> 19:34.000]  Поэтому вот здесь появится
[19:34.000 --> 19:36.000]  дополнительно разность
[19:36.000 --> 19:38.000]  с градиентом в точке 0.
[19:38.000 --> 19:39.000]  Которую мы, ну, то есть,
[19:39.000 --> 19:40.000]  грубо говоря, запишем,
[19:40.000 --> 19:42.000]  что f' от xk
[19:42.000 --> 19:45.000]  минус f' от x-озвездочкой
[19:45.000 --> 19:46.000]  у нас будет там
[19:46.000 --> 19:48.000]  равен интеграл от 0 до 1
[19:48.000 --> 19:50.000]  f' х от tau
[19:50.000 --> 19:51.000]  ну, то есть,
[19:51.000 --> 19:52.000]  перепишем в виде интеграла.
[19:52.000 --> 19:53.000]  Вот.
[19:53.000 --> 19:54.000]  И если это все вместе объединить,
[19:54.000 --> 19:55.000]  то получим, что
[19:55.000 --> 19:56.000]  остается единица
[19:56.000 --> 19:57.000]  плюс бета катой
[19:57.000 --> 19:58.000]  на единичную матрицу.
[19:58.000 --> 19:59.000]  Вот.
[19:59.000 --> 20:01.000]  Только здесь теперь остается
[20:01.000 --> 20:02.000]  минус альфа катой
[20:02.000 --> 20:03.000]  на вот этот вот интеграл
[20:03.000 --> 20:04.000]  при ряда 1
[20:04.000 --> 20:05.000]  f'
[20:05.000 --> 20:06.000]  потому что он будет
[20:06.000 --> 20:07.000]  тоже умножаться на
[20:07.000 --> 20:09.000]  x катой минус x-озвездочкой.
[20:09.000 --> 20:10.000]  Да.
[20:10.000 --> 20:11.000]  Все-все-все.
[20:11.000 --> 20:12.000]  Правильно?
[20:12.000 --> 20:13.000]  А, нет, неправильно.
[20:13.000 --> 20:14.000]  А, нет, правильно.
[20:14.000 --> 20:15.000]  Сорри.
[20:15.000 --> 20:16.000]  Здесь xxx от tau.
[20:16.000 --> 20:17.000]  Соответственно, путь
[20:17.000 --> 20:18.000]  x катого
[20:18.000 --> 20:19.000]  плюс tau
[20:19.000 --> 20:20.000]  x-озвездочкой
[20:20.000 --> 20:21.000]  минус x катой.
[20:21.000 --> 20:22.000]  Правда?
[20:22.000 --> 20:23.000]  Нет.
[20:23.000 --> 20:24.000]  Стойте.
[20:24.000 --> 20:25.000]  Что-то не то.
[20:25.000 --> 20:26.000]  Тут вот еще надо домножить
[20:26.000 --> 20:27.000]  на x
[20:27.000 --> 20:28.000]  со звездочкой
[20:28.000 --> 20:29.000]  минус xk.
[20:29.000 --> 20:30.000]  И как раз тогда
[20:30.000 --> 20:31.000]  все будет правомерно.
[20:31.000 --> 20:32.000]  От x от tau до tau.
[20:32.000 --> 20:33.000]  Вот.
[20:33.000 --> 20:34.000]  Коэффициент
[20:34.000 --> 20:35.000]  минус бета катой
[20:35.000 --> 20:36.000]  единичная матрица
[20:36.000 --> 20:37.000]  останется.
[20:37.000 --> 20:38.000]  Тоже все будет хорошо,
[20:38.000 --> 20:39.000]  но получится,
[20:39.000 --> 20:40.000]  что здесь у нас
[20:40.000 --> 20:41.000]  x k
[20:41.000 --> 20:42.000]  минус x-озвездочкой.
[20:42.000 --> 20:43.000]  А тут
[20:43.000 --> 20:44.000]  x k
[20:44.000 --> 20:45.000]  минус 1
[20:45.000 --> 20:46.000]  минус x-озвездочкой.
[20:46.000 --> 20:47.000]  По историю,
[20:47.000 --> 20:48.000]  наш интеракционный
[20:48.000 --> 20:49.000]  процесс
[20:49.000 --> 20:50.000]  виду y kt
[20:50.000 --> 20:51.000]  равняется некой
[20:51.000 --> 20:52.000]  матрице
[20:52.000 --> 20:53.000]  на y k
[20:53.000 --> 20:54.000]  минус 1.
[20:54.000 --> 20:55.000]  Это,
[20:55.000 --> 20:56.000]  собственно,
[20:56.000 --> 20:57.000]  была цель.
[20:57.000 --> 20:58.000]  Дальше,
[20:58.000 --> 20:59.000]  дальше мы знаем,
[20:59.000 --> 21:00.000]  что такой
[21:00.000 --> 21:01.000]  интеракционный
[21:01.000 --> 21:02.000]  процесс сходит
[21:02.000 --> 21:03.000]  с линейной скорости
[21:03.000 --> 21:04.000]  сходимости
[21:04.000 --> 21:05.000]  пропорциональной
[21:05.000 --> 21:06.000]  спектральному радиусу
[21:06.000 --> 21:07.000]  матрицы и
[21:07.000 --> 21:08.000]  трассы.
[21:08.000 --> 21:09.000]  Все знают,
[21:09.000 --> 21:10.000]  что такое спектральный радиус.
[21:10.000 --> 21:11.000]  Ставьте плюс,
[21:11.000 --> 21:12.000]  если вы знаете,
[21:12.000 --> 21:13.000]  что такое спектральный
[21:13.000 --> 21:14.000]  радиус.
[21:14.000 --> 21:15.000]  Ага.
[21:15.000 --> 21:16.000]  То есть,
[21:16.000 --> 21:17.000]  в этой матрице
[21:17.000 --> 21:18.000]  есть определенная
[21:18.000 --> 21:19.000]  структура.
[21:19.000 --> 21:20.000]  То есть,
[21:20.000 --> 21:21.000]  она какого
[21:21.000 --> 21:22.000]  вида,
[21:22.000 --> 21:23.000]  на самом деле?
[21:23.000 --> 21:24.000]  Вот тут
[21:24.000 --> 21:25.000]  диагональ,
[21:25.000 --> 21:26.000]  тут
[21:26.000 --> 21:27.000]  диагональ,
[21:27.000 --> 21:28.000]  а вот здесь
[21:28.000 --> 21:29.000]  стоит что-то
[21:29.000 --> 21:30.000]  типа
[21:30.000 --> 21:31.000]  диагональ
[21:31.000 --> 21:32.000]  плюс
[21:32.000 --> 21:33.000]  что-то плотное.
[21:33.000 --> 21:34.000]  Ну,
[21:34.000 --> 21:35.000]  это что-то плотное.
[21:35.000 --> 21:36.000]  Мы можем,
[21:36.000 --> 21:37.000]  на самом деле,
[21:37.000 --> 21:38.000]  воспользовавшись
[21:38.000 --> 21:39.000]  теоремой в среднем,
[21:39.000 --> 21:40.000]  можем вот эту
[21:40.000 --> 21:41.000]  штуку заменить
[21:41.000 --> 21:42.000]  на десян в какой-то
[21:42.000 --> 21:43.000]  промежуточной
[21:43.000 --> 21:44.000]  точке u.
[21:44.000 --> 21:45.000]  И,
[21:45.000 --> 21:46.000]  соответственно,
[21:46.000 --> 21:47.000]  если мы ее
[21:47.000 --> 21:48.000]  ну,
[21:48.000 --> 21:49.000]  там,
[21:49.000 --> 21:50.000]  семитечно,
[21:50.000 --> 21:51.000]  все с ней понятно,
[21:51.000 --> 21:52.000]  все хорошо,
[21:52.000 --> 21:53.000]  если мы ее
[21:53.000 --> 21:54.000]  диагонализуем,
[21:54.000 --> 21:55.000]  вот,
[21:55.000 --> 21:56.000]  то окажется,
[21:56.000 --> 21:57.000]  что
[21:57.000 --> 21:58.000]  в базе
[21:58.000 --> 21:59.000]  там u,
[21:59.000 --> 22:00.000]  если вот так вот
[22:00.000 --> 22:01.000]  сделать,
[22:01.000 --> 22:02.000]  тут останется
[22:02.000 --> 22:03.000]  диагональка,
[22:03.000 --> 22:04.000]  там,
[22:04.000 --> 22:05.000]  единица плюс
[22:05.000 --> 22:06.000]  диагональка,
[22:06.000 --> 22:07.000]  тоже диагональ,
[22:07.000 --> 22:08.000]  тут ноль,
[22:08.000 --> 22:09.000]  а тут будет
[22:09.000 --> 22:10.000]  утранспонировано,
[22:10.000 --> 22:11.000]  утранспонировано.
[22:11.000 --> 22:12.000]  Что-то такое.
[22:12.000 --> 22:13.000]  Тут,
[22:13.000 --> 22:14.000]  ну,
[22:14.000 --> 22:15.000]  все хорошо,
[22:15.000 --> 22:16.000]  окей,
[22:16.000 --> 22:17.000]  вроде понятно,
[22:17.000 --> 22:18.000]  это хорошая новость.
[22:18.000 --> 22:19.000]  Вот,
[22:19.000 --> 22:20.000]  а дальше
[22:20.000 --> 22:21.000]  надо,
[22:21.000 --> 22:22.000]  по сути дела,
[22:22.000 --> 22:23.000]  значить силой
[22:23.000 --> 22:24.000]  в том,
[22:24.000 --> 22:25.000]  что надо оценить
[22:25.000 --> 22:26.000]  спектры,
[22:26.000 --> 22:27.000]  вот такой вот матрицы.
[22:27.000 --> 22:28.000]  Вот,
[22:28.000 --> 22:29.000]  и вот у то
[22:29.000 --> 22:30.000]  чудо,
[22:30.000 --> 22:31.000]  на самом деле,
[22:31.000 --> 22:32.000]  что
[22:32.000 --> 22:33.000]  с помощью
[22:33.000 --> 22:34.000]  некоторых перестановок
[22:34.000 --> 22:35.000]  это можно привести
[22:35.000 --> 22:36.000]  к
[22:36.000 --> 22:37.000]  матрице
[22:37.000 --> 22:38.000]  блочной
[22:38.000 --> 22:39.000]  диагональной.
[22:39.000 --> 22:40.000]  И тут матрица
[22:40.000 --> 22:41.000]  будет 2 на 2.
[22:41.000 --> 22:42.000]  Ну,
[22:42.000 --> 22:46.160]  получается, что спектр этой матрицы сводится к анализу
[22:46.160 --> 22:52.440]  спектра вот этих вот блоков, из которых там что-то сидит.
[22:52.440 --> 22:56.080]  И взяв максимальное собственное значение из этих штук и
[22:56.080 --> 22:59.560]  променивизировав его по альфа и бета, мы получим
[22:59.560 --> 23:03.320]  довольно жуткие значения, которые записываются так,
[23:03.320 --> 23:06.940]  что если у нас альфа-кате — это 4 на корень из L плюс
[23:06.940 --> 23:11.160]  корень из μ в квадрате, бета-кате — это максимум
[23:11.160 --> 23:17.640]  из 1 минус корень альфа-кате L и 1 минус корень альфа-кате
[23:17.640 --> 23:18.640]  μ.
[23:18.640 --> 23:22.560]  Ну, это, собственно, мотивирована тема, что там надо отрицательные
[23:22.560 --> 23:24.040]  и положительные все учесть.
[23:24.040 --> 23:25.040]  Это все в квадрате.
[23:25.040 --> 23:28.160]  Если коэффициент выбран так, то есть альфа-кате — это
[23:28.160 --> 23:32.480]  у нас мершага, у нас классический, бета-кате — это коэффициент
[23:32.480 --> 23:33.480]  перед...
[23:33.480 --> 23:36.640]  Коэффициент перед дополнительным слагаемом, то метод будет
[23:36.640 --> 23:37.640]  сходить сверху...
[23:37.640 --> 23:39.760]  Будет сходиться линейно с правильным коэффициентом.
[23:39.760 --> 23:44.880]  Хк плюс 1 минус х со звездочкой по норме, хк минус х со звездочкой.
[23:44.880 --> 23:47.960]  Будет меньше либрага, чем корень из ка-п минус 1 на
[23:47.960 --> 23:53.640]  корень из ка-п плюс 1 в степени k, ну, на норму того же вектора
[23:53.640 --> 23:54.640]  только...
[23:54.640 --> 23:56.400]  Так, надо написать.
[23:56.400 --> 24:00.520]  Х1 минус х со звездочкой, и тут будет х0 минус х со звездочкой.
[24:00.520 --> 24:03.520]  То есть желаемого коэффициента нам удалось добиться.
[24:03.520 --> 24:06.120]  Понятны ли понятия на результаты?
[24:06.120 --> 24:08.560]  Поставьте плюс или результат понятия на минус, если не
[24:08.560 --> 24:09.560]  понятен.
[24:09.760 --> 24:12.760]  Так, ну, каких-то вопросов вроде пока нет явных.
[24:12.760 --> 24:14.960]  Так, надо показать картинку.
[24:14.960 --> 24:16.360]  Это все добро сходится.
[24:16.360 --> 24:18.880]  Сейчас секундочку я все подготовлю.
[24:18.880 --> 24:19.880]  Тут стоп шер.
[24:19.880 --> 24:20.880]  Так вот.
[24:20.880 --> 24:23.720]  Ну, короче говоря, вот взяли случайную квадратичную
[24:23.720 --> 24:24.720]  задачу.
[24:24.720 --> 24:25.720]  Вот.
[24:25.720 --> 24:29.680]  И поскольку для квадратичной задачи у нас l и μ соответствуют
[24:29.680 --> 24:33.240]  максимальному и минимальному значению матрицы, то мы
[24:33.240 --> 24:35.160]  можем явно посчитать оптимальные параметры.
[24:35.160 --> 24:36.160]  Вот.
[24:36.160 --> 24:38.600]  И оказывается, что вот так будет сходиться градиентный
[24:38.600 --> 24:39.600]  спуск.
[24:39.600 --> 24:40.600]  Пока на зеленую не смотрите.
[24:40.600 --> 24:42.600]  Вот так будет сходиться градиентный спуск почти
[24:42.600 --> 24:45.600]  что сублинеида, потому что, в общем, число бусловности
[24:45.600 --> 24:46.600]  достаточно большое.
[24:46.600 --> 24:49.600]  И за 5000 терраций всего лишь 10-1 сойдется.
[24:49.600 --> 24:54.600]  В то же время тяжелый шарик сошелся в 10-5 за почти 4000
[24:54.600 --> 24:55.600]  терраций.
[24:55.600 --> 24:56.600]  Вот.
[24:56.600 --> 24:59.840]  То есть оцените, насколько быстрее стало все работать
[24:59.840 --> 25:02.600]  только из-за того, что мы добавили дополнительное
[25:02.600 --> 25:03.600]  наслагаемое.
[25:03.600 --> 25:04.600]  Вот.
[25:04.600 --> 25:07.600]  При этом вроде кажется, что монотонность есть.
[25:08.600 --> 25:10.600]  Норма градиента монотонного бывает.
[25:10.600 --> 25:12.600]  Однако же, если внимательно присмотреться, то вот здесь
[25:12.600 --> 25:15.600]  в самом начале у него есть небольшой интервал, когда
[25:15.600 --> 25:18.600]  его там монотонно осцилирует, и уже такой строгой монотонности
[25:18.600 --> 25:20.600]  как градиентного спуска нет.
[25:20.600 --> 25:21.600]  Вот.
[25:21.600 --> 25:25.600]  Поэтому, в общем, если параметры не удаются найти оптимальные,
[25:25.600 --> 25:29.600]  это довольно часто случается, то обычно бету выбирают
[25:29.600 --> 25:31.600]  близко к единице, типа 0,8-0,9.
[25:31.600 --> 25:32.600]  Вот.
[25:32.600 --> 25:36.600]  А альфу выбирают исходя из масштаба задачи и того.
[25:36.600 --> 25:39.600]  В общем, в какой там масштаб ничего в голову не приходит.
[25:39.600 --> 25:44.600]  То есть там 10-3, 10-2 типичные значения, для которых более
[25:44.600 --> 25:45.600]  или менее все работает.
[25:45.600 --> 25:46.600]  А можно вопрос?
[25:46.600 --> 25:47.600]  А нельзя?
[25:47.600 --> 25:49.600]  Просто, ну, потому что получается градиентный спуск, ну,
[25:49.600 --> 25:51.600]  в начале эффективнее, пока мы видим.
[25:51.600 --> 25:54.600]  Нельзя сначала делать градиентный спуск без вот этого
[25:54.600 --> 25:57.600]  дополнительного наслагаемого с весом, ну, с…
[25:57.600 --> 25:59.600]  А непонятно, когда переключаться.
[25:59.600 --> 26:03.600]  Когда у нас, ну, уменьшается приращение, ну, ниже какого-то
[26:03.600 --> 26:04.600]  рога.
[26:04.600 --> 26:07.600]  А у нас шаг дает эффективность, ну, уменьшение нормы…
[26:07.600 --> 26:10.600]  уменьшение нормы между последовательными вот
[26:10.600 --> 26:13.600]  иксами меньше, чем во сколько-то раз.
[26:13.600 --> 26:14.600]  Или меньше, чем на сколько.
[26:14.600 --> 26:16.600]  Да, ну, просто во сколько это раз – это непонятно.
[26:16.600 --> 26:18.600]  Вы это сложно точно оценить, потому что у вас всех
[26:18.600 --> 26:21.600]  этих констант нет, которые участвуют в оценках в этом
[26:21.600 --> 26:22.600]  проблемах.
[26:22.600 --> 26:24.600]  То есть вы можете там грубо говоря поставить какую-то
[26:24.600 --> 26:26.600]  рандомную чиселку и надеяться, что когда-нибудь она будет
[26:26.600 --> 26:27.600]  выполняться.
[26:27.600 --> 26:29.600]  Но гарантий вам никто не даст.
[26:29.600 --> 26:31.600]  Ну, в общем случае, для произвольной задачи.
[26:31.600 --> 26:33.600]  Поэтому, да, конечно, есть свои проблемы.
[26:33.600 --> 26:36.600]  Это была картинка для тяжелого шарика.
[26:36.600 --> 26:37.600]  Теперь едем дальше.
[26:37.600 --> 26:40.600]  И посмотрим, посмотрим на, собственно, быстрый грядентный
[26:40.600 --> 26:43.600]  метод, который, который достигает оптимальных оценок
[26:43.600 --> 26:46.600]  как для сильного пуклого случая, который здесь уже
[26:46.600 --> 26:47.600]  был упомянут.
[26:47.600 --> 26:50.600]  И для просто эль гладкого выпуклого.
[26:50.600 --> 26:52.600]  Так, быстрый метод.
[26:52.600 --> 26:57.600]  Это Юрий Евгеньевич Нестеров, 983.
[26:57.600 --> 26:58.600]  Статья доступна.
[26:58.600 --> 27:00.600]  Статья доступна тоже в открытом доступе, вы можете
[27:00.600 --> 27:01.600]  ознакомиться.
[27:01.600 --> 27:04.600]  Один из вариантов его формулировки.
[27:04.600 --> 27:08.600]  Не самый, может быть, точный, но как минимум самый
[27:08.600 --> 27:11.600]  понятный для того, чтобы, наверное, интуицию какую-то
[27:11.600 --> 27:12.600]  развить.
[27:12.600 --> 27:13.600]  Такой.
[27:13.600 --> 27:15.600]  Вводим дополнительную последовательность.
[27:15.600 --> 27:17.600]  Помимо х ноль, у нас будет еще у ноль.
[27:17.600 --> 27:20.600]  Значит, х ка плюс первый у нас теперь пересчитывается
[27:20.600 --> 27:21.600]  вот таким вот образом.
[27:21.600 --> 27:23.600]  У пересчитывает на основе почитанных х.
[27:23.600 --> 27:26.600]  То есть сейчас надо внимательно посмотреть на эти выражения
[27:26.600 --> 27:30.600]  и сказать, чем они принципиально отличаются от того, что
[27:30.600 --> 27:32.600]  было в тяжелом шарике на предыдущей странице.
[27:32.600 --> 27:35.600]  Если вы помните формулу, там она в деле очевидна.
[27:35.600 --> 27:38.600]  Что существенно образом изменилось в сравнении
[27:38.600 --> 27:39.600]  с тяжелым шариком?
[27:39.600 --> 27:40.600]  Какие будут версии?
[27:40.600 --> 27:42.600]  Мне кажется, теперь даже трех-шаговая.
[27:42.600 --> 27:44.600]  Ну, если считать, что у нас шаговая.
[27:44.600 --> 27:45.600]  Почему?
[27:45.600 --> 27:47.600]  Если у и х объединяются в одну последовательность,
[27:47.600 --> 27:49.600]  то нам нужно знать и предыдущий.
[27:49.600 --> 27:53.600]  Нам для подсчета у ка плюс первого нужно знать и
[27:53.600 --> 27:55.600]  х ка плюс первый и х ка.
[27:55.600 --> 27:57.600]  А значит, это уже три предыдущих членов,
[27:57.600 --> 27:59.600]  потому что между ними еще и у ка.
[27:59.600 --> 28:02.600]  Не, ну то, что надо сохранять три вектора, это правда.
[28:02.600 --> 28:05.600]  Но в истории мы идем по-прежнему только на один шаг назад.
[28:05.600 --> 28:07.600]  То есть шаги, сколько в истории,
[28:07.600 --> 28:09.600]  как далеко в истории мы идем,
[28:09.600 --> 28:11.600]  а не то, сколько вторых мы храним.
[28:11.600 --> 28:13.600]  У нас история состоит из чередующихся у и х.
[28:13.600 --> 28:15.600]  И нам нужно три последних элемента истории,
[28:15.600 --> 28:17.600]  чтобы насчитать следующий.
[28:17.600 --> 28:18.600]  Нет, еще раз.
[28:18.600 --> 28:21.600]  История это история индексировать с номером интераций.
[28:21.600 --> 28:23.600]  А не тем, сколько элементов вы храните.
[28:23.600 --> 28:26.600]  А, то есть считается, что мы на одной итерации насчитываем и х и у.
[28:26.600 --> 28:27.600]  Ну, написано же.
[28:27.600 --> 28:30.600]  Ну, в плане, просто у нас два пересчета,
[28:30.600 --> 28:32.600]  логично их склеить, ну, последовательно,
[28:32.600 --> 28:36.600]  что на чётных итерациях пересчитываем х и на ничётных у.
[28:36.600 --> 28:38.600]  Погодите, вы видите, что тут х ка плюс один написано?
[28:38.600 --> 28:39.600]  Там и там.
[28:39.600 --> 28:40.600]  Да, да, да, да.
[28:40.600 --> 28:43.600]  Ну, индексы, да, но просто у нас два индекса появилось,
[28:43.600 --> 28:44.600]  две последовательности.
[28:44.600 --> 28:46.600]  А мы раньше работали с одной, логично склеить.
[28:46.600 --> 28:49.600]  Ну, и они склеиваются в одну итерацию, наверное.
[28:49.600 --> 28:51.600]  Так, в чём разница-то с тяжёлым шариком?
[28:51.600 --> 28:53.600]  Ну, да, появилась последовательность, окей.
[28:53.600 --> 28:55.600]  Ну, в тяжёлом шарике мы тоже могли в общем-то вести эту последовательность,
[28:55.600 --> 28:57.600]  просто сказав, что вот это у нас типа игрит.
[28:57.600 --> 28:58.600]  А вот ещё одно последовательство.
[28:58.600 --> 29:01.600]  Кто внимательно смотрит на формулы?
[29:01.600 --> 29:04.600]  Ну, кажется, что особо никто не смотрит на формулы внимательно.
[29:04.600 --> 29:05.600]  Ладно, смотрите, в чём дело.
[29:05.600 --> 29:09.600]  В тяжёлом шарике главное, конечно же, происходит вот в этой строчке,
[29:09.600 --> 29:16.600]  потому что здесь получается так, что мы вычисляем градиент
[29:16.600 --> 29:21.600]  точки отличной от той точки у нас… точки той последовательности,
[29:21.600 --> 29:22.600]  которую мы получаем.
[29:22.600 --> 29:25.600]  То есть здесь, хоть у нас и была какая-то последовательность y, k, t,
[29:25.600 --> 29:28.600]  мы всё равно считали градиент в текущей точке –
[29:28.600 --> 29:30.600]  того, чтобы получить следующую.
[29:30.600 --> 29:33.600]  Здесь мы как будто бы эти две последовательности,
[29:33.600 --> 29:35.600]  они друг с другом как-бы перемinnно пересчитываются.
[29:35.600 --> 29:38.600]  И получается, что для того, чтобы посчитать следующий x,
[29:38.600 --> 29:41.600]  нужно посчитать градиент в другой совсем точке,
[29:41.600 --> 29:42.600]  точке другой последовательности.
[29:42.600 --> 29:45.600]  То есть, еслиoa рисовать картинку, то она будет выглядеть вот так.
[29:45.600 --> 29:51.640]  сейчас я хочу оставить формулы, типа пусть это был x0 равный y0, мы пересчитали вот сюда,
[29:51.640 --> 30:00.880]  получили x1, вот дальше мы берем и из x1 идем немножко вперед, немножко вот сюда, это будет наш,
[30:00.880 --> 30:06.720]  давайте я другим цветом сделаю, это будет наш y1, относительно y1 мы делаем градиентный шаг,
[30:06.720 --> 30:13.880]  получаем здесь x2, затем на вот этой вот линии мы получаем y2, и дальше из y2 мы куда-то там идем,
[30:13.880 --> 30:19.880]  чтобы потом получить x3, x3 и тут получить y3, понятно ли как теперь выглядит траектория,
[30:19.880 --> 30:25.960]  ставьте плюс если понятно, вижу пока два плюса, неплохо, вроде вопросов пока таких нет по поводу
[30:25.960 --> 30:31.720]  того что происходит, вот и значит оказывается, что вот такая стратегия, она более общая,
[30:31.720 --> 30:37.120]  скажем так, то есть она работает хорошо для не только сильно выпуклых функций, но и для просто
[30:37.120 --> 30:43.200]  l гладкий, при этом почему вот здесь вот тройка, вот давайте я просто сейчас статью пришлю в чат,
[30:43.200 --> 30:50.160]  чтобы если будет интересно почитать, там короче целый раздел про магическую константу тройка,
[30:50.160 --> 30:55.680]  и почему туда можно поставить что-то больше тройки, но нельзя поставить ничего меньше тройки, вот,
[30:55.680 --> 31:02.920]  с это все основывается на устойчивости некоторых соответствующих дифференциальных уравнений,
[31:02.920 --> 31:09.680]  вот и так это уже на счет ремонт, ну да сход не нашлось, ладно, я после лекции тогда пришлю
[31:09.680 --> 31:16.240]  в стулчику, вот, и заодно дальше с мешотом покажу как это устроено, в общем, почему здесь тройка,
[31:16.240 --> 31:21.440]  отдельная история, но тройка работает достаточно неплохо, вот, и то что вот эта вот последовательность
[31:21.440 --> 31:28.960]  она стремится к единичке, вот, тоже как бы достаточно разумно оказывается, так, значит этот метод
[31:28.960 --> 31:34.780]  по-прежнему, так как мы назвали двухшаговый, да, но он стремится к вектору, вот, плюс он также не
[31:34.780 --> 31:40.560]  монотонный, мы сейчас увидим насколько он не монотонный, вот, и ему также соответствуют некоторые
[31:40.560 --> 31:47.720]  специальные уравнения второго порядка, вот, изучение которого можно понять, что происходит
[31:47.720 --> 31:56.480]  с самим методом, вот, так, картинка видимости, обязательно надо показать, да, вот как это выглядит,
[31:56.480 --> 32:02.480]  на той же самой задаче. Тут, короче, нас интересует сейчас красная линия, видно, что вот у нее такие вот
[32:02.480 --> 32:11.520]  называются... Зигзаг... Зигзагообразные, забыл, секунду. В общем, типа похоже на зыбь,
[32:11.520 --> 32:18.440]  вот, скучкообразные траектории, вот, это, значит, если вы такое наблюдаете, значит, у вас, скорее
[32:18.440 --> 32:23.760]  всего, все правильно реализовали и все работает, вот, не надо пугаться, что он не монотонный, это уже
[32:23.760 --> 32:31.960]  как-то встроено в структуру самого метода, и это нормально, вот. Интересно, что вот здесь работает быстрее,
[32:31.960 --> 32:38.880]  чем все, что мы до этого обсуждали, доходит где-то до 10-3, там, 10-4, начинают все эти ассоциации,
[32:38.880 --> 32:46.120]  и на них его догоняет тяжелый шаг, вот. Понятно, что вот в этой точке хочется сделать какую-то
[32:46.120 --> 32:52.080]  штуку, так чтобы он шел не вот сюда, а шел еще дальше вниз. Как вы думаете, каким образом это можно
[32:52.080 --> 32:56.440]  проделать? Ну, то есть, грубо говоря, понять, что в этой точке мы начали возрастать, можно.
[32:56.440 --> 33:00.720]  Просто значение функции посчитали, или там норма градиента, увидели, что, а, тут мы типа,
[33:00.720 --> 33:06.000]  у нас увеличивается. Давайте мы что-нибудь сделаем так, чтобы не ходить в эту точку, а ходить в другую
[33:06.000 --> 33:11.720]  точку. Вопрос, как вы думаете, каким образом это можно сделать? Ну, будем идти по антиградиенту,
[33:11.720 --> 33:18.000]  или там, возьмем Xкат, и с минусом, ну, короче, добавим минус вот где-то в пересчет. Да, ну,
[33:18.000 --> 33:25.440]  то есть, наверное, я, кстати, не уверен, что взять просто противоположное направление, оно, так, ну,
[33:25.440 --> 33:33.040]  для функции-то оно может сработать, но для градиента не уверен. Неважно пока что. Важно другое. Важно,
[33:33.040 --> 33:39.760]  что можно взять просто антиградиент, вы правы. Вот. И это в каком-то смысле будет означать то,
[33:39.760 --> 33:45.760]  что мы взяли и забыли всю вашу историю, сделали просто restart. Вот из этой точки запустили наш метод,
[33:45.760 --> 33:51.800]  как будто у нас не было предыдущей истории, никакой никаких Y мы не копили. И из этой точки
[33:51.800 --> 33:56.000]  запустить restart, и он пойдет благополучно ниже. И сойдется, ну, за какое-то разумное время,
[33:56.000 --> 34:00.680]  ну, то есть, вот этого уже не будет. Будет, ну, то есть, он сделает шаг, потом, возможно,
[34:00.680 --> 34:07.240]  снова, значит, попытается начать вот эти вот волнообразные какие-то движения. Вот. И они
[34:07.240 --> 34:12.960]  также могут гаситься тем же самым техникой restart. Вот. То есть, это довольно продуктивная история,
[34:12.960 --> 34:18.600]  которая, в общем, 5-6 лет назад была показана, и там, как бы, все довольно неплохо работает.
[34:18.600 --> 34:22.440]  Поэтому, в общем, этого пугаться не надо. Это все, все с этим, это была картинка. Теперь,
[34:22.440 --> 34:27.600]  собственно, сходимость надо сформулировать. Здесь 0,7. Очень хорошо. Вот. Ну, и результаты
[34:27.600 --> 34:35.560]  сходимости тоже достаточно, достаточно понятные, то есть, для сходимости. Для L-гладких выпуклых
[34:35.560 --> 34:42.280]  будет единица на, как, квадрат, собственно. Для мио-сильно выпуклых, там, L-гладких тоже.
[34:42.280 --> 34:47.920]  Будет Q линейная сходимость с нужным коэффициентом. Вот. То есть, метод на самом деле является оптимальным
[34:47.920 --> 34:54.800]  в контексте использования нижних оценок, вот, о котором мы до этого обсуждали. Вот. Значит,
[34:54.800 --> 35:02.320]  вот эти два метода, они очень здорово укладываются во всю эту довольно красивую теорию. Вот. И,
[35:02.320 --> 35:08.280]  значит, довольно, довольно активно используется на практике. Теперь еще есть один метод,
[35:08.280 --> 35:12.840]  называется метод сопряженных градиентов, за который мне нужно вам рассказать за, типа,
[35:12.840 --> 35:19.040]  10 минут. Ну ладно, я пытаюсь. Вот. Значит, изначально он был разработан для решения задачи вот таких,
[35:19.040 --> 35:25.320]  которые сводятся к решению системы линейных уравнений. Вот. Про него там много теорий придумали,
[35:25.320 --> 35:30.760]  там, результаты сходимости прекрасные. Вот. Но интересно друг, интересно то, как он обобщается
[35:30.760 --> 35:37.400]  на нелинейные случаи. Вот. На нелинейные случаи он обобщается очень похожим образом на те методы,
[35:37.400 --> 35:44.640]  которые мы только что обсудили. Вот. Единственное, что для него нет таких хороших оценок, потому что,
[35:44.640 --> 35:49.560]  в общем, почему сейчас я пытаюсь объяснить. То есть, как он работает? Он берет и говорит,
[35:49.560 --> 36:00.520]  что мы возьмем и будем строить хк плюс первый, как х0 плюс хкт плюс альфкт и пкт. Вот. А пкт у
[36:00.520 --> 36:07.800]  нас будет, ну там понятно, по нолю равен минус градиент. Вот. А пкт будет равно минус, ну там,
[36:07.800 --> 36:14.520]  пкт плюс первый. Минус пкт плюс, так, неправильно. Минус градиент в новые точки, вот так правильно.
[36:14.520 --> 36:21.560]  Все, я мельчу, это плохо, ничего не видно. Так, минус. Берем то же самое направление антиградиента,
[36:21.560 --> 36:26.920]  которое было в грядном спуске, плюс бета катое на пкт. Отправляем его в предыдущем направлении. Вот.
[36:26.920 --> 36:31.880]  То есть, концепция очень похожа на тяжелую шарику, в самом деле. Только здесь альф и бета немножко
[36:31.880 --> 36:36.720]  другую роль выполняют. То есть, если в тяжелом шарике у нас бета подправляла итоговое направление,
[36:36.720 --> 36:42.440]  то здесь у нас итоговое направление генерируется через бету, а шаг альф выделяется в отдельную,
[36:42.440 --> 36:48.200]  как бы, историю. Значит, что делать, когда, то есть, для вот этой задачи там есть отдельное выражение
[36:48.200 --> 36:54.440]  для альфа и бета замкнув виде, но нас интересует, понятное дело, не такие задачи, а задачи более
[36:54.440 --> 36:59.480]  общего вида, пока что, вот такие. Вот. И что делать с альфы и бетой? Ну, вот альфа катое делают
[36:59.480 --> 37:04.640]  просто адаптивный поиск. Правила армии, там, вот эта вся история. Я надеюсь, что на семинарах у вас
[37:04.640 --> 37:08.040]  в том или ином виде это уже было. Поставьте пилотики, если у вас уже все это было на семинарах.
[37:08.040 --> 37:13.040]  Интересно, кстати, вы все знаете. Так, вот было все, да. И минус, если не было. И минус более
[37:13.040 --> 37:18.240]  интересный. Наличие. Ага. Что не было? Чего не было? Адаптивного поиска или... Ничего. Ладно,
[37:18.240 --> 37:23.000]  я тогда сейчас ничего расскажу про адаптивный поиск, как раз в своем есть. Значит... Да, адаптивного
[37:23.000 --> 37:27.680]  поиска не было. Хорошо. Значит, альфа катое делается адаптивным поиском каким-то. То есть,
[37:27.680 --> 37:33.560]  подстраивается под текущие направления, точку и градиент. Вот бета катое, оно пересчитывается,
[37:33.560 --> 37:39.040]  может пересчитываться разными способами. Вот. Например, можно брать для каждого способа, типа,
[37:39.040 --> 37:45.160]  свой именной метод. Ну, что-то типа такого. Называется метод Fletcher-Reeves. Fletcher-Reeves.
[37:45.160 --> 37:53.320]  Если бета катое вот такое... Сейчас, секунду. Всегда я плохо помню фото. F'x-k-1. А здесь, типа,
[37:53.320 --> 37:58.640]  разность. Деленно. Опять же, на норму. Вот. Это метод полукарибьера. Два разных человека. Вот.
[37:58.640 --> 38:05.160]  Там еще есть хестенс-фестиваля. Ну, короче, там зоопарк этих всех способов выбрать бетла. Вот.
[38:05.160 --> 38:11.280]  Почему это интересно? Потому что все это вы можете обнаружить в тайфай, который метод спряженных
[38:11.280 --> 38:17.360]  градиентов как раз-таки версии полукарибьера используют. Я постараюсь показать. Пам-пам-пам.
[38:17.360 --> 38:22.280]  Зону потерял. Ну вот. Так, то есть, вот если вы посмотрите в документации, то тут будет понятно
[38:22.280 --> 38:28.840]  метод спряженных градиентов conjugate gradient CG. Вот. И... А, это я сюда зря перешел. Вот. И если
[38:28.840 --> 38:33.760]  почитать детали про то, что там реализовано внутри, вот, то он тут вам напишет, что вот, типа,
[38:33.760 --> 38:40.320]  полукарибьер. Вот. В общем, метод Fletcher-Reeves можно в литературе посмотреть. Наверное,
[38:40.320 --> 38:51.600]  это на Сидаль Райт. Вот. Мы обсудим в дальнейшем, что такое FGS, Newton CG и LBFGS без вот этого
[38:51.600 --> 38:57.680]  вот дополнения. Вот, что оно значит, я тоже расскажу. Вот. И в целом кратко, может быть,
[38:57.680 --> 39:04.880]  перечислим то, почему это что за trust. Так, что это за приписка, зачем она нужна. Вот. Все остальное
[39:04.880 --> 39:12.120]  останется вне курса, потому что, ну, что это называется, не так, чтобы хорошо работает,
[39:12.120 --> 39:18.560]  в каком-то смысле. Вот. Ну, то есть, вот эта штука, это, типа, эти безградентные методы. Мы про них
[39:18.560 --> 39:23.280]  немножко поговорим, но это супер какая-то базовая история, которая сейчас где-то может применять,
[39:23.280 --> 39:31.360]  но не так, чтобы супер активна. Вот. Все остальное, оно решает невыпуклые задачи. Вот. Информация
[39:31.360 --> 39:35.440]  об ограничении. Ну, в общем, для этого, скорее всего, существуют более эффективные методы. То есть,
[39:35.440 --> 39:39.280]  тут, как бы, некоторые baseline есть. Вы можете им при необходимости воспользоваться, но детально
[39:39.280 --> 39:42.840]  погружаться в то, почему это работает, наверное, сейчас. Вот. Единственное, что вот эта вот штука,
[39:42.840 --> 39:50.280]  довольно неплохая концепция про, сейчас я себя правильно помню, self-sequential squares. Да. Вот.
[39:50.280 --> 39:56.200]  Может быть, про это немножко еще поговорим. Ладно. Короче, CG, классная штука. Хорошо работает,
[39:57.200 --> 40:02.560]  вот. И я что-то еще хотел показать. А, я хотел бы рассказать про адаптивный поиск. Вот. Ну,
[40:02.560 --> 40:09.440]  адаптивный поиск или еще так называемый backtracking основан на следующей простой идее. Вот. Мы хотим в
[40:09.440 --> 40:14.280]  данном случае, чтобы наше значение функции в новой точке все-таки было меньше. Вот. В этих
[40:14.280 --> 40:18.840]  ускоренных методах мы его, как бы, как бы, получно забыли про него. Здесь все-таки хочется как-то,
[40:18.840 --> 40:25.720]  ну, чтобы было вот так. Ну, наивный самый. Нулевая попытка. Это что такое? Ну, мы берем и говорим,
[40:25.720 --> 40:32.840]  что слева у нас стоит f от xk плюс альфа кт пкт. Пкт же, да? Пкт. Вот. И мы хотим,
[40:32.840 --> 40:39.520]  чтобы эта штука была меньше tмf от xkt. Вот. Ну, то есть как? Мы берем, запускаем цикл, и если вот это
[40:39.520 --> 40:46.440]  нарушается, то альфа делим пополам, например. Или там умножаем на 0.3, на 0.1. До тех пор, пока мы не
[40:46.440 --> 40:51.080]  достаточно уменьшим здесь шаг, чтобы это направление, которое там, оказывается, что локальному
[40:51.680 --> 40:58.200]  все-таки будет, чтобы оно уменьшило значение функций. Это первое такое, нулевое приближение. Вот.
[40:58.200 --> 41:02.160]  Первое приближение, которое, в общем-то, в большинстве случаев используется, что они в большинстве,
[41:02.160 --> 41:09.920]  но хороший такой solid baseline называется. Это искать такую альфа, что будет не только меньше, чем f от
[41:09.920 --> 41:19.720]  xkt, но меньше, чем f от xkt, а плюс бета кт на скалярное произведение градиента с кт. И тут еще умножить
[41:19.720 --> 41:25.800]  на альфа кт. Эта штука меньше нуля, поэтому у нас слева знака не равен сосредоточительной функции,
[41:25.800 --> 41:29.920]  довольно странная. Справа у нас стоит линейная функция по альфе. Поэтому если строить картинку,
[41:29.920 --> 41:34.520]  тут будет f от альфы, который вот здесь вот. Вот здесь будет 0, это наша f от xkt. То есть,
[41:34.520 --> 41:39.400]  если мы нарисуем картинку выражения, которая находится вот здесь, то это, типа, какая-то
[41:39.400 --> 41:45.720]  прямая с отрицательным коэффициентом наклона. Вот. А то, что стоит слева, это что-то вот, типа,
[41:45.720 --> 41:51.160]  локально, которое бывает, что оно может быть локально вот так. Тут вот у него что-то с ним
[41:51.160 --> 41:56.800]  происходит. И вот нам нужно выбрать альфы, которые лежат, соответственно, вот тут, тут, тут. То есть,
[41:56.800 --> 42:01.880]  нужно попасть в какой-то, знаете, интервал. Ой, что-то я... Что-то такое. Вот. При этом понятно,
[42:01.880 --> 42:08.040]  что если мы с бетой промахнемся, может получиться ровно вот такая вот история, когда мы поуменьшились
[42:08.040 --> 42:13.240]  вот досюда и все равно оказались выше. А может, промахнулись беты. Вот. Поэтому обычно беты берут
[42:13.240 --> 42:18.720]  достаточно маленькой, типа, около 0.1. Вот. Ну и так атеративно пересчитывают альфы,
[42:18.720 --> 42:22.840]  пока не будет выполнено этого условия. Так. Понятно ли, что это за метод? Ставьте плюс,
[42:22.840 --> 42:27.360]  если понятно, и минус, если непонятно. Но при этом понятно, что если у вас там функция фигурирует
[42:27.360 --> 42:32.840]  какой-нибудь логариф, например, у вас f от x, типа, сумма, помню, там, логариф, мот, v и t минус,
[42:32.840 --> 42:38.800]  a транспонированная, и t x. Надо учитывать, чтобы у вас шаг был достаточно маленьким,
[42:38.800 --> 42:42.720]  чтобы вы за области определения не вышли. Тут, как бы, в процессе конкретизации для
[42:42.720 --> 42:47.360]  каждой конкретной задачи нарешивают еще это плотное условие, чтобы вы оставались в области
[42:47.360 --> 42:54.240]  определения. Пока только один плюс. Дмитрий, а вам непонятно, или как, или понятно, пока еще
[42:54.240 --> 42:58.920]  не поставили плюс, или есть какие-то вопросы? Все понятно. Окей. Просов нет. Ага. Хорошо. Спасибо.
[42:58.920 --> 43:04.320]  Ну, в общем, да, 10 и 20. Давайте на сегодня тогда закончим. В следующий раз мы посмотрим
[43:04.320 --> 43:08.960]  настокофические методы и поймем, что происходит со всеми этими прекрасными результатами про
[43:08.960 --> 43:14.880]  ускорение, когда у вас градиент не точен. Анонс. Что происходит при неточном градиенте. Вот. Надеюсь,
[43:14.880 --> 43:19.520]  как это удалось, настоятельно образом заинтриговать, чтобы вы в следующий раз тоже
[43:19.520 --> 43:25.120]  подключились, и мы бы с вами рассмотрели такие посмотки знаешь, когда градиент точно
[43:25.120 --> 43:29.760]  посчитать не получает. Ладно, всем большое спасибо за внимание. Извините, а может, пожалуйста,
[43:29.760 --> 43:36.520]  пока мы не закончили, показать еще раз постановку метода соображенных градиентов? Ну вот.
[43:36.520 --> 43:41.440]  То есть я говорю, тяжелый шарик, только коэффицианты другие. Ну, другой ролик играет. Да, спасибо. Вот так.
[43:41.440 --> 43:47.920]  Ну, я запись-то выложу все равно сейчас в чат, в общем, если что-то забыли, не успели переписать,
[43:47.920 --> 43:48.400]  ничего страшного.
