[00:00.000 --> 00:11.120]  У нас сегодня будет не меньше одной и не больше двух лекций. Я пытался компенсировать четвертые и
[00:11.120 --> 00:16.160]  восемнадцатое, но восемнадцатое может еще не придется компенсировать, может восемнадцатое будет
[00:16.160 --> 00:21.800]  нормальная лекция. В общем, я хочу, как я уже тут объявил, разбить традицию этого семестра,
[00:21.800 --> 00:27.520]  когда какая-то сложная сумма, как мне сказали, вводится в конце лекции, а уже подсчитывается
[00:27.520 --> 00:34.680]  на следующий. Я постараюсь дойти до какого-то катарсиса и на этом остановиться. Но пока мы эту
[00:34.680 --> 00:40.720]  традицию не разбили, то есть прошлая эта лекция закончилась, если не суммой, то некой случайной
[00:40.720 --> 00:47.960]  величиной. И нам вообще бы вспомнить, что мы с вами доказываем. Давайте я вот здесь, во-первых,
[00:47.960 --> 01:01.240]  сформулирую теорему, которую мы доказываем. Это теорема Балабаша. Так, ну, Балабаша тут
[01:01.240 --> 01:09.760]  просклонял я эту фамилию, то есть это не в именительном падеже, а в родительном. Так,
[01:09.760 --> 01:17.320]  теорема Балабаша утверждает, что если вероятность ребра случайного графа ведет себя как n в степени
[01:17.320 --> 01:25.000]  минус альфа и альфа больше пяти шестых, то асимпатически, то существует такое у,
[01:25.000 --> 01:34.040]  зависище только от n и от альфа, что асимпатически почти, наверное, хроматическое число случайного
[01:34.040 --> 01:43.240]  графа принадлежит множеству у, у плюс один, у плюс два и у плюс три. Такой вот совершенно
[01:43.440 --> 01:48.200]  замечательный результат. Но мы довольно сильно продвинулись в его доказательстве. У нас есть
[01:48.200 --> 01:59.680]  лемма, которая утверждает, что в тех же условиях следующая вероятность достаточно велика. Так,
[01:59.680 --> 02:06.120]  нет, наверное, для любого лучше писать. Мы ее оценивали сверху, когда существует. А писать надо
[02:06.120 --> 02:17.040]  для любого. Вероятность того, что для любого s, мощность которого не больше, чем корень из n на
[02:17.040 --> 02:27.240]  логариф mn, хроматическое число g, ограниченного на s, не больше тройки. Вот эта вероятность не
[02:27.240 --> 02:36.200]  меньше, чем один минус один поделить на логариф mn. Ну, конечно, начиная с какого-то нулевого,
[02:36.200 --> 02:43.560]  но я надеюсь, это вы как-то осознаете, помните. Дальше мы, собственно, начали доказывать теорему,
[02:43.560 --> 02:52.520]  и мы ввели определение вот этого у. Определение было неявное, мы сказали у, это минимальное,
[02:52.520 --> 03:01.400]  да, конечно, у это минимальное у, это будет не очень хорошо так написать. В общем, это минимальное
[03:01.400 --> 03:09.840]  такое число, что вероятность хроматического числа случайного графа вот в этой нашей
[03:09.840 --> 03:16.600]  ситуации, фиксированного альфа, для фиксированного n достаточно большого, вероятность которой это все
[03:16.600 --> 03:27.520]  еще так. Как там это было у нас? Больше либо равняется у? Нет, сейчас, меньше либо равняется? Меньше,
[03:27.520 --> 03:35.680]  да? Меньше, конечно, да. А вот здесь больше, да? Больше, чем один поделить на логариф mn. Вот так,
[03:35.680 --> 03:41.280]  вот так. Ну, это вы можете посмотреть в предыдущей лекции. В частности, из этого сразу, конечно,
[03:41.280 --> 03:48.360]  следовало, из минимальности такого у следовало, что, наоборот, вероятность, с которой хиадже больше
[03:48.360 --> 04:01.120]  либо равняется того же самого у, больше, чем один минус один на логариф mn. Правильно? Больше,
[04:01.120 --> 04:08.800]  строго, но уже вот этой разности. Именно в таком определении. Вот, для нас принципиально вот это
[04:08.800 --> 04:17.040]  лемма, для нас принципиально вот это утверждение, и дальше там появилась такая хитрая случайная
[04:17.040 --> 04:24.760]  величина, которая вроде как обозначалась у, зависела, конечно, от графа, и определялась как
[04:24.760 --> 04:38.040]  минимальное число k. k, да, оно обозначалось. Хочется сохранять обозначение такое, что существует w из
[04:38.040 --> 04:52.240]  w. А, здесь было s, да? А, w было заменено на s. Да, да, вот это. Понял, да. Конечно, вот оно s, и вот оно
[04:52.240 --> 04:58.480]  s. Ну, так гораздо удобнее, да, это правильно. Это мне из аудитории подсказали. Так, я не вижу никакого
[04:58.480 --> 05:04.920]  чата, но если, в принципе, если есть желание писать в чат, можно через вас транслировать.
[05:04.920 --> 05:10.080]  Не обязательно, чтобы я смотрел, если вдруг вопросы возникают, что-то непонятно надо задавать.
[05:10.080 --> 05:22.800]  Минимальное такое k, что существует s мощности k, такое, что hi от g, ограниченного на v-s,
[05:22.800 --> 05:30.600]  меньше ли обровняется u. Вот такая вот хитрая штука. Но я в конце прошлой лекции уже комментировал
[05:30.600 --> 05:37.080]  вообще всю идею доказательств. Там должно было быть понятно, к чему дело идет. Наша задача каким-то
[05:37.080 --> 05:44.520]  образом оценить математическое ожидание у и воспользоваться концентрацией мер, но более
[05:44.520 --> 05:50.520]  мощной, чем та, которая вытекает из Чебышовского неравенства. Вот это, наверное, придется сейчас
[05:50.520 --> 05:57.960]  здесь тоже как-то напомнить. Что у нас было? У нас было такое дело. Давайте, прежде чем дело,
[05:58.840 --> 06:06.320]  попробуем понять, а у, она Липшицева или нет? Ну, конечно, опять же, могли за полторы недели забыть,
[06:06.320 --> 06:11.560]  что такое Липшицева, случайная величина. Мы говорили, что случайная величина Липшицева по
[06:11.560 --> 06:19.240]  ребрам, если два графа отличаются только на одно ребро, у них одинаковое множество вершин, вот это v,
[06:19.240 --> 06:25.040]  но отличаются они в одном ребре, то есть в одном графе это ребро есть, в другом графе этого ребра нет.
[06:25.040 --> 06:37.000]  Вот тогда мы говорим, да, и если вот так вот f от g минус f от g штрих для этих двух графов всегда
[06:37.000 --> 06:43.520]  не превосходит единицы, то мы говорим, что f Липшицева по ребрам. Два графа отличаются только в одном ребре,
[06:43.520 --> 06:50.000]  и мы точно знаем, что f минус f не превосходит единицы, тогда Липшицева по ребрам. Если
[06:50.000 --> 06:55.760]  отличаются в одной вершине, в окрестности одной вершины, мы долго это дискутировали тогда,
[06:55.760 --> 07:01.560]  помните, что мы зафиксировали одну вершину и испортили как-то ее окрестность, вот у графа g
[07:01.560 --> 07:07.400]  была какая-то вершина, в ней были какие-то ребра, вот мы можем часть удалить, часть добавить,
[07:07.400 --> 07:12.480]  получится граф g штрих, но только в окрестности одной вершины, тогда мы можем утверждать,
[07:12.480 --> 07:18.400]  что f Липшицева по вершине. Но опять же, если в любых двух таких графов модуль разности не превосходит
[07:18.400 --> 07:24.360]  единицы, мы говорим, что f Липшицева по вершинам. И кроме того, там было вот это неравенство Азумы,
[07:24.360 --> 07:30.960]  которое я сейчас напомню, но мы выяснили, что f Липшицева по вершинам лучше, чем f Липшицева по ребрам,
[07:30.960 --> 07:37.640]  концентрация выше. В таком темпе понятно? Ну потому что иначе придется все переписывать заново,
[07:37.640 --> 07:44.000]  что было на прошлой лекции. Вот, f Липшицева по вершинам лучше, вот здесь какая f Липшицева имеет
[07:44.000 --> 07:50.800]  место. Можно сказать, что y Липшицева по ребрам или по вершинам? Минимальное количество вершин,
[07:50.800 --> 07:56.960]  минимальное количество вершин, удаление которых приводит к раскраске в не более чем у цветов.
[07:56.960 --> 08:07.480]  Да даже на вершины похоже. Нет, ну понятно, что если f Липшицева по ребрам, то и по вершинам тоже.
[08:07.480 --> 08:16.640]  То есть одно из другого следует. Рёбер тоже верно. Другое дело, что f Липшицева по вершинам,
[08:16.640 --> 08:22.080]  как мы выяснили, лучше. И вот она здесь есть. Это f Липшицева по вершинам. Потому что если вы
[08:22.080 --> 08:27.400]  испортите окрестность только одной вершины, ну как вот эта минимальная k может измениться
[08:27.400 --> 08:34.680]  больше, чем на единицу? Вам все равно докрашивать только эту вершину в худшем случае. Добавлять
[08:34.680 --> 08:39.480]  новый цвет, если, например, в этой вершине появились новые ребра. Или если часть мы удалили,
[08:39.480 --> 08:48.120]  ну может быть лишний цвет тут был. Поэтому при наличии этой вершины минимальное множество,
[08:48.120 --> 08:53.960]  минимальное множество удаления которого дает там какую-то раскраску, и при отсутствии этой вершины
[08:53.960 --> 08:57.720]  два таких минимальных множества могут разниться не больше, чем вот на эту собственную вершину.
[08:57.720 --> 09:08.040]  То есть она Липшицева по вершинам. Красивое слово, которое выглядит как такая подпись.
[09:08.040 --> 09:18.080]  Липшицева по вершинам. Ну это круто! Это значит, что сейчас будет очень высокая плотность концентрации.
[09:18.080 --> 09:24.400]  При этом мат ожидания такой штуки посчитать, я и в прошлый раз говорил, так каприори, это совершенно
[09:24.400 --> 09:31.600]  непонятно как делать. Тут линейностью не пахнет. Когда у нас случайная величина является счетчиком
[09:31.600 --> 09:38.240]  количества чего-то, число треугольников, число независимых множеств и так далее. Ну там понятно,
[09:38.240 --> 09:43.520]  надо просуммировать индикаторы, воспользоваться линейностью. А тут-то какая линейность? Тут непонятно.
[09:43.520 --> 09:49.880]  Так вот мы сейчас вспомним Липшицева по вершинам. Вот было такое неравенство Азумы.
[09:49.880 --> 10:01.560]  Я в прошлый раз без доказательства давал. Оно было очень похоже на неравенство блуждания пьяницы.
[10:01.560 --> 10:15.440]  Вот, неравенство Азумы. Но утверждало, что если f Липшицева по вершинам,
[10:21.600 --> 10:30.960]  то, ну я писал вот так, вероятность с которой f минус математическое ожидание f больше либо
[10:30.960 --> 10:38.600]  равняется А, ну или больше, строго чем А, это неважно как писать, меньше либо равна 2 помножить
[10:38.600 --> 10:47.440]  на Е в степени минуса квадрат на 2 н-1. Так, товарищ, это тоже было в прошлый раз, это надо как-то
[10:47.440 --> 10:54.680]  слечить. Мы сейчас раскроем этот модуль. Понятно, что как и в случае случайного блуждания пьяницы,
[10:54.680 --> 11:01.840]  на самом деле верно и без модуля то же самое, но без двойки соответственно. То есть я напишу это
[11:01.840 --> 11:10.880]  вот в такой форме. Во-первых, вероятность того, что f минус Еf больше либо равняется А, не превосходит
[11:10.880 --> 11:21.200]  Е в степень минуса квадрат на 2 н-1. И во-вторых, вероятность с которой f минус Еf не превосходит
[11:21.200 --> 11:32.280]  минуса не больше чем Е в степени минуса квадрат на 2 н-1. Мелл пишет шикарно, но я ожидаю, что когда
[11:32.280 --> 11:38.160]  я начну стирать, будет не так красиво. А пока очень здорово все проявляется на доске. То есть вот на
[11:38.160 --> 11:44.480]  самом деле верны оба этих симметричных неравенства и из этого уже следует то, что написано сверху. Ну,
[11:44.480 --> 11:49.760]  какая разница? Я не доказывал ни то, ни другое, ни третье, поэтому поверить надо вот в эти оба,
[11:49.760 --> 11:55.000]  то, что тут есть полная симметрия, это, по-моему, более-менее очевидно. Из этих двух, конечно,
[11:55.000 --> 12:00.120]  вот это следует. А почему любой из них верно? Ну, это уж другой вопрос. Я в прошлый раз говорил,
[12:00.120 --> 12:08.320]  что я подумаю, может доказать это. Ну, так подумал, кокнет. Ну, поверить в это можно,
[12:08.320 --> 12:14.600]  оно как-то сопоставляется с пьяницами, поэтому только по модулю этого останется дырка. Так,
[12:14.600 --> 12:19.640]  сейчас будет полный катарсис. Потому что, смотрите, я сейчас буду оценивать математическое ожидание
[12:19.640 --> 12:27.040]  исходя вот из этого, наверное, второго варианта одного и того же неравенства. Ну, то есть я
[12:27.040 --> 12:32.840]  подводил вас к мысли о том, что само математическое ожидание фиг посчитаешь, но у нас есть вот это
[12:32.840 --> 12:38.840]  неравенство плотной концентрации меры, куда как более плотной, чем неравенство Чебышова,
[12:38.840 --> 12:44.720]  конечно. Ну, уж неравенство Чебышова, это было бы что-то типа 2n поделить на а в квадрате. И это,
[12:44.720 --> 12:49.440]  конечно, нам никак бы не помогло. Вот сейчас я хочу воспользоваться каким-то чудом этим
[12:49.440 --> 12:59.040]  неравенством для того, чтобы оценить математическое ожидание. Так, ну, давайте а возьмем сейчас равным.
[12:59.040 --> 13:05.720]  Это же верно для любого а, товарищи. У нас зафиксировано альфа и зафиксировано n с самого
[13:05.720 --> 13:12.920]  начала доказательства. Мы вольны вот это число а выбрать таким, как нам заблагорассудится. Вот я
[13:12.920 --> 13:24.760]  возьму и определю его как корень из двух повторных логарифмов. Не, ну вы не воспринимаете уж как прям
[13:24.760 --> 13:29.920]  троллинг какой-то. Я не издеваюсь. Нет, ну вот так вот, да. Не, ну смотрите, как сейчас будет все красиво.
[13:29.920 --> 13:36.880]  Все объясняется очень быстро. Берем такое а и подставим. Неправильно определил. Вот тут надо,
[13:36.880 --> 13:43.280]  конечно, n-1 добавить. Но это виноват, да, это очевидно. Конечно, n-1 забыл добавить. И все,
[13:43.280 --> 13:48.640]  сейчас все будет понятно. Смотрите, если а возвести в квадрат, а потом результат
[13:48.640 --> 13:54.880]  возведения в квадрат поделить на 2n-1, то останется повторным логарифом. Так,
[13:54.880 --> 14:02.480]  успеваете, да? А в квадрате корень пропал. Делим на 2n-1 на 2n-1. Случаем просто повторный
[14:02.480 --> 14:09.080]  логарифом. Не в степени минус повторный логарифом. О, чудо! Это опять 1 поделить на логарифом n.
[14:09.080 --> 14:17.600]  Так, это значит вот тут будет 1 поделить на логарифом n. И вот тут будет 1 поделить на логарифом n. Ну,
[14:17.600 --> 14:23.200]  то есть мы зафиксировали в начале доказательства n. Взяли вот такое а, подставили сюда и получили
[14:23.200 --> 14:32.240]  вот эти неравенства. Они правильные, что f липшится. Так, теперь смотрите. Вот сейчас будет главный катарсис
[14:32.240 --> 14:50.840]  этой части лекции. Предположим, что математическое ожидание f, ох-ох-ох-ох-ох. Наверное,
[14:50.840 --> 14:58.280]  меньше липр равняется, чем а. Или больше липр равняется. Сейчас секунду. Больше липр равняется.
[14:58.280 --> 15:09.040]  Больше липр равняется. Ну, чем вот это а. Ну, что бы не предположить? Вдруг оно больше липр
[15:09.040 --> 15:16.800]  равняется, чем а? Ну, может такое быть. А может не может? Сейчас посмотрим. Вот давайте сюда
[15:16.800 --> 15:30.120]  посмотрим. Тогда вероятность того, что f-ef меньше либо равняется минуса. Ну, с одной стороны она,
[15:30.120 --> 15:38.640]  конечно, не больше, чем 1 поделить на логарифом n. Это не тогда. Это просто мы знаем. А вот что будет
[15:38.640 --> 15:46.920]  тогда в этом предположении? Мы сейчас напишем. Это равно вероятность того, что f меньше либо
[15:46.920 --> 15:56.400]  равняется e-f-a. Ну, это тривиально. Я просто e-f перенес направо. Но мы еще предположили,
[15:56.400 --> 16:05.120]  что e-f больше либо равняется а. Тогда e-f-a больше либо равняется нуля, правильно?
[16:05.120 --> 16:12.720]  Так, дайте я вот здесь напишу. Больше либо равняется нуля. Секундочку, мне опять что-то прислали.
[16:12.720 --> 16:27.160]  Ясно. Так, e-f-a больше либо равняется нуля. Вот смотрите, f не превосходит чего-то,
[16:27.160 --> 16:40.080]  что само по себе не меньше нуля. Но, наверное, эта вероятность больше либо равна вероятности
[16:40.080 --> 16:50.000]  того, что f не больше нуля. Ну, вы меня сейчас убьете, конечно, и я сам себя убью, потому что я,
[16:50.000 --> 16:57.160]  конечно, забыл сказать, что f-то это нераненство азумы, но нам-то сейчас надо вместо f-y написать.
[16:57.160 --> 17:04.120]  Что-то я зарапортовался. Ну, то есть нераненство азумы сформулировано абсолютно правильно. Другое
[17:04.120 --> 17:11.400]  дело, что применить-то его нам нужно к y. Виноват. Вот здесь везде, вот тут вот y. Тут, конечно, y.
[17:11.400 --> 17:19.120]  Что-то я зарапортовался. Это верно для любой липшицевой по вершинам функции. y липшицевой
[17:19.120 --> 17:27.920]  по вершинам. Поэтому просто везде вместо f пишем y, конечно же. Друзья, это что-то я поторпился,
[17:27.920 --> 17:35.120]  не продумал момент. Конечно, y везде. Везде здесь y стоит. Нормально? Ничего? Ну, извините. Да,
[17:35.120 --> 17:45.320]  здесь, конечно, стоит y. И здесь y. Но я уже все перепишу. Здесь y. Здесь y. Только тарсиса не будет.
[17:45.320 --> 17:52.040]  И здесь y. Я же еще раз, с чего я начал. Я сказал, что вот есть y, которая липшится по вершинам. Нам
[17:52.040 --> 17:58.960]  надо каким-то образом сейчас оценить ее математическое ожидание. Вот мы смотрим на нее и делаем такой укол
[17:58.960 --> 18:05.400]  пальцем в небо. А вдруг математическое ожидание y не меньше, чем вот это вот загадочное a. Но оно не
[18:05.400 --> 18:10.960]  совсем загадочное, потому что согласно неравенству азумы, которая верна для любой липшицевой функции,
[18:10.960 --> 18:16.520]  для y тоже будет вот такое неравенство. То есть оно вот тут есть. А с другой стороны,
[18:16.520 --> 18:27.080]  мы получаем вероятность того, что y не больше нуля. Так, что значит, что y не больше нуля? Смотрите
[18:27.080 --> 18:34.000]  на определение. Это значит, что вообще ничего не надо удалять, и граф сам по себе красятся в у цветов,
[18:34.000 --> 18:41.480]  правда? y не больше нуля, значит он равен нулю, но то есть нам вообще по минимуму ничего не надо
[18:41.480 --> 18:47.400]  удалять, и уже сам граф красятся в у цветов. Сейчас будет катарсис. Это вероятность того,
[18:47.400 --> 19:09.400]  что хиадже не превосходит у. Не будет катарсис? Будет катарсис. Идем сюда. Во, и камера сюда
[19:09.400 --> 19:15.880]  приехала. Смотрите, как определялся у. Это такое число, но минимальное нужно для того, чтобы вот
[19:15.880 --> 19:21.280]  это выполнялось. Но главное сейчас, что это просто такое число, с которым выполнено прямо
[19:21.280 --> 19:25.720]  противоположное неравенство. Вероятность того, что хиадже не превосходит у больше,
[19:25.720 --> 19:32.240]  чем один поделить на логориф men. Я сюда теперь возвращаюсь, пишу больше, чем один поделить на
[19:32.240 --> 19:42.720]  логориф men. Смотрю сюда и смотрю сюда. Какое красивое противоречие. То есть если вы поняли,
[19:42.720 --> 19:49.040]  это должно пробрать. Вот мы за счет неравенства зумы, причем в одном из вариантов своих раскрытия
[19:49.040 --> 19:55.680]  модуля, мы получаем такое удивительное, совершенно противоречие. То есть у не может быть не больше,
[19:55.680 --> 20:06.560]  не меньше, чем а. Он меньше, чем а. Вывод отсюда. Мат ожидания у меньше, чем а. Если мы
[20:06.560 --> 20:12.800]  предполагаем противное, то мы получаем такое фантастически красивое противоречие. Ну раз ей
[20:12.800 --> 20:16.640]  меньше, чем а, то давайте воспользуемся, сейчас я вот сюда немножко вернусь, вот этим первым
[20:16.640 --> 20:23.240]  вариантом неравенства зумы. Сейчас мы еще его используем. Мы пишем вероятность того, что у,
[20:23.240 --> 20:31.080]  давайте я сразу напишу, больше либо равняется а плюс математическое ожидание у, не превосходит
[20:31.080 --> 20:38.880]  1 поделить на логориф мэна. Перенес сразу вправо просто математическое ожидание у и переписал
[20:38.880 --> 20:46.240]  первый вариант следствия из неравенства зумы. Так, ну теперь мы знаем, что мат ожидания у строго
[20:46.240 --> 20:52.400]  меньше, чем а, ну или там не больше, чем а, здесь это не так важно. Не больше, чем а. Тогда то,
[20:52.400 --> 21:03.720]  что стоит справа не больше, чем 2а, значит, наверное, эта вероятность больше либо равна,
[21:03.720 --> 21:16.800]  нежели вероятность того, что у просто больше либо равен 2а. Отодвинутся вправо от 2а менее или
[21:16.800 --> 21:24.680]  столь же вероятно, скоро-то отвинутся вправо от а, плюс что-то меньшее, чем а. Правильно? Правильно,
[21:24.680 --> 21:29.840]  правильно. Но можете начертить прямую, если вы не представляете. Смотрите, где эти две точки
[21:29.840 --> 21:36.520]  расположены, вот это и вот это. Понятно, что вероятность не вырастет. Вот так, ну это у нас
[21:36.520 --> 21:43.600]  вероятность того, я просто перепишу, что у больше либо равняется 2 корень из 2а n-1,
[21:43.600 --> 21:57.720]  помножить на повторный логориф мэн. Так, ну дорогие товарищи, теперь я раскрываю здесь карты. Это,
[21:57.720 --> 22:07.120]  конечно, меньше с запасом, чем корень из n на логориф мэн. Ну корень из n на логориф мэн-то
[22:07.120 --> 22:18.000]  откуда взялся? Он взялся вот отсюда. Ну вернее, он тут взялся из тех соображений, чтобы заведомо
[22:18.000 --> 22:24.880]  мажорировать вот такую противную величину, как двойный пинец повторного логорифма. Чтобы не писать
[22:24.880 --> 22:30.640]  здесь какую-то длиннющую бяку повторного логорифма корень из 2-ки, я написал с запасом. Но все равно
[22:30.640 --> 22:36.200]  же получилось даже с запасом. Потому что чего я хочу теперь сказать? Я хочу сказать, что раз
[22:36.200 --> 22:43.280]  вот такая вероятность не превосходит 1 поделить на логориф мэн, то вероятность того, что у больше
[22:43.280 --> 22:49.760]  чем корень из n на логориф мэн, тем более не превосходит 1 поделить на логориф мэн.
[22:49.760 --> 23:01.360]  Отодвинутся вправо от относительно маленького числа менее вероятно... сейчас... от относительно
[23:01.360 --> 23:07.200]  маленького более вероятно, чем от относительно большого. Но опять та же самая история. Сдвинут
[23:07.200 --> 23:13.000]  вправо точку по прямой, вероятность получилась только меньше. Вот, с огромным запасом, ну я просто
[23:13.000 --> 23:17.680]  хотел унифицировать обозначение, чтобы не было какой-то вот такой громоздкости в лемме. В лемме,
[23:17.680 --> 23:23.520]  еще раз вернусь, прошу прощения, в лемме, если вы поняли ее доказательство в прошлый раз, написать
[23:23.520 --> 23:29.600]  вот здесь логорифм, логорифм в 45-й степени, какой-нибудь е в степени корень из логорифма,
[23:29.600 --> 23:35.960]  да наплевать. Все, что хотите. Корень из логорифма, да, правильно сказал, е в степени корень из
[23:35.960 --> 23:43.400]  логорифма. Все, что хотите, лишь бы не степяное паэн. Вот этот самножитель из доказательства леммы
[23:43.400 --> 23:48.280]  видно, что совершенно паразитический. Можно написать все, что угодно, растущее медленнее
[23:48.280 --> 23:54.320]  наперед-заданной степени, любой наперед-заданной степени. Но я написал логорифм просто для такой
[23:54.320 --> 24:01.880]  унификации. Ну все, товарищи, теперь мы готовы завершить доказательство теоремы ровно так,
[24:01.880 --> 24:11.000]  как я обещал в конце прошлой лекции. Ну где бы мне его завершить? Давайте я, наверное, компактифицирую.
[24:11.000 --> 24:24.180]  Все, вот это можно убрать. Это было напоминание. Не равенство зумы. Не, в принципе, нормально.
[24:24.180 --> 24:31.240]  Грязная доска написать будет хорошо. Без воды лучше, я думаю, что вот так как раз нормально.
[24:31.240 --> 24:38.960]  Значит, мы получили еще вот что, что вероятность, с которой у больше, чем корень из n, на логорифм n,
[24:38.960 --> 24:48.320]  ну зря я так стал писать, конечно. Меньше либо равна 1 на логорифм n, ну а значит вероятность,
[24:48.320 --> 24:56.520]  с которой у не превосходит корень из n на логорифм n, больше либо равняется 1 минус 1 на логорифм n.
[24:56.520 --> 25:00.000]  Вот это то, что мне нужно. Мне нужны вот эти три вещи.
[25:00.000 --> 25:17.760]  Ну как? Давайте, например, вот это событие обозначим буквой а. Событие, состоящее в том,
[25:17.760 --> 25:24.360]  что хроматическое число не меньше, чем у. Событие, которое фигурирует вот в этой лемме,
[25:24.360 --> 25:33.240]  обозначим буквой б, а последнее событие обозначим буквой с. То есть у нас есть три вероятности,
[25:33.240 --> 25:39.320]  каждая из которых отмечена такой вот квадратной скобочкой. Под знаком вероятности стоит какое-то
[25:39.320 --> 25:47.960]  событие, но вот здесь оно обозначается а, здесь обозначается b, здесь обозначается с. Вот давайте
[25:48.040 --> 25:56.520]  рассмотрим совершенно любой граф, который принадлежит пересечению а, b и с.
[25:56.520 --> 26:04.280]  Что-то мне, по-моему, опять прислали. Да что ж такое? И правда?
[26:04.280 --> 26:11.400]  Ох, ух, онюшки. Сейчас отвечу, виноват, к сожалению.
[26:11.400 --> 26:37.200]  Так, любой граф вот в этом пересечении, какими свойствами он обладает? Ну,
[26:37.200 --> 26:42.760]  во-первых, хроматическое число графа больше либо равняется у. Это просто потому,
[26:42.760 --> 26:51.240]  что он принадлежит множеству а. То есть уже хорошо. Но это с самого начала было понятно. Во-вторых,
[26:51.240 --> 27:04.920]  у от g не превосходит корень из n на логариф mn. Ну, просто потому, что он принадлежит событию с.
[27:04.920 --> 27:14.520]  Ну, что это означает? Это означает, что вот в этом графе можно выделить некоторое конкретное подмножество
[27:14.520 --> 27:22.640]  s. Вот такой вот мощности не больше, чем корень из n на логариф mn. Просто по определению у, смотрите,
[27:22.640 --> 27:32.040]  можно выделить подмножество мощности не больше, чем столько. Такое, что вот эта вся часть графа g
[27:32.040 --> 27:41.800]  минус s, на v минус s ограниченного, вот эта вся часть красится в у цветов. Просто вот этот конкретный
[27:41.800 --> 27:51.120]  граф, принадлежащий данному пересечению, он так устроен. Она красится в у цветов. Теперь в-третьих,
[27:51.120 --> 28:01.520]  g принадлежит множеству b. Это последнее, что мы используем. Следовательно, каким бы ни было вот
[28:01.520 --> 28:09.680]  это s, выкидывание которого привело к раскраске в у цветов оставшейся части графа, мы это конкретное
[28:09.680 --> 28:16.760]  множество спокойно покрасим в три цвета. Какие-то, наверное, новые три цвета. Не в те, которые вот
[28:16.760 --> 28:22.360]  здесь задействованы среди этих у цветов, но, наверное, в какие-то новые три цвета. Следовательно,
[28:22.360 --> 28:29.680]  вот это множество s, это, то есть найденное на шаге с номером 2, вот здесь, в пункте с номером 2,
[28:29.680 --> 28:38.680]  это множество s красится в три цвета. В смысле, что граф ограниченный, на него красится в три цвета.
[28:38.680 --> 28:49.400]  Ну все, из объединения пунктов 2 и 3 следует, что хроматическое число графа не больше,
[28:49.400 --> 28:56.840]  чем у плюс 3, потому что мы покрасили вот эту всю внешнюю часть в у цветов и докрасили еще в три
[28:56.840 --> 29:04.760]  цвета за счет того, что граф g принадлежит событию с леммом. Любой граф из этого пересечения точно
[29:04.760 --> 29:12.200]  имеет хроматическое число не меньшее, чем у и не большее, чем у плюс 3. Ну а вероятность этого
[29:12.200 --> 29:18.360]  пересечения, это, конечно, простое упражнение по теории вероятности. Ну ладно, я так и быть напишу.
[29:18.360 --> 29:28.760]  Это, конечно, что такое? Это вероятность a с чертой, объединенная с b с чертой, объединенная с c с чертой,
[29:28.760 --> 29:35.960]  все с чертой. У нас точно есть среди слушателей один человек, который является поборником вот этой
[29:35.960 --> 29:42.520]  аккуратности, но сейчас его, по-моему, среди нас нет. Возможно, он есть с той стороны экрана. Вот,
[29:42.520 --> 29:47.160]  поэтому я распишу подробно. Но, в принципе, это можно было считать упражнением. Так это правильно?
[29:47.160 --> 29:55.000]  Ну там какая-то формула из логики, из теории множеств. Да-да-да-да-да, вот какая-то такая.
[29:55.000 --> 30:13.480]  Это есть единица минус вероятность a с чертой, b с чертой, c с чертой. Это больше либо равно,
[30:13.480 --> 30:21.600]  ну давайте здесь не пишу, больше либо равно. Один минус вероятность a с чертой, минус вероятность
[30:21.920 --> 30:26.840]  b с чертой, минус вероятность c с чертой. Но потому что вероятности объединения
[30:26.840 --> 30:34.480]  не больше чем сумма вероρώдностей. Вероятность a с чертой не превосходит один поделитель на
[30:34.480 --> 30:42.000]  логориф men. Вероятность a больше либо равна 1 минус 1 на логориф men, а вероятность a с чертой не
[30:42.000 --> 30:46.680]  больше, чем 1 на логориф men. То же самое для b с чертой, то же самое для c с чертой,
[30:46.680 --> 30:53.340]  То есть всё это не меньше, чем 1 минус 3 поделительно логарифа m, и это, конечно, стремится к единице всё.
[30:54.660 --> 31:00.220]  Ну то есть почти каждый граф действительно красятся в u-у плюс 3 цвета.
[31:01.780 --> 31:05.340]  Потому что а пересечённое с b пересечённое с c это почти все графы.
[31:06.860 --> 31:08.860]  Вероятность этого события стремится к единице.
[31:09.900 --> 31:11.260]  Всё.
[31:11.260 --> 31:15.720]  Ну вот здесь катарсис, это вот где-то тут случился, когда мы от ожидания оценивали.
[31:16.160 --> 31:20.760]  Это самое красивое место, как вот прийти к противоречию. Вот так вот подобрали.
[31:21.600 --> 31:27.160]  Вот, но я напоминаю, что эту теорему люди научились ещё усиливать, то есть можно довести до u-plus 1,
[31:28.120 --> 31:32.720]  и альфа можно брать не большим пяти шестых, а большим, чем одна вторая. Ну, в общем,
[31:33.400 --> 31:35.160]  тем не менее.
[31:35.220 --> 31:40.060]  Так вот, на гребне знаний практически находимся. Давайте я, наверное, сейчас всё сотру и
[31:40.700 --> 31:45.020]  буду рассказывать ещё про один последний случай,
[31:45.940 --> 31:50.700]  связанный с хроматическим числом случайного графа. Теорема тоже будет балабаша. Что?
[31:53.420 --> 31:54.940]  Агрегат есть.
[31:54.940 --> 32:01.700]  Ну, в принципе, можно воспользоваться агрегатом, тогда придется сделать 5-минутный перерыв. Ну, пока там будет сохнуть.
[32:02.400 --> 32:04.960]  Так, ну, мы вернулись, товарищи. Значит, у нас
[32:06.160 --> 32:09.600]  последняя теорема про хроматическое число. Больше красить ничего не будем.
[32:10.640 --> 32:16.600]  В общем, я понимаю, что кого-то уже, может быть, немножко так поднапрягло, сколько можно красить. Есть какие-то другие задачи.
[32:16.960 --> 32:23.920]  Их много, они у нас будут. Но вот один случай такой, прям ключевой, мы до сих пор не рассмотрели.
[32:24.080 --> 32:30.000]  Мы, конечно, кучу случаев не рассмотрели, потому что у нас всё время вероятность довольно быстро стремилась к нулю, но
[32:30.000 --> 32:34.380]  есть совсем ключевой случай. П-ровняется 1 и 2.
[32:35.460 --> 32:38.700]  Ну, граф случайен в том смысле, что он просто вот случайен.
[32:39.460 --> 32:41.460]  Классическое определение вероятности.
[32:41.780 --> 32:45.620]  Тучка, в которой летели графы, была целиком равномерно беленькая такая, да?
[32:47.140 --> 32:53.380]  Вот. Ну, смотрите, кое-что мы с вами можем про такой случайный граф сходу сказать.
[32:54.780 --> 32:57.620]  У нас в своё время было такое замечательное утверждение,
[32:57.640 --> 33:04.680]  что асимптатически почти, наверное, альфа от такого графа
[33:05.600 --> 33:09.440]  меньше, ну, если хотите, равняется, это неважно, чем два
[33:11.000 --> 33:13.000]  двоичных логарифмена.
[33:13.760 --> 33:17.200]  Это было утверждение, которое, в частности, свидетельствовало о том, что
[33:17.800 --> 33:24.000]  гораздо лучше хроматическое число оценивать с помощью дроби n поделить на альфа, а не
[33:24.700 --> 33:29.660]  омеги от g, которая тоже почти всегда меньше либо равна вот этой величине.
[33:30.820 --> 33:32.820]  Вот. Ну, соответственно, что?
[33:33.540 --> 33:34.980]  Значит,
[33:34.980 --> 33:37.300]  конечно же, асимптатически почти, наверное,
[33:38.740 --> 33:40.740]  хроматическое число не меньше, чем
[33:42.180 --> 33:45.620]  n поделить на два лог двоичные.
[33:47.980 --> 33:50.980]  Ну, вот, пользуемся, собственно, этим неравенством, n поделить на альфа.
[33:51.400 --> 33:58.760]  Альфа, почти, наверное, не больше, чем два лог двоичный. Ну, значит, х не меньше, асимптатически почти, наверное, чем этот дробь.
[34:01.600 --> 34:07.720]  Ну, оказывается, оказывается, что это почти не улучшаемый результат.
[34:10.720 --> 34:14.520]  То есть, мало того, что неравенство n поделить на альфа
[34:15.400 --> 34:19.600]  гораздо, конечно, сильнее для почти всех графов, чем просто омега,
[34:21.980 --> 34:25.120]  оно еще и не улучшаемо, асимптатически.
[34:25.840 --> 34:31.200]  То есть, вот этот результат, лучше которого в среднем нету, ну, для почти всех графов нету.
[34:32.040 --> 34:34.760]  Теорема, которую доказал тот же самый Балабаш.
[34:42.520 --> 34:44.040]  Вот.
[34:44.040 --> 34:48.400]  Предыдущую теорему доказала Балабаша, а эту теорему доказал Балабаш.
[34:48.700 --> 34:51.580]  Я здесь не стал склонять.
[34:53.220 --> 34:55.220]  Она утверждает следующее.
[34:57.460 --> 35:00.180]  Существует такая функция phi
[35:02.100 --> 35:04.100]  от n,
[35:04.620 --> 35:06.620]  что
[35:07.820 --> 35:09.300]  phi
[35:09.300 --> 35:12.620]  равняется о маленькое от n поделить на логариф mn,
[35:14.380 --> 35:16.380]  и асимптатически почти, наверное,
[35:17.240 --> 35:21.080]  хроматическое число случайного графа отличается
[35:21.960 --> 35:24.680]  от n поделить на 2 лог 2-ичный n
[35:25.280 --> 35:29.000]  не больше, чем на величину вот этой функции.
[35:31.200 --> 35:36.680]  Ну, то есть, можно, конечно, с самого начала было неформально сказать, что асимптатически почти, наверное,
[35:37.480 --> 35:39.480]  хроматическое число случайного графа
[35:40.200 --> 35:42.200]  симптатически равно вот этой дроби.
[35:42.880 --> 35:46.200]  Но это не очень понятно, что значит. Я строго это сформулировал.
[35:46.380 --> 35:52.480]  Для большинства графов, для почти всех графов,
[35:53.320 --> 35:59.320]  отличие значения их хроматических чисел от вот этой величины, которая служит заведомо нижней оценкой,
[36:00.640 --> 36:04.960]  не превосходит величины, которая бесконечно мала по сравнению с этой оценкой.
[36:05.800 --> 36:09.440]  Ну, то есть, хроматическое число болтается в окрестности вот этой вот дроби
[36:10.600 --> 36:12.600]  на расстояние плюс-минус
[36:13.280 --> 36:15.600]  величина бесконечно малая по сравнению с этой дробью.
[36:15.740 --> 36:18.860]  Ну, я здесь написал о малой от n поделительной логарифм натуральной,
[36:19.020 --> 36:23.780]  здесь стоит логарифм двоичный, да еще умноженный на двойкунный, но я надеюсь, понятно, что это без разницы.
[36:27.660 --> 36:32.780]  Возникает вопрос, а есть ли здесь такая плотная концентрация, какая была в предыдущей теореме?
[36:33.340 --> 36:35.340]  Все-таки, там концентрация была вообще офигенная.
[36:36.340 --> 36:38.340]  У стремилась к бесконечности,
[36:40.060 --> 36:45.060]  а хроматическое число принимало только значение у и у плюс один, или там у плюс один, у плюс два, у плюс три.
[36:46.220 --> 36:51.120]  Вот здесь, как совершенно недавно доказали, такой концентрации нет.
[36:52.260 --> 36:54.260]  Буквально в прошлом году это стало.
[36:55.540 --> 36:59.780]  Теоремы свои Балабаш доказал в 80-е годы, так, чтобы было понятно.
[37:00.380 --> 37:05.300]  Это результаты примерно сорокалетней давности, тоже очень-очень свежие, конечно.
[37:06.860 --> 37:08.860]  Понятное дело, что очень важные.
[37:09.180 --> 37:13.580]  Вот, и вот эта теорема, и предыдущая, которую мы уже доказали, это 80-е годы.
[37:13.800 --> 37:20.440]  А вот утверждение о том, что phi at n нельзя заменить на константу, это буквально прошлый год.
[37:22.120 --> 37:27.920]  Сейчас я понятно говорю, да? Вот здесь phi at n, это o маленькое от n поделить на логариф mn,
[37:28.280 --> 37:30.920]  но оно может стремиться к бесконечности.
[37:31.280 --> 37:37.200]  И вот недавно доказали, что в утверждении подобного типа, где вот здесь вот написано симпатически почти наверно,
[37:37.600 --> 37:39.920]  нельзя phi at n заменить никакой константы.
[37:43.580 --> 37:50.120]  Судя по всему, правильный порядок роста, это что-то типа корень четвертой степени из n, но это пока не доказано.
[37:52.040 --> 37:56.920]  Но правильный порядок величины разброса, скажем так, насколько от вот этой дроби
[37:57.360 --> 38:00.720]  реально уклоняется хроматическое число. То есть вот какая-то дисперсия
[38:01.320 --> 38:06.200]  оценивается, видимо, как корень четвертой степени из n, но это гипотеза, которая пока не доказана.
[38:07.800 --> 38:11.080]  Вот такие вот продвижения. В прошлом году я говорил, что
[38:11.100 --> 38:14.220]  это нерешенная проблема. Говорю, что это вот уже известный результат.
[38:16.300 --> 38:18.300]  Нельзя константы заменить.
[38:19.140 --> 38:21.780]  Вот. Я хочу эту теорему доказать.
[38:23.620 --> 38:28.340]  Очень амбициозная задача. В прошлом году я это сделал по модулю некоторого противного вычисления,
[38:28.820 --> 38:33.860]  которое прокомментировал, но сказал, в большей степени его считать не нужно. Экзамены не потребуют.
[38:34.620 --> 38:37.980]  Вот. Там идентично все опять основано на неравенствах Азумы.
[38:38.080 --> 38:43.200]  Но тут своя специфика, поэтому, ну, черт возьми, черт. Время есть, черт не доказать.
[38:45.040 --> 38:52.600]  Нет, я ни в коем случае не собираюсь использовать сегодняшний бонус в качестве бонуса по отношению к 30 лекциям, которые должны быть в двух семестрах.
[38:53.400 --> 38:55.900]  30 их останется. 31 я не сделаю.
[38:56.400 --> 38:59.600]  Вот. Но в прошлом году я успел, так что и в этом году, наверное, успеем.
[39:00.720 --> 39:06.560]  Посмотрим. Ну, я даже не стану писать доказательства, но, в общем-то, я не буду писать доказательства.
[39:06.560 --> 39:12.980]  Ну, я даже не стану писать доказательства слова, потому что я его сейчас потом буду долго что-то рассуждать, рассуждать.
[39:13.660 --> 39:15.660]  Ну, в общем, мы начинаем доказывать теорию.
[39:17.740 --> 39:21.620]  Вот. Ну, смотрите, значит, доказательство будет состоять из
[39:22.900 --> 39:26.460]  как бы двух блоков. Один занудный, а другой содержательный и красивый.
[39:26.620 --> 39:34.660]  Ну, занудный, это я сейчас буду вводить некоторые функции, некоторые параметры в духе самых неприятных семинаров про асимптотики.
[39:36.980 --> 39:41.700]  Виноват. Вот. После того, как я их введу, появится уже красота, катарсисы и так далее.
[39:41.860 --> 39:46.540]  Ну, а для чего я их именно так буду вводить? Ну, это будет понятно ближе к концу.
[39:47.620 --> 39:51.100]  Значит, параметры. Это довольно ужасно.
[39:52.780 --> 39:56.940]  Параметры. Это довольно ужасно. Ну, давайте сделаем вот так. Есть
[39:57.940 --> 40:04.260]  сначала такая случайная величина из KTAG. Это будет просто по определению количество
[40:05.160 --> 40:07.160]  K-элементных
[40:09.120 --> 40:11.920]  независимых множеств
[40:14.000 --> 40:19.240]  в случайном графе G. Ну, или просто в графе G, не важно, случайно, какой-то фиксированный.
[40:19.760 --> 40:21.640]  XKTAG.
[40:21.640 --> 40:28.160]  Ну, она реально зависит, конечно, еще от N, она зависит от P. Ну, P у нас равно 1 и 2.
[40:28.640 --> 40:32.200]  Я напоминаю. А N, ну, мы N всегда опускаем.
[40:33.100 --> 40:35.100]  Понятно, что зависимость от N тоже присутствует.
[40:35.980 --> 40:44.060]  Так, ну, что мы с вами точно знаем? Это, конечно, математическое ожидание XKTAG. Я не буду в очередной раз спрашивать, чему оно равно. Я просто напишу.
[40:44.420 --> 40:46.660]  Это, конечно, c из N по K
[40:47.740 --> 40:54.460]  умножить на 2 в степени минус c из K по 2. 2 в степени, потому что вероятность ребра 1 вторая.
[40:55.380 --> 41:00.580]  Ну, раз она 1 вторая, значит 1 вторая в степени c из K по 2. Это вероятность отсутствия всех ребр.
[41:01.080 --> 41:03.080]  Мат ожидания мы знаем.
[41:03.640 --> 41:05.360]  Давайте
[41:05.360 --> 41:07.360]  временно...
[41:07.400 --> 41:14.280]  Тут будет довольно забавно. По ходу доказательства эта штука будет переобозначаться самыми разными способами, но мы не запутаемся, я вас уверяю.
[41:14.280 --> 41:19.160]  Это уже опыт показывает. Но временно это предпозначим вот так. FKTAG.
[41:20.120 --> 41:27.560]  Здесь укажем зависимость от N, потому что я чуть-чуть хочу порассуждать о поведении этой величины. И в зависимости от K, и в зависимости от N.
[41:28.460 --> 41:30.460]  Хочу порассуждать.
[41:32.460 --> 41:40.940]  Так, ну и как же она зависит, правда? Вот, например, f1 от N. Это просто метод тыка называется. Давайте попробуем угадать чего-нибудь.
[41:41.420 --> 41:43.820]  Что именно сейчас хотим угадать, скоро поймете.
[41:44.580 --> 41:47.380]  Так, f1 от N это N.
[41:49.620 --> 41:51.620]  По-моему, и все, да?
[41:52.280 --> 41:58.080]  С из одного по два это ноль, два в степени ноль это единица. Ну ладно, f1 от N это N.
[41:59.000 --> 42:05.920]  f2 от N. Я хочу вас подвести к пониманию какой-то простой вещи, но чтобы это неформально было, ну порассуждаем вместе.
[42:06.480 --> 42:08.480]  f2 от N это...
[42:08.880 --> 42:15.080]  Давайте я асимптотику буду писать сразу. Это N квадрат пополам, c из N по два, N квадрат пополам.
[42:15.840 --> 42:18.520]  Ну а тут еще на 2 в минус первой степени.
[42:18.520 --> 42:23.580]  Ну, дальше я не буду мучиться, но видно, что вот эта штука стремится к бесконечности.
[42:24.180 --> 42:29.980]  Эта штука тоже стремится к бесконечности, в чем с одной стороны как бы побыстрее, да, потому что N возвелось в квадрат.
[42:30.460 --> 42:37.060]  Но с другой стороны, как это не смешно бы прозвучало, но помедленнее, потому что поделили на 4, а тут ни на что не делили.
[42:37.620 --> 42:41.460]  Но это издевательство, понятно, что это быстрее стремится к бесконечности, да?
[42:42.260 --> 42:44.860]  Вот, ну ладно, ладно. А теперь смотрите вот сюда.
[42:45.360 --> 42:55.920]  А теперь смотрите вот сюда. Симпатически почти наверное, альфа, ну давайте я все-таки оставлю меньше, это неважно, там и так, и так получается, альфа меньше, чем 2 лог 2 х N, это вы помните, да?
[42:57.040 --> 42:59.240]  Симпатически почти наверное, как это доказывалось?
[42:59.760 --> 43:01.560]  Это доказывалось
[43:01.560 --> 43:06.120]  просто это равносильно тому, что асимптотически почти наверное
[43:06.920 --> 43:08.920]  х kt
[43:09.160 --> 43:10.920]  равняется нулю,
[43:10.920 --> 43:12.920]  если k
[43:13.140 --> 43:18.460]  равняется 2 лог 2 х N. Вот так. Мы же это доказывали.
[43:23.300 --> 43:30.020]  Число независимых множеств вот этого размера равняется нулю, это просто равносильно тому, что альфа меньше, чем это число.
[43:31.260 --> 43:32.500]  Правда?
[43:32.500 --> 43:40.660]  Дальше, как мы это доказывали? Ну, вспоминайте, это же было просто неравенство Маркова. То есть мы сосчитали мат ожиданий х катово и убедились, что оно стремится к нулю.
[43:41.520 --> 43:43.520]  Привод таком k.
[43:45.600 --> 43:51.880]  Не, ну вы можете себе это сейчас, конечно, как-то пометить, но вот когда мы в начале семестра доказывали вот это вот утверждение,
[43:52.400 --> 43:54.600]  мы пользовались просто неравенством Маркова.
[43:56.120 --> 43:58.120]  Посчитали вот это математическое ожидание,
[43:58.800 --> 44:04.240]  подставили в него вместо k 2 лог 2 х N и убедились, что вот тут оно уже к нулю.
[44:05.240 --> 44:09.240]  Смотрите, f1 стремится к бесконечности, f2 стремится к бесконечности,
[44:09.980 --> 44:15.220]  вы можете там f3 посчитать, f5 посчитать, f10, они вроде всех к бесконечности стремятся.
[44:17.020 --> 44:23.420]  Но, когда вы вместо k подставляете ни 3, ни 5, ни 10, а вот так растущую функцию,
[44:25.140 --> 44:31.260]  начинает стремиться к нулю, потому что 2 в степени минус k квадрат пополам,
[44:32.260 --> 44:40.360]  оно в конце концов перестает быть просто константочкой в знаменателе, про которую я вроде как шутливо говорил, что побыстрее стремится,
[44:40.840 --> 44:42.840]  помедленнее стремится к бесконечности.
[44:43.320 --> 44:45.960]  Оно перестает быть вот этой смешной константой,
[44:46.480 --> 44:54.400]  которая якобы не вредит стремлению к бесконечности, а она таки начинает в знаменателе забивать вот этот числитель и все вместе стремится к нулю.
[44:56.760 --> 44:58.760]  Понятно?
[44:59.300 --> 45:00.780]  Короче,
[45:00.780 --> 45:07.540]  можно, и это вы можете уже самостоятельно попробовать обосновать, но это не очень сложно, просто не хочется тратить на это время,
[45:08.180 --> 45:12.460]  можно дать корректное определение величины, давайте назовем ее k1, например,
[45:13.300 --> 45:16.660]  давайте k0. k0 от n
[45:18.220 --> 45:19.580]  это
[45:19.580 --> 45:21.580]  минимальное такое k,
[45:22.780 --> 45:24.780]  что f
[45:25.340 --> 45:27.340]  kt от n
[45:28.760 --> 45:32.000]  ну да, это больше либо равно
[45:33.340 --> 45:35.340]  единицы, вот так.
[45:37.420 --> 45:44.700]  Да нет, ну тут вообще ничего не нужно особенно обосновывать, для каждого n найти такое минимальное k можно просто перебором,
[45:45.140 --> 45:53.180]  не надо знать никаких сложных алгоритмов, просто тупым перебором такое k найдется, и это видно вот из всех этих выкладок, которые я сейчас показываю.
[45:55.020 --> 45:57.020]  Видно, что в какой-то момент оно станет
[45:57.140 --> 45:59.140]  достаточно II и перестанет
[45:59.160 --> 46:04.520]  быть больше либо равной единице, вот оно стремится в бесконечности, стремится к бесконечности,
[46:05.240 --> 46:07.240]  а потом бац, это начинается стремиться к нулю.
[46:10.800 --> 46:17.440]  А я не в ту сторону нераненства написал, ну дайте я меньше либо равно единицы напишу, сейчас, подождите. Да, да да да, да, конечно! Спасибо!
[46:17.720 --> 46:24.640]  Спасибо, это меня аудитория, которая здесь сидит правильно поправляет, да, меньше либо равно единицы, это я описался, конечно, да вот оно
[46:24.640 --> 46:29.840]  оно большое-большое, но уже как бы поменьше. Вот для каждого конкретного n в какой-то момент
[46:29.840 --> 46:39.220]  настает вот такое, что оно перестает быть большим. Находится минимальная k, при
[46:39.220 --> 46:43.040]  котором в k-ты не превосходит единицы.
[46:44.160 --> 46:49.360]  А, знаете, я какое вам упражнение задам? Я понял, это понятно. Ну, дали такое
[46:49.360 --> 46:56.080]  определение. Хорошо, нашли k нулевой для каждого n. А я вас попрошу доказать,
[46:56.080 --> 47:11.960]  докажите, что если k, ну скажем, не превосходит два лог, двоичный n, минус
[47:11.960 --> 47:20.080]  какая-то там, с огромным запасом напишу 100, а дальше какая-то константа, я хотел
[47:20.080 --> 47:24.440]  сказать, с огромным запасом напишу 100, напишу повторный двоичный логариф
[47:24.440 --> 47:28.520]  m или натуральный там, какой хотите. Ну, просто удобно в одинаковых основаниях
[47:28.520 --> 47:36.400]  мыслить. Вот, минус 100 раз двукратный логарифом двоичный n. Вот, если такое k,
[47:36.400 --> 47:44.000]  то уже fk-ты от n стремится к бесконечности.
[47:47.040 --> 47:53.320]  Ну, это вот упражнение гнусное, обычное на симпатический анализ. c из n по k
[47:53.320 --> 47:57.680]  это n в k-ты поделить на k факториал. Тут примерно 2 в степени минус k квадрат
[47:57.680 --> 48:01.640]  пополам. Тупо это подставляем и проверяем, что это стремится к бесконечности.
[48:02.080 --> 48:07.240]  k факториал заменяем какой-нибудь своей хорошей оценкой, типа стирлинга, там,
[48:07.240 --> 48:12.000]  чего хотите. В общем, тупо проверяется, что вот тут уже стремится к бесконечности.
[48:12.000 --> 48:18.280]  Соответственно, минимальная k таким образом лежит где-то между вот этой
[48:18.280 --> 48:22.240]  величиной, ограничена она сверху этой величиной, а снизу она, соответственно,
[48:22.240 --> 48:29.960]  ограничена вот этой величиной. Это понятно? То есть, если вы доказываете вот это, а это
[48:29.960 --> 48:38.160]  простое упражнение на асимптотике, то из этого, конечно, следует, что k0 от n асимптотически
[48:38.160 --> 48:49.800]  равняется 2 лог 2-ичные. Но одно небольшое упражнение, это можно сделать. Мне кажется,
[48:49.800 --> 48:55.800]  оно проще, чем иные упражнения на OKTCH. Поэтому ничего страшного тут нет. Ну хорошо,
[48:56.080 --> 49:01.680]  поверили, что k0 такое? Это вот такой нудный выбор параметров. Дальше мы вводим в величину,
[49:01.680 --> 49:11.080]  виноват m, равную целой части от n поделить на логарифом в квадрате n. То есть, это меньше,
[49:11.080 --> 49:17.960]  чем количество наших вершин, меньше асимптотически, и даже меньше, чем n поделить на 2 лог 2-ичный n,
[49:17.960 --> 49:24.840]  асимптотически это сейчас сработает. Но меньше не сильно. Вот ни корень четвертой степени из n,
[49:24.840 --> 49:34.920]  в каком смысле это как раз про это. Возьмем такое m и обозначим k1 от m, или просто k1,
[49:34.920 --> 49:50.120]  величину k0 от m виноват минус 3. Что такое k0 от m, я надеюсь, понятно. Это то же самое,
[49:50.120 --> 49:57.440]  что мы здесь мучительно определяли, только вот для m, а не для n. Теперь смотрите, поскольку
[49:57.440 --> 50:03.000]  m выбрано именно вот так, а не, например, как корень четвертой степени из n, n делится на какую-то
[50:03.000 --> 50:11.320]  фигню, на логарифу. То когда вы, смотрите на эту асимптотику, сюда m подставляете, k0 от m,
[50:11.320 --> 50:19.520]  асимптотически равно 2 лог 2-ичный m. То асимптотика по n такая же. Я хочу сказать,
[50:19.520 --> 50:29.280]  что вот это все это 2 лог 2-ичный n тоже. Ну и m, конечно, и n. Ну то, что минус 3,
[50:29.280 --> 50:34.000]  это я надеюсь, вообще понятно, что никак не влияет. Да, это 2 лог 2-ичный n. Зачем
[50:34.000 --> 50:42.120]  минус 3 вы узнаете сильно позже? А сейчас пока такая асимптотика. Вы выбрали такой параметр k1
[50:42.120 --> 50:48.000]  от m, он асимптотически равен вот этому. Это совершенно понятно. Так, что еще на самом деле
[50:48.000 --> 51:02.320]  понятно, это что fk1 от m, fk1 от m. Это знаете, что такое? Мы отступили от минимального числа,
[51:02.320 --> 51:14.640]  при котором f все еще не больше единицы, на троечку. Ну если вы посмотрите снова внимательно сюда,
[51:14.640 --> 51:19.360]  это я думаю тоже надо рассматривать как такое небольшое упражнение, то вы увидите,
[51:19.360 --> 51:31.920]  что при каждом уменьшении величины k на единичку, k уменьшаем на единичку. Вот здесь вот происходит
[51:31.920 --> 51:37.640]  уменьшение, но это вообще очевидно, примерно в n раз. Ну когда k само порядка логарифма,
[51:37.640 --> 51:42.320]  там в знаменателе еще какой-то логарифм появляется, ну в общем я хочу сказать,
[51:42.320 --> 51:49.400]  что вот это это m в степени 3, ну плюс какое-то умалое от единицы в показателе этой степени.
[51:49.400 --> 51:54.440]  Имеется в виду, что m в степени умалое от единицы это какая-то степень логарифма
[51:54.440 --> 52:08.040]  m, на самом деле. Но я так о грубе, просто более грубо написал. Нет, имеет конечно, она тоже от
[52:08.040 --> 52:17.480]  м, естественно, да. Да-да-да, конечно, ну так я просто не дописал. Просто вот это коротко
[52:17.480 --> 52:23.520]  обозначается k1, но конечно от m, да, то есть мы всюду предполагаем, что это зависимость от м. Так
[52:23.520 --> 52:31.920]  понятно сказал, да? Вот еще раз понятно, чего я утверждаю. Видно, что c каждый раз это n в степени
[52:31.920 --> 52:37.560]  k, там n в степени k-1, n в степени k-2, но при этом в знаменателе было k факториал,
[52:37.560 --> 52:44.280]  потом станет k-1 факториал, это в k раз уменьшение, но k порядка логарифма. Поэтому,
[52:44.280 --> 52:50.000]  когда вы k уменьшаете на тройку, m-ка в данном случае, m-ка не n-ка, потому что, ну понятно,
[52:50.000 --> 52:56.120]  да, m-ка возводится в третью степень, ну а куда-то там в знаменателе лезут эти логарифмы, ну и черт бы
[52:56.120 --> 53:01.960]  с ними я их загнал в маленькой от единицы. Вот это ружье, которое выстрелит самым последним,
[53:01.960 --> 53:08.680]  я его приберегу, это будет такой тоже мегакатарсис. Зачем бы это было нужно? Но пока так вот,
[53:08.680 --> 53:17.840]  это понятно чисто аналитически? Вот все, все, параметры мы, кажись, выбрали. То есть мы будем
[53:17.840 --> 53:23.720]  работать с вот этим k-1 и будем работать с вот этим m. А теперь будет сформулирована ключевая
[53:23.720 --> 53:30.800]  лемма, из которой мгновенно будет следовать доказательство, собственно, теоремы. Да, я, может быть,
[53:30.800 --> 53:36.400]  забыл сказать, в одну-то сторону неравенства вообще очевидно, то есть phi равняется нулю. Мы
[53:36.400 --> 53:45.080]  его уже фактически доказали. Нам нужно теперь доказать, что phi не превосходит n поделить на 2
[53:45.080 --> 53:54.120]  лог 2-ичный n плюс какой это phi от n. Вот все, что нам осталось доказать. Согласны? Потому что
[53:54.120 --> 53:59.760]  нижняя оценка даже с phi равна нулю уже доказана. Вычитать ничего не надо, минус phi писать не надо.
[53:59.760 --> 54:09.920]  Мы сейчас верхнюю оценку хотим сделать. Вот сейчас мы сформулируем ключевую лемму,
[54:09.920 --> 54:28.000]  которая сложно доказывается. А симпатически, почти наверно, выполнено следующее замечательное
[54:28.000 --> 54:38.480]  утверждение. Для любого s из V, в этом множество вершин случайного графа нашего,
[54:38.600 --> 54:48.640]  как всегда, мощность V равняется n, если вдруг кто-то не помнит и не понимает. Берем наш n-вершинный
[54:48.640 --> 54:55.400]  граф с вероятностью ребра 1 на 2 и говорим, что а симпатически, почти наверно, для любого s мощности
[54:55.400 --> 55:03.480]  m, вот этой мощности, которая меньше, для любого под множество, меньше, но не сильно меньше,
[55:03.480 --> 55:15.920]  мощности. Хроматическое число g, альфа от g ограниченного на s, альфа именно число независимости,
[55:15.920 --> 55:33.240]  от g ограниченного на s не меньше, чем k1, ну а от m. Давайте сначала пафос этого утверждения,
[55:33.240 --> 55:45.120]  чтобы оно точно было понятно. Вот сарделька, это V мощности n. Что утверждается? Давайте сначала
[55:45.120 --> 55:59.400]  сюда посмотрим. Вообще говоря, мы знаем, что а симпатически, почти наверно, альфа меньше,
[55:59.400 --> 56:04.800]  чем 2 лог 2 х н. Помните это? Вот запомните это, держите это в голове, а сейчас вернемся сюда.
[56:04.800 --> 56:12.600]  Альфа меньше, чем 2 лог 2 х н, а лемму утверждает, что какое бы множество,
[56:12.600 --> 56:19.720]  ну такой сравнительно большой мощности, вы бы не взяли. Не, ну она конечно бесконечно маленькая
[56:19.720 --> 56:27.960]  по сравнению с n, это я плохо нарисовал. Наверное, лучше все-таки не так рисовать, а вот так.
[56:27.960 --> 56:40.960]  Какое угодно, какое бы множество, вы не взяли, но вот этого размера, m. В нём есть независимое
[56:40.960 --> 56:49.160]  множество, и тут есть независимое, и тут есть, и тут есть, и тут, и тут, и тут, везде есть. Какого
[56:49.160 --> 56:59.060]  размера? Почти такого же. Да, там мы его долго мучительно выбирали, потом будет понятно,
[56:59.060 --> 57:04.600]  почему именно так выбирали, но факт тот, что асимптотика этого размера почти такая же,
[57:04.600 --> 57:14.920]  как у той величины, которой уже ни одно вообще независимое множество не соответствует. Нет,
[57:14.920 --> 57:22.800]  ни одного множества вот такого размера, ни одного. Почти, наверное. Я туда специально водил,
[57:22.800 --> 57:29.840]  больше не поведу, должны помнить. Вот такого размера асимптотически почти, наверное, нет,
[57:29.840 --> 57:36.200]  но вот такого размера, который ну вообще почти не отличается от этого, да, ну подумаешь,
[57:36.200 --> 57:42.520]  там какой-то стол эго рифмов повторных надо вычислить, чёрт его знает, ну фигня какая-то. И не то,
[57:42.600 --> 57:51.040]  что оно уже есть. Мало того, что оно есть, оно повсюду, оно повсеместно. Знаете,
[57:51.040 --> 57:56.360]  какой резкий скачок в проявлении свойств случайного графа. Такого почти, наверное,
[57:56.360 --> 58:04.840]  нет нигде вообще, нигде, а такое есть почти везде. Я всегда в этом месте цитирую рекламу,
[58:04.840 --> 58:12.920]  даже в маленьком кусочке есть лесной орех. Это довольно маленький кусочек, в общем,
[58:12.920 --> 58:18.160]  ну так. Я его сначала плохо нарисовал, он всё-таки маленький, но орешек-то ещё гораздо меньше,
[58:18.160 --> 58:24.480]  конечно. Вот такое вот удивительное утверждение. Почему оно сразу решает нашу задачу про оценку
[58:24.480 --> 58:28.920]  хроматического числа, это я сейчас объясню. Давайте, вот на оставшейся доске. Это как раз
[58:28.920 --> 58:33.520]  просто совершенно. Если мы верим в справедливость Леммы, которая удивительно совершенно звучит,
[58:33.520 --> 58:38.680]  вот для неё как раз нужна опять концентрация меры. Чебышёвского неравенства не хватит отнюдь.
[58:38.680 --> 58:46.080]  Оно докажет только, что есть такое множество, что оно повсюду есть, оно не докажет. Вот. Значит,
[58:46.080 --> 58:54.440]  как решать задачу? Ну, давайте вот это событие, как обозначим буквой А. Всё вот это событие,
[58:54.440 --> 59:09.240]  всё вот это событие. Это всё буква А. Рассмотрим любой граф из А. Ну, вероятность такого же
[59:09.240 --> 59:15.560]  стремиться к единице, это мы поверили. Вероятность вот этого события, что же попадает в А,
[59:15.560 --> 59:21.480]  конечно, стремится к единице. А симпатически почти, наверное. Вот. Но если мы просто посмотрим на
[59:21.480 --> 59:27.480]  любой конкретный граф, почти любой, да? Почти любой. То каким свойством он обладает? Ну,
[59:27.480 --> 59:35.360]  ещё раз, рисую картину. Вот этот граф. У него повсюду есть довольно большие лесные орешки,
[59:35.360 --> 59:44.600]  островки независимости. Ну, давайте возьмём какой-нибудь один такой островок и покрасим
[59:44.600 --> 59:51.400]  его в первый цвет. Мы же можем независимое множество красить в один цвет. Можем? По
[59:51.400 --> 59:59.000]  определению. Взяли, он точно есть. У нас сколько вершин осталось? Ну, я имею в виду, что этот
[59:59.000 --> 01:00:04.200]  островок будет размером в точности к1. Если есть больше либо равные, давайте в точности к1 возьмём
[01:00:04.200 --> 01:00:10.800]  вершин. Тех, которые можно спокойно покрасить в один цвет. У нас останется n вычесть к1 вершин,
[01:00:10.800 --> 01:00:17.960]  правильно? Но у нас же всюду есть независимое множество размера к1. Найдём ещё одно и покрасим
[01:00:17.960 --> 01:00:25.160]  его в второй цвет. Граф же таким свойством обладает. Наша-то цель, да конечно, почти любое
[01:00:25.160 --> 01:00:30.400]  обладает. Это трудно. Но если он обладает, то ясно. Вот нашли одно, потом нашли второе,
[01:00:30.400 --> 01:00:36.520]  потом также третье. Покрасили в третий цвет. Сколько можно таких островков независимости выделить?
[01:00:36.520 --> 01:00:51.120]  Да, наверное, но не совсем. Потому что нам-то важно, чтобы кусок, в котором мы ищем вот этот кусок,
[01:00:51.120 --> 01:00:56.960]  в котором есть лесной орех, чтобы он был хотя бы размером m. Как только мы выкинем столько множеств
[01:00:56.960 --> 01:01:03.640]  мощности к1, что у нас не останется м вершин, мы уже не сможем гарантировать даже для этого графа,
[01:01:03.640 --> 01:01:11.040]  что среди оставшихся вершин есть независимый кусочек. Я бы сказал вот так. n-m поделить на
[01:01:11.040 --> 01:01:18.840]  k1. Целая часть. Вот столько шагов мы проделаем, после чего у нас останется, ну, вообще говоря,
[01:01:18.840 --> 01:01:24.040]  уже не больше, чем m вершин или примерно m. Поэтому мы не сможем после этого уже гарантировать
[01:01:24.040 --> 01:01:31.280]  наличие там островочка независимости. Так понятно говорю? Вот это количество цветов,
[01:01:31.280 --> 01:01:40.080]  которые мы наберем к тому моменту времени. Но после этого останется не больше, чем m вершин
[01:01:40.080 --> 01:01:50.040]  вот этого графа g, который пока что не покрашен. После того, как мы выбрали столько цветов каждой
[01:01:50.040 --> 01:01:57.640]  мощности k1, у нас остается не больше, чем m не покрашенных вершин. Дайте каждую из них покрасим
[01:01:57.640 --> 01:02:04.520]  свой отдельный новый цвет. То есть цветов будет в итоге вот столько, как максимум.
[01:02:10.520 --> 01:02:17.560]  Ну, m бесконечно мало по сравнению с n, поэтому вот эта штука ведет себя симпатически как n
[01:02:17.560 --> 01:02:27.480]  поделить на k1, то есть как n поделить на 2 двоичных логарифм n. А это бесконечно мало по сравнению с
[01:02:27.480 --> 01:02:39.000]  n поделить на лог двоичный n. Потому что на логарифм в квадрате делится. Ну и все. Значит, вся эта
[01:02:39.000 --> 01:02:44.840]  сумма тоже вот такую асимптотику имеет. Любой граф, который находится в событии а, может быть
[01:02:44.840 --> 01:02:51.040]  покрашен бы симпатически столько цветов. Ну, можно отсюда выделить явный вид функции phi от n,
[01:02:51.040 --> 01:03:02.440]  который у нас получился, но кажется, что это не очень важно. Так, понятно объяснил? Вот, то есть все
[01:03:02.440 --> 01:03:09.680]  теорема доказана, но по модулю это сложного утверждения. Сейчас я подпишу бумаги там снаружи,
[01:03:09.680 --> 01:03:16.960]  и в принципе кажется, что можно тоже устроить пятиминутный перерыв на стирание с доски. Так,
[01:03:16.960 --> 01:03:22.360]  ну, видимо мы вернулись, да? Давайте пытаться доказывать лемму. Ну, как я тут в кулуарах говорил,
[01:03:22.360 --> 01:03:27.160]  это длинная, конечно, история. То есть мы сейчас ее сведем к чему-то, потом это еще к чему-то,
[01:03:27.160 --> 01:03:34.600]  но ничего. Значит, так, прежде всего давайте напишем отрицание этого утверждения и будем
[01:03:34.600 --> 01:03:39.360]  оценивать вероятность сверху, доказывая, что она в итоге будет стремиться к нулю. Ну,
[01:03:39.360 --> 01:03:51.120]  то есть прямо честно напишем вероятность уже от того, что существует s из v мощности m такое,
[01:03:51.120 --> 01:04:06.400]  что α от g на s не больше, чем k1. Это же отрицание, правильно? Так, ну, кажется совершенно очевидным,
[01:04:06.400 --> 01:04:13.240]  что какая разница, какое именно множество мощности m смотреть. Случайный граф однороден.
[01:04:13.240 --> 01:04:19.200]  Если мы выделили в нем кусок размера m, то фактически он просто индуцирует такой случайный
[01:04:19.200 --> 01:04:26.000]  подграф на m вершинах. Я понятно говорю или это страшно звучит? Ну, а раз это понятно,
[01:04:26.000 --> 01:04:30.960]  тогда вероятность существования, как обычно, не больше, чем сумма, и мы просто вот так напишем
[01:04:30.960 --> 01:04:39.800]  эту сумму. Ну ладно, и надо даже сумму писать. Ну что, я же вроде все сказал. Сумма превращается
[01:04:39.800 --> 01:04:48.560]  в c из n по m одинаковых слаганин. Она просто превращается в c из n по m умножить на вероятность.
[01:04:48.560 --> 01:04:55.040]  Ну, вот тут я временно нарисую буквку m, подчеркивая, что вот эта вероятность в отличие от вот этой
[01:04:55.040 --> 01:05:03.440]  будет на графе с m вершинами. Ну, а здесь уже будет просто альфа от g не превосходит k1. Вот так.
[01:05:03.440 --> 01:05:10.280]  Если вдруг кого-то смущает, что я здесь написал букву g и здесь написал букву g,
[01:05:10.280 --> 01:05:16.240]  я, конечно, могу здесь написать букву h, но, я надеюсь, понятно здесь же имеется в виду просто,
[01:05:16.240 --> 01:05:23.360]  где, где, где? Вот здесь мера множества всех таких графов g. То есть g это не единственный граф,
[01:05:23.360 --> 01:05:27.760]  а это просто обозначение типичного представителя из множества тех графов,
[01:05:27.760 --> 01:05:32.000]  которые обладают вот этим свойством. И здесь то же самое. Мы берем просто какой-то граф,
[01:05:32.000 --> 01:05:36.040]  который обладает вот этим свойством, но среди всех графов уже на m вершинах.
[01:05:36.040 --> 01:05:49.040]  Может, я сложно как-то выразился, но смысл-то вроде простой. gm написать? Нет, ну gm. Не,
[01:05:49.160 --> 01:05:55.640]  ну формально надо вообще, знаете, как писать? Здесь g, а в скобках n запитает 1 вторая,
[01:05:55.640 --> 01:06:01.440]  а здесь g и в скобках m запитает 1 вторая. Тогда вот это, конечно, писать не нужно. То есть всякий
[01:06:01.440 --> 01:06:06.800]  раз, когда я здесь пишу g, я, конечно, должен по-хорошему писать все вот это обозначение для
[01:06:06.800 --> 01:06:14.840]  случайного элемента, но это страшно. Ну, давайте я m здесь напишу хорошо, как вам удобнее, но могу
[01:06:14.840 --> 01:06:20.800]  вообще его не писать. Но просто вот надо помнить, что вот в этом месте мы переходим от n вершинных
[01:06:20.800 --> 01:06:27.560]  к m вершинным случайным графам. Я могу вообще нигде m не рисовать. Я это пояснил, вы запомнили
[01:06:27.560 --> 01:06:36.160]  все. Вот здесь m вершинные все. Так, ну я не буду долго нудить по поводу того, что такое c из n по m.
[01:06:36.160 --> 01:06:42.280]  Вот здесь специально для нас сохранили напоминание о том, что такое m. Можно, конечно, очень аккуратно
[01:06:42.280 --> 01:06:50.520]  по стирлингу посчитать и сдохнуть. Конечно, это что-то субэкспоненциальное. Это не экспонента.
[01:06:50.520 --> 01:06:56.840]  Вы помните первую лекцию курса? Экспонента там получается только, если вы берете c из n почему-то
[01:06:56.840 --> 01:07:06.400]  линейно-зависящему от n. По а n. c из n по а умножить на n. Вот тогда будет экспонента. Если там не а умножить
[01:07:06.400 --> 01:07:13.800]  на n в c-шке наверху, а что-то вот такое, например, то это уже будет субэкспонента, конечно. Ну,
[01:07:13.800 --> 01:07:20.080]  суб-то суб. Уж точно не линейное ничего-нибудь и уж точно не полином. Будет какая-то жуткая биака,
[01:07:20.080 --> 01:07:28.240]  которая растет, если не экспоненциально, то очень близко к тому. Короче, я тупо оценю это как 2 в
[01:07:28.240 --> 01:07:35.280]  степени n, но просто чтобы по мне не придирались и не говорили мне, что вот это я здесь оценил,
[01:07:35.280 --> 01:07:43.160]  вот эту вот вероятность как 2 в степени n, вот поэтому-то мне пришлось использовать неравенство
[01:07:43.160 --> 01:07:49.200]  зумы. Нет, не поэтому. Если бы я даже честно сосчитал вот эту штуку и ее асимптотику,
[01:07:49.200 --> 01:07:54.880]  ну было бы что-то чуть меньше, чем 2 в степени n, типа 2 в степени n поделить алгорифом n. Все равно биака.
[01:07:54.880 --> 01:08:01.560]  Ничего хорошего не будет. Поэтому я тупо оценю, но неравенство зумы такое мощное, что даже вот эта
[01:08:01.560 --> 01:08:07.720]  тупая оценка с запасом пройдет. А неравенство чебышова здесь не катится совсем, я это даже покажу.
[01:08:07.720 --> 01:08:15.720]  Ну здесь опять пишем альфа дже, не превосходит к1, по-прежнему не забывая, что тут уже всюду
[01:08:15.720 --> 01:08:30.360]  букс к м. А вот тут н, ну это по делу. Так, ну смотрите, можно я чуть-чуть поиздеваюсь? Чуть-чуть.
[01:08:32.040 --> 01:08:38.880]  Ну так, чуть-чуть. Маленькая такая вставочка, свидетельствующая о том, почему неравенство
[01:08:38.880 --> 01:08:46.000]  чебышова здесь не работает. Этого я мог не делать, потому что мне же надо доказать теорему. Я могу
[01:08:46.000 --> 01:08:51.120]  просто взять, сразу привезти здесь неравенство зумы и все получить. Но я хочу, чтобы вы поняли,
[01:08:51.120 --> 01:08:57.800]  просто чем азума здесь спасает. Почему неравенство чебышова не работает. Я хочу, чтобы это как-то
[01:08:57.800 --> 01:09:02.680]  усвоилось. Поэтому вставочка сейчас будет неправильное. Продолжение доказательства называется.
[01:09:02.680 --> 01:09:07.640]  Попытка доказать с помощью неравенства чебышова. Что значит доказать с помощью неравенства
[01:09:07.640 --> 01:09:13.840]  чебышова? Ну очень просто. Надо написать вот так. 2 в степени n умножить на вероятность того,
[01:09:13.840 --> 01:09:22.680]  что x... А, кстати, я неправильно написал. Меньше строго. Меньше строго. Отрицание не совсем
[01:09:22.680 --> 01:09:28.320]  правильно написал. Там же было больше либо равно. Отрицание это строго меньше. Ну мелочь,
[01:09:28.320 --> 01:09:35.320]  конечно, но так приятнее. Тогда действительно будет корректно написать вот так. xk1adg равняется нулю.
[01:09:35.320 --> 01:09:43.800]  Так, кто-нибудь еще помнит, что такое x с индексом kadg? Количество независимых множеств на k вершинах.
[01:09:43.800 --> 01:09:52.160]  У нас сегодня такое было. Вот утверждение о том, что альфа меньше, чем k1. Мы сегодня тоже это
[01:09:52.160 --> 01:09:58.760]  вспоминали, равносильно тому, что x с индексом k1 равен нулю. Нет ни одного независимого множества
[01:09:58.760 --> 01:10:06.640]  на вершинах в таком количестве. Так, дальше можно переписать вот так. Ну, во-первых, вот так написать.
[01:10:06.640 --> 01:10:14.000]  Я надеюсь, что это не очень кокает, чтобы еще там дважды переписывать. Величина заведомо не отрицательная,
[01:10:14.000 --> 01:10:20.400]  конечно, но я для красоты добавил. И дальше стандартно. У нас уже было. Можно было даже на
[01:10:20.400 --> 01:10:29.000]  него сослаться, но вы его забыли, поэтому я его напишу заново. 2 в степени n, вероятность e xk t1,
[01:10:29.000 --> 01:10:37.040]  которая, как вы помните, еще fk t1 от m обозначалась. Кстати, минус xk1, но это неважно, я просто
[01:10:37.040 --> 01:10:50.680]  напоминаю, e xk1 х, ну и применить неравенство Чебышова. 2 в степени n умножить на d xk1 поделить на
[01:10:50.680 --> 01:10:59.280]  e xk t1 в квадрате. Ну, было у нас такое неравенство, я еще говорил, что его можно вообще всегда применять,
[01:10:59.280 --> 01:11:03.920]  не только для какого-нибудь конкретного числа, но для любого, который считает что-нибудь
[01:11:03.920 --> 01:11:11.600]  не отрицательное. Ну и все, и облом нас подстерег, потому что мат ожиданий xk t1,
[01:11:11.600 --> 01:11:23.360]  пойдемте сюда. Вот оно, мне его тут очень хорошо сохранили, эта величина m в кубе. Ну то есть в
[01:11:23.360 --> 01:11:29.900]  знаменателе стоит что-то порядка m в шестой степени, и рассчитывать на то, что такая дробь забьет
[01:11:29.900 --> 01:11:36.980]  экспоненту, или даже субэкспоненту вот эту, ну не приходится, товарищи, ну никак. Видите,
[01:11:36.980 --> 01:11:41.580]  это всего одной строчки хватило, чтобы убедиться, что неравенство Чебышова здесь ну вообще не катит.
[01:11:41.580 --> 01:11:48.300]  Именно из-за того, что мы попытались доказать вездесущесть вот этих независимых множеств,
[01:11:48.300 --> 01:11:53.580]  что в каждом кусочке есть лесной орех, если бы не было вот этого каждого кусочка вот этого
[01:11:53.580 --> 01:11:59.020]  сомножителя, то конечно нам бы удалось доказать стремление к нулю вот этой величины, все было бы
[01:11:59.020 --> 01:12:05.060]  классно. Понимаете, да? Но нам надо в каждом кусочке, иначе вот тот алгоритм, который я там
[01:12:05.060 --> 01:12:11.900]  прописывал, не сработает по краске. Нам в каждом надо. Нам надо как-то эту экспоненту чем-то забить,
[01:12:11.900 --> 01:12:20.460]  поэтому я вот это все зачеркиваю, прям зачеркиваю, не стираю, чтобы вы видели,
[01:12:20.460 --> 01:12:28.820]  что это неправильный ход рассуждения. Дальше я говорю следующее, но смотрите, если бы xkt1 было бы
[01:12:28.820 --> 01:12:36.900]  Липшицева, то можно было бы не зачеркивать, а попробовать вот все вот это превратить неравенство
[01:12:36.900 --> 01:12:47.420]  Азумы. Но xkt1 нифига не Липшицева. Количество независимых множеств. Представьте себе,
[01:12:47.460 --> 01:12:53.420]  у вас было две вершины, соединенных ребром, и вот тут была целая туча независимых множеств. Тут
[01:12:53.420 --> 01:13:07.340]  была целая... ну понятно. Кок? Или наоборот надо рисовать? Ну понятно, да? То есть одно ребро удалили.
[01:13:07.340 --> 01:13:16.340]  А, понял, наоборот. Вот так было. Туча независимая. Кок наоборот, вот такой кок. Провели ребро,
[01:13:16.340 --> 01:13:21.220]  и все, они все пропали, они перестали быть независимыми. То есть добавление всего одного
[01:13:21.220 --> 01:13:29.020]  ребра, и тем более порчат нам какой-то окрестности вершины, и куча всего порушится. Никакой тут нету
[01:13:29.020 --> 01:13:34.260]  Липшицевости. То есть к иксу не получится применить неравенство Азумы ну никак. То есть надо
[01:13:34.260 --> 01:13:40.260]  вычеркивать и вообще забывать. Надо придумывать какую-то величину, которая удовлетворяла бы
[01:13:40.260 --> 01:13:45.260]  неравенство Азумы, и равенство нулю которой было бы равносильно вот этому неравенству.
[01:13:45.260 --> 01:13:54.180]  Быстро произнесли? Понятно. У нас была понятная случайная величина хкт. Ее равенство нулю,
[01:13:54.180 --> 01:13:58.740]  конечно, равносильна вот этому неравенству. Но она оказалась не Азумлемой.
[01:13:58.740 --> 01:14:09.060]  Не применима неравенство Азумы. Так, цветочек-то я сотру с независимой множеством. Вот. Она не
[01:14:09.060 --> 01:14:18.420]  удалась. Мы сейчас офигенную величину предложим. укт аж. Ну, в частности, укт первое. Какое
[01:14:18.420 --> 01:14:25.620]  хотите. Вот укт аж. Сейчас будет офигенная величина. Вот это я очень люблю момент.
[01:14:25.620 --> 01:14:43.700]  Давайте я лучше словами скажу. Это максимальное количество или лучше написать. Да, давайте я
[01:14:43.700 --> 01:14:48.980]  лучше все-таки напишу, не словами. Словами скажу, а то долго писать и понятнее не станет. Сейчас
[01:14:48.980 --> 01:14:55.260]  формально напишу. Это максимальное такое, какую букву мы еще не использовали,
[01:14:55.260 --> 01:15:06.140]  Т. Максимальное такое Т, что существует С1 и так далее СТ под множество множества вершин
[01:15:06.140 --> 01:15:24.020]  всего графа. Так. Такие, что для любого И мощность СИТ равняется К. СИТ независимо, ну, в смысле,
[01:15:24.020 --> 01:15:29.540]  что не содержит ребер, независимое множество вершин. И еще, ну ладно, прямо вот здесь продумал,
[01:15:29.540 --> 01:15:40.740]  для любых ИЖ мощность СИТ пересеченного с СИТ не превосходит единицы. О, какое роскошное
[01:15:40.740 --> 01:15:49.060]  определение. Жуть полная. Нет, смысл-то очень простой, но картину надо опять нарисовать. Вот
[01:15:49.060 --> 01:15:56.340]  наше множество вершин В. Ну, кстати, оно теперь у нас из А элементов состоит, потому что мы с таким
[01:15:56.340 --> 01:16:01.460]  графом работаем. Ну так, чтобы не запутаться, сразу напомню. Но это не так важно, можно
[01:16:01.460 --> 01:16:07.300]  определять с любым количеством вершин, конечно. Вот. И мы хотим в нашем конкретном графе, вот в
[01:16:07.300 --> 01:16:14.100]  этом графе же, найти какие-то под множество, которые мало между собой пересекаются. Ну,
[01:16:14.100 --> 01:16:20.180]  тут можно какую-нибудь такую вот сардельечку прицепить, пришпандорить. Немножко она не влезла,
[01:16:20.180 --> 01:16:27.460]  правда. Ну понятно. Рисую плохо. Вот. Чтобы они мало попарно пересекались, но они могут очень
[01:16:27.460 --> 01:16:34.180]  хитро пересекаться. То есть, каждые два не больше, чем по одной общей вершине, но их может быть много
[01:16:34.180 --> 01:16:41.020]  таких. Вот. И чтобы каждый из них был при этом независимым. Ну и каждая мощность СК. То есть,
[01:16:41.020 --> 01:16:48.980]  максимальный размер такой гирлянды ИСК вершинных сарделек, которые попарно пересекаются не больше,
[01:16:48.980 --> 01:16:53.540]  чем по одной вершине. Каждые две имеют не больше, чем одну общую вершину. И при этом все эти
[01:16:53.540 --> 01:17:03.620]  сардельки независимы. Не содержат ряда. Понятно, да, как это устроено? Ну, я часто про это рассказываю,
[01:17:03.620 --> 01:17:11.540]  веселую интерпретацию. Представьте себе, что К равняется тройке. Знаете, есть веселая задача.
[01:17:11.540 --> 01:17:17.980]  Собрались пьяницы. Каждый вечер они собираются на троих, выпивают, потом бьют друг другу морду
[01:17:17.980 --> 01:17:25.660]  и на следующие вечера, и на последующие вечера они уже вместе не пойдут. Вот как долго это может
[01:17:25.660 --> 01:17:39.180]  продолжаться. Это задача про у3 от КМ с чертой. Вот это задача про пьяниц. Ну то есть, если мы берем
[01:17:39.180 --> 01:17:46.180]  полный граф на М вершинах и начинаем в нем выбирать такие треугольники, тройки, но выбирать так,
[01:17:46.180 --> 01:17:51.700]  чтобы каждый вечер они пересекались не больше, чем по одному пьянице. Иначе они уже подрались,
[01:17:51.700 --> 01:17:57.300]  они просто выпивать вместе не хотят. Вот это будет в точности то, что мы сейчас ищем для конкретно
[01:17:57.300 --> 01:18:02.980]  вот этих параметров. Понятно сказал, да? Ну, веселая такая интерпретация, запоминающаяся. То есть,
[01:18:02.980 --> 01:18:09.180]  здесь речь идет о том, что не все К-элементные множество пьяниц в принципе могут собираться. То
[01:18:09.180 --> 01:18:15.260]  есть, речь идет не про полный граф, а про какой-то его подграф. То есть, есть заранее какие-то запреты
[01:18:15.260 --> 01:18:20.900]  на то, как соображать на троих или там на пятерых или на сколько-то. Вот есть заранее те запреты,
[01:18:20.900 --> 01:18:26.780]  которые диктует нам граф. А так нас интересует, как долго может продолжаться это безобразие. Вот
[01:18:26.780 --> 01:18:34.700]  на этом конкретном графе. Такая вот смешная интерпретация. Ну ладно, это очень интересная
[01:18:34.700 --> 01:18:39.180]  задача. Мы про нее будем говорить дальше, а не сегодня, когда будем изучать некоторые
[01:18:39.180 --> 01:18:45.500]  характеристики гиперграфов. Это отдельная, очень важная, интересная история. Там теория
[01:18:45.500 --> 01:18:50.620]  кодирования вылезет, про которую мы когда-то с вами говорили еще на ОКТЧ. Ну, в общем,
[01:18:50.620 --> 01:18:57.180]  это просто как для примера, чтобы весело было. Так, вернемся сюда. Так, друзья, ну на самом деле
[01:18:57.180 --> 01:19:04.140]  совершенно очевидно, что здесь звездочку нарисуем, что звездочка это в точности вероятность того,
[01:19:04.140 --> 01:19:17.220]  что yкт равняется нулю. Ну, если в графе нет независимых множеств, то и размер самой большой
[01:19:17.220 --> 01:19:23.780]  гирлянды из каких-то мало пересекающихся независимых множеств тоже равен нулю. Вроде
[01:19:23.780 --> 01:19:28.740]  ужасное совершенно определение, но тривиальным образом, конечно, yкт равняется нулю. Если вообще
[01:19:28.740 --> 01:19:35.060]  нет ни одного независимого множества на к1 вершине, вообще ни одного, то вы не сможете
[01:19:35.060 --> 01:19:43.540]  собрать гирлянду из таких множеств. Гирлянд будет ноль. Пафос-то в чем? Пафос в том, что,
[01:19:43.540 --> 01:19:49.620]  конечно, эта величина Липшицевая. Но по кому? Понимаете вы или нет?
[01:19:49.620 --> 01:20:02.460]  По вершинам не знаю. По вершинам не знаю. Понимаете, вот тут опять может быть гирлянда вот такая. Вот они
[01:20:02.460 --> 01:20:10.340]  все по одной вершине пересекаются, эти независимые множества. Выкинули эту вершину, и все, не осталось
[01:20:10.340 --> 01:20:15.100]  ни одного независимого множества. Ну, не выкинули, а испортили. Там добавили какие-то ребра вот так,
[01:20:15.100 --> 01:20:22.500]  и не осталось ни одного независимого множества. Понимаете? То есть по вершинам эта величина не
[01:20:22.500 --> 01:20:29.900]  обязана быть Липшицевой и не является. А вот по ребрам является, потому что специально так сделано,
[01:20:29.900 --> 01:20:36.940]  чтобы вот эти сосиски из гирлянды не могли иметь общего ребра. Удаление или добавление каких-либо
[01:20:36.940 --> 01:20:42.660]  ребер не может поменять вот эту структуру больше, чем на единицу, максимальную структуру в графе.
[01:20:42.660 --> 01:20:50.540]  Потому что если бы она поменялась больше, чем на единицу, это бы означало, что у ново появившихся
[01:20:50.540 --> 01:20:55.100]  множеств есть общее ребро, а они вот так вот устроены. Там нет общего ребра.
[01:20:59.100 --> 01:21:04.900]  Вот это такой тонкий момент, который всегда вызывает определенные трудности. Она так замудренно
[01:21:04.900 --> 01:21:18.020]  вымрана, чтобы быть Липшицевой. Если мы предположим, что удаление одного ребра изменяет значение этой
[01:21:18.020 --> 01:21:23.860]  величины больше, чем на единицу, то это означает, что концы этого ребра принадлежат сразу нескольким
[01:21:23.860 --> 01:21:29.740]  независимым множествам, которые были изначально. Но так быть не может, потому что любые два пересекаются
[01:21:29.740 --> 01:21:36.420]  не больше, чем по одной вершине. Поэтому вот она Липшицева по ребрам. Видите, как интересно,
[01:21:36.420 --> 01:21:41.260]  в предыдущей теореме Балабаша была Липшицевость по вершинам, и без нее ничего бы не получилось.
[01:21:41.260 --> 01:21:52.060]  А здесь нам хватит Липшицевости по ребрам. И даже убьем вот эту экспоненту, в отличие от Чебышова,
[01:21:52.060 --> 01:21:58.140]  который не убил. Но это мы выясним. Так, друзья, я не очень взорвался, не слишком сложно рассказываю,
[01:21:58.140 --> 01:22:03.540]  понятно? Я очень стараюсь рассказывать суть, и из-за этого может быть чуть труднее следить тем,
[01:22:03.540 --> 01:22:13.660]  кто хочет записывать формально. Я неправ? Понятно, точно все понятно. Формально я это мог рассказать за
[01:22:13.660 --> 01:22:19.300]  пять минут. Вот просто двигаемся формально, вот вводим такое формальное определение, вот оно равенство,
[01:22:19.300 --> 01:22:27.060]  ну да, она Липшицева. Я потратил на это 20 минут, желая просто пояснить суть происходящую. Вот,
[01:22:27.060 --> 01:22:35.300]  а дальше делаем то же самое. А? Да, это разумный ход. Да, на 2 в степени N, конечно, надо, да,
[01:22:35.300 --> 01:22:41.340]  множить, да, и тут тоже. Так, 2 в степени N, ну а здесь делаем стандартную процедуру,
[01:22:41.340 --> 01:22:51.220]  минус yk1 больше либо равняется 0, 2 в степени N на вероятность того, что, что ты будешь,
[01:22:51.220 --> 01:23:03.860]  на вероятность того, что e yk1 минус yk1 больше либо равняется e yk1. Так, ну я не буду сейчас с вашего
[01:23:03.860 --> 01:23:09.560]  позволения напоминать неравенство азумы в той форме, которая для ребер, вы посмотрите потом
[01:23:09.560 --> 01:23:17.000]  в записи, с прошлого раза или сейчас посмотрите. Вот, значит, здесь получится 2 в степени N умножить
[01:23:17.000 --> 01:23:24.000]  на e в степени минус, ну тут, конечно, а квадрат, но а это то, что стоит справа, то есть математическое
[01:23:24.000 --> 01:23:34.760]  ожидание yк в квадрате. А поделить надо на 2, там, c из чего-то по два, да? Ну, c из m по два,
[01:23:34.760 --> 01:23:41.400]  из m прямо в точности как в той формулировке, потому что сейчас у нас именно мэвершин в нашем
[01:23:41.400 --> 01:23:48.000]  случайном графе. На 2, c из m по 2, ну это просто вот говорю, смотрите утверждение азумы. Я не
[01:23:48.000 --> 01:23:58.160]  рисую дополнительную двойку, потому что тут нет модуля, он мне и не нужен. Так, ну лемма в лемме,
[01:23:58.160 --> 01:24:08.320]  куда же деваться. Лемма в лемме вот так. Ну, это шутка, конечно, но мы лему доказываем,
[01:24:08.320 --> 01:24:13.320]  а чтобы его доказать, но я обещал, уже придется доказать некое еще одно вспомогательное утверждение,
[01:24:13.320 --> 01:24:26.480]  а утверждение сейчас будет такое, eyt больше либо равняется m в квадрате, поделить на 2k1 в четвертый,
[01:24:26.480 --> 01:24:35.480]  умножить на один плюс о малой от единицы. Ну, плюс это на самом деле минус, но вы понимаете,
[01:24:35.480 --> 01:24:40.280]  о малой может быть отрицательным, я это каждый раз напоминаю. Просто не принято писать минус о
[01:24:40.280 --> 01:24:44.880]  малой от единицы, принять плюс, но если неравенство снизу, то имеется в виду, что существует функция
[01:24:44.880 --> 01:24:50.160]  отрицательная, конечно, которая стремится к нулю при нашем параметре, стремящемся к бесконечности.
[01:24:50.160 --> 01:24:57.400]  Так, если поверить в справедливость леммы в лемме, то мы можем продолжить вот это неравенство,
[01:24:57.400 --> 01:25:07.240]  давайте вот так отчертим, у нас получится 2 в степени n на e в степени минус m в четвертый на 2k1 в
[01:25:07.240 --> 01:25:14.880]  восьмой на один плюс о малой от единицы, совсем фигня. Так, это я возвел мат ожидания в квадраты,
[01:25:14.880 --> 01:25:17.840]  поскольку оно с минусом, то неравенство идет в правильную сторону.
[01:25:21.160 --> 01:25:33.280]  Но еще на два, что надо? На 2c и 2c надо поделить, да? А на что еще? Какую-то двойку потерял?
[01:25:33.280 --> 01:25:46.280]  Так, так, так, так, так, подождите. А, вот здесь 4k1 в восьмой, да? Вот здесь 4,
[01:25:46.280 --> 01:25:52.880]  ну, 4, конечно, да, 4. Да, да, да, еще в знаменателе 2c из m по 2, ну,
[01:25:52.880 --> 01:25:58.480]  2c из m по 2 это асимптотический m в квадрате, а асимптотика у нас уже
[01:25:58.480 --> 01:26:05.880]  тут написана, так что не жалко. Давайте я вообще вот так напишу, все, сразу, чтобы не переписывать.
[01:26:05.880 --> 01:26:13.240]  Было m в четвертый, потом разделили вот на этот m в квадрате, двойки сократились, а асимптотика пошла сюда.
[01:26:16.920 --> 01:26:22.720]  m в четвертый на 4k1 в восьмой, но m в четвертый сократилось вот с этим m в квадрате.
[01:26:30.720 --> 01:26:39.200]  Где? Здесь? Здесь пофиг абсолютно. Здесь совершенно пофиг, потому что запасом стремится к нулю.
[01:26:39.200 --> 01:26:48.200]  Смотрите, тут стоит 2 в степени n, ну, давайте я напомню здесь прямо, что m это асимптотический n поделить на логарифа в квадрате n.
[01:26:48.200 --> 01:27:00.560]  А? Асимптотика сюда пойдет. Ну, то есть, это равно 2 в степени n на e в степени минус n в квадрате поделить на...
[01:27:00.560 --> 01:27:16.520]  Чего? На 4k1 в восьмой и на логарифом в четвертый. Ну, в квадрат m возводим.
[01:27:16.520 --> 01:27:24.000]  Вот здесь еще логариф m в четвертой степени. Ну, и там какая-то фигня, 1 плюс о малые от единицы.
[01:27:24.000 --> 01:27:31.120]  Так, ну, может быть, кто-то забыл, что k1 это 2 лог 2kn.
[01:27:31.120 --> 01:27:40.560]  То есть, k1 в восьмой, это логарифом в восьмой степени. Тут еще логарифом в четвертой степени.
[01:27:40.560 --> 01:27:47.440]  Но будет логарифом в двенадцатой степени с какой-то константой, с какой-то асимптотикой. Да наплевать!
[01:27:47.440 --> 01:27:55.480]  Потому что на этот логарифом в двенадцатой степени делится n в квадрате, а тут с плюсом всего лишь n.
[01:27:55.480 --> 01:28:04.320]  С плюсом идет n, а с минусом идет n в квадрат поделить на какую-то дурацкую степень логарифма.
[01:28:04.320 --> 01:28:10.640]  Конечно, вычитаемая забивает n с огромным запасом, то есть это стремится к нулю.
[01:28:10.640 --> 01:28:14.240]  Все. Со свистом стремится к нулю. Отлично все.
[01:28:14.240 --> 01:28:31.840]  Вот, честно говоря, я бы не мучил вас сейчас и вот эту лему и завершение доказательства доказывал бы уже в раз следующий.
[01:28:31.840 --> 01:28:38.880]  Потому что это еще час. Мы так, в принципе, больше полутора часов говорим. Я могу начать,
[01:28:38.880 --> 01:28:44.800]  могу, но это сейчас некоторых усилий потребует. У меня время формально есть. Я могу.
[01:28:44.800 --> 01:28:56.080]  Не против чего? А, доказательства. А слушатели, которые там ли, все умерли уже. Там-то хоть кто-нибудь остался?
[01:28:56.080 --> 01:28:58.480]  Или только те, кто сюда пришел?
[01:28:58.480 --> 01:29:11.680]  Офигели, наверное, уже от происходящего. Ну, я не знаю, очень надеюсь, что нет. По-моему, все довольно так, но нетривиально, потому что много.
[01:29:11.680 --> 01:29:16.560]  Много. Вот я поэтому думал, что может быть продолжить в следующий раз. Что тут, конечно.
[01:29:16.560 --> 01:29:22.080]  Ну, смотрите, я на самом деле все-таки предлагаю в следующий раз, но что я хочу сделать прямо сейчас?
[01:29:22.960 --> 01:29:31.200]  Я хочу прокомментировать это. Опять в терминах условных пьяниц. Ну, или просто, даже без пьяниц, просто прокомментировать.
[01:29:31.200 --> 01:29:39.840]  Смотрите, вот если мы возьмем yкт от km с чертой, вот в этом смысле про условных пьяниц.
[01:29:39.840 --> 01:29:43.120]  Так, а все понимают, что km с чертой это просто пустой граф на мэ вершинах?
[01:29:45.120 --> 01:29:51.520]  km это полный граф на мэ вершинах, km с чертой это пустой граф на мэ вершинах. Без единого ребра.
[01:29:52.480 --> 01:30:00.160]  Вот если мы рассмотрим такую величину, то она очевидно не больше, она очевидно не больше,
[01:30:00.160 --> 01:30:06.240]  чем, ну очевидно не очевидно, это мы сейчас обсудим, чем c из m подва. Запомните это, кстати,
[01:30:06.240 --> 01:30:12.960]  это будет потом, нам тоже потребуется когда-нибудь, на c из k подва. Но это может не очевидно.
[01:30:12.960 --> 01:30:26.840]  Ну ладно, я объясню. Значит, что такое yкт от km с чертой? Ну, это значит,
[01:30:26.840 --> 01:30:32.160]  что мы берем какую-то такую вот гирлянду из сосисок, то есть цепочку из кавершинных независимых
[01:30:32.160 --> 01:30:38.560]  множеств, вот в этом пустом графе. Ну, то есть просто цепочку каких-то k-элементных под множество,
[01:30:38.560 --> 01:30:43.320]  м-элементного множества, правильно? Лишь бы они пересекались каждые два не больше,
[01:30:43.320 --> 01:30:48.640]  чем по одному элементу, по одной вершине. Ну, давайте их как-нибудь обозначим, а1,
[01:30:48.640 --> 01:30:59.120]  а, s1 они обозначались, вот пусть будет s1 и так далее, st. s1 и так далее, st. Это будут те самые
[01:30:59.120 --> 01:31:04.400]  независимые множества, которые образуют гирлянду. То есть мощность каждого из них это k,
[01:31:08.560 --> 01:31:21.320]  отлично. Так, вот смотрите, как бы это обозначить-то. Дайте я словами скажу,
[01:31:21.320 --> 01:31:28.000]  сколько всего отсутствует ребер в множестве s1, оно независимое, ну, сколько в нем всего отсутствует
[01:31:28.000 --> 01:31:36.520]  ребер. Понятно, что csk по 2, и тут тоже отсутствует csk по 2 ребер. Значит, суммарно отсутствует
[01:31:36.520 --> 01:31:47.360]  сколько ребер? t умножить на csk по 2, правильно? Причем общих отсутствующих ребер нет. Они не
[01:31:47.360 --> 01:31:54.440]  пересекаются эти множества. Множество отсутствующих ребер не пересекаются, потому что сами эти
[01:31:54.440 --> 01:32:00.000]  множества пересекаются только по одной вершине или вообще не пересекаются. Значит, здесь свое
[01:32:00.000 --> 01:32:07.920]  множество отсутствующих ребер, тут свое, тут какое-то тт по счету. Так, это суммарное количество
[01:32:07.920 --> 01:32:18.160]  отсутствующих ребер. А всего ребер вот в этом смешном графе отсутствует csk по 2. Это всего,
[01:32:18.160 --> 01:32:25.280]  сколько в нем отсутствует ребер. Ну, так ясно, что соотношение вот такое. Все, я доказал вот
[01:32:25.280 --> 01:32:34.080]  неравенство. Это действительно очевидно, надо просто написать, чуть подумать. Поняли, да? Вот,
[01:32:34.080 --> 01:32:40.680]  то есть верхняя оценка имеет, ну скажем так, порядок роста m квадрат поделить на k квадрат.
[01:32:40.680 --> 01:32:47.360]  Ну, роста там или чего-то, порядок своей величины. m квадрат поделить на k квадрат. То есть утверждение
[01:32:47.360 --> 01:32:55.160]  леммы нетривиально в том смысле, что когда мы заменяем абсолютно пустой граф на случайный
[01:32:55.160 --> 01:33:03.240]  его под граф, то в среднем, если мы и теряем, то не более чем какую-то логарифмическую в квадрате
[01:33:03.240 --> 01:33:11.840]  величину в знаменателе. Тут верхняя оценка вот такой величины, а тут нижняя, ну почти такое же. Тут
[01:33:11.840 --> 01:33:22.240]  было k квадрат, тут становится k в четвертый. Значит, друзья, если вас еще так заводит прямо от чистой
[01:33:22.240 --> 01:33:29.160]  математики, то я вам так скажу. Гипотеза, которая, по-моему, до сих пор не доказана и не опровергнута,
[01:33:29.160 --> 01:33:34.720]  вот я ее не встречал, доказательства, пока что, состоит в том, что даже в этой лемме четверку
[01:33:34.720 --> 01:33:42.120]  вообще можно на двойку заменить, ну поставишь тут какую-то большую константу. Никто не может доказать.
[01:33:42.120 --> 01:33:48.880]  То есть утверждается, что, знаете, вот это просто пустой граф, в нем вообще нет ни одного ребра,
[01:33:49.040 --> 01:33:56.000]  а тут случайный граф, то есть половина ребер возникает в среднем. Реброядность, ребра одна-вторая же,
[01:33:56.000 --> 01:34:02.160]  правда? Значит, вот у этого случайного графа половина ребер откуда-то появляется. Тем не менее утверждается,
[01:34:02.160 --> 01:34:09.920]  что вот эти сосиски не набегут, вернее, не пропадут, не пропадут, не съедятся. Их
[01:34:09.920 --> 01:34:15.760]  все равно будет порядка столько же, сколько верхняя оценка, вот эта простая верхняя оценка. Я понятно
[01:34:15.760 --> 01:34:22.200]  объясняю, да? Ну ладно, в общем, вот это нам предстоит доказать. Я все-таки хочу, чтобы люди,
[01:34:22.200 --> 01:34:28.200]  которые готовы в четверг, уже не в выходной день, честно прийти на лекцию, с удовольствием послушали,
[01:34:28.200 --> 01:34:34.880]  как это доказывается. Потому что доказывается это очень красиво. Мы доказываем вероятностное утверждение,
[01:34:34.880 --> 01:34:40.400]  добавляя в доказательстве некую дополнительную случайность, и за счет этой дополнительной
[01:34:40.400 --> 01:34:45.000]  случайности удается все доказать. Но там придется довольно много аккуратно объяснять,
[01:34:45.000 --> 01:34:50.440]  ничего сложного нет, но надо просто, чтобы вы прочувствовали. Но очень красиво. Вероятностным
[01:34:50.440 --> 01:34:57.680]  методом доказывается вероятностное утверждение. Строго говоря, до шести я, наверное, бы уложился,
[01:34:57.680 --> 01:35:03.400]  но что-то мне вот кажется, что время у нас пока есть в семестре, давайте все это продолжим в четверг.
[01:35:03.400 --> 01:35:12.320]  Но, по крайней мере, вроде мы традицию это разбили. Я остановился, конечно, не доказав всю теорему,
[01:35:12.320 --> 01:35:18.200]  но тут нет никакой страшной формулы, которую нужно доказывать в следующий раз. В следующий раз я
[01:35:18.200 --> 01:35:22.640]  просто напоминаю, что такое YK, и мы прямо начинаем доказывать это утверждение. Думаю,
[01:35:22.640 --> 01:35:33.760]  что за пару мы за все завершим. Аккуратно, спокойно. Что еще раз? Да-да-да, это проблема
[01:35:33.760 --> 01:35:39.080]  нерешенная. То есть можно ли четверку заменить на двойку, мы не знаем. Ничего не знаю. По-моему,
[01:35:39.080 --> 01:35:43.960]  как четвертый, это самое лучшее, что известно. Вот по-моему, это самое лучшее, что известно.
[01:35:43.960 --> 01:35:51.400]  Я не встречал других утверждений, но это удивительно совершенно. С точки зрения вот этой задачи убрать
[01:35:51.400 --> 01:35:55.720]  какую-то степень логарифмов знаменателя, но это никакого значения не имеет. Что вы видите,
[01:35:55.720 --> 01:36:02.920]  это двенадцатая степень, ну, сто сорок пятая, какая хотите. Вот. Если просто интересоваться тем,
[01:36:02.920 --> 01:36:06.840]  а насколько же плотно сконцентрировано, можно ли улучшить это неравенство. Есть
[01:36:06.840 --> 01:36:10.720]  альтернативные неравенства, более сильные в некоторых случаях, чем неравенство Азу.
[01:36:10.720 --> 01:36:15.800]  Называется неравенство Тологра. Я про них здесь рассказывать не буду. Но вообще,
[01:36:16.560 --> 01:36:21.960]  завершая лекцию, еще один важный комментарий. Мы много рассуждаем про неравенство плотной
[01:36:21.960 --> 01:36:27.000]  концентрации мира. Чебышов сломался, вот у нас Азума сработала. А кроме Азумы,
[01:36:27.000 --> 01:36:31.240]  сейчас вот прозвучало, есть какие-то Толограны еще. Но Тологранов я рассказывать не буду.
[01:36:31.240 --> 01:36:37.040]  Вот если кого-то, может, по ту сторону экрана и здесь присутствующих, протаскивает, так сказать,
[01:36:37.040 --> 01:36:40.680]  не только от чистой математики, в которой доказываются вот такие офигенные теоремы,
[01:36:40.680 --> 01:36:49.560]  но еще и от каких-то таких явлений прикладной математики, то есть не совсем сугубой прикладухи,
[01:36:49.560 --> 01:36:56.520]  но когда стык, вроде как, и чистая математика, и в то же время бах, и какие-то приложения. Я вам
[01:36:56.520 --> 01:37:01.600]  скажу, что вот эта вся деятельность неравенства плотной концентрации меры исключительно важна
[01:37:01.600 --> 01:37:06.800]  для задач оптимизации. Вот задача оптимизации в очень существенной степени повязана на то,
[01:37:06.800 --> 01:37:11.960]  как плотно сконцентрирована мера около какого-то своего среднего. И вот все эти неравенства Zoom,
[01:37:11.960 --> 01:37:16.640]  это Лограна и так далее, они там используются на пропалую, а оптимизация это, по сути,
[01:37:16.640 --> 01:37:22.520]  машинное обучение и статистика. То есть это уже, конечно, прямые приложения, и вот у нас тоже
[01:37:22.520 --> 01:37:27.000]  люди этим занимаются, в тот же Гасниках, например, очень много про это рассказов. Но это так в сторону.
[01:37:27.000 --> 01:37:31.400]  Ну ладно, тогда на сегодня все.
