[00:00.000 --> 00:10.000]  Смотрите, мы, к сожалению, опять не успели в прошлый раз завершить некое доказательство,
[00:10.000 --> 00:14.000]  но в данном случае, мне кажется, нам не стоит начинать его повторять сначала,
[00:14.000 --> 00:21.000]  как это было в начале прошлой лекции. Оно длинное было, и мы свели всю историю к выкладке.
[00:21.000 --> 00:27.000]  То есть нам надо оценить некую ужасную сумму. Вы это помните, нет?
[00:28.000 --> 00:31.000]  То есть вы готовы к тому, что у нас будет чистый анализ сейчас,
[00:31.000 --> 00:35.000]  а уже комбинаторика вся была в прошлый раз в этом месте.
[00:35.000 --> 00:39.000]  Так, но мне надо, наверное, напомнить, или, может быть, я сам вспомню.
[00:39.000 --> 00:43.000]  Давайте, значит, во-первых, я помню, что у нас был вот такой параметр.
[00:43.000 --> 00:52.000]  Целая часть от n поделить на 1 минус епсилон лог 2-ичный n.
[00:52.000 --> 01:02.000]  Дальше у нас были чиселки a1 и так далее, a с индексом m, каждая из которых была не больше, чем...
[01:05.000 --> 01:09.000]  А, да, да, да, да, конечно, здесь двойка, спасибо, да.
[01:09.000 --> 01:14.000]  Да, каждая из которых не больше, чем вот эта как раз величина, да.
[01:18.000 --> 01:21.000]  А тут без двойки, да, сейчас, а почему тут без a?
[01:22.000 --> 01:27.000]  Да, да, да, конечно, тут без двойки, да. Да, да, да, конечно, тут двойка не нужна, правильно.
[01:27.000 --> 01:31.000]  Меньше просто, чем 1 минус епсилон лог 2-ичный n.
[01:31.000 --> 01:43.000]  И дальше у нас были множество c1 и так далее, cm такие, что мощность цитова равняется аитому.
[01:43.000 --> 01:51.000]  И была жутковатая сумма, в которой внешнее m-кратное суммирование вот по всем таким чиселкам в этих пределах,
[01:51.000 --> 01:57.000]  внутреннее m-кратное суммирование по всем таким множествам мощности m, мощности аитое,
[01:57.000 --> 02:00.000]  но так что они еще попарно не пересекаются.
[02:00.000 --> 02:03.000]  Было такое, да? Важно, что суммировалось.
[02:03.000 --> 02:11.000]  Значит, суммировалось, наверное, вот такая бяка, произведение по i от единицы до m,
[02:11.000 --> 02:24.000]  1 минус 1 на 2 в степени аитое, все это, вот это все в степени он пополам, да?
[02:24.000 --> 02:27.000]  Вот так.
[02:27.000 --> 02:33.000]  Да ладно, на самом деле все просто.
[02:33.000 --> 02:38.000]  Ну, во-первых, аитое, каждое, не превосходит вот этой величины, да?
[02:38.000 --> 02:47.000]  Значит, 2 в степени аитое, стоящее в знаменателе, не превосходит n в степени 1 минус эпсилон.
[02:47.000 --> 02:53.000]  Соответственно, если вы переворачиваете, то есть берете единицу, поделите на 2 в степени аитое,
[02:53.000 --> 03:00.000]  то будет больше либо равно соответствующей дроби, а еще раз со знаком минус снова будет меньше либо равно.
[03:00.000 --> 03:03.000]  Но наша цель доказать, что вся сумма стремится к нулю.
[03:03.000 --> 03:12.000]  Значит, у нас получается, что это меньше либо равно, опять произведение по i от единицы до m,
[03:12.000 --> 03:22.000]  1 минус 1 поделенное на n в степени 1 минус эпсилон, и все это в степени n попало.
[03:22.000 --> 03:28.000]  Так? Вроде так.
[03:28.000 --> 03:38.000]  Эти произведения суммировались по всем a1am и c1cm, да. Я же это проговорил. Нет разве?
[03:38.000 --> 03:45.000]  Мы как бы зафиксировали во внешнем суммировании вот эти числа, во внутреннем вот эти множество.
[03:45.000 --> 03:51.000]  Как бы мы их не зафиксировали, то произведение, которое суммируется, оценивается так, как я написал.
[03:51.000 --> 03:58.000]  Ну потому что каждая ита не больше этой величины, а дальше сначала стало больше либо равно, потом снова меньше либо равно.
[03:58.000 --> 04:01.000]  То есть знак неравенства в нужную сторону.
[04:01.000 --> 04:08.000]  Дальше пользуемся стандартным соображением, что если вы возьмете какой-нибудь 1 минус п,
[04:08.000 --> 04:14.000]  то это е в степени логарифм от 1 минус п, и соответственно это не больше, чем е в степени минус п.
[04:14.000 --> 04:18.000]  Ну такое стандартное неравенство, которое мы уже не раз использовали.
[04:18.000 --> 04:20.000]  Было такое ведь, да?
[04:20.000 --> 04:22.000]  Ну и здесь то же самое.
[04:22.000 --> 04:27.000]  П у нас в данном случае это вот эта величина, 1 поделить на n в степени 1 минус эпсилон.
[04:27.000 --> 04:31.000]  У нас получается меньше либо равно.
[04:31.000 --> 04:39.000]  Значит, тут получается е в степени минус 1 поделенное на n в степени 1 минус эпсилон,
[04:39.000 --> 04:46.000]  умноженное на m и возведенное в степени n пополам.
[04:46.000 --> 04:49.000]  Но можно было сразу умножить на n пополам.
[04:49.000 --> 04:53.000]  Так, я понятно объяснил, откуда это взялось.
[04:53.000 --> 04:59.000]  Мы каждую скобку оценили как е в степени 1 поделенное на n в степени 1 минус эпсилон,
[04:59.000 --> 05:06.000]  скобок m штук, и еще это все в степени n пополам.
[05:06.000 --> 05:18.000]  То есть вот так получается е в степени mn пополам 1 поделить на n в степени 1 минус эпсилон,
[05:18.000 --> 05:28.000]  или можно вот так написать е в степени mn в степени эпсилон пополам.
[05:28.000 --> 05:30.000]  А, минус потерялся, да, спасибо.
[05:30.000 --> 05:32.000]  Здесь минус, здесь тоже минус, конечно, это важно.
[05:32.000 --> 05:35.000]  Нам надо стремление к нулю получить, а не к бесконечности.
[05:35.000 --> 05:37.000]  Это понятно, да.
[05:37.000 --> 05:41.000]  Так, ну вон видим, какой у нас там m.
[05:42.000 --> 05:45.000]  Ну чего не превосходит?
[05:45.000 --> 05:48.000]  Я не знаю, ну давайте я скажу, что оно не превосходит.
[05:48.000 --> 05:51.000]  n поделить на лог двоичный n.
[05:51.000 --> 05:56.000]  Коль скоро n больше либо равняется какого-то, n первого.
[05:56.000 --> 06:00.000]  Что? Еще раз?
[06:02.000 --> 06:05.000]  А, больше либо равно, да, нам же нужно больше либо равно.
[06:05.000 --> 06:09.000]  Ну хорошо, меньше либо равно может тоже пригодиться, не знаю, а может и нет.
[06:09.000 --> 06:12.000]  Хорошо, давайте, да, больше либо равно, это проще.
[06:12.000 --> 06:17.000]  Оно, очевидно, больше либо равно n поделить на 2 лог двоичный n.
[06:17.000 --> 06:21.000]  Ну просто потому что 1 минус эпсилон меньше единицы.
[06:21.000 --> 06:25.000]  Ну тоже может быть, начиная с какого-то очень небольшого n,
[06:25.000 --> 06:32.000]  потому что я целую часть снял, но я думаю, что это уже слишком такое ковыряние в очевидных вещах.
[06:32.000 --> 06:38.000]  Так, меньше либо равно е в степени минус n стало.
[06:38.000 --> 06:45.000]  n стало снова в степени 1 плюс эпсилон, но надо поделить на 2 лог двоичный n.
[06:45.000 --> 06:48.000]  Ну, если хотите, я еще вот так напишу.
[06:48.000 --> 06:52.000]  Ясно, что поскольку эпсилон мы зафиксировали заранее,
[06:52.000 --> 06:58.000]  то n в степени эпсилон с какого-то момента, конечно, превосходит логарифом.
[06:58.000 --> 07:00.000]  И превосходит существенно.
[07:00.000 --> 07:05.000]  Ну, то есть, вот, начиная с какого-нибудь там очередного n1 или n2, не важно,
[07:05.000 --> 07:14.000]  мы можем написать е в степени минус n в степени 1 плюс, скажем, эпсилон попало.
[07:17.000 --> 07:22.000]  Убрать этот 2-логариф на двоичный n паразитически он не нужен.
[07:23.000 --> 07:24.000]  Что?
[07:26.000 --> 07:28.000]  Четыре потерял, да?
[07:28.000 --> 07:29.000]  А почему?
[07:29.000 --> 07:31.000]  А, я вот эту двойку потерял.
[07:31.000 --> 07:33.000]  Чего ж я так сегодня, а?
[07:33.000 --> 07:34.000]  Ну, строго говоря, четыре.
[07:34.000 --> 07:36.000]  Давайте все-таки писать, как правильно.
[07:36.000 --> 07:40.000]  Понятное дело, что я и четверкой здесь пренебрегу с большим удовольствием.
[07:40.000 --> 07:41.000]  Вот.
[07:41.000 --> 07:42.000]  Но, тем не менее.
[07:43.000 --> 07:45.000]  Конечно, так правильнее.
[07:45.000 --> 07:46.000]  Вот.
[07:46.000 --> 07:53.000]  Ну, а теперь вспоминаем, что у нас есть внутреннее суммирование вот это по c1 и так далее cm.
[07:53.000 --> 08:00.000]  И суммируются теперь у нас величины е в степени минус n в степени 1 плюс эпсилон пополам.
[08:00.000 --> 08:04.000]  Ну, видно, что эти величины не зависят от c1, cm вообще никак.
[08:06.000 --> 08:07.000]  Правда же?
[08:09.000 --> 08:17.000]  Ну, то есть, вся эта сумма, она равна количеству способов зафиксировать вот эти множества c1, cm.
[08:17.000 --> 08:21.000]  И это количество умножается просто на такую вот константу.
[08:21.000 --> 08:24.000]  Ну, в кавычках, конечно, константу по c1, cm.
[08:24.000 --> 08:25.000]  Вот.
[08:25.000 --> 08:41.000]  Ну, формально тут получается c из n по a1, c из n минус a1 по a2, c из n минус a1, минус и так далее, минус am, ой, am минус 1, по am.
[08:43.000 --> 08:49.000]  Не путать с полинамиальным коэффициентом, потому что сумма вот здесь вот все-таки не равна нулю.
[08:49.000 --> 08:55.000]  Ну, потому что 1 ам, они там выбираются до серединки примерно от n, до половинки от n.
[08:55.000 --> 08:56.000]  Вот.
[08:56.000 --> 09:02.000]  Но мы-то по-дурацки это считаем на е в степени минус n в степени 1 плюс эпсилон пополам.
[09:02.000 --> 09:08.000]  Мы по-дурацки сейчас эти цешки оценим с огромным запасом, но, к сожалению, эпсилон это не поможет убрать.
[09:11.000 --> 09:15.000]  Ну, то есть, вот смотрите, в нашей формулировке эпсилон больше нуля это важно.
[09:16.000 --> 09:19.000]  Заменить эпсилон на ноль не получится, сейчас вы увидите.
[09:20.000 --> 09:23.000]  Даже если здесь аккуратнее оценить, не получится ничего.
[09:23.000 --> 09:25.000]  Но мы оценим идиотским образом.
[09:25.000 --> 09:27.000]  Мы это оценим вот так.
[09:28.000 --> 09:36.000]  n в степени a1 плюс и так далее, плюс am, на е все в той же степени 1 плюс эпсилон попало.
[09:37.000 --> 09:39.000]  n в степени 1 плюс эпсилон попало.
[09:42.000 --> 09:43.000]  Поняли откуда, да?
[09:43.000 --> 09:48.000]  Ну, просто c из чего-то почему-то уж точно меньше, чем это в степени это.
[09:49.000 --> 09:53.000]  А n-а1 меньше, чем n, n-это меньше, чем n.
[09:53.000 --> 09:55.000]  Вот я так тупо оценил.
[09:55.000 --> 09:57.000]  Но реально это ни на что не влияет.
[09:57.000 --> 10:00.000]  Понимаете, потому что в знаменателе написать вот эти факториалы,
[10:00.000 --> 10:05.000]  так это факториалы чисел, которые порядка лог 2хn, от этого ничего не изменится.
[10:06.000 --> 10:08.000]  Но это так, чтобы вы понимали.
[10:08.000 --> 10:12.000]  Формально я могу про это не говорить, но оценил, победители сейчас судить не будут.
[10:12.000 --> 10:15.000]  Победители не судят, а я сейчас победю.
[10:17.000 --> 10:22.000]  Так, а1 плюс и так далее плюс am мы знаем, это меньше либо равно n пополам.
[10:23.000 --> 10:27.000]  То есть все это меньше либо равно n в степени n пополам,
[10:28.000 --> 10:32.000]  на е в степени минус n в степени 1 плюс эпсилон пополам.
[10:33.000 --> 10:39.000]  Это равняется е в степени n пополам логарифм n
[10:40.000 --> 10:46.000]  минус n в степени 1 плюс эпсилон пополам.
[10:49.000 --> 10:55.000]  Но это еще не все, потому что мы пока не разобрались с внешним суммированием по а1 на m.
[10:57.000 --> 11:01.000]  Мы зафиксировали а1 на m и разобрались с внутренним суммированием.
[11:01.000 --> 11:03.000]  Вот оно так оценивается.
[11:04.000 --> 11:06.000]  Так, друзья, это понятно или нет?
[11:07.000 --> 11:09.000]  Непонятна оценка? Все понятно?
[11:10.000 --> 11:11.000]  Нормально, да?
[11:11.000 --> 11:13.000]  Ну смотрите просто, если что-то непонятно, лучше спросить.
[11:14.000 --> 11:16.000]  А во внешнем суммировании сколько слагаемых?
[11:17.000 --> 11:18.000]  Ну уж точно меньше.
[11:19.000 --> 11:22.000]  То есть я вот так напишу сумма по а1 и так далее.
[11:23.000 --> 11:28.000]  Ам теперь получается вот этих выражений, которые опять от а1 ам никак не зависят.
[11:28.000 --> 11:35.000]  Н пополам логарифм n минус n в степени 1 прибавить эпсилон пополам.
[11:36.000 --> 11:46.000]  Это меньше тупо, чем лог двоичный n в степени m умножить вот на эту штуку.
[11:47.000 --> 11:51.000]  n пополам минус n в степени 1 плюс эпсилон пополам.
[11:52.000 --> 11:54.000]  Так, откуда я взял это сомножитель, понятно?
[11:54.000 --> 11:57.000]  У нас в этом суммировании m в независимых слагаемых,
[11:58.000 --> 12:01.000]  каждый из которых точно меньше, чем лог двоичный n.
[12:05.000 --> 12:08.000]  Ну то есть выбрать первое слагаемое можно вот таким количеством способов.
[12:09.000 --> 12:10.000]  Второе таким же.
[12:11.000 --> 12:15.000]  Ну у нас получается вот столько способов зафиксировать числа а1 и так далее ам.
[12:16.000 --> 12:17.000]  Ну...
[12:18.000 --> 12:19.000]  Что?
[12:20.000 --> 12:21.000]  Какие логарифмы?
[12:21.000 --> 12:24.000]  А вот здесь потерял. Да что ж такое-то сегодня?
[12:25.000 --> 12:27.000]  Опечатка на опечатке, простите, пожалуйста.
[12:28.000 --> 12:29.000]  Конечно, здесь логарифм.
[12:30.000 --> 12:32.000]  Но от него тоже, понятно, ни тепло, ни холодно.
[12:33.000 --> 12:35.000]  Тут катерсис-то в чем аналитический?
[12:36.000 --> 12:38.000]  В том, что эпсилон все-таки фиксированная константа,
[12:39.000 --> 12:41.000]  и тут к единице какое-то число прибавляется.
[12:42.000 --> 12:43.000]  n в степени какое-то положительное число.
[12:44.000 --> 12:46.000]  А здесь n в первой степени умножается на логарифм.
[12:47.000 --> 12:50.000]  И когда из такой функции вычитается такая, то это со свистом идет в ноль.
[12:51.000 --> 12:54.000]  А вот если эпсилон заменить на ноль, то ничего не получится.
[12:55.000 --> 12:56.000]  Логарифм важен.
[12:57.000 --> 12:58.000]  Понятно говорю, да?
[12:59.000 --> 13:01.000]  Вот. Но это вообще фигня.
[13:02.000 --> 13:04.000]  Все-таки не зря я m оценил сверху тоже.
[13:05.000 --> 13:06.000]  Пригодилось.
[13:07.000 --> 13:15.000]  Это меньше, чем e в степени n делить налог двоичный n.
[13:16.000 --> 13:17.000]  Это оценка n.
[13:18.000 --> 13:19.000]  Это оценка для m.
[13:19.000 --> 13:21.000]  И умножить на повторный...
[13:22.000 --> 13:23.000]  Ой, какой повторный логарифм.
[13:24.000 --> 13:26.000]  Логарифм натуральный внешний, а внутри логарифм двоичный.
[13:27.000 --> 13:28.000]  Гениально.
[13:29.000 --> 13:30.000]  Но это все равно повторный логарифм по порядку.
[13:31.000 --> 13:32.000]  Даже асимпатически это неважно.
[13:33.000 --> 13:34.000]  Ой.
[13:35.000 --> 13:38.000]  Ну и вот плюс вот это n пополам на логарифм n,
[13:39.000 --> 13:44.000]  минус n в степени 1, плюс эпсилон попал в показатель экспонента.
[13:45.000 --> 13:48.000]  Но это слагаемое еще меньше, чем вот это.
[13:49.000 --> 13:52.000]  Оно даже меньше, чем n, потому что делится налог двоичный,
[13:53.000 --> 13:54.000]  а умножается налог повторный.
[13:55.000 --> 13:59.000]  Вот это меньше, чем n.
[14:00.000 --> 14:02.000]  Это больше, чем n, но в логарифм раз.
[14:03.000 --> 14:06.000]  А вычитаемое больше, чем n, в n в какой-то положительной степени раз.
[14:07.000 --> 14:11.000]  Поэтому все вот это вычитаемое, вся вот эта разность, сумма разности,
[14:12.000 --> 14:15.000]  она стремится к минус бесконечности, а экспонент от нее стремится к нулю.
[14:16.000 --> 14:17.000]  Теорема доказана наконец.
[14:18.000 --> 14:21.000]  Вы поймите, тут ничего сложного нет, очень грубые оценки.
[14:22.000 --> 14:28.000]  Главное придумать вот эту вот идею, что жадный алгоритм наловил много маленьких множеств,
[14:29.000 --> 14:31.000]  потому что ничего к ним добавить дальше не сумел.
[14:32.000 --> 14:36.000]  И вот за счет того, что он много чего не сумел добавить, получается вот такое вот понижение.
[14:37.000 --> 14:41.000]  m умножить на n гораздо больше, чем n в степени 1, минус эпсилон.
[14:42.000 --> 14:43.000]  Вот в этом смысл.
[14:43.000 --> 14:46.000]  А дальше это просто такая тупая техника стандартная, тут ничего особо умного нет.
[14:51.000 --> 14:52.000]  Вот.
[14:53.000 --> 14:57.000]  Ну, что я вам хочу еще про жадный алгоритм сказать, давайте я все-таки прокомментирую.
[14:58.000 --> 15:02.000]  На самом деле, это прямо проблема открытая.
[15:02.000 --> 15:06.000]  Существуют ли хоть какие-нибудь полиномиальные алгоритмы,
[15:06.000 --> 15:08.000]  которые
[15:12.000 --> 15:14.000]  опроксимировали
[15:15.000 --> 15:17.000]  и,
[15:18.000 --> 15:20.000]  ну,
[15:21.000 --> 15:23.000]  и
[15:24.000 --> 15:26.000]  и
[15:27.000 --> 15:29.000]  и
[15:30.000 --> 15:32.000]  и
[15:33.000 --> 15:35.000]  опроксимировали
[15:37.000 --> 15:39.000]  бы
[15:43.000 --> 15:45.000]  ну, скажем, альфа от g,
[15:46.000 --> 15:48.000]  или, что то же самое, хи от g.
[15:49.000 --> 15:53.000]  Химы не обсуждали, там технически чуть посложнее, ну, пусть будет альфа, так понятнее.
[15:54.000 --> 15:58.000]  Значит, существуют ли полиномиальные алгоритмы, которые опроксимировали бы вот эти величины
[15:58.000 --> 16:02.000]  с еще большей точностью, в следующем смысле,
[16:03.000 --> 16:05.000]  с точностью
[16:08.000 --> 16:10.000]  до саммножителя
[16:17.000 --> 16:19.000]  строго меньшего двойки?
[16:22.000 --> 16:24.000]  Вот это прямо проблема открытая.
[16:25.000 --> 16:27.000]  Ну, то есть, что мы с вами сейчас доказали?
[16:27.000 --> 16:29.000]  Мы доказали, что если мы возьмем жадный алгоритм,
[16:30.000 --> 16:32.000]  то реальное число независимости
[16:33.000 --> 16:35.000]  по отношению,
[16:36.000 --> 16:38.000]  да, ну, конечно, с точностью до саммножителя меньшего двойки
[16:39.000 --> 16:43.000]  и вероятностью стремящейся к единице на случайном графе,
[16:44.000 --> 16:46.000]  и вероятностью стремящейся к единице.
[16:47.000 --> 16:49.000]  То есть, мы по-прежнему говорим про случайные графы,
[16:50.000 --> 16:52.000]  стремящиеся к единице.
[16:53.000 --> 16:55.000]  Ну, то есть, чтобы они работали не на всех графах,
[16:56.000 --> 16:58.000]  а на почти всех графах, вот такие существуют или нет,
[16:59.000 --> 17:03.000]  мы сейчас доказали, что вот такое отношение меньше
[17:04.000 --> 17:06.000]  либо равняется 2 плюс Эпсилон,
[17:07.000 --> 17:09.000]  ну, просто 2 плюс Эпсилон,
[17:10.000 --> 17:12.000]  а симпатически почти наверно
[17:13.000 --> 17:15.000]  на случайном графе g от n одна вторая,
[17:16.000 --> 17:18.000]  то есть, когда все графы равновозможны, равновероятны.
[17:19.000 --> 17:21.000]  Вот мы это доказали, правильно?
[17:23.000 --> 17:25.000]  Люди умеют убрать вот это Эпсилон,
[17:26.000 --> 17:28.000]  но не для жадного алгоритма,
[17:29.000 --> 17:30.000]  а для некоторого более сложного алгоритма,
[17:31.000 --> 17:32.000]  который тоже работает за полином от n.
[17:33.000 --> 17:35.000]  Работает за полином от n на всех графах,
[17:36.000 --> 17:39.000]  и а симпатически почти наверно дает вот здесь неравенство без Эпсилон.
[17:40.000 --> 17:41.000]  Это люди умеют делать.
[17:42.000 --> 17:44.000]  А вот сделать здесь 2 минус Эпсилон
[17:45.000 --> 17:47.000]  с каким-нибудь строго положительным Эпсилон
[17:48.000 --> 17:50.000]  фиксированным, константный, скажем, 1 и 999.
[17:50.000 --> 17:52.000]  Вот это проблема.
[17:55.000 --> 17:57.000]  Проблема, существует ли такой алгоритм,
[17:58.000 --> 18:01.000]  что α g поделить на α a g
[18:02.000 --> 18:06.000]  меньше либо равняется, скажем, 1, 9, 9, 9,
[18:07.000 --> 18:08.000]  а симпатически почти наверно.
[18:09.000 --> 18:11.000]  Вот в этом проблема, существует ли такой полиномиальный
[18:12.000 --> 18:13.000]  на всех графах алгоритм,
[18:14.000 --> 18:16.000]  который бы давал с вероятностью стремящихся к единице
[18:17.000 --> 18:18.000]  вот такую вот оценку.
[18:20.000 --> 18:21.000]  Похоже, что его не существует.
[18:22.000 --> 18:27.000]  То есть это еще один довод в пользу, как ни странно, жадности.
[18:28.000 --> 18:30.000]  Получается, что жадный алгоритм при всей своей простоте
[18:31.000 --> 18:34.000]  фактически это лучшее, что на случайном графе можно реализовать.
[18:35.000 --> 18:37.000]  Ну да, там Эпсилон можно убрать, конечно,
[18:38.000 --> 18:40.000]  это чуть лучше, но это не бог весть что.
[18:41.000 --> 18:44.000]  Убрать вот эту двойку, ее, по-видимому, в принципе не получится.
[18:45.000 --> 18:46.000]  Настолько сложная задача,
[18:46.000 --> 18:48.000]  что даже на почти всех графах
[18:49.000 --> 18:51.000]  нету, по-видимому, такого алгоритма,
[18:52.000 --> 18:53.000]  который работал бы за полином
[18:54.000 --> 18:55.000]  и при этом выдавал бы результат,
[18:56.000 --> 18:57.000]  отличающийся от правильного,
[18:58.000 --> 18:59.000]  не больше, чем вот в такую константу раз,
[19:00.000 --> 19:01.000]  или там 10 девяток, напишите.
[19:02.000 --> 19:03.000]  Все равно, по-видимому, такого нет.
[19:04.000 --> 19:05.000]  Я понятно объяснил?
[19:06.000 --> 19:09.000]  Это довольно любопытная вещь, конечно.
[19:10.000 --> 19:11.000]  С другой стороны, конечно,
[19:12.000 --> 19:15.000]  ну все вы интуитивно понимаете, что где-то вас обманывают.
[19:16.000 --> 19:18.000]  Ну потому что есть же, наверное, графы,
[19:19.000 --> 19:20.000]  на которых это все не работает.
[19:21.000 --> 19:22.000]  Подумаешь, на почти всех работает.
[19:23.000 --> 19:24.000]  Что значит на почти всех?
[19:25.000 --> 19:26.000]  Всего графов сколько?
[19:27.000 --> 19:28.000]  Два в степени c и n по 2, правильно,
[19:29.000 --> 19:30.000]  вот столько всего графов.
[19:31.000 --> 19:33.000]  А что значит на почти всех?
[19:34.000 --> 19:35.000]  Это значит, вычтем отсюда какое-то количество,
[19:36.000 --> 19:37.000]  которое бесконечно мало,
[19:38.000 --> 19:39.000]  по сравнению с этой величиной.
[19:40.000 --> 19:41.000]  Ну, например, два в степени n лог н.
[19:42.000 --> 19:43.000]  Это тоже величина, которая бесконечномала,
[19:44.000 --> 19:45.000]  по сравнению с два в степени н квадрат.
[19:46.000 --> 19:52.000]  на самом деле может быть не обслужено нашим алгоритмом, тем не менее у нас получится почти все.
[19:52.000 --> 19:56.000]  То есть некоторая обман, конечно, в этом присутствует.
[19:56.000 --> 20:05.000]  И, к сожалению, вот на этом остаточном множестве, да, оно бесконечно мало по сравнению с главным слагаемым,
[20:05.000 --> 20:09.000]  но вот на этом остаточном множестве есть совершенно убийственные примеры ситуации.
[20:09.000 --> 20:15.000]  Сейчас я сформулирую теорему, которую не буду доказывать, но которую считаю важным всегда говорить,
[20:15.000 --> 20:19.000]  потому что она свидетельствует уже против жадного алгоритма.
[20:19.000 --> 20:23.000]  То есть тут надо смотреть, что выбирать в каждой конкретной ситуации.
[20:23.000 --> 20:28.000]  Все-таки бывают такие графы, на которых все вообще ужасно.
[20:28.000 --> 20:35.000]  Сейчас я объясню, что именно.
[20:35.000 --> 20:41.000]  Давайте прежде всего заметим, что во всем вот этом вот рассуждении, во всей этой истории, которую я сейчас рассказал,
[20:41.000 --> 20:46.000]  номерация вершины изначально была фиксирована.
[20:46.000 --> 20:51.000]  Мы даже никак не пользовались тем, что мы имеем право выбирать номерацию.
[20:51.000 --> 20:55.000]  Понятно, да? Ну и вроде все уже хорошо.
[20:55.000 --> 21:00.000]  Вот сейчас я про эти номерации немножко скажу. Страшная вещь.
[21:00.000 --> 21:05.000]  Так. Как бы это сказать?
[21:05.000 --> 21:08.000]  Доказал я Кучера.
[21:14.000 --> 21:17.000]  Сейчас попробую сказать.
[21:17.000 --> 21:21.000]  Существует... Нет, не существует.
[21:21.000 --> 21:27.000]  Для любого эпсилон и для любого дельта большего нуля
[21:27.000 --> 21:32.000]  существует последовательность графов
[21:39.000 --> 21:46.000]  g с индексом n таких, что мощность v от g с индексом n равняется n.
[21:46.000 --> 21:49.000]  Последность графов на n вершинах, проще говоря.
[21:49.000 --> 21:53.000]  Существует такая последовательность графов на n вершинах,
[21:54.000 --> 21:59.000]  что...
[21:59.000 --> 22:02.000]  Давайте сигмой обозначим номерацию этих вершин.
[22:02.000 --> 22:04.000]  Ну как обычно, перестановку.
[22:04.000 --> 22:06.000]  Сигма маленькая, да?
[22:06.000 --> 22:12.000]  Ну сейчас оно появится на доске, просто я заранее предупреждаю, что сигма будет означать перестановку.
[22:12.000 --> 22:18.000]  Так, как бы мне это лучше написать? Вот здесь напишу.
[22:18.000 --> 22:29.000]  Так, альфа от gn поделить на альфа жадная с индексом сигма.
[22:29.000 --> 22:33.000]  Сейчас я все поясню от gn.
[22:33.000 --> 22:36.000]  И, вероятно, здесь по сигму берется.
[22:36.000 --> 22:41.000]  Больше либо равняется n в степени 1 минус эпсилон,
[22:41.000 --> 22:45.000]  больше либо равняется 1 минус дельта.
[22:45.000 --> 22:46.000]  Во!
[22:46.000 --> 22:49.000]  Так, ничего не понятно, сейчас я все буду пояснять.
[22:49.000 --> 22:52.000]  Ну я старался пояснить, значит, что имеется в виду?
[22:52.000 --> 22:57.000]  Мы здесь не граф берем случайный, а перестановку множества его вершин берем случайный.
[22:57.000 --> 23:04.000]  Ну то есть вероятность каждой перестановки это просто единица поделить на n факториал.
[23:04.000 --> 23:06.000]  Это понятно, да?
[23:06.000 --> 23:10.000]  Граф фиксированный, существует такая последовательность графов,
[23:10.000 --> 23:14.000]  что вот если мы посчитаем реальное число независимости у этого графа
[23:14.000 --> 23:17.000]  и разделим его на то число независимости,
[23:17.000 --> 23:24.000]  которое выдает жадный алгоритм на вот этой вот перестановке сигма,
[23:24.000 --> 23:27.000]  и получится почти n.
[23:27.000 --> 23:34.000]  Вот вероятность того, что на случайной перестановке получится такая ужасная хрень,
[23:34.000 --> 23:38.000]  но согласите, ужасная хрень, реальное число больше,
[23:38.000 --> 23:42.000]  чем то, которое отыщет нам наш замечательный жадный алгоритм
[23:42.000 --> 23:45.000]  почти в n раз, где n количество вершин.
[23:45.000 --> 23:48.000]  Так вот вероятность этого сама тоже почти единица,
[23:48.000 --> 23:53.000]  что мы вольны зафиксировать сколь угодно маленькое ε, сколь угодно маленькое дельта.
[23:53.000 --> 23:57.000]  Ну может быть проще говорить не в терминах вероятности, чтоб было понятнее,
[23:57.000 --> 24:04.000]  просто вам придется перебрать вот столько нумераций,
[24:04.000 --> 24:06.000]  ну что понятное дело невозможно сделать,
[24:06.000 --> 24:11.000]  перебрать вот такое количество нумераций 1 минус дельта на n в степени,
[24:11.000 --> 24:17.000]  и тем не менее вот на этих конкретных графах отношение альфа джен
[24:17.000 --> 24:21.000]  к результату применения жадного алгоритма на вот этих перебранных нумерациях
[24:21.000 --> 24:25.000]  будет настолько ужасным, что дальше ехать некуда.
[24:25.000 --> 24:28.000]  Почти n равняться.
[24:28.000 --> 24:32.000]  Реальное от найденного.
[24:32.000 --> 24:34.000]  Я понятно объяснил?
[24:34.000 --> 24:37.000]  То есть вот в этом вычитаемом маленьком множестве,
[24:37.000 --> 24:41.000]  маленьком по сравнению с количеством всех графов,
[24:41.000 --> 24:44.000]  которая гарантирует доказанная нами теорема,
[24:44.000 --> 24:47.000]  вот в нем есть такие вычурные бяки.
[24:47.000 --> 24:50.000]  То есть на вас может случайно свалиться граф,
[24:50.000 --> 24:54.000]  который имеет асимпатическую вероятность, стремящуюся к нулю,
[24:54.000 --> 24:57.000]  но граф вот из этой последовательности.
[24:57.000 --> 25:02.000]  И тогда случится полное несчастье, потому что вы не в два раза приблизите,
[25:02.000 --> 25:04.000]  как нам гарантирует вот эта теорема,
[25:04.000 --> 25:09.000]  а хуже, чем в n в степени 1-эпсилон раз.
[25:09.000 --> 25:12.000]  С ошибетесь, почти в n раз.
[25:12.000 --> 25:16.000]  Я не знаю, понятен пафос? Нет? Антипафос такой.
[25:16.000 --> 25:20.000]  Ну по сигму это отношение числа, вот я же написал,
[25:20.000 --> 25:25.000]  это отношение числа всех нумераций, в которых будет получаться такой результат,
[25:25.000 --> 25:28.000]  к n факториал, к числу всех нумераций.
[25:28.000 --> 25:32.000]  Ну то есть мы сигму берем с вероятностью 1 поделить на n факториал.
[25:32.000 --> 25:35.000]  У нас случайно не граф, у нас случайно перестановка.
[25:35.000 --> 25:39.000]  P сигма означает просто, что мы вероятно считаем на пространстве,
[25:39.000 --> 25:43.000]  в котором случайно перестановки на множестве вершин вот этого графа.
[25:45.000 --> 25:47.000]  Ух ты господи!
[25:47.000 --> 25:49.000]  Ой, ну я же это написал.
[25:49.000 --> 25:53.000]  Ну давайте я так скажу, мощность множества тех сигма,
[25:53.000 --> 26:00.000]  для которых α от gn поделить на α g сигма от gn,
[26:00.000 --> 26:04.000]  больше либо равняется n в степени 1 минус эпсилон.
[26:04.000 --> 26:07.000]  Вот мощность множества таких нумераций,
[26:07.000 --> 26:11.000]  на которых случилась хрень при применении жадного алгоритма,
[26:11.000 --> 26:14.000]  она больше либо равна, чем вот эта величина,
[26:14.000 --> 26:17.000]  чем 1 минус дельта на n факториал.
[26:17.000 --> 26:20.000]  Вот это в точности то, что здесь написано.
[26:21.000 --> 26:24.000]  Классическое определение вероятности.
[26:24.000 --> 26:27.000]  Это просто отношение числа тех элементарных исходов,
[26:27.000 --> 26:30.000]  которые благоприятствуют тому, что написано в скобках.
[26:30.000 --> 26:33.000]  А элементарные исходы – это сигмы.
[26:33.000 --> 26:36.000]  К числу всех элементарных исходов, к n факториал.
[26:36.000 --> 26:39.000]  Ну вот я этот n факториал, который в знаменателе здесь стоит,
[26:39.000 --> 26:41.000]  перенес вот сюда направо.
[26:41.000 --> 26:43.000]  Сейчас понятно?
[26:43.000 --> 26:48.000]  То есть вам скорее всего придется жуткое количество нумераций перебрать,
[26:48.000 --> 26:50.000]  чтобы уйти вот от этого проклятия.
[26:50.000 --> 26:52.000]  Ну а вы столько перебрать не сможете.
[26:52.000 --> 26:55.000]  Жадный-то алгоритм линейный по числу ребер,
[26:55.000 --> 26:57.000]  а нумерация – n факториал.
[26:57.000 --> 26:59.000]  И все, кронтец.
[27:01.000 --> 27:03.000]  Таких графов мало.
[27:03.000 --> 27:04.000]  И это мы доказали.
[27:04.000 --> 27:07.000]  Они сидят вот в этом каком-то там вычитаемом.
[27:07.000 --> 27:09.000]  Но они есть.
[27:09.000 --> 27:11.000]  И если на вас случайно такой граф капнет,
[27:11.000 --> 27:13.000]  если вы этого хоть немножко боитесь,
[27:13.000 --> 27:16.000]  то вам, наверное, жадный алгоритм применять не стоит.
[27:19.000 --> 27:23.000]  То есть, с одной стороны, на почти всех графах жадный алгоритм
[27:23.000 --> 27:25.000]  дает аппроксимацию вдвое,
[27:25.000 --> 27:28.000]  а с другой стороны, вот на тех, почти никаких,
[27:28.000 --> 27:30.000]  которые остаются,
[27:30.000 --> 27:32.000]  есть такие ужасные ситуации,
[27:32.000 --> 27:36.000]  что он ошибается не вдвое, а в n в степени 1 минус и апсалон раз.
[27:36.000 --> 27:40.000]  И больше того, делает это не на какой-то фиксированной нумерации,
[27:40.000 --> 27:42.000]  как в доказательстве вот этой теоремы,
[27:42.000 --> 27:44.000]  а на почти всех нумерациях.
[27:44.000 --> 27:46.000]  Ну, наверное, сейчас объясню.
[27:47.000 --> 27:48.000]  Вот.
[27:48.000 --> 27:51.000]  Ну, давайте еще немножко позанимаемся хроматическим числом.
[27:51.000 --> 27:55.000]  Я могу, конечно, разбавить эту историю с хроматическим числом.
[27:55.000 --> 27:58.000]  Может быть, даже это стоит сделать, чтобы вам не так скучно было.
[27:58.000 --> 28:01.000]  Есть еще одна очень важная тема,
[28:01.000 --> 28:03.000]  которая касается случайных графов
[28:03.000 --> 28:05.000]  и которую обязательно нужно знать.
[28:05.000 --> 28:07.000]  Я что-то подумал, давайте сейчас пока ее обсудим,
[28:07.000 --> 28:09.000]  а то вы подумаете, что хроматическое число,
[28:09.000 --> 28:11.000]  это типа на нем мир клином сошел.
[28:11.000 --> 28:13.000]  Мы потом к нему вернемся.
[28:13.000 --> 28:15.000]  Оно действительно важное.
[28:15.000 --> 28:17.000]  На нем во многом мир клином сошелся.
[28:17.000 --> 28:21.000]  Но давайте рассмотрим какую-нибудь такую немножко другую тему,
[28:21.000 --> 28:23.000]  чтобы было вкрапление содержательное тоже.
[28:27.000 --> 28:29.000]  Я подумал, что так будет лучше.
[28:30.000 --> 28:32.000]  Я подумал, что так будет лучше.
[28:51.000 --> 28:54.000]  Так, связность случайного графа.
[28:55.000 --> 28:58.000]  Но это такая самая прикладная, наверное, тема.
[28:58.000 --> 29:00.000]  Очевидно, прикладная,
[29:00.000 --> 29:02.000]  потому что связность – это вопрос о том,
[29:02.000 --> 29:05.000]  сохраните ли вы какую-нибудь там конкретную инфраструктуру.
[29:05.000 --> 29:08.000]  То есть представьте себе, что у вас вершина графа –
[29:08.000 --> 29:12.000]  это какие-то компьютеры, которые изначально соединены линиями связи.
[29:12.000 --> 29:15.000]  Потом линии связи могут разрываться,
[29:15.000 --> 29:18.000]  и может граф перестать быть связным.
[29:18.000 --> 29:20.000]  Тогда вы не сможете с какого-то одного компьютера
[29:20.000 --> 29:22.000]  на какой-то другой передавать информацию
[29:22.000 --> 29:25.000]  не только напрямую, но даже по цепочке.
[29:25.000 --> 29:28.000]  Так, друзья, я быстро сказал, или понятно,
[29:28.000 --> 29:30.000]  почему важна связность?
[29:30.000 --> 29:32.000]  Ну елки-палки, случайного графа.
[29:35.000 --> 29:37.000]  Вот мотивацию я очень быстро объяснил,
[29:37.000 --> 29:39.000]  и все-таки можно было понять.
[29:40.000 --> 29:42.000]  То есть представьте себе еще раз,
[29:42.000 --> 29:44.000]  вот у вас такие вершины какие-то,
[29:44.000 --> 29:48.000]  они изначально попарно соединены ребрами.
[29:48.000 --> 29:50.000]  Это могут быть, например, линии связи
[29:50.000 --> 29:52.000]  между какими-то компьютерами.
[29:52.000 --> 29:56.000]  И вот они есть между любыми двумя компьютерами изначально.
[29:56.000 --> 30:01.000]  А потом вы с какой-то вероятностью P сохраняете жизнь каждому ребру,
[30:01.000 --> 30:04.000]  а с какой-то, соответственно, вероятностью Q равной 1-P
[30:04.000 --> 30:06.000]  это ребро удаляете.
[30:06.000 --> 30:08.000]  То есть возникают помехи, например,
[30:08.000 --> 30:11.000]  или может быть как-то прямо кто-то взял
[30:11.000 --> 30:14.000]  и целенаправленно вам кокнул это ребро.
[30:14.000 --> 30:17.000]  Спрашивается, насколько большой или маленькой
[30:17.000 --> 30:20.000]  должна быть вероятность сохранения жизни ребру,
[30:20.000 --> 30:23.000]  чтобы хотя бы по какой-то цепочке можно было
[30:23.000 --> 30:26.000]  передать информацию с одного компьютера на другой.
[30:27.000 --> 30:31.000]  Это и есть вопрос о связанности случайного графа.
[30:31.000 --> 30:34.000]  Ну и вот первая основополагающая теорема,
[30:34.000 --> 30:36.000]  которая, собственно, была доказана здесь
[30:36.000 --> 30:39.000]  Эрда Шамеренни в свое время.
[30:39.000 --> 30:41.000]  Давайте я напишу.
[30:47.000 --> 30:50.000]  Так, она звучит следующим образом.
[30:50.000 --> 30:55.000]  Пусть P это не константа, а функция от N,
[30:55.000 --> 30:57.000]  которая ведет себя вот так.
[30:57.000 --> 31:01.000]  Это C логариф натуральный N поделить на N,
[31:01.000 --> 31:03.000]  где C, естественно, больше нуля,
[31:03.000 --> 31:06.000]  просто какая-то константа.
[31:06.000 --> 31:09.000]  То есть чем больше вершин, тем меньше вероятность того,
[31:09.000 --> 31:11.000]  что мы сохраняем жизнь ребру.
[31:11.000 --> 31:14.000]  В любом случае, если у нас есть вероятность,
[31:14.000 --> 31:17.000]  тем меньше вероятность того, что мы сохраняем жизнь ребру.
[31:17.000 --> 31:20.000]  В любом случае, какой бы ни была эта константа,
[31:20.000 --> 31:24.000]  вероятность сохранения жизни ребра, она стремится к нулю.
[31:24.000 --> 31:28.000]  Тем не менее утверждается, что даже в этих рамках
[31:28.000 --> 31:31.000]  есть две прямо противоположные ситуации.
[31:31.000 --> 31:35.000]  Значит, первая ситуация состоит в том,
[31:35.000 --> 31:41.000]  что если C больше единицы,
[31:41.000 --> 31:47.000]  то асимптатически почти, наверное, случайный граф
[31:51.000 --> 31:55.000]  G от NP связан.
[31:55.000 --> 31:59.000]  И вторая принципиально противоположная ситуация,
[31:59.000 --> 32:02.000]  если C строго меньше единицы,
[32:02.000 --> 32:05.000]  то асимптатически почти, наверное,
[32:05.000 --> 32:08.000]  наоборот случайный граф разваливается.
[32:08.000 --> 32:12.000]  Получайный граф не является связанным.
[32:12.000 --> 32:14.000]  Не связан.
[32:14.000 --> 32:18.000]  Ну, вы, конечно, спросите, что будет, если C равно единицы.
[32:18.000 --> 32:22.000]  Это я вам отвечу и даже более подробно потом, сейчас чуть позже.
[32:22.000 --> 32:26.000]  Вот такая штука в физике называется фазовым переходом.
[32:26.000 --> 32:29.000]  Ну и в математике это слово тоже переняли.
[32:29.000 --> 32:34.000]  То есть резкий скачок асимптатически почти, наверное, одному свойству
[32:34.000 --> 32:38.000]  асимптатически почти, наверное, его противоположности.
[32:38.000 --> 32:44.000]  Видите, да, с практической точки зрения, что это означает?
[32:44.000 --> 32:48.000]  Вот если вернуться к той истории с уничтожающимися ребрами,
[32:48.000 --> 32:52.000]  связями между компами там или между чем-то еще,
[32:52.000 --> 32:54.000]  означает очень простую вещь.
[32:54.000 --> 32:57.000]  То есть у нас очень много изначально вот этих компьютеров.
[32:57.000 --> 33:00.000]  Ну скажем N, я всегда говорю, пусть равняется 2000.
[33:00.000 --> 33:03.000]  Я не знаю, много очень компьютеров.
[33:03.000 --> 33:07.000]  И вы возьмете какой-нибудь C, ну скажем, равное тройке.
[33:07.000 --> 33:09.000]  Оно больше единицы.
[33:09.000 --> 33:14.000]  Можно доказать, что в этом случае не просто вероятность связности стремится к единице,
[33:14.000 --> 33:17.000]  а можно оценить, с какой скоростью она стремится к единице
[33:17.000 --> 33:21.000]  и доказать, что это стремление вот такое, 1 минус 1n.
[33:21.000 --> 33:27.000]  Это оценка снизу вероятности того, что связность сохранится в случайном графе.
[33:27.000 --> 33:29.000]  Вот при таком C равном тройке.
[33:29.000 --> 33:31.000]  Я понятно говорю, да?
[33:31.000 --> 33:33.000]  Тогда что получается?
[33:33.000 --> 33:40.000]  У вас получается, что вероятность сохранения ребра каждого отдельно взятого вот такая.
[33:40.000 --> 33:43.000]  Но это, если вы посчитаете, это примерно две сотых.
[33:43.000 --> 33:47.000]  Две сотых примерно, это вероятность сохранения жизни ребра.
[33:47.000 --> 33:53.000]  То есть 0,98 это вероятность того, что ребро пропадет.
[33:53.000 --> 34:03.000]  Тем не менее, с вероятностью 0,9995, 1 минус 1 2000 граф сохранит связность.
[34:03.000 --> 34:07.000]  Каждое ребро уничтожается с вероятностью 98%.
[34:07.000 --> 34:11.000]  А вот с такой вот вероятностью, без пятидесяти тысячных, тем не менее,
[34:11.000 --> 34:14.000]  по какой-то цепочке вы сможете передать информацию.
[34:14.000 --> 34:18.000]  То есть очень низкая вероятность того, что вы потеряете инфраструктуру,
[34:18.000 --> 34:23.000]  так сказать, возможность передачи информации.
[34:23.000 --> 34:25.000]  А, про C равная единица, да.
[34:25.000 --> 34:27.000]  Про C равной единицы сейчас скажу.
[34:27.000 --> 34:32.000]  Слушайте, ну, наверное, сейчас перерыв будет, нет?
[34:32.000 --> 34:34.000]  Ну, я не знаю, давайте сделаем, наверное.
[34:34.000 --> 34:36.000]  Сейчас как раз 40 минут прошло от начала пары.
[34:36.000 --> 34:39.000]  Конечно, прерывался там на какой-то разговор, но неважно.
[34:39.000 --> 34:41.000]  Давайте сейчас уместно сделать перерыв.
[34:41.000 --> 34:43.000]  Потом скажу, что будет при C равном единице.
[34:43.000 --> 34:45.000]  И начну доказывать эту теорию.
[34:45.000 --> 34:47.000]  Так, про C равной единице.
[34:47.000 --> 34:53.000]  Ну, если просто C равной единице, тогда можно доказать, но я не буду этого делать,
[34:53.000 --> 35:05.000]  что вероятность, с которой g от np связан, стремится к1 поделить на e.
[35:09.000 --> 35:12.000]  Но можно еще точнее сказать, это я тоже не буду доказывать.
[35:12.000 --> 35:14.000]  Докажу только, собственно, теорему.
[35:14.000 --> 35:16.000]  Значит, можно сказать еще точнее.
[35:16.000 --> 35:21.000]  Если p от n имеет вот такой вот вид,
[35:21.000 --> 35:25.000]  logarithm n плюс гамма поделить на n,
[35:25.000 --> 35:29.000]  это ситуация, которая, в принципе, не укладывается в теорему,
[35:29.000 --> 35:31.000]  потому что здесь C константа.
[35:31.000 --> 35:35.000]  А тут получается асимптотика такая, как если бы C равнялась единице.
[35:35.000 --> 35:40.000]  Но все-таки тут еще есть добавочная вот эта слагаемая гамма поделить на n.
[35:40.000 --> 35:47.000]  Да, гамма теперь тоже произвольная константа, причем может быть отрицательная.
[35:47.000 --> 35:54.000]  Вот утверждается, что тогда вот эта вероятность того, что g от np связан,
[35:54.000 --> 36:01.000]  стремится к e в степени минус e в степени минус гамма.
[36:01.000 --> 36:05.000]  Вот так.
[36:05.000 --> 36:13.000]  Ну, понятно, что если γ очень большое положительное, 100 миллионов, например,
[36:13.000 --> 36:16.000]  то e в степени минус гамма это почти 0,
[36:16.000 --> 36:21.000]  ну то есть вот это e в степени, вот это, это почти единица.
[36:21.000 --> 36:26.000]  А если гамма очень большая, но отрицательная, большая по модулю, но отрицательная,
[36:26.000 --> 36:32.000]  минус 100 миллионов, тогда здесь будет e в какой-то очень большой положительной степени,
[36:32.000 --> 36:37.000]  То есть со знаком минус будет очень-очень большое число, а все вместе будет почти ноль.
[36:37.000 --> 36:45.000]  То есть на самом деле фазовый переход, который я докажу, он даже еще более такой быстрый, что ли.
[36:45.000 --> 36:49.000]  Не нужно переключаться с c больше единицы на c меньше единицы.
[36:49.000 --> 36:55.000]  Достаточно прибавить что-то очень большое, чтобы получилось почти что единица,
[36:56.000 --> 37:02.000]  или вычесть что-то очень большое, чтобы была почти ноль вероятности того, что сохранится связность.
[37:02.000 --> 37:05.000]  Сейчас я понятно это объяснил?
[37:05.000 --> 37:09.000]  Чисто просто прокомментировал утверждение, доказывать я это не буду.
[37:09.000 --> 37:15.000]  А теорему, ну, давайте с какого пункта начнем?
[37:15.000 --> 37:21.000]  Неравенство Чебышова я вроде вам рассказал, так что я могу пользоваться немножко попроще второй пункт.
[37:22.000 --> 37:27.000]  Вот как вы думаете, за счет чего скорее всего граф потеряет связность?
[37:27.000 --> 37:30.000]  Что проще всего откалывать от графа?
[37:30.000 --> 37:37.000]  Какие должны появиться компоненты связности в первую очередь?
[37:37.000 --> 37:39.000]  Изолированные вершины, конечно, да.
[37:39.000 --> 37:45.000]  Разорвать граф пополам на двудольные, разорвать просто пополам.
[37:45.000 --> 37:48.000]  Здесь n пополам в вершин, здесь n пополам в вершин.
[37:48.000 --> 37:51.000]  Это значит удалить n в квадрате поделить на четыре ребер.
[37:51.000 --> 37:55.000]  А отцепить одну вершину, это значит удалить n минус одно ребро.
[37:55.000 --> 37:57.000]  Гораздо меньше.
[37:57.000 --> 38:01.000]  То есть интуитивно понятно, что скорее всего должны появляться изолированные вершины.
[38:01.000 --> 38:03.000]  Вот ровно это и произойдет.
[38:03.000 --> 38:11.000]  Итак, вот если мы доказываем пункт два, то давайте мы введем случайную величину х,
[38:12.000 --> 38:17.000]  которая на графе равняется количеству изолированных вершин.
[38:17.000 --> 38:20.000]  То есть вершин, которые имеют степень ноль.
[38:20.000 --> 38:23.000]  Такие компоненты связности из одной вершины.
[38:41.000 --> 38:49.000]  Так, ну, хорошо количество изолированных вершин.
[38:49.000 --> 38:56.000]  Ну давайте посчитаем математическое ожидание для начала.
[38:56.000 --> 38:58.000]  Наверное.
[38:58.000 --> 39:00.000]  А, нет, давайте не так.
[39:00.000 --> 39:02.000]  Потом посчитаем математическое ожидание, дисперсию, все посчитаем.
[39:02.000 --> 39:04.000]  Я объясню, зачем их считать.
[39:04.000 --> 39:06.000]  Главное, зачем их считать.
[39:06.000 --> 39:08.000]  То есть надо применить неравенство Чебышова.
[39:08.000 --> 39:14.000]  Мы хотим доказать, что вот такая вот вероятность стремится к единице.
[39:14.000 --> 39:18.000]  Если мы это докажем, то пункт два будет доказан, правда?
[39:18.000 --> 39:20.000]  Что есть хотя бы одна изолированная вершина.
[39:20.000 --> 39:25.000]  Вот мы хотим доказать, что эта вероятность стремится к единице.
[39:25.000 --> 39:28.000]  Ну давайте это перепишем вот так.
[39:28.000 --> 39:32.000]  Это один минус вероятность того, что х не больше нуля.
[39:32.000 --> 39:34.000]  Просто отрицание события.
[39:34.000 --> 39:36.000]  Оно вот такое.
[39:36.000 --> 39:38.000]  И вы мне скажете, х не может быть отрицательным.
[39:38.000 --> 39:40.000]  А я все-таки неравенство сохраню.
[39:40.000 --> 39:42.000]  Какая разница? Это же правда.
[39:42.000 --> 39:44.000]  Я могу сказать, равно нулю в точности.
[39:44.000 --> 39:46.000]  Но я хочу сохранить неравенство.
[39:46.000 --> 39:48.000]  Все равно это верно.
[39:50.000 --> 39:55.000]  А дальше я сделаю два смешных преобразования таких.
[39:57.000 --> 40:00.000]  Я, во-первых, вот так напишу.
[40:00.000 --> 40:02.000]  Опять переверну знаки,
[40:02.000 --> 40:06.000]  и минус единицу левую и правую часть неравенства под знаком вероятности.
[40:06.000 --> 40:07.000]  Вот.
[40:07.000 --> 40:10.000]  А затем добавлю слева и справа некоторую константу.
[40:10.000 --> 40:12.000]  А именно математическое ожидание х.
[40:12.000 --> 40:14.000]  Это константа.
[40:14.000 --> 40:16.000]  Я напишу единица.
[40:16.000 --> 40:24.000]  Минус вероятность того, что ех минус х больше либо равняется ех.
[40:26.000 --> 40:30.000]  А вот это уже очень похоже на неравенство Чебышова.
[40:30.000 --> 40:32.000]  Как выглядит неравенство Чебышова?
[40:32.000 --> 40:38.000]  Вероятность того, что модуль х минус ех больше либо равняется а,
[40:38.000 --> 40:42.000]  не превосходит дисперсии х, поделенной на а в квадрате.
[40:42.000 --> 40:44.000]  Это вот неравенство Чебышова, правильно?
[40:44.000 --> 40:48.000]  Я описал в прошлый раз, я его доказал фактически в нашем случае.
[40:48.000 --> 40:51.000]  Может быть, это уже были на основном курсе, но неважно.
[40:51.000 --> 40:53.000]  Вот оно такое.
[40:53.000 --> 40:55.000]  А здесь нет модуля, да?
[40:55.000 --> 40:57.000]  Но в остальном все очень похоже.
[40:58.000 --> 41:03.000]  Но согласитесь, что вероятность, с которой выполнено такое неравенство,
[41:03.000 --> 41:11.000]  она не превосходит вероятности, с которой выполнено неравенство с навешанным слева модулем.
[41:11.000 --> 41:17.000]  Потому что модуль, чаще говоря, больше либо равен чего-то, чем сама случайная величина.
[41:17.000 --> 41:21.000]  Модульши это удаляются отрицательные случаи.
[41:21.000 --> 41:23.000]  Больше либо равно, но со знаком минус...
[41:23.000 --> 41:27.000]  Ой, меньше либо равно, но со знаком минус больше либо равно.
[41:27.000 --> 41:29.000]  То есть получается вот так.
[41:29.000 --> 41:39.000]  Больше либо равно один минус вероятность того, что модуль х-ех больше либо равняется ех.
[41:47.000 --> 41:49.000]  Согласны, да?
[41:49.000 --> 41:52.000]  Вот, все, сюда применяем неравенство Чебышова.
[41:52.000 --> 41:57.000]  Эта вероятность не больше, но со знаком минус опять знак неравенства в нужную нам сторону.
[41:57.000 --> 42:05.000]  Больше либо равно один минус дисперсии х поделить на квадрат математического ожидания.
[42:08.000 --> 42:14.000]  Ну и вообще я замечу, что это неравенство ведь никак не использовало специфику этой случайной величины.
[42:14.000 --> 42:18.000]  Мы не использовали никак то, что мы считаем именно количество изолированных вершин.
[42:18.000 --> 42:24.000]  Мы использовали только то, что эта величина принимает неотрицательные целые значения, правильно?
[42:24.000 --> 42:29.000]  Я хочу, чтобы вы для себя просто усвоили, что в принципе такое неравенство можно использовать,
[42:29.000 --> 42:35.000]  коль скорая х это любая совершенно неотрицательно значенная целочисленная случайная величина.
[42:35.000 --> 42:43.000]  Вероятность того, что она отлична от нуля, больше либо равна единице, всегда не меньше, чем один минус вот такая дробь.
[42:43.000 --> 42:46.000]  То есть это некое общее неравенство, очень полезно.
[42:46.000 --> 42:54.000]  То есть теперь нам осталось доказать, что для вот этой конкретной величины, вот в этих конкретных условиях c меньше единицы,
[42:54.000 --> 42:58.000]  вот эта разность стремится к одному, то есть вот эта дробь стремится к нулю.
[43:02.000 --> 43:04.000]  Осталось это доказать, правильно?
[43:05.000 --> 43:07.000]  Сейчас я по-моему кокнул.
[43:07.000 --> 43:14.000]  Ну ладно, тогда давайте считать мат ожиданий дисперсии и убеждаться в том, что дробь в наших текущих условиях стремится к нулю.
[43:16.000 --> 43:38.000]  Так, ну математическое ожидание это очень просто.
[43:38.000 --> 43:40.000]  Это линейность, конечно.
[43:40.000 --> 43:45.000]  Давайте просто сложим индикаторные случайные величины x1 и так далее xn,
[43:45.000 --> 43:58.000]  где x и t это единица, если вершина с номером i изолирована и 0 иначе.
[43:58.000 --> 44:03.000]  То есть мы каждую вершину просто тестируем, на то является она изолированной в графе или нет.
[44:03.000 --> 44:08.000]  Нам на вход поступает граф, мы смотрим, вершина с номером i изолированна или нет.
[44:08.000 --> 44:11.000]  Если изолированная, добавляем в счетчик еще одну единичку.
[44:11.000 --> 44:13.000]  Пользуемся линейностью.
[44:13.000 --> 44:20.000]  Величины, конечно, зависимые, но линейность верна всегда, поэтому можем написать вот так.
[44:25.000 --> 44:28.000]  Ну а чему равно математическое ожидание x этого?
[44:28.000 --> 44:38.000]  1-p, наверное, в степени n-1.
[44:38.000 --> 44:42.000]  1-p в степени n-1, то есть вот так получается.
[44:42.000 --> 44:51.000]  Ну что, конкретная вершина не отправляет ни одного ребра в n-1 оставшуюся.
[44:52.000 --> 44:58.000]  Это 1-p в n-1, а n за счет того, что у нас сумма n одинаковых слагаемых.
[44:58.000 --> 45:05.000]  Повторяю, величины зависимые, поэтому дисперсию так легко не посчитать.
[45:05.000 --> 45:10.000]  Вы знаете, наверное, да, что дисперсия суммы независимых величин от суммы дисперсий.
[45:10.000 --> 45:17.000]  Но в данном случае так не получится, потому что это зависимые величины, но не сильно зависимые, но все-таки зависимые.
[45:17.000 --> 45:26.000]  Поэтому мы честно напишем, что это мат ожидания x в квадрате минус квадрат мат ожидания, одна из формул для дисперсии.
[45:26.000 --> 45:31.000]  И посчитаем, вычитаем, а мы знаем, посчитаем вот это вот уменьшаемое.
[45:31.000 --> 45:35.000]  Второй момент. Посчитаем e x в квадрат.
[45:35.000 --> 45:51.000]  Значит, e x в квадрат, это мат ожидания квадрата вот этой суммы, вот этой суммы, с теми же самыми индикаторами.
[45:51.000 --> 46:03.000]  Честно возводим в квадрат, получаем x1 в квадрате, так далее xn в квадрате, плюс сумма по i неравном g,
[46:03.000 --> 46:11.000]  имеется в виду по упорядоченным парам, поэтому я не пишу двойку перед суммой в качестве сомножителя, а дальше x и t, x и t.
[46:11.000 --> 46:17.000]  Ну то есть просто слагаемых здесь n умножить на n минус 1. Сразу.
[46:17.000 --> 46:29.000]  Затем замечаю, что вот эти квадраты можно вычеркнуть, потому что в квадрат мы возводим величину, которая принимает значение 1 и 0, а значит, я в квадрат возводить не надо.
[46:29.000 --> 46:35.000]  Снова пользуемся линейностью, которая верна всегда.
[46:35.000 --> 46:49.000]  Вот в этой части получаем e x, а в этой части получаем сумму по i неравном g в мат ожиданий произведения x и t на x и t.
[46:49.000 --> 46:55.000]  Что такое произведение x и t на x и t? Это что же индикатор, правда?
[46:55.000 --> 47:03.000]  x и t умножить на x и t. Индикатор чего? Что обе вершины изолированы. Да, вот картина такая.
[47:03.000 --> 47:09.000]  И g, тут еще сарделька из n минус 2 вершин.
[47:09.000 --> 47:20.000]  И вот надо посчитать фактически вероятность того, что и отсюда нет ни одного ребра, и отсюда нет ни одного ребра, и вот этого ребра нет.
[47:20.000 --> 47:26.000]  Правильно? А сколько всего здесь нарисован ребер, которых не должно быть?
[47:26.000 --> 47:33.000]  Нарисовано дважды n минус 2 и плюс 1. 2n минус 3.
[47:33.000 --> 47:44.000]  То есть у нас получается e x, которое мы знаем, плюс n на n минус 1 и 1 минус p в степени 2n минус 3.
[47:44.000 --> 47:50.000]  Что? n минус 2 плюс n минус 2 плюс 1.
[47:50.000 --> 47:56.000]  n минус 2 плюс n минус 2 плюс 1. Это 2n минус 3.
[47:56.000 --> 48:05.000]  Ну, это мало влияет на итоговый результат на самом деле, но, конечно, все-таки хочется написать правильно.
[48:05.000 --> 48:10.000]  В какую сторону корреляция есть между этими величинами?
[48:14.000 --> 48:35.000]  Так, ну все, нам осталось посчитать dx поделить на квадрат математического ожидания.
[48:35.000 --> 48:56.000]  Так, это e x плюс n на n минус 1 на 1 минус p в 2n минус 3 минус e x в квадрате поделить на e x в квадрате.
[48:56.000 --> 48:59.000]  Вот так. Верно?
[48:59.000 --> 49:11.000]  Ключевой момент на самом деле, откуда вылезает вот эта функция и зачем нужно, чтобы c было меньше единицы, он состоит в том, что вот эта дробь стремится к нулю.
[49:11.000 --> 49:19.000]  Сейчас я объясню. Она стремится к нулю, потому что мы сейчас убедимся в том, что мат ожидания наша стремится к бесконечности.
[49:20.000 --> 49:25.000]  Ну, если мат ожидания стремится к бесконечности, тогда вот эта дробь будет стремиться к нулю.
[49:25.000 --> 49:34.000]  Но вот это надо доказать. Смотрите, мат ожидания это n на 1 минус p в n минус 1, я просто переписал формулу.
[49:34.000 --> 49:43.000]  Это n на e в степени n минус 1 логарифм от 1 минус p, стандартная замена.
[49:43.000 --> 50:00.000]  Так, это равняется n на e в степени 1 плюс о малое от единицы на n на p со знаком минус.
[50:00.000 --> 50:09.000]  Ну, то есть логарифм от 1 минус p, поскольку p у нас стремится к нулю, я могу асимпатически заменить на минус p.
[50:09.000 --> 50:15.000]  Логарифм от 1 минус p асимпатически равен минус p, потому что p стремится к нулю.
[50:15.000 --> 50:22.000]  Ну, n минус 1 асимпатически равняется n, конечно. А симптотику я написал вот в таком виде.
[50:22.000 --> 50:30.000]  Вот, теперь смотрите, какой тетрис. E в степени минус 1 плюс о малое от единицы.
[50:30.000 --> 50:47.000]  np это c логарифм n. Получаем n умножить на 1, поделенное на n в степени c, помножить на 1 плюс о малое от единицы.
[50:47.000 --> 50:51.000]  Я надеюсь, вы это видите, потому что e в степени логарифм n это просто n.
[50:51.000 --> 51:01.000]  И вот это просто n, оно прыгает в знаменатель за счет минуса, и в числе в этом показателе остается c умножить на 1 плюс о малое от единицы.
[51:01.000 --> 51:07.000]  Нормально? Успеваете? Ну и все.
[51:07.000 --> 51:14.000]  С у нас больше, меньше одного, правильно? С меньше одного. Мы во втором случае находимся.
[51:14.000 --> 51:20.000]  Поэтому, начиная с некоторого момента, вот это произведение тоже меньше одного, строго.
[51:20.000 --> 51:32.000]  А значит, n поделить на это больше нуля. Ну, в смысле, единица, которая стоит здесь в показателе числа n, если вы из нее вычитаете вот это произведение,
[51:32.000 --> 51:37.000]  то это все равно положительное число. n возводит в какую-то степень, которая положительна.
[51:37.000 --> 51:42.000]  И это действительно стремится к плюс бесконечности, но прямо на грани.
[51:42.000 --> 51:47.000]  Сейчас, друзья, я понятно объяснил или нет? Вроде очень просто.
[51:47.000 --> 51:55.000]  Это стремится к плюс бесконечности, значит, действительно вот эта дробь стремится к нулю.
[51:55.000 --> 52:02.000]  Так, ну здесь у нас что происходит? Ну здесь-то все просто.
[52:02.000 --> 52:09.000]  Смотрите, n на n минус 1 на 1 минус p в степени 2n минус 3.
[52:09.000 --> 52:18.000]  Так, а квадрат математического ожидания это n квадрат 1 минус p в степени 2n минус 2.
[52:18.000 --> 52:23.000]  Так, товарищи, вы услышиваете происходящее? Ну анализ такой идет несложный.
[52:23.000 --> 52:33.000]  Так, куда эта штука стремится? К нулю. А паук единица.
[52:33.000 --> 52:39.000]  Но смотрите, n на n минус 1, это же асимптотический n квадрат.
[52:39.000 --> 52:45.000]  1 минус p в 2n минус 3 на 1 минус p в 2n минус 2, ну давайте я напишу.
[52:45.000 --> 52:53.000]  Вот эта n квадрат сократилась, превратилась в асимптотику, а здесь осталось 1 поделить на 1 минус p.
[52:53.000 --> 52:58.000]  Но p-то стремится к нулю, то есть это асимптотическая единица.
[52:58.000 --> 53:04.000]  p стремится к нулю в любом случае, поэтому это асимптотическая единица.
[53:04.000 --> 53:10.000]  А ех квадрат поделить на ех квадрат это просто единица, правильно?
[53:10.000 --> 53:16.000]  То есть мы берем асимптотический ноль, прибавляем асимптотическую единицу и вычитаем просто единицу.
[53:16.000 --> 53:25.000]  Что мы получаем в пределе? Ноль, конечно, все. Я доказал.
[53:25.000 --> 53:35.000]  Пункт два я доказал. В пределе получаем ноль.
[53:35.000 --> 53:39.000]  Вот это? Я складываю члены.
[53:39.000 --> 53:45.000]  Вот один член очевидно стремится к нулю, потому что мы доказали, что есть стремление к бесконечности ума от ожидания.
[53:45.000 --> 53:50.000]  Потом я смотрю среднее слагаемое, вот оно здесь. Оно асимптотически равно единице.
[53:50.000 --> 53:54.000]  И есть еще одно вычитаемое, которое просто равно единице.
[53:54.000 --> 53:59.000]  Вот вы из асимптотической единицы вычитаете единицу, вы получаете в пределе ноль.
[53:59.000 --> 54:05.000]  И тут в пределе ноль. Сумма двух нулей ноль. Все.
[54:05.000 --> 54:15.000]  Смотрите, что здесь важно. Математическое ожидание, вот вдумайтесь, числа изолированных вершин, оно стремится к бесконечности.
[54:15.000 --> 54:23.000]  Это совсем просто, но этого не хватает для доказательств.
[54:23.000 --> 54:33.000]  Нам еще нужно доказать, что случайная величина достаточно тесно сконцентрирована, как говорят, то есть прижата к своему математическому ожиданию.
[54:33.000 --> 54:43.000]  Представьте себе, что вот есть какое-то среднее, да, оно стремится к бесконечности, но случайная величина ужасно болтается, все больше и больше.
[54:43.000 --> 54:51.000]  Тогда нельзя будет утверждать, что с вероятностью стремящейся к единице она больше либо равна одного, несмотря на то, что среднее растет.
[54:51.000 --> 54:59.000]  Нам нужно было дополнительно доказать, что она около этого растущего среднего плотненько сконцентрирована, и для этого мы использовали неравенство Чебышова.
[54:59.000 --> 55:05.000]  Вот вы вникнете в эту идею, потому что у нас подобные идеи еще будут на курсе возникать.
[55:05.000 --> 55:15.000]  Про еще более плотную концентрацию меры, это очень важно. Неравенство Чебышова это такое неравенство концентрации меры около среднего значения.
[55:15.000 --> 55:25.000]  Без него не получилось бы доказать этот пункт. Хотя то, что мат ожидания стремится к бесконечности, очевидно практически.
[55:25.000 --> 55:33.000]  И вы понимаете, что первый пункт формально отличается тем, что в нем мат ожидания стремится к нулю.
[55:33.000 --> 55:44.000]  Понимаете, да? В чем отличие? То есть фазовый переход ровно на том основан, что в одном случае мат ожидания растет неограниченно, а в другом стремится к нулю.
[55:44.000 --> 55:54.000]  Но опять же, из того, что мат ожидания числа изолированных вершин стремится к нулю, еще не следует, что в графе не появится какая-нибудь компонента связности.
[55:54.000 --> 56:02.000]  Но изолированных вершин нет. Может какие-то другие есть? И это усложняет доказательство пункта 1.
[56:02.000 --> 56:08.000]  Но поскольку время у нас еще какое-то есть, наверное надо начать.
[56:08.000 --> 56:33.000]  Так, ну, пункт 1.
[56:33.000 --> 56:44.000]  Ну, давайте просто посмотрим на вероятность того, что случайный граф не связан.
[56:44.000 --> 56:58.000]  Конечно, это можно в терминах неравенства Маркова записать. Может быть, образцово показательно так и надо было бы сделать, но в данном случае все можно вообще без каких-либо неравенств делать.
[56:58.000 --> 57:04.000]  Мы хотим доказать, что вот эта вероятность в нашем пункте стремится к нулю. Вы согласны, да?
[57:04.000 --> 57:14.000]  Ну а что значит граф не связан? Это значит, что он принадлежит объединению множеств каких-то там несвязанных графов.
[57:14.000 --> 57:34.000]  Ну давайте я так напишу. Это вероятность того, что существует k от единицы до n-1 и существует w из w. w это множество вершин нашего графа.
[57:34.000 --> 57:43.000]  Ну можно так вот написать w из 1 и так далее n. У нас множество вершин. Это числа от единицы до n. Так мы определяли случайный граф.
[57:43.000 --> 58:00.000]  Вот существует w такое, что мощность w равняется k и g, ограниченные на этом множество, это связанная компонента.
[58:00.000 --> 58:16.000]  Вот так. Ну я просто формально переписал то же самое. Что значит граф не связан? Это значит, что в нем есть компоненты связанности размера до n-1.
[58:16.000 --> 58:24.000]  Иначе это бессмыслится полное. Конечно до n-1. Граф не связан, если в нем есть нетривиальная связанная компонента.
[58:24.000 --> 58:33.000]  Вот все, что я написал. Тривиальность некую. Ну существует множество его вершин, которые имеют мощность строго меньшую, чем мощность всего множества вершин.
[58:33.000 --> 58:38.000]  И на котором граф обработан. Кусок графа является связанным и никуда дальше ребра не идут.
[58:38.000 --> 58:52.000]  А я же вроде определял уже в рамках этого курса такую запись. Было, было это g, ограниченные на этом множество просто.
[58:52.000 --> 59:01.000]  То есть мы берем наш граф, рассматриваем в нем кусок и смотрим индуцированный под граф. Я даже определение давал. Индуцированный или порожденный под граф.
[59:06.000 --> 59:10.000]  Нет, я сказал связанная компонента. То есть оно максимальное по включению, да.
[59:10.000 --> 59:35.000]  Ну я могу еще подробнее сказать, что g на w связан, давайте это нам пригодится, g на w связан и для любой вершины не принадлежащей w x нет ребер, нет ребер из x в w.
[59:35.000 --> 59:49.000]  Ну давайте я так напишу, да. То есть что вот этот кусок граф, ограниченный на множество w, он связан, если вы возьмете любую вершину, которая не входит в w, то таких ребер нет.
[59:49.000 --> 59:57.000]  Это и есть связанная компонента, да, совершенно верно. Я фактически это и подразумевал, но так наверное понятнее.
[59:58.000 --> 01:00:02.000]  Тем более, что нам это пригодится. Ну сейчас понятно все, да, что я написал.
[01:00:02.000 --> 01:00:07.000]  Существует нетривиальная связанная компонента, размер которой меньше, чем размер всего графа.
[01:00:07.000 --> 01:00:16.000]  Сколько-то вершин она имеет, есть множество вот этой мощности, на котором кусок графа связанный и наружу никакие ребра не идут.
[01:00:16.000 --> 01:00:22.000]  Соответственно все кванторы существования означают объединение множеств графов.
[01:00:22.000 --> 01:00:29.000]  Мы как всегда, как и в предыдущей теореме, помните, с жадным алгоритмом все кванторы существования оцениваем суммами.
[01:00:29.000 --> 01:00:34.000]  Это понятно? Я сейчас напишу, что это меньше либо равно.
[01:00:34.000 --> 01:00:50.000]  Суммы пока от единицы до n-1, суммы по всем w из 1 и так далее n мощности k.
[01:00:50.000 --> 01:01:10.000]  Ну вот этой вероятности, что g на w связан и для любого x не из w, нет ребер из x в w.
[01:01:10.000 --> 01:01:19.000]  Вот так. Я совершенно не понимаю, как оценивать вероятность того, что граф связан, но поскольку это пересечение двух условий,
[01:01:19.000 --> 01:01:24.000]  то я тупо сейчас вот это забью и у меня получится опять верхняя оценка.
[01:01:24.000 --> 01:01:28.000]  Ну то есть я напишу верхнюю оценку вот так.
[01:01:49.000 --> 01:01:59.000]  Так, сумма пока от единицы до n-1, сумма по w мощности k, понятно каким.
[01:01:59.000 --> 01:02:17.000]  Вероятность того, что, ну давайте я так напишу, для любого x не из w и для любого y из w пара x и y не является ребром.
[01:02:17.000 --> 01:02:22.000]  Ну это то же самое, что я писал словами, что нет ребер.
[01:02:22.000 --> 01:02:29.000]  Берем любую вершину снаружи, любую внутри, и они ребром не соединены.
[01:02:29.000 --> 01:02:35.000]  То есть я тупо просто пересечение двух событий оценил одним.
[01:02:35.000 --> 01:02:43.000]  Это понятно. Чему равна вот эта вероятность? Это совсем легко.
[01:02:43.000 --> 01:02:51.000]  Ну на картину смотрите, вот таких ребер нет. Сколько всего таких ребер?
[01:02:51.000 --> 01:02:55.000]  k умножить на n-k, товарищи.
[01:02:55.000 --> 01:03:02.000]  Ну k способов выбрать y из w и n-k способов выбрать x не из w.
[01:03:02.000 --> 01:03:11.000]  То есть вот эта вся вероятность, это просто 1-p в степени k на n-k.
[01:03:11.000 --> 01:03:17.000]  Соответственно от w эта вероятность не зависит, поэтому получаем вот такую запись.
[01:03:17.000 --> 01:03:26.000]  Сумма по k от единицы до n-1, c из n по k на 1-p в степени k на n-k.
[01:03:26.000 --> 01:03:33.000]  c из n по k это просто количество слагаемых. Сколько есть множеств мощности k? Это понятно.
[01:03:33.000 --> 01:03:47.000]  Смотрите, если k равно единице, то c из n по k на 1-p в степени k на n-k это в точности n на 1-p в n-1.
[01:03:47.000 --> 01:03:53.000]  Я надеюсь вы это узнаете. Это мата ожидания числа изолированных вершин.
[01:03:53.000 --> 01:03:59.000]  Про которые мы знаем, что в нашей текущей ситуации оно стремится к нулю.
[01:03:59.000 --> 01:04:03.000]  Потому что c теперь больше единицы, оно стремится к нулю.
[01:04:03.000 --> 01:04:08.000]  Но это стремление к нулю только самого первого слагаемого.
[01:04:08.000 --> 01:04:11.000]  О слагаемых замесище от n-количества.
[01:04:11.000 --> 01:04:18.000]  Даже если каждое последующее меньше предыдущего, из этого еще не следует, что вся сумма стремится к нулю.
[01:04:18.000 --> 01:04:22.000]  Потому что стремление к нулю этой штуки уже на грани.
[01:04:22.000 --> 01:04:28.000]  Помните, что если c очень близко к единице, то стремление к нулю прямо по кромочке проходит.
[01:04:28.000 --> 01:04:33.000]  Поэтому так вот за здорово живешь на n, например, умножить не получится.
[01:04:33.000 --> 01:04:37.000]  Ну какая может быть идея, что с этим делать дальше?
[01:04:40.000 --> 01:04:43.000]  Но надо не просто каждое из них оценить сверху,
[01:04:43.000 --> 01:04:52.000]  а надо доказать, что каждое последующее не просто меньше предыдущего, а в растущее число раз меньше.
[01:04:52.000 --> 01:04:56.000]  Давайте я вот эти штуки обозначу ак, т, ат, н.
[01:04:56.000 --> 01:04:59.000]  Объясню общую идею, а выкладку опять оставлю на следующий раз.
[01:04:59.000 --> 01:05:05.000]  У нас как-то так в этом семестре повелось, что вся идейная часть на одной лекции, а выкладка на другой.
[01:05:05.000 --> 01:05:06.000]  Но ничего страшного.
[01:05:06.000 --> 01:05:08.000]  Вот давайте слагаемый обозначим ак, т, ат, н.
[01:05:08.000 --> 01:05:11.000]  Мы знаем, что а1, ат, н стремится к нулю.
[01:05:11.000 --> 01:05:13.000]  Это вот как раз вот эта величина.
[01:05:13.000 --> 01:05:15.000]  Это мы знаем.
[01:05:15.000 --> 01:05:23.000]  Идея такая. Мы хотим посмотреть на отношение ак плюс первого ат, н к ак, т, ат, н.
[01:05:23.000 --> 01:05:29.000]  И попробовать доказать, что оно оценивается сверху каким-то q, ат, н независящим от k.
[01:05:29.000 --> 01:05:31.000]  И при этом стремящимся к нулю.
[01:05:31.000 --> 01:05:34.000]  Прен стремящимся к бесконечности.
[01:05:34.000 --> 01:05:42.000]  Вот если это получится, если это получится, тогда итоговая оценка всей суммы выглядела бы так.
[01:05:42.000 --> 01:05:48.000]  Мы вынесли бы за скобки а1, ат, н, которая стремится к нулю.
[01:05:48.000 --> 01:05:52.000]  В скобках была единица b от а1, ат, оставшаяся.
[01:05:52.000 --> 01:05:57.000]  Потом а2, ат, н поделить на а1, ат, н.
[01:05:57.000 --> 01:06:02.000]  Потом а3, ат, н поделить на а2, ат, н.
[01:06:02.000 --> 01:06:06.000]  На а2, ат, н поделить на а1, ат, н.
[01:06:06.000 --> 01:06:08.000]  Но мы уже пользовались такой идеей.
[01:06:08.000 --> 01:06:10.000]  И так далее.
[01:06:10.000 --> 01:06:12.000]  Чего?
[01:06:12.000 --> 01:06:14.000]  Не понял. В чем вопрос?
[01:06:14.000 --> 01:06:18.000]  Если бы оказалось, что вот это вот так, как я написал,
[01:06:18.000 --> 01:06:21.000]  то я бы воспользовался вот такой вот простой идеей.
[01:06:21.000 --> 01:06:23.000]  У нас уже один раз такая идея была.
[01:06:23.000 --> 01:06:25.000]  В чем проблема?
[01:06:25.000 --> 01:06:26.000]  А, ни в чем, да?
[01:06:26.000 --> 01:06:28.000]  Всем понятно, что там вот так получается.
[01:06:28.000 --> 01:06:32.000]  Ну так вот это у нас было бы меньше либо равно q от n,
[01:06:32.000 --> 01:06:36.000]  и это было бы меньше либо равно q квадрата от n.
[01:06:36.000 --> 01:06:38.000]  Там дальше q в кубе, q в четвертой и так далее.
[01:06:38.000 --> 01:06:42.000]  То есть это сумма геометрической прогрессии, хоть бесконечной.
[01:06:42.000 --> 01:06:48.000]  То есть это меньше, чем а1 от n умножить на 1, поделить на 1, минус q от n.
[01:06:48.000 --> 01:06:50.000]  А q от n стремилось бы к нулю.
[01:06:50.000 --> 01:06:51.000]  И все.
[01:06:51.000 --> 01:06:56.000]  Эта штука ерундовская, она стремится к единице, а а1 от n стремится к нулю.
[01:06:58.000 --> 01:07:00.000]  Идея такая.
[01:07:00.000 --> 01:07:02.000]  Есть еще чуть-чуть времени.
[01:07:02.000 --> 01:07:04.000]  Это очень хорошо.
[01:07:04.000 --> 01:07:07.000]  Потому что техническая реализация, к сожалению, чуть сложнее.
[01:07:08.000 --> 01:07:13.000]  Нечто в духе асимптотики для унициклических графов, если помните.
[01:07:13.000 --> 01:07:15.000]  Там надо сумму разбить на две части.
[01:07:15.000 --> 01:07:20.000]  Ну, во-первых, надо заметить, что фактически нас интересует вот такая сумма.
[01:07:27.000 --> 01:07:31.000]  Ну, потому что верхняя часть, вот эта, она симметричная.
[01:07:31.000 --> 01:07:36.000]  Ну, потому что верхняя часть, вот эта, она симметричная.
[01:07:36.000 --> 01:07:39.000]  c и z пока симметрично относительно серединки.
[01:07:39.000 --> 01:07:42.000]  И q умножить на n минус q тоже симметрично относительно серединки.
[01:07:42.000 --> 01:07:46.000]  Поэтому достаточно доказать, что вот такая сумма стремится к нулю, правда ж?
[01:07:51.000 --> 01:07:52.000]  Да.
[01:07:53.000 --> 01:08:02.000]  К сожалению, вот это вот все верно только в случае, если мы суммируем до какого-нибудь верхнего предела,
[01:08:02.000 --> 01:08:05.000]  который бесконечно мал по сравнению с n.
[01:08:05.000 --> 01:08:07.000]  Но это вы увидите потом.
[01:08:07.000 --> 01:08:09.000]  Это уже на следующей лекции будет.
[01:08:09.000 --> 01:08:13.000]  К сожалению, прямо вот до n пополам эта идея не реализуется.
[01:08:13.000 --> 01:08:19.000]  Начиная с какого-то момента отношение перестает быть ограниченным функцией, стремящееся к нулю.
[01:08:19.000 --> 01:08:24.000]  Но к этому времени само окатое становится настолько маленьким,
[01:08:24.000 --> 01:08:29.000]  что можно отцепить этот оставшийся хвостик и его с запасом оценить.
[01:08:29.000 --> 01:08:32.000]  Короче, техническая реализация такая.
[01:08:32.000 --> 01:08:39.000]  Пишем отдельно сумма пока от единицы до n поделить на корень из логарифма n.
[01:08:39.000 --> 01:08:43.000]  Почему именно на корень из логарифма, этого узнаете в следующий раз.
[01:08:43.000 --> 01:08:54.000]  И отдельно пишем сумму пока вот n на корень из логарифма n плюс 1 до n пополам того же самого.
[01:08:54.000 --> 01:09:00.000]  Вот этот хвостик будет оценен просто за счет того, что здесь уже окаты совсем ничтожно маленькие,
[01:09:00.000 --> 01:09:06.000]  а эта часть основная, она будет оценена за счет реализации этой идеи.
[01:09:06.000 --> 01:09:18.000]  Ещё раз, не надо суммировать до n минус 1, потому что функция, которую мы суммируем, симметрична относительно n пополам.
[01:09:18.000 --> 01:09:26.000]  Но фактически эта сумма, это просто удвоенная вот эта сумма, примерно удвоенная.
[01:09:26.000 --> 01:09:33.000]  Мы хотим доказать, что она стремится к нулю, но не надо удваивать. Зачем?
[01:09:33.000 --> 01:09:41.000]  Ну, просто понятно, что сначала эти штуки убывают, убывают, вот как я написал, а дальше они симметрично начинают обратно возрастать.
[01:09:41.000 --> 01:09:43.000]  Но зачем нам это возрастать, ловить?
[01:09:43.000 --> 01:09:47.000]  Оно же удваивает только исходную сумму.
[01:09:47.000 --> 01:09:53.000]  Поэтому мы смотрим только левую половинку, на которой действительно удастся реализовать вот эту идею, по крайней мере, вот досюда.
[01:09:53.000 --> 01:09:59.000]  Ну или даже до чего-то другого, просто вот конкретно в этой части приятнее считать, когда в знаменателе корень из логарифма.
[01:09:59.000 --> 01:10:04.000]  Это вы увидите. Но это большого значения не имеет.
[01:10:04.000 --> 01:10:06.000]  Все на сегодня.
