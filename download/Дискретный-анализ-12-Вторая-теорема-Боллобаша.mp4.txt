[00:00.000 --> 00:11.960]  Так, ну всё, давайте продолжим нашу деятельность. Как у вас дела вообще?
[00:11.960 --> 00:21.480]  Феместор заканчивается, да? Всё уже. Учиться трудно. Но давайте попробуем. Довольно сложная у
[00:21.480 --> 00:27.320]  нас сейчас тема. Идёт вот эти хроматические числа и концентрация. Но мне кажется, что в
[00:27.320 --> 00:33.680]  прошлый раз была очень красивая теорема. Всё-таки прям вообще мега крутая. Сегодня она тоже будет
[00:33.680 --> 00:38.480]  очень красивая, но она просто сложнее с точки зрения своего, так сказать, технического
[00:38.480 --> 00:47.840]  доказательства. Значит, она за сегодня, скорее всего, и не докажется. Ну ещё раз я её напомню. Это
[00:47.840 --> 00:56.440]  ещё одна теорема Балабаши о том, что если вероятность ребра случайного графа равняется одной
[00:56.440 --> 01:03.680]  второй, мы находимся в таком случае, когда все графы совершенно одинаково возможны, одинаково
[01:03.680 --> 01:20.600]  вероятны, то существует такая функция phi, она у маленькой от n на логариф m, а симпатически
[01:20.600 --> 01:36.600]  почти, наверное, модуль хроматического числа случайного графа минус вот это вот не превосходит
[01:36.600 --> 01:44.160]  phi t. Это утверждение, которое нам нужно в каком-то виде доказать. Ну, там какие-то будут, как всегда,
[01:44.160 --> 01:49.320]  пропущенные кусочки, наиболее технические, чтобы просто вас не убивать совсем уж. А вот
[01:49.320 --> 01:55.920]  идейно хотелось бы понять, что делается. Ну, смотрите, я вот в прошлый раз напоминал, что вот эта
[01:55.920 --> 02:05.560]  пункция, которая стоит в знаменателе, мы про неё знаем, что альфа её не превосходит, а симпатически
[02:05.560 --> 02:11.520]  почти, наверное, при p равном одной второй. Я напоминал, это надо держать в голове. Ну, я не знаю,
[02:11.520 --> 02:25.360]  вот здесь вот где-нибудь напишу. Мы знаем, что вот такое вот неравенство выполнено симпатически
[02:25.360 --> 02:31.200]  почти, наверное. Сейчас мы докажем, что противоположное неравенство не просто выполнено,
[02:31.200 --> 02:38.560]  но противоположное близкое к вот этому. То есть, справа будет стоять функция, которая очень похожа
[02:38.560 --> 02:45.240]  на 2 лог 2 ич на n, но всё-таки её поменьше. И вот с этой функцией уже будет выполнено противоположное
[02:45.240 --> 02:51.120]  неравенство, причем в очень-очень сильной форме. Но для того, чтобы это сформулировать красиво,
[02:51.120 --> 02:56.920]  аккуратно, так, чтобы это зашло, чтобы вас проканало, нам придется технически чисто,
[02:56.920 --> 03:02.280]  вот для каких-то целей, которые я проясню позже, аккуратно выбрать некоторые параметры.
[03:02.280 --> 03:10.640]  Ну, разумеется, как обычно, все эти параметры могут быть представлены на официальной шпаргалке
[03:10.640 --> 03:18.320]  во время экзамена, поэтому не пугайтесь тому, как это можно запомнить. Например, я введу м очередное,
[03:18.320 --> 03:26.160]  у нас уже м было с вами. Знаете, когда? Когда я вам доказывал теорему про жадный алгоритм,
[03:26.160 --> 03:40.920]  там тоже было м. Оно будет похоже. Так, вот такой вот м. У нас n стремится к бесконечности,
[03:40.920 --> 03:46.560]  м будет стремиться вместе с ним, но при этом, видите, вот эта функция, она уподобна фи. Она
[03:46.560 --> 03:54.800]  бесконечно мала по сравнению с n поделительно алгоритм. Ну, так вот. Значит, сразу для тех,
[03:54.800 --> 03:59.680]  кто действительно хочет глубоко понять, чего происходит, не просто формально разобраться,
[03:59.680 --> 04:05.720]  а глубоко понять. Сразу скажу, что вот важно, что она действительно бесконечно мала по сравнению с
[04:05.720 --> 04:13.400]  этим, но то, что тут написан именно квадрат, как обычно, это мой произвол, мне так удобно. Ну,
[04:13.400 --> 04:18.800]  тут целая часть, просто чтобы м было целым числом. А то, что здесь написан квадрат,
[04:18.800 --> 04:26.800]  это вещь такая, ну, чисто, знаете, для красоты. Могу куб нарисовать, могу пятую степень. Там
[04:26.800 --> 04:33.480]  это плевать. Взяли какую-то конкретную функцию, которая не слишком мала по сравнению с n поделительно
[04:33.480 --> 04:42.080]  алгоритм n, но во всяком случае мала. Мала, но не слишком. Слушайте, ну, если я буду очень долго
[04:42.080 --> 04:46.160]  такие вещи разжевывать, то я никогда ничего не закончу, поэтому давайте я двинусь дальше.
[04:46.160 --> 04:55.320]  Дальше немножко хуже. Давайте, во-первых, напомню, что у нас есть вот такое обозначение
[04:55.320 --> 05:09.880]  для числа независимых множеств размера k в графе g. Давайте будет число независимых множеств
[05:09.880 --> 05:20.040]  на k-вершинах. Нам спускается с неба граф g случайный. Спустился, мы посчитали,
[05:20.040 --> 05:27.600]  сколько в нем k-вершинных независимых множеств. Это будет значение величины x-каты. Так,
[05:27.600 --> 05:33.520]  ну, разумеется, мы знаем, что математическое ожидание этого x-катого
[05:33.520 --> 05:45.560]  это вот такая величина. Так, дорогие друзья, вот это мы знаем точно, ведь в этом месте я никого
[05:45.560 --> 05:51.880]  не кокну. Линейность мат ожидания. Просто перебираем все возможные множества на k-вершинах
[05:51.880 --> 06:03.440]  и каждое тестируем на то, что оно независимо. Ну, независимо значит отсутствуют все цископодвы
[06:03.440 --> 06:10.800]  ребер. Это 2 в степени минус цископодвы. Минус виден? Минус, конечно. Мат ожидания такое. И в
[06:10.800 --> 06:16.600]  частности, товарищи, вот это вот то, что я здесь напомнил наверху, можете для себя это тоже как-то
[06:16.600 --> 06:23.280]  пометить. Оно же как получается? Оно получается, внимание, это очень важно, из того, что если вместо
[06:23.280 --> 06:32.880]  k сюда подставить вот этот удвоенный логарифм, то в пределе получится 0. Вот если сюда вместо k
[06:32.880 --> 06:40.240]  подставить удвоенный логарифм, то в пределе получится 0. Именно поэтому альфа от g не превосходит
[06:40.240 --> 06:50.120]  этого логарифма в вероятность стремящейся к единице. Неравенство Маркова просто. Помните,
[06:50.120 --> 06:55.600]  да, понимаете, чего я говорю? Ну, поймите это для себя, это стандартная вещь, мы это много
[06:55.600 --> 07:00.720]  раз доказывали. Передоказывать сейчас я не вижу большого смысла. Мне просто важно, чтобы вы
[07:00.720 --> 07:07.560]  понимали, если вместо пункции k от n вот сюда подставить вот этот 2 лог 2 ич на n, то такое
[07:07.560 --> 07:13.440]  математическое ожидание будет стремиться к нулю. Именно поэтому вот это неравенство выполнило.
[07:13.440 --> 07:26.520]  Так, давайте эту функцию еще переобозначим. Вот так вот fk,t от n. Просто по определению положим fk,t
[07:26.520 --> 07:32.360]  от n равным вот этому мат ожиданию, но в принципе можно было и не обозначать, но я уж так обозначу.
[07:32.360 --> 07:39.960]  Можно fk,t от n, можно fn,t от k, ну пусть будет fk,t от n. Не помню, как в прошлом году я обозначал,
[07:39.960 --> 07:46.680]  можно посмотреть, это неважно. Вот, ну так вот обозначу. И смотрите, вот если я вместо k подставляю,
[07:46.680 --> 07:53.240]  как я уже говорил, 2 лог 2 ич на n, в пределе будет 0. А вот, например, если я напишу что-нибудь типа f3
[07:53.240 --> 08:03.000]  от n, то это будет c из n по 3 на 2 в минус третьей степени, и это, конечно, стремится к плюсу бесконечности.
[08:03.000 --> 08:15.880]  Вот я что хочу сказать, что если k маленькое, то рост к бесконечности. Но когда k становится
[08:15.880 --> 08:23.680]  достаточно большим, а именно, например, вот таким, то тут уже будет стремление к нулю. Вот я утверждаю,
[08:23.680 --> 08:36.640]  что есть некоторая точка перехода для каждого n, то есть можно рассмотреть такое минимальное k, скажем, 0,
[08:36.640 --> 08:54.480]  нам дано n, и мы можем по этому n найти самое маленькое k, при котором f0 от n, но, скажем,
[08:54.480 --> 09:02.640]  все еще меньше единицы. Набравно написать неважно. Вот, найдем такое самое, для данного n найдем
[09:02.640 --> 09:10.200]  самое маленькое k0, при котором fk0 меньше либо равно единицы. При сильно маленьких будет
[09:10.200 --> 09:15.920]  очень большим значение, но когда вы начнете их растить, растить-растить, в какой-то момент оно
[09:15.920 --> 09:21.160]  станет меньше единицы. Ну, может быть, надо считать, что n достаточно велико, чтобы асимптотика
[09:21.160 --> 09:28.160]  сработала. Здесь вот n можно считать достаточно большим. Вот для каждого достаточно большого n
[09:28.160 --> 09:35.760]  существует минимальное такое k0, что fk0 от n не превосходит единицы. Вот, определим такое k0.
[09:35.760 --> 09:50.080]  Значит, смотрите, я утверждаю такое утверждение, чисто аналитическое, которое мне бы не очень
[09:50.080 --> 09:55.080]  хотелось сейчас подробно объяснять. В прошлом году Тихон Евтеев меня заставил его подробно
[09:55.080 --> 10:01.000]  объяснить, я потратил минут 20. Если хотите, я, конечно, сделаю это еще раз, а можете посмотреть
[10:01.000 --> 10:08.600]  запись прошлого года. Да, первый раз, когда оно стало меньше, совершенно верно. Я вот интуицию
[10:08.600 --> 10:13.920]  осознал, что в какой-то момент должно стать меньше, идет переключение от стремления к нулю к стремлению
[10:13.920 --> 10:19.800]  к бесконечности. Но вот утверждение состоит в том, что если мы посмотрим асимптотику вот этой
[10:19.800 --> 10:25.080]  функции k0 от n при n стремящемся к бесконечности, то она будет вот такой.
[10:25.080 --> 10:36.560]  Не, ну понятно, что k0 от n не превосходит 2 лог 2 ич на n при достаточно больших n.
[10:36.560 --> 10:58.680]  Понятно, давайте я прямо напишу, это понятно, что k0 от n не превосходит 2 лог 2 ич на n при
[10:58.680 --> 11:03.440]  каких-то достаточно больших n. Но это просто следует из-за того, что вот я говорил, да,
[11:03.440 --> 11:08.720]  если вместо k0 от n просто подставить 2 лог 2 ич на n, там будет стремление к нулю,
[11:08.720 --> 11:18.320]  а минимальная k0, оно только раньше возникнет, вообще говоря. Это понятно. Утверждение состоит
[11:18.320 --> 11:28.400]  в том, что асимптотически эта оценка не улучшаема. То есть, да, я умудрился это тогда сказать,
[11:28.400 --> 11:36.880]  я уже не помню. Может быть, а, слушайте, я, наверное, знаете, что сказал, что если взять k0 от n в
[11:36.880 --> 11:46.880]  каком-то вот таком вот виде 2 лог 2 ич на n минус c лог лог, если вот как-то так взять, ну c
[11:46.880 --> 11:52.640]  написал там 100, например, 100 точно хватит. Вот если в таком виде k0 от n взять, то уже будет
[11:52.640 --> 11:59.200]  стремление к бесконечности. Ну можете это проверить. Слушайте, ну очень не хочется это считать,
[11:59.200 --> 12:07.200]  в чем этого, если Тихон будет смотреть, я напрасно не возвожу. Это Тихон мне просил. Это понятно.
[12:07.200 --> 12:14.080]  Подставите, увидите, что стремится к бесконечности. Он просил, сейчас скажу, что сейчас, мы до этого еще
[12:14.080 --> 12:19.200]  не дошли до того, что он просил, мы не дошли. Это как раз все понятно. То, что оно будет таким,
[12:19.200 --> 12:25.320]  это следует вот отсюда. Просто тупо проверите, как упражнение, что при подстановке такой функции,
[12:25.320 --> 12:31.520]  вот в это выражение, уже получается стремление к плюс бесконечности. Ну, то есть, она точно не
[12:31.520 --> 12:38.400]  подходит на кандидатуру минимального k, при котором не больше единицы. Оно стремится к бесконечности.
[12:38.400 --> 12:47.920]  То k0 от n, которое мы определили, оно при больших n болтается где-то точно в этих пределах. Сейчас
[12:47.920 --> 12:56.520]  понятно сказал эту часть. Значит, сейчас объясню, что он попросил сказать. Дальше я, смотрите,
[12:56.520 --> 13:06.760]  я рассмотрю fk. Рассмотрим, давайте я напишу, чтобы было понятно. Я рассмотрю fk от m, вот от этого m.
[13:06.760 --> 13:14.080]  Скоро поймете зачем, пока я чисто формально ввожу какие-то параметры. Я рассмотрю fk не как
[13:14.080 --> 13:21.480]  функцию от n, а как функцию от m. Ну, увидите, зачем это нужно. Там будет очень понятно,
[13:21.480 --> 13:28.880]  чисто вот алгоритмически все будет понятно. Скоро поймете. Ну, чуть-чуть позже. Давайте рассмотрим fk от m.
[13:28.880 --> 13:38.040]  По нему найдем, вот так я нарисую, чтобы это не путалось со значком стремления. По нему найдем k0 и k0 от m.
[13:38.040 --> 13:50.440]  Смотрите, k0 и k0 от m асимпатически равно 2 лог 2-ичный m, согласно вот этому утверждению. Но когда вы
[13:50.440 --> 13:59.080]  берете лог 2-ичный от вот такого m, вы асимпатически получаете исходный 2-ичный логориф. Сейчас понятно,
[13:59.080 --> 14:04.840]  что логорифом от этой штуки асимпатически равен логориф в учителе. Очевидно абсолютно.
[14:04.840 --> 14:15.520]  Вот это вот 2 лог 2-ичный. Это просто мне нужно, чтобы запомнить. И вот теперь мы берем зачем-то,
[14:15.520 --> 14:23.280]  это будет ясно не скоро зачем, но это будет очень круто, это будет катарсис полный. Мы берем k1 от m,
[14:23.280 --> 14:40.800]  а в n-м к0 от m минус 3. Это уже конечно надо еще косликом подпрыгнуть на одной ножке. Да вот,
[14:40.800 --> 14:46.520]  понимаете, минус 3. Почему минус 3 я обязательно объясню, то есть я всегда конечно заостряю на
[14:46.520 --> 14:51.920]  этом внимание. Будет понятно зачем вычитать тройку, но пока не понятно совершенно. Так вот,
[14:51.920 --> 14:57.160]  смотрите, вот мы вычли эту тройку. Что произошло? Что произошло вот с этой
[14:57.160 --> 15:03.160]  функцией, с функцией математического ожидания? Она стала куда стремиться к нулю или к бесконечности,
[15:03.160 --> 15:12.600]  если k0 это была вот такая вот граница. Но может быть константой. Да, да, да, да, да,
[15:12.600 --> 15:17.360]  совершенно верно. Но во всяком случае мы куда-то поднимаемся по отношению к единице, да ведь?
[15:17.360 --> 15:26.640]  Потому что это уменьшается, а мы, значит, поднимаемся. Вот я утверждаю еще одно утверждение. Вот это
[15:26.640 --> 15:40.040]  утверждение Тихон попросил разобрать подробно. Значит, я утверждаю, что это вот fk1 вот так вот,
[15:40.040 --> 15:47.280]  если мы подставим k1 от m в качестве k и m устремим к бесконечности, ведет себя следующим
[15:47.280 --> 15:54.280]  образом. Вот так вот. То есть оно становится больше единицы, причем не в константу раз, а в m в
[15:54.280 --> 16:01.440]  кубе раз. Вот мы три раза сдвигаемся и каждый раз как бы умножаемся на m, ну и с какими-то там
[16:01.440 --> 16:08.520]  логарифмами, которые в показатель попадают в видеомалово от единицы. Это действительно не очевидно.
[16:08.520 --> 16:15.680]  Чтобы это стало понятным, надо взять и при соседних значениях k разделить одно на другое,
[16:15.680 --> 16:24.160]  то есть взять выражение c из m по k на 2 в степени минус c из k по 2 и давайте, знаете как,
[16:24.160 --> 16:31.920]  по k плюс 1 и разделить на c из m по k на 2 в степени минус c из k по 2. Надо просто найти
[16:31.920 --> 16:40.720]  отношение двух величин вот этих вот k плюс 1, fk плюс 1 от m и fk и от m. Да.
[16:50.560 --> 16:52.680]  Да.
[17:01.920 --> 17:16.960]  Ну, утверждаю, да. Может быть надо вычислить четыре. Сейчас мы посмотрим. Но мне надо,
[17:16.960 --> 17:22.440]  чтобы m в кубе было. Вот это m в кубе мне очень важно. Не, ну можно вот честно разделить одно на
[17:22.440 --> 17:37.320]  другое. Давайте, пап. Не, ну давайте, ну если хотите, давайте вот это разделим,
[17:37.320 --> 17:42.120]  чтобы было понятие и чисто вот аналитическая сторона вопроса. Что будет, если поделить?
[17:42.120 --> 17:50.040]  Сейчас, наверное лучше только k минус 1, наоборот было вот здесь писать, а здесь k. Ну ладно уж,
[17:50.040 --> 17:57.720]  как написали, так написали, неважно. Значит, m факториал сокращается, правда же. Так,
[17:57.720 --> 18:05.120]  тут k плюс 1 факториал, тут k факториал, то есть в знаменателе будет k плюс 1. Так? Так,
[18:05.120 --> 18:11.680]  а в числителе что будет? m минус k, наверное, да? m минус k будет в числителе. Теперь двойки
[18:11.680 --> 18:21.920]  в степени, вот это противно. Тут значит будет k на k плюс 1 пополам, минус k на k минус 1 пополам,
[18:21.920 --> 18:30.880]  только не минус, а плюс. Ой, боже мой. k квадрат пополам сокращается, остается минус k пополам,
[18:30.880 --> 18:38.720]  и еще раз минус k пополам, то есть минус k. Ничего противного, все легко. m минус k на
[18:38.720 --> 18:49.440]  k плюс 1 на 2 в степени минус k. Вот такое вот отношение. Теперь смотрите, k у нас,
[18:49.440 --> 19:00.480]  k у нас, это 2 лог 2-ичный m. Вот если k это 2 лог 2-ичный m, то здесь получается 2 в степени
[19:00.480 --> 19:08.000]  минус 2 лог 2-ичный m, и это 1 поделить на m в квадрате. k это мизер по сравнению с m,
[19:08.000 --> 19:16.040]  поэтому тут асимптотика получается вот такая. m поделить на k и умножить на 1 деленное на m в
[19:16.040 --> 19:24.440]  квадрате. Это будет 1 поделить на km. Ну вот что я и утверждал, то есть при уменьшении на единичку
[19:24.440 --> 19:34.680]  вот этого k, увеличение происходит вот примерно во столько раз. Ну m умножить на k это m в степени
[19:34.680 --> 19:42.840]  1 плюс о малое от 1, потому что k это логариф. И вот если мы три раза сдвинемся, то увеличение
[19:42.840 --> 19:54.440]  произойдет вот так. Ну ладно, повторили тихонно. Сейчас я объяснил, понятно? Каждый раз вырастает
[19:54.440 --> 20:05.160]  примерно в m раз. Ну все. То есть если мы влево, вправо вернее, прибавим единичку к этому к 0,
[20:05.160 --> 20:12.680]  это уже будет что-то типа 1 поделить на m, на m в степени 1 плюс о малое от 1. А когда мы влево
[20:12.680 --> 20:19.160]  сдвигаемся три раза, вычитаем вот эту единичку три раза, мы наоборот вот это примерно 1 умножаем
[20:19.160 --> 20:30.560]  на m в степени 3 плюс о малое от 1. Вроде все, я объяснил. Ну двигаемся дальше, товарищи,
[20:30.560 --> 20:36.880]  это все технические вещи. Сейчас будет лемма, формулировка которой сама по себе, если вы ее
[20:36.880 --> 20:45.680]  осознаете, ну уже катарсисная в каком-то смысле. Вот лему надо применить и потом доказать. Лемма
[20:45.680 --> 20:54.440]  звучит следующим образом. Вероятность того, ну можно, кстати, асимпатически почти,
[20:54.440 --> 21:02.040]  наверное. Ладно, напишу вероятность того что. Вероятность того, что для любого s из v. Так,
[21:02.040 --> 21:09.160]  v, товарищи, это как обычно множество вершин нашего случайного графа, и оно состоит из n чисел.
[21:09.160 --> 21:18.080]  Обычный граф на n вершинах, вот тот который в теории. Вот для любого s из v. Такого,
[21:18.080 --> 21:30.600]  что мощность s равняется m. Помните, что такое m? Целая часть от n логарифа в квадрате. Вон там
[21:30.600 --> 21:46.480]  написано. Число независимости под графа, ограниченного на s, больше либо равняется k1.
[21:46.480 --> 22:01.520]  К1 от m. Того самого, которое мы нашли. Сейчас долго обсуждать. Оно, естественно, тоже имеет
[22:01.520 --> 22:09.840]  асимптотику. Два лог двоичные. Так, давайте осознаем в чем действительно катарсисность этого
[22:09.840 --> 22:18.000]  утверждения. Почему тут грандиозное что-то получилось? А, ну, виноват. Да-да-да-да-да. Ну,
[22:18.000 --> 22:22.880]  я говорю, можно писать асимптотически почти наверно. Да-да, стремится к единице при n,
[22:22.880 --> 22:29.480]  стремящимся к бесконечности. Ну или при m, стремящимся, неважно. Ну, при n, конечно,
[22:29.480 --> 22:36.560]  у нас главный параметр это n. Так, в чем катарсис-то? Смотрите, вот есть множество всех n вершин,
[22:36.560 --> 22:45.440]  и мы утверждаем, что какое бы подмножество мощности m, какое бы подмножество мощности m в нем
[22:45.440 --> 22:52.760]  мы не взяли, в этом подмножестве обязательно есть независимый кусочек, кусочек без ревер,
[22:52.760 --> 23:00.080]  размер которого не меньше, чем k1. То есть, смотрите, с одной стороны, вот я специально
[23:00.080 --> 23:05.800]  здесь это написал, чтобы вам четче было понятно. С одной стороны, почти наверняка,
[23:05.800 --> 23:14.440]  число независимости меньше, чем 2 лог 2-ичное, то есть в случайном графе нет вот такого размера
[23:14.440 --> 23:21.520]  независимых множеств. Но едва вы уменьшаете этот размер до чего-то, практически такого же
[23:21.520 --> 23:28.480]  в асимптотике, вы берете ту же самую функцию асимптотически, ну, немножко другую там смещаетесь,
[23:28.480 --> 23:35.240]  может, на повторный логарифм. Понимаете, да, о чём я говорю? Вы читаете из вот этого какой-то
[23:35.240 --> 23:42.160]  мизер, какой-то может быть повторный логарифм. Вот как только вы это делаете, у вас не просто
[23:42.160 --> 23:48.120]  возникают независимые множества этого размера, вот этого размера, не просто они возникают,
[23:48.120 --> 24:01.800]  а они есть в каждом куске размера м, их чертова туча. Понятно говорю, да? Какой рыбок! С одной стороны,
[24:01.800 --> 24:07.720]  нет независимых множеств размера 2 лог 2-ичное, с другой стороны, независимое множество какого-то
[24:07.720 --> 24:17.680]  вот такого размера есть почти всюду. Чего бы не взяли размер м, и там найдется такой вот маленький
[24:17.680 --> 24:27.680]  островок. Вот такой вот. М это n на логарифм в квадрате. Так, друзья, вот эта сложная лемма,
[24:27.680 --> 24:34.560]  которую мы докажем с помощью концентрации меры, давайте её применим, чтобы завершить доказательство
[24:34.560 --> 24:45.080]  Балабаша. Теорему Балабаша мы сейчас мгновенно выведем. Так, смотрите, давайте вот это множество,
[24:45.080 --> 24:53.800]  множество графов на n вершинах. Ну как-нибудь обозначим, как водится а с индексом n. Это множество
[24:53.800 --> 25:01.360]  графов, события. Давайте предположим, что какой-то граф принадлежит этому множеству, то есть ну вот
[25:01.360 --> 25:08.500]  выполнено для него это событие. Какой-то граф таков, что вот он обладает свойством, описанным под
[25:08.500 --> 25:17.180]  знаком вероятности. Смотрите, что мы тогда сделаем. Вот этот граф. Найдем в нем независимый кусочек
[25:17.180 --> 25:25.460]  размера k1. Он там есть, потому что он там повсюду есть. Правильно? Найдем, покрасим его в первый
[25:25.460 --> 25:37.380]  цвет, потому что это независимый кусочек. Понимаете? Выкинем это множество и в оставшемся снова
[25:37.380 --> 25:45.340]  найдем кусочек размера k1 и его покрасим во второй цвет и так далее. Сколько раз мы так можем
[25:45.340 --> 25:51.860]  сделать, товарищи? Вот давайте осознаем. Исходя из этого свойства, в каждом под множестве мощности
[25:51.860 --> 25:57.780]  мэй есть кусочек размера k1, который можно красить в очередной цвет. Сколько раз мы так сделаем?
[25:57.780 --> 26:06.220]  Когда завершится эта процедура в алгоритме? Не, ну давайте напишем явно. Наверное, когда мы пройдем
[26:06.220 --> 26:11.900]  вот столько шагов просто и все. Если мы сделаем, ну целую часть лучше нарисовать, вот если мы
[26:11.900 --> 26:20.260]  сделаем столько шагов, то после этого может остаться уже меньше, чем m вершин и это перестанет быть
[26:20.260 --> 26:30.060]  применительно. Так, друзья, согласны? Вот столько цветов появится. После этого останется m вершин,
[26:30.060 --> 26:37.420]  каждую из которых в худшем случае мы покрасим в отдельный цвет. После того, как мы сделаем вот
[26:37.420 --> 26:46.820]  столько шагов, крася вот эти вот кусочки, мы получим в остатке не больше, чем m вершин и в худшем случае
[26:46.820 --> 26:55.580]  каждую из них покрасим в отдельный цвет. То есть суммарное количество цветов хиадже точно не больше,
[26:55.580 --> 27:01.020]  чем вот это. Если граф обладает этим свойством, то он вот с помощью такого банального алгоритма
[27:01.020 --> 27:09.740]  красятся не более, чем в столько цветов. Сейчас вот это понятно объяснил? В смысле, это все что
[27:09.740 --> 27:17.980]  нам нужно, потому что k1 асимпатически равен 2 лог 2 ищ на n, так? Значит у нас получается,
[27:17.980 --> 27:25.840]  что вот это выражение асимпатически равно n поделить на 2 лог 2 ищ на n. А m у нас выбрано так,
[27:25.840 --> 27:33.300]  чтобы быть бесконечно маленьким по сравнению с этим. Ну то маленькое от n на логарифм n. Ну то есть
[27:33.300 --> 27:41.380]  все вместе вот этого маленького, все вместе тоже асимпатически равно n поделить на 2 лог 2 ищ на n.
[27:41.380 --> 27:48.340]  И теорем Балабаши доказано, что любой граф из вот этого множества, такие красятся в не более,
[27:48.340 --> 27:54.260]  чем асимпатически столько цветов. А это множество имеет меру с тремящейся к единице. Значит,
[27:54.260 --> 28:05.900]  почти каждый граф красятся в вот такое количество цветов. Сейчас, друзья, я что-ли быстро рассказываю?
[28:05.900 --> 28:19.980]  Нормально? Ну естественно. Вы имеете в виду, что вот тут мы еще вычитаем. Ну m на k1 еще меньше,
[28:19.980 --> 28:29.060]  чем m. Нет, но мы можем вообще сказать, знаете, что это меньше, чем n поделить на k1 плюс m. n поделить
[28:29.060 --> 28:34.620]  на k1 асимпатически равно вот этому. m бесконечно мало, значит в сумме получаем ту же асимптотику.
[28:35.900 --> 28:48.060]  Нет, но тут же вот есть phi от n анонсируемое. Вот это phi от n оно как раз и присутствует вот в этой
[28:48.060 --> 28:55.940]  асимптотике плюс вот в этой. Вот phi от n получается отсюда. Ну не явно, конечно, но получается же.
[28:55.940 --> 29:03.460]  Но в частности ясно, что при моем вот этом подходе phi от n точно не меньше,
[29:03.460 --> 29:09.660]  чем n поделить на логарифм в квадрате. Но еще тут есть какая-то поправка, может быть еще отсюда что-то
[29:09.660 --> 29:16.140]  вырезать. Но не важно. Важно, что это асимптотически равно, а значит какое-то phi существует. Это просто
[29:16.140 --> 29:22.460]  равносильные вещи. Все, теорема была ваша, я доказал. Но лемму надо доказать. Понимаете,
[29:22.460 --> 29:29.420]  вот лемма-то это самое интересное, удивительное результат. Давайте начнем, хорошо? И начнем,
[29:29.420 --> 29:41.260]  может и закончим, как повезет. Не, ну закончим вряд ли. Так, где бы мне писать? Давайте вот тут пока что
[29:41.260 --> 29:47.940]  будем писать. Это все, долой.
[29:57.420 --> 29:57.940]  Так.
[29:57.940 --> 30:14.580]  Так, друзья, все живы? Готовы воспринимать доказательство леммы? Давайте, давайте. Оно
[30:14.580 --> 30:20.620]  достаточно трудное, конечно, но я постараюсь рассказывать вам максимально внятно. В том числе
[30:20.620 --> 30:27.340]  вот как не надо действовать, я тоже расскажу. Но давайте так, давайте для начала, как обычно,
[30:27.340 --> 30:32.700]  напишем отрицание того события, которое в скобках, чтобы доказывать не стремление к единице,
[30:32.700 --> 30:41.580]  а к нулю. Оценивать сверху всегда проще. Довероятность того, что существует S из V мощности
[30:41.580 --> 30:57.780]  M такое, что альфа от G на S больше, нет, меньше, чем k1. Существует множество мощностей M, в котором
[30:57.780 --> 31:06.460]  нету независимого подмножества мощности k1, альфа меньше. Ну, как это дело оценивать? Стандартно,
[31:06.460 --> 31:14.220]  тут, в общем, деваться некуда. Значок кванторсуществования это всегда объединение
[31:14.220 --> 31:21.740]  событий, товарищи. Это мы уже набили оскомину, наверное, да? Постоянно я это повторяю. То есть
[31:21.740 --> 31:29.340]  здесь получается просто С из N по M, количество способов выбрать множество мощностей M на N
[31:29.340 --> 31:40.860]  вершинах. Умножить, на вероятность того, я давайте так напишу, что альфа давайте от H, может быть,
[31:40.860 --> 31:50.380]  поаккуратнее, меньше, чем k1. Имеется в виду, что H это уже граф не на N вершинах, а на M вершинах.
[31:50.380 --> 31:58.700]  Ну, какая разница, на какое множество S ограничить граф G? Если вы на какое-то M
[31:58.700 --> 32:04.700]  вершинное множество его ограничиваете, то у вас просто получается случайный граф на M вершинах.
[32:04.700 --> 32:11.860]  Понимаете, да? Неважно, поэтому никакого суммирования по S не надо писать, надо писать
[32:11.860 --> 32:17.660]  просто количество этих S и умножить на вероятность того, что на каком-либо из них альфа меньше,
[32:17.660 --> 32:29.980]  чем k1. Ну, давайте я еще раз подчеркну, вот эта мера на вот это вот мера, она на G от NP, а вот эта
[32:29.980 --> 32:40.340]  вот мера, она на G от MP. Все. Ну, мера вот этой вот вероятности, она определена здесь на множестве
[32:40.340 --> 32:46.500]  вот этих случайных графов, а здесь уже на вот таких. Ну, просто чтобы вы для себя как-то
[32:46.500 --> 32:55.780]  максимально четко пометили. Понятно? Когда мы G ограничиваем на S мощности M, мы получаем
[32:55.780 --> 33:11.180]  просто случайный граф на M вершинах. Так, ну ладно, это все понятно. Смотрите, друзья, если вы готовы
[33:11.180 --> 33:18.660]  воспринимать суть, то я потрачу время на то, чтобы уйти в неправильную ветку решения.
[33:18.660 --> 33:27.340]  Не, но смотрите, я хочу, на самом деле, что я хочу сделать? Я хочу вот это наше неравенство,
[33:27.340 --> 33:33.100]  помните неравенство, которое похоже на пьяницу? Что если F липшется вот, то F уклоняется от
[33:33.100 --> 33:40.780]  своего мата ожидания, с вероятностью, которая очень маленькая. Помните такое? Вот я хочу в итоге
[33:40.780 --> 33:50.260]  применить его для того, чтобы оценить вот эту вероятность. И я это сделаю. Но если я сейчас начну
[33:50.260 --> 33:55.860]  это делать чисто формально, то у любого нормального человека, который хочет понять вообще чего
[33:55.860 --> 34:03.780]  происходит, возникнет некоторый как бы когнитивный диссонанс. То есть этот человек подумает,
[34:03.780 --> 34:10.020]  зачем такой огород городить? Ну мы же умеем оценивать вот такие вероятности через что-то
[34:10.020 --> 34:15.780]  гораздо более простое. Я сейчас вам награжу огород. Вот смотрите, вы можете даже себе сейчас какое-то
[34:15.780 --> 34:21.060]  время не записывать, я вам скажу, вот такая врезка будет. Я вам просто поясню, что вот можно, конечно,
[34:21.060 --> 34:28.140]  пытаться вот эту вероятность оценить как-то по-простому, по-рабочекрестьянски, не используя вот
[34:28.140 --> 34:36.220]  это вот неравенство с липшицами функции. Ни хрена не получится. Вот я хочу вас в этом убедить, товарищи.
[34:36.220 --> 34:43.260]  Можно? Но все-таки вот смотрите, вот сейчас, если хотите, можете не записывать, вас это никто не
[34:43.260 --> 34:53.500]  спросит. Просто, ну не знаю, Аркадий Борисович может что угодно, но он обычно спрашивает формально те
[34:53.500 --> 34:58.180]  вещи, которые требуются для доказательства. То есть если вы ссылаетесь на что-то и не доказывать,
[34:58.180 --> 35:03.420]  там формулу Стирлинга, он может потребовать ее доказать. Но уж какие-то врезки про то,
[35:03.420 --> 35:09.260]  что не работает, он спрашивать не будет. Не-не, но там, где не надо доказывать, я прямо поставил,
[35:09.260 --> 35:14.700]  что не надо доказывать, так что вас не кокнут. Не переживайте. Вот, ну смотрите, значит, вот такая
[35:14.700 --> 35:21.660]  небольшая врезка. Вот я хочу оценить эту вероятность. Хочу. Давайте, вероятность того,
[35:21.660 --> 35:31.660]  что альфа-атаж меньше какого-то k1. Ну, слушайте, это в точности вероятность того, что х с индексом k1,
[35:31.660 --> 35:41.340]  вот он еще светится тут. Что такое х с индексом k1? Число независимых множеств. Равняется нулю.
[35:41.340 --> 36:05.100]  Ну, да. Не, она каждый раз вырастает. Я же про это сказал, что если прибавить единицу,
[36:05.100 --> 36:10.460]  то она наоборот уменьшится в мэра столько. Поэтому меньше, чем 1мт, она тоже не будет.
[36:10.460 --> 36:16.700]  Но, может быть, надо на 4 сдвинуться, чтобы быть уверенным, но я точно знаю, что на 3
[36:16.700 --> 36:22.740]  достаточно. Неважно, можно хоть на 10 сдвинуться, от этого в итоге мое доказательство не пострадает.
[36:22.740 --> 36:30.580]  Если вам спокойнее, сдвиньтесь на 4. Ну, вы вот если вам спокойнее, сдвиньтесь на 4,
[36:30.580 --> 36:37.060]  этого точно достаточно. Вот на 4 уж точно достаточно. Она в свою очередь за счет того,
[36:37.060 --> 36:42.980]  что каждый раз идет изменение в м раз, больше ли равна 1 поделить на м в степенью 1 плюс о малой
[36:42.980 --> 36:50.420]  от единицы. Потому что если 4 раза вы сдвинетесь, там м в кубе будет. Хорошо, да, это нормально.
[36:50.420 --> 36:57.780]  Так, вернемся сюда. Все понимают, что это одно и то же. х это число независимых множеств на
[36:58.780 --> 37:06.580]  Поэтому отсутствие независимых множеств можно и так и так обозначить. Вот, ну, стандартный
[37:06.580 --> 37:13.100]  код. Слушайте, я вообще могу, знаете как, сослаться. У нас же было неравенство. У нас было
[37:13.100 --> 37:22.460]  неравенство. Смотрите, я его доказывал. Вот такое. Что я буду его переписывать заново? Помните
[37:22.460 --> 37:28.980]  такую штуку? Я для треугольников ее писал, а потом говорил, ну, смотрите, какая разница. Мне важно
[37:28.980 --> 37:36.620]  только, что здесь случайная величина, принимающая не отрицательные значения. Не отрицательные целые
[37:36.620 --> 37:42.260]  значения. Вот если она принимает не отрицательные целые значения, всегда верно такое неравенство.
[37:42.260 --> 37:53.100]  Я это точно писал. Кто-нибудь хотя бы помнит? Ну, в общем, короче говоря. Не, ну, друзья, ну,
[37:53.100 --> 37:57.780]  слушайте, ну, что я буду по три раза, что ли, за курс одно и то же доказывать? Я ссылаюсь на то,
[37:57.780 --> 38:04.300]  что было. Если вы записывали, у вас точно было, вы вспомните. Вот это стандартное простое
[38:04.300 --> 38:11.100]  неравенство, которое, внимание, товарищи, вытекает из неравенства Чебышова. Это просто следствие
[38:11.100 --> 38:16.780]  неравенства Чебышова. Ну, неравенство Чебышова это тоже неравенство плотной концентрации и меры,
[38:16.780 --> 38:24.940]  но если вы помните историю про пьяницу, то как последний гвоздь в крышку гроба его алкоголизма
[38:24.940 --> 38:31.940]  забивает не Чебышов, а вот то неравенство большого уклонения с экспонентой. Помните,
[38:31.940 --> 38:37.900]  да? Сейчас давайте я договорю, потом сделаем перерыв. Смотрите, товарищи,
[38:37.900 --> 38:46.820]  тот стоит в номинации. Вот мы только что с Мишей обсуждали. Ну, примерно М в кубе,
[38:46.820 --> 39:05.940]  да? В квадрате. М в шестой. Чего? Ой, да. Да, просто вот так, конечно. Да, вот так, извините,
[39:05.940 --> 39:12.460]  нам же сверху надо оценивать, вы глупость сказали. Короче, вот в нашей ситуации это примерно М в шестой.
[39:12.460 --> 39:21.460]  Какая там дисперсия, уже наплевать. Почему? Потому что эта дробь, если и стремится к ноль,
[39:21.460 --> 39:27.260]  ну стремится, то примерно как многочлен. Не важно там десятой степени, двадцатой, шестой,
[39:27.260 --> 39:36.020]  но это многочлен в знаменатель. А что такое C и Zn по М, на которое это вот стука умножается?
[39:36.220 --> 39:43.340]  Не, ну дисперсия тоже будет, конечно, полиномом, вспоминайте, как мы с треугольниками считали.
[39:43.340 --> 39:50.460]  То есть мы потом посчитаем даже эту дисперсию, она будет, конечно, полиновом, то есть здесь вот
[39:50.460 --> 39:55.400]  будет, ну, отрицательный полином. Может быть, то есть как вот тут М в шестой знаменатель, дисперсия
[39:55.400 --> 40:00.400]  тоже может быть полиномом в знаменателе. Но даже если вы делите на М в двадцатой степени,
[40:00.400 --> 40:07.000]  но это значит, что вы делите на n в двадцатой степени, грубо говоря. А вот эта штука
[40:07.000 --> 40:14.920]  c из n по m, ну слушайте, ну вы на такую ерунду делите, что это уже ну как бы не очень сильно
[40:14.920 --> 40:21.040]  отличается от c из n по n на 2, которая, как вы понимаете, есть примерно экспонента 2 в степени n.
[40:21.040 --> 40:32.260]  Убить экспоненту по линомам хрен получится. Понимаете? Да, вот поэтому Кибышов здесь не сработает от слова
[40:32.260 --> 40:38.520]  совсем. Вот я только это хотел вам пояснить. Почему придется строить Липшицеву функцию и
[40:38.520 --> 40:47.800]  применять неравенство, которое было с ней. Сейчас перерыв 5 минут. Так, ну все, давайте продолжать.
[40:47.800 --> 40:59.040]  Ну я написал, собственно, резюме, да, что надо продолжать как-то оценивать. Заодно c из n по m оценил
[40:59.040 --> 41:05.080]  тупо как 2 в n, но я уже предупреждал, что сильно лучше оценить-то и не получится. Ну получится,
[41:05.080 --> 41:10.120]  конечно, но эта фигня там какая-то будет знаменателем, она не сработает, я вас уверяю.
[41:10.120 --> 41:18.360]  Надо придумать какой-то ход, похожий на то, что мы делали с Чебышовым, но как-то вот по-другому
[41:18.360 --> 41:27.400]  заменить вот это неравенство. Значит, код следующий давайте обозначим через y с индексом k от g.
[41:27.400 --> 41:37.720]  Ну k это вот, это k. Так, k у нас k1. Ну пусть будет k любое там, в частности k1. Значит, через y с индексом k от g
[41:37.720 --> 41:47.000]  обозначим случайную величину, которая равна максимуму, среди всех, ну какую букву использовать,
[41:47.000 --> 41:55.360]  давайте m, а m у нас есть, давайте l. Максимум среди всех чисел l таких, что существует
[41:55.360 --> 42:16.920]  a1 и так далее, а с индексом l из v под множество. Так, такие, что для любого i мощность аитова
[42:16.920 --> 42:26.720]  равняется k, для любых и g, вот я сейчас начинаю городить огород, чтобы возникла Липшицева,
[42:26.720 --> 42:35.800]  сейчас увидите, для любого i мощность равна k, для любых и g мощность аитова пересеченного
[42:35.800 --> 42:47.960]  сожитом не превосходит единицы. И, наконец, для любого и g, ограниченной на аите, клика,
[42:47.960 --> 43:01.000]  ой, клика, независимое множество, антиклика, независимое множество. Максимальная l такое,
[43:01.000 --> 43:09.040]  что, ну это для данного графа, что вот у этого графа есть l под множество мощности k на каждом
[43:09.040 --> 43:15.280]  из которых клика, и при этом эти клики пересекаются не больше, чем по одной вершине. Каждые две либо
[43:15.280 --> 43:20.200]  вообще не пересекаются, либо пересекаются ровно по одной вершине. Ну, то есть, картина какая-то,
[43:20.200 --> 43:27.920]  вот такая опять, есть m вершин, у нас теперь, помните, m вершин, m вершин теперь, мы у графа h
[43:27.920 --> 43:38.080]  рассматриваем m вершин, не забывайте про это. Ну, в каком-то смысле, ну да-да-да, ну давайте я
[43:38.080 --> 43:44.320]  напишу h, действительно, чтобы оно, не то чтобы логичнее, но как бы понятнее может быть,
[43:44.320 --> 43:53.200]  действительно, коррелирует больше запись одна с другой, давайте h напишу. То есть, у нас всего
[43:53.200 --> 44:03.880]  m вершин, и вот мы можем найти какие-то под множество a1, a2, там a3 и так далее. Вот нам
[44:03.880 --> 44:09.200]  хочется их найти как можно больше, чтобы каждые два пересекались не более, чем по одной вершине,
[44:09.200 --> 44:19.840]  не имели общих ребер, если угодно, и при этом все они были бы кликами в этом графе. Значит,
[44:19.840 --> 44:26.960]  друзья, на самом деле, вы помните, я вам когда-то рассказывал еще в ОКТЧ, про теорию кодирования,
[44:26.960 --> 44:35.160]  там была история про то, что надо выбрать тройки пьяниц, ну ладно, бог с ними с тройками пьяниц,
[44:35.160 --> 44:41.080]  может я это не произносил, сейчас вам расскажу. Теория кодирования, она устроена так, надо
[44:41.080 --> 44:48.520]  выбрать тройки пьяниц, которые бы соображали каждый вечер на троих, сейчас отвечу, и при этом
[44:48.520 --> 44:52.680]  пересекались бы не больше, чем по одному человеку, потому что иначе они опять морду друг
[44:52.680 --> 45:02.240]  другу набьют, но они, правда, все равно морду набивают. Так, вопрос. Я сказал клика, потом сказал,
[45:02.240 --> 45:08.520]  ой, извините, антиклика стерна, писал независимое множество. Нас интересует независимое множество,
[45:08.520 --> 45:14.720]  я оговорился просто. Наши интересуют альфа, а не омега. Нас интересует независимое множество.
[45:14.720 --> 45:20.400]  Теперь я возвращаюсь к истории. Вот там ровно про это шла речь, как построить как можно больше
[45:20.400 --> 45:26.920]  множеств, чтобы они попарно мало пересекались, тогда у нас будет код, который исправляет некоторое
[45:26.920 --> 45:34.400]  количество ошибок. Ну бог с ними с пьяницами, ну теорию кодирования-то вы помните? Помните, да,
[45:34.400 --> 45:39.800]  что там кодируют-то не от пьянства, там кодируют именно так, чтобы исправлять ошибки на канале
[45:39.800 --> 45:47.800]  зашумлённым. И вот если множество соответствует векторам из нулей единиц, то чем меньше они
[45:47.800 --> 45:53.920]  пересекаются, тем больше ошибок мы можем исправить. Я про это всё рассказывал, там были матрицы Адамара,
[45:53.920 --> 46:00.240]  границы Плоткина, ну много чего было. Вот на самом деле то, что вот весь определённой yкт атаж,
[46:00.240 --> 46:05.800]  это в каком-то смысле вот история про кодирование. Ну просто напоминаю, друзья, чтобы у вас в голове
[46:05.800 --> 46:12.360]  мостик вот этот возник, это не нужно ни для чего, кроме понимания, ну знаете как, всё в мире
[46:12.360 --> 46:18.200]  взаимосвязанно. Вот в моих курсах на самом деле тоже всё взаимосвязанно. Я себя ощущаю господом бога.
[46:18.200 --> 46:30.040]  Ну не могу же я вас не развлечь, товарищи. Так, теперь давайте вернёмся к определению. Значит,
[46:30.040 --> 46:36.680]  смотрите, оно, я надеюсь, что оно перестало быть для вас слишком формальным игромостким после того,
[46:36.680 --> 46:43.120]  как я напомнил, что оно на самом деле про пьяниц, про вот этих вот, про теорию кодирования. Я только
[46:43.120 --> 46:59.080]  для этого вспомнил. Теперь, вот согласны ли вы, что я могу написать теперь вот так? Ну какая разница?
[46:59.800 --> 47:07.100]  У меня просто нет независимых множеств. Или длина самой длинной цепочки из независимых множеств,
[47:07.100 --> 47:12.640]  которые... а, я все время говорю «клика», я понял, я ещё и тут говорю «клика». Нет, это всё время
[47:12.640 --> 47:17.060]  независимое множество. Я понял, я всё время оговариваюсь, я теперь понял, почему вы спрашиваете.
[47:17.060 --> 47:23.240]  Вот это всё независимое множество. Не клики никакие. Это я всё время оговорю.
[47:23.240 --> 47:38.240]  Значит, друзья, ну вы согласны, да, что если размер вот этот вот L самого большого набора из независимых множеств, которые мало пересекаются между собой, равен нулю, то это в точности означает, что их просто нет.
[47:41.240 --> 47:49.240]  Ну, то же самое. Как x-катая первая равнялась нулю, так и y-катая первая будет равняться нулю. Согласны, нет?
[47:50.240 --> 47:56.240]  Но зачем я рассматриваю y-катая первая? Затем, чтобы заиметь липшицевость.
[47:57.240 --> 48:10.240]  Вот величина x-катая, вот эта, она абсолютно никоим образом не липшится, вы понимаете, да, ну число треугольников там, число независимых множеств на k вершинах.
[48:11.240 --> 48:14.240]  Вы одно ребро добавили, куча независимых множеств пропала.
[48:15.240 --> 48:24.240]  Этим общим ребром с этой общей парой вершин. Понимаете, да? То есть вот это ни разу не липшится от слова совсем, как сейчас принято говорить.
[48:26.240 --> 48:36.240]  Ничего с ней не сделаешь. Пришлось ввести вот такую вот случайную величину y-катая, чтобы она была липшицевой и уже к ней можно было применять что-то. Какая она липшицева? По кому?
[48:44.240 --> 48:51.240]  По ребрам. По ребрам, потому что мы говорим о том, что тут если и есть что-то общее, то не ребро, а вершина.
[48:51.240 --> 49:03.240]  То есть если эта величина увеличилась бы на два при добавлении ребра, то это бы означало, что какие-то два независимых множества по этим двум вершинам пересекаются.
[49:04.240 --> 49:07.240]  Понимаете, да, у нас это запрещено.
[49:10.240 --> 49:20.240]  y-катая липшицева по ребрам. Это не самая лучшая липшицевость, как вы помните, но этого нам хватит.
[49:21.240 --> 49:25.240]  В данном случае этого нам хватит. Она липшица по ребрамам.
[49:26.240 --> 49:31.240]  Ну а тогда, смотрите, я сейчас воспроизведу как раз ту цепочку, которую поленился воспроизводить для Чебышова.
[49:32.240 --> 49:36.240]  Сейчас вот прям всю эту цепочку смешных перегонок, которые Чебышов нам давал.
[49:37.240 --> 49:49.240]  Вот тут вот будет так, 2 в степени n, на вероятность того, что y-катая первая не больше, чем ноль, но равняться нулю и быть не больше, чем ноль для величины, которая отрицательных значений не принимает, это одно и то же.
[49:49.240 --> 49:55.240]  Дальше. Вот у вас должно в голове всплывать, вот мы такое уже делали.
[49:56.240 --> 50:00.240]  Вот как раз то неравенство с дисперсией квадратом мат ожидания, оно так и получалось.
[50:01.240 --> 50:10.240]  Здесь будет минус y-катая первая, больше ли б равняется нуля, да множе ли просто на минус 1. Вот было, было прямо вот оно так получалось.
[50:10.240 --> 50:27.240]  Дальше равно 2 в степени n, на вероятность того, что е-катая первая, минус y-катая первая, больше ли б равняется е-катая первая.
[50:28.240 --> 50:39.240]  И вот это вот согласно неравенству большого уклонения, ну вот того, который мы не доказывали, но которое похоже на историю с пьяницей.
[50:40.240 --> 50:59.240]  Значит оно, она это вероятность не больше, чем е маленькое, то есть 2.71 в степени минус, что, почему 2.72, но я понял, да хорошо.
[50:59.240 --> 51:10.240]  Основание натурального логарифма, так, минус, что там получается, е, y-катая первая в квадрате поделить на 2c из m по 2.
[51:14.240 --> 51:24.240]  Да, 2 в степени n я потерял, конечно, 2 в степени n. Да, вот эти 2 в степени n я потерял, старательно выписывая результат, который получается из липшицы.
[51:25.240 --> 51:31.240]  Но тут вот стояла буковка а там, тут было написано е-эф, а тут было еф.
[51:32.240 --> 51:42.240]  И говорилось, что если еф липшится по ребрам, то тут будет минус а квадрат, но вот наше а, это сейчас мат ожиданий y-катого первого, поделить на 2c из m по 2.
[51:43.240 --> 51:45.240]  Лори Опер в полном графе на мэй вершине.
[51:47.240 --> 51:50.240]  Так, друзья, кто-то сравнивает с тем, что я писал? Похоже?
[51:50.240 --> 51:51.240]  Похоже?
[51:53.240 --> 51:55.240]  Но вроде люди поддакивают, некоторые, смотри.
[51:56.240 --> 51:58.240]  Ну, должно быть, я стараюсь.
[51:59.240 --> 52:02.240]  Так, смотрите, но мы ж не знаем чему, все ужасно.
[52:03.240 --> 52:07.240]  Одно дело найти мат ожиданий x-катого, вот оно вам все, и дело с концом.
[52:09.240 --> 52:11.240]  А что такое мат ожидания y-катого?
[52:12.240 --> 52:20.240]  Жуть же какая-то, как считать среднее значение вот такой вот бешеной теоретикой кодировочной величины.
[52:22.240 --> 52:28.240]  Значит, мы сейчас сформулируем лему, которую, может быть, даже частично докажем.
[52:29.240 --> 52:34.240]  Где бы мне ее сформулировать? Давайте вот тут я ее сформулирую, лемма будет такая врезка.
[52:34.240 --> 52:44.240]  Лемма состоит в том, что мат ожидания y-катого первого больше либо равняется m в квадрате,
[52:45.240 --> 52:51.240]  поделить на 2k1 в четвертой степени, умножить на 1 плюс о малой от 1.
[52:52.240 --> 52:56.240]  Значит, сейчас, друзья, я вам кое-что поясню по поводу этой леммы, я ее докажу потом.
[52:57.240 --> 52:59.240]  Потом я ее докажу.
[53:00.240 --> 53:03.240]  Но сегодня мы это не закончим, но, в общем, я ее докажу.
[53:04.240 --> 53:08.240]  Естественно, вопрос в билетах, он будет разбит на много частей.
[53:09.240 --> 53:12.240]  Понятно, что все это доказывать в одном билете вам не придется.
[53:15.240 --> 53:18.240]  Да, здесь в знаменателе 2k1 в четвертой.
[53:19.240 --> 53:24.240]  Я прокомментирую, потом докажу, но давайте с помощью этой леммы, конечно, все получается.
[53:25.240 --> 53:28.240]  Потому что, смотрите, если эта лемма верна, то у нас получается вот так.
[53:28.240 --> 53:33.240]  Это равно просто 2 в степени n, на e в какой степени?
[53:34.240 --> 53:36.240]  Надо вот это возвести в квадрат.
[53:37.240 --> 53:41.240]  То есть будет m в четвертой, поделить на 4k1 в восьмой.
[53:42.240 --> 53:44.240]  4k1 в восьмой.
[53:45.240 --> 53:48.240]  И еще надо поделить вот на это, но это m в квадрат.
[53:49.240 --> 53:53.240]  Так, друзья, понятно, что дважды c из m под v это m в квадрат.
[53:53.240 --> 53:55.240]  Оно же в обе стороны верно.
[53:56.240 --> 53:58.240]  Уклонение в любую сторону, какая разница?
[54:03.240 --> 54:05.240]  Ну, прочитайте вот это вот-вот так.
[54:06.240 --> 54:10.240]  Это же то же самое, что ykt1 меньше либо равняется...
[54:11.240 --> 54:13.240]  Вот сюда перенесли.
[54:14.240 --> 54:15.240]  А?
[54:16.240 --> 54:18.240]  Вот так вот.
[54:18.240 --> 54:20.240]  Сейчас, ну, подождите.
[54:21.240 --> 54:23.240]  Нет, я неправильно сказал.
[54:24.240 --> 54:26.240]  Вы говорите f-ef больше либо равняется a.
[54:27.240 --> 54:29.240]  Но было и вот такое.
[54:30.240 --> 54:33.240]  f-ef меньше или равняется minus a.
[54:34.240 --> 54:35.240]  Такое же тоже было.
[54:36.240 --> 54:38.240]  И вот e и f.
[54:39.240 --> 54:42.240]  И вот f-ef меньше или равняется minus a.
[54:43.240 --> 54:45.240]  Такое же тоже было.
[54:45.240 --> 54:47.240]  Такое же тоже было.
[54:48.240 --> 54:51.240]  И вот его прочитайте в обратную сторону, вот туда перенесите.
[54:52.240 --> 54:54.240]  Это будет как раз ef-f больше либо равняется a.
[54:59.240 --> 55:01.240]  Ну, это сдвиг влево, пьяница ушел влево.
[55:04.240 --> 55:06.240]  Там все симметрично.
[55:07.240 --> 55:09.240]  Так, друзья, давайте подставим все-таки.
[55:10.240 --> 55:11.240]  Вот я вроде уже почти подставил.
[55:12.240 --> 55:14.240]  Тут надо еще поправить на один плюс о малой от единицы.
[55:15.240 --> 55:17.240]  То есть оно, во-первых, отсюда вылезает,
[55:18.240 --> 55:20.240]  а во-вторых, я еще c-ку заменил на m в квадрате пополам.
[55:21.240 --> 55:23.240]  Но это тоже в симптотике верно.
[55:24.240 --> 55:26.240]  То есть с точностью до 1 плюс о малой от единицы я прав.
[55:27.240 --> 55:29.240]  Что все корректно написано.
[55:30.240 --> 55:31.240]  Написано, все корректно.
[55:32.240 --> 55:34.240]  Теперь у нас получается, ну, давайте я еще раз перепишу.
[55:35.240 --> 55:37.240]  2 в степени n на e в степени
[55:38.240 --> 55:41.240]  minus m в квадрат 1 плюс о малой от единицы
[55:42.240 --> 55:45.240]  m в квадрат, потому что m в четвертой с m в квадрате сократилось,
[55:46.240 --> 55:50.240]  подденить на 4k1 в восьмой степени.
[55:51.240 --> 55:54.240]  Так, друзья, я надеюсь, понятно, что это стремится к нулю.
[55:55.240 --> 55:56.240]  Или нет?
[55:57.240 --> 55:59.240]  Ну, смотрите еще раз, m это что такое?
[56:00.240 --> 56:02.240]  Вот оно светится.
[56:04.240 --> 56:09.240]  То есть m в квадрате – это n в квадрате.
[56:09.240 --> 56:12.240]  Ну, поделить на логарифу в четвертой степени.
[56:13.240 --> 56:16.240]  То есть, если хотите, я уж ладно, перепишу еще раз.
[56:17.240 --> 56:19.240]  2 в степени n на e в степени
[56:20.240 --> 56:23.240]  minus n в квадрате на 1 плюс о малой от единицы.
[56:24.240 --> 56:26.240]  А тут будет...
[56:27.240 --> 56:29.240]  Слушайте, а k1 это что же логарифом, да?
[56:30.240 --> 56:32.240]  Ну ладно, ладно.
[56:33.240 --> 56:35.240]  На 4k1 в восьмой.
[56:35.240 --> 56:37.240]  И на что там?
[56:38.240 --> 56:41.240]  На логарифом в четвертой степени, вот такой.
[56:42.240 --> 56:46.240]  Но это вы меня вынуждаете, потому что никто не подтверждает, что все понятно.
[56:47.240 --> 56:48.240]  Я пишу очевидности.
[56:49.240 --> 56:51.240]  Ну, переписал, m в квадрате.
[56:52.240 --> 56:54.240]  Вот здесь, смотрите, тут просто экспонента,
[56:55.240 --> 56:57.240]  а тут e, ну отрицательная экспонента,
[56:58.240 --> 57:01.240]  с n в квадрате, ну там оно делится на какие-то степени логарифмов.
[57:02.240 --> 57:04.240]  Ладно, тут двенадцатая степень логарифма.
[57:05.240 --> 57:06.240]  Вот все примерно двойка.
[57:07.240 --> 57:11.240]  Это она убивает с огромным запасом обычную экспоненту.
[57:12.240 --> 57:14.240]  Это, конечно, все стремится к нулю со свистом.
[57:15.240 --> 57:19.240]  Видите, насколько мощнее вот этот гвоздь в гроб пьянства?
[57:24.240 --> 57:26.240]  Получилось даже сильнее, чем нам нужно, да.
[57:27.240 --> 57:28.240]  Сильно сильнее, чем нам нужно.
[57:29.240 --> 57:31.240]  То есть нам действительно наплевать в эту экспоненту,
[57:32.240 --> 57:34.240]  можно было ее чуть-чуть подчистить, там что-то в знаменатель загнать,
[57:35.240 --> 57:36.240]  но наплевать не нужно.
[57:40.240 --> 57:42.240]  Так, ну мне надо доказать теперь эту лему.
[57:43.240 --> 57:45.240]  Давайте, как я обещал, я сначала ее прокомментирую,
[57:46.240 --> 57:47.240]  а потом формально буду доказывать.
[57:48.240 --> 57:51.240]  Там формальное доказательство требует некоторых усилий, понимания.
[57:52.240 --> 57:53.240]  А смысл очень простой.
[57:54.240 --> 57:56.240]  Вот я же напомнил здесь, что это определение
[57:57.240 --> 58:01.240]  фактически строит нам такую вот, такую историю с теорией кодирования.
[58:02.240 --> 58:03.240]  Напомню.
[58:05.240 --> 58:10.240]  Ну может вы даже помните, мне казалось я это говорил, но может быть и нет.
[58:11.240 --> 58:16.240]  Вот смотрите, если мы возьмем yкт не от какого-то графа h,
[58:17.240 --> 58:23.240]  сейчас вот задумаю, а от графа km с чертой.
[58:24.240 --> 58:27.240]  Граф km с чертой, товарищи, это пустой граф.
[58:29.240 --> 58:33.240]  Ну km это полный граф, а с чертой это значит все ребра стерли.
[58:33.240 --> 58:37.240]  Каких не было провели, но их не было таких, которых не было.
[58:38.240 --> 58:39.240]  Поэтому это пустой граф.
[58:40.240 --> 58:43.240]  Вот что такое yкт на пустом графе?
[58:46.240 --> 58:52.240]  Нет, смотрите, я утверждаю, что это точно не больше, чем c из m Подова.
[58:53.240 --> 58:54.240]  Вот я хочу, чтобы это осознавали.
[58:55.240 --> 58:57.240]  Хотя бы те, кто ходят на лекции, чтобы это осознавали.
[58:58.240 --> 58:59.240]  Ну те, кто послушают тоже.
[59:00.240 --> 59:02.240]  Значит c из m Подова поделить на t из m Подова.
[59:03.240 --> 59:06.240]  Я этого не доказывал никогда, я уже не помню.
[59:07.240 --> 59:08.240]  Это очень простая вещь.
[59:09.240 --> 59:17.240]  У нас в каждой вот этой маленькой сарделечке отсутствующих ребер пар вершин.
[59:18.240 --> 59:20.240]  Вот столько, сколько в знаменателе.
[59:21.240 --> 59:25.240]  А всего пар вершин вот в этом графе km с чертой c из m Подова.
[59:26.240 --> 59:31.240]  Поскольку общих пар не должно быть, то количество таких сарделечек,
[59:31.240 --> 59:34.240]  просто по принципу дирихления, больше этой дроби.
[59:35.240 --> 59:37.240]  Друзья, ну это простое упражнение.
[59:38.240 --> 59:39.240]  Такой факт из теории Кадир.
[59:40.240 --> 59:43.240]  Но это примерно, мы к этому еще когда-нибудь вернемся.
[59:44.240 --> 59:45.240]  m квадрат на k квадрат.
[59:46.240 --> 59:48.240]  Так вот, я чего утверждаю-то в этой лемме?
[59:49.240 --> 59:51.240]  Это же надо интуитивно осознать, в этом есть содержательный смысл.
[59:52.240 --> 59:57.240]  Я утверждаю, что если мы теперь y берем не на пустом графе, а на случайном,
[59:57.240 --> 01:00:02.240]  то, конечно, вот эта величина, по идее, должна уменьшиться, если тут не пустой граф, а какой-то.
[01:00:03.240 --> 01:00:04.240]  Согласны?
[01:00:05.240 --> 01:00:11.240]  Вот я, когда беру на случайном графе с p равном 1 и 2, то в среднем она, если уменьшается, то ничтожно.
[01:00:12.240 --> 01:00:13.240]  k1 в квадрате раз.
[01:00:14.240 --> 01:00:15.240]  Ну это же логарифум.
[01:00:16.240 --> 01:00:17.240]  Понимаете, да?
[01:00:18.240 --> 01:00:21.240]  То есть, есть очевидная верхняя оценка, она верна для пустого,
[01:00:21.240 --> 01:00:24.240]  но, значит, она тем более верна для этого мат ожидания.
[01:00:25.240 --> 01:00:27.240]  Я утверждаю, что нижняя оценка почти такая же.
[01:00:28.240 --> 01:00:30.240]  Понятен смысл теперь этой леммы?
[01:00:35.240 --> 01:00:37.240]  Еще раз, у нас всего пар вершин.
[01:00:38.240 --> 01:00:40.240]  Т.е. замкодово вот в этом графе.
[01:00:41.240 --> 01:00:45.240]  В каждой сардельечке, которую мы ищем, независимое множество.
[01:00:46.240 --> 01:00:50.240]  Но нам же надо их построить так, чтобы они не имели общих пар вершин.
[01:00:51.240 --> 01:00:53.240]  Ну, значит, их не больше, чем вот эта дробь.
[01:00:59.240 --> 01:01:04.240]  Получается, что даже не на пустом графе, а на случайном графе в среднем оценка снизу почти такая же,
[01:01:05.240 --> 01:01:06.240]  что и на пустом графе.
[01:01:07.240 --> 01:01:13.240]  Получается, что даже не на пустом графе, а на случайном графе в среднем оценка снизу
[01:01:14.240 --> 01:01:16.240]  почти такая же, как на пустом сверху.
[01:01:17.240 --> 01:01:18.240]  Ну, значит, на любом сверху.
[01:01:20.240 --> 01:01:24.240]  Само yкт первое сверху оценивается как m в квадрате на k первое в квадрате.
[01:01:25.240 --> 01:01:29.240]  А мы утверждаем, что в среднем оно и снизу примерно так же оценивается.
[01:01:30.240 --> 01:01:32.240]  И вот за счет этого получается крутое стремление к нулю.
[01:01:33.240 --> 01:01:35.240]  Сейчас нормально объясню?
[01:01:37.240 --> 01:01:40.240]  Так, ну давайте попробуем начать доказательство этой леммы.
[01:01:41.240 --> 01:01:43.240]  Не хотелось бы все-таки откладывать это на следующий раз.
[01:01:44.240 --> 01:01:45.240]  Что-то я, наверное, успею рассказать.
[01:02:06.240 --> 01:02:11.240]  Ну, друзья, вы меня правильно поймите.
[01:02:12.240 --> 01:02:15.240]  Я, конечно, ни с кого не буду спрашивать вот эти все штучки-дрючки,
[01:02:16.240 --> 01:02:17.240]  которые я пояснениями даю.
[01:02:18.240 --> 01:02:20.240]  Но мне кажется, что если кто-то из вас осознает глубже,
[01:02:21.240 --> 01:02:22.240]  то от этого будет только польза.
[01:02:23.240 --> 01:02:26.240]  Поэтому я стараюсь рассказать максимально глубоко со всеми штучками-дрючками.
[01:02:27.240 --> 01:02:28.240]  Я понятно говорю, да?
[01:02:29.240 --> 01:02:32.240]  Это не мешает ведь вам воспринимать все-таки конву доказательства?
[01:02:32.240 --> 01:02:35.240]  Ну, я стараюсь вроде четко говорить, где штучки-дрючки,
[01:02:36.240 --> 01:02:38.240]  а где прям вот то, что формально нужно.
[01:02:39.240 --> 01:02:40.240]  Так, ну как доказывать лему?
[01:02:41.240 --> 01:02:42.240]  Это, кстати, безумно красиво тоже,
[01:02:43.240 --> 01:02:45.240]  потому что мы сейчас добавим случайности в некотором смысле.
[01:02:46.240 --> 01:02:47.240]  Значит...
[01:02:50.240 --> 01:02:52.240]  Страшно, да? Страшно стало.
[01:02:53.240 --> 01:02:54.240]  Ой, как страшно.
[01:02:55.240 --> 01:02:58.240]  Так, ну смотрите, вот пусть у нас, наоборот,
[01:02:59.240 --> 01:03:00.240]  пока уберем всякую случайность,
[01:03:00.240 --> 01:03:01.240]  пусть есть какой-то граф.
[01:03:02.240 --> 01:03:04.240]  Слушайте, можно я буду писать G? Ну а G, какая разница?
[01:03:05.240 --> 01:03:06.240]  Мне как-то привычнее G писать.
[01:03:07.240 --> 01:03:08.240]  Ну, это то же самое, что H, конечно.
[01:03:09.240 --> 01:03:10.240]  Есть какой-то граф.
[01:03:11.240 --> 01:03:12.240]  Есть какой-то граф.
[01:03:13.240 --> 01:03:24.240]  Вот, давайте возьмем в нем все его независимые множества на K1-вершинах.
[01:03:24.240 --> 01:03:30.240]  Нет, это шмат ожидания, число.
[01:03:31.240 --> 01:03:35.240]  Это просто число, среднее значение.
[01:03:36.240 --> 01:03:38.240]  Тут ничего, никакой вероятности нет.
[01:03:39.240 --> 01:03:41.240]  Так, возвращаемся сюда.
[01:03:42.240 --> 01:03:44.240]  Взяли какой-то совершенно конкретный граф G.
[01:03:45.240 --> 01:03:48.240]  Так, друзья, вы все вот там спеваете еще живы?
[01:03:49.240 --> 01:03:51.240]  Или я беседую только там с частью первого ряда?
[01:03:51.240 --> 01:03:54.240]  Я не кохнул остальных, нормально?
[01:03:55.240 --> 01:04:00.240]  Так, ну смотрите, взяли какой-то конкретный совершенно, пока не случайный, граф G.
[01:04:01.240 --> 01:04:05.240]  И хорошенько им обо что-то стукнули.
[01:04:06.240 --> 01:04:11.240]  Так, значит, и выбрали в нем все независимые множества, какие в нем есть.
[01:04:12.240 --> 01:04:18.240]  Ну, давайте их как-нибудь обозначим, эти независимые множества, как их обозначить.
[01:04:18.240 --> 01:04:23.240]  Ну, пусть будет там какой-нибудь K1.
[01:04:24.240 --> 01:04:29.240]  Ну, а последнее, товарищи, это понятно, что это XKT первое от G.
[01:04:30.240 --> 01:04:32.240]  Ну, сколько всего в графе G независимых множеств.
[01:04:33.240 --> 01:04:37.240]  XKT первое от G независимых множеств на K1-вершинах.
[01:04:38.240 --> 01:04:41.240]  Взяли граф, нашли по нему все эти множества.
[01:04:42.240 --> 01:04:48.240]  Ну, правда же, мы же так и определили, XKT от G это число независимых множеств на K-вершинах.
[01:04:49.240 --> 01:04:52.240]  Ну, XKT первое от G это число независимых множеств на K1-вершинах.
[01:04:53.240 --> 01:04:55.240]  Вот, возьмем просто, их все перечислим.
[01:04:56.240 --> 01:04:58.240]  Возьмем их все перечислим.
[01:04:59.240 --> 01:05:02.240]  Как-нибудь, наверное, знаете, это мы тоже обозначим.
[01:05:03.240 --> 01:05:10.240]  Введем такое K, красивое, каллиграфическое, которое будет представлять собой множество из вот этих товарищей.
[01:05:11.240 --> 01:05:19.240]  Ну, мысло очень простое.
[01:05:20.240 --> 01:05:23.240]  Взяли граф, взяли все его независимые множества с нужным числом вершин.
[01:05:24.240 --> 01:05:32.240]  Перечислили, получилось какое-то множество K большое, красивое, состоящее вот из этих независимых кусочков, дырочек таких в графе.
[01:05:33.240 --> 01:05:34.240]  Так.
[01:05:39.240 --> 01:05:44.240]  Ну, ну, сделали или не сделали, что бы с этого хорошего-то.
[01:05:45.240 --> 01:05:49.240]  Давайте сделаем, как я обещал, дополнительную случайность.
[01:05:50.240 --> 01:05:52.240]  Вот граф пока не случайный, граф просто конкретный.
[01:05:53.240 --> 01:05:59.240]  Ну, а когда он случайный, ну что же, в конечном счете конкретный, просто ему присвоена вероятность какая-то, вы же понимаете.
[01:05:59.240 --> 01:06:03.240]  Случайно, в каком смысле, что у него просто есть некоторая вероятность возникнуть?
[01:06:04.240 --> 01:06:07.240]  Если он возник, то вот эти множества совершенно конкретные.
[01:06:08.240 --> 01:06:11.240]  Если он случайный, ну в каком-то смысле K красивое, это случайная совокупность.
[01:06:12.240 --> 01:06:13.240]  Ну вот.
[01:06:14.240 --> 01:06:19.240]  Значит, давайте возьмем какую-нибудь чиселку, как бы ее обозначить.
[01:06:20.240 --> 01:06:26.240]  Я обычно пишу K со звездочкой, но просто чтобы не путать ее с вероятностью ребра случайного графа,
[01:06:26.240 --> 01:06:28.240]  или вероятностью ее отсутствия.
[01:06:29.240 --> 01:06:35.240]  Не хочу букву P писать, хотя у нас сейчас в нашей задаче P равно 1-2.
[01:06:36.240 --> 01:06:40.240]  Я все равно не хочу писать P, потому что это другая вероятность.
[01:06:41.240 --> 01:06:48.240]  Это какое-то число, пока что просто из отрезка 0,1, которое, товарищи, мы потом чуть-чуть позже подберем оптимально.
[01:06:49.240 --> 01:06:51.240]  Так, чтобы все хорошо получилось.
[01:06:51.240 --> 01:06:54.240]  Вот возьмем число K со звездочкой.
[01:06:57.240 --> 01:06:58.240]  Так.
[01:06:59.240 --> 01:07:02.240]  И проредим множество K.
[01:07:03.240 --> 01:07:08.240]  Проредим, это значит, мы будем бросать монетку с вероятностью успеха K со звездочкой.
[01:07:09.240 --> 01:07:15.240]  И если в очередном бросании успех, то мы сохраняем жизнь вот этому независимому множеству.
[01:07:16.240 --> 01:07:17.240]  Сейчас быстро говорю, да?
[01:07:18.240 --> 01:07:24.240]  Сейчас увидите, ну может не сейчас увидите, но я не хочу бросать, потому что это 15 минут потеря.
[01:07:25.240 --> 01:07:27.240]  Но увидите, вы охренеете, когда поймете, зачем.
[01:07:28.240 --> 01:07:30.240]  Вот человек придумал такое, вы увидите.
[01:07:31.240 --> 01:07:33.240]  Нет, ну слушайте, ну нельзя же ужасаться сразу.
[01:07:34.240 --> 01:07:37.240]  С другой стороны, вот вы лучше понимаете смысл слова катарсис.
[01:07:38.240 --> 01:07:43.240]  Ну что такое катарсис? Это ведь завершение трагедии, когда случается просветление души.
[01:07:44.240 --> 01:07:48.240]  То есть вот вы сейчас смотрите на меня, что за хрень происходит.
[01:07:49.240 --> 01:07:51.240]  И вдруг бабах, и оно все сошлось.
[01:07:52.240 --> 01:07:53.240]  Это и есть катарсис, понимаете?
[01:07:54.240 --> 01:07:58.240]  Сейчас, друзья, я очень быстро говорю, или вы успеваете фиксировать, что происходит?
[01:07:59.240 --> 01:08:04.240]  Я беру и от множества K, ну перехожу, я не знаю, давайте C.
[01:08:05.240 --> 01:08:07.240]  Назовем его как-нибудь.
[01:08:08.240 --> 01:08:10.240]  Как-нибудь назовем, пусть множество C будет.
[01:08:14.240 --> 01:08:18.240]  Так, друзья, друзья, ну пожалуйста, давайте только сосредоточим.
[01:08:19.240 --> 01:08:21.240]  Если мы будем долго дискутировать, мы правда ничего не успеем.
[01:08:22.240 --> 01:08:26.240]  Еще раз, как мы перешли? Мы взяли такую тхему испытаний и вернули.
[01:08:27.240 --> 01:08:30.240]  Вот столько раз бросили монетку с вероятностью успеха Q со звездочкой.
[01:08:31.240 --> 01:08:36.240]  И если в очередном бросании успех, то сохранили жизнь множество отсюда.
[01:08:37.240 --> 01:08:45.240]  Ну то есть, например, с вероятностью Q со звездочкой вот в этой степени мы сохраняем все независимое множество.
[01:08:46.240 --> 01:08:50.240]  Получается такое случайное подмножество этого множества K.
[01:08:51.240 --> 01:08:53.240]  Ну такое случайное подмножество.
[01:08:54.240 --> 01:08:55.240]  Хорошо?
[01:08:56.240 --> 01:08:57.240]  Ну вот зачем-то оно получилось.
[01:08:58.240 --> 01:08:59.240]  Пока поверьте мне, что это поможет.
[01:09:00.240 --> 01:09:01.240]  Почему это поможет? Будет катарсис.
[01:09:02.240 --> 01:09:05.240]  Ну я же для чего стараюсь, чтобы вы поняли какие-то методы.
[01:09:06.240 --> 01:09:09.240]  Не только узнали факты, но мы же с вами не гуманитаристикой занимаемся.
[01:09:10.240 --> 01:09:11.240]  Мы хотим научиться эти факты доказывать.
[01:09:12.240 --> 01:09:14.240]  Может быть вы самостоятельно что-то получите потом.
[01:09:15.240 --> 01:09:17.240]  Вот взяли какое-то такое случайное множество.
[01:09:18.240 --> 01:09:22.240]  Теперь в итоге у нас получаются такие пары G и C от G.
[01:09:23.240 --> 01:09:34.240]  G это уже теперь случайный граф, а C от G это случайное подмножество в множестве независимых множества этого случайного графа.
[01:09:36.240 --> 01:09:37.240]  Такие пары.
[01:09:38.240 --> 01:09:43.240]  Но вероятность пары это просто 1 поделить на 2 в степени C и знам по 2.
[01:09:44.240 --> 01:09:48.240]  Это вероятность графа умножить на вероятность C от этого же.
[01:09:49.240 --> 01:09:55.240]  То есть это просто вот такое немножко усиленное вероятностное пространство.
[01:09:56.240 --> 01:10:04.240]  То есть мы берем не просто случайный граф, а случайный граф и на нем случайное подмножество множества его независимых множеств.
[01:10:07.240 --> 01:10:12.240]  Случайный граф и в его множестве независимых множеств случайное подмножество.
[01:10:15.240 --> 01:10:18.240]  Так, друзья, нить-то не должна потеряться.
[01:10:19.240 --> 01:10:20.240]  Понятно, что произошло.
[01:10:21.240 --> 01:10:23.240]  Для каждого графа взяли случайную такую совокупность.
[01:10:24.240 --> 01:10:32.240]  Теперь, смотрите, давайте, ну, виноват, ведем еще две величины или два множества вернее.
[01:10:33.240 --> 01:10:35.240]  Значит, будет множество.
[01:10:36.240 --> 01:10:40.240]  Я сейчас, вы скоро поймете, нам же надо с этим разобраться.
[01:10:41.240 --> 01:10:42.240]  Вы скоро поймете.
[01:10:43.240 --> 01:10:48.240]  Я бы, конечно, хотел сегодня успеть, поэтому давайте сосредоточено от того, что вы сейчас чего-то не до конца понимаете.
[01:10:49.240 --> 01:10:52.240]  Если мы тут будем дискутировать, мы до катарсиса не дойдем.
[01:10:54.240 --> 01:10:56.240]  Значит, W от G.
[01:10:57.240 --> 01:11:02.240]  Сейчас, товарищи, это множество пар A и B.
[01:11:04.240 --> 01:11:13.240]  Таких, что A и B это подмножество вершин нашего графа.
[01:11:15.240 --> 01:11:17.240]  Множество пар подмножеств.
[01:11:18.240 --> 01:11:24.240]  Таких, что мощность A пересеченного с B не больше единицы.
[01:11:31.240 --> 01:11:33.240]  А, можно, знаете как, я лучше напишу.
[01:11:34.240 --> 01:11:37.240]  Чтобы понять не было, извините, A и B нехорошо.
[01:11:38.240 --> 01:11:39.240]  Давайте я лучше вот так напишу.
[01:11:39.240 --> 01:11:49.240]  Таких, что КАИТОЕ пересеченное с КАЖИТОМ не больше единицы.
[01:11:50.240 --> 01:11:53.240]  Чего писать заново, когда у нас есть обозначение для независимых множеств?
[01:11:54.240 --> 01:12:01.240]  Меня просто интересует количество пар независимых множеств, которые мало пересекаются.
[01:12:02.240 --> 01:12:05.240]  То есть, тех, которые могут присутствовать в определении Y.
[01:12:06.240 --> 01:12:08.240]  Помните, что такое Y?
[01:12:09.240 --> 01:12:13.240]  Наймальное число независимых множеств, каждые два из которых пересекаются вот так.
[01:12:14.240 --> 01:12:15.240]  Помните, да?
[01:12:16.240 --> 01:12:23.240]  Вот мы рассмотрим множество тех пар, которые могут служить кандидатами на попадание вот в эту цепочку.
[01:12:25.240 --> 01:12:26.240]  Поняли определение W?
[01:12:28.240 --> 01:12:29.240]  Нет?
[01:12:31.240 --> 01:12:33.240]  Так, отлично.
[01:12:34.240 --> 01:12:40.240]  И W штрих, оно уже будет зависеть от V, от C и от G, от C.
[01:12:42.240 --> 01:12:44.240]  Они по определению все независимые, понимаете?
[01:12:45.240 --> 01:12:47.240]  Поэтому они соответствуют определению Y.
[01:12:48.240 --> 01:12:50.240]  Там же как раз независимые множества.
[01:12:51.240 --> 01:12:54.240]  Так, теперь смотрите, это соответствует прореженной ситуации.
[01:12:55.240 --> 01:12:58.240]  То есть, пишем то же самое КАИТОЕ КАЖИТОЕ.
[01:12:59.240 --> 01:13:04.240]  Да, смотрите, я их пишу в фигурные скобки, это значит, что они неупорядочены.
[01:13:05.240 --> 01:13:07.240]  Ну то есть, нам плевать в каком порядке.
[01:13:08.240 --> 01:13:15.240]  Так, таких что то же самое, но при этом КАИТОЕ КАЖИТОЕ принадлежат С.
[01:13:16.240 --> 01:13:17.240]  Вот так.
[01:13:23.240 --> 01:13:24.240]  Ну тоже понятно.
[01:13:24.240 --> 01:13:34.240]  Мы зачем-то выбираем кандидатов на попадание в определение Y не из всех независимых множеств, а только из C, которая получена прорешением.
[01:13:34.240 --> 01:13:35.240]  Так.
[01:13:44.240 --> 01:13:45.240]  Так.
[01:13:47.240 --> 01:13:49.240]  Так, друзья, пока не умерли.
[01:13:49.240 --> 01:13:51.240]  Формально, понятно?
[01:13:52.240 --> 01:13:56.240]  Держитесь, осталось не так много времени, но я думаю, что я успеваю, мы можем продолжить.
[01:13:56.240 --> 01:13:58.240]  Значит, смотрите.
[01:14:03.240 --> 01:14:09.240]  Давайте математическое ожидание мощности W.
[01:14:14.240 --> 01:14:15.240]  Мы его не знаем, конечно.
[01:14:16.240 --> 01:14:17.240]  Его нас нет.
[01:14:18.240 --> 01:14:19.240]  Мы его не знаем.
[01:14:20.240 --> 01:14:21.240]  Мы его не знаем.
[01:14:21.240 --> 01:14:23.240]  Мы его не знаем, конечно, его надо считать.
[01:14:24.240 --> 01:14:25.240]  Этим мы займемся в следующий раз.
[01:14:26.240 --> 01:14:31.240]  Но это не очень сложно, я там частично проглочу какие-то сложные выкладки, все будет легко.
[01:14:32.240 --> 01:14:36.240]  Ну давайте, вот мат ожидания пока обозначим просто кандидат пополам.
[01:14:37.240 --> 01:14:38.240]  Пополам?
[01:14:38.240 --> 01:14:39.240]  Ну почему пополам?
[01:14:39.240 --> 01:14:43.240]  Потому что я сказал, они неупорядоченные, а считать будет удобно для упорядоченных.
[01:14:44.240 --> 01:14:45.240]  В этом смысле пополам.
[01:14:46.240 --> 01:14:48.240]  Вот так просто обозначим.
[01:14:49.240 --> 01:14:50.240]  Вот так просто обозначим.
[01:14:51.240 --> 01:14:52.240]  Дельта пополам.
[01:14:53.240 --> 01:14:56.240]  Вот, сейчас нужно что осознать?
[01:14:57.240 --> 01:14:59.240]  Во-первых, а, и вот еще что.
[01:15:00.240 --> 01:15:03.240]  Совсем временно вот это вот мат ожидания, вот это.
[01:15:04.240 --> 01:15:05.240]  Вот это.
[01:15:06.240 --> 01:15:10.240]  Временно обозначим короткобуквой мю, чтобы не таскать все эти громоздкие обозначения.
[01:15:11.240 --> 01:15:12.240]  Просто назовем вот это все мю.
[01:15:13.240 --> 01:15:20.240]  Так, смотрите, мат ожидания, мощность к, ну это естественно мю.
[01:15:21.240 --> 01:15:24.240]  Потому что мощность к, это как раз экскатая первая.
[01:15:26.240 --> 01:15:33.240]  Мат ожидания мощности к, это мат ожидания экскатовой первой, то есть мю в наших нынешних коротких обозначениях.
[01:15:34.240 --> 01:15:35.240]  Так, друзья, понятно?
[01:15:35.240 --> 01:15:36.240]  Так, друзья, понятно?
[01:15:37.240 --> 01:15:42.240]  Так, теперь смотрите, мат ожидания мощности с.
[01:15:43.240 --> 01:15:46.240]  Мат ожидания мощности с, какое?
[01:15:51.240 --> 01:15:53.240]  Мю на ку со звездочкой, конечно, да.
[01:15:54.240 --> 01:15:58.240]  Конечно, ну как в схеме Бернульны, надо умножить на вероятность успеха.
[01:15:59.240 --> 01:16:00.240]  Мю на ку со звездочкой.
[01:16:00.240 --> 01:16:01.240]  Мю на ку со звездочкой.
[01:16:02.240 --> 01:16:06.240]  Теперь смотрите, а мат ожидания мощности w'.
[01:16:07.240 --> 01:16:08.240]  Это хороший вопрос.
[01:16:09.240 --> 01:16:10.240]  Мат ожидания мощности w'.
[01:16:11.240 --> 01:16:12.240]  Кто скажет, чему равно?
[01:16:15.240 --> 01:16:18.240]  Ну, наверное, дельта пополам там будет присутствовать, да?
[01:16:19.240 --> 01:16:20.240]  Потому что мы проредили w.
[01:16:23.240 --> 01:16:24.240]  Абсолютно верно.
[01:16:24.240 --> 01:16:30.240]  Наверное, дельта пополам на ку со звездочкой в квадрате.
[01:16:31.240 --> 01:16:34.240]  Конечно, потому что нам надо, чтобы оба множества попали в с.
[01:16:35.240 --> 01:16:39.240]  Каждый из них, независимо от другого, попадает с вероятностью ку со звездочкой.
[01:16:40.240 --> 01:16:42.240]  Чтобы с вероятностью ку со звездочкой в квадрате.
[01:16:45.240 --> 01:16:47.240]  Все, отлично, смотрите, что мы сейчас сделаем.
[01:16:48.240 --> 01:16:49.240]  Сейчас будет абсолютно гениальный ход.
[01:16:49.240 --> 01:16:59.240]  Так, друзья, помните, у нас когда-то доказывалась великая теория Мердыша про то, что вбивают графы с большим обхватом и большим хроматическим числом?
[01:17:00.240 --> 01:17:02.240]  Там была гениальная идея что-то выкинуть лишнее.
[01:17:04.240 --> 01:17:05.240]  Помните, была такая?
[01:17:06.240 --> 01:17:07.240]  Значит, знаете, что мы сейчас сделаем?
[01:17:08.240 --> 01:17:15.240]  Мы сейчас из с, вот этого, которое у нас получилось, из с, я тебе скажу, из с.
[01:17:15.240 --> 01:17:40.240]  Выкинем по одному представителю, я будет кататься, по одному представителю из каждой пары, принадлежащей к этой паре.
[01:17:41.240 --> 01:17:50.240]  Принадлежащей w'.
[01:17:51.240 --> 01:17:55.240]  В w' находятся пары множества, которые находятся в с.
[01:17:56.240 --> 01:18:02.240]  Ух, как же-то я так.
[01:18:02.240 --> 01:18:10.240]  Конечно, здесь больше либо равняются двойки, наоборот, мне не больше единиц, это плохие пары, виноват.
[01:18:11.240 --> 01:18:16.240]  Портал Катар застанет. Загубил все.
[01:18:17.240 --> 01:18:19.240]  Конечно, больше либо равняется двойки.
[01:18:20.240 --> 01:18:21.240]  Не, ну, друзья, это не очень страшно.
[01:18:22.240 --> 01:18:25.240]  На самом деле ничего страшного не случилось, ну, противоположное неравенство должно быть.
[01:18:26.240 --> 01:18:31.240]  Это не те пары, которые должны попасть в ук, а те, которые не должны туда попасть.
[01:18:32.240 --> 01:18:36.240]  Не, ну, друзья, ну, слушайте, с точки зрения сущности, пока ничего не поменялось.
[01:18:37.240 --> 01:18:40.240]  Ну, как? Ну, хорошо, вот это пары, которых не должно быть.
[01:18:43.240 --> 01:18:44.240]  Что?
[01:18:45.240 --> 01:18:50.240]  Да точно так же. Нет, здесь тоже больше либо равно. Это вот сохранилось, конечно.
[01:18:51.240 --> 01:18:54.240]  Мы берем w с каким-то условием и его прореживаем просто.
[01:18:55.240 --> 01:19:01.240]  Так, чтобы вот мат ожидания мощности w' было мат ожиданием w на q2.
[01:19:03.240 --> 01:19:09.240]  Да что вас так смутило-то сейчас? Ну, но поменял я это неравенство от этого.
[01:19:10.240 --> 01:19:13.240]  Что изменилось? Вы пока все равно не понимали, зачем оно нужно в ту сторону.
[01:19:14.240 --> 01:19:17.240]  Теперь логично выкидывать. Я почему вспомнил?
[01:19:18.240 --> 01:19:21.240]  Ты вот поглядел сюда, поглядел сюда и перестаю понимать, что происходит.
[01:19:22.240 --> 01:19:25.240]  Больше же ничего не произошло, товарищи. Ну, что вас так смутило-то?
[01:19:26.240 --> 01:19:29.240]  Ну, звонок, ну, давайте еще пять минут. Ну, что же я могу сделать?
[01:19:29.240 --> 01:19:34.240]  Ну, я хочу просто, чтобы было понятно. Вот выкинем из c по одному представителю из каждой пары.
[01:19:35.240 --> 01:19:39.240]  У нас останется какое-то множество c со звездочкой.
[01:19:40.240 --> 01:19:46.240]  Друзья, но вы понимаете, что в этом множестве уже нет ни одной пары, которая пересекается вот так.
[01:19:47.240 --> 01:19:55.240]  Вот в этом множестве каждые две k1 элементные штуковины пересекаются так, как нам нужно с точки зрения вот этого определения.
[01:19:56.240 --> 01:19:59.240]  Ну, сейчас будет. Катар, смотрите.
[01:20:00.240 --> 01:20:02.240]  Я, y, kt первое.
[01:20:03.240 --> 01:20:07.240]  Тем самым, больше либо равняется мат ожидания мощности c со звездочкой.
[01:20:08.240 --> 01:20:15.240]  Но больше либо равняется, потому что мы предложили некий рандомизированный алгоритм от искания вот той цепочки, которая заложена сюда.
[01:20:16.240 --> 01:20:21.240]  c со звездочкой это c, из которого выкинули по одному элементу из w штрих.
[01:20:21.240 --> 01:20:26.240]  Но, может быть, из разных мы выкинули одно и то же. Я не знаю, так могло получиться.
[01:20:27.240 --> 01:20:31.240]  Поэтому здесь тоже надо писать не равно, а больше либо равно. Но это хорошо для нас.
[01:20:32.240 --> 01:20:38.240]  Это мат ожидания мощности c минус мат ожидания мощности w штрих.
[01:20:39.240 --> 01:20:50.240]  По линейности просто. Мы из c вычли w штрих, но при этом мы могли что-то вычитать не столько раз, но тогда будет больше либо равно.
[01:20:51.240 --> 01:20:56.240]  Так, переписываем. Мы же знаем, что это такое. Вот мат ожидания мощности c.
[01:20:57.240 --> 01:21:04.240]  Это mu на q со звездочкой, а тут получается дельта пополам на q со звездочкой в квадрате.
[01:21:07.240 --> 01:21:13.240]  Вот катарсис неполный, потому что полный будет в начале следующей лекции, но неполный, смотрите, в чем состоит.
[01:21:14.240 --> 01:21:18.240]  Мы же вольны были с самого начала выбрать q со звездочкой оптимально.
[01:21:18.240 --> 01:21:22.240]  Мы его просто хотим, чтобы он был в 0.1.
[01:21:23.240 --> 01:21:35.240]  За счет того, что здесь получилась квадратичная функция после этой дополнительной рандомизации, выбор q со звездочкой дает оптимизацию этой разности.
[01:21:36.240 --> 01:21:43.240]  Но какое здесь q со звездочкой оптимально? Надо производную приравнять к нулю, там минус b поделить на 2, как в школе учат.
[01:21:44.240 --> 01:21:53.240]  Так, что там получается? Минус mu поделить на минус дельта, то есть mu поделить на дельта.
[01:21:58.240 --> 01:22:06.240]  Друзья, ну давайте подставим mu, деленное на дельта еще сюда, то у нас получится mu квадрат поделить на дельта,
[01:22:07.240 --> 01:22:16.240]  минус дельта пополам, mu квадрат на дельта квадрат, чпок-чпок, mu квадрат на дельта,
[01:22:17.240 --> 01:22:21.240]  минус mu квадрат на 2 дельта, это mu квадрат на 2 дельта.
[01:22:24.240 --> 01:22:25.240]  Сейчас, друзья, понятно?
[01:22:29.240 --> 01:22:31.240]  Ну нам-то надо было вот это получить.
[01:22:33.240 --> 01:22:34.240]  Что отсюда следует?
[01:22:36.240 --> 01:22:46.240]  Ну слушайте, ну я не знаю, я должен, наверное, вас отпустить, у вас следующая пара.
[01:22:47.240 --> 01:22:52.240]  Должен, потому что если мне дать еще 10 нит, я все объясню, но это жду как, ну всю перерыв весь забирать.
[01:22:53.240 --> 01:22:54.240]  Это не мой стиль.
[01:22:55.240 --> 01:23:00.240]  Значит, друзья, катарсис абсолютный будет состоять в том, что, смотрите, для того, чтобы получить вот это,
[01:23:00.240 --> 01:23:06.240]  смотрите, для того, чтобы вот это получить, мы лему чуть-чуть не доказали, для того, чтобы вот это получить отсюда,
[01:23:07.240 --> 01:23:10.240]  нужно, чтобы между mu и дельта было совершенно понятное соотношение.
[01:23:11.240 --> 01:23:14.240]  Ну, вот это mu квадрат на дельта должно вот этому оказаться равным.
[01:23:15.240 --> 01:23:28.240]  Мы увидим, товарищи, что вот это вот q со звездочкой принадлежит 0,1 ровно потому, что k1 это m в кубе плюсу малое от единицы.
[01:23:30.240 --> 01:23:35.240]  Я уж вам раскрою этот катарсис, а то вы забудете к следующему разу.
[01:23:36.240 --> 01:23:42.240]  Вот было совершенно загадочное, мы долго дискутировали, откуда, зачем, вот оно нужно, чтобы вот это попало в 0,1.
[01:23:43.240 --> 01:23:45.240]  Ну, мы это посчитаем аккуратно в начале.
[01:23:46.240 --> 01:23:48.240]  Такая жизнь.
