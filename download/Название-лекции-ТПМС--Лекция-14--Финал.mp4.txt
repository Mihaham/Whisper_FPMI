[00:00.000 --> 00:11.600]  Итак, приветствую всех. У нас сегодня то ли последнее, то ли предпоследнее занятие,
[00:11.600 --> 00:18.640]  ну, в зависимости от того, что мы решим, потому что у нас ещё есть, кажется, и, может быть, даже
[00:18.640 --> 00:25.360]  немного времени в следующую субботу, и темы, которые мы не успели покрыть, которые совершенно
[00:25.360 --> 00:32.360]  бонусные, но те, кто захочет, может быть, решит их послушать. Но по плану у нас сегодня последнее
[00:32.360 --> 00:38.440]  занятие, финальная лекция, и на этой лекции мы не будем что-то новое изучать, хотя, может быть,
[00:38.440 --> 00:43.360]  я случайно неаккуратно расскажу что-нибудь. Но наша цель сегодня просто поговорить о том,
[00:43.360 --> 00:49.520]  как этот курс был устроен, о чём он был, что оттуда можно вынести и чем можно заняться дальше,
[00:49.520 --> 00:56.760]  потому что было бы довольно наивно надеяться, что по истечении трёх месяцев мы освоили большую
[00:56.760 --> 01:02.280]  дисциплину, которую люди разрабатывают уже не первые десяток лет и до сих пор не нашли какого-то
[01:02.280 --> 01:10.720]  окончательного, идеального, всем удобного решения. Я надеюсь, что сегодня не только я буду говорить,
[01:10.720 --> 01:14.520]  а в первую очередь, может быть, вы будете задавать вопросы. У меня есть какой-то внутренний план,
[01:14.520 --> 01:23.120]  ну, такой довольно свободный, чтобы я хотел рассказать, но мне важно, чтобы вы получили ответы на какие-то
[01:23.120 --> 01:28.520]  вопросы, которые у вас остались к этому моменту. Ну, не в смысле там, как что-то синхронизировать или
[01:28.520 --> 01:34.520]  почему у меня переполняется StackBlock, FreeMuteX и с Fork в онлоке, а какие-то более фундаментальные,
[01:34.520 --> 01:41.280]  более масштабные вопросы про организацию всего, про то, как это можно в своей голове уложить.
[01:41.280 --> 01:45.440]  Вот, ну, если у нас прямо сейчас есть вопросы, то можно прямо с них и начать.
[01:45.440 --> 01:49.520]  Про ThreadSanitizer и Coroutine, это пока не вопрос.
[01:49.520 --> 01:57.520]  Трэд санитайзер с корутинами C++, я, честно говоря, не вижу прямой связи между ThreadSanitizer.
[01:57.520 --> 02:08.880]  Я не знаю, мне кажется, что ThreadSanitizer и Coroutine C++ никак не связаны между собой абсолютно,
[02:08.880 --> 02:15.280]  но просто вот Coroutine – это какой-то код. ThreadSanitizer ищет обращение
[02:15.280 --> 02:21.120]  рейса к… Ну, может быть, все в другом проблеме. Ну, еще раз, да. Давай по порядку. Мы сегодня не
[02:21.120 --> 02:27.920]  разбираемся с какими-то мелочами. Я вот попросил этого не делать, и мы начали с этого. Мы не про мелочи,
[02:27.920 --> 02:34.640]  мы про какие-то инженерные подробности, вот как там что-то починить сейчас, а про то,
[02:34.720 --> 02:45.520]  как организовать все те знания, все те подходы, которые мы за эти три месяца коротких довольно…
[02:45.520 --> 02:49.040]  Куда вообще движется конкарнс? Куда движется конкарнс?
[02:49.040 --> 02:52.640]  Давай сначала итог какой-то подведем, чтобы… Видите, куда движется конкарнс.
[02:52.640 --> 02:58.720]  Ладно, значит, с вопросами, пока у меня трудно, я… Вопросы, или маленькие, или не те, которые я хочу,
[02:58.720 --> 03:03.520]  видимо, я морально не готов на них пока отвечать в таком формате. Давайте сначала все-таки расскажу
[03:03.520 --> 03:10.400]  то, что хочу, а потом уже мы… Уже по мере того, как я что-то рассказываю, скорее нужно на это,
[03:10.400 --> 03:18.560]  наверное, откликаться и уточнять, и спрашивать что-то. Что мы делали в этом семестре? Мы с вами…
[03:18.560 --> 03:25.800]  Ну, как бы, начну с главного, с самого большого. Чем мы глобально занимались весь семестр? Мы с вами,
[03:25.800 --> 03:32.280]  как можно было заметить, писали некоторую библиотеку, некоторый фреймворк для того, чтобы в
[03:32.320 --> 03:40.280]  этом фреймворке можно было… Через этот фреймворк можно было описывать и исполнять какие-то конкурентные
[03:40.280 --> 03:46.360]  активности, под которыми мы понимаем, видимо, какие-то запросы пользователей. Ну, конкретная там
[03:46.360 --> 03:52.040]  логика обслуживания пользователей нас совершенно не волновала. Она нас будет волновать, но скорее вот
[03:52.040 --> 03:56.680]  осенью на спецкурсе кто захочет послушать про распределенные системы. Ну, можно себе представить
[03:56.680 --> 04:01.440]  какую-то более простую логику, нежели там какие-то сложные распределенные системы с консенсусом.
[04:01.440 --> 04:07.960]  Но в любом случае, в этом курсе это было в топик, мы в первую очередь занимались тем, собственно,
[04:07.960 --> 04:18.440]  как описать эти активности и как их исполнять. И понятно, что у нас есть компьютер, у нас есть
[04:18.440 --> 04:23.920]  тюринг полный язык, можно что угодно написать и как угодно исполнять. Наша цель была в том, чтобы,
[04:23.920 --> 04:29.760]  во-первых, описывать эти конкурентные активности и какие-то сценарии, их взаимодействие, отмены,
[04:29.760 --> 04:37.520]  синхронизации было очень удобно, а во-вторых, чтобы все это могло очень эффективно исполняться. И вот
[04:37.520 --> 04:46.560]  это две большие половины курс, две половины курсы, они одинаково важны, и вот перед нами список лекций,
[04:46.560 --> 04:52.360]  и вот каждая лекция, она относится либо к одной половине, либо к другой. Либо мы говорим про
[04:52.360 --> 04:57.840]  выразительные средства, про то, как мы описываем обработчики запросов, либо мы говорим про рантайм,
[04:57.840 --> 05:03.920]  про среду исполнения, которое эти обработчики должны эффективно исполнять. Ну и из чего наш курс
[05:03.920 --> 05:11.400]  начался? Мы начали его с взаимного исключения, это как раз вот первая базовая тема про рантайм,
[05:11.400 --> 05:16.520]  по сути. Про то, как что-то исполнять, а чтобы что-то исполнять, нужно просто уметь решать
[05:16.520 --> 05:25.040]  простейшую задачу, синхронизировать обращение разных ядер к общим ячейкам памяти. Вот в идеале,
[05:25.040 --> 05:30.200]  конечно, у нас все параллельное, и никакой коммуникации, никакого взаимодействия нет,
[05:30.200 --> 05:35.600]  но все-таки мы пишем программы, которые запускаются и разделяют какие-то данные, там какие-то,
[05:35.600 --> 05:44.000]  ну не знаю, в любом случае обработчики, они разделяют общие ресурсы исполнения, там
[05:44.000 --> 05:50.720]  аллокаторы, какие-то очереди пулопотоков, которые у нас к этому времени еще не появился. В общем,
[05:50.720 --> 05:57.440]  синхронизация в любом случае нужна, и эта синхронизация, она не про, нужно сразу разделять,
[05:57.440 --> 06:02.920]  мы сейчас можем об этом поговорить, нужно сразу разделять синхронизацию на уровне потоков,
[06:02.920 --> 06:10.320]  и вот какие-то файберы, карутины, фьючи, которые мы строим выше. Вот тема взаимной исключения и
[06:10.320 --> 06:17.120]  тема Lock Freedom, это две довольно удаленные друг от друга темы, две удаленные лекции, между ними
[06:17.120 --> 06:24.080]  там два месяца, но это две парные лекции про то, как решать одну и ту же задачу, про то,
[06:24.080 --> 06:30.000]  как обращаться к разделяемым данным с разных ядер. Мы сейчас не говорим там про файберы,
[06:30.000 --> 06:35.760]  потоки, вот в этих лекциях это неважно, у нас код может исполняться на разных ядрах, в файбере,
[06:35.760 --> 06:42.240]  в потоке, это не имеет значения, он обращается к общим ячейкам памяти, и нужно синхронизироваться,
[06:42.240 --> 06:50.760]  нужно работать с каким-то разделяемым состоянием, переводить его из одного состояния в другое,
[06:50.760 --> 06:55.840]  делать это корректно, не разрушая какие-то внутренние инварианты. И в теме про взаимные
[06:55.840 --> 07:00.800]  исключения мы поговорили про самый базовый примитив для решения такой задачи, собственно,
[07:00.800 --> 07:05.440]  Mutex, который обеспечивал взаимные исключения, то есть гарантировал, что между Lock и Unlock
[07:05.440 --> 07:12.920]  исполняется только один поток на одном ядре, а в Lock Freedom мы... что сделали? Как можно
[07:12.920 --> 07:18.200]  соотнести два этих топика? Мы ослабили требования к планировщику. Когда мы говорили про взаимные
[07:18.200 --> 07:21.520]  исключения, мы говорили про свойства safety and liveness, что не происходит ничего плохого и
[07:21.520 --> 07:26.960]  происходит нечто хорошее eventually, то есть если Lock свободен, то кто-то его захватывает и совершает
[07:26.960 --> 07:32.600]  полезную работу. Но если Lock захватывает, если какой-то поток захватывает Lock, а потом планировщик
[07:32.600 --> 07:38.640]  операционной системы там по системному таймеру просто вытесняет его с ядра, то мы получаем простой
[07:38.640 --> 07:45.000]  всей нашей системы, потому что один поток не работает, который владеет Lock'ом и мог
[07:45.000 --> 07:49.840]  делать что-то полезное, вытеснен, не работает, а другие потоки, которые сейчас на ядрах, не могут
[07:49.840 --> 07:56.880]  работать, потому что они упёрлись в захваченный Lock. Вот гарантия liveness, она у нас была формальна
[07:56.880 --> 08:01.080]  для Lock, она была в предположении, что планировщик не может вытеснить поток на бесконечное время,
[08:01.080 --> 08:07.760]  видимо он его вернет и прогресс продолжится возобновиться. Но вот в Lock Freedom мы это требование
[08:07.760 --> 08:15.120]  ослабляли, мы избавлялись от требования к планировщику не ставить потоки на паузу на бесконечное
[08:15.120 --> 08:21.640]  время и таким образом получали более сильную гарантию, которая уже позволяла достигать прогресса
[08:21.640 --> 08:27.800]  независимо от того, как ведут себя другие потоки, когда они исполняются, когда они не исполняются,
[08:27.800 --> 08:35.040]  в какой момент их вытесняют с ядра, это всё для Lock Freedom было неважно. Вот два таких парных топика,
[08:35.040 --> 08:41.320]  пожалуйста, соотнесите их, ну и вот поймите, что они решают одну и ту же задачу. Просто Lock
[08:41.320 --> 08:49.280]  Freedom делает это более, ну, более сложную версию решает без требований к планировщику и решает
[08:49.280 --> 08:55.040]  её, разумеется, более сложно, потому что теперь мы можем там наблюдать какие-то промежуточные
[08:55.040 --> 09:02.840]  состояния. В теме про взаимные исключения, что можно оттуда ещё было вынести? Ну, наверное, можно
[09:02.840 --> 09:10.520]  было подумать над тем, как, обратите внимание в разных задачах, как безопасно с взаимным исключением
[09:10.520 --> 09:16.760]  работать, как можно гарантировать, что мы не попадаем в локи, как можно строить API, которая вообще
[09:16.760 --> 09:24.560]  более безопасна для работы с локами. Ну, не самый важный, наверное, в курсе топик, но всё-таки он
[09:24.560 --> 09:32.280]  там был, стоит обратить на него внимание. Дальше мы перешли к теме про Treadpool. И про что была лекция
[09:32.280 --> 09:40.840]  про Treadpool? Ну, во-первых, она была про, это была первая задача, где нам потребовалось ожидание, где мы не
[09:40.840 --> 09:46.040]  просто вытеснялись, ну, соревновались с другими потоками за доступ к каким-то разделяемым ресурсам,
[09:46.040 --> 09:53.920]  а где мы ждали какого-то действия другого потока. И тут у нас появились кондвары, и тут у нас
[09:53.920 --> 10:01.040]  появились, ну, у нас на самом деле появились ещё в первой лекции фьютекса, они появились при ожидании
[10:01.040 --> 10:07.480]  в мьютексе, в ожидании онлока. Но вот Treadpool — это задача, где у нас была, был более явный сценарий
[10:07.480 --> 10:14.920]  ожидания. Мы блокировались на кондваре в ожидании, пока в очереди не появится новая задача. И вот мы
[10:14.920 --> 10:20.280]  увидели в этих двух занятиях базовый примитив, который у нас есть в процессоре для того, чтобы
[10:20.280 --> 10:26.480]  работать с этим ожиданием — это фьютекс. Ничего другого у нас нет. И вот с одной стороны фьютекс,
[10:26.480 --> 10:31.880]  а с другой стороны атомик, который появился в лекции про взаимные исключения — это вот те два
[10:31.880 --> 10:39.480]  простых инструмента, из которых мы, в общем, дальше изготавливали ну вот вообще всё. И в конце концов,
[10:39.480 --> 10:47.040]  мы там дошли до, ну, тех, кто дошёл и прорешал почти все задачи, они, кажется, увидели, что вот буквально
[10:47.040 --> 10:53.720]  ничего, кроме атомика и фьютекса, от операционной системы, от компьютера, от процессора нам не нужно,
[10:53.720 --> 11:00.920]  чтобы построить такой целый изыго с сложным планировщиком, с какими-то выразительными
[11:00.920 --> 11:07.200]  инструментами и всякими там каналами фьючами. Вот всё это достаточно, для всего этого достаточно
[11:07.200 --> 11:18.960]  двух очень простых механизмов. Про что ещё лекция по Трэдпулу в первую очередь? Зачем она была нужна в
[11:18.960 --> 11:23.640]  курсе? Почему она появилась так рано? Она была с одной стороны, мне кажется, поначалу, может,
[11:23.640 --> 11:27.280]  немного фрустрирующей, потому что мы сказали, что мы не собираемся больше работать с потоками
[11:27.280 --> 11:32.040]  напрямую, только запускать их в Трэдпуле. Но, надеюсь, вот по прошествии этого времени стало понятно,
[11:32.040 --> 11:40.000]  почему мы так сделали, потому что потоки для нас – это довольно низкий уровень, и потоки для нас – это
[11:40.000 --> 11:46.440]  не масштабируемый инструмент. Для нас потоки – это вот буквально виртуальные ядра. Их не
[11:46.440 --> 11:51.240]  может быть сильно больше, чем настоящих физических ядер. Если мы пытаемся занимать работы, то вот
[11:51.240 --> 11:55.080]  сколько у нас физических ядер, столько у нас, наверное, и поток, который загружен какой-то
[11:55.080 --> 12:00.560]  полезной работой и стоит на процессоре. А уже поверх этого ограниченного количества потоков,
[12:00.560 --> 12:11.240]  мы можем писать какие-то свои инструменты, свои Future, Fiber, Stackful, Stackless-крутины, которые
[12:11.240 --> 12:16.200]  будут уже конкурировать и которые будут много спать, поэтому их можно уместить в один компьютер,
[12:16.200 --> 12:23.480]  в один Трэдпул очень большое количество. Так что это были вот эти две лекции про замены исключений
[12:23.480 --> 12:29.880]  и про Трэдпул. Это две лекции про рантайм. Что еще можно было в лекции про Трэдпул
[12:29.880 --> 12:38.000]  вот сейчас детреспективно отметить? Можно сразу обратить внимание, что мы очень аккуратно в первой
[12:38.000 --> 12:45.320]  же лекции ограничили APP у лап потоков. Там был единственный метод Submit, фактически, и мы увидели
[12:45.320 --> 12:49.960]  спустя продолжительное время весьма, что ничего другого от Трэдпула не требовалось, хотя, возможно,
[12:49.960 --> 12:55.800]  хотелось бы. В Трэдпуле могут запускаться зависимые задачи, в Трэдпуле иногда хочется дожидаться
[12:55.800 --> 13:02.280]  какой-то конкретной задачи, но мы решили, что сразу не будем ничего делать с этим AP, и более того,
[13:02.280 --> 13:08.760]  наше AP в Трэдпуле оно получилось даже избыточным, потому что, если вы, скажем, писали планировщик,
[13:08.760 --> 13:14.000]  а я надеюсь, что те, кто собрался сегодня писали планировщик, вы могли заметить, что, скажем,
[13:14.000 --> 13:18.800]  метод WaitIdle там выглядит довольно инородно, потому что это, по сути, единственное место,
[13:18.960 --> 13:26.240]  в котором остается такой contention. Вот все остальное мы шардировали, и вся остальная работа делается
[13:26.240 --> 13:33.760]  потоками независимо, все эти локальные очереди, но даже общение с координатором можно оптимизировать,
[13:33.760 --> 13:39.920]  чтобы там какие-то мутирующие, изменяющие состояния операции были редки. И вот у нас столько дурацкий
[13:39.920 --> 13:46.240]  счетчик оставался, который мы там каждый раз накручивали и опускали. Так что наш Трэдпул даже
[13:46.240 --> 13:51.480]  получился избыточным в этом смысле, но и в хорошем Трэдпуле, в хорошем дизайне такого метода не
[13:51.480 --> 13:56.080]  должно быть, но мы его все-таки пощадили, оставили, потому что с ним было очень удобно писать тесты.
[13:56.080 --> 14:01.280]  Пока у нас ничего нет, вот этот WaitIdle был удобен просто потому, что можно легко с ним написать
[14:01.280 --> 14:08.280]  какой-то простой дождаться чего. Но потом, спустя долгое время, вот в лекции про сендеры и ресиверы,
[14:08.280 --> 14:14.080]  мы... Ну, вообще, мы Трэдпул достаточно долго развивали, если вы заметили. Сначала мы построили
[14:14.080 --> 14:20.800]  самый простой Трэдпул с разделяемой очередью, потом мы заметили в лекции про... Про фьюч, кажется,
[14:20.800 --> 14:29.080]  да? Что этот Трэдпул... Когда мы используем этот Трэдпул для исполнения файберов или для
[14:29.080 --> 14:37.840]  исполнения фьюч, то, по сути-то, мы не пользуемся знанием про Трэдпул. Мы пользуемся только тем,
[14:37.840 --> 14:45.720]  что он способен исполнять задачи, и эти задачи могут быть чем угодно. Ну, а если мы от этого Трэдпула
[14:45.720 --> 14:51.360]  много не требуем, то почему бы нам его не абстрагировать и не заменить на какой-то абстрактный планировщик,
[14:51.360 --> 14:59.920]  абстрактный экзекьютор? И мы получим тогда абстракцию, которая будет очень простой, очень точной,
[14:59.920 --> 15:06.280]  ну, то есть просто у нее будет очень компактная API. Она решает вот очень конкретную задачу. Это говорит
[15:06.280 --> 15:12.280]  о том, что вот мы выделили какую-то проблему вот в отдельный компонент, и дальше мы можем разбивать
[15:12.280 --> 15:17.320]  независимо. Мы получили очень универсальную абстракцию, потому что, как мы увидели, она подходит
[15:17.320 --> 15:26.520]  ко всему. И к файберам, и к фьючам, и к рутинам, причем не требует какой-то модификации. И дальше
[15:26.520 --> 15:33.840]  мы за этой абстракцией в лекции про фьюч и экзекьюторы поместили разные реализации. Ну, и я бы обратил
[15:33.840 --> 15:38.880]  внимание на manual executor, который там возник. Может быть, он не привлек вашего большого внимания,
[15:38.880 --> 15:45.520]  но на самом деле это чрезвычайно важный топик, потому что тестирование – это сложно, и тестирование
[15:45.520 --> 15:53.600]  конкурентного кода – это особенно сложно. А мы этим manual executor'ом пользовались в, скажем,
[15:53.600 --> 15:58.640]  stackless коррутинов. Ну, то есть вы написали его, потом я же его, взяв вашу реализацию, использовал
[15:58.640 --> 16:03.840]  для того, чтобы тестировать вашу коррутину, детерминированно. Это чертовски удобно, и в это
[16:03.840 --> 16:09.640]  направление можно очень далеко зайти, но про это я отдельно поговорю. Ну, и этот threadpool, он
[16:09.640 --> 16:15.560]  завершил свою… Ну, не то что завершил, но вот он продолжил свою эволюцию в занятии про sender и
[16:15.560 --> 16:23.680]  receiver, которое у нас было совсем недавно. И там мы пересмотрели API этого threadpool,
[16:23.680 --> 16:30.000]  которое, казалось бы, уже проще быть не может, и избавились там от прямого метода send, заменили
[16:30.000 --> 16:38.520]  его на метод, который возвращает нам планировщик, который строит некоторые sender,
[16:38.520 --> 16:45.040]  которые представляют собой еще не запущенные, но как бы уже готовые запуститься некоторые
[16:45.040 --> 16:52.720]  вычисления задач в пуле. И такое API позволяет нам еще аккуратнее выполнять какие-то задачи,
[16:52.720 --> 17:01.000]  избегать накладных расходов в тех сценариях, где это не нужно. Ну вот, threadpool начался,
[17:01.000 --> 17:06.520]  продолжался, продолжался, продолжался, и вот завершился в sender и receivers, ну и вот вы можете
[17:06.520 --> 17:13.520]  сейчас осмыслить всю его эволюцию. Ну, давайте я сейчас немного прервусь, я так буду дальше
[17:13.520 --> 17:24.800]  рассказывать. Ну вот, вернусь к соображению, что у нас все лекции поделены на runtime и выразительные
[17:24.800 --> 17:30.800]  средства. Ну вот, лекции про runtime это какие у нас? Это взаимные исключения, это threadpool,
[17:30.800 --> 17:39.120]  это часть про executors, это log freedom, это планировщик, это безусловные модели памяти,
[17:39.120 --> 17:47.400]  а часть про выразительные средства — это потоки, в смысле файберы, это крутины, это future
[17:47.400 --> 17:54.440]  executors, это sender и receiver, это stackless крутины, это structured concurrency. Вот два таких отдельных,
[17:54.440 --> 18:02.240]  больших параллельных топика. И вот почему я сейчас об этом говорю? Потому что в лекции про
[18:02.240 --> 18:11.200]  future и executors, и на самом деле в двух лекциях, в крутине, в лекции про крутины и в лекции про
[18:11.200 --> 18:17.520]  future executors мы сделали два очень больших шага, а именно мы декомпозировали одно от другого. И
[18:17.520 --> 18:24.040]  именно поэтому мы вообще за семестр смогли сделать то, что мы сделали. Напомню, что мы сделали в лекции
[18:24.040 --> 18:30.880]  про крутину, она была чертовски важна, потому что мы в этот момент уже умели с одной стороны
[18:30.880 --> 18:36.600]  писать threadpool, который исполняет какие-то задачи. Ну так вот, абстрактный threadpool вакууме,
[18:36.600 --> 18:41.920]  который мы даже не понимали, зачем он нам толк. А с другой стороны, мы рассмотрели на четвертом
[18:41.920 --> 18:48.120]  занятии простую реализацию файберов, которые использовали механизм переключения контекста и
[18:48.120 --> 18:53.600]  могли чередоваться на одном потоке операционной системы и изображать concurrency без физического
[18:53.600 --> 19:03.240]  параллелизма. И вот две этих занятия, они были на уровне кода, которые мы писали, ну вот,
[19:03.240 --> 19:08.640]  абсолютно независимые, но в плохом смысле, как бы нам хотелось бы иметь параллельные и файберы,
[19:08.640 --> 19:13.920]  а с другой стороны, у нас был отдельно threadpool, отдельно вот эти самые однопоточные файберы,
[19:13.920 --> 19:19.480]  и как получить многопоточные файберы, честно говоря, после двух этих занятий не должно было
[19:19.480 --> 19:24.600]  быть понятно, наверное. Ну если вы, конечно, очень наблюдательно этого могли догадаться, но все же мы
[19:24.600 --> 19:31.160]  рассмотрели совершенно два разных механизма, и они по отдельности были понятными, но вот самое
[19:31.160 --> 19:36.400]  главное, наверное, в курсе мы совершили вот на этом занятии, когда мы посмотрели внимательно на
[19:36.400 --> 19:43.200]  реализацию файберов и заметили, что переключения контекста там структурированы, что мы всегда
[19:43.200 --> 19:49.840]  переключаемся из планировщиков файбер и обратно, и вот в этот момент мы выделили сущность карутина,
[19:49.840 --> 19:57.440]  и вот ровно в этом занятии мы разделили две эти большие подзадачи, декомпозировали друг от друга,
[19:57.440 --> 20:04.080]  и после этого момента мы отдельно развивали средства выразительности, ну, на основе преимущественно
[20:04.080 --> 20:10.480]  stackful карутина, дальше были stackless, дальше были future, и независимо от этого мы разбирали рантайм.
[20:10.480 --> 20:19.720]  Ну, это была такая декомпозиция, вот, собственно, про это была задача карутинные файберы,
[20:19.720 --> 20:30.520]  и это очень важная задача, я рад, что в этом году её очень многие написали, потому что это отправная
[20:30.520 --> 20:43.600]  точка, это вот такая база для нашего дизайна, разобрав вот эту декомпозицию, разобрав, как наша
[20:43.600 --> 20:50.480]  задача выражается через некоторый набор сущностей, и как это всё, эта декомпозиция вот выражена в коде,
[20:50.480 --> 21:00.080]  в самом дизайне библиотеки, мы дальше смогли уйти очень далеко и очень сложным образом развивать
[21:00.080 --> 21:08.240]  планировщик, то есть среду исполнения, и очень сложным образом развивать сами файберы. Вот всё
[21:08.240 --> 21:15.160]  благодаря этой задаче, ну, в смысле, всё благодаря этой идее. А дальше мы эту идею ещё развили, и это
[21:15.160 --> 21:24.080]  был следующий очень важный в курсе момент, наверное, два таких ключевых момента, которые нужно
[21:24.080 --> 21:29.680]  обязательно, на которые нужно обязательно обратить внимание. Это декомпозиция в задачах
[21:29.680 --> 21:38.120]  корутина, и это следующий шаг, который мы делаем в экзекьюторах, а именно мы говорим, что корутины
[21:38.120 --> 21:44.560]  и файберы с одной стороны, и конкретный тредпул с другой стороны, они уже достаточно изолированы,
[21:44.560 --> 21:50.440]  и можно теперь и с одной стороны внести вариативность некоторую, и попробовать разные
[21:50.440 --> 21:55.960]  инструменты, в смысле, разные средства выразительности писать, и с другой стороны, под капотом,
[21:55.960 --> 22:03.080]  среди исполнения, пробовать разные планировщики. И тут было очень важное замечание ещё в самом
[22:03.080 --> 22:09.120]  начале условия, в том, что у нас есть разные выразительные средства, stackful-файберы, цепочки
[22:09.120 --> 22:14.320]  фьюч, stackless-корутины, которые вы уже все знаете. Вообще полезно возвращаться назад и перечитывать
[22:14.320 --> 22:23.280]  условия, потому что в них очень много таких отсылок вперёд в будущее, которое нужно потом в этом
[22:23.280 --> 22:30.680]  будущем освоить. Так вот, все эти инструменты, они выглядят очень по-разному, но при этом в конце концов,
[22:30.680 --> 22:35.280]  когда мы пытаемся их запустить, где-то всё это сводится к тому, что мы запускаем некоторые цепочки
[22:35.280 --> 22:41.760]  задач. Ну вот, если вы пишете сейчас фьюч, или вы уже написали фьюч, то вот представьте себе граф,
[22:41.760 --> 22:47.720]  где у вас есть shared-states, и они там друг на друга указывают. Это же буквально граф.
[22:47.720 --> 22:56.760]  Понимаете, да? Или мы говорим про... А может быть, я его покажу сейчас? Не знаю,
[22:56.760 --> 23:07.240]  может быть, у меня под рукой есть картинка? Секундочку.
[23:26.760 --> 23:35.400]  Ну вот, когда мы пишем какую-то сложную конструкцию, мы берём две фьючи, там F и F, навешиваем на неё
[23:35.400 --> 23:46.600]  продолжение, получаем новую фьючу, потом мы связываем их к комбинаторам... Ну, кстати, нет, это уже
[23:46.600 --> 23:52.080]  неправда, здесь нужно за него ударить. Мы связываем это к комбинаторам, мы получаем граф задач. Ну, если вы
[23:52.680 --> 23:58.200]  пишете, скажем, фьючи, то вот, если вы представите себе, какая конструкция у вас возникает в памяти, то вот
[23:58.200 --> 24:05.040]  возникает такой граф, где у нас есть фьюча с зеном, есть другая фьюча, мы их связываем first-off, а потом
[24:05.040 --> 24:09.880]  навешиваем на всю этот колбэк, который останавливает файбер и дожидается, пока вот эта фьюча итоговая
[24:09.880 --> 24:15.760]  не готова. Мы же буквально выстраиваем граф задач, где вершина это shared-states и комбинаторы, и в них
[24:15.760 --> 24:23.520]  лежат колбэки, и вот промесы, они запускают исполнение этих колбэков по цепочке. Получается такой
[24:23.520 --> 24:30.840]  граф. Или мы говорим про файберы, это же тоже граф задач, только вот такая вот цепочка. Мы работаем-работаем,
[24:30.840 --> 24:35.240]  потом останавливаемся, подписываемся на какое-то событие, ну или просто делаем yield в самом тупом
[24:35.240 --> 24:41.480]  сценарии, потом продолжаем. Ну, stackless-карутина, тут нет большой разницы между stackless и stackful,
[24:41.480 --> 24:47.160]  потому что, в смысле, разница, конечно, огромная, но в смысле вот этого осмысления как графа в
[24:47.160 --> 24:55.680]  задач, разницы-то нет никакой. Так что, если мы это сходство обнаружим, если мы на него обратим
[24:55.680 --> 25:05.960]  внимание, то мы можем заметить, что у нас все вот эти механизмы самые разные для выражения наших
[25:05.960 --> 25:12.680]  намерений конкурентных могут подходить одной и той же среде исполнения. И всем этим механизмом
[25:12.680 --> 25:20.080]  от среды исполнения требуется очень простой API, просто возможность запускать задачу. И почему бы
[25:20.080 --> 25:27.360]  теперь не абстрагировать вот эти конкретные средства выразительности от runtime и выделить
[25:27.360 --> 25:33.440]  интерфейс iExecutor, который будет давать очень простую гарантию, как исполнять, что он просто
[25:33.440 --> 25:42.560]  исполняет задачи, даже непонятно где, непонятно когда. И дальше мы можем переписать весь наш код,
[25:42.560 --> 25:50.000]  но вот к этому моменту Fiber'а на эту абстракцию Executor почти ничего в них не поменять, но зато
[25:50.000 --> 25:57.680]  получить возможность, ну вот, детерминированно тестировать код. Ну, это очень важные возможности,
[25:57.680 --> 26:02.680]  я продолжаю говорить, что я к ней вернусь. Но вот именно благодаря этой декомпозиции и
[26:02.680 --> 26:09.560]  этому абстрагированию мы в какой-то момент смогли сделать, решить очень сложную задачу. Мы написали
[26:09.560 --> 26:17.000]  планировщик быстрый. Ну, кто-то из вас написал быстрый планировщик. И вот давайте я к этой
[26:17.000 --> 26:22.040]  половине перейду, потому что быстрый планировщик мы писали на самом деле долго. Ну, то есть,
[26:22.040 --> 26:32.040]  мы к нему шли долго. Вот вся половина, я бы сказал, добрая половина лекций, она, где же она была,
[26:32.040 --> 26:38.000]  секундочку. Вот добрая половина лекций, которые про runtime, вот взаимные исключения, thread pool,
[26:38.000 --> 26:46.320]  потом кэши, модель памяти, lock freedom. Вот они все были нужны просто для того, чтобы дать задачу
[26:46.320 --> 26:52.640]  про планировщика, чтобы хороший планировщик написать. Все к этому шло. Вот мы там использовали все эти
[26:52.640 --> 26:57.920]  топики. Ну, про взаимные исключения мы уже поговорили, мы понимаем, что это такая совершенно базовая
[26:57.920 --> 27:04.040]  задача, самая простая, которую только можно вообразить. А дальше мы вот, скажем, перешли к кэшам.
[27:04.040 --> 27:09.720]  Про что была лекция про кэши? Ну, с одной стороны, да, что вот есть кэши, что это важная оптимизация в
[27:09.720 --> 27:14.760]  процессоре, в компьютере, что благодаря этому сглаживается зазор между там скоростью процессора,
[27:14.760 --> 27:21.920]  скоростью памяти. Но какое это отношение к нам имело? Ну, можно сказать, как? Лекция про кэши была в
[27:21.920 --> 27:33.640]  какой-то степени про то, чтобы мы в реализации там своего, своих там планировщиков могли бы написать
[27:33.640 --> 27:41.720]  вот такую вот строчку. Ну, то есть, в какой-то степени это справедливо. Ну, то есть, в нашем
[27:41.720 --> 27:48.320]  итоговом коде знание про кэши оно выродилось вот в такую строчку в спинлоке, в сокращение сценария
[27:48.320 --> 27:57.280]  пинг-понга, когда мы, значит, оптимизировали трансферы данных и вот инвалидацию кэш линий в соседних
[27:57.280 --> 28:03.440]  кэшах при ожидании потоками захваченного другим потоком спинлока. Но это, конечно, неправда,
[28:03.440 --> 28:10.160]  потому что лекция про кэши, она была в первую очередь про другое. Про что она была? Ну, вот давайте
[28:10.160 --> 28:17.960]  проверим, провалидируем ваше понимание. Зачем нам в курсе была лекция про кэши нужная? И с какой
[28:17.960 --> 28:24.720]  лекцией она вот, какую лекцию она продолжала на самом деле? Ну, она была до модели памяти,
[28:24.720 --> 28:28.760]  поэтому было бы странно, если бы она продолжала эту тему, согласись, да? Тогда бы мне стоило
[28:28.760 --> 28:33.240]  их читать в другом порядке. Эта лекция продолжала, конечно, взаимное исключение, потому что о чем она
[28:33.240 --> 28:37.840]  была? О том, что взаимное исключение — это очень плохой сценарий с точки зрения когнитности кэшей
[28:37.840 --> 28:44.200]  для процессора, для компьютера. Что вот, собственно, та цена, ту стоимость, которую мы платим за
[28:44.200 --> 28:52.080]  синхронизацию, она рождается именно при когнитности, при синхронизации кэшей. Вот то, что мы хотим
[28:52.080 --> 28:58.720]  минимизировать — это коммуникацию между ядрами. Эту инвалидацию, когда мы поддерживаем инвариант
[28:58.720 --> 29:03.920]  протокола Мессия, когда наша запись должна инвалидировать копии кэшлини в других кэшах.
[29:03.920 --> 29:10.760]  И мы вот, захватывая спинлок на одном ядре, инвалидируем копию данных на другом ядре,
[29:10.760 --> 29:17.280]  получаем их себе монопольно, модифицируем, потом отпускаем спинлок, потом его захватывает другой
[29:17.280 --> 29:23.280]  поток на другом ядре, он инвалидирует копию других, забирает себе. И вот в такой бессмысленной
[29:23.280 --> 29:27.760]  коммуникации проходит процессорное время. Процессор тратит время на то, чтобы вот обрабатывать
[29:27.760 --> 29:35.680]  сообщение об инвалидации. Это очень негативный для процессора сценарий, и мы его в задаче
[29:35.680 --> 29:42.080]  пересмотрели. Мы сказали, что мы не хотим исполнять код, который... у нас есть код,
[29:42.080 --> 29:47.240]  который не может исполняться параллельно, который должен исполняться последовательно. И мы его
[29:47.240 --> 29:52.240]  исполняем на разных ядрах, и это оказывается очень неэффективно. Да, мы там можем в протоколе
[29:52.240 --> 29:57.280]  блокировки там какие-то евристики придумывать, но в конце концов, когда мы работаем уже с данными,
[29:57.280 --> 30:04.120]  нам приходится их постоянно двигать между ядрами, между кышами. И вот эта лекция, она про то,
[30:04.120 --> 30:10.680]  что не нужно двигать данные между ядрами, не нужно двигать данные к потокам, нужно потоки двигать
[30:10.680 --> 30:15.760]  к данным в обратную сторону. Это такая очень большая, очень мощная идея, которая используется особенно
[30:15.760 --> 30:22.760]  в распределённых учислениях. И мы придумали... ну, это был такой промежуточный для нас шаг,
[30:22.760 --> 30:29.760]  на самом деле он сам по себе важный. Мы придумали такую штуку, как асинхронный Mutex, Strand. И вот
[30:29.760 --> 30:34.480]  ему отдавали асинхронные критические секции, а Strand уже их кластеризовал там где-то на одном
[30:34.480 --> 30:39.920]  потоке и выполнял сериями. Причём, чем больше нагрузка, тем он больше серии брал. Между сериями
[30:39.920 --> 30:45.560]  не было синхронизации внутренней, и они попадали в горячий кэш, и всё это работало быстро. Вот для
[30:45.560 --> 30:50.240]  этого нужна была лекция, для того чтобы понять, что Mutex — это, возможно, не самый разумный сценарий
[30:50.240 --> 30:57.040]  синхронизации, когда у нас есть много активности, которые работают с общими данными. И второй важный
[30:57.040 --> 31:06.200]  вывод из этой темы, что вот конгериантность кэшей — это и есть цена синхронизации. Это и есть то время,
[31:06.200 --> 31:18.000]  которое мы расходуем неэффективно. Нам нужно его минимизировать. И вот эта идея про то, что мы
[31:18.000 --> 31:26.840]  хотим снизить коммуникацию между ядрами, она где потом нашла своё отражение? Ну вот она нашла отражение
[31:26.840 --> 31:32.080]  в планировщике как раз. Там мы сказали, мы не хотим работать с разделяемым состоянием. Разделяемое
[31:32.080 --> 31:39.280]  состояние — это неэффективно. Мы хотим, чтобы потоки, которые работали с одними Mutex-ами,
[31:39.280 --> 31:43.600]  скапливались на одном ядре. Мы хотим, чтобы они находились там, не знаю, в одной очереди
[31:43.600 --> 31:49.640]  планировщика. Мы хотим, чтобы потоки, которые отправляют друг другу данные через каналы,
[31:49.640 --> 31:56.800]  они исполнялись вот прямо друг за другом и подали в кэш. Вот лекция про кэши, она чертовски,
[31:56.800 --> 32:01.360]  она выглядит как такая маленькая инженерная подробность, но на самом деле она для организации,
[32:01.360 --> 32:07.080]  для понимания правильных сценарий синхронизации критически важна. И вот мы дальше, отталкиваясь
[32:07.080 --> 32:12.840]  от знания про кэши, говорили в планировщике, что нам нужно не просто там планирование с
[32:12.840 --> 32:20.640]  очередями, нам нужно refo-планирование, потому что оно нам ускорит все. А дальше мы, как этот
[32:20.640 --> 32:25.400]  Strand развивали, мы же напрямую им не пользовались, но на самом деле мы будем пользоваться осенью на
[32:25.400 --> 32:29.680]  спецкурсе, там в RPC-фреймворке я покажу, как Strand находит очень естественным образом свое
[32:29.680 --> 32:37.080]  применение, свое место. Но мы связали сейчас вот этот Strand асинхронный, который про исполнение,
[32:37.080 --> 32:44.520]  с нашими средствами выразительности, с файберами или с теклусской рутинами, неважно здесь. И заметили,
[32:44.520 --> 32:49.640]  что вот у нас есть Strand, и он по своей природе асинхронный, то есть мы запускаем задачу,
[32:49.640 --> 32:54.960]  критическую секцию, чтобы она когда-то исполнилась. И это не похоже на сценарий работы с мютоксом,
[32:54.960 --> 33:01.720]  когда мы блокируемся, дожидаемся секции, потом выполняем, потом идем дальше. Но тут мы сделали
[33:01.720 --> 33:06.800]  следующий шаг. Мы подумали, что вот файберы, они про что? Или с теклусской рутиной, про то,
[33:06.800 --> 33:12.840]  чтобы исполнять код, чтобы писать код последовательно, а если ему нужно сделать паузу,
[33:12.840 --> 33:19.720]  то он просто остановится, там становится карутина. Мы подпишемся на какое-то событие,
[33:19.720 --> 33:27.320]  что Лок освободился, и когда Лок освободится, кто-то его освободит, мы возобновимся. И вот здесь
[33:27.320 --> 33:36.640]  нужно заметить общую идею, что стеклуска-рутины или stackful-файберы за счет вот этой карутины своей
[33:36.640 --> 33:44.440]  останавливаемой природы помогают трансформировать асинхронное, а пивсинхронное. И вот мы взяли и
[33:44.440 --> 33:50.240]  просто переиспользовали идею Strand с этими всеми соображениями про когеретность кашей,
[33:50.240 --> 33:57.160]  про серийность и перенесли ее в файберы. И вот так у нас все-таки два мира пересеклись немного.
[33:57.160 --> 34:07.160]  Схватываете, да? Это очень важно для планировщика все. Ну а дальше модели памяти. Ну и модели
[34:07.160 --> 34:13.960]  памяти – это такая бездонная абсолютно тема, про нее можно целый курс читать. Мы уложились там,
[34:13.960 --> 34:18.360]  не знаю, в две лекции, я рассказал самые базовые вещи и, наверное, еще я не помню,
[34:18.360 --> 34:27.160]  пару семинаров, но это огромная тема в этом всем курсе. И она про что? Ну, с одной стороны,
[34:27.160 --> 34:32.280]  как будто бы про оптимизации, про то, как можно оптимизировать код, который там работает с
[34:32.280 --> 34:39.400]  разделяемыми ячейками памяти. Но это на самом деле еще один топик про абстрагирование чего-то
[34:39.400 --> 34:43.920]  сложного. У нас есть чертовски сложные машины, у нас есть чертовски сложные, ну в смысле,
[34:43.920 --> 34:50.440]  процессоры. Они устроены совершенно по-разному, ведут себя совершенно дико иногда. И мы хотим
[34:50.440 --> 34:58.440]  как-то эту сложность подчинить своему разуму, как-то думать о ней. И вот модели памяти нам дают очень
[34:58.440 --> 35:04.920]  мощную, очень сложную абстракцию, в которой можно думать, в которой можно о чем-то что-то доказывать,
[35:04.920 --> 35:10.920]  в которой можно формулировать гарантии, которых мы ожидаем от примитива синхронизации. И,
[35:11.920 --> 35:17.440]  ну то есть это такой целый формальный язык, на котором можно говорить о работе разделяемых,
[35:17.440 --> 35:28.240]  о работе ядер с разделяемыми ячейками памяти. И что самое-то интересное, что этот язык позволяет,
[35:28.240 --> 35:34.120]  что вот на этом формальном языке, в общем, в этой формальной системе можно оптимизировать настоящий
[35:34.120 --> 35:40.000]  исполняемый промышленный код. То есть мы можем доказать, что мы сохраняем какие-то свойства,
[35:40.000 --> 35:51.600]  что мы соблюдаем, что мы имеем необходимые нам гарантии, и при этом мы используем самые слабые
[35:51.600 --> 35:57.880]  предположения о том, что в исполнении все-таки будет упорядочено. И потом, вот сделав такую работу
[35:57.880 --> 36:04.960]  в формальной системе, мы комперируем код, и этот код, ну если все сработали хорошо, и разработчики
[36:04.960 --> 36:11.240]  процессоров, разработчики модели памяти, то этот код комперируется в оптимальный машинный код,
[36:11.240 --> 36:18.600]  там с оптимальными барьерами, с минимальной синхронизацией. Что еще можно было заметить,
[36:18.600 --> 36:25.800]  если вы аккуратно изучали модели памяти и пробовали их применять? Ну, можно было заметить,
[36:25.800 --> 36:35.200]  что среди сценария синхронизации есть более и менее оптимальные. И вот, возвращаясь к взаимному
[36:35.200 --> 36:43.960]  исключению и кэшам, мы там могли заметить, что есть такой обычный mutex, и он неэффективен с точки
[36:43.960 --> 36:49.360]  зрения кэшей, с точки зрения всех этих протоколов инвалидации и когелентности, а есть асинхронный
[36:49.360 --> 36:56.400]  mutex, который гораздо более разумен. И вот модели памяти на самом деле нам указывали на ту же самую
[36:56.400 --> 37:02.760]  идею, что у нас есть сценарий, когда у нас разные потоки одновременно что-то пишут в разные ячейки,
[37:02.760 --> 37:08.560]  и нам для них требовалось sequential consistency. Ну, иногда требовалось, иногда мы могли его избежать.
[37:08.560 --> 37:14.040]  А вот иногда у нас был сценарий продюсер-консюмер, когда один поток писал, а другие читали, ну или
[37:14.040 --> 37:19.640]  еще лучше single writer вообще. Вот это идеальное воплощение, когда у нас только один поток пишет,
[37:19.640 --> 37:28.280]  а другие там читают. Ну или, ладно, просто продюсер-консюмер уже лучше, потому что такая
[37:28.280 --> 37:36.200]  модель коммуникации, она позволяет процессорам минимизировать накладные расходы на упорядочивание
[37:36.200 --> 37:42.600]  операций. Нам не нужно иметь какой-то глобальный сквозной порядок, когда продюсеры работают с
[37:42.600 --> 37:49.680]  консьюмерами. Нам достаточно соблюдать причинность. И вот happens before — это одна из гарантий,
[37:49.680 --> 37:55.200]  которые мы в моделях памяти получали. Мы обеспечивали то, что, то есть если у нас в коде есть причинность,
[37:55.200 --> 37:59.800]  мы опираемся только на нее, а не на какой-то глобальный порядок, то мы специальным образом
[37:59.800 --> 38:04.920]  аннотируем свои обращения к раздреваемым переменам, и процессор гарантирует, что эта причинность
[38:04.920 --> 38:12.040]  будет соблюдать нам в исполнении на конкретном, на каждом процессоре. И вот только иногда в каких-то
[38:12.040 --> 38:16.800]  вырожденных случаях нам могла потребоваться именно sequential consistency, то есть сквозной порядок на
[38:16.800 --> 38:25.720]  разных ячеек. И опять такое какое-то простое, ну не то что простое, какое-то очень инженерное
[38:25.720 --> 38:31.000]  наблюдение про какие-то маленькие совсем вещи, про какие-то ячейки памяти там записали, прочитали,
[38:31.000 --> 38:38.120]  а с другой стороны, вот посмотрите на Design Go. И он ведь отталкивается от понятия канала, а не
[38:38.120 --> 38:44.760]  mutex, от того что мы там отправляем, получаем. Почему так сделано? Ну потому что это хороший
[38:44.760 --> 38:49.280]  сценарий, потому что этот сценарий, ну как бы он выразительный, то есть в нем можно все что угодно
[38:49.280 --> 38:56.720]  написать, любую вашу логику оформить, а с другой стороны, он просто очень хорошо подходит к компьютерам,
[38:56.720 --> 39:03.520]  потому что там можно или фо-планирование делать, и более слабые memory ордера ставить, это все
[39:03.520 --> 39:08.120]  как бы чертовски разумно и подчиняется. То есть вот этот дизайн, который вы видите там в языках
[39:08.120 --> 39:14.600]  программирования, он же, в частности в Go, он же не случайный, он же не произвольный, он с одной
[39:14.600 --> 39:23.400]  стороны очень согласованный, выразительный, очень удачный на мой вкус, а с другой стороны, он очень
[39:23.400 --> 39:29.240]  хорошо ложится просто на специфику оборудования, на то что в процессоре, в компьютере исполняется
[39:29.240 --> 39:34.640]  эффективно, а то что неэффективно мы стараемся не использовать, то есть мы уходим от взаимного
[39:34.640 --> 39:41.640]  исключения, переходим к продюсеру консюма, вот про это были модели памяти в том числе, вот то есть
[39:41.640 --> 39:48.760]  это все, тут все связано, вот все что происходит связано, ну мы собственно и в домашних это видим,
[39:48.760 --> 39:54.000]  потому что мы пишем одну большую библиотеку, и вот все эти топики, они друг за другом цепляются,
[39:54.000 --> 40:00.440]  и вот еще раз кэши и модели памяти это предвизит к планировщику, ну и логфри разумеется, потому что
[40:00.440 --> 40:09.520]  мы за счет логфри получали более масштабируемый код, который реже упирается в блокировки и там
[40:09.520 --> 40:20.320]  реже просто потоки ждут другие потоки, одни потоки ждут другие, то есть вот раз два три четыре пять,
[40:20.320 --> 40:27.200]  вот эти занятия они все подчиняются планировщику, и в конце концов мы можем этот планировщик хороший
[40:27.200 --> 40:32.400]  написать, и поэтому очень важно, чтобы вы, реализуя хороший планировщик, собственно в своем коде
[40:32.400 --> 40:38.040]  использовали все, что мы изучили, потому что ради него все и делалось, и модели памяти там ставили,
[40:38.040 --> 40:44.600]  и когнитность кэшей про нее думали, и там какой-то логфри, вот все это собиралось в этой задачи,
[40:44.600 --> 40:50.560]  но а теперь я откатываюсь далеко по стэку вверх, и возвращаюсь к задаче про
[40:50.560 --> 41:04.320]  про экзекьюторы, вот очень важно, что мы в какой-то момент нашего курса взяли и разделили экзекьюторы
[41:04.320 --> 41:10.120]  и файберы, то есть провели между ними очень простую границу, видя одного метода экзекьютора,
[41:11.120 --> 41:18.960]  и дальше мы смогли и файберы развивать, там всякие вот эти овейтеры творить, всякие там фьютексы,
[41:18.960 --> 41:25.240]  они не нужны конечно, это отдельная тема, все вот эти овейтеры, вейт-группы, мьютексы,
[41:25.240 --> 41:32.440]  кондвары, каналы, селекты, которые вы еще не написали, вот это все же довольно сложная,
[41:32.440 --> 41:36.320]  там логфри, мьютексы, это же довольно сложная машинерия, все там много код, и он довольно,
[41:36.640 --> 41:42.680]  такой сложный, непонятный, очень абстрактный, оперирующий какими-то странными словами,
[41:42.680 --> 41:51.960]  нечеловеческими, а с другой стороны, мы под этой сложностью за простым интерфейсом громоздим
[41:51.960 --> 41:57.880]  другую большую сложность, и за счет того, что мы одно отделили от другого и разделили простым
[41:57.880 --> 42:02.960]  интерфейсом, мы в общем-то можем вот эту сложность, этой сложностью управлять, то есть эта
[42:02.960 --> 42:07.000]  сложность не перемножается, она складывается, и это очень на самом деле важное достижение,
[42:07.000 --> 42:15.200]  потому что ну, вообразите себе альтернативную реальность, где вы пишете весь этот код, вот
[42:15.200 --> 42:19.360]  весь код, который мы написали, вот просто соберите его в одну задачу, мы кстати это сделаем, я вот на
[42:19.360 --> 42:24.480]  днях выложу ее, где можно все-таки все вместе вообще собрать, фьючи, файберы, карутины,
[42:24.480 --> 42:30.200]  планировщик, ну просто вообразите себе, что вот вы приходите на первую лекцию, да, мы там говорим
[42:30.200 --> 42:35.520]  про то, что есть атомики, у них там есть операция compare exchange, да, спинлог можно написать, а потом вот вам
[42:35.520 --> 42:40.480]  говорят, вот напишите пожалуйста библиотеку, да, в которой есть каналы, фьючи, там быстрый
[42:40.480 --> 42:47.200]  планировщик, в чем здесь сложность-то, ну в чем сложность вообще всего происходящего, в том,
[42:47.200 --> 42:54.120]  чтобы правильно задачу декомпозировать, и вот это разделение на две половины, оно с одной стороны,
[42:54.120 --> 42:58.640]  ну вот мы к нему уже привыкли, воспринимаем как естественное что-то, но благодаря этому все и
[42:58.640 --> 43:05.120]  произошло, благодаря тому, что мы вынули карутину из нашего кода, обратили на это внимание, и вот от
[43:05.120 --> 43:13.480]  карутины мы дальше построили весь наш дизайн, и мы дальше можем спокойно, вот находясь за абстракцией
[43:13.480 --> 43:18.000]  экзекутера, подставлять там мэнал экзекутер и тестировать что-то, подставлять там чудовищно
[43:18.000 --> 43:24.080]  сложный планировщик, и при этом мы не беспокоимся, что это как-то начнет взаимодействовать с файберами,
[43:24.080 --> 43:31.200]  ну здесь конечно всякое бывает в жизни, но вообще говоря вы знаете, что если у вас файберы протестированы
[43:31.200 --> 43:37.640]  под одним планировщиком, то подставляет другой планировщик, и что-то вдруг не работает, вы понимаете,
[43:37.640 --> 43:44.920]  где проблему искать, вам не нужно менять сразу очень много кода, вот вы занимаетесь отдельным
[43:44.920 --> 43:49.440]  компонентом, и подставляете его вот в некоторые пазлы, просто ставите одну детальку, ставите
[43:49.440 --> 43:56.640]  другую детальку, более сложную, более оптимальную, и все вместе продолжает работать. Все это благодаря тому,
[43:56.640 --> 44:07.360]  что мы провели вот такую некомпозицию, вот здесь вот про фьюч-экзекутер. Что еще нужно рассказать?
[44:07.360 --> 44:17.200]  Наверное про, собственно, фьюч, потому что мы только сейчас их пишем, но мне кажется,
[44:17.200 --> 44:25.040]  что сейчас удачное время, чтобы их писать, потому что мы уже накопили довольно
[44:25.040 --> 44:30.520]  большое понимание о том, как код должен эффективно исполняться, про то, какие оптимизации в нем
[44:30.520 --> 44:36.960]  можно делать, и поэтому мы можем сейчас найти очень хорошие фьючи. Но вот фьючи и, смотрите,
[44:36.960 --> 44:45.000]  по-другому начну, у нас в курсе были stackful-файберы и stackless-карутины, и они в принципе про одно и то же,
[44:45.000 --> 44:51.160]  то есть мы просто взяли понятие карутины, построили от него идею какой-то активности,
[44:51.160 --> 44:55.840]  которая может что-то делать, синхронизироваться, останавливаться, перепланироваться, а дальше
[44:55.840 --> 45:00.800]  просто сказали, что у нас есть два варианта эту карутину реализовать. Stackful-вариант с переключением
[45:00.800 --> 45:06.240]  контекста и stackless-вариант, где мы делегируем реализацию карутины, написание этого автомата
[45:06.240 --> 45:15.120]  к императору. Вот это как бы один подход к выражению конкурентности последовательной,
[45:15.120 --> 45:21.520]  когда мы выполняем операцию A, потом выполняем операцию B, потом выполняем операцию C. И ну как бы
[45:21.520 --> 45:26.800]  две альтернативы, но вы понимаете, что вы используете одну из них, то есть вы берете либо stackless-карутину,
[45:26.800 --> 45:32.200]  либо stackful-файбер в своем проекте, а вот фьюча — это инструмент, во-первых, альтернативно
[45:32.200 --> 45:39.560]  выглядящий совсем, а во-вторых, комбинирующийся с stackful-карутинами, stackful-файберами или
[45:39.560 --> 45:48.480]  stackless-карутинами. И для меня очень важен этот пункт в задаче про карутины, ой, про фьюч, простите.
[45:48.480 --> 46:03.120]  Про то, что вот файберы slash-карутины и фьюча — это не какие-то вот альтернативные
[46:03.120 --> 46:11.840]  способы описывать цепочки задач, потом их исполнять. Это инструмент, который дополняет
[46:12.400 --> 46:19.920]  синхронный интерфейс файберов-карутин, потому что файберы подходят для задач, когда у вас выполняется
[46:19.920 --> 46:26.000]  а, потом b, потом c. На файберах удобно писать циклы, удобно писать витвления, удобно работать с
[46:26.000 --> 46:33.320]  включениями, но когда вам нужно сделать что-то параллельно, то в этом случае гораздо более
[46:33.320 --> 46:42.240]  выразительными оказываются фьючи. Ну, можно, конечно, как бы совсем через фьючи все писать,
[46:42.240 --> 46:47.840]  и про это есть чертовски хорошая статья у Server-as-a-Function, которую я вам продолжаю реклонировать,
[46:47.840 --> 46:59.920]  и буду продолжать, пока у меня есть время. Что? Да, ну, про ссылки в задачах — это отдельная
[46:59.920 --> 47:08.400]  история, я сейчас к этому перейду. Где я был? Можно писать весь код, в принципе, и это тоже
[47:08.400 --> 47:13.080]  интересно понять, как можно вот совершенно по-другому к задачу подходить, но лучше комбинировать,
[47:13.080 --> 47:20.040]  и как раз осенью мы поговорим про то, как это комбинировать. Но фьючи — это такая отдельная,
[47:20.040 --> 47:23.600]  я бы сказал, даже ветка в курсе, потому что она начинается с блокирующих фьюч, которые, конечно,
[47:23.600 --> 47:29.480]  неполноценные, и фьючам их называть не стоит, можно только смеяться над ними. Дальше идут настоящие
[47:29.480 --> 47:35.800]  фьючи, которые мы пишем, и которые можно написать очень хорошо. Очень хорошо можно написать. И есть
[47:35.800 --> 47:42.200]  задачи, которые мы к ней не подошли, но в этот раз как-то не успели, и я, может быть, успею выложить
[47:42.200 --> 47:50.320]  в этом смеси обновленную, может быть, нет. Посмотрю, это таски для корутин, это такое продолжение
[47:50.320 --> 47:56.160]  фьючи, в смысле, ленивое фьючи, когда фьюч представляет вычисление асинхронную операцию,
[47:56.160 --> 48:00.600]  которая уже исполняется, таск, который еще не исполняется, корутину, которая еще не исполняется.
[48:00.600 --> 48:08.800]  И, во-первых, это такая отдельная линия в курсе, асинхронная, асинхронная API. А во-вторых,
[48:08.800 --> 48:16.800]  это, в принципе, другой способ мышления, другой язык, на котором можно говорить. Это язык
[48:16.800 --> 48:22.560]  декларативный. Вот fiber — это про то, про control flow, когда мы запускаем код, и он там начинает
[48:22.560 --> 48:27.480]  как-то исполняться, чередоваться, переключение контекста. Вот мы об этом всем думаем. Когда мы
[48:27.480 --> 48:32.800]  говорим про фьюч, то мы думаем не про control flow, мы думаем про data flow. То есть мы строим граф и
[48:32.800 --> 48:39.400]  думаем, как по нему текут какие-то результаты, ну, либо ошибки. Вот я в прошлый раз вам показывал
[48:39.400 --> 48:45.760]  картинки про cancellation. Вот cancellation — это как раз топик, который про... Ну, вот на фьючах он
[48:45.760 --> 48:51.320]  очень красиво изображается. Мы строим какой-то граф, и по нему текут результаты, сигналы отмены,
[48:51.320 --> 48:59.880]  ошибки. Все это как-то движется. И мы, когда пишем код, не думаем о том, как это происходит. Мы думаем
[48:59.880 --> 49:07.400]  о том, в каком... как мы комбинируем вычисления. Ну, комбинируем о синхронной операции. Мы думаем,
[49:07.400 --> 49:12.040]  как из одних операций составить другие операции. Мы запустили две, а потом дождались первой,
[49:12.040 --> 49:19.240]  или дождались всех, или там еще что-нибудь. А вся синхронизация, вся вот эта машинерия,
[49:19.240 --> 49:26.280]  все promises, все вот сигналы отмены, все там какие-то weight-free автоматы, все вот это спрятано
[49:26.280 --> 49:32.720]  внутри. Это очень мощная идея, и вот на ней буквально можно production написать,
[49:32.720 --> 49:42.200]  а можно комбинировать с файберами. Ну, или там с чем-то таким останавливаемым. И на самом деле
[49:42.200 --> 49:47.680]  хорошие фреймворки... Ну вот в любом хорошем фреймворке используются два подхода. Вот у вас
[49:47.680 --> 49:56.400]  есть корутины, и это такие... ну, как бы не потоки, но... не знаю, как это назвать... цепочки шагов,
[49:56.400 --> 50:04.320]  но они сами порождают таски, они же фьючи, и можно вот комбинировать что-то на уровне таск,
[50:04.320 --> 50:09.600]  а можно синхронизировать сами корутины. Или у вас запускаются файберы, они делают запросы там
[50:09.600 --> 50:15.480]  по RPC, получают фьючи, и вы там в файбере дожидаетесь двух фьюч через комбинатор там... первый
[50:15.480 --> 50:19.440]  фьюч через комбинатор first-off, потому что через него можно сделать эффективную отмену второй
[50:19.440 --> 50:25.000]  синхронной... второй синхронной операции. Вот, то есть эти инструменты всегда работают сообща,
[50:25.000 --> 50:32.640]  но само понятие фьюча, оно само по себе интересное, оно иллюстрирует понятие там монад функторов,
[50:32.640 --> 50:38.600]  это вот совершенно параллельный, очень красивый функциональный мир, и ну вот таким вот очень
[50:38.600 --> 50:45.200]  косвенным сложным путем можно туда тоже проникнуть и про это почитать. Мне кажется, что это очень ценно,
[50:45.200 --> 50:50.120]  поэтому я очень рекламирую задачу фьюча. Попробуйте все-таки успеть ее сделать.
[50:50.120 --> 50:59.880]  Дедлайн по ней какой-то большой, да, но как бы дедлайн и дедлайнами, а задачу-то сделать
[50:59.880 --> 51:10.120]  все равно нужно. Вот, если мы хотим что-то вынести из всего этого. Вот мы получаем такой дизайн,
[51:10.120 --> 51:15.760]  плюс еще у нас есть важный топик, это structure and concurrency, вот обработка ошибок и cancellation,
[51:15.760 --> 51:20.920]  это очень важно, это очень важно для промышленного кода, любой промышленный код должен работать с
[51:20.920 --> 51:26.360]  отменами, он не может просто запускать и дожидаться вечно. И вот с одной стороны у вас есть stackful
[51:26.360 --> 51:34.160]  fiber, stackless коррутины, у вас есть перпендикулярно этому фьюча slash task в зависимости от того,
[51:34.160 --> 51:42.080]  что вы выбрали среди этих двух, и у вас есть cancellation, то есть распространение отмены в
[51:42.080 --> 51:50.880]  противоположную сторону, распространение всех этих сигналов по графу вычислений. И вот все это
[51:50.880 --> 51:57.800]  образует ваше выразительное средство, а под капотом у вас есть экзекьютор, эффективный планировщик или
[51:57.800 --> 52:02.960]  threadpool с общей очередью для вычислений, для независимых вычислений, или у вас есть
[52:02.960 --> 52:15.880]  manual executor для тестирования кода, и все это собирается вот в такой один большой сложный
[52:15.880 --> 52:21.200]  фреймворк. Ну и давайте я, наверное, про это расскажу, потому что это большое достижение этой
[52:21.200 --> 52:27.280]  итерации курса, мы с вами, честно говоря, сделали очень много и очень сложно, и вы большие молодцы,
[52:27.360 --> 52:32.960]  потому что вы с этим справились, потому что... Ну я, прямо скажем, особо не думал о том,
[52:32.960 --> 52:36.280]  справитесь вы или нет, потому что мне просто так хотелось сделать, мне казалось это правильным,
[52:36.280 --> 52:39.960]  но вы справились. Я, конечно, старался вам помочь в этом, как мог, в смысле,
[52:39.960 --> 52:48.200]  направлял вас в правильные моменты, в лекциями и условиями задач, в нужную сторону, но вообще то,
[52:48.280 --> 52:57.400]  что мы написали, это дико сложно, и я бы сказал так, что мы, наверное, нигде, ну может быть, иногда,
[52:57.400 --> 53:04.120]  но мы почти что нигде не писали с вами какой-то учебный код, мы с вами писали код, который,
[53:04.120 --> 53:11.360]  ну кажется, может быть максимально хорошим, то есть там некоторые шаблоны, конечно, упрощены,
[53:11.360 --> 53:19.560]  но мы их потом дорабатываем, усложняем, и всегда оставлена возможность сделать, ну просто максимально
[53:19.560 --> 53:28.160]  хорошо. Вот так, чтобы лучше уже нельзя было, ну в рамках там предложенного подхода, разумеется.
[53:28.160 --> 53:37.600]  Поэтому, ну именно поэтому мне важно, чтобы, скажем, вы научились работать с профилировщиком,
[53:37.840 --> 53:44.080]  строить Flame Graph и оптимизировать. Мне важно, чтобы вы использовали знания про протокол когерентности и
[53:44.080 --> 53:50.640]  про модели памяти и думали про слабые memory-ордеры, потому что то, что вы получили, может работать
[53:50.640 --> 53:57.640]  супер быстро, может работать максимально быстро, как это возможно. Мы нигде не пишем с вами учебного
[53:57.640 --> 54:04.120]  кода, мы, ну я честно вам рассказываю и строю шаблоны так, вот настолько хорошо, насколько я умею,
[54:04.120 --> 54:10.200]  вот я стал на год умнее, да, и почему-то научился, и вот задачи стали немного сложнее, немного
[54:10.200 --> 54:17.720]  аккуратнее. Вот сейчас они, мне кажется, в очень хорошем состоянии, в том смысле, что,
[54:17.720 --> 54:25.720]  ну почти всю лишнюю работу в них можно аккуратно соптимизировать, и для этого даны какие-то
[54:25.720 --> 54:31.080]  указания. Ну вот, скажем, я вас мучаю с интрузивностью, да, вот весь семестр, и, наверное, ошибка, что я
[54:31.080 --> 54:36.200]  пытался заставить вас самостоятельно придумать, нужно все-таки просто рассказать напрямую. Ну,
[54:36.200 --> 54:44.760]  как бы, это мы учтем в будущем. А сейчас это один из тех нюансов, который важен для производительности,
[54:44.760 --> 54:51.480]  и, с одной стороны, вот можно думать про все это, как про оптимизации, да, вот мы там оптимизируем
[54:51.480 --> 54:59.080]  memory-ордеры, мы оптимизируем там локации, мы оптимизируем там еще что-то. Ну, у оптимизации есть
[54:59.080 --> 55:04.040]  такой, ну, я не знаю, можно заметить такую негативную краску небольшую, что мы как будто бы
[55:04.040 --> 55:09.120]  усложняем код, делаем что-то, как будто бы у нас был код простой, а теперь мы что-то с ним делаем,
[55:09.120 --> 55:15.400]  чтобы он был быстрее, ценой какого-то, не знаю, усложнения, ухудшения его. На самом деле, вот вся
[55:15.400 --> 55:21.280]  та мелкая возня, которую мы делали в курсе, и с локациями, с memory-ордерами, это не про то, чтобы
[55:21.280 --> 55:27.280]  прям оптимизировать код. Я бы по-другому на это смотрел. Мы стараемся думать о том, что коду нужно
[55:27.280 --> 55:34.840]  делать, а что не нужно. Вот на какие предположения об упорядочивании операции обращения к памяти
[55:34.840 --> 55:41.400]  он опирается. Думаем об этом, думаем, ага, продюсер-консюмер, там нету глобального порядка. Отлично,
[55:41.400 --> 55:47.800]  ослабили memory-ордеры. А доживет ли объект до конца выполнения операции там в тредпуле? Доживет,
[55:47.800 --> 55:53.880]  ага, можно лоцировать его на куче, ой, на стэке, а не на куче. То есть мы скорее пишем не то чтобы
[55:53.880 --> 55:58.560]  оптимальный код, мы пишем просто аккуратный код, который не делает того, что ему делать не нужно.
[55:58.560 --> 56:06.960]  Вот, и если вы пишете аккуратный код, то у вас, ну в смысле, если вы подходите к этому как к чему-то
[56:06.960 --> 56:13.240]  аккуратному, то вы можете написать и как бы фреймворк, который эту аккуратность поощряет. Ну да,
[56:13.240 --> 56:18.240]  конечно, он будет сложнее, но тем не менее там не будет, то есть это не то чтобы мы там какими-то
[56:18.240 --> 56:23.680]  ассемблерными вставками что-то оптимизируем, это совсем другой класс оптимизации. Мы наоборот
[56:23.680 --> 56:29.000]  пишем какие-то интерфейсы и вот за счет них, за счет того, что мы вот там, не знаю, отделили
[56:29.000 --> 56:35.200]  понятие сториджа от виртуального вызова и вот сделали где-то локации на куче за счет этого. Это
[56:35.200 --> 56:40.960]  вопрос аккуратности. И вот с этой аккуратностью можно зайти очень далеко с одной стороны, то есть
[56:40.960 --> 56:47.240]  получить очень сложный код, с другой стороны он получится очень эффективным и будет понятно каждый
[56:47.240 --> 56:53.280]  компонент за как бы за какую оптимизацию отвечает. Вот мы видим айтайск, мы понимаем, ага, это про
[56:53.280 --> 57:00.200]  там экономию локаций. Это про то, чтобы определиться с временем жизни объекта. Или мы видим,
[57:00.200 --> 57:07.080]  мы reorder и думаем, ага, это про коммуникацию потоков. То есть все заключается в какие-то вот такие
[57:07.080 --> 57:14.200]  рамки и об этом все еще можно думать. Это все вот, ну то есть мы написали много код на самом деле и
[57:14.200 --> 57:20.080]  все же о нем можно думать довольно модульно, потому что мы разделили задачи, мы разделили
[57:20.080 --> 57:24.400]  абстракции, мы разделили там как бы в разных плоскостях, разделили сложность на какие-то
[57:24.400 --> 57:28.560]  независимые компоненты, которые комбинируются между собой и про комбинации которых мы почти не
[57:28.560 --> 57:36.800]  думаем. Это чертовски сложно. И я бы сказал, что вот это и есть настоящее содержание курса. Ну то
[57:36.800 --> 57:44.480]  есть вы там конечно пишете всякие синхронизации, всякие там файберы запускаете, но то, чему вы
[57:44.480 --> 57:50.560]  можете научиться из этого курса, это не только писать лог-free mutex или лог-free stack. Ну то есть вы
[57:50.560 --> 57:53.920]  этому научились, вы забудете об этом через неделю, потом вспомните, когда потребуется.
[57:53.920 --> 58:05.240]  Настоящая польза от этого курса — это то, как мы взяли Atomic, потом из него, потом из него
[58:05.240 --> 58:11.680]  построили mutex, потом к нему нам потребовалось добавить какой-нибудь кундвар, который мы тоже
[58:11.680 --> 58:16.800]  написали своими руками. Мы из этого сделали thread pool, а потом мы заметили, что можно взять
[58:16.800 --> 58:22.360]  корутину, а потом их можно скомбинировать, получить планировщик, а потом можно заметить,
[58:22.360 --> 58:26.960]  что планировщик можно абстрагировать, сделать файберы, а потом можно заметить, что файберы,
[58:26.960 --> 58:32.040]  независимо от планировщика, можно сделать интерфейс, а с этим интерфейсом можно сделать
[58:32.040 --> 58:36.360]  теперь разные реализации, а потом можно сделать асинхронный интерфейс, потом понять, что это
[58:36.360 --> 58:44.280]  все граф и задач, и значит, можно их совместить, а потом все это разрастается, и каждый шаг в
[58:44.280 --> 58:49.880]  эволюции этого кода — это то знание, на самом деле, которое вы получаете в этом курсе. Вот как можно
[58:49.880 --> 58:58.720]  было развиваться от таких простых примитивов к целому языку Go, практически языку Go? Потому
[58:58.720 --> 59:04.320]  что представьте себе, как вам дали просто задачу — напишите свой Go, но это же ушло в бесконечное
[59:04.320 --> 59:11.280]  время, и мы бы не справились все равно с этим. Вот смысл всего курса, смысл всех лекций и
[59:11.280 --> 59:15.920]  домашних задач не в том, чтобы слушать меня и то, что я вам рассказываю про какое-то решение,
[59:15.920 --> 59:21.920]  которое мне нравится. Тут вопрос, вкус очень большой, очень значимый, он сильно влияет на
[59:21.920 --> 59:30.000]  все происходящее, но ценно в этом курсе именно та эволюция, которую наш код претерпевает. Поэтому,
[59:30.000 --> 59:38.720]  скажем, мне кажется правильным, это с одной стороны неудобно и, наверное, вас бесит. Да и меня
[59:38.720 --> 59:46.120]  тоже немного бесит. Но мне кажется, это правильным, что мы постоянно, у нас дублируются задачи,
[59:46.120 --> 59:56.160]  в смысле, мы не пишем один код, мы постоянно переписываем некоторый код. И вот при переходе
[59:56.160 --> 01:00:01.280]  из одной задачи к другой, из одного шаблона к другому, мы чувствуем разницу, мы понимаем,
[01:00:01.280 --> 01:00:08.120]  что изменилось, где мы немного продвинулись вперед. Вот, к сожалению, очень сложно сделать одну большую
[01:00:08.120 --> 01:00:11.880]  задачу, в которую все бы можно было интегрировать, потому что в ней было бы слишком много выходов в
[01:00:11.880 --> 01:00:19.080]  будущее, слишком много ответов. Сейчас задача устроена так, что задача Fibers Mutex, она оперируется
[01:00:19.080 --> 01:00:23.480]  очень простым шаблоном, нет экзекутеров, нет ничего такого. Потом мы в другой задаче находим
[01:00:23.480 --> 01:00:31.480]  экзекутеры и выражаем отдельный директорию со всеми этими вариациями. Потом мы переносим ее туда,
[01:00:31.480 --> 01:00:40.080]  потом мы что-то еще делаем. И вот эта эволюция, она и есть содержание курса. Ну или смотрите,
[01:00:40.080 --> 01:00:49.760]  есть стеклоскорутины. Где они были? Стеклоскорутины. Я говорил вам, что, в принципе, дизайн можно
[01:00:49.760 --> 01:00:55.040]  рассказать не то, чтобы в середине мая, а где-нибудь в середине апреля, а вот раньше там на месяц, скажем,
[01:00:55.040 --> 01:01:02.920]  или на полтора. Но что мы сделали в курсе? Мы взяли Fibers, сделали там простой Yield,
[01:01:02.920 --> 01:01:09.680]  ну как-то на коленке придумали, написали, вот прям Fibers захардкодили его. Потом мы подумали про там
[01:01:09.680 --> 01:01:15.280]  немножко про EO, про Event Loops, это отдельная история, наверное, не успею сейчас про это поговорить.
[01:01:15.280 --> 01:01:21.760]  Потом мы стали делать Mutex, стали делать Futex, что-то там накостырили, а потом стали думать,
[01:01:21.760 --> 01:01:26.320]  а как же со всем этим управляться? Потому что там как бы набор операций, на которых Fiber блокируется,
[01:01:26.320 --> 01:01:32.560]  растет, но их, эти там примитивы операции множатся, нужно каким-то образом опять выделить
[01:01:32.560 --> 01:01:38.760]  какую-то подзадачу, абстрагировать сами Fiber от конкретных примитивов. И вот так мы придумали
[01:01:38.760 --> 01:01:46.880]  Awaiter. И вот все эти маленькие шаги нужны были для того, чтобы потом перейти к рутинам и
[01:01:46.880 --> 01:01:54.120]  свести всю лекцию буквально к одной фразе. Все то же самое, только теперь компилятор пишет
[01:01:54.120 --> 01:02:00.760]  коррутину, а не мы. И вот вся механика коррутин в этот момент должна быть для нас ясна. То есть
[01:02:00.760 --> 01:02:07.000]  мы не то чтобы, изучая вот дизайн, который упал на нас с неба, мы, пройдя через эту серию итераций,
[01:02:07.000 --> 01:02:14.240]  сами чувствуем, откуда такой дизайн появился, чем он мотивирован. Ну, тем, что, видимо,
[01:02:14.240 --> 01:02:20.920]  Awaiter это точка кастомизации, которая позволяет нам отделить, как бы, ядро коррутин, которое,
[01:02:20.920 --> 01:02:25.960]  ядро коррутин, от конкретных примитивов от рантайма. И в случае с Techless коррутин это
[01:02:25.960 --> 01:02:31.880]  особенно важно, потому что теперь коррутин и пишет компилятор, и он уже не может интегрироваться в
[01:02:31.880 --> 01:02:38.880]  наш рантайм, он про него ничего не знает. Ну вот, еще одно соображение, которое мне представляется
[01:02:38.880 --> 01:02:46.240]  важным. Ну и возвращаясь к тому, что мы пишем, кажется, довольно хороший код, мы можем написать
[01:02:46.240 --> 01:02:51.400]  очень хороший код в задачах, и именно поэтому в задачах очень много, ну не то что очень много,
[01:02:51.400 --> 01:02:55.720]  есть ссылки. И это не просто какие-то случайные ссылки из интернета, это, мне кажется, самые
[01:02:55.720 --> 01:03:01.200]  хорошие ссылки, по которым только можно в интернете переходить по этой теме. И они даны не
[01:03:01.200 --> 01:03:07.800]  только для того, чтобы вы просто вот изучили, что как бывает, вы просто можете пойти в future
[01:03:07.800 --> 01:03:14.360]  фоли и посмотреть, как вот, это future, который используется в продакшен и фейсбук, и посмотреть,
[01:03:14.360 --> 01:03:30.240]  как там реализовано что-то, где я, черт возьми, как я сюда попал. Идем во future и просто, не знаю,
[01:03:30.240 --> 01:03:34.920]  читаем код, читаем, смотрим там, что у них в shared state находится, какой там автомат.
[01:03:34.920 --> 01:03:44.200]  У нас будет немного попроще, но вот как бы, вот эта часть автомата у нас будет ровно такой же. Или
[01:03:44.200 --> 01:03:50.000]  там можно посмотреть, как там устроена синхронизация, можно посмотреть, как там устроены экзекьюторы,
[01:03:50.000 --> 01:04:06.080]  или, ну я, по-моему, про это не успел еще написать, в stackless корутинах, опять ссылка на фоли,
[01:04:06.080 --> 01:04:12.880]  и ну вот там корутины, которые интегрированы с экзекьюторами фоли, и вот вы можете пойти и
[01:04:12.880 --> 01:04:18.480]  посмотреть, как там реализованы, ну вот mutex, или вот то, что мы в этой задаче пишем. И не то,
[01:04:18.480 --> 01:04:23.840]  чтобы у вас получиться другая реализация, у вас вот такая реализация и получится в итоге. Ну,
[01:04:23.840 --> 01:04:29.760]  потому что мы пишем настоящий промышленный код, можем написать, и вы можете заимствовать идеи из
[01:04:29.760 --> 01:04:35.240]  промышленного кода, который вы видите вокруг себя. Про future ссылки скорее не про реализацию,
[01:04:35.240 --> 01:04:43.760]  наверное, а про то, про дизайн, про то, что future должны, это не то, про то, что future должны уметь.
[01:04:43.760 --> 01:04:48.960]  Вот, скажем, ссылки про скалу, они как раз про то, как может выглядеть такой сложный,
[01:04:48.960 --> 01:04:57.120]  развитый язык комбинаторов, что там future может уметь. Как можно комбинировать разные синхронные
[01:04:57.120 --> 01:05:04.960]  операции с помощью вот этих вот функций. Или, ну вот, этот доклад мне тоже представляется интересным,
[01:05:04.960 --> 01:05:12.840]  я его рекламировал уже, это future в твиттере, и какие технически-инженерные идеи в них
[01:05:12.840 --> 01:05:17.320]  реализованы, которые позволяют этим future быть эффективнее, чем скальный future.
[01:05:17.320 --> 01:05:33.440]  Или, не помню в какой задаче, кажется в задаче про карутины, самый первый. Да, есть совершенно
[01:05:33.440 --> 01:05:46.560]  чудесная ссылка про… Что? Почему это видео? Не, так не пойдет. Как мы без этой ссылки живем? С ума сойти.
[01:05:46.560 --> 01:05:58.040]  Ссылка на то, как устроены, как дизайнерись файберы в джаве, которые вот скоро приземлят там. А? Ну,
[01:05:58.120 --> 01:06:05.920]  их делают не так давно, кстати, несколько лет всего. Несколько лет в масштабе. Там их делают не для
[01:06:05.920 --> 01:06:12.640]  джавы, их делают для GVM. Вот, дизайн-док, который тоже можно прочитать. Ну, и вот,
[01:06:12.640 --> 01:06:21.200]  собственно, мы этот же дизайн с вами используем. И в этом дизайн-доке инженер пишет, что вот мы делаем
[01:06:21.200 --> 01:06:27.800]  карутины в GVM, поверх мы в библиотеке сделаем файберы, а потом мы просто переиспользуем
[01:06:27.800 --> 01:06:31.840]  готовый, хороший планировщик, который есть в джаве, который называется fork-join-pool, который как
[01:06:31.840 --> 01:06:38.200]  раз использует work-steering. Вот, это ровно тот дизайн, который мы с вами используем. Ну,
[01:06:38.200 --> 01:06:45.640]  то есть, мы в курсе… Ну, почему курс… Он иногда, возможно, кажется сложным, потому что он… Ну,
[01:06:45.640 --> 01:06:52.760]  потому что он не делает никаких скидок на вот то, что вы втором курсе, к сожалению, для вас. Он
[01:06:52.760 --> 01:06:56.480]  пытается действовать максимально честно. То есть, то, что люди умеют делать в продакшене хорошо,
[01:06:56.640 --> 01:07:04.600]  то мы и пытаемся сделать с вами. Вот, это, разумеется, сложно, но можно попытаться. Можно попытаться.
[01:07:04.600 --> 01:07:11.360]  Про планировщик, да. Ну, про планировщик-то особенно. Там замечательные же ссылки. Они про то,
[01:07:11.360 --> 01:07:23.640]  что… Они про… Где планировщик? Про то, как устроено планирование карутин в Котлине,
[01:07:23.640 --> 01:07:28.040]  про то, как устроено планирование гарутин в Расте, про то, как гарутин в ГО, про то,
[01:07:28.040 --> 01:07:36.000]  как устроено планирование синхронных задач в Расте, в Токио. Вот вы пишете такой же планировщик,
[01:07:36.000 --> 01:07:41.080]  и вот вы просто посмотрите. Великолепный доклад Дмитрия Бюкова, если вы еще не посмотрели,
[01:07:41.080 --> 01:07:46.040]  когда вы писали планировщик, то посмотрите. Я бы сказал, что весь этот курс нужен для того,
[01:07:46.040 --> 01:07:53.440]  чтобы походить по ссылкам. И чтобы вы могли… Ну, то есть не то чтобы… Я вот вам что-то рассказал,
[01:07:53.440 --> 01:08:02.880]  и вот вы там профессионал. Вероятно, нет. За три месяца им сложно сделать. Но вы теперь можете
[01:08:02.880 --> 01:08:09.320]  на основе того кода, который вы написали, и вот как бы попробовали написать, по крайней мере,
[01:08:09.320 --> 01:08:13.240]  вы можете ходить по вот этим ссылкам и смотреть, как устроен настоящий реальный мир,
[01:08:13.240 --> 01:08:21.760]  как устроен продакшн в ГО, в Расте, в Пайтон, в Котлине, в Скале, в любом современном языке.
[01:08:21.760 --> 01:08:27.560]  И все сущности должны вам быть понятны, все слова должны вам быть понятны, все механики должны
[01:08:27.560 --> 01:08:34.920]  вам быть понятны. Да, мы пишем на C++, но мы пишем на C++, потому что мы, во-первых, его знаем,
[01:08:34.920 --> 01:08:39.400]  а во-вторых, потому что на нем можно все что угодно попробовать, все подходы просто. И
[01:08:39.400 --> 01:08:44.680]  фьюча написать, и файберы написать, стэк, фуллфайберы, и стэк лоскарутина у нас готова есть,
[01:08:44.680 --> 01:08:49.480]  можно ими воспользоваться. То есть весь спектр инструментов нам доступен, и нам доступны все
[01:08:49.480 --> 01:08:54.400]  низковыровневые оптимизации. У нас есть слабые модели памяти, у нас есть там доступ к ассемблеру
[01:08:54.400 --> 01:08:59.800]  с каким-то примитивным инструкциям, у нас есть там сисколы, фютексы, все вот это можно использовать,
[01:08:59.800 --> 01:09:08.480]  из этого всего можно собирать очень сложные вещи. Что еще, мне кажется, важным? Да, конечно,
[01:09:08.480 --> 01:09:12.800]  протестирование. Это отдельная история, которую вы, наверное, не замечаете, ну, точнее, я не знаю,
[01:09:12.800 --> 01:09:20.880]  замечаете вы или нет, но это очень важная мораль, которая, наверное, сейчас не ощущается как важная,
[01:09:20.880 --> 01:09:29.480]  но без хорошего тестирования невозможно писать сложный код. И в этом курсе мы пробуем достаточно
[01:09:29.480 --> 01:09:36.240]  много разных техник. Ну, мы, разумеется, работаем с санитайзерами, там, с тремя санитайзерами,
[01:09:36.240 --> 01:09:43.740]  и вот без санитайзеров код надежно писать невозможно просто. И, что очень важно, мы используем,
[01:09:43.740 --> 01:09:49.400]  как мы тестируем именно конкарнси, потому что, если вы пойдете смотреть в какую-нибудь продакшн,
[01:09:49.400 --> 01:09:57.000]  ну, вот вы смотрите реализацию каких-нибудь примитивов, фоль, и думаете, боже, как это
[01:09:57.000 --> 01:10:03.400]  тестируется? А непонятно, как это тестируется, потому что, если вы видите сложный конкурентный код
[01:10:03.400 --> 01:10:11.320]  со слабым модеримом памяти, совсем вот этим вот, то, если вы пишете его или видите его, то как
[01:10:11.320 --> 01:10:17.000]  вы убедите себя, что он работает? Ну, потому что человеческий ум не справляется с этой сложностью,
[01:10:17.000 --> 01:10:21.520]  он не может в голове перебрать интерливинги даже. А если мы используем где-то слабые модеримы
[01:10:21.520 --> 01:10:26.240]  ордера, то все, мы даже должны про интерливинги, мы даже думать больше не можем, мы должны про графы
[01:10:26.240 --> 01:10:33.800]  думать формально. Вот, и это совсем сложно, это вообще уже невозможно. Поэтому нужна какая-то
[01:10:33.800 --> 01:10:37.880]  автоматика, которая позволяет все это тестировать. И здесь мы использовали две очень важные техники.
[01:10:37.880 --> 01:10:44.000]  Во-первых, мы использовали fault injection. Вот без fault injection ничего с stress-tests не ловится,
[01:10:44.000 --> 01:10:52.480]  вот просто ничего. Если вы просто напишите stress-test, ну, вот повезет, там что-то найдете. Но опыт
[01:10:52.480 --> 01:11:02.120]  показывает, что stress-tests без fault injection — это очень слабые тесты, они очень много упустят. Поэтому то,
[01:11:02.120 --> 01:11:06.320]  что мы принимаем как данность, то, что мы даже не замечаем, как работает, вот благодаря этому
[01:11:06.320 --> 01:11:12.560]  всему тесты и работают на самом деле, богищицы. А во-вторых, очень важный топик — это дотерминизм.
[01:11:12.560 --> 01:11:22.680]  Дотерминизм, ну, вы, я его показывал вам через manual executor, но вот опять никто этого не видит,
[01:11:22.680 --> 01:11:27.000]  а на самом же деле под капотом, когда мы тестируем ваш код под файберами, то только подумайте,
[01:11:27.000 --> 01:11:31.600]  что происходит, потому что это полная дикость, я сам не понимаю, как это работает. Вот вы написали
[01:11:31.600 --> 01:11:39.280]  груду вот этих файберов с lock-free mutex, да, положили это все на workstream-планировщик,
[01:11:39.280 --> 01:11:45.920]  где еще горо кодок вот сложного, да, и все это запускается еще на виртуальных потоков,
[01:11:45.920 --> 01:11:50.080]  которые файберы на самом деле, которые тоже переключают контексты. Вот если подумать,
[01:11:50.080 --> 01:11:53.840]  как это все вместе работает, это становится невыносимо абсолютно для человеческого ума,
[01:11:53.840 --> 01:12:00.400]  ну, для моего скромного. Но за счет того, что как бы есть некоторые слои абстракции, можно эту
[01:12:00.400 --> 01:12:08.040]  сложность как-то все-таки декомпозировать и думать про нее отдельно. Но вот когда у вас виртуальный
[01:12:08.040 --> 01:12:12.040]  поток делает переключение контекста ваше, ну, только подумайте, как это работает. Это
[01:12:12.040 --> 01:12:20.480]  несколько странно. Вот благодаря этому код тестируется детерминированно, воспроизводимо и очень
[01:12:20.480 --> 01:12:27.400]  быстро. И все это совместимо с санитайзерами. Это очень мощные техники, и вот осенью, кто захочет
[01:12:27.400 --> 01:12:33.920]  послушать, я покажу, как можно так тестировать прямо распределенный код. Это подход, который мало кто
[01:12:33.920 --> 01:12:38.720]  использует, так буквально в нескольких местах в мире так делают. Так делают где-то, кажется,
[01:12:38.720 --> 01:12:46.160]  иногда в Амазоне, в AWS, так делают в одной системе в Apple. Но, в принципе, этот подход очень дорогой,
[01:12:46.160 --> 01:12:51.440]  очень сложный, и у него нужно очень много сил инвестировать. Но тогда это дает какие-то
[01:12:51.440 --> 01:12:57.520]  невероятные возможности для тестирования очень недетерминированного, очень конкурентного кода,
[01:12:57.520 --> 01:13:04.440]  который работает со временем, с сетью, с переключением потоков, с планировщиками. И все это можно
[01:13:04.440 --> 01:13:10.400]  запустить в IDE, по кнопке «воспроизвести» и добавить лагирование и повторить в точно
[01:13:10.400 --> 01:13:19.960]  такой же порядке. Поэтому, пожалуйста, продвигайте Fault Injection, когда вы уйдете в мир, продвигайте
[01:13:19.960 --> 01:13:29.000]  эту тему, без нее невозможно. Что еще важного? А у нас время кончилось, но мы, кажется,
[01:13:29.000 --> 01:13:42.960]  можем немножко сдержаться, да? Вот, так что давайте я… Не знаю, все ли я про курс рассказал,
[01:13:42.960 --> 01:13:47.800]  что хотел. Наверное, не все, наверное, что-то забыл. А, что я забыл, да, действительно. Давайте
[01:13:47.800 --> 01:13:54.360]  рассказать, что я забыл, но не успел в курсе. Мы и так уже не помещаемся, конечно, по времени,
[01:13:54.360 --> 01:14:07.440]  но еще нам очень не хватает, наверное, домашней работы про cancellation. Нам не хватает домашней
[01:14:07.440 --> 01:14:13.480]  работы… Ну, это мне не хватает, вам, наверное… Мне хочется, чтобы у нас была такая отдельная
[01:14:13.480 --> 01:14:19.840]  линия. Это канал Lock Free, канал через Lock Free, очередь Майкла Скотта, но это такое… Это красиво.
[01:14:19.840 --> 01:14:27.840]  Еще не хватает интеграции с вводом-выводом. Мы в этом году пошли немного по другой траектории и
[01:14:27.840 --> 01:14:32.080]  собрали вместе такой большой фреймворк. Это наше большое достижение огромное. Вот, гордитесь им,
[01:14:32.080 --> 01:14:38.240]  вы большие молодцы. Но в нем мы кое-чего еще не успели интегрировать, а именно мы вот вывод так
[01:14:38.240 --> 01:14:44.080]  немного посмотрели на него в сторону немного, на это ASIO. А нам все-таки хочется интегрировать это
[01:14:44.080 --> 01:14:51.800]  все в наши планировщики, потому что ASIO — это как бы альтернативное представление нашего фреймворка,
[01:14:51.800 --> 01:14:58.440]  который мы пишем. Там и экзекьюторы, и рантаем, и вот-вывод. А нам хочется взять конкретный
[01:14:58.440 --> 01:15:04.960]  компонент, реактор, который про события, и интегрировать поддержку событий в наши планировщики.
[01:15:04.960 --> 01:15:10.200]  Но вот если вы помните, когда мы говорили про планировщик ГО, когда мы код смотрели. Давайте
[01:15:10.200 --> 01:15:26.800]  посмотрим на код. Да. Смотрим на find runnable, да, и там вот мы перебираем локальную очередь,
[01:15:26.800 --> 01:15:33.840]  глобальную очередь, а потом мы полим сеть. И вот вывод — это еще один источник задачи,
[01:15:33.840 --> 01:15:38.240]  также как и очереди. Вот очереди — это когда задачи синхронизируются, запускаются. А вот вывод,
[01:15:38.240 --> 01:15:44.480]  когда приходят там, не знаю, клиенты, когда приходят данные в сокеты, и вот представьте,
[01:15:44.480 --> 01:15:50.080]  что у вас есть в коде некоторый компонент, интерфейс, реактор. Какой у него API? Подписаться на
[01:15:50.080 --> 01:15:56.240]  события, там сокет зарегистрировать, таймер завести, и опросить события, получить там пачку готовых.
[01:15:56.240 --> 01:16:02.880]  И вот это еще одна очередь, и вы ее опрашиваете иногда. Просто это очередь в системе, а не у вас.
[01:16:02.880 --> 01:16:08.880]  Но это такая же очередь, и она интегрируется удобным образом. И, например, когда вы паркуете
[01:16:08.880 --> 01:16:14.600]  Fiber в планировщике, где вы его паркуете? Ну, пока вы паркуете его на атоматомике, на фьютаксе,
[01:16:14.600 --> 01:16:22.160]  по сути. А могли бы парковать его на E-Pole до тех пор, пока либо событие снаружи не придет в ваш
[01:16:22.160 --> 01:16:28.000]  поток, ну, в смысле, в ваш планировщик, либо когда кто-то не сделает через этот E-Pole, через там
[01:16:28.000 --> 01:16:35.320]  какой-нибудь такой пайп, зацикленный, интерапт. И вот вы интегрировали свой фреймворк с быстрым
[01:16:35.320 --> 01:16:41.080]  планировщиком, еще и с вводом-выводом, и можете там всякие скипфоры писать, сокеты и так далее.
[01:16:41.080 --> 01:16:45.160]  Если повезет, я, может быть, в этом месяце даже успею это сделать, и там можно будет
[01:16:45.160 --> 01:16:50.080]  попробовать вписать это все в свой код. Это довольно просто делается в том пределе.
[01:16:50.080 --> 01:16:55.320]  Вот. Это, наверное, то, чего не хватает, чего мне очень хочется, и тогда получится полноценный
[01:16:55.320 --> 01:17:01.240]  уже ГО. Но нам бы это успеть, честно говоря. Я даже не знаю, что делать, потому что мы и так
[01:17:01.240 --> 01:17:07.760]  не успеваем. Курс начался вот сейчас, когда мы накопили базу для того, чтобы решать сложные
[01:17:07.760 --> 01:17:16.280]  задачи, к сожалению. Так что будьте сейчас внимательны. Ну и давайте я последнее,
[01:17:16.280 --> 01:17:29.440]  что я расскажу, а потом отвечу на ваши вопросы любые. Я должен… секунду. Да,
[01:17:29.440 --> 01:17:34.920]  я должен рекламировать осенний курс, которые просто определенные системы, и можно было бы сказать,
[01:17:34.920 --> 01:17:42.160]  что весенний курс рекламы осеннего, но это одна из интерпретаций моя. Пожалуйста,
[01:17:42.160 --> 01:17:46.200]  если вам понравилось, если вам интересно, приходите, потому что дальше мы будем говорить
[01:17:46.200 --> 01:17:53.800]  про… ну как бы сказать, в таком же духе, но про вещи гораздо более масштабные. То есть мы будем
[01:17:53.800 --> 01:17:57.600]  говорить не про ячейки памяти, не про того, как два потока синхронизировать, и про то,
[01:17:57.600 --> 01:18:03.320]  как классы написать, а мы будем говорить про системы. То есть это как бы следующий уровень
[01:18:03.320 --> 01:18:10.840]  иерархии, и мы будем говорить про системы, ну вот иногда очень большие. И где-нибудь там к ноябрю мы
[01:18:10.840 --> 01:18:16.000]  дойдем до системы, которая называется Google Spanner, которая про то, чтобы построить огромную геораспределение
[01:18:16.000 --> 01:18:24.880]  базу данных, которая хранит все данные Google. Там какие-то, ну не знаю, несметные там… что там
[01:18:24.880 --> 01:18:32.000]  после пятобайтов идет? Вот. Это все там хранится в масштабах всего глобуса, синхронизируется через
[01:18:32.000 --> 01:18:37.720]  спутники, GPS в том числе. Ну короче, это жутко сложные, очень красивые вещи. Там очень много
[01:18:37.720 --> 01:18:41.920]  алгоритмической составляющей, поэтому половина курса про алгоритмы, потому что вот от них,
[01:18:41.920 --> 01:18:47.640]  по сути, зависят ключевые свойства системы. Сколько отказов они переживают, сколько какова их
[01:18:47.640 --> 01:18:53.240]  доступность, как их масштабировать. А с другой стороны, этот курс будет, ну, наверное, вот в этот
[01:18:53.240 --> 01:18:59.080]  раз особенно заметно это будет про системный дизайн, то есть про то, как строить надежные системы,
[01:18:59.080 --> 01:19:07.920]  про то, как там быть с отменой, с трассировкой, с логированием, с RPC-серилизацией, с тайм-аутами,
[01:19:07.920 --> 01:19:15.680]  с балансировкой нагрузки. Короче, все вещи, без которых настоящий промышленный код просто
[01:19:15.680 --> 01:19:22.160]  негде запускать. Это очень большие и сложные топики, и это как бы следующий уровень. И, конечно же,
[01:19:22.160 --> 01:19:28.240]  на третьем курсе, ну, мы еще маленькие, можно сказать, для этого, нам хорошо бы перед этим
[01:19:28.240 --> 01:19:36.120]  получить какой-то промышленный опыт. Но я, кажется, вполне могу это все рассказать, а вы, в свою очередь,
[01:19:36.120 --> 01:19:43.680]  можете попытаться меня понять. Но если вам вдруг это кажется интересным, то я вам рекомендую,
[01:19:43.680 --> 01:19:48.480]  ну, прямо сейчас можно примерно составить представление о том, в каком направлении
[01:19:48.480 --> 01:19:53.680]  будем двигаться. Вот я вам порекомендую такие статьи. Ну, почитайте про «Мопредьюз». Это,
[01:19:53.680 --> 01:19:59.040]  собственно, то, с чего начались распределенные системы современные. Это статья Google, где они
[01:19:59.040 --> 01:20:05.200]  показывают, как построить... Вообще, о чем наш курс-то будет про распределенные системы? Он про
[01:20:05.200 --> 01:20:12.600]  то, как строить надежные системы из ненадежных компонентов. Из сети, которая теряет сообщения,
[01:20:12.600 --> 01:20:17.440]  которая переворачивает биты в проводах, из дисков, которые ломаются, которые зарепают,
[01:20:17.440 --> 01:20:22.480]  из компьютеров, которые перезагружаются, из проводов между дата-центрами, которые выкапывают
[01:20:22.480 --> 01:20:27.840]  экскаваторы. Вот из всего этого что-то сделать надежно, которое никогда не ломается. Мы будем
[01:20:27.840 --> 01:20:36.560]  писать код, который должен быть устойчивым к ошибке в любом месте. Вот работал компьютер,
[01:20:36.560 --> 01:20:42.320]  и вот между какими-то двумя инструкциями он взорвался или там перезагрузился. Взорвался — это,
[01:20:42.320 --> 01:20:48.480]  наоборот, удобно. Перезагрузился. И вот любые две строчки это могли быть, и нигде не должно
[01:20:48.480 --> 01:20:52.880]  ничего потеряться. Вы писали в сокет, написали половину, ничего страшного не должно произойти.
[01:20:52.880 --> 01:20:58.960]  Вы писали на диск, и записалась половина вашего буфера, а половина затранкетилась. Ничего плохого
[01:20:58.960 --> 01:21:03.960]  не должно произойти. И вот все это должны пережить. Вы отправили три запроса, получили только два ответа,
[01:21:03.960 --> 01:21:08.840]  или один ответ получили, или, ну не знаю, там у вас сеть раскололась на две части. Вот никакой
[01:21:08.840 --> 01:21:14.320]  сбой, вот все, что можно представить себе, что может поломаться, не должно ломать наш код. Это
[01:21:14.320 --> 01:21:20.360]  чертовски сложно, и мы попытаемся, ну я попытаюсь объяснить, как это все можно делать. Это сложный
[01:21:20.360 --> 01:21:31.840]  курс. Иногда очень такой дотошный к мелочам, но с другой стороны, я вот попытаюсь вам рассказать
[01:21:31.840 --> 01:21:39.640]  честно все, что я знаю к этому моменту. Нигде вас не обмануть. А теперь статьи, про которые можно
[01:21:39.640 --> 01:21:44.360]  почитать к началу этого курса. Это, конечно, спаннер не нужно читать, это не получится.
[01:21:44.360 --> 01:21:53.640]  MapReduce — это система, с которой началась инфраструктура современная, начался Google современной,
[01:21:53.640 --> 01:22:02.000]  ну там с PageRank из MapReduce. Это система, которая позволяет вам надежно, отказоустойчиво выполнять
[01:22:02.000 --> 01:22:06.800]  распределенные вычисления, и при этом не думать о том, как это отказоустойчивость реализуется.
[01:22:06.800 --> 01:22:11.520]  Вы просто говорите, я вот сейчас собрал такой граф из там функциональных операций MapReduce,
[01:22:11.520 --> 01:22:19.080]  вот вам, исполняйте. А дальше он как-то исполняется на сотнях машин параллельно. Там машины залипают,
[01:22:19.080 --> 01:22:24.360]  машины выключаются, у машин пропадают диски. Все это работает без участия пользователя. Как
[01:22:24.360 --> 01:22:29.600]  такую систему построить? Вот Google писал, и до сих пор этой идеей пользуются, и в следующем
[01:22:29.600 --> 01:22:37.960]  семестве вы на другом курсе будете тоже ей пользоваться в виде HDFS Hadoop. И вот к этой
[01:22:37.960 --> 01:22:45.000]  системе прилагается файловая система для хранения данных, распределенная файловая система, и мы этот
[01:22:45.000 --> 01:22:50.160]  дизайн будем в курсе развивать, то есть мы его изучим, будем дальше его масштабировать и делать
[01:22:50.160 --> 01:22:54.800]  более отказоустойчивым. Ну опять, это вот начало двухтысячных, это то, с чего Google начинал.
[01:22:54.800 --> 01:23:01.920]  Почитайте про это. Ну и еще одна очень клевая статья. На 13-го года написал Джефф Дин. Джефф Дин
[01:23:01.920 --> 01:23:07.880]  написал... не написал Джефф Эс, странно. Джефф Дин написал MapReduce со своим товарищем,
[01:23:07.880 --> 01:23:11.960]  это такой большой коллективный разум, очень крутой, который развивал инфраструктуру Google
[01:23:11.960 --> 01:23:21.080]  долгое время. И он написал другую статью. Вот есть Fold Tolerance, которая про то, чтобы делать
[01:23:21.080 --> 01:23:29.920]  систему отказоустойчивыми, а есть Tail Tolerance, чтобы делать системы, ну так скажем, доступными в
[01:23:30.080 --> 01:23:37.080]  смысле, чтобы пользователи, которые отправляли запросы в нагруженную систему, ну вот вы как бы
[01:23:37.080 --> 01:23:42.760]  пользователь счастливый, вы отправились на удачную машину, и вам ответили за 10 миллисекунд. А может
[01:23:42.760 --> 01:23:46.840]  быть ваш запрос ушел на машину какую-то неудачную, и там сборка мусора началась, и вам ответили за
[01:23:46.840 --> 01:23:54.840]  100 миллисекунд или за секунду вообще. Вот статья про то, как можно строить, какие техники использовать
[01:23:54.840 --> 01:24:01.360]  для того, чтобы строить системы, которые всегда отвечают за 10 миллисекунд. Даже если какая-то
[01:24:01.360 --> 01:24:07.560]  машина может залипнуть, даже если там какие-то там общие ресурсы есть. Вот два этих аспекта,
[01:24:07.560 --> 01:24:12.040]  две этих половины, как строить что-то отказоустойчивое, и это достигается алгоритмами,
[01:24:12.040 --> 01:24:19.320]  и как строить что-то доступное, это достигается другими техниками инженерными. Вот про это
[01:24:19.320 --> 01:24:28.040]  весь курс и будет, про комбинацию всего этого. Я буду рад, если вы придете. Опыт показывает,
[01:24:28.040 --> 01:24:36.760]  что среди, ну мне нужно 20 человек. Вот, если вас больше, то вероятно кто-то из вас не захочет его
[01:24:36.760 --> 01:24:43.160]  слушать. Не потому что там он сложный курс, или потому что, не знаю, вот просто этот курс,
[01:24:43.160 --> 01:24:47.840]  он такой более специализированный. Он для людей, которым нравится, вот есть люди,
[01:24:47.840 --> 01:24:52.800]  которым нравится делать кнопки, и которым перекладывать байты. И вот этот курс для людей,
[01:24:52.800 --> 01:24:58.480]  которые любят байты перекладывать. Так что, вот вы можете выбрать, ну в смысле, лучше быть и тем,
[01:24:58.480 --> 01:25:04.360]  и тем, конечно, но в первую очередь он для людей таких инфраструктурных, которым интересная
[01:25:04.360 --> 01:25:09.240]  оптимизация, интересные все вот эти инженерные подробности, и интересный алгоритм, потому что
[01:25:09.240 --> 01:25:23.320]  мы про них будем много говорить. Что? Этот курс, он, этот курс, ну он, в нем должно быть, конечно,
[01:25:23.320 --> 01:25:30.360]  больше кнопок, но он все еще про байты. Просто смотри, этот курс, вот текущий, он более понятный,
[01:25:30.360 --> 01:25:34.440]  более доступный, потому что ты вот куда бы ни пришел, потом на каком бы языке ни писал,
[01:25:34.440 --> 01:25:41.760]  ты так или иначе столкнешься с какой-нибудь корутины или с Fiber или с Future. Вот какой бы современный
[01:25:41.760 --> 01:25:47.920]  язык ты ни взял, там что-то будет. Поэтому у тебя не возникает вопроса, зачем тебе это нужно. Мы
[01:25:47.920 --> 01:25:53.600]  будем говорить про системы распределенные в следующем году, и мы будем говорить о них с позиции
[01:25:53.600 --> 01:26:00.320]  не пользователя, а разработчика. Как такие системы строить. Вот, и это, ну такие довольно специальные
[01:26:00.320 --> 01:26:07.040]  люди, в смысле, что вот это люди, которым это интересно, которые это делают, и таких людей, ну,
[01:26:07.040 --> 01:26:11.120]  меньше, чем людей, которые делают кнопки. Ну, я так утрированно говорю и никого не оскорбляю
[01:26:11.120 --> 01:26:14.800]  ни в коем случае. Я просто говорю, что есть люди, которые делают продукты, а есть, которые делают
[01:26:14.800 --> 01:26:21.760]  инфраструктуру. Вот, и я буду говорить про инфраструктуру. Вот, просто вопрос в том, в чем
[01:26:21.760 --> 01:26:27.000]  ты видишь больше ценности. В том, что ты соптимизировал там какой-нибудь процентиль
[01:26:27.480 --> 01:26:31.840]  своего сервиса, или в том, что там у пользователя теперь там работает саджест поиски. Вот, что тебе
[01:26:31.840 --> 01:26:37.680]  больше нравится, что тебе кажется важнее в жизни. Ну, то есть, тут зависит просто от твоих вкусов,
[01:26:37.680 --> 01:26:46.680]  того, что тебе больше по душе. Просто опыт показывает, что если тебе по душе все-таки что-то такое более
[01:26:46.680 --> 01:26:51.720]  прикладное пользовательское, то, наверное, те подробности, которые у нас будут, они будут
[01:26:51.720 --> 01:27:00.200]  изматывать. Они сложные, они очень… Ладно. Их очень много, и это все про такую инженерию,
[01:27:00.200 --> 01:27:08.280]  про очень абстрактные вещи. Ну, вот если ты уже налочился говорить, строить предложения из слов
[01:27:08.280 --> 01:27:13.040]  «крути новейтор», «экзекьютор» и т.д., а не произносить ни одного нормального человеческого
[01:27:13.040 --> 01:27:19.520]  слова, то, как бы, там все тоже будет понятно. Ну, в смысле, там будет похожим образом. К сожалению,
[01:27:19.800 --> 01:27:23.560]  инфраструктура – это про такие понятия, которых в природе нет. Вот, «пойди на улицу,
[01:27:23.560 --> 01:27:37.800]  найди корутину». Довольно сложно. А? Автобус. Не знаю. Ну, значит, такими налогами можно, конечно,
[01:27:37.800 --> 01:27:45.840]  многое покрыть. Я бы не стал. Все-таки мне кажется, что корутин в природе довольно мало. А понятия
[01:27:45.840 --> 01:27:51.720]  для нас совершенно фундаментальные. Вот. В общем, если вам интересно, вы можете, по крайней мере,
[01:27:51.720 --> 01:27:56.760]  оценить, насколько вам это интересно, почитав пару статей. Мы в любом случае это все разберем еще
[01:27:56.760 --> 01:28:09.640]  осенью, но вот вы можете представление составить уже сейчас. Со всеми ссылками курса? Так он же в корне
[01:28:09.640 --> 01:28:17.680]  Редми лежит. Добро пожаловать в репозиторий. Смотри, давайте я сейчас покажу. Возможно,
[01:28:17.680 --> 01:28:29.960]  ты удивишься, но вот первая ссылка в Редми курса – она про ссылки курса. Ну, вот. Там ее нужно
[01:28:29.960 --> 01:28:36.400]  актуализировать, конечно, и переструктурировать. Я этим займусь. Но вообще, обязательно сходи,
[01:28:36.400 --> 01:28:41.800]  и давай я покажу, мне кажется, самые важные ссылки, которые можно прочесть в первую очередь. У меня
[01:28:41.800 --> 01:28:50.240]  где-то они были открыты. Ну, в случайном порядке. Про фьюч я уже много раз говорил. Очень полезно.
[01:28:50.240 --> 01:28:56.040]  Ну и посмотри, как это сделано в фолле, там документация и дизайн этих фьюч в Фейсбуке.
[01:28:56.040 --> 01:29:05.040]  Есть довольно старый уже пост про принципы дизайна, которые за Unifex, за Unified Executor.
[01:29:05.040 --> 01:29:16.080]  Но это старый пост, но он отражает ключевые идеи дизайна. Понятно, что там он уточняется,
[01:29:16.080 --> 01:29:22.680]  полируется. Но вот то, что мы делали, сендеры, ресиверы, шедулеры, интрузивность, вот все вот
[01:29:22.680 --> 01:29:27.720]  это этим постом покрывается. Дальше, если вы понимаете это, то вот можно почитать уже,
[01:29:27.720 --> 01:29:36.640]  собственно, и Proposal to Execution. И, собственно, теперь все это можно читать. Если вы решили задачи
[01:29:36.640 --> 01:29:44.280]  там на отл разные, то можно надеяться, что, конечно, все это будет сложно, потому что здесь,
[01:29:44.280 --> 01:29:51.520]  ну это промышленный код, и в нем больше сценариев учтено, больше инструментов дано. Но принципиально
[01:29:51.520 --> 01:30:01.240]  вы должны все понимать. Ну, я не знаю, нравится ли вам эта серия постов. Мне она кажется разумной,
[01:30:01.240 --> 01:30:05.640]  потому что это Льюис Бейкер, один из авторов Coroutine C++. У него есть серия постов про то,
[01:30:05.640 --> 01:30:11.160]  как эти корутины работают. И кто-то мне говорил, что это все сложно читать. Но, с другой стороны,
[01:30:11.160 --> 01:30:16.960]  потому что он просто описывает дискоуровневую механику подробно. Вот мало где это все можно
[01:30:16.960 --> 01:30:24.920]  увидеть еще. Конечно, обязательно посмотрите доклад Дмитрия Вьюкова. Он великолепен. Дмитрий
[01:30:24.920 --> 01:30:31.840]  Вьюков сам по себе великолепен, бесподобен. И его доклад тоже про планировщика Go, который он
[01:30:31.840 --> 01:30:39.920]  написал, про все вот такие подробности, которые мы потом переиспользуем в нашем коде. Ну и вот
[01:30:39.920 --> 01:30:47.640]  по мотивам этого доклада и этого дизайна есть тоже замечательный пост из Токио. Там, когда там
[01:30:47.640 --> 01:30:52.120]  переписывали этот планировщик на Rust, поделились своим опытом. Просто как они переписывали,
[01:30:52.120 --> 01:30:56.560]  что они попробовали, это тоже было бы интересно изучить. Ну, просто чтобы эволюцию отсредить.
[01:30:56.560 --> 01:31:05.040]  Очень клевое короткое эссе What Color Is The Function про то, что мир, асинхронный, корутинный,
[01:31:05.040 --> 01:31:11.800]  делится на… ну, красится в два цвета. Точнее, как корутинный мир, в зависимости от того,
[01:31:11.800 --> 01:31:17.520]  выбрали ли вы stackful корутина или stackless корутина, будет у вас либо монохромным,
[01:31:17.520 --> 01:31:25.440]  либо двуцветным. Либо он будет красно-синим, либо он будет, ну не знаю, серым или каким-то. Розовым,
[01:31:25.440 --> 01:31:30.280]  да, совершенно верно. Конечно же, stackful корутины гораздо приятнее, потому что в них не нужно ни о
[01:31:30.280 --> 01:31:36.800]  чем думать. А вот если вы пишите stackless корутину, то вы неизбежно красите свой код в синхронные,
[01:31:36.800 --> 01:31:42.800]  асинхронные функции, и они вызываются по-разному, они работают по-разному. И вот, ну, это довольно
[01:31:42.800 --> 01:31:50.040]  серьезное отличие. Вот эссе обращает внимание на вот это, на это отличие, как бы проводит эту
[01:31:50.040 --> 01:31:56.800]  границу между синхронным и синхронным миром, как-то влияет на код. Это довольно сильная, ну, довольно
[01:31:56.800 --> 01:32:01.840]  заметная особенность, потому что она влияет на то, как вы пишете код, как вы комбинируете этот код.
[01:32:01.840 --> 01:32:09.600]  В общем, предлагаю почитать. Это такая довольно знаковая статья, очень многие на нее ссылаются,
[01:32:09.600 --> 01:32:16.560]  но и вы всегда отличите розовый язык от красно-синего языка, просто по наличию ключевого слова await.
[01:32:16.560 --> 01:32:25.160]  Мне очень нравится статья про барьеры памяти, вот такая вот вводная, про то, откуда вообще
[01:32:25.280 --> 01:32:32.680]  появляются, ну, мы перешли от примитивного синхронизации, в смысле от выразительных средств, простите,
[01:32:32.680 --> 01:32:42.960]  к процессору, каким-то мелочам, к runtime'у, да. Простая статья, где берется процессор с двумя ядрами,
[01:32:42.960 --> 01:32:49.120]  с шинами, с шиной между кышами, с протоколом когерентности простым, и объясняется, откуда
[01:32:49.120 --> 01:32:54.880]  вообще берутся модели, откуда берутся вот эти барьеры памяти и почему вдруг у вас может
[01:32:54.880 --> 01:33:03.560]  разломаться причинность, почему вы пишете простую программу, где вы, ну, где здесь простой пример
[01:33:03.560 --> 01:33:09.880]  программы, вы пишете A, пишете B, а потом в другом потоке читаете B, если вы видите B единицу,
[01:33:09.880 --> 01:33:14.680]  то вы, наверное, ожидаете увидеть и в A единицу. Вот почему такая простая программа,
[01:33:14.960 --> 01:33:22.960]  скопировавшись на процессоре, может ломаться. Какие там оптимизации над протоколом когерентности
[01:33:22.960 --> 01:33:29.600]  будет ваш процессор исполнять, чтобы разломать ваш такой простой код, который опирается на причинность?
[01:33:29.600 --> 01:33:37.480]  Ну, дальше про модели памяти. В модели памяти тут есть много хороших статей, мне очень нравится вот
[01:33:37.480 --> 01:33:43.080]  это, потому что она написана, во-первых, основателями всего этого, то есть декларативных моделей.
[01:33:43.080 --> 01:33:51.880]  И она описывает не то, чтобы вот модель памяти спустилась на нас с неба, она про то,
[01:33:51.880 --> 01:33:58.080]  как строили модели памяти и как там просто отталкивались от существующей реальности. Потому
[01:33:58.080 --> 01:34:04.560]  что модели памяти, все вот эти memory orders, happens before, все эти порядки, они не произвольные,
[01:34:04.640 --> 01:34:14.560]  они просто фиксируют ожидания разработчика от исполнения программы, соблюдение причинности,
[01:34:14.560 --> 01:34:20.040]  соблюдение порядка некоторого, и фиксируют просто реальность аппаратную, как процессоры себя ведут.
[01:34:20.040 --> 01:34:28.040]  И вот эта статья, она связывает два этих мира, то есть как отталкиваясь от аппаратной реальности дать
[01:34:28.040 --> 01:34:35.600]  какую-то понятную модель для рассуждений, для доказательств разработчику. Очень классная статья.
[01:34:35.600 --> 01:34:42.280]  Ну а дальше я бы, наверное, посоветовал серию постов Расси Хоккса, который написал совсем недавно,
[01:34:42.280 --> 01:34:48.440]  это один из разработчиков языка ГО, и вот совершенно великолепная серия постов про то,
[01:34:48.440 --> 01:34:56.480]  как, собственно, мы в курсе следовали примерно этой же схеме, когда я рассказывал о модели памяти,
[01:34:56.480 --> 01:35:03.240]  сначала идет рассказ про аппаратную реальность, про то, как устроены процессоры, почему они там
[01:35:03.240 --> 01:35:10.880]  что-то реордерят, потом рассказ про то, как можно эту аппаратную реальность описать в виде
[01:35:10.880 --> 01:35:15.800]  декларативной модели в языке программирования и избавить разработчиков от знания о том,
[01:35:15.800 --> 01:35:25.320]  как все это работает под капотом, и в-третьих, как дальше на основе всех вот этих общих соображений
[01:35:25.320 --> 01:35:36.720]  инженеры конкретно выбирали, значит, как построить, как выстроить модель памяти языка ГО. Нужно ли там
[01:35:36.720 --> 01:35:42.120]  делать слабые memory order или ненужные? Какой ordering выбирать по умолчанию? Все это, мне кажется,
[01:35:42.120 --> 01:35:49.480]  очень ценно, когда вообще люди рассказывают, как они что-то делают. Вот я надеюсь, что наш курс
[01:35:49.480 --> 01:35:54.040]  выглядел так, в смысле, что вот я рассказываю, как мы что-то делаем, мы решаем одну большую задачу.
[01:35:54.880 --> 01:35:59.920]  Только так и можно чему-то научиться не решению, в смысле, не через решение, в смысле, готовое
[01:35:59.920 --> 01:36:05.080]  решение, а через вот дорогу к этому решению, где мы пробуем разные варианты. Вот это такая
[01:36:05.080 --> 01:36:13.120]  серия постов, где такая траектория описана. Ну а напоследок можно, если вы уже освоили модели
[01:36:13.120 --> 01:36:19.920]  памяти, можно разобраться с тем, где они несовершенны, потому что они несовершенны,
[01:36:19.920 --> 01:36:25.600]  в них много странностей. И вот есть такая классная статья, где, скажем, описывается проблема out of
[01:36:25.600 --> 01:36:35.320]  scenario. Почему есть некоторые странные сценарии, которые почему-то допустимы с точки зрения модели
[01:36:35.320 --> 01:36:43.400]  памяти формальной, и для которых в модели памяти написаны какие-то, в смысле, в документации
[01:36:43.400 --> 01:36:51.400]  модели памяти написаны какие-то костыли. Ну вот, я это показывал на одном из семинаров. Почему
[01:36:51.400 --> 01:36:56.200]  вдруг мы открываем вроде бы такую сложную навороченную модель памяти, она там написана
[01:36:56.200 --> 01:37:04.520]  прямым текстом, что вот в этой программе запрещается читать 42. Вот как будто бы кто-то
[01:37:04.520 --> 01:37:09.160]  захардкодил какой-то странный частный случай в модели памяти, хотя у нас были какие-то порядки,
[01:37:09.440 --> 01:37:17.280]  гарантии. Вот почему так вышло? Почему люди решают задачу там много лет уже, и все равно
[01:37:17.280 --> 01:37:26.080]  получаются вот такие странные частные случаи, которые общим фреймворком не покрываются? Непонятно.
[01:37:26.080 --> 01:37:42.320]  Ну и, да, вот Андрей нам советует почитать статью про то, что даже атомики с memory order
[01:37:42.320 --> 01:37:47.720]  sequential consistency — это не самая тривиальная вещь в модели памяти, потому что как только они
[01:37:47.720 --> 01:37:53.920]  начинают взаимодействовать с какими-то слабыми моделями памяти, то начинается путешествие где-то
[01:37:53.920 --> 01:38:06.680]  в к центру земли, там к ледяному озеру, короче, вот в самый ад, где вот очень сложные, очень
[01:38:06.680 --> 01:38:13.360]  нетривиальные сценарии реализуются, которые должны быть в модели памяти учтены. И как вообще описать
[01:38:13.360 --> 01:38:20.800]  гарантии memory order? Вот, да, обращу внимание, я это говорил как-то то ли на семинале, где-то,
[01:38:20.800 --> 01:38:26.040]  то ли кому-то в частной беседе, что не учите, пожалуйста, модели памяти по cpp-референс,
[01:38:26.040 --> 01:38:34.200]  или в чате, наверное. Cpp-референс — это справочник для разработчиков, а модели памяти — это такая
[01:38:34.200 --> 01:38:41.800]  сложная наука, и никакого способа ее изучить, кроме как вот закапываться в такие подробности нет,
[01:38:41.800 --> 01:38:48.600]  к сожалению. Но вот если вам будет интересно, как это все по-настоящему, об этом вообще правильно
[01:38:48.600 --> 01:38:54.000]  думать, по-честному, без всяких там скидок упрощений, вот вы можете до такой статьи добраться,
[01:38:54.000 --> 01:39:06.680]  но это, конечно, уже такой высший пилотаж, так мало кто умеет. Ну что ж, не знаю, у меня кончились
[01:39:06.680 --> 01:39:13.280]  слова, я устал, наверное, что-то забыл, но, наверное, что-то не очень важное. Поэтому если у вас
[01:39:13.280 --> 01:39:19.760]  вопросы есть, потому что происходило, что я еще о чем не рассказал вам, то давайте я, может быть,
[01:39:19.760 --> 01:39:48.840]  отвечу на них. Я не думаю, что изменится что-то драматически, скорее оно, не знаю,
[01:39:48.840 --> 01:39:57.960]  уточняется, полируется, обретает какую-то более удобную форму. Но вот из того, что прямо сейчас
[01:39:57.960 --> 01:40:02.560]  делается или делалось там в какие-то последние годы, но, кстати, вот много всего, много того,
[01:40:02.560 --> 01:40:09.080]  что мы изучаем, делается прямо сейчас. Ну вот я говорю, Fiber и Java, Project Loom делают сейчас,
[01:40:09.080 --> 01:40:16.040]  еще не выкатили. Sender и Receiver, но это вот как раз какой-то новый подход, который вот нигде,
[01:40:16.040 --> 01:40:22.200]  кроме C++, не пробовали, вот этот такой пионер. Делают прямо сейчас, уже тоже много лет,
[01:40:22.200 --> 01:40:28.720]  развивают этот дизайн. Structured concurrency — это то, что появилось, да, как же я вам не посоветовал,
[01:40:28.720 --> 01:40:34.640]  обязательно, обязательно, обязательно почитайте статью про structured concurrency. Конечно, ее мало
[01:40:34.640 --> 01:40:45.000]  для понимания, но она, если знать о чем она, то она очень мощная. Этот топик, который тоже делали
[01:40:45.000 --> 01:40:56.240]  совсем недавно, я вам рекламировал доклад Романа Елизарова, который сейчас главный дизайнер
[01:40:56.240 --> 01:41:06.800]  языка Котлин, и у него есть великолепный доклад, где он рассказывает про то, как в Котлине внедряли
[01:41:06.800 --> 01:41:15.520]  эти идеи. Этого тоже делали совсем недавно, там три года назад, и в новых языках это продолжают
[01:41:15.520 --> 01:41:21.840]  делать. Так что то, что мы изучаем, это скорее вот такая текущая реальность, этим и занимаются.
[01:41:21.840 --> 01:41:34.000]  Ну вот здесь скорее к решению близки. Вот кажется, что как бы удобные формы нащупаны. В конце концов
[01:41:34.000 --> 01:41:40.120]  все сводится к тому, что у тебя асинхронные интерфейсы или асинхронные, и для синхронных
[01:41:40.120 --> 01:41:47.640]  интерфейсов у тебя розовый или красно-синий мир. Вот скорее это какой-то такой незыблемый
[01:41:47.640 --> 01:41:53.760]  фундамент, тут особо ничего не поменяется. Ну ладно, я вру, есть еще акторы. Есть еще акторы,
[01:41:53.760 --> 01:41:57.720]  которых в курсе нет, потому что я на акторах ничего не писал, никогда сложно, чтобы в этом
[01:41:57.720 --> 01:42:05.040]  рассказывать. Но, кстати, вот на днях будет High-Load, и там будет один из разработчиков
[01:42:05.040 --> 01:42:13.760]  Yandex DB рассказывать про акторную систему, в которой на Яндексе написана очень большая база данных.
[01:42:13.760 --> 01:42:19.720]  Вот именно на фреймворке актора. Там под капотом тоже, кажется, всякие переключения контекста. Но
[01:42:19.720 --> 01:42:29.020]  вот акторы — это такой отдельный топик, который полностью изолирует runtime от конкурентных
[01:42:29.020 --> 01:42:35.160]  активностей. То есть мы пишем отдельные акторы, которые последовательные, которые не могут напрямую
[01:42:35.160 --> 01:42:43.320]  с кем-то конкурировать за какие-то разделяемые ячейки, их там просто не бывает. И все оптимизации
[01:42:43.320 --> 01:42:49.600]  спущены в runtime. То есть это нечто похожее, в смысле идея похожая чем-то на future, в том смысле,
[01:42:49.600 --> 01:42:52.840]  что мы синхронизацию скрываем, прячем ее под капот, дальше вот декларативно что-то делаем.
[01:42:52.840 --> 01:42:57.240]  Но это другой подход. Я не привожу ни в коем случае знак равенства или какой-то параллель,
[01:42:57.240 --> 01:43:07.280]  просто обозначаю, что цель — отделить runtime от активности, которую мы пишем. Ну вот это еще
[01:43:07.280 --> 01:43:12.960]  одно направление, которое, ну есть языки, которые его развивают. Есть, там скажем,
[01:43:12.960 --> 01:43:20.240]  довольно экзотические языки. Есть еще одно направление интересное. Оно связано на самом
[01:43:20.240 --> 01:43:24.840]  деле не с конкуренцией в первую очередь, оно связано с языками программирования. Но тем не
[01:43:24.840 --> 01:43:29.600]  менее, это вот сейчас языки программирования очень активно развиваются в самых разных
[01:43:29.600 --> 01:43:39.800]  направлениях. И большое направление — это условно safety в самом широком понимании. Safety,
[01:43:39.800 --> 01:43:47.600]  которое достигается разными сложными системами типов. И вот некоторые способы дизайна системы
[01:43:47.600 --> 01:43:52.000]  типов приводит к тому, что наши программы становятся корректнее в смысле конкурентного
[01:43:52.000 --> 01:43:59.480]  доступа к разделяемым объектам. Вот есть язык Rust. И там в безопасном расте невозможно сделать
[01:43:59.480 --> 01:44:05.960]  датарейс, потому что невозможно иметь ссылку на две ссылки, две конфликтующие ссылки на одну
[01:44:05.960 --> 01:44:12.040]  ячейку памяти. Просто такая программа не комплирируется. Это с одной стороны ограничение,
[01:44:12.040 --> 01:44:19.400]  а с другой стороны — это, ну как бы, любая система типов, она чем занимается? Вот у вас есть класс
[01:44:19.400 --> 01:44:24.960]  всех программ, и есть корректные программы, есть некорректные программы. И вот любая система
[01:44:25.040 --> 01:44:31.200]  типов пытается отрезать максимальное количество некорректных программ, но нельзя их точно
[01:44:31.200 --> 01:44:37.200]  выделить. Но если вы там, не знаю, какую-то теорию изучали, то невозможно построить такой алгоритм,
[01:44:37.200 --> 01:44:43.080]  который отделяет от некорректного. Поэтому мы отделяем много некорректных программ и заодно
[01:44:43.080 --> 01:44:49.200]  отсекаем какое-то количество корректных. То есть мы где-то жертвуем удобством, но при этом мы
[01:44:49.200 --> 01:44:54.680]  получаем более безопасный код, в общем случае. Вот и есть разные подходы к системе типов. Там
[01:44:54.680 --> 01:45:02.000]  есть, в первую очередь, это все двигается в функциональных языках, конечно. Но скажем,
[01:45:02.000 --> 01:45:07.720]  вот есть совершенно экзотический PonyLang, который язык акторов, который вроде бы про то, что данные
[01:45:07.720 --> 01:45:14.640]  нужно копировать, а не разделять. Но за счет системы типов можно гарантировать, что можно
[01:45:14.640 --> 01:45:20.640]  все-таки актором обращаться к разделяемым ячейкам, и что они точно ничего не поломают. Вот за счет
[01:45:20.640 --> 01:45:25.360]  сложности системы типов. Вот это тоже направление, которое сейчас развивается, которое с конкуренцией
[01:45:25.360 --> 01:45:33.000]  связано. Чинить модели памяти, пытаются починить, пытаются что-то придумать. До сих пор задача не
[01:45:33.000 --> 01:45:41.080]  решена. Вот. Удивительно, что как бы все это делается и все это покоится на понятие коррутина в
[01:45:41.080 --> 01:45:47.480]  конечном итоге, да. А понятие коррутина вот больше полувека уже. Или вот structure of concurrency,
[01:45:47.480 --> 01:45:54.120]  там идея тоже 50-летней давности. Вот. Но люди обращаются к глубокому прошлому, находят какие-то
[01:45:54.120 --> 01:46:00.480]  идеи, переиспользуют их, переносят на новую реальность. Хорошие, удобные concurrency делать
[01:46:00.480 --> 01:46:07.880]  научились совсем-совсем недавно. Вот раньше люди работали с потоками и там с колбэками. Совсем
[01:46:07.880 --> 01:46:14.720]  недавно. Вот Котлин сделал коррутины. Когда? Последние несколько лет. Ну, Go это... Go появился
[01:46:14.720 --> 01:46:24.320]  10 лет назад. Но Go это очень, очень разумный, очень согласованный язык, где очень аккуратно все
[01:46:24.320 --> 01:46:29.920]  декомпозировано и собирается вместе в такую структуру. Потому что, ну, Go написали в Google,
[01:46:29.920 --> 01:46:35.400]  а Google собаку съели на том, чтобы строить отказоустойчивые, надежные, конкурентные,
[01:46:35.400 --> 01:46:41.840]  распределённые системы. Вот. У них был большой опыт. Ну, вот они предложили некоторое решение.
[01:46:41.840 --> 01:46:49.400]  Rust появился, ну, как бы он появился там 10 лет назад примерно. Ну, в смысле, он развивался. Ну,
[01:46:49.400 --> 01:46:59.280]  вот он совсем недавно пришёл к своим Async Await и Future. C++ Execution делают вот сейчас. Коррутины
[01:46:59.280 --> 01:47:07.160]  появились тоже, там, в C++ 20. И то, ну, как бы есть некоторое мнение, что они не сам... Это не
[01:47:07.160 --> 01:47:12.680]  самый удачный дизайн коррутины. Можно было бы сделать лучше, если бы ещё их там немного поварить.
[01:47:12.680 --> 01:47:21.800]  Ну, или по-другому вообще поварить. Вот. Так что трудно представить, что что-то вот фундаментальное
[01:47:21.800 --> 01:47:28.800]  новое изобретут, но вот над эргономикой сильно работают и прямо в самых разных языках всё это
[01:47:28.800 --> 01:47:51.280]  прямо сейчас делают. Ну, вот так. Как я это вижу. Всё, нет больше вопросов. В Memory Order, конечно же,
[01:47:51.280 --> 01:47:58.600]  мне нравится больше всего Release the Acquire. Какой вопрос, такой ответ. Ну, он, смотри,
[01:47:58.600 --> 01:48:04.040]  это Memory... Ну, это наполовину серьёзно. Это потому, что он всем нравится больше всего,
[01:48:04.040 --> 01:48:08.720]  потому что, во-первых, он про синхронизацию, да, вот. Что-то меньше ему не можем рассчитывать. А с
[01:48:08.720 --> 01:48:14.360]  другой стороны, это вот, как бы, та наиболее оптимальная синхронизация, которую мы хотим иметь в
[01:48:14.360 --> 01:48:24.440]  процессоре. Мы не хотим порядка, мы хотим причинности. В смысле, я не считаю Memory Order,
[01:48:24.440 --> 01:48:41.000]  его нет. Я закрываю... Вот нет никакого консюма. Не думайте о консюме. Вычеркните его из своего
[01:48:41.800 --> 01:48:58.400]  ума. Ну... Не знаю, мне в моделях памяти больше нравится, вот, и во Future это нравится,
[01:48:58.400 --> 01:49:03.560]  и в моделях памяти это нравится, то, что вам предлагают думать не императивно, а декларативно.
[01:49:03.560 --> 01:49:09.760]  То есть думать о том, какие гарантии вы имеете и что вы получаете, а не то, как это работает.
[01:49:09.880 --> 01:49:17.360]  Это всё-таки абстракция, но, то есть она получается очень сложной, очень, как бы, ну, короче,
[01:49:17.360 --> 01:49:25.240]  с дырами она течёт где-то, она где-то вот, как-то её корёжит вот в там Out of Scenair. Но это правильный
[01:49:25.240 --> 01:49:30.280]  путь. Мы пытаемся сложность спрятать, потому что иначе этой сложности невозможно управлять.
[01:49:30.280 --> 01:49:47.840]  Что-нибудь? Про историю курса я не знаю, это неинтересно, наверное. Ну,
[01:49:47.840 --> 01:49:55.160]  каждый год курс становится в два раза лучше, чем он был в прошлом году, то есть пока это работает,
[01:49:55.160 --> 01:50:00.400]  а? В полтора? Ну, я не знаю, мне кажется, что в этом году он стал сильно лучше для меня,
[01:50:00.400 --> 01:50:03.960]  потому что, во-первых, всё собралось в одну задачу, и это большое достижение. В смысле,
[01:50:03.960 --> 01:50:11.080]  всё всему подходит, это очень важно. А ещё, мне важно то, что никто не видит, то,
[01:50:11.080 --> 01:50:16.520]  что всё это тестировалось под файберами очень хорошо, и поэтому я спокоен за то,
[01:50:16.520 --> 01:50:23.000]  что тот код, который я вижу в EmergeRequest, там очень мало неправильного кода. Вот, это тоже
[01:50:23.000 --> 01:50:28.040]  очень большое внутреннее достижение. Ну, всякое бывает, конечно, бывают исключения,
[01:50:28.040 --> 01:50:38.880]  но в целом по-прежнему всё так. Ну, не знаю, наверное. Мне кажется, что в этом году получились,
[01:50:38.880 --> 01:50:48.000]  ну, у меня более хорошие условия, там много, там более чётко и аккуратно выстроена линия,
[01:50:48.480 --> 01:50:55.320]  ну, дерево это эволюционное, как всё это развивается, что от чего зависит, где мы что добавляем. Вот.
[01:50:55.320 --> 01:51:02.480]  Мне очень важно, чтобы вы, пройдя курс целиком, могли бы вернуться в прошлое и понять, что же это
[01:51:02.480 --> 01:51:11.920]  всё было, о чём же эти все замечания, там абзац, лекции были. Курс движется в сторону такую,
[01:51:11.920 --> 01:51:16.440]  ну, больше прикладную. Раньше мы забавлялись каким-то, ну, давным-давно, на заре времён,
[01:51:16.440 --> 01:51:22.480]  какими-то синхронизациями, там, лок-фри хэштабрицами, но это всё я склонен считать каким-то
[01:51:22.480 --> 01:51:29.480]  праздным занятием. Всё-таки мы сейчас пишем, ну, кажется, гораздо интереснее решать большую
[01:51:29.480 --> 01:51:35.240]  сложную задачу, писать собственные ГО, а не, там, изучать какие-то ловкие способы синхронизировать,
[01:51:35.240 --> 01:51:42.120]  там, не знаю, построить хэштабрицу. Потому что, ну, это забавно, это, как бы, у вас такая инерция
[01:51:42.120 --> 01:51:47.880]  после всяких, там, олимпиад алгоритмов сохраняется, но, в целом, никогда производительность настоящего кода,
[01:51:47.880 --> 01:51:51.520]  настоящих систем, от этого не зависит. Если вам интересно, от чего зависит производительность
[01:51:51.520 --> 01:51:56.200]  систем, ну, вот мы занимались memory-order, интрузивностью, там, протоколом конгерентности кэшей,
[01:51:56.200 --> 01:52:06.280]  там, лифо-планированием. Мы будем, там, заниматься осенью всеми этими отменными ошибками, там,
[01:52:06.280 --> 01:52:14.680]  вот этим tail-tolerance, full-tolerance. Вот-вот, что влияет на настоящий мир, на настоящие системы. И
[01:52:14.680 --> 01:52:20.880]  акцент у курса сильно сместился в эту сторону. Мне кажется, что это важно. Вот что мы потеряли в этом
[01:52:20.880 --> 01:52:32.920]  году, то, что я не успел сделать в угоду другим вещам, это вот вывод. Но если вы понимаете,
[01:52:32.920 --> 01:52:37.480]  что происходит, вы понимаете, что там довольно, как бы, технические вещи остались. Но, все-таки,
[01:52:37.480 --> 01:52:48.360]  там, одну-две задачи вписать в это все, в наш фреймворк стоит. Что? Я не знаю, как быть потом.
[01:52:48.360 --> 01:53:00.400]  Ну, как маленькое. Смотри, сколько мы времени потратили сейчас. Смотри, у нас вот
[01:53:00.400 --> 01:53:10.800]  раз, ну, сколько? Пятнадцать, да, плюс шестнадцать, семнадцать, восемнадцать. Ну, вот такое количество
[01:53:10.800 --> 01:53:19.080]  лекционных часов. Ну, я бы сказал, что, если бы было, ну, вот вышки, я читаю три пары. Ну, то есть,
[01:53:19.080 --> 01:53:23.920]  там, формально, лекции два семинара, но я, мы всех обманываем и делаем, как бы, два занятия, плюс
[01:53:23.920 --> 01:53:29.120]  семинар, там, про разбор задач. Вот это, наверное, оптимальное время. Но, в принципе, я, вот, за
[01:53:29.120 --> 01:53:35.520]  семестр укладываюсь по темам. Ну, я, скорее, укладываюсь. То есть, мне можно было бы это
[01:53:35.520 --> 01:53:41.880]  растягивать, но я, вот, в общем-то, все, что хотел рассказать, рассказал. Может быть, можно где-то
[01:53:41.880 --> 01:53:47.680]  развернуть, где-то подробнее, вот там, еще какой-то хвостик получится. Но мне кажется, что лучше,
[01:53:47.680 --> 01:53:51.480]  когда насыщенно, плотно, и вот, как бы, больше параллелей, больше связи возникает, больше
[01:53:51.480 --> 01:53:57.040]  интенсивность. Для меня это ценно. Наверное, мне не хватает еще кусочка с семинарами. То есть,
[01:53:57.040 --> 01:54:01.960]  мы могли бы там еще встречаться месяц-полтора и, там, разговаривать про то, что мы дописываем
[01:54:01.960 --> 01:54:08.720]  сейчас. Это правда. Как тут поступить, я пока не знаю, но, ну, я, скажем, в среду проведу семинар.
[01:54:08.720 --> 01:54:16.480]  Можно к нему, не знаю, можно на него прийти всем. Можно на сдачу прийти, да. Вот, в следующую субботу
[01:54:16.480 --> 01:54:20.640]  я тоже могу прочитать еще одну. Вот, про лог-фри канал мне хочется, я не прочисла консенсус,
[01:54:20.640 --> 01:54:28.640]  я не знаю, что мне больше нравится. Короче, выберу что-нибудь. Ну, если я не знаю, если я в конце
[01:54:28.640 --> 01:54:43.440]  мая останусь в Москве, то, может быть, то и другое. Да. Нет, неправда. Ну, в смысле, он всегда был,
[01:54:43.440 --> 01:54:47.640]  ну, был конкарнс, а потом я просто сделал распределенные системы, потому что, ну, как бы,
[01:54:47.640 --> 01:54:54.480]  это инструмент, а распределенные системы — это цель. То есть, это то, что мне интересно, и без
[01:54:54.480 --> 01:55:02.840]  конкарнси невозможно говорить про распределенные системы. Я не знаю. Ну, это уже, мне кажется,
[01:55:02.840 --> 01:55:09.280]  сейчас не очень интересно, все сильно далеко ушло вперед. Ну, важно не то, как бы что было,
[01:55:09.280 --> 01:55:13.400]  потому что вас это в меньшем, ну, вас это как-то касается, непонятно как. Мне важно, к чему мы
[01:55:13.400 --> 01:55:18.000]  пришли. А мы пришли к тому, что мы вот в этом семестре собрали одну большую сложную библиотеку,
[01:55:18.000 --> 01:55:24.280]  в которой совмещается все. И это сложно. В смысле, сложно подогнать так, чтобы все сочеталось,
[01:55:24.280 --> 01:55:30.480]  чтобы все друг с другом клеилось без какого-то оверхеда. Вот если вы это увидите, то вот вы
[01:55:30.480 --> 01:55:40.120]  осознаете, прочувствуете мощь нашей библиотеки и вот всего происходящего. Это сложно было сделать,
[01:55:40.120 --> 01:55:46.200]  это потребовало больших усилий. Но оно собралось, оно не идеально собралось, там можно еще по-другому
[01:55:46.200 --> 01:55:51.920]  что-то делать. Но то, что уже сейчас, мне кажется, это здорово. Я вот рад, что в этом семестре у нас так
[01:55:51.920 --> 01:55:59.720]  получилось. Мне кажется, что, то есть, я первый раз почти что доволен. Вот так, я близок к тому,
[01:55:59.720 --> 01:56:04.600]  что вот процентов на 70, наверное, доволен происходящее. Это уже получилось неплохо.
[01:56:04.600 --> 01:56:17.800]  Да. Ну, смотри, это не решается никаким курсом, это решается учебным планом. Ну,
[01:56:17.800 --> 01:56:22.360]  я не знаю. Тебе нужно сдавать 10 экзаменов, да, и я не могу на это повлиять своим курсом.
[01:56:22.360 --> 01:56:32.360]  Просто проблема в другой плоскости. Ну, не то что проблема, я не знаю. Ты, с одной стороны,
[01:56:32.440 --> 01:56:39.240]  сдаешь 10 экзаменов, ты становишься жутко умным за счет этого. Вот. Ну, с большим трудом. Может быть,
[01:56:39.240 --> 01:56:44.200]  ты бы где-то стал умнее, да, если бы ты посещал теме какой-то более, ну, специализация у тебя была,
[01:56:44.200 --> 01:56:48.840]  но ты бы там что-то другого не узнал. Ты поступил в МФТИ, потому что тебе, наверное, нравится так.
[01:56:48.840 --> 01:56:57.320]  Ты к этому должен быть готов, ты к этому уже должен быть привычен. Я не знаю, как с этим поступить,
[01:56:57.320 --> 01:57:02.680]  я вот просто стараюсь рассказывать все, что могу, а дальше кто найдет время, тот разберется
[01:57:02.680 --> 01:57:08.480]  основательно. Я так скажу, я разговаривался там в семействе с разными людьми, там на защитах,
[01:57:08.480 --> 01:57:17.920]  на реакциях, там просто где-то между, и я в итоге, кажется, проговорил с людьми примерно все подземные,
[01:57:17.920 --> 01:57:23.160]  все там подводные камни, все скрытые уровни, задачи, которые были. Другое дело, что это были
[01:57:23.160 --> 01:57:32.800]  разные люди, если вас всех сложить, то вы, наверное, вы в сумме освоили все детали курса. Я не знаю,
[01:57:32.800 --> 01:57:38.040]  есть ли где-то какое-то сосредоточение этого, но вот, скажем, по таблице есть пара человек,
[01:57:38.040 --> 01:57:44.920]  которые сделали почти все, кроме одной из задачи. Все никто не успел сделать до последней реакции,
[01:57:44.920 --> 01:57:51.280]  но с другой стороны, для меня все это без лук фри, это можно сказать, что все. Но вот с бонусными
[01:57:51.280 --> 01:57:58.400]  уровнями это по-настоящему все. Вот, это требует времени, да, и я тут найти его за вас не могу,
[01:57:58.400 --> 01:58:08.560]  только вы сами. Не знаю, что сделать. Мы можем продолжить общаться в чатике, и там, не знаю,
[01:58:08.560 --> 01:58:13.240]  как-нибудь, если у нас будет, я не знаю, может быть, если у нас будет время, желание, мы можем как-то
[01:58:13.240 --> 01:58:18.920]  вот ближе к концу месяца устроить какой-то разбор приватный про то, чтобы посмотреть,
[01:58:18.920 --> 01:58:25.080]  как это все можно было бы написать и обсудить все вместе. Если мы так захотим, можем подумать над
[01:58:25.080 --> 01:58:32.040]  этим. Вот, ну, когда мы уже докрутим задачи, вот эти последние, про там, грутины, каналы.
[01:58:32.040 --> 01:58:42.680]  Летом CI, наверное, закроется, я не знаю. Не знаю, если там виртуалка. Локальные тесты останутся,
[01:58:42.680 --> 01:58:50.800]  да, с ними ничего не изменится. Вот, ну и осенью я, ну или осенью-весной, собственно, мы будем работать,
[01:58:50.800 --> 01:58:58.120]  да, я забыл, когда рекламировал осенний спецкурс же, рекламировать то, что мы будем весь код писать на
[01:58:58.120 --> 01:59:03.200]  том фреймворке, который мы вот в этом курсе разрабатывали. То есть, вот буквально то, что вы сейчас
[01:59:03.200 --> 01:59:09.800]  пишете, вот этим мы будем пользоваться. Не то чтобы, если вы не написали, то не сможете, да. Нет,
[01:59:09.800 --> 01:59:16.880]  я за вас написал, и я пишу этот фреймворк, из него делаю этот курс, так он получается побочный,
[01:59:16.880 --> 01:59:23.080]  можно сказать. Ну вот, мы будем этим пользоваться для того, чтобы писать уже какой-то распределенный код.
[01:59:23.080 --> 01:59:32.680]  И этот фреймворк, он, не знаю, он там летом появится, я его открою снова. Он на семестр закрывается,
[01:59:32.680 --> 01:59:44.120]  чтобы не провоцировать людей, подсматривать него. Ну вот, можно будет его почитать и сказать,
[01:59:44.120 --> 01:59:51.400]  а я же могу и лучше сделать. Это тоже запросто может случиться. Вообще, вот я скажу, что в разных
[01:59:51.400 --> 01:59:55.600]  mergeRequest'ах я видел очень клёвый код, то есть вы делаете прям очень хорошие вещи. Ну не то, что
[01:59:55.600 --> 02:00:03.120]  кто-то один делает хорошие вещи, а вот разные люди в разных задачах пишут иногда чертовски хороший
[02:00:03.120 --> 02:00:25.360]  код, доходят до самых глубин. Это здорово. Супер-приз. Так нет же победителя. Никто не
[02:00:25.360 --> 02:00:40.600]  победил. Не знаю, приза нет пока. Я не знаю, нужно зафиксировать условия, то есть мы считаем до
[02:00:40.600 --> 02:00:48.040]  конца месяца или мы считаем до сегодня. Придумаем что-нибудь, посмотрим. Ещё непоздно, я думаю. У нас
[02:00:48.040 --> 02:00:53.240]  ещё есть время формальное, до когда можно сдавать задачи, так что давайте подождём.
[02:00:53.240 --> 02:01:05.280]  Если у нас вопросы закончились, то спасибо большое, что были этой весной здесь, ходили,
[02:01:05.280 --> 02:01:09.800]  слушали. Спасибо большое, что решили задачи. Вы большие, молодцы, вы сделали очень много,
[02:01:09.800 --> 02:01:16.520]  поверьте мне. Я от вас ждал этого, но надеялся, ну вот вы смогли. Спасибо вам.
[02:01:18.040 --> 02:01:19.040]  Аплодисменты.
