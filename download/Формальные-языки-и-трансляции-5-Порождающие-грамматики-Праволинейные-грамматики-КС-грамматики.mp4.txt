[00:00.000 --> 00:07.360]  всем доброго дня мы сегодня с вами продолжаем изучать наш курс и сегодня у
[00:07.360 --> 00:13.400]  нас будет новая тема посвященная грамматика внезапно но давайте прежде чем мы с вами
[00:13.400 --> 00:19.520]  начнем поймем что мы уже с вами прошли какие конструкции мы с вами уже прошли
[00:19.520 --> 00:28.520]  да мы с вами построили минимальный пдк напомню что это именно полный
[00:28.520 --> 00:32.420]  детерминированный конечный автомат минимизировать обычный автомат нельзя и
[00:32.420 --> 00:37.920]  кстати по моему одна задачка которая будет на семинарах про это говорит да
[00:37.920 --> 00:43.720]  там про теоретика множественная операция а мы с вами это поняли раз что мы с
[00:43.720 --> 00:48.040]  вами построили минимальный пдк а во вторых мы с вами поняли что класс языков
[00:48.040 --> 00:54.440]  распознаваемых автоматами достаточно мало пример языка можете назвать который
[00:54.440 --> 01:06.040]  не распознается автоматами а вн и бв слова простой длины ну с ними будет
[01:06.040 --> 01:12.760]  некоторая проблема да то есть проверка на простоту это вообще вещь которая
[01:12.760 --> 01:17.680]  тяжело распознается всякими автоматными историями или около
[01:17.680 --> 01:23.320]  автомата то есть для них нужно уже использовать машину тюринга вот поэтому
[01:23.320 --> 01:26.800]  план на сегодняшней лекции во первых ввести понятие порождающий грамматик во
[01:26.800 --> 01:31.640]  вторых построить иерархию порождающий грамматик и в третьих понять какие
[01:31.640 --> 01:38.480]  грамматики и квалетный автоматом то есть взять построить новую конструкцию
[01:38.480 --> 01:43.160]  таким образом чтобы эта новая конструкция была связана с предыдущей
[01:43.160 --> 01:49.400]  конструкцией давайте поймем следующее прежде чем я веду определение что по
[01:49.400 --> 01:52.880]  вашему мнению такое грамматика
[01:54.320 --> 02:00.160]  да правила по которым мы с вами можем писать представьте себе мы пишем с
[02:00.160 --> 02:06.360]  вами предложение предложение у нас из чего состоит так нет ну подлежащие
[02:06.360 --> 02:10.320]  исказуемость синтактический разбор значит у нас есть подлежащие у нас
[02:10.320 --> 02:14.920]  исказуемые значит что относится к подлежащему что привязывает собой
[02:14.920 --> 02:24.800]  подлежащие обычно не не это часть речи которая скрывается красное яблоко
[02:24.800 --> 02:29.040]  определение то есть у нас есть именная группа которая состоит обычно из
[02:29.040 --> 02:34.200]  подлежащего и набора так сейчас я заступил как называется это
[02:34.200 --> 02:41.280]  определение и дальше у нас есть глагольная группа которая имеет с собой
[02:41.280 --> 02:46.240]  связки множество дополнений и обстоятельств да то есть мы с вами можем
[02:46.240 --> 02:50.880]  сказать что у нас его предложение
[02:52.520 --> 03:01.400]  sentence состоит из наунгрупп и вертгрупп что такой наунгрупп наунгрупп у нас
[03:01.400 --> 03:08.240]  может представлять собой либо собственно сабжект
[03:09.280 --> 03:16.880]  не не не я пока просто пишу о том как это выглядит на практике примеры просто
[03:16.880 --> 03:22.200]  приводим значит это либо сабжект либо допустим сабжект и как
[03:22.200 --> 03:31.560]  определение по-английски я забыл все время не определение которое не то
[03:31.560 --> 03:36.440]  определение который который это подчеркивает волной да давайте
[03:36.440 --> 03:44.760]  назовем и аджиптик либо у нас аджиптик может стоять перед сабжектом и вертгрупп
[03:44.760 --> 03:51.560]  что такое вертгрупп это у нас либо предикейт
[03:52.560 --> 04:00.440]  это этот предикат это на самом деле всказуемый переводится английского языка
[04:00.440 --> 04:05.320]  либо смотрите мы можем записывать правила так что у нас из этого вводится
[04:05.320 --> 04:12.760]  либо предикейт либо вводится предикейт плюс отверт предикейт
[04:12.760 --> 04:19.000]  ну или еще какие-нибудь другие правила да и смотрите дальше что у нас с вами
[04:19.000 --> 04:24.160]  происходит а дальше нам нужно спуститься до части речи то есть попытаться
[04:24.160 --> 04:29.080]  раскрутить эти правила до тех моментов пока мы дойдем до части речи когда мы
[04:29.080 --> 04:34.880]  доходим уже до 4 речи мы с вами уже спускаемся в лексический анализ то есть
[04:34.880 --> 04:39.200]  вот это у нас синтоксический анализ мы берем раскладываем предложение а есть у
[04:39.240 --> 04:43.520]  нас лексический анализ и как вы думаете какими конструкциями шлятся лексический
[04:43.520 --> 04:51.200]  анализ то есть определение части речи там определение склонений а нет какими
[04:51.200 --> 04:53.840]  конструкциями
[04:55.360 --> 05:03.000]  отлично а как задать множество слов имеющие окончание а я регулярными
[05:03.000 --> 05:08.960]  выражениями или автоматами то есть на уровне лексического анализа мы с вами
[05:08.960 --> 05:12.480]  работаем с автоматами регулярными выражениями здесь же мы будем работать с
[05:12.480 --> 05:19.800]  такими объектами как грамматика я просто сейчас веду определение и чтобы
[05:19.800 --> 05:24.920]  было был пример который показывает как это работает и так давайте ведем
[05:24.920 --> 05:33.160]  первое определение порождающие грамматики
[05:39.000 --> 05:47.560]  это такое кортеже который будет состоять из следующих символов n и сигма
[05:47.600 --> 05:54.760]  ps где все множество конечны сразу скажу а
[05:54.760 --> 06:13.240]  s это элемент нашего множества значит n называется не терминалы это множество
[06:13.240 --> 06:27.680]  сигма как вы думаете что такое сигма алфавит он тоже конечный п кстати
[06:27.680 --> 06:33.120]  спрошу здесь видно на записи все отлично не зря свет выключали это
[06:33.120 --> 06:45.280]  под множество n объединить сигма с плюсом умножить на n объединить сигма со
[06:45.280 --> 06:59.840]  звездой это правило так еще забыл сказать что в данном случае сигма и n
[06:59.840 --> 07:09.080]  пересекаются по пустому множеству то есть они не пересекаются не терминалы
[07:12.000 --> 07:17.480]  терминал это символов которых мы с вами можем заканчивать то есть обычно
[07:17.480 --> 07:22.080]  алфавита как раз называются терминал символы алфавита называются терминальными
[07:22.080 --> 07:30.200]  потому что их мы дальше раскрыть никак не сможем вот такое определение значит
[07:30.200 --> 07:36.200]  п это правила которые будут записываться интересным образом на самом деле мы видим
[07:36.200 --> 07:40.920]  с вами как они уже записываются то есть у нас а вот эта часть это левая часть из
[07:40.920 --> 07:45.080]  которой мы будем что-то выводить а вот эта часть это правая часть в котором мы
[07:45.080 --> 07:53.200]  будем подставлять и четвертая это с это стартовый не терминал
[07:53.200 --> 08:11.760]  а вот это а все понял
[08:11.760 --> 08:17.800]  все все я не буду писать
[08:17.960 --> 08:28.280]  давайте в качестве примера поймем на вот этой штуке что есть что
[08:28.280 --> 08:46.400]  давайте начнем с s как вы думаете чему здесь s равно
[08:46.400 --> 08:57.680]  с чего мы начинаем разбор sentence да так п
[08:57.680 --> 09:10.480]  стоится из всех правил так n
[09:10.480 --> 09:16.520]  начинаем перечислять их
[09:16.520 --> 09:23.560]  виртгрупп сабжик течекте
[09:23.560 --> 09:32.840]  чему равняется алфавит вот этот самый интересный вопрос
[09:32.840 --> 09:47.520]  нет n и сигма не должны пересекаться нет
[09:47.520 --> 10:01.400]  этого уже раскрываете на самом деле мы можем сказать что в нашем случае африт это части
[10:01.400 --> 10:08.080]  речи это подлежать это существительное это глагол это
[10:08.080 --> 10:17.960]  препозицион и так далее потому что части речи мы уже будем обнаруживать
[10:17.960 --> 10:27.120]  лексическим анализом на такой пример может быть сразу не тривиальный но зато
[10:27.120 --> 10:42.360]  примеры с реальной жизнью в плане
[10:42.360 --> 10:59.760]  ну смотрите правила имеют вид такой из альфа выводится бета да любой может иметь
[10:59.760 --> 11:06.320]  вид на самом деле вы можете сказать что из аб допустим выводится какой-нибудь с
[11:06.320 --> 11:31.880]  где а это у нас символ афавита об и не терминал да да да да знаете почему так
[11:31.880 --> 11:38.680]  сделано немного забегу наперед подумайте как в этих терминах будет работать машина
[11:38.680 --> 11:51.720]  тюринга что такое машина тюринга да ну нет как она работает у нас смотрите мы стоим в
[11:51.720 --> 12:00.800]  каком-то состоянии куеты да у нас есть текущий символ который мы с вами читаем дальше у нас
[12:00.800 --> 12:14.880]  есть какие действия да ну вот да и вы можете сделать следующее попробовать сделать снэпшот
[12:14.880 --> 12:23.680]  состояние слева состояние до которого вас было то есть вы стояли в состоянии куета здесь у
[12:23.680 --> 12:30.240]  нас был записан какой-то символ икс да и еще какие-то слова слева или справа и потом вы
[12:30.240 --> 12:36.360]  указываете еще какое-то действие л я конечно не не очень тут честно пишу да потому что это можно
[12:36.360 --> 12:42.480]  было сделать в одно слово и дальше вы можете перевести это все вы какое-то состояние кутжита
[12:42.480 --> 12:48.120]  допустим если у нас состояние было слева то мы написали слово дубль там какой-то символ
[12:48.120 --> 12:58.080]  дубль в справа оставили символ икс и мы находимся здесь то есть понимаете я к чему клоню что вот
[12:58.080 --> 13:07.560]  такой вот самый общий способ позволяет задать машину тюринга слева это состояние до перехода
[13:07.560 --> 13:15.520]  справа это состояние после перехода просто тут на самом деле последний момент который необходимо
[13:15.520 --> 13:20.440]  обсудить это принимающее состояние в машине тюринга на котором мы программу заканчиваем тогда
[13:20.440 --> 13:25.720]  нам нужно убрать наш символ и выдать пустое слово заменить вон пустое слово чтобы у нас
[13:25.720 --> 13:34.400]  осталось выходное слово наши машины тюринга но нам нужно убрать грубо говоря принимающее состояние
[13:34.400 --> 13:49.640]  то есть мы его просто газим добавляем такое правило вот вот я вкратце рассказал понятно что тут
[13:49.640 --> 13:55.480]  нужны подробные доказательства того почему машина тюринга можно задать порождающей грамматикой
[13:55.480 --> 14:07.080]  вот то есть это самый широкий класс который у нас существует а да кстати
[14:07.080 --> 14:19.360]  да я убрал сигнусы звездой смотрите тут важно что да бак в определении блин вот так что слева
[14:19.400 --> 14:24.680]  нам нужно хотя бы один порождающий символ один не терминальный символ а то смысл что-то раскрывать
[14:24.680 --> 14:35.560]  да да да да да да да но собственно машине тюринга вот у нас куит и являются не терминалами
[14:35.560 --> 14:51.920]  ну никто не запрещает
[14:51.920 --> 15:01.320]  да но если у нас остались только терминальные символы в нашем слове ну все закончили разбор
[15:01.320 --> 15:08.080]  нет вот в таком определении которые да но здесь уже нет
[15:08.080 --> 15:16.560]  да да
[15:28.560 --> 15:35.680]  не не нет это означает что просто правила давайте обсудим что правила вот слева альфа
[15:35.680 --> 15:40.920]  справа бета а в альфе у нас не могут быть только символа алфавита то есть там как
[15:40.920 --> 15:50.160]  минимум один должен быть не терминальный символ так хорошо но это самый общий класс грамматик
[15:50.160 --> 15:55.680]  собственно правила грамматики задается таким образом вот пример нашей грамматики кстати
[15:55.680 --> 16:00.960]  эта грамматика такая более приятная почему вот ту грамматика ту часть грамматики
[16:00.960 --> 16:05.880]  которые мы с вами записали она более приятная в сравнению с той которую мы с вами обсудили для
[16:05.880 --> 16:17.360]  машины тюринга да переходы чуть приятней смотрите у нас переходы всегда идут изне
[16:17.360 --> 16:30.880]  терминала вы какую-то последность терминалов и не терминалов да да вот и вот как раз больше
[16:30.880 --> 16:38.360]  часть этой темы мы будем изучать грамматики именно такого вида мы их дальше введем давайте
[16:38.360 --> 16:47.440]  пример некоторый предположим что у нас n это саб а сигма это а и б и п будет состоять из вот таких
[16:47.440 --> 17:15.480]  правил так давайте я перепишу этот пример это старт так bb и вот она порождающая грамматика
[17:15.480 --> 17:27.440]  как понять что оно выводит ну неявный алгоритм такой давайте мы будем выводить какое-то слово
[17:27.440 --> 17:32.360]  если у нас встречается какая-то последность символов мы ее можем заменить на ту которая
[17:32.360 --> 17:44.200]  находится справа наша цель опять же распознавание какого-то слова поэтому наша цель именно получить
[17:44.200 --> 17:55.240]  какое-то слово на выходе конкретно да смотрите давайте попробуем вывести какое-то слово
[17:55.240 --> 18:11.040]  св это б дальше попробуем а раскрыть а так что получается да дальше у нас неоднозначность
[18:11.040 --> 18:18.920]  уникает которую можно тут разрешать разными способами ну давайте кажется что здесь можно
[18:18.920 --> 18:38.400]  разобрать bb и дальше из bb вывести а что правда o bb b b что получается дальше
[18:44.400 --> 18:45.480]  нет смотрите
[18:49.920 --> 19:00.440]  во то есть смотрите что мы сделали мы заменили вот эти 2 bb на bb дальше вот эти
[19:00.440 --> 19:04.520]  две внутренних bb заменили на bb а дальше вот это заменили на
[19:04.520 --> 19:19.800]  да мы с вами вывели слово а а б но да ну могли бы зайти в тупик да да да да то есть
[19:19.800 --> 19:23.120]  видите у нас в этой грамматике есть какая-то неоднозначность причем не однозначность
[19:23.120 --> 19:30.440]  которая в тупик приводит вот это проблема но в целом в машине тюринга кажется тупик тоже можно
[19:30.440 --> 19:37.920]  зайти вот значит теперь вопрос что нам необходимо для того чтобы вот такую штуку писать
[19:37.920 --> 19:46.640]  мне но это понятно дело не но можно было фломастер и маркер притащить тоже пошло бы
[19:46.640 --> 19:55.160]  не как математические объекты чего нам не хватает какого определения да нам не хватает
[19:55.160 --> 20:03.720]  определение штопора ничего давайте вводить штопор да я не помню какой пример а вот он
[20:03.720 --> 20:09.840]  собственно отношение штопора это снова же наименьшее рефлексивное транзитивное
[20:09.840 --> 20:26.200]  отношение которое определяется для нашей грамматики наименьшее рефлексивное транзитивное
[20:26.200 --> 20:39.320]  отношение такое что для любого фи и пси принадлежащее n объединить сигма со звездой
[20:39.320 --> 20:52.480]  для любого правила альфа бета принадлежащего нашей грамматики будет следовать что мы можем
[20:52.480 --> 20:59.020]  написать вот такой вывод то есть по факту у нас есть лево слово фи есть справа слово
[20:59.020 --> 21:07.680]  пси мы левую часть правила заменяем на правую часть правила и это именно рефлексивное транзитивное
[21:07.680 --> 21:14.200]  отношение то есть у нас получается фи альфа пси всегда будет выводить фи альфа пси а если у
[21:14.200 --> 21:21.760]  нас есть фи альфа пси выводит фи бета пси и допустим фи бета пси выводит фи гамма пси пси то у
[21:21.760 --> 21:38.520]  нас получается фи альфа пси будет выводить фи гамма пси да что не знаю может потому что я не знаю
[21:38.520 --> 21:53.960]  про него хорошо буду использовать ну это теховские буковки насколько я правильно понимаю да ну вот хорошо
[21:53.960 --> 22:03.560]  буду знать я думаю что это только для epsilon работает вот а кстати вот тут баг вот смотрите
[22:03.560 --> 22:11.720]  пример из а мы можем вывести аб и дальше за один шаг мы можем вывести аб ну и дальше мы можем
[22:11.720 --> 22:18.720]  с вами вывести аб из этого а а из этого всего дела то есть понятно зачем нам нужно это отношение
[22:18.720 --> 22:28.840]  хорошо теперь давайте подумаем над следующим как определить что слово лежит в языке задаваемым
[22:28.840 --> 22:50.680]  грамматикой это конечно гениально но как то из стартового состояния можно вывести это слово вот
[22:50.680 --> 22:57.600]  то есть мы покойно вам выводим вот мы говорим что слово вводим в грамматике если у нас из с выводится
[22:57.600 --> 23:03.120]  пустое нашу текущее слово или мы говорим что язык задаваемый грамматика это множество всех
[23:03.120 --> 23:10.080]  слов которые выводится из стартового символа да то есть логичное определение которого у нас
[23:10.080 --> 23:18.960]  теперь должно быть пример выводимости который мы с вами тоже уже успели посмотреть да конечно
[23:18.960 --> 23:33.400]  логично да все хорошо а теперь смотрите пример выводимости достаточно простой ну
[23:33.400 --> 23:40.640]  который мы с вами уже разобрали то есть смотрите мы берем какую-то часть и заменяем ее на правую
[23:40.640 --> 23:47.720]  часть то есть допустим здесь bb заменяем на bb так у нас ответ совпал это знаете как это вы
[23:47.720 --> 23:58.560]  листаете потом в ответы и смотрите совпало оно или нет да не но я на доске допустил бак ну возможно
[23:58.560 --> 24:10.520]  что я а не ну тут сложно наверное было прийти к неоднозначно глобально конечно же да ну
[24:10.520 --> 24:20.440]  понятно что у нас языки вот так про штопор понятно так а теперь знакомимся с частными
[24:20.440 --> 24:27.280]  случаями порождающих грамматик значит для этого есть иерархия хомского значит хомский один из
[24:27.280 --> 24:34.360]  основоположников вообще компьютерной лигуистики и как раз ему принадлежит так сказать концепция
[24:34.360 --> 24:40.520]  грамматик который мы с вами изучаем нам мы будем проходить нормальную форму хомского и другие
[24:40.520 --> 24:47.960]  тоже вещи тоже значит давайте разграничим классы грамматик по виду правил значит наверху у нас
[24:47.960 --> 25:03.360]  будут с вами порождающие здесь мы разрешаем любые правила раз дальше у нас возникают
[25:03.360 --> 25:16.240]  контекстно зависимые грамматики у нас правила будут иметь
[25:16.240 --> 25:39.480]  си альфа где альфа не пустое слово вот это важно то есть почему грамматика называется
[25:39.480 --> 25:45.320]  контекстно зависимый потому что у нее слева есть контекст вывода и справа есть какой-то
[25:45.320 --> 25:57.720]  конкретный контекст вывода это мы ограничиваем свод правил которые у нас существует так
[25:57.720 --> 26:08.400]  следующий да да фиксированный контекст то есть у нас правила имеют фиксированный контекст то
[26:08.400 --> 26:13.640]  есть у нас слева что-то есть есть право что-то да и посередине мы можем изменять не терминал
[26:13.640 --> 26:30.200]  на какую-то правую часть да а из n то есть мы раскрываем один уже конкретный не терминал
[26:30.200 --> 26:39.080]  а последовательность из терминалов не терминал давайте сразу скажу что важно большими буквами
[26:39.080 --> 26:45.040]  обозначаем не терминалы маленькими буквами обозначаем терминалы а греческими буквами мы
[26:45.040 --> 26:50.760]  обозначаем произвольную по сенсе терминалов и не терминалов если мы этого если мы не оговариваем
[26:50.760 --> 27:04.280]  иное да большая с это старт у кроме тех случаев которые не ограничили следующий вид грамматика это
[27:04.280 --> 27:18.320]  контекстно свободной грамматики как вы думаете что надо убрать здесь фи и все убрать надо только
[27:18.320 --> 27:31.520]  важный момент здесь альфа может быть уже пустым а не нет каждый из этих классов будет более узок
[27:31.720 --> 27:48.440]  давайте еще раз грамматика называется контекстно зависимый если все ее правила
[27:48.440 --> 27:55.960]  имеет вот такой вид контекст свободной грамматика называется контекстно зависимый если все
[27:55.960 --> 28:10.560]  ее правила имеет вот такой вид где вот это да одна буква и остался последний класс это
[28:10.560 --> 28:15.560]  праволинейные грамматики или их еще на могут называть леволинейными грамматики
[28:15.560 --> 28:36.160]  это либо а выводит в в либо у нас а выводит в дубль в аб это не терминал
[28:36.160 --> 28:45.960]  вот это самый узкий класс да мы еще и альфа ограничили
[28:45.960 --> 28:58.000]  вот да тут надо было это сразу сразу ставить презентацию что мы будем
[28:58.000 --> 29:04.480]  возначать терминалами большими буквами да а потом обозначать любые греческие буквы мы
[29:04.480 --> 29:09.840]  будем означать последствия терминалов и не терминалов так здесь на слайдах есть
[29:09.840 --> 29:17.440]  примеры смотрите для кз грамматики пример смотрите у нас возможно правила от аб выводит
[29:17.440 --> 29:25.200]  сб при этом левый контекст это пустое слово а правый контекст это слово б да то есть у нас
[29:25.200 --> 29:34.160]  получается мы вместо вместо psi подставляем b а альфа в нашем случае это c значит следующий
[29:34.160 --> 30:00.800]  о господи это не латинская буква это вообще да да да да да собственно есть такое
[30:01.040 --> 30:08.640]  левый контекст и р hag context это пустые слова здесь левый контекст а то я а правый контекст
[30:08.640 --> 30:20.240]  р hag context точнее это у нас пустое слово да то есть видите и мы можем прайт типа того и допустим
[30:20.240 --> 30:26.440]  у нас есть еще слово ец ф его это еды и а ف а тогда у нас получается левый контекст это
[30:26.440 --> 30:38.440]  а равый контекст это f. Внутри из c мы выводим de. Пример ks грамматики, скажите, вот так вот выводить проще.
[30:38.440 --> 30:50.440]  Правда, мы можем вывести сильно меньше слов. Пример права линейной грамматики. Вот он, вот такой вот.
[30:50.440 --> 31:02.440]  Да, кстати, давайте раз мы тут поговорим про грамматики, поймем, почему класс контекста свободных грамматик шире, чем класс автоматных языков.
[31:02.440 --> 31:08.440]  Как распознать a в n и b в n при помощи...
[31:08.440 --> 31:22.440]  Нет, не обязательно. Пример правильной скобочной последовательности.
[31:22.440 --> 31:32.440]  А, или наоборот, что...
[31:32.440 --> 31:39.440]  Нет, а если это буквы нету в левых частях правил?
[31:39.440 --> 31:43.440]  Да.
[31:43.440 --> 31:55.440]  Да.
[31:55.440 --> 32:03.440]  Ну, слушайте...
[32:03.440 --> 32:12.440]  Не, но это уже может привести к неоднозначности.
[32:12.440 --> 32:17.440]  Это да.
[32:17.440 --> 32:22.440]  Да.
[32:22.440 --> 32:32.440]  Но при этом мы в итоге можем...
[32:32.440 --> 32:38.440]  Нет, не всегда будет однозначный разбор.
[32:38.440 --> 32:46.440]  Ну, пример тот же самый PSP. Там можно задать грамматику таким образом, что всегда слово будет получено ровно одним способом.
[32:46.440 --> 32:56.440]  А можно задать так, что если вы посмотрите на вывод, который у вас получается, то там будет другой вывод.
[32:56.440 --> 33:05.440]  А, ну, в этом плане надо подумать. Вполне возможно, что да.
[33:05.440 --> 33:15.440]  Ну да, для контекста свободных так точно.
[33:15.440 --> 33:20.440]  Не, ну там контекст может дополнительный появиться.
[33:20.440 --> 33:26.440]  Так, давайте разберем пример АВН и БВН.
[33:26.440 --> 33:36.440]  Какая грамматика подойдет нам?
[33:36.440 --> 33:43.440]  С АСБ и С выводит Эпсилон. Все.
[33:43.440 --> 33:49.440]  Вы можете вывести любое слово вида АВН и БВН.
[33:49.440 --> 33:56.440]  Да здрасте. Я сейчас докажу теорему, которая вас опровергнет.
[33:56.440 --> 34:06.440]  Все равно. Утверждение есть, что праволинейные грамматики точно те же самые, что конечные автоматы.
[34:06.440 --> 34:10.440]  АВН и БВН – это автоматный язык у нас?
[34:10.440 --> 34:15.440]  Нет.
[34:15.440 --> 34:20.440]  Нет, так что не задать. Вот.
[34:20.440 --> 34:25.440]  Вывод при этом будет такой.
[34:25.440 --> 34:30.440]  АВН и БВН.
[34:30.440 --> 34:36.440]  Обратно делаются индукции по количеству правил вывода.
[34:36.440 --> 34:43.440]  Так. Иерархия Хомского. Вот. Теперь такая вот табличка. Что чему соответствует.
[34:43.440 --> 34:47.440]  Значит, порождающие грамматики. Да, начнем с самого низа.
[34:47.440 --> 34:54.440]  Праволинейные грамматики соответствуют недетерминированным конечным автоматам.
[34:54.440 --> 34:58.440]  И это то, что мы сегодня будем доказывать.
[34:58.440 --> 35:03.440]  Контекстно свободные автоматы эквивалентны МП-автоматам.
[35:03.440 --> 35:06.440]  И эту конструкцию мы с вами будем разбирать.
[35:06.440 --> 35:12.440]  Что такое МП-автомат? Это автомат, у которого сбоку приделан стэк.
[35:12.440 --> 35:21.440]  Это МП-автомат, у которого, когда вы выводите какое-то слово, вы можете на стэк положить определенный набор символов.
[35:21.440 --> 35:27.440]  Для того, что... А? МП. С магазинной памятью.
[35:27.440 --> 35:31.440]  А?
[35:31.440 --> 35:35.440]  А, новый термин появился.
[35:35.440 --> 35:38.440]  Да.
[35:38.440 --> 35:48.440]  Смотрите, сейчас будет еще более взрывной термин, когда я скажу, чему эквалентны контекстно зависимые грамматики.
[35:48.440 --> 35:53.440]  Магазинный автомат-то интересный, а еще магазинный полуавтомат остался.
[35:56.440 --> 36:00.440]  Котекста зависимой грамматики.
[36:00.440 --> 36:06.440]  Как говорит научная литература, это ограничены недетерминированные машины тюринга.
[36:06.440 --> 36:14.440]  Грубо говоря, чтобы вы понимали, это по факту машины тюринга, в которых можно делать произвольные переходы.
[36:14.440 --> 36:18.440]  То есть вы из одного состояния можете перейти не в одно состояние, а в набор состояния.
[36:18.440 --> 36:26.440]  Но важно, что у вас сверху есть консанта С, сверху по дополнительной памяти, которую вы можете использовать.
[36:26.440 --> 36:32.440]  Да, нельзя слишком далеко уходить направо и налево.
[36:32.440 --> 36:40.440]  И последние, это порождающие грамматики, они эквалентны машины тюринга.
[36:40.440 --> 36:44.440]  С точки зрения задачи распознавания слов.
[36:44.440 --> 36:50.440]  То есть каждый из этих классов более узок, чем предыдущий.
[36:50.440 --> 36:56.440]  И давайте начнем как раз сегодня с доказательства первого факта.
[36:56.440 --> 37:02.440]  Так, давайте я этот слайд остановлю. Есть ли вопросы?
[37:02.440 --> 37:09.440]  Разве ограниченные ММЦ не эквалентны конечным и автоматным?
[37:09.440 --> 37:10.440]  Не совсем.
[37:10.440 --> 37:12.440]  А в чем там проблема?
[37:12.440 --> 37:18.440]  В чем там проблема? Проблема там в том, что нужно контекст учитывать.
[37:23.440 --> 37:27.440]  Ну то есть у вас есть состояние, вам надо посмотреть, что находится слева, что находится справа.
[37:27.440 --> 37:30.440]  А там не получится это состояние?
[37:30.440 --> 37:33.440]  Нет, не получится их, там может быть бесконечно много.
[37:38.440 --> 37:39.440]  То есть по факту...
[37:39.440 --> 37:42.440]  А контекстов бесконечно много, но при этом памяти вообще ограничены.
[37:42.440 --> 37:43.440]  Да, да.
[37:43.440 --> 37:46.440]  Поэтому автомат может не быть конечным, а бесконечные автоматы не гарантируют.
[37:46.440 --> 37:48.440]  Ну да, типа того.
[37:48.440 --> 37:51.440]  Так, по вот этому понятно?
[37:53.440 --> 37:54.440]  Чего, вот это?
[37:54.440 --> 37:58.440]  Значит смотрите, мы будем доказывать эквалентность первых двух строк.
[38:00.440 --> 38:02.440]  Третье, четвертое для общего развития.
[38:04.440 --> 38:09.440]  Возможно, на семинаре рассмотрите задачу, как построить порождающую грамматику
[38:09.440 --> 38:13.440]  для распознавания каких-то слов, которые вот из машины тюринга.
[38:13.440 --> 38:15.440]  Или проэмулируйте машину тюринга.
[38:22.440 --> 38:24.440]  А зачем нам недетерминированность?
[38:24.440 --> 38:28.440]  Недетерминированность нам нужна чисто по той причине, что с ней проще возиться.
[38:28.440 --> 38:31.440]  То есть объекты, которые нам нужны, их проще строить.
[38:36.440 --> 38:39.440]  Ну я думаю, что если подумать, то...
[38:43.440 --> 38:44.440]  Да.
[38:50.440 --> 38:55.440]  Ну, слушайте, тут тонкий момент, потому что с ограниченностью,
[38:55.440 --> 38:58.440]  потому что это и прокатит, а с неограниченностью не прокатит.
[38:58.440 --> 39:05.440]  Потому что машины тюринга задают класс P, допустим, если мы говорим за время,
[39:05.440 --> 39:08.440]  а недетерминированные машины тюринга задают класс NP.
[39:11.440 --> 39:14.440]  Ну, с точки зрения симптотики алгоритмов.
[39:14.440 --> 39:25.440]  Да, любые машины тюринга, которые у вас определялись на курсе матлога.
[39:31.440 --> 39:33.440]  Чего было, конечно.
[39:33.440 --> 39:37.440]  Ну, не, качество состояния машины тюринга, конечно, будет конечным.
[39:40.440 --> 39:41.440]  А, бесконечно...
[39:44.440 --> 39:46.440]  В ограниченной машине у тебя конечная лента.
[39:47.440 --> 39:50.440]  А просто в машине у тебя лента очевидная.
[39:58.440 --> 40:00.440]  Так, чего переходим к доказательству следующего факта?
[40:06.440 --> 40:07.440]  Следующая теорема.
[40:07.440 --> 40:12.440]  Множество автоматных языков равно множеству языков, задаваемых праволинейными грамматиками.
[40:14.440 --> 40:16.440]  Вот этот факт мы сегодня с вами будем доказывать.
[40:16.440 --> 40:24.440]  Значит, сразу скажу, что мы с вами рассмотрим конструкции, посмотрим, как они работают,
[40:26.440 --> 40:33.440]  а дальше, а дальше дело рук индукции, то есть к аккуратному выводу.
[40:34.440 --> 40:36.440]  Значит, теорема.
[40:44.440 --> 40:46.440]  Автоматный.
[40:48.440 --> 41:01.440]  Тогда и только тогда, когда существует G праволинейная грамматика, такая, что L равняется LJ.
[41:05.440 --> 41:07.440]  То есть наша идея какая?
[41:07.440 --> 41:10.440]  Для каждой грамматики построить праволинейный автомат,
[41:10.440 --> 41:17.440]  ой, наоборот, для каждого автомата построить праволинейную грамматику и для каждой грамматики построить автомат.
[41:18.440 --> 41:24.440]  Собственно, идея, которая состоит в доказательстве этого факта, что состояние в автомате,
[41:25.440 --> 41:31.440]  это следующее, что это не терминалы в грамматике плюс сток, плюс стоковая вершина.
[41:31.440 --> 41:36.440]  Посмотрите, пожалуйста, вот внимательно на вот эти правила.
[41:37.440 --> 41:40.440]  Из A выводят слово W и B.
[41:40.440 --> 41:43.440]  Как вы думаете, что в терминах автоматов?
[41:43.440 --> 41:46.440]  Мы по слову W перешли из A в B.
[41:46.440 --> 41:50.440]  Да, смотрите, мы по слову W перешли из A в B.
[41:50.440 --> 41:52.440]  А вот это?
[41:52.440 --> 41:54.440]  Перешли в терминал по слову W.
[41:54.440 --> 41:58.440]  Да, перешли в терминальное состояние, которое является ровным одним по слову W.
[41:58.440 --> 42:05.440]  То есть мы просто каждой вершинице поставим, мы каждый не терминальный вершинец поставим какой-то символ?
[42:05.440 --> 42:10.440]  Да, именно так.
[42:10.440 --> 42:13.440]  То есть доказательство достаточно простое.
[42:13.440 --> 42:23.440]  Да, давайте сначала докажем, получается, и справа влево.
[42:23.440 --> 42:25.440]  Значит, построим автомат.
[42:25.440 --> 42:27.440]  Значит, что у нас будет?
[42:27.440 --> 42:31.440]  Это будет множество стоп.
[42:31.440 --> 42:33.440]  Сейчас подумаю.
[42:33.440 --> 42:35.440]  Тут баг.
[42:35.440 --> 42:37.440]  Да, тут баг.
[42:37.440 --> 42:39.440]  Найдите баг в презентации.
[42:42.440 --> 42:45.440]  Да, N.
[42:45.440 --> 42:57.440]  N объединяет с QF, значит, сигма, дельта, множество стартовое состояние и множество завершающее состояние.
[42:57.440 --> 42:59.440]  Как определяются переходы?
[42:59.440 --> 43:10.440]  Это у нас переход из A по слову W в слово W, если у нас было правило A выводит W в.
[43:10.440 --> 43:24.440]  И второе правило, из A по слову W мы переходим в состояние QF, если у нас было правило в грамматике A выводит W.
[43:29.440 --> 43:37.440]  Вот такая идея.
[43:37.440 --> 43:39.440]  Значит, что нам нужно доказать теперь?
[43:53.440 --> 43:57.440]  Для этого нам нужно доказать следующий факт.
[43:57.440 --> 44:01.440]  Давайте будем доказывать более общий факт.
[44:07.440 --> 44:16.440]  A в грамматике G будет выводить слово W тогда и только тогда, когда мы с вами...
[44:16.440 --> 44:18.440]  Что получается?
[44:18.440 --> 44:25.440]  Из A по W выводим в нашем автомате пару B.
[44:26.440 --> 44:28.440]  В конфигурациях нашего автомата.
[44:28.440 --> 44:30.440]  Это 1.
[44:30.440 --> 44:32.440]  И 2.
[44:44.440 --> 44:46.440]  Вот такой.
[44:48.440 --> 44:50.440]  Логично.
[44:50.440 --> 44:58.440]  Давайте разберем, наверное, следующий переход в качестве упражнения.
[44:58.440 --> 45:02.440]  Мы будем доказывать переход с вами излево вправо.
[45:02.440 --> 45:04.440]  Почему именно переход излево вправо?
[45:04.440 --> 45:08.440]  Потому что хочется показать новый тип индукции.
[45:08.440 --> 45:13.440]  Индукция будет подлиннее вывода в грамматике.
[45:13.440 --> 45:17.440]  Справа налево. Как вы думаете, индукция будет почему?
[45:17.440 --> 45:19.440]  Нет.
[45:20.440 --> 45:26.440]  По длине вывода в автомате.
[45:26.440 --> 45:35.440]  То есть индукция справа налево по длине вывода в автомате, слева направо индукция по длине вывода в грамматике.
[45:36.440 --> 45:41.440]  У нас пока нет никаких...
[45:41.440 --> 45:45.440]  Мы здесь вообще берем произвольный...
[45:51.440 --> 45:54.440]  Мы же из грамматики автомат хотим построить сейчас.
[46:02.440 --> 46:04.440]  Поэтому давайте сделаем так.
[46:04.440 --> 46:08.440]  Я сейчас докажу факт слева направо, собственно, вывод.
[46:08.440 --> 46:12.440]  А пункт справа налево делается похожим способом.
[46:12.440 --> 46:15.440]  Просто это куча выводов буковок.
[46:17.440 --> 46:19.440]  Этот пункт мы пропускаем.
[46:19.440 --> 46:22.440]  Здесь база индукции делается аккуратно.
[46:27.440 --> 46:30.440]  Говорю, написать это надо.
[46:30.440 --> 46:34.440]  То есть база индукции, собственно, за ноль шагов что мы можем вывести.
[46:34.440 --> 46:39.440]  Дальше посмотрим на последний переход, который здесь происходит.
[46:39.440 --> 46:43.440]  На последнем переходе мы получаем с вами индукционный переход.
[46:45.440 --> 46:47.440]  Или второй пункт, когда мы вводим эпсилон.
[46:47.440 --> 46:51.440]  То есть здесь чисто написание индукции.
[46:51.440 --> 46:54.440]  Теперь давайте мы подумаем с вами про вот эту вещь.
[47:00.440 --> 47:02.440]  Длине вывода.
[47:02.440 --> 47:04.440]  Давайте я буду написать.
[47:04.440 --> 47:07.440]  По длине вывода в грамматике.
[47:07.440 --> 47:09.440]  Значит, база.
[47:20.440 --> 47:22.440]  Да, да. Именно так.
[47:24.440 --> 47:27.440]  Да, он нам нужен только в доказательстве ЛЕМА.
[47:27.440 --> 47:29.440]  Так, смотрите.
[47:29.440 --> 47:33.440]  Значит, с другой стороны, индукция под длине вывода в грамматике.
[47:33.440 --> 47:35.440]  База.
[47:39.440 --> 47:42.440]  За сколько шагов мы можем что-то вывести?
[47:44.440 --> 47:46.440]  За ноль.
[47:48.440 --> 47:50.440]  Тогда у нас работает верхнее правило.
[47:52.440 --> 47:56.440]  Мы в грамматике G за ноль шагов выводим слово, символ WB.
[47:57.440 --> 47:59.440]  Из этого что следует?
[47:59.440 --> 48:02.440]  Из этого следует, что W у нас пустое слово.
[48:02.440 --> 48:04.440]  А B равняется A.
[48:05.440 --> 48:14.440]  Ну и тогда мы можем с вами вывести, что из A эпсилон действительно выводится B эпсилон.
[48:18.440 --> 48:20.440]  За ноль.
[48:20.440 --> 48:22.440]  Мы никуда не перешли.
[48:23.440 --> 48:26.440]  Нет, мы как бы перешли как бы по дыде.
[48:26.440 --> 48:30.440]  Нет, мы остались на том же самом месте именно.
[48:30.440 --> 48:33.440]  Если мы сделали вот так, мы и остались на дыде.
[48:33.440 --> 48:35.440]  Ну, это называется переход по дыде.
[48:35.440 --> 48:36.440]  Нет.
[48:36.440 --> 48:38.440]  У нас нет дыди.
[48:38.440 --> 48:42.440]  Нет, мы всегда говорили, что у нас вот это вот, смотрите, это рефлексивно-трандитивное отношение.
[48:42.440 --> 48:46.440]  То есть в нем может быть переход за ноль шагов.
[48:48.440 --> 48:51.440]  То есть мы могли отсюда-сюда попасть за ноль шагов.
[48:51.440 --> 48:54.440]  Но просто это означает, что левая часть эквалентна правой.
[48:54.440 --> 48:56.440]  То есть является то же самое, что и правая.
[49:10.440 --> 49:11.440]  Так.
[49:11.440 --> 49:15.440]  И единственный момент, который нужно проверить, это K равная единица.
[49:15.440 --> 49:17.440]  Вот для вот этого случая.
[49:22.440 --> 49:24.440]  Второй случай K равная единица.
[49:24.440 --> 49:26.440]  Смотрите.
[49:26.440 --> 49:30.440]  Из A за один шаг выявилось слово W.
[49:33.440 --> 49:39.440]  Из этого следует, что A, W принадлежит нашим правилам грамматики.
[49:39.440 --> 49:42.440]  Ну а из этого следует, что?
[49:42.440 --> 49:44.440]  У нас что?
[49:44.440 --> 49:53.440]  Следовательно, у нас из A по слову W мы так могли дойти до слова, до состояния QF, Epson.
[49:53.440 --> 49:57.440]  Просто по той причине, что у нас есть вот этот вот факт.
[50:02.440 --> 50:06.440]  Да, то есть что у нас есть вот это правило, по которому мы могли перейти.
[50:06.440 --> 50:15.440]  Ну давайте, да, тоже разберем, тоже несложно.
[50:21.440 --> 50:23.440]  Да, согласен.
[50:23.440 --> 50:36.440]  Потому что индукционный переход будет одновременный.
[50:36.440 --> 50:38.440]  Так, смотрите, значит, что у нас получается?
[50:42.440 --> 50:44.440]  Ну, для вот этого факта.
[50:44.440 --> 50:47.440]  То есть нам нужно будет вывод относительно этой штуки колдовать.
[50:47.440 --> 50:52.440]  Ну, на самом деле, вот для первого правила тоже можно не доказывать.
[50:54.440 --> 50:57.440]  Потому что он будет следовать из индукционного перехода.
[51:03.440 --> 51:06.440]  Следовательно, у нас здесь существует правило.
[51:14.440 --> 51:19.440]  Принадлежит дельта. Из A, W мы выводим B, Epson.
[51:20.440 --> 51:23.440]  Ну, здесь ничего сложного нет.
[51:24.440 --> 51:26.440]  Так.
[51:28.440 --> 51:33.440]  А, ну тут даже, да, тут говорится, что даже переход индукции можно использовать.
[51:35.440 --> 51:37.440]  Да, что это даже индукционный переход.
[51:39.440 --> 51:42.440]  Ну что, давайте смотреть, что мы можем с вами сделать.
[51:42.440 --> 51:44.440]  Ну давайте рассмотрим последний переход.
[51:49.440 --> 51:52.440]  Да, переход.
[51:52.440 --> 51:55.440]  Значит, давайте рассмотрим последнее правило.
[51:55.440 --> 51:57.440]  Последний вывод.
[52:00.440 --> 52:01.440]  Шаг.
[52:02.440 --> 52:03.440]  Да.
[52:09.440 --> 52:10.440]  Нет.
[52:14.440 --> 52:15.440]  Ну да.
[52:20.440 --> 52:22.440]  Ну можно, да, согласен.
[52:27.440 --> 52:30.440]  Ну да, согласен, хорошо.
[52:30.440 --> 52:35.440]  Ну да, давайте посмотрим, что мы дошли до какого-то терминала УС,
[52:35.440 --> 52:39.440]  и дальше за один шаг в грамматике мы раскрыли УВБ.
[52:41.440 --> 52:44.440]  Ну тогда смотрите, что у нас получается.
[52:44.440 --> 52:46.440]  У нас получается интересная вещь.
[52:46.440 --> 52:53.440]  Что по предположению индукции у нас с вами получается,
[52:53.440 --> 53:00.440]  есть вывод из АУВЦ, да,
[53:00.440 --> 53:04.440]  а вот отсюда у нас из правил грамматики будет следовать,
[53:04.440 --> 53:10.440]  что из СВ мы выводим пару В,
[53:12.440 --> 53:14.440]  ну и осталось сделать техники.
[53:17.440 --> 53:22.440]  Да, АУВЦ мы можем съесть, получить СВ,
[53:22.440 --> 53:27.440]  съедаем УСа входа, и дальше оставляем пару В.
[53:27.440 --> 53:29.440]  Все, победили.
[53:35.440 --> 53:37.440]  Второй пункт будем доказывать?
[53:39.440 --> 53:41.440]  То же самое.
[53:42.440 --> 53:46.440]  Поэтому здесь будет четыре одинаковых индукционных перехода,
[53:46.440 --> 53:49.440]  в каждом из которых еще два пункта.
[53:54.440 --> 53:59.440]  Честно, у меня была одна статья на матпраке по формальным языкам,
[53:59.440 --> 54:03.440]  там будет нормальная форма, мы сделали обобщение,
[54:03.440 --> 54:06.440]  там, по-моему, доказательства было пункта,
[54:06.440 --> 54:10.440]  оно состояло в разборе семи случаев в одну сторону индукции,
[54:10.440 --> 54:13.440]  и семи случаев в другую сторону индукции.
[54:24.440 --> 54:27.440]  Итак, смотрите, допустим, мы дошли до такого правила,
[54:27.440 --> 54:31.440]  за один шаг, но тогда отсюда у нас, по предположению индукции,
[54:31.440 --> 54:35.440]  вот как раз нам нужна цепочка, вот та вот сверху,
[54:35.440 --> 54:38.440]  по предположению индукции.
[54:38.440 --> 54:44.440]  А вторая цепочка у нас получается из С по W, мы уходим в QF епсилон.
[54:48.440 --> 54:52.440]  И в итоге из А у В мы получаем переход СВ
[54:55.440 --> 54:57.440]  в QF епсилон.
[54:57.440 --> 55:00.440]  Все, доказали переход в другую сторону.
[55:00.440 --> 55:03.440]  То есть мы с вами доказали индукционный переход.
[55:04.440 --> 55:08.440]  Так, теперь как доказать, имея вот этот вот факт
[55:08.440 --> 55:12.440]  и имея вот эту вот лему, да, давайте я напишу специально
[55:12.440 --> 55:15.440]  вот для тех, кто смотрит это,
[55:15.440 --> 55:18.440]  в другую сторону смотри презентацию.
[55:22.440 --> 55:24.440]  Нет.
[55:24.440 --> 55:27.440]  Мы доказали здесь переход слева направо.
[55:54.440 --> 55:57.440]  Нет, нет, нет.
[55:57.440 --> 56:00.440]  Смотрите, как устроена будет процедура экзамена,
[56:00.440 --> 56:04.440]  немножко поговорим, да, мы, значит, будем спрашивать
[56:04.440 --> 56:08.440]  именно идеи доказательств, какие именно факты нужно доказать.
[56:08.440 --> 56:12.440]  А дальше, если мы хотим уточнить всю эту историю,
[56:12.440 --> 56:14.440]  мы попросим аккуратненько провести индукцию.
[56:14.440 --> 56:18.440]  Причем все факты, которые необходимы для проведения индукции, мы дадим.
[56:18.440 --> 56:22.440]  Нет, нет, нет. Ну то есть наша цель не зазубрить эти доказательства,
[56:22.440 --> 56:25.440]  а научиться их понимать.
[56:25.440 --> 56:28.440]  Ну они тупые, понимать нечего.
[56:28.440 --> 56:31.440]  Там надо просто писать.
[56:31.440 --> 56:34.440]  Можно просто говорить в языке графов?
[56:34.440 --> 56:37.440]  Ну на полуформальном языке графов можно говорить.
[56:37.440 --> 56:41.440]  То есть в целом можно объяснить по-настоящему,
[56:41.440 --> 56:44.440]  как мы можем это сделать.
[56:45.440 --> 56:48.440]  Да, да, да, да.
[56:48.440 --> 56:51.440]  Отлично.
[56:51.440 --> 56:54.440]  Нет, так не прокатит.
[56:54.440 --> 56:58.440]  Ладно, давайте лирику в сторону докажем,
[56:58.440 --> 57:02.440]  имея вот этот факт и имея вот эти две ремы,
[57:02.440 --> 57:06.440]  то, что у нас есть, в общем-то,
[57:06.440 --> 57:10.440]  и есть, в общем-то, и есть, в общем-то,
[57:11.440 --> 57:17.440]  то, что у нас язык с задаваемого автомата
[57:17.440 --> 57:20.440]  принадлежит языку с задаваемой грамматикой.
[57:23.440 --> 57:28.440]  Итак, предположим, что у нас В лежит в языке с задаваемой грамматикой.
[57:28.440 --> 57:31.440]  Это, верно, когда?
[57:31.440 --> 57:34.440]  Помогайте.
[57:36.440 --> 57:39.440]  А это и когда?
[57:40.440 --> 57:50.320]  Выводимо qf эпсилон. qf у нас является единственным завершающим
[57:50.320 --> 58:13.440]  состоянием. Все, все время осталось. Хорошо, а теперь вопрос, то есть понятно, как это
[58:13.640 --> 58:22.600]  в одну сторону проходят? Нет, идея в чем? То есть мы берем стоковую вершину и делаем
[58:22.600 --> 58:28.080]  переходы прямо как они написаны. Давайте подумаем, как в обратную сторону делать.
[58:28.080 --> 58:43.400]  Да, по автомату грамматику. Нет, можно одно стоковое состояние оставить и вернуть,
[58:43.400 --> 58:55.600]  доказать, что ровно таким же, как оно было. Да, каждая вершина это не терминал. Михаил
[58:55.600 --> 59:11.880]  рассказал интересную идею. Чуть-чуть сложнее. По факту идея может так. Строим с одним завершающим
[59:11.880 --> 59:23.560]  состоянием. И дальше, если у нас есть переход по v, то мы его превращаем в правило a вводит в b.
[59:23.560 --> 59:37.800]  А если у нас с вами есть завершающее состояние q, то как его породить? Да, q эпсилон. На самом деле
[59:37.800 --> 59:46.440]  можно просто не делать одно завершающее состояние, а просто для каждого завершающего состояния это написать.
[59:46.440 --> 01:00:10.000]  Вот так. Спасибо. Вот. И опять же, просто аккуратно это надо написать.
[01:00:10.000 --> 01:00:17.040]  Давайте посмотрим, как это аккуратно пишется.
[01:00:17.040 --> 01:00:26.000]  Кстати, пример. Опять же, на презентациях есть примеры. Вот такой автомат получается,
[01:00:26.000 --> 01:00:45.120]  допустим, для вот этой грамматики. Вот это? Это нужно было доказать. Смотрите, мы по грамматике
[01:00:45.120 --> 01:00:51.080]  построили автомат. И нам нужно доказать, что эти языки, которые задают грамматику и задают автомат,
[01:00:51.080 --> 01:00:58.400]  они совпадают. Мы этого пока не делали. То есть мы доказали вспомогать лему, которая нам помогла,
[01:00:58.400 --> 01:01:06.640]  и дальше при помощи этой леммы уже доказали факт, что языки совпадают. Нет, ну смотрите,
[01:01:06.640 --> 01:01:12.720]  здесь история такая, что здесь мы по грамматике построили, у нас была произвольная грамматика,
[01:01:12.720 --> 01:01:19.640]  мы по ней построили автомат. А тут мы с вами будем делать следующее, что если у нас есть какой-то
[01:01:19.640 --> 01:01:30.960]  автомат, как его в грамматику превратить? Да, то есть смотрите, здесь мы доказали,
[01:01:30.960 --> 01:01:36.120]  что из грамматики существует автомат и показали. А теперь нам нужно делать обратно,
[01:01:36.120 --> 01:01:46.080]  что из-за автомата можно построить грамматику. Вот, это пример. Смотрите, идея такая, не терминалы
[01:01:46.080 --> 01:01:52.920]  в грамматике, это состояние в автомате. Ну и тут говорится, что добавить Epsilon переход. То есть
[01:01:52.920 --> 01:02:01.360]  вот оно формальное определение, которое я сейчас нарисовал. То есть мы делаем вот такие переходы.
[01:02:01.360 --> 01:02:07.320]  И тогда что нам нужно сделать? Ну, собственно, доказать еще раз тот же самый факт,
[01:02:07.320 --> 01:02:33.240]  который нам нужен. Вопрос, хотим ли мы на это тратить время? Нет, не сильно фатально. То есть
[01:02:33.240 --> 01:02:49.320]  вторая лемма, которая у нас будет, это получается... Ну да, тут лемма на самом деле будет ровно той же
[01:02:49.320 --> 01:02:57.000]  самой. Вот, то есть опять же, идея какая, что если мы дошли до завершающего состояния,
[01:02:57.000 --> 01:03:05.520]  тогда мы вводим слово. Если мы с вами не дошли до завершающего состояния, то мы вводим его с правым
[01:03:05.520 --> 01:03:13.760]  символом. Опять же, смотрите, сколько тут замечательных пунктов, которые есть. Давайте
[01:03:13.760 --> 01:03:19.720]  я их пропущу. Если вам, допустим, возникнут вопросы в доказательствах вот этого факта,
[01:03:19.720 --> 01:03:30.640]  я просто отдельно сяду и запишу видео для этого всего. Договорились? Да,
[01:03:30.640 --> 01:03:57.200]  в общем, аккуратненько делается вывод. Тут видите, сколько слайдов. В принадлежит языку,
[01:03:57.200 --> 01:04:02.560]  сдаваемой грамматикой. Значит, если у нас имеется этот факт, то существует завершающее
[01:04:02.560 --> 01:04:08.080]  состояние, которое это распознает. Ну а раз существует завершающее состояние, которое это распознает,
[01:04:08.080 --> 01:04:16.000]  то вот у нас есть вывод, который у нас находится справа вверху, что из Q1 вводится слово W. Вот,
[01:04:16.000 --> 01:04:23.120]  Q0 вводится слово W. А это значит, что слово лежит в языке, сдаваемой данной грамматикой. То есть
[01:04:23.120 --> 01:04:33.680]  это дело техники, а не дело измышлений философских, которые у нас есть на это дело. Потому что,
[01:04:33.680 --> 01:04:38.760]  я помню, всегда доказательства идут достаточно сложно. Главная идея, которая в этом доказательстве
[01:04:38.760 --> 01:04:45.200]  есть, что, оказывается, можно проводить индукцию по длине вывода в грамматике. Все. И что, если у
[01:04:45.200 --> 01:04:48.640]  нас есть индукция по длине вывода в грамматике, то мы можем раскрывать либо первое правило,
[01:04:48.640 --> 01:04:59.320]  либо последнее. Мозги на этом закончились. Точнее измышления в мозгах. Вот тоже пример,
[01:04:59.320 --> 01:05:07.280]  который нам это позволяет делать. Вот они все переходы, и дополнительно для завершающего
[01:05:07.280 --> 01:05:16.640]  состояния мы добавляем переходы из Q0 в эпсилон и из Qs в эпсилон. Вот такая вот картинка. Давайте
[01:05:16.640 --> 01:05:33.160]  я зафиксирую ее на минуту буквально. Зафиксировали картинку, чтобы она у нас в памяти зашла. Хорошо,
[01:05:33.160 --> 01:05:40.800]  двигаемся дальше. То есть мы с вами поняли, что у нас классы языков, задаваемых автоматами и
[01:05:40.800 --> 01:05:47.560]  праволинейными грамматиками, это одно и то же. Вопрос подвохом. Для леволинейных будет то же самое?
[01:05:47.560 --> 01:06:03.320]  Да, просто там правила немного имеют другой вид. Если у нас праволинейных правила имеют вид вот такой вот.
[01:06:10.800 --> 01:06:40.120]  Ну да. Хорошо, давайте двигаться дальше тогда. Теперь наконец-то мы переходим к контексте
[01:06:40.120 --> 01:06:48.560]  свободного грамматика. И здесь уже можно делать некоторые новые определения. Определение работает
[01:06:48.560 --> 01:06:56.280]  только для контекста свободного грамматика, подчеркну. Значит, на самом деле, вот если внимательно
[01:06:56.280 --> 01:07:04.640]  посмотреть грамматику какую-нибудь, то мы вывод можем представить в виде дерева. Вот этого вот
[01:07:04.640 --> 01:07:10.560]  интересного слова. То есть смотрите, что мы говорим. Мы можем последовательность выводов,
[01:07:10.560 --> 01:07:17.200]  символов сделать так, что давайте зафиксируем вершину нашего дерева и не терминал,
[01:07:17.200 --> 01:07:23.240]  попытаемся раскрыть как некоторое под дерево. То есть смотрите, тут есть цепочка выводов.
[01:07:23.240 --> 01:07:37.880]  Мы рассмотрим с вами грамматику АСАА. Дальше, что там, из А выводят СА, да и С выводят АПСУ.
[01:07:37.880 --> 01:07:48.640]  Значит, мы можем раскрывать это все. Допустим, мы из С выводим АСАА. Давайте нарисуем вершину дерева.
[01:07:48.640 --> 01:08:01.440]  Да. Какие могут быть?
[01:08:01.440 --> 01:08:18.320]  Ну, бывает.
[01:08:18.320 --> 01:08:33.440]  Вот. И дальше тут можно это все дело раскрывать, раскрывать, раскрывать до тех пор, пока мы не
[01:08:33.440 --> 01:08:46.680]  получим наше слово. А почему направленное цикли? Почему? Для конкретного слова это будет дерево.
[01:08:46.680 --> 01:08:51.360]  Для конкретного слова это будет дерево. Просто это дерево можно будет получить несколькими способами.
[01:08:51.360 --> 01:09:07.120]  Да, мы всегда... Да, конечно же. И здесь важно... Вот, смотрите, вот такое замечательное дерево получается.
[01:09:07.120 --> 01:09:16.160]  То есть С раскрывается ВСА, и С раскрывается А. Вот. И дальше дается следующее определение. Дерево вывода.
[01:09:16.160 --> 01:09:24.320]  Смотрите, дерево это просто называется в нашей эфемерной голове. На самом деле, если мы говорим строго математически,
[01:09:24.320 --> 01:09:35.520]  это последовательность символов, каждый из элементов которых получается заменой одного символа из множества нетерминалов на правую часть вывода грамматики.
[01:09:35.520 --> 01:09:45.920]  То есть это цепочка раскрытия наших штопоров. Заменили один нетерминал на последовательность терминалов нетерминалов.
[01:09:45.920 --> 01:09:55.120]  Просто для контекста свободной грамматики мы можем это явно представить в виде дерева. И этим мы с вами будем пользоваться.
[01:09:55.120 --> 01:10:03.680]  Я подчеркну этот момент, потому что на экзамене обычно говорят, ну дерево вывода это дерево. Но это неправда.
[01:10:04.640 --> 01:10:11.840]  Это очень сильная абстракция, которую мы подгоняем, просто чтобы нам было удобно.
[01:10:11.840 --> 01:10:13.840]  Да, именно так.
[01:10:13.840 --> 01:10:30.560]  Я согласен, я сам биоинформатик, поэтому я скажу это. И поэтому, чтобы у нас всегда было понимание, как мы раскрываем наши правила, это будет важно для парсеров.
[01:10:31.200 --> 01:10:33.200]  Да?
[01:10:37.200 --> 01:10:43.200]  Да, бамбук. Просто мы этот бамбук можем представить в виде вот этого.
[01:10:51.200 --> 01:10:53.200]  Нет.
[01:10:55.200 --> 01:10:57.200]  Взяли какой-то конкретный...
[01:11:01.200 --> 01:11:07.200]  Для контекста свободной грамматики это дерево, а для каких-то странах грамматика это дерево.
[01:11:07.200 --> 01:11:13.200]  Ну да, для каких-то грамматика он вообще может быть отциклическим графом, каким-то сложным.
[01:11:13.200 --> 01:11:15.200]  Вы это имеете в виду?
[01:11:15.200 --> 01:11:19.200]  Нет, я имею в виду, смотрите, пример.
[01:11:19.200 --> 01:11:25.200]  Давайте рассмотрим пример вот такой грамматики. Asb и sv.
[01:11:25.840 --> 01:11:31.840]  Собственно, как выводить слово abab?
[01:11:31.840 --> 01:11:49.840]  Значит, для вывода у нас получается, смотрите, если мы пишем цепочку выводов, то это будет asb, aasbb, aabb, то есть вот это бамбук у нас.
[01:11:50.480 --> 01:11:54.480]  Но если мы попробуем это представить в виде дерева красивого...
[01:12:10.480 --> 01:12:14.480]  Так, смотрите, что у нас получается.
[01:12:15.120 --> 01:12:17.120]  У нас получается следующее, смотрите, как это будет.
[01:12:17.120 --> 01:12:19.120]  s.
[01:12:19.120 --> 01:12:21.120]  Дальше мы это раскрываем.
[01:12:29.120 --> 01:12:31.120]  Во.
[01:12:31.120 --> 01:12:35.120]  Тут есть большой вопрос. Зачем это вообще делать?
[01:12:35.120 --> 01:12:37.120]  Для практиков это надо.
[01:12:37.120 --> 01:12:41.120]  Ну просто мы написали не меньше текста, чем линейные.
[01:12:41.120 --> 01:12:49.760]  Да, но просто вот этот вот вывод будет намного сложнее воспринимать, чем посмотреть на вот эту картинку.
[01:13:11.760 --> 01:13:13.760]  Ну да.
[01:13:21.760 --> 01:13:25.760]  Встретились с математикой практик, называется.
[01:13:27.760 --> 01:13:29.760]  Так, ладно.
[01:13:29.760 --> 01:13:31.760]  Давайте я продолжу.
[01:13:31.760 --> 01:13:33.760]  Значит, вообще...
[01:13:34.400 --> 01:13:36.400]  Да, давайте в куларах обсудим.
[01:13:36.400 --> 01:13:44.400]  Значит, смотрите, для того, чтобы зафиксировать порядок, существует такое понятие, как правосторонний и левосторонний вывод.
[01:13:44.400 --> 01:13:46.400]  Что означает левосторонний вывод?
[01:13:46.400 --> 01:13:50.400]  Это означает, что мы всегда заменяем самый левый не терминал.
[01:13:50.400 --> 01:13:56.400]  Правосторонний вывод означает, что мы всегда заменяем самый правый не терминал.
[01:13:57.040 --> 01:14:01.040]  С точки зрения визуала дерева, это никак не влияет.
[01:14:01.040 --> 01:14:07.040]  Но с точки зрения последовательности вот этих вот символов, которые у нас, они будут... цепочка у нас будет меняться.
[01:14:07.040 --> 01:14:09.040]  Нет.
[01:14:09.040 --> 01:14:13.040]  Для одного и того же самого слова, визуал дерева не поменяется.
[01:14:13.040 --> 01:14:17.040]  Ну, вы решаете просто, когда какую гроздь раскрыть.
[01:14:17.040 --> 01:14:19.040]  Нет.
[01:14:19.040 --> 01:14:23.040]  Для одного и того же самого слова, визуал дерева не поменяется.
[01:14:23.680 --> 01:14:27.680]  Ну, вы решаете просто, когда какую гроздь раскрыть.
[01:14:27.680 --> 01:14:31.680]  Итоговый результат будет точно такой же.
[01:14:31.680 --> 01:14:33.680]  Да.
[01:14:33.680 --> 01:14:35.680]  Образно.
[01:14:35.680 --> 01:14:39.680]  Нет.
[01:14:43.680 --> 01:14:51.680]  Допустим, у нас вот такая вот грамматика, и мы с вами хотим, не знаю, S раскрыть A.
[01:14:52.320 --> 01:14:54.320]  Что у нас получается?
[01:14:54.320 --> 01:15:02.320]  Да, ну смотрите, если мы визуал, нам все равно это надо будет раскрыть в A.
[01:15:02.320 --> 01:15:04.320]  И вот это надо будет раскрыть в A.
[01:15:04.320 --> 01:15:06.320]  Просто последствия действия у нас будут другие.
[01:15:08.320 --> 01:15:10.320]  Да.
[01:15:10.320 --> 01:15:12.320]  Ну, смотрите, что у нас получается.
[01:15:12.960 --> 01:15:20.960]  В стороннем выводе у нас будет вывод A, S, S, B, A, S, A, B, A, A, A, B.
[01:15:20.960 --> 01:15:28.960]  А в левостороннем выводе у нас будет A, S, S, B, A, A, S, B.
[01:15:32.960 --> 01:15:34.960]  Да, я...
[01:15:34.960 --> 01:15:36.960]  Да, да, да.
[01:15:36.960 --> 01:15:38.960]  Тут уже другое.
[01:15:42.960 --> 01:15:46.960]  Поэтому всегда, когда хотят проверить однозначность,
[01:15:46.960 --> 01:15:50.960]  хотят понять, а какое именно дерево вывода мы фиксируем.
[01:15:50.960 --> 01:15:52.960]  Последствия вывода фиксируем левостороннее или правостороннее.
[01:15:52.960 --> 01:15:58.960]  И поэтому KS-грамматика называется однозначной,
[01:15:58.960 --> 01:16:04.960]  если для каждого слова W существует ровно одно правостороннее дерево вывода.
[01:16:04.960 --> 01:16:08.960]  Правда ли, что если мы объединем как ровно одно левостороннее, то будет...
[01:16:08.960 --> 01:16:10.960]  Да, да.
[01:16:11.600 --> 01:16:13.600]  Фиксировано.
[01:16:13.600 --> 01:16:17.600]  Вот, и спрашивается, любое ли контекса свободный язык можно задать однозначной грамматикой.
[01:16:19.600 --> 01:16:21.600]  Ответ нет.
[01:16:23.600 --> 01:16:27.600]  Ответ нет, потому что существует вот такой вот замечательный язык.
[01:16:27.600 --> 01:16:29.600]  Только это существенный неоднозначный язык.
[01:16:29.600 --> 01:16:35.600]  То есть, для вот этого языка, A, V, N, B, V, M, T, C, K, T,
[01:16:35.600 --> 01:16:37.600]  у нас либо N равняется M,
[01:16:38.240 --> 01:16:40.240]  либо M равняется K.
[01:16:40.240 --> 01:16:42.240]  Нельзя построить однозначную грамматику.
[01:16:50.240 --> 01:16:52.240]  На самом деле, тяжело понять,
[01:16:52.240 --> 01:16:58.240]  как определение однозначности реально согласует с деревьями.
[01:17:00.240 --> 01:17:02.240]  Согласует с деревьями так.
[01:17:04.240 --> 01:17:06.240]  Сейчас давайте пример тогда.
[01:17:06.880 --> 01:17:10.880]  Ну что ж, все равно, когда фиксируем дерево ровно одностороннее,
[01:17:10.880 --> 01:17:12.880]  однозначно фиксируем, откуда мы должны объединять его.
[01:17:12.880 --> 01:17:14.880]  Так.
[01:17:14.880 --> 01:17:16.880]  Пример.
[01:17:16.880 --> 01:17:18.880]  Что это такое у нас?
[01:17:18.880 --> 01:17:20.880]  Узнаете, товарищи?
[01:17:22.880 --> 01:17:24.880]  Правильные скобочные последовательности?
[01:17:24.880 --> 01:17:26.880]  Ну, да.
[01:17:26.880 --> 01:17:28.880]  Ну, давайте какой-нибудь зададим неоднозначность.
[01:17:30.880 --> 01:17:32.880]  Вы знаете, что правильные скобочные последовательности,
[01:17:32.880 --> 01:17:34.880]  они неоднозначно разбираются.
[01:17:35.520 --> 01:17:37.520]  Вот именно такой грамматикой.
[01:17:39.520 --> 01:17:41.520]  Ну вот такой.
[01:17:43.520 --> 01:17:45.520]  Вот для такой грамматики
[01:17:45.520 --> 01:17:47.520]  с однозначностью уже будет
[01:17:47.520 --> 01:17:49.520]  получше.
[01:18:01.520 --> 01:18:03.520]  А так, и что?
[01:18:05.520 --> 01:18:07.520]  А можем вывести
[01:18:07.520 --> 01:18:09.520]  АСС
[01:18:09.520 --> 01:18:11.520]  и отсюда
[01:18:11.520 --> 01:18:13.520]  АСБ
[01:18:13.520 --> 01:18:15.520]  и отсюда
[01:18:15.520 --> 01:18:17.520]  АВ.
[01:18:17.520 --> 01:18:19.520]  Вот, видите, у нас два визуально
[01:18:19.520 --> 01:18:21.520]  дерева разных.
[01:18:21.520 --> 01:18:23.520]  Даже несмотря на то, что
[01:18:23.520 --> 01:18:25.520]  если мы здесь будем одновременно раскрывать
[01:18:25.520 --> 01:18:27.520]  самый левый не терминал.
[01:18:35.520 --> 01:18:37.520]  Не типа того.
[01:18:37.520 --> 01:18:39.520]  Вот, поэтому, значит,
[01:18:39.520 --> 01:18:41.520]  вот этот язык, он
[01:18:41.520 --> 01:18:43.520]  является существенно неоднозначным.
[01:18:47.520 --> 01:18:49.520]  Да.
[01:18:49.520 --> 01:18:51.520]  Да.
[01:18:51.520 --> 01:18:53.520]  Называется.
[01:18:59.520 --> 01:19:01.520]  Так.
[01:19:01.520 --> 01:19:03.520]  Хорошо.
[01:19:04.160 --> 01:19:06.160]  И еще один факт,
[01:19:06.160 --> 01:19:08.160]  который я быстренько хочу рассказать.
[01:19:08.160 --> 01:19:10.160]  Вот совсем быстренько.
[01:19:10.160 --> 01:19:12.160]  Давайте подумаем,
[01:19:12.160 --> 01:19:14.160]  относительно каких операций
[01:19:14.160 --> 01:19:16.160]  замкнуты контекст
[01:19:16.160 --> 01:19:18.160]  свободной грамматики.
[01:19:18.160 --> 01:19:20.160]  Утверждение, которое мы
[01:19:20.160 --> 01:19:22.160]  хотим доказать сейчас, что контекст
[01:19:22.160 --> 01:19:24.160]  свободной грамматики...
[01:19:24.160 --> 01:19:26.160]  Почему на презентации язык
[01:19:26.160 --> 01:19:28.160]  А, Н, Б, М, Ц, К
[01:19:28.160 --> 01:19:30.160]  подсчитан как неоднозначный?
[01:19:30.160 --> 01:19:32.160]  Потому что
[01:19:32.800 --> 01:19:34.800]  это... кто-то...
[01:19:34.800 --> 01:19:36.800]  кто-то...
[01:19:38.800 --> 01:19:40.800]  Это...
[01:19:40.800 --> 01:19:42.800]  Хотите проект-диплом...
[01:19:42.800 --> 01:19:44.800]  Хотите проект-дипломной работы?
[01:19:44.800 --> 01:19:46.800]  Написать фреймворк для юни-тестирования ладьих презентаций?
[01:19:48.800 --> 01:19:50.800]  А как же вы еще не написали?
[01:19:50.800 --> 01:19:52.800]  Ну, вот...
[01:19:52.800 --> 01:19:54.800]  Не...
[01:19:54.800 --> 01:19:56.800]  Покрытие, а вы презентации дипестируете.
[01:19:56.800 --> 01:19:58.800]  Да...
[01:19:58.800 --> 01:20:00.800]  Остаток. Утверждение,
[01:20:01.440 --> 01:20:03.440]  что на самом деле тоже нет в презентации.
[01:20:03.440 --> 01:20:05.440]  КС языки
[01:20:07.440 --> 01:20:09.440]  замкнуты
[01:20:11.440 --> 01:20:13.440]  относительно
[01:20:15.440 --> 01:20:17.440]  первое объединение,
[01:20:23.440 --> 01:20:25.440]  второе конкатинация,
[01:20:26.080 --> 01:20:28.080]  а этого на слайдах нет.
[01:20:32.080 --> 01:20:34.080]  Да, я просто вспомнил,
[01:20:34.080 --> 01:20:36.080]  что обычно это в программе есть,
[01:20:36.080 --> 01:20:38.080]  но на слайдах этого нет.
[01:20:38.080 --> 01:20:40.080]  А контексты свободной языки
[01:20:40.080 --> 01:20:42.080]  замкнуты относительно
[01:20:42.080 --> 01:20:44.080]  первое объединение,
[01:20:44.080 --> 01:20:46.080]  второе конкатинация,
[01:20:46.080 --> 01:20:48.080]  третья итерация к линии.
[01:20:56.080 --> 01:20:58.080]  Отверждение.
[01:20:58.080 --> 01:21:00.080]  Мы это докажем за две минуты.
[01:21:12.080 --> 01:21:14.080]  Так, давайте объединение начнем.
[01:21:18.080 --> 01:21:20.080]  Языки.
[01:21:26.080 --> 01:21:28.080]  Поехали.
[01:21:28.080 --> 01:21:30.080]  Объединение.
[01:21:52.080 --> 01:21:54.080]  То есть мы идем либо в одну, либо в другую.
[01:21:56.080 --> 01:21:58.080]  Но не из этой или из этой.
[01:21:58.080 --> 01:22:00.080]  Конкатинация.
[01:22:04.080 --> 01:22:06.080]  Вначале будем в первую часть,
[01:22:06.080 --> 01:22:08.080]  потом в вторую часть.
[01:22:14.080 --> 01:22:16.080]  Лучше так.
[01:22:16.080 --> 01:22:18.080]  Из этой?
[01:22:18.080 --> 01:22:20.080]  Из этой.
[01:22:20.080 --> 01:22:22.080]  Больше однозначности появляется.
[01:22:26.080 --> 01:22:30.080]  Так С1 же будет в целом то же самое?
[01:22:30.080 --> 01:22:32.080]  Ну в целом да.
[01:22:32.080 --> 01:22:34.080]  С1 это изначально?
[01:22:34.080 --> 01:22:36.080]  Да, просто эта грамматика будет более однозначно, так сказать.
[01:22:36.080 --> 01:22:38.080]  Если...
[01:22:38.080 --> 01:22:40.080]  А с точки зрения...
[01:22:40.080 --> 01:22:42.080]  С точки зрения распознавания...
[01:22:42.080 --> 01:22:44.080]  Да-да-да.
[01:22:46.080 --> 01:22:48.080]  Так, что, мы успели за две минуты?
[01:22:48.080 --> 01:22:50.080]  Время еще не вышло.
[01:22:50.080 --> 01:22:52.080]  Ну все.
[01:22:52.080 --> 01:22:54.080]  Мы справились за 1 минуту.
[01:22:54.720 --> 01:22:56.720]  Все, отлично.
[01:22:56.720 --> 01:22:58.720]  Ну все, давайте на этом закончим.
[01:22:58.720 --> 01:23:00.720]  Тогда в следующий раз мы будем упрощать нашу грамматику
[01:23:00.720 --> 01:23:02.720]  вот к такому вот замечательному виду.
[01:23:02.720 --> 01:23:04.720]  Собственно, определение
[01:23:04.720 --> 01:23:06.720]  вот этой панормальной формы мы дадим.
[01:23:06.720 --> 01:23:08.720]  И сделаем алгоритм приведения
[01:23:08.720 --> 01:23:10.720]  к этой нормальной форме.
[01:23:10.720 --> 01:23:12.720]  То есть у нас презентация получилась в чечне?
[01:23:12.720 --> 01:23:14.720]  Ну оно всегда так идет.
[01:23:14.720 --> 01:23:16.720]  Всегда по-разному.
[01:23:16.720 --> 01:23:18.720]  Все, спасибо.
