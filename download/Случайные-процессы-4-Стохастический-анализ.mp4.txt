[00:00.000 --> 00:11.800]  поехали на прошлой лекции я вел вам новое для вас важное понятие винаровский процесс и
[00:11.800 --> 00:20.320]  описал примерно откуда он берется это его еще называют броновским движением началось все с того
[00:20.320 --> 00:27.120]  что если мы наблюдаем частицу в жидкости мелкую и будем следить за ее координатом это мы увидим
[00:27.120 --> 00:32.160]  что она как бы трясется да то есть координат представляет собой некий случайный процесс вот
[00:32.160 --> 00:39.320]  броновский процесс броновского движения левинарский процесс этот модель для описания движения такой
[00:39.320 --> 00:46.120]  частицы и движение этой частицы обусловлено тем что на нее то и дело со всех сторон давит молекулы
[00:46.120 --> 00:52.920]  соударяются в очень малом промежутке времени на нее воздействует огромное число молекул и
[00:52.920 --> 00:58.560]  движение определяется именно этим и это можно формализовать вот этот факт то что
[00:58.560 --> 01:07.000]  винарский процесс получается как сумма большого числа вот этих соударений вот и я хочу вам сейчас
[01:07.000 --> 01:13.840]  привести доказать теорему о связи винарского процесса и процесса случайных блужданий то есть
[01:13.840 --> 01:28.960]  сумма так теорема которая говорит следующим значит пусть случайные величины кси 1 и так
[01:28.960 --> 01:40.360]  далее кси n ну и так далее независимые совокупности вот математическое ожидание
[01:40.360 --> 01:48.580]  существует равно нулю и сперсия у них тоже существует и равна некоторой сигме квадрат
[01:48.580 --> 01:54.600]  который будем считать одинаковый для всех этих случайных величин вот тогда
[01:54.600 --> 02:00.920]  тогда
[02:00.920 --> 02:18.320]  конечномерные распределение процесса вот такого xnt равняется единице разделить на
[02:18.320 --> 02:28.820]  sigma корень из n сумма по х от единицы до целой части nt т у нас не обязательно целая да но
[02:28.820 --> 02:38.120]  вот есть до целой части nt кси катах то конечномерные распределения вот такого процесса поточечно
[02:38.120 --> 02:56.680]  сходятся к соответствующим конечномерным распределениям винарского процесса вот
[02:56.680 --> 03:04.760]  но пояснение вот можно картинку такую нарисовать почему этот мы так это интерпретируем что это
[03:04.760 --> 03:12.520]  некие случайные блуждания суммы соударения легко посмотреть на это так возьмем t равная единице
[03:12.520 --> 03:19.480]  т у нас целая и тогда целая часть nt это просто n ну просто для простоты понимания вот единицу
[03:19.480 --> 03:28.720]  возьмем здесь у нас t направлено единицы тогда если n равняется единичке то здесь стоит 1 разделить
[03:28.720 --> 03:40.720]  на сигму кси 1 вот ну давайте для простоты также считать что наши кси они ну скажем принимают
[03:40.720 --> 03:46.440]  значение только плюс минус сигма здесь-то на самом деле не обязательно это какие-то плюс-минус
[03:46.440 --> 03:50.840]  чего-то да здесь это могут быть самые разные случайные величины лишь бы мы от ожидания было
[03:50.840 --> 03:59.480]  ноль а дисперсия была сигма в квадрате вот ну допустим что это так может быть некоторые постоянные
[03:59.480 --> 04:05.560]  там к сигма ну так вот она надо только чтобы дисперсия была равно сигме ну и вот тогда здесь
[04:05.560 --> 04:12.680]  получается сигма кси 1 разделить на сигму вот и значение процесса в точке 1 если здесь он был
[04:12.680 --> 04:19.440]  ноль это будет определяться только одной случайной величиной вот одна молекула ударила все значение
[04:19.440 --> 04:27.160]  в этот момент времени вот такое если мы рассмотрим n равняется двойке то тогда смотрите при t равном
[04:27.160 --> 04:35.280]  1 при t равном 1 n равно 2 и здесь уже сумма двух случайных величин вот с теми же самыми
[04:35.280 --> 04:42.080]  распределениями но они поделятся правда еще на корень из n так что значение процесса в момент
[04:42.080 --> 04:47.680]  1 будет уже суммой двух случайных величин ну скажем вот это у нас поднималась мы берем ту же
[04:47.680 --> 04:55.840]  самую кси 1 но теперь мы ее поделим на корень из два вот она опустится вот и нужно прибавить еще
[04:55.840 --> 05:00.800]  следующую случайную величину которая у нас не было до этого но допустим она падает да падает на
[05:00.800 --> 05:07.520]  какую-то величину можно она даже даже пусть она даже попала в эту единицу вот это у нас было при
[05:07.520 --> 05:14.080]  n равном 1 это у нас было при n равном 2 мы n увеличили добавили одну случайную величину понизили
[05:14.080 --> 05:19.060]  как бы силу каждой случайной величины, умножили на один делить на корень из 2, и
[05:19.060 --> 05:25.520]  поэтому у нас здесь они немножечко сильнее прижались к нулю, но их стало больше на одну,
[05:25.520 --> 05:30.580]  теперь у нас здесь две случайных величины, здесь была прямая, здесь уже вот два, здесь
[05:30.580 --> 05:35.780]  был один отрезок, здесь уже два отрезка. Теперь если мы возьмем n равное 3, то здесь будет уже
[05:35.780 --> 05:40.420]  сумма трех случайных величин делиться будет на корень из 3, то есть мы должны сильнее ужать,
[05:40.420 --> 05:44.460]  но у нас будет больше случайных величин. Это у нас поднималось, это у нас опускалось,
[05:44.460 --> 05:49.180]  так сейчас, только не до половины, а до трети. Это поднималось, это опускалось,
[05:49.180 --> 05:54.860]  следующее, допустим, тоже поднимется. Вот. Это уже n равное 3. Ну и так далее. И в
[05:54.860 --> 06:01.860]  пределе это будет какая-то кривая. Вот. И оказывается, что эти кривые это
[06:01.860 --> 06:05.880]  реализация некоторого процесса предельного, у которого, конечно, мерное
[06:05.880 --> 06:09.260]  распределение совпадает с Винерским процессом. То есть, это будет Винерский процесс.
[06:09.260 --> 06:17.180]  Вот такое вот пояснение к тому, что здесь написано. То есть, как мы видим, мы можем в
[06:17.180 --> 06:22.220]  смысле вот этой сходимости приближать Винерский процесс вот такими процессами,
[06:22.220 --> 06:30.460]  как сумма независимых одинаково распределенных случайных величин с такими характеристиками.
[06:30.460 --> 06:43.700]  Доказательства. Доказательства будем проводить так. Ну давайте введем, во-первых, обозначение нам
[06:43.700 --> 06:53.260]  полезное. Сn мы будем обозначать сумму k равным от единицы до n кс. Вот. И докажем, что сначала
[06:53.260 --> 07:00.340]  докажем, что одномерное распределение xn сходится к одномерному распределению v от t. Вот.
[07:00.340 --> 07:08.260]  То есть, докажем, что единица разделить на sigma корень из n, сумма k равным от единицы до n,
[07:08.260 --> 07:20.300]  t и kt входится по распределению при н, стремящемся к бесконечности, к vt. То есть, случайно в величине
[07:20.300 --> 07:27.140]  с распределением v от t. А она распределена как n0t. Вот. Если мы это докажем, то мы докажем
[07:27.140 --> 07:33.740]  сходимость одномерных распределений. Мы взяли сечение. Мы зафиксировали t. Взяли
[07:33.740 --> 07:39.380]  сечение xnt. Это вот эта случайная величина. И показываем, что она сходится к соответствующему
[07:39.380 --> 07:45.540]  сечению, тот же самый момент t, для винорского процесса. Вот это нам предстоит доказать сейчас.
[07:45.540 --> 07:52.580]  И тогда мы докажем, что одномерное распределение этого сходится к одномерным распределениям того.
[07:52.580 --> 07:59.220]  И чтобы это доказать, нам нужно действовать так же, как мы доказываем центральную предельную
[07:59.220 --> 08:05.860]  теорему. То есть, вспомнить о том, что сходимость по распределению равносильна по точечной всюду
[08:05.860 --> 08:12.100]  сходимости характеристических функций. То есть, мы запишем char функцию вот этой вещи и докажем,
[08:12.100 --> 08:17.180]  что она по точечной сходится к char функции вот этой случайной величины. Тогда это будет означать,
[08:17.180 --> 08:24.380]  по теореме неперерывности, что сходимость по распределению имеет место. Ну вот, мы пишем тогда
[08:24.380 --> 08:33.220]  характеристическую функцию. Вот тут я ввел обозначение, поэтому я сокращу. S целая часть nt,
[08:33.220 --> 08:40.620]  а t с маленькой. Это аргумент характеристической функции. Значит, что это такое по определению?
[08:40.620 --> 08:51.460]  Математическое ожидание i s и умножить на единицу разделить на корень из n фигма. И тут у нас,
[08:51.460 --> 09:02.220]  ну давайте мы так напишем, я распишу x1 плюс и так далее, плюс x целая часть nt. Но экспонент,
[09:02.220 --> 09:08.460]  а сейчас, и тут экспоненту я забыл, экспонента, экспонент от всего этого. Значит, экспонента от
[09:08.500 --> 09:14.680]  суммы равна всегда произведению экспонента. Мат ожидания произведения не всегда равно
[09:14.680 --> 09:21.040]  произведению мат ожиданий. Но у нас случайный величины ks независимо в совокупности по нашему
[09:21.040 --> 09:28.860]  предположению. Поэтому и функции от этих кси тоже независимы, а значит, математическое ожидание
[09:28.860 --> 09:34.380]  произведений этих функций равно произведению математических ожиданий, этих функций. Ну,
[09:34.380 --> 09:42.600]  ну давайте я наверху продолжу значит получается произведение по g равном от единицы до nt
[09:42.600 --> 09:51.380]  математических ожиданий экспонента от значит i s 1 разделить на корень z sigma
[09:51.380 --> 10:00.540]  на x jt вот а это есть характеристическая функция вот этой случайной величины
[10:00.540 --> 10:07.900]  вот в этой точке s разделить на корень z sigma вот то есть произведение g равном
[10:07.900 --> 10:17.740]  от единицы до n характеристическая функция x jt значит от чего точки s разделить на корень
[10:17.740 --> 10:29.620]  z sigma дальше так как у этой случайной величины существует математическое ожидание дисперсия
[10:29.620 --> 10:37.140]  это значит что мы можем записать такую вещь мы можем представить функцию фи приблизить функцию
[10:37.140 --> 10:45.460]  фи в окрестности s равняется 0 формулой т лора вот это получается единица так как
[10:45.460 --> 10:51.700]  математическое ожидание равно нулю поэтому слагаемого пропорционального и умножающегося
[10:51.700 --> 10:58.380]  на есть здесь не будет поэтому пишем минус и минус потому что мимо единицы в квадрате умножить
[10:58.380 --> 11:09.020]  на дисперсию полам то есть на s в квадрате разделить на 2 n sigma в квадрате да
[11:13.020 --> 11:24.540]  ой здесь dnt спасибо спасибо вот n значит здесь умалое умалое и здесь в степени а в какой а не
[11:24.540 --> 11:33.020]  в какой вот произведение мы берем произведение вот таких штук вот произведение таких штук они
[11:33.020 --> 11:38.820]  все одинаково распределены поэтому вот эта внутренняя часть она джи не зависит так что по
[11:38.820 --> 11:47.460]  сути здесь написано просто 1 минус s в квадрате разделить на 2 n sigma в квадрате плюс умалое от
[11:47.460 --> 11:58.020]  1 разделить на n в степени целой части nt вот так и нам остается устремить только n к бесконечности и
[11:58.020 --> 12:04.780]  посмотреть к чему это сходится но прежде чем это делать давайте мы так поступим мы внутреннюю
[12:04.780 --> 12:14.060]  часть возведем в степень n а внешнюю часть в 1 делить на n тогда мы получим тогда мы
[12:14.060 --> 12:22.780]  получим 1 минус s в квадрате разделить на 2 n sigma в квадрате плюс умалое 1 разделить на n
[12:22.780 --> 12:30.940]  все это в степени n и вот они фигу квадратную не надо а то будете думать что это целая часть
[12:30.940 --> 12:43.260]  пусть будет круглая вот это в степени nt разделить на n но вот ну и к чему тоже все сходится значит
[12:43.260 --> 12:49.820]  по теоремам изматонализа мы знаем что внутренняя часть вот это при n стремящимся к бесконечности
[12:49.820 --> 13:07.820]  сходится к е степени минус s в квадрате так сейчас это мне не нравится или все нормально
[13:07.820 --> 13:11.380]  так
[13:11.380 --> 13:22.460]  ну допустим значит все это сходится к е степени с квадрата разделить на 2 sigma в квадрате вот так
[13:22.460 --> 13:32.260]  так а к чему сходится вот эта вещь значит мы можем написать числитель как просто nt без всяких
[13:32.260 --> 13:41.820]  скобок минус дробная часть nt и разделить на n и тогда у нас получится просто t минус дробная часть
[13:41.820 --> 13:50.100]  nt деленная на n и мы видим что если n стремится к бесконечности то так как вот это ограничено
[13:50.100 --> 13:56.820]  оно принадлежит от нуля до единицы то деление на n делает ее бесконечно малой так что это
[13:56.820 --> 14:06.380]  стремится к нулю а t это t так что получается что все это сходится вот sigma квадрат мне осталось
[14:06.380 --> 14:20.860]  вот это странно ну ладно значит это все сходится к е степени минус s в квадрате разделить давайте так
[14:20.860 --> 14:38.620]  s квадрат t разделить на 2 sigma в квадрате вот sigma квадрат да так ну это характеристическая
[14:38.620 --> 14:50.100]  функция какой случайной величины нормальный с параметрами 0 t разделить на sigma квадрата
[14:50.100 --> 15:00.020]  получается разделить на sigma квадрат что не очень хорошо она тут нужно 0 t ну значит так здесь
[15:00.020 --> 15:05.900]  мы получаем видимо да если это sigma это будет сходимый с ним к винарскому процессу а к винарскому
[15:05.900 --> 15:11.820]  процессу с параметром sigma квадрат то есть когда там распределение это 0 запятая sigma в квадрате
[15:11.820 --> 15:33.420]  модуль t-s вот ну а чужую меня сейчас одну секунду а нет нет нет подождите меня есть ошибка так меня
[15:33.420 --> 15:41.260]  ошибка что я тут делаю я раскладываю по формуле t лора так мото ожидание у меня равно 0 там как
[15:41.860 --> 15:51.940]  и в квадрате на второй момент а стоп а я вторым момент забыл у меня здесь стоит квадрат
[15:51.940 --> 15:59.540]  с в квадрате n sigma квадрат двойку а второго момента у меня здесь нет вот а вы молчите второго
[15:59.540 --> 16:08.860]  момента у меня здесь нет значит второй момент тигмы это получается sigma квадрате то есть
[16:08.860 --> 16:14.460]  мотожадание кси в квадрате это дисперсия плюс квадрат мотожадания, который равен нулю.
[16:14.460 --> 16:22.860]  Да, вот здесь сигма в квадрате, я забыл. Я забыл здесь сигму в квадрате. Второй момент. Так что на самом
[16:22.860 --> 16:31.700]  деле сигма в квадрате сокращаются и здесь тоже сигма в квадрате не будет. Вот. И здесь тоже сигма в
[16:31.700 --> 16:38.420]  квадрат не будет. И здесь тоже сигма в квадрат не будет. Вот. И здесь тоже сигма в квадрат не
[16:38.420 --> 16:44.500]  будет. Сигма сокращается. Неважно какая сигма, она сокращается. Ну вот. А это характеристическая
[16:44.500 --> 16:52.140]  функция случайной величины вот с таким распределением. И точно такое же распределение
[16:52.140 --> 17:00.460]  имеет w от t. Все. Значит мы показали, что хр функция этой штуки сходится к хр функции этой штуки. Вот.
[17:00.460 --> 17:05.380]  А это означает это равносильно, потому что эта штука сходится по распределению к этой
[17:05.380 --> 17:10.700]  штуке. Вот. А это есть одномерное распределение процесса х, это есть
[17:10.700 --> 17:16.820]  одномерное распределение процесса Винеровского. Так что сходимость одномерных распределений
[17:16.820 --> 17:25.180]  мы таким образом показали. Вот. Все. Это что касается одномерного распределения. Теперь давайте
[17:25.180 --> 17:26.300]  рассмотрим двумерные распределения.
[17:30.460 --> 17:37.960]  Для того, чтобы показать сходимость для двумерного
[17:37.960 --> 17:41.800]  распределения, нам понадобится один факт, который я доказывать
[17:41.800 --> 17:42.800]  не буду.
[17:42.800 --> 17:51.860]  Он заключается в следующем, что если xn-вектор, заставленный
[17:51.860 --> 17:56.560]  из двух последовательностей, xn-это n, если вот эта штука
[17:56.560 --> 18:02.400]  сходится по распределению при n, стремящемся к бесконечности,
[18:02.400 --> 18:15.840]  к xi-это, то тогда отсюда следует, что xn-это n плюс xn сходится
[18:15.840 --> 18:19.280]  по распределению при n, стремящемся к бесконечности,
[18:19.280 --> 18:23.120]  к xi-это плюс xi.
[18:23.120 --> 18:28.000]  Вот этим фактом мы воспользуемся, его можно найти, например,
[18:28.000 --> 18:44.000]  в книжке Billings-Lee, Вероятностных мер, очень хорошая книжка
[18:44.000 --> 18:46.920]  глубокая, которая изучает, в частности, Винерский
[18:46.920 --> 18:50.880]  процесс, советую туда посмотреть, но вот этим фактом мы просто
[18:50.880 --> 18:51.880]  воспользуемся здесь.
[18:52.880 --> 18:58.640]  Это очень технический факт, он нам нигде не пригодится,
[18:58.640 --> 19:02.400]  кроме этой теоремы, поэтому мы его возьмем без доказательства.
[19:02.400 --> 19:07.240]  Одно из свойств сходимости по распределению.
[19:07.240 --> 19:19.280]  Так, ну вот и как мы его применим, а очень просто,
[19:19.280 --> 19:29.320]  для того, чтобы доказать, что вот эта вещь сходится
[19:29.320 --> 19:44.160]  к v от t, v от s, нам достаточно, нам достаточно доказать,
[19:44.160 --> 19:52.480]  что это будет следовать из того, что xc на t, ну давайте
[19:52.480 --> 20:01.600]  возьмем t больше s, допустим, что вот эта штука сходится
[20:01.600 --> 20:17.040]  как v от t на v от t минус v от s, чтобы просумировать.
[20:17.040 --> 20:24.640]  Вот, при t больше, значит, если t больше s, то, так,
[20:24.640 --> 20:34.680]  сейчас, а что тут у меня, все напутал, прошу прощения,
[20:34.680 --> 20:37.360]  при t больше s рассматриваем.
[20:37.360 --> 20:43.400]  Итак, если мы докажем вот это, то по вот этому факту
[20:43.400 --> 20:46.480]  отсюда будет следовать вот это.
[20:46.480 --> 20:47.720]  Почему мы так делаем?
[20:47.720 --> 20:52.360]  Потому что трудно понять, какое совместное распределение
[20:52.360 --> 20:57.800]  имеют эти x, чтобы исследовать на сходимость по распределению.
[20:57.800 --> 21:01.720]  И здесь тоже они зависимы, эти случайные величины,
[21:01.720 --> 21:04.240]  поэтому какая у них там функция распределения,
[21:04.240 --> 21:05.240]  это сложно.
[21:05.240 --> 21:11.160]  А в этом случае у нас получается, при t больше s, вот эти случайные
[21:11.160 --> 21:14.160]  величины независимы, потому что процесс имеет независимые
[21:14.840 --> 21:16.720]  а это проще исследовать.
[21:16.720 --> 21:19.640]  И на самом деле, смотрите, что получается, все это очень
[21:19.640 --> 21:20.640]  просто.
[21:20.640 --> 21:28.880]  Значит, давайте рассмотрим вот эти все вещи.
[21:28.880 --> 21:33.960]  Значит, вот это, то, что здесь написано, это единица
[21:33.960 --> 21:41.400]  разделить на корень n сигма от s нt минус единица разделить
[21:41.400 --> 21:45.680]  на корень из n сигма с ns.
[21:45.680 --> 21:49.280]  И видите, множитель одинаковый.
[21:49.280 --> 21:54.920]  Здесь мы суммируем от 1 до nt, а здесь от 1 до ns, s меньше
[21:54.920 --> 21:55.920]  t.
[21:55.920 --> 22:01.920]  И поэтому куча слагаемых от 1 до ns у нас сократится.
[22:01.920 --> 22:05.720]  Так что по сути, то, что здесь написано, это есть единица
[22:05.720 --> 22:12.320]  разделить на корень из n сигма при кси от ns плюс 1 плюс
[22:12.320 --> 22:19.560]  и так далее, плюс кси nt, вот то, что здесь написано.
[22:19.560 --> 22:25.960]  А вот эта вещь, это 1 разделить на n корень из n сигма, значит
[22:25.960 --> 22:32.160]  кси 1 плюс и так далее, плюс кси ns.
[22:32.160 --> 22:37.440]  Видите, здесь мы идем до ns, а здесь ns нет, мы начинаем
[22:37.440 --> 22:38.440]  от него.
[22:38.440 --> 22:41.880]  Но случайная величина кси независима в совокупности.
[22:41.880 --> 22:45.440]  А это означает, что вот эта случайная величина и вот
[22:45.440 --> 22:49.160]  эта случайная величина, эта сумма, они независимы.
[22:49.160 --> 22:52.200]  Так что вот это и вот это независимы.
[22:52.200 --> 22:57.200]  Значит, их функции распределения разбиваются на произведение
[22:57.200 --> 23:01.600]  и характеристическая функция вот этого вектора равна
[23:01.600 --> 23:04.720]  произведению характеристических функций вот этой и умножить
[23:04.720 --> 23:07.520]  на хар-функцию вот этой вещи.
[23:07.520 --> 23:09.360]  Ну и что получается?
[23:09.360 --> 23:12.680]  Хар-функция этой вещи мы уже выяснили, что она
[23:12.680 --> 23:17.080]  сходится к хар-функции вот этой вещи.
[23:17.080 --> 23:21.440]  Хар-функция этой вещи абсолютно аналогична, выписывая все,
[23:21.440 --> 23:25.880]  что у нас было, просто с точностью до переиндексации.
[23:25.880 --> 23:28.880]  Мы приходим к тому, что хар-функция этой вещи сходится
[23:28.880 --> 23:30.720]  к хар-функции этой вещи.
[23:31.560 --> 23:34.200]  Но хар-функция всего это произведение этих двух
[23:34.200 --> 23:37.200]  хар-функций, значит, это произведение сходится
[23:37.200 --> 23:39.840]  к произведению хар-функций этих.
[23:39.840 --> 23:40.840]  Все.
[23:40.840 --> 23:41.840]  Доказано.
[23:41.840 --> 23:45.360]  Значит, раз сходится хар-функция, значит, сходится по распределению.
[23:45.360 --> 23:49.020]  А раз это выполнено, то по вот этому факту складываем
[23:49.020 --> 23:53.300]  вот эту с этим, вот эту с этим, и приходим вот к этому,
[23:53.300 --> 23:55.400]  мы доказываем вот этот факт.
[23:55.400 --> 23:56.400]  Все.
[23:56.400 --> 23:58.760]  то есть самое сложное в этой теореме это
[24:00.320 --> 24:04.640]  выписать нечто похожее на центральную предельную теоремы для одномерного распределения, а здесь уже
[24:05.800 --> 24:07.480]  элементарно получается
[24:07.480 --> 24:09.480]  точно также можно это
[24:09.680 --> 24:11.680]  выписать для
[24:11.760 --> 24:19.760]  векторов с тремя компонентами тоже через независимые приращения и для произвольного вектора размерности n
[24:21.120 --> 24:24.320]  вот то есть просто опираюсь вот на эту теорему
[24:24.320 --> 24:28.240]  вот, ну такие вот детальные выкладки для случаев
[24:28.880 --> 24:37.640]  более высокого порядка размерности я показывать не буду, мне здесь главное было вам указать некую идею, но я думаю что это будет достаточно для понимания, для доказательств
[24:38.640 --> 24:40.640]  вот, на этом теорема завершена
[24:41.840 --> 24:46.480]  свинерский процесс является в этом смысле пределом
[24:47.600 --> 24:49.600]  случайных блужданий
[24:49.920 --> 24:58.360]  случайным блужданием называется любой процессу такого вида, где стоит сумма каких-то независимых случайных величин
[25:01.480 --> 25:05.760]  винерский процесс это предел случайных блужданий, но это вот предел в одном из смысла
[25:07.120 --> 25:09.120]  конечно можно
[25:09.600 --> 25:16.960]  найти теоремы о сходимости случайных блужданий к винерскому процессу в других более сильных смыслах на
[25:17.200 --> 25:19.200]  функциональных пространствах в смысле
[25:20.160 --> 25:25.440]  некоторых метрик, ну вот у меня в лекциях в pdf как вы можете найти там ссылки
[25:26.240 --> 25:29.840]  где об этом можно почитать, как эту всю науку углубить, но это
[25:30.400 --> 25:34.920]  выходит за рамки курса, поэтому мы пожалуй остановимся только на этом
[25:36.440 --> 25:38.440]  ну вот
[25:38.960 --> 25:40.960]  вот
[25:42.080 --> 25:44.080]  ну и на этом мне
[25:44.480 --> 25:46.480]  вот эту
[25:47.200 --> 25:52.960]  ветку рассказа про гауссовский и винерский процесс хочется завершить
[25:54.080 --> 25:56.080]  вот на этой теореме
[25:56.800 --> 26:00.520]  мы с вами переходим к следующей теме
[26:04.280 --> 26:06.840]  которая называется стахастический анализ у
[26:07.640 --> 26:13.560]  вас уже было много разных видов анализа был математический анализ дискретный анализ
[26:14.880 --> 26:16.880]  функциональный анализ у
[26:17.080 --> 26:21.400]  кого-то еще выпуклый анализ но вот здесь стахастический анализ
[26:22.040 --> 26:24.160]  то есть мы будем изучать случайные процессы
[26:25.160 --> 26:27.160]  точки зрения
[26:27.720 --> 26:30.840]  пределов разных смысле то есть там будем
[26:31.600 --> 26:34.200]  изучать что такое непрерывный процесс что такое
[26:34.760 --> 26:36.480]  дифференцируемый процесс
[26:36.480 --> 26:39.480]  интегрируемые процессы в каких смыслах это можно понимать
[26:40.040 --> 26:43.200]  как выяснить является ли процесс некоторый
[26:44.200 --> 26:49.080]  непрерывным или интегрируемым как это связано с его траекториями и так далее и так далее
[26:50.280 --> 26:53.760]  вот этой темой мы сегодня в основном и займемся
[26:53.760 --> 26:55.760]  вот
[27:10.440 --> 27:14.480]  значит как я уже говорил случайные процессы это функции
[27:15.400 --> 27:17.400]  двух аргументов
[27:17.800 --> 27:19.800]  исхода и времени
[27:20.080 --> 27:26.040]  если мы хотим вести понятие непрерывности относительно времени естественно мы будем это вводить
[27:27.320 --> 27:29.320]  дифференцируемость относительно t
[27:29.360 --> 27:36.160]  там интегрируемости по t то тогда нам нужно будет что-то сказать о том как пределы
[27:36.520 --> 27:38.800]  в этих понятиях в непрерывности
[27:39.360 --> 27:42.320]  дифференцируемости интегрируемости как они связаны с этой омегой
[27:43.280 --> 27:46.480]  но вы хорошо знаете из курса теории вероятности что
[27:47.040 --> 27:48.720]  предел можно
[27:48.760 --> 27:56.160]  понимать в разных смыслах бывает предел в среднем квадратичном по вероятности почти на верное по распределению
[27:56.600 --> 27:58.600]  это все разные виды пределов
[27:59.120 --> 28:01.280]  которые по-разному относятся к этой омеге
[28:02.240 --> 28:03.640]  вот
[28:03.640 --> 28:05.640]  соответственно можно по-разному вводить
[28:06.360 --> 28:11.520]  непрерывность дифференцируемости интегрируемость можно рассмотреть понятие sk
[28:12.560 --> 28:14.320]  непрерывности
[28:14.320 --> 28:15.680]  sk
[28:15.680 --> 28:17.680]  дифференцируемости sk
[28:18.420 --> 28:23.040]  интегрируемости можно вести понятие почти на верно
[28:24.620 --> 28:27.500]  непрерывности дифференцируемости интегрируемости
[28:29.060 --> 28:31.060]  т.е. по вероятности
[28:32.500 --> 28:36.080]  непрерывности дифференцируемости интегрируемости и по распределению
[28:37.580 --> 28:39.440]  непрерывности
[28:39.440 --> 28:41.440]  дифференцируемости интегрируемости и
[28:41.440 --> 28:47.820]  И у вас в задании будет задача, где нужно будет исследовать винаровский и поассоновский процесс
[28:47.820 --> 28:52.240]  на непрерывность, дифференцируемость, интегрируемость во всех вот этих смыслах.
[28:55.660 --> 28:59.100]  Все они отличаются только тем, как они понимают предел.
[28:59.100 --> 29:03.540]  Ну вот, напомню вам определение в среднем квадратичном.
[29:03.540 --> 29:08.740]  Мы говорим, что последовательность xn сходится к x,
[29:08.740 --> 29:13.340]  в среднем квадратичном, при n, стремящемся к бесконечности,
[29:13.340 --> 29:18.040]  или еще говорят, сходимость в среднем первого порядка,
[29:18.040 --> 29:24.840]  если математическое ожидание xn-x в квадрате
[29:24.840 --> 29:28.840]  входит к нулю, при n, стремящемся к бесконечности.
[29:28.840 --> 29:32.240]  Потому что xn и xy зависят от омеги от исхода,
[29:32.240 --> 29:34.740]  но здесь мат ожидания квадрата,
[29:34.840 --> 29:36.840]  и вот эта вещь, она уже от исхода не зависит,
[29:36.840 --> 29:39.840]  это обычная числовая последовательность,
[29:39.840 --> 29:43.640]  для которой существует из мат-анализа определение предела.
[29:43.640 --> 29:45.940]  Так что мы говорим, что случайная последовательность
[29:45.940 --> 29:48.440]  сходится к этой случайной величине,
[29:48.440 --> 29:52.240]  если вот эта числовая последовательность сходится к нулю.
[29:52.240 --> 29:52.840]  Вот и все.
[29:52.840 --> 29:57.640]  Вот это определение сходимости в среднем квадратичном.
[29:57.640 --> 30:03.540]  Сразу же скажу, то есть в этом определении есть тонкость.
[30:04.440 --> 30:07.740]  В этом определении ничего не сказано о существовании
[30:07.740 --> 30:12.840]  вторых моментов отдельно для xn-го и для x.
[30:12.840 --> 30:14.440]  Обратите внимание.
[30:14.440 --> 30:20.140]  То есть это сходится сюда в sk смысле, если вот это.
[30:20.140 --> 30:25.340]  В принципе, мат ожидания квадрата не xn-го,
[30:25.340 --> 30:28.440]  ни предела x может не существовать.
[30:28.440 --> 30:30.440]  Ну, возьмите какую-нибудь случайную величину x,
[30:30.440 --> 30:33.140]  у которой второго момента не существует.
[30:33.140 --> 30:36.540]  И возьмите xn, тождественно, равный x.
[30:36.540 --> 30:39.040]  Тогда здесь будет 0 просто стоять.
[30:39.040 --> 30:42.040]  И получается, что в этом смысле последовательность сходится,
[30:42.040 --> 30:45.040]  хотя никто из них, ни у кого из них по отдельности
[30:45.040 --> 30:47.540]  мат ожидания квадрата не существует.
[30:47.540 --> 30:49.440]  Ну, вот такая вот тонкость.
[30:49.440 --> 30:51.040]  Единственное в этом определении есть.
[30:51.040 --> 30:54.740]  Правда, для того, чтобы многие теоремы доказывать,
[30:54.740 --> 30:57.240]  нам понадобится дополнительно предположить,
[30:57.240 --> 31:02.140]  что у x, иногда у xn-го существуют конечные и вторые моменты.
[31:02.140 --> 31:04.840]  Но в самом определении
[31:04.840 --> 31:09.640]  конечности вторых моментов отдельных xn-го и x-а нет.
[31:09.640 --> 31:11.540]  Вот, вот это выясните.
[31:11.540 --> 31:14.440]  Значит, цитокосический анализ мы будем строить
[31:14.440 --> 31:18.040]  на основе вот этой сходимости,
[31:18.040 --> 31:24.440]  потому что это позволит нам получить очень много критериев,
[31:24.440 --> 31:28.740]  как определить, что процесс является непрерывным, дифференцируемым, интегрированным.
[31:28.740 --> 31:31.240]  То есть много результатов это дает полезных.
[31:31.240 --> 31:34.340]  К сожалению, для этих сходимостей
[31:34.340 --> 31:37.440]  подобных результатов я не встречал.
[31:37.440 --> 31:42.040]  А здесь они существуют и элементарно доказываются.
[31:42.040 --> 31:46.640]  Так что мы сосредоточим наше внимание вот на этом типе сходимости.
[31:46.640 --> 31:52.240]  И будем строить всю нашу дальнейшую науку в основном вот здесь.
[31:52.240 --> 31:55.040]  Так, ну хорошо.
[31:55.040 --> 31:57.640]  Значит, прежде чем идти дальше,
[31:57.640 --> 32:00.540]  я хочу вам привести три леммы,
[32:00.540 --> 32:04.640]  которые нам пригодятся для доказательств следующих теорий.
[32:04.640 --> 32:05.940]  Вот.
[32:07.940 --> 32:11.940]  Лемма 1.
[32:11.940 --> 32:15.740]  Это одна из самых важных лемм в вашем курсе.
[32:15.740 --> 32:18.240]  Значит, она звучит так.
[32:18.240 --> 32:23.140]  Пусть хм сходится к х в среднем квадратичном.
[32:23.140 --> 32:26.140]  При м, стремящемся к бесконечности.
[32:26.140 --> 32:27.140]  Пусть.
[32:27.140 --> 32:32.140]  И пусть ун, я специально беру разные индексы.
[32:32.140 --> 32:34.240]  Для меня это будет потом важно.
[32:34.240 --> 32:39.240]  Это к при н, стремящемся к бесконечности, к у.
[32:39.240 --> 32:45.040]  И пусть у х
[32:45.040 --> 32:47.840]  существует конечный второй момент.
[32:47.840 --> 32:53.340]  И у у существует конечный второй момент.
[32:53.340 --> 32:56.340]  Тогда.
[32:56.340 --> 32:59.840]  Математическое ожидание.
[32:59.840 --> 33:03.440]  Хм, у, н.
[33:03.440 --> 33:06.640]  Ходится, как обычная числовая последовательность,
[33:06.640 --> 33:08.340]  потому что там от ожидания стоит.
[33:08.340 --> 33:12.440]  При м, н, стремящемся к бесконечности.
[33:12.440 --> 33:14.440]  К математическому ожиданию.
[33:14.440 --> 33:15.940]  Ху.
[33:15.940 --> 33:17.440]  Вот так.
[33:17.440 --> 33:23.940]  Причем не важно, как м и н между собой там соотносятся при стремлении к бесконечности.
[33:23.940 --> 33:28.940]  Доказательства.
[33:28.940 --> 33:32.940]  Очень простое у этой теоремы доказательство.
[33:32.940 --> 33:35.440]  Ну, немножечко техничное, но оно простое.
[33:35.440 --> 33:37.940]  Значит, хм минус х.
[33:37.940 --> 33:41.940]  Пишем ун минус у.
[33:42.440 --> 33:44.440]  Значит.
[33:44.440 --> 33:47.940]  Давайте мы рассмотрим вот такую скобку.
[33:47.940 --> 33:52.940]  Значит, что это такое будет?
[33:52.940 --> 33:56.940]  Так, это получается хм, у, н.
[33:56.940 --> 33:59.940]  Минус хм, у.
[33:59.940 --> 34:02.940]  Минус х, у, н.
[34:02.940 --> 34:05.940]  Плюс х.
[34:05.940 --> 34:08.940]  Так, и мне надо доказать, что м от ожидания вот этой штуки
[34:08.940 --> 34:13.440]  вообще сходится к м от ожидания вот этой штуки.
[34:13.440 --> 34:16.440]  Так, как мы тут поступим?
[34:16.440 --> 34:20.940]  Хм минус х.
[34:20.940 --> 34:25.940]  Давайте мы вот к этой вещи.
[34:25.940 --> 34:28.940]  Так, сейчас, сейчас, сейчас, сейчас.
[34:28.940 --> 34:30.440]  Я подумаю, что мы сделаем.
[34:30.440 --> 34:31.440]  Смотрите, как мы сделаем.
[34:31.440 --> 34:32.940]  Мы возьмем вот в этой вещи.
[34:32.940 --> 34:37.440]  Здесь напишем двойку.
[34:37.440 --> 34:42.440]  Или нет, сейчас, сейчас, сейчас.
[34:42.440 --> 34:43.940]  Я напишу так хм.
[34:43.940 --> 34:45.940]  Сейчас, дайте я сначала напишу.
[34:45.940 --> 34:47.440]  А потом вы.
[34:47.440 --> 34:51.440]  Я хочу выразить хм, у, н.
[34:51.440 --> 34:53.940]  Минус х, у.
[34:53.940 --> 34:56.940]  Через вот эту скобку и все остальное.
[34:56.940 --> 34:59.940]  Значит, тогда я получаю хм.
[34:59.940 --> 35:01.940]  Минус х.
[35:01.940 --> 35:04.940]  На у, н, минус у.
[35:04.940 --> 35:05.440]  Вот.
[35:05.440 --> 35:07.940]  И что у меня останется?
[35:07.940 --> 35:10.440]  Значит, ага.
[35:10.440 --> 35:15.940]  Я здесь, считай, вычел минус х и добавлю х.
[35:15.940 --> 35:16.940]  Давайте так.
[35:16.940 --> 35:20.440]  Минус х плюс х.
[35:20.440 --> 35:23.940]  Тогда у меня выделяется вот это и вот это.
[35:23.940 --> 35:24.440]  Вот.
[35:24.440 --> 35:28.440]  Они равны вот этому, минус все остальное.
[35:28.440 --> 35:32.940]  И я приведу слагаемые.
[35:32.940 --> 35:39.440]  Значит, здесь, здесь, здесь, здесь.
[35:39.440 --> 35:40.940]  Так.
[35:40.940 --> 35:41.940]  Значит, что это получается?
[35:41.940 --> 35:48.440]  Это получается минус или плюс, плюс, наверное.
[35:48.440 --> 35:55.440]  Значит, хм минус х на у.
[35:55.440 --> 36:02.940]  И плюс у, н, минус у на х.
[36:02.940 --> 36:03.940]  По-моему.
[36:03.940 --> 36:04.440]  Так.
[36:04.440 --> 36:05.440]  Давайте я еще раз проверю.
[36:05.440 --> 36:07.940]  Значит, вот это.
[36:07.940 --> 36:09.940]  Значит, так вот это, минус это.
[36:09.940 --> 36:11.940]  То перекидываем вправо.
[36:11.940 --> 36:15.440]  Получаем хм, у, минус х.
[36:15.440 --> 36:16.440]  У выносим.
[36:16.440 --> 36:18.440]  Здесь получается разность.
[36:18.440 --> 36:20.440]  Это идет с плюсом.
[36:20.440 --> 36:21.440]  Вот.
[36:21.440 --> 36:23.440]  И это мы переносим туда тоже.
[36:23.440 --> 36:27.440]  Получается х мы выносим, у, н, минус у.
[36:27.440 --> 36:28.440]  Да.
[36:28.440 --> 36:29.440]  Вот так.
[36:29.440 --> 36:31.440]  Получается вот так.
[36:31.440 --> 36:32.440]  Все.
[36:32.440 --> 36:33.440]  Теперь.
[36:33.440 --> 36:38.440]  Берем математическое ожидание от левой правой части.
[36:38.440 --> 36:41.440]  Пишем модуль.
[36:41.440 --> 36:49.440]  Модуль математического ожидания хм, у, н, минус ху.
[36:49.440 --> 36:53.440]  И получаем, что здесь стоит модуль математического
[36:53.440 --> 36:55.440]  ожидания того, что стоит здесь.
[36:55.440 --> 36:59.440]  А это меньше либо равно, чем математическое ожидание
[36:59.440 --> 37:03.440]  модуля от того, что стоит внутри.
[37:03.440 --> 37:05.440]  Суммы.
[37:05.440 --> 37:08.440]  Модуль суммы не превосходит суммы модулей.
[37:08.440 --> 37:09.440]  Так.
[37:09.440 --> 37:13.440]  Значит, получаем, что это меньше либо равно, чем
[37:13.440 --> 37:20.440]  Модуль математического ожидания хм, у, н, минус у.
[37:20.440 --> 37:29.440]  Плюс математическое ожидание хм, у.
[37:29.440 --> 37:38.440]  Плюс математическое ожидание у, н, минус у на х.
[37:38.440 --> 37:39.440]  Вот.
[37:39.440 --> 37:40.440]  Мел.
[37:40.440 --> 37:41.440]  Сейчас сменю.
[37:41.440 --> 37:44.440]  Ну вот.
[37:44.440 --> 37:53.440]  И теперь нам остается воспользоваться только неравенством
[37:53.440 --> 37:54.440]  Коши Буниковского.
[37:54.440 --> 37:55.440]  Мат.
[37:55.440 --> 37:59.440]  Ижидание модуля произведения не превосходит корня мат.
[37:59.440 --> 38:00.440]  Ижидания квадрата.
[38:00.440 --> 38:02.440]  Вот это умножить на квадрат вот этого.
[38:02.440 --> 38:07.440]  То есть это меньше либо равно, чем корень мат.
[38:07.440 --> 38:16.440]  Ижидание хм, у, н, минус у в квадрате.
[38:16.440 --> 38:18.440]  Корень вот такой.
[38:18.440 --> 38:20.440]  Плюс корень мат.
[38:20.440 --> 38:26.440]  Ижидание хм, у, н, минус у в квадрате.
[38:26.440 --> 38:27.440]  А, сейчас тут.
[38:27.440 --> 38:28.440]  Мат.
[38:28.440 --> 38:30.440]  Ижидание у в квадрате.
[38:30.440 --> 38:31.440]  Вот.
[38:31.440 --> 38:34.440]  И плюс корень мат.
[38:34.440 --> 38:39.440]  Ижидания у, н, минус у в квадрате.
[38:39.440 --> 38:40.440]  Мат.
[38:40.440 --> 38:41.440]  Ижидание ха в квадрате.
[38:41.440 --> 38:44.440]  Ну и вот.
[38:44.440 --> 38:49.440]  И мы устремляем м и н независимо друг от друга к бесконечности.
[38:49.440 --> 38:54.440]  Но так как хм сходится к х, то по определению вот эта
[38:54.440 --> 38:55.440]  вещь сходится к нулю.
[38:55.440 --> 38:58.440]  Эта вещь тоже сходится к нулю.
[38:58.440 --> 39:02.440]  Вот эта вещь сходится к нулю, и она умножается на
[39:02.440 --> 39:03.440]  нечто, что конечное.
[39:03.440 --> 39:08.440]  Видите, вот где мы пользуемся тем, что конечный второй
[39:08.440 --> 39:09.440]  момент.
[39:09.440 --> 39:10.440]  Вот здесь.
[39:10.440 --> 39:13.440]  То есть это конечное число, а это сходится к нулю.
[39:13.440 --> 39:15.440]  Значит, вот это все сходится к нулю.
[39:15.440 --> 39:16.440]  Аналогично здесь.
[39:16.440 --> 39:19.440]  Вот это сходится к нулю, а это константа.
[39:19.440 --> 39:20.440]  Вот.
[39:20.440 --> 39:22.440]  Так что все это сходится к нулю.
[39:27.440 --> 39:29.440]  Вот.
[39:29.440 --> 39:33.440]  Так что получается, что математическое ожидание
[39:33.440 --> 39:37.440]  этой вещи, минус математическое ожидание этой вещи, сходится
[39:37.440 --> 39:38.440]  к нулю.
[39:38.440 --> 39:41.440]  То есть вот это мотожидание сходится к вот этому.
[39:41.440 --> 39:43.440]  Мотожидание вот этого.
[39:43.440 --> 39:46.440]  На этом лемма первая доказана.
[39:46.440 --> 39:49.440]  Да, кстати, небольшое объявление.
[39:49.440 --> 39:55.440]  Вот у меня на Notion есть раздел Письменные задания.
[39:55.440 --> 39:57.440]  И там списки.
[39:57.440 --> 40:01.440]  Вот это те задачи, которые вы должны сдавать своим
[40:01.440 --> 40:04.440]  семинаристам, чтобы сдать задания.
[40:04.440 --> 40:05.440]  Понятно?
[40:05.440 --> 40:08.440]  Я ничего не менял там с прошлого года.
[40:08.440 --> 40:11.440]  Вроде там все нормально в плане задач.
[40:11.440 --> 40:14.440]  Так что вот эти и только эти задачи.
[40:14.440 --> 40:18.440]  И важность задачи решать, потому что эти задачи, они
[40:18.440 --> 40:19.440]  будут на экзамене.
[40:19.440 --> 40:23.440]  Но я не помню, все ли из этих задач попадают в билет
[40:23.440 --> 40:24.440]  на экзамене.
[40:24.440 --> 40:26.440]  Но, наверное, почти все.
[40:26.440 --> 40:31.440]  Несколько комментариев по поводу вот этой леммы,
[40:31.440 --> 40:32.440]  которой мы доказали.
[40:32.440 --> 40:38.440]  Обратите внимание, что значит, что она гласит, что если
[40:38.440 --> 40:45.440]  ХН сходится к ИКСУ в СК смысле, и ХН сходится к Y в СК
[40:45.440 --> 40:53.440]  смысле, то тогда МАТ ожидания ХН сходится к МАТ ожидания
[40:53.440 --> 41:00.440]  ХЫ, при М и Н, стремящемся к бесконечности.
[41:00.440 --> 41:04.440]  В этой теореме, кроме того, что должны существовать
[41:04.440 --> 41:08.440]  конечные вторые моменты у ХА и Y, ничего не сказано
[41:08.440 --> 41:10.440]  о самих последовательностях.
[41:10.440 --> 41:14.440]  То есть, это означает, что Х и Y, они могут быть
[41:14.440 --> 41:18.440]  независимыми, они могут совпадать, могут быть
[41:18.440 --> 41:19.440]  константами.
[41:19.440 --> 41:23.440]  Ну, например, пусть YН равняется тождественно единито.
[41:23.440 --> 41:24.440]  Подставим сюда.
[41:24.440 --> 41:25.440]  Что мы получим?
[41:25.440 --> 41:31.440]  Что МАТ ожидания ХМ сходится к МАТ ожиданию ИКСА, при
[41:31.440 --> 41:35.440]  М, стремящемся к бесконечности.
[41:35.440 --> 41:40.440]  То есть, если ХМ сходится к ИКСУ в среднем квадратичном
[41:40.440 --> 41:46.440]  и существует второй момент ИКСА, то тогда МАТ ожидания
[41:46.440 --> 41:48.440]  ХМ сходится к МАТ ожиданию ИКС.
[41:48.440 --> 41:50.440]  Вот.
[41:50.440 --> 41:54.440]  Это прямое следствие этой леммы.
[41:54.440 --> 41:57.440]  Теперь пусть YН равен Х, ну Н.
[41:57.440 --> 41:59.440]  Давайте мы возьмем одинаковые последовательности.
[41:59.440 --> 42:01.440]  Пусть эти последовательности будут одинаковыми.
[42:01.440 --> 42:05.440]  Тогда отсюда следует, что математическое ожидание
[42:05.440 --> 42:11.440]  Х, ну М или Н, не важно, в квадрате, сходится к МАТ
[42:11.440 --> 42:15.440]  ожиданию в квадрате, при Н, стремящемся к бесконечности.
[42:15.440 --> 42:16.440]  Вот.
[42:16.440 --> 42:19.440]  Значит, если это сходится сюда в ИКСА смысле, и у
[42:19.440 --> 42:23.440]  вот этой штуки существует конечный второй момент,
[42:23.440 --> 42:26.440]  то тогда второй момент этого сходится ко второму моменту
[42:26.440 --> 42:27.440]  этого.
[42:27.440 --> 42:31.440]  Вот для других там видов сходимости, из их сходимости
[42:31.440 --> 42:34.440]  там не обязательно следует, что и числовые характеристики
[42:34.440 --> 42:36.440]  типа МАТ ожидания сходятся.
[42:36.440 --> 42:38.440]  Но для ИСКА сходимости это так.
[42:38.440 --> 42:41.440]  Вот это очень сильно помогает при теоремах, при решении
[42:41.440 --> 42:42.440]  задач.
[42:42.440 --> 42:44.440]  Вот это свойство ИСКА сходимости.
[42:44.440 --> 42:47.440]  Не надо только забывать, что предел должен, для того
[42:47.440 --> 42:50.440]  чтобы такое утверждать, предел должен быть, иметь
[42:50.440 --> 42:52.440]  второй конечный момент.
[42:52.440 --> 42:54.440]  Вот такая теорема.
[42:54.440 --> 43:01.440]  Значит, вторая лемма, я ее приведу без доказательства.
[43:01.440 --> 43:04.440]  Она говорит вот о чем.
[43:04.440 --> 43:12.440]  Что если, что последовательность сходится в ИСКА смысле,
[43:12.440 --> 43:16.440]  тогда и только тогда, когда она фундаментальная.
[43:16.440 --> 43:21.440]  Ну, мы привыкли в математическом анализе к такого рода теоремам.
[43:21.440 --> 43:23.440]  Они помогают нам доказывать, что последовательность
[43:23.440 --> 43:27.440]  сходится к чему-то без выбора кандидата.
[43:27.440 --> 43:29.440]  К чему ты хочешь рассматривать сходимость.
[43:31.440 --> 43:32.440]  Значит,
[43:32.440 --> 43:33.440]  пусть
[43:33.440 --> 43:35.440]  xkt
[43:35.440 --> 43:38.440]  k равным от единицы до бесконечности, это
[43:38.440 --> 43:41.440]  случайная последовательность,
[43:41.440 --> 43:44.440]  для каждой из которых
[43:44.440 --> 43:46.440]  случайная последовательность такая, что
[43:46.440 --> 43:48.440]  от ожидания xk в квадрате
[43:48.440 --> 43:50.440]  конечная.
[43:50.440 --> 43:51.440]  Вот.
[43:51.440 --> 43:53.440]  Тогда
[43:53.440 --> 43:55.440]  необходимым
[43:55.440 --> 43:56.440]  и
[43:56.440 --> 43:58.440]  достаточным
[43:58.440 --> 43:59.440]  условиям
[43:59.440 --> 44:01.440]  xk
[44:01.440 --> 44:03.440]  сходимости
[44:05.440 --> 44:07.440]  xk
[44:07.440 --> 44:09.440]  ну, xk
[44:09.440 --> 44:11.440]  к x в среднем квадратичном
[44:14.440 --> 44:17.440]  является равенство
[44:17.440 --> 44:19.440]  значит, предел
[44:19.440 --> 44:22.440]  при n и m стремящемся к бесконечности
[44:22.440 --> 44:26.440]  от ожидания ym-dm
[44:26.440 --> 44:28.440]  в квадрате, равное нулю
[44:28.440 --> 44:31.440]  для любых
[44:31.440 --> 44:34.440]  последовательностей
[44:34.440 --> 44:36.440]  yn
[44:36.440 --> 44:37.440]  и
[44:37.440 --> 44:39.440]  zm
[44:40.440 --> 44:42.440]  последовательности
[44:42.440 --> 44:44.440]  xk
[44:44.440 --> 44:45.440]  то есть
[44:45.440 --> 44:47.440]  xk
[44:47.440 --> 44:49.440]  сходится
[44:49.440 --> 44:51.440]  а, сейчас
[44:51.440 --> 44:53.440]  сходимости
[44:55.440 --> 44:57.440]  тут еще добавьте
[44:58.440 --> 45:00.440]  всюду, всюду это требуем
[45:00.440 --> 45:02.440]  итак, xk-то
[45:02.440 --> 45:04.440]  xk сходит к x
[45:04.440 --> 45:06.440]  тогда и только тогда, когда для любых
[45:06.440 --> 45:08.440]  ее под последовательностей вот это
[45:08.440 --> 45:10.440]  вот
[45:10.440 --> 45:12.440]  когда для любых ее под последовательностей
[45:12.440 --> 45:14.440]  будет выполняться вот это
[45:14.440 --> 45:16.440]  y и z опять же произвольные
[45:16.440 --> 45:18.440]  это случайные последовательности
[45:18.440 --> 45:20.440]  они могут быть зависимыми
[45:20.440 --> 45:22.440]  хоть равными между собой, хоть совпадающими
[45:22.440 --> 45:24.440]  с x хоть какие, любые под последовательности
[45:24.440 --> 45:26.440]  x-а
[45:26.440 --> 45:28.440]  вообще вот это утверждение
[45:28.440 --> 45:30.440]  о том, что
[45:30.440 --> 45:32.440]  последовательность случайно сходится
[45:32.440 --> 45:34.440]  тогда и только тогда, когда она фундаментальна
[45:34.440 --> 45:36.440]  это свойство
[45:36.440 --> 45:38.440]  не только xk-сходимости
[45:38.440 --> 45:40.440]  это свойство и сходимости
[45:40.440 --> 45:42.440]  по вероятности, почти наверно
[45:42.440 --> 45:44.440]  и по распределению
[45:44.440 --> 45:46.440]  вот, ну здесь я привел
[45:46.440 --> 45:48.440]  просто формулировку для xk-сходимости
[45:48.440 --> 45:50.440]  но для других видов сходимости
[45:50.440 --> 45:52.440]  это тоже все работает
[45:52.440 --> 45:54.440]  и если нужно, вы можете этим пользоваться
[45:54.440 --> 45:56.440]  но, по-моему, нам
[45:56.440 --> 45:58.440]  в задачах
[45:58.440 --> 46:00.440]  и пиаремах это нигде
[46:00.440 --> 46:02.440]  не понадобится
[46:02.440 --> 46:04.440]  а вот эта лемма 2 понадобится
[46:16.440 --> 46:18.440]  так
[46:18.440 --> 46:20.440]  и наконец, лему 3
[46:20.440 --> 46:22.440]  введу
[46:24.440 --> 46:26.440]  с доказательством
[46:26.440 --> 46:28.440]  но она простая
[46:28.440 --> 46:30.440]  значит, пусть
[46:30.440 --> 46:32.440]  для последовательности
[46:32.440 --> 46:34.440]  xk-а
[46:34.440 --> 46:36.440]  у которой
[46:36.440 --> 46:38.440]  те моменты
[46:38.440 --> 46:40.440]  вторые конечные
[46:42.440 --> 46:44.440]  пусть для этой последовательности
[46:44.440 --> 46:46.440]  существует c
[46:46.440 --> 46:48.440]  такое, что
[46:48.440 --> 46:50.440]  для любых
[46:50.440 --> 46:52.440]  под последовательностей
[46:54.440 --> 46:56.440]  yn
[46:56.440 --> 46:58.440]  и zm
[46:58.440 --> 47:00.440]  последовательности
[47:00.440 --> 47:02.440]  xk
[47:04.440 --> 47:06.440]  выполнено
[47:06.440 --> 47:08.440]  что
[47:08.440 --> 47:10.440]  математическое ожидание
[47:10.440 --> 47:12.440]  yn
[47:12.440 --> 47:14.440]  zm
[47:14.440 --> 47:16.440]  входит к c
[47:16.440 --> 47:18.440]  пусть такая c найдется
[47:18.440 --> 47:20.440]  что для любых
[47:20.440 --> 47:22.440]  под последовательности
[47:22.440 --> 47:24.440]  вот имеет место вот эта сходимость
[47:24.440 --> 47:26.440]  к одному и тому же c
[47:26.440 --> 47:28.440]  при n и m
[47:28.440 --> 47:30.440]  стремящимся к бесконечности
[47:30.440 --> 47:32.440]  вот
[47:32.440 --> 47:34.440]  тогда
[47:34.440 --> 47:36.440]  xk
[47:36.440 --> 47:38.440]  сходится
[47:38.440 --> 47:40.440]  то есть, тогда существует x
[47:40.440 --> 47:42.440]  такой, что
[47:42.440 --> 47:44.440]  у него конечный второй момент
[47:44.440 --> 47:46.440]  и xk-сходимость
[47:46.440 --> 47:48.440]  и xk
[47:48.440 --> 47:50.440]  сходится
[47:50.440 --> 47:52.440]  xk-стримящимся к бесконечности
[47:52.440 --> 47:54.440]  вот
[47:54.440 --> 47:56.440]  видите, тут не просто сходится
[47:56.440 --> 47:58.440]  а то, что момент
[47:58.440 --> 48:00.440]  еще существует второго порядка
[48:02.440 --> 48:04.440]  вот так вот
[48:04.440 --> 48:06.440]  давайте доказательства напишем
[48:08.440 --> 48:10.440]  ну, для этого надо что заметить
[48:10.440 --> 48:12.440]  тут очень простое доказательство
[48:12.440 --> 48:14.440]  yn-zm
[48:16.440 --> 48:18.440]  ну, покажем, что эта последовательность
[48:18.440 --> 48:20.440]  сходится
[48:20.440 --> 48:22.440]  и будет вот это
[48:22.440 --> 48:24.440]  верно
[48:24.440 --> 48:26.440]  значит, вот это у нас получается
[48:26.440 --> 48:28.440]  yn2-2
[48:28.440 --> 48:30.440]  ynzm
[48:30.440 --> 48:32.440]  плюс zm2
[48:32.440 --> 48:34.440]  вот
[48:34.440 --> 48:36.440]  и мы рассмотрим
[48:36.440 --> 48:38.440]  предел при n и m
[48:38.440 --> 48:40.440]  стремящимся
[48:40.440 --> 48:42.440]  к бесконечности
[48:42.440 --> 48:44.440]  значит, мат ожидания
[48:44.440 --> 48:46.440]  yn-zm
[48:46.440 --> 48:48.440]  вот покажем, что этот
[48:48.440 --> 48:50.440]  предел равен 0
[48:50.440 --> 48:52.440]  ну, скобку мы написали
[48:52.440 --> 48:54.440]  мат ожиданий этой суммы
[48:54.440 --> 48:56.440]  это сумма этих мат ожиданий
[48:56.440 --> 48:58.440]  мат ожиданий yn2-2
[48:58.440 --> 49:00.440]  сходится к c
[49:00.440 --> 49:02.440]  потому что здесь мы пишем, что существует c
[49:02.440 --> 49:04.440]  для любых подпоследовательностей
[49:04.440 --> 49:06.440]  в том числе, для которых z и y совпадают
[49:06.440 --> 49:08.440]  так что если они
[49:08.440 --> 49:10.440]  совпадут, то получается, что
[49:10.440 --> 49:12.440]  по этому условию
[49:12.440 --> 49:14.440]  у нас мат ожиданий yn2-2
[49:14.440 --> 49:16.440]  сходится к c
[49:16.440 --> 49:18.440]  здесь получается c
[49:18.440 --> 49:20.440]  то есть мы применяем вот это вот условие
[49:20.440 --> 49:22.440]  когда y и z равны
[49:22.440 --> 49:24.440]  здесь у нас y и z
[49:24.440 --> 49:26.440]  такие, какие они нам даны
[49:26.440 --> 49:28.440]  поэтому минус 2c
[49:28.440 --> 49:30.440]  предел будет равен
[49:30.440 --> 49:32.440]  и здесь тоже, когда они равны
[49:32.440 --> 49:34.440]  этому z плюс c
[49:34.440 --> 49:36.440]  ну вот, все сокращается, получается 0
[49:36.440 --> 49:38.440]  вот
[49:38.440 --> 49:40.440]  а это значит, по вот этой лемме
[49:40.440 --> 49:42.440]  что раз, вот это справедливо
[49:42.440 --> 49:44.440]  для любых двух подпоследовательностей
[49:44.440 --> 49:46.440]  значит
[49:46.440 --> 49:48.440]  у нас имеет место Sка-сходимость
[49:48.440 --> 49:50.440]  вот такая при вот этом условии y
[49:50.440 --> 49:52.440]  н效상 Cка-сходимость
[49:52.440 --> 49:54.440]  еще вот это условие. Вот здесь зашито
[49:54.440 --> 49:56.440]  вот это
[49:56.440 --> 49:58.440]  C crimes
[49:58.440 --> 50:00.440]  darauf stealing
[50:00.440 --> 50:02.440]  вот это
[50:02.440 --> 50:04.440]  C whole equals
[50:04.440 --> 50:06.440]  0
[50:06.440 --> 50:08.440]  вот такая
[50:08.440 --> 50:10.440]  лемма
[50:10.440 --> 50:28.120]  Случайные последовательности мы разобрались. Теперь перейдем уже к определению непрерывности,
[50:28.120 --> 50:41.820]  дифференцированности и интегрированности. Мы будем говорить, что случайный процесс
[50:41.820 --> 51:02.140]  x от t, t из t большого, sk непрерывен точки t0, если x от t плюс эпсион входится в sk смысле
[51:02.140 --> 51:15.100]  при эпсион стремящимся к нулю, к x от t. Случайный процесс sk непрерывен в точке t0, если вот это
[51:15.100 --> 51:26.100]  вот справедливо. Вот так как тут все сводится в итоге к числовым пределам, а числовых пределов,
[51:26.100 --> 51:32.060]  помните там мотонализу у нас было утверждение, что если мы по непрерывной переменной куда-то
[51:32.220 --> 51:36.820]  сходимся, то это равносильно тому, что по любой последовательности, которая отвечает
[51:36.820 --> 51:41.640]  это исходимости, мы куда-то сходимся. Так что вот на это можно смотреть в терминах
[51:41.640 --> 51:47.580]  числовых последовательностей. То, что вот это выполнено для любой числовой последовательности,
[51:47.580 --> 51:51.940]  которая стремится к нулю. Здесь у нас непрерывная переменная эпсион стремится к нулю,
[51:51.940 --> 51:57.260]  а мы на это можем посмотреть, как она равносильна условия. Что бы любой последовательности,
[51:57.260 --> 52:01.900]  стремящемся к нулю, если мы его сюда подставим, у нас будет исходимость вот сюда. Но это
[52:01.900 --> 52:09.300]  просто свойство изоматематического анализа вот но для того чтобы не говорить каждый раз
[52:09.300 --> 52:14.100]  вот для любой последовательности стремящиеся к нулю мы используем просто вот такое обозначение
[52:14.100 --> 52:19.540]  как бы непрерывная переменная сходится здесь неважно справа слева просто epsilon стремится к
[52:19.540 --> 52:27.940]  нулю вот это искание прерывность точки т 0 давайте я сразу веду и другие определения искать
[52:27.940 --> 52:40.020]  дифференцируемости значит случайный процесс икса т значит с называется с к дифференцируемым
[52:40.020 --> 52:58.180]  точки т 0 называется с к дифференцируем в точке т 0 если если значит если x от т плюс
[52:58.180 --> 53:11.940]  epsilon минус x от t разделить на epsilon ходится среднем квадратичном при epsilon стремящимся к
[53:11.940 --> 53:24.140]  нулю к некоторой случайной величине это вот если сходится к некоторой случайной величине это если
[53:24.140 --> 53:32.540]  найдет такая случайная лично который сходится вот это случайная величина называется с к производные
[53:32.540 --> 53:41.940]  процесса точки а сейчас подождите т 0 т 0 а и там т 0 я сегодня не внимательный совсем т 0 вот
[53:41.940 --> 53:57.060]  называется с к производной в точке т 0 с к производная процесса x в точке т 0 и она обозначается у нас
[53:57.060 --> 54:09.140]  вот так x штрих от т 0 вот для этого мы придумаем вот такой символ x штрих от т 0 и будем называть
[54:09.140 --> 54:15.300]  это случайно величины который сходится вот эта вещь значит здесь есть определенная тонкость вот
[54:15.300 --> 54:23.220]  как считать имеет конечный второй момент это или нет в принципе по определению сходимости это не
[54:23.220 --> 54:33.620]  нужно но для теорем которые пойдут дальше по-моему нам важно то что у это должен существовать второй
[54:33.620 --> 54:39.180]  конечный момент поэтому я предлагаю добавить это просто в определение но это не есть что-то
[54:39.180 --> 54:47.540]  принципиальное либо мы здесь это не добавляем тогда последующим нам нужно постоянно с этим как-то
[54:47.540 --> 54:53.980]  работать где там и конечно где не конечно либо мы добавляем и тогда мы просто упрощаем себе
[54:53.980 --> 54:59.780]  жизнь потом просто не будут эти фразы лишние дополнительно и добавляться а так теория будет
[54:59.780 --> 55:05.060]  построена кивалетным образом так что давайте мы здесь просто ведем что математическое ожидание
[55:05.060 --> 55:12.580]  это в квадраты конечно дополнительные условия сюда добавим но это не принципиальные условия для
[55:12.580 --> 55:18.020]  дальнейшей теории вот потому что мы всегда можем позволить себя потом говорить что если
[55:18.020 --> 55:24.500]  ска дифференцируемо и производный имеет второй порядок вот так теория мы строить давайте мы
[55:24.500 --> 55:36.860]  добавим и будем вот так считать так и третье это ска интегрируемость тоже веду
[55:43.020 --> 55:54.340]  такое определение определение определение ска интегрируемости по ривану значит пусть дан
[55:54.340 --> 56:05.260]  случайный процесс икса т т т большого и некоторые отрезок
[56:05.260 --> 56:18.020]  принадлежит вот этому т ему будем рассматривать интеграл на этом отрезке значит рассмотрим
[56:18.020 --> 56:30.020]  разбиение отрезка а б а именно а равняется т0 меньше чем т1 меньше и так далее меньше тн равная
[56:30.020 --> 56:51.020]  б и точки тау и т которые принадлежат т 0 т т сейчас и минус 1 и и вот для и от единицы до
[56:51.380 --> 57:13.500]  вот тогда если существует ска предел частичных сумма вот таких вот это значит получается у нас
[57:13.500 --> 57:29.580]  сумма так сумма значит по и от единицы до n икс от и этого на т и минус т и минус 1 если
[57:29.580 --> 57:37.460]  существует вот этот предел или если вот это частичные суммы сходится в среднем квадратичном
[57:37.460 --> 57:48.500]  при n стремящимся к бесконечности к некоторой случайной величине про которую мы здесь тоже
[57:48.500 --> 57:53.220]  потребуем чтобы она имела второй конечный момент точно также как и там такую оговорку
[57:53.220 --> 58:04.020]  сделаем то тогда а и этот предел не зависит от разбиения и выбора точек то тогда будем
[58:04.020 --> 58:11.340]  говорить что этот процесс ска интегрируем по риману и вот эту случайную величину будем
[58:11.340 --> 58:26.980]  называть ска интегралом римана процесса икс на отрезке а б сейчас и этот предел не зависит от
[58:26.980 --> 58:40.740]  разбиения и выбора точек но как вот при определении интеграла римана
[58:56.980 --> 59:14.380]  вот и выбора точек то процесс икс от называется ска интегрируем им по риману
[59:14.380 --> 59:35.020]  на отрезке а б и случайная величина это называется ска интегралом римана
[59:35.020 --> 59:55.060]  процесса икс от на отрезке а б вот и обозначается так значит это равняется как обычный интеграл
[59:56.060 --> 01:00:05.980]  вот то что здесь написано это некий символ это символ для этой который похож на обычный
[01:00:05.980 --> 01:00:12.020]  интеграл но необычный интеграл здесь предел в котором понимается сходимость частичных
[01:00:12.020 --> 01:00:19.340]  сумм она и ска сходимость здесь но интеграл мы используем обозначение привычное нам вот это
[01:00:19.340 --> 01:00:35.340]  ска интеграл вот да ой так так так так так да спасибо здесь стал получается здесь получается
[01:00:35.340 --> 01:00:45.860]  тау а здесь ты здесь ты и ты минус ты ты минус первая здесь стал да спасибо вот хорошо хорошо
[01:00:48.860 --> 01:00:53.100]  так ну ладно вот я ввел такие определения
[01:01:06.340 --> 01:01:11.180]  значит определение ска непрерывности ска дифференцируемость значит всюду у нас
[01:01:11.180 --> 01:01:18.340]  здесь предел мы требуем для него чтобы мот ожидания квадрата было конечным но
[01:01:18.340 --> 01:01:22.300]  по крайней мере для дифференцируемости интегрируемости давайте мы это и здесь
[01:01:22.300 --> 01:01:31.380]  потребуем чтобы все было симметрично когда получается что непрерывность если мы хотим
[01:01:31.380 --> 01:01:34.900]  чтобы была непрерывность точки то мы требуем чтобы существовал второй конечный момент
[01:01:34.900 --> 01:01:42.140]  как бы да давайте вот так поступим ну что везде симметрично было то придется помнить тогда где
[01:01:42.140 --> 01:01:48.300]  мы это потребовали а где мы это не потребовали вот пусть будет везде все симметрично ну хорошо
[01:01:48.300 --> 01:02:01.060]  а теперь можно воспользоваться возможностями который дает ска сходимость и доказать и вывести
[01:02:01.060 --> 01:02:10.660]  некоторые критерии непрерывности дифференцируемости и интегрируемости но я сегодня все наверное не успею
[01:02:10.660 --> 01:02:18.980]  доказать здесь все очень просто смотрите оказывается что если мы рассматриваем непрерывность
[01:02:18.980 --> 01:02:25.820]  дифференцируемость и интегрируемость некоторого процесса в среднем квадратичном то для
[01:02:25.820 --> 01:02:34.580]  исследования процесса найти свойства нам достаточно посмотреть на ее ко вариационную функцию или что
[01:02:34.580 --> 01:02:40.940]  эквивалентно на ее математическое ожидание и корреляционную функцию а именно мы с вами
[01:02:40.940 --> 01:02:53.420]  докажем что процесс вот в этом смысле является непрерывным ска непрерывным точки т 0 тогда и
[01:02:53.600 --> 01:03:01.660]  только тогда когда ко вариационная функция ко мы обозначали непрерывна вп точке то ноль то ноль
[01:03:01.660 --> 01:03:08.860]  критерии такой так что чтобы это выяснить находишь ковы риационную функцию и проверяешь ее непрерывность
[01:03:08.860 --> 01:03:16.340]  в точке ту нуль ту ноль все вот дифференцируемость там тоже будет некоторому смысле дифференцируемость
[01:03:16.340 --> 01:03:22.840]  кавриционной функции интегрируемость там будет тоже интегрируемос 54 функции то есть вот эти
[01:03:22.840 --> 01:03:28.000]  свойства непрерывности дифференцированности и интегрированности involve
[01:03:28.000 --> 01:03:44.780] ον неприрывность дифференцированность и интегрировakk
[01:03:44.780 --> 01:03:50.220]  сходятся к проверке соответствующих свойств для мотожидания и корреляционной
[01:03:50.220 --> 01:03:57.020]  функции или к проверке этих свойств для ковриационной функции.
[01:03:57.020 --> 01:04:00.980]  Для других видов сходимости таких результатов уже нет, а здесь они есть, мы этим
[01:04:00.980 --> 01:04:05.220]  будем пользоваться. Давайте, сколько успеем сегодня, столько докажем, и первое,
[01:04:05.220 --> 01:04:09.620]  что мы рассмотрим, это критерии искани прерывности.
[01:04:14.780 --> 01:04:25.340]  Теориям критерий S-к непрерывности.
[01:04:25.620 --> 01:04:38.900]  Значит, процесс X от T с мотожиданием X от T в квадрате меньше бесконечности
[01:04:38.940 --> 01:04:56.220]  является S-к непрерывным T0 тогда и только тогда, когда ковриационная функция KX от T
[01:04:57.060 --> 01:05:11.220]  непрерывно точки T0 T0, что равносильно, и это мы тоже докажем, двум вещам, что
[01:05:11.220 --> 01:05:19.420]  математическое ожидание процесса непрерывно точки T0 и корреляционная
[01:05:19.420 --> 01:05:32.820]  функция непрерывно T0 T0. Вот видите, в чем польза ковриационной функции, она одна,
[01:05:32.820 --> 01:05:37.420]  вот непрерывность этого равносильно непрерывности этого. Корреляционной
[01:05:37.420 --> 01:05:41.220]  функции, ее иногда проще находить, но тогда здесь, видите, надо еще им от
[01:05:41.220 --> 01:05:49.020]  ожидания проверять. Ну, в общем, тут смотришь уже по ситуации, можно так, можно сяк.
[01:06:11.220 --> 01:06:35.260]  Так, ну будем доказывать этот критерий. Так, ну с чего бы тут начать? Мы с вами докажем
[01:06:35.860 --> 01:06:45.900]  следствие вот это, то есть пусть и с K непрерывен, тогда ковриационная функция непрерывна, потом мы
[01:06:45.900 --> 01:06:54.860]  докажем, что если ковриационная функция непрерывна, то тогда и процесс и с K непрерывен. Вот, то есть мы
[01:06:54.860 --> 01:07:01.420]  докажем с вами сначала вот это, вот эту равносильность, а затем мы воспользуемся вот
[01:07:01.420 --> 01:07:07.380]  этой равносильностью потом, чтобы доказать вот эту равносильность. Вот такой у нас будет план.
[01:07:07.380 --> 01:07:16.100]  Итак, сначала предполагаем, что, давайте, первый шаг здесь, это будет вот этот шаг,
[01:07:16.100 --> 01:07:36.380]  первый, что пусть x, значит t0, пусть x от t сходится, ну давайте так, пусть x от t с K сходится к x,
[01:07:36.380 --> 01:07:50.460]  нет сейчас, что я пишу-то, с K непрерывен к точке t0. Вот, тогда что мы можем написать? x от t плюс
[01:07:50.460 --> 01:07:59.900]  некий епсилон 1 сходится в среднем квадратичном смысле к x от t, здесь везде надо 0 писать,
[01:07:59.900 --> 01:08:08.780]  то что мы точку t0 рассматриваем. Вот, и мы можем написать, что x от t 0 плюс какой-то
[01:08:08.780 --> 01:08:16.780]  другой епсилон 2 тоже сходится в среднем квадратичном к x от t 0, здесь только епсилон 1 стремится к нулю,
[01:08:16.780 --> 01:08:22.380]  а здесь епсилон 2 стремится к нулю, и как они стремятся к нулю, они могут стремиться к нулю
[01:08:22.380 --> 01:08:33.900]  совершенно независимым образом. Тогда что мы получаем? Математическое ожидание x от t0 плюс
[01:08:33.900 --> 01:08:44.660]  епсилон 1 умножить на x от t0 плюс епсилон 2, по лемме 1 это сходится к чему? к математическому
[01:08:44.660 --> 01:08:58.580]  ожиданию от x t0, здесь и это тоже сходится к x t0, значит сходится вот к этому по лемме 1,
[01:08:58.580 --> 01:09:11.920]  вот, значит при епсилон 1, епсилон 2 стремящимся к нулю независимым друг от друга образом. Но что
[01:09:11.920 --> 01:09:18.000]  здесь написано? Ведь это есть не что иное по определению как ковариационная функция процесса
[01:09:18.000 --> 01:09:29.080]  x точки t0 плюс епсилон 1, t0 плюс епсилон 2, а это что? А это есть ковариационная функция точки t0 t0,
[01:09:29.080 --> 01:09:36.880]  и вот мы видим входимость при епсилон 1 и епсилон 2 к нулю независимым образом. Вот,
[01:09:36.880 --> 01:09:46.160]  видите как все просто на самом деле. Это был первый вот этот пункт, в эту сторону мы показали,
[01:09:46.160 --> 01:10:01.120]  теперь покажем в обратную сторону пункт 2. Теперь мы предположим, что к x t s непрерывно точки t0 t0,
[01:10:01.120 --> 01:10:10.600]  и мы напишем вот какую вещь, что мы должны доказать, что математическое ожидание x от t0
[01:10:10.600 --> 01:10:19.040]  плюс епсилон минус x от t0, что вот эта штука сходится к нулю. Но давайте посмотрим, что это такое
[01:10:19.040 --> 01:10:29.520]  повнимательнее, раскроем квадраты, что мы получаем от ожидания x от t0 плюс епсилон на x от t0 плюс епсилон,
[01:10:29.520 --> 01:10:42.680]  т.е. вот тут в квадрате. Минус 2 мат. ожидания x t0 плюс епсилон x t0 и плюс мат. ожидания x в квадрате t0.
[01:10:42.680 --> 01:10:54.280]  Так. И выразим это в терминах k. k x в точке t0 плюс епсилон t0 плюс епсилон,
[01:10:54.280 --> 01:11:07.520]  минус 2 k t0 плюс епсилон t0 плюс, допустим, тоже k, не важно, t0 t0. Вот. И мы предположили,
[01:11:07.520 --> 01:11:16.320]  что она непрерывна в точке t0 t0. Значит, при епсилон, стремящемся к нулю, вот это сходится к x t0 t0,
[01:11:16.320 --> 01:11:34.400]  вот это сходится к x t0 t0, а там уже к x t0 t0. 1 минус 2 плюс 1. Нулю сходится. Вот так. Так что мы
[01:11:34.400 --> 01:11:40.480]  предположили это и записали то, что нам нужно доказать. Выразили это в терминах k и показали
[01:11:40.480 --> 01:11:48.080]  в силу непрерывности, что это будет 0. Вот. Второй пункт мы доказали. Если эта штука непрерывна,
[01:11:48.080 --> 01:11:53.440]  тогда вот это все. И мы считаем с этого момента это справедливо. Что процесс сходится, не важно
[01:11:53.440 --> 01:11:59.480]  какой, любой совершенно произвольный процесс, сходится в sk тогда и только тогда, непрерывно,
[01:11:59.480 --> 01:12:08.520]  в sk смысле, тогда и только тогда, когда кавалерационная функция непрерывна, точка t0 t0. Вот. Так. Хорошо. Теперь
[01:12:08.520 --> 01:12:16.760]  рассмотрим вот это следствие туда-обратно. Здесь, наверное, мне ничего не понадобится, я сытру.
[01:12:29.040 --> 01:12:36.480]  Будем доказывать. Так. Ну тут проще всего доказать какую. Смотрите. Давайте вот это будет нашим
[01:12:36.480 --> 01:12:49.560]  третьим. Если это непрерывно и это непрерывно, то k непрерывно. Как это показать? Пусть mx t непрерывно
[01:12:49.560 --> 01:13:01.920]  t0 и rx ts непрерывно t0 t0. Надо просто вспомнить, как связана кавалерационная функция и
[01:13:01.920 --> 01:13:10.480]  корреляционная функция. А мы знаем, что кавалерационная функция ts это корреляционная
[01:13:10.480 --> 01:13:24.880]  функция в точке ts плюс mx t на mx s. Вот. И поэтому, если m и r непрерывны, то тогда это непрерывно,
[01:13:24.880 --> 01:13:30.160]  это непрерывно, произведение непрерывно, эта штука непрерывна, но понятно тогда, что и вся эта
[01:13:30.160 --> 01:13:36.080]  комбинация, вся эта сумма тоже непрерывна. Элементарно. Все. Исходимости непрерывной сходятся,
[01:13:36.080 --> 01:13:44.640]  это тоже будет непрерывной. T0 T0. Просто из этого вида. Так что вот это следствие тривиально.
[01:13:44.640 --> 01:14:01.800]  И четвертое следствие. Пусть теперь kx ts непрерывно t0 t0.
[01:14:01.800 --> 01:14:16.200]  Но по уже доказанному, если она непрерывна в t0 t0, то у нас есть исходимость. Мы можем этим
[01:14:16.200 --> 01:14:28.440]  пользоваться, потому что мы это доказали. Тогда отсюда следует, что x от t sk непрерывно t0, то есть,
[01:14:28.440 --> 01:14:43.560]  то есть, математическое ожидание от xt плюс epsilon минус x от t, тут t0 везде, t0 в квадрате,
[01:14:43.720 --> 01:14:48.720]  входится к нулю с одной стороны. Вот эта вещь сходится к нулю, это то, что мы знаем.
[01:14:48.720 --> 01:14:54.520]  А теперь там мы выразили от ожидания квадрата разности через k.
[01:14:54.520 --> 01:15:04.120]  А здесь давайте выразим через m и r.
[01:15:04.120 --> 01:15:30.560]  И как мы с вами поступим здесь? Мы перейдем к центрированным величинам.
[01:15:30.560 --> 01:15:39.040]  Смотрите, вот эта вещь будет равна следующей. Математическое ожидание x центрированное,
[01:15:39.040 --> 01:15:48.160]  то есть x минус ее мат ожидания в точке t0 плюс epsilon, минус тоже x центрированное t0,
[01:15:48.160 --> 01:15:54.640]  то есть x от t0 минус ее мат ожидания. Нам надо добавить то, что мы вычли. Поэтому мы прибавим
[01:15:54.640 --> 01:16:08.960]  мат ожидания x в точке t, тут везде t0, t0 плюс epsilon, там t0, так, минус mx в точке t0,
[01:16:08.960 --> 01:16:18.800]  так, в квадрате. Вот я написал эквивалентную вещь. А теперь раскроем скобки здесь. И смотрите,
[01:16:18.800 --> 01:16:24.160]  как у нас все свернется интересно. Математическое ожидание вот этой скобки в квадрате.
[01:16:24.160 --> 01:16:41.000]  Дальше я должен написать плюс два умножить на мат ожидания произведение вот этого на вот эту
[01:16:41.000 --> 01:16:49.760]  разность. Но эта вещь не случайная, и поэтому она вынестся за мат ожидания. И там останется
[01:16:49.760 --> 01:16:55.000]  значит два вот этой разности умножить на мат ожидания вот этой разности. Здесь
[01:16:55.000 --> 01:17:00.080]  центрированные величины, их мат ожидания равно нулю. То, что никакого двойного произведения
[01:17:00.080 --> 01:17:08.280]  не будет, оно равно нулю. То, что это центрированные, их мат ожидания равно нулю. Плюс вот эта скобка в квадрате,
[01:17:08.280 --> 01:17:23.840]  она константом от ожидания мы можем убрать. mx t0 минус mx t0. И мы знаем, что это все стремится к нулю,
[01:17:23.840 --> 01:17:29.400]  прежде всего стремящимся к нулю, потому что это вот что у нас такое. Это есть вот это выражение,
[01:17:29.400 --> 01:17:35.640]  оно стремится к нулю, потому что x непрерывно в точке t0, потому что kx непрерывно в точке t0,
[01:17:35.640 --> 01:17:43.880]  как мы предположили. А это следствие мы доказали ранее. Вот так. Но что получается, если мы внимательно
[01:17:43.880 --> 01:17:50.120]  посмотрим на это выражение? Здесь стоит нечто не отрицательное, и здесь стоит нечто не отрицательное,
[01:17:50.120 --> 01:17:56.080]  и их сумма стремится к нулю. А это возможно тогда и только тогда, когда они по отдельности стремятся
[01:17:56.080 --> 01:18:03.760]  к нулю. Видите, как у нас расщепилась отдельно m и вот эта величина. Так что вот это стремится к нулю,
[01:18:03.760 --> 01:18:23.680]  и это означает, что mx непрерывно в точке t0. И вот это стремится к нулю. Но что это такое?
[01:18:23.680 --> 01:18:39.920]  Значит, это означает, что, смотрите, здесь очень хитрый ход, между прочим, вот здесь. Здесь написано,
[01:18:39.920 --> 01:18:50.640]  что вот такой процесс, эксцентрированный, непрерывен в точке t0, правильно? По определению. Он
[01:18:50.640 --> 01:18:58.480]  непрерывен в точке t0. А мы доказали, что если процесс sk непрерывен в точке t0, то тогда его
[01:18:58.480 --> 01:19:08.640]  ковариационная функция непрерывна в точке t0. Следовательно, ковариационная функция эксцентрированного
[01:19:08.640 --> 01:19:20.840]  непрерывна в точке t0. Но ковариационная функция эксцентрированного – это корреляционная функция
[01:19:20.920 --> 01:19:36.880]  Вот и все. Просто по определению. Потому что ковариационная – это мат ожидания вот этого вот в этой
[01:19:36.880 --> 01:19:41.120]  точке умножить на вот это в этой точке. Если мы этот эксцентрированный раскроем, то мы увидим
[01:19:41.120 --> 01:19:49.400]  просто определение для корреляционной функции. Вот так вот. Значит, rx непрерывно в точке t0, t0.
[01:19:49.400 --> 01:19:55.960]  Так что видите, какая логика интересная здесь. Чтобы доказать эту теорему, надо сначала
[01:19:55.960 --> 01:20:04.080]  доказать вот это нерандество. Установить, что sk непрерывность процесса совпадает с непрерывностью
[01:20:04.080 --> 01:20:09.640]  kx в этой точке. Вот это надо доказать. Потому что когда мы будем доказывать вот эту равносильность,
[01:20:09.640 --> 01:20:14.560]  мы пользуемся то одной, то другой. То одним, то другим следствием. Отсюда перешли к sk сходимости.
[01:20:14.560 --> 01:20:19.880]  Теперь из sk сходимости перешли к ковариационной функции, которая в данном случае корреляционная
[01:20:19.880 --> 01:20:33.400]  функция. Вот как. Ну вот. Вот мы с вами и доказали вот этот замечательный критерий. Ну, буквально
[01:20:33.400 --> 01:20:40.520]  пару минут. Давайте сразу выясним для известных нам процессов, что получается. Винеровский процесс.
[01:20:40.520 --> 01:20:49.320]  Что мы про него знаем? Является ли он sk непрерывным в произвольной точке t? Мы знаем, что его
[01:20:49.320 --> 01:20:58.320]  математическое ожидание, тождественный ноль, это непрерывная функция. Окей. Корреляционная
[01:20:58.320 --> 01:21:08.400]  функция. Это минимум t и s. Это тоже непрерывная функция для любого t и s. Значит, так как вот эта
[01:21:08.400 --> 01:21:17.560]  штука непрерывна всюду, эта штука непрерывна всюду, в том числе в точках вида tt, то это означает,
[01:21:17.560 --> 01:21:31.160]  что винеровский процесс sk непрерывен. Причем в любой точке. Прерывен в любой точке t. И самое
[01:21:31.160 --> 01:21:39.760]  интересное. Теперь плацоновский процесс. Плацоновский процесс. Что мы про него знаем? Его
[01:21:39.760 --> 01:21:48.120]  математическое ожидание есть лямбда t. Это непрерывная функция в любой точке. И корреляционная
[01:21:48.120 --> 01:21:56.680]  функция его, это лямбда на минимум t и s, тоже непрерывная функция для любых t и s, в том числе
[01:21:56.680 --> 01:22:05.520]  и в точках вида tt. Значит, по этому критерию плацоновский процесс является тоже sk непрерывным
[01:22:05.520 --> 01:22:17.560]  в любой точке t. Но при этом его траектории это ступеньки, скачки, разрывные функции.
[01:22:17.560 --> 01:22:26.280]  Видите? Так что этот пример показывает, что sk непрерывность не связана с непрерывностью траекторий.
[01:22:26.280 --> 01:22:32.440]  Они могут быть как непрерывными, как у винеровского процесса, так и разрывными,
[01:22:32.440 --> 01:22:40.800]  как у плацоновского процесса. Вот такой примещательный пример. Свойства sk не связаны
[01:22:40.800 --> 01:22:46.400]  со свойствами траекторий. Вот это важное дополнение. А то вы так посмотрите траекторию,
[01:22:46.400 --> 01:22:53.200]  а она непрерывная, а значит процесс непрерывный. Нет, не обязательно. Ну хорошо, на этом мы заканчиваем,
[01:22:53.200 --> 01:23:00.440]  и в следующий раз продолжим доказывать оставшиеся критерии дифференцированности,
[01:23:00.440 --> 01:23:02.440]  интегрированности траектории.
