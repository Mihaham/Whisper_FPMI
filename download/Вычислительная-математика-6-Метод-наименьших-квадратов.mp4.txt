[00:00.000 --> 00:16.440]  Когда мы начинаем нашу лекцию, я напомню, что мы на прошлой лекции говорили о числях бедных
[00:16.440 --> 00:25.280]  решений, уравнений и системе линейных уравнений. Прошлая лекция была посвящена нерду Южного,
[00:25.280 --> 00:31.760]  но этот метод достойен того, чтобы его посвятить лекции, поскольку он основной
[00:31.760 --> 00:39.200]  базовый метод для решения таких задач. Однако вот что интересно и на что я сейчас
[00:39.200 --> 00:46.840]  некоторое отступление сделаю. Мы с вами говорили о том, что если у нас есть уравнение,
[00:46.840 --> 01:14.360]  то точка, к которой сходится наша последовательность,
[01:14.920 --> 01:22.120]  мы называли ее предельной точкой последовательности, либо притягивающей точкой
[01:22.120 --> 01:31.960]  нашей последовательности. Мы говорили об одной точке. Вот оказывается, существует отображение,
[01:31.960 --> 01:41.360]  но мы говорили, что у нас уравнение соответствует отображению выглядит следующим образом.
[01:41.360 --> 01:49.360]  Оказывается, есть отображение, которое имеет не одну притягивающую точку, а несколько. Это вот такой
[01:49.360 --> 02:02.760]  не совсем обычный результат, который был довольно подробно исследован где-то в конце прошлого века.
[02:02.760 --> 02:15.400]  Это чисто такой нелинейный результат. Вот вообще говоря, отображение или их называют
[02:15.400 --> 02:21.320]  разностными отображениями. Ну разностные уравнения тоже есть такой термин, хотя разностные уравнения
[02:21.320 --> 02:28.120]  больше используются в численных методах решения дифференциальных уравнений, обыкновенных и
[02:28.120 --> 02:37.800]  частно производных. Ну разностные отображения имеют обычно вот такой общий вид. УК плюс один, это есть
[02:37.800 --> 02:51.960]  функция УК, УК минус один и так далее. Ну это вид слишком общий. Здесь видите, какая как бы
[02:52.800 --> 03:08.520]  модель представлена. В реальной жизни отображения бывают либо такие, либо максимум две переменды
[03:08.520 --> 03:19.880]  здесь участвуют. УК, УК, УК минус один. Ну вот свойства таких отображений известны. Его исследовано
[03:19.880 --> 03:27.320]  достаточно хорошо, хотя не могу сказать, что они исследованы, что это все было просто. Свойства
[03:27.320 --> 03:35.000]  вот таких отображений уже исследованы недостаточно хорошо. Оказывается, исследование свойств нелинейных
[03:35.000 --> 03:43.600]  отображений это непростая математическая задача. Ну вот я хотел бы остановиться на одном отображении,
[03:43.600 --> 03:52.640]  чтобы один пример, но он такой пример очень важный. Он идет аж с 19 века, но его свойства были
[03:52.640 --> 04:01.160]  изучены где-то в конце прошлого века, только до 20 века. Значит где-то середине 19 века немецкий
[04:01.160 --> 04:12.080]  биолог, который очень увлекался математикой. Кроме того, его имя Ферсюльст изучал изменения
[04:12.080 --> 04:23.160]  популяции некого стада с годами. Ну как отменяется каждый год численность особей популяции. И предложил
[04:23.160 --> 04:28.920]  вот такую формулу. В результате, и конечно у него было много экспериментального материала,
[04:28.920 --> 04:42.800]  лямбда УК на 1 минус УК. Лямбда это некая константа, которая характерна для каждой популяции. И каждый
[04:42.800 --> 04:50.200]  год он предположил, что меняется популяция вот по такому циклу. Ну у ноль равняется а, всегда
[04:50.200 --> 05:00.360]  начальная данная. Ну и вот формула очень-очень простая. Неземельность всего лишь квадратичная,
[05:00.360 --> 05:07.760]  казалось бы. И о чем говорить? Ну вот оказалось, что если мы будем менять параметр лямбда, то
[05:07.760 --> 05:18.040]  свойства вот этого отображения будут меняться неожиданно и качественно. Хотя вроде бы все очень
[05:18.040 --> 05:26.480]  просто. Оказал все непросто. Ну как всегда работы Фельхюйса на эту тему так были не очень
[05:26.480 --> 05:33.600]  хорошо известны. Я бы даже сказал подзабыты. Однако вот где-то примерно через сто лет наш
[05:33.600 --> 05:38.960]  математик, который увлекался биологией, это уже наоборот математик, который в биологии увлекался,
[05:38.960 --> 05:45.440]  что начал заниматься исследованием изменения численности лососи в Дальневосточных реках.
[05:45.440 --> 05:53.000]  И пришел к мнению, что вот эта формула является очень неплохой для опроксимации таких, для решения
[05:53.000 --> 06:03.280]  таких задач. А далее за эту формулу взялись радиофизики, потом механики, потом экономисты и
[06:03.280 --> 06:11.440]  так далее. Вот формула оказалась очень интересной с точки зрения ее свойств. Вот сейчас мы поговорим
[06:11.440 --> 06:22.360]  о свойствах. Дело в том, что у этого отображения, вроде бы страшно простого, оказывается могут
[06:22.360 --> 06:30.000]  быть несколько притягивающих точек. Несколько притягивающих точек. Хотя вроде бы все, казалось
[06:30.000 --> 06:38.000]  бы, откуда она одна должна. Нет, оказывается не все так просто. Ну и вот это отображение послужило
[06:38.000 --> 06:43.440]  основанием той науки, о которой я вам говорил, которая называется нелинейная динамика. Итак,
[06:43.440 --> 06:55.000]  вот пишем вот это рекуррентное соотношение, которое предложил Вильфюцк. Ну ноль равняется а. Давайте
[06:55.000 --> 07:03.080]  вот поговорим о его свойствах. Как меняется его свойство при изменении вот этого параметра лямбда.
[07:03.080 --> 07:12.260]  Ну первое. Пусть лямбда меняется от нуля до единицы. Ну в этом случае параметр решается
[07:12.260 --> 07:22.920]  квадратное уравнение. Ну и вы получаете решение у1 равняется нолью. То есть если вы нарисуете
[07:22.920 --> 07:29.680]  лестнику лямбрея, мы с вами уже несколько раз нарисовали эти лестники лямбрея. То есть
[07:29.680 --> 07:38.320]  бисер-криксу проводим, у равняется у. И вот эту параболу, это наша правая часть,
[07:38.320 --> 07:48.640]  где-то здесь у нас есть предназначенное приближение. И мы начинаем вычислять значение функции. И
[07:48.640 --> 07:58.000]  потом идем вот по этой лестнике лямбрея спускаемся к нулю. Нулю это вот у нас притягивающая
[07:58.000 --> 08:05.040]  точка у0. С точки зрения биолога, скажем, перехуйчества, это означает гибель популяции.
[08:05.040 --> 08:19.520]  То есть популяции не осталось ни одной особи. Ну у1 я, давайте так, у1 написал это первая наша,
[08:19.520 --> 08:25.800]  первая наш корень. Я пока без звездочек пишу первой корень, потому как у нас появится еще корень.
[08:25.800 --> 08:36.920]  Еще корень. Ну у0 это начальное приближение. Идем дальше, увеличиваем лямбрея. Лямбрея от единички
[08:36.920 --> 08:45.560]  до трех. Также у нас остается ситуация с одним корнем. Только он будет несколько другой.
[08:45.560 --> 08:54.480]  Этот корень будет несколько другой. Тоже я рисую бисер-криксу. И здесь у нас будет парабола
[08:55.120 --> 09:04.280]  пересекающая при лямбреи меньше двух. Опять же, пусть у нас где-то будет у0. Я от у0 вычисляю
[09:04.280 --> 09:12.160]  значение функции. И тоже лестница лямбрея приводит нас к другому корню. Давайте я его назову у2.
[09:12.160 --> 09:20.120]  Буду нумеровать. У2. Ну его легко вычислить. У2 это единица минус лямбра минус первой степени.
[09:20.120 --> 09:27.880]  Он пока притягивает еще точка одна. Но правда здесь давайте я уточню. При лямбреи меньше двух у
[09:27.880 --> 09:36.280]  нас вот так вот. Так лестница лямбрея будет выглядеть. При лямбреи больше двух и меньше трех.
[09:36.280 --> 09:46.240]  Давай так лямбрея меньше трех. Пишу. Она будет несколько по-другому выглядеть. Сходимость будет
[09:46.240 --> 09:52.640]  вот так по спирали. Такая сходимость называется не монотонной, а вот такая сходимость называется
[09:52.640 --> 10:03.040]  монотонной. То есть пока вроде бы никаких особенностей нет. Все просто и ясно.
[10:03.040 --> 10:18.880]  Ну вот отмечу, что вот к точке лямбрея равняется один. Это правая часть, правая часть. Производно
[10:18.880 --> 10:24.080]  ее должна быть меньше единицы для того, чтобы точка была притягивающей. Это достаточное
[10:24.080 --> 10:32.480]  условие сходимости метода простых итераций. Точке один это условие нарушается и появляется
[10:32.480 --> 10:38.080]  другая притягивающая точка. Точка становится отталкивающей, ее так называют отталкивающей,
[10:38.080 --> 10:45.640]  а вторая становится притягивающей. Но самое интересное происходит дальше, когда мы увеличиваем
[10:45.640 --> 10:56.920]  лямбда больше трех. Больше трех. Так пусть у нас лямбда будет больше трех и меньше и равняется
[10:56.920 --> 11:10.880]  1 плюс 0 из 5. В этом случае происходит неочевидная ситуация. Наша последовательность распадается
[11:10.880 --> 11:16.880]  на две подпоследовательности, каждая из которых сходится к своей предельной точке. Вот это уже
[11:16.880 --> 11:27.520]  ситуация не очевидна. Причем у нас появляются две предельные точки у3 и у4. Вот это на компьютере
[11:27.520 --> 11:45.680]  хорошо проделывается. Причем у4 есть f от у3, а у3 есть f от у4. Ну если нарисовать опять же
[11:45.680 --> 11:54.160]  вот такой график, то он будет выглядеть немного уже по-другому. Вот так здесь только нужно
[11:54.160 --> 12:04.720]  очертись аккуратно. Здесь получается вот что-то вот такого типа. Не просто нарисовать.
[12:04.720 --> 12:12.640]  Получается вот такой квадратик. То есть две последовательности сходятся к двум точкам у3 и
[12:13.120 --> 12:23.960]  у4. Интересно, что эти две точки оказываются корнем следующего уравнения. f2 у поравняется 0.
[12:23.960 --> 12:40.520]  Что такое f2? Давайте ведем вот такую сложную функцию. f2 у это будет f от f от u. f3 от u это будет f от f.
[12:40.520 --> 12:55.280]  И еще раз от f от u. Ну и так далее. fкта от u. Это будет включить f. Соответственно многоточие f от u и так далее.
[12:55.280 --> 13:03.880]  Каск обок здесь у нас образуется. То есть это такая сложная функция. Такая сложная функция. И вот
[13:03.880 --> 13:13.080]  при лямдо больше трех у нас появляются две притягивающие точки, которые являются решением
[13:13.080 --> 13:20.080]  вот такого уравнения. Ну если вы его распишете, то получите такое квадратное уравнение. Лямдо
[13:20.080 --> 13:31.000]  квадрат у плюс. Так только минус здесь лямдо. Единица плюс лямдо на у и плюс единица плюс лямдо.
[13:31.000 --> 13:39.600]  Если вы его решите, получите вот как раз эти две точки. Это уже неочевидный такой факт.
[13:39.600 --> 13:48.800]  Чисто вот нелинейный эффект. При этом говорят, что появляется цикл периода 2. Его обозначает
[13:49.400 --> 13:59.760]  либо в копках u3, u4. То есть обозначение либо вот p2, либо u3, u4. Это уже какие стандартные обозначения
[13:59.760 --> 14:10.520]  для так называемых циклов. Говорят, что в точке лямдо равняется 3 происходит бифуркация. Вот откуда
[14:10.520 --> 14:17.320]  берется этот период. То есть это вот терринг бифуркация. Вот отсюда он и берется. Этот же терринг
[14:17.320 --> 14:22.000]  правда появляется в нелинейных обыкновенных дифференциальных уравнениях. Когда мы будем
[14:22.000 --> 14:26.880]  о них с вами говорить, я об этом напомню. Кроме того, он будет появляться в ваших
[14:26.880 --> 14:43.960]  лабораторных компьютерных работах. Такие нелинейные эффекты. Теперь пришла пора ввести
[14:43.960 --> 14:54.880]  некоторые определения. Некоторые определения, которые касаются вот как раз понятия цикл,
[14:54.880 --> 15:07.680]  бифуркация и так далее. Первое определение. Точка A называется периодической периода m.
[15:07.680 --> 15:28.520]  Если fm от A равняется A, и fi от A не равняется A, если i не равно. То есть вот это определение
[15:28.520 --> 15:36.120]  периодической точки. Каждая точка в цикле на самом деле является периодической. Период ее равен
[15:36.120 --> 15:52.160]  периоду цикла. И точек может быть несколько. Бифуркация называется следующим явлением. В
[15:52.160 --> 15:58.440]  некоей точке, в данном случае точке лямбра, равняется 3. Когда параметр приобретает это значение,
[15:58.440 --> 16:13.680]  наша притягивающая точка была у 2 единицы минус лямбра минус 1. Перестает быть притягивающей.
[16:13.680 --> 16:21.720]  Почему? Потому как должно быть в этой точке f' меньше единицы, чтобы точка была притягивающей.
[16:21.720 --> 16:30.320]  Это условия, которые мы получали. В этой точке лямбра равняется 3. Точка притягивающая. Вот это
[16:30.320 --> 16:37.760]  условие не выполняется. Другое дело, что мы как бы ожидали, что будет другая предельная точка,
[16:37.760 --> 16:44.640]  а их оказалось сразу две. Вот это чисто такой нельнень эффект. Вообще говоря, самые интересные
[16:44.640 --> 16:52.320]  вещи, физики, механики, экономики, в любой привязной области появляются там, когда появляются
[16:52.320 --> 16:58.120]  вот какие-то нельнень эффекты. Они бывают неожиданные. Здесь тоже эффект был достаточно неожиданный.
[16:58.120 --> 17:09.280]  И вот это потеря устойчивости предельной точки, переход в цикл называют бифуркацией. Называют
[17:09.280 --> 17:17.280]  бифуркацией. Переход из одного цикла в другой также называется бифуркацией. В математике, конечно,
[17:17.280 --> 17:23.840]  давно уже эту ситуацию отработали. Есть даже понятия такие, как теория бифуркации. Это
[17:23.840 --> 17:30.960]  не качественная теория. Обыкновенные дифференциальные уравнения. К ним тоже это отношение имеет.
[17:30.960 --> 17:44.560]  Чуть позже мы об этом поговорим. Вот. Ну, определение второе. Цикл П, Т, М, периода М
[17:44.560 --> 18:08.960]  называется притягивающим. Притягивающим. Если существует кисло К0 такое, что для всех К больше
[18:09.160 --> 18:22.120]  К0 наша последовательность ФК. ФК это вот эта последовательность, которую я вот только что
[18:22.120 --> 18:33.840]  писал вам. Распадается на М под последовательность. И каждый из которых сходится к точкам у1, у, М.
[18:33.840 --> 18:48.080]  В противном случае цикл называется отталкивающим. Еще раз. Еще одна деталь. Вот это последовательность,
[18:48.080 --> 18:57.840]  за которую мы получили ФК. Это фактически сложная функция. Представляет собой вот такую
[18:57.840 --> 19:04.880]  траекторию. Ее еще называют вот траекторией отображения. Отображение обозначает так.
[19:04.880 --> 19:14.160]  Ф от у1 КТ К от 0 до бесконечности. Ее еще называют эту последовательность траекторией отображения.
[19:14.160 --> 19:21.280]  То есть Ф от Ф от Ф и так далее. Вот это сложная функция. И здесь эта сложная функция появляется.
[19:21.280 --> 19:34.640]  Появляется в циклах. В этих циклах. Ну еще раз. Цикл ПМ его так обозначают либо так. Мы назовем
[19:34.640 --> 19:43.800]  притягивающим. Если существует такой номер фена последовательности К0. Такое, что для всех К больше
[19:43.800 --> 19:53.040]  К0, наша траектория отображения распадается на М под последовательности. Каждый из которых
[19:53.040 --> 20:04.920]  стремится к числу у1 многоточия ОМ. То есть к своей предельной точке. Первое пределение это
[20:04.920 --> 20:12.760]  определение точки периодической точки периода Н. То есть каждая точка на самом деле,
[20:12.760 --> 20:22.800]  каждая притягивающая точка является точкой периодической периода Н. Вот 1, 2 и так далее.
[20:22.800 --> 20:32.000]  Это вот периодические точки периода Н. Ну вот. И если дальше увеличивать лямбда,
[20:32.080 --> 20:45.200]  то появляются тоже довольно интересные эффекты. Прежде чем к ним перейти, давайте я вот еще о чем скажу.
[20:45.200 --> 20:59.200]  Для любого, то есть существует некий номер нашей последовательности, нашей траектории. Такое,
[20:59.200 --> 21:08.000]  что для любого большего номера наша траектория распадается или последовательности распадается
[21:08.000 --> 21:15.440]  на М под последовательности. Каждый из которых стремится к одной из точек у1, у2, у3, ОМ.
[21:15.440 --> 21:26.920]  Траектория. Вот смотрите, я вам написал Ф2, Ф3 и Фкат и так далее. Понятно, что это такое? Сложная
[21:26.920 --> 21:37.720]  функция. Ну скажем, Ф2 это есть Ф от Ф от У. Ну в данном случае, это у нас сейчас, давайте,
[21:37.720 --> 21:51.000]  что такое Ф? Ук плюс 1, это есть что у нас лямбда Ук, а здесь единица минус Ук. Наша Ф это вот наша
[21:51.000 --> 22:00.720]  функция. Ф от Ф, но вместо Ук вы ставите Ф от У. Если Ф3 еще раз ставите вместо У, Ф и так далее.
[22:00.720 --> 22:17.240]  Получаем такую сложную функцию. А где возникает? Сейчас вы увидите, вот если мы эту функцию построили,
[22:17.240 --> 22:26.280]  я вам дальше сказал, что вот это последовательность Фкат. Это есть не что иное, как, ну ее так называется,
[22:26.280 --> 22:35.960]  она так называется. Это есть траектория отображения. Отображение вот этого. Вот это отображение. Ну оно
[22:35.960 --> 22:41.240]  может быть здесь, функция Ф может быть другой, но мы сейчас рассматриваем конкретно эту функцию.
[22:41.240 --> 22:51.400]  Для другой функции свойства будут другие, и поведение будет другое. А это вот траектория отображения,
[22:51.400 --> 22:59.160]  это есть последовательность Фкат. То есть функция Ф от Ф, Ф от Ф от Ф и так далее, сложная функция.
[22:59.160 --> 23:13.280]  Это означает следующее. У нас есть последовательность Фкат. Легко и просто говорить,
[23:13.280 --> 23:22.680]  если она стремится к одной предельной точке, у со звездой. А здесь оказывается, что вот эта
[23:22.680 --> 23:36.440]  последовательность при неком К0, точнее при К, при любых К, которые больше К0, то есть после
[23:36.440 --> 23:45.920]  некого К0, появляется несколько под последовательств. Несколько под последовательств. Ну мы можем
[23:45.920 --> 23:57.800]  назначить как, например, у К1, у К2, ну лучше не один, а один сверху, один где-нибудь сверху,
[23:57.800 --> 24:08.120]  у К2 и так далее. И каждая из этих последовательств будет стремиться к своей точке у 1, у 2 и так далее.
[24:08.120 --> 24:20.840]  Понятно это или нет? Что одна последовательность на числовое все это, которая стремится к одной
[24:20.840 --> 24:28.000]  точке, это все понятно, все хорошо. Но оказывается, что одна часть последовательств может стремиться
[24:28.000 --> 24:36.760]  к одной точке, а другая часть к другой точке. Это уже будет появляться цикл периода 2. Ну на
[24:36.760 --> 24:43.080]  самом деле может быть М под последовательств, которые стремятся к М предельной точке. Это вот
[24:43.080 --> 24:51.480]  факты немного неочевидные и непривычные, и сразу в общем-то их понять непросто. На этом как раз и
[24:51.480 --> 25:00.600]  базируется теория биофоркации либо нелинейная динамика. Так, теперь давайте вот дальше. Дальше тут
[25:00.600 --> 25:07.800]  тоже ситуации очень такие интересные происходят. Увеличиваем лямб. Это, кстати говоря,
[25:07.800 --> 25:13.400]  можно без труда сделать на компьютерах, все промоделировать, и все эти эффекты увидеть
[25:13.400 --> 25:23.800]  лестники ламбрея, построить и так далее. Идем дальше. Пусть лямбра будет теперь больше 1
[25:23.800 --> 25:33.000]  плюс корень из 5. И меньше, ну давайте так, меньше равно, примерно 3,54. Там еще в периоде стоят цифры.
[25:33.000 --> 25:42.080]  Не будем говорить. Вот когда лямбра превышает эту цифру, 1 плюс корень из 5, происходит следующая
[25:42.080 --> 25:58.400]  биофоркация. Следующая биофоркация. Появляются 4 притягивающие точки. У5, У6, У7, У8. То есть говорят,
[25:58.880 --> 26:28.320]  что появляется цикл П4, либо периода 4. У5, У8. Ну и еще одна небаловодная
[26:28.320 --> 26:35.200]  важная деталь. Я дал определение притягивающих циклов. То есть, когда последовательства
[26:35.200 --> 26:41.360]  распадаются на М под последовательствами, каждый из которых стремится к своей предельной точке.
[26:41.360 --> 26:53.280]  Но каково условие существования такого цикла? То есть он может существовать, а может и не
[26:53.280 --> 26:59.480]  существовать. Кстати говоря, для большинства таких вот отображений, таких циклов не существует. Эта
[26:59.480 --> 27:08.040]  функция в этом плане уникальна. То есть, как говорится, повезло напал на ту функцию, которая имеет
[27:08.040 --> 27:16.920]  такие интересные свойства. Ну смотрим, что такое вот. Мы знаем, что для одной точки предельной у нас
[27:16.920 --> 27:26.280]  достаточно условия сходимости к ней. Это вот первая производная по модулю меньше единиц. Это для одной
[27:26.280 --> 27:33.360]  точки. А здесь у нас что получается? Функция f2, f3, fk. Это сложная функция. Производная сложная
[27:33.360 --> 27:39.840]  функция это что у нас? Это произведение. Производная сложная функция, вспоминайте,
[27:39.840 --> 27:46.560]  первое курс моего модоанализа. Поэтому здесь должно у нас войти произведение производных.
[27:46.560 --> 27:52.640]  Оно и входит. Я не буду просто сейчас доказывать соответствующие теоремы, иначе мы уйдем очень
[27:52.640 --> 28:01.200]  далеко от нашей темы. Но вводится такой параметр, который называется мультипликатор цикла PM. Это
[28:01.200 --> 28:12.240]  есть произведение производных f шлифа паукатая по к. К от единицы до m. Так называемый мультипликатор цикла.
[28:12.240 --> 28:17.080]  Это есть произведение производное. Берется он именно потому, что у нас есть сложная функция.
[28:17.080 --> 28:26.320]  Производная это есть произведение производных. И доказывается, и это теорема не будет доказывать,
[28:26.320 --> 28:37.920]  что достаточным условием существования притягивающего цикла является модуль мультипликатора по модулю.
[28:37.920 --> 28:43.960]  То есть модуль мультипликатора меньше единиц. То есть условия как бы аналогичны условию сходимости
[28:43.960 --> 28:50.120]  простых итераций. Но с учетом того, что это функция сложная.
[28:56.840 --> 29:06.160]  Ну и если мы пойдем дальше, то есть увеличивая лямбда. Я уже здесь не буду подробно говорить,
[29:06.160 --> 29:15.680]  так ну давайте п4. Да мы остановились на п4. Ну если его попытаться изобразить,
[29:15.680 --> 29:22.360]  но это уже на доске его изобразить непросто. Через лестницу ланаре это будет примерно следующее.
[29:22.360 --> 29:28.920]  Ну это наверное все-таки качественная будет такая картинка. Вот примерно вот такой будет цикл.
[29:28.920 --> 29:37.920]  Вот здесь будут вот эти точки. У 5 и так далее у 8. Будут 4 точки этого цикла.
[29:37.920 --> 29:43.760]  И вот в последствии будешь стремиться к этим 4 точкам.
[29:58.920 --> 30:08.920]  В литературе я вам дал книгу киевских математиков, которые довольно подробно исследовали только вот это одно отображение.
[30:08.920 --> 30:18.920]  То есть этому одному отображению была посвящена целая книга. Я вам рассказываю результаты этих исследований.
[30:18.920 --> 30:27.920]  Ну как подробно, мы конечно не имеем возможности о них говорить, но сами вот эффекты, которые появляются
[30:27.920 --> 30:36.920]  вот в этих нелинейных отображениях, конечно они так удивляют. Конечно это очень красивые эффекты.
[30:36.920 --> 30:44.920]  Очень неожиданные, очень красивые эффекты. И так если я дальше буду увеличивать лямбда больше 3,54,
[30:44.920 --> 30:53.920]  у меня появятся циклы P8, P16, ну вообще говоря P2.
[30:53.920 --> 31:02.920]  Ну конечно изображать их на наших графиках я уже не смогу. P4 это наверное последний цикл, который можно изобразить.
[31:02.920 --> 31:12.920]  Но на компьютерах вы можете получать эти циклы без особого труда. Это уже нужно на компьютере делать.
[31:12.920 --> 31:16.920]  Это вот такая удача была своего рода.
[31:16.920 --> 31:24.920]  Ну потом к этому отображению пришли вот сначала радиофизики, потом механики, ну и так далее.
[31:24.920 --> 31:30.920]  Потом даже вот, я уж не хочу углубляться, даже философы стали интересоваться этим отображением.
[31:30.920 --> 31:37.920]  Появилась теория эволюции через серию дефрукации. Может быть вы даже о такой теории эволюции слышали.
[31:37.920 --> 31:43.920]  Через серию дефрукации. Ну потом оказалось, что все-таки все намного сложнее.
[31:43.920 --> 31:49.920]  И как-то об этом стали немного забывать.
[31:49.920 --> 31:57.920]  Дефрукация это вот такое явление, характерное, математическое явление, характерное для нелинейных отображений.
[31:57.920 --> 32:07.920]  Ну вот если мы пойдем дальше, там изображать уже на доске это бесполезно, фактически получится что-то типа черного квадрата.
[32:07.920 --> 32:21.920]  Ну вот американский математик Фейгенбаум исследовал, что же будет если мы будем дальше и дальше увеличивать номер этого периода.
[32:21.920 --> 32:26.920]  В результате появились так называемые знаменитые каскады Фейгенбаума.
[32:26.920 --> 32:37.920]  Вот что они означают. Давайте вот сделаем по одной оси будем откладывать наши лямбды, лямбда 1, лямбда 2, лямбда 3.
[32:37.920 --> 32:45.920]  Как я делал, а по вертикальной оси уитые, то есть у1, у2, у3, то есть корни наших вот этих уравнений.
[32:45.920 --> 32:52.920]  То есть вот эти самые предельные точки или притягивающие точки.
[32:52.920 --> 32:59.920]  Что у нас получится? Ну первая точка понятна, это у1, лямбда 1, это точка 0.
[32:59.920 --> 33:16.920]  Дальше решение будет уходить, точку лямбда 2 это 0, лямбда 1 это вы помните, лямбда 2 это значит где-то 3, здесь будет у1.
[33:16.920 --> 33:22.920]  А дальше идет бифрукация, то есть лямбда 2 это 3, и точка 3 происходит бифрукация.
[33:22.920 --> 33:33.920]  Еще раз. При лямбда меньше единицы, да и решение 0.
[33:33.920 --> 33:43.920]  А кривая вот, я как раз вам объясняю, мы берем по вертикальной оси, откладываем решение нашего уравнения у1, у2, у3.
[33:43.920 --> 33:52.920]  То есть предельные точки, которые мы получали в цикле у1, у2, у3 и так далее.
[33:52.920 --> 33:59.920]  При лямбда меньше единицы у нас одна точка, одна состонарно-притягивающая точка.
[33:59.920 --> 34:13.920]  А теперь лямбда я увеличиваю до 3, и у меня по графике меняется, то есть вот эти корни от 0 до 1 единицы до 3.
[34:13.920 --> 34:21.920]  А нет, но это я все-таки рисую картинку качественную, вы можете нарисовать на компьютере точно эту картинку, просто вы вычислить все эти кривые.
[34:21.920 --> 34:25.920]  Ну и здесь я конечно качественно рисую, как вы сами понимаете.
[34:25.920 --> 34:36.920]  И вот здесь появляется бифрукация, точки лямбда 3, то еще одна бифрукация появляется, ну и так далее.
[34:36.920 --> 34:46.920]  То есть появляется так называемая серия бифрукаций, но я уже дальше не буду рисовать, потому как рисовать здесь сложно.
[34:46.920 --> 34:56.920]  То есть в каждой вот такой точке появляется бифрукация, когда цикл, скажем, П2 переходит в цикл П4, П4 в П8, П8 в П16 и так далее.
[34:56.920 --> 35:07.920]  Это все вот серия бифрукаций. И вот эта серия бифрукаций получила название каскады Фегенбаума, каскады бифрукаций Фегенбаума.
[35:07.920 --> 35:11.920]  Ну это на самом деле не столь график, сколь диаграмма.
[35:11.920 --> 35:19.920]  Вот это в плане удивления ваше справедливо, это более диаграмма, чем график, который нарисовал Фегенбаум.
[35:19.920 --> 35:23.920]  Но в этой диаграмме появилась вот такая, он нашел вот такую интересную особенность.
[35:23.920 --> 35:33.920]  Если взять точку 0,5 вот здесь на этой оси и провести вот такую линию, это вот надо было заметить.
[35:33.920 --> 35:43.920]  Далее он вот такие вот начал отрезки рисовать от этой линии до ближайшей метри этой диаграммы.
[35:43.920 --> 35:53.920]  Где-то здесь D1, D2, а будет где-то D3 и так далее.
[35:53.920 --> 36:03.920]  Вот то есть от этой горизонтальной линии уровняется 0,5 до ближайшей точки ветви этой диаграммы.
[36:03.920 --> 36:09.920]  Вот он такие величины нашел.
[36:09.920 --> 36:19.920]  И оказалось, что предел ДКТ к ДК плюс первому, приказ, стремящимся к бесконечности,
[36:19.920 --> 36:29.920]  есть некое число Альфа, которое вычислил, оказалось, что это 2,5, 0 и так далее.
[36:29.920 --> 36:35.920]  То есть число это оказалось постоянным для всех каскадов, для всех дефрокаций.
[36:35.920 --> 36:47.920]  Второй момент, который он заметил, предел вот такого отношения, лямбда К плюс 1 минус лямбда К.
[36:47.920 --> 36:55.920]  К это уже горизонтальная ось. Делим на лямбда К плюс 2 минус лямбда К плюс 1.
[36:55.920 --> 37:05.920]  Тоже некое число, он его назвал дельта, примерно 4,67, ну и там какие-то точки периода.
[37:05.920 --> 37:13.920]  Он точно вычислил все эти числа. Оказалось, что два этих предела постоянно.
[37:13.920 --> 37:19.920]  То есть это постоянные величины. Их назвали постоянными Фегенбаума.
[37:19.920 --> 37:25.920]  Потом появился термин теория универсальности Фегенбаума.
[37:25.920 --> 37:31.920]  Ну, это термин уже пока не буду о нем говорить.
[37:31.920 --> 37:42.920]  Важно то, что вот в этих каскадах появились некоторые закономерности, которые были обнаружены по тематикам.
[37:43.920 --> 37:52.920]  Далее эти каскады продолжаются до некоего лямбда, который назвали лямбда бесконечности.
[37:52.920 --> 38:02.920]  Это примерно 3,569 лямбда бесконечности, примерно такая величина.
[38:02.920 --> 38:12.920]  Вот эту величину назвали началом хаоса.
[38:12.920 --> 38:20.920]  Ну, хаос, правда, в этом плане это некий беспорядок. На самом деле, хаос математически это не совсем беспорядок.
[38:20.920 --> 38:24.920]  Есть понятие беспорядка в физике, а есть порядка хаоса.
[38:24.920 --> 38:28.920]  Хаос, он оказывается, имеет некие закономерности.
[38:28.920 --> 38:33.920]  А беспорядок, это считается вот что-то незакономерное, полное беспорядок.
[38:33.920 --> 38:45.920]  И вот действительно казалось, что после этого лямбда, когда уже трудно было различить эти бифуркации,
[38:45.920 --> 38:53.920]  вдруг появился цикл, который тоже начал делать бифуркации. Цикл был непростой.
[38:54.920 --> 39:00.920]  У нас были циклы П2 в степенниках, а здесь появились циклы П3 в степенниках.
[39:00.920 --> 39:03.920]  Это тоже совершенно нетриверальный результат.
[39:03.920 --> 39:09.920]  И математика как раз в конце прошлого века над этими результатами долго бились,
[39:09.920 --> 39:12.920]  чтобы изучить все особенности вот таких нелинейных отображений.
[39:12.920 --> 39:16.920]  Они действительно совершенно неочевидны, совершенно нетриверальны.
[39:16.920 --> 39:25.920]  Это все было доказано. Я просто вам говорю, что это результат уже исследований долгих и непростых.
[39:25.920 --> 39:31.920]  Но это все было показано, доказаны теоремы и так далее, о том, что должен появиться цикл П3.
[39:31.920 --> 39:36.920]  Сначала это кажется совершенно непонятно, потом все-таки были доказаны серии теорем,
[39:36.920 --> 39:40.920]  и действительно оказалось, что должен появиться цикл П3.
[39:46.920 --> 39:55.920]  Бифуркации не закончились. Здесь вот в хаотической области они продолжаются, но они уже теряют такую упорядоченность.
[39:59.920 --> 40:03.920]  Но видите, область, я сказал, на одной стороны мы ее хаотической называем,
[40:03.920 --> 40:09.920]  с другой стороны все-таки там остается, что-то остается, какие-то закономерности в этой хаотической области.
[40:09.920 --> 40:15.920]  Иначе бы не появился новый цикл. То есть это вот математический хаос, это не беспорядок.
[40:15.920 --> 40:20.920]  В физике есть понятие беспорядка и понятие хаоса. Это разные понятия.
[40:20.920 --> 40:24.920]  Здесь тоже самое в математике. Есть понятие беспорядка и понятие хаоса.
[40:24.920 --> 40:30.920]  То есть в хаосе есть определенные закономерности, которые сразу не видны, но они существуют.
[40:32.920 --> 40:41.920]  Ну вот, это вот то, что я хотел вам рассказать о том, какие сюрпризы нам могут преподнести нелинейные отображения.
[40:41.920 --> 40:45.920]  Это не только решение нелинейных уравнений системы уравнений.
[40:45.920 --> 40:49.920]  Конечно же, решение системы уравнений это важнейшая часть вычислительной математики.
[40:49.920 --> 40:56.920]  Они встречаются буквально на каждом шагу во всех предметах областях, во всех приложениях решений нелинейных уравнений.
[40:56.920 --> 41:06.920]  Но вот то, что вы можете получить не одно решение, а несколько, это сразу догадаться трудно.
[41:06.920 --> 41:09.920]  Это результат такой нетривиальный.
[41:10.920 --> 41:17.920]  Ну и, конечно же, вот таких отображений, как отображение физикульсов, в общем-то, не много.
[41:17.920 --> 41:26.920]  Если вы нарисуете любую функцию, просто какой-то коэффициент поставите, типа лямбда, и будете его менять,
[41:26.920 --> 41:30.920]  вы можете никакого каскада бифуркации не получить.
[41:30.920 --> 41:35.920]  Но вот это отображение интересно тем, что каскад бифуркации получается.
[41:36.920 --> 41:40.920]  Ну давайте вот эту тему я закончу, перейду к другой важнейшей теме.
[41:40.920 --> 41:43.920]  Правда, слово важнейшее на условиях.
[41:43.920 --> 41:49.920]  Здесь все темы у нас совершенно практически и фундаментально одновременно.
[41:49.920 --> 41:54.920]  И они везде используются при решении реальных задач.
[42:01.920 --> 42:03.920]  Сейчас мы поговорим вот какой теме.
[42:05.920 --> 42:10.920]  Приближение к функции, либо более правильное название,
[42:10.920 --> 42:13.920]  аппроксимация функций в функциональных пространствах.
[42:21.920 --> 42:29.920]  Ну, проще всего представить эту задачу, если мы имеем функцию одной переменной, числовую ось,
[42:29.920 --> 42:39.920]  функ, например, f от x, и мы ее хотим приблизить неким пареномом.
[42:39.920 --> 42:45.920]  Ну, для добавки слова обращенным пареномом q, p от x.
[42:45.920 --> 42:49.920]  Вот обращенным пареномом мы будем понимать следующую комбинацию.
[42:49.920 --> 43:01.920]  Эта сумма уужитет на phi z от x, z от 0 до f, где p стипа паренома.
[43:01.920 --> 43:08.920]  Значит, f от x может быть задано аналитически, а может быть задано по точкам.
[43:08.920 --> 43:14.920]  Конечно, в практике чаще всего эта функция f от x задается не аналитически, а по точкам.
[43:14.920 --> 43:17.920]  Но теоретически она может быть задана в явном виде.
[43:18.920 --> 43:22.920]  И нам ее нужно приблизить вот таким обобщенным пареномом.
[43:22.920 --> 43:25.920]  Почему я говорю не пареном, а обобщенным пареномом?
[43:25.920 --> 43:29.920]  Дело в том, что у нас здесь стоят функции пижритые.
[43:29.920 --> 43:35.920]  Пижритые – это система базистых линейно-независимых функций.
[43:35.920 --> 43:41.920]  Часто их делают степенными, это наиболее часто.
[43:41.920 --> 43:46.920]  Тогда мы просто говорим о многочленении или о пареноме, если это степенные функции.
[43:46.920 --> 43:51.920]  Этой функцией могут быть, например, экспоненты f степени kx.
[43:51.920 --> 43:55.920]  Это могут быть перигонометрические функции sin kx.
[43:55.920 --> 44:00.920]  Это могут быть гиперболические функции sin kx.
[44:00.920 --> 44:09.920]  Это все системы линейно-независимых функций, которые могут быть использованы в обобщенном пареноме.
[44:09.920 --> 44:12.920]  Хотя чаще всего действительно используются функции степенные.
[44:13.920 --> 44:18.920]  В радиофизике, конечно, используются очень часто экспоненты и перигонометрические функции.
[44:18.920 --> 44:22.920]  Это традиционные для радиофизиков родные функции.
[44:26.920 --> 44:31.920]  Степенными пареномами приближается очень много каких-то зависимости.
[44:31.920 --> 44:35.920]  Это и уравнение состояния, газа, плазма, чего угодно.
[44:36.920 --> 44:44.920]  Но очень много примерных областей, где используются вот такие обобщенные пареномы.
[44:44.920 --> 44:49.920]  И приближаются какие-то закононедности благодаря им.
[44:49.920 --> 44:54.920]  Давайте вот какой-нибудь простенький пример приведем для начала.
[44:54.920 --> 44:56.920]  Совсем простой.
[44:56.920 --> 45:01.920]  Проще уже, я, наверное, не смогу придумать.
[45:01.920 --> 45:06.920]  Если у нас будет функция f of x, мы о ней знаем, что она линейная.
[45:06.920 --> 45:12.920]  То есть у 0 плюс у 1 это коэффициенты этой функции, но нужно использовать функцию линейной.
[45:12.920 --> 45:15.920]  Проще уже, но константы это соседние интересы.
[45:15.920 --> 45:17.920]  И есть три ее значения.
[45:17.920 --> 45:24.920]  Ну, не ее значения, а значения недалеко от этой функции f it и f it.
[45:24.920 --> 45:28.920]  Ну, пусть будет и 0, 1, 2.
[45:28.920 --> 45:34.920]  То есть три точки недалеко от нашей функции.
[45:34.920 --> 45:36.920]  Вот наша прямая.
[45:36.920 --> 45:39.920]  По трем точкам провести прямую, как вы знаете, может только в одном случае.
[45:39.920 --> 45:42.920]  Если все три точки лежат на этой прямой.
[45:42.920 --> 45:45.920]  А здесь мы получили эти точки, например, экспериментально.
[45:45.920 --> 45:48.920]  И они никак не будут лежать на одной прямой.
[45:48.920 --> 45:52.920]  Они будут немного разбросаны этой прямой.
[45:52.920 --> 45:58.920]  Давайте построим такую функцию погрешности.
[45:58.920 --> 46:00.920]  С it это будет так.
[46:00.920 --> 46:02.920]  Ну, с каторя давайте.
[46:02.920 --> 46:09.920]  У 0 плюс у 1 х каторя минус f каторя.
[46:09.920 --> 46:13.920]  0, 1, 2.
[46:13.920 --> 46:21.920]  То есть как раз для трех точек построим вот такую функцию погрешности.
[46:21.920 --> 46:26.920]  А далее введем следующую функцию phi от у 0, у 1.
[46:26.920 --> 46:37.920]  Это уже будет функция, которая будет характеризовать все три погрешности.
[46:37.920 --> 46:40.920]  Summa xi it квадрат.
[46:40.920 --> 46:42.920]  Ее называют квадратичным отклонением.
[46:42.920 --> 46:45.920]  То есть от 0 до 2.
[46:45.920 --> 46:47.920]  Три точки.
[46:47.920 --> 46:50.920]  Ну или это будет у нас summa.
[46:50.920 --> 46:58.920]  У 0 плюс у 1 х ка минус f ка в квадрате.
[46:58.920 --> 47:01.920]  Ну и ка от 0 до 2.
[47:01.920 --> 47:03.920]  То есть вот такая функция отклонения.
[47:03.920 --> 47:05.920]  Ее можно назвать целевой функцией.
[47:05.920 --> 47:13.920]  Потому как, наверное, вы уже догадались, о чем я буду говорить.
[47:13.920 --> 47:17.920]  Эту функцию нам нужно минимизировать.
[47:17.920 --> 47:24.920]  Минимизировать мы можем по коэффициентам у 0 и у 1.
[47:24.920 --> 47:30.920]  И найти у 0 и у 1 эти коэффициенты, соответствующие минимуму этой функции.
[47:30.920 --> 47:35.920]  Не помните, как такой этот метод называется?
[47:35.920 --> 47:38.920]  Методный метчик квадрата, совершенно верно.
[47:38.920 --> 47:44.920]  Мы с ним уже по крайней мере в физических лабораторных сталкивались.
[47:44.920 --> 47:47.920]  Это действительно очень популярный метод.
[47:47.920 --> 47:48.920]  Популярно почему?
[47:48.920 --> 47:52.920]  Потому что своей простотой и реализацией простой.
[47:52.920 --> 47:57.920]  Но когда вы доталкиваетесь на что-то простое в учлительных методах,
[47:57.920 --> 48:04.920]  сразу же после того, как изучили метод, нужно думать о том, какие подводные камни у него есть.
[48:04.920 --> 48:08.920]  У меня на меньше квадратов есть серьезные подводные камни.
[48:08.920 --> 48:11.920]  Сейчас мы о них поговорим.
[48:11.920 --> 48:19.920]  Дальше вы, видимо, помните, как ищем коэффициенту у 0 и у 1.
[48:19.920 --> 48:22.920]  Сначала дифференцируем вот эту функцию.
[48:22.920 --> 48:25.920]  Это квадратическое отклонение по у 0.
[48:25.920 --> 48:29.920]  Дальше и второе по у 1.
[48:29.920 --> 48:35.920]  Что мы получаем в результате, если мы продиференцируем и проявляем к 0 производную?
[48:35.920 --> 48:37.920]  Два линейных уравнения.
[48:37.920 --> 48:39.920]  Система двух линейных уравнений.
[48:39.920 --> 48:42.920]  Но я уже ее решать не буду, бы ее без меры решить.
[48:42.920 --> 48:45.920]  Она слишком простая, чтобы не умереть.
[48:45.920 --> 48:48.920]  Вот мы нашли эти коэффициенты.
[48:48.920 --> 48:50.920]  Это один из вариантов.
[48:50.920 --> 48:52.920]  Второй вариант.
[48:52.920 --> 48:57.920]  У нас три точки и заданный вид функции, линейная.
[48:57.920 --> 49:00.920]  А теперь пусть у нас будут, например, две точки.
[49:00.920 --> 49:04.920]  У и равное 0 и 1.
[49:04.920 --> 49:06.920]  То есть у нас две точки.
[49:06.920 --> 49:10.920]  Через две точки мы знаем прямую, мы провести можем.
[49:10.920 --> 49:13.920]  Я уже не буду это расписывать.
[49:13.920 --> 49:18.920]  Это будут методы интерполяции.
[49:18.920 --> 49:23.920]  Кстати, об интерполяции мы будем отдельно говорить на следующей лекции.
[49:23.920 --> 49:26.920]  Тема тоже интересная и совершенно непростая.
[49:26.920 --> 49:31.920]  Оказывается, интерполяция это не просто провести прямую через две точки
[49:31.920 --> 49:33.920]  и параболу через три.
[49:33.920 --> 49:35.920]  Это гораздо более сложная ситуация.
[49:35.920 --> 49:38.920]  Да, через три точки вы проведете параболу без проблем.
[49:38.920 --> 49:41.920]  Но если вы будете количество точек увеличивать,
[49:41.920 --> 49:46.920]  то у вас появится явление неустойчивости.
[49:46.920 --> 49:50.920]  Как их, собственно говоря, медленно имеющие квадратов.
[49:50.920 --> 49:52.920]  Но об этом чуть позже.
[49:52.920 --> 49:55.920]  Об интерполяции давайте на следующей лекции поговорим.
[49:55.920 --> 49:59.920]  Сегодня мы поговорим о приближении функций в функциональных пространствах.
[49:59.920 --> 50:01.920]  Вы уже один из методов знаете.
[50:01.920 --> 50:05.920]  Но о нем я чуть-чуть поподробнее расскажу.
[50:05.920 --> 50:09.920]  Потому как там не все так просто, как кажется.
[50:09.920 --> 50:11.920]  В медленно имеющих квадратах.
[50:11.920 --> 50:13.920]  Не все так просто.
[50:13.920 --> 50:16.920]  Сейчас я сделаю небольшое отступление.
[50:16.920 --> 50:18.920]  Вот чем связано.
[50:18.920 --> 50:24.920]  Дело в том, что функцию, которую мы можем назвать целевой функцией,
[50:24.920 --> 50:26.920]  поскольку ее минимизируем,
[50:26.920 --> 50:28.920]  она не единственная.
[50:28.920 --> 50:32.920]  Мы можем и другие функции предложить в качестве меротклонения.
[50:32.920 --> 50:34.920]  Это вот меротклонение.
[50:34.920 --> 50:36.920]  Мы предложили квадратичные меротклонения.
[50:36.920 --> 50:39.920]  Вот так оно называется, квадратичные отклонения.
[50:39.920 --> 50:43.920]  Есть такие понятия, как среднее квадратичное отклонение.
[50:43.920 --> 50:46.920]  Оно выглядит следующим образом.
[50:46.920 --> 50:50.920]  Ну, если у нас заранее там какой-то количество точек,
[50:50.920 --> 50:52.920]  н точек, да, по-моему.
[50:52.920 --> 50:54.920]  Н точек, да.
[50:54.920 --> 50:56.920]  Оно как будет? Это кольни квадратные.
[50:56.920 --> 51:00.920]  Если у нас функция задана на отрезки аналитически,
[51:00.920 --> 51:02.920]  то это будет интеграл.
[51:02.920 --> 51:10.920]  Вот a до b наш обобщенный полином
[51:10.920 --> 51:15.920]  УП минус f от x в квадрате dx.
[51:15.920 --> 51:22.920]  Ну, кстати говоря, здесь я вам написал три точки.
[51:22.920 --> 51:25.920]  В принципе, если функция задана аналитически на отрезки,
[51:25.920 --> 51:30.920]  то тоже мы можем точно такую же вот отклонение,
[51:30.920 --> 51:33.920]  функцию квадратичного отклонения, составить для неправильной функции,
[51:33.920 --> 51:35.920]  которая задана аналитически, а не по точкам.
[51:35.920 --> 51:37.920]  Это никаких проблем нет.
[51:37.920 --> 51:40.920]  Но если функция задана по точкам,
[51:40.920 --> 51:44.920]  то среднее квадратичное отклонение будет выглядеть следующим образом.
[51:44.920 --> 51:46.920]  Здесь будет единица 9 на n.
[51:46.920 --> 51:52.920]  А здесь будет сумма УП от x минус...
[51:52.920 --> 51:54.920]  Ну, только от xk уже будет.
[51:54.920 --> 51:58.920]  Сумма у нас пока будет от 0 до n.
[51:58.920 --> 52:00.920]  От fk в квадрате.
[52:00.920 --> 52:02.920]  Ну, и все это под кольни квадрата.
[52:02.920 --> 52:04.920]  Это будет среднее квадратичное отклонение.
[52:04.920 --> 52:06.920]  Оно тоже используется в практике.
[52:06.920 --> 52:08.920]  Реже, но используется.
[52:08.920 --> 52:12.920]  Среднее квадратичное отклонение.
[52:12.920 --> 52:17.920]  Ну, и самое объективное отклонение
[52:17.920 --> 52:20.920]  носит название абсолютного отклонения.
[52:20.920 --> 52:22.920]  Что это такое?
[52:22.920 --> 52:24.920]  Абсолютное отклонение.
[52:24.920 --> 52:38.920]  Это тоже f.
[52:38.920 --> 52:40.920]  Наших параметров.
[52:40.920 --> 52:44.920]  У 0, простите, УП здесь у нас.
[52:44.920 --> 52:48.920]  Здесь исправки УП.
[52:48.920 --> 52:52.920]  У нас степень полинома ЯП обозначил.
[52:52.920 --> 52:56.920]  ЯП пусть будет и останется, чтобы мы не путались.
[52:56.920 --> 53:00.920]  А вот абсолютное отклонение для функции одной переменной
[53:00.920 --> 53:02.920]  будет следующее.
[53:02.920 --> 53:06.920]  Это будет максимум по отрезку АВ.
[53:06.920 --> 53:14.920]  Вот такого модуля QP от x минус f от x.
[53:14.920 --> 53:18.920]  То есть максимальное отклонение
[53:18.920 --> 53:20.920]  полинома от нашей функции.
[53:20.920 --> 53:24.920]  Это отклонение, которое называется абсолютным отклонением.
[53:24.920 --> 53:30.920]  Оно оказалось наиболее трудным для реализации, для исследования.
[53:30.920 --> 53:34.920]  Но оно интересно вот чем.
[53:34.920 --> 53:38.920]  Дело в том, что Верштраш доказал очень замечательную теорему
[53:38.920 --> 53:40.920]  по поводу абсолютного отклонения.
[53:40.920 --> 53:42.920]  Она выглядит следующим образом.
[53:42.920 --> 53:48.920]  Пусть функция f от x непрерывно
[53:48.920 --> 53:50.920]  на отрезке АВ.
[53:50.920 --> 53:52.920]  То есть одно единство переводит.
[53:52.920 --> 53:54.920]  Непрерывно в функции.
[53:54.920 --> 53:56.920]  Больше и больше никаких.
[53:56.920 --> 54:02.920]  В этом случае существует единственный
[54:02.920 --> 54:06.920]  так называемый полином наилучшего приближения.
[54:06.920 --> 54:08.920]  Давайте его обозначим так.
[54:08.920 --> 54:10.920]  QP, но с волной.
[54:10.920 --> 54:12.920]  Чтобы отличить его просто от полинома.
[54:12.920 --> 54:14.920]  Полином наилучшего приближения.
[54:14.920 --> 54:18.920]  Q равный этой сумме, которую мы писали.
[54:18.920 --> 54:22.920]  Давайте самому эти коэффициенты обозначим.
[54:28.920 --> 54:34.920]  Коэффициент доставляет минимум абсолютного отклонения.
[54:34.920 --> 54:40.920]  То есть вот этой функции, которую я написал.
[54:40.920 --> 54:46.920]  Этим абсолютным отклонением очень сильно привлекло внимание математиковый исследователь.
[54:46.920 --> 54:50.920]  Потому что для него, оказывается, существует полином наилучшего приближения.
[54:50.920 --> 54:54.920]  На котором указал В. Штрасс.
[54:54.920 --> 55:00.920]  Чуть забегая вперед, скажу, что для задачи интерполяции такой полином был найден.
[55:00.920 --> 55:02.920]  Эта задача была решена Чебышовым.
[55:02.920 --> 55:04.920]  Мы об этом полиноме будем говорить.
[55:04.920 --> 55:06.920]  Это совершенно уникальное явление.
[55:06.920 --> 55:08.920]  Чебышов занимался другой задачей.
[55:08.920 --> 55:12.920]  Но вот нашел полиновный наилучшего приближения.
[55:12.920 --> 55:14.920]  Лучшего просто уже не существует.
[55:14.920 --> 55:18.920]  Он доказал терим соответствующую теорему.
[55:18.920 --> 55:30.920]  А вот для задачи неинтерполяции, например, когда количество точек превышает степень полинову плюс один,
[55:30.920 --> 55:34.920]  эта задача оказалась очень непростой.
[55:34.920 --> 55:36.920]  В этом смысле нет наивнейших квадратов.
[55:36.920 --> 55:40.920]  Он не совсем точный, но он очень прост для реализации.
[55:40.920 --> 55:46.920]  В гляде случаев он просто незаменим по своей простоте и эффективности.
[55:46.920 --> 55:48.920]  Но в гляде случаев его поменять нельзя.
[55:48.920 --> 55:50.920]  Об этом мы сейчас поговорим.
[55:50.920 --> 55:54.920]  Еще одна деталь, друзья, которую я хотел вам заметить.
[55:54.920 --> 56:00.920]  Смотрите, вот я вам пишу пары чисел x и t, f и t.
[56:00.920 --> 56:08.920]  Ничего они вам не напоминают из терминологии методов машинного обучения.
[56:08.920 --> 56:12.920]  Это есть обучающая выборка терминологии в машинном обучении.
[56:12.920 --> 56:14.920]  Просто обучающая выборка.
[56:14.920 --> 56:16.920]  И как в машинном обучении построено?
[56:16.920 --> 56:22.920]  Есть некая исходная массив данных, есть отклик на эту исходную массив данных.
[56:23.920 --> 56:25.920]  Вот то, что мы имеем.
[56:25.920 --> 56:32.920]  И нам нужно построить какие-то функции, которые имеют отношение к этим двум массивам данных.
[56:32.920 --> 56:38.920]  В данном случае мы строим функцию заданную, линейную функцию.
[56:38.920 --> 56:45.920]  То есть если мы имеем заданную функцию, заданную полином, заданную обучающую выборку.
[56:45.920 --> 56:47.920]  Кстати, ее называют еще прецедентом.
[56:47.920 --> 56:50.920]  В машинном обучении ее называют прецедентами.
[56:50.920 --> 56:54.920]  Дальше мы строим целевую функцию и минимизируем ее.
[56:54.920 --> 56:57.920]  Это типичный ход метода машинного обучения.
[56:57.920 --> 57:00.920]  Ну, правда, очень простой.
[57:00.920 --> 57:03.920]  Но это типичный гид машинного обучения.
[57:03.920 --> 57:09.920]  Когда мы имеем на основании обучающей выборки некую целевую функцию,
[57:09.920 --> 57:14.920]  минимизируем ее и получаем какую-то функцию с заданными свойствами, которую мы хотим получить.
[57:14.920 --> 57:19.920]  Кстати говоря, задача интерполяции тоже является задачей машинного обучения.
[57:19.920 --> 57:21.920]  Мы с ним неоднократно столкнемся.
[57:21.920 --> 57:26.920]  Ряд задач, которые считаются классическими задачами вычислительной математики,
[57:26.920 --> 57:32.920]  являются задачами, которые сейчас называют задачей машинного обучения.
[57:32.920 --> 57:38.920]  На самом деле эти задачи были довольно давно поставлены и просто назывались по-другому.
[57:38.920 --> 57:40.920]  Просто назывались по-другому.
[57:40.920 --> 57:44.920]  А у нас с этими задачами основатель этих задач академик Журавлев Юрий Иванович,
[57:44.920 --> 57:51.920]  который до сих пор жив в 50-х годах, начал заниматься и называл их методами распознавания.
[57:51.920 --> 57:59.920]  Но потом параллельно американские математики занимались, они дали название машинного обучения.
[57:59.920 --> 58:07.920]  Хотя сам Журавлев и его ученик, к сожалению, ушедший от нас недавно академик Журавлев, мой старый друг,
[58:07.920 --> 58:13.920]  называл их либо обучением по прецедентам задачи машинного обучения, что очень правильно,
[58:13.920 --> 58:18.920]  обучением по прецедентам, то есть по парам обучающих парам,
[58:18.920 --> 58:22.920]  либо задачами нелинейной или обобщенной экстраполяции.
[58:22.920 --> 58:26.920]  Это тоже более правильное название, чем название машинного обучения.
[58:26.920 --> 58:31.920]  Но потом даже эти задачи начали называть задачами искусства интеллекта.
[58:31.920 --> 58:40.920]  Вы знаете, честно говоря, я не знаю специалистов по искусству по задачам машинного обучения, которым бы нравился этот термин искусственный интеллект.
[58:40.920 --> 58:49.920]  Это тоже вот термин, который придумали, ну не знаю, для рекламы что ли.
[58:49.920 --> 59:03.920]  Это тоже, по-моему, американский термин, у нас назывался автоматикой, что-то с автоматом связано, теперь это называется по-другому.
[59:03.920 --> 59:13.920]  Ну в принципе, все это было известно, сейчас просто в связи с развитием компьютерной техники, конечно, эта ситуация очень резко развивается, очень резко и очень серьезно развивается.
[59:13.920 --> 59:19.920]  Появляется робота, которые раньше не могли быть созданы, потому что все они основаны на компьютерах и так далее.
[59:19.920 --> 59:28.920]  Ну это я так между делом заметил, что метод машинного обучения были известны довольно давно, только назывались по-другому.
[59:28.920 --> 59:38.920]  Перейдем дальше. Итак, давайте вернемся к квадратичному отклонению.
[59:39.920 --> 59:46.920]  То есть я имею в виду метод наименьших квадратов.
[59:46.920 --> 01:00:00.920]  То есть технически, как он реализуется, вот я вам написал это, он реализуется достаточно просто, ну как говорится, я вам заведу в деталях реализации.
[01:00:00.920 --> 01:00:19.920]  Итак, у нас есть функция, пришли ее значение, точку давайте их, f от x ката, f ката обозначим, есть полином, f от x полином в степени p.
[01:00:19.920 --> 01:00:35.920]  Соответственно у нас есть уравнение q, p от x ката равняется f ката, то есть в точках ката значение полиновных функций должны совпадать.
[01:00:35.920 --> 01:00:41.920]  Это условие. Но на самом деле оказывается не все так просто.
[01:00:41.920 --> 01:00:51.920]  Как мы чуть дальше узнаем, в антрополяс они действительно совпадают, а вот для, скажем, для наименьших квадратов они совпадать не могут.
[01:00:51.920 --> 01:00:57.920]  Мы получаем переопределенную систему иллюминия как юридическое уравнение, которую как-то надо решать.
[01:00:57.920 --> 01:01:02.920]  Хотя вы знаете прекрасно, что если система переопределена, то она решения не имеет.
[01:01:03.920 --> 01:01:06.920]  Решать ей все как-то надо. Что значит как-то надо?
[01:01:06.920 --> 01:01:14.920]  Это значит, что мы ее будем решать в некотором смысле, то есть искать, как говорят математики, обобщенное решение этой системы уравнений,
[01:01:14.920 --> 01:01:19.920]  которая конечно не может являться решением переопределенной системы уравнений.
[01:01:19.920 --> 01:01:29.920]  То есть если мы, это у нас получилась система линейных, переопределенная система линейных уравнений, естественно я ее выпишу.
[01:01:30.920 --> 01:01:34.920]  Мы сейчас пускали обновить, это будет примерно следующее.
[01:01:34.920 --> 01:01:47.920]  У0 на финоль, здесь у нас х0 плюс у1, феодин, х0, ну плюс тогда это первое уравнение я пишу.
[01:01:47.920 --> 01:01:56.920]  Уп, хп на х0 равняется х0, ну и так далее.
[01:01:56.920 --> 01:02:00.920]  Второе уравнение аналогичное, ну давайте я последнее уравнение напишу.
[01:02:00.920 --> 01:02:12.920]  У0 на финоль на х, н у нас будет дать, у нас н уравнений плюс у1 на п1 на х, ну и плюс тогда нет.
[01:02:12.920 --> 01:02:22.920]  Уп, хп на х, н равняется фин, ну вот такая система уравнений.
[01:02:22.920 --> 01:02:36.920]  Здесь, как я уже говорил, вектор У относится к пространству РП, например к Евклидову пространству, линейной векторной пространства.
[01:02:36.920 --> 01:02:44.920]  А вектор правой части относится к пространству РН.
[01:02:45.920 --> 01:02:54.920]  Матрица А этой системы уравнений Н на П прямоугольная, где Н трога больше П.
[01:02:54.920 --> 01:02:58.920]  То есть система переопределена.
[01:02:58.920 --> 01:03:05.920]  Ну вот, поэтому здесь нам придется говорить о неком обобщенном решении.
[01:03:06.920 --> 01:03:12.920]  Я уже начал об этом говорить, мы строим некую функцию отклонений.
[01:03:12.920 --> 01:03:20.920]  Это функция у0, уп, ну давайте квадратичная функция пусть будет.
[01:03:20.920 --> 01:03:28.920]  У нас квадратичная функция отклонения, это у нас будет сумма по К от 0 до N.
[01:03:28.920 --> 01:03:42.920]  А здесь у нас будет наш полином, сумма у и ж это наш полином, хк от 0 до П, минус fк.
[01:03:42.920 --> 01:03:48.920]  Все это в квадрате. То есть вот эта функция квадратичного отклонения.
[01:03:48.920 --> 01:03:52.920]  Она в реализации самая простая и самая удобная.
[01:03:52.920 --> 01:03:57.920]  Поэтому, конечно, в первую очередь люди смотрят, давайте использовать на меньше квадратов.
[01:03:57.920 --> 01:04:02.920]  Ну и в общем-то трудно в этом отказать, исследовать.
[01:04:02.920 --> 01:04:05.920]  Но несет с ним просто, оказывается.
[01:04:05.920 --> 01:04:10.920]  Дальше мы что делаем? Дальше мы делаем то, что я уже делал только для трех точек.
[01:04:10.920 --> 01:04:14.920]  Мы дифференцируем эту функцию по каждому из ужитых.
[01:04:14.920 --> 01:04:21.920]  Да их по D ужитая равняется 0, g у нас меняется от 0 до P.
[01:04:21.920 --> 01:04:26.920]  То есть у нас получается система линей алгебридических уравнений по этому порядку.
[01:04:26.920 --> 01:04:32.920]  С квадратной матрицы. Вот что нам дает метод линей на квадратах.
[01:04:32.920 --> 01:04:37.920]  Система уравнений с квадратной матрицы, которую мы можем решить.
[01:04:37.920 --> 01:04:41.920]  Давайте посмотрим на эту квадратную матрицу.
[01:04:46.920 --> 01:04:54.920]  Если мы продиференцируем, я это не буду делать, это такая техническая работа, вы ее без меня сделаете.
[01:04:54.920 --> 01:04:57.920]  И мы получим следующую систему уравнений.
[01:04:57.920 --> 01:05:07.920]  Только я веду еще одно понятие скалерного произведения векторной функции phi и на phi g.
[01:05:07.920 --> 01:05:12.920]  Это будет phi i t на х от х t на phi g t.
[01:05:12.920 --> 01:05:19.920]  Вот х, пятая сумма по к от 0 до n.
[01:05:19.920 --> 01:05:24.920]  Это будет скалерное произведение таких векторных функций.
[01:05:24.920 --> 01:05:33.920]  Так вот, если мы ведем такое скалерное произведение, то полученные системы линей уравнений в этом можете получить сами без проблем.
[01:05:33.920 --> 01:05:37.920]  И обязательно получите следующим образом.
[01:05:37.920 --> 01:05:46.920]  Скалерное произведение phi 0 на phi 0 на у 0 плюс phi 0 и 1 на у 1 и так далее.
[01:05:46.920 --> 01:06:01.920]  Это первое уравнение phi 0 на phi p, а здесь скалерное произведение phi 0 на правую часть.
[01:06:01.920 --> 01:06:04.920]  Тоже скалерное произведение векторов.
[01:06:04.920 --> 01:06:11.920]  Это первое уравнение, но второе уравнение тоже можно записать phi 1 на phi 0 на у 0.
[01:06:11.920 --> 01:06:19.920]  Многоточие здесь будет phi 1 на phi p на у p.
[01:06:19.920 --> 01:06:23.920]  Это будет скалерное произведение phi 1 на f.
[01:06:23.920 --> 01:06:26.920]  И последнее уравнение давайте напишем.
[01:06:26.920 --> 01:06:36.920]  Последнее уравнение это будет phi p на phi 1 у 0 плюс многоточие и здесь будет phi p на phi p.
[01:06:36.920 --> 01:06:46.920]  Скалерное произведение phi p на phi p, у p и в правой части скалерное произведение phi p на f.
[01:06:46.920 --> 01:06:53.920]  Вот посмотрите, вам незнакома матрица этой системы уравнений?
[01:06:53.920 --> 01:06:57.920]  Ничего подобного не встречали нигде?
[01:06:57.920 --> 01:07:00.920]  Какой ваш инер погромче?
[01:07:00.920 --> 01:07:03.920]  Встречали.
[01:07:03.920 --> 01:07:11.920]  Встречали. Как называется эта матрица?
[01:07:11.920 --> 01:07:14.920]  Матрица грамма.
[01:07:14.920 --> 01:07:18.920]  Какие свойства замечательные у этой матрицы грамма?
[01:07:18.920 --> 01:07:25.920]  Которые позволяют не доказывать теорему существования единственности решения данной задачи медно-именьших квадратов.
[01:07:25.920 --> 01:07:31.920]  Оно существует и единственное. Всегда существует и всегда единственное.
[01:07:31.920 --> 01:07:34.920]  Она симметрична и положительно определенна.
[01:07:34.920 --> 01:07:37.920]  В чем замечательные свойства матрицы грамма?
[01:07:37.920 --> 01:07:44.920]  И казалось бы, чего еще лучше, гениальный метод и все здорово.
[01:07:44.920 --> 01:07:48.920]  Ну вот был такой замечательный математик Гильберт.
[01:07:48.920 --> 01:08:00.920]  Он привел контрпример, который показал, что на самом деле при высоких степенях, в случае степенных функций, базовых,
[01:08:00.920 --> 01:08:03.920]  методно-именьших квадратов применять нельзя.
[01:08:03.920 --> 01:08:11.920]  В реальной жизни выше пятой, ну может быть шестой степени следователи не поднимаются.
[01:08:11.920 --> 01:08:15.920]  Дальше начинается явление неустойчивости.
[01:08:15.920 --> 01:08:21.920]  Хотя примерно до пятой и четвертой степени все хорошо, метно-именьших квадратов просто реализации.
[01:08:21.920 --> 01:08:26.920]  Неплохо работает и так далее.
[01:08:26.920 --> 01:08:31.920]  Вот давайте я этот пример Гильберта приведу.
[01:08:31.920 --> 01:08:42.920]  Гильберт привел пример для степенных функций, то есть базисные функции, степенные.
[01:08:42.920 --> 01:08:48.920]  Ну вот если вы возьмете, поставите...
[01:08:48.920 --> 01:08:51.920]  Что?
[01:08:51.920 --> 01:08:54.920]  Она что?
[01:08:54.920 --> 01:09:02.920]  А, откуда появилось? Я взял и продиференсировал D, вот эти все производные.
[01:09:02.920 --> 01:09:05.920]  Так сейчас сколько у нас времени осталось?
[01:09:05.920 --> 01:09:09.920]  Так времени у нас немного осталось, да?
[01:09:09.920 --> 01:09:13.920]  Ну давайте приведу пример Гильберта.
[01:09:13.920 --> 01:09:16.920]  Для этого у нас, я думаю, время будет.
[01:09:16.920 --> 01:09:26.920]  Оказывается, что если мы приближаем функции полиновами, то полиновы не должны иметь высокую степень.
[01:09:26.920 --> 01:09:31.920]  Иначе появляется явление неустойчивости.
[01:09:31.920 --> 01:09:35.920]  Пусть у нас будет полиновку P от X.
[01:09:35.920 --> 01:09:39.920]  Это полиновка со степенными баллевскими функциями.
[01:09:39.920 --> 01:09:44.920]  Их степени же от 0 до P.
[01:09:44.920 --> 01:09:51.920]  И Х пусть будет на отрезочке 0.1.
[01:09:51.920 --> 01:09:58.920]  Значит, если мы применим вот такого степенного полинову метно-именьших квадратов,
[01:09:58.920 --> 01:10:03.920]  то сделаю то, что я делал раньше, вы это сделаете очень легко без меня.
[01:10:03.920 --> 01:10:08.920]  То мы тоже получим, естественно, систему линейных алгоритмических уравнений.
[01:10:08.920 --> 01:10:13.920]  Она будет выглядеть следующим образом.
[01:10:13.920 --> 01:10:16.920]  Вот я пишу так, работа Гильберта была записана.
[01:10:16.920 --> 01:10:20.920]  ХП плюс 1 на У. Х – это матрица Гильберта.
[01:10:20.920 --> 01:10:23.920]  Она так и получила название матрицы Гильберта.
[01:10:23.920 --> 01:10:28.920]  На У равняется F.
[01:10:28.920 --> 01:10:32.920]  Здесь У – это, как обычно у нас, вектор.
[01:10:32.920 --> 01:10:37.920]  У0, УП. Вектор П этого порядка.
[01:10:37.920 --> 01:10:42.920]  Правая часть F – это тоже вектор.
[01:10:42.920 --> 01:10:46.920]  Но давайте я его в строчу выпишу, там поставлю знак транспонирования.
[01:10:46.920 --> 01:10:52.920]  Интеграл от 0 до единицы F dx.
[01:10:52.920 --> 01:10:55.920]  Интеграл тоже от 0 до единицы.
[01:10:55.920 --> 01:10:59.920]  Ну, здесь многоточие поставлю. ХП dx.
[01:10:59.920 --> 01:11:04.920]  Это вот вектор, но здесь я знак транспонирования поставлю, чтобы знали, что это вектор столбец.
[01:11:04.920 --> 01:11:11.920]  Вот. И матрица Гильберта. Самое главное, как говорят, вишенка на торте.
[01:11:12.920 --> 01:11:16.920]  ХП плюс 1 – это матрица Гильберта.
[01:11:16.920 --> 01:11:20.920]  Ну, вы это все возьмите и получите честным образом.
[01:11:20.920 --> 01:11:23.920]  И плюс G минус 1.
[01:11:23.920 --> 01:11:28.920]  И здесь и G от единицы до П плюс 1.
[01:11:28.920 --> 01:11:33.920]  До П плюс 1. Вот это знаменитая матрица Гильберта.
[01:11:33.920 --> 01:11:35.920]  Чем она знаменита?
[01:11:35.920 --> 01:11:43.920]  Гильбертт показал, что в этом случае матрица Гильберта очень плохо обусловлена.
[01:11:43.920 --> 01:11:47.920]  Даже вот здесь не идет. Она совсем плохо обусловлена.
[01:11:47.920 --> 01:11:53.920]  А, следовательно, решать систему уравнения высокого порядка нельзя.
[01:11:53.920 --> 01:12:03.920]  Например, для P равного единицы параметр обусловленности матрицы оказывается район 9.
[01:12:03.920 --> 01:12:12.920]  А для P равного 9 параметров обусловленности оказался не 9, а 10 в девятой степени.
[01:12:12.920 --> 01:12:15.920]  То есть это очень плохая обусловленность.
[01:12:15.920 --> 01:12:19.920]  Вот что сделал Гильбертт.
[01:12:19.920 --> 01:12:23.920]  Очень сильно испортил настроение.
[01:12:23.920 --> 01:12:32.920]  Но тем не менее, опять же, я говорю, что не всегда нужно приближать функции при новом высокой степени
[01:12:32.920 --> 01:12:34.920]  и достаточно невысоких степеней.
[01:12:34.920 --> 01:12:38.920]  Тогда мета на мете с квадратов прекрасно используется.
[01:12:38.920 --> 01:12:43.920]  Просто в реализации и вообще просто.
[01:12:43.920 --> 01:12:47.920]  Но для дальнейшего нужно смотреть на свойства функций,
[01:12:47.920 --> 01:12:51.920]  поскольку система оказывается плохо обусловленной.
[01:12:51.920 --> 01:12:54.920]  Ну вот, на сегодня тогда мы закончим.
