[00:00.000 --> 00:10.400]  Всем доброго дня, мы с вами продолжаем наш курс по компиляторам. Сегодня у нас шестая лекция,
[00:10.400 --> 00:16.520]  да, мы тут пытались посчитать какая у нас лекция, с учетом перерывов, но вроде справились. Значит,
[00:16.520 --> 00:23.080]  сегодняшняя тема у нас интересная и, наверное, я так скажу, что если бы мы с вами проходили
[00:23.080 --> 00:28.280]  полноценный курс по компиляторам, наверное, мы бы полноценно имеется в виду годовой или вообще бы
[00:28.280 --> 00:33.120]  занимались компилятором, это был бы там, не знаю, отдельный полусемистровый или семистровый курс.
[00:33.120 --> 00:41.880]  Да, тут как раз сидят люди с кафедрой Испрану, мы передаем вам привет. И сегодня как раз мы
[00:41.880 --> 00:46.040]  познакомимся с этой темой. Я оставил некоторые блоки для того, чтобы просто было понимание,
[00:46.040 --> 00:51.680]  куда в сторону оптимизации можно копать. Наша цель все-таки дойти до конца компилятора,
[00:51.680 --> 00:57.760]  поэтому мы этот момент пропустим. Дополнительно мы с вами в прошлый раз говорили про оптимизацию
[00:57.760 --> 01:04.960]  иара, да, то есть мы с вами построили дерево промежуточного представления, и мы сразу сказали,
[01:04.960 --> 01:10.800]  что у нас это дерево промежуточного представления больше представлено именно для целочисленных
[01:10.800 --> 01:16.600]  типов, то есть там по факту нету типа Bool, поэтому у нас там возникали некоторые веселые конструкции,
[01:16.600 --> 01:27.600]  вот, и наша цель будет сегодня от них же избавиться. Опа, бах, перезагрузка случилась. Вот,
[01:27.600 --> 01:38.600]  и поэтому нам нужно поговорить про кононизацию этого дерева, заодно вывести некоторые основные
[01:38.600 --> 01:44.360]  понятия, которые так или иначе просто есть в современных языках промежуточного представления,
[01:44.360 --> 01:50.120]  в том же самом LVM, поэтому нам нужно сегодня как раз привести все к виду кононизации дерева и
[01:50.120 --> 01:55.080]  после этого уже все это разбирать. Мы находимся с вами сейчас на стадии оптимизации, то есть мы
[01:55.080 --> 02:00.640]  потихоньку движемся в нашей цели. Напомню, что к концу семестра, на самом деле, я бы скажу так,
[02:00.640 --> 02:08.240]  к середине к концу апреля хочется добежать до последней стадии. Хочется добежать до последней
[02:08.240 --> 02:12.920]  стадии для того, чтобы мы с вами все детально разобрали. Посмотрим получится или нет, ну,
[02:12.920 --> 02:19.120]  еще дополнительные темы тоже рассмотрим в нашем курсе. Итак, давайте вспомним, что у нас есть. У нас
[02:19.120 --> 02:24.920]  с вами было в прошлый раз яр дерева, то есть мы с вами решили строить яр в виде дерева. У нас с
[02:24.920 --> 02:32.160]  вами в этой конструкции есть следующие инструкции. У нас с вами есть expression, у нас с вами есть
[02:32.160 --> 02:37.880]  statement и у нас есть expression list для вызова аргументов функции. Пока что у нас нету statement
[02:37.880 --> 02:44.720]  листа и хотелось бы, как ни странно, взять список, у нас есть sequence, sequence, sequence, sequence,
[02:44.720 --> 02:50.240]  хотелось бы привести его в линейный вид, то есть чтобы можно было положить statement list. Понятно,
[02:50.240 --> 02:55.920]  что если мы строим современные яры, то там это просто так получается. Просто мы применяем
[02:55.920 --> 03:03.520]  pattern строитель и при помощи применения pattern строитель мы как раз и получим statement list,
[03:03.520 --> 03:09.000]  когда мы будем добавлять каждый statement последовательно. Итак, цель на сегодня
[03:09.000 --> 03:16.080]  построить конструкцию яр дерева раз, во-вторых, понять, что такое basic block и разбить яр дерева
[03:16.080 --> 03:22.800]  на составные части, которые называются basic block. После того, как мы с вами построим уже
[03:22.800 --> 03:31.160]  наборы basic block, мы с вами попробуем провести оптимизацию этих деревьев. Итак, давайте вспомним,
[03:31.160 --> 03:37.360]  какие у нас есть проблемы в яр дереве. У нас, значит, смотрите, у нас есть инструкция вида
[03:37.360 --> 03:44.840]  e-sec. В чем она заключается? Она заключается в следующем, что у нас с вами нужно получить
[03:44.840 --> 04:04.120]  некоторые expression. Как сложно. То есть у нас есть... Что это означает? Это означает, что на шаге 1
[04:04.120 --> 04:13.640]  нам нужно вычислить значение statement, а после этого на шаге 2 вернуть expression. Что это дает нам в
[04:13.640 --> 04:19.720]  точки зрения исполнения? Это нам дает нелинейность исполнения нашего алгоритма. То есть такие
[04:19.720 --> 04:25.080]  инструкции парсить уже намного сложнее, потому что нам нужно вычислить side effect, возможно вычислять
[04:25.080 --> 04:32.640]  side effect не сразу в нашем коде. То есть каким-то образом нужно будет преобразовать эти составные
[04:32.640 --> 04:44.480]  части. Давайте проверим, может быть кто-то там в Zoom заходил. Просто в waiting room один человек
[04:44.480 --> 04:56.120]  сидел, а теперь его нету. Да, наожидался. Мы слишком долго разбирали. Вот, и во-вторых, для того,
[04:56.120 --> 05:02.280]  чтобы представить, решить эту проблему, нам нужно вынести e-sec на самый верхний уровень. Почему?
[05:02.280 --> 05:09.720]  Потому что e-sec на самом верхнем уровне просто становится sequence. Мы его можем легко вынести и
[05:09.720 --> 05:16.680]  предобработать сначала. То же самое, что мы делали в C-стандарте, когда мы сначала объявляем
[05:16.680 --> 05:21.600]  переменные, а потом только с ними работаем. И дополнительно хотелось бы понять, как работает
[05:21.600 --> 05:27.040]  conditional jump, потому что conditional jump это тоже веселье и нам нужно правильно выставить порядок этих
[05:27.040 --> 05:39.440]  conditional jump. Итак, если мы с вами смотрите, посмотрим на вот этот код. Comparer dx 0, а дальше мы
[05:39.440 --> 05:46.480]  говорим jump, если ответ да, то мы прыгаем в метку 7, а вывод если нет jump, то дальше должен сразу идти
[05:46.480 --> 06:07.600]  false branch. Вот, то есть нам нужно каким-то образом наши jump правильно поставить. Дальше, значит,
[06:07.600 --> 06:14.320]  если у нас есть какие-то колы, то мы должны прерываться с вами и мы должны тем самым
[06:14.320 --> 06:20.880]  регламентировать порядок обхода нашего дерева. И вот смотрите, есть еще одна проблема. Представьте
[06:20.880 --> 06:27.800]  себе, что у нас есть бинарная операция, а дальше идет call и call. У нас проблема в том, что нам
[06:27.800 --> 06:34.720]  нужно сохранять регистры. То есть мы вызвали один call, нам нужно сохранить регистр сразу где-то,
[06:34.720 --> 06:41.680]  и потом сразу вызовет второй call. То есть пока что этого нет. Хотелось бы от таких инструкций в
[06:41.680 --> 06:47.840]  ER дереве отойти. Понятно, что call у нас возвращает expression, по идее нам нужно бы этот expression
[06:47.840 --> 06:55.440]  сразу куда-то сохранить в памяти. То есть нам нужно решать будет вот такие вот проблемы.
[06:55.440 --> 07:03.520]  Давайте сейчас поговорим следующее. О следующем, что образно говоря, каноническое ER дерево,
[07:03.520 --> 07:07.920]  то есть дерево, которое в принципе уже можно каким-то образом представлять, работать с ним,
[07:07.920 --> 07:15.160]  это дерево, в котором нет операции sec или esec. Мы должны избавиться от всех операций esec раз,
[07:15.160 --> 07:20.040]  а все операции sec можно превратить просто в последовательский команд. То есть у нас
[07:20.040 --> 07:25.960]  останется statement list. У нас получается код будет линейным. Потому что сейчас нам в ER никто не
[07:25.960 --> 07:33.640]  запрещает делать нелинейный код. То есть у нас внутри sec много sec. И дальше смотрите, для того,
[07:33.640 --> 07:38.840]  чтобы избавиться от бинарных вызовов, родителям каждого кола должен быть либо expression, либо
[07:38.840 --> 07:46.680]  move tmp, то есть либо операция store. Потому что иначе у нас возникает проблема с вызовом инструкций.
[07:46.680 --> 07:54.520]  Вот, давайте как раз решать эти проблемы. Проблемы, которые у нас есть. У нас могут
[07:54.520 --> 08:00.280]  быть узлы, у которых имеется два ребенка кол, то есть тогда у нас есть проблема. Либо у нас есть
[08:00.280 --> 08:06.240]  узлы с операцией esec и есть необходимость поднять секвенсы на самый верхний уровень.
[08:06.240 --> 08:15.200]  Поехали решать. Значит, первое call. Вы не поверите. Так, давайте посмотрим на код. Что мы делаем? Вот
[08:15.200 --> 08:20.080]  представьте, что у нас есть функция call, которая принимает на себе функцию и набор аргументов.
[08:20.080 --> 08:26.560]  Тогда мы ее можем переписать вот в таком страшном виде. Я, блин, дайте я переводкну проектор. Я надеюсь,
[08:26.560 --> 08:44.480]  что это поможет. Я в зоме пишу, если что. Я сделаю. Возможно, у меня проектор обладает
[08:44.480 --> 08:54.480]  свойством антикоммунативности. Да, действительно, у меня проектор обладает свойством
[08:54.480 --> 09:01.800]  антикоммунативности. А нет, обладает коммунативностью. Вот. Давайте разберем, что здесь же написано. Значит,
[09:01.800 --> 09:09.720]  у нас есть функция call, которая вызывается некоторым аргументом. И что мы делаем в данном аспекте?
[09:09.720 --> 09:15.760]  Давайте попытаемся понять, что здесь написано. Нет, у меня проектор обладает свойством коммунативности,
[09:15.760 --> 09:32.320]  видимо. Что это означает? А? Ну, смотрите. Значит, мы пишем следующее, что у нас, значит,
[09:32.320 --> 09:51.400]  T. Это call. F-args. И дальше что мы делаем? Возвращаем этот T. Да, то есть, как бы, мы получается
[09:51.400 --> 09:58.120]  заранее операцию call, которая у нас есть, которая может быть сагрегирована с другим call. Мы сразу
[09:58.120 --> 10:03.640]  ее оборачиваем в то, что, вот, выполни, пожалуйста, сохрани нам значение, пожалуйста, в определенном
[10:03.640 --> 10:14.040]  регистре, а после этого верни этот регистр. Так, что у нас с оскобочным балансом? Да, да. Нет,
[10:14.040 --> 10:27.240]  все нормально. Наоборот. Не, все нормально. То есть, вот такой хитрый вещь. Хитрая вещь. Но у нас
[10:27.240 --> 10:32.160]  возникает проблема. Какая? У нас появляется новый e-sec. То есть, у нас появляется сайд-эффект.
[10:32.160 --> 10:38.440]  Значит, нам нужно теперь каким-то образом взять вот этот e-sec, который есть, и от них избавиться.
[10:38.440 --> 10:46.560]  Давайте как раз попробуем от них избавиться. И здесь начинается веселье. Значит, тут нам
[10:46.560 --> 10:52.720]  нужно будет явно просто рисовать те команды, которые у нас есть. Первая операция заключается в
[10:52.720 --> 10:59.280]  следующем. Представьте себе, да, сразу скажу, что если мы поднимем e-sec на самый верхний узел,
[10:59.280 --> 11:05.040]  вот это важно, мы его можем превратить в операцию sequence. Значит, смотрите, представьте себе,
[11:05.040 --> 11:23.240]  что у нас есть операция e-sec, здесь s1, здесь у нас s2 и expression. Но давайте подумаем,
[11:23.240 --> 11:29.520]  что это означает. Это означает, что нам нужно сначала вычислить s1, после этого вычислить
[11:29.520 --> 11:37.480]  s2, типа вот это наш сайд-эффект, а после этого вычислить e. Да, но мы в принципе можем в
[11:37.480 --> 11:45.360]  сайд-эффекте последовательно вычислить s1 и s2, а после этого вернуть результат. То есть,
[11:45.360 --> 11:58.720]  вот у нас сайд-эффект, а здесь мы последовательно вычисляем s1 и s2. Здесь нужно сказать следующее
[11:59.200 --> 12:06.280]  вещь. Так, я тут применю для любителей формализмов и доказательств. Короче, будем упрощать эту
[12:06.280 --> 12:12.720]  инструкцию, связанную с тем, что у нас будет метод спуска, так сказать, она противоположится
[12:12.720 --> 12:18.720]  аналогу индукции, по количеству e-sec в нашем дереве, плюс суммарная высота этих e-sec. То есть,
[12:18.720 --> 12:24.720]  здесь мы как количество e-sec уменьшили на 1, то есть, здесь было 2 e-sec, здесь был 1 e-sec. Да,
[12:24.720 --> 12:29.400]  причем, если мы возьмем visitor, то это легко делается. То есть, мы просто проверяем,
[12:29.400 --> 12:37.720]  что правый тип у нас e-sec, тогда мы переписываем правое под дерево налевое. Так, с этим разобрались?
[12:37.720 --> 12:47.720]  Просто такая вот оптимизация. Так, дальше. Собственно, если у нас e-sec находится в какой-то
[12:47.720 --> 12:55.560]  бинарной операции. Да, причем, смотрите, важно заключается в том, что как бы эта операция у нас
[12:55.560 --> 13:01.880]  идет до нашего дерева. Значит, давайте рассмотрим аспекты. Значит, если у нас есть бинарная операция,
[13:01.880 --> 13:08.360]  смотрите, здесь важно, что это первый оперант. Кстати, скажите, пожалуйста, как вы думаете,
[13:08.360 --> 13:12.280]  почему важно, что в e-sec здесь пока рассматривается первый оперант и не второй?
[13:17.720 --> 13:23.600]  Да, а теперь представьте, что у нас есть второй оперант, как бы он тоже создает сайд-эффект,
[13:23.600 --> 13:27.000]  и, возможно, этот сайд-эффект повлияет на значение первого оператора.
[13:27.000 --> 13:43.640]  Ну, e-sec говорит, да? Ну, то есть, сначала сайд-эффект, потом выражение. Вот, ну и смотрите,
[13:43.720 --> 13:50.200]  главная суть такова, что если у нас есть какой-то сайд-эффект до выполнения либо унарных операторов,
[13:50.200 --> 13:55.840]  либо операторов, которые есть бинарных, то в нем выражение состоит на первом месте.
[13:55.840 --> 14:08.680]  Что у нас получается? Мы его можем просто вынести наверх. Логично? Да, то есть, как бы,
[14:08.680 --> 14:14.160]  единственный момент нужно отслеживать. Типа, у нас эта операция какая? Типа,
[14:14.160 --> 14:18.120]  можем ли мы ее сразу в sequence превратить или не можем сразу превратить в sequence? То есть,
[14:18.120 --> 14:23.760]  если у нас на выходе expression, то, наверное, не можем. Если у нас какой-то statement,
[14:23.760 --> 14:33.600]  то мы поднимаем наверх и переобразуем его в statement. Так, понятно? Все, хорошо. Что
[14:33.600 --> 14:40.480]  делать со вторым оператором? А вот здесь уже приходится делать некоторые финты ушами,
[14:40.480 --> 14:45.120]  да? Потому что нам нужно хранить результат нашего операнда. Представьте себе, что у нас
[14:45.120 --> 14:52.400]  есть бинарная операция, дальше у нас есть operation, E1 и еще один E sec. Давайте это буду
[14:52.400 --> 15:11.000]  рисовать, наверное, чтобы это было видно. Наверное, вот сюда. Я сразу приношу извинения всем тем,
[15:11.000 --> 15:20.480]  у кого есть признаки эпилепсии, потому что я, честно, не знаю, из-за чего наш проектор
[15:20.480 --> 15:42.040]  коррептить. Значит, смотрите, вот у нас здесь оперант и биноб, SE1. Вот у нас statement. То есть,
[15:42.040 --> 15:46.440]  что у нас может быть? У нас statement может повлиять на значение выражения expression 1. Нам нужно от
[15:46.440 --> 15:54.480]  этого избавиться. Ну как от этого можно избавиться? Давайте подумаем. Мы можем сохранить результат T в E1,
[15:54.480 --> 16:07.280]  а после этого сделать операцию следующую. Мы вычисляем S, а после этого делаем бинарную
[16:07.280 --> 16:18.600]  операцию, связанную с тем, что мы вызываем наш оператор T. То есть, то, что мы сохранили в
[16:18.600 --> 16:22.760]  нашем промежуточном результате. То есть, нам так или иначе нужно какое-то промежуточное хранение.
[16:22.760 --> 16:32.080]  Так, ну хорошо. Давайте подумаем, почему здесь у нас будет выполняться индукционный переход.
[16:32.080 --> 16:41.080]  Вот это важно. Вот у нас вот это дерево, оно пишется вот так. То есть, смотрите,
[16:41.080 --> 16:49.720]  мы сначала в T записываем E1, потом мы используем S, а после этого мы делаем биноб. Скажите,
[16:49.720 --> 16:56.840]  пожалуйста, сколько ессеков у нас на самом деле здесь? Ну, кажется, что два. То есть,
[16:56.840 --> 17:08.120]  тут было один, тут было два. Во-первых, давайте я спрошу, вот эта конструкция понятна? А теперь
[17:08.120 --> 17:15.560]  смотрите трюк номер два. Мне кажется, мы это уже где-то умели делать. То есть, на самом деле,
[17:15.560 --> 17:21.480]  вот тот вот ессек, который у нас есть вот здесь, на самом деле он уберется. Просто
[17:21.480 --> 17:24.760]  последующий проход. То есть, мы это можем даже сделать in place. То есть, у нас, смотрите,
[17:24.760 --> 17:30.320]  получается ессек поднялся на уровень вверх. То есть, у нас теперь наш дерево упрощается.
[17:30.320 --> 17:37.880]  Вот, это значит следующее. А если у нас S не влияет на значение, то есть, смотрите, это если у нас S
[17:37.880 --> 17:43.480]  влияло на значение выражения, нам надо сохранить в регистре. Если мы внезапно понимаем, что S никаким
[17:43.480 --> 17:49.960]  образом не влияло на значение выражения E1, это в принципе можно сделать и посчитать. Ну, для этого
[17:49.960 --> 17:57.240]  нужен life-анализ. Мы можем просто ессек поднять. Но на самом деле, если так внимательно подумать,
[17:57.240 --> 18:04.080]  то можно вот это сразу не применять, а применять предыдущую операцию. Почему? Потому что мы
[18:04.080 --> 18:08.280]  можем просто на следующей стадии оптимизации компилятора как раз убрать эти инструкции,
[18:08.280 --> 18:24.280]  которые нам не нужны. Ну да, наша цель как раз сейчас, вот, у нас, короче, есть таракашка под
[18:24.280 --> 18:33.880]  названием ессек. Нам надо эту таракашку убрать в как можно большем количестве. Кстати, если,
[18:33.880 --> 18:39.160]  допустим, вам кажется, что это не очень полезная вещь, но это вообще тема связана с тем, что мы
[18:39.160 --> 18:46.840]  убираем любые сайд-эффекты. То есть, образно говоря, если у нас надо что-то. Да, кстати,
[18:46.840 --> 18:53.120]  в функциональном программировании это активно помогает. Так, ну и дальше тут есть некоторые
[18:53.120 --> 18:59.160]  инструкции. Давайте подумаем, когда у нас S может не влиять на E1. Ну на самом деле, если E1 это
[18:59.160 --> 19:05.800]  либо у нас константа, либо это название какой-то метки, либо S это эксп, а выражение в нем является
[19:05.800 --> 19:12.000]  константом. То есть набор вариантов не очень большой, но в принципе его можно использовать. Так,
[19:12.000 --> 19:17.720]  теперь смотрите, следующий момент заключается в том, что у нас ессек может находиться в экспрешен
[19:17.720 --> 19:24.080]  листе для вызов аргументов. Ну тогда на самом деле все достаточно просто. Смотрите, здесь у нас
[19:24.080 --> 19:32.080]  есть несколько вариантов. Собственно, зависит ли S от E1 или от E2, то есть влияет ли он на результаты.
[19:32.080 --> 19:38.640]  Если не влияет, то мы просто сначала выполняем statement test, потом передаем аргументы. Если у
[19:38.640 --> 19:45.680]  нас S влияет на E2, то нам нужно сохранить сначала все результаты во временную память, а потом
[19:45.680 --> 19:53.160]  использовать темповые регистры. То есть у нас получается, что нужно T присвоить E1, T2 присвоить
[19:53.160 --> 19:59.640]  E2, а потом уже вычислить значение, взять вот эти вот регистры, поднять их и как раз их передать
[19:59.640 --> 20:07.720]  в аргументы. Вот, если допустим, ну в зависимости от того влияет аргумент или нет, у нас наша
[20:07.720 --> 20:14.360]  инструкция будет либо больше, либо меньше. Вот, ну смотрите, поскольку у нас экспрешен лист
[20:14.360 --> 20:21.200]  находится всегда сразу там в аргументах вызова функции, да, то есть у нас это все применяется
[20:21.200 --> 20:26.200]  только в операции call, то мы как бы перед колом просто вставляем набор инструкций, которые у нас
[20:26.200 --> 20:32.840]  есть. То есть у нас получается был кол, да, внутри него есть сек. Мы просто перед этим колом вставим
[20:32.840 --> 20:45.600]  последствия операции и получаем наш результат. Да, значит, смотрите, утверждение, внутри есть сек,
[20:45.600 --> 20:55.600]  не может стоять в левом ребенке есть сек. Ну понятно, потому что у нас, если бы у нас был какой-то
[20:55.600 --> 21:06.240]  есть сек, а внутри него стоял есть сек, то это был бы экспрешен, а не statement. Есть сек это у нас
[21:06.240 --> 21:13.520]  экспрешен. Почему мы это доказываем? Потому что мы утверждение, что мы разобрали все варианты в
[21:13.520 --> 21:22.320]  нашем кейсе, потому что нам нужно сказать, что мы все утверждения перебрали, у нас количество
[21:22.320 --> 21:28.000]  есть секов уменьшается и вывод после этого будет, точнее количество есть секов у нас не увеличивается,
[21:28.000 --> 21:31.680]  а даже уменьшается. Вывод будет такой, что после всех оптимизаций у нас просто есть секов не
[21:31.680 --> 21:38.360]  останется. Так, ну смотрите, здесь у нас все понятно. Дальше второй оператор заключается в том,
[21:38.360 --> 21:48.200]  что если у нас родитель является есть секом, родитель есть сека экспорт, то это просто с. Да,
[21:48.200 --> 21:53.440]  то есть мы просто вернули наш экспрешен, поэтому нам достаточно просто выполнить этот statement. Ну вот,
[21:53.440 --> 21:59.760]  смотрите, значит, у нас есть сек в итоге останется ровно один, в конце концов он поднимется либо
[21:59.760 --> 22:06.000]  до экспрешена, да, либо до какой-то нормальной операции. Вот, значит, и от него можно будет избавиться.
[22:06.000 --> 22:19.000]  Все, есть секов у нас нет, мы их победили. Хорошо, так, этот сценарий понятен? Все, хорошо,
[22:19.000 --> 22:25.200]  то есть такая... И вторая вещь, это линеризация. Собственно, заключается в том, что если у вас
[22:25.200 --> 22:31.080]  внезапно sequence остался в какой-то левой части выражения, вдруг при построении яра, хотя такое
[22:31.080 --> 22:38.400]  скорее всего не будет, то вы можете ее перенести в правую часть, то есть переподвешиваем в левую часть
[22:38.400 --> 22:46.520]  направо. Вот, ну после этого все секвенсы можно будет убрать, вот, и у нас просто появится упорядоченный
[22:46.520 --> 22:52.120]  набор команд. Вот эта стадия называется линеризация, дерево яра. То есть теперь у нас как раз с вами
[22:52.120 --> 23:00.280]  есть линейный операнда, и это хорошо. Значит, и последняя вещь, которая заключается в том,
[23:00.280 --> 23:06.600]  что если, допустим, нам нужно будет поставить правильный порядок операции, то, в принципе,
[23:06.600 --> 23:12.920]  мы это тоже можем сделать. Да, если нам, допустим, не нужен jump в каком-то месте, то, в принципе,
[23:12.920 --> 23:21.080]  вот такая вот инструкция есть. То есть переставим, можно всегда переставлять true метки и false метки
[23:21.080 --> 23:26.240]  местами, потому что они как раз у нас не зависит друг с другом. Вот, и мы с вами после этого приходим
[23:26.240 --> 23:33.400]  к вот такой вот вещи. Эта абстракция называется basic block. И не поверите, она как раз есть во всех
[23:33.400 --> 23:40.680]  иарах. Даже, более того, скажу, если мы посмотрим LWM-овский иар, то там как раз используются активно
[23:40.680 --> 23:48.320]  basic block. То есть мы прямо на предыдущем семинаре смотрели, как они создаются. Вот basic block create,
[23:48.320 --> 23:53.000]  то есть у него есть... Что такое basic block? Значит, в чем она заключается? У нас с вами первая инструкция
[23:53.000 --> 24:00.240]  всегда label. Последняя инструкция... Тут я, кстати, неверно писал, тут надо уточнить. Это либо jump,
[24:00.240 --> 24:08.840]  либо conditional jump, либо... либо return, либо exit. Да, потому что у нас из функции можно вернуть
[24:08.840 --> 24:18.520]  значение какое-то, либо просто завершить код нашему. Вот, и между первой и последней инструкцией нет
[24:18.520 --> 24:27.840]  ни label, ни jump, ни cjump. Собственно, если внезапно у нас нет jump, то добавляем jump в следующую
[24:27.840 --> 24:38.760]  метку. То есть если у нас, смотрите, оказалось следующее, что у нас есть, допустим, L1, L2, и здесь
[24:38.760 --> 24:44.720]  ничего внезапно не было, да, ни jump, ни cjump, то мы просто делаем jump на метку L2.
[24:44.720 --> 24:56.200]  Вот. Вот. И если у нас есть последняя метка, jump add down. Ну, собственно, мы создаем метку down,
[24:56.200 --> 25:03.240]  либо мы делаем return инструкцию. В этом случае она работает. Вот. И в чем особенность именно
[25:03.240 --> 25:11.480]  basic block или базовых блоков? А то, что поскольку у нас любое начало это метка, а любой конец это
[25:11.480 --> 25:22.160]  прыжок в какую-то метку, то мы можем эти блоки менять местами в любом порядке. Вот. И это как раз полезно.
[25:22.160 --> 25:37.320]  Так. Так, ребят, я сейчас на секунду буквально... Так, продолжаем, да, пришлось мне отличиться на
[25:37.320 --> 25:43.320]  некоторое время. В общем, смотрите, что у нас такое basic block? Это у нас как раз инструкция, такой блок,
[25:43.320 --> 25:49.920]  который мы самостоятельно можем переставлять в разные места для того, чтобы каждым блоком
[25:49.920 --> 25:55.800]  оперировать независимо друг от друга. Итак, но на самом деле, когда мы будем транслировать все в
[25:55.800 --> 26:02.160]  Assembler, тут небольшое забегание наперед, нам, опять же, эти инструкции нужно будет линеризовать в
[26:02.160 --> 26:09.320]  каком-то определенном виде. Итак, еще у нас один небольшой перерыв. Значит, смотрите, у нас блоки
[26:09.320 --> 26:13.880]  могут идти в случайном порядке, поэтому мы можем их использовать как отдельные единицы в графе
[26:13.880 --> 26:20.200]  исполнения. Но все равно, когда вы читаете код на Assembler, он у нас плюс-минус тоже линейный. И важно,
[26:20.200 --> 26:27.360]  что там jump обычно не в две метки происходит, а в одну метку. Вот. Поэтому нам нужно будет код объединить
[26:27.360 --> 26:38.560]  снова. И как раз наша цель будет сделать такой код на Assembler с минимальным количеством швов. То есть
[26:38.560 --> 26:44.040]  что значит швов? Швов это значит, что мы берем и делаем некоторый jump. Вот. И как раз для этого мы
[26:44.040 --> 26:49.640]  можем сделать следующее. Организовать след. И это по сути блоков, которые соединены в виде цепочки.
[26:49.640 --> 26:56.920]  Соответственно, если у нас есть какой-то jump, то мы как раз летаем с этой цепочки. Ну, тут я
[26:56.920 --> 27:06.040]  хочу сказать следующее. У вас, наверное, не было курса по сложности вычислений, но... а? Есть. Был. Был.
[27:06.040 --> 27:10.920]  Значит, для того, чтобы решить эту задачу оптимально и создать минимальное количество блоков, нужно
[27:10.920 --> 27:20.800]  решить задачу coverset. Покрытие множества путями. Но эта задача НП полная. Так что... а? Ну, значит,
[27:20.800 --> 27:25.840]  мы будем скорее всего использовать какой-нибудь а-ля жадный алгоритм с некоторыми небольшими
[27:25.840 --> 27:32.440]  оптимизациями. Вот. Для того, чтобы построить блоки. Так. Значит, на самом деле, как строятся следы?
[27:32.440 --> 27:37.080]  Значит, пока не все вершины покрыты, достаем вершину, идем по графу выполнения, доставляя
[27:37.080 --> 27:44.080]  элементы в цепь. Для conditional jump преимущественно используем false ветку, потому что после false
[27:44.080 --> 27:52.840]  ветки зачастую нету переходов. То есть мы сразу двигаемся дальше. Вот. То есть это такая простая
[27:52.840 --> 28:00.400]  вещь. Значит, превращение AC jump в label от false. То есть, смотрите, если у нас был conditional jump в ветку
[28:00.400 --> 28:07.080]  label true, label false, то мы можем с вами сделать следующее. Менять true и false местами, и все будет
[28:07.080 --> 28:11.520]  замечательно. Ну, вот это приблизительно выглядит вот так. То есть, у нас есть какой-то conditional,
[28:11.520 --> 28:19.000]  A, B. Дальше у нас label true. После этого, если у нас есть jump в X, то мы переставляем как раз,
[28:19.000 --> 28:27.000]  ставим метку X, и после этого делаем jump в ветку с названием false. То есть это то, как мы переставляем
[28:27.000 --> 28:35.720]  conditional jump в ветку false. Так. Ну и наконец-таки, мы с вами наконец-таки уже избавились от всех
[28:35.720 --> 28:42.800]  блоков. Кстати, сразу скажу, что построение следов, трейсов идет после оптимизации. И наши
[28:42.800 --> 28:50.200]  требования для оптимизации. Значит, давайте подумаем, что нам нужно потребовать от оптимизации.
[28:50.200 --> 29:07.240]  Да. Да. Собственно, во-первых, безопасность. То есть, результат не должен меняться. Выгодность.
[29:07.240 --> 29:15.240]  Это было бы неплохо, чтобы количество операций у нас все-таки уменьшилось. Ну да, мы можем память
[29:15.240 --> 29:21.880]  уменьшать, можем увеличивать производительность. И третье, это взятие рисков. То есть, возможно,
[29:21.880 --> 29:27.560]  что у нас увеличится число регистров, и после этого у нас будет регистр spilling. То есть,
[29:27.560 --> 29:34.280]  мы скидываем их в оперативную память. Кстати, забавный момент. Рублика оптимизация. Знаете ли
[29:34.280 --> 29:41.840]  вы следующий момент? Это небольшая отсылка к курсе по куде. Вы берете видеокарту, значит,
[29:41.840 --> 29:50.640]  1080, запускаете на ней код. Какой это? X. Потом берете видеокарту, 3090, запускаете на ней тот же
[29:50.640 --> 29:58.440]  самый код X. Ну, обычно это, кстати, к нейросетям относится. На 3090, понятно, нейросет работает
[29:58.440 --> 30:05.920]  быстро. В сравнении с 1080. Код ровно такой же. Ну, как вы думаете, что происходит с потреблением памяти?
[30:05.920 --> 30:20.400]  Ну, то есть, представьте себе, образно говоря, на 1080 у вас один гигабайт в рам съелся. Как вы
[30:20.400 --> 30:32.880]  думаете, сколько в рам будет есть 3090 на той же самой сети? Больше. Там как раз больше процентов на
[30:32.880 --> 30:41.440]  30, на 40 будет оно. Ну, за счет того, что как раз по факту микропроцессор видеокарты раскладывает
[30:41.440 --> 30:57.200]  это все так, как ему надо, в памяти. За счет этого количество памяти увеличивается. Да-да-да-да. Да-да-да,
[30:57.200 --> 31:10.560]  такие. Ага. Да-да-да, то есть, вот такая вот хитрая вещь, и ее нужно просто учитывать,
[31:10.560 --> 31:17.200]  что за оптимизация Gnatsa можно количество оперативной памяти увеличить используемой. Так, ну,
[31:17.200 --> 31:22.200]  давайте поговорим, какие у нас есть возможности для оптимизации. Первое, это уменьшение оверхеда
[31:22.200 --> 31:27.880]  на имеющиеся абстракции, которые у нас есть. Значит, использование преимущества в специальных
[31:27.880 --> 31:33.840]  случаях. Это, знаете, такая кейс, это статистический анализ данных. То есть, вы просто берете
[31:33.840 --> 31:42.480]  какую-нибудь кодовую базу, скачиваете откуда-нибудь, с какого-нибудь GitHub. Ну, или еще... Ну, не, на самом
[31:42.480 --> 31:51.960]  деле, есть, кстати, статья, я, кстати, когда готовился к оптимизации, статья, октября 23-го
[31:51.960 --> 31:59.120]  года, использование LLM для оптимизации компиляторов. LLM — это большая языковая модель или отчет
[31:59.120 --> 32:03.400]  ГПТ. Ну, почти, да.
[32:03.400 --> 32:25.360]  Ну, да, да, то есть,
[32:29.360 --> 32:36.080]  ну да, на самом деле, история такая, что, по идее, мы можем прогнать количество переходов условных,
[32:36.080 --> 32:41.880]  замерить какой-то статистический анализ и дальше, как говорится, формула условного вероятности нам
[32:41.880 --> 32:46.720]  в помощь, грубо говоря. Бывает такое, что в большом количестве инструкций у нас, грубо говоря,
[32:46.720 --> 32:52.080]  мы обычно ожидаем, что в 60% случаев, ну, типа, мы думаем, что мы чаще после EFA прыгаем в ветку
[32:52.080 --> 32:59.600]  связанную с true, да, или нет условия, да, либо там не false return. Да, ну, понятно, что, собственно,
[32:59.600 --> 33:03.880]  если мы имеем просто, грубо говоря, матрицу вероятностных переходов, то мы можем действовать,
[33:03.880 --> 33:09.360]  как, образно говоря, шахматисты и сами устанавливать порядок операции, который мы хотим.
[33:09.360 --> 33:29.400]  Ну, да.
[33:29.400 --> 33:45.160]  Ну да, это динамическая оптимизация. Кстати, более того, если так говорить не чисто про компилятор,
[33:45.160 --> 33:53.520]  а вдруг кто-то внезапно зашел на этот ролик и вообще интересуется сетями, нейросетями, да, то на самом
[33:53.520 --> 33:57.920]  деле, эта же идея есть и в нейросетях. Называется динамическая квантизация, то есть, когда нужно
[33:57.920 --> 34:03.600]  уменьшить размер нейросети, вот, просто прогоняется, грубо говоря, большой сет, замеряется, в каких
[34:03.600 --> 34:10.040]  диапазонах у нас есть веса моделей, ну, типа, максимальные значения, которые выходят в тензоры,
[34:10.040 --> 34:16.640]  и под них как раз производится оптимизация. В итоге нейросети весят меньше. Ну, и здесь тоже, как бы,
[34:16.640 --> 34:21.960]  мы прогоняем статистику, понимаем, по каким блокам мы чаще всего переходим или прыгаем, ну, собственно,
[34:21.960 --> 34:27.440]  мы это можем сделать. Вот, ну, и последняя вещь — это связь между кодом и системными ресурсами. То
[34:27.440 --> 34:32.200]  есть, в принципе, если даже сами компиляторы позволяют компилироваться под определенный набор
[34:32.200 --> 34:39.640]  инструкций, такие как SSE, AVX и так далее. То есть, про них тоже не стоит забывать. Включать
[34:39.640 --> 34:45.840]  векторную инструкцию. Итак, значит, что касается уровня локальности оптимизации, их обычно выделяют
[34:45.840 --> 34:51.720]  четыре. Значит, первый уровень — это локальные оптимизации, они происходят внутри одного basic
[34:51.720 --> 34:57.360]  блока. Дальше у нас есть региональные оптимизации, то есть, у нас по факту оптимизация идет на уровне
[34:57.360 --> 35:03.960]  набора блоков, которые лежат, так сказать, в одном регионе относительно структурной операции. То
[35:03.960 --> 35:07.960]  есть, это, грубо говоря, внутри FA, внутри Вайла и так далее. Потому что там как раз тоже есть
[35:07.960 --> 35:13.560]  некоторое количество блоков, хотелось бы их тоже их разбирать. Глобальная оптимизация — это оптимизация
[35:13.560 --> 35:19.520]  не всего кода, важно. Это оптимизация внутри процедуры, то есть внутри функции. И у нас
[35:19.520 --> 35:27.760]  могут быть межпроцедурные оптимизации. Это оптимизация между процедурами. Да, есть еще
[35:27.760 --> 35:33.440]  великая link time оптимизация. Ну, я не знаю, рассмотрим или нет. Собственно, давайте вопрос.
[35:33.440 --> 35:45.520]  Inlining к какому уровню относится? Да, это межпроцедурная оптимизация. То есть, по-моему, в каких-то
[35:45.520 --> 35:49.920]  компиляторах, кстати, в той же самой куде, по-моему, поддерживается Fragma Forum Sandline.
[35:49.920 --> 36:00.800]  Да, да, да. То есть, как раз использовать inline, то есть, постановку аргументов. Значит, смотрите,
[36:00.800 --> 36:06.400]  локальные оптимизации на самом деле достигаются за счет перестановок внутри одного блока. То есть,
[36:06.400 --> 36:11.400]  блок — это как раз посредство инструкции, которое начинается одной меткой и заканчивается либо
[36:11.400 --> 36:19.160]  условно, либо безусловным переходом. Вот. И, значит, какие бывают виды локальных оптимизаций? Тут
[36:19.160 --> 36:26.040]  надо опять же сказать, почему это важно про локальные оптимизации. Потому что, как ни странно,
[36:26.040 --> 36:32.000]  у нас, если внимательно посмотреть на наши инструкции, которые у нас есть в компьютере,
[36:32.000 --> 36:39.800]  вот у нас есть обычно наш ассемлерные вставки. Но перед тем, как наш компилятор, наш код будет
[36:39.800 --> 36:45.640]  исполняться, на самом деле ассемлерный код перегоняется в код микропроцессора. Вот. И нужно
[36:45.640 --> 36:50.720]  понимать, что в микропроцессоре есть конвейерность, возможно, есть параллельные исполнения инструкции,
[36:50.720 --> 37:04.760]  и так далее. Да, поэтому, возможно, ему стоит помочь в этом деле. И если у нас есть некоторый набор
[37:04.760 --> 37:11.520]  регистров, которые могут считаться параллельно, как бы лучше это так и написать. Вот. Поэтому здесь
[37:11.520 --> 37:16.960]  еще одна из оптимизаций заключается в том, что у нас возникает перебалансировка дерева. То есть,
[37:16.960 --> 37:25.360]  опять же, у нас был sequence, мы его снова перегоняем в дерево и начинаем его балансировать. Да.
[37:25.360 --> 37:31.160]  Значит, первый алгоритм, который здесь есть, я пока что начну с самого сложного алгоритма и потом
[37:31.160 --> 37:36.000]  перейдем к более простым алгоритмам. Первый алгоритм называется local value numbering. Он на самом
[37:36.000 --> 37:44.360]  деле как раз помогает найти разные сложные вещи, так сказать. Да, вот. Да, ты, Михаил.
[37:44.360 --> 38:10.920]  Что, что, что? А, поэтому? Ну, господи. Понятно, у вас уже прямо курс по оптимизации, так сказать.
[38:14.360 --> 38:28.520]  Господи. О, господи, бедная. Ладно. Давайте все-таки тему разберем. Значит, смотрите,
[38:28.520 --> 38:33.600]  просмотрим следующий последствий с операцией. А стрелочка B плюс C, B стрелочка A минус D,
[38:33.600 --> 38:38.240]  C стрелочка B плюс C, D стрелочка A минус D. Вопрос. Как это можно оптимизировать?
[38:38.240 --> 38:55.480]  Нельзя. Ну да, D можно заменить на B. Да, потому что почему, кстати, C нельзя заменить на A? Да,
[38:55.480 --> 39:02.000]  потому что B меняется. Да, соответственно, нам нужно это уметь считать каким-то образом. Ну и здесь
[39:02.000 --> 39:07.120]  как раз веникает следующее, что для каждого набора переменных, ну или виртуальных регистров нам
[39:07.120 --> 39:13.080]  нужно запоминать, когда у них все было установлено в определенном порядке. Так, кстати,
[39:13.080 --> 39:20.200]  сразу скажу про ER. В этом случае с ER действует намного проще, потому что у нас там есть SSA,
[39:20.200 --> 39:25.840]  статик Single Assignment, и вот там как раз на ленту этого не надо делать и вычислять. То есть сразу
[39:25.840 --> 39:31.720]  понимаем, что оптимизация на уровне AST, возможно, это не очень хорошая затея. Все-таки лучше приводить
[39:31.720 --> 39:37.800]  это все к дереву ER. Значит, это можно оптимизировать вот таким образом. И алгоритм. Да, тут я сейчас его
[39:37.800 --> 39:42.160]  написал вот таким образом. Цель для каждой переменной виртуального регистров присвоить порядковый
[39:42.160 --> 39:47.760]  номер версии этого виртуального регистров. Ну и цель дальше следующая. Нам нужно будет завести
[39:47.760 --> 39:54.240]  хк таблицу с ключами вида операции EOPG, то есть, грубо говоря, переменная с историческим номером E
[39:54.240 --> 40:00.080]  будет взаимодействовать с историческим оператором G. Значит, если у нас новая операция, собственно,
[40:00.080 --> 40:06.400]  если у нас операция была, то мы ставим над результатом просто значение из хк таблицы, иначе мы
[40:06.400 --> 40:12.000]  добавляем в нашу хк таблицу новый ключ. То есть, если у нас есть, допустим, третья версия плюс сложить
[40:12.000 --> 40:17.840]  четвертую версию, то мы просто берем вот эту четвертую версию и вот эту ключ к таблице заменяем на то
[40:17.840 --> 40:25.600]  значение, которое мы записывали. Так, давайте я покажу алгоритм. Собственно, вот, новой версии добавляется
[40:25.600 --> 40:32.400]  хк. Вот представьте себе, вот у нас есть нумерация в правой верхней части слайда, у нас есть переменная
[40:32.400 --> 40:37.920]  B, которая имеет нулевой версию, и переменная C, которая имеет нулевой версию. Значит, когда мы записываем
[40:37.920 --> 40:46.240]  значение A, мы записываем вторую версию. После этого мы берем B, это A2-D3, то есть у нас появится
[40:46.240 --> 40:54.800]  3D равное тройке, мы ее записываем. Получаем на выходе B4. Дальше у нас будет C5, это B4 плюс C1.
[40:54.800 --> 41:02.920]  Не хватит видео, чтобы я это рассказывал. Вот у нас получается C5, а дальше смотрите,
[41:02.920 --> 41:07.640]  следующее, что у нас происходит. Мы достаем значение A, это двойка, и достаем значение D,
[41:07.640 --> 41:12.280]  это тройка. То есть, мы для каждой переменной храним номер версии, когда она была задействована в
[41:12.280 --> 41:18.840]  последний раз. Вот, поставили 3, и смотрите, что у нас происходит. У нас есть A2-D3, то есть мы можем
[41:18.840 --> 41:24.840]  как раз в хэштаблице заставить уже значение 2, 3 и минус, и понять, что это на самом деле B4,
[41:24.840 --> 41:31.560]  поэтому здесь значение будет, во-первых, B, а во-вторых, результат будет иметь тот же самый номер
[41:31.560 --> 41:38.280]  версии, то есть у нас по факту B и D будут разыменовывать один и тот же указатель. Точнее, не то,
[41:38.280 --> 41:41.760]  что они будут разыменовывать один и тот же указатель, мы просто будем использовать одно и
[41:41.760 --> 41:49.880]  тоже номер версии. Вот, это вот как раз алгоритм local value numbering. Контрольного мы по нему писать не
[41:49.880 --> 42:02.680]  будем. Можно попробовать его просто использовать для своих задач. Так, понятна суть алгоритма? Хорошо,
[42:02.680 --> 42:11.280]  значит, вторая вещь, которая совсем простая. Мы, значит, в local value numbering можем считать
[42:11.280 --> 42:17.720]  следующее, что если операция является операцией с нейтральным элементом группы, все знают,
[42:17.720 --> 42:36.160]  что такое группа. Ну да. Вот, то, в принципе, вот она табличка, которая здесь есть. Собственно,
[42:36.160 --> 42:40.480]  коммутативная операция, кстати, про коммутативность операции, коммутативные операции тоже должны
[42:40.480 --> 42:48.640]  видеть одинаковый хэш. Ну, логично. То есть, смена операции нам должна быть точно так же. То есть,
[42:48.640 --> 42:57.720]  можно считать, что у коммутативных операций регистр с меньшим индексом идет раньше. Ну, в общем,
[42:57.720 --> 43:05.520]  здесь несколько наборов инструкций, которые у нас есть. Значит, проблемы алгоритмов, которые у нас
[43:05.520 --> 43:11.520]  есть, нужно аккуратно отлавливать, изменилось ли значение после замены. То есть, как бы здесь у
[43:11.520 --> 43:21.480]  нас должен устанавливаться новый номер версии. Потому что иначе у нас алгоритм может пойти куда-то
[43:21.480 --> 43:25.800]  не туда. То есть, когда обращаемся к значению переменной А, здесь это тройка, а когда обращаемся
[43:25.800 --> 43:32.360]  А, здесь это четверка. Вот. И нужно, конечно же, аккуратно смотреть на неявные присвоения. То есть,
[43:32.360 --> 43:39.080]  это всякие указатели, элементы массива и так далее. А то иначе возникнет проблема в том, что вы
[43:39.080 --> 43:49.960]  объявляете, грубо говоря, в питоне. Какой там есть пример в питоне? Что-то вот такое можно написать.
[43:49.960 --> 44:00.280]  А равно 0 умножить на 5. А давайте-ка, кстати, это. Может быть, возьмем, что-нибудь напишем.
[44:00.280 --> 44:27.680]  Так, Python 3, да. Так? А, ненастроенные, да. Так. Да. А, они уже работают. В общем,
[44:27.680 --> 44:43.240]  тут есть какие-то подводные камни, в которых... А, ну так имеется в виду?
[44:43.240 --> 45:06.800]  О, да, да, да.
[45:06.800 --> 45:17.960]  Да. Ну, то есть, он понял, что это не примитивный тип, он взял, просто указатель расплодил.
[45:17.960 --> 45:46.280]  Ну, потому что... Ну, потому что int – это обертка над p-object.
[45:46.280 --> 46:03.880]  Да, в питоне все объект, в том числе int, load и все такое. А int передается, на самом деле, по ссылке, просто, когда ты меняешь значение, ты его копируешь и потом меняешь. Ну, да.
[46:03.880 --> 46:29.480]  А они создаются новую копию при изменении. Более того, я скажу следующее. Есть такая интересная, такой интересный язык, R называется. Наверное... А?
[46:29.480 --> 46:59.240]  Да. Во третью. R, да. R. И там есть два оператора. Второй mutable. А? Да, а первый присваивание.
[46:59.240 --> 47:13.240]  То есть, там явно есть mutable и mutable объекта. Вот. Ну, раз мы уже немножко отошли в сторону, как у нас обращение к полям класса обычно в любых языках программирования?
[47:13.240 --> 47:35.240]  Ага. Значит, не поверите, в R настолько продвинутый язык, что это переменная. Да, да. Это как подчеркивание в других языках программирования.
[47:35.240 --> 47:45.240]  А чтобы обратиться к полям, тут есть специальный символ доллар.
[47:45.240 --> 48:03.240]  Да, более того, R, если говорить про язык, он вообще веселый.
[48:03.240 --> 48:17.240]  Он заключается в том, что, вы не поверите, для интерпретатора он интерпретируемый, но если вы попытаетесь импортировать какой-то другой пакет и с ним работать...
[48:17.240 --> 48:31.240]  Ну да, ну нет, типа вы подключаете какую-то внешнюю библиотеку. То есть, что в питоне удобен? Вы импортируете библиотеку, потом можете поменять код, образно говоря.
[48:31.240 --> 48:37.240]  Зайти прям в код своей библиотеки, поменять что-то, там, допустим, прогресс-бар включить и запустить новую версию, у вас прогресс-бар будет работать.
[48:37.240 --> 48:49.240]  В Ари не так. В Ари внешние модули, они компилируемые. То есть, вы, когда устанавливаете пакет, он у вас его компилирует.
[48:49.240 --> 48:55.240]  Фитон, он, типа, тоже прикомпилирует, просто отслеживает, что если файл заменялся на декабилизатор.
[48:55.240 --> 49:04.240]  Ну да. Не-не-не, а можно прямо, когда точка py-файл меняю, мы даже можем не переустанавливать пакет.
[49:04.240 --> 49:15.240]  Когда точка py-файл импортите, он составляет файл.pyc, который не удаляет после окончания работы, чтобы в следующий раз переиспользовать.
[49:15.240 --> 49:21.240]  А если файл.pyc поменялся, то он удаляет файл.pyc, она его компилирует и использует.
[49:21.240 --> 49:31.240]  Кстати, вопрос тебе надо сыграть тогда. У вас есть программа, которая запускает сама себя, когда эта прошивка будет в питошке?
[49:31.240 --> 49:39.240]  Ну, ты это рассказывал. Она отслеживает передатки самой себя и дает репуршен юроризм.
[49:39.240 --> 49:41.240]  Ну да.
[49:41.240 --> 49:43.240]  Ну нормально.
[49:43.240 --> 49:53.240]  Вот как бы видно, что у нас, как говорится, нужно быть с указателями очень корректно и отслеживать явные изменения, в том числе и в исходном коде.
[49:53.240 --> 50:08.240]  Так, это что касается local value numbering. А если у нас есть вот такое вот линейризованное дерево, то было бы неплохо использовать его в нормальную версию, не сбалансированную версию.
[50:08.240 --> 50:14.240]  То есть как бы у нас, если дерево 8 операций, хотелось бы, чтобы оно выполнялось в 3 глубины, в 3 тактах.
[50:14.240 --> 50:23.240]  Есть некоторые проблемы, потому что ладно-то одно дерево операции, а что будет, если у нас есть операция, которая должна находиться в разных узлах дерева?
[50:23.240 --> 50:26.240]  То есть у нас есть узел 1, есть узел 2, они используют одну и ту же операцию.
[50:26.240 --> 50:30.240]  Поэтому нам нужно каким-то более грамотным образом это все переподвешивать.
[50:30.240 --> 50:35.240]  Более того, local value numbering умеет работать перед балансировкой.
[50:35.240 --> 50:46.240]  И знаете, здесь вот, я не знаю, вы наверное чуть помоложе, чем я, но, не знаю, застали, это отсылка к определенному мему.
[50:46.240 --> 50:50.240]  Значит, сколько деревьев вы видите на рисунке?
[50:50.240 --> 50:56.240]  Знаете, были передачи где-то лет 10-15 назад по телевизору, где деньги предлагали.
[50:56.240 --> 51:01.240]  Да, вот здесь точно так же. Сколько здесь?
[51:06.240 --> 51:12.240]  Ну, как-то хочется спросить, что такое дерево в случае 1,2 грамма?
[51:14.240 --> 51:17.240]  Скорость у нас вот так.
[51:17.240 --> 51:20.240]  У нас три вершины, смотрите, вот так.
[51:20.240 --> 51:23.240]  Вот так вот, три вершины, вот так вот.
[51:28.240 --> 51:31.240]  Существуют вершины, из которых достижимы остальные?
[51:36.240 --> 51:40.240]  Не, не весь граф.
[51:40.240 --> 51:46.240]  Но главное, что здесь у дерева должны быть дочерние узлы, хотя бы один дочерний узел у корня.
[51:46.240 --> 51:49.240]  Четыре здесь дерева.
[51:49.240 --> 51:55.240]  С корнем Y, с корнем Z, корень T1 и корень T2.
[51:55.240 --> 52:00.240]  Поэтому эту структуру нужно каким-то образом правильно расшифровывать.
[52:00.240 --> 52:06.240]  Видно, что у нас здесь операции, они каким-то образом должны быть еще и подвешены грамотным образом.
[52:06.240 --> 52:13.240]  Собственно, для этого нам нужно найти корни дерева, которые перевешивать так по факту нельзя.
[52:13.240 --> 52:16.240]  У нас должна быть завязка на корень.
[52:16.240 --> 52:22.240]  И мы говорим следующее, что у нас корень дерева, значит, если наш узел может быть корнем дерева,
[52:22.240 --> 52:26.240]  если он как минимум два раза используется как определенный ребенок.
[52:26.240 --> 52:31.240]  То есть вот этот узел T1 у нас используется два раза.
[52:31.240 --> 52:37.240]  И второе, если T1 используется как ребенок еще в какой-то другой операции.
[52:37.240 --> 52:40.240]  И с разным набором оперантов.
[52:40.240 --> 52:45.240]  То есть у нас получается, что этот узел используется в разном наборе операций.
[52:45.240 --> 52:48.240]  Это описание алгоритма.
[52:48.240 --> 52:53.240]  По факту, смотрите, вот у нас есть дерево, у нас есть вот такой набор операций.
[52:53.240 --> 52:57.240]  Да, это до сих пор мы находимся с вами в Basic блоке.
[52:57.240 --> 53:00.240]  И вот мы нарисовали вот это дерево.
[53:00.240 --> 53:04.240]  И здесь видно, что T3, T7 получается.
[53:04.240 --> 53:09.240]  Да, T6 и T10 это корни нашего дерева.
[53:09.240 --> 53:16.240]  То есть T11 и T10 это просто переменные, которые у нас требуют результат работы функции.
[53:16.240 --> 53:19.240]  Это life variable на выходе.
[53:19.240 --> 53:23.240]  И T3, оно у нас используется в двух местах.
[53:23.240 --> 53:28.240]  Как выход T11 с операцией плюс и выход T10 с операцией умножить.
[53:28.240 --> 53:33.240]  И дополнительно, что у нас, и T6 у нас просто сам тоже корень дерева.
[53:33.240 --> 53:36.240]  То есть у нас есть переменные, так называемые life out.
[53:36.240 --> 53:40.240]  То есть те переменные, которые у нас выходят из нашего Basic блок.
[53:40.240 --> 53:42.240]  И используются в других Basic блоках.
[53:42.240 --> 53:49.240]  Да, кстати, к вопросу о том, что при помощи этой штуки можно еще и находить dead code.
[53:49.240 --> 53:54.240]  Elimination, если мы построим дерево, то, в принципе, если у нас T6 нигде не используется дальше,
[53:54.240 --> 53:58.240]  то мы просто можем некоторое под дерево просто прибить.
[53:58.240 --> 54:01.240]  И следующая его операция.
[54:01.240 --> 54:04.240]  Вот такой вот код. Мы находим в нем деревья.
[54:04.240 --> 54:06.240]  А дальше нам нужно делать именно перебалансировку.
[54:06.240 --> 54:10.240]  То есть по факту мы перебалансировать, у нас же Zoom есть.
[54:10.240 --> 54:13.240]  Знаете, какая главная фишка Zoom?
[54:13.240 --> 54:16.240]  Что здесь можно рисовать.
[54:26.240 --> 54:30.240]  Вот он dead code. Вот у нас одно дерево.
[54:30.240 --> 54:34.240]  Дальше у нас есть второе дерево.
[54:35.240 --> 54:38.240]  Вот оно.
[54:38.240 --> 54:40.240]  Ну и остальные тут уже по мелочи.
[54:40.240 --> 54:45.240]  Вот как раз вот эти деревья нам нужно перебалансировать.
[54:45.240 --> 54:48.240]  Получаются, ну, самые такие нелинейные деревья.
[54:48.240 --> 54:51.240]  Это деревья T11 и T3.
[54:51.240 --> 54:55.240]  И давайте посмотрим, как они у нас с вами будут работать.
[55:05.240 --> 55:08.240]  Ну, это да.
[55:08.240 --> 55:11.240]  Ну, это зависит от архитектуры процессора.
[55:15.240 --> 55:17.240]  Ну да, да, да.
[55:17.240 --> 55:20.240]  Есть такое. Так, это алгоритм нахождения корней дерева.
[55:20.240 --> 55:22.240]  Там можно поставить на паузу, почитать.
[55:22.240 --> 55:25.240]  Вот я думаю, что это числа нет.
[55:25.240 --> 55:28.240]  Значит, смотрите. А дальше делается следующее.
[55:28.240 --> 55:30.240]  Корни дерева мы находим.
[55:30.240 --> 55:33.240]  Причем для каждого корня дерева мы дополнительно записываем
[55:33.240 --> 55:35.240]  еще следующую вещь.
[55:35.240 --> 55:38.240]  То есть какое количество оперантов у нас есть.
[55:38.240 --> 55:42.240]  И, собственно, дальше мы говорим следующее,
[55:42.240 --> 55:47.240]  что давайте, значит, каждый узел, который у нас есть,
[55:47.240 --> 55:50.240]  посмотрим просто, в каком порядке у нас идут они.
[55:50.240 --> 55:54.240]  То есть, грубо говоря, делаем некоторый порядок.
[55:54.240 --> 55:57.240]  То есть как бы получается, что, вот смотрите внимательно,
[55:57.240 --> 56:01.240]  корни дерева T11-T1, то есть как бы оно под себе
[56:01.240 --> 56:04.240]  не хранит никаких других детей, именно виртуальных.
[56:04.240 --> 56:08.240]  Значит, T получается 7.
[56:08.240 --> 56:10.240]  Это тоже один, он не использует.
[56:10.240 --> 56:12.240]  А вот T10, он использует двух детей.
[56:12.240 --> 56:16.240]  Поэтому мы его должны обработать в последнюю очередь.
[56:16.240 --> 56:19.240]  Вот. И дальше делается следующее.
[56:19.240 --> 56:23.240]  На самом деле для всех операций смотрим количество зависимости,
[56:23.240 --> 56:25.240]  которое есть. Смотрите.
[56:25.240 --> 56:28.240]  И здесь оказывается, что если их правильно добавлять в очередь,
[56:28.240 --> 56:31.240]  то константы у нас отправятся в самое начало.
[56:31.240 --> 56:34.240]  То есть у нас тут еще и получается constant folding.
[56:34.240 --> 56:37.240]  То есть у нас есть 13, у нас есть 4.
[56:37.240 --> 56:41.240]  Собственно, внутри этого дерева мы видим, что они находятся в одном блоке,
[56:41.240 --> 56:44.240]  мы начинаем их разбирать, и оказывается, что опа,
[56:44.240 --> 56:49.240]  типа мы с вами можем получить наш корректный результат.
[56:49.240 --> 56:52.240]  То есть как бы тут еще и считается количество оперантов,
[56:52.240 --> 56:55.240]  которые нам нужно задействовать.
[56:55.240 --> 56:58.240]  И в итоге, значит, если внимательно провернуть этот алгоритм,
[56:58.240 --> 57:01.240]  то вот у нас было вот такое вот дерево,
[57:01.240 --> 57:04.240]  а в итоге оно может получиться вот таким.
[57:04.240 --> 57:08.240]  То есть как бы дерево получается более приятным.
[57:08.240 --> 57:13.240]  И операция T7, кстати, смотрите, куда у нас переехал T7.
[57:13.240 --> 57:17.240]  Он у нас переехал вот сюда, потому что на самом деле,
[57:17.240 --> 57:20.240]  если посмотреть T7, а T7 у нас был здесь,
[57:20.240 --> 57:24.240]  T3 у нас теперь становится сюда, а T6 у нас находится здесь.
[57:24.240 --> 57:28.240]  То есть небольшая перебалансировка дерева произошла.
[57:28.240 --> 57:32.240]  То есть, в принципе, при желании, знаете, что?
[57:32.240 --> 57:36.240]  За какое количество тактов у нас все посчитается?
[57:36.240 --> 57:39.240]  Вот в таком коде.
[57:39.240 --> 57:42.240]  Если все идеально.
[57:42.240 --> 57:45.240]  Вот в правом дереве.
[57:45.240 --> 57:48.240]  Знаете, я даже его увеличу.
[57:55.240 --> 57:59.240]  Сколько тактов нужно посчитать, чтобы посчитать все эти значения?
[58:09.240 --> 58:12.240]  Ну это да, я согласен.
[58:12.240 --> 58:15.240]  Но если бы у нас были все одинаковые операции?
[58:15.240 --> 58:22.240]  Получается 1, 2, 3, то есть T6 это 3.
[58:22.240 --> 58:26.240]  Возможно, кстати, его параллельно куда-то можно вставить.
[58:26.240 --> 58:29.240]  4, 5, 6.
[58:29.240 --> 58:35.240]  То есть где-то там 6-7 операций у нас по сравнению с исходным кодом.
[58:35.240 --> 58:39.240]  В исходном коде у нас было большое количество операций.
[58:39.240 --> 58:44.240]  То есть как бы вот у нас есть конвейер, который мы с вами делаем.
[58:44.240 --> 58:47.240]  То есть, в принципе, можно использовать это для
[58:47.240 --> 58:50.240]  совершения своих собственных задач.
[58:51.240 --> 58:55.240]  Ну и, собственно, здесь еще есть некоторый набор оптимизации.
[58:55.240 --> 58:59.240]  Давайте так, спрошу, идея алгоритма ясна?
[58:59.240 --> 59:02.240]  Да, то есть главное аккуратно находить кор.
[59:02.240 --> 59:06.240]  Значит, дальше копия propagation тоже идея такая очень простая,
[59:06.240 --> 59:09.240]  что если у вас есть присваивание какой-то переменной,
[59:09.240 --> 59:12.240]  то и local value numbering это отслеживает,
[59:12.240 --> 59:16.240]  то, в принципе, мы можем прокинуть эти переменные дальше.
[59:16.240 --> 59:21.240]  Да, и есть вот такая вот вещь еще называется dead code elimination.
[59:21.240 --> 59:26.240]  То есть, в принципе, мы можем найти те инструкции, которые нам не нужны.
[59:26.240 --> 59:29.240]  Значит, я как раз тут взял некоторый пример,
[59:29.240 --> 59:34.240]  который показывает, что вот у нас есть код на джаве, аля код на джаве.
[59:34.240 --> 59:40.240]  И мы пытаемся как раз его, вот это у нас не очищенный яр, который есть.
[59:40.240 --> 59:43.240]  И мы пытаемся как раз создать объект.
[59:43.240 --> 59:45.240]  Tx равно new object.
[59:45.240 --> 59:50.240]  Потом получается, вытаскиваем параметр 4, присваиваем значение.
[59:50.240 --> 59:53.240]  В общем, видно, что здесь очень много лишнего кода.
[59:53.240 --> 59:58.240]  И хотелось бы понять, используется переменная в дальнейшем или нет.
[59:58.240 --> 01:00:02.240]  И вот оказывается, что переменная Tx в дальнейшем-то не используется,
[01:00:02.240 --> 01:00:05.240]  потому что она прямо записывается в виртуальный регистр,
[01:00:05.240 --> 01:00:08.240]  и дальше мы работаем с виртуальным регистром.
[01:00:08.240 --> 01:00:12.240]  Поэтому нам нужно посмотреть, какие переменные у нас являются живыми.
[01:00:12.240 --> 01:00:15.240]  Да, для этого как раз мы, наверное, в будущем будем,
[01:00:15.240 --> 01:00:20.240]  когда мы будем говорить про live analysis, мы будем считать именно,
[01:00:20.240 --> 01:00:22.240]  какие переменные живы и какие переменные не живы.
[01:00:22.240 --> 01:00:26.240]  Нам это называется уравнение потока графов.
[01:00:26.240 --> 01:00:29.240]  Control flow...
[01:00:29.240 --> 01:00:33.240]  Да, data flow, да.
[01:00:33.240 --> 01:00:38.240]  И в принципе, если посмотреть на этот код, то после применения
[01:00:38.240 --> 01:00:43.240]  dot-code elimination у нас вот так вот он меняется у нас.
[01:00:43.240 --> 01:00:49.240]  Так, это что касается локальных оптимизаций.
[01:00:49.240 --> 01:00:52.240]  Скажите, понятно ли?
[01:00:52.240 --> 01:00:55.240]  Ну да, в целом можно сделать.
[01:00:55.240 --> 01:00:58.240]  Значит, теперь следующие оптимизации.
[01:00:58.240 --> 01:01:01.240]  Переходим на уровень выше. Это региональные оптимизации.
[01:01:01.240 --> 01:01:04.240]  Значит, первое super local value numbering.
[01:01:04.240 --> 01:01:06.240]  То есть мы можем то же самое применять,
[01:01:06.240 --> 01:01:09.240]  только еще нумеровать не только наши переменные,
[01:01:09.240 --> 01:01:12.240]  но и операции между basic блоками.
[01:01:12.240 --> 01:01:15.240]  Ну и вторая достаточно частая региональная оптимизация
[01:01:15.240 --> 01:01:17.240]  это loop unrolling.
[01:01:17.240 --> 01:01:23.240]  То есть если у нас есть какой-то цикл, то почему бы его руками не развернуть?
[01:01:23.240 --> 01:01:26.240]  Значит, собственно, что делает региональная перенумерация?
[01:01:26.240 --> 01:01:31.240]  Суть алгоритма будет обойти в DFS всем по расширенным блокам
[01:01:31.240 --> 01:01:37.240]  и говорить следующее, что если у нас с вами есть какой-то набор блоков,
[01:01:37.240 --> 01:01:40.240]  то нам как раз нужно провести эти манипуляции.
[01:01:40.240 --> 01:01:46.240]  То есть важно именно здесь посмотреть, какие из них образуют дерево,
[01:01:46.240 --> 01:01:50.240]  которые не являются зависимыми от двух ребенков.
[01:01:50.240 --> 01:01:54.240]  И вот если посмотреть на количество блоков, которые у нас есть,
[01:01:54.240 --> 01:01:57.240]  поток графов управления, то оказывается, что у нас есть переменные B0,
[01:01:57.240 --> 01:02:00.240]  B1, B2, B3, B4, которые объединяются в одно дерево.
[01:02:00.240 --> 01:02:06.240]  После этого к нему в дочерний узел спускается B5, и в конце у нас используется B6.
[01:02:06.240 --> 01:02:12.240]  То есть в принципе мы можем как раз взять, применить local value numbering B0,
[01:02:12.240 --> 01:02:16.240]  потом для B1, и добавить наш узел после этого.
[01:02:16.240 --> 01:02:20.240]  То есть как раз идет оптимизация по определенному пути.
[01:02:20.240 --> 01:02:25.240]  То есть как бы мы параллельно берем наш путь,
[01:02:25.240 --> 01:02:29.240]  и внутри DFS как раз сохраняем наборы переменных по зависимости.
[01:02:29.240 --> 01:02:35.240]  То есть получается, что у нас типа нумерация для B4 будет так после той,
[01:02:35.240 --> 01:02:38.240]  которая у нас идет по B2.
[01:02:38.240 --> 01:02:41.240]  А поскольку B3 и B4 между собой независимы,
[01:02:41.240 --> 01:02:45.240]  то как бы у нас будет нумерация для B4 после того,
[01:02:46.240 --> 01:02:49.240]  поскольку B3 и B4 между собой независимы,
[01:02:49.240 --> 01:02:51.240]  то как бы мы их не оптимизируем.
[01:02:51.240 --> 01:02:56.240]  То есть у нас получается как раз супер блок B0, B2, B4.
[01:03:02.240 --> 01:03:04.240]  Это что касается оригинальной переноминации.
[01:03:04.240 --> 01:03:07.240]  Если мы говорим про loop unrolling,
[01:03:07.240 --> 01:03:09.240]  ну здесь на самом деле все просто.
[01:03:09.240 --> 01:03:12.240]  Если мы можем посчитать значение нашей константы заранее
[01:03:12.240 --> 01:03:14.240]  до того, как у нас есть какой-то код,
[01:03:14.240 --> 01:03:19.240]  то мы в принципе можем как раз вместо одной инструкции цикла
[01:03:19.240 --> 01:03:22.240]  поставить большое количество инструкций нашего цикла.
[01:03:22.240 --> 01:03:28.240]  Более того, некоторые опции компиляции поддерживают прямо loop unrolling.
[01:03:28.240 --> 01:03:33.240]  Я правда не знаю, есть ли в классическом C++ с прогом unroll?
[01:03:33.240 --> 01:03:38.240]  Там по числу компиляторов какие-нибудь константы у циклы loop unrolling.
[01:03:38.240 --> 01:03:46.240]  Но у них есть еще опция, типа aggresive loop unrolling.
[01:03:46.240 --> 01:03:49.240]  Не, просто в той же самой куде, в компиляторе,
[01:03:49.240 --> 01:03:51.240]  прямо есть прогма unroll.
[01:03:51.240 --> 01:03:53.240]  Форсировать unroll?
[01:03:53.240 --> 01:03:55.240]  Да, форсировать unroll.
[01:03:55.240 --> 01:04:00.240]  Ну да, это некритично,
[01:04:00.240 --> 01:04:04.240]  но иногда циклы не unroll-ятся напрямую.
[01:04:07.240 --> 01:04:09.240]  Да, кстати, у меня кейс был как раз,
[01:04:09.240 --> 01:04:11.240]  писал какой-то криптографический алгоритм,
[01:04:11.240 --> 01:04:14.240]  и оказалось, что там типа for int i равно нулю
[01:04:14.240 --> 01:04:17.240]  и имеет 16++i было в одном месте.
[01:04:17.240 --> 01:04:21.240]  Работало, значит, со скоростью 5 мегабайт в секунду.
[01:04:21.240 --> 01:04:23.240]  Перегоняло данные.
[01:04:23.240 --> 01:04:28.240]  Первая оптимизация была, это просто 16 раз copy-paste этот цикл.
[01:04:28.240 --> 01:04:32.240]  Работало не в 16 раз быстрее, но близко к тому.
[01:04:41.240 --> 01:04:44.240]  Ну вот, поэтому с этим нужно быть аккуратнее
[01:04:44.240 --> 01:04:46.240]  и смотреть, как это можно делать.
[01:04:46.240 --> 01:04:49.240]  Значит, дальше поехали глобальные оптимизации.
[01:04:49.240 --> 01:04:52.240]  Значит, это инструкция между блоками.
[01:04:52.240 --> 01:04:55.240]  На следующих лекциях будем смотреть уравнение потока.
[01:04:55.240 --> 01:04:58.240]  В общем, здесь тоже нужно отсеживать.
[01:04:58.240 --> 01:05:01.240]  Или мы можем использовать профилировщик для построения следов,
[01:05:01.240 --> 01:05:04.240]  как раз про тот статистический анализ, который я говорил.
[01:05:04.240 --> 01:05:07.240]  То есть мы пропускаем, грубо говоря, профилировщик,
[01:05:07.240 --> 01:05:11.240]  забираем время работы, понимаем, что что-то не так, перестраиваем его.
[01:05:11.240 --> 01:05:14.240]  Ну и, наверное, это все на сегодня.
[01:05:14.240 --> 01:05:16.240]  Собственно, мы что поняли?
[01:05:16.240 --> 01:05:19.240]  Мы с вами сегодня построили каноническое арт-дерево,
[01:05:19.240 --> 01:05:22.240]  научились понимать, что у нас есть basic блоки,
[01:05:22.240 --> 01:05:24.240]  научились разбивать инструкции на блоки
[01:05:24.240 --> 01:05:28.240]  и что из себя представляет оптимизация в целом.
[01:05:28.240 --> 01:05:31.240]  Сейчас мы, наверное, побежим сразу дальше, чтобы...
[01:05:31.240 --> 01:05:34.240]  Ну, на следующих лекциях побежим сразу дальше.
[01:05:34.240 --> 01:05:36.240]  Это что будет означать?
[01:05:36.240 --> 01:05:39.240]  Это будет означать, что мы перейдем сразу к low-level кодингу
[01:05:39.240 --> 01:05:43.240]  и начнем рассматривать instruction-selection алгоритм.
[01:05:43.240 --> 01:05:47.240]  То есть каким образом мы можем собирать наш построенный AR
[01:05:47.240 --> 01:05:51.240]  с оптимизированной под определенные инструкции ассеблера.
[01:05:51.240 --> 01:05:56.240]  Сразу скажу, что мы возьмем тоже определенный конкретный пример ассеблера
[01:05:56.240 --> 01:05:58.240]  и его рассмотрим.
[01:05:58.240 --> 01:06:01.240]  Здесь уже будет важна особенность архитектуры.
[01:06:01.240 --> 01:06:06.240]  Потому что вы не поверите, компилятор на ARM написать в разы проще,
[01:06:06.240 --> 01:06:12.240]  чем back-end на ARM написать намного проще, чем back-end на x86 архитектуре.
[01:06:12.240 --> 01:06:14.240]  На x86 архитектуре.
[01:06:14.240 --> 01:06:16.240]  А?
[01:06:16.240 --> 01:06:18.240]  На x86 архитектуре.
[01:06:18.240 --> 01:06:22.240]  Она имеет две инструкции того же типа.
[01:06:22.240 --> 01:06:24.240]  Угу.
[01:06:24.240 --> 01:06:26.240]  Ну, у ARM есть свои.
[01:06:26.240 --> 01:06:28.240]  В этом плане.
[01:06:28.240 --> 01:06:30.240]  То есть он есть.
[01:06:30.240 --> 01:06:33.240]  А он, конечно, глобально удобный, но...
[01:06:33.240 --> 01:06:34.240]  Ну да.
[01:06:34.240 --> 01:06:36.240]  Нажимать его тоже.
[01:06:36.240 --> 01:06:39.240]  Можно компилить его в бего-сендре.
[01:06:39.240 --> 01:06:41.240]  Можно?
[01:06:41.240 --> 01:06:43.240]  У ARM...
[01:06:43.240 --> 01:06:48.240]  У них сатамарка все спеша, не все лечит.
[01:06:48.240 --> 01:06:50.240]  Когда тебе надо такие...
[01:06:50.240 --> 01:06:52.240]  Ну да.
[01:06:52.240 --> 01:06:55.240]  Компилиатуры, в целом, расставлять...
[01:06:55.240 --> 01:06:59.240]  Ну да, да.
[01:06:59.240 --> 01:07:01.240]  Так.
[01:07:01.240 --> 01:07:03.240]  На этом все тогда.
[01:07:03.240 --> 01:07:05.240]  До следующего раза.
[01:07:05.240 --> 01:07:09.240]  А на семинаре мы продолжим, так сказать,
[01:07:09.240 --> 01:07:11.240]  рассматривать LVM YAR.
[01:07:11.240 --> 01:07:14.240]  Если успеем сегодня, то посмотрим все-таки,
[01:07:14.240 --> 01:07:18.240]  как таблица символов делается.
[01:07:18.240 --> 01:07:20.240]  Так что жду.
