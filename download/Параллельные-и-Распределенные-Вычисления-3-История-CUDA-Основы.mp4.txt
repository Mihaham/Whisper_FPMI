[00:00.000 --> 00:19.000]  Всем доброго дня, мы с вами, да, тут это кажется очень смешным, но все-таки где-то минут 15, но в целом, как говорится, мы строили-строили и наконец построили.
[00:19.000 --> 00:23.000]  Вот, мы с вами сегодня начинаем проходить блог, посвященный вычислением на видеокартах,
[00:23.000 --> 00:31.000]  и наша цель вообще будет познакомиться с тем, а как в сферах параллельных вычислений пришло понятие видеокарта и графические вычисления.
[00:31.000 --> 00:41.000]  Да, потому что, ну, кажется, для чего обычно нужны видеокарты? Ну, классическая, а? В игры играть, да.
[00:41.000 --> 00:51.000]  Ну, вот почему, как ни странно, вот компания Nvidia, вот, кстати, недавно вышел буквально отчет финансовый за 2023 год, они порвали все рекорды.
[00:51.000 --> 01:03.000]  Свои, и котировки акций Nvidia выросли там еще на 15-20%. То есть, это там реально тузымун, если посмотреть на котировки акций Nvidia, то это прям явно видно.
[01:03.000 --> 01:13.000]  Но на самом деле компания Nvidia, если так честно говорить, она сейчас зарабатывает не только за счет того, что продают видеокарты, но она вообще предоставляет разные решения, связанные с искусственным интеллектом.
[01:13.000 --> 01:23.000]  Поэтому, так или иначе, сейчас программирование на видеокарте очень полезно в концепции обработки больших объемов данных, ну, и вообще процессирование этих объемов данных.
[01:23.000 --> 01:30.000]  Поэтому важно, как минимум, в основе понимать, каким образом происходит программирование на вот этих устройствах.
[01:30.000 --> 01:36.000]  Вот, и самое главное про инструмент, который используется в данном кейсе, это инструмент под названием CUDA.
[01:36.000 --> 01:52.000]  Значит, я еще введу аббревиатуру понятия CUDA. Вот, наша сегодня цель будет понять в том, в чем состоит история этого процесса, и разобрать основные концепции для того, чтобы на первых семинарах вы уже спокойно могли с этими концепциями работать.
[01:52.000 --> 02:02.000]  Давайте как раз начнем. Что мы узнаем сегодня на сегодняшней лекции? Во-первых, мы сегодня поймем, чем же процессор отличается от видеокарт.
[02:02.000 --> 02:13.000]  Во-вторых, вспомним, что такое закон Мура, и поймем, почему он в оригинальной постановке, так сказать, которая обычно считается неверной, работает до сих пор для видеокарт.
[02:13.000 --> 02:17.000]  Для центральных процессоров классический закон Мура сейчас не работает.
[02:17.000 --> 02:25.000]  Значит, как ускорять программы на видеокарте? Ну, собственно, это цель того, посмотреть, каким образом это все работает.
[02:25.000 --> 02:30.000]  И последняя вещь, мы поймем с вами, как использовать всю мощность на видеокарте. Почему это важно?
[02:30.000 --> 02:40.000]  Потому что, когда мы говорим с вами про обработку на видеокарте, то оказывается, что у нее модель вычислений немного другая по сравнению с центральным процессором.
[02:40.000 --> 02:51.000]  И это необходимо учитывать для работы. То есть, если вы кажется, что, ну, вот сейчас мы с вами все распараллели, грубо говоря, на тысячу потоков, у нас будет ускорение в тысячу раз.
[02:51.000 --> 03:00.000]  Ну, вообще, это неправда. Если вы попробуете распараллелиться на ГПУ ровно так же, как на ЦПУ, то вас постигнет фиаско.
[03:00.000 --> 03:13.000]  Вы ускоритесь не в тысячу раз, а раз, ну, не знаю, раз в двадцать от силы. То есть, как бы законом ДАЛа пойдет гулять лесом. Вы знаете, что такое законом ДАЛа?
[03:13.000 --> 03:15.000]  В этом мире.
[03:15.000 --> 03:21.000]  Да, вроде говорили. Это максимальное ускорение, которое можно получить в программе.
[03:21.000 --> 03:27.000]  Да, в зависимости от числа потоков и доли программы, которая выполняется последовательно.
[03:28.000 --> 03:32.000]  Вот, хорошо. Значит, давайте поймем, вообще, с чем мы с вами работаем.
[03:32.000 --> 03:37.000]  И что такое ГПУ? Значит, ГПУ расшифровывается как Graphic Processing Unit.
[03:37.000 --> 03:43.000]  Если мы говорим про обычные задачи, то они обычно выполняются у нас на ЦПУ. Что такое ЦПУ?
[03:43.000 --> 03:52.000]  Это Центровый Процессинг Unit. Это электронная схема, которая необходима для того, чтобы вы производите операции в произвольной компьютерной программе.
[03:52.000 --> 04:00.000]  То есть, любое действие, которое вы по умолчанию делаете на вашем компьютере, так или иначе выпускается в набор регистров.
[04:00.000 --> 04:06.000]  И там по факту есть язык Assembler, в котором мы стараемся транслировать все команды.
[04:06.000 --> 04:11.000]  Понятно, что на уровне процессора у нас с вами, помимо Assembler, есть микрокод.
[04:11.000 --> 04:17.000]  Это такое устройство, которое умеет транслировать команды Assembler в внутренней инструкции процессора.
[04:17.000 --> 04:22.000]  Но зачастую вы не имеете понятия, каким образом устроен микрокод.
[04:22.000 --> 04:31.000]  То есть, ваша цель просто ввести к программе Assembler, а дальше ЦПУ в режиме конвейерности будет решать, что именно делать.
[04:31.000 --> 04:45.000]  Так, вопрос такой. Понятие конвейера, знаете, это такое последствие действия, в котором нам говорится, что операции должны идти в строго определенном порядке.
[04:45.000 --> 04:53.000]  И, собственно, у самого ЦПУ есть несколько вычислительных частей, несколько очередей, через которые этот конвейер может быть сделан.
[04:53.000 --> 04:57.000]  Да, представьте себе кейс. Мы делаем какую-нибудь машину.
[04:57.000 --> 05:06.000]  Понятно, что у нас с вами одна часть, один отдел, допустим, строит корпус, другой отдел красят его.
[05:06.000 --> 05:14.000]  Понятно, что эти действия выполняются последовательно, но в принципе параллельно двумя разными командами можем делать разные действия.
[05:14.000 --> 05:18.000]  То есть, одни собирают машину, другие, допустим, ее красят.
[05:18.000 --> 05:24.000]  В итоге мы получаем некоторую цепочку действий, в которой это все работает достаточно быстро.
[05:24.000 --> 05:26.000]  Так, а на доске ничего не видно, да?
[05:29.000 --> 05:33.000]  То есть, вот она у нас в две стадии. Это сборка и покраска.
[05:39.000 --> 05:42.000]  Понятно, что мы тогда можем сделать вот такой конвейер.
[05:44.000 --> 05:59.000]  Вот, и это все делать в момент времени Т. То есть, у нас две разные команды могут заниматься одной и той же параллельной сборкой нескольких машин.
[05:59.000 --> 06:09.000]  В центральном процессоре мы этого с вами не видим, а вот на графических ускорителях это можно увидеть, но правда связано с обработкой памяти.
[06:09.000 --> 06:18.000]  Так, значит, что такое Graphic Processing Unit? Это, на самом деле, обычно специально электронная схема, которая необходима для того, чтобы выводить изображение на экран.
[06:18.000 --> 06:22.000]  Процедура отрисовки объектов на экране называется рендерингом.
[06:22.000 --> 06:35.000]  И, значит, если мы говорим про Graphic Processing Unit, то в нашем, так сказать, обиходе в русском языке есть некоторое другое понятие, которое заменяет понятие Graphic Processing Unit.
[06:36.000 --> 06:38.000]  Как мы это называем?
[06:38.000 --> 06:40.000]  Да, это мы называем видеокартой.
[06:41.000 --> 06:46.000]  Конечно, то есть у нас по факту есть отдельное устройство, и мы его называем видеокартой.
[06:47.000 --> 06:55.000]  Вот, и давайте вот детально представим себе, значит, как у нас выглядит обычная видеокарта.
[06:56.000 --> 06:58.000]  Кто-нибудь видел?
[06:59.000 --> 07:02.000]  Ну, давайте я открою, наверное, какие-нибудь рендеры.
[07:03.000 --> 07:12.000]  Так. Ну, давайте посмотрим какой-нибудь процессор. Какой вам процессор больше нравится, Intel или AMD?
[07:14.000 --> 07:20.000]  Блин. А, давайте какой-нибудь Ryzen, открою, 9.
[07:21.000 --> 07:25.000]  И посмотрим, как они выглядят. Так, давайте мне без коробки.
[07:26.000 --> 07:30.000]  Вот, смотрите, то есть, ну, допустим, вот выглядит процессор вот таким вот образом.
[07:30.000 --> 07:34.000]  То есть, это именно такой чип, он обычно занимает немного места.
[07:35.000 --> 07:43.000]  Вот, и там по факту он вставляется в материнскую плату, и дальше мы, собственно, к нему подключаем некоторый набор вентиляторов.
[07:44.000 --> 07:47.000]  Ну, то есть, кажется, устройство приблизительно вот такое.
[07:48.000 --> 07:52.000]  Там вместе со слотом материнской плати оно занимает немного места.
[07:53.000 --> 07:56.000]  Ну, что, давайте теперь откроем видеокарту. Какую откроем?
[07:56.000 --> 07:58.000]  Ну, давайте, допустим, RTX.
[08:03.000 --> 08:04.000]  4090.
[08:08.000 --> 08:10.000]  Не знаю, видно ли объемы или нет.
[08:15.000 --> 08:18.000]  О, ну, давайте вот какую-нибудь сборку компьютера.
[08:21.000 --> 08:24.000]  Так, откроем, откроем сайт. Я надеюсь, что тут позволит нам это.
[08:25.000 --> 08:28.000]  Значит, смотрите, теперь, чтобы вы понимали все по объемам.
[08:29.000 --> 08:32.000]  Да-да-да-да-да, спасибо, спасибо, что предлагаете мне это купить.
[08:33.000 --> 08:40.000]  Значит, вот видите, вот это вот, то, что я на экране вывожу, это у нас вот такая вот коробочка.
[08:41.000 --> 08:43.000]  Вот это центральный процессор.
[08:44.000 --> 08:50.000]  Вот, собственно, поверх него привязана помпа, и справа от него видно вентиляторы.
[08:50.000 --> 08:56.000]  А теперь вот это, видите, вот параллельно сбоку еще одно устройство.
[08:57.000 --> 08:58.000]  Называется GeForce RTX.
[08:59.000 --> 09:00.000]  Оцените размеры.
[09:02.000 --> 09:06.000]  Ну, то есть, это такая бандура, на ней висит три вентилятора.
[09:07.000 --> 09:10.000]  Вот, и она еще сама занимает три слота PCI-Express.
[09:11.000 --> 09:12.000]  Выводы информации.
[09:13.000 --> 09:16.000]  То есть, по факту, вы классический компьютер, вряд ли его поставите больше, чем две.
[09:16.000 --> 09:22.000]  Вот, а если вы захотите поставить три видеокарты, то вам придется сделать приблизительно то же самое, что мне в свое время пришлось сделать.
[09:23.000 --> 09:28.000]  Идти в магазин, арендовать дрель и просверливать дырку для системного блока.
[09:30.000 --> 09:33.000]  Да, потому что системный блок у меня железный.
[09:34.000 --> 09:37.000]  Ну, вот такой вот аспект, то есть понятно, что оно занимает очень-очень много места.
[09:38.000 --> 09:41.000]  Ну, понятно, что большая часть из этого вентилятора, но в принципе, вот такая вот плашка.
[09:41.000 --> 09:43.000]  Что мы с вами из этого можем сказать?
[09:44.000 --> 09:47.000]  Что видеокарты и центральные процессоры сейчас выглядят по-другому.
[09:48.000 --> 09:49.000]  По-разному совсем.
[09:50.000 --> 09:52.000]  Но это было далеко не всегда так.
[09:53.000 --> 09:58.000]  Были времена, когда центральные процессоры и видеокарты выглядели одинаково, приблизительно.
[09:59.000 --> 10:00.000]  Давайте поймем почему.
[10:01.000 --> 10:04.000]  Для этого нам нужно отмотаться, поверьте, где-то на 40 лет назад.
[10:06.000 --> 10:07.000]  40 лет назад.
[10:07.000 --> 10:08.000]  Да, 80-е годы.
[10:09.000 --> 10:11.000]  Представьте себе, живем мы в 80-х годах.
[10:13.000 --> 10:16.000]  И у нас есть замечательное устройство.
[10:17.000 --> 10:21.000]  Ну, на самом деле, если мы живем, так сказать, на Западе, то у нас есть,
[10:22.000 --> 10:26.000]  как раз, такое устройство, как Nintendo Entertainment System.
[10:27.000 --> 10:32.000]  Значит, она у нас есть, как раз, такое устройство, как Nintendo Entertainment System.
[10:32.000 --> 10:35.000]  Значит, она до нас доехала в 90-е годы, и это приставка Dendy.
[10:36.000 --> 10:37.000]  Возможно, слышали про такое.
[10:38.000 --> 10:42.000]  Вот, давайте как раз разберем характеристики этого устройства и поймем,
[10:43.000 --> 10:46.000]  на самом деле, сколько нам нужно информации прогонять за единицу времени
[10:47.000 --> 10:49.000]  для того, чтобы отрисовывать изображение на экране.
[10:50.000 --> 10:52.000]  То есть, какой рендеринг нам нужен.
[10:53.000 --> 10:58.000]  Значит, давайте оценим, сколько ресурсов вообще занимает 2D отрисовка объекта.
[10:58.000 --> 11:02.000]  Значит, для этого нам нужно понять, что у нас с вами есть количество пикселей.
[11:03.000 --> 11:05.000]  Да, сразу скажу, что игрушки были плоскими.
[11:06.000 --> 11:07.000]  То есть, не было никакого 3D тогда.
[11:08.000 --> 11:11.000]  То есть, это всякие новомодные технологии, их еще тогда не было.
[11:20.000 --> 11:23.000]  Значит, давайте посмотрим внимательно на экране.
[11:23.000 --> 11:25.000]  На экране тот, который я сейчас нарисую на доске.
[11:27.000 --> 11:29.000]  У нас изображение.
[11:30.000 --> 11:32.000]  У нас есть ширина.
[11:34.000 --> 11:36.000]  У нас есть высота.
[11:40.000 --> 11:46.000]  Сейчас мы понимаем с вами, что у современных мониторов ширина это 1920 в пикселях,
[11:46.000 --> 11:48.000]  высота 1080 в пикселях.
[11:49.000 --> 11:55.000]  Но, когда были 80-е годы, то ширина была 320, а высота 240.
[11:56.000 --> 11:58.000]  И то, если повезет.
[11:59.000 --> 12:01.000]  То есть, иногда еще меньше объема.
[12:02.000 --> 12:06.000]  Вот, значит, сколько цветов могло храниться в одном пикселе?
[12:07.000 --> 12:12.000]  Сейчас мы понимаем с вами, что у современных мониторов ширина это 1920 в пикселях,
[12:13.000 --> 12:15.000]  высота 1080 в пикселях.
[12:16.000 --> 12:21.000]  И мы понимаем с вами, что у нас на хранение каждого пикселя отводится 32 бита.
[12:22.000 --> 12:24.000]  Ну, либо 64 бита.
[12:25.000 --> 12:27.000]  Это, собственно, RGB.
[12:28.000 --> 12:30.000]  8, 8, 8.
[12:31.000 --> 12:33.000]  Ну, иногда еще, считая так, анал.
[12:34.000 --> 12:37.000]  Значит, в тех приставках вообще было 8-битное разрешение экрана.
[12:38.000 --> 12:41.000]  То есть, у нас как бы один пиксель занимал 8 бит.
[12:42.000 --> 12:44.000]  Так, хорошо.
[12:45.000 --> 12:46.000]  То есть, что у нас получается?
[12:47.000 --> 12:52.000]  Значит, для отрисовки одного пикселя, одного экрана, сколько нам нужна информация?
[12:55.000 --> 12:58.000]  Что нам нужно сделать с этими всеми числами?
[12:59.000 --> 13:01.000]  Да, теперь у нас получается объем.
[13:02.000 --> 13:07.000]  Это 320 на 240 на, давайте, один байт сразу же.
[13:08.000 --> 13:18.000]  Значит, это сколько мы перегоняем с вами, точнее, за один кадр per frame.
[13:22.000 --> 13:24.000]  А теперь как оценить объем?
[13:25.000 --> 13:29.000]  Информация, которую нам необходимо перегнать за одну секунду.
[13:31.000 --> 13:32.000]  Ложь на FPS.
[13:33.000 --> 13:35.000]  Надо вот эту величину.
[13:37.000 --> 13:39.000]  Умножить на frame per second.
[13:40.000 --> 13:51.000]  Значит, тут нужно сказать сразу, что несмотря на то, что тогда частотность была 24 кадра в секунду, либо 25 кадра, либо 30 кадров в секунду.
[13:52.000 --> 13:55.000]  На самом деле у нас есть два буфера.
[13:56.000 --> 14:02.000]  Точнее, у нас кадр состоит из основного экрана и буфера, который отрисовывается.
[14:02.000 --> 14:06.000]  Да, поэтому нам на самом деле нужно в два раза больше ресурсов для отрисовки.
[14:07.000 --> 14:18.000]  Ну, можно считать так, что все равно некоторые, если посмотреть приставки, которые отрисовывают изображение, все равно они старались соблюдать частоту кадров, либо 50 кадров в секунду, либо 60 кадров в секунду.
[14:19.000 --> 14:20.000]  Еще в те времена.
[14:21.000 --> 14:27.000]  Поэтому давайте мы оцепим по минимуму это все дело и скажем, что у нас будет 50 frame per second.
[14:27.000 --> 14:28.000]  Frame per second.
[14:29.000 --> 14:31.000]  Здесь у нас было делить на frame.
[14:32.000 --> 14:33.000]  Размерности сокращаются.
[14:34.000 --> 14:36.000]  Так, тут byte получается.
[14:37.000 --> 14:38.000]  И сколько это у нас выходит?
[14:39.000 --> 14:43.000]  А мы считаем, что включаем на каждую длину одна америка?
[14:45.000 --> 14:46.000]  А, да.
[14:47.000 --> 14:48.000]  Да, да, да, да.
[14:49.000 --> 14:52.000]  То есть у нас получается, каждый пиксель отрисовывается восьми битами.
[14:53.000 --> 14:55.000]  Восемь бит – это один byte.
[14:55.000 --> 14:56.000]  Так.
[14:57.000 --> 14:58.000]  Да, да, да.
[14:59.000 --> 15:00.000]  Да, да.
[15:01.000 --> 15:02.000]  А?
[15:03.000 --> 15:07.000]  Ну, понятно, что там есть статические картинки и так далее.
[15:08.000 --> 15:10.000]  Понятно, что там надо смотреть в ресурсы процессора.
[15:11.000 --> 15:12.000]  По-хорошему говоря.
[15:13.000 --> 15:14.000]  То есть мы оцениваем прикидочно припады.
[15:15.000 --> 15:17.000]  Ну, давайте посчитаем.
[15:18.000 --> 15:19.000]  Сколько это будет у нас?
[15:20.000 --> 15:21.000]  320 на 240?
[15:22.000 --> 15:23.000]  Ну...
[15:23.000 --> 15:24.000]  Ну...
[15:31.000 --> 15:33.000]  366 мегабайтами в самом деле.
[15:42.000 --> 15:47.000]  Понятно, что если мы отрисовываем 25 кадров в секунду, то получаем где-то 108-109 мегабайт в секунду.
[15:49.000 --> 15:51.000]  Ну, вроде я нигде не обманулся счетом.
[15:54.000 --> 16:00.000]  А теперь давайте поймем, приблизительно какой объем информации мы можем перегонять в единицу времени.
[16:01.000 --> 16:09.000]  Здесь делается еще одно крайне неточное допущение, поскольку память и центральный процессор – это все-таки разные.
[16:10.000 --> 16:16.000]  Давайте будем считать, что приблизительно за один такт мы будем перегонять один байт информации.
[16:17.000 --> 16:21.000]  Понятно, что это неправда, но если говорить про битность процессоров, вроде это совпадает.
[16:21.000 --> 16:32.000]  То есть, приблизительно для того, чтобы отрисовать этот объем, нам нужно порядка 2-4 мегагерца иметь частоту процесса.
[16:33.000 --> 16:35.000]  Опять же, это грубые оценки.
[16:35.000 --> 16:59.000]  Так, ну теперь смотрите, если мы пойдем в Google, спросим следующий запрос, мощность процессора Dendy, то что мы с вами увидим?
[17:05.000 --> 17:13.000]  1 вольт 7 мегагерц. То есть, в принципе, мы попадаем в ту оценку, которая у нас есть для центральных процессоров.
[17:14.000 --> 17:21.000]  То есть, в принципе, за отрисовку изображения можно использовать классический центральный процессор для отрисовки 2D объектов.
[17:21.000 --> 17:23.000]  Хорошо, так, это понятно?
[17:24.000 --> 17:33.000]  Это грубая оценка, потому что там были спрайты, то же самое приставки Dendy, Dt, Dt.
[17:34.000 --> 17:39.000]  Коны были статическими, ну и так далее. То есть, есть достаточно большое ограничение на ресурс.
[17:40.000 --> 17:49.000]  Итак, значит, а если мы говорим про более широкие разрешения, то VGA-экран появился там в 1987 году, и разрешение у него стало 640 на 480.
[17:50.000 --> 17:59.000]  То есть, как бы тогда появилось все. Кажется, что, вот, типа, тут так, может процессор Dendy у меня указан неверно, значит, оно на самом деле два раза меньше.
[18:00.000 --> 18:06.000]  То есть, 2D все хорошо. Так, а давайте подумаем, что у нас произойдет, когда мы из 2D в 3D перейдем?
[18:09.000 --> 18:16.000]  В чем будет отличие? Значит, это будет уже не в 80-е годы, это уже будут 90-е годы.
[18:19.000 --> 18:26.000]  Давайте прикинем. Значит, теперь у нас чистота будет, как ни странно, 32 пито.
[18:28.000 --> 18:35.000]  То есть, нам как бы появилась полная цветовая гамма. Раз, ну может быть, не совсем полная.
[18:35.000 --> 18:45.000]  Значит, разрешение экрана увеличилось в 640 на 480. Могло увеличиться. Так, хорошо.
[18:46.000 --> 18:59.000]  А теперь, даже если мы сейчас подставим, то у нас получается, смотрите, X2, X2, X4, то есть у нас получается X16 от этого объема, ну и это уже, кажется, в 50 мегабайт в секунду.
[19:05.000 --> 19:13.000]  Ну, кажется, что, в принципе, не сильный рост, но здесь мы забываем учесть один важный фактор. Какой?
[19:17.000 --> 19:25.000]  Как понять, как пиксели выводить? Да, как понять, какой пиксель выводить? Для этого что нам нужно сделать?
[19:27.000 --> 19:32.000]  Да, смотрите, что-то спровицировать. То есть, как минимум, нам нужно взять какой-то трехмерный объект и его обсчитать.
[19:32.000 --> 19:39.000]  А если мы предполагаем, давайте прикинем следующую вещь, что у нас трехмерный объект будет сферическим.
[19:43.000 --> 19:55.000]  С учетом того, что вся 3D-графика отрисовывается треугольничками, то количество треугольников, ну они маленькие достаточно, можем оценить приблизительно опять же сверху, как площадь фигуры.
[19:55.000 --> 20:02.000]  Понятно, что у нас есть квадратные, которые достаточно просто отрисовываются, но вот сферообразные, у нас сегодня какая-то проблема.
[20:03.000 --> 20:11.000]  А чему ровняется площадь сферы? Ну, не 6, а 4 пиро-квадратные.
[20:12.000 --> 20:15.000]  Ну, не 6, а 4 пиро-квадратные.
[20:26.000 --> 20:32.000]  Кажется, пора снова на вышмате учить вычислять фигуру.
[20:33.000 --> 20:38.000]  Ну вот, да. Ладно. Сколько это приблизительно будет?
[20:39.000 --> 20:46.000]  Ну, r квадрат нам не важен, нам нужно понять вот этот коэффициент. Ну, где-то 12,5.
[20:49.000 --> 20:57.000]  То есть, вот эту штуку нам по факту еще нужно будет умножить на где-то 12,5.
[20:57.000 --> 21:15.000]  Да. Ну, смотрите, нам нужно, значит, вычислительным мы рисуем сферу. Каким-то образом она у нас вращается, она представим себе такая разноцветная, то есть у нее какой-то градиент есть.
[21:16.000 --> 21:21.000]  Вот. И нам нужно каждый раз вычислить, какой цвет нам нужен для этой сферы. Ну, для спроецировать экран в часть сферы.
[21:22.000 --> 21:27.000]  То есть, нам нужно обсчитать все треугольники, которые у нас имеются, которые водятся на экран.
[21:30.000 --> 21:37.000]  Ну, да, половина. Ну, как, нам нужно понять, для половины объектов сферы находятся они внутри или нет, половину отрисовать.
[21:38.000 --> 21:45.000]  Картинка меняется динамически каждую секунду. Ну, сфера вращается у нас.
[21:51.000 --> 22:09.000]  Ну, это понятно. Не-не-не, это уже чудеса оптимизации происходит, и про чудеса оптимизации как раз и получается.
[22:10.000 --> 22:18.000]  Почему некоторые игры, которые были тогда в PS1, они реально выглядели достаточно круто, несмотря на ограничения по ресурсам.
[22:18.000 --> 22:35.000]  Да, да, да. Ну, еще плюс порядка. Ну, да, да, да. Вот. Ну, на самом деле, с оптимизациями константа будет реально порядка 50-100 мегабайт в секунду.
[22:36.000 --> 22:39.000]  Вот. Без оптимизации это получается где-то 600-700 мегабайт.
[22:39.000 --> 22:54.000]  Вот. И что у нас получается? Смотрите, то есть вот такой объем информации нам нужно перегонять за секунду. Ну, если грубо прикидывать.
[22:55.000 --> 23:02.000]  Хотите вас обратно, как вы думаете, какая мощность процессора была у приставки PS1?
[23:02.000 --> 23:17.000]  Тут тоже определенные вычисления были. Мощность процессора PlayStation 1.
[23:17.000 --> 23:33.000]  То есть частота процессора не выросла в порядке. То есть нам нужен был скачок. Но порядка, у нас произошел скачок только на один порядок.
[23:34.000 --> 23:44.000]  То есть мы не успеваем вывозить разрешение на экран. Ну, и тогда смотреть. Классический пример. Давайте сделаем следующее.
[23:44.000 --> 23:59.000]  Посмотрим на вот эту игру и посмотрим на картинки. Не знаю, вот к примеру. Так, это In Unity какой-то.
[23:59.000 --> 24:18.000]  Ну вот, смотрите. Открою картинку. Вот так выделила игрушка Crash Bandicoot в 90-е годы. То есть видно какие-то очень грубые фигуры.
[24:18.000 --> 24:26.000]  И как выглядит она сейчас на перезапуске. То есть тогда мощность центрального процессора просто не хватало для того, чтобы это отрисовывать.
[24:27.000 --> 24:39.000]  Поэтому старались максимально все оптимизировать. И из-за этого переход из 2D в 3D оказался, ну, некоторые игры просто, так сказать, потеряли свой шарм при переходе от 2D в 3D.
[24:39.000 --> 24:48.000]  То есть у вас была красивая картинка, грубо говоря. Тот же самый Марио бегает, прыгает, прыгает, все хорошо. Да, вы переходите на 3D и у вас какая-то кашель на экране.
[24:49.000 --> 24:53.000]  Понятно, что это людям не нравилось. Вот. И здесь как раз возникает первый фазовый переход.
[24:54.000 --> 25:12.000]  Который заключается в том, что некоторые компании решили как раз заняться тем, а что если мы вместо классической видеокарты будем к ней подключать, которые будут чисто заниматься отрисовкой изображений на экран.
[25:12.000 --> 25:26.000]  Вот. И так появилась компания 3DFX, и у нее был графический ускоритель по имени Voodoo. Значит, здесь скриншот с сайта, собственно, 3DFX Historia.
[25:27.000 --> 25:38.000]  И слева мы видим изображение с вами игры без графического ускорителя Voodoo, справа с графическим ускорением Voodoo. То есть левая рендерилась на CPU, правая рендерилась на обновленный GPU.
[25:38.000 --> 25:40.000]  Разница видна?
[25:45.000 --> 25:46.000]  Нет.
[25:46.000 --> 25:47.000]  Понятно.
[25:47.000 --> 25:54.000]  Ну, на самом деле просто деталь стала отрисовываться намного больше, и фигурки стали на более платье.
[25:54.000 --> 26:09.000]  Честно, я почему это привожу, потому что я сам с этим столкнулся. Правда, тогда уже Glide не был, это в 2005-2006 году стоял, но как бы был специальный патч, который позволял отрисовать, перейти в поддержку Glide.
[26:10.000 --> 26:17.000]  Ну, реально игра стала совсем другой. Вот. Ну, кажется, что все замечательно. Есть компания 3DFX, есть графический ускоритель Voodoo.
[26:18.000 --> 26:22.000]  Вопрос. Вы сейчас в первый раз услышали про этот графический ускоритель?
[26:23.000 --> 26:24.000]  Да.
[26:24.000 --> 26:26.000]  Да, а это значит, что что-то с ним произошло.
[26:28.000 --> 26:33.000]  Значит, компания 3DFX начала выпускать графический ускоритель Voodoo, Voodoo 2, Voodoo 3.
[26:34.000 --> 26:41.000]  Более того, такая популярная игра, как Quake 3 в свое время, она просто без Glide нормально не запускалась.
[26:41.000 --> 26:52.000]  Ну, и компания сказала, значит, здрасте. Мы такие, ура, у нас все идет в гору, все замечательно, мы живем в шоколаде.
[26:53.000 --> 26:58.000]  Но это был конец 90-х, начало нулевых годов, а в то время как раз был этот, крах.ком.
[26:59.000 --> 27:06.000]  То есть, когда все IT-компании реально повалились в цене и в итоге нужно было выживать каким-то образом.
[27:06.000 --> 27:11.000]  А более того, помимо компании 3DFX появились новые компании.
[27:12.000 --> 27:16.000]  Значит, первая компания это компания Nvidia. Она как раз тогда набирала обороты.
[27:17.000 --> 27:20.000]  Это 2000 год. Они сделали следующую вещь. Это создатели шейдеров.
[27:21.000 --> 27:26.000]  То есть, что такое шейдер? Это программированные модули для вычисления световых характеристик или цветовых характеристик.
[27:27.000 --> 27:34.000]  То есть, свет, это отражение света падает, который у нас свет, это отрисовка разных экранов, разных цветов, текстуры наложить.
[27:34.000 --> 27:37.000]  И появилась вторая компания, которая называется Silicon Graphics.
[27:38.000 --> 27:43.000]  Она по факту создала стандарт под названием OpenGL, Open Graphical Language.
[27:44.000 --> 27:49.000]  И на самом деле, до где-то 17-19-го года, это был стандарт de facto для отрисовки графики.
[27:50.000 --> 27:53.000]  То есть, у вас появляется интерфейс, в котором вы можете работать независимо от видеокарт.
[27:54.000 --> 27:58.000]  Ну и, собственно, они дали API для этого доступа.
[27:58.000 --> 28:05.000]  И компания 3DFX была встала в обороты, поскольку проект был достаточно приоперитарным и не замечал конкурентов.
[28:06.000 --> 28:07.000]  В итоге, что произошло?
[28:08.000 --> 28:09.000]  Произошло следующее исторически.
[28:10.000 --> 28:14.000]  Значит, компания 3DFX была выкуплена компанией NVIDIA за гроши.
[28:15.000 --> 28:16.000]  Реально за гроши.
[28:17.000 --> 28:21.000]  После этого компания Silicon Graphics тоже была продана, по-моему, компанией ETI.
[28:22.000 --> 28:24.000]  А компания AMD потом выкупила компанию ETI.
[28:25.000 --> 28:28.000]  То есть, в итоге сейчас у нас есть два крупных производителя видеокарт.
[28:29.000 --> 28:30.000]  Это NVIDIA и AMD.
[28:31.000 --> 28:32.000]  Вот такая вот история.
[28:33.000 --> 28:38.000]  У нас появились с вами шейдеры, которые позволяют отрисовывать изображение на экран.
[28:39.000 --> 28:41.000]  То есть, программирование модуля.
[28:42.000 --> 28:45.000]  Это значит, что у нас есть всякие функции, которые мы с вами можем использовать.
[28:46.000 --> 28:50.000]  И давайте посмотрим, чтобы понимать, что мы хотим сделать.
[28:51.000 --> 28:52.000]  Мы хотим, чтобы у нас программы быстро работали.
[28:52.000 --> 28:56.000]  Пока что у нас какой-то графический язык и непонятно вообще, как это связано.
[28:57.000 --> 29:01.000]  Для этого нам нужно посмотреть то, каким образом рендерится экран в OpenGL.
[29:02.000 --> 29:03.000]  То есть, у нас с вами есть два шейдера.
[29:04.000 --> 29:09.000]  Первый называется Vertex Processor, который, по факту, позволяет вам построить изображение.
[29:10.000 --> 29:15.000]  Дальше построить точки в пространстве по определенным координатам.
[29:16.000 --> 29:18.000]  Делать какие-то геометрические преобразования.
[29:18.000 --> 29:24.000]  Дальше у вас есть Rasterizer, который, по факту, вы берете границы, он, так сказать, выстраивает фигуры.
[29:25.000 --> 29:27.000]  То есть, у вас есть каркас, вы каркас заливаете.
[29:28.000 --> 29:31.000]  Дальше у вас есть Fragment Processor, который позволяет вычислять цвет.
[29:32.000 --> 29:35.000]  И после этого, значит, фрагменты у нас мерзнутся на экран и проецируются.
[29:36.000 --> 29:42.000]  То есть, как минимум, у нас с вами появляются проецированные модули, которые можно использовать.
[29:43.000 --> 29:47.000]  Вот. И после этого у нас на выходе получается экран.
[29:48.000 --> 29:52.000]  Все замечательно. Но здесь, как говорится, все не без интересных вещей.
[29:53.000 --> 30:03.000]  А программируемые модулями, ну и вообще, вся операция по работе с графикой делается в преобразованиях матрицы 4 на 4.
[30:05.000 --> 30:07.000]  Не матрицы 3 на 3.
[30:08.000 --> 30:10.000]  Как вы думаете, почему?
[30:10.000 --> 30:12.000]  А?
[30:13.000 --> 30:17.000]  Не, не, не. Не по этой причине.
[30:18.000 --> 30:21.000]  Да, однородные координаты.
[30:22.000 --> 30:30.000]  То есть, смотрите, у нас получается так, что мы работаем с вами, когда мы говорим с графикой, не в евклидовой геометрии.
[30:31.000 --> 30:37.000]  Потому что если бы мы работали в классической евклидовой геометрии, то у нас были бы преобразования в вида матрицы 3 на 3.
[30:37.000 --> 30:39.000]  Мы работаем с вами в проективной геометрии.
[30:40.000 --> 30:42.000]  Почему это важно?
[30:43.000 --> 30:45.000]  Мне кажется, у нас сегодня урок в физике.
[30:52.000 --> 30:54.000]  Итак.
[30:55.000 --> 30:59.000]  Извините, пожалуйста, те, кто физику не любят.
[31:00.000 --> 31:02.000]  Но для понимания процесса нам это нужно.
[31:03.000 --> 31:05.000]  Так, смотрите.
[31:06.000 --> 31:14.000]  Ну, так обычно делают, когда говорят, что давайте мы теоретическую механику скроем и назовем математической физикой.
[31:15.000 --> 31:17.000]  Вот.
[31:18.000 --> 31:20.000]  Значит, смотрите, я рисую вот такой замечательный объект.
[31:21.000 --> 31:25.000]  И рисую вот тут вот такую вот штуку.
[31:26.000 --> 31:28.000]  Собственно, догадайтесь, что это такое.
[31:29.000 --> 31:30.000]  Линза, да.
[31:30.000 --> 31:36.000]  Собственно, когда мы работаем в графике, мы на самом деле смотрим все сквозь поверхность некоторых линз.
[31:37.000 --> 31:38.000]  Значит, что у нас происходит?
[31:39.000 --> 31:44.000]  Когда мы пускаем пучок параллельных прямых, то что мы знаем с ней?
[31:45.000 --> 31:46.000]  Вот эти пучки.
[31:47.000 --> 31:48.000]  Куда они?
[31:49.000 --> 31:50.000]  Фокус, да.
[31:51.000 --> 31:52.000]  То есть смотрите, что у нас получается.
[31:53.000 --> 32:00.000]  У нас получается, что пучок параллельных прямых при прохождении через линзу пересекается с фокусом.
[32:01.000 --> 32:08.000]  А это означает, что если прямые пересекались здесь, то прямые, которые были здесь...
[32:11.000 --> 32:12.000]  Замеряли?
[32:13.000 --> 32:14.000]  Нет.
[32:15.000 --> 32:17.000]  Не, в проективной геометрии я говорю.
[32:18.000 --> 32:19.000]  Тоже должны пересекаться.
[32:20.000 --> 32:23.000]  То есть как бы, смотрите, у нас две прямые пересекаются.
[32:24.000 --> 32:27.000]  Первая постула от проективной геометрии, что любые две прямые пересекаются.
[32:28.000 --> 32:34.000]  Если здесь они пересекались вот так, то значит, где они здесь пересекаются?
[32:35.000 --> 32:36.000]  Да, где-то в бесконечности.
[32:37.000 --> 32:41.000]  Опять же, формула для нахождения расстояния, это нам тоже говорит.
[32:43.000 --> 32:47.000]  То есть если мы в качестве f поставим f, то мы получим равновесие бесконечности.
[32:48.000 --> 32:49.000]  То есть здесь все четко.
[32:52.000 --> 32:56.000]  Так, формула для нахождения расстояния в линзе.
[32:59.000 --> 33:03.000]  Мы вообще понимаем, почему у нас матрицы преобразования 4 на 4 должны быть.
[33:06.000 --> 33:07.000]  Да, вот.
[33:11.000 --> 33:14.000]  Вот, смотрите, вот у нас были прямые до преобразования.
[33:14.000 --> 33:16.000]  После преобразования они пересеклись в фокусе.
[33:17.000 --> 33:20.000]  Значит, до преобразования они должны были пересекаться в какой-то точке.
[33:23.000 --> 33:24.000]  Аксиома геометрии такая.
[33:25.000 --> 33:27.000]  То есть мы вводим новую геометрию, которая называется проективной,
[33:28.000 --> 33:30.000]  в которой говорим, что любые две прямые должны пересекаться.
[33:33.000 --> 33:37.000]  Ну, преобразование должно сохранить свойство пересечения прямых.
[33:37.000 --> 33:41.000]  Расскажи это вот этому товарищу, который снимает.
[33:42.000 --> 33:44.000]  Он же пропускает всю информацию через линзу.
[33:45.000 --> 33:48.000]  И он фокусирует пучок параллельных прямых в одну точку на экране.
[33:53.000 --> 33:55.000]  Да, да, да, мы хотим проецировать это на плоскость, да.
[33:57.000 --> 33:58.000]  Вот.
[33:59.000 --> 34:01.000]  То есть смотрите, что у нас получается.
[34:02.000 --> 34:04.000]  У нас любые две параллельные прямые должны пересекаться.
[34:04.000 --> 34:05.000]  В некоторые точки.
[34:06.000 --> 34:08.000]  Значит, эта точка называется бесконечно удаленной точкой.
[34:09.000 --> 34:11.000]  Это постулаток проективной геометрии.
[34:12.000 --> 34:13.000]  Но при этом, смотрите.
[34:15.000 --> 34:18.000]  Что у нас происходит, если мы пустим вот другой пучок параллельных прямых?
[34:22.000 --> 34:23.000]  А?
[34:23.000 --> 34:24.000]  Они пересекутся на фокальной плоскости.
[34:27.000 --> 34:28.000]  Угу.
[34:29.000 --> 34:30.000]  Ну, вот.
[34:30.000 --> 34:31.000] 've changed course.
[34:32.000 --> 34:33.000]  Ой,ange it expressed.
[34:34.000 --> 34:36.000]  А что мы можем сказать про вот эту точку А.
[34:37.000 --> 34:39.000]  И вот эту точку Б?
[34:40.000 --> 34:42.000]  Они на одной прямой лежат.
[34:46.000 --> 34:47.000]  Но они лежат на фокальной плоскости.
[34:48.000 --> 34:51.000]  Значит, смотрите, если точки у нас лежат
[34:52.000 --> 34:54.000]  на фокальной плоскости, на одной плоскости.
[34:55.000 --> 34:57.000]  То и то при образовании они должны лежать на одной и той же плоскости.
[34:58.000 --> 34:59.000]  На бесконечно удаленной.
[35:00.000 --> 35:12.000]  что все бесконечно удаленные прямые, все бесконечно удаленные точки лежат на бесконечно удаленной прямой в случае 2D и на бесконечно удаленной плоскости в случае 3D.
[35:15.000 --> 35:27.000]  Вот аксема проективной геометрии. А теперь смотрите, какие чудеса. Чудеса заключаются в том, что всю вот эту геометрию можно зашить при помощи как раз однородных координат.
[35:27.000 --> 35:36.000]  То есть, любая точка в проективной геометрии может представляться в виде пары x, y, z, t, где у нас есть эквалютное преобразование.
[35:37.000 --> 35:43.000]  То есть, любое домножение всех координат на альфу приводит нас к однородности.
[35:44.000 --> 35:50.000]  Значит, каким образом зашить в эту геометрию теперь бесконечно удаленную прямую и не бесконечно удаленную прямую?
[35:51.000 --> 35:58.000]  Значит, если мы говорим, что нам нужна бесконечно удаленная прямая, то мы полагаем t равное нулю.
[35:59.000 --> 36:02.000]  То есть, у этих объектов t равное нулю.
[36:03.000 --> 36:08.000]  Значит, если мы говорим про классическую эвклидную геометрию, то в ней будет t равно единиц.
[36:09.000 --> 36:14.000]  Тогда у нас все преобразования могут отнормироваться на этот коэффициент t.
[36:15.000 --> 36:16.000]  Чего?
[36:17.000 --> 36:18.000]  То есть, t просто отнормировано?
[36:19.000 --> 36:20.000]  Да, да, t просто…
[36:21.000 --> 36:23.000]  Да, бесконечно удаленную, не бесконечно удаленную.
[36:24.000 --> 36:27.000]  Уже вот x, y, z, t, это тоже какая-то проективная геометрия?
[36:28.000 --> 36:29.000]  Да.
[36:30.000 --> 36:31.000]  Какая?
[36:31.000 --> 36:32.000]  В смысле?
[36:33.000 --> 36:35.000]  В плане, как кризнаты задают?
[36:36.000 --> 36:40.000]  А, для этого нужно смотреть, для этого нужно посмотреть на…
[36:40.000 --> 36:44.000]  Тоже пустить, так сказать, пучок, выполнить проекцию и понять, где на плоскости эта проекция будет.
[36:49.000 --> 36:51.000]  Ну, чтобы было удобно с этим работать.
[36:52.000 --> 36:59.000]  Да, просто накоалентность удобна и матрица преобразований из одной системы кардинат другую будет намного проще писаться.
[37:04.000 --> 37:07.000]  Ну да, если мы говорим про классическую эвклидную геометрию,
[37:08.000 --> 37:11.000]  да, если это не бесконечно удаленная прямая.
[37:14.000 --> 37:16.000]  Да, в общем, вот такая интересная геометрия.
[37:17.000 --> 37:20.000]  То есть у нас есть, смотрите, перемножение на матрицу вида 4 на 4.
[37:21.000 --> 37:23.000]  И о чудо совпадения, 4 это степень двойки.
[37:30.000 --> 37:33.000]  А представьте себе, что вот для математического моделирования,
[37:33.000 --> 37:37.000]  ну и вообще для компьютерных всяких вычислений степень двойки это отличное число.
[37:39.000 --> 37:43.000]  Да, в памяти находится хорошо и все замечательно.
[37:44.000 --> 37:46.000]  Значит, а тут проективной геометрии…
[37:47.000 --> 37:52.000]  Значит, тут еще показывают какие преобразования можно использовать для различных переводов.
[37:53.000 --> 37:56.000]  То есть мы начинаем рисовывать объект, каким образом он рендерится на экран.
[37:57.000 --> 38:00.000]  То есть здесь у нас есть несколько как раз перемножений вида проективной матрицы.
[38:00.000 --> 38:03.000]  То есть все эти перемножения можно использовать для своих целей.
[38:04.000 --> 38:05.000]  А теперь главный трюк.
[38:06.000 --> 38:09.000]  Давайте мы будем использовать их не для того, чтобы выводить изображение на экран.
[38:11.000 --> 38:13.000]  А для того, чтобы считать что-то для себя.
[38:15.000 --> 38:17.000]  То есть нам не важно, что будет отрисовываться на экране.
[38:18.000 --> 38:20.000]  Нам, допустим, нужно перемножить матрицу быстро.
[38:21.000 --> 38:27.000]  Мы задаем нашу входную матрицу как набор точек в проективной геометрии.
[38:27.000 --> 38:29.000]  Задаем проективные преобразования.
[38:30.000 --> 38:32.000]  А это по факту блочное перемножение матриц.
[38:33.000 --> 38:38.000]  И получаем результат, который получается на выходе относительно этих преобразований.
[38:39.000 --> 38:40.000]  А?
[38:41.000 --> 38:44.000]  Нет, это не то, к чему мы будем заниматься, а то, к чему мы идем.
[38:48.000 --> 38:51.000]  Ну, я так скажу, наперед забегу.
[38:52.000 --> 38:55.000]  Компания Nvidia увидела все это и решила сделать нормальный интерфейс.
[38:56.000 --> 38:57.000]  Для всего этого.
[38:58.000 --> 39:00.000]  Вот, значит, идея такая.
[39:01.000 --> 39:03.000]  Давайте ничего не изображать, а использовать матрицу для вычислений.
[39:04.000 --> 39:06.000]  И здесь у нас возникает концепция из классификации по Флину.
[39:07.000 --> 39:08.000]  Single Instruction Multiple Data.
[39:09.000 --> 39:14.000]  Значит, мы можем одну векторную инструкцию выполнять на некотором векторе значения в один такт времени.
[39:15.000 --> 39:16.000]  Одной ассемлерной инструкцией.
[39:17.000 --> 39:19.000]  Вот как раз, посмотрите, у нас по факту есть набор точек.
[39:19.000 --> 39:24.000]  Этот набор точек нужно быстро привести проективным преобразованием в какой-то другой набор точек.
[39:25.000 --> 39:27.000]  Почему бы это не сделать одной ассемлерной командой?
[39:30.000 --> 39:35.000]  Просто поставить одно устройство управления на некоторый набор регистров.
[39:36.000 --> 39:38.000]  Как говорится, сказано, сделано.
[39:39.000 --> 39:42.000]  То есть, это у нас как раз есть в видеокарте и появился как раз специальным механизм.
[39:43.000 --> 39:46.000]  Язык в то время назывался brook.
[39:46.000 --> 39:48.000]  Это обертка на DAP компьютерная графика.
[39:49.000 --> 39:51.000]  То есть, у нас был OpenGL, а поверх него был brook.
[39:52.000 --> 39:57.000]  Точнее, поверх механизма шейдеров, которое позволяет выполнить некоторые векторные операции.
[40:00.000 --> 40:04.000]  Ну, даже есть статья, которая позволяет это сделать.
[40:05.000 --> 40:07.000]  API напоминаю, что это Application Programming Interface.
[40:08.000 --> 40:11.000]  То есть, это тот формат, в котором мы взаимодействуем.
[40:11.000 --> 40:15.000]  Вы уже, наверное, знакомы с тем, как работает MPI.
[40:17.000 --> 40:19.000]  Все были на семинарах по MPI.
[40:20.000 --> 40:22.000]  И вы пользовались компилятором MPiCC.
[40:23.000 --> 40:26.000]  Здесь такая же была обертка, код brookCC.
[40:27.000 --> 40:28.000]  Язык назывался.
[40:29.000 --> 40:35.000]  Я не знаю, у меня, по-моему, даже где-то здесь должны быть исходники этого всего.
[40:35.000 --> 40:36.000]  Вот они.
[40:37.000 --> 40:39.000]  Собственно, это код на этом.
[40:42.000 --> 40:44.000]  Исходный код brook.
[40:45.000 --> 40:51.000]  Здесь, на самом деле, видно, что есть вот такой вот механизм.
[40:52.000 --> 40:54.000]  Давайте откроем текстовый редактор.
[40:54.000 --> 40:57.000]  Не знаю, видно ли что-то или нет.
[41:01.000 --> 41:04.000]  Вот. Ну, тут есть специальные именно коды.
[41:05.000 --> 41:07.000]  То есть, видите, какие-то коды.
[41:08.000 --> 41:09.000]  Вот.
[41:10.000 --> 41:11.000]  Вот.
[41:12.000 --> 41:13.000]  Вот.
[41:14.000 --> 41:15.000]  Вот.
[41:16.000 --> 41:17.000]  Вот.
[41:18.000 --> 41:19.000]  Вот.
[41:20.000 --> 41:21.000]  Вот.
[41:21.000 --> 41:22.000]  Коды.
[41:23.000 --> 41:28.000]  То есть, видите, какие-то слова, которые отличаются от классического C.
[41:37.000 --> 41:45.000]  Да, смотрите, появляется ключевое слово kernel, которое обозначает, что этот набор инструкций нужно трансформировать в набор команд для видеокарт.
[41:46.000 --> 41:49.000]  То есть, обычно пишутся на видеокарте ядра.
[41:49.000 --> 41:50.000]  Вот.
[41:51.000 --> 41:53.000]  И второе здесь дополнительное ключевое слово есть reduce.
[41:54.000 --> 41:55.000]  То есть, это операция свертки.
[41:56.000 --> 41:59.000]  Для того, чтобы сложить какой-то результат.
[42:00.000 --> 42:03.000]  Понятно, что это все использует OpenGL runtime.
[42:04.000 --> 42:09.000]  То есть, и как раз, видите, тут уже большое количество прямо было написано разных вещей.
[42:10.000 --> 42:12.000]  Даже трассировка была написана.
[42:13.000 --> 42:16.000]  В принципе, можно почитать исходный код, но это не наша цель, на самом деле.
[42:16.000 --> 42:18.000]  Наша цель – понять вот такую вещь.
[42:19.000 --> 42:25.000]  Это график производительности, который был получен на разных видеокартах в зависимости от временной шкалы.
[42:26.000 --> 42:28.000]  И что мы с вами здесь замечаем?
[42:29.000 --> 42:35.000]  Процессор Pentium 4, несмотря на то, что они выпускались как процессор нового поколения, мы видим, что производительность растет не сильно.
[42:36.000 --> 42:42.000]  Да, но при этом код, который был написан на разных видеокартах, NVIDIA и ATI,
[42:43.000 --> 42:48.000]  в каком у него рост по производительности?
[42:49.000 --> 42:50.000]  Прямо порядке.
[42:51.000 --> 43:00.000]  Да, порядке. То есть, смотрите, как раз у нас появляется следующее, что за какое-то обозримое время у нас скорость вычисления увеличивается в разы.
[43:01.000 --> 43:05.000]  А это как раз и то, что говорит закон Moora в неверной постановке.
[43:06.000 --> 43:09.000]  Что говорит закон Moora в неверной постановке?
[43:10.000 --> 43:17.000]  Что за каждые два года, за каждые 24 месяца количество транзисторов в электронной схеме будет возрастать два раза.
[43:18.000 --> 43:21.000]  Количество транзисторов в компьютерной схеме.
[43:22.000 --> 43:24.000]  И, как ни странно, это выполняется.
[43:25.000 --> 43:28.000]  Ну, возможно, сейчас уже с некоторыми ограничениями, но потому что у нас есть техпроцесс.
[43:29.000 --> 43:33.000]  И сейчас, собственно, величина транзистора измеряется несколькими нанометрами.
[43:34.000 --> 43:35.000]  И это уже не очень много.
[43:35.000 --> 43:42.000]  А на видеокарте, как ни странно, до сих пор выполняется закон Moora, но он выполняется как раз про количество операций.
[43:43.000 --> 43:49.000]  То есть, до сих пор новые версии видеокарты позволяют получить все большее и большее количество операций в секунду.
[43:50.000 --> 43:58.000]  Ну, это было все в NVIDIA VTI, и компания поняла, что это золотая жила, и они решили сделать следующее.
[43:58.000 --> 44:04.000]  Они решили придумать свой механизм для вычисления кода всяких механизмов на видеокарте.
[44:05.000 --> 44:07.000]  Значит, смотрите, это модель шейдера.
[44:08.000 --> 44:09.000]  Каким он выглядит?
[44:10.000 --> 44:11.000]  Что подойдет на вход шейдера?
[44:12.000 --> 44:18.000]  У нас есть некоторый набор входных регистров, через которые у нас передаются, так сказать, константы.
[44:19.000 --> 44:22.000]  Типа, у нас есть точка на плоскости, и нам нужно ее отрисовать.
[44:23.000 --> 44:24.000]  Покрасьте в какой-то цвет.
[44:25.000 --> 44:27.000]  Значит, что в ходу можно туда присобачить?
[44:28.000 --> 44:29.000]  Текстуру, которую нам нужно отрисовать.
[44:30.000 --> 44:31.000]  Что такое текстура?
[44:32.000 --> 44:34.000]  Это по факту обои либо цвет, который нам нужно прорисовать.
[44:35.000 --> 44:41.000]  Дальше у нас есть некоторый набор констант, который мы можем зашить, и некоторый набор регистров общего назначения.
[44:42.000 --> 44:47.000]  Они все подойдут в фрагментную программу, и мы получаем с вами выходные регистры.
[44:48.000 --> 44:49.000]  То есть, выходные регистры это по факту...
[44:50.000 --> 44:51.000]  Что там?
[44:52.000 --> 44:54.000]  Для каждой точки на экране мы определяем ее цветом.
[44:55.000 --> 45:00.000]  То есть, это то, как изначально пользовались эти всеми на видеокарте.
[45:01.000 --> 45:06.000]  Но понятно, что таким образом мы с вами не можем работать никаким образом с массивами.
[45:07.000 --> 45:08.000]  Это проблемно.
[45:09.000 --> 45:10.000]  Но тогда что мы сможем с вами сделать с массивами?
[45:11.000 --> 45:16.000]  Давайте мы вместо того, чтобы использовать в данной концепции входные регистры,
[45:17.000 --> 45:21.000]  давайте мы передадим идентификатор нашего потока.
[45:22.000 --> 45:25.000]  То есть, у нас с вами будет на вход подаваться номер потока,
[45:26.000 --> 45:30.000]  который отвечает за выполнение операции, не какой-то набор значений.
[45:31.000 --> 45:34.000]  А фрагментную программу переименуем в thread program.
[45:35.000 --> 45:36.000]  То есть, она на входе будет принимать какое-то число,
[45:37.000 --> 45:40.000]  и в зависимости от этого числа будет выполнять какую-то операцию.
[45:41.000 --> 45:42.000]  Значит, давайте я спрошу.
[45:43.000 --> 45:44.000]  MPI все заботали?
[45:47.000 --> 45:48.000]  Хорошо.
[45:49.000 --> 45:51.000]  Тогда рубрика повторяем MPI.
[45:52.000 --> 45:56.000]  Когда у нас компьютер запускается в одну,
[45:57.000 --> 46:00.000]  когда он из несколько процессоров запускается,
[46:01.000 --> 46:04.000]  в несколько процессов запускается в общую программу,
[46:05.000 --> 46:07.000]  то что назначается каждому процессу?
[46:09.000 --> 46:10.000]  Да.
[46:11.000 --> 46:13.000]  Этот номер обращается от rank.
[46:14.000 --> 46:17.000]  То есть, у нас есть группа под названием combo,
[46:17.000 --> 46:22.000]  из которой мы можем знать world size, размер группы.
[46:23.000 --> 46:26.000]  И каждому процессу назначается rank ID.
[46:28.000 --> 46:30.000]  От 0 до world size минус 1.
[46:31.000 --> 46:38.000]  Это позволяет нам использовать концепцию single program multiple data.
[46:39.000 --> 46:42.000]  То есть, мы пишем одну программу на обработку большого объема данных.
[46:42.000 --> 46:47.000]  Это под концепцией multiple instruction multiple data.
[46:51.000 --> 46:54.000]  В данной концепции мы говорим следующее.
[46:55.000 --> 46:57.000]  Давайте вместо того, чтобы у нас был rank,
[46:58.000 --> 47:00.000]  мы с вами передадим некоторую константу,
[47:01.000 --> 47:02.000]  которая называет straight IDX.
[47:03.000 --> 47:06.000]  То есть, у нас будет номер потоков и вещества.
[47:06.000 --> 47:08.000]  На самом деле, мы можем получить элементы массива,
[47:09.000 --> 47:11.000]  которые должны обрабатываться данным массивом.
[47:12.000 --> 47:15.000]  Там они будут от нуля до бесконечности.
[47:16.000 --> 47:18.000]  Ну, не до бесконечности, до максимального ограничения.
[47:19.000 --> 47:21.000]  Сразу скажу, что это логическая абстракция.
[47:22.000 --> 47:24.000]  На физическом уровне это будет немного по-другому.
[47:25.000 --> 47:27.000]  Значит, у нас появляется вот такой вот номер потока,
[47:28.000 --> 47:30.000]  который мы с вами, в принципе, можем использовать.
[47:30.000 --> 47:31.000]  А дальше мы сделаем следующее.
[47:32.000 --> 47:34.000]  Ну, понятно, что выходные регистры писать неудобно,
[47:35.000 --> 47:38.000]  поэтому было бы неплохо иметь память для хранения тех ресурсов.
[47:39.000 --> 47:42.000]  То есть, не дать больший контроль нашим исполнению.
[47:43.000 --> 47:44.000]  То есть, вместо того, чтобы указывать,
[47:45.000 --> 47:47.000]  что вот эти пиксели отрисовываются в какое-то место на экране,
[47:48.000 --> 47:50.000]  давайте мы будем указывать, что именно запиши, пожалуйста,
[47:51.000 --> 47:52.000]  это все вот конкретный элемент массива.
[47:53.000 --> 47:55.000]  То есть, у нас будет номер потока.
[47:55.000 --> 47:58.000]  То есть, мы будем required на экране.
[47:59.000 --> 48:01.000]  И третий переход, который здесь был.
[48:02.000 --> 48:04.000]  Это, собственно, нужно добавить разделяемую память.
[48:05.000 --> 48:06.000]  Что такое разделяемая память?
[48:07.000 --> 48:09.000]  Это память, которая доступна соседним элементам.
[48:10.000 --> 48:13.000]  То есть, представь себе, что нам нужно посчитать какую-нибудь локальную свертку.
[48:14.000 --> 48:16.000]  Вот, у нас, допустим, есть сверточный слой,
[48:17.000 --> 48:19.000]  и нам нужно взять значение только соседних элементов,
[48:20.000 --> 48:21.000]  но не всех элементов.
[48:22.000 --> 48:24.000]  И поэтому нам нужен более, более-более большой диагноз,
[48:25.000 --> 48:33.160]  быстрый доступ к соседним элементам, чем к глобальной памяти, а-ля кэш. Вот. И про что мы
[48:33.160 --> 48:36.880]  будем с вами в следующий раз говорить? Мы будем говорить с вами про то, что на самом деле в
[48:36.880 --> 48:45.560]  видеокарте кэш управляемый, в отличие от центральных процессоров. Вот. И в итоге вот такая вот
[48:45.560 --> 48:51.000]  архитектура нам позволила сделать следующее. Она позволяет нам сказать, что есть некоторая
[48:51.000 --> 48:58.880]  архитектура, которая по факту выполняется на видеокартах, но при этом уже готова к тому,
[48:58.880 --> 49:06.320]  чтобы мы с вами могли обрабатывать наши массивы, наши элементы при помощи классических стандартных
[49:06.320 --> 49:12.360]  операций. То есть это максимально приближено у нас получается к MPI. Вот. Но при этом мы будем
[49:12.360 --> 49:19.440]  все считать на видеокартах. Значит, это называется CUDA, а расшифровывается как Compute Unified Device
[49:19.440 --> 49:25.560]  with Architecture. То есть это архитектура, которая позволяет на самом деле использовать графические
[49:25.560 --> 49:34.040]  ускорители от компании NVIDIA, как процессоры общего назначения. То есть вы можете написать,
[49:34.040 --> 49:41.000]  смотрите, в чем особенность. Вы в принципе можете написать похожий код как на CPU, и он у нас
[49:41.000 --> 49:49.720]  запустится. Правда, он будет работать сильно медленнее, но он запустится. Вот. И какая история
[49:49.720 --> 50:00.360]  этой всей, этого всего процесса? А первая версия CUDA появилась 15 февраля 2007 года. То есть это сколько
[50:00.360 --> 50:18.760]  лет назад? Ну уже 17, наверное. Да. То есть уже через несколько лет, вы понимаете, CUDA будет старше,
[50:18.760 --> 50:26.520]  чем люди, которые будут проходить эту CUDA. Вот. А последняя версия, которая сейчас является стабильной,
[50:26.520 --> 50:37.640]  это CUDA 12. Она была выпущена в 2022 году для поддержки карты RTX 40 звездочка-звездочка. Не исключаю,
[50:37.640 --> 50:45.840]  что в этом году выйдет 13-я CUDA. Ну или если посчитают, что 13 это плохое число, будет выпущена
[50:45.840 --> 50:55.280]  сразу 14-я версия CUDA. Ну посмотрим. Вот. И, естественно, вот эта архитектура нам позволяет каким-то
[50:55.280 --> 51:01.480]  образом выполнять ускорение. Пока, правда, непонятно каким образом она это будет делать,
[51:01.480 --> 51:09.520]  но сейчас мы это посмотрим. Так, есть ли вопросы? Это такое введение. История, как мы дожили до жизни такой.
[51:09.520 --> 51:20.840]  Хорошо. Давайте теперь поговорим про базовые понятия, которые у нас есть в CUDA. Сейчас сразу скажу,
[51:20.840 --> 51:27.240]  что будет большое количество определений, потому что архитектурно это все отличается. Первое,
[51:27.240 --> 51:32.080]  что нам нужно понять, это какие виды памяти существуют в концепции CUDA. Значит, у нас,
[51:32.080 --> 51:37.160]  у оперативной, на нашем компьютере есть своя собственная память, это оперативная память,
[51:37.160 --> 51:47.760]  и есть память видеокарты. Это называется host memory, это наша память, нашего компьютера. И есть
[51:47.760 --> 51:55.880]  device memory, это память устройства. То есть они находятся независимо друг от друга. И не поверите,
[51:55.880 --> 52:02.640]  зачастую как раз указывается количество памяти, которое у нас есть на видеокарте. То есть вы открываете
[52:02.640 --> 52:11.000]  какой-нибудь интернет-магазин, или идете в магазин, и у вас там написано, образно говоря, GTX 3080,
[52:11.000 --> 52:19.880]  столько-то гигабайт. Это означает, сколько гигабайт у вас есть. Это оперативная память. Давайте я как
[52:19.880 --> 52:30.400]  раз параллельно буду открывать. Здравствуй, Crash. RTX 3090. Ну, собственно, ценник тут понятный.
[52:30.400 --> 52:50.240]  Да, игрушка недешевая. Ну, кстати, дешевле становится. Техпроцесс 5 нм, то есть это не очень много.
[52:50.240 --> 52:57.720]  И вот что мы здесь видим с вами. Здесь нам нужно количество памяти. Видите, объем видеопамяти 24
[52:57.720 --> 53:04.960]  гигабайт. То есть девайс memory, который мы можем алоцировать, это 24 гигабайта на видеокарте. То есть видно,
[53:04.960 --> 53:11.480]  что уже на некоторых компьютерах оперативной памяти уже меньше. Вот сколько оперативной
[53:11.480 --> 53:26.040]  памяти на ваших компьютерах? Ну, 8.16 у кого-то 32, у кого-то 64. То есть видно, что как бы есть разница.
[53:26.040 --> 53:36.600]  То есть понятно, что память одна, девайс память другая. Так, давайте дальше. Потоки. Вот тут важная вещь.
[53:36.600 --> 53:43.560]  Сейчас я буду говорить про физическую абстракцию. Поэтому, чтобы вы понимали, я обычно рисую таблицу.
[53:43.560 --> 53:58.640]  Значит, у нас есть физическая абстракция и есть логическая абстракция. Мы начнем с физики.
[53:58.640 --> 54:07.640]  Вот, хотя код, когда вы будете писать, вы будете говорить, мы будем говорить про логи. То есть это как
[54:08.640 --> 54:15.080]  первая абстракция. Это кудоядро. Это атомная единица вычисления на видеокарте.
[54:15.080 --> 54:30.040]  Вот, количество кудоядер можно посмотреть на спецификации сайта, но при этом его тоже
[54:30.040 --> 54:35.440]  можно вычислить самостоятельно. Дальше следующая абстракция, которая у нас есть, это абстракция ворб.
[54:35.440 --> 54:47.720]  Она состоит из набора кудо-потоков. И смотрите, в чем особенность. Особенность в том, что устройство
[54:47.720 --> 54:58.600]  управления находится не в кудоядре, а находится в ворте. То есть именно здесь происходит управление
[54:58.600 --> 55:06.280]  регистрами. Не здесь. При этом обычно, если мы говорим про спецификацию, у нас получается,
[55:06.280 --> 55:14.640]  что на один ворб, по современным архитектурам видеокарты, 32 ворпа. То есть одно устройство
[55:14.640 --> 55:24.200]  управления одновременно управляет 32 ядрами. Это означает следующее, что если у вас, допустим,
[55:24.200 --> 55:29.320]  будет некоторое дивергентное поведение. Что это означает? Это означает, допустим,
[55:29.320 --> 55:35.960]  что у вас на первые 16 кудоядер вы хотите отправить одну команду, а на вторые 16 ядер вы хотите
[55:35.960 --> 55:40.840]  отправить другую команду. Они будут вставать последовательно. То есть первые 16 будут
[55:40.840 --> 55:47.360]  обрабатывать одну команду, и вторые 16 будут ждать, пока первые 16 выполнят эту команду. Поэтому
[55:47.360 --> 55:55.280]  лучше делать все эти команды плочно, чтобы все 32 кудоядра, которые находятся в одном ворпе,
[55:55.280 --> 56:06.800]  выполняли одну и ту же команду. Но он так и сделает. Он сделает это в два такта.
[56:06.800 --> 56:19.760]  То есть желательно, чтобы они все-таки в одном такте все это делали. Ну да, то есть у нас получается,
[56:19.760 --> 56:25.560]  ну мы используем, так сказать, половину ресурсов видеокарты. Ну просто потому,
[56:25.560 --> 56:31.720]  что мы делаем две операции. Хотя можно было бы, допустим, смотрите, если у вас первые 16 делают
[56:31.720 --> 56:37.480]  одну, вторые 16 делают вторую, потом еще 16 делать одну и еще 16 делать вторую. Может быть, надо
[56:37.480 --> 56:44.280]  поменять порядок и сделать вот так. То есть чтобы эти 32 выполняли последний, эти 32 выполняли
[56:44.280 --> 56:49.480]  последний, одну операцию. То есть вот такой шаблон будет работать два раза быстрее, чем вот такой шаблон.
[56:49.480 --> 57:05.880]  Ну как быстро, так сказать, они выполняют ее параллельно. Они все-таки обрабатывают чуть
[57:05.880 --> 57:12.120]  медленнее, чем центральный процессор. Потому что здесь как раз одна команда будет, каждым кудоядром
[57:12.120 --> 57:19.400]  будут выполняться в спецификациях в частоте. То есть у нас там, грубо говоря, центральный процессор имеет
[57:19.400 --> 57:25.280]  частоту порядка 3 ГГц, то есть они могут делать 3 на 10 9 операции. Здесь они будут выполнять порядка
[57:25.280 --> 57:31.840]  полутора на 10 в 9 операции в секунду, каждый отдельно, но получается за счет того, что у нас есть общий
[57:31.840 --> 57:41.440]  ворб, то как бы количество операций будет умножаться на 32 в этот момент времени. Так, значит, это ворб,
[57:41.440 --> 57:48.600]  да, несколько кудоядр, как и одно единое целое, выполняют. А дальше есть еще одна абфракция,
[57:48.600 --> 57:59.320]  которая называется стриминг мультипроцессор. Она состоит из набора ворбов, причем наборов ворбов
[57:59.320 --> 58:06.960]  в физическом исполнении. И вот здесь как раз у нас возникает одно такое интересное понятие.
[58:06.960 --> 58:13.080]  Значит, в центральных процессорах, вы как понимаете, существует два типа ядер. Это физическое ядро и,
[58:13.080 --> 58:22.400]  Господи, как оно еще называется? Виртуальные ядра, да. Вот SM это как раз аналог физического ядра.
[58:22.400 --> 58:34.520]  Вот, если мы говорим про ворб, это больше виртуальный ядро. Вот, и как мы понимаем,
[58:34.520 --> 58:39.400]  в центральных процессорах обычно физическое ядро состоит из двух виртуальных. Здесь же тоже
[58:39.400 --> 58:44.600]  есть некоторые ограничения, в зависимости от архитектуры видеокарты. У нас получается на один
[58:44.600 --> 58:50.960]  стриминг мультипроцессор приходится либо два, либо четыре виртуальных ядра, то есть ворпа.
[58:50.960 --> 58:57.840]  В большинстве видеокарт у нас будет использоваться именно четыре ворпа, но, как ни странно, на том
[58:57.840 --> 59:03.240]  сервере, на который мы с вами будем работать, там будет именно на одно физическое ядро два виртуальных
[59:03.240 --> 59:13.400]  ядра, два ворпа. То есть это зависит от архитектуры самой видеокарты. Вот такая вот у нас физическая
[59:13.400 --> 59:19.200]  абстракция. Но, опять же, если у нас физическая абстракция есть, с ней непонятно, что пока делать.
[59:19.200 --> 59:24.720]  Но она будет важна для того, чтобы мы понимали с вами, как организовывать логическое пространство.
[59:24.720 --> 59:34.200]  И тут как раз есть задача, которая есть. Представьте себе, что у некоторого Паша есть видеокарта.
[59:34.200 --> 59:45.960]  Старая видеокарта. Что он прочитал? Он прочитал, что в нём находится 2560 кудоядер. Это правда.
[59:45.960 --> 59:52.920]  Дальше он пытался долгим вечером разобраться, собственно, какая здесь константа, два или четыре.
[59:52.920 --> 59:58.440]  И узнал, что в спецификации количество стриминг-мультипроцессоров равняется 20.
[59:58.440 --> 01:00:09.800]  То есть здесь у нас 23 мультипроцессоров на 2560 кудоядер. Вопрос. Сколько ворпов в одном стриминг-мультипроцессоре?
[01:00:09.800 --> 01:00:18.920]  Ну, смотрите, нужно вот эту величину поделить на вот эту. Тогда мы поймем, сколько ворпов у нас всего
[01:00:18.920 --> 01:00:30.320]  существует. То есть это у нас получается 2560 поделить на 128. Ой, на 20. Мы получаем с вами 128.
[01:00:30.320 --> 01:00:40.040]  И дальше вот эту величину нужно поделить на количество ядер в ворпе. Получаем, что здесь константа четыре.
[01:00:40.040 --> 01:00:44.480]  То есть на самом деле по количеству стриминг-мультипроцессоров вы явно можете
[01:00:44.480 --> 01:00:49.920]  посчитать количество кудоядер. О, количество ворпов в одном стриминг-мультипроцессоре.
[01:00:49.920 --> 01:00:56.120]  Это важно. Так, понятно, как эта задача решается?
[01:00:56.120 --> 01:01:10.120]  А размер ворпа это сколько кудоядер помещается в одном ворпе?
[01:01:10.120 --> 01:01:18.040]  Да, мы хотели узнать, сколько ворпов находится в одном стриминг-мультипроцессоре. Вот, их оказалось
[01:01:18.040 --> 01:01:26.760]  столько. Просто в старых версиях архитектуры видеокарты их было 16, а они 32. Так, хорошо,
[01:01:26.760 --> 01:01:33.080]  это что касается физической абстракции, теперь давайте про логические абстракции. Да, кстати,
[01:01:33.080 --> 01:01:40.360]  картинка. Вот так выглядит один стриминг-мультипроцессор. Вы не поверите, вы можете
[01:01:40.360 --> 01:01:47.640]  даже тут пересчитать, сколько тут регистров есть. Вот оно, то есть у нас есть стриминг-мультипроцессор,
[01:01:47.640 --> 01:01:54.800]  у него есть LED 1 cache, и здесь можно пересчитать, сколько юнитов здесь находится. Как ни странно,
[01:01:54.800 --> 01:02:01.080]  если сложить тут INT плюс FP32, тут их как раз получится 32. То есть это по факту ворпы. Вот,
[01:02:01.080 --> 01:02:09.520]  а то устройство, которое управляет ворпами, оно оранжевое, это ворпшедулер. То есть в нем как
[01:02:09.520 --> 01:02:14.840]  раз мы можем с вами вычислить 32 потока. Значит, здесь есть в новых версиях видеокарты есть
[01:02:14.840 --> 01:02:19.920]  еще тензорные ядра, но я думаю, мы про них поговорим чуть позже, потому что это необходимо
[01:02:19.920 --> 01:02:25.040]  для того, чтобы как раз всякие нейросети обучать. То есть сейчас компания NVIDIA занимается еще тем,
[01:02:25.040 --> 01:02:29.440]  что устройство внедряет всякие штуки для того, чтобы быстрее нейросети обучались, потому что это
[01:02:29.440 --> 01:02:37.600]  коммерчески успешно. Вот, одна из таких вещей — это как раз тензорное ядро. Теперь давайте
[01:02:37.600 --> 01:02:44.440]  поговорим про логические абстракции. Значит, в качестве логической абстракции у нас здесь находится
[01:02:44.440 --> 01:02:53.920]  трет, и обычно один трет выполняется на одном CUDA-ядре. То есть здесь соотношение один к одному.
[01:02:53.920 --> 01:03:03.560]  Следующая абстракция, которая есть, я и нарисую чуть ниже, это блок. Это набор потоков,
[01:03:03.560 --> 01:03:09.760]  которые логически исполняется на единицу времени. Я ее нарисую здесь ниже, почему? Потому что хоть
[01:03:09.760 --> 01:03:17.800]  блок состоит из 3DO, но когда мы будем выполнять блок, он, видеокарта, его будет автоматически бить на ворпы.
[01:03:17.800 --> 01:03:26.680]  То есть блок будет делиться на ворпы и посылаться команду будет через ворпы.
[01:03:26.680 --> 01:03:35.400]  Поэтому размер блока, который мы с вами задаем, должен быть кратен размеру ворпа. То есть это 32,
[01:03:35.400 --> 01:03:42.600]  64, 128, 256 и так далее. Но, опять же, есть максимальное ограничение. Я напишу его так,
[01:03:42.600 --> 01:03:48.320]  что на один блок можно использовать максимум 1024 потока. Возможно, что архитектура видеокарты
[01:03:48.320 --> 01:03:53.160]  поменяется и вот эта консанта будет меняться в зависимости от архитектуры видеокарты.
[01:03:53.160 --> 01:04:04.840]  Да, он просто заиспользует лишний блок и, соответственно, получается в последнем ворпе
[01:04:04.840 --> 01:04:17.640]  будет использоваться 8 элементов из 32. Ну, в целом ладно, но там 8 там, 8 там накопится в итоге.
[01:04:17.640 --> 01:04:25.360]  Вот, поэтому это лучше как раз... Блоки делятся на ворпы, я сказал. И дальше здесь еще есть одна
[01:04:25.360 --> 01:04:29.240]  абстракция, которая называется гридом. Это набор из блоков,
[01:04:29.240 --> 01:04:41.040]  который выполняется логически. Значит, смотрите, что происходит, когда работает видеокарта? Она
[01:04:41.040 --> 01:04:48.280]  берет грид и делит это все на стриминг мультипроцессоры. То есть у нас один стриминг
[01:04:48.280 --> 01:04:53.720]  мультипроцессор, точнее сказать, один блок выполняется на одном стриминг мультипроцессоре.
[01:04:53.720 --> 01:04:58.800]  То есть что делает стриминг мультипроцессор? Он берет один блок и берет его в обработку.
[01:04:58.800 --> 01:05:07.200]  То есть у нас здесь есть 128 кудо-потоков, кудоядер, допустим, размер блока 256,
[01:05:07.200 --> 01:05:16.760]  он берет и за два такта обрабатывает этот блок. 128 плюс 128. Вот. А грид это логическая абстракция,
[01:05:16.760 --> 01:05:21.920]  которую мы с вами можем использовать для решения наших задач. Для того, чтобы мы не
[01:05:21.920 --> 01:05:26.880]  занимались распределением блоков по стриминг мультипроцессорам, потому что мы не знаем,
[01:05:26.880 --> 01:05:30.880]  сколько стриминг мультипроцессоров в каждой видеокарте есть. То есть у нас наша цель будет
[01:05:30.880 --> 01:05:35.280]  написать код. Опять же, мы про параллельное вычисление здесь говорим, мы больше говорим про ученых,
[01:05:35.280 --> 01:05:42.320]  которые пишут этот код. Поэтому как-то не очень хочется делать так, чтобы указывать явно стриминг
[01:05:42.320 --> 01:05:45.840]  мультипроцессоров, насколько из них параллельно. Тем более часть из них может быть свободна,
[01:05:45.840 --> 01:05:56.040]  часть из них может быть не свободна. Так, хорошо. И смотрите, когда мы запускаем грид. То есть на самом
[01:05:56.040 --> 01:06:10.760]  деле, когда мы запускаем код, мы будем с вами запускать именно грид. Что у нас с вами будет
[01:06:10.760 --> 01:06:17.320]  происходить в этот момент времени? В этот момент времени мы будем с вами задавать при вызове ядра.
[01:06:17.320 --> 01:06:24.680]  Нам нужно будет задать два параметра. Я специально пишу тройные угловые скобки.
[01:06:24.680 --> 01:06:43.080]  Первое это grid-size, а второе это block-size. Это у нас будет количество блоков, а вот это у нас будет
[01:06:43.080 --> 01:06:57.160]  количество потоков в одном блоке. А почему это называется grid? Что такое grid в переводе с английского
[01:06:57.160 --> 01:07:03.120]  языка? Сетка. То есть у нас с вами организуется вот такая сетка. Видеокарта самостоятельно
[01:07:03.120 --> 01:07:20.040]  организует. Значит по горизонтали у нас будет блок dim, а вот этот параметр это grid dim. Давайте
[01:07:20.040 --> 01:07:35.440]  всех переименую, чтобы... И дальше каждый поток, который у нас будет выполнять на исполнение,
[01:07:35.440 --> 01:07:46.560]  получит две определенных константы. Значит вот эта константа будет обозначаться как блок ADX,
[01:07:46.560 --> 01:08:02.920]  а вот эта константа будет обозначаться как thread ADX. Нумерация идет с нуля, то есть у нас
[01:08:02.920 --> 01:08:09.800]  получается здесь ноль и здесь ноль. То есть когда мы задаем логически вот эту вещь, то у нас
[01:08:09.800 --> 01:08:15.560]  автоматически, когда мы будем запускать код ядра, будет выделяться две константы, каждая из которых
[01:08:15.560 --> 01:08:26.840]  будет отличаться у собственного ядра. Давайте вопрос, который я хочу задать. Как вычислить
[01:08:26.840 --> 01:08:43.600]  идентификатор вот этого потока? Вот в этой общей нотации. Да, смотрите, вот это все что до него.
[01:08:43.600 --> 01:09:12.880]  Это что у нас получается? Блок ADX на блок DIM, а вот это thread ADX. То есть
[01:09:12.880 --> 01:09:20.560]  зачастую, когда вы хотите получить номер какого-то потока, то это можно сделать вот таким вот
[01:09:20.560 --> 01:09:30.200]  способом. Вот такой формулой. И при этом это все будет происходить параллельно. Обычно в базовой
[01:09:30.200 --> 01:09:47.120]  концепции что делают? Берут, просто говорят, что у нас green DIM получается, это верхняя целая часть,
[01:09:47.120 --> 01:10:02.800]  N на блок DIM. Да, то есть у нас получается весь массив мы запихиваем в сетку. А дальше видеокарта сама
[01:10:02.800 --> 01:10:09.440]  будет вычислять для каждого элемента массива его позицию. Понятно, что у нас в последних каких-то
[01:10:09.440 --> 01:10:15.880]  элементах у нас элементов не будет. То есть здесь у нас не будет каких-то элементов. Но тогда мы
[01:10:15.880 --> 01:10:20.760]  это можем легко решить. Сказать, что если у нас ADX будет меньше, чем число элементов,
[01:10:20.760 --> 01:10:32.040]  тогда делаем вычисление. Иначе вычисление мы проводить не будем. А потому что если нижняя
[01:10:32.040 --> 01:10:37.160]  грань, то у нас несколько последних элементов просто не будут обрабатываться. Как бы нам
[01:10:37.160 --> 01:10:43.600]  нужна сетка, которая минимально покроет наше все пространство. Да, то есть у нас получается
[01:10:43.760 --> 01:10:49.800]  N делить на размер блока. Понятно, что это не оптимальная конструкция для некоторых вычислений,
[01:10:49.800 --> 01:10:56.520]  но в целом это можно сделать. Почему это важно? Почему важно именно сдавать таким образом? Потому
[01:10:56.520 --> 01:11:03.480]  что на самом деле, когда это все происходит, каждый из этих блоков будет браться определенным
[01:11:03.480 --> 01:11:10.120]  стриммультипроцессором. А мы с вами понимаем, что когда мы берем стриммультипроцессор один,
[01:11:10.120 --> 01:11:16.000]  да, и назначить, допустим, размер блока равный количеству стриммультипроцессора – это плохая
[01:11:16.000 --> 01:11:20.040]  задача. Потому что у нас некоторые стриммультипроцессоры могут работать быстрее,
[01:11:20.040 --> 01:11:25.200]  некоторые освобождаются и так далее. Поэтому вместо того, чтобы городить огород, так сказать,
[01:11:25.200 --> 01:11:32.920]  мы можем сделать следующее. А давайте-ка поверх вот этих вот гридов мы по факту с вами сделаем,
[01:11:32.920 --> 01:11:41.720]  так сказать, thread pool. Так, всем знакомым понятие thread pool. Мы сделаем с вами thread pool поверх
[01:11:41.720 --> 01:11:47.000]  стриммультипроцессоров. Соответственно, как только у нас стриммультипроцессор будет свободен,
[01:11:47.000 --> 01:11:55.000]  он будет вычислять определенную команду. Он будет брать этот блок и обрабатывать. Тем самым вы
[01:11:55.000 --> 01:11:59.640]  можете сами указывать, вам не надо указывать количество стриммультипроцессоров, они просто у вас
[01:11:59.640 --> 01:12:09.200]  начнут с вычисления. Это вот такая вот эффективная абстракция. Тут есть, правда, картинки. Да,
[01:12:09.200 --> 01:12:23.440]  что в этой абстракции есть что? Давайте поймем. Сразу скажу, что здесь изображена логическая
[01:12:23.440 --> 01:12:34.320]  абстракция. Как вы думаете, что здесь является? Да, одно растение. Хорошо, что является блоком?
[01:12:34.320 --> 01:12:53.360]  Да, грядка называется. Что грядом является? Поле, огород. Так, теперь давайте разобремся с
[01:12:53.360 --> 01:13:01.920]  физической абстракцией. Что можно с растениями делать? Зачастую. Что чаще всего делают с растениями?
[01:13:01.920 --> 01:13:13.120]  Поливают, да. Хорошо. Значит, что тогда будет у нас куду-ядром? Да, когда мы поливаем одно
[01:13:13.120 --> 01:13:22.440]  растение. Что такое будет ворб тогда? Ну, вот смотрите, вы берете вот такую большую-большую
[01:13:22.440 --> 01:13:34.240]  вещь, я сейчас ее покажу. Ассинизатор называется. Вот такую вот. Бандурину и берете, проливает.
[01:13:34.240 --> 01:13:38.900]  Соответственно, как только у вас ассинизатор проходит часть ряда по факту, мы можем считать,
[01:13:38.900 --> 01:13:43.840]  что она проходит определенный ворб. То есть, она проливает часть не весь ряд целиком, а вот
[01:13:43.840 --> 01:13:48.800]  маленький кусочек этого ряда. Соответственно, за несколько итераций она берет и обрабатывает
[01:13:48.800 --> 01:13:54.680]  весь ряд. То есть, обрабатывает весь блок. А вот это вот такой вот большой-большой стриминг
[01:13:54.680 --> 01:13:59.840]  мультипроцессор. Она берет и это все проливает. Понятно, что таким образом огород мы можем
[01:13:59.840 --> 01:14:12.320]  пролить намного быстрее. Вот, приблизительно вот так работает видеокарта. Вот. В общем,
[01:14:12.480 --> 01:14:23.000]  вот такие вещи. Ну и давайте, может быть, что-нибудь на затравку я покажу какую-нибудь картинку. Как раз из
[01:14:23.000 --> 01:14:42.400]  исследований, которые мы сейчас делаем. Так, так покажу. Секунду. Вот, для sparse matrix.
[01:14:42.400 --> 01:15:09.200]  Во, не знаю, видно картинка или нет. Давайте я скачаю тогда. Во. Это время обработки. Мы
[01:15:09.200 --> 01:15:15.360]  делаем пакет, который занимается вычислением матриц расстояний. Посмотрите внимательно,
[01:15:15.360 --> 01:15:21.080]  то есть, в зависимости от разреженности матриц, какая скорость работы программ. Значит,
[01:15:21.080 --> 01:15:30.280]  последний метод, который предпоследний, это GPU классический, который считает попарные расстояния,
[01:15:30.280 --> 01:15:38.400]  а это в dense режиме. Значит, слева это временная шкала в порядках микросекунд. То есть, шестерка
[01:15:38.400 --> 01:15:48.280]  это одна секунда. Семерка это десять секунд, восьмерка это сто секунд. Значит, вот они GPU. Вот
[01:15:48.280 --> 01:15:55.680]  видно, где они находятся. И видно, где находится sparse GPU. Впечатляет ли вас скорость работы?
[01:15:55.680 --> 01:16:07.600]  Матрица расстояний вычислять. То есть, всякие корреляции и так далее. Именно на GPU. То есть,
[01:16:07.600 --> 01:16:12.640]  у нас есть матрица, у нас есть вторая матрица, и мы хотим посчитать попарное расстояние между всеми
[01:16:12.640 --> 01:16:19.960]  строками в матрице. Вот. При этом у нас матрица бывает обычная, а бывает sparse матрица. Вот. Здесь
[01:16:19.960 --> 01:16:28.360]  корреляция кендала попарные считается. То есть, смотрите, что у нас получается. У нас получается,
[01:16:28.360 --> 01:16:37.600]  что если у нас GPU считает что-то от одного до десяти секунд, то сколько времени необходимо
[01:16:37.600 --> 01:16:44.160]  для этого всего, для того чтобы посчитать это все с пул пакетом? От десяти до сотен секунд. То есть,
[01:16:44.160 --> 01:16:56.800]  ускорение видно в порядке. Поэтому мы это так или иначе и проходим с вами. Все, давайте,
[01:16:56.800 --> 01:17:19.440]  наверное, вопросы. Что такое grid? Grid это сетка, при помощи которой видеокарта будет
[01:17:19.440 --> 01:17:28.040]  назначать задачи на обработчики. То есть, у нас есть размер блока. То есть, что делает? Она создает
[01:17:28.040 --> 01:17:35.840]  сетку и для каждого элемента этой сетки выдаёт отдельную задачу на исполнение. То есть, как бы,
[01:17:35.840 --> 01:17:44.760]  вот так вот видеокарта передает задачи в физическую инфраструктуру. Каждая строка в этой
[01:17:44.760 --> 01:17:50.400]  истории обрабатывается одним стриминг-мультипроцессором. То есть, что берётся? Берётся вот эта строка,
[01:17:50.400 --> 01:17:55.640]  отдаётся на стриминг-мультипроцессор. Потом стриминг-мультипроцессор берёт вот эту строку
[01:17:55.640 --> 01:18:03.560]  блока и бьёт её на варпы и её исполняет. Вот, просто чтобы нам с физической абстракцией не сталкиваться,
[01:18:03.560 --> 01:18:08.720]  мы как раз отдаём максимально это всё на выполнение видеокарты.
[01:18:08.720 --> 01:18:24.560]  А dance это означает, что мы работали тут с part с матрицами в разных режимах.
[01:18:24.560 --> 01:18:37.880]  А это мы подаём part с матрицей с разной степенью разреженности.
[01:18:37.880 --> 01:18:48.440]  Ну да, это просто продублированный график, чтобы показать просто динамику.
[01:18:48.440 --> 01:18:56.800]  Чем меньше элементов матрицы физически находятся, то есть 99% значений это нули.
