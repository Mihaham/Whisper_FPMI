[00:00.000 --> 00:13.160]  Мы можем с вами начать про дискретную оптимизацию говорить. По-моему, в прошлый раз мы с вами ничего
[00:13.160 --> 00:19.520]  вообще не успели начать. Мы только поговорили про задачи, которые есть. Сказали, что они трудные,
[00:19.520 --> 00:26.800]  что к ним нужны разные подходы. И мы с вами будем некоторые подходы в приложении к
[00:26.800 --> 00:34.200]  некоторым из этих задач рассматривать. Сегодня мы начнем с задачи, с которой и Генрих начинает
[00:34.200 --> 00:43.160]  на курсере. Начнем с задачи о рюкзаке. Мы задачу о рюкзаке посмотрим с точки зрения двух вещей.
[00:44.160 --> 00:50.160]  Сегодня мы рюкзак посмотрим с точки зрения линейной релаксации. Такие страшные слова,
[00:50.160 --> 00:54.960]  линейная релаксация. Но с другой стороны, слово релаксация не страшное. Это значит,
[00:54.960 --> 01:00.600]  что делать ничего не надо. Релаксируйся и все. Так что мы с этой точки зрения посмотрим,
[01:00.600 --> 01:06.960]  а потом чуть позже, когда мы будем рассматривать полностью полинамиальные приближающие схемы,
[01:06.960 --> 01:12.880]  то мы еще раз вернемся к задаче о рюкзаке и посмотрим, что можно взять алгоритм динамического
[01:12.880 --> 01:18.440]  программирования для рюкзака, там покруглять кое-что и у нас получится полинамиальный алгоритм,
[01:18.440 --> 01:22.680]  но приближенный. В прошлый раз я, по-моему, уже сказал, что тот рюкзак, который мы с вами
[01:22.680 --> 01:27.600]  рассматриваем с чистым динамическим программированием в курсе алгоритмов,
[01:27.600 --> 01:31.920]  это получается алгоритм не в точности полинамиальный, а псевдополинамиальный.
[01:31.920 --> 01:38.620]  Но об этом всем попозже. Сейчас мы с вами начнем с задачи о рюкзаке и линейной релаксации в
[01:38.620 --> 01:44.800]  приложении «Задача о рюкзаке». Давайте я начну даже с еще более отдаленной вещи,
[01:44.800 --> 02:00.680]  с линейного программирования. А вы знаете, что такое линейное программирование? Слушайте,
[02:00.680 --> 02:10.680]  а как линейное программирование применяется в теормехе? Ничего себе, я думал, что теормех,
[02:10.680 --> 02:25.560]  он про что-то нелинейное, про что-то сильно нелинейное. Я вообще, на самом деле, я чужой
[02:25.560 --> 02:31.560]  среди своих и свой среди чужих, потому что я сам заканчивал в МК МГУ. У меня физики практически,
[02:31.560 --> 02:37.840]  но она была, но такая рудиментарная достаточно. Я думаю, что если взять среднестатистическую
[02:37.840 --> 02:43.040]  физтеху, то я знаю примерно одну десятую в физике того, что знает среднестатистический физтех,
[02:43.040 --> 02:48.560]  но мне казалось, что в теормехе нет линейных практических вещей, а они, оказывается, есть.
[02:48.560 --> 03:02.080]  Ну это же паспорт, правильно? А я как сотрудник же могу купить такую обложку? Нет, в каком-то
[03:02.080 --> 03:08.080]  смысле я честный физтех, потому что я закончил ВМК, потом я аспирантуру закончил на ВМК,
[03:08.080 --> 03:13.120]  потом я поработал на ВМК, а потом я ушел на физтех в 2012 году и так и не возвращался на ВМК.
[03:13.120 --> 03:19.760]  Вот, так что вам все равно должно быть приятно, наверное. Так вот, линейное
[03:19.760 --> 03:24.600]  программирование. Линейное программирование никакого отношения не имеет к написанию кода,
[03:24.600 --> 03:31.620]  к software engineering. Линейное программирование – это задача линейной функции или максимизации
[03:31.620 --> 03:37.360]  линейной функции. А вы знаете, что такое линейная функция? Это выражение, являющейся суммой
[03:37.360 --> 03:41.840]  переменных, со какими-то константными коэффициентами. Ну вот давайте мы эти
[03:41.840 --> 03:50.440]  константные коэффициенты обозначим c1, cn, переменные сами обозначим x, и вот необходимость
[03:50.440 --> 03:54.560]  найти максимум или минимум такого выражения – это и есть задача линейного программирования.
[03:54.560 --> 04:01.520]  Ну естественно, нужно как-то ограничить область, в которой эти переменные могут меняться,
[04:01.520 --> 04:07.880]  и вот линейное программирование у нас только в том случае, если эта область задана тоже чисто
[04:07.880 --> 04:13.480]  линейными ограничениями. У нас могут быть линейные ограничения типа равенства, то есть просто
[04:13.480 --> 04:19.520]  системы линейных уравнений, но вот в той форме, которую мы будем с вами рассматривать,
[04:19.520 --> 04:25.840]  у нас ограничения будут в форме неравенств. Вообще, можно записать произвольную систему
[04:25.840 --> 04:32.040]  неравенств в виде неравенств вида меньше или равно. Вот мы так, наверное, и сделаем. Значит,
[04:32.040 --> 04:37.440]  первое неравенство меньше или равно, значит, какой-то констант, да, линейная функция от
[04:37.440 --> 04:48.200]  переменных меньше или равно какой-то константе и так далее. Ну, МТ неравенство АМНХН меньше или равно
[04:48.200 --> 04:58.080]  какой-то константе БМ. Вот что такое задача линейного программирования. Давайте я чуть-чуть про
[04:58.080 --> 05:04.920]  геометрию этой задачи скажу. Мы совсем практически не будем затрагивать способы решения вот таких
[05:04.920 --> 05:09.800]  задач линейного программирования. Нам для нашего курса важно будет как можно скорее связать эту
[05:09.800 --> 05:15.960]  задачу, которая вроде бы из такого, но из мотана какого-то там, мотан, линал, да, вот дискретной
[05:15.960 --> 05:22.440]  оптимизации вроде не пахнет. Вот, но мы это очень быстро свяжем с задачами дискретной оптимизации.
[05:22.440 --> 05:29.640]  Сейчас увидим как. Так вот, вот такая задачка, значит, как ее можно трактовать. Ну, например,
[05:29.640 --> 05:41.160]  если бы это была задача от двух переменных, было бы у нас неравенство тогда А1,1 Х1 плюс А1,2 Х2 меньше
[05:41.160 --> 05:48.880]  или равно B1. Вот такое неравенство. Как бы мы могли с вами его геометрически представить? Вот если
[05:48.880 --> 05:57.720]  нарисовать такую дикартовую плоскость Х1 Х2, то, значит, как можно представить себе область
[05:57.720 --> 06:03.880]  значений Х1 и Х2, которые удовлетворяют такому неравенству? Ну, это вроде полуплоскость, да,
[06:03.880 --> 06:15.800]  такая. Вот. Да, значит, мы просто берем, значит, одну из полуплоскостей, на которой вот такая прямая
[06:15.800 --> 06:22.200]  с равенством делит нашу плоскость. Значит, так что на самом деле такое неравенство, оно задает нам
[06:22.200 --> 06:27.440]  полуплоскость. Если у нас система неравенства, то понятно, что мы пересекаем просто несколько
[06:27.440 --> 06:36.280]  полуплоскостей, и у нас получается, ну, что-нибудь, например, какой-нибудь такой четырехугольник. В общем
[06:36.280 --> 06:41.440]  случае у нас получается, если много переменных, у нас многомерное пространство, но все равно
[06:41.440 --> 06:48.560]  получается не многоугольник, а многогранник. На самом деле многогранник получается, если это
[06:48.560 --> 06:54.160]  ограниченная область, картинка же может быть и какой-нибудь такой. Мы хотим находиться ниже
[06:54.160 --> 07:01.400]  вот такой прямой, например, левее вот такой прямой и левее вот такой прямой. Это не ограниченная область,
[07:01.400 --> 07:08.160]  туда можно уходить сколько угодно далеко. Такие штуки называются политопы, но многогранник это
[07:08.160 --> 07:12.280]  ограниченный политоп, по сути. Я не хочу, чтобы вы это запоминали вообще, то есть многогранники,
[07:12.280 --> 07:18.200]  политопы. Просто я хочу на самом деле объяснить, что задачка линейного программирования, вот это,
[07:18.200 --> 07:23.480]  она, поскольку у нее такая геометрическая интерпретация, очень хорошая, то она считается
[07:23.480 --> 07:31.280]  достаточно простой в решении. Например, есть симплекс-метод для этой задачи, подназываемый,
[07:31.280 --> 07:39.600]  который берет и ищет решение вот этой вот задачки не на всем вот этом бесконечном множестве
[07:39.600 --> 07:46.640]  возможных вариантов, а только перебирая крайние точки вот этой вот области. Почему? Потому что
[07:46.640 --> 07:51.920]  максимизация вот такой вот функции, ну давайте я опять-таки для двух переменных покажу, значит,
[07:51.920 --> 07:57.760]  вот у нас есть система неравенств, а вот, допустим, мы максимизируем теперь функцию, ну скажем x1
[07:57.760 --> 08:04.360]  плюс 2x2. Вот как нам максимизировать такую штуку? Это значит, нам нужно взять вектор коэффициентов
[08:04.360 --> 08:11.000]  1 запятая 2, вот такой вот вектор, и максимально в направлении этого вектора двигаться, оставаясь
[08:11.000 --> 08:15.800]  внутри вот этой области. То есть можно считать, что вот вектор коэффициентов, ведь сама эта
[08:15.800 --> 08:25.120]  функция, это скалярное произведение вот такого вектора, на вектор x1 и x2. Значит, она тем больше,
[08:25.120 --> 08:33.280]  чем дальше мы способны уйти вот в этом направлении. Вот, ну как бы если формально не очень понятно,
[08:33.280 --> 08:39.120]  почему именно так, то не беда на самом деле тоже. Вот здесь про геометрию разговор. Вот представьте,
[08:39.120 --> 08:44.320]  что это направление ветра, ну и в общем случае тоже вот вектор коэффициентов c1 и так далее,
[08:44.320 --> 08:50.880]  cн это такое направление ветра. И вот куда ветер дует, там хорошо. И нам нужно подбросить перышко
[08:50.880 --> 08:58.480]  внутрь вот этой области, и куда эта перышко улетит под действием ветра, значит там и самая
[08:58.480 --> 09:05.160]  лучшая точка, там самый лучший набор x1, xn. Ну или можно считать, что гравитация в этом направлении
[09:05.160 --> 09:09.840]  действует, и вот мы кидаем шарик такой, и куда он скатывается по действиям такой гравитации,
[09:09.840 --> 09:15.280]  там и хорошо. Естественно, что можно так придумать вектор вот этой гравитации условно,
[09:15.280 --> 09:20.080]  что нам будет хорошо прям на всем отрезке на таком, например. Ну понятно, если мы
[09:20.080 --> 09:26.400]  перпендикулярно направим наш вектор коэффициентов c к этому отрезку, то будет хорошо много где. Но
[09:26.400 --> 09:32.720]  всегда найдется какая-то крайняя точка, одна из угловых точек, в которой нам гарантировано будет
[09:32.720 --> 09:39.280]  хорошо. И вот simplex-метод, про который мы ничего не будем с вами пока говорить, это алгоритм,
[09:39.280 --> 09:46.200]  который как-то умудряется перебирать хорошо вот эти вот крайние точки, так что только из них мы
[09:46.200 --> 09:54.240]  выбираем оптимальное решение. Да, я еще напоминаю, не напоминаю, наверное говорю, вот наверное эта
[09:54.240 --> 10:00.400]  новость. Значит, что мы с вами будем рассматривать такую терминологию. В любой задачи оптимизации,
[10:00.400 --> 10:05.200]  в том числе в дискретной оптимизации, и, пожалуй, особенно в дискретной оптимизации, у нас будет два
[10:05.200 --> 10:24.240]  понятия с вами. У нас будет понятие feasible solution, допустимое решение, и optimal solution. То есть
[10:24.240 --> 10:39.160]  оптимальное решение самое лучшее. Ну а почему так? Обычно, я думаю, что мы привыкли с вами часто,
[10:39.160 --> 10:44.400]  что решением задачи называется все-таки нечто, что удовлетворяет всем всем всем требованиям. Вот
[10:44.400 --> 10:50.160]  если нас просят найти максимальное значение вот такой вот штуки, да, это значит решить вот эту
[10:50.160 --> 10:57.880]  задачу, это все-таки предъявить действительно наиболее оптимальный, значит, набор иксов. Но задачи
[10:57.880 --> 11:03.480]  дискретной оптимизации настолько сложные, что часто найти оптимальное решение, это вообще без
[11:03.480 --> 11:09.560]  шансов. И поэтому мы ищем решение, которое в первую очередь главное, чтобы оно хотя бы удовлетворяло всем
[11:09.560 --> 11:18.320]  вот этим жестким ограничением. Но, как правило, уже из, значит, всех решений мы выбираем наиболее
[11:18.320 --> 11:23.280]  близкое по возможности к оптимальному, но оптимальное мы не знаем почти никогда. И поэтому вот чтобы
[11:23.280 --> 11:28.680]  не говорить, что у нас типа есть решение задачи, а мы какими-то нерешениями к нему подходим,
[11:28.680 --> 11:33.320]  вместо этого мы говорим, у нас есть оптимальные решения задачи, которые мы не знаем, но хотим
[11:33.320 --> 11:38.680]  к нему приблизиться. Ну мы строим какие-то, может, неоптимальные решения, но главное, что они
[11:38.680 --> 11:45.160]  допустимые. Вот допустимость означает удовлетворение всех вот этих вот ограничений, ну какая бы ни
[11:45.160 --> 11:51.480]  была здесь система линейных, нелинейных ограничений, просто всех жестких ограничений. Ну так вот,
[11:51.480 --> 12:00.040]  значит, я забыл уже о чем я говорил в применении к этой штуке. Вот допустимое решение вот здесь,
[12:00.040 --> 12:05.640]  вот это любая точка просто внутри вот этой вот области получается. Оптимальные решения можно
[12:05.640 --> 12:11.440]  искать только среди вот этих вот угловых. Задача линейного программирования вот такая. Если
[12:11.440 --> 12:17.360]  предполагается, что переменные это произвольные действительные числа, то есть кроме вот этих
[12:17.360 --> 12:23.520]  линейных неравенств никаких ограничений больше нет, то тогда эта задача, можете быть уверены,
[12:23.520 --> 12:29.560]  что она отлично решается и на практике, и в теории. На практике есть симплекс метод, есть алгоритмы
[12:29.560 --> 12:33.400]  внутренней точки, которые хорошо работают в теории, есть просто алгоритмы внутренней точки,
[12:33.400 --> 12:39.240]  которые хорошо работают. Вот нам с вами надо про эту задачу знать вот что. Что вот эта вот задача,
[12:39.320 --> 12:50.040]  вот эта вот задача, она решается за полинамиальное время, решается за полинамиальное время.
[12:50.040 --> 13:00.400]  Но я думаю, что у вас было уже определение NP, значит у вас было определение P, и вы понимаете,
[13:00.400 --> 13:06.200]  что вот есть такое важное деление в computer science между полинамиальным временем и
[13:06.200 --> 13:11.560]  неполинамиальным временем. И вот задачи такие эффективно разрешимые, считаются это те,
[13:11.560 --> 13:19.000]  которые за полинамиальное время можно найти оптимальные именно решения. Решается за
[13:19.000 --> 13:24.920]  полинамиальное время на любых входных данных, причем ответом задачи оптимизации вообще может
[13:24.920 --> 13:35.600]  быть один из трех. Какие три ответа? Бывают задачки вот такие хорошие, в которых область не пустая,
[13:35.600 --> 13:39.920]  вот всем этим ограничениям можно одновременно удовлетворить, получается какая действительно
[13:39.920 --> 13:45.440]  хорошая область, и мы в ней можем найти действительно некое конечное максимальное значение
[13:45.440 --> 13:52.360]  какой-то функции. Такие задачи называются ограниченными и разрешимыми.
[13:52.360 --> 14:08.440]  Easeable и bounded, то есть можно удовлетворить системе ограничений, и значит оптимальное значение
[14:08.440 --> 14:14.880]  функции ограничено, это какая-то все-таки константа, какое-то конкретное число. Бывают задачки,
[14:14.880 --> 14:21.400]  в которых, вот как там я приводил пример, область бесконечная, и внутри этой области можно
[14:21.400 --> 14:28.200]  бесконечно далеко уходить в направлении ветра, который дует сообразно нашим коэффициентом c1cn,
[14:28.200 --> 14:37.040]  и тогда задача называется feasible unbounded, ну или по-русски не ограниченная. Вот, область задачей
[14:37.040 --> 14:47.400]  feasible. Это задачки, в которых, например, нам бы сказали, ну я думаю, что вы понимаете, да, вот что
[14:47.400 --> 14:54.360]  какая-нибудь такая задача, вот с такими вот требованиями, она вообще здесь нету ни одного,
[14:54.360 --> 15:00.600]  ни одной комбинации иксов, который удовлетворил бы всем ограничениям одновременно, ну вот, и здесь
[15:00.600 --> 15:07.240]  что-то такое получается не очень. Хотя нет, в этой задачке, наверное, да, вот все истребки бы
[15:07.240 --> 15:15.600]  смотрели в разные стороны, да, вот тогда, наверное, было бы плохо точно. Ну ладно, на самом деле,
[15:15.760 --> 15:19.920]  те задачки, которые мы с вами линейного программирования будем рассматривать, исходя из
[15:19.920 --> 15:25.280]  практических задач, они все будут feasible и bounded. То есть вот мы всегда будем оставаться более-менее
[15:25.280 --> 15:31.080]  здесь, а это просто полезно знать как терминологию, ну потому что если вы будете, например, запускать
[15:31.080 --> 15:36.080]  какие-то сторонние solvers или как-то экспериментировать со своими ограничениями, то запросто можно вляпаться
[15:36.080 --> 15:42.360]  в какую-нибудь infeasible задачку. Вот мы с вами позже поговорим про введение дополнительных ограничений,
[15:42.360 --> 15:49.080]  вот такие всякие трюки для ускорения поиска решений, и вот в ходе экспериментов просто solver
[15:49.080 --> 15:54.240]  вам что-то такое может выдать, чтобы мы знали термин. Так, ну вот, помимо того, что эта задача
[15:54.240 --> 16:01.080]  решается в теории за полимеральное время, она на практике тоже очень эффективна. А что я
[16:01.080 --> 16:06.080]  подразумеваю под очень эффективным решением на практике? Это означает, что вот такую вот задачку,
[16:06.080 --> 16:13.880]  ну solver современный решает на обычном компьютере для нескольких десятков тысяч ограничений и
[16:13.880 --> 16:21.680]  нескольких сотен переменных решает на секунд за 10-15. То есть, ну это нормально, вот это как
[16:21.680 --> 16:27.760]  много чего можно понарешать, да, когда у вас так быстро все работает. То есть на практике я скажу
[16:27.760 --> 16:38.400]  так, ну порядка 10 в третий, 10 в третий по порядку, 10 в четвертый неравенств, ограничений, и тоже
[16:38.400 --> 16:46.680]  порядка там 10 во второй, 10 в третьей переменных, у нас время обчета, ну как правило меньше одной минуты.
[16:46.680 --> 17:01.160]  Нас это вполне вполне устраивает. Теперь, дальше, это хорошие новости. Плохие новости
[17:01.160 --> 17:10.040]  состоят вот в чем, в том, что если мы с вами оставляем вот все те же самые требования,
[17:10.040 --> 17:15.680]  решаем ту же самую задачу, только вместо действительных переменных мы рассматриваем
[17:15.680 --> 17:22.960]  только целочисленные значения переменных, то тогда здесь все плохо и эта задача оказывается
[17:22.960 --> 17:31.320]  NP трудной. Значит, вот такой вариант задачки линейного программирования называется целочисленное
[17:31.320 --> 17:38.440]  линейное программирование. Есть задачки смешанного целочисленного линейного программирования,
[17:38.440 --> 17:45.640]  когда часть переменных обязательно целая, а часть переменных произвольная, действительная.
[17:45.640 --> 17:52.680]  Фактически, что происходит, если мы требуем целочисленность переменных, но это значит,
[17:52.680 --> 18:00.160]  что мы внутри вот этой вот области ищем только точки с целочисленными координатами. Давайте
[18:00.160 --> 18:06.680]  посмотрим, почему вообще задача может стать сложной. Сейчас еще чуть-чуть нам нужно потерпеть,
[18:07.000 --> 18:14.360]  потому что мы совсем скоро с вами возьмем пару задач даже дискретной оптимизации и посмотрим,
[18:14.360 --> 18:19.040]  как они ставятся на вот таком языке. Сейчас я еще чуть-чуть поболтаю насчет вот этого всего.
[18:19.040 --> 18:26.720]  Значит, почему, казалось бы, такая замена, вот все оставили, только вместо R написали Z? Почему
[18:26.720 --> 18:33.800]  эта замена превращает такую естественную легкую задачу в очень трудную? А дело в том,
[18:33.800 --> 18:42.240]  что очень сложно предугадать по форме нашей области, какие именно целочисленные точки даже
[18:42.240 --> 18:49.360]  в нее попадут, просто элементарно. Вот представьте себе, значит, целочисленную задачу. Это значит,
[18:49.360 --> 18:54.560]  мы вместо всех возможных точек плоскости рассматриваем только вот такую сетку,
[18:54.680 --> 19:04.680]  точек с целочисленными координатами. Дальше представьте, что у нас какие-нибудь такие неравенства.
[19:04.680 --> 19:21.960]  Сейчас я попробую это сделать. Ну, в общем, у меня примерно получилось. Представьте,
[19:21.960 --> 19:30.360]  такой треугольничит. Давайте даже представим, что он промазывает мимо вот этой вот точки. Вот
[19:30.360 --> 19:38.160]  какой-то он такой. Какая точка, если у нас вектор ветра дует вот в эту сторону, то есть мы,
[19:38.160 --> 19:45.560]  например, максимизируем функцию минус x1, минус x2 или минимизируем функцию такую. Допустим,
[19:45.560 --> 19:51.240]  что задача какая-то такая. Это значит, что мы должны сдвинуться максимально против ветра 1,
[19:51.560 --> 19:57.560]  вот. Скорее всего, у нас в обычной задаче линейного программирования вот эта вот точка будет
[19:57.560 --> 20:03.960]  оптимальна. Но в вот эту вот область, ближайшая точка, которая попадает вообще целочисленная,
[20:03.960 --> 20:09.320]  она находится как далеко. То есть, например, не работает такая идея, очень естественная. Давайте
[20:09.320 --> 20:15.200]  решим вот эту вот задачку, да, и потом просто округлим как-то значение переменных. Она не работает.
[20:15.200 --> 20:21.040]  Ближайшая точка к вот этой целочисленной, это вот эта, ну или вот одна из этих. Вот эту точку никак
[20:21.040 --> 20:30.760]  не назовешь округленной точкой, близкой к этой. И вот из-за такой ерунды теряется многое в
[20:30.760 --> 20:41.080]  геометрии задачки, и задача становится очень трудной для решения. Такс, ну хорошо. Тем не менее,
[20:41.080 --> 20:49.320]  вот этот водораздел, он очень эффективно используется нами, мы сейчас его прямо начнем
[20:49.320 --> 20:53.800]  использовать в дискретной оптимизации. Почему? Потому что это очень уникальный, на самом деле,
[20:53.800 --> 21:01.040]  случай такой, что есть некая очень широкая задача линейного программирования, и не менее
[21:01.040 --> 21:06.320]  широкая задача по возможностям целочисленного программирования. Одна из которых очень легкая,
[21:06.320 --> 21:12.440]  другая очень трудная, а отличаются они все-таки всего лишь одним условием, вот этим. И иногда,
[21:12.440 --> 21:17.800]  ну вот в этом патологическом случае с округлением как-то вообще мне не катит, но иногда мы,
[21:17.800 --> 21:24.760]  действительно, можем как-то округлить решение, это не всегда далеко, ну такой процесс естественного
[21:24.760 --> 21:31.320]  округления к ближайшему целому, но мы можем что-то сделать с решением одной задачи, чтобы попытаться
[21:31.320 --> 21:39.560]  получить решение другой задачи. Вот давайте мы это и научимся делать в паре задач дискретной оптимизации.
[21:39.560 --> 21:53.240]  И давайте начнем с задачи о рюкзаке как раз. А знаете, вы знаете, почему название появилось? Может
[21:53.240 --> 21:57.640]  не знаете? Линейное программирование. Как же это связано с программированием? Значит это связано
[21:57.640 --> 22:02.720]  скорее со старым пониманием слова программа, ну или с общечеловеческим. Вот для нас программа
[22:02.720 --> 22:08.000]  это какой-то текст для компилятора какого-нибудь, а для обычных людей программа это там программка в
[22:08.000 --> 22:14.880]  театре, там телевизионная программа, ну не в газете уже, на сайте, там афиша какая-то. То есть это некий
[22:14.880 --> 22:22.040]  план, план того, что будет. Вот здесь слово программирование надо воспринимать именно как
[22:22.040 --> 22:27.840]  планирование. А почему здесь именно линейное планирование? Да потому что сама вся вот эта
[22:27.840 --> 22:32.680]  задача, она возникла в свое время вовсе не из компьютерсайенс и не из попытки решать задачи
[22:32.680 --> 22:39.160]  дискретной оптимизации, а скорее из экономических задач, планирования ресурсов. Вот например у вас
[22:39.160 --> 22:45.520]  фабрика производит разные товары из каких-то видов сырья. И у вас есть ограничения, у вас есть
[22:45.520 --> 22:51.920]  B1 тонн такого-то сырья, B2 тонн какого-то сырья и так дальше. А ваша фабрика производит N видов
[22:51.920 --> 22:58.760]  товаров. И вы знаете, что на товар X1 на одну порцию этого товара, продукта, да, у вас тратится вот
[22:58.760 --> 23:03.480]  столько вида, вот столько килограмм первого сырья, вот столько-то килограмм второго сырья и так
[23:03.480 --> 23:10.160]  далее. И спланировать как именно распределить ваши производственные мощности между разными видами
[23:10.160 --> 23:15.800]  продуктов, которые вы производите, так чтобы вам хватило сырья на каждый, да, на производство всех
[23:15.800 --> 23:22.080]  этих видов. И при этом максимизировать, например, прибыль. Да, вот если C это то, за сколько вы
[23:22.080 --> 23:28.440]  можете продать соответствующие виды продукта, вот ваша прибыль, то это вот задача планирования,
[23:28.440 --> 23:37.080]  да, производственных, планирование производства. И первые такие важные практические применения
[23:37.080 --> 23:42.880]  были именно здесь, на этом фронте. Так, ну вот про название тоже сказал. Теперь можно рюкзак
[23:42.880 --> 23:55.360]  наконец вести, да. Задача о рюкзаке. Задача о рюкзаке, значит, мы будем рассматривать
[23:55.360 --> 24:03.360]  0.1 рюкзак, хотя можно и говорить о более общей задаче. Есть предметы, предметы. У этих предметов
[24:03.360 --> 24:15.760]  есть стоимости или ценности. Давайте мы эти стоимости обозначим P1Pn. Это слово price, да,
[24:15.760 --> 24:22.640]  ну можно value называть. Ладно, стоимости. Какие-то положительные числа. Есть веса у этих предметов?
[24:22.640 --> 24:34.080]  Веса, ну пусть будет W1, weight 1 и weight n. Тоже положительные числа. Ну и кроме того,
[24:34.080 --> 24:41.360]  есть максимальный допустимый вес, который можно запихнуть в рюкзак. Наша задача нагрузить рюкзак
[24:41.360 --> 24:47.400]  предметами так, чтобы максимизировать общую ценность предметов, которые в нём лежат. Значит,
[24:47.400 --> 24:54.280]  давайте мы эту задачу поставим как задачу дискретной оптимизации. Задача дискретной
[24:54.280 --> 25:01.080]  оптимизации нам нужно понять, что мы по сути ищем. Мы ищем подмножество предметов. Комбинаторная
[25:01.080 --> 25:05.200]  оптимизация это значит, что то, что мы ищем, является каким-то комбинаторным объектом, каким-то
[25:05.200 --> 25:10.680]  выборкой, подмножеством, вот чем-то таким, дискретной конфигурацией какой-то. Соответственно,
[25:10.680 --> 25:20.440]  мы ищем такое подмножество предметов s, но можно считать, что это подмножество индексов от 1 до n.
[25:20.440 --> 25:31.720]  Вот такое, что тумарный вес предметов, попадающих в это подмножество, не превосходит максимально
[25:31.720 --> 25:41.600]  допустимого веса, и при этом мы максимизируем, максимизируем тумарную стоимость предметов,
[25:41.600 --> 25:54.680]  попадающих в наше множество. Тумарную стоимость предметов, попадающих во множество. Вопрос,
[25:54.680 --> 26:08.520]  ну да, пока еще рано ставить вопрос. Давайте мы эту задачку поставим как задачу программирования
[26:08.520 --> 26:13.960]  линейного. Вот, но как задачу целочисленного линейного программирования. Я и вот это вот уже
[26:13.960 --> 26:29.400]  стираю, эту чисто терминологическую часть доски. И здесь я, пожалуй, заголовок дам такой. Рюкзачная
[26:29.400 --> 26:38.520]  целочисленная линейная программа. ILP это стандартное сокращение Integer Linear Programming,
[26:38.520 --> 26:44.480]  как вот процесс решения или наука о решении таких программ, или Integer Linear Programming.
[26:58.000 --> 27:05.800]  А мы легко можем с вами обычно поставить вот такую задачу, как задачу линейного программирования.
[27:05.800 --> 27:11.880]  Почему? Потому что мы видим, что максимизируется какая-то сумма. Но это правда сумма не каких-то
[27:11.880 --> 27:18.040]  переменных с константными коэффициентами, а это сумма по какому-то под множеству меняющемуся,
[27:18.040 --> 27:24.040]  которую нам надо еще найти. Ну ладно, с этим разберемся. И неравенство здесь тоже в общем
[27:24.040 --> 27:30.000]  линейное, ну какое-то почти линейное. Суммируются константы. У нас, правда, переменных здесь никаких
[27:30.000 --> 27:37.440]  нету. Вот, но переменность наша этой суммы в том, что мы по какому-то изменяемому, подбираемому
[27:37.440 --> 27:44.560]  нами под множество суммируем. Но переход от множеств неизвестных нам, которые нам надо найти,
[27:44.560 --> 27:52.680]  к каким-то переменным, он осуществляется обычно введением, знаете, такого индикаторного вектора
[27:52.680 --> 28:01.360]  множества. А у вас тервер же был? А нет, у вас не было тервера. Значит, любому множеству, а вы знаете,
[28:01.360 --> 28:06.440]  что количество под множество любого конечного множества, это два в степени мощность. Ну вот,
[28:06.440 --> 28:11.560]  вот как мы это обычно доказываем, мы говорим, давайте сопоставим под множеством их индикаторные
[28:11.560 --> 28:16.200]  векторы из нулей единиц, поставив напротив каждого элемента 0, если он не входит, и единичка,
[28:16.200 --> 28:21.480]  если он входит в под множество. И тогда, значит, векторов у нас два в степени n, и, значит,
[28:21.480 --> 28:26.720]  самих под множество тоже два в степени n. Вот ровно эту идею индикаторных векторов мы используем
[28:26.720 --> 28:31.600]  для того, чтобы задачу о выборе под множество закодировать как задачу о выборе его индикаторного
[28:31.600 --> 28:41.080]  вектора. Значит, мы вводим в переменные x1 и так далее xn. Переменная, которая, вот когда мы ставим
[28:41.080 --> 28:46.120]  какую-то содержательную задачу на языке линейного программирования, может, нелинейного
[28:46.120 --> 28:51.840]  программирования. Мы вводим переменные, которые отвечают нашему выбору основному. Вот здесь мы
[28:51.840 --> 28:56.880]  выбираем множество. Это значит, если мы выбор множества кодируем выбором каких-то переменных,
[28:56.880 --> 29:02.840]  эти переменные будут называться у нас такими выбранными переменными. Decision variables по-английски.
[29:09.840 --> 29:15.920]  Decision variables. Переменные, которые кодируют наш выбор. Соответственно, мы хотим, чтобы
[29:15.920 --> 29:23.640]  вот этот телеком набор отвечал нашему множеству s. Ну, то есть, по смыслу, смысл у нас такой,
[29:23.640 --> 29:35.520]  у этих переменных x it равняется единице, если it объект мы кладем в рюкзак и нулю иначе.
[29:35.520 --> 29:45.720]  Вот это смысл этих перемен. В терминах этих переменных мы можем теперь записать
[29:45.720 --> 29:52.920]  и целевую функцию, и наше ограничение. То, что мы максимизируем, называется или минимизируем,
[29:52.920 --> 29:57.560]  называется всегда целевой функцией. По-английски это будет objective function.
[29:57.560 --> 30:11.880]  Ну, это и в общей теории выпуклые оптимизаторы тоже называется целевой функцией, поэтому это
[30:11.880 --> 30:17.720]  полезно запомнить. У вас же будет еще курс выпуклой оптимизации. Целевая функция,
[30:17.720 --> 30:24.800]  значит, это сумма получается, и нам бы вот с вами теперь записать это как просто сумму
[30:24.800 --> 30:30.960]  переменных с константными коэффициентами. Давайте мы запишем, я даже избавлюсь на всякий случай
[30:30.960 --> 30:40.120]  пока от знака суммирования. Вот, как можно это записать? w1 на x1 плюс w2 на x2 плюс и так далее,
[30:40.120 --> 30:50.360]  плюс wn на xn. Ведь действительно, да, здесь вот в эту сумму, когда мы x заполняем нулями и
[30:50.360 --> 30:57.160]  единицами, по факту войдут только те w, в которых соответствующие переменные выставлены в единицу,
[30:57.160 --> 31:04.280]  то есть w только тех предметов, которые попадают в рюкзак. Но теперь, вот когда я это объяснил,
[31:04.280 --> 31:12.480]  я могу, наверное, это все переписать, написав уже взрослую сумму. Значит, взрослая сумма у нас такая,
[31:12.480 --> 31:24.080]  получается, по i от единицы до n w i t на x i. Я обращаю ваше внимание на вот какой факт. Выглядит очень
[31:24.080 --> 31:30.680]  похоже. И тут оператор суммирования, и там оператор суммирования. Но вот это вот условие не
[31:30.680 --> 31:35.840]  является условием, которое можно напрямую подать в solver для задач линейного программирования,
[31:35.840 --> 31:42.360]  потому что здесь сумма выполняется по какому-то переменному множеству. Вот, это не является какой-то
[31:42.360 --> 31:49.480]  линейной функцией, вот какой-то переменной. Здесь непонятно пока, что переменная, кроме s. Нет
[31:49.480 --> 31:55.800]  у нас в линейном программировании множество как переменной. А здесь уже сумма с константным
[31:55.800 --> 32:01.280]  числом слагаемых, потому что пределы суммирования не зависят от самих переменных. Мы не говорим,
[32:01.280 --> 32:06.680]  что если переменная какая-то равна единичке, то мы здесь берем какое-то число слагаемых, а если
[32:06.680 --> 32:12.200]  нулю, то секо это число слагаемых. Мы говорим, что просто по факту те переменные, которые равны нулю,
[32:12.200 --> 32:18.000]  для них соответствующие слагаемые обнуляются. Но все равно эти слагаемые можно формально считать,
[32:18.000 --> 32:23.520]  что они в сумму по-прежнему входят. Число слагаемых в сумме формально, оно никак не зависит от того,
[32:23.520 --> 32:28.120]  какие именно значения у наших переменных. И коэффициенты теперь перед этими переменными,
[32:28.120 --> 32:32.880]  при каждой переменной, своя четко определенная константа есть. Вот теперь это условие, оно уже
[32:32.880 --> 32:39.480]  чисто линейное по всем нашим decision variables, по всем нашим переменным. А у нас здесь ничего,
[32:39.480 --> 32:45.240]  кроме decision variables и не будет. Это да, что мы с вами уже будем вводить какие-то еще вспомогательные
[32:45.240 --> 32:49.680]  переменные, еще Бог знает что. Пока у нас все переменные, задачи которые будут, это вот они.
[32:49.680 --> 33:03.760]  Так, теперь наше ограничение constraint. Я надеюсь просто еще на то, что я вот вас помучаю так английским
[33:03.760 --> 33:08.800]  языком немножко сейчас и дальше по ходу курса. Но зато те из вас, кто одновременно дополнительно
[33:08.800 --> 33:15.280]  на курсере что-то берут, вот сразу как-то вам будет чуть попроще. И гент Энрика смотри, например.
[33:15.280 --> 33:20.880]  Так, а кто мне может подсказать теперь как ограничение записать?
[33:20.880 --> 33:32.040]  Тоже хочется вот такого суммы с константным часовом слагаем.
[33:32.040 --> 33:45.760]  Ой, пэшки, да, здесь же пэшки, точно. А то теперь дубльбэшки, да? Да, спасибо. Но так
[33:45.760 --> 33:52.360]  всегда, если бы, представляете, если бы я читал лекции пустой аудитории, что бы я тогда наговорил,
[33:52.360 --> 34:04.280]  я бы никто не поправил. Вот, это наше ограничение constraint. Чудесно, вот теперь все линейное. У нас
[34:04.280 --> 34:11.640]  есть, видите, из всего множества неравенств только одно неравенство есть. Но теперь переменные вот
[34:11.640 --> 34:16.480]  никакому солверу задачи линейного программирования и даже целочисленного линейного
[34:16.480 --> 34:21.640]  программирования не подашь на вход вот эту информацию содержательную, что на самом деле
[34:21.640 --> 34:27.440]  вы знаете, господин солвер, вот эти переменные x, они равны мне нулю или единице в зависимости от
[34:27.440 --> 34:32.520]  того, кладу ли я предмет в рюкзак или нет. Это вообще такое непонятно, да. Вот, мы должны как-то
[34:32.520 --> 34:37.480]  просто закодировать, что это булевские переменные, что они должны принимать только два значения,
[34:37.480 --> 34:45.160]  0 или 1. И это, по счастью, можно сделать с помощью линейных неравенств. Каким образом? Мы говорим,
[34:45.160 --> 34:53.680]  что для каждого и от единицы до n, переменная x, и меняется в пределах от нуля до единицы. Ну,
[34:53.680 --> 35:02.440]  и при этом все переменные у нас целочисленные. О, смотрите, получилось, что вот это вот условие,
[35:02.440 --> 35:09.520]  и оно абсолютно стандартное для многих кодирований, значит, задачей скрипной оптимизации, оно нам
[35:09.520 --> 35:17.720]  говорит, что переменные только булевые. Дальше мы подаем, вот мы можем подать вот такую вот линейную
[35:17.720 --> 35:23.360]  программу, целочисленную линейную программу, в какой-нибудь солвер, он нам выдаст набор
[35:23.360 --> 35:28.560]  переменных ноликов и единичек, набор значений переменных, и мы имеем взаимнооднозначное
[35:28.560 --> 35:33.640]  соответствие теперь между тем, что выдал солвер, и какой-то комбинаторной конфигурации, вот неким
[35:33.640 --> 35:38.640]  множеством s. И просто по построению этой задачи получится, что множество s, вот которое
[35:38.640 --> 35:46.400]  проистекает из таких значений переменных, у нас будет оптимальным решением задачи о рюкзаке. Но задача
[35:46.400 --> 35:53.000]  целочисленного линейного программирования, она НП трудная, и есть солверы для задач CLP. Ну,
[35:53.000 --> 36:01.400]  Гуроби, вот то, что я перечислял, наверное, в прошлый раз, там Гуроби, CPLEX, CoinBC, GLPK, Google
[36:01.400 --> 36:07.480]  WarTools, то есть, короче, и много этих солверов. Но мы не можем ни на что... Ну, они не могут нам
[36:07.480 --> 36:12.000]  ничего гарантировать. Они не могут гарантировать, что эту задачу они решат вот так же круто, там,
[36:12.000 --> 36:17.280]  со столькими ограничениями, столькими переменными, там, меньше, чем за минуту. Вы можете загнать
[36:17.280 --> 36:22.680]  в солвер там всего лишь сотню ограничений, сотню переменных, и он там и за два часа ничего не
[36:22.680 --> 36:28.320]  выдаст. Ну, то есть, он оптимальное решение не найдется два часа. Все зависит от задачки. Ну, нет,
[36:28.320 --> 36:33.200]  это я, конечно, махнулся, два часа найдет при сотне ограничений, при сотне переменных,
[36:33.200 --> 36:41.160]  но он найдет. Вот. Но, тем не менее, ничего гарантировать нам, вообще говоря, формально никто не
[36:41.160 --> 36:55.160]  может. Вот. Так вот, мы теперь дальше что делаем? Мы поставили с вами задачу о рюкзаке. Такую
[36:55.160 --> 37:03.240]  диаграмму сейчас напишу. Мы поставили с вами задачу о рюкзаке, как задачу целочисленного
[37:03.240 --> 37:14.440]  линейного программирования. А дальше мы говорим, а мы не будем искать ключи там, где мы их потеряли,
[37:14.440 --> 37:19.720]  мы будем искать там, где их проще искать. И проще решать не задачу целочисленного линейного
[37:19.720 --> 37:24.560]  программирования, а обычную задачу линейного программирования. То есть, дальше мы с вами перейдем
[37:24.560 --> 37:33.280]  от задачи CLP к задачи LP. Как это делается? А мы просто забываем про единственное ограничение,
[37:33.280 --> 37:39.800]  которое отличает эти две задачи. Легкую и трудную. Мы говорим, а теперь у нас переменные, это
[37:39.800 --> 37:46.280]  правпроизвольные действительные числа, меняющиеся в отрезке от 0 до единицы. И посмотрим, как это
[37:46.280 --> 37:52.040]  позволит нам задачку решить. Но не точно, а приближенно. Этот процесс я, наверное, не буду сильно
[37:52.040 --> 38:09.080]  долго комментировать, за исключением того, что... Давайте немножко напишу. Вот, собственно, вот этот
[38:09.080 --> 38:14.040]  этап, он, конечно, творческий, но какие-то стандартные подходы здесь есть. Вот, как, например,
[38:14.040 --> 38:19.080]  замена множества его характеристическим векторам. Вот этот этап, он совсем не творческий, он просто
[38:19.080 --> 38:26.360]  состоит в том, что мы тупо отбрасываем ограничение целочисленности. И всё. Вот. И вот эта вот линейная
[38:26.360 --> 38:31.880]  программа, обращаю ваше внимание на новый термин, очередной на сегодня. Вот такая линейная программа,
[38:31.880 --> 38:37.440]  которая возникла из целочисленной линейной программы, которая кодирует однозначно исходную
[38:37.440 --> 38:44.360]  задачу. Она называется линейной релаксацией исходной задачи. То есть, вот если мы с вами возьмём
[38:44.360 --> 38:50.240]  теперь здесь вместо буквы Z, напишем R, то то, что здесь на доске написано, вот ниже вот этой вот
[38:50.240 --> 38:55.280]  линии, пожалуй, да, то, что написано ниже этой линии с буквой R, это будет называться линейной
[38:55.280 --> 39:03.680]  релаксацией. Ей задача о рюкзаке. Я это подпишу. Линейная релаксация.
[39:10.560 --> 39:16.080]  Линейная релаксация. Почему называется, ну, линейная, я не буду комментировать. Почему называется
[39:16.080 --> 39:24.800]  релаксацией? Ну, relax, да, вот это математически вполне термин. Relax constraints. Мы ослабляем
[39:24.800 --> 39:30.520]  наши ограничения. В принципе, вот любой момент, когда вы взяли какие-то ограничения в задачи и
[39:30.520 --> 39:36.040]  что-то с ними сделали, отбросили целиком, как в случае целочисленности, или заменили, ну,
[39:36.040 --> 39:43.000]  например, W на 2W, да, то есть, позволили рюкзаку быть вдвое более вместительным. Этого, получается,
[39:43.000 --> 39:49.880]  ослабили ваши ограничения. Вы многие рюкзаки, которые для вас были недостижимы, вы сделали
[39:49.880 --> 39:56.920]  достижимыми. Вот это все называется релаксацией. Любое снятие целиком, либо ослабление ограничений.
[39:56.920 --> 40:05.640]  Что мы можем сказать, значит, вот что справедливо для линейной релаксации? Когда вы отбрасываете
[40:05.640 --> 40:12.240]  какое-то условие, как можно это нарисовать, концептуально себе представить? Вот помните,
[40:12.240 --> 40:19.480]  да, помните, мы рисовали многоугольник для задачи линейного программирования. Вот в оптимизации
[40:19.480 --> 40:25.120]  вообще тоже любят рисовать такие облачка, вот и называть их областью допустимых решений.
[40:25.120 --> 40:32.500]  Вот представьте, что вы, вот в этой луже, в этом облачке в нем плавают всевозможные наборы
[40:32.500 --> 40:37.840]  переменных, которые удовлетворяют всем вашим ключевым ограничениям. Ну, у нас есть единственное
[40:37.840 --> 40:42.620]  ключевое ограничения, хотя, нет, не единственное — вот еще вот эти неравенства, это же тоже ключевые
[40:42.620 --> 40:47.800]  ограничения. Представьте, что здесь плавают всевозможные допустимые наборы переменных,
[40:47.800 --> 40:53.660]  значений переменных. Что происходит, когда вы ослабили какие-то ограничения? Это значит,
[40:53.660 --> 40:59.680]  что вы к этим наборам, которые были допустимые, добавили еще кучу допустимых наборов. У вас все
[40:59.680 --> 41:05.540]  нецелочисленные наборы тоже стали допустимыми. Вот гораздо шире стало множество допустимых
[41:05.540 --> 41:16.140]  решений. Вопрос, а как тогда минимальное значение вот этой вот функции у нас изменилось? Если мы
[41:16.140 --> 41:24.380]  сняли какие-то ограничения и тем самым расширили множество допустимых вариантов. Оно могло не
[41:24.380 --> 41:28.940]  измениться, но если оно как-то изменилось, то оно точно уменьшилось. Правда? Если мы
[41:28.940 --> 41:34.980]  минимизируем... О, виноват. Мы чего здесь делаем? Максимизируем, наверное. Если мы
[41:34.980 --> 41:42.100]  максимизируем стоимость рюкзака и мы теперь сильно расширили область допустимых рюкзаков,
[41:42.100 --> 41:48.100]  то мы можем какие-то новые рюкзаки для себя открыть, которые раньше для нас были запрещены
[41:48.100 --> 41:55.940]  недопустимыми. Так что мы по-прежнему, естественно, у нас есть допустимые решения исходной задачи,
[41:55.940 --> 42:01.100]  оно по-прежнему никуда не исчезло, но могут появиться какие-то новые решения, которые еще круче.
[42:01.100 --> 42:08.820]  И это используется тоже. Это одна из ключевых вещей, которые мы на самом деле используем вот во всей
[42:08.820 --> 42:23.420]  этой науке, маленькой науке про линейную релаксацию. Так, чудесно. Я здесь еще стрелку в обе стороны
[42:23.420 --> 42:29.300]  вис. Что мы будем делать дальше? Дальше мы посмотрим, а как выглядит оптимальное решение вот этой вот
[42:29.300 --> 42:36.180]  задачки линейной релаксации. Причем не всегда нам даже нужно запускать solver для задач линейного
[42:36.180 --> 42:40.500]  программирования, чтобы это понять. В задаче о рюкзаке она чем хороша в качестве первой
[42:40.500 --> 42:46.820]  задачи в любом курсе? Тем, что в задаче о рюкзаке мы сами можем с вами угадать, как будет выглядеть
[42:46.820 --> 42:52.620]  оптимальное решение. Ведь снятие этого ограничения фактически означает, что мы можем дробить теперь
[42:52.620 --> 43:00.620]  наши предметы. Вот Гент Энрик, он сам Бильгейтс, и он облекает такую форму. Представьте, что вы в
[43:00.620 --> 43:05.940]  рюкзак напихиваете шоколадки, плитки шоколада. И вот когда вы снимаете это ограничение, вам
[43:05.940 --> 43:10.900]  разрешается дробить плитку шоколада, отламывать от нее кусочек и класть в рюкзак. Не всю плитку,
[43:10.900 --> 43:17.820]  а только часть. Но мне нравится другая аналогия, которую я придумал в прошлом году. Она про духи,
[43:17.820 --> 43:24.700]  ну и про спиртные напитки. Представьте, что рюкзак и то и то спиртосодержащий, но духи как-то
[43:24.700 --> 43:32.380]  более приличны, наверное. Представьте, что рюкзак превратился в бочку в местимости W, и вы теперь не
[43:32.380 --> 43:37.660]  кладете туда предметы дискретные, а наливаете туда жидкости. И у вас есть флакончики жидкостями.
[43:37.660 --> 43:48.860]  Значит, вместимость каждого флакончика это W, миллилитров духов, а вот это стоимость
[43:48.860 --> 43:56.740]  целиком флакончиков. Получается, что у вас есть возможность отливать целиком бутылочку,
[43:56.740 --> 44:04.300]  целиком или вообще ее не наливать, ничего, или что угодно промежуточное. Вопрос, как вы тогда
[44:04.300 --> 44:11.780]  бы сделали вашу бочку с духами максимально, но если считать, что при слиянии ароматов стоимость
[44:11.780 --> 44:17.780]  тоже суммируется просто, что не факт, то как взять и набрать наиболее дорогостоящую бочку?
[44:17.780 --> 44:30.500]  Да, берем духи, в первую очередь наливаем самые дорогие в расчете на 1 миллилитр. Давайте мы
[44:30.500 --> 44:38.660]  вот эту и используем, такую интуицию. Оказывается, нам очевидно, как выглядит
[44:38.660 --> 44:46.020]  оптимальное решение в релаксированной задаче. Мы в первую очередь берем и кладем в рюкзак,
[44:46.020 --> 44:54.980]  покуда он не заполнился до краев, кладем в рюкзак, наливаем в бочку духи, имеющие максимально
[44:54.980 --> 45:03.860]  удельную ценность. А удельная ценность, это вот там P i t поделить на W i t, стоимость 1 миллилитра.
[45:03.860 --> 45:11.060]  Так, чудесно, но вот сейчас мы этим как раз и будем заниматься. Давайте мы представим,
[45:11.060 --> 45:19.900]  предположим, для определенности, чтобы упростить обозначение и не говорить, что давайте переупорядочим
[45:19.900 --> 45:26.980]  наши предметы, так и сяк. Давайте, скажем, без ограничений общности будем считать, это математики
[45:26.980 --> 45:32.740]  обожают это делать. Без ограничений общности будем считать, что наши предметы в рюкзаке уже
[45:32.740 --> 45:47.500]  занумерованы, так что они идут по убыванию удельной стоимости. Считаем, что нумерация такая,
[45:47.500 --> 45:57.860]  что P i на W i. И здесь я еще, чтобы не плодить в сущности, предположу, что удельные стоимости
[45:57.860 --> 46:04.940]  все чуть-чуть отличаются, что вот здесь точных равенств нигде нет. P 1 на W 1 больше или равно,
[46:04.940 --> 46:17.300]  чем P 2 на W 2, виноват. Строго больше, чем P 3 на W 3, ну и так далее. Строго больше, чем P n на W n.
[46:17.300 --> 46:25.460]  Зачем вот это мне нужно? Ну, это не обязательно совершенно, так на всякий пожарный, что называется.
[46:25.460 --> 46:33.580]  Если у двух духов одинаковые удельные стоимости, то у нас сильно возрастает множество формальных
[46:33.580 --> 46:38.820]  оптимальных решений. Это как раз тот случай, когда два флакончика духов содержат абсолютно
[46:38.820 --> 46:42.980]  одинаковые по стоимости духи, и тогда вы можете чуть-чуть из одного флакончика отличить чуть-чуть
[46:42.980 --> 46:48.540]  из другого. Чтобы вот этой ерунды не было, чтобы вы доливали флакончик до краев, покуда бочка
[46:48.540 --> 46:55.220]  вообще не заполнилась целиком, вот я, пожалуй, потребую здесь строгие неравенства. Но никакого,
[46:55.220 --> 47:02.700]  по факту, существенного ограничения не дает. Просто для анализа чуть проще. Да, и понятно,
[47:02.700 --> 47:08.420]  что пока бочка не заполнится совсем-совсем целиком, мы в нее продолжаем что-то наливать,
[47:08.420 --> 47:16.120]  разумеется. Так вот, если мы работаем в таком предположении, то тогда как выглядит оптимальное
[47:16.120 --> 47:28.240]  решение нашей задачи. Оптимальное решение линейной релаксации. Значит, мы наливаем, наливаем,
[47:28.240 --> 47:34.840]  наливаем, наливаем флаконы в бочку. Причем, покуда бочка еще не заполнилась до краев,
[47:34.840 --> 47:40.760]  мы целиком выливаем флакончики с духами в порядке уменьшения стоимости. И только может
[47:40.760 --> 47:46.720]  быть один какой-то флакончик, вот покуда мы его наливали, у нас бочка все абсолютно заполнилась,
[47:46.720 --> 47:51.480]  и мы этот флакончик не долили, но тогда мы ни один из оставшихся флакончиков уже даже не откроем.
[47:51.480 --> 47:59.480]  Все, бочка налита до краев. Что это означает в терминах набора значений переменных? Оптимальное
[47:59.480 --> 48:05.320]  решение задачки обычно обозначается так. Мы вот берем все те же самые буквы для переменных,
[48:05.320 --> 48:11.480]  и над ними ставим звездочку. Так что обозначение здесь будет такое. Оптимальный набор значений
[48:11.480 --> 48:18.760]  переменных это x1 со звездочкой и так далее xn со звездочкой. Вот как он получается у нас выглядит
[48:18.760 --> 48:26.240]  в нашей задачке. До какого-то момента у нас идут единички, потом вот может быть один флакончик,
[48:26.240 --> 48:32.040]  максимум один. Он вот не весь влез, он между нулем и единицей, но если уж он не влез, то все
[48:32.040 --> 48:37.160]  оставшиеся флакончики точно нули. То есть можно сказать, что у нас решение такое здесь получается.
[48:37.160 --> 48:48.360]  До какого-то катего флакончика, ну давайте до k-1 считать, у нас единица. Вот катый флакончик,
[48:48.360 --> 48:56.200]  если он такой вообще есть с звездочкой, он у нас между нулем и единицей, давайте я это так и
[48:56.200 --> 49:08.280]  запишу. От нуля до единицы. И значит, если этот флакончик не влез, то с k-1 и до самого-самого
[49:08.280 --> 49:18.680]  последнего у нас точно все нули. Вот мораль. Какая здесь мораль? Иногда оптимальное решение задачи
[49:18.680 --> 49:23.520]  линейного программирования, не целочисленного, не надо даже искать с помощью солвера. Мы можем
[49:23.520 --> 49:29.000]  просто интуитивно понять, угадать какое оно должно быть. Но, к сожалению, помимо задачи рюкзаки,
[49:29.000 --> 49:36.680]  не так уж много задач, прям вот совсем все хорошо угадывается. Смотрите-ка, а нам практически
[49:36.680 --> 49:43.720]  повезло, потому что мы сняли целочисленные ограничения на все переменные, решили задачу
[49:43.720 --> 49:47.720]  линейного программирования, а по факту оказалось, что только одна переменная у нас в каком-то
[49:47.720 --> 49:54.840]  непонятном статусе. Давайте мы по максимуму попытаемся использовать вот эту вот информацию,
[49:54.840 --> 50:02.160]  которую нам выдал солвер или мы сами. Давайте те переменные, которые здесь целочисленные,
[50:02.160 --> 50:09.120]  итак мы и возьмем. То есть фактически мы в рюкзак положим те предметы, которые в рюкзак заведомо
[50:09.120 --> 50:20.640]  влезают, вплоть до К-1. Чего с катом предметом делать, если не вмещается в рюкзак? Можно
[50:20.640 --> 50:27.160]  так посмотреть среди оставшихся, просто какие еще влезают в рюкзак, взять предметы просто дальше
[50:27.160 --> 50:33.040]  по убыванию их удельной стоимости и покуда там влезают. Пройтись до самого конца, честно остановиться.
[50:33.040 --> 50:41.680]  Вот так что у нас есть первая такая стратегия. Да, первая стратегия. Ух, наверное тут столько места
[50:41.680 --> 50:52.120]  здесь хватит. Стратегия один, ивристика один. Ивристика один. Ивристика, я напоминаю, это какая-то
[50:52.120 --> 51:00.160]  разумная, интуитивная, как правило, стратегия решения задачи, которая не претендует вообще по
[51:00.160 --> 51:05.720]  умолчанию на оптимальность. Просто вот кажется, что неплохим должен быть рюкзак, который построен
[51:05.720 --> 51:17.480]  вот так. Берем предметы в порядке убывания удельной стоимости. Берем предметы по убыванию
[51:17.480 --> 51:34.000]  вот этих вот величин. P i t поделить на W i. Так, чудесно. Какая стоимость рюкзака у нас получается?
[51:34.000 --> 51:51.560]  Значит, стоимость рюкзака. Ну, давайте ее обозначим P i. Ну, поскольку при такой стратегии мы знаем,
[51:51.560 --> 51:57.320]  что у нас заведомо вот эти вот предметы, первые k-1, точно влезают в рюкзак, они точно там окажутся,
[51:57.320 --> 52:06.760]  стоимость рюкзака у нас получается не меньше, чем P i, плюс и так далее, плюс P t-1. Ну, какие
[52:06.760 --> 52:14.720]  из оставшихся влезут, мы не знаем, может, ни один не влезет, а может, еще какие-то влезут. А вот это
[52:14.720 --> 52:19.600]  ровно то, что мы сделали, да, то есть мы фактически берем предметы вот, ну, по счету, если предполагать,
[52:19.600 --> 52:30.080]  что мы в этих обозначениях, да, то берем просто по возрастанию индекса. Вот, значит, окей,
[52:30.080 --> 52:37.200]  насколько хорошо работает эта стратегия, давайте посмотрим. Я, да, здесь придется мне стирать.
[52:37.200 --> 52:50.640]  Ну, не всегда она хорошо работает, потому что можно привести пример, когда вот это вот,
[52:50.640 --> 52:56.280]  вот предмет X с катой, он как раз, который не целиком влез, и который мы в итоге и не
[52:56.280 --> 53:02.280]  сможем положить, если возьмем первый k-1 предмет, когда его-то как раз и следовало положить в рюкзак.
[53:02.280 --> 53:14.960]  Такой пример плохой для вот этой вристики 1. Ну, допустим, стоимость первого предмета равняется 2,
[53:14.960 --> 53:24.280]  вес первого предмета равняется единичке. Вот, ну, а второй предмет, я не буду заморачиваться с тем,
[53:24.280 --> 53:34.720]  что много предметов здесь напридумывать. Стоимость второго предмета равна 1,5 W, ну,
[53:34.720 --> 53:46.080]  а вес второго предмета равен W. Ну, я думаю, вы понимаете, да, в чем теперь подвох, что вот у этого
[53:46.080 --> 53:53.040]  предмета удельная стоимость большая, 2 против 1,5, но у этого предмета абсолютная стоимость очень
[53:53.040 --> 54:02.240]  большая. И очень жалко, что мы вот начав с этого предмета, заполним в рюкзаке маленькую-маленькую,
[54:02.240 --> 54:09.120]  да, вот такую полосочку, и этот предмет уже не войдет, потому что ему весь рюкзак необходим.
[54:09.120 --> 54:17.720]  Вот, то есть получается, что оптимальная стоимость рюкзака 1,5 W была бы, а она у нас получится
[54:17.720 --> 54:25.840]  оптимальной стоимость всего лишь 2. Ну и никакой хорошей оценки, да, мы, значит, не можем дать на вот
[54:25.840 --> 54:32.440]  эту ивристику 1. Ну, например, мы не можем сказать, что построенный по этой ивристики рюкзак всегда
[54:32.440 --> 54:38.360]  по стоимости не хуже, чем, например, половина от оптимума, да, вот оптимально можно было бы на
[54:38.360 --> 54:43.560]  миллион долларов предметов туда набрать, а мы на 500 тысяч долларов хотя бы предметов туда набрали.
[54:43.560 --> 54:54.000]  Ну, что делать? Если все ломается на катом предмете, да, вот как у нас здесь, то все ломается,
[54:54.000 --> 55:00.960]  как вот из примера видно, потому что у него абсолютная стоимость очень большая, и как можно
[55:00.960 --> 55:06.880]  тогда придумать еще какую-то альтернативную стратегию, которая бы вот этим предметом не
[55:06.880 --> 55:13.320]  давала пропасть с очень большой абсолютной стоимостью, несотносительной. Чем будем делать?
[55:13.320 --> 55:24.560]  Ну да, в общем-то ничего, ничего так особо не приходит в голову, если про простое что-то нужно
[55:24.560 --> 55:29.360]  выдумать. Давайте в первую очередь будем класть в рюкзак предметы с максимальной абсолютной
[55:29.360 --> 55:35.760]  стоимостью. Вот какие из них влезут, такие влезут. Да, берем предметы по убыванию пейтового просто,
[55:35.760 --> 55:50.160]  берем убывание просто величин пейта. Абсолютных стоимости. Стоимость рюкзака какая у нас
[55:50.160 --> 56:00.360]  получается? Построенного по второй стратегии, B2, не меньше чем, ну формально говоря, не меньше
[56:00.360 --> 56:06.480]  чем стоимость хотя бы одного предмета, самого большого. Да, мы здесь будем предполагать, чтобы
[56:06.480 --> 56:13.200]  вот исключить какие-то лишние разговоры, что все предметы, которые нам поданы на вход задачи,
[56:13.200 --> 56:17.240]  они в рюкзак по отдельности все-таки влезают, потому что нет никакого смысла рассматривать
[56:17.240 --> 56:23.560]  предметы, у которых W маленькое больше, чем вот это W большое, рюкзачное. Да, значит, мы будем
[56:23.560 --> 56:34.240]  предполагать вот это и еще мы будем предполагать, что максимум W маленьких W не превосходит W
[56:34.240 --> 56:41.280]  большого. Но это такое естественное предположение, вы скорее всего сразу будете предметы, конечно,
[56:41.280 --> 56:49.040]  отфильтровывать по этому признаку. Первое, что мы делаем. Тогда стоимость B2 вот такого рюкзака у
[56:49.040 --> 56:54.440]  нас будет не меньше, чем стоимость, ну хотя бы одного предмета, самого-самого большого по стоимости.
[56:54.440 --> 57:06.120]  Максимум по I от единицы до N по I. И это заведомо не хуже, чем стоимость одного единственного
[57:06.120 --> 57:11.200]  катового предмета, правда? Потому что, ну если кат и предмет сам по себе максимальный по стоимости,
[57:11.200 --> 57:16.920]  то окей. Если не максимальный, то значит, второй рюкзак он еще чуточку лучше. Ну а на практике он
[57:16.920 --> 57:21.560]  скорее всего сильно лучше, чем стоимость одного единственного какого-то предмета, пусть даже
[57:21.560 --> 57:28.280]  самого большого. Так, и с этим примером мы тогда боремся вот с помощью второй стратегии. Ну легко
[57:28.280 --> 57:33.040]  придумать пример обратный, когда вторая стратегия плохо работает, а первая стратегия работает лучше.
[57:34.000 --> 57:44.480]  Давайте теперь посмотрим, а как эти две стратегии комбинируются. Как эти две стратегии комбинируются.
[57:44.480 --> 57:52.480]  И для этого мы как раз помним про вот эту вот картинку, которую я рисовал, с уменьшенным множеством
[57:52.480 --> 57:58.200]  возможностей нашей и с увеличенным множеством возможностей. Когда мы релаксируем задачу и
[57:58.200 --> 58:03.800]  снимаем ограничения, мы расширяем множество допустимых решений. И мы целевую функцию,
[58:03.800 --> 58:10.120]  то есть стоимость рюкзака или бочки, мы ее можем сделать еще больше, еще больше.
[58:16.120 --> 58:23.000]  Вопрос, а как выразить через вот эти вот переменные х1 со звездочкой и так далее,
[58:23.000 --> 58:28.360]  х1 со звездочкой и значение целевой функции. Да, вот собственно мы знаем, что такое целевая
[58:28.360 --> 58:42.360]  функция. Да, это сумма по всем и в этой единице до n. И что такое оптимальное решение задачки
[58:42.360 --> 58:48.840]  линейной релаксации? Это как раз и есть вот эти вот х со звездочками, которые доставляют максимальное
[58:48.840 --> 58:54.720]  значение вот этой вот функции. То есть при подстановке вот этих вот звездочек этих значений
[58:54.720 --> 59:01.480]  сюда, мы получаем максимально возможное значение, которое вообще может быть у такой функции. И оно
[59:01.480 --> 59:10.040]  заведомо не меньше, чем оптимальное значение целевой функции в задаче CLP. Мы к задаче LP,
[59:10.040 --> 59:16.200]  для которой рассматривается оптимальное решение, мы как раз перешли, сняв ограничения,
[59:16.200 --> 59:23.680]  релаксировавшись. Значит, увеличив право-налево, если считать, увеличив значение, оптимальное
[59:23.680 --> 59:28.440]  значение целевой функции. Значит, здесь мы можем смело подставить оптимальное значение целевой
[59:28.440 --> 59:34.760]  функции в задаче CLP. Целочисленное линейное программирование. Это вот то, что мы с вами
[59:34.760 --> 59:40.760]  писали здесь в терминах вот этих переменных. И здесь у нас было условие. Каждый х это целое число.
[59:40.760 --> 59:53.640]  ILP. Integer Linear Programming. Guys. CLP это по-русски, а ILP это по-английски.
[59:53.640 --> 01:00:09.600]  Оптимальное значение, оптимальное значение целевой функции в задаче CLP.
[01:00:09.600 --> 01:00:20.240]  Есть два варианта, что может произойти со мной с вами под конец курса. Либо я вас абсолютно
[01:00:20.240 --> 01:00:25.520]  достану переходом с английского на русский обратно, либо вы немножко выучите терминологию
[01:00:25.520 --> 01:00:32.440]  дискретной оптимизации на обоих языках. Вот, но я надеюсь, что второе. Так вот, оптимальное значение
[01:00:32.440 --> 01:00:39.720]  целевой функции в задаче CLP. А что вот это такое? Поскольку задача CLP кодирует один в один задачу
[01:00:39.720 --> 01:00:46.280]  о рюкзаке, мы же по смыслу, помните, вводили переменные х как раз таким образом, чтобы набору
[01:00:46.280 --> 01:00:54.040]  значений х булевских, которые только нолики или единицы, однозначно отвечало какое-то наполнение
[01:00:54.040 --> 01:01:00.320]  рюкзака. То есть вот это я не зря здесь стрелку ставлю в обе стороны. Когда мы берем целочисленную
[01:01:00.320 --> 01:01:07.040]  линейную программу для исходной комбинаторной задачи, эта программа, она однозначно кодирует вот
[01:01:07.040 --> 01:01:14.480]  любой ее набор значений переменных выбора, decision variables вот этих, он однозначно абсолютно
[01:01:14.480 --> 01:01:19.600]  отвечает некоторые комбинаторные конфигурации, которые мы здесь как раз ищем. В том числе,
[01:01:19.600 --> 01:01:25.200]  оптимальный набор х, который доставляет максимальное значение функции в задаче CLP,
[01:01:25.200 --> 01:01:32.720]  он кодирует нам оптимальный рюкзак, оптимальное наполнение рюкзака и соответственно,
[01:01:32.720 --> 01:01:37.760]  оптимальное значение целевой функции, то есть значение как раз вот этой суммы на этом оптимальном
[01:01:37.760 --> 01:01:44.800]  наборе, это и есть максимально достижимая стоимость рюкзака. Вот это один в один. А вот этот
[01:01:44.800 --> 01:01:51.240]  переход, он у нас с потерями логическими как раз, но тем не менее с некоторым неравенством.
[01:01:51.320 --> 01:01:57.600]  Но вот что я хочу дальше сказать, что вот это неравенство, оно возникает из вот такого перехода,
[01:01:58.460 --> 01:02:04.200]  не только в задаче о рюкзаке, абсолютно любой переход от задачи CLP к задачи LP, он сопряжен
[01:02:04.200 --> 01:02:08.580]  вот с таким вот неравенством, если исходная задача была задачей максимизации и с неравенством
[01:02:08.580 --> 01:02:14.520]  в обратную сторону если исходная задача была задачей минимизации. А дальше, я что могу написать?
[01:02:14.520 --> 01:02:20.420]  Дальше могу написать равенство, поскольку здесь у нас переход 1 в 1, но здесь я могу написать равно
[01:02:20.420 --> 01:02:31.980]  стоимости оптимального рюкзака или оптимальной стоимости рюкзака, оптимальная стоимость рюкзака.
[01:02:37.060 --> 01:02:42.340]  Ну, я думаю, что вы это себе уже отметили, здесь можно поставить оптимальную стоимость рюкзака,
[01:02:42.340 --> 01:03:01.100]  я напишу сокращение. Это просто оптим. По-английски, от слова оптимум. Но дело в том,
[01:03:01.100 --> 01:03:06.180]  что в статьях по дискретной оптимизации это уже абсолютно стандартное обозначение,
[01:03:06.180 --> 01:03:11.940]  которое даже, скорее всего, никто объяснять не будет отдельно. Что оптимальное решение и
[01:03:11.940 --> 01:03:17.700]  или соответствующее оптимальное значение целевой функции обозначается просто словом
[01:03:17.700 --> 01:03:23.100]  сокращением опт. Это максимально достижимая стоимость рюкзака. Задача о рюкзаке для нас
[01:03:23.100 --> 01:03:34.180]  в данном случае. Так, скажите, пожалуйста, теперь, да, мы знаем здесь в этой сумме некоторые,
[01:03:34.180 --> 01:03:39.660]  да как не некоторые, мы все слагаемые знаем, потому что мы знаем, как выглядит оптимальное
[01:03:39.660 --> 01:03:47.780]  решение. Чему равна эта сумма? Она у нас равна. Давайте подставим сюда все, что мы знаем про наши
[01:03:47.780 --> 01:03:58.120]  переменные. Значит, переменные с первой по камену с первого у нас равны единичке. Переменная х
[01:03:58.120 --> 01:04:06.420]  катая, она от нуля до единицы. Вот, но я так и напишу, плюс п катая на что-то такое непонятное пока,
[01:04:06.420 --> 01:04:16.580]  от нуля до единицы. А дальше что будет стоять? Дальше нули, да, потому что мы знаем, что остальные
[01:04:16.580 --> 01:04:27.220]  переменные все равно нулю. Вот, но хорошо. Можем мы так теперь перейти по неравенству. Если выполнено
[01:04:27.220 --> 01:04:32.980]  такое равенство, давайте мы вот эту вот переменную округлим мысленно к единичке. То есть дольем в бочку
[01:04:32.980 --> 01:04:38.740]  флакончик, который на самом деле в нее не влезает. Но мы вот так еще сверху горкой дольем духов. Если
[01:04:38.740 --> 01:04:43.780]  представить, что на бочке может сверху образоваться горка, да, вот здесь я могу поставить теперь
[01:04:43.780 --> 01:04:50.900]  неравенство видом меньше или равно заменив вот эту вот непонятность, которая от нуля до единицы,
[01:04:50.900 --> 01:04:55.860]  просто на единичку, долив вот этот вот на самом деле не влезающий флакончик духов.
[01:04:55.860 --> 01:05:07.060]  О, чудесно. И теперь вот эта штука меньше или равна, чем, чтобы здесь такое записать,
[01:05:07.060 --> 01:05:11.380]  зависящее только уже от наших вот этих евреистических результатов P1 и P2.
[01:05:11.380 --> 01:05:27.060]  P1 плюс P2, да. P1 плюс P2. Чудесно. Так, теперь у нас есть получается две еврестики, два рюкзака,
[01:05:27.060 --> 01:05:37.020]  допустимых. А тем, что P1 у нас вот только до K-1 предмета влезают в рюкзак гарантированно,
[01:05:37.020 --> 01:05:44.780]  а K-1 не влезает. А P2 в стратегии мы заведомо положим как минимум один предмет,
[01:05:44.780 --> 01:05:50.700]  который по стоимости как минимум не хуже, чем P-K-1. Ну, очевидно, что любой отдельный вес не
[01:05:50.700 --> 01:05:56.060]  превосходит максимум, не вес, а стоимость не превосходит максимум стоимости по всем И,
[01:05:56.060 --> 01:06:03.820]  да, поэтому P-K-1 не превосходит, конечно, вот такого максимума. На самом деле стратегия P2,
[01:06:03.820 --> 01:06:09.540]  скорее всего, сильно лучше. Вряд ли в реальных входах в задачу рюкзаки у нас только один
[01:06:09.540 --> 01:06:14.140]  предмет влезет и больше ничего не влезет. Скорее всего, обе эти стратегии, ну не P1,
[01:06:14.140 --> 01:06:21.780]  а вот стратегия P2, она сработает намного лучше, чем вот эта вот штука. И мы теперь знаем,
[01:06:21.780 --> 01:06:30.740]  что суммарная стоимость двух рюкзаков не меньше, чем стоимость оптимального рюкзака. Что тогда мы
[01:06:30.740 --> 01:06:38.060]  можем гарантировать, если возьмем из этих двух ивристик лучшую по факту? Половинка, да, хотя бы.
[01:06:38.060 --> 01:06:46.180]  Вот, следовательно, то есть из вот этой вот цепочки неравенств следует, то лучшая из ивристик P1,
[01:06:46.180 --> 01:07:10.740]  P2, лучшая из ивристик 1 и 2, дает рюкзак по стоимости не меньше, чем половинка от опт.
[01:07:10.740 --> 01:07:22.380]  Половинка от опт. Потому что мы выяснили, что суммарная стоимость двух рюкзаков не меньше,
[01:07:22.380 --> 01:07:27.420]  чем опт целиком. Значит, лучшая из них, максимально из этих двух чисел, точно не меньше половины.
[01:07:27.420 --> 01:07:37.500]  Скорее всего, сильно больше. Вопрос, а может быть какая-нибудь из этих чиселок P1 и P2 больше опта?
[01:07:37.500 --> 01:07:47.820]  Не может, потому что по определению опт это и есть. Там самая максимально достижимая стоимость
[01:07:47.820 --> 01:07:53.980]  рюкзака допустимого, в который все влезает. А мы эти ивристики построили так, что они дают нам
[01:07:53.980 --> 01:08:04.660]  допустимые решения, то есть не переполненные рюкзаки. Вот, значит, какие выводы можно сделать из этого всего?
[01:08:04.660 --> 01:08:13.900]  Мы использовали вот этот вот LP и рюкзак. Использовали на самом деле по-разному. Значит,
[01:08:13.900 --> 01:08:20.980]  во-первых, решение задачи линейного программирования оптимальное позволило нам сформировать некое
[01:08:20.980 --> 01:08:27.580]  эвристическое решение задачи вот этой исходной. То есть, с одной стороны, мы имеем какое-то
[01:08:27.580 --> 01:08:46.700]  приближенное решение для задачи о рюкзаке исходной. А с другой стороны, некие знания
[01:08:46.700 --> 01:08:54.620]  про линейную релаксацию позволяют нам еще кое-как оценивать оптимум исходной задачи. Каким
[01:08:54.620 --> 01:09:01.020]  образом? Вот когда мы с вами выписали вот это вот неравенство, во-первых, вот это неравенство,
[01:09:01.020 --> 01:09:10.180]  возникшее из вот этого перехода, и дальше выписали вот это вот неравенство, мы с вами знаем, что, ага,
[01:09:10.180 --> 01:09:17.820]  мы не знаем в точности стоимость оптимального рюкзака. Это трудная комбинаторная задача. Но мы
[01:09:17.820 --> 01:09:23.900]  умеем очень неплохо оценить стоимость оптимального рюкзака сверху. Мы знаем, что опт не больше,
[01:09:23.900 --> 01:09:35.380]  чем вот сумма таких пэшек. Так что мы с другой стороны, умеем еще с помощью вот этого вот задачи
[01:09:35.380 --> 01:09:49.060]  линейного программирования, вот этой штуки, оценивать. Оцениваем. Баунд. Оценивать.
[01:09:49.060 --> 01:09:57.220]  Получаем некие оценки. Баунд для исходной задачи, которые позволяют нам, видите, в итоге сравниться,
[01:09:57.220 --> 01:10:02.100]  насколько полученное нам евристическое решение близко к настоящему оптимуму.
[01:10:04.100 --> 01:10:08.660]  Вот. Но давайте я это все вытащу. Теперь все наши достижения.
[01:10:19.620 --> 01:10:42.220]  Первый. Начленина и релаксация. Во-первых, дает некую евристику часто, евристику для исходной задачи,
[01:10:42.300 --> 01:10:58.260]  для комбинаторной задачи. Во-вторых, линейная релаксация позволяет оценить оптимальное значение
[01:10:58.260 --> 01:11:13.020]  функции целевой восходной задачи. Позволяет оценить оптимум комбинаторной задачи.
[01:11:13.020 --> 01:11:31.620]  Третье. Что еще полезное мы с вами выяснили. Не всегда оптимальное решение задачи линейного
[01:11:31.620 --> 01:11:36.100]  программирования надо получать с помощью солдера. Иногда просто уже вот тот факт,
[01:11:36.100 --> 01:11:40.940]  что мы задумались, а как бы выглядело это решение, если бы нам позволялось предметы
[01:11:40.940 --> 01:11:48.380]  раскалывать или вместо предметов были бы духи. Это уже полезная точка зрения на исходную задачу.
[01:11:48.380 --> 01:12:00.140]  Значит, иногда оптимальное решение линейной релаксации можно просто угадать,
[01:12:00.140 --> 01:12:18.380]  не решая эту задачу. Следующее. Это пример, показывающий наглядно, что в сложных задачах
[01:12:18.380 --> 01:12:25.300]  может сработать такой подход. Иногда только он на самом деле и работает по-настоящему. Нету
[01:12:25.300 --> 01:12:31.740]  одного алгоритма на все случаи жизни. Решение задачки. Вот мы привыкли, привыкаем в курсе
[01:12:31.740 --> 01:12:36.620]  алгоритмов, например, таком вводном, что есть жестко поставленные задачи о кратчайшем пути.
[01:12:36.620 --> 01:12:41.580]  Есть один единственный верный алгоритм. Там этот алгоритм Дэйкстр. Ну, условно. Или там есть
[01:12:41.580 --> 01:12:47.220]  сортировка массива. Есть вот сортировка только слияния. Ну или что-то другое. В общем, есть
[01:12:47.220 --> 01:12:52.820]  точное решение задачи, которое можно получить с помощью вот одного алгоритма. Вот мы его и учим.
[01:12:52.820 --> 01:12:58.460]  И на практике ищем самый крутой алгоритм, самый быстрый, только его кодируем. Все,
[01:12:58.460 --> 01:13:03.380]  остальные алгоритмы нам просто не нужны. На практике в дискретной оптимизации оказывается,
[01:13:03.380 --> 01:13:08.180]  что обычно нам как раз полезно закодировать несколько разных иллюстических подходов для
[01:13:08.180 --> 01:13:13.820]  решения задачи и выбрать тот, который на конкретных входных данных сработает наилучшим образом по факту.
[01:13:13.820 --> 01:13:18.580]  То есть заранее это очень часто предстоять невозможно. Какая иллюстика кажется лучше.
[01:13:18.580 --> 01:13:25.940]  Только по факту запуска. Не боимся реализовывать сразу много иллюстики. Выбирать из них
[01:13:25.940 --> 01:13:32.820]  ту, которая сработает лучше на конкретных входных данных. Часто нет. Часто для задач
[01:13:32.820 --> 01:13:46.340]  комбинаторная оптимизация. Комбинаторная оптимизация полезна. Не то, что нужно,
[01:13:46.340 --> 01:13:54.140]  да, полезно реализовать несколько подходов и выбрать лучшие уже по факту запуска. Полезно
[01:13:54.140 --> 01:14:20.060]  иметь несколько подходов, несколько иллюстиков и выбирать лучшие по факту запуска. Но если еще
[01:14:20.060 --> 01:14:27.100]  чего вспомню, вот, что можно отсюда выводить, то, наверное, скажу. Но вот ко второй иллюстики мы
[01:14:27.100 --> 01:14:34.540]  пришли каким образом. Мы посмотрели, а что, как может сработать неудачно первая иллюстика. Это,
[01:14:34.540 --> 01:14:42.940]  наверное, все-таки будет пятым таким takeaway. Придумывать иллюстики для задач можно,
[01:14:42.940 --> 01:14:49.580]  специфически подбирая примеры, на которых старые иллюстики работают плохо, доказуемо плохо. То
[01:14:49.580 --> 01:14:56.220]  есть придумывание примеров трудных для имеющихся иллюстик может навести вас на мысль о какой должна
[01:14:56.220 --> 01:15:08.900]  быть альтернативная иллюстика. Придумываем, просто напишу, придумываем примеры трудные для иллюстики.
[01:15:08.900 --> 01:15:16.900]  Ну плохие, трудные, неудачные, на которых имеющиеся иллюстики работают плохо. Просто
[01:15:16.900 --> 01:15:22.380]  думание над такими примерами позволяет нам прокачать интуицию и придумать какие-то
[01:15:22.380 --> 01:15:35.860]  иллюстики альтернативные. Трудные для имеющихся иллюстик. Ну это все, наверное, что из этой задачки
[01:15:35.860 --> 01:15:41.140]  можно выводить, из нашего решения. Сейчас мы с вами, нет, сейчас мы с вами сначала, я поотвечаю,
[01:15:41.140 --> 01:15:47.740]  я только уже поотвечаю на вопрос, потому что осталось три минуты. Ну или, может быть,
[01:15:47.740 --> 01:15:52.500]  у вас есть чего добавить. Если вам на практике встречалась когда-нибудь, может вы сами кодили
[01:15:52.500 --> 01:16:00.260]  уже, вот ситуация, когда не работает подход с одним единственным, таким святым гралем,
[01:16:00.260 --> 01:16:05.660]  единственным алгоритмом, который, если он у вас будет, можно все остальные выкинуть. Бывало такое?
[01:16:05.660 --> 01:16:15.500]  Нет? Пока нет. Ну это хорошо, это значит, мы с вами рассматриваем что-то для вас новое. Значит,
[01:16:15.500 --> 01:16:21.500]  когда вы будете рассмотреть курс Гентенрика, да, внимание, задача о рюкзаке, это задача,
[01:16:21.500 --> 01:16:27.500]  с которой начинаются сразу два курса на курсере. С одной стороны курс Клер Матье, с другой стороны
[01:16:27.500 --> 01:16:32.900]  курс Гентенрика. Поэтому то, что мы с вами сегодня рассмотрели, я надеюсь, позволит вам хотя бы
[01:16:32.900 --> 01:16:39.460]  первые две лекции посмотреть по курсам вот этим двум, approximation algorithm с Матье и discrete
[01:16:39.460 --> 01:16:44.660]  optimization с Гентенрика. Если вы не боитесь совсем-совсем английского языка, а я не вижу смысла его
[01:16:44.660 --> 01:16:49.340]  бояться, потому что рано или поздно он нам встретится, то я вам советую в этих двух курсах
[01:16:49.340 --> 01:16:55.460]  посмотреть первые две лекции, а вдруг вам понравится и вы возьмете те курсы вместо нашего, ну или в
[01:16:55.460 --> 01:17:01.260]  дополнение к нашему, что еще лучше. Поэтому дерзайте, я надеюсь, что вы что-то новое в тех лекциях для
[01:17:01.260 --> 01:17:04.700]  себя вынести тоже под рюкзак. Все тогда на сегодня, всем счастливого!
