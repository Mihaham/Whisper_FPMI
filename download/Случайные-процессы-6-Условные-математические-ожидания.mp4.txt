[00:00.000 --> 00:26.880]  было винарский процесс, ну я не буду перечислять его свойства на доске, но напомню, что это
[00:26.880 --> 00:39.320]  независимые приращения и приращение гауссовские, одно приращение гауссовское с дисперсией вот
[00:39.320 --> 00:55.440]  у такого приращения дисперсия t-s, если t больше s, значит, почему непрерывные траектории?
[00:55.440 --> 01:18.320]  ну я напомню, значит, это по теореме Колмогорова, там такая была теорема, что если вот такая вот
[01:18.320 --> 01:30.200]  оценка есть, то непрерывные траектории есть, так у нас с чем это нужно применять, значит,
[01:30.200 --> 01:37.240]  смотрите, а если так совсем банально сделать, ну с двойкой, тут самое милое дело с двойкой,
[01:37.240 --> 01:42.960]  уже считать ничего не надо, но с двойкой не дотягивает, видите, эпсилон нет, с двойкой
[01:42.960 --> 01:57.840]  получится не эпсилон, значит, бета вовсе не двойка, а бету нужно взять четверку, так вот,
[01:57.840 --> 02:08.840]  если сосчитать четвертый момент, так, а четвертый момент у гауссовской случайной величины заданной
[02:08.840 --> 02:13.520]  дисперсии, ну давайте это не будем считать, будем считать, что это относится там к какому-нибудь
[02:13.520 --> 02:25.320]  прошлому семестру, то тогда получится, что единица плюс эпсилон можно взять равное 3,
[02:25.320 --> 02:38.880]  но нам даже не важно какое, давайте я не буду даже писать, тогда оно точно будет единица,
[02:38.880 --> 02:50.880]  ну вот сосчитайте, какой будет ответ, ну годится, ответ будет 4 на t-s в кубе, но это даже не важно,
[02:50.880 --> 03:00.800]  что именно в кубе, важно, что стало больше единицы, вот, а теперь обсуждается, вот это у нас,
[03:00.800 --> 03:22.720]  так сказать, было, обсуждается альтернативный способ, вот в виде функционального ряда,
[03:22.720 --> 03:46.320]  ен базис вл2, ну скажем, давайте для определенности на 0.2p, мы там в прошлый раз на 0.2p обсуждали,
[03:46.320 --> 03:52.760]  значит базис какой угодно годится, артнормированный, и как я в прошлый раз говорил,
[03:52.760 --> 04:00.120]  значит есть теорема, о которой полезно знать, но доказывать мы ее не будем, и самой даже,
[04:00.120 --> 04:06.960]  так сказать, у нас самого обсуждения этого нет, почему так будет, вот, ну как это полезно,
[04:06.960 --> 04:20.640]  как факт просто знать, значит, но если ен это синусы нт, косинусы нт, ну там с множителями,
[04:20.640 --> 04:31.800]  так, то получается, что когда вы проинтегрируете, так, значит, получаются ряды,
[04:31.800 --> 04:41.800]  получаются ряды вот такого вот вида, вот мы на этом закончились, давайте я, значит,
[04:41.800 --> 04:48.840]  выпишу, какого вида ряды получаются, получаются вот такого вот, ну там с коэффициентами, конечно,
[04:48.840 --> 05:08.520]  значит, по синусам и по косинусам, так, аналогичные ряды, так, значит, спрашивается,
[05:08.520 --> 05:18.840]  почему хотя бы в L2 это даст что-то, при таком способе действия трудность никуда не уйдет,
[05:18.840 --> 05:26.520]  потому что тут же цель, чтобы была равномерная сходимость, а тут не станет от этого легче
[05:26.520 --> 05:33.200]  доказывать равномерную сходимость, потому что, видите, если бы тут стояли квадраты, то все было
[05:33.200 --> 05:41.400]  бы чудненько, ряд бы равномерно сходился, но увы, стоят те, кто не сходятся, но хотя бы в L2,
[05:41.400 --> 05:58.880]  хотя бы в L2 сходимость есть, значит, почему есть хотя бы в L2 сходимость, значит, вот такой вот ряд
[05:58.880 --> 06:18.440]  сходится почти наверно, потому что, потому что ряд из интегралов,
[06:18.440 --> 06:30.440]  который как раз уже хороший ряд, значит, он сходится, значит, раз ряд из интегралов сходится,
[06:30.440 --> 06:40.160]  то сходится, значит, как известно, почти в чуду сам функциональный ряд, поэтому для тех омега,
[06:40.160 --> 06:47.160]  для тех омега, для которых вот та сумма конечна, ну, можно считать, что это для всех,
[06:47.160 --> 06:54.120]  выбросив множество меры нуль, можно считать, что это для всех омега, так, значит, получается,
[06:54.120 --> 07:06.720]  что ряды сходятся в L2, так, ну, на самом деле, на самом деле сходимость, как видно из этой оценки,
[07:06.720 --> 07:24.120]  сходимость в L2 на, по двум переменам, значит, по мере, вот меру либега умножить на p, даже в таком будет,
[07:24.120 --> 07:32.600]  значит, эти вот из-за этой оценки следует, что этот ряд как двух функций, двух переменных сходится,
[07:32.600 --> 07:50.800]  так, поэтому можно положить, можно взять то, что мы хотим, функции двух переменных, как сумму ряда,
[07:50.800 --> 08:09.680]  значит, как сумму ряда, где он сходится, значит, он тогда сходится почти всю, ну,
[08:09.680 --> 08:23.680]  для при почти всех, значит, то есть при почти всех парах t омега, но вы скажете, по нашей доктрине,
[08:23.680 --> 08:32.160]  процесс, это функция двух переменных, но она все-таки при всех t должна быть определена, так, а не при
[08:32.160 --> 08:41.360]  почти всех, как быть, а здесь, значит, получилось при почти всех, ну, тут можно подправить, можно
[08:41.360 --> 08:48.680]  подправить то, что получилось, а пока что у нас получилось, значит, вот так, но давайте подправим,
[08:48.680 --> 08:59.600]  значит, по Фубини, так, поминаем итальянскую мафию, значит, по Фубини, при почти всех,
[08:59.600 --> 09:21.480]  значит, при почти всех фиксированных t есть сходимость ряда при почти всех омега, так, ну, множество
[09:21.480 --> 09:34.080]  таких t пусть будет, ну, какое-то там t0, так, вот, значит, при каждом t0, при каждом t0, при
[09:34.080 --> 09:44.920]  почти всех, значит, омега будет сходимость, так, а теперь, значит, мы сделаем следующее, давайте
[09:44.920 --> 09:58.480]  сосчитаем, ну, там, где у нас все определено, давайте сосчитаем мат ожидания и дисперсию,
[09:58.480 --> 10:09.600]  ну, раз ряд сходится в l2, то смотрите, что получается, значит, получается, что мат ожидания вот этого, так,
[10:09.600 --> 10:32.880]  это будет 0, ну, при почти всех t, почему? Ну, потому что мат ожидания вот этих всех нулей, так,
[10:32.880 --> 10:43.560]  а теперь давайте посмотрим, теперь давайте посмотрим,
[10:43.560 --> 11:06.180]  чему вот это равно мат ожидания квадрата, так, значит, смотрите, что получается, получается,
[11:06.300 --> 11:13.980]  что это мат ожидания, вот от чего, значит, на первый взгляд, значит, ну, что-то ужасное предстоит делать,
[11:13.980 --> 11:22.300]  ряд возводить в квадрат, так, но давайте посмотрим, что это за ряд, значит, это вот какой ряд,
[11:22.300 --> 11:34.900]  давайте, давайте, вот я напишу вот так, да нет, давайте сразу интеграл напишу,
[11:34.900 --> 11:50.220]  значит, смотрите, это ряд, вот какой, стоят стандартные гауссовские случайные величины,
[11:50.420 --> 12:02.740]  так, и при них что-то, так, значит, и при них что-то, но тогда они независимые, так,
[12:02.740 --> 12:09.660]  и тогда получается вот какой ряд, будет просто ряд из квадратов вот этих вот,
[12:09.660 --> 12:30.820]  потому что вот эти независимые стандартные гауссовские, а тут же T и S фиксировано,
[12:30.820 --> 12:36.860]  так что они пока, ну, какие-то числа стоят, при этих гауссах стоят какие-то числа,
[12:36.860 --> 12:45.860]  значит, дисперсия суммы будет просто сумма дисперсий, так, а что вот это, что такое,
[12:45.860 --> 12:54.940]  смотрим внимательно вот на это, значит, стоит, ну, вроде какие-то ужасные интегралы какие-то стоят,
[12:54.940 --> 13:00.340]  так, значит, если вот пуститься во все тяжкие, начать сюда подставлять синусы и косусы,
[13:00.340 --> 13:06.020]  ну, какой-то тихий ужас получится, так, но на самом деле не надо на это смотреть,
[13:06.020 --> 13:17.980]  как на интегралы, а на это надо посмотреть вот как на что, это стоят индикаторы отрезка скалярно,
[13:17.980 --> 13:32.100]  скалярно с Dn в L2, то есть, смотрите, тут стоит сумма квадратов коэффициентов фурье, так,
[13:32.100 --> 13:52.300]  и поэтому по парсивалю, значит, по парсивалю, так, это будет просто квадрат нормы индикатора в L2,
[13:52.300 --> 14:05.020]  ну, а это будет t-s, потому что вот считать нормы в L2 индикаторов одно удовольствие,
[14:05.020 --> 14:12.380]  это просто длинные квадраты норм, это просто длинных отрезков, значит, смотрите,
[14:12.380 --> 14:28.220]  получили заказанную величину, так сказать, на самом деле можно считать, что пока t и s,
[14:28.220 --> 14:35.780]  вот из этого t0, где есть сходимость, потому что мы что-то исполняли при фиксированных t и s,
[14:36.180 --> 14:45.780]  ну и поэтому нужно, чтобы при них была сходимость, но на самом деле из этого вычисления видно,
[14:45.780 --> 14:54.140]  из этого вычисления видно, что это верно при всех t и s, когда мы проделали вычисление,
[14:54.140 --> 15:05.460]  то видно, что тут не важно сходился ряд, сходился ряд, так сказать, или нет, а вот этот, вот этот ряд
[15:05.460 --> 15:13.020]  будет сходиться в L2, так, значит, это ответ, это оправдывает, значит, смотрите, что у нас получилось,
[15:13.020 --> 15:22.300]  значит, у нас получилось, ну, то, что мы заказывали, что действительно у приращения средняя ноль,
[15:22.300 --> 15:35.100]  дисперсия какая надо, так, а теперь при t не из t0, мы теперь переопределяем вот это,
[15:35.100 --> 15:49.140]  как предел в L2, w, s, так, ну, по каким s, ну, s стремится к t и s из t0, ну, значит,
[15:49.140 --> 15:59.620]  вы берем последовательность, у нас множество полной меры было, значит, это множество t0
[15:59.620 --> 16:13.820]  всюду плотно, значит, t0 всюду плотно, раз у него дополнение имело меру ноль, поэтому мы, чтобы у нас
[16:13.820 --> 16:22.620]  вот эта функция двух переменных была не при почти всех t задана, а, честно, как полагается у процесса,
[16:22.620 --> 16:32.860]  при всех t, мы вот еще такой последний финт делаем, переопределяем, так, значит, в итоге у нас
[16:32.860 --> 16:41.060]  получилось вот это при всех, значит, у нас при каждом t появилась случайная величина, так, значит,
[16:41.060 --> 16:50.860]  ну, при таком способе остаются вот эти свойства, значит, остаются вот эти вот,
[16:50.860 --> 17:09.940]  конечно, остаются уже при всех t, кроме того, понятно, что при таком способе задания wt
[17:09.940 --> 17:23.260]  гауссовский процесс, процесс гауссовский получился, а теперь, значит, нам нужно еще что,
[17:23.260 --> 17:32.100]  чтобы приращения были независимы, значит, еще мы хотели, значит, уже почти все, так сказать,
[17:32.100 --> 17:50.980]  сделано, так, но, значит, нужны приращения, значит, приращения независимы, а из-за гауссовости,
[17:50.980 --> 18:03.180]  из-за гауссовости процесса, проверяем, проверяем некоррелированность приращений,
[18:03.180 --> 18:21.460]  значит, вам нужно взять вот такие вот, так, и, ну, скажем, вот так, значит, сейчас давайте, так,
[18:21.460 --> 18:34.740]  4, 3, так, значит, где t1 меньше t2 меньше либо равно t3 меньше t4, значит, вот у этих нужно проверить
[18:34.740 --> 18:45.380]  некоррелированность, так, значит, уже процесс гауссовский, значит, для независимости достаточно
[18:45.380 --> 18:52.860]  некоррелированность, значит, средняя ноль, поэтому никаких там мат ожиданий нет и получается,
[18:52.860 --> 19:04.260]  что нам нужно сосчитать, значит, смотрите, что нам нужно сосчитать, нам нужно сосчитать вот такую вот вещь,
[19:04.260 --> 19:20.420]  ну, значит, считаем, значит, смотрите, что получается, тут получается вот такая вещь,
[19:20.420 --> 19:42.100]  сумма ксиенных на интеграл от t1 до t2, ен, значит, ds, так, а тут, значит, ксиенный на интеграл вот такой,
[19:42.100 --> 19:53.020]  но опять стоят, значит, два ряда перемножаются с независимыми гауссовскими и с какими-то
[19:53.020 --> 20:06.380]  числовыми коэффициентами, так, значит, получается, что эта сумма будет просто произведение вот этих,
[20:06.380 --> 20:18.820]  все попарно уйдут, когда мы честно будем перемножать ряды, то тут будут всякие кси, ен, на ксяка, но они все уйдут,
[20:18.820 --> 20:25.300]  когда k не равно n, потому что они попарно-ортагональны, значит, останутся только одноименные и при
[20:25.300 --> 20:42.500]  одноименных будет вот такая вот вещь стоять, но в этом опять узнаем, в этом опять узнаем скалярные
[20:42.500 --> 21:07.700]  произведения вл2, значит, индикаторов с базисными, опять тут стоит произведение скалярных произведений,
[21:07.700 --> 21:24.180]  ну и, значит, опять парсиваль, значит, дает, что это будет скалярное произведение вл2 индикаторов,
[21:24.180 --> 21:39.460]  но отрезки у нас не накладываются, поэтому это будет ноль, то есть, видите, значит, вот тут все вычисления при таком подходе
[21:39.460 --> 21:45.780]  основаны на равенстве парсивали, ну, я полагаю, что у вас в функциональном анализе оно уже когда-то там давно уже было,
[21:45.780 --> 21:53.420]  это равенство парсивали, так что, видите, штука полезная, вот мужик сто лет назад придумал, ну там сто с лишним лет назад,
[21:53.820 --> 22:10.700]  и, видите, до сих пор не устарела, значит, тут все очень мило, получился нужный процесс, но у него какой, так сказать, дефект,
[22:10.700 --> 22:17.420]  ну вот мы при таком подходе, мы не знаем, что у него непрывные траектории, чтобы узнать, что непрывные траектории,
[22:17.900 --> 22:27.900]  нужно либо к теориями Колмогорова обращаться, ну, она здесь опять применима, потому что мы же как только приращение гауссовской
[22:27.900 --> 22:36.460]  из известной дисперсии, все, четвертый момент читаем, точно так же теориями Колмогорова применима, ну, я считаю, что это самый эффективный
[22:36.540 --> 22:46.620]  и дешевый способ тут отделаться, но, возможно, более сильные средства из теории функций можно, так сказать, засучив рукава,
[22:46.620 --> 22:54.380]  браться за сходимость этого ряда, ну, что само по себе довольно вещь любопытная, но довольно коровопролитные подробности,
[22:54.780 --> 23:06.300]  поэтому мы их опускаем. Теперь спрашивается, а как было у Винера, который вроде бы это придумал, до Колмогорова?
[23:06.300 --> 23:22.300]  Значит, Винер это в двадцатых годах придумал, а Колмогоров это, так сказать, преобразовал, ну, там можно сказать, в конце двадцатых, в начале тридцатых.
[23:22.700 --> 23:36.700]  Ну, вот у самого Винера изначально, честно говоря, было не очень внятно, а у него на самом деле, так сказать, по нынешним меркам как бы не было какого-то аккуратного доказательств.
[23:37.100 --> 23:57.100]  То, что у него написано, ну, я когда-то пробовал читать, это довольно тяжело читать, и, в общем, не так просто довести до ума, но потом у Винера появился талантливый ученик Пелли,
[23:57.500 --> 24:17.500]  который потом, к сожалению, погиб в горах, был адвинистом. Вот он успел внести важный вклад в это дело, и вот с его помощью уже, так сказать, позже, уже в тридцатых годах, уже после Колмогорова,
[24:17.900 --> 24:33.900]  они все-таки довели вот этот, так сказать, первоначальный способ Винера, ну, вот изменили его, и довели до некоторого строгого рассуждения,
[24:33.900 --> 24:44.900]  но вот у них вот как раз был такой вот анализ вот этих вот тригонометрических рядов со случайными коэффициентами, вот у них такой был способ.
[24:45.300 --> 25:02.300]  Он технически более длинный, но, ну, имеет самостоятельную ценность, если не считать, что основная цель как-то получить процесс, то вот их способ через разложение функциональной ряды тоже представляет интерес, тоже был красивый результат,
[25:02.700 --> 25:15.700]  но, несомненно, самый такой ясный способ построить аккуратно, мне кажется, самый ясный и короткий способ, это Колмогоровский.
[25:15.700 --> 25:23.700]  Ну, у Колмогорова всегда так, вот когда он делал какие-то задачи, у него они всегда как-то получались ясные и короткие.
[25:24.100 --> 25:38.100]  Он даже вообще считал, что не может быть длинных математических доказательств, потому что он говорил, что в человеческом мозгу не может поместиться больше, чем на пять страниц чего-то,
[25:38.100 --> 25:47.100]  поэтому он как-то с сомнением относился к работам, у которых доказательства не помещались на пять страниц.
[25:47.500 --> 26:08.500]  Получается так, что у нас Винеровский процесс появился как комбинация двух теорем Колмогорова, и вторая нужна для того, чтобы траектории стали непрывными, вот у нас какой итог.
[26:08.900 --> 26:21.900]  Так, теперь, но это я рассказываю на самом деле некоторые дополнительные вещи, которые в принципе полезно представлять, а собственно, как всегда говорили Колмогоров,
[26:21.900 --> 26:32.900]  что студентам не важно, что вы рассказываете, им важно как полагается на билеты отвечать, значит, так вот, на билет тут полагается отвечать так,
[26:33.300 --> 26:43.300]  что должно быть, так сказать, определение Винеровского процесса, ну и объяснение, как он получается из двух теорем Колмогорова, которые, обратите внимание, у нас без доказательств,
[26:43.300 --> 26:53.300]  у нас обе эти теорем Колмогорова, они без доказательств. Ну, почему они у нас без доказательств? Ну, потому что, если еще их доказывать, то это будет какая-то сплошная теория меры,
[26:53.700 --> 27:07.700]  случайные процессы, поэтому, в общем, где-то нужно остановиться в теории меры, чтобы, ну, хоть какое-то место, так сказать, каким-то, так сказать, статистическим понятиям дать.
[27:08.100 --> 27:25.100]  Так, теперь, значит, вот некоторые свойства, некоторые свойства, это у нас все без доказательства, значит, Винеровского процесса,
[27:25.500 --> 27:43.500]  значит, ну, свойства, значит, первое свойство траектории, на самом деле, Гельдеровы, значит, почти всякая, почти всякая траектория,
[27:43.900 --> 28:10.900]  значит, почти всякая траектория Гельдерова, порядка альфа больше одной второй, значит, это вот, что значит, это значит, что w от t плюс h от омега,
[28:11.300 --> 28:27.300]  минус w от t оценивается, ну, с некоторой константой, зависящей от омега, конечно, и от альфа, на, значит, a модуль h в степени альфа.
[28:27.700 --> 28:29.700]  Что?
[28:33.700 --> 28:45.700]  Можно, чтобы множество этих омега было фиксировано и обслуживало все альфы, ну, которые меньше одной второй.
[28:46.100 --> 29:02.100]  Ну, вы спросите, почему, почему такая странная избирательность, а почему исключать, ну, значит, во-первых, это видно, что это лучше, чем, видно, что это лучше, чем просто непрывность, правда,
[29:02.500 --> 29:10.500]  то есть, это такая вот, такая еще количественная непрывность, так, ну, а, кстати, откуда это берется?
[29:10.500 --> 29:15.500]  Ну, это можно усмотреть, на самом деле, из доказательства теория Макалмогорова, которого у вас, у нас не было,
[29:16.500 --> 29:25.500]  потому что в действительности его доказательство непрывности дает вовсе не непррывность, а дает Гельдеровасть, вот, собственно, откуда это берется.
[29:25.900 --> 29:39.900]  Теперь спрашивается, почему, почему такое странное, ну, ладно бы еще, ладно бы еще альфа не было бы единицей, ну, это мы сейчас увидим, почему альфа точно не единицы, так,
[29:40.300 --> 29:54.300]  ну, почему, можно было бы думать, ну, годятся все альфы меньше единиц, так, вот, почему, значит, вот давайте я сразу напишу свойства два,
[29:54.700 --> 30:08.700]  а почти, наверное, траектории, траектории не имеют точек дифференцируемости,
[30:09.100 --> 30:25.100]  так, ну, из этого видно, что не годится альфа равно единицы, потому что если бы годилась альфа равно единицы, то траектории были бы Липшицевы,
[30:25.100 --> 30:33.100]  а у Липшицевой функции есть обязательно точки дифференцируемости, их много, а тут ни одной нет точки дифференцируемости,
[30:33.500 --> 30:43.500]  смотрите, это второе утверждение сильнее, чем то, что в заданной точке нет дифференцируемости, вот то, что в заданной точке нет дифференцируемости,
[30:43.900 --> 30:59.900]  это понятно, потому что когда вы точку фиксируете, так, когда вы точку фиксируете и делите на корень, когда вы делите на корень из аж,
[31:00.300 --> 31:18.300]  то вот это имеет нормальное распределение, так, с дисперсией 1, так, поэтому если вы еще на один корень поделите, ну, как полагается для разностного отношения,
[31:18.700 --> 31:28.700]  то это пойдет в бесконечность, поэтому то, что в отдельной точке Т0 нет дифференцируемости, это очевидное из, вот, просто определение,
[31:28.700 --> 31:38.700]  но тут ведь не говорится, что в заданной точке почти, наверное, нет дифференцируемости, тут гораздо сильнее, что вы берете траекторию,
[31:39.100 --> 31:47.100]  а у нее нет точек, вообще ни одной, нет точек дифференцируемости, это довольно нетривиальная теорема, так, значит, но она объясняет,
[31:47.100 --> 32:00.100]  она объясняет, почему не годится тут α равно 1, но она не объясняет, почему α, скажем, две трети не годится, так, значит, ну, на самом деле,
[32:00.500 --> 32:14.500]  это следует, ну, вот, примерно из этого соотношения, но давайте это оставим в качестве задачи, значит, альфа больше одной второй не годится,
[32:14.900 --> 32:26.900]  так, значит, так что ответ точный, альфа, простите, альфа больше либо равна одной второй, ну, на самом деле, чтобы увидеть,
[32:26.900 --> 32:34.900]  что альфа больше либо равна одной второй не годится, достаточно, конечно, увидеть, что не годится альфа в точности равной одной второй, так,
[32:35.300 --> 32:45.300]  но вот почему альфа не годится в точности равной одной второй, это как раз предмет задачи, и это надо как-то вывести из того,
[32:45.300 --> 33:01.300]  что как раз тогда такое отношение получается, так, и оно 0,1, значит, гауссовское 0,1, так, ну, в общем, нужно понять,
[33:01.700 --> 33:13.700]  как это помогает, но на самом деле, на самом деле есть еще два последних факта, которые я приведу без доказательства тоже,
[33:13.700 --> 33:23.700]  как все в этом разделе, потому что все эти факты, они, ну, в принципе, обозримые у них доказательства, но это тогда
[33:24.100 --> 33:30.100]  какой-то такой удвоенный был бы курс, значит, если все это с доказательствами, а кроме того еще,
[33:30.100 --> 33:38.100]  что плохо, доказательства довольно еще и тяжелые, поэтому, вот еще и поэтому имеет смысл иногда их не приводить,
[33:38.500 --> 33:54.500]  значит, теорем, значит, вот что говорит, значит, с вероятностью, с вероятностью 1, вот такие вот
[33:54.900 --> 34:10.900]  предельные соотношения, техний предел при Т, стремящемся к нулю, wT от омега делить на корень из 2T,
[34:11.300 --> 34:29.300]  значит, логарифм, модуль логарифм T, так, равен единице, так, и аналогичная вещь, значит, верхний предел,
[34:29.300 --> 34:37.300]  когда T идет в бесконечность, но это когда мы уже не на отрезке процесс строим, а на всей, значит, полупрямой,
[34:37.700 --> 34:53.700]  ну, примерно то же самое на бесконечности, 2T на логарифм, логарифма T тоже равен единице,
[34:53.700 --> 35:03.700]  значит, смотрите, значит, смотрите, что получается из вот этого первого, из этого первого получается,
[35:04.100 --> 35:14.100]  из этого первого получается, что при фиксированном, при фиксированном T0 вот будет, значит,
[35:14.500 --> 35:22.500]  значит, ну и тоже h стремится к нулю, будет вот такая вещь,
[35:22.500 --> 35:50.900]  значит, 2h логарифм модуля логарифм h, значит, смотрите, видите, получается, что верхний предел,
[35:51.300 --> 36:01.300]  а, значит, приращение деленного на что-то, то есть получается, что модуль непрерывности,
[36:01.300 --> 36:09.300]  видите, вот такой, так, а это значит, ну это немного хуже, чем Гольдер, одна вторая, так,
[36:09.700 --> 36:23.700]  вот если бы не было вот этого логарифма, значит, вот это все называется закон повторного логарифма,
[36:23.700 --> 36:35.700]  значит, если бы не было этого повторного логарифма, то как раз бы получалась Гольдеровость одна вторая,
[36:36.100 --> 36:46.100]  но тут, видите, этот ухудшающий множитель, так, вот он немножко, значит, он, так сказать,
[36:46.100 --> 36:54.100]  немножко мешает вот одной второй, но задача, в этой задаче предполагается, конечно,
[36:54.100 --> 36:58.100]  доказать, что альфа одна вторая не годится, не пользуясь, конечно, этой теоремой,
[36:58.100 --> 37:04.100]  потому что из этой теоремы это очевидно, доказывать нечего, а в задаче предлагается
[37:04.100 --> 37:12.700]  голыми руками сделать, значит, так, значит, это все про Винеровский процесс, сейчас я что-то еще
[37:12.700 --> 37:25.500]  хотел про них сказать, а вот еще, значит, вот еще полезный процесс, значит, вот замечание,
[37:25.500 --> 37:42.400]  значит, похожий процесс, значит, В от Т от Омега, это WT от Омега минус Т на W1 от Омега,
[37:42.400 --> 37:59.240]  так, значит, эта штука называется Броуновский мост, ну вот в качестве упражнения найти его
[37:59.240 --> 38:11.240]  к вариацию надо, значит, чем интересен этот Броуновский мост у Винеровского процесса,
[38:11.240 --> 38:24.060]  в нуле фиксированное значение, так, ноль, а у Броуновского процесса, а еще и вот у этого
[38:24.060 --> 38:32.960]  Броуновского моста, а еще и в единицы, ну, разумеется, этот мост можно устраивать между нулем и какой
[38:32.960 --> 38:38.400]  угодно другой точкой, не обязательно единицы, это я для упрощения обозначения пишу единицы,
[38:38.400 --> 38:47.760]  тоже довольно интересный процесс, ну, который там тоже во всяких там физических и прикладных
[38:47.760 --> 38:55.520]  задачах возникает, так, теперь, ну, там в конспекте у меня еще какие-то есть примеры, но сейчас на них
[38:55.520 --> 39:03.080]  уже нет времени останавливаться, потому что надо энергично обсудить условные математические ожидания,
[39:03.080 --> 39:19.320]  так, значит, вот еще некая порция теории и меры, значит, зачем нужны эти условные математические
[39:19.320 --> 39:26.880]  ожидания, ну, потому что это необходимый бэкграунд для последнего куска курса, в котором речь идет
[39:26.880 --> 39:38.400]  про мартингалы и марковские процессы, значит, вот я уже перечислял небольшой список, так сказать,
[39:38.400 --> 39:45.160]  основных классов процессов, которые там встречаются у нас и в приложениях, он, конечно, не исчерпывает
[39:45.160 --> 39:51.640]  всех полезных процессов, но вот для такого короткого курса, ну, представляется разумным небольшой
[39:51.640 --> 40:00.360]  список иметь, но вот для того, чтобы вот эти два еще не обсуждавшихся класса, мартингалы и марковские
[40:00.360 --> 40:07.520]  обсудить, там нужно понятие условного математического ожидания, значит, ну, можно, конечно, объявить,
[40:07.520 --> 40:15.480]  что это якобы было в теории вероятностей, но это, я знаю, это лекторы так любят делать, говорить,
[40:15.480 --> 40:21.560]  что якобы в другом курсе что-то было, а зачастую в этих других курсах, наоборот, бывает так,
[40:21.560 --> 40:27.240]  что вот студент говорит, а вот у вас будет такой-то курс, и вот там про это расскажут, поэтому давайте,
[40:27.240 --> 40:38.120]  значит, кратко обсудим, значит, это понятие, значит, вот, значит, дано, значит, дано вероятностное,
[40:38.120 --> 40:48.840]  значит, основное вероятностное пространство, ну, как водится, сигма алгебра на нем видена, так,
[40:48.840 --> 41:02.080]  и, значит, вот появилась под сигма алгебра, значит, под сигма алгебра в b, так, значит,
[41:02.080 --> 41:16.960]  значит, определение, значит, определение, значит, пусть, пусть, значит, кси интегрируемая случайная величина, так,
[41:16.960 --> 41:30.320]  значит, условное, условное, значит, смотрите, вот это условное математическое ожидание, немножко длинный термин,
[41:31.120 --> 41:45.600]  поэтому чтобы на доске было короче написано, ну и драгоценного мела, чтобы меньше тратилось, будем это называть условное среднее, так,
[41:45.600 --> 42:06.720]  в английской литературе для математического ожидания используются слова expectation, ну и тогда здесь, значит, появляется conditional expectation,
[42:06.800 --> 42:21.760]  там нет этой добавки mathematical expectation, просто expectation, так, ну expectation это в английском разные, имеют значение, значит, вот ожидания, надежды,
[42:22.480 --> 42:37.360]  значит, вот, например, там роман классика, значит, большие надежды, он great expectations, но там вовсе не о математических ожиданиях идет речь, так,
[42:37.360 --> 42:51.760]  значит, условное среднее, значит, есть, ну или, значит, еще другое обозначение, вот такое,
[42:51.760 --> 43:15.200]  ну оно вот будет видно, что иногда вот это удобное, значит, есть, что-что, кси интегрируемая случайная величина, ну вот можно написать так,
[43:15.200 --> 43:28.560]  кси лежит в L1P, вот так, значит, смотрите, значит, кто ее, значит, какие у нее great expectations, значит, у нее, вот, что это такое,
[43:28.560 --> 43:39.920]  это A измеримое, A измеримое интегрируемое случайная величина, для которой,
[43:39.920 --> 44:03.280]  интеграл, вот это кси dP равен, значит, интегралу это, ну вот с этой вот случайной величиной,
[44:03.280 --> 44:18.640]  для всех ограниченных A измеримых, A измеримых это, ну понятно, что это равносильно, вот чему, что интеграл по каждому множеству из этой сигма-алгебры
[44:18.640 --> 44:33.520]  равен интегралу вот от этой случайной величины, значит, для всех A из вот этой под сигма-алгебры, так,
[44:33.520 --> 44:49.360]  значит, а почему такая есть, значит, можно двумя способами это объяснить, а, значит, если, если кси лежит в L2, то,
[44:49.360 --> 45:05.440]  вот эта штука, это ортогональная проекция, проекция кси на подпространство, на подпространство кси,
[45:05.440 --> 45:27.040]  вот эта штука, это ортогональная проекция, проекция кси на подпространство L2A, порожденное A измеримыми.
[45:35.440 --> 45:51.760]  А, значит, ну, кстати, я сказал, что они равносильны, а почему они равносильны, ну, потому что, ну понятно, что это частный случай этого, когда к индикатору применяется, так,
[45:51.760 --> 46:06.880]  но если вот это верно для всех, если это верно для всех A, то значит, что это верно для всех индикаторов, так, ну, значит, это верно для линейных комбинаций индикаторов, так,
[46:06.880 --> 46:21.440]  а всякая ограниченная A измеримая функция равномерно приближается конечными линейными комбинациями индикаторов, поэтому получаем, что верные для всех ограниченных.
[46:21.440 --> 46:31.760]  А почему тут ограничение на ограниченные? Ну, потому что это всего-навсего интегрируемо, поэтому ничего больше мы пока не можем подставлять,
[46:32.000 --> 46:47.200]  но вот если бы она была из L2, ну, что не обязательно, конечно, то сюда можно было бы в качестве это подставлять и другие из L2, так, это получилось бы скалярное произведение в L2,
[46:47.200 --> 46:56.160]  это выглядит как скалярное произведение, но оно не является скалярным произведением, потому что скалярное произведение, это, ну, что это такое, это обычно никто не помнит,
[46:56.320 --> 47:06.880]  но по крайней мере нужно помнить, что эта штука равноправная по отношению к двум, а тут получается, так сказать, неравноправная, если она не из L2, так, вот,
[47:06.880 --> 47:22.720]  но если она из L2, то можно взять замкнутое линейное подпространство во всем L2, вот, порожденное A измеримыми функциями, так, и на него спроектировать, это будет то, что надо.
[47:23.280 --> 47:45.600]  А в общем случае, значит, это можно, значит, общий случай, общий случай, значит, откуда берется, значит, вывод, вывод из случая, значит, ограниченного кси,
[47:46.480 --> 48:07.360]  как вывести, ну, для ограниченного делаем проекции в L2, так, а как дальше, когда кси не ограничено, ну, разбиваем, как водится, общую интегрируемую на положительно-отрицательной части и возимся с каждой в отдельности,
[48:07.360 --> 48:33.360]  значит, сводим к случаю, когда это неотрицательное, так, значит, рассматриваем, когда это неотрицательное, берем, берем, обрезаем по уровню n, так, значит, когда обрезаем, эти стримятся,
[48:33.360 --> 48:53.360]  эти ограниченные стремятся к этому, ну, и устремляем n в бесконечности, ну, и оказывается, что у них есть предел, почему у них есть предел, по теореме, по теореме там, фату или беппелеви, потому что оказывается, что они возрастают,
[48:53.360 --> 49:09.360]  а интегралы у них ограничены, ну, из-за чего у них ограничены интегралы, это из-за того, что если сюда подставить единицу, то будет, ну, тут единица будет, интегралы у них единицы будут, ну, если у этого кси был интеграл единицы,
[49:09.360 --> 49:38.360]  но тут неважно, какой, я даже зря сказал единица, ни при чем тут, если подставить эту единицу, будет просто интеграл от кси, значит, интегралы от этих ограничены интегралом от кси, значит, вот, получится, что у этих, так, значит, смотрите, что получится при таком подходе.
[49:38.360 --> 49:53.360]  При таком подходе получится, что вот эти вот, ну, к какой-то штуке возрастают, вот к чему они возрастают, это мы и берем в качестве кси.
[49:53.360 --> 50:16.360]  Ну, а самый общий случай разложение на две компоненты, значит, другой вариант, если кто, у кого еще не выветрился прошлый семестр, значит, то другой вариант такой, значит, другой вариант, теорема, теорема Радона-Никодима.
[50:23.360 --> 50:50.360]  Значит, мера, мера Q на A задана такой формулой, значит, Q от A есть интеграл по A кси dp.
[50:50.360 --> 51:09.360]  Ну, это если, ну, опять, если кси не отрицательно, так, значит, получается, что есть такая мера, значит, эта мера, эта мера абсолютно непрерывна относительно P на A.
[51:09.360 --> 51:31.360]  Ну, из этого следует, из этого следует, что Q есть ρ умножить на P на A, так, где ρ, ρ, A измеримая функция, значит, это общая теорема Радона-Никодима,
[51:31.360 --> 51:49.360]  что если есть две меры на сигма-алгебре, и одна зануляется на нулях другой, но это и значит, что абсолютно непрерывна, значит, зануляется на ее нулях, то та, которая зануляется на нулях, есть основная умножить на некую плотность Радона-Никодима.
[51:49.360 --> 51:59.360]  Ну, вот это очевидно и есть, тогда очевидно, что вот это ρ, оно и есть нужная плотность.
[51:59.360 --> 52:12.360]  Но эта теорема не очень элементарная, обычно лекторы, даже которые включают ее в курс, предпочитают не ввязываться в доказательства.
[52:12.360 --> 52:24.360]  Значит, если ее аккуратно доказывать, то, ну, лекцию ухлопаешь на это дело, а когда лекции там всего десяток с небольшим, то бывает жалко на единичную теорему ухлопать целую лекцию.
[52:24.360 --> 52:31.360]  Но теорема, конечно, принадлежит именитым мужам, и выдающаяся, конечно, теорема.
[52:31.360 --> 52:45.360]  Значит, Радон – это австрийский математик, ну, выдающийся, так сказать, не только по этой теореме, реально выдающийся математик, выдающийся аналитик.
[52:45.360 --> 52:56.360]  Ну, вот можно сказать, что это, так сказать, отец-основатель темографии.
[52:56.360 --> 53:09.360]  Вот за, так сказать, технологическое воплощение его математических идей в начале 20 века, в середине 20 века, вот люди получили Нобелевскую премию за томограф.
[53:09.360 --> 53:21.360]  Ну и другими он достижениями знаменит. Ну, вот эта теорема тоже, так сказать, ну, вот тут не поймешь, что важнее, томография или эта теорема, ну, кто его знает.
[53:21.360 --> 53:38.360]  Значит, Никодим – это был такой чешско-польский математик, ну, он вроде как формально польский, но, кажется, ему это очень не нравилось, что он польский, и он себя как чешским выставлял.
[53:38.360 --> 53:51.360]  Ну, естественно, как это часто бывает с теми, кто очень заботится, так сказать, о таких аспектах, он, конечно, все это исполнял не в Польше, не в Чехословакии, а в США, конечно.
[53:51.360 --> 54:08.360]  Но этот вопрос его даже и там занимал, настолько занимал, что он даже в конце жизни ввел в написание своей фамилии диакритический знак,
[54:08.360 --> 54:16.360]  которого не было в его вот этих знаменитых статьях тридцатых годов, в частности, где теорема Родон Никодима появилась.
[54:16.360 --> 54:28.360]  Значит, он вот в это имя Никодим, он ввел, значит, диакритический знак, по-видимому с целью показать, что он не поляк, потому что у поляков таких диакритических знаков нет.
[54:28.360 --> 54:38.360]  И даже вот на его памятники на кладбище США даже вот фамилия выведена с этим диакритическим знаком.
[54:38.360 --> 54:45.360]  Ну, я точно не знаю, когда он это сделал, ну, очень похоже, что когда эмигрировал в США.
[54:45.360 --> 54:52.360]  Но эта теорема появилась еще до того, значит, она появилась вот абстрактная теорема.
[54:52.360 --> 55:03.360]  Значит, Родон это придумал для обычной меры Либега, ну, или там для иных мер на РН, а у Никодима в абстрактной ситуации.
[55:03.360 --> 55:13.360]  В тридцатом году он это придумал. Но прославил его, конечно же, Колмогоров.
[55:13.360 --> 55:17.360]  Значит, Колмогоров его прославил так.
[55:17.360 --> 55:27.360]  Колмогоров в это время, когда вышел журнал со статьей Никодима, Колмогоров находился в Гетингене.
[55:27.360 --> 55:31.360]  Ну, тогда еще можно было выезжать за границу.
[55:31.360 --> 55:35.360]  Ну, у нас какие-то такие странные периоды бывают.
[55:35.360 --> 55:38.360]  Можно, потом нельзя, потом опять можно.
[55:38.360 --> 55:41.360]  Ну, как-то и не очень понятно, когда что будет.
[55:41.360 --> 55:45.360]  Ну, вот Колмогоров попал как раз в такой небольшой кусочек, когда можно было.
[55:45.360 --> 55:47.360]  И находился в Гетингене.
[55:47.360 --> 55:56.360]  И, значит, в библиотеке там лежали на полках, ну, там у них раньше такой обычай был,
[55:56.360 --> 56:00.360]  только что вышедшие журналы на полках выставлять.
[56:00.360 --> 56:05.360]  Потом этот обычай долго продолжался, ну, больше ста лет.
[56:05.360 --> 56:10.360]  Но примерно лет десять назад он почти исчез.
[56:10.360 --> 56:14.360]  Вот я долгие годы в Германии наблюдал этот обычай в библиотеках,
[56:14.360 --> 56:18.360]  а потом, когда все перешло, так сказать, в онлайн, он, значит, этот обычай исчез.
[56:18.360 --> 56:21.360]  И там, так сказать, полки уже стояли пустыми.
[56:21.360 --> 56:24.360]  Но во времена Колмогорова на них вот стояли эти вышедшие журналы.
[56:24.360 --> 56:30.360]  Ну, и Колмогоров в этой библиотеке полистал этот журнал и наткнулся на теорему Никодима.
[56:30.360 --> 56:32.360]  Она его заинтересовала.
[56:32.360 --> 56:37.360]  А сам он в этот момент мыслями был со своей выдающейся статьей
[56:37.360 --> 56:43.360]  об основаниях теории вероятности, которая его, так сказать, прославила
[56:43.360 --> 56:47.360]  и действительно сделала отцом-основателем современной теории вероятности.
[56:47.360 --> 56:58.360]  И по этой теории вероятности он подрядился писать монографию в издательстве Шпрингер.
[56:58.360 --> 57:03.360]  Ну, зачем ему нужно было писать монографию в издательстве Шпрингер?
[57:03.360 --> 57:10.360]  Дело в том, что они с Александровым на двоих незадолго до того приобрели в Подмосковье,
[57:10.360 --> 57:13.360]  в поселке Комаровка, приобрели дачный дом.
[57:13.360 --> 57:18.360]  И у него прохудилась крыша, и надо было эту крышу чинить.
[57:18.360 --> 57:24.360]  Ну, вот сейчас я иногда бываю в этом мемориальном доме.
[57:24.360 --> 57:30.360]  Сейчас там нынешний владелец Ширяев его, так сказать, в идеальном порядке держит.
[57:30.360 --> 57:34.360]  Но тогда он был такой изрядной развалюхой, зверявой крышей.
[57:34.360 --> 57:39.360]  Ну и вот надо было, так сказать, как-то снискать средства, чтобы починить.
[57:39.360 --> 57:45.360]  Ну и Колмогорову кто-то присоветовал, вот, напиши монографию в издательстве Шпрингер,
[57:45.360 --> 57:47.360]  прилично заплатит, и крышу можно починить.
[57:47.360 --> 57:49.360]  Ну, Колмогоров за эту идею хватился.
[57:49.360 --> 57:55.360]  Но каково ему было, когда он рекомендовал по пять страниц статьи писать, а тут монография.
[57:55.360 --> 58:00.360]  И вот он написал страниц 70, а по договору там, кажется, больше надо было.
[58:00.360 --> 58:03.360]  Я уж точно деталей не помню, но не хватало ему.
[58:03.360 --> 58:07.360]  В общем, не пять страниц ему надо было написать для этой монографии, какой-то там объем.
[58:07.360 --> 58:15.360]  И вот он уже все написал, выдающаяся работа, которая и сейчас считается одним из фундаментальных застяжений века.
[58:15.360 --> 58:17.360]  А ему страниц не хватает.
[58:17.360 --> 58:22.360]  И вот он увидел эту статью Никодима и его осенило.
[58:22.360 --> 58:26.360]  Вот что у него сейчас будет. Условное математическое ожидание.
[58:26.360 --> 58:28.360]  Это то, что мы сейчас с вами обсуждаем.
[58:28.360 --> 58:37.360]  И вот это Колмогоров, как раз вот этот второй способ с помощью теоремы Никодима, он туда сразу и ухнул в свою книгу.
[58:37.360 --> 58:47.360]  Значит, книга вышла, крыша была починена, и потом еще полвека они с Александровым на этой даче жили,
[58:47.360 --> 58:50.360]  на лыжах катались, ученики на лыжах катались.
[58:50.360 --> 58:54.360]  Так что теорема оказалась очень-таки прикладная.
[58:54.360 --> 58:58.360]  Это Родон Никодима во всех отношениях.
[58:58.360 --> 59:09.360]  Вот у нас появилось это условное математическое ожидание.
[59:09.360 --> 59:13.360]  Что про него можно хорошего еще сказать, кроме того, что оно есть?
[59:13.360 --> 59:35.360]  Во-первых, понятно, что если кси сама аизмерима, то ничего не нужно, то условное мат ожидания будет сама кси.
[59:35.360 --> 59:51.360]  Дальше, значит, если взять это равно единице, то получаем, что мат ожидания от условного мат ожидания совпадает просто с мат ожидания.
[59:51.360 --> 01:00:05.360]  Дальше, естественно, из этого первого получается, что от константа, конечно, константа будет.
[01:00:05.360 --> 01:00:10.360]  Что еще можно сказать хорошего?
[01:00:10.360 --> 01:00:30.360]  Еще можно сказать следующее, что если кси1 больше либо равно кси2, то условное мат ожидания почти всюду,
[01:00:30.360 --> 01:00:36.360]  если вот эти вот почти всюду, то и эти будут почти всюду.
[01:00:36.360 --> 01:00:45.360]  Но это очевидно из построения, потому что мы так строили, что у неотрицательных неотрицательные условные мат ожидания.
[01:00:45.360 --> 01:00:51.360]  Ну и у нас линейная эта процедура, поэтому это свойство очевидно.
[01:00:51.360 --> 01:01:06.360]  В частности, можно было даже так сказать, что если кси неотрицательно почти всюду, то условное мат ожидания тоже почти всюду неотрицательно.
[01:01:06.360 --> 01:01:10.360]  Значит, это все, так сказать, такие довольно банальные вещи.
[01:01:10.360 --> 01:01:17.360]  Теперь вот полезное предложение, давайте его даже отдельное оформим, это нам понадобится.
[01:01:17.360 --> 01:01:29.360]  Все эти банальные наблюдения, конечно, тоже можно было бы назвать каким-нибудь там леммами, но вот реально полезная вещь, вот какая.
[01:01:29.360 --> 01:01:49.360]  Если это ограниченное, а измеримое, то условное мат ожидания,
[01:01:49.360 --> 01:02:01.360]  то ее можно выносить из подусловного мат ожидания.
[01:02:01.360 --> 01:02:04.360]  Ну как водится, все такие равенства почти всюду.
[01:02:04.360 --> 01:02:06.360]  Ну почему почти всюду?
[01:02:06.360 --> 01:02:12.360]  Ну потому что случайная величина, она у нас определяется своим действием через интегралы.
[01:02:12.360 --> 01:02:18.360]  Поэтому если ее заменить на множество меры 0, то интеграл этих манипуляций не заметен.
[01:02:18.360 --> 01:02:28.360]  Но обратите внимание, заменять на множество меры 0 тут нельзя бы как, потому что условное мат ожидания должно быть а измеримым.
[01:02:28.360 --> 01:02:35.360]  Поэтому если мы где-то его подменяем на множество меры 0, то само это множество должно быть из а, а не а бы какое меры 0.
[01:02:35.360 --> 01:02:44.360]  Ну давайте это докажем, доказательства.
[01:02:44.360 --> 01:02:55.360]  Это предложение, доказательства.
[01:02:55.360 --> 01:02:58.360]  Ну смотрите, что нужно доказывать.
[01:02:58.360 --> 01:03:06.360]  Нужно сравнивать интегралы по множеству из а.
[01:03:06.360 --> 01:03:21.360]  Спрашивается, верно ли, что интеграл вот от этого равен интегралу вот от этого.
[01:03:21.360 --> 01:03:29.360]  Вот вопрос еще такой, будет ли такое равенство.
[01:03:29.360 --> 01:03:34.360]  Ну давайте посмотрим, что это за равенство.
[01:03:34.360 --> 01:03:36.360]  Смотрите, что тут слева стоит.
[01:03:36.360 --> 01:03:47.360]  Слева стоит интеграл по омега от индикатора а умножить на условное мат ожидание от это кси dp.
[01:03:47.360 --> 01:03:53.360]  Вот кто такой слева стоит.
[01:03:53.360 --> 01:04:08.360]  Ну и по определению, это есть интеграл по омега от индикатора а умножить на вот на это дело.
[01:04:08.360 --> 01:04:11.360]  Значит здесь я dp забыл.
[01:04:11.360 --> 01:04:16.360]  Значит это тот, кто стоял слева.
[01:04:16.360 --> 01:04:20.360]  А справа, а справа, кто стоит.
[01:04:20.360 --> 01:04:35.360]  А справа стоит интеграл по омега от единицы на а умножить на это и умножить на вот на это дело.
[01:04:35.360 --> 01:04:38.360]  Вот кто стоит.
[01:04:38.360 --> 01:04:44.360]  Но вот эта штука, вот эта штука, она аизмерима.
[01:04:44.360 --> 01:04:48.360]  Значит вот это произведение, оно аизмеримо.
[01:04:48.360 --> 01:04:56.360]  А поэтому, поэтому это это же будет интеграл.
[01:04:56.360 --> 01:04:59.360]  То есть то же самое.
[01:04:59.360 --> 01:05:01.360]  То же самое получается.
[01:05:01.360 --> 01:05:11.360]  Так что видите, вот доказали путем сравнения интегралов по множеством из а.
[01:05:11.360 --> 01:05:24.360]  Теперь давайте какой-нибудь пример рассмотрим простой.
[01:05:24.360 --> 01:05:27.360]  Давайте рассмотрим простой пример вычисления.
[01:05:27.360 --> 01:05:30.360]  Вообще это страшно важная вещь.
[01:05:30.360 --> 01:05:37.360]  Вот эти условные мат ожидания в теории вероятности, в теории случайных процессов, в статистике и в теоретической прикладной.
[01:05:37.360 --> 01:05:40.360]  Это все страшно важная вещь.
[01:05:40.360 --> 01:05:56.360]  Так что Калмогорову воистине повезло, что он нуждался в ремонте дачи и наткнулся на эту статью Никодима в библиотеке немецкого университета.
[01:05:56.360 --> 01:06:09.360]  Почти никогда эти условные маты... вот это такая странная вещь.
[01:06:09.360 --> 01:06:11.360]  Почти никогда нельзя вычислить.
[01:06:11.360 --> 01:06:14.360]  Вот такой вроде важный объект.
[01:06:14.360 --> 01:06:21.360]  Но это не тот неуловимый Джо, которого никто не может поймать.
[01:06:21.360 --> 01:06:26.360]  Это реальная вещь, которая нужна и применяется.
[01:06:26.360 --> 01:06:28.360]  Давайте посмотрим.
[01:06:28.360 --> 01:06:33.360]  Пусть Омега разбита на...
[01:06:33.360 --> 01:06:35.360]  Вот давайте так.
[01:06:35.360 --> 01:06:38.360]  А1...
[01:06:38.360 --> 01:06:42.360]  Аn дизюнктные.
[01:06:42.360 --> 01:06:45.360]  Дизюнктные множества.
[01:06:45.360 --> 01:06:47.360]  Вот это сигма алгебра.
[01:06:47.360 --> 01:06:50.360]  Разбита на конечное число кусков.
[01:06:50.360 --> 01:06:59.360]  Аa это порожденное вот этими множествами.
[01:06:59.360 --> 01:07:01.360]  А сигма алгебра...
[01:07:01.360 --> 01:07:03.360]  Но она очень просто устроена.
[01:07:03.360 --> 01:07:09.360]  Когда у вас пространство разбито на несколько кусков дизюнктных,
[01:07:09.360 --> 01:07:18.360]  вот такая вот картинка.
[01:07:18.360 --> 01:07:22.360]  То как устроены множества из сигма алгебры?
[01:07:22.360 --> 01:07:25.360]  Это пустое множество.
[01:07:25.360 --> 01:07:31.360]  И какие-то конечные поднаборы вот этих.
[01:07:31.360 --> 01:07:35.360]  Можно брать их по отдельности парами, тройками.
[01:07:35.360 --> 01:07:41.360]  В общем, всякие такие наборы, ну и плюс еще пустое, будут образовывать сигма алгебру.
[01:07:41.360 --> 01:07:46.360]  Ну как очевидно, это сигма алгебра на конечный просто будет.
[01:07:46.360 --> 01:07:50.360]  И как устроено...
[01:07:50.360 --> 01:08:00.360]  Давайте посмотрим, как устроено условное мат ожидания интегрируемой функции
[01:08:00.360 --> 01:08:04.360]  вот для такой очень простенькой сигма алгебры.
[01:08:04.360 --> 01:08:08.360]  Значит, оно устроено так.
[01:08:08.360 --> 01:08:20.360]  Значит, эта сумма будет вот чего.
[01:08:20.360 --> 01:08:31.360]  Нужно взять интегралы по этим множествам.
[01:08:31.360 --> 01:08:43.360]  А давайте я еще только забыл сказать, пусть эти множества еще положительные меры.
[01:08:43.360 --> 01:08:45.360]  Вот это я еще забыл сказать.
[01:08:45.360 --> 01:08:57.360]  Значит, я про это вспомнил, когда стало нужно делить на них.
[01:08:57.360 --> 01:08:59.360]  Вот, значит, вот какой ответ.
[01:08:59.360 --> 01:09:09.360]  Смотрите, это будет такая ступенчатая функция, которая постоянно на каждом вот этом кусочке.
[01:09:09.360 --> 01:09:14.360]  И чему оно равно, какое значение этой функции на кусочке.
[01:09:14.360 --> 01:09:18.360]  Это среднее значение ее по этому кусочку.
[01:09:18.360 --> 01:09:24.360]  Среднее значение это интеграл делить на меру кусочка.
[01:09:24.360 --> 01:09:33.360]  Значит, как устроены функции измеримые относительно такой очень простенькой сигма алгебры.
[01:09:33.360 --> 01:09:36.360]  Это и есть ступенчатые функции.
[01:09:36.360 --> 01:09:40.360]  Измеримые функции это те, которые на этих кусочках постоянные.
[01:09:40.360 --> 01:09:44.360]  То есть получается, что конечномерное пространство.
[01:09:44.360 --> 01:09:48.360]  Это конечномерное пространство таких вот ступенек на этих множествах.
[01:09:48.360 --> 01:09:57.360]  И то, что здесь написано, это выглядит как артагональная проекция на конечномерное подпространство.
[01:09:57.360 --> 01:10:05.360]  Если бы кси была из s2, то это и было бы артагональной проекции на это конечномерное подпространство ступенек.
[01:10:05.360 --> 01:10:13.360]  Но в общем случае это не скалярное произведение интеграл, но формула в общем случае такая же.
[01:10:14.360 --> 01:10:18.360]  Ну давайте проверим, почему это верно.
[01:10:18.360 --> 01:10:20.360]  Давайте проверим, почему это верно.
[01:10:20.360 --> 01:10:34.360]  Ну достаточно, поскольку у нас линейно, поскольку у нас условная мат ожидания линейна,
[01:10:34.360 --> 01:10:45.360]  то достаточно рассмотреть вместо кси умножить на индикатор.
[01:10:45.360 --> 01:10:47.360]  Ну скажем первого множества.
[01:10:47.360 --> 01:10:49.360]  Ну для остальных аналогично.
[01:10:49.360 --> 01:10:54.360]  Значит, эта функция слагается из суммы.
[01:10:54.360 --> 01:10:57.360]  Она умножить на индикаторы вот этих.
[01:10:57.360 --> 01:11:00.360]  Потому что сумма этих индикаторов единица.
[01:11:00.360 --> 01:11:10.360]  Значит, если мы для каждой такой проверим, то ответ будет перенесенный на общий случай.
[01:11:10.360 --> 01:11:18.360]  Значит, смотрите, в этом случае получается следующее.
[01:11:18.360 --> 01:11:24.360]  А условная, ну вот это что нам эта формула дает?
[01:11:24.360 --> 01:11:30.360]  Значит, эта формула нам говорит, ну это еще подлежит проверке.
[01:11:30.360 --> 01:11:39.360]  Но если это так, то смотрите, в этой формуле исчезли все интегралы, кроме одного.
[01:11:39.360 --> 01:11:46.360]  Потому что новая функция, она вне всех ноль, значит все интегралы исчезают кроме первого.
[01:11:46.360 --> 01:11:50.360]  Поэтому получается, что вот такой должен быть ответ.
[01:11:50.360 --> 01:12:02.360]  Интеграл по a1 делить на меру a1 и умножить на индикатор a1.
[01:12:02.360 --> 01:12:05.360]  Вот какой должен быть ответ.
[01:12:05.360 --> 01:12:08.360]  Значит, если эта формула правильная.
[01:12:08.360 --> 01:12:12.360]  Ну и наоборот, если ответ такой, то значит формула правильная.
[01:12:12.360 --> 01:12:14.360]  Значит, ну давайте проверять.
[01:12:14.360 --> 01:12:21.360]  То есть видите, это я еще пока, так сказать, со знаком вопрос поставил, верно ли.
[01:12:21.360 --> 01:12:28.360]  Значит, правая часть определена, а левая живет в какой-то своей внутренней жизни.
[01:12:28.360 --> 01:12:32.360]  И вот почему она совпадает с правой.
[01:12:32.360 --> 01:12:38.360]  Значит, ну давайте проверять.
[01:12:38.360 --> 01:12:46.360]  Значит, смотрим, что тут полагается смотреть.
[01:12:46.360 --> 01:13:04.360]  Значит, смотрим на интегралы обеих частей по множествам a из сигма алгебры.
[01:13:04.360 --> 01:13:10.360]  Но эти множества, это конечные объединения ожитых.
[01:13:10.360 --> 01:13:28.360]  Поэтому достаточно смотреть на интегралы по ожитым, ну по отдельным вот этим ожитым.
[01:13:28.360 --> 01:13:52.360]  Значит, у левой части, интеграл левой части.
[01:13:52.360 --> 01:13:55.360]  Значит, интеграл левой части, что это такое?
[01:13:55.360 --> 01:13:59.360]  Это просто интеграл по ожитому, ну вот этого вот.
[01:13:59.360 --> 01:14:04.360]  Xi умножить на индикатор a1.
[01:14:04.360 --> 01:14:09.360]  Значит, правой части.
[01:14:09.360 --> 01:14:11.360]  Значит, правая часть.
[01:14:11.360 --> 01:14:13.360]  Значит, смотрите, что дает правая часть.
[01:14:13.360 --> 01:14:26.360]  Ну это вообще число, оно выносится при интегрировании.
[01:14:26.360 --> 01:14:40.360]  А это интеграл, ну по ожитому, вот индикатора a1.
[01:14:40.360 --> 01:14:45.360]  Значит, чему это равно?
[01:14:45.360 --> 01:14:49.360]  Ожитое это какое-то из этих множеств.
[01:14:49.360 --> 01:14:52.360]  A1 это первое фиксированное.
[01:14:52.360 --> 01:15:08.360]  Значит, если ожитое, ну если Xi равно 1, то это просто будет,
[01:15:08.360 --> 01:15:13.360]  из всего этого останется интеграл вот этого.
[01:15:13.360 --> 01:15:16.360]  Потому что здесь будет просто мера ожитого,
[01:15:16.360 --> 01:15:20.360]  то есть мера ожитого равна a1 и сократится с этим.
[01:15:20.360 --> 01:15:23.360]  Это если Xi равно 1.
[01:15:23.360 --> 01:15:29.360]  А 0 будет если Xi не равно 1.
[01:15:29.360 --> 01:15:31.360]  Вот такой ответ получился.
[01:15:31.360 --> 01:15:35.360]  Значит, у правой части будет либо 0, либо этот интеграл.
[01:15:35.360 --> 01:15:39.360]  А у левой части, что будет?
[01:15:39.360 --> 01:15:48.360]  Ну опять, ну это будет как и левая часть.
[01:15:48.360 --> 01:15:51.360]  Потому что здесь то же самое.
[01:15:51.360 --> 01:15:54.360]  Если же не 1, то это 0.
[01:15:54.360 --> 01:15:59.360]  А если же 1, то это просто интеграл от Xi по a1.
[01:15:59.360 --> 01:16:07.360]  Так что вот прямая проверка показывает, что все так.
[01:16:07.360 --> 01:16:15.360]  Ну еще, если же пользоваться вот этой апелляцией к L2,
[01:16:15.360 --> 01:16:19.360]  то тут ничего и обосновывать не надо.
[01:16:19.360 --> 01:16:29.360]  Потому что смотрите, какой наглядный смысл этой формулы.
[01:16:29.360 --> 01:16:36.360]  Это как раз ортогональная проекция на конечномерное подпространство.
[01:16:36.360 --> 01:16:40.360]  Как устраивается ортогональная проекция на конечномерное подпространство?
[01:16:40.360 --> 01:16:44.360]  В нем берется базис ортонормированный.
[01:16:44.360 --> 01:16:47.360]  И как будет выглядеть ортогональная проекция?
[01:16:47.360 --> 01:16:53.360]  Нужно брать скалярные произведения с элементами этого базиса, ну и умножать на них и суммировать.
[01:16:53.360 --> 01:16:57.360]  Вот как будто бы мы просто по базису суммируем,
[01:16:57.360 --> 01:17:03.360]  но только суммируется не по базису всего пространства, а по базису этого подпространства.
[01:17:03.360 --> 01:17:08.360]  Но кто здесь в этом подпространстве, кто здесь базис?
[01:17:08.360 --> 01:17:13.360]  А вот эти индикаторы этих множеств ожитые, они попарно ортогональные.
[01:17:13.360 --> 01:17:19.360]  Чтобы они стали базисом, нужно еще на константы их умножить, пронормировать, тогда это будет базис.
[01:17:19.360 --> 01:17:27.360]  И тогда если пользоваться этой формулой ортогонального проектора, то в точности то, что у нас написано, и получится.
[01:17:27.360 --> 01:17:29.360]  Поэтому, в общем, ответ неудивительный.
[01:17:29.360 --> 01:17:37.360]  Ну, кстати, вот таким способом можно было, без вот этой проверки, таким способом можно было бы это обосновать.
[01:17:37.360 --> 01:17:45.360]  Так, теперь, сейчас, ну еще есть несколько минут, сейчас я гляну, что-то я еще собирался.
[01:17:53.360 --> 01:17:55.360]  Так, что-то я еще собирался.
[01:18:00.360 --> 01:18:03.360]  Значит, что-то я еще собирался сказать.
[01:18:03.360 --> 01:18:17.360]  А, вот, значит, полезное, сейчас у нас будут некие связанные с этими делами объекты, но это уже в следующий раз.
[01:18:17.360 --> 01:18:27.360]  Значит, мартингалы, ну и уже такая вот более, так сказать, вероятностная пойдет дискуссия.
[01:18:27.360 --> 01:18:30.360]  Но сейчас еще одно техническое неравенство.
[01:18:30.360 --> 01:18:32.360]  Значит, неравенство Янсона.
[01:18:35.360 --> 01:18:37.360]  Неравенство Янсона.
[01:18:39.360 --> 01:18:44.360]  Значит, давайте я, чтобы обозначения были как в конспекте.
[01:18:44.360 --> 01:18:52.360]  Значит, пусть В – выпуклая функция, значит, выпуклая функция на R.
[01:18:52.360 --> 01:18:59.360]  Кси – интегрируемая случайная величина.
[01:18:59.360 --> 01:19:09.360]  И еще дополнительно предполагается, что В от кси тоже интегрируемо.
[01:19:09.360 --> 01:19:11.360]  Тоже интегрируемо.
[01:19:14.360 --> 01:19:21.360]  Тогда верно вот такое вот неравенство.
[01:19:21.360 --> 01:19:48.360]  А В от, давайте так напишем, В от условного мат ожидания относительно А меньше либо равно, чем условное мат ожидания В от кси.
[01:19:48.360 --> 01:19:50.360]  Вот так.
[01:19:50.360 --> 01:19:52.360]  Значит, это почти всюду.
[01:19:52.360 --> 01:19:54.360]  Значит, это почти всюду.
[01:19:54.360 --> 01:20:00.360]  Значит, смотрите, обычная, обычный Янсон.
[01:20:00.360 --> 01:20:08.360]  Значит, обычный Янсон.
[01:20:08.360 --> 01:20:27.360]  Это условное мат ожидание, наоборот, обычное мат ожидание, сейчас, В от обычного мат ожидания меньше либо равно, чем мат ожидания от композиции.
[01:20:27.360 --> 01:20:29.360]  Это обычный Янсон.
[01:20:29.360 --> 01:20:33.360]  Видите, это неравенство для интегралов.
[01:20:33.360 --> 01:20:48.360]  Можно еще так, естественно, написать, что В от интеграла от кси оценивается через В от кси проинтегрированное.
[01:20:48.360 --> 01:20:54.360]  Это для чисел неравенства, для чисел и для интегралов.
[01:20:54.360 --> 01:20:57.360]  А тут не совсем так.
[01:20:57.360 --> 01:21:08.360]  Потому что, смотрите, сюда-то вы подставляете числа, ну, там, завище от Омега, вот эта функция, вы ее в В подставили.
[01:21:08.360 --> 01:21:18.360]  Но справа, справа, у вас уже получилось, ну, у вас в чистом виде функция получилась.
[01:21:18.360 --> 01:21:21.360]  Это, так сказать, не число завище.
[01:21:21.360 --> 01:21:31.360]  Ну, конечно, функция тоже есть число, завище от Омега, но это не так, что, так сказать, это число как бы другого сорта, чем в левой части.
[01:21:31.360 --> 01:21:42.360]  Поэтому так не очень банально, не очень банальным и очевидным кажется, как вот это связано с тем.
[01:21:42.360 --> 01:21:50.360]  Понятно, что вроде как вещи общие, но и там Янсон, и там Янсон, там ожидание, и здесь ожидание, и там выпукло, и здесь выпукло.
[01:21:50.360 --> 01:21:55.360]  Вроде ключевые слова те же, а как бы это доказать?
[01:21:55.360 --> 01:22:08.360]  Ну вот сейчас нам уже надо сделать перерыв, но, значит, способы доказательства такие, способы доказательства такие.
[01:22:08.360 --> 01:22:25.360]  Один способ, значит, посмотреть, вспомнить, как доказывается неравенство Янсона вот в этом виде, ну и, так сказать, как-то модифицировать рассуждение в этом случае.
[01:22:25.360 --> 01:22:32.360]  Это один способ. Другой способ.
[01:22:32.360 --> 01:22:43.360]  Вспомнить, что когда что-то доказывают для там какие-то неравенства общего вида для функций, то обычная технология такая,
[01:22:43.360 --> 01:22:57.360]  доказывают для простых функций с конечным числом значений, но потом там предельным переходом устраивают в общем случае.
[01:22:57.360 --> 01:23:09.360]  Это другой способ, но, значит, каждый раз мы будем утыкаться, что вот при чем тут почти всюду, там никаких почти всюду не было, а тут почти всюду.
[01:23:09.360 --> 01:23:14.360]  Это каждый раз будет, значит, некий предмет раздумий.
[01:23:14.360 --> 01:23:23.360]  Ну и, наконец, третий способ. Вот это я сейчас так на обум скажу и сделаю перерыв, чтобы не надо было его обосновывать, потому что я никогда таким способом не делал.
[01:23:23.360 --> 01:23:32.360]  Третий способ такой. Ну для того, чтобы доказать, что это верно, ну вообще-то вроде бы как надо что сделать?
[01:23:32.360 --> 01:23:39.360]  Просто-напросто проинтегрировать обе части по множеству из А.
[01:23:39.360 --> 01:23:48.360]  И если окажется, что после интегрирования обеих частей каждому множеству из А будет неравенство, ну значит все окей и есть.
[01:23:48.360 --> 01:24:02.360]  Но когда вы проинтегрируете, когда вы проинтегрируете по множеству, значит, А обе части, то здесь, ну здесь понятно, что получится.
[01:24:02.360 --> 01:24:12.360]  Вот эта часть, это будет просто интеграл, вот такой будет интеграл, если вы проинтегрировали.
[01:24:12.360 --> 01:24:21.360]  Вот будет вот такой интеграл. А здесь что получится? А здесь получится вот что.
[01:24:21.360 --> 01:24:33.360]  Интеграл, ну вот от этого дела получится интеграл. Вот смотрите какая вещь.
[01:24:33.360 --> 01:24:47.360]  Ну и вот вопрос, что с этим можно поделать? Там уже никаких условных мат ожиданий нет, ну и там некое число стоит.
[01:24:47.360 --> 01:24:57.360]  А здесь стоит вот такой интеграл. Но вот все упование, все упование, вот на это неравенство.
[01:24:57.360 --> 01:25:07.360]  Вот надо подумать, нельзя ли как-то грамотно, нельзя ли как-то грамотно вот то неравенство применить.
[01:25:07.360 --> 01:25:16.360]  Вот это надо подумать, можно ли его как-то применить.
[01:25:16.360 --> 01:25:22.360]  Но это такой способ сомнительный, поэтому я в этот момент лучше всего и останавливаюсь.
[01:25:22.360 --> 01:25:29.360]  Ну а в качестве задачи, ну вот как придумайте, как доказать этого Янсона.
[01:25:29.360 --> 01:25:34.360]  Так, все, значит тогда на этом пока закончим.
