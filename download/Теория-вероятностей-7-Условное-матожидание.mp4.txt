[00:00.000 --> 00:18.440]  Видно ли экран? Нормально ли видно? Да, видно. Спасибо. Так, значит, мы в прошлый раз не начали с
[00:18.440 --> 00:23.280]  вами условным от ожидания, но я так коротко сказал о том, об интуиции этого понятия,
[00:23.280 --> 00:27.720]  и сегодня мы с вами в общем про него начнём говорить. Так, тема сегодняшней лекции – это условное
[00:27.720 --> 00:41.520]  математическое ожидание. Ну, как я в прошлый раз пояснял, интуиция следующая – что мы хотим не
[00:41.520 --> 00:47.880]  просто найти среднее значение случайной величины, а понять, какое у него среднее в зависимости от
[00:47.880 --> 00:54.360]  тех или иных исходов. То есть простейшая такая интуиция – это то, что у нас есть какой-то случайный
[00:54.360 --> 01:01.720]  процесс, и у нас же есть некая история, то есть мы не в начальном моменте времени этого процесса
[01:01.720 --> 01:05.760]  находимся, а вот уже какая-то история прошла, и в зависимости от того, какая история, средний может
[01:05.760 --> 01:11.160]  быть разным. Вот, значит, как это дело формально определить? Ну, предположим, что у нас есть
[01:11.160 --> 01:15.240]  случайная величина, которая задана, как обычно, на комнату верентосного пространства, то есть
[01:15.240 --> 01:19.320]  есть верентосное пространство МегаФП, и есть случайная величина КСИ на нём.
[01:19.320 --> 01:28.360]  Вот представьте, что у вас информация, которую вы можете использовать,
[01:28.360 --> 01:36.920]  которую будет зависеть условно-математическое ожидание, она заключается в некоторой подсигмалгебре
[01:36.920 --> 01:41.960]  F, то есть вы внутри F выбираете некоторую сигмалгебру, которая в ней содержится.
[01:41.960 --> 01:52.440]  И мы хотим понять, что такое умоджедание КСИ при условии G. Давайте для удобства считать, что у КСИ
[01:52.440 --> 02:03.520]  конечное математическое ожидание. Вот, что тогда такое условное умоджедание КСИ при условии G?
[02:03.520 --> 02:10.400]  Это есть такая случайная величина, которая же измерима.
[02:14.920 --> 02:20.360]  То есть представьте себе, что в G у вас лежат события, в зависимости от которых вы мерите
[02:20.360 --> 02:27.600]  среднее случайное величина, и, соответственно, то или иное событие G произошло у вас то или иное
[02:28.080 --> 02:29.760]  Поэтому это случайная величина должна быть же измерима.
[02:29.760 --> 02:37.560]  И должно быть выполнено некоторое интегральное свойство, которое говорит о том, что это действительно
[02:37.560 --> 02:44.520]  среднее значение. Значит, это же измеримая случайная величина такая, что для любого события A из G
[02:44.520 --> 02:55.720]  мат ожидания КСИ умножить на индикатор A совпадает с мат ожиданием от условного мат ожидания КСИ при
[02:55.720 --> 03:13.160]  условии G на индикатора. То есть это понятное свойство. То есть чем оно заключается?
[03:13.160 --> 03:17.640]  Заключается в том, что если вы усредняете вашу случайную величину КСИ на любом событии из
[03:17.640 --> 03:22.040]  вашей сигма алгебры G, в которой содержится известная вам информация, то это все равно,
[03:22.160 --> 03:28.040]  что усреднить ваше среднее по этому событию. Поэтому это определение кажется вполне естественным.
[03:28.040 --> 03:36.360]  Давайте мы сейчас на каком-то примере увидим то, что это определение дает нужное нам условное
[03:36.360 --> 03:41.040]  математическое ожидание. А именно проще всего это понять, когда у вас сигма алгебры G порождена
[03:41.040 --> 03:59.800]  разбиением. Давайте разберем такой пример. Пусть G это наименьшее сигма алгебры,
[03:59.800 --> 04:05.640]  которая порождена каким-то разбиением. То есть у вас есть разбиение омега на не пересекающиеся
[04:05.640 --> 04:09.600]  подножество. Их может быть конечное количество, может быть счетное бесконечное количество,
[04:09.600 --> 04:17.120]  несуть важно. Давайте считать, что все эти множества из разбиения не тривиальные в том смысле,
[04:17.120 --> 04:28.800]  что вероятность каждого положительная. И вот пусть наша сигма алгебра G порождена разбиением.
[04:28.800 --> 04:34.080]  То есть это минимальная сигма алгебра, которая содержит все вот эти подножества 1, 2 и так далее.
[04:34.080 --> 04:42.480]  И вот мы хотим понять, что же такое условное мы ожидание G при условии G. Давайте подумаем,
[04:42.480 --> 04:51.880]  что нам подсказывает интуиция. Интуиция нам подсказывает, что когда мы думаем про условное
[04:51.880 --> 04:56.080]  математическое ожидание, G это известная нам информация. То есть на самом деле у нас есть
[04:56.080 --> 05:02.080]  эти элементарные подножества, из которых G состоит 1, 2 и так далее. И мы хотим на каждом из них
[05:02.080 --> 05:06.080]  усреднить. То есть при каждом из этих событий мы хотим по-своему посчитать средний. Понятно,
[05:06.080 --> 05:11.920]  что это средний, это будет просто мат ожидания кси умножить на индикатор Деитова. Если вы
[05:11.920 --> 05:23.520]  захотите посчитать среднее на множестве Деитова, вы получите такое. Но когда вы считаете условное
[05:23.520 --> 05:29.840]  мат ожидание, то вам еще нужно отнормировать. Потому что если вы просто посчитаете мат ожидания
[05:29.840 --> 05:35.320]  кси на индикатор Деитова, то оно будет сильно меньше по сравнению с вашим условным мат ожиданием
[05:35.320 --> 05:38.560]  из-за того, что вы не отнормировали на вероятность Деитова. То есть интуиция подсказывает,
[05:38.560 --> 05:47.600]  что на множестве Деитова условное мат ожидания должно быть равно вот чему. И давайте мы с вами
[05:47.600 --> 05:54.360]  докажем, что это действительно так. То есть докажем, что условное мат ожидания кси при условии G
[05:54.360 --> 06:06.920]  это вот такая штука на множестве Деита. То есть умножить на индикатор Деита. Но еще надо написать
[06:06.920 --> 06:17.640]  сумму по всем И. А можете, пожалуйста, объяснить еще? У нас есть какое условие? То есть если,
[06:17.640 --> 06:23.640]  например, до этого мы проходили условия, было понятно, что произошло какое-то событие. А здесь
[06:23.640 --> 06:29.200]  какое условие? Смотрите, мы хотим… Да, это очень хороший вопрос. Смотрите, в чем прикол. Здесь то же
[06:29.200 --> 06:36.040]  самое. Давайте зафиксируем вообще Деитое, Д1, например, и предположим, что оно наступило. И при
[06:36.040 --> 06:40.920]  этом условии посчитаем математическое ожидание. Потом зафиксируем Д2. Предположим, что оно наступило,
[06:40.920 --> 06:44.760]  и при этом условии посчитаем математическое ожидание. И при каждом из этих условий у нас
[06:44.760 --> 06:48.600]  будет получаться ровная тедра. Мат ожидания кси на индикатор Деита и подсказывает на вероятность
[06:48.600 --> 06:55.280]  Деита. Это будет значение условного мат ожидания на событии Деита. Значит, когда вы говорите про вот
[06:55.280 --> 07:00.080]  этот именно объект условного мат ожидания кси при условии Ж, вы подразумеваете, что вы одновременно
[07:00.080 --> 07:05.920]  смотрите на все возможные значения вашего условного мат ожидания при условии наступлений разных
[07:05.920 --> 07:10.320]  событий. То есть это, на самом деле, случайная величина. В зависимости от того, какое событие из
[07:10.320 --> 07:17.880]  Деитах наступило, у вас будет то или иное значение условного среднего. Понятно?
[07:17.880 --> 07:27.800]  Наверное, потом будет понятнее. Да, ну давайте вот какой-нибудь простой пример. Скажем,
[07:27.800 --> 07:37.680]  подбросили, бросаете вы кубик, на грани, к которому написано число от 1 до 6. И давайте
[07:37.840 --> 07:42.400]  рассмотрим два события. Одно событие, это то, что выпало нечетное число с либо единичкой либо
[07:42.400 --> 07:46.420]  тройкой либо пятеркой. Другое событие, это то, что выпало чётное число – либо двоикалиб, четверк
[07:46.420 --> 07:52.660]  либо шестерка. И, если вы будете считать среднее значение при условии первого события, при условии
[07:52.660 --> 07:57.160]  того что выпало нечетное число, вы получите 3. Теперь если вы будете считать среднее значение при
[07:57.160 --> 08:02.160]  условии того, что выпало чётное число, то получите 4. То есть у вас тем самым, у вас получается
[08:02.160 --> 08:08.280]  случайная величина, которая принимает два значения. 3 и 4. это ваша условная средняя. она
[08:08.280 --> 08:13.240]  принимает значение 3, если выпала нечётное число, и она принимает значение 4, если выпала нечётное число.
[08:13.240 --> 08:29.040]  а, то есть вот эти вот а и б это как раз и есть элементы g? d1, d2 вы имеете ввиду. да, это элементы g,
[08:29.040 --> 08:36.080]  конечно. это элементарные, ну как это сказать, это атомарные события g. это те события,
[08:36.080 --> 08:44.000]  которые g порождают. ну понятно. окей, давайте докажем, что действительно так, что это просто
[08:44.000 --> 08:51.880]  следует из нашего определения. ну, во-первых, уже измеримость. то есть мы хотим проверить,
[08:51.880 --> 08:56.920]  что значит, что мы хотим доказать это утверждение. на самом деле, условным от ожидания, это не то,
[08:56.920 --> 09:03.240]  чтобы какая-то одна конкретная величина. для пары случайная величина и сигма алгебры g,
[09:03.240 --> 09:09.640]  условных от ожидания много. вы, грубо говоря, какое-то одно значение можете поменять на
[09:09.640 --> 09:14.080]  элементарном исходе, вероятность которого равна нулю. и от этого случайная величина
[09:14.080 --> 09:17.760]  останется такой же. ну то есть, имеется ввиду, что есть класс эквивалентности условных от
[09:17.760 --> 09:23.400]  ожидания, который совпадает с вероятностью 1. и поэтому вот здесь, когда мы пишем равенство,
[09:23.560 --> 09:26.840]  когда мы пишем, что условно от ожидания равно чему-то, мы просто подразумеваем,
[09:26.840 --> 09:31.580]  что вот это представитель из класса эквивалентности всех условных от ожидания, да. так-то их вообще
[09:31.580 --> 09:36.120]  много. но я об этом чуть позже поговорю. то есть знак равенства между условным от ожидания и
[09:36.120 --> 09:40.160]  какой-то конкретной случайной величиной надо подразумевать как на самом деле принадлежность
[09:40.160 --> 09:46.880]  этой случайной величины классу эквивалентности всех условных математических ожиданий. то есть
[09:46.880 --> 09:50.440]  когда мы хотим проверить это равенство, мы на самом деле просто хотим проверить определение. то
[09:50.440 --> 09:53.520]  то, что вот то, что стоит в правой части равенства, подходит под определение
[09:53.520 --> 09:57.280]  в условном от ожидания. во-первых, мы хотим проверить g-измеримость, а во-вторых,
[09:57.280 --> 10:01.240]  мы хотим проверить вот это интегральное равенство, что для любого a и g
[10:01.240 --> 10:05.040]  среднее от xi умножительный индикатор раз вкладает со средним
[10:05.040 --> 10:11.160]  это условном от ожидания множество индикатора. но уже измеримость, во-первых.
[10:11.160 --> 10:15.000]  то есть, во-первых, почему вот эта вот штука, которая справа написана, сумма
[10:15.000 --> 10:20.760]  по всем и от ожидания кси умножительный индикатор даито, определительно п от даито,
[10:20.760 --> 10:23.760]  умножительный индикатор даито, это же измеримо.
[10:23.760 --> 10:30.200]  но это очевидно, просто из вида, это случайные величины.
[10:30.200 --> 10:37.440]  ну как это можно понять? ну во-первых, все индикаторы даито, конечно, измеримы,
[10:37.440 --> 10:40.920]  потому что это даито, которые мы взяли из нашей сигмалы.
[10:40.920 --> 10:47.640]  поэтому все индикаторы измеримы, то есть все эти идаиты же измеримы,
[10:47.640 --> 10:51.160]  и поэтому их линейная комбинация тоже же измерима.
[10:51.160 --> 10:59.800]  вот эти вот коэффициенты, просто числа, то есть, по сути, это какая-то линейная комбинация индикаторов,
[10:59.800 --> 11:05.040]  поэтому она тоже будет же измерима.
[11:05.240 --> 11:19.560]  понятно, что как конечная линейная комбинация измеримых функций является измеримой,
[11:19.560 --> 11:22.780]  так и отсчетная линейная комбинация тоже является измериваем, просто потому
[11:22.780 --> 11:24.640]  что мы знаем, что мы можем переходить к пределу.
[11:24.640 --> 11:28.800]  предел последовательности измеримых функций является измеримой функцией.
[11:28.800 --> 11:37.360]  Во-вторых, интегральное свойство, мы берем любое ASG и должны проверить это равенство,
[11:37.360 --> 11:41.160]  которое написано в определении условного математического ожидания. Но смотрите,
[11:41.160 --> 11:48.120]  что такое ASG? Можно ли в каком-то общем виде записать любое событие, которое ASG принадлежит?
[11:48.120 --> 11:56.000]  Значит, J – это сигнал Юра, порожденное конечным или счетным разбиением. Если мы берем любое
[11:56.000 --> 12:06.240]  множество ASG, то очевидно, что это есть просто объединение каких-то деитов. Если вы порождаете
[12:06.240 --> 12:12.680]  из разбиения сигма-алгебру, то любое множество сигма-алгебры – это просто объединение атомарных
[12:12.680 --> 12:21.160]  подмножеств. То есть, если А принадлежит J, то А равно объединению дезюнкному по всем и ину из
[12:21.160 --> 12:33.480]  какого-то и большого деитов, для некоторого и большого. Значит, тогда давайте сразу правую
[12:33.480 --> 12:41.120]  часть возьмем вот этого равенства, правую часть, и посмотрим, чему будет равно такое мат ожидания.
[12:41.120 --> 12:50.440]  То есть, мы ищем мат ожидания от условного мат ожидания x при условии g умножить на индикатор
[12:50.440 --> 12:52.920]  A. Так, сейчас, одну секундочку.
[13:20.440 --> 13:34.080]  Прошу прощения. Значит, давайте найдем вот это математическое ожидание, которое у нас в правой
[13:34.080 --> 13:38.200]  части интегрального равенства написано. То есть, подставим наше выражение вместо условного
[13:38.200 --> 13:47.640]  мат ожидания. Сумма по всем и, мат ожидания x на индикатор деитое, поделить на p от деитое на
[13:47.640 --> 13:58.840]  индикатор деитое и умножить на индикатор A. Ну, понятно, что, значит, еще раз, А – это объединение по
[13:58.840 --> 14:04.840]  какому-то множеству и большое деитов. Если вы индикатор деитое умножаете на индикатор А,
[14:04.840 --> 14:10.280]  у вас получается либо ноль, либо единица. Единица у вас получается в том и только в том случае.
[14:10.280 --> 14:14.360]  Значит, вот это произведение равно единице, а это только тогда, когда и маленькое принадлежит и
[14:14.360 --> 14:19.640]  большое. То есть, когда деитое – это под множество большое, иначе ноль. Поэтому, на самом деле,
[14:19.640 --> 14:30.040]  это мат ожидания суммы по всем и из и большого. Сумма по всем и из и большого. Мат ожидания x на
[14:30.040 --> 14:36.600]  индикатор деитое поделить на вероятность деитое и умножить на индикатор деитое.
[14:36.600 --> 14:46.360]  Ну вот, по линейности математического ожидания у вас что тут написано? У вас написано какие-то
[14:46.360 --> 14:51.000]  эти коэффициенты, которые умножаются на индикатор деитое. Если вы теперь мат ожидания внесете
[14:51.000 --> 14:57.400]  внутрь суммы, вы получите сумму по всем и из и большого. Мат ожидания x на индикатор деитое
[14:57.480 --> 15:03.820]  поделить на вероятность деитое и умножить на вероятность деитое. Вероятность деитое сократится,
[15:03.820 --> 15:13.320]  останется просто сумма по всем и из и большое. Мат ожидания x на индикатор деитое. Снова по
[15:13.320 --> 15:18.380]  линейности мат ожидания вы сумму можете внести внутрь и получите ровно мат ожидания x на индикатор
[15:18.380 --> 15:24.700]  а. Что и требовалось. Да, это в точности наша ровность из определения мат ожидания,
[15:24.700 --> 15:30.940]  значит все доказано. Есть ли какие-то вопросы? А мы столько раз индикатор деитое пишем,
[15:30.940 --> 15:40.140]  чтобы потом перейти к вероятности от мат ожидания. Или как? Мы тут три раза написали индикатор
[15:40.140 --> 15:47.660]  деитое в два раза подряд. Вы имеете в виду вот эти два индикатора? Да, да, да. Смотрите,
[15:47.660 --> 15:52.980]  здесь под мат ожиданием стоит индикатор. Да, то есть мат ожидания это произведение,
[15:52.980 --> 15:58.620]  x на индикатор деитое, это число. А следующий индикатор это случайная величина, то есть здесь
[15:58.620 --> 16:05.540]  написан коэффициент, вот эта дробь это число и она умножается на индикатор деитое. Здесь тоже самое.
[16:05.540 --> 16:26.260]  Окей? Ну да. А можно тогда уточнить? Условное мат ожидание, это значит функция? Да, причем важно,
[16:26.260 --> 16:30.580]  что это случайная величина измеримо относительно сигнал гибра, который стоит в условиях. Это не
[16:30.580 --> 16:36.740]  просто случайная величина, она мега fp, а некоторое сужение. Мы знаем, что все ее прообразы,
[16:36.740 --> 16:44.300]  все параллельские множества меж RG. Так, окей, теперь давайте вернемся к тому, что я говорил
[16:44.300 --> 16:50.420]  про существование единственности в условном мат ожидании. Да, оно существует и единственно,
[16:50.420 --> 16:57.140]  но единственно в том смысле, что с точностью почти наверно. То есть условных мат ожиданий, конечно,
[16:57.140 --> 17:02.100]  много. Это классы револидности, они все друг другу равны почти наверно. И когда мы пишем равенство,
[17:02.100 --> 17:10.900]  мы имеем в виду просто принадлежность одному и тому же классу револидности. Давайте это утвердим,
[17:10.900 --> 17:15.660]  но прежде чем это утвердить, мне понадобится теорема Радона-Никодима, которую, я так понимаю,
[17:15.660 --> 17:20.620]  вам Иван Геннер, к сожалению, не рассказал. Очень важная теорема из теории меры,
[17:20.620 --> 17:32.460]  но ее доказательство это, в общем, целый квест, и мы его опустим. Кому интересно,
[17:32.460 --> 17:39.100]  вы можете заглянуть в любую книгу по теории меры и посмотреть. Значит,
[17:39.100 --> 17:48.900]  Терема Радона-Никодима это как раз о том, что условным мат ожидания существует единственно,
[17:48.900 --> 17:57.300]  но оно формулируется в терминах абсолютно непрерывных мер. Давайте я сначала расскажу,
[17:57.300 --> 18:01.820]  что такое абсолютно непрерывные меры, еще расскажу, что такое заряд, а потом сформулирую теорему.
[18:01.820 --> 18:11.340]  Заряд – это просто... Чем заряд отличается от меры? Заряд отличается от меры тем,
[18:11.340 --> 18:17.340]  что он может принимать отрицательные значения. То есть, если у вас есть какая-то функция
[18:17.340 --> 18:27.940]  NU, которая действует из сигма алгебры G в R, который является счетно-аддитивной,
[18:35.220 --> 18:36.340]  то он называется зарядом.
[18:36.340 --> 18:53.620]  Некоторые обобщения понятия меры, мера со знаком. Заряд будем называть
[18:53.620 --> 18:56.420]  абсолютно непрерывным относительно вероятностной меры P.
[18:56.420 --> 19:23.340]  Если существует плотность, если существует плотность, то есть это такая функция,
[19:23.340 --> 19:41.420]  значит, такая функция G, которая действует из Омега в R,
[19:41.420 --> 20:10.220]  которая является G-измеримой. Такая, что для любого A из G значение заряда на
[20:10.220 --> 20:29.980]  множестве А совпадает с интегралом по А от G dp. Что такое dA? Что такое dA? Это NU.
[20:29.980 --> 20:43.980]  Вот смотрите, мы когда говорили про абсолютную непрерывность, мы ее понимали в смысле
[20:43.980 --> 20:48.420]  абсолютной непрерывности относительно классической меры Лебега. Когда мы говорили,
[20:48.420 --> 20:55.180]  что распределение является абсолютно непрерывным, то мы имели в виду, что существует плотность,
[20:55.180 --> 21:01.460]  то есть такая функция, что вероятность любого множества равна интегралу этой функции по
[21:01.460 --> 21:07.980]  классической мере Лебега. Здесь у нас вместо классической меры Лебега произвольная конечная,
[21:07.980 --> 21:13.580]  ну в нашем случае, вероятностная мера P. В принципе, то же самое можно определять и для
[21:13.580 --> 21:20.460]  сигмаконечных мер, то есть для классической меры Лебега и для других сигмаконечных мер.
[21:20.460 --> 21:27.940]  И вот понятие абсолютной непрерывности в общем смысле, это именно оно, именно то,
[21:27.940 --> 21:31.420]  что здесь написано. То есть вот та абсолютная непрерывность, к которой мы привыкли, это на
[21:31.420 --> 21:39.900]  самом деле просто, если классическая мера Лебега множество равна нулю, то и из этого следует,
[21:39.900 --> 21:44.340]  что и вероятность этого множества тоже ноль. Это то же самое, что существование плотности.
[21:44.340 --> 21:53.380]  Существование плотности равносильно тому, что мера абсолютно непрерывна, то есть для любого
[21:53.380 --> 21:57.460]  множества классической меры Лебега, которого равна нулю, и вероятность этого множества тоже ноль.
[21:57.460 --> 22:02.980]  Вот, и правильно абсолютно непрерывность воспринимать именно в этом смысле. Именно в том смысле,
[22:02.980 --> 22:12.020]  что... Сейчас, что я тут написал? А, я вас немного запутал, прошу прощения. Значит, я уже теорию
[22:12.220 --> 22:20.960]  родон Никодима формулировать, хотел сначала определить абсолютную непрерывность. Сейчас я
[22:20.960 --> 22:31.960]  исправлюсь. Понятие абсолютной непрерывности – это то, (*.р.у.) чую сейчас объяснял, а это то,
[22:31.960 --> 22:36.500]  что я написал ниже, это уже формулировка теории родон Никодима. Сейчас я исправлюсь,
[22:36.500 --> 22:40.260]  прошу прощения. Значит, понятие абсолютной непрерывности следующее. Здесь у меня было
[22:40.260 --> 22:47.020]  здесь у меня было понятие заряда, а здесь абсолютные непрерывности.
[22:48.220 --> 22:56.180]  если из того, что для любого ASG из того, что
[22:56.180 --> 23:02.260]  P от A равно 0, следует, что у него от A тоже равно 0. вот, понятие абсолютной непрерывности
[23:02.260 --> 23:08.180]  нужно воспринимать именно вот так. меры ню, заряд ню абсолютно непрерывен
[23:08.180 --> 23:15.020]  относительно меры P, если из того, что мера P равна 0, следует, что заряд равен 0. вот, и то же
[23:15.020 --> 23:19.420]  самое касается и нашей привычной на абсолютную непрерывности, когда мы говорим про абсолютную
[23:19.420 --> 23:24.340]  непрерывность распределения, мы говорим, что если классическая мера либега равна 0, то и тогда
[23:24.340 --> 23:29.380]  распределение тоже равно 0. и по теореме радона никодима это то же самое, что существование
[23:29.380 --> 23:34.860]  плотности. что теперь утверждает теорема радона никодима? теорема радона никодима утверждает,
[23:34.860 --> 23:43.220]  что существует плотность, то есть существует такая измеримая функция. какое условие теоремы?
[23:43.220 --> 23:51.060]  да, сейчас я все объясню. вот это условие теоремы. значит, мы говорим, что такой заряд, потом говорим,
[23:51.060 --> 23:58.500]  что такой абсолютно непрерывный заряд. и после этого мы говорим следующее, что теорема радона
[23:58.500 --> 24:03.340]  никодима утверждает, что если заряд является абсолютно непрерывным относительно p,
[24:03.340 --> 24:20.580]  если nu абсолютно непрерывным относительно p, то существует плотность, то есть существует такая же
[24:20.580 --> 24:27.140]  измеримая функция, что для любого события из g заряд на этом событии совпадает с интегралом от
[24:27.140 --> 24:34.900]  плотности. то есть иными словами, но понятно, что в другую сторону это тоже верно. если у вас
[24:34.900 --> 24:41.340]  существует плотность, то из этого будет следовать, что мера абсолютно непрерывна. потому что если вы
[24:41.340 --> 24:47.740]  возьмете вот в этом равенстве, если вы вот в этом равенстве рассмотрите какое-то множество a такое,
[24:47.740 --> 24:52.860]  что его мера равна нулю, то интеграл от любой функции по этой мере тоже будет равен нулю.
[24:52.860 --> 24:58.700]  поэтому если существует плотность, то тогда верное определение абсолютно непрерывной, из того,
[24:58.700 --> 25:05.720]  что p от равны нулю следует, что nu от равны нулю. поэтому это равносильные вещи, существование
[25:06.580 --> 25:13.120]  плотности и определение абсолютной непрерывности. еще раз провожу параллель с известной нам
[25:13.120 --> 25:18.160]  абсолютно непрерывностью вероятностной меры, которая говорит, что распреяние вероятности
[25:18.160 --> 25:21.760]  является абсолютно непрерывным, если существует плотность. Здесь написано в
[25:21.760 --> 25:28.720]  точности то же самое, но для более общего случая. Еще раз поясню, что можно
[25:28.720 --> 25:32.360]  абсолютно непрерывность и вот в нашем обычном случае воспринимать точно так же.
[25:32.360 --> 25:36.280]  Говорить, что мера абсолютно непрерывна, если из того, что классическая мера или
[25:36.280 --> 25:41.080]  бега равна нулю, следует, что вероятность на меры равна нулю тоже.
[25:42.080 --> 25:45.720]  Прошу прощения, что немного запутал, но надеюсь, что разобрались. Если какие-то
[25:45.720 --> 25:50.360]  вопросы по определению заряда абсолютно непрерывности и по формулировке теоремы
[25:50.360 --> 25:51.360]  Радона-Никодима.
[25:51.360 --> 26:06.760]  Ну, в общем, из этого сразу следует, что существует условным от ожидания.
[26:06.760 --> 26:15.200]  Более того, в теореме Радона-Никодима можно добавить единственность, то есть
[26:15.200 --> 26:23.040]  можно здесь написать существует единственная функция g. И вот эта единственность, ее надо
[26:23.040 --> 26:28.120]  воспринимать в смысле почти наверно. Единственность нули или почти всюду
[26:28.120 --> 26:33.240]  единственной, в зависимости от того вероятностной меры у вас или нет. Вот здесь это почти
[26:33.240 --> 26:38.520]  наверно. Единственность, то есть это единственность, единственность p почти
[26:38.520 --> 26:48.120]  наверное. То есть, какие бы вы не взяли две функции g, которые являются плотностями,
[26:48.120 --> 26:58.280]  вероятность того, что они совпадают, будет равна единице. Из этого сходу следует, что
[26:58.280 --> 27:16.840]  условное от ожидания x при условии g существует и единственно p почти наверно. Во-первых, существует,
[27:16.840 --> 27:20.600]  во-вторых, какие бы два вы условных от ожидания не взяли, они с вероятностью 1 будут совпадать.
[27:20.600 --> 27:26.480]  Давайте увидим, что действительно это следствие стереомародона Никодима.
[27:26.480 --> 27:32.240]  Рассмотрим заряд
[27:39.360 --> 27:46.000]  NUATA, который определен следующим образом. NUATA совпадает с мотожданием ксина индикатора.
[27:46.000 --> 27:55.000]  Счётная дитивность очевидна и залегийность математического ожидания.
[27:55.000 --> 28:00.560]  Можно вопрос? А мотождание берётся у кси или у кси индикатора?
[28:00.560 --> 28:09.360]  В определении математического ожидания то же самое.
[28:09.360 --> 28:25.320]  Во-втором, случая пастелского. Смотрите, когда мы пишем мотождание произведения, например,
[28:25.320 --> 28:33.000]  мы пишем мотождание произведения случайных величин x1, x2. Иногда пишем, иногда не пишем.
[28:33.040 --> 28:37.960]  Вообще скобки можно опускать. Вот такая запись означает мотождание произведения
[28:37.960 --> 28:42.000]  случайных величин. То есть это то же самое, что мотождание произведения.
[28:42.000 --> 28:50.080]  В том случае, когда вы хотите умножить случайную величину на мотождание, вы обязаны писать вот так.
[28:54.080 --> 28:57.600]  А если вы хотите взять мотождание произведения, то скобки ставить необязательно.
[28:58.200 --> 29:03.480]  Поэтому, когда скобки не стоят, нужно воспринимать, как мотождание применённое к произведению
[29:03.480 --> 29:13.200]  случайных величин. Итак, рассмотрим такую функцию NU, которая действует из JVR.
[29:13.200 --> 29:23.600]  Издал следующим образом. На событии A она просто совпадает с мотожданием от произведения кси индикатора.
[29:23.600 --> 29:31.200]  Понятно, что она является зарядом. Это сходу следует из линейности математического ожидания.
[29:31.200 --> 29:33.920]  Это заряд.
[29:33.920 --> 29:45.360]  Более того, этот заряд абсолютно непрерывен относительно P. Действительно, если P от R равно нулю,
[29:45.360 --> 29:54.240]  то и мотождание кси индикатора тоже равно нулю.
[29:54.240 --> 30:07.400]  А следовательно, по определению, NU абсолютно непрерывный заряд относительно вероятностной меры P.
[30:15.400 --> 30:31.360]  Тогда по теории миродомника Дима существует единственная, опять единственность, напомню,
[30:31.360 --> 30:37.800]  что подразумевает смысл P почти, наверное, функция J, которая действует из-за мега в R,
[30:37.800 --> 30:54.200]  который является J измеримой. И такая, что для любого ASG NU от A, который в свою очередь совпадает
[30:54.200 --> 31:04.000]  с мотожданием кси индикатора, по определению NU от A, равно интегралу по A от JDP.
[31:04.000 --> 31:11.520]  Ну что такое интеграл от A по JDP? Это есть ничто иное, как мотождание от J на индикатора.
[31:11.520 --> 31:15.000]  Да, J это случайная величина.
[31:15.000 --> 31:22.840]  J это случайная величина, поэтому мы вправе здесь поставить просто математическое ожидание.
[31:22.840 --> 31:27.040]  А это и есть в точности определение условного мотождания.
[31:27.040 --> 31:33.440]  Да, J это действительно просто условно мотождание от кси при условии J.
[31:33.440 --> 31:40.440]  По определению условного мотождания, должна быть J измеримая функция, такая, что для любого ASG выполнут
[31:40.440 --> 31:44.720]  это равенством от ожидания от кси индикатора, равно от ожидания от этой функции на индикатора.
[31:44.720 --> 31:49.880]  А знаете, J действительно условно мотождание, т.е. следствие доказано.
[31:49.880 --> 31:57.240]  Есть какие-то вопросы?
[31:57.240 --> 32:01.840]  А единственность?
[32:01.840 --> 32:05.920]  Ну вот потеряемая радона никодима, это функция единственная.
[32:05.920 --> 32:15.640]  Да, то есть, значит, еще раз, вот мы получили вот это равенство.
[32:15.640 --> 32:19.560]  У нас существует единственная функция, такая, что выполнено вот это равенство.
[32:19.560 --> 32:20.840]  Вот эта штука равно вот этой штуке.
[32:20.840 --> 32:25.000]  Такая единственная. Это как раз ровно определение условного мотождания.
[32:25.000 --> 32:36.400]  Так, хорошо, давайте теперь поговорим про свойства условного мотождания.
[32:36.400 --> 32:42.360]  Значит, с существованием единственности мы разобрались, пример привели.
[32:42.440 --> 32:58.440]  Есть некоторые специфичные свойства, которые мы для обычного математического ожидания не утверждали,
[32:58.440 --> 33:03.080]  которые очень удобно используют для вычисления условного мотождания.
[33:03.080 --> 33:05.920]  На семинарах будете делать, мы сейчас тоже пример разберем.
[33:05.920 --> 33:11.400]  Но есть свойства, которые копируют свойства обычного мотождания.
[33:11.440 --> 33:12.720]  Давайте в общем все в порядку.
[33:12.720 --> 33:22.960]  Так, ну во-первых, что будет, если в качестве сигма-алгебры G выбрать саму сигма-алгебру F?
[33:22.960 --> 33:26.760]  То есть, что будет, если посчитать мотождания от Xi при условии F?
[33:26.760 --> 33:34.920]  Я напомню, что Xi это случайная величина, которая задана на сигма-алгебре F.
[33:34.920 --> 33:37.840]  Отверждают, что это просто Xi.
[33:37.840 --> 33:45.640]  И это совершенно естественно, вы берете всю полноту информации,
[33:45.640 --> 33:48.480]  то есть вы вообще ни почему не усредняете.
[33:48.480 --> 33:53.560]  Вы вот на какой сигма-алгебре у вас задана случайная величина, вы по той сигма-алгебре ее усредняете.
[33:53.560 --> 33:57.520]  Поэтому должна остаться сама случайная величина.
[33:57.520 --> 34:02.360]  Давайте это увидим, что это следует из определения.
[34:02.800 --> 34:12.080]  Ну, во-первых, должна быть F-измеримость, раз вы мерите условные мотождания при условии сигма-алгебре F,
[34:12.080 --> 34:15.200]  то должна быть F-измеримость, которая есть по определению Xi.
[34:15.200 --> 34:18.360]  Xi F-измеримо, поэтому здесь все OK.
[34:18.360 --> 34:26.520]  Значит, теперь нам нужно проверить, что для любого A из F
[34:26.520 --> 34:32.480]  мотождание от нашего условного мотождания
[34:32.480 --> 34:40.160]  совпадает с мотожданием от кси на индикатора.
[34:40.160 --> 34:53.680]  Ну, это понятно, потому что просто проверяем, что условное мотождание от кси при условии F равно кси.
[34:53.680 --> 34:55.960]  Мы ровно это и проверяем.
[34:55.960 --> 35:03.160]  А значит, это равенство выполнено, что это ее, то есть это очевидно.
[35:03.160 --> 35:21.560]  Хорошо, теперь что будет, если сигма-алгебра, которая стоит в условии, не зависит от F?
[35:21.560 --> 35:25.120]  Значит, пусть G и F независимы.
[35:25.120 --> 35:35.960]  Или давайте даже для общности пусть G не зависит от кси, то есть от сигма-алгебры,
[35:35.960 --> 35:37.440]  порожденной случайно-величной кси.
[35:37.440 --> 35:43.640]  Я напомню, что сигма-алгебра, порожденная случайно-величной кси, это есть минимальная сигма-алгебра,
[35:43.640 --> 35:51.520]  которая содержит все… ну даже можно просто сигмы не писать, можно взять просто все прообразы,
[35:51.520 --> 35:54.680]  баррельских множеств, и вы получите сигма-алгебру.
[35:54.680 --> 36:03.000]  То есть просто система прообразов всех баррельских множеств, система прообразов всех баррельских множеств,
[36:03.000 --> 36:07.760]  это сигма-алгебра и называется на Fx.
[36:07.760 --> 36:16.880]  Так вот, если G не зависит от Fx, то тогда условное мотождание кси при условии G равно мотожданию кси.
[36:17.000 --> 36:23.840]  Ну это может быть интуитивно, не настолько очевидно, хотя если задуматься, кажется,
[36:23.840 --> 36:24.920]  что действительно должно быть так.
[36:24.920 --> 36:35.080]  Да, если вы меряете условное мотождание при условии какой-то информации,
[36:35.080 --> 36:39.520]  которая никак не зависит от кси, то кажется, что условное мотождание должно быть одинаковым
[36:39.520 --> 36:41.720]  для всех событий из этого G.
[36:41.720 --> 36:45.440]  Ну раз есть независимость, то оно не должно зависеть, то есть оно должно быть одинаковым.
[36:46.280 --> 36:50.480]  Но если все мотождание целиком, если вы усоедините вообще по всей Омега,
[36:50.480 --> 36:54.800]  совпадает с мотождание кси, то тогда это ровно должно быть вот это число,
[36:54.800 --> 36:56.520]  которое одинаково для всех событий.
[36:56.520 --> 37:00.800]  Да, то есть кажется, что это вполне логично, что так должно быть, давайте докажем.
[37:00.800 --> 37:09.280]  Ну константы измеримы относительно любой сигма-алгебры, поэтому тут проверять нечего.
[37:09.280 --> 37:10.920]  Мотождание кси является же измеримым.
[37:10.920 --> 37:29.800]  Вот, теперь берем любое ASG и хотим проверить, что вот наше, то что мы подозреваем на роль
[37:29.800 --> 37:35.840]  условного мотождания, если мы усредним его произведение на индикатора, то получим
[37:35.840 --> 37:37.120]  просто мотождание кси на индикатора.
[37:37.120 --> 37:44.080]  То есть хотим, чтобы мотождание от мотождания кси на индикатора совпадало с мотожданием
[37:44.080 --> 37:44.800]  кси на индикатора.
[37:44.800 --> 37:53.320]  Ну по линейности вы можете мотождание кси вынести и получите мотождание кси умножить
[37:53.320 --> 37:54.520]  на мотождание от индикатора.
[37:54.520 --> 38:00.640]  С другой стороны, в силу того, что кси и индикатора независимы,
[38:00.640 --> 38:04.160]  мотождание произведения равно произведению мотождания, то есть это мотождание
[38:04.160 --> 38:06.840]  произведения кси на индикатора, что и требовалось.
[38:06.840 --> 38:14.560]  Да, получили то, что требовалось, а значит, действительно мотождание кси
[38:14.560 --> 38:17.040]  константа подходит на роль условного мотождания.
[38:17.040 --> 38:21.360]  Почему индикатор A и кси независимы?
[38:21.360 --> 38:26.920]  Ну потому что G и F кси независимы.
[38:26.920 --> 38:29.560]  Мы взяли A и G.
[38:29.560 --> 38:35.080]  Значит, что означает, давайте вспомним, что означает независимость систем событий.
[38:35.080 --> 38:37.760]  У нас есть две системы событий G и F кси.
[38:37.760 --> 38:43.160]  Когда мы пишем, что G и F кси независимы, мы имеем в виду, что,
[38:43.160 --> 38:47.960]  какие бы мы ни взяли два события из G и F кси,
[38:47.960 --> 38:53.920]  один из G, а два из F кси.
[38:53.920 --> 39:03.200]  Верно, что вероятность их пересечения равна произведению вероятностей.
[39:13.200 --> 39:17.520]  Я утверждаю, что из этого следует, что кси не зависит от индикатора A.
[39:17.520 --> 39:22.720]  Значит, кси не зависит от индикатора A.
[39:22.720 --> 39:29.280]  Тогда и только тогда, что означает, что две случайные величины независимы.
[39:29.280 --> 39:31.680]  Значит, какие бы вы ни взяли два баррельских множества,
[39:31.680 --> 39:38.920]  вероятность попадания в эти баррельские множества двух случайных величин
[39:38.920 --> 39:40.440]  равна произведению вероятностей.
[39:40.440 --> 39:52.320]  Ну, попадание в баррельское множество индикатора – это, на самом деле, что-то тривиальное,
[39:52.320 --> 39:54.480]  потому что индикатор равен либо единице, либо нулю.
[39:54.480 --> 39:57.640]  Надо проверять для двух случаев.
[39:57.640 --> 40:00.120]  Один – это когда индикатор равен единице, другой – равен нулю.
[40:00.120 --> 40:05.480]  Давайте… Хорошо, я напишу для общности все здесь.
[40:05.480 --> 40:09.480]  Значит, это тогда и только тогда, когда вероятность того, что кси принадлежит B…
[40:09.520 --> 40:17.960]  И индикатор A равен единице, равно произведению вероятностей.
[40:31.960 --> 40:38.400]  Ну и что то же самое, вероятность прообраза множества B,
[40:38.400 --> 40:41.760]  то есть P от кси минус 1 от B, умножить на P от A.
[40:41.760 --> 40:53.520]  И с другой стороны еще то же самое должно быть верно для индикатора A равно нулю.
[40:53.520 --> 41:04.160]  Такая вероятность равна произведению прообраза множества B умножить на вероятность дополнения
[41:04.920 --> 41:08.920]  А. И это должно быть верно для любого B-баррельюсского.
[41:08.920 --> 41:16.920]  Но это очевидно верно, то есть вот из первой строчки следует вторая строчка.
[41:16.920 --> 41:28.920]  Да, потому что в первой строчке написано, что вероятность пересечения любых двух множеств A1, A2 из fx, равна произведению вероятностей.
[41:29.680 --> 41:37.680]  А A2 у нас уже попало в fx, то есть если вы посмотрите на кси принадлежит B, то есть не что иное, как кси минус 1 от B.
[41:37.680 --> 41:43.680]  А если вы посмотрите на индикатор A равно нулю, то есть не что иное, как просто A-дополнение.
[41:43.680 --> 41:49.680]  Поэтому здесь и в первой и второй строчке написано просто пересечение двух множеств.
[41:49.680 --> 41:53.680]  Первое взятое из сигма алгебры g, второе взятое из сигма алгебры fx.
[41:53.680 --> 41:57.680]  И вероятность их пересечения равна произведению вероятностей.
[41:57.680 --> 42:01.680]  Из того, что g в x независима, следует в частности что x и индикатора независима.
[42:01.680 --> 42:05.920]  Быле общonic у вас есть 2 сигма алгебры, которые независимы.
[42:05.920 --> 42:15.920]  Это тоже самое, что случайная величина, для которой эти сигма алгебры появляются порожденными, является независимой.
[42:15.920 --> 42:21.680]  То есть говорить про независимость случайных величин и говорить про независимость порожденных сигма альгебр – это равносильная вещь.
[42:21.680 --> 42:33.160]  Так, есть еще какие-то вопросы. А вот еще вопрос по первому равенству в доказательстве. Разве тут мы
[42:33.160 --> 42:38.960]  не используем то равенство, которое хотим доказать? Не, смотри, может быть не очень аккуратно написано,
[42:38.960 --> 42:44.400]  смысл в общем. Мы проверяем, значит, интегральное равенство. Да, мы проверяем, что левая часть вот
[42:44.400 --> 42:49.600]  этого вот этой длинной сфочки совпадает с правой. Я здесь имею в виду следующее. Я говорю, я говорю,
[42:49.600 --> 42:57.680]  что возьмем на роль условного мат ожидания вот наше гипотетическое значение. Мы с вами
[42:57.680 --> 43:03.080]  предполагаем, что условное мат ожидания совпадает с екси. И вот давайте попробуем проверить,
[43:03.080 --> 43:11.040]  так ли это. И вот в этом мат ожидания подставим, давайте я не пишу вот это равенство, я имею в виду
[43:11.480 --> 43:19.800]  подставим на роль условного мат ожидания подставим мат ожидания к��, просто мат ожидания кси и
[43:19.800 --> 43:28.960]  проверим, правда ли что после этой подстановки у нас получится требуемое. То есть еще раз,
[43:28.960 --> 43:34.520]  когда мы проверяем, что некоторая случайная величина подходит на роль условного engages,
[43:34.520 --> 43:37.440]  что мы делаем? Мы сначала проверяем, что это случайная величина является же измеримой,
[43:37.440 --> 43:41.960]  если это так, то после этого мы подставляем в наше интегральное равенство из определения
[43:41.960 --> 43:46.080]  условного отжадания, подставляем вместо условного отжадания случайную величину и
[43:46.080 --> 43:49.280]  проверяем то, что получилось в итоге отжадания ктиной индикатора.
[43:49.280 --> 43:58.840]  Хорошо, спасибо. Вычислить это никак нельзя, можно только таким угадыванием.
[43:58.840 --> 44:05.040]  Вы знаете, вот еще раз, когда мы в этом проекте свойствоговорим,
[44:05.040 --> 44:10.240]  вычислять условным отжаданием мы скоро научимся, во многих ситуациях, не во всех, но во многих
[44:10.240 --> 44:14.560]  научимся. Когда мы здесь говорим про свойства, эти свойства не на самом деле очевидны. То есть я
[44:14.560 --> 44:20.400]  все время, когда пишу свойства, я говорю интуицию, почему должно получиться так, и в каком смысле это
[44:20.400 --> 44:27.040]  угадывание. Но угадывание на слове довольно строгой интуиции. И потом мы, после того,
[44:27.040 --> 44:30.800]  как мы угадали, мы проверяем, что это действительно так. Но у нас будут в дальнейшем некоторые общие
[44:30.800 --> 44:34.760]  теоремы, которые позволят в довольно общих случаях в условном отжадании. Читать в частности,
[44:34.760 --> 44:39.840]  когда мы говорили про пример, то мы научились читать условным от ожидания. Вот у нас есть
[44:39.840 --> 44:45.200]  конкретная формула для всех ситуаций, когда сигма алгебра порождена разбиением.
[44:50.200 --> 44:51.520]  Так, свойства 3.
[44:51.520 --> 45:01.040]  Мат ожидания от условного мат ожидания совпадает с обычным от ожидания. Но опять же,
[45:01.040 --> 45:07.200]  это свойство выглядит вполне естественно. То есть одно дело сразу усреднить случайную
[45:07.200 --> 45:13.160]  величину и найти мат ожидания к себе. Другое дело сначала усреднить его по каким-то подсобытиям,
[45:13.160 --> 45:19.120]  потом усреднить это усредненное значение. Должно получиться одно и то же. Давайте
[45:19.120 --> 45:27.400]  проверим, что это действительно так. Давайте в определении условного мат ожидания возьмем
[45:27.400 --> 45:36.880]  a равное амета. Есть у нас в определении условного мат ожидания это интегральное равенство,
[45:36.880 --> 45:46.640]  которое говорит, что мат ожидания от условного мат ожидания, умноженного на индикатор a,
[45:46.640 --> 45:58.240]  совпадает с мат ожидания мат ксин индикатора. Но если в качестве a поставить ω, в левой
[45:58.240 --> 46:03.680]  части этого равенства вы получите мат ожидания от условного мат ожидания умножить на индикатор
[46:03.680 --> 46:09.280]  ω. Индикатор ω это просто единица на всех элементарных исходах, поэтому его можно
[46:09.280 --> 46:16.640]  просто выкинуть и получить мат ожидания от условного мат ожидания. Далее по свойству
[46:16.640 --> 46:26.000]  никакого свойства. Теперь обращаемся к правой части этого равенства. В правой части этого равенства
[46:26.000 --> 46:33.120]  написано мат ожидания ксин индикатор а. Опять а меняем на ω. Это просто единица,
[46:33.120 --> 46:37.640]  значит получаем мат ожидания кси. Все, смотрите, в правой части равенства, в самой правой части
[46:37.640 --> 46:43.800]  равенства стоит мат ожидания кси, а в самой левой части равенства стоит мат ожидания
[46:43.800 --> 46:47.360]  от условного мат ожидания, и они действительно получились равные, что и требовалось.
[46:47.360 --> 47:00.360]  То есть очевидное следствие определения условного мат ожидания, если в качестве a взять множество g.
[47:01.040 --> 47:04.240]  Четвёртое свойство, так называемое телескопическое.
[47:04.240 --> 47:18.840]  Телескопическое свойство. Это свойство о том, что будет, если усреднить сначала
[47:18.840 --> 47:25.440]  по одной сигнал г, а потом по другой. Представьте, что вы уже нашли условного
[47:25.440 --> 47:31.920]  мат ожидания, а потом вы его ещё раз захотели усреднить, но теперь по какому-то другому,
[47:31.920 --> 47:38.080]  какой-то другой сигнал г. Давайте рассмотрим ситуацию, когда эти сигнал г вложены, то есть пусть
[47:38.080 --> 47:45.280]  есть g1 и g2, это какие-то две под сигнал г в, которые ещё и вложены друг другу.
[47:45.280 --> 47:53.680]  Тогда
[47:58.400 --> 48:04.400]  условное мат ожидания от условного мат ожидания от кси при условии g1,
[48:04.400 --> 48:15.040]  при условии g2 совпадает. Неважно в каком порядке считать,
[48:15.040 --> 48:20.640]  вы можете сначала усреднить по g2, то есть написать условного мат ожидания от условного
[48:20.640 --> 48:25.440]  мат ожидания при условии g2, при условии g1. Это на самом деле то же самое, что усреднить сразу
[48:25.440 --> 48:35.640]  по самой маленькой. На самом деле видно, что пункт 3 это частный случай пункта 4. То есть,
[48:35.640 --> 48:42.960]  если вы усредняете по тривиальной сигнал г, то есть в качестве g2 вы выберете g1,
[48:42.960 --> 48:47.360]  в качестве самой маленькой сигмалы, выберете сигнал г, который состоит только из пустого множества
[48:47.360 --> 48:59.160]  и омеги, то пункт 4 просто превратится в пункт 3. Давайте докажем, что верно вот это телескопическое
[48:59.160 --> 49:16.080]  свойство для произвольных ложных сигналгебов g1 и g2. Ну смотрите, какое из этих равенств
[49:16.080 --> 49:22.640]  очевидно. Давайте сообразим. Очевидно совпадение самой левой части равенства, самой правой части
[49:23.000 --> 49:25.440]  то есть я хочу сказать, что очевидно, что
[49:25.440 --> 49:35.200]  условным от ожидания от условного от ожидания кси при условии g1 при условии g2
[49:35.200 --> 49:51.400]  совпадает с условным от ожиданиям кси при условии g1. Почему я считаю, что это очевидно?
[49:51.400 --> 50:03.880]  Ну, например, это очевидно следует из свойства 1. Значит, я считаю, что это верно просто по
[50:03.880 --> 50:16.920]  свойству 1. Давайте вспомним, что такое свойство 1. Если усреднить случайную величину относительно
[50:16.920 --> 50:25.400]  сигналгебры, относительно которой это случайная величина измерима, то останется сама случайная
[50:25.400 --> 50:32.480]  величина. Теперь возвращаемся к свойству 4. Смотрите, условным от ожидания кси при условии g1,
[50:32.480 --> 50:36.320]  вот которая здесь вот написана, когда мы первый раз берем условным от ожидания,
[50:36.320 --> 50:45.880]  оно является g1-измеримым по определению. Это g1-измеримая случайная величина.
[50:45.880 --> 50:57.760]  А g2 содержит в себе g1. Ну, если измеримо относительно меньше сигналгебры,
[50:57.760 --> 51:01.680]  то тогда измеримо относительно больше сигмала. Значит, g2-измеримо тоже.
[51:01.680 --> 51:08.920]  И вы как раз берете условным от ожидания при условии g2. Ну, значит, оно не поменяет случайную
[51:08.920 --> 51:15.240]  величину. У вас просто остается в ожидании кси при условии g1. Поэтому то, что левая часть равенства
[51:15.240 --> 51:21.240]  совпадает с правой, это очевидно. Давайте докажем, что второе выражение совпадает с третьим.
[51:21.240 --> 51:33.600]  В первом свойстве у нас же было, что случайная величина действует из f.
[51:33.600 --> 51:44.400]  Она действует из omega w, f это сигмалгебра. Там прообразы не различают g1 от g2.
[51:44.400 --> 51:52.480]  Прообразы не различают g1 от g2. Конечно, это вот условным от ожидания кси при условии g1,
[51:52.480 --> 51:59.080]  оно g1-измеримо. А g2 содержит все множества, которые есть в g1, и содержит еще какие-то
[51:59.080 --> 52:04.360]  дополнительные. Ну, и плевать на эти дополнительные множества. Если прообразы всех бареллерских
[52:04.360 --> 52:07.520]  множеств принадлежат g1, значит, они и g2 тоже принадлежат.
[52:15.400 --> 52:18.080]  Так, теперь проверим, что
[52:25.560 --> 52:36.560]  условным от ожидания от кси при условии g2 при условии g1 совпадает с от ожиданием кси при условии g1.
[52:45.000 --> 52:49.640]  Первое, что нам нужно для этого проверить, это измеримость.
[52:55.800 --> 53:00.920]  Смотрите, что мы хотим сделать. Вот у нас здесь вот это внешнее условное от ожидания,
[53:00.920 --> 53:07.000]  вот это внешнее. Мы хотим проверить именно его определение. То есть мы хотим проверить,
[53:07.000 --> 53:12.280]  что на роль вот этого большого условного от ожидания можно взять то, что стоит в правой части
[53:12.280 --> 53:19.040]  равенства. То есть, во-первых, мы хотим проверить измеримость правой части равенства, измеримость
[53:19.040 --> 53:25.120]  относительно чего? Ну, относительно вот этой сигма алгебры. Но это по определению. От ожидания
[53:25.120 --> 53:36.400]  кси при условии g1 является g1 измеримой, случайно величиной. Да, поэтому все OK. В смысле измеримости
[53:36.400 --> 53:39.800]  все OK. Вот это внешнее условное от ожидания, которое стоит в левой части равенства,
[53:40.040 --> 53:48.560]  является g1 измеримой. Теперь нам нужно проверить интегральное равенство. Осталось проверить,
[53:48.560 --> 54:10.160]  что для любого ASG1. Значит, мат ожидания от того, что мы хотим взять на роль условного
[54:10.160 --> 54:14.400]  мат ожидания, то есть вот мат ожидания кси при условии g1 умножить на индикатора,
[54:14.400 --> 54:22.120]  совпадает с тем, что мы усредняем. А усредняем мы вот то, что у нас тут стоит в левой части равенства.
[54:22.120 --> 54:26.200]  Вот эту штуку мы усредняем, то есть должна совпасть с мат ожиданием от условного
[54:26.200 --> 54:32.440]  мат ожидания от кси при условии g2 на индикатора. Вот что мы хотим.
[54:32.440 --> 54:47.600]  Ну смотрите, так как APRING g1, то по определению условного мат ожидания,
[54:47.600 --> 54:56.160]  условного мат ожидания от кси при условии g1 на индикатора совпадает
[54:56.160 --> 55:04.680]  с мат ожиданием кси на индикатора. Это просто определение условного мат ожидания при условии g1.
[55:04.680 --> 55:21.280]  Но g1 вложено в g2. Значит, так как g1 вложено в g2, то а еще и g2 принадлежит. А следовательно,
[55:21.280 --> 55:30.640]  по определению условного мат ожидания при условии g2, вот такое мат ожидание тоже совпадает
[55:30.640 --> 55:38.280]  с мат ожиданием кси на индикатора. Ну все, мы получили знать, что эти вещи одинаковые, что и тревога.
[55:38.280 --> 55:41.480]  Есть какие-то вопросы?
[55:51.280 --> 56:01.600]  Движемся дальше. Эти все свойства были специфичны. Именно вот для обычного мат ожидания
[56:01.600 --> 56:07.080]  нас ничего подобного не было. Теперь мы разберем несколько свойств, которые были точно такие же
[56:07.080 --> 56:15.800]  для обычного мат ожидания. Во-первых, неравенство, сохранение неравенства. Если кси1 меньше
[56:15.800 --> 56:37.720]  от кси2 почти наверное, то и мат ожидания кси1 при условии g меньше оно, чем мат ожидания кси2
[56:37.720 --> 56:49.000]  при условии g почти наверное. А почему здесь почти наверное сохраняются? То есть мат ожидания
[56:49.000 --> 57:05.080]  уже усередняет? Это же тоже случайная величина? Ну вы скажете, что мы когда писали про равенство,
[57:05.080 --> 57:13.400]  то мы почти наверное не писали, а тут написали. Но смотрите еще раз, когда я писал про равенство,
[57:13.400 --> 57:17.000]  то я на самом деле когда писал про равенство, я просто подразумевал принадлежность к классу
[57:17.000 --> 57:20.600]  эквивалентности. То есть когда я пишу, что условно мат ожидания равно чему-то, я имею в виду,
[57:20.600 --> 57:24.960]  что правая часть этого равенства принадлежит к классу эквивалентности, который называется
[57:24.960 --> 57:28.840]  условно мат ожидания. Условно мат ожидания можно подразумевать как класс эквивалентности.
[57:29.620 --> 57:38.320]  Здесь имеется в виду что если я возьму произвольного представителя и из одного
[57:38.320 --> 57:42.280]  класса эквивалентности, возьму произвольного представителя и из другого класса эквивалентности,
[57:42.280 --> 57:44.740]  то есть возьму какую-то случайную чему которая спадает с условным от ожиданиям кси1 при условии g,
[57:44.740 --> 57:50.640]  и возьму другую случайную чему которая сtopодает с условным от ожиданиям кс 2 при условии g,
[57:50.640 --> 57:57.240]  то окажется что это нерая совершенность веротstatности 1. Вот что здесь имеется в виду.
[57:57.240 --> 58:05.480]  Так, ну как это доказать? Смотрите, вот эти две случайные величины, мотожидание x1 при условии g
[58:05.480 --> 58:14.840]  и мотожидание x2 при условии g, они являются же измеримыми по определению, условному от ожидания.
[58:14.840 --> 58:29.000]  Поэтому на самом деле для этого неравенства у нас такое свойство мотожидания было, из которого
[58:29.000 --> 58:35.880]  это следует. Значит, для вот этого неравенства мотожидание x1 при условии g меньше, чем мотожидание
[58:35.880 --> 58:39.720]  x2 при условии g почти, наверное. Достаточно,
[58:45.720 --> 58:50.760]  достаточно, чтобы для любого ASG
[58:50.760 --> 59:04.680]  мотожидание x1 при условии g на индикатор A и от этого все мотожидание.
[59:04.680 --> 59:12.120]  Было меньше набрано, чем мотожидание от условного мотожидания x2 при условии g на индикатора.
[59:12.120 --> 59:22.600]  Да, мы знаем, что если для двух случайных величин, которые являются же измеримыми,
[59:22.600 --> 59:29.960]  справедливо такое неравенство, то есть какое бы ни взяли множество ASG, мотожидание от первого
[59:29.960 --> 59:33.280]  на индикатора меньше, чем мотожидание второго на индикатора, из этого следует, что между
[59:33.280 --> 59:41.480]  случайными величинами с вероятностью x1 такое же неравенство. Вот, ну давайте и собственно это докажем.
[59:41.480 --> 59:46.440]  Давайте докажем последнее неравенство, то есть возьмем ASG
[59:53.640 --> 59:58.960]  и прям проверим, то есть сначала напишем левую часть неравенства, мотожидание от
[59:58.960 --> 01:00:01.960]  условного мотожидания x1 при условии g на индикатора.
[01:00:01.960 --> 01:00:11.360]  По определению условного мотожидания, это есть мотожидание от x1 на индикатора.
[01:00:11.360 --> 01:00:22.720]  Дальше, так как x1 меньше равно, чем x2, эта штука меньше набрано, чем от ожидания x2 на индикатора.
[01:00:22.720 --> 01:00:31.920]  В свою очередь, по определению условного мотожидания от x2, последнее мотожидание
[01:00:31.920 --> 01:00:37.280]  совпадает с мотожиданием от условного мотожидания x2 при условии g на индикатора.
[01:00:37.280 --> 01:01:03.160]  Так, следующая линейность.
[01:01:08.160 --> 01:01:23.920]  Линейность, значит мотожидание от c1 x1 плюс c2 x2 при условии g равно c1 на мотожидание x1 при условии g
[01:01:23.920 --> 01:01:30.480]  плюс c2 на мотожидание x2 при условии g.
[01:01:37.280 --> 01:01:42.880]  Ну, то есть, как мы проверяем подобные утверждения?
[01:01:42.880 --> 01:01:46.880]  Мы хотим просто доказать, что то, что стоит в правой части равенства,
[01:01:46.880 --> 01:01:52.880]  подходит под определение условного мотожидания случайно-вечной, которая стоит в левой части равенства.
[01:01:52.880 --> 01:01:56.880]  Ну, же изменимость правой части очевидна по определению.
[01:01:56.880 --> 01:02:06.880]  Значит, вот эта вот линейная комбинация c1 мотожидание x1 при условии g плюс c2 мотожидание x2 при условии g,
[01:02:06.880 --> 01:02:12.480]  она является g измеримой, случайно-вечной.
[01:02:18.480 --> 01:02:28.480]  Поскольку постольку мотожидание x1 при условии g и мотожидание x2 при условии g являются линейными измерениями,
[01:02:28.480 --> 01:02:34.480]  значит их линейная комбинация является g измеримой.
[01:02:34.480 --> 01:02:40.080]  Теперь нужно проявить равенство интегральное, то есть взять ASG
[01:02:40.080 --> 01:02:54.080]  и посмотреть, что будет, если на роль условного мотожидания подставить правую часть равенства нашего,
[01:02:54.080 --> 01:03:02.080]  то есть c1 на e x1 при условии g плюс c2 на мотожидание x2 при условии g.
[01:03:02.680 --> 01:03:04.680]  И умножить это все дело на индикатора.
[01:03:04.680 --> 01:03:13.680]  То есть мы хотим проверить, что действительно эта линейная комбинация подходит на роль условного мотожидания,
[01:03:13.680 --> 01:03:21.680]  то есть проверить, что эта штука совпадет с мотожиданием от c1 к c1 плюс c2 к c2 на индикатора.
[01:03:21.680 --> 01:03:25.680]  Ну, пользуемся обычной линейностью, обычным мотожиданием.
[01:03:25.780 --> 01:03:35.680]  Получаем c1 на мотожидание от произведения условного мотожидания x1 при условии g на индикатора,
[01:03:35.680 --> 01:03:45.680]  плюс c2 на мотожидание от произведения условного мотожидания x2 при условии g на индикатора.
[01:03:45.680 --> 01:03:59.000]  Теперь в силу определения, условным от ожидания, первое
[01:03:59.000 --> 01:04:06.840]  от ожидания совпадает с от ожиданиям от KC1 на индикатора,
[01:04:06.840 --> 01:04:13.800]  второе от ожидания совпадает с от ожидания от KC2 на индикатора,
[01:04:13.800 --> 01:04:17.600]  новое пользуясь линейностью, получаем от ожидания от
[01:04:17.600 --> 01:04:27.000]  C1 к C1 плюс C2 к C2 на индикатор А, что и требовалось, да,
[01:04:27.000 --> 01:04:33.440]  значит, что и свойство тоже доказано, есть ли какие-то
[01:04:33.440 --> 01:04:34.440]  вопросы.
[01:04:34.440 --> 01:04:42.960]  А вот индикатора попадает в от ожидания или нет?
[01:04:42.960 --> 01:04:45.240]  Да-да, еще раз, когда мы пишем от ожиданий, дальше стоит
[01:04:45.240 --> 01:04:46.800]  произведение случайных причин.
[01:04:46.800 --> 01:05:15.800]  Так, далее, модуль, значит, от ожидания от модуля
[01:05:15.800 --> 01:05:25.720]  к C при условии G меньше собрано, чем модуль от условного
[01:05:25.720 --> 01:05:33.800]  от ожидания к C при условии, наоборот, больше собрано,
[01:05:33.800 --> 01:05:41.560]  больше собрано, чем модуль от условного от ожидания
[01:05:41.560 --> 01:05:45.480]  к C при условии G.
[01:05:45.480 --> 01:05:54.000]  Ну, это свойство 5, да, то есть это очевидно следует
[01:05:54.000 --> 01:05:56.040]  из свойства 5, где у нас были неравенства.
[01:05:56.040 --> 01:06:01.680]  Значит, смотрите, к C лежит между модулем к C и минус
[01:06:01.680 --> 01:06:07.280]  модулем к C, конечно, к C лежит между модулем к C и минус
[01:06:08.000 --> 01:06:16.600]  Поэтому по свойству 5, правда же, 5, да, по свойству 5 из этого
[01:06:16.600 --> 01:06:24.680]  следует, что от ожидания от минус модуля к C при условии
[01:06:24.680 --> 01:06:32.640]  G меньше собрано, чем от ожидания от к C при условии G и меньше
[01:06:33.000 --> 01:06:35.320]  собрано, чем от ожидания от модуля к C при условии G.
[01:06:35.320 --> 01:06:47.440]  Теперь по свойству 6, в этой цепочке не равен самое
[01:06:47.440 --> 01:06:53.600]  левое выражение, в нем минус можно вынести и получится
[01:06:53.600 --> 01:07:02.160]  минус от ожидания от модуля к C при условии G меньше собрано,
[01:07:02.680 --> 01:07:10.680]  чем от ожидания к C при условии G меньше собрано, чем от ожидания
[01:07:10.680 --> 01:07:11.680]  от модуля к C при условии G.
[01:07:11.680 --> 01:07:15.560]  Это есть именно то, что требуется, да, это в точности означает,
[01:07:15.560 --> 01:07:19.640]  что модуль от ожидания меньше собрано, чем от ожидания
[01:07:20.120 --> 01:07:22.120]  модуля.
[01:07:35.120 --> 01:07:37.120]  Что это требуется?
[01:07:42.120 --> 01:07:44.120]  Так, есть какие-то вопросы?
[01:07:44.600 --> 01:07:50.600]  У нас было там почти, наверное, здесь, соответственно,
[01:07:50.600 --> 01:07:52.600]  почти, наверное...
[01:07:52.600 --> 01:07:55.600]  Здесь даже более сильное, да, здесь просто нерайство
[01:07:55.600 --> 01:07:59.600]  верно для всех элементарных исходов без звучания.
[01:08:03.600 --> 01:08:06.600]  То есть, в частности, почти, наверное.
[01:08:07.080 --> 01:08:20.080]  Так, ну, кстати, не совсем я, правда, сказал.
[01:08:20.080 --> 01:08:22.080]  Вот когда мы говорим, смотрите, про вот это нерайство,
[01:08:22.080 --> 01:08:26.080]  про вот это нерайство, когда мы говорим, то вот это
[01:08:26.080 --> 01:08:29.080]  нерайство, конечно, верно для всех элементарных исходов
[01:08:29.080 --> 01:08:30.080]  без исключения.
[01:08:30.080 --> 01:08:33.080]  Здесь давайте все-таки напишем в том, что мы утверждаем,
[01:08:33.080 --> 01:08:36.080]  давайте напишем почти, наверное.
[01:08:36.560 --> 01:08:40.560]  Поскольку, постольку еще раз напомню, что условным
[01:08:40.560 --> 01:08:42.560]  от ожидания это класс эквивалентности.
[01:08:42.560 --> 01:08:45.560]  Мы можем там на одном элементарном исходе попортить
[01:08:45.560 --> 01:08:48.560]  левую часть или правую часть, каким нам хочется
[01:08:48.560 --> 01:08:50.560]  образом, да, если возьмем какой-то элементарный
[01:08:50.560 --> 01:08:52.560]  исход, которого есть, вероятность которого ноль,
[01:08:52.560 --> 01:08:56.560]  то на нем мы можем что левую часть, что правую часть
[01:08:56.560 --> 01:09:00.560]  задать как угодно, от этого они, для них останется
[01:09:00.560 --> 01:09:03.560]  верным условным от ожидания, нерайство может в принципе
[01:09:03.560 --> 01:09:04.560]  не быть.
[01:09:04.560 --> 01:09:07.040]  Поэтому, да, правильно, вот в самом свойстве правильно
[01:09:07.040 --> 01:09:08.040]  написать, конечно, почти, наверное.
[01:09:08.040 --> 01:09:09.040]  Спасибо.
[01:09:16.040 --> 01:09:20.040]  Так, теперь аналог тирем или бега, и мы жарим
[01:09:20.040 --> 01:09:21.040]  исходимости.
[01:09:21.040 --> 01:09:25.040]  Значит, если ксиен стремится кси почти, наверное, да,
[01:09:25.040 --> 01:09:27.040]  то есть если вероятность того, что ксиен стремится
[01:09:27.040 --> 01:09:30.040]  кси, равна единице, и что еще надо?
[01:09:30.040 --> 01:09:33.040]  Все ксиенты по модуле не превосходят какой-то случайной
[01:09:33.040 --> 01:09:34.040]  величины.
[01:09:34.520 --> 01:09:36.520]  И мы от ожидания это конечна.
[01:09:42.520 --> 01:09:49.520]  То тогда мы от ожидания ксиен при условии g стремится
[01:09:49.520 --> 01:09:51.520]  к мы от ожидания кси при условии g.
[01:09:53.520 --> 01:09:56.520]  Но доказательства в каком-то смысле аналогичны доказательств
[01:09:56.520 --> 01:09:59.520]  тирем или бега, позвольте мне это оставить без доказательства.
[01:10:00.000 --> 01:10:04.000]  Вместо этого мы восьмой пункт не будем никогда
[01:10:04.000 --> 01:10:07.000]  использовать, в общем, он нам особо без надобности,
[01:10:07.000 --> 01:10:09.000]  он нам единственное зачем нужно для того, чтобы доказать
[01:10:09.000 --> 01:10:10.000]  девятый пункт.
[01:10:10.000 --> 01:10:13.000]  Очень важное свойство, которое мы постоянно будем
[01:10:13.000 --> 01:10:15.000]  использовать при учтении условного от ждания.
[01:10:15.000 --> 01:10:16.000]  Оно следующее.
[01:10:16.000 --> 01:10:18.000]  Если случайная величина g измерима,
[01:10:18.480 --> 01:10:33.480]  то тогда условного от ожидания от произведения
[01:10:33.480 --> 01:10:42.480]  кси это при условии g совпадает с это умножить на условном
[01:10:42.480 --> 01:10:44.480]  от ожидания кси при условии g.
[01:10:44.480 --> 01:10:47.480]  Я напоминаю, что когда мы говорим про условном от
[01:10:47.960 --> 01:10:51.960]  ожидания, мы всегда считаем, что от ожидания обычное,
[01:10:51.960 --> 01:10:52.960]  конечное.
[01:10:52.960 --> 01:10:57.960]  То есть мы рассматриваем всю эту теорию только в
[01:10:57.960 --> 01:11:00.960]  случае, когда случайная величина интегрирует,
[01:11:00.960 --> 01:11:01.960]  то интеграл конечный.
[01:11:01.960 --> 01:11:04.960]  То есть здесь, когда я пишу это равенство, я предположил,
[01:11:04.960 --> 01:11:07.960]  что как от ожидания кси конечное, так и от ожидания произведения
[01:11:07.960 --> 01:11:08.960]  кси, это конечное.
[01:11:13.960 --> 01:11:16.960]  Самое сложное всех свойств, которые я тут написал,
[01:11:17.440 --> 01:11:19.440]  давайте его за оставшиеся 10 минут попробуем доказать.
[01:11:19.440 --> 01:11:23.440]  В общем-то, это последнее свойство, которое я хотел
[01:11:23.440 --> 01:11:24.440]  сказать.
[01:11:24.440 --> 01:11:28.440]  Значит, сперва докажем его для индикаторов.
[01:11:28.440 --> 01:11:35.440]  То есть сперва докажем, что оно верно для это равное
[01:11:35.440 --> 01:11:39.440]  индикатору множеству b, где b это некоторое баррелевское
[01:11:39.440 --> 01:11:40.440]  множество.
[01:11:40.440 --> 01:11:45.440]  В общем, баррелевское b принадлежит, давайте это
[01:11:45.920 --> 01:11:46.920]  A будет.
[01:11:46.920 --> 01:11:49.920]  A принадлежит G.
[01:11:49.920 --> 01:11:53.920]  Да, то есть на множестве A единица случайная величина,
[01:11:53.920 --> 01:11:56.920]  а вне множества A ноль.
[01:11:56.920 --> 01:11:59.920]  Вот, хорошо.
[01:12:02.920 --> 01:12:05.920]  В этом случае A не всегда баррелевское, правильно?
[01:12:05.920 --> 01:12:08.920]  A это никакое не баррелевское множество, потому что A
[01:12:08.920 --> 01:12:13.920]  это под множество Омега, а не R.
[01:12:14.400 --> 01:12:15.400]  Я говорился.
[01:12:15.400 --> 01:12:20.400]  Значит, забыл сказать, что я хочу проверять это исключительно
[01:12:20.400 --> 01:12:21.400]  интегральное равенство.
[01:12:21.400 --> 01:12:22.400]  G измеримость очевидна.
[01:12:22.400 --> 01:12:25.400]  То есть еще раз, когда я хочу проверить, что условным
[01:12:25.400 --> 01:12:28.400]  от ожидания чему-то равно, я просто проверяю, что правая
[01:12:28.400 --> 01:12:30.400]  часть подходит под определение условного от ожидания.
[01:12:30.400 --> 01:12:33.400]  Так вот эта правая часть, это умножительное от ожидания
[01:12:33.400 --> 01:12:36.400]  x при условии G, она очевидно же измерима, потому что
[01:12:36.400 --> 01:12:41.400]  это произведение двух же измеримых функций.
[01:12:41.880 --> 01:12:44.880]  Поэтому, как обычно, измеримость проверять не нужно, проверяем
[01:12:44.880 --> 01:12:47.880]  сразу интегральное равенство.
[01:12:50.880 --> 01:12:53.880]  Для интегрального равенства сперва рассмотрим простейший
[01:12:53.880 --> 01:12:55.880]  случай, когда случайная величина это индикатор
[01:12:55.880 --> 01:12:58.880]  какого-то измеримого множества.
[01:12:58.880 --> 01:13:01.880]  Тогда, что хотим проверить?
[01:13:01.880 --> 01:13:03.880]  Хотим проверить, что какой бы мы не взяли A с валлой
[01:13:04.360 --> 01:13:07.360]  из G,
[01:13:08.360 --> 01:13:11.360]  должно быть выполнено интегральное равенство.
[01:13:11.360 --> 01:13:14.360]  То есть подставляем на роль условного от ожидания
[01:13:14.360 --> 01:13:16.360]  нашу правую часть.
[01:13:16.360 --> 01:13:19.360]  То есть это нам от ожидания x при условии G,
[01:13:19.360 --> 01:13:22.360]  умножаем это на индикатор A с валлой.
[01:13:26.360 --> 01:13:29.360]  Нам нужно проверить, что это от ожидания совпадет
[01:13:29.360 --> 01:13:33.360]  с от ожидания от x на это на индикатор A с валлой.
[01:13:33.840 --> 01:13:36.840]  Тогда мы действительно докажем нашу равенство.
[01:13:38.840 --> 01:13:41.840]  Я напоминаю, что это индикатор A.
[01:13:43.840 --> 01:13:46.840]  По тому, как мы взяли это.
[01:13:50.840 --> 01:13:53.840]  И вот тут внутри этого всего длинного произведения
[01:13:53.840 --> 01:13:56.840]  есть индикатор A и индикатор A с валлой.
[01:13:57.840 --> 01:14:00.840]  Когда их перемножаю, получаю индикатор пересечение.
[01:14:01.320 --> 01:14:04.320]  В результате, это есть от ожидания от условного
[01:14:04.320 --> 01:14:07.320]  от ожидания x при условии G,
[01:14:07.320 --> 01:14:10.320]  индикатор пересечения.
[01:14:12.320 --> 01:14:16.320]  И так как A и A с валлой принадлежат G,
[01:14:16.320 --> 01:14:19.320]  то их пересечение тоже принадлежит G.
[01:14:19.320 --> 01:14:22.320]  А значит, по определению условного от ожидания,
[01:14:22.320 --> 01:14:26.320]  это в точности от ожидания от x на индикатор пересечения.
[01:14:31.320 --> 01:14:34.320]  Это по определению условного от ожидания x при условии G.
[01:14:38.320 --> 01:14:43.320]  Теперь снова эти два индикатора раскрываем.
[01:14:43.320 --> 01:14:46.320]  То есть, вместо индикатора пересечения
[01:14:46.320 --> 01:14:48.320]  напишем произведение индикаторов.
[01:14:48.320 --> 01:14:50.320]  Индикатор A на индикатор A с валлой.
[01:14:50.320 --> 01:14:53.320]  У нас индикатор A это в точности это.
[01:14:53.320 --> 01:14:55.320]  Значит, мы получаем от ожидания от x на это,
[01:14:55.320 --> 01:14:57.320]  на индикатор A с валлой, что и требуется.
[01:14:57.800 --> 01:15:01.800]  Да, это в точности наше интегральное равенство.
[01:15:01.800 --> 01:15:04.800]  Поэтому можем переходить к следующей ситуации,
[01:15:04.800 --> 01:15:07.800]  когда случайно влечена эта простая.
[01:15:07.800 --> 01:15:12.800]  То есть, эта равна сумме по i от 1 до n
[01:15:12.800 --> 01:15:16.800]  с i t на индикатор i t,
[01:15:16.800 --> 01:15:19.800]  для некоторых i t из G
[01:15:19.800 --> 01:15:23.800]  и с i t из G.
[01:15:27.800 --> 01:15:29.800]  Вот. Ну, линейность просто.
[01:15:29.800 --> 01:15:34.800]  Значит, берем от ожидания от это
[01:15:34.800 --> 01:15:38.800]  на от ожидания x при условии G
[01:15:38.800 --> 01:15:40.800]  на индикатор A с валлой опять.
[01:15:45.800 --> 01:15:47.800]  Значит, по линейности это совпадает,
[01:15:47.800 --> 01:15:49.800]  по линейности от ожидания это совпадает
[01:15:49.800 --> 01:15:52.800]  с суммой по i от 1 до n.
[01:15:52.800 --> 01:15:55.800]  Целью, что мы получаем,
[01:15:56.280 --> 01:16:06.280]  от ожидания от индикатора i t
[01:16:06.280 --> 01:16:10.280]  на от ожидания x при условии G
[01:16:10.280 --> 01:16:13.280]  на индикатор A с валлой.
[01:16:13.280 --> 01:16:17.280]  Для вот этих вот индикаторов уже все доказано.
[01:16:17.280 --> 01:16:20.280]  То есть, мы воспользуемся предыдущим пунктом
[01:16:20.280 --> 01:16:23.280]  и получим просто сумму по i от 1 до n
[01:16:23.280 --> 01:16:26.280]  с i t на от ожидания x
[01:16:26.280 --> 01:16:29.280]  на индикатор i t и на индикатор A с валлой.
[01:16:32.280 --> 01:16:33.280]  Снова по линейности.
[01:16:33.280 --> 01:16:35.280]  Теперь заносим коэффициенты из суммы
[01:16:35.280 --> 01:16:36.280]  внутри от ожидания.
[01:16:36.280 --> 01:16:37.280]  Получаем требуемое.
[01:16:37.280 --> 01:16:38.280]  То есть, мы от ожидания x
[01:16:38.280 --> 01:16:40.280]  это на индикатор A с валлой.
[01:16:44.280 --> 01:16:46.280]  Ну и наконец, последний пункт.
[01:16:46.280 --> 01:16:48.280]  Это произвольное.
[01:16:49.280 --> 01:16:50.280]  Что мы знаем?
[01:16:50.280 --> 01:16:55.280]  Мы знаем, как мы определяли
[01:16:55.280 --> 01:16:56.280]  обычное от ожидания.
[01:16:56.280 --> 01:16:58.280]  Мы приближали простыми функциями.
[01:16:58.280 --> 01:16:59.280]  Мы знаем, что произвольную
[01:16:59.280 --> 01:17:00.280]  случайную величину можно приблизить
[01:17:00.280 --> 01:17:01.280]  простыми функциями.
[01:17:01.280 --> 01:17:04.280]  Значит, существует последовательность
[01:17:04.280 --> 01:17:08.280]  это-энте, которая стремится к это.
[01:17:08.280 --> 01:17:11.280]  Значит, все это-энты, они простые.
[01:17:11.280 --> 01:17:13.280]  То есть, равны вот этим конечным
[01:17:13.280 --> 01:17:15.280]  суммам из предыдущего пункта.
[01:17:15.280 --> 01:17:17.280]  И к тому же, что мы делаем
[01:17:17.280 --> 01:17:18.280]  из предыдущего пункта.
[01:17:18.280 --> 01:17:19.280]  И к тому же, они все по модуле
[01:17:19.280 --> 01:17:21.280]  не превосходят это.
[01:17:29.280 --> 01:17:31.280]  Давайте это произвольное
[01:17:31.280 --> 01:17:32.280]  и не отрицательное.
[01:17:37.280 --> 01:17:38.280]  Давайте так.
[01:17:38.280 --> 01:17:39.280]  Пусть модуль это-энты
[01:17:39.280 --> 01:17:41.280]  не превосходит модуле это.
[01:17:41.280 --> 01:17:42.280]  Вот так.
[01:17:42.280 --> 01:17:44.280]  Вот так вот мы умеем делать.
[01:17:44.280 --> 01:17:45.280]  Мы умеем приближать простыми
[01:17:45.280 --> 01:17:46.280]  такие, что их модуль
[01:17:46.280 --> 01:17:48.280]  не превосходит модуле это.
[01:17:52.280 --> 01:17:53.280]  Вот, хорошо.
[01:17:56.280 --> 01:17:57.280]  Хорошо.
[01:17:57.280 --> 01:17:59.280]  Тогда патиоремия Либега,
[01:17:59.280 --> 01:18:00.280]  точнее, не патиоремия Либега,
[01:18:00.280 --> 01:18:02.280]  а по пункту 8.
[01:18:02.280 --> 01:18:04.280]  По свойству 8.
[01:18:07.280 --> 01:18:10.280]  Мы с вами знаем, что
[01:18:10.280 --> 01:18:14.280]  мотожидание
[01:18:17.280 --> 01:18:21.280]  кси на это-эн, при условии g,
[01:18:21.280 --> 01:18:23.280]  стремится к мотожиданию
[01:18:23.280 --> 01:18:25.280]  кси на это, при условии g.
[01:18:30.280 --> 01:18:32.280]  Да, так как это-эн
[01:18:32.280 --> 01:18:34.280]  стремятся к это,
[01:18:34.280 --> 01:18:36.280]  то тоже самое верно
[01:18:36.280 --> 01:18:38.280]  и для кси это-эн.
[01:18:38.280 --> 01:18:40.280]  Да, мы знаем, что кси это...
[01:18:40.280 --> 01:18:42.280]  Только, извините, у нас же
[01:18:42.280 --> 01:18:44.280]  в условиях пункта 8
[01:18:44.280 --> 01:18:46.280]  нужно, чтобы модуль это-эн
[01:18:46.280 --> 01:18:48.280]  был меньше равен чем это.
[01:18:48.280 --> 01:18:50.280]  Может быть, там все-таки стоит
[01:18:50.280 --> 01:18:52.280]  это взять, не отрицательно.
[01:18:52.280 --> 01:18:54.280]  Сейчас, подождите, смотрите.
[01:18:56.280 --> 01:18:58.280]  Во-первых, у нас есть сходимость
[01:18:58.280 --> 01:19:00.280]  почти наверно, и вот это.
[01:19:00.280 --> 01:19:02.280]  Во-вторых, у нас есть, что модуль кси
[01:19:02.280 --> 01:19:04.280]  на это-эн меньше либо равно,
[01:19:04.280 --> 01:19:06.280]  чем модуль кси на это.
[01:19:06.280 --> 01:19:08.280]  И в-третьих, у нас есть, что мы от
[01:19:08.280 --> 01:19:10.280]  ожидания модуля кси это-эн меньше бесконечности.
[01:19:14.280 --> 01:19:16.280]  Да, так сказал Уско.
[01:19:18.280 --> 01:19:20.280]  Этого достаточно, чтобы делать
[01:19:20.280 --> 01:19:22.280]  утверждение про сходимость модуля к модулю,
[01:19:22.280 --> 01:19:24.280]  но для сходимости
[01:19:24.280 --> 01:19:26.280]  самих величин к...
[01:19:28.280 --> 01:19:30.280]  Вот я же говорю,
[01:19:30.280 --> 01:19:32.280]  можете промотать вверх до условий
[01:19:32.280 --> 01:19:34.280]  8-го звезда.
[01:19:34.280 --> 01:19:36.280]  Там должно быть, чтобы модуль кси
[01:19:36.280 --> 01:19:38.280]  это был меньше или равен самого это,
[01:19:38.280 --> 01:19:40.280]  а не его модуле.
[01:19:40.280 --> 01:19:42.280]  Что такое само это? Здесь это какая-то
[01:19:42.280 --> 01:19:44.280]  случайная вещь. Наоборот, должно существовать.
[01:19:44.280 --> 01:19:46.280]  Она никак не связана со всем, что
[01:19:46.280 --> 01:19:48.280]  написано в остальных местах.
[01:19:48.280 --> 01:19:50.280]  То есть, давайте вместо это
[01:19:50.280 --> 01:19:52.280]  напишем большое...
[01:19:58.280 --> 01:20:00.280]  Да, значит, хорошо.
[01:20:00.280 --> 01:20:02.280]  Вот есть такая сходимость.
[01:20:02.280 --> 01:20:04.280]  Теперь что? Теперь
[01:20:04.280 --> 01:20:06.280]  по уже доказанному выше,
[01:20:06.280 --> 01:20:08.280]  по предыдущему пункту мы знаем,
[01:20:08.280 --> 01:20:10.280]  что мод ожидания кси
[01:20:10.280 --> 01:20:12.280]  на это-эн при условии g
[01:20:12.280 --> 01:20:14.280]  совпадает с это-эн
[01:20:14.280 --> 01:20:16.280]  на мод ожидания кси при условии g.
[01:20:16.280 --> 01:20:18.280]  Это мы в предыдущем пункте доказали.
[01:20:20.280 --> 01:20:22.280]  С другой стороны, левая часть этого неравенства
[01:20:22.280 --> 01:20:24.280]  стремится...
[01:20:26.280 --> 01:20:28.280]  Здесь везде имеет в виду
[01:20:28.280 --> 01:20:30.280]  почти наверно стремится.
[01:20:30.280 --> 01:20:32.280]  Я вот набишу на стрелочкуinto здесь
[01:20:32.280 --> 01:20:34.280]  почти наверно. То есть, имею в виду, что
[01:20:34.280 --> 01:20:35.280]  вероятность этойiderman Rubies
[01:20:35.280 --> 01:20:36.280]  стремится к единице.
[01:20:36.280 --> 01:20:38.280]  Также здесь надо было написать...
[01:20:40.280 --> 01:20:42.280]  Прошу прощения.
[01:20:42.280 --> 01:20:44.280]  С вероятностью 1 стремится
[01:20:44.280 --> 01:20:46.280]  или иными словами, вероятность
[01:20:46.280 --> 01:20:48.280]  стремление равна единице здесь тоже самое.
[01:20:48.280 --> 01:20:50.280]  Когда я пишу на стрелочке почти наверно,
[01:20:50.280 --> 01:20:52.280]  я имею в виду, что вероятность этой
[01:20:52.280 --> 01:20:54.280]  сходимости равна единице.
[01:20:54.280 --> 01:20:56.280]  Левая часть этого неравенства почти наверно
[01:20:56.280 --> 01:20:58.280]  стремится по моду от kslov custom
[01:20:58.280 --> 01:21:04.680]  кроме того мы знаем что это n стремится к это мы так выбрали поэтому правой части равенства тоже
[01:21:04.680 --> 01:21:10.920]  почти наверное даже без почти наверное вообще по точечно стремится к это нам от ожидания x при
[01:21:10.920 --> 01:21:17.720]  условии g, ну а значит есть разница с вероятностью единицы да значит из этого сходу следует то что
[01:21:17.720 --> 01:21:25.000]  нам нужно от ожидания x это при условии g совпадает с это умножить нам от ожидания x при условии g что и
[01:21:25.000 --> 01:21:35.080]  требуется. Есть какие-то вопросы?
[01:21:45.080 --> 01:21:50.520]  Так, ну вот это все свойства которые я хотел рассказать, хотел еще успеть разобрать пример
[01:21:50.520 --> 01:21:56.160]  с применением всех этих свойств но уже разберем в следующий раз на ближайших семинарах не знаю у кого-то
[01:21:56.160 --> 01:22:02.040]  там контрольная сперва у кого-то условным от ожидания сперва вы будете разбирать примеры на
[01:22:02.040 --> 01:22:08.360]  применение этих свойств ну и мы на следующей лекции тоже такой пример разберем так если есть еще
[01:22:09.360 --> 01:22:17.160]  Можно по прошлой лекции один вопросик? Да, пожалуйста. Можете открыть вот неравенство Маркова, по-моему? Да,
[01:22:17.160 --> 01:22:27.960]  пожалуйста. Вот мы там когда считаем мат ожидания сейчас вот первое исследование вот у нас тут
[01:22:27.960 --> 01:22:37.560]  получается типа переход от мат ожидания к вероятности? Да, это вот это равенство. А где мы
[01:22:37.560 --> 01:22:44.440]  его вводили? Ну то есть мы писали типа барреливская функция, да? Ну было свойство для
[01:22:44.440 --> 01:22:52.680]  барреливской функции, это оно? Вы спрашиваете почему это равенство верно? Ну я понимаю это у нас
[01:22:52.680 --> 01:22:58.600]  вроде было во витме, но я просто не нашел где мы здесь это обозначали. Сейчас, подождите значит не
[01:22:58.600 --> 01:23:03.120]  всем понимаю чего говорить про барреливские функции здесь очень простая мысль здесь берется мат
[01:23:03.120 --> 01:23:09.200]  ожидания от случайной величины, которая понимает два значения 0 и а. То есть это простая функция. А,
[01:23:09.200 --> 01:23:22.040]  ну да, окей. Ну хорошо. Окей? Да, да. Ага, еще какие-то вопросы? Можете еще раз я просто не всем
[01:23:22.040 --> 01:23:30.000]  понял вначале, чем все-таки нужна нужна условная мат ожидания, то есть что она отражает вот как
[01:23:30.000 --> 01:23:42.120]  случайная величина? Интуиция условного мат ожидания, да? Да. Ну вот помните я в конце прошлой лекции
[01:23:42.120 --> 01:23:49.680]  пытался как-то это пояснить. Вот давайте представим себе такую ситуацию, что вы пытаетесь заработать на
[01:23:49.680 --> 01:23:56.800]  каком-то финансовом инструменте, ну например на акциях. Вы торгуете, продаете, покупаете акции и
[01:23:56.800 --> 01:24:04.120]  следите за тем, как изменяется цена акции во время. Вы естественно на основании ее изменения делать
[01:24:04.120 --> 01:24:12.560]  какой-то прогноз. Ну например вы целый год следили за ее ценой и вот у вас есть эта история длиной в
[01:24:12.560 --> 01:24:17.000]  год и вы там делаете прогноз, не знаю, на ближайшую неделю скажем. Вы говорите ну окей, значит у меня
[01:24:17.000 --> 01:24:21.480]  есть вот эта вот история длиной в год. Я теперь скажу, что через неделю цена акции будет такой.
[01:24:21.480 --> 01:24:29.360]  Получается, что ваш прогноз, какая цена акции будет через неделю, зависит от того какая была
[01:24:29.360 --> 01:24:33.560]  история длиной в год. Если история такая, будет одна цена, если другая история, то будет другая
[01:24:33.560 --> 01:24:47.600]  цена. Вы тем самым, вы усредняете, вы усредняете значение вашего актива через неделю при условии
[01:24:47.600 --> 01:24:53.760]  того, что вы знаете, какое оно было за последний год. И получается, что цена вашего актива через неделю
[01:24:53.760 --> 01:25:01.360]  это функция вот этой истории. История одна, средняя цена через неделю будет одна. История другая,
[01:25:01.360 --> 01:25:06.040]  средняя цена через неделю будет другая. То есть вы получаете функцию от истории. Теперь если
[01:25:06.040 --> 01:25:13.640]  вы считаете, что ваша история, все возможные истории, которые вообще бывают вот за один год,
[01:25:13.640 --> 01:25:21.640]  это множество элементарных исходов, ваши элементарные исходы, это все возможные истории,
[01:25:21.640 --> 01:25:27.920]  которые были через год. Вы тем самым, усредняете значение вашей случайной величины через неделю
[01:25:27.920 --> 01:25:35.360]  при условии сигма-алгебры, порожденной вот этими всеми историями. И в зависимости от того, как та или
[01:25:35.360 --> 01:25:41.120]  иная история, вы получаете разное функцию. Вы получаете новую случайную величину, которая равна
[01:25:41.120 --> 01:25:48.280]  среднему значению вашей акции через неделю при условии того, какое было значение за последний год.
[01:25:48.280 --> 01:25:56.960]  Сейчас, а мы же сигма-алгебру можем выбирать разную? Разную. Вот как выбор сигма-алгебры
[01:25:56.960 --> 01:26:05.960]  соотносится с заданием последней истории? Значит, это сигма-алгебра, которая порождена всеми
[01:26:05.960 --> 01:26:14.040]  возможными историями. Представьте, что ваша история – это случайный процесс. То есть,
[01:26:14.040 --> 01:26:20.360]  у вас есть случайный процесс, который равен значению цены акции за последний год. И вы
[01:26:20.360 --> 01:26:26.920]  рассматриваете сигма-алгебру, порожденную этим случайным процессом. То есть, вы рассматриваете
[01:26:26.920 --> 01:26:38.600]  прообразы всех бареллевских множеств в смысле вашего случайного процесса. У нас понятий
[01:26:38.600 --> 01:26:46.000]  случайных процессов не было, но если говорить формально, то есть у вас отрезок длиной в год.
[01:26:46.000 --> 01:26:53.960]  У вас на этом отрезке задано значение случайного вашего процесса. Это значение акции. Время меняется
[01:26:53.960 --> 01:26:59.880]  от 0 до единицы, в том смысле, что в течение года. Вы смотрите на самом деле в вашу сигму-алгебр
[01:26:59.880 --> 01:27:17.640]  g. Это будут всевозможные прообразы. Вы будете брать x t1 в минус 1 от b1 пересечь x tn в минус 1
[01:27:17.640 --> 01:27:29.080]  от bn по всем возможным моментам времени от 0 до единицы и по всем возможным бареллевским b1 bn,
[01:27:29.080 --> 01:27:37.160]  еще и по всем возможным натуральным числам n. Вот это будет не что иное, как сигма-алгебра,
[01:27:37.160 --> 01:27:46.400]  которая содержит всю вашу историю. То есть, это информация о том, какая у вас была цена
[01:27:46.400 --> 01:27:52.240]  акции за последний год. Если вы относительно нее усредните, значение, теперь вы берете x t
[01:27:52.240 --> 01:28:01.040]  плюс epsilon, это значение вашей акции через неделю относительно x1. Это значение вашей
[01:28:01.040 --> 01:28:08.240]  акции через неделю после того, как прошел год, и усредняете ее относительно g. Вы получите в
[01:28:08.240 --> 01:28:13.400]  точности, условным от ожидания при условии того, какая у вас была цена акции за последний год.
[01:28:14.400 --> 01:28:24.320]  Вы знаете целиком значение график цены акции за последний год. Более на пальцах, то есть,
[01:28:24.320 --> 01:28:28.040]  если не забегать к случайным процессам, вот я говорил сегодня про кубик. Представьте,
[01:28:28.040 --> 01:28:34.280]  что вы сначала бросаете кубик, и вам говорят, вот вы сидите в одной комнате, а в другой комнате
[01:28:34.280 --> 01:28:38.560]  человек бросает кубик. Этот человек очень честно бросает кубик, смотрит и говорит,
[01:28:38.560 --> 01:28:42.720]  четное число выпало или нечетное. И вот это будет информация, которую вы обладаете,
[01:28:42.720 --> 01:28:49.920]  четное или нечетное число выпало. Это будет ваш сигма алгебра, которая состоит из двух подножеств,
[01:28:49.920 --> 01:28:55.160]  наименьше сигма алгебра, прошу прощения, которая порождена разбиением, состоящим из двух подножеств,
[01:28:55.160 --> 01:29:09.560]  1,35 и 2,46. Если вы будете устранять значение, которое выбыл на кубике при условии сигма алгебра,
[01:29:09.560 --> 01:29:27.080]  то получите 3 на индикатор нечетности плюс 4 на индикатор черности. Понятно более-менее?
[01:29:27.080 --> 01:29:39.480]  Кажется, да. Получается, элементарный исход, который мы подставляем, чтобы получить
[01:29:39.480 --> 01:29:48.640]  значение предсказания, это соответственно вот то, что последнее выпало, четное или нечетное?
[01:29:48.640 --> 01:29:53.600]  Наверное правильнее говорить не элементарный исход. Мне тоже иногда говорили элементарный,
[01:29:53.600 --> 01:30:00.240]  элементарный исход это вообще все, это 1,3,5,2,4,6. Это скорее атомарный исход. У нас есть атомы,
[01:30:00.240 --> 01:30:07.960]  это множество, которые наш сигмал алгебру порождают, и тогда да, это либо нечетное выпадение
[01:30:08.040 --> 01:30:18.200]  числа, либо нечетное выпадение числа. Ладно, хорошо, я, кажется, понял. Прекрасно. Спасибо.
[01:30:18.200 --> 01:30:27.000]  Не за что. Какие еще вопросы? То есть в этом получается можем условным от ожидания посчитать
[01:30:27.000 --> 01:30:35.320]  еще до того, как узнали, что выпало на кубике, четное или нечетное? Именно в этом и смысл.
[01:30:35.320 --> 01:30:40.720]  То есть вы заранее рассчитываете условным от ожидания при условии всех возможных историй,
[01:30:40.720 --> 01:30:44.400]  а потом уже в зависимости от того, какая история произошла, вы сразу говорите,
[01:30:44.400 --> 01:30:48.600]  а окей, при вот таком значении истории будет вот такое вот значение среднего.
[01:30:48.600 --> 01:30:57.520]  То есть вы заранее делаете прогноз при условии всех возможных событий, которые могли бы произойти.
[01:31:06.320 --> 01:31:08.760]  Так, есть еще какие-то вопросы?
[01:31:08.760 --> 01:31:18.280]  Вопросов нет? Прекрасно. Тогда до встречи следующего суббота. Всем присутствующим спасибо.
