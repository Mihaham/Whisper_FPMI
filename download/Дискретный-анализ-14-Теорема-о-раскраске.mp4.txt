[00:00.000 --> 00:13.080]  Мы разобрались с тем, что такое энтропия, и доказали, что энтропия от нескольких случайных величин
[00:13.080 --> 00:20.280]  не больше, чем сумма отдельных энтропий. С помощью неравенства выпуклости мы в конце это доказали.
[00:21.040 --> 00:33.640]  Я, конечно, могу написать просто само утверждение. Такая теорема была, что энтропия, скажем так, совместного
[00:33.640 --> 00:44.640]  распределения не больше, чем сумма отдельных энтропий. И вот мы хотим как-то с помощью этого
[00:44.640 --> 00:54.960]  замечательного факта умудриться доказать теорему о раскраске. Теорема раскраски, наверное,
[00:54.960 --> 01:13.000]  звучала следующим образом. Пусть h. Совершенно не помню, как я обозначал множество вершин.
[01:13.000 --> 01:21.160]  Может, оно было r с индексом n, но давайте я так и напишу. h это r с индексом n, а тут, наверное,
[01:21.160 --> 01:29.920]  тогда m каллиграфически. E было. Оно всё взаимно заменило, понятное дело. Множество вершин
[01:29.920 --> 01:37.320]  это множество из n элементов. Про D мы знаем, что оно тоже состоит из n элементов, то есть ребер
[01:37.320 --> 01:43.320]  столько же, сколько вершин. Но при этом гиперграф какой угодно, не обязательно однородный. Я еще
[01:43.320 --> 01:48.000]  там рассуждал про матрицу Адамару, у которой гиперграф почти однородный, но всё-таки одно
[01:48.000 --> 02:02.520]  ребро выбивает. Вот есть какой-то произвольный такой гиперграф, тогда существует раскраска rn
[02:02.520 --> 02:27.840]  в красные и синие цвета. Такая, что для любого ребра из E разница между
[02:27.840 --> 02:36.720]  числом его красных и синих вершин
[02:42.040 --> 02:44.600]  не больше, чем что-то типа 11 карнизов.
[02:49.920 --> 02:56.840]  Ну да, известно, что 5 карнизов. Вы увидите, я расскажу основную идею, но я выкладки последние
[02:56.840 --> 03:02.600]  делать не стану, потому что они скучные, суть ясна и запоминать их не имеет никакого смысла.
[03:02.600 --> 03:10.520]  Поэтому вот в эту константу 11 особенно не впериваетесь, так сказать. Ну 11, ну 20,
[03:10.520 --> 03:17.600]  ну 100, неважно. Важно, что корень из n без корни из логарифма, который вытекал из простой оценки,
[03:17.600 --> 03:28.840]  доказанной на прошлой лекции. Что-нибудь помните? Я на прошлой лекции доказал, что если ребер просто
[03:28.840 --> 03:35.160]  какое-то количество m штук, то здесь вот к этому корню из n добавляется еще корень из логарифма
[03:35.160 --> 03:42.040]  m. А тут вот оказывается, что если m равно n, то этот корень из логарифма можно просто убить
[03:42.040 --> 03:47.600]  каким-то образом. И вот убивать мы его будем с помощью в том числе вот этого неравенства для
[03:47.600 --> 03:56.560]  энтропии. Какая-то энтропия будет. Но идея следующая. Давайте докажем вот такую теорему,
[03:56.560 --> 04:04.640]  пускай штрих, как обычно, я их не нумирую. Докажем не совсем пока то, что хотелось бы доказать,
[04:04.640 --> 04:19.480]  а докажем, что вот чего выполнено. Ну, давайте вот так. Все то же самое. Пусть h
[04:19.480 --> 04:40.720]  равняется n, тогда существует неполная раскраска. Сейчас как бы это лучше сказать, чтобы не ковнуть
[04:40.720 --> 04:46.080]  сразу. Да нет, все просто. Существует раскраска, в которой почти все покрашено, но кроме какой-то
[04:46.080 --> 04:49.840]  очень небольшой части. Существует раскраска
[04:54.840 --> 04:55.400]  rn,
[04:57.520 --> 05:09.160]  которой не менее 1, минус 10 в минус 9 степени n вершин
[05:09.160 --> 05:20.960]  покрашены красные и синие цвета. Частичная раскраска, как говорят, красные и синие цвета.
[05:20.960 --> 05:28.840]  Ну а остальные вершины, вообще говоря, условно просто не покрашены. Остальные вершины пока не
[05:28.840 --> 05:35.340]  докрашены. Ни менее, чем столько вершин покрашены в красный, в синий цвета, остальные вершины
[05:35.340 --> 05:45.040]  покрашены нейтрально, не покрашены. Остальные вершины пока не покрашены.
[05:51.040 --> 06:03.820]  Вот, причем снова в каждом ребре для любого омытого S-E разница между числом красных и
[06:03.820 --> 06:23.700]  синих вершин такая, как нужно. Разница между числом красных и синих вершин, ну скажем,
[06:23.700 --> 06:29.500]  не больше чем 10 корней Z. То есть разница хорошая, но некоторые вершины не покрашены,
[06:29.500 --> 06:38.060]  она даже лучше, чем то, что мы хотим в итоге получить. Она оценивается как 10 корней Z. Но какие-то
[06:38.060 --> 06:46.340]  вершины могут быть недокрашены. Понимаете идею? Вот, допустим, мы это доказали. Почти все покрашено,
[06:46.340 --> 06:51.620]  ну почти все не в асимптатическом смысле этого слова, а вот ровно в том, как здесь написано,
[06:51.620 --> 06:58.740]  одна миллиардная доля не покрашена, но зато все остальное покрашено. Вот все остальное покрашено
[06:58.740 --> 07:04.820]  очень хорошо. Как мы будем действовать дальше? Мы возьмем вот эту одну миллиардную от общего
[07:04.820 --> 07:12.020]  числа вершин и попробуем доказать на этой одной миллиардной аналогичный результат. Ну, то есть
[07:12.020 --> 07:17.060]  вот на этой одной миллиардной от общего числа вершин будут какие-то хвостики, недокрашенные
[07:17.060 --> 07:24.140]  хвостики каждого ребра, и мы снова попробуем красить красные и синие цвета, так чтобы различие
[07:24.140 --> 07:29.980]  между количеством красных и синих вершин на каждом из хвостиков, но было уже не 10 корней
[07:29.980 --> 07:36.540]  из N, а там какая-нибудь 1 сотая корня из N. И так будем действовать итеративно, после чего в сумме
[07:36.540 --> 07:46.740]  накопится как раз 11. Ну, разности мы всегда смотрим по модулю, как-то в прошлый раз вы не
[07:46.740 --> 07:52.540]  спросили, но в общем, конечно, это подразумевалось. Но вы можете, да-да-да, понимаете, в одном ребре
[07:52.540 --> 07:57.700]  красных больше, чем синих, в другом синих больше, чем красных, это нормально. Конечно,
[07:57.700 --> 08:04.340]  по модулю, да, то есть вот эта разница, имеется в виду модуль разницы, то всегда так подразумевалось.
[08:04.340 --> 08:14.740]  Сейчас понятно, или нет? Значит, смотрите, я ее целиком, еще раз повторю, я ее целиком не буду
[08:14.740 --> 08:18.780]  реализовывать, и на экзамене, естественно, с вас никто не спросит, вы должны просто понимать,
[08:18.780 --> 08:25.060]  как дело развивается дальше. То есть я не собираюсь доказывать теорему два штриха с оценкой того,
[08:25.060 --> 08:32.340]  насколько разброс велик или мал на вот этой одной миллиардной доле. Абсолютно аналогичное
[08:32.340 --> 08:38.140]  рассуждение там будет работать, но мучить людей на экзамен двумя одинаковыми рассуждениями,
[08:38.140 --> 08:44.660]  чтобы теорема сошлась прямо вот к этим 11, это было бы жестоко. Мне кажется, это не нужно.
[08:44.660 --> 08:50.700]  Главное, чтобы вы понимали, почти все покрасили, ну уже хорошо, даже вот уклонение не слишком
[08:50.700 --> 08:56.540]  большое. Ну, маленький кусочек точно так же покрасим, там уклонение будет сильно меньше,
[08:56.540 --> 09:03.060]  и сумма этих уклонений, она как раз должна докопиться во что-то такое. То есть, короче,
[09:03.060 --> 09:06.820]  еще раз, я вот сейчас эту теорему докажу, а больше ничего доказывать не буду, но смысл,
[09:06.820 --> 09:18.100]  я надеюсь, вы поняли. Или плохо? Поняли, да? Вот, но она уже достаточно катарсисогенная,
[09:18.100 --> 09:27.300]  красивая, замечательная, так что сейчас мы ее и произведем на свет доказательства. Так,
[09:29.300 --> 09:34.500]  ну, во-первых, давайте вспомним, что красный и синий цвета, когда мы работаем вот с этой
[09:34.500 --> 09:40.380]  задачей, мы интерпретировали как плюс и минус единицу просто. То есть, каждой вершине из
[09:40.380 --> 09:47.580]  множества rn, каждому числу от единицы до n, мы присваиваем плюс или минус единичку. Помните,
[09:47.580 --> 09:55.180]  да? Ну, давайте вот, если вершина окажется в итоге не покрашенной, будем считать, что ей присвоен
[09:55.180 --> 10:04.820]  ноль. Плюс единица – это условно красный цвет, минус единица – синий, и ноль – это никак. Просто на
[10:04.820 --> 10:10.780]  будущее, чтобы было понятно. Но пока давайте действовать прямо как в доказательстве теоремы
[10:10.780 --> 10:23.140]  с логарифом. То есть, случайно, в обычном смысле этого слова, покрасим rn. Каждому числу с
[10:23.140 --> 10:29.740]  вероятностью одна вторая присвоим плюс единицу красный цвет или минус единица синий цвет. Никаких
[10:29.740 --> 10:38.900]  нейтральных вершин пока нет. Просто берем обычную случайную раскраску. Четко уясните для себя,
[10:38.900 --> 10:48.500]  что обычная случайная раскраска – это вектор из плюс-минус единицы длины. Вектор из плюс-минус
[10:48.500 --> 10:54.140]  единиц длины. Пока нейтральных вершин нет. Когда-то они в конце появятся. Но вот пока есть
[10:54.140 --> 10:59.220]  случайная раскраска. Целиком все множество покрасили. Все элементы в красные и синие цвета,
[10:59.220 --> 11:04.700]  причем банальные. С вероятностью одна вторая – плюс один, с вероятностью одна вторая – минус один.
[11:04.700 --> 11:14.420]  Так, давайте введем вспомогательные случайные величины. Введем не случайные величины,
[11:14.420 --> 11:28.660]  обозначим их BIT – случайные величины. И здесь от единицы до N. И это номер ребра. BIT
[11:28.660 --> 11:36.100]  отвечает очередному ребру из множества ребр нашего гипрограмма. У нас их N штук – ребр. Поэтому
[11:36.100 --> 11:42.260]  соответствующих величин, которые я сейчас определю, их будет как раз N штук. Так,
[11:42.820 --> 11:47.820]  зависеть они будут, естественно, от раскраски, как случайные величины, на множестве элементарных
[11:47.820 --> 11:54.980]  событий. Раскраска – это элементарное событие. Так, давайте считать, что BIT равняется нулю,
[11:54.980 --> 12:10.140]  если… Сейчас чихну. Уже чихну, сейчас еще чихну. Возможно, не один раз. Так, BIT равняется нулю,
[12:10.140 --> 12:21.100]  если выполнена вот такая вот цепочка неравенств. Ну, давайте где-нибудь сделаем строгий значок,
[12:21.100 --> 12:30.460]  где-то не строгий, чтобы все было однозначно. Вот так вот, если хи от Эмитова лежит вот в таких
[12:30.460 --> 12:45.540]  пределах. Так, что такое хи от Эмитова? Это вот то самое уклонение, которое нас интересует. Это
[12:45.540 --> 12:53.820]  было, конечно, в прошлый раз, но я повторю. Итак, хи от жи – это плюс или минус единица,
[12:53.820 --> 12:59.700]  с вероятностью одна-вторая, и сумма хи от жи по жи из Эмитова – это как раз разница между
[12:59.700 --> 13:07.380]  количеством красных и синих вершин вот в этом конкретном ребре Эмитова. Но в данном случае
[13:07.380 --> 13:14.660]  именно даже не по модулю, а просто разница между красными и синими. Складываем столько плюс единиц,
[13:14.660 --> 13:21.660]  сколько есть красных вершин, и потом вычитаем все сини. Ну вот, если эта разница лежит вот в
[13:21.660 --> 13:27.820]  таких пределах полустрогих, то боитое считаем равной нулю. Ну и дальше двигаемся по таким вот
[13:27.820 --> 13:38.060]  отрезкам длины 20 корней и зен. Пишем 10 корней и зен меньше строку, чем хи от Эмитова меньше
[13:38.060 --> 13:50.220]  либо равно 30 корней и зен. Здесь будет боитое равно единице и так далее, причем в обе стороны.
[13:54.220 --> 14:02.780]  Ну понятно, что хи от Эмитова не может принимать бесконечно много значений. То есть когда-то дело
[14:02.780 --> 14:11.780]  оборвется, но неважно. Так понятно, да, как определено боитое? Очень просто.
[14:11.780 --> 14:21.980]  Так, ну давайте рассмотрим зачем-то. Пока совершенно непонятно зачем. Ну друзья,
[14:21.980 --> 14:26.580]  в конечном счете все будет понятно, но случайные величины понятны как определенно. Давайте
[14:26.580 --> 14:44.900]  рассмотрим их на тропе. Х от боитое. Рассмотрим и оценим. Так, что такое х от боитое? Это минус,
[14:44.900 --> 15:01.220]  минус сумма. Какая у нас будет сумма боитое? Какие значения принимает 0, 1, минус 1? Все целые.
[15:01.220 --> 15:13.740]  Сейчас какой-то вопрос. Тоже самое, да, я вот сюда нарисовал многоточие. Я сказал вот многоточие в
[15:13.740 --> 15:20.460]  обе стороны. То есть если от минус 30 до минус 10, то боитое это минус 1 и так далее. Да-да-да-да. То есть
[15:20.460 --> 15:25.740]  сумма будет формальна от минус бесконечности до бесконечности, но как я сказал, конечно для
[15:25.740 --> 15:32.060]  конкретного n она принимает лишь конечное много значение. Не ограниченное с ростом n, но конечное
[15:32.060 --> 15:38.940]  при каждом конкретном значении n. Как бы тут написать-то по k может быть, да, формально от
[15:38.940 --> 15:46.180]  минус бесконечности до бесконечности будет вероятность того, что боитое равняется k на
[15:46.180 --> 15:56.540]  дворичный логарифом этой же самой вероятности. Ну опять же понятно на самом деле, что можно было
[15:56.540 --> 16:02.140]  суммировать от нуля до бесконечности, вернее даже не так, выделить отдельно слагаемое с нулем,
[16:02.140 --> 16:07.980]  а остальные они одинаковые. Какая разница, уклониться вправо или уклониться влево,
[16:07.980 --> 16:15.540]  как у пьяницы. Все же симметрично, блуждание симметрично. Здесь фактически же блуждание,
[16:15.540 --> 16:22.860]  мы это и в прошлый раз обсуждали, складываются плюс и минус единички. Ну давайте посмотрим.
[16:22.860 --> 16:33.220]  Минус вероятность того, что боитое равно нулю на лог дворичной вероятности того, что боитое
[16:33.220 --> 16:42.580]  равно нулю. Что значит, что боитое равно нулю? Это значит, что модуль хиатемитова не превосходит
[16:42.580 --> 16:49.840]  10 карниза. Давайте я отдельно напишу. Вероятность того, что боитое равно нулю, это вероятность того,
[16:49.840 --> 17:00.660]  что модуль хиатемитова не превосходит 10 карниза. Ну вы можете придраться, наверное, к тому,
[17:00.660 --> 17:14.780]  что здесь значок строго больше, но, но в общем, конечно, это ничего больше либо ровно что-ли?
[17:14.780 --> 17:23.100]  Извините, что-то я не то чихаю, то каждая непростуженно, совершенно что-то попало.
[17:23.100 --> 17:32.340]  Как это называется? Поняли, что я написал? Что здесь не совсем равенство, потому что здесь вот я
[17:32.340 --> 17:39.020]  старался, вроде как, разделал не крепекающиеся отрядки. В какую сторону неравенство-то получается?
[17:39.020 --> 17:44.900]  Если здесь я написал меньше либо равно, я могу здесь меньше написать, тогда будет в одну сторону.
[17:44.900 --> 17:50.380]  Могу написать меньше либо равно, тогда в другую. Так, в какую сторону сейчас неравенство? Я хочу,
[17:50.380 --> 17:57.780]  чтобы вы участвовали в процессе. Как? Меньше либо равно? Меньше либо равно. А мне что-то кажется,
[17:57.780 --> 18:09.260]  что мне лучше будет, чтобы было больше либо равно. Давайте я вот так вот. Ну, теперь это есть
[18:09.260 --> 18:22.900]  единица минус вероятность того, что модуль h от m и t больше либо равен 10 корней z. Это просто
[18:22.900 --> 18:29.880]  отрицание написал. Ну, а это снова неравенство большого уклонения, которое с e в степени. Мы в
[18:29.880 --> 18:35.300]  прошлый раз вспоминали как раз про пьяница, которая далеко уходит от кабака с ничтожно маленькой
[18:35.300 --> 18:49.060]  вероятностью. Это будет больше либо равно, чем единица минус 2e в степени минус 100n поделить на что?
[18:49.060 --> 19:01.100]  На 2n, да? Ну ладно, нет, я нормально пишу. На удвоенную мощность m. На удвоенную мощность m.
[19:05.300 --> 19:11.380]  Сейчас правильно? По-моему, правильно. Что, забыли уже за неделю неравенство большого уклонения?
[19:11.380 --> 19:19.020]  Ну, там e в степени минус a квадрат поделить на 2n, где n это количество слагаемых. Ну,
[19:19.020 --> 19:24.620]  сейчас у нас слагаемых столько, сколько элементов в множестве мытое. Вот столько будет слагаемых.
[19:24.620 --> 19:32.020]  Вот. Больше либо равно. Ну, понятно, потому что вероятность не больше, чем вот это удвоенное,
[19:32.020 --> 19:38.880]  потому что тут модуль. Без модуля была бы просто экспонента, а двойка за счет того,
[19:38.880 --> 19:47.620]  что модуль сразу. Так, мощность мытого точно не превосходит n, не превосходит, значит переворачиваем
[19:47.620 --> 19:53.140]  больше либо равно, с минусом меньше либо равно, с этим минусом все правильно, больше либо равно.
[19:53.140 --> 20:01.540]  Снак неравенства в нужную сторону, поэтому я могу написать, что это больше либо равно 1-2e в степени
[20:01.540 --> 20:12.660]  просто минус 50. Заменяем на n, n сокращается. Ну, очень близкая клиниция, вероятно, что?
[20:17.500 --> 20:24.140]  10-9 Поршу будет совершенно неожиданным образом, вы пока не догадаетесь. Это не 10-9, нет. Вы
[20:24.140 --> 20:28.340]  пока даже не догадываетесь, как я собираюсь применить. Это там катарсис будет, если вы все
[20:28.340 --> 20:35.260]  поймете. Это совершенно неожиданно. Сейчас пока, я уверен, вы не понимаете. Это не 10-9,
[20:35.260 --> 20:41.100]  это конечно гораздо меньше. Но это меньше, а само-то оно близко к единице. Смотрите,
[20:41.100 --> 20:49.100]  как устроена функция энтропии. Вот на отрезке от нуля до единицы, на котором находится значение
[20:49.100 --> 20:55.420]  вероятности. Так, друзья, функция энтропии в смысле как функция от вероятности. Она устроена
[20:55.420 --> 21:05.020]  вот так. Ее максимум в 1 и 2, и она в нуле ноль, и в единице ноль. Ну, я надеюсь,
[21:05.020 --> 21:12.060]  это можно сообразить без подробных пояснений. То есть, если мы знаем, что вероятность больше
[21:12.060 --> 21:18.780]  либо равна чего-то очень близкого к единице, то это значит, что сама энтропия не превосходит
[21:18.780 --> 21:37.180]  своего значения в точке равной вот это. Вот это. Вот не больше, чем там минус. Вот, минус 1 на 2e в
[21:37.180 --> 21:47.420]  минус 50, на лог двоичный вот 1 минус 2e в минус 50. Она в этом месте уже убывает. Поэтому, если мы
[21:47.420 --> 21:55.700]  написали неравенство в эту сторону, то сама энтропия в эту оценивается. Ну, при этом вы понимаете,
[21:55.700 --> 22:00.220]  конечно, что этот логарифм отрицательный. Соответственно, с минусом там получается
[22:00.220 --> 22:08.460]  положительное число. Но это положительное число ничтожно маленькое. Ну, я с вашего позволения не
[22:08.460 --> 22:13.860]  буду вспоминать, чему оно равно. Я и не помню. Ну, если вы хотите, вы можете посчитать на
[22:13.860 --> 22:22.700]  калькуляторе. Оно очень-очень маленькое. Хорошо. Мы разобрались с центральным слагаемым в этой
[22:22.700 --> 22:30.060]  бесконечной в обе стороны сумме. Теперь посмотрим на слагаемые с положительными k. Все остальные
[22:30.060 --> 22:36.060]  слагаемые им симметрично, то есть дают там какой-то удвоение. Ну, вот берем, например, слагаемое с k
[22:36.500 --> 22:41.940]  равном единице. У нас получается минус вероятность того, что bit равно единице,
[22:41.940 --> 22:51.660]  на лог-двоичной вероятность того что bit равно единице. Что такое вероятность того что bit
[22:51.660 --> 22:58.740]  равно единице. Вот, давайте я тут führt, с того что bit равно единице это вероятность
[22:58.740 --> 23:01.580]  того, что хи от эму те лежит вот в этом полуинтервале.
[23:01.580 --> 23:09.060]  Ну, это уж точно не больше, чем вероятность того, что
[23:09.060 --> 23:16.500]  хи от эму те больше, чем 10 корней z.
[23:16.500 --> 23:21.180]  Я опускаю вот это вот ограничение, оставляя только нижнюю
[23:21.180 --> 23:22.180]  границу.
[23:22.180 --> 23:25.620]  Снова пользуюсь неравенством большого уклонения с
[23:25.620 --> 23:30.020]  пьяницей и получаю, что это не превосходит не в степени
[23:30.020 --> 23:33.020]  минус 50.
[23:33.020 --> 23:36.580]  Прям вот пьяница в чистом виде.
[23:36.580 --> 23:39.460]  Ну точно так же оцениваю как здесь, но только уже
[23:39.460 --> 23:43.060]  теперь сверху, а не снизу.
[23:43.060 --> 23:46.820]  Но опять, пользуясь вот этой картинкой, раз у меня
[23:46.820 --> 23:50.260]  вероятность очень маленькая, значит энтропия тоже очень
[23:50.260 --> 23:51.260]  маленькая.
[23:51.260 --> 23:54.020]  Она оценивается путем подстановки этой величины
[23:54.020 --> 23:56.940]  Вот в эту, вот какую там формулу где она?
[23:56.940 --> 23:57.940]  Вот в эту формулу, да?
[23:57.940 --> 23:59.900]  А, вот в эту все, нашелась.
[23:59.900 --> 24:04.780]  Вот, она не превосходит минус, e в минус 50.
[24:04.780 --> 24:06.900]  Заметьте, двойки тут нет, потому что модуля нет.
[24:06.900 --> 24:14.540]  Ну, не важно, e в минус 50, налог двоичный, e в минус
[24:14.540 --> 24:15.540]  50.
[24:15.540 --> 24:17.900]  Это снова ничтожно, маленькая, конечно, положительная
[24:17.900 --> 24:20.900]  величина.
[24:20.900 --> 24:25.540]  А дальше они убывают в какой-то геометрической прогрессии,
[24:25.540 --> 24:27.500]  если не хлеще того.
[24:27.500 --> 24:30.580]  То есть, когда вы на следующий шаг переходите, что там
[24:30.580 --> 24:31.580]  получается?
[24:31.580 --> 24:32.580]  E в какой степени?
[24:32.580 --> 24:38.180]  Можете быстро сообразить в уме?
[24:38.180 --> 24:41.740]  Минус 450, абсолютно верно, но понимаете.
[24:41.740 --> 24:45.780]  То есть, вот здесь e в минус 50 на что-то, а следующее
[24:45.780 --> 24:49.700]  слагаемое это e в минус 450, ну там на что-то может чуть
[24:49.700 --> 24:54.340]  побольше, но все равно.
[24:54.340 --> 24:57.420]  Бешенно сходящийся ряд.
[24:57.420 --> 25:01.700]  Вот этот ряд, бешенно сходящийся, состоит из очень маленьких
[25:01.700 --> 25:02.700]  величин.
[25:02.700 --> 25:08.900]  То есть, короче, у нас получается, что это меньше либо равно
[25:08.900 --> 25:13.020]  некоторого epsilon, которое можно вычислить, ну или оценить
[25:13.020 --> 25:16.900]  там на компьютере руками, как угодно, я помню, что
[25:16.900 --> 25:21.060]  это 3 на 10 минус 20.
[25:21.060 --> 25:27.140]  Ну, вы можете в это просто поверить, естественно,
[25:27.140 --> 25:30.740]  ни один человек на экзамене не потребуется вас доказывать,
[25:30.740 --> 25:36.100]  что именно 10 минус 20, да на 3.
[25:36.100 --> 25:38.300]  Если вы очень герливы, вы можете попробовать запустить
[25:38.300 --> 25:40.460]  компьютер и проверить, а то вдруг я ошибся.
[25:40.460 --> 25:44.020]  Меня еще пока ни разу не поправлял никто, но это
[25:44.020 --> 25:46.980]  совершенно не значит, что я ни разу не ошибался.
[25:46.980 --> 25:49.780]  Вполне возможно, я каждый год рассказываю 3 на 10 минус
[25:49.780 --> 25:51.340]  20 и каждый год лажаю.
[25:51.340 --> 25:57.300]  Но смысл от этого не меняется, пусть не 3 на 10 минус 20,
[25:57.300 --> 26:01.500]  пусть 2 на 10 минус 19, может быть там в итоге тогда получится
[26:01.500 --> 26:04.900]  не 10 минус 9, а что-то другое, но все равно все в итоге
[26:04.900 --> 26:08.540]  сойдется просто не к 11, а к 20 скажешь.
[26:08.540 --> 26:11.220]  Главное, чтобы вы суть поняли, доказательство, понимаете,
[26:11.460 --> 26:16.460]  выкладки, они никому особо не интересны, но я для определенности
[26:16.460 --> 26:19.420]  просто пишу и вроде бы это правильное, вроде бы это
[26:19.420 --> 26:20.420]  правильное.
[26:20.420 --> 26:24.940]  Ну, товарищи, воспользуемся вот этой теоремой, из нее
[26:24.940 --> 26:29.940]  следует, что энтропия от вектора с координатами
[26:29.940 --> 26:34.540]  b1 и так далее bn не превосходит эпсалону множительной.
[26:34.540 --> 26:39.860]  Эпсалон это вот то сам, 3 на 10 минус 20, пользуемся вот
[26:39.860 --> 26:41.100]  этой субоддитивности.
[26:41.100 --> 26:47.380]  Так, ну, что бы из этого следовало?
[26:47.380 --> 26:51.260]  Я утверждаю, что из этого вот чего следует.
[26:51.260 --> 26:58.180]  Следует, что существует набор конкретных значений
[26:58.180 --> 27:08.380]  s1, s2 для вот этих случайных величин такой, что вероятность,
[27:08.380 --> 27:15.260]  при которой случайный вектор b1, bn принимает именно этот
[27:15.260 --> 27:19.900]  векторный набор значений, больше либо равна 2 в скепени
[27:19.900 --> 27:22.380]  1 минус эпсалон умножительная.
[27:22.380 --> 27:29.380]  Ну, это я сейчас подробно поясню, это почти очевидно,
[27:29.380 --> 27:32.420]  на самом деле, просто из определения энтропии, но
[27:32.420 --> 27:36.620]  на всякий случай я аккуратно поясню, предположим, противно.
[27:36.620 --> 27:47.220]  Предположим, что все такие вероятности b1, bn равняется
[27:47.220 --> 27:51.500]  чему-то меньше, чем 2 в скепени 1 минус эпсалон.
[27:51.500 --> 27:57.140]  Так, нет, наверное, не один минус эпсалон.
[27:57.140 --> 28:02.780]  Вероятность, я не прав, вероятность 2 в скепени минус эпсалон
[28:02.780 --> 28:10.020]  просто 2 в скепени, ой, черт, вот так вот, конечно, поторопился,
[28:10.020 --> 28:15.660]  вот так, один минус появится чуть позже, он появится,
[28:15.660 --> 28:18.700]  но в другом контексте, сейчас сразу после этого
[28:18.700 --> 28:21.100]  появится, предположим, что все вероятности совсем
[28:21.100 --> 28:32.100]  меньше, чем 2 в скепени минус эпсалон, но тогда энтропия
[28:32.100 --> 28:39.340]  этого вектора b1, bn, ну, она, естественно, равна минус
[28:39.340 --> 28:48.500]  сумма вот этих самых вероятностей, b1, bn, равно там чему-то, умноженных
[28:48.500 --> 28:55.660]  на логарифум двоичный тех же самых вероятностей,
[28:55.660 --> 28:58.980]  b1, bn равно чему-то.
[28:59.660 --> 29:03.620]  Так, и мы предположили, что вероятность меньше, чем 2 в
[29:03.620 --> 29:11.020]  степени минус эпсалон n, но давайте вот сюда эту оценку
[29:11.020 --> 29:18.260]  подставим, под логарифум, только под логарифум, мы
[29:18.260 --> 29:20.900]  же предположили, что все вероятности меньше, чем 2
[29:20.900 --> 29:24.220]  в минус эпсалон n, значит, под логарифум стоит величина
[29:24.220 --> 29:28.500]  меньше, чем 2 в скепени минус эпсалон n, то есть логарифум
[29:28.500 --> 29:34.460]  меньше, чем минус эпсалон n, успеваете, да, но он со
[29:34.460 --> 29:37.620]  знаком минус, поэтому все получается строго больше,
[29:37.620 --> 29:43.380]  чем эпсалон n на сумму вероятностей, ну, сумма вероятностей
[29:43.380 --> 29:44.380]  равна единице.
[29:44.380 --> 29:51.300]  Вот это вот, это просто один противоречие с тем, что
[29:51.300 --> 29:52.300]  мы здесь вот имеем.
[29:54.700 --> 29:59.060]  То есть это очевидное неравенство вот это вот, но я подробно
[29:59.060 --> 30:00.060]  про это поясню.
[30:04.540 --> 30:08.940]  Итак, существует конкретный набор значений, которые
[30:08.940 --> 30:12.180]  случайный вектор принимает с сравнительно большой
[30:12.180 --> 30:14.620]  вероятностью, больше либо равны 2 в степени минус
[30:14.620 --> 30:15.620]  эпсалон n.
[30:15.620 --> 30:20.500]  Вот сейчас будет 1 минус эпсалон, смотрите, тут написать
[30:20.500 --> 30:25.580]  нет, тут написать нет, тут, ну, знаете, вот тут нормально.
[30:25.580 --> 30:28.260]  Определение пока стирать не буду, оно может пригодиться
[30:28.260 --> 30:35.300]  попозже, а вот это можно, можно стереть, сейчас отчертим
[30:35.300 --> 30:39.620]  верхнюю часть доски используем, что из этого следует.
[30:39.620 --> 30:43.620]  Смотрите, ну, что такое вероятность в нашем-то случае.
[30:43.620 --> 30:46.660]  У нас же раскраска-то случайная, в смысле, что каждый цвет
[30:46.660 --> 30:50.060]  присваивается независимо от другого, с вероятностью
[30:50.060 --> 30:55.500]  одна-вторая, но если это же вероятность множества
[30:55.500 --> 31:00.180]  каких-то раскрасок, правда, ну, то есть в знаменателе
[31:00.180 --> 31:05.700]  там стоит 2 в степени n в определении этой вероятности.
[31:05.700 --> 31:09.220]  Давайте перейдем обратно к количествам, от вероятностей
[31:09.220 --> 31:10.220]  к количествам.
[31:10.220 --> 31:15.700]  Если вероятность равномерная, это классическая вероятность
[31:15.700 --> 31:20.020]  чего-то больше либо равна, значит тех объектов, которые
[31:20.020 --> 31:24.100]  считает эта вероятность, не меньше, чем вот это число
[31:24.100 --> 31:32.180]  умножить на 2 в степени, то есть получается, что существует
[31:32.180 --> 31:37.620]  не менее 2 в степени, вот, наконец, 1 минус епсилон
[31:37.620 --> 32:00.140]  на n раскрасок, для которых вектор b1 и так далее bn принимает
[32:00.140 --> 32:12.300]  одно и то же значение, вот какой вывод.
[32:12.300 --> 32:16.620]  А раскраски, напоминаю, это векторы из плюс-минус
[32:16.620 --> 32:22.340]  единиц размерности n, раскраска это вектор с плюс-минус единиц
[32:22.340 --> 32:26.300]  размерности n, и вот у нас есть огромное на самом деле
[32:26.300 --> 32:29.020]  множество раскрасок в каком-то смысле, ну, как бы почти
[32:29.020 --> 32:32.820]  все не совсем корректно так говорить, но и 3 на 10
[32:32.820 --> 32:37.460]  минус 20 всего раскрасок 2 в n степени, а тут их 2 в
[32:37.460 --> 32:43.660]  степени 1 минус вот эта фигня умножить на n, то есть очень-очень
[32:43.660 --> 32:48.300]  жирное множество векторов из плюс-минус единиц, на
[32:48.300 --> 32:51.860]  которых при этом все вот эти значения, я их специально
[32:51.860 --> 32:54.820]  не стирал, одинаковые, на каждом из которых все эти
[32:54.820 --> 33:00.700]  значения одинаковые, понятно я говорю?
[33:00.700 --> 33:02.820]  Может быть вот теперь уже, может быть кто-то понимает
[33:02.820 --> 33:09.580]  к чему дело идет, не знаю, я неоднократно в рамках
[33:09.580 --> 33:12.580]  этого двухгодичного курса рассказывал про теорию
[33:12.580 --> 33:20.540]  кодирования, помните, нет, на множестве из векторов,
[33:20.540 --> 33:22.620]  которые состоят из двух координат, но обычно это
[33:22.620 --> 33:25.980]  были нолики и единички, но можно и плюс-минус один,
[33:25.980 --> 33:29.860]  можно ввести то, что называется хеммингового расстояния,
[33:29.860 --> 33:32.020]  по идее вы должны помнить, что это такое количество
[33:32.020 --> 33:37.260]  несовпадающих координат, вот давайте его введем, я
[33:37.260 --> 33:39.740]  сейчас вот здесь сотру, это уже ничего не нужно, давайте
[33:39.740 --> 33:46.700]  снабдим 2 в степени n последовательностей расстоянием хемминга,
[33:46.700 --> 33:50.980]  но это все поняли, это я писать не буду, теперь смотрите,
[33:50.980 --> 33:59.980]  вот допустим, сейчас будет некий факт без доказательства,
[33:59.980 --> 34:03.180]  но интуитивно понятный, я его оставлю просто без
[34:03.180 --> 34:14.260]  доказательства, много сил не тратит ваше, допустим,
[34:14.260 --> 34:34.660]  есть какое-то множество, зовем его а, раскрасок, ну
[34:34.660 --> 34:40.580]  или что то же самое векторов из плюс-минус единиц, векторов
[34:40.580 --> 34:54.900]  из плюс-минус единиц, есть какое-то множество, в котором
[34:54.900 --> 35:10.380]  любые две точки отстоят друг от друга, отстоят друг
[35:10.380 --> 35:20.460]  от друга на расстояние хемминга, который мы обсуждали,
[35:20.460 --> 35:27.140]  на расстояние хемминга, не превосходящее ну скажем
[35:27.140 --> 35:32.860]  какого-нибудь d, ну вот мы знаем про некоторое множество
[35:32.860 --> 35:36.180]  раскрасок, что каждые две раскраски в нем, как вектор
[35:36.180 --> 35:39.660]  из плюс-минус единиц, находятся друг от друга на хемминговом
[35:39.660 --> 35:48.100]  расстоянии не больше чем d, как вы думаете, как можно
[35:48.100 --> 35:52.660]  тогда мощность а оценить, чем можно оценить мощность
[35:52.660 --> 35:56.580]  а, то есть по-другому говоря, если дан диаметр множества,
[35:56.580 --> 36:00.500]  ну вот эта вот граница, это граница на диаметр множества,
[36:00.500 --> 36:04.380]  максимальное расстояние между точками в нем, то
[36:04.380 --> 36:07.980]  чего объем этого множества, ну объем в комбинаторном
[36:07.980 --> 36:11.740]  смысле, мощности, не превосходит заведомо, какое множество
[36:11.740 --> 36:18.620]  данного диаметра самое жирное, самое объемное, а, нет,
[36:18.620 --> 36:23.140]  ну два в степени это много, какое множество самое объемное
[36:23.140 --> 36:26.740]  все-таки еще раз, вот в обычном пространстве, как вы думаете,
[36:26.740 --> 36:30.580]  какое множество самое объемное, если данного диаметра, ну
[36:30.580 --> 36:35.700]  шар наверное, интуитивно это должно быть понятно,
[36:35.740 --> 36:38.820]  давайте не будем с вас требовать доказательства этого, в комбинаторном
[36:38.820 --> 36:41.460]  случае это не очень сложно, это можно сделать, но я не хочу
[36:41.460 --> 36:46.100]  тратить ваше время и свое тоже, давайте поверим в интуитивно
[36:46.100 --> 36:50.900]  понятную вещь, что если есть какое-то множество с диаметром
[36:50.900 --> 36:54.340]  не большим, чем d, то мощность этого множества не больше,
[36:54.340 --> 37:02.660]  чем мощность шара с диаметром d, я утверждаю, что тогда
[37:02.660 --> 37:12.580]  мощность не больше, чем мощность объема, это не важно,
[37:12.580 --> 37:22.500]  но комбинаторная это мощность, мощность шара, ну давайте я скажу
[37:22.500 --> 37:30.740]  радиус d попала, радиус d попала, так, дорогие товарищи, вы понимаете,
[37:30.820 --> 37:35.460]  что такое мощность шара в комбинаторном смысле, для плюс-минус единичных
[37:35.460 --> 37:39.620]  векторов радиуса d попала, что такое шар, это множество
[37:39.620 --> 37:43.540]  точек, которые от данной отстоят на не более, чем такое расстояние,
[37:43.540 --> 37:49.940]  ну какая разница от какой данной, считайте, например, что она из
[37:49.940 --> 37:54.660]  одних нульней или там из одних плюс единиц, сколько точек
[37:54.660 --> 38:00.180]  отстоят от нее на расстояние ноль, одна, сколько точек отстоит
[38:00.180 --> 38:05.380]  от нее на расстояние один, c и z по одному, надо одну координату поменять,
[38:05.380 --> 38:12.900]  сумма c-шек до вот этой в той сумме, да, то есть это равно просто сумма по
[38:12.900 --> 38:19.540]  какому-нибудь там k от нуля до d пополам, ну или до целой части d пополам,
[38:19.540 --> 38:25.220]  если вдруг не целое число, но понятно, до целой части d пополам, c и z по k,
[38:25.220 --> 38:32.820]  сейчас я достаточно понятен, я не спешу, все успевают,
[38:32.820 --> 38:41.620]  тут я проглотил доказательства на идее ясна, а эту, ну я надеюсь, понятно,
[38:41.620 --> 38:48.980]  сколько векторов отличается в нуле координата, в одной, в д пополам координата, такая вот сумма,
[38:48.980 --> 38:58.260]  так, смотрите, что отсюда следует, у нас есть сейчас множество, которое состоит из больше или
[38:58.260 --> 39:02.660]  не меньше, чем два в степени 1 минус эпсалон на n раскрасок векторов,
[39:02.660 --> 39:13.060]  так, что стало быть можно сказать про его диаметр, исходя вот из этого рассуждения,
[39:13.060 --> 39:20.340]  ну давайте обозначим это множество тоже как-нибудь буквой а, например, а это вот множество
[39:20.340 --> 39:29.380]  состоящее из не менее чем два в степени 1 минус эпсалон на n раскрасок, есть такое множество,
[39:29.380 --> 39:34.900]  как можно оценить его диаметр, наверное, чем-то достаточно большим можно оценить снизу,
[39:34.900 --> 39:43.860]  вот давайте подумаем, как его можно оценить снизу, это, конечно, вот как бы некая проверка на то,
[39:43.860 --> 39:49.260]  насколько вы все-таки осознали науку про асимптотики цешек, с этого начинался первый
[39:49.260 --> 39:56.820]  семестр дискретного анализа, ну понятно, что если вот эта величина d пополам больше,
[39:56.820 --> 40:05.220]  чем n пополам, то все плохо, потому что эта сумма зачерпывает k равный n пополам в том числе,
[40:05.220 --> 40:12.660]  это очень плохо, а вот если d пополам лежит строго ниже серединки суммирования,
[40:12.660 --> 40:19.200]  ну ниже чем n пополам, тогда вот эта сумма просто возрастающих величины,
[40:19.200 --> 40:26.760]  с которых последняя самая большая, так, ну сейчас я попробую как-то по-понятней объяснить,
[40:26.760 --> 40:39.280]  так, как бы это по-понятней объяснить, как бы это по-понятней объяснить, может быть,
[40:39.280 --> 40:44.120]  прямо сразу на вас все вот этот катарсис-то выплеснуть, да нет, ну это катарсис, понимаете,
[40:44.120 --> 40:52.520]  где ж 10-9, где 10-9, откуда она полезет, 10-9, вот она сейчас полезет, в оценке идеальна,
[40:52.520 --> 41:09.920]  ну кто мне там еще бы сгумал звонить, не знаю, так, ну что, большой мощный,
[41:09.920 --> 41:17.320]  но смотрите, вот идея-то какая, я просто хочу, чтобы вы идею послушали, а потом уже я на вас
[41:17.320 --> 41:29.520]  выплеснул 10-9, идея-то какая, нам нужно подобрать вот это d пополам в виде 1 вторая, 1 минус там
[41:29.520 --> 41:35.080]  какой-нибудь дельта, но вот это и будет 10-9, я все равно раскрываю карты уже, ну тут деваться некуда,
[41:35.080 --> 41:43.200]  на n, вот если мы вот эту верхнюю границу выберем так, чтобы асимптотика логарифма вот этой сумм
[41:43.200 --> 41:49.760]  совпадала с асимптотикой логарифмы или была там больше, ни как меньше, чем асимптотика вот
[41:49.760 --> 41:59.880]  этого логарифма, то мы придем к оценке идеали, ну ладно, давайте, вот пусть d пополам имеет
[41:59.880 --> 42:04.640]  какой-то вот такой вид, пока что дельта это не 10 минут 9, а что хотите, вот имеет какой-то такой
[42:04.640 --> 42:13.160]  дельта, это какое-то фиксированное число, давайте подумаем вместе, как устроена асимптотика логарифма
[42:13.160 --> 42:22.720]  вот этой суммы, но мы с вами умеем считать c и z по альфы n, помните, что мы умеем такое
[42:22.720 --> 42:31.120]  дело считать, самое начало первого семестра второго курса, между прочим, там тоже слово
[42:31.120 --> 42:36.680]  энтропия появлялось в другом контексте, но просто сама оценка выглядит так же, как энтропия,
[42:36.680 --> 42:42.240]  там получается вот так, один поделить на альфа в степени альфа, один минус альфа в степени 1
[42:42.240 --> 42:49.840]  минус альфа, плюс там какое-то маленькое от единицы и все это в n степени, но то есть по
[42:49.840 --> 42:59.040]  другому, это можно переписать вот так, это 2 в степени минус альфа лог 2 ичный альфа,
[42:59.040 --> 43:12.240]  минус 1 минус альфа лог 2 ичный 1 минус альфа, но это прямо h от альфа, ну так, если что, я говорю,
[43:12.240 --> 43:16.680]  что та энтропия, которую мы оценивали, нам уже не нужна, но здесь чудесным образом другая энтропия
[43:16.680 --> 43:24.560]  появилась, фиг бы с ней, но просто вот такое вот выражение, и дальше вот это все, ну, наверное,
[43:24.560 --> 43:33.600]  надо умножить на 1 плюс о малое от единицы и еще на n, вот так, то же самое абсолютно, написать
[43:33.600 --> 43:41.040]  выражение вот в таком виде или сэкспоненцировать его, прологарифмировав то, что стоит под знаком
[43:41.040 --> 43:48.360]  с этим экспонентом, так, у кого-то вот это вызывает сложности, все уже понимают, да,
[43:48.360 --> 43:54.080]  так вызывает, то есть показатель вот этой экспонента асимпатически равен тому, что тут
[43:54.080 --> 44:01.360]  напитка n и тут у нас тоже n, но тут 1 минус эпсилон, а тут вот эта вот энтропия от альфы,
[44:02.360 --> 44:11.080]  ну, от распределения, которое принимает два значения, альфа и минуса, неважно, с вероятностями,
[44:11.080 --> 44:20.080]  альфа и минуса, так, никого не кохнуло, понятно, что происходит, теперь смотрите, ну, все предыдущие
[44:20.080 --> 44:29.080]  слагания имеют только меньшую асимптотику, чем вот это, поэтому, когда мы суммируем с точностью до
[44:29.080 --> 44:33.520]  выбора вот этой функции, которая стремится к нулю, получится все равно вот это выражение,
[44:33.520 --> 44:42.960]  если дельта меньше строго, вернее, больше строго нуля, если вот это строго меньше 1 минус дельта,
[44:42.960 --> 44:48.800]  то асимптотика лагеризма сосредоточена в максимальном слагаемом, ну, почему,
[44:48.800 --> 44:54.960]  давайте я по-другому скажу, есть максимальная слагаемая, а всего слагаемых меньше, чем n,
[44:54.960 --> 45:02.520]  ну, значит, вся сумма меньше, чем n умножить на максимальная слагаемая, и больше в то же
[45:02.520 --> 45:09.120]  время, чем максимальная слагаемая, но если максимальная слагаемая, по сути, экспоненциальная,
[45:09.120 --> 45:13.960]  то и вся сумма будет, по сути, экспоненциальная, потому что она сверху оценивается вот этим,
[45:13.960 --> 45:22.480]  умноженным на n, а снизу просто вот этим, нормально объясню? Точно? Я понял.
[45:25.640 --> 45:34.200]  Асимптотика лагеризма не меняется. Вся, конечно, меняется, на нас интересует только 1 плюс 1 от 1
[45:34.200 --> 45:40.440]  в показателе. Вся меняется, конечно, на n все-таки домножение может случиться, но домножение на n
[45:40.440 --> 45:45.760]  не меняет асимптотику лагеризма, поэтому вот это равенство справедливо не только для последнего
[45:45.760 --> 45:52.000]  слагаемого, но для всей суммы тоже, в смысле выбора вот этого маленького от 1, это в точности утверждение
[45:52.000 --> 45:59.160]  о том, что асимптотика лагеризма этой суммы это вот выражение, стоящее сейчас в показателе двойки
[45:59.160 --> 46:14.480]  в степи. Все, вроде объяснил, да? Теперь, смотрите, что получается? Получается, если вот это вот выражение,
[46:14.480 --> 46:26.080]  ну альфа это у нас вот это вот альфа, это вот альфа, альфа это на самом деле что-то
[46:26.080 --> 46:35.880]  зависящее от дельта. Если окажется, что это выражение меньше, чем 1 минус эпсилон, строго меньше,
[46:35.880 --> 46:41.720]  чем 1 минус эпсилон, то что у нас получится? У нас получится как бы противоречие, да?
[46:41.720 --> 46:49.320]  У нас получится противоречие. С одной стороны, мы знаем, что мощность а большая больше либо равна вот
[46:49.320 --> 46:55.440]  это, а с другой стороны, предполагая, что диаметр не превосходит вот такой вот удвоенной величины,
[46:55.440 --> 47:06.200]  мы получаем противоречащее неравенство при больших n. Нормально, четко объясняю. То есть,
[47:06.200 --> 47:12.880]  получается, что если мы выбираем максимальная дельта, вернее, минимальная дельта, минимальная
[47:12.880 --> 47:19.560]  дельта, при котором вот это выражение меньше, чем 1 минус эпсилон, то мы получаем, что диаметр
[47:19.560 --> 47:27.320]  множества а не превосходит вот этой величины. Больше либо равен вот этой величине, извините.
[47:27.320 --> 47:33.560]  Знаете, еще раз, если у множества диаметр не больше, чем d, то его мощность не больше,
[47:33.560 --> 47:42.360]  чем вот столько, тогда она будет меньше, чем столько, сколько у нас есть на самом деле. И это
[47:42.360 --> 47:50.000]  будет противоречием, означающим, что на самом деле диаметр множества больше, чем вот эта величина.
[47:52.000 --> 47:59.080]  Вот утверждается, что в качестве такого дельта и надо взять пресловутые 10 минус 9. Если вы возьмете
[47:59.080 --> 48:08.160]  в качестве дельты 10 минус 9, то вот это выражение, показатели двойки, будет строго меньше, чем 1 минус
[48:08.160 --> 48:15.760]  3 на 10 минус 20. Но опять, можете на калькуляторе или на компьютере подставить и проверить. Просто
[48:15.760 --> 48:23.200]  тупо подставляете 10 минус 9 вот сюда, получаете альфа, считаете вот эту штуку для такого альфа и
[48:23.200 --> 48:32.640]  убеждаетесь, что она меньше, чем 1 минус 3 на 10 минус 20. Откуда следует, что диаметр
[48:32.640 --> 48:44.520]  множества больше либо равен, или даже строго больше, вот этой вот величины. Ибо,
[48:44.520 --> 48:50.920]  будь он меньше, было бы меньше векторов, чем у нас есть на самом деле. Сумел объяснить?
[48:53.200 --> 48:59.080]  Это место как-то трудно, просто по-моему, знаю воспринимается, поэтому я стараюсь его подробно.
[49:05.320 --> 49:10.520]  Ну, нам не важно, что такое один плюс во маленькое. Если константа строго меньше, чем 1 минус
[49:10.520 --> 49:15.000]  Эпсуум, то рано или поздно оценки вступят в противоречие друг с дружкой. А нас интересует
[49:15.000 --> 49:30.720]  только Н, стремящийся к бесконечному. Для больших Н, конечно, да. Ну да. Наверное,
[49:30.720 --> 49:39.320]  это означает, что мне по-хорошему надо переформулировать, что существует такое нулевое,
[49:39.320 --> 49:44.840]  что начинает с этого н-нулевого. Разница будет не больше, чем один дискорнейзен. Слушайте,
[49:44.840 --> 49:50.000]  вот это хорошее замечание, да. Поскольку здесь присутствует асимптотика, мы вынуждены говорить
[49:50.000 --> 49:55.280]  о том, что N достаточно велико. Поправьте это в формулировке, извините, да, это я не подумал.
[49:55.280 --> 50:00.880]  Действительно, в этом месте возникает какое-то н-нулевое, начиная с которого это точно верно.
[50:00.880 --> 50:11.840]  Какое, там, посчитаешь. Так, все, нормально. Вот. Ну, что из этого следует-то? Из этого следует,
[50:11.840 --> 50:21.400]  раз диаметр большой, что существуют две раскраски хи1, хи2, принадлежащие множеству А, такие,
[50:21.400 --> 50:29.760]  что значение вот этого вот вектора b1b на обеих одно и то же. Ну, я могу вот так, знаете,
[50:29.760 --> 50:38.960]  b со стрелочкой от хи1 равно b со стрелочкой от хи2. Подставляю вот сюда хи1, подставляю
[50:38.960 --> 50:43.160]  сюда хи2, мы получаем один и тот же набор значений, которые я старательно не стираю,
[50:43.160 --> 50:48.640]  как определяются. Здесь написано, как они определяются. Это значение. Причем,
[50:48.640 --> 50:58.400]  расстояние хэминга, как бы его назвать, ну хэм, например, между хи1 и хи2 больше
[50:58.400 --> 51:12.400]  либо равняется вот этой вот величины. 1-10-9. Ну, то есть, они почти ни в одной координате не
[51:12.400 --> 51:18.520]  совпадают. Совпадают на не более чем одной миллиардной доле от координат, от числа
[51:18.520 --> 51:25.400]  координат. Вот эти две раскраски почти не совпадают. Тем не менее, у них одинаковые
[51:25.400 --> 51:33.960]  значения вот этих векторов. Ну, что надо теперь сделать, чтобы получить обещанную частичную
[51:33.960 --> 51:41.600]  раскраску из формулировки теоремы штрих? Кто соображает сходу? Как построить частичную
[51:41.600 --> 51:46.800]  раскраску, в которой будут нолики, и этих ноликов будет мало? Очень легко сообразить.
[51:46.800 --> 51:54.480]  Есть два вектора из плюс-минус единиц, две раскраски, которые очень мало где различаются.
[51:54.480 --> 51:58.840]  Очень много где различаются, очень мало где совпадают.
[51:58.840 --> 52:14.000]  Ну, а формулу не хотите предложить явную, без словок, ссор?
[52:14.000 --> 52:23.520]  Ну, нет, это я понимаю. Нет, нет, это вот не совсем то. Формула другая. Надо взять полуразность.
[52:23.600 --> 52:32.320]  Надо взять полуразности. Координаты, на которых они совпадают, занулятся. Но этих координат не
[52:32.320 --> 52:37.920]  больше, чем одна миллиардная от общего числа координат. Ну, давайте я напишу,
[52:37.920 --> 52:44.280]  раз вызвала все эти трудности. Сейчас вот тут напишу. Я думал, кто-то сразу скажет.
[52:44.280 --> 52:57.600]  Вот такую взять штуку. Хи1 минус хи2 попала. Это будет не раскраска, но частичная раскраска.
[52:57.600 --> 53:04.000]  Почти все, за исключением не более, чем 10 в минус 9 умножить на n координат у нее плюс или
[53:04.000 --> 53:12.640]  минус единица, потому что столько было разнящихся координат у хи1 хи2. Но на не более, чем одной
[53:12.640 --> 53:18.720]  миллиардной доли от общего числа координат они совпадают. Значит, при вычитании получается ноль,
[53:18.720 --> 53:24.440]  после деления пополам тоже получается ноль. А там, где они различаются, ну да, вычитаем,
[53:24.440 --> 53:30.600]  получаем либо минус единица, либо минус двойку, потом делим пополам, либо плюс двойку, потом делим
[53:30.600 --> 53:39.320]  пополам. Так, теперь вопрос. Почему уклонение такое, как мы хотели? Помните, я утверждал,
[53:39.320 --> 53:44.440]  что на каждом множестве разница, ну модуль разности между красными и синими вершинами,
[53:44.440 --> 53:52.600]  не превосходит 10 корней из n. Это вот ровно из этого построения. Потому что у них одинаковые
[53:52.600 --> 54:00.800]  значения на все хомытые. Вот у этих хи1 и хи2. Ну, допустим, скажем, значение лежит вот на этом
[54:00.800 --> 54:06.000]  отрезке, на этом полуинтервале. У каждой из них лежит на этом полуинтервале. Значит,
[54:06.000 --> 54:13.760]  чего модуль полуразности не превосходит? Ну как раз 10 корней из n, потому что модуль разности не
[54:13.760 --> 54:22.280]  превосходит 20 корней из n, а после деления на 2 – 10 корней из n. То же самое здесь. Опять,
[54:22.280 --> 54:28.040]  они отличаются друг от друга реально. Не больше, чем на 20 корней из n, после деления на 2 – не
[54:28.040 --> 54:36.280]  больше, чем на 10 корней из n. Все. На любом интервале. Так, длины 20 корней из n.
[54:42.880 --> 54:50.440]  Понятно, да? Ну, по-моему, это такое очень продвинутое, красивое решение. Идейно,
[54:50.440 --> 54:54.240]  не тривиально, идейно. Мне казалось, что вот очень полезно. Все-таки ты осознаешь,
[54:54.360 --> 55:00.120]  антропия так работает в комбинаторике. Оказывается, что она нужна не только для физики или для каких-то
[55:00.120 --> 55:05.600]  вероятностных нужд, но в комбинаторике она тоже является удобным инструментом для получения таких
[55:05.600 --> 55:12.560]  вот, в итоге, мощностных оценок. Например, мощность какого-то множества большая. Дальше уже вступает в
[55:12.560 --> 55:18.880]  силу такая вот комбинаторика теории кодировки. Если мощность большая, то диаметр, например,
[55:18.880 --> 55:24.320]  большой. А раз диаметр большой, значит, есть два объекта, которые сильно разнятся. Возьмем
[55:24.320 --> 55:30.720]  полуразность, получим объект, который почти без нули. И при этом, вот видите, значения совпадают.
[55:35.920 --> 55:42.600]  Ну, то есть, и 1 от m, и и 2 от m отстанет друг от друга не больше, чем на 20 корней из n. Значит,
[55:42.600 --> 55:45.640]  здесь вот уклонение быть не больше 10 корней из n на каждом.
