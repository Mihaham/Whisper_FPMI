[00:00.000 --> 00:11.420]  Что у нас было на прошлой лекции? На чем мы с вами закончили? Минимальная основная дерево и алгоритм
[00:11.420 --> 00:19.140]  прима. Было такое? Было чудесно. Вот смотрите, сегодня мы будем с вами с этим продолжать.
[00:19.140 --> 00:30.460]  Но перед тем, как пойти дальше, на семинарах почти, наверное, вам что-то сказали, что существует
[00:30.460 --> 00:38.580]  какой-то алгоритм краскала, крускала, как его только не называют, бедолагу. Вот. И для того,
[00:38.580 --> 00:43.820]  чтобы к нему перейти, необходимо сначала поговорить про систему непересекающихся множеств. Это
[00:43.820 --> 00:48.540]  достаточно важная и интересная тема сама по себе. Что такое система непересекающихся множеств?
[00:48.540 --> 00:55.380]  Представьте следующее. У вас есть некоторая такая задача в том, что у вас есть n элементов,
[00:55.380 --> 01:00.820]  они как-то перечислены, и вот вы присваиваете им номера. И они могут быть разбиты на
[01:00.820 --> 01:07.180]  непересекающиеся множества. Вот здесь вот представлено А1, А2 и какое там АКТ. А1 это 024,
[01:07.180 --> 01:14.540]  А2 это 1.6, АК опять. Например. Вот. Требуется построить какую-то эффективную структуру данных,
[01:14.540 --> 01:21.180]  которая будет поддерживать три операции. Это make set. Это создать новое одноэлементное множество,
[01:21.180 --> 01:28.520]  то есть я могу вводить новые элементы и давать им новые номера. Find set. Он возвращает некоторый
[01:28.520 --> 01:35.180]  идентификатор множества, то есть к какому множеству оно относится. Ну не знаю. Эти все вершины,
[01:35.180 --> 01:41.460]  там вершины или какие-то элементы, они там красные, грубо говоря. Вот find set может возвращать вот это
[01:41.460 --> 01:48.020]  вот понимание, к какому именно множеству мы относимся. То есть в данном случае там, не знаю,
[01:48.020 --> 01:56.300]  А1, А2, А3 и так далее АКТ. К какому-то из них. И мы будем считать, что два множества лежат,
[01:56.300 --> 02:03.220]  ой, два элемента лежат в одном множестве, когда у них find set как раз таки одинаковые. Вот. И последнее,
[02:03.220 --> 02:12.660]  что нам нужно еще union. Union это когда мы хотим объединить два множества. Make set ничего не подается,
[02:12.660 --> 02:18.020]  он просто увеличивает на один количество элементов, создает новое множество из одного
[02:18.020 --> 02:26.140]  элемента. Из какого элемента? Вот мы говорим, что у нас точно мы знаем, что у нас n элемента,
[02:26.140 --> 02:32.940]  значит из n плюс первого. Вот. То есть оно вот так вот увеличивается итеративно. Можно это
[02:32.940 --> 02:39.260]  прописать внутри make set, а здесь как удобнее, но в данном случае мы будем делать так. А что здесь
[02:39.260 --> 02:50.140]  есть? Какие есть идеи? Идея номер один. Давайте с вами организуем следующую структуру. У нас
[02:50.140 --> 02:58.100]  будут множество, у каждого из множества будет некий представитель. Представителем множества будет
[02:58.100 --> 03:03.180]  являться один из элементов этого множества. Мы скажем просто вот ты главный и все. Вот. Ну,
[03:03.180 --> 03:10.060]  у вас так старость выбирали, да скорее всего. Вот ты главный типа все, делай что хочешь. А это
[03:10.060 --> 03:16.180]  является представителем множества и все ссылаются на него. Все элементы, которые у нас есть в этом
[03:16.180 --> 03:21.860]  множестве, когда мы будем вызывать find set, они будут указывать на этого представителя. Вот здесь вот у
[03:21.860 --> 03:30.940]  нас с вами нарисовано 2, 0, 8, 5, 4, 7 и смотрите 0 и 5 они указывают на 2 и 8 тоже. И они говорят,
[03:30.940 --> 03:37.580]  что я ссылаюсь на представителя. 4 и 7 ссылаются на 8, а 8 ссылается на 2. То есть мы будем вот так
[03:37.580 --> 03:42.780]  вот и итеративно ходить до того момента, пока мы не дойдем до какого-то элемента, который ни на
[03:42.780 --> 03:51.460]  что не ссылается. Благодаря этому всему мы с вами построим такой вот лес непересекающихся множеств.
[03:51.460 --> 03:59.220]  В этом лесу непересекающихся множеств мы с вами как раз таки и будем говорить, что мы можем находить
[03:59.220 --> 04:04.140]  представители. Представители будут эти корни, на которые ссылаются. Вот и все. Понятно, что
[04:04.140 --> 04:13.060]  происходит. Понятно, как это выглядит между собой. Сама по себе структура несложная, правда? Вот.
[04:13.060 --> 04:31.100]  Как написать find set, представляете здесь? Как? Да, то есть просто идем вверх и складываем. А вот если
[04:31.100 --> 04:38.980]  мы захотим объединить эти множества, что мы сделаем? Да, да. То есть один корень возьмем,
[04:38.980 --> 04:44.220]  переподвесим и покажем, что он будет теперь указывать на какой-то другой корень. В действительности
[04:44.220 --> 04:51.500]  все достаточно просто. Find set можно написать while, а можно написать рекурсивно. Но как бы здесь как
[04:51.500 --> 04:57.940]  вам удобнее. Но фактически find set будет делать вот такую вот вещь. Он будет while идти до тех пор,
[04:57.940 --> 05:04.780]  пока x не равен parent x, то есть пока он сам на себя не указывает, и подниматься по parent. Как только
[05:04.780 --> 05:08.860]  он дойдет до этого момента, он вернет сам x. То есть вот это тот представитель, который у нас
[05:08.860 --> 05:16.620]  является данного множества. Что важно понимать? Важно понимать, что у нас время работы find set
[05:16.620 --> 05:25.900]  будет зависеть от высоты. Какая может быть максимальная высота? N. Неприкольно и с этим
[05:25.900 --> 05:32.100]  работать неинтересно. Вот это первый момент, который мы должны понять, что с этим делать. Нам
[05:32.100 --> 05:41.020]  надо подумать. Второй union мы объединяем наше множество. По факту мы просто переподвешиваем,
[05:41.020 --> 05:49.060]  у x находим, кто является представителем, у y находим, кто является представителем, и говорим,
[05:49.060 --> 05:58.940]  что parent x становится y. Вот, то есть x это вот то самое множество, с которым мы работаем. Здесь
[05:58.940 --> 06:09.420]  все понятно, все просто звучит. Хорошо. Вся проблема именно в этом выражении, в том,
[06:09.420 --> 06:16.740]  что у нас будет работать все за o от n. Это неприкольно, это не круто. Что же делать? Какие есть идеи?
[06:16.740 --> 06:26.020]  Бинарная, ой-ой-ой, сбалансировать его еще, вот это вот все не хочу. Учитывая, что их
[06:26.020 --> 06:34.860]  переподвешивать будет неудобно друг к дружке. Кучу сделать тоже неприкольно, потому что мы потом
[06:34.860 --> 06:43.420]  должны как-то переподвесить их друг к другу, а они могут элементами расходиться. Давайте,
[06:43.420 --> 06:56.020]  я в вас верю. Много разных деревьев, но такого еще не было. Много разных деревьев проходили,
[06:56.020 --> 07:01.500]  это правда. Смотрите, давайте начнем с простой мысли. Вот у меня есть
[07:01.500 --> 07:25.060]  вот такое дерево и такое дерево. Какое подвесить к какому лучше? Правое к левому, почему? Чтобы
[07:25.060 --> 07:32.460]  высота не росла. Вот, хорошо, и вот сделать и сделать указатель вот таким вот образом. Правильно? То есть
[07:32.460 --> 07:40.980]  я могу так их взять и объединить. И в действительности это называется ранговый евристикой. То есть
[07:40.980 --> 07:49.540]  подвесивать менее глубокое дерево к более глубокому. А в этом случае что у нас происходит,
[07:49.540 --> 07:56.580]  когда мы подвешиваем менее глубоко к более глубокому? Высота не растет сама по себе. Согласны? Как это
[07:56.580 --> 08:01.900]  оценить? Мы сейчас будем с вами оценивать, к чему это приведет. Но в действительности, когда мы так
[08:01.900 --> 08:06.820]  объединяем, то у нас все хорошо. Единственный случай, когда у нас высота может возрасти,
[08:06.820 --> 08:14.300]  это только тот случай, когда у нас одинаковая высота. У обоих этих множеств. В этом случае
[08:14.300 --> 08:22.340]  высота вырастет на один. И неважно, какое мы к какому подвесим. Согласны? Вот, поэтому union
[08:22.340 --> 08:28.820]  будет выглядеть так. Рангом выступает здесь глубина дерева. Это называется ранговый евристикой. Это
[08:28.820 --> 08:33.860]  улучшение того же того процесса, который у нас есть. Мы сначала находим представителя у х,
[08:33.860 --> 08:39.460]  представителя у у. Говорим, что теперь х и у это представители. Дальше мы сравниваем ранг у х и
[08:39.460 --> 08:48.540]  ранг у у. Если какой-то из них меньше, то меньше подвешиваем к большему. Если одинаково, тогда нам
[08:48.540 --> 08:55.620]  здесь без разницы. Мы их подвешиваем одно к другому. Например, здесь у меня подвешен х к у. И мы
[08:55.620 --> 09:01.260]  увеличиваем ранг у на один, потому что мы знаем, что у них высота одинаковая. Значит, высота
[09:01.260 --> 09:09.940]  увеличилась на один. Согласны? Вот, это первый момент, который у нас есть. Сколько это работает и
[09:09.940 --> 09:16.060]  почему это хорошо? В действительности утверждение следующее. При использовании ранговой евристики
[09:16.060 --> 09:26.780]  размер дерева с корнем в х будет равен 2 в степени ранг х. Больше ли бы равен? Количество вершин, да.
[09:26.780 --> 09:34.660]  Количество вершин в нашем множестве. Вот утверждение такое. Как будем доказывать?
[09:44.660 --> 09:52.020]  Но это можно, но это сложно. По индукции, да, в действительности легче всего по индукции сделать.
[09:52.020 --> 09:58.660]  Почему бы нам не попробовать это сделать? Смотрите, в начальный момент времени, когда у нас один
[09:58.660 --> 10:07.060]  элементик, мы говорим, что у нас высота дерева ноль согласна с тем, что один больше либо равно
[10:07.060 --> 10:17.340]  одному. Правда? Логично, чудесно. Значит, это база индукции сделана. Теперь, когда мы говорим с вами
[10:17.340 --> 10:24.660]  о продолжении этого всего, у нас есть два поддерева, для которых выполнено данное условие,
[10:24.660 --> 10:34.020]  что size х больше либо равно, чем 2 ранга х, 2 в степени ранг х, и size y больше либо равен,
[10:34.020 --> 10:40.380]  чем 2 в степени ранг y. Отлично. Какие есть два варианта без ограничения общности? Если с
[10:40.380 --> 10:48.500]  ограничением, то три варианта. Но будем считать, что у нас ранг х либо больше, либо равен. То есть,
[10:48.500 --> 10:55.420]  меньше аналогично вот первому случаю, который был. Мы говорим, что если у нас ранг х больше,
[10:55.420 --> 11:06.100]  чем ранг y, то в этом случае я y подвешиваю к x. Размер моего x будет равен size x плюс size y.
[11:06.100 --> 11:11.380]  Согласны? Ну, как бы, я соединил все вершины, получил два размера. Это больше либо равно,
[11:11.380 --> 11:17.820]  чем 2 в степени ранг x, плюс 2 в степени ранг y. Правильно? Правильно. Из утверждения,
[11:17.820 --> 11:24.460]  которое было выше, то, что мы предположили. Чудесно. Могу я выкинуть два ранга y? 2 в степени
[11:24.460 --> 11:30.860]  ранг y? Ну, могу. Ничего не изменится. Отлично. Я говорю, больше либо равно, чем 2 в степени ранг x.
[11:30.860 --> 11:37.380]  А теперь смотрите, ранг x и ранг штрих x, это вот, когда мы добавили вершины, они одинаковы или нет?
[11:37.380 --> 11:48.500]  Ранги. В этом случае да. Почему? Потому что высота не изменилась. Согласны? Задайте вопросы. А то вы
[11:48.500 --> 11:57.180]  смотрите, читаете, либо не понимаете, либо понимаете. Понятно, что происходит? Как этот
[11:57.180 --> 12:07.100]  случай выглядит? Он выглядит вот так. Только здесь x, здесь y. Высота не изменилась, ранги не
[12:07.100 --> 12:14.980]  изменились, поэтому ранг у x и у нового x одинаковые. Все чудесно. Мы доказали для этого случая. Теперь
[12:14.980 --> 12:20.060]  вопрос встает, когда у нас одинаковые ранги, у нас увеличивается высота. Давайте смотреть,
[12:20.060 --> 12:25.380]  что у нас происходит. Мы говорим, что size штрих, ну, то есть вот новый, который у нас есть размер,
[12:25.380 --> 12:43.180]  ну, он, естественно, складывается из двух size, что логично. Вот. А это раз. Дальше мы говорим,
[12:43.180 --> 12:53.260]  что, по предположению нашей индукции, это 2 в степени ранг x плюс 2 в степени ранг y.
[12:53.260 --> 13:09.740]  Смотрите, ранг x и ранг y равны? Равны. Значит, 2 в степени ранг x плюс 1. Да? Ну, а ранг x плюс 1
[13:09.740 --> 13:18.820]  это высота моего нового дерева? Это тот самый новый ранг x. Поэтому это 2 в степени ранг 3x.
[13:18.820 --> 13:30.980]  Логика простая. Окей. Принято. Чудесно. Какое из этого следствие, из этого следствие,
[13:30.980 --> 13:35.820]  что высота нашего вот этого дерева, которое есть, оно не больше, чем логарифм?
[13:35.820 --> 13:59.300]  Ну, смотрите. Высота. У нас меньше ранга, ранг меньше чего? Под рангом высоту. А, я понял. Смотрите,
[13:59.460 --> 14:06.380]  а мы говорим о том, что у нас здесь немножко в другую сторону меньше либо равно должно идти.
[14:06.380 --> 14:12.660]  Высота это и есть ранг. Все верно. Тут равно должно быть. История. Ошибочка.
[14:20.180 --> 14:20.740]  Еще раз.
[14:20.740 --> 14:32.980]  Ну, для нулевого элемента, да, типа, ну, как бы это не сильно считается.
[14:32.980 --> 14:50.180]  Не совсем так. Ашат-х. А, ты имеешь в виду, что вот здесь ашат-х, вот здесь разная ашат-х.
[14:50.180 --> 14:56.460]  Смотрите, я беру максимальное ашат-х и говорю высота с самого дерева. Вот. Ну,
[14:56.460 --> 15:00.980]  в действительности, как бы берем логарифмируем, получаем логарифм. Окей. То есть,
[15:00.980 --> 15:12.860]  у меня уже логарифмическая здесь сложность, и она лучше, чем вот уже хорошо. Что-то мы с вами
[15:13.180 --> 15:29.980]  сделаем. Как еще могу улучшить? Как вы думаете? А? Ну, не-не-не-не. Это перебор. А? Зачем? Зачем
[15:30.140 --> 15:50.820]  штаблица? Да. Давайте еще. Смотрите. Вопрос следующий. Предположим, что у этой вершины я вызываю...
[15:50.820 --> 15:58.900]  Скажите мне, вот я вот поднимаюсь, прихожу к своей вершине X, которая является представителем.
[15:58.900 --> 16:08.380]  А нелогично, что пока я поднимаюсь, вот это, ну, не знаю, давай, 0, 1, 2, 3. Почему бы мне не
[16:08.380 --> 16:19.020]  сделать так, чтобы в следующие вызовы я не поднимался больше так долго и сделать вот так.
[16:19.020 --> 16:29.940]  Ну, нет-нет-нет. Я поднимаю вот именно каждую из вершинок. То есть, я смотрю, ага, один указывает
[16:29.940 --> 16:37.740]  на X. Ну, отлично. Два, давайте вот я подниму тоже выше. Ну, как бы зачем я буду еще раз ходить? Я
[16:37.740 --> 16:45.060]  же файнсетом все равно буду спускаться вниз и искать это, точнее, идти вверх и находить представителя.
[16:45.060 --> 16:51.780]  Почему бы сразу все это не переподвешивать? Но здесь я буду делать это рекурсивно. То есть,
[16:51.780 --> 16:57.180]  смотрите, я спускаюсь сюда, спускаюсь сюда, спускаюсь сюда, нахожу, грубо говоря, что мне
[16:57.180 --> 17:04.820]  нужно, а потом поднимаюсь обратно. То есть, раскручивается так я буду. Ну, точнее, вот так, да.
[17:04.820 --> 17:11.860]  Нахожу представителя и в обратную сторону говорю, что один подвешивается к X,
[17:11.860 --> 17:20.820]  parent 2 становится X, parent 3 становится X. Почему бы так не сделать? Как вы думаете,
[17:20.820 --> 17:34.740]  как называется такая ивристика? А? Мы до этого дойдем. Нет, не будет. А в действительности это
[17:34.740 --> 17:41.060]  просто называется сжатие путей. Это ивристика сжатия путей. То есть, смотрите, как ее добиться?
[17:41.060 --> 17:47.180]  Ну, достаточно просто. Мы делаем файнсет от какого-то X и говорим, что если X равен parent X,
[17:47.180 --> 17:52.840]  то возвращаем X. Ну, то есть, сам корень нашли. А если нет, то мы говорим, что parent X равен
[17:52.840 --> 18:03.480]  файнсету от parent X. Что здесь означает? Вот у меня есть некоторая вершина. Некоторая вершина здесь.
[18:03.480 --> 18:15.480]  Я говорю, parent этой тройки равен файнсету от parent этой двойки. Ну, вот от этой двойки смотрю.
[18:15.480 --> 18:23.440]  Теперь от нее я смотрю на единичку и такой. Ну вот, parent у двойки равен файнсету от единички.
[18:23.440 --> 18:29.080]  И поднимаюсь. Дальше, когда я дошел до конца, то есть дошел до окончания своей рекурсии,
[18:29.080 --> 18:34.880]  я раскручиваюсь назад. 1 становится X, 2 указывает на X, 3 указывает на X.
[18:36.880 --> 18:42.440]  С точки зрения написания кода, изменили мы ровным счетом почти ничего. То есть,
[18:42.440 --> 18:49.200]  не сильно много у нас здесь вернулось. Согласна? Но вот с точки зрения ивристики у нас появилась
[18:49.200 --> 18:58.200]  хорошая вещь. Что нам это само по себе дает? Это утверждение без доказательства. Звучит оно так.
[18:58.200 --> 19:04.680]  Если вы используете ивристику сжатия путей плюс ранговую ивристику одновременно, то в этом случае
[19:04.680 --> 19:13.640]  файнсет работает за O от обратной функции Акермана. Как вы видите, здесь обратная функция Акермана,
[19:13.640 --> 19:18.320]  альфа от единички, ноль, альфа от трех, один, альфа от семи, два, альфа от шестидесяти одного, три.
[19:18.320 --> 19:28.880]  Как вы думаете, какое следующее, чтобы было четыре? Все правильно. 2 в степени 2, в степени 2,
[19:28.880 --> 19:37.760]  65536. Минус три. Это будет четыре. Очевидно, что все правильно. Смотрите, обратная функция Акермана
[19:37.760 --> 19:45.840]  растет крайне медленно. Она, конечно, растет, но очень медленно. Поэтому в этом случае мы говорим,
[19:45.840 --> 19:53.160]  что это почти константа. Понятно? Вот. Ну, чтобы нам не надо было это все доказать,
[19:53.160 --> 20:02.200]  поэтому вас теряем без доказательства. Ура. Вот. Кроме того, вы периодически, если где-нибудь будете
[20:02.200 --> 20:12.280]  читать про систему непересекающихся множеств, в виде ранга можете увидеть не высоту, а можете
[20:12.280 --> 20:19.840]  увидеть количество элементов. И вот просто к менее кучному, назову так, дереву вы подвешиваете,
[20:19.840 --> 20:27.000]  тем более кучно, подвешиваете к менее кучному. Вот. Так тоже можно. Такое тоже будет работать,
[20:27.000 --> 20:31.120]  и тоже работать с функцией Акермана, если немножко другой констант, но суть-то останется такая же.
[20:31.120 --> 20:37.000]  И как бы все хорошо. Кроме того, задачка всем наподумать, я попрошу семинаристов, может быть,
[20:37.000 --> 20:43.720]  с вами подумать. Я подумаю об этом, чтобы предложить это семинаристам. Почему ивристика сжатия
[20:43.720 --> 20:52.480]  путей одна сама по себе тоже будет давать логарифм. Вот. В общем, вот такие вот приколы.
[20:52.480 --> 21:12.760]  Прикольная структура данных. Откуда это появилось? Здесь, к сожалению,
[21:13.000 --> 21:16.920]  без четкого доказательства не сказать, потому что сначала поговорить про функцию Акермана,
[21:16.920 --> 21:24.360]  а потом брать обратную функцию Акермана. То есть здесь чуть больше от этого всего. Но если очень
[21:24.360 --> 21:33.760]  хочется, можно почитать странички, наверное, четыре доказательства в Курмане, если не ошибаюсь. Вот.
[21:33.760 --> 21:40.480]  Ну как бы четыре странички в Курмане, это много для доказательств, на самом деле. Но такое есть. Есть
[21:40.480 --> 21:47.040]  еще вопросы. Понятно? А теперь смотрите. Как вы думаете, зачем я вам это все рассказал сейчас?
[21:47.040 --> 21:58.440]  Для Миностовы. Зачем в Миностове? Я так сказал. Хорошо. Есть еще варианты. Вот давайте. Кроме этого.
[22:10.480 --> 22:26.920]  Угу. Смотрите. Помните лему о безопасном ребре? Был такой. Мы сейчас немножко, немножко уйдем в
[22:26.920 --> 22:34.000]  сторону. По сути, будем говорить о том же. Представьте, что у меня есть некоторый граф.
[22:34.000 --> 22:52.360]  Какой-нибудь такой. Мне нужен Миностов отсюда. Давайте представим каждую вершину как какое-то
[22:52.360 --> 23:07.200]  свое множество. Какое ребро лучше всего добавить сюда, чтобы оно было минимально остовным деревом? Самое
[23:07.200 --> 23:14.520]  маленькое. Логично? Логично. И причем это ребро должно соединять два разных множества. Иначе,
[23:14.520 --> 23:21.360]  если оно уже в одном множестве, вершины находятся, зачем их соединять? Согласна? То есть, ну давайте
[23:21.360 --> 23:44.400]  здесь чиселки мне придумайте. Семь, двенадцать, один, три, пять. Хорошо. Вот. Смотрите. Грубо говоря,
[23:44.400 --> 23:50.040]  представьте, у него разукрашены там разные цвета какие-то. Вот вы берете самое минимальное
[23:50.040 --> 23:57.360]  ребро из своего графа и говорите, ага, проведу его. Теперь вот эти вершины разукрашены одинаково.
[23:57.360 --> 24:01.640]  Фактически, они будут ну, не знаю, нулевого цвета какого-нибудь. Вот это там будет один,
[24:01.640 --> 24:10.120]  два, три. Что я делаю дальше? Я смотрю с вами и говорю, ага, следующее ребро три. Оно соединяет
[24:10.120 --> 24:16.440]  множество ноль с множеством три. Оно соединяет разные множества. Нам их все равно нужно соединить
[24:16.440 --> 24:22.800]  в конце концов, поэтому давайте я их соединю. И тогда тройка станет нулевым множеством, например.
[24:22.800 --> 24:32.240]  Пойдем дальше. Три. Теперь у меня четыре. Четыре будет соединять первое со вторым множеством.
[24:32.240 --> 24:39.240]  Разные множества. Разные. Давайте соединю и пусть это множество станет единичкой. Теперь у меня
[24:39.240 --> 24:44.480]  осталось два множества. Осталось как-то соединить. Давайте смотреть. Вот у нас уже использовано это
[24:44.480 --> 24:53.440]  ребро, это ребро, это ребро и все пока. Сталось пять. Следующая пять. Пять соединяет первое и нулевое
[24:53.440 --> 25:03.440]  множество. Давайте это соединим и теперь все множество единичек станет нулевым. У нас все
[25:03.440 --> 25:08.640]  соединилось. Но мы должны рассмотреть ребра, потому что так алгоритм будет работать. Мало ли,
[25:08.640 --> 25:15.880]  последнее ребро будет самое нужное, к примеру. Вот. Дальше мы смотрим на семь. Семь будет соединять
[25:15.880 --> 25:21.240]  множество ноль с множеством ноль. Нам такое ребро не нужно, мы его пропустим. Аналогично для восемь,
[25:21.240 --> 25:27.680]  аналогично для двенадцати. Прошлись по всем ребрам, выбрали минимальное, добавили их в свое
[25:27.680 --> 25:35.040]  дерево, получили миностов. Прикольно? Вот. И для того, чтобы поддерживать вот эту раскраску некоторую,
[25:35.040 --> 25:42.360]  нам и понадобится система не пересекающихся множеств. Мы именно с ней и будем с вами работать.
[25:42.360 --> 25:51.440]  Вот. Ну как бы, как работает данный алгоритм? Ну, к сожалению, вам ребра не всегда в отсортированном
[25:51.440 --> 25:58.640]  списке даются. Поэтому нужно сначала считать ребра, потом по весу их отсортировать. Это самая
[25:58.640 --> 26:07.760]  сложная операция здесь, которая есть, и работает она за Е лог В. Е лог Е, как угодно. Одно и то же
[26:07.760 --> 26:16.400]  будет лог Е и лог В. Ну а дальше проходимся по всем ребрам. Создаем сначала N представителей,
[26:16.400 --> 26:22.600]  сколько у нас есть вершин. Дальше мы проходимся по всем ребрам и соединяем наше множество. Делаем
[26:23.000 --> 26:30.880]  если у них разные представители. Итак, мы понимаем, какие ребра мы вкладываем, какие нет миностов.
[26:30.880 --> 26:39.480]  Понятно? Вот так работает данный алгоритм сам по себе. Вот. Нет ничего сложного.
[26:39.480 --> 26:56.520]  Я помню, когда... Какой вопросик? Можешь задать? Вы можете задать вопрос.
[26:56.520 --> 27:05.240]  Мы ищем ребра.
[27:10.480 --> 27:18.400]  Ну, не обязательно. Минимальное основное дерево это то, где мы оставляем все вершины,
[27:18.400 --> 27:26.720]  и граф должны получить связанным, добавив с минимальным суммарным весом. То есть граф должен
[27:26.720 --> 27:40.520]  быть связан просто. Вот. Что, есть вопросы? Нету. Вот. Расскажу поучительную историю относительно
[27:40.520 --> 27:46.160]  поучительную. Это, получается, мой был то ли первый курс, то ли второй. Я уже не помню,
[27:46.160 --> 27:52.880]  когда был этот алгоритм. Вот. Я решил, что типа на итоговом контесте я напишу сначала алгоритм
[27:52.880 --> 28:00.600]  примы. Он мне не заходил. Вот. Ну, просто категорически не заходил. После этого я взял,
[28:00.600 --> 28:06.920]  все переписал на алгоритм краскала, и все получилось. Такая вот маленькая история. Причем,
[28:06.920 --> 28:11.800]  ну, как бы алгоритм примы, я причем помнил, как он пишется. Он у меня был написанный. Даже вот так
[28:11.800 --> 28:18.080]  получилось, что он оказался у меня написанным. Но он не работал, понимаете? Вот. То есть такие вот
[28:18.080 --> 28:22.840]  ситуации тоже бывают. Осторожнее с этим. Лучше понимать алгоритм, потому что алгоритм краскала,
[28:22.840 --> 28:29.960]  я просто помнил основные концепции и идеи. Вот. Алгоритм примы мне никогда не нравился,
[28:29.960 --> 28:38.680]  но так уж получилось. Сейчас я отношусь к нему, назову это так, толерантно. Окей. Последний
[28:38.680 --> 28:45.520]  алгоритм праминостовы. Это алгоритм барувки. Алгоритм барувки в действительности соединяет
[28:45.520 --> 28:52.360]  в себе какую-то часть из примы, какую-то часть из краскала. Каким образом алгоритм барувки работает?
[28:52.360 --> 29:00.400]  Я лишь объясню сутивую его часть. Покажу код, мы с вами его разберем, но вот прям сильно-сильно
[29:00.400 --> 29:06.000]  погружаться вы, если что, на семинарах это сделайте. Смотрите, у вас все так же существует множество
[29:06.000 --> 29:13.280]  деревьев в самом начале. Вот вы, одноэлементных вот этих вот деревьев, которые есть. А для каждого
[29:13.280 --> 29:21.080]  отдельного дерева вы ищите минимальное ребро, которое из него исходит, и оно должно связывать
[29:21.080 --> 29:29.640]  его с другим каким-то представителем. Вы связываете их, после чего добавляете эти
[29:29.640 --> 29:37.960]  ребра в ваш миностов и обновляем эти деревья. То есть обновляем вот это вот множество деревьев,
[29:37.960 --> 29:42.840]  которые у нас есть. В системе не пересекаются их все множество. И повторяем это до тех пор,
[29:42.840 --> 29:53.760]  пока у нас количество деревьев больше одного. Почему это работать должно быстрее? Да, мы каждый
[29:53.760 --> 29:58.920]  раз можем уменьшать почти в два раза. Мы не будем это сильно много доказывать с алгоритмом барувки.
[29:58.920 --> 30:06.680]  Вот, но просто в том суть, что да, если в краскале вы идете по одному ребру каждый раз,
[30:06.680 --> 30:12.880]  то в этом случае вы просто смотрите минимально на каждом шаге для каждого из элементов и
[30:12.880 --> 30:24.640]  пытаетесь их связать. Понятно? Смотрите, краскал что делает? Он смотрит конкретное
[30:24.640 --> 30:29.120]  ребро и смотрит, что здесь происходит. Что делает барувка? Давайте на этом же примере.
[30:29.120 --> 30:40.580]  Что у нас тут? Ну, давайте смотреть. Я беру вот это вот элементик. Какие
[30:40.580 --> 30:47.560]  минимальные ребра, какие ребра из него выходят? 4,12,7. Какое для меня выгодно? 4,
[30:47.560 --> 30:56.360]  отлично. Иду дальше. Смотрю в этом. Какое для меня выгодно ребро минимальное? Какое
[30:56.360 --> 31:05.120]  ребро для меня выгодно? 4,5,8. 4 опять. Ничего не происходит. Хорошо. Поехали дальше. В этой
[31:05.120 --> 31:22.360]  вершине 7,1. Всё. 1. В этом, в этой вершине 1,12,5,3. 1. Оставляю также. Здесь смотрю 8,3. 3.
[31:22.360 --> 31:33.400]  Смотрите. Видите, после первого обхода я уже соединил вот так. Алгоритм же краскала в самом
[31:33.400 --> 31:42.080]  начале провел мне лишь вот это ребро. Понятно? То есть мы здесь идем итеративно, добавляя по
[31:42.080 --> 31:46.640]  одному ребру и проверяем и сделаем от всеми писькающих множеств. Здесь же наоборот. Мы с
[31:46.640 --> 31:52.200]  вами раз хлопнули. И теперь смотрите, что мне осталось. У меня появилось два вот таких вот множества.
[31:52.200 --> 32:03.400]  Давайте теперь их соединим минимальным ребром. Можем? Можем. Получится вот так.
[32:07.920 --> 32:16.160]  Откуда узнаем минимальное ребро? Мы можем пройтись по всем вершинам. Мы можем хранить эти
[32:16.160 --> 32:20.680]  минимальные ребра и смотреть как... Ну то есть мы можем ходить в вершинку и смотреть, что там
[32:20.680 --> 32:27.080]  происходит в принципе. Вот. Можем делать похоже на примо. Помните, у нас был разрез, мы обновляли,
[32:27.080 --> 32:33.840]  вот это все такое. Вот. Можно делать здесь разными вещами. Но как выглядит вообще весь этот код?
[32:33.840 --> 32:40.640]  Смотрите. Мы с вами строим вот эту систему неприсекающихся множеств с самого начала. И дальше
[32:40.640 --> 32:46.000]  мы говорим, что пока у нас множество не одно, мы повторяем один и тот же код. Какой код? Мы
[32:46.000 --> 32:51.480]  смотрим минимальное ребро. Ну вот у нас минимальные ребра. Мы будем сохранять их как раз таки в нашем
[32:51.480 --> 33:01.960]  массивчике. Дальше проходимся по всем ребрам, которые у меня есть. Я говорю, что у меня есть
[33:01.960 --> 33:09.440]  компонент В, есть компонент У. Смотрю, в разные ли компоненты это смотрят. В разные, тогда буду
[33:09.440 --> 33:14.520]  их соединять. Не в разные, не буду их соединять. Ну то есть если в одной тоже компоненты это смотрит.
[33:14.520 --> 33:21.240]  То есть я прохожусь просто по всем ребрам. И благодаря тому, что я прохожусь, сколько раз я
[33:21.240 --> 33:28.080]  пройдусь, ну я прохожусь Е раз. Мне нужно пройтись по всем ребрам, чтобы проверить в самом начале.
[33:28.080 --> 33:35.800]  А дальше вот сколько раз вот это вот все будет объединяться друг к дружку. Ну где-то логорифт на
[33:35.800 --> 33:52.600]  самом деле. Поэтому это будет Е лог. Ну вопрос константа. Это чуть быстрее будет. Вот так что так.
[33:52.600 --> 34:00.480]  Понятно, что делает алгоритм Барувки? Вот он просто некоторые вот части оттуда,
[34:00.480 --> 34:04.480]  части отсюда. Вот оно так получилось. Ну больше всего на краскала, конечно, похоже.
[34:04.480 --> 34:13.760]  Вопросы остались к минимальным основным деревьям? Нет. Тогда переходим к одной
[34:13.760 --> 34:20.560]  из самых интересных тем. Называется кратчайшие пути. Что помните про кратчайшие пути?
[34:20.560 --> 34:35.280]  Зря. Все ее любят. Особенности на собеседование. Потому что все ее почему-то на самом деле кратчайшие
[34:35.280 --> 34:44.160]  пути запоминаются. Вот то есть как бы у этого есть максимальное практическое применение. Вот.
[34:44.160 --> 34:51.920]  Потому что представьте следующую картину. Вот у вас есть, вот любите вы играть, не знаю,
[34:51.920 --> 34:57.320]  на мини-карте тыкаете, и вот вам нужно дойти до какого-то места. И он же вам как-то ее прокладывает
[34:57.320 --> 35:06.240]  по минимальному пути. А вот. А навигатор. Ну как бы сейчас это чуть более интеллектуальная вещь,
[35:06.240 --> 35:12.000]  тем просто типа от точки до точки посчитать километры. Но опять же, вот он у вас как-то
[35:12.000 --> 35:17.400]  строит этот некоторый граф, как вам пройти. Но там уже учитываются пробки и так далее. Крутили,
[35:17.400 --> 35:23.520]  навертели. Но суть все равно остается такая же. И так далее. То есть это кратчайшие пути это
[35:23.520 --> 35:30.800]  одно из самых применимых, что есть. И пока что вы знали только один алгоритм поиска. BFS. Был
[35:30.800 --> 35:38.040]  такое. И 0K BFS был. Был такое. Отлично. Теперь давайте говорить про кратчайшие пути в принципе.
[35:38.040 --> 35:49.680]  Смотрите. Представьте, что у нас как бы не целые числа могут выступать для нашего графа весами
[35:49.680 --> 35:54.960]  наших ребер. А вообще любые действительные числа. То есть существует некоторая весовая функция из
[35:54.960 --> 36:03.960]  ребра в какое-то множество положительных пока чисел. Ну не отрицательных. Окей? Не отрицательных
[36:04.840 --> 36:12.160]  чисел. И вот у нас есть некоторая вершина S. И вот из нее нужно найти кратчайшие пути до остальных
[36:12.160 --> 36:19.920]  вершин. То есть вот откуда, как я должен ходить из моей вершины S в остальные вершинки. За сколько
[36:19.920 --> 36:24.400]  минимальное количество времени я могу дойти. То есть это конкретная вершина до всех остальных.
[36:24.400 --> 36:33.560]  Вот такая вот построение задачи. Понятная задача. Задача как бы изучить несложно. И первое,
[36:33.560 --> 36:42.080]  что здесь есть, это алгоритм Dijkstra. Смотрите, алгоритм Dijkstra очень похож на алгоритм Прима.
[36:42.080 --> 36:52.160]  Вы не поверите. Это вот почти что одна и та же сущность будет. А алгоритм Dijkstra... Прима же,
[36:52.160 --> 37:00.040]  я же не ошибся. Да, вот. В действительности мы будем говорить с вами следующее. В любой
[37:00.040 --> 37:06.360]  момент времени мы будем поддерживать два каких-то множества. Множество вершин,
[37:06.360 --> 37:13.640]  которые мы уже прошли и нашли там кратчайшие пути, и множество непокрытых вершин еще. Это
[37:13.640 --> 37:19.360]  будет два непересекающихся множества. И у них есть разрез. Ну это разрез просто нашего графа.
[37:19.360 --> 37:29.320]  Правильно? Вот. И что будет делать алгоритм Dijkstra? Он будет находить минимальное ребро из этого разреза.
[37:29.440 --> 37:38.080]  Между этими разрезами. И говорит, вот пойду по нему. И тогда мы будем находить расстояние до наших вершин.
[37:38.080 --> 37:46.600]  Вот. А мы будем поддерживать это все в массиве некотором Dist. Ну D здесь. D, где мы будем хранить
[37:46.600 --> 37:52.720]  сам этот кратчайший путь. И в зависимости от него куда-то идти. То есть мы будем вот так вот расширяться,
[37:52.720 --> 37:58.920]  расширяться, расширяться и смотреть, что у нас происходит. Вот. Ну то есть давайте опять
[37:58.920 --> 38:06.200]  нарисуем какой-нибудь граф. Вот так хочу. Представим, что я хочу из этой вершины пойти. Вот у меня есть
[38:06.200 --> 38:20.040]  так, так, так, ребро. Вот так. Вот. Я буду выбирать минимальные ребра из этих. И дальше по ним ходить. Как
[38:20.040 --> 38:34.600]  вы думаете, это будет работать вообще? Будто бы нет. Как будто бы да. Непонятно. Так мы же смотрим по
[38:34.600 --> 38:42.760]  разрезам. То есть представьте, что мы вот добавили вот эти все вершины. Мы же пойдем во все остальные. Они
[38:42.760 --> 38:49.160]  как-то связаны с другими. Ну либо граф не связан. Как выглядит сам алгоритм Dijkstra в этом случае? Ну
[38:49.160 --> 38:55.240]  смотрите, мы все также говорим, что у нас есть одна вершина и есть другое множество вершин. Мы говорим,
[38:55.240 --> 38:59.240]  как мы будем отличать множество одно от других? Мы будем говорить, что в одном будет лежать
[38:59.240 --> 39:06.440]  бесконечность. Ну вот размер, который у нас есть. В другом какое-то число. То есть если мы можем
[39:06.440 --> 39:13.800]  дойти до вершины, у нас будет там уже какое-то число. Вот. В этом массиве D мы будем с вами
[39:13.800 --> 39:20.640]  поддерживать следующее. Что расстояние до вершины S нулевое. Почему? Потому что мы из нее стартуем.
[39:20.640 --> 39:29.280]  Правильно? Поэтому там размер все такой же. До всех остальных вершинок мы говорим, что если у нас
[39:29.280 --> 39:40.120]  есть ребро от S, то мы сделаем это расстояние ровно нашим весам. Ага. То есть давайте, ну не знаю,
[39:40.120 --> 39:44.240]  назовите мне еще числа. Мы с вами проделаем весь алгоритм до extra. Будет понятней, я думаю.
[39:44.240 --> 40:00.040]  Три. Один. Пять. Десять. Кто-то очень любит нечетные числа. Дальше. Да, после этого сразу
[40:00.040 --> 40:13.080]  учетные. Хорошо. Два. Одиннадцать и тринадцать. Я услышал тринадцать. Хотите 32 сделаю? Пусть будет
[40:13.080 --> 40:21.360]  тринадцать. Окей. Чуть-чуть несчастье не помешает. В общем-то, а что мы с вами делаем? Мы говорим,
[40:21.360 --> 40:31.400]  что у нас в S хранится вот эта вот нулевая вершина в начале. Стрелочки поставим?
[40:31.400 --> 40:55.360]  Хорошо. Я ставлю максимально рандомно. Он для всех работает. Пойдет такие стрелочки? Все вроде
[40:55.360 --> 41:07.120]  связано. Ну могу здесь в обратную сторону. Поинтереснее. Окей? Окей. Хорошо. Значит, смотрите.
[41:07.120 --> 41:14.640]  Первоначально мой массив D, он какой? Вот в моем множестве S хранится только вот эта вершинка. Да?
[41:14.640 --> 41:28.320]  Массив D, он следующий. Значит, у нас там ноль. До вершины один я дойти не могу. До вершины два.
[41:28.320 --> 41:39.560]  Где у меня два-то? Вот это два. До вершины два я дойти могу и там три. Дальше до вершины три я
[41:39.560 --> 41:51.240]  могу и здесь один. Потом четыре не могу, пять не могу. Логично? Что я дальше делаю? Я говорю,
[41:51.240 --> 42:02.680]  ага, давайте найдем здесь минимальная чиселка. Ну нет, S не считаем. Для всех вершин без S. Один.
[42:02.680 --> 42:09.720]  Такой. Хорошо. В этом случае я расширяю свое множество S и говорю, что вот оно.
[42:09.720 --> 42:28.560]  Окей? И вот эти вот. Ой, ой-ой-ой, сори, не в туда посмотрел. Вот это множество S. Правильно?
[42:28.560 --> 42:39.640]  Сори, не могу выделять красиво. А вот ноль и три у меня получается. Правильно? Вот это и вот это
[42:39.640 --> 42:45.560]  теперь лежит в моем множестве. Могу ли я из нулевой вершины все еще куда-то попасть? То есть
[42:45.560 --> 42:53.640]  что-то, что я не учел среди этих чисел? Вроде нет. Значит, давайте мы обновим массив D уже для этой
[42:53.640 --> 42:58.360]  тройки. То есть тройка только может куда-то увеличить или уменьшить или что-то с этим сделать.
[42:58.360 --> 43:09.480]  Правильно? Давайте смотреть. Мы с вами говорим, что у нас, чтобы дойти из этой нулевой вершины
[43:09.480 --> 43:16.080]  в любую другую, нам нужно пройти через три и куда-нибудь еще. Согласны? Расстояние до
[43:16.080 --> 43:21.720]  этой вершины нужно учитывать. Потому что я же хочу смотреть на расстояние от своей нулевой вершины.
[43:21.720 --> 43:29.880]  Согласны? Поэтому массив D у меня будет обновляться примерно следующим образом. Здесь все будет ноль
[43:29.880 --> 43:37.160]  и единица. Это уже зафиксировано. Смотрим. До второй вершины я могу добраться. А, кстати,
[43:37.160 --> 43:41.840]  сейчас. До первой вершины. До первой вершины я все еще не могу добраться. Согласны? Поэтому
[43:41.840 --> 43:48.600]  тут остается бесконечно. Теперь смотрим на вторую вершину. У меня было три. А если я пойду через третью
[43:48.600 --> 43:55.680]  вершину, то у меня будет один плюс десять. Одиннадцать. Кажется, невыгодно. Правильно? Поэтому
[43:55.680 --> 44:03.360]  мы оставляем все также тройку. До четырех. Чтобы дойти до четырех, я должен вот это расстояние один
[44:03.360 --> 44:15.120]  и прибавить еще шесть. Получаю семь. Ну и до пяти у меня будет восемь. Теперь, смотрите, я вот это и вот это,
[44:15.120 --> 44:25.800]  оно у меня зафиксировано. Я смотрю на все остальные вершины. Какая у меня самая минимальная? Три. Это у нас
[44:25.800 --> 44:32.160]  вершина номер два. Согласны? Теперь моим множеством S становится вот эта вот штука.
[44:32.160 --> 44:45.920]  То есть у меня фиксируется теперь ноль, три, один. Давайте смотреть от двойки. От двойки я могу хоть
[44:45.920 --> 44:54.120]  куда-нибудь попасть. Никуда. Поэтому у меня остается бесконечность семь, восемь. Какое минимум из них? Семь.
[44:54.120 --> 45:05.880]  Смотрим дальше. Семь у меня относится к четырем. У меня вот так еще добавляется. Окей. Поехали. У нас
[45:05.880 --> 45:15.360]  будет ноль, три, один, семь уже зафиксировано. Теперь я смотрю просто расстояние до первой вершины
[45:15.360 --> 45:20.880]  и до пятой вершины. Правильно? Правильно. Из четырех в пятую вершину попасть никак не могу,
[45:20.880 --> 45:30.400]  ничего не происходит. А вот в единичку могу. И у меня будет семь плюс два. Согласны? Это расстояние
[45:30.400 --> 45:39.440]  семь до четырех плюс два. Здесь будет девять. Ну и пятерка у меня остается восемь. Смотрите,
[45:39.440 --> 45:50.640]  чтобы было какое-нибудь интрига, мы можем добавить еще одну ребро вот так. Какое хотите число? Нельзя. Мы
[45:50.640 --> 46:03.360]  пока говорим про не отрицательное. Ну давайте, а давайте четыре. Сейчас подождите, я подумаю,
[46:03.360 --> 46:15.040]  четыре. Нет, четыре не прикольно. Давайте ноль. Хорошо? Не отрицательное. Вот. Смотрите,
[46:15.040 --> 46:22.120]  у меня зафиксировано ноль, три, один, семь. Восемь фиктирую. Восемь это последний элемент. Правильно?
[46:22.120 --> 46:30.280]  Мы смотрим до первого элемента, чтобы обновить. Что мы смотрим? Ага. У меня здесь было девять,
[46:30.280 --> 46:35.920]  а я могу пойти через нулевое ребро, и тогда у меня от восьми будет восемь опять. Получается,
[46:35.920 --> 46:43.480]  я делаю ноль, восемь, три, один, семь, восемь. Вот это, вот это, вот это, вот это зафиксировано,
[46:43.480 --> 46:48.880]  вот это остается. Ну как бы от него никакие ребра уже не идут, мы уже все рассмотрели. Понятно?
[46:48.880 --> 47:04.720]  Как работает алгоритм Dijkstra? На что похоже? Или на что не похоже? На прям похоже? Ну по сути
[47:04.720 --> 47:10.000]  у нас есть вот эти некоторые разрезы, мы берем минимальное ребро, впихиваем его и смотрим. Здесь
[47:10.000 --> 47:16.520]  по сути такое же алгоритм, почти что. Просто смотрим на минимальное расстояние уже. Вот,
[47:16.560 --> 47:23.680]  здесь тоже был пример, но чуть более сложный. Я думаю, я боюсь его вам долго расписывать. Вот.
[47:23.680 --> 47:32.960]  Корректность. Тот, кто сомневался, что Dijkstra работает. Давайте докажем корректность. Если мы
[47:32.960 --> 47:41.160]  говорим, что ребра у нас, у графа не отрицательны, то по завершению работы алгоритма у нас будет все
[47:41.160 --> 47:51.280]  корректно. То есть расстояние, то, которое мы найдем, будет минимальным расстоянием. Как это
[47:51.280 --> 47:59.360]  все доказывается? Мы будем доказывать индукции по числу итераций. Смотрите, ну база индукции,
[47:59.360 --> 48:07.680]  нулевое, нулевая вершина, нулевое расстояние, оно минимально. Согласны? У меня нет отрицательных,
[48:07.680 --> 48:15.200]  отрицательных ребер, отрицательных циклов, значит, не может быть, значит, все хорошо. Окей? Вот.
[48:15.200 --> 48:27.680]  Теперь давайте про переход. Смотрите. Мы говорим, что для любой вершины V из S,
[48:27.680 --> 48:35.960]  то есть вот, вот, которая у меня уже находится в моем множестве S, оно вертно. То есть вот это
[48:35.960 --> 48:52.160]  наше предположение индукции. Окей? Окей. А рассмотрим кратчайший путь из S до U. Что такое U? Что такое S?
[48:58.160 --> 49:04.120]  Ну, смотрите, ну как бы, S это что-то из множества, которое у нас уже верное,
[49:04.280 --> 49:14.920]  U это другой разрез. Какой-нибудь S, S это то самое начальное число, а вот U тут какая-то вершинка.
[49:14.920 --> 49:30.520]  Окей? Этот кратчайший путь должен пересекать данный разрез, правда? По какому-то ребру. Ну,
[49:30.680 --> 49:38.640]  вот здесь еще может продолжаться путь, но когда-нибудь он придет. Вот. У нас есть то есть
[49:38.640 --> 49:49.600]  некоторая вершина X и некоторая вершина Y. Вот он, этот путь. Тогда, ой, ой, ой, ой. Тогда мы
[49:49.600 --> 49:59.920]  точно с вами знаем, что вот если мы рассмотрим весь этот наш путь, который у нас есть, до вершины,
[49:59.920 --> 50:04.360]  например, Y по этому кратчайшему пути, согласны, что другого кратчайшего пути в принципе не
[50:04.360 --> 50:10.120]  должно быть? То есть, если у меня кратчайший путь проходит через Y, то этот кратчайший путь будет
[50:10.120 --> 50:21.240]  до Y тоже? Или нет? Или да? Да. Вот. А чему у меня равен, равно вот этот вот кратчайший путь до
[50:21.760 --> 50:35.040]  нашей вершины Y? От S до Y. Ну, он складывается из rho SX плюс вес нашего ребра XY. Согласны? Правда?
[50:35.040 --> 50:45.880]  Правда. Теперь, смотрите, по нашему предположению индукции в S все корректно. Поэтому rho SX это то
[50:45.880 --> 50:56.280]  же самое, что dx. Согласны? Согласны. Вот. И получается, у нас к этому dx добавляется вес нашего
[50:56.280 --> 51:07.320]  ребра XY. Отлично. У нас все это получилось. Теперь вопрос, что мы можем здесь еще дополнительно
[51:07.320 --> 51:14.240]  к этому всему сказать? Что мы должны как-то вычислить вот этот dy и сказать, что он равен тому,
[51:14.240 --> 51:21.840]  что нам необходимо. dy как вычисляется? dy вычисляется из старого какого-то значения,
[51:21.840 --> 51:34.000]  либо из dx плюс xy. Вес этого xy. Хорошо. Все нормально здесь, с одной стороны. Но,
[51:34.000 --> 51:42.160]  когда мы на это все смотрим, то в действительности мы получаем, что у нас будет равенство уже,
[51:42.320 --> 51:50.920]  что dy у меня будет равен dx плюс вес xy. Почему? Потому что у нас это расстояние d,
[51:50.920 --> 52:00.960]  оно явно всегда больше либо равно, чем минимальное расстояние. Согласны? Вот. Из-за этого dy не
[52:00.960 --> 52:12.760]  может быть меньше, чем dx плюс вес xy. С точки зрения реализации. Реализация бывает с
[52:12.760 --> 52:19.040]  поиском минимума пирамиды, с помощью минимума наивного, с помощью минимума фибоначевой пирамиды.
[52:19.040 --> 52:29.120]  Все ровно то же самое, что было у вас где? В Риме. Аналогично ровно тому, что происходило. То есть,
[52:29.120 --> 52:36.040]  вы можете делать за e локве, за e плюс v локве и так далее. Оно происходит аналогично. Если
[52:36.040 --> 52:43.240]  просто искать минимум, то это e плюс v квадрат. Когда что лучше делать в dx, то здесь уже думать
[52:43.240 --> 52:52.520]  вам самостоятельно. Здесь ровно то, что мы с вами когда-то говорили еще в Риме, что в разреженных
[52:52.520 --> 53:00.120]  графах можно и нужно использовать бинарные пирамиды, в плотных графах использовать массивы сами
[53:00.120 --> 53:09.680]  по себе. Окей? Принято. Вот. Теперь представьте следующее. У нас существует отрицательный
[53:09.680 --> 53:20.280]  ребр. Отрицательный ребр — это беда. Почему не будет работать dx? Да, вся проблема будет в
[53:20.280 --> 53:30.360]  отрицательных циклах. Если у вас есть некоторый цикл и даже не то что цикл, у вас может быть путь
[53:30.360 --> 53:43.480]  просто отрицательный. Например, вот такое. У вас сюда расстояние там 7, сюда расстояние 10, а вот
[53:43.480 --> 53:57.080]  здесь будет расстояние там минус 100. Нет, вот так. Цикла не будет. То есть до этой вершины минус 90,
[53:57.080 --> 54:03.440]  вообще кратчайшее расстояние. Алгоритм же dx сам по себе работает на основе же одного алгоритма. То
[54:03.440 --> 54:10.200]  есть он берет минимальное ребро и забирает его себе, забирает эту вершину. Именно из-за этого это так
[54:10.200 --> 54:16.040]  работает. Поэтому с отрицательными ребрами здесь нужно всегда быть аккуратным. Если мы с вами
[54:16.040 --> 54:20.360]  говорим, что есть отрицательные ребра, то дэкстра начинает не работать.
[54:20.360 --> 54:47.840]  Мы уже зафиксируем же, да. У меня будет 0, 7, 10. 7 фиксирую. Говорю, что сюда расстояние 7.
[54:47.840 --> 55:04.280]  И больше я не обновляю это. Вот. В этом всем проблема. И если бы мы с вами в действительности искали
[55:04.280 --> 55:10.640]  даже простые кратчайшие пути, то это была бы проблема с НП полными задачами. Ой, с НП полной задачи,
[55:10.640 --> 55:16.080]  то есть мы не решали бы быстро хоть за какое-то нормальное время. Решали бы за какой-то дикий
[55:16.080 --> 55:25.120]  поляном. Это не круто, это не прикольно. И в этом вся проблема. В действительности задача поиска
[55:25.120 --> 55:29.560]  кратчайшего пути хоть как-то корректна, если в графе нет отрицательных циклов. Логично,
[55:29.560 --> 55:34.360]  логично. Если мы попытаемся с вами добавить отрицательный цикл, у нас совсем все ломается.
[55:34.360 --> 55:42.040]  Там минус бесконечность есть везде. Мы сколько хотим, можем пройтись по этому всему. Поэтому
[55:42.040 --> 55:49.520]  здесь у нас есть некоторые вещи, которые мы должны с вами понимать, что эти отрицательные циклы мы
[55:49.520 --> 55:56.520]  должны фиксировать. Если они вдруг есть, мы говорим, что ничего не работает. Потому что у нас просто
[55:56.520 --> 56:04.720]  отрицательные веса эти есть. Алгоритм Dijkstra не подходит, мы с вами обсудили почему. Вот. Если
[56:04.720 --> 56:09.160]  вдруг вас просят на экзамене, вы говорите, ну алгоритм жадный, не учитывает чуть-чуть побольше
[56:09.160 --> 56:17.480]  пути. Все, а это конец. И с алгоритмом Dijkstra, к сожалению, нужно придумывать, что делать. Что?
[56:17.480 --> 56:33.040]  Нет. А какой потенциал вершины? Придумаешь, скажешь. Да, мы такую задачу рассмотрим. Если
[56:33.040 --> 56:39.280]  потенциалы прибавлять, то да. Ну если ввести потенциал вообще, в принципе. Вот. Но прибавить
[56:39.280 --> 56:44.480]  ко всем какое-то число не получится. У тебя путь может состоять из пяти вершин или из одной.
[56:44.480 --> 56:51.800]  Из пяти ребер или из одного. Из-за этого у тебя будет разница. Вот этих плюсов. Вот. Ну в общем
[56:51.800 --> 56:58.560]  случае пока что мы с вами говорим про алгоритм Форда Белмана. Что это такое вообще за чудо?
[56:58.560 --> 57:10.560]  Смотрите. Пусть у нас будут найдены какие-то пути из S в. У нас есть Dist V и есть Dist U. И мы
[57:10.560 --> 57:19.040]  будем с вами брать и делать релаксацию ребер. Что такое релаксация ребер сама по себе? Ну вот у
[57:19.040 --> 57:28.040]  нас есть вершина V, есть вершина U. Я говорю, что у меня из V в U есть ребро. Давайте с вами проверим,
[57:28.040 --> 57:37.520]  что расстояние в U будет не больше, чем Dist от V, плюс вот это ребро, которое мы делаем. То есть
[57:37.520 --> 57:46.720]  смотрите. У нас есть некоторые вершины V, некоторые вершины U и вот какое-то ребро. Ну не знаю там,
[57:46.720 --> 57:56.160]  с весом Омега. Релаксация. Я говорю, что сюда расстояние D от U, сюда расстояние D от V. Я говорю,
[57:56.160 --> 58:07.640]  что, ага, проверим, если у меня D у будет больше, больше, чем D от V, плюс это Омега, тогда я сделаю
[58:07.640 --> 58:15.200]  релаксацию ребер и скажу, что расстояние до моей U равно вот этому. Логично? Логично. То есть я говорю,
[58:15.200 --> 58:19.520]  что да, бесконечность была, давайте сейчас что-нибудь с этим сделаем. И вот это называется
[58:19.520 --> 58:24.760]  релаксация ребер. И алгоритм Форда Белмана говорит нам следующее. Согласны ли вы с тем,
[58:24.760 --> 58:30.840]  что любой кратчайший путь, если у меня нет отрицательных циклов, например, он состоит не
[58:30.840 --> 58:41.720]  более чем из V-1 ребра? Согласны? Ну как бы максимально вот развернем, получим такой путь.
[58:41.720 --> 58:50.760]  Поэтому для нахождения всех путей достаточно V-1 раз отрелаксировать все ребра.
[58:54.760 --> 59:05.440]  Ну смотрите, у меня есть в начале вот эта вот нулевая вершинка. Да? Я запускаю релаксацию
[59:05.440 --> 59:13.240]  ребер и все вершины, до которых оно достает, с расстоянием 1, ну вот расстоянием, я имею в виду
[59:13.240 --> 59:20.680]  количество ребер, оно отрелаксирует корректно. Согласны? То есть у меня станет уже вот так,
[59:21.080 --> 59:26.360]  в начале было вот такое, а теперь вот так. Дальше, когда я начну еще одну релаксацию,
[59:26.360 --> 59:34.480]  согласны, что вот это отрелаксирует корректно путь до всех вершин, которые находятся на расстоянии 1 от
[59:34.480 --> 01:00:00.320]  вот этих. А? Там не было кода. А, релаксация? True или false? Была релаксация или нет? Ну что
[01:00:00.320 --> 01:00:06.360]  делает этот код? Он проверяет вот это, если это действительно так, и у меня расстояния до У больше,
[01:00:06.360 --> 01:00:20.800]  то так. Окей. Вот, ну то есть смотрите, мы прорелаксировали раз ребра, расстояние 1 нашли
[01:00:20.800 --> 01:00:27.920]  корректно. Согласны? Прорелаксировали еще раз, уже в расстоянии 2 зашли. Ну в такую эпоху 2,
[01:00:27.920 --> 01:00:33.920]  я не знаю, как лучше назвать вам. Ага. И так далее. То есть мы вот это вот все продолжаем и делаем,
[01:00:33.920 --> 01:00:39.960]  и все становится чудесно. А так как у меня максимальный путь V-1, ребро, то V-1 раз я
[01:00:39.960 --> 01:00:48.560]  прорелаксирую все ребра, получу свой ответ. Ага. Есть вопросы? Вот. Поэтому в действительности
[01:00:48.560 --> 01:01:01.920]  алгоритма Форда Белмена выглядит вот так. Еще раз смотрите, мы не решаем проблему цикла,
[01:01:01.920 --> 01:01:08.080]  мы решаем проблему отрицательных ребер. Если есть отрицательное ребро, не означает,
[01:01:08.080 --> 01:01:16.240]  что будет цикл. С точки зрения отрицательных ребер представим следующую вот, опять же,
[01:01:16.240 --> 01:01:22.600]  вот эту картину. У меня первая это 0, что там? Ну бесконечность, к примеру, бесконечность.
[01:01:22.600 --> 01:01:29.680]  Я делаю релаксацию, я релаксирую вот от этого ребра ко всем остальным. У меня получается 0, 7,
[01:01:29.680 --> 01:01:37.640]  10. Ага. Я запускаю еще одну релаксацию, потому что у меня V-1 раз должно быть, 2 раза хотя бы.
[01:01:37.640 --> 01:01:47.320]  0 остается нулем. До 7 вот здесь до первого элемента, у меня здесь 7, а здесь у меня получится 10 минус
[01:01:47.320 --> 01:01:56.720]  100. Поэтому будет минус 90. Ну а до двойки 10 так было, так и осталось. Вот проблема решена.
[01:01:56.720 --> 01:02:08.360]  Поэтому алгоритм Форд Белман вот такой. Сложность у него V-e. То есть в плотных графах
[01:02:08.360 --> 01:02:24.080]  работает ZV-куп. Не круто, но как есть. Ага. Есть тут вопросы? Нету вопроса. Чудно. Вот. Давайте
[01:02:24.080 --> 01:02:28.280]  докажем корректность. Почему, если у нас в графе отсутствуют отрицательные циклы,
[01:02:28.280 --> 01:02:34.520]  то по завершению алгоритма у нас будет все правильно. Ну смотрите. Рассмотрим какую-то
[01:02:34.520 --> 01:02:40.920]  произвольную вершину V и кратчайший путь до нее. Вот этот кратчайший путь он состоит из вершинки
[01:02:40.920 --> 01:02:47.720]  S самой начальной, а до этой вершины V. Окей? Ну как бы обозначение понятное. Он состоит из
[01:02:47.720 --> 01:02:58.400]  нескольких вершинок. Покажем, что после каты итерации, но вот здесь вот сейчас. Ну да. А после
[01:02:58.400 --> 01:03:04.000]  каты итерации нам нужно доказать, что вот то, что я говорил, что мы вот ходим по вот этим вот уровням
[01:03:04.000 --> 01:03:10.920]  и оно становится корректно. Это будет минимальный путь. И тогда это будет все правда. Ну как бы как
[01:03:10.920 --> 01:03:18.320]  это можно сделать? Ну по индукции. Для базы у нас понятно. Теперь мы смотрим на переход. Пусть у нас
[01:03:18.320 --> 01:03:26.200]  на k-1 итерации все корректно. Предполагаем, предполагаем. Отлично. Значит, на каты, на каты
[01:03:26.200 --> 01:03:33.480]  самой итерации у нас будет релаксироваться ребро vk-1, vk-2. Правильно? Если оно релаксируется,
[01:03:33.480 --> 01:03:39.080]  то у нас вот это расстояние будет правильное, потому что оно входит в кратчайший путь все еще.
[01:03:39.080 --> 01:03:49.120]  Согласны? Вот. А значит у нас все правильно. Ну вот как-то так. Ну то есть вот это вот то,
[01:03:49.120 --> 01:03:56.120]  что написано, что дист от vk равно дист от vk-1 плюс омега k-1 vk. То есть оно отрелаксировалось.
[01:03:56.120 --> 01:04:04.680]  Так как оно входит в кратчайший путь, то все хорошо. Мы говорим, что rho от s vk-1. Это как
[01:04:04.680 --> 01:04:12.840]  раз минимальный кратчайший путь. Точнее d от s до vk-1. Плюс вот это вот, вот это наше ребро. И
[01:04:12.840 --> 01:04:22.160]  мы получаем, что мы находим этот самый кратчайший путь. Все. Форт Белман очень легко доказывается.
[01:04:22.160 --> 01:04:33.520]  А вот теперь смотрите. А как нам определить, что у нас есть цикл читательного веса?
[01:04:33.520 --> 01:04:54.320]  С помощью алгоритма Форда Белмана. Подряд? Да. Давайте сделаем на одну релаксацию больше.
[01:04:54.320 --> 01:05:04.280]  v-1 это максимальный простой путь. Его длина согласны. Давайте запустим еще раз релаксацию
[01:05:04.280 --> 01:05:12.000]  всех ребер. И в случае, если эта релаксация произошла, то у нас есть цикл отрицательного веса.
[01:05:12.000 --> 01:05:25.080]  Вот и все. Вот. Поэтому мы просто делаем таким вот моментом. Просто вот этот кусок, надеюсь,
[01:05:25.080 --> 01:05:33.360]  что вам достаточно понятен и прост должен быть. Окей? Океюшки. Ну как бы, а то, что алгоритм
[01:05:33.360 --> 01:05:40.800]  действительно найдет кратчайший путь корректно, ну а если у нас нет кратчайшего пути, ой, если у
[01:05:40.800 --> 01:05:45.000]  нас нет цикла отрицательного веса, то все понятно, мы с вами доказали корректность. Только что он
[01:05:45.000 --> 01:05:50.920]  вернет правильно. Вот если у нас есть отрицательный цикл какой-то, ну тогда это делается аналогично
[01:05:50.920 --> 01:05:55.560]  тому, что мы делали с вами ранее. Мы строим вот этот путь, смотрим, что у нас там происходит и
[01:05:55.560 --> 01:06:01.480]  смотрим, ага, что у нас расстояние будет по какой-то сумме отрицательное. Почему? Потому что мы еще
[01:06:01.480 --> 01:06:10.520]  раз прорелаксировались и сделали какой-то путь больше, чем k-1, чем v-1. Тогда вам задачка
[01:06:10.520 --> 01:06:15.920]  наподумать, а что нам сделать с отрицательными ребрами так, чтобы мы могли запустить дейкстру.
[01:06:15.920 --> 01:06:23.960]  Задача сразу скажу не тривиальная. Тогда, в принципе, все. Хорошего вам вечера. Пока-пока.
