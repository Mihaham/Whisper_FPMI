[00:00.000 --> 00:13.000]  Так, пора начинать. Начнем с вопроса. Внезапно, что вы думаете насчет этого кода?
[00:13.000 --> 00:25.000]  Ну, немного предыстории. Я решил немного посмотреть посылки ваши по заданиям и так далее.
[00:25.000 --> 00:30.000]  Некоторые стали активно пользоваться исключениями. Это на самом деле здорово.
[00:30.000 --> 00:36.000]  Но хочется как бы разобрать пару ошибок, которые на самом деле студенты каждый год совершают.
[00:36.000 --> 00:40.000]  И каждый год так или иначе приходится к этому возвращаться.
[00:40.000 --> 00:44.000]  В общем, что здесь происходит? Я написал функцию f, которая что-то делает.
[00:44.000 --> 00:47.000]  Потом в какой-то момент у нее происходит что-то опасное.
[00:47.000 --> 00:51.000]  Ну, в частности, опасный вызов функции g, которая потенциально может что-то бросить.
[00:51.000 --> 00:57.000]  Я тут ловлю это исключение, а потом пробрасываю дальше. В чем беда?
[00:57.000 --> 01:04.000]  Все понимают, что это бесполезное действие.
[01:04.000 --> 01:09.000]  То есть вы поймали исключение, а потом сразу его выбросили обратно.
[01:09.000 --> 01:15.000]  Грубо говоря, если вы тут не писали try-catch-блок, то программу вы сделаете то же самое.
[01:15.000 --> 01:19.000]  То есть если у вас из g вылетает исключение, вы его никак не обрабатываете, но просто летит дальше.
[01:19.000 --> 01:23.000]  Здесь вы написали то же самое, но просто некоторыми дополнительными средствами.
[01:23.000 --> 01:28.000]  И потенциально замедлили свой рантайм и так далее. Здесь ясно?
[01:28.000 --> 01:37.000]  То есть написать вот эту штуку это, по сути, то же самое, как если бы вы написали просто вызов функции g внутри функции f.
[01:37.000 --> 01:42.000]  То есть если вам на самом деле не хочется эту ошибку обрабатывать, то есть если вам не нужно делать никаких лишних действий,
[01:42.000 --> 01:46.000]  то и, соответственно, лишний раз ловить исключение, потом ее снова перебрасывать, естественно, не нужно.
[01:46.000 --> 01:51.000]  Потому что это ровно то, как работает программа в нормальном режиме.
[01:51.000 --> 01:57.000]  Ну и есть еще один более интересный кейс. Выглядит он следующим образом.
[01:57.000 --> 02:01.000]  У вас есть функция f, которая сама что-то бросает.
[02:01.000 --> 02:08.000]  И вот это само выбрасывание заворачивается в try-catch-блок, то есть вы в try делаете throw, потом это все ловите и выбрасываете.
[02:08.000 --> 02:13.000]  Наверное, стоит прокомментировать, так как я это своими глазами видел.
[02:13.000 --> 02:19.000]  Еще раз, что здесь происходит. Если вы хотите из функции f выбросить исключение, то просто бросайте его и все.
[02:19.000 --> 02:23.000]  Не надо его бросать, подкидывать, ловить и потом дальше бросать.
[02:23.000 --> 02:27.000]  Это бесполезно. Если вы уж решили бросить исключение, то бросайте.
[02:27.000 --> 02:32.000]  Если вам нужно какие-то действия перед выбросом исключения сделать, то сделайте это до throw.
[02:32.000 --> 02:39.000]  Не надо бросать исключение, потом вспоминать, ой, а я там память не освободил, давайте я в каче, это освобожу память и потом снова выброшу.
[02:39.000 --> 02:45.000]  Просто сделайте все до throw и все будет работать как надо.
[02:45.000 --> 02:51.000]  Это была небольшая преамбула.
[02:51.000 --> 02:58.000]  Теперь давайте вернемся к нашему плану разговора про исключение.
[02:58.000 --> 03:04.000]  Сегодня мы поговорим, так скажем, закончим разговоры про исключение.
[03:04.000 --> 03:13.000]  Поговорим про исключение в конструкторах и деструкторах, про гарантии безопасности исключения и то, как писать безопасный код на C++.
[03:13.000 --> 03:20.000]  Дальше немного поговорим про стандартную библиотеку исключений в языке C++.
[03:20.000 --> 03:23.000]  Итак, исключение в конструкторах и деструкторах.
[03:23.000 --> 03:30.000]  В прошлый раз, когда мы заканчивали лекцию, мы говорили, что одним из ключевых преимуществ использования исключения перед, скажем,
[03:30.000 --> 03:35.000]  например, возвратом кода ошибки является возможность сообщить об ошибке в конструкторе.
[03:35.000 --> 03:41.000]  Если вы используете возврат кода ошибки, то если у вас что-то идет не так в конструкторе, то у вас нет возможности об этом сообщить пользователю,
[03:41.000 --> 03:43.000]  потому что конструктор ничего не возвращает.
[03:43.000 --> 03:51.000]  Но если вы бросаете исключение, то у вас есть возможность из конструктора выбросить исключение и таким образом сообщить пользователю, что что-то пошло не так.
[03:51.000 --> 03:57.000]  Но тем не менее, есть пара тонких моментов, про которые стоит поговорить, когда мы говорим про исключение в конструкторах.
[03:57.000 --> 04:00.000]  Начнем с вот такого кода.
[04:00.000 --> 04:03.000]  Есть у него структура A, и у нее есть два поля.
[04:03.000 --> 04:08.000]  Одно имеет тип Вектор, второе имеет тип Сравоуказатель на int.
[04:08.000 --> 04:15.000]  Ну и что я делаю? Я свожу дефолтный конструктор, который инициализирует вектор из ста элементов,
[04:15.000 --> 04:19.000]  ну и дальше я сохраняю в ПТР указатель на динамическую область памяти.
[04:19.000 --> 04:24.000]  То есть выделяю в динамическую область памяти некоторый кусочек и сохраняю указатель на него в ПТР.
[04:24.000 --> 04:30.000]  И дальше я внутри тела конструктора, например, вызываю функцию F, которая чисто теоретически и потенциально может бросить исключение.
[04:30.000 --> 04:36.000]  В чем потенциальная проблема?
[04:36.000 --> 04:41.000]  Да, при этом у меня еще есть написанный деструктор, который вызывает далить ПТР.
[04:41.000 --> 04:46.000]  С Вектором, естественно, ничего делать не надо, потому что деструктор для Вектора вызовется автоматически.
[04:46.000 --> 04:51.000]  Что здесь может пойти не так? Догадки может какие-то есть.
[04:51.000 --> 04:56.000]  Ну у меня же есть деструктор.
[04:56.000 --> 05:02.000]  Ну в целом да, в общем правило здесь такое.
[05:02.000 --> 05:07.000]  Дело в том, что если у вас конструктор бросает исключение, то объект считается не созданным.
[05:07.000 --> 05:10.000]  То есть если конструктор не завершил работу все по какой-то причине,
[05:10.000 --> 05:13.000]  ну там классическая причина, из конструктора вылетело исключение,
[05:13.000 --> 05:17.000]  то считается, что в программе вашего объекта создана не было.
[05:17.000 --> 05:21.000]  Ну, понятно, если конструктор разработMM для конца, то объект создан не до конца.
[05:21.000 --> 05:26.000]  А следовательно, если объект не был создан, то и деструктор для него вызванock не будет.
[05:26.000 --> 05:29.000]  Понятно?
[05:29.000 --> 05:32.600]  Если объект создан не до конца, то есть его конструктор выполнился не полностью,
[05:32.600 --> 05:36.000]  то и деструктор для такого объекта вызывать чисто теоретически опасно.
[05:36.000 --> 05:37.600]  Деструктора для него вызывать нельзя.
[05:37.600 --> 05:40.800]  То есть если у вас объект не создан до конца, то уничтожать его, естественно, нельзя.
[05:40.800 --> 05:44.000]  Поэтому здесь возникает проблема утечки памяти.
[05:44.000 --> 05:48.600]  То есть мы выделили память в списке инициализации для APTR.
[05:48.600 --> 05:52.000]  Дальше у нас f бросило исключение, объект as был создан не до конца,
[05:52.000 --> 05:55.000]  но при этом память мы выделили. Беда.
[05:55.000 --> 05:57.600]  Как мы решаем эту проблему? Как и раньше.
[05:57.600 --> 06:01.200]  Оборачиваем опасную функцию в try-catch-блок.
[06:01.200 --> 06:04.600]  В try вызываем функцию f, в cache эту функцию ловим,
[06:04.600 --> 06:07.200]  удаляем указатель и выбрасываем дальше.
[06:07.200 --> 06:09.800]  Ну хорошо, эту проблему победили.
[06:09.800 --> 06:10.800]  Второй вопрос.
[06:10.800 --> 06:15.400]  Смотрите, у меня помимо APTR в моем классе есть еще и вектор.
[06:15.400 --> 06:20.200]  То есть у меня класс A состоит из вектора и указателя на динамическую область памяти.
[06:20.200 --> 06:22.600]  Ну хорошо, динамическую память я освободил.
[06:22.600 --> 06:27.000]  Вопрос. Что делать с вектором?
[06:27.000 --> 06:31.000]  Вызвать вектор-деструктора.
[06:31.000 --> 06:35.600]  Вообще говоря, можно вызывать деструктора у объектов,
[06:35.600 --> 06:46.600]  но скажем, если у вас есть вектор v, то чисто теоретически можно позвать вот так.
[06:46.600 --> 06:48.400]  То есть это допустимо.
[06:48.400 --> 06:52.800]  Но вопрос в другом. Нужно это делать или нет?
[06:52.800 --> 06:55.000]  Ну короче говоря, ответ нет.
[06:55.000 --> 06:58.600]  Дело в том, что в этом и заключается смысл раи,
[06:58.600 --> 07:01.800]  в этом и заключается смысл вот этих классов оберток, которые мы и там пишем.
[07:01.800 --> 07:04.000]  Вектор, умные указатели и так далее.
[07:04.000 --> 07:07.600]  Дело в том, что они гарантируют, что для любого созданного объекта
[07:07.600 --> 07:11.800]  для любого созданного объекта у вас в итоге будет вызван деструктор.
[07:11.800 --> 07:13.600]  То есть какая здесь логика на самом деле?
[07:13.600 --> 07:15.000]  Логика следующая.
[07:15.000 --> 07:18.600]  У вас конструктор A завершился неполностью.
[07:18.600 --> 07:21.000]  То есть у вас есть объект A, из чего он состоит?
[07:21.000 --> 07:24.800]  Он состоит из вектора, и он состоит из указатель на динамическую область памяти.
[07:24.800 --> 07:26.400]  Этот объект был создан неполностью,
[07:26.400 --> 07:28.160]  поэтому для него деструктор не будет вызван.
[07:28.160 --> 07:30.800]  Для объекта A как целого деструктор не вызывается.
[07:30.800 --> 07:32.720]  Но при этом,
[07:32.720 --> 07:36.000]  при этом, у него есть составная часть, это вектор.
[07:36.000 --> 07:38.400]  То есть вектор, это часть объекта A.
[07:38.400 --> 07:43.000]  И вот сам вектор, как часть объекта A, был создан целиком,
[07:43.000 --> 07:44.400]  то есть это полноценный объект.
[07:44.400 --> 07:45.360]  Но так, как он был создан,
[07:45.360 --> 07:47.600]  то для него соответственно будет вызван деструктор.
[07:47.600 --> 07:49.800]  Все нормально. Понятно?
[07:49.800 --> 07:53.360]  То есть если у вас внутри класса есть поля,
[07:53.360 --> 08:00.360]  которые имеют тип sd-вектор или у вас есть поля других классов, то если они были созданы в момент конструирования, то есть
[08:00.360 --> 08:07.360]  в момент выброса исключения эти объекты успели создаться, то для них будет вызван деструктор.
[08:07.360 --> 08:15.360]  Короче говоря, общее правило, без оглядки на исключение в конструкторах и так далее, для всех объектов, которые были созданы полностью,
[08:15.360 --> 08:21.360]  будет вызван деструктор. Вот здесь вектор создаться успел до того, как мы выбросили исключение.
[08:21.360 --> 08:27.360]  Соответственно для вектора будет вызван деструктор. Объект A не был создан до конца в момент выброса исключения,
[08:27.360 --> 08:33.360]  поэтому сам деструктор A вызван не будет, и поэтому нам нужно самостоятельно здесь в страйке чблоке вызвать delete.
[08:33.360 --> 08:37.360]  Окей? Все ясно.
[08:37.360 --> 08:49.360]  Ну и собственно возвращаемся к морали с прошлой лекции. Не нужно использовать, в общем, уже сейчас на текущем этапе
[08:49.360 --> 08:56.360]  не нужно использовать динамически выделяемую память. Вот этот сырой указатель, который был использован в предыдущем примере,
[08:56.360 --> 09:02.360]  вполне спокойно может заменить на умный указатель, например, std.unic.ptr. И тогда все будет работать отлично. Почему?
[09:02.360 --> 09:08.360]  Потому что если у вас в какой-то момент будет выброшено исключение, то есть смотрите, у вас был создан объект V,
[09:08.360 --> 09:15.360]  а у вас был создан объект ptr, который является unic.ptr. И дальше, если у вас внутри конструктора F вызывается исключение,
[09:15.360 --> 09:21.360]  то все будет очищено нормально. Для вектора будет вызван деструктор, так как он успел создаться,
[09:21.360 --> 09:26.360]  и для умного указателя тоже будет вызван деструктор, потому что он успел в какой-то момент создаться. Все, никаких проблем.
[09:26.360 --> 09:32.360]  То есть не нужно писать ни деструктора, не нужно писать копирования, перемещения и так далее. Все сделано за вас.
[09:32.360 --> 09:39.360]  И код автоматически становится безопасным. Пример понятен? Мораль тоже понятна?
[09:39.360 --> 09:48.360]  Тогда небольшой выточняющий вопрос. Хорошо, у меня в этом классе есть деструктор. Есть у меня в этом классе конструктор копирования?
[09:58.360 --> 10:03.360]  А как выглядит конструктор копирования для unic.ptr?
[10:03.360 --> 10:15.360]  Да, смотрите. Деструктор в этом классе есть. Дефолтный деструктор просто вызывает деструктор от всех полей классов.
[10:15.360 --> 10:21.360]  Давайте начнем с того, что тут есть. Есть ли тут конструктор перемещения?
[10:21.360 --> 10:27.360]  Конструктор перемещения есть. Потому что если мы не написали свой конструктор перемещения, ну и конструктор копирования,
[10:27.360 --> 10:32.360]  то компилятор за нас создает перемещение и как оно работает.
[10:32.360 --> 10:45.360]  То есть просто вызовется перемещение у поля вектора и перемещение у unic.ptr. То же самое с перемещающим присваиванием.
[10:45.360 --> 10:50.360]  А конструктор копирования создан не будет. В этом классе, в классе A, конструктора копирования нет. Почему?
[10:50.360 --> 10:56.360]  Потому что одно из полей у вас некопируемое. И это unic.ptr. Для unic.ptr конструктор копирования объявлен как удаленный.
[10:56.360 --> 11:00.360]  Поэтому конструктор копирования для A тоже будет объявлен как удаленный.
[11:00.360 --> 11:04.360]  Если вы заводите поле unic.ptr, наверное вы на это поведение рассчитываете.
[11:04.360 --> 11:10.360]  Если у вас какое-то поле копировать нельзя, то понятно, что и класс целиком копировать, наверное, нельзя.
[11:10.360 --> 11:16.360]  Все, что тут показано, демонстрирует так называемое правило нуля.
[11:16.360 --> 11:20.360]  Мы прошли весь цикл эволюции. Мы поговорили про правила трех.
[11:20.360 --> 11:26.360]  Потом, когда мы поговорили про семантику перемещения, мы поговорили про правила пяти.
[11:26.360 --> 11:28.360]  И теперь переходим до правила нуля.
[11:28.360 --> 11:30.360]  В общем, правило нуля звучит следующим образом.
[11:30.360 --> 11:36.360]  Если вам вдруг в классе нужно реализовать конструктор копирования, конструктор перемещения, перемещающий присваивание,
[11:36.360 --> 11:40.360]  деструктор или копирующий присваивание, то на самом деле вам это не нужно.
[11:40.360 --> 11:54.360]  Если ваш класс как-то нетривиально управляет ресурсами, то, наверное, стоит использовать обертки в виде std-vector, std-unique-ptr, std-shared-ptr и не управлять ресурсами вручную.
[11:54.360 --> 12:01.360]  А если вы вручную не управляете ресурсами, то, значит, вам и копирование перемещения и деструкторы реализовывать не нужно. Понятно?
[12:02.360 --> 12:10.360]  Короче, правило нуля говорит следующее, что ваш класс управлять ресурсами не должен. В общем, делегируете это все необходимым классом-оберткам.
[12:10.360 --> 12:18.360]  Единственное место, где вам возможно нужно реализовать конструктор копирования, перемещения или деструктор, это если вы пишете один из этих классов.
[12:18.360 --> 12:25.360]  Вот если вы пишете вектор, который вам нужно будет писать в третьем задании, вот там нужно писать свои перемещения и копирования.
[12:25.360 --> 12:32.360]  Если вы пишете не вектор и не умный указатель, грубо говоря, то никакие там конструкторы копирования и так далее вам не нужны.
[12:38.360 --> 12:46.360]  Ну теперь про совсем плохую ситуацию, про исключение в деструкторах.
[12:46.360 --> 12:51.360]  Ну хорошо, там разобрались исключения в конструкторах и так далее.
[12:51.360 --> 12:59.360]  Что если у меня бросающий деструктор? Ну, снова пример. У меня структура A нормально создалась, то есть у меня выделилась динамическая память,
[12:59.360 --> 13:04.360]  у меня создался вектор, и время жизни объекта A подошло к концу.
[13:04.360 --> 13:10.360]  Вот вызывается его деструктор, и снова он вызывает функцию F, которая потенциально бросает исключение.
[13:10.360 --> 13:15.360]  Ну понятно, что если мы это исключение не обработаем, то мы не дойдем до строки deletePtr, и у нас произойдет утечка памяти.
[13:15.360 --> 13:20.360]  То есть если у нас вылетит исключение из деструктора, то деструктор отработает не до конца, и соответственно delete вызов не будет.
[13:20.360 --> 13:23.360]  Это понятно. Ну и как проблему это решить? Ну достаточно просто.
[13:23.360 --> 13:28.360]  Снова мы оборачиваем функцию F в tri-catch-блок, то есть говорим, что вызов функции F потенциально опасен,
[13:28.360 --> 13:34.360]  мы это исключение ловим, удаляем указатель и пробрасываем исключение дальше.
[13:34.360 --> 13:39.360]  Видит ли кто-нибудь здесь потенциальную проблему?
[13:39.360 --> 13:45.360]  Снова давайте вернемся к коду. Ну проблему кроме, скажем, какого-то уродского кода, который дублирует код,
[13:45.360 --> 13:50.360]  что мы и в каче делаем delete, и потом вне кача делаем delete, это просто необходимость.
[13:50.360 --> 13:57.360]  Если абстрагироваться от чисто эстетических чувств, кто-нибудь понимает, в чем может возникнуть проблема.
[13:57.360 --> 14:04.360]  Например, вот в таком коде. У меня есть функция H, я создаю внутри функции H объект A.
[14:04.360 --> 14:09.360]  У объекта A известно, что его деструктор может бросить исключение.
[14:09.360 --> 14:14.360]  Я вызываю функцию H, которая тоже может бросить исключение.
[14:14.360 --> 14:21.360]  Что еще раз? Не, деструктор это будет вызван.
[14:21.360 --> 14:28.360]  Нет, подождите, а в какой момент вызывается деструктор?
[14:28.360 --> 14:33.360]  Деструктор вызывается, когда вы выходите из скопа, из области действия.
[14:33.360 --> 14:38.360]  В момент вызова функции G, A существует, для A деструктора не будет вызвано.
[14:38.360 --> 14:47.360]  Давайте по порядку.
[14:47.360 --> 14:54.360]  Сценарий такой. Как работает функция H?
[14:54.360 --> 14:59.360]  Функция H создает объект A.
[14:59.360 --> 15:04.360]  Дальше функция H вызывает функцию G, которая потенциально бросает исключение.
[15:04.360 --> 15:09.360]  Вот допустим, H бросает исключение. Что происходит при выбросе исключения?
[15:09.360 --> 15:16.360]  Понятное дело, там завершается G, так как мы здесь функции H не обрабатываем исключение, то есть завершается H.
[15:16.360 --> 15:21.360]  Что происходит перед завершением H?
[15:21.360 --> 15:26.360]  Это было бы печально при завершении функций.
[15:26.360 --> 15:31.360]  Короче, вызывается деструктор просто. Уничтожаются локальные объекты,
[15:31.360 --> 15:36.360]  ну и при уничтожении локальных объектов вызываются их деструкторы, если это классы.
[15:36.360 --> 15:41.360]  Ну и смотрите, у меня G бросила исключение, дальше началась размотка стека,
[15:41.360 --> 15:46.360]  и деструктор A тоже бросил исключение. И теперь у вас что?
[15:46.360 --> 15:51.360]  У H вылетело два исключения вместо одного.
[15:51.360 --> 15:54.360]  Все понятно?
[15:54.360 --> 16:01.360]  Ну а, собственно, если у вас из функции вылетает два исключения, то по стандарту это DefinedBehaviour.
[16:01.360 --> 16:06.360]  Ну то есть просто неопределенное поведение.
[16:06.360 --> 16:12.360]  Ну здесь, а что если вам на самом деле внутри функции G нужна A? То есть я вызываю G от A.
[16:12.360 --> 16:16.360]  То есть если вам нужно создать объект A, обязательно до G.
[16:16.360 --> 16:19.360]  Ну это будет печально.
[16:19.360 --> 16:22.360]  Поэтому история следующая.
[16:22.360 --> 16:27.360]  Если у вас из одной функции вылетает два исключения, то это DefinedBehaviour.
[16:27.360 --> 16:30.360]  К такому компилятор не готов.
[16:30.360 --> 16:35.360]  Соответственно, бросать исключение в деструкторах опасно.
[16:35.360 --> 16:39.360]  Но вообще говоря, здесь все понятно.
[16:39.360 --> 16:45.360]  Ну а не бросаем исключений из деструкторов, потому что если деструктор이다 бросит исключение
[16:45.360 --> 16:50.360]  то если у вас так случилось, что кто-то бросил исключение и у вас начинает разматываться стег
[16:50.360 --> 16:55.360]  и в этот момент из вашего деструктора вылетит исключение, то у вас из функции полетит два исключения.
[16:55.360 --> 16:58.360]  И короче говоря, никак бы не обработать. Все будет печально.
[16:58.360 --> 17:03.360]  Вот. Поэтому мы не бросаем исключения из деструкторов.
[17:03.360 --> 17:05.360]  Вот.
[17:05.360 --> 17:08.360]  Если коротко, то так.
[17:08.360 --> 17:13.360]  На самом деле вы не можете бросить исключения из деструкторов не потому, что
[17:13.360 --> 17:18.360]  запрещено бросать два исключения одновременно, а просто потому, что в современных плюсах
[17:18.360 --> 17:23.360]  все деструкторы автоматически помечаются как noexcept.
[17:23.360 --> 17:36.360]  Давайте просто проговорим, что начиная с C++11 все деструкторы автоматически помечаются как noexcept.
[17:36.360 --> 17:41.360]  Мы говорили про значение ключевого условия noexcept. Если вы какую-то функцию помечаете noexcept,
[17:41.360 --> 17:46.360]  то это означает, что вы гарантируете компилятору, что эта функция не бросает исключений.
[17:46.360 --> 17:50.360]  Если вы из этой функции бросаете исключения, то вызывается автоматическое завершение программы sd terminate,
[17:50.360 --> 17:55.360]  то есть без размотки стека и так далее. Соответственно, если вы бросаете исключения из деструкторов,
[17:55.360 --> 17:59.360]  то на самом деле до выброса двух исключений не доходит, то есть компилятор просто вас сразу убивает.
[17:59.360 --> 18:03.360]  То есть вы бросили исключения из деструктора, вы нарушили контракт.
[18:03.360 --> 18:09.360]  Условно компилятор за вас пообещал, что вы ничего не будете бросать, и вы бросили.
[18:09.360 --> 18:15.360]  Вопрос, а вот что если прям хочется бросить исключения из деструктора?
[18:15.360 --> 18:23.360]  Здесь написано noexcept false. Условно, если вы хотите бросить исключения из какого-то деструктора,
[18:23.360 --> 18:33.360]  то вы просто должны пометить, что ваш деструктор noexcept false.
[18:33.360 --> 18:39.360]  И тогда чисто теоретически вы можете бросить исключения из деструктора.
[18:39.360 --> 18:42.360]  Но опять же, повторюсь, так делать не стоит.
[18:42.360 --> 18:50.360]  Это тоже не совсем правда. Существуют кейсы, когда вам нужно бросить исключения из деструктора,
[18:50.360 --> 18:56.360]  причем это можно сделать, когда у вас уже летит какое-то исключение, но я сейчас не готов это обсуждать.
[18:56.360 --> 19:04.360]  Если интересно, то можете пройтись по ссылке и почитать, что для этого нужно и как это все работает.
[19:04.360 --> 19:09.360]  Да, сразу скажу, что, ну давайте, не знаю, сработает.
[19:09.360 --> 19:18.360]  Ладно, забьем. Там есть две функции. По этой ссылке есть две функции.
[19:18.360 --> 19:22.360]  Есть std-uncode-exception и есть функция std-uncode-exceptions.
[19:22.360 --> 19:26.360]  Так вот, вам нужна вторая версия, так как первая считается устаревшей.
[19:26.360 --> 19:35.360]  На всякий случай. Дальше? Хорошо.
[19:35.360 --> 19:42.360]  Ну и давайте поговорим про гарантии безопасности исключений.
[19:42.360 --> 19:48.360]  Попробуем формализовать, что такое безопасный код.
[19:48.360 --> 19:56.360]  Когда вы говорите, что ваш код безопасный, вы должны как бы на что-то сослаться.
[19:56.360 --> 20:01.360]  Вы должны в некотором смысле пояснить, в каком смысле ваш код безопасный.
[20:01.360 --> 20:06.360]  То есть код может быть безопасным с точки зрения, что он в принципе никогда не приводит к ничему плохому.
[20:06.360 --> 20:11.360]  То есть у вас код никогда не бросает исключения, никогда не приводит к undefined-behavior и так далее.
[20:11.360 --> 20:17.360]  Ваш код может быть безопасным в том смысле, что если пользователь, который пользуется вашей функцией или вашим классом,
[20:17.360 --> 20:20.360]  корректно обработает исключения, то все будет нормально.
[20:20.360 --> 20:24.360]  Ваш код может быть небезопасным в том смысле, что если у вас внутри что-то пошло не так,
[20:24.360 --> 20:28.360]  то это значит, что во всей программе все идет не так, и ее можно только перезапустить.
[20:28.360 --> 20:30.360]  Дальше ее никак не восстановить.
[20:30.360 --> 20:36.360]  Естественно последний случай отвратительный, поэтому давайте поговорим про то,
[20:36.360 --> 20:45.360]  какие гарантии должен давать ваш код и как их собственно обеспечить.
[20:45.360 --> 20:50.360]  Более-менее существует три гарантии безопасности.
[20:50.360 --> 20:53.360]  Первая гарантия безопасности – это гарантия отсутствия исключений.
[20:53.360 --> 20:55.360]  Она самая понятная.
[20:55.360 --> 21:01.360]  Если у вас есть гарантия отсутствия исключений, то ваша функция или ваш метод класса гарантирует,
[21:01.360 --> 21:06.360]  что у него отсутствует исключение, значит, что он в принципе никогда не бросает исключений.
[21:06.360 --> 21:10.360]  Вот и все. Все просто.
[21:10.360 --> 21:16.360]  Например, у стека есть метод size.
[21:16.360 --> 21:19.360]  Метод size никогда не бросает исключения.
[21:19.360 --> 21:24.360]  Поэтому его, во-первых, можно пометить noexcept, во-вторых, он удовлетворяет строгие гарантии безопасности.
[21:24.360 --> 21:31.360]  Если мы рассмотрим конструктор копирования стека, то конструктор копирования стека не удовлетворяет строгой гарантии безопасности.
[21:31.360 --> 21:33.360]  Понятно почему.
[21:33.360 --> 21:40.360]  Например, почему конструктор копирования у стека не может давать гарантию отсутствия исключений?
[21:40.360 --> 21:44.360]  Ну да, банально может опять же не хватить памяти.
[21:44.360 --> 21:50.360]  То есть при выделении памяти, понятно дело, что если вы попросили создать стек из миллиона объектов
[21:50.360 --> 21:57.360]  и ему не удалось выделить миллион объектов, то он сообщает пользователю с помощью исключения, что этого ничего не получилось.
[21:57.360 --> 22:03.360]  Так, у меня, кажется, были демки.
[22:03.360 --> 22:09.360]  Про остальные гарантии безопасности поговорим на примерах.
[22:09.360 --> 22:12.360]  Так нормально видно?
[22:12.360 --> 22:16.360]  Про гарантию отсутствия исключений поговорили.
[22:16.360 --> 22:18.360]  Давайте еще пару примеров.
[22:18.360 --> 22:20.360]  Например, метод swap.
[22:20.360 --> 22:26.360]  Вот метод swap в стеке может давать строгую гарантию отсутствия исключений.
[22:26.360 --> 22:30.360]  Почему? Потому что в чем заключается swap двух стеков?
[22:30.360 --> 22:33.360]  Сваб двух стеков заключается в том, что мы свапаем размеры стека,
[22:33.360 --> 22:39.360]  свапаем вместимости стеков и свапаем их указатели на массивы.
[22:39.360 --> 22:46.360]  То есть тут происходит просто свап примитивных типов, то есть int, int и указатель на int, например.
[22:46.360 --> 22:51.360]  Поэтому тут свап, короче говоря, в таких ситуациях никогда не генерирует исключения,
[22:51.360 --> 22:56.360]  поэтому мы можем пометить new except и гарантировать, что наш свап никогда не бросит исключения.
[22:56.360 --> 23:02.360]  Также операция перемещающего присваивания тоже может давать гарантию отсутствия исключений.
[23:02.360 --> 23:05.360]  Каким образом это, например, можно сделать?
[23:05.360 --> 23:09.360]  Например, можно вызвать конструктор перемещения от other
[23:09.360 --> 23:12.360]  и дальше тот временный объект, который мы создали,
[23:12.360 --> 23:15.360]  у него вызвать метод swap с нашим текущим объектом.
[23:15.360 --> 23:22.360]  Вот такая реализация операции перемещающего присваивания в одну строчку называется moving swap idiom.
[23:22.360 --> 23:26.360]  То есть перемести и swap-ни.
[23:26.360 --> 23:29.360]  Короче говоря, что тут происходит?
[23:29.360 --> 23:35.360]  Как правило, когда вы реализуете перемещающие присваивания или копирующие присваивания,
[23:35.360 --> 23:38.360]  у вас происходит дублирование кода. Все писали, да?
[23:38.360 --> 23:44.360]  У вас происходит дублирование кода в том смысле, что вам нужно создать новый объект и удалить старый объект.
[23:44.360 --> 23:49.360]  То есть по сути вы заново переписываете деструктор и заново переписываете конструктор.
[23:49.360 --> 23:53.360]  И все это делаете в операции перемещения.
[23:53.360 --> 23:58.360]  Вот тут это все можно сделать в одной строке с помощью следующего трюка.
[23:58.360 --> 24:03.360]  Вы вызываете конструктор, то есть создаете временный объект с помощью конструктора перемещения.
[24:03.360 --> 24:08.360]  То есть тут происходит создание нового стека, то есть того стека, который вам нужен.
[24:08.360 --> 24:12.360]  Ну и дальше вы просто swap-ите этот временный стек с текущим стеком.
[24:12.360 --> 24:18.360]  Что у вас происходит? Содержимое other оказывается в Visi, то есть в вашем стеке.
[24:18.360 --> 24:22.360]  А, ваше старое содержимое оказывается во временном стеке.
[24:22.360 --> 24:24.360]  И когда завершается этот строк, что происходит?
[24:24.360 --> 24:27.360]  Временный стек уничтожается и вот все ваши старые данные тоже уничтожаются.
[24:27.360 --> 24:32.360]  автоматически вызывается деструктор. Трюк понятен?
[24:32.360 --> 24:36.360]  Ну и соответственно, если у нас, скажем, конструктор перемещения не бросает исключения,
[24:36.360 --> 24:42.360]  и swap, как мы написали выше, не бросает исключения, то, понятное дело, что такое перемещающее
[24:42.360 --> 24:46.360]  присваивание тоже исключения бросать не может.
[24:46.360 --> 24:51.360]  Теперь давайте поговорим далее.
[24:51.360 --> 24:59.360]  Базовая гарантия безопасности говорит следующее.
[24:59.360 --> 25:02.360]  Она не обещает, что вы не будете бросать исключения.
[25:02.360 --> 25:07.360]  Может так случиться, что ваша функция в каких-то моментах может бросать исключения.
[25:07.360 --> 25:12.360]  Но при этом необходимо гарантировать хотя бы базовую гарантию безопасности.
[25:12.360 --> 25:17.360]  Что она означает? Она означает, что если у вас из функции или из класса в какой-то момент
[25:17.360 --> 25:23.360]  выбросилось исключение, то, первое, никаких утечек памяти, никаких утечек ресурса не произошло,
[25:23.360 --> 25:29.360]  и во-вторых, все ваши классы, все ваши объекты и так далее, в целом ваша программа
[25:29.360 --> 25:32.360]  находится в согласованном состоянии.
[25:32.360 --> 25:36.360]  То есть вы пользуетесь каким-то классом, вы у этого класса вызвали какой-то метод,
[25:36.360 --> 25:38.360]  и этот метод сказал, что что-то пошло не так.
[25:38.360 --> 25:44.360]  Если вы эту ошибку поймали, и после того, как вы эту ошибку поймали и обработали,
[25:44.360 --> 25:49.360]  вам этот класс гарантирует, что этим классом можно спокойно продолжать дальше пользоваться.
[25:49.360 --> 25:57.360]  То есть у него внутри ничего не испортилось, у него внутри ничего не испортилось.
[25:57.360 --> 26:02.360]  Вашу программу можно чисто теоретически как-то вылечить.
[26:02.360 --> 26:07.360]  Давайте пример приведем, тут может быть не совсем до конца понятно.
[26:07.360 --> 26:11.360]  Рассмотрим операцию копирующего присваивания.
[26:11.360 --> 26:15.360]  Понятно дело, что когда мы делаем копирующие присваивания, у нас может возникнуть исключение.
[26:15.360 --> 26:20.360]  Но опять же, почему? Потому что мы тут как минимум должны выделить новую память.
[26:20.360 --> 26:26.360]  Что мы тут делаем? Мы говорим, что наш размер теперь равен размеру другого стека,
[26:26.360 --> 26:29.360]  наш вместимость тоже равна размеру другого стека.
[26:29.360 --> 26:34.360]  И мы удаляем старый буфер, выделяем память для нового буфера,
[26:34.360 --> 26:42.360]  и дальше в цикле копируем содержимое другого стека в наш новый буфер.
[26:42.360 --> 26:52.360]  Понятно дело, что у этой операции присваивания нет гарантии отсутствия исключений.
[26:52.360 --> 26:56.360]  Я утверждаю, что у нее нет даже базовой гарантии безопасности.
[26:56.360 --> 27:03.360]  Я утверждаю, что если в какой-то момент что-то пойдет не так, то этим стекам в принципе нельзя будет пользоваться.
[27:03.360 --> 27:10.360]  Ваша программа полностью похеренная, с ней ничего нельзя будет сделать. Почему так?
[27:14.360 --> 27:19.360]  Давайте начнем с анализа того, какие строчки тут опасные.
[27:19.360 --> 27:24.360]  34, 35, 36 строки, они не опасные.
[27:24.360 --> 27:28.360]  37 я поняла, давайте проговорим здесь.
[27:28.360 --> 27:32.360]  Тут просто происходит присваивание одного примитивного типа в другой, это безопасно.
[27:32.360 --> 27:36.360]  Тут тоже присваивание примитивного типа в другой, это безопасно.
[27:36.360 --> 27:40.360]  Что происходит, когда я вызываю delete-буфер?
[27:43.360 --> 27:46.360]  Освобождение памяти, это не полный ответ.
[27:49.360 --> 27:53.360]  Даже это не полный ответ, не туда копаете.
[27:53.360 --> 27:56.360]  Когда я вызываю delete, что в первую очередь происходит?
[27:56.360 --> 27:58.360]  Вызвать деструктор, да.
[27:58.360 --> 28:03.360]  Опять же, стек теоретически может хранить себе строчки, другие вектора и так далее.
[28:03.360 --> 28:09.360]  Поэтому прежде чем освободить память, отдать ее обсерсионной системе, нужно для всех объектов вызвать деструктор.
[28:09.360 --> 28:12.360]  И delete здесь проходит по всем элементам и вызывает деструктор.
[28:12.360 --> 28:18.360]  Но мы говорили, что деструкторы не должны бросать исключений, поэтому мы тут верим, что деструктор ничего не бросит.
[28:18.360 --> 28:23.360]  Даже если деструктор что-то бросит, то нашу программу убьют и мы с этим ничего не можем сделать.
[28:24.360 --> 28:26.360]  А вот в третьей седьмой строке действительно опасно.
[28:26.360 --> 28:30.360]  В третьей седьмой строке снова мы выделяем память, тут может что-то пойти не так.
[28:33.360 --> 28:35.360]  Тут есть еще один момент, кто понимает.
[28:35.360 --> 28:38.360]  Допустим, у меня память просто море.
[28:38.360 --> 28:45.360]  Просто куча памяти, у меня чистая система, я запускаю программу и выделяю 5 интов.
[28:45.360 --> 28:49.360]  Не 5 интов, а просто 5 легких объектов.
[28:49.360 --> 28:54.360]  Вот я утверждаю, что эта строчка все равно будет опасной, даже если у меня памяти просто дофига.
[28:54.360 --> 28:56.360]  Что еще здесь может пойти не так?
[28:58.360 --> 29:00.360]  Из чего состоит new?
[29:03.360 --> 29:05.360]  Что происходит, когда я вызываю new?
[29:07.360 --> 29:12.360]  Во-первых, выделяется память, а во-вторых вызывают конструкторы для каждых ячеек.
[29:12.360 --> 29:16.360]  То есть когда я вызываю new, то у меня помимо того, что выделяется память,
[29:16.360 --> 29:18.360]  еще вызывают конструкторы.
[29:18.360 --> 29:20.360]  А вот конструкторы уже могут бросить исключения.
[29:20.360 --> 29:27.360]  Поэтому тут необходимо быть параноиком.
[29:27.360 --> 29:30.360]  Конструкторы тоже могут чисто теоретически бросить исключения.
[29:30.360 --> 29:34.360]  В третьей седьмой строке выбросилось исключение.
[29:34.360 --> 29:36.360]  Что не так? В чем проблема?
[29:36.360 --> 29:39.360]  Почему стеком в принципе нельзя будет пользоваться?
[29:43.360 --> 29:48.360]  Ну ладно, не выделилось, не выделалось, что бухтеть.
[29:48.360 --> 29:56.360]  Да, отлично. Этот стек врет о своем состоянии.
[29:56.360 --> 29:58.360]  Просто вот врет.
[29:58.360 --> 30:04.360]  Смотрите, если у вас в 37 строке вылетело исключение, то в каком состоянии у вас находится стек?
[30:04.360 --> 30:09.360]  У вас находится состояние, что он говорит, что у него other size равен 10.
[30:09.360 --> 30:11.360]  И здесь тоже равно 10.
[30:11.360 --> 30:14.360]  То есть ваш стек говорит, что у него 10 элементов,
[30:14.360 --> 30:17.360]  и что у него памяти выделено под 10 элементов.
[30:17.360 --> 30:19.360]  Но при этом реально у него какая память?
[30:19.360 --> 30:22.360]  Да никакой у него памяти нет, мы ее удалили.
[30:22.360 --> 30:25.360]  Все, и соответственно у вас нет возможности в принципе это восстановить.
[30:25.360 --> 30:27.360]  Вот вопрос.
[30:27.360 --> 30:31.360]  Допустим, у вас есть стек, который утверждает, что у него размер 10,
[30:31.360 --> 30:33.360]  что у него есть память под 10 элементов,
[30:33.360 --> 30:35.360]  на самом деле у него там в памяти лежит какой-то мусор.
[30:35.360 --> 30:37.360]  Как такой стек исправить снаружи?
[30:37.360 --> 30:39.360]  Никак не исправить.
[30:39.360 --> 30:42.360]  Чтобы вы не сделали, вы работаете с неволидной памятью.
[30:42.360 --> 30:44.360]  Это во-первых.
[30:44.360 --> 30:47.360]  А во-вторых, когда у вас будет вызываться деструктор этого стека, что произойдет?
[30:47.360 --> 30:49.360]  Двойное удаление.
[30:49.360 --> 30:51.360]  То есть у вас память была удалена здесь.
[30:51.360 --> 30:53.360]  Например, когда вы будете вызывать деструктор стека,
[30:53.360 --> 30:55.360]  у вас эта память снова попытается удалиться,
[30:55.360 --> 30:57.360]  а это как бы undefinedBehaviour снова.
[30:57.360 --> 30:59.360]  Все, то есть этим стеком в принципе нельзя пользоваться,
[30:59.360 --> 31:02.360]  и вы исправить это как пользователь не сможете.
[31:03.360 --> 31:08.360]  Поэтому этот метод не обладает даже базовой гарантией безопасности.
[31:08.360 --> 31:10.360]  Это понятно?
[31:10.360 --> 31:14.360]  Отличие базовой гарантии безопасности от отсутствия гарантии безопасности заключается в том,
[31:14.360 --> 31:17.360]  можно ли вашим объектом дальше пользоваться или нет.
[31:17.360 --> 31:20.360]  Ну и в 39-й строке то же самое.
[31:20.360 --> 31:22.360]  То есть чисто теоретически,
[31:22.360 --> 31:25.360]  операция присваивания может бросить исключение.
[31:25.360 --> 31:28.360]  Например, вы присваиваете один вектор к другому вектору вот здесь.
[31:28.360 --> 31:30.360]  Ну и снова при присваивании одного вектора к другому
[31:30.360 --> 31:32.360]  у вас может быть выброшено исключение.
[31:32.360 --> 31:34.360]  И тут то же самое по сути.
[31:34.360 --> 31:37.360]  На самом деле тут более легкая ситуация.
[31:37.360 --> 31:42.360]  Она заключается в том, что у вас стек просто-напросто врет о размере.
[31:42.360 --> 31:45.360]  То есть так-то у него и память нормальная и так далее.
[31:45.360 --> 31:49.360]  Но вообще говоря, тут тоже беда.
[31:51.360 --> 31:53.360]  Все понятно?
[31:53.360 --> 31:55.360]  Вопросы есть?
[31:56.360 --> 31:59.360]  Хорошо, этот код небезопасный.
[31:59.360 --> 32:04.360]  Значит, как переписать этот код так, чтобы он давал хотя бы базовую гарантию безопасности?
[32:04.360 --> 32:06.360]  Ну вот, например, вот так.
[32:06.360 --> 32:09.360]  Ну что можно сделать?
[32:09.360 --> 32:11.360]  Какая у нас тут проблема?
[32:11.360 --> 32:14.360]  Проблема у нас была в том, что к моменту 37-й строки,
[32:14.360 --> 32:17.360]  то есть тот момент, когда у нас потенциально может быть брошено исключение,
[32:17.360 --> 32:20.360]  у нас объект находится в несогласованном состоянии.
[32:20.360 --> 32:22.360]  В неправильном состоянии.
[32:22.360 --> 32:25.360]  Поэтому возможное решение заключается в следующем.
[32:25.360 --> 32:27.360]  Давайте просто-напросто следить за тем,
[32:27.360 --> 32:32.360]  чтобы в каждый момент времени у нас стек находился в нормальном состоянии.
[32:32.360 --> 32:34.360]  Ну вот как это можно сделать?
[32:34.360 --> 32:36.360]  Ну, например, так.
[32:36.360 --> 32:38.360]  Сначала мы удаляем старый буфер.
[32:38.360 --> 32:41.360]  Удаляем старый буфер и сразу говорим, что буфер равен 0PTR.
[32:41.360 --> 32:43.360]  Ну, точнее не так.
[32:43.360 --> 32:46.360]  Мы удаляем старый буфер и сразу приводим наш стек в нормальное состояние.
[32:46.360 --> 32:49.360]  То есть так мы удалили старую память, мы говорим, что теперь мы ни на что не указываем,
[32:49.360 --> 32:52.360]  размер у нас 0 и capacity равен 0, окей?
[32:52.360 --> 32:55.360]  Все, мы привели стек в согласованное состояние.
[32:55.360 --> 32:57.360]  Ну а дальше мы делаем все, что хотим.
[32:57.360 --> 33:00.360]  Ну вот, например, говорим, что буфер равно newT и так далее.
[33:00.360 --> 33:03.360]  И если тут выбросить исключение, то все нормально.
[33:03.360 --> 33:08.360]  Ну, выбросить исключение и просто мы его во внешнем коде обработаем
[33:08.360 --> 33:10.360]  и просто заметим, что наш стек стал пустой.
[33:10.360 --> 33:14.360]  Ну, как бы печально, но все равно этим стеком можно будет продолжить пользоваться.
[33:14.360 --> 33:16.360]  Понятно?
[33:16.360 --> 33:20.360]  Стек свое внутреннее состояние, свои внутренние инварианты никак не нарушает.
[33:20.360 --> 33:23.360]  Окей, допустим, нам удалось выделить нормальную память,
[33:23.360 --> 33:26.360]  и теперь мы вполне о себе можем установить новое capacity.
[33:26.360 --> 33:28.360]  Согласны?
[33:28.360 --> 33:30.360]  Все, выделение памяти прошло успешно.
[33:30.360 --> 33:32.360]  Мы теперь назначаем capacity.
[33:32.360 --> 33:34.360]  То есть у нас теперь capacity равен реально выделенному буферу,
[33:34.360 --> 33:36.360]  size по-прежнему равен 0,
[33:36.360 --> 33:39.360]  потому что мы реально его ничем другим не заполнили.
[33:39.360 --> 33:41.360]  Ага.
[33:41.360 --> 33:43.360]  Ну и дальше мы делаем следующий трюк.
[33:43.360 --> 33:45.360]  Мы в качестве счетчика,
[33:45.360 --> 33:47.360]  в качестве счетчика Cyclofor
[33:47.360 --> 33:50.360]  используем непосредственно сам size стека.
[33:50.360 --> 33:52.360]  То есть на каждой итерации,
[33:52.360 --> 33:54.360]  то есть в начале каждой итерации у нас size
[33:54.360 --> 33:56.360]  содержит реальное количество
[33:56.360 --> 33:58.360]  успешно скопированных элементов.
[33:58.360 --> 34:00.360]  Ага.
[34:00.360 --> 34:02.360]  Ну то есть если мы успешно скопировали элемент,
[34:02.360 --> 34:04.360]  то мы увеличиваем size.
[34:04.360 --> 34:06.360]  Снова успешно скопировали элемент, увеличили size.
[34:06.360 --> 34:08.360]  Если в какой-то момент у нас возникло тут исключение,
[34:08.360 --> 34:10.360]  то снова нас это не беспокоит.
[34:10.360 --> 34:12.360]  Почему?
[34:12.360 --> 34:14.360]  Потому что память выделена,
[34:14.360 --> 34:16.360]  capacity хранит реально
[34:16.360 --> 34:18.360]  сколько ячеек памяти у нас выделено,
[34:18.360 --> 34:20.360]  а size хранит реально сколько у нас элементов было скопировано.
[34:20.360 --> 34:22.360]  Понятно?
[34:22.360 --> 34:24.360]  То есть таким образом мы
[34:24.360 --> 34:26.360]  обеспечили базовую
[34:26.360 --> 34:30.360]  гарантию безопасности.
[34:30.360 --> 34:34.360]  Вопросы по коду этому есть?
[34:34.360 --> 34:38.360]  Окей.
[34:38.360 --> 34:40.360]  Ну и наконец,
[34:40.360 --> 34:42.360]  строгая гарантия безопасности
[34:42.360 --> 34:44.360]  это про следующее.
[34:44.360 --> 34:46.360]  Ну, снова,
[34:46.360 --> 34:48.360]  допустим, мы не можем гарантировать,
[34:48.360 --> 34:50.360]  что наш метод или функция не бросает исключений.
[34:50.360 --> 34:52.360]  Так вот,
[34:52.360 --> 34:54.360]  строгая гарантия безопасности говорит следующее,
[34:54.360 --> 34:56.360]  что мы гарантируем,
[34:56.360 --> 34:58.360]  во-первых, мы даем базовую гарантию безопасности,
[34:58.360 --> 35:00.360]  то есть нашим классам можно будет пользоваться.
[35:00.360 --> 35:02.360]  А во-вторых,
[35:02.360 --> 35:04.360]  что самое главное,
[35:04.360 --> 35:06.360]  это то, что если вдруг функция или метод
[35:06.360 --> 35:08.360]  завершилась неуспешно,
[35:08.360 --> 35:10.360]  то вся наша программа,
[35:10.360 --> 35:12.360]  ну или весь наш класс,
[35:12.360 --> 35:14.360]  находится ровно в том состоянии,
[35:14.360 --> 35:16.360]  в каком он был до вызова этого метода.
[35:16.360 --> 35:18.360]  Понятно?
[35:18.360 --> 35:20.360]  То есть если вызывать какой-то метод,
[35:20.360 --> 35:22.360]  если метод дает вам строгую гарантию безопасности,
[35:22.360 --> 35:24.360]  то этот метод говорит следующее,
[35:24.360 --> 35:26.360]  либо я завершаюсь успешно,
[35:26.360 --> 35:28.360]  либо я завершаюсь неуспешно,
[35:28.360 --> 35:30.360]  но при этом все остается как было.
[35:30.360 --> 35:32.360]  То есть как будто бы ничего не произошло.
[35:32.360 --> 35:34.360]  Понятна разница
[35:34.360 --> 35:36.360]  между базовой гарантией
[35:36.360 --> 35:38.360]  безопасности и гарантией
[35:38.360 --> 35:40.360]  безопасности. Базовая гарантия безопасности вам говорит следующее,
[35:40.360 --> 35:42.360]  что ваш стэк или ваш класс
[35:42.360 --> 35:44.360]  находится в нормальном состоянии,
[35:44.360 --> 35:46.360]  но в каком состоянии? Не понятно.
[35:46.360 --> 35:48.360]  То есть чисто теоретически ваш стэк может опустеть,
[35:48.360 --> 35:50.360]  как было в примере здесь.
[35:50.360 --> 35:52.360]  Если что-то пошло не так,
[35:52.360 --> 35:54.360]  то ваш стэк в нормальном состоянии,
[35:54.360 --> 35:56.360]  но он опустел по какой-то причине.
[35:56.360 --> 35:58.360]  Если бы стэк давал
[35:58.360 --> 36:00.360]  строгую гарантию безопасности,
[36:00.360 --> 36:02.360]  то он бы сказал, что хорошо.
[36:02.360 --> 36:04.360]  Если присваивание не получилось,
[36:04.360 --> 36:08.520]  что стэк содержит ровно те же элементы, что и до этого,
[36:08.520 --> 36:12.160]  ни больше ни меньше.
[36:12.160 --> 36:14.360]  Логически понятно разницу?
[36:14.360 --> 36:15.360]  Окей.
[36:15.360 --> 36:17.720]  Давайте попробуем, да, и соответственно понятно
[36:17.720 --> 36:21.320]  тоже, почему вот этот код не дает строгой гарантии
[36:21.320 --> 36:22.320]  безопасности.
[36:22.320 --> 36:26.120]  Опять же, мы очистили стэк, потом вызываем new.
[36:26.120 --> 36:28.680]  Если new выбросил исключение, то пользователь видит,
[36:28.680 --> 36:29.680]  что у него стэк опустел.
[36:29.680 --> 36:31.480]  Ну, естественно, это не то состояние, в котором
[36:31.480 --> 36:32.480]  он отдавал нам стэк.
[36:32.480 --> 36:37.920]  Как обеспечить строгую гарантию безопасности?
[36:37.920 --> 36:39.600]  Ну, например, вот так.
[36:39.600 --> 36:42.240]  Собственно, предложение заключается в следующем.
[36:42.240 --> 36:45.280]  Давайте просто-напросто возьмем и вот эти два блока,
[36:45.280 --> 36:47.840]  в котором мы что-то очищаем, то есть что-то назначаем
[36:47.840 --> 36:51.480]  в буфер size и capacity, и в то место, где мы реально
[36:51.480 --> 36:53.800]  выделяем память и производим копировки, просто поменяем
[36:53.800 --> 36:54.800]  их местами.
[36:54.800 --> 36:58.840]  Что у нас тогда получится?
[36:58.840 --> 37:01.440]  Мы выделяем новый буфер и сохраняем его в отдельную
[37:01.440 --> 37:02.440]  переменную.
[37:02.440 --> 37:07.120]  Если у нас тут что-то пошло не так, то ну и ладно.
[37:07.120 --> 37:11.200]  Но что пройдет, если у меня в 71-й строке выйдет исключение?
[37:11.200 --> 37:13.400]  У меня стэк останется в прежнем состоянии, потому
[37:13.400 --> 37:15.680]  что я состояние стэка не поменял, я еще со стэком
[37:15.680 --> 37:16.680]  ничего не успел сделать.
[37:16.680 --> 37:17.680]  Понятно?
[37:17.680 --> 37:18.680]  Окей.
[37:18.680 --> 37:19.680]  Идем дальше.
[37:19.680 --> 37:23.880]  Дальше я в этот новый буфер, который выделил отдельно,
[37:23.880 --> 37:28.960]  в этот новый буфер копирую содержимое вот этого other,
[37:28.960 --> 37:30.160]  которое мне передали в качестве параметра.
[37:30.160 --> 37:36.160]  Что пройдет, если тут вылетит исключение, я его не обработаю.
[37:36.160 --> 37:38.320]  Вот почему я тут написал эту обработку?
[37:38.320 --> 37:41.960]  Да, потому что если тут вылетит исключение, то мой
[37:41.960 --> 37:44.360]  стэк по-прежнему останется в правильном состоянии,
[37:44.360 --> 37:45.360]  то есть в нормальном состоянии.
[37:45.360 --> 37:48.240]  То есть я у стэка самого ничего не изменил, но при этом
[37:48.240 --> 37:49.240]  у меня произойдет утечка памяти.
[37:49.240 --> 37:51.000]  Вот чтобы не отпустить утечки памяти, я оборачиваю
[37:51.000 --> 37:54.040]  вот этот потенциально опасный участок кода в tri-cache-блок
[37:54.040 --> 37:58.240]  и в каче просто-напросто удаляю новый выделенный буфер
[37:58.240 --> 37:59.240]  и все.
[37:59.240 --> 38:00.840]  Ну и перебрасываю исключение дальше.
[38:00.840 --> 38:05.280]  И вот наконец мы доходим до 80-й строки.
[38:05.280 --> 38:07.400]  Что произошло к моменту 80-й строки?
[38:07.400 --> 38:11.080]  У меня выделился новый буфер, и я успешно все содержимое
[38:11.080 --> 38:12.320]  other скопировал новый буфер.
[38:12.320 --> 38:13.320]  Понятно?
[38:13.320 --> 38:16.320]  Ну и что теперь?
[38:16.320 --> 38:21.480]  Ну теперь я могу спокойно просто-напросто взять и
[38:21.480 --> 38:25.920]  обновить мой стэк, сказать, что я теперь удаляю старый
[38:25.920 --> 38:28.200]  буфер, говорю, что буфер равен новому буферу,
[38:28.200 --> 38:32.360]  сайс равен новому сайзу, capacity равен тоже новому сайзу
[38:32.360 --> 38:33.360]  и все.
[38:33.360 --> 38:37.840]  Кажется, что мы добились строгой гарантии безопасности.
[38:37.840 --> 38:40.760]  Потому что в какой бы момент, то есть тут потенциально
[38:40.760 --> 38:43.360]  опять же две строки, в которых может что-то пойти не так,
[38:43.360 --> 38:45.840]  и вот неважно, в 71-й строке что-то пошло не так, или
[38:45.840 --> 38:48.280]  в 74-й строке что-то пошло не так, у меня стэк от этого
[38:48.280 --> 38:49.280]  не изменится.
[38:49.280 --> 38:52.480]  Потому что я изменяю это все только после потенциально
[38:52.480 --> 38:53.480]  опасных операций.
[38:53.480 --> 39:03.160]  Вот это копирующее присваивание дает строгую гарантию безопасности.
[39:03.160 --> 39:05.280]  Ясно?
[39:05.280 --> 39:08.920]  Нет вопросов.
[39:08.920 --> 39:16.600]  Ну и примерно то же самое можно сделать проще, например,
[39:16.600 --> 39:18.920]  если воспользуемся копией ансвап идеомой.
[39:18.920 --> 39:21.720]  То есть когда мы писали перемещающее присваивание,
[39:22.400 --> 39:30.200]  то же самое можно переписать и для копирующего присваивания.
[39:30.200 --> 39:33.320]  То есть трюк абсолютно точно такой же, что мы делаем.
[39:33.320 --> 39:36.400]  Мы вызываем конструктор копирования, дальше вот
[39:36.400 --> 39:40.920]  то, что у нас получилось, свапим с this.
[39:40.920 --> 39:43.640]  Содержимое this у нас удалится, так как оно окажется во
[39:43.640 --> 39:48.000]  временном объекте, а все, что мы скопировали, окажется
[39:48.000 --> 39:50.000]  в нашем стэке.
[39:50.000 --> 39:52.900]  При этом, если у вас конструктор копирования обладает строгой
[39:52.900 --> 39:55.400]  гарантией безопасности, то ваша операция присваивания
[39:55.400 --> 39:56.760]  тоже обладает строгой гарантией безопасности.
[39:56.760 --> 39:58.320]  Понятно?
[39:58.320 --> 40:02.580]  Ну потому что мы не выполняем свап, мы не выполняем свап
[40:02.580 --> 40:04.920]  до тех пор, пока у нас вот эта штука успешней отработает.
[40:04.920 --> 40:08.320]  То есть у нас свап выполняет только в случае, если конструктор
[40:08.320 --> 40:09.500]  копирования успешно отработал.
[40:09.500 --> 40:13.140]  Вот как можно обеспечить строгую гарантию безопасности
[40:13.140 --> 40:15.460]  буквально в одну строчку.
[40:15.460 --> 40:16.980]  Продолжаем разговор про безопасность.
[40:16.980 --> 40:25.980]  И мы наконец дошли до момента, чтобы понять, для чего на самом деле нужен noexcept.
[40:25.980 --> 40:30.980]  Начнем с того, что я пытался рассказать в прошлый раз.
[40:30.980 --> 40:41.980]  Повторюсь, что эффективный код и безопасный код, вообще говоря, не всегда, а если быть точным, то редко когда совместимы.
[40:41.980 --> 40:47.980]  У вас есть такая вилка всегда, либо вы пишете безопасный код, либо эффективный код.
[40:47.980 --> 40:51.980]  Тут далеко за примером ходить не надо, например, вот здесь.
[40:51.980 --> 41:02.980]  Вот здесь мы обеспечили строгую гарантию безопасности относительно исключений, но при этом утверждается, что этот метод не самый эффективный.
[41:02.980 --> 41:11.980]  Не самый эффективный в том смысле, что здесь в один момент времени у нас одновременно хранится и новый буфер, и старый буфер.
[41:11.980 --> 41:21.980]  Мы, по сути, требуем в два раза больше памяти, чем, например, вот такой подход, где мы сначала удаляем буфер, а только потом вызываем новый.
[41:21.980 --> 41:24.980]  Беда.
[41:24.980 --> 41:34.980]  Здесь еще раз повторюсь, что у нас в каждом моменте времени, например, в 80-й строке у нас есть как новый буфер, так и старый буфер.
[41:34.980 --> 41:39.980]  В общем, затрат памяти больше. Это вот такой небольшой пример.
[41:39.980 --> 41:47.980]  Ну и, соответственно, если вы хотите добиться код какой-то безопасности, то вы используете менее эффективные функции.
[41:47.980 --> 41:59.980]  Например, если вы хотите, чтобы вектор никогда не выходил за границу массива, и при этом вы хотите, чтобы программа сообщила о том, что вы вышли за границу массива, то вы используете метод add.
[41:59.980 --> 42:08.980]  То есть у вектора есть метод v.add, который проверяет, вышли вы за границу массива или нет. Если вышли, то бросает исключение.
[42:08.980 --> 42:11.980]  Но при этом на эту проверку коет лишнее время.
[42:11.980 --> 42:23.980]  Если вы не хотите, чтобы компилятор за вами следил, то вы используете просто квадратные скобки. Квадратные скобки просто ничего не проверяют, а просто обращаются по элементу, берут указатель на начало массива и обращаются за скрытые ячейки.
[42:23.980 --> 42:30.980]  Быстро, быстро, безопасно? Ну нет, тут вы уже обязаны сами следить за тем, чтобы там все было безопасно и корректно.
[42:30.980 --> 42:37.980]  Вот такие вот небольшие примеры, что на самом деле сложно добиться одновременной безопасности и эффективности.
[42:37.980 --> 42:47.980]  Но при этом noexcept, оказывается, если вы используете noexcept, то в некоторых ситуациях получается одновременно добиться и безопасности, и эффективности.
[42:47.980 --> 42:56.980]  Пример. Пример следующий. Смотрите. Снова вернемся к стеку.
[42:56.980 --> 43:05.980]  Допустим, в стеке я хочу написать функцию reallocate, которая просто принимает новые capacity, то есть у стека есть какой-то буфер, есть какая-то выделенная память,
[43:05.980 --> 43:11.980]  и я вызываю у него reallocate, ну в смысле просто выделяю память другого размера, ну либо большего размера, либо меньшего размера.
[43:11.980 --> 43:20.980]  Ну это часто приходится делать, когда вы работаете с памятью. Ну окей, как выглядит функция? Я создаю новый буфер.
[43:20.980 --> 43:28.980]  Если я попросил capacity больше нуля, то я выделяю память с помощью new. Если у меня capacity равен нулю, то я просто возвращаю nullptr.
[43:28.980 --> 43:36.980]  Дальше я говорю, что у меня есть новый размер, то есть если у меня capacity, новый capacity, он, короче говоря, меньше текущего размера,
[43:36.980 --> 43:42.980]  то я просто говорю, что у меня размер ограничен new capacity. Если нет, то просто берет старый size.
[43:42.980 --> 43:48.980]  Ну и дальше я просто-напросто беру и по элементу накопирую все содержимое из старого буфера в новый буфер.
[43:48.980 --> 43:56.980]  После того, как копирование завершено, я удаляю старый буфер, говорю, что буфер равен новому буферу, size равен новому size, capacity равен новому capacity.
[43:56.980 --> 44:04.980]  И тут сверху написано, что это очень плохая реализация. Она, во-первых, неэффективна, во-вторых, она небезопасна. Почему?
[44:04.980 --> 44:14.980]  Давайте начнем с того, почему эта реализация небезопасна. То есть она не обладает, чего она не обладает?
[44:14.980 --> 44:18.980]  Ну строк гарантии безопасности она точно не обладает.
[44:18.980 --> 44:34.980]  Так, ну хорошо, в четвертой строке может не хватить места, или конструктор UT может произвести исключение.
[44:34.980 --> 44:44.980]  Ну окей, ну если тут даже выбросить исключение, то, казалось бы, я мой стэк никак не изменил. Все продолжит работу.
[44:44.980 --> 44:52.980]  Давайте обратим внимание на седьмую строчку. Тут же теоретически тоже что-то может пойти не так, но в частности при присваивании у вас тоже может возникнуть исключение.
[44:52.980 --> 44:56.980]  Вот если тут возникает исключение, то что произойдет?
[44:56.980 --> 45:16.980]  Ну тогда тупо утечка будет. Ну то есть, да, если у вас тут вылетело исключение, то вот этот новый буфер вы никак не освободили.
[45:16.980 --> 45:24.980]  То есть вы тут чисто теоретически вызвали new, но при этом этот новый буфер не освободили. То есть эта локальная переменная просто уничтожится, ну все, банальная утечка памяти.
[45:24.980 --> 45:34.980]  Как мы ее поборем? Try-catch, да. Напишем вот такой код. То есть снова создаем новый буфер, говорим, какой у нас новый размер.
[45:34.980 --> 45:38.980]  Ну и дальше вот этот потенциально опасный цикл оборачиваем в try-catch-блок.
[45:38.980 --> 45:44.980]  Если у нас вылетело исключение, то в catch-блоке мы удаляем выделенный буфер и пробрасываем исключение дальше.
[45:44.980 --> 45:54.980]  Казалось бы, ну да, эта реализация обладает строгой гарантией безопасности, но утверждается, ну кто-то тут написал, что она неэффективна.
[45:54.980 --> 46:03.980]  Почему эта реализация неэффективна? И это уже принципиально новый вопрос.
[46:03.980 --> 46:19.980]  Как бы вы ускорили данную реализацию? Я понял.
[46:19.980 --> 46:38.980]  Смотрите, вот вы когда-то жили, ну год назад, жили дома. У вас был дом, и вот там находились какие-то вещи.
[46:38.980 --> 46:53.980]  Дальше вы переезжаете в общежитие. Ну нет. Вы переезжаете в общежитие и, соответственно, что вы делаете? Перевозите туда свои вещи.
[46:53.980 --> 46:59.980]  У вас был какой-то компьютер, у вас была какая-то одежда, у вас было что-то еще.
[46:59.980 --> 47:05.980]  И при переезде, что вы делали? Вы купили новый компьютер, вы купили новую одежду, вы купили новые книги.
[47:05.980 --> 47:10.980]  И вообще все, что у вас было дома, осталось дома, а все, что вам понадобилось в общежитии, вы купили заново.
[47:17.980 --> 47:21.980]  Ну вот у меня, собственно, вопрос. Какая у вас стипензия? То есть тут нет никаких криков, возмущений и так далее.
[47:21.980 --> 47:25.980]  Ну естественно, нет. Естественно, это не происходило. Что происходило при переезде?
[47:25.980 --> 47:31.980]  Вы переместили компьютер, переместили одежду, переместили и так далее.
[47:31.980 --> 47:38.980]  Намек понятен? То есть смотрите, у вас есть вот старый буфер, старое содержимое.
[47:38.980 --> 47:45.980]  Теперь оно вам понадобилось не здесь, а вот здесь. То есть теперь все содержимое вам нужно как бы убрать отсюда и перенести сюда.
[47:45.980 --> 47:51.980]  Ну естественно, зачем это все копировать, если здесь это уже не понадобится? Естественно, нужно это все переместить.
[47:51.980 --> 47:55.980]  Перемещение работает эффективнее копирования. Согласны?
[47:55.980 --> 48:01.980]  То есть в большинстве ситуаций у вас перемещение работает за единицу, копирование работает за линейное время, если у вас объект большой.
[48:01.980 --> 48:15.980]  Поэтому как сделать из этого кода эффективный код, который работает не за, ну не знаю там, если у вас размер объекта m, а размер массива вот этого m,
[48:15.980 --> 48:25.980]  то вот этот код работает теоретически за отm, а хотелось бы наверное за отm. То есть просто за единицу заполнить каждую ячейку.
[48:25.980 --> 48:36.980]  Как исправить? Да, просто взять и переместить. Это уже здесь сделано, вот.
[48:36.980 --> 48:49.980]  Просто содержимое старого буфера не копировать, а перемещать. Согласны? Тогда у вас в случае тяжелых объектов перемещение будет работать за единицу и при этом старые объекты копироваться не будут.
[48:49.980 --> 49:05.980]  Вот. Ну и теперь вопрос вам. Этот код обладает, ну то есть мы в прошлом, чуть выше мы поняли, что этот код, вот этот код, обладал строк гарантии безопасности, но при этом он не был эффективным.
[49:05.980 --> 49:14.980]  Теперь мы здесь заменили копирование на stmove, то есть на перемещение. Вопрос. Является ли этот код одновременно и безопасным, и эффективным?
[49:14.980 --> 49:27.980]  Что еще-то повторите?
[49:27.980 --> 49:53.980]  Вот именно это и будет, да. Смотрите в чем беда. Вот у вас был какой-то старый буфер, вы перемещаете его содержимое, ну не знаю, в какой-то новый.
[49:53.980 --> 50:14.980]  Что вы делаете? Вот у вас есть какой-то объект x, y, z, a, b. Что происходит при перемещении? Вы перемещаете x сюда, то есть здесь становится x, здесь объект каким-то образом удаляется, ну короче тут уже старого объекта нет. Согласны?
[50:14.980 --> 50:33.980]  Дальше мы перемещаем y сюда, старого объекта тут больше нет. Перемещаем z сюда, старого объекта нет. Перемещаем a и вот тут возникло исключение.
[50:33.980 --> 50:56.980]  Вот тут мы перемещаем a сюда, возникло исключение. Что делать? Вот этот код говорит следующее. Ну хорошо, если возникло исключение, то я это исключение ловлю и удаляю новый буфер. То есть вот то, что я новое выделал, я просто-напросто удаляю. Ну и продолжаю пользоваться этим. Что не так?
[50:56.980 --> 51:19.980]  Что не так? Ну они не удалились, они просто опустели. То есть тут исчезла строгая гарантия безопасности. Понятно? То есть у нас старый буфер, он изменился, а именно часть объектов просто-напросто опустела. То есть они оказались здесь, но мы их удалили вместе с новым буфером.
[51:19.980 --> 51:47.980]  А ячаи не понятны? Беда понятна? Ага. Предлагаю это все исправить вот таким образом. В кейчблоке дописать вот еще один цикл. Давайте я просто-напросто буду в отдельном счетчике запоминать, сколько объектов я переместил. В данном случае я переместил три объекта.
[51:49.980 --> 52:09.980]  И вот если на очередном объекте у меня произошла беда, то что я сделаю? Перед тем как я буду удалять этот массив, я перемещу все обратно. Я перемещу все обратно, и только после этого удаляю массив. Нормальный план.
[52:09.980 --> 52:37.980]  Что еще раз? Ну, по времени-то ладно. У нас симпатика все равно будет у отм, тут как бы... Во, да. Проблема второго уровня. Хорошо, вот тут мы перемещали, а возникло исключение.
[52:37.980 --> 52:55.980]  И решили все вернуть обратно. Ну хорошо, Z вернули обратно, Y вернули обратно, возвращаем X обратно. Упс, исключение. Что делаем? Снова пытаемся обратно все переместить. И так до бесконечности.
[52:55.980 --> 53:16.980]  Проблема ясна? Если при перемещении у вас может возникнуть исключение, то строго гарантии безопасности вы никак обеспечить не сможете. И вот тут как раз и содержится вот этот самый парадокс между эффективностью и безопасностью.
[53:16.980 --> 53:32.980]  Перемещение, оно эффективно. Оно для тяжелых классов, для тяжелых объектов работает за единицу. Но при этом, если у вас перемещение потенциально опасное, хоть и эффективное, то никакой строго гарантии вы уже говорить не можете.
[53:32.980 --> 53:40.980]  Ну вот пример. При перемещении старого буфера в новую у нас может возникнуть исключение, при перемещении обратно из нового буфера в старый тоже может возникнуть исключение.
[53:40.980 --> 53:53.980]  Поэтому гарантируя, что вы целиком переместите все отсюда-сюда или отсюда-сюда, никак не получается. Беда.
[53:53.980 --> 54:06.980]  И решение заключается в следующем. А давайте вспомним, что мы делали с конструкторами перемещения или перемещающим присваиванием. Пора.
[54:06.980 --> 54:18.980]  Помните, что когда мы писали конструктор перемещения и перемещающий присваивание, мы там писали noexcept. Я говорил, что важно для перемещения писать noexcept.
[54:18.980 --> 54:28.980]  И вот сейчас на самом деле становится понятно, почему. Дело в том, что в стандартной библиотеке, помимо функции std move,
[54:28.980 --> 54:38.980]  которая просто делает из объекта временный объект, то есть говорит, что объект должен предвариться временным, есть такая функция, которая называется std move if noexcept.
[54:38.980 --> 54:48.980]  Что она делает? Она смотрит, является ли конструктор перемещения или перемещающий присваивание, являются ли они noexcept.
[54:48.980 --> 54:58.980]  Вот если вы дали гарантию, что перемещения у вас никогда не бросают, то происходит move, то есть происходит преобразование к временному объекту.
[54:58.980 --> 55:06.980]  А если ваш конструктор перемещения или перемещающий присваивание не дает гарантию безопасности, то происходит обычное копирование.
[55:06.980 --> 55:21.980]  Понятно? Ещё раз повторить или всё. Короче, move if noexcept, он перемещает, если перемещение безопасно, и копирует, если перемещение небезопасно.
[55:21.980 --> 55:36.980]  То есть таким образом, что у вас получается? У вас получается следующая вещь, что если перемещение noexcept, то всё работает за o от m, и всё безопасно.
[55:36.980 --> 55:51.980]  Если у вас перемещение noexcept, то всё работает за o от n на n, где n это сложность копирования, и тоже безопасно.
[55:51.980 --> 56:10.980]  Ну вообще, в стандартной библиотеке C++ упор делается в основном на безопасность. Если есть возможность что-то гарантировать, что что-то работает безопасно, то это скорее будет работать безопасно, чем эффективно.
[56:10.980 --> 56:18.980]  И вот как раз использование noexcept, это как раз тот момент, когда вы можете действительно гарантировать одновременно и безопасность, и эффективность.
[56:18.980 --> 56:28.980]  И вот, собственно, пример это показывает. Понятно? Ну вот.
[56:31.980 --> 56:38.980]  Да, ну давайте ещё раз на всякий случай пройдёмся. Что здесь происходит, зачем нужна функция move if noexcept и так далее.
[56:38.980 --> 56:44.980]  Мы выделяем новый буфер. Если при выделении памяти у нас выбрасывается исключение, ничего страшного.
[56:44.980 --> 56:51.980]  Ну хорошо, вылетело исключение. Мы наш стэк никак не изменили. Если мы наш стэк никак не изменили, то мы обладаем строк гарантии безопасности.
[56:51.980 --> 57:05.980]  Дальше. Мы заходим в этот цикл. Если у нас перемещение noexcept, то есть мы пообещали, что наш класс, который мы сейчас копируем, не бросает исключений, то, во-первых, этот цикл не бросает исключений, и всё нормально.
[57:05.980 --> 57:12.980]  Во-вторых, это всё работает быстро и эффективно. Всё. То есть код целиком и эффективный, и быстрый. И эффективный, и безопасный.
[57:12.980 --> 57:19.980]  А если вы не обещали, то есть если вы не давали гарантию, что ваше перемещение безопасно, то тогда здесь происходит просто-напросто копирование.
[57:19.980 --> 57:27.980]  Ну всё, происходит копирование. Если копирование успешно, то мы идём дальше. Если копирование не успешно, то мы можем спокойно удалить новый буфер и бросить исключения.
[57:27.980 --> 57:32.980]  Если мы копировали элементы, то старый буфер у нас никак не изменился.
[57:32.980 --> 57:37.980]  Поэтому снова строк гарантии безопасности, она удовлетворена.
[57:37.980 --> 57:51.980]  Ага. Ну вот. Вопросы?
[57:51.980 --> 58:06.980]  Ну окей. На этом про, скажем, ядро C++ или ядро стандартной библиотеки всё. Давайте поговорим про иерархию исключений C++, какие вообще классы исключений C++ есть и зачем они нужны.
[58:06.980 --> 58:16.980]  Ну тут пара вопросов. В прошлый раз мы делали там штуки типа throw1, throw0, throw2 и так далее. То есть мы бросали объект типа int.
[58:16.980 --> 58:24.980]  Вот первый вопрос, как вы думаете, нормальный или бросать int? В чём проблема того, что мы бросаем int?
[58:24.980 --> 58:29.980]  Несодержательный. Да, несодержательный. Ну хорошо, мы бросили int, то есть бросили одно число.
[58:29.980 --> 58:33.980]  Понятное дело, что в int можно там что-то сохранить, то есть сохранить какую-нибудь информацию.
[58:33.980 --> 58:39.980]  Например, если бросили единицу, нам не хватило памяти. Если мы бросили двойку, то проблема в конструкторе. Если мы бросили тройку, то что-то ещё.
[58:39.980 --> 58:43.980]  Но никакой возможности сохранить дополнительную информацию в int у нас нет.
[58:43.980 --> 58:47.980]  Например, написать текстовое сообщение, что вот на самом деле пошло что-то ещё не так.
[58:47.980 --> 58:53.980]  Ошибка возникла в такой-то строке, в таком-то файле, в такой-то функции и так далее.
[58:53.980 --> 59:02.980]  Ну и второй вопрос, а хорошо ли вообще, говоря, ловить что угодно? То есть вот мы писали catch и три точки. В чём проблема?
[59:02.980 --> 59:16.980]  Ну вообще говоря, да. Ну а что если мы не знаем, что может произойти?
[59:16.980 --> 59:20.980]  То есть мы хотим обработать ошибку, но при этом мы не знаем, какая ошибка вылетает.
[59:20.980 --> 59:22.980]  Ну как вы её обгоняете?
[59:22.980 --> 59:24.980]  Catch многоточие.
[59:24.980 --> 59:30.980]  Нет, ну catch многоточие вы ловите.
[59:30.980 --> 59:39.980]  Вот, ну то есть мы не можем понять. Если мы поймали с помощью catch многоточия, мы ловим исключения, но мы не понимаем, что это за исключение.
[59:39.980 --> 59:45.980]  Вот такая проблема. То есть бросать int и ловить что угодно не совсем хорошо.
[59:46.980 --> 59:55.980]  Поэтому есть следующие принятые правила приличия.
[59:55.980 --> 01:00:03.980]  Мы бросаем не int, мы бросаем не doubly, мы бросаем не bool, даже не строки, а мы бросаем специальные классы исключения.
[01:00:03.980 --> 01:00:11.980]  То есть если вдруг вы пишете код, например, функцию divide, в которой чисто теоретически может возникнуть проблема с делением на ноль,
[01:00:11.980 --> 01:00:15.980]  то будьте добры для этого типа ошибки написать свой класс.
[01:00:15.980 --> 01:00:21.980]  Как он выглядит? Мы пишем класс divisionByZero, сохраняем в поле инфо, то есть некоторую информацию,
[01:00:21.980 --> 01:00:28.980]  что пользователь вызвал в такой-то строчке, в такой-то функции метод divide,
[01:00:28.980 --> 01:00:32.980]  передал такие-то аргументы и возникло деление на ноль.
[01:00:32.980 --> 01:00:35.980]  В конструкторе естественно мы сохраняем эту информацию,
[01:00:35.980 --> 01:00:40.980]  ну и дальше там заводим некоторый метод вот, который позволяет получить информацию о том, что произошло.
[01:00:40.980 --> 01:00:46.980]  Ну и теперь, когда мы вызываем divide, если у нас происходит деление на ноль, мы просто бросаем ошибку divisionByZero.
[01:00:46.980 --> 01:00:53.980]  И теперь пользователь может в кетче сказать, что я хочу поймать divisionByZero, то есть поймать исключение типа деления на ноль,
[01:00:53.980 --> 01:00:57.980]  и при необходимости понять некоторую дополнительную информацию с помощью метода вот.
[01:01:00.980 --> 01:01:04.980]  То есть мы теперь по типу ошибки понимаем, во-первых, что это за ошибка,
[01:01:04.980 --> 01:01:09.980]  а во-вторых, можем получить некоторую дополнительную информацию, которая содержится непосредственно внутри объекта этого класса.
[01:01:09.980 --> 01:01:13.980]  То есть при бросании int, естественно у нас такого добиться не получится.
[01:01:18.980 --> 01:01:25.980]  Ну и собственно проблема с кетч многоточия, как я уже сказал, заключается в следующем.
[01:01:25.980 --> 01:01:30.980]  Хорошо, у нас есть функция divide, которая чисто теоретически бросает исключение divisionByZero.
[01:01:30.980 --> 01:01:37.980]  И мы говорим, что если у нас есть деление на ноль, то мы в лог ошибок выводим это самое сообщение или там,
[01:01:37.980 --> 01:01:41.980]  некоторую дополнительную информацию. Ну хорошо, а что если мы хотим поймать вообще все остальные исключения?
[01:01:41.980 --> 01:01:45.980]  Мы пишем кетч многоточия, то есть мы ловим все остальные исключения, но при этом мы не понимаем,
[01:01:45.980 --> 01:01:52.980]  а что на самом деле произошло. То есть вот тут тоже, наверное, хотелось бы понять, что именно пошло не так,
[01:01:52.980 --> 01:01:57.980]  и возможно там вывести куда-то, не знаю, в консоль или в отдельный файл лог,
[01:01:57.980 --> 01:02:01.980]  или пользователю выйдет сообщение об ошибке, что у тебя вот это пошло не так.
[01:02:01.980 --> 01:02:04.980]  Кетч многоточия этого сделать не позволяет.
[01:02:04.980 --> 01:02:09.980]  Потому что когда вы ловите с помощью кетч многоточия, у вас объекта исключения на руках нет.
[01:02:09.980 --> 01:02:14.980]  Потому что вы не знаете его типа. Проблема ясна?
[01:02:14.980 --> 01:02:20.980]  И чтобы побороть эту проблему, предлагается делать следующую вещь.
[01:02:20.980 --> 01:02:26.980]  Давайте заведем некоторый класс exception, который будет обозначать вообще любую ошибку.
[01:02:26.980 --> 01:02:30.980]  Любая ошибка – это exception.
[01:02:30.980 --> 01:02:34.980]  Мы написали класс exception, задали, например, виртуальный метод what,
[01:02:34.980 --> 01:02:42.980]  мы говорим, что любой exception, любой класс ошибки должен уметь говорить, что произошло.
[01:02:42.980 --> 01:02:47.980]  Мы заводим метод what, делаем его виртуальным, чтобы потомки могли его переопределить.
[01:02:47.980 --> 01:02:52.980]  Дальше пишем наш класс ошибки, который наследуем от общего класса ошибки exception.
[01:02:52.980 --> 01:02:54.980]  И дальше внутри него переопределяем метод what.
[01:02:54.980 --> 01:02:59.980]  То есть exception просто говорит, что произошел exception, произошел что-то.
[01:02:59.980 --> 01:03:03.980]  A division by zero говорит, что конкретно произошло.
[01:03:03.980 --> 01:03:07.980]  Теперь вместо того, чтобы писать многоточие, мы можем делать следующее.
[01:03:07.980 --> 01:03:12.980]  Мы можем ловить exception по ссылке.
[01:03:12.980 --> 01:03:18.980]  Мы помним, что если у нас летит исключение, которое является наследником того, что мы ловим,
[01:03:18.980 --> 01:03:20.980]  то мы его тоже поймаем.
[01:03:20.980 --> 01:03:23.980]  Родитель может поймать наследника.
[01:03:23.980 --> 01:03:27.980]  В данном случае exception является родителем division by zero.
[01:03:27.980 --> 01:03:31.980]  Поэтому exception сможет поймать и это исключение, и это исключение.
[01:03:31.980 --> 01:03:38.980]  Теперь я вызываю у exception метод what, и мне на экран выводится division by zero.
[01:03:38.980 --> 01:03:42.980]  Почему выводится division by zero, а не exception?
[01:03:42.980 --> 01:03:46.980]  Потому что метод what виртуальный.
[01:03:46.980 --> 01:03:48.980]  Понятно?
[01:03:48.980 --> 01:03:50.980]  Виртуальность ровно так и работает.
[01:03:50.980 --> 01:03:54.980]  Если вы вызываете метод через указатель или ссылку на базовый класс,
[01:03:54.980 --> 01:04:00.980]  то у вас реально будет вызываться метод, который соответствует типу брошенного исключения
[01:04:00.980 --> 01:04:04.980]  или реальному типу объекта, а не типу ссылки.
[01:04:04.980 --> 01:04:06.980]  Окей?
[01:04:06.980 --> 01:04:09.980]  То есть если у вас тут реально в этом каче был пойман division by zero,
[01:04:09.980 --> 01:04:14.980]  то при вызове метода what будет вызван метод именно класса division by zero.
[01:04:14.980 --> 01:04:17.980]  Именно потому, что этот метод виртуальный.
[01:04:17.980 --> 01:04:21.980]  Вот именно здесь нам пригодилось это свойство с виртуальными функциями,
[01:04:21.980 --> 01:04:23.980]  с наследованием и так далее.
[01:04:23.980 --> 01:04:27.980]  То есть теперь мы можем ловить любое исключение с помощью класса exception
[01:04:27.980 --> 01:04:35.980]  и спрашивать what и этот what нам будет говорить, что на самом деле произошло.
[01:04:35.980 --> 01:04:39.980]  Идея понятна?
[01:04:39.980 --> 01:04:43.980]  Ну и естественно все, что было написано до этого, это все велосипеды.
[01:04:43.980 --> 01:04:47.980]  И естественно базовый класс exception и так далее, это все есть в стандартной библиотеке.
[01:04:47.980 --> 01:04:49.980]  Давайте в этом поговорим.
[01:04:49.980 --> 01:04:57.980]  В общем, C++ принято, что любая ошибка является наследником стандартного класса std exception.
[01:04:57.980 --> 01:05:06.980]  В стандартной библиотеке в заголовочном файле std accept или exception есть базовый класс std exception.
[01:05:06.980 --> 01:05:10.980]  Он как и в том классе, который был написан на предыдущем слайде,
[01:05:10.980 --> 01:05:17.980]  в нем есть просто виртуальный метод what, который говорит, что произошло.
[01:05:17.980 --> 01:05:22.980]  Дальше есть другие стандартные классы ошибок, которые от него уже у нас следованы.
[01:05:22.980 --> 01:05:28.980]  Например, logic error, то есть логический ошибка, runtime error, ошибка во время исполнения,
[01:05:28.980 --> 01:05:31.980]  badcast, badalloc, badwigptr.
[01:05:31.980 --> 01:05:36.980]  Badwigptr бросает charred pointer, когда вы создаете с помощью неправильного vigptr.
[01:05:36.980 --> 01:05:40.980]  Badalloc бросает new, если не удалось выделить память, и так далее.
[01:05:40.980 --> 01:05:44.980]  В общем, все эти классы ошибок у наследованы от std exception.
[01:05:44.980 --> 01:05:48.980]  То есть какая бы ошибка у вас не была выброшена, вы всегда ее сможете поймать
[01:05:48.980 --> 01:05:52.980]  с помощью ссылки на std exception. Понятно?
[01:05:52.980 --> 01:05:56.980]  Потому что они являются наследником одного общего базового класса exception.
[01:05:56.980 --> 01:05:59.980]  Ну и дальше существует целая иерархия вот этих самых исключений.
[01:05:59.980 --> 01:06:04.980]  То есть от всех этих классов у нас следованы какие-то другие ошибки.
[01:06:04.980 --> 01:06:06.980]  Ну вот в частности есть ошибка std outOfRange.
[01:06:06.980 --> 01:06:09.980]  Она вызывается, когда вы в векторе выходите за границу.
[01:06:09.980 --> 01:06:16.980]  То есть используйте метод add, когда вы в векторе вызываете v.add.
[01:06:16.980 --> 01:06:21.980]  И если вы там выходите за границу массива, то этот метод вам бросает исключение outOfRange.
[01:06:21.980 --> 01:06:27.980]  И вот этот outOfRange у наследован от класса logic error, а logic error в свою очередь у наследован от std exception.
[01:06:27.980 --> 01:06:33.980]  Дальше есть ошибка badanycast, которая на самом деле является наследником просто std badcast, ну и так далее.
[01:06:33.980 --> 01:06:35.980]  Существует целая иерархия ошибок.
[01:06:35.980 --> 01:06:37.980]  Для чего это нужно?
[01:06:37.980 --> 01:06:41.980]  Ну просто-напросто, чтобы вы могли группировать ошибки по смыслу.
[01:06:41.980 --> 01:06:47.980]  Ну например, если у вас функция бросает outOfRange, то вы ее обрабатываете здесь.
[01:06:47.980 --> 01:06:51.980]  Если вы хотите обработать все возможные логические ошибки, не только outOfRange,
[01:06:51.980 --> 01:06:53.980]  вы идете вот во второй блок catch.
[01:06:53.980 --> 01:06:57.980]  Если вам нужно обработать вообще все возможные ошибки во время выполнения программы,
[01:06:57.980 --> 01:06:59.980]  вы пишете std runtime error.
[01:07:00.980 --> 01:07:05.980]  И если у вас ошибка не подходит ни под outOfRange, ни под logic error, ни под runtime error,
[01:07:05.980 --> 01:07:08.980]  то вы уловите любую ошибку с помощью просто std exception.
[01:07:12.980 --> 01:07:14.980]  Ну и контрольный вопрос.
[01:07:14.980 --> 01:07:16.980]  Зачем тут везде написана ссылка?
[01:07:20.980 --> 01:07:23.980]  Чтобы не копировать, но это не самое главное.
[01:07:23.980 --> 01:07:29.980]  Нет, std exception можно создать, он не абстрактный.
[01:07:37.980 --> 01:07:42.980]  Даже если мы не напишем ссылку, то все равно можно будет ловить наследников.
[01:07:44.980 --> 01:07:46.980]  Тогда будет происходить срезка.
[01:07:46.980 --> 01:07:48.980]  Но самое главное, зачем мы ловим по ссылке?
[01:07:49.980 --> 01:07:52.980]  Потому что иначе у нас виртуальные функции не работают.
[01:07:54.980 --> 01:08:00.980]  Если вы тут поймаете просто по значению, то когда вы будете вызывать метод вот у logic error,
[01:08:00.980 --> 01:08:03.980]  у вас будет вызываться метод вот у logic error.
[01:08:04.980 --> 01:08:13.980]  Но если вы хотите, чтобы у вас метод вот возвращал именно то, что содержится в значаемом классе ошибки,
[01:08:13.980 --> 01:08:15.980]  то мы должны ловить его по ссылке.
[01:08:15.980 --> 01:08:19.980]  Потому что с помощью logic error мы можем поймать наследника logic error.
[01:08:19.980 --> 01:08:24.980]  То есть мы хотим узнать, что произошло именно в наследнике logic error, а не в самом классе logic error.
[01:08:24.980 --> 01:08:25.980]  Понятно?
[01:08:28.980 --> 01:08:34.980]  И виртуальность нам как раз позволяет достучаться до метода производного класса с помощью ссылки на базовый класс.
[01:08:37.980 --> 01:08:38.980]  Да?
[01:08:41.980 --> 01:08:42.980]  Ну допустим.
[01:08:42.980 --> 01:08:47.980]  Ну и соответственно, если вдруг вы захотели написать свой класс ошибки, то...
[01:08:48.980 --> 01:08:51.980]  Ну соответственно, естественно вы пишете свой класс ошибки,
[01:08:51.980 --> 01:08:53.980]  то есть для какой-то своей специфичной задачи, например,
[01:08:53.980 --> 01:08:57.980]  вы хотите сообщить всему миру, что у вас там функция бросает исключения,
[01:08:57.980 --> 01:09:00.980]  может теоретически что-то разделить на ноль.
[01:09:00.980 --> 01:09:03.980]  Ну тогда вы выводите свой класс division by 0
[01:09:03.980 --> 01:09:07.980]  и в обязательном порядке наследуете его от одного из стандартных классов ошибки.
[01:09:07.980 --> 01:09:09.980]  Ну например, говорите, что он наследник runtime error.
[01:09:09.980 --> 01:09:13.980]  То есть деление на ноль – это ошибка во время выполнения программы.
[01:09:13.980 --> 01:09:17.980]  Ну и дальше там в паблике вы можете либо переопределить метод вот,
[01:09:17.980 --> 01:09:20.980]  либо не переопределять, если вам это не нужно.
[01:09:20.980 --> 01:09:21.980]  Вот, ну здесь...
[01:09:21.980 --> 01:09:23.980]  Что здесь написано, кто помнит?
[01:09:23.980 --> 01:09:25.980]  Что это такое?
[01:09:29.980 --> 01:09:31.980]  Ну, не совсем.
[01:09:31.980 --> 01:09:33.980]  Кто помнит, что означает эта строчка?
[01:09:36.980 --> 01:09:39.980]  Она означает, мне лень писать конструкторы, используя конструктор runtime error.
[01:09:39.980 --> 01:09:41.980]  Вот и все.
[01:09:41.980 --> 01:09:45.980]  То есть чтобы заново не прописывать все конструкторы, которые там нужны division by 0,
[01:09:45.980 --> 01:09:49.980]  просто говорите, что создать division by 0 можно ровно так же,
[01:09:49.980 --> 01:09:51.980]  как мы создаем объект runtime error.
[01:09:51.980 --> 01:09:54.980]  То есть мы берем класс runtime error и у него берем конструктор.
[01:09:54.980 --> 01:09:56.980]  Вот, вот это все.
[01:09:56.980 --> 01:09:58.980]  А имя конструктора совпадает с именем класса.
[01:10:02.980 --> 01:10:06.980]  Ну и давайте пару таких необязательных моментов.
[01:10:08.980 --> 01:10:10.980]  Вот вопрос такой.
[01:10:12.980 --> 01:10:16.980]  Представьте себе, что у вас есть функция, которая вызывает...
[01:10:16.980 --> 01:10:18.980]  Ну, очень часто вызывает такой вопрос.
[01:10:18.980 --> 01:10:20.980]  Что это такое?
[01:10:20.980 --> 01:10:22.980]  Что это такое?
[01:10:22.980 --> 01:10:24.980]  Что это такое?
[01:10:24.980 --> 01:10:26.980]  Функция, которая вызывает...
[01:10:26.980 --> 01:10:30.980]  Ну, очень часто вызывает потенциально опасные методы или потенциально опасные функции.
[01:10:30.980 --> 01:10:34.980]  И вы хотите навесить try-catch-блок на всю функцию целиком.
[01:10:34.980 --> 01:10:38.980]  То есть вы хотите сказать, что если у вас хоть где-нибудь в функции пошло что-то не так,
[01:10:38.980 --> 01:10:42.980]  то это все нужно обработать в едином catch-блоке.
[01:10:42.980 --> 01:10:44.980]  Естественно, можно сделать следующим образом.
[01:10:44.980 --> 01:10:46.980]  Можно сказать try, открыть фигурные скобки,
[01:10:46.980 --> 01:10:48.980]  и весь код функции написать внутри блока try.
[01:10:48.980 --> 01:10:50.980]  Дальше написать catch и все написать там.
[01:10:50.980 --> 01:10:52.980]  И на этом закончить функцию.
[01:10:52.980 --> 01:10:54.980]  Но это не очень удобно, возникает такая лейсинга.
[01:10:54.980 --> 01:10:56.980]  То есть вы открываете фигурные скобки для функции,
[01:10:56.980 --> 01:10:58.980]  потом открываете фигурные скобки для try-блока.
[01:10:58.980 --> 01:11:01.980]  Соответственно, получается два уровня вложенности.
[01:11:01.980 --> 01:11:06.980]  Ну, чисто эстетически, может быть, не красиво.
[01:11:06.980 --> 01:11:08.980]  Вторая проблема.
[01:11:08.980 --> 01:11:10.980]  Ну, тоже из того же порядка.
[01:11:10.980 --> 01:11:12.980]  Ну, вот смотрите.
[01:11:12.980 --> 01:11:16.980]  Допустим, у меня есть класс B, у которого есть указатель,
[01:11:16.980 --> 01:11:20.980]  который мы предполагаем, который будет вести нас в динамическую область памяти.
[01:11:20.980 --> 01:11:22.980]  Что мы делаем?
[01:11:22.980 --> 01:11:28.980]  Мы вызываем тут newInt, сохраняем это все в указатель.
[01:11:28.980 --> 01:11:33.980]  И дальше создаем объект A, который тоже является полем.
[01:11:33.980 --> 01:11:35.980]  Ну, и тут возникает проблема.
[01:11:35.980 --> 01:11:38.980]  Что если при этом конструкторе, вот здесь, при вызове конструктора A,
[01:11:38.980 --> 01:11:40.980]  у вас вылетает исключение?
[01:11:40.980 --> 01:11:46.980]  Если у вас вылетает исключение, то у вас происходит утечка памяти.
[01:11:46.980 --> 01:11:51.980]  Вот эту память вы не освобождаете.
[01:11:51.980 --> 01:11:53.980]  И при этом возникает вопрос.
[01:11:53.980 --> 01:11:55.980]  Хорошо, а где обработать вот эту ошибку?
[01:11:55.980 --> 01:11:59.980]  Где нужно обработать ошибку, которая вылетает из A?
[01:11:59.980 --> 01:12:03.980]  Вы же try, вы по сути try можете писать только внутри функции.
[01:12:03.980 --> 01:12:05.980]  А здесь вы еще внутри функции не вошли.
[01:12:05.980 --> 01:12:07.980]  Что делать?
[01:12:07.980 --> 01:12:09.980]  Проблема понятна?
[01:12:09.980 --> 01:12:13.980]  Ну, и решение заключается в том, чтобы использовать так называемый function try-блок.
[01:12:13.980 --> 01:12:16.980]  Try-catch-блок можно навесить на всю функцию целиком.
[01:12:16.980 --> 01:12:18.980]  И делать это так.
[01:12:18.980 --> 01:12:22.980]  Вы пишете прототип функции, ну или тип функции.
[01:12:22.980 --> 01:12:26.980]  Дальше пишете try, и только после этого начинаете тело функции.
[01:12:26.980 --> 01:12:31.980]  И вот в такой синтаксе означает, что вы try-блок навесили на всю функцию целиком.
[01:12:31.980 --> 01:12:34.980]  То есть вы в try-блок навесили на всю функцию целиком,
[01:12:34.980 --> 01:12:37.980]  и после того, как функция завершилась, вы выполняете catch-блок,
[01:12:37.980 --> 01:12:40.980]  если реально там было выброшено исключение.
[01:12:40.980 --> 01:12:42.980]  Ну, это просто чисто такая косметическая...
[01:12:42.980 --> 01:12:44.980]  Ну, вот тут это косметическое изменение.
[01:12:44.980 --> 01:12:46.980]  То есть вместо того, чтобы писать try-блок целиком внутри,
[01:12:46.980 --> 01:12:49.980]  вы просто try-навешиваете на всю функцию сразу.
[01:12:49.980 --> 01:12:52.980]  А в случае конструкторов это просто необходимо. Почему?
[01:12:52.980 --> 01:12:58.980]  Потому что вы по-прежнему можете написать try на весь конструктор целиком.
[01:12:58.980 --> 01:13:00.980]  И делать это ровно таким же образом.
[01:13:00.980 --> 01:13:03.980]  Вы пишете прототип конструктора, дальше пишете try,
[01:13:03.980 --> 01:13:06.980]  ну а дальше, собственно, все, что нужно сделать в конструкторе.
[01:13:06.980 --> 01:13:10.980]  Ну, в частности, через двоеточие вы в списке инициализации
[01:13:10.980 --> 01:13:12.980]  инициализируете ptr, инициализируете a,
[01:13:12.980 --> 01:13:15.980]  дальше пишете тело конструктора и так далее.
[01:13:15.980 --> 01:13:17.980]  И теперь, где бы у вас ни возникло исключение,
[01:13:17.980 --> 01:13:21.980]  неважно, в списке инициализации или в теле конструктора,
[01:13:21.980 --> 01:13:24.980]  у вас все это будет поймано вот в этом try-блоке в общем,
[01:13:24.980 --> 01:13:27.980]  и, соответственно, оно окажется вот в этом catch-блоке.
[01:13:27.980 --> 01:13:29.980]  Соответственно, если у вас из a вылетает исключение,
[01:13:29.980 --> 01:13:32.980]  то вы это все ловите в catch-блоке здесь,
[01:13:32.980 --> 01:13:35.980]  удаляете ptr и пробрасываете исключение дальше.
[01:13:35.980 --> 01:13:38.980]  Вот. Все ясно?
[01:13:40.980 --> 01:13:43.980]  Да, ну и, собственно, вот здесь вот во втором примере есть
[01:13:43.980 --> 01:13:45.980]  небольшая проблема.
[01:13:45.980 --> 01:13:49.980]  В общем, это не всегда будет работать корректно.
[01:13:49.980 --> 01:13:52.980]  Короче, подумайте, что здесь не так.
[01:13:52.980 --> 01:13:55.980]  Просто упражнение. Что здесь не так.
[01:13:56.980 --> 01:13:59.980]  Ну и второй короткий бонус.
[01:13:59.980 --> 01:14:03.980]  В прошлом году меня после лекции спрашивали,
[01:14:03.980 --> 01:14:07.980]  я говорил, что когда вы бросаете исключение в метод вот,
[01:14:07.980 --> 01:14:10.980]  вы можете записать какую-то полезную информацию.
[01:14:10.980 --> 01:14:12.980]  Например, в какой строчке произошла ошибка,
[01:14:12.980 --> 01:14:14.980]  в каком месте, в какой функции, в каком файле,
[01:14:14.980 --> 01:14:18.980]  чтобы пользователь получил вполне себе нормальное сообщение об ошибке.
[01:14:18.980 --> 01:14:21.980]  Что в файле main.cpp в функции f,
[01:14:21.980 --> 01:14:24.980]  в строке номер 241 у вас произошла такая-то ошибка.
[01:14:24.980 --> 01:14:26.980]  Пожалуйста, исправьте.
[01:14:26.980 --> 01:14:29.980]  Ну и возник вопрос, а как это делать?
[01:14:29.980 --> 01:14:32.980]  Как составить корректное сообщение об ошибке,
[01:14:32.980 --> 01:14:34.980]  чтобы туда подставилось и имя файла,
[01:14:34.980 --> 01:14:37.980]  подставилось и имя функции, и номер строки?
[01:14:37.980 --> 01:14:40.980]  Естественно, первый вариант – это захардкодить все.
[01:14:40.980 --> 01:14:42.980]  То есть просто написать, что мы находимся в 241 строке,
[01:14:42.980 --> 01:14:45.980]  поэтому в 241 строке у вас возникла ошибка.
[01:14:45.980 --> 01:14:49.980]  Но это как бы использует очень шаткое предположение о том,
[01:14:49.980 --> 01:14:52.980]  что ваш код никогда не будет меняться.
[01:14:52.980 --> 01:14:54.980]  Представьте, что у вас есть тот же самый файл,
[01:14:54.980 --> 01:14:56.980]  и вы там дописали какой-то код.
[01:14:56.980 --> 01:14:58.980]  И теперь во всех местах, где вы это прописали,
[01:14:58.980 --> 01:15:00.980]  вам нужно номер строки изменить.
[01:15:00.980 --> 01:15:02.980]  Изменили название функции, изменили название файла.
[01:15:02.980 --> 01:15:04.980]  Вот вам везде это все нужно тоже изменять.
[01:15:04.980 --> 01:15:09.980]  Так вот в C++, в языке C есть специальные макросы,
[01:15:09.980 --> 01:15:12.980]  которые позволяют подставить это автоматически.
[01:15:12.980 --> 01:15:14.980]  Макросы называются func.
[01:15:14.980 --> 01:15:17.980]  Понятное дело, это имя функции, в которой вы сейчас находитесь.
[01:15:17.980 --> 01:15:20.980]  Line – это номер строки, в которой вы сейчас находитесь.
[01:15:20.980 --> 01:15:23.980]  Ну и файл говорит о том, в каком файле вы тоже сейчас находитесь.
[01:15:23.980 --> 01:15:27.980]  Используя эти макросы, вы можете оставить нужное сообщение об ошибке.
[01:15:27.980 --> 01:15:31.980]  Ну и, как бы это уже дело более современное,
[01:15:31.980 --> 01:15:34.980]  в C++ 20 завезли класс STD source location,
[01:15:34.980 --> 01:15:39.980]  который позволяет все эти штуки получить уже без использования макросов.
[01:15:39.980 --> 01:15:41.980]  Ну ссылка тут приведена.
[01:15:41.980 --> 01:15:44.980]  В общем, если вы хотите в сообщении об ошибке сохранить
[01:15:44.980 --> 01:15:48.980]  какую-то метаинформацию, где это произошло в кумфайле и так далее,
[01:15:48.980 --> 01:15:52.980]  то используйте класс source location или, соответственно,
[01:15:52.980 --> 01:15:54.980]  макросы func line или file.
[01:15:54.980 --> 01:16:00.980]  Продолжим говорить про хэштаблицы.
[01:16:00.980 --> 01:16:05.980]  Знаете, небольшое напоминание.
[01:16:05.980 --> 01:16:12.980]  У нас было простое равномерное хэширование.
[01:16:12.980 --> 01:16:16.980]  И в случае простого равномерного хэширования мы говорили,
[01:16:16.980 --> 01:16:32.980]  что среднее время работы find было у большого от единицы плюс,
[01:16:32.980 --> 01:16:35.980]  ну, напишем, n на m.
[01:16:35.980 --> 01:16:40.980]  Ну и небольшой кусок доказательства, который нам сейчас понадобится.
[01:16:40.980 --> 01:16:43.980]  У нас там что возникало?
[01:16:43.980 --> 01:16:50.980]  У нас там возникала такая сумма, сумма по i от единицы до n,
[01:16:50.980 --> 01:17:00.980]  вероятности того, что h от x, то есть вот тот самый x, который мы ищем,
[01:17:00.980 --> 01:17:06.980]  h от x совпадает с h от x и там, ну, где x это вот набор элементов,
[01:17:06.980 --> 01:17:09.980]  которые уже вставлены в мою хэштаблицу.
[01:17:09.980 --> 01:17:19.980]  Вот. И эта штука у нас была меньше либо равна, чем та же самая сумма,
[01:17:19.980 --> 01:17:27.980]  1 на m или единица, если x и равен x и, если наоборот не равен,
[01:17:27.980 --> 01:17:33.980]  x и равен x. Ну и так далее.
[01:17:33.980 --> 01:17:37.980]  Короче говоря, у нас в доказательстве возникала вот такая вот штука,
[01:17:37.980 --> 01:17:41.980]  и из этой цепочки равенств и неравенств, ну, здесь сам ли стоял равно,
[01:17:41.980 --> 01:17:47.980]  из этой цепочки равенств и неравенств мы пришли к тому,
[01:17:47.980 --> 01:17:51.980]  что у нас средняя длина цепочки, она не превосходит в такой величины,
[01:17:51.980 --> 01:17:57.980]  ну, а из этого следует, что и find тоже в среднем не превосходит в такой величины.
[01:17:57.980 --> 01:18:01.980]  Но затем мы поняли, что простого равномерного кшр не существует,
[01:18:01.980 --> 01:18:05.980]  и сейчас попытаемся мы побороть эту проблему.
[01:18:05.980 --> 01:18:11.980]  И поговорим мы про так называемое универсальное кширование.
[01:18:28.980 --> 01:18:32.980]  Значит, что мы вообще хотим? То есть мы поняли, что простого равномерного кширования не существует.
[01:18:32.980 --> 01:18:36.980]  Во-первых, даже если мы придумаем, как это все оформить,
[01:18:36.980 --> 01:18:42.980]  нам придется хранить очень много памяти для хранения всего лишь одной хэш-функции.
[01:18:42.980 --> 01:18:46.980]  Плюс, если мы будем генерировать нашу хэш-функцию как-то итеративно,
[01:18:46.980 --> 01:18:50.980]  то есть нам приходит один пример, мы запомнили, что мы сгенерировали и так далее,
[01:18:50.980 --> 01:18:54.980]  нам придется придумать хэш-таблицу, которая обходится без хэш-функций.
[01:18:54.980 --> 01:18:57.980]  Ну, такого, естественно, мы себе позволить не можем.
[01:18:57.980 --> 01:19:07.980]  Ну, что мы хотим? Мы хотим найти h, который появлялась под множеством множества всевозможных хэш-функций.
[01:19:07.980 --> 01:19:26.980]  Вот. Давайте я напишу небольшое семейство,
[01:19:26.980 --> 01:19:47.980]  которое обладало теми же свойствами, что и простого равномерного кширования.
[01:19:47.980 --> 01:19:51.980]  То есть, смотрите, чего мы хотели от простого равномерного кширования?
[01:19:51.980 --> 01:19:59.980]  От простого равномерного кширования мы добивались того, что все элементы у нас размазывались равновероятно по всем корзинам.
[01:19:59.980 --> 01:20:03.980]  И вот, собственно, вот этим фактом мы здесь и пользовались.
[01:20:03.980 --> 01:20:09.980]  И мы хотим найти какой-нибудь, уже искать функции не из всего множества всевозможных функций,
[01:20:09.980 --> 01:20:12.980]  а найти какое-нибудь небольшое под множество, которое обладало таким же свойством.
[01:20:12.980 --> 01:20:16.980]  То есть, мы берем из этого небольшого множества произвольную функцию,
[01:20:16.980 --> 01:20:20.980]  и она бы тоже нам как-то равномерно размазывала все элементы по корзинам.
[01:20:20.980 --> 01:20:29.980]  И вот такие под множества есть, они называются как раз-таки универсальными семействами.
[01:20:29.980 --> 01:20:39.980]  Значит, семейство H универсально,
[01:20:39.980 --> 01:21:02.980]  если при случайном равновероятном выборе H из H у нас бы соблюдалось следующее свойство.
[01:21:02.980 --> 01:21:12.980]  То есть, вероятность того, что H от X, ну да, для любого X, Y, принадлежащего к X неравным Y,
[01:21:12.980 --> 01:21:19.980]  то есть для любых двух неравных X, Y из множества ключей, у нас бы выполнялось следующее соотношение.
[01:21:19.980 --> 01:21:29.980]  Вероятность того, что их хэши совпадут, была бы меньше либо равна, чем 1 деленное на m.
[01:21:29.980 --> 01:21:36.980]  В чем смысл этого предъявления?
[01:21:36.980 --> 01:21:44.980]  Мы берем некоторое множество хэш-функций, и наугад берем одну хэш-функцию.
[01:21:44.980 --> 01:21:49.980]  Смотрим, совпали ли для х и у хэши или нет.
[01:21:49.980 --> 01:21:52.980]  Если совпали, то ставим плюсик, если нет, то минус.
[01:21:52.980 --> 01:21:55.980]  Ставим плюсики и минусики для всех функций.
[01:21:55.980 --> 01:21:59.980]  И считаем долю тех функций, для которых у меня H от X совпало с H от Y.
[01:21:59.980 --> 01:22:04.980]  И вот если доля таких функций, что у меня H от X совпадает с H от Y меньше либо равна, чем 1 на m,
[01:22:04.980 --> 01:22:09.980]  то это семейство у меня универсальное, естественно, если это выполнено для любой пары х и у.
[01:22:09.980 --> 01:22:12.980]  Понятно?
[01:22:12.980 --> 01:22:19.980]  Давайте поймем, почему такие универсальные семейства тоже хороши.
[01:22:19.980 --> 01:22:25.980]  Замечание.
[01:22:25.980 --> 01:22:31.980]  Так, эта теорема у нас как-то обозначала, давайте ее обозначим теорема 1, если мы не обозначали.
[01:22:31.980 --> 01:22:36.980]  Замечание.
[01:22:36.980 --> 01:22:54.980]  Теорема 1 верна при замене простого рано-ярного хэширования на универсальное хэширование.
[01:22:54.980 --> 01:22:57.980]  Ну, действительно, почему так?
[01:22:57.980 --> 01:23:01.980]  Смотрите, вся цепочка, которая нас приводила до вот этого момента,
[01:23:01.980 --> 01:23:05.980]  она на самом деле от свойств хэш-функции не зависит вообще никак.
[01:23:05.980 --> 01:23:09.980]  Единственное место, где мы как-то использовали свойства хэш-функции, это вот здесь.
[01:23:09.980 --> 01:23:13.980]  То есть что мы говорили, что вероятность совпадения H от X и H от X и,
[01:23:13.980 --> 01:23:16.980]  она у нас раньше была равна 1 на m.
[01:23:16.980 --> 01:23:20.980]  А теперь по определению вероятность такого совпадения у меня меньше либо равна, чем 1 на m.
[01:23:20.980 --> 01:23:21.980]  Согласны?
[01:23:21.980 --> 01:23:27.980]  То есть вот тут я просто меняю знак равенства на нестрогое неравенство.
[01:23:27.980 --> 01:23:28.980]  Ну и все.
[01:23:28.980 --> 01:23:31.980]  В остальном все то же самое.
[01:23:31.980 --> 01:23:33.980]  Понятно?
[01:23:33.980 --> 01:23:35.980]  Окей.
[01:23:35.980 --> 01:23:36.980]  Окей.
[01:23:36.980 --> 01:23:38.980]  Ну, в общем, рецепт такой.
[01:23:38.980 --> 01:23:43.980]  Мы вместо простого рано-ярного хэширования пользуемся универсальными семействами, и все работает.
[01:23:43.980 --> 01:23:47.980]  Ну, после прошлой лекции, я думаю, вы мне уже не поверите, что такое на самом деле существует.
[01:23:47.980 --> 01:23:49.980]  Поэтому надо как-то доказать.
[01:23:49.980 --> 01:23:52.980]  Ну, давайте приведем пример хотя бы какого-нибудь универсального семейства,
[01:23:52.980 --> 01:23:56.980]  что вот то, что мы определили, на самом деле в природе есть.
[01:23:56.980 --> 01:23:57.980]  Так.
[01:23:57.980 --> 01:23:59.980]  Здесь нормально, если буду писать?
[01:23:59.980 --> 01:24:02.980]  Ну, давайте.
[01:24:02.980 --> 01:24:05.980]  Пример.
[01:24:05.980 --> 01:24:10.980]  Рассмотрим пример для следующего кейса.
[01:24:10.980 --> 01:24:15.980]  Для следующего случая.
[01:24:15.980 --> 01:24:21.980]  В качестве множества всех ключей возьмем систему вычетов по модулю P,
[01:24:21.980 --> 01:24:28.980]  то есть все положительные остатки от деления на P.
[01:24:28.980 --> 01:24:30.980]  Знакомо такое?
[01:24:30.980 --> 01:24:31.980]  Да?
[01:24:31.980 --> 01:24:32.980]  Ну, то есть, если...
[01:24:32.980 --> 01:24:33.980]  Ну, понятно.
[01:24:33.980 --> 01:24:34.980]  В общем, где P – простое число, естественно.
[01:24:34.980 --> 01:24:41.980]  P – простое число.
[01:24:41.980 --> 01:24:43.980]  Так, так, так.
[01:24:43.980 --> 01:24:48.980]  Да, ну и в качестве h возьмем следующее множество.
[01:24:48.980 --> 01:25:03.980]  Ну, множество всех функций hA,B таких, что hA,B от X равно AX плюс B остаток от деления на P
[01:25:03.980 --> 01:25:07.980]  и остаток от деления на M.
[01:25:07.980 --> 01:25:14.980]  Причем A лежит в ZP без нуля.
[01:25:14.980 --> 01:25:17.980]  Тут без нуля.
[01:25:17.980 --> 01:25:22.980]  Вот.
[01:25:22.980 --> 01:25:29.980]  Ну, то есть, это просто множество всех линейных функций без учета нулевого коэффициента.
[01:25:29.980 --> 01:25:31.980]  И потом мы просто берем остаток от деления на P,
[01:25:31.980 --> 01:25:33.980]  и потом дополнительно берем остаток от деления на M.
[01:25:33.980 --> 01:25:35.980]  Ну, понятно, почему берем остаток от деления на M.
[01:25:35.980 --> 01:25:42.980]  Ну, чтобы у нас номер корзины лежал в пределах от нуля до M-1.
[01:25:42.980 --> 01:25:44.980]  Вот.
[01:25:44.980 --> 01:25:50.980]  Ну, тут утверждается, что такое семейство множества вот таких всех функций – оно универсально.
[01:25:50.980 --> 01:25:52.980]  Давайте поймем, почему.
[01:25:52.980 --> 01:25:55.980]  Значит, ну, начнем вот с чего.
[01:25:55.980 --> 01:25:57.980]  Ну, возьмем.
[01:25:57.980 --> 01:25:59.980]  Ну, во-первых, давайте поймем, что нам нужно доказать.
[01:25:59.980 --> 01:26:02.980]  Нам нужно доказать, что какие бы мы x и y не взяли, не равные друг другу,
[01:26:02.980 --> 01:26:07.980]  у нас вероятность h от x равно h от y будет меньше или равно, чем 1 на M.
[01:26:07.980 --> 01:26:09.980]  При условии, что мы h выбираем случайно.
[01:26:09.980 --> 01:26:10.980]  Окей?
[01:26:10.980 --> 01:26:13.980]  Вот если мы h выбираем случайно вот из этого множества,
[01:26:13.980 --> 01:26:16.980]  то нам нужно доказать, что вот это выполняется.
[01:26:18.980 --> 01:26:20.980]  Ну, возьмем.
[01:26:23.980 --> 01:26:27.980]  Возьмем произвольные x и y.
[01:26:27.980 --> 01:26:29.980]  x не равно y.
[01:26:29.980 --> 01:26:31.980]  Ну, наоборот.
[01:26:31.980 --> 01:26:36.980]  Значит, не принадлежат zp, и x не равно y.
[01:26:37.980 --> 01:26:39.980]  Вот. Возьмем произвольные x и y и зафиксируем их.
[01:26:39.980 --> 01:26:42.980]  Вот, давайте для них докажем, что вот это вот выполняется.
[01:26:42.980 --> 01:26:47.980]  Значит, ну, первое, что стоит сказать, наверное, это...
[01:26:50.980 --> 01:26:52.980]  Ну, обозначим...
[01:26:57.980 --> 01:26:59.980]  Вот так.
[01:27:00.980 --> 01:27:02.980]  Ну, возьмем h от x, обозначим за x штрих.
[01:27:02.980 --> 01:27:04.980]  Возьмем h от y, обозначим за y штрих.
[01:27:05.980 --> 01:27:10.980]  Вот. Я утверждаю, что x штрих никогда не равен y штрих...
[01:27:10.980 --> 01:27:12.980]  А, нет. Простите.
[01:27:12.980 --> 01:27:15.980]  Я возьму не такую штуку. Я возьму часть от этой штуки.
[01:27:18.980 --> 01:27:20.980]  Процент p.
[01:27:20.980 --> 01:27:24.980]  И ay плюс b, процент p.
[01:27:24.980 --> 01:27:28.980]  Вот. То есть возьму всю вот эту функцию, но без последнего деления на m.
[01:27:30.980 --> 01:27:33.980]  Я утверждаю, что x штрих и y штрих никогда не равны друг другу.
[01:27:34.980 --> 01:27:37.980]  Ну, кажется, это понятно, но давайте это окажем.
[01:27:37.980 --> 01:27:41.980]  То есть рассмотрим, например, x штрих минус y штрих, чему это будет равно.
[01:27:41.980 --> 01:27:43.980]  Ну, арифметику остатков все знают, да?
[01:27:43.980 --> 01:27:47.980]  То есть я могу остатки спокойно там вычитать друг из друга и так далее.
[01:27:47.980 --> 01:27:52.980]  Ну, в частности, я могу вычесть ay плюс b минус... вычесть ay плюс b и ay плюс b.
[01:27:52.980 --> 01:27:57.980]  Получится просто a на x минус y процент p.
[01:27:57.980 --> 01:27:59.980]  Вот.
[01:27:59.980 --> 01:28:02.980]  Ну, а эта штука уже гарантированно не равна нулю. Почему?
[01:28:03.980 --> 01:28:05.980]  Ну, потому что a не делится на p.
[01:28:05.980 --> 01:28:06.980]  Ну, помните, да?
[01:28:06.980 --> 01:28:09.980]  Я a выбрал специально так, что у меня a никогда не равно нулю.
[01:28:09.980 --> 01:28:12.980]  Если a не равно нулю, то, следовательно, a не может делиться на p.
[01:28:12.980 --> 01:28:16.980]  x минус y, x это остаток вот деления на p, и y это тоже остаток деления на p.
[01:28:16.980 --> 01:28:18.980]  И при этом они не равны.
[01:28:18.980 --> 01:28:21.980]  Поэтому разность x минус y тоже не делится на p.
[01:28:21.980 --> 01:28:26.980]  Ну, а произведение двух чисел, которые не делятся на p, не может делиться на простое число.
[01:28:26.980 --> 01:28:28.980]  Да?
[01:28:28.980 --> 01:28:29.980]  Ну, все.
[01:28:29.980 --> 01:28:31.980]  Ну, то есть они не нулевые, понятно.
[01:28:31.980 --> 01:28:33.980]  Окей.
[01:28:33.980 --> 01:28:35.980]  Второй пункт.
[01:28:39.980 --> 01:28:41.980]  Следующая.
[01:28:41.980 --> 01:28:46.980]  Существует биекция
[01:28:48.980 --> 01:28:50.980]  между
[01:28:50.980 --> 01:29:06.980]  всевозможными х-штрих не равный y-штрих и парами ab.
[01:29:09.980 --> 01:29:11.980]  Давайте сначала про смысл.
[01:29:11.980 --> 01:29:13.980]  Что я хочу во втором пункте?
[01:29:13.980 --> 01:29:18.980]  В втором пункте я хочу показать, что если я выбираю разные ab, разные пары ab,
[01:29:18.980 --> 01:29:22.980]  то я буду получать всевозможные пары x-штрих и y-штрих.
[01:29:22.980 --> 01:29:25.980]  То есть, грубо говоря, мне дали какие-то x и y,
[01:29:25.980 --> 01:29:28.980]  и я утверждаю, что я всегда смогу выбрать такое a и такое b,
[01:29:28.980 --> 01:29:32.980]  что я получу какие угодно, наперед, заданные x-штрих и y-штрих.
[01:29:32.980 --> 01:29:33.980]  Понятно?
[01:29:33.980 --> 01:29:37.980]  Ну, скажем, мне дают, скажем, x равны единице, y равны двойке.
[01:29:37.980 --> 01:29:42.980]  И я из этого хочу сделать x-штрих равны тройке и y равны нулю.
[01:29:42.980 --> 01:29:45.980]  Вот я утверждаю, что я всегда смогу найти такую пару ab.
[01:29:45.980 --> 01:29:48.980]  В общем, для любой такой пары уникальная.
[01:29:48.980 --> 01:29:49.980]  Окей?
[01:29:49.980 --> 01:29:50.980]  Ну, почему это так?
[01:29:50.980 --> 01:29:53.980]  Ну, просто, на самом деле, рассмотрим систему.
[01:29:53.980 --> 01:29:55.980]  Осмотрим систему уравнений.
[01:29:55.980 --> 01:30:00.980]  ax плюс b процент p равно x-штрих.
[01:30:00.980 --> 01:30:08.980]  И ay плюс b процент p равно y-штрих.
[01:30:11.980 --> 01:30:12.980]  Что здесь можно сказать?
[01:30:12.980 --> 01:30:16.980]  Здесь можно, не знаю, воспользоваться каким-то сакральным знанием,
[01:30:16.980 --> 01:30:19.980]  сказать, что вот тут у нас поле, вот, значит, тут линейное уравнение,
[01:30:19.980 --> 01:30:22.980]  матрица невырожденная, поэтому тут система линейных уравнений
[01:30:22.980 --> 01:30:24.980]  дает ровно единственное решение.
[01:30:24.980 --> 01:30:26.980]  Ну, вот тут какая матрица у нас?
[01:30:26.980 --> 01:30:28.980]  x единица, y единица.
[01:30:28.980 --> 01:30:30.980]  x и y не равны друг другу.
[01:30:30.980 --> 01:30:34.980]  И более того, x-штрих не равен y-штрих.
[01:30:34.980 --> 01:30:38.980]  Поэтому эта система невырожденная, она имеет единственное решение.
[01:30:38.980 --> 01:30:42.980]  Ну, если мы были в рамках линейной алгебры обычной.
[01:30:42.980 --> 01:30:43.980]  Согласны?
[01:30:43.980 --> 01:30:46.980]  Ну, на самом деле, в случае остатков тут все то же самое выполняется.
[01:30:46.980 --> 01:30:53.980]  Ну, опять же, в случае, если у меня простой, модуль простой,
[01:30:53.980 --> 01:30:56.980]  то есть все то же самое, но это можно показать в лоб,
[01:30:56.980 --> 01:31:04.980]  например, просто-напросто воспользоваться методом подстановки.
[01:31:08.980 --> 01:31:12.980]  Ну, например, мы можем вычесть одно уравнение из другого,
[01:31:12.980 --> 01:31:19.980]  получить, что a должно быть равно x-штрих-у-штрих,
[01:31:19.980 --> 01:31:26.980]  умноженное на x-у в минус 1.
[01:31:26.980 --> 01:31:32.980]  Ну, опять же, так как у меня, да, по модулю P, все.
[01:31:32.980 --> 01:31:35.980]  Ну, естественно, так как у меня модуль P простой,
[01:31:35.980 --> 01:31:37.980]  то обратное число тоже существует, x-у не нулевое.
[01:31:37.980 --> 01:31:41.980]  Ну, и отсюда, собственно, b, например, равно,
[01:31:41.980 --> 01:31:47.980]  ну, вот, из первого уравнения можно вытащить, можно вытащить b.
[01:31:47.980 --> 01:31:56.980]  Ну, ax-x-штрих, ax-x-штрих, процент b.
[01:31:56.980 --> 01:31:59.980]  Ну, короче, так или иначе, вы пользуетесь либо этим способом, либо этим способом,
[01:31:59.980 --> 01:32:08.980]  то есть мы получаем, что у этого уравнения существует единственное решение.
[01:32:08.980 --> 01:32:26.980]  Окей? Хорошо.
[01:32:26.980 --> 01:32:30.980]  И смотрите, что мы к текущему моменту имеем.
[01:32:30.980 --> 01:32:33.980]  Вот мне приходят какие-то x, y.
[01:32:33.980 --> 01:32:36.980]  А, нет, это еще не заканчивает вот это утверждение.
[01:32:36.980 --> 01:32:42.980]  Тут еще можно, тут еще нужно заметить.
[01:32:42.980 --> 01:32:52.980]  Ну, и заметим, что мощность множества всевозможных пар a, b равно чему?
[01:32:53.980 --> 01:32:58.980]  Ну, наоборот, p-1 на p. Согласны?
[01:32:58.980 --> 01:33:03.980]  Ну, h я могу выбрать p-1 способом, b я могу выбрать p способом.
[01:33:03.980 --> 01:33:08.980]  Поэтому мощность множества всевозможных пар a, b равна вот такой штуке.
[01:33:08.980 --> 01:33:13.980]  Ну, и по удивительному стеянию обстоятельств,
[01:33:13.980 --> 01:33:17.980]  эта штука равна количеству всевозможных пар x-штрих и y-штрих,
[01:33:17.980 --> 01:33:20.980]  таких, что x-штрих не равен y-штрих.
[01:33:20.980 --> 01:33:24.980]  Ну, потому что мы в первом пункте сказали, что x-штрих не может быть равен y-штрих.
[01:33:24.980 --> 01:33:25.980]  То есть все.
[01:33:25.980 --> 01:33:29.980]  Теперь у меня есть два одинаковых по мощности множества.
[01:33:29.980 --> 01:33:32.980]  И для любого x-штрих и y-штрих у меня существует ровно один ab,
[01:33:32.980 --> 01:33:35.980]  который меня переводит ab в x-штрих и y-штрих.
[01:33:35.980 --> 01:33:38.980]  Ну все, биекция.
[01:33:41.980 --> 01:33:44.980]  Теперь смысл того, что мы доказали.
[01:33:44.980 --> 01:33:46.980]  Смотрите, что мы сделали.
[01:33:46.980 --> 01:33:48.980]  Мы сказали следующую вещь.
[01:33:48.980 --> 01:33:51.980]  Мне дали произвольные x и y. Я не знаю, какие.
[01:33:51.980 --> 01:33:52.980]  И мне на самом деле плевать.
[01:33:52.980 --> 01:33:55.980]  Мне дали просто x и y и сказали, что они разные.
[01:33:55.980 --> 01:33:56.980]  Дальше что происходит?
[01:33:56.980 --> 01:33:59.980]  Дальше я выбираю случайную функцию h.
[01:33:59.980 --> 01:34:01.980]  Ну, как происходит генерация случайной функции h?
[01:34:01.980 --> 01:34:05.980]  Ну, я просто выбираю случайное число a и случайное число b.
[01:34:05.980 --> 01:34:08.980]  А так как я выбрал a и b случайно,
[01:34:08.980 --> 01:34:11.980]  то я получил случайную пару x-штрих и y-штрих.
[01:34:11.980 --> 01:34:12.980]  Согласны?
[01:34:12.980 --> 01:34:17.980]  Ну, так как каждая конкретная пара ab дает мне какую-то конкретную пару x-штрих и y-штрих.
[01:34:17.980 --> 01:34:20.980]  Соответственно, если я случайно генеруру ab,
[01:34:20.980 --> 01:34:22.980]  то я получаю случайную пару x-штрих и y-штрих.
[01:34:22.980 --> 01:34:26.980]  То есть по сути получается, что мне дали какие-то числа x и y,
[01:34:26.980 --> 01:34:28.980]  а я из них сделал вообще случайную пару x-штрих и y-штрих,
[01:34:28.980 --> 01:34:32.980]  которая вообще почти никак не связана с исходными x и y.
[01:34:32.980 --> 01:34:33.980]  Понятно?
[01:34:33.980 --> 01:34:36.980]  То есть скажем, вы мне даете два числа какие-то,
[01:34:36.980 --> 01:34:38.980]  а я у себя в голове придумал ab.
[01:34:38.980 --> 01:34:41.980]  И вот вы ни за что не догадаетесь, в какую пару у меня все перешло.
[01:34:41.980 --> 01:34:43.980]  А там?
[01:34:43.980 --> 01:34:46.980]  То есть в этом и заключается свойство этого семейства,
[01:34:46.980 --> 01:34:52.980]  что оно как-то равномерно размазывает все возможные числа по корзинам.
[01:34:52.980 --> 01:34:55.980]  И вот на этом на самом деле можно было остановиться,
[01:34:55.980 --> 01:34:57.980]  но давайте доведем до конца.
[01:34:57.980 --> 01:35:00.980]  В общем, то есть третий пункт.
[01:35:00.980 --> 01:35:15.980]  То есть теперь можем перейти от анализа h и x, y.
[01:35:15.980 --> 01:35:24.980]  И x, y к анализу x-штрих, y-штрих.
[01:35:24.980 --> 01:35:27.980]  То есть у меня теперь уже не интересует x и y,
[01:35:27.980 --> 01:35:29.980]  я теперь могу анализировать тот факт,
[01:35:29.980 --> 01:35:31.980]  что у меня x-штрих, y-штрих выбраются случайно.
[01:35:31.980 --> 01:35:33.980]  Окей?
[01:35:33.980 --> 01:35:38.980]  А x-штрих, y-штрих у меня вот такие.
[01:35:38.980 --> 01:35:40.980]  То есть осталось показать,
[01:35:40.980 --> 01:35:48.980]  что вероятность того, что x-штрих процент m равно y-штрих процент m,
[01:35:48.980 --> 01:35:51.980]  меньше либо равно, чем m.
[01:35:51.980 --> 01:35:54.980]  Вот это мне осталось доказать.
[01:35:54.980 --> 01:35:56.980]  Согласны?
[01:35:56.980 --> 01:35:57.980]  Все.
[01:35:57.980 --> 01:36:01.980]  Ну при условии того, что x-штрих, y-штрих я выбираю как-то случайно и рандомно.
[01:36:01.980 --> 01:36:04.980]  Ну вот.
[01:36:04.980 --> 01:36:07.980]  Ну давайте оценим, чему равна эта вероятность.
[01:36:07.980 --> 01:36:12.980]  Ну снова классическое определение вероятности.
[01:36:12.980 --> 01:36:14.980]  Чему равно всевозможное количество исходов?
[01:36:14.980 --> 01:36:16.980]  То есть чему равно потенциально количество пар x-штрих, y-штрих,
[01:36:16.980 --> 01:36:21.980]  которые я могу получить?
[01:36:21.980 --> 01:36:24.980]  Да, вот p-1 на p, ну все.
[01:36:24.980 --> 01:36:27.980]  То есть количество всевозможных исходов у меня такое.
[01:36:27.980 --> 01:36:32.980]  А сколько из вот таких исходов удовлетворяют вот такому свойству?
[01:36:32.980 --> 01:36:34.980]  Ну это не так просто.
[01:36:34.980 --> 01:36:47.980]  Давайте порисуем.
[01:36:47.980 --> 01:36:52.980]  Ну вот они выглядят так.
[01:36:52.980 --> 01:36:57.980]  Ну тут у меня m, тут 2m, тут 3m, тут 4m, ну и так далее.
[01:36:57.980 --> 01:37:00.980]  Ну и тут где-то p.
[01:37:00.980 --> 01:37:01.980]  Давайте по порядку.
[01:37:01.980 --> 01:37:06.980]  Сколькими способами я могу выбрать x-штрих?
[01:37:06.980 --> 01:37:07.980]  Ну просто x-штрих.
[01:37:07.980 --> 01:37:13.980]  Сколькими способами я могу выбрать?
[01:37:13.980 --> 01:37:16.980]  Ну p, естественно, да.
[01:37:16.980 --> 01:37:24.980]  То есть у меня x-штрих лежит во множестве этих остатков от деления на p.
[01:37:24.980 --> 01:37:28.980]  Ну хорошо, то есть я где-то выбираю x случайно, например вот здесь.
[01:37:28.980 --> 01:37:30.980]  И теперь мне нужно подобрать такой y-штрих,
[01:37:30.980 --> 01:37:34.980]  который бы давал точно такой же остаток от деления на m, что и p.
[01:37:34.980 --> 01:37:37.980]  А какие это y-ки?
[01:37:37.980 --> 01:37:47.980]  Ну которые находятся на одном и том же расстоянии от делителей m.
[01:37:47.980 --> 01:37:50.980]  Ну то есть здесь, здесь, здесь.
[01:37:50.980 --> 01:37:53.980]  Ну логика понятна, да?
[01:37:53.980 --> 01:37:56.980]  У меня x-штрих дает вот такой остаток от деления на m.
[01:37:56.980 --> 01:38:00.980]  Но соответственно, чтобы у меня y-штрих процент m совпадал с x-штрих процент m,
[01:38:00.980 --> 01:38:05.980]  мне нужно чтобы y лежал либо здесь, либо здесь, либо здесь, либо здесь, либо и так далее.
[01:38:05.980 --> 01:38:10.980]  Вот эта точка, естественно, выколота.
[01:38:10.980 --> 01:38:17.980]  Потому что я в первом пункте сказал, что x-штрих не равно y-штрих.
[01:38:17.980 --> 01:38:23.980]  Ага. Все ясно.
[01:38:23.980 --> 01:38:24.980]  Ну все.
[01:38:24.980 --> 01:38:32.980]  Ну и сколько вот таких точек зеленых у меня получается в итоге?
[01:38:32.980 --> 01:38:37.980]  Ну p делить на m минус 1, ну округленное вверх.
[01:38:37.980 --> 01:38:44.980]  Ну почему вверх? Потому что я еще могу вот этот вот неполный кусок,
[01:38:44.980 --> 01:38:49.980]  который целиком не содержит отрезок деления на m, могу тоже захватить теоретически.
[01:38:49.980 --> 01:38:51.980]  Согласны?
[01:38:51.980 --> 01:38:54.980]  В общем, p деленное на m, округленное вверх, минус 1.
[01:38:54.980 --> 01:38:57.980]  Минус 1, потому что вот эта точка у меня выколота.
[01:38:57.980 --> 01:39:00.980]  Ну все. Вот это уже сразу можем сократить.
[01:39:00.980 --> 01:39:07.980]  И получаем p деленное на m минус 1 делить на p минус 1.
[01:39:07.980 --> 01:39:10.980]  Так. Теперь.
[01:39:10.980 --> 01:39:15.980]  Ну все, короче, осталось вот поработать с этим уравнением, и мы все получили.
[01:39:15.980 --> 01:39:19.980]  Ну мне не нравятся целые части, а вам?
[01:39:19.980 --> 01:39:24.980]  Но с ними как-то неудобно работать. Давайте на что-нибудь заменим, на какую-нибудь верхнюю оценку.
[01:39:24.980 --> 01:39:33.980]  Мне кажется, вот это вполне нормальная верхняя оценка вот такой штуки.
[01:39:33.980 --> 01:39:35.980]  Нормально?
[01:39:35.980 --> 01:39:37.980]  Вот.
[01:39:37.980 --> 01:39:43.980]  Но я утверждаю, что это уже и есть 1 на m.
[01:39:43.980 --> 01:39:44.980]  Все.
[01:39:44.980 --> 01:39:46.980]  Ну вот это m деленное на m сокращается с этой единицей,
[01:39:46.980 --> 01:39:49.980]  остается p минус 1 деленное на m и деленное на p минус 1.
[01:39:49.980 --> 01:39:51.980]  Числитель сокращается, остается только m.
[01:39:51.980 --> 01:39:58.980]  Все.
[01:39:58.980 --> 01:40:03.980]  Все? Теперь верите?
[01:40:03.980 --> 01:40:04.980]  Ну вот.
[01:40:04.980 --> 01:40:08.980]  Значит, универсальная семейство существует.
[01:40:08.980 --> 01:40:14.980]  И вот, например, вот оно.
[01:40:14.980 --> 01:40:18.980]  Причем, заметьте, что теперь для хранения одной хэш-функции вот такой,
[01:40:18.980 --> 01:40:22.980]  мне достаточно хранить всего лишь два числа, a и b.
[01:40:22.980 --> 01:40:27.980]  То есть, по сути, я храню два nта и уже таким образом описываю хэш-функцию.
[01:40:27.980 --> 01:40:29.980]  Потом мне очень просто ее сгенерировать случайно.
[01:40:29.980 --> 01:40:32.980]  Ну то есть я генерурую случайное число a, генерурую случайное число b.
[01:40:32.980 --> 01:40:38.980]  И в итоге получаю хэш-функцию случайную, которая обладает вот таким свойством.
[01:40:38.980 --> 01:40:40.980]  Супер?
[01:40:40.980 --> 01:40:42.980]  Что?
[01:40:42.980 --> 01:40:44.980]  А п вам дано по условию сдачи.
[01:40:44.980 --> 01:40:48.980]  То есть если вам сказано, что, например, все числа не превосходят миллиард,
[01:40:48.980 --> 01:40:57.980]  ну вы в качестве п просто берете какое-нибудь простое число, которое больше миллиарда, и все.
[01:40:57.980 --> 01:41:02.980]  Еще вопросы можно?
[01:41:02.980 --> 01:41:05.980]  Ну ладно.
[01:41:05.980 --> 01:41:11.980]  Так.
[01:41:11.980 --> 01:41:18.980]  Давайте, может быть, приведем пример, чтобы закрепить понятие универсальной семейств,
[01:41:18.980 --> 01:41:22.980]  давайте приведем пример функции, которая не является универсальным семейством.
[01:41:22.980 --> 01:41:36.980]  Ну, например, семейство h, которое содержит всевозможные функции, надавайте вот такого вида.
[01:41:36.980 --> 01:41:53.980]  h равно просто ax, процент p, процент m.
[01:41:53.980 --> 01:42:01.980]  Вот такое не является универсальным семейством.
[01:42:01.980 --> 01:42:05.980]  Ну, короче говоря, вот из этого семейства нельзя выкинуть член b.
[01:42:05.980 --> 01:42:10.980]  Если мы избавляемся от члена b, то полученная hash-функция уже не является универсальной.
[01:42:10.980 --> 01:42:14.980]  Ну, как мы доказываем то, что функция не является универсальным?
[01:42:14.980 --> 01:42:17.980]  Ну, просто отрицанием определения.
[01:42:17.980 --> 01:42:19.980]  Определение мы убрали.
[01:42:19.980 --> 01:42:24.980]  Ну, короче, нужно показать.
[01:42:24.980 --> 01:42:29.980]  Мы должны найти x и y.
[01:42:29.980 --> 01:42:40.980]  x не равно y такие, что вероятность того, что h от x равна h от y, будет строго больше, чем 1 на m.
[01:42:40.980 --> 01:42:43.980]  Согласны?
[01:42:43.980 --> 01:42:46.980]  Ну, давайте приведем пример.
[01:42:46.980 --> 01:42:48.980]  Ну, я заранее подготовил.
[01:42:48.980 --> 01:42:51.980]  Сейчас, если вспомню.
[01:42:51.980 --> 01:43:03.980]  Значит, если взять p равно 7, m равно 2, x равно 1, y равно 3, по-моему, то все должно получиться.
[01:43:03.980 --> 01:43:09.980]  В общем, если вы хешируете множество из семи элементов и берете hash-таблицу размера 2,
[01:43:09.980 --> 01:43:15.980]  то для таких x и y у вас не получится вероятности совпадения меньше, чем 1 на m.
[01:43:15.980 --> 01:43:17.980]  Ну, в данном случае меньше, чем 1 вторая.
[01:43:17.980 --> 01:43:18.980]  Ну, как это показать?
[01:43:18.980 --> 01:43:31.980]  Ну, давайте просто рассмотрим всевозможные a и соответствующие значения h от x и h от y.
[01:43:31.980 --> 01:43:42.980]  Ну, a пробегает значения от 1 до 6, так как a не равно 0.
[01:43:42.980 --> 01:43:45.980]  Ну, чему равно h от x при a равным единице?
[01:43:45.980 --> 01:43:47.980]  Напомню, x равно единице.
[01:43:47.980 --> 01:43:52.980]  Ну, 1 на 1 процент p единица, процент m тоже единица.
[01:43:52.980 --> 01:43:53.980]  Согласны?
[01:43:53.980 --> 01:43:57.980]  Ну, давайте выпишем.
[01:43:57.980 --> 01:44:00.980]  Чему мне равна хеш-функция ax?
[01:44:00.980 --> 01:44:05.980]  Процент 7, процент 2.
[01:44:05.980 --> 01:44:08.980]  Вот туда подставляю.
[01:44:08.980 --> 01:44:10.980]  Так, a равно 2.
[01:44:10.980 --> 01:44:14.980]  2 умножить на 1, процент 7, это 2, процент 2 это 0.
[01:44:14.980 --> 01:44:18.980]  3 умножить на 1, процент 7 это 3, процент 2 это 1.
[01:44:18.980 --> 01:44:23.980]  Ну и дальше, на самом деле, легко понять, что все то же самое будет, потому что у меня х единица.
[01:44:23.980 --> 01:44:26.980]  Ну, там, 4 процент 7 это 4, процент 2 это 0.
[01:44:26.980 --> 01:44:28.980]  5 процент 7 это 5, процент 2 это единица.
[01:44:28.980 --> 01:44:30.980]  6 процент 7 это 6, процент 2 это 0.
[01:44:30.980 --> 01:44:32.980]  Вот такие значения.
[01:44:32.980 --> 01:44:36.980]  А теперь давайте посмотрим, какие значения у меня получаются для y.
[01:44:36.980 --> 01:44:38.980]  y равен тройке.
[01:44:38.980 --> 01:44:40.980]  Поэтому получается 3.
[01:44:40.980 --> 01:44:43.980]  3 умножить на 1, это 3.
[01:44:43.980 --> 01:44:46.980]  3 процент 7, 3 процент 2 это единица.
[01:44:46.980 --> 01:44:47.980]  Дальше.
[01:44:47.980 --> 01:44:49.980]  2 умножаю на y.
[01:44:49.980 --> 01:44:50.980]  Получается 6.
[01:44:50.980 --> 01:44:54.980]  6 процент 7 это 6, процент 2 это 0.
[01:44:54.980 --> 01:44:56.980]  Вот, уже есть два совпадения.
[01:44:56.980 --> 01:44:57.980]  Дальше.
[01:44:57.980 --> 01:44:58.980]  Для тройки.
[01:44:58.980 --> 01:44:59.980]  3 ж до 3, 9.
[01:44:59.980 --> 01:45:01.980]  Процент 7 это 2.
[01:45:01.980 --> 01:45:03.980]  2 процент 2 это 0.
[01:45:03.980 --> 01:45:05.980]  Тут не совпало.
[01:45:05.980 --> 01:45:06.980]  4.
[01:45:06.980 --> 01:45:08.980]  4 умножить на 3, это 12.
[01:45:08.980 --> 01:45:10.980]  12 процент 7 это 5.
[01:45:10.980 --> 01:45:12.980]  Процент 2 это 1.
[01:45:12.980 --> 01:45:13.980]  Снова не совпало.
[01:45:13.980 --> 01:45:14.980]  Ну, пока равенство.
[01:45:14.980 --> 01:45:15.980]  Интрига.
[01:45:15.980 --> 01:45:17.980]  Смотрим для пятёрки.
[01:45:17.980 --> 01:45:18.980]  y.
[01:45:18.980 --> 01:45:20.980]  3 умножить на 5, это 15.
[01:45:20.980 --> 01:45:22.980]  15 процент 7, это 1.
[01:45:22.980 --> 01:45:24.980]  1 процент 2, это 1.
[01:45:24.980 --> 01:45:25.980]  Совпало.
[01:45:25.980 --> 01:45:27.980]  Ну и последнее.
[01:45:27.980 --> 01:45:29.980]  6 умножить на 3, это 18.
[01:45:29.980 --> 01:45:31.980]  18 процент 7, 4.
[01:45:31.980 --> 01:45:34.980]  4 процент 2, это 0.
[01:45:34.980 --> 01:45:38.980]  Сколько у меня совпадений h от x и h от y?
[01:45:38.980 --> 01:45:40.980]  4 из 6.
[01:45:40.980 --> 01:45:48.980]  То есть, вероятность того, что у меня h от 1 совпадёт с h от 3, равно 2 трети.
[01:45:48.980 --> 01:45:51.980]  Что больше, чем 1 вторая.
[01:45:51.980 --> 01:45:55.980]  Ну всё, это не универсальное семейство.
[01:45:55.980 --> 01:45:56.980]  Понятно?
[01:45:56.980 --> 01:46:03.980]  То есть, если мне кто-нибудь будет подавать значение 1 и 3, то с большой вероятностью я получу коллизию.
[01:46:03.980 --> 01:46:09.980]  А я хотел, чтобы у меня коллизия была с маленькой вероятностью, то есть с вероятностью хотя бы 1 вторая.
[01:46:09.980 --> 01:46:11.980]  Ага.
[01:46:13.980 --> 01:46:15.980]  Всё.
[01:46:22.980 --> 01:46:24.980]  Вопросы?
[01:46:24.980 --> 01:46:27.980]  Ну не знаю, можно упражнения ставить кое-нибудь.
[01:46:31.980 --> 01:46:52.980]  Доказать, что множество hb, h от x равно x плюс b процент p процент n, тоже не универсально.
[01:46:52.980 --> 01:46:54.980]  Универсально.
[01:46:54.980 --> 01:46:59.980]  Короче говоря, у этой формулы нельзя взять ни b, ни a.
[01:46:59.980 --> 01:47:06.980]  То есть, если мы a отнимаем и привели пример, когда у нас существует пара x и y, что вероятность большая,
[01:47:06.980 --> 01:47:10.980]  то тут тоже самое, но только для x плюс b.
[01:47:10.980 --> 01:47:12.980]  Ладно.
[01:47:14.980 --> 01:47:20.980]  Ну и третий пункт нашего разговора про hash функции, про hash таблицы.
[01:47:20.980 --> 01:47:24.980]  Короче, про метод цепочек мы на самом деле закончили.
[01:47:24.980 --> 01:47:31.980]  Если мы строим динамическую hash таблицу, то, вообще говоря, нам достаточно использовать универсальную hash функцию.
[01:47:31.980 --> 01:47:34.980]  Универсальные hash функции существуют не только для целых чисел, как здесь.
[01:47:34.980 --> 01:47:36.980]  Они существуют и для строк, и так далее.
[01:47:36.980 --> 01:47:39.980]  Для строк используется полинамерный hash, и так далее, и все они универсальные.
[01:47:39.980 --> 01:47:41.980]  Поэтому всё нормально.
[01:47:41.980 --> 01:47:48.980]  То есть мы для каждого множества можем гарантировать, что мы сможем это всё в среднем захашировать так,
[01:47:48.980 --> 01:47:53.980]  что среднее время поиска будет равно o большое от единицы плюс n деленное на m.
[01:47:53.980 --> 01:47:56.980]  Ну и плюс мы помним, мы использовали схему с расширением,
[01:47:56.980 --> 01:48:02.980]  поэтому мы можем обеспечить, что поиск в такой hash таблице всегда будет в среднем занимать от единицы.
[01:48:02.980 --> 01:48:04.980]  Окей.
[01:48:06.980 --> 01:48:08.980]  Здесь всё понятно.
[01:48:08.980 --> 01:48:12.980]  Теперь давайте рассмотрим несколько другую постановку задачи.
[01:48:13.980 --> 01:48:15.980]  Называется она
[01:48:21.980 --> 01:48:23.980]  идеальное
[01:48:27.980 --> 01:48:31.980]  хаширование статического множества.
[01:48:42.980 --> 01:48:44.980]  Задача такая.
[01:48:48.980 --> 01:48:52.980]  Ну вот, когда мы строили hash таблицу методом цепочек,
[01:48:52.980 --> 01:48:55.980]  ну вот до этого мы строили там hash таблицу,
[01:48:55.980 --> 01:48:58.980]  мы на самом деле наперёд не знали, какие нам объекты придут.
[01:48:58.980 --> 01:49:02.980]  То есть нам приходит какой-то объект, и мы должны сразу же определить, в какую корзину его положить.
[01:49:02.980 --> 01:49:04.980]  Нам приходит объект, нам говорят, что нужно его удалить,
[01:49:04.980 --> 01:49:08.980]  и мы сразу должны пойти в нужную корзину и этот объект удалить.
[01:49:08.980 --> 01:49:10.980]  И вот в этих условиях, когда мы заранее не знаем,
[01:49:10.980 --> 01:49:12.980]  какие ключи нам придут,
[01:49:12.980 --> 01:49:14.980]  мы должны как-то построить эффективную hash таблицу.
[01:49:14.980 --> 01:49:16.980]  Вот нам удалось построить hash таблицу,
[01:49:16.980 --> 01:49:18.980]  которая работает в среднем за единицу.
[01:49:18.980 --> 01:49:21.980]  А теперь я ставлю другую задачу.
[01:49:25.980 --> 01:49:33.980]  Дано фиксированное множество х
[01:49:37.980 --> 01:49:39.980]  из n элементов.
[01:49:40.980 --> 01:49:42.980]  То есть мне заранее сказали,
[01:49:42.980 --> 01:49:44.980]  мне заранее говорят, что будут такие элементы,
[01:49:44.980 --> 01:49:46.980]  и никакие другие.
[01:49:46.980 --> 01:49:48.980]  И я хочу это множество захешировать.
[01:49:48.980 --> 01:49:50.980]  То есть я хочу быстро отвечать,
[01:49:50.980 --> 01:49:52.980]  какой это элемент лежит в этом множестве или нет.
[01:49:52.980 --> 01:49:55.980]  Понятное дело, что я могу эту задачу решить старым способом,
[01:49:55.980 --> 01:49:58.980]  то есть просто засунуть это всё в hash таблицу с методом цепочек
[01:49:58.980 --> 01:50:00.980]  и работать с ней.
[01:50:00.980 --> 01:50:02.980]  Но при этом что у меня может возникнуть?
[01:50:02.980 --> 01:50:04.980]  У меня могут возникать коллизии,
[01:50:04.980 --> 01:50:07.980]  чисто теоретически опять же могут возникать длинные цепочки.
[01:50:07.980 --> 01:50:09.980]  Ну, наверное, если мне известно множество заранее,
[01:50:09.980 --> 01:50:12.980]  я могу как-то построить мою таблицу как-то эффективней.
[01:50:12.980 --> 01:50:15.980]  То есть сделать так, чтобы в ней, например, вообще не было коллизий.
[01:50:15.980 --> 01:50:18.980]  И вот как раз такие задачи хеширования без коллизий
[01:50:18.980 --> 01:50:20.980]  называются идеальным хешированием.
[01:50:20.980 --> 01:50:23.980]  Соответственно, задача
[01:50:23.980 --> 01:50:33.980]  будет построить hash таблицу
[01:50:33.980 --> 01:50:39.980]  на множестве х
[01:50:39.980 --> 01:50:45.980]  без коллизий.
[01:50:45.980 --> 01:50:47.980]  Ну, вот этой задачей после первого займёмся.
[01:50:47.980 --> 01:50:50.980]  Так, давайте продолжим.
[01:50:53.980 --> 01:50:57.980]  Так, нам дано некоторое фиксированное множество ключей,
[01:50:57.980 --> 01:51:01.980]  которое естественно является под множеством множества всевозможных ключей,
[01:51:01.980 --> 01:51:03.980]  которые в принципе могут быть.
[01:51:03.980 --> 01:51:06.980]  И нам нужно построить хеш таблицу такую,
[01:51:06.980 --> 01:51:08.980]  что на таком множестве она не даёт коллизий.
[01:51:08.980 --> 01:51:11.980]  То есть мы хотим сохранить все эти элементы
[01:51:11.980 --> 01:51:15.980]  и условно хотим, чтобы операция
[01:51:15.980 --> 01:51:28.980]  find от x работала за θ от единицы в худшем случае.
[01:51:28.980 --> 01:51:36.980]  Ну, операции типа insert и erase, их нет.
[01:51:36.980 --> 01:51:38.980]  То есть множество фиксировано,
[01:51:38.980 --> 01:51:42.980]  и оно остаётся таким до конца жизни хеш таблицы.
[01:51:42.980 --> 01:51:46.980]  Так, ну давайте попробуем как-то проанализировать
[01:51:46.980 --> 01:51:49.980]  и решить эту задачу.
[01:51:49.980 --> 01:51:56.980]  В качестве первого пункта давайте обозначим за c
[01:51:56.980 --> 01:52:03.980]  число коллизий в хеш таблице.
[01:52:03.980 --> 01:52:05.980]  Вот пусть c это общее число коллизий,
[01:52:05.980 --> 01:52:10.980]  которое у меня есть в хеш таблице.
[01:52:10.980 --> 01:52:14.980]  Значит математически число c я могу выразить следующим образом.
[01:52:14.980 --> 01:52:19.980]  Сумма по всем i меньше, чем j.
[01:52:19.980 --> 01:52:29.980]  Индикатор того, что h от x и совпадает с h от x j.
[01:52:29.980 --> 01:52:32.980]  Согласны?
[01:52:32.980 --> 01:52:36.980]  Я просто перебираю всевозможные пары x и y,
[01:52:36.980 --> 01:52:38.980]  да, всевозможные пары x,
[01:52:38.980 --> 01:52:43.980]  и спрашиваю, верно ли что хеш от x этого совпадает с хешом от x этого.
[01:52:43.980 --> 01:52:45.980]  Если хешы совпадают, то есть коллизия.
[01:52:45.980 --> 01:52:47.980]  Я делаю плюс один.
[01:52:47.980 --> 01:52:50.980]  Если они совпадают, то коллизии нет, соответственно плюс ноль.
[01:52:50.980 --> 01:52:54.980]  Вот если я всё это просумирую, то я получу как раз таки общее число коллизий.
[01:53:08.980 --> 01:53:12.980]  Ну и давайте с этим числом что-нибудь сделаем.
[01:53:12.980 --> 01:53:36.980]  Ну, например, оценим среднее число коллизий в хеш таблице размера m.
[01:53:38.980 --> 01:53:48.980]  При выборе h из некоторого универсального семейства хешей.
[01:53:48.980 --> 01:53:54.980]  Из универсального семейства.
[01:53:54.980 --> 01:53:58.980]  Ну, снова, я как бы сейчас, сейчас я буду предполагать,
[01:53:58.980 --> 01:54:00.980]  что я всегда работаю с хешами из универсального семейства.
[01:54:00.980 --> 01:54:03.980]  Да, потому что они существуют и потому что они хорошие.
[01:54:03.980 --> 01:54:05.980]  Окей?
[01:54:05.980 --> 01:54:09.980]  Вот, то есть я случайно выбираю хеш функцию из универсального семейства,
[01:54:09.980 --> 01:54:12.980]  беру хеш таблицу размера m и смотрю, сколько у меня в среднем,
[01:54:12.980 --> 01:54:16.980]  в среднем будет получаться коллизий.
[01:54:16.980 --> 01:54:19.980]  Я просто должен взять среднее число c.
[01:54:19.980 --> 01:54:22.980]  Ну, среднее от случайной величины c.
[01:54:22.980 --> 01:54:27.980]  Значит, это просто средняя сумма, которая была написана там.
[01:54:27.980 --> 01:54:37.980]  h от x и равно h от xj и меньше, чем j.
[01:54:37.980 --> 01:54:48.980]  Средняя сумма, это то же самое, что сумма средних в прошлый раз обсуждали.
[01:54:48.980 --> 01:54:53.980]  h от x и равно h от xj.
[01:54:53.980 --> 01:54:56.980]  А чему равно средние величины, которые понимают значение 0 или 1?
[01:54:56.980 --> 01:55:01.980]  Да, равно просто вероятности вот этого события.
[01:55:01.980 --> 01:55:13.980]  То есть это просто сумма по i меньше, чем j, вероятности h от x и равно h от xj.
[01:55:13.980 --> 01:55:16.980]  Что можно сказать про эту штуку, про эту вероятность?
[01:55:16.980 --> 01:55:19.980]  Да, меньше или равно, чем 1 на m.
[01:55:19.980 --> 01:55:23.980]  Потому что h мы выбрали случайно из универсального семейства.
[01:55:23.980 --> 01:55:29.980]  Средней суммой меньше равно, чем сумма по всем i меньше, чем j, 1 на m.
[01:55:29.980 --> 01:55:37.980]  Но это чему равно? Чему равно количество слагаемых вот в такой сумме?
[01:55:37.980 --> 01:55:39.980]  n на n-1 пополам, да.
[01:55:39.980 --> 01:55:42.980]  Просто мы берем всевозможное количество неупорядочных пар.
[01:55:42.980 --> 01:55:50.980]  Количество неупорядочных пар это n на n-1 пополам, ну и 1 на m.
[01:55:50.980 --> 01:55:55.980]  Все, вот.
[01:55:55.980 --> 01:56:00.980]  Вот такое число коллизий у меня получается в среднем.
[01:56:00.980 --> 01:56:07.980]  Ну а мы-то вроде хотели вообще без коллизий.
[01:56:07.980 --> 01:56:10.980]  Ну и в принципе, смотрите, эта формула уже что-то показывает.
[01:56:10.980 --> 01:56:17.980]  Но в частности она говорит нам то, что чем больше у нас m, тем меньше у нас коллизий.
[01:56:17.980 --> 01:56:22.980]  Логично? Очевидно.
[01:56:22.980 --> 01:56:27.980]  То есть чем больше х-таблицу мы берем, тем меньше у нас вероятность того,
[01:56:27.980 --> 01:56:31.980]  что у нас два объекта попадут в одну корзину.
[01:56:31.980 --> 01:56:32.980]  Ну, кажется, понятно.
[01:56:32.980 --> 01:56:40.980]  Значит, прежде чем доказывать что-то разумное, давайте докажем одну лему из тервера.
[01:56:40.980 --> 01:56:44.980]  Лему Маркова.
[01:56:44.980 --> 01:56:48.980]  Значит, сформирую ее в несколько упрощенном виде.
[01:56:48.980 --> 01:56:56.980]  Потом, спустя какое-то время, на тервере докажете ее в общем случае.
[01:56:56.980 --> 01:57:09.980]  Пусть х случайная величина.
[01:57:09.980 --> 01:57:11.980]  Ну, что такое случайная величина?
[01:57:11.980 --> 01:57:13.980]  Формально я опущу.
[01:57:13.980 --> 01:57:17.980]  Ну, просто скажем, что х это некоторая величина,
[01:57:17.980 --> 01:57:20.980]  которая принимает случайные значения на множестве натуральных чисел.
[01:57:20.980 --> 01:57:22.980]  Окей?
[01:57:22.980 --> 01:57:23.980]  Понятно?
[01:57:23.980 --> 01:57:26.980]  Ну, не знаю, там, подбрасывание кубика.
[01:57:26.980 --> 01:57:29.980]  То есть это случайная величина, которая принимает значения от 1 до 6.
[01:57:29.980 --> 01:57:32.980]  Там количество людей, присутствующих на лекции.
[01:57:32.980 --> 01:57:36.980]  Это случайная величина от нуля до, сколько у вас там может быть.
[01:57:36.980 --> 01:57:41.980]  Соответственно, пусть х случайная величина,
[01:57:41.980 --> 01:57:50.980]  тогда вероятность того, что х будет больше, чем ε,
[01:57:50.980 --> 01:57:54.980]  ну, естественно, ε больше нуля, меньше либо равна,
[01:57:54.980 --> 01:57:59.980]  давайте вот так.
[01:57:59.980 --> 01:58:01.980]  Вероятность того, что х будет больше либо равней, чем ε,
[01:58:01.980 --> 01:58:08.980]  меньше либо равна, чем среднее х разделенное на ε.
[01:58:08.980 --> 01:58:11.980]  То есть смысл этой леммы какой?
[01:58:11.980 --> 01:58:14.980]  Если у вас средней величины мало,
[01:58:14.980 --> 01:58:17.980]  то и вероятность больших значений тоже мала.
[01:58:17.980 --> 01:58:21.980]  То есть если вы знаете, что какая-то величина принимает в среднем значение 2,
[01:58:21.980 --> 01:58:23.980]  то вероятность того, что она будет больше миллиона,
[01:58:23.980 --> 01:58:26.980]  она стремится к нулу, то есть она тоже очень-очень мала.
[01:58:26.980 --> 01:58:28.980]  Понятно?
[01:58:28.980 --> 01:58:31.980]  Но это неформальный смысл такой, давайте докажем.
[01:58:31.980 --> 01:58:36.980]  Очень просто, значит.
[01:58:36.980 --> 01:58:44.980]  Нет, с другой стороны пойдем.
[01:58:44.980 --> 01:58:50.980]  Наоборот, распишем среднее значение х.
[01:58:50.980 --> 01:58:52.980]  Что такое среднее значение х?
[01:58:52.980 --> 01:58:54.980]  Это сумма по всем х,
[01:58:54.980 --> 01:59:01.980]  вероятность того, что х большое равно х.
[01:59:01.980 --> 01:59:04.980]  То есть просто я беру все значения х
[01:59:04.980 --> 01:59:06.980]  и уножаю на вероятность, потом складываю.
[01:59:06.980 --> 01:59:09.980]  Просто усреднение.
[01:59:09.980 --> 01:59:14.980]  Так, теперь оценю это все снизу.
[01:59:14.980 --> 01:59:23.980]  Давайте я возьму и выкину те х, которые меньше, чем ε.
[01:59:23.980 --> 01:59:28.980]  То есть просто возьму только те члены, которые нужны мне.
[01:59:28.980 --> 01:59:37.980]  Вот это вот такие.
[01:59:37.980 --> 01:59:39.980]  Никто не против?
[01:59:39.980 --> 01:59:41.980]  То есть я просто выкинул какие-то члены из этой суммы.
[01:59:41.980 --> 01:59:46.980]  Соответственно, не увеличил сумму таким образом.
[01:59:46.980 --> 01:59:48.980]  Теперь давайте эту сумму еще больше уменьшу.
[01:59:48.980 --> 01:59:50.980]  Ну а в частности скажу следующую вещь.
[01:59:50.980 --> 01:59:53.980]  Ну смотрите, у меня здесь х, все больше либо равны ε.
[01:59:53.980 --> 01:59:56.980]  Давайте я возьму все х и заменю просто на ε.
[01:59:56.980 --> 02:00:01.980]  Согласны, что у меня значение суммы от этого тоже только уменьшится.
[02:00:01.980 --> 02:00:05.980]  То есть возьму ε и вытащу сразу за знак суммы.
[02:00:05.980 --> 02:00:12.980]  В итоге получится вот такая вещь.
[02:00:12.980 --> 02:00:14.980]  Согласны?
[02:00:14.980 --> 02:00:18.980]  Ну а чему равна сумма вероятности того, что х равен ε,
[02:00:18.980 --> 02:00:23.980]  ε плюс 1, ε плюс 2 и так далее?
[02:00:23.980 --> 02:00:25.980]  Ну кажется, это просто равно вероятности тому,
[02:00:25.980 --> 02:00:32.980]  что у меня х больше или равней, чем ε.
[02:00:32.980 --> 02:00:35.980]  Последний переход понятен?
[02:00:35.980 --> 02:00:37.980]  Здесь я просто просуммировал все вероятности того,
[02:00:37.980 --> 02:00:39.980]  что у меня х большое равен ε,
[02:00:39.980 --> 02:00:41.980]  на ε плюс 1, на ε плюс 2 и так далее.
[02:00:41.980 --> 02:00:42.980]  И так до бесконечности.
[02:00:42.980 --> 02:00:44.980]  Ну соответственно, вся эта сумма это то же самое,
[02:00:44.980 --> 02:00:49.980]  что вероятности того, что х у меня больше либо равен, чем ε.
[02:00:49.980 --> 02:00:52.980]  Ну все.
[02:00:52.980 --> 02:00:54.980]  Осталось, понятное дело, разделить обе части на ε
[02:00:54.980 --> 02:00:57.980]  и получим как раз то, чего хотели.
[02:00:57.980 --> 02:01:00.980]  Все, просто.
[02:01:00.980 --> 02:01:03.980]  Окей.
[02:01:20.980 --> 02:01:28.980]  Так, ну и наконец теорема,
[02:01:28.980 --> 02:01:34.980]  которая будет говорить нам следующее.
[02:01:34.980 --> 02:01:46.980]  Пусть h выбрано из универсального семейства
[02:01:46.980 --> 02:01:53.980]  и размер х-таблицы m равен m квадрат.
[02:01:53.980 --> 02:01:57.980]  Ну то есть снова я х-функцию выбираю случайно из универсального семейства
[02:01:57.980 --> 02:02:01.980]  и беру х-таблицу, которая у меня имеет размер n квадрат.
[02:02:01.980 --> 02:02:04.980]  Она имеет квадратичный размер относительно количества элементов,
[02:02:04.980 --> 02:02:09.980]  которые в ней содержатся.
[02:02:09.980 --> 02:02:15.980]  Тогда вероятность того, что у меня есть хотя бы одна коллизия...
[02:02:15.980 --> 02:02:18.980]  ну c это число коллизий, мы за c обозначили число коллизий.
[02:02:18.980 --> 02:02:22.980]  Тогда вероятность того, что у меня есть хотя бы одна коллизия,
[02:02:22.980 --> 02:02:25.980]  меньше чем 1 вторая.
[02:02:25.980 --> 02:02:30.740]  с очень большой вероятностью, с вероятностью больше, чем одна вторая, у меня в кэштаблице не будет коллизии вообще.
[02:02:33.260 --> 02:02:35.820]  Смысл понятен? Давайте тут напишу.
[02:02:38.380 --> 02:02:40.380]  С большой
[02:02:41.420 --> 02:02:44.980]  вероятностью не будет
[02:02:47.660 --> 02:02:49.660]  коллизий.
[02:02:51.140 --> 02:02:53.140]  Доказательства.
[02:02:55.980 --> 02:02:59.980]  Воспользуемся леммий Маркова.
[02:03:02.980 --> 02:03:09.740]  Все условия соблюны. С у меня принимает только натуральные значения, то есть число коллизий это натуральное число, единица больше нуля.
[02:03:11.940 --> 02:03:13.940]  Тогда по
[02:03:15.020 --> 02:03:21.860]  леммий Маркова что получается? Это меньше киберно, чем среднее значение С делено единицу. Согласны?
[02:03:23.300 --> 02:03:25.300]  А чему равно среднее значение С?
[02:03:26.980 --> 02:03:28.980]  А мы вот считали.
[02:03:33.100 --> 02:03:38.260]  Ну это давайте за звездочку обозначим, этот факт из звездочки.
[02:03:38.980 --> 02:03:42.900]  Следует, что это меньше киберно, чем n на n-1
[02:03:43.740 --> 02:03:45.740]  на 2m.
[02:03:46.020 --> 02:03:48.020]  Так, а m у нас n квадрат.
[02:03:50.940 --> 02:03:55.300]  Получается n на n-1 на 2n квадрат.
[02:03:55.980 --> 02:04:03.660]  Доказывать, что это меньше, чем 1 вторая. Я не буду упражнений, окей?
[02:04:06.340 --> 02:04:08.060]  Все понятно.
[02:04:08.060 --> 02:04:14.540]  То есть таким образом, что из этого следует? Если мы хотим взять множество и идеально его захэшировать без коллизий,
[02:04:15.100 --> 02:04:18.380]  то мы берем хэш таблицу размера m равный n квадрат,
[02:04:19.540 --> 02:04:21.380]  хэшируем.
[02:04:21.380 --> 02:04:27.940]  Смотрим, есть ли у нас коллизии или нет. Если коллизии нет, то все хорошо. Если коллизии есть, то
[02:04:28.540 --> 02:04:30.660]  строим нашу хэш таблицу заново. Вот.
[02:04:33.340 --> 02:04:37.260]  Ну и с большой вероятностью мы получим хэш таблицу, в которой коллизии нет. Понятно?
[02:04:38.700 --> 02:04:40.700]  Ну на этом все. Всем спасибо.
[02:04:42.740 --> 02:04:46.780]  Не повелись, ладно. Хорошо. Что смущает?
[02:04:46.780 --> 02:04:48.780]  Что смущает?
[02:04:49.780 --> 02:04:51.780]  Что смущает?
[02:04:57.180 --> 02:04:59.180]  Только это.
[02:04:59.980 --> 02:05:01.980]  Ну тогда посидим, ладно.
[02:05:02.940 --> 02:05:04.940]  В чем проблема?
[02:05:06.820 --> 02:05:08.820]  У вас, например,
[02:05:09.260 --> 02:05:11.740]  ничего, что у нас хэш таблица имеет размер n квадрат, а
[02:05:12.580 --> 02:05:15.780]  ничего, что я хочу хэшировать, например, множество размера миллион.
[02:05:16.780 --> 02:05:22.740]  Ну, то есть, естественно, это не все.
[02:05:28.540 --> 02:05:34.820]  Если мы будем действовать вот по такому плану, то наша хэш таблица будет жрать слишком много памяти, и это беда.
[02:05:39.860 --> 02:05:43.500]  В идеале хотелось бы хэш таблицы, которая потребляет
[02:05:44.220 --> 02:05:51.380]  линейное количество памяти. То есть, мне дали миллион объектов, я хочу, чтобы меня потратил порядка миллиона там байт, чего угодно, бит.
[02:05:53.540 --> 02:05:56.380]  Давайте попробуем это как-то получить.
[02:06:00.180 --> 02:06:06.140]  Иметь одну хэш таблицу
[02:06:10.900 --> 02:06:12.900]  размер n квадрат
[02:06:14.500 --> 02:06:16.500]  дорого.
[02:06:17.500 --> 02:06:19.500]  Идея.
[02:06:25.500 --> 02:06:28.500]  Заведем хэш таблицу
[02:06:34.500 --> 02:06:38.500]  в каждой ячейке которой
[02:06:43.500 --> 02:06:47.500]  мы будем хранить
[02:06:52.860 --> 02:06:56.260]  другую хэш таблицу.
[02:06:59.500 --> 02:07:08.500]  Ну вот, если я буду хранить одну хэш таблицу на все элементы, ну и говорить о том, что, ну вот там, если у меня хэш таблица большая, то у меня вероятность калидий будет маленькая, поэтому это меня устраивает.
[02:07:09.500 --> 02:07:12.500]  Нет, не устраивает. Давайте я сделаю следующую вещь. Давайте я распределю
[02:07:13.500 --> 02:07:15.500]  мои элементы по корзинам,
[02:07:16.500 --> 02:07:23.500]  по некоторому большому количеству корзин, а дальше внутри каждой корзины построю свою хэш таблицу уже размера n квадрат.
[02:07:24.500 --> 02:07:27.500]  Ну то есть, сделаю такую вещь. У меня будет одна
[02:07:29.500 --> 02:07:31.500]  внешняя хэш таблица,
[02:07:32.500 --> 02:07:39.500]  и внутри этой внешней хэш таблицы будет хэш таблица 1, хэш таблица 2, хэш таблица 3,
[02:07:39.500 --> 02:07:47.500]  каждая из которых будет иметь размер n1 квадрат, n2 квадрат, n3 квадрат, ну и так далее.
[02:07:48.500 --> 02:07:49.500]  Окей?
[02:07:50.500 --> 02:07:55.500]  То есть, сначала я раскидаю элементы, раскидаю элементы по корзинам,
[02:07:56.500 --> 02:07:59.500]  а потом внутри каждую корзину сделаю так, чтобы она там была без коллизий.
[02:08:00.500 --> 02:08:05.500]  Ну и тогда у меня в целом вся хэш таблица тоже не будет иметь коллизий. Почему?
[02:08:05.500 --> 02:08:09.500]  Потому что я буду всегда точно знать, где находится тот или иной элемент.
[02:08:10.500 --> 02:08:16.500]  Ну скажем, сначала я иду в эту корзину, а потом внутри этой корзины я за единицу понимаю,
[02:08:17.500 --> 02:08:20.500]  в какой ячейке у меня хранится тот или иной элемент. План понятен?
[02:08:21.500 --> 02:08:23.500]  То есть у меня будет хэш таблица хэш таблиц.
[02:08:24.500 --> 02:08:26.500]  Каждый из внутренних хэш таблиц будет иметь размер n квадрат.
[02:08:27.500 --> 02:08:29.500]  Где n это количество элементов, которые попали сюда.
[02:08:30.500 --> 02:08:32.500]  План понятен?
[02:08:32.500 --> 02:08:34.500]  План понятен?
[02:08:35.500 --> 02:08:39.500]  Возникает вопрос, ну хорошо, вот я взял одну большую хэш таблицу размера n квадрат,
[02:08:40.500 --> 02:08:42.500]  или я взял много маленьких хэш таблиц размера n квадрат.
[02:08:43.500 --> 02:08:46.500]  Вот с чего я взял, что общий размер этой штуки будет меньше, чем тот?
[02:08:47.500 --> 02:08:53.500]  Ну давайте докажем, что это действительно так.
[02:09:02.500 --> 02:09:12.500]  Давайте теорема 3.
[02:09:12.500 --> 02:09:40.500]  Пусть m равно n, h из универсального семейства.
[02:09:42.500 --> 02:10:07.500]  Пусть так-так, так-так, и дополнительно и в корзину и попало n и объектов.
[02:10:07.500 --> 02:10:16.500]  Ну то есть все то же самое, я беру какую-то внешнюю хэш функцию h,
[02:10:17.500 --> 02:10:19.500]  и все элементы распределяю по корзинам.
[02:10:20.500 --> 02:10:22.500]  И пусть там выитую корзину, у меня попало n и элементов.
[02:10:23.500 --> 02:10:25.500]  Вот это условие.
[02:10:26.500 --> 02:10:28.500]  Тогда утверждается следующее.
[02:10:29.500 --> 02:10:34.500]  Тогда среднее значение суммы n и в квадрате,
[02:10:35.500 --> 02:10:43.500]  где i от единицы до n, меньше либо равно, даже строго меньше, чем 2n, кажется.
[02:10:44.500 --> 02:10:46.500]  Ну сейчас поймем.
[02:10:47.500 --> 02:10:49.500]  Понятно?
[02:10:50.500 --> 02:10:55.500]  Утверждается следующее, что если я возьму хэш функцию из универсального семейства,
[02:10:55.500 --> 02:11:01.500]  возьму хэш таблицу размера n, и буду случайно распределить все элементы по корзинам,
[02:11:02.500 --> 02:11:04.500]  то сумма квадратов всех размеров внутренних корзин,
[02:11:05.500 --> 02:11:09.500]  то есть я сказал, что у меня каждая корзина, это хэш таблица размера n квадрат.
[02:11:10.500 --> 02:11:12.500]  Вот если я все размеры этих хэш таблиц просуммирую,
[02:11:13.500 --> 02:11:16.500]  у меня в среднем получится величина, которая не превосходит 2n.
[02:11:17.500 --> 02:11:19.500]  Понятно? То есть в среднем я получу хэш таблицу,
[02:11:20.500 --> 02:11:22.500]  которая не более чем в два раза превосходит размер моего множества.
[02:11:22.500 --> 02:11:24.500]  Круто?
[02:11:27.500 --> 02:11:29.500]  Давайте докажем.
[02:11:33.500 --> 02:11:35.500]  Вот так.
[02:11:41.500 --> 02:11:46.500]  Давайте перепишем n и t в квадрате каким-нибудь способом
[02:11:47.500 --> 02:11:49.500]  типа такого
[02:11:58.500 --> 02:12:00.500]  n-1 в полам
[02:12:01.500 --> 02:12:05.500]  плюс сумма х100m
[02:12:11.500 --> 02:12:13.500]  Ну, кажется, не соврал.
[02:12:14.500 --> 02:12:17.500]  Кажется, что эта сумма действительно совпадает с тем, что написано здесь.
[02:12:19.500 --> 02:12:21.500]  Вот эта двойка с этой двойкой сократятся,
[02:12:22.500 --> 02:12:24.500]  тут будет n и t в квадрате минус n и, и плюс n и.
[02:12:25.500 --> 02:12:27.500]  Все, останется просто n и t в квадрате.
[02:12:28.500 --> 02:12:32.500]  Для чего я это сделал? Давайте для начала поймем, что здесь написано.
[02:12:38.500 --> 02:12:40.500]  Чему равна вот эта штука?
[02:12:41.500 --> 02:12:45.500]  Чему? Просто n. Все видят.
[02:12:46.500 --> 02:12:50.500]  Но если я просуммирую просто количество элементов, которые попало сюда, сюда, сюда, сюда,
[02:12:51.500 --> 02:12:54.500]  то я получу просто n. То есть это не случайная штука, это просто
[02:12:55.500 --> 02:12:57.500]  общее число всех элементов.
[02:13:00.500 --> 02:13:02.500]  А вот это?
[02:13:04.500 --> 02:13:06.500]  Вот это уже интересней.
[02:13:07.500 --> 02:13:11.500]  Смотрите, я беру какую-то корзину
[02:13:12.500 --> 02:13:14.500]  и т.
[02:13:15.500 --> 02:13:21.500]  И смотрю, какое количество всевозможных пар я могу составить из элементов одной корзины.
[02:13:22.500 --> 02:13:24.500]  То есть я беру все элементы, которые попали сюда,
[02:13:25.500 --> 02:13:27.500]  и считаю количество всевозможных пар неупорядоченных здесь.
[02:13:28.500 --> 02:13:30.500]  А потом все это суммирую.
[02:13:31.500 --> 02:13:33.500]  Чему это в итоге будет равно?
[02:13:33.500 --> 02:13:36.500]  У нас не так много вариантов. Мы не так много букв вводили.
[02:13:37.500 --> 02:13:39.500]  C.
[02:13:40.500 --> 02:13:41.500]  Всем понятно, почему C?
[02:13:42.500 --> 02:13:45.500]  Всем ли понятно, почему это в точности равно общему числу коллизий?
[02:13:46.500 --> 02:13:48.500]  Какие объекты у меня образуют коллизии?
[02:13:49.500 --> 02:13:50.500]  Коллизии у меня образуют те объекты, которые попали в одну корзину.
[02:13:51.500 --> 02:13:53.500]  Я смотрю эту корзину и смотрю всевозможные пары здесь.
[02:13:54.500 --> 02:13:56.500]  Потом я беру эту корзину, смотрю всевозможные пары здесь и так далее.
[02:13:57.500 --> 02:13:59.500]  И потом суммирую их количество. В итоге получаю общее число коллизий.
[02:14:00.500 --> 02:14:01.500]  Здорово?
[02:14:01.500 --> 02:14:16.500]  Так, в итоге получается среднее значение, ну двойку давайте сразу вынесу, в итоге получается среднее значение, среднее количество коллизий, плюс просто n.
[02:14:16.500 --> 02:14:18.500]  Ну, среднее значение n-ки просто n.
[02:14:18.500 --> 02:14:23.500]  Ну, то есть неважно, как я там расправляю элементы, у меня общее количество элементов, вот это не меняется.
[02:14:23.500 --> 02:14:28.500]  Так, ну и кажется вот это я тоже считал уже когда-то.
[02:14:28.500 --> 02:14:37.500]  Это n на n-1, деленное на 2m, плюс n.
[02:14:37.500 --> 02:14:40.500]  Вот.
[02:14:40.500 --> 02:14:44.500]  А чему равно m?
[02:14:44.500 --> 02:14:48.500]  По условию у меня m равно n, да?
[02:14:49.500 --> 02:14:56.500]  Ну все, и кажется это, кажется я даже угадал, то есть меньше чем 2n. Понятно?
[02:14:56.500 --> 02:15:00.500]  Ну вместо m-ки ставлю n, сокращается, получается n-1 плюс n, естественно меньше чем 2n.
[02:15:00.500 --> 02:15:03.500]  Все.
[02:15:03.500 --> 02:15:15.500]  Почти все, мы почти готовы, осталось только доказать одно, ну не доказать, а просто привести следствие и пазл сойдется.
[02:15:18.500 --> 02:15:25.500]  Следствие.
[02:15:25.500 --> 02:15:37.500]  Вероятность того, что сумма n в квадрате будет больше либо равно, чем 4n, меньше чем, ну меньше либо равно, чем 1 вторая.
[02:15:37.500 --> 02:15:43.500]  Ну даже строго меньше, чем 1 вторая.
[02:15:43.500 --> 02:15:56.500]  То есть вероятность того, что у меня размер х-таблицы будет огромный, ну в смысле больше чем 4n, очень маленькая, меньше чем 1 вторая.
[02:15:56.500 --> 02:16:02.500]  Ну при доказательстве воспользуемся просто Леммемаркова.
[02:16:02.500 --> 02:16:15.500]  Это меньше либо равно по Леммемаркова среднее значение суммы n в квадрате, деленное на 4n. Согласны?
[02:16:15.500 --> 02:16:22.500]  Ну а среднее значение suma n в квадрате мы считали здесь. Это меньше чем 2n.
[02:16:22.500 --> 02:16:31.500]  Да?
[02:16:31.500 --> 02:16:38.500]  Все.
[02:16:38.500 --> 02:16:47.500]  Все, теорем больше не будет.
[02:16:47.500 --> 02:16:55.500]  Как минимум сегодня.
[02:16:55.500 --> 02:17:02.500]  Все, наконец-то переходим к алгоритму. Смотрите. Сначала в общих словах, потом напишем.
[02:17:02.500 --> 02:17:07.500]  Что я буду делать? Я возьму какую-то hash функцию.
[02:17:07.500 --> 02:17:12.500]  Распределю все элементы по n корзинам.
[02:17:12.500 --> 02:17:16.500]  То есть возьму количество корзин, строго равное количество элементов во множестве х.
[02:17:16.500 --> 02:17:20.500]  Распределю все элементы по корзинам.
[02:17:20.500 --> 02:17:26.500]  Посмотрю, какое суммарный размер внутренней х-таблицы у меня может получиться.
[02:17:26.500 --> 02:17:31.500]  То есть я просто возьму и просуммирую вот такое величину.
[02:17:31.500 --> 02:17:37.500]  Если у меня так получится, что моя hash функция слишком неравномерно распиляет мои элементы,
[02:17:37.500 --> 02:17:41.500]  то есть если у меня вдруг получится так, что suma n в квадрате больше чем 4n,
[02:17:41.500 --> 02:17:46.500]  то я скажу, что у меня такая х-таблица не устраивает. Она слишком большая.
[02:17:46.500 --> 02:17:50.500]  Я построю мою х-таблицу заново.
[02:17:50.500 --> 02:17:56.500]  То есть если у меня сумма квадратов размеров внутренних х-таблиц будет больше чем 4n,
[02:17:56.500 --> 02:18:01.500]  то я забываю про эту х-функцию и строю новую, какую-нибудь аж триг.
[02:18:01.500 --> 02:18:03.500]  То есть выбираю другую случайно.
[02:18:03.500 --> 02:18:08.500]  Снова смотрю, верно ли, что у меня суммарный размер всех х-таблиц не больше чем 4n.
[02:18:08.500 --> 02:18:12.500]  Если он не больше чем 4n, то меня все устраивает, я перехожу к следующему этапу.
[02:18:12.500 --> 02:18:17.500]  Вот на этом этапе, на первом этапе я гарантировал, что у меня размер х-таблицы будет небольшой.
[02:18:17.500 --> 02:18:21.500]  То есть общий размер х-таблицы будет небольшой. Понятно?
[02:18:21.500 --> 02:18:23.500]  Теперь, что я делаю далее?
[02:18:23.500 --> 02:18:27.500]  Далее я просто прохожусь по каждой внутренней х-таблице
[02:18:27.500 --> 02:18:33.500]  и выбираю там свою х-функцию аж ит.
[02:18:33.500 --> 02:18:38.500]  Понятное дело, я говорю, что размер внутренней х-таблицы равен n и в квадрате.
[02:18:38.500 --> 02:18:43.500]  Я смотрю количество элементов, которые попало сюда, говорю, что размер этой х-таблицы будет равен n и в квадрате.
[02:18:43.500 --> 02:18:49.500]  И начинаю процесс подбора х-функции аж ит.
[02:18:49.500 --> 02:18:53.500]  С какой целью я выбираю аж ит? Что я хочу?
[02:18:53.500 --> 02:18:57.500]  Я хочу х-таблицу без коллизий. Согласны?
[02:18:57.500 --> 02:19:03.500]  Ну вот, соответственно, я выбираю аж ит, и если у меня получилось так, что здесь коллизий нет, то я победил.
[02:19:03.500 --> 02:19:11.500]  Если оказалось так, что здесь есть коллизия, то я забываю про эту х-функцию, генерирую ее заново.
[02:19:11.500 --> 02:19:15.500]  И так далее, до тех пор, пока я не получу здесь х-таблицу без коллизий.
[02:19:15.500 --> 02:19:19.500]  Почему я уверен, что я быстро найду такую х-функцию?
[02:19:19.500 --> 02:19:25.500]  А потому что у меня была теорема, которая говорит о том, что вероятность того, что у меня не будет коллизий, больше, чем одна вторая.
[02:19:25.500 --> 02:19:30.500]  То есть с вероятостью больше, чем одна вторая, на каждом шаге я получу х-функцию, у которой нет коллизий.
[02:19:30.500 --> 02:19:34.500]  То есть в среднем примерно за два шага я уже найду нужную х-функцию.
[02:19:34.500 --> 02:19:37.500]  Ну и так далее.
[02:19:37.500 --> 02:19:43.500]  Ну давайте формально опишем то, что я сказал.
[02:19:43.500 --> 02:19:49.500]  Так, алгоритм называется алгоритм ФКС.
[02:19:49.500 --> 02:19:52.500]  ФКС.
[02:19:52.500 --> 02:19:55.500]  Первый автор Фредман, точно.
[02:19:55.500 --> 02:19:57.500]  Он вообще много чего придумал.
[02:19:57.500 --> 02:20:03.500]  Про вторых, прошу прощения, я не знаю.
[02:20:03.500 --> 02:20:06.500]  Вот так.
[02:20:06.500 --> 02:20:08.500]  Алгоритм такой.
[02:20:08.500 --> 02:20:12.500]  Первое.
[02:20:12.500 --> 02:20:33.500]  Строим внешнюю х-таблицу с m равная n.
[02:20:33.500 --> 02:20:47.500]  Естественно выбираем случайную х-функцию h.
[02:20:47.500 --> 02:20:53.500]  То есть процесс построения х-таблицы включает в себя выбор случайной х-функции и дальше распределение элементов по корзинам.
[02:20:53.500 --> 02:20:56.500]  Всего корзину у меня m равная n.
[02:20:56.500 --> 02:21:23.500]  Если сумма ni в квадрате больше чем 4n или больше либо равная, не важно, давайте больше чем 4n, то повторяем один заново.
[02:21:23.500 --> 02:21:29.500]  Если у меня получилась так, что сумма ины в квадрате, то есть сумма квадратов размерах ячеек у меня большая,
[02:21:29.500 --> 02:21:33.500]  ну большая в смысле больше чем 4n, то я говорю, что такая х-таблица меня не устраивает.
[02:21:33.500 --> 02:21:35.500]  Она слишком большая, она потребляет слишком много памяти.
[02:21:35.500 --> 02:21:39.500]  Поэтому начинаю ее строить заново.
[02:21:39.500 --> 02:21:56.500]  Здесь надо написать, что это займет примерно одну-две итерации.
[02:21:56.500 --> 02:22:01.500]  То есть примерно уже на втором шаге я найду нужную х-функцию.
[02:22:01.500 --> 02:22:05.500]  Уже на втором шаге я построю х-таблицу, которая будет маленький размер.
[02:22:05.500 --> 02:22:16.500]  Почему? По теореме 3, ну или следствию из нее.
[02:22:16.500 --> 02:22:23.500]  Следствие из теоремы 3 мне говорит, что вероятность того, что у меня будет сумма квадратов большая, меньше чем 1 вторая.
[02:22:23.500 --> 02:22:29.500]  Соответственно с вероятностью больше чем 1 вторая я найду нужную мне х-функцию.
[02:22:29.500 --> 02:22:33.500]  Все. Ну и дальше третий пункт.
[02:22:33.500 --> 02:22:58.500]  Для каждой ячейки И строим х-таблицу размера Mi равная Ni в квадрате.
[02:22:58.500 --> 02:23:07.500]  И выбираем Hi.
[02:23:07.500 --> 02:23:35.500]  Если в х-таблице И есть коллизии, то повторяем пункт 3 для нее.
[02:23:35.500 --> 02:23:48.500]  Понятно? То есть я беру внутреннюю х-таблицу и перестраиваю ее до тех пор, пока у меня не получится так, что в ней нет коллизий.
[02:23:48.500 --> 02:23:53.500]  То есть я взял какую-то х-функцию, построил х-таблицу размера Mi в квадрате, смотрю, опция, есть коллизии.
[02:23:53.500 --> 02:23:59.500]  Ну что делать? Надо строить заново. Построил заново, смотрю, опция, нет коллизий. Все, закончил работу.
[02:23:59.500 --> 02:24:06.500]  Вот количество таких перестроений у меня сколько будет? Ну тоже примерно 1-2 операции.
[02:24:06.500 --> 02:24:19.500]  Примерно 1-2 операции. Почему? По теореме 2.
[02:24:19.500 --> 02:24:29.500]  Ну теорема 2 нам что говорила? Она нам говорила то, что если я возьму х-таблицу размера N квадрат, то с вероятностью больше, чем 1-2, у меня в ней не будет коллизий.
[02:24:30.500 --> 02:24:37.500]  Вот и все. Ну вот и весь алгоритм.
[02:24:37.500 --> 02:25:04.500]  Ну давайте оценим, что можем оценить. Время строения TOT N равно UOT N средним.
[02:25:04.500 --> 02:25:13.500]  Понятно, почему UOT N средним? Потому что я примерно, то есть в среднем 1-2 раза перестраиваю внешнюю х-таблицу, а внешняя х-таблица имеет размер N.
[02:25:13.500 --> 02:25:19.500]  И дальше примерно 1-2 раза перестраиваю каждую внутреннюю х-таблицу размера Ni в квадрате.
[02:25:19.500 --> 02:25:25.500]  А сумма Ni в квадрате у меня не превосходит чем 4N. Это я гарантировал на первом шаге. Вот здесь. Понятно?
[02:25:26.500 --> 02:25:31.500]  То есть общее время на построение всей х-таблицы UOT N в среднем.
[02:25:35.500 --> 02:25:39.500]  Так, дальше. Память.
[02:25:43.500 --> 02:25:48.500]  Сколько жрет память эта х-таблица? Суммарно.
[02:25:49.500 --> 02:25:58.500]  Тоже TOT N. В среднем или в худшем случае?
[02:26:01.500 --> 02:26:12.500]  В худшем случае. Вот. Тут уже не в среднем, а в худшем случае. То есть у вас гарантированно, то есть гарантированно у вас память уйдет, ну даже тут можно сказать не более чем 5N, 4N.
[02:26:12.500 --> 02:26:18.500]  Почему? Потому что вот я строю х-таблицу до тех пор, пока не добьюсь вот этого.
[02:26:18.500 --> 02:26:23.500]  Ну не вот этого, а обратной ситуации вот этой штуки.
[02:26:27.500 --> 02:26:30.500]  Сумма Ni в квадрате меньше равно чем 4N.
[02:26:30.500 --> 02:26:35.500]  Вот пока я этого не добьюсь, я буду повторять процесс построения снова и снова.
[02:26:35.500 --> 02:26:39.500]  И вот только когда у меня получилось это гарантировать, я заканчиваю построение.
[02:26:39.500 --> 02:26:45.500]  Ну соответственно у меня гарантированно после построения х-таблица имеет линейный размер.
[02:26:48.500 --> 02:26:50.500]  Ну и поиск.
[02:26:54.500 --> 02:26:56.500]  Время поиска.
[02:26:58.500 --> 02:27:01.500]  Тета от единицы в худшем случае.
[02:27:01.500 --> 02:27:05.500]  Понятно почему поиск за единицу теперь. А потому что у меня коллизий нет.
[02:27:05.500 --> 02:27:08.500]  Как выглядит поиск? Ну давайте пропишем.
[02:27:09.500 --> 02:27:11.500]  Find at x.
[02:27:11.500 --> 02:27:14.500]  Значит я сначала ищу нужную мне х-таблицу.
[02:27:18.500 --> 02:27:28.500]  А потом, собственно, возвращаю x равно равно a.
[02:27:31.500 --> 02:27:37.500]  Как мы обозначали b, от hi от x.
[02:27:40.500 --> 02:27:44.500]  Ну вот эта внешняя х-таблица у нас обозначалась буквой b.
[02:27:44.500 --> 02:27:46.500]  b большая.
[02:27:49.500 --> 02:27:51.500]  Понятно, что здесь написано?
[02:27:51.500 --> 02:27:54.500]  Я сначала смотрю в какой корзине у меня лежит объект.
[02:27:54.500 --> 02:27:59.500]  А дальше, так как сама корзина внутренняя b, у меня сама по себе является,
[02:27:59.500 --> 02:28:01.500]  так как сама корзина у меня является х-таблицей,
[02:28:01.500 --> 02:28:04.500]  я внутри этой х-таблицы иду по индексу hi от x.
[02:28:04.500 --> 02:28:09.500]  И смотрю верно лишь, что у меня x совпадает с тем, что там лежит.
[02:28:12.500 --> 02:28:16.500]  Так как у меня х-таблица без коллизий, то, собственно, у меня ответ всегда верный.
[02:28:16.500 --> 02:28:22.500]  Ну и плюс весь find занимает всего лишь одно обращение к функции h от x,
[02:28:22.500 --> 02:28:25.500]  одно обращение к функции cache от x, ну и просто обращение по индексу.
[02:28:25.500 --> 02:28:27.500]  То есть все это занимается за единицу.
[02:28:27.500 --> 02:28:31.500]  То есть никакого линейного поиска по цепочкам и так далее у нас нет.
[02:28:31.500 --> 02:28:33.500]  Понятно?
[02:28:34.500 --> 02:28:36.500]  Ну вот.
[02:28:41.500 --> 02:28:43.500]  Спросить что-нибудь?
[02:28:49.500 --> 02:28:51.500]  По алгоритму есть вопросы?
[02:28:53.500 --> 02:28:56.500]  Ну тогда все, точно все. Спасибо.
