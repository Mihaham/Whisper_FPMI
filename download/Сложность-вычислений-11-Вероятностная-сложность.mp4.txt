[00:00.000 --> 00:11.360]  В прошлый раз мы изучали схемы. У нас осталась небольшая тема про НСИ и иерархию и всякие
[00:11.360 --> 00:15.800]  быстрые сумматры. Я думаю, что ее можно пропустить, либо она будет на семинарах,
[00:15.800 --> 00:24.760]  ну или просто пропустим. А вот подробнее поговорим про вероятные вычисления. Сегодня и через неделю
[00:24.760 --> 00:31.240]  поговорим, с одной стороны, про то, что можно вычислить при помощи случайных битов,
[00:31.240 --> 00:41.640]  но и, с другой стороны, можно от этого, наоборот, избавиться. То есть можно заменить рандомизированные
[00:41.640 --> 00:46.320]  алгоритмы на детерминированные. Есть одна очень известная история про то,
[00:46.320 --> 00:52.520]  как это было сделано. Это вопрос о проверке простоты. Есть известная задача.
[00:52.520 --> 01:01.440]  Праймс. То есть нужно по числу понять, что оно простое.
[01:01.440 --> 01:13.600]  Соответственно, если тут расписывать подробно, то на вход дана двоечный запись числа натурального,
[01:13.600 --> 01:23.200]  то нужно понять, что оно простое. При этом, если мы говорим о полинамиальном времени,
[01:23.200 --> 01:30.720]  то стандартный школьный алгоритм, перебирать все делители до корня и пытаться поделить,
[01:30.720 --> 01:35.800]  он не будет полинамиальным, потому что мы же смотрим на длину записи, то есть на число знаков.
[01:35.800 --> 01:42.920]  А число знаков – это алгоритм от самого числа. То есть полинамиальный алгоритм для этой задачи
[01:42.920 --> 01:50.320]  – это на самом деле полилогарифмический от самого числа. Ну и, конечно, если мы перебираем
[01:50.320 --> 02:00.000]  все числа до корня, то никаким полилогарифом тут не пахнет. Это долгое время было интересной
[02:00.000 --> 02:11.200]  задачей. Ну и сейчас остается интересной задачей. На самом деле, задача решена. Есть алгоритм
[02:11.200 --> 02:18.400]  Агревала Кояло-Соксене 2004 года, который как раз решает за полилогарифмическое время от П,
[02:18.400 --> 02:26.080]  но там степень довольно высокая. Там степень примерно 6 плюс Эпсилон. Есть там всякие вариации,
[02:26.080 --> 02:30.640]  если там какая-то гипотеза верна, там будет ни шестая, четвертая степень и так далее.
[02:30.640 --> 02:38.200]  Вот. Не знаю, вам, вроде, Андрей Михайлович не рассказывал, да, НОКОТЧа? Не собирается. Не,
[02:38.200 --> 02:43.400]  НОКОТЧа закончилась уже. Не, был какой-то год, когда этот алгоритм входил прямо в основную
[02:43.400 --> 02:53.200]  программу, да, и все его учили и сдавали. Ну, кто на 5 хотел сдать? Ну, не на хор 5, а на отлично.
[02:53.200 --> 03:04.800]  Хорошо, мы его тоже не будем изучать, но вот о чем Андрей Михайлович тогда не рассказывал,
[03:04.800 --> 03:10.680]  это то, что на самом деле этот алгоритм был получен в результате дерандомизации. То есть
[03:10.680 --> 03:18.280]  сначала Агревал придумал некоторый вероятностный алгоритм, а потом уже вместе с Кояло-Соксеной они
[03:18.280 --> 03:24.280]  придумали, как его заменить на детерминированный, который по сути делает то же самое. Вот. Ну и вот это
[03:24.280 --> 03:31.280]  на самом деле один вообще из базовых вопросов в сложке вычислений верно лишь, что все можно
[03:31.280 --> 03:39.880]  дерандомизировать. То есть что можно заменить вероятностные вычисления на детерминированные.
[03:39.880 --> 03:52.640]  Причем это вообще важная задача для криптографии. Как вы, наверное, понимаете, что многие
[03:52.640 --> 03:59.520]  криптографические протоколы основаны на том, что вам нужны большие простые числа, потом вы их там
[03:59.520 --> 04:06.840]  перемножаете, и это получается ключ и так далее. Есть очень много разных протоколов,
[04:06.840 --> 04:11.480]  которых нужны большие простые числа. Соответственно, если у вас есть большое и простое число, нужно
[04:11.480 --> 04:17.680]  проверить, что оно простое. Ну и соответственно, если оно большое, то тогда простые алгоритмы не будут
[04:17.680 --> 04:27.000]  работать. Будут слишком долго работать. И поэтому нужны какие-то хитрые алгоритмы. На самом деле и
[04:27.000 --> 04:32.680]  даже АКС-алгоритм на практике все равно слишком долгий, потому что там шестая степень от числа
[04:32.680 --> 04:40.920]  знаков. А вероятностные тесты работают за вторую степень от числа знаков и уже дают приемлемую
[04:40.920 --> 04:50.200]  точность. Начну я с того, что мы поговорим немножко о конкретных вероятностных алгоритмах. Или вас
[04:50.200 --> 05:02.720]  это учили где-нибудь? Ну скажем, Миллера Рабина или Славея Штрасна, знаете, что такое? Сейчас,
[05:02.720 --> 05:32.480]  вы все знаете откуда-то еще. Ну какие-то другие были алгоритмы,
[05:32.480 --> 05:38.760]  да? Не, вот Монте-Карло это вообще правильные слова. Можно сначала вот это, кстати, обсудить. Но
[05:38.760 --> 05:43.400]  Монте-Карло и Лас-Вегас, значит, Монте-Карло есть в узком смысле некоторые конкретные алгоритмы,
[05:43.400 --> 05:48.200]  да, и в широком смысле некоторые классы алгоритмов. Вот. А Лас-Вегас, насколько я знаю,
[05:48.200 --> 05:56.000]  это только класс. Или у вас тоже был класс. Да, ну давайте сначала тогда это обсудим быстренько.
[05:56.000 --> 06:04.880]  Про Монте-Карло это еще в середине XX века придумали, как быстро считать многомерные интегралы.
[06:04.880 --> 06:17.160]  Если у вас какая-нибудь плоская картинка, да, напишу, метод Монте-Карло. Так, ну это напоминание,
[06:17.160 --> 06:23.120]  как я понимаю, то есть можно быстро вспоминать. Значит, если у вас плоская картинка, да, то есть
[06:23.120 --> 06:30.480]  вообще такой метод в школе проходит. Нужно взять палетку, вот так вот разбить на ячейке,
[06:30.480 --> 06:40.200]  и посчитать, сколько у вас клеточек целиком попало внутрь, сколько частично, значит,
[06:40.200 --> 06:45.840]  взять количество тех, которые целиком попали, плюс половину тех, которые частично, это будет
[06:45.840 --> 06:55.240]  примерно площадь. Вот, и это довольно точный метод на плоскости. А если у вас будет
[06:55.240 --> 07:01.200]  десятимерное пространство, то будет проблема. Здесь как бы нет проблемы, скажем, на 100 частей
[07:01.200 --> 07:05.760]  разбить здесь, на 100 частей разбить здесь и 10 тысяч клеточек проанализировать. Но если у вас
[07:05.760 --> 07:12.640]  десятимерное пространство, то будет не 10 тысяч, а 100 в десятый, то есть 10 в двадцатый. Это уже
[07:12.640 --> 07:20.640]  очень много, и все эти клеточки просто так не проанализировать. Соответственно, что придумали
[07:20.640 --> 07:29.760]  Метрополис и Улам? Что придумали Метрополис и Улам? Они придумали, что когда у вас много
[07:29.760 --> 07:37.480]  измерений, то не нужно вообще делать некую сетку, а нужно просто случайно кидать точки. Кидаем
[07:37.480 --> 07:46.600]  точку. В общем, как-то вот случайно накидываем точки в достаточно большом количестве. Ну,
[07:46.600 --> 07:53.440]  в общем, что-то такое там получается. Значит, накидали точки в большом количестве, и дальше просто
[07:53.440 --> 08:00.080]  считаем, какая доля попала внутрь фигуры. И тут уже от размеров не зависит, это зависит только того,
[08:00.080 --> 08:07.040]  умеем ли мы понимать, лежит ли точка внутри фигуры. Просто по всяким вероятствам-тиоремам,
[08:07.040 --> 08:15.200]  независимо от размерности, одно и то же число точек нужно взять, чтобы разброс был какой нужно.
[08:15.200 --> 08:23.400]  Вот, хорошо. Значит, таким образом, что это в узком смысле метод Монте-Карло под счет объема. В широком
[08:23.400 --> 08:30.360]  смысле, можно сказать следующее, здесь гарантированно время работы, но не гарантирована точность,
[08:30.360 --> 08:47.880]  то есть, возможно, ошибка. Значит, гарантированно время, но, возможно, ошибка. Вот, Лас-Вегас на
[08:47.880 --> 08:56.520]  оборот. Лас-Вегас точно правильно, но не гарантированно время, может быть, долго, только
[08:56.520 --> 09:21.560]  в среднем гарантированное время. Значит, точно верно, но, возможно, задержка. Ну, простой пример
[09:21.560 --> 09:29.800]  алгоритма такого духа. Это как при помощи обычной монетки сгенерировать случайную величину 1 3 2 3.
[09:29.800 --> 09:35.080]  Да, значит, понятно, что если вы какое-то фиксируемое число раз кидаете монетку, то у вас
[09:35.080 --> 09:42.280]  точно вероятности будут со становящим степень двойки, а 1 3 не является такой дробью. Но можно
[09:42.280 --> 09:51.040]  делать следующее, кидать монетку два раза, и, например, если выпало два орла, то говорить да,
[09:51.040 --> 10:00.320]  если выпало разное, орел-решка в любом порядке, то говорить нет, а если выпало две решки, то еще два
[10:00.320 --> 10:09.680]  раза бросать. Тогда получается, что одна четверть это ответ да, две четверти ответ нет, и еще одна
[10:09.680 --> 10:16.320]  четверть повтор. Ну и там ряды просуммируются, будут как раз одна треть и две трети для ответов да и нет.
[10:16.320 --> 10:27.840]  Но, конечно, никакого гарантированного времени нет. Любое ограничение на время сразу сваливает все
[10:27.840 --> 10:37.360]  в большинственные числа. Но среднее время будет не очень большое. Среднее число бросков будет
[10:37.360 --> 10:48.640]  вообще 4 третьих, видимо, да. Вот, то есть даже меньше двух. Ой, в смысле 4 третьих умножить на два.
[10:48.640 --> 11:01.140]  Средний число пар бросков 4 третьих. Да, то есть это получается 8 третьих, да, если одиночные
[11:01.140 --> 11:13.060]  броски считать, но меньше трех. Так, хорошо, еще бывает алгоритм Атлантик-Сити, в которых и ошибка
[11:13.060 --> 11:24.660]  возможна, и задержка возможна, но как бы ничего лучше не получается. Не, это правда, да, что можно
[11:24.660 --> 11:40.220]  превращать одно в другое. Ну сейчас, метод Монте-Карло, как бы если ответ это число, то можно
[11:40.220 --> 11:49.540]  увеличивать время и уменьшать ошибку. Так, ну хорошо. Ладно, теперь давайте про простые числа поговорим.
[11:49.540 --> 12:00.660]  Значит, начнем совсем простой вещи, который называется тест Ферма. Так, что нам говорит
[12:00.660 --> 12:07.820]  малотерема Ферма? Что любой остаток в степени p сравним с единицей по моделю p, ну, кроме нуля.
[12:07.820 --> 12:21.540]  Так, это что? Это малотерема Ферма. Значит, малотерема Ферма, что если наибольший общудитель от a и p
[12:21.540 --> 12:31.740]  равен единице, то тогда в степени p сравним с единицей. Так, что там p-1, да? А, давайте так,
[12:31.740 --> 12:46.380]  а в степени p сравним с a по моделю p, тогда это вообще всегда верно. Так, сейчас, ну ладно, пусть так
[12:46.380 --> 13:03.420]  останется. Ну и ладно, давайте я напишу. Все-таки с минус 1. Потому что тест Ферма устроен следующим образом.
[13:03.420 --> 13:18.980]  Тест Ферма устроен так, что мы берем случайное a, ну, например, от единицы до p-1. Тут нам как
[13:18.980 --> 13:27.060]  раз пригодится вот это бросание монеток с повторами. На самом деле, да, совсем случайно у нас не
[13:27.060 --> 13:39.460]  получится, если только p-1 не степень двойки. Но если даже и не степень двойки, то там какие-то
[13:39.460 --> 13:50.500]  небольшие отличия от равномерного распределения нам ничего не испортит. Что? Да нет, ну зачем два раза?
[13:50.500 --> 13:59.780]  У нас пусть будет отличие от... Ну мы что можем сделать? Мы можем сделать, чтобы отличие от честной 1
[13:59.780 --> 14:15.500]  длить на p-1 было каким-то экспоненциально маленьким. Ну да, то есть если p-1, если степень двойки,
[14:15.500 --> 14:25.020]  то нам нужно логарифм p монеток кинуть. Если не степень двойки, нужно следующую степень двойки
[14:25.020 --> 14:31.020]  делать как вот это самое, с одной третью. Соответственно, можно еще порядка того же
[14:31.020 --> 14:39.620]  логарифма это сделать. И вероятность того, что каждый раз будет ошибка, будет как раз порядка 1
[14:39.620 --> 14:48.380]  длить на p, что будет экспоненциально маленьким от логарифма, то есть от числа знаков. Короче говоря,
[14:48.380 --> 14:52.540]  это все не очень важно. Давайте считаем, что мы умеем выбирать прямо случайное число с таким
[14:52.540 --> 15:03.020]  распределением, как надо. Так, выбираем случайно от 1 до p-1. После этого, во-первых, если так
[15:03.020 --> 15:11.500]  получилось, что наибольший общеделитель от a и p не равен единице, то тогда число точно непростого.
[15:11.500 --> 15:35.220]  Ответ нет. Второе. Иначе проверяем, что a в степени p-1 сравнивается с единицей.
[15:35.220 --> 15:52.660]  И соответственно, как есть, так и отвечаем. Если да, то мы отмечаем, что, скажем так, возможно,
[15:52.660 --> 16:14.660]  простое. Вот. А если нет, тогда уж точно составное. Точно составное. Так.
[16:14.660 --> 16:24.580]  Тут, кстати, еще нужно упомянуть о быстром возведении степени, чтобы это был полиномиальный алгоритм.
[16:24.580 --> 16:31.260]  Это вы знаете, наверное. Посчитать там квадрат, 4 степени, 8, 16 и так далее. Потом сложить,
[16:31.260 --> 16:39.140]  какие нужно, чтобы получилось a в степени p-1. А тут алгоритм Евклида, так что это полиномиальный
[16:39.140 --> 16:46.580]  в целом алгоритм получается. Вот. Тогда что же получается? В чем его плюс, в чем его минусы?
[16:46.580 --> 17:05.740]  Слышишь, что первый не обязательно проверять, да? Ну, вообще, наверное, да.
[17:05.740 --> 17:14.540]  Да, то есть этот нотас будет оставаться деятелем. Ну, может, конечно. На самом деле, просто
[17:14.540 --> 17:24.980]  алгоритм Евклида, по идее, попроще будет. Ну, неважно. Правильно. Можно и не проверять.
[17:24.980 --> 17:34.460]  Вот. Проблема тут в другом. Проблема в том, что некоторые составные числа проходят этот тест
[17:34.460 --> 17:45.660]  Renste-1. Знаете ли вы такие числа? Кармаекла, да. Вот. Их, конечно, мало. Да, их, конечно, мало.
[17:45.660 --> 17:51.980]  Так, но вроде, насколько я помню, доказали, что их бесконечно много. По-моему, это какой-то недавний
[17:51.980 --> 18:01.020]  результат, но доказали, что их бесконечно много. Что-то, я помню, мы это выясняли. Какой-то типа,
[18:01.020 --> 18:13.100]  десятилетней давности или что-то такое. Нет, критерий-то простой. Критерий, что p-1 делится
[18:13.100 --> 18:19.940]  на функциялер от p. Критерий простой. Вопрос верный, что он выполнен для бесконечного числа чисел.
[18:19.940 --> 18:38.180]  Вот. Проблема в том, что числа Кармаекла составные, но проходят тест всегда.
[18:38.180 --> 18:53.180]  С точки зрения теории, но не практики, можно было сказать следующее, что если бы оказалось,
[18:53.180 --> 18:58.020]  что их конечное число, то можно было бы это конечное число исключения прямо прописать в
[18:58.020 --> 19:06.860]  текст алгоритма, и тогда этот тест работал бы. Если у нас число входит в конечный список чисел
[19:06.860 --> 19:15.180]  Кармаекла, то тогда оно составное, а иначе мы делаем вот это. И там есть еще теорема, что если
[19:15.180 --> 19:23.180]  p не простой и не число Кармаекла, то тогда вот здесь ответ да будет с вероятностью максимум половина
[19:23.180 --> 19:35.020]  для случайного а. Половина. А тогда, смотрите, половина это уже хорошо, потому что можно взять
[19:35.020 --> 19:43.140]  не одно случайное а, а десять случайных а. И тогда, чтобы все десять раз сказали да, а на самом деле не
[19:43.140 --> 19:48.540]  всегда было да, нужно, чтобы мы все десять раз попали в эту нужную половину, а у этого вероятности уже
[19:48.540 --> 19:55.660]  будет одна тысяча двадцать четвертая. Ну, если мало, возьмите двадцать раз, будет одна миллионная с лишним.
[19:55.660 --> 20:05.580]  Вот, это называется амплификация, это позволяет уменьшать ошибку. Вот, ну хорошо, значит, но даже в
[20:05.580 --> 20:13.100]  теории оказалось, что чисел Кармаекла бесконечно много, вот, поэтому этот тест он хоть и для
[20:13.100 --> 20:18.380]  малого, да, для редких входов дает ошибку, но тем не менее для этих редких ходов он дает
[20:18.380 --> 20:32.860]  всегда ошибку с рентстью один. И за пункт один не всегда. Да, хорошо, за пункт один не всегда, но все
[20:32.860 --> 20:45.900]  равно там мало будет делителей. Вот, а мы хотим не это, мы хотим, чтобы для каждого входа был ответ
[20:45.900 --> 20:55.260]  правильный, но, возможно, была ошибка за счет неудачного выбора случайных битов. Вот, хорошо,
[20:55.260 --> 21:08.700]  ну и, значит, на этом основание Миллер и Рабин придумали, но в некотором смысле, обобщение теста
[21:08.700 --> 21:15.980]  ферма. Вот, и вот это уже прямо на практике используется и до сих пор, да, то есть если нужно
[21:15.980 --> 21:22.940]  проверить на простоту и допустимо ошибка, да, то вот можно тест Миллера Рабина использовать. Так,
[21:22.940 --> 21:31.460]  он действительно довольно простой. Значит, смотрите, вот пока пусть п простое, значит,
[21:31.460 --> 21:41.820]  п простое, тогда мало-то время ферма выполнена, да, и, соответственно, а в степени p-1 равняется единице.
[21:41.820 --> 21:58.540]  Да, ну правильно, сейчас, мы это уже обсудили, да, что есть небольшой шанс, что мы прямо попадем
[21:58.540 --> 22:05.620]  в делитель, выбирая а, но это очень редко бывает. Ну числа кармайкла, там обычно не маленький делитель.
[22:05.620 --> 22:18.740]  Так, хорошо, ладно, я буду писать сравнимо, но не буду писать модуль. Значит, также, конечно,
[22:18.740 --> 22:29.900]  в случае p-2 мы как-нибудь разберем, соответственно, p будет нечетная. Тогда в этом случае получается,
[22:29.900 --> 22:43.900]  что а в степени p-1 пополам должно быть сравнимо с плюс-минус единицей. Вот, а если а в степени
[22:43.900 --> 22:50.980]  p-1 пополам сравнимо с плюс-минус единицей, и при этом еще p-1 делится не только на 2, но и на 4,
[22:50.980 --> 22:59.460]  значит, то можно, соответственно, еще и дальше сказать, что а в степени p-1 пополам на 4 тоже
[22:59.460 --> 23:09.180]  сравнимо с плюс-минус единицей. Вот, ну и так далее. Вот, и так далее, да, то есть рассматривается ряд
[23:09.180 --> 23:20.860]  вот a в степени p-1, p-1 пополам, p-1 на 4 и так далее, пока будет делиться. Да, то есть вот это уже как, в чем тенд заключается.
[23:20.860 --> 23:34.220]  Ну, можно и так сказать.
[23:34.220 --> 23:46.300]  Вот, значит, рассмотрим а в степени p-1, а в степени p-1 пополам, а в степени p-1 на 4 и так далее,
[23:46.300 --> 23:55.420]  значит, все поможет для p. Значит, соответственно, если p простое, то этот ряд,
[23:55.420 --> 24:10.020]  то в этом ряду либо только единица, либо сначала единица, потом минус единица. Значит, в этом ряду
[24:10.020 --> 24:31.220]  либо все единицы, значит, либо префикс. Это сначала обязательно единица, значит,
[24:31.220 --> 24:37.660]  потом еще сколько-то единиц, и потом минус единица. Здесь хотя бы одна единица.
[24:37.660 --> 24:54.660]  Вот, но для простых это понятно, потому что по простому модулю есть только два корня из каждого
[24:54.660 --> 25:03.060]  квадратичного вычета, и из единицы только единица и минус единица. Вот, но вот Миллер и Рабин
[25:03.060 --> 25:14.700]  доказали следующее. Значит, теорема, что если p не простое, значит, если p составное,
[25:14.700 --> 25:37.700]  то вот это верно с вероятностью не больше одной четверти. Ну, можно сказать так, да.
[25:37.700 --> 25:45.700]  Пока либо не будет минус единицы, а если вместо, если были единицы, а потом не минус единицы,
[25:45.700 --> 26:00.500]  а что-нибудь еще, то значит, точно не простое. Вот, ну тоже получается так, что если число
[26:00.500 --> 26:06.100]  простое, то это точно верно, и соответственно, если это условие нарушено, то число точно составное.
[26:06.100 --> 26:15.500]  Ну получается, что так, да.
[26:30.500 --> 26:49.100]  Ой, ну такие детали уже зависит от точной модели. Вот это и называется точная модель. Ну, в принципе,
[26:49.100 --> 27:11.300]  да. Ну, типа того, да. Ну, хорошо, доказывать я это не буду. Теория чисел какая-то хитрая.
[27:11.300 --> 27:18.500]  Но дальше идея такая, что опять же, вот эта вот одну четверть, это вообще еще лучше, чем одна вторая,
[27:18.500 --> 27:25.300]  потому что тут надо в два раза меньше повторять, чтобы такую же маленькую вероятность ошибки оставить.
[27:25.300 --> 27:34.900]  Вот так, ну хорошо, значит, Славея Штрассена, значит, я думаю, можно пропустить.
[27:34.900 --> 27:49.900]  Славея Штрассена основана на квадратичных вычетах. Так, а вот квадратичный закон взаимности у вас был?
[27:49.900 --> 27:59.900]  Или не у всех, да. Хорошо, ну ладно, значит.
[27:59.900 --> 28:16.500]  Ага, так у вас второй квадратич был по выбору, да, и там не все брали, да. А вообще не было, да.
[28:16.500 --> 28:40.300]  Понятно. Вот. А что такое символ Якови, знаете? Символ Якови, знаете, что такое? Вот есть символ
[28:40.300 --> 28:49.100]  Лежандра, есть символ Якови, который тоже самое, но по непростому модулю. Так, не, ну ладно, тогда это пропустим.
[28:49.100 --> 29:01.100]  Это слишком долго рассказывать. Вот, значит, я лучше про другое расскажу, значит, для чего окотуче не нужно.
[29:01.900 --> 29:11.900]  Есть такая очень важная задача, называется polynomial identity testing, значит, PIT, задача о равенстве многочленов по-русски.
[29:11.900 --> 29:29.900]  Задача о равенстве многочленов. Значит, ну, как бы, на первый взгляд, звучит очень просто, да, есть два многочлена,
[29:29.900 --> 29:40.700]  надо проверить это один и тот же многочлен или разный. Вот. Ну, дальше начинается сразу много вопросов.
[29:40.700 --> 29:51.700]  Значит, во-первых, что мы вообще понимаем под многочленом? Потому что у многочленов есть две принципиально разные понимания.
[29:52.500 --> 30:00.500]  Это формальная запись, там сумма с коэффициентами, и это функция на каком-то множестве, который эту запись задает.
[30:00.500 --> 30:06.500]  Если это множество, это конечное поле, то это получается не одно и то же. Вот у нас были многочлены Джигалкина,
[30:06.500 --> 30:13.500]  которые основаны на том, что x² и x это разные записи, но один тоже многочлен, то есть одна и та же функция.
[30:13.500 --> 30:19.500]  Разные многочлены как записи, но один тоже многочлен как функция.
[30:20.300 --> 30:25.300]  Значит, на этот вопрос мы рассматриваем многочлены как записи.
[30:25.300 --> 30:33.300]  Ну, дальше вопрос, а как именно мы их записываем? Потому что ясно, что если у нас просто сумма с коэффициентами,
[30:33.300 --> 30:41.300]  то там вопрос только в порядке слагаемых и порядке множителей, это мы как-нибудь проверим, что можно так сортировать.
[30:41.300 --> 30:46.300]  Ну, можно как-то сортировать оба многочлена, единообразные, проверить, что получилось одно и то же.
[30:47.100 --> 30:56.100]  Тут тоже нет проблемы. Но проблема начинается, если эти многочлены заданы какими-то выражениями со скобками.
[30:56.100 --> 31:05.100]  Конечно, мы все умеем раскрывать скобки, но если скобок много, их все раскрыть, то может получиться очень длинное выражение.
[31:05.100 --> 31:12.100]  Если у вас есть ян скобок и в каждом два слагаемых вы все раскрыли, то будет два степени ян слагаемых,
[31:12.900 --> 31:19.900]  и потом еще приводить подобное. Ну, два степени ян, да, и каждый из ян скобок, либо первый слагаемый, либо второй.
[31:31.900 --> 31:40.900]  Классическая постановка даже еще более хитрая. Не только формулы разрешаются, но и схемы.
[31:41.700 --> 31:46.700]  Вот рассматривается понятие алгебраическая схема.
[31:50.700 --> 32:00.700]  Алгебраическая схема – это аналог логической, но там будут сложения и умножения в качестве базовых операций.
[32:01.500 --> 32:16.500]  Аналог логической с сложением и умножением в качестве базовых операций.
[32:17.300 --> 32:24.300]  Тоже правильный вопрос.
[32:24.300 --> 32:38.300]  Переменных у нас будет много, то есть тут, смотрите, я как бы формулирую как можно более общую задачу, которую можно решать вероятностно.
[32:39.100 --> 32:48.100]  Даже с одной переменной могут быть некоторые трудности за счет итерированного умножения.
[32:48.100 --> 32:58.100]  То есть мы можем взять х и потом его как бы взять и умножить сам на себя,
[32:58.100 --> 33:06.100]  а потом результат еще раз умножить сам на себя, а потом еще раз умножить сам на себя и так далее.
[33:06.900 --> 33:15.900]  Что это я рисую? Я имею в виду, что результат умножения поддаю и как первый множественный, и как второй множественный на следующий элемент умножения.
[33:15.900 --> 33:20.900]  Да, тогда, соответственно, в итоге тут получится х в степени 2 в степени n.
[33:20.900 --> 33:27.900]  То есть даже степень получается экспедиенциальной, даже для одной переменной может быть какая-то слишком длинная запись.
[33:28.700 --> 33:32.700]  Вот, и это такая прямолинейная схема.
[33:32.700 --> 33:40.700]  Если как-то витвиться будет и так далее, то может там и слагаемых будет тоже экспедиенциально много, а не только степень.
[33:43.700 --> 33:51.700]  Ну, собственно, будет, если перенажать х плюс 1 на х квадрате, плюс 1 на х4, плюс 1 на х8, плюс 1 и так далее, все раскрыть, то там будут все степени.
[33:52.500 --> 33:59.500]  Вот, ну хорошо, соответственно, получается, что задача такая.
[34:02.500 --> 34:14.500]  Значит, даны две вот таких алгебрических схемы, схемы по IQ.
[34:15.300 --> 34:34.300]  Значит, и нужно проверить, что они задают один и тот же многочлен от многих переменных.
[34:39.300 --> 34:41.300]  Один и тот же многочлен.
[34:45.300 --> 34:51.300]  Вот, вот это называется PIT.
[34:54.300 --> 35:00.300]  Значит, как ее решать за полинальное время никто не знает.
[35:02.300 --> 35:04.300]  Но он знает, как решать вероятностно.
[35:07.300 --> 35:09.300]  Значит, вероятность алгорита такой.
[35:10.100 --> 35:18.100]  Но нужно взять какую-нибудь модуль, большой, но простой, и взять два случайных остатка по этому модулю,
[35:19.100 --> 35:23.100]  взять один случайный остаток по этому модулю и вычислить на нем его многочлену.
[35:24.100 --> 35:30.100]  Конечно, не раскрывая скобки, а идя просто сверху вниз и вычисляя значение всех этих штук.
[35:31.100 --> 35:34.100]  Если получилось разное, то мы решим точно разное.
[35:35.100 --> 35:38.100]  Если получилось одно и то же, то мы решим, скорее всего, один и тот же.
[35:40.100 --> 35:45.100]  Тут, значит, вероятностный тест.
[35:48.100 --> 35:56.100]  Значит, вычислить PQ
[36:00.100 --> 36:02.100]  по модулю
[36:02.900 --> 36:10.900]  по модулю P на случайном входе.
[36:20.900 --> 36:22.900]  Значит, это будет быстро, если P не слишком большое.
[36:23.900 --> 36:28.900]  Если P имеет размер порядка экспонента от вообще размера входа.
[36:29.700 --> 36:33.700]  Значит, размер входа – это число элементов в этих схемах.
[36:40.700 --> 36:42.700]  Вот это правильное замечание.
[36:48.700 --> 36:51.700]  То есть возникает вопрос, откуда брать вот это вот P.
[36:52.700 --> 36:54.700]  Откуда брать P.
[36:55.500 --> 36:57.500]  Вообще проблема еще может быть,
[36:58.500 --> 37:02.500]  если вдруг получилось, что именно по этому модулю P многочлен равен нулю, а вообще не равен.
[37:03.500 --> 37:08.500]  Ну, точнее, в смысле, эти многочлены два совпадают по модулю P, а вообще не совпадают.
[37:09.500 --> 37:12.500]  Если так вдруг получилось, то будет проблема.
[37:16.500 --> 37:19.500]  Ну, их конечно конечное количество, но важно еще не только, что оно конечное,
[37:20.500 --> 37:22.500]  но еще не слишком большое.
[37:23.300 --> 37:27.300]  То есть, на самом деле, вот это вот P тоже надо брать случайным, но в некотором диапазоне.
[37:33.300 --> 37:39.300]  Значит, случайный в некотором диапазоне.
[37:41.300 --> 37:43.300]  Значит, а в каком?
[37:44.300 --> 37:48.300]  Ну, все-таки, на чем основана работа этого теста?
[37:49.100 --> 37:54.100]  В принципе, что у многочлена корней не больше, чем его степени.
[37:55.100 --> 38:01.100]  И это, на самом деле, верно и для нескольких переменных.
[38:02.100 --> 38:06.100]  Значит, там эта более хитрая штука называется Лемма-Шварца-Зиппеля.
[38:07.100 --> 38:09.100]  Ну, не знаю, сейчас можно обсудить, наверное.
[38:10.100 --> 38:12.100]  И это вам не говорили, да, таких слов?
[38:13.100 --> 38:15.100]  Лемма-Шварца-Зиппеля тоже не говорили.
[38:15.900 --> 38:17.900]  Там что-то похожее было.
[38:20.900 --> 38:22.900]  Там тоже были какие-то корни.
[38:23.900 --> 38:26.900]  Ну, там были тоже две корни у многочлены многих переменных.
[38:27.900 --> 38:29.900]  Тоже помню.
[38:36.900 --> 38:38.900]  Нет, это вроде в первом семестре.
[38:39.900 --> 38:41.900]  Там, значит, была без доказательств, я и сам не помню.
[38:42.700 --> 38:44.700]  А...
[38:59.700 --> 39:02.700]  Так, ну ладно, сейчас, может, обсудим.
[39:04.700 --> 39:08.700]  В общем, глобально картина такая,
[39:09.500 --> 39:13.500]  что мы хотим взять P достаточно большим,
[39:14.500 --> 39:17.500]  чтобы все-таки по этому модулю,
[39:18.500 --> 39:20.500]  если по этому модулю многочлены тоже оказались разными,
[39:21.500 --> 39:23.500]  чтобы у них было мало общих корней.
[39:24.500 --> 39:26.500]  Ну, не общих корней, в смысле.
[39:27.500 --> 39:29.500]  Точи, где они равны, то есть корни их разности.
[39:32.500 --> 39:34.500]  Поэтому P должно быть достаточно большим.
[39:35.500 --> 39:37.500]  С другой стороны, P должно быть достаточно маленьким,
[39:37.500 --> 39:39.500]  чтобы по этому модулю все-таки все можно было вычислять.
[39:41.500 --> 39:45.500]  И с третьей стороны, нужно, чтобы P не было делителем
[39:46.500 --> 39:48.500]  всех коэффициентов разности этих многочленов.
[39:52.500 --> 39:55.500]  Но оказывается, что все-таки все это можно одновременно выполнить.
[39:56.500 --> 39:58.500]  Получается, что чтобы...
[39:59.500 --> 40:03.500]  Ну, идея такая, что чтобы можно было вычислять по этому модулю,
[40:03.500 --> 40:05.500]  нужно, чтобы P было экспоненциальным,
[40:06.500 --> 40:08.500]  но более-менее любым экспоненциальным.
[40:11.500 --> 40:13.500]  А чтобы P...
[40:14.500 --> 40:16.500]  Сейчас, чтобы было не слишком много корней,
[40:17.500 --> 40:20.500]  P должно быть больше некоторых конкретных экспонентов,
[40:21.500 --> 40:23.500]  которые возникают из размера этих схем.
[40:24.500 --> 40:25.500]  И там получается зазор.
[40:26.500 --> 40:28.500]  То есть зазор между той экспонентой,
[40:29.500 --> 40:30.500]  которая уже дает мало корней,
[40:30.500 --> 40:32.500]  и той экспонентой, которая еще позволяет все быстро вычислить.
[40:33.500 --> 40:37.500]  И более того, можно показать, что в этом зазоре достаточно много простых чисел,
[40:38.500 --> 40:40.500]  чтобы, если мы берем случайное простое число в этом зазоре,
[40:41.500 --> 40:43.500]  то мы попадаем в то, по которому...
[40:44.500 --> 40:46.500]  Скорее всего, попадаем в то, по которому многочлены,
[40:47.500 --> 40:49.500]  если были разные изначально, то останутся разными.
[40:50.500 --> 40:51.500]  И по этому модулю тоже.
[40:52.500 --> 40:56.500]  Это следует из того, что простых чисел довольно много,
[40:56.500 --> 40:59.500]  если эта разница на них на всех делится,
[41:00.500 --> 41:03.500]  то это такой маленькой схемы уже просто не получится сделать.
[41:05.500 --> 41:06.500]  Вот. Ну вот.
[41:07.500 --> 41:08.500]  Так, ну я не знаю, надо ли в эти детали лезть,
[41:09.500 --> 41:11.500]  или так примерно поняли, и можно дальше идти.
[41:15.500 --> 41:17.500]  Да, хорошо, потому что дальше я хочу поговорить про
[41:18.500 --> 41:20.500]  уже сложностные классы,
[41:21.500 --> 41:22.500]  их соотношения.
[41:23.500 --> 41:24.500]  Так, а перерыв надо делать?
[41:27.500 --> 41:28.500]  Ну давайте на три минутки сделаем.
[41:35.500 --> 41:38.500]  Я в прерыве уже начали спрашивать про формальную модель,
[41:39.500 --> 41:40.500]  действительно я про нее ничего не сказал.
[41:41.500 --> 41:43.500]  Значит, давайте тогда с этого начнем.
[41:44.500 --> 41:50.500]  Значит, что такое вероятностная машина тюринга?
[41:50.500 --> 41:51.500]  Вероятностная машина тюринга.
[41:56.500 --> 41:58.500]  Значит, вероятностная машина тюринга.
[42:01.500 --> 42:04.500]  На самом деле есть разные определения,
[42:05.500 --> 42:07.500]  и они не всегда эквивалентны,
[42:08.500 --> 42:10.500]  особенно если речь идет о лагерфнической памяти.
[42:11.500 --> 42:13.500]  Значит, если речь идет о поленальном времени,
[42:14.500 --> 42:15.500]  там более-менее неважно, что происходит.
[42:15.500 --> 42:20.500]  С лагерфнической памятью есть некоторые тонкости,
[42:21.500 --> 42:23.500]  про них мы, наверное, почти не будем говорить.
[42:29.500 --> 42:33.500]  Простейший вариант – это просто машина с двумя аргументами,
[42:34.500 --> 42:36.500]  где второй аргумент случайный.
[42:36.500 --> 43:00.500]  Простейшее определение – это машина с двумя аргументами M от X, R.
[43:00.500 --> 43:02.500]  Где X – это вход, а R – случайные биты.
[43:12.500 --> 43:15.500]  Значит, это похоже на сертификатное определение NP.
[43:16.500 --> 43:18.500]  Там у нас тоже был вход и сертификат.
[43:19.500 --> 43:22.500]  Отличие в том, что сертификат нам там один подходил,
[43:23.500 --> 43:25.500]  а здесь мы не можем выбирать,
[43:25.500 --> 43:27.500]  просто он выбирается случайно.
[43:28.500 --> 43:32.500]  На первый взгляд, недетерминированные случайные – это синонимы,
[43:33.500 --> 43:35.500]  но не в смысле сложить вычислений.
[43:36.500 --> 43:39.500]  В смысле сложить вычислений получается, что R случайно,
[43:40.500 --> 43:43.500]  и все вместе M от X, R получается случайной величиной.
[43:44.500 --> 43:46.500]  Вернульевской, которая либо 0, либо 1,
[43:47.500 --> 43:50.500]  и, соответственно, будет какая-то вероятность для каждого экзотика,
[43:50.500 --> 43:52.500]  вероятность того, что это выдаст единицу.
[43:53.500 --> 43:55.500]  Точно так же можно сделать вариант
[43:58.500 --> 44:01.500]  и через недетерминированного шинонтюринга.
[44:02.500 --> 44:04.500]  Можно сказать так, что вероятная машина –
[44:05.500 --> 44:09.500]  это точно такой же объект, как недетерминированная машина,
[44:10.500 --> 44:12.500]  и у нее там есть дерево вычислений,
[44:13.500 --> 44:15.500]  и у нее там есть дерево вычислений,
[44:15.500 --> 44:17.500]  но вместо того, чтобы выискивать ветку,
[44:18.500 --> 44:20.500]  которая ведет к ответу «да»,
[44:21.500 --> 44:23.500]  мы берем просто среднее по всем ветвям.
[44:24.500 --> 44:28.500]  То есть просто в каждой точке ветвления у нас, пусть там равновероятно,
[44:29.500 --> 44:32.500]  по всем ветвям уходят, получается распределение на листьях,
[44:33.500 --> 44:36.500]  но и мы берем среднее, это и будет как бы ответ.
[44:39.500 --> 44:41.500]  Так.
[44:41.500 --> 44:43.500]  Сколько случайных битов?
[44:44.500 --> 44:46.500]  Сколько случайных битов?
[44:47.500 --> 44:49.500]  Значит время работы должно быть, если мы там говорим,
[44:50.500 --> 44:53.500]  ну вообще все ресурсы меряются как функции от длины х.
[44:54.500 --> 44:56.500]  То есть по лином от длины х?
[44:57.500 --> 44:59.500]  Да, то есть случайных битов по лином от длины х.
[45:00.500 --> 45:02.500]  То есть на самом деле это больше, чем она работает?
[45:03.500 --> 45:05.500]  Ну типа того, да.
[45:06.500 --> 45:08.500]  В принципе есть еще другой подход, например,
[45:08.500 --> 45:10.500]  на одной ленте у вас есть х,
[45:11.500 --> 45:13.500]  а другая лента вообще бесконечная,
[45:14.500 --> 45:16.500]  она вся целиком заполнена случайными битами.
[45:17.500 --> 45:20.500]  Но это я с временем не ограничивать.
[45:21.500 --> 45:24.500]  Ну в плане вот с этой модели у нас нет точности смоделирования.
[45:26.500 --> 45:29.500]  Ну да.
[45:30.500 --> 45:33.500]  Да, если это ограничено, то так Лас-Вегас не смоделирует.
[45:34.500 --> 45:36.500]  Да, я согласен.
[45:38.500 --> 45:39.500]  Вот.
[45:40.500 --> 45:44.500]  Можно еще моделировать через специальное состояние,
[45:45.500 --> 45:47.500]  которое выдает просто случайный бит.
[45:48.500 --> 45:51.500]  То есть мы переходим в специальное состояние кинуть монетку,
[45:52.500 --> 45:55.500]  и в этот момент в той клетке, куда мы смотрим,
[45:56.500 --> 45:57.500]  в следующий момент получается случайный бит.
[45:58.500 --> 46:00.500]  И мы его дальше как-то используем.
[46:01.500 --> 46:03.500]  Вот.
[46:04.500 --> 46:06.500]  Значит вот если есть логографическая память,
[46:06.500 --> 46:08.500]  то это все не совсем одно и то же.
[46:09.500 --> 46:11.500]  Потому что одно дело, когда у вас уже есть лента
[46:12.500 --> 46:14.500]  с случайными битами, вы их можете там туда и сюда ходить.
[46:15.500 --> 46:16.500]  Вот.
[46:17.500 --> 46:19.500]  А другое дело, если вы все, что можете хранить,
[46:20.500 --> 46:22.500]  только на логографической памяти,
[46:23.500 --> 46:26.500]  да и соответственно не можете хранить те биты, которые уже были.
[46:27.500 --> 46:29.500]  А на случайные биты не односторонние ленты?
[46:30.500 --> 46:32.500]  Может быть односторонние.
[46:33.500 --> 46:34.500]  Но все равно, нет, не одно и то же.
[46:34.500 --> 46:36.500]  Потому что если у вас есть любая память,
[46:37.500 --> 46:39.500]  даже если есть случайный бит односторонняя,
[46:40.500 --> 46:41.500]  если у вас сколько угодно памяти,
[46:42.500 --> 46:45.500]  то вы можете все, что получилось, уже себе записывать и хранить.
[46:46.500 --> 46:48.500]  Вот. Если у вас логографическая память, то все вы не можете хранить.
[46:49.500 --> 46:52.500]  Вы только логариф можете хранить выпавших битов.
[46:53.500 --> 46:54.500]  Вопрос.
[46:55.500 --> 46:58.500]  Если мы предъявим через него, как они через медитерминированную машину,
[46:59.500 --> 47:01.500]  то у нас одинаковое распределение по листам?
[47:02.500 --> 47:03.500]  Или мы считаем, что каждый по вашему?
[47:04.500 --> 47:06.500]  По листам, по ветвелениям.
[47:07.500 --> 47:09.500]  Ну опять, там тоже есть разные варианты.
[47:10.500 --> 47:13.500]  Есть вообще такой подход и к недотмирной тоже,
[47:14.500 --> 47:16.500]  что у вас просто есть две функции перехода.
[47:17.500 --> 47:18.500]  Там дельта 0 и дельта 1.
[47:19.500 --> 47:22.500]  И недотмирно у нас получается либо недотмирно одно и то же,
[47:23.500 --> 47:25.500]  поэтому просто переход, либо у вас получается ветвление.
[47:26.500 --> 47:29.500]  Вероятность получается, что просто вы кидаете монетку,
[47:30.500 --> 47:31.500]  по какой функции перехода переходить.
[47:35.500 --> 47:36.500]  Вот, хорошо.
[47:37.500 --> 47:43.500]  Ладно, в общем получается, что для каждого х есть вероятность,
[47:48.500 --> 47:59.500]  для каждого х задана вероятность того, что m от xr равно 1.
[47:59.500 --> 48:05.500]  Вот, и дальше есть такой маленький зоопарк веренственных классов.
[48:07.500 --> 48:13.500]  И они все определяются так, что если х лежит в множестве,
[48:14.500 --> 48:17.500]  то какое-то одно условие должно быть выполнено на эту вероятность.
[48:18.500 --> 48:21.500]  Если х не лежит в множестве, то какое-то другое условие на эту вероятность.
[48:22.500 --> 48:24.500]  Значит так, что эти условия конечны.
[48:24.500 --> 48:25.500]  Сейчас изучим.
[48:30.500 --> 48:33.500]  Изучим, какие есть классы и как они соотносятся.
[48:33.500 --> 48:36.500]  Изучим, какие есть классы и как они соотносятся.
[49:03.500 --> 49:31.040]  так но дать табличку
[49:31.040 --> 49:39.520]  тут будет табличка определений, а здесь я нарисую диаграмму, как эти классы друг у друга относятся
[49:39.520 --> 50:00.760]  тут будет класс, какая должна быть вероятность того, что м от хр равно 1 при х лежащем в а
[50:00.760 --> 50:13.520]  вот и дальше вероятность того, что м от хр равно 1 при х не лежащем в а
[50:13.520 --> 50:33.800]  ну с чего начнем? начнем с класса rp, rp расшифровывается как randomised polynomial
[50:33.800 --> 50:47.440]  тут всюду будет полиномиальное время, то есть что вот м от хр работает за полином от длины х
[50:47.440 --> 51:03.640]  значит в случае с рп тут будет 0, а тут будет больше либо равно 1 и 2
[51:03.640 --> 51:14.040]  вот и к нему есть парный qrp, так равно 0 давайте напишу
[51:14.040 --> 51:27.680]  парный qrp тут будет равно 1, а тут будет меньше либо равно 1 и 2
[51:27.680 --> 51:41.680]  как раз простые числа и вот эта задача равенстве многочленов они все будут в qrp
[51:41.680 --> 51:50.680]  если утверждение выполнено, если число простое или если многочлены равны, то наш алгоритм всегда выдавал единицу
[51:50.680 --> 52:01.680]  если соответственно неверно было, то тогда вероятность была меньше чем 1 вторая, но там у Миллера равен 1 четверть
[52:01.680 --> 52:08.680]  здесь надо аккуратно показать какие параметры, может и меньше 1 и 2
[52:08.680 --> 52:19.680]  это класс с односторонней ошибкой, дальше есть класс с двусторонней ошибкой bpp
[52:19.680 --> 52:26.680]  буква kb означает bounded error, bounded error пробабилистик полиномиал
[52:26.680 --> 52:32.680]  тут рандомайст, а тут пробабилистик, и это разное означает, что так сложилось
[52:32.680 --> 52:42.680]  соответственно здесь будет больше либо равно чем 2 третья, здесь будет меньше либо равно чем 1 третья
[52:42.680 --> 52:52.680]  еще есть без буквки b, просто pp
[52:52.680 --> 53:03.680]  тут будет больше либо равно 1 и 2, а тут будет строго меньше 1 и 2
[53:03.680 --> 53:11.680]  тут решается по большинству, а если ничья, то в пользу ответа да
[53:11.680 --> 53:17.680]  и такое решение должно дать правильный ответ, тогда это будет pp
[53:17.680 --> 53:27.680]  еще есть, но можно делать просто p, значит если здесь равно 1, если здесь равно 0
[53:27.680 --> 53:30.680]  почему это будет просто p?
[53:30.680 --> 53:35.680]  потому что можно просто какой угодно r написать, например из всех нулей
[53:35.680 --> 53:39.680]  и вычислить m от x и этого r, и это будет правильный ответ
[53:39.680 --> 53:45.680]  если здесь всегда дают 1, здесь всегда дают 0, значит с любым r всегда дают правильный ответ
[53:45.680 --> 53:48.680]  то есть это просто p
[53:48.680 --> 53:55.680]  а есть вот как раз к вопросу о Лас-Вегасе есть zpp
[53:55.680 --> 54:05.680]  значит тут тоже zero error zpp, тоже тут равно 1, тут равно 0
[54:05.680 --> 54:10.680]  но только среднее время полиномиальная
[54:16.680 --> 54:24.680]  среднее время работы полиномиальная
[54:25.680 --> 54:36.680]  ну и на самом деле можно в этих же терминах и np и co-np тоже сформулировать
[54:36.680 --> 54:45.680]  значит np тут у нас будет больше 0, а тут равно 0
[54:45.680 --> 54:54.680]  ну а co-np соответственно тут будет 1, а тут будет меньше 1
[54:54.680 --> 55:02.680]  но проблема в том, что это большая нуля, это может быть что-то экспоненциально маленькое
[55:09.680 --> 55:14.680]  так, хорошо, вот такое местоопределение
[55:24.680 --> 55:30.680]  правда, это сейчас обсудим
[55:30.680 --> 55:34.680]  и в bpp тоже
[55:54.680 --> 56:09.680]  так, сейчас я нарисую большую диаграмму, как все эти классы друг к другу соотносятся
[56:09.680 --> 56:24.680]  значит здесь будет p, дальше будет zpp
[56:24.680 --> 56:32.680]  и оно тут не просто будет, а можно про него доказать, что он равняется rp в пересечении co-rp
[56:32.680 --> 56:39.680]  соответственно тут будет
[56:39.680 --> 56:49.680]  что еще раз?
[56:49.680 --> 56:56.680]  ну это я диаграмму хасса рисую, кто в кого вложен
[56:56.680 --> 57:02.680]  значит здесь rp, здесь co-rp
[57:02.680 --> 57:08.680]  так, значит здесь bpp
[57:08.680 --> 57:14.680]  значит здесь np
[57:14.680 --> 57:17.680]  значит здесь co-np
[57:17.680 --> 57:25.680]  и вот здесь на самом верху будет pp
[57:25.680 --> 57:33.680]  вроде все, да? 8 и там 8
[57:33.680 --> 57:38.680]  некоторые положения тут очевидны
[57:38.680 --> 57:42.680]  например, почему p в zpp вложено?
[57:42.680 --> 57:48.680]  потому что если время в худшем случае полиномиально, то в среднем оно тоже полиномиально
[57:48.680 --> 57:52.680]  а ошибки там те же самые
[57:52.680 --> 57:56.680]  так, дайте я буду жирным делать то, что мы обсудили
[57:56.680 --> 57:58.680]  так, вот это очевидно
[57:58.680 --> 58:01.680]  еще очевидно вот это вот
[58:01.680 --> 58:08.680]  потому что если меньше чем 1 на треть, то меньше, чем 1 на вторая, если больше, чем 1 на треть, то больше, чем 1 на вторая
[58:08.680 --> 58:13.680]  поэтому если выполним условия для вот этого, то выполним для вот этого тоже
[58:13.680 --> 58:21.680]  и по тем же самым причинам rp вложено в np
[58:21.680 --> 58:25.680]  значит co-rp вложено в co-np тоже просто из этой таблички
[58:25.680 --> 58:29.680]  если больше 1 и 2, то больше 0
[58:29.680 --> 58:35.680]  то есть можно сказать так, что случайные биты, которые дают ответ 1 в rp
[58:35.680 --> 58:39.680]  они живут в сертификатном смысле np
[58:39.680 --> 58:44.680]  остальные уже не такие очевидные
[58:44.680 --> 58:47.680]  я, наверное, буду уже записывать
[58:47.680 --> 58:53.680]  в общем, про то, почему rp вложено в bpp вы на самом деле уже сказали
[58:53.680 --> 58:55.680]  это называется амплификация
[58:55.680 --> 58:57.680]  нужно два раза повторить
[58:57.680 --> 58:59.680]  и взять
[58:59.680 --> 59:05.680]  в случае с rp нужно взять дизьюнкцию
[59:07.680 --> 59:10.680]  запустить два раза
[59:10.680 --> 59:18.680]  два раза взять дизьюнкцию
[59:18.680 --> 59:22.680]  и так получается, что 0 останется нулем
[59:22.680 --> 59:30.680]  а вот больше ли бравно 1 и 2 превратится в больше ли бравно, чем 3 четверти
[59:30.680 --> 59:35.680]  ну понятно, да?
[59:36.680 --> 59:42.680]  что получился 0, ну чтобы там и там получился 0, а там, вероятно, не больше 1 и 2
[59:42.680 --> 59:48.680]  и запуски независимые, и поэтому будет не больше, чем в 1 четверти
[59:48.680 --> 59:55.680]  ну а 3 четверти уже больше, чем в 2 третьи, да, и мы получили условие на bpp
[59:55.680 --> 01:00:00.680]  так, ну чего, понятно, да?
[01:00:01.680 --> 01:00:03.680]  так
[01:00:13.680 --> 01:00:17.680]  ну тут понятно, что аналогично, да, только наоборот
[01:00:17.680 --> 01:00:26.680]  так, почему вот это вот верно, что zpp вложено в rp
[01:00:31.680 --> 01:00:34.680]  так, чего, почему, говорите?
[01:00:46.680 --> 01:00:49.680]  а, из np в pp, нет, это немножко посложнее
[01:00:49.680 --> 01:00:51.680]  давайте вот это сначала обсудим
[01:00:51.680 --> 01:01:00.680]  значит, zpp почему вложено в rp?
[01:01:00.680 --> 01:01:06.680]  ну смотрите, пусть у нас есть алгоритм, который работает в среднем t от n
[01:01:06.680 --> 01:01:09.680]  и дает правильный ответ
[01:01:09.680 --> 01:01:19.680]  да, значит, пусть m от xr работает в среднем
[01:01:22.680 --> 01:01:27.680]  значит, t от n дает верный ответ
[01:01:27.680 --> 01:01:30.680]  так, тогда есть вероятность Маркова
[01:01:30.680 --> 01:01:32.680]  так, вы это проходили?
[01:01:32.680 --> 01:01:33.680]  да
[01:01:33.680 --> 01:01:34.680]  хорошо
[01:01:34.680 --> 01:01:35.680]  чего?
[01:01:35.680 --> 01:01:36.680]  8 раз проходили
[01:01:36.680 --> 01:01:41.680]  а, 8 раз уже проходили вероятность Маркова, ну хорошо
[01:01:41.680 --> 01:01:49.680]  тогда получается, что вероятность того, что время работая
[01:01:49.680 --> 01:01:59.680]  ой, time m от xr будет больше, чем 2t от n
[01:01:59.680 --> 01:02:03.680]  значит, тут вероятность будет меньше, чем 1 вторая
[01:02:03.680 --> 01:02:06.680]  вот, и тогда получается, что алгоритм такой
[01:02:06.680 --> 01:02:10.680]  значит, rp алгоритм
[01:02:10.680 --> 01:02:19.680]  значит, вот запустить m от xr на 2t от n шагов
[01:02:19.680 --> 01:02:26.680]  значит, соответственно, если остановилось, то такой ответ и дать
[01:02:26.680 --> 01:02:33.680]  значит, остановилось, дать ответы, дать ответы, дать ответы
[01:02:33.680 --> 01:02:38.680]  Значит, соответственно, если остановилось, то такой ответ и дать.
[01:02:38.680 --> 01:02:45.680]  Значит, остановилось, значит, дать такой же ответ.
[01:02:49.680 --> 01:02:57.680]  Значит, не остановилось, но надо дать такой ответ, чтобы не ошибиться в нужную сторону.
[01:02:57.680 --> 01:03:04.680]  Так, значит, смотрите, нам нельзя давать ответ 1, если х не лишь ва.
[01:03:04.680 --> 01:03:10.680]  Ну, раз мы не можем давать ответ 1, не знаем, какой на самом деле, но дадим ответ 0.
[01:03:10.680 --> 01:03:15.680]  Значит, соответственно, если не останавливается, то дадим ответ 0.
[01:03:17.680 --> 01:03:21.680]  Вот, тогда что же получается?
[01:03:27.680 --> 01:03:39.680]  Ну, получается, что если, значит, если на самом деле не лежит ва, то мы в любом случае дадим ответ 0.
[01:03:39.680 --> 01:03:45.680]  Либо потому, что мы успели почитать правильный ответ, либо потому, что мы по умолчанию дали ответ 0.
[01:03:45.680 --> 01:03:55.680]  Вот, если лежит ва, то тогда получается, что с вероятностью 1-2 хотя бы мы успели почитать правильный ответ,
[01:03:55.680 --> 01:04:03.680]  значит, и соответственно, да, значит, и сказали верно 1.
[01:04:03.680 --> 01:04:09.680]  Ну, а с оставшейся вероятностью сказали 0, ошиблись, но эта ошибка нам разрешена.
[01:04:18.680 --> 01:04:20.680]  Ну, понятно, да?
[01:04:20.680 --> 01:04:31.680]  То есть мы говорим, что P&R равно 1 при условии, что их служит A больше, чем просто P&R равно 1.
[01:04:36.680 --> 01:04:44.680]  И мы берем вот этот P&R и играем, что P&R равно 1, если оно работает хотя бы на 2.
[01:04:44.680 --> 01:04:48.680]  Ну, да. Ну, типа того, да.
[01:04:49.680 --> 01:04:53.680]  Вот, хорошо. Значит, ложно в QRP аналогично.
[01:04:53.680 --> 01:05:00.680]  То, что обратное, значит, пересечение RP в QRP вложено в ZPP, это давайте я оставлю там на семинар или на упражнения.
[01:05:03.680 --> 01:05:09.680]  Так, и чего еще был вопрос вот про эту часть, да? Почему NP вложено в PPP?
[01:05:09.680 --> 01:05:11.680]  Так, а в чем вопрос?
[01:05:11.680 --> 01:05:15.680]  Ну, у нас же там ровно 0, а не меньше, чем Epsilon.
[01:05:15.680 --> 01:05:17.680]  Ровно 0, да.
[01:05:17.680 --> 01:05:22.680]  Ну, как бы, а там, типа, то есть моделирование сразу отпадает?
[01:05:26.680 --> 01:05:29.680]  Нет, значит, смотрите.
[01:05:32.680 --> 01:05:37.680]  Значит, смотрите, идея такая, что нам нужно, как бы у нас по духу и там, и там нет разрыва.
[01:05:37.680 --> 01:05:40.680]  Значит, смотрите, когда я вот здесь пишу меньше, чем 1 вторая,
[01:05:40.680 --> 01:05:45.680]  тут на самом деле меньше, чем 1 вторая, минус 1 делить на 2 в степень длина R.
[01:05:45.680 --> 01:05:47.680]  Давайте я это прям тут напишу.
[01:05:47.680 --> 01:05:53.680]  То есть это меньше либо равно, чем 1 вторая, минус 1 делить на 2 в степень длина R.
[01:05:54.680 --> 01:05:57.680]  Соответственно, здесь тоже, когда я пишу больше нуля,
[01:05:57.680 --> 01:06:02.680]  то тут тоже на самом деле будет больше либо равно, чем 1 делить на 2 в степень длина R.
[01:06:02.680 --> 01:06:06.680]  Соответственно, вот этот экспоненциальный разрыв у нас есть.
[01:06:06.680 --> 01:06:10.680]  То есть тут, хотя все выглядит непрерывно, на самом деле все дискретно.
[01:06:10.680 --> 01:06:13.680]  И, соответственно, есть какой-то маленький разрыв.
[01:06:13.680 --> 01:06:17.680]  Дело в том, что нужно этот маленький разрыв передвинуть как бы с нуля на 1 вторую.
[01:06:20.680 --> 01:06:21.680]  Да.
[01:06:27.680 --> 01:06:29.680]  Да, да, да, совершенно верно.
[01:06:29.680 --> 01:06:31.680]  Совершенно верно.
[01:06:31.680 --> 01:06:34.680]  Для фиксированного X, то есть для любого фиксированного X,
[01:06:34.680 --> 01:06:40.680]  среднее время по случайным битам должно быть меньше, опять же, фиксированного полинома длины этого X.
[01:06:44.680 --> 01:06:45.680]  Вот.
[01:06:45.680 --> 01:06:49.680]  Ну вот, соответственно, вот это вот NP вложено в PP.
[01:06:50.680 --> 01:06:53.680]  Значит, это делается так.
[01:06:53.680 --> 01:06:56.680]  Ну а смотрите, я тут еще, ну не знаю, специально или не специально,
[01:06:56.680 --> 01:07:01.680]  но я сделал так, что здесь как бы в другую сторону получается,
[01:07:01.680 --> 01:07:09.680]  что здесь у меня одна вторая вот тут вот, а здесь получается ноль вот здесь вот.
[01:07:09.680 --> 01:07:10.680]  Но это неважно.
[01:07:10.680 --> 01:07:14.680]  Сейчас я сразу покажу, как можно как бы сюда и сюда перекидывать.
[01:07:16.680 --> 01:07:17.680]  Вот.
[01:07:17.680 --> 01:07:28.680]  Значит, давайте пусть там скажем V от XS, значит, это машина из NP.
[01:07:30.680 --> 01:07:34.680]  Машина для языка A из NP.
[01:07:35.680 --> 01:07:36.680]  Вот.
[01:07:36.680 --> 01:07:39.680]  Тогда можно сделать вот что.
[01:07:42.680 --> 01:07:50.680]  Значит, M от XR, значит, длина R будет длина S плюс 1.
[01:07:53.680 --> 01:07:55.680]  Так, значит, это будет вот что.
[01:07:55.680 --> 01:08:01.680]  Значит, это будет ноль, если R состоит из всех нулей.
[01:08:05.680 --> 01:08:12.680]  Значит, это будет один, если R начинается с нуля, но содержит единицу.
[01:08:13.680 --> 01:08:16.680]  Давайте я так условно напишу, это ноль, значит, а здесь где-то есть один.
[01:08:19.680 --> 01:08:20.680]  Вот.
[01:08:20.680 --> 01:08:32.680]  И это будет V от XS, значит, если, ой, если R, это 1S.
[01:08:34.680 --> 01:08:42.680]  То есть, если R начинается с единицы, то мы эту единицу откусываем, все что осталось, значит, подставляем в качестве сертификата в машину.
[01:08:43.680 --> 01:08:44.680]  Вот.
[01:08:44.680 --> 01:08:45.680]  А что у нас получается?
[01:08:45.680 --> 01:08:49.680]  У нас получается, что у нас почти одна вторая единица уже получилась за счет вот этих вот.
[01:08:50.680 --> 01:08:53.680]  За счет этих получилась еще не совсем одна вторая.
[01:08:53.680 --> 01:08:55.680]  Одна вторая минус одно исключение.
[01:08:55.680 --> 01:08:56.680]  Вот.
[01:08:56.680 --> 01:09:04.680]  И если вот здесь есть единица, то она с этой исключения добавит, да, заменит как бы вместо этого исключения будет единица вот отсюда.
[01:09:05.680 --> 01:09:07.680]  И уже будет больше либо вот одной второй.
[01:09:07.680 --> 01:09:08.680]  Вот.
[01:09:08.680 --> 01:09:15.680]  Если же все S не подходят, да, то у нас здесь будут нули, еще здесь один ноль, поэтому единица строго меньше, чем одна вторая.
[01:09:18.680 --> 01:09:19.680]  Нет?
[01:09:20.680 --> 01:09:23.680]  Ну давайте разберемся уже, видимо, больше ничего не успеем, все равно.
[01:09:26.680 --> 01:09:30.680]  Ну, значит, смотрите, у нас S было случайным.
[01:09:31.680 --> 01:09:35.680]  Ну, машина не терминирована, но, значит, смотрите, если...
[01:09:35.680 --> 01:09:37.680]  Давайте подробно, что, значит, если...
[01:09:38.680 --> 01:09:49.680]  Если X лежит в A, то тогда существует S, значит, такое, что V от XS равно единице.
[01:09:50.680 --> 01:09:53.680]  Тогда давайте местную вероятность посчитаем количество.
[01:09:53.680 --> 01:10:11.680]  Значит, тогда количество таких R, что M от XR равно единице, будет больше либо равно, значит, больше, чем 2 в степени длина S минус 1.
[01:10:12.680 --> 01:10:14.680]  И это которые вот отсюда берутся.
[01:10:15.680 --> 01:10:19.680]  Да, если первый бит ноль, а дальше где-то есть единица.
[01:10:19.680 --> 01:10:23.680]  Таких будет 2 в степени длина S минус 1.
[01:10:26.680 --> 01:10:29.680]  И еще плюс один.
[01:10:30.680 --> 01:10:33.680]  Да, плюс один, который из вот этого S.
[01:10:34.680 --> 01:10:41.680]  То есть вот это это R, который из всех нулей, значит, а это будет R, который 1S.
[01:10:43.680 --> 01:10:48.680]  Ну а это будет равняться 2 в степени длина S, то есть доля будет хотя бы одна вторая.
[01:10:49.680 --> 01:10:51.680]  Может, длина R будет в два раза больше.
[01:10:52.680 --> 01:10:55.680]  Длина R на один больше, а 2 в степени будет в два раза больше.
[01:10:56.680 --> 01:10:58.680]  Да, поэтому так одна вторая получилась.
[01:10:59.680 --> 01:11:02.680]  Вот, это если X лежит в A, а если X не лежит в A, то вот этой вот добавки точно нет.
[01:11:03.680 --> 01:11:05.680]  И поэтому будет строго меньше, чем одна вторая.
[01:11:06.680 --> 01:11:11.680]  И вот и получилось, что мы как бы порог сдвинули с нуля на одну вторую.
[01:11:12.680 --> 01:11:15.680]  Дальше есть, на самом деле, еще более хитрое дело.
[01:11:15.680 --> 01:11:17.680]  Избавиться от асимметрии.
[01:11:18.680 --> 01:11:19.680]  Вот здесь вот.
[01:11:20.680 --> 01:11:23.680]  Сделал так, чтобы здесь было строго больше одной второй, а здесь было строго меньше одной второй.
[01:11:26.680 --> 01:11:28.680]  Ну это примерно так же делается.
[01:11:30.680 --> 01:11:31.680]  Но прямо так не получится.
[01:11:32.680 --> 01:11:33.680]  Там это немножко по-другому нужно.
[01:11:34.680 --> 01:11:36.680]  Нужно добавить там минимум два новых бита.
[01:11:37.680 --> 01:11:43.680]  Ну и там дальше немножко там поперекидывать, чтобы мы точно как бы сдвинули на градацию.
[01:11:46.680 --> 01:11:47.680]  Вот.
[01:11:48.680 --> 01:11:51.680]  И это позволяет доказать, что PP замкнута относительно дополнения.
[01:11:52.680 --> 01:12:02.680]  Если здесь будет строго больше, здесь строго меньше, то от того, что мы перевернем ответ, то как бы и здесь большинство тоже перевернется.
[01:12:05.680 --> 01:12:06.680]  Вот так. Ну вот.
[01:12:07.680 --> 01:12:08.680]  Значит, хорошо.
[01:12:09.680 --> 01:12:10.680]  Что мы в следующий раз изучать?
[01:12:11.680 --> 01:12:13.680]  Ну, во-первых, все-таки обсудим про амплификацию.
[01:12:14.680 --> 01:12:17.680]  Что здесь можно вместо одной второй, что еще можно написать.
[01:12:18.680 --> 01:12:22.680]  На самом деле, не только любое число от 0 до единицы, но еще и некоторые функции.
[01:12:23.680 --> 01:12:24.680]  Но не любые.
[01:12:25.680 --> 01:12:26.680]  Вот.
[01:12:27.680 --> 01:12:32.680]  И второе, что мы обсудим, это, значит, где вот это BPP находится относительно других классов.
[01:12:33.680 --> 01:12:36.680]  То есть, довольно легко понять, что даже PP будет в PSP вложено.
[01:12:36.680 --> 01:12:44.680]  Просто потому что на полинамиальной памяти можно просто перебирать все R и прямо посчитать вероятность и сравнить, что с чем нужно.
[01:12:45.680 --> 01:12:46.680]  Вот.
[01:12:47.680 --> 01:12:48.680]  Ну а сам BPP будет ниже лежать.
[01:12:49.680 --> 01:12:53.680]  А именно оно будет и в PSP лежать.
[01:12:54.680 --> 01:12:56.680]  То есть это можно заменить на схемы.
[01:12:57.680 --> 01:13:00.680]  И будет еще лежать в полинамиальной иерархии на втором уровне.
[01:13:01.680 --> 01:13:02.680]  Вот.
[01:13:03.680 --> 01:13:04.680]  Ну, наверное, этого нам хватит на следующий раз.
[01:13:04.680 --> 01:13:10.680]  А через две недели мы поговорим про то, нельзя ли тут все схлопнуть, вот эту вот нижнюю часть.
[01:13:11.680 --> 01:13:14.680]  Вообще есть гипотеза о том, что P равняется BPP.
[01:13:15.680 --> 01:13:17.680]  Да, и нижняя часть, вот это вот сейчас схлопывается.
[01:13:18.680 --> 01:13:22.680]  Ну, это верхняя оценка.
[01:13:23.680 --> 01:13:25.680]  Это не нижняя оценка, это верхняя оценка.
[01:13:28.680 --> 01:13:29.680]  Вот.
[01:13:30.680 --> 01:13:31.680]  Ну вот.
[01:13:31.680 --> 01:13:40.680]  Соответственно, есть основания полагать, что можно все дорандомизировать.
[01:13:41.680 --> 01:13:43.680]  И что на самом деле P равняется BPP.
[01:13:44.680 --> 01:13:45.680]  Вот.
[01:13:46.680 --> 01:13:47.680]  Так, хорошо.
[01:13:48.680 --> 01:13:49.680]  Ладно, это все.
[01:13:50.680 --> 01:13:51.680]  Спасибо за внимание.
[01:13:52.680 --> 01:13:53.680]  До встречи.
