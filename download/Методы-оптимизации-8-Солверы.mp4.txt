[00:00.000 --> 00:10.080]  Так, всем здравствуйте, продолжаем разговор, небольшое
[00:10.080 --> 00:13.360]  исправление того, что было в прошлый раз, вот в этом
[00:13.360 --> 00:16.280]  утверждении про линейное программирование надо
[00:16.280 --> 00:20.880]  было дописать, что требуется еще дополнительно, что допустим
[00:20.880 --> 00:24.560]  множество, ну в общем, да, напоминаю, мы изучали двойственность
[00:24.560 --> 00:27.080]  на примере вот такой вот простейшей задачи, вот
[00:27.080 --> 00:29.920]  было линейное программирование, целевая функция линейно-ограниченная,
[00:29.920 --> 00:32.600]  равенство и неравенство такие.
[00:32.600 --> 00:36.040]  Мы получали двойственно задачу и потом было утверждение
[00:36.040 --> 00:40.440]  о том, что допустимое множество в прямой задаче пусто, то
[00:40.440 --> 00:45.100]  же самое, что и двоясная задача имеет, неограничена
[00:45.100 --> 00:48.000]  целевая функция на допустимое множество и тут важно было
[00:48.000 --> 00:51.980]  добавить, что еще и допустимое множество в самой двойственной
[00:51.980 --> 00:54.300]  задаче не пусто, потому что оно может быть пустым
[00:54.300 --> 00:58.000]  вместе с допустимым множеством в прямой задаче.
[00:58.000 --> 01:02.400]  И тогда все работает точно так же, как было, только
[01:02.400 --> 01:05.120]  ту лямбду, которую мы будем подставлять, строим как
[01:05.120 --> 01:08.040]  лямбда с чертой плюс тета на p, где p — это вектор из
[01:08.040 --> 01:09.040]  лемма-фаркаша.
[01:09.040 --> 01:13.160]  И тогда все работает, потому что для лямбды с чертой оно
[01:13.160 --> 01:16.840]  уже допустимо, поэтому вот эта штука, то есть вот эта
[01:16.840 --> 01:19.360]  плюс вот эта уже больше либо равна нуля, и мы добавляем
[01:19.360 --> 01:23.400]  то, что от tp больше либо равно нуля, если будет выполняться.
[01:23.400 --> 01:27.080]  И, соответственно, здесь также будет минус бесконечность,
[01:27.080 --> 01:31.480]  потому что лямбда с чертой на b — это константа некоторая,
[01:31.480 --> 01:34.200]  а p, транспонированная на b, у нас строго меньше нуля,
[01:34.200 --> 01:36.760]  вот это вот стремление к бесконечности, получаем
[01:36.760 --> 01:38.520]  бесконечно маленькое значение.
[01:38.520 --> 01:41.680]  Бесконечно маленькое, в смысле, стремляющийся к
[01:41.680 --> 01:42.680]  минусу бесконечности.
[01:42.680 --> 01:48.320]  Теперь пример того, в чем может быть проблема за допустимым
[01:48.320 --> 01:49.320]  множеством.
[01:49.320 --> 01:53.680]  Довольно простой пример, берем вот такую вот допустимую
[01:53.680 --> 01:55.800]  множество задачи линейного программирования, то есть
[01:55.800 --> 01:59.080]  у нас не отрицательные чиселки, но одна из них
[01:59.080 --> 02:03.040]  меньше минус единицы, а одна компонента меньше
[02:03.040 --> 02:07.000]  минус единицы, что заведом противоречит этому условию.
[02:07.000 --> 02:10.400]  Но формально ничего не ломается, потому что мы
[02:10.400 --> 02:14.200]  его можем переписать вот так вот, то есть вот формальная
[02:14.200 --> 02:19.280]  матрица A, вектор B и ограничение на новый блочный вектор.
[02:20.280 --> 02:24.720]  было вот здесь.
[02:24.720 --> 02:26.680]  Вот это наше допустимое множество.
[02:26.680 --> 02:35.480]  Вот, которое пусто, вот, тогда соответственно по тем
[02:35.480 --> 02:38.080]  правилам, которые мы вывели вот здесь, вот-вот, у нас
[02:38.080 --> 02:40.040]  тут допустимое множество такое вот.
[02:40.040 --> 02:43.880]  И заметьте, что оно внезапно, неожиданно зависит от вектора
[02:43.880 --> 02:44.880]  C еще дополнительно.
[02:44.880 --> 02:50.760]  То есть, если тут мы выбрали A и B, вот, матрица A, вот,
[02:50.760 --> 02:55.960]  вектор B, то поставив, ну, по строке допустимое множество
[02:55.960 --> 03:00.880]  для, соответственно, C плюс A транспонированное на
[03:00.880 --> 03:04.800]  лямбда, лямбда, соответственно, двумерный, вот, мы получаем,
[03:04.800 --> 03:08.440]  что наше допустимое множество в двое, значит, вот такое
[03:08.440 --> 03:09.440]  вот.
[03:09.440 --> 03:12.000]  Вот, ну и давайте подберем, можно подобрать очевидным
[03:12.000 --> 03:15.840]  образом, C2 и C4 так, чтобы вот эта штука не выполнялась.
[03:15.840 --> 03:18.960]  Вот, ну, например, C2 и C4 равны минус единице.
[03:18.960 --> 03:19.960]  Вот.
[03:19.960 --> 03:23.080]  Получим, что и здесь тоже получается пустое множество
[03:23.080 --> 03:28.920]  за счет того, что у нас допустимое множество зависит от целевой,
[03:28.920 --> 03:31.400]  от вектора C, который в целевой функции, который никак
[03:31.400 --> 03:34.080]  не участвует в допустимом множестве исходной задачи.
[03:34.080 --> 03:38.600]  Понятно, да, откуда взялась еще одна степень свободы,
[03:38.600 --> 03:40.080]  которой можем получить пустое множество.
[03:40.080 --> 03:48.280]  Так, да, нет, руки поднимите, кто понял.
[03:48.280 --> 03:56.800]  Так, один, два, так, давайте еще раз, было вот так, это
[03:56.800 --> 03:58.800]  допустимое, понятно, что это пустое множество?
[03:58.800 --> 04:01.480]  Так, тут понятно, понятно ли, как мы его переписали
[04:01.480 --> 04:05.800]  таким образом?
[04:05.800 --> 04:10.480]  Добавили к X1 некоторое положительное число, чтобы получить равенство
[04:10.480 --> 04:16.840]  минус единице, это, соответственно, S1, и к минус X2 добавили тоже
[04:16.840 --> 04:19.560]  положительное число, это наше S2, чтобы получить равенство
[04:19.560 --> 04:20.560]  минус единице.
[04:20.560 --> 04:24.240]  Это, соответственно, S1 и S2, и получаем, что X1 плюс
[04:24.240 --> 04:28.600]  S1 равно минус единице, и минус X2 плюс S2 равно минус единице.
[04:28.600 --> 04:33.000]  Получили еще две дополнительные переменные.
[04:33.840 --> 04:35.320]  Так, вот это понятен.
[04:35.320 --> 04:39.040]  Это наше допустимое множество, которое в точности совпадает
[04:39.040 --> 04:40.200]  с тем, что было вот здесь.
[04:40.200 --> 04:46.160]  Вот наша матрица, вот наш вектор B, вот не отрицательность
[04:46.160 --> 04:48.080]  по компоненту нашего целевого вектора.
[04:48.080 --> 04:53.640]  Далее, мы тут страдали долгую порну, получали, допустим,
[04:53.640 --> 04:56.520]  множество двойственного значения, вот такое.
[04:56.520 --> 04:59.680]  Вот наша матрица A, вот наш вектор B, значит, допустим,
[04:59.680 --> 05:07.160]  что будет записываться как C плюс A транспонированное
[05:07.160 --> 05:08.160]  на лямбду.
[05:08.160 --> 05:14.880]  A транспонированная, соответственно, матрица 4 на 2, где строки
[05:14.880 --> 05:18.240]  – это столбсы, я надеюсь, тут понятно.
[05:18.240 --> 05:21.560]  Поэтому получается, что первая строка становится
[05:21.560 --> 05:25.240]  первым столбсом, тут лямбда 1, тут минус лямбда 2, тут
[05:25.240 --> 05:28.160]  плюс лямбда 1 и плюс лямбда 2 умножили.
[05:28.160 --> 05:34.520]  Из этих четырех нерайс мы выбираем 2, а именно нерайс
[05:34.520 --> 05:37.160]  на лямбду, что у нас отсюда лямбда 2 меньше либо равно
[05:37.160 --> 05:41.600]  C2, вот из второго, и лямбда 2 больше либо равно, чем минус
[05:41.600 --> 05:42.600]  C4.
[05:42.600 --> 05:47.680]  Понятно, откуда что взялось?
[05:47.680 --> 05:50.160]  Отлично, говорим, что если у нас вектор C оказывается
[05:50.160 --> 05:53.480]  вот таким вот, например, то это пустое множество,
[05:53.480 --> 05:54.480]  заведомо.
[05:54.480 --> 05:57.920]  Отсюда и тут пустое множество, и тут пустое множество.
[05:57.920 --> 06:03.320]  То есть условия того, что допустимое множество в прямой
[06:03.320 --> 06:06.600]  издаче пусто, ничего не означает о том, что допустимая
[06:06.600 --> 06:07.920]  издача обязательно будет разрешима.
[06:07.920 --> 06:13.400]  Поэтому эта вот оговорка здесь существенная, чтобы
[06:13.400 --> 06:16.080]  было вот это лямбда с чертой, которую мы здесь используем
[06:16.080 --> 06:18.160]  для того, чтобы у нас все сработало.
[06:18.160 --> 06:26.040]  Так, понятно, так, подеватируйте, кому понятно, так, окей,
[06:26.040 --> 06:27.040]  хорошо.
[06:27.040 --> 06:28.040]  Едем дальше.
[06:28.040 --> 06:31.000]  Так, все, это тут с прошлой лекции вроде я все долги
[06:31.000 --> 06:32.000]  вернул.
[06:32.000 --> 06:33.880]  Там еще были некоторые поправки, но они вроде плюс-минус
[06:33.880 --> 06:34.880]  очевидны.
[06:34.880 --> 06:36.440]  Это ладно, они мне будут не возвращаться.
[06:36.440 --> 06:41.840]  Так, переходим к сегодняшней непосредственной лекции,
[06:41.840 --> 06:47.280]  а именно про то, как, собственно, строятся солверы для выпуклых
[06:47.280 --> 06:48.280]  задач.
[06:48.280 --> 06:50.240]  Ну, для в целом задач и выпуклых в частности.
[06:50.240 --> 06:57.200]  Так что сегодня будет немного примеров, немного каких-то
[06:57.200 --> 06:59.360]  ссылок на ранее рассмотренный материал.
[06:59.360 --> 07:02.520]  Так, это было в прошлый раз, двойственность, обученное
[07:02.520 --> 07:04.760]  неравенство, коническая двойственность, нам сегодня
[07:04.760 --> 07:08.520]  понадобятся конические представления задач, двойственность
[07:08.520 --> 07:12.680]  для СДП и условия солвера для СДП почему это существенные.
[07:12.680 --> 07:15.400]  Напоминаю, как выглядит в общем виде наши задачи.
[07:15.400 --> 07:18.080]  Мы минимизируем некоторую целевую функцию f0 при условии,
[07:18.080 --> 07:20.960]  что у нас есть неравенство и равенство.
[07:20.960 --> 07:23.720]  То, насколько мы можем такие задачи решать, напрямую
[07:23.720 --> 07:25.960]  зависит от свойств вот этих самых функций, которые
[07:25.960 --> 07:28.920]  сюда входят, собственно, в такие задачи.
[07:28.920 --> 07:31.800]  Значит, если у нас есть, если все афинно, то это
[07:31.800 --> 07:34.680]  линия программирования, о которой мы до этого, о которой
[07:34.680 --> 07:35.960]  некоторое время уже обсуждали.
[07:35.960 --> 07:39.240]  И такие задачи могут быть крайне эффективны и быстро
[07:39.240 --> 07:41.800]  решены, там куча методов, мы про них поговорим чуть
[07:41.800 --> 07:42.800]  позже.
[07:43.320 --> 07:46.520]  С другой стороны, если что-то нелинейное, то даже очень
[07:46.520 --> 07:49.680]  простое, то это напрямую может существенным образом
[07:49.680 --> 07:53.160]  повлиять на сложность решения и привести к тому, что задача
[07:53.160 --> 07:56.640]  станет по полной, по сложной и все эти вот слова о том,
[07:56.640 --> 07:59.360]  что только переборные методы экспоненциальной сложности
[07:59.360 --> 08:00.360]  будут работать.
[08:00.360 --> 08:09.360]  К счастью, для многих нелинейных, нелинейных функций, целевых
[08:09.440 --> 08:14.480]  и в ограничениях, которые выглядят, может быть, сильно
[08:14.480 --> 08:16.960]  нелинейно, оказывается, что при наличии выпуклости
[08:16.960 --> 08:20.840]  на них все разрешимо также за полинамиальное время,
[08:20.840 --> 08:21.840]  то есть достаточно быстро.
[08:21.840 --> 08:26.840]  Да, это напоминание того, как выглядит задача выпукло-оптимизации,
[08:26.840 --> 08:27.840]  в общем, видим.
[08:27.840 --> 08:30.840]  Какие у нее свойства?
[08:30.840 --> 08:33.040]  Линейное программирование – частный случай, то здесь
[08:33.040 --> 08:36.720]  разделение, как я уже говорил на одной из первых лекций,
[08:36.720 --> 08:39.520]  что разделение происходит не по линейности и нелинейности,
[08:39.520 --> 08:42.520]  а по выпуклости и невыпуклости.
[08:42.520 --> 08:45.000]  Удивительно, но нелинейные целевые функции с нелинейными
[08:45.000 --> 08:49.120]  ограничениями, но выпуклыми оказываются почти так же
[08:49.120 --> 08:51.880]  быстро решаемы, как и линейное программирование, когда
[08:51.880 --> 08:52.880]  все линейно.
[08:52.880 --> 08:57.120]  Значит, может выглядеть довольно сложно, страшно,
[08:57.120 --> 09:02.600]  непонятно, но при должном внимании и аккуратном переписывании
[09:03.360 --> 09:08.800]  все получается переписать так, что окажется, что функции
[09:08.800 --> 09:10.720]  выпуклые, и поэтому можем решить быстро.
[09:10.720 --> 09:16.320]  Встречается очень много приложений, где это все появляется,
[09:16.320 --> 09:19.640]  поэтому это достаточно интересно, разумно и полезно
[09:19.640 --> 09:20.920]  рассматривать подобного рода задачи.
[09:20.920 --> 09:27.600]  Да, значит, как мы знание о том, что или ожидание о
[09:27.600 --> 09:30.600]  том, что наши функции выпуклые, можем использовать?
[09:31.600 --> 09:36.080]  Тут есть много вариантов того, что мы можем делать,
[09:36.080 --> 09:38.920]  для того, чтобы ничего не делать и просто верить в
[09:38.920 --> 09:42.160]  то, что нам пришло на вход, является выпуклым и исходя
[09:42.160 --> 09:44.600]  из этих предпосылок, что-то с этим делать.
[09:44.600 --> 09:47.800]  Это не очень понятное дело, перспективное направление,
[09:47.800 --> 09:52.240]  поскольку у нас много информации, но мы не всегда можем быть
[09:52.240 --> 09:54.760]  уверены, что оно действительно работает, потому что мы никак
[09:54.760 --> 09:57.880]  не проверили то, что нам пришло, действительно выпукло.
[09:57.880 --> 10:00.280]  Вы написали в Питоне какую-то функцию и отправили ее
[10:00.280 --> 10:03.880]  в оптимизатор, и он может начать с ней делать, при
[10:03.880 --> 10:07.360]  этом непонятно, почему оно будет работать, если вы
[10:07.360 --> 10:09.080]  никак не проверяете это все.
[10:09.080 --> 10:14.400]  Это, по-моему, дело просто, ничего делать не надо, но
[10:14.400 --> 10:18.080]  преимущества теряются, поскольку вы не используете в явном
[10:18.080 --> 10:22.840]  виде, вы не понимаете заранее или никак не выводите то,
[10:22.840 --> 10:24.880]  как это выпукло, если непосредственно строится, то есть почему
[10:24.880 --> 10:28.600]  то, что вам пришло на вход, выпукло или не выпукло.
[10:28.600 --> 10:31.480]  Понятно, что альтернативный способ этого можно проверять,
[10:31.480 --> 10:33.520]  то есть вам что-то пришло, вы сказали, давайте мы сначала
[10:33.520 --> 10:35.520]  проверим, выпукло или не выпукло, а потом только
[10:35.520 --> 10:36.520]  будем что-то запускать.
[10:36.520 --> 10:43.960]  Тут не очень понятно, как это делать, поскольку вам
[10:43.960 --> 10:46.640]  пришел черный ящик, который вы подаёте х, он вам возвращает
[10:46.640 --> 10:48.760]  значение, и вам надо как-то проверить, что вот эта вся
[10:48.760 --> 10:49.760]  штука, она выпукла.
[10:49.760 --> 10:52.280]  Но не очень понятно, как это делать, поскольку либо
[10:52.280 --> 10:55.320]  вы будете по каким-то критериям это проверять, но во всех
[10:55.320 --> 10:58.720]  критериях фигурирует страшный квантор для любого, и когда
[10:58.720 --> 11:01.120]  вам нужно для всех в мерном пространстве проверить,
[11:01.120 --> 11:04.520]  вы дольше проверять будете, чем решать.
[11:04.520 --> 11:10.040]  Компромисты, некоторые вариант вот этих двух крайностей
[11:10.040 --> 11:16.120]  являются в том, что мы предполагаем, что пришедшая функция
[11:16.120 --> 11:18.880]  на вход будет выпуклой, но наше предположение опирается
[11:18.880 --> 11:23.520]  на то, что мы заранее заставляем пользователей строить целевую
[11:23.520 --> 11:27.280]  функцию так, чтобы в процессе, перед тем как решать, вот
[11:27.280 --> 11:30.680]  эта вот проверка была достаточно быстро осуществима.
[11:30.680 --> 11:37.080]  То есть у нас есть некоторое правило композиции некоторых
[11:37.080 --> 11:42.880]  элементарных блоков FIT, исходя из знания о том, из каких
[11:42.880 --> 11:48.080]  блоков мы строим нашу функцию, и того, как допустимое
[11:48.080 --> 11:50.720]  преобразование меняет свойства функции, мы можем
[11:50.720 --> 11:55.040]  вывести свойства в целом результата.
[11:55.040 --> 11:58.760]  То есть как проверять выпуклость, например?
[11:58.760 --> 12:02.280]  Можно проверять по критериям, например, критерия второго
[12:02.280 --> 12:03.280]  порядка.
[12:03.280 --> 12:05.640]  Грустно, что во-первых, нужна определенность гессиана,
[12:05.640 --> 12:07.440]  во-вторых, нужна, что эта определенность была для
[12:07.440 --> 12:08.440]  любого вектора.
[12:08.440 --> 12:13.760]  Это грустно, это долго и непонятно, как это для
[12:13.760 --> 12:17.280]  любого исследовать, особенно это страшно, когда у вас
[12:17.280 --> 12:19.760]  какой-нибудь максимум сидит, который не дифференцируем.
[12:19.760 --> 12:21.840]  Там вообще это работать не будет, потому что только
[12:21.840 --> 12:23.200]  непрерывная дифференцируемость требуется.
[12:23.200 --> 12:24.200]  Вот.
[12:24.200 --> 12:27.040]  Вот проверка выпуклости через зачисление выпуклых
[12:27.040 --> 12:30.720]  функций более перспективный способ, который заключается
[12:30.720 --> 12:34.080]  в том, что я уже частично проговорил, что есть набор
[12:34.080 --> 12:36.720]  простых функций, выпуклость которых вы показали руками,
[12:36.720 --> 12:39.080]  на основе как раз-таки, например, вот этого.
[12:39.080 --> 12:40.080]  Вот.
[12:40.080 --> 12:41.800]  Есть некоторые преобразования, которые выпуклость не
[12:41.800 --> 12:42.800]  портит.
[12:42.800 --> 12:44.920]  Можно максимум брать, например, можно там афинные
[12:44.920 --> 12:47.120]  преобразования от аргумента делать, еще что-то можно
[12:47.120 --> 12:49.640]  там складывать, на константы положительные домножать.
[12:49.640 --> 12:50.640]  Вот.
[12:50.640 --> 12:56.200]  И вы на основе этих правил генерируете новую выпуклую
[12:56.200 --> 12:58.440]  функцию просто по этим самым правилам.
[12:58.440 --> 12:59.440]  Вот.
[12:59.440 --> 13:01.960]  Тогда, соответственно, solver надо будет разобрать
[13:01.960 --> 13:08.480]  вашу функцию на составляющие и проверить, что ингредиенты,
[13:08.480 --> 13:11.560]  которые вы туда засунули и правила, которые вы использовали,
[13:11.560 --> 13:13.000]  в результате дают выпуклую функцию.
[13:14.000 --> 13:16.240]  Какие функции считаются простыми?
[13:16.240 --> 13:18.800]  Так, а понятно, что вообще происходит-то?
[13:18.800 --> 13:21.400]  Я так, может, слишком быстро говорю?
[13:21.400 --> 13:23.400]  Нормально, да?
[13:23.400 --> 13:24.400]  Прекрасно.
[13:24.400 --> 13:27.640]  Ну, понятно, у нас есть степенные функции, у нас есть всякие
[13:27.640 --> 13:32.240]  алгорифмы, экспоненты, есть линейные функции.
[13:32.240 --> 13:34.720]  Я надеюсь, все понимают, как все дело проверяется.
[13:34.720 --> 13:37.920]  Все понимают.
[13:37.920 --> 13:40.920]  И как же?
[13:40.920 --> 13:41.920]  Громче.
[13:42.840 --> 13:46.120]  Ну да, в случае, когда у вас скаляры, то просто
[13:46.120 --> 13:48.720]  берете вторую производную, смотрите на ее знак, тут
[13:48.720 --> 13:51.400]  линейность по определению можно проверить, норма
[13:51.400 --> 13:55.320]  по определению проверяется, максимум проверяется,
[13:55.320 --> 13:57.680]  ну, по определению, наверное, алгорифм проверяется через
[13:57.680 --> 13:59.080]  которые второго порядка.
[13:59.080 --> 14:00.480]  То есть тут надо гессианом проанализировать.
[14:00.480 --> 14:01.480]  Вот.
[14:01.480 --> 14:04.480]  Вот эта штука проверяется более хитрыми техниками
[14:04.480 --> 14:07.680]  через сведение к функции от скалярного аргумента.
[14:07.680 --> 14:08.680]  Вот.
[14:08.680 --> 14:11.840]  То есть вот эти функции проверяются руками.
[14:11.840 --> 14:14.360]  Ну, наверное, еще какой-то набор функций можно проверить.
[14:14.360 --> 14:18.880]  Это, в общем, не так, чтобы очень сложно и страшно.
[14:18.880 --> 14:19.880]  Вот.
[14:19.880 --> 14:25.240]  Теперь, как бы, наши элементарно некоторые штуки, которые
[14:25.240 --> 14:27.760]  мы можем использовать для того, чтобы генерировать
[14:27.760 --> 14:30.840]  новые выпуклые функции с помощью некоторых довольно
[14:30.840 --> 14:31.840]  несложных правил.
[14:31.840 --> 14:32.840]  Вот.
[14:32.840 --> 14:35.080]  Ну, например, как бы, на константе вот можно домножать,
[14:35.080 --> 14:36.080]  на неотрицательном.
[14:36.080 --> 14:37.080]  Вот.
[14:37.080 --> 14:38.080]  Это по определению проверяется.
[14:38.080 --> 14:39.080]  Вот.
[14:39.080 --> 14:40.080]  Можно складывать.
[14:40.320 --> 14:43.520]  Это проверяется, ну, да, тоже по определению, наверное.
[14:43.520 --> 14:44.520]  Вот.
[14:44.520 --> 14:47.560]  Можно вот с афиной функцией брать композицию, это проверяется
[14:47.560 --> 14:48.560]  тоже по определению.
[14:48.560 --> 14:50.240]  Тут, в принципе, все по определению проверяется.
[14:50.240 --> 14:53.440]  А, вот максимум проверяется, не обязательно по определению,
[14:53.440 --> 14:56.480]  можно через над-график это все дело сформулировать,
[14:56.480 --> 14:57.480]  сказать, что...
[14:57.480 --> 15:00.080]  То есть вот это все, я в каком-то смысле повторяю то, что мы
[15:00.080 --> 15:03.200]  уже обсуждали на занятии про соответственно выпуклые
[15:03.200 --> 15:04.200]  функции.
[15:04.200 --> 15:05.200]  Вот.
[15:05.200 --> 15:06.200]  Чтобы как бы актуализировать, что ли, ваше представление,
[15:06.200 --> 15:07.200]  ну, как это работает.
[15:08.200 --> 15:12.640]  Значит, максимум, да, можно брать, ну, и там, понятно,
[15:12.640 --> 15:13.640]  можно брать композицию.
[15:13.640 --> 15:16.480]  Вот тут приведен один пример, их, понятное дело, довольно
[15:16.480 --> 15:22.240]  много, что если у вас функция от числа, то если она выпуклая
[15:22.240 --> 15:26.120]  и возрастает, то если вы на вход подадите результат
[15:26.120 --> 15:28.840]  действия выпуклой функции, то в результате у вас тоже
[15:28.840 --> 15:29.840]  будет выпуклая функция.
[15:29.840 --> 15:30.840]  Вот.
[15:30.840 --> 15:34.920]  Показывается это либо по определению, либо в случае,
[15:34.920 --> 15:36.960]  если вы накладываете еще какие-то ограничения
[15:36.960 --> 15:39.880]  на дифференцированность, то можно в критерии второго
[15:39.880 --> 15:40.880]  порядка воспользоваться.
[15:46.880 --> 15:47.880]  Возможно, нет.
[15:47.880 --> 15:49.960]  Там меньше либо равно же должно стоять.
[15:49.960 --> 15:50.960]  Поэтому...
[15:50.960 --> 15:53.960]  Ну, не убывает, да, как минимум.
[15:53.960 --> 15:57.960]  То есть линейная функция подходит, вот.
[15:57.960 --> 15:59.960]  Простой пример, чтобы себя проверить, как бы.
[15:59.960 --> 16:00.960]  Вот.
[16:00.960 --> 16:04.480]  Ну и да, в общем, их довольно много, тут можно, помимо скалярных
[16:04.520 --> 16:07.520]  композиций, можно изучать векторные композиции.
[16:07.520 --> 16:09.520]  То есть когда у нас результат одного...
[16:09.520 --> 16:12.520]  То есть, грубо говоря, когда вот такая вот ситуация,
[16:12.520 --> 16:15.520]  что у вас, как бы, одна функция переводит один вектор
[16:15.520 --> 16:18.520]  n-мерный в другой, там, m-мерный, потом этот m-мерный
[16:18.520 --> 16:21.520]  переходит какой-то в p-мерный, вот, и потом это все еще
[16:21.520 --> 16:23.520]  в какую-то функцию, которая скалярно возвращает.
[16:23.520 --> 16:25.520]  То есть, такая вот литвистая сложная композиция.
[16:25.520 --> 16:26.520]  Вот.
[16:26.520 --> 16:29.520]  Ну, пример можно посмотреть, типа, максимум линейной
[16:29.520 --> 16:30.520]  функций.
[16:30.560 --> 16:34.560]  Довольно выразительное семейство, потому что, ну,
[16:34.560 --> 16:36.560]  потому что вы можете любую функцию, как бы, приблизить
[16:36.560 --> 16:38.560]  набором подпирающих ломаных.
[16:38.560 --> 16:39.560]  Вот.
[16:39.560 --> 16:42.560]  И, в общем, тем самым приблизить, в некотором смысле, с помощью
[16:42.560 --> 16:43.560]  вот такого вот семейства.
[16:43.560 --> 16:44.560]  Вот.
[16:44.560 --> 16:45.560]  Ну, что у нас здесь есть?
[16:45.560 --> 16:46.560]  У нас есть...
[16:46.560 --> 16:47.560]  Да, давайте.
[16:47.560 --> 16:49.560]  У нас есть линейная функция, набор линейных функций,
[16:49.560 --> 16:50.560]  у нас есть максимум.
[16:50.560 --> 16:51.560]  Вот.
[16:51.560 --> 16:53.560]  Ну, линейная функция выпуклась, максимум сохранять
[16:53.560 --> 16:54.560]  выпуклась.
[16:54.560 --> 16:55.560]  По этому результате будет выпуклая функция.
[16:55.560 --> 16:56.560]  Вот.
[16:56.560 --> 16:58.560]  То есть тут проверка несложная.
[16:58.560 --> 16:59.560]  Вот.
[16:59.600 --> 17:02.600]  Если вы смотрите вот такую вот L1 регуляризацию линейнейших
[17:02.600 --> 17:04.600]  квадратов, то тут что у нас?
[17:04.600 --> 17:05.600]  Первая это сумма.
[17:05.600 --> 17:08.600]  Какие функции здесь стоят?
[17:08.600 --> 17:12.600]  Тут функция, константа положительная умножить на что-то выпуклое.
[17:12.600 --> 17:16.600]  Тут константа положительная умножить на квадрат от нормы,
[17:16.600 --> 17:18.600]  от афинного преобразования аргумента.
[17:18.600 --> 17:19.600]  Вот.
[17:19.600 --> 17:20.600]  Квадрат...
[17:20.600 --> 17:25.600]  Важный момент, что квадрат на положительных аргументах
[17:25.600 --> 17:28.600]  выпуклый и возрастает, поэтому вот это вот правило
[17:28.640 --> 17:29.640]  вот это вот работает.
[17:29.640 --> 17:30.640]  Вот.
[17:30.640 --> 17:34.640]  То есть если бы у вас был вот здесь вот была не норма,
[17:34.640 --> 17:39.640]  а что-то, знак чего вы не могли бы определить, то
[17:39.640 --> 17:40.640]  все бы перестало работать.
[17:40.640 --> 17:41.640]  Вот.
[17:41.640 --> 17:46.640]  Это, кстати, можно будет сейчас проверить.
[17:46.640 --> 17:47.640]  Вот.
[17:47.640 --> 17:49.640]  Ну вот еще такой более общий пример, что если
[17:49.640 --> 17:53.640]  у вас есть выпуклая функция f it, то взяв вот такую вот
[17:53.640 --> 17:57.640]  функцию, минус сумма логарифм от минуса f it, вы получите
[17:57.680 --> 18:00.680]  тоже выпуклую функцию, рекомендую это проверить
[18:00.680 --> 18:03.680]  с помощью критерии второго порядка, например, взяв
[18:03.680 --> 18:04.680]  явно десятку счетов.
[18:04.680 --> 18:07.680]  Это хорошее упражнение для того, чтобы вспомнить
[18:07.680 --> 18:12.680]  или потренироваться, дополнить на том, как это все
[18:12.680 --> 18:13.680]  дело происходит.
[18:13.680 --> 18:14.680]  Вот.
[18:14.680 --> 18:20.680]  Это полезно для того, чтобы когда у вас вот такое вот
[18:20.680 --> 18:23.680]  ограничение и ваш допустимое множество по сути дела
[18:23.720 --> 18:26.720]  ограничивается вот такими вот эксами, то вы можете
[18:26.720 --> 18:29.720]  как бы вот это ограничение перенести в целевую функцию
[18:29.720 --> 18:31.720]  с помощью вот такого вот дополнительного слагаемого,
[18:31.720 --> 18:36.720]  которое будет предотвращать при решении выход за пределы
[18:36.720 --> 18:37.720]  допустимого множества.
[18:37.720 --> 18:41.720]  Ну, просто потому что при f от x близких к нулю эта
[18:41.720 --> 18:46.720]  штука будет плюс бесконечностью, и вы заведомо
[18:46.720 --> 18:49.720]  попытаетесь не сильно близко к границе подходить.
[18:49.720 --> 18:52.720]  Понятны ли примеры?
[18:52.760 --> 18:55.760]  Окей.
[18:55.760 --> 18:58.760]  Да, ну и последний пример.
[18:58.760 --> 19:00.760]  Тут максимальное собственное значение у симметричной
[19:00.760 --> 19:01.760]  матрицы.
[19:01.760 --> 19:05.760]  Понятны ли, почему это выпуклая функция?
[19:05.760 --> 19:09.760]  Тут более сложная история.
[19:09.760 --> 19:14.760]  Ну, Suprema Maximum.
[19:14.760 --> 19:16.760]  Так, неплохо.
[19:16.760 --> 19:19.760]  А вот эта функция какая?
[19:19.800 --> 19:24.800]  Ну, гисян по матрице тяжело.
[19:24.800 --> 19:27.800]  Четырехмерный.
[19:27.800 --> 19:29.800]  А как вы будете определенноспроверять?
[19:29.800 --> 19:32.800]  Вам надо там сворачивать с любыми двумя матрицами.
[19:32.800 --> 19:33.800]  Тяжело.
[19:33.800 --> 19:36.800]  Можно проще.
[19:36.800 --> 19:39.800]  Когда мы обсуждали максимум, у нас было что?
[19:39.800 --> 19:42.800]  Нам надо было, чтобы для каждого индекса вот эта
[19:42.800 --> 19:45.800]  функция была выпуклая.
[19:45.800 --> 19:47.800]  Вот написано, да?
[19:47.840 --> 19:49.840]  Это понятно.
[19:49.840 --> 19:51.840]  Для Suprema все то же самое, только тут нужно, чтобы
[19:51.840 --> 19:55.840]  для каждого икса эта штука была выпуклая.
[19:55.840 --> 19:59.840]  А для каждого икса, это что за функция?
[20:05.840 --> 20:07.840]  Какие врядды?
[20:09.840 --> 20:13.840]  То есть вот это вот x фиксирован, и эта функция от матрицы.
[20:13.880 --> 20:17.880]  Каким свойством она обладает?
[20:25.880 --> 20:27.880]  Не, не, функция от матрицы еще раз.
[20:30.880 --> 20:32.880]  А переменная, да.
[20:32.880 --> 20:34.880]  В этом-то вопрос как бы.
[20:34.880 --> 20:36.880]  То есть все привыкли обычно, что вот когда идет
[20:36.880 --> 20:38.880]  такое, то матрица фиксирована, а x переменная.
[20:38.880 --> 20:40.880]  Поэтому эта штука квадратичная.
[20:40.880 --> 20:42.880]  Все сразу типа квадратичная, квадратичная.
[20:42.920 --> 20:44.920]  А у нас ситуация меняется, потому что мы хотим
[20:44.920 --> 20:48.920]  проанализировать вот это выражение на выпуклость.
[20:48.920 --> 20:50.920]  Но она линейная, конечно.
[20:50.920 --> 20:52.920]  Она линейная.
[20:52.920 --> 20:54.920]  Просто вы в силу того, что сюда поставьте
[20:54.920 --> 20:58.920]  αа плюс, что там, 1 минус αb,
[20:58.920 --> 21:00.920]  и у вас все распадется просто в сумму.
[21:02.920 --> 21:04.920]  Всем это видно.
[21:04.920 --> 21:05.920]  Окей.
[21:05.920 --> 21:07.920]  Поэтому эта штука линейная,
[21:07.920 --> 21:09.920]  линейная значит выпуклая,
[21:09.920 --> 21:11.920]  поэтому взять Suprema выпуклость не портит.
[21:12.920 --> 21:14.920]  А у нас, конечно, множество максимума.
[21:14.920 --> 21:16.920]  Ну он не максимум.
[21:16.920 --> 21:18.920]  Множество тут такое, ну типа.
[21:18.920 --> 21:20.920]  Да, потому что проблема в том,
[21:20.920 --> 21:22.920]  что мы все вместе стоим.
[21:22.920 --> 21:24.920]  Нет, проблем никаких нет.
[21:24.920 --> 21:26.920]  Да, но тут проблем никаких нет,
[21:26.920 --> 21:28.920]  потому что вот когда мы,
[21:28.920 --> 21:30.920]  если вот это вот показывать не совсем по определению,
[21:30.920 --> 21:32.920]  а через надграфики.
[21:32.920 --> 21:34.920]  Вам в многих семинарах про это рассказывали,
[21:34.920 --> 21:36.920]  что-нибудь про надграфики?
[21:36.920 --> 21:38.920]  Тишин? Да?
[21:38.920 --> 21:40.920]  Нет? Окей, я тогда расскажу.
[21:40.960 --> 21:42.960]  Ну вот как вот так показать
[21:42.960 --> 21:44.960]  через надграфики?
[21:44.960 --> 21:46.960]  Понятно или нет?
[21:50.960 --> 21:52.960]  А что надо рисовать?
[21:52.960 --> 21:54.960]  Вот эти футы, да?
[21:56.960 --> 21:58.960]  Так, а что дальше?
[22:03.960 --> 22:05.960]  Так, и что получится?
[22:06.000 --> 22:08.000]  Какое?
[22:10.000 --> 22:12.000]  Какое?
[22:12.000 --> 22:14.000]  Почему?
[22:14.000 --> 22:16.000]  Нет, может быть да, может быть нет,
[22:16.000 --> 22:18.000]  а аргументы-то какие?
[22:18.000 --> 22:20.000]  То есть тут важен не ответ, тут важен Путин, как бы.
[22:24.000 --> 22:26.000]  Да, через так,
[22:26.000 --> 22:28.000]  чтобы потом можно было обобщить на Suprema.
[22:30.000 --> 22:32.000]  Ну вот да, вот вопрос
[22:32.000 --> 22:34.000]  через надграфик, как это делает.
[22:34.040 --> 22:36.040]  Да, вот, правильно.
[22:36.040 --> 22:38.040]  То есть когда мы берем максимум,
[22:38.040 --> 22:40.040]  то мы пересекаем над графики вот этих функций.
[22:40.040 --> 22:42.040]  Это как раз то, что вы хотели закрашивать.
[22:42.040 --> 22:44.040]  Вот, а поскольку надграфик
[22:44.040 --> 22:46.040]  у каждого из вот этих вот ингредиентов
[22:46.040 --> 22:48.040]  выпуклый, поскольку сами функции
[22:48.040 --> 22:50.040]  выпуклые, то их пересечение будет
[22:50.040 --> 22:52.040]  выпуклым. А когда мы берем Suprema,
[22:52.040 --> 22:54.040]  то мы пересекаем бесконечную множество над графиков
[22:54.040 --> 22:56.040]  для каждого элемента.
[22:56.040 --> 22:58.040]  Ну и бесконечную множество
[22:58.040 --> 23:00.040]  мы можем пересекать, и выпуклость от этого
[23:00.040 --> 23:02.040]  не портится. Поэтому тут
[23:02.080 --> 23:04.080]  никаких проблем с Suprema нет.
[23:06.080 --> 23:08.080]  Это к тому, что иногда доказывать по определению
[23:08.080 --> 23:10.080]  может быть не всегда хорошо. Ну не всегда
[23:10.080 --> 23:12.080]  продуктивно для каких-то дальнейших
[23:12.080 --> 23:14.080]  общений. Вот.
[23:14.080 --> 23:16.080]  А есть ли понимание,
[23:16.080 --> 23:18.080]  как эту штуку представить в
[23:18.080 --> 23:20.080]  конической форме?
[23:24.080 --> 23:26.080]  В конической.
[23:26.080 --> 23:28.080]  Когда у вас минимизируются линейные функции
[23:28.080 --> 23:30.080]  при условии, что
[23:30.120 --> 23:32.120]  в каком условии-то?
[23:32.120 --> 23:34.120]  Ну там, линейное равенство и то,
[23:34.120 --> 23:36.120]  что искомый аргумент
[23:36.120 --> 23:38.120]  принадлежит некоторому конусу.
[23:52.120 --> 23:54.120]  То есть хотим условно, например,
[23:54.120 --> 23:56.120]  что сделать?
[23:56.120 --> 23:58.120]  Suprema был функционал?
[23:58.160 --> 24:00.160]  Это типа целевая функция,
[24:00.160 --> 24:02.160]  мы хотим записать минимум
[24:02.160 --> 24:04.160]  lambda max от некоторой
[24:04.160 --> 24:06.160]  матрицы.
[24:08.160 --> 24:10.160]  Так, наверное, это надо написать.
[24:13.160 --> 24:15.160]  Где тут моя доска?
[24:19.160 --> 24:21.160]  То есть хотим вот что сделать?
[24:25.160 --> 24:27.160]  Там A лежит в некоторой множестве,
[24:27.200 --> 24:28.200]  например, ну неважно,
[24:28.200 --> 24:30.200]  где-то лежит.
[24:30.200 --> 24:32.200]  Как вот это в конической форме записать?
[24:32.200 --> 24:34.200]  Давайте пока игнорировать вот это множество,
[24:34.200 --> 24:36.200]  я не хочу сейчас сильно заморачиваться,
[24:36.200 --> 24:38.200]  хочу просто вот этот значение записать в конической
[24:38.200 --> 24:40.200]  форме.
[24:40.200 --> 24:42.200]  Так, чтобы
[24:42.200 --> 24:44.200]  Ой.
[24:44.200 --> 24:46.200]  Было минимум, там
[24:46.200 --> 24:48.200]  zeta x
[24:48.200 --> 24:50.200]  a x равно b
[24:52.200 --> 24:54.200]  Вот так.
[24:54.200 --> 24:56.200]  То есть как первый шаг
[24:56.200 --> 24:58.200]  я сделал так, чтобы целевая функция
[24:58.200 --> 25:00.200]  стала линейной?
[25:00.200 --> 25:02.200]  Уже несколько раз обсуждали,
[25:04.200 --> 25:06.200]  что надо заменить
[25:06.200 --> 25:08.200]  и каким образом.
[25:24.200 --> 25:26.200]  То есть мы можем
[25:26.200 --> 25:28.200]  вкатить с паттерном
[25:28.200 --> 25:30.200]  и вкатить на паттерн x и z
[25:30.200 --> 25:32.200]  и на z и z.
[25:34.200 --> 25:36.200]  Ну там просто значение нет.
[25:38.200 --> 25:40.200]  То есть
[25:40.200 --> 25:42.200]  x и z и y, потому что
[25:42.200 --> 25:44.200]  a
[25:50.200 --> 25:52.200]  Ну сейчас мы у нас
[25:52.200 --> 25:54.200]  как?
[25:54.200 --> 25:56.200]  Ликтуйте.
[26:06.200 --> 26:08.200]  Сейчас погодите,
[26:08.200 --> 26:10.200]  минимум y, так,
[26:10.200 --> 26:12.200]  как что?
[26:18.200 --> 26:20.200]  Так.
[26:22.200 --> 26:24.200]  Ну почти.
[26:26.200 --> 26:28.200]  Ну я бы сказал
[26:28.200 --> 26:30.200]  даже не выпукло,
[26:30.200 --> 26:32.200]  потому что у нас с x
[26:32.200 --> 26:34.200]  некоторые проблемы есть.
[26:34.200 --> 26:36.200]  В частности, ну
[26:36.200 --> 26:38.200]  понятно, да?
[26:38.200 --> 26:40.200]  Ну типа
[26:40.200 --> 26:42.200]  норма x равна единице, это типа шар какой-то.
[26:42.200 --> 26:44.200]  Не выпукло множество,
[26:44.200 --> 26:46.200]  как минимум.
[26:46.200 --> 26:48.200]  Давайте чинить.
[26:48.200 --> 26:50.200]  Хороший вопрос.
[26:50.200 --> 26:52.200]  Куда делся максимум по x?
[26:56.200 --> 26:58.200]  Ну, видимо, хотели сделать следующее.
[26:58.200 --> 27:00.200]  Хотели сказать, что
[27:00.200 --> 27:02.200]  вот то, что вот здесь, вот это можно записать
[27:02.200 --> 27:04.200]  как минимум t
[27:04.200 --> 27:06.200]  при условии, что лямбда
[27:06.200 --> 27:08.200]  max от a меньше
[27:08.200 --> 27:10.200]  либо равно t.
[27:14.200 --> 27:16.200]  Понятно, что это одно и то же?
[27:16.200 --> 27:18.200]  Или нет?
[27:24.200 --> 27:26.200]  Да, нет.
[27:26.200 --> 27:28.200]  Руки подьмите, кому понятно.
[27:30.200 --> 27:32.200]  Громче?
[27:32.200 --> 27:34.200]  А, хорошо,
[27:34.200 --> 27:36.200]  давайте обсудим еще раз этот момент.
[27:36.200 --> 27:38.200]  Смотрите, когда мы ищем
[27:38.200 --> 27:40.200]  минимум функции,
[27:40.200 --> 27:42.200]  я, мне кажется, зарисовал эту картинку, но нарисую еще раз.
[27:42.200 --> 27:44.200]  Например, вот такой.
[27:44.200 --> 27:46.200]  То это наш x,
[27:46.200 --> 27:48.200]  это наш f от x.
[27:52.200 --> 27:54.200]  И мы ищем
[27:54.200 --> 27:56.200]  только по оси x минимум.
[27:56.200 --> 27:58.200]  Если мы делаем вот так,
[27:58.200 --> 28:00.200]  то мы ищем одновременно и x
[28:00.200 --> 28:02.200]  и значение t,
[28:02.200 --> 28:04.200]  чтобы t было как можно меньше,
[28:04.200 --> 28:06.200]  то есть f от x было как можно меньше,
[28:06.200 --> 28:08.200]  но x все еще был допустим.
[28:10.200 --> 28:12.200]  То есть мы как бы
[28:12.200 --> 28:14.200]  ищем и x и значения
[28:14.200 --> 28:16.200]  на всей плоскости,
[28:16.200 --> 28:18.200]  а не только на оси x.
[28:18.200 --> 28:20.200]  Поэтому мы делаем неравенство.
[28:20.200 --> 28:22.200]  Понятно?
[28:22.200 --> 28:24.200]  Ура.
[28:24.200 --> 28:26.200]  Ну смотрите, у нас что получилось,
[28:26.200 --> 28:28.200]  здесь уже что-то линейное, это прекрасно.
[28:28.200 --> 28:30.200]  Все видят, что это что-то линейное.
[28:30.200 --> 28:32.200]  Замечательно.
[28:32.200 --> 28:34.200]  Теперь давайте разберемся,
[28:34.200 --> 28:36.200]  как расписать вот это в виде
[28:36.200 --> 28:38.200]  некоторого конического ограничения.
[28:38.200 --> 28:40.200]  То есть эта штука какая-то
[28:40.200 --> 28:42.200]  нелинейная, существенно.
[28:44.200 --> 28:46.200]  Так?
[28:50.200 --> 28:52.200]  Все видят, что это нелинейная штука.
[28:52.200 --> 28:54.200]  Это максимум какая-то,
[28:54.200 --> 28:56.200]  страшное дело.
[29:00.200 --> 29:02.200]  Что делать?
[29:02.200 --> 29:04.200]  Что значит, что максимальное собственное значение
[29:04.200 --> 29:06.200]  матрицы А меньше либо равно, чем t?
[29:08.200 --> 29:10.200]  Вспомнить надо ли имя алгебру теперь?
[29:16.200 --> 29:18.200]  И какой конус у нас связан
[29:18.200 --> 29:20.200]  с матрицами там как-то?
[29:22.200 --> 29:24.200]  Ну,
[29:24.200 --> 29:26.200]  ну,
[29:26.200 --> 29:28.200]  ну,
[29:28.200 --> 29:30.200]  ну,
[29:30.200 --> 29:32.200]  ну,
[29:34.200 --> 29:36.200]  Хорошо. Какой конус связан с матрицами?
[29:38.200 --> 29:40.200]  Отлично. Положить на определенный симметричный матриц.
[29:40.200 --> 29:42.200]  Шикарно.
[29:42.200 --> 29:44.200]  Какая матрица должна быть симметричной
[29:44.200 --> 29:46.200]  положительно полуопределенной, чтобы это было
[29:46.200 --> 29:48.200]  выполнено? Которая будет зависеть
[29:48.200 --> 29:50.200]  от A и T?
[29:54.200 --> 29:56.200]  Громче?
[29:56.200 --> 29:58.200]  T на I минус A.
[29:58.200 --> 30:00.200]  Хорошая гипотеза. Давайте проверим.
[30:06.200 --> 30:08.200]  Вроде похоже на правду.
[30:08.200 --> 30:10.200]  Давайте проверим.
[30:10.200 --> 30:12.200]  Все увидели, почему это правда.
[30:16.200 --> 30:18.200]  Поднимите же, кто увидел.
[30:18.200 --> 30:20.200]  Два. Ну, три, наверное.
[30:22.200 --> 30:24.200]  Смотрите, что происходит со спектром,
[30:24.200 --> 30:26.200]  если мы умножаем, вычитаем из матрицы
[30:26.200 --> 30:28.200]  диагональную матрицу с
[30:28.200 --> 30:30.200]  одинаковым элементом на диагонали.
[30:34.200 --> 30:36.200]  Да, они смещаются на одно и то же
[30:36.200 --> 30:38.200]  число. Соответственно, если у нас
[30:38.200 --> 30:40.200]  максимальное собственное значение меньше
[30:40.200 --> 30:42.200]  T, то когда мы
[30:42.200 --> 30:44.200]  ну, там, условно A
[30:44.200 --> 30:46.200]  минус T берем,
[30:46.200 --> 30:48.200]  то у нас точно будет все отрицательное
[30:48.200 --> 30:50.200]  значение будут все.
[30:50.200 --> 30:52.200]  Поэтому эта штука будет отрицательно
[30:52.200 --> 30:54.200]  полуопределена.
[30:54.200 --> 30:56.200]  Ну, мы на минуту намножим, получим вот это.
[31:00.200 --> 31:02.200]  Так, получилась картинка?
[31:02.200 --> 31:04.200]  Или лучше расписать?
[31:06.200 --> 31:08.200]  Поднимите руки, кто хочет, чтобы я это расписал.
[31:10.200 --> 31:12.200]  Так, поднимите руки, кому все понятно.
[31:12.200 --> 31:14.200]  Так, ура.
[31:14.200 --> 31:16.200]  Вот, ну и соответственно, вот наша
[31:16.200 --> 31:18.200]  то есть T
[31:18.200 --> 31:20.200]  и минус A. Это что такое?
[31:20.200 --> 31:22.200]  Это лежит в нашем конусе.
[31:22.200 --> 31:24.200]  А сама по себе вот эта штука
[31:24.200 --> 31:26.200]  это, ну, понятно, что
[31:26.200 --> 31:28.200]  это, наверное, да?
[31:28.200 --> 31:30.200]  Или нет?
[31:34.200 --> 31:36.200]  Ну, вот это линейно-матричное
[31:36.200 --> 31:38.200]  не нравится, по сути дела, когда мы
[31:38.200 --> 31:40.200]  записываем, типа,
[31:40.200 --> 31:42.200]  наши константы умножить на некоторые
[31:42.200 --> 31:44.200]  константные матрицы и больше либо равно нуля.
[31:44.200 --> 31:46.200]  Как вот двойственная задача в прошлой лекции.
[31:46.200 --> 31:48.200]  Давайте, я, наверное, не зря ее
[31:48.200 --> 31:50.200]  открыл,
[31:50.200 --> 31:52.200]  быстренько сейчас промотаю,
[31:52.200 --> 31:54.200]  вот так вот. Ну вот, ровно вот то,
[31:54.200 --> 31:56.200]  что мы здесь получали, вот.
[31:58.200 --> 32:00.200]  Понятно, да?
[32:00.200 --> 32:02.200]  Откуда взялось?
[32:02.200 --> 32:04.200]  То есть тут у нас T, а потом
[32:04.200 --> 32:06.200]  все остальные, ой, все остальные матрицы, которые были,
[32:06.200 --> 32:08.200]  они
[32:08.200 --> 32:10.200]  да,
[32:10.200 --> 32:12.200]  они образовались вот здесь.
[32:12.200 --> 32:14.200]  Что это?
[32:14.200 --> 32:16.200]  Они образовались, тут минус Y, как раз стоит,
[32:16.200 --> 32:18.200]  и это все конечная задача.
[32:18.200 --> 32:20.200]  То есть мы минимизируем T,
[32:20.200 --> 32:22.200]  то есть C транспонирует
[32:22.200 --> 32:24.200]  на некоторый большой вектор,
[32:24.200 --> 32:26.200]  длинный, при вот этом условии.
[32:26.200 --> 32:28.200]  При этом T у нас здесь как
[32:28.200 --> 32:30.200]  число, а матрица A
[32:30.200 --> 32:32.200]  у нас как матрица.
[32:32.200 --> 32:34.200]  Если вам
[32:34.200 --> 32:36.200]  не очень понятно, почему тут,
[32:36.200 --> 32:38.200]  как это, почему вот это
[32:38.200 --> 32:40.200]  похоже на вот это, хотя тут вроде одна
[32:40.200 --> 32:42.200]  и та же размерность, но вот это
[32:42.200 --> 32:44.200]  вот выражение, его же можно вытянуть в один большой
[32:44.200 --> 32:46.200]  вектор.
[32:48.200 --> 32:50.200]  Понятно, да?
[32:50.200 --> 32:52.200]  Или нет?
[32:52.200 --> 32:54.200]  Вот это.
[32:54.200 --> 32:56.200]  То есть это T
[32:56.200 --> 32:58.200]  на единичную матрицу, это типа
[32:58.200 --> 33:00.200]  N квадрат, вектор длины
[33:00.200 --> 33:02.200]  N квадрат, и вы из него вычитаете
[33:02.200 --> 33:04.200]  тоже вектор длины N квадрат.
[33:04.200 --> 33:06.200]  И на него просто хитрые
[33:06.200 --> 33:08.200]  ограничения наложены, которые
[33:08.200 --> 33:10.200]  сильно нелинейные, но записываются таким вот
[33:10.200 --> 33:12.200]  образом.
[33:12.200 --> 33:14.200]  А здесь в C сидит тоже
[33:14.200 --> 33:16.200]  N квадрат плюс одно число, которое
[33:16.200 --> 33:18.200]  соответственно
[33:18.200 --> 33:20.200]  нули там, где матрица A
[33:20.200 --> 33:22.200]  и единицы там, где T.
[33:24.200 --> 33:26.200]  Получается транспонированный
[33:26.200 --> 33:28.200]  на некоторый большой вектор.
[33:30.200 --> 33:32.200]  Поделитесь, кто понял такое
[33:32.200 --> 33:34.200]  объяснение.
[33:34.200 --> 33:36.200]  Так, не очень.
[33:36.200 --> 33:38.200]  Ну, смотрите,
[33:38.200 --> 33:40.200]  тут, видите, один конус, тут
[33:40.200 --> 33:42.200]  одна и та же переменная должна фигурировать.
[33:42.200 --> 33:44.200]  А тут у нас фигурирует
[33:44.200 --> 33:46.200]  T, а тут фигурирует какая-то матрица еще,
[33:46.200 --> 33:48.200]  которую мы ищем.
[33:48.200 --> 33:50.200]  Вот как это связать?
[33:50.200 --> 33:52.200]  Связывается это очень просто. Вот эта
[33:52.200 --> 33:54.200]  штука рассматривается как
[33:54.200 --> 33:56.200]  операция, условно, над длинными
[33:56.200 --> 33:58.200]  векторизованными матрицами.
[33:58.200 --> 34:00.200]  И тогда для вектора C у нас есть
[34:00.200 --> 34:02.200]  просто N квадрат нулевых компонент,
[34:02.200 --> 34:04.200]  чтобы убрать всю зависимость от
[34:04.200 --> 34:06.200]  матрицы A и оставить
[34:06.200 --> 34:08.200]  единичку только там, где элемент
[34:08.200 --> 34:10.200]  для числа T, который мы
[34:10.200 --> 34:12.200]  также ищем.
[34:12.200 --> 34:14.200]  Стало ли полегче?
[34:14.200 --> 34:16.200]  Стало полегче.
[34:16.200 --> 34:18.200]  Ну, хорошо. Так, ладно, это было некоторое
[34:18.200 --> 34:20.200]  отступление, не знаю, насколько оно было нужно,
[34:20.200 --> 34:22.200]  но, наверное, полезно. Так,
[34:22.200 --> 34:24.200]  где слайд? Вот.
[34:24.200 --> 34:26.200]  Да, короче говоря,
[34:26.200 --> 34:28.200]  это к тому, каким образом
[34:28.200 --> 34:30.200]  подобного рода задачи можно переписать в
[34:30.200 --> 34:32.200]  кодической форме. Сейчас далее будет
[34:32.200 --> 34:34.200]  данный общий рецепт того, как это
[34:34.200 --> 34:36.200]  делается и почему это можно делать
[34:36.200 --> 34:38.200]  почти на лету и автоматически.
[34:38.200 --> 34:40.200]  Да, но
[34:40.200 --> 34:42.200]  сначала, перед тем, как
[34:42.200 --> 34:44.200]  переходить к тому, как это все делать
[34:44.200 --> 34:46.200]  на лету и автоматически, надо сказать пару слов
[34:46.200 --> 34:48.200]  о том, в общем, в целом, как решать задачу
[34:48.200 --> 34:50.200]  к оптимизации, если она у вас
[34:52.200 --> 34:54.200]  если она у вас есть. Значит,
[34:54.200 --> 34:56.200]  первый путь, самый, наверное,
[34:56.200 --> 34:58.200]  понятный, использовать некоторые
[34:58.200 --> 35:00.200]  стандартные солверы для определенного
[35:00.200 --> 35:02.200]  типа задач. То есть, условно говоря,
[35:02.200 --> 35:04.200]  вот вы, у вас есть какая-то задача,
[35:04.200 --> 35:06.200]  вы понимаете, ага, это задача линопрограммирования
[35:06.200 --> 35:08.200]  или это задача квадратичного
[35:08.200 --> 35:10.200]  программирования. Или у нас что-то полуопределенное
[35:10.200 --> 35:12.200]  в одном из видов,
[35:12.200 --> 35:14.200]  вот таком вот
[35:14.200 --> 35:16.200]  или вот таком вот, например.
[35:16.200 --> 35:18.200]  Вот тогда,
[35:18.200 --> 35:20.200]  окей, есть написанное, просто
[35:20.200 --> 35:22.200]  гуглите lpsolver,
[35:22.200 --> 35:24.200]  у вас выпадет
[35:24.200 --> 35:26.200]  огромное количество реализации различных
[35:26.200 --> 35:28.200]  языков программирования библиотек,
[35:28.200 --> 35:30.200]  вы говорите, ага, вот мне нужно
[35:30.200 --> 35:32.200]  условно на плюсах,
[35:32.200 --> 35:34.200]  на питоне, на скале,
[35:34.200 --> 35:36.200]  на чем хотите, вот, на джули,
[35:36.200 --> 35:38.200]  берете,
[35:38.200 --> 35:40.200]  скачиваете
[35:40.200 --> 35:42.200]  и отправляете ваши данные,
[35:42.200 --> 35:44.200]  ваши задачи в этот солвер, он выдает ответ.
[35:44.200 --> 35:46.200]  Проблема, а, ну точнее, пока не проблема,
[35:46.200 --> 35:48.200]  пока плюсы довольно
[35:48.200 --> 35:50.200]  легко.
[35:50.200 --> 35:52.200]  Не надо ничего писать, все за вас уже написали,
[35:52.200 --> 35:54.200]  вам просто надо правильно запустить.
[35:54.200 --> 35:56.200]  Это, возможно, тоже не всегда легко,
[35:56.200 --> 35:58.200]  но, по крайней мере, это исключительно
[35:58.200 --> 36:00.200]  работа с тем, как правильно представить,
[36:00.200 --> 36:02.200]  да, ну, в общем, да, это вот
[36:02.200 --> 36:04.200]  собственно второй пункт, что
[36:04.200 --> 36:06.200]  солвер жестко фиксирует форму задачи.
[36:06.200 --> 36:08.200]  То есть, если у вас
[36:08.200 --> 36:10.200]  линейное программирование в форме
[36:10.200 --> 36:12.200]  ограничений AX равно B
[36:12.200 --> 36:14.200]  и X больше либо равно нуля,
[36:14.200 --> 36:16.200]  а солвер требует задачу
[36:16.200 --> 36:18.200]  в виде AX меньше либо равно B,
[36:18.200 --> 36:20.200]  то все, всю работа
[36:20.200 --> 36:22.200]  по превращению задачи
[36:22.200 --> 36:24.200]  из одного вида в другой вы берете на себя.
[36:24.200 --> 36:26.200]  Вот, это некоторая
[36:26.200 --> 36:28.200]  проблема, потому что, в общем,
[36:28.200 --> 36:30.200]  в случае, вот, все, что мы видели
[36:30.200 --> 36:32.200]  вот здесь,
[36:34.200 --> 36:36.200]  вот,
[36:36.200 --> 36:38.200]  оно, ну, сложно сказать,
[36:38.200 --> 36:40.200]  что это стандартный вид некоторый,
[36:40.200 --> 36:42.200]  то есть, это пока что и не линейное
[36:42.200 --> 36:44.200]  программирование, и не квадратичное,
[36:44.200 --> 36:46.200]  в общем, в случае, то есть, это что-то странное
[36:46.200 --> 36:48.200]  пока что, вот, поэтому есть некоторые
[36:48.200 --> 36:50.200]  зазоры между той общей формой, о которой мы
[36:50.200 --> 36:52.200]  говорили, и теми стандартными солверами, которые,
[36:52.200 --> 36:54.200]  ну, для тех задач, которые мы
[36:54.200 --> 36:56.200]  до этого обсуждали, как пример из задач
[36:56.200 --> 36:58.200]  выпуска оптимизации и
[36:58.200 --> 37:00.200]  смотрели на то, каким классом они относятся.
[37:00.200 --> 37:02.200]  Вот, значит,
[37:02.200 --> 37:04.200]  понятно, что
[37:04.200 --> 37:06.200]  вот это все дело
[37:06.200 --> 37:08.200]  сделано довольно долго
[37:08.200 --> 37:10.200]  и упорно большим количеством разработчиков,
[37:10.200 --> 37:12.200]  вот, поэтому, значит,
[37:12.200 --> 37:14.200]  считается, что
[37:14.200 --> 37:16.200]  то, как долго
[37:16.200 --> 37:18.200]  и упорно вот это разрабатывать,
[37:18.200 --> 37:20.200]  окупается тем, чтобы много людей этим может воспользоваться.
[37:20.200 --> 37:22.200]  Вот, то есть, некоторая
[37:22.200 --> 37:24.200]  огромная махина,
[37:24.200 --> 37:26.200]  которую вы, скорее всего, смотреть не будете,
[37:26.200 --> 37:28.200]  но вам надо как бы научиться
[37:28.200 --> 37:30.200]  грамотно этим пользоваться.
[37:30.200 --> 37:32.200]  Вот, второй подход
[37:32.200 --> 37:34.200]  это вы увидите задачу
[37:34.200 --> 37:36.200]  и начинаете думать, так, как же мне ее решить?
[37:36.200 --> 37:38.200]  Вот, придумываете какой-то свой метод,
[37:38.200 --> 37:40.200]  реализуете, проверяете корректность
[37:40.200 --> 37:42.200]  проблемы, трудоемко,
[37:42.200 --> 37:44.200]  вы можете получить
[37:44.200 --> 37:46.200]  эффективность для одной конкретной задачи,
[37:46.200 --> 37:48.200]  при этом, если у вас там что-то поменяет, все может
[37:48.200 --> 37:50.200]  сломаться. Вот.
[37:50.200 --> 37:52.200]  Опять же, компромиссный вариант между этими
[37:52.200 --> 37:54.200]  двумя, то есть, один это
[37:54.200 --> 37:56.200]  использовать уже что-то написанное,
[37:56.200 --> 37:58.200]  но оно написано не для вашей задачи, а для
[37:58.200 --> 38:00.200]  другой, ну, в другой форме, как минимум.
[38:00.200 --> 38:02.200]  Вот, и вам нужно как-то
[38:02.200 --> 38:04.200]  что-то там, как-то ее подкрутить так, чтобы она
[38:04.200 --> 38:06.200]  стала, чтобы те параметры, которые принимают
[38:06.200 --> 38:08.200]  функции solve, они бы
[38:08.200 --> 38:10.200]  соответствовали тому, что вам надо.
[38:10.200 --> 38:12.200]  Вот. И тому,
[38:12.200 --> 38:14.200]  что, типа, все писать с нуля, ничего
[38:14.200 --> 38:16.200]  и ни на кого не смотрим, причисали статью,
[38:16.200 --> 38:18.200]  реализовали кое-как
[38:18.200 --> 38:20.200]  с какими-то ошибками, не ошибками,
[38:20.200 --> 38:22.200]  все проблемы, как на все грабли
[38:22.200 --> 38:24.200]  по дороге наступили, которые вот здесь вот
[38:24.200 --> 38:26.200]  уже за вас решили. Вот.
[38:26.200 --> 38:28.200]  И в конце что-то получили, но
[38:28.200 --> 38:30.200]  потратили кучу времени на разработку, на
[38:30.200 --> 38:32.200]  отлаживание, одна задача решена,
[38:32.200 --> 38:34.200]  другая задача чуть-чуть другая пришла,
[38:34.200 --> 38:36.200]  я не понял, что делать. Вот.
[38:36.200 --> 38:38.200]  Компромиссный
[38:38.200 --> 38:40.200]  вариант это преобразовывать
[38:40.200 --> 38:42.200]  вот задачу, которая вам пришла вот здесь,
[38:42.200 --> 38:44.200]  вот, к некоторому стандартному виду,
[38:44.200 --> 38:46.200]  который бы решался вот этими solver'ами.
[38:46.200 --> 38:48.200]  Вот.
[38:48.200 --> 38:50.200]  Как это делается? Да,
[38:50.200 --> 38:52.200]  перед тем, как это делается. Значит, множество задач,
[38:52.200 --> 38:54.200]  которые мы можем решить вот этими штуками,
[38:54.200 --> 38:56.200]  расширяется, преобразование,
[38:56.200 --> 38:58.200]  которое вы, в принципе, можете делать,
[38:58.200 --> 39:00.200]  может быть довольно сложным,
[39:00.200 --> 39:02.200]  неприятным, громоздким, сейчас посмотрим,
[39:02.200 --> 39:04.200]  к чему это может привести. Вот.
[39:04.200 --> 39:06.200]  И, в принципе, этом
[39:06.200 --> 39:08.200]  не всегда, то есть
[39:08.200 --> 39:10.200]  это может быть не совсем тривиальное
[39:10.200 --> 39:12.200]  действие, которое,
[39:12.200 --> 39:14.200]  то есть, есть методы, которые автоматически это
[39:14.200 --> 39:16.200]  делают, за счет того,
[39:16.200 --> 39:18.200]  что они делают это автоматически,
[39:18.200 --> 39:20.200]  приходится платить, возможно, некоторой избуточностью.
[39:20.200 --> 39:22.200]  Вот. Но, как бы, вот эта вот
[39:22.200 --> 39:24.200]  громоздкость не всегда
[39:24.200 --> 39:26.200]  является большой проблемой.
[39:26.200 --> 39:28.200]  Так, ну давайте пять минут перерыв,
[39:28.200 --> 39:30.200]  и потом продолжим. Тут как раз там,
[39:30.200 --> 39:32.200]  ну да, примерно половина. Немножко
[39:32.200 --> 39:34.200]  похоже
[39:34.200 --> 39:36.200]  на вот это,
[39:36.200 --> 39:38.200]  вот, но, в общем,
[39:38.200 --> 39:40.200]  как бы, они не заточены
[39:40.200 --> 39:42.200]  под конкретный вид задачи,
[39:42.200 --> 39:44.200]  но заточены под ее,
[39:44.200 --> 39:46.200]  как бы, класс. То есть, словно там,
[39:46.200 --> 39:48.200]  с ограничениями задач или без ограничений,
[39:48.200 --> 39:50.200]  там, какие, какого рода
[39:50.200 --> 39:52.200]  ограничения. Про часть из них мы поговорим
[39:52.200 --> 39:54.200]  в дальнейших, в дальнейших лекциях.
[39:54.200 --> 39:56.200]  Вот. Но, в общем,
[39:56.200 --> 39:58.200]  вот это про вот это и вот это говорить
[39:58.200 --> 40:00.200]  не будем, про максимальные методы поговорим.
[40:00.200 --> 40:02.200]  Вот. В основном, они были разработаны
[40:02.200 --> 40:04.200]  в шестидесятых-семидесятых годах
[40:04.200 --> 40:06.200]  в Советском Союзе. Подробнее вот здесь
[40:06.200 --> 40:08.200]  написано довольно хорошо.
[40:08.200 --> 40:10.200]  Вот. Можете по слуге пройти, там будет
[40:10.200 --> 40:12.200]  некоторый документ. Вот.
[40:12.200 --> 40:14.200]  Значит, универсальные методы
[40:14.200 --> 40:16.200]  для задачи
[40:16.200 --> 40:18.200]  оптимизации, есть ли какие-то функции
[40:18.200 --> 40:20.200]  недиференцируемые, ничего страшного, они с этим
[40:20.200 --> 40:22.200]  кое-как, как-то там справятся.
[40:22.200 --> 40:24.200]  Вот. Значит, металлипсоид
[40:24.200 --> 40:26.200]  знаменит тем, что с помощью
[40:26.200 --> 40:28.200]  него показали полинамиальность
[40:28.200 --> 40:30.200]  доза членов программирования.
[40:30.200 --> 40:32.200]  Вот. Впервые, там,
[40:32.200 --> 40:34.200]  семидесятый какой-то год.
[40:34.200 --> 40:36.200]  Про это еще, там, когда будет лекция про линейное
[40:36.200 --> 40:38.200]  программирование, более подробно поговорим.
[40:38.200 --> 40:40.200]  Вот. Но на практике не очень эффективен.
[40:40.200 --> 40:42.200]  В общем, они, вот эти два, они на практике
[40:42.200 --> 40:44.200]  так. Есть некоторые
[40:44.200 --> 40:46.200]  недостатки. Вот.
[40:46.200 --> 40:48.200]  Значит, более продвинутые
[40:48.200 --> 40:50.200]  и полезные с практической точки
[40:50.200 --> 40:52.200]  зрения методы называются методами внутренней точки.
[40:52.200 --> 40:54.200]  Вот. Они работают
[40:54.200 --> 40:56.200]  значит, с ограничениями. Вот.
[40:56.200 --> 40:58.200]  Вот тут вот есть книжка,
[40:58.200 --> 41:00.200]  девятьдесят четвертый год. Есть Рев Немировский.
[41:00.200 --> 41:02.200]  Тоже советские математики.
[41:02.200 --> 41:04.200]  Юрий Евгеньевич сейчас
[41:04.200 --> 41:06.200]  профессор в
[41:06.200 --> 41:08.200]  Левине, в Бельгии.
[41:08.200 --> 41:10.200]  Немировский в Джорджи
[41:10.200 --> 41:12.200]  Атехе в США.
[41:12.200 --> 41:14.200]  Вот. Девятьдесят четвертый год. Можете посмотреть.
[41:14.200 --> 41:16.200]  Там куча цитирований. Все
[41:16.200 --> 41:18.200]  ими очень сильно пользуются.
[41:18.200 --> 41:20.200]  Вот. Обзор более понятный.
[41:20.200 --> 41:22.200]  И вот я не уверен, доступно ли
[41:22.200 --> 41:24.200]  вот это для скачивания. Вот это точно
[41:24.200 --> 41:26.200]  доступно.
[41:26.200 --> 41:28.200]  Вот. Важные отличия этих методов в том,
[41:28.200 --> 41:30.200]  что они применяются для гладких задач.
[41:30.200 --> 41:32.200]  Вот. Для гладких функций.
[41:32.200 --> 41:34.200]  И задач в конической форме.
[41:34.200 --> 41:36.200]  То есть тех задач, про которые мы
[41:36.200 --> 41:38.200]  до этого, которые мы до этого
[41:38.200 --> 41:40.200]  обсуждали. То есть линейное программирование,
[41:40.200 --> 41:42.200]  конусы второго порядка, полупределенная
[41:42.200 --> 41:44.200]  итерация. Вот.
[41:44.200 --> 41:46.200]  Очень эффективный метод.
[41:46.200 --> 41:48.200]  Удивительно, но в зависимости...
[41:48.200 --> 41:50.200]  То есть нужно всего лишь несколько
[41:50.200 --> 41:52.200]  десятков итераций обычно.
[41:52.200 --> 41:54.200]  И это количество
[41:54.200 --> 41:56.200]  итераций растет
[41:56.200 --> 41:58.200]  в зависимости
[41:58.200 --> 42:00.200]  от размера, с ростом
[42:00.200 --> 42:02.200]  размерся задачи, чуть ли не там, типа, ну, плюс пять.
[42:02.200 --> 42:04.200]  Не знаю. Размер нас увеличил
[42:04.200 --> 42:06.200]  в десять раз, он там, типа, плюс
[42:06.200 --> 42:08.200]  десять итераций. Вот. Ну, то есть она
[42:08.200 --> 42:10.200]  очень... Методы очень
[42:10.200 --> 42:12.200]  не очень, точнее, чувствительны
[42:12.200 --> 42:14.200]  к тому, какая разбирательная вход приходит.
[42:14.200 --> 42:16.200]  Вот. Я надеюсь, что мы успеем
[42:16.200 --> 42:18.200]  все-таки поговорить о том, как они строятся
[42:18.200 --> 42:20.200]  и какие у них у этих методов есть свойства.
[42:20.200 --> 42:22.200]  Вот. Идейно
[42:22.200 --> 42:24.200]  они довольно понятные.
[42:24.200 --> 42:26.200]  Когда начинает... Если начинает
[42:26.200 --> 42:28.200]  разбираться в том, как это
[42:28.200 --> 42:30.200]  эффективно реализовывать, там как бы отдельный
[42:30.200 --> 42:32.200]  курс можно про это, наверное, прочитать. Вот.
[42:32.200 --> 42:34.200]  Какие все толкости реализации вот этих методов
[42:34.200 --> 42:36.200]  для вот такого рода задач.
[42:36.200 --> 42:38.200]  Вот. К счастью, если вам нужно просто этим
[42:38.200 --> 42:40.200]  воспользоваться, есть готовые пакеты, где все это реализовано,
[42:40.200 --> 42:42.200]  вы просто нажимаете кнопку solve
[42:42.200 --> 42:44.200]  для правильной записи, и все у вас все получается.
[42:44.200 --> 42:46.200]  Вот. Каждая итерация
[42:46.200 --> 42:48.200]  требует решения некоторой блокчины
[42:48.200 --> 42:50.200]  или линейной системы. Откуда наберется,
[42:50.200 --> 42:52.200]  тоже поговорим. Вот.
[42:52.200 --> 42:54.200]  Значит, в чем проблема
[42:54.200 --> 42:56.200]  применения подобного рода методов в том, что
[42:56.200 --> 42:58.200]  например, вот у вас задача, типа, негладкая.
[42:58.200 --> 43:00.200]  Потому что есть первая норма, которая
[43:00.200 --> 43:02.200]  не является гладкой функцией.
[43:02.200 --> 43:04.200]  Поскольку равна сумме
[43:04.200 --> 43:06.200]  модулей входного
[43:06.200 --> 43:08.200]  вектора.
[43:08.200 --> 43:10.200]  Что предлагается сделать?
[43:10.200 --> 43:12.200]  Предлагается, да, все выпукло, но F негладкая.
[43:12.200 --> 43:14.200]  Предлагается поменять задачу
[43:14.200 --> 43:16.200]  так, чтобы она стала гладкой.
[43:16.200 --> 43:18.200]  Каким образом
[43:18.200 --> 43:20.200]  это делается?
[43:20.200 --> 43:22.200]  Как сделать так, чтобы
[43:22.200 --> 43:24.200]  задача стала гладкой,
[43:24.200 --> 43:26.200]  а никакой негладкости не было?
[43:26.200 --> 43:28.200]  Тут, кстати, тяжело на X.
[43:28.200 --> 43:30.200]  Sorry за опечатку.
[43:30.200 --> 43:32.200]  Прости.
[43:32.200 --> 43:34.200]  Так, а понятно,
[43:34.200 --> 43:36.200]  что было сказано до этого-то?
[43:36.200 --> 43:38.200]  Везде.
[43:44.200 --> 43:46.200]  Что в квадрат возвести?
[43:46.200 --> 43:48.200]  И что у вас будет?
[43:48.200 --> 43:50.200]  У вас будет там произведение модулей.
[43:50.200 --> 43:52.200]  И поздравления.
[43:56.200 --> 43:58.200]  Не, погодите, ну, задач уметь нельзя.
[43:58.200 --> 44:00.200]  Надо получить решение вот этой задачи.
[44:00.200 --> 44:02.200]  Но какие-то эквивалентные преобразования
[44:02.200 --> 44:04.200]  провести так, чтобы
[44:04.200 --> 44:06.200]  стала гладкой.
[44:08.200 --> 44:10.200]  Что делать?
[44:20.200 --> 44:22.200]  Ну да, на самом деле
[44:22.200 --> 44:24.200]  вводим переменную T.
[44:24.200 --> 44:26.200]  Говорим, что первая норма X
[44:26.200 --> 44:28.200]  меньше либо равна T, ну а дальше
[44:28.200 --> 44:30.200]  все компоненты
[44:30.200 --> 44:32.200]  по значению
[44:32.200 --> 44:34.200]  каждой компоненты от −T
[44:34.200 --> 44:36.200]  до T.
[44:36.200 --> 44:38.200]  Получаем, тут все выпукло,
[44:38.200 --> 44:40.200]  тут выпукло.
[44:40.200 --> 44:42.200]  Что оказалось?
[44:42.200 --> 44:44.200]  Оказалось, что количество переменных
[44:44.200 --> 44:46.200]  увеличилось в два раза
[44:46.200 --> 44:48.200]  и ничего ограничения появились.
[44:48.200 --> 44:50.200]  Но задача стала гладкой.
[44:52.200 --> 44:54.200]  Важно, что
[44:54.200 --> 44:56.200]  решив одну задачу, мы получаем решение
[44:56.200 --> 44:58.200]  о следующей задаче.
[44:58.200 --> 45:00.200]  И вспоминаем, что для медно-внутренней точки
[45:00.200 --> 45:02.200]  количества переменных
[45:02.200 --> 45:04.200]  в большой зависимости нет в числе
[45:04.200 --> 45:06.200]  итераций.
[45:06.200 --> 45:08.200]  Поэтому что хоть так,
[45:08.200 --> 45:10.200]  что N, что 2,
[45:10.200 --> 45:12.200]  в целом будем считать, что
[45:12.200 --> 45:14.200]  некритично.
[45:14.200 --> 45:16.200]  Зато можем решить
[45:16.200 --> 45:18.200]  плюс-минус,
[45:18.200 --> 45:20.200]  можем сделать это все
[45:20.200 --> 45:22.200]  почти что автоматически.
[45:22.200 --> 45:24.200]  То есть, как это работает?
[45:24.200 --> 45:26.200]  Есть некоторые выпуклые задачи.
[45:26.200 --> 45:28.200]  Далее делаем некоторые
[45:28.200 --> 45:30.200]  преобразования этой задачи
[45:30.200 --> 45:32.200]  квалентные.
[45:32.200 --> 45:34.200]  ПК является такой задачей,
[45:34.200 --> 45:36.200]  для которой применимы методы внутренней точки.
[45:38.200 --> 45:40.200]  Решаем
[45:40.200 --> 45:42.200]  эту задачу медно-внутренней точки,
[45:42.200 --> 45:44.200]  который зашит где-то
[45:44.200 --> 45:46.200]  вот здесь.
[45:48.200 --> 45:50.200]  Где-то вот здесь, в стандартном солдере.
[45:54.200 --> 45:56.200]  И получив решение,
[45:56.200 --> 45:58.200]  поскольку мы знаем,
[45:58.200 --> 46:00.200]  какие здесь были преобразования,
[46:00.200 --> 46:02.200]  мы просто из решения задачи ПК
[46:02.200 --> 46:04.200]  получаем решение по ноль.
[46:08.200 --> 46:10.200]  Вот здесь, понятное дело,
[46:10.200 --> 46:12.200]  может быть больше ограничений,
[46:12.200 --> 46:14.200]  переменных, все что хотите,
[46:14.200 --> 46:16.200]  но важный момент,
[46:16.200 --> 46:18.200]  что вот правила преобразования,
[46:18.200 --> 46:20.200]  которые мы здесь делаем,
[46:20.200 --> 46:22.200]  мы знаем, как их реализовывать
[46:22.200 --> 46:24.200]  эффективно.
[46:24.200 --> 46:26.200]  Вот здесь у нас появилась единичная матрица
[46:26.200 --> 46:28.200]  или что-нибудь еще там,
[46:28.200 --> 46:30.200]  мы знаем, что там будет единичная матрица
[46:30.200 --> 46:32.200]  для этого блока переменных,
[46:32.200 --> 46:34.200]  и мы ее явно не храним.
[46:34.200 --> 46:36.200]  Мы просто говорим, что действие этой матрицы на вектор
[46:36.200 --> 46:38.200]  это он сам,
[46:38.200 --> 46:40.200]  и когда нам нужно решать какую-то систему
[46:40.200 --> 46:42.200]  с блочной матрицей, с соответствующими блоками,
[46:42.200 --> 46:44.200]  то мы не формируем ее явно,
[46:44.200 --> 46:46.200]  мы просто, грубо говоря,
[46:46.200 --> 46:48.200]  индексацию правильно прописываем,
[46:48.200 --> 46:50.200]  где что у нас находится.
[46:50.200 --> 46:52.200]  И все довольно эффективно делается.
[46:52.200 --> 46:54.200]  Значит,
[46:54.200 --> 46:56.200]  соответственно,
[46:56.200 --> 46:58.200]  важный момент, что
[46:58.200 --> 47:00.200]  правила преобразования для выпуклых функций
[47:00.200 --> 47:02.200]  у нас порождает преобразование
[47:02.200 --> 47:04.200]  для задач. То есть то,
[47:04.200 --> 47:06.200]  что мы делали для функций,
[47:06.200 --> 47:08.200]  автоматически приводит к преобразованию
[47:08.200 --> 47:10.200]  из П0 в ПК.
[47:10.200 --> 47:12.200]  Был у нас максимум,
[47:12.200 --> 47:14.200]  то есть, условно, видим максимум,
[47:14.200 --> 47:16.200]  вводим новую переменную, добавляем ограничения.
[47:16.200 --> 47:18.200]  Все, условно, алгоритмически делается
[47:18.200 --> 47:20.200]  абсолютно понятно.
[47:20.200 --> 47:22.200]  Увидели композицию,
[47:22.200 --> 47:24.200]  вводим новую переменную,
[47:24.200 --> 47:26.200]  добавляем ограничения.
[47:30.200 --> 47:32.200]  У нас стало h от t
[47:32.200 --> 47:34.200]  и добавилась переменная.
[47:34.200 --> 47:36.200]  То есть разносим композицию.
[47:38.200 --> 47:40.200]  Ну, а для h от t
[47:40.200 --> 47:42.200]  у нас, во-первых, скалярная функция,
[47:42.200 --> 47:44.200]  для нее можно сделать то же самое только для t.
[47:44.200 --> 47:46.200]  Еще одну переменную ввести, условно, s
[47:46.200 --> 47:48.200]  и сказать, что у нас тут вместо h от t
[47:48.200 --> 47:50.200]  s и h от t меньше любовной s.
[47:50.200 --> 47:52.200]  Вот.
[47:56.200 --> 47:58.200]  Да, давайте.
[47:58.200 --> 48:00.200]  Да, давайте.
[48:00.200 --> 48:02.200]  Да, давайте.
[48:14.200 --> 48:16.200]  Так это то же самое, что было до этого,
[48:16.200 --> 48:18.200]  когда мы обсуждали.
[48:18.200 --> 48:20.200]  Но вот, во-первых, не отрицательная штука
[48:20.200 --> 48:22.200]  это нас спасает.
[48:22.200 --> 48:24.200]  И мы просто говорим, что вот это, при условии,
[48:24.200 --> 48:26.200]  что вот эта норма меньше либо равна t.
[48:30.200 --> 48:32.200]  Сейчас, погодите, вру, не так.
[48:32.200 --> 48:34.200]  Лямбда умножить на сумму модулей.
[48:34.200 --> 48:36.200]  Так?
[48:36.200 --> 48:38.200]  Каждый модуль меньше либо равен t-итому.
[48:44.200 --> 48:46.200]  Если он, ну, еще раз, идея та же самая,
[48:46.200 --> 48:48.200]  то мы минимизируем функцию,
[48:48.200 --> 48:50.200]  заменяем функцию
[48:50.200 --> 48:52.200]  на число
[48:52.200 --> 48:54.200]  и говорим, что функция меньше либо равна числа.
[48:54.200 --> 48:56.200]  Вот это оно и сделано.
[49:06.200 --> 49:08.200]  Да, но то, что у нас
[49:08.200 --> 49:10.200]  этот минимум зависит и от x, и от t,
[49:10.200 --> 49:12.200]  компенсируется как раз
[49:12.200 --> 49:14.200]  тем, что у нас есть здесь
[49:14.200 --> 49:16.200]  вектор t, у каждого x
[49:16.200 --> 49:18.200]  свой
[49:18.200 --> 49:20.200]  ограничитель сверху.
[49:32.200 --> 49:34.200]  Нет, проблема в том, что
[49:34.200 --> 49:36.200]  x равна t не выпукло ограничение.
[49:38.200 --> 49:40.200]  И поэтому нам нужно
[49:40.200 --> 49:42.200]  сделать вот так.
[49:44.200 --> 49:46.200]  Ну,
[49:48.200 --> 49:50.200]  то есть
[49:50.200 --> 49:52.200]  равенство будет достигаться?
[49:52.200 --> 49:54.200]  Да.
[49:54.200 --> 49:56.200]  Но если,
[49:56.200 --> 49:58.200]  грубо говоря,
[49:58.200 --> 50:00.200]  чтобы обеспечить выпуклость, мы искусно расширяем область значений.
[50:00.200 --> 50:02.200]  Да, но вы скажите,
[50:02.200 --> 50:04.200]  получите ли мы его, можем ли мы ответить,
[50:04.200 --> 50:06.200]  который не на исходных значениях?
[50:06.200 --> 50:08.200]  Получим ли мы его, давайте посмотрим.
[50:10.200 --> 50:12.200]  Можем ли мы его получить, в принципе?
[50:12.200 --> 50:14.200]  То есть, если у нас x, грубо говоря,
[50:14.200 --> 50:16.200]  вы хотите сказать, лежит, да, между t и
[50:16.200 --> 50:18.200]  t? То есть, если у нас
[50:18.200 --> 50:20.200]  x лежит между t и t,
[50:20.200 --> 50:22.200]  что получится?
[50:22.200 --> 50:24.200]  Можем ли мы его пододвинуть куда-то,
[50:24.200 --> 50:26.200]  чтобы он
[50:28.200 --> 50:30.200]  условно сделал эту штуку поменьше?
[50:32.200 --> 50:34.200]  Наверное, можем.
[50:36.200 --> 50:38.200]  От этой тоже зависит,
[50:38.200 --> 50:40.200]  вы правы, да.
[50:42.200 --> 50:44.200]  Как раз таки вы можете,
[50:44.200 --> 50:46.200]  не согласовывая на скорость
[50:46.200 --> 50:48.200]  набира x и t,
[50:48.200 --> 50:50.200]  у вас получится, может получиться,
[50:50.200 --> 50:52.200]  в зависимости от пункта этого дела,
[50:52.200 --> 50:54.200]  что можно ли с ним дать?
[50:54.200 --> 50:56.200]  Так, давайте я пока
[50:56.200 --> 50:58.200]  обновлю слайды, чтобы было
[50:58.200 --> 51:00.200]  понятнее. Я понял вопрос.
[51:00.200 --> 51:02.200]  Давайте
[51:02.200 --> 51:04.200]  я тут допишу, почему так
[51:04.200 --> 51:06.200]  можно делать. Окей, принято.
[51:08.200 --> 51:10.200]  О чем мы говорили?
[51:10.200 --> 51:12.200]  Если мы видим
[51:12.200 --> 51:14.200]  подобного рода функции ограничения,
[51:14.200 --> 51:16.200]  то мы их автоматически изменим на такие.
[51:16.200 --> 51:18.200]  Это я тоже проговорил.
[51:18.200 --> 51:20.200]  Теперь, да, важный вопрос.
[51:20.200 --> 51:22.200]  Вот эта штука, если мы ее
[51:22.200 --> 51:24.200]  получили, то почему,
[51:24.200 --> 51:26.200]  как такое неравенство конвертируется
[51:26.200 --> 51:28.200]  в коничность?
[51:28.200 --> 51:30.200]  Конвертируется очень хитрым образом, на самом деле.
[51:30.200 --> 51:32.200]  Если есть такое ограничение
[51:32.200 --> 51:34.200]  для упеклой функции,
[51:34.200 --> 51:36.200]  то мы можем рассматривать такой хитрый конус.
[51:36.200 --> 51:38.200]  Конус состоит
[51:38.200 --> 51:40.200]  из точек в Rn плюс 2.
[51:40.200 --> 51:42.200]  И
[51:42.200 --> 51:44.200]  эти точки
[51:44.200 --> 51:46.200]  удовлетворяют вот такому неравенству.
[51:46.200 --> 51:48.200]  То есть упражнение
[51:48.200 --> 51:50.200]  проверьте, что это будет
[51:50.200 --> 51:52.200]  выпеклый конус для выпеклой функции.
[51:52.200 --> 51:54.200]  Сейчас будет дан некоторый дополнительный
[51:54.200 --> 51:56.200]  инструмент, который позволит
[51:56.200 --> 51:58.200]  это легко сделать.
[51:58.200 --> 52:00.200]  И тогда вот это неравенство
[52:00.200 --> 52:02.200]  и эквилент тому, что у нас
[52:02.200 --> 52:04.200]  некоторому конусу
[52:04.200 --> 52:06.200]  принадлежит вот такая вот тройка чисел.
[52:08.200 --> 52:10.200]  То есть если вот эту тройку поставить вот сюда,
[52:10.200 --> 52:12.200]  z равно t,
[52:12.200 --> 52:14.200]  y равно 1, получим в точности f от x
[52:14.200 --> 52:16.200]  меньше уровня t.
[52:18.200 --> 52:20.200]  Да, при выпеклой.
[52:22.200 --> 52:24.200]  То есть выпеклое
[52:24.200 --> 52:26.200]  ограничение такого вида
[52:26.200 --> 52:28.200]  эквивалентно тому, что тройка чисел
[52:28.200 --> 52:30.200]  лежит в конусе.
[52:30.200 --> 52:32.200]  То есть мы каждой выпеклой функции
[52:32.200 --> 52:34.200]  можем поставить соответствие некоторый конус,
[52:34.200 --> 52:36.200]  который тоже будет выпуклым.
[52:36.200 --> 52:38.200]  И более того,
[52:38.200 --> 52:40.200]  для него можно получить сопряженный,
[52:40.200 --> 52:42.200]  что нам открывает дорогу конической
[52:42.200 --> 52:44.200]  двойственности, о которой мы говорили
[52:44.200 --> 52:46.200]  в прошлый раз.
[52:46.200 --> 52:48.200]  Теперь, почему это будет работать?
[52:48.200 --> 52:50.200]  Почему эта штука, то есть как инструмент,
[52:50.200 --> 52:52.200]  который позволит показывать
[52:52.200 --> 52:54.200]  выпуклость этого конуса?
[52:54.200 --> 52:56.200]  Для этого нам поможет перспективное
[52:56.200 --> 52:58.200]  преобразование,
[52:58.200 --> 53:00.200]  так называемое. Пусть у нас есть функция
[53:00.200 --> 53:02.200]  выпеклая функция,
[53:02.200 --> 53:04.200]  тогда функция от n плюс 1 переменной
[53:04.200 --> 53:06.200]  вида вот такого
[53:06.200 --> 53:08.200]  для положительных t
[53:08.200 --> 53:10.200]  также будет выпуклой.
[53:14.200 --> 53:16.200]  Выглядит, я понимаю, может быть довольно страшно
[53:16.200 --> 53:18.200]  и непривычно,
[53:18.200 --> 53:20.200]  но на самом деле логика очень простая.
[53:20.200 --> 53:22.200]  Мы расширяем область определения
[53:22.200 --> 53:24.200]  на положительные числа
[53:24.200 --> 53:26.200]  и в аргумент
[53:26.200 --> 53:28.200]  подставляем x делить на t,
[53:28.200 --> 53:30.200]  а потом результат умножаем на t.
[53:42.200 --> 53:44.200]  Понятно, непонятно?
[53:44.200 --> 53:46.200]  Давайте пример.
[53:46.200 --> 53:48.200]  Пусть у нас была функция
[53:48.200 --> 53:50.200]  в квадрате эвклидовой нормы.
[53:50.200 --> 53:52.200]  Мы знаем, что нам выпукло?
[53:54.200 --> 53:56.200]  Знаем?
[53:56.200 --> 53:58.200]  Знаем.
[53:58.200 --> 54:00.200]  Давайте вместо нашего вектора
[54:00.200 --> 54:02.200]  подставим x делить на t.
[54:02.200 --> 54:04.200]  Что мы получим?
[54:10.200 --> 54:12.200]  Получится посчитать?
[54:16.200 --> 54:18.200]  Да.
[54:22.200 --> 54:24.200]  Вторая, вторая, квадрат эвклидовой нормы,
[54:24.200 --> 54:26.200]  да, все просто.
[54:28.200 --> 54:30.200]  Что получится?
[54:30.200 --> 54:32.200]  Нет.
[54:32.200 --> 54:34.200]  Потому что еще умножение на t есть.
[54:36.200 --> 54:38.200]  Просто посчитать,
[54:38.200 --> 54:40.200]  будет делить на t квадрат, умножаем на t,
[54:40.200 --> 54:42.200]  получаем, что функция
[54:42.200 --> 54:44.200]  нормы эвклидовой
[54:44.200 --> 54:46.200]  от x делить на t,
[54:46.200 --> 54:48.200]  выпуклая функция по x и t.
[54:50.200 --> 54:52.200]  А теперь если мы вспомним,
[54:52.200 --> 54:54.200]  что афинное преобразование
[54:54.200 --> 54:56.200]  аргументов не портит выпуклости,
[54:56.200 --> 54:58.200]  то функции вида...
[55:02.200 --> 55:04.200]  Угадайте какого.
[55:06.200 --> 55:08.200]  Да, наверное это странный вопрос.
[55:08.200 --> 55:10.200]  Функция вида
[55:10.200 --> 55:12.200]  вот такого
[55:14.200 --> 55:16.200]  тоже будет выпуклой.
[55:22.200 --> 55:24.200]  Что называется?
[55:24.200 --> 55:26.200]  Попробуйте проверить каким-то другим способом.
[55:26.200 --> 55:28.200]  Вы будете долго и упорно страдать.
[55:34.200 --> 55:36.200]  Да, потому что у нас была норма
[55:36.200 --> 55:38.200]  x делить на t.
[55:38.200 --> 55:40.200]  А мы взяли...
[55:40.200 --> 55:42.200]  Что мы взяли? Афинное преобразование от каждого аргумента.
[55:42.200 --> 55:44.200]  Представили его в виде
[55:44.200 --> 55:46.200]  некоторой афины.
[55:52.200 --> 55:54.200]  Да, подставили линейную...
[55:54.200 --> 55:56.200]  Просто линейное преобразование
[55:56.200 --> 55:58.200]  аргумента сделали.
[55:58.200 --> 56:00.200]  Вот, ну там понятно,
[56:00.200 --> 56:02.200]  эта штука больше нуля.
[56:02.200 --> 56:04.200]  Должно быть.
[56:04.200 --> 56:06.200]  Да, кстати,
[56:06.200 --> 56:08.200]  может быть, я немножко вас обманываю,
[56:08.200 --> 56:10.200]  в том плане, что
[56:10.200 --> 56:12.200]  может быть, надо лучше сказать наоборот.
[56:12.200 --> 56:14.200]  Но если мы взяли
[56:14.200 --> 56:16.200]  афинное преобразование аргумента,
[56:16.200 --> 56:18.200]  то мы получили
[56:18.200 --> 56:20.200]  афинное преобразование аргумента.
[56:20.200 --> 56:22.200]  Может быть, надо лучше сказать наоборот.
[56:22.200 --> 56:24.200]  Что вы там...
[56:24.200 --> 56:26.200]  Ну есть понятно, преобразование вперед
[56:26.200 --> 56:28.200]  и преобразование назад.
[56:30.200 --> 56:32.200]  Непонятно, чем я сейчас говорю, да?
[56:34.200 --> 56:36.200]  Да, да, да.
[56:36.200 --> 56:38.200]  Что это t, а это вот это.
[56:38.200 --> 56:40.200]  И наоборот будет то же самое.
[56:40.200 --> 56:42.200]  Вот.
[56:42.200 --> 56:44.200]  Число знаменателей.
[56:44.200 --> 56:46.200]  Число знаменателей.
[56:46.200 --> 56:48.200]  Не переживайте.
[56:48.200 --> 56:50.200]  Здесь плюс D, все, тут все честно.
[56:50.200 --> 56:52.200]  Вот, это я к тому, что вот
[56:52.200 --> 56:54.200]  условно вот такого вида выражения,
[56:54.200 --> 56:56.200]  вы их выпуклась
[56:56.200 --> 56:58.200]  условно гессиан считать здесь довольно
[56:58.200 --> 57:00.200]  бессмысленную.
[57:00.200 --> 57:02.200]  Вот, ну вы получите вот такое какое-то огромное
[57:02.200 --> 57:04.200]  штуковина, вы ее на положительную полуопределенность
[57:04.200 --> 57:06.200]  будете проверять очень долго и упорно.
[57:12.200 --> 57:14.200]  Да, поэтому я и сказал,
[57:14.200 --> 57:16.200]  что это типа, наверное, можно думать о том,
[57:16.200 --> 57:18.200]  что в обратном преобразовании.
[57:18.200 --> 57:20.200]  То есть это была функция условно от
[57:20.200 --> 57:22.200]  X, вот.
[57:22.200 --> 57:24.200]  А мы говорим, что t у нас
[57:24.200 --> 57:26.200]  это вот это,
[57:26.200 --> 57:28.200]  вот, и типа,
[57:28.200 --> 57:30.200]  а вот это это типа обратное преобразование
[57:30.200 --> 57:32.200]  вот здесь вот. И нам нужно
[57:32.200 --> 57:34.200]  получить из выпукл...
[57:34.200 --> 57:36.200]  Из какой-то функции выпуклую, при этом мы знаем,
[57:36.200 --> 57:38.200]  что обратное преобразование сохранит выпуклость.
[57:42.200 --> 57:44.200]  Непонятно.
[57:44.200 --> 57:46.200]  Ага.
[57:54.200 --> 57:56.200]  От X и от...
[57:58.200 --> 58:00.200]  Ну, то есть, короче, вопрос, почему здесь было
[58:00.200 --> 58:02.200]  t, а тут t нет? Я правильно понял вопрос?
[58:08.200 --> 58:10.200]  А...
[58:14.200 --> 58:16.200]  Да, правда.
[58:20.200 --> 58:22.200]  Ничего не портит, потому что мы берем
[58:22.200 --> 58:24.200]  линейные преобразования, то есть у
[58:24.200 --> 58:26.200]  нашего преобразования,
[58:26.200 --> 58:28.200]  которое было, каким, афинным,
[58:28.200 --> 58:30.200]  оно может нам размерности
[58:30.200 --> 58:32.200]  понизить. Поэтому можем наложить
[58:32.200 --> 58:34.200]  дополнительные ограничения на связь
[58:34.200 --> 58:36.200]  от двух аргументов.
[58:40.200 --> 58:42.200]  Окей.
[58:42.200 --> 58:44.200]  Подходит такое объяснение?
[58:44.200 --> 58:46.200]  Хорошо.
[58:46.200 --> 58:48.200]  Так, окей, это я
[58:48.200 --> 58:50.200]  показал пример, так, а теперь
[58:50.200 --> 58:52.200]  собственно, да,
[58:52.200 --> 58:54.200]  небольшой доказательств того, почему это работает,
[58:54.200 --> 58:56.200]  а... Какое?
[58:56.200 --> 58:58.200]  Доказательств с продолжением, я бы сказал.
[58:58.200 --> 59:00.200]  Пусть у нас
[59:00.200 --> 59:02.200]  есть точка, которая лежит на графике
[59:02.200 --> 59:04.200]  функции g вот этой.
[59:04.200 --> 59:06.200]  То есть xts над график g
[59:06.200 --> 59:08.200]  это значит, что
[59:08.200 --> 59:10.200]  g больше...
[59:10.200 --> 59:12.200]  Ой, не g больше, а s больше, чем
[59:12.200 --> 59:14.200]  g.
[59:14.200 --> 59:16.200]  Это значит, что f меньше,
[59:16.200 --> 59:18.200]  чем s на t.
[59:18.200 --> 59:20.200]  Ну, поделили на t, получили вот такое соотношение.
[59:20.200 --> 59:22.200]  Значит, вот эта точка
[59:22.200 --> 59:24.200]  x делить на t и s делить на t
[59:24.200 --> 59:26.200]  лежит на графике f.
[59:28.200 --> 59:30.200]  Понятны две строчки?
[59:34.200 --> 59:36.200]  Поднимите руки кому?
[59:36.200 --> 59:38.200]  Понятно.
[59:38.200 --> 59:40.200]  Так, good.
[59:40.200 --> 59:42.200]  Соответственно, получили, что над график
[59:42.200 --> 59:44.200]  для g
[59:44.200 --> 59:46.200]  это
[59:46.200 --> 59:48.200]  некоторое обратное преобразование от вот такого вот
[59:48.200 --> 59:50.200]  для над графика f.
[59:56.200 --> 59:58.200]  Ну, было вот так,
[59:58.200 --> 01:00:00.200]  мы там сделали какое-то преобразование,
[01:00:00.200 --> 01:00:02.200]  вернулись сюда.
[01:00:02.200 --> 01:00:04.200]  Вот. Над график f выпукло и в множество,
[01:00:04.200 --> 01:00:06.200]  мы это знаем, потому что функция выпукла.
[01:00:06.200 --> 01:00:08.200]  Теперь осталось понять, почему
[01:00:08.200 --> 01:00:10.200]  вот это преобразование будет сохранять выпуклость.
[01:00:12.200 --> 01:00:14.200]  Видите оно какое хитрое?
[01:00:14.200 --> 01:00:16.200]  Мы берем
[01:00:16.200 --> 01:00:18.200]  вектор,
[01:00:18.200 --> 01:00:20.200]  берем последнюю координату,
[01:00:20.200 --> 01:00:22.200]  делим все координаты
[01:00:22.200 --> 01:00:24.200]  на последнюю
[01:00:24.200 --> 01:00:26.200]  и отбрасываем последнюю координату.
[01:00:28.200 --> 01:00:30.200]  Вот какая механика
[01:00:30.200 --> 01:00:32.200]  за этим стоит.
[01:00:32.200 --> 01:00:34.200]  Это называется перспективным отображением,
[01:00:34.200 --> 01:00:36.200]  что довольно логично.
[01:00:36.200 --> 01:00:38.200]  То есть было
[01:00:38.200 --> 01:00:40.200]  было множество c
[01:00:40.200 --> 01:00:42.200]  из rn
[01:00:42.200 --> 01:00:44.200]  декарта в произведении r++
[01:00:44.200 --> 01:00:46.200]  и у нас вот такая функция, которая
[01:00:46.200 --> 01:00:48.200]  делит на положительную
[01:00:48.200 --> 01:00:50.200]  последнюю компоненту и оббрасывает ее.
[01:00:54.200 --> 01:00:56.200]  После применения
[01:00:56.200 --> 01:00:58.200]  такого преобразования выпуклость
[01:00:58.200 --> 01:01:00.200]  в множество сохраняется.
[01:01:00.200 --> 01:01:02.200]  Доказательство очень простое,
[01:01:02.200 --> 01:01:04.200]  будет небольшое упражнение,
[01:01:04.200 --> 01:01:06.200]  которое несложно проделать,
[01:01:06.200 --> 01:01:08.200]  надо расписать
[01:01:08.200 --> 01:01:10.200]  на полстраничке формулы,
[01:01:10.200 --> 01:01:12.200]  пусть у нас были
[01:01:12.200 --> 01:01:14.200]  две такие точки
[01:01:14.200 --> 01:01:16.200]  с положительными числами
[01:01:16.200 --> 01:01:18.200]  в конце.
[01:01:18.200 --> 01:01:20.200]  Наше преобразование
[01:01:20.200 --> 01:01:22.200]  к их
[01:01:22.200 --> 01:01:24.200]  выпуклой комбинации
[01:01:24.200 --> 01:01:26.200]  это вот такая вот точка.
[01:01:28.200 --> 01:01:30.200]  То есть подставили, поделили,
[01:01:30.200 --> 01:01:32.200]  я не знаю, тут
[01:01:32.200 --> 01:01:34.200]  наверное понятно.
[01:01:34.200 --> 01:01:36.200]  Поднимите руки, кто понял,
[01:01:36.200 --> 01:01:38.200]  что происходит.
[01:01:38.200 --> 01:01:40.200]  Да, да, да,
[01:01:40.200 --> 01:01:42.200]  вот, вот взяли вот эту точку
[01:01:42.200 --> 01:01:44.200]  и применяем p, p это вот это.
[01:01:44.200 --> 01:01:46.200]  Соответственно,
[01:01:46.200 --> 01:01:48.200]  первый n тут,
[01:01:48.200 --> 01:01:50.200]  последний здесь, поделили.
[01:01:50.200 --> 01:01:52.200]  Что теперь надо доказать?
[01:01:52.200 --> 01:01:54.200]  Точнее, что теперь надо найти?
[01:01:56.200 --> 01:01:58.200]  То есть это пример того, что мы
[01:01:58.200 --> 01:02:00.200]  напоминаем, мы доказывали, что под действием
[01:02:00.200 --> 01:02:02.200]  некоторого преобразования выпуклость сохраняется.
[01:02:02.200 --> 01:02:04.200]  На одной из первых лекций
[01:02:04.200 --> 01:02:06.200]  мы доказывали, что действие
[01:02:06.200 --> 01:02:08.200]  афинной функции
[01:02:08.200 --> 01:02:10.200]  сохраняет выпуклость. Там в одну строчку
[01:02:10.200 --> 01:02:12.200]  все расписывалось.
[01:02:12.200 --> 01:02:14.200]  Здесь в две
[01:02:14.200 --> 01:02:16.200]  будет расписываться.
[01:02:18.200 --> 01:02:20.200]  Что надо показать?
[01:02:22.200 --> 01:02:24.200]  То есть это некоторый образ
[01:02:24.200 --> 01:02:26.200]  нашей точки,
[01:02:26.200 --> 01:02:28.200]  который лежит в том множестве
[01:02:28.200 --> 01:02:30.200]  выпуклость которого мы хотим найти.
[01:02:34.200 --> 01:02:36.200]  Какой следующий шаг?
[01:02:44.200 --> 01:02:46.200]  Почти.
[01:02:46.200 --> 01:02:48.200]  Надо найти такие бета,
[01:02:48.200 --> 01:02:50.200]  чтобы образ лежал
[01:02:50.200 --> 01:02:52.200]  внутри
[01:02:52.200 --> 01:02:54.200]  образов x и y.
[01:02:56.200 --> 01:02:58.200]  Понятно.
[01:02:58.200 --> 01:03:00.200]  Почему так?
[01:03:02.200 --> 01:03:04.200]  Не понятно.
[01:03:04.200 --> 01:03:06.200]  Давайте я распишу тогда подробнее.
[01:03:10.200 --> 01:03:12.200]  Это наше множество
[01:03:12.200 --> 01:03:14.200]  C.
[01:03:14.200 --> 01:03:16.200]  Мы взяли две точки
[01:03:16.200 --> 01:03:18.200]  и берем
[01:03:18.200 --> 01:03:20.200]  какую-то точку между ними.
[01:03:20.200 --> 01:03:22.200]  И у нас есть отображение
[01:03:22.200 --> 01:03:24.200]  P, которое переводит
[01:03:24.200 --> 01:03:26.200]  это все в C с волной.
[01:03:26.200 --> 01:03:28.200]  Чтобы показать, что при этом
[01:03:28.200 --> 01:03:30.200]  отображении множество C с волной
[01:03:30.200 --> 01:03:32.200]  будет выпуклым,
[01:03:32.200 --> 01:03:34.200]  нам надо показать, что вот эта
[01:03:34.200 --> 01:03:36.200]  точка, которая была здесь,
[01:03:36.200 --> 01:03:38.200]  она отображается куда-то еще,
[01:03:38.200 --> 01:03:40.200]  будет лежать в отрезке, который
[01:03:40.200 --> 01:03:42.200]  есть
[01:03:42.200 --> 01:03:44.200]  в конце которого
[01:03:44.200 --> 01:03:46.200]  образы исходных точек.
[01:03:50.200 --> 01:03:52.200]  Понятно, да, теперь?
[01:03:52.200 --> 01:03:54.200]  Это, собственно, и будет знать,
[01:03:54.200 --> 01:03:56.200]  что множество C с волной выпуклым.
[01:04:00.200 --> 01:04:02.200]  Да, нет, понятно.
[01:04:02.200 --> 01:04:04.200]  Поднимите рыбка, вам понятно.
[01:04:06.200 --> 01:04:08.200]  Так, почти.
[01:04:10.200 --> 01:04:12.200]  Так, разбрались
[01:04:12.200 --> 01:04:14.200]  или нет?
[01:04:14.200 --> 01:04:16.200]  Скажите, что вас смущает.
[01:04:22.200 --> 01:04:24.200]  Все?
[01:04:24.200 --> 01:04:26.200]  Отлично.
[01:04:26.200 --> 01:04:28.200]  Так, это наша цель,
[01:04:28.200 --> 01:04:30.200]  которая благополучно
[01:04:30.200 --> 01:04:32.200]  решается
[01:04:32.200 --> 01:04:34.200]  с помощью коэффициента
[01:04:34.200 --> 01:04:36.200]  β, который надо найти,
[01:04:36.200 --> 01:04:38.200]  просто подставив,
[01:04:38.200 --> 01:04:40.200]  то есть у нас есть вот эта левая часть,
[01:04:40.200 --> 01:04:42.200]  а правая часть,
[01:04:42.200 --> 01:04:44.200]  это β умножить на х
[01:04:44.200 --> 01:04:46.200]  с крышкой делить на хн плюс 1
[01:04:46.200 --> 01:04:48.200]  плюс 1 минус β на y с крышкой
[01:04:48.200 --> 01:04:50.200]  делить на yн плюс 1.
[01:04:50.200 --> 01:04:52.200]  Да, и вы просто приводите
[01:04:52.200 --> 01:04:54.200]  к общему знаменателю и выражаете
[01:04:54.200 --> 01:04:56.200]  β. Я верю,
[01:04:56.200 --> 01:04:58.200]  что вы справитесь
[01:04:58.200 --> 01:05:00.200]  с этим несложным заданием
[01:05:00.200 --> 01:05:02.200]  и убедитесь, что оно действительно будет лежать
[01:05:02.200 --> 01:05:04.200]  от 0 до 1. Там
[01:05:04.200 --> 01:05:06.200]  несложные выражения.
[01:05:06.200 --> 01:05:08.200]  Значит, образ также будет выпуклым множеством.
[01:05:08.200 --> 01:05:10.200]  Соответственно,
[01:05:10.200 --> 01:05:12.200]  вот то, что пропущено
[01:05:14.200 --> 01:05:16.200]  в этих слайдах
[01:05:16.200 --> 01:05:18.200]  пока что, это то, что
[01:05:18.200 --> 01:05:20.200]  в определенном уровне доказывается результат
[01:05:20.200 --> 01:05:22.200]  в том, что обратное отображение перспективного
[01:05:22.200 --> 01:05:24.200]  тоже сохранит выпуклость.
[01:05:24.200 --> 01:05:26.200]  То есть если у вас было множество вот такое,
[01:05:28.200 --> 01:05:30.200]  а дальше вы
[01:05:32.200 --> 01:05:34.200]  подставляете, ну понятно,
[01:05:34.200 --> 01:05:36.200]  что он сделал, подставить просто
[01:05:36.200 --> 01:05:38.200]  множество вот такое,
[01:05:38.200 --> 01:05:40.200]  то из него
[01:05:40.200 --> 01:05:42.200]  вернуть в
[01:05:42.200 --> 01:05:44.200]  rn плюс 1 с полным вектором.
[01:05:48.200 --> 01:05:50.200]  Так, понятно, как выглядит обратное отображение?
[01:05:54.200 --> 01:05:56.200]  Или нет?
[01:06:02.200 --> 01:06:04.200]  Ну, например, да.
[01:06:08.200 --> 01:06:10.200]  Так, good.
[01:06:10.200 --> 01:06:12.200]  Собственно, вот это, некоторый
[01:06:12.200 --> 01:06:14.200]  путь к тому, как показать, что это
[01:06:14.200 --> 01:06:16.200]  все, ну, то есть вот это, видите, просто
[01:06:16.200 --> 01:06:18.200]  именно отображение самой функции.
[01:06:22.200 --> 01:06:24.200]  Понятно, да?
[01:06:24.200 --> 01:06:26.200]  То есть вот это будет по-прежнему выпукло,
[01:06:26.200 --> 01:06:28.200]  ну и дальше вроде все более-менее очевидно
[01:06:28.200 --> 01:06:30.200]  показывается вот про выпуклость этого конуса.
[01:06:30.200 --> 01:06:32.200]  То есть то, что это конус, это совсем понятно.
[01:06:32.200 --> 01:06:34.200]  Умножаете x, y, z
[01:06:34.200 --> 01:06:36.200]  на одно и то же число, тут все сокращается,
[01:06:36.200 --> 01:06:38.200]  получаете то же самое выражение.
[01:06:38.200 --> 01:06:40.200]  Вот, объединяете это дело с нулем,
[01:06:40.200 --> 01:06:42.200]  ну ноль будет лежать. Осталось
[01:06:42.200 --> 01:06:44.200]  выпуклость проверить, но выпуклость как раз-таки показывается
[01:06:44.200 --> 01:06:46.200]  через перспективность.
[01:06:48.200 --> 01:06:50.200]  Понятно ли основные ингредиенты?
[01:06:54.200 --> 01:06:56.200]  Непонятно.
[01:06:56.200 --> 01:06:58.200]  Что непонятно?
[01:06:58.200 --> 01:07:00.200]  Смотрите, утверждение было такое, пусть у нас
[01:07:00.200 --> 01:07:02.200]  f от x выпукловая функция.
[01:07:02.200 --> 01:07:04.200]  Тогда этот конус будет
[01:07:04.200 --> 01:07:06.200]  выпуклым.
[01:07:06.200 --> 01:07:08.200]  То, что это конус, это понятно.
[01:07:08.200 --> 01:07:10.200]  Отлично. Теперь про выпуклость.
[01:07:10.200 --> 01:07:12.200]  Вот эта штука, это
[01:07:12.200 --> 01:07:14.200]  перспективное отображение, тут плюсика не хватает,
[01:07:14.200 --> 01:07:16.200]  перспективное отображение функции f.
[01:07:18.200 --> 01:07:20.200]  Вот оно.
[01:07:28.200 --> 01:07:30.200]  Нет, стоп, стоп, стоп. Это множество.
[01:07:30.200 --> 01:07:32.200]  А это функция.
[01:07:34.200 --> 01:07:36.200]  Функция умножается еще на это самое число.
[01:07:36.200 --> 01:07:38.200]  То есть умножение
[01:07:38.200 --> 01:07:40.200]  на это число
[01:07:40.200 --> 01:07:42.200]  надо для того, чтобы
[01:07:42.200 --> 01:07:44.200]  получить обратное перспективное
[01:07:44.200 --> 01:07:46.200]  отображение для ноб графика.
[01:07:48.200 --> 01:07:50.200]  То есть если бы мы просто делили,
[01:07:50.200 --> 01:07:52.200]  то тут был бы s и мы такие
[01:07:52.200 --> 01:07:54.200]  непонятно, что делать, потому что это какое-то странное преобразование.
[01:07:58.200 --> 01:08:00.200]  Это понятно этот шаг?
[01:08:02.200 --> 01:08:04.200]  Давайте еще раз.
[01:08:04.200 --> 01:08:06.200]  Давайте еще раз. Смотрите.
[01:08:06.200 --> 01:08:08.200]  Хотим показать, что этот конус
[01:08:08.200 --> 01:08:10.200]  выпуклое множество.
[01:08:12.200 --> 01:08:14.200]  Смотрим на это выражение.
[01:08:16.200 --> 01:08:18.200]  Это перспективное преобразование функции f
[01:08:18.200 --> 01:08:20.200]  по вот этому определению.
[01:08:22.200 --> 01:08:24.200]  Значит это некоторая выпуклая функция.
[01:08:26.200 --> 01:08:28.200]  Ну а дальше у нас тут есть
[01:08:28.200 --> 01:08:30.200]  выпуклая функция от x и y,
[01:08:30.200 --> 01:08:32.200]  которая меньше либо равна z.
[01:08:34.200 --> 01:08:36.200]  И вот эта вот множество таких точек,
[01:08:36.200 --> 01:08:38.200]  что g от x и y меньше либо равно z
[01:08:38.200 --> 01:08:40.200]  задает выпуклое множество.
[01:08:42.200 --> 01:08:44.200]  Проверяется по определению.
[01:08:44.200 --> 01:08:46.200]  Берете две точки,
[01:08:46.200 --> 01:08:48.200]  подставляете серединку
[01:08:48.200 --> 01:08:50.200]  или точку из отрезка функцию g,
[01:08:50.200 --> 01:08:52.200]  пользуетесь выпуклостью
[01:08:54.200 --> 01:08:56.200]  и у вас получается, что точка
[01:08:56.200 --> 01:08:58.200]  из середины отрезка тоже будет меньше z.
[01:09:00.200 --> 01:09:02.200]  Точка из отрезка будет меньше z.
[01:09:02.200 --> 01:09:04.200]  Если в гранических точках
[01:09:04.200 --> 01:09:06.200]  у вас выполнено это неравенство.
[01:09:08.200 --> 01:09:10.200]  Вот.
[01:09:10.200 --> 01:09:12.200]  Выучили выпуклость этого конуса.
[01:09:12.200 --> 01:09:14.200]  То есть тут ключевой момент
[01:09:14.200 --> 01:09:16.200]  это вот это преобразование.
[01:09:16.200 --> 01:09:18.200]  Выпуклость которого
[01:09:18.200 --> 01:09:20.200]  вот такая вот через все
[01:09:20.200 --> 01:09:22.200]  доказывается.
[01:09:22.200 --> 01:09:24.200]  То есть
[01:09:24.200 --> 01:09:26.200]  я поэтому
[01:09:26.200 --> 01:09:28.200]  всю эту историю не рассказывал,
[01:09:28.200 --> 01:09:30.200]  когда мы обсуждали выпуклые функции множества,
[01:09:30.200 --> 01:09:32.200]  потому что когда
[01:09:32.200 --> 01:09:34.200]  если бы я вам это рассказал тогда,
[01:09:34.200 --> 01:09:36.200]  вы бы наверное удивились, зачем это надо.
[01:09:36.200 --> 01:09:38.200]  Вот. Но вот сейчас это надо вот этим вот.
[01:09:40.200 --> 01:09:42.200]  Чтобы обосновать, как от неравенств
[01:09:42.200 --> 01:09:44.200]  перейти к конусам.
[01:09:46.200 --> 01:09:48.200]  Вот. Окей. Теперь собственно переходим
[01:09:48.200 --> 01:09:50.200]  к тому,
[01:09:50.200 --> 01:09:52.200]  как
[01:09:52.200 --> 01:09:54.200]  трансформируется точка
[01:09:54.200 --> 01:09:56.200]  методов внутренней точки.
[01:09:56.200 --> 01:09:58.200]  Так, да, даже наверное что-то я еще успею
[01:09:58.200 --> 01:10:00.200]  рассказать.
[01:10:00.200 --> 01:10:02.200]  Значит,
[01:10:02.200 --> 01:10:04.200]  когда мы строим CFITF0
[01:10:04.200 --> 01:10:06.200]  из линейтарных функций правил,
[01:10:06.200 --> 01:10:08.200]  то мы проверяем выпуклость.
[01:10:08.200 --> 01:10:10.200]  Можем проверить автоматически выпуклость.
[01:10:10.200 --> 01:10:12.200]  И о чудо,
[01:10:12.200 --> 01:10:14.200]  такой же разбор на ингредиенты
[01:10:14.200 --> 01:10:16.200]  позволит привести задачу
[01:10:16.200 --> 01:10:18.200]  к стандартной форме.
[01:10:18.200 --> 01:10:20.200]  То есть он позволит записать задачу
[01:10:20.200 --> 01:10:22.200]  в виде, здесь что-то линейное,
[01:10:22.200 --> 01:10:24.200]  а тут конуса.
[01:10:24.200 --> 01:10:26.200]  Потому что
[01:10:28.200 --> 01:10:30.200]  вот.
[01:10:38.200 --> 01:10:40.200]  Если мы будем рассматривать элементарные функции,
[01:10:40.200 --> 01:10:42.200]  которые будут нам собирать
[01:10:42.200 --> 01:10:44.200]  что-то гладкое,
[01:10:44.200 --> 01:10:46.200]  то мы в процессе
[01:10:46.200 --> 01:10:48.200]  выпуклости задачи
[01:10:48.200 --> 01:10:50.200]  получим преобразование,
[01:10:50.200 --> 01:10:52.200]  которое нам позволит
[01:10:52.200 --> 01:10:54.200]  переписать эту задачу так,
[01:10:54.200 --> 01:10:56.200]  чтобы можно было запустить метод
[01:10:56.200 --> 01:10:58.200]  внутренней точки.
[01:10:58.200 --> 01:11:00.200]  То есть одновременная проверка выпуклости
[01:11:00.200 --> 01:11:02.200]  приводит к преобразованию
[01:11:02.200 --> 01:11:04.200]  задачи, которые делают ее гладкой.
[01:11:06.200 --> 01:11:08.200]  Ну и конической.
[01:11:08.200 --> 01:11:10.200]  Понятно ли это?
[01:11:16.200 --> 01:11:18.200]  Так, теперь пример вроде тут
[01:11:18.200 --> 01:11:20.200]  скоро должен появиться, который мне очень нравится.
[01:11:22.200 --> 01:11:24.200]  Все это называется Discipline Convex Programming,
[01:11:24.200 --> 01:11:26.200]  DCP.
[01:11:26.200 --> 01:11:28.200]  Идея в чем? Сдаются перемены, сдаются параметры.
[01:11:28.200 --> 01:11:30.200]  Целевую функцию
[01:11:30.200 --> 01:11:32.200]  и ограничение строите из элементарных
[01:11:32.200 --> 01:11:34.200]  функций, которые
[01:11:34.200 --> 01:11:36.200]  как-то переопределены
[01:11:36.200 --> 01:11:38.200]  и оснащены чем-то еще дополнительно
[01:11:38.200 --> 01:11:40.200]  внутри пакета, внутри библиотеки.
[01:11:40.200 --> 01:11:42.200]  И правила композиции тоже заданы.
[01:11:42.200 --> 01:11:44.200]  Вы получили выпуклость задачи
[01:11:44.200 --> 01:11:46.200]  по построению.
[01:11:46.200 --> 01:11:48.200]  Вы ее потом,
[01:11:48.200 --> 01:11:50.200]  ну не вы, а когда вы ее отправляете
[01:11:50.200 --> 01:11:52.200]  в библиотеку, она там внутри разбирается
[01:11:52.200 --> 01:11:54.200]  на элементы.
[01:11:54.200 --> 01:11:56.200]  И приводится к форме,
[01:11:56.200 --> 01:11:58.200]  для которой подлежит запуск одного из
[01:11:58.200 --> 01:12:00.200]  стандартных солверов.
[01:12:00.200 --> 01:12:02.200]  Решаете пакетом,
[01:12:02.200 --> 01:12:04.200]  восстанавливаете решение.
[01:12:04.200 --> 01:12:06.200]  Пример разбора. Давайте тут
[01:12:06.200 --> 01:12:08.200]  может не очень крупно.
[01:12:08.200 --> 01:12:10.200]  Допустим,
[01:12:10.200 --> 01:12:12.200]  у вас, ой,
[01:12:12.200 --> 01:12:14.200]  видно, да?
[01:12:14.200 --> 01:12:16.200]  Жуткая функция.
[01:12:16.200 --> 01:12:18.200]  Что это такое?
[01:12:18.200 --> 01:12:20.200]  Агариф сумма экспонент
[01:12:20.200 --> 01:12:22.200]  это единица делить
[01:12:22.200 --> 01:12:24.200]  на аргумент,
[01:12:24.200 --> 01:12:26.200]  при том, что аргумент положительный.
[01:12:26.200 --> 01:12:28.200]  Ну, грубо говоря, единица на х, при х больше нуля.
[01:12:30.200 --> 01:12:32.200]  И модуль 364 умножить
[01:12:32.200 --> 01:12:34.200]  на z.
[01:12:34.200 --> 01:12:36.200]  Переменами является z и v.
[01:12:36.200 --> 01:12:38.200]  Как проверить ее
[01:12:38.200 --> 01:12:40.200]  на выпуклость? Выглядит
[01:12:40.200 --> 01:12:42.200]  жутко, не правда ли?
[01:12:42.200 --> 01:12:44.200]  Очень просто.
[01:12:44.200 --> 01:12:46.200]  Мы говорим, у нас
[01:12:46.200 --> 01:12:48.200]  основная функция – алгорифма сумма экспонент.
[01:12:48.200 --> 01:12:50.200]  Какие у нее аргументы?
[01:12:50.200 --> 01:12:52.200]  Функция 1 на х
[01:12:52.200 --> 01:12:54.200]  и модуль.
[01:12:54.200 --> 01:12:56.200]  Значит, это выпукло,
[01:12:56.200 --> 01:12:58.200]  это выпуклые знаки положительные.
[01:12:58.200 --> 01:13:00.200]  Дальше. Функция
[01:13:00.200 --> 01:13:02.200]  1 на х. Вот она.
[01:13:02.200 --> 01:13:04.200]  А какой у нее аргумент?
[01:13:04.200 --> 01:13:06.200]  Линейный.
[01:13:06.200 --> 01:13:08.200]  Линейная функция может быть как отрицательная,
[01:13:08.200 --> 01:13:10.200]  так и положительная.
[01:13:10.200 --> 01:13:12.200]  Это что такое? Это операция плюс,
[01:13:12.200 --> 01:13:14.200]  которая делится,
[01:13:14.200 --> 01:13:16.200]  которая сочетает в себе
[01:13:16.200 --> 01:13:18.200]  что-то зависщее от z, что зависщее от v,
[01:13:18.200 --> 01:13:20.200]  все линейно. Знак плюс-минус.
[01:13:20.200 --> 01:13:22.200]  Здесь все аналогично.
[01:13:22.200 --> 01:13:24.200]  Далее. Когда все дело собирается,
[01:13:24.200 --> 01:13:26.200]  то получается, что это все
[01:13:26.200 --> 01:13:28.200]  выпукло.
[01:13:28.200 --> 01:13:30.200]  Вот тут анализ знака, анализ выпуклости.
[01:13:34.200 --> 01:13:36.200]  Вот тот разбор,
[01:13:36.200 --> 01:13:38.200]  который происходит для проверки выпуклости.
[01:13:38.200 --> 01:13:40.200]  В соответствии с правилами.
[01:13:40.200 --> 01:13:42.200]  Давайте теперь
[01:13:42.200 --> 01:13:44.200]  вместе поиграем в...
[01:13:44.200 --> 01:13:46.200]  В общем, пример взят
[01:13:46.200 --> 01:13:48.200]  вот с этого сайта. Я надеюсь, он сейчас откроется.
[01:13:48.200 --> 01:13:50.200]  Видно, да?
[01:13:50.200 --> 01:13:52.200]  Давайте я вот так делаю.
[01:13:52.200 --> 01:13:54.200]  Вот. И тут есть
[01:13:54.200 --> 01:13:56.200]  типа квиз,
[01:13:56.200 --> 01:13:58.200]  где можно поиграться.
[01:14:00.200 --> 01:14:02.200]  Собственно, quad over lin
[01:14:02.200 --> 01:14:04.200]  это то, что я вот недавно писал про
[01:14:04.200 --> 01:14:06.200]  нормы х в квадрате делить на t.
[01:14:06.200 --> 01:14:08.200]  В одномерном случае
[01:14:08.200 --> 01:14:10.200]  это х в квадрат делить на t.
[01:14:12.200 --> 01:14:14.200]  Х в квадрат
[01:14:14.200 --> 01:14:16.200]  делится на t.
[01:14:16.200 --> 01:14:18.200]  Как вы думаете, будет ли это выпукло?
[01:14:24.200 --> 01:14:26.200]  Что-что?
[01:14:30.200 --> 01:14:32.200]  Кто?
[01:14:32.200 --> 01:14:34.200]  Не-не, смотрите, мы когда
[01:14:34.200 --> 01:14:36.200]  обсуждали, то мы пришли к тому, что
[01:14:36.200 --> 01:14:38.200]  у нас
[01:14:38.200 --> 01:14:40.200]  было вот так.
[01:14:40.200 --> 01:14:42.200]  Было вот так.
[01:14:42.200 --> 01:14:44.200]  Была...
[01:14:44.200 --> 01:14:46.200]  Да, у нас она оказалась
[01:14:46.200 --> 01:14:48.200]  выпуклой. Давайте теперь
[01:14:48.200 --> 01:14:50.200]  поймем, будет ли выпукло то, что
[01:14:50.200 --> 01:14:52.200]  написано вот тут.
[01:15:00.200 --> 01:15:02.200]  Тут есть два варианта.
[01:15:02.200 --> 01:15:04.200]  А финна выпукла вовнута или не подходит
[01:15:04.200 --> 01:15:06.200]  под правила DisciplineConvex Programming?
[01:15:06.200 --> 01:15:08.200]  Я знаю.
[01:15:08.200 --> 01:15:10.200]  Почти.
[01:15:10.200 --> 01:15:12.200]  Вроде как.
[01:15:12.200 --> 01:15:14.200]  Давайте проголосуем.
[01:15:14.200 --> 01:15:16.200]  Кто за афинность?
[01:15:16.200 --> 01:15:18.200]  Никого. Кто за выпуклость?
[01:15:18.200 --> 01:15:20.200]  Руки поднимите.
[01:15:20.200 --> 01:15:22.200]  Два человека. Три.
[01:15:22.200 --> 01:15:24.200]  Кто за вовнутость?
[01:15:24.200 --> 01:15:26.200]  Нет таких.
[01:15:26.200 --> 01:15:28.200]  Кто за вот это? Один.
[01:15:28.200 --> 01:15:30.200]  Кто воздержался?
[01:15:30.200 --> 01:15:32.200]  А вы почему воздержались?
[01:15:32.200 --> 01:15:34.200]  Я не понимаю.
[01:15:34.200 --> 01:15:36.200]  Какая функция?
[01:15:36.200 --> 01:15:38.200]  Смотрите, вот функция. Я попытался
[01:15:38.200 --> 01:15:40.200]  объяснить, что это за функция.
[01:15:40.200 --> 01:15:42.200]  Вы поняли, что это за функция?
[01:15:42.200 --> 01:15:44.200]  Да.
[01:15:44.200 --> 01:15:46.200]  Это 34 на z в квадрате
[01:15:46.200 --> 01:15:48.200]  делить на w.
[01:15:48.200 --> 01:15:50.200]  Надо проверить, будет ли она
[01:15:50.200 --> 01:15:52.200]  такой, такой, такой или такой.
[01:15:54.200 --> 01:15:56.200]  То есть, это вот эта функция.
[01:15:56.200 --> 01:15:58.200]  x в квадрат на t.
[01:15:58.200 --> 01:16:00.200]  Вместо x у нас 34 на z.
[01:16:00.200 --> 01:16:02.200]  Это афинное преобразование.
[01:16:04.200 --> 01:16:06.200]  Делим на w.
[01:16:08.200 --> 01:16:10.200]  Что?
[01:16:10.200 --> 01:16:12.200]  Почему вы не знаете?
[01:16:12.200 --> 01:16:14.200]  Мы знаем, что если мы...
[01:16:14.200 --> 01:16:16.200]  Смотрите, я тут только что показываю.
[01:16:16.200 --> 01:16:18.200]  Что эта штука будет выпуклой,
[01:16:18.200 --> 01:16:20.200]  потому что это перспективное отображение
[01:16:20.200 --> 01:16:22.200]  для выпуклой функции.
[01:16:22.200 --> 01:16:24.200]  Похоже.
[01:16:24.200 --> 01:16:26.200]  Но не та же самая.
[01:16:26.200 --> 01:16:28.200]  Потому что там еще
[01:16:28.200 --> 01:16:30.200]  афинное преобразование вот здесь какое-то.
[01:16:32.200 --> 01:16:34.200]  Сохраняет.
[01:16:34.200 --> 01:16:36.200]  Это правда.
[01:16:36.200 --> 01:16:38.200]  Что да?
[01:16:38.200 --> 01:16:40.200]  Ну, квад оверлин, это вот
[01:16:40.200 --> 01:16:42.200]  x в квадрат делить на t.
[01:16:42.200 --> 01:16:44.200]  Хорошо. Разбрались.
[01:16:44.200 --> 01:16:46.200]  Вот вопрос.
[01:16:46.200 --> 01:16:48.200]  Давайте проголосуем. Я как раз таки призываю.
[01:16:48.200 --> 01:16:50.200]  То есть вы за выпуклость?
[01:16:50.200 --> 01:16:52.200]  Хорошо.
[01:16:52.200 --> 01:16:54.200]  Так. В итоге
[01:16:54.200 --> 01:16:56.200]  большинство за выпуклость.
[01:16:56.200 --> 01:16:58.200]  Так. Давайте проверим.
[01:17:00.200 --> 01:17:02.200]  И вы правы.
[01:17:04.200 --> 01:17:06.200]  Давайте поймем почему.
[01:17:14.200 --> 01:17:16.200]  Умножение
[01:17:18.200 --> 01:17:20.200]  и w здесь уходит
[01:17:20.200 --> 01:17:22.200]  все как вроде получается.
[01:17:26.200 --> 01:17:28.200]  Давайте повысим уровень
[01:17:28.200 --> 01:17:30.200]  до hard.
[01:17:32.200 --> 01:17:34.200]  Так. Но это еще не hard.
[01:17:34.200 --> 01:17:36.200]  Ну ладно. Давайте быстро.
[01:17:36.200 --> 01:17:38.200]  Это что такое?
[01:17:38.200 --> 01:17:40.200]  Логарифм от корня
[01:17:40.200 --> 01:17:42.200]  x пополам минус 1 на u.
[01:17:46.200 --> 01:17:48.200]  Переменная x и u.
[01:17:50.200 --> 01:17:52.200]  То, что u больше 0,
[01:17:52.200 --> 01:17:54.200]  это просто область определения
[01:17:54.200 --> 01:17:56.200]  этой функции записана.
[01:18:02.200 --> 01:18:04.200]  Вроде нет.
[01:18:04.200 --> 01:18:06.200]  Еще раз. Область определения
[01:18:06.200 --> 01:18:08.200]  им в пост только для положительных
[01:18:08.200 --> 01:18:10.200]  аргументов.
[01:18:10.200 --> 01:18:12.200]  1 на u, да.
[01:18:12.200 --> 01:18:14.200]  Да.
[01:18:18.200 --> 01:18:20.200]  То есть тут разность.
[01:18:20.200 --> 01:18:22.200]  Удозрительно, да?
[01:18:22.200 --> 01:18:24.200]  Логарифм от корня.
[01:18:26.200 --> 01:18:28.200]  Страшное дело.
[01:18:28.200 --> 01:18:30.200]  Корень вот так,
[01:18:30.200 --> 01:18:32.200]  логарифм как-то вот так.
[01:18:32.200 --> 01:18:34.200]  И еще что-то вычитается, да?
[01:18:36.200 --> 01:18:38.200]  Давайте, типа, кто за
[01:18:38.200 --> 01:18:40.200]  афинность? Руки поднимите.
[01:18:40.200 --> 01:18:42.200]  Никто.
[01:18:42.200 --> 01:18:44.200]  Кто за выпуклость?
[01:18:44.200 --> 01:18:46.200]  2. Кто за могнутость?
[01:18:46.200 --> 01:18:48.200]  1.
[01:18:48.200 --> 01:18:50.200]  Кто знает, что нельзя этого проверить?
[01:18:50.200 --> 01:18:52.200]  Я вижу опять много
[01:18:52.200 --> 01:18:54.200]  воздержавшихся. Что вас останавливает
[01:18:54.200 --> 01:18:56.200]  от того, чтобы принять решение?
[01:19:00.200 --> 01:19:02.200]  Что непонятно.
[01:19:04.200 --> 01:19:06.200]  Ну, смотрите,
[01:19:06.200 --> 01:19:08.200]  мы знаем о том, как,
[01:19:08.200 --> 01:19:10.200]  какие композиции функции, какие функции нам дают.
[01:19:10.200 --> 01:19:12.200]  Ну вот,
[01:19:12.200 --> 01:19:14.200]  это надо применить здесь.
[01:19:14.200 --> 01:19:16.200]  Так, ну ладно, большинство
[01:19:16.200 --> 01:19:18.200]  проголосовавших вроде за выпуклость.
[01:19:20.200 --> 01:19:22.200]  А вот и нет.
[01:19:22.200 --> 01:19:24.200]  А эта штука вогнута на самом деле.
[01:19:24.200 --> 01:19:26.200]  Да, тут даже вот вам
[01:19:26.200 --> 01:19:28.200]  написали почему.
[01:19:28.200 --> 01:19:30.200]  Потому что инфпоз это
[01:19:30.200 --> 01:19:32.200]  выпукло, минус это вогнуто.
[01:19:34.200 --> 01:19:36.200]  Вот, а вот логарифм от корня
[01:19:36.200 --> 01:19:38.200]  это вогнуто. И поэтому
[01:19:38.200 --> 01:19:40.200]  вы как бы складываете две вогнутые функции,
[01:19:40.200 --> 01:19:42.200]  получаете вогнутую функцию.
[01:19:42.200 --> 01:19:44.200]  Ну вы на минус да множество,
[01:19:44.200 --> 01:19:46.200]  вы учтите, что вогнутая
[01:19:46.200 --> 01:19:48.200]  это минус выпуклое.
[01:19:48.200 --> 01:19:50.200]  И это правило, оно как бы
[01:19:50.200 --> 01:19:52.200]  конвертируется в плюс-минус.
[01:19:52.200 --> 01:19:54.200]  Ну то есть, что там если
[01:19:54.200 --> 01:19:56.200]  бывает и вогнутая, и композиция
[01:19:56.200 --> 01:19:58.200]  с вогнутой, то будет вогнутая скорее всего.
[01:19:58.200 --> 01:20:00.200]  Что такое?
[01:20:00.200 --> 01:20:02.200]  Короче говоря, ссылочка в презентации есть,
[01:20:02.200 --> 01:20:04.200]  можете поиграться.
[01:20:04.200 --> 01:20:06.200]  Это мне кажется довольно забавно.
[01:20:06.200 --> 01:20:08.200]  Что?
[01:20:08.200 --> 01:20:10.200]  Сейчас, давайте посмотрим,
[01:20:10.200 --> 01:20:12.200]  по-моему можно.
[01:20:12.200 --> 01:20:14.200]  Вот она лазит.
[01:20:14.200 --> 01:20:16.200]  Короче, экспрешу сюда пишите в нужном виде,
[01:20:16.200 --> 01:20:18.200]  он вам его разбирает.
[01:20:18.200 --> 01:20:20.200]  Ну тут надо как бы сначала прочитать,
[01:20:20.200 --> 01:20:22.200]  какие функции он поддерживает.
[01:20:22.200 --> 01:20:24.200]  Типа вот.
[01:20:24.200 --> 01:20:26.200]  Ну и довольно много, как видно, да.
[01:20:26.200 --> 01:20:28.200]  Вот quadoverlink,
[01:20:28.200 --> 01:20:30.200]  который я пытался
[01:20:30.200 --> 01:20:32.200]  рассказать сегодня.
[01:20:32.200 --> 01:20:34.200]  pos,
[01:20:34.200 --> 01:20:36.200]  нормы разные,
[01:20:36.200 --> 01:20:38.200]  нормы разные,
[01:20:38.200 --> 01:20:40.200]  логарифма, сумма, экспонент.
[01:20:40.200 --> 01:20:42.200]  Вот он в pos,
[01:20:42.200 --> 01:20:44.200]  кстати, да, вот видите, их больше нуля.
[01:20:46.200 --> 01:20:48.200]  Ну, короче говоря, вроде как
[01:20:48.200 --> 01:20:50.200]  выпуклость или вогнутость почти всего,
[01:20:50.200 --> 01:20:52.200]  что тут есть, мы с вами обсудили в той или иной
[01:20:52.200 --> 01:20:54.200]  степени подробности.
[01:20:54.200 --> 01:20:56.200]  Единственное, что было не рассмотрено до сегодняшней
[01:20:56.200 --> 01:20:58.200]  лекции, это вот это. Ну вот я вроде попытался
[01:20:58.200 --> 01:21:00.200]  объяснить, почему это работает.
[01:21:00.200 --> 01:21:02.200]  Так что,
[01:21:02.200 --> 01:21:04.200]  короче говоря, опять я ничего не успел,
[01:21:04.200 --> 01:21:06.200]  но в следующий раз тогда продолжим.
[01:21:06.200 --> 01:21:08.200]  Так, на чем мы остановились? Вот здесь.
[01:21:08.200 --> 01:21:10.200]  И тогда, да, тут немножко
[01:21:10.200 --> 01:21:12.200]  истории, DCP и solver.
[01:21:12.200 --> 01:21:14.200]  Да, короче, остался чуть-чуть,
[01:21:14.200 --> 01:21:16.200]  но ладно, не буду вас задерживать.
[01:21:16.200 --> 01:21:18.200]  Надо делать перерывы тоже.
[01:21:18.200 --> 01:21:20.200]  Так, все, всем спасибо
[01:21:20.200 --> 01:21:22.200]  и до следующего раза. А, в следующий раз
[01:21:22.200 --> 01:21:24.200]  он уже наверное будет в зуме, да?
[01:21:24.200 --> 01:21:26.200]  Ну все, тогда как раз в зуме вроде обычно
[01:21:26.200 --> 01:21:28.200]  проходит.
[01:21:28.200 --> 01:21:30.200]  Может быть больше народу подключится.
