[00:00.000 --> 00:11.920]  Хорошо, тогда давайте начинать, в общем, мы с вами две лекции
[00:11.920 --> 00:15.860]  посвятили MapReducer и как вы наверно убедились на семинарах
[00:15.860 --> 00:18.840]  писать код на чистом MapReduce неудобно, даже для простой
[00:18.840 --> 00:23.860]  задачки типа WordCount надо написать что, mapper, reducer,
[00:23.860 --> 00:27.520]  два файла на Python, надо написать bash script, а если мы хотим
[00:27.520 --> 00:30.920]  сделать что-нибудь дополнительное типа сортировки, то надо
[00:30.920 --> 00:34.440]  еще два файла на Python и опять bash script, в общем, это все
[00:34.440 --> 00:40.360]  долго и еще в середине двухтысячных сообществу разработчиков
[00:40.360 --> 00:43.760]  стало понятно, что MapReduce задачи хорошо ложатся на
[00:43.760 --> 00:49.920]  SQL, давайте проверим, как они хорошо ложатся, небольшое
[00:49.920 --> 00:53.360]  задание для вас, попробуйте вот эти SQL конструкции
[00:53.360 --> 00:57.400]  представить в виде MapReducer, как бы вы решали задачу,
[00:57.400 --> 01:04.600]  например, селектова Reducer или фильтрации в виде VA,
[01:04.600 --> 01:05.600]  давайте.
[01:05.600 --> 01:35.520]  Хорошо, а что мы почему сортируем, то есть что является ключом?
[01:35.520 --> 01:38.080]  То есть у нас получается два ключа, один или ноль,
[01:38.080 --> 01:41.320]  один берем, ноль не берем, так, и получается, что все,
[01:41.320 --> 01:43.920]  что мы берем, оно пойдет на один Reducer, потому что
[01:43.920 --> 01:48.040]  ключ один, и тебе не кажется, что это как-то не очень
[01:48.040 --> 01:52.240]  хорошо, потому что, ну, просто твое решение задачи
[01:52.240 --> 01:56.000]  это всегда один Reducer, даже если у тебя 5 терабайт табличка
[01:56.000 --> 01:58.080]  и как бы слишком много.
[01:58.080 --> 02:07.760]  Можно как-то еще сделать, напомню, MapReduce это не обязательно
[02:07.760 --> 02:10.280]  всегда Map и Reduce, может быть что-нибудь одно.
[02:28.080 --> 02:34.240]  На семинарах еще не делал я никаких фильтраций.
[02:34.240 --> 02:45.560]  Ну, в общем, что мы делаем на мапе вообще, вот на каком-то
[02:45.560 --> 02:46.560]  рандомном мапе?
[02:46.560 --> 02:49.360]  К нам приходят строки, и мы их опроватываем, и мы
[02:49.360 --> 02:51.480]  принимаем решение вообще печатать что-то на выход
[02:51.480 --> 02:55.360]  или нет, и поэтому на мапе можно вполне себе сделать
[02:55.360 --> 02:56.360]  фильтрацию.
[02:56.360 --> 03:00.120]  Потому что уже на мапе можно какие-то данные выкинуть,
[03:00.120 --> 03:03.160]  и если, например, это таблица, то у нас приходят строки,
[03:03.160 --> 03:07.000]  и мы эти строки обрабатываем, выбрасываем лишние поля.
[03:07.000 --> 03:09.680]  То есть уже на мапе весь, всю логику селекта можно
[03:09.680 --> 03:10.680]  сделать.
[03:10.680 --> 03:11.680]  Чего?
[03:11.680 --> 03:25.120]  Почему условный файлик, да, но, а почему файлик не
[03:25.880 --> 03:27.880]  в HDFS?
[03:27.880 --> 03:34.520]  Да, ну, то есть еще раз, если у нас в мап-редьюсе нет редьюсера,
[03:34.520 --> 03:37.200]  то то, что нам нагенерил маппер, это является результатом,
[03:37.200 --> 03:41.280]  и оно переносится в HDFS, ходуб его сам переносит.
[03:41.280 --> 03:45.360]  Поэтому селекта можно реализовать на обычном мапе, УЭА тоже
[03:45.360 --> 03:49.440]  можно реализовать на обычном мапе, просто мы сортируем,
[03:49.440 --> 03:53.280]  точнее мы фильтруем не по вертикали, а по горизонтали,
[03:53.280 --> 03:56.160]  то есть мы принимаем решение, какие строки оставлять,
[03:56.160 --> 03:57.160]  какие не оставлять.
[03:57.160 --> 04:01.520]  Вот, что касается OrderBy, ну, здесь понятно, нужна
[04:01.520 --> 04:06.520]  сортировка, нужен редьюсер, что касается GRUBY, тут тоже
[04:06.520 --> 04:10.480]  нужен редьюсер и нужна сортировка, джойн мы с вами
[04:10.480 --> 04:14.760]  разбирали, и вы, наверное, помните, что там, бывает
[04:14.760 --> 04:17.920]  конечно мап-джойн, когда редьюсер не надо, но в большинстве
[04:17.920 --> 04:20.440]  случаев, если брать общий случай джойна, редьюсер
[04:20.440 --> 04:22.840]  там надо, то скажите про хевинг.
[04:22.840 --> 04:34.040]  Хевинг это, по сути, УЭА, но поверх агрегации, то есть
[04:34.040 --> 04:37.560]  когда ты пишешь там селект, сумма чего-нибудь, фром
[04:37.560 --> 04:40.560]  чего-нибудь, и потом ты хочешь отфильтровать уже по
[04:40.560 --> 04:43.360]  этой сумме, не по полю, а по агрегату, вот тогда
[04:43.360 --> 05:06.320]  нужен хевинг.
[05:06.320 --> 05:09.480]  Ну если ты делаешь какую-то агрегацию, то нужно редьюсер.
[05:09.480 --> 05:12.480]  Чего?
[05:12.480 --> 05:15.280]  Можно цепочку, а точнее мап-редьюс полноценный
[05:15.280 --> 05:20.320]  плюс маппер и маппер, да, а можно прямо на редьюсе
[05:20.320 --> 05:23.320]  это делать, то есть когда ты посчитал агрегат, ты посчитал
[05:23.320 --> 05:26.920]  сумму какую-нибудь допустим, и дальше у тебя написано
[05:26.920 --> 05:30.880]  хевинг сумма больше пяти, и прямо на редьюсере можно
[05:30.880 --> 05:34.840]  вот по этому агрегату пофильтровать, и в больше пяти, значит выводим,
[05:34.840 --> 05:35.840]  иначе не выводим.
[05:35.840 --> 05:40.160]  Вот получается вот такая штука, то есть действительно
[05:40.160 --> 05:44.080]  на селект ве это мап, остальное это мап-редьюс, ну и бывает,
[05:44.080 --> 05:45.760]  что мап-редьюс еще с чем-нибудь.
[05:45.760 --> 05:51.840]  И получается, что действительно задачи мап-редьюса они
[05:51.840 --> 05:56.080]  хорошо ложатся на SQL, и если сделать SQL фреймворк, который
[05:56.080 --> 05:58.920]  будет это все реализовывать, нам будет намного проще,
[05:58.920 --> 06:04.080]  потому что, как вам наверное сказали на семинарах, для
[06:04.080 --> 06:07.240]  того чтобы писать на ходу, надо обладать большим количеством
[06:07.240 --> 06:10.640]  разных компетенций, то есть нужно знать сам мап-редьюс,
[06:10.640 --> 06:14.600]  нужно знать многопоточку, нужно знать джаву, питон,
[06:14.600 --> 06:18.480]  и хочется делать то же самое, но на SQL, когда вот кроме
[06:18.480 --> 06:20.120]  SQL по сути ничего знать не надо.
[06:20.120 --> 06:28.120]  И действительно в 2002 году появился фреймворк, не единственный,
[06:28.120 --> 06:31.360]  их появилось сразу несколько, вот если успеем, мы с вами
[06:31.360 --> 06:34.920]  рассмотрим совсем обзорно еще пару штук.
[06:35.000 --> 06:39.280]  Ну вот, самый известный это был Hive, Hive это SQL обертка
[06:39.280 --> 06:43.320]  поверх мап-редьюса, вот не нужно путать с UBD, у вас
[06:43.320 --> 06:47.400]  во всех был курс по базам данных, так, в прошлом году.
[06:47.400 --> 06:50.600]  Хорошо, напомните определение база данных, вот с UBD, что
[06:50.600 --> 06:52.920]  это вообще такое, это же не просто SQL.
[06:58.920 --> 07:04.040]  Да, как именно управлять, то есть какие действия должно
[07:04.040 --> 07:07.720]  делать это приложение, чтобы мы сказали, оно с UBD, вот просто
[07:07.720 --> 07:10.640]  какая-то программка, которая ходит в базу, дергает по
[07:10.640 --> 07:13.640]  селекту что-то, это же не с UBD, хотя она управляет базой.
[07:21.640 --> 07:22.640]  Чего?
[07:26.640 --> 07:31.040]  Свойства сохраняются, хотя это не обязательно, а что еще,
[07:31.040 --> 07:35.040]  то есть мы должны предоставлять все возможности для хранения
[07:35.040 --> 07:37.040]  и для обработки, и для оптимизации еще к тому же.
[07:40.040 --> 07:44.040]  Если мы посмотрим на Hive, то он ничего для хранения
[07:44.040 --> 07:49.040]  и для обработки нам не предоставляет, как мы увидим позже, Hive просто
[07:49.040 --> 07:53.040]  транслирует SQL в набор задач на Hadoop, и данные как хранились
[07:53.040 --> 07:57.040]  в HDFS, так и хранятся в HDFS, обрабатывали мы, как в Hadoop
[07:57.040 --> 08:00.040]  писали код, только мы сами писали кучу кода, а теперь
[08:00.040 --> 08:05.040]  он генерится, и все, поэтому Hive это не с UBD, это просто обертка.
[08:07.040 --> 08:11.040]  Но с приходом этой обертки появляется не только удобство
[08:11.040 --> 08:15.040]  в плане того, что две строчки SQL у тебя все готово, а
[08:15.040 --> 08:19.040]  появляется еще и проблема, которая обозначена на этом
[08:19.040 --> 08:22.040]  слайде, это схема, то есть когда у нас был чистый Hadoop, мы
[08:22.040 --> 08:26.040]  могли в этот Hadoop запихать что угодно, все равно мы сами
[08:26.040 --> 08:29.040]  код пишем, и мы сами с этим как-то разберемся, а теперь
[08:29.040 --> 08:33.040]  у нас появляется схема, и нужно думать, как нам эту схему,
[08:33.040 --> 08:36.040]  ну то есть как с этой схемой вообще работать.
[08:39.040 --> 08:43.040]  Что такое схема on read, схема on write, на курсе UBD объясняли?
[08:45.040 --> 08:49.040]  Ну вот если мы берем обычную базу данных, Oracle, PostgreU, там
[08:49.040 --> 08:53.040]  SQL, неважно, когда мы пишем данные, то сразу на этапе
[08:53.040 --> 08:57.040]  инсерта обычно проверяется, все ли у нас правильно записалось
[08:57.040 --> 09:00.040]  записалось и все ли соответствует нашей табличке, то есть если в
[09:00.040 --> 09:05.040]  табличке 5 полей, там int, а мы сделали insert 10 строковых
[09:05.040 --> 09:10.040]  полей, то наверное не сработает и будет ошибка, это конечно
[09:10.040 --> 09:17.040]  хорошо, но что делать, если данных много, и например мы
[09:17.040 --> 09:21.040]  пишем в эту нашу хайвовскую базу данных какие-то логи, мы
[09:21.040 --> 09:24.040]  их пишем, а читать мы может их вообще не будем, мы может
[09:24.040 --> 09:28.040]  будем читать самый последний какой-то кусочек head этих логов,
[09:28.040 --> 09:31.040]  то есть большая часть строк нам может быть не понадобится,
[09:31.040 --> 09:34.040]  тогда какой смысл делать вот эту проверку при каждом
[09:34.040 --> 09:38.040]  инсерте? При каждом инсерте мы проверку не делаем,
[09:40.040 --> 09:44.040]  то есть схема on write это когда проверка делается при записи,
[09:44.040 --> 09:49.040]  при инсертах, а схема on read это когда проверка делается при
[09:49.040 --> 09:54.040]  чтении, и вы тоже посмотрите на это на семинарах, это очень
[09:54.040 --> 09:59.040]  необычно, когда вы создали табличку, вот сделали create
[09:59.040 --> 10:03.040]  table, подали в эту табличку какую-нибудь большую папку,
[10:03.040 --> 10:08.040]  там гигов 100 размером, и у вас эта команда выполнилась
[10:08.040 --> 10:12.040]  за десятую часть секунды, все очень быстро, в ответе
[10:12.040 --> 10:15.040]  OK, все хорошо, и кажется табличка готова, мы можем с ней
[10:15.040 --> 10:18.040]  работать, потом мы начинаем данные читать, делаем первый
[10:18.040 --> 10:21.040]  селект, и у нас этот селект валится с ошибкой, вот это
[10:21.040 --> 10:26.040]  и есть схема on read, вот так работает Hive, давайте теперь
[10:26.040 --> 10:31.040]  посмотрим как он в плане архитектуры работает, тут большая сложная
[10:31.040 --> 10:36.040]  схема, но ее можно разбить на две части, и вот правая
[10:36.040 --> 10:39.040]  часть это знакомый вам ходуб, левая часть это то, что нам
[10:39.040 --> 10:44.040]  приносит Hive, что нам приносит Hive? Он нам приносит UI,
[10:44.040 --> 10:49.040]  UI может быть разным, на этом курсе мы будем работать
[10:49.040 --> 10:57.040]  с UI Apache Huey, и мы будем работать с Hive Shell, еще бывает
[10:57.040 --> 11:01.040]  Apache Zeppelin, еще бывают разные интерфейсы, вообще можно
[11:01.040 --> 11:05.040]  Hive даже к Юпитеру прицепить, в общем у нас есть интерфейс,
[11:05.040 --> 11:10.040]  в этом интерфейсе мы пишем запросы, и у нас работает
[11:10.040 --> 11:19.040]  драйвер, драйвер логично он все это как бы обрабатывает
[11:19.040 --> 11:23.040]  и передает дальше, дальше у нас идет компиляция, то
[11:23.040 --> 11:27.040]  есть здесь мы проверяем синтаксис, мы превращаем запрос,
[11:27.040 --> 11:32.040]  то есть мы превращаем SQL текст в план запроса, мы сегодня
[11:32.040 --> 11:36.040]  тоже посмотрим, что это за планы запроса такие, и этот
[11:36.040 --> 11:42.040]  план запроса дальше можно уже выполнить, и мы передаем
[11:42.040 --> 11:47.040]  этот план запроса на Execution Engine, и Execution Engine уже разбирается
[11:47.040 --> 11:50.040]  как этот запрос будет выполнять, здесь возможны варианты,
[11:50.040 --> 11:53.040]  смотрите какие возможны варианты, чтобы понять какие
[11:53.040 --> 12:00.040]  возможны варианты давайте вспомним язык SQL, все запросы
[12:00.040 --> 12:04.040]  которые мы пишем на языке SQL, на какие типы их можно
[12:04.040 --> 12:16.040]  разбить, ну там вот эти типы они обычно тремя буквами
[12:16.040 --> 12:22.040]  называются, DDL, да, что такое DDL, это Data Definition Language,
[12:22.040 --> 12:27.040]  то есть что это, это Create Table, например, там Create Database,
[12:27.040 --> 12:36.040]  дальше Manipulation, что делает Manipulation, ну да, что-то с этими
[12:36.040 --> 12:44.040]  данными делает, там Update и Insert, еще их 5 если я не ошибаюсь,
[12:44.040 --> 12:51.040]  хотя в литературе иногда то 4, то 5 пишут, Select как его
[12:51.040 --> 12:59.040]  называют, Data Query Language, ну то есть DDL это definition это мы
[12:59.040 --> 13:02.040]  определяем какая у нас будет схема, Manipulation это мы как-то
[13:02.040 --> 13:06.040]  с ней взаимодействуем, изменяем, а Select он ничего не изменяет,
[13:06.040 --> 13:19.040]  и это отдельно Data Query Language, еще два осталось, Transaction, да
[13:19.040 --> 13:23.040]  DCL, то есть это работа с транзакциями, это всякие там
[13:23.040 --> 13:32.040]  Commit, Rollback и еще, да, ну там смотря какое удаление,
[13:32.040 --> 13:36.040]  то есть есть удаление всей схемы данных, это DDL, а есть
[13:36.040 --> 13:42.040]  удаление просто данных, это DML, то есть Drop Table это будет
[13:42.040 --> 13:48.040]  DDL, а Delete по условию это будет DML, вот, какой пятый
[13:48.040 --> 13:56.040]  остался класс, он не сильно относится к Hive, в Hive он
[13:56.040 --> 14:01.040]  представлен достаточно бедно, Data Control Language, то есть работа
[14:01.040 --> 14:10.040]  с правами, вот, и что мы тут видим, у нас есть DDL, DDL здесь
[14:10.040 --> 14:14.040]  отдельная стрелочка, потому что когда мы пишем какой-нибудь
[14:14.040 --> 14:18.040]  DDL запрос, он не взаимодействует с самими данными, он взаимодействует
[14:18.040 --> 14:22.040]  со схемой данных, схема у нас хранится в MetaStore, MetaStore
[14:22.040 --> 14:31.040]  это вот тут написано, это специальная база данных, и она сохраняет
[14:31.040 --> 14:35.040]  метаинформацию про таблицу, какие поля, какие типы, кто создал,
[14:35.040 --> 14:39.040]  какие файлы, вот все, что мы знаем про базу данных, это
[14:39.040 --> 14:44.040]  MetaStore, и DDL он взаимодействует с MetaStore, дальше
[14:44.040 --> 14:56.040]  здесь Hive, вот он умеет взаимодействовать с Hadoop'ом
[14:56.040 --> 15:01.040]  тремя способами, большая часть запросов, которые мы будем
[15:01.040 --> 15:05.040]  делать, это запросы, которые порождают джобы, то есть мы написали
[15:05.040 --> 15:13.040]  SQL, она превратилась в десяток цепочку MapReduce.Job, но бывает такое,
[15:13.040 --> 15:17.040]  что мы данные откуда-то перемещаем, например, из одной папки
[15:17.040 --> 15:21.040]  в другую, и делается это без MapReduce, и тогда нам MapReduce
[15:21.040 --> 15:29.040]  не нужен, мы ходим напрямую в HDFS, и еще бывает отдельный тип
[15:29.040 --> 15:33.040]  запросов, это селекты без агрегации, то есть просто селект
[15:33.040 --> 15:37.040]  набор полей from таблица, без агрегации, без фильтрации,
[15:37.040 --> 15:41.040]  без ничего, чистый селект, Hive его делает без применения
[15:41.040 --> 15:45.040]  MapReduce, тоже отдельная стрелочка называется fetchResult.
[15:51.040 --> 15:57.040]  А теперь давайте посмотрим, как происходит преобразование
[15:57.040 --> 16:02.040]  SQL текста в MapReduce задачи, оно происходит в 4 шага,
[16:02.040 --> 16:06.040]  первый шаг это парсер, то есть просто проверка синтакса,
[16:06.040 --> 16:10.040]  за что мы написали действительно SQL, дальше идет
[16:10.040 --> 16:16.040]  семантический анализ, то есть проверка типов данных,
[16:16.040 --> 16:21.040]  например, если мы сравниваем в разделе where 2 поля,
[16:21.040 --> 16:25.040]  одно из них int, другое из них big integer, то какой будет
[16:25.040 --> 16:33.040]  в итоге тип. Да, big integer, то есть мы просто приведем
[16:33.040 --> 16:40.040]  они явно к большему типу. Ну и тут вообще мы проверяем
[16:40.040 --> 16:43.040]  типы данных, чтобы мы не сравнивали число со строкой,
[16:43.040 --> 16:47.040]  допустим. Раскрытие звездочки, вот с раскрытия звездочки
[16:47.040 --> 16:50.040]  тут я остановлюсь отдельно, только мне нужен маркер.
[16:56.040 --> 16:57.040]  Так.
[16:57.040 --> 17:26.040]  Вот как вы думаете, какой из вот таких запросов будет
[17:26.040 --> 17:41.040]  работать быстрее? Ну давайте посмотрим, то есть звездочка,
[17:41.040 --> 17:44.040]  вот как у меня написано на слайде, происходит раскрытие
[17:44.040 --> 17:47.040]  звездочки. Что такое звездочка? Это список всех полей,
[17:47.040 --> 17:52.040]  то есть у нас звездочка превращается в field1, field2,
[17:52.040 --> 18:03.040]  field3 и так далее. Здесь просто field1. Вот, если мы имеем дело
[18:03.040 --> 18:09.040]  с текстовым форматом данных, когда как только мы читаем
[18:09.040 --> 18:12.040]  какую-то запись, мы читаем всю строку, то здесь особой
[18:12.040 --> 18:16.040]  разницы нет. Но в хайве, ну не только в хайве, есть такое
[18:16.040 --> 18:22.040]  понятие, как колончные форматы хранения. Это всякие там,
[18:22.040 --> 18:48.040]  может быть слышали вот такие форматы. Вот, часто применяются
[18:48.040 --> 18:56.040]  такие форматы в работе с хайвом и со спарком, и так как
[18:56.040 --> 19:00.040]  у нас обычно колонок много, то здесь имеет значение,
[19:00.040 --> 19:03.040]  сколько колонок мы прочитаем. Мы можем прочитать не всю
[19:03.040 --> 19:08.040]  строку, а набор каких-то колонок. Поэтому вот это, это
[19:08.040 --> 19:11.040]  сразу будет работать очень долго, потому что нам приходится
[19:11.040 --> 19:16.040]  читать все колонки. Дальше вот это. Здесь мы читаем одну
[19:16.040 --> 19:20.040]  колонку. А что мы делаем с единичкой? Единичка это не
[19:20.040 --> 19:23.040]  номер колонки. Единичка это просто константа 1. То есть
[19:23.040 --> 19:27.040]  по сути в этом случае мы не читаем ничего, мы просто
[19:27.040 --> 19:31.040]  создаем еще одно поле эффективное, которое заполнено
[19:31.040 --> 19:35.040]  единичками. То есть самый лучший вариант это вот это.
[19:35.040 --> 19:39.040]  Потому что мы тут не читаем даже первое поле. Мы просто
[19:39.040 --> 19:42.040]  увидели, что строка есть, добавили единичку. Увидели,
[19:42.040 --> 19:52.040]  что строка есть, еще добавили единичку. Вот и следующий
[19:52.040 --> 19:56.040]  этап после семантического анализа это построение
[19:56.040 --> 20:00.040]  логического плана запроса. То есть здесь уже SQL окончательно
[20:00.040 --> 20:07.040]  превращается в набор джабов, в набор мапперов и редьюсеров.
[20:07.040 --> 20:10.040]  И последняя стадия это физический план запроса. То есть мы
[20:10.040 --> 20:13.040]  учитываем уже, как именно, на каких нодах хранятся
[20:13.040 --> 20:17.040]  данные. И в этом случае Hive при выполнении он будет знать
[20:17.040 --> 20:21.040]  откуда тот или иной кусочек данных читать, на какой машинке
[20:21.040 --> 20:24.040]  он есть, откуда его ближе достать и так далее.
[20:29.040 --> 20:31.040]  Вот давайте посмотрим на вот этот план запроса и
[20:31.040 --> 20:34.040]  попробуем по нему что-нибудь понять. Вот если здесь нормально
[20:34.040 --> 20:37.040]  видно, что вы можете сейчас сказать по вот этому вот
[20:37.040 --> 20:40.040]  набору такого текста, можно ли как-то восстановить запрос,
[20:40.040 --> 20:42.040]  понять, что там происходило.
[20:59.040 --> 21:03.040]  Ну что мы видим? Мы видим tablescan, причем два раза. То есть
[21:03.040 --> 21:07.040]  во-первых, мы видим mapReduce. Значит, у нас есть джаба,
[21:07.040 --> 21:11.040]  как минимум одна. Дальше мы видим mapOperator3, то есть
[21:11.040 --> 21:14.040]  вот это маппер, вот это редьюсер. На маппере у нас
[21:14.040 --> 21:18.040]  происходит tablescan, то есть, видимо, тут какой-то селед
[21:18.040 --> 21:24.040]  был по табличке books. Дальше filterOperator, значит, у нас
[21:24.040 --> 21:28.040]  тут было где-то where и было polyTimeStamp, которое мы вот
[21:28.040 --> 21:33.040]  так вот сравнивали. Второй tablescan, табличка users, и здесь
[21:33.040 --> 21:39.040]  фильтра никакого не было. Вот ReduceOperator, здесь у нас
[21:39.040 --> 21:43.040]  join. То есть, получается, мы поджойнили две таблички,
[21:43.040 --> 21:47.040]  причем одна, видимо, была в подзапросе, и мы там что-то
[21:47.040 --> 21:51.040]  пофильтровали. И поверх всего этого следующий stage это
[21:51.040 --> 21:55.040]  conditionalOperator, то есть вот этот весь наш join, он обернут
[21:55.040 --> 21:59.040]  еще в один запрос, в котором есть where.
[22:05.040 --> 22:08.040]  Ну и давайте посмотрим, какие таблички вообще у нас
[22:08.040 --> 22:14.040]  бывают. Что касается времени жизни,
[22:16.040 --> 22:19.040]  таблицы бывают постоянные и временные. Здесь, я думаю,
[22:19.040 --> 22:24.040]  все понятно. Что касается влияния на данные, у нас
[22:24.040 --> 22:27.040]  бывают два типа таблиц, и мы с вами на курсе будем
[22:27.040 --> 22:31.040]  работать в основном с таблицами external. Они вообще более
[22:31.040 --> 22:34.040]  популярны в том случае, если есть какие-нибудь ценные
[22:34.040 --> 22:38.040]  данные. Вот представьте, есть какая-нибудь жутко дорогая
[22:38.040 --> 22:43.040]  установка физическая, ну или какая-нибудь еще. Ее
[22:43.040 --> 22:47.040]  запустили, провели эксперимент, сохранили данные, и дальше
[22:47.040 --> 22:50.040]  разные команды аналитиков данных начинают с ними
[22:50.040 --> 22:54.040]  работать, с этими файлами. Может быть такое, что у
[22:54.040 --> 22:57.040]  разных команд им нужны разные данные, и у них будут
[22:57.040 --> 23:00.040]  разные таблицы. Но при этом источник данных, он будет
[23:00.040 --> 23:04.040]  общий для всех. И нам надо сделать так, чтобы никто
[23:04.040 --> 23:07.040]  ни в коем случае не сломал вот этот источник данных,
[23:07.040 --> 23:10.040]  чтобы он там не перезаписал ничего случайно, не удавил,
[23:10.040 --> 23:14.040]  не дропнул. Поэтому в таком случае мы делаем таблицу
[23:14.040 --> 23:18.040]  external, это значит, что мы берем источник данных,
[23:18.040 --> 23:22.040]  создаем свою схему, и эта схема накладывается как
[23:22.040 --> 23:27.040]  трафарет на этот источник данных. То есть мы читаем
[23:27.040 --> 23:31.040]  сам источник, но проводим его через эту схему, если
[23:31.040 --> 23:36.040]  мы что-то хотим дропнуть, удалить, изменить, то у нас
[23:36.040 --> 23:39.040]  происходит следующее, у нас или меняется сама схема,
[23:39.040 --> 23:43.040]  или используется такая штука, как Data Warehouse.
[23:43.040 --> 23:53.040]  То есть когда мы создаем вот такую external таблицу,
[23:53.040 --> 23:57.040]  у нее есть Data Warehouse, и если мы хотим данные перегруппировать,
[23:57.040 --> 24:00.040]  добавить, что-то поменять в них, исходник мы не меняем
[24:00.040 --> 24:04.040]  ни в коем случае. Все, что мы доделываем, все добавляется
[24:04.040 --> 24:08.040]  вот сюда, и мы потом работаем с исходником плюс DWH,
[24:08.040 --> 24:10.040]  ну или просто с DWH работаем.
[24:10.040 --> 24:15.040]  И даже если мы такую external таблицу полностью дропнем,
[24:15.040 --> 24:18.040]  у нас дропнется только схема данных, а сами данные
[24:18.040 --> 24:19.040]  у нас останутся.
[24:25.040 --> 24:29.040]  Вот, теперь давайте посмотрим в сторону вот такой задачки.
[24:29.040 --> 24:33.040]  И пока мы не знаем еще хайва, не умеем на нем писать,
[24:33.040 --> 24:36.040]  буквально через 5 минут мы начнем смотреть на код,
[24:36.040 --> 24:40.040]  и будем вместе с вами, у кого есть ноутбуки,
[24:40.040 --> 24:43.040]  то можете сразу подключиться и что-нибудь пробовать написать.
[24:43.040 --> 24:46.040]  Но пока мы до этого не дошли, давайте попробуем
[24:46.040 --> 24:48.040]  на MapReduce вот эту задачу решить.
[24:51.040 --> 24:54.040]  Вот, посмотрите на условия, посмотрите на данные,
[24:54.040 --> 24:56.040]  и ответьте на первый вопрос.
[24:56.040 --> 24:59.040]  Сколько будет MapReduce Job в решении такой задачи?
[25:06.040 --> 25:24.040]  Пока вот сюда мы не смотрим 3 пункта, создать базу данных
[25:24.040 --> 25:27.040]  и так далее, это мы с вами все сейчас пройдем.
[25:27.040 --> 25:29.040]  Пока мы просто на MapReduce.
[25:29.040 --> 25:33.040]  И потом мы сравним, как это делается на MapReduce и как
[25:33.040 --> 25:35.040]  это делается на хайве за 5 строчек.
[25:35.040 --> 26:00.040]  Ну и что у нас будет на первом маппере?
[26:00.040 --> 26:06.040]  Результат Map задачи будет какой?
[26:06.040 --> 26:13.040]  Так, хорошо, нам нужно среднее количество адресов
[26:13.040 --> 26:15.040]  по подсетям, но сами адреса нам не нужны,
[26:15.040 --> 26:19.040]  поэтому мы колонку адресов можем превратить в единички.
[26:19.040 --> 26:25.040]  И тут будет Subnet, единичка.
[26:25.040 --> 26:32.040]  Так, а здесь что будет?
[26:32.040 --> 26:35.040]  Subnet и Summa.
[26:35.040 --> 26:42.040]  Так, ну вы сказали, что здесь одна джоба, но вроде как
[26:42.040 --> 26:44.040]  у нас одна джоба кончилась на этом.
[26:44.040 --> 26:48.040]  Чего?
[26:48.040 --> 26:54.040]  А как мы будем это среднее вычислять?
[26:54.040 --> 27:01.040]  То есть получается, нужна все-таки еще одна джоба,
[27:01.040 --> 27:03.040]  и нам надо подумать, что будет здесь.
[27:03.040 --> 27:11.040]  Все, а все это что значит?
[27:11.040 --> 27:21.040]  То есть ты имеешь в виду взять все эти Subnet
[27:21.040 --> 27:23.040]  и сконкатенировать их между собой или что?
[27:23.040 --> 27:25.040]  Таких может много быть очень.
[27:25.040 --> 27:33.040]  Никак не меняем, хорошо.
[27:33.040 --> 27:42.040]  Дальше что будет тут?
[27:42.040 --> 28:01.040]  Это какое-то одно число, то есть в среднем
[28:01.040 --> 28:11.040]  сколько у нас адресов в среднем по всем нашим подсетям.
[28:11.040 --> 28:14.040]  Тогда с вот этим мы что-то делаем, потому что
[28:14.040 --> 28:17.040]  количество подсетей мы теперь в рамках редьюса не посчитаем.
[28:17.040 --> 28:44.040]  У нас просто разные подсети пойдут на разные редьюсеры.
[28:44.040 --> 28:46.040]  А еще раз, а как мы нашли числитель, где он у нас?
[28:46.040 --> 28:50.040]  N это же не числитель, это только одно число,
[28:50.040 --> 28:52.040]  а числитель это общая сумма.
[28:52.040 --> 29:05.040]  То есть нам нужно посчитать общую сумму, поделить на count.
[29:05.040 --> 29:07.040]  О, можем конечно.
[29:07.040 --> 29:09.040]  Тут может один быть, тут может быть просто какая-то
[29:09.040 --> 29:13.040]  константа или null, то есть какой-то один ключ.
[29:13.040 --> 29:21.040]  А дальше у нас получается кортеж, и тут будет N и 1.
[29:21.040 --> 29:37.040]  А здесь будет потом K.
[29:37.040 --> 29:39.040]  Все, вот так мы и посчитаем.
[29:39.040 --> 29:42.040]  И вот это будет у нас ответ, одно число.
[29:42.040 --> 29:45.040]  Ну и теперь давайте подумаем, сколько нам всякого кода
[29:45.040 --> 29:48.040]  нужно тут написать.
[29:48.040 --> 30:00.040]  Это у нас будет 4 питон скрипта и 2 bash.
[30:00.040 --> 30:03.040]  Вот, а теперь мы с вами попробуем это же самое,
[30:03.040 --> 30:15.040]  точно эту же задачку решить на SQL, на хайве.
[30:15.040 --> 30:25.040]  Так, сейчас мне нужно зайти на наш Hadoop cluster.
[30:25.040 --> 30:28.040]  Я захожу на другой, чтобы не грузить ресурсы, но он
[30:28.040 --> 30:51.040]  в большинстве похож на тот, который МИПТ.
[30:51.040 --> 30:55.040]  Вот, и так для начала давайте поймем, как вообще нам
[30:55.040 --> 30:57.040]  работать с хайвом.
[30:57.040 --> 30:59.040]  С хайвом можно работать несколькими способами.
[30:59.040 --> 31:03.040]  Первый, это просто запустили хайв.
[31:03.040 --> 31:05.040]  Да, вот, не обращайте внимания на этот permission-deny,
[31:05.040 --> 31:16.040]  то у вас на кластере их не будет.
[31:16.040 --> 31:21.040]  Так виден код или увеличите.
[31:21.040 --> 31:25.040]  Вот, и у нас есть интерактивный интерфейс хайв.
[31:25.040 --> 31:29.040]  И, например, мы можем посмотреть, какие базы данных у нас
[31:29.040 --> 31:33.040]  у нас тут есть.
[31:33.040 --> 31:38.040]  Show databases.
[31:38.040 --> 31:40.040]  Вот список баз данных.
[31:40.040 --> 31:44.040]  Ну и, в общем, можно в этом хайв-шеле выполнять разные SQL-команды.
[31:44.040 --> 31:48.040]  Можно прямо тут же обращаться к файловой системе
[31:48.040 --> 31:51.040]  через восхитительный знак.
[31:51.040 --> 31:55.040]  Вот, например, так. Ну, как в Юпитер ноутбуке.
[31:55.040 --> 31:58.040]  Можно обращаться к файловой системе HDFS.
[31:58.040 --> 32:10.040]  Причем не надо писать HDFS в начале.
[32:10.040 --> 32:13.040]  Да, не забываем ставить точку с запятой в конце.
[32:13.040 --> 32:17.040]  Вот, в общем, такой хайв-шел.
[32:17.040 --> 32:19.040]  Это первый вариант, как можно работать с хайвом.
[32:19.040 --> 32:22.040]  Второй вариант. Это можно выполнять однострочники.
[32:22.040 --> 32:30.040]  Например, хайв-database-example-e.
[32:30.040 --> 32:33.040]  Да, minus database. Это мы подключились, приконнектились к базе.
[32:33.040 --> 32:36.040]  И теперь мы выполняем команду show tables.
[32:49.040 --> 32:57.040]  Вот, ну мы видим, что у нас есть табличка subnets.
[32:57.040 --> 33:08.040]  Вот, ну а если мы хотим выполнить какой-нибудь большой файл,
[33:08.040 --> 33:12.040]  потому что в хайв-шеле писать большой SQL трудно.
[33:12.040 --> 33:20.040]  Потом через однострочник тоже большое что-то не напишешь.
[33:20.040 --> 33:25.040]  У нас остается третий способ. Это хайв-f.
[33:25.040 --> 33:29.040]  Вот, например, давайте посмотрим на вот этот файл.
[33:29.040 --> 33:37.040]  Так, не топ, наверное, файл.
[33:37.040 --> 33:41.040]  Вот, мы подключились к базе данных.
[33:41.040 --> 33:43.040]  Посмотрели какие таблицы есть.
[33:43.040 --> 33:47.040]  Описали таблицу describe и выполнили простой селект.
[33:47.040 --> 33:51.040]  Вот такой вот целый набор запросов. Давайте его выполним.
[33:51.040 --> 33:52.040]  Выполняется все просто.
[33:52.040 --> 34:09.040]  Hive-f. Test-hive.
[34:09.040 --> 34:13.040]  Вот, мы все видим. У нас сначала подключились к базе данных.
[34:13.040 --> 34:14.040]  Получили OK.
[34:14.040 --> 34:17.040]  Потом вывели список таблиц.
[34:17.040 --> 34:18.040]  Потом описали таблицу.
[34:18.040 --> 34:20.040]  Вот у нас два поля IP-маска.
[34:20.040 --> 34:25.040]  И вот наш селект. Все как на слайде.
[34:25.040 --> 34:28.040]  И есть еще четвертый способ.
[34:28.040 --> 34:55.040]  Для этого мне нужно пробросить порт.
[34:55.040 --> 35:00.040]  Вот, есть вот эта вот система. Ее называют Apache Huey.
[35:00.040 --> 35:06.040]  Вот это вот ругательное слово, оно расшифровывается как Hadoop User Experience.
[35:06.040 --> 35:12.040]  То есть здесь не только вещи, касающиеся хайва, здесь, в принципе, такая оболочка,
[35:12.040 --> 35:17.040]  которая делает работу с Hadoop более красивой и приятной.
[35:17.040 --> 35:23.040]  И, например, здесь можно тоже работать с какой-нибудь базой данных.
[35:23.040 --> 35:28.040]  Давайте найдем ее Example.
[35:28.040 --> 35:33.040]  Где у нас Example? Вот у нас Example.
[35:33.040 --> 35:44.040]  Можно открыть табличку, можно посмотреть, как она устроена.
[35:44.040 --> 35:57.040]  Ну и вот с автоподстановкой в более таком приятном интерфейсе можно выполнять какой-нибудь код.
[35:57.040 --> 36:00.040]  Вот такая вот штука.
[36:00.040 --> 36:04.040]  Теперь мы немножко поняли, как работать с оболочкой хайва.
[36:04.040 --> 36:08.040]  И давайте вернемся к нашему запросу.
[36:08.040 --> 36:10.040]  Как решать задачу? Мы поняли.
[36:10.040 --> 36:14.040]  Но теперь, чтобы ее все-таки решить на хайве, нам надо немного подготовиться.
[36:14.040 --> 36:20.040]  Нам надо создать базу данных, создать таблицу и уже на ней писать запрос.
[36:20.040 --> 36:22.040]  Давайте создадим базу данных.
[36:22.040 --> 36:25.040]  В принципе, вы можете делать все то же самое вместе со мной.
[36:25.040 --> 36:28.040]  Я думаю, это будет полезно.
[36:28.040 --> 36:31.040]  Создаем базу данных. Вот такой код.
[36:31.040 --> 36:36.040]  Что мы делаем? Вот название нашей базы, а вот location.
[36:36.040 --> 36:46.040]  Тест DVH. DVH это тот самый Date Warehouse, куда будет складываться все то, что должно попасть в нашу таблицу, а таблица external.
[36:46.040 --> 36:50.040]  То есть все то, что мы должны изменить.
[36:50.040 --> 36:54.040]  Поэтому давайте создадим такую базу данных.
[36:54.040 --> 36:58.040]  Сейчас я еще раз зайду в папку.
[37:06.040 --> 37:12.040]  Сначала мы базу данных удаляем, если она была, и создаем новую.
[37:15.040 --> 37:18.040]  Пока она создается, идем дальше.
[37:18.040 --> 37:20.040]  А дальше мы создаем таблицу.
[37:20.040 --> 37:24.040]  Первое мы подключаемся к базе данных, пишем use.
[37:24.040 --> 37:28.040]  Потом удаляем таблицу, если она есть, и дальше ее создаем.
[37:28.040 --> 37:30.040]  Вот create external table.
[37:30.040 --> 37:35.040]  Здесь, как в любом create table, прописываем типы полей, названия полей.
[37:35.040 --> 37:37.040]  И потом вот raw format delimited.
[37:37.040 --> 37:39.040]  Что вот это значит?
[37:39.040 --> 37:42.040]  Ну, это можно прописать.
[37:42.040 --> 37:44.040]  Обычным человеческим языком.
[37:44.040 --> 37:48.040]  И понятно, что поля у нас разделены табами.
[37:48.040 --> 37:54.040]  С точки зрения хайва здесь используется такая вещь, как Simple Serde.
[37:54.040 --> 37:57.040]  Serde это сериализация, диссериализация.
[37:57.040 --> 38:01.040]  В хайве есть много библиотек, которые называются Serde.
[38:01.040 --> 38:05.040]  И они не имеют никакого значения.
[38:05.040 --> 38:09.040]  В хайве есть много библиотек, которые называются Serde.
[38:09.040 --> 38:16.040]  И они отвечают за чтение данных из Hadoop, и за запись данных в Hadoop.
[38:16.040 --> 38:19.040]  Потому что в Hadoop может быть один формат хранения.
[38:19.040 --> 38:21.040]  Там могут быть какие-нибудь строки.
[38:21.040 --> 38:28.040]  И вот часто встречающийся кейс, если мы в Hadoop, например, имеем джейсоны.
[38:28.040 --> 38:31.040]  Как хранить джейсоны в базе данных?
[38:31.040 --> 38:34.040]  Что собой представляет джейсон?
[38:34.040 --> 38:40.040]  С точки зрения таблицы SQL.
[38:40.040 --> 38:45.040]  Обычно это какой-нибудь вложенный набор массивов и словарей.
[38:45.040 --> 38:48.040]  То есть словарь внутри массив, внутри еще словарь.
[38:48.040 --> 38:51.040]  Если распаковать, получится джейсон.
[38:51.040 --> 38:58.040]  И вот в хайве есть разные библиотеки, которые, например, могут превратить джейсон в такую таблицу.
[38:58.040 --> 39:02.040]  Или другой кейс, который вы будете разбирать на семинарах.
[39:02.040 --> 39:11.040]  Когда у нас в Hadoop хранится какая-то помойка текста, совершенно не распаршенная, с кучей какого-то мусора.
[39:11.040 --> 39:15.040]  И вы к этому всему применяете Regex Serde.
[39:15.040 --> 39:19.040]  То есть пишете специальную регулярку, запихиваете ее в Hive.
[39:19.040 --> 39:26.040]  И Hive, на лету при создании таблицы, вычленяет колонки из этого мусорника, и у вас создается табличка.
[39:26.040 --> 39:30.040]  Но это такие более сложные кейсы, вы будете их разбирать на семинаре.
[39:30.040 --> 39:36.040]  Здесь у нас самый простой кейс, когда у нас просто идет разделение по табам.
[39:36.040 --> 39:46.040]  Дальше последние две строчки, это store test.xfile, то есть как хранится, ну и где хранится путь к данным.
[39:48.040 --> 39:52.040]  Давайте снова выполним, мы видим, что база данных у нас создалась.
[39:53.040 --> 39:57.040]  Теперь табличка, табличка у нас вот такая.
[40:02.040 --> 40:06.040]  У кого-нибудь есть возможность за мной повторять или пока вы этого не делаете?
[40:10.040 --> 40:12.040]  А что не получается?
[40:14.040 --> 40:16.040]  Что, порт пробросить?
[40:16.040 --> 40:18.040]  Порт пробросить или что?
[40:22.040 --> 40:30.040]  Ну дело в том, что да, у нас на кластере не очень новый клиент Hive.
[40:30.040 --> 40:34.040]  То есть в Hive есть сейчас два клиента, есть Hive и есть Beeline.
[40:34.040 --> 40:36.040]  И чем они отличаются?
[40:36.040 --> 40:40.040]  Hive более толстый клиент, он при запуске стартует виртуальную машину Java,
[40:40.040 --> 40:46.040]  подключается к Hive сервер, а Beeline в этом смысле проще.
[40:46.040 --> 40:49.040]  Для него Java не нужна, и он запускается быстрее.
[40:53.040 --> 40:59.040]  Можно mcedit, можно vim, можно touch, ну в общем, как угодно в Linux.
[41:05.040 --> 41:11.040]  Ну а теперь, когда мы уже создали файлы, когда у нас есть табличка база данных и колонки,
[41:13.040 --> 41:17.040]  кто-нибудь может написать SQL-код, который получится.
[41:18.040 --> 41:21.040]  Вы все проходили базы данных в прошлом семестре.
[41:21.040 --> 41:24.040]  Наверное, написали коды посложнее. Что?
[41:25.040 --> 41:27.040]  Ну хотя бы те, кто проходил.
[41:30.040 --> 41:34.040]  Тут много людей, которые кивали, когда я спросил, были ли базы данных у вас.
[41:41.040 --> 41:46.040]  Ну можете просто рассказать, что у нас будет, какие будут запросы.
[41:51.040 --> 41:52.040]  Чего?
[41:58.040 --> 42:00.040]  Таблица есть, которая называется subnets.
[42:01.040 --> 42:03.040]  Вот, а задачка у нас вот такая.
[42:05.040 --> 42:11.040]  В этой таблице лежит два поля. Вот, собственно, сэмпл таблички, он прямо на слайде есть.
[42:21.040 --> 42:22.040]  Ну что?
[42:25.040 --> 42:30.040]  Так, губай по маске, дальше sumo по маске, и потом усоединяем.
[42:31.040 --> 42:32.040]  Ну вот, например, вот так.
[42:33.040 --> 42:36.040]  Правда, нам еще с вами не нужны пока что три поля.
[42:37.040 --> 42:38.040]  Вот так.
[42:39.040 --> 42:40.040]  И вот.
[42:41.040 --> 42:42.040]  Вот, вот так.
[42:43.040 --> 42:44.040]  Вот так.
[42:45.040 --> 42:46.040]  Вот, и вот так.
[42:47.040 --> 42:48.040]  Ну, вот.
[42:49.040 --> 42:50.040]  Ну вот, и вот так.
[42:51.040 --> 42:52.040]  Вот так.
[42:53.040 --> 42:54.040]  Ну вот.
[42:55.040 --> 42:56.040]  А, вот так.
[42:57.040 --> 42:58.040]  Ну вот.
[42:58.040 --> 43:01.040]  Правда, нам еще с вами не нужны пока что тейбл-сэмплы.
[43:01.040 --> 43:19.640]  Вот, то есть можно сумму, можно каунд, то есть сколько
[43:19.640 --> 43:23.400]  у нас вообще айпишников в каждой подсети и потом
[43:23.400 --> 43:24.400]  усредняем.
[43:24.400 --> 43:30.680]  Заметьте, что все настройки, которые мы делали для
[43:30.680 --> 43:34.440]  ходупа, то есть название джабы, количество редьюсеров,
[43:34.440 --> 43:36.880]  все, что мы указывали в ходупе, все можно указывать
[43:36.880 --> 43:45.960]  и здесь, то есть вот через сет, сет и дальше конфиг.
[43:45.960 --> 43:49.360]  Давайте теперь посмотрим на план запроса, который
[43:49.360 --> 43:50.360]  у нас получился.
[43:50.360 --> 43:56.640]  Чтобы посмотреть план запроса, мы просто перед запросом
[43:56.640 --> 44:00.680]  вставим ключевое слово explain и дальше, как обычно,
[44:00.680 --> 44:01.680]  запускаем код.
[44:01.680 --> 44:08.800]  Тогда у нас вместо выполнения запроса мы изгенерим планы
[44:08.800 --> 44:09.800]  и на этом остановимся.
[44:09.800 --> 44:19.160]  Вот, что мы видим?
[44:19.160 --> 44:22.000]  Во-первых, мы видим, что у нас как бы две джабы было,
[44:22.000 --> 44:25.080]  мы с вами тут обсуждали на доске, что две джабы,
[44:25.080 --> 44:27.120]  а стейджа почему-то три.
[44:27.120 --> 44:29.960]  На самом деле три стейджа это как раз и значит две
[44:29.960 --> 44:33.640]  джабы, потому что последний стейдж, вот этот, он отвечает
[44:33.640 --> 44:34.640]  просто за вывод.
[44:34.640 --> 44:39.520]  Это вот та самая стрелочка fetch, которая в архитектуре
[44:39.520 --> 44:45.320]  хайва шла вот сюда вниз, fetch results, она вот отдельно
[44:45.320 --> 44:47.120]  и здесь никакого map reducer нету.
[44:47.120 --> 44:53.040]  Она отвечает за то, что мы, например, поставим лимит
[44:53.040 --> 45:00.320]  вывода какой-нибудь, в общем, вот это последний стейдж.
[45:00.320 --> 45:06.560]  Перед этим идет у нас вот такой стейдж map reduce, что
[45:06.560 --> 45:07.560]  мы здесь видим?
[45:07.600 --> 45:13.440]  У нас есть group by, у нас есть aggregation count 1 и вот мы
[45:13.440 --> 45:15.880]  на стадии reducer видим, что у нас работает count.
[45:15.880 --> 45:25.120]  И здесь, кстати, видим lazy binaries rd, то есть как происходит
[45:25.120 --> 45:29.360]  обмен данными между хайвом и ходупом, потому что раз
[45:29.360 --> 45:32.280]  у нас разные стейджи, значит это разные джобы.
[45:32.280 --> 45:35.480]  Между джобами, где сохраняются промежуточные данные в
[45:35.920 --> 45:37.640]  и потом опять из ходу почитаются.
[45:37.640 --> 45:45.760]  Вот, ну а здесь у нас на этапе reducer происходит average.
[45:45.760 --> 45:50.760]  Так.
[45:50.760 --> 46:02.920]  Вот, теперь давайте этот код наконец-то выполним
[46:02.920 --> 46:04.400]  и посмотрим, что он нам выдаст.
[46:04.400 --> 46:26.360]  Сейчас мы впервые увидим, как выполняется код на хайве
[46:26.360 --> 46:28.480]  и при этом получается map reduce задача.
[46:28.480 --> 46:33.440]  Вот видите, total jobs равно два.
[46:33.480 --> 46:37.840]  Number of reduced tasks, вот мы установили через config, что это 10, вот
[46:37.840 --> 46:38.840]  у нас 10.
[46:38.840 --> 46:43.200]  А кто может сказать, во второй джобе сколько будет
[46:43.200 --> 46:44.200]  reducer?
[46:44.200 --> 46:46.080]  Вот та джоба, которая средние берет.
[46:46.080 --> 46:50.200]  Один, потому что один ключ.
[46:50.200 --> 46:54.480]  Здесь ключей много, в первой джобе нам пришлось ограничить
[46:54.480 --> 46:55.480]  десяткой.
[46:55.480 --> 47:13.600]  Как вы думаете, какая джоба будет работать быстрее,
[47:13.600 --> 47:16.600]  первая или вторая?
[47:16.600 --> 47:17.600]  Почему?
[47:17.600 --> 47:19.320]  Да, меньше данных.
[47:19.320 --> 47:44.520]  7 гигов, ну кластер поменьше, чем тот, на котором вы домашки
[47:44.520 --> 47:45.520]  делаете.
[47:45.840 --> 47:46.840]  Это такой резервный кластер.
[47:46.840 --> 47:53.160]  Ну и скорее всего, тут кто-нибудь что-нибудь сейчас тоже считает.
[47:53.160 --> 47:57.000]  Вот, первая джоба отработала.
[47:57.000 --> 48:07.480]  И начинается вторая джоба, и тут написано number of reduced
[48:07.480 --> 48:10.960]  tasks determined at compile time 1, то есть мы уже тут ничего
[48:10.960 --> 48:14.960]  не устанавливали, а мы просто, у нас один ключ.
[48:14.960 --> 48:25.440]  Ну все, у нас все посчиталось.
[48:25.440 --> 48:28.720]  Запомним вот это время, total map reduced time spent, мы будем
[48:28.720 --> 48:31.720]  оптимизировать код, или мы с вами сейчас, или вы
[48:31.720 --> 48:32.720]  на семинарах.
[48:32.720 --> 48:36.040]  В общем, это такое максимальное время, оно будет меньше.
[48:36.040 --> 48:37.520]  Ну и сейчас 8 с половиной минут.
[48:37.520 --> 48:41.200]  Вот такой вот код.
[48:41.760 --> 48:44.760]  Так.
[48:49.760 --> 48:52.680]  А теперь давайте подумаем, как можно оптимизировать
[48:52.680 --> 48:53.680]  этот код.
[48:55.680 --> 48:56.680]  Да.
[49:05.680 --> 49:10.280]  Само выполнение на map reduced оно было бы примерно
[49:10.360 --> 49:12.640]  таким же, потому что это все равно код выполняется
[49:12.640 --> 49:13.640]  на ходупе.
[49:13.640 --> 49:17.880]  Возможно, мы немного сэкономили бы на преобразовании, на
[49:17.880 --> 49:20.880]  генерации этого map reduced.
[49:20.880 --> 49:23.560]  Да, не сильно отличался.
[49:23.560 --> 49:28.880]  А сейчас мы будем с вами придумывать оптимизации,
[49:28.880 --> 49:32.400]  которые помогут нашему коду сильно отличаться в
[49:32.400 --> 49:36.120]  лучшую сторону.
[49:36.120 --> 49:41.480]  Давайте представим такой кейс, что у нас есть таблица
[49:41.480 --> 49:45.520]  со всеми IT-специалистами России, допустим, или даже
[49:45.520 --> 49:49.840]  не России, а мира, и мы знаем про этих IT-специалистов
[49:49.840 --> 50:08.840]  Некоторый набор данных, например, country, city,
[50:08.840 --> 50:13.360]  ну допустим, 4 поля нам хватит, и нам нужно по этой таблице
[50:13.360 --> 50:15.920]  проводить регулярную аналитику.
[50:15.920 --> 50:18.440]  Например, искать среднюю зарплату специалистов
[50:18.440 --> 50:21.240]  в России, сравнивать ее с другими странами, считать
[50:21.240 --> 50:25.460]  среднюю зарплату по странам, максимальную там за какой-нибудь
[50:25.460 --> 50:27.480]  период, если мы тут дату добавим.
[50:27.480 --> 50:34.800]  В общем, мы постоянно взаимодействуем с вот этим полем в сканторе,
[50:34.800 --> 50:37.520]  и получается, что нам нужно, даже если нам нужна одна
[50:37.520 --> 50:41.040]  страна, нам нужно делать full table scan по всей таблице.
[50:41.040 --> 50:45.920]  Чтобы такого не было, чтобы это как-то оптимизировать,
[50:45.920 --> 50:49.680]  используется такая вещь, как партиционирование.
[50:49.680 --> 50:57.760]  Потому что и в случае, когда мы находим среднее, нам
[50:57.760 --> 51:01.640]  нужно отдельно друг друга страны обсчитывать, и когда
[51:01.640 --> 51:04.720]  мы находим какую-то одну страну, нам нужно тоже ее
[51:04.720 --> 51:09.040]  искать по всей таблице, и нам бы хорошо иметь заранее
[51:09.040 --> 51:13.360]  данные разложенные, чтобы мы каждую страну хранили
[51:13.360 --> 51:14.360]  где-то отдельно.
[51:14.520 --> 51:16.640]  Этот механизм и называется партиционирование.
[51:16.640 --> 51:19.920]  Как он работает?
[51:19.920 --> 51:23.920]  Берется вот эта таблица, и у нас готовятся данные
[51:23.920 --> 51:29.360]  заранее, по каждому ключу создается отдельная папка,
[51:29.360 --> 51:32.000]  и в эту папку складываются данные для этого ключа.
[51:32.000 --> 51:36.240]  То есть вот у нас отдельная будет папка для России,
[51:36.240 --> 51:41.080]  отдельная папка будет там для Америки, ну и так далее.
[51:41.080 --> 51:50.280]  И в эту папку у нас попадут три поля конкретно для этого
[51:50.280 --> 51:51.280]  ключа.
[51:51.280 --> 51:57.040]  И тогда, если мы будем искать, например, делать аналитику
[51:57.040 --> 52:01.080]  по одной стороне, мы сначала найдем нужную страну, нужную
[52:01.080 --> 52:03.680]  папку, и внутри этой папки будем уже ходить.
[52:12.080 --> 52:17.080]  Так, сейчас мы с вами посмотрим тоже, как это делается в коде.
[52:37.400 --> 52:40.240]  Таблица будет новая, я говорю это о том, с точки зрения
[52:40.240 --> 52:41.480]  синтаксиса и как данные хранятся.
[52:41.480 --> 52:49.760]  В одной папке одна таблица, но в этой папке появится
[52:49.760 --> 52:50.760]  подпапки.
[52:50.760 --> 52:55.680]  Сейчас мы это увидим физически, как это все происходит.
[52:55.680 --> 53:08.280]  Вот с точки зрения синтаксиса мы создаем новую таблицу
[53:08.320 --> 53:11.240]  и пишем сюда одно поле.
[53:11.240 --> 53:15.080]  Мы сейчас вернемся от этой предметной области обратно
[53:15.080 --> 53:17.080]  к нашим подсетям.
[53:17.080 --> 53:22.240]  Мы создаем таблицу, в ней одно поле, а второе поле
[53:22.240 --> 53:25.480]  у нас идет сюда, partition by.
[53:25.480 --> 53:28.600]  Почему его нету даже в create table, мы тоже сейчас поймем,
[53:28.600 --> 53:31.760]  когда у нас код это работает и когда мы посмотрим живьем
[53:31.760 --> 53:33.240]  на папке, которая получится.
[53:33.240 --> 53:42.560]  Мы создаем таблицу, переносим данные из старой таблицы
[53:42.560 --> 53:43.880]  в новую таблицу.
[53:43.880 --> 53:47.480]  Осталось понять вот это, первая строчка, dynamic partition
[53:47.480 --> 53:48.480]  mode non-strict.
[53:48.480 --> 53:53.760]  Что это значит, на самом деле в хайве может быть
[53:53.760 --> 53:56.880]  партиционирование строгое и нестрогое, по умолчанию
[53:56.880 --> 53:57.880]  оно строгое.
[53:57.880 --> 54:00.360]  Строгое это значит, что мы заранее знаем сколько
[54:00.360 --> 54:02.640]  будет у нас папок, сколько будет ключей.
[54:02.720 --> 54:08.160]  То есть мы заранее знаем сколько у нас стран и готовим
[54:08.160 --> 54:09.160]  эти папки.
[54:09.160 --> 54:13.240]  Но это не всегда удобно, иногда мы просто не знаем
[54:13.240 --> 54:14.240]  сколько их будет.
[54:14.240 --> 54:16.960]  Вот, например, в случае с подсетями мы понятия не
[54:16.960 --> 54:20.240]  имеем заранее, сколько у нас подсетей в этой табличке
[54:20.240 --> 54:21.240]  есть.
[54:21.240 --> 54:24.280]  Поэтому нам хочется иметь возможность создавать
[54:24.280 --> 54:27.440]  папки на лету, пришла новая подсеть, мы создали новую
[54:27.440 --> 54:30.800]  папку и туда складируем данные для этой подсети.
[54:30.800 --> 54:33.040]  Ещё одна подсеть новая пришла, опять новую папку
[54:33.040 --> 54:35.240]  создаём и так далее.
[54:41.880 --> 54:45.680]  Давайте этот код выполним, посмотрим как создаются
[54:45.680 --> 54:50.920]  папки, куда переносятся данные и у вас наверно сразу
[54:50.920 --> 54:54.880]  возник вопрос, таблица видик стёрнул, о каком вообще
[54:54.880 --> 54:58.240]  переносе данных, рассортировке по каким-то папкам может
[54:58.240 --> 54:59.640]  идти речь, она же не изменяемая.
[55:01.640 --> 55:06.360]  А как маски приведут к тому, что у нас папки появятся
[55:06.360 --> 55:07.920]  разные и в них данные появятся?
[55:21.920 --> 55:25.320]  Хорошо, но когда мы создаём таблицу партиционированную,
[55:25.320 --> 55:28.480]  мы не знаем, нам понадобится Россия или Польша или ещё
[55:28.480 --> 55:29.480]  какая-то страна.
[55:30.800 --> 55:41.520]  Как оно отражается в твоей частине, как оно формируется
[55:41.520 --> 55:45.520]  в таблицах или в метаинформациях?
[55:47.520 --> 55:50.880]  Метаинформация у нас хранится в базе данных, как я в начале
[55:50.880 --> 55:54.640]  сказал, у нас есть база, там есть специальные таблички
[55:54.640 --> 55:59.040]  и в этих табличках хранятся данные про то, какие поля
[55:59.280 --> 56:03.320]  в таблице, кто создатель, какие права доступа, какие
[56:03.320 --> 56:05.760]  данные, где эти данные лежат, вся информация.
[56:09.760 --> 56:12.280]  Да, они-то не трогаются, но здесь как раз тот случай,
[56:12.280 --> 56:15.840]  когда нам их нужно потрогать, потому что нам нужно, чтобы
[56:15.840 --> 56:17.880]  у нас появилась другая структура папок.
[56:19.880 --> 56:22.320]  Как раз, чтобы не делать full table scan при поиске нужной
[56:22.320 --> 56:26.480]  стороны, допустим, надо, чтобы по странам мы их разложили,
[56:26.920 --> 56:29.360]  а данные изменить мы не можем, поэтому что нам приходит
[56:29.360 --> 56:30.360]  на помощь?
[56:30.360 --> 56:33.520]  Нам приходит на помощь Data Warehouse, вот этот самый
[56:33.520 --> 56:40.160]  location, который вот тут, где у нас создание базы данных,
[56:40.160 --> 56:42.600]  вот этот location, который мы создали при создании
[56:42.600 --> 56:46.840]  BD, вот это у нас Data Warehouse и сейчас нам придется скопировать
[56:46.840 --> 56:50.720]  данные вот сюда, они вот тут будут разложены по папкам
[56:50.720 --> 56:54.480]  и мы потом будем при работе с этой таблицей обращаться
[56:54.480 --> 57:00.680]  уже к Data Warehouse, в данном случае, да, бывают разные
[57:00.680 --> 57:03.960]  кейсы, бывает, когда мы делаем инсерты и в Data Warehouse помещаются
[57:03.960 --> 57:06.960]  только инсерты, а здесь нам надо пересортировать
[57:06.960 --> 57:09.760]  все, поэтому придется копировать тоже все.
[57:18.760 --> 57:21.200]  Пока работает наш код, ну, заметьте, тут редьюсера
[57:21.200 --> 57:22.880]  у нас не будет, а будут только мапперы.
[57:25.480 --> 57:29.480]  Вот, наш Data Warehouse, давайте посмотрим.
[57:29.480 --> 57:56.480]  А что именно мы запоминаем?
[57:56.480 --> 58:05.040]  Так, во-первых, маска будет, да, весить много, во-вторых,
[58:05.040 --> 58:10.200]  тебе придется обойти всю таблицу, ну, то есть, у нас,
[58:10.200 --> 58:13.720]  так нам нужна одна страна Россия, а так у нас там 289
[58:13.720 --> 58:17.360]  стран, тебе придется в 289 раз больше данных каждый
[58:17.360 --> 58:21.520]  раз читать и тут как бы неизвестно, что лучше, раз скопировать
[58:21.520 --> 58:24.480]  или на каждом запросе читать в 200 раз больше данных.
[58:27.480 --> 58:33.480]  Вот, так, где у нас Data Warehouse?
[58:35.480 --> 58:40.480]  А, тут немного у меня неправильное название, в названии базы данных.
[58:46.480 --> 58:51.480]  Вот, в нашем Data Warehouse появилась табличка Subnet Part.
[58:56.480 --> 59:03.480]  В этой таблице появились папки.
[59:03.480 --> 59:06.480]  У каждой папки, видите, название маска равно чему-то.
[59:08.480 --> 59:12.480]  Давайте посмотрим на эту папку, на любую.
[59:16.480 --> 59:19.480]  Вот, эта папка соответствует партиции.
[59:22.480 --> 59:25.480]  В этой папке у нас есть файлы, давайте откроем
[59:25.480 --> 59:27.480]  какой-нибудь файл на выбор.
[59:42.480 --> 59:43.480]  Что мы видим?
[59:43.480 --> 59:46.480]  Мы видим одну колонку, но у нас всего было две, осталась одна.
[59:46.480 --> 59:54.480]  Именно поэтому, вот здесь, мы в разделе Create Tables оставляем одну колонку,
[59:54.480 --> 59:57.480]  потому что и в нашей таблице, по сути, будет одна колонка.
[59:57.480 --> 01:00:00.480]  Вторая колонка полностью перекочевала в название папок.
[01:00:10.480 --> 01:00:15.480]  Давайте теперь посмотрим, как наш код будет выполняться на этой нашей новой таблице.
[01:00:15.480 --> 01:00:25.480]  Все, что нам надо сделать, это заменить Subnet на Subnet Part и выполнить код еще раз.
[01:00:38.480 --> 01:00:43.480]  А пока давайте посмотрим, какие тут возможны варианты с этими партициями.
[01:00:43.480 --> 01:00:49.480]  Вложенные партиции в Hive делать нельзя, поэтому там будет другой механизм.
[01:00:49.480 --> 01:00:59.480]  Если мы хотим сделать партиционирование сначала по стране, потом по городу, допустим,
[01:00:59.480 --> 01:01:04.480]  то вложенные партиции сделать не получится, а вот партиции по двум ключам спокойно можно сделать.
[01:01:04.480 --> 01:01:08.480]  То есть, можно будет, чтобы был там Part 1.
[01:01:13.480 --> 01:01:28.480]  Вот, то есть, мы разбиваем и по стране, и по городу. Чем это плохо, как вы думаете?
[01:01:28.480 --> 01:01:37.480]  Очень много маленьких папок, поэтому вот так обычно не делают.
[01:01:37.480 --> 01:01:45.480]  Да, там вопрос какой-то. Так обычно не делают, а вместо этого делают следующий уровень,
[01:01:45.480 --> 01:01:48.480]  который называется бакетирование или кластеризация.
[01:01:48.480 --> 01:01:57.480]  То есть, если партиции у нас делаются тогда, когда ключей точно немного,
[01:01:57.480 --> 01:02:03.480]  то стран у нас сколько? 289, если я правильно помню, примерно так. Ну, не 5 миллионов.
[01:02:03.480 --> 01:02:09.480]  А городу у нас намного больше, там уже счет идет на сотни тысяч, по-моему.
[01:02:09.480 --> 01:02:16.480]  Поэтому в этом случае, для полей, у которых много уникальных ключей,
[01:02:16.480 --> 01:02:21.480]  мы используем не партиционирование, а бакетирование. Чем оно отличается?
[01:02:21.480 --> 01:02:28.480]  Физически один бакет это не одна партиция, а один файл. То есть, это следующий уровень вложенности.
[01:02:29.480 --> 01:02:38.480]  Потом, как происходит разбиение на бакеты. Если в партициях мы имеем столько партиций,
[01:02:38.480 --> 01:02:43.480]  сколько ключей, то что касается бакетов, ключей может быть много.
[01:02:43.480 --> 01:02:49.480]  Поэтому там используется любимая нами формула еще из MapReduce, вот такая.
[01:02:49.480 --> 01:03:01.480]  HashAdcap по модулю на B, B это количество бакетов. То есть, количество бакетов,
[01:03:01.480 --> 01:03:06.480]  как и количество редьюсеров мы задаем сами, потому что если мы это все оставим на откуп
[01:03:06.480 --> 01:03:10.480]  самого хайву, он нагенерит очень много файлов маленьких.
[01:03:10.480 --> 01:03:22.480]  Пока что вернемся к нашим партизиям и давайте смотреть. Вместо 8,5 минут мы имеем 5 минут.
[01:03:22.480 --> 01:03:27.480]  Вот, хорошее такое ускорение получилось примерно на треть.
[01:03:27.480 --> 01:03:35.480]  Что касается бакетов, давайте посмотрим подробнее здесь, как это происходит.
[01:03:35.480 --> 01:03:40.480]  Вам есть сейчас пример кода, показывать про бакеты не буду, потому что у нас все равно
[01:03:40.480 --> 01:03:45.480]  два поля. Тут уже с нашими данными бакетировать нечего.
[01:03:45.480 --> 01:03:49.480]  Но в принципе мы можем использовать бакетирование.
[01:03:49.480 --> 01:04:03.480]  Вот, бакет-тейпл.
[01:04:19.480 --> 01:04:36.480]  Хороший пример здесь. То есть, мы указываем clusterBy по какому полю или по каким полям.
[01:04:36.480 --> 01:04:44.480]  И дальше int сколько бакетов. То есть, мы явно указываем вот это число B.
[01:04:44.480 --> 01:04:54.480]  Ну и дальше у нас следующий уровень, если не помогает не вот это, не вот это.
[01:04:54.480 --> 01:04:59.480]  Допустим, данные были собраны как-то не очень правильно и получилось, что больше всего
[01:04:59.480 --> 01:05:03.480]  записей из России и больше всего записей здесь, из Москвы.
[01:05:03.480 --> 01:05:11.480]  И когда мы делали это разбиение, у нас все равно 90% записей оказалось вот здесь,
[01:05:11.480 --> 01:05:17.480]  у нас получился самый большой такой бакет. Что мы в этом случае делаем?
[01:05:17.480 --> 01:05:20.480]  Мы в этом случае используем ключевое слово skewedBy.
[01:05:20.480 --> 01:05:29.480]  Это такой последний шанс все-таки еще раз разбить данные, еще раз оптимизировать.
[01:05:29.480 --> 01:05:36.480]  SkewedBy он уже вручную с конкретным бакетом можно поработать и как-нибудь разбить вот этот
[01:05:36.480 --> 01:05:40.480]  один большой бакет по какому-нибудь условию.
[01:05:51.480 --> 01:06:00.480]  Если мы его разбили и у нас оказалось, что в основном RuMSK 90%, значит надо разбить как-то еще,
[01:06:00.480 --> 01:06:04.480]  потому что вот здесь допустим у нас будет не name salary, а будет больше полей.
[01:06:04.480 --> 01:06:07.480]  И нам надо учиться как-то и по этим полям разбивать.
[01:06:07.480 --> 01:06:10.480]  Ну просто потому что разбиение по вот этим ничего не дало.
[01:06:15.480 --> 01:06:17.480]  Вот в этом случае у нас используется skewedBy.
[01:06:22.480 --> 01:06:31.480]  Где еще можно использовать бакетирование? Можно его использовать в сэмплинге.
[01:06:35.480 --> 01:06:38.480]  То есть вот есть такая утилита в хайве как tableSample.
[01:06:38.480 --> 01:06:44.480]  Она используется в том случае, если вам, например, нужно что-то очень быстро, но не точно посчитать.
[01:06:47.480 --> 01:06:52.480]  В этом случае мы делаем sample. Делается это все в одну строчку.
[01:06:52.480 --> 01:06:59.480]  То есть мы указываем таблицу и указываем условия, соответственно с которыми мы будем формировать выборку.
[01:07:00.480 --> 01:07:05.480]  Есть два типа сэмплинга. BucketSampling и BlockSampling.
[01:07:06.480 --> 01:07:12.480]  Если у нас есть бакеты, если таблица разбита на бакеты, мы можем просто указать,
[01:07:12.480 --> 01:07:20.480]  какие бакеты или сколько бакетов мы берем, например, каждый третий из 32.
[01:07:20.480 --> 01:07:24.480]  То есть разбили все бакеты по 32 и берем каждый третий.
[01:07:24.480 --> 01:07:28.480]  Как именно, вот, рандомно. А можно не рандомно, можно по какому-то правилу.
[01:07:30.480 --> 01:07:33.480]  Сделали такую выборку и дальше можем с ней работать.
[01:07:33.480 --> 01:07:37.480]  Если бакетов нет, то нам на помощь приходит BlockSampling.
[01:07:37.480 --> 01:07:39.480]  Это, собственно, разбиение по блокам.
[01:07:39.480 --> 01:07:46.480]  И здесь мы можем указать не только блоки, здесь мы можем указать количество процентов,
[01:07:52.480 --> 01:07:56.480]  количество байт, вот в мегабайтах, в гигабайтах и количество строк.
[01:07:59.480 --> 01:08:06.480]  И здесь надо понимать такую вещь. У вас, по-моему, даже в домашке будет такое,
[01:08:06.480 --> 01:08:12.480]  что вот эти три способа, если данных мало, то реально работает только один по строкам.
[01:08:12.480 --> 01:08:16.480]  Потому что два остальных, они округляют сэмпл до блока.
[01:08:16.480 --> 01:08:22.480]  И вот представьте, если у вас данные небольшие и там всего, допустим, 5 блоков,
[01:08:22.480 --> 01:08:29.480]  то все равно, что вы скажете, один процент, что пять процентов, что десять процентов,
[01:08:29.480 --> 01:08:34.480]  у вас все равно это будет один блок. То есть от одного до двадцати процентов,
[01:08:34.480 --> 01:08:41.480]  у вас будет одна пятая, будет один блок. И поэтому размер такого сэмпла будет одинаковый.
[01:08:41.480 --> 01:08:47.480]  Поэтому в домашке, когда у вас будет задачка, насколько я помню, она есть,
[01:08:47.480 --> 01:08:53.480]  где надо будет что-то просэмплировать, берете сразу, ну или бакеты создаете,
[01:08:53.480 --> 01:08:58.480]  или берете последний способ сэмплирования, где указываете строки.
[01:08:58.480 --> 01:09:04.480]  Вот здесь округления до блока не будет. Там, где вы будете задавать размер
[01:09:04.480 --> 01:09:11.480]  и будете задавать проценты, будет округление до ближайшего целого блока и будет все нарушено.
[01:09:17.480 --> 01:09:29.480]  Если сейчас какие-то вопросы, нам, в принципе, осталось разобрать два небольших кусочка,
[01:09:29.480 --> 01:09:40.480]  тогда map join. Вы, наверное, помните, насколько в Hadoop'е нам было проще делать map join,
[01:09:40.480 --> 01:09:46.480]  но, правда, он не всегда корректно работал, там были исключения. Сейчас попробуем это на Hive.
[01:09:46.480 --> 01:09:54.480]  Сейчас я зайду все-таки на наш с вами MIPS-кластер, потому что он просто больше.
[01:09:54.480 --> 01:10:19.480]  Вот, и так у нас будет сейчас две таблицы, с которыми мы будем делать join.
[01:10:19.480 --> 01:10:25.480]  Для того, чтобы понять, что это за таблица, давайте выполним вот такое простое исследование,
[01:10:25.480 --> 01:10:34.480]  то есть опишем таблицы, посчитаем, сколько строк и посмотрим на структуру.
[01:10:34.480 --> 01:10:56.480]  У вас какие-то вопросы?
[01:10:56.480 --> 01:11:08.480]  Так, вот у нас семь мапперов, один редьюсер. Ну и вот мы видим, какие поля в наших табличках.
[01:11:08.480 --> 01:11:17.480]  Первая таблица – это логи работы какого-нибудь веб-сервиса, там, какой запрос, в какое время,
[01:11:17.480 --> 01:11:27.480]  из какого IP-шника. И вторая таблица – это маппинг IP и регион России. У вас примерно такие таблицы будут в домашках.
[01:11:27.480 --> 01:11:42.480]  Вот, и так у нас получается первая таблица. Где тут ее число? Вот у нас получается сколько?
[01:11:42.480 --> 01:11:52.480]  Десять миллионов строк. И вид этих строк вот такой. И вторая табличка – она у нас маленькая,
[01:11:52.480 --> 01:11:59.480]  у нее всего восемь тысяч, и сами строки тоже маленькие, всего по две колонки. То есть понятно,
[01:11:59.480 --> 01:12:06.480]  что у нас как раз готовая картина для мапджойна. Теперь мы с вами будем джойнить эти таблицы и смотреть,
[01:12:06.480 --> 01:12:18.480]  как это все работает. Сначала у нас будет такой полноценный взрослый джойн,
[01:12:18.480 --> 01:12:27.480]  без всяких оптимизаций, без мапджойна. И чтобы это точно было так, я отключил опцию автоконверт,
[01:12:27.480 --> 01:12:33.480]  потому что Хайф умный, если он видит, что одна таблица маленькая, он может сделать мапджойн автоматически.
[01:12:33.480 --> 01:12:38.480]  Поэтому я это все отключил и делаем просто обычный вот такой лэфт джойн.
[01:12:38.480 --> 01:13:02.480]  Сейчас пока весь этот код выполняется, можете задать какие-нибудь вопросы.
[01:13:08.480 --> 01:13:36.480]  Я понял. То есть ты имеешь в виду блок-сэмплинг вот это по процентам, по строчкам?
[01:13:36.480 --> 01:13:45.480]  И третий способ – по мегабайтам.
[01:13:45.480 --> 01:14:01.480]  Вот именно из-за того, чтобы такого не было, Хайф округляет сэмпл до ближайшего блока.
[01:14:01.480 --> 01:14:07.480]  То есть ты возьмешь, например, 10 мегабайт, а у тебя размер блока 128 мегабайт.
[01:14:07.480 --> 01:14:10.480]  У тебя будет 128 мегабайт в сэмпле. Считается весь блок.
[01:14:10.480 --> 01:14:16.480]  Поэтому просто в домашней нашей я не рекомендую использовать мегабайты. У нас маленькие данные, маленькие блоки.
[01:14:16.480 --> 01:14:23.480]  И просто когда в задаче надо будет поисследовать что-нибудь в зависимости от размера сэмпла,
[01:14:23.480 --> 01:14:28.480]  у вас там прямая будет просто, не будет зависимости. Сэмпл будет всегда одинаковый.
[01:14:28.480 --> 01:14:37.480]  Вот у нас сработал джойн. И время его работает 3 минуты 19 секунд.
[01:14:37.480 --> 01:14:45.480]  Теперь второй вариант этого джойна. Второй вариант мап-джойн.
[01:14:45.480 --> 01:14:50.480]  Чтобы у нас был мап-джойн, что надо сделать? Первое, мы включаем автоконверт.
[01:14:50.480 --> 01:14:55.480]  Второе, мы подсказываем Хайфу, что нужно сделать мап-джойн.
[01:14:55.480 --> 01:15:02.480]  Есть специальный такой хинт. Это не комментарии. Комментарии в Хайве ставятся двумя дефисами.
[01:15:02.480 --> 01:15:09.480]  А это специальный такой, как бы, комментарий с плюсиком.
[01:15:09.480 --> 01:15:14.480]  Специальный такой синтаксис для того, чтобы мы указали, вот здесь мы хотим сделать мап-джойн.
[01:15:14.480 --> 01:15:18.480]  И вот эта таблица у нас идет в роли маленькой.
[01:15:18.480 --> 01:15:23.480]  На самом деле Хайф позволяет делать и тройной, и четверной мап-джойн.
[01:15:23.480 --> 01:15:27.480]  То есть здесь через запятую можно указать целый список маленьких таблиц.
[01:15:27.480 --> 01:15:33.480]  Они все добавятся в distributed cache и будет мап-джойн сразу от нескольких таблиц.
[01:15:33.480 --> 01:15:38.480]  Но на самом деле не вот это, не вот это не гарантирует нам того, что мап-джойн реально будет.
[01:15:38.480 --> 01:15:45.480]  Это все только подсказки. Если мы вот такой код используем для двух равных больших таблиц,
[01:15:45.480 --> 01:15:54.480]  то Хайф никакой мап-джойн делать не будет.
[01:15:54.480 --> 01:15:58.480]  Выполняем код. Пока выполняем, давайте посмотрим, что у нас тут было.
[01:15:58.480 --> 01:16:03.480]  А тут у нас было 8 мапперов. Почему 8 мапперов? Потому что 8 блоков.
[01:16:03.480 --> 01:16:08.480]  И почему 15 редьюсеров? Потому что мы так указали.
[01:16:08.480 --> 01:16:16.480]  Что здесь?
[01:16:16.480 --> 01:16:21.480]  Здесь, во-первых, мы видим number of reducers равно 0.
[01:16:21.480 --> 01:16:29.480]  И во-вторых, мы видим, что наша задача работала 13 секунд, ну 14 секунд хорошо.
[01:16:29.480 --> 01:16:33.480]  То есть здесь было 3 минуты чем-то, а тут было 14 секунд.
[01:16:33.480 --> 01:16:37.480]  И в результате мы получили то же самое.
[01:16:37.480 --> 01:16:43.480]  Вот, это что касается того, насколько мап-джойн нам может помочь ускорить работу.
[01:16:43.480 --> 01:16:49.480]  Есть ли какие-нибудь вопросы сейчас?
[01:17:07.480 --> 01:17:24.480]  Смотрите, не совсем так. На самом деле вот часть этих ускорений я вам рассказал только теоретически,
[01:17:24.480 --> 01:17:29.480]  а практически мы сделали только два. То есть как бы алгоритм был такой.
[01:17:29.480 --> 01:17:36.480]  Сначала мы сделали партиции, разбросали большие ключи, которых мало по папкам.
[01:17:36.480 --> 01:17:38.480]  И это мы сделали на практике.
[01:17:38.480 --> 01:17:42.480]  Потом мы уже без практики, мы сделали бакетирование.
[01:17:42.480 --> 01:17:48.480]  То есть те ключи, которых больше, мы разбросали по файлам. Следующий уровень оптимизации.
[01:17:48.480 --> 01:17:57.480]  Потом мы взяли один большой ключ, который не получилось разбить ни партиционированием, ни бакетированием.
[01:17:57.480 --> 01:18:02.480]  И разбили его уже в ручном режиме как-то с помощью скьюет бай.
[01:18:02.480 --> 01:18:06.480]  Нет, через скьюет бай. Тут пока нет джойнов. Это другое совсем.
[01:18:06.480 --> 01:18:14.480]  Это просто разбиение данных. То есть мы могли оптимизировать вот так в три этапа.
[01:18:14.480 --> 01:18:19.480]  Следующие вообще не связанные никак. Это можно использовать отдельно.
[01:18:19.480 --> 01:18:25.480]  Можно делать партиции или делать только мап-джойны. Это вообще разницы нету.
[01:18:26.480 --> 01:18:33.480]  То есть вот эта оптимизация мап-джойн связана с тем, что мы маленькую таблицу добавляем в distributed cache
[01:18:33.480 --> 01:18:39.480]  и реализуем на ней тот алгоритм мап-джойн, который мы в прошлый раз разобрали.
[01:18:39.480 --> 01:18:44.480]  И это никак не связано. Если заметишь, у нас таблицы даже были разные.
[01:18:44.480 --> 01:18:59.480]  Но в оставшееся время давайте сделаем небольшой обзор того, что у нас существует, кроме хайва, для аналогичных задач.
[01:18:59.480 --> 01:19:11.480]  Есть пиг. Точнее он уже скорее не есть, а скорее был, потому что пиг, он в принципе у него такая же логика работы, как у хайва.
[01:19:11.480 --> 01:19:16.480]  Поэтому мы имеем высокоуровневый язык, который транслируется в MapReduce.
[01:19:16.480 --> 01:19:25.480]  Но если в хайве это SQL, точнее HiveQL, это все-таки диалект SQL, он не совсем, не на 100% SQL.
[01:19:25.480 --> 01:19:31.480]  То есть здесь это свой язык, пиг латин. Вот такая вот помесь питона с SQL, которую надо отдельно учить.
[01:19:31.480 --> 01:19:36.480]  И поэтому пиг сейчас практически не используется.
[01:19:36.480 --> 01:19:41.480]  Дальше импала. В отличие от хайва, это полноценная база данных.
[01:19:41.480 --> 01:19:50.480]  То есть у нее есть и своя логика хранения, и своя логика вычислений. Она может быть не связана даже вообще с MapReduce.
[01:19:50.480 --> 01:19:57.480]  Часть данных она хранит в памяти, из-за этого она работает намного быстрее.
[01:19:58.480 --> 01:20:02.480]  Минус импалы в том, что тут нет поддержки сложных типов.
[01:20:02.480 --> 01:20:05.480]  Вообще какие в хайве существуют типы данных?
[01:20:08.480 --> 01:20:11.480]  Давайте посмотрим. Вот Hive Data Types.
[01:20:13.480 --> 01:20:18.480]  Что мы тут видим? Мы видим большое количество численных типов данных.
[01:20:18.480 --> 01:20:22.480]  И тоже обращайте на это внимание, когда будете делать домашку.
[01:20:22.480 --> 01:20:28.480]  Например, если вам указана колонка возраст, то возраст это TinyInt.
[01:20:28.480 --> 01:20:32.480]  Потому что, наверное, странно, чтобы у человека был возраст 32 тысячи.
[01:20:34.480 --> 01:20:39.480]  Поэтому осмысленно выбирайте численные типы данных.
[01:20:39.480 --> 01:20:44.480]  Потом у нас есть разные строковые, буллевские типы данных, есть разные таймстемпы.
[01:20:44.480 --> 01:20:49.480]  И есть комплекс Data Types. Где-то тут я это видел.
[01:20:49.480 --> 01:20:54.480]  Вот. Четыре типа данных. Массивы, словари, структуры и юнионы.
[01:20:54.480 --> 01:20:56.480]  Вот ничего этого в импале нет.
[01:20:56.480 --> 01:21:02.480]  Поэтому в импале сложнее работать, например, с XML, с JSON, с Ямлами.
[01:21:02.480 --> 01:21:05.480]  То есть когда у нас есть какая-то вложенность.
[01:21:05.480 --> 01:21:11.480]  Надо больше парсить руками, чтобы превращать это в плоскую табличку.
[01:21:11.480 --> 01:21:14.480]  Ну или в набор плоских табличек.
[01:21:19.480 --> 01:21:24.480]  Дальше Apache Presto. Это тоже еще одна база данных.
[01:21:24.480 --> 01:21:28.480]  Тоже полноценная база данных. Написана на джаве.
[01:21:28.480 --> 01:21:36.480]  Сейчас она продвигается всякими большими big data гигантами.
[01:21:36.480 --> 01:21:38.480]  Типа Data Stacks.
[01:21:40.480 --> 01:21:42.480]  Ну по сути она чем-то похожа на импалу.
[01:21:45.480 --> 01:21:47.480]  Правда сложные типы здесь есть.
[01:21:49.480 --> 01:21:51.480]  Дальше Apache Presto.
