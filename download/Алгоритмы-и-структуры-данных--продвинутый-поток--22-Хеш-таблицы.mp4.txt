[00:00.000 --> 00:20.000]  Так, ой, ой, я спорил шпаргалку, да? Ну ладно, кстати, познакомьтесь. Ладно, ну, в общем, не то чтобы я ее собирался скрывать, собственно, это наша литература, да, это вот конспирты Эхилл Кихомира. У меня вот есть таких три, собственно, все три мы с вами уже обсудили.
[00:20.000 --> 00:34.000]  Ну, пока можно, так что вот туда. Ну, тут действительно, да, на самом деле замечательно написано, на самом деле.
[00:34.000 --> 00:36.000]  Ставили против ума.
[00:43.000 --> 00:51.000]  Так, а, и еще, конечно, одна важная у нас будет литература. И, соответственно, вот такая.
[00:51.000 --> 00:58.000]  Введение. Ну, как вам сказать, введение, смотрите, да. Ну, возможно, кто-то из вас не сталкивался.
[00:58.000 --> 01:05.000]  Потому что тут, конечно, выбраны такие немножко оригинальные темы, да, то есть, когда вот, там, введение, сортировки.
[01:05.000 --> 01:18.000]  Вот, то есть, плейдинг. Нет, кстати, вот, ну, в принципе, да, то есть, например, здесь есть доказательства, когда там потенциал вершин, это логарифм округленный вниз.
[01:18.000 --> 01:27.000]  Вот, тут они, как бы, там писали такое вот доказательство напасть. То есть, да, нам с вами оно не помогло, мы и, там, изучили что-то более трагичное.
[01:27.000 --> 01:35.000]  Ну, также вот здесь можно было прочитать про лучше всех. Поэтому, говорю, да, точно, да, точно вы не сталкивались с этой книжкой.
[01:35.000 --> 01:38.000]  Потому что я почти наверно в прошлый месяц его бы уже и планировал.
[01:39.000 --> 01:48.000]  Вот. Ну, и нас сейчас будет интересовать вот это, конечно. Вот. Вот этот вот красивый азиат.
[01:50.000 --> 01:57.000]  Так что, вот, Бобенко-Левин, собственно, в ведении Тюрелка ритма по черепу. Ну, да, книжка просто берется и будет интересно, что.
[01:57.000 --> 02:07.000]  Вот. Так, теперь давайте, а мы с вами откроем презентацию. Так, что это? Что у нас-то? Количная куча.
[02:11.000 --> 02:18.000]  Бла-бла-бла-бла-бла-бла-бла-бла-бла. Да, обычно, ну, скажем так, долгая презентация долгое время жила на первом курсе.
[02:18.000 --> 02:25.000]  Я это все обсужал на первом курсе. Значит, как-то там подумал, что лучше, конечно, наверно, США обсуждать, когда вы все-таки знаете теорию.
[02:25.000 --> 02:29.000]  Вот. И, действительно, сейчас будет все такое, что очень интересно.
[02:29.000 --> 02:37.000]  Ну, давайте начнем с, конечно же, простого. Вот. Что вообще такое сэштаблица? Да. То есть, ну, в чем смысл США?
[02:37.000 --> 02:43.000]  То есть, смысл в том, что мы хотим выполнять там операции типа добавление и удаление поиска там читерским методом,
[02:43.000 --> 02:49.000]  вида, что по каждому значению, по каждому ключу, который мне придет, я вычисляю какой-то там супер хэш.
[02:49.000 --> 02:55.000]  Ну, вот. И по этому хэшу пытаюсь его найти. То есть, ну, там самая тупая идея.
[02:55.000 --> 03:01.000]  Какая у нас для строчек возникает, например, могла быть идея, да? Или от строчек или чего-нибудь еще.
[03:01.000 --> 03:06.000]  То есть, у нас есть какие-нибудь, то есть, такой вот, или даже не для хэшей, а вот самый простой пример.
[03:06.000 --> 03:13.000]  Допустим, мы хотим реализовать вот сет, вот такой вот урезанный сет с этим вот, на числа до 10 и 18, да?
[03:13.000 --> 03:21.000]  Вот. Тогда какая возникает идея? Ну, давайте, то есть, такая вот, то есть, такой флаг.
[03:21.000 --> 03:27.000]  Если мы знаем, что числа накидываются там условно рамтомно, да, то тогда идея могла быть такая.
[03:27.000 --> 03:32.000]  Давайте введем m равно, ну скажем там, миллион. От балды, да?
[03:32.000 --> 03:39.000]  И будем, для каждого числа вычислим его остаток отделения на миллион и что-нибудь с этим сделаем.
[03:39.000 --> 03:45.000]  Вот. Ну, собственно, что, ну вот, ну там, что именно там? Ну, разные варианты могут быть, но там основная идея может быть там,
[03:45.000 --> 03:51.000]  создадим, например, создадим миллион списков, где в каждом списке будем творить все элементы,
[03:51.000 --> 03:56.000]  у которых там остаток отделения на m равен, например, там то, что надо, да?
[03:56.000 --> 04:03.000]  И тогда, если числа гондонная, то, в принципе, тогда поиск это, ну там, получается, во сколько-то в миллион раз сокращает.
[04:03.000 --> 04:08.000]  То есть, если у вас чисел порядка миллион, то это вообще в среднем получается около 1.
[04:08.000 --> 04:16.000]  Ну, можно о том и о другом подробнее, да? То есть, точно, потому что тут, на самом деле, можно по-разному разговаривать.
[04:16.000 --> 04:22.000]  Потому что, да, то есть, можно, конечно, ввести еще такое понятие, как вот коэффициент заполнения, он же вот фактор, да?
[04:22.000 --> 04:29.000]  То есть, это просто вот, то есть, говорим, сколько мы сравним х-таблицы элементов и сколько, и пусть х-таблица имеет размер l.
[04:29.000 --> 04:35.000]  Тут вот очень интересно, потому что сейчас у нас вот, вот как вы думаете, альто больше единицы или меньше единицы?
[04:35.000 --> 04:50.000]  Ну, опять, на самом деле, и так, и так бывает. Все зависит от того, какого вида х-таблицу вы реализуете.
[04:50.000 --> 04:59.000]  Ну, потому что, да, в идеале, конечно, хотелось бы, конечно, хранить так.
[05:00.000 --> 05:09.000]  Заводим массив размера m, и в ячейке номер i храним элемент, хэш которого равен i.
[05:09.000 --> 05:22.000]  Ну, или есть такого элемента нет, то ничего не храним. Все работает, все чимно и хорошо, все работает за от единицы, пока не обнаружится два, случайно не обнаружится два элемента, у которых хэш совпал.
[05:23.000 --> 05:31.000]  Эта ситуация называется коллизия. Причем действительно замечается, что тут она достаточно быстро растет.
[05:31.000 --> 05:46.000]  Потому что, ну, вот, возможно, мы уже с вами обсуждали такой парадокс нерождений, то есть, который звучит, такая теорема звучит так, что, предположим, что мы проигнорируем бесслокостные года и рассмотрим там, там, рандомность n людей.
[05:46.000 --> 05:51.000]  И посмотрим, верно ли, что у них там найдется два человека с одинаковым день рождения.
[05:51.000 --> 05:56.000]  Ну, заметим, кажется, что мы, по идее, редко встречаем людей, у которых с нами одинаковый день рождения.
[05:56.000 --> 06:07.000]  Но если брать, ну, если брать конкретно с нами, то, как бы, то есть, да, вероятность того, что я возьму рандомного человека, у него там, совпадет день рождения, равна там один делик на 365.
[06:07.000 --> 06:18.000]  Но если мы будем рандомных n человек, и будем спрашивать, сколько совпадает, там, найдут ли два человека между ними хотя бы, то, оказывается, эта вероятность растет быстрее.
[06:18.000 --> 06:26.000]  Скажем, вот, примерно, где-то, вот там, ну, ну, 20 или чуть больше, чем 20, если взять, то эта вероятность уже превысит даже одну-вторую.
[06:26.000 --> 06:39.000]  Ну, на пальцах можно убедиться так, смотрите, то есть, мы, да, то есть, на пальцах, конечно, нам сейчас очень сложно посчитать вероятость, по крайней мере, в уме, там, как я ж, в питоне это можно сделать сомгновенно, вот.
[06:39.000 --> 06:49.000]  Ну, а вы можете посчитать мат ожидания. Ну, давайте посмотрим. Вот, если у нас n человек, каково мат ожидания там пар человек, у которого совпали дни рождения?
[06:50.000 --> 06:54.000]  N, наверное, зелень пополам, умножить на...
[06:59.000 --> 07:00.000]  Какова вероятность?
[07:00.000 --> 07:01.000]  На 1,65.
[07:01.000 --> 07:12.000]  Совершенно верно. Совершенно верно. То есть, получается, да, что если n это где-то порядка корни из этих 3,665, да, то вероятность уже где-то, то там, мат ожидания уже на вторая.
[07:12.000 --> 07:27.000]  А если там n взять чуть больше, ну, там, я не знаю, сколько там взять, сколько там надо, вот, если не 20, то, например, если взять день, мы там, ну, скажем, ну, от балды так 30, например, взять, то сколько там получится?
[07:27.000 --> 07:39.000]  900 поделить на это, то есть больше единицы. То есть, вот, то есть, уже в среднем будет больше единицы, значит, скорее всего, там, значит, как минимум, видимо, вероятность того, что коллизии, там, меньше одна вторая, там, по-видимому...
[07:39.000 --> 07:43.000]  Так, у нас есть, кстати, на эту тему неравенство, Маша, вот, интересно.
[07:43.000 --> 07:44.000]  Неравенство.
[07:44.000 --> 07:45.000]  Что?
[07:45.000 --> 07:47.000]  Неравенство.
[07:47.000 --> 07:55.000]  Нет, ну да. Нет, ну, а вот давайте вспомним, нам-то по-любому пригодится. Вот давайте с этим немножко поиграемся.
[07:57.000 --> 08:07.000]  Нет, ну, может быть, просто аналогично доказывается, потому что, смотрите, у нас есть, действительно, такой тупнячок, да, что, действительно, допустим, что у нас есть неотрицательная величина, да?
[08:07.000 --> 08:23.000]  Тогда мы знаем, что вероятность того, что звездок C больше, чем какая, больше, чем какой-то, там, я не знаю, х, значит, она меньше либо равна, чем это надо ожидание поделить на х.
[08:28.000 --> 08:31.000]  Это я написал неравенство Маркова, да?
[08:31.000 --> 08:39.000]  Ну, то есть, понятно, что это эквалентно тому, что х на P от этого х больше х меньше либо равно от ожидания х, а берется оно откуда?
[08:39.000 --> 08:48.000]  Ну, потому что, практически, действительно, мы берем, то есть, мы берем вот это вот распределение, там, какой-то, этой вот х.
[08:48.000 --> 08:53.000]  Ну, вот, и здесь, соответственно, все, что больше х оцениваем х.
[08:53.000 --> 09:04.000]  Ну, вот, то есть, там, допустим, вот это вот все, типа, оцениваем х, то есть, сюда вот прижимаем, ну, вот, а это все прижимаем сюда и получается меньше.
[09:04.000 --> 09:06.000]  Ну, понятно, что меньше, да?
[09:06.000 --> 09:07.000]  Вот.
[09:07.000 --> 09:10.000]  Так, а теперь вот возникает вопрос.
[09:10.000 --> 09:19.000]  А если я хочу, вот, интересно, не верно ли, что вероятность того, что х меньше, чем игр, меньше либо равно, чем, условно, там, игр умножить на вот это х?
[09:20.000 --> 09:23.000]  Странно вообще.
[09:26.000 --> 09:27.000]  Чего?
[09:27.000 --> 09:29.000]  Агим и немец.
[09:29.000 --> 09:31.000]  Агим и немец, ну, если в нот.
[09:31.000 --> 09:33.000]  На отождание, на операцию.
[09:33.000 --> 09:34.000]  Так.
[09:34.000 --> 09:36.000]  Чего еще раз?
[09:36.000 --> 09:37.000]  Нет.
[09:39.000 --> 09:42.000]  А теперь, берем, как санит события.
[09:42.000 --> 09:43.000]  Так.
[09:45.000 --> 09:46.000]  Так.
[09:47.000 --> 09:48.000]  Понятно.
[09:48.000 --> 09:50.000]  То есть, хорошо.
[09:50.000 --> 09:52.000]  Нет, ну, мы что, вероятность оцениваем?
[09:52.000 --> 09:53.000]  Так.
[09:53.000 --> 09:54.000]  Хорошо.
[09:54.000 --> 09:55.000]  А.
[09:55.000 --> 09:58.000]  Это равно 1 минус п кси больше либо равно игр.
[09:58.000 --> 09:59.000]  Так.
[09:59.000 --> 10:02.000]  Но это п теперь надо снизу тогда получать.
[10:02.000 --> 10:03.000]  Больше равно.
[10:03.000 --> 10:04.000]  А, ну.
[10:04.000 --> 10:06.000]  Это же мы хотели.
[10:06.000 --> 10:07.000]  Нет.
[10:07.000 --> 10:08.000]  Нет.
[10:08.000 --> 10:09.000]  Нет, я хотел наоборот.
[10:09.000 --> 10:12.000]  Предположим, что мы от ожидания 1.
[10:12.000 --> 10:15.000]  Как бы, можем ли мы сказать что-нибудь типа, что вероятность
[10:15.000 --> 10:18.000]  того, что случайная личина меньше 1.2, она там, я не знаю,
[10:18.000 --> 10:20.000]  1.2 или меньше.
[10:21.000 --> 10:23.000]  Мне вот это интересно.
[10:36.000 --> 10:40.000]  Ой, тут что-то мне раньше чем-то шоу вспоминать надо что-нибудь.
[10:40.000 --> 10:43.000]  Там, это там дисперсия там всякая, вот это все.
[10:43.000 --> 10:44.000]  Ну, ладно.
[10:44.000 --> 10:45.000]  Так, ну ладно.
[10:45.000 --> 10:46.000]  Не получилось, не получилось.
[10:46.000 --> 10:47.000]  Не важно.
[10:48.000 --> 10:49.000]  Ладно.
[10:49.000 --> 10:50.000]  Снизу, да.
[10:50.000 --> 10:52.000]  Сверху можно отсекать, снизу нельзя.
[10:52.000 --> 10:53.000]  Ну, вот.
[10:53.000 --> 10:58.000]  Хотя, хотя, да, наверное нельзя, потому что, ну, оценивать
[10:58.000 --> 11:01.000]  что там, вероятность того, что случайная личина меньше
[11:01.000 --> 11:02.000]  1.
[11:02.000 --> 11:04.000]  Типа, обязательно меньше 1.
[11:04.000 --> 11:06.000]  Нельзя, потому что у вас, как бы, может быть случайной
[11:06.000 --> 11:09.000]  величины, вероятность 50% 0, вероятность 50% 2.
[11:18.000 --> 11:21.000]  Так, значит, что можно делать с коллизиями?
[11:22.000 --> 11:23.000]  Вот.
[11:23.000 --> 11:26.000]  Ну, на самом деле, если нам очень хочется, действительно,
[11:26.000 --> 11:28.000]  с этими коллизиями как-то бороться, да, потому что,
[11:28.000 --> 11:30.000]  ну, то, как бы, какие есть варианты?
[11:31.000 --> 11:32.000]  Значит, есть два варианта.
[11:32.000 --> 11:37.000]  Один подходит для, там, load фактора больше 1.
[11:37.000 --> 11:40.000]  Другой подходит для load фактора меньше 1.
[11:41.000 --> 11:43.000]  Итак, о том и о другом подробнее.
[11:44.000 --> 11:45.000]  Так.
[11:46.000 --> 11:48.000]  Ну, например, метод цепочек.
[11:48.000 --> 11:50.000]  Ну, это такое, видимо, просто первое, что вам приходит,
[11:50.000 --> 11:52.000]  приходит в голову, когда говорят хэш-таблицы.
[11:52.000 --> 11:57.000]  То есть, на каждом потенциальном значении хэша висит односвязанный список.
[11:58.000 --> 12:02.000]  Односвязанный список всех элементов с таким хэшом.
[12:03.000 --> 12:04.000]  Вот.
[12:04.000 --> 12:06.000]  С таким хэшом.
[12:07.000 --> 12:08.000]  Что это означает?
[12:09.000 --> 12:10.000]  Ну, вот.
[12:10.000 --> 12:12.000]  То есть, тогда получается, что...
[12:12.000 --> 12:14.000]  Ну, то есть, понятно, что если коллизия всего лишь означает,
[12:14.000 --> 12:16.000]  что у вас будут цепочки больше одного элемента.
[12:16.000 --> 12:19.000]  Ну, в общем-то, если вы гарантируете, что у вас гарантирует...
[12:19.000 --> 12:22.000]  Если, там, во все время везет их в цепочки не более чем 5 элементов,
[12:22.000 --> 12:24.000]  то, в общем-то, вы не спрятаете.
[12:25.000 --> 12:26.000]  Вот.
[12:28.000 --> 12:31.000]  Ну, то есть, метод работает, ну, конечно, понятно.
[12:31.000 --> 12:32.000]  Худше в случае...
[12:33.000 --> 12:34.000]  Ну, то есть, да. То есть, как добавлять?
[12:34.000 --> 12:36.000]  Добавляете у нас вообще за вот единицы,
[12:36.000 --> 12:39.000]  потому что в начало списка можно за вот единицы добавить, да?
[12:40.000 --> 12:41.000]  А вот если мы ищем какой-нибудь...
[12:41.000 --> 12:42.000]  Ну, вот.
[12:43.000 --> 12:44.000]  Ну, вот.
[12:44.000 --> 12:47.000]  Ну, как бы, единственное, конечно, может быть, еще вопрос,
[12:47.000 --> 12:49.000]  не требуется ли она наличие дупля, да?
[12:49.000 --> 12:50.000]  То есть, там...
[12:50.000 --> 12:53.000]  Потому что, может быть, вы хотите поддерживать сеп,
[12:53.000 --> 12:55.000]  и вам хочется, прежде чем добавлять, узнать,
[12:55.000 --> 12:57.000]  а нет ли у вас такого элемента.
[12:58.000 --> 13:00.000]  Тогда это получается от единицы плюс поиска.
[13:01.000 --> 13:03.000]  Вот. Ну, удаление, ну, тут, из вариантов.
[13:04.000 --> 13:07.000]  Просто бежим по соответствующему хрешу, приближаемся по списку
[13:07.000 --> 13:10.000]  и, там, найденный элемент удаляем.
[13:11.000 --> 13:13.000]  То есть, совсем, если нам будет фантастически не вести...
[13:13.000 --> 13:15.000]  Ну, например, у нас там плохая хреш-функция.
[13:15.000 --> 13:19.000]  Теперь, там, хреш от элемента равен нулю.
[13:20.000 --> 13:21.000]  Это тоже хреш-функция.
[13:21.000 --> 13:22.000]  Хреш-функция.
[13:22.000 --> 13:23.000]  Вот. Но дебильная.
[13:24.000 --> 13:25.000]  Вот.
[13:26.000 --> 13:27.000]  Соответственно.
[13:27.000 --> 13:28.000]  Ну, и поиск, соответственно, тоже.
[13:28.000 --> 13:31.000]  Ну, тут, в общем-то, думаю, все тривиально, а тут, в общем-то, известно.
[13:31.000 --> 13:34.000]  Кстати, интересно, вы писали, пытались ли вы писать что-нибудь подобное?
[13:35.000 --> 13:39.000]  Мы написали, только у нас там был один большой двусоветный список.
[13:40.000 --> 13:44.000]  И, типа, массив гитараторов на начало каждого батика.
[13:45.000 --> 13:48.000]  Ну, это детали реализации именно, а не элементы.
[13:48.000 --> 13:49.000]  Ага, нет.
[13:49.000 --> 13:50.000]  Ну, я вас помню.
[13:50.000 --> 13:52.000]  Нет, я даже имел в виду не это, да.
[13:52.000 --> 13:54.000]  Ну, список вы, конечно, писали.
[13:54.000 --> 13:57.000]  Да, но вот олимпиаду вам не пригодилось.
[13:57.000 --> 13:58.000]  Свой писать?
[13:58.000 --> 13:59.000]  Зачем?
[13:59.000 --> 14:00.000]  Нет, все.
[14:00.000 --> 14:01.000]  Олдерец спасал всегда.
[14:01.000 --> 14:02.000]  Воль меня, да.
[14:03.000 --> 14:05.000]  Тут отдельно, потому что он вообще не так часто нужен, знаете?
[14:05.000 --> 14:06.000]  Ну, да.
[14:07.000 --> 14:09.000]  Точнее, на самом деле, он чаще всего не спасал.
[14:09.000 --> 14:12.000]  Спасал, обычно, вместо него, или МАП.
[14:12.000 --> 14:14.000]  Они даже быстрее могут работать.
[14:14.000 --> 14:18.000]  Ну, там есть всякие ускоренные штуки, там, типа, БТС.
[14:19.000 --> 14:21.000]  Они быстрее МАПов работают.
[14:23.000 --> 14:24.000]  Ну, да.
[14:24.000 --> 14:25.000]  Это все здорово.
[14:25.000 --> 14:26.000]  Значит, смотрите.
[14:27.000 --> 14:31.000]  Ну, и теперь, если говорить, на самом деле, о медленной секунде,
[14:31.000 --> 14:33.000]  то о какой у нас среднее время работы?
[14:34.000 --> 14:38.000]  Ну, в принципе, можно попытаться сказать, что да, у нас.
[14:39.000 --> 14:44.000]  Допустим, в некотором смысле, конечно, что мат ожидания времени работы,
[14:44.000 --> 14:49.000]  это на каждую операцию от 1 плюс альфа.
[14:51.000 --> 14:52.000]  Почему?
[14:52.000 --> 14:54.000]  Ну, просто потому что говорим, что...
[14:56.000 --> 15:00.000]  Ну, правда, теперь давайте внимательно посмотрим,
[15:00.000 --> 15:02.000]  какое тут собирательское пространство.
[15:02.000 --> 15:04.000]  Давайте внимательно посмотрим.
[15:05.000 --> 15:08.000]  То есть, видим, что...
[15:09.000 --> 15:11.000]  Ну, вот.
[15:12.000 --> 15:15.000]  Что, как вы видите, тут, на самом деле, подразумевается,
[15:15.000 --> 15:17.000]  что у нас еще элемент, который нам приходит,
[15:17.000 --> 15:20.000]  у него называется хэш рандоме.
[15:21.000 --> 15:24.000]  То есть, во-первых, каждое значение хэша для каждого элемента
[15:24.000 --> 15:27.000]  может выпасть с равной вероятностью 1 деликатем.
[15:30.000 --> 15:33.000]  Соответственно, причем более того, у двух разных элементов,
[15:33.000 --> 15:36.000]  там, собственно, сэши берутся независимо.
[15:38.000 --> 15:39.000]  Понятно, да?
[15:40.000 --> 15:44.000]  Ну, по крайней мере, так, по крайней мере, интуитивно хочется сказать.
[15:45.000 --> 15:48.000]  Да, ключи равновероятные, хэш-кунса равномерна,
[15:48.000 --> 15:51.000]  чем эти слова сочетания отличаются, непонятно.
[15:51.000 --> 15:53.000]  И получается вот такое мат ожидания.
[15:54.000 --> 15:58.000]  Ну, то есть, видим, что для каждого элемента реальное время работы
[15:58.000 --> 16:02.000]  это 1 плюс там сколько таких элементов в этой цепочке, правда?
[16:03.000 --> 16:04.000]  Вот.
[16:05.000 --> 16:06.000]  Ну вот, то есть, этого, ну вот.
[16:06.000 --> 16:08.000]  То есть, заметим, что тут неважно какие длинные,
[16:08.000 --> 16:10.000]  главное, что сумма этих длин по любому n,
[16:10.000 --> 16:12.000]  и в результате получается 1 плюс i.
[16:14.000 --> 16:18.000]  Кстати, в связи с этим действительно возникает естественный вопрос.
[16:20.000 --> 16:22.000]  Действительно, какими вероятностями мы пользуемся?
[16:22.000 --> 16:24.000]  Пользовались ли мы тем, что
[16:25.000 --> 16:28.000]  каждый хэш,
[16:29.000 --> 16:32.000]  каждый хэш генерируется с вероятностью 1 деликатем.
[16:33.000 --> 16:34.000]  Ну да.
[16:34.000 --> 16:37.000]  То есть, заметим, да, мы тут прям добьемся.
[16:38.000 --> 16:41.000]  Но, просто, на самом деле, да, интерес к другому.
[16:41.000 --> 16:46.000]  А пользовались ли мы с вами тем, что хэши генерируются независимо?
[16:51.000 --> 16:53.000]  А что значит независимо?
[16:53.000 --> 16:56.000]  Ну, то есть, ну, мы как бы подразумевали.
[16:56.000 --> 16:57.000]  Ну, как?
[16:57.000 --> 16:59.000]  То есть, что для каждого элемента,
[16:59.000 --> 17:01.000]  независит от другого?
[17:01.000 --> 17:03.000]  Ну да, вот внимание вопроса.
[17:03.000 --> 17:06.000]  Мы этим где-нибудь, вот тут мы этим воспользовались?
[17:11.000 --> 17:13.000]  Нас не бы преднамерно дожидали.
[17:13.000 --> 17:15.000]  Нас столько моего спросили.
[17:15.000 --> 17:17.000]  Мы говорили, что у нас вероятность для того,
[17:17.000 --> 17:20.000]  что мы пойдем в каждую, в каждый из m вариантов,
[17:20.000 --> 17:22.000]  один из m вариантов,
[17:22.000 --> 17:24.000]  один из m вариантов,
[17:24.000 --> 17:26.000]  один из m вариантов,
[17:26.000 --> 17:30.000]  каждый из m вариантов одинаковый.
[17:30.000 --> 17:33.000]  Для этого не нужна независимость хэши или распределения.
[17:33.000 --> 17:34.000]  Ну да.
[17:34.000 --> 17:36.000]  То есть, нет, вот, обойдите внимание, да.
[17:36.000 --> 17:38.000]  То есть, мы говорим, что вот у нас там,
[17:38.000 --> 17:41.000]  то есть, мы там сверкаем время поиска обработки ключа.
[17:41.000 --> 17:42.000]  Вот это вот.
[17:42.000 --> 17:45.000]  Вот ожидание вот этого очередного ключа.
[17:46.000 --> 17:47.000]  Почему оно равно?
[17:47.000 --> 17:49.000]  То есть, мы говорим, что с вероятностью 1 делить на m,
[17:49.000 --> 17:52.000]  у него значение 0, 1, 2, 3 и так далее.
[17:52.000 --> 17:56.000]  Если ему равно i, то время работы у него будет 1 плюс ni.
[17:58.000 --> 17:59.000]  Вот.
[17:59.000 --> 18:02.000]  И дальше, то есть, мы выполнили просто абсолютно честное,
[18:02.000 --> 18:04.000]  просто алгебрическое преобразование.
[18:04.000 --> 18:06.000]  И требующая независимость.
[18:06.000 --> 18:07.000]  Вот.
[18:07.000 --> 18:09.000]  То есть, на самом деле, да, неплохая новость.
[18:09.000 --> 18:12.000]  То есть, на самом деле, получается, нас интересует,
[18:12.000 --> 18:16.000]  то есть, нам только требуется, чтобы вероятность каждого хэша была...
[18:17.000 --> 18:18.000]  Ну вот.
[18:18.000 --> 18:20.000]  То есть, для вот такому утверждения требуется,
[18:20.000 --> 18:23.000]  что среднее время работы у нас получается...
[18:25.000 --> 18:28.000]  То есть, требует только того, что каждый хэш генерируется равноверно.
[18:30.000 --> 18:31.000]  Вот.
[18:32.000 --> 18:34.000]  Каждый хэш генерируется равноверно.
[18:35.000 --> 18:36.000]  Вот.
[18:36.000 --> 18:38.000]  Но, правда, заметим, что может быть...
[18:39.000 --> 18:40.000]  Вот.
[18:40.000 --> 18:41.000]  Ну, хотя, да.
[18:41.000 --> 18:43.000]  То есть, получается, тогда от ожидания получается вот такое.
[18:43.000 --> 18:46.000]  Если каждый хэш от каждого элемента генерируется равноверно.
[18:47.000 --> 18:48.000]  Вот.
[18:49.000 --> 18:50.000]  Ну, в принципе, да.
[18:50.000 --> 18:51.000]  Выглядит тут вот...
[18:51.000 --> 18:53.000]  Тут вот некоторая реализация, да.
[18:53.000 --> 18:54.000]  То есть, вот.
[18:54.000 --> 18:55.000]  Ну ладно.
[18:55.000 --> 18:57.000]  Это вам уже бесполезно показывать.
[18:57.000 --> 18:58.000]  Вы уже круче можете.
[18:58.000 --> 19:00.000]  Там с интераторами, там все дела.
[19:00.000 --> 19:01.000]  А теперь пойдем...
[19:01.000 --> 19:02.000]  Ну вот.
[19:02.000 --> 19:05.000]  Это была, так сказать, хэш-таблица с закрытой адресацией.
[19:06.000 --> 19:12.000]  А теперь мы исследуем хэш-таблицу, которая подходит для load-фактора меньше единицы.
[19:12.000 --> 19:15.000]  То есть, идея в том, что мы храним массив длины m.
[19:15.000 --> 19:20.000]  И в этом массиве все элементы хотим искать.
[19:22.000 --> 19:23.000]  Вот такая идея.
[19:24.000 --> 19:25.000]  То есть, ну, идея...
[19:25.000 --> 19:32.000]  Ну, самое тупое, что можно было реализовать, это для каждого, значит, элемента в строчке мы вычисляем хэш
[19:32.000 --> 19:35.000]  и кладем элемент в соответствующий элемент по хэшу.
[19:36.000 --> 19:39.000]  Спрашивается, что делать...
[19:39.000 --> 19:40.000]  Значит, там теперь вопрос.
[19:40.000 --> 19:42.000]  А что делать, если мы...
[19:42.000 --> 19:43.000]  Вот здесь произошла корридия.
[19:43.000 --> 19:48.000]  То есть, происходит элемент, и мы его также попытались положить в соответствующий хэш, а он занят.
[19:51.000 --> 19:52.000]  Все делать.
[19:53.000 --> 19:59.000]  Ну, один из базовых вариантов предлагает следующее.
[19:59.000 --> 20:01.000]  Так, смотрим, хотим, класть вот в эту ячейку.
[20:01.000 --> 20:03.000]  Так, занято, кладем в следующее.
[20:03.000 --> 20:04.000]  Тоже занято.
[20:04.000 --> 20:07.000]  Дальше, дальше, дальше, дальше, дальше.
[20:08.000 --> 20:10.000]  Как только найдем пустую, собственно, вот радует.
[20:12.000 --> 20:14.000]  Это нас приводит к чему?
[20:14.000 --> 20:15.000]  Ну, тогда получается...
[20:15.000 --> 20:16.000]  То есть, тогда...
[20:16.000 --> 20:19.000]  Ну, это называется, как можно сказать, последовательностью проб.
[20:21.000 --> 20:22.000]  Вот.
[20:22.000 --> 20:26.000]  Ну, правда, конкретно у такой штуки тогда будет проблема, что...
[20:26.000 --> 20:27.000]  То есть, ну, как бы, в логике проблем.
[20:27.000 --> 20:33.000]  Хорошо, вставлять умеем, но тогда искать тоже придется, когда вычислили хэш, ищите до ближайшего пустого места.
[20:34.000 --> 20:39.000]  Ну, если там сразу пустое место, то нам повезло, но если не пустое, то как бы идем, идем, идем, проверяем, проверяем, проверяем.
[20:40.000 --> 20:41.000]  Вот.
[20:41.000 --> 20:43.000]  И отдельная песня, как удалять.
[20:45.000 --> 20:46.000]  Как вы думаете, как удалять?
[20:51.000 --> 20:52.000]  Ну...
[20:54.000 --> 20:55.000]  Как говорится, это, конечно, тоже.
[20:55.000 --> 20:56.000]  А если хэштаб лить, то как удалить?
[20:57.000 --> 21:00.000]  Нужно все, что сдвинулось из-за него, нужно еще найти назад.
[21:01.000 --> 21:04.000]  То есть, надо для каждого элемента хранить, что там из-за него сдвинулось.
[21:04.000 --> 21:05.000]  Это да, это странно.
[21:05.000 --> 21:06.000]  Это больно.
[21:06.000 --> 21:09.000]  То есть, поэтому приходится там извращаться, типа, самые тупые варианты там.
[21:09.000 --> 21:11.000]  Просто тупо поменьше пишем, да и идите.
[21:11.000 --> 21:16.000]  То есть, типа, самого элемента нет, ну, типа, дальше проверяем, потому что могла быть проблема.
[21:16.000 --> 21:18.000]  А если странно слишком много литов, то перестраиваем, что ли?
[21:18.000 --> 21:19.000]  Ну, типа, да.
[21:20.000 --> 21:23.000]  Вот такие вот развлечения начинаются, но...
[21:24.000 --> 21:26.000]  Да, но тут разные варианты есть, на самом деле.
[21:27.000 --> 21:30.000]  Потому что, смотрите, дело в том, что я вам сразу скажу, да?
[21:30.000 --> 21:32.000]  Да, вот про удаление это мы сказали.
[21:33.000 --> 21:34.000]  Ну, просто вот говорим.
[21:34.000 --> 21:39.000]  Да, давайте я вам в общем случае скажу, потому что этот метод можно обобщить.
[21:43.000 --> 21:44.000]  Вот.
[21:45.000 --> 21:48.000]  То есть, как бы, мы говорим так, что давайте мы ведем не только хэш-функцию,
[21:48.000 --> 21:52.000]  но на самом деле, то есть, будем считать, что хэш, на самом деле,
[21:52.000 --> 21:57.000]  генерирует по каждому элементу не один хэш, но перестановку чисел от m.
[21:58.000 --> 22:03.000]  Перестановка нам будет говорить, в каком порядке, собственно, нам элементы тыкать.
[22:05.000 --> 22:06.000]  Вот.
[22:06.000 --> 22:08.000]  Ну, то есть, например, в нашем случае, наверное, оказывалось,
[22:08.000 --> 22:10.000]  что каждое следующее это как предыдущее плюс один.
[22:12.000 --> 22:14.000]  Ну, понятно, да? Циклический из них.
[22:15.000 --> 22:17.000]  Ну, могут быть и другие варианты.
[22:18.000 --> 22:21.000]  Ну, потому что действительно, наверное, легко представить, что как-то,
[22:21.000 --> 22:24.000]  если у вас каждое следующее это предыдущее плюс один,
[22:24.000 --> 22:27.000]  то, конечно, у вас там будет достаточно быстро процветать пластеризация, правда?
[22:29.000 --> 22:30.000]  Ну, в том плане, что будет большой отрезок,
[22:30.000 --> 22:33.000]  а чем больше отрезок, тем с большей вероятностью туда что-то будет попадать,
[22:33.000 --> 22:35.000]  и он будет расширяться, расширяться, расширяться.
[22:37.000 --> 22:38.000]  Вот.
[22:38.000 --> 22:40.000]  Ну, и да, тут есть такой недостаток.
[22:40.000 --> 22:43.000]  Так, ну, это вот все эти, все детально обсудили, да?
[22:43.000 --> 22:44.000]  Вот.
[22:44.000 --> 22:45.000]  Но есть...
[22:46.000 --> 22:49.000]  Вот, да, ну, вот это я вот как сказал, то есть, вот это h и k, это вот,
[22:49.000 --> 22:51.000]  обычно хэш плюс и, но вот есть пластеризация.
[22:51.000 --> 22:52.000]  Вот.
[22:53.000 --> 22:54.000]  Ну, как бы, ну, вот.
[22:54.000 --> 22:58.000]  Но, на самом деле, бывает, конечно, продвинутая версия, квадратичное предъявление.
[23:01.000 --> 23:02.000]  Вот.
[23:07.000 --> 23:08.000]  То есть...
[23:11.000 --> 23:12.000]  Вот.
[23:12.000 --> 23:14.000]  То есть, в принципе, к пластеризации такой нет,
[23:14.000 --> 23:16.000]  но есть так называемая вторичная к пластеризации,
[23:16.000 --> 23:19.000]  ну, которая заключается в том, что, если у вас есть один ассистент,
[23:19.000 --> 23:22.000]  то вы по одинаковым сообщениям бегать будете, правда?
[23:24.000 --> 23:25.000]  Вот.
[23:27.000 --> 23:28.000]  То есть, соответственно.
[23:28.000 --> 23:31.000]  То есть, ну, практически это очень похоже на цепочку медленных цепочек,
[23:31.000 --> 23:33.000]  только там с возможностью пересечения.
[23:34.000 --> 23:36.000]  Поэтому есть еще веселые варианты.
[23:42.000 --> 23:45.000]  Не-не-не, нет, это не в смысле там комплексное хэширование.
[23:46.000 --> 23:47.000]  Нет.
[23:47.000 --> 23:50.000]  Ну, так просто можно это и так воспринимать.
[23:54.000 --> 23:56.000]  Но в данном случае нет.
[23:56.000 --> 23:59.000]  И это все-таки нормальный такой, это индекс от 0 до M-1.
[24:00.000 --> 24:01.000]  Ну, просто для каждого.
[24:01.000 --> 24:03.000]  То есть, ну, тут хотя бы приятно, да,
[24:03.000 --> 24:05.000]  что даже если у хэшей совпал первый хэш,
[24:05.000 --> 24:09.000]  то тогда, скорее всего, там будет вероятность того, что совпадут прямо оба,
[24:09.000 --> 24:11.000]  она все-таки уже один деликат на M квадрат.
[24:12.000 --> 24:14.000]  То есть, вероятность этого крайне мала,
[24:14.000 --> 24:18.000]  поэтому там они все-таки, там дальше пойдут бегать все-таки по разным местам,
[24:18.000 --> 24:21.000]  и все-таки есть надежда, что будет адекват.
[24:23.000 --> 24:24.000]  Вот.
[24:24.000 --> 24:26.000]  То есть, видим, что, видите, количество последовательств,
[24:26.000 --> 24:28.000]  что получается от M квадрата, не M, да,
[24:28.000 --> 24:31.000]  то есть, какие-то наши возможности расширяем.
[24:32.000 --> 24:34.000]  Ну, отдельная там песня, конечно, за какой интуит,
[24:34.000 --> 24:36.000]  какой-то вообще будет работать в среднем.
[24:39.000 --> 24:42.000]  Ну, у нас тут есть теорема без, ну, вот,
[24:42.000 --> 24:44.000]  ну, вот, отдельно, то есть, без доказательства,
[24:44.000 --> 24:47.000]  соответственно, есть вот такое интересное впечатление.
[24:54.000 --> 24:55.000]  Эх.
[24:55.000 --> 24:57.000]  Осталось только вспомнить.
[24:57.000 --> 24:59.000]  Это называется прирублено, да.
[25:01.000 --> 25:02.000]  Прикрая оно, прикрая оно,
[25:02.000 --> 25:05.000]  при каком нет и где проверке, но, видимо, прирублено.
[25:06.000 --> 25:09.000]  Получается такая красота, которую вот надо знать.
[25:10.000 --> 25:26.000]  Ну, красота здесь действительно простая, да.
[25:26.000 --> 25:29.000]  Такая, что, да, то есть преимущество, конечно, метода,
[25:29.000 --> 25:32.000]  что нет этих ваших указателей, динамической памяти
[25:32.000 --> 25:37.000]  Но с другой стороны, оказывается, что hash таблицы иногда бывают заполнены.
[25:37.000 --> 25:46.000]  Но с другой стороны, ладно, то есть мы уже изучаем адепты вектора и прочих других представителей математического анализа,
[25:46.000 --> 25:51.000]  поэтому расширение и сужение это для нас не такая точная проблема.
[25:51.000 --> 25:54.000]  Но, правда, приходится заморачиваться.
[25:54.000 --> 25:59.000]  Но, с другой стороны, как мы знаем, там unordered mobcast этим всем тоже занимается, если что.
[26:02.000 --> 26:10.000]  Но, правда, единственная проблема, что и сальса стремится к единице, то время работы стремится тоже к не самой приятной вещи.
[26:10.000 --> 26:16.000]  Ну, хотя, да, вот это вот, а, ну это вот то, что мы сейчас обсуждаем, да-да-да-да-да, вот это вот все.
[26:16.000 --> 26:26.000]  Ого. Да, тут вот есть конкретные рекомендации, но думаю, как бы, думаю, общую суть вы понимаете.
[26:27.000 --> 26:32.000]  Вот. Так. Ну, собственно, так, это я вот действительно в быстром темпе прогнал.
[26:32.000 --> 26:36.000]  То есть вот просто какие-то вот общие слова, общие знания, которые просто надо знать.
[26:36.000 --> 26:38.000]  Общие такие, понятно.
[26:40.000 --> 26:41.000]  Так.
[26:42.000 --> 26:48.000]  А теперь мы с вами попробуем, значит, теперь ключи к математике и делать что-нибудь реально прикольное.
[26:48.000 --> 26:50.000]  Если не круто, то прикольно.
[26:51.000 --> 26:53.000]  Значит, смотри.
[26:54.000 --> 27:00.000]  Чем мы с вами, значит, какую глобальную задачу мы вообще с вами попробуем решить?
[27:01.000 --> 27:04.000]  Так. Ну, помимо того, что стереть вот это вот все естественно.
[27:04.000 --> 27:07.000]  Так. Ну, это простая задача.
[27:08.000 --> 27:14.000]  Как там называется, как это, да, можно, конечно, там употребить слово глина, но это простая задача.
[27:15.000 --> 27:16.000]  Так вот.
[27:16.000 --> 27:20.000]  Значит, какую мы сейчас задачу с вами попробуем неожиданно решить?
[27:20.000 --> 27:22.000]  Значит, задача будет такая.
[27:22.000 --> 27:30.000]  Мы хотим создать, так сказать, идеальную статическую хэштаблицу.
[27:30.000 --> 27:32.000]  Хотя бы статическую.
[27:32.000 --> 27:34.000]  Работать это будет так.
[27:34.000 --> 27:37.000]  Давайте представим себе, что у нас есть числа.
[27:37.000 --> 27:42.000]  X1, X2, X3 и так далее, Xn.
[27:45.000 --> 27:47.000]  Это целые числа.
[27:47.000 --> 27:52.000]  Ну, давайте, например, там не происходящее, но я не знаю, 10, 18.
[28:01.000 --> 28:03.000]  Вот. Ну, допустим.
[28:05.000 --> 28:06.000]  Вот.
[28:06.000 --> 28:12.000]  Значит, наша задача создать, значит, да, вот это множество статическое.
[28:12.000 --> 28:15.000]  То есть оно вот заданное изначально, но не меняет.
[28:15.000 --> 28:19.000]  Нам очень хочется, желательно его не сортируй я.
[28:21.000 --> 28:23.000]  Нам нужно создать хэштаблицу.
[28:23.000 --> 28:31.000]  То есть некую структуру данных, которая в этом множестве умеет делать операцию x.
[28:34.000 --> 28:38.000]  Ну, то есть существует ли x в этом списке, да или нет?
[28:39.000 --> 28:44.000]  Причем, внимание, у нас суть быть неожиданная.
[28:44.000 --> 28:47.000]  Мы очень хотим, чтобы Xist работал за O от единицы.
[28:49.000 --> 28:51.000]  Причем O от единицы честно.
[28:56.000 --> 29:00.000]  То есть без всякой амортизации и без всяких вероятностей.
[29:01.000 --> 29:04.000]  То есть как бы хэши хэшами.
[29:05.000 --> 29:16.000]  Но нам очень-очень-очень захочется действительно сделать это так, чтобы отвечать на запрос потом с вероятностью 100%.
[29:18.000 --> 29:27.000]  При этом построение у нас будет работать за O от е.
[29:29.000 --> 29:32.000]  Внимание в среднем.
[29:35.000 --> 29:36.000]  Вот.
[29:37.000 --> 29:38.000]  Понятно?
[29:43.000 --> 29:45.000]  Да нет, наверное.
[29:48.000 --> 29:49.000]  Вот.
[29:50.000 --> 29:52.000]  То есть вот такая вот идея.
[29:58.000 --> 30:00.000]  То есть насколько это нереально?
[30:02.000 --> 30:03.000]  Вот.
[30:05.000 --> 30:06.000]  Ну вот.
[30:06.000 --> 30:07.000]  Насколько это нереально?
[30:08.000 --> 30:15.000]  Ну, давайте попробуем покидать какую-нибудь такую, значит, рандомную ситуацию.
[30:17.000 --> 30:19.000]  То есть давайте вот действительно поанализируем.
[30:20.000 --> 30:21.000]  То есть так.
[30:22.000 --> 30:26.000]  На уровне идеи, на самом деле, одна из первых идей будет базироваться на следующем.
[30:27.000 --> 30:29.000]  Вот давайте попробуем создать.
[30:30.000 --> 30:34.000]  Вот пока на O от n забьем, но предположим, что n не сильно большое.
[30:35.000 --> 30:37.000]  То есть числа большие, но n не сильно большое.
[30:38.000 --> 30:40.000]  Тогда хэштаб лицу можно было бы создать следующим образом.
[30:41.000 --> 30:50.000]  Давайте создадим мегахэш функцию по модулю n квадрат.
[30:55.000 --> 30:56.000]  Вот возьмем и создадим.
[30:57.000 --> 31:04.000]  Предположим, что нам фантастически, что там как-то хэш выбирается действительно для каждого элемента случайная равновероятность.
[31:05.000 --> 31:07.000]  И еще и так, что потом еще адекватно вычислить можно.
[31:10.000 --> 31:12.000]  Тогда у нас будет идея такая.
[31:14.000 --> 31:21.000]  Вот, ну предположим, то есть у нас есть какой-то генератор, который генерирует, который дает нам какую-то хэш функцию так, чтоб там вероятности какие-то были.
[31:21.000 --> 31:29.000]  А теперь скажите, пожалуйста, каково математическое ожидание коллизий тогда будет?
[31:51.000 --> 32:03.000]  То есть получается, мат ожидания количества коллизий, оно равно n на n минус 1 пополам на n квадрат, это меньше, чем одна вторя.
[32:05.000 --> 32:07.000]  То есть хэш это означает?
[32:08.000 --> 32:13.000]  Это означает, что когда вы генерите хэши, то с вероятностью не менее чем...
[32:14.000 --> 32:29.000]  Ну тогда вот по неравенству Маркова отсюда следует, что вероятность того, что есть хотя бы одна коллизия, эта вероятность тоже не превосходит одной второй.
[32:30.000 --> 32:32.000]  Ну просто, я просто по неравенству Маркова, правда?
[32:32.000 --> 32:47.000]  То есть получается, в принципе, если у нас есть возможность создать хэш таблицу n квадрат размера, то тогда мы просто генерируем хэш функцию и пытаемся по этой хэш функции этот массив ну типа заполнить.
[32:48.000 --> 32:58.000]  Ну при заполнении как бы понятно, что мы идентифицируем коллизию, если мы попытались положить элемент в какую-то ячейку и опа, в этой ячейке оказывается уже все есть.
[33:02.000 --> 33:03.000]  Понятно, да?
[33:04.000 --> 33:06.000]  То есть отсюда получается, ну вот.
[33:07.000 --> 33:12.000]  И оказывается, что с вероятностью одна вторая никаких проблем нет.
[33:18.000 --> 33:21.000]  Осталось только взять вопрос, откуда такие красивые хэш функции брать?
[33:22.000 --> 33:27.000]  Ведь у нас же, у хэш функции как бы фишка не только в том, что она рандомная, но еще и в том, что ее как-то просто вычисляет.
[33:28.000 --> 33:30.000]  То есть данный элемент, мы ее можем детерминированно вычислить.
[33:30.000 --> 33:44.000]  То есть конечно пока это работает только в предположении, что у нас есть какой-то мега-ораку, который там внутри себя хранит, значит для каждого элемента как-то умеет в себе хранить какое-то значение и он их как-то независимо генерирует, да?
[33:45.000 --> 33:46.000]  Вот.
[33:47.000 --> 33:52.000]  Значит, поэтому, значит, ну придется, значит, например, попроводить чуть более аккуратный анализ, во-вторых, что-то поводить.
[33:53.000 --> 33:54.000]  Вот. Ну, например.
[33:54.000 --> 33:59.000]  Да. Вот давайте я, значит, теперь сформулируем то, значит, то, что мы уже говорили.
[34:00.000 --> 34:05.000]  Значит, вот есть такое понятие, как гипотеза простого равномерного хэширования.
[34:05.000 --> 34:09.000]  Гипотеза простого равномерного хэширования.
[34:10.000 --> 34:17.000]  Гипотеза простого равномерного хэширования.
[34:18.000 --> 34:30.000]  Она будет нам говорить о том, значит, она будет говорить первое, что для любого ключака, вот так,
[34:31.000 --> 34:36.000]  допустим, х от к будет у нас равномерно распределена.
[34:41.000 --> 34:48.000]  А что это в смысле? Что значит равномерно распределена?
[34:49.000 --> 34:55.000]  Это означает, что в некотором смысле х выбирается в некотором смысле случайно.
[34:55.000 --> 35:04.000]  Ну, то есть, опять же, знаете, можем пока вовлестить себе оракул, да, как он работает отдельной песней,
[35:05.000 --> 35:07.000]  но предположим, что у нас происходит две вещи.
[35:08.000 --> 35:14.000]  То есть, во-первых, во-первых, у нас происходит, что, значит, аш от к равномерно распределена.
[35:15.000 --> 35:19.000]  То есть, как бы, то есть, вероятно, то есть, для любого ключа, верно, что у него там, вероятность того,
[35:19.000 --> 35:25.000]  что х будет равен 0, 1, чего угодно, дм минус 1, равна 1, 9 на m.
[35:26.000 --> 35:28.000]  Ну, то есть...
[35:32.000 --> 35:44.000]  И еще, а еще мы скажем, что для любого к1, значит, к2, уточним, неравных, конечно,
[35:44.000 --> 35:54.000]  утверждает, что аш от к1 и аш от к2 должны быть независимы.
[35:59.000 --> 36:02.000]  Обратите внимание, это не такое общее утверждение, как кажется.
[36:03.000 --> 36:11.000]  Потому что, как вы уже знаете из теормера, то, что каждые две случайно влечены по парной независимой, не значит, что они независимы глобально, правда?
[36:12.000 --> 36:14.000]  Было такое, да?
[36:15.000 --> 36:16.000]  Вот.
[36:17.000 --> 36:18.000]  Вот.
[36:19.000 --> 36:20.000]  То есть, вот такая вот есть гипотеза.
[36:21.000 --> 36:22.000]  Ну, вот.
[36:23.000 --> 36:24.000]  Ну, может, например, такое...
[36:25.000 --> 36:29.000]  Для разминки можно сформулировать, скажем, утверждение 1.
[36:32.000 --> 36:37.000]  То есть, условно, смотрите, то есть, можно так сформулировать.
[36:37.000 --> 37:02.000]  То есть, средняя длина цепочки, там, в гипотезе такого, ну вот, при гипотезе вот так равномерного хэширования, да, ну, имейте в виду в методе цепочек, конечно.
[37:05.000 --> 37:06.000]  Вот.
[37:07.000 --> 37:15.000]  Ну, значит, при гипотезе вот этого простого равномерного хэширования, давайте вот так вот.
[37:18.000 --> 37:19.000]  Уж посмотри, КПРХ.
[37:20.000 --> 37:21.000]  Да, КПРХ тоже.
[37:22.000 --> 37:23.000]  Вот.
[37:24.000 --> 37:28.000]  Ну, допустим, не превосходит 1 плюс, ну, вот это вот N9M.
[37:30.000 --> 37:31.000]  Вот.
[37:33.000 --> 37:34.000]  А, вру.
[37:35.000 --> 37:36.000]  Еще-еще прочее.
[37:37.000 --> 37:39.000]  Я хочу сказать, что она просто равна N делить на M.
[37:40.000 --> 37:42.000]  Причем, заметим, средняя здесь не совсем так.
[37:43.000 --> 37:48.000]  То есть, понятно, что если я возьму все цепочки и возьму среднюю арифметическую длину, то получится, конечно же, N делить на M.
[37:49.000 --> 37:50.000]  Это неинтересно, да?
[37:51.000 --> 37:53.000]  Но здесь утверждается немножко круче.
[37:54.000 --> 37:55.000]  То есть, здесь можно рассмотреть так.
[37:56.000 --> 38:00.000]  Рассмотрим какой-нибудь элемент K и посмотрим, в какую цепочку он попал.
[38:01.000 --> 38:06.000]  Так вот, математическое ожидание длины этой цепочки, соответственно, N поделить на M.
[38:08.000 --> 38:13.000]  Так если у нас элемент попадает случайно в каждую из цепочек, то это и так видно.
[38:14.000 --> 38:15.000]  Угу.
[38:16.000 --> 38:17.000]  Ну, в принципе, да.
[38:23.000 --> 38:25.000]  Ну, хотя, хотя нет, хотя тут надо аккуратно.
[38:26.000 --> 38:32.000]  То, что я сказал, на самом деле, по-хорошему, заметим, что в какую бы цепочку он не попал, себя-то он в ней точно посчитает,
[38:32.000 --> 38:37.000]  а каждый из остальных элементов попадет туда с вероятностью N-1 делить на M.
[38:38.000 --> 38:39.000]  Ну, это в такой формат видно.
[38:40.000 --> 38:41.000]  Да.
[38:42.000 --> 38:43.000]  Ну, вот.
[38:44.000 --> 38:46.000]  То есть, вот так, фиксированного элемента K.
[38:47.000 --> 38:49.000]  Ну, естественно, при положении, ну да.
[38:50.000 --> 38:51.000]  Вот так.
[38:52.000 --> 38:55.000]  Ну, тут разные можно проводить, действительно, такое.
[38:56.000 --> 38:57.000]  Вот.
[39:03.000 --> 39:04.000]  Вот.
[39:05.000 --> 39:06.000]  Ну, и, соответственно, там, бла-бла-бла, бла-бла-бла.
[39:07.000 --> 39:09.000]  Значит, дальше разные варианты.
[39:10.000 --> 39:15.000]  Теперь вот возникает вопрос, как же нам, значит, теперь возникает вопрос, как же нам эту крышкунцу генерирует.
[39:19.000 --> 39:22.000]  Ну, генерируйте ее, оказывается, можно так.
[39:23.000 --> 39:24.000]  Смотрите.
[39:25.000 --> 39:31.000]  Значит, то есть, на самом деле, то есть, идея будет в том, что вот как достичь вот такой вот красивой гипотезы.
[39:32.000 --> 39:40.000]  На самом деле, достичь ее можно, да, если от один из вариантов, если у вас есть семейство хэш-функций, из которых вы рандомно выбираете душу.
[39:42.000 --> 39:43.000]  Понятно, да?
[39:45.000 --> 39:46.000]  Ну, вот, например.
[39:47.000 --> 39:51.000]  То есть, один из вариантов мог бы быть, допустим, таким.
[39:53.000 --> 39:54.000]  То есть, да, ну вот.
[39:55.000 --> 39:57.000]  Ну, там разные могут быть варианты.
[39:58.000 --> 39:59.000]  Но давайте так скажу.
[39:59.000 --> 40:04.000]  Значит, тут предлагается ввести такое семейство, значит, красивое хэш-функции.
[40:05.000 --> 40:06.000]  Итак, значит, будем говорить следующее.
[40:07.000 --> 40:16.000]  Значит, пусть у нас, действительно, аж это семейство хэш-функций,
[40:16.000 --> 40:17.000]  хэш-функций,
[40:20.000 --> 40:29.000]  которые отправляют нас из множества ключей наших вот в этот вот сладостный, хирующий и упоительный мир.
[40:30.000 --> 40:32.000]  0, 1, бла-бла-бла и минус 1.
[40:34.000 --> 40:35.000]  Понятно, да?
[40:36.000 --> 40:37.000]  Ла.
[40:38.000 --> 40:39.000]  Допустим.
[40:40.000 --> 40:41.000]  Так вот.
[40:41.000 --> 40:42.000]  Так вот.
[40:43.000 --> 40:44.000]  Ну, давайте так.
[40:45.000 --> 40:46.000]  Мистическое определение.
[40:50.000 --> 40:55.000]  Значит, мы будем называть это семейство универсальным.
[41:00.000 --> 41:03.000]  Оно будет называться у нас универсальным.
[41:03.000 --> 41:04.000]  Универсальный.
[41:07.000 --> 41:08.000]  Там.
[41:09.000 --> 41:10.000]  Если...
[41:12.000 --> 41:13.000]  Я так напишу.
[41:14.000 --> 41:21.000]  Для любых K1, K2, лежащих в ключах и не совпадающих.
[41:26.000 --> 41:27.000]  Вот.
[41:28.000 --> 41:29.000]  Верно.
[41:29.000 --> 41:30.000]  Вот, значит.
[41:31.000 --> 41:34.000]  Сейчас эту вероятность просто напишу в комбинаторном смысле.
[41:35.000 --> 41:36.000]  А комбинаторный смысл такой.
[41:37.000 --> 41:42.000]  То есть количество таких функций h в этом семействе,
[41:43.000 --> 41:48.000]  что h от K1 случайно совпало с h от K2,
[41:52.000 --> 41:58.000]  не превосходит, как вы уже догадались, общего количества числа функций на m.
[41:59.000 --> 42:00.000]  О.
[42:13.000 --> 42:14.000]  Вот.
[42:18.000 --> 42:19.000]  Ну вот.
[42:20.000 --> 42:23.000]  Так что вот такая вот красота у нас получается.
[42:24.000 --> 42:25.000]  Тогда...
[42:26.000 --> 42:32.000]  Заметим, что вот что-то очень похожее на гипотезу просторного равноверного хэширования
[42:33.000 --> 42:36.000]  как-то вот что-то намекает.
[42:37.000 --> 42:41.000]  В предположении, что хэш-функцию мы будем из этого множества выбирать случайно и равновероятно.
[42:42.000 --> 42:43.000]  То есть действительно.
[42:44.000 --> 42:47.000]  Ну то есть у нас, конечно, независимость.
[42:48.000 --> 42:51.000]  То есть здесь, конечно, говорилось, что h от K1 желательно равноверно распределить,
[42:51.000 --> 42:54.000]  потому что h от K2 желательно равноверно распределена должна быть.
[42:55.000 --> 42:58.000]  Но с другой стороны, есть вероятность того, что хэши совпадут.
[42:59.000 --> 43:02.000]  В общем, по большому счету, давайте проанализируем вот это утверждение.
[43:03.000 --> 43:07.000]  Средняя длина цепочки какого-то конкретного элемента K, да?
[43:08.000 --> 43:10.000]  Средняя длина цепочки.
[43:11.000 --> 43:12.000]  Вот давайте подумаем.
[43:13.000 --> 43:14.000]  То есть какая она?
[43:15.000 --> 43:16.000]  Ну, заметьте теперь, что у нас там есть n элементов.
[43:16.000 --> 43:26.000]  И получается, что каждый элемент будет иметь вероятность того,
[43:27.000 --> 43:34.000]  что у него хэш совпадет с нашим, на самом деле не превосходит 1 делить на m.
[43:35.000 --> 43:36.000]  Правда?
[43:37.000 --> 43:39.000]  То есть поэтому здесь тогда получается, что эта средняя она получается даже меньше,
[43:40.000 --> 43:42.000]  чем 1 плюс вот это вот.
[43:43.000 --> 43:45.000]  И плюс, правда?
[43:46.000 --> 43:51.000]  В чем? Обратите внимание, мы там, ну, или что-то смущает?
[43:52.000 --> 43:53.000]  Смущает что-то?
[43:54.000 --> 43:55.000]  Или пока все нормально?
[43:56.000 --> 43:57.000]  Какое смысл?
[43:58.000 --> 44:00.000]  Так, ну давайте, давайте.
[44:01.000 --> 44:02.000]  Давайте.
[44:02.000 --> 44:03.000]  А мы как тут делаем?
[44:04.000 --> 44:18.000]  Мы 1 раз уберем хэш функцию и будем пользоваться и все время из семейства?
[44:19.000 --> 44:20.000]  Да.
[44:21.000 --> 44:22.000]  Ну, точнее так.
[44:23.000 --> 44:24.000]  То есть алгоритм будет работать так.
[44:25.000 --> 44:27.000]  Выбираем случайную хэш функцию из семейства.
[44:28.000 --> 44:29.000]  И будем вот метр цепочек забабахивать.
[44:29.000 --> 44:37.000]  И тогда обратите внимание, да, у каждого элемента тогда получается среднее время работы, это что-то типа 1 плюс m делить на n.
[44:37.000 --> 44:43.000]  То есть у каждого кайфа нот. Причем, заметьте, то есть вероятность генерируется уже нами и нашим семейством.
[44:43.000 --> 44:48.000]  Обратите внимание, они каким-то там арахулом, да? Ну, точнее, мы изобрели этот арахул.
[44:48.000 --> 44:52.000]  Точнее, если мы изобретем такое универсальное семейство хэш-функций, конечно же.
[44:52.000 --> 44:57.000]  Это, видите, это как бы чисто комбинаторная задача.
[45:00.000 --> 45:01.000]  Вот.
[45:01.000 --> 45:04.000]  А неравенство можно чувствовать?
[45:04.000 --> 45:05.000]  Неравенство?
[45:05.000 --> 45:06.000]  Да.
[45:06.000 --> 45:11.000]  Ну, смотрите, давайте так.
[45:11.000 --> 45:15.000]  Ну, вот 1 это, ну, здесь я имел в виду следующее.
[45:15.000 --> 45:19.000]  Допустим, вот k у нас находит, там, отправляется в какую-то цепочку, да?
[45:19.000 --> 45:22.000]  Тогда какова его длина этой цепочки?
[45:22.000 --> 45:26.000]  Пишем, что она 1, это потому что сам элемент там, да?
[45:26.000 --> 45:39.000]  Плюс сумма по всем, значит, всем добавленным вот этим вот, значит, то есть всем остальным каитам не равно k, да?
[45:39.000 --> 45:48.000]  Значит, фактически вероятность того, что h от k случайно совпало с h от k.
[45:48.000 --> 45:51.000]  Логично, да?
[45:51.000 --> 45:54.000]  Вот.
[45:54.000 --> 46:02.000]  То есть, ну, замечаем, что, ну, то есть это вот в качестве мат ожидания, да?
[46:02.000 --> 46:05.000]  Ну, что такое длина цепочки, да?
[46:05.000 --> 46:08.000]  Это количество элементов, в которых хэш совпал с нашим, правда?
[46:08.000 --> 46:09.000]  Вот.
[46:09.000 --> 46:13.000]  По-этому мы это вот, аккуратно суммируем, и эта вероятность равна 1 делить на Н.
[46:13.000 --> 46:19.000]  То есть, получается, это 1 плюс там всех остальных элементов 1-N, ну и там поделить на Н.
[46:19.000 --> 46:24.000]  Да, получается, может быть даже где-то равенств?
[46:24.000 --> 46:29.000]  Вот. То есть, можно было 1 делить, то есть, можно, вот прямо, равенству вот такое написать,
[46:29.000 --> 46:36.240]  Ну и там более аккуратно можно написать, что если мы делали не сколько элементов предположений, что наш элемент тоже находится,
[46:36.240 --> 46:42.240]  а просто какой-то рандомный элемент, мы хотим его вставить, мы хотим его проверить или мы его хотим удалить.
[46:42.240 --> 46:50.240]  То вот аналогичным образом мы показываем, что среднее время работы получается это от 1 плюс длина цепочки, а средняя длина цепочки на m.
[46:50.240 --> 46:56.240]  Ну а единица просто на то, чтобы вычислить хэш, вообще хоть о чем-то подумать, добавить элемент.
[46:56.480 --> 46:59.480]  Почему мы не можем вставить меньше кибарону?
[46:59.480 --> 47:01.480]  Ага.
[47:01.480 --> 47:08.480]  Ой, а не знаю почему, видимо что-то по-моему пока получается, что просто радость то и все, действительно.
[47:08.480 --> 47:14.480]  А, ну просто мы в общем вот это вот, то что универсальность мы пока не пользуемся.
[47:14.480 --> 47:16.480]  Пользуемся.
[47:16.480 --> 47:25.480]  Ну потому что фактически вот это означает, что для любых двух элементов вероятность того, что у них хэши совпадают, не превосходит 1 делить на m.
[47:25.720 --> 47:28.720]  То есть мы вот этим начали пользоваться.
[47:28.720 --> 47:34.720]  То есть как бы да, то есть раньше у нас вообще психологически было, что там просто какие-то числа абсолютно независимо генерятся.
[47:34.720 --> 47:39.720]  Ну а теперь просто задача хэш-функций сделать так, чтобы они там почти независимо генерировались.
[47:39.720 --> 47:42.720]  Ну то есть есть у них вероятность того, что они совпадут будет еще меньше, чем 1.
[47:42.720 --> 47:52.720]  То есть типа мы забиваем на то, что там вот равномерный хэш, и он бы сказал, что вероятность того, что это равно 57, а это 179,
[47:52.960 --> 47:55.960]  там в принципе равна 1 делить на m квадрат.
[47:55.960 --> 48:03.960]  Тут мы на это забиваем, нам как бы главное, чтобы они как бы совпадали с вероятностью не более чем 1 делить на m, и остальное нам уже наплевать.
[48:03.960 --> 48:05.960]  Вот.
[48:05.960 --> 48:07.960]  Ну а теперь.
[48:09.960 --> 48:11.960]  Ну вот.
[48:11.960 --> 48:13.960]  Теперь мы искать вопрос.
[48:13.960 --> 48:19.960]  Как такое универсальное семейство хэш-функций сгенерировать?
[48:19.960 --> 48:21.960]  Как это сделать?
[48:22.200 --> 48:26.200]  Значит, случай easy.
[48:28.200 --> 48:30.200]  Если m...
[48:30.200 --> 48:34.200]  Какое дальше слово напишу, как вы будете?
[48:36.200 --> 48:39.200]  А у нас m это что, это то же самое, что и маленькое?
[48:39.200 --> 48:40.200]  Да.
[48:40.200 --> 48:41.200]  Ну простое, наверное?
[48:41.200 --> 48:43.200]  Да, конечно.
[48:43.200 --> 48:47.200]  Если m оказалось еще и простое,
[48:47.440 --> 48:52.440]  то тогда сгенерировать х прощепарим на репы.
[48:52.440 --> 48:54.440]  Х просто равно...
[48:54.440 --> 48:58.440]  Значит, смотрите, такое семейство функций, как...
[48:58.440 --> 49:00.440]  Значит, ax...
[49:00.440 --> 49:02.440]  Ну вот.
[49:02.440 --> 49:04.440]  То есть, допустим...
[49:04.440 --> 49:06.440]  Ну, вот тут так.
[49:06.440 --> 49:10.440]  Значит, обычно генерировать ax плюс b процент m.
[49:12.440 --> 49:14.440]  Значит, внимание.
[49:14.440 --> 49:18.440]  B лежит на отрезке 1, m-1.
[49:18.440 --> 49:21.440]  И b лежит на отрезке 1.
[49:21.440 --> 49:25.440]  То есть, от нуля до m-1.
[49:33.440 --> 49:37.440]  Если бы еще m было достаточно большим, вообще бы мокрее.
[49:38.440 --> 49:40.440]  Опа.
[49:42.440 --> 49:45.440]  Так что вот, допустим, вот такое вот...
[49:45.440 --> 49:49.440]  Да, это сгенерировать будет, действительно, да.
[49:55.440 --> 50:01.440]  Вы просто говорили, что этот 1, m-1 это время добавления элемента?
[50:01.440 --> 50:04.440]  Добавление и удаление поиска.
[50:04.440 --> 50:06.440]  Добавление и удаление поиска.
[50:06.440 --> 50:08.440]  Типа того.
[50:08.440 --> 50:10.440]  Ну вот.
[50:10.440 --> 50:12.440]  Ну, за счет чего тут хочется такое говорить?
[50:12.440 --> 50:14.440]  То есть, смотрите, давайте предположим, что...
[50:14.440 --> 50:18.440]  То есть, размер такого h у нас получается какой?
[50:18.440 --> 50:20.440]  m на m-1.
[50:24.440 --> 50:26.440]  А теперь давайте думать.
[50:26.440 --> 50:28.440]  В скольких случаях...
[50:28.440 --> 50:32.440]  Вот, допустим, нам даны чиселки x1 и x2.
[50:32.440 --> 50:41.440]  И в скольких случаях у нас окажется, что действительно ax1 плюс b равно ax2 плюс b?
[50:45.440 --> 50:47.440]  Ну, правда, по модулю m, конечно.
[50:56.440 --> 50:58.440]  В скольких случаях это окажется?
[50:58.440 --> 51:06.440]  Это у нас эквалент к тому, что a на x1 минус x2 сравнимо по модулю m с нулю.
[51:18.440 --> 51:19.440]  Так.
[51:19.440 --> 51:21.440]  Да, ну и вообще вытекает ощущение, что...
[51:21.440 --> 51:26.440]  Так, сейчас, пока вот вытекает ощущение, что действительно такого не произойдет никогда.
[51:27.440 --> 51:31.440]  Если x1 и x2 не сравнимо по модулю m, то это произойдет всегда.
[51:31.440 --> 51:32.440]  Ну да.
[51:32.440 --> 51:37.440]  Тогда у нас действительно возникает мелкая проблема, что если они совпадают по модулю m, то...
[51:37.440 --> 51:44.440]  Значит, хеши заведомо совпадают, причем в таком контексте мы с этим ничего не сделаем.
[51:44.440 --> 51:47.440]  Но если они не совпадают, то как будто получается, что...
[51:51.440 --> 51:55.440]  Да, что как будто они просто заведомо никогда совпадать не будут.
[51:56.440 --> 51:57.440]  Ладно.
[51:57.440 --> 51:58.440]  Ладно.
[51:58.440 --> 52:00.440]  Давайте тогда попробуем более сильные вещи.
[52:01.440 --> 52:02.440]  И смотрите.
[52:02.440 --> 52:04.440]  То есть у нас был вот этот, конечно, чит.
[52:04.440 --> 52:07.440]  То есть это бы, конечно, работало, если бы все х были от нуля до m-1.
[52:08.440 --> 52:10.440]  А мы теперь пойдем по другому.
[52:11.440 --> 52:16.440]  Давайте скажем, что теперь у нас, значит, продвинутая версия будет такая.
[52:16.440 --> 52:18.440]  Мы заведем простое число p.
[52:20.440 --> 52:25.440]  Которое будет больше всех вот этих вот m, x1, x2 и так далее, xn.
[52:27.440 --> 52:28.440]  Вот прям вот на сток.
[52:29.440 --> 52:30.440]  Понимаете, да?
[52:32.440 --> 52:35.440]  И h у нас сейчас будет неожиданно следующая версия.
[52:37.440 --> 52:43.440]  Значит, ax плюс b процент p и результат уже будет процент m.
[52:46.440 --> 52:48.440]  a и b, естественно, по модулю p.
[52:56.440 --> 53:01.440]  Ну, правда, единственное, конечно, у вас будет чит, что вам придется инклюзить этот ваш int 128, конечно.
[53:03.440 --> 53:08.440]  Ну ладно, вы уже, так, вы умеете писать не только хэш функцию, там это хэштаблицу, но и длинную арифметику.
[53:10.440 --> 53:11.440]  Или нет.
[53:13.440 --> 53:14.440]  Умейте писать хэш функцию.
[53:15.440 --> 53:16.440]  Умейте писать длинную арифметику.
[53:16.440 --> 53:17.440]  Я этого бы и не сказал.
[53:18.440 --> 53:19.440]  Си-си-си.
[53:19.440 --> 53:20.440]  В смысле?
[53:20.440 --> 53:23.440]  Чтобы писать длинную арифметику, надо исполнить хэш функцию.
[53:23.440 --> 53:24.440]  В смысле?
[53:24.440 --> 53:27.440]  Чтобы писать длинную арифметику, надо использовать длинную арифметику.
[53:27.440 --> 53:29.440]  Нет, в принципе, здесь я использую так.
[53:29.440 --> 53:30.440]  Ну в смысле?
[53:30.440 --> 53:36.440]  Ну как бы, если у вас число на 10 и 18, то, ну, смотрите там, допустим, простое p вы как-нибудь найдете.
[53:37.440 --> 53:46.440]  Ну там понятно, что, ну как минимум, потому что, там, ладно, есть теория, вообще бы, шова на тему того, что между 10 и 18 и двумя на 10 и 18, наверное, есть простое число.
[53:46.440 --> 53:47.440]  Ну не наверное, а точно.
[53:48.440 --> 53:52.440]  Там, скорее всего, наверное, там в гугле вам даже еще скажут, какое конкретно.
[53:53.440 --> 53:54.440]  Их там, скорее всего, больше.
[53:55.440 --> 53:56.440]  Вот.
[53:56.440 --> 54:02.440]  Но просто, нет, проблема будет в том, что, когда вы будете выполнять вот это умножение, то у вас будет там просто переполнение лонголга.
[54:03.440 --> 54:06.440]  Ну, то есть, либо и 128, либо используйте свою длинную арифметику.
[54:07.440 --> 54:09.440]  Ну или там, я не знаю, притом еще может.
[54:10.440 --> 54:12.440]  Не, не в тот случай как-то выдумался.
[54:12.440 --> 54:13.440]  Ну да.
[54:13.440 --> 54:17.440]  Не, ну мало ли, может вы, может, нет, я ж не знаю, может вы вообще джаваи, я не знаю.
[54:18.440 --> 54:21.440]  Не, ну мало ли, может вы там какой-то чуть-чуть подавдройте, я не знаю.
[54:22.440 --> 54:23.440]  Всякое бывает.
[54:24.440 --> 54:25.440]  Не, кстати, у вас джавы нету?
[54:26.440 --> 54:27.440]  Нету? А будет?
[54:28.440 --> 54:29.440]  Нет.
[54:30.440 --> 54:31.440]  Нет, потому что вы не говорили.
[54:32.440 --> 54:33.440]  Обязательно точно нет.
[54:34.440 --> 54:38.440]  А, ну дальше, видимо, зависит от того, вы в математике или кто?
[54:39.440 --> 54:41.440]  Да я вроде, мне кажется, я ни в каком расписании не видел.
[54:42.440 --> 54:43.440]  Совсем-совсем я не знаю.
[54:44.440 --> 54:45.440]  Понятно.
[54:45.440 --> 54:46.440]  Ну, понятно.
[54:46.440 --> 54:47.440]  Не важно.
[54:47.440 --> 54:48.440]  Значит, смотрите, давайте думать.
[54:48.440 --> 54:49.440]  У меня есть вопрос.
[54:50.440 --> 54:51.440]  Вот если у нас с этим планетой это неравенство, да?
[54:52.440 --> 54:53.440]  Что ли?
[54:53.440 --> 54:54.440]  Боба К1, К2, там не больше, чем айшельт на М.
[54:55.440 --> 54:57.440]  Где-то в разуме связано, что это должно быть строгое равенство везде?
[54:58.440 --> 55:02.440]  Ну, потому что у нас просто, понятно, М значений хэш-функций.
[55:03.440 --> 55:05.440]  И если на каждое такое неравенство, то суммарно должно равенство получаться.
[55:06.440 --> 55:07.440]  Что-то такое.
[55:08.440 --> 55:09.440]  Ну, конкретно нет, на самом деле нет.
[55:10.440 --> 55:16.440]  Потому что, ну, сумма вероятности того, что, нет, в смысле, ну, потому что на самом деле это просто может быть то, что,
[55:16.440 --> 55:26.440]  как бы, равенство должно было быть, если бы я писал бы тут, что для любых Т1, Т2, верно, что вероятность того, что аш от К1 равно Т1, а аш от К2 равно Т2,
[55:27.440 --> 55:32.440]  вероятность было бы, не происходило бы там аш поделить на М квадрат, тогда это было бы равенство.
[55:35.440 --> 55:38.440]  Но здесь мы, как бы, просто не все события ставим.
[55:38.440 --> 55:39.440]  Вот, ставим.
[55:44.440 --> 55:46.440]  Хотя, такая равномерность, вообще-то, здесь будет иметь место.
[55:47.440 --> 55:52.440]  Вот давайте посмотрим, почему вот эта штука все-таки адекватна, да, почему она универсальна.
[55:53.440 --> 55:54.440]  Она универсальна, вот почему.
[55:54.440 --> 56:08.440]  Потому что давайте найдем количество таких функций, то есть таких вот АВ, ну, вот адекватных, я не буду сейчас от 1 до P-1, и тут от 0 до P-1,
[56:09.440 --> 56:21.440]  таких, что АХ1 плюс B процент P равно T1, и, допустим, АХ2 плюс B процент P равно T2.
[56:21.440 --> 56:24.440]  Вот, сколько таких А и Б вообще можно набрать?
[56:36.440 --> 56:43.440]  Да, вот эта вот штука, заданное число от 0 до P-1, и вот эта штука от 0 до P-1.
[56:46.440 --> 56:48.440]  Вот сколько таких пар А и Б я могу подобрать?
[56:51.440 --> 57:16.440]  АХ1 зафиг фиксированная.
[57:16.440 --> 57:22.440]  Да, ну, что-нибудь вот из, ну, допустим, АХ1, АХ2, даже вот эти, я тут могу, конечно, АХ2, АХ3 дописать.
[57:23.440 --> 57:24.440]  Давайте я допишу, чтобы.
[57:25.440 --> 57:28.440]  АХ1, АХ2 различные.
[57:31.440 --> 57:35.440]  Ну, что, сколько? Сколько у вас там получилось?
[57:46.440 --> 58:01.440]  Ну, сейчас, ну, А восстанавливается не более, чем мы назнаем, если Х1 и Х2 различные.
[58:02.440 --> 58:03.440]  Ну, они различные.
[58:04.440 --> 58:08.440]  Ну, да. Ну, потому что мы можем, типа, вычесть, получить, что А на И75 равно T2.
[58:09.440 --> 58:17.440]  Ну, да. То есть, можно просто, если это заметить, что А равно T2-T1 поделить, так сказать, по модулю на Х2-Х1.
[58:18.440 --> 58:24.440]  Ну, и там вроде так. Вот. Ну, естественно, деление по модулю. Ну, и там В равно, понятно, чему.
[58:25.440 --> 58:27.440]  Единственное, только надо подлянка, что желательно, чтобы А не оказалось.
[58:28.440 --> 58:33.440]  Только единственная проблема, что А может оказаться, что если T2 равно T1, то, как мы уже поняли, этого просто не бывает.
[58:34.440 --> 58:41.440]  Вот. Поэтому это количество, скажем так, меньше либо равно 1. Вот так скажем.
[58:42.440 --> 58:51.440]  Или оно равно, то есть оно равно, вот так правильно написать, 1, если T1 не равно T2, и 0 иначе.
[58:57.440 --> 58:58.440]  Неплохо, да?
[58:59.440 --> 59:00.440]  Угу.
[59:00.440 --> 59:13.440]  А теперь давайте посмотрим, чтобы у нас, давайте, количество таких h, то есть таких h, что h от X1 равно h от X2.
[59:14.440 --> 59:19.440]  Да? То есть, это количество чему равно?
[59:20.440 --> 59:34.440]  Ну, заметим, так как X1 и первое не равно, значит, X и второе, допустим, они не равны, тогда получается, что у нас, значит, T-шки по модулю P могут не совпадать, правда?
[59:35.440 --> 59:39.440]  То есть, они должны не совпадать по модулю P, но должны совпадать по модулю M, правда?
[59:39.440 --> 59:50.440]  Вот. Ну, тогда получается, что я должен перебрать потенциально, допустим, все остатки по модулю P.
[59:51.440 --> 01:00:02.440]  И для каждого остатка сказать, что если вот, даже не h, вот, допустим, я все вот эти T1 переберу, и теперь я должен подобрать количество соответствующих T2.
[01:00:02.440 --> 01:00:17.440]  То есть, я должен найти количество таких T2 от 0 до P-1, что T1 не равно T2, но T1 сравнимо по модулю M с T2.
[01:00:17.440 --> 01:00:39.440]  Понятно, что я сделал? Так, ну давайте разбираться. Что у нас тогда получается? Что такое T1 и T2? Ну вот.
[01:00:39.440 --> 01:00:45.440]  Ну их строго меньше, чем по 9 на M, для каждого T1.
[01:00:46.440 --> 01:00:55.440]  Ну, давайте так, можно даже в точности посчитать, что для каждого T1 посчитать сколько таких. То есть, ну на самом деле, то есть, вопрос, ну, там, действительно...
[01:00:55.440 --> 01:01:04.440]  Ну, что случится от 0 до P-1, который... Да, имеют, имеют такой остаток. Это да.
[01:01:04.440 --> 01:01:18.440]  Сколько их? Ну их, очевидно, на самом деле, вот так надо написать. То есть, количество таких же остатков, то их, на самом деле, очевидно, P делить на M, то есть, но каждого остатка есть, как минимум, вот столько раз.
[01:01:18.440 --> 01:01:38.440]  Вот. Плюс еще, конечно же, значит, вот эта вот штука. То есть, плюс один еще, если T1%M, значит, строго, допустим, меньше, чем P%M, и еще не забыть, конечно, вот.
[01:01:38.440 --> 01:01:40.440]  Вот. Или вот.
[01:01:40.440 --> 01:01:46.440]  Минус один, потому что... Да, и еще, конечно, не забыть минус один, потому что совсем уж совпадать не должно.
[01:01:48.440 --> 01:02:01.440]  Так. Ну, то есть, видите, это слагаемое где-то больше, чем, там, по 9 на M, там, все, наверное, там, где-то больше, где-то меньше. Ну, давайте аккуратно посчитаем.
[01:02:02.440 --> 01:02:17.440]  Ну, заметим, что вот этого, ну вот, ну, на самом деле, можно уже написать, конечно, что-нибудь типа, там, P на, там, P поделить на M минус один, плюс вот эта вот единица встречается у нас сколько раз?
[01:02:21.440 --> 01:02:27.440]  Эта единица встречается у нас ровно P%M раз. Логично, да?
[01:02:27.440 --> 01:02:46.440]  Вот. А что бы нам хотелось? Нам бы хотелось, чтобы это количество, то есть, вернули, что вот это вот количество не превосходит P на P-1 поделить на M.
[01:03:16.440 --> 01:03:18.440]  А почему?
[01:03:19.440 --> 01:03:30.440]  Сейчас, да, просто. Ну, в общем, что такое, в целой части, поделить на M? Это просто дробь поделить на M минус P...
[01:03:31.440 --> 01:03:40.440]  Да? То есть, действительно, заметим, что вот эта штука, да, если проявить, это равно P на P-M минус P%M, по большому счету, поделить на...
[01:03:41.440 --> 01:03:42.440]  Ну, еще минус один, там, минус.
[01:03:43.440 --> 01:03:47.440]  Еще здесь минус один. Плюс P%M.
[01:03:48.440 --> 01:03:49.440]  Ну, вот, да.
[01:03:53.440 --> 01:03:57.440]  Так, и... Так, вот, смотрите.
[01:03:57.440 --> 01:04:00.440]  Ну, по-моему, достаточно даже значительно получается.
[01:04:01.440 --> 01:04:02.440]  Что-что? Ну, вот.
[01:04:03.440 --> 01:04:13.440]  Ну, давайте так. Получается, пока P на P делить на M минус 1 минус P%M умножить на P делить на M минус 1.
[01:04:14.440 --> 01:04:16.440]  Что? Что больше 0. То есть, можно...
[01:04:16.440 --> 01:04:28.440]  То есть, равно P минус P%M умножить на P делить на M минус 1. Ну, не совсем. Видите, мы с P на P-1 сравниваем P делить на M.
[01:04:29.440 --> 01:04:40.440]  То есть, ну, допустим, вот P-1 делить на M мы берем отсюда. Ну, в принципе, да, можно сказать, что это не превосходит P, это не превосходит P-1 делить на M.
[01:04:42.440 --> 01:04:44.440]  А это правда? Нет.
[01:04:45.440 --> 01:04:46.440]  Что?
[01:04:47.440 --> 01:04:49.440]  Это равно P минус M делить на M.
[01:04:50.440 --> 01:04:51.440]  А, не больше. Ну, да.
[01:04:52.440 --> 01:04:54.440]  Не больше, конечно. Так, ну, что, вроде сошлось, да?
[01:04:55.440 --> 01:04:56.440]  Да.
[01:04:57.440 --> 01:04:58.440]  Вроде не сошлось, правда. Что-то меня спущает, что у нас с таким запасом. Ну, окей.
[01:04:59.440 --> 01:05:03.440]  Ну, мы просто вообще забили на то, что мы считаем не отрицательно ослабляем, и на него просто 0 оценили.
[01:05:04.440 --> 01:05:08.440]  Сейчас мы себя оценили. Я до этого момента вообще предельно чинил.
[01:05:08.440 --> 01:05:14.440]  Ну, по сути, мы сделали что в реальности. Мы сказали, что то, что у нас при P по модели M, оно нулём просто оценивается.
[01:05:15.440 --> 01:05:17.440]  И да, и этого типа нам хватило.
[01:05:18.440 --> 01:05:19.440]  И это нам хватило.
[01:05:20.440 --> 01:05:25.440]  Ну, не совсем. Ну, правда, тут у нас... Нет, ну... Не, ну, не, не, по-моему так...
[01:05:26.440 --> 01:05:27.440]  Слишком легко?
[01:05:28.440 --> 01:05:32.440]  А, ну, хотя да. Нет, ну, да. Нет, ну, я сейчас поглядю, конечно.
[01:05:33.440 --> 01:05:35.440]  Хе-хе-хе-хе-хе. Да, хотя...
[01:05:39.440 --> 01:05:40.440]  Ну, нет.
[01:05:52.440 --> 01:05:59.440]  А, ну, они, правда, видимо, не поскорее, что они тут, видимо, проводили доказательство, что, допустим, зафиксируем одно значение T1.
[01:06:00.440 --> 01:06:06.440]  А, значит, теперь давайте посмотрим там вероятность того, что вторая совпадёт, и окажется, что оно там не более чем то, что нам надо.
[01:06:07.440 --> 01:06:09.440]  Вот. Ну, окей. Хорошо.
[01:06:10.440 --> 01:06:12.440]  Значит, вот такое hash у нас есть.
[01:06:13.440 --> 01:06:16.440]  Мы теперь говорим, что вероятность того, что кто-то там совпадёт, теперь не превосходит...
[01:06:17.440 --> 01:06:26.440]  То есть там, что у разных элементов два hash-асов падут, это у нас вероятность теперь не превосходит, оказывается, один делить на M, обратите внимание, да?
[01:06:27.440 --> 01:06:29.440]  Чем не превосходит, может даже меньше.
[01:06:30.440 --> 01:06:31.440]  Вот.
[01:06:32.440 --> 01:06:39.440]  И теперь заметим, что если бы у нас была возможность создать hash-таблицу размера M2, то мы бы это создали...
[01:06:40.440 --> 01:06:42.440]  Ну, то есть, допустим, вот M2, да?
[01:06:46.440 --> 01:06:47.440]  Нет, M2.
[01:06:52.440 --> 01:06:53.440]  Так.
[01:06:53.440 --> 01:06:54.440]  Пока вот M2.
[01:06:56.440 --> 01:07:05.440]  Ну, то есть, допустим, если бы у нас была возможность создать таблицу размера M2, то есть M было бы там порядка M2, то, получается, мы вот такими hash-функциями могли бы пользоваться.
[01:07:06.440 --> 01:07:08.440]  Потому что, обратите внимание, на M у нас никаких ограничений нет.
[01:07:10.440 --> 01:07:18.440]  Вообще никаких. То есть, теперь говорим, что если M порядка, скажем, M2 какого-нибудь, то есть мы говорим, что M равно M2, и завести вот эту hash-функцию.
[01:07:19.440 --> 01:07:28.440]  То есть, завести hash-функцию, получится, что с вероятностью не менее, чем 1,2, она вообще никаких ограничений нет. То есть, вообще идеальное хреширование.
[01:07:30.440 --> 01:07:31.440]  Вот. Понятная идея?
[01:07:32.440 --> 01:07:33.440]  Вот.
[01:07:34.440 --> 01:07:35.440]  Вообще идеально бы сразу.
[01:07:36.440 --> 01:07:39.440]  Но, конечно же, настолько за M2 мы, конечно, не хотим.
[01:07:40.440 --> 01:07:42.440]  Ну, то есть, мы просто знаем, что в случае чего мы можем ее найти.
[01:07:43.440 --> 01:07:49.440]  Причем, от ожидания построения этой hash-функции было бы там вот это вот M2 плюс потом O от M, согласны?
[01:07:51.440 --> 01:07:52.440]  Вот.
[01:07:53.440 --> 01:07:55.440]  Поэтому смотрите теперь, собственно, какой чит.
[01:07:56.440 --> 01:07:59.440]  Значит, как мы будем строить теперь идеальную hash-таблицу линейного размера?
[01:08:00.440 --> 01:08:03.440]  Да, она еще и по партии будет линейная, как вы уже догадались.
[01:08:04.440 --> 01:08:05.440]  Как же это мы будем делать?
[01:08:05.440 --> 01:08:06.440]  А вот.
[01:08:07.440 --> 01:08:09.440]  Мы сделаем двухуровневую систему.
[01:08:22.440 --> 01:08:23.440]  Ну вот.
[01:08:24.440 --> 01:08:25.440]  Значит, система будет такая.
[01:08:26.440 --> 01:08:28.440]  Значит, уровень 1.
[01:08:28.440 --> 01:08:29.440]  Уровень 1.
[01:08:34.440 --> 01:08:36.440]  Значит, пишем M равно N.
[01:08:37.440 --> 01:08:38.440]  Вот, понятно, да?
[01:08:42.440 --> 01:08:43.440]  Добиваемся того,
[01:08:43.440 --> 01:08:58.440]  что сумма по всем i от 0 до M, до M-1,
[01:08:59.440 --> 01:09:04.440]  длина вот этой вот цепочек, суммы квадратов длины вот этих цепочек,
[01:09:09.440 --> 01:09:10.440]  не превосходит
[01:09:14.440 --> 01:09:17.440]  ну, допустим, O от M в некотором смысле.
[01:09:18.440 --> 01:09:22.440]  То есть, в некотором, ну, у нас там будет что-то типа 4, M6 и M-шотова собираются.
[01:09:28.440 --> 01:09:30.440]  Вот, уровень 2.
[01:09:33.440 --> 01:09:36.440]  Внутри каждой цепочки
[01:09:36.440 --> 01:09:37.440]  длины
[01:09:44.440 --> 01:09:45.440]  длина этой цепочки.
[01:09:46.440 --> 01:09:49.440]  Ну, то есть, смотрите, мы же можем сгенерировать х-функцию
[01:09:50.440 --> 01:09:53.440]  и за O от M просто построить цепочки, просто построить, да?
[01:09:54.440 --> 01:09:56.440]  Это мы делаем тупо за O от M буквально, да?
[01:09:57.440 --> 01:09:59.440]  Мы можем их построить, посчитать их длины,
[01:10:00.440 --> 01:10:01.440]  возвести эти длины в квадрат, просуммировать.
[01:10:01.440 --> 01:10:06.440]  Так вот, мы будем ждать того, что сумма квадратов этих длин не будет превосходить 4N.
[01:10:08.440 --> 01:10:10.440]  Потому что уровень 2 теперь будет говорить нам так, что
[01:10:11.440 --> 01:10:13.440]  внутри каждой цепочки
[01:10:14.440 --> 01:10:18.440]  делаем, объявляем N равно Nит в квадрате.
[01:10:31.440 --> 01:10:33.440]  Вот такая красота.
[01:10:48.440 --> 01:10:54.440]  Ну, заметим, что вот это вот мы делаем в среднем за O от M.
[01:10:55.440 --> 01:10:56.440]  Ну, потому что каждая цепь...
[01:10:57.440 --> 01:10:59.440]  Потому что один раз мы построили...
[01:10:59.440 --> 01:11:00.440]  То есть мы добились...
[01:11:01.440 --> 01:11:04.440]  Один раз мы построили вот эти вот массивы квадратичных размеров
[01:11:05.440 --> 01:11:08.440]  и заполнили их там чем-то там минус единичками суммарно за O от N, да?
[01:11:10.440 --> 01:11:13.440]  А потом внутри каждой цепочки мы делаем там O от единицы
[01:11:14.440 --> 01:11:16.440]  генерации уже внутренней х-функции, да?
[01:11:17.440 --> 01:11:19.440]  И внутренней х-функции проверки нет ли там количества.
[01:11:21.440 --> 01:11:24.440]  Вот, если есть количество, генерируем еще, если нет, то останавливаемся фиксируем.
[01:11:25.440 --> 01:11:28.440]  То есть таким образом мы с вами генерируем N плюс одну х-функцию.
[01:11:30.440 --> 01:11:37.440]  То есть как бы одна глобальная первоуровневая, а на втором уровне мы генерируем N х-функции.
[01:11:42.440 --> 01:11:43.440]  Красиво, правда?
[01:11:44.440 --> 01:11:46.440]  Так, понятно, что происходит?
[01:11:47.440 --> 01:11:49.440]  Или тут уже совсем черная мальчика?
[01:11:50.440 --> 01:11:53.440]  Что сейчас мы внутри каждой цепочки делаем?
[01:11:54.440 --> 01:11:56.440]  Внутри каждой цепочки мы говорим...
[01:11:56.440 --> 01:11:58.440]  Вот у нас есть N и T там элементов, да?
[01:11:59.440 --> 01:12:06.440]  Я генерирую на них вот такую же х-функцию, но N у меня равно теперь уже N и T в квадрате.
[01:12:07.440 --> 01:12:08.440]  Вот так вот сделаем.
[01:12:09.440 --> 01:12:10.440]  Так что, может быть, да.
[01:12:11.440 --> 01:12:15.440]  Ладно, давайте допишем, нам еще придется, наверное, N квадрат еще сюда допустить.
[01:12:26.440 --> 01:12:27.440]  Хотя, может, и не надо.
[01:12:28.440 --> 01:12:35.440]  Потому что если все элементы меньше P, а P будет меньше, чем N квадрат, то как бы любая х-функция будет идеальной.
[01:12:36.440 --> 01:12:38.440]  Так что можно было N квадрат не дописывать.
[01:12:39.440 --> 01:12:40.440]  Но не важно.
[01:12:41.440 --> 01:12:42.440]  Да, давайте выбираем, не дописываем.
[01:12:43.440 --> 01:12:44.440]  Ладно, смотри.
[01:12:45.440 --> 01:12:46.440]  Генерируем.
[01:12:47.440 --> 01:12:48.440]  Теперь алгоритм понятен?
[01:12:49.440 --> 01:12:51.440]  А теперь остается только выяснить его симпатику.
[01:12:52.440 --> 01:13:01.440]  То есть он работает в среднем за O от N плюс O от N умножить на сколько нам потребуется, прежде чем произойдет вот эту.
[01:13:03.440 --> 01:13:04.440]  Понятно, да?
[01:13:05.440 --> 01:13:09.440]  Ну, так, ну, а, ну тут уже поверили, что каждую такую штуку мы будем генерировать от единицы раз в среднем, да?
[01:13:09.440 --> 01:13:10.440]  Нет, не поверили?
[01:13:13.440 --> 01:13:14.440]  Ну, смотрите.
[01:13:15.440 --> 01:13:22.440]  Ну, базируется все на том, что мы знаем, что с вероятностью не менее, чем одна вторая, нам фантастически повезет, правда?
[01:13:23.440 --> 01:13:24.440]  Понимаешь?
[01:13:25.440 --> 01:13:26.440]  Ну да.
[01:13:26.440 --> 01:13:28.440]  И тогда получается мат ожидания количества итерации.
[01:13:29.440 --> 01:13:30.440]  Вот эту вот кси.
[01:13:32.440 --> 01:13:33.440]  Какой у нас?
[01:13:34.440 --> 01:13:43.440]  Оно на самом деле равно, значит вероятность того, что повезет, вероятность повезет на что-то, в том числе, что это фантастически повезет.
[01:13:43.440 --> 01:13:54.860]  Итерацией. Вот это вот кси. Какое у нас? Оно на самом деле равно. Значит, вероятность того,
[01:13:54.860 --> 01:14:09.260]  что повезет. Вот давайте, пусть P это вероятность того, что повезет. Вот так вот, я даже не шукался.
[01:14:09.260 --> 01:14:17.780]  Вот. Тогда это получается, тогда сколько раз мы будем, то есть фактически мы кидаем монетку.
[01:14:17.780 --> 01:14:21.700]  С вероятностью P она выпадет, с вероятностью 1 минус P не выпадет. Спрашивается, сколько средним
[01:14:21.700 --> 01:14:30.540]  мы будем ее кидать, прежде чем она нам выпадет. Тогда мат ожидания работает так, с вероятностью P это
[01:14:30.540 --> 01:14:42.780]  будет 1, а с вероятностью 1 минус P это будет 1 плюс. В общем, то же самое. Это мы расписываем
[01:14:42.780 --> 01:14:52.740]  количество итераций. Вот здесь, да. Вообще мы просто говорим, пока даже в общем случае. То есть мы уже
[01:14:52.740 --> 01:14:58.300]  вычислили с вами, что с помощью простого мат ожидания и неравенства марка, что вероятность того,
[01:14:58.300 --> 01:15:08.260]  что нам повезет не менее чем 1 вторая. То есть когда мы кидаем тут монетку, нам с вероятностью не менее
[01:15:08.260 --> 01:15:17.140]  чем 1 вторая, она выпадет. Повезет это что? Ну, в данном случае это означает, что как бы коллизий не найдется.
[01:15:17.140 --> 01:15:24.900]  И мы так думаем, за от и на это быстро определяем, коллизия есть или нет. Вот. А теперь пока просто давайте
[01:15:24.900 --> 01:15:30.660]  проверим. Пусть у нас есть P, вероятность того, что повезет. Тогда вот нам от ожидания выполнять вот
[01:15:30.660 --> 01:15:39.900]  это уравнение. Ну, это равно 1 плюс 1 минус P на вот эту штуку. В общем, отсюда следует, что х равно банально 1
[01:15:39.900 --> 01:15:50.740]  делить на P. Если P равно 1 вторая или меньше, если P это больше либо равно, чем 1 вторая, то есть при
[01:15:50.740 --> 01:15:58.580]  P больше либо равно, чем 1 вторая, это меньше либо равно. То есть в среднем мы будем делать две операции.
[01:15:58.580 --> 01:16:06.180]  То есть там вероятность, то есть получается вероятность того, что мы там сделаем 10 операций,
[01:16:06.180 --> 01:16:13.180]  это уже не превосходит. Получается там 1 и пятый. И это только так от полтышной оценки. Там чисто
[01:16:13.180 --> 01:16:17.220]  теоретически можно заморочиться, наверное, вычислить дисперсию и нарисовать хуйненький равенство
[01:16:17.220 --> 01:16:30.860]  чебушова. И там может получиться еще круче. Вот. И так. То есть это если так. Ну, в принципе,
[01:16:30.860 --> 01:16:35.820]  вообще заметим, что если P больше либо равно хотя бы 1 делить на хуйню константу K, то тогда мы
[01:16:35.820 --> 01:16:44.860]  делаем O от K и итерации в среднем. И нам остается финал. Ой, умирай. Все, у нас финалочка.
[01:16:44.860 --> 01:16:53.460]  Как бы сейчас это, финального босса тут с этого победим и домой пойдем. Так, кстати, где финальный
[01:16:53.460 --> 01:17:04.180]  босс? Строим совершенно, да, это называется идеальное эфиширование, кстати. Да, это официальное
[01:17:04.180 --> 01:17:15.860]  дросслайне. Вот что мы делаем. То есть мы пытаемся доказать, что этот алгоритм будет работать за O от M.
[01:17:15.860 --> 01:17:25.780]  А для этого нам получается надо найти вот мат ожидания суммы вот этих квадратов. Ну, надо
[01:17:25.780 --> 01:17:30.780]  ее раскрыть, скобки списать, наверное. А как это? Ну, что такое квадраты? Вот давайте так,
[01:17:30.780 --> 01:17:40.180]  пишем. Это 1 плюс 1 плюс загадали в квадрате, да. Ну, вот так, сейчас вот N и T в квадрате. Так, да, что это такое?
[01:17:40.180 --> 01:17:47.180]  Ну, во-первых, там понятно, вылезает просто N, ну типа это сумма 1 квадрата. Да, но это равно
[01:17:47.180 --> 01:17:52.740]  мат ожидания, давайте я пока напишу в сумме. Да, но можно на самом деле написать так, я вот экзотически пишу,
[01:17:52.740 --> 01:18:07.740]  это N плюс 2 в сумме, перебираем по всем ж, да, ж неравным, и конечно. Почему, если мы перебираем по неравным,
[01:18:07.740 --> 01:18:15.300]  тогда 2, наверное, не нужно набрать. Ну, я думаю, что мы переберем пару. Что бы получился квадрат,
[01:18:15.300 --> 01:18:21.740]  мы каждую пару должны два раза вычесть. Ну, просто смотри, вот допустим. А если мы учитываем ее как i и ж, и как ж и это раз,
[01:18:21.740 --> 01:18:31.740]  и мы не читаем уже два раза пару. Да, действительно. Спасибо. И то, что они оказались в одной цепочке.
[01:18:31.740 --> 01:18:46.740]  Да, то есть это называется, то есть как мы говорим, что h от x и равно h от x и. Так, понятно это, откуда мы вообще это заклинание взяли?
[01:18:46.740 --> 01:18:54.740]  Так, ладно, я тут пропустил один шаг. Давайте пропущенный шаг вот такой. Я утверждаю, что вот это вот.
[01:18:54.740 --> 01:19:04.740]  Это сумма по всем i равно от 0 до N минус 1. Сумма по всем ж от 0 до N минус 1. Ну, вот этого,
[01:19:04.740 --> 01:19:12.740]  индикаторные величины равны вернори, что h от x и равно h от x и. Так, вот с этим согласны?
[01:19:12.740 --> 01:19:39.740]  Ну да. Ну, просто смотри, рассмотрим вот эту сумму. А, то есть там пары такие-такие. Да, но заметим, что в этих парах мы учли пары элементов, которые вот сам собой совпадают.
[01:19:39.740 --> 01:20:00.740]  Таких N, поэтому тут выплыло. Вот. Так, теперь. Ну, заметим, что это равно N плюс, ну, мат ожидания этого получается, да, пишем N на N минус 1.
[01:20:00.740 --> 01:20:17.740]  Ладно, меньше либо равно. N на N минус 1. Ну, это, что тут пишем. Ну, вот, что это N на N минус 1 поделить на, в данном случае, N.
[01:20:17.740 --> 01:20:28.740]  Потому что, как бы, мы помним, что оказалось, что спиральность того, что два различных х неожиданно дадут один и тот же хэш, у нас не превосходит 1 делить на N.
[01:20:28.740 --> 01:20:42.740]  Ну, потому что у нас M равно N для 200, правда? Но это равно, ну, то есть шлёп-шлёп, 2N минус 1. То есть тупо меньше, чем 2N.
[01:20:42.740 --> 01:20:52.740]  Ой, поэтому, да, считаю, вот. Чёрт, память сработала. Хотя, сколько лет, честно говоря, сколько лет это не попадало в программу.
[01:20:52.740 --> 01:21:03.740]  Нет, ну, знаете, просто так произошло. Просто, как бы, мне, я помню, как-то из последних раз я просто пытался рассказать это на первом курсе, для этого пришлось вводить, собственно, директорское пространство, мне не понравилось.
[01:21:03.740 --> 01:21:15.740]  Вот, поэтому решил оставить хэш напоследок, но в итоге у нас там несколько лет не хватало времени. Ну, вот у нас с вами время оказалось вагон, поэтому, вот, наконец, мы вспомнили об этой замечательной красоте.
[01:21:15.740 --> 01:21:28.740]  Ну, да, вот про двое я правильно вспомнил. Почему я правильно вспомнил? Потому что теперь мы замечаем, что неравенство Маркова нам сообщает, что вероятность того, что тут будет больше 4N не превосходит 1 и 2.
[01:21:28.740 --> 01:21:38.740]  Ну, и, соответственно, то есть это означает, что это тоже мы будем генерировать от 1 раз.
[01:21:38.740 --> 01:21:46.740]  То есть мы просто будем брать рандомную хэш-функцию и делать вот это, пока не получится так, что...
[01:21:46.740 --> 01:21:50.740]  Да, сумма квадратных цепочек там не происходит 4N.
[01:21:50.740 --> 01:21:58.740]  После этого вы для каждой цепочки генерируете массив на ее длину в квадрате и заполняете его нулями. Это тоже вы теперь делаете за линию.
[01:21:58.740 --> 01:22:06.740]  Ну, и после этого внутри каждой цепочки вы уже генерируете свой локальный идеальный хэш на квадратичном размере.
[01:22:06.740 --> 01:22:13.740]  Ну, там на практике оказывалось, что действительно там что-то фантастически быстро все летает.
[01:22:13.740 --> 01:22:21.740]  Вот. Так что вот. То есть оказывается, да, вот оказывается, да, не такая ушибать я даже оказался.
[01:22:21.740 --> 01:22:27.740]  То есть, на самом деле, в общем, я думаю, там написать код, вот это вот, то есть это вам, конечно, не там...
[01:22:27.740 --> 01:22:30.740]  Ой, не сувечная идея его написать.
[01:22:30.740 --> 01:22:33.740]  Да, сувечная идея тоже не очень сложная.
[01:22:33.740 --> 01:22:38.740]  Ну, да, да, да. А, ну ладно. Ладно, рядом с Атами Кхипом, да.
[01:22:38.740 --> 01:22:42.740]  Или там... Или Соф Кхипом. Но это другой вопрос.
[01:22:42.740 --> 01:22:46.740]  Нет, ну вот это, пожалуйста. То есть, если вам на контесте понадобится хэш-функция, то...
[01:22:46.740 --> 01:22:56.740]  Да, в принципе, это можно заметить, что, да, на самом деле, как бы, да, то есть, если вы хотите хэшировать там строки, я не знаю, да, то, возможно...
[01:22:56.740 --> 01:23:07.740]  Ну, вот. То там, наверное, возможно можно почетерить и брать там какое-нибудь простое число и генерировать там, допустим, полимерные хэши по модулю P, например.
[01:23:07.740 --> 01:23:13.740]  То есть, по модулю P... Ну ладно, вы там скажете, что P, конечно, не будет больше, чем там все эти полинамеральные строки там, что-то.
[01:23:13.740 --> 01:23:19.740]  Но уж пока я нот. Но будем там... Там попробуем, наверное, свято поверить, что там как-нибудь алиниса в платформе.
[01:23:19.740 --> 01:23:25.740]  Хотя на реальном контесте, в общем-то, вам, в общем-то, и логинчик на построение такой хэш-таблицы, в общем, вам не помешает.
[01:23:28.740 --> 01:23:30.740]  Ну что, понятно?
[01:23:31.740 --> 01:23:41.740]  Ну, кстати, заметим, что да, то есть, ну да, осталось только, то есть, честно говоря, к сожалению, у нас, видимо, так и останется за кадром, а как эту штуку динамизировать?
[01:23:42.740 --> 01:23:45.740]  Потому что я могу динамизировать только с доможением за логарифом.
[01:23:47.740 --> 01:23:54.740]  Ну, то есть, там идея такая, у вас есть хранитель логарифом хэш-функции, в каждой хэш-функции N это степень двойки.
[01:23:55.740 --> 01:24:00.740]  Если у нас есть N-лог, то зачем использовать хэш-таблицу, если можно?
[01:24:00.740 --> 01:24:06.740]  Ну вот да, но тут и проблема, да, если у нас есть N-лог, давайте уже честно реализуем наше любимое красночерное дерево.
[01:24:07.740 --> 01:24:11.740]  Или даже вспомним, что мы его уже, что эстрель уже сделал эту зону.
[01:24:12.740 --> 01:24:15.740]  Так что вот, но, тем не менее, вот такая красота есть.
[01:24:17.740 --> 01:24:19.740]  Так, ну что, если тут не так...
[01:24:24.740 --> 01:24:26.740]  Да нет, наверное, нету.
[01:24:27.740 --> 01:24:30.740]  Слушай, ладно, пока пришло время официально объявить, что наш курс закончен.
[01:24:31.740 --> 01:24:35.740]  Этот грустный момент наступил. Не то, чтобы мы с вами не увидимся.
[01:24:36.740 --> 01:24:38.740]  То есть, да, мы с вами увидимся на экзамене.
