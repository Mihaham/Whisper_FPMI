[00:00.000 --> 00:09.460]  Так, мы в прошлый раз остановились на критерии сходимости
[00:09.460 --> 00:10.460]  почти-наверное.
[00:10.460 --> 00:13.340]  Вот я его выписал, это в прошлый раз мы записали.
[00:13.340 --> 00:17.500]  И здесь пониже, ну, вам результат знаком, я его очень кратко
[00:17.500 --> 00:20.620]  повторю, потому что мы из него серединку используем.
[00:20.620 --> 00:24.780]  Значит, и вот здесь пониже я записал условия, кси
[00:24.780 --> 00:27.300]  энное не сходится к си почти-наверное.
[00:27.300 --> 00:28.900]  Правильно, да?
[00:28.900 --> 00:34.640]  Существует n, для любого n найдется, о, прошу прощения,
[00:34.640 --> 00:42.600]  n малое, больше ли равное n большое, такое, что наша
[00:42.600 --> 00:45.600]  омега удовлетворяет вот такому условию, да, вот
[00:45.600 --> 00:46.600]  не сходится.
[00:46.600 --> 00:53.720]  Вот, значит, ну и давайте, так сказать, просто введем
[00:53.720 --> 00:54.720]  обозначение.
[00:54.720 --> 01:06.400]  Вот это множество обозначим b, n, m, а вот это множество
[01:06.400 --> 01:07.400]  обозначим c, m.
[01:07.400 --> 01:17.000]  Ну и давайте пусть, пусть, пусть, омега такие, что кси
[01:17.000 --> 01:22.680]  n от омега, точнее говоря, вероятность не сходится
[01:22.680 --> 01:29.080]  к си от омега, пусть это равно нулю.
[01:29.080 --> 01:34.000]  Отсюда следует, вот смотрим на вот эту запись, что вероятность
[01:34.000 --> 01:38.360]  счетного объединения c, m тоже равна нулю.
[01:38.360 --> 01:43.760]  Отсюда следует, что вероятность c, m-того равно нулю для любого
[01:43.920 --> 01:44.920]  m.
[01:44.920 --> 01:49.720]  Первое наше, так сказать, рассуждение.
[01:49.720 --> 01:55.000]  Второе наше, или на что обратим внимание, что для любого
[01:55.000 --> 02:02.840]  m множество b, m, 1, стягиваются, вот по индексу n большое
[02:02.840 --> 02:04.240]  является стягивающимися.
[02:04.240 --> 02:17.520]  И p, c, m для любого m, которое с одной стороны равно нулю,
[02:17.520 --> 02:26.240]  с другой стороны равно пределу вероятности b, n, m, когда n стремится
[02:26.240 --> 02:27.240]  к бесконечности.
[02:27.240 --> 02:31.480]  Теорема непрерывности вероятности.
[02:31.480 --> 02:37.760]  Ну и давайте этот предел или p, b, n, выпишем так сказать
[02:37.760 --> 02:38.760]  явно.
[02:38.760 --> 02:50.160]  p, b, n, это вероятность события объединения по n больше равно
[02:50.160 --> 02:58.640]  n, ω такие что, к си n от омега минус к си от омега больше
[02:58.640 --> 03:06.040]  единицы на m, больше единицы на m, и это в точности равно,
[03:06.040 --> 03:12.000]  вот здесь я напишу, а потом поясню, вероятности омега
[03:12.000 --> 03:19.520]  таких что, супремум к си n от омега минус к си от омега
[03:19.520 --> 03:24.600]  больше единицы на m, где супремум берется, прошу прощения,
[03:25.600 --> 03:27.960]  пока больше или равно n.
[03:27.960 --> 03:33.240]  Равенство вероятности, потому что эти множества тождественны.
[03:33.240 --> 03:36.000]  Если вот этот супремум больше, значит на каком-то
[03:36.000 --> 03:40.680]  индексе k при каком-то конкретном омеге вот эта величина
[03:40.680 --> 03:43.920]  больше единицы на m и значит она войдет вот сюда и в обратную
[03:43.920 --> 03:44.920]  сторону.
[03:44.920 --> 03:49.880]  Ну собственно, тот хвостик, который нам как бы понадобится.
[03:49.880 --> 03:53.480]  Вот, ну и видим, вероятность вот этого стремится к нулю
[03:53.480 --> 03:57.080]  на основании этого, а вот это собственно с точностью
[03:57.080 --> 04:02.560]  до замены единицы на m на эпсилон, что вопрос технический,
[04:02.560 --> 04:05.960]  завершает доказательство в одну сторону и в обратную
[04:05.960 --> 04:08.480]  сторону просто с конца.
[04:08.480 --> 04:11.000]  То есть предполагаете, что вот это стремится к нулю
[04:11.000 --> 04:15.360]  и назад-назад-назад приходите вот к тому, что вероятность
[04:15.360 --> 04:17.160]  вот этого множества равна нулю.
[04:17.160 --> 04:19.920]  Значит еще раз повторюсь, поскольку результат вам
[04:19.920 --> 04:25.760]  известный, нам на самом деле надо вот это равенство,
[04:25.760 --> 04:29.520]  значит считаем, что с этим нам все понятно.
[04:29.520 --> 04:32.560]  Теперь у нас, я вот тут выписал, остались там хвостики
[04:32.560 --> 04:34.160]  с прошлой лекции.
[04:34.160 --> 04:37.240]  Мы с вами не доказали, что исходимость и почти наверное
[04:37.240 --> 04:40.400]  следует исходимость по вероятности, а также две
[04:40.400 --> 04:43.080]  условных исходимости.
[04:43.080 --> 04:45.680]  Быстрая исходимость по вероятности, которая приводит
[04:45.680 --> 04:48.400]  к тому, что исходимость и пиратность следует исходимость
[04:48.400 --> 04:52.720]  почти наверное, и быстрая исходимость порядка R, из
[04:52.720 --> 04:57.800]  которой тоже, если она имеет место, то из исходимости
[04:57.800 --> 05:00.760]  порядка R следует исходимость почти наверное.
[05:00.760 --> 05:04.520]  Ну давайте мы это по-быстрому, теперь это по-быстрому.
[05:04.520 --> 05:10.720]  Значит смотрите, вот эта вот вероятность, вот позволю
[05:10.720 --> 05:14.160]  себе вот так вот сделать, вот так вот написать, больше
[05:14.160 --> 05:18.160]  или равна, это вероятность объединения, поэтому по крайней
[05:18.160 --> 05:21.400]  мере это вероятность больше вероятности одного члена,
[05:21.400 --> 05:36.720]  а именно с индексом n большое, n большое.
[05:36.720 --> 05:41.400]  Ну позволю себе епсилон написать, вот, ну и поскольку
[05:41.400 --> 05:45.600]  это стремится к нулю, то это стремится к нулю при
[05:45.760 --> 05:51.840]  большом стремящемся к нулю бесконечности, а это по
[05:51.840 --> 05:54.720]  определению исходимость по вероятности.
[05:54.720 --> 05:58.720]  Дальше, с другой стороны, вот можно теперь вот так
[05:58.720 --> 06:03.720]  вот напишу, с другой стороны, вот эта вероятность, поскольку
[06:03.720 --> 06:07.760]  эта вероятность объединения, она меньше или равна суммы
[06:07.760 --> 06:12.840]  вероятностей отдельных множеств, ну тоже себе
[06:12.840 --> 06:18.080]  тут позволю уже без обега написать, кси n минус кси
[06:18.080 --> 06:23.160]  больше епсилон, n от n большого до бесконечности.
[06:23.160 --> 06:30.280]  Значит, если вот это выражение, если вот знак вопроса поставлю,
[06:30.280 --> 06:34.160]  стремится к нулю при n большом, стремящемся к бесконечности,
[06:34.160 --> 06:37.360]  то тогда вероятность вот этого множества стремится
[06:37.360 --> 06:41.320]  к бесконечности, что означает исходимость почти наверная.
[06:41.400 --> 06:45.360]  Но для того, чтобы вот это хвостик ряда, поэтому если
[06:45.360 --> 06:48.320]  мы потребуем, чтобы вот этот ряд сходился, вот смотрите
[06:48.320 --> 06:55.600]  вот здесь, то его хвостик будет стремиться к нулю,
[06:55.600 --> 06:58.920]  то есть если вот этот ряд сходится, то его остаток
[06:58.920 --> 07:03.640]  стремится к нулю, а это и означает, что выполнил
[07:03.640 --> 07:04.840]  сходимость почти наверная.
[07:04.840 --> 07:08.640]  Ну и еще буквально один шаг.
[07:08.640 --> 07:13.800]  Позвольте я вот это сотру теперь и напишу.
[07:13.800 --> 07:19.680]  По неравенству Чебушева меньше или равно 1 на епсилон
[07:19.680 --> 07:25.120]  в степени r сумма n равно от n большое до бесконечности,
[07:25.120 --> 07:29.680]  вероятность того, что кси, ой, невероятность,
[07:29.680 --> 07:37.200]  прошу прощения, математическое ожидание модуля кси n минус
[07:37.200 --> 07:42.560]  кси в степени r по неравенству Чебушева, вот это неравенство.
[07:42.560 --> 07:43.560]  Правильно, да?
[07:43.560 --> 07:47.320]  Ну и те же рассуждения, для того чтобы вот эта величина
[07:47.320 --> 07:53.560]  стремилась к нулю, достаточно, чтобы вот этот ряд сходился,
[07:53.560 --> 07:57.440]  то есть имела место так называемая быстрая сходимость
[07:57.440 --> 07:58.440]  порядка r.
[07:59.200 --> 08:02.520]  Из быстрой сходимости порядка r следует сходимость почти
[08:02.520 --> 08:06.600]  наверная, и из быстрой сходимости по вероятности
[08:06.600 --> 08:09.200]  тоже следует сходимость почти наверная.
[08:09.200 --> 08:16.240]  Вот, нет вопросов?
[08:16.240 --> 08:19.720]  Но это мы как бы добили хвостик с прошлого раза,
[08:19.720 --> 08:21.080]  ну а теперь двинемся дальше.
[08:21.080 --> 08:24.080]  Вот это я сотру.
[08:24.080 --> 08:40.840]  Что еще нам нужно знать про эти типы сходимости?
[08:40.840 --> 08:47.000]  Оказывается, что все четыре введенных у нас типа сходимости
[08:47.000 --> 08:50.800]  случайных последовательств являются фундаментальными
[08:50.800 --> 08:51.800]  покоши.
[08:51.800 --> 08:58.240]  Ну, где-то это очень просто доказывается.
[08:58.240 --> 09:03.720]  Значит, мы с вами для примера, и ввиду того, что будем этим
[09:03.720 --> 09:07.360]  непосредственно пользоваться, докажем это для сходимости
[09:07.360 --> 09:08.360]  почти наверная.
[09:08.360 --> 09:15.000]  Значит, с одной стороны, вселенная сходится к С почти
[09:15.000 --> 09:20.480]  наверная, а сходимость покоши я выпишу следующим
[09:20.480 --> 09:21.480]  образом.
[09:21.480 --> 09:25.760]  Так, вот тут стер, надо было написать другую формулировочку.
[09:25.760 --> 09:30.080]  Я сейчас воспользуюсь чуть-чуть, может, менее привычной
[09:30.080 --> 09:33.960]  формулировкой критерии сходимости почти наверная.
[09:33.960 --> 09:35.200]  Я ему запишу так.
[09:35.200 --> 09:42.040]  Вероятность того, supremum по k больше или равно нулю
[09:42.040 --> 09:48.920]  кси n плюс k минус кси больше епсилон стремится к нулю.
[09:48.920 --> 09:51.800]  Вот видите, просто вот так вот, индекс чуть по-другому
[09:51.800 --> 09:52.800]  представил.
[09:52.800 --> 09:55.520]  Это обычная сходимость.
[09:55.520 --> 09:59.520]  То есть, я напишу, что вот сходимость почти наверная
[09:59.520 --> 10:06.120]  – это то же самое, что вероятность того, что supremum k больше
[10:06.120 --> 10:11.960]  равно нулю кси n плюс k минус кси больше епсилон стремится
[10:11.960 --> 10:12.960]  к нулю.
[10:12.960 --> 10:21.640]  А сходимость покоши мы так определим, supremum, пусть
[10:21.640 --> 10:27.840]  также будет k больше равно нулю, кси n плюс k минус кси
[10:27.840 --> 10:32.400]  больше епсилон, стремится к нулю при n, стремящихся
[10:32.400 --> 10:33.400]  к бесконечности.
[10:33.400 --> 10:38.200]  А вот так определим сходимость покоши.
[10:38.200 --> 10:44.040]  Ну и вот оказывается, что один следует из другого,
[10:44.040 --> 10:47.000]  как и для числовых последовательностей.
[10:47.000 --> 10:52.400]  Из обычной сходимости следует сходимость покоши, и сходимость
[10:52.400 --> 10:54.880]  покоши следует обычная сходимость.
[10:54.880 --> 10:58.120]  Давайте мы этот факт для сходимости почти наверная
[10:58.120 --> 10:59.120]  докажем.
[10:59.120 --> 11:02.280]  Хотя, еще раз повторюсь, это имеет место для всех
[11:02.280 --> 11:03.280]  типов сходимости.
[11:03.280 --> 11:18.480]  А, извините, прошу прощения, конечно, прошу прощения.
[11:25.880 --> 11:26.880]  Забыл.
[11:26.880 --> 11:27.880]  Так.
[11:27.880 --> 11:40.040]  Ну, в одну сторону совсем просто, то есть пусть есть
[11:40.040 --> 11:43.640]  обычная сходимость, докажем, что имеет место сходимость
[11:43.640 --> 11:44.640]  покоши.
[11:44.640 --> 11:50.600]  Для этого рассмотрим вот такую разность по модулю,
[11:50.600 --> 11:52.120]  которая меньше или равна.
[11:52.120 --> 12:05.200]  Ну и, соответственно, я не буду переписывать, внизу
[12:05.200 --> 12:06.200]  напишу.
[12:06.200 --> 12:11.280]  Здесь возьму supremum k больше равно нуля, здесь возьму
[12:11.280 --> 12:20.040]  supremum k больше равно нуля, а вот эту вот заменю на
[12:20.080 --> 12:22.080]  вот этот supremum.
[12:22.080 --> 12:25.680]  То есть напишу, что это меньше или равно, меньше или равно
[12:25.680 --> 12:33.160]  двух supremum'ов k больше равно нуля, кси n плюс k минус
[12:33.160 --> 12:34.160]  кси.
[12:34.160 --> 12:35.160]  Законно, да.
[12:35.160 --> 12:43.600]  Ну и отсюда видно, что если вот этот supremum превосходит
[12:43.600 --> 12:46.600]  епсилон, то этот тоже превосходит епсилон.
[12:46.600 --> 12:54.360]  Ну и как бы получается, что из сходимости обычной
[12:54.360 --> 12:56.960]  почти, наверное, следует сходимость покоши.
[12:56.960 --> 13:01.720]  Вот со вторым в обратную сторону чуть по занудливей,
[13:01.720 --> 13:04.200]  ну так же, как и для числовых последовательностей.
[13:04.200 --> 13:07.520]  Проблема в чем состоит в обратную сторону.
[13:07.520 --> 13:15.640]  Что насуществование предела доказать, да, то есть доказать,
[13:15.640 --> 13:18.880]  что из выполнения этого свойства, если говорить
[13:18.880 --> 13:22.760]  про числовые последовательности, следует существование
[13:22.760 --> 13:26.960]  ну предела вот этого, ну кси, грубо говоря, да.
[13:26.960 --> 13:30.000]  Так, ну давайте сделаем это следующим образом.
[13:30.000 --> 13:33.000]  Давайте введем специальную случайную величину, эта
[13:34.000 --> 13:40.360]  Прям определимая так, это supremum k больше равно нуля
[13:40.360 --> 13:45.720]  кси n плюс k минус кси n.
[13:45.720 --> 13:46.720]  Для удобства.
[13:46.720 --> 13:52.360]  Значит, тогда что вот это условие означает, если
[13:52.360 --> 14:00.640]  мы так ввели такую случайную величину?
[14:00.640 --> 14:06.320]  И это означает, что эта n отсюда следует сходится
[14:06.320 --> 14:09.360]  по вероятности к нулю, правильно?
[14:09.360 --> 14:14.440]  А отсюда следует, по теории Мириса, что существует такая
[14:14.440 --> 14:23.480]  подпоследовательность nt такая, что эта nt стремится
[14:23.480 --> 14:28.400]  к нулю почти наверно, правильно, да?
[14:28.400 --> 14:31.040]  Давайте просто чуть подробнее напишем, что это значит,
[14:31.040 --> 14:32.040]  вот это.
[14:32.040 --> 14:38.840]  Это значит, что вероятностная мера Омега таких, что supremum
[14:38.840 --> 14:55.560]  кси n plus k от Омега минус кси nt от Омега, ой, да, кси
[14:56.400 --> 15:01.120]  t от Омега больше Эпсилон, стремится к нулю, точнее говоря, равна
[15:01.120 --> 15:02.120]  единице.
[15:02.120 --> 15:16.800]  Извините, supremum стремится к нулю, и эта вероятность
[15:16.800 --> 15:22.760]  равна единице, вот, вот так, правильно, да, согласны?
[15:22.760 --> 15:29.040]  То есть мощность Омега таких, что вот этот supremum стремится
[15:29.040 --> 15:33.640]  к нулю, имеет мощность единицы, это множество, вероятность
[15:33.640 --> 15:34.640]  единицы.
[15:34.640 --> 15:38.680]  Так, а скажите, пожалуйста, если Омега фиксирована,
[15:38.680 --> 15:41.720]  то вот эти последствия превращаются в числовые,
[15:41.720 --> 15:42.880]  что вот это означает?
[15:42.880 --> 15:52.160]  Ну, это просто такая немножко специфичная запись сходимости
[15:52.160 --> 15:56.600]  по коши для числовых последовательств, да, то есть для каждого
[15:56.600 --> 16:02.600]  фиксирована Омега из некого множества, единичная мера,
[16:02.600 --> 16:03.600]  правда.
[16:03.600 --> 16:10.880]  Существует такое число кси от Омега.
[16:10.880 --> 16:17.800]  Для любого Омега существует, я его совершенно случайно
[16:17.800 --> 16:19.840]  обозначу кси от Омега.
[16:20.080 --> 16:28.840]  Вот такое, что кси НТ от Омега сходится кси от Омега
[16:28.840 --> 16:35.960]  для любого множества из вот таких, да, то есть на множестве
[16:35.960 --> 16:41.320]  единичной меры для каждого Омега из этого множества
[16:41.320 --> 16:45.800]  кси НТ от Омега сходится кси от Омега, что означает
[16:45.880 --> 16:48.440]  Какую сходимость?
[16:48.440 --> 16:52.760]  Почти наверно, но возникает вопрос, мы когда говорим
[16:52.760 --> 16:56.880]  о сходимости почти наверно, мы имеем в виду, что предел
[16:56.880 --> 17:01.360]  почти наверно, это случайная величина, вот это вот таким
[17:01.360 --> 17:04.440]  образом, все-таки довольно хитро построили, да, взяли
[17:04.440 --> 17:08.040]  каждый Омега, нашли предел как числовая последовательсть,
[17:08.040 --> 17:14.600]  получилось некое отображение, это будет случайная величина-то?
[17:14.600 --> 17:16.360]  Тоесть свойство говорит о том, что это случайная
[17:16.360 --> 17:23.360]  величина, это поточный предел измеримых функций, то
[17:23.360 --> 17:26.400]  есть то, что мы построили, это корректно, это случайная
[17:26.400 --> 17:27.400]  величина.
[17:27.400 --> 17:30.200]  Ну вот, мы нашли вот эту случайную величину, к которой
[17:30.200 --> 17:33.280]  все должно стремиться, теперь осталось так сказать проделать
[17:33.280 --> 17:38.520]  некоторые, ну там не знаю, технические, не технические
[17:38.520 --> 17:46.400]  ну некие выкладки, давайте возьмем кси n плюс k минус
[17:46.400 --> 18:01.400]  кси, и тут прибавим, вычтем, кси n, это вот это n, и еще прибавим,
[18:01.400 --> 18:07.360]  вычтем, кси nt, это не случайная nt, а из вот этой вот последовательности,
[18:07.360 --> 18:11.880]  и еще нам будет удобно, а мы можем это сделать, ничто
[18:11.880 --> 18:15.120]  нас не ограничивает, nt будем всегда выбирать больше
[18:15.120 --> 18:16.120]  n.
[18:16.120 --> 18:24.520]  И тогда эта разность, меньше или равна, кси n плюс k минус
[18:24.520 --> 18:36.040]  кси n, плюс кси nt минус кси n, и плюс кси минус кси nt.
[18:36.040 --> 18:43.760]  Так, кси n каплин, кси, два раза кси n и два раза кси
[18:43.760 --> 18:50.400]  nt, правильно, да?
[18:50.400 --> 19:05.320]  Теперь беру супремум, значит беру супремум по k больше
[19:05.320 --> 19:11.160]  равно нуля, k больше равно нуля, он меньше, ну во-первых
[19:11.160 --> 19:21.480]  супремум по кси n плюс k минус кси n, а вот это я заменю
[19:21.480 --> 19:26.360]  на такой же супремум, поскольку nt больше n, значит nt это какой-то
[19:26.360 --> 19:31.840]  из этих, заменю на супремум, хуже не станет, два супремума
[19:31.840 --> 19:37.000]  пока больше равно нуля, ну а это пока без изменений.
[19:37.000 --> 19:51.040]  Так, вот это я с вашего позволения сотру, можно.
[19:51.040 --> 20:19.520]  Так, вероятность того, что супремум кси n плюс k минус
[20:19.520 --> 20:27.880]  кси минус кси больше эпсилон, пока больше равно нуля, меньше
[20:27.880 --> 20:36.320]  или равен вероятности того, что два супремума кси n
[20:36.320 --> 20:47.920]  плюс k минус кси n плюс кси минус кси nt больше эпсилон,
[20:47.920 --> 20:48.920]  правильно, да?
[20:49.040 --> 20:51.080]  Ну а теперь прием, который вам, наверное, известен.
[20:51.080 --> 20:57.240]  Сумма двух положительных чисел больше эпсилон, это
[20:57.240 --> 21:00.960]  значит, что хотя бы одно из них больше эпсилон пополам,
[21:00.960 --> 21:04.000]  то есть это меньше или равно вероятности объединения
[21:04.000 --> 21:05.680]  вот таких событий.
[21:05.680 --> 21:20.560]  Два супремума больше эпсилон пополам или кси минус кси
[21:20.560 --> 21:24.880]  nt больше эпсилон пополам.
[21:24.880 --> 21:29.160]  Меньше или равно, всегда объединение меньше равно
[21:29.160 --> 21:42.680]  суммы, меньше равно вероятности два супремума
[21:42.680 --> 21:48.200]  плюс вероятность того, что кси минус кси nt больше
[21:48.200 --> 21:49.200]  эпсилон пополам.
[21:49.200 --> 21:55.520]  Так, вот эта штука стремится к нулю ровно потому, что
[21:55.520 --> 21:57.600]  у нас имеет место сходимость по каши.
[21:57.600 --> 22:02.760]  А здесь вспоминаем, что, что за последствия нт?
[22:02.760 --> 22:06.040]  На этой последовательности кси nt сходится почти наверно
[22:06.040 --> 22:10.240]  к си, а значит она сходится по вероятности и значит
[22:10.240 --> 22:15.400]  эта штука стремится к нулю, но не nt пишу, а n стремится
[22:15.400 --> 22:16.400]  к бесконечности.
[22:16.400 --> 22:18.120]  Что мне позволяет так написать?
[22:18.120 --> 22:23.640]  Способ задания nt, мы его всегда брали больше n, видите?
[22:24.640 --> 22:28.880]  Ну вот, мы с вами, собственно, закончили доказательство
[22:28.880 --> 22:34.600]  такого, как потом увидим, очень важного факта, состоящего
[22:34.600 --> 22:38.620]  в том, что сходимость почти наверно обладает фундаментально
[22:38.620 --> 22:39.620]  по каши.
[22:39.620 --> 22:42.400]  Еще раз скажу, что это имеет место и для всех остальных
[22:42.400 --> 22:46.040]  видов сходимости, ну и там в качестве упражнения
[22:46.040 --> 22:47.480]  можно, конечно, попробовать.
[22:47.480 --> 22:52.840]  Так, давайте теперь вот это, ну, наверное, уже теперь
[22:52.840 --> 22:56.280]  вот здесь можно стереть, да?
[22:56.280 --> 23:02.800]  Значит, следующий факт или особенность сходимости,
[23:02.800 --> 23:08.360]  которую нам нужно знать, это так называемое свойство
[23:08.360 --> 23:10.200]  наследования сходимости.
[23:10.200 --> 23:17.880]  Пусть у нас есть некая функция жиатекс, непрерывная, ну
[23:17.880 --> 23:20.120]  и бареллевская, конечно же.
[23:20.120 --> 23:22.920]  Но если у нас она непрерывная, что мы можем утверждать?
[23:22.920 --> 23:28.160]  Что если хн сходится к х, то отсюда следует, что
[23:28.160 --> 23:35.280]  ж от хн сходится к ж от х, правильно, да?
[23:35.280 --> 23:40.200]  Ну и давайте проверим, есть ли такое свойство у сходимости.
[23:40.200 --> 23:42.560]  Ну, возьмем сходимость почти наверная, например.
[23:42.560 --> 23:48.560]  Ксин сходится к си почти наверная.
[23:48.560 --> 23:51.320]  Когда мы можем записать аналогичное включение,
[23:51.320 --> 23:58.000]  а именно, омега такие, что ксин от омега сходится
[23:58.000 --> 24:03.640]  к си от омега, а мы знаем, что вероятность этого события
[24:03.640 --> 24:06.960]  единица, потому что есть сходимость почти наверная.
[24:06.960 --> 24:15.080]  Но, тем не менее, такое событие, влечет событие ж ксин от
[24:15.080 --> 24:22.440]  омега сходится ж кси от омега.
[24:22.440 --> 24:26.040]  Веду такое включение, вероятность вот этого события меньше
[24:26.040 --> 24:28.600]  или равна вероятности вот этого, но вероятность
[24:28.600 --> 24:31.920]  вот этого единицы, значит вероятность вот этого единицы.
[24:31.920 --> 24:36.240]  И мы с вами получаем такое свойство, что если хн сходится
[24:36.240 --> 24:41.240]  к си почти наверная, то для непрерывной функции
[24:41.240 --> 24:46.640]  ж от ксинного будет сходиться к ж от кси.
[24:46.640 --> 24:50.160]  Поэтическое название – свойство наследования сходимости.
[24:50.160 --> 24:55.280]  А, сходится, кстати, в том же смысле почти наверная.
[24:55.280 --> 24:57.600]  Вот, свойство наследования сходимости.
[24:57.600 --> 25:02.600]  Ну, понятно, что ж может быть в принципе разрывно,
[25:02.600 --> 25:04.600]  только она множество меры ноль.
[25:04.600 --> 25:08.160]  Значит, для сходимости почти наверная наследование
[25:08.160 --> 25:09.160]  имеет место.
[25:09.160 --> 25:11.600]  Свойство наследования сходимости имеет место.
[25:11.600 --> 25:18.320]  Ну, давайте посмотрим, что будет для вероятности,
[25:18.320 --> 25:19.320]  например.
[25:19.320 --> 25:21.800]  Для сходимости по вероятности.
[25:21.800 --> 25:28.520]  Для сходимости по вероятности.
[25:28.520 --> 25:34.080]  Хн сходится к си по вероятности.
[25:34.080 --> 25:38.880]  Следует ли отсюда, пока знак вопрос поставим,
[25:38.880 --> 25:46.600]  что ж от ксинного будет сходиться к ж от кси по вероятности?
[25:46.600 --> 25:51.480]  Ну, давайте предположим, что это не так.
[25:51.480 --> 26:01.440]  Пусть ж от ксиного не сходится по вероятности ж от кси.
[26:01.440 --> 26:03.880]  Что это значит?
[26:03.880 --> 26:07.600]  Напишу одну из интерпретаций, что это значит.
[26:07.600 --> 26:12.840]  Это значит, что существуют два числа епсилон дельта
[26:12.840 --> 26:22.400]  больше нуля, а также подпоследовательность n-каты такая что?
[26:22.400 --> 26:34.000]  Вероятность того, что ж от кси n-катого минус ж от
[26:34.000 --> 26:41.480]  кси больше епсилон больше дельта.
[26:41.480 --> 26:45.440]  Вот посмотрите, правильно, да?
[26:45.440 --> 26:49.680]  То есть я вот так записал условия отсутствия сходимости.
[26:49.680 --> 26:55.200]  Через выделение по определению, существует, что для любого
[26:55.200 --> 26:59.600]  n-большого всегда найдется такой, который дальше от
[26:59.600 --> 27:02.760]  предела по расстоянию больше, чем епсилон.
[27:02.840 --> 27:06.280]  Вот те, которые всегда найдутся, мне с ними и построила
[27:06.280 --> 27:07.680]  такую последовательность.
[27:07.680 --> 27:10.080]  Так Po吃 такая последовательность.
[27:10.080 --> 27:18.480]  Хорошо, но в то же время кси от n-каты сходится кси по вероятности,
[27:18.480 --> 27:21.400]  потому что это последовательность сходящейся последовательности,
[27:21.400 --> 27:22.400]  любая подпоследовательность.
[27:22.400 --> 27:28.280]  Но если и от сessedly от n-ка сходится кси по вероятности,
[27:28.280 --> 27:31.680]  отсюда следует, что существует последовательность Б sam.
[27:31.680 --> 27:33.680]  последовательность k,t
[27:35.760 --> 27:37.760]  которая включена в последовательность
[27:38.600 --> 27:40.600]  n,k
[27:40.760 --> 27:42.760]  такая что
[27:42.800 --> 27:44.800]  c,g,c
[27:50.520 --> 27:54.440]  а ну да, для начала такая что
[27:57.760 --> 27:59.760]  c,k,t
[27:59.800 --> 28:02.200]  сходится к
[28:02.200 --> 28:04.200]  ci почти наверное
[28:04.200 --> 28:06.200]  в теории марриса да
[28:06.880 --> 28:09.120]  выделил под последовательность которая сходится по
[28:09.400 --> 28:11.940]  вероятности и из нее выделил вторую под последовательность
[28:12.440 --> 28:15.600]  которая сходится почти наверное но если
[28:15.920 --> 28:18.240]  с180 сходится и и XISH innerhalb
[28:18.720 --> 28:20.720]  то что отсюда следует
[28:22.200 --> 28:24.200]  что g
[28:24.200 --> 28:25.920]  от x и к
[28:25.920 --> 28:35.040]  сходится к g от x, почти, наверное, по ранее доказанному наследованию
[28:35.040 --> 28:43.680]  сходимости, почти, наверное. Правильно? Но для любого kt, который является индексом из nt,
[28:43.680 --> 28:58.840]  выполнено а, и значит отсюда уже следует, что g от x кt сходится g от x по вероятности. Правильно,
[28:58.840 --> 29:07.520]  да? Но для любого kt, который из nt и nk последовательности, а для последовательности nk,
[29:07.520 --> 29:13.080]  для каждого члена последовательности выполнено вот такое неравенство, это означает, что она не
[29:13.080 --> 29:19.040]  может сходиться по вероятности. Получили противоречие. Значит, наше исходное положение
[29:19.040 --> 29:29.200]  неверно, что не выполнено. Убираем знак вопроса и заключаем, что свойство наследования сходимости
[29:29.200 --> 29:39.480]  выполнено и для сходимости по вероятности. Нетрудно убедиться, что для сходимости порядка r
[29:39.480 --> 29:44.480]  свойство наследования не выполнено. То есть это не универсальное свойство.
[29:44.480 --> 29:53.080]  Вот соответствующий пример довольно несложно построить, если кто заинтересуется,
[29:53.080 --> 30:01.080]  полюбопытствует, то с легкостью его построит. Итак, значит, мы с вами установили свойство
[30:01.080 --> 30:06.840]  наследования сходимости, для сходимости почти наверное и сходимости по вероятности.
[30:06.840 --> 30:21.000]  Следующий наш как бы факт или утверждение, связанный со сходимостью,
[30:21.120 --> 30:41.240]  это будет у нас теорема Слуцкого. Значит, Слуцкий наш соотечественник,
[30:41.240 --> 30:55.120]  математик первой половины прошлого века, коллега Колмогорова, вообще-то являлся специалистом в
[30:55.120 --> 31:01.240]  области экономической статистики и там у него ряд как бы важных работ связан с экономикой,
[31:01.240 --> 31:07.080]  но тем не менее оставил след и в математической статистике и в теории вероятности отметился
[31:07.080 --> 31:14.680]  именной теоремой. Значит, теорема выглядит следующим образом. Пусть кси n-ное сходится кси
[31:14.680 --> 31:25.760]  по распределению, а это n-ное сходится к константе С по вероятности. Тогда отсюда следует, во-первых,
[31:25.760 --> 31:37.440]  что кси n плюс это n сходится по распределению кси плюс с, а кси n умножить на это n сходится
[31:37.440 --> 31:49.360]  по распределению c кси. Вот утверждение теоремы Слуцкого. Значит, мы с вами докажем одну часть из-за
[31:49.360 --> 31:57.120]  нехватки времени, но как бы логика доказательства прослеживается. В принципе, вторую можно доказать
[31:57.120 --> 32:06.360]  практически по аналогии. Есть, правда, кое-какие тонкости. Так, ну давайте, значит, первый факт,
[32:06.360 --> 32:13.920]  который я хочу анонсировать, состоит в следующем, что в условиях теоремы кси n-ное плюс с сходится
[32:13.920 --> 32:21.360]  по распределению кси плюс с. Первый-то реальный факт. Ну, позвольте, я не буду доказывать. Его
[32:21.360 --> 32:27.600]  можно доказать непосредственно из-за определения или рассмотрев характеристические функции.
[32:27.600 --> 32:33.080]  Поскольку кси n-ое сходится кси по распределению, то функция распределения кси n-ого сходится к
[32:33.080 --> 32:40.480]  функции распределения кси, ну а константа, как мы знаем, это всегда множитель. Вот, теперь я выпишу,
[32:40.480 --> 32:46.920]  можно сказать, ключевое неравенство. Весьма простое, но как бы здесь оно нам
[32:46.920 --> 32:54.600]  очень сильно поможет. Пусть у нас есть две случайные величины x и y. Это случайные величины.
[32:54.600 --> 33:13.560]  Тогда имеет место вот такое включение. Событие y меньше a влечет событие x меньше a плюс
[33:13.560 --> 33:28.240]  епсилон и одновременно с этим x минус y по модулю больше епсилон. И это имеет место для любого
[33:28.240 --> 33:39.200]  епсилона больше нуля. Ну и а, естественно, любых. Ничего сложного, нарисовать плоскость, посмотреть,
[33:39.200 --> 33:47.160]  так сказать, вот эти области, ну и станет ясно, что слегку перекрывается. То есть,
[33:47.160 --> 33:57.520]  простое соотношение, надо было догадаться, так сказать, ну его применить. Ну и, собственно,
[33:57.520 --> 34:13.120]  теперь, честно говоря, дело техники дальше. Теперь ничего не перепутать. Так. Ну давайте,
[34:13.120 --> 34:21.080]  значит, первый случай, ну как бы два случая нам понадобятся. Первый случай в качестве y возьмем
[34:21.080 --> 34:43.320]  xn плюс это n. В качестве x возьмем xn плюс c. Ну и все. И выпишем, что получится. Выпишу в
[34:43.320 --> 34:53.720]  вероятностях. Вероятность того, что xn плюс это n меньше a, меньше ли равна вероятности того,
[34:53.720 --> 35:05.080]  что xn плюс c меньше a плюс епсилон, плюс вероятность того, их разность будет, представляете,
[35:05.080 --> 35:22.040]  это n минус c больше епсилон. Первый случай. И второй случай. Так, в качестве y берем xn
[35:22.040 --> 35:42.240]  плюс c. В качестве x берем xn плюс это n. И в качестве a берем a минус епсилон. Выписываем.
[35:42.240 --> 35:53.760]  Вероятность того, что xn плюс c меньше a минус епсилон, меньше или равна вероятности того,
[35:53.760 --> 36:05.440]  что xn плюс это n меньше a, плюс вероятность того же самого, это n минус c больше епсилон. Ну вот
[36:05.440 --> 36:12.640]  эти, смотрите, штуки одинаковые. Я их как-нибудь обозначу там. Дельта n епсилон. Вот так. Так.
[36:35.440 --> 36:48.480]  Ну и теперь, значит, вот так это перепишу. Вероятность того, что x это n меньше a с одной
[36:48.480 --> 37:01.960]  стороны, меньше ли равна вероятности того, что xn меньше плюс c, плюс c меньше a плюс епсилон,
[37:01.960 --> 37:16.200]  плюс дельта n епсилон, а с другой стороны, из второго, больше ли равна вероятности того,
[37:16.200 --> 37:31.080]  что xn плюс c меньше a минус епсилон, минус дельта n епсилон. Устремляем к бесконечности.
[37:31.080 --> 37:42.360]  Поскольку это n сходится к c по вероятности, то дельта n епсилон стремится к нулю. А вот это
[37:42.360 --> 37:57.080]  к чему стремится? Вот сюда смотрю. К чему это стремится? Это стремится к функции распределения
[37:57.080 --> 38:05.160]  случайной величины кси плюс с, взятой в точке а минус епсилон. Меньше или равно, здесь пока оставлю
[38:05.160 --> 38:11.880]  в виде предела. Предел, пример стремяющийся к бесконечности. Функция распределения кси n
[38:11.880 --> 38:26.800]  плюс это n в точке а, меньше или равно, f к си плюс с в точке а минус епсилон, ну а минус епсилон.
[38:26.800 --> 38:44.280]  Вот так, да? Ну, дальше что? Дальше епсилон к нулю. Естественно, предполагаем, что точка а,
[38:44.280 --> 38:50.560]  точка непрерывности, поскольку сходимость почти наверная, только в точке непрерывности. Так,
[38:50.560 --> 39:02.160]  значит, это f к си плюс с в точке а, меньше или равно, ну не буду этот предел переписывать,
[39:02.160 --> 39:10.360]  а здесь f тоже к си плюс с, тоже в точке а. Ну, отсюда сделаем вывод, естественно,
[39:10.360 --> 39:17.360]  по теориям там о двух собачках, что вот этот предел как раз и равен функции распределения
[39:17.360 --> 39:31.000]  случайной личины к си плюс с, что и требовалось доказать. Понятно я все изложил? Так, это звонок
[39:31.000 --> 39:41.640]  или что? Звонок. Ну, давайте, как раз вот уложились, отдыхайте и продолжим. Так, ну мы закончили
[39:41.640 --> 39:50.920]  с вами свойства сходимости. Это, конечно, не все, но тот минимум, который как бы нам нужно знать. И
[39:50.920 --> 40:00.760]  переходим уже к таким финальным темам. Это закон больших чисел у нас теперь на очереди. Значит,
[40:00.760 --> 40:07.440]  давайте определимся, что мы имеем в виду. Пусть у нас есть случайная последовательность,
[40:07.440 --> 40:20.600]  счетная. И мы ведем вот такую случайную личину s,n с чертой сверху. Ну, довольно стандартное
[40:20.600 --> 40:33.840]  обозначение. Это среднее значение. Среднее значение. Так вот, мы будем говорить, что случайная
[40:33.840 --> 40:46.440]  последовательность подчиняется закону больших чисел ЗБЧ. Удобное сокращение. ЗБЧ. Если существует
[40:46.440 --> 40:57.560]  числовая последовательность аэнная, такая что к си,н средняя минус аэнная сходится к нулю по
[40:57.560 --> 41:10.960]  вероятности. Это общее определение. Мы будем говорить, что для случайной последствий к си,н выполнен
[41:10.960 --> 41:17.800]  закон больших чисел, если существует такая числовая последовательность, что к си,н средняя
[41:17.800 --> 41:30.680]  минус аэнная сходится по вероятности к нулю. Но в части ЗБЧ мы все результаты получим для
[41:30.680 --> 41:39.640]  конкретного вида аэнная. Для нас аэнная это математическое ожидание к си,н среднего,
[41:39.640 --> 41:56.640]  которое по линейности есть среднее математических ожиданий. И тогда вот это свойство можно
[41:56.640 --> 42:11.200]  переписать в виде. Ну либо к си,н средняя минус, явно запишу среднее математических ожиданий,
[42:11.200 --> 42:27.680]  или ввести просто обозначение с,н центрированное среднее, которое есть среднее значение
[42:27.680 --> 42:38.680]  центрированных случайных величин, то есть из которых вычислим от ожидания. Вот наши результаты в
[42:38.680 --> 42:48.920]  части выполнения ЗБЧ будут относиться вот к этому случаю. Ну собственно, как мы глобально ставим
[42:48.920 --> 42:55.400]  задачу? Мы хотим описать свойство последствий к си,н, какими она должна обладать свойствами,
[42:55.400 --> 43:04.520]  чтобы выполнялся ЗБЧ. Ну попросту говоря, для начала какие-нибудь достаточно условия. Ну и первое
[43:04.520 --> 43:16.760]  достаточно условие дается нам теоремой Маркова и выглядит следующим образом. Если для последовательности
[43:16.760 --> 43:27.840]  единица на,н квадрат дисперсия сумма ксикатых к от единицы до,н стремится к нулю, при,н стремясь к
[43:27.840 --> 43:37.640]  бесконечности, то ЗБЧ. Если последовательность такова, что вот такая величина стремится к нулю,
[43:37.640 --> 43:45.360]  никаких других условий мы не требуем, то для нее выполнен закон большой чисел. Доказательства,
[43:45.360 --> 43:55.640]  ну оно в две строчки, ну надо его, значит напомню, неравенство Чебышева вот в такой форме, вероятность
[43:55.640 --> 44:02.520]  того, что случайная величина это отклонится от своего математического ожидания на величину
[44:02.520 --> 44:11.520]  большую чем,эпсилон не превосходит дисперсии это делить на,эпсилон квадрат. Правильно, да?
[44:11.520 --> 44:22.480]  Ну давайте в качестве это возьмем ксиен средняя, давайте я вот здесь вот это напишу,
[44:22.480 --> 44:33.240]  чтобы вторую доску так сказать осталась свободной, значит ну давайте просто воспользуемся неравенством
[44:33.240 --> 44:42.720]  Чебышева, подставим чего надо. Вероятность того, ну здесь я могу смело написать кси-эн
[44:42.720 --> 44:56.600]  центрированная средняя больше или равно,эпсилон меньше или равно дисперсии кси-эн центрированная
[44:56.600 --> 45:04.480]  средняя делить на,эпсилон квадрат, что в свою очередь равно дисперсии, ну а здесь я напишу явно,
[45:04.480 --> 45:12.200]  что из-за случайной величины, это 1-энная сумма кси-катых, минус мат ожидания кси-катых,
[45:12.200 --> 45:24.520]  кат единицы до,эн в квадрате делить на,эпсилон квадрат. Единицы на,эн квадрат выносим за скобки,
[45:24.520 --> 45:39.800]  ну а тут остается дисперсия, видно, что это как раз дисперсия суммы кси-катых, потому что
[45:39.800 --> 45:45.960]  вычитание константы дисперсию не меняет, помните свойства. Ну и еще тут,эпсилон квадрат конечно,
[45:45.960 --> 45:54.000]  ну вот там наш искомый член, если он стремится к нулю, то значит вот эта вероятность стремится к нулю,
[45:54.000 --> 45:59.880]  что и означает сходимость по вероятности кси-эн центрированного среднего, что означает выполнение
[45:59.880 --> 46:09.000]  закону больших чисел. Вот такое достачное условие. Следующее достачное условие задается теоремой
[46:09.000 --> 46:22.800]  Хинчина, теорема Хинчина. Хинчин наш соотечественник, академик, академия СССР, ну вторая половина,
[46:22.800 --> 46:31.440]  наверное такая, ранняя вторая половина двадцатого века. Вот, теорема Хинчина немножко другие
[46:31.440 --> 46:40.320]  устанавливает достачатые условия. Пусть кселенная независимые одинаково распределенные случайные
[46:40.320 --> 46:49.760]  величины, нор СВ. И еще известно, что существует математическое ожидание кси меньше бесконечности.
[46:49.920 --> 46:54.960]  Я здесь не ставлю индексы, поскольку они все одинаково распределены, у них у всех одинаковое
[46:54.960 --> 47:07.520]  мат ожидания. То тогда ЗБЧ. Вот такие вот достаточно условия. Последствия независимых одинаково
[47:07.520 --> 47:12.360]  распределенных случайных величин, существует мат ожидания, выполнен закон большой чисел. В чем
[47:12.360 --> 47:17.760]  отличие от теоремы Маркова? Не требует существования дисперсии, но правда требуется
[47:17.760 --> 47:24.520]  такое сильное условие независимости, одинаковая распределенность. Ну как есть. Так, доказывается
[47:24.520 --> 47:30.520]  эта теорема с помощью аппарата характеристических функций. Давайте найдем характеристическую
[47:30.520 --> 47:38.240]  функцию кси Н средняя от Т. Что это такое? Это математическое ожидание Е в степени И,
[47:38.240 --> 47:47.440]  Т единица на Н сумма ксикатых К от единицы до Н. Все ксикаты независимы, поэтому это
[47:47.440 --> 47:53.520]  произведение характеристической функции, взятых в точке Т делить на Н. Но поскольку они еще одинаково
[47:53.520 --> 48:01.200]  распределены, то еще характеристические функции одинаковые. Поэтому есть фиг С, взятая в точке Т
[48:01.200 --> 48:11.800]  делить на Н в степени Н. Правильно, да? Ну давайте характеристическую функцию в окрестности нуля
[48:11.800 --> 48:24.600]  разложим, как он говорит, маклорена. Фи от нуля чему равно? Чему равна характеристическая функция в нуле? Единицы всегда.
[48:24.600 --> 48:31.440]  Плюс надо теперь взять производную в нуле. Производная в нуле чему равна характеристической функции?
[48:31.440 --> 48:41.680]  А? И нам от ожидания, если оно существует, но, к счастью, у нас по условию теоремы оно существует.
[48:41.680 --> 48:52.720]  Т на Н, ну и плюс умало от единицы на Н, все в степени Н. Чему это стремится? При Эн-слемящей бесконечности.
[48:52.720 --> 49:04.880]  Это стремится к Е в степени И, Т, мотождание кси. А это что такое? А это характеристическая функция,
[49:04.880 --> 49:15.080]  выраженная случайной величины мотождания кси, взятая в точке Т. Что отсюда следует? Отсюда следует,
[49:15.080 --> 49:25.160]  что кси Эн-средняя сходится по распределению к мотожданию кси. Но тут вспоминаем, что исходимости
[49:25.160 --> 49:32.640]  по распределению к константе, следует исходимость по вероятности. Отсюда следует, что кси Эн-средняя
[49:32.640 --> 49:41.560]  сходится по вероятности к мотожданию кси. То есть выполнен закон больших чисел. Вот
[49:41.560 --> 49:48.880]  достаточные условия выполнения закона больших чисел в форме хинчина. Ну и третье достаточное
[49:48.880 --> 49:57.920]  условие, которое нам нужно знать, это теорема, ну раз есть Марков, кто должен быть? Чебышев,
[49:57.920 --> 50:10.000]  да, теорема Чебышева. Значит тут такие условия накладываются. Значит есть у нас последовательная
[50:10.000 --> 50:20.480]  случайная, могут быть зависимые, но не коррелированные. То есть кавариация кси-этое, кси-житое равна нулю.
[50:20.480 --> 50:30.800]  Ну для любого и не равно жи. Первое. И второе. Дисперсия может себя как-то вести произвольно,
[50:30.800 --> 50:39.800]  но с одним ограничением. Не очень быстро расти, а именно дисперсия кси-эн-ного должна быть
[50:39.800 --> 50:46.640]  ограничена константой на n в степени альфа, где альфа строго меньше единицы, больше равно нуля.
[50:46.640 --> 51:01.040]  То есть дисперсия не быстрее линейной должна быть. И если вот эти условия выполнены, то тогда забычье.
[51:01.040 --> 51:21.000]  Ну такажем, естественно, использовать теорему Маркова. Значит возьмем единица на n квадрат,
[51:21.000 --> 51:29.880]  дисперсия сумма кси-катых крат единицы до n. Для некоррелированных случайных величин дисперсия
[51:29.880 --> 51:37.320]  сумма чему равна? Сумма дисперсии. Помним, что это не только для независимых или скорее не столько
[51:37.320 --> 51:44.440]  для независимых, а для некоррелированных случайных величин. Поэтому есть сумма дисперсии кси-катых
[51:44.440 --> 51:55.640]  делить на n квадрат. Это меньше или равно c делить на n квадрат сумма n в степени k в степени альфа,
[51:55.760 --> 52:02.600]  альфа, где k изменяется от единицы до n. Ну а вот это уж, конечно, меньше или равно,
[52:02.600 --> 52:11.880]  чем c делить на n квадрат интеграл от нуля, чтобы не возиться до n плюс один, х в степени альфа
[52:11.880 --> 52:24.360]  dx, что равно c делить на n квадрат n плюс один в степени альфа плюс один делить на альфа плюс один.
[52:24.360 --> 52:33.680]  Вот это заведомо меньше двух, строго меньше двух. А это означает, что принц, стремящийся к
[52:33.680 --> 52:41.680]  бесконечности может быть и очень медленно, но это все-таки будет сходиться к нулю. Итак,
[52:41.680 --> 52:48.240]  для такой последовательности некоррелированной из дисперсии, растущей не быстрее, чем линейная
[52:48.240 --> 52:56.080]  функция, получается выполнено достаточно условия в форме Маркова. Ну что и заканчивает доказательство
[52:56.080 --> 53:06.760]  теоремы Чебышева. Понятно, да? Нет вопросов? Ну, конечно, мы когда исследуем вот такие связи,
[53:06.760 --> 53:16.720]  то помимо достаточных условий, что нам хочется? Критерий нам хочется еще. И он есть у меня для вас,
[53:16.720 --> 53:24.560]  ну, точнее, не у меня, у Колмогорова. Теорема Колмогорова гласит.
[53:24.560 --> 53:52.880]  Значит, теорема Колмогорова гласит, что закон больших чисел необходимый и достаточно для
[53:52.880 --> 54:01.800]  последовательности, чтобы вот такое мат ожидания, кси n центрированная средняя в квадрате делит на
[54:01.800 --> 54:13.720]  единица плюс кси n центрированная средняя в квадрате, сходилось к нулю. В общем случае,
[54:13.720 --> 54:25.080]  а если кси n независимые случайные величины, то критерием является вот такая вещь. Сумма
[54:25.080 --> 54:36.480]  математических ожиданий, кси k центрированная в квадрате делит на n квадрат плюс кси k центрированная
[54:36.480 --> 54:46.560]  в квадрате стремится к нулю. При сумма k от единицы до n стремится к нулю при n стремящейся к бесконечности.
[54:46.560 --> 54:56.560]  Значит, надо было вверху, но напишу здесь. Теорема Колмогорова.
[54:56.560 --> 55:11.280]  Так, мы ее сейчас докажем в общем виде, но здесь мы не воспользуемся доказательством Колмогорова,
[55:11.280 --> 55:18.720]  несмотря на то, что оно может быть даже проще, но здесь мы пойдем длинным путем.
[55:18.720 --> 55:27.920]  Ну понятно, с извлечением дополнительной пользы.
[55:27.920 --> 55:43.920]  Давайте рассмотрим какую-нибудь последнюю случайных величин Zn,
[55:44.320 --> 55:53.600]  которые по распределению сходятся к нулю. Я утверждаю, что отсюда следует, что для любого альфа больше нуля
[55:53.600 --> 56:04.120]  математическое ожидание модуль Zn в степени альфа делить на единицы плюс модуль Zn в степени альфа
[56:04.120 --> 56:07.800]  тоже стремится к нулю при н стремящейся к бесконечности.
[56:07.800 --> 56:19.320]  Вот сейчас стрельнут все те свойства, которые или многие, которые мы так сказать муторно выводили.
[56:19.320 --> 56:29.040]  Итак, Zn стремится к нулю по вероятности. Я утверждаю, что отсюда следует, что Zn в степени альфа на единицы
[56:29.040 --> 56:34.760]  плюс Zn в степени альфа тоже стремится к нулю при н стремящейся к бесконечности.
[56:34.760 --> 56:54.040]  Откуда это следует? На следовании сходимости. Теперь обратите внимание, что вот эта вот
[56:54.040 --> 57:04.640]  случайная величина с вероятностью единица ограничена единицей для любого n. А что мы знаем?
[57:04.640 --> 57:11.160]  Какое знаем свойство сходящихся по вероятности последствий, которые с вероятностью единицы
[57:11.160 --> 57:22.680]  ограничены для всех n? Для чего мы это делали? Чтобы пользоваться. Отсюда следует,
[57:22.840 --> 57:29.120]  что имеет место сходимость порядка r и в частности сходимость в среднем, то есть c равном единице. А
[57:29.120 --> 57:35.440]  для такой случайной величины сходимость в среднем это как раз и есть. Собственно,
[57:35.440 --> 57:57.680]  вот это даже не буду писать. Согласны? Нет возражений? Теперь давайте в обратную сторону.
[57:57.680 --> 58:11.840]  Пусть вот эта штука выполнена. Тогда отсюда что следует? Исходимость порядка 1. Сходимость
[58:11.840 --> 58:26.120]  по вероятности. Правильно? Исходимость порядка 1 вот для такой случайной величины. Следует
[58:26.120 --> 58:38.800]  сходимость по вероятности. А отсюда что следует? Так уж в лоб по наследованию сходимости zn по
[58:38.800 --> 58:45.640]  модулю. Ну а сходимость zn по модулю к нулю это просто сходимость zn к нулю по вероятности.
[58:45.640 --> 59:00.360]  Согласны? Ну смотрите, а мы с вами доказали, что если zn сходится к нулю, то вот это выполнено
[59:00.360 --> 59:08.360]  не для какого-то альфа, для какого-то проверяли, а для любого. И отсюда мы получаем вот такой,
[59:08.360 --> 59:16.400]  за две минуты с вами получили вот такой замечательный факт, что для любого альфа
[59:16.400 --> 59:29.200]  zn сходится к нулю по вероятности. Это то же самое, что математическое ожидание zn модуль в степени
[59:29.200 --> 59:38.640]  альфа единица плюс zn в степени альфа стремится к нулю, при н стремяющейся к бесконечности. Для
[59:38.640 --> 59:44.520]  любого альфа, любое можно взять. Все будут критерии. Ну просто потому, что вот эти при любом альфа
[59:44.520 --> 59:53.680]  одновременно либо стремятся к нулю, либо нет. Вот. Калмагора взял z равно 2. Вот если взять не z,
[59:53.680 --> 01:00:04.400]  а альфа равно 2. Ну а в качестве zn, естественно, xn центрировано средне. Видите, да? Калмагора взял
[01:00:04.400 --> 01:00:10.040]  альфа равно 2. Получился критерий Калмагорова. Но можно взять альфа равно единицы, например. Это
[01:00:10.040 --> 01:00:17.840]  тоже будет критерий. Чем альфа равно единицы лучше или хуже любого другого, в частности альфа равна 2?
[01:00:17.840 --> 01:00:27.440]  Непонятно, да? Ну смотрите, 2 чем хорошо? Модуль пропадает. Может быть, с вычислительной
[01:00:27.440 --> 01:00:37.160]  точки зрения двойка удачный выбор. Но у альфа равного 1 тоже есть замечательное свойство. Оно
[01:00:37.160 --> 01:00:57.920]  состоит в том, что мат ожидания, пусть будет zn, это метрика. Все как мы любим. Мы оказались
[01:00:57.920 --> 01:01:06.200]  в метрическом пространстве. И все эти кладовые с теоремами метрических пространств теперь как бы
[01:01:06.200 --> 01:01:14.360]  в нашем распоряжении. Этот фокус или прием называется метризация типов сходимости. Мы
[01:01:14.360 --> 01:01:23.320]  с вами метризовали сходимость по вероятности. При альфа равном 2 это уже не метрика, но это критерий,
[01:01:23.320 --> 01:01:30.360]  зато именной критерий Калмагорова. Естественный вопрос, который возникает. А другие типы
[01:01:30.360 --> 01:01:41.040]  сходимости метризуются. Вообще говоря, нетрудно в этом убедиться. Пусть у нас есть сходимость порядка r,
[01:01:41.040 --> 01:01:53.080]  но это то же самое, что мат ожидания xn-xr в степени 1 на r. А вот это уже метрика.
[01:01:53.080 --> 01:02:02.280]  Для сходимости по распределению тоже есть метрика. Она немножко громоздкая. Называется
[01:02:02.280 --> 01:02:11.880]  метрика Левия. Такая громоздкая немножко. Но если рассмотреть ее на классе непрерывных случайных
[01:02:11.880 --> 01:02:18.880]  величин, непрерывные случайные величины, непрерывные не независимые, непрерывных случайных величин,
[01:02:18.880 --> 01:02:32.880]  то тогда вот это вот в обе стороны оказывается. Эквивалентно вот чему, что supremum fxn-x-fx
[01:02:32.880 --> 01:02:41.760]  от x, supremum по x стремится к нулю, прем стремящееся к бесконечности. Равномерная метрика.
[01:02:41.760 --> 01:02:53.360]  Не, ну проверяем по определению. Ну чуть-чуть просто нет времени, к сожалению. Вот чуть-чуть надо
[01:02:53.360 --> 01:02:58.720]  повозиться, так сказать. Доказывается, что это метрика. Причем это такая метрика, смотрите,
[01:02:58.720 --> 01:03:05.120]  например, просто zt-ная по модулю может быть там равно бесконечности. А вот это ее нормируют на
[01:03:05.120 --> 01:03:11.440]  единицу. Это такая метрика, что расстояние между двумя элементами никогда не будет больше единицы.
[01:03:11.440 --> 01:03:20.640]  Вот, значит, итак, для сходимости по распределению тоже есть соответствующая метрика. Еще раз повторю,
[01:03:20.640 --> 01:03:29.240]  в общем случае это метрика Леви, такая громоздкая, но для случайных величин, которые непрерывны,
[01:03:29.240 --> 01:03:35.720]  она превращается в равномерную метрику. Ну и следующий вопрос, а какая же метрика для сходимости
[01:03:35.720 --> 01:03:42.720]  почти наверное? И здесь нас ждет сюрприз. Сходимость почти наверное не метризуется. Не существуют
[01:03:42.720 --> 01:03:49.040]  метрики эквивалентной сходимости почти наверное. Для тех, кто интересуется или заинтересуется,
[01:03:49.040 --> 01:03:59.560]  полюбопытствует, это неплохая задачка, но вполне вам доступная. Так, с метризацией и критерием
[01:03:59.560 --> 01:04:08.440]  выполнения закона больших чисел. Я заканчиваю. Вопросы есть? Вопросов нет. Буквально два слова. Я
[01:04:08.440 --> 01:04:15.120]  когда вот это писал, ну как бы подразумевается обычно так по логике, что частные случаи независимой
[01:04:15.120 --> 01:04:20.560]  случайной величины как-то следуют отсюда. Вы знаете, нет. То есть доказательства для независимости
[01:04:20.560 --> 01:04:26.680]  случайных величин, это критерия, это отдельная работа Колмогорова, там я не знаю, там на десяток
[01:04:26.680 --> 01:04:36.360]  страниц с формулами там, промежучными леммами и так далее. То есть тот случай, когда частный
[01:04:36.360 --> 01:04:43.960]  случай в доказательстве намного сложнее общего. А вот из общей формулировки получить вот этот
[01:04:43.960 --> 01:04:51.600]  частный случай, там нигде не встречал, не знаю как, всем студентам говорю, может кто-нибудь из вас
[01:04:51.600 --> 01:04:58.520]  докажет это как следствие вот этой теоремы. Это будет хороший результат, между прочим. Вот,
[01:04:58.520 --> 01:05:04.720]  потому что само по себе доказательство просто вообще другое. Оно построено по-другому и более
[01:05:04.720 --> 01:05:19.960]  сложное. Ну, тогда все и двигаемся дальше. Так, очень бы хотелось успеть еще один результат довести
[01:05:19.960 --> 01:05:31.240]  до конца, чтобы не начинать потом с совводной. Значит, без предисловий, все скажу потом. Сейчас
[01:05:31.240 --> 01:05:40.600]  просто давайте рассмотрим с вами результат, который называется Леммаково. Коллеги, вот если вас
[01:05:40.600 --> 01:05:46.520]  спрашивают, чей результат в теории вероятности, вам нужно говорить Колмогорова и в 90 процентах
[01:05:46.520 --> 01:05:57.760]  вы окажетесь правы. То есть ошибка возможна, но почти все Колмогорова. Лемма. Значит, пусть у нас
[01:05:57.760 --> 01:06:03.320]  есть последовательность случайных величин, но они независимые случайные величины. Это мы
[01:06:03.320 --> 01:06:10.440]  такое накладываем ограничение. И введем такую частичную сумму СН, сумма ксикатых,
[01:06:10.440 --> 01:06:20.160]  нет, ксиджитых здесь будет, ксиджитых, g от единицы до n и еще центрированных там уже. То есть
[01:06:20.160 --> 01:06:26.740]  частичная сумма центрированных случайных величин. Так вот, утверждение Колмогорова состоит
[01:06:26.740 --> 01:06:38.560]  следующим. Вероятность того, что supremum S Катова окажется больше епсилон, когда k пробегает
[01:06:38.560 --> 01:06:48.760]  значение от 1 до n. Ну supremum тут как бы максимум, ну ладно, воспользуемся suprem. Меньше или равно
[01:06:48.760 --> 01:06:56.840]  математического ожидания S N в квадрате делить на епсилон квадрат, что ввиду, ну как бы,
[01:06:56.840 --> 01:07:05.440]  свойств S Нного на самом деле дисперсия S Нного в квадрате на епсилон квадрат или ввиду их
[01:07:05.440 --> 01:07:13.920]  независимости, просто сумма дисперсии си джитых g равно от единицы до n делить на епсилон квадрат.
[01:07:13.920 --> 01:07:30.640]  Что? Кто независимый? А я ж написал, независимый случайно. Ну да, независимый, независимый. Да,
[01:07:30.640 --> 01:07:36.000]  в прошлый раз я отметил, что речь идет именно о непрерывных. Это независимые случайные
[01:07:36.000 --> 01:07:48.480]  веричины. Значит, ну давайте как бы сразу в карьер. Значит, введем вот такое множество окатая. Это,
[01:07:48.480 --> 01:07:58.240]  вспомним, происходное вероятностное пространство. Это Омега такие, что S житая от Омега, я здесь
[01:07:58.240 --> 01:08:03.400]  подчеркну. Ну то есть смотрите, Омега, каждому Омега соответствует последовательность, каждой
[01:08:03.400 --> 01:08:10.200]  последовательности соответствует последовательности S Нного. Поэтому я тут Омега. Модуль S Омега меньше
[01:08:10.200 --> 01:08:22.840]  или равно епсилон, и это имеет место для всех g от единицы до k минус 1, а вот S ж s кт от Омега
[01:08:22.840 --> 01:08:35.240]  по модулю уже больше епсилона. То есть смысл множества катая туда входят те последовательности,
[01:08:35.240 --> 01:08:43.600]  которые до катой частичной суммы не превышают епсилон, и именно на катой ее в первый раз
[01:08:43.600 --> 01:08:56.480]  превышают. Ну, во-первых, аитая, а житая равно пустому множеству. Объединение окатых кат единицы
[01:08:56.480 --> 01:09:06.280]  до N мы для краткости обозначим А, но на самом деле это как раз и есть. Вот это множество Омега такие,
[01:09:06.280 --> 01:09:25.040]  что supremum s кт больше епсилон, где кат единицы до N. Правильно, да? Вот. Ну и давайте тут же,
[01:09:25.040 --> 01:09:32.360]  чтобы все условия тут описать, введем характеристическую функцию множества А,
[01:09:32.360 --> 01:09:39.080]  которая ввиду того, что эти множества несовместны, на самом деле представляет
[01:09:39.080 --> 01:09:45.000]  из себя сумму характеристических функций. Надо бы написать Акатая, но я, чтобы не таскать
[01:09:45.000 --> 01:09:56.480]  двухэтажный индекс, напишу просто Хкатая от Омега. Катая это Акатая. Вот, значит,
[01:09:56.480 --> 01:10:01.760]  все обозначения ввели. Давайте, двинемся дальше.
[01:10:01.760 --> 01:10:30.640]  Так, ну давайте вот изучим вот это математическое ожидание Sn в квадрате.
[01:10:30.760 --> 01:10:37.240]  Я так запишу, чтобы вы вспомнили, что это такое. Это Sn в квадрате от Омега pdОмега.
[01:10:37.240 --> 01:10:53.400]  Здесь напишу, больше ли равно Sn в квадрате от Омега Ха от Омега pdОмега. Никто не возражает
[01:10:53.400 --> 01:11:04.880]  Ха либо 0, либо 1. То есть эта функция заведомо, ну больше ли равна вот этой вот. Так, Ха это
[01:11:04.880 --> 01:11:13.320]  можно представить в виде суммы, поэтому это на самом деле сумма. Теперь как бы интеграл,
[01:11:13.320 --> 01:11:21.240]  что называется, сверну и напишу математическое ожидание Sn в квадрате на Хкт. К от 1 до n.
[01:11:21.240 --> 01:11:30.800]  Правильно, да? Вот, ну а теперь давайте вот с таким от ожиданий для конкретного Ка повозимся,
[01:11:30.800 --> 01:11:38.960]  напишем. Математическое ожидание Sn в квадрат на Хкт. Это есть математическое ожидание. Помни,
[01:11:38.960 --> 01:11:48.120]  что такое Sn. Мы напишем, что это Скт плюс сумма ксиджитых центрированных g от k плюс 1 до n.
[01:11:48.120 --> 01:11:56.720]  Все в квадрате на Хкт. Квадрат раскрываем, пользуемся линейностью и пишем, что это равно
[01:11:56.720 --> 01:12:07.280]  математическое ожидание Скт в квадрате Хкт плюс, а вот эти два члена я здесь напишу. Там будет
[01:12:07.280 --> 01:12:18.760]  математическое ожидание 2 Скт Хкт умножить на сумму ксиджитых центрированных g от k плюс 1 до n
[01:12:18.760 --> 01:12:32.080]  плюс двойная сумма по g и по l, например. Математическое ожидание ксиджитого
[01:12:32.080 --> 01:12:47.480]  центрированного на кси лт центрированное изобилищу Хкт. Давайте смотрим вот на этот
[01:12:47.480 --> 01:12:55.080]  член. Смотрите, вот эта случайная величина определяется кси к плюс первым, кси к вторым,
[01:12:55.080 --> 01:13:06.240]  кси н. Хкт это функция от кси 1 кси к. Скт это функция от кси 1 кси к. Мы с вами знаем,
[01:13:06.240 --> 01:13:12.720]  что если случайные величины независимы, то любые функции на независимых случайных величинах тоже
[01:13:12.720 --> 01:13:19.120]  независимы. Поэтому вот эти две случайные величины независимы. Математическое ожидание произведения
[01:13:19.120 --> 01:13:24.000]  равно произведению математических ожиданий. А чему равно это ожидание вот этой случайной величины?
[01:13:24.000 --> 01:13:33.560]  Суммы центрированных. Ну ноль. Мат ожидания суммы равно сумме мат ожиданий. Мат ожидания
[01:13:33.560 --> 01:13:38.880]  центрированных случайных членов всегда равно нулю. То есть вот этого члена нет. Смотрим на этот
[01:13:38.880 --> 01:13:48.520]  член. Та же логика. Хкт не зависит от вот этой суммы, потому что здесь индексы с k плюс 1 начинаются.
[01:13:48.520 --> 01:13:55.920]  Поскольку они независимы, все перекрёстные мат ожидания к вариации равны нулю. Те, которые не
[01:13:55.920 --> 01:14:02.320]  равны нулю этой дисперсии, больше или равны нуля. Поэтому вот эта вот вся двойная скобочка для нас
[01:14:02.320 --> 01:14:08.800]  важно, что она просто больше равна нуля. И исходя из этого, мы можем теперь написать, что это больше или
[01:14:08.800 --> 01:14:28.400]  равно математического ожидания sk в квадрате на хк. Мат ожидания sn в квадрате на хк больше
[01:14:28.400 --> 01:14:36.280]  равно мат ожидания sk в квадрате на хк. Видите вот, что мы получили. Вот. Ну, дело за малым.
[01:14:36.280 --> 01:15:03.960]  Значит, напишу, чему это равно в виде интеграла Либега. Это sk в квадрате от
[01:15:03.960 --> 01:15:17.120]  омега на хк от омега. Значит, подинтегральная функция не равна нулю только тогда, когда хк не
[01:15:17.120 --> 01:15:26.040]  равно нулю. Хк не равно нулю. А хк не равно нулю, это означает, что произошло событие акк. Осмотрим
[01:15:26.040 --> 01:15:33.280]  на событие акк. Что оно нам гарантирует? Оно нам гарантирует, что sk по модулю больше
[01:15:33.280 --> 01:15:43.560]  эпсилон. Видите, sk по модулю больше эпсилон. Поэтому все вот это больше или равно эпсилон
[01:15:43.560 --> 01:15:54.600]  квадрат на интеграл хк от омега pd омега. Согласны? А это в свою очередь, ну просто
[01:15:54.600 --> 01:16:03.240]  эпсилон квадрат на вероятность окатова. Возвращаемся вот сюда. Пишем больше или равно
[01:16:03.240 --> 01:16:13.120]  эпсилон квадрат сумма вероятности окатова как единица dn. Поскольку окаты независимы,
[01:16:13.120 --> 01:16:19.640]  то это эпсилон квадрат на вероятность а, но вероятность а это собственно то, что нам... это
[01:16:19.640 --> 01:16:27.120]  событие а это то, что нам и надо. Ну на эпсилон квадрат делим и получаем ответ, так сказать.
[01:16:27.120 --> 01:16:37.080]  Согласны? Отлично. Ну выразил бы некие эмоции, но некогда. Давай еще успеем сформулировать одну
[01:16:37.080 --> 01:16:46.200]  теорему, с которой начнем в следующий раз. Как бы сразу, сейчас начнем получать приятные
[01:16:46.200 --> 01:16:54.760]  последствия. Так, следующая теорема, которую нам нужно знать, ну и вообще весьма полезная,
[01:16:54.760 --> 01:17:04.240]  в том числе и методологической точки зрения. Это теорема кого? Хинчина. Совершенно справедливо.
[01:17:04.240 --> 01:17:15.920]  Теорема Калмагорова-Хинчина. Теорема Калмагорова-Хинчина. Значит, пусть у нас есть СН независимые
[01:17:15.920 --> 01:17:27.400]  случайные величины, про которые известно. Значит, независимые случайные величины. Введем СН по тому же
[01:17:27.400 --> 01:17:37.360]  правилу. Ксикаты и центрированные К, от единицы до Н. И еще известно, что ряд из дисперсии сходится.
[01:17:37.360 --> 01:17:48.880]  Ряд из дисперсии сходится. Ну, это на самом деле означает, что они существуют, им от ожидания
[01:17:48.880 --> 01:17:58.680]  существуют. Вот если для последующих случайных величин, сходя ряд из дисперсии сходится, тогда
[01:17:58.680 --> 01:18:17.280]  существует некая случайная величина С от Омега. Такая, что СН от Омега сходится почти, наверное, С от Омега.
[01:18:18.880 --> 01:18:33.000]  Вот давайте полезная интерпретация за ту минуту, что осталось. Мы на самом деле любым рядом, там я не знаю,
[01:18:33.000 --> 01:18:40.520]  ряд из х-катых от единицы до бесконечности, это же обозначение. Мы на самом деле обозначаем предел
[01:18:40.520 --> 01:18:49.160]  х-катых от единицы до Н, как до Н стремится к бесконечности, правильно? То есть предел частичных
[01:18:49.160 --> 01:18:56.600]  сумм. И здесь, смотри, что написано, что частичные суммы сходятся к некоторому пределу. Но некий
[01:18:56.600 --> 01:19:05.640]  предел частичных сумм, если он существует, это как раз и есть. СН сходится почти, наверное, к сумме
[01:19:05.640 --> 01:19:12.360]  вот такого ряда. Так можно проинтерпретировать. Более того, поскольку это случайная величина,
[01:19:12.360 --> 01:19:21.360]  то она меньше бесконечности, почти, наверное. Любая случайная величина, почти, наверное,
[01:19:21.360 --> 01:19:28.440]  меньше бесконечности. Вот эта интерпретация, которая нам понадобится. Ну давайте тогда на
[01:19:28.440 --> 01:19:35.000]  формулировке этой закончим и с этого момента начнем с вами в следующий раз. Нам осталось немного,
[01:19:35.000 --> 01:19:41.760]  но как бы самое важное. Все, коллеги, давайте. Спасибо.
