[00:00.000 --> 00:14.000]  Тема сегодняшней лекции – численные методы решения обыкновенных дифференциальных уравнений для задачи каши.
[00:14.000 --> 00:19.000]  История этих методов восходит к концу XVII века.
[00:19.000 --> 00:36.000]  Если вы помните, в это время Ньютон и Лебнис предложили обыкновенные дифференциальные уравнения, которые сыграли огромную роль в дальнейшем исследовании процессов физики, экономики и многое еще где.
[00:36.000 --> 00:43.000]  Что касается численных методов, по понятным причинам, не было компьютеров в течение долгого времени.
[00:43.000 --> 00:56.000]  Численные методы не развивались, но тем не менее, несмотря на это, через сто лет после их открытия Эйлер предложил первый метод Эйлера.
[00:56.000 --> 01:07.000]  Да, он самый простой, он первого порядка точности. Его в чистом виде сейчас для решения задачи никто не использует.
[01:07.000 --> 01:20.000]  Его, скорее всего, используют в учебнометодических целях, он очень полезен для учебнометодических целей и как конструкционный элемент для построения методов высокого порядка точности.
[01:20.000 --> 01:31.000]  Причем сходимость этого метода к решению дифференциального уравнения доказал каши примерно через 50 лет.
[01:31.000 --> 01:37.000]  Все, так сказать, вот такими большими шагами двигалось.
[01:37.000 --> 01:51.000]  Примерно через 70 лет после доказательства сходимости немецкий математик Рунге предложил методы построения численных методов высокого порядка точности.
[01:51.000 --> 01:55.000]  За ним английский математик Адамс.
[01:55.000 --> 02:05.000]  Давайте начнем. Хорошо известны вам дифференциальные уравнения первого порядка. Я вам его напомню.
[02:05.000 --> 02:14.000]  Вы его знаете из курса дифференциальных уравнений. Диференциальное уравнение – начальное данное.
[02:14.000 --> 02:25.000]  Вообще говоря, это может быть система уравнений. В этом случае U, F и A принадлежат инверному ифлидовому пространству.
[02:25.000 --> 02:29.000]  Это может быть и скалерное уравнение. Я буду это отдельно оговаривать.
[02:29.000 --> 02:33.000]  То есть скалерное уравнение либо система уравнений.
[02:33.000 --> 02:44.000]  Если мы имеем уравнение n порядка, дифференциальное D, T, N, D, N, U, P, D, T, N,
[02:44.000 --> 02:57.000]  то в случае решения задачи Каши обычно такое уравнение n порядка сводит к системе n уравнений дифференциальных первого порядка.
[02:57.000 --> 03:12.000]  Здесь нужно поставить U от 0 равняется A1, U' от 0 равняется A2 и так далее.
[03:12.000 --> 03:15.000]  Обычно сводится к системе первого порядка.
[03:15.000 --> 03:28.000]  Давайте пример такой напишем. U1 равняется U, U2 равняется dU1 по dt и так далее.
[03:28.000 --> 03:48.000]  U' равняется dUn-1 по dt и dUn по dt это есть f от t U1, U2 и так далее.
[03:48.000 --> 04:06.000]  И, соответственно, начальные данные тоже переносится U1 от 0, A0, U2 от 0 это будет A1 и до конца.
[04:06.000 --> 04:12.000]  Это сведение уравнения n порядка к системе n уравнений первого порядка.
[04:12.000 --> 04:16.000]  Для задачи Каши обычно так и делают.
[04:16.000 --> 04:24.000]  Что касается краевых задач для дифференциальных уравнений, то здесь ситуация немного другая.
[04:24.000 --> 04:38.000]  Например, для уравнений второго-четвертого порядка обычно не сводится к системе уравнений второго-четвертого порядка, решает вот эти уравнения.
[04:38.000 --> 04:42.000]  Теперь что касается численного решения.
[04:42.000 --> 04:46.000]  Сделаю одно небольшое замечание.
[04:46.000 --> 05:08.000]  Иногда бывает так, что решить численное дифференциальное уравнение оказывается более просто, чем получить решение аналитического,
[05:08.000 --> 05:10.000]  решение записанного в довольно сложном виде.
[05:10.000 --> 05:14.000]  Ну вот какой-нибудь простой пример давайте приведу.
[05:14.000 --> 05:18.000]  Вот, например, пусть будет dU divided by t уравнение.
[05:18.000 --> 05:24.000]  Его решение напишу U-t, U-t.
[05:24.000 --> 05:26.000]  Его решение следующее.
[05:26.000 --> 05:42.000]  Одна вторая логарифма t квадрат плюс U квадрат плюс арк тангенс U делить на t равняется константе.
[05:42.000 --> 05:44.000]  Ну как мы будем вот это уравнение решать?
[05:44.000 --> 05:48.000]  Ну, вспомните, как мы решали нелинейное уравнение.
[05:48.000 --> 05:52.000]  При каждом t равном tn мы решаем уравнение.
[05:52.000 --> 05:56.000]  То есть это означает, что мы вводим в сетку.
[05:56.000 --> 06:00.000]  Умега n, как обычно вводим.
[06:00.000 --> 06:04.000]  tn это будет t0 плюс n tau.
[06:04.000 --> 06:08.000]  t0 это значальная точка.
[06:08.000 --> 06:12.000]  n это 0, 1 и так далее.
[06:12.000 --> 06:16.000]  И n большое.
[06:16.000 --> 06:20.000]  tau это вот t большое.
[06:20.000 --> 06:26.000]  Итак, интегрирование делить на n большое.
[06:26.000 --> 06:30.000]  tn равняется t большое.
[06:30.000 --> 06:32.000]  Здесь небольшая оговорка.
[06:32.000 --> 06:36.000]  В дифференциальных уравнениях для задачи каши обычно пишется так.
[06:36.000 --> 06:44.000]  t принадлежит t0 бесконечности.
[06:44.000 --> 06:49.000]  Ну, поскольку у нас численные методы, мы не можем оперировать понятием бесконечности.
[06:49.000 --> 06:53.000]  Если ведем счет до какого-то t большого.
[06:53.000 --> 06:57.000]  Поэтому здесь у нас t будет принадлежать отрезку конечному.
[06:57.000 --> 07:03.000]  t0 и t большое.
[07:03.000 --> 07:07.000]  Всегда мы будем писать, что этот отрезок конечен.
[07:07.000 --> 07:13.000]  Ну вот, и для каждого узла t равное tn мы будем решать нелинейное уравнение.
[07:13.000 --> 07:17.000]  Ну, например, методом простых итераций, либо методом Newton.
[07:17.000 --> 07:23.000]  На каждом tn мы должны делать какое-то количество итераций.
[07:23.000 --> 07:31.000]  И будет ли это более экономично, чем решать численно наше дифференциальное уравнение?
[07:31.000 --> 07:33.000]  Это вопрос.
[07:33.000 --> 07:39.000]  Есть такие решения, то есть решения выписаны в таком сложном виде дифференциальных уравнений,
[07:39.000 --> 07:42.000]  что легче решать численно дифференциальное уравнение,
[07:42.000 --> 07:48.000]  чем численно решать точные решения, выписанные в очень сложном виде.
[07:48.000 --> 07:51.000]  Особенно это сказывается в уравнении математической физики,
[07:51.000 --> 07:53.000]  то есть в уравнении в частных производных.
[07:53.000 --> 07:58.000]  Там вот таких точных решений, записанных в виде очень сложных функций,
[07:58.000 --> 08:01.000]  типа функций Бесселя разного рода.
[08:01.000 --> 08:04.000]  Там тоже такая же ситуация имеет место быть.
[08:04.000 --> 08:08.000]  Ну, это, конечно, не всегда. Разумеется, не всегда.
[08:08.000 --> 08:11.000]  Всегда хорошо получить точные решения.
[08:11.000 --> 08:19.000]  Но в жизни, оказывается, что в реальных задачах чаще всего...
[08:19.000 --> 08:24.000]  Сейчас, наверное, почти всегда нужно получать численные решения.
[08:24.000 --> 08:27.000]  Численные решения.
[08:27.000 --> 08:35.000]  Так, идём дальше.
[08:35.000 --> 08:42.000]  Давайте предложим операторный вид решения наших уравнений.
[08:42.000 --> 08:48.000]  Ну, в частности, для уравнений, которые записаны в таком каноническом виде.
[08:48.000 --> 08:52.000]  Давайте так.
[08:52.000 --> 08:59.000]  Мы предложим операторную форму записи такого уравнения.
[08:59.000 --> 09:08.000]  Пусть L – дифференциальный оператор, LU равняется F.
[09:08.000 --> 09:11.000]  Это будет операторная форма записи дифференциального уравнения
[09:11.000 --> 09:14.000]  либо системы дифференциальных уравнений.
[09:14.000 --> 09:20.000]  Здесь оператор LU означает следующее.
[09:20.000 --> 09:32.000]  DU по Dt при t больше 0, U0 при t равном 0.
[09:32.000 --> 09:36.000]  Это 1 и F.
[09:36.000 --> 09:50.000]  Это будет F от TU при t больше 0 и A при t равном 0.
[09:50.000 --> 09:55.000]  Вот такая форма операторной записи дифференциального уравнения.
[09:55.000 --> 10:01.000]  Ну и давайте будем также записывать в операторной форме уравнения апроксинирующие.
[10:01.000 --> 10:05.000]  Значит, вводится сетка. Сетку я написал только что.
[10:05.000 --> 10:12.000]  И давайте, следуя Леонарду Эдеру, апроксинируем наше дифференциальное уравнение методом Эдера.
[10:12.000 --> 10:15.000]  Это простейший метод.
[10:15.000 --> 10:17.000]  Выглядит следующим образом.
[10:17.000 --> 10:28.000]  Ft-1 минус Un ем на tau равняется Ftn Un.
[10:28.000 --> 10:31.000]  У от нуга это есть A.
[10:31.000 --> 10:33.000]  Вот это метод Эдера.
[10:33.000 --> 10:37.000]  Забегая вперед, скажу, что он имеет первый порядок точности.
[10:37.000 --> 10:41.000]  И схема такая называется явной схемой.
[10:41.000 --> 10:46.000]  Когда схема называется явной, когда в правой части все функции нам известны.
[10:46.000 --> 10:50.000]  То есть на n-м слое мы считаем функции все известны.
[10:50.000 --> 10:53.000]  И находим решение на n-м с первым слоем.
[10:53.000 --> 10:58.000]  То есть Un плюс 1 это есть что?
[10:58.000 --> 11:08.000]  Это есть Un плюс tau на Ftn Un.
[11:08.000 --> 11:15.000]  U0 равняется нашим начальному значениям.
[11:15.000 --> 11:18.000]  Ну и здесь рекуррентная обычная формула.
[11:18.000 --> 11:26.000]  U1 это есть U0 плюс tau на Ft0 U0.
[11:26.000 --> 11:34.000]  U2 это есть U1 плюс tau на Ft1 U1.
[11:34.000 --> 11:36.000]  Ну и так далее.
[11:36.000 --> 11:39.000]  Обычная рекуррентная формула.
[11:39.000 --> 11:42.000]  Далеко программируются такие явные схемы.
[11:42.000 --> 11:46.000]  Такие, что называют схемами бегущего счета.
[11:46.000 --> 11:51.000]  Они легко программируются и получаются результаты.
[11:51.000 --> 12:00.000]  Ну как правило, конечно, в реальной жизни используется схема более высокого порядка точности, о чем мы сегодня будем говорить.
[12:00.000 --> 12:06.000]  Ну вот давайте запишем в опературном виде вот эту схему Эдинга.
[12:06.000 --> 12:17.000]  В численных методах принято называть такими схемами, когда производные аппроксимируются вот такими разностями.
[12:17.000 --> 12:21.000]  Помните, конечные разности, разделенные разности я вам вводил.
[12:21.000 --> 12:27.000]  Это тоже есть ничто иное, как аппроксимация первопроизводная с помощью конечной разности.
[12:27.000 --> 12:30.000]  Принято называть разностными схемами.
[12:30.000 --> 12:36.000]  Сейчас, конечно, вычислительная математика ушла далеко.
[12:36.000 --> 12:45.000]  И не только разностные схемы используются для численного решения аппроксимации интегралов, вариационных методов.
[12:45.000 --> 12:50.000]  Их много, я буду говорить, но в чине всего курса о них.
[12:50.000 --> 12:57.000]  Но вот этот термин разностные схемы к численным методам решения дифференциальных уравнений так вот остался.
[12:57.000 --> 13:03.000]  Он не совсем корректен, но он остался, как некая священная корова.
[13:03.000 --> 13:14.000]  Один из самых фундаментальных учебников по решению дифференциальных уравнений,
[13:14.000 --> 13:20.000]  который написал Виктор Самулович Рябинке, который где-то лет 20 на футболе лекции читал,
[13:20.000 --> 13:28.000]  и Сергей Косынович Годунов, который предложил один из самых важных численных методов,
[13:28.000 --> 13:38.000]  который известен во всем мире и во всей мировой численной практике, называется этот учебник разностные схемы.
[13:38.000 --> 13:42.000]  Ну хотя, с теми оговорками, о которых я говорил.
[13:42.000 --> 13:48.000]  Так, ну давайте вот напишем эту разностную схему в виде оператора.
[13:48.000 --> 13:53.000]  l tau u tau равняется f tau.
[13:53.000 --> 14:04.000]  Значит, l tau u tau у нас будет разностный оператор, который прохиммирует в данном случае первую производную.
[14:04.000 --> 14:11.000]  Здесь n строго больше 0, у 0 при n равном 0.
[14:11.000 --> 14:21.000]  И f tau, значит tau, я внизу эти буквы ставлю tau, означает, что это разностный оператор, это апроксиммирующее уравнение.
[14:21.000 --> 14:24.000]  Не дифференциальное, а апроксиммирующее уравнение.
[14:25.000 --> 14:32.000]  Это будет f при t больше 0, то есть правая часть наша.
[14:32.000 --> 14:37.000]  И а при, ну здесь лучше написать так, при n больше 0.
[14:37.000 --> 14:43.000]  И а при n равном 0.
[14:43.000 --> 14:51.000]  Вот в таком операторном виде мы будем писать наше дифференциальное уравнение и разностные уравнения.
[14:51.000 --> 14:56.000]  Вид очень удобен для дальнейшего исследования.
[14:56.000 --> 15:02.000]  Ну какой вопрос первый должен встать, когда мы видим, например, вот такую проксимацию,
[15:02.000 --> 15:06.000]  например, этим простейшим методом дифференциального уравнения.
[15:06.000 --> 15:08.000]  Какой вопрос встает?
[15:08.000 --> 15:15.000]  Я на самом деле намекнул на этот вопрос, говоря, что Каши что-то доказал.
[15:15.000 --> 15:22.000]  Через 50 лет после того, как Энер предложил свой метод, доказал сходимость.
[15:22.000 --> 15:30.000]  То есть нужно показать, что данная разностная схема имеет отношение к нашему дифференциальному уравнению.
[15:30.000 --> 15:32.000]  И довольно конкретное отношение.
[15:32.000 --> 15:34.000]  Давайте об этом как раз и поговорим.
[15:34.000 --> 15:38.000]  То есть прежде чем решать численно какое-нибудь дифференциальное уравнение,
[15:38.000 --> 15:46.000]  нужно быть уверенным в том, что вы решаете тем методом, который вам даст.
[15:46.000 --> 15:52.000]  Ну, например, при тау, это шаг в нашей расчетной сетке,
[15:52.000 --> 15:57.000]  при тау, стремящийся к нулю, точное решение.
[15:57.000 --> 16:02.000]  Для этого вводится три фундаментальных понятия.
[16:02.000 --> 16:04.000]  В теории раз за всем.
[16:04.000 --> 16:08.000]  Это значит сходимость, аппроксимация и устойчивость.
[16:08.000 --> 16:16.000]  Заранее скажу, что эти понятия были введены профессором Рябинским Виктором Самволовичем в начале 50-х годов.
[16:16.000 --> 16:25.000]  Это один из одноположников теории разностных схем, который, как я говорю, на футболе около 20 лет читал лекции.
[16:25.000 --> 16:32.000]  И за океаном был у него Визови, тоже блестящий американский математик Питер Блакс,
[16:32.000 --> 16:37.000]  который также разрабатывал теорию разностных схем, теорию сходимости.
[16:37.000 --> 16:44.000]  И он параллельно, почти в это же время, ввел понятие сходимости, аппроксимации и устойчивости.
[16:44.000 --> 16:53.000]  Правда, когда была конференция, это довольно давно было уже, не помню сколько, на Мехмате,
[16:53.000 --> 17:00.000]  была конференция, посвященная памяти Академика Петровского, Питер Блакс единственный раз приехал в Москву.
[17:00.000 --> 17:04.000]  И встретился с Рябиньким.
[17:04.000 --> 17:10.000]  Поскольку Питер Блакс на русском разговаривал, так же, как Виктор Самволович Рябинький на английском,
[17:10.000 --> 17:14.000]  мне пришлось там у них поработать переводчиком.
[17:14.000 --> 17:23.000]  И исходя из этого беседы с ним, я понял, что центральную теорию обосновывающую теорию разностных схем,
[17:23.000 --> 17:28.000]  теорию квалетности, о которой сейчас мы будем говорить, первым доказал Рябинький.
[17:28.000 --> 17:34.000]  По этому теорию правильно называть тиремой Рябинького лакса, поскольку лакс независимо от Рябинького доказал.
[17:34.000 --> 17:38.000]  Но это нигде не зафиксировано. Почему не зафиксировано?
[17:38.000 --> 17:43.000]  Поскольку в 50-х годах все работы по численным методам были просто рассекречены.
[17:43.000 --> 17:50.000]  У американцев над ними стоял гриф ТС, у нас СС.
[17:50.000 --> 17:55.000]  Рассекреченные эти работы были где-то примерно в середине, в конце 50-х годов.
[17:56.000 --> 18:07.000]  Но тем не менее в отчетах, которые представлялись закрытых, трудно сказать, кто что раньше сделал.
[18:07.000 --> 18:18.000]  Итак, по поводу этих определений, определения сходимости, давайте обозначим у большой от Тау
[18:18.000 --> 18:24.000]  точное решение дифференциального уравнения, у малой от Тау решение разностного уравнения.
[18:24.000 --> 18:32.000]  Так вот говорят, что решение разностного уравнения сходится к решению исходного дифференциального уравнения.
[18:32.000 --> 18:42.000]  Если у большой от Тау минус у малой от Тау по норме стремится к нулю, при Тау стремящимся к нулю,
[18:42.000 --> 18:51.000]  то есть при измельчении шага нашей сетки, то есть такая асимптотическая сходимость.
[18:51.000 --> 18:59.000]  Второе, это определение хорошее, но у него есть один недостаток.
[18:59.000 --> 19:08.000]  Сейчас скажу, причем если имеет место быть вот такое неравенство, то есть норма этой разности меньше,
[19:08.000 --> 19:18.000]  чем С на Тау в степени П, где С не есть константа, зависящая от Тау,
[19:18.000 --> 19:23.000]  причем при умолчании я буду считать, что С порядка у большой от единицы.
[19:23.000 --> 19:27.000]  То есть это не небольшое, не малое число, порядка у большой от единицы.
[19:27.000 --> 19:37.000]  То говорят, что сходимость имеет порядок П.
[19:37.000 --> 19:42.000]  Это определение сходимости, но минус у него какой?
[19:42.000 --> 19:50.000]  К сожалению, для того, чтобы доказать сходимость, нужно знать точное решение как дифференциального уровня, так и разностного.
[19:50.000 --> 19:56.000]  Что решает смысл исследования лобового сходимости?
[19:56.000 --> 20:01.000]  Есть такие ситуации, но они имеют методический характер.
[20:01.000 --> 20:04.000]  Я, наверное, приведу, если будет время, такую ситуацию.
[20:04.000 --> 20:08.000]  Реально для того, чтобы исследовать сходимость, используются два важнейших определения.
[20:08.000 --> 20:12.000]  Первое, определение так называемой аппроксимации.
[20:12.000 --> 20:15.000]  Ведем понятие невязки R-tau.
[20:15.000 --> 20:23.000]  Это ставим в разностный оператор точное решение дифференциального уравнения у большое.
[20:23.000 --> 20:31.000]  Естественно, этот R-tau не должно быть ровно улю, поскольку у Тау это решение дифференциального уравнения, а не разностного.
[20:31.000 --> 20:36.000]  Как вот мы говорим, что разностная задача аппроксимирует дифференциального,
[20:36.000 --> 20:45.000]  если норма R-tau стремится к нулю при Тау, стремящемся к нулю.
[20:45.000 --> 20:50.000]  То есть невязка тоже должна стремиться к нулю при измельчении шага.
[20:50.000 --> 20:59.000]  При этом, если имеет место вот такое неравенство R-tau меньше или равно c1 на Тау в степени P,
[20:59.000 --> 21:07.000]  мы говорим об аппроксимации по этому порядку.
[21:07.000 --> 21:14.000]  Чуть позже мы покажем, что порядок сходимости и порядок аппроксимации просто равный.
[21:14.000 --> 21:20.000]  И третье важнейшее определение – определение устойчивости.
[21:20.000 --> 21:23.000]  Устойчивость – это фундаментальное понятие.
[21:23.000 --> 21:27.000]  И в теории разностных схем я вообще говорил о всех вычислительных методах.
[21:27.000 --> 21:34.000]  На самом деле я вам давал как-то определение корректности по Домару, я его буду вспоминать.
[21:34.000 --> 21:37.000]  Итак, будем говорить об устойчивости.
[21:37.000 --> 21:41.000]  Мы будем говорить, что разностная задача устойчива,
[21:41.000 --> 21:52.000]  если из двух близких уравнений, сейчас я объясню, что такое близкие уравнения,
[21:52.000 --> 22:00.000]  вот такого вида, это два разностных уравнения,
[22:00.000 --> 22:10.000]  следует мне равниться у Тау по норме минус В Тау меньше или равно c2,
[22:10.000 --> 22:16.000]  c2 – это уже константа независящая от Тау, вот шага порядка у большого это единица,
[22:16.000 --> 22:24.000]  здесь кси Тау плюс это Тау, сейчас объясню ситуацию.
[22:24.000 --> 22:28.000]  Почему я назвал эти два уравнения близкими?
[22:28.000 --> 22:32.000]  Потому что кси Тау и это Тау – это возмущение правых частей.
[22:32.000 --> 22:40.000]  Они, как правило, малые величины по сравнению с абсолютными величинами правых частей.
[22:40.000 --> 22:43.000]  То есть кси Тау и это Тау – это возмущение.
[22:43.000 --> 22:47.000]  Поэтому эти два уравнения близкие, но не одинаковые.
[22:47.000 --> 22:51.000]  Что означает это неразрешство?
[22:51.000 --> 22:55.000]  Это есть не что иное, как...
[23:01.000 --> 23:08.000]  Что означает, что при малых изменениях правых частей и начальных данных,
[23:08.000 --> 23:13.000]  в f входят начальные данные, решения будут меняться так же мало.
[23:13.000 --> 23:17.000]  То есть это есть равномерная непрерывная зависимость решений по правым частям.
[23:17.000 --> 23:21.000]  А равномерно означает, что c2 не зависит от Тау.
[23:21.000 --> 23:24.000]  Непрерывная зависимость – вот она и есть.
[23:24.000 --> 23:28.000]  То есть при малых изменениях правых частей либо начальных данных,
[23:28.000 --> 23:31.000]  решения меняются тоже мало.
[23:31.000 --> 23:37.000]  Как некая единица, некая константа, умноженная на малое возмущение.
[23:37.000 --> 23:41.000]  Это важнейшее понятие устойчивости.
[23:41.000 --> 23:47.000]  Эти три определения дал профессор Рябенький.
[23:47.000 --> 23:54.000]  Что касается устойчивости, то Питер Лакс дал аналогичное определение,
[23:54.000 --> 23:59.000]  только назвал его определением корректности задач.
[23:59.000 --> 24:03.000]  Фактически это есть определение корректности по одомару, о котором я говорил.
[24:03.000 --> 24:07.000]  Как оно выглядит? Оно выглядит следующим образом.
[24:07.000 --> 24:12.000]  Это третье определение по Питеру Лаксу.
[24:12.000 --> 24:18.000]  Задача называется корректной. Разности задача называется корректной.
[24:18.000 --> 24:24.000]  Если решение ее существует, единственное и имеет место быть неравенство.
[24:24.000 --> 24:32.000]  Норма у Тау меньше равняется c2 на норму f Тау.
[24:32.000 --> 24:36.000]  Если вы вспомните определение корректности задачи по одомару,
[24:36.000 --> 24:40.000]  которое я давал, то фактически это оно и есть.
[24:40.000 --> 24:46.000]  Только спроецированное на разностную задачу.
[24:46.000 --> 24:52.000]  Эти два определения легко доказываются.
[24:52.000 --> 24:57.000]  Это вы сделаете в качестве упражнения.
[24:57.000 --> 25:03.000]  Это одно и то же уравнение, фактически одно и то же определение.
[25:09.000 --> 25:13.000]  Вот так оставим. Это два квадратных определения устойчивости.
[25:13.000 --> 25:20.000]  Зачем они вводятся? Ввести их пришлось, поскольку неустойчивость явления,
[25:20.000 --> 25:26.000]  которые являются очень неприятным явлением,
[25:26.000 --> 25:30.000]  это когда наши функции начинают неограниченно расти.
[25:30.000 --> 25:36.000]  Правда, есть в этом явления и положительные свойства.
[25:36.000 --> 25:40.000]  Какие положительные свойства? Если вы видите, что решение неустойчивое,
[25:40.000 --> 25:45.000]  то есть оно неограниченно растет, это означает, что вы что-то неправильно сделали.
[25:45.000 --> 25:49.000]  То ли метод плохой применили, то ли модель какая-то не такая,
[25:49.000 --> 25:53.000]  и что-то нужно менять. Хуже бывает другое,
[25:53.000 --> 26:01.000]  когда решение хорошее, гладкое и так далее, но оно неправильное.
[26:01.000 --> 26:05.000]  Такое тоже бывает в частных методах, мы об этом будем говорить.
[26:05.000 --> 26:09.000]  Поэтому чаще всего сложная задача подвергается верификации,
[26:09.000 --> 26:17.000]  валидации и так далее. Такие ситуации тоже имеют место быть.
[26:17.000 --> 26:21.000]  Поэтому в этом смысле неустойчивость имеет определенный положительный момент.
[26:21.000 --> 26:26.000]  Если она есть, значит что-то нужно менять. То ли в программе ошибка,
[26:26.000 --> 26:30.000]  то ли в алгоритме ошибка, то ли в методе, то ли в модели.
[26:30.000 --> 26:37.000]  Так вот оказывается, что если исследование на сходимость практически нереально,
[26:37.000 --> 26:42.000]  то исследование на апроксимацию и устойчивость реальны.
[26:42.000 --> 26:46.000]  Методы исследования на апроксимацию и устойчивость существуют.
[26:46.000 --> 26:50.000]  Я чуть позже о них расскажу.
[26:50.000 --> 26:55.000]  Исследование на апроксимацию, фактически это использует расложение Врия Тейлора.
[26:55.000 --> 26:58.000]  Технология довольно простая.
[26:58.000 --> 27:02.000]  Что касается устойчивости, здесь ситуация сложнее.
[27:02.000 --> 27:07.000]  Для нелинейных задач этот вопрос практически исследован.
[27:07.000 --> 27:11.000]  Для нелинейных задач устойчивость приходится доказывать
[27:11.000 --> 27:16.000]  через устойчивость соответствующих линейных задач
[27:16.000 --> 27:19.000]  с замораживанием так называемых коэффициентов.
[27:19.000 --> 27:23.000]  То есть считаешь, что нелинейные коэффициенты заморожены.
[27:23.000 --> 27:29.000]  То есть для нелинейных задач вообще говоря устойчивость – это проблемный вопрос.
[27:29.000 --> 27:34.000]  Но тем не менее, как я сказал, как это делается, работает.
[27:34.000 --> 27:38.000]  Работает и решаются очень сложные задачи.
[27:38.000 --> 27:41.000]  Об этом чуть позже я буду рассказывать.
[27:41.000 --> 27:46.000]  Теорема, о которой я сказал, теорема эквивалентности,
[27:46.000 --> 27:51.000]  она доказывается очень просто, когда четко введены эти три понятия.
[27:51.000 --> 27:57.000]  Пусть у оттау это точное решение дифференциальной задачи,
[27:57.000 --> 28:01.000]  а малое оттау – точное решение разностной задачи.
[28:01.000 --> 28:06.000]  Тогда в соответствии с определением устойчивости
[28:06.000 --> 28:12.000]  a-tau на u-большое tau минус f-tau чему равно,
[28:12.000 --> 28:17.000]  если мы в разностное уравнение ставим точное решение дифференциального?
[28:17.000 --> 28:21.000]  Это определение невязкое, просто-напросто.
[28:21.000 --> 28:23.000]  То есть это есть оттау.
[28:23.000 --> 28:28.000]  Если мы в разностный оператор ставим точное решение разностного уравнения,
[28:28.000 --> 28:33.000]  то что получим? Естественно, получим 0.
[28:33.000 --> 28:41.000]  Из определения устойчивости следует, что из этих двух близких уравнений
[28:41.000 --> 28:48.000]  норма разности u-большое tau минус u- малое tau меньше или равна
[28:48.000 --> 28:52.000]  некой константе С2, которая тоже не зависит от tau,
[28:52.000 --> 28:58.000]  как мы говорили, на норму невязки r-tau.
[28:58.000 --> 29:02.000]  Норма невязки, если вы помните, она тоже меньше или равна
[29:02.000 --> 29:09.000]  С1 на tau в степени p, то есть это будет С1 на С2 на tau в степени p.
[29:09.000 --> 29:12.000]  Вот всё доказательство. Доказательство прямо следует
[29:12.000 --> 29:16.000]  из определений этих понятий сходимости о проснимации устойчивости.
[29:16.000 --> 29:19.000]  Но это очень такая важная теорема.
[29:19.000 --> 29:24.000]  Она обосновывает многие наши дальнейшие действия.
[29:24.000 --> 29:29.000]  Эта теорема, которую правильно называть теоремой Рябникова-Лакс.
[29:38.000 --> 29:41.000]  То есть исследование на сходимость мы сводим к исследованию
[29:41.000 --> 29:44.000]  на опроксимацию и устойчивость.
[29:45.000 --> 29:48.000]  Это важный момент.
[29:48.000 --> 29:52.000]  Как это конкретно делается чуть позже.
[29:52.000 --> 30:00.000]  Сейчас мы можем построить схемы для решения дифференциального уравнения.
[30:00.000 --> 30:03.000]  В данном случае обыкновенное дифференциальное уравнение
[30:03.000 --> 30:06.000]  и для задачи каши.
[30:06.000 --> 30:08.000]  Да, конечно.
[30:13.000 --> 30:16.000]  В данном случае, да.
[30:16.000 --> 30:21.000]  То есть невязкое тоже, как правило, малое число.
[30:21.000 --> 30:24.000]  То есть не у большего это единица.
[30:24.000 --> 30:28.000]  И в определении устойчивости кси, и это малое возмущение.
[30:28.000 --> 30:32.000]  И невязкое тоже, я считаю, малое число.
[30:33.000 --> 30:38.000]  Одну раз эту схему Эллера я вам привел.
[30:38.000 --> 30:41.000]  Эта схема называется явный метод Эллера.
[30:41.000 --> 30:44.000]  Явный, потому что в правой части, как я говорил,
[30:44.000 --> 30:46.000]  все величины нам известны.
[30:46.000 --> 30:49.000]  Теперь неявный метод Эллера.
[30:49.000 --> 30:56.000]  Он очень похож на явный, но в правой части стоят величины.
[30:56.000 --> 30:59.000]  Значит, n плюс 1 это нам известно,
[30:59.000 --> 31:03.000]  а вот n плюс 1 это величина нам неизвестна.
[31:03.000 --> 31:07.000]  Ну и начальная данность, данная, естественно, А.
[31:07.000 --> 31:11.000]  Зачем нужны неявные схемы, зачем мы усложняем себе жизнь,
[31:11.000 --> 31:13.000]  я чуть позже расскажу.
[31:13.000 --> 31:17.000]  Есть целый класс задач, которые называются жесткие задачи,
[31:17.000 --> 31:22.000]  для которых используется, как правило, именно неявная схема.
[31:22.000 --> 31:25.000]  Именно неявная схема.
[31:25.000 --> 31:30.000]  Но чтобы решить вот такую задачу в каждом момент времени tn,
[31:30.000 --> 31:32.000]  что нужно сделать?
[31:32.000 --> 31:36.000]  То есть в каждом момент времени tn решается нелинейные уравнения,
[31:36.000 --> 31:38.000]  либо системы нелинейных уравнений.
[31:38.000 --> 31:41.000]  Как их решать, мы с вами говорили,
[31:41.000 --> 31:43.000]  и я рассказывать не буду.
[31:43.000 --> 31:46.000]  Это либо метод простыхиатарации, либо метод Ньютона.
[31:46.000 --> 31:48.000]  Лучше, конечно, метод Ньютона.
[31:48.000 --> 31:51.000]  И на каждом шаге решается,
[31:51.000 --> 31:58.000]  на каждом шаге по tn, t1 и так далее решается очень нелинейное уравнение.
[31:58.000 --> 32:00.000]  Следующий пример.
[32:00.000 --> 32:02.000]  Мы можем поднять...
[32:02.000 --> 32:04.000]  Ну, здесь тоже схема первого порядка,
[32:04.000 --> 32:07.000]  надо сказать, конечно, грубовато,
[32:07.000 --> 32:11.000]  но здесь важно, что пример неявной схемы.
[32:11.000 --> 32:14.000]  Можно поднять порядок опроксимации,
[32:14.000 --> 32:18.000]  например, опроксимировав первого производного вот таким образом.
[32:18.000 --> 32:22.000]  ОН плюс один, минус ОН, минус один, делим на два тау,
[32:22.000 --> 32:27.000]  и равняется f от tn ОН.
[32:27.000 --> 32:30.000]  Здесь мы сталкиваемся с ситуацией,
[32:30.000 --> 32:35.000]  которая называется формальным несовпадением порядков дифференциального и разностного уравнения.
[32:35.000 --> 32:38.000]  То есть дифференциальное уравнение имеет первый порядок,
[32:38.000 --> 32:42.000]  а разностное уравнение, второй порядок точности, имеет.
[32:42.000 --> 32:46.000]  Более того, у нас есть только одно начальное условие.
[32:47.000 --> 32:51.000]  Если одно условие, мы не сможем оттолкнуться от него,
[32:51.000 --> 32:53.000]  чтобы решать дальше задачи.
[32:53.000 --> 32:55.000]  Поскольку есть ОН плюс один,
[32:55.000 --> 32:57.000]  что нужно сделать?
[32:57.000 --> 33:00.000]  Нужна еще одна точка, например, у1.
[33:00.000 --> 33:05.000]  Здесь у нас точка у0 дана, равняется А.
[33:05.000 --> 33:09.000]  Но нужно еще определить точку, например, у1 каким-то образом.
[33:09.000 --> 33:11.000]  Как ее определить?
[33:11.000 --> 33:15.000]  Ну, например, можно сделать следующее.
[33:15.000 --> 33:23.000]  В начале момента времени провести аппроксимацию первой производы следующим образом,
[33:23.000 --> 33:39.000]  а дальше использовать следующую аппроксимацию правой части f от t0 У0 плюс f от t1 У1.
[33:39.000 --> 33:45.000]  Вот такая аппроксимация в нулевой точке будет иметь второй порядок.
[33:45.000 --> 33:53.000]  Тогда будет совпадать порядок и аппроксимации начальных данных, и самого уравнения.
[33:53.000 --> 33:57.000]  Это довольно известный прием.
[33:57.000 --> 33:59.000]  Мы можем поднимать дальше порядок уравнения,
[33:59.000 --> 34:03.000]  поднимая порядок аппроксимации производных.
[34:04.000 --> 34:08.000]  Это один из вариантов.
[34:08.000 --> 34:12.000]  Я вам привел простейшую схему.
[34:12.000 --> 34:16.000]  Идем дальше.
[34:16.000 --> 34:18.000]  Это звонок, да?
[34:18.000 --> 34:20.000]  Или не звонок?
[34:25.000 --> 34:28.000]  Немного попозже начали, потому что ничего страшного.
[34:28.000 --> 34:31.000]  Идем дальше.
[34:31.000 --> 34:38.000]  Как можно еще аппроксимировать уравнение?
[34:38.000 --> 34:41.000]  Ну, например, так.
[34:41.000 --> 34:45.000]  Из дифференциального уравнения, я его просто уже много раз писал,
[34:45.000 --> 34:49.000]  мы можем выписать очевидное равенство.
[34:49.000 --> 34:53.000]  Пусть нам известно решение в точке tn,
[34:53.000 --> 34:57.000]  и мы хотим определить решение в точке у tn плюс t0.
[34:57.000 --> 35:03.000]  Это будет у tn плюс интеграл.
[35:03.000 --> 35:07.000]  Вот tn, здесь tn плюс t0.
[35:07.000 --> 35:11.000]  У штрих здесь кси, на D кси.
[35:11.000 --> 35:15.000]  Кси – это некая независимая переменная, новая.
[35:15.000 --> 35:18.000]  Это прямо из дифференциального уравнения следует.
[35:18.000 --> 35:22.000]  Вы это много раз делали, такие вещи, в прошлом году.
[35:22.000 --> 35:28.000]  Что нам нужно для того, чтобы построить разностную схему?
[35:28.000 --> 35:30.000]  Нам нужно аппроксимировать интеграл.
[35:30.000 --> 35:33.000]  О чем шла речь на прошлой лекции.
[35:33.000 --> 35:36.000]  Аппроксимировать интеграл.
[35:36.000 --> 35:38.000]  Как его можно аппроксимировать?
[35:38.000 --> 35:44.000]  Методы аппроксимации интегралов вам рассказывали.
[35:44.000 --> 35:46.000]  Давайте возьмем простейший метод.
[35:46.000 --> 35:49.000]  Самый грубый – метод прямоугольников.
[35:49.000 --> 35:53.000]  Давайте, чтобы меньше писать, обозначим.
[35:53.000 --> 35:57.000]  Вот это неизвестно, уn плюс 1.
[35:57.000 --> 35:59.000]  Это уn.
[35:59.000 --> 36:13.000]  Когда будет уn плюс 1, равняется уn плюс tau на u штрих в точке tn плюс o.
[36:13.000 --> 36:18.000]  Вот это есть аппроксимация интегралов по методу прямоугольников.
[36:18.000 --> 36:23.000]  Ну, левых прямоугольников, в данном случае.
[36:23.000 --> 36:25.000]  Что мы получим?
[36:25.000 --> 36:29.000]  Если мы пренебрежем малыми второго порядка,
[36:29.000 --> 36:35.000]  то мы получаем нашу любимую схему Эдера.
[36:35.000 --> 36:38.000]  Вот она.
[36:38.000 --> 36:41.000]  Мы получили схему Эдера.
[36:41.000 --> 36:43.000]  Приблизим интеграл.
[36:43.000 --> 36:46.000]  Это тоже самый грубый метод прямоугольников.
[36:46.000 --> 36:50.000]  Он тоже используется, как правило, для учебно-методических целей.
[36:50.000 --> 36:53.000]  Конечно, интегралы вернутся более высокими порядками.
[36:53.000 --> 36:58.000]  В форму Симсонова слышали, наверное, и так далее.
[36:58.000 --> 37:06.000]  Но можно интеграл взять число и другими способами, и другими методами.
[37:06.000 --> 37:10.000]  Например, методом трапеции.
[37:10.000 --> 37:12.000]  Тогда будет у нас следующее, уn плюс 1.
[37:12.000 --> 37:17.000]  Это есть уn плюс tau пополам.
[37:17.000 --> 37:31.000]  А здесь f от tn уn плюс f от tn плюс 1 уn плюс 1.
[37:31.000 --> 37:33.000]  Ну, пренебрегаем опять же малыми.
[37:33.000 --> 37:36.000]  Здесь, конечно, нужно поставить o большой от tau в кубе.
[37:36.000 --> 37:40.000]  Но метод трапеции будет иметь уже второй порядок точности.
[37:40.000 --> 37:43.000]  Более высокий второй порядок точности.
[37:43.000 --> 37:46.000]  Но можно еще использовать...
[37:46.000 --> 37:47.000]  Еще один пример.
[37:47.000 --> 37:50.000]  Можно использовать много методов аппроксимации интеграла.
[37:50.000 --> 37:54.000]  И зависит от квадратурной формулы взятия интеграла.
[37:54.000 --> 37:56.000]  Мы получаем разные числи методы.
[37:56.000 --> 38:00.000]  Это вот такой стандартный подход.
[38:00.000 --> 38:02.000]  Далее уn плюс 1.
[38:02.000 --> 38:05.000]  Если мы берем интеграл по формуле средних,
[38:05.000 --> 38:18.000]  это будет ун плюс tau на f от tn плюс 1 вторая ун плюс 1 вторая.
[38:18.000 --> 38:23.000]  Разумеется, здесь тоже нужно поставить o большой от tau в кубе.
[38:23.000 --> 38:31.000]  Но мы этими методами пренебрегаем и получаем разные схемы.
[38:31.000 --> 38:36.000]  Эта схема называется неявный метод трапеции,
[38:36.000 --> 38:39.000]  а этот неявный метод средних.
[38:39.000 --> 38:41.000]  Это методы оба неявные.
[38:41.000 --> 38:45.000]  Но можно делать и явные методы.
[38:45.000 --> 38:48.000]  Теперь идем дальше.
[38:48.000 --> 38:54.000]  Причем идти дальше, я обещал всегда давать продвинутую литературу
[38:54.000 --> 38:56.000]  по каждой теме.
[38:56.000 --> 39:07.000]  Поскольку каждая тема очень-очень важна в вашей жизни в дальнейшей.
[39:07.000 --> 39:15.000]  Я вам приведу пример самого подробной книги
[39:15.000 --> 39:21.000]  по числям методам решения дифференциальных уравнений.
[39:21.000 --> 39:24.000]  Это книга немецких математиков.
[39:44.000 --> 39:49.000]  Название книги «Решение обыкновенных дифференциальных уравнений».
[39:50.000 --> 39:54.000]  Давайте я сокращенно напишу обыкновенных дифференциальных уравнений.
[39:54.000 --> 40:00.000]  Книга полностью называется «Ordinary differential equations».
[40:00.000 --> 40:04.000]  Нежесткие задачи – это важно.
[40:12.000 --> 40:18.000]  В книге очень подробно изложены и методы, и их получение.
[40:18.000 --> 40:21.000]  Что касается нежестких задач,
[40:21.000 --> 40:27.000]  здесь центральным классом методов являются методы Рунге Кутэ.
[40:27.000 --> 40:31.000]  Это немецкая математика, которая в конце XIX века
[40:31.000 --> 40:36.000]  предложила методы повышенного порядка точности.
[40:36.000 --> 40:41.000]  И в конце концов, с помощью других исследователей математиков
[40:41.000 --> 40:48.000]  Эти методы выросли до больших величин порядка сходимости.
[40:48.000 --> 40:54.000]  В дифференциальных уравнениях одна переменная,
[40:54.000 --> 41:00.000]  численность методов нередко решает с точностью близко к машинной.
[41:00.000 --> 41:03.000]  Для одной переменной это допустимо.
[41:03.000 --> 41:06.000]  Когда мы имеем несколько переменных, скажем, четыре,
[41:06.000 --> 41:09.000]  как в уравнениях частно-производных, это сложнее.
[41:09.000 --> 41:12.000]  Там приходится, конечно, суперкомпьютерное вычисление применять.
[41:12.000 --> 41:17.000]  Хотя здесь тоже есть примеры системы уравнений высокого порядка,
[41:17.000 --> 41:25.000]  когда тоже решается система уравнений обыкновенных с помощью суперкомпьютеров.
[41:25.000 --> 41:28.000]  Например, задача молекулярной динамики.
[41:28.000 --> 41:30.000]  Самый яркий пример.
[41:30.000 --> 41:33.000]  Там система уравнений высокого порядка,
[41:33.000 --> 41:35.000]  и там как раз всплываются активные суперкомпьютеры.
[41:35.000 --> 41:45.000]  Так вот Рунге предложил записать методы численной или разницы схемы в общей форме.
[41:45.000 --> 41:47.000]  Она выглядит следующим образом.
[41:47.000 --> 41:54.000]  Оn плюс 1 – это есть Оn плюс там умножить на вот такую сумму.
[41:54.000 --> 42:01.000]  d it на k it и от единицы до r.
[42:01.000 --> 42:04.000]  Это пока вроде бы не совсем понятно.
[42:04.000 --> 42:11.000]  На самом деле это есть к решению Оn, которую мы знаем на n-м слой.
[42:11.000 --> 42:17.000]  Добавляем, слой по времени – это тоже такое стандартное выражение.
[42:17.000 --> 42:20.000]  Добавляем вот такой добавочек.
[42:20.000 --> 42:24.000]  Давайте его обозначим d it.
[42:24.000 --> 42:31.000]  d it здесь числовые коэффициенты, которые определяют нашу схему.
[42:31.000 --> 42:34.000]  Не только они есть, будут еще числовые коэффициенты.
[42:34.000 --> 42:43.000]  k it – это правые части, пересчитанные в разных точках нашей схемы.
[42:43.000 --> 42:50.000]  В частности, здесь я написал общее выражение для методов Рунге-кута, явных и не ядов.
[42:50.000 --> 42:55.000]  Сейчас я пишу выражение для k it, для явных методов Рунге-кута.
[42:55.000 --> 42:59.000]  k1 – это просто есть tn Оn.
[42:59.000 --> 43:05.000]  Сразу понятно, что если d it – это единичка, а k it – это то, что я написал.
[43:05.000 --> 43:09.000]  Что будет, какой метод – мет тейнер.
[43:09.000 --> 43:10.000]  Ну и так далее.
[43:10.000 --> 43:15.000]  k2 напишем следующим образом.
[43:15.000 --> 43:26.000]  tn плюс альфа 2 тау Он плюс тау бета 2.1 на k1.
[43:26.000 --> 43:31.000]  Значит, бета 2.1 – это тоже боежитые коэффициенты Рунге-кута.
[43:31.000 --> 43:35.000]  Они тоже, как и d it, определяют конкретный метод.
[43:35.000 --> 43:37.000]  А это их общая запись.
[43:37.000 --> 43:41.000]  Альфа 2 – тоже коэффициенты Рунге-кута, которые определяют метод.
[43:41.000 --> 43:45.000]  Ну и вы видите, что коэффициенты вычисляются рекуррентным образом.
[43:45.000 --> 43:50.000]  То есть, сначала k1 вычисляем, потом по k1, k2 и так далее.
[43:50.000 --> 43:56.000]  Если мы хотим написать kr, это будет f.
[43:56.000 --> 44:04.000]  tn плюс альфа r тау Ун плюс тау.
[44:04.000 --> 44:07.000]  Ну и здесь сумма коэффициентов.
[44:07.000 --> 44:20.000]  r1 k1 плюс бета r2 на k2 плюс многоточие бета rr1 на krr1.
[44:20.000 --> 44:25.000]  Здесь не пугайтесь виду этого записи в форме Рунге.
[44:25.000 --> 44:31.000]  На самом деле эти коэффициенты все определяются.
[44:31.000 --> 44:36.000]  Я приведу простой пример, как это делается.
[44:42.000 --> 44:44.000]  Следующий момент.
[44:44.000 --> 44:51.000]  Математик Бутчер предложил эти методы Рунге-кута записывать,
[44:51.000 --> 44:54.000]  точнее, коэффициенты медов в виде таблицы,
[44:54.000 --> 44:57.000]  которую получили, назвали таблицу Бутчерга.
[44:57.000 --> 45:00.000]  Это не матрица, это таблица.
[45:00.000 --> 45:04.000]  Вот здесь коэффициенты альфа.
[45:04.000 --> 45:06.000]  Так, здесь один важный момент.
[45:06.000 --> 45:08.000]  Что такое r?
[45:08.000 --> 45:12.000]  r – это называется количество стадий методов Рунге-кута.
[45:12.000 --> 45:15.000]  Значит, r раз мы пересчитываем правую часть.
[45:15.000 --> 45:20.000]  Потому что все каиты – это есть не что иное, как пересчет правых частей.
[45:20.000 --> 45:22.000]  Значит, r раз мы их пересчитываем.
[45:22.000 --> 45:25.000]  Это r – стадийный метод.
[45:25.000 --> 45:27.000]  Будут еще многошаговые методы.
[45:27.000 --> 45:30.000]  Значит, методы Рунге-кута – это многостадийные методы.
[45:30.000 --> 45:33.000]  Будут еще меды атмоса многошаговые.
[45:33.000 --> 45:35.000]  Здесь нужно не путать.
[45:35.000 --> 45:37.000]  Пока мы говорим о Рунге-кутах.
[45:37.000 --> 45:40.000]  Так, здесь у нас будет β2,1,
[45:40.000 --> 45:42.000]  β3,1,
[45:42.000 --> 45:44.000]  β3,2,
[45:44.000 --> 45:46.000]  ну и так далее.
[45:46.000 --> 45:48.000]  βr,1,
[45:48.000 --> 45:50.000]  βr2,
[45:50.000 --> 45:52.000]  и так далее, βr,
[45:52.000 --> 45:54.000]  r-1,
[45:54.000 --> 45:56.000]  ну и внизу d1,
[45:56.000 --> 45:58.000]  d2,
[45:58.000 --> 46:00.000]  и так далее, dr.
[46:00.000 --> 46:03.000]  То есть вот с такой таблицой вмосятся коэффициенты
[46:03.000 --> 46:06.000]  конкретных методов Рунге-кута,
[46:06.000 --> 46:09.000]  и получаем конкретный метод.
[46:09.000 --> 46:12.000]  Ну, пример давайте какой-нибудь простой приведу.
[46:12.000 --> 46:15.000]  Например, тот же наш любимый мио-тейлер.
[46:15.000 --> 46:17.000]  Как выглядит для него таблица Бутчера?
[46:17.000 --> 46:20.000]  Очень прекрасно выглядит.
[46:20.000 --> 46:24.000]  Вот таблица Бутчера для методейлера.
[46:24.000 --> 46:26.000]  3 числа.
[46:26.000 --> 46:28.000]  3 числа.
[46:28.000 --> 46:30.000]  Метод средних.
[46:30.000 --> 46:32.000]  Если я буду писать.
[46:32.000 --> 46:34.000]  0,0,
[46:34.000 --> 46:36.000]  1,2,
[46:36.000 --> 46:38.000]  1,2,
[46:38.000 --> 46:40.000]  и здесь вот 0,1.
[46:40.000 --> 46:42.000]  Это для методов средних.
[46:42.000 --> 46:44.000]  Ну и так далее.
[46:44.000 --> 46:47.000]  Здесь я все выписывать не буду.
[46:47.000 --> 46:49.000]  Как вы догадываетесь,
[46:49.000 --> 46:51.000]  невероятное количество.
[46:51.000 --> 46:54.000]  Здесь лучше обратиться к книгам,
[46:54.000 --> 46:56.000]  к справочникам.
[46:56.000 --> 46:58.000]  Справочник, конечно, таблицы Бутчера есть,
[46:58.000 --> 47:01.000]  но если говорить о той книге, которую я привел,
[47:01.000 --> 47:03.000]  там, конечно, приводится
[47:03.000 --> 47:06.000]  очень большое количество именно тех методов,
[47:06.000 --> 47:09.000]  которые практически люди используют.
[47:09.000 --> 47:11.000]  И таблица Бутчера для них, и так далее.
[47:11.000 --> 47:16.000]  Это то, что касается методов явных.
[47:16.000 --> 47:19.000]  Есть еще неявные методы Рунге-Куте.
[47:19.000 --> 47:21.000]  Для них, на самом деле,
[47:21.000 --> 47:23.000]  верхняя строчка справедлива.
[47:23.000 --> 47:26.000]  Они так и выписываются в виде верхней строчки.
[47:26.000 --> 47:28.000]  А вот коэффициенты,
[47:28.000 --> 47:30.000]  это коэффициенты Рунге,
[47:30.000 --> 47:33.000]  Каи-Те, их так называют,
[47:33.000 --> 47:35.000]  выглядят по-другому.
[47:35.000 --> 47:38.000]  Например, K1 это есть
[47:38.000 --> 47:43.000]  f от tn плюс α1 tau,
[47:43.000 --> 47:46.000]  здесь on плюс tau,
[47:46.000 --> 47:50.000]  β1,1,k1,
[47:50.000 --> 47:55.000]  плюс β1,2,k2,
[47:55.000 --> 47:58.000]  ну, плюс многоточие,
[47:58.000 --> 48:04.000]  β1,r,k,kr.
[48:04.000 --> 48:09.000]  То есть здесь вся таблица выписывается.
[48:09.000 --> 48:12.000]  Все коэффициенты в каждом уравнении выписываются.
[48:12.000 --> 48:16.000]  Многоточие, если я поставлю последний коэффициент,
[48:16.000 --> 48:23.000]  kr, это будет f от tn плюс αr tau,
[48:23.000 --> 48:26.000]  здесь on плюс tau,
[48:26.000 --> 48:30.000]  на β,r,1,k1,
[48:30.000 --> 48:34.000]  плюс β,r,2,k2,
[48:34.000 --> 48:36.000]  плюс многоточие,
[48:36.000 --> 48:42.000]  β,r,r,k,r,
[48:42.000 --> 48:45.000]  β,r,r,k,r.
[48:45.000 --> 48:48.000]  Так, здесь надо скобочку давайте закроем,
[48:48.000 --> 48:51.000]  ну, а здесь сделаю скобку квадратную.
[48:51.000 --> 48:53.000]  Так будет более правильно,
[48:53.000 --> 48:55.000]  квадратную скобку.
[48:55.000 --> 48:58.000]  То есть здесь выписывается
[48:58.000 --> 49:00.000]  вся таблица Бутчера,
[49:00.000 --> 49:02.000]  которая, конечно же, будет выглядеть по-другому.
[49:02.000 --> 49:05.000]  α0, α1, αr,
[49:05.000 --> 49:10.000]  здесь у нас будет d1, d2, dr
[49:10.000 --> 49:14.000]  и коэффициенты b и житы b1,1.
[49:14.000 --> 49:18.000]  Так давайте получше напишу b1,1 многоточие,
[49:18.000 --> 49:20.000]  b1,r.
[49:20.000 --> 49:25.000]  Так, здесь не α0, давайте α1, альфа2, альфаr.
[49:25.000 --> 49:27.000]  Давайте не с 0, а с 1 начнем.
[49:27.000 --> 49:32.000]  2,1, β,2,1 многоточие,
[49:32.000 --> 49:34.000]  β,2,r.
[49:34.000 --> 49:36.000]  Ну и последняя строчка,
[49:36.000 --> 49:41.000]  β,r,1, β,r,r.
[49:41.000 --> 49:43.000]  То есть заполняя вот это таблицу конкретными числами,
[49:43.000 --> 49:45.000]  мы получаем конкретные числа метод.
[49:45.000 --> 49:48.000]  Ну, в той книге, разумеется,
[49:48.000 --> 49:51.000]  не может быть разговора, чтобы я все эти методы получал
[49:51.000 --> 49:55.000]  по, скажем, десятому порядку аппроксимации.
[49:55.000 --> 49:58.000]  На это уйдет, наверное, весь семестр.
[49:58.000 --> 50:01.000]  Но вот в целом ряде книг,
[50:01.000 --> 50:03.000]  вот особенно в той, которую я привел,
[50:03.000 --> 50:06.000]  приведены очень много полезных таблиц Бутчера,
[50:06.000 --> 50:08.000]  как раз методов, которые работают,
[50:08.000 --> 50:10.000]  которые работают в реальной жизни.
[50:10.000 --> 50:14.000]  Конечно же, методомеддер в реальной задаче не считается.
[50:14.000 --> 50:16.000]  Он используется, как я сказал, в учебнометодических целях
[50:16.000 --> 50:19.000]  либо как конструкционный элемент для построения метода
[50:19.000 --> 50:21.000]  высокого порядка точности.
[50:21.000 --> 50:25.000]  Сейчас совершенно нормально считаются методы
[50:25.000 --> 50:27.000]  шестого, седьмого, седьмого, восьмого порядка точности.
[50:27.000 --> 50:29.000]  Вот такие.
[50:29.000 --> 50:32.000]  Ну, в общем, до десятого, на самом деле.
[50:32.000 --> 50:35.000]  Вот есть методы еще более высокого порядка точности.
[50:35.000 --> 50:38.000]  Но там вопрос в том, что там точность такая,
[50:38.000 --> 50:41.000]  что она уже начинает превышать машину,
[50:41.000 --> 50:44.000]  а это уже... зачем это надо?
[50:44.000 --> 50:48.000]  Выше машины точности уже особого смысла нет.
[50:48.000 --> 50:51.000]  Конечно, там есть double precision и так далее.
[50:51.000 --> 50:55.000]  Это специалисты конструктором машины все уточняют.
[50:55.000 --> 50:58.000]  Разрядность машин.
[50:58.000 --> 51:01.000]  Ну, до бесконечности это нельзя сделать.
[51:01.000 --> 51:05.000]  Хотя точность, конечно, сейчас очень высока.
[51:05.000 --> 51:07.000]  Очень высока расчет.
[51:07.000 --> 51:10.000]  Ну, вот это то, что касается методов Ронгекута.
[51:10.000 --> 51:12.000]  Ну, как их получать?
[51:12.000 --> 51:14.000]  Ну, давайте я один пример приведу простой.
[51:14.000 --> 51:16.000]  Как можно получить, например,
[51:16.000 --> 51:19.000]  метод первого порядка Ронгекута,
[51:19.000 --> 51:22.000]  поскольку если взяться за метод второго порядка,
[51:22.000 --> 51:24.000]  то на это уйдет половина лекций.
[51:24.000 --> 51:27.000]  Ну, разумеется, вот в книгах он описан.
[51:27.000 --> 51:31.000]  И вот в книге Харри ранее что-то Видера тоже описан.
[51:31.000 --> 51:34.000]  В моих учебниках это описано, как делается.
[51:34.000 --> 51:37.000]  Значит, вводится функция такая.
[51:37.000 --> 51:42.000]  Огрешность у от tn плюс tau.
[51:43.000 --> 51:50.000]  Конечно, минус у от tn плюс.
[51:50.000 --> 51:55.000]  То есть это как раз функция дельта Ронги.
[51:55.000 --> 51:59.000]  Tau на d и tk и t.
[51:59.000 --> 52:03.000]  И от единицы до r.
[52:03.000 --> 52:08.000]  То есть мы считаем, что мы знаем решение на n-ов слое.
[52:08.000 --> 52:10.000]  Хотим получить решение на n-ов слое.
[52:10.000 --> 52:13.000]  Вот это решение, которое должно получиться.
[52:13.000 --> 52:15.000]  То есть это правильное решение.
[52:15.000 --> 52:19.000]  Ну и их разность, естественно, это погрешность.
[52:19.000 --> 52:23.000]  Погрешность обычно разлагают в ряд Тейлора.
[52:23.000 --> 52:30.000]  То есть пишут, что это есть дельта i от 0 на i факториал.
[52:30.000 --> 52:32.000]  Tau в степени i.
[52:32.000 --> 52:35.000]  Ну и, естественно, от 0 до p,
[52:35.000 --> 52:39.000]  где p – это порядок точности нашего метода i.
[52:39.000 --> 52:41.000]  Осадочный член.
[52:41.000 --> 52:46.000]  Осадочный член – это будет, что дельта p плюс 1.
[52:46.000 --> 52:48.000]  Здесь θ, tau.
[52:48.000 --> 52:53.000]  Где tau сразу заметим от 0 до 1 меняется.
[52:53.000 --> 52:58.000]  Вот внизу p плюс 1 факториал.
[52:58.000 --> 53:01.000]  И tau в степени p плюс 1.
[53:01.000 --> 53:04.000]  То есть вот это осадочный член.
[53:04.000 --> 53:06.000]  Он очень важен.
[53:06.000 --> 53:09.000]  Важен потому, как Ронг предположил,
[53:09.000 --> 53:13.000]  что все эти элементы ряда Тейлор должны быть равны 0.
[53:13.000 --> 53:17.000]  И это есть исходная система уравнений.
[53:17.000 --> 53:19.000]  p – уравнение.
[53:19.000 --> 53:23.000]  То есть каков порядок, столько и уравнений.
[53:23.000 --> 53:30.000]  Пусть у нас в предстоящем случае порядок равен 1,
[53:30.000 --> 53:33.000]  количество стадий равно 1.
[53:33.000 --> 53:36.000]  Как будет выглядеть верхняя строчка?
[53:36.000 --> 53:39.000]  Дельта tau – это что будет у нас?
[53:39.000 --> 53:43.000]  u tn плюс tau,
[53:43.000 --> 53:47.000]  минус u tn
[53:47.000 --> 53:54.000]  и минус tau на d1 на k1.
[53:54.000 --> 53:59.000]  Итак, все дельты производные от 0.
[53:59.000 --> 54:01.000]  Дельта от 0 тоже.
[54:01.000 --> 54:05.000]  Ну дельта от 0 – 0 это сразу видно.
[54:05.000 --> 54:07.000]  Пусть теперь будет первая производная.
[54:07.000 --> 54:09.000]  Дельта штрих от 0.
[54:09.000 --> 54:10.000]  Что это будет?
[54:10.000 --> 54:15.000]  Это будет u штрих минус d1 на k1.
[54:15.000 --> 54:19.000]  u штрих и k1 – это есть не что иное, как f.
[54:19.000 --> 54:20.000]  Правая часть.
[54:20.000 --> 54:24.000]  То есть единица минус d1 на правую часть.
[54:24.000 --> 54:28.000]  И это тоже должно быть в соответствии с уважением…
[54:28.000 --> 54:30.000]  Ронге равняется 0.
[54:30.000 --> 54:34.000]  Отсюда мы получаем d1 равняется единицам.
[54:34.000 --> 54:37.000]  То есть коэффициент ронге-кота равен единицам.
[54:37.000 --> 54:39.000]  Вот так они ищутся.
[54:39.000 --> 54:44.000]  Это просто простейший пример схемы первого порядка.
[54:44.000 --> 54:47.000]  Схему второго порядка можете в том же учебнике посмотреть,
[54:47.000 --> 54:51.000]  поскольку, как я сказал, если я буду получать схему более высоких порядков,
[54:51.000 --> 54:55.000]  это полнекса уйдет, если не будешь до второго.
[54:55.000 --> 54:58.000]  В принципе, здесь ничего нет хитрого.
[54:58.000 --> 55:01.000]  Формально гибролические вычисления.
[55:01.000 --> 55:04.000]  Наверное, немецкие математики в силу своего сооружения
[55:04.000 --> 55:09.000]  очень такие люди дотошные, поэтому они решали эти системы уравнения
[55:09.000 --> 55:12.000]  до десятого порядка и выше.
[55:12.000 --> 55:18.000]  Но там действительно очень сложные системы уравнений получаются.
[55:18.000 --> 55:22.000]  Методы известны до высокого порядка.
[55:22.000 --> 55:26.000]  Впрочем, у нас есть выпускник физиологии Андрея Игоревича Толстых,
[55:26.000 --> 55:30.000]  который всех наших немецких математиков перебил.
[55:30.000 --> 55:33.000]  У него есть метод 32 порядка точности.
[55:33.000 --> 55:38.000]  Это наивысший метод порядок, который вообще неизвестен.
[55:38.000 --> 55:42.000]  Но он уже, правда, перебивает машинную точность.
[55:42.000 --> 55:45.000]  Это классик такого мирового уровня.
[55:45.000 --> 55:47.000]  Да-да?
[55:47.000 --> 55:49.000]  Есть ли какая-то связь между П и Р?
[55:49.000 --> 55:51.000]  Между чем?
[55:51.000 --> 55:53.000]  Между П и Р.
[55:53.000 --> 55:55.000]  Прекрасный вопрос.
[55:55.000 --> 55:57.000]  Прямо хочу сказать спасибо за вопрос.
[55:57.000 --> 55:59.000]  Я чуть бы не забыл это сказать.
[55:59.000 --> 56:01.000]  Связь очень важна.
[56:01.000 --> 56:03.000]  Связь очень важна.
[56:03.000 --> 56:05.000]  И почему важна?
[56:05.000 --> 56:11.000]  Потому что, как вы поняли, мед. гекута в исходном варианте имеет интерполюционный характер.
[56:11.000 --> 56:14.000]  Я брал квадратуры.
[56:14.000 --> 56:16.000]  А квадратуры – это что?
[56:16.000 --> 56:20.000]  Если формула Ньютона-Котеса – это интерполюционная формула.
[56:20.000 --> 56:22.000]  Формулу Гауса я не находил.
[56:22.000 --> 56:26.000]  А если интерполяция, то там есть процесс неустойчивости.
[56:26.000 --> 56:28.000]  Интерполюционный процесс.
[56:28.000 --> 56:30.000]  Поэтому он должен и здесь казаться.
[56:30.000 --> 56:32.000]  На как раз соотношениях между П и Р.
[56:32.000 --> 56:35.000]  Почему это вопрос очень-очень хороший?
[56:35.000 --> 56:37.000]  И вот что получается.
[56:37.000 --> 56:44.000]  Оказывается, вот тот же Бочер – это очень доточный такой математик,
[56:44.000 --> 56:47.000]  который именно этот вопрос и поставил.
[56:47.000 --> 56:52.000]  И доказал совершенно блестящую, но пессимистическую теорию.
[56:52.000 --> 56:54.000]  Выгодно очень коротко.
[56:54.000 --> 56:58.000]  Не существует явных мед. фронт гекута,
[56:58.000 --> 57:04.000]  не существует пятиста единних явных мед. фронт гекута пятого порядка точности.
[57:04.000 --> 57:08.000]  То есть, оказывается, П и Р совпадают до четвертого порядка.
[57:08.000 --> 57:10.000]  До цифры 4.
[57:10.000 --> 57:12.000]  А дальше ситуация такая.
[57:12.000 --> 57:22.000]  Если мы имеем Р равное 5, то порядок точности уже будет Р-1.
[57:22.000 --> 57:25.000]  И нам нужны дополнительные пересчеты правочастей.
[57:25.000 --> 57:32.000]  Если Р меняется от 5 до 7, то как раз вот это и будет.
[57:32.000 --> 57:34.000]  Я написал.
[57:34.000 --> 57:41.000]  Если Р меняется от 8 до 9, то порядок точности будет Р-2.
[57:41.000 --> 57:50.000]  Если Р меняется от 10 до 11, то порядок точности Р-3.
[57:50.000 --> 57:52.000]  Ну и так далее. Дальше писать не буду.
[57:52.000 --> 57:55.000]  Десять стадий – это уже приличное количество.
[57:55.000 --> 58:00.000]  И седьмой порядок точности – это тоже очень хороший порядок точности.
[58:00.000 --> 58:06.000]  Так что вот вопросы неустойчивости интерпретационного процесса
[58:06.000 --> 58:11.000]  Перекидываются сначала, переходят на квадратурную формулу эти проблемы,
[58:11.000 --> 58:14.000]  а с квадратурной формулой и на формулу Рунгикод.
[58:14.000 --> 58:17.000]  Вот такая ситуация интересная.
[58:17.000 --> 58:21.000]  Но тем не менее, в общем, это неприятно, но это не страшно.
[58:21.000 --> 58:24.000]  Поскольку методы можно строить тем не менее высокого порядка точности,
[58:24.000 --> 58:28.000]  да, это, так сказать, обходится в более дорого смысле машинного времени.
[58:28.000 --> 58:33.000]  Но строить их можно, эти методы.
[58:33.000 --> 58:36.000]  Пойдем дальше.
[58:36.000 --> 58:42.000]  Вот английский математик Ричардсон предложил очень хороший метод.
[58:42.000 --> 58:45.000]  Очень простой метод.
[58:45.000 --> 58:49.000]  Увеличение порядка точности на единицу.
[58:49.000 --> 58:54.000]  Ну, насколько он простой, насколько хороший, что им пользуется очень часто.
[58:54.000 --> 58:57.000]  Я так кратко изложу, в чем здесь дело.
[58:57.000 --> 59:01.000]  Положим, что у нас есть метод к этому порядку.
[59:01.000 --> 59:05.000]  В этом случае я могу написать точное решение от tn
[59:05.000 --> 59:09.000]  минус числое решение у малое tn.
[59:09.000 --> 59:17.000]  Это есть c на tau в степени p и plus o большое от tau в степени p плюс 1.
[59:17.000 --> 59:21.000]  А теперь давайте вдвое уменьшим сетку.
[59:21.000 --> 59:25.000]  Ну, давайте есть u1 поставим для определенности.
[59:25.000 --> 59:28.000]  А здесь вот уменьшили сетку вдвое u2.
[59:28.000 --> 59:31.000]  Всего-то нужно уменьшить вдвое сетку.
[59:31.000 --> 59:37.000]  И чудесно можно получать метод на единичку более высокого порядка.
[59:37.000 --> 59:43.000]  tau в степени p, 2 в степени p, plus o большое от tau в степени p плюс 1.
[59:43.000 --> 59:49.000]  Вот я записал два очевидных равенства.
[59:49.000 --> 59:53.000]  Для шага tau и для шага tau пополам.
[59:53.000 --> 59:57.000]  Теперь я из первого уравнения вычитаю второе.
[59:57.000 --> 01:00:02.000]  Отсюда нахожу c константу независящей от tau и ставлю ее во второе уравнение.
[01:00:02.000 --> 01:00:06.000]  При этом получается, я уже окончательно итог напишу,
[01:00:06.000 --> 01:00:20.000]  u от tn это минус u2 плюс u2 минус u1 делим на 2 в степени p минус 1
[01:00:20.000 --> 01:00:25.000]  равняется o большое от tau в степени p плюс 1.
[01:00:25.000 --> 01:00:27.000]  Вот что получится.
[01:00:27.000 --> 01:00:32.000]  Если вы из первого уравнения вычитаете второе, вычислите константу c и поставите во второе уравнение.
[01:00:32.000 --> 01:00:38.000]  Это школьная задача, поэтому я не буду на нее очень много внимания уделять.
[01:00:38.000 --> 01:00:40.000]  Это элементарно.
[01:00:40.000 --> 01:00:44.000]  Вот то, что получили, получили очень интересный результат.
[01:00:44.000 --> 01:00:47.000]  У2 это у нас что?
[01:00:47.000 --> 01:00:50.000]  Это решение с уменьшим шагом в двое.
[01:00:50.000 --> 01:00:53.000]  У1 это решение с шагом tau.
[01:00:53.000 --> 01:01:00.000]  Вот это выражение, обозначенное дэнком, это оценка погрешности на одном шаге интегрирования.
[01:01:00.000 --> 01:01:06.000]  То есть, оказывается, вот так можно очень просто оценить погрешность на одном шаге.
[01:01:06.000 --> 01:01:08.000]  Это предложил сделать Рунге.
[01:01:08.000 --> 01:01:15.000]  Это называется правило Рунге оценки погрешности решения уравнения разосовровнений на одном шаге.
[01:01:15.000 --> 01:01:17.000]  А это очень важно.
[01:01:17.000 --> 01:01:24.000]  Почему? Ну, например, вы задали точность решения на одном шаге epsilon, там 10, там минус 11.
[01:01:24.000 --> 01:01:28.000]  Посчитали вот эту дельту, не получилось.
[01:01:28.000 --> 01:01:32.000]  Уменьшаете шаг вдвое, еще раз пересчитываете вдвое, еще раз пересчитываете.
[01:01:32.000 --> 01:01:36.000]  Так до тех пор, пока эта дельта не станет той, которая вам нужна.
[01:01:36.000 --> 01:01:42.000]  То есть, таким образом вы можете делать автоматически, выбирать шаг интегрирования такой, который вам нужен.
[01:01:42.000 --> 01:01:45.000]  Это очень важный момент.
[01:01:45.000 --> 01:01:47.000]  Почему я на него обратил внимание?
[01:01:47.000 --> 01:01:51.000]  И второй момент. Что такое вот это вот выражение?
[01:01:51.000 --> 01:01:55.000]  Ну, давайте его назовем U с чертой, с начерком.
[01:01:55.000 --> 01:02:00.000]  Это есть не что иное, как уже следующее приближение к нашему решению.
[01:02:00.000 --> 01:02:03.000]  У с начерком давайте N обозначим.
[01:02:03.000 --> 01:02:09.000]  Но оно уже имеет не P порядок, а P плюс первый порядок.
[01:02:09.000 --> 01:02:14.000]  То есть, мы увеличили порядок опроксимации на единичку, ну, очень дешевым способом.
[01:02:14.000 --> 01:02:16.000]  То есть, почти ничего не делаем.
[01:02:16.000 --> 01:02:21.000]  Но, разумеется, количество вычислений у нас возросло по понятной причине.
[01:02:21.000 --> 01:02:27.000]  Идея очень простая и очень эффективная, ее используют очень часто.
[01:02:27.000 --> 01:02:29.000]  Так, идем дальше.
[01:02:29.000 --> 01:02:42.000]  Это метод оценки ошибки на шаге Рунге и метод построения решения более высокого порядка Ричардсону.
[01:02:42.000 --> 01:02:44.000]  Идем дальше.
[01:02:44.000 --> 01:02:51.000]  Надо поговорить о важнейшей вещи, об устойчивости методов Рунге-Котта.
[01:02:51.000 --> 01:02:54.000]  Об устойчивости мы будем говорить всегда.
[01:02:54.000 --> 01:03:01.000]  Это момент, который нужно исследовать априорно до решения любой задачи численной.
[01:03:01.000 --> 01:03:06.000]  Потому что в любых численных задачах появляется явление неустойчивости.
[01:03:06.000 --> 01:03:11.000]  Ну, в той или иной степени в одних меньше, в другой больше, но оно всегда есть.
[01:03:11.000 --> 01:03:16.000]  Вот об устойчивости.
[01:03:16.000 --> 01:03:21.000]  Давайте для нашего дифференциального уравнения, пусть оно будет для простоты скалерным.
[01:03:21.000 --> 01:03:27.000]  Это, так сказать, не очень важно.
[01:03:27.000 --> 01:03:30.000]  Мы напишем некую разницу из схемы Рунге-Котта.
[01:03:30.000 --> 01:03:33.000]  Давайте ее представим в таком общем виде.
[01:03:33.000 --> 01:03:37.000]  ОН плюс 1 минус ОН, это про 17-1 производное.
[01:03:37.000 --> 01:03:40.000]  А здесь вот F большое пусть будет от ОН.
[01:03:40.000 --> 01:03:43.000]  Это пересчеты всех правоучастей наших.
[01:03:43.000 --> 01:03:45.000]  Вот то, что я описал.
[01:03:45.000 --> 01:03:51.000]  К2, К3, К4, это все F большое в Гольме.
[01:03:51.000 --> 01:03:54.000]  Вот теорема.
[01:03:54.000 --> 01:03:58.000]  Пусть функция F липче с непрерывным.
[01:03:58.000 --> 01:04:12.000]  То есть F от Tx минус F от Ty по модулю меньше равняется C на x минус y.
[01:04:12.000 --> 01:04:21.000]  В этом случае решение явных метод Рунге-Котты устойчиво.
[01:04:21.000 --> 01:04:24.000]  И имеет место быть неравенство.
[01:04:24.000 --> 01:04:31.000]  ОН минус ВН меньше равняется Е в степени СТОН,
[01:04:31.000 --> 01:04:35.000]  где С это константа липчеца или константа непрерывности.
[01:04:35.000 --> 01:04:42.000]  Здесь ОН минус ВН и здесь плюс 2 ε делить на С.
[01:04:42.000 --> 01:04:45.000]  Эпсилум это некая малая погрешность.
[01:04:45.000 --> 01:04:47.000]  Например, машинная погрешность.
[01:04:47.000 --> 01:04:50.000]  То есть это некая малая погрешность.
[01:04:50.000 --> 01:04:55.000]  Такая погрешность входила, например, в определение понятия устойчивости.
[01:04:55.000 --> 01:04:58.000]  С это, ну, здесь, конечно, обозначено.
[01:04:58.000 --> 01:05:06.000]  И далее СТОН, поскольку акспоненты это всегда опасно,
[01:05:06.000 --> 01:05:12.000]  должно быть всегда равняется О большой от единицы, чтобы погрешность не росла.
[01:05:12.000 --> 01:05:19.000]  В этом случае вы видите, что ТН есть О большой от единицы.
[01:05:19.000 --> 01:05:22.000]  Это важный момент, обратите внимание.
[01:05:22.000 --> 01:05:25.000]  То есть если мы берем только липчец непрерывности,
[01:05:25.000 --> 01:05:28.000]  это самое грубое условие нагладкости функции,
[01:05:28.000 --> 01:05:30.000]  самое минимальное условие,
[01:05:30.000 --> 01:05:35.000]  то мы получаем гарантию устойчивости на отрезке порядка О большой от единицы.
[01:05:35.000 --> 01:05:42.000]  Если мы хотим двигаться дальше, то мы должны знать больше о свойствах правой части.
[01:05:42.000 --> 01:05:44.000]  Об этом я чуть позже скажу.
[01:05:44.000 --> 01:05:50.000]  Так, и далее СТОН должно быть много меньше единицы.
[01:05:50.000 --> 01:05:53.000]  Что такое С константа непрерывности?
[01:05:53.000 --> 01:06:01.000]  Ее можно определить как норма производной правой части по решению.
[01:06:01.000 --> 01:06:04.000]  Вот, а вот это вот условие уже крайне важно.
[01:06:04.000 --> 01:06:05.000]  Что это такое?
[01:06:05.000 --> 01:06:09.000]  Это условие выбора шага интегрирования для числого решения
[01:06:09.000 --> 01:06:11.000]  нелинейного дифференциального уравнения
[01:06:11.000 --> 01:06:14.000]  методом, явным методом Лангекута.
[01:06:14.000 --> 01:06:17.000]  На этот вопрос студенты обычно не отвечают.
[01:06:17.000 --> 01:06:19.000]  Как выбрать шаг интегрирования?
[01:06:19.000 --> 01:06:22.000]  Обычно слышат ответ из соображения точности.
[01:06:22.000 --> 01:06:23.000]  О чем я только что говорю?
[01:06:23.000 --> 01:06:26.000]  Правильно, точность раз, но если вы не соблюдете,
[01:06:26.000 --> 01:06:29.000]  не будете соблюдать вот это такое условие,
[01:06:29.000 --> 01:06:35.000]  вы натолкнетесь на явление неустойчивости числого решения.
[01:06:35.000 --> 01:06:37.000]  Что это означает физически?
[01:06:37.000 --> 01:06:44.000]  Это означает, что вы должны учитывать в явных методах все изменения правой части.
[01:06:44.000 --> 01:06:48.000]  То есть если у вас правая часть какая-нибудь вот такая,
[01:06:48.000 --> 01:06:53.000]  а вы сделаете вот такой шаг, перешагнете через все волны, скажем, синусоида,
[01:06:53.000 --> 01:06:56.000]  вы получите гарантированную неустойчивость.
[01:06:56.000 --> 01:06:59.000]  В явных схемах вы должны все это учитывать.
[01:06:59.000 --> 01:07:01.000]  Это неверно для неявных схем.
[01:07:01.000 --> 01:07:04.000]  Об этом чуть позже я скажу.
[01:07:04.000 --> 01:07:11.000]  Неявные схемы могут перепрыгнуть через изменения правой части и не пикнуть, как говорится.
[01:07:11.000 --> 01:07:16.000]  Программа будет считать, но вы получите неправильное решение.
[01:07:16.000 --> 01:07:22.000]  Поэтому здесь неявная схема имеет определенное преимущество при решении жестких задач,
[01:07:22.000 --> 01:07:28.000]  но определенный недостаток, если это так можно сказать, у них тоже есть.
[01:07:28.000 --> 01:07:34.000]  Так, ну конечно, сколько у нас осталось времени?
[01:07:37.000 --> 01:07:38.000]  Ох, есть.
[01:07:38.000 --> 01:07:43.000]  Давайте я вот вследствие вот этой теоремы, но на самом деле очень важна теорема об устойчивости.
[01:07:43.000 --> 01:07:48.000]  Ее очень часто забывают и потом горько за это расплачиваются.
[01:07:48.000 --> 01:07:54.000]  Беря, так сказать, шаг, то в явных, то неявных схемах, не тот, который нужен.
[01:07:54.000 --> 01:07:56.000]  И в результате получается, конечно, проблема.
[01:07:56.000 --> 01:07:58.000]  Давайте все-таки эту теорему мы докажем.
[01:07:58.000 --> 01:08:01.000]  Кстати, теорему доказал Радий Петрович Федоренко.
[01:08:01.000 --> 01:08:07.000]  Действительно, тоже, я его иначе как великим вычислительному математикам назвать не могу.
[01:08:07.000 --> 01:08:11.000]  Он читал лекции на Фафевче, примерно 20 лет.
[01:08:11.000 --> 01:08:17.000]  Предложил два метода, совершенно уникальных метода, которые до сих пор используются во всем мире,
[01:08:17.000 --> 01:08:22.000]  во всех, так сказать, цивилизованных странах, где ведется чистое решение задач.
[01:08:22.000 --> 01:08:27.000]  Медо, Рябинько и Федоренко известны во всем мире.
[01:08:27.000 --> 01:08:30.000]  Я с ними работал, я их хорошо знаю, к сожалению, их уже нет в живых.
[01:08:30.000 --> 01:08:34.000]  Это великие люди, конечно. Это великие люди.
[01:08:38.000 --> 01:08:43.000]  Когда был единственный конгресс по учислительной математике в Америке,
[01:08:43.000 --> 01:08:47.000]  сопредседателем конгресса был Питер Лакс и Федоренко Радий Петрович.
[01:08:47.000 --> 01:08:51.000]  Два сопредседателя конгресса было.
[01:08:51.000 --> 01:08:56.000]  Вот это одна из теорем, которую он доказал.
[01:08:56.000 --> 01:09:00.000]  Формулировку априо доказались следующие.
[01:09:00.000 --> 01:09:11.000]  Из условия устойчивости мы можем написать следующую аппроксимацию нашего уравнения Роггикута.
[01:09:11.000 --> 01:09:15.000]  Это аппроксимация первопроизводной.
[01:09:15.000 --> 01:09:23.000]  У нас будет f от un плюс, давайте так тоже обозначим,
[01:09:23.000 --> 01:09:27.000]  xn это погрешность на n-ом слое.
[01:09:27.000 --> 01:09:29.000]  И второе уравнение.
[01:09:29.000 --> 01:09:35.000]  Опять же, два близких уравнения, которые фигурируют в определении понятия устойчивости.
[01:09:35.000 --> 01:09:39.000]  fvn плюс это n.
[01:09:39.000 --> 01:09:42.000]  Если не писать, мы сразу обозначимся.
[01:09:42.000 --> 01:09:46.000]  xn мы положим меньше и не равняется епсилам.
[01:09:46.000 --> 01:09:51.000]  И это n по норме тоже положим меньше и не равняется епсилам.
[01:09:51.000 --> 01:09:56.000]  Теперь вычтем из одного уравнения другое, что получим.
[01:09:56.000 --> 01:09:58.000]  И возьмем их сразу по норме.
[01:09:58.000 --> 01:10:00.000]  Это равен состоянию по норме.
[01:10:00.000 --> 01:10:06.000]  Это будет un плюс 1 минус vn плюс 1.
[01:10:06.000 --> 01:10:17.000]  Меньше равняется un минус vn по норме плюс tau f от un
[01:10:17.000 --> 01:10:25.000]  минус f от vn по норме плюс 2 tau епсилам.
[01:10:27.000 --> 01:10:33.000]  Теперь используем свойство функции липшу с неприемностью.
[01:10:33.000 --> 01:10:38.000]  И это не равнится, перепишем в другом виде.
[01:10:38.000 --> 01:10:41.000]  un плюс 1 минус vn.
[01:10:41.000 --> 01:10:54.000]  Плюс 1 меньше не равняется un минус vn по норме плюс tau c.
[01:10:54.000 --> 01:11:02.000]  И тоже un минус vn по норме плюс 2 tau епсилам.
[01:11:02.000 --> 01:11:05.000]  Давайте сюда переведу.
[01:11:05.000 --> 01:11:12.000]  Я пишу крупно, надеюсь, что ребятам, которые сидят за компьютером, это будет видно, видны формулы.
[01:11:12.000 --> 01:11:19.000]  Стараюсь как можно более крупно писать, но досок не хватает.
[01:11:19.000 --> 01:11:27.000]  Тогда у нас получится un плюс 1 минус vn плюс 1.
[01:11:27.000 --> 01:11:32.000]  По норме меньше не равняется 1 плюс c tau.
[01:11:32.000 --> 01:11:40.000]  Здесь у нас un минус vn и плюс 2 tau епсилам.
[01:11:40.000 --> 01:11:43.000]  То есть довольно простой не равнится.
[01:11:43.000 --> 01:11:47.000]  Теперь давайте сделаем так.
[01:11:47.000 --> 01:11:49.000]  Серия не равнится, напишем.
[01:11:49.000 --> 01:12:10.000]  у1 минус v1 это будет 1 плюс c tau на норму у0 минус v0 плюс 2 tau епсилам.
[01:12:10.000 --> 01:12:14.000]  Дальше у2 минус v2. Что это будет?
[01:12:14.000 --> 01:12:22.000]  Значит, здесь будет не у0 и v0, а у1 и v1.
[01:12:22.000 --> 01:12:31.000]  Плюс c tau норма у1 минус v1 плюс 2 tau епсилам.
[01:12:31.000 --> 01:12:33.000]  Но меньше не равняется.
[01:12:33.000 --> 01:12:37.000]  Сюда вместо разности у1 и v1 составим верхнюю разность.
[01:12:37.000 --> 01:12:42.000]  Получим единица плюс c tau в квадрате.
[01:12:42.000 --> 01:12:49.000]  У0 минус v0 по норме плюс 2 tau епсилам.
[01:12:49.000 --> 01:12:52.000]  Ну и дальше идем.
[01:12:52.000 --> 01:12:57.000]  Третья разность, четвертая и n-ая разность.
[01:12:57.000 --> 01:13:03.000]  Как будет выглядеть n-ая разность?
[01:13:03.000 --> 01:13:06.000]  Она нас как раз и интересует.
[01:13:06.000 --> 01:13:10.000]  То есть эволюция, вот ошибка, как она будет выглядеть.
[01:13:10.000 --> 01:13:13.000]  Экспоненты, когда в ошибке, это всегда опасно.
[01:13:13.000 --> 01:13:16.000]  Но с экспонентами, значит, как нужно бороться.
[01:13:16.000 --> 01:13:22.000]  Итак, получается уn минус vn меньше не равно.
[01:13:22.000 --> 01:13:33.000]  Это единица плюс c tau в степени n на у0 минус v0 плюс 2 tau епсилам.
[01:13:33.000 --> 01:13:45.000]  А здесь 1 плюс 1 плюс c tau плюс 1 плюс c tau в квадрате плюс многоточие.
[01:13:45.000 --> 01:13:50.000]  1 плюс c tau в степени n минус 1.
[01:13:50.000 --> 01:13:52.000]  Вот такая сумма, то есть геометрическая прогрессия.
[01:13:52.000 --> 01:13:55.000]  Мы ее просто сумму знаем.
[01:13:55.000 --> 01:14:01.000]  Поэтому можно написать, что уn минус vn по норме.
[01:14:01.000 --> 01:14:15.000]  Это есть 1 плюс c tau в степени n у0 минус v0 плюс 2 tau епсилам.
[01:14:15.000 --> 01:14:17.000]  И сумма геометрической прогрессии.
[01:14:17.000 --> 01:14:22.000]  1 плюс c tau в степени n минус 1 минус 1.
[01:14:22.000 --> 01:14:30.000]  В знаменателе 1 плюс c tau минус 1 меньше не равно.
[01:14:30.000 --> 01:14:39.000]  1 плюс c tau в степени n здесь у0 минус v0.
[01:14:39.000 --> 01:14:41.000]  Ну и здесь понятно.
[01:14:41.000 --> 01:14:43.000]  Единицы сокращаются.
[01:14:43.000 --> 01:14:45.000]  Здесь единицу можно убрать.
[01:14:45.000 --> 01:14:55.000]  И получим 2 епсилам на c и на 1 плюс c tau в степени n.
[01:14:55.000 --> 01:14:57.000]  Меньше не равняется.
[01:14:57.000 --> 01:14:59.000]  Это единица плюс c tau в степени n.
[01:14:59.000 --> 01:15:02.000]  c tau много меньше единицы по условиям было.
[01:15:02.000 --> 01:15:06.000]  Поэтому мы можем приблизить ее экспонентой.
[01:15:06.000 --> 01:15:10.000]  Экспонента в степени c tau n.
[01:15:10.000 --> 01:15:20.000]  Здесь у нас будет у0 минус v0 плюс 2 епсилам на c.
[01:15:20.000 --> 01:15:22.000]  Ну 2 епсилам величина малая.
[01:15:22.000 --> 01:15:24.000]  С величина порядка у большой единицы.
[01:15:24.000 --> 01:15:26.000]  Здесь ничего плохого не будет.
[01:15:26.000 --> 01:15:30.000]  Экспонентность двух начальных данных тоже величина небольшая.
[01:15:30.000 --> 01:15:32.000]  Не более чем у большой единицы.
[01:15:32.000 --> 01:15:34.000]  У нас волнует только экспонента.
[01:15:34.000 --> 01:15:36.000]  Экспонента всегда опасна.
[01:15:36.000 --> 01:15:39.000]  Если она будет расти, будет расти по грешности.
[01:15:39.000 --> 01:15:41.000]  Со временем.
[01:15:41.000 --> 01:15:49.000]  Поэтому c tau, c умножить на tn должно быть порядка у большой единицы.
[01:15:49.000 --> 01:15:52.000]  Чтобы метод был устойчив.
[01:15:52.000 --> 01:15:56.000]  Я об этом вам говорил.
[01:15:56.000 --> 01:15:59.000]  Но скажу еще раз.
[01:15:59.000 --> 01:16:02.000]  Условия устойчивости метода.
[01:16:02.000 --> 01:16:08.000]  Это tau на норму матрицы якобы.
[01:16:08.000 --> 01:16:11.000]  Это должно быть много меньше единицы.
[01:16:11.000 --> 01:16:15.000]  При этом, если мы берем только одно условие.
[01:16:15.000 --> 01:16:17.000]  На гладкость условия гипшится.
[01:16:17.000 --> 01:16:24.000]  Мы имеем и ограничение на время на отрезок интегрирования.
[01:16:24.000 --> 01:16:30.000]  Оказывается, если взять более тонкие условия на правую часть.
[01:16:30.000 --> 01:16:33.000]  То ситуация резко может измениться.
[01:16:33.000 --> 01:16:40.000]  Например, если окажется, что уравнение таково дифференциально,
[01:16:40.000 --> 01:16:47.000]  что траектория его решения устойчива.
[01:16:47.000 --> 01:16:50.000]  Вы помните эти определения из курса дифференциальных уравнений?
[01:16:50.000 --> 01:16:55.000]  Или нет? Устойчивость траектории дифференциальных уравнений.
[01:16:55.000 --> 01:16:58.000]  Например, для скаверного уравнения,
[01:16:58.000 --> 01:17:07.000]  если производная правая часть будет меньше отрицательного числа.
[01:17:07.000 --> 01:17:12.000]  То есть отрицательное производное будет в сказании выравнений,
[01:17:12.000 --> 01:17:16.000]  то решение дифференциального уравнения устойчив.
[01:17:16.000 --> 01:17:23.000]  Если меньше равняется нуля, т.е. траектория такого уравнения называется устойчивыми,
[01:17:23.000 --> 01:17:28.000]  а если производное будет меньше равняется нулю,
[01:17:28.000 --> 01:17:35.000]  то траектория такого уравнения называется нейтральной или неустойчивой.
[01:17:35.000 --> 01:17:41.840]  нейтральной траектории. Если мы систему уровней имеем, то мы вводим вот такую
[01:17:41.840 --> 01:17:48.800]  матрицу А, это есть одна вторая, f' по у, это матрица якобы, плюс транспонированная
[01:17:48.800 --> 01:17:57.720]  матрица якобы, и вводится вот такая квадратичная форма, акция х,
[01:17:57.920 --> 01:18:07.840]  если меньше отрицательного числа, а больше нуля, то траектория такой системы устойчива,
[01:18:07.840 --> 01:18:16.320]  если меньше и не равняется нулю, то траектория такой системы нейтральна. Так вот, для нас это
[01:18:16.320 --> 01:18:22.880]  оказалось очень важным, в частности, это следствие, теоремы которое доказал, я уже следствие доказывать
[01:18:22.880 --> 01:18:30.960]  не буду, потому что все доказать невозможно. Оказывается, что если наши траектории решений
[01:18:30.960 --> 01:18:36.480]  нашего дифференциального уровня устойчивы, то вот то неравенство, которое написал,
[01:18:36.480 --> 01:18:49.120]  резко упрощается и выглядит следующим образом, у0-v0 по норме, плюс 2 лепсиум 9 на ц, то есть
[01:18:49.120 --> 01:18:59.160]  решение нашего уровня не устойчиво при любом t, при любом времени, ограничений о большой t нет,
[01:18:59.160 --> 01:19:06.680]  если траектория решения устойчива. Это можно доказать, но я уже делать делать не буду. Это
[01:19:06.680 --> 01:19:13.720]  следствие теоремы Федоренко, которую я вам привел доказать. Если ситуация меняется,
[01:19:13.720 --> 01:19:24.680]  если траектория нейтральна, оказывается в этом случае время продлевается до уровня
[01:19:24.680 --> 01:19:31.360]  о большой от 1 на t, t всегда величина малая, даже очень малая, поэтому время продлевается
[01:19:31.360 --> 01:19:41.240]  для нейтральных траекторий существенно, но при этом теряется порядок точности разницы схемы,
[01:19:41.240 --> 01:19:50.560]  t в степени p-1, но зато мы далеко проходим по времени для нейтральных траекторий, то есть если
[01:19:50.560 --> 01:19:58.120]  мы берем самые минимальные условия на гладкость, условия лепсиума, мы получаем два важных момента.
[01:19:58.120 --> 01:20:05.600]  Во-первых, мы получаем ограничения на временной интеграл, интегрирование, и мы получаем условия
[01:20:05.600 --> 01:20:14.760]  устойчивости, то есть условия выбора шала устойчивого для нашего решения. Если мы более тонкие
[01:20:14.760 --> 01:20:20.120]  свойства правой части привлекаем, в частности устойчивую траекторию, нейтральную траекторию,
[01:20:20.120 --> 01:20:28.200]  мы получаем уже лучшие свойства, то есть наш отрезок интегрирования продлевается, а в случае
[01:20:28.200 --> 01:20:36.400]  устойчивых траекторий он просто бесконечен, то есть решение у нас устойчивое, метда франгикута от нуля до
[01:20:36.400 --> 01:20:43.480]  бесконечности. Правда, вот эти устойчивые траектории, они как правило описывают такие десепативные процессы,
[01:20:43.480 --> 01:20:50.500]  то есть если, скажем, там вращательный процесс выписывается, то это вращение будет свертываться по
[01:20:50.500 --> 01:20:58.240]  спирали, то есть это вращение с тренингом, скажем, спутник на орбите где-нибудь, что-нибудь таком, но на сегодня
[01:20:58.240 --> 01:21:04.720]  все. Следующая лекция может быть в этом семестре даже не последняя, мы будем говорить о жестких
[01:21:04.720 --> 01:21:10.880]  системах обыкновенных дифференциальных уровнях, тоже очень важная тема, они очень часто встречаются в
[01:21:10.880 --> 01:21:17.000]  практике, вот решение. Ну тогда на сегодня все.
