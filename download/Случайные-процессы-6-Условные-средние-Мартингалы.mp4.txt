[00:00.000 --> 00:08.700]  Сейчас мы обсуждаем условные и средние.
[00:08.700 --> 00:25.980]  Ситуация такая, есть вероятностное пространство, есть под сигма алгебра,
[00:25.980 --> 00:45.900]  и есть оператор условного среднего, который определяется одним из двух способов,
[00:45.900 --> 00:53.620]  как вам больше нравится, либо как в L2 ортогональная проекция на подпространство,
[00:53.620 --> 01:00.460]  порожденная А-измеримыми функциями, либо с помощью теоремы Радонна-Никодима.
[01:00.460 --> 01:08.900]  Для первого способа сначала это делается, естественно, для функций из L2,
[01:08.900 --> 01:17.980]  ну раз уж что-то делается в L2, но как потом получить обычные свойства условного среднего,
[01:17.980 --> 01:29.860]  которые приистекают из Радона-Никодима. Можно заметить, что если функция не отрицательная,
[01:29.860 --> 01:40.540]  то ее условное среднее не отрицательно, ну как водится в таких делах, почти всюду.
[01:40.540 --> 01:46.420]  Ну раз почти всюду, то можно выбрать версию, которая всюду не отрицательна.
[01:47.300 --> 02:00.820]  Почему это так? Ну это потому что вот это для всех множеств будет не отрицательно,
[02:00.820 --> 02:13.540]  а это есть интеграл условного среднего. Ну и поэтому раз от этой функции интегралы
[02:13.540 --> 02:17.700]  по множеству не отрицательны, значит она сама почти всюду не отрицательна.
[02:17.700 --> 02:34.180]  Из этого вытекает такое, что если кс меньше либо равно это, то условные средние также расположены.
[02:34.180 --> 02:46.860]  Ну разумеется тут все почти всюду. Ну вот если это сначала получено хотя бы для ограниченных
[02:46.860 --> 03:03.020]  функций, то перейти к L1 можно так. Перейти от кси из L2 кси из L1, значит можно так.
[03:03.020 --> 03:18.340]  Значит сначала для не отрицательных, ну а потом естественно общую разложить в разность.
[03:18.340 --> 03:29.420]  Значит для не отрицательных делаем так. Берем ксиэнные, которые есть, ну обычная
[03:29.420 --> 03:41.260]  технология срезок. Значит берем вот такие вот срезки. Значит для них условные средние есть.
[03:41.260 --> 03:55.660]  Значит для этих срезок условные средние есть. Значит эти срезки возрастают, поэтому условные
[03:55.660 --> 04:08.940]  средние тоже возрастают, ну как водится почти всюду. Значит получилась такая последовательность
[04:08.940 --> 04:25.300]  функций возрастающая. И интеграл, ну как всегда интеграл, это есть интеграл с единицей и поэтому
[04:25.300 --> 04:44.380]  получается вот так. И это не отрицательно, то что не отрицательно, это не важно, это меньше
[04:44.380 --> 04:54.300]  либо равно, чем вот это. Ну и поэтому получилась последовательность функций возрастающая с
[04:54.300 --> 05:02.900]  ограниченными интегралами. Значит следовательно существует вот такая вот функция, ну дзета,
[05:02.900 --> 05:23.500]  которая есть предел вот этих вот, почти всюду. Почти всюду и в L1. Ну и из этого очевидным
[05:23.500 --> 05:31.780]  образом следует, что, ну если перейти к интеграмам по множествам, то из этого следует,
[05:31.780 --> 05:45.860]  что эта функция служит условным средним. Ну и получается, что на L1 аналогичные свойства
[05:45.860 --> 05:55.500]  выполняются. Ну вот если через Родон Никодима делать это сразу, ну а здесь получается как следствие
[05:55.500 --> 06:05.940]  того, что это было в L2. Значит, ну свойства такие. Значит вот такое соответствие линейно.
[06:05.940 --> 06:30.740]  Так, дальше значит оно монотонно. Вот в этом смысле. Дальше интеграл, ну или вот мат ожидания
[06:30.740 --> 06:52.020]  от условного среднего есть ростом от ожидания. Так, и если функция эта ограниченная, а измеримая,
[06:52.020 --> 07:09.060]  то тогда можно ее выносить из подусловного среднего. Значит, тогда условное среднее с ней
[07:09.060 --> 07:22.940]  будет вот так выглядеть. Ну откуда это следует? Значит, откуда это следует? Значит, как это
[07:22.940 --> 07:30.880]  свойство проверяется? Ну в случае L2 это просто из свойств артагональных проекций, конечно,
[07:30.880 --> 07:39.120]  следует. Но если это делать из Родона Никодима, ну или вот выводить из L2, то получается так.
[07:39.120 --> 07:58.040]  Значит, мы берем интеграл от этого дела по множеству а. Ну естественно, а из сигма-алгебры.
[07:58.040 --> 08:11.360]  И получаем, что это есть вот это. Получаем, что это есть вот это. А это можно записать
[08:11.360 --> 08:24.560]  как интеграл по всему пространству. Вот от чего. А это по определению, поскольку эта функция,
[08:24.560 --> 08:36.360]  вот эта функция, она а измерима. Поэтому вот этот интеграл можно скрутить обратно в интеграл
[08:36.360 --> 08:57.160]  с условным средним. Ну и значит, это последнее есть интеграл по множеству а. Вот от этого дела.
[08:57.160 --> 09:06.760]  Ну и что и доказывает, поскольку множество а произвольно, то получается такое равенство.
[09:06.760 --> 09:24.080]  Значит, вот это свойство, в частности от констант, конечно, будут получаться ниже.
[09:24.080 --> 09:35.360]  Значит, вот это свойство, ну такое вот, такое вот мультипликативное свойство, оно на самом деле
[09:35.360 --> 09:45.600]  описывает все условные средние. Значит, вот в качестве упражнения проверьте такую вещь.
[09:45.600 --> 10:09.640]  Значит, пусть оператор дан. Это ортогональный проектор ВЛ2П. Причем он обладает вот каким
[10:09.640 --> 10:25.560]  свойством, ну вот аналогичным, вот этому. Значит, интеграл. Значит, интеграл. Сейчас,
[10:25.560 --> 10:34.920]  значит, как это лучше написать? Ну, давайте я сразу напишу вот так. Значит, вот так давайте
[10:34.920 --> 10:47.560]  напишу. Значит, вот так без интегралов. Напишу прямо в терминах самого этого оператора,
[10:47.560 --> 11:08.320]  в терминах этого проектора. Значит, это верно для всех, для всех ограниченных F и G. Вот задан такой
[11:08.320 --> 11:14.280]  ортогональный проектор. Ну, то есть что такое ортогональный проектор? Значит, ВЛ2 есть какое-то
[11:14.280 --> 11:21.080]  замкнутое подпространство, и на него дан ортогональный проектор. И у этого проектора вот такое
[11:21.080 --> 11:29.960]  свойство на ограниченных, ну вот аналогично этому. Но тут, видите, тут никакой пока сигма-алгебры
[11:29.960 --> 11:47.960]  нет. Но тогда существует сигма-алгебра, сигма-алгебра А в B такая, что этот проектор есть условное среднее
[11:47.960 --> 11:54.400]  относительно этой сигма-алгебры. То есть условные и средние характеризуются, стало быть, двумя
[11:54.400 --> 12:03.600]  свойствами. Они ортогональные проекторы и плюс еще вот это свойство, что можно выносить, значит,
[12:03.600 --> 12:12.480]  аизмеримые функции из-под них. Но когда еще сигма-алгебры нет и нет аизмеримых функций,
[12:12.480 --> 12:27.600]  это трансформируется вот в такое вот условие. Так, значит, что-то я еще хотел сказать про условные
[12:27.600 --> 12:41.560]  средние. А, ну вот несколько еще простых вещей. Ну тоже, это все вроде бы должно быть где-то
[12:41.560 --> 12:49.560]  там раньше в теории вероятности, но такие вещи всегда полезно напомнить. Значит, если, значит,
[12:49.560 --> 13:04.320]  если А0 лежит в А, то когда вы возьмете сначала спроектируете на одно подпространство, а потом
[13:04.320 --> 13:16.160]  на меньшее в нем, то это то же самое, что сразу проектировать на меньшее. Ну в терминах ортогональных
[13:16.160 --> 13:22.760]  проекторов это совсем очевидно. Ну и если это записывать через интегралы, ну тоже это из
[13:22.760 --> 13:33.680]  определения сразу вытекает. И, значит, еще неравенство, неравенство Йенсона полезная вещь.
[13:33.680 --> 13:48.320]  Значит, неравенство Йенсона оно для функций выпуклых, значит, в выпуклая функция, ну скажем,
[13:48.320 --> 14:03.040]  для упрощения дела на всей прямой. Тогда выпуклая функция от интеграла оценивается через интеграл от
[14:03.040 --> 14:11.480]  композиции. Ну, разумеется, тут требуется, чтобы интегралы существовали. А аналогично для условных
[14:11.480 --> 14:18.520]  средних, значит, для обычных интегралов это неравенство для чисел, а для условных средних,
[14:18.520 --> 14:30.200]  значит, для условных средних, значит, вот так это будет. Значит, это будет вот так. А, значит,
[14:30.200 --> 14:52.600]  В от условного среднего оценивается через условное среднее от композиции. Если, если
[14:52.600 --> 15:10.040]  кси и композиция интегрируемы. Так, значит, ну как это доказывается? Ну, это можно доказывать
[15:10.040 --> 15:18.640]  разными способами, но, наверное, самый наглядный такой, но это не единственный способ, но, мне кажется,
[15:18.640 --> 15:34.080]  он самый наглядный. Значит, обоснование, как это обосновывается, сводим срезками к ограниченным,
[15:34.080 --> 15:42.800]  к ограниченным кси. Значит, ну, то есть, замечаем, что достаточно доказать это для ограниченных,
[15:42.800 --> 15:52.400]  а потом, значит, с помощью предела это можно распространить. А, значит, равномерными приближениями
[15:52.400 --> 16:04.400]  сводим к простым, к простым кси. Значит, ну опять, если для простых, ну, то есть, с конечным
[16:04.400 --> 16:14.240]  числом значений это известно, то понятно, что, когда вы будете равномерно приближать ограниченную
[16:14.240 --> 16:27.600]  простыми, то, ну, очевидно, что, значит, ну, давайте это я замечу. Значит, если ксиены сходятся кси равномерно,
[16:27.600 --> 16:42.720]  то тогда получается, что V от ксиенных равномерно сходится V от кси. Ну, мы тут пользуемся, конечно,
[16:42.720 --> 16:53.120]  не явно тем, что функция выпуклая непрерывно. Так, и, значит, теперь, значит, мы только еще
[16:53.120 --> 17:07.960]  замечаем, что из свойств, из свойств, значит, условного среднего, значит, смотрите, что получается.
[17:07.960 --> 17:20.240]  Получается, что если Gn равномерно сходятся к G, то тогда условные средние равномерно сходятся
[17:20.240 --> 17:29.200]  к условному среднему. Ну, это из-за вот, из-за оценок, которые были для условных средних. То есть,
[17:29.200 --> 17:36.800]  если функция по модулю меньше либо равно epsilon, то условные средние тоже. Значит, поэтому достаточно,
[17:36.800 --> 17:51.400]  поэтому достаточно рассмотреть случаи, когда кси простая. Значит, вот теперь, значит, кси простая.
[17:51.400 --> 18:06.320]  Значит, что это значит? Это значит, что она есть вот кто. Так, значит, она вот такая есть, где, значит,
[18:06.320 --> 18:19.480]  омега это дизюнктное объединение. Так, значит, омега разбили на дизюнктные куски, ну, разумеется,
[18:19.480 --> 18:32.600]  из сигмала вибры. Так, то есть, не, конечно, не из A, а из B. Значит, омега разбили на куски,
[18:32.600 --> 18:41.400]  на каждом куске функция постоянна. Так, теперь давайте, сейчас, ну, давайте я среднее лучше
[18:41.400 --> 18:54.160]  затру. Значит, давайте посмотрим, значит, что, значит, что тут будет. Значит, смотрите,
[18:54.160 --> 19:16.400]  чему равно, чему равно тогда условное среднее. Значит, условное среднее это сумма. Значит,
[19:16.400 --> 19:33.320]  вот такая сумма. Так, ну, как водится почти всюду. Значит, это из-за линейности. Так,
[19:33.320 --> 19:49.240]  теперь, кто будет, кто будет условное среднее от композиции, кто будет условное среднее от
[19:49.240 --> 20:03.200]  композиции. Значит, ну, это будет вот кто. Композиция, значит, композиция, значит, смотрите,
[20:03.200 --> 20:16.760]  функция была константой на каждой из этих. Значит, когда применили V, то что оказалось? Ну, оказалось,
[20:16.760 --> 20:31.680]  что она стала другой константой. Так, значит, вот, вот так поэтому будет. Ну, и здесь будет вот,
[20:31.680 --> 20:46.880]  что V от C1 на условное среднее от этого, плюс, ну, и так далее, плюс V от Cn на условное среднее
[20:46.880 --> 20:55.120]  от последнего. Так, значит, это вот такая правая часть. А теперь мы хотим применить V вот к этому
[20:55.120 --> 21:04.520]  делу. Так, и увидеть, что это оценивается через правую часть. Ну, как это увидеть? Ну, замечаем,
[21:04.520 --> 21:22.080]  что сумма вот этих вот тождественно равна единице. Так, из этого следует, что сумма условных средних
[21:22.080 --> 21:39.720]  тоже единица, но только почти всюду. Так, но тогда смотрите, что здесь стоит. Здесь стоят какие-то
[21:39.720 --> 21:48.240]  числа. Ну, они случайные, конечно, но, тем не менее, они хоть и случайные, но у них сумма единицы
[21:48.240 --> 21:57.720]  почти всегда. И, значит, их комбинация с какими-то весами, циитами. Значит, V выпуклая,
[21:57.720 --> 22:13.360]  значит, V выпуклая. Из этого следует, что V вот от этого дела, значит, V вот от этого дела будет
[22:13.360 --> 22:30.240]  оцениваться, ну, как полагается, для выпуклой функции будет V от C1 на вот это, значит,
[22:30.240 --> 22:40.840]  плюс-плюс и так далее, V от Cn на вот это. Ну, почти всюду. Значит, вот так будет почти всюду. Ну,
[22:40.840 --> 22:48.040]  а это и есть то, что мы хотели получить справа. Так что получается, что для конечно значных функций
[22:48.040 --> 22:56.880]  это непосредственное следствие выпуклости, для ограниченных функций результата равномерного
[22:56.880 --> 23:06.880]  предела, а для функций уже неограниченных, ну, ну, чуть там, чуть более изысканный предел с помощью
[23:06.880 --> 23:16.240]  срезок. Вот, значит, так что вот, значит, вот основные свойства. Так, если я ничего не забыл,
[23:16.240 --> 23:30.440]  что хотел сказать. А, вот, вот еще две, вот еще две полезные задачи. Значит, две задачи, значит,
[23:30.440 --> 23:39.720]  ну, они в конспекте тоже есть. Ну, давайте я их здесь выпишу. Эти задачи мы дальше будем использовать.
[23:39.720 --> 23:50.000]  То есть, это такие задачи, которые надо решить. Значит, задача один. Значит, задача один. Значит,
[23:50.000 --> 24:14.480]  пусть интегрируемая кси независимо, независимо с а, то есть со всеми а измеримыми функциями. Так,
[24:14.480 --> 24:38.160]  тогда ее условное среднее, а есть просто ее обычное среднее. То есть, значит, это, ну, вообще говоря,
[24:38.160 --> 24:45.280]  для большинства функций условное среднее это функция, так, но в некоторых случаях эта функция
[24:45.280 --> 24:52.160]  может становиться константой. Вот константой она становится тогда, когда вот эта функция,
[24:52.160 --> 24:57.480]  случайная величина, независимость сигма-алгебры. А независимость сигма-алгебры понимается как
[24:57.480 --> 25:05.160]  независимость со всеми случайными величинами оттуда, измеримыми относительно нее. Вот, значит,
[25:05.240 --> 25:16.240]  первая задача и вторая задача тоже в таком же духе. Значит, это вот какая задача. Когда же
[25:16.240 --> 25:34.960]  случайная величина, значит, случайная величина кси, ну, уже не обязательно интегрируемая,
[25:34.960 --> 25:52.720]  независимо, независимо с а. Значит, тогда и только тогда, когда, значит, верно следующее,
[25:52.720 --> 26:03.480]  значит, когда вы берете ее, подставляете в Борелевские функции ограниченные, и у вас получается всегда
[26:03.480 --> 26:19.640]  вот это для всех ограниченных Борелевских ф. Значит, то есть, видите, по одному такому равенству,
[26:19.640 --> 26:28.280]  по одному такому равенству еще нельзя судить, что случайная величина независима с сигма-алгеброй.
[26:28.280 --> 26:35.200]  Но если равенство из предыдущей задачи выполняется не для одной только нее самой,
[26:35.200 --> 26:47.640]  а еще и для всех функций, ограниченных от нее, то тогда это равнозначно, значит,
[26:47.640 --> 26:55.200]  независимости относительно сигма-алгеброй. Так, значит, ну, дальше, значит, смотрите,
[26:55.200 --> 27:05.240]  значит, дальше нам эти условные средние понадобятся для двух оставшихся основных классов
[27:05.240 --> 27:12.120]  случайных процессов, для маркенгалов и для марковских процессов. Ну и вот, значит,
[27:12.120 --> 27:20.760]  сейчас я начну про маркенгалы, ну, видимо, в следующий раз закончу про маркенгалы,
[27:20.760 --> 27:28.840]  потом будет небольшое обсуждение, значит, другого важного класса марковских процессов,
[27:28.840 --> 27:35.320]  где тоже условные средние фигурируют. И на этом, так сказать, общая, как бы, абстрактная,
[27:35.320 --> 27:40.360]  так, ну, в кавычках абстрактная, ну, она может, конечно, и отчасти и правда абстрактная,
[27:40.360 --> 27:47.760]  ну, такая или, скажем, теоретическая часть закончится, а мы должны будем разобрать еще
[27:47.760 --> 27:54.600]  две, ну, вот с помощью этих технологий, так сказать, основанных на абстрактных вещах,
[27:54.600 --> 28:02.680]  две конкретные задачи, которые классики решили еще очень давно, еще когда не было маркенгалов,
[28:02.680 --> 28:08.360]  всей этой техники, но вот, значит, как-то искусно они, значит, голыми руками эти задачи взяли,
[28:08.360 --> 28:14.720]  ну, а мы, значит, руководствуясь вот этими теоретическими, значит, построениями, ну,
[28:14.720 --> 28:24.920]  решим эти задачи несколько короче, чем их решили классики. Значит, вот, значит, следующий раздел,
[28:24.920 --> 28:45.600]  значит, фильтрации и маркенгалы. Значит, теперь Т у нас будет не абстрактное параметрическое
[28:45.600 --> 28:54.520]  множество параметров, а под множество R. Ну, в общем-то, для части обсуждения будет неважно,
[28:54.600 --> 29:02.200]  что это именно R, будет важно, что T упорядоченное множество, но все-таки давайте, чтобы немножко
[29:02.200 --> 29:14.080]  технически, так сказать, приземлить наше обсуждение, пусть T будет частью R. Что? Нет,
[29:14.080 --> 29:20.360]  не обязательно. Ну, T может быть, например, целые числа, натуральные числа. Нет, связанности не
[29:20.360 --> 29:38.480]  требуется. Значит, что такое фильтрация? Значит, семейство сигма-алгебр FT, содержащихся в этой
[29:38.480 --> 29:59.480]  основной сигма-алгебры. Фильтрация, значит, если оно, значит, вот связано вот таким вот соотношением
[29:59.480 --> 30:12.120]  для элементов времени. Ну, мы так будем условно на это тесселлаться, как на время. Ну, еще иногда
[30:12.120 --> 30:23.680]  говорят поток сигма-алгебр. Теперь, ну, какой практический смысл вот этих множеств в реальных
[30:23.680 --> 30:33.200]  задачах. Ну, это речь идет о событиях, о наступлении или ненаступлении которых,
[30:33.200 --> 30:44.120]  известно уже в момент времени, ну, до момента T или в момент времени T. Так вот, если интерпретировать
[30:44.120 --> 30:52.520]  события, ну, как что-то, что наблюдается, то вот, так сказать, такая вот простая интерпретация. Но
[30:52.520 --> 31:01.400]  это совершенно, это совершенно не обязательно расшифровать, потому что, ну, если взяться за это,
[31:01.400 --> 31:08.240]  то тогда возникнет вопрос, что такое известно, там и так далее. А, значит, здесь, ну, вот такой
[31:08.240 --> 31:17.840]  чисто теоретико множественные условия. Значит, значит, определение, значит, случайный процесс,
[31:17.840 --> 31:29.680]  значит, вот с этим параметрическим множеством согласован с фильтрацией.
[31:29.680 --> 31:56.640]  Значит, вот это и вот. А, если ксиат T, ft измеримо для всех T. Значит, смотрите,
[31:56.640 --> 32:05.360]  общий случайный процесс это какой угодно набор случайных величин, а согласованный с фильтрацией
[32:05.360 --> 32:14.560]  это еще дополнительное требование, чтобы они были измеримы не относительно большой сигмал гибр,
[32:14.560 --> 32:21.480]  относительно которой все должны быть измеримы, а относительно своей меньшей. Значит, всякий
[32:21.480 --> 32:41.840]  процесс, значит, всякий процесс ксиат T порождает, порождает фильтрацию. Значит,
[32:41.840 --> 32:51.600]  А, которую мы обозначим вот таким символом, значит, это сигма алгебра, порожденная всеми
[32:51.600 --> 33:03.520]  случайными величинами до момента времени T. Ну и, очевидным образом, он с ней согласован.
[33:03.520 --> 33:14.560]  Ну, разумеется, очень легко привести пример процесса, который с какой-то фильтрацией не
[33:14.560 --> 33:25.680]  согласован. Так что, значит, бывает так, а бывает, значит, и не так. И, значит, теперь вот основное
[33:25.680 --> 33:34.920]  определение, ну, смотрите, парамартингалы, значит, получается так. Значит, есть такие побочные
[33:34.920 --> 33:44.160]  тоже определения, ну, что это такое фильтрация, что такое согласованный процесс. Ну, и есть основное,
[33:44.160 --> 34:02.840]  что такое мартингал. Значит, определение, значит, процесс, значит, процесс ксиат T мартингал
[34:02.840 --> 34:29.240]  относительно, значит, фильтрации. Значит, если, значит, он с ней согласован,
[34:29.240 --> 34:50.120]  значит, кси T интегрируемый, и выполнено вот такое вот тождество, значит, условное среднее,
[34:50.280 --> 35:08.280]  значит, условное среднее. Ну, вот здесь бывает удобно обозначить условное среднее вот так,
[35:08.280 --> 35:24.480]  а не обычным нашим символом. Значит, ну, давайте я здесь помечу, что вот такой символ это, значит,
[35:24.480 --> 35:35.000]  такой же, как этот. Ну, почему так удобней иногда бывает? Ну, в общем, дальше это будет видно. Это
[35:35.000 --> 35:41.720]  из-за того, что иногда вот здесь, ну, какие-то довольно длинные выражения возникают, и очень
[35:41.720 --> 35:49.800]  неудобно их все загонять в верхний индекс. Ну, и кроме того, такова традиция. Вот, в принципе,
[35:49.800 --> 36:00.240]  я бы даже сказал, что вот более распространен такой символ, но такой просто немножко короче,
[36:00.240 --> 36:09.320]  я поэтому для краткости вот такой использую. Но вот наступают времена, когда надо, ну,
[36:09.320 --> 36:16.200]  так сказать, более громоздкий символ, оказывается, удобнее. Значит, ну, естественно,
[36:16.200 --> 36:28.560]  значит, естественно, это все должно быть почти всюду, конечно. Так, значит, если этот процесс
[36:28.560 --> 36:34.640]  квадратично интегрируемый, но этого не предполагается, но если он квадратично интегрируемый,
[36:34.640 --> 36:42.840]  то что геометрически означает мартингальность? Значит, вот эти сигма-алгебры, получается,
[36:42.840 --> 36:52.000]  что они задают проектирование на такое возрастающее семейство замкнутых подпространств. Значит,
[36:52.000 --> 36:56.960]  каждая сигма-алгебра, значит, порождает замкнутое подпространство. Большая сигма-алгебра,
[36:56.960 --> 37:04.720]  большее подпространство. И получается, что есть такой вот веер, раскрывающийся подпространств
[37:04.720 --> 37:16.480]  замкнутых, а процесс, это такая кривая в гильбертовом пространстве. И вот получается так,
[37:16.480 --> 37:23.400]  что тут реально требуется, что когда вы проектируете точку кривой на меньшее подпространство,
[37:23.400 --> 37:33.000]  то у вас должна получиться точка искривой при этом меньшем моменте времени. Так что многие
[37:33.000 --> 37:43.960]  свойства мартингалов из этого, так сказать, соображения усматриваются. Давайте заметим,
[37:43.960 --> 37:56.600]  ну давайте что-нибудь докажем. Давайте я вам сразу скажу, что мы будем доказывать про мартингалы.
[37:56.600 --> 38:12.200]  Про мартингалы у нас будет несколько примеров и паратиарем. Причем одна из них, может быть даже
[38:12.200 --> 38:24.680]  и самая важная про мартингалы, будет без доказательства. Прежде чем говорить про некие
[38:24.680 --> 38:30.840]  свойства, эти примеры и теоремы будут как бы крутиться вокруг свойств мартингалов. Но
[38:30.840 --> 38:39.320]  прежде чем говорить про свойства мартингалов, намечание про терминологию. Почему такое название
[38:39.320 --> 38:46.800]  мартингал? Этого никто не знает, потому что это название появилось у классиков в 30-х годах,
[38:46.800 --> 38:58.400]  у них не спросишь. Но французское слово мартингал имеет такое отчасти архаическое значение,
[38:58.400 --> 39:08.760]  там ну часть иконской упряжки, ну в общем-то, так сказать, там наездники, наверное, сейчас там
[39:08.760 --> 39:17.480]  французские это используют слово. А другое значение, ну тоже довольно старое, французское, оно такое
[39:17.480 --> 39:25.120]  немножко жаргонное, и оно означает, значит, такую тактику игры в азартные игры со ставками, ну вот
[39:25.120 --> 39:36.520]  таких там типа бросания монетки, когда вы при проигрыше удваиваете ставку. Ну вот чем из двух
[39:36.520 --> 39:43.760]  руководствовались классики, когда выбрали такой термин для этого процесса, ну вот сейчас, так сказать,
[39:43.760 --> 39:55.360]  уже спросить не у кого. Ну а теперь это слово, значит, ну перекочевало во все языки, ну и в том
[39:55.360 --> 40:03.640]  числе русский. Значит, мартингал это, ну вот из общих классов процессов, это один из самых важных
[40:03.640 --> 40:09.040]  процессов. Вот я уже говорил, из конкретных процессов два самых важных, это Виннеровский
[40:09.040 --> 40:18.640]  и Пуассоновский, а из классов процессов, ну вот мартингал один из самых важных, вот самые важные,
[40:18.640 --> 40:32.440]  можно сказать, мартингал, Марковский, ну и Гауссовский, наверное. Теперь, что можно наблюсти про
[40:32.440 --> 40:53.040]  мартингалы? Значит, давайте заметим, что, значит, если, значит, ксиат Мартингал, то у него среднее
[40:53.040 --> 41:06.040]  постоянно, так, значит, давайте, давайте поймем, почему у него среднее постоянно, так, значит,
[41:06.040 --> 41:20.200]  есть идеи, откуда, как это получить, почему среднее постоянно. Ну у нас, смотрите, что известно,
[41:20.200 --> 41:29.280]  кто такой, вот этот, ну скажем, пусть, пусть с, скажем, меньше, так, значит, при меньшем, значит,
[41:29.280 --> 41:43.040]  он кто будет? Он будет условным средним от большего, так, а теперь, если, если навесить
[41:43.040 --> 41:52.320]  среднее, так, если навесить среднее, то справа получится, то есть слева получится, ну просто
[41:52.320 --> 42:00.460]  среднее, так, а справа средний от условного среднего, но средние от условного среднего
[42:00.460 --> 42:08.380]  вот у нас было такое свойство, что это просто среднее, так вот, поэтому про некоторые процессы,
[42:08.380 --> 42:17.500]  у которых средние непостоянно, но сразу можно сказать, что они не мартингалы,
[42:17.500 --> 42:28.460]  например, Пуассоновский процесс. Но на самом деле очень многие важные процессы
[42:28.460 --> 42:38.300]  получаются из мартингалов какими-то очень довольно простыми манипуляциями,
[42:38.300 --> 42:53.340]  например, вычитанием среднего. Дальше у нас будет несколько таких утверждений, частично в виде
[42:53.340 --> 43:02.980]  задач, ну из которых будет видно, что мартингалы это вещь такая довольно распространенная. Так,
[43:02.980 --> 43:11.060]  теперь, значит, что мы хотим доказать про мартингалы? А, вот давайте я сразу сделаю
[43:11.060 --> 43:31.900]  замечание, значит, если вместо равенства у нас будет вот такое вот неравенство, так, то это
[43:31.900 --> 43:52.340]  получается супер мартингал. А если вместо, ну а если равенство противоположное, то суп мартингал.
[43:52.340 --> 44:11.380]  Ну вот из дальнейшего будет видно, что большинство разумных процессов представляют собой либо мартингал
[44:11.380 --> 44:18.460]  с какой-то такой уже специфической добавкой, ну либо суп мартингал или супер мартингал,
[44:18.460 --> 44:27.620]  ну тоже с какой-то специфической добавкой. Так что вот все вместе это уже очень широкий класс
[44:27.620 --> 44:41.020]  процессов. Но это я к сведению привожу, у нас не будет, вот про это у нас ничего не будет, но единственное,
[44:41.020 --> 44:51.660]  что можно сказать, что из неравенства Йенсона видно, что если мартингал подставить, ну выпуклую,
[44:51.660 --> 44:57.340]  ну или вогнутую функцию, то получится, ну там, соответственно, суп или супер мартингал. Так,
[44:57.340 --> 45:04.380]  но это вот, так сказать, прямое следствие Йенсона и вот этого неравенства. Так, теперь,
[45:05.340 --> 45:20.180]  вот давайте примеры. Ну один из первых примеров, который рассматривали классики такой, вот у нас
[45:20.180 --> 45:32.420]  будет два общих примера, а потом будут, ну так сказать, про конкретные вопросы, про конкретные
[45:32.420 --> 45:37.620]  процессы мы зададим вопросы, мартингалы они или нет. Но скажем про Пуассона, мы уже выяснили,
[45:37.620 --> 45:43.100]  что он не мартингал, но будет интересно, как он связан с мартингалами. Значит, ну вот,
[45:43.100 --> 45:56.220]  значит, первый пример, пусть ксииты независимые, случайные величины, значит, с нулевыми средними,
[45:56.220 --> 46:19.260]  так, пусть сн, это их сумма, так, и фн, это порождена первыми n, так, значит, ну вот,
[46:19.260 --> 46:27.620]  время натуральное, так, значит, время натуральное, значит, тогда, да, да, и еще конечно, значит,
[46:27.620 --> 46:35.740]  еще конечно, мы требуем раз говорится про средние, ну конечно требуется, чтобы они были интегрируемы,
[46:35.740 --> 46:53.180]  так, а тогда, тогда сн мартингал относительно, ну вот этой вот фильтрации, значит, вот,
[46:53.180 --> 47:00.940]  обратите внимание, что мартингал, он всегда связан с какой-то фильтрацией, значит, если
[47:00.940 --> 47:08.940]  заменили сигма-алгебры, то мартингал, конечно, может перестать быть мартингалом, так, ну давайте
[47:08.940 --> 47:17.860]  проверим, почему это, значит, давайте проверим, почему это мартингал, вот это, ну можно сказать,
[47:17.860 --> 47:28.860]  один из самых главных примеров мартингалов, ну и в общем-то в дискретном варианте, ну вот,
[47:28.860 --> 47:38.980]  можно сказать, один из основных примеров, а, значит, в непрерывном варианте, который мы не будем
[47:38.980 --> 47:48.140]  тут обсуждать, а мартингалы это стахастические интегралы, то есть это некие такие вот непрерывные
[47:48.140 --> 47:58.580]  обобщения сумм, так, значит, ну давайте проверим, значит, давайте проверим, почему это мартингал,
[47:58.580 --> 48:14.740]  значит, ну пусть, скажем, м, значит, пусть м больше n, так, и вот мы хотим взять условное среднее,
[48:14.740 --> 48:27.500]  значит, мы хотим взять условное среднее вот этой суммы, значит, относительно вот этой сигма-алгебры,
[48:27.500 --> 48:45.020]  ну из чего она эта сумма состоит, эта сумма состоит из суммы до n и оставшегося куска,
[48:45.020 --> 48:54.820]  ну сумма до n она будет, естественно, при взятии условного среднего себя воспроизводить,
[48:54.900 --> 49:09.420]  а дальше будет сумма условных, сейчас только я не то написал, вот смотрите, вот вы видите,
[49:09.420 --> 49:14.220]  вот почему нас все время обманывают, а видим какую-то лажу и, так сказать, спокойно,
[49:14.220 --> 49:29.780]  значит, да, начали как-то спокойно, значит, ее проглатываем, значит, а дальше здесь будет,
[49:29.780 --> 49:51.020]  вот и от всего этого остается только вот этот первый кусок, так, значит, остается первый кусок,
[49:51.020 --> 50:03.500]  значит, почему, потому что, вот это м, значит, вот это м, значит, почему, потому что условное
[50:03.500 --> 50:17.580]  среднее ксижитово относительно вот этой сигма-алгебры равно нулю при g больше n,
[50:17.580 --> 50:28.060]  ну почему так будет, значит, почему так будет, значит, откуда это видно, ну это, конечно,
[50:28.060 --> 50:37.260]  должно следовать из независимости их, так, из равенства нулю средних, так, но, значит,
[50:37.260 --> 50:48.740]  давайте посмотрим, почему так будет, ну потому что, значит, еще раз, значит, так как, потому что
[50:48.740 --> 51:03.180]  интеграл от ксижитово и от всякой функции вот такой вот, так, значит, от этих переменных, ну где
[51:03.180 --> 51:21.540]  фи-Борелевская, значит, фи-ограниченная Борелевская из-за независимости равен вот такому интегралу,
[51:21.540 --> 51:27.860]  ну и равен нулю из-за того, что у этих нулевые средние, а интеграл распадается, ну это,
[51:27.860 --> 51:33.220]  ну можно сказать, по определению независимости, вот, значит, значит, это, значит, это первый,
[51:33.220 --> 51:43.780]  значит, это первый, значит, очень важный пример Мартингала, значит, теперь, значит, второй пример,
[51:43.780 --> 51:53.300]  ну давайте, это будет первый пример, вот так его сделаем, так, значит, и теперь, значит,
[51:53.300 --> 52:00.860]  значит, и так первый пример суммы независимых, ну вот надо не забыть, правда, про средние, ну почему
[52:00.860 --> 52:09.780]  надо не забыть про средние, ну потому что если забыть про средние, то, конечно, нарушится вот это
[52:09.780 --> 52:18.620]  условие постоянства среднего, так, и это, ну это напоминает, что надо не забыть, но получается,
[52:18.620 --> 52:27.660]  что легко, когда средние не нули, то получается, что очень легко к этому перейти, ну нужно просто
[52:27.660 --> 52:35.260]  вычесть из независимых их средние, ну и складывать вот центрированные, так что, в общем-то, поэтому так
[52:35.260 --> 52:42.140]  вот обычно говорят без уточнения, что, значит, первый пример это суммы независимых, так, ну вот,
[52:42.140 --> 52:47.140]  если даже забыли, значит, про средние, ну потом, значит, подкорректируем, теперь второй важный
[52:47.140 --> 53:02.420]  пример, значит, пусть кси интегрируемая, так, значит, f от t, значит, f от t фильтрация,
[53:02.420 --> 53:21.820]  тогда кси t, которые по определению получены как условные средние, вот этой одной, это мартингал,
[53:21.820 --> 53:35.500]  так, то есть, видите, значит, второй пример, это вы берете одну, так сказать, случайную величину и
[53:35.500 --> 53:42.860]  ее проектируете на эти подпространства, ну и из определения очевидно, что это мартингал,
[53:42.860 --> 53:50.340]  ну если она из l2, то это просто очевидно из определения, потому что получаются такие вот
[53:50.340 --> 53:56.500]  протагональные проекции, а если она из l1, ну из свойства условного среднего, это получается,
[53:56.500 --> 54:08.100]  так, вот такие мартингалы исчерпывают, ну большинство, большинство, так сказать,
[54:08.100 --> 54:14.140]  ну я бы сказал так, большинство непривывных мартингалов, вот у нас дальше будет теорема,
[54:14.220 --> 54:27.860]  показывающая, что при широких условиях мартингал имеет такой вид, ну, например,
[54:27.860 --> 54:31.900]  например, ну вот забегаю, я это приведу, теорема, ну просто сейчас сразу скажу,
[54:31.900 --> 54:38.700]  например, если мартингал, то есть, если не мартингал, ну, если заранее дан мартингал,
[54:38.700 --> 54:49.780]  который просто равномерно ограничен, или у него дисперсия, скажем, дан мартингал с нулевым
[54:49.780 --> 54:56.140]  средним и равномерно ограниченными дисперсиями, вот у него тоже такое представление будет,
[54:56.140 --> 55:06.780]  значит, не всякий мартингал так сдается, вот можете придумать пример из пункта 1,
[55:06.780 --> 55:19.580]  так, ну, показывающий, что вот такая вот сумма, значит, такая сумма может не быть такого вида,
[55:19.580 --> 55:27.980]  так, ну, оно и понятно, почему, ну, почему у суммы такого может не быть, ну, в общем,
[55:27.980 --> 55:34.580]  вот в качестве примера придумайте такую ситуацию, когда вот это такая нарастающая сумма,
[55:34.740 --> 55:44.900]  вот так не получается, вот, значит, вот, значит, вот это два основных примера, и сейчас мы приведем
[55:44.900 --> 55:54.780]  третий пример, сейчас, значит, если я, сейчас, секундочку, значит, если я что-то еще не забыл,
[55:54.780 --> 56:13.420]  что хотел сказать про них, вот, значит, значит, вот еще, значит, еще одно замечание, ну,
[56:13.420 --> 56:28.780]  прежде чем будет следующий пример, значит, замечание, значит, если, значит, ксиате мартингал,
[56:28.780 --> 56:52.860]  и он квадратично интегрируем, то это процесс, это процесс с ортогональными,
[56:52.940 --> 57:05.900]  с ортогональными приращениями, ну, это значит следующее, что приращение,
[57:05.900 --> 57:29.820]  значит, приращение ортогонально, если вы берете, ну, вот такие вот, значит, точки последовательные,
[57:29.820 --> 57:38.520]  так, значит, ну, вот упражнение, докажите это, это, значит, очень несложное упражнение,
[57:38.520 --> 57:44.140]  которое надо сделать, чтобы, ну, так сказать, как-то понимать, что такое мартингалы, так,
[57:44.140 --> 57:50.700]  значит, но единственное, что обратите внимание, что так, чтобы так записать, конечно, надо,
[57:50.700 --> 57:56.340]  чтобы он был из l2, если мартингал не квадратично интегрируем, такой вопрос не возникает,
[57:56.340 --> 58:03.540]  значит, таким образом, видите, процесс с ортогональными приращениями, ну, это
[58:03.540 --> 58:11.420]  что-то такое послабее, чем процесс с независимыми приращениями, так, ну, вот скажем, если это
[58:11.420 --> 58:16.740]  гауссовский процесс, то это то же самое, а если не гауссовский, ну, это послабее, чем с независимыми
[58:16.740 --> 58:27.140]  приращениями, но с другой стороны, если, значит, процесс с независимыми приращениями в l2,
[58:27.140 --> 58:44.060]  так, то получается, значит, такая теорема, значит, пусть, значит, ксиат-т мартингал
[58:44.060 --> 59:01.740]  квадратично интегрируемый, так, пусть у него ксеноль постоянная, так, ну, давайте только вот так
[59:01.740 --> 59:07.620]  сделаем, чтобы ксеноль был, вот так сделаем его с неотрицательным временем, ксеноль постоянная и
[59:07.620 --> 59:25.260]  средняя тоже постоянная, так, значит, сейчас, я чушь написал, наоборот, это еще пока не мартингал,
[59:25.260 --> 59:35.260]  значит, это процесс с независимыми приращениями, процесс с независимыми приращениями,
[59:35.260 --> 59:45.060]  квадратично интегрируем и, значит, как, ну, полагается мартингалу с постоянным средним,
[59:45.060 --> 59:57.300]  тогда, значит, этот процесс мартингал, мартингал относительно чего, относительно
[59:57.300 --> 01:00:10.220]  порожденной им самим фильтрации, так, вот смотрите, всякий процесс согласован со своей фильтрацией,
[01:00:10.220 --> 01:00:16.460]  но отнюдь не всякий процесс будет мартингалом относительно порожденной им фильтрации, но это,
[01:00:16.460 --> 01:00:24.300]  в общем, довольно очевидно, значит, но оказывается, что процесс с независимыми приращениями будет
[01:00:24.300 --> 01:00:30.780]  мартингалом относительно порожденной им фильтрации, ну, тут вот еще технические условия, ну, они нужны,
[01:00:30.780 --> 01:00:39.660]  конечно, потому что среднее должно быть постоянного мартингала, значит, ну, чтобы говорить,
[01:00:39.660 --> 01:00:48.780]  значит, ну, здесь еще требуется, что он из L2, так, для независимости приращения это не требуется,
[01:00:48.780 --> 01:00:57.460]  а вот тут это требуется, так, и, ну, еще вот он выходит из нуля, ну, это можно немножко
[01:00:57.460 --> 01:01:04.980]  модифицировать, но вот формулировка, короче всего, так получается, значит, таким образом, ну,
[01:01:04.980 --> 01:01:14.660]  вот если пренебречь такими техническими мелочами типа того, что он в L2, там еще вот этими вещами,
[01:01:14.660 --> 01:01:23.020]  то получается, что мартингал это нечто среднее между процессом с независимыми приращениями и
[01:01:23.020 --> 01:01:33.700]  процессом с некоррелированными приращениями, вот видите, значит, вот одно условие, есть более
[01:01:33.700 --> 01:01:41.780]  сильная, значит, независимость, вот, значит, большинство общих мартингалов он где-то вот между этими
[01:01:41.780 --> 01:01:48.020]  двумя, ну, конечно, за рамки этого можно выйти, если брать неквадратично интегрируемый, так,
[01:01:48.020 --> 01:01:54.500]  так, что это, это, конечно, надо, так, ну, сказанное, так сказать, так воспринимать немножко,
[01:01:54.500 --> 01:02:03.860]  как, ну, такое, так сказать, не совсем точное утверждение, вот, ну, а точно и вот они, так,
[01:02:03.860 --> 01:02:13.420]  значит, ну, давайте, значит, так, сейчас, только надо сообразить, сейчас, я все время забываю время,
[01:02:13.420 --> 01:02:22.100]  нет, нет, время еще есть, да, значит, ну, я думаю, что это мы сейчас и докажем, даже кажется,
[01:02:22.100 --> 01:02:37.060]  меньше нужно, чтобы доказать, значит, значит, доказательства, значит, при S меньше T,
[01:02:37.060 --> 01:02:49.100]  значит, смотрите, что у нас будет, значит, условное среднее, значит, условное среднее, можно записать так,
[01:02:49.100 --> 01:02:58.100]  ну, тут, естественно, условия подсказывают, к чему надо стремиться, значит, надо делать из
[01:02:58.100 --> 01:03:03.860]  процессов, надо делать их приращение, так, но так просто нельзя заменить, значит, надо вот так
[01:03:03.860 --> 01:03:13.180]  заменить, так, значит, надо вот так заменить, теперь, значит, смотрите, что получается, получается,
[01:03:13.180 --> 01:03:23.060]  что из-за, значит, линейности среднего, условного среднего, вот эта штука выйдет, но она будет сама
[01:03:23.060 --> 01:03:38.740]  собой, и плюс еще будет, ну, вот от этой первой части будет, вот это, так, но вот это будет 0,
[01:03:38.740 --> 01:03:51.900]  почему, значит, почему это будет 0, так, потому что, значит, ну, давайте это докажем, значит,
[01:03:51.900 --> 01:04:15.260]  давайте это докажем, что почему будет 0, значит, а, значит, почему будет 0, а, значит,
[01:04:15.260 --> 01:04:20.660]  значит, ну, давайте, значит, я здесь это напишу,
[01:04:20.660 --> 01:04:40.740]  значит, почему это так, значит, ну, потому что
[01:04:40.740 --> 01:05:09.720]  кси t минус кси s независимо со всеми кси tau при tau меньше либо равном s, но это из-за того,
[01:05:09.720 --> 01:05:23.680]  что независимо с кси tau минус кси 0, а и кси 0 равняется нулю, значит, она вот это приращение
[01:05:23.680 --> 01:05:31.440]  независимо со всяким таким приращением, но из-за того, что кси 0 0, то другое приращение,
[01:05:31.440 --> 01:05:37.240]  оно просто кси tau, значит, получается, что вот эта штука независимо со всякой случайной величиной
[01:05:37.240 --> 01:05:45.000]  кси tau, ну, значит, независимо с сигма-алгебрами порожденной, то есть вот с этой вот, с этой так,
[01:05:45.000 --> 01:05:56.000]  значит, таким образом, значит, получается вот такой ответ. Так, теперь, значит, теперь,
[01:05:56.000 --> 01:06:16.320]  значит, давайте вам, значит, будет задача. Да, ну вот, например, какой из этого проистекает
[01:06:16.320 --> 01:06:35.280]  пример, значит, вот, значит, пример. Винеровский процесс, процесс WT-мартингал, а относительно,
[01:06:35.280 --> 01:06:54.000]  значит, порожденной им фильтрации. А по-асоновски, ну, как я уже говорил, нет. Ну и вот давайте,
[01:06:54.000 --> 01:07:11.120]  значит, задача, значит, задача, значит, пусть, пусть t это натуральное время, так, значит,
[01:07:11.120 --> 01:07:34.680]  FN фильтрация, значит, и, значит, процесс, значит, кси N-мартингал относительно нее, причем,
[01:07:34.680 --> 01:07:53.840]  значит, причем верно следующее, значит, значит, дисперсии равномерно ограничены. Значит, тогда,
[01:07:53.840 --> 01:08:17.320]  тогда существует кси из L2 такая, что они получаются условными средними, значит, этой кси. Так, ну,
[01:08:17.320 --> 01:08:24.280]  это такая вот, как бы, это задачка, так сказать, про проекторы в Гильвертовом пространстве, можно
[01:08:24.280 --> 01:08:42.920]  сказать. Так, и, значит, значит, без доказательства, значит, без доказательства вот такая теорема,
[01:08:43.040 --> 01:08:52.000]  которая усиливает эту задачу. Ну, впрочем, нельзя сказать, что это какая-то уж очень такая жестокая
[01:08:52.000 --> 01:09:02.480]  теорема. Ну, в принципе, если бы лекция была 25, то такую теорему можно было бы и доказать,
[01:09:02.480 --> 01:09:11.040]  то есть она вполне себе укладывается, значит, в те результаты, которые можно доказывать,
[01:09:11.040 --> 01:09:18.160]  но вот когда лекции меньше полутора десятков, то, значит, такие вещи лучше оставлять без
[01:09:18.160 --> 01:09:30.920]  доказательств, хотя теорема очень важная. Значит, теорема дуба о сходимости мартингалов.
[01:09:30.920 --> 01:09:49.760]  Ну, дуб это был такой математик американский, но дуб, он не случайный дуб, он чешского
[01:09:49.760 --> 01:10:01.880]  происхождения, и когда он был, значит, еще у себя на родине, ну, а он где-то там в тридцатых
[01:10:01.880 --> 01:10:07.920]  годах прошлого века перебрался в Америку, то он таки был просто дуб, ну и писался, ну вот был
[01:10:07.920 --> 01:10:18.240]  наш обычный дуб, но когда он, значит, перебрался в Америку, ему не понравилась транскрипция вот
[01:10:18.240 --> 01:10:30.040]  этого дуба через ю, потому что многие американцы стали его называть дабом, и он поэтому такой вот,
[01:10:30.040 --> 01:10:37.760]  так сказать, ну как бы французский вариант избрал написание, ну и вот стал, так сказать, стал дубом,
[01:10:37.760 --> 01:10:45.120]  таким вот. Ну, а по-русски он, вот как был дуб, так и остался. Значит, теорема вот какая,
[01:10:45.120 --> 01:10:53.920]  значит, пусть ксиен, значит, это вот, так сказать, один из отцов-основателей вот всей этой науки
[01:10:53.920 --> 01:11:06.800]  мартингальной, значит, пусть ксиен мартингал относительно вот этой вот фильтрации,
[01:11:06.800 --> 01:11:29.200]  значит, где n, значит, натуральная. Значит, этот мартингал, мартингал сходится в l1,
[01:11:29.200 --> 01:11:51.640]  значит, в точности тогда, значит, в точности тогда, когда существует такая функция кси из l1,
[01:11:51.640 --> 01:12:05.840]  которая дает, которая дает, значит, ну вот по этой технологии, значит, все эти, значит, функции.
[01:12:05.840 --> 01:12:21.000]  При этом, при этом ксиенная сходится к этой кси еще и почти всюду. Тут, значит,
[01:12:21.000 --> 01:12:31.720]  основное утверждение про, когда он сходится в l1, так, то есть вот получается так, а, значит,
[01:12:31.720 --> 01:12:42.280]  существование вот такой порождающей одной функции, порождающей всех, это есть просто ситуация,
[01:12:42.280 --> 01:12:52.280]  когда исходный мартингал к чему-то сходился в l1, так, но если он сходится в l1, то он сходится и
[01:12:52.280 --> 01:13:00.680]  почти всюду, так, а вот тут важно, что первичная сходимость в l1, значит, если он просто сходился
[01:13:00.680 --> 01:13:08.680]  почти всюду, то это еще не означает всего этого, так, так что здесь все-таки, ну, такая основная
[01:13:08.680 --> 01:13:18.120]  сходимость в l1, а вот это второе утверждение, ну, это такой, так сказать, дополнительный бонус за
[01:13:18.120 --> 01:13:24.600]  эту сходимость, значит, он ей не равносилен, но он присутствует, потому что, вообще говоря, из
[01:13:24.600 --> 01:13:30.840]  сходимости интегральной, ну, обычно не следует сходимость почти всюду, там интегралы могут
[01:13:30.840 --> 01:13:36.680]  сходиться к нулю, а функции вовсе не обязательно сходиться к нулю, но вот в этой специфической
[01:13:36.680 --> 01:13:48.040]  ситуации оказывается, что и, ну, есть сходимость почти всюду, ну, еще можно заметить, что, значит,
[01:13:48.040 --> 01:14:10.840]  сходимость в l1 равносилена также такому, что называется равномерная интегрируемость,
[01:14:10.840 --> 01:14:19.480]  значит, вот я давайте здесь выпишу, но это уже, так сказать, дополнение, это не в самой теореме,
[01:14:19.480 --> 01:14:25.120]  а это тоже, так сказать, полезное дополнение, к чему это равносильно, это равносильно вот к чему,
[01:14:25.120 --> 01:14:36.520]  что когда, значит, возьмем интеграл вот такой по множеству, где это больше либо равно r,
[01:14:37.200 --> 01:14:52.200]  возьмем sup по этим n, и тогда вот это должно стремиться к нулю, когда r идет в плюс бесконечность,
[01:14:52.200 --> 01:15:08.640]  так вот, и это же еще равносильно вот к чему, что существует выпуклая функция v, такая,
[01:15:08.640 --> 01:15:22.720]  которая растет на бесконечности быстрее t, такая вот функция, которая на бесконечности растет
[01:15:22.720 --> 01:15:43.040]  быстрее t, такая, что интегралы вот от этих вот v от xn, значит, равномерно ограничены, ну вот,
[01:15:43.040 --> 01:15:49.680]  поэтому ваша задача, но она более простая, чем теорема дуба, но она вот охватывается этим случаем,
[01:15:49.680 --> 01:15:58.160]  потому что как раз ваши задачи вот этой предыдущей, где квадраты были, интегралы от квадратов были
[01:15:58.160 --> 01:16:06.000]  ограничены, ну она соответствует функции v от t, t квадрат, но вот из этого дополнения видно,
[01:16:06.000 --> 01:16:13.720]  что годится какая угодно выпуклая функция, ну вот t не годится, значит, смотрите, а ограниченности
[01:16:13.800 --> 01:16:27.480]  ограниченности v1 мало, так, значит, вот давайте это будет упражнение, ограниченности v1 мало,
[01:16:27.480 --> 01:16:38.160]  из нее не следует, но если есть ограниченность чуть-чуть лучше, чем v1, значит, вот там vlp каком-то
[01:16:38.160 --> 01:16:47.640]  там с p чуть больше 1, то уже все окей, вот, значит, так, значит, это кажется,
[01:16:47.640 --> 01:17:02.840]  значит, это кажется все, что я хотел сказать про мартингалы, а вот еще задача, вот еще тоже
[01:17:02.840 --> 01:17:31.800]  полезная задача, значит, так, ну давайте вот это я сотру, значит, задача, значит, пусть
[01:17:31.800 --> 01:17:47.080]  значит опять процесс с независимыми приращениями, так, значит, с неотрицательным
[01:17:47.080 --> 01:17:59.400]  временем, с независимыми приращениями, так, и пусть, ну пусть он выходит из нуля и давайте
[01:17:59.400 --> 01:18:12.280]  сразу его сделаем с нулевым средним, значит, вот такой процесс, тогда вот такой вот процесс
[01:18:12.280 --> 01:18:22.680]  нелинейный, видите, такое нелинейное преобразование процесса с независимым,
[01:18:22.680 --> 01:18:31.680]  значит, ну мы знаем, что сам, значит, да, да, еще, ну еще, еще важно, конечно, это я тут имею в виду,
[01:18:31.680 --> 01:18:38.040]  но давайте явно запишу, значит, он еще и из l2, значит, смотрите, значит, мы разобрали,
[01:18:38.040 --> 01:18:43.560]  что он сам будет мартингалом, так, значит, он был с независимыми приращениями, он сам был
[01:18:43.560 --> 01:18:49.440]  мартингалом, но оказывается, не только, значит, вот, ну, что он сам мартингал, еще вот такой
[01:18:49.440 --> 01:19:01.720]  процесс, тоже мартингал относительно, ну, порожденной им фильтрации, так, ну вот, в частности,
[01:19:01.880 --> 01:19:13.800]  смотреть, что получается, значит, если в качестве процесса, ну вот мы уже знаем, что винаровский
[01:19:13.800 --> 01:19:20.240]  процесс мартингал, так, из-за того, что он подпал под этот пример с независимыми приращениями,
[01:19:20.240 --> 01:19:28.360]  но получается еще один интересный пример мартингала, такой довольно неочевидный, значит, ну вот, например,
[01:19:28.360 --> 01:19:45.760]  значит, если wt винаровский, то тогда wt в квадрате минус t мартингал, вот, это так сразу не очень
[01:19:45.760 --> 01:19:54.400]  очевидно, ну вот, например, совершенно очевидно, что wt в квадрате не мартингал, так, ну хотя бы
[01:19:54.400 --> 01:20:04.720]  потому, что среднее непостоянно, так, но оказывается, что вычитанием среднего получается мартингал,
[01:20:04.720 --> 01:20:13.160]  то есть вот, ну, здесь тоже, видите, какая ситуация, сам процесс, ну, вообще говоря, не мартингал такой
[01:20:13.160 --> 01:20:21.840]  в квадрате, а тут сделали банальную вещь, вычли, ну, просто сделали его центрированным, сделали нулевое
[01:20:21.840 --> 01:20:30.080]  среднее, и вдруг оказалось, что это мартингал после вычитания, ну, конечно, ситуация специфическая,
[01:20:30.080 --> 01:20:35.440]  к сиатте, конечно, никакой угодно был процесс, он был с независимыми приращениями, это, конечно,
[01:20:35.440 --> 01:20:42.280]  очень важно, но, тем не менее, такой довольно неожиданный эффект, значит, вот тоже задача, ну,
[01:20:42.280 --> 01:20:47.760]  я бы сказал, не сложная, но полезная, в общем, значит, ее, значит, хорошо бы ее сделать, так, и,
[01:20:47.840 --> 01:20:55.960]  значит, сейчас, но вот сейчас, кажется, уже время кончается, правильно? Да, ну, давайте,
[01:20:55.960 --> 01:21:04.680]  давайте не буду следующую важную вещь начинать, потому что, ну, вот еще будет одна теорема,
[01:21:04.680 --> 01:21:09.520]  связанная с Дубом и его учеником, Полем Андреемиером, но это давайте в следующий раз,
[01:21:09.520 --> 01:21:14.600]  потому что, ну, как-то вроде нехорошо, важную вещь в ППХ в конце, но хотя, с другой стороны,
[01:21:14.840 --> 01:21:19.840]  Штирлиц учил нас, что последняя фраза запоминается лучше всего, так что, в общем,
[01:21:19.840 --> 01:21:26.400]  тут не поймешь, кого слушать, Штирлиц или методистов, так, все, давайте на этом закончим.
