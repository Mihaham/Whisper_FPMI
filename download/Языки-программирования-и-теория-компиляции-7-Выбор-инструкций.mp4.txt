[00:00.000 --> 00:09.000]  Так, всем доброго дня, мы с вами продолжаем наш курс занятий. Сегодня у нас дождик, поэтому,
[00:09.000 --> 00:16.440]  возможно, у нас смена антуража. Вот, мы сегодня с вами наконец-таки пойдем в БК. Мы начнем
[00:16.440 --> 00:23.600]  разбирать именно такую тему под названием Low Reconstruction. Итак, значит, где мы с вами находимся,
[00:23.600 --> 00:35.920]  давайте вспомним, сравнить с предыдущими частями. Где мы с вами находимся? Ну, это понятное дело,
[00:35.920 --> 00:43.040]  что мы в 113 ГК находимся. Да, значит, смотрите, у нас был LWM, и по факту мы с вами уже некоторый
[00:43.040 --> 00:49.520]  набор Basic блоков объединили в следы для того, чтобы минимизировать количество джампов. Николай
[00:49.640 --> 00:59.560]  смотрит. Это когда мы несколько блоков объединяем в одну общую конструкцию. Да, трейсы.
[00:59.560 --> 01:12.800]  То есть, у нас есть Basic блоки, мы их объединяем в трейсы, чтобы, если мы хотим куда-то прыгать,
[01:12.800 --> 01:18.080]  мы могли бы прыгать именно в другое место. Хорошо, значит, опять у нас экран моргает,
[01:18.080 --> 01:26.440]  но я думаю, что мы с этим ничего не сделаем. Итак, значит, вот у нас есть такой блок. Видимо,
[01:26.440 --> 01:31.720]  тут нет нашей замечательной картинки, я ее забыл вставить. Вот, и мы сегодня начинаем как раз
[01:31.720 --> 01:38.120]  говорить про Backend, и про Backend мы будем говорить с вами в трех контекстах. Первый контекст будет
[01:38.120 --> 01:44.200]  заключаться в том, что нам нужно будет, во-первых, понять, какие наборы инструкции мы с вами используем,
[01:44.200 --> 01:50.280]  и вообще здесь как раз начинает играть большую роль зависимость от той архитектуры, под которую мы
[01:50.280 --> 01:55.600]  компилируем, потому что у нас есть RISC архитектуры, у нас есть CISC архитектуры, и в зависимости от
[01:55.600 --> 02:01.240]  этого Backends будут сильно различаться. Даже более того, они будут различаться до такой степени,
[02:01.240 --> 02:10.320]  что одну из стадий, одну из архитектур можно практически пропустить. Ну, поэтому и то же.
[02:10.320 --> 02:27.720]  Ну да, есть. Есть. Ну да. Вот, то есть смотрите, у нас с вами по факту, можно сказать, что у нас есть
[02:27.720 --> 02:34.680]  ER дерево для блока, либо у нас с вами есть trace. И на выходе нам нужно на самом деле займить эти
[02:34.680 --> 02:41.280]  наборы инструкции Assembler, в котором число регистров в данной степени будет бесконечным. То есть мы
[02:41.280 --> 02:48.240]  пока что не выходим за пределы виртуальности наших регистров. То есть наши регистры становятся
[02:48.240 --> 02:53.920]  чуть менее виртуальными, чем фактически, потому что в VR мы видели с вами, что виртуальные регистры
[02:53.920 --> 03:00.800]  могут иметь произвольный тип. А здесь, к сожалению, уже был тип непроизвольный. И, значит, мы с
[03:00.800 --> 03:08.120]  вами разберем как раз на основе примеров тему под названием паттерны покрытия. То есть как раз,
[03:08.120 --> 03:14.080]  смотрите, по факту, что у нас с вами есть. У нас, если честно, попробовать все инструкции представить,
[03:14.080 --> 03:20.320]  у нас с вами будет ER дерево. Да, то есть у нас есть выражение, у нас есть присваивание и так далее. И
[03:20.320 --> 03:26.040]  вот как раз в данном случае очень удобно будет снова вернуться к представлению ER в виде дерева,
[03:26.040 --> 03:31.600]  потому что, как ни странно, мы сейчас будем как раз покрывать наше дерево другими маленькими кустами.
[03:31.600 --> 03:39.600]  Давайте откроем страницу. Здесь есть как раз вот такой вот Assembly Instruction. Это достаточно
[03:39.600 --> 03:47.000]  давний язык, 2007 год. И давайте как раз познакомимся с набором инструкций, которые здесь нам предлагают
[03:47.000 --> 03:54.000]  освоить. То есть, смотрите, по факту, здесь есть у нас некоторый язык Assembler, в котором у нас с
[03:54.000 --> 04:02.400]  вами инструкция состоит из некоторых из Operation Code. И дальше есть набор регистров, которые мы с вами
[04:02.400 --> 04:10.480]  можем применять. То есть, у нас с вами есть операции классические, есть операции с сайд-эффектами.
[04:10.480 --> 04:16.680]  Значит, и смотрите, какие у нас инструкции есть. Тут важно сразу, что если мы с вами работаем в
[04:16.680 --> 04:24.240]  концепции ER, то у нас нет никакой по факту стоимости нашей инструкции. Ну, она на самом деле есть,
[04:24.240 --> 04:30.360]  если мы хотим сделать какую-то оптимизацию. Здесь мы можем уже на уровне, так сказать, Assembler понять
[04:30.360 --> 04:35.880]  каждую инструкцию, сколько стоит. То есть, взять, допустим, ту же самую спецификацию микропроцессора,
[04:35.880 --> 04:41.560]  там, если она есть, и через нее как раз прогнать эти стоимости. Итак, давайте посмотрим на некоторые
[04:41.560 --> 04:49.120]  инструкции и поймем, что они делают. Значит, здесь первая инструкция – это арифметические операции.
[04:49.120 --> 04:56.600]  Давайте подумаем, почему здесь у нас стоимости, скорее всего, такие. То есть, на сложение вычитания
[04:56.600 --> 05:05.120]  два, на умножение деления 5 и 10. Так-то, да, это такты процессорного времени, которые нам нужны.
[05:05.120 --> 05:19.600]  Пока нет конвейерность на следующих стадиях. То есть, пока что нам ценность инструкции надо сделать.
[05:19.600 --> 05:25.560]  Хорошо, то есть, вот у нас получается есть регистры, значит, у нас два операнта, мы делаем либо плюс,
[05:25.560 --> 05:31.960]  либо умножить, либо минус, либо поделить. Следующая инструкция – add increment. Значит,
[05:31.960 --> 05:38.560]  добавляет константное значение, и видно здесь важная особенность в том, что константу вычислить
[05:38.560 --> 05:48.520]  намного проще. Да, то есть, прибавить константу сильно проще. Дальше у нас есть, значит, вот такой
[05:48.520 --> 05:56.160]  язык. Опять же, он не классический ассемблер. У нас есть язык move, инструкция move a, которая позволяет
[05:56.160 --> 06:02.920]  по факту получить адрес pointer, который указывает на датарегистре, и можем расшифровать наши
[06:02.920 --> 06:10.520]  инструкции. То есть, у нас тоже есть инструкции по два, они стоят два такта. А дальше есть вот такая
[06:10.520 --> 06:20.200]  операция, она позволяет сделать следующее. Мы загружаем значение из памяти по указателю agt
[06:20.200 --> 06:28.080]  плюс c. То есть, мы передвигаем указатель pointed плюс адрес регистр, плюс сдвиг делаем на датарегистр.
[06:28.080 --> 06:36.760]  Скажите, пожалуйста, в каких случаях эта операция может пригождаться. То есть, сдвиг по значению,
[06:36.760 --> 06:50.040]  плюс некоторый константный сдвиг. Это инструкция load. Во-первых, для полиэструктур. Еще где?
[07:00.920 --> 07:03.360]  Ну да, но то же самое в принципе.
[07:07.760 --> 07:18.400]  Ну да. А, немножко другая инструкция. Ну в целом, да. Ну тут надо смотреть, кстати, под back-end,
[07:18.400 --> 07:24.760]  какая из инструкций подойдет. А дальше у нас есть операция store. То есть, у нас есть, можем хранить
[07:24.760 --> 07:29.880]  данные в нашем регистре сдвинутые на определенную операцию. То есть, это оператор присваивания.
[07:29.880 --> 07:37.600]  И смотрите, самая тяжелая операция, которая здесь есть, это операция move memory. То есть,
[07:37.600 --> 07:45.280]  сцена перемещает память из одного регистр в другой участок памяти.
[07:55.600 --> 07:59.560]  Ну да, вот в принципе сверху и видно, что она выражается через две таких.
[07:59.560 --> 08:08.320]  Не-не-не, она двигает один the word. Она просто одно слово двигает.
[08:08.320 --> 08:23.400]  Ну да. Ну пока что мы работаем с интами. У нас пока что все, что есть, это инты. Так,
[08:23.400 --> 08:31.000]  хорошо. А теперь смотрите, важная особенность этого языка. Если у нас здесь conditional jumper.
[08:31.000 --> 08:38.760]  Видно, что здесь jump не conditional. То есть, мы можем прыгнуть. А? То есть, мы можем...
[08:38.760 --> 08:49.040]  conditional jumper имеется, который разбегается на два basic блока. То есть, если у нас в VR был
[08:49.040 --> 08:56.240]  conditional jump в две метки, то есть, либо с веткой true, либо с веткой false, то здесь jump идет только,
[08:56.240 --> 09:01.840]  если определенное условие выполнено. То есть, как раз для этого мы и делали trace, чтобы мы
[09:01.840 --> 09:07.960]  отклонялись от основного trace. И соответственно conditional jump будет весить меньше, чем классический
[09:07.960 --> 09:18.560]  jump. То есть, получается, что мы экономим инструкцию. Так, ну и простой оператор go to, оператор jump,
[09:18.560 --> 09:24.560]  он позволяет прыгнуть как раз в определенное значение. Следующая инструкция, которая у нас
[09:24.560 --> 09:31.680]  с вами есть, это инструкция call. То есть, мы по факту перемещаемся в метку m и при этом запоминаем
[09:31.680 --> 09:38.720]  return location. То есть, грубо говоря, это вызов функции. Вот оно у нас стоит пять поинтов. Да, то есть,
[09:38.720 --> 09:45.560]  как бы вызвать функцию иногда, конечно, полезно, но иногда полезно ее заинлайнить, чтобы, собственно,
[09:45.560 --> 09:54.560]  у нас не было вот таких вот операций. Значит, return будет стоить 3. И установка метки будет стоить
[09:54.560 --> 10:15.560]  нулечков. Ну, на самом деле, да. Ну, почему он... Ну, в смысле два кола. Ну, да. Ну, понятно,
[10:15.560 --> 10:26.240]  что это... А? Ну, это да. Ну, в целом, вот такой язык. Вот. Ну, и, собственно, здесь указывается,
[10:26.240 --> 10:33.160]  допустим, для этого языка, типа какой размер слова. То есть, у нас размер слова всегда равен единичке.
[10:33.160 --> 10:38.720]  То есть, здесь у нас по факту есть чара. Да, ну, понятно, что для интов это тоже можно адаптировать и
[10:38.720 --> 10:42.920]  посмотреть, сколько у нас стоимость. Значит, у нас есть дейты регистра, у нас есть адресные
[10:42.920 --> 10:50.480]  регистры. Да, то есть, видите, есть развлечение. И есть программа каунта. Есть указатель нас так.
[10:50.480 --> 11:00.120]  То есть, в принципе, мы можем обращаться к этим. Так, по вот этой спецификации все понятно? А теперь
[11:00.120 --> 11:06.120]  давайте перерисуем это все в виде дерева. Значит, в виде дерева это будет выглядеть вот таким вот
[11:06.120 --> 11:10.760]  образом. То есть, у нас есть операция add, и мы видим, что это как раз у нас add-оператор. То есть,
[11:10.760 --> 11:17.560]  у него есть вершина плюсик, и снизу он подцепляет два других оператора. А оператор mull это оператор
[11:17.560 --> 11:22.760]  перемножения. То есть, у нас есть перемножение двух операторов. Оператор add-i, он является вот таким.
[11:22.760 --> 11:28.800]  То есть, у нас есть Rit равно Rgt плюс c. И, соответственно, у нас получается с вами три возможных варианта действий.
[11:28.800 --> 11:38.640]  Дальше, операция load, она у нас может редуцироваться. Значит, это либо Rit равно m от mem. То есть, это как
[11:38.640 --> 11:44.760]  раз вот эти вот операции, помните, mem, move и так далее, которые были в VR. То есть, это то, как эти
[11:44.760 --> 11:51.480]  инструкции будут у нас транслироваться в VR. Значит, это либо mem от Rit плюс const, либо mem const
[11:51.480 --> 11:58.560]  плюс Rit, либо mem от const, то есть, в качестве регистра мы игнорируем информацию, либо просто оператор mem.
[11:58.560 --> 12:08.600]  Соответственно, оператор store, видно, что в VR дереве стоит достаточно дорого. То есть, как бы, нам нужно
[12:08.600 --> 12:15.360]  собственно сделать mem, потом сделать move. То есть, он стоит 10 очков. И move mem это move от
[12:15.360 --> 12:21.280]  move mem. То есть, в принципе, наша цель, первая, которая заключается в покрытии инструкций,
[12:21.280 --> 12:27.760]  это взять все наши конструкции промежуточного представления, взять все наши конструкции
[12:27.760 --> 12:36.240]  ассемблера, которые у нас есть, и переложить, попытаться построить их в VR дереве. Да, вот чем мы
[12:36.240 --> 12:43.200]  должны в целом заниматься на этой стадии. А дальше, если у нас есть стоимость инструкций,
[12:43.200 --> 12:49.440]  то мы можем выполнять разные покрытия. Вот смотрите, здесь есть некоторый пример того, каким
[12:49.440 --> 12:54.920]  образом мы можем превратить вот этот вот набор инструкций. То есть, у нас, как бы, есть вот такое VR
[12:54.920 --> 13:01.640]  дерево. Это у нас AssignIndexStatement. То есть, мы говорим, что у нас а и тому нужно присвоить какое-то значение
[13:01.640 --> 13:09.120]  х. Давайте посмотрим на эти два разбиения. Собственно, в первом разбиении мы берем frame
[13:09.120 --> 13:17.320]  pointer и получаем значение регистра на константу а. То есть, это наш массив. То есть, первая
[13:17.320 --> 13:24.000]  операция здесь это load. Вот она, это вторая инструкция. После этого мы должны с вами сделать
[13:24.000 --> 13:32.680]  следующее. К константу сделать четвертую инструкцию, которая прибавит к R0 значение 4. То есть,
[13:32.680 --> 13:40.160]  возьмем значение нашего указатель. Дальше, значит, мы должны будем перемножить R1 и R2. Да, то есть,
[13:40.160 --> 13:48.400]  вот так вот, вот так. Да, R0 это регистр, в котором всегда 0 сидит. Константа 0. Опять же,
[13:48.400 --> 13:53.840]  взятия константа. Просто вот такой R. Интересно. Дальше мы берем перемножение. Дальше мы берем
[13:53.840 --> 14:00.680]  сложение. То есть, R1 это R1 плюс R2. То есть, вот он оператор. После этого вот это вот у нас
[14:00.680 --> 14:07.680]  получается значение нашего элемента массива. Дальше мы загружаем значение нашего значения
[14:07.680 --> 14:14.000]  нашего x и делаем операцию store. То есть, мы прямо берем и присваиваем значение нашему массиву. То
[14:14.000 --> 14:19.720]  есть, вот такая инструкция. Мы можем это переписать по-другому и сказать, что давайте вместо того,
[14:19.720 --> 14:25.280]  чтобы сделать операцию load по хрейнфоитору плюс x, мы сделаем сразу операцию addE. То есть,
[14:25.280 --> 14:32.040]  прибавим это значение по константе, а потом сделаем moveMe. Попрос. Как вы думаете,
[14:32.040 --> 14:37.680]  какая из операций стоит дороже? Какое из покрытий? То есть, у нас получается,
[14:37.680 --> 14:43.800]  для каждого объекта и R у нас может быть, каждого дерева и R у нас может быть несколько покрытий
[14:43.800 --> 14:53.400]  ассамблярными инструкциями. Значит, у нас есть loadStore и addE moveM.
[15:13.800 --> 15:28.120]  Сделано. Так, давайте оценивать. Как мы это оценим? Нам нужно посмотреть на инструкции.
[15:28.120 --> 15:35.680]  Так, давайте поймем. Сколько у нас load стоит?
[15:35.680 --> 15:55.800]  Store, moveM. А здесь addE неважно сколько стоит, это любое всё больше нуля и мы видим с вами,
[15:55.800 --> 16:12.520]  что нам выгоднее не использовать moveNem, а использовать addE и констант. Хорошо. То есть,
[16:12.520 --> 16:19.280]  вот такое вот у нас покрытие получилось. И здесь возникает некоторое понятие. Смотрите,
[16:19.400 --> 16:26.840]  у нас есть код, у нас есть дерево и у нас может быть несколько покрытий. Соответственно,
[16:26.840 --> 16:32.400]  мы можем попробовать склассифицировать эти покрытия. Каким образом мы можем склассифицировать?
[16:32.400 --> 16:42.640]  Значит, смотрите, здесь делается следующая вещь. Мы с вами можем построить наилучшее покрытие. То
[16:42.640 --> 16:48.920]  есть, что означает наилучшее покрытие? Это покрытие, которое имеет наименьший вес. Дальше,
[16:48.920 --> 16:55.840]  оптимальное покрытие. Это покрытие, в котором любые два соседних паттерна не могут быть
[16:55.840 --> 17:03.640]  преобразованы паттерном с меньшей суммой весов. Вот, кстати, если мы воспользуемся вот этой
[17:03.640 --> 17:13.000]  инструкцией addE и moveMem по сравнению с load и store, то это будет, смотрите, это будет не оптимальным и
[17:13.000 --> 17:19.600]  не оптимальным покрытием и не наилучшим покрытием. Почему вот эта инструкция не будет наилучшим покрытием?
[17:19.600 --> 17:30.240]  Ну, вот, moveMem и addE. Ну, потому что есть инструкция, которая весит меньший вес.
[17:30.240 --> 17:45.600]  Ну, а почему оно не будет оптимальным? А? А оно не будет оптимальным, посмотри, ровно по вот этой причине,
[17:45.600 --> 17:54.680]  я сейчас помечу экране. Если бы это покрытие было бы не оптимальным, то бы мы не могли взять вот
[17:54.680 --> 18:01.040]  эти вот две инструкции, которые я обвожу, да, 9 и 8, и преобразовать их в набор инструкций с меньшим
[18:01.040 --> 18:08.120]  весом. Вот конкретно две соседних. А здесь мы как раз, смотрите, берем две соседних инструкции и
[18:08.120 --> 18:22.880]  как раз распиливаем их по-другому. То есть если бы такую вот эту инструкцию нельзя было бы склеить
[18:22.880 --> 18:30.880]  и снова расклеить с меньшим весом, то такая конструкция была бы оптимальной. Вот, и обычно,
[18:30.880 --> 18:37.440]  когда мы строим компилятор, мы строим все-таки оптимальное покрытие, а не наилучшее. Почему,
[18:37.440 --> 18:55.280]  как вы думаете? Ну да, ее нельзя решить достаточно быстро, поэтому мы стараемся хоть какое-то покрытие
[18:55.280 --> 19:00.960]  найти, ну, грубо говоря, чтобы у нас каких-то прямо очевидных оптимизаций не возникало. Вот,
[19:00.960 --> 19:06.840]  поэтому мы будем искать как раз с вами оптимальное покрытие. Так, хорошо, мы строим оптимальное
[19:06.840 --> 19:13.160]  покрытие, и здесь как раз возникает алгоритм, который начинает с следующего. Это алгоритм
[19:13.160 --> 19:20.200]  максимального покрытия. Он строит оптимальное покрытие, и он называется, по факту, является жадным
[19:20.200 --> 19:25.640]  алгоритмом. То есть что мы делаем? Мы начинаем с корня дерева, добавляем ее в очередь, и дальше
[19:25.640 --> 19:30.360]  делаем следующее. Мы пытаемся выбрать паттерн с наибольшим количеством вершин, при этом при
[19:30.360 --> 19:36.400]  равенстве количестве вершин выбираем произволь. Вот, и дальше этот паттерн, узлы этого дочернего
[19:36.400 --> 19:42.200]  процесса, добавляем в очередь. Вот, в этом очередь можно заменить на рекурсивный выход.
[19:42.200 --> 19:49.960]  Вот, при этом можно заметить в целом, что такое дерево сойдет. То есть мы как бы идем не от корня
[19:49.960 --> 19:55.400]  к вершине, а не от вершины к корню, а от корня к вершине. Соответственно, если у нас есть оптимальный
[19:55.400 --> 20:00.880]  набор инструкций, то так или иначе у нас дерево сойдется в какой-то момент времени. Единственное,
[20:00.880 --> 20:07.240]  сразу тут нужно сказать, что этот алгоритм в принципе может обладать нерекурсивным свойств,
[20:07.240 --> 20:14.120]  свойств именно связанных с откатом, потому что мы в принципе можем с вами дойти до определенного
[20:14.120 --> 20:22.840]  момента и дальше не подниматься для этого выхода. Вот, собственно, это вот алгоритм, который
[20:22.840 --> 20:29.680]  позволяет найти оптимальное покрытие. Понятен? То есть тут тупой жадный алгоритм. Мы пытаемся
[20:29.680 --> 20:36.600]  присоединиться сверху вниз. Хорошо, другой вариант это динамическое программирование. И что
[20:36.600 --> 20:40.960]  позволяет сделать динамическое программирование? Динамическое программирование позволяет найти
[20:40.960 --> 20:49.720]  наилучшее покрытие. То есть как бы он идет снизу вверх. И идея такая, что мы по факту можем с вами
[20:49.720 --> 20:58.800]  сказать следующее. Давайте в вершине каждого дерева будем хранить паттерн с его детьми. То
[20:58.800 --> 21:05.720]  есть сколько занимает сейчас в текущий момент покрытие оптимальный паттерн. И дальше мы что с
[21:05.720 --> 21:11.640]  вами делаем? Мы говорим, что вес покрытия паттерн, потенциал покрытия паттерна, это значит его значение,
[21:11.640 --> 21:16.320]  плюс значения, которые висят на груздах его детей. Понятно, что если у нас какой-то паттерн не
[21:16.320 --> 21:23.400]  покрывается дочерним, то мы считаем, что вес этого паттерна бесконечный. И в итоге мы с вами
[21:23.400 --> 21:30.400]  выбираем покрытие наименьшего веса. По идее оно является наилучшим, но по факту нужно смотреть
[21:30.400 --> 21:35.840]  аккуратно с набором инструкций. Потому что, грубо говоря, несмотря на то, что у нас есть линейные
[21:35.840 --> 21:44.400]  инструкции, то что делать с фи-инструкциями это хороший вопрос. Потому что нам нужно взять
[21:44.400 --> 21:51.360]  определенные значения. И вот такие инструкции, по которых у нас код не является линейным,
[21:51.360 --> 22:03.640]  как его покрывать? Хороший вопрос. Поэтому если у вас фи-инструкции нет, то динамическое
[22:03.640 --> 22:08.480]  программирование подходит. Если у нас нету фи-инструкции, точнее, наоборот, если у нас
[22:08.480 --> 22:14.520]  есть фи-инструкция, то, к сожалению, этот алгоритм может не работать. А, в принципе, подход,
[22:14.520 --> 22:22.920]  который берет сверху вниз, он позволяет получить правильное значение. Так, смотрите, здесь как
[22:22.920 --> 22:28.840]  раз показывается алгоритм, который заключается в том, что у нас с вами есть вот такой оперант.
[22:28.840 --> 22:40.280]  Это у нас алгоритм, который идет связанный именно с дочерним снизу вверх. Итак, смотрите,
[22:40.280 --> 22:44.520]  значит, первый способ, которым мы можем двигаться, это мы берем, складываем что-то
[22:44.520 --> 22:53.080]  со константы, мы получаем вес один. При этом лифт-кост тоже будет один. То есть взятие константа
[22:53.080 --> 23:01.600]  это тоже один такт. И второй шаг, который мы можем сделать, то есть мы оцениваем значение
[23:01.600 --> 23:07.440]  операнда плюс. Значение операнда плюс это значение суммы операнда, которое у нас имеется. И вот этот
[23:07.440 --> 23:15.120]  плюс он как раз нам дает в итоге значение либо три, если мы возьмем add и возьмем отдельно две
[23:15.120 --> 23:22.280]  константы, либо add и, когда мы говорим, что мы можем прибавить какое-то число заранее. Вот,
[23:22.280 --> 23:26.640]  в итоге у нас получается вес либо три, либо два, либо два. Соответственно, мем дальше это
[23:26.640 --> 23:33.080]  инструкция load. И тут все зависит на самом деле от того, какой load мы сделаем. Мы можем сделать
[23:33.080 --> 23:39.040]  load тупой, который загрузит определенные значения только. Мы можем сделать умнее. Мы можем взять
[23:39.040 --> 23:45.880]  операцию load, которая берет значение и складывает его с константой. То есть это классический оператор
[23:45.880 --> 23:51.800]  load. А здесь у нас как раз регистр, который позволяет взять значение с константой. То есть значение
[23:51.800 --> 23:56.800]  взять регистр с константой это единичка. В итоге у нас получается, так или иначе, total
[23:56.800 --> 24:03.520]  cost оптимален тогда, когда мы берем мем плюс констант. Да, сразу скажу, что здесь style cost по факту не
[24:03.520 --> 24:10.440]  один, если мы берем код a10, потому что мы сказали, что load у нас занимает 10 операций. То есть вот
[24:10.440 --> 24:15.160]  явно таким образом поднимаясь снизу вверх, мы можем увидеть инструкции, которые нам нужны.
[24:15.160 --> 24:34.000]  Вот так. Понятен ли этот алгоритм? Поднимаемся снизу вверх и строим наше дерево. Вот его недостатки.
[24:34.000 --> 24:40.200]  Хорошо, давайте поговорим про следующее. Паттерны как правила в грамматике. То есть
[24:40.200 --> 24:46.120]  иногда правила разбора полезно задавать как определенные правила в грамматике, но тогда нам
[24:46.120 --> 24:52.600]  нужно интеррироваться по правилам и это кажется не оптимально. Но в целом, если у вас грамматика
[24:52.600 --> 24:59.360]  плюс-минус однозначная, можно использовать безон. Но я думаю, что вот если внезапно возникнет вот
[24:59.360 --> 25:06.400]  такое фанатичное правило, давайте воспользуемся парсером правил ассемблера и используем для
[25:06.400 --> 25:14.160]  instruction-selection безон. Лучше это откинуть нафиг. Тем более первая недозначность,
[25:14.160 --> 25:22.520]  которую мы поймем, она нам не даст результат. Вот давайте как раз вот с учетом этого попробуем
[25:22.520 --> 25:29.480]  оценить сложность алгоритма покрытия. Значит, здесь математический факт. Пусть у нас имеется
[25:29.480 --> 25:38.680]  т шаблонов и всего у нас имеется т шаблонов. Вот в наше правило, если мы говорим про язык,
[25:38.680 --> 25:44.960]  который мы говорили, там порядка 20 шаблонов. При этом каждый паттерн в среднем содержит
[25:44.960 --> 25:51.560]  кани листовых узлов, то есть ка точек, к которому мы можем привязаться. При этом давайте оценим.
[25:51.560 --> 25:57.240]  Пусть у нас понятно, что каждый паттерн нужно сделать в соответствии ему какому-то примеру.
[25:57.240 --> 26:01.280]  И предположим, что к штрих это количество узлов, которые необходимо для того, чтобы
[26:01.280 --> 26:06.040]  сопоставить наш шаблон. То есть понять, подходит нам этот шаблон или не подходит.
[26:06.040 --> 26:14.120]  И будем считать, что у нас в среднем т штрих паттернов подходит каждому узлу. Тогда давайте
[26:14.120 --> 26:21.080]  оценим сложность, которая у нас возникает в алгоритме максимального покрытия. Смотрите,
[26:21.680 --> 26:34.360]  всего в дереве N узлов. Каждый из узлов уменьшает, грубо говоря, в среднем оставляет где-то
[26:34.360 --> 26:57.480]  К. Почему нам надо найти N делительно K узлов? Ну да, не листовые узлы, это именно те узлы,
[26:57.480 --> 27:02.440]  которые внутри правила содержатся. То есть, образно говоря, если мы возьмем наши правила,
[27:02.440 --> 27:20.280]  где тряпки? Смотрите.
[27:33.160 --> 27:42.760]  Он для вот этого примера К равняется 3. То есть, вот он раз не листовый узел, вот он два не
[27:42.760 --> 27:46.840]  листовый узел, вот он три не листовый узел. Листовый узел, это тот узел,
[27:46.840 --> 27:52.680]  которым мы можем подцепить правила. Ответственно, смотрите, у нас всего N узлов,
[27:52.680 --> 27:58.840]  К не листовых, то есть каждый раз у нас отсекается пока узлов. В итоге количество
[27:58.840 --> 28:05.600]  узлов равняется N делительно K. То есть, количество раз, которым нам нужно будет мачить наш шаблон,
[28:05.600 --> 28:12.840]  будет N делительно K. При этом, каждый узел у нас будет обрабатываться за K штрих на T
[28:12.840 --> 28:19.040]  штрих операции. Почему? Потому что у нас с вами количество узлов, которые необходимо проверить
[28:19.040 --> 28:27.080]  для этого шаблона, это K штрих, который нам для каждого паттерна необходимо проверить. При
[28:27.080 --> 28:33.320]  этом, у нас в среднем T штрих, узлов подходят каждому узлу. Тут в итоге получается, что нам как бы
[28:33.320 --> 28:45.960]  нужно найти эти шаблоны. Тут на самом деле, может быть даже на T. Ну, где-то вот такая если точка,
[28:45.960 --> 28:51.080]  то есть вот эта константа у нас будет зашиваться. В итоге, сложность нашего алгоритма получается
[28:51.080 --> 28:56.440]  K штрих на T штрих, потому что нам надо среди всех этих паттерн найти максимальные по количеству вершин.
[28:56.440 --> 29:06.640]  А умножить на N поделить на K. То есть как бы мы с вами экономим получается одну кат операции для этой
[29:06.640 --> 29:10.440]  штуки. Ну, а если мы делаем классическое динамическое программирование, нам необходимо
[29:10.440 --> 29:17.400]  просмотреть все вершины. У нас точка будет именно в K раз больше. Вот такой вот у нас получается
[29:17.400 --> 29:28.360]  результат. Вот такая интересная вещь. Ну, в целом, этот алгоритм как раз можно использовать для
[29:28.360 --> 29:43.440]  своих задач. Так, понятно ли оценка этой точки? Ну, то есть, ну да, ну то есть, важно посмотреть
[29:43.440 --> 29:49.760]  именно какое количество решений у нас есть для каждого уравнения. Вот, значит, и теперь мы как
[29:49.760 --> 29:56.360]  раз с вами, когда осваиваем эту всю вещь, нам нужно поговорить с вами детально про
[29:56.360 --> 30:02.120]  архитектуры процессоров. Собственно, есть две классические архитектуры. Первая это RISC, это
[30:02.120 --> 30:08.480]  Reduced Instruction Set Computer. Это инструкция быстрая, приблизительно одинаковой стоимости,
[30:08.480 --> 30:22.400]  но работа с памятью только через операцию LoadStore. Да, и при этом инструкция обычно трех адресной.
[30:22.400 --> 30:28.400]  Пример таких архитектур это ARM. Значит, если мы говорим про RISC архитектуры, которая комплекс
[30:28.400 --> 30:32.840]  Instruction Set Computer, есть инструкция разной сложности, разного типа доступа к регистрам данным.
[30:32.840 --> 30:37.080]  Инструкция, кстати, обычно двух адресные, и пример этого x86.
[30:37.080 --> 30:53.760]  Ну да, и вообще этот процессор изначально придумали для калькулятора. Да, таким образом,
[30:53.760 --> 31:06.360]  что сколько тут? Раз, два, три, четыре, пять компьютеров, да? Нет, у меня не калькулятор. Да,
[31:06.360 --> 31:15.600]  у меня Mac, у меня Mac на M1. Ну, посмотрим в примере как конструкция. Да, Reduced Instruction Set Computer.
[31:15.600 --> 31:37.400]  Вот, значит, в чем особенность RISC? Архитектуру? Да, согласен. Кто? А что?
[31:45.600 --> 32:12.000]  Ну да. Так, извините. Так, извините, куда изобрелась? Там же был забавный эффект,
[32:12.000 --> 32:19.880]  что классический пример того, для каких целей на самом деле использовался PlayStation 3 в свое время
[32:19.880 --> 32:37.600]  и PlayStation 4. Фермы большие. Да, да, да, да, да. Да, да, да, да, да. Вот, поэтому тоже особенность
[32:37.600 --> 32:47.920]  есть. Особенно это Николай знает. Особенность приставок консолей. Вот, значит, в RISC что у нас
[32:47.920 --> 32:52.720]  есть? У нас есть больше регистров. Дальше у нас есть арифитические инструкции между регистрами,
[32:52.720 --> 32:59.920]  инструкции трехадресные и low attestor в режиме M от регистр плюс const и результат на одну инструкцию.
[32:59.920 --> 33:10.760]  Я предлагаю какой-нибудь код скомпилировать. Главное, чтобы петличка не падала. Итак,
[33:10.760 --> 33:26.200]  значит, какой код скомпилируем? Блин, hello world неинтересно. А? Ага. Давайте это,
[33:26.200 --> 33:34.440]  какой-нибудь я возьму. Да, я, кстати, наконец-таки запушил код. Ветку 2024. Пока не смерзнул с мастером.
[33:34.440 --> 33:50.400]  Да, да, да. Так, давайте, что мы именно посмотрим? Я предлагаю
[33:50.400 --> 34:05.360]  эта неинтересная функция. Давайте if и начнем. А вот он, наш любимый if. Идем мы с вами в Godbolt.
[34:05.360 --> 34:21.640]  Это сайт Compilers Instructor. Да. О, кстати, у меня есть код. Прекрасно. Так,
[34:21.640 --> 34:32.960]  какой компилятор будем использовать? Arm gcc я предлагаю использовать.
[34:32.960 --> 34:54.560]  Так, вот у нас инструкция на арме. Давайте посмотрим. Да, нет, это функция square, вот это вот.
[34:54.560 --> 35:22.400]  У нас arm v1. Ну а что тут? Есть разные версии. А, вот да, действительно. У меня было включена опция
[35:23.240 --> 35:38.960]  Вот у нас две функции. Square, 3nta. Что мы здесь видим? Да, здесь, кстати, есть трансляция. Вот он if, да, и вот у нас как раз есть LDR, да.
