[00:00.000 --> 00:09.000]  Так, всем доброго дня, мы с вами продолжаем наш курс занятий. Сегодня у нас дождик, поэтому,
[00:09.000 --> 00:16.440]  возможно, у нас смена антуража. Вот, мы сегодня с вами наконец-таки пойдем в БК. Мы начнем
[00:16.440 --> 00:23.600]  разбирать именно такую тему под названием Low Reconstruction. Итак, значит, где мы с вами находимся,
[00:23.600 --> 00:35.920]  давайте вспомним, сравнить с предыдущими частями. Где мы с вами находимся? Ну, это понятное дело,
[00:35.920 --> 00:43.040]  что мы в 113 ГК находимся. Да, значит, смотрите, у нас был LWM, и по факту мы с вами уже некоторый
[00:43.040 --> 00:49.520]  набор Basic блоков объединили в следы для того, чтобы минимизировать количество джампов. Николай
[00:49.640 --> 00:59.560]  смотрит. Это когда мы несколько блоков объединяем в одну общую конструкцию. Да, трейсы.
[00:59.560 --> 01:12.800]  То есть, у нас есть Basic блоки, мы их объединяем в трейсы, чтобы, если мы хотим куда-то прыгать,
[01:12.800 --> 01:18.080]  мы могли бы прыгать именно в другое место. Хорошо, значит, опять у нас экран моргает,
[01:18.080 --> 01:26.440]  но я думаю, что мы с этим ничего не сделаем. Итак, значит, вот у нас есть такой блок. Видимо,
[01:26.440 --> 01:31.720]  тут нет нашей замечательной картинки, я ее забыл вставить. Вот, и мы сегодня начинаем как раз
[01:31.720 --> 01:38.120]  говорить про Backend, и про Backend мы будем говорить с вами в трех контекстах. Первый контекст будет
[01:38.120 --> 01:44.200]  заключаться в том, что нам нужно будет, во-первых, понять, какие наборы инструкции мы с вами используем,
[01:44.200 --> 01:50.280]  и вообще здесь как раз начинает играть большую роль зависимость от той архитектуры, под которую мы
[01:50.280 --> 01:55.600]  компилируем, потому что у нас есть RISC архитектуры, у нас есть CISC архитектуры, и в зависимости от
[01:55.600 --> 02:01.240]  этого Backends будут сильно различаться. Даже более того, они будут различаться до такой степени,
[02:01.240 --> 02:10.320]  что одну из стадий, одну из архитектур можно практически пропустить. Ну, поэтому и то же.
[02:10.320 --> 02:27.720]  Ну да, есть. Есть. Ну да. Вот, то есть смотрите, у нас с вами по факту, можно сказать, что у нас есть
[02:27.720 --> 02:34.680]  ER дерево для блока, либо у нас с вами есть trace. И на выходе нам нужно на самом деле займить эти
[02:34.680 --> 02:41.280]  наборы инструкции Assembler, в котором число регистров в данной степени будет бесконечным. То есть мы
[02:41.280 --> 02:48.240]  пока что не выходим за пределы виртуальности наших регистров. То есть наши регистры становятся
[02:48.240 --> 02:53.920]  чуть менее виртуальными, чем фактически, потому что в VR мы видели с вами, что виртуальные регистры
[02:53.920 --> 03:00.800]  могут иметь произвольный тип. А здесь, к сожалению, уже был тип непроизвольный. И, значит, мы с
[03:00.800 --> 03:08.120]  вами разберем как раз на основе примеров тему под названием паттерны покрытия. То есть как раз,
[03:08.120 --> 03:14.080]  смотрите, по факту, что у нас с вами есть. У нас, если честно, попробовать все инструкции представить,
[03:14.080 --> 03:20.320]  у нас с вами будет ER дерево. Да, то есть у нас есть выражение, у нас есть присваивание и так далее. И
[03:20.320 --> 03:26.040]  вот как раз в данном случае очень удобно будет снова вернуться к представлению ER в виде дерева,
[03:26.040 --> 03:31.600]  потому что, как ни странно, мы сейчас будем как раз покрывать наше дерево другими маленькими кустами.
[03:31.600 --> 03:39.600]  Давайте откроем страницу. Здесь есть как раз вот такой вот Assembly Instruction. Это достаточно
[03:39.600 --> 03:47.000]  давний язык, 2007 год. И давайте как раз познакомимся с набором инструкций, которые здесь нам предлагают
[03:47.000 --> 03:54.000]  освоить. То есть, смотрите, по факту, здесь есть у нас некоторый язык Assembler, в котором у нас с
[03:54.000 --> 04:02.400]  вами инструкция состоит из некоторых из Operation Code. И дальше есть набор регистров, которые мы с вами
[04:02.400 --> 04:10.480]  можем применять. То есть, у нас с вами есть операции классические, есть операции с сайд-эффектами.
[04:10.480 --> 04:16.680]  Значит, и смотрите, какие у нас инструкции есть. Тут важно сразу, что если мы с вами работаем в
[04:16.680 --> 04:24.240]  концепции ER, то у нас нет никакой по факту стоимости нашей инструкции. Ну, она на самом деле есть,
[04:24.240 --> 04:30.360]  если мы хотим сделать какую-то оптимизацию. Здесь мы можем уже на уровне, так сказать, Assembler понять
[04:30.360 --> 04:35.880]  каждую инструкцию, сколько стоит. То есть, взять, допустим, ту же самую спецификацию микропроцессора,
[04:35.880 --> 04:41.560]  там, если она есть, и через нее как раз прогнать эти стоимости. Итак, давайте посмотрим на некоторые
[04:41.560 --> 04:49.120]  инструкции и поймем, что они делают. Значит, здесь первая инструкция – это арифметические операции.
[04:49.120 --> 04:56.600]  Давайте подумаем, почему здесь у нас стоимости, скорее всего, такие. То есть, на сложение вычитания
[04:56.600 --> 05:05.120]  два, на умножение деления 5 и 10. Так-то, да, это такты процессорного времени, которые нам нужны.
[05:05.120 --> 05:19.600]  Пока нет конвейерность на следующих стадиях. То есть, пока что нам ценность инструкции надо сделать.
[05:19.600 --> 05:25.560]  Хорошо, то есть, вот у нас получается есть регистры, значит, у нас два операнта, мы делаем либо плюс,
[05:25.560 --> 05:31.960]  либо умножить, либо минус, либо поделить. Следующая инструкция – add increment. Значит,
[05:31.960 --> 05:38.560]  добавляет константное значение, и видно здесь важная особенность в том, что константу вычислить
[05:38.560 --> 05:48.520]  намного проще. Да, то есть, прибавить константу сильно проще. Дальше у нас есть, значит, вот такой
[05:48.520 --> 05:56.160]  язык. Опять же, он не классический ассемблер. У нас есть язык move, инструкция move a, которая позволяет
[05:56.160 --> 06:02.920]  по факту получить адрес pointer, который указывает на датарегистре, и можем расшифровать наши
[06:02.920 --> 06:10.520]  инструкции. То есть, у нас тоже есть инструкции по два, они стоят два такта. А дальше есть вот такая
[06:10.520 --> 06:20.200]  операция, она позволяет сделать следующее. Мы загружаем значение из памяти по указателю agt
[06:20.200 --> 06:28.080]  плюс c. То есть, мы передвигаем указатель pointed плюс адрес регистр, плюс сдвиг делаем на датарегистр.
[06:28.080 --> 06:36.760]  Скажите, пожалуйста, в каких случаях эта операция может пригождаться. То есть, сдвиг по значению,
[06:36.760 --> 06:50.040]  плюс некоторый константный сдвиг. Это инструкция load. Во-первых, для полиэструктур. Еще где?
[07:00.920 --> 07:03.360]  Ну да, но то же самое в принципе.
[07:07.760 --> 07:18.400]  Ну да. А, немножко другая инструкция. Ну в целом, да. Ну тут надо смотреть, кстати, под back-end,
[07:18.400 --> 07:24.760]  какая из инструкций подойдет. А дальше у нас есть операция store. То есть, у нас есть, можем хранить
[07:24.760 --> 07:29.880]  данные в нашем регистре сдвинутые на определенную операцию. То есть, это оператор присваивания.
[07:29.880 --> 07:37.600]  И смотрите, самая тяжелая операция, которая здесь есть, это операция move memory. То есть,
[07:37.600 --> 07:45.280]  сцена перемещает память из одного регистр в другой участок памяти.
[07:55.600 --> 07:59.560]  Ну да, вот в принципе сверху и видно, что она выражается через две таких.
[07:59.560 --> 08:08.320]  Не-не-не, она двигает один the word. Она просто одно слово двигает.
[08:08.320 --> 08:23.400]  Ну да. Ну пока что мы работаем с интами. У нас пока что все, что есть, это инты. Так,
[08:23.400 --> 08:31.000]  хорошо. А теперь смотрите, важная особенность этого языка. Если у нас здесь conditional jumper.
[08:31.000 --> 08:38.760]  Видно, что здесь jump не conditional. То есть, мы можем прыгнуть. А? То есть, мы можем...
[08:38.760 --> 08:49.040]  conditional jumper имеется, который разбегается на два basic блока. То есть, если у нас в VR был
[08:49.040 --> 08:56.240]  conditional jump в две метки, то есть, либо с веткой true, либо с веткой false, то здесь jump идет только,
[08:56.240 --> 09:01.840]  если определенное условие выполнено. То есть, как раз для этого мы и делали trace, чтобы мы
[09:01.840 --> 09:07.960]  отклонялись от основного trace. И соответственно conditional jump будет весить меньше, чем классический
[09:07.960 --> 09:18.560]  jump. То есть, получается, что мы экономим инструкцию. Так, ну и простой оператор go to, оператор jump,
[09:18.560 --> 09:24.560]  он позволяет прыгнуть как раз в определенное значение. Следующая инструкция, которая у нас
[09:24.560 --> 09:31.680]  с вами есть, это инструкция call. То есть, мы по факту перемещаемся в метку m и при этом запоминаем
[09:31.680 --> 09:38.720]  return location. То есть, грубо говоря, это вызов функции. Вот оно у нас стоит пять поинтов. Да, то есть,
[09:38.720 --> 09:45.560]  как бы вызвать функцию иногда, конечно, полезно, но иногда полезно ее заинлайнить, чтобы, собственно,
[09:45.560 --> 09:54.560]  у нас не было вот таких вот операций. Значит, return будет стоить 3. И установка метки будет стоить
[09:54.560 --> 10:15.560]  нулечков. Ну, на самом деле, да. Ну, почему он... Ну, в смысле два кола. Ну, да. Ну, понятно,
[10:15.560 --> 10:26.240]  что это... А? Ну, это да. Ну, в целом, вот такой язык. Вот. Ну, и, собственно, здесь указывается,
[10:26.240 --> 10:33.160]  допустим, для этого языка, типа какой размер слова. То есть, у нас размер слова всегда равен единичке.
[10:33.160 --> 10:38.720]  То есть, здесь у нас по факту есть чара. Да, ну, понятно, что для интов это тоже можно адаптировать и
[10:38.720 --> 10:42.920]  посмотреть, сколько у нас стоимость. Значит, у нас есть дейты регистра, у нас есть адресные
[10:42.920 --> 10:50.480]  регистры. Да, то есть, видите, есть развлечение. И есть программа каунта. Есть указатель нас так.
[10:50.480 --> 11:00.120]  То есть, в принципе, мы можем обращаться к этим. Так, по вот этой спецификации все понятно? А теперь
[11:00.120 --> 11:06.120]  давайте перерисуем это все в виде дерева. Значит, в виде дерева это будет выглядеть вот таким вот
[11:06.120 --> 11:10.760]  образом. То есть, у нас есть операция add, и мы видим, что это как раз у нас add-оператор. То есть,
[11:10.760 --> 11:17.560]  у него есть вершина плюсик, и снизу он подцепляет два других оператора. А оператор mull это оператор
[11:17.560 --> 11:22.760]  перемножения. То есть, у нас есть перемножение двух операторов. Оператор add-i, он является вот таким.
[11:22.760 --> 11:28.800]  То есть, у нас есть Rit равно Rgt плюс c. И, соответственно, у нас получается с вами три возможных варианта действий.
[11:28.800 --> 11:38.640]  Дальше, операция load, она у нас может редуцироваться. Значит, это либо Rit равно m от mem. То есть, это как
[11:38.640 --> 11:44.760]  раз вот эти вот операции, помните, mem, move и так далее, которые были в VR. То есть, это то, как эти
[11:44.760 --> 11:51.480]  инструкции будут у нас транслироваться в VR. Значит, это либо mem от Rit плюс const, либо mem const
[11:51.480 --> 11:58.560]  плюс Rit, либо mem от const, то есть, в качестве регистра мы игнорируем информацию, либо просто оператор mem.
[11:58.560 --> 12:08.600]  Соответственно, оператор store, видно, что в VR дереве стоит достаточно дорого. То есть, как бы, нам нужно
[12:08.600 --> 12:15.360]  собственно сделать mem, потом сделать move. То есть, он стоит 10 очков. И move mem это move от
[12:15.360 --> 12:21.280]  move mem. То есть, в принципе, наша цель, первая, которая заключается в покрытии инструкций,
[12:21.280 --> 12:27.760]  это взять все наши конструкции промежуточного представления, взять все наши конструкции
[12:27.760 --> 12:36.240]  ассемблера, которые у нас есть, и переложить, попытаться построить их в VR дереве. Да, вот чем мы
[12:36.240 --> 12:43.200]  должны в целом заниматься на этой стадии. А дальше, если у нас есть стоимость инструкций,
[12:43.200 --> 12:49.440]  то мы можем выполнять разные покрытия. Вот смотрите, здесь есть некоторый пример того, каким
[12:49.440 --> 12:54.920]  образом мы можем превратить вот этот вот набор инструкций. То есть, у нас, как бы, есть вот такое VR
[12:54.920 --> 13:01.640]  дерево. Это у нас AssignIndexStatement. То есть, мы говорим, что у нас а и тому нужно присвоить какое-то значение
[13:01.640 --> 13:09.120]  х. Давайте посмотрим на эти два разбиения. Собственно, в первом разбиении мы берем frame
[13:09.120 --> 13:17.320]  pointer и получаем значение регистра на константу а. То есть, это наш массив. То есть, первая
[13:17.320 --> 13:24.000]  операция здесь это load. Вот она, это вторая инструкция. После этого мы должны с вами сделать
[13:24.000 --> 13:32.680]  следующее. К константу сделать четвертую инструкцию, которая прибавит к R0 значение 4. То есть,
[13:32.680 --> 13:40.160]  возьмем значение нашего указатель. Дальше, значит, мы должны будем перемножить R1 и R2. Да, то есть,
[13:40.160 --> 13:48.400]  вот так вот, вот так. Да, R0 это регистр, в котором всегда 0 сидит. Константа 0. Опять же,
[13:48.400 --> 13:53.840]  взятия константа. Просто вот такой R. Интересно. Дальше мы берем перемножение. Дальше мы берем
[13:53.840 --> 14:00.680]  сложение. То есть, R1 это R1 плюс R2. То есть, вот он оператор. После этого вот это вот у нас
[14:00.680 --> 14:07.680]  получается значение нашего элемента массива. Дальше мы загружаем значение нашего значения
[14:07.680 --> 14:14.000]  нашего x и делаем операцию store. То есть, мы прямо берем и присваиваем значение нашему массиву. То
[14:14.000 --> 14:19.720]  есть, вот такая инструкция. Мы можем это переписать по-другому и сказать, что давайте вместо того,
[14:19.720 --> 14:25.280]  чтобы сделать операцию load по хрейнфоитору плюс x, мы сделаем сразу операцию addE. То есть,
[14:25.280 --> 14:32.040]  прибавим это значение по константе, а потом сделаем moveMe. Попрос. Как вы думаете,
[14:32.040 --> 14:37.680]  какая из операций стоит дороже? Какое из покрытий? То есть, у нас получается,
[14:37.680 --> 14:43.800]  для каждого объекта и R у нас может быть, каждого дерева и R у нас может быть несколько покрытий
[14:43.800 --> 14:53.400]  ассамблярными инструкциями. Значит, у нас есть loadStore и addE moveM.
[15:13.800 --> 15:28.120]  Сделано. Так, давайте оценивать. Как мы это оценим? Нам нужно посмотреть на инструкции.
[15:28.120 --> 15:35.680]  Так, давайте поймем. Сколько у нас load стоит?
[15:35.680 --> 15:55.800]  Store, moveM. А здесь addE неважно сколько стоит, это любое всё больше нуля и мы видим с вами,
[15:55.800 --> 16:12.520]  что нам выгоднее не использовать moveNem, а использовать addE и констант. Хорошо. То есть,
[16:12.520 --> 16:19.280]  вот такое вот у нас покрытие получилось. И здесь возникает некоторое понятие. Смотрите,
[16:19.400 --> 16:26.840]  у нас есть код, у нас есть дерево и у нас может быть несколько покрытий. Соответственно,
[16:26.840 --> 16:32.400]  мы можем попробовать склассифицировать эти покрытия. Каким образом мы можем склассифицировать?
[16:32.400 --> 16:42.640]  Значит, смотрите, здесь делается следующая вещь. Мы с вами можем построить наилучшее покрытие. То
[16:42.640 --> 16:48.920]  есть, что означает наилучшее покрытие? Это покрытие, которое имеет наименьший вес. Дальше,
[16:48.920 --> 16:55.840]  оптимальное покрытие. Это покрытие, в котором любые два соседних паттерна не могут быть
[16:55.840 --> 17:03.640]  преобразованы паттерном с меньшей суммой весов. Вот, кстати, если мы воспользуемся вот этой
[17:03.640 --> 17:13.000]  инструкцией addE и moveMem по сравнению с load и store, то это будет, смотрите, это будет не оптимальным и
[17:13.000 --> 17:19.600]  не оптимальным покрытием и не наилучшим покрытием. Почему вот эта инструкция не будет наилучшим покрытием?
[17:19.600 --> 17:30.240]  Ну, вот, moveMem и addE. Ну, потому что есть инструкция, которая весит меньший вес.
[17:30.240 --> 17:45.600]  Ну, а почему оно не будет оптимальным? А? А оно не будет оптимальным, посмотри, ровно по вот этой причине,
[17:45.600 --> 17:54.680]  я сейчас помечу экране. Если бы это покрытие было бы не оптимальным, то бы мы не могли взять вот
[17:54.680 --> 18:01.040]  эти вот две инструкции, которые я обвожу, да, 9 и 8, и преобразовать их в набор инструкций с меньшим
[18:01.040 --> 18:08.120]  весом. Вот конкретно две соседних. А здесь мы как раз, смотрите, берем две соседних инструкции и
[18:08.120 --> 18:22.880]  как раз распиливаем их по-другому. То есть если бы такую вот эту инструкцию нельзя было бы склеить
[18:22.880 --> 18:30.880]  и снова расклеить с меньшим весом, то такая конструкция была бы оптимальной. Вот, и обычно,
[18:30.880 --> 18:37.440]  когда мы строим компилятор, мы строим все-таки оптимальное покрытие, а не наилучшее. Почему,
[18:37.440 --> 18:55.280]  как вы думаете? Ну да, ее нельзя решить достаточно быстро, поэтому мы стараемся хоть какое-то покрытие
[18:55.280 --> 19:00.960]  найти, ну, грубо говоря, чтобы у нас каких-то прямо очевидных оптимизаций не возникало. Вот,
[19:00.960 --> 19:06.840]  поэтому мы будем искать как раз с вами оптимальное покрытие. Так, хорошо, мы строим оптимальное
[19:06.840 --> 19:13.160]  покрытие, и здесь как раз возникает алгоритм, который начинает с следующего. Это алгоритм
[19:13.160 --> 19:20.200]  максимального покрытия. Он строит оптимальное покрытие, и он называется, по факту, является жадным
[19:20.200 --> 19:25.640]  алгоритмом. То есть что мы делаем? Мы начинаем с корня дерева, добавляем ее в очередь, и дальше
[19:25.640 --> 19:30.360]  делаем следующее. Мы пытаемся выбрать паттерн с наибольшим количеством вершин, при этом при
[19:30.360 --> 19:36.400]  равенстве количестве вершин выбираем произволь. Вот, и дальше этот паттерн, узлы этого дочернего
[19:36.400 --> 19:42.200]  процесса, добавляем в очередь. Вот, в этом очередь можно заменить на рекурсивный выход.
[19:42.200 --> 19:49.960]  Вот, при этом можно заметить в целом, что такое дерево сойдет. То есть мы как бы идем не от корня
[19:49.960 --> 19:55.400]  к вершине, а не от вершины к корню, а от корня к вершине. Соответственно, если у нас есть оптимальный
[19:55.400 --> 20:00.880]  набор инструкций, то так или иначе у нас дерево сойдется в какой-то момент времени. Единственное,
[20:00.880 --> 20:07.240]  сразу тут нужно сказать, что этот алгоритм в принципе может обладать нерекурсивным свойств,
[20:07.240 --> 20:14.120]  свойств именно связанных с откатом, потому что мы в принципе можем с вами дойти до определенного
[20:14.120 --> 20:22.840]  момента и дальше не подниматься для этого выхода. Вот, собственно, это вот алгоритм, который
[20:22.840 --> 20:29.680]  позволяет найти оптимальное покрытие. Понятен? То есть тут тупой жадный алгоритм. Мы пытаемся
[20:29.680 --> 20:36.600]  присоединиться сверху вниз. Хорошо, другой вариант это динамическое программирование. И что
[20:36.600 --> 20:40.960]  позволяет сделать динамическое программирование? Динамическое программирование позволяет найти
[20:40.960 --> 20:49.720]  наилучшее покрытие. То есть как бы он идет снизу вверх. И идея такая, что мы по факту можем с вами
[20:49.720 --> 20:58.800]  сказать следующее. Давайте в вершине каждого дерева будем хранить паттерн с его детьми. То
[20:58.800 --> 21:05.720]  есть сколько занимает сейчас в текущий момент покрытие оптимальный паттерн. И дальше мы что с
[21:05.720 --> 21:11.640]  вами делаем? Мы говорим, что вес покрытия паттерн, потенциал покрытия паттерна, это значит его значение,
[21:11.640 --> 21:16.320]  плюс значения, которые висят на груздах его детей. Понятно, что если у нас какой-то паттерн не
[21:16.320 --> 21:23.400]  покрывается дочерним, то мы считаем, что вес этого паттерна бесконечный. И в итоге мы с вами
[21:23.400 --> 21:30.400]  выбираем покрытие наименьшего веса. По идее оно является наилучшим, но по факту нужно смотреть
[21:30.400 --> 21:35.840]  аккуратно с набором инструкций. Потому что, грубо говоря, несмотря на то, что у нас есть линейные
[21:35.840 --> 21:44.400]  инструкции, то что делать с фи-инструкциями это хороший вопрос. Потому что нам нужно взять
[21:44.400 --> 21:51.360]  определенные значения. И вот такие инструкции, по которых у нас код не является линейным,
[21:51.360 --> 22:03.640]  как его покрывать? Хороший вопрос. Поэтому если у вас фи-инструкции нет, то динамическое
[22:03.640 --> 22:08.480]  программирование подходит. Если у нас нету фи-инструкции, точнее, наоборот, если у нас
[22:08.480 --> 22:14.520]  есть фи-инструкция, то, к сожалению, этот алгоритм может не работать. А, в принципе, подход,
[22:14.520 --> 22:22.920]  который берет сверху вниз, он позволяет получить правильное значение. Так, смотрите, здесь как
[22:22.920 --> 22:28.840]  раз показывается алгоритм, который заключается в том, что у нас с вами есть вот такой оперант.
[22:28.840 --> 22:40.280]  Это у нас алгоритм, который идет связанный именно с дочерним снизу вверх. Итак, смотрите,
[22:40.280 --> 22:44.520]  значит, первый способ, которым мы можем двигаться, это мы берем, складываем что-то
[22:44.520 --> 22:53.080]  со константы, мы получаем вес один. При этом лифт-кост тоже будет один. То есть взятие константа
[22:53.080 --> 23:01.600]  это тоже один такт. И второй шаг, который мы можем сделать, то есть мы оцениваем значение
[23:01.600 --> 23:07.440]  операнда плюс. Значение операнда плюс это значение суммы операнда, которое у нас имеется. И вот этот
[23:07.440 --> 23:15.120]  плюс он как раз нам дает в итоге значение либо три, если мы возьмем add и возьмем отдельно две
[23:15.120 --> 23:22.280]  константы, либо add и, когда мы говорим, что мы можем прибавить какое-то число заранее. Вот,
[23:22.280 --> 23:26.640]  в итоге у нас получается вес либо три, либо два, либо два. Соответственно, мем дальше это
[23:26.640 --> 23:33.080]  инструкция load. И тут все зависит на самом деле от того, какой load мы сделаем. Мы можем сделать
[23:33.080 --> 23:39.040]  load тупой, который загрузит определенные значения только. Мы можем сделать умнее. Мы можем взять
[23:39.040 --> 23:45.880]  операцию load, которая берет значение и складывает его с константой. То есть это классический оператор
[23:45.880 --> 23:51.800]  load. А здесь у нас как раз регистр, который позволяет взять значение с константой. То есть значение
[23:51.800 --> 23:56.800]  взять регистр с константой это единичка. В итоге у нас получается, так или иначе, total
[23:56.800 --> 24:03.520]  cost оптимален тогда, когда мы берем мем плюс констант. Да, сразу скажу, что здесь style cost по факту не
[24:03.520 --> 24:10.440]  один, если мы берем код a10, потому что мы сказали, что load у нас занимает 10 операций. То есть вот
[24:10.440 --> 24:15.160]  явно таким образом поднимаясь снизу вверх, мы можем увидеть инструкции, которые нам нужны.
[24:15.160 --> 24:34.000]  Вот так. Понятен ли этот алгоритм? Поднимаемся снизу вверх и строим наше дерево. Вот его недостатки.
[24:34.000 --> 24:40.200]  Хорошо, давайте поговорим про следующее. Паттерны как правила в грамматике. То есть
[24:40.200 --> 24:46.120]  иногда правила разбора полезно задавать как определенные правила в грамматике, но тогда нам
[24:46.120 --> 24:52.600]  нужно интеррироваться по правилам и это кажется не оптимально. Но в целом, если у вас грамматика
[24:52.600 --> 24:59.360]  плюс-минус однозначная, можно использовать безон. Но я думаю, что вот если внезапно возникнет вот
[24:59.360 --> 25:06.400]  такое фанатичное правило, давайте воспользуемся парсером правил ассемблера и используем для
[25:06.400 --> 25:14.160]  instruction-selection безон. Лучше это откинуть нафиг. Тем более первая недозначность,
[25:14.160 --> 25:22.520]  которую мы поймем, она нам не даст результат. Вот давайте как раз вот с учетом этого попробуем
[25:22.520 --> 25:29.480]  оценить сложность алгоритма покрытия. Значит, здесь математический факт. Пусть у нас имеется
[25:29.480 --> 25:38.680]  т шаблонов и всего у нас имеется т шаблонов. Вот в наше правило, если мы говорим про язык,
[25:38.680 --> 25:44.960]  который мы говорили, там порядка 20 шаблонов. При этом каждый паттерн в среднем содержит
[25:44.960 --> 25:51.560]  кани листовых узлов, то есть ка точек, к которому мы можем привязаться. При этом давайте оценим.
[25:51.560 --> 25:57.240]  Пусть у нас понятно, что каждый паттерн нужно сделать в соответствии ему какому-то примеру.
[25:57.240 --> 26:01.280]  И предположим, что к штрих это количество узлов, которые необходимо для того, чтобы
[26:01.280 --> 26:06.040]  сопоставить наш шаблон. То есть понять, подходит нам этот шаблон или не подходит.
[26:06.040 --> 26:14.120]  И будем считать, что у нас в среднем т штрих паттернов подходит каждому узлу. Тогда давайте
[26:14.120 --> 26:21.080]  оценим сложность, которая у нас возникает в алгоритме максимального покрытия. Смотрите,
[26:21.680 --> 26:34.360]  всего в дереве N узлов. Каждый из узлов уменьшает, грубо говоря, в среднем оставляет где-то
[26:34.360 --> 26:57.480]  К. Почему нам надо найти N делительно K узлов? Ну да, не листовые узлы, это именно те узлы,
[26:57.480 --> 27:02.440]  которые внутри правила содержатся. То есть, образно говоря, если мы возьмем наши правила,
[27:02.440 --> 27:20.280]  где тряпки? Смотрите.
[27:33.160 --> 27:42.760]  Он для вот этого примера К равняется 3. То есть, вот он раз не листовый узел, вот он два не
[27:42.760 --> 27:46.840]  листовый узел, вот он три не листовый узел. Листовый узел, это тот узел,
[27:46.840 --> 27:52.680]  которым мы можем подцепить правила. Ответственно, смотрите, у нас всего N узлов,
[27:52.680 --> 27:58.840]  К не листовых, то есть каждый раз у нас отсекается пока узлов. В итоге количество
[27:58.840 --> 28:05.600]  узлов равняется N делительно K. То есть, количество раз, которым нам нужно будет мачить наш шаблон,
[28:05.600 --> 28:12.840]  будет N делительно K. При этом, каждый узел у нас будет обрабатываться за K штрих на T
[28:12.840 --> 28:19.040]  штрих операции. Почему? Потому что у нас с вами количество узлов, которые необходимо проверить
[28:19.040 --> 28:27.080]  для этого шаблона, это K штрих, который нам для каждого паттерна необходимо проверить. При
[28:27.080 --> 28:33.320]  этом, у нас в среднем T штрих, узлов подходят каждому узлу. Тут в итоге получается, что нам как бы
[28:33.320 --> 28:45.960]  нужно найти эти шаблоны. Тут на самом деле, может быть даже на T. Ну, где-то вот такая если точка,
[28:45.960 --> 28:51.080]  то есть вот эта константа у нас будет зашиваться. В итоге, сложность нашего алгоритма получается
[28:51.080 --> 28:56.440]  K штрих на T штрих, потому что нам надо среди всех этих паттерн найти максимальные по количеству вершин.
[28:56.440 --> 29:06.640]  А умножить на N поделить на K. То есть как бы мы с вами экономим получается одну кат операции для этой
[29:06.640 --> 29:10.440]  штуки. Ну, а если мы делаем классическое динамическое программирование, нам необходимо
[29:10.440 --> 29:17.400]  просмотреть все вершины. У нас точка будет именно в K раз больше. Вот такой вот у нас получается
[29:17.400 --> 29:28.360]  результат. Вот такая интересная вещь. Ну, в целом, этот алгоритм как раз можно использовать для
[29:28.360 --> 29:43.440]  своих задач. Так, понятно ли оценка этой точки? Ну, то есть, ну да, ну то есть, важно посмотреть
[29:43.440 --> 29:49.760]  именно какое количество решений у нас есть для каждого уравнения. Вот, значит, и теперь мы как
[29:49.760 --> 29:56.360]  раз с вами, когда осваиваем эту всю вещь, нам нужно поговорить с вами детально про
[29:56.360 --> 30:02.120]  архитектуры процессоров. Собственно, есть две классические архитектуры. Первая это RISC, это
[30:02.120 --> 30:08.480]  Reduced Instruction Set Computer. Это инструкция быстрая, приблизительно одинаковой стоимости,
[30:08.480 --> 30:22.400]  но работа с памятью только через операцию LoadStore. Да, и при этом инструкция обычно трех адресной.
[30:22.400 --> 30:28.400]  Пример таких архитектур это ARM. Значит, если мы говорим про RISC архитектуры, которая комплекс
[30:28.400 --> 30:32.840]  Instruction Set Computer, есть инструкция разной сложности, разного типа доступа к регистрам данным.
[30:32.840 --> 30:37.080]  Инструкция, кстати, обычно двух адресные, и пример этого x86.
[30:37.080 --> 30:53.760]  Ну да, и вообще этот процессор изначально придумали для калькулятора. Да, таким образом,
[30:53.760 --> 31:06.360]  что сколько тут? Раз, два, три, четыре, пять компьютеров, да? Нет, у меня не калькулятор. Да,
[31:06.360 --> 31:15.600]  у меня Mac, у меня Mac на M1. Ну, посмотрим в примере как конструкция. Да, Reduced Instruction Set Computer.
[31:15.600 --> 31:37.400]  Вот, значит, в чем особенность RISC? Архитектуру? Да, согласен. Кто? А что?
[31:45.600 --> 32:12.000]  Ну да. Так, извините. Так, извините, куда изобрелась? Там же был забавный эффект,
[32:12.000 --> 32:19.880]  что классический пример того, для каких целей на самом деле использовался PlayStation 3 в свое время
[32:19.880 --> 32:37.600]  и PlayStation 4. Фермы большие. Да, да, да, да, да. Да, да, да, да, да. Вот, поэтому тоже особенность
[32:37.600 --> 32:47.920]  есть. Особенно это Николай знает. Особенность приставок консолей. Вот, значит, в RISC что у нас
[32:47.920 --> 32:52.720]  есть? У нас есть больше регистров. Дальше у нас есть арифитические инструкции между регистрами,
[32:52.720 --> 32:59.920]  инструкции трехадресные и low attestor в режиме M от регистр плюс const и результат на одну инструкцию.
[32:59.920 --> 33:10.760]  Я предлагаю какой-нибудь код скомпилировать. Главное, чтобы петличка не падала. Итак,
[33:10.760 --> 33:26.200]  значит, какой код скомпилируем? Блин, hello world неинтересно. А? Ага. Давайте это,
[33:26.200 --> 33:34.440]  какой-нибудь я возьму. Да, я, кстати, наконец-таки запушил код. Ветку 2024. Пока не смерзнул с мастером.
[33:34.440 --> 33:50.400]  Да, да, да. Так, давайте, что мы именно посмотрим? Я предлагаю
[33:50.400 --> 34:05.360]  эта неинтересная функция. Давайте if и начнем. А вот он, наш любимый if. Идем мы с вами в Godbolt.
[34:05.360 --> 34:21.640]  Это сайт Compilers Instructor. Да. О, кстати, у меня есть код. Прекрасно. Так,
[34:21.640 --> 34:32.960]  какой компилятор будем использовать? Arm gcc я предлагаю использовать.
[34:32.960 --> 34:54.560]  Так, вот у нас инструкция на арме. Давайте посмотрим. Да, нет, это функция square, вот это вот.
[34:54.560 --> 35:22.400]  У нас arm v1. Ну а что тут? Есть разные версии. А, вот да, действительно. У меня было включена опция
[35:23.240 --> 35:38.960]  Вот у нас две функции. Square, 3nta. Что мы здесь видим? Да, здесь, кстати, есть трансляция. Вот он if, да, и вот у нас как раз есть LDR, да.
[35:38.960 --> 35:51.680]  LDR, что у нас делать? Он загружает регистр. То есть у нас получается, вот это классическая операция load. То есть у нас есть как раз R7 и $12, да, то есть это у нас, кстати,
[35:51.680 --> 36:11.120]  что такое $12? Скорее всего сдвиг. Давайте поймем. Значит, вот он у нас получился. Вот это у нас, кстати, стекпоинтер. Решетка 0, значит, дальше R0 и решетка 12. Да, вот, смотрите, кстати, обращу внимание,
[36:11.120 --> 36:20.640]  не зная интересный момент, заключается в том, что кажется, что операция пишется в обратном порядке. Потому что R3 это у нас
[36:21.600 --> 36:23.600]  сравнивается с константой 10.
[36:35.040 --> 36:37.040]  Вот, то есть мы...
[36:37.040 --> 37:03.280]  Ну вот, да. То есть, смотрите, дальше сравнится 10 и дальше есть B на E. Да, то есть мы прыгаем, если у нас значение not equal. А ведь? Да, if not equal. То есть, смотрите, у нас trace,
[37:03.520 --> 37:19.040]  обращу внимание, как настроен. То есть мы по умолчанию будем заходить внутри цикла, а не вне цикла. Ой, внутри условия, а не вне условия. Да, то есть как бы if and else лучше контролировать вот
[37:19.040 --> 37:29.280]  таким образом. Значит, дальше у нас идет load. Загружаем мы с вами еще раз значение, решетка 8. Я, правда, не понимаю, почему он грузит несколько... А, тут уже как раз, видите,
[37:29.280 --> 37:41.280]  используется разный набор регистров. Вопрос, а почему он это не оптимизирует? Нет. Что-то включить?
[37:41.280 --> 37:59.280]  Да, и что возвращать-то будем?
[37:59.280 --> 38:19.280]  Да, internal.
[38:19.280 --> 38:33.280]  Ага. Спасибо.
[38:33.280 --> 39:01.280]  Да, кстати, the conditional instruction. То есть, видите, тут есть даже if-then оператор.
[39:01.280 --> 39:25.280]  Да, конечно, он делает следующее. Up to 4 following construction conditionals. А, он включает возможность movelt использовать регистр.
[39:25.280 --> 39:45.280]  Да.
[39:45.280 --> 40:09.280]  Смотрите, у нас же фишка в том, что b больше c.
[40:09.280 --> 40:27.280]  Ну да, да.
[40:27.280 --> 40:55.280]  Так, минус o3, давайте посмотрим. Ну да, да, да. Нет, тут уже некуда. А вот o1, кстати. Ну, то есть, смотрите, как раз мы сравним значение r0, да, и значение, кстати, передается по регистрам. То есть, r1, r2 это регистры, которые передаются в аргументы функции. Да, кстати.
[40:55.280 --> 41:09.280]  Ну да, да.
[41:09.280 --> 41:21.280]  Так, кстати, вопрос. Сколько регистров он может принимать? Давайте проверим.
[41:21.280 --> 41:33.280]  Так, ну вот, смотрите, я добавил 5 аргументов.
[41:33.280 --> 41:51.280]  Смотрите, значит, branch for equal l4. То есть, видите, здесь он уже создал новую метку. Значит, дальше он сравнит r1, r2. Если получается less, то мы прыгаем в ветку l3. Где она? А, вот она. То есть, это l3. То есть, здесь все окей.
[41:51.280 --> 42:05.280]  А что здесь происходит? Да, да, да. И смотрите, что у нас происходит. Мы загружаем регистр, да, r0 и sp это stack pointer.
[42:05.280 --> 42:30.280]  Да, сверху stack. То есть, видите, переменная e уже нам прилетает со stack. То есть, как бы до четырех аргументов, а дальше уже аргументы берутся со stack. Вот такая особенность. То есть, это как раз у нас ARM, да, и видно, что здесь количество инструкций очень большое.
[42:30.280 --> 42:40.280]  Так, на o3.
[42:40.280 --> 43:04.280]  Да, он уже примерно со stack использует. Что, на MIPS посмотрим? Где тут MIPS? MIPS GCC тоже используем, да?
[43:04.280 --> 43:32.280]  Так, давайте с оптимизацией.
[43:32.280 --> 43:46.280]  А 4 это что?
[43:46.280 --> 44:14.280]  Ну, это да, да, да. Сейчас сравнится. Прыгаем, да, в l5, а дальше что это? SLT. Да, метки какие-то. Ну, вообще видно, что инструкции такие. Интересные. То есть, в зависимости от бэкэнта у нас все...
[44:14.280 --> 44:22.280]  Да, да, да, да, да. Вот это да.
[44:22.280 --> 44:39.280]  Так, ну что? Осталось CISC посмотреть архитектуру. Давайте как раз про нее поговорим. Что заключается в CISC? В CISC у нас меньше регистров. Регистры при этом поделены на разные классы регистров.
[44:39.280 --> 44:49.280]  Вот, аэропедические операции могут работать как с памятой, так и с регистрами. Двухадресная форма. То есть, здесь у нас было трехадресная.
[44:49.280 --> 45:05.280]  Давайте еще раз покажу. То есть, мы идем с вами на... куда? На ARM. Давайте вернемся. Вот, да. То есть, у нас трехадресная инструкция есть. Двухадресная и трехадресная.
[45:05.280 --> 45:15.280]  Здесь двухадресная инструкция, но здесь есть побочные эффекты. Допустим, к примеру, побочный эффект относится к автоинкарминенту адресов. То есть, специальная переменная, которая нужна.
[45:15.280 --> 45:29.280]  И, кстати, сразу скажу, что видно, тут вот есть это. Типа, вот здесь вот как раз все было заточено под x86 изначально. То есть, потому что здесь есть программа Counter.
[45:29.280 --> 45:39.280]  Так, ну что, посмотрим пример этого кода на этом. А как x86, наверное.
[45:39.280 --> 46:04.280]  Давайте его один. Здесь он на уровне. Так, смотрите, давайте читать. У нас есть регистры EIX, EBX.
[46:04.280 --> 46:21.280]  То есть, видно, что у нас инструкции есть разного класса. Здесь мы копируем регистр. Дальше, значит, сравниваем значение EDE с десяткой.
[46:21.280 --> 46:38.280]  И дальше прыгаем. То есть, jump equal в L4. Если нет, то return. Да, мы за этим сэйвили все в EIX. То есть, это аргумент возвращения.
[46:38.280 --> 46:56.280]  Дальше, что мы делаем? Jump equal. А, стоп, а где тут сравнение B больше C?
[46:56.280 --> 47:09.280]  А, все, понял. То есть, он сначала вычислил результаты выражений, да, получается?
[47:09.280 --> 47:19.280]  Сейчас, я что-то не понимаю.
[47:19.280 --> 47:29.280]  А в ECXD лежит или в R8D?
[47:29.280 --> 47:37.280]  Я что-то не понял. А, понятно.
[47:37.280 --> 47:57.280]  Да, вот это вот D+. Так, стоп, сейчас получается.
[47:57.280 --> 48:17.280]  В общем, видно, что здесь, как говорится, несколько оптимизаций. И здесь как раз по операциям видно, что мы очень сильно экономим на количестве регистров.
[48:17.280 --> 48:29.280]  У нас есть у регистров разные классы, да, и, собственно, да. То есть, видите, у нас прямо особенности идут под определенные инструкции.
[48:29.280 --> 48:37.280]  Вот, значит, давайте скажем что. Давайте попробуем решить некоторые проблемы сейчас на текущей стадии.
[48:37.280 --> 48:47.280]  Значит, как ни странно, на текущей стадии у нас происходит следующее. Первое, мало регистров, они у нас виртуальные, пока что мы не паримся с проблемой малого числа регистров.
[48:47.280 --> 49:00.280]  Да, и регистры распределяются в разные операнты. Собственно, если мы хотим использовать какой-нибудь оператор T1, T2 на T3, то мы можем сделать следующее.
[49:01.280 --> 49:11.280]  Собственно, сделать оперант MOV EIX T2, да, потом MOV EIX T3, то есть взять значение операнта, и потом переместить значение T1 в EIX.
[49:11.280 --> 49:19.280]  Сразу скажу, что здесь T1, T2 и T3 это виртуальные регистры. То есть они пока что самым никаким образом не влияют.
[49:19.280 --> 49:26.280]  Вот, собственно, двухадресные инструкции, если у нас есть, то, собственно, тоже перемещаем значение регистров дальше складом.
[49:26.280 --> 49:32.280]  То есть видно, что у нас идет большое количество оперантов MOV, которые нам необходимо обеспечивать.
[49:34.280 --> 49:43.280]  Вот, ну и репетические операции у нас в ЦИСКи могут обращаться к памяти. То есть наша цель будет попытаться именно отслеживать команды, которые делают лишние операции MOV.
[49:49.280 --> 50:13.280]  Да, да, тут именно такие вот вещи. Так, побочные эффекты. Собственно, у ЦИСК-арфитектуры бывают сайд-эффекты.
[50:13.280 --> 50:41.280]  Вот, ну и, собственно, если мы говорим про сайд-эффекты,
[50:41.280 --> 50:55.280]  то сейчас на современных арфитектурах их практически, господи, вот.
[50:55.280 --> 51:15.280]  Ну да, от всех этих нужно.
[51:15.280 --> 51:23.280]  Ну вот.
[51:23.280 --> 51:43.280]  Ну вот, вот, вот, как бы, ну, на современных арфитектурах их очень мало, вот, поэтому, как бы,
[51:43.280 --> 51:57.280]  вот, поэтому их можно использовать на сайд-эффекты.
[51:57.280 --> 52:11.280]  Так, кстати, вот, раз у нас есть такая возможность, давайте посмотрим, собственно, как работает X64-Силанг.
[52:11.280 --> 52:19.280]  Мы тоже можем посмотреть.
[52:19.280 --> 52:25.280]  Да, да, да, да, да.
[52:25.280 --> 52:28.280]  Ну вот, да, да, да, да.
[52:28.280 --> 52:31.280]  Да, то есть все.
[52:31.280 --> 52:35.280]  Так, РЦХ плюс Р8.
[52:35.280 --> 52:37.280]  А?
[52:37.280 --> 52:43.280]  Господи.
[52:43.280 --> 52:50.280]  Да, то есть КМП, ЕДХ, ЕДХ, собственно, и если у нас значение не равно, то мы перемещаем указатель А.
[52:50.280 --> 52:56.280]  То есть здесь видно, в чем особенность, здесь еще порядок конструкции меняется.
[52:56.280 --> 53:04.280]  Ну вот, в отличие от ARMA, да.
[53:04.280 --> 53:17.280]  Ух, ё.
[53:17.280 --> 53:21.280]  Ну, рейск архитектуры.
[53:21.280 --> 53:24.280]  Да, да, да, значит, добавляет значение V4, V3.
[53:24.280 --> 53:28.280]  Кстати, он тоже их переставил.
[53:28.280 --> 53:29.280]  Ну, да, да, да.
[53:29.280 --> 53:33.280]  Кстати, обращу внимание, что теперь он D плюс E, типа, посчитал.
[53:33.280 --> 53:40.280]  То есть он, типа, вместил их.
[53:40.280 --> 53:42.280]  Ну да.
[53:42.280 --> 53:46.280]  Дальше, значит, мы сравним V1 и V2.
[53:46.280 --> 53:47.280]  Что такое V1 и V2?
[53:47.280 --> 53:50.280]  B и C, да.
[53:50.280 --> 53:52.280]  А дальше мы говорим следующее.
[53:52.280 --> 54:01.280]  Что если Conditions True, Conditions Selects в райс.
[54:01.280 --> 54:07.280]  А вот мы и поняли, как эти инструкции можно использовать.
[54:07.280 --> 54:17.280]  Я сейчас начну.
[54:17.280 --> 54:18.280]  Что?
[54:18.280 --> 54:19.280]  Да.
[54:19.280 --> 54:29.280]  Я пытаюсь быть шокер.
[54:29.280 --> 54:34.280]  Ясно, наверное, но мы пишем первый пол, а потом destination.
[54:34.280 --> 54:37.280]  Если пол, то второй пол, значит, destination.
[54:37.280 --> 54:39.280]  Так, я еще и задал вопрос, что не destination.
[54:39.280 --> 54:44.280]  Ну, destination первого и Conditions, а, Conditions конце.
[54:44.280 --> 54:48.280]  А, Conditions 1 и 2.
[54:48.280 --> 54:49.280]  А, все.
[54:49.280 --> 54:50.280]  Ага.
[54:50.280 --> 54:53.280]  So, plane, V4 или там 2.
[54:53.280 --> 54:54.280]  Да, да, да, да.
[54:54.280 --> 54:55.280]  То есть, что у нас получается?
[54:55.280 --> 55:02.280]  В общем, весело.
[55:02.280 --> 55:06.280]  Ну, что, по традиции, как говорится, уже.
[55:06.280 --> 55:22.280]  Да, да, да, да, да.
[55:22.280 --> 55:38.280]  Ну что, попробуем скомпилировать вот эту штуку.
[55:38.280 --> 55:43.280]  Давайте рубрика эксперимента.
[55:43.280 --> 55:49.280]  Посмотрим, что скомпилирует мой маг.
[55:49.280 --> 55:58.280]  Так, Selang, Minus S.
[55:58.280 --> 56:12.280]  О, Господи, как же он долго компилировал.
[56:12.280 --> 56:40.280]  А, я забыл опцию оптимизации включить.
[56:40.280 --> 56:42.280]  Да, да, да.
[56:42.280 --> 56:45.280]  Ну, не знаю, мне кажется, что он то же самое сделал.
[56:45.280 --> 56:51.280]  Молодец.
[56:51.280 --> 56:57.280]  Aram Selang.
[56:57.280 --> 56:59.280]  Да, да, да, да.
[56:59.280 --> 57:03.280]  Давайте посмотрим, как структурам обращаться.
[57:03.280 --> 57:07.280]  Что-то, где у нас?
[57:07.280 --> 57:12.280]  Массивы, да?
[57:12.280 --> 57:13.280]  Господи, и как это написать?
[57:13.280 --> 57:18.280]  Сейчас давайте подумаем.
[57:18.280 --> 57:22.280]  Так, идём сюда, идём сюда.
[57:22.280 --> 57:27.280]  Всё, давайте int.
[57:27.280 --> 57:36.280]  Как передать массив?
[57:36.280 --> 57:50.280]  А?
[57:50.280 --> 57:59.280]  Так, вот он код, кстати.
[57:59.280 --> 58:05.280]  Значит, давайте посмотрим, что у нас тут есть.
[58:05.280 --> 58:10.280]  Да, да, да.
[58:10.280 --> 58:11.280]  То есть, что он сделал?
[58:11.280 --> 58:33.280]  Он сделал jump if not equal.
[58:33.280 --> 58:35.280]  Да, то есть, смотрите, что тут происходит.
[58:35.280 --> 58:40.280]  Мы, значит, load-регистр x0x9, да?
[58:40.280 --> 58:42.280]  А, подождите.
[58:42.280 --> 58:51.280]  По-моему, он сделал следующую вещь.
[58:51.280 --> 58:55.280]  Кстати, интересно, что будет, если сделать 100.
[58:55.280 --> 58:56.280]  То же самое, да?
[58:56.280 --> 58:58.280]  А почему он x0x9 назвал их?
[58:58.280 --> 59:02.280]  Ну ладно, видимо, в обратном порядке.
[59:02.280 --> 59:08.280]  Ну да, да, да.
[59:08.280 --> 59:10.280]  То есть, у нас всегда, кстати, есть ещё регистры, которые
[59:10.280 --> 59:13.280]  необходимо именно сохранять.
[59:13.280 --> 59:18.280]  А?
[59:18.280 --> 59:29.280]  Чего, long?
[59:29.280 --> 59:53.280]  Так, сейчас подключу зарядник.
[59:53.280 --> 59:55.280]  То есть, смотрите, в чём особенность?
[59:55.280 --> 59:57.280]  Особенность в том, что он прибавляет не один, но
[59:57.280 --> 01:00:00.280]  прибавляет по восемь.
[01:00:00.280 --> 01:00:02.280]  Да, прибавляет size-ов для того, чтобы как раз к нему
[01:00:02.280 --> 01:00:03.280]  обратиться.
[01:00:03.280 --> 01:00:06.280]  А?
[01:00:06.280 --> 01:00:09.280]  А потому что это 4-битная архитектура.
[01:00:09.280 --> 01:00:14.280]  Размер long-а совпадает с размером слова.
[01:00:14.280 --> 01:00:25.280]  Тоже, тоже.
[01:00:25.280 --> 01:00:40.280]  Да, кстати, кстати, был забавный момент, что в какой-то
[01:00:40.280 --> 01:00:45.280]  проекте мы что-то делали под Arduino, и мы в качестве
[01:00:45.280 --> 01:00:49.280]  каунтера использовали, счётчика времени использовали
[01:00:50.280 --> 01:01:05.280]  А там им будут ввадьны, да.
[01:01:05.280 --> 01:01:14.280]  Чё?
[01:01:14.280 --> 01:01:17.280]  Чё он сделал, он цикл развернул?
[01:01:17.280 --> 01:01:44.280]  Мочесное.
[01:01:44.280 --> 01:02:04.280]  Какой?
[01:02:04.280 --> 01:02:32.280]  Ну да, да, да, да, да.
[01:02:32.280 --> 01:02:58.280]  Вот они, кстати, принимаемые значения, x0 плюс 64, x0, x0, x0 плюс 64.
[01:02:58.280 --> 01:03:03.280]  Да.
[01:03:03.280 --> 01:03:08.280]  А что такое в один точке?
[01:03:08.280 --> 01:03:35.280]  4 plus 4 plus 2, да?
[01:03:35.280 --> 01:03:39.280]  Ну, мощный.
[01:03:39.280 --> 01:03:52.280]  Так, кентам вернёмся?
[01:03:52.280 --> 01:03:55.280]  Ну, микрокод как-нибудь.
[01:03:55.280 --> 01:04:03.280]  Да, а v1.2 это у нас...
[01:04:03.280 --> 01:04:13.280]  А, развернутые, всё.
[01:04:13.280 --> 01:04:17.280]  То есть на самом деле современные процессоры умеют даже вот такое, то есть
[01:04:17.280 --> 01:04:19.280]  векторные инструкции, да.
[01:04:19.280 --> 01:04:37.280]  Эх, я боюсь, давайте посмотрим.
[01:04:37.280 --> 01:04:40.280]  Что он взял?
[01:04:40.280 --> 01:04:43.280]  XMM, да?
[01:04:43.280 --> 01:04:50.280]  Да.
[01:04:50.280 --> 01:05:05.280]  Да, то есть видно, что все инструкции так или иначе пытаются...
[01:05:05.280 --> 01:05:07.280]  Вот, в общем, вот такие вот интересные вещи, да.
[01:05:07.280 --> 01:05:11.280]  Понятно, что именно здесь важная особенность...
[01:05:11.280 --> 01:05:13.280]  А?
[01:05:13.280 --> 01:05:16.280]  Охё!
[01:05:16.280 --> 01:05:25.280]  А?
[01:05:25.280 --> 01:05:29.280]  Ну, кстати...
[01:05:29.280 --> 01:05:32.280]  Кстати, не только в этом...
[01:05:32.280 --> 01:05:35.280]  Это где?
[01:05:35.280 --> 01:05:37.280]  Ага.
[01:05:37.280 --> 01:05:40.280]  Ну да, кстати, как ни странно, вот если код...
[01:05:40.280 --> 01:05:43.280]  Вернуться к коду на куде...
[01:05:43.280 --> 01:05:47.280]  Там есть вот такая инструкция, причём она делает это векторно внутри одного варпа,
[01:05:47.280 --> 01:05:49.280]  то есть внутри одного сингла инструкции...
[01:05:49.280 --> 01:05:54.280]  А?
[01:05:54.280 --> 01:05:57.280]  Операция называется shuffle down.
[01:05:57.280 --> 01:06:08.280]  Синг.
[01:06:08.280 --> 01:06:10.280]  Во!
[01:06:10.280 --> 01:06:13.280]  Вот так она работает.
[01:06:13.280 --> 01:06:15.280]  Да, да, да, да.
[01:06:15.280 --> 01:06:19.280]  Ну, shuffle down, она двигает регистр на 4 влево.
[01:06:19.280 --> 01:06:23.280]  Ну, она...
[01:06:23.280 --> 01:06:25.280]  Не, ну тут тоже есть shuffle инструкция.
[01:06:25.280 --> 01:06:27.280]  То есть они все, я так или иначе, shuffle инструкцию,
[01:06:27.280 --> 01:06:31.280]  но скорее всего по наиде с x86.
[01:06:31.280 --> 01:06:34.280]  Вот, в общем, вот такие вот интересные вещи.
[01:06:34.280 --> 01:06:36.280]  То есть что у нас есть?
[01:06:36.280 --> 01:06:38.280]  У нас есть вами риск архитектуры, у нас есть вами циск архитектуры.
[01:06:38.280 --> 01:06:43.280]  Собственно, если вдруг кто-то хочет реализовывать бэк-энд,
[01:06:43.280 --> 01:06:45.280]  можно выбирать любую архитектуру по желанию.
[01:06:45.280 --> 01:06:47.280]  Понятно, что...
[01:06:47.280 --> 01:06:52.280]  Кстати, как вы думаете, под какой бэк-энд проще писать код?
[01:06:52.280 --> 01:06:54.280]  По-дармовски или по...
[01:06:54.280 --> 01:06:57.280]  Ой, под циск или под риск?
[01:06:57.280 --> 01:07:00.280]  Под риск.
[01:07:00.280 --> 01:07:01.280]  Да, да, да, да.
[01:07:01.280 --> 01:07:03.280]  Семблерного файла.
[01:07:03.280 --> 01:07:05.280]  Да, конечно, под риск всегда проще.
[01:07:05.280 --> 01:07:11.280]  Но, опять же, особенность в том, что именно с точки зрения железа
[01:07:11.280 --> 01:07:14.280]  риск архитектуры работает сильно капризней.
[01:07:14.280 --> 01:07:18.280]  Для того, чтобы сделать эту риск архитектуры рабочей,
[01:07:18.280 --> 01:07:20.280]  нужно сильно постараться.
[01:07:20.280 --> 01:07:26.280]  Все еще подъезжают в оперативе, а не в реглистпо,
[01:07:26.280 --> 01:07:30.280]  а на единый мультик копировать на одной граффе, а потом
[01:07:30.280 --> 01:07:32.280]  копировать обратно.
[01:07:32.280 --> 01:07:37.280]  Не, я говорю не про то, как этот код писать, а про то, что...
[01:07:37.280 --> 01:07:43.280]  Ага, ну да.
[01:07:43.280 --> 01:07:53.280]  Ну, это тоже есть такое.
[01:07:53.280 --> 01:07:59.280]  Не, просто, если честно говорить, то армовские процессоры, они просто
[01:07:59.280 --> 01:08:05.280]  с точки зрения неосвоенности архитектуры, они могут работать либо
[01:08:05.280 --> 01:08:09.280]  сильно энергоэффективно, вот те же самые маки, либо наоборот.
[01:08:09.280 --> 01:08:12.280]  Жрать энергии как не в себя.
[01:08:12.280 --> 01:08:15.280]  Ну да.
[01:08:15.280 --> 01:08:18.280]  И, как ни странно, тоже можно посмотреть.
[01:08:18.280 --> 01:08:20.280]  Я, кстати, сделаю эту вещь.
[01:08:20.280 --> 01:08:23.280]  У меня есть доступ к FPGA одной.
[01:08:23.280 --> 01:08:27.280]  Я, наверное, смогу сказать, какая там архитектура.
[01:08:27.280 --> 01:08:32.280]  Да, чтобы вы понимали, что такое FPGA.
[01:08:32.280 --> 01:08:37.280]  Это специальная плата, которую можно самостоятельно запрограммировать.
[01:08:37.280 --> 01:08:39.280]  Вот.
[01:08:39.280 --> 01:08:42.280]  И, собственно, выполнять разные операции.
[01:08:42.280 --> 01:08:44.280]  Именно зачастую под этим.
[01:08:44.280 --> 01:08:47.280]  То есть она у меня там используется для...
[01:08:47.280 --> 01:08:51.280]  Ну, не совсем даже.
[01:08:51.280 --> 01:08:55.280]  То есть можно самому запрограммировать чипы, и именно при помощи
[01:08:55.280 --> 01:08:57.280]  него выполнять операции.
[01:08:57.280 --> 01:09:00.280]  Просто там как раз всякие биоинформатические выравнивания
[01:09:00.280 --> 01:09:03.280]  происходят, просто говоря, на геном.
[01:09:03.280 --> 01:09:07.280]  Разработчики, конечно, утверждают, что их тул работает
[01:09:07.280 --> 01:09:09.280]  в разы быстрее.
[01:09:09.280 --> 01:09:11.280]  Но, типа...
[01:09:11.280 --> 01:09:14.280]  Ну, чтобы честно сказать, там, грубо говоря, чипы,
[01:09:14.280 --> 01:09:17.280]  на котором, типа, 20 ядер заявлено,
[01:09:17.280 --> 01:09:21.280]  работают где-то два раза быстрее, чем...
[01:09:24.280 --> 01:09:26.280]  Сейчас дайте мне не соврать.
[01:09:26.280 --> 01:09:30.280]  По-моему, где-то чем 100-ядерный компьютер.
[01:09:31.280 --> 01:09:34.280]  А? 100-ядерный ЦПУ.
[01:09:37.280 --> 01:09:40.280]  Нет, 100-ядер X86.
[01:09:44.280 --> 01:09:46.280]  Ну, это именно кластеры.
[01:09:46.280 --> 01:09:48.280]  То есть это именно СХД.
[01:09:48.280 --> 01:09:52.280]  То есть это вот как берется, все на слу уровне запускается.
[01:09:52.280 --> 01:09:54.280]  Ну и поехали.
[01:09:56.280 --> 01:09:59.280]  Не, ну в целом такие системы есть там.
[01:09:59.280 --> 01:10:03.280]  Просто берут процессоры, объединяют их в несколько...
[01:10:08.280 --> 01:10:10.280]  Да, да, да, да.
[01:10:10.280 --> 01:10:12.280]  В общем, вот такая вот вещь.
[01:10:12.280 --> 01:10:15.280]  Давайте сразу затравку на следующий раз.
[01:10:15.280 --> 01:10:18.280]  Больше мы с вами рассматривали всякие особенности,
[01:10:18.280 --> 01:10:20.280]  связанные с ассемблером.
[01:10:20.280 --> 01:10:23.280]  То есть вы поняли, что нам нужно делать большое количество
[01:10:23.280 --> 01:10:25.280]  виртуальных регистров.
[01:10:25.280 --> 01:10:27.280]  А теперь будет вопрос следующий.
[01:10:27.280 --> 01:10:29.280]  Как эти виртуальные регистры
[01:10:32.280 --> 01:10:34.280]  переправить в обычные регистры?
[01:10:34.280 --> 01:10:37.280]  И здесь как раз мы, так сказать,
[01:10:37.280 --> 01:10:40.280]  эту тему можно было рассматривать на уровне оптимизации.
[01:10:40.280 --> 01:10:43.280]  На теме, связанном с оптимизациями.
[01:10:43.280 --> 01:10:48.280]  Но мы к этой теме как раз приступим на уровне как раз выделения регистров.
[01:10:49.280 --> 01:10:52.280]  Да, то есть это как раз грав потоку управления.
[01:10:52.280 --> 01:10:54.280]  Нам как раз нужно будет его посмотреть.
[01:10:58.280 --> 01:11:02.280]  Да, то есть будем смотреть, кстати,
[01:11:02.280 --> 01:11:05.280]  и вообще, если смотреть на тему,
[01:11:05.280 --> 01:11:07.280]  которая будет этому посвящена,
[01:11:07.280 --> 01:11:09.280]  это алгоритмы раскраски на графах.
[01:11:11.280 --> 01:11:13.280]  То есть нам нужно будет построить граф пересечений
[01:11:13.280 --> 01:11:15.280]  и граф конфликтов,
[01:11:15.280 --> 01:11:17.280]  и его раскрасить в определенные цвета.
[01:11:19.280 --> 01:11:21.280]  Все, наверное, на этом даже все.
[01:11:23.280 --> 01:11:25.280]  Давайте вопрос.
[01:11:27.280 --> 01:11:29.280]  Вопрос.
[01:11:33.280 --> 01:11:35.280]  Окей.
[01:11:35.280 --> 01:11:37.280]  Да, вопросов нет.
[01:11:37.280 --> 01:11:39.280]  Ладно, тогда
[01:11:39.280 --> 01:11:41.280]  восстанавливаем все всем,
[01:11:41.280 --> 01:11:43.280]  кто смотрит в Ютубе.
[01:11:43.280 --> 01:11:45.280]  Всем хорошего дня.
