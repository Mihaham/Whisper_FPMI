[00:00.000 --> 00:12.520]  Отлично. Тогда смотрите. Наш план на сегодня. Я могу что-то рассказать, но в первую очередь я бы
[00:12.520 --> 00:18.400]  поговорил про задачи, которые есть в домашней работе, и про ваши вопросы, которые должны были
[00:18.400 --> 00:24.480]  возникнуть там. Ну, если они не возникли, я сам их обозначу, потому что в задачах есть,
[00:24.480 --> 00:27.840]  безусловно, о чем подумать. Ну, конечно, было бы здорово, если у нас было больше сейчас,
[00:27.840 --> 00:38.240]  потому что вопросов всегда было бы больше. Да, отлично. Я хотел бы поговорить сейчас в первую
[00:38.240 --> 00:42.960]  очередь про две задачи. Про мютекс в смысле про фьютекс, на самом деле, и про атомики,
[00:42.960 --> 00:48.800]  про спинлок в смысле про атомики. Вот. Там есть еще другие задачи. Ну, дедлок мы, кажется,
[00:48.800 --> 00:54.960]  обсуждали, философов. Про философов можно было бы поговорить, но, наверное, в чуть более полном
[00:54.960 --> 01:04.440]  составе. Давайте сначала поговорим про задачу спинлок. Вот, обращаю внимание, кто здесь делал,
[01:04.440 --> 01:21.840]  вообще, из присутствующих? А вы избегаете этой задачи? Ну, тогда я... Не знаю, может быть,
[01:21.840 --> 01:27.200]  для тебя так будет даже удобнее, а, может быть, и лучше было бы наоборот, кто знает. В этой
[01:27.200 --> 01:33.440]  задачи, на самом деле, есть две... Есть формальная задача. Написать какую-то реализацию. Так ты в
[01:33.440 --> 01:40.640]  курсе про условия, да? Вот. Написать о тамарной операции, которая позволит спинлок работать. И вот у вас
[01:40.640 --> 01:48.640]  есть какая-то заглушка. Она, ну, вроде бы, в какой-то степени даже реализация, непонятно, тамарная или
[01:48.640 --> 01:54.520]  нет, просто скорее иллюстрирует семантическую операцию, что каждый из этих лоудов, сторов,
[01:54.520 --> 02:04.200]  вообще, что-нибудь должен делать. Вот одна половина задачи — это и про то, что такое отомарность. Какие
[02:04.200 --> 02:10.400]  инструкции мы считаем отомарными? Как вообще об этом можно думать? Как реализована разная тамарная
[02:10.400 --> 02:18.160]  операция? Вторая часть задачи, мне кажется, не менее важная. Может быть, даже она точно не менее
[02:18.160 --> 02:23.400]  важная, и она точно намного более сложная. Это вот этот пункт из условия. Про то, чтобы подумать,
[02:23.400 --> 02:31.080]  а почему атомик ваш отличается от стд-атомиков, в котором на самом деле стор — это не одна операция,
[02:31.080 --> 02:36.400]  а... Ну, это один метод с тремя разными аргументами. И эти аргументы, дополнительный memory-order,
[02:36.400 --> 02:42.160]  который называется, почему-то влияют на реализацию. И это тоже можно поисследовать. Ну, в общем,
[02:42.160 --> 02:47.560]  без этих вопросов, без этого пункта задача, конечно, неполна будет. И про эти тесты это
[02:47.560 --> 02:51.760]  совсем не самая интересная задача. Это скорее первый, самый незначительный ее шаг.
[02:51.760 --> 02:59.480]  Задача, на самом деле, про исследование. Вот у вас есть первый понятный пункт — реализовать
[02:59.480 --> 03:04.800]  атомарные операции. И вы пишете какой-то код, вы, может быть, даже где-то его не меняете,
[03:04.800 --> 03:11.960]  где-то вы меняете его. Он начинает работать. Но вот, смотрите, одного этого мало, конечно же. То,
[03:11.960 --> 03:17.480]  что вы прошли тесты, ничего не означает. Это дает какую-то надежду, но, с другой стороны,
[03:17.480 --> 03:22.280]  вот вас самих это убеждает, что ваша реализация атомарная, что ваша реализация правильная или нет?
[03:22.280 --> 03:27.800]  Нет. Ну, то есть вы должны убедить... Конечно же, вы учитесь для себя, чтобы себя убедить,
[03:27.800 --> 03:31.760]  что вот действительно вы написали правильную реализацию. Но и на защите нужно будет убедить меня.
[03:31.760 --> 03:36.440]  Поэтому вам нужны какие-то более убедительные аргументы, нежели чем пройденные тесты. Тем более
[03:36.440 --> 03:41.480]  тесты, еще раз повторяю, у нас недетерминированные... Ну, в смысле, баги недетерминированные,
[03:41.480 --> 03:45.440]  поэтому если баг просто не возник в тестах, это не значит, что его нет. То есть если он возник,
[03:45.440 --> 03:50.200]  то точно знаем, что он есть, но если не возник, то, возможно, он есть. Возможно и нет. Мы эти
[03:50.200 --> 03:55.200]  ситуации не различаем здесь, поэтому нам нужен какой-то более надежный референс, на который можно
[03:55.200 --> 04:05.960]  соспаться. Ну, прежде чем эти референсы обсуждать, давайте какие-то общие свойства там атомарности
[04:05.960 --> 04:12.880]  на уровне процессора обсудим, то есть то, о чем мы точно верим. Вот скажем, ясно ли, что если
[04:12.880 --> 04:24.680]  мы на Assembler пишем две инструкции, то они точно в совокупности не могут быть атомарными. Вот
[04:24.680 --> 04:31.320]  между двумя этими инструкциями что может случиться? Чуть аккуратнее, может случиться
[04:31.320 --> 04:37.720]  прерывание интерапта. Вот процессор просто переключится на исполнение обработчика этого
[04:37.720 --> 04:43.280]  интерапта, но, видимо, на какой-то код ядра. Потом он к нам вернется. Ну, то есть и что в этом обработчике
[04:43.280 --> 04:47.720]  ядра может происходить? Может быть, это было прерывание по таймеру, там запустится процедура
[04:47.720 --> 04:53.960]  планировщика операционной системы, планировщик выберет другой поток и намажет его регистры на
[04:53.960 --> 04:58.680]  процессор, и процессор побежит дальше в другой код исполнить другие инструкции. Так что две
[04:58.800 --> 05:07.480]  инструкции это точно не атомарно. Но с другой стороны, есть инструкции, которые, скажем, работают только
[05:07.480 --> 05:15.520]  с регистрами. Вот мы двигаем что-то из одного регистра в другой регистр. Вот такие операции... Тут
[05:15.520 --> 05:21.000]  про атомарность вообще смысла говорить нет, потому что операции над регистрами это дело локальное
[05:21.000 --> 05:27.200]  для ядра. Каждого ядра свой собственный набор регистров, и пока это ядро общие ячейки памяти
[05:27.200 --> 05:29.200]  не трогает, вообще вопрос об атомарности не встает.
[05:29.200 --> 05:37.580]  По-моему, у нас может быть есть... Ну в МУВ МУВ он атомарный, потому что это же всеизмичное
[05:37.580 --> 05:43.400]  уритмное слово. А вот МУВы, которые МУВы меньше объема, они, кажется, не атомарные, потому что там еще
[05:43.400 --> 05:55.200]  поравнивание включается. Нет, все атомарно, конечно. Ладно. Аккуратно. Все атомарно. Конечно не все атомарно.
[05:55.200 --> 06:03.480]  Аккуратнее. Вот есть две инструкции, они в совокупности не атомарные, это мы хорошо понимаем. Еще одно
[06:03.480 --> 06:08.760]  свойство, которое важное, в котором мы тоже сомневаться не должны, но которое я не проговорил,
[06:08.760 --> 06:14.800]  а очевидным оно, возможно, не является. Вот мы смотрим на Atomic, у него довольно много операций
[06:14.800 --> 06:22.200]  атомарных. Сейчас мы вернемся. Вот фиджи, всякие вот вариации фиджи чего-нибудь,
[06:22.200 --> 06:27.800]  Compare, Exchange, Exchange, Load, Store. Но я Wait на TFI не беру, потому что это все сколы в ядро, это вообще не
[06:27.800 --> 06:34.400]  про атомарность операции, не про инструкции процессора. Так вот, вот все эти операции, Load,
[06:34.400 --> 06:43.920]  Store, Exchange, Compare, Exchange, Fidget, у них есть общее свойство. Они все работают только с одной
[06:43.920 --> 06:51.480]  разделяемой ячеек памяти. Вот, скажем, вы смотрите на операцию Exchange, и вот если вы, скажем так,
[06:51.480 --> 06:57.800]  неаккуратно, вы можете подумать следующее, что операция Exchange свопает две ячейки памяти. Вот то,
[06:57.800 --> 07:05.320]  что в аргументе и то, что слева от вызова, перед точкой написано. Это, конечно же, не так. Мы понимаем это?
[07:05.320 --> 07:17.720]  Или не понимаем? Вот мы передаем туда аргумент, значение, которое мы хотим записать. Аргументы
[07:17.720 --> 07:26.800]  передаются через регистры, ну или через стэк. Но что регистры, что стэк? Это вот память,
[07:26.800 --> 07:30.320]  которая локальна, она не разделяется между разными потоками, по крайней мере, пока мы сами это,
[07:30.320 --> 07:37.040]  народ, что не сделали. Вот у всех инструкций, через которые реализуется атомарная операция,
[07:37.040 --> 07:44.000]  есть общее свойство. Они всегда работают только с одной ячейкой памяти и с какими-то регистрами.
[07:44.000 --> 07:48.200]  Вот то есть, если мы говорим про реализацию Exchange, собственно, в «домашке» нужно будет найти
[07:48.200 --> 07:56.600]  инструкцию, которая реализует эту операцию. Вот вы там свопаете значение из регистра, то есть,
[07:56.600 --> 08:02.840]  локальное значение для вашего ядра, с содержимым ячейки памяти. У вас есть более сложные инструкции,
[08:02.840 --> 08:11.120]  вот скажем, есть операция Compare Exchange. Знакомы ли вы с ней? Вот. Ну, небольшой спойлер, но,
[08:11.120 --> 08:16.200]  кажется, уже не страшно. Есть задачи в «домашке», которые специально про то, чтобы про эту операцию
[08:16.200 --> 08:26.920]  узнать. И вот, она довольно... Что? Тебя интересует формальный ответ или содержательный? Содержательный,
[08:26.920 --> 08:32.680]  я от содержательного уклонюсь. Формально отличается тем, что Вик может, во-первых,
[08:32.680 --> 08:38.360]  семантика. Сравнить, если совпало, то записать, и вернуть true, если не совпало, то вернуть false.
[08:38.360 --> 08:46.280]  Вот. Само по себе операция сложная. И вот для неё есть какая-то отдельная инструкция,
[08:46.280 --> 08:54.560]  которая её реализует. И опять она работает с одной ячейкой памяти и набором регистров. Вот в
[08:54.560 --> 09:00.080]  регистры вы помещаете, перед выполнением этой инструкции, что вы хотите, что вы ожидаете,
[09:00.080 --> 09:05.640]  увидите ячейки памяти, что вы хотите записать в ячейку памяти. Вот. И инструкция выполняется,
[09:05.640 --> 09:11.360]  и вот, как бы, статус, то есть, результат, и ещё какой-то регистр. Опять, всегда любая сложная
[09:11.360 --> 09:16.080]  Тамарная операция, любая сложная такая инструкция, она будет трогать только одну ячейку памяти. В
[09:16.080 --> 09:21.160]  процессоре в любом, в принципе, невозможно написать инструкцию, которая была бы... Нет таких
[09:21.160 --> 09:25.200]  инструкций, таких процессоров, кажется, с такими инструкциями, где можно было бы, скажем,
[09:25.200 --> 09:31.720]  свопнуть две ячейки памяти или скопировать ячейку памяти в другую ячейку памяти Тамарную. У этого
[09:31.720 --> 09:39.400]  правила есть некоторые исключения. Вот, скажем, есть Compare Exchange 16B, то есть это Compare Exchange
[09:39.400 --> 09:44.320]  на 16 байтах, то есть на двух машинных словах. В некоторых современных процессорах Intel вы
[09:44.320 --> 09:52.400]  можете сделать Compare Exchange над 128-битным словом, то есть на двух ячейках, но только при условии,
[09:52.400 --> 09:57.760]  что они лежат прямо в памяти рядом, подряд, там и выровнено определённым образом. Или, скажем,
[09:57.760 --> 10:04.280]  есть такое понятие, как транзакционная память. Вот вы базу данных посещали, вы знаете,
[10:04.280 --> 10:14.320]  что есть транзакции? Есть транзакции, не знаете про транзакции. Ну, в общем, если коротко говорить,
[10:14.320 --> 10:21.440]  то некоторые процессы, не знаю, удачная эта идея или она оказалась неуспешным экспериментом,
[10:21.440 --> 10:25.480]  но в общем, в некоторых процессорах есть поддержка так называемой транзакционной памяти,
[10:25.480 --> 10:34.080]  где вы можете атомарно потрогать сразу несколько ячеек. И, может быть, операция будет успешной,
[10:34.080 --> 10:37.480]  а может быть, она провалится, потому что вот что-то пошло не так, почему это отдельная история,
[10:37.480 --> 10:42.440]  а она скорее про... В лекции про QC немного про это расскажу. Ну, в общем, это всё некоторые
[10:42.440 --> 10:45.680]  исключения, некоторые маргинальные случаи. Вот, в общем, можно считать, по крайней мере,
[10:45.680 --> 10:52.120]  про Atomic, что все операции, которые он умеет, он... Все операции, которые он выполняет на процессоре,
[10:52.440 --> 10:57.400]  здесь атомарные, Ridley-Fairbite, они все работают всегда только с одной ячейкой памяти. Это ячейка
[10:57.400 --> 11:03.240]  памяти, это сам Atomic. Все остальные аргументы – это регистры. Значит, это второе наблюдение
[11:03.240 --> 11:10.440]  про атомарность операции. То есть две инструкции не атомарны, между ними может вклиниться другой
[11:10.440 --> 11:14.800]  поток, может приключение случиться. Атомарные инструкции могут работать только с одной ячейкой
[11:14.800 --> 11:24.080]  памяти. И третье важное замечание, что отдельная инструкция не обязана быть, вообще говоря, атомарной.
[11:24.080 --> 11:32.320]  Ну, ответ здесь я не знаю, почему, я могу только некоторую интуицию предложить. Вот, скажем, есть
[11:32.320 --> 11:42.760]  инструкция Move. Чем она занимается? Move? Только этим занимается.
[11:44.800 --> 11:53.840]  Можно регистр скопировать, можно из памяти в регистр прочесть, можно из регистры в память
[11:53.840 --> 11:59.360]  записать. Вы же понимаете, что это не может быть одна инструкция в процессоре? Не атомарно. Нет,
[11:59.360 --> 12:04.560]  это дело не в атомарности, а в том, что инструкции процессора, инструкции в ассемблере – это же,
[12:04.560 --> 12:11.840]  ну, некоторый интерфейс. Понимаешь, что Move не может выполнять и то, и другое. Реализации в
[12:11.840 --> 12:17.040]  процессоре должны быть разные. И вот в процессоре есть некоторый микрокод, то есть, как он по-настоящему
[12:17.040 --> 12:20.480]  работает, а есть некоторый интерфейс, который просто он сохраняет, чтобы ваши программы старые не
[12:20.480 --> 12:27.200]  развалились ассемблянные. Вот, поэтому отдельная инструкция атомарности не означает само по себе.
[12:27.200 --> 12:36.560]  Ну, вот Move будет атомарен, а вот, скажем, вот этот самый Compare Exchange, он уже не будет атомарен. То
[12:36.560 --> 12:42.880]  есть, сама инструкция, она не атомарна. И для того, чтобы она стала атомарной, чтобы она превратилась в
[12:42.880 --> 12:49.520]  операцию Compare Exchange, там, Vicarious Strong, нужно кое-что еще сделать. И вот, ну, в этом и смысл Домашки,
[12:49.520 --> 12:54.960]  чтобы узнать, что нужно сделать. Вот здесь это как раз написано, я не буду просто подчеркивать это
[12:54.960 --> 13:02.240]  сейчас в скринкасте. Ну, вот, в частности, на этой страничке можно найти ответ. И вот задача в том
[13:02.240 --> 13:07.760]  числе про то, чтобы такие странички поискать, найти их, прочитать и разобраться с гарантиями. И вот так
[13:07.760 --> 13:14.480]  вы сможете убедить себя и меня. Вот, но есть, как бы, еще один вопрос. А как эти странички вообще
[13:14.480 --> 13:23.680]  найти? То есть, как найти инструкции, которые вы должны использовать? Ну, в условии есть дежурная
[13:23.680 --> 13:30.680]  подсказка и вот на предыдущем семинаре почему-то никто не заметил этой подсказки. Я тоже не знаю,
[13:30.680 --> 13:38.360]  мне тоже кажется, что очевидно. Ну, короче, вот нужно узнать про инструкции, нужно пойти в какой-нибудь
[13:38.360 --> 13:44.600]  мануал процессора или там найти хороший референс и там уже разобраться, с какими гарантиями у вас все
[13:44.600 --> 13:49.640]  работает. То есть, вы учитесь не для того, чтобы узнать, что вот здесь нужно вставить такую инструкцию,
[13:49.640 --> 13:53.920]  а чтобы понимать вообще, ну, такие вопросы, ответы находить. Это, кажется, более общий навык,
[13:53.920 --> 13:58.160]  более полезный. Ну, и про инструкции тоже разобраться. Сейчас, возвращаюсь к тому вопросу,
[13:58.160 --> 14:07.480]  наконец, я сбился, прости. Вот есть Compare Exchange Week и Strong. И вот оказывается, что на x86 две эти
[14:07.480 --> 14:13.880]  операции компилируют один и тот же машинный код. Ты можешь это проверить. Тебе следует это сделать.
[14:13.880 --> 14:21.560]  Вот. То есть, они на x86, вот на этом ноутбуке, они не отличаются ничем. Но формально они отличаются
[14:21.560 --> 14:29.560]  своими гарантиями, что Compare Exchange Week может вернуть false, даже если значение атомика ничей
[14:29.560 --> 14:37.160]  к памяти совпадает с аргументом expected. И более того, мы же используем Twist с вами для того, чтобы
[14:37.160 --> 14:45.200]  код тестировать. Сейчас, секунду, я просто предостерегу тебя и тех, кто, возможно, это
[14:45.200 --> 14:52.560]  посмотрит. Вот смотрите, что я недавно закоммитил, и в шаде это кому-то уже сломало решение. Вот наш
[14:52.560 --> 14:58.160]  атомник, он может иногда сказать Compare Exchange Week просто false, потому что имеет право на это
[14:58.160 --> 15:06.520]  формально. Почему так происходит? Я честный ответ дам на семинаре где-то спустя месяц-полтора, когда
[15:06.520 --> 15:10.800]  мы будем говорить про лукфри, и там вот эта операция Compare Exchange станет вот, мы с помощью
[15:10.800 --> 15:17.320]  лукфри еще не будем все на свете делать. Дело в том, что есть разные процессоры с разными
[15:17.320 --> 15:23.880]  атомарными инструкциями под капотом, и есть стандартная библиотека языка C++, есть атомик,
[15:23.880 --> 15:31.400]  и вот все операции, которые атомик предоставляет, должны быть реализуемы на каждом процессоре.
[15:31.400 --> 15:37.920]  Разумное требование, да? Ну то есть некоторые общие знаменатели. Вот, разумеется, процессоры,
[15:37.920 --> 15:44.560]  они разные по разным причинам, но может быть исторически по разным причинам. Вот у разработчиков
[15:44.560 --> 15:50.600]  процессоров был разный подход к тому, какие инструкции нужно иметь для синхронизации, но все-таки
[15:50.600 --> 15:55.960]  мир не совсем произвольно устроен, есть некоторые фундаментальные в нем законы, в том числе и
[15:55.960 --> 16:03.880]  синхронизацию, поэтому скорее набор разумных инструкций не такой уж и большой. Но вот в случае,
[16:03.880 --> 16:11.080]  скажем, Arma X86 этот набор отличается, и подход немного отличается к атомарности и к реализации
[16:11.080 --> 16:18.600]  таких операций, поэтому вот оказалось, что на Arma реализовать Compare Exchange, ну то есть там нет вот
[16:18.600 --> 16:24.240]  такой специальной инструкции прочитать, сравнить, если сравнить, то записать, вот просто такой готовой
[16:24.240 --> 16:29.360]  инструкции там нет, там есть другие отдельные инструкции чтения записи с некоторой хитрой
[16:29.360 --> 16:38.160]  дополнительной семантикой, и вот беда в том, что инструкции, которые есть на Arma, на X86 не выразить,
[16:38.160 --> 16:45.820]  но то, что есть на Arma, из них можно построить Compare Exchange, то есть вот из инструкции Arma можно
[16:45.820 --> 16:51.800]  построить вот такую инструкцию, ну примерно, наоборот нельзя, поэтому в Atomic есть такая операция,
[16:51.800 --> 16:58.280]  но оказывается, что на Arma ее можно написать по-разному, и одна операция будет иметь семантику WIC,
[16:58.280 --> 17:03.000]  но она будет иметь меньше аверхед, а другая реализация будет иметь семантику Strong,
[17:03.000 --> 17:07.760]  но иметь больше аверхед, и вот есть разные случаи, про которые мы поговорим в теме Prologue Free,
[17:07.760 --> 17:13.400]  когда тебе достаточно более слабые семантики и меньше аверхеда внутри реализации этой операции,
[17:13.400 --> 17:20.840]  я не знаю, запутать тебя или нет, то есть есть процессоры, где Compare Exchange, вот как сама
[17:20.840 --> 17:25.080]  логическая операция реализуется разными способами, вот есть две реализации, и одна из них может
[17:25.080 --> 17:32.480]  ошибаться, но иногда этого бывает достаточно, поэтому можем себе это позволить, в смысле ошибка,
[17:32.480 --> 17:37.400]  она не повлияет на корректность кода, а есть случаи, когда повлияет, ну вот, скажем, если ты пишешь
[17:37.400 --> 17:45.080]  Trialog в задаче против Kitlog, то ты понимаешь, что, ну видимо, там разумно использовать сильную
[17:45.080 --> 17:53.160]  гарантию, потому что если лог свободен, то он должен быть захвачен. Да, теперь у тебя был вопрос.
[17:53.160 --> 18:04.080]  То есть еще раз, регистры у нас у каждого ядра свои, и даже если это ядро при этом моменте прижмут,
[18:04.080 --> 18:14.040]  и вот когда оно вернется к исполнению этой функции, регистр окажется теми же самыми, которые были?
[18:14.040 --> 18:18.200]  Да, разумеется, ну представь, что ты компаниятор, ты генерируешь машинный код, и вот между двумя
[18:18.200 --> 18:22.680]  инструкциями все остальное может, все твоё состояние исполнения могут стереться, процессор, это было бы
[18:22.680 --> 18:26.680]  очень печально. Так что этим занимается процессор, то есть он поддерживает механизм прерывания,
[18:26.680 --> 18:33.360]  которым пользуется операционная система, и вот при прерывании делается снимок состояния регистров.
[18:33.360 --> 18:39.560]  Когда мы там переключаемся обратно, то мы снимок устанавливаем, намазываем процессор, и поток
[18:39.560 --> 18:50.080]  исполнения продолжается с того же места, где оно остановилось. То есть, разумеется, компилятор,
[18:50.080 --> 18:54.320]  или вот ты, когда смотришь на последовательный код, ты можешь считать, что возможно чередование,
[18:54.320 --> 19:01.600]  что потоки могут друг на друга переключаться, но при этом сам поток выполняется относительно
[19:01.600 --> 19:07.280]  какого-то стабильного состояния регистров. Память там может меняться, если между двумя инструкциями
[19:07.280 --> 19:13.320]  кто-то другой вклинился, память, конечно, может измениться, а регистры нет. Ну и есть частные случаи,
[19:13.320 --> 19:18.640]  когда ты вызываешь функцию, разумеется, когда ты пишешь инструкцию call в ассемблере, то после
[19:18.640 --> 19:24.640]  возврата из этого кола ты ожидаешь, что у тебя сохранились только часть регистров. Это про
[19:24.640 --> 19:35.720]  соглашение вызовов в Сталии. А вы не можете вообще рассказать про мембрио? К сожалению, я не могу,
[19:35.720 --> 19:43.840]  то есть я могу, конечно, но я не стану этого делать, потому что рассказ занимает шесть часов времени. Я
[19:43.840 --> 19:49.200]  могу только прокомментировать, чего мы хотим, чего я от вас хочу сейчас. То есть смотрите,
[19:49.200 --> 19:54.800]  вот этот пункт про atomic store и разные версии atomic store, о чем он вообще? О том, что вы пишете
[19:54.800 --> 20:01.640]  какой-то код, вот вы пишете atomic store, и вы как-то себя убеждаете, почему он атомарен. Вот,
[20:01.640 --> 20:06.960]  может быть, вы говорите, инструкция move просто атомарна. Вас это устраивает, вы пишете код,
[20:06.960 --> 20:13.400]  вот он копируется, работает. Вы думаете, но похоже на правду. А с другой стороны, вы смотрите
[20:13.400 --> 20:20.800]  на STD atomic, ну или вас призывают, посмотрите на STD atomic, и вот вы открываете любую операцию,
[20:20.800 --> 20:28.760]  в частности, store, и вы видите, что у нее есть аргумент, что записать, и у любой
[20:28.760 --> 20:36.920]  операции есть аргумент memory order. И очевидно, этот аргумент каким-то образом влияет на поведение
[20:36.920 --> 20:41.800]  этого store. И условия вам говорят, что от memory order вообще много разных бывает,
[20:41.800 --> 20:48.480]  но не все комбинации разумны, и вот в случае со store можно написать relax store,
[20:48.480 --> 20:57.000]  можно написать release store, и можно написать sequential и consistent store. И если вы научились разбираться,
[20:57.000 --> 21:01.640]  а как понять, ну то есть если вы научились смотреть assembler для ваших реализаций,
[21:01.640 --> 21:09.920]  то вы можете убедиться, что, скажем, в зависимости от аргумента, от выбранного memory order,
[21:09.920 --> 21:17.840]  ваша реализация, не ваша, а реализация store в STD Atomic меняется. Помните, я говорил, как вот
[21:17.840 --> 21:22.640]  найти вот эту инструкцию Comparachy, как вообще про нее узнать. Вот если вы знаете, как про нее
[21:22.640 --> 21:29.040]  узнать, то вы можете также узнать, что atomic store реализован по-разному, в зависимости от memory
[21:29.040 --> 21:36.920]  order, точнее, может быть реализован по-разному. Вот, ну и это первое наблюдение, которое вы должны
[21:36.920 --> 21:41.560]  сделать, что вот есть на самом деле много разных stores, то есть много разных способов записать
[21:41.560 --> 21:47.520]  значения в ячеек памяти разделяемую, ну и такой первый технический вопрос разобраться, а какую
[21:47.520 --> 21:56.560]  именно версию вы написали? Вот какой store у вас? Ну просто будет странно, если ваш store не совпадет
[21:56.560 --> 22:02.440]  не с одним, это будет подозрительно все же. Вот видимо совпадет. А дальше вопрос, ну там как бы есть
[22:02.440 --> 22:08.680]  много, не то что много, там есть еще интересные вопросы, но это скорее они для защиты предназначены.
[22:08.680 --> 22:14.800]  А вот второй вопрос сложный. Вот вы, допустим, узнали, что store есть разные, что они реализованы
[22:14.800 --> 22:19.480]  могут быть по-разному, что вы написали вот какой-то из них. А дальше вопрос, какой вам нужно было
[22:19.480 --> 22:26.320]  написать? Вот такой правильный. Ну под правильностью здесь можно разное понимать, ну во-первых,
[22:26.320 --> 22:31.120]  корректность разумеется, мы не должны нарушать, во-вторых, может быть есть разные корректные
[22:31.120 --> 22:38.000]  способы, а среди них есть вот более оптимальные, менее оптимальные. Вот ничего не объясняя, можно
[22:38.000 --> 22:46.520]  так сказать, что memory order, он нужен для того, чтобы оптимизировать. То есть это некоторая оптимизация.
[22:46.520 --> 23:00.080]  По умолчанию выбирается, видимо, самый надежный способ. Вот sequential и consistent atomic. Вот если вы не
[23:00.080 --> 23:04.280]  пишете дополнительных аргументов в операции атомика, то выбирается такой memory order и,
[23:04.280 --> 23:14.760]  видимо, он позволяет вам меньше всего думать про memory order. В примерах каких?
[23:14.760 --> 23:30.120]  Капер экченч. Если операция, если со мне неудачная, надо перезаписать, то мы используем
[23:30.120 --> 23:40.760]  релиз, а если неудачная и нам все равно, то релакс. Ну смотри, я бы предостерег тебя от таких, прямо скажем,
[23:40.760 --> 23:47.520]  очень поверхностных рассуждений. Они не имеют никакого понимания, никакого отношения к пониманию
[23:47.520 --> 23:51.560]  модели памяти. Не то чтобы это критика тебя, потому что ты не можешь сейчас его иметь, потому что
[23:51.560 --> 23:56.360]  sweeper-reference — это, прямо скажем, последнее место, по которому стоит учиться моделям памяти.
[23:56.360 --> 24:15.020]  Я начну и попробую объяснить про memory order немного, не забегая сильно вперед. Вот смотри,
[24:15.020 --> 24:23.400]  тебе нужно описать, что такое стандарт C++ или стандарт языка C. Вот какую задачу он решает?
[24:23.400 --> 24:39.720]  Стандарт фиксирует для вас семантику языка. Вот что значит программа на языке C,
[24:39.720 --> 24:53.520]  которая написана там int main, принтеф, потом return 0. Короче, вот семантика программы — как она
[24:53.520 --> 25:01.240]  себя ведет, грубо говоря, как можно об этом думать, о ее исполнении. И вот стандарт, скажем, C, он как
[25:01.240 --> 25:06.840]  решает этот вопрос, как он описывает семантику, он вам описывает некоторую абстрактную машину и
[25:06.840 --> 25:16.080]  как она исполняет вашу программу. Или, скажем, стандарт C++, я не помню, там же, наверное, нет понятия
[25:16.080 --> 25:21.680]  кучи и стек, но там есть automatic storage и еще какое-то название. Короче говоря, вам описывают машину,
[25:21.680 --> 25:28.200]  как она исполняет вашу программу. Скажем, там вот может быть описано, что если вы берете int 32
[25:28.200 --> 25:35.240]  и со значением 2 в 31 и минус 1 и добавляете к нему единицу, то что после этого последует?
[25:35.240 --> 25:43.400]  То есть вам говорят, что будущее состояние неизвестно. Или говорят, что будет, если у вас на самом
[25:43.400 --> 25:48.960]  деле переменная без знаков, и она переполнится. То есть описывают поведение двоустройства. И дальше
[25:48.960 --> 25:55.760]  компилятор обязуется при компиляции, компилятор для конкретной архитектуры обязуется обеспечить
[25:55.760 --> 26:02.240]  вашей программе вот такую вот семантику, потому что реальный компьютер может отличаться. В модели
[26:02.240 --> 26:12.400]  памяти это тоже ответ, как ведет себя программа. Это тоже описание семантики языка, но только
[26:12.400 --> 26:17.680]  программа многопоточной. То есть как ведет себя программа, в которой есть несколько потоков,
[26:17.680 --> 26:24.840]  которые общаются с общими человеками памяти. И ответ тут, ну и не то чтобы ответ пока, а реальность
[26:24.840 --> 26:34.920]  тут сложная. Вот мы на лекциях смотрели, вот такой пример. У нас были два потока и две ячейки
[26:34.920 --> 26:42.880]  памяти, разделяемые х и у. Ну и были еще две локальные, но вот с ними работает только один поток,
[26:42.880 --> 26:47.280]  поэтому ячейки, регистры, тут уже разницы нет. Поэтому они называются R1 и R2, это скорее регистры.
[26:47.280 --> 26:57.040]  И что делали потоки? Первый поток писал в X, читал из Y. Второй поток делал симметричный,
[26:57.040 --> 27:04.920]  писал в Y, читал из X. Ну вот очень простая программа на C++, в которой есть потоки,
[27:04.920 --> 27:11.040]  и эти потоки работают с несколькими ячейками памяти разделяемыми. Вот мы задаемся вопросом,
[27:11.040 --> 27:19.160]  какова симантика этой программы? Вот наивный и неправильный ответ – это модель чередования,
[27:19.160 --> 27:23.840]  когда мы переключаемся после любой инструкции на другой поток, но как будто мы исполняемся на
[27:23.840 --> 27:30.080]  одном ядре. А дальше мы запускаем этот код и видим, что реальность в эту модель не вписывается.
[27:30.080 --> 27:37.360]  То есть в этой программе можно увидеть и в R1 0 и в R2 0. Никаким чередованием такой ответ,
[27:37.360 --> 27:43.360]  такой исход не объясняется. Ну это же недetermинированные эффекты, это может,
[27:43.360 --> 27:52.200]  там не знаю, полминуты работать и не ломаться. Ну вот, смотри. Тут прошло много итераций. Тут
[27:52.200 --> 27:58.200]  процессор R1, а он сейчас у меня там IDE, код индексирует, там запись, видео пишет, скринкасс пишет.
[27:58.200 --> 28:04.840]  Много вещей влияет. Так вот, видите, что реальность сложная и нужно как-то описать,
[28:04.840 --> 28:10.080]  какие вообще исходы возможны. Вот модель памяти, если забегать сильно вперед,
[28:10.080 --> 28:17.280]  это способ описать семантику произвольных подобных программ. Как они могут себя вести,
[28:17.280 --> 28:24.880]  какие исходы в них возможны. И беда в том, что эта семантика, есть семантика операционная,
[28:24.880 --> 28:30.680]  есть семантика декларативная. Вот операционная семантика, это когда вам рассказывают, что вот
[28:30.680 --> 28:37.280]  есть там условно такая абстрактная машина, она вот так-то исполняет код. А есть семантика
[28:37.280 --> 28:43.800]  операционная, когда вам описывают, декларативная, когда скорее вам описывают наблюдаемые поведения
[28:43.800 --> 28:47.680]  всевозможные и не описывают, как они реализуются. То есть это посторонний вопрос. Почему так
[28:47.680 --> 28:52.200]  получилось? Вот модель памяти не пытается вам объяснить, почему так получилось. Почему здесь
[28:52.200 --> 28:58.280]  получилось два нуря? Она объясняет вам, какие исходы здесь вообще в принципе были допустимы. То
[28:58.280 --> 29:03.520]  есть на какие гарантии можно полагаться. И это сложно по двум причинам. Потому что сама по себе
[29:03.520 --> 29:09.960]  эта семантика сложная. А еще сложно, потому что она декларативная, а весь основной язык, а во всем
[29:09.960 --> 29:16.360]  остальном языке у вас семантика операционная. И вот это как бы плохо друг другу подходит. Ну и беда еще
[29:16.360 --> 29:22.760]  в том, что вот все эти референсы, именно такие программистские, инженерные, они не справляются
[29:22.760 --> 29:28.040]  с разумным. Операционная декларативная семантика это вообще, говорят там,
[29:28.040 --> 29:35.120]  некоторая формальная система. Это математика, короче говоря. Вот читать на программистском сайте
[29:35.120 --> 29:46.440]  про какую-то математику не стоит. Там плохо описано. Ну смотри,
[29:46.440 --> 29:56.840]  чтобы понять, изучать формализм редко, когда полезно. Формализм не объясняет,
[29:56.840 --> 30:02.080]  ну формализм, он формализм. Он просто тебе говорит вот так вот. Но с другой стороны,
[30:02.080 --> 30:08.560]  почему он такой? Вот тут вопрос не про формальное понимание гарантии, а про интуитивное понимание.
[30:08.560 --> 30:13.320]  Почему формализм именно такой? Потому что это же человеческий произвол. Вот модель памяти,
[30:13.320 --> 30:20.840]  это не то чтобы с неба спустилась, это же творение рук человека. Почему оно такое? Почему правила такие?
[30:20.840 --> 30:29.200]  Вот понимание модели памяти, оно не про то, какие правила есть, а про интуитивное понимание,
[30:29.200 --> 30:34.760]  почему они такие. Вот модель памяти это очень неинтуитивная штука для тех, кто ее изучает в
[30:34.760 --> 30:39.480]  первый раз. Но если ты ее поймешь по-настоящему, как она работает, почему все так, то все становится
[30:39.480 --> 30:45.120]  очень интуитивно. И вот тебе, наоборот, не хочется думать про процессоры, про то, что в них что-то
[30:45.120 --> 30:49.560]  там переставляется местами. То есть можно было бы ожидать, что, например, процессор вот эту инструкцию
[30:49.560 --> 30:56.280]  выполнил до этой, переставил их местами. И тогда бы это все объяснило. И в каком-то смысле так и есть.
[30:56.280 --> 31:02.800]  Но это сделает конкретный процессор, а другой процессор, там какой-нибудь ARM, Macbook, он сделает
[31:02.800 --> 31:09.200]  по-другому. И вот думать нужно не про то, что именно он сделал, а про то, на какие гарантии мы можем
[31:09.200 --> 31:15.560]  полагаться. Вот модель памяти про это и вот настоящее понимание модели памяти, оно про то, откуда эти
[31:15.560 --> 31:21.560]  правила берутся, почему они именно такие. Потому что вот в моделях памяти очень много терминов. Там
[31:21.560 --> 31:28.160]  десятки каких-то понятий, они как-то вот связаны между собой, там какие-то исключения есть. Очень
[31:28.160 --> 31:33.520]  много комбинаций мем реордеров, которые можно использовать. Вот если просто читать референс,
[31:33.520 --> 31:41.880]  то запутаешься просто-напросто. Нужно подходить по-другому. Вот мы на реакции попытаемся пойти по-другому,
[31:41.880 --> 31:49.200]  я объясню, откуда этот формализм берется, как его интуитивно понимать. Ну и вообще тема,
[31:49.200 --> 32:00.200]  которая до сих пор люди исследуют, хорошего решения нет. Вот модель памяти C++, в ней есть некоторые
[32:00.200 --> 32:07.600]  противоречия, ну точнее некоторые, в общем дыры в ней есть и есть что-то, что лучше бы вообще в ней
[32:07.600 --> 32:14.320]  не было. Ну не знаю, как это объяснить. Короче, очень сложно, не нужно сейчас это понимать, невозможно
[32:14.320 --> 32:23.640]  это сейчас понять. Можно пробовать. В задании про... нет, ты не понимаешь мой замысел. В задании
[32:23.640 --> 32:32.400]  смотри, что просят. В задании просят, во-первых... сейчас мы вернемся. Во-первых, вас спрашивают,
[32:32.400 --> 32:40.440]  вот посмотрите, вот на Atomic Store, и убедитесь, что там есть аргумент memory-order, и вот есть три
[32:40.440 --> 32:53.080]  варианта. Первый шаг, второй шаг. Ну нет, их меньше, потому что не все они разумны просто. Вот некоторые
[32:53.080 --> 32:57.000]  не стоит писать, потому что ты не знаешь, что будет. Это будет... я бы сказал, что TOB будет, если ты напишешь
[32:57.000 --> 33:07.800]  Store с memory-orderm Acquire. Это бессмысленно. Вот в условии написано, какие варианты осмысленные,
[33:07.800 --> 33:13.120]  какие значения осмысленные. Вот, и ты дальше исследуешь, что вот для каждого из них может быть
[33:13.120 --> 33:18.520]  своя реализация, а может быть какие-то... а может быть даже странно очень, что memory-order бывают
[33:18.520 --> 33:23.680]  разные реализации одна. Вот, ну это как бы ты все еще способен это постичь, потому что ты можешь
[33:23.680 --> 33:30.160]  посмотреть просто на то, в какой Assembler компилируются вызовы Store для разных memory-orders. Как это
[33:30.160 --> 33:35.480]  сделать, написано в условиях, в общем-то. Вот дальше вопрос. Store для какого memory-order вы
[33:35.480 --> 33:39.520]  реализовали? Ну опять, просто сравниваешь свой код, сравниваешь там разные реализации, которые
[33:39.520 --> 33:45.240]  ты видишь, говоришь, вот такой вот я реализовал. Вот, это пока никакого понимания не добавляет. Это
[33:45.240 --> 33:50.560]  скорее просто добавляет тебе понимание, что мир сложен. Вот, дальше ты спрашиваешь, какая версия
[33:50.560 --> 33:56.040]  нужна спинлоку? И тут ты пытаешься ответить. А как это просто ответить, не разбираясь? Невозможно.
[33:56.040 --> 34:04.680]  Невозможно. Ну, то есть, чтобы ответить на этот вопрос, нужно хорошо понимать модель памяти.
[34:04.680 --> 34:08.960]  Если вдруг ты хорошо понимаешь модель памяти, ты сможешь на него ответить. Если нет, то ты просто
[34:08.960 --> 34:14.520]  этот вопрос в голове себе подвесишь, и рано или поздно мы его разберем. Ну, просто смотри, я же
[34:14.520 --> 34:20.040]  не могу прийти на лекцию и сказать, а вот сегодня на смотри памяти. И ты такой, ну хорошо, изучим и это
[34:20.040 --> 34:26.880]  сейчас. Должна быть какая-то мотивация к этой теме. Ну вот, я так очень издалека к этому подхожу.
[34:26.880 --> 34:34.520]  Вот, видимо, какая-то мотивация есть. Видимо, ну, почему ты, то есть, ты видишь, что в Atomic есть разные
[34:34.520 --> 34:42.480]  версии Store. Ты не понимаешь, какую версию нужна спинлоку. Какая из них корректная, какая из них
[34:42.480 --> 34:50.480]  оптимальная. И вот у тебя вопрос, почему в Atomic Store три версии, и какую из них подобрать спинлоку.
[34:50.480 --> 34:58.440]  И вот, в частности, этот вопрос мы отвечаем на лекции про модель памяти. То есть, у тебя уже есть какой-то
[34:58.440 --> 35:06.000]  открытый вопрос. Сейчас ты вряд ли сможешь ответить на него сам. Ты можешь попробовать читать документацию,
[35:06.000 --> 35:11.280]  но смотри, я очень предостерегаю всех, кто, не знаю, послушает эту запись, и тех, кто присутствует здесь,
[35:11.280 --> 35:16.880]  пока memory-ордеры какие-то писать. Вот ты мне говоришь, я подсчитал, там есть какие-то примеры,
[35:16.880 --> 35:22.960]  вот релиз, релакс, что-нибудь еще. Вот это такое абсолютно, ну, за этим никакого понимания не стоит.
[35:22.960 --> 35:30.880]  Такие-то общие рецепты. Нужно писать вот так вот. Там написано так. Пока, вот, смотри, универсальное
[35:30.880 --> 35:36.320]  правило, которое точно верно. Если ты не уверен, что ты хорошо понимаешь memory-ордеры, и модели памяти,
[35:36.320 --> 35:41.600]  в принципе, то не нужно писать memory-ордеры, потому что правильно ты их не сможешь представлять.
[35:41.600 --> 35:46.160]  Если ты не будешь писать ничего, то есть, будет представляться дефолтный, то дефолтный дает самые
[35:46.160 --> 35:53.120]  сильные гарантии. То есть, он наиболее безопасен. То есть, если проблема будет, то она будет не с
[35:53.120 --> 36:00.520]  memory-ордерами. Так что пока я призываю просто писать, там, сторы, лоды, лишних аргументов не
[36:00.520 --> 36:07.440]  добавлять. После лекции про модели памяти можно будет, когда это уже будет осознанно. Просто там
[36:07.440 --> 36:11.920]  копировать какие-то рецепты из документации, это, вот, боюсь, что не сработает. Там нужно
[36:11.920 --> 36:16.920]  некоторые общие правила в голове иметь, которые в документации не описаны, к сожалению. Ну, они мало
[36:16.920 --> 36:24.360]  где описаны. Вот мы их обсудим на семинарах позже. Вот это, то есть, сложная тема, и в задачу
[36:24.360 --> 36:32.040]  предлагается в нее немножко закопаться, просто поисследовать, как тут устроен мир. Хорошо,
[36:32.040 --> 36:40.720]  давайте про FUTX поговорим теперь. Мы на лекции почти ничего не успели, просто сказали, что он есть.
[36:40.720 --> 36:49.040]  Вот. Для чего он есть? Для чего нам предлагается его использовать в домашних работах? Для
[36:49.040 --> 36:54.040]  блокирующего ожидания. Мы в домашних работах пишем свой Mutex, который блокирует потоки,
[36:54.040 --> 36:59.800]  которые ждут блокировки. Она захвачена другим потоком. Мы пишем сейчас уже кондвар, с помощью
[36:59.800 --> 37:04.160]  которого можно дожидаться выполнения некоторого состояния, некоторого предиката на некотором
[37:04.160 --> 37:09.560]  состоянии, блокирующей очереди. Вот. И задача подождать чего-то — это задача, которая не
[37:09.560 --> 37:16.520]  решается на уровне процессора, на уровне ваших инструкций. Потому что, если вы на ядре,
[37:16.520 --> 37:21.240]  то вы исполняете инструкции, а вы в Mutex Log хотите не исполнять инструкции, из процессора уйти.
[37:21.240 --> 37:26.800]  Единственный способ для этого — обратиться к ядру и сказать, чтобы она вас с процессора сняла.
[37:26.800 --> 37:33.960]  То есть, сделать сискол в планировщиках. У вас есть этот сискол, он называется Futex. Если вы на него
[37:33.960 --> 37:41.880]  посмотрите, то окажется, что он чертовски сложен. То есть, это сискол один, но у него есть аргумент
[37:41.880 --> 37:49.320]  Futex Op, то есть, операция, которую мы выполняем с ним Futex, и тут много вариантов. Wait, wake,
[37:49.320 --> 38:00.360]  и мы про другие даже ничего не говорим. И есть еще какое-то количество разных других. Вот. Мы в это
[38:00.360 --> 38:06.520]  не погружаемся, нам и двух хватит, уже довольно сложно. Значит, в чем идея? Это очередь для ожидания.
[38:06.520 --> 38:14.840]  Ну вот, мы так интуитивно представляем себе планировщик. В нем есть какая-то очередь потоков,
[38:14.840 --> 38:20.600]  которые готовы исполняться, но еще не исполняются. И мы, видимо, на ближайшие лекции это обсудим,
[38:20.600 --> 38:26.920]  когда будем рассматривать Fiber, как они устроены. Там будет планировщик с очередью. Но вот Futex — это
[38:26.920 --> 38:32.240]  тоже очередь, только не на исполнение, а на ожидание. То есть, это очередь, которая находится снаружи от
[38:32.240 --> 38:39.360]  планировщика, и мы в нее встаем, когда не хотим исполняться. Мы говорим atomic wait, или прямо
[38:39.360 --> 38:47.760]  говорим syscall Futex с режимом Futex wait, и встаем в эту очередь. Когда другой поток говорит Futex wake,
[38:47.760 --> 38:53.640]  Futex с Futex wake, то он нас в этой очереди будет, и мы возвращаемся в планировщик. То есть, мы
[38:53.640 --> 39:02.880]  перемещаемся из одной очереди в другую очередь. Но есть тонкость, потому что, как мы, кажется,
[39:02.880 --> 39:13.240]  из условия и вообще из описания atomic wait в STD видим, семантика вызова wait — не просто запарковать
[39:13.240 --> 39:20.280]  поток в очереди. Она немного сложнее. Она про то, чтобы сравнить значение atomic с аргументом,
[39:20.280 --> 39:33.400]  и только если оно совпадает, то тогда уснуть. И вообще, сам Futex, ну просто by design, он связывает
[39:33.400 --> 39:39.880]  очередь ожидания с некоторым адресом в вашей памяти, то есть, с некоторой ячеек памяти.
[39:39.880 --> 39:48.280]  То есть, семантика Futex — это не просто добавить поток в очередь, а прыгнуть в syscall, там прочесть
[39:48.280 --> 39:54.960]  содержимое вот этой ячейки памяти, сравнить его с передным аргументом, и если совпало значение,
[39:54.960 --> 40:01.280]  то тогда запарковать поток в очереди. Если не совпало, то просто разбудить сразу, выйти из wait
[40:01.280 --> 40:11.920]  обратно. Ну вот, такая довольно нетривиальная семантика, и хотелось бы понять, почему все
[40:11.920 --> 40:20.840]  именно так. Вот, есть ли у вас понимание, почему, казалось бы, проверка, сравнение содержимого ячейки
[40:20.840 --> 40:26.920]  с значением? То есть, если совпало, то заснуть. Вот почему, если совпало, то нужно делать user
[40:26.920 --> 40:36.400]  space в ядре? Зачем это прямо в syscall тащить? Почему в нашем коде не прочитать, не сравнить,
[40:36.400 --> 40:42.480]  и только после этого просто запарковать поток в очереди? Что значит можно? Тут вопрос уже не про
[40:42.480 --> 40:51.120]  можно, тут вопрос как бы, что будет работать не так? Ты решал задачу Mutex? Это усложняет
[40:51.120 --> 40:55.760]  меня этот вопрос, потому что задача Mutex про это. А кто решал задачу Mutex? И вы знаете ответ?
[40:55.760 --> 41:02.520]  Нет. Что значит нет? Я не понимаю, зачем вы вообще что-либо проверяете. Ты хочешь запарковать поток?
[41:02.520 --> 41:12.680]  Там же в задаче говорят, что для тех, кто не хочет ничего сравнивать, там же есть вот такой
[41:12.680 --> 41:23.880]  странный вспомогательный класс, у которого есть просто методы park и wait. Я реализовал почти такие
[41:23.880 --> 41:31.640]  методы, как там сам. Но с ними невозможно в сеть Mutex? Ну не знаю. Он не будет работать,
[41:31.640 --> 41:35.480]  он будет зависеть. Я еще один вопрос. Атомик, возможно, немного кастритный, но по-моему,
[41:35.480 --> 41:41.000]  который дает нормально в городе. Нет, то, что ты мог написать кастрит, я не сомневаюсь,
[41:41.000 --> 41:48.240]  это можно было бы сделать. Но вот таких методов точно недостаточно. Вот вот таких просто запарковать
[41:48.240 --> 42:01.440]  и разбудить. И объяснить это очень легко. Что такое Mutex? Это, в конце концов, ячейка памяти,
[42:01.440 --> 42:09.240]  которая написана в простейшем случае. Либо 0, либо 1. 0 свободен, 1 захвачен. И вот вы приходите и
[42:09.240 --> 42:16.360]  пытаетесь его захватить. Делаете, видимо, экченж. Пишете единицу, читаете то, что в нем было. Читаете,
[42:16.360 --> 42:23.040]  допустим, 0. Ну отлично. Вызов лог завершился, вы захватили его. Ладно, второй случай,
[42:23.040 --> 42:29.480]  прочитали единицу. Это значит, лог уже захвачен, и вы должны ждать. И тут, казалось бы, нужно просто
[42:29.480 --> 42:40.720]  взять и заснуть. Ну а теперь ситуация. Два потока. Один вызывает лог. Делает экченж, видит,
[42:40.720 --> 42:47.880]  что в ячейке единица. То есть Mutex захвачен. И у него следующая строчка заснуть. И вот между
[42:47.880 --> 42:52.640]  этими двумя строчками выполняется онлог до второго потока. Второй поток, что он делает? Сбрасывает
[42:52.640 --> 43:00.280]  ячейку в ноль и говорит на tify. И никого не будет, потому что в очереди пока никто не спит. И все.
[43:00.280 --> 43:10.080]  И Mutex свободен, а поток засыпает. И он блокируется вот навсегда. Проблема понятна, да? Казалось бы,
[43:10.080 --> 43:17.000]  почему проверка в ядре этому должна помочь? Почему вообще важно нам в ядре или в userspace? В конце
[43:17.000 --> 43:22.680]  концов, когда мы сделали экченж, мы уже сделали сравнение. Мы уже прочитали значение и сравнили его
[43:22.680 --> 43:28.880]  с нулем. Не совпало. Зачем нам прыгать в ядро и еще раз перечитывать ячейку и проверять ее?
[43:28.880 --> 43:42.920]  Ответа на этот вопрос нет, пока мы не знаем реализацию Fuedex. Такая штука, про которую нужно
[43:42.920 --> 43:50.960]  знать, как она устроена. Потому что иначе она полностью понятна не будет. Смотрите, Fuedex это очередь
[43:50.960 --> 43:58.920]  в ядре, которую мы адресуем с помощью ячейки памяти, с помощью поэнтера. Конечно же, ядро не то,
[43:58.920 --> 44:05.360]  чтобы отдельную очередь заводит для каждой ячейки памяти, с которой вы работаете. Устроена эта
[44:05.360 --> 44:11.680]  техническая подробность. Можно в принципе об этом не думать, но раз уж картинка есть, покажу. Вот вы
[44:11.680 --> 44:19.960]  приходите в ядро с адресом A, допустим, и ядро хэширует его, и вы падаете в бакет. И в этом бакете
[44:19.960 --> 44:29.960]  сложены все ждущие потоки для всех адресов, которые хэшом отображаются сюда. Когда вы засыпаете на
[44:29.960 --> 44:40.960]  адресе A, вы падаете в эту очередь. Когда другой поток будет вас по адресу A, делает Fuedex wake по
[44:40.960 --> 44:53.400]  адресу A, то он адрес снова хэширует, падает в бакет, идет по этому бакету и будет только те потоки,
[44:53.400 --> 45:01.080]  которые привязаны к адресу A. Если вы сделали Fuedex wake и будет один поток, то разбудится один. Если
[45:01.080 --> 45:12.960]  O, то все зеленые. Нет никакого спонтанного пробуждения, почему? Там же написано, это A или B. Вот
[45:12.960 --> 45:20.720]  ядро посмотрит, что вот A и раз будет в A, B не будет. Вот видишь, на картинке написано, что A. Вот мы это
[45:20.720 --> 45:31.920]  используем. Тут ничего криминального нет. Просто такая вот очередь. Это очередь, в которой работают
[45:31.920 --> 45:46.440]  разные сисколы. На одном ядре выполняется Fuedex wake. Мы просто списки храним в общем, много списков храним в одном.
[45:46.440 --> 45:54.280]  Причем тут хэширование? Мы не хэш таблицу строим, мы списки храним. Ну это не хэш таблица,
[45:54.280 --> 46:04.680]  она не хранит. Ладно, это довольно правильный вопрос. Зачем мы используем хэширование? Нам
[46:04.680 --> 46:24.240]  в списке именно нужно обходить списки. Вопрос посторонний обсуждается. Это способ, каким ядро хранит
[46:24.240 --> 46:32.760]  все эти очереди. Можно считать, что для каждой человек своей очередь, свой список не важно. Но важно,
[46:32.760 --> 46:38.680]  что у вас есть два ядра, скажем, в процессоре. И на одном ядре выполняется сискол Fuedex wake,
[46:38.680 --> 46:47.560]  на другом исполнится сискол Fuedex wake. И они работают с одним списком. И, разумеется, уже на уровне ядра
[46:47.560 --> 46:55.960]  нужно делать взаимные исключения. Поэтому этот список, вот этот бакет, он защищается спинлоком в ядре.
[46:55.960 --> 47:06.400]  И в условии задачи вам предлагают, пожалуйста, сходите по очень хорошей ссылке, где все написано,
[47:06.400 --> 47:15.160]  как все работает. Это ядро Linux, это то место, через которое нужно изучать ядро Linux. Это
[47:15.160 --> 47:22.480]  такая наименьшая косменность возможная. И смотрите, что здесь написано. Когда мы делаем сискол
[47:22.480 --> 47:33.960]  Fuedex wake, вот с такой ячейкой памяти, с таким значением, то мы читаем, вот такая вот наивная
[47:33.960 --> 47:42.280]  реализация. Мы читаем ячейку памяти, сравниваем, потом берем бакет, лочим бакет и вставляем в очередь.
[47:42.280 --> 47:50.000]  Вот такого, конечно же, делать нельзя. Почему? Потому что, ну смотрите, вот еще раз повторю пример.
[47:50.000 --> 48:01.720]  Вы прочли ячейку памяти, а потом ее сравнили со значением. Оно совпало. Но между вот этими
[48:01.720 --> 48:05.480]  двумя операциями вклинился другой поток, который ячейку памяти изменил и сделал wake.
[48:05.480 --> 48:16.960]  И в итоге этот поток все равно заснул. То есть он прочел старое значение, оно тут же изменилось,
[48:16.960 --> 48:27.520]  но первое ядро этого не увидело и заснуло. Это вот ровно сценарий зависания в Fuedex. Поэтому
[48:27.520 --> 48:38.120]  настоящий Fuedex устроен по-другому. Он сначала лочит бакет и только после этого читает содержимые
[48:38.120 --> 48:44.800]  ячейки. И именно поэтому все в ядре происходит. Именно поэтому чтение в ядре повторяется. Как это
[48:44.800 --> 48:51.640]  помогает? Вообще говоря, после этого чтения на другом ядре может быть выполнена запись в ячейку
[48:51.640 --> 49:03.600]  памяти. То есть вы пытались взять Mutex, сделали Exchange, увидели единицу, пошли во Fuedex спать. Во Fuedex
[49:03.600 --> 49:10.040]  еще раз перечисли ячейку, увидели там снова единицу. Но вроде бы нужно засыпать. И тут на другом ядре
[49:10.040 --> 49:18.080]  сразу после этого в операции Unlock другой поток ячейку сбрасывает в ноль. То есть все, ваша проверка
[49:18.080 --> 49:29.880]  дважды устарела. Но это не... В сущности, нет, ячейка не залочена. Почему залочена? Вот ячейка,
[49:29.880 --> 49:34.880]  она просто ячейка. Вот вы ее здесь прочли на одном ядре, а на другом ядре ты записал в эту ячейку.
[49:34.880 --> 49:51.000]  Никто никому не мешает. Вот, смотрите, мы можем, как и раньше, прочесть старое значение, его тут же
[49:51.000 --> 49:58.280]  перепишут. Но раньше Fuedex Wake мог уклиниться между вот этой чтением и проверкой. А сейчас Fuedex Wake
[49:58.280 --> 50:06.400]  он берет лог на bucket. А у нас лог уже взят. И поэтому он не может вот сюда вставиться. Вот этот
[50:06.400 --> 50:14.200]  код, он не может выполниться... Вот этот wake не может выполниться вот здесь вот. То есть, смотри,
[50:14.200 --> 50:21.960]  weight относительно store не атомарин, разумеется. То есть store может вклиниться в середину weight,
[50:21.960 --> 50:31.320]  а вот здесь вот. Вот store, а вот weight исполняется в ядре. Но natify в weight вклиниться не может,
[50:31.320 --> 50:40.280]  потому что natify и weight работают с общим спинлоком в ядре. И именно поэтому чтение внутри
[50:40.280 --> 50:49.440]  сискола, потому что чтение внутри спинлока в ядре. Ну тут такой тонкий момент, но если его понять,
[50:49.440 --> 50:55.080]  то гарантия станет ясной. То есть нужно понять в первую очередь, от какого сценария мы стараемся
[50:55.080 --> 51:00.000]  избавиться. Вот от такого сценария, где поток анлочного видоса и другой поток не увидит,
[51:00.000 --> 51:10.800]  а твой засыпает навечно. Это вообще псевдокод. DataRace в смысле, потому что у тебя есть просто
[51:10.800 --> 51:19.280]  ячейка памяти, и ты в нее пишешь и читаешь. Смотри, ядро линукса это не язык C++ уж точно,
[51:19.280 --> 51:28.200]  и там своя модель памяти. То есть там свои правила, что считать DataRace, что не считать,
[51:28.200 --> 51:34.400]  какие там гарантии. В C++ вы даны одни правила. Ну еще раз, это правила. Понимаете, правила,
[51:34.400 --> 51:51.640]  они говорят, это УБ, но компьютер от этого не взрывается. В этой программе УБ. То есть просто
[51:51.640 --> 51:58.360]  напросто вам не говорят ни про какие гарантии здесь. Но при этом программа, она вполне себе
[51:58.360 --> 52:03.600]  компилируется в какой-то понятный код и потом исполняется процессором. И там никаких ошибок,
[52:03.600 --> 52:08.000]  конечно, не возникает, никаких проблем нет. Просто модель памяти отказывается вам давать
[52:08.000 --> 52:14.800]  гарантии относительно поведения этой программы. Может быть у ядра линукса более сложные гарантии,
[52:14.800 --> 52:19.600]  более сложные модели памяти. А давайте мы ее найдем. Это очень любопытный пример.
[52:19.600 --> 52:42.400]  Я хочу прямо... Сейчас, если быстро получится найти. Вот описание модели памяти линукса,
[52:42.400 --> 52:52.440]  то есть как ядро работает с ячейками памяти. Ну и... Такое-то очень короткое описание. Это не то.
[52:52.440 --> 53:09.680]  Сейчас это... Explanation, вот. Explanation, по-моему, оно. Смотрите на размер ползунка. Вот. Это как бы
[53:09.680 --> 53:19.280]  главы. 25 таких параграфов. Вот. Довольно сложно. То есть как ядро работает с памятью и какие там
[53:19.280 --> 53:24.480]  возможны сценарии. Их много, они сложные, и там гарантии сложные. Это вот декларативная модель
[53:24.480 --> 53:31.600]  памяти для ядра линукса. Она своя. То есть формально в C++... Можно я закончу ответ на вопрос?
[53:31.600 --> 53:36.720]  Формально в C++ это был бы датарейс. Если это просто ячейка памяти, не атомика, и ты пишешь,
[53:36.720 --> 53:45.120]  читаешь без синхронизации. Линукса просто свои правила. И правила не влияют на реальность. Поэтому
[53:45.120 --> 54:01.640]  противоречия нет никакого. Вот C++ это датарейс. Да, слушаю тебя. Во-первых, видимо, да. Во-вторых,
[54:01.640 --> 54:17.000]  нет, не легче. Дело-то не в том... Проблемы с моделью памяти в любом языке, они примерно одинаковые.
[54:17.000 --> 54:28.320]  Тут выбор на стороне разработчиков языка, насколько большую свободу ты дашь разработчику. Вот в
[54:28.320 --> 54:34.560]  Java, скажем, нет вот этих всех memory-ордеров. Там модель памяти сложная по-своему. Получился
[54:34.560 --> 54:41.440]  семинар про модель памяти. Не то, что я хотел. В Java модель памяти немного принципиально такая же,
[54:41.440 --> 54:48.520]  в некоторых местах отличается, но в ней memory-ордеров нет. Там буквально вот можно считать, что там есть
[54:48.520 --> 54:57.080]  вот memory-order sequential consistency. А вот этих всех вариаций нет. В C++ это все есть, потому что C++
[54:57.080 --> 55:05.240]  дает тебе очень большую гибкость, и ты можешь вот очень тонко настраивать перформанс. То есть,
[55:05.240 --> 55:11.400]  ты можешь очень глубоко оптимизировать код. В некоторых языках все проще, потому что тебе не
[55:11.400 --> 55:20.120]  дают таких тонких настроек. С другой стороны, сама семантика получается проще. Я забыл вопрос,
[55:20.120 --> 55:31.200]  если честно. Скажем, я просто не знаю про нее, не буду спекулировать. В языке раз,
[55:31.200 --> 55:35.840]  смотрите, что сделали. Ну, я на лекции потом покажу. Там вообще не определились еще. Там как бы ждут,
[55:35.840 --> 55:48.560]  пока научное сообщество все-таки построит нормальную модель памяти без дыр. Что? Ну,
[55:48.560 --> 56:16.560]  не говорят. Ну, как C++. Да. Сейчас, значит, модель памяти — это не вопрос, это не run time,
[56:17.040 --> 56:27.000]  это вопрос семантики. Не через run time же это определяется. В смысле, ты про то,
[56:27.000 --> 56:38.520]  что в run time реализована абстракция транзакционной памяти. Но ты слишком далеко от реальности в мире
[56:38.520 --> 56:46.240]  хаскере, потому что модель памяти C++ пытается математически описать зоопарк процессоров,
[56:46.240 --> 56:53.400]  что довольно сложно сделать. То есть нельзя очень аккуратно математически описать
[56:53.400 --> 57:00.040]  вот некоторый человеческий произвол инженерный. Не всегда это возможно. Либо ты говоришь просто,
[57:00.040 --> 57:04.640]  что я не думаю про процессоры, я строю свою абстракцию с транзакционной памятью и описываю ее.
[57:04.640 --> 57:33.040]  Зачем стд-атомик в weight проверяет еще раз ее после? У меня есть гипотеза,
[57:33.040 --> 57:41.240]  что, смотри, фьютекс, курс, у него есть некоторая смещенность в сторону, во-первых,
[57:41.240 --> 57:47.240]  x86, во-вторых, линукса. Фьютекс — это сискол для линукса, в других операционных системах его нет.
[57:47.240 --> 57:54.360]  И скажем, для некоторых реализаций, давай я прям покажу в условии, там же есть в условии задачи,
[57:54.360 --> 57:59.200]  есть ссылка на реализацию этого самого weight. Не то, чтобы я предлагал это читать,
[57:59.200 --> 58:11.760]  потому что код стд не для людей написан. В некоторых случаях weight эмулируется через
[58:11.760 --> 58:24.840]  кундвары. У вас в операционной системе нет никакого готового примитива для этого,
[58:24.840 --> 58:29.320]  поэтому вы описываете weight через кундвары. И там получается вот такая семантика более слабая,
[58:29.320 --> 58:34.280]  не то что более слабая, немного другая. И опять, кажется, что просто это общий знаменатель.
[58:34.280 --> 58:43.800]  Я не знаю, мне кажется, что это неважно. Перепроверил это еще раз, не перепроверил,
[58:43.800 --> 58:52.840]  это, кажется, какая-то минорная деталь. Ну, значит, я бы предлагал твой код ударить
[58:52.840 --> 59:00.560]  и переписать как-то иначе его. Мне кажется, что нормальная реализация, она от этой подробности
[59:00.560 --> 59:05.600]  не зависит. Просто это дополнительная проверка, она почти не должна влиять. Ну, не знаю, ладно,
[59:05.600 --> 59:12.440]  нужно код смотреть. То есть, это моя гипотеза, почему так? Потому что сискол фьюдекс — это
[59:12.440 --> 59:17.560]  вот сискол на одной операционной системе, на других могут быть другие способы это weight выразить,
[59:17.560 --> 59:26.840]  и, возможно, что это такая минимальная семантика, которую удается везде написать, везде реализовать.
[59:26.840 --> 59:39.720]  Так, ну, с фьюдексом, наверное, хватит. Тут еще есть забавная подробность про модели памяти,
[59:39.720 --> 59:44.760]  я не знаю, усугубляет ли этот разговор про модели памяти еще больше. Но, короче говоря,
[59:44.760 --> 59:50.520]  если вы почитаете эту документацию, вот этот комментарий, то вот окажется, что в ядре линукса
[59:50.520 --> 59:57.600]  возникает ровно вот такой сценарий, который мы рассматривали на прошлой или позапрошей
[59:57.600 --> 01:00:04.880]  лекции в этом примере. Вот буквально в коде фьюдекса, при конкуренции вейка и вейта,
[01:00:04.880 --> 01:00:13.760]  возникает вот такой вот паттерд. И вот мы видим, что процессор в нем генерирует довольно неожиданный
[01:00:13.760 --> 01:00:21.760]  исход. И если бы так было, то вот ядро во фьюдексе ломалось, там происходило бы зависание, поток
[01:00:21.760 --> 01:00:31.880]  зависает, простите, поток засыпает и не видит на тифая, точнее поток засыпает, а другой поток не
[01:00:31.880 --> 01:00:39.280]  может его разбудить, потому что там две ячейки памяти вот так вот с два потока, два ядра с двумя
[01:00:39.280 --> 01:00:44.120]  ячейками памяти так поработали вместе. Короче, вот этот сценарий выглядит довольно синтетически,
[01:00:44.120 --> 01:00:50.960]  но вот в ядре, в реализации фьюдекса он прямо возникает и может, если ядро об этом не позаботится,
[01:00:50.960 --> 01:01:03.440]  то он приведет к зависанию. Да, это можно почитать, это может быть поможет пониманию модели памяти в
[01:01:03.440 --> 01:01:12.640]  будущем, но в любом случае я это все буду потом пересказывать. Так что сейчас скорее понимания не
[01:01:12.640 --> 01:01:18.280]  требуется, требуется понимание вопроса, а понимание ответа не является необходимым.
[01:01:18.280 --> 01:01:25.160]  Что еще в домашке может быть сейчас непонятно? Что еще я могу пояснить?
[01:01:31.520 --> 01:01:38.040]  Про гарантии Comperexchange мы сказали, про Atomic сказали, про Mutex, в Mutex поговорили,
[01:01:38.040 --> 01:01:45.880]  LifeLog, LifeLog там вроде все понятно должно быть, DeadLog там тоже все понятно должно быть,
[01:01:45.880 --> 01:02:00.200]  про философов непонятно. Вот возможно, что? Философы все просто, а это легко узнать просто
[01:02:00.200 --> 01:02:09.120]  или непросто. Есть очень простой тест. Давай сейчас попробуем, попробуем кое-что сделать.
[01:02:09.120 --> 01:02:18.680]  Вот сразу узнаем, все тебе понятно. Ну тут присутствующие уже некоторые знают.
[01:02:18.680 --> 01:02:27.960]  Вот берем философа и...
[01:02:27.960 --> 01:02:44.240]  Тут ничего не написано вообще. Это шаблон, да? Тут ничего не было. У него есть правая елка и левая елка.
[01:02:44.240 --> 01:02:53.040]  Просто где мой CodeCompletion? Спрашиваю я в ВДЕ и не получаю ответа.
[01:02:53.040 --> 01:03:08.720]  Я пишу DeadLog, да? Мы понимаем это. То есть все философы взяли в руку левую
[01:03:08.720 --> 01:03:25.600]  вилку и все. На этом обед закончился. И дальше я хочу запустить этот код, CodeThreadSanitizer.
[01:03:38.720 --> 01:03:52.640]  Ага. Вот критерии понимания задачи. Вы можете так сделать? Ну понятно, что возник DeadLog.
[01:03:52.640 --> 01:03:57.840]  ThreadSanitizer это, видимо, нашел. Но он написал следующее. Он написал LogOrderInversion,
[01:03:57.840 --> 01:04:03.520]  на скобочках, потенциальный DeadLog. И вот что он имел в виду этим сообщением? Он же не написал,
[01:04:03.520 --> 01:04:15.000]  что у вас DeadLog. Судя по этому сообщению, он не понимает, DeadLog у вас или нет. Вот что все это значит?
[01:04:22.160 --> 01:04:28.080]  Ну давайте разберем. Наверное, осталось 10 минут, да? Кажется, это подходящий момент, чтобы это сделать
[01:04:28.080 --> 01:04:42.520]  в тот день, когда никого нет. Ну, запись будет. Ну, сообщение Релинсуторвальца, оно зачем в условии
[01:04:42.520 --> 01:04:51.560]  задачи дано? Во-первых, оно про анлоки. А мы говорим сейчас про локи, а не про анлоки. А во-вторых,
[01:04:51.560 --> 01:05:04.760]  оно про то, что нужно быть вежливее и добрее. Вот это второй посыл этой ссылки. Вот по поводу того,
[01:05:04.760 --> 01:05:11.600]  что анлоки... Проблема-то не в анлоках здесь. Вот, наоборот, письман говорит, что чтобы мы в
[01:05:11.600 --> 01:05:17.560]  релиз Forks не написали, вот все что угодно сойдет. Не то чтобы это прям хорошая идея что угодно
[01:05:17.560 --> 01:05:26.440]  написать. Но это не влияет на DeadLog. Вот Ред Санитайзер говорит, что он даже не... Давайте по-другому.
[01:05:26.440 --> 01:05:31.200]  Почему у нас философы заблокировались и умерли с голоду? Потому что все взяли левую вилку,
[01:05:31.200 --> 01:05:41.280]  так сложилось исполнение, и они зависли. В условии задачи говорят, что вот... Ну, вы понимаете,
[01:05:41.280 --> 01:05:46.680]  что это DeadLog. Но вот есть какой-то более формальный способ об этом говорить. Он называется
[01:05:46.680 --> 01:05:54.640]  WaitForGraph. Вы строите граф, где есть вершины Mutex и вершины потоки. И вот как в нем появляются
[01:05:54.640 --> 01:06:01.800]  направленные дуги. Если поток T вызывает лог и ждет Mutex, то возникает дуга из T в M. Поток T
[01:06:01.800 --> 01:06:08.440]  ждет Mutex M. Когда лог завершается, то есть поток T захватывает Mutex, то мы проводим дугу... То есть мы
[01:06:08.440 --> 01:06:16.280]  ту стираем, проводим обратную сторону другую. Что Mutex M теперь принадлежит потоку T. Когда
[01:06:16.280 --> 01:06:22.240]  мы вызываем Unlog, то просто стирается дуга между M и T. Вот в терминах этого графа DeadLog это что?
[01:06:22.240 --> 01:06:30.040]  Это цикл. Поток ждет Mutex, который владеет другой поток, который ждет Mutex, и вот возвращаемся в
[01:06:30.040 --> 01:06:41.400]  восходное место. А дальше вас просят в терминах этого графа придумайте... Ну, в общем, задачи.
[01:06:41.400 --> 01:06:49.840]  Про что задача? Про то, чтобы придумать некоторый общий рецепт, как брать вилки так, чтобы DeadLog
[01:06:49.840 --> 01:06:59.800]  не возникало. Но DeadLog... Что я несу? Какие вилки? Как брать в потоках Mutex, чтобы DeadLog не возникало?
[01:06:59.800 --> 01:07:06.320]  Вилки и философы — это просто частный пример, когда у нас есть вот N потоков, N Mutex, и вот они
[01:07:06.320 --> 01:07:11.920]  так распределены. У каждого потока по два Mutex нужно взять. В общем случае у нас приложение
[01:07:11.920 --> 01:07:16.720]  произвольное, там какие-то... Ну, в произвольном приложении, может быть, скорее всего, много потоков,
[01:07:16.720 --> 01:07:24.720]  неизвестное количество, но и, видимо, какое-то фиксированное количество Mutex. Ну, потому что Mutex
[01:07:24.720 --> 01:07:30.400]  спонтанно не заводится все же чаще всего. У Mutex они защищают какие-то данные, но вот этих данных,
[01:07:30.400 --> 01:07:37.160]  вы знаете про эти данные, вы объявили Mutex. И вот как использовать этот WaitForGraph придумать
[01:07:37.160 --> 01:07:43.160]  некоторое общее решение и доказать, что оно корректное? Но вы не можете придумывать, может быть,
[01:07:43.160 --> 01:07:46.640]  общего решения сразу, поэтому вы придумываете частное решение. Как оно выглядит?
[01:07:46.640 --> 01:08:03.320]  Нет, нет, мы говорим про философов сейчас.
[01:08:16.640 --> 01:08:21.640]  Ну вот, ты придумал какое-то частное решение, которое вот помогает философам за круглым столом.
[01:08:21.640 --> 01:08:28.640]  Вот, а хочется, чтобы из этого частного решения родилось какое-то общее решение. Вот некоторое
[01:08:28.640 --> 01:08:38.240]  общее решение, которое ты применил к этой задаче и получил свое частное. Вот. Ну, решение такое, вот
[01:08:38.240 --> 01:08:44.240]  сказать, что у нас есть... Ну, у философов есть номера, да, но не у философа, ну, места за столом
[01:08:44.240 --> 01:08:51.280]  пронумерованы. И, скажем, можно написать какой-то такой код, что нулевой философ берет вилки в одном
[01:08:51.280 --> 01:08:57.040]  порядке, а все остальные в другом порядке. То есть все сначала левую, потом правую, а один сначала
[01:08:57.040 --> 01:09:02.080]  правую, потом левую. И это вот помогает, потому что разрывает вот этот цикл гигантский. Но это
[01:09:02.080 --> 01:09:07.240]  вот какое-то частное решение, а хочется, чтобы оно стало общим, прям вот глобально общим для любой
[01:09:07.240 --> 01:09:19.960]  подобной задачи. Вот. И это общее решение. Как выглядит? То есть у нас, в общем случае, нет
[01:09:19.960 --> 01:09:28.840]  никаких мест, нет никаких вилок, там круглого стола левый и правый, это все. Но вот общая идея
[01:09:28.840 --> 01:09:36.720]  такая. Мы можем взять и Mutex изонумеровать. Просто вот статически заранее это выглядит. Мы знаем,
[01:09:36.720 --> 01:09:40.960]  что у нас в программе там, не знаю, 10 Mutex, мы их пронумеровали произвольным образом. А дальше,
[01:09:40.960 --> 01:09:49.240]  ну, чутику. Буду говорить аккуратнее. Мы их пронумеровали каким-то разумным образом и
[01:09:49.240 --> 01:09:54.600]  придерживаемся следующего правила простого, что мы берем Mutex в каждом потоке только строком
[01:09:54.600 --> 01:10:06.680]  монотонно. Почему? Тут разные вопросы. Почему это помогает, в общем случае, то есть почему это
[01:10:06.680 --> 01:10:13.360]  избавляет от цикловой этфрографии? И как связано наше решение с философом, который вот один берет
[01:10:13.360 --> 01:10:20.000]  вилки наоборот, с этим общим рецептом? Вот второй вопрос. Как мы на него ответим?
[01:10:20.000 --> 01:10:28.000]  Ну вот, как ты нумируешь вилки в итоге? Как ты нумируешь Mutex?
[01:10:28.000 --> 01:10:40.720]  Нет, еще раз. Общий рецепт пронумеровать Mutex, а потом брать сначала меньше, потом больше.
[01:10:40.720 --> 01:10:56.080]  Нумерация Mutex глобальная для всех философов разума, сквозная. Она глобальная для всех, еще раз.
[01:10:56.080 --> 01:11:09.200]  Ладно, наверное, мы понимаем все, но не можем потом сказать друг другу. Я по-другому скажу проще.
[01:11:09.200 --> 01:11:14.800]  Возьмем и пронумеруем вилки за столом по часовой обстрелке, ну или против часовой, неважно. Тогда
[01:11:14.800 --> 01:11:20.000]  почти для всех монотонность сначала левая, потом правая, а для одного, который сидит там, где
[01:11:20.000 --> 01:11:26.880]  нумерация wrap around делает, сказать по-русски, для него получается наоборот, что справа от него меньше
[01:11:26.880 --> 01:11:34.080]  номера, справа с левой больше будет. То есть получается, что когда все делают одинаково, а один
[01:11:34.080 --> 01:11:40.320]  наоборот, то это на самом деле глобальная монотонность для всех, для каждого из них в предположении
[01:11:40.320 --> 01:11:46.920]  о нумерации по или против часовой обстрелке, не знаю, как там лево-право сложится. То есть вот это
[01:11:46.920 --> 01:11:58.480]  частное решение философов, это проекция такого вот общего рецепта. И теперь, кстати, можно объяснить,
[01:11:58.480 --> 01:12:09.120]  почему вот на такое решение трансценитайзер пишет вот такое вот сообщение. Он вам вот тем самым
[01:12:09.120 --> 01:12:22.000]  говорит, что он видит, что, похоже, вы не соблюдаете монотонность налогов. То есть он не понимает,
[01:12:22.000 --> 01:12:27.840]  что у вас дедлог, но он чувствует, в смысле наблюдает, что вы нарушаете общий рецепт. То есть
[01:12:27.840 --> 01:12:33.680]  с одной стороны у вас как бы все одинаково. Сначала левая, потом правая. Но это как бы для вас,
[01:12:33.680 --> 01:12:38.080]  которые думают про круглый стол, про философов, которые за ним сидят. А у трансценитайзера просто
[01:12:38.080 --> 01:12:42.680]  есть пачка мьютокса в программе, и он видит, что какие-то потоки захватывают их в одном порядке,
[01:12:42.680 --> 01:12:48.280]  какие-то в другом порядке. И у него общий порядок не выстраивается никакой, просто там цикл в графе
[01:12:48.280 --> 01:12:53.640]  появляется некоторый. Не цикл wait for графе, а вот он просто собирает такие вот пары,
[01:12:53.640 --> 01:13:03.600]  что вы лочили мьютокс B, когда лотили мьютоксом A. Что? Нет, я не понял просто вопрос.
[01:13:03.600 --> 01:13:20.280]  Что значит выбор мьютокса? Выбор мьютокса кем? Можешь просто переформулировать вопрос по-другому?
[01:13:20.280 --> 01:13:26.760]  Не, я не знаю, то или не то, я не могу понять, что именно ты, Миша.
[01:13:26.760 --> 01:13:43.560]  Кто такие мы? Ну, философ берет левый и правый. Сначала левый, потом правый. В каком порядке они
[01:13:43.560 --> 01:13:49.880]  будут выполнять свои локи, это конечно от планировщика зависит. Просто сложилось такое
[01:13:49.880 --> 01:13:56.720]  исполнение, где Трэд Санитайзер увидел, что вы берете разные локи. Короче, он видит,
[01:13:56.720 --> 01:14:00.960]  что явно вы не соблюдаете какой-то глобальный порядок, какую-то глобальную монотонность,
[01:14:00.960 --> 01:14:07.800]  и поэтому он жалуется, и поэтому он пишет потенциальный дедлог. Он даже не понял,
[01:14:07.800 --> 01:14:14.320]  что дедлог произошел, но вот он видит, что вы рецепт нарушаете. Это и есть почти что
[01:14:14.320 --> 01:14:17.560]  понимание задачи. Последнее, что нужно сделать, нужно просто доказать строго,
[01:14:17.560 --> 01:14:29.200]  что монотонности в логах достаточно. Очень просто делается. Итак, предположение. Мы берем локи
[01:14:29.200 --> 01:14:35.240]  монотонно в каждом потоке, и при этом возникает дедлог. От противного доказываем. Что такое дедлог
[01:14:35.240 --> 01:14:42.000]  WaitForGraphy? У нас есть поток Т1, который ждет нюдекса М1. Нюдекс М1 при этом принадлежит
[01:14:42.000 --> 01:14:51.640]  потоку Т2, который хочет в свою очередь захватить нюдекс М2, который принадлежит нюдекс МК и,
[01:14:51.640 --> 01:15:02.960]  в конце концов, Т1. Мы скажем, что с каждым нюдексом у нас ассоциировано некоторый номер.
[01:15:02.960 --> 01:15:13.400]  Это просто монотонный номерат, но не нумерация их. И мы ведем такую величину L от T. L от T это
[01:15:13.400 --> 01:15:23.760]  максимум L от M по всем М, которыми владеет поток T. Это максимальный номер нюдекс,
[01:15:23.760 --> 01:15:33.280]  которым поток Т уже владеет. Ну а теперь просто выписываем все эти L вот здесь. L от T1 и L от M1.
[01:15:33.280 --> 01:15:48.760]  Каком они отношения состоят? Это простой вопрос. L от T1 это максимальный номер потока, максимальный
[01:15:48.760 --> 01:15:55.520]  номер нюдекс, которым Т1 уже владеет. И мы знаем, что каждый поток захватывает нюдекс строго монотонно.
[01:15:55.520 --> 01:16:06.040]  Две минутки буквально. Строго монотонно. Это значит, что здесь знак меньше. L от M1 и L от T2.
[01:16:06.040 --> 01:16:14.440]  Ну вот M1 уже принадлежит потоку T2. Значит, эта L входит вот сюда. Значит, меньше либо равным. Ну и вот
[01:16:14.440 --> 01:16:24.160]  так в конце концов получается, что L от T1 меньше, чем L от T1. Ну вот чуть корректнее. Вот так. Нет,
[01:16:24.160 --> 01:16:35.040]  да, вот так. Ну и вот получается противоречие, а значит циклов возникать не может. Все. Ну вот это
[01:16:35.040 --> 01:16:40.680]  уже полное такое основательное решение философии. На сегодня тогда все.
