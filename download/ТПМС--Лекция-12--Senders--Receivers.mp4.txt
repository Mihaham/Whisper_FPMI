[00:00.000 --> 00:07.000]  И сегодня у нас очень важный этап, потому что мы поговорим про то, как конкарнсия,
[00:07.000 --> 00:13.000]  ну вот, про то, как самые в современном мире инженеры,
[00:13.000 --> 00:16.000]  ну, которые, по крайней мере, занимаются разработкой на C++,
[00:16.000 --> 00:21.000]  видят себе идеальное выражение конкурентных активностей,
[00:21.000 --> 00:26.000]  как наиболее естественным образом, наиболее абстрактно представить их в коде.
[00:26.000 --> 00:31.000]  Ну вот, мы к этому подойдем, а начну я довольно издалека.
[00:31.000 --> 00:36.000]  В прошлый раз мы с вами говорили про стеклус карутины.
[00:36.000 --> 00:43.000]  Про стеклус карутины – это другая реализация карутины, другая реализация конкурента.
[00:44.000 --> 00:52.000]  Про стеклус карутины – это другая реализация карутины, другая реализация функций,
[00:52.000 --> 00:55.000]  которые могут останавливаться во время своего вызова,
[00:55.000 --> 00:59.000]  которые, останавливаясь, сохраняют только текущий стекловый фрейм
[00:59.000 --> 01:03.000]  и никак не влияют на вызовы выше по стеку.
[01:03.000 --> 01:07.000]  И мы в прошлый раз говорили как с помощью таких карутины,
[01:07.000 --> 01:10.000]  с помощью некоторых точек кастомизации, которые назывались овейтеры.
[01:10.000 --> 01:14.000]  Давайте я вам напомню это.
[01:14.000 --> 01:17.000]  Получить асинхронность.
[01:17.000 --> 01:20.000]  Как программировать задачи, которые могут останавливаться
[01:20.000 --> 01:22.000]  и дожидаться каких-то событий.
[01:22.000 --> 01:27.000]  Готовность фьюча, завершение водовывода, разблокировки мьютекса, чего-то подобного.
[01:27.000 --> 01:32.000]  И сегодня у вас в репоститории открылась задача,
[01:32.000 --> 01:38.000]  в которой вы можете с помощью стеклус карутины написать конкуренты.
[01:38.000 --> 01:41.000]  Никакие новые примитивы мы там делать не будем.
[01:41.000 --> 01:46.000]  Мы скорее должны посмотреть на, изучить в этой задаче дизайн карутин,
[01:46.000 --> 01:48.000]  который представлен в C++.
[01:48.000 --> 01:51.000]  И решая эту задачу, вы должны...
[01:51.000 --> 01:54.000]  Тут есть зависимость у нее Fibers Mutex.
[01:54.000 --> 01:57.000]  Видимо, предполагается, что вы должны сначала ее решить.
[01:57.000 --> 02:01.000]  Но я бы сказал, что вы можете решать эти задачи параллельно.
[02:01.000 --> 02:04.000]  Они друг друга дополняют, потому что, с одной стороны,
[02:04.000 --> 02:06.000]  мы в Fibers Mutex придумываем дизайн,
[02:06.000 --> 02:08.000]  потом встречаем его в стеклус-карутинах,
[02:08.000 --> 02:12.000]  и он нам кажется уже знакомым, и мы понимаем, почему он такой.
[02:12.000 --> 02:15.000]  А с другой стороны, если вы идете другим путем,
[02:15.000 --> 02:21.000]  то, может быть, вы не понимали, как можно изящно решить Fibers Mutex,
[02:21.000 --> 02:25.000]  как там построить правильно все эти абстракции границы,
[02:25.000 --> 02:28.000]  и, посмотрев на то, как это сделано в стеклус-карутинах,
[02:28.000 --> 02:32.000]  вы сможете портировать эту идею обратно в Fibers.
[02:32.000 --> 02:36.000]  Ну и в итоге у вас в обоих случаях получится какой-то похожий код,
[02:36.000 --> 02:41.000]  потому что, в конце концов, различие только в том,
[02:41.000 --> 02:43.000]  как устроена карутина.
[02:43.000 --> 02:45.000]  Она устроена в стеклус или она устроена в стеклус,
[02:45.000 --> 02:48.000]  то есть через переключение контекста.
[02:48.000 --> 02:51.000]  Но смотрите, почему эта задача еще важна.
[02:51.000 --> 02:54.000]  Но даже не только эта задача, а еще парная задача,
[02:54.000 --> 02:57.000]  которая появится вот-вот и вместе с фьючами.
[02:57.000 --> 03:01.000]  Потому что стеклус-карутины, как здесь они описаны,
[03:01.000 --> 03:06.000]  это не только способ, не только альтернатива Fiber'ам.
[03:06.000 --> 03:10.000]  Это, скорее, более общий альтернатив, ну, смотрю, более общий инструмент.
[03:10.000 --> 03:13.000]  И в этой задаче они называются, этот инструмент назван просто задачами.
[03:13.000 --> 03:18.000]  То есть в этом задании мы пишем такую подбиблиотеку,
[03:18.000 --> 03:20.000]  которая называется Tasks.
[03:20.000 --> 03:25.000]  То есть некоторые обобщенные, универсальные кооперативные задачи,
[03:25.000 --> 03:29.000]  которые, во-первых, могут вести себя, в общем, как Fiber'а,
[03:29.000 --> 03:33.000]  то есть они запускаются и императивно через какие-то примитивы синхронизации
[03:33.000 --> 03:35.000]  начинают, собственно, синхронизироваться.
[03:35.000 --> 03:38.000]  Ну, там захватывают общие Mutex'ы,
[03:38.000 --> 03:42.000]  и там синхронизируются с помощью WhiteGroup.
[03:42.000 --> 03:45.000]  Это код, который похож на код, который мы писали для Fiber'ов,
[03:45.000 --> 03:49.000]  только здесь у нас постоянно кое вейт, потому что нужно указать компиратору,
[03:49.000 --> 03:54.000]  в каких точках нужно карутину остановить и подписаться на какое-то событие,
[03:54.000 --> 03:57.000]  указать, когда ее возобновить нужно.
[03:57.000 --> 04:00.000]  На другой стороны, мы в прошлый раз говорили,
[04:00.000 --> 04:04.000]  что карутины выгодно запускать лениво.
[04:04.000 --> 04:07.000]  То есть когда мы запускаем карутину, давайте я покажу вам пример,
[04:07.000 --> 04:09.000]  который был в прошлый раз,
[04:09.000 --> 04:12.000]  тут немного уточнились именами спейсов, стало только лучше.
[04:12.000 --> 04:15.000]  Вот, когда мы запускаем карутину,
[04:18.000 --> 04:20.000]  то есть делаем такой вызов,
[04:20.000 --> 04:22.000]  то на самом деле никакого запуска не происходит,
[04:22.000 --> 04:25.000]  потому что карутина возвращает объект Task,
[04:25.000 --> 04:30.000]  и это такое представление созданной, но еще не запущенной асинхронной работы.
[04:30.000 --> 04:35.000]  И вот эту работу можно запустить, ну, разными способами можно запустить.
[04:35.000 --> 04:37.000]  Можно, например, самому стать карутиной,
[04:37.000 --> 04:41.000]  и вот с помощью кое вейт запустить под задачу,
[04:41.000 --> 04:44.000]  а самому остановиться до того, как задача будет завершена.
[04:44.000 --> 04:49.000]  Вот, то есть у карутин, у вот этих асинхронных задач обобщенных,
[04:49.000 --> 04:52.000]  которые мы называем задачами просто сейчас,
[04:52.000 --> 04:56.000]  есть представление в виде объекта Task.
[04:56.000 --> 05:05.000]  И с одной стороны, вот эти карутины асинхронные можно использовать
[05:05.000 --> 05:08.000]  и смотреть на них как-то на альтернативу файбером оперативным,
[05:08.000 --> 05:11.000]  а с другой стороны, можно эти объекты Task,
[05:11.000 --> 05:15.000]  которые представляют собой остановленные еще не запущенные карутины,
[05:15.000 --> 05:20.000]  остановленные задачи комбинировать и трансформировать в функциональном стиле.
[05:20.000 --> 05:24.000]  И про это будет другая задача, и это все отсылает к фьючам.
[05:24.000 --> 05:32.000]  И вот наш код в этой задаче будет помещен в namespace-tasks
[05:32.000 --> 05:37.000]  именно потому, что карутины здесь – это такой инструмент для унификации.
[05:37.000 --> 05:41.000]  Они связывают, в общем, и то, что мы делали в файберах,
[05:41.000 --> 05:46.000]  и параллельную композицию во фьючах, и последовательную композицию в файберах
[05:46.000 --> 05:49.000]  через некоторые общие инструменты.
[05:49.000 --> 05:51.000]  Вот именно поэтому просто задача.
[05:51.000 --> 05:54.000]  Это, на самом деле, не те задачи, которые, конечно, в экзекьюторах.
[05:54.000 --> 05:58.000]  Но это такие универсальные задачи для исполнения в экзекьюторах.
[05:58.000 --> 06:02.000]  Но это бы сложно прочувствовать, просто так услышав меня,
[06:02.000 --> 06:06.000]  нужно только самому написать код и вот это увидеть своими глазами,
[06:06.000 --> 06:09.000]  своими руками это вбить, тогда это станет понятно.
[06:09.000 --> 06:13.000]  Но карутины, они претендуют на некоторую универсальность.
[06:13.000 --> 06:17.000]  Вы можете через Task с ними работать в функциональном стиле,
[06:17.000 --> 06:21.000]  собирая из них какие-то графы, либо же вы можете работать с ними в императивном стиле
[06:21.000 --> 06:24.000]  с помощью примитива синхронизации.
[06:24.000 --> 06:29.000]  Поэтому задача шутливой называется горрутины, потому что
[06:29.000 --> 06:34.000]  такие вот императивные карутины с примитивом и синхронизацией.
[06:34.000 --> 06:37.000]  Чем-то похоже на грутины из ГО.
[06:37.000 --> 06:42.000]  Вот, эти карутины претендуют в итоге на универсальность.
[06:42.000 --> 06:48.000]  Но на самом деле можно, если закопаться глубже в их реализацию,
[06:48.000 --> 06:57.000]  то можно увидеть, что карутины это может быть не самый фундаментальный механизм,
[06:57.000 --> 07:01.000]  не самая фундаментальная сущность, которая нам в курсе нужна
[07:01.000 --> 07:04.000]  и через которую вообще можно говорить о вычислениях.
[07:04.000 --> 07:11.000]  Мы сегодня хотим на лекции поговорить про то, как описывать произвольные вычисления.
[07:11.000 --> 07:15.000]  В данной задаче, в данном дизайне предлагается строить эти вычисления,
[07:15.000 --> 07:18.000]  описывать эти вычисления с помощью карутины.
[07:18.000 --> 07:22.000]  Вот сегодня мы пытаемся подняться на еще один уровень абстракции
[07:22.000 --> 07:27.000]  и вот еще какие-то механизмы под карутиными обнаружить.
[07:27.000 --> 07:32.000]  Давайте я как-то попробую объяснить, откуда все это берется,
[07:32.000 --> 07:35.000]  откуда вообще появляются такие мысли.
[07:35.000 --> 07:39.000]  Ну вот, вспомним про пример из прошлой лекции.
[07:39.000 --> 07:42.000]  Вот у нас какая-то асинхронная работа.
[07:42.000 --> 07:49.000]  У нас есть функция, в ней мы запускаем в пуле потоков какое-то вычисление,
[07:49.000 --> 07:52.000]  получаем future, потом дожидаемся, потом...
[07:52.000 --> 07:55.000]  Ну, конечно, код довольно бесполезный, потому что он дважды одно и то же делает,
[07:55.000 --> 07:59.000]  он мог бы сам это карутина сама могла бы переехать в пул потоков
[07:59.000 --> 08:01.000]  и вычислить там какое-то значение.
[08:01.000 --> 08:05.000]  Ну, не суться сейчас, а может быть, я даже пример получше найду, давайте я.
[08:05.000 --> 08:10.000]  Раз уж у нас должен быть, я его сразу и покажу.
[08:10.000 --> 08:15.000]  Ну вот, у нас есть какая-то карутина, которая телепортируется в пул потоков
[08:15.000 --> 08:17.000]  и там что-то вычисляет.
[08:17.000 --> 08:19.000]  Ну вот, асинхронное вычисление.
[08:19.000 --> 08:24.000]  И это вычисление возвращает объект future.
[08:24.000 --> 08:28.000]  А мы говорим, что можно же оптимальнее сделать, можно же возвращать не future,
[08:28.000 --> 08:32.000]  можно же возвращать из асинхронного вычисления task.
[08:32.000 --> 08:33.000]  Почему?
[08:33.000 --> 08:36.000]  Потому что task, вот этот объект, который карутина возвращает,
[08:36.000 --> 08:38.000]  он управляет запуском этой карутины.
[08:38.000 --> 08:44.000]  И вот если мы, имея future, запуская, скажем, вычисления в пуле потоков
[08:44.000 --> 08:48.000]  через асинхрея здесь, через future, сразу получаем и future,
[08:48.000 --> 08:50.000]  и одновременно стартуем асинхронную операцию,
[08:50.000 --> 08:54.000]  то в случае карутин с task-ами, когда мы стартуем карутину,
[08:54.000 --> 08:57.000]  мы получаем объект task, который тоже представляет собой, в общем,
[08:57.000 --> 09:00.000]  будущее какой-то результат, будущее вычисление.
[09:00.000 --> 09:03.000]  Но это вычисление, оно еще не стартовало.
[09:03.000 --> 09:06.000]  И мы можем сначала подписаться на него, потом стартовать
[09:06.000 --> 09:10.000]  и обойтись без синхронизации, обойтись без локации shared state,
[09:10.000 --> 09:11.000]  без подсчета ссылок.
[09:11.000 --> 09:14.000]  То есть мы можем скрыть, избавиться от накладных расходов,
[09:14.000 --> 09:16.000]  которые нам, в принципе, не нужны.
[09:16.000 --> 09:20.000]  Если мы так структурировали код, что одна задача дожидается синхронно,
[09:20.000 --> 09:23.000]  другую, пусть даже асинхронную задачу, то, в принципе,
[09:23.000 --> 09:27.000]  overhead на future нам не требуется здесь.
[09:27.000 --> 09:29.000]  Что мы сделали по сравнению с асинхрея?
[09:29.000 --> 09:34.000]  Вот здесь мы одновременно планируем задачу в пул потоков
[09:34.000 --> 09:37.000]  и встроим future и возвращаем ее.
[09:37.000 --> 09:41.000]  И в итоге у вас уже есть задача, которая запланировалась в пул,
[09:41.000 --> 09:46.000]  у нее есть promise, у пользователей есть future, ну и все.
[09:46.000 --> 09:49.000]  Теперь есть гонка уже врожденная между ними.
[09:49.000 --> 09:53.000]  Непонятно, как соотносятся lifetime продюсера и консьюмера.
[09:53.000 --> 09:56.000]  Между продюсером и консьюмером нужна синхронизация.
[09:56.000 --> 09:59.000]  Им нужно поддерживать shared state, держать на него сильные ссылки,
[09:59.000 --> 10:04.000]  подчитывать, держать счетчик ссылок и атомарно инкрементировать,
[10:04.000 --> 10:05.000]  декрементировать его.
[10:05.000 --> 10:08.000]  Вот мы уже получили некоторые накладные расходы.
[10:08.000 --> 10:10.000]  Потому что мы сделали два шага разом.
[10:10.000 --> 10:16.000]  Мы и задачу запланировали, и future построили и вернули пользователю.
[10:16.000 --> 10:20.000]  Вот что мы сделали в крутинах, что мы делаем в крутинах?
[10:20.000 --> 10:22.000]  Мы разделяем два этих шага.
[10:22.000 --> 10:28.000]  Когда мы получаем таск, то мы еще не стартовали под задачу.
[10:28.000 --> 10:31.000]  Крутина уже построилась, а под задачу не стартовала.
[10:31.000 --> 10:34.000]  И когда мы разворачиваем этот таск с помощью co-await,
[10:34.000 --> 10:39.000]  мы вот запускаем под задачу, но перед этим мы подписываемся на ее завершение.
[10:39.000 --> 10:41.000]  Вот два шага разделены.
[10:41.000 --> 10:47.000]  Простые два шага, но они разделены все же на две разных операции.
[10:47.000 --> 10:51.000]  Старт к крутину, вызов к крутины и старт к крутины.
[10:51.000 --> 10:52.000]  Это теперь разные шаги.
[10:52.000 --> 10:57.000]  И за счет этого мы сэкономим себе лишние аллокации, почет ссылок.
[10:57.000 --> 11:00.000]  Кроме того, мы наблюдали другой пример.
[11:00.000 --> 11:06.000]  Мы говорили о том, как можно написать эффективный тредпул для крутин.
[11:06.000 --> 11:14.000]  Потому что пример, который был у нас на прошлом занятии,
[11:14.000 --> 11:16.000]  ну вот такой avator.
[11:16.000 --> 11:19.000]  Мы останавливались и планировали в тредпул лямбду,
[11:19.000 --> 11:21.000]  которая резюмила к крутинам.
[11:21.000 --> 11:27.000]  Это был неэффективный способ, потому что, ну вот, это лямбда, это некоторая...
[11:27.000 --> 11:31.000]  Чтобы положить лямбду в структуру планировщика, нужно стереть ее тип,
[11:31.000 --> 11:33.000]  нужно переместить ее на кучу, сделать динамическую локацию,
[11:33.000 --> 11:36.000]  короче, какой-то стд-фанкшн использовать или аналогичный контейнер.
[11:36.000 --> 11:43.000]  Вот мы тратим опять локации на такую задачу, хотя к крутинам это все не требуется.
[11:43.000 --> 11:46.000]  Почему? Потому что можно сделать гораздо изящнее.
[11:46.000 --> 11:50.000]  Можно вспомнить, что когда мы выполняем вот такой код,
[11:50.000 --> 11:52.000]  то компиатор разворачивает его во что?
[11:52.000 --> 12:01.000]  Он строит по этому выражению объект avator, собственно, вот этот вот,
[12:01.000 --> 12:03.000]  и на нем вызывает avate suspend.
[12:03.000 --> 12:07.000]  Но этот avator, как и любая локальная переменная в крутине,
[12:07.000 --> 12:09.000]  компиатором переписывается в поля.
[12:09.000 --> 12:14.000]  Ну вот мы знаем, что так работают крутины.
[12:14.000 --> 12:16.000]  Локальная переменная становится полями.
[12:16.000 --> 12:18.000]  Ну вот avator тоже становится полем.
[12:18.000 --> 12:20.000]  Avator для тратпула.
[12:20.000 --> 12:25.000]  И если мы скажем, что avator для тратпула будет узлом интрузивного списка
[12:25.000 --> 12:28.000]  и положим в него pointer на какой-то следующий узел,
[12:28.000 --> 12:32.000]  то мы можем через avatars, которые заинлайнятся в поля крутин,
[12:32.000 --> 12:38.000]  связать эти крутины в список, ну и список в тратпуле получится интрузивным.
[12:38.000 --> 12:44.000]  И мы можем добавлять крутины в планировщик, не выполняя аллокации.
[12:44.000 --> 12:47.000]  Ну просто потому что каждая крутина – это уже сама по себе аллокация.
[12:47.000 --> 12:52.000]  Ну и если сделать это совсем аккуратно, то пусть avator будет реализовывать интерфейс,
[12:52.000 --> 12:55.000]  ну будет наследником нашей таски интрузивной,
[12:55.000 --> 13:02.000]  и тогда крутины органично впишутся в наш фреймворк общих планировщиков, экзекутеров.
[13:02.000 --> 13:07.000]  То есть смотрите, мы снова можем получить некоторый выигрыш
[13:07.000 --> 13:10.000]  за счет того, что мы снова разделяем две задачи.
[13:10.000 --> 13:12.000]  Вот нужно понять, где выигрыш берется.
[13:12.000 --> 13:16.000]  Мы разделяем планирование задачи в пул потоков,
[13:16.000 --> 13:21.000]  и мы разделяем аллокацию стейта для нее.
[13:21.000 --> 13:25.000]  Ну то есть стейт – это вот некоторая хранилища,
[13:25.000 --> 13:28.000]  где написано, там, аргументы, запускаемые задачи,
[13:28.000 --> 13:31.000]  там, функции, которые мы хотим запустить.
[13:32.000 --> 13:37.000]  Вот в наивном тредпуле у нас есть просто submit от function.
[13:37.000 --> 13:42.000]  И тут и задача упаковывается, конкретная лямбда,
[13:42.000 --> 13:46.000]  или что угодно упаковывается в std function, это уже аллокация.
[13:46.000 --> 13:47.000]  И потом она планируется.
[13:47.000 --> 13:50.000]  Вот снова мы вот с помощью интрузивности, с помощью крутин,
[13:50.000 --> 13:52.000]  можем разделить два этих шага.
[13:52.000 --> 13:57.000]  Мы можем разделить аллокацию стейта для задачи,
[13:57.000 --> 14:00.000]  и мы можем разделить планирование задачи в тредпул.
[14:00.000 --> 14:04.000]  Ну это тонкие материи, но с другой стороны, этап курса
[14:04.000 --> 14:08.000]  уже достаточно поздний, поэтому мы занимаемся сложными вещами.
[14:08.000 --> 14:11.000]  Ну вот, две такие оптимизации, и у них одна и та же природа.
[14:11.000 --> 14:14.000]  Мы берем сложную задачу и ищем в ней подзадачи
[14:14.000 --> 14:16.000]  и разделяем их на явные шаги.
[14:16.000 --> 14:24.000]  И те применения, те контексты применения, там, тредпула
[14:24.000 --> 14:29.000]  или асинхронности, которые могут сэкономить за счет знания
[14:29.000 --> 14:31.000]  об отдельных шагах, они могут этим пользоваться.
[14:31.000 --> 14:33.000]  А те, кто не может, ну вот работают как и раньше.
[14:33.000 --> 14:35.000]  То есть мы получаем возможность для оптимизации,
[14:35.000 --> 14:39.000]  потому что мы дробим составные операции на более примитивные,
[14:39.000 --> 14:40.000]  более таки атомарные.
[14:40.000 --> 14:45.000]  И в обоих случаях мы пользовались тем, что у нас задача – это крутины.
[14:45.000 --> 14:48.000]  Так вот, я сегодня хочу обратить ваше внимание,
[14:48.000 --> 14:53.000]  что крутины здесь в таких соображениях совершенно не обязательно.
[14:53.000 --> 14:58.000]  Что на самом деле можно те же самые оптимизации придумать
[14:58.000 --> 15:05.000]  и реализовать, забыв про крутины, а потом крутины в них интегрировать.
[15:05.000 --> 15:09.000]  Ну, короче, мы сейчас ведем еще один слой абстракции,
[15:09.000 --> 15:11.000]  еще одни промежуточные сущности,
[15:11.000 --> 15:14.000]  и, с одной стороны, дизайн еще больше усложнится.
[15:14.000 --> 15:16.000]  То есть у нас бы словарь расширится.
[15:16.000 --> 15:18.000]  У нас так уже много всяких непонятных слов,
[15:18.000 --> 15:25.000]  типа «крутины», «авейторы», «экзекьюторы».
[15:25.000 --> 15:27.000]  «Экзекьюторы» – огромное количество слов,
[15:27.000 --> 15:29.000]  уже это похоже на какой-то странный птичий язык.
[15:29.000 --> 15:31.000]  Вот сегодня станет еще сложнее,
[15:31.000 --> 15:34.000]  но, с другой стороны, станет еще аккуратнее.
[15:34.000 --> 15:37.000]  Мы сегодня с вами разберем, по сути,
[15:37.000 --> 15:40.000]  ну, по существу, не в подробностях,
[15:40.000 --> 15:47.000]  но основные концепции дизайна пропозала STD Execution.
[15:47.000 --> 15:50.000]  Это вот представление о светлом будущем C++
[15:50.000 --> 15:52.000]  о том, как в нем, в этом светлом будущем,
[15:52.000 --> 15:55.000]  нужно описывать произвольные вычисления.
[15:55.000 --> 15:57.000]  Вот утверждается, что это некорутины,
[15:57.000 --> 15:59.000]  то есть способ, которым нужно описывать
[15:59.000 --> 16:01.000]  произвольные вычисления, это некорутина.
[16:01.000 --> 16:06.000]  Это, к сожалению, не 23 уже,
[16:06.000 --> 16:08.000]  это история более поздняя,
[16:08.000 --> 16:11.000]  но, с другой стороны, это все можно
[16:11.000 --> 16:13.000]  своими глазами пронаблюдать
[16:13.000 --> 16:16.000]  в виде отдельной библиотеки.
[16:16.000 --> 16:19.000]  Ну, то есть не требуется ждать будущего.
[16:19.000 --> 16:21.000]  Это не языковая фича,
[16:21.000 --> 16:24.000]  именно что библиотека, в отличие от корутины.
[16:24.000 --> 16:28.000]  И мы сегодня разберем, на каких принципах,
[16:28.000 --> 16:30.000]  на каких сущностях она построена.
[16:30.000 --> 16:35.000]  Я так скажу, что на бумаге,
[16:35.000 --> 16:37.000]  вот на уровне идей, концепции,
[16:37.000 --> 16:39.000]  все выглядит чрезвычайно строено,
[16:39.000 --> 16:41.000]  чрезвычайно изящно,
[16:41.000 --> 16:44.000]  и, ну, по крайней мере, такого дизайна,
[16:44.000 --> 16:46.000]  кажется, нет в других языках.
[16:46.000 --> 16:50.000]  Он еще не сошелся, но выглядит все чертовски разумно,
[16:50.000 --> 16:52.000]  и я хочу, чтобы мы сегодня, ну, попытались
[16:52.000 --> 16:55.000]  все это сами прочувствовать.
[16:58.000 --> 17:00.000]  Давайте начнем.
[17:00.000 --> 17:03.000]  Говорить про этот самый CD-XQ.
[17:08.000 --> 17:13.000]  Итак, дизайн строится, ну, поначалу
[17:13.000 --> 17:15.000]  на двух сущностях.
[17:15.000 --> 17:18.000]  На сущности сендера и сущности ресивера.
[17:19.000 --> 17:22.000]  Мы сегодня снова будем писать все своими руками,
[17:22.000 --> 17:26.000]  потому что иначе мы ничего не разберем.
[17:26.000 --> 17:29.000]  Так что, пожалуйста, следите за тем, что я пишу,
[17:29.000 --> 17:32.000]  у меня будут ошибки компиляции, помогайте мне их чинить.
[17:32.000 --> 17:34.000]  Будет неизбежно.
[17:34.000 --> 17:37.000]  Две сущности – сендера и ресивера.
[17:37.000 --> 17:40.000]  Тут они вот так очень, очень наспех описаны
[17:40.000 --> 17:42.000]  такими простыми концептами.
[17:44.000 --> 17:46.000]  Давайте начнем с сущности ресивера.
[17:46.000 --> 17:48.000]  Ресивер – это очень простая идея.
[17:48.000 --> 17:51.000]  Это некоторое обобщение колбека.
[17:51.000 --> 17:54.000]  А сендер – это некоторое представление
[17:54.000 --> 17:56.000]  операции, которая что-то вычисляет.
[17:56.000 --> 18:00.000]  Вот есть вычисление, и есть некоторые…
[18:00.000 --> 18:04.000]  есть асинхронное или синхронное, не знаю, какое-то вычисление,
[18:04.000 --> 18:08.000]  и есть колбек, который хочет получить результат этого вычисления.
[18:08.000 --> 18:10.000]  Сендеры и ресивера.
[18:10.000 --> 18:13.000]  Как мы представляем колбек, который ожидает
[18:13.000 --> 18:15.000]  некоторого результата вычислений?
[18:15.000 --> 18:19.000]  Это некоторый объект, который поддерживает вот такой вот протокол.
[18:19.000 --> 18:21.000]  Три метода.
[18:21.000 --> 18:23.000]  Во-первых, на нем можно сказать setValue.
[18:23.000 --> 18:28.000]  Вот вычисление состоялось, вычислило значение value,
[18:28.000 --> 18:30.000]  и вот ресивер получает это значение,
[18:30.000 --> 18:32.000]  и как-то на него реагирует, как-то его обрабатывает.
[18:32.000 --> 18:34.000]  Он его ждал.
[18:34.000 --> 18:36.000]  Но, может быть, вычисление завершилось ошибкой.
[18:36.000 --> 18:40.000]  Тогда мы отправляем ресиверу exception pointer,
[18:40.000 --> 18:44.000]  ну и вот ресивер своим способом,
[18:44.000 --> 18:47.000]  одному ему известному, обрабатывает эту ошибку.
[18:47.000 --> 18:51.000]  Ну или setDone – это отдельный механизм,
[18:51.000 --> 18:53.000]  про который мы совсем еще не говорили в курсе,
[18:53.000 --> 18:55.000]  и, видимо, поговорим через неделю.
[18:55.000 --> 18:58.000]  Это механизм для отмены операции.
[18:58.000 --> 19:00.000]  Ну, потому что, может быть, вычисление,
[19:00.000 --> 19:04.000]  которого ожидал ресивер, просто отменилось,
[19:04.000 --> 19:06.000]  потому что оно уже никому не нужно.
[19:07.000 --> 19:13.000]  Нет, вот может показаться, что да, но мне кажется, что нет,
[19:13.000 --> 19:15.000]  потому что если бы там было похоже,
[19:15.000 --> 19:17.000]  я бы назвал метод cancel, а я назвал его discard,
[19:17.000 --> 19:19.000]  потому что discard – это про то,
[19:19.000 --> 19:20.000]  когда задачу просто выбросили,
[19:20.000 --> 19:22.000]  а cancel, скажем, для файберов,
[19:22.000 --> 19:24.000]  он должен реализовываться совершенно иначе,
[19:24.000 --> 19:26.000]  на другом уровне, не на уровне экзекютеров.
[19:26.000 --> 19:28.000]  Ну, вот тонкие какие-то материи,
[19:28.000 --> 19:30.000]  я сейчас не готов подробно их обсуждать,
[19:30.000 --> 19:32.000]  но мне кажется, что это разные вещи все же.
[19:32.000 --> 19:35.000]  То есть можно увидеть связь, но мне кажется,
[19:35.000 --> 19:37.000]  что она не совсем точна здесь.
[19:37.000 --> 19:39.000]  Так или иначе, вот callback,
[19:39.000 --> 19:41.000]  который ожидает результаты вычисления,
[19:41.000 --> 19:43.000]  может получить либо значение, либо ошибку,
[19:43.000 --> 19:45.000]  либо сигнал о том, что вычисление просто отменилось.
[19:49.000 --> 19:51.000]  Что?
[20:05.000 --> 20:13.000]  Это описание того, что мы ожидаем от типа T.
[20:19.000 --> 20:21.000]  Для лекции совершенно неважно
[20:21.000 --> 20:23.000]  наличие в этом коде концептов,
[20:23.000 --> 20:25.000]  это просто способ в одном месте,
[20:25.000 --> 20:27.000]  но я буду в одном месте буквально этим пользоваться,
[20:27.000 --> 20:29.000]  чтобы оператор QA weight перегрузить для нужных типов.
[20:29.000 --> 20:31.000]  В общем, мы ожидаем, что есть
[20:31.000 --> 20:33.000]  некоторый тип ресивера,
[20:33.000 --> 20:35.000]  он поддерживает такой протокол,
[20:35.000 --> 20:37.000]  вот что сейчас важно.
[20:39.000 --> 20:41.000]  И откуда этот ресивер получает
[20:41.000 --> 20:43.000]  вот эти вот все либо значения,
[20:43.000 --> 20:45.000]  либо ошибки,
[20:45.000 --> 20:47.000]  либо сигнал про отмену,
[20:47.000 --> 20:49.000]  он получает его от сендера.
[20:49.000 --> 20:51.000]  Вот сендер – это чуть менее интуитивная
[20:51.000 --> 20:53.000]  сущность, хотя не знаю,
[20:53.000 --> 20:55.000]  может быть и вполне интуитивная.
[20:55.000 --> 20:57.000]  Сендер – это некоторое вычисление
[20:57.000 --> 20:59.000]  это вот объект, который представляет собой вычисление.
[20:59.000 --> 21:01.000]  У этого вычисления
[21:01.000 --> 21:03.000]  должен быть value type,
[21:03.000 --> 21:05.000]  ну то есть вычисление заканчивается
[21:05.000 --> 21:07.000]  вычислением значения некоторого типа,
[21:07.000 --> 21:09.000]  ну либо ошибкой, либо отменой.
[21:09.000 --> 21:11.000]  И мы хотим
[21:11.000 --> 21:13.000]  операцию,
[21:13.000 --> 21:15.000]  которая собственно стартует
[21:15.000 --> 21:17.000]  вычисление. Вот мы хотим разделить
[21:17.000 --> 21:19.000]  описание вычисления и
[21:19.000 --> 21:21.000]  старт вычисления.
[21:21.000 --> 21:23.000]  И старт вычисления мы
[21:23.000 --> 21:25.000]  представим вот таким образом.
[21:25.000 --> 21:27.000]  У нас есть некоторый сендер,
[21:27.000 --> 21:29.000]  у нас есть некоторый ресивер,
[21:33.000 --> 21:35.000]  и мы скажем, что
[21:35.000 --> 21:37.000]  сендер, сабмит, ресивер.
[21:37.000 --> 21:39.000]  Но это такой очень странный написанный
[21:39.000 --> 21:41.000]  шаблонный код, тут, конечно, такой описать нельзя,
[21:41.000 --> 21:43.000]  но я намеренно все упрощаю, если вам кажется,
[21:43.000 --> 21:45.000]  что я сильно упрощаю, то да, я упрощаю.
[21:47.000 --> 21:49.000]  Вот мы хотим через
[21:49.000 --> 21:51.000]  сендеры, ресиверы
[21:51.000 --> 21:53.000]  и операцию сабмит,
[21:53.000 --> 21:55.000]  выразить вот буквально все на свете.
[21:57.000 --> 21:59.000]  Задача пока выглядит довольно амбициозно,
[21:59.000 --> 22:01.000]  но вот давайте посмотрим на какие-то
[22:01.000 --> 22:03.000]  примеры. Давайте напишем
[22:03.000 --> 22:05.000]  какие-то сендеры, какие-то ресиверы
[22:05.000 --> 22:07.000]  и увидим, как это работает.
[22:07.000 --> 22:09.000]  Начнем с ресиверов.
[22:09.000 --> 22:11.000]  Вот мы ресиверы, то есть
[22:11.000 --> 22:13.000]  прям классы с тремя методами
[22:13.000 --> 22:15.000]  писать не будем, это будет утомительно,
[22:15.000 --> 22:17.000]  поэтому мы напишем, ну точнее,
[22:17.000 --> 22:19.000]  мы уже написали вот такую
[22:19.000 --> 22:21.000]  вспомогательную функцию,
[22:21.000 --> 22:23.000]  с ресивер, которая
[22:23.000 --> 22:25.000]  по лямбде, зачем я так написал
[22:25.000 --> 22:27.000]  вообще,
[22:29.000 --> 22:31.000]  которая по лямбде, которая ожидает значения
[22:31.000 --> 22:33.000]  типа t, строит объект с тремя методами.
[22:35.000 --> 22:37.000]  Вот у меня есть какой-то функтор,
[22:37.000 --> 22:39.000]  какая-то лямбда,
[22:39.000 --> 22:41.000]  и я для нее конструирую такой
[22:41.000 --> 22:43.000]  объект, фактор ресивер,
[22:43.000 --> 22:45.000]  у которого есть метод setValue, который
[22:45.000 --> 22:47.000]  вызывает просто фактор значения
[22:47.000 --> 22:49.000]  setError, который не реализован здесь,
[22:49.000 --> 22:51.000]  и setDen, который тоже не реализован,
[22:51.000 --> 22:53.000]  мы сегодня этими двумя вещами
[22:53.000 --> 22:55.000]  заниматься почти не будем.
[22:55.000 --> 22:57.000]  Вот, ну и мы построили ресивер,
[22:57.000 --> 22:59.000]  теперь можно его вызвать,
[22:59.000 --> 23:01.000]  и он должен напечатать, видимо,
[23:01.000 --> 23:03.000]  17,
[23:03.000 --> 23:05.000]  если все с нашим кодом хорошо.
[23:07.000 --> 23:09.000]  Ну вот, пожалуйста, мы работаем с ресиверами, да?
[23:09.000 --> 23:11.000]  Вот у нас есть некоторый кулбэк.
[23:11.000 --> 23:13.000]  Пока смысла в этом мало.
[23:13.000 --> 23:15.000]  Давайте теперь заведем некоторые вычисления
[23:15.000 --> 23:17.000]  и воспользуемся вот наличием
[23:17.000 --> 23:19.000]  ростованием сендеров и функцией Submit.
[23:19.000 --> 23:21.000]  Я сейчас напишу какой-то код,
[23:21.000 --> 23:23.000]  а вы
[23:23.000 --> 23:25.000]  ответите на вопрос, а что я
[23:25.000 --> 23:27.000]  имел в виду, а потом уже мы напишем
[23:27.000 --> 23:29.000]  реализацию, то есть как он должен себя вести, а потом
[23:29.000 --> 23:31.000]  реализацию напишем.
[23:31.000 --> 23:33.000]  Я конструирую сендер
[23:35.000 --> 23:37.000]  вот так вот.
[23:37.000 --> 23:39.000]  Я конструирую ресивер.
[23:39.000 --> 23:41.000]  Это вычисление,
[23:41.000 --> 23:43.000]  а это обработчик, результат.
[23:47.000 --> 23:49.000]  Вот.
[23:49.000 --> 23:51.000]  Пока ничего не стартовало
[23:51.000 --> 23:53.000]  никакого вычисления, а теперь я говорю
[23:53.000 --> 23:55.000]  Submit Sender
[23:55.000 --> 23:57.000]  Perceiver.
[23:57.000 --> 23:59.000]  Что должно случиться
[23:59.000 --> 24:01.000]  вот в этой строчке?
[24:01.000 --> 24:03.000]  Утверждается, что я описал некоторые вычисления.
[24:03.000 --> 24:05.000]  Не похоже, чтобы тут какая-то
[24:05.000 --> 24:07.000]  асинхронность была, какие-то там
[24:07.000 --> 24:09.000]  параллельности, полый поток в планировщики,
[24:09.000 --> 24:11.000]  вот тут ничего такого нет.
[24:11.000 --> 24:13.000]  Что я имел в виду?
[24:13.000 --> 24:15.000]  Я имел в виду, что
[24:15.000 --> 24:17.000]  вот тут ничего такого нет.
[24:17.000 --> 24:19.000]  Что я имел в виду вот этими строчками?
[24:19.000 --> 24:21.000]  Какое вычисление должно произойти?
[24:21.000 --> 24:23.000]  Что вообще должно произойти?
[24:23.000 --> 24:25.000]  Какой код должен исполниться?
[24:25.000 --> 24:27.000]  Ну, видимо, я ожидаю,
[24:27.000 --> 24:29.000]  что на ресивере
[24:29.000 --> 24:31.000]  вызовется Set Value от 17
[24:31.000 --> 24:33.000]  просто синхронно. Вот в этом вызови Submit.
[24:35.000 --> 24:37.000]  Ну вот, давайте теперь напишем
[24:37.000 --> 24:39.000]  этот самый Sender Just.
[24:45.000 --> 24:47.000]  Ну вот.
[24:47.000 --> 24:49.000]  Ну вот.
[24:49.000 --> 24:51.000]  Ну вот.
[24:51.000 --> 24:53.000]  Ну вот.
[24:53.000 --> 24:55.000]  Ну вот.
[24:55.000 --> 24:57.000]  Ну вот.
[24:59.000 --> 25:01.000]  Ну вот.
[25:01.000 --> 25:03.000]  Ну вот.
[25:03.000 --> 25:05.000]  Ну вот.
[25:05.000 --> 25:07.000]  Ну вот.
[25:07.000 --> 25:09.000]  Ну вот.
[25:09.000 --> 25:11.000]  Ну вот.
[25:11.000 --> 25:13.000]  Ну вот.
[25:13.000 --> 25:15.000]  Ну вот.
[25:15.000 --> 25:17.000]  Ну вот.
[25:17.000 --> 25:19.000]  Ну вот.
[25:19.000 --> 25:21.000]  Ну вот.
[25:21.000 --> 25:23.000]  Ну вот.
[25:23.000 --> 25:25.000]  Ну вот.
[25:25.000 --> 25:27.000]  Ну вот.
[25:27.000 --> 25:29.000]  Ну вот.
[25:29.000 --> 25:31.000]  Ну вот.
[25:31.000 --> 25:33.000]  Ну вот.
[25:33.000 --> 25:35.000]  Ну вот.
[25:35.000 --> 25:37.000]  Ну вот.
[25:37.000 --> 25:39.000]  Ну вот.
[25:39.000 --> 25:41.000]  Ну вот.
[25:41.000 --> 25:46.000]  и в нем вызывается sender-submit-receiver, на экран печаталось бы 17.
[25:49.000 --> 25:55.000]  Ну, там нет Receiver, там есть setValue. setR. setValue какого?
[25:57.000 --> 25:59.000]  Ну, видимо, которого я не написал, да?
[26:04.000 --> 26:06.000]  Вот я хотел сказать вот так.
[26:07.000 --> 26:11.000]  Давайте проверим, что вычисления состоялось.
[26:14.000 --> 26:18.000]  Здорово. Вот, смотрите, мы с помощью senders и receivers описали вычисления.
[26:19.000 --> 26:26.000]  Ну, не очень пока полезно, но еще раз напоминаю, что наш фреймворк сегодня предназначен для того, чтобы описывать произвольные вычисления.
[26:27.000 --> 26:31.000]  Появится скоро какая-то асинхронность, но вот пока можно описать что-то синхронное.
[26:31.000 --> 26:36.000]  Вот мы написали Receiver, вот мы написали sender, самый простой синхронный, который прожидает значения.
[26:37.000 --> 26:43.000]  Да, он не дописан, конечно же, потому что чтобы быть sender-ом, нужно объявить value type, который мы вычисляем.
[26:46.000 --> 26:48.000]  Это нам...
[26:53.000 --> 26:55.000]  Да, можно.
[26:55.000 --> 26:57.000]  Так можно делать.
[27:00.000 --> 27:04.000]  Ну, я в одном месте где-то мне необходимо сделаю, а в остальном я жизнь сложить не буду.
[27:05.000 --> 27:09.000]  Но ты совершенно правильно говоришь, что зачем объявили концепты, когда им не пользуемся.
[27:10.000 --> 27:12.000]  Было бы странно, нужно ставить ограничение на тип.
[27:13.000 --> 27:17.000]  Давайте теперь напишем следующий sender.
[27:25.000 --> 27:27.000]  Непонятно что.
[27:28.000 --> 27:32.000]  А потом submit, sender, receiver.
[27:33.000 --> 27:39.000]  Вот два вопроса, что я имел в виду, и какой тип должен получить вот здесь receiver.
[27:40.000 --> 27:42.000]  Ну, я не знаю.
[27:43.000 --> 27:45.000]  Я не знаю.
[27:46.000 --> 27:48.000]  Я не знаю.
[27:49.000 --> 27:51.000]  Я не знаю.
[27:51.000 --> 27:55.000]  И какой тип должен получить вот здесь receiver?
[27:56.000 --> 27:58.000]  Future?
[27:59.000 --> 28:02.000]  А что значит future? Ну, future – это вообще-то не value, это вот...
[28:03.000 --> 28:05.000]  Здесь я хочу обычно значение получать.
[28:06.000 --> 28:09.000]  Вот значение, ну, receiver, он же получает результат вычисления.
[28:10.000 --> 28:13.000]  Это не может быть future, потому что future – это некоторое еще незавершенное вычисление.
[28:14.000 --> 28:16.000]  Я хочу уже значение получить.
[28:16.000 --> 28:21.000]  Ну и к тому же, значение какого типа я хочу получить, когда у меня просто написано neutral без аргументов?
[28:22.000 --> 28:24.000]  Никакого. То есть future от никакого значения.
[28:25.000 --> 28:27.000]  Ну, тут...
[28:28.000 --> 28:30.000]  Давайте, ну, нет, void мы не хотим писать.
[28:33.000 --> 28:35.000]  Мы не угадываем.
[28:36.000 --> 28:38.000]  Понимаете ли вы, что происходит?
[28:39.000 --> 28:41.000]  Вот смотрите, здесь вычисление синхронное, да?
[28:42.000 --> 28:44.000]  Это довольно непривычно, но пусть.
[28:44.000 --> 28:47.000]  Но зато понятно, что оно вычисляет значение типа int.
[28:48.000 --> 28:50.000]  А здесь вычисление у нас будет асинхронное.
[28:51.000 --> 28:53.000]  Но, с другой стороны, что оно вычисляет – непонятно.
[28:55.000 --> 28:57.000]  Но есть какие-то гипотезы, что оно вычисляет.
[28:58.000 --> 29:00.000]  Ну, семантические. То есть не то, чтобы какой тип написать сначала.
[29:01.000 --> 29:05.000]  Ну, может быть, мы дадим вот этот thread, в котором он сможет дальше другие...
[29:06.000 --> 29:08.000]  Вот, это правильная мысль.
[29:09.000 --> 29:12.000]  Мы здесь вычисляем, по сути, ничего, но асинхронно.
[29:12.000 --> 29:14.000]  Вот. Но ничего можно по-разному представлять.
[29:15.000 --> 29:19.000]  Вот, если вы когда-нибудь писали шаблонный код, то вы понимаете, что с void лучше не работать с шаблоном.
[29:20.000 --> 29:24.000]  Что отсутствие значения лучше представлять типом unit, который имеет одно единственное значение.
[29:25.000 --> 29:27.000]  Unit – это пустая структура. Вот.
[29:28.000 --> 29:33.000]  И ресивер, и сендер здесь будет вычислять просто unit type.
[29:34.000 --> 29:36.000]  Но асинхронно.
[29:37.000 --> 29:39.000]  И здесь я хочу написать следующее.
[29:43.000 --> 29:45.000]  Здесь же есть такое название.
[29:46.000 --> 29:49.000]  То есть это demon estate совсем не похоже по названию на type unit, которым он является.
[29:50.000 --> 29:54.000]  Поэтому я, если позволишь, воспользуюсь возможностью, напишу свой type unit с нормальным названием.
[29:58.000 --> 30:01.000]  Может, ему стоит добавить новую негативность?
[30:06.000 --> 30:08.000]  Так, давайте держать себя в руках.
[30:09.000 --> 30:15.000]  Мы сейчас не пишем максимально хороший код, потому что я уже во многих местах написал его плохо.
[30:16.000 --> 30:19.000]  Мы пишем простой код, который иллюстрирует то, что нам нужно сейчас.
[30:20.000 --> 30:28.000]  Итак, давайте напишем теперь сендер neutral, который асинхронно вычисляет значение типа unit.
[30:28.000 --> 30:31.000]  А, кстати, мы сегодня сдержаны границами времени, потому что мы не успеем?
[30:36.000 --> 30:38.000]  Ну что ж, тогда сильно ускорится.
[30:41.000 --> 30:43.000]  Итак. Нет, эту реакцию невозможно разорвать.
[30:43.000 --> 30:45.000]  Итак, что мы здесь напишем?
[30:45.000 --> 30:49.000]  И тогда мы будемByte.
[30:56.000 --> 30:58.000]  Б Ting-tongue.
[31:01.000 --> 31:03.000]  Д pitching-tongue.
[31:04.000 --> 31:06.000] ungkin.
[31:07.000 --> 31:11.000]  И на этом environmental sequence.
[31:11.000 --> 31:33.400]  Я создаю трэд, в него передаю лямбду, в которую захватываю,
[31:33.400 --> 31:40.600]  давайте экономить время, захватываю ресивер
[31:40.600 --> 31:51.640]  и вызываю ресивер setValue от экземпляра унита, ну и DetachThread.
[31:51.640 --> 31:59.640]  Вот теперь можно наверное вызвать этот код,
[31:59.640 --> 32:02.920]  но убедиться сначала, что мы в одном потоке.
[32:10.600 --> 32:24.200]  Ну да.
[32:38.440 --> 32:39.480]  Попробуем еще раз.
[32:40.600 --> 32:46.920]  Ну вот, вот теперь мы научились стартовать асинхронную операцию,
[32:46.920 --> 32:53.560]  которая ничего не вычисляет, но которая как бы запускает ресивер уже где-то в другом потоке.
[32:53.560 --> 32:59.160]  Вот, довольно мощная идея, потому что сейчас мы с помощью нее напишем thread pool.
[32:59.160 --> 33:05.160]  И я бы сказал, что сегодняшняя лекция, она с одной стороны про такой более общий фреймворк вычислений,
[33:05.160 --> 33:10.200]  как можно вычисление описывать довольно абстрактно, а с другой стороны она вот как бы
[33:11.000 --> 33:18.280]  закрывает эту длинную арку развития пула потоков, которая начала где-то в феврале еще,
[33:18.280 --> 33:22.440]  да, наверное, где мы построили совсем скромный, совсем простой thread pool.
[33:22.440 --> 33:28.760]  Потом мы его улучшили с помощью сложного алгоритма планирования,
[33:28.760 --> 33:35.240]  мы там усложнили его интрузивностью, улучшили его интрузивностью, ну некоторые из вас.
[33:35.240 --> 33:39.320]  А сейчас мы поговорим о том, как вообще должно выглядеть API thread pool,
[33:39.320 --> 33:44.920]  потому что оказывается, что оно может выглядеть иначе, не так, как мы до этого момента полагали.
[33:44.920 --> 33:47.880]  Вот, это такая очень сложная, очень длинная эволюция пулопотоков.
[33:47.880 --> 33:51.480]  Вот, пожалуйста, зафиксируйте ее в своем сознании.
[33:51.480 --> 33:56.920]  Итак, мы хотим написать thread pool, но не думайте, что сейчас буду писать thread pool прям заново весь,
[33:56.920 --> 33:58.920]  я напишу его несколько проще.
[33:58.920 --> 34:13.480]  Вот, у него будет метод Submit, который получает таску и исполняет ее.
[34:13.480 --> 34:15.960]  Вот, это наш thread pool пока на сегодня.
[34:15.960 --> 34:18.360]  Ну, то есть здесь можно представить себе какой-то более сложный код,
[34:18.360 --> 34:21.400]  можно представить себе там шардированный планировщик с workstation,
[34:21.400 --> 34:27.080]  ну или хотя бы блокирующую очередь и потоки, но здесь мне не важно, как он устроен внутри,
[34:27.080 --> 34:32.360]  мне важно, как я с ним работаю, а я с ним хочу работать снова как с sender.
[34:32.360 --> 34:39.240]  Вот, у меня есть пулпоток, и вот у меня есть ресивер.
[34:39.240 --> 34:48.440]  Этот ресивер снова будет вычислять значение вой, значение юнь.
[34:48.440 --> 34:59.240]  Как я хочу этот ресивер запустить в пулепотоков?
[34:59.240 --> 35:04.840]  Ну, видимо, мне нужна будет операция запланировать в thread pool.
[35:04.840 --> 35:08.280]  Давайте ее напишем.
[35:08.280 --> 35:17.640]  Но в конце концов, какая разница?
[35:17.800 --> 35:22.680]  Я планирую задачу в новый thread или в thread pool, да?
[35:22.680 --> 35:26.200]  То есть и в том, и в другом случае sender, и я снова их не подписываю,
[35:26.200 --> 35:34.200]  в смысле, обвращаемые типы совершенно напрасно.
[35:34.200 --> 35:44.200]  В этом случае нам снова нужен sender,
[35:44.200 --> 35:56.760]  который снова вычисляет юнит, но вот в одном из потоков воркеров пула.
[35:56.760 --> 36:00.600]  Мы получаем ресивер, и что же мы с ним сделаем?
[36:00.600 --> 36:10.760]  Ну, мы для начала построим thread pool sender,
[36:10.840 --> 36:15.320]  запомним в нем thread pool, в который мы планируем задачу.
[36:15.320 --> 36:21.320]  Ну и в методе submit мы напишем что?
[36:21.320 --> 36:23.320]  Мы в методе submit напишем submit.
[36:23.320 --> 36:26.360]  Вот, кажется, что все довольно разумно.
[36:26.360 --> 36:32.360]  Вычисляем юнит и запускаем ресивер set value.
[36:32.360 --> 36:46.920]  Получился thread pool sender, да?
[36:46.920 --> 36:50.920]  И теперь мы можем в thread pool запланировать работу.
[36:50.920 --> 36:54.920]  Давайте этот пример закомментируем, потому что он будет нас шуметь немножко.
[36:55.480 --> 37:03.480]  Мы не сделали submit.
[37:03.480 --> 37:13.480]  Как хорошо, что я не один.
[37:13.480 --> 37:19.480]  Ага, ну невозможно установить эту плему или нет, потому что...
[37:20.040 --> 37:24.040]  Ну давайте хотя бы здесь напишем следующее.
[37:28.040 --> 37:32.040]  Это нас чуть больше убедит, что происходит нечто разумное.
[37:42.040 --> 37:48.040]  Ну вот, мы построили sender для poola-потоков.
[37:48.600 --> 37:54.600]  Вот прямо сейчас, мне кажется, что разумно еще немного наш дизайн усложнить
[37:54.600 --> 37:58.600]  и вот к трем сущностям, которые у нас уже появились, sender и receiver,
[37:58.600 --> 38:02.600]  добавить сущность, которая называется планировщик.
[38:02.600 --> 38:08.600]  Как вы думаете, чем будет заниматься планировщик для poola-потоков?
[38:12.600 --> 38:16.600]  Ну submit, так это деталь реализации планировщика.
[38:17.160 --> 38:21.160]  Я хочу вписать же эту сущность в наш абстрактный дизайн, где есть sender и receiver.
[38:23.160 --> 38:27.160]  Вот да, мы хотим придумать планировщики теперь, которые будут строить sender.
[38:27.160 --> 38:31.160]  А sender – это представление каких-то вычислений синхронных, асинхронных.
[38:31.160 --> 38:35.160]  Вот планировщик для poola-потоков будет строить sender,
[38:35.160 --> 38:39.160]  который асинхронно вычисляет voids.
[38:39.160 --> 38:41.160]  Понятно, да?
[38:41.160 --> 38:43.160]  Давайте мы сейчас это все и напишем.
[38:43.720 --> 38:47.720]  И мы немного перефакторим этот код.
[38:53.720 --> 38:59.720]  У нас есть sender, и мы хотим написать планировщик для poola-потоков.
[38:59.720 --> 39:01.720]  Какой-то конкретный планировщик.
[39:01.720 --> 39:05.720]  И у него будет метод shadow, который
[39:07.720 --> 39:11.720]  строит sender для poola-потоков.
[39:12.280 --> 39:16.280]  То есть вот такие еще не стартовавшие асинхронные операции,
[39:16.280 --> 39:20.280]  которые в случае poola будут асинхронно вычислять значение типа u.
[39:22.280 --> 39:28.280]  И мы напишем метод getShadowler,
[39:30.280 --> 39:36.280]  который возвращает планировщик для poola-потоков.
[39:36.280 --> 39:40.280]  А это мы вообще сотрем.
[39:42.280 --> 39:46.280]  И давайте, чтобы у нас не было соблазнов больше, уберем submit.
[39:50.280 --> 39:52.280]  Submit – это какая-то деталь реализации.
[39:52.280 --> 39:56.280]  В нашем фреймворке будут только sender, receiver и планировщики,
[39:56.280 --> 40:00.280]  поэтому, чтобы запланировать задачу в threadpool,
[40:00.280 --> 40:06.280]  мы должны сначала получить планировщик,
[40:06.840 --> 40:10.840]  потом с помощью него
[40:12.840 --> 40:16.840]  построить sender, который асинхронно вычисляет void,
[40:16.840 --> 40:18.840]  а потом запустить.
[40:18.840 --> 40:20.840]  Вот видите, мы разделили два шага.
[40:20.840 --> 40:26.840]  Мы разделили представление нашего асинхронного вычисления unit void
[40:26.840 --> 40:30.840]  и запуск планирования в threadpool.
[40:32.840 --> 40:34.840]  Пока все довольно сложно выглядит,
[40:35.400 --> 40:41.400]  мы атомизируем отдельные шаги в наших предшествующих операциях,
[40:41.400 --> 40:45.400]  поэтому не удивительно, что появляются какие-то промежуточные сущности.
[40:47.400 --> 40:49.400]  Итак, у нас есть теперь уже три sender,
[40:49.400 --> 40:53.400]  и мы сейчас научимся делать вот что.
[40:53.400 --> 40:57.400]  Вот вспомним про future.
[40:57.400 --> 40:59.400]  В чем их замысел?
[40:59.400 --> 41:03.400]  В том, что можно для future, для асинхронной операции,
[41:03.960 --> 41:07.960]  запланировать продолжение с помощью метода subscribe
[41:07.960 --> 41:09.960]  или с помощью комбинатора Zen.
[41:09.960 --> 41:11.960]  То есть у нас есть future,
[41:11.960 --> 41:13.960]  мы можем прицепить к ней следующий шаг вычисления,
[41:13.960 --> 41:15.960]  то есть продлить вот этот граф вычисления.
[41:15.960 --> 41:17.960]  И у нас здесь есть sender,
[41:17.960 --> 41:19.960]  которые представляют собой по сути,
[41:19.960 --> 41:21.960]  ну это не future, разумеется,
[41:21.960 --> 41:23.960]  но суть очень похожая.
[41:23.960 --> 41:25.960]  Это какое-то вычисление, которое еще не стартовало,
[41:25.960 --> 41:29.960]  но про которое известно, какой результат оно построит.
[41:30.520 --> 41:32.520]  Вот давайте мы для sender-ов
[41:32.520 --> 41:34.520]  напишем теперь комбинатор,
[41:34.520 --> 41:36.520]  который будет называться Zen,
[41:38.520 --> 41:40.520]  и посмотрим,
[41:40.520 --> 41:42.520]  чего мы от него хотим.
[41:44.520 --> 41:46.520]  Мы начнем с какого-то вычисления
[41:46.520 --> 41:48.520]  в пуле потоков,
[41:48.520 --> 41:50.520]  вычисления unit.
[41:52.520 --> 41:54.520]  А дальше мы хотим следующего от него,
[41:54.520 --> 41:56.520]  мы хотим написать вот так вот.
[41:59.960 --> 42:01.960]  Вот, по-моему, все правильно.
[42:17.960 --> 42:19.960]  Вот, я хочу в пуле потоков вычислить 42.
[42:19.960 --> 42:21.960]  Вот я вычислил в пуле потоков 42.
[42:23.960 --> 42:25.960]  Я взял sender,
[42:25.960 --> 42:27.960]  который вычисляет 42,
[42:27.960 --> 42:29.960]  я взял его к асинхронному вычислению unit,
[42:29.960 --> 42:31.960]  и вот теперь я асинхронно вычисляю 42.
[42:33.960 --> 42:35.960]  А теперь я хочу
[42:37.960 --> 42:39.960]  добавить
[42:39.960 --> 42:41.960]  к вычисленному значению
[42:41.960 --> 42:43.960]  еще один.
[42:47.960 --> 42:49.960]  И все это вычисление
[42:49.960 --> 42:51.960]  я хочу замкнуть
[42:51.960 --> 42:53.960]  некоторым ресивером,
[42:53.960 --> 42:55.960]  который напечатает результат на экран.
[42:57.960 --> 42:59.960]  Вот.
[43:15.960 --> 43:17.960]  Вот теперь я хочу, чтобы выполнился
[43:17.960 --> 43:19.960]  такой код. Для этого мне нужен
[43:19.960 --> 43:21.960]  комбинатор Zen, который получает sender,
[43:21.960 --> 43:23.960]  то есть вычисление, которое вычисляет
[43:23.960 --> 43:25.960]  некоторое значение, получает
[43:25.960 --> 43:27.960]  продолжение синхронное,
[43:27.960 --> 43:29.960]  и строит новое вычисление,
[43:29.960 --> 43:31.960]  которое вычисляет
[43:31.960 --> 43:33.960]  уже результат, который вычисляет
[43:33.960 --> 43:35.960]  цепочку.
[43:35.960 --> 43:37.960]  Давайте его писать.
[43:43.960 --> 43:45.960]  Нет, мы этого не хотим
[43:45.960 --> 43:47.960]  делать.
[43:51.960 --> 43:53.960]  Назначение в общем случае
[43:53.960 --> 43:55.960]  нон-копия было. Как мы можем использовать
[43:55.960 --> 43:57.960]  назначение в нескольких местах?
[44:03.960 --> 44:05.960]  Ну, если тебе хочется
[44:05.960 --> 44:07.960]  циклы писать, то мне кажется, что
[44:07.960 --> 44:09.960]  для всего можно придумать
[44:09.960 --> 44:11.960]  решение, но
[44:11.960 --> 44:13.960]  вот писать его в таком
[44:13.960 --> 44:15.960]  фреймворке, мне кажется, уже нецелесообразно,
[44:15.960 --> 44:17.960]  но есть разные мнения.
[44:17.960 --> 44:19.960]  Давайте сейчас напишем Zen,
[44:19.960 --> 44:21.960]  потому что у нас довольно мало времени остается.
[44:23.960 --> 44:25.960]  Итак, у нас есть
[44:27.960 --> 44:29.960]  sender, у нас есть некоторая
[44:29.960 --> 44:31.960]  функция продолжения,
[44:31.960 --> 44:33.960]  и мы пишем
[44:33.960 --> 44:35.960]  комбинатор Zen, который получает
[44:35.960 --> 44:37.960]  sender, который получает
[44:37.960 --> 44:39.960]  продолжение и
[44:39.960 --> 44:41.960]  возвращает
[44:41.960 --> 44:43.960]  новый sender,
[44:49.960 --> 44:51.960]  который вычисляет уже цепочку.
[44:53.960 --> 44:55.960]  Вот тут нужно аккуратиться,
[44:55.960 --> 44:57.960]  смотрите,
[44:57.960 --> 44:59.960]  у нас есть
[44:59.960 --> 45:01.960]  фреймворк,
[45:01.960 --> 45:03.960]  у нас есть
[45:03.960 --> 45:05.960]  фреймворк,
[45:05.960 --> 45:07.960]  у нас есть
[45:07.960 --> 45:09.960]  фреймворк,
[45:09.960 --> 45:11.960]  у нас есть
[45:11.960 --> 45:13.960]  фреймворк,
[45:13.960 --> 45:15.960]  у нас есть
[45:15.960 --> 45:17.960]  фреймворк,
[45:17.960 --> 45:19.960]  у нас есть
[45:19.960 --> 45:21.960]  фреймворк,
[45:21.960 --> 45:23.960]  и нужно аккуратиться, смотрите,
[45:23.960 --> 45:25.960]  у нас есть
[45:25.960 --> 45:27.960]  sender, есть продолжение,
[45:27.960 --> 45:29.960]  и нужно разобраться, что вычислял
[45:29.960 --> 45:31.960]  S и что вычисляем мы,
[45:31.960 --> 45:33.960]  Zen. Вот что вычислял S?
[45:33.960 --> 45:35.960]  S вычислял
[45:35.960 --> 45:37.960]  тип T,
[45:41.960 --> 45:43.960]  который объявлен
[45:43.960 --> 45:45.960]  у каждого sender.
[45:45.960 --> 45:47.960]  Мы потребовали, чтобы каждый sender объявлял,
[45:47.960 --> 45:49.960]  что он вычисляет. А что мы вычисляем?
[45:51.960 --> 45:53.960]  А...
[46:05.960 --> 46:07.960]  Итак,
[46:07.960 --> 46:09.960]  как мы собираемся вычислить это значение
[46:09.960 --> 46:11.960]  U? То есть смотрите, вот мы
[46:11.960 --> 46:13.960]  Zen sender, который вычисляет U теперь,
[46:13.960 --> 46:15.960]  поэтому мы ожидаем ресивера,
[46:15.960 --> 46:17.960]  который ожидает на вход
[46:17.960 --> 46:19.960]  U. Давайте мы так его назовем,
[46:19.960 --> 46:21.960]  у ресивер, чтобы различать.
[46:21.960 --> 46:23.960]  Вот. Но когда мы...
[46:23.960 --> 46:25.960]  Но чтобы стартовать цепочку, мы же должны
[46:25.960 --> 46:27.960]  стартовать ее сначала. То есть мы должны стартовать
[46:27.960 --> 46:29.960]  наш sender, вот S, который нам дан.
[46:31.960 --> 46:33.960]  Вот. То есть мы в конце концов напишем здесь,
[46:35.960 --> 46:37.960]  давайте вот так напишем, T sender,
[46:37.960 --> 46:39.960]  мы
[46:39.960 --> 46:41.960]  стартуем вычисления,
[46:41.960 --> 46:43.960]  а для этого должны передать сюда, видимо,
[46:43.960 --> 46:45.960]  T ресивер. То есть ресивер
[46:45.960 --> 46:47.960]  вспомогательный, который получит значение T
[46:47.960 --> 46:49.960]  и преобразует его в U.
[46:57.960 --> 46:59.960]  Ну, да,
[46:59.960 --> 47:01.960]  она где-то ниже объявлена просто.
[47:03.960 --> 47:05.960]  Вот. Мы сейчас напишем T ресивер,
[47:05.960 --> 47:07.960]  который будет
[47:09.960 --> 47:11.960]  ожидать значение
[47:11.960 --> 47:13.960]  типа T,
[47:13.960 --> 47:15.960]  от первого шага вычисления, ну вот,
[47:15.960 --> 47:17.960]  как бы префикса вычисления, да,
[47:17.960 --> 47:19.960]  которому мы хотим добавить еще одно звено.
[47:21.960 --> 47:23.960]  И что мы хотим сделать
[47:23.960 --> 47:25.960]  с этим T value?
[47:25.960 --> 47:27.960]  Мы хотим применить
[47:27.960 --> 47:29.960]  F к этому значению.
[47:29.960 --> 47:31.960]  Давайте его захватим.
[47:37.960 --> 47:39.960]  Получить значение
[47:39.960 --> 47:41.960]  U.
[47:41.960 --> 47:43.960]  И что с ним сделать?
[47:43.960 --> 47:45.960]  Отправить его в ресивер.
[47:45.960 --> 47:47.960]  Отправить его в ресивер.
[47:57.960 --> 47:59.960]  Ну что ж, неплохо, да?
[47:59.960 --> 48:01.960]  Вроде написалось.
[48:01.960 --> 48:03.960]  Написалось, но,
[48:03.960 --> 48:05.960]  как всегда, не комперируется,
[48:05.960 --> 48:07.960]  потому что я не аккуратен.
[48:13.960 --> 48:15.960]  А почему он не используется,
[48:15.960 --> 48:17.960]  когда вот же используется?
[48:19.960 --> 48:21.960]  Ну, давайте попробуем.
[48:27.960 --> 48:29.960]  Я где-то что...
[48:29.960 --> 48:31.960]  Ну да, я не объявил у Зэн Сэндера
[48:31.960 --> 48:33.960]  тип, который он вычисляет.
[48:35.960 --> 48:37.960]  Да.
[48:43.960 --> 48:45.960]  Уют был, да, спасибо.
[48:55.960 --> 48:57.960]  Здорово.
[48:57.960 --> 48:59.960]  Работает.
[48:59.960 --> 49:01.960]  Что?
[49:03.960 --> 49:05.960]  Вот он.
[49:05.960 --> 49:07.960]  Нет.
[49:11.960 --> 49:13.960]  Не очень понимаю. Мы пишем Сэндер.
[49:13.960 --> 49:15.960]  Мы пишем Сэндер, который...
[49:15.960 --> 49:17.960]  Мы пишем вообще
[49:17.960 --> 49:19.960]  Трансформатор, который получает Сэндер,
[49:19.960 --> 49:21.960]  некоторое вычисление
[49:21.960 --> 49:23.960]  и вот функцию, которая
[49:23.960 --> 49:25.960]  хочет прицепиться к этому вычислению.
[49:27.960 --> 49:29.960]  И строим новый Сэндер, который
[49:29.960 --> 49:31.960]  называется Зэн, который представляет собой
[49:31.960 --> 49:33.960]  вот такое новое длинное вычисление,
[49:33.960 --> 49:35.960]  которое состоит из вычисления S,
[49:35.960 --> 49:37.960]  которому конкатинируется
[49:37.960 --> 49:39.960]  функция F.
[49:39.960 --> 49:41.960]  Так что мы сначала
[49:41.960 --> 49:43.960]  запускаем этот префикс вычисления,
[49:43.960 --> 49:45.960]  а потом,
[49:45.960 --> 49:47.960]  когда это вычисление завершается,
[49:47.960 --> 49:49.960]  мы во вспомогательном ресивере
[49:49.960 --> 49:51.960]  запускаем эту самую функцию F
[49:51.960 --> 49:53.960]  и уже отправляем
[49:53.960 --> 49:55.960]  результат в
[49:55.960 --> 49:57.960]  ресивера всей цепочки,
[49:57.960 --> 49:59.960]  которую мы построили.
[49:59.960 --> 50:01.960]  Ну что ж,
[50:01.960 --> 50:03.960]  достойный результат, а теперь
[50:03.960 --> 50:05.960]  нужно представить, в какой-то кодке
[50:05.960 --> 50:07.960]  это все скомпилируется. Вот смотрите,
[50:07.960 --> 50:09.960]  что такое
[50:09.960 --> 50:11.960]  ThreadPoolShadow?
[50:11.960 --> 50:13.960]  ThreadPoolShadow or Shadow
[50:13.960 --> 50:15.960]  это класс ThreadPoolSender,
[50:15.960 --> 50:17.960]  да?
[50:17.960 --> 50:19.960]  ThreadPoolSender, у которого есть... Где же он?
[50:21.960 --> 50:23.960]  ThreadPoolSender,
[50:23.960 --> 50:25.960]  у которого есть одно поле, это
[50:25.960 --> 50:27.960]  ссылка на ThreadPool.
[50:27.960 --> 50:29.960]  Потом мы строим по нему
[50:29.960 --> 50:31.960]  Zen от S0.
[50:31.960 --> 50:33.960]  Zen это класс
[50:33.960 --> 50:35.960]  ZenSender.
[50:35.960 --> 50:37.960]  У него есть два поля.
[50:37.960 --> 50:39.960]  Это предшествующий
[50:39.960 --> 50:41.960]  Sender и функция.
[50:41.960 --> 50:43.960]  Предшествующий Sender это ThreadPoolSender,
[50:43.960 --> 50:45.960]  то есть мы в поле этого класса заинлайним
[50:45.960 --> 50:47.960]  ThreadPoolSender с одним полем,
[50:47.960 --> 50:49.960]  ссылку на ThreadPool.
[50:49.960 --> 50:51.960]  А теперь мы говорим
[50:51.960 --> 50:53.960]  еще раз Zen.
[50:53.960 --> 50:55.960]  И мы строим
[50:55.960 --> 50:57.960]  еще один ZenSender,
[50:57.960 --> 50:59.960]  у которого будет
[50:59.960 --> 51:01.960]  поле S и поле F.
[51:01.960 --> 51:03.960]  Поле F это предшествующий Sender,
[51:03.960 --> 51:05.960]  в котором было уже
[51:05.960 --> 51:07.960]  ссылка на ThreadPool и
[51:07.960 --> 51:09.960]  первая функция.
[51:09.960 --> 51:11.960]  И то есть, вот мы, смотрите, здесь
[51:11.960 --> 51:13.960]  получим конкретный класс
[51:13.960 --> 51:15.960]  неизвестного нам типа, у которого будут
[51:15.960 --> 51:17.960]  три поля.
[51:17.960 --> 51:19.960]  Ссылка на ThreadPool
[51:19.960 --> 51:21.960]  λ1, л2.
[51:23.960 --> 51:25.960]  И когда мы назовем, вызовем на нем
[51:25.960 --> 51:27.960]  Submit, то что он сделает?
[51:27.960 --> 51:29.960]  Он в ThreadPool бросит сразу
[51:29.960 --> 51:31.960]  скомбинированную лямду, которая вызывает
[51:31.960 --> 51:33.960]  сначала функцию,
[51:33.960 --> 51:35.960]  сначала первое
[51:35.960 --> 51:37.960]  Receiver, то есть первую функцию от
[51:37.960 --> 51:39.960]  унита, а потом вызывает от результата
[51:39.960 --> 51:41.960]  вторую функцию. То есть это все заинлайнится,
[51:41.960 --> 51:43.960]  понимаете?
[51:43.960 --> 51:45.960]  Но если не понимаете, то...
[51:49.960 --> 51:51.960]  Если не понимаете,
[51:51.960 --> 51:53.960]  то можно продемонстрировать.
[51:53.960 --> 51:55.960]  Вот давайте мы
[51:55.960 --> 51:57.960]  сотрем все лишнее,
[51:57.960 --> 51:59.960]  что нам
[51:59.960 --> 52:01.960]  сейчас помешает.
[52:01.960 --> 52:03.960]  Сотрем...
[52:05.960 --> 52:07.960]  Сотрем корутины,
[52:07.960 --> 52:09.960]  которые нам
[52:09.960 --> 52:11.960]  не нужны
[52:11.960 --> 52:13.960]  пока.
[52:13.960 --> 52:15.960]  Будь здоров. И
[52:15.960 --> 52:17.960]  сотрем лишние
[52:17.960 --> 52:19.960]  сложные функции.
[52:21.960 --> 52:29.960]  И все еще очень
[52:29.960 --> 52:31.960]  сложный код.
[52:37.960 --> 52:39.960]  Я хочу, чтобы он был попроще,
[52:39.960 --> 52:41.960]  но я где-то ошибся, нет?
[52:41.960 --> 52:43.960]  Да, вот.
[52:43.960 --> 52:45.960]  Вот что мне мешает,
[52:45.960 --> 52:47.960]  чтобы получить простой код.
[52:47.960 --> 52:49.960]  Мне нужно избавиться от этой строчки еще.
[52:49.960 --> 52:51.960]  Вот, отлично.
[52:51.960 --> 52:53.960]  Во что скомпинировался Main?
[52:53.960 --> 52:55.960]  Он скомпинировался
[52:55.960 --> 52:57.960]  в вызов 43.
[52:57.960 --> 52:59.960]  Ну, то есть компилятор
[52:59.960 --> 53:01.960]  все это заинлайнил, и
[53:01.960 --> 53:03.960]  то, что мы делаем,
[53:03.960 --> 53:05.960]  то, что мы делаем,
[53:05.960 --> 53:07.960]  то, что мы делаем,
[53:07.960 --> 53:09.960]  то, что мы делаем,
[53:09.960 --> 53:11.960]  компилятор все это заинлайнил, и
[53:11.960 --> 53:13.960]  ну, если бы здесь был Трэдпул,
[53:13.960 --> 53:15.960]  то код бы выглядел сложнее,
[53:15.960 --> 53:17.960]  то есть он бы заинлайнил Сендер,
[53:17.960 --> 53:19.960]  то есть построил бы функциональный объект
[53:19.960 --> 53:21.960]  с двумя полями функциями, там внутри
[53:21.960 --> 53:23.960]  смог вызвать одно в другом и получить 43,
[53:23.960 --> 53:25.960]  Трэдпул бы он сам не стер.
[53:25.960 --> 53:27.960]  Но здесь он стер даже Трэдпул,
[53:27.960 --> 53:29.960]  потому что у нас он ничего полезного не делал.
[53:29.960 --> 53:31.960]  Вот, то есть
[53:31.960 --> 53:33.960]  за счет того, что
[53:33.960 --> 53:35.960]  мы вот здесь пишем все на шаблонах, за счет того,
[53:35.960 --> 53:37.960]  что вот эти Зены можно заинлайнить друг друга,
[53:37.960 --> 53:39.960]  и все это схлопывается в такие вот
[53:39.960 --> 53:41.960]  атомарные шаги, и все получается еще
[53:41.960 --> 53:43.960]  эффективнее.
[53:45.960 --> 53:47.960]  Хорошо.
[53:47.960 --> 53:49.960]  Вот утверждается, что мы построили
[53:49.960 --> 53:51.960]  новый универсальный
[53:51.960 --> 53:53.960]  API для Трэдпула. Вот так
[53:53.960 --> 53:55.960]  в него должны планироваться все задачи.
[53:57.960 --> 53:59.960]  В частности, корутины.
[53:59.960 --> 54:01.960]  Почему бы в Трэдпуле не запускать корутины,
[54:01.960 --> 54:03.960]  да? Мы же так делали уже.
[54:03.960 --> 54:05.960]  Ну, то есть чтобы корутина стала
[54:05.960 --> 54:07.960]  вообще какой-то асинхронной работой,
[54:07.960 --> 54:09.960]  она должна переместиться в Трэдпул.
[54:09.960 --> 54:11.960]  И раньше мы писали
[54:11.960 --> 54:13.960]  Трэдпул Сенд для корутин.
[54:13.960 --> 54:15.960]  Вот давайте начнем
[54:15.960 --> 54:17.960]  это делать.
[54:17.960 --> 54:19.960]  И вот у нас есть
[54:19.960 --> 54:21.960]  пусть
[54:21.960 --> 54:23.960]  корутина,
[54:23.960 --> 54:25.960]  которая получает Трэдпул
[54:25.960 --> 54:27.960]  и хочет в нем исполняться.
[54:27.960 --> 54:29.960]  Ну ладно, мы сказали,
[54:29.960 --> 54:31.960]  что мы работаем с планировщиками,
[54:31.960 --> 54:33.960]  поэтому пусть мы получаем даже
[54:33.960 --> 54:35.960]  не Трэдпул,
[54:35.960 --> 54:37.960]  а мы получаем сразу
[54:37.960 --> 54:39.960]  планировщик.
[54:39.960 --> 54:41.960]  Планировщик, то есть штук,
[54:41.960 --> 54:43.960]  который возвращает Сендр.
[54:45.960 --> 54:47.960]  И мы хотим
[54:47.960 --> 54:49.960]  перепланироваться в пул потоков,
[54:49.960 --> 54:51.960]  в произвольный планировщик.
[54:51.960 --> 54:53.960]  А произвольный планировщик строит Сендр.
[54:53.960 --> 54:55.960]  Вот мы хотим каким-то образом написать
[54:55.960 --> 54:57.960]  CoEv8
[55:03.960 --> 55:05.960]  ShadowerShadow
[55:05.960 --> 55:07.960]  Shadow, я напомню,
[55:07.960 --> 55:09.960]  возвращает нам Сендр.
[55:09.960 --> 55:11.960]  Сендр — это представление
[55:11.960 --> 55:13.960]  для асинхронных операций,
[55:13.960 --> 55:15.960]  которые потоки в Orkery вычисляют unit.
[55:17.960 --> 55:19.960]  И мы хотим этот пример
[55:19.960 --> 55:21.960]  сейчас написать.
[55:21.960 --> 55:23.960]  У нас есть Трэдпул,
[55:23.960 --> 55:25.960]  у нас есть планировщик,
[55:25.960 --> 55:27.960]  и мы стартуем к корутину,
[55:29.960 --> 55:31.960]  которая хочет переместиться в этот планировщик.
[55:31.960 --> 55:33.960]  И вот это очень важный момент
[55:33.960 --> 55:35.960]  лекции, может быть даже самый важный,
[55:35.960 --> 55:37.960]  который поясняет,
[55:37.960 --> 55:39.960]  демонстрирует нам,
[55:39.960 --> 55:41.960]  почему вот этот дизайн чертовски разумен.
[55:41.960 --> 55:43.960]  Сендр и ресивер.
[55:43.960 --> 55:45.960]  Почему выгодно описывать
[55:45.960 --> 55:47.960]  все вычисления в виде Сендр и ресивера
[55:47.960 --> 55:49.960]  в конце концов?
[55:49.960 --> 55:51.960]  Потому что эти Сендр и ресиверы
[55:51.960 --> 55:53.960]  очень хорошо ложатся на корутины,
[55:53.960 --> 55:55.960]  потому что на самом деле тут есть
[55:55.960 --> 55:57.960]  совершенно прямая, очень ясная
[55:57.960 --> 55:59.960]  параллель.
[55:59.960 --> 56:01.960]  Вот.
[56:01.960 --> 56:03.960]  Что такое у нас есть?
[56:03.960 --> 56:05.960]  Какие у нас составные элементы есть?
[56:05.960 --> 56:07.960]  Сендр – это асинхронная операция,
[56:07.960 --> 56:09.960]  которая еще не стартовала.
[56:09.960 --> 56:11.960]  Вычисление, возможно, асинхронное,
[56:11.960 --> 56:13.960]  которая еще не стартовала,
[56:13.960 --> 56:15.960]  ленивое вычисление.
[56:15.960 --> 56:17.960]  Есть ресивер, который ожидает результат.
[56:17.960 --> 56:19.960]  И есть операция, которая стартует,
[56:19.960 --> 56:21.960]  то есть связывает Сендр ресиверы,
[56:21.960 --> 56:23.960]  запускает вычисления,
[56:23.960 --> 56:25.960]  все это случается.
[56:25.960 --> 56:27.960]  А теперь у нас есть корутина.
[56:27.960 --> 56:29.960]  Корутина хочет попасть в третпул.
[56:29.960 --> 56:31.960]  Для этого она должна остановиться,
[56:31.960 --> 56:33.960]  а потом в третпуле
[56:33.960 --> 56:35.960]  возобновиться.
[56:37.960 --> 56:39.960]  Вот видите ли вы
[56:39.960 --> 56:41.960]  связь между корутиной
[56:41.960 --> 56:43.960]  и Сендром?
[56:43.960 --> 56:45.960]  Корутиной и планировщиком
[56:45.960 --> 56:47.960]  пула, который строит Сендр для пула.
[56:47.960 --> 56:49.960]  Или вообще связь между
[56:49.960 --> 56:51.960]  произвольной корутиной и произвольным
[56:51.960 --> 56:53.960]  Сендром?
[56:53.960 --> 56:55.960]  Потому что, смотрите, что я утверждаю,
[56:55.960 --> 56:57.960]  что операция коэвейт
[56:57.960 --> 56:59.960]  от Сендора это чертовски разумная
[56:59.960 --> 57:01.960]  операция.
[57:01.960 --> 57:03.960]  Вот если у нас есть Сендор, который представляет собой
[57:03.960 --> 57:05.960]  вычисление, то очень естественно
[57:05.960 --> 57:07.960]  и универсально для него поддержать
[57:07.960 --> 57:09.960]  оператор коэвейт.
[57:15.960 --> 57:17.960]  И вот ровно здесь мне нужны концепты, наконец.
[57:25.960 --> 57:27.960]  Понимаете ли вы, в чем связь?
[57:27.960 --> 57:29.960]  Вот давайте
[57:29.960 --> 57:31.960]  выпишем сущности. У нас есть ресиверы,
[57:31.960 --> 57:33.960]  у нас есть в дизайне, в нашем Сендоре,
[57:33.960 --> 57:35.960]  и есть Сабмит.
[57:35.960 --> 57:37.960]  Ресивер это колбэк
[57:37.960 --> 57:39.960]  обобщенный, Сендор
[57:39.960 --> 57:41.960]  это ленивое, еще не стартовавшее
[57:41.960 --> 57:43.960]  вычисление, Сабмит
[57:43.960 --> 57:45.960]  это точка, которая связывает
[57:45.960 --> 57:47.960]  Сендор и ресивер,
[57:47.960 --> 57:49.960]  и сэндор это
[57:49.960 --> 57:51.960]  ленивое, еще не стартовавшее
[57:51.960 --> 57:53.960]  вычисление. Сабмит это точка,
[57:53.960 --> 57:55.960]  которая связывает Сендор и ресивер
[57:55.960 --> 57:57.960]  и стартует вычисление.
[57:57.960 --> 57:59.960]  Вот можно ли
[57:59.960 --> 58:01.960]  провести аналогию с корутинами здесь?
[58:03.960 --> 58:05.960]  Проводи.
[58:05.960 --> 58:07.960]  Вот ресивер
[58:07.960 --> 58:09.960]  это что?
[58:11.960 --> 58:13.960]  Другие попытки.
[58:15.960 --> 58:17.960]  Ресивер это
[58:17.960 --> 58:19.960]  сама корутина. Вот смотрите,
[58:19.960 --> 58:21.960]  когда мы пишем коэвейт, почему вообще
[58:21.960 --> 58:23.960]  мы пишем коэвейт?
[58:23.960 --> 58:25.960]  Вот допустим, давайте откроем пример,
[58:25.960 --> 58:27.960]  мы пишем коэвейт на фьюче.
[58:27.960 --> 58:29.960]  Что мы имеем в виду? У нас есть
[58:29.960 --> 58:31.960]  фьюча, некоторые синхронные вычисления.
[58:31.960 --> 58:33.960]  Мы хотим корутину остановить,
[58:33.960 --> 58:35.960]  а когда оно завершится, мы хотим корутину
[58:35.960 --> 58:37.960]  возобновить и передать
[58:37.960 --> 58:39.960]  ей значение, которое оказалось
[58:39.960 --> 58:41.960]  во фьюче.
[58:41.960 --> 58:43.960]  Ну вот возобновить
[58:43.960 --> 58:45.960]  корутину и вызвать ресивер
[58:45.960 --> 58:47.960]  с значением v
[58:47.960 --> 58:49.960]  это же что-то очень похоже.
[58:49.960 --> 58:51.960]  Потому что корутина это и есть
[58:51.960 --> 58:53.960]  машинно генерируемый
[58:53.960 --> 58:55.960]  колбэк.
[58:55.960 --> 58:57.960]  Ну правда же.
[58:57.960 --> 58:59.960]  Просто сам
[58:59.960 --> 59:01.960]  компилятор перепишет функцию корутину
[59:01.960 --> 59:03.960]  на объект с вызовом
[59:03.960 --> 59:05.960]  резюм, который по сути является
[59:05.960 --> 59:07.960]  колбэком. Мы вызываем этот резюм,
[59:07.960 --> 59:09.960]  когда операция завершилась.
[59:09.960 --> 59:11.960]  Вот здесь вот,
[59:11.960 --> 59:13.960]  в овейтсаспенде мы подписываемся
[59:13.960 --> 59:15.960]  на фьючу и вызываем
[59:15.960 --> 59:17.960]  здесь резюм.
[59:17.960 --> 59:19.960]  И передаем значение через поле.
[59:19.960 --> 59:21.960]  Ну это же буквально
[59:21.960 --> 59:23.960]  set value на ресивере.
[59:23.960 --> 59:25.960]  Вот я утверждаю, что
[59:25.960 --> 59:27.960]  повернемся сюда, что
[59:27.960 --> 59:29.960]  корутин это ресивер в терминах
[59:29.960 --> 59:31.960]  вот нашего фреймворка.
[59:31.960 --> 59:33.960]  А что такое sender?
[59:33.960 --> 59:35.960]  Сендер это некоторая синхронная операция.
[59:41.960 --> 59:43.960]  На что она похожа в терминах
[59:43.960 --> 59:45.960]  корутин?
[59:45.960 --> 59:47.960]  Вот sender
[59:47.960 --> 59:49.960]  это некоторое вычисление,
[59:49.960 --> 59:51.960]  точнее, я говорю, синхронная операция все время,
[59:51.960 --> 59:53.960]  но в общем случае вычисление.
[59:53.960 --> 59:55.960]  Вот. Это
[59:55.960 --> 59:57.960]  то, чего мы дожидаемся, да?
[59:57.960 --> 59:59.960]  То, чего ресивер дожидается. То, чего дожидается
[59:59.960 --> 01:00:01.960]  корутина. А то, чего дожидается
[01:00:01.960 --> 01:00:03.960]  корутина решает овейтер.
[01:00:05.960 --> 01:00:07.960]  Вот у нас есть некоторое выражение, кое вейт там
[01:00:07.960 --> 01:00:09.960]  что-нибудь, и мы поэтому что-нибудь
[01:00:09.960 --> 01:00:11.960]  строим овейтер, который знает, как дожидаться.
[01:00:11.960 --> 01:00:13.960]  Вот.
[01:00:13.960 --> 01:00:15.960]  Это овейтер.
[01:00:15.960 --> 01:00:17.960]  А что такое submit?
[01:00:17.960 --> 01:00:19.960]  Submit это вот, это операция,
[01:00:19.960 --> 01:00:21.960]  которая стартует вычисление.
[01:00:21.960 --> 01:00:23.960]  Это просто
[01:00:23.960 --> 01:00:25.960]  кое вейт.
[01:00:25.960 --> 01:00:27.960]  Вот кое вейт, он
[01:00:27.960 --> 01:00:29.960]  и вызывает на овейтере овейт
[01:00:29.960 --> 01:00:31.960]  suspend. Когда мы пишем в коде
[01:00:31.960 --> 01:00:33.960]  кое вейт,
[01:00:33.960 --> 01:00:35.960]  вот здесь вот, когда мы доходим
[01:00:35.960 --> 01:00:37.960]  до его исполнения, то комператор
[01:00:37.960 --> 01:00:39.960]  что делает? Он
[01:00:39.960 --> 01:00:41.960]  строит овейтер и
[01:00:41.960 --> 01:00:43.960]  в нем вызывает овейт suspend.
[01:00:43.960 --> 01:00:45.960]  И связывает, смотрите,
[01:00:45.960 --> 01:00:47.960]  сэндера
[01:00:47.960 --> 01:00:49.960]  и ресивера.
[01:00:49.960 --> 01:00:51.960]  То есть, овейтер с
[01:00:51.960 --> 01:00:53.960]  конкретным хэндлом,
[01:00:53.960 --> 01:00:55.960]  который нужно возобновить потом. То есть,
[01:00:55.960 --> 01:00:57.960]  с конкретной корутиной, которую нужно возобновить.
[01:00:57.960 --> 01:00:59.960]  То есть, у нас вот совершенно прямая параллель.
[01:00:59.960 --> 01:01:01.960]  То есть, мы придумали фреймворк, который
[01:01:01.960 --> 01:01:03.960]  более общий, чем корутина,
[01:01:03.960 --> 01:01:05.960]  и в который корутины очень естественно,
[01:01:05.960 --> 01:01:07.960]  очень органично интегрируются.
[01:01:07.960 --> 01:01:09.960]  Поэтому мы сейчас можем сделать что?
[01:01:09.960 --> 01:01:11.960]  Написать совершенно произвольный
[01:01:11.960 --> 01:01:13.960]  написать
[01:01:17.960 --> 01:01:19.960]  овейтер
[01:01:19.960 --> 01:01:21.960]  для совершенно произвольного сэндера.
[01:01:21.960 --> 01:01:23.960]  И корутины смогут дожидаться любого
[01:01:23.960 --> 01:01:25.960]  сэндера. Синхронного,
[01:01:25.960 --> 01:01:27.960]  асинхронного, что угодно. То есть, мы
[01:01:27.960 --> 01:01:29.960]  свяжем одни сущности с другими.
[01:01:29.960 --> 01:01:31.960]  Вот давайте мы сейчас это аккуратно напишем.
[01:01:39.960 --> 01:01:41.960]  Тут
[01:01:41.960 --> 01:01:43.960]  вот еще больше абстрактных слов
[01:01:43.960 --> 01:01:45.960]  стало совсем много, но
[01:01:47.960 --> 01:01:49.960]  ничего не поделать.
[01:02:01.960 --> 01:02:03.960]  Что такое овейтер? Овейтер — это класс,
[01:02:03.960 --> 01:02:05.960]  который реализует протокол овейтера.
[01:02:05.960 --> 01:02:07.960]  Например, овейт, ну, в частности, овейт радио.
[01:02:07.960 --> 01:02:09.960]  Корутина хочет остановиться.
[01:02:09.960 --> 01:02:11.960]  Вот мы говорим, останавливайся.
[01:02:13.960 --> 01:02:15.960]  А когда он останавливается, мы пишем
[01:02:15.960 --> 01:02:17.960]  await suspend,
[01:02:17.960 --> 01:02:19.960]  который получает корутин-хэндл.
[01:02:25.960 --> 01:02:27.960]  И этот овейтер
[01:02:27.960 --> 01:02:29.960]  решает, когда корутину нужно возмновить.
[01:02:29.960 --> 01:02:31.960]  Когда? Когда сэндер вычислит значение.
[01:02:33.960 --> 01:02:35.960]  А когда он вычислит значение?
[01:02:35.960 --> 01:02:37.960]  Ну, то есть, во-первых,
[01:02:37.960 --> 01:02:39.960]  мы должны стартовать это вычисление,
[01:02:39.960 --> 01:02:41.960]  кажется, здесь, да?
[01:02:41.960 --> 01:02:43.960]  А в качестве ресивера мы
[01:02:43.960 --> 01:02:45.960]  передадим что?
[01:02:49.960 --> 01:02:51.960]  В качестве
[01:02:51.960 --> 01:02:53.960]  ресивера... А мы, кстати, не знаем, что
[01:02:53.960 --> 01:02:55.960]  этот сэндер вычисляет, да?
[01:02:55.960 --> 01:02:57.960]  Да, конечно.
[01:03:11.960 --> 01:03:13.960]  Мы бросаем ресиверы,
[01:03:13.960 --> 01:03:15.960]  и этот ресивер, когда вычислится
[01:03:15.960 --> 01:03:17.960]  значение типа T,
[01:03:19.960 --> 01:03:21.960]  мы должны передать его в
[01:03:21.960 --> 01:03:23.960]  корутину. Но мы должны
[01:03:23.960 --> 01:03:25.960]  корутину зарезюмить,
[01:03:25.960 --> 01:03:27.960]  во-первых,
[01:03:27.960 --> 01:03:29.960]  поэтому мы захватили ее хэндл.
[01:03:29.960 --> 01:03:31.960]  А во-вторых, после резюма
[01:03:31.960 --> 01:03:33.960]  она должна вернуть
[01:03:33.960 --> 01:03:35.960]  значение типа T.
[01:03:39.960 --> 01:03:41.960]  As receiver вот здесь.
[01:03:43.960 --> 01:03:45.960]  Вот, но после возобновления мы должны вернуть значение.
[01:03:45.960 --> 01:03:47.960]  Ну, так уж и быть.
[01:03:47.960 --> 01:03:49.960]  Придется его вот в этом классе
[01:03:49.960 --> 01:03:51.960]  запомнить.
[01:03:53.960 --> 01:03:55.960]  Ой, ладно, что я мучаюсь-то?
[01:03:57.960 --> 01:03:59.960]  Буду писать
[01:03:59.960 --> 01:04:01.960]  неаккуратно.
[01:04:03.960 --> 01:04:05.960]  Не делайте так, но вы и сами понимаете,
[01:04:05.960 --> 01:04:07.960]  что так не сделать.
[01:04:07.960 --> 01:04:09.960]  В общем случае.
[01:04:11.960 --> 01:04:13.960]  Вот так вот.
[01:04:13.960 --> 01:04:15.960]  Вот так вот.
[01:04:17.960 --> 01:04:19.960]  Вот так вот.
[01:04:19.960 --> 01:04:21.960]  Вот так вот.
[01:04:21.960 --> 01:04:23.960]  Ну что,
[01:04:23.960 --> 01:04:25.960]  утверждается, что я написал
[01:04:25.960 --> 01:04:27.960]  вот
[01:04:27.960 --> 01:04:29.960]  овейтер для
[01:04:29.960 --> 01:04:31.960]  произвольного сэндера, если вы все еще
[01:04:31.960 --> 01:04:33.960]  с нами, конечно.
[01:04:33.960 --> 01:04:35.960]  И ровно поэтому мне кажется,
[01:04:35.960 --> 01:04:37.960]  что у меня заработал кое овейт для шэдулера
[01:04:37.960 --> 01:04:39.960]  шэдул.
[01:04:41.960 --> 01:04:43.960]  Давайте мы в этом
[01:04:43.960 --> 01:04:45.960]  убедимся.
[01:04:47.960 --> 01:04:49.960]  Нужно что-нибудь вывести?
[01:04:49.960 --> 01:04:51.960]  Где вообще?
[01:04:51.960 --> 01:04:53.960]  Кто все эти люди?
[01:05:07.960 --> 01:05:09.960]  Да, вот работает. Итак, смотрите,
[01:05:09.960 --> 01:05:11.960]  что мы сделали. Мы увидели, что...
[01:05:11.960 --> 01:05:13.960]  Ну, во-первых, чего мы достигли? Мы выдумали
[01:05:13.960 --> 01:05:15.960]  новые сущности, сэндеры,
[01:05:15.960 --> 01:05:17.960]  ресиверы, шэдулеры.
[01:05:17.960 --> 01:05:19.960]  И утверждаем, что любое вычисление
[01:05:19.960 --> 01:05:21.960]  можно выразить с помощью этих сущностей.
[01:05:21.960 --> 01:05:23.960]  Выдумали новый аппетит
[01:05:23.960 --> 01:05:25.960]  Редпула, потому что он должен
[01:05:25.960 --> 01:05:27.960]  иллюстировать эту идею, что
[01:05:27.960 --> 01:05:29.960]  можно выразить все в таком виде.
[01:05:29.960 --> 01:05:31.960]  И мы увидели, что корутины, а вот это
[01:05:31.960 --> 01:05:33.960]  довольно абстрактный, вот
[01:05:33.960 --> 01:05:35.960]  почти что максимально абстрактный способ
[01:05:35.960 --> 01:05:37.960]  описывать вычисления,
[01:05:37.960 --> 01:05:39.960]  асинхронные в первую очередь,
[01:05:39.960 --> 01:05:41.960]  интегрируются с этим фреймворком
[01:05:41.960 --> 01:05:43.960]  очень органично. Мы можем
[01:05:43.960 --> 01:05:45.960]  в корутине дожидаться произвольного
[01:05:45.960 --> 01:05:47.960]  сэндера, потому что сэндер – это произвольное вычисление.
[01:05:47.960 --> 01:05:49.960]  Почему бы и нет?
[01:05:49.960 --> 01:05:51.960]  А ну, давайте, кстати, еще раз
[01:05:51.960 --> 01:05:53.960]  проверим, что все работает. Вот у нас есть
[01:05:53.960 --> 01:05:55.960]  корутина. Давайте мы
[01:05:55.960 --> 01:05:57.960]  еще
[01:05:57.960 --> 01:05:59.960]  напишем вот так.
[01:06:09.960 --> 01:06:11.960]  Почему бы не дождаться
[01:06:11.960 --> 01:06:13.960]  17?
[01:06:13.960 --> 01:06:15.960]  Пустив при этом кучу скрытой механики, да?
[01:06:15.960 --> 01:06:17.960]  Ну вот, замечательно.
[01:06:17.960 --> 01:06:19.960]  Все работает.
[01:06:19.960 --> 01:06:21.960]  А теперь
[01:06:21.960 --> 01:06:23.960]  теперь
[01:06:23.960 --> 01:06:25.960]  мы сделаем еще один шаг
[01:06:27.960 --> 01:06:29.960]  и поймем, как можно придумать
[01:06:29.960 --> 01:06:31.960]  интузивность в планировщиках.
[01:06:31.960 --> 01:06:33.960]  И увидим, что еще в нашем коде есть
[01:06:33.960 --> 01:06:35.960]  неоптимальность. Давайте я сейчас
[01:06:35.960 --> 01:06:37.960]  перееду в
[01:06:37.960 --> 01:06:39.960]  другой файл,
[01:06:39.960 --> 01:06:41.960]  потому что мне нужно избавиться от
[01:06:41.960 --> 01:06:43.960]  некоторого
[01:06:43.960 --> 01:06:45.960]  накопленного кода.
[01:06:47.960 --> 01:06:49.960]  Я хочу
[01:06:51.960 --> 01:06:53.960]  хочу сохранить себе третку.
[01:06:55.960 --> 01:06:57.960]  И я хочу, наверное,
[01:06:57.960 --> 01:06:59.960]  сохранить себе
[01:07:01.960 --> 01:07:03.960]  что бы я еще хотел сохранить.
[01:07:03.960 --> 01:07:05.960]  Зен не хочу.
[01:07:05.960 --> 01:07:07.960]  А я не здесь.
[01:07:11.960 --> 01:07:13.960]  Ну, допустим, я хочу
[01:07:13.960 --> 01:07:15.960]  сохранить корутины пока.
[01:07:21.960 --> 01:07:23.960]  Я хочу сохранить корутины.
[01:07:25.960 --> 01:07:27.960]  И я хочу сохранить
[01:07:31.960 --> 01:07:33.960]  сабмит.
[01:07:37.960 --> 01:07:39.960]  Итак.
[01:07:41.960 --> 01:07:43.960]  Итак.
[01:07:49.960 --> 01:07:51.960]  Мы с вами разделили
[01:07:51.960 --> 01:07:53.960]  два шага
[01:07:55.960 --> 01:07:57.960]  конструирования операции,
[01:07:57.960 --> 01:07:59.960]  планирования асинхронных операций,
[01:07:59.960 --> 01:08:01.960]  планирования шагов,
[01:08:01.960 --> 01:08:03.960]  в виде цепочки, например, этих зенов,
[01:08:03.960 --> 01:08:05.960]  и запуск операции.
[01:08:05.960 --> 01:08:07.960]  И поэтому мы получаем возможность
[01:08:07.960 --> 01:08:09.960]  писать код эффективнее.
[01:08:09.960 --> 01:08:11.960]  Но у нас еще есть некоторая
[01:08:11.960 --> 01:08:13.960]  неэффективность.
[01:08:13.960 --> 01:08:15.960]  Где ее можно увидеть?
[01:08:15.960 --> 01:08:17.960]  Ее можно увидеть,
[01:08:17.960 --> 01:08:19.960]  как бы мне это успеть за 7 минут,
[01:08:19.960 --> 01:08:21.960]  увидеть здесь.
[01:08:21.960 --> 01:08:23.960]  Мы в третпул бросаем, в конце концов,
[01:08:23.960 --> 01:08:25.960]  лямду, которая запускает
[01:08:25.960 --> 01:08:27.960]  на ресивере сетвэлью.
[01:08:27.960 --> 01:08:29.960]  Но лямда это очень неэффективно,
[01:08:29.960 --> 01:08:31.960]  потому что это же аллокация памяти.
[01:08:33.960 --> 01:08:35.960]  Мы оборачиваем произвольную
[01:08:35.960 --> 01:08:37.960]  лямду в std function.
[01:08:37.960 --> 01:08:39.960]  И она не возит.
[01:08:41.960 --> 01:08:43.960]  Ну давайте я попробую это быстро
[01:08:43.960 --> 01:08:45.960]  написать все же.
[01:08:45.960 --> 01:08:47.960]  Что такое std function?
[01:08:47.960 --> 01:08:49.960]  Давайте в третпул напишем чуть более разумным образом.
[01:09:07.960 --> 01:09:09.960]  Где я ошибся?
[01:09:37.960 --> 01:09:39.960]  Ну вот, это уже более разумный третпул.
[01:10:01.960 --> 01:10:03.960]  Да, надо.
[01:10:07.960 --> 01:10:09.960]  Ну вот, перенос кода не состоялся.
[01:10:11.960 --> 01:10:13.960]  И конечно, здесь мы ничего
[01:10:13.960 --> 01:10:15.960]  от императора хорошего не узнаем.
[01:10:19.960 --> 01:10:21.960]  Ну вот, вот, вот.
[01:10:21.960 --> 01:10:23.960]  Вот, вот.
[01:10:23.960 --> 01:10:25.960]  Ну вот, вот.
[01:10:25.960 --> 01:10:27.960]  Ну вот, вот.
[01:10:27.960 --> 01:10:29.960]  Ну вот, вот.
[01:10:29.960 --> 01:10:31.960]  Ну вот, вот.
[01:10:31.960 --> 01:10:33.960]  Ну вот.
[01:10:33.960 --> 01:10:35.960]  Ну вот.
[01:10:35.960 --> 01:10:37.960]  А, ну потому что сейчас
[01:10:37.960 --> 01:10:39.960]  А, ну потому что сейчас
[01:10:39.960 --> 01:10:41.960]  это ерунда просто,
[01:10:41.960 --> 01:10:43.960]  это нужно сценить.
[01:10:49.960 --> 01:10:51.960]  А, я карутины не перенес
[01:10:51.960 --> 01:10:53.960]  еще.
[01:11:05.960 --> 01:11:07.960]  Третпул.
[01:11:11.960 --> 01:11:13.960]  Нет, вот же она.
[01:11:27.960 --> 01:11:29.960]  Я не тот код запускаю просто.
[01:11:35.960 --> 01:11:37.960]  А у нас осталось 5 минут, да?
[01:11:37.960 --> 01:11:39.960]  Мы не успеем ничего.
[01:11:41.960 --> 01:11:43.960]  Ну то есть можно даже не начинать, мне кажется.
[01:11:43.960 --> 01:11:45.960]  Если у нас правда осталось 5 минут,
[01:11:45.960 --> 01:11:47.960]  то мы упустили
[01:11:47.960 --> 01:11:49.960]  самую важную часть лекции.
[01:11:51.960 --> 01:11:53.960]  Что?
[01:11:53.960 --> 01:11:55.960]  Ну, я могу,
[01:11:55.960 --> 01:11:57.960]  но только если,
[01:11:57.960 --> 01:11:59.960]  только если по зуму уже.
[01:11:59.960 --> 01:12:01.960]  Вряд ли мы будем собираться заново.
[01:12:01.960 --> 01:12:03.960]  Вот, ну вот.
[01:12:03.960 --> 01:12:05.960]  Давайте я за 5 минут расскажу,
[01:12:05.960 --> 01:12:07.960]  что мы хотим сделать,
[01:12:07.960 --> 01:12:09.960]  а мы продолжим,
[01:12:09.960 --> 01:12:11.960]  и ты же смонтируешь просто потом
[01:12:11.960 --> 01:12:13.960]  в один файл.
[01:12:13.960 --> 01:12:15.960]  Смотрите, в чем у нас прямо сейчас
[01:12:15.960 --> 01:12:17.960]  есть неоптимальность.
[01:12:17.960 --> 01:12:19.960]  Вот, аккуратно.
[01:12:19.960 --> 01:12:21.960]  Мы действительно построили
[01:12:21.960 --> 01:12:23.960]  общий API.
[01:12:23.960 --> 01:12:25.960]  Мы действительно разделили
[01:12:25.960 --> 01:12:27.960]  два шага планирования операции
[01:12:27.960 --> 01:12:29.960]  и запуск операции.
[01:12:29.960 --> 01:12:31.960]  Но вот если мы пойдем
[01:12:31.960 --> 01:12:33.960]  вглубь всей этой механики
[01:12:33.960 --> 01:12:35.960]  и посмотрим на то,
[01:12:35.960 --> 01:12:37.960]  что делает карутина, когда она пытается
[01:12:37.960 --> 01:12:39.960]  перепланироваться в тредпул,
[01:12:39.960 --> 01:12:41.960]  то она берет сендер
[01:12:41.960 --> 01:12:43.960]  тредпула, который выглядит вот сейчас
[01:12:43.960 --> 01:12:45.960]  вот так вот.
[01:12:45.960 --> 01:12:47.960]  И с помощью
[01:12:47.960 --> 01:12:49.960]  CoAwait
[01:12:49.960 --> 01:12:51.960]  в AwaitSuspend
[01:12:53.960 --> 01:12:55.960]  вызывает на этом сендере Submit,
[01:12:55.960 --> 01:12:57.960]  а сендер для тредпула в методе Submit
[01:12:57.960 --> 01:12:59.960]  вызывает непосредственно уже
[01:12:59.960 --> 01:13:01.960]  Submit в тредпул. И здесь
[01:13:01.960 --> 01:13:03.960]  ресивер, который
[01:13:03.960 --> 01:13:05.960]  резюмит карутина,
[01:13:05.960 --> 01:13:07.960]  отправляется
[01:13:07.960 --> 01:13:09.960]  запакованным в лямбду
[01:13:09.960 --> 01:13:11.960]  в пул поток.
[01:13:11.960 --> 01:13:13.960]  Это неэффективно, потому что
[01:13:13.960 --> 01:13:15.960]  что такое... Давайте про лямбду я как раз успею.
[01:13:15.960 --> 01:13:17.960]  Как это вот работает?
[01:13:17.960 --> 01:13:19.960]  Вот в тредпул бросаются
[01:13:19.960 --> 01:13:21.960]  произвольные лямбды.
[01:13:21.960 --> 01:13:23.960]  Эти произвольные лямбды
[01:13:23.960 --> 01:13:25.960]  это вот какие-то классы какого-то разного размера,
[01:13:25.960 --> 01:13:27.960]  потому что ресиверы это какие-то классы
[01:13:27.960 --> 01:13:29.960]  разного размера, потому что у них какие-то произвольные поля
[01:13:29.960 --> 01:13:31.960]  функторы.
[01:13:31.960 --> 01:13:33.960]  Вот. Так что мы должны положить в
[01:13:33.960 --> 01:13:35.960]  контейнер, вот в частности в дек
[01:13:35.960 --> 01:13:37.960]  задачи
[01:13:37.960 --> 01:13:39.960]  разного размера.
[01:13:39.960 --> 01:13:41.960]  Но контейнеры так не работают, контейнеры гомогенны.
[01:13:41.960 --> 01:13:43.960]  Это должен быть тип некоторого известного размера
[01:13:43.960 --> 01:13:45.960]  size of t.
[01:13:45.960 --> 01:13:47.960]  Поэтому мы должны каким-то образом тип стереть.
[01:13:47.960 --> 01:13:49.960]  Поэтому мы пишем класс
[01:13:49.960 --> 01:13:51.960]  task,
[01:13:51.960 --> 01:13:53.960]  который как устроен? Ну вот...
[01:13:53.960 --> 01:13:55.960]  Давайте
[01:13:55.960 --> 01:13:57.960]  это фанкшн. Фанкшн, который
[01:13:57.960 --> 01:13:59.960]  без
[01:13:59.960 --> 01:14:01.960]  аргументов и без
[01:14:01.960 --> 01:14:03.960]  возвращаемого значения.
[01:14:03.960 --> 01:14:05.960]  И этот фанкшн
[01:14:13.960 --> 01:14:15.960]  получает в конструкторе, ну почему
[01:14:15.960 --> 01:14:17.960]  f?
[01:14:17.960 --> 01:14:19.960]  Получает f. Ну я вот грубо копировать
[01:14:19.960 --> 01:14:21.960]  буду, неважно. Вот. И я хочу сделать
[01:14:21.960 --> 01:14:23.960]  этот фанкшн, который бы имел
[01:14:23.960 --> 01:14:25.960]  такой предсказуемый размер.
[01:14:25.960 --> 01:14:27.960]  Непроизвольный. Каким образом я могу
[01:14:27.960 --> 01:14:29.960]  этого достичь? Но видимо, я не могу хранить
[01:14:29.960 --> 01:14:31.960]  в полях фанкшна сам f.
[01:14:31.960 --> 01:14:33.960]  Но я могу переместить его на кучу.
[01:14:33.960 --> 01:14:35.960]  И хранить на кучу уже.
[01:14:53.960 --> 01:14:55.960]  Да?
[01:14:55.960 --> 01:14:57.960]  И дальше я мог бы сохранить
[01:14:57.960 --> 01:14:59.960]  в полях
[01:14:59.960 --> 01:15:01.960]  что?
[01:15:01.960 --> 01:15:03.960]  Ну как будто бы function
[01:15:03.960 --> 01:15:05.960]  storage
[01:15:05.960 --> 01:15:07.960]  f звездочка, да?
[01:15:07.960 --> 01:15:09.960]  И вот вызывать
[01:15:09.960 --> 01:15:11.960]  все это.
[01:15:11.960 --> 01:15:13.960]  В операторе круглые скобочки.
[01:15:17.960 --> 01:15:19.960]  Ну вот не знаю, что...
[01:15:19.960 --> 01:15:21.960]  Напишем что-нибудь.
[01:15:21.960 --> 01:15:23.960]  Вот так не получится. Почему?
[01:15:23.960 --> 01:15:25.960]  Потому что я же не могу хранить pointer
[01:15:25.960 --> 01:15:27.960]  на класс
[01:15:27.960 --> 01:15:29.960]  какой-то конкретный шаблон. Я не знаю,
[01:15:29.960 --> 01:15:31.960]  здесь f заранее.
[01:15:31.960 --> 01:15:33.960]  Понимаете проблемы, да?
[01:15:33.960 --> 01:15:35.960]  Вот. То есть внутри
[01:15:35.960 --> 01:15:37.960]  function, внутри std function,
[01:15:37.960 --> 01:15:39.960]  внутри нашего function
[01:15:39.960 --> 01:15:41.960]  должен быть
[01:15:41.960 --> 01:15:43.960]  pointer на класс, который хранит
[01:15:43.960 --> 01:15:45.960]  функцию. И умеет ее вызывать.
[01:15:45.960 --> 01:15:47.960]  Произвольный фанкшн умеет его вызывать.
[01:15:47.960 --> 01:15:49.960]  И этот класс
[01:15:49.960 --> 01:15:51.960]  конкретный в данном
[01:15:51.960 --> 01:15:53.960]  каждый раз имеет
[01:15:53.960 --> 01:15:55.960]  некоторый свой тип,
[01:15:55.960 --> 01:15:57.960]  зависящий от типа лямбда.
[01:15:57.960 --> 01:15:59.960]  От типа функторов, которые в него попало.
[01:15:59.960 --> 01:16:01.960]  Но я знаю, что у всех
[01:16:01.960 --> 01:16:03.960]  этих функторов есть в конце концов
[01:16:03.960 --> 01:16:05.960]  операторы круглые скобочки.
[01:16:05.960 --> 01:16:07.960]  И мне нужно с ними работать как-то полиморфно.
[01:16:07.960 --> 01:16:09.960]  Ну как я эту проблему решаю?
[01:16:09.960 --> 01:16:11.960]  Я завожу интерфейс.
[01:16:17.960 --> 01:16:19.960]  И переставляю местами.
[01:16:25.960 --> 01:16:27.960]  Наследуюсь от этого интерфейса.
[01:16:27.960 --> 01:16:29.960]  Здесь реализую.
[01:16:35.960 --> 01:16:37.960]  И уже в поле храню
[01:16:37.960 --> 01:16:39.960]  просто pointer на интерфейс.
[01:16:39.960 --> 01:16:41.960]  Это называется TypeRaiser.
[01:16:41.960 --> 01:16:43.960]  И вот здесь
[01:16:43.960 --> 01:16:45.960]  у меня есть
[01:16:45.960 --> 01:16:47.960]  это называется TypeRaiser.
[01:16:51.960 --> 01:16:53.960]  А здесь
[01:16:55.960 --> 01:16:57.960]  ну зачем так писать?
[01:17:09.960 --> 01:17:11.960]  Похоже на правду?
[01:17:11.960 --> 01:17:13.960]  Вот еще буквально минутку
[01:17:13.960 --> 01:17:15.960]  и мы распустимся.
[01:17:33.960 --> 01:17:35.960]  Если конечно все заработает.
[01:17:43.960 --> 01:17:45.960]  Так, и где же я?
[01:18:13.960 --> 01:18:15.960]  А, ну господи.
[01:18:15.960 --> 01:18:17.960]  А, ну господи.
[01:18:33.960 --> 01:18:35.960]  Я же наследуюсь.
[01:18:45.960 --> 01:18:47.960]  Вот.
[01:18:47.960 --> 01:18:49.960]  К чему я?
[01:18:49.960 --> 01:18:51.960]  К тому, что вот так в конце концов
[01:18:51.960 --> 01:18:53.960]  реализована steady function,
[01:18:53.960 --> 01:18:55.960]  который таз, который мы храним в тредпуле.
[01:18:55.960 --> 01:18:57.960]  И когда мы бросаем корутины,
[01:18:57.960 --> 01:18:59.960]  которые уже динамически алоцированы
[01:18:59.960 --> 01:19:01.960]  на куче, мы все равно
[01:19:01.960 --> 01:19:03.960]  оборачиваем эти
[01:19:03.960 --> 01:19:05.960]  ресиверы, которые
[01:19:05.960 --> 01:19:07.960]  оборачиваем лямбды,
[01:19:07.960 --> 01:19:09.960]  в которых лежат ресиверы, которые
[01:19:09.960 --> 01:19:11.960]  соответствуют корутинам, вот в такие
[01:19:11.960 --> 01:19:13.960]  вот объекты, которые
[01:19:13.960 --> 01:19:15.960]  мы алоцируем на куче. И вот у нас есть этот
[01:19:15.960 --> 01:19:17.960]  new. И вот этот new он
[01:19:17.960 --> 01:19:19.960]  неестественный для нашего
[01:19:19.960 --> 01:19:21.960]  приложения. Мы уже знаем, что
[01:19:21.960 --> 01:19:23.960]  экзекьюторы, экзекьюторам
[01:19:23.960 --> 01:19:25.960]  не нужны эти динамические аллокации.
[01:19:25.960 --> 01:19:27.960]  Вот, видимо,
[01:19:27.960 --> 01:19:29.960]  пока наш фреймворк не совершенен,
[01:19:29.960 --> 01:19:31.960]  потому что он не позволяет этих динамических
[01:19:31.960 --> 01:19:33.960]  аллокаций для корутины сбавиться.
[01:19:33.960 --> 01:19:35.960]  В очередной задаче про корутины
[01:19:35.960 --> 01:19:37.960]  вас просят напишите, пожалуйста,
[01:19:37.960 --> 01:19:39.960]  вот эти самые корутины так, чтобы
[01:19:39.960 --> 01:19:41.960]  никаких аллокаций при планировании
[01:19:41.960 --> 01:19:43.960]  не было, чтобы мы получали как раз вот
[01:19:43.960 --> 01:19:45.960]  эту вот интрузивность. А здесь
[01:19:45.960 --> 01:19:47.960]  в нашем фреймворке мы пока ее потеряли.
[01:19:47.960 --> 01:19:49.960]  Вот, видимо, наш фреймворк все еще не
[01:19:49.960 --> 01:19:51.960]  совершенен, и нам нужно ввести еще
[01:19:51.960 --> 01:19:53.960]  что-то, ну, еще что-то атомизировать,
[01:19:53.960 --> 01:19:55.960]  и тогда мы избавимся от этого new
[01:19:55.960 --> 01:19:57.960]  дека-рутина и станет вот совсем оптимально.
[01:19:57.960 --> 01:19:59.960]  И вот в этом месте мы остановимся.
[01:19:59.960 --> 01:20:01.960]  Ну, а пока остановимся сейчас,
[01:20:01.960 --> 01:20:03.960]  сделаем это завтра. Спасибо
[01:20:03.960 --> 01:20:05.960]  за внимание.
[01:20:05.960 --> 01:20:07.960]  Меня зовут Рома Липовский, чтобы вы помнили.
[01:20:07.960 --> 01:20:09.960]  Мы сегодня
[01:20:09.960 --> 01:20:11.960]  продолжаем разговор про то,
[01:20:11.960 --> 01:20:13.960]  как можно описывать
[01:20:13.960 --> 01:20:15.960]  какие-то асинхронные задачи
[01:20:15.960 --> 01:20:17.960]  или вычисления в более широком
[01:20:17.960 --> 01:20:19.960]  смысле, как можно
[01:20:19.960 --> 01:20:21.960]  более абстрактно, как можно более универсально.
[01:20:21.960 --> 01:20:23.960]  В начале прошлой
[01:20:23.960 --> 01:20:25.960]  лекции...
[01:20:25.960 --> 01:20:27.960]  Так, будет тяжело.
[01:20:27.960 --> 01:20:29.960]  В начале
[01:20:29.960 --> 01:20:31.960]  вчерашней субботней лекции мы с вами
[01:20:31.960 --> 01:20:33.960]  говорили, что, в общем-то, корутины претендуют
[01:20:33.960 --> 01:20:35.960]  на некоторую универсальность, что корутины могут быть
[01:20:35.960 --> 01:20:37.960]  такими вот универсальными асинхронными
[01:20:37.960 --> 01:20:39.960]  задачами, которые могут императивно
[01:20:39.960 --> 01:20:41.960]  друг другу взаимодействовать, которые
[01:20:41.960 --> 01:20:43.960]  можно функционально комбинировать,
[01:20:43.960 --> 01:20:45.960]  потому что у нас есть представление
[01:20:45.960 --> 01:20:47.960]  для еще не стартовавшей задачи.
[01:20:47.960 --> 01:20:49.960]  Это объект TaskT, такая
[01:20:49.960 --> 01:20:51.960]  ленивая фьюча.
[01:20:51.960 --> 01:20:53.960]  Но мы дальше заметили, что
[01:20:53.960 --> 01:20:55.960]  даже вот с таким инструментом
[01:20:55.960 --> 01:20:57.960]  мы можем еще более
[01:20:57.960 --> 01:20:59.960]  абстрагировать природу наших задач.
[01:20:59.960 --> 01:21:01.960]  Мы можем еще больше
[01:21:01.960 --> 01:21:03.960]  обобщить понятия,
[01:21:03.960 --> 01:21:05.960]  с которыми мы работаем,
[01:21:05.960 --> 01:21:07.960]  показаться даже от корутин,
[01:21:07.960 --> 01:21:09.960]  а говорить уже просто про произвольные
[01:21:09.960 --> 01:21:11.960]  ленивые вычисления, которые
[01:21:11.960 --> 01:21:13.960]  в нашем случае представлялись
[01:21:13.960 --> 01:21:15.960]  в виде
[01:21:15.960 --> 01:21:17.960]  пары сендеров
[01:21:17.960 --> 01:21:19.960]  и ресиверов. Но вернее как,
[01:21:19.960 --> 01:21:21.960]  мы сказали, что давайте представлять
[01:21:21.960 --> 01:21:23.960]  вычисления в виде сендеров.
[01:21:23.960 --> 01:21:25.960]  Сендер — это некоторое вычисление, которое
[01:21:25.960 --> 01:21:27.960]  вот уже представлено
[01:21:27.960 --> 01:21:29.960]  в виде какого-то объекта,
[01:21:29.960 --> 01:21:31.960]  которое вычисляет некоторое значение
[01:21:31.960 --> 01:21:33.960]  некоторого типа, но
[01:21:33.960 --> 01:21:35.960]  это вычисление еще не стартовало.
[01:21:35.960 --> 01:21:37.960]  А для того, чтобы этому вычислению
[01:21:37.960 --> 01:21:39.960]  стартовать, нам нужен объект Receiver.
[01:21:39.960 --> 01:21:41.960]  Receiver — это callback, который
[01:21:41.960 --> 01:21:43.960]  готов принять результат
[01:21:43.960 --> 01:21:45.960]  вычисления, который вычисляет
[01:21:45.960 --> 01:21:47.960]  этот самый сендер. Давайте посмотрим
[01:21:47.960 --> 01:21:49.960]  на код, который мы вчера писали.
[01:21:49.960 --> 01:21:51.960]  У нас были такие
[01:21:51.960 --> 01:21:53.960]  очень компактные концепты
[01:21:53.960 --> 01:21:55.960]  Receiver и сендера.
[01:21:55.960 --> 01:21:57.960]  Receiver принимал либо значение
[01:21:57.960 --> 01:21:59.960]  вычисленное, либо ошибку,
[01:21:59.960 --> 01:22:01.960]  либо сигнал об отмене
[01:22:01.960 --> 01:22:03.960]  вычисления, а вычисление
[01:22:03.960 --> 01:22:05.960]  стартовало, когда
[01:22:05.960 --> 01:22:07.960]  ему подавали на вход сендер.
[01:22:07.960 --> 01:22:09.960]  Ну и у нас была такая общая
[01:22:09.960 --> 01:22:11.960]  операция, которая стартует вычисление,
[01:22:11.960 --> 01:22:13.960]  которая называлась Submit,
[01:22:13.960 --> 01:22:15.960]  которая вызывала Submit
[01:22:15.960 --> 01:22:17.960]  на сендере от Receiver.
[01:22:17.960 --> 01:22:19.960]  Ну и в случае ThreadPool
[01:22:19.960 --> 01:22:21.960]  Submit был довольно естественным.
[01:22:21.960 --> 01:22:23.960]  Давайте мы его найдем.
[01:22:23.960 --> 01:22:25.960]  Так мы его не найдем, конечно.
[01:22:25.960 --> 01:22:27.960]  В случае Pool подоков, который мог бы
[01:22:27.960 --> 01:22:29.960]  строить сендеры через специальный объект
[01:22:29.960 --> 01:22:31.960]  сэндер-долвер, метод Submit
[01:22:31.960 --> 01:22:33.960]  у сендера ThreadPool просто вызывал
[01:22:33.960 --> 01:22:35.960]  ThreadPool Submit. Ну вот так можно
[01:22:35.960 --> 01:22:37.960]  объяснить себе, почему такое название.
[01:22:37.960 --> 01:22:39.960]  Мы стартуем некоторые вычисления.
[01:22:39.960 --> 01:22:41.960]  А дальше мы с помощью двух тех понятий
[01:22:41.960 --> 01:22:43.960]  пытались выразить произвольные
[01:22:43.960 --> 01:22:45.960]  синхронные и асинхронные вычисления.
[01:22:45.960 --> 01:22:47.960]  Мы начали с
[01:22:47.960 --> 01:22:49.960]  синхронного вычисления,
[01:22:49.960 --> 01:22:51.960]  мы построили sender.just, который
[01:22:51.960 --> 01:22:53.960]  просто вычисляет синхронное
[01:22:53.960 --> 01:22:55.960]  данное значение,
[01:22:55.960 --> 01:22:57.960]  вызывали Submit на этом сендере
[01:22:57.960 --> 01:22:59.960]  и этот Submit привел к тому,
[01:22:59.960 --> 01:23:01.960]  что просто на экране сразу
[01:23:01.960 --> 01:23:03.960]  печаталось вычисленное значение
[01:23:03.960 --> 01:23:05.960]  в этом кулбеке.
[01:23:05.960 --> 01:23:07.960]  Дальше мы написали
[01:23:07.960 --> 01:23:09.960]  другой ресивер, который называл
[01:23:09.960 --> 01:23:11.960]  другой сендер, который назывался NewThread
[01:23:11.960 --> 01:23:13.960]  и он уже был менее интуитивен,
[01:23:13.960 --> 01:23:15.960]  потому что он
[01:23:15.960 --> 01:23:17.960]  вычислял что-то асинхронно,
[01:23:17.960 --> 01:23:19.960]  но вычислял не какое-то значение,
[01:23:19.960 --> 01:23:21.960]  привычное нам, вычислял значение
[01:23:21.960 --> 01:23:23.960]  типа Unit, то есть фактически
[01:23:23.960 --> 01:23:25.960]  ничего не вычислял, зато асинхронно.
[01:23:25.960 --> 01:23:27.960]  То есть он асинхронно запускал
[01:23:27.960 --> 01:23:29.960]  ресивер кулбек
[01:23:29.960 --> 01:23:31.960]  в новом потоке.
[01:23:31.960 --> 01:23:33.960]  А потом мы подумали, зачем нам запускать
[01:23:33.960 --> 01:23:35.960]  новые потоки на каждое вычисление,
[01:23:35.960 --> 01:23:37.960]  у нас же есть пул потоков и сказали,
[01:23:37.960 --> 01:23:39.960]  что давайте теперь пул потоков
[01:23:39.960 --> 01:23:41.960]  будет строить нам сендеры, которые будут
[01:23:41.960 --> 01:23:43.960]  асинхронно вычислять
[01:23:43.960 --> 01:23:45.960]  юниты в
[01:23:45.960 --> 01:23:47.960]  потоках ворковых.
[01:23:49.960 --> 01:23:51.960]  Но для того, чтобы эти сендеры строить,
[01:23:51.960 --> 01:23:53.960]  мы ввели еще вспомогательную сущность,
[01:23:53.960 --> 01:23:55.960]  которая называлась планировщик.
[01:23:55.960 --> 01:23:57.960]  Вот по Threadpool строили планировщик
[01:23:57.960 --> 01:23:59.960]  и планировщик в методе Shadow
[01:23:59.960 --> 01:24:01.960]  строил сендер, которому
[01:24:01.960 --> 01:24:03.960]  можно было потом с помощью Submit
[01:24:03.960 --> 01:24:05.960]  прицепить ресивер и стартовать
[01:24:05.960 --> 01:24:07.960]  асинхронные вычисления, то есть фактически
[01:24:07.960 --> 01:24:09.960]  здесь внутри Submit положить задачу
[01:24:09.960 --> 01:24:11.960]  в Threadpool.
[01:24:11.960 --> 01:24:13.960]  Какая нам польза была
[01:24:13.960 --> 01:24:15.960]  от всего этого?
[01:24:15.960 --> 01:24:17.960]  Польза состояла в том, что наши вычисления
[01:24:17.960 --> 01:24:19.960]  теперь ленивые, но
[01:24:19.960 --> 01:24:21.960]  и до своего запуска они имеют
[01:24:21.960 --> 01:24:23.960]  некоторое физическое представление
[01:24:23.960 --> 01:24:25.960]  в нашей программе. Есть некоторый объект
[01:24:25.960 --> 01:24:27.960]  Sender, который представляет это вычисление,
[01:24:27.960 --> 01:24:29.960]  который вычисляет некоторые типизированные значения,
[01:24:29.960 --> 01:24:31.960]  и за счет того, что у нас есть
[01:24:31.960 --> 01:24:33.960]  представление этого объекта, а операция еще не началась,
[01:24:33.960 --> 01:24:35.960]  мы можем к этому объекту
[01:24:35.960 --> 01:24:37.960]  прицепить какие-то дальнейшие шаги,
[01:24:37.960 --> 01:24:39.960]  то есть планировать более сложные вычисления
[01:24:39.960 --> 01:24:41.960]  с помощью
[01:24:41.960 --> 01:24:43.960]  комбинатора, который называется Zen,
[01:24:43.960 --> 01:24:45.960]  который получает одно вычисление,
[01:24:45.960 --> 01:24:47.960]  получает функцию, которая хочет
[01:24:47.960 --> 01:24:49.960]  к этому вычислению прицепиться
[01:24:49.960 --> 01:24:56.240]  сделать последний шаг, получить результат предыдущего вычисления и
[01:24:56.240 --> 01:25:01.920]  трансформировать его с помощью вот этой функции. И мы можем с помощью Zen
[01:25:01.920 --> 01:25:06.880]  получить вот sender функцию и построить новый sender, который
[01:25:06.880 --> 01:25:10.160]  выполняет уже более длинную цепочку,
[01:25:10.160 --> 01:25:13.720]  вернее представляет более длинную цепочку вычисления.
[01:25:13.720 --> 01:25:19.000]  Мы какую-то мелочь, кажется, здесь не сделали, мы не написали здесь простой
[01:25:19.000 --> 01:25:23.840]  сахар, который, конечно, хочется иметь.
[01:25:23.840 --> 01:25:51.360]  И вот этот пример можно было бы написать, наверное, посимпатичнее, потому что
[01:25:51.360 --> 01:26:03.840]  зачем нам все эти промежуточные объекты? Мы сначала планируем вычисление, которое
[01:26:03.840 --> 01:26:10.840]  ассинхронно в потоке пулопотоков вычисляет юнит, а потом мы к нему цепляем
[01:26:10.840 --> 01:26:24.920]  продолжение. А потом мы делаем еще один шаг.
[01:26:40.920 --> 01:26:46.520]  Ну вот и так мы декларативно описали вычисление, которое еще не стартовало и
[01:26:46.520 --> 01:26:54.080]  стартует оно вот здесь. Напомню, что выиграли мы то, что мы разделили, ну давайте из
[01:26:54.080 --> 01:26:58.160]  далека, с чем мы вообще начинали в прошлый раз. Мы начинали вот с такого
[01:26:58.160 --> 01:27:02.320]  примера, где у нас была некоторая функция, какое-то ассинхронное вычисление,
[01:27:02.320 --> 01:27:08.840]  которое мы вызывали, оно возвращало фьючу и одновременно с этим планировало
[01:27:08.840 --> 01:27:13.560]  задачу в пул потоков, а потом мы подписывались на результаты этого вычисления.
[01:27:13.560 --> 01:27:19.240]  Проблема с этим кодом состояла в том, что у нас уже есть фьюча, когда
[01:27:19.240 --> 01:27:23.760]  вычисление стартовало, и когда мы подписываемся на результат этой фьючи, то
[01:27:23.760 --> 01:27:29.680]  возникает уже гонка с продюсером, который в пуле потоков вычисляет значение. То есть
[01:27:29.680 --> 01:27:35.280]  имея фьючу, фьючу существует тогда, когда вычисление уже стартовало, и поэтому,
[01:27:35.280 --> 01:27:38.560]  когда мы планируем продолжение, когда мы ассинхронно потребляем результат этой
[01:27:38.560 --> 01:27:42.160]  фьючи, то у нас возникает такая естественная гонка между продюсером и
[01:27:42.160 --> 01:27:46.080]  консьюером, и нам нужна синхронизация, нам нужна динамическая локация, нам
[01:27:46.080 --> 01:27:50.240]  нужен подсчет ссылок. Вот много разного оверхеда, который нам не требуется, если
[01:27:50.240 --> 01:27:55.400]  мы разделяем старт операции, то есть планирование задачи в тредпул, и
[01:27:55.400 --> 01:27:59.760]  конструирование некоторого представления для результата этой операции. Вот здесь
[01:27:59.760 --> 01:28:06.160]  два этих шага они скрыты вместе, а мы их вот в этом коде разделили. Мы сначала
[01:28:06.160 --> 01:28:10.240]  получаем представление для будущего результата, потом подписываемся на него,
[01:28:10.240 --> 01:28:14.320]  ну вот таким вот замысловатым образом в конце концов, и только в конце стартуем
[01:28:14.320 --> 01:28:18.320]  операцию, то есть вот здесь вот происходит сабмит задачи в тредпул, и собственно
[01:28:18.320 --> 01:28:25.360]  начинается вычисление. Вот это первый выигрыш, который мы получаем от
[01:28:25.360 --> 01:28:30.480]  использования наших новых концепций, то есть от нашего нового словаря, который
[01:28:30.480 --> 01:28:37.080]  мы ввели для описания вычислений. Следующий эффект, который у нас получилось,
[01:28:37.080 --> 01:28:41.960]  это то, что пул потоков изменил свой API. Вот вроде бы ничего проще, чем пул
[01:28:41.960 --> 01:28:46.840]  потоков на свете не бывает, но тем не менее в нашем пуле потоков у нас нет
[01:28:46.840 --> 01:28:52.480]  метода сабмита, наверное он где-то под капотом, разумеется, есть, но в нашем пуле
[01:28:52.480 --> 01:29:01.880]  он приватный, и наружу торчит только метод getShaddler, который строит
[01:29:01.880 --> 01:29:06.080]  планировщик, который в единственной своей операции shadow без аргументов
[01:29:06.080 --> 01:29:10.680]  строит sender, который ассинхронно вычисляет юнит, и который в методе
[01:29:10.680 --> 01:29:16.400]  сабмит, связывая, получая ресивер, отправляет уже в тредпул задачу, которая
[01:29:16.400 --> 01:29:23.600]  отправляет значение ресиверу. Вот такая сложная история.
[01:29:23.600 --> 01:29:28.960]  Ну, кстати, легко представить, кто будет звать setDone, то есть отмену операции,
[01:29:28.960 --> 01:29:33.320]  то есть если, скажем, на пуле потоков позовут stop и операция отменится, то пул
[01:29:33.320 --> 01:29:38.440]  потоков может на ресивере позвать в конце концов setDone, но здесь немного
[01:29:38.440 --> 01:29:44.760]  сложнее будет. Окей, значит, мы с этим пока вроде бы разобрались, да, то есть мы
[01:29:44.760 --> 01:29:48.960]  понимаем, что мы делаем, мы понимаем, кажется, зачем мы делаем. Дальше, мы сказали,
[01:29:48.960 --> 01:29:55.360]  что, ну, а как же так? У нас были уже довольно универсальные задачи в виде
[01:29:55.360 --> 01:30:04.000]  корутин. Давайте я покажу. Вот, а нет, сейчас я не покажу, это другая ветка. У нас
[01:30:04.000 --> 01:30:10.720]  были довольно универсальные задачи в виде корутин, а мы почему-то переключились
[01:30:10.720 --> 01:30:15.400]  на другой язык, на другие сущности для описания вычислений. Почему бы не вернуться
[01:30:15.400 --> 01:30:21.280]  к корутинам? Ну, оказывается, что это вполне можно сделать и интегрировать корутины в
[01:30:21.280 --> 01:30:27.280]  этот фреймворк с эндерами и ресиверами. Можно заметить следующее, что вот пусть у нас есть
[01:30:27.280 --> 01:30:32.920]  какая-то корутина, которая чего-то дожидается. Ну, вот корутина, в которой написано co-await.
[01:30:32.920 --> 01:30:37.880]  Давайте такую корутину найдем. У нас их должно быть изрядно.
[01:30:37.880 --> 01:30:46.840]  Ну, с таймером это менее интересно, потому что таймер ничего не вычисляет.
[01:30:46.840 --> 01:30:55.800]  Давайте, наверное, посмотрим здесь. Да, вот у нас корутина, которая синхронно дожидается в
[01:30:55.800 --> 01:31:04.960]  фьюче. Ну, неважно, чего она дожидается. Важно, что есть некоторая синхронная операция. В данном
[01:31:04.960 --> 01:31:08.680]  случае, это композиция двух синхронных вычислений. Есть помощь у комбинатора first of,
[01:31:08.680 --> 01:31:12.760]  который вычисляет первое из двух, который возвращает результат первого из двух
[01:31:12.760 --> 01:31:21.640]  вычислений. И мы хотим остановить корутину до тех пор, пока за этой фьючей first of не
[01:31:21.640 --> 01:31:26.320]  появится некоторое значение. И вот тогда корутину возобновить и значение использовать.
[01:31:26.320 --> 01:31:33.880]  Ну, то есть корутина останавливается и хочет быть запущена тогда, когда появится значение. Она
[01:31:33.880 --> 01:31:41.840]  хочет потребить это будущее еще не вычисленное значение. В этом смысле она для нас вполне
[01:31:41.840 --> 01:31:52.360]  вписывается в сущность какую? В сущность ресивера. Корутина это ресивер. То есть это колбэк,
[01:31:52.360 --> 01:31:58.760]  который потребляет значения. Ну, вот когда мы писали с вами фьючи, то вот буквально корутины
[01:31:58.760 --> 01:32:07.160]  и были и были колбэками. Вот можно посмотреть на этот код. Мы подписывались на фьючу и в обработчике,
[01:32:07.160 --> 01:32:13.800]  в колбэке фьюче мы возобновляли корутину, которая потом потребляла вычисленный результат,
[01:32:13.800 --> 01:32:20.160]  возвращала его через await resume. Ну, это у нас такой рукописанный код для корутин,
[01:32:20.160 --> 01:32:27.880]  но вы, надеюсь, понимаете как он выглядит на C++, но в любом случае в домашней вы его напишете. То есть
[01:32:27.880 --> 01:32:38.640]  корутина вполне пока вписывается в нашу сущность. Это, секундочку, это не что иное как ресивер.
[01:32:38.640 --> 01:32:47.160]  Ну, в принципе остальные сущности для корутины тоже вписываются, потому что смотрите, вот что
[01:32:47.160 --> 01:32:54.680]  такое coawait? Когда мы пишем coawait, во что он разворачивается? Coawait разворачивается вот в такой
[01:32:54.680 --> 01:33:01.000]  код. Мы строим объект awaiter, который знает, как дождаться результата асинхронной операции,
[01:33:01.000 --> 01:33:10.360]  и мы, в смысле компиратор, генерируем такой вот вызов. Мы на awaiter вызываем await suspend и
[01:33:10.360 --> 01:33:17.440]  передаем туда корутину. Вот этот awaiter, он знает про вычисление, про то, как значение вычислить,
[01:33:17.440 --> 01:33:28.200]  и он планирует возобновление корутины, получает callback и фактически планирует его запуск. То есть
[01:33:28.200 --> 01:33:35.520]  у нас есть здесь слева некоторое вычисление, объект, который знает про вычисление и про то,
[01:33:35.520 --> 01:33:41.880]  как его дождаться. Справа у нас есть callback, который хочет, простите, потребить результаты
[01:33:41.880 --> 01:33:46.880]  этого вычисления, и у нас есть операция await suspend, которая одно с другим связывает. Ну,
[01:33:46.920 --> 01:33:54.480]  опять, это все удивительно похоже на те сущности, которые у нас есть. Тут параллель не совсем прямая,
[01:33:54.480 --> 01:34:01.240]  но есть некоторые нюансы, за которые можно зацепиться. Но все же, я бы провел такую параллель,
[01:34:01.240 --> 01:34:06.960]  что awaiter в данном случае похож на sender, а submit очень похож на await suspend, который происходит
[01:34:06.960 --> 01:34:16.840]  внутри коя await, и он вот связывает асинхронную операцию и callback корутину. Также как submit
[01:34:16.840 --> 01:34:23.160]  связывает sender, вычисление и receiver, callback, который ждет результаты этого вычисления.
[01:34:23.160 --> 01:34:29.120]  Ну а раз можно провести такую параллель, значит, можно переложить, значит, можно интегрировать
[01:34:29.120 --> 01:34:36.920]  корутины и sender и receiver, а именно можно реализовать оператор коя await для абсолютно
[01:34:36.920 --> 01:34:44.160]  произвольного sender. Ну раз sender вычисляет значения, а корутина умеет дождаться значений,
[01:34:44.160 --> 01:34:51.280]  то почему бы корутине не научиться дожидаться произвольного sender? Когда мы пишем коя await от
[01:34:51.280 --> 01:35:02.760]  sender, то оператор коя await строит объект sender awaiter, который в методе await suspend, получая корутину,
[01:35:02.760 --> 01:35:08.400]  вызывает на sender submit, то есть говорит ему, что вот вычисление стартует теперь, когда корутина
[01:35:08.400 --> 01:35:14.920]  решила его дождаться. И в качестве callback, в качестве receiver передает такой вот вспомогательный
[01:35:14.920 --> 01:35:25.640]  callback, который в методе set value вызывает корутин handle resume. И вот корутина receiver, получив значение,
[01:35:25.640 --> 01:35:31.040]  возобновляет корутину, которая этого значения дожидалась, ну и через await resume возвращает его
[01:35:31.040 --> 01:35:38.640]  из оператора коя await. Вот пример, как корутина интегрируется с двумя sender. Это планировщик
[01:35:38.640 --> 01:35:46.160]  пула, и мы вызываем на нем shadow, и планировщик пула про корутину ничего не знает. И мы здесь
[01:35:46.160 --> 01:35:52.200]  синхронно вычисляем 17, но в этом смысле, конечно, мало, мы просто иллюстрируем, что коя await
[01:35:52.200 --> 01:35:58.040]  интегрируется с произвольным sender, неважно, синхронный он или синхронный. Вот threadpool здесь,
[01:35:58.040 --> 01:36:03.080]  это очень важно. Мы не требуем никакого знания про корутины. Ему это не нужно знать, потому что
[01:36:03.080 --> 01:36:12.480]  связь происходит вот в этом месте, когда мы поддерживаем коя await. Мы с вами интегрировали
[01:36:12.480 --> 01:36:19.240]  корутины и sender-ресиверы, что, видимо, говорит о том, что подход, который мы сейчас рассматриваем
[01:36:19.240 --> 01:36:25.560]  универсальный. Мы уже получили пользу от sender-ресиверов, потому что мы получили
[01:36:25.560 --> 01:36:35.280]  возможность лениво планировать вычисления. Где это мы делали? Вот здесь вот. И все это говорит в
[01:36:35.280 --> 01:36:42.480]  пользу нашего дизайна, но пока есть момент, который мы до конца не разработали. А именно, у нас есть
[01:36:42.480 --> 01:36:50.760]  все же в этом дизайне overhead. Overhead, который состоит в том, что мы выполняем все еще... Смотрите,
[01:36:50.760 --> 01:36:57.880]  когда мы приходили к ленивости sender-ов, мы рассуждали как. Что вот с кодис фьючами у нас
[01:36:57.880 --> 01:37:05.120]  асинкве выполняет сразу два шага. Он и работу в threadpool планирует, и фьюч строит. И в итоге
[01:37:05.120 --> 01:37:09.840]  два этих шага они слиты вместе, и из этого возникает гонка, что подписываясь на фьючи,
[01:37:09.840 --> 01:37:17.480]  мы уже конкурируем с продюсером. Мы разделили два этих шага, то есть построение фьючи, вернее
[01:37:17.480 --> 01:37:26.600]  sender-а, и submit, который запускает вычисления. Но у нас внутри асинкве есть, на самом деле,
[01:37:26.600 --> 01:37:33.360]  еще два слитых шага, которые мы не разделили. А именно, они происходят в методе submit полуопоток.
[01:37:33.360 --> 01:37:41.800]  Ну вот давайте вернемся в наш написанный код. Мы в конце вчерашнего занятия успели перенести
[01:37:41.800 --> 01:37:51.320]  threadpool в новый пример, избавились от всего лишнего, и теперь говорим про планирование карутин.
[01:37:51.320 --> 01:37:58.040]  Вот у нас есть threadpool, вот мы построили по нему планировщик, который строит sender,
[01:37:58.040 --> 01:38:03.680]  который асинхронно вычисляет юниты, и мы отправили карутину в threadpool. Ну то есть мы вызвали
[01:38:03.680 --> 01:38:11.080]  карутину, карутина делает свой первый шаг, и доходит до кое вейта, в нем вызывает shader-shadle,
[01:38:11.080 --> 01:38:23.080]  получает sender, с помощью avator дожидается значение на этом sender, то есть перепланируется
[01:38:23.080 --> 01:38:32.360]  pool потоков, и вот здесь синхронный вызов карутины завершается. Что происходит в этом shader-shadle?
[01:38:32.360 --> 01:38:40.120]  Мы строим sender, от которого потом строится sender-avator, и в этом sender-avator в конце концов
[01:38:40.120 --> 01:38:47.520]  вызывается submit на sender-pool потоков, а sender-pool потоков, как мы уже много раз видели,
[01:38:47.520 --> 01:38:56.200]  отправляет служебную задачку в threadpool, и эта задача вызывает на ресивере, который построен
[01:38:56.200 --> 01:39:01.560]  специально для карутины метод setValue. Я не знаю, у меня лично, когда я это все говорю, мне становится
[01:39:01.560 --> 01:39:06.520]  смешно, потому что слишком много странных слов, которые образуют очень длинные предложения,
[01:39:07.480 --> 01:39:12.120]  но это так и должно быть, потому что мы сейчас находимся на очень поздней стадии курса,
[01:39:12.120 --> 01:39:21.280]  я это еще раз проговорю, и мы сейчас занимаемся тем, что говорим про дизайн, над которым люди шли,
[01:39:21.280 --> 01:39:27.840]  в общем-то, не одно десятилетие, который разрабатывают прямо сейчас, поэтому то, что в нем все слова,
[01:39:27.840 --> 01:39:32.760]  которые мы произносим довольно абстрактные и не имеют физического представления в материальном
[01:39:32.760 --> 01:39:39.480]  мире, ну вот такова наша участь, мы довольно далеко зашли, и сейчас мы зайдем еще дальше,
[01:39:39.480 --> 01:39:45.360]  потому что мы пытаемся оптимизировать вот это место. Итак, что происходит? В конце концов,
[01:39:45.360 --> 01:39:54.600]  когда выполняется эта строчка, в pool потоков бросается задача, которая должна сделать резюм на
[01:39:54.600 --> 01:40:01.960]  карутине, ну вот если там все вот эти промежуточные шаги и всякие возникающие там между, в них
[01:40:01.960 --> 01:40:06.160]  концепции стереть, то в конце концов в tradpool бросается задача, которая резюмит карутину.
[01:40:06.160 --> 01:40:22.720]  Вот, задача для нашего tradpool это функция, то есть буквально объект function. Какие это
[01:40:22.720 --> 01:40:28.320]  последствия для нас имеют? Ну вот здесь происходит, как мы в прошлый раз разбирались,
[01:40:28.400 --> 01:40:36.120]  скрытая локация. Pool потоков хочет выполнять произвольные задачи. Произвольные задачи это,
[01:40:36.120 --> 01:40:42.080]  ну вот, например, какие-то лямбда, а лямбда, мы с вами понимаем, могут иметь разный размер.
[01:40:42.080 --> 01:40:48.960]  Ну вот скажем, у нас есть эта лямбда и эта лямбда, и вот у этой лямбды нет полей, у этой есть, ну,
[01:40:48.960 --> 01:40:56.220]  эта лямбда ничего не захватывает, а это захватывает значение x. Что значит захватывает? Ну компиатра
[01:40:56.220 --> 01:41:01.460]  берет эту лямбду и переписывает ее просто в класс функтор, некоторые анонимные, то есть мы
[01:41:01.460 --> 01:41:07.340]  типа этого функтора не знаем, но, впрочем, можем на него alias поставить каким-то образом,
[01:41:07.340 --> 01:41:13.900]  это не очень важно. Сейчас важно то, что alias классов в одном случае не будет полей, а вот в этом
[01:41:13.900 --> 01:41:21.260]  случае будут поля, будет поле типа int и размер l1 будет меньше, чем размер l2. Ну давайте мы для
[01:41:21.260 --> 01:41:31.820]  порядка запустим пример и увидим, что действительно это так. Вот l2 имеет размер 4 или 1 единица. И теперь мы
[01:41:31.820 --> 01:41:38.140]  хотели бы, ну вот отвлекаясь даже от крутин, сейчас положить две такие лямбды в пул потоков. Вот они
[01:41:38.140 --> 01:41:42.500]  имеют разный размер, поэтому было бы странно положить, ну непонятно, в какой контейнер их
[01:41:42.500 --> 01:41:49.700]  можно было бы положить. Для того, чтобы с этим справляться, мы с самого начала, то есть еще с
[01:41:49.700 --> 01:41:58.380]  threadpool, который мы написали где-то в середине февраля, мы оборачивали в threadpool задачи в std
[01:41:58.380 --> 01:42:08.500]  function. std function это объект, который представляет собой некоторую функцию, которую можно выполнить,
[01:42:08.500 --> 01:42:15.060]  вызвать с помощью оператора круглые скобочки. Но польза function в том, что этот объект стирает тип,
[01:42:15.060 --> 01:42:22.300]  конкретный лямбда, который он внутри себя держит, конкретного функционального объекта. И этот
[01:42:22.300 --> 01:42:29.940]  function стирает тип и имеет фиксированный размер, а значит этот объект уже можно положить в контейнер,
[01:42:29.940 --> 01:42:36.980]  ну в какой-нибудь привычный нам дек. Каким образом этот function устроен? Вот на этом мы в прошлый раз
[01:42:36.980 --> 01:42:43.500]  остановились. Мы сказали, что как сделать объект function некоторого фиксированного размера. Ну нужно
[01:42:43.500 --> 01:42:50.380]  видимо лямбду, которую мы получаем в конструкторе, переложить на кучу. Для этого мы написали
[01:42:50.380 --> 01:42:57.420]  вспомогательный класс function storage, который просто хранил этот функтор, функциональный объект, и вот
[01:42:57.420 --> 01:43:03.140]  двигали его туда. Ну тут нужно более аккуратный код написать, конечно, но мы понимаем, что это
[01:43:03.140 --> 01:43:11.460]  просто для упрощения нашего рассказа. Мы передвинули этот объект на кучу и вроде бы нам в самом объекте
[01:43:11.460 --> 01:43:18.780]  функцион достаточно хранить просто указатель на этот storage, но не совсем понятно какого
[01:43:18.780 --> 01:43:23.220]  типа указатель должен быть, ну то есть на какой объект он должен, на объект какого типа он должен
[01:43:23.220 --> 01:43:29.700]  указывать. И тут мы говорим, что ну почему бы не работать с этим function storage polymorph,
[01:43:29.700 --> 01:43:39.620]  почему бы не иметь некоторый общий указатель на интерфейс invocable. Вот он объявлен.
[01:43:39.620 --> 01:43:47.380]  И function storage для конкретного вот некоторого уникального типа лямбда, некоторого уникального
[01:43:47.380 --> 01:43:52.860]  типа функционального объекта, будет этот интерфейс реализовывать и в методе invoke вызывать этот
[01:43:52.860 --> 01:44:01.860]  самый f, который он хранит. Тогда мы можем алоцировать этот function storage на куче и сохранить
[01:44:02.460 --> 01:44:10.060]  этот function storage видя pointer на интерфейс invocable. А дальше в операторе круглые скобочки через
[01:44:10.060 --> 01:44:17.100]  интерфейс polymorph вызвать оператора круглых скобочки на конкретном функциональном объекте
[01:44:17.100 --> 01:44:25.540]  конкретного неизвестного нам типа. Вот эта техника называется type erasure, то есть у нас в функции
[01:44:25.540 --> 01:44:36.260]  спрятан стерт тип этой лямбды и мы с ней в конце концов работаем прямой. Отлично, это просто мы
[01:44:36.260 --> 01:44:43.260]  разобрали механику, теперь мы понимаем где здесь, ну где в threadpool, где в методе submit возникает
[01:44:43.260 --> 01:44:49.740]  overhead. Overhead относительно чего? Относительно идеального решения, который выглядит вот так.
[01:44:49.740 --> 01:44:57.700]  Если мы хотим класть в threadpool задачи, которые в конце концов резюмит корутины, то можно было
[01:44:57.700 --> 01:45:02.380]  бы поступить эффективнее, потому что когда корутина планируется в threadpool, она дожидается на
[01:45:02.380 --> 01:45:12.140]  некотором объекте awaiter и этот awaiter ну просто самим компириатором инлайнится в поле корутины.
[01:45:12.140 --> 01:45:19.580]  Мы с вами это все проходили неделю назад, мы писали развертку кода, который генерирует
[01:45:19.580 --> 01:45:24.580]  компириатор для всех этих корутин, он выглядел примерно так, ну и вот awaiter становился полем класса.
[01:45:24.580 --> 01:45:35.820]  Возвращаемся на картинку и если мы теперь в awaiter сделаем поле next, то есть awaiter сделаем
[01:45:35.820 --> 01:45:43.740]  узлом интузивного списка и в awaiter положим handle корутины, которая хочет запланироваться в
[01:45:43.740 --> 01:45:58.900]  pool потоков и свяжем эти awaiter в список, то мы фактически свяжем сами корутины в список и у
[01:45:58.900 --> 01:46:05.380]  нас получится такой интузивный список корутин внутри пула поток. Обращаем внимание, что нам
[01:46:05.380 --> 01:46:11.300]  не обязательно опять писать pool потоков, которые знают прямо про корутины, потому что прямо в
[01:46:11.300 --> 01:46:19.300]  домашней работе вам говорят интегрируйте ваши корутины с пулом потоков, интегрируйте,
[01:46:19.300 --> 01:46:24.220]  но не то что ваши корутины, корутины C++ с вашим пулом потоков без оверхеда,
[01:46:24.220 --> 01:46:31.940]  а воспользую этот факт, что pool потоков поддерживает интузивность. И вот смотрите,
[01:46:32.860 --> 01:46:46.100]  какова наша цель на сегодняшнюю встречу. Наша цель написать код, уточнить, улучшить,
[01:46:46.100 --> 01:46:52.180]  атомизировать еще больше наш дизайн сендеров и ресиверов, чтобы с помощью него можно было
[01:46:52.180 --> 01:46:59.500]  планировать, чтобы threadpool работал по-прежнему только сендер, чтобы threadpool по-прежнему
[01:46:59.500 --> 01:47:04.740]  строил только сендеры и ничего не знал про корутины, но при этом, когда бы мы интегрировали
[01:47:04.740 --> 01:47:14.780]  корутины с пулом потоков через сендеры, вот через эту прослойку, мы все равно имели бы
[01:47:14.780 --> 01:47:21.860]  возможность сделать так, то есть получить интузивность и избежать лишних локаций памяти.
[01:47:21.860 --> 01:47:28.620]  Вот это наша цель. Я с тебе еще позволю маленькое отступление, раз уж я этот функцион написал,
[01:47:28.620 --> 01:47:34.740]  я обращаю внимание, что std function совершенно не обязательно делает динамическую локацию каждый
[01:47:34.740 --> 01:47:41.980]  раз, потому что если у вас объект f маленького размера, то в принципе мы можем здесь завести
[01:47:41.980 --> 01:47:49.260]  небольшой буфер и сделать placement new, то есть алоцировать этот function storage прямо в самом
[01:47:49.260 --> 01:47:53.340]  объекте, то есть не обязательно динамическую память использовать, но это оптимизация для
[01:47:53.340 --> 01:47:57.420]  маленьких объектов, так же как вы можете там, не знаю, вообразить себе оптимизацию векторит для
[01:47:57.420 --> 01:48:02.700]  маленьких векторов, но в общем случае это динамическая локация и мы хотим в общем случае от нее абсолютно,
[01:48:02.700 --> 01:48:14.380]  в общем случае от нее избавиться для корутины. И тут нужно вспомнить, а как мы избавлялись от этой
[01:48:14.380 --> 01:48:20.700]  динамической локации в файберах, но вернее, если вы избавляете динамической локации в файберах.
[01:48:20.700 --> 01:48:30.180]  Ну я начну с обратного, с ответа, а потом объясню как он получился. Вот мы написали этот
[01:48:30.180 --> 01:48:37.980]  function, этот объект function, внутри есть этот invocable, у которого есть invoke и через него мы вызываем
[01:48:37.980 --> 01:48:50.660]  функцию. А теперь посмотрим на задачу, ну или планировщика, или стеклоскорутина. В ней вам
[01:48:50.660 --> 01:49:00.580]  даны экзекутеры, которые нужно, в которых нужно работать уже с инкрузивными задачами. Экзекутер,
[01:49:00.580 --> 01:49:08.980]  который принимает уже taskbase, а taskbase — это наследник itask. Ну вот смотрите, когда мы говорим
[01:49:08.980 --> 01:49:17.500]  про пул потоков, когда мы говорим вообще про произвольный экзекютер, то мы пытаемся сейчас
[01:49:17.500 --> 01:49:26.900]  разделить две задачи. Собственно планирование задачи в threadpool. Давайте я еще раз покажу место,
[01:49:26.900 --> 01:49:35.260]  которое нас волнует. Вот здесь происходят два шага, и отсюда берется неоптимальность. Первый
[01:49:35.260 --> 01:49:44.220]  шаг — мы берем некоторый ресивер, конкретный тип, и обворачиваем его в std function. В сигнатуре submit
[01:49:44.220 --> 01:49:50.940]  это заворачивание происходит. Происходит динамическая локация, мы стерли тип. Вторым шагом мы
[01:49:50.940 --> 01:50:00.460]  планируем в данном случае через ресивер карутину в пул потоков. То есть стирание типа с динамической
[01:50:00.460 --> 01:50:13.380]  локации — раз. И два — это планирование задачи. И для произвольных лямп для произвольных ресиверов
[01:50:13.380 --> 01:50:22.540]  наверное это нужно. А вот если ресивер является карутиной, это не нужно, потому что карутина сама
[01:50:22.540 --> 01:50:34.900]  уже живет на куче. Поэтому мы можем разделить два этих шага. Мы можем сказать, что пусть операция,
[01:50:34.900 --> 01:50:42.860]  которая запускается в пуле потоков, вот пусть ее состояние управляется снаружи пула. Вот собственно
[01:50:42.860 --> 01:50:51.980]  здесь мы так поступаем. Мы говорим, пул потоков не знает, где живет сама задача, в смысле в какой
[01:50:51.980 --> 01:51:01.660]  памяти она живет. Мы лишь получаем указатель на объект, который реализует интерфейс itask и
[01:51:01.660 --> 01:51:10.860]  может запуститься. То есть мы сами не занимаемся локацией объекта, который хранит задачу. Ну там
[01:51:10.860 --> 01:51:20.020]  какую-то произвольную лямпу с какими-то полями. Понимаете меня сейчас? Вот нам нужно, чтобы
[01:51:20.020 --> 01:51:25.140]  где-то задача жила. Задача, вот в общем случае, это например лямпда, какое-то замыкание, у которого
[01:51:25.140 --> 01:51:32.420]  есть какие-то поля. Вот этот объект где-то должен жить. И он должен дожить до того момента, когда
[01:51:32.420 --> 01:51:42.020]  задача запустится. Вот в текущем дизайне, вот в таком наивном, мы обеспечиваем это сами. Мы
[01:51:42.020 --> 01:51:50.740]  принимаем лямпду произвольную и сразу упаковываем ее, вот здесь мы принимаем лямпду и сразу упаковываем
[01:51:50.740 --> 01:51:57.020]  ее в task, то есть переносим на кучу и сами гарантируем, что она доживет до момента старта, до момента
[01:51:57.020 --> 01:52:03.580]  исполнения. Но возможно, не всем задачам это нужно, потому что остановленная корутина, которая
[01:52:03.580 --> 01:52:09.260]  хочет попасть в пул потоков, она разумеется доживет, потому что пока она находится в пуле потоков,
[01:52:09.260 --> 01:52:15.820]  она не исполняется, она же остановилась. Или скажем файбер, та же самая история. Файбер хочет
[01:52:15.820 --> 01:52:24.420]  дождаться мютокса, вот он остановился, пока мютокс захвачен. Нам не нужно алоцировать некоторое
[01:52:24.420 --> 01:52:29.460]  состояние на куче для этого остановленного файбера, потому что файбер уже живет на куче и он не
[01:52:29.460 --> 01:52:43.420]  исполняется, пока его не запустят снова. Вот если он блокируется на мютоксе, то нам немного не туда ушел.
[01:52:43.420 --> 01:52:55.500]  Вот не знаю, просто файбер сделал yield, вот он остановился и он не начнет работать, пока его не
[01:52:55.500 --> 01:53:01.660]  запустит в пуле потоков. Вот сам файбер мог бы быть задачей, сама корутина могла бы быть задачей,
[01:53:01.660 --> 01:53:08.780]  потому что и файбер и корутина живут на стеке. Но я напомню, что файбер мы сами на куче алоцировали,
[01:53:08.780 --> 01:53:15.220]  а корутина на куче алоцирует, ну так скажем, компириатор, когда он не понимает lifetime этой
[01:53:15.220 --> 01:53:22.500]  корутины, он ее state алоцирует с помощью оператора нее и дальше мы в конце корутины себя разрушаем.
[01:53:22.500 --> 01:53:30.180]  Вот мы этот факт пока в пуле потоков никак не используем, а могли бы, и вот поэтому мы разделяем
[01:53:30.180 --> 01:53:40.180]  в интрузивности два этих шага. Аллокация, слишком много примеров, аллокация стейты для задачи и
[01:53:40.180 --> 01:53:47.860]  submit, то есть планирование задач на исполнение. Вот мы говорим, что пусть экзепьютер не отвечает
[01:53:47.860 --> 01:53:55.340]  за это, пусть пользователь беспокоится о том, чтобы задача конкретная дожила до момента запуска ее в
[01:53:55.340 --> 01:54:05.220]  пуле потоков. Вот, и ровно поэтому у нас есть такая вспомогательная функция execute для лямд. Что она
[01:54:05.220 --> 01:54:12.460]  будет делать? Вот она будет делать ровно то же, что делает function. Вот буквально то же самое, вот
[01:54:12.460 --> 01:54:21.460]  буквально то же самое. То есть мы должны будем в этом, в этой функции execute для лямды алоцировать
[01:54:21.460 --> 01:54:29.220]  некоторый function storage, который реализует интерфейс itask и в методе run вызвать объект f. Ну то есть
[01:54:29.220 --> 01:54:38.180]  мы буквально должны внутренности от функшена написать руками в этом execute. Выглядит странно,
[01:54:38.180 --> 01:54:43.980]  зачем мы переписываем реализацию функшена за тем, что для лямд это нужно, а для файберов и для
[01:54:43.980 --> 01:54:52.980]  корутин это не нужно. Понятен замысел? То есть мы даем возможность пользователям, которым не
[01:54:52.980 --> 01:54:58.940]  нужно это заворачивание в функцию, не нужно это искусственное продление жизни, гарантии продления
[01:54:58.940 --> 01:55:07.520]  жизни, не нужно management lifetime не получать overhead. Для лямд этот overhead необходим, а для файберов и
[01:55:07.520 --> 01:55:15.240]  корутин нет. Поэтому мы трансформируем API экзекьюторов, полопотоков, разделяем два этих шага.
[01:55:15.240 --> 01:55:27.760]  Аллокацию стейта задачи и собственно планирование задачи. Вот такой замысел в конце концов стоит за
[01:55:27.760 --> 01:55:33.040]  интрузивностью в нашем курсе. Вот наша задача с самого начала к этому готова. Вот с момента,
[01:55:33.040 --> 01:55:38.480]  кажется, корутин, с момента задачи корутина, где это в первый раз может потребоваться,
[01:55:38.480 --> 01:55:45.360]  где возникают файберы, которые от интрузивности могут извлечь пользу. Ну и вы в принципе сразу
[01:55:45.360 --> 01:55:53.800]  же во всех задачах могли бы этим пользоваться. Вот ровно поэтому вот еще отсюда, давайте я найду
[01:55:54.400 --> 01:56:03.000]  пункт, где-то он был. Да, именно поэтому мы перестали вызывать метод submit на тратпуле напрямую,
[01:56:03.000 --> 01:56:07.240]  мы вызываем такую вспомогательную функцию. И вот эта функция, она будет делать динамическую
[01:56:07.240 --> 01:56:21.280]  локацию, а запуск файбера вот здесь не будет делать динамическую локацию, хотя будет вызывать метод
[01:56:21.280 --> 01:56:29.320]  submit на пулья поток. Вот разница. А теперь мы бы хотели, вот если все это понятно, если не понятно,
[01:56:29.320 --> 01:56:33.400]  то самое время спросить, потому что и задача с таковской корутин, и задача про планировщик
[01:56:33.400 --> 01:56:40.360]  требует реализации интрузивности. Поэтому если вот сейчас не понятно, то лучше пользоваться моментом.
[01:56:40.360 --> 01:56:52.360]  Ну хорошо, раз понятно, тогда возвращаемся к нашей исходной цели. Мы хотим поддержать вот такую
[01:56:52.360 --> 01:57:00.560]  возможность пользоваться интрузивностью для, ну в случае фреймворка сендеров и ресиверов. Ну то есть
[01:57:00.560 --> 01:57:07.360]  у нас есть тратпул, у нас есть корутины, и корутином может быть интрузивная задача для пулопоток.
[01:57:07.360 --> 01:57:16.320]  Загостка в том, что теперь между тратпулом и корутиной есть объект sender. Вот эту проблему мы
[01:57:16.320 --> 01:57:22.800]  сейчас и решим, уточнив наш дизайн. Вот мы скажем, что наша операция submit, она не годится,
[01:57:22.800 --> 01:57:33.440]  потому что она на самом деле получает какой-то ресивер и должна в, должна обеспечить тот факт,
[01:57:33.440 --> 01:57:41.000]  что должна отправить этот ресивер в конечном счете в sender пулпотоков. И sender пулпотоков
[01:57:41.000 --> 01:57:48.120]  обязан продлить жизнь этому ресиверу, где-то его сохранить, управлять его storage. Мы скажем,
[01:57:48.120 --> 01:57:58.000]  что эти два шага нужно разделить, и вместо функции submit мы сейчас напишем две другие функции. То есть
[01:57:58.000 --> 01:58:13.880]  мы этот шаг submit разделим на два. Мы напишем функцию connect. Эта функция будет возвращать,
[01:58:13.880 --> 01:58:25.080]  ну она будет вызывать как обычно sender connect ресивер, и замысел ее такой, connect должен построить
[01:58:25.080 --> 01:58:31.800]  новую сущность в нашем дизайне. У нас есть sender, это представление вычисления, у нас есть ресиверы,
[01:58:31.800 --> 01:58:38.960]  это callback, который ожидает результаты вычисления, и у нас есть shader, это объекты, которые строят
[01:58:38.960 --> 01:58:47.360]  sender. Вот мы добавим к ним еще одну сущность, которая называется operation state. Вот она. Operation
[01:58:47.360 --> 01:58:57.440]  state это объект, который представляет собой хранилище для асинхронной, объект, который представляет
[01:58:57.440 --> 01:59:09.040]  собой, материализует асинхронную операцию. И вот его уже можно отправить sender для выполнения.
[01:59:09.040 --> 01:59:22.120]  Точнее не так, все переврал. Operation state это вот, давайте, дайте мне еще один шанс. У нас есть sender
[01:59:22.120 --> 01:59:28.200]  и ресивер, и вот что такое submit логически? Мы связываем sender и ресивер и запускаем вычисления.
[01:59:28.200 --> 01:59:33.360]  Я об этом всегда так и говорю, как бы в два шага. Вот я сейчас хочу отдельно связать sender и ресивера,
[01:59:33.360 --> 01:59:41.240]  а потом запустить вычисления. В случае threadpool'а, что это значит? У меня есть ресивер, это фактически
[01:59:41.240 --> 01:59:53.520]  лямбда, которая вызывает routing handle resume, и у меня есть sender, это класс, который хранит ссылку на
[01:59:53.520 --> 02:00:07.680]  пул потоков. Где же он? Секундочку, вот он. И я хочу их связать. А что значит связать? Ну я хочу
[02:00:07.680 --> 02:00:14.940]  на самом деле построить интузивную задачу для пул потоков, вот что я хочу. Я хочу, чтобы мой
[02:00:14.940 --> 02:00:24.780]  пул потоков стал лучше. Мне он не нравится, он неэффективен. Я хочу написать, я хочу вместо
[02:00:24.780 --> 02:00:48.700]  task'и написать itask и хочу, чтобы мой пул потоков занимался выполнением этих itask. Когда я
[02:00:48.700 --> 02:00:58.600]  планирую задачу, я получаю pointer на itask. Сейчас мы перепишем и все станет понятнее. Ну я не хочу
[02:00:58.600 --> 02:01:06.960]  дек, конечно, иметь, я обойдусь просто односвязным списком. Когда я делаю submit, ну я пишу, конечно,
[02:01:06.960 --> 02:01:22.300]  manual executor, если вы понимаете, что это. Ну смотри, мы не хотим, чтобы планировщик заботился о
[02:01:22.300 --> 02:01:27.300]  времени жизни лямбды, которую он исполняет. Мы хотим, чтобы была снаружи некоторая задача, и пусть сам
[02:01:27.300 --> 02:01:32.780]  пользователь заботится о времени ее жизни. Пусть сам пользователь заботится о том, чтобы задача
[02:01:32.780 --> 02:01:39.680]  дожила до исполнения. Если мы говорим про файбер, то файбер пока он планируется, он точно не разрушится.
[02:01:39.680 --> 02:01:45.560]  Ну просто потому, что он не работает, пока он в планировщике. Когда он запущен, тогда он может
[02:01:45.560 --> 02:01:54.800]  разрушиться. Ну вот, так что мы переносим проблему управления временем жизни задачи пользователю.
[02:01:54.800 --> 02:02:04.400]  Пусть он об этом беспокоится. А мы будем просто принимать itasks, ну или даже чуть аккуратнее
[02:02:04.400 --> 02:02:19.700]  taskbase, который наследует itask, и внутри у него еще есть pointer next для того, чтобы задачи связывать
[02:02:19.700 --> 02:02:37.420]  списки. В методе submit я должен задачу, которую дал мне пользоваться, привязать к своему списку.
[02:02:37.420 --> 02:02:46.740]  Вот, кажется, я написал вставку в односвязанный список, если я не ошибся. Похоже на то. Ну и здесь
[02:02:46.740 --> 02:03:14.620]  я что буду делать. Я буду исполнять все задачи. Ну вот, такой примитивный код, но в этом месте вы
[02:03:14.620 --> 02:03:22.020]  можете представить себе какой-то сложный планировщик, шардированный с локальными очередями. То, о чем мы
[02:03:22.020 --> 02:03:32.980]  говорили не так давно. У меня такая наивная реализация, и в методе submit, ну метод submit придется
[02:03:32.980 --> 02:03:44.420]  переписать, но вообще-то я метод submit закомментировал, мне он уже не нужен. Мне нужно, чтобы, давайте я
[02:03:44.420 --> 02:03:53.380]  напишу, что я хочу, наверное. Я хочу, чтобы пользователь, когда он хочет положить задачу в
[02:03:53.380 --> 02:04:03.620]  пул потоков, давайте корутину спрячем. Корутина это довольно сложный пример. Я хочу следующего. Вот у
[02:04:03.620 --> 02:04:11.980]  меня есть stratpool, и чтобы в него что-то запланировать, я должен построить сначала планировщик. Вот построил
[02:04:11.980 --> 02:04:28.780]  планировщик. Допустим, я хочу запланировать в нем исполнение лямбда. Давайте назовем ее просто l,
[02:04:28.780 --> 02:04:37.340]  а может быть и не будем их называть. Я хочу следующего. Я хочу иметь операцию. Сначала я
[02:04:37.340 --> 02:04:44.260]  получаю sender, который представляет собой вычисление в пуле потоков, вычисление юнита,
[02:04:44.260 --> 02:05:00.420]  а дальше я просто вызвал, дальше у меня есть receiver, который юнит потреблял. Значение его не
[02:05:00.420 --> 02:05:10.180]  интересовал. У юнита всегда одно значение. Вот и синхронный receiver. И дальше я вызывал
[02:05:10.180 --> 02:05:17.740]  обычно submit sender receiver. Связывал sender receiver и планировал задачу в пул поток. Делал два шага,
[02:05:17.740 --> 02:05:25.420]  вот даже просто я произношу и говорю там что-то и что-то. Теперь я делаю два отдельных явных шага.
[02:05:25.420 --> 02:05:44.500]  Я сначала говорю, что я связываю sender и receiver, а потом уже я говорю start операции. В чем замысел?
[02:05:44.500 --> 02:05:57.780]  Если мы говорим про пул потоков, то для пул потоков вот такого эффективного нам требуется
[02:05:57.780 --> 02:06:08.060]  иметь инклюзивную задачу. Она должна жить снаружи. Операция в случае конкретного sender
[02:06:08.060 --> 02:06:18.460]  это будет объект, который реализует интерфейс itask. И вот я его здесь построил и вот у меня
[02:06:18.460 --> 02:06:26.140]  объект есть и теперь я сам должен позаботиться о том, чтобы он дожил до момента запуска в пуле поток.
[02:06:26.140 --> 02:06:38.020]  А вот здесь я просто стартую операцию, но видимо бросаю ее в пул. То есть вот эта
[02:06:38.020 --> 02:06:42.340]  операция в данном случае это будет видимо реализация интерфейса task.
[02:06:42.340 --> 02:07:01.580]  Ну а дальше, если я хочу, чтобы она прожила долго, я ее на кучу переложу. Если я знаю,
[02:07:01.580 --> 02:07:10.220]  что скажем она доживет до времени своего исполнения, ну вот здесь вот так вот. То есть я
[02:07:10.220 --> 02:07:16.660]  заблокирую, я сначала выполню все задачи, а потом выйду из кулопа. То есть здесь мне достаточно,
[02:07:16.660 --> 02:07:20.580]  чтобы операция жила на стеке. То есть я не обязан даже лямбду на кучу перекладывать здесь,
[02:07:20.580 --> 02:07:25.700]  потому что я знаю, что она доживет в момент своего исполнения. Замысел ясен?
[02:07:25.700 --> 02:07:38.860]  Ну вот, то есть я здесь могу сэкономить даже для лямбд в таком дизайне, когда я понимаю,
[02:07:38.860 --> 02:07:44.300]  что я синхронно дожидаюсь задач. Ну а для корутин и файберов уж тем более.
[02:07:44.300 --> 02:07:55.700]  Вот, операция start, она будет будет тривиальной, если у нас есть теперь некоторая операция. Это
[02:07:55.700 --> 02:08:00.380]  тоже некоторые неизвестный нам тип, потому что операция для каждого сендера будет своя. Для
[02:08:00.380 --> 02:08:05.900]  threadpool'а это будет реализация интерфейса task, itask. Для какого-то другого пула она может быть
[02:08:05.900 --> 02:08:12.300]  вот чем-то другим. И я здесь стартую операцию. Здесь ничего интересного.
[02:08:12.300 --> 02:08:28.740]  И давайте теперь напишем сендер для пула потоков, который строит уже что-то,
[02:08:28.740 --> 02:08:35.340]  которое умеет уже коннект делать. Да, у нас, кстати, поменялись концепты, теперь я хочу
[02:08:35.340 --> 02:08:45.300]  коннект. Давайте я немного срежу угол. Я вот читал лекцию в шаде в начале недели, и мы там писали
[02:08:45.300 --> 02:08:57.660]  сендер для... Я забежал вперед, извините. Смотрите это из своей памяти, пожалуйста. Давайте
[02:08:57.660 --> 02:09:11.540]  напишем сендер для пула потоков. Нам теперь не нужен метод submit, нам нужен метод connect,
[02:09:11.540 --> 02:09:21.940]  который что-то возвращает. Он получает ресивер и должен из него сделать задачу, объект задачи,
[02:09:21.940 --> 02:09:32.580]  временем жизни которой будет управлять сам пользователь. Ну вот в терминах нашего
[02:09:32.580 --> 02:09:47.380]  фреймворка это operation state. Вот мы так его назовем. И временем жизни этого operation state будет
[02:09:47.380 --> 02:09:56.140]  управлять пользователь, поэтому мы назовем его manual operation state. Вот, мы такую штуку должны вернуть.
[02:09:56.140 --> 02:10:11.100]  Для конкретного ресивера. В этом manual operation state будет жить ресивер. Ресивер,
[02:10:11.100 --> 02:10:24.220]  который хочет в пуле потоков запуститься и получить оттуда юнит. И вот этот manual operation
[02:10:24.220 --> 02:10:35.020]  state я должен в методе start потом уметь запустить. Поэтому, видимо, я должен сохранить ссылку на
[02:10:35.020 --> 02:10:45.620]  полпотоков и сделать вот так. И я должен наследоваться от... То есть я хочу построить
[02:10:45.620 --> 02:10:51.740]  задачу для лямбы. Ну, для ресивера вернее. Вот задача. Вот она и будет задача.
[02:11:06.220 --> 02:11:10.020]  Нам нужен конструктор.
[02:11:15.620 --> 02:11:24.420]  Нам нужно знать protrude pool и нужно знать ресивер. Почему-то все в обратном порядке получилось.
[02:11:45.620 --> 02:11:57.940]  Так, что нам... Ну, не нам, что комператору здесь не нравится. Простите, у нас довольно много IDE.
[02:11:57.940 --> 02:12:07.860]  А, но я не написал метод run, конечно же. Я строю задачу, а у задачи должен быть метод run. И в этом методе мы
[02:12:07.860 --> 02:12:14.420]  подарим ресиверу этот самый вычисленный юнь.
[02:12:24.060 --> 02:12:34.620]  Так. Правда ли, что я написал код? Или я что-то упустил? Давайте проверим.
[02:12:35.340 --> 02:12:42.740]  Start реализован. Connect реализован. И connect для
[02:12:46.220 --> 02:12:47.260]  полпотоков.
[02:12:51.260 --> 02:12:59.540]  Медленный компьютер. Connect для полпотоков реализован. Ну, попробуем. Если не скомпедируется, то будем разбираться.
[02:13:04.620 --> 02:13:27.060]  Так, ну тут много всяких бесполезных сообщений выводится. Давайте... Вот так.
[02:13:34.620 --> 02:14:00.340]  Здорово, все работает. Все работает, причем смотрите как удивительно. Мы вот на уровне
[02:14:00.340 --> 02:14:11.700]  этого сниппета оперируем максимально общими сущностями. Shader, Sender, Receiver, OperationState, Connect.
[02:14:11.700 --> 02:14:22.580]  Ну, то есть вот мы используем большую часть этого словаря. Словаря концептов. Design execution.
[02:14:22.580 --> 02:14:34.060]  Мы сделали очень много маленьких тамарных шагов. И что мы получили? Мы получили возможность запустить
[02:14:34.060 --> 02:14:42.460]  задачу в пуле потоков, не выполнив ни одной динамической аллокации памяти. Потому что в
[02:14:42.460 --> 02:14:47.900]  пуле потоков динамических аллокаций нет. Потому что пул потоков работает только с интрузивными
[02:14:47.900 --> 02:14:55.100]  задачами. Тут нет контейнеров динамическими аллокациями. Тут нет функций, которые баллоцировали
[02:14:55.100 --> 02:15:01.340]  память при стирании типа. Мы в Submit получаем Pointer, провязываем его в список через поле Next,
[02:15:01.340 --> 02:15:10.380]  которое встроено в объект задачи. Вот. Ну и тут мы вручную вызываем функции. Ну, представьте
[02:15:10.380 --> 02:15:16.700]  себе потоки Worker, которые зовут Run, доставая там задачи из какой-то очереди. Опять это все
[02:15:16.700 --> 02:15:22.980]  вообразимо. То есть, в пуле потоков в самом динамической аллокации нет. И она не требуется даже
[02:15:22.980 --> 02:15:33.140]  снаружи для лямбды. Потому что мы здесь знаем, что операция доживет до момента вызова RunTasks. Ну,
[02:15:33.140 --> 02:15:40.940]  то есть, ну представьте, что мы здесь написали Start, а потом написали ThreadPool WaitIdle. И вот, то есть,
[02:15:40.940 --> 02:15:48.380]  этот код гарантирует, что операция доживет до момента своего исполнения. И используя этот факт,
[02:15:48.380 --> 02:15:57.660]  мы получили возможность сэкономить аллокацию для самой лямбды. То есть, фактически, что мы сделали?
[02:15:57.660 --> 02:16:03.820]  Мы здесь сделали, мы понимаем, что лямбду на куче аллоцировать не нужно, и мы аллоцировали ее на
[02:16:03.820 --> 02:16:12.340]  стейке. Ну, мы, вот давайте вернемся к этому FunctionState. Где я его писал? Вот здесь. Мы фактически
[02:16:12.340 --> 02:16:23.100]  поняли, что FunctionStorage можно аллоцировать на стейке. И аллоцировали его здесь. То есть, можно,
[02:16:23.100 --> 02:16:30.540]  в принципе, про все эти оптимизации говорить вне контекста сендеров и ресиверов. Тут важно, в данный
[02:16:30.540 --> 02:16:37.300]  момент важно не это. Но к сендерам и ресиверам это имеет прямое отношение, потому что вот можно
[02:16:37.300 --> 02:16:42.700]  все эти задачи в ThreadPool и вообще разговоры про ThreadPool, про все вот это обобщить и говорить про
[02:16:42.700 --> 02:16:52.780]  сендеры, ресиверы и операции. И почему? Потому что теперь можно, используя вот эту идею, написать
[02:16:52.780 --> 02:17:01.940]  хороший авейтер для корутины, который позволит ей перепланироваться в пул потоков без динамической
[02:17:01.940 --> 02:17:15.940]  локации. Давайте я немного упрощу себе жизнь, потому что писать общий сендер я не хочу. Это
[02:17:15.940 --> 02:17:21.380]  можно сделать, это будет просто немного сложнее. Больше головной боли, а суть продемонстрирует
[02:17:21.380 --> 02:17:31.180]  то, что важно. Добавится больше деталей и отвлечет нас от того, что важно. Я хочу написать сейчас
[02:17:31.180 --> 02:17:43.340]  оператор CoAv8. Не для произвольного сендера, фундаментальной проблемы здесь нет, такой написать,
[02:17:43.340 --> 02:17:54.020]  а для конкретного сендера, для пула потоков. Это будет проще, потому что я знаю, что он возвращает
[02:17:54.020 --> 02:18:03.940]  юнит и от знания конкретного типа мне будет немного легче жить, только и все. Нужно еще name
[02:18:03.940 --> 02:18:24.620]  space закрыть. Что-то пошло не так, сейчас буду разбираться. Ну да, я понимаю, что хочу писать. У
[02:18:24.620 --> 02:18:35.940]  меня есть name space с деталями реализации, у меня есть там CoAv8.
[02:18:54.620 --> 02:19:01.580]  Сложно во всем этом говорить, столько абстрактных слов. Я-то еще себя понимаю,
[02:19:01.580 --> 02:19:09.020]  вот какого вам я даже не представляю сейчас. Но тем не менее мы доведем работу до конца. Мы пишем
[02:19:09.020 --> 02:19:17.860]  о вейтера, который сможет дождаться вычисления юнит в пуле потоков, то есть перепланировать
[02:19:17.860 --> 02:19:27.660]  коротину в пул поток. Пишем о вейтер, ну и тут обычная рутина, мы пишем await radio, мы пишем,
[02:19:27.660 --> 02:19:33.180]  вот да, в этом месте я себе немного упростил жизнь, await resume, который ничего не делает,
[02:19:33.180 --> 02:19:41.540]  потому что я знаю, что мы возвращаем юнит в случае конкретного такого сендера. А теперь я хочу
[02:19:41.540 --> 02:19:56.220]  написать await suspend, получить здесь коротин handle для коротины и запланировать его возобновление.
[02:19:56.220 --> 02:20:04.940]  А у меня есть сендер для пула потоков. Как мне поступить здесь? Что я хочу? Я хочу алоцировать,
[02:20:04.940 --> 02:20:23.100]  во-первых, я хочу построить ресивер. Сейчас я подумаю, нужно мне это делать или нет. Давайте
[02:20:23.100 --> 02:20:28.500]  явно напишу, у меня будет ресивер для коротин handle.
[02:20:28.500 --> 02:20:50.340]  И в... нужно мне это делать или нет. Так, решаю проблему по мере необходимости. У меня есть ресивер,
[02:20:50.340 --> 02:21:04.020]  который будет резюмить коротину. Ну вот, я построил какой-то объект сейчас, ну то есть
[02:21:04.020 --> 02:21:13.820]  у меня есть некоторый объект такого типа, у которого есть метод functor-receiver, у которого есть...
[02:21:13.820 --> 02:21:23.180]  ну где-то я себе код сломал, ладно, потом... у которого есть set-value, set-error, set-done.
[02:21:31.420 --> 02:21:37.860]  И я хочу, во-первых, сказать вот это, сендер,
[02:21:37.860 --> 02:21:55.060]  connect, receiver. Вот получить операцию, то есть вот этот объект, который в случае threadpool-сендера
[02:21:55.060 --> 02:22:01.980]  будет представлять из себя что. Тут, кстати, можно перейти, а тут не шаблонный, вот уже получается
[02:22:02.180 --> 02:22:12.260]  конкретный тип. Построит мне manual operation state, который реализует интерфейс таски. Вот, и я хочу,
[02:22:12.260 --> 02:22:23.460]  чтобы этот объект дожил до момента запуска задачи в пуле потоков. Ну, здесь он не доживет,
[02:22:23.460 --> 02:22:28.460]  потому что вот я его построил на стейке этого вызова, вот я стартовал операцию, то есть бросил
[02:22:28.460 --> 02:22:34.180]  эту операцию по поинтеру в threadpool, а дальше вызов завершился, операция разрушилась, не годится.
[02:22:34.180 --> 02:22:46.980]  Но я знаю, что avator, он будет жить в поле крутины, поэтому если я сохраню этот объект операции в
[02:22:46.980 --> 02:22:59.740]  поле avator, то я гарантирую, что объект операция доживет до момента запуска крутины в пуле потоков
[02:22:59.740 --> 02:23:10.740]  через интерфейс itask. Хорошо, нужно это сделать, но для этого нужно знать type name для вот такой
[02:23:10.740 --> 02:23:20.100]  операции. Да, вот именно поэтому мне нужно написать все-таки класс Receiver явно.
[02:23:20.100 --> 02:23:28.500]  Receiver для крутины. Ну, сложно его написать.
[02:23:40.740 --> 02:24:06.540]  Вот это мы оставим светлым в будущем. А нам value type еще не нужно или это для серии? Value type он
[02:24:06.540 --> 02:24:18.060]  в sender, sender объявляет, кого он вычисляет. А дальше, когда мы их коннектим, то просто у нас
[02:24:18.060 --> 02:24:25.540]  программа не скомпилируется, если у Receiver не будет set value с value type, который вычисляет sender.
[02:24:25.540 --> 02:24:33.860]  То есть value type выявляет тот, кто вычисляет это value, это sender, а Receiver просто получает,
[02:24:33.860 --> 02:24:42.140]  вот он в сигнатуре объявляет, что он получает. Понятно, да? То есть тут объявление value type
[02:24:42.140 --> 02:24:53.660]  для Receiverа есть, оно вот тут находится. А теперь я могу объявить, что же будет operation state.
[02:24:53.660 --> 02:25:14.420]  Конкретный тип. Это thread pool, manual operation state от Cora Receiver. Ура! И теперь я могу,
[02:25:14.500 --> 02:25:24.020]  теперь я могу сделать следующее, кажется. Я могу завести еще одно поле, но тут,
[02:25:24.020 --> 02:25:35.380]  простите, какой-то корд очень неупорядочный, но он пишется так спонтанно. Теперь я могу сохранить
[02:25:35.380 --> 02:25:51.420]  вот эту операцию в поле овейтера, написать, все это стереть, написать здесь connect Cora Receiver от H
[02:25:51.420 --> 02:26:08.420]  и положить результат в поле. Смотрим. Ура! И теперь уже я могу сказать start. Ну, стрелочка,
[02:26:08.420 --> 02:26:15.260]  потому что option у нас завелся. Ну и ладно, я могу даже написать, где у меня, в каком порядке все это
[02:26:15.260 --> 02:26:28.620]  объявлено, в правильном. Могу написать теперь вот так. Ну что, мне кажется, что я написал все,
[02:26:28.620 --> 02:26:35.180]  нужно теперь проверить, что работает и прокомментировать, что случилось еще раз.
[02:26:35.180 --> 02:26:49.340]  Корутина. Трэдпул. Шедулер. Вызываем Cora. В ней видим шедулер-шедул. Получаем сендер.
[02:26:49.340 --> 02:26:57.340]  Строим по нему овейтер. В этом овейтере, в овейтсаспенде строим Receiver, который будет
[02:26:57.340 --> 02:27:09.100]  возобновлять корутину. С помощью коннекта мы строим объект. Ждем, ждем, ждем. Строим объект
[02:27:09.100 --> 02:27:21.700]  manual operation state, который реализует интерфейс задачи. Сохраняем его в поле овейтера, а овейтер
[02:27:21.700 --> 02:27:33.020]  является полем корутин стейта. И после этого наконец стартуем задачу. И давайте посмотрим,
[02:27:33.020 --> 02:27:46.300]  что нам все удалось. Да, было очень наивно рассчитывать, что мы уложимся в одну пару в
[02:27:46.300 --> 02:28:02.500]  прошлый раз. Это была большая ошибка. Простите. Ну, блестяще. Мы написали код и да, непонятно,
[02:28:02.500 --> 02:28:11.660]  что мы исполняемся в пулепоток, правда. Но вот давайте мы напишем здесь немного помощи.
[02:28:16.300 --> 02:28:23.700]  Действительно, пулепоток исполняет теперь эту корутину.
[02:28:37.420 --> 02:28:43.420]  Ну что ж, грандиозно. Смотрите, почему грандиозно. Потому что теперь в этом коде,
[02:28:43.420 --> 02:28:55.380]  ну вот в этом коде и вот в этом коде нет ни одной явной динамической локации. То есть мы смогли
[02:28:55.380 --> 02:29:01.540]  запустить корутину в пулепотоков. Мы знаем, что она, ну мы смогли запустить корутину в
[02:29:01.540 --> 02:29:11.940]  пулепотоков. Мы воспользовались интрузивностью тредпула, но при этом мы отделили корутины от
[02:29:11.940 --> 02:29:19.060]  пулепотоков с помощью вот такой прослойки сендеров и ресиверов. Ну вот прямо скажем,
[02:29:19.060 --> 02:29:23.500]  в последнем шаге вот какого-то большого смысла, ну не то что большого смысла нет,
[02:29:23.500 --> 02:29:30.060]  разумеется он есть. Это скорее препятствие. То, что мы сейчас сделали, вот это было препятствием
[02:29:30.060 --> 02:29:38.660]  для нас. Но результат получился чертовски разумный. Объясняю еще раз. Мы с самого начала решили,
[02:29:38.660 --> 02:29:44.180]  ну вот с самого начала прошлого занятия решили, что каким-то образом все наши вычисления,
[02:29:44.180 --> 02:29:52.220]  вот любые наши вычисления мы можем представить себе с помощью, выразить с помощью такого
[02:29:52.220 --> 02:29:58.980]  словаря. Сендеры, вычисления, которые что-то вычисляют, ленивые. Ресиверы это колбэки,
[02:29:58.980 --> 02:30:06.500]  шедулеры это объект, который строят сендеры и operation state это материализация вот асинхронной
[02:30:06.500 --> 02:30:14.220]  операции, которая связывает сендеры и ресиверы. Вот максимально абстрактные слова. И что мы
[02:30:14.220 --> 02:30:20.060]  показали? Мы показали, что на них можно переложить, ну да в общем-то все подряд можно переложить.
[02:30:20.060 --> 02:30:27.340]  Можно писать синхронные вычисления, можно написать асинхронные вычисления, можно комбинировать
[02:30:27.340 --> 02:30:35.180]  вычисления. И можно интегрировать все это с корутинами, потому что вот есть такое соответствие.
[02:30:35.820 --> 02:30:41.660]  Можно так поставить. Да, кстати, можно теперь написать к чему соответствует operation state в случае
[02:30:41.660 --> 02:30:50.860]  корутин. Это корутин state. Вот этот самый объект, который живет на куче. Мы в корутин state inlinem
[02:30:50.860 --> 02:31:02.780]  объект operation state. Собственно вот мы здесь это и сделали. Вот-вот-вот-вот здесь. То есть
[02:31:02.780 --> 02:31:08.380]  наш словарь претендует на универсальность, потому что мы можем какие-то произвольные вычисления
[02:31:08.380 --> 02:31:13.980]  писать. Причем мы можем даже писать их оптимальнее, чем раньше, за счет того, что мы атомизировали
[02:31:13.980 --> 02:31:21.700]  отдельные шаги. И мы можем интегрировать это с корутинами опять без верхета. Видимо это доказывает,
[02:31:21.700 --> 02:31:29.460]  что наш дизайн очень разумен, очень логичен. Ну просто вот он хорошо описывает любую реальность,
[02:31:29.460 --> 02:31:41.340]  корутинную, некорутинную. Да, вот тут еще больше абстрактных терминов. Но это не удивительно,
[02:31:41.340 --> 02:31:46.860]  потому что мы взяли простую операцию, вот такую. Вот сейчас давайте мы вернемся к примеру с
[02:31:46.860 --> 02:31:54.220]  фьючами. Вот такую операцию, которая делает три вещи разом. Оборачивает лямбду в функцию,
[02:31:54.220 --> 02:32:00.660]  бросает ее в пул потоков и возвращает фьючу. Вот три шага были сделаны разом,
[02:32:00.660 --> 02:32:08.300]  поэтому были сделаны не оптимальны с разных позиций. Сейчас мы сделали все шаги отдельно.
[02:32:08.300 --> 02:32:18.300]  Мы представили вычисление, мы алоцировали для него стейт и вручную им управляем. И только
[02:32:18.300 --> 02:32:25.620]  потом мы сделали сабмит. Мы представили будущее вычисление с Эндером, мы алоцировали для него
[02:32:25.620 --> 02:32:33.740]  состояние и мы стартовали. Вот мы три шага выполнили отдельно. И за счет того, что мы... Да,
[02:32:33.740 --> 02:32:39.100]  для этого потребовались новые слова, ну потому что много шагов, много приручных объектов стало,
[02:32:39.100 --> 02:32:48.100]  но зато мы получили возможность для очень тонкого управления всем происходящим. То есть
[02:32:48.100 --> 02:32:52.260]  в этом смысле мы не придумывали ничего нового, мы просто подобрали слова для того,
[02:32:52.260 --> 02:32:58.580]  чтобы описывать все промежуточные шаги. В этом смысле дизайн совершенно не удивителен и в
[02:32:58.580 --> 02:33:06.060]  каком-то смысле не избежен. Мы просто зафиксировали реальность. Но тем не менее, это вот стоило
[02:33:06.060 --> 02:33:12.420]  сделать. Это делается плюс-плюс только сейчас. Да, делают рано или поздно, надеюсь.
[02:33:12.420 --> 02:33:19.220]  Наверное стандартизируют, это уже страостепенный вопрос. Но вот библиотеку пишут, ну или написали
[02:33:19.220 --> 02:33:26.580]  уже в какой-то степени значительной, она называется Libionifex Unified Executors. Можно на нее посмотреть,
[02:33:26.580 --> 02:33:30.540]  можно с помощью нее попробовать что-то писать. Возможности там гораздо шире, чем мы обсуждали,
[02:33:30.540 --> 02:33:35.900]  потому что должна быть поддержка для потоков данных асинхронных, не только для просто
[02:33:35.900 --> 02:33:41.460]  вычислений данных. Должна быть поддержка для отмены, должна быть поддержка водо-вывода-времени,
[02:33:41.460 --> 02:33:48.180]  чтобы общаться с внешним миром. Ну вот это все в любом случае должно быть вписано в framework
[02:33:48.180 --> 02:33:55.740]  on currency. Мы про это все мало говорим, все же у нас не хватает на все времени. Ну а вот в основе
[02:33:55.740 --> 02:34:01.380]  те сущности, которые мы описали. В общем, можно пользоваться, можно попробовать руками это подрогать.
[02:34:01.380 --> 02:34:12.580]  Ну что ж, на этом пожалуй и на сегодня все. В смысле, я выполнил поставленную самим
[02:34:12.580 --> 02:34:18.740]  собой перед собой цель. Рассказал вам про sender и receiver. Кажется, попытался связать их
[02:34:18.740 --> 02:34:25.740]  с корутинами, с интрузивностью. В общем, все, что мы в курсе наблюдаем, это все связано. И вот мы,
[02:34:26.180 --> 02:34:33.060]  почти что уже до конца достроили нашу большую-большую картину, в которой очень-очень много теперь деталек.
[02:34:33.060 --> 02:34:42.340]  И наша задача их осмыслить и дописать задачи, которые у нас вот сейчас есть. И планировщик
[02:34:42.340 --> 02:34:48.660]  быстро дописать, и корутины дописать. И вот я в начале недели, в середине недели выложу future.
[02:34:48.660 --> 02:34:57.340]  И вот за май, дописав все вот эти задачи, мы, кажется, сможем почувствовать, как все эти запчасти,
[02:34:57.340 --> 02:35:03.020]  как все эти детали могут друг с другом взаимодействовать, сочетаться друг с другом,
[02:35:03.020 --> 02:35:08.100]  не противоречить друг другу. Это все очень нетривиальная задача. В смысле, связать это все вместе.
[02:35:08.100 --> 02:35:13.780]  Ну, кажется, что мы к этому сейчас близки. Ну что ж, да.
[02:35:13.780 --> 02:35:19.660]  Вам не кажется вообще, что стоит так же написать простой интерфейс для пользователя?
[02:35:19.660 --> 02:35:25.980]  То есть, условно говоря, чтобы он мог сделать tp create от количества подоков,
[02:35:25.980 --> 02:35:31.260]  а потом просто закидывать в threadpool lambda? Ну, если он так будет делать, смотри,
[02:35:31.260 --> 02:35:38.420]  такое интерфейс у нас уже был с самого начала, да? Мы с него начали. Нет, ты справедливо говоришь,
[02:35:38.420 --> 02:35:43.740]  что у нас есть вот такой интерфейс, где все по шагам, но если пользователю это не нужно,
[02:35:43.740 --> 02:35:48.820]  если он ленивый, если он не хочет оптимизировать ничего, то давайте сделаем для него просто вот,
[02:35:48.820 --> 02:35:59.260]  ну, я не знаю, какой-нибудь грубный метод submit в threadpool, да? Ну да, можно выразить по-прежнему
[02:35:59.260 --> 02:36:07.940]  submit sender. У нас был sender receiver, да? Мы можем его оставить. Ну, то есть, для этого мы в sender
[02:36:07.940 --> 02:36:16.260]  должны поддержать и submit, который не будет перекладывать управление lifetime storage задачи
[02:36:16.260 --> 02:36:22.140]  на пользователя, а разместить на куче. То есть, смотри, ты справедливо говоришь,
[02:36:22.140 --> 02:36:28.460]  можно это прямо сейчас и сделать. Ну, то есть, можно написать здесь в sender еще один метод,
[02:36:28.460 --> 02:36:48.860]  ну, точнее вернуть старый или можно его по-другому назвать. В общем-то, это делается точно так же,
[02:36:48.860 --> 02:36:55.900]  как мы. Ну да, да, да. Это, наверное, просто дополнительные методы или перегрузки старых.
[02:36:55.900 --> 02:37:05.260]  Ну, то есть, можно промежуточные шаги вскрывать. Вот, и можно сделать следующее. Мы лоцировали
[02:37:05.260 --> 02:37:15.900]  эту штуку на кучу, мы говорим threadpool, как у нас там назывался, submit. Ладно,
[02:37:15.900 --> 02:37:22.140]  давай я напишу тут. Писать-то еще 30 секунд. Тем более, я себе время сэкономлю и скопирую.
[02:37:22.140 --> 02:37:38.660]  Threadpool нам не нужен. И я в методе run сделаю что? Ну, продиктуй мне, если ты все понимаешь.
[02:37:38.660 --> 02:38:00.060]  Что? А, да, спасибо. Что я напишу в run? Вот, я уже лоцировал объект на кучу. То есть,
[02:38:00.060 --> 02:38:05.380]  я говорю, что пользователь, не заморачивайся с тем, где хранить operation state. Я сам лоцирую
[02:38:05.380 --> 02:38:15.620]  на кучу, а когда задача завершится, я сотру его. Вот, и теперь я могу еще написать
[02:38:15.620 --> 02:38:25.340]  вспомогательный метод spawn, который будет избавлять пользователя от необходимости думать
[02:38:25.340 --> 02:38:40.780]  про operation state. Ну, надеюсь, что нигде не ошибся. Сейчас можно это быстро проверить. Да,
[02:38:40.780 --> 02:38:54.660]  я не хочу так делать. Сложно слишком, поэтому я говорю spawn sender receiver. У кого-то микрофон,
[02:38:54.660 --> 02:39:13.060]  пожалуйста, заметьте себя. Тут стоит кое-что другое отметить. Что в std execution,
[02:39:13.060 --> 02:39:21.380]  что в libunifex, там есть некая философия про то, что пользователь конечный, который пишет
[02:39:21.380 --> 02:39:28.540]  бизнес логику ассинхронную, он вообще не должен знать ни про operation state, ни про receiver,
[02:39:28.540 --> 02:39:38.020]  ни про что. Он знает только про sender, что-то, что их производит, и различные функции,
[02:39:38.020 --> 02:39:46.420]  комбинаторы для их трансформации, типа when. Можно when all написать. В качестве заводов,
[02:39:46.420 --> 02:39:55.660]  сендеров у нас дредпул, то есть любой шеддлер. Сокеты могут быть заводами сендеров, делать
[02:39:55.660 --> 02:40:02.620]  сендеры, в которых появляются данные, когда они пришли в сокет, ну и так далее. В конечном
[02:40:02.620 --> 02:40:09.380]  итоге получается интерфейс такой же, как у фьюч. Ну да, это совершенно верно. Так смотри,
[02:40:09.380 --> 02:40:14.060]  вот пример с корутиной, он же это и демонстрирует. Мы просто пишем корутино, в нем говорим
[02:40:14.060 --> 02:40:20.780]  кое weight, shader, shadle, и внутри все эти сендеры, ресиверы есть, а в коде их нигде нет.
[02:40:20.780 --> 02:40:28.460]  Ну это пример на корутинах. Если мы пишем другой код, то там та же самая история. Ну и с фьючом
[02:40:28.460 --> 02:40:32.860]  я это говорил, что если мы пишем код на фьючах, то промесов нигде не возникает. Промесы — это всякая
[02:40:32.860 --> 02:40:38.420]  внутренняя инфраструктура. Ну, замечание очень хорошее, справедливое. Да, давай мы это еще раз
[02:40:38.420 --> 02:40:45.300]  проговорим, что вся эта механика, она используется некоторой инфраструктурой, в которой пользователь
[02:40:45.300 --> 02:40:51.020]  пишет свой код, но она пользователя большей частью скрыта. То есть, редко когда пользователь будет
[02:40:51.020 --> 02:40:55.980]  писать вот прям вот так все голыми руками. Мы сейчас это пишем, потому что мы хотим проиллюстрировать
[02:40:55.980 --> 02:41:00.740]  эту механику, то есть за счет чего достигается оптимальность. И иллюстрируем, что оптимальность
[02:41:00.740 --> 02:41:07.580]  достигается с помощью корутин. Вот, но в корутинах никакого сложного кода нет. Мы получили планировщик,
[02:41:07.580 --> 02:41:11.980]  сделали коэвейт на планировщике, и вот автоматически все получилось оптимально.
[02:41:11.980 --> 02:41:20.580]  Вот это то, что, то что видит пользователь. А под капотом работает вся эта машинерия,
[02:41:20.580 --> 02:41:25.860]  но вот она работает, обеспечивает оптимальность, то есть через нее можно все оптимально выразить,
[02:41:25.860 --> 02:41:36.020]  но в прикладном коде этого всего быть не должно. Но даже если мы хотим работать как-то более-менее
[02:41:36.020 --> 02:41:41.060]  прямой линейно с этим всем, то можно писать себе какие-то вспомогательные шорткаты,
[02:41:41.060 --> 02:41:47.180]  которые вот все равно все это скрывают. И еще тут может встать закономерный вопрос,
[02:41:47.180 --> 02:41:56.020]  я удивлен, что никто его не задал, хотя, наверное, не удивлен. Авейтер, ну или точнее сказать,
[02:41:56.020 --> 02:42:05.060]  какой-нибудь awaitable, типа task, который можно коавейтнуть и получить там авейтер и дождаться
[02:42:05.700 --> 02:42:13.340]  да можем ли мы его превратить в sender? По-моему закономерный вопрос, ну я сам на него отвечу,
[02:42:13.340 --> 02:42:21.420]  да можем, но очень интересен вопрос как, потому что этот awaitable, task или еще что-либо,
[02:42:21.420 --> 02:42:27.740]  он может нам к нам прийти из другой библиотеки, а другая библиотека уже написана и менять мы ее
[02:42:27.740 --> 02:42:36.860]  не можем. Соответственно, то, что мы здесь разбираем, это типа минимальный в простоте пример
[02:42:36.860 --> 02:42:45.020]  всего этого, а в жизни нужно немножко все усложнить, чтобы была возможность поддержать какие-то штуки из
[02:42:45.020 --> 02:42:52.100]  других библиотек, которые тоже хочется объявить с sender. Ну и, так сказать, вопрос на подумать,
[02:42:52.100 --> 02:42:58.740]  чем кто заинтересован, а лучше погуглить, как это сделать? Вообще, замечание чертовски правильное,
[02:42:58.740 --> 02:43:04.100]  потому что если мы пишем что-то максимально абстрактное, да, ну то есть оперируем какими-то
[02:43:04.100 --> 02:43:10.180]  такими абстрактными сущностями, то, разумеется, чтобы потом можно было на них плавно перейти в
[02:43:10.180 --> 02:43:15.900]  любом промышленном козе, нам нужно иметь возможность сочетать наш framework, ну вот просто уже с внешними
[02:43:15.900 --> 02:43:21.500]  библиотеками, которые какую-то функциональность реализуют, поэтому мы хотим, чтобы связи было
[02:43:21.500 --> 02:43:26.820]  поменьше, чтобы не нужно было менять объявления, менять типы, которые мы используем, которых мы
[02:43:26.820 --> 02:43:34.340]  дожидаемся, в частности, в корутине. Ну вот, по счастью, здесь все довольно декомпозировано,
[02:43:34.340 --> 02:43:42.660]  не то что довольно декомпозировано, и нам не нужно знать про конкретные особенности реализации,
[02:43:42.660 --> 02:43:50.260]  нам нужно иметь какие-то концепты, ну и адаптеры для них, в общем-то, и все. Ну,
[02:43:50.260 --> 02:43:58.380]  мой поинт скорее про то, что мы сейчас говорим, что sender должен иметь метод connect, так? Вот,
[02:43:58.380 --> 02:44:04.700]  а как мы метод connect допишем в другую библиотеку? Мы его не допишем. Ну а что мешает адаптер написать,
[02:44:04.700 --> 02:44:11.380]  я пока не понимаю в чем фундаментальная сложность. А неудобно, тогда придется фасад для
[02:44:11.380 --> 02:44:17.860]  всей библиотеки писать. А вот авторы STD execution умудрились сделать так, что этого делать не
[02:44:17.860 --> 02:44:26.620]  нужно. Не нужны адаптеры, не нужны фасады, просто много хитростей, вот, которые я предлагаю погуглить.
[02:44:26.620 --> 02:44:32.980]  Разве не нужно просто написать, ну, адаптера произвольного evitable, который будет, соответственно,
[02:44:32.980 --> 02:44:43.540]  в коннекте сохранять, условно evitable, не запуская его, а дальше в старте. Это правда,
[02:44:43.540 --> 02:44:49.140]  вот если только для evitable достаточно, да, вот по такой логике, как ты начал говорить, вот да,
[02:44:49.140 --> 02:44:56.780]  можно написать, но помимо evitable в библиотеках бывают другие механизмы конкурентности какие-то
[02:44:56.780 --> 02:45:02.540]  модели, которые могут быть не evitable, у них могут быть свои представления о том, как нужно писать
[02:45:02.540 --> 02:45:09.140]  конкурентный код. Вот, и утверждается, что STD execution позволяет все это универсально очень легко
[02:45:09.140 --> 02:45:19.100]  превратить в, ну, почти очень легко превратить нужные нам сущности в сендеры. Вот, ну, и интересно,
[02:45:19.100 --> 02:45:26.380]  как они этого добились, какой ценой. То есть, еще раз, адаптеры не нужны для того механизма,
[02:45:26.380 --> 02:45:31.540]  которые они придумали. Можно прямо с голыми типами, которые в библиотеке есть, работать,
[02:45:31.540 --> 02:45:37.540]  но это удобнее, да, когда код не измазан кучей адаптеров, и можно напрямую там в дебагере
[02:45:37.540 --> 02:45:44.220]  посмотреть, что за тип, и не нужно постоянно после вызова библиотечной функции еще оборачивать
[02:45:44.220 --> 02:45:51.460]  ее в адаптерах или писать целый фасад для библиотеки. Вот, ну, Рома большой поклонник
[02:45:51.460 --> 02:45:57.780]  Unifex, сложно ему отказать в его антидиазме. Я лишь замечу, что дизайн все же очень сложный,
[02:45:57.780 --> 02:46:04.140]  ну, то есть, он очень точный, потому что он позволяет, ну, то есть, он вот максимально
[02:46:04.140 --> 02:46:13.300]  аккуратно описывает все, делит на какие-то такие уже совсем уж неделимые атомы, но, ну,
[02:46:13.300 --> 02:46:20.940]  прямо скажем, иногда кажется, что он слишком точен, и цена за эту точность, она тоже некоторая
[02:46:20.940 --> 02:46:25.460]  имеется, но это можно почувствовать скорее на своем опыте, я сейчас не хочу навязывать
[02:46:25.460 --> 02:46:31.100]  какое-то мнение, я говорю скорее, что автору Unifex существует его оптимальным решением,
[02:46:31.100 --> 02:46:37.980]  ну, а вы можете, ну, вот у вас уже за курс сложилось какое-то количество решений,
[02:46:37.980 --> 02:46:43.740]  задачи выражения конкуренции, вот, хорошо бы, чтобы вы попробовали написать своими
[02:46:43.740 --> 02:46:50.660]  руками разные механизмы и почувствовать какой из них нравится вам больше, ну,
[02:46:50.660 --> 02:46:58.980]  какой он просто удобнее, эргономичнее, оптимальность и там zero cost это одна из целей,
[02:46:58.980 --> 02:47:05.060]  но это в общем не единственная цель, есть, ну, не то что не цель, а вот не единственные критерии,
[02:47:05.060 --> 02:47:10.500]  единственная шкала, по которой можно что-то измерять, может быть вы готовы к чему-то
[02:47:10.500 --> 02:47:20.020]  менее эффективному, но более простому, не знаю, в общем, это скорее самый детализированный,
[02:47:20.020 --> 02:47:25.420]  самый абстрактный дизайн, к которому мы пришли, мы вот разделили, декомпозировали еще больше
[02:47:25.420 --> 02:47:28.820]  сущностей, которые у нас уже были к этому моменту, и вот получили все эти сендеры,
[02:47:28.820 --> 02:47:35.580]  ресиверы, операцион стейта, которые были раньше неявными и какими-то конкретными классами,
[02:47:35.580 --> 02:47:39.940]  а теперь они вот такие абстрактные сущности и уже можно на этом уровне как-то их
[02:47:39.940 --> 02:47:48.740]  комбинировать, то есть стало еще сложнее. Ну что ж, спасибо вам, что вы пришли сегодня в
[02:47:48.740 --> 02:47:57.140]  воскресенье, послушали, в следующий раз мы поговорим про structured concurrency, видимо,
[02:47:57.140 --> 02:48:08.940]  про то, чем наша функция Go, которую мы пишем в Fiber'ах, похожа на Go 2 из языков программирования,
[02:48:08.940 --> 02:48:13.140]  почему Go 2 это не очень хорошо, наверное вы догадываетесь, почему, но еще раз проговорим,
[02:48:13.140 --> 02:48:19.020]  и почему, видимо, Go не очень хорош. Через две недели мы с вами поговорим,
[02:48:19.020 --> 02:48:25.860]  наверное, про какое-то занятное lock-free, про мультикассы, про какие-то структуры данных,
[02:48:25.860 --> 02:48:32.980]  про задачу lock-free канал, про lock-free канал для Fiber'ов, который мы напишем,
[02:48:32.980 --> 02:48:41.340]  ну не lock-free мы напишем, мы напишем со спинлоками, но попробуем написать в мае. И у нас остается,
[02:48:41.340 --> 02:48:46.820]  кажется, третье-последнее занятие, на нем мы подведем итог всему курсу, соберем вместе все,
[02:48:46.820 --> 02:48:53.300]  что мы делали, и мы это постараемся еще собрать вместе на уровне библиотеки, на уровне отдельной
[02:48:53.300 --> 02:49:00.900]  задачи, прям вот все подзадачи, которые мы решали, мы соберем вместе и попробуем это все скомпилировать,
[02:49:00.900 --> 02:49:06.220]  пройти тест, ну для тех, кто решит разные задачи. Поэтому я очень рекомендую вам потратить на это
[02:49:06.220 --> 02:49:12.900]  силы, потратить оставшееся время для того, чтобы попробовать разные и потом совместить. Все,
[02:49:12.900 --> 02:49:19.180]  спасибо вам большое, до встречи через неделю, в следующую субботу. Вопросы, да. Вопрос, а можно ли
[02:49:19.180 --> 02:49:24.660]  как-то найти вот код про sender и receiver в свободном доступе, потому что... Который вот на этой лекции
[02:49:24.660 --> 02:49:30.740]  пишется. Который мы на этих лекциях писали, да. Да, так есть же репозиторий курса, есть репозиторий
[02:49:30.740 --> 02:49:37.100]  курса, а в нем в редми есть ссылка на репозитории, которые вот там по пути мы, с которыми мы работаем
[02:49:37.100 --> 02:49:45.340]  в разных занятиях. Там их возможно нужно актуализировать, я их актуализирую, и там можно будет найти.
[02:49:45.340 --> 02:49:53.060]  Вот для библиотекса тоже интересно почитать, много нового про C++ узнаешь, конечно его понять
[02:49:53.060 --> 02:50:00.980]  весь так на втором курсе сразу невозможно, надо долго и тщательно вчитываться. Вот, но куча новых открытий
[02:50:00.980 --> 02:50:06.900]  совершаетесь. Ну что ж, если вопросы закончились, то тогда прощаемся с вами, до встречи в следующую
[02:50:06.900 --> 02:50:13.100]  субботу. До свидания, спасибо, до свидания. Счастливо. До свидания.
