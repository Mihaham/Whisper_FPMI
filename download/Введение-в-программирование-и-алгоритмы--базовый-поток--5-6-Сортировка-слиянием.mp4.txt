[00:00.000 --> 00:09.360]  Давайте с вами вообще вспомним, что мы проходили на алгоритмах. На алгоритмах мы с вами проходили
[00:09.360 --> 00:20.720]  несколько вещей. У нас была аннотация, амбратизационный анализ и сортировки.
[00:20.720 --> 00:27.280]  Сортировки мы успели пройти всего 4-3 из них квадратичные. Это не очень круто, так что нам
[00:27.280 --> 00:31.280]  нужно нагонять. У нас будет очень много сортировок еще впереди, как минимум две.
[00:31.280 --> 00:42.760]  Нам необходимо их доделать и досмотреть, что это такое. Давайте с вами начнем с такого
[00:42.760 --> 00:51.280]  небольшого повторения. Какие виды сортировок бывают? Я имею в виду, чем они могут отличаться и
[00:51.280 --> 01:03.920]  что было бы круто что-то делать. Давайте сделаем подзаголовок виды сортировок.
[01:09.240 --> 01:15.120]  Количество обменов. Количество обменов действительно мы ведем, но для видов сортировок
[01:15.120 --> 01:22.000]  необходимы немножко другие штуки. Первое. Какой есть вид сортировки? Она называется
[01:24.000 --> 01:29.320]  in-place сортировка. Это сортировки
[01:34.920 --> 01:41.560]  ну или просто алгоритмы. На самом деле можно применять это слово к любым, не только к сортировкам,
[01:41.560 --> 01:59.320]  которые не используют дополнительные хранилища.
[01:59.320 --> 02:15.720]  По факту для вас как это можно интерпретировать? Интерпретируется это очень просто, что используется
[02:15.720 --> 02:31.240]  только swap. Вот. Это первый момент какая бывает сортировка. Вторая. Это без доп памяти.
[02:31.240 --> 02:48.400]  Доп. Смотрите. Без доп памяти подразумевает, что мы используем максимум у от единички памяти.
[02:48.400 --> 03:06.400]  У от единицы памяти. Скажите мне, входит ли создание нового массива в создание памяти,
[03:06.400 --> 03:12.640]  создание каких-то новых переменных? Вот создание новой переменной. Это сколько памяти занимает?
[03:12.640 --> 03:22.560]  У от единички. У от единички. А создание массива размера n? У от n. Хорошо. А теперь вопрос.
[03:22.560 --> 03:34.240]  Ну теперь вопрос будет следующий. У нас есть quick sort, правда? Quick sort надеюсь вы все помните.
[03:34.880 --> 03:47.200]  Мы его проходили не зря. Quick sort использует ли доп память? Кажется, что нет. А quick sort что делает внутри себя?
[03:47.200 --> 03:54.800]  Он вызывает что-то рекурсивно, правда? И у нас образуется стэк вызовов. Вы это проходили на языке.
[03:54.800 --> 04:02.000]  То есть когда мы рекурсивно вызываем сами себя функцию, у нас появляется так называемый стэк вызовов.
[04:02.560 --> 04:11.360]  Стэк вызовов, где мы начинаем что-то раскручивать. У нас есть этот вот вызов, у нас есть функция f от 10,
[04:11.360 --> 04:20.800]  которая вызывает f от 5 и f от 7, но я просто рандомные числа пишу и так далее. И этот стэк вызов
[04:20.800 --> 04:29.280]  он хранится, потому что кто зачем идет. Это тоже доп память. Поэтому quick sort это in-place сортировка,
[04:29.680 --> 04:37.280]  потому что она внутри использует только свопы и не выделяет никакой доп памяти именно для массива
[04:37.280 --> 04:43.680]  там какого-нибудь. Но она использует доп память, потому что она использует внутри себя рекурсию.
[04:43.680 --> 04:49.200]  Именно в том виде, в котором мы писали. Если вы напишете не рекурсивном случае, тогда это будет
[04:50.800 --> 04:57.760]  без доп памяти. Любую рекурсию можно заменить циклом. Правда, надо иногда постараться, чтобы
[04:57.760 --> 05:03.440]  это сделать. И третий важный пункт у сортировок это стабильность.
[05:10.240 --> 05:16.720]  Стабильность. Что это означает? Это означает следующее. Представьте, что у меня есть какой-то
[05:16.720 --> 05:27.200]  массив А0, АИТ, АЖИТО и АН-1, к примеру. И мы с вами это сортируем и получаем там какие-то
[05:27.200 --> 05:33.680]  вот такие вот штуки. Тут П от нуля. П, я имею ввиду, это просто перестановка какая-то. То есть мы
[05:33.680 --> 05:40.320]  взяли и переставили элементы между собой. И так далее. Я получил здесь АП от И, к примеру,
[05:42.320 --> 05:53.280]  АП от ЖИ. Так вот в чем суть. Если у меня АИТ равно АЖИТОМУ и И меньше чем ЖИ, то это
[05:53.280 --> 06:01.560]  влечет за собой, что перестановка ИТ-го элемента меньше, чем перестановка ЖИТ-го элемента. Что под
[06:01.560 --> 06:08.160]  этим подразумевается? Представьте следующее. У меня есть массив, ну к примеру, там не знаю,
[06:08.160 --> 06:32.720]  0-2-3-2-2-4-1. Вот так. Я хочу это отсортировать. Если я получаю 0-1-2-2-3, то это стабильная
[06:32.720 --> 06:58.920]  сортировка. Стабильная. Если я получаю 0-1-2-2-2-3, то это нестабильная. Вот что такое стабильная
[06:58.920 --> 07:04.520]  сортировка. То есть еще раз, мы говорим о том, что если у нас элементы одинаковые по какому-то
[07:04.520 --> 07:09.760]  признаку, то это стабильная сортировка, значит нестабильная. Вам сейчас может показаться странно,
[07:09.760 --> 07:17.120]  зачем мне двоечки обозначают там, к примеру, отдельно считаю разные двоечки. Но представьте
[07:17.120 --> 07:23.280]  следующее. Вот вы написали структуру, у вас там есть фамилия, у вас есть там оценка за контрольную,
[07:23.280 --> 07:29.880]  еще что-нибудь. Вы берете и отсортировали, к примеру, всех там по фамилии. У кого-то сошлись фамилии,
[07:29.880 --> 07:36.360]  и вы в разном порядке можете делать. У кого-то вы сначала отсортировали так, потом вы решили
[07:36.360 --> 07:43.680]  отсортировать по оценкам за контрольную, например, и вы хотите, чтобы они шли в нужном вам порядке. То
[07:43.680 --> 07:49.760]  есть в том моменте, как они сдавали контрольную, так можно, к примеру, списывания найти. Вот как
[07:49.760 --> 07:54.080]  они сдавали друг за дружкой. Вот если у них ответ одинаковый, и у них одинаковая оценка за
[07:54.080 --> 07:58.880]  контрольную, то, возможно, они списывали, а, возможно, не списывали. Но здесь все равно вопрос. И мне важно
[07:58.880 --> 08:07.000]  стабильность в этом все. Мне нужно здесь как-то оценить. И поэтому стабильная сортировка – это
[08:07.000 --> 08:16.520]  хорошо. И это неплохо. Вот. Таким образом, у нас есть вот такие вот три категории, которые мы можем
[08:16.520 --> 08:26.440]  как-то говорить об этом все. Смотрите, у нас с вами были сортировки какие? Квадратичные.
[08:26.440 --> 08:33.120]  И мы здесь кое-что ведем еще новое. Были квадратичные сортировки.
[08:33.120 --> 08:50.920]  И был пока только QuickSort. Смотрите, квадратичные сортировки, они все у нас… Смотрите, пузырек
[08:50.920 --> 08:59.600]  использовал только Swap. При курсе никакой не было. Давайте здесь мы разделим пузырек.
[08:59.600 --> 09:16.520]  Пузырек. Выбор. Ставки. Для них всех они являются без доп памяти. То есть ничего из этого не требовало
[09:16.520 --> 09:23.280]  никакой дополнительной памяти. Ни рекурсивной из остека вызов, ни какой-то вводить еще определенной.
[09:23.280 --> 09:34.680]  Поэтому они все без доп памяти. Но есть еще одно важное свойство этих всех сортировок. Это
[09:34.680 --> 09:41.760]  количество Swap. Количество Swap, которое возможно. То есть в среднем сколько количество Swap. И на самом
[09:41.760 --> 09:48.280]  деле, вот здесь вот сортировка выбора выигрывает абсолютно у всех, потому что здесь достаточно N,
[09:48.280 --> 10:00.920]  то есть тут O от N Swap. У пузырька количество Swap, O от N квадрат. А у вставок тоже O от N квадрат,
[10:00.920 --> 10:07.160]  потому что мы все время перекидываем и Swap элемент, просто двигая его. В среднем это N квадрат.
[10:07.160 --> 10:27.360]  Что касается QuickSort. QuickSort он in place, но с доп памятью. Именно для рекурсии. Это первое. Второе.
[10:27.360 --> 10:45.600]  Количество Swap здесь в среднем. Это O от N log N. Количество Swap. А теперь стабильность.
[10:45.600 --> 10:55.120]  Пузырьковая может нам гарантировать стабильность. В принципе, выбором точно
[10:55.120 --> 10:59.880]  гарантирует нам стабильность. Если мы первый минимум двигаем, то если есть такой же минимум
[10:59.880 --> 11:07.120]  дальше, то мы его встретим только позже и Swap'нем только позже. Вставками тоже нам может гарантировать
[11:07.120 --> 11:19.320]  стабильность. То есть они все еще и стабильные. А вот QuickSort все зависит от того, как он написан.
[11:19.320 --> 11:25.480]  По факту он чаще всего нестабилен. В плане написания, смотря что вы напишете,
[11:25.480 --> 11:33.480]  как именно сделаете. Если вы поставите знак меньше, либо равно, либо меньше. Вот подумайте,
[11:33.480 --> 11:44.480]  что из этого стабильное, а что нестабильное. Это то, что касается стабильности. Она может быть
[11:44.480 --> 12:01.760]  стабильной. Но не всегда. А теперь важный вопрос. Верно ли следующее утверждение любую
[12:01.760 --> 12:20.840]  сортировку? Даже те, которые мы еще не прошли. Сортировку можно сделать стабильней.
[12:20.840 --> 12:41.600]  Верно ли это утверждение? Как вы считаете? Да. Да, почему? Иначе бы не спрашивали. Люблю такое.
[12:41.600 --> 12:48.280]  На самом деле, да, действительно можно любую сортировку сделать стабильной. Каким образом?
[12:48.280 --> 12:54.320]  Достаточно нам ввести следующую штуку. Пусть у нас сортируются не просто элементы,
[12:54.320 --> 13:12.280]  а иты. А иты вместе с парой и. И если у нас элементы, и если у нас а ит равно ажитом и и,
[13:12.280 --> 13:24.760]  то тогда мы сортируем по и и ж, что меньше. То есть еще раз, если у нас элементы а иты равны
[13:24.760 --> 13:31.080]  ажитом, то есть как раз равны наши элементы, это может быть по любому признаку равным. Не
[13:31.080 --> 13:34.600]  обязательно говорить, что мы говорим только лишь о числах. Это любые элементы могут быть.
[13:34.600 --> 13:44.440]  То мы сортируем для стабильности по и и ж, если они у нас будут равны. Это понятно?
[13:44.440 --> 13:57.840]  Или непонятно? Видимо понятно. Можно вопрос? Я не совсем понимаю. Я помню,
[13:57.840 --> 14:03.680]  мы когда проходили сортировки за n квадрат, вы говорили, что средний случай это худший случай.
[14:03.680 --> 14:09.000]  Там действительно средний случай это худший случай, потому что нам никак не влияло,
[14:09.000 --> 14:18.560]  для нас никак не влияло именно сама суть свопов. То есть у нас из-за неопределенности ничего не
[14:18.560 --> 14:23.760]  происходило. То есть все случаи были равны друг для дружки. Для квиксорта это не так,
[14:23.760 --> 14:31.760]  к примеру. То есть там рандомный случай может разделить мне массив на 1 и n-1 элементов,
[14:31.760 --> 14:37.920]  а вот в пузырек он всегда будет пройдется один раз по массиву и свопнет что сможем.
[14:37.920 --> 14:42.600]  Понятно. И там такой же случай будет. Вот и все. Спасибо.
[14:42.600 --> 14:51.760]  Понятно. Как стабилизировать квиксорт? Нам надо еще сортировать кусочки.
[14:51.760 --> 14:59.840]  Представь, ты сделаешь структуру. Структуру, где у тебя будет помимо самого числа еще и индекс этого
[14:59.840 --> 15:07.840]  числа. И ты сортируешь структуры. У тебя было, если аи меньше ожито, то ты там свапал,
[15:07.840 --> 15:12.880]  к примеру, в квиксорте. Правильно? А здесь тебе необходимо проверить структуру,
[15:12.880 --> 15:27.080]  если структура a.data меньше, чем b.data. А внутри еще один ик. Если a.data равно,
[15:27.080 --> 15:33.920]  ну точнее дополнительных, если они равны, то ты сравниваешь их индексом. Все, ты доводишь
[15:33.920 --> 15:44.840]  дополнительные сравнения. Понятно? Вот. Это то, что касается сортировок. Есть ли к этому вопроса?
[15:46.840 --> 16:00.600]  Надеюсь, что нет. Больше. Поверно. Окей. Тогда мы переходим к сегодняшней сортировке. И это
[16:03.920 --> 16:22.520]  сортировка. Слияние. Слияние. Сейчас, а можно еще вопрос, вот эти индексы и ожи,
[16:22.520 --> 16:31.680]  это которые в процессе меняются или изначально? Изначально. Изначально массив, у тебя шла первая
[16:31.680 --> 16:40.320]  двойка до второй двойки. Я понял. Сортировка слиянием. Сортировка слиянием. Очень полезная
[16:40.320 --> 16:44.560]  сортировка, на самом деле. И вы сейчас узнаете скоро почему. Сейчас, момент.
[16:48.560 --> 16:59.120]  Что касается сортировки слиянием. У нее есть просто несколько принципов, по которым она работает.
[16:59.120 --> 17:10.880]  Давайте первое, что там необходимо сделать, это просто мерч. Давайте я напишу. По-английски это
[17:10.880 --> 17:29.520]  мерч-сорт. У данной сортировки есть один главный метод. Как у QuickSort был partition,
[17:29.520 --> 17:38.240]  здесь есть один метод, который нам необходимо будет описать. Он называется мерч. Слияние. Слияние
[17:38.240 --> 17:49.640]  двух массивов, которые уже отсортированы. А и Б. И нам необходимо из того, что мы их замерчили,
[17:49.640 --> 18:00.840]  получить отсортированный массив С. Я так изображаю, типа отсортирован по возрастам. Вот. Как это
[18:00.840 --> 18:08.120]  сделать? Давайте представим, что у нас, ну не представим, а у нас вот есть мерч. Нам необходимо
[18:08.120 --> 18:14.040]  отсортировать два элемента. Ну, точнее отсортировать это так, чтобы у нас получился большой-большой
[18:14.040 --> 18:21.000]  массив. Как я могу делать? Ну, давайте сначала сделаем это на примере, после чего напишем
[18:21.000 --> 18:32.840]  псевдокод. Пусть у меня есть массив один, три, восемь. И есть массив два, четыре, два, два, четыре.
[18:32.840 --> 18:43.680]  Сейчас подумаю, пусть будет девять, например. Вот. Как нам отсортировать? Мы с вами строим массив С.
[18:43.680 --> 18:54.280]  Массив С. У нас здесь три элемента и три элемента. Если их по три элемента, то мы с вами берем и делаем.
[18:54.280 --> 19:02.080]  У нас суммарный массив будет из шести элементов. А так как они отсортированы по возрастанию,
[19:02.080 --> 19:10.920]  нам достаточно сравнивать только лишь первые два элемента. И вести указатель на эти элементики.
[19:10.920 --> 19:18.200]  Я сравниваю первые два элемента. Какой из них меньше? Один или два? Естественно, один меньше,
[19:18.200 --> 19:26.600]  и я его записываю в массив С. После чего двигаю этот указатель. И теперь оно меня на три и два.
[19:26.600 --> 19:34.280]  Я сравниваю опять два и три, наши элементы. Два меньше, поэтому я вставляю эту двойку вот сюда.
[19:34.280 --> 19:43.800]  И двигаю здесь уже указатель. Сравниваю три и четыре. Дальше у нас три. И опять двигаю указатель.
[19:43.800 --> 19:54.120]  Потом у нас четыре. Потом у нас восемь. И потом у нас девять. То есть смотрите,
[19:54.120 --> 19:59.880]  мы идем по отсортированным частям, начиная с самого начала. Там самые наименьшие элементы
[19:59.880 --> 20:06.840]  в этих массивах. Мы предполагаем, что эти массивы уже отсортированы. И просто их пытаемся слить между
[20:06.840 --> 20:16.320]  собой. Для того, чтобы их слить, достаточно пройти у одного и у второго. Просто линейно. Линейно пройтись
[20:16.320 --> 20:22.760]  по двум данным кускам, и тогда мы сможем записать наш массив. На примере понятно,
[20:22.760 --> 20:28.400]  как работает сам мерч. Чудно. Тогда давайте напишем наш псевдопод.
[20:28.400 --> 20:33.560]  Попрос. Массивы AB всегда должны быть одинаковых размеров, да?
[20:33.560 --> 20:44.640]  Не обязательно. Ну, давайте тогда еще один пример сделаем. Пусть у меня есть восемь, есть один,
[20:44.720 --> 20:56.560]  три, пять. Мне нужен массив из четырех элементов. Раз, два, три. Я беру указатель здесь, беру указатель
[20:56.560 --> 21:04.040]  здесь. Вставляю сюда единичку. Двигаю указатель. Три меньше восьми. Все еще вставляю тройку.
[21:04.040 --> 21:12.840]  Потом двигаю еще раз указатель. Пятерка. Пятерку вставляю вот сюда. Пять. А только потом восемь.
[21:12.840 --> 21:20.120]  Тоже я смог смёртвить. Где без разницы какая длина массива? Сортировать отдельные массивы
[21:20.120 --> 21:27.200]  кликсортом. Сейчас мы до этого дойдем. Давайте сначала мерч рассмотрим. А нам все равно, да,
[21:27.200 --> 21:32.880]  они оба сортированы одинаково или один по возрастанию, другой по убыванию? В смысле,
[21:32.880 --> 21:40.120]  они все должны быть одинаковы по возрастанию. Ну, по неубыванию давайте так скажем. Могут быть
[21:40.120 --> 21:52.760]  одинаковыми. Понятно? Да. Хорошо, тогда продолжаем. Нам нужно написать вообще наш... Как же реализовать
[21:52.760 --> 22:00.800]  стабильность? Ну, то есть что там будет элементом порядка? Чего ж вы так сильно вперед-то идете?
[22:00.800 --> 22:15.400]  Давайте сейчас все проверим. Все посмотрим. Давайте напишем псевдокод на эту операцию мерч.
[22:15.400 --> 22:23.560]  Мерч нам возвращает наш с. Правильно? То есть он возвращает какой-то массив, который мы хотим
[22:23.560 --> 22:38.040]  как раз увидеть. Окей, тогда в этот мерч мы с вами передаем массивы а и b. Вот. Давайте введем индекс,
[22:38.040 --> 22:49.040]  что у меня и... Давайте, чтобы не запутаться, и а равно и b, равно и c, равно нулю. Но мы начинаем
[22:49.040 --> 23:06.800]  с самого начала. Да? Друзья. И а, и b, и c, это у вас указатель на начало массива? Это указатель на
[23:06.800 --> 23:27.040]  начало массива, да. Все указатели начало массива. Вот. После чего я говорю пока и а меньше, чем а, и...
[23:27.040 --> 23:33.360]  Это имеется ввиду количества элементов, я думаю вы понимаете, правда? Ну, то есть количество элементов
[23:33.360 --> 23:44.080]  и и b меньше, чем b. Ну, то есть мы идем до конца массива. То в этом случае что мы делаем? Мы говорим,
[23:44.080 --> 24:03.360]  что если у нас массив а от и а меньше, либо равен, чем массив b от и b, то в этом случае мы делаем
[24:03.360 --> 24:23.200]  что? Мы говорим, что c от и c, равно а от и а. Ну и увеличиваем и c, и и а. То есть это будет и c, равно и c, плюс 1.
[24:23.200 --> 24:32.640]  Я напишу так, но просто в одну строчку, чтобы у меня поместилось. И и а, равно и а, плюс 1. То есть я
[24:32.640 --> 24:49.640]  двигаю эти указатели. Все, чудно. Иначе, иначе, я говорю, что c от и c, равно b от и b. То есть смотрите,
[24:49.640 --> 24:58.040]  если у меня элемент а, элемент из а, меньше либо равен, чем элемент из b, то я вставляю в c наш
[24:58.040 --> 25:06.160]  элемент из а. Иначе, я вставляю из b. То есть я просто сравниваю первые элементы и иду этими указателями.
[25:06.160 --> 25:22.520]  Ну и здесь у меня и c, равно и c, плюс 1. И а, о и b, равно и b, плюс 1. А ведь можно увеличение и c просто
[25:22.520 --> 25:35.480]  вынести за if. Вместо того, чтобы писать и в if, и в else. Можно. Можно. Пожалуйста. Вот. Скажите мне,
[25:35.480 --> 25:46.240]  это весь мерч, который нам нужен или нет? Это не весь мерч, который нам нужен. Если у нас остались
[25:46.240 --> 25:54.200]  элементы в каком-то измножестве. Да, нам надо написать. Остались ли элементы действительно в каком-то
[25:54.200 --> 26:01.360]  измножестве? Это очень важно понимать, что вообще там происходит. То есть давайте сейчас я здесь сбоку
[26:01.360 --> 26:11.200]  нарисую. Представьте, вот у меня есть массив а, и у меня вот есть массив b. Я получаю сюда массив
[26:11.280 --> 26:18.560]  c. Причем самое начало, предположим, я вставил, ну вот, то есть вот до этого момента, я вставил вот так.
[26:18.560 --> 26:27.680]  У меня и а, меньше а, уже не работает. А вот это все заполнено. Значит, мне надо всю часть b вставить
[26:27.680 --> 26:35.640]  в c. Аналогично будет, если у меня в а останется какая-то часть, мне нужно доставить ее в c. То есть
[26:35.640 --> 26:56.960]  я здесь дополнительно должен написать. While и а меньше а, c и c равно а и а.
[26:56.960 --> 27:13.280]  И c равно и c плюс один, и а равно и а плюс один. И естественно для b. То есть смотрите, если одно из
[27:13.280 --> 27:18.400]  этого не выполняется, мы перейдем к другому while. Иначе мы просто проверили, ну типа ничего страшного.
[27:18.400 --> 27:45.200]  While здесь у нас и и b меньше чем b, c и b равно b и b, и c равно и c плюс один, и b равно и b плюс один.
[27:45.200 --> 27:50.840]  Почему c и b? Ой, c и c, да. Спасибо.
[27:55.320 --> 28:05.480]  Так, есть ли вопросы к самому мерджу? Получается, в данном примере указатель это номер элемента
[28:05.480 --> 28:12.080]  массива. Это индекс. Индекс последнего элемента, который не сволкнут. Ну, точнее, не взят массив c.
[28:12.200 --> 28:24.560]  Еще вопросы? Видимо нет вопросов. Хорошо, у нас с вами есть мердж.
[28:24.560 --> 28:33.920]  Окей, мердж у нас с вами есть. Теперь необходимо вообще отсортировать наш массив. А что же нам
[28:33.920 --> 28:42.720]  как его делать и отсортировать? Смотрите, мне как-то один раз сказали, мердж sort это
[28:42.720 --> 28:48.640]  сортировка оптимистов. Почему? Потому что все считают, что у нас массив не отсортированный,
[28:48.640 --> 28:54.640]  его нужно отсортировать. А мердж sort считает, что у нас каждый элемент отсортированный, уже все
[28:54.640 --> 29:00.240]  хорошо и мы можем с этим работать. Именно в этом и будет заключаться сама суть. Представьте
[29:00.240 --> 29:12.560]  следующее, у меня есть массив. У меня есть массив из чиселок. Каждый из чисел, давайте его как-нибудь
[29:12.560 --> 29:25.040]  запомним, 1, 3, минус 1, 0, 5, 7, 3, 4, 9. Но мы его можем разбить на n под массивов. Мы его можем
[29:25.040 --> 29:50.960]  разбить на кучу ячеек таких. 1, 3, минус 1, 0, 5, 7, 3, 4, 9. Смотрите, мы разбили кучу под массивов,
[29:51.920 --> 30:00.160]  и каждый из них, каждый из них у нас отсортирован. Сам для себя я всегда отсортирован. То есть я есть,
[30:00.160 --> 30:08.400]  ну типа вот один элемент, он всегда считается упорядоченным между собой. Чудно, тогда это
[30:08.400 --> 30:16.600]  означает, что у меня этот кусок и этот кусок отсортированы, значит я могу их объединить в один
[30:16.600 --> 30:25.720]  большой кусочек. И тогда в этом случае я получу элемент уже из двух чисел. Дальше объедини
[30:25.720 --> 30:32.480]  другие кусочки. Здесь получу минус 1, 0. У меня так получилось, что они все в нужном порядке идут.
[30:32.480 --> 30:45.680]  Давайте что-нибудь, ну ладно, буду зачеркивать, потом мы разъединим. У нас потом 5, 7. Здесь 3,
[30:45.680 --> 30:55.280]  4. А здесь 9 так и осталось. Ну оставим его 9. У нас появились новые кусочки. Чудно,
[30:55.280 --> 31:02.640]  тогда давайте их объединять. Мы опять их объединяем с помощью мерджа. 1, 3, минус 1,
[31:02.640 --> 31:08.960]  0. Минус 1 меньше 1. Да, действительно, поэтому будет минус 1. Потом у нас идет 0,
[31:08.960 --> 31:17.720]  потом у нас идет 1, а потом у нас идет 3. Потом я обвиняю два этих кусочка. У нас здесь будет
[31:17.720 --> 31:31.240]  3, 4, 5, 7. А 9 все так же несчастное идет понемножку. Просто одна. Потом я объединяю
[31:31.240 --> 31:51.120]  вот эти куски, получая здесь уже отсортированный массив. Здесь у нас будет минус 1, 0, 1, 3, 3, 4, 5,
[31:51.120 --> 32:00.880]  и 7, и 9. Все еще несчастная одна. И после этого мы уже вместе их объединим, и девятка наконец-то
[32:00.880 --> 32:14.680]  обретет свое место в этом массиве. Сейчас, момент, побольше его сделаем. Вот так. Вот,
[32:14.680 --> 32:29.680]  то есть здесь у нас будет массив минус 1, 0, 1, 3, 3, 4, 5, 7, и 9. Таким образом я получаю отсортированный
[32:29.680 --> 32:35.200]  массив. То есть я вначале должен разбить все на кусочки, потом мерджить друг за дружкой все это.
[32:35.200 --> 32:42.880]  Это лучше всего делать рекурсивно. Рекурсивно, и тогда у нас будет какой-то стек вызовов. Конечно
[32:42.880 --> 32:50.520]  же. То есть у нас будет использоваться какая-то доп память, но пока это выглядит так. Однако,
[32:50.520 --> 32:57.680]  смотрите, в чем вся еще проблема? В том, что мы создаем новый массив C. Когда мы создаем
[32:57.680 --> 33:04.240]  с вами новый массив C, у нас все очень грустно в том плане, что мы очень много памяти можем
[33:04.240 --> 33:09.440]  израсходовать. По факту, мы каждый раз, в первом этапе, когда у нас 2 элемента, у нас их тоже мержатся.
[33:09.440 --> 33:18.080]  На первом этапе, когда объединяются 2 элемента. 2 элемента объединяются, это естественно тоже мерч.
[33:18.080 --> 33:29.880]  То есть это все мерч. Давайте, я сделаю небольшое пояснение. Это мерч. Это мерч. Ну, для всех
[33:29.880 --> 33:41.600]  остальных аналогично. Это мерч. И это мерч. То есть мы просто берем все мерчем. У нас все
[33:41.600 --> 33:50.920]  с вами хорошо получается. Класс. А можно вопрос? Да. А вот где девятки, там тоже мерч? Да. Спасибо.
[33:50.920 --> 33:58.040]  Когда мы добавляем один элемент, мы тоже его мерчим. Вот. И таким вот образом мы с вами
[33:58.040 --> 34:10.240]  получаем. А имеет ли смысл добавлять в мерч в конце дилиты A и B массивов? Смотрите,
[34:10.240 --> 34:17.520]  вот здесь все и начинается как раз таки. Эта сортировка с лиянием требует памяти. Причем
[34:17.520 --> 34:22.360]  памяти каждый раз у от N. То есть сколько у нас здесь элементов хранится? У нас здесь было N
[34:22.360 --> 34:29.800]  элементов, стало N пополам массивов и суммарно их количество равно N. То есть каждый раз мы должны
[34:29.800 --> 34:40.640]  выделять N памяти. Поэтому эта сортировка работает с O от N памяти. O от N памяти.
[34:40.640 --> 34:50.760]  А почему O от N тут же получается выделяется на каждом уровне рекурсии правильно? Да. Тут же
[34:50.760 --> 34:59.800]  каждый раз. Смотрите, здесь вопрос в том, что вы считаете дополнительной памятью. Если вы
[34:59.800 --> 35:09.480]  очищаете все вот эти элементики 1, 3, минус 1, 0, 5, 7, 3, 4, 9. Если вы их уничтожаете, то у вас в
[35:09.480 --> 35:19.520]  какой-то момент максимум до памяти используется O от N. Понятно? Вот. То есть еще раз. У вас в один
[35:19.520 --> 35:27.040]  момент времени должно быть два слоя только. Этого достаточно для решения этой задачи. После этого мы
[35:27.040 --> 35:34.040]  верхний слой очищаем и на основе него делаем третий слой. N же элементов. Правильно?
[35:36.560 --> 35:46.040]  За какую скорость работает Merge? Сейчас. Ну что ж такое-то? Сейчас расскажу. То есть нам в
[35:46.040 --> 35:54.960]  Merge надо дописать еще очистку вот этого первого слоя. Я пишу псевдокод. А ну то если вы не псевдокоде,
[35:54.960 --> 36:03.720]  там очистка есть. Конечно. Но если только ты надзаб или C sharp не пишешь, тогда. Вот. Третий
[36:03.720 --> 36:11.880]  слой создается за счет первого. Что еще раз? Вы сказали, что третья срочка создается за счет
[36:11.880 --> 36:23.440]  первой с точки. То есть вы имеете в виду то, что первое очищается, освобождается место для третьей.
[36:23.440 --> 36:35.920]  Поэтому памяти O от N дополнительно. Помимо этого, смотрите. Какова глубина вот этого чуда?
[36:35.920 --> 36:49.280]  Кто мне скажет? Кто понимает? Третий по основанию 2 от N? Да. Ну то вверх мы должны округлить.
[36:49.280 --> 36:58.560]  Но порядок такой. Выгорифм от N. Выгорифм двоично. Вот. Таким образом мы каждый раз с вами берем и
[36:58.560 --> 37:05.360]  делаем сколько сравнений. Давайте сравним. На первой стадии мы сравниваем каждый элемент с каждым.
[37:05.360 --> 37:15.440]  И это сравнение. И потом еще вставляем это. То есть каждый уровень занимает у нас. Ну вот
[37:15.440 --> 37:29.880]  первый уровень как минимум. Занимает нас с вами. Второй уровень аналогично. Третий тоже. И так
[37:29.880 --> 37:36.680]  далее. То есть каждый раз мы с вами вставляем по элементу. И мы суммарно вставляем сколько новых
[37:36.680 --> 37:46.040]  элементов. N. Таким образом мы делаем это от N действий. А сравниваем мы сколько раз. Смотрите,
[37:46.040 --> 37:57.920]  если у меня объединяется массив A и B. Они делают merge. C. То в этом случае у меня количество
[37:57.920 --> 38:12.600]  сравнений это тета от A плюс B. Потому что мы сравниваем каждый элемент из первого массива и
[38:12.600 --> 38:17.960]  сравним с каждым элементом. Ну каждый элемент из первого массива мы хотя бы один раз используем.
[38:17.960 --> 38:29.960]  Каждый элемент из второго. Получается он в общее время это тета от N на log N. Н log N. Именно
[38:29.960 --> 38:37.600]  такова работа merge сорта. То есть смотрите, каждое действие тетн количество действия log N. Суммарно
[38:37.600 --> 38:46.920]  тета от N log N. Ну либо можно написать O от N log N. Чаще всего пишто просто в силу обозначений. Но
[38:46.920 --> 38:56.200]  здесь и в среднем и в общем и в худшем случае всегда у нас будет N log N действий. То есть время
[38:56.200 --> 39:14.280]  работы. Время работы от N log N. Время. То есть здесь нет очень сложной математики. Достаточно
[39:14.280 --> 39:20.320]  просто вот именно порисовать и сказать сколько у нас будет уровней и сколько мы действие делаем
[39:20.320 --> 39:26.000]  на каждом из них и из них. Сколько мы сравнений делаем для получения этого уровня. Каждый раз у
[39:26.000 --> 39:38.760]  нас будет тета от N. Вот этот от N уменьшается количество элементов. У нас уменьшается количество
[39:38.760 --> 39:44.480]  массивов. Да, количество массивов уменьшается. А вот количество элементов этих массивов
[39:44.480 --> 39:52.640]  увеличивается. Вот сколько элементов вот на этом уровне, на третьем? Девять. Девять. А на первом?
[39:52.640 --> 40:00.400]  Тоже девять. Получается, что мы должны вставить все равно эти девять элементов. Да, спасибо.
[40:01.400 --> 40:11.480]  Можно еще раз про память? Почему-то это от N. Про память. Еще раз. Для хранения первого
[40:11.480 --> 40:18.200]  это N элементов, правильно? Да. Для хранения второго куска сколько необходим элементов?
[40:18.200 --> 40:26.520]  Сколько памяти необходимо? Массивов раз меньше. Массивов. Памяти сколько? Памяти столько же.
[40:26.520 --> 40:37.400]  Столько же N, да? После этого я предыдущую ветку удаляю, правда? И я ее перекидываю в нижнюю,
[40:37.400 --> 40:44.400]  а на следующем мне опять надо N элементов. То есть каждый раз мне надо два N памяти для массива
[40:44.400 --> 40:52.200]  из N элементов. Понятно? Да. Вот. А можете, пожалуйста, напомнить, чем тета от пола большого отличается?
[40:56.520 --> 41:04.720]  Сейчас скажу. Если у меня есть функция F, я могу зажать с какими-нибудь функциями вот
[41:04.720 --> 41:13.440]  такими вот. А это F, это G, это C1 на G, это C2 на G. И вот если я могу зажать такими
[41:13.440 --> 41:27.280]  функциями, то F это тета от G. Если я могу лишь ограничить сверху свое F каким-то C от G,
[41:27.280 --> 41:38.040]  любым. Ну почти любым. Существует такое C, что оно ограничивает F. То в этом случае, давайте
[41:38.040 --> 41:51.720]  вот так расчерю, то в этом случае F это O'G. Понятно? Да. Отлично. Окей. Еще вопросы к Мёртвому.
[41:51.720 --> 41:58.040]  Какое? Вот количество операций, там где log2N, мы округляем в большую сторону,
[41:58.040 --> 42:03.080]  это для ничего отночного случая нужно, да? Ну если у тебя степень двойки, ну представь,
[42:03.080 --> 42:09.440]  у тебя не степень двойки, вот тут девятка так идет вниз. Они всегда так и будут идти вниз. То
[42:09.440 --> 42:14.720]  есть тебе необходимо по-хорошему, чтобы понять сколько здесь действий, до степени двойки добить,
[42:14.720 --> 42:25.280]  и тогда ты получишь правильный результат, если без округления. Понятно. Еще раз, а почему лопаты?
[42:25.280 --> 42:36.040]  Каждый раз мы уменьшаем количество элементов в два раза. Правда? Вот. Все. Мы уменьшаем количество
[42:36.040 --> 42:41.920]  этих массивчиков в два раза, если берем на степень двойки. Ну вот она, типа вот они, восемь
[42:41.920 --> 42:49.960]  элементов. Видишь? Да. Оно уменьшается в два раза, то есть было восемь элементов, стало четыре,
[42:49.960 --> 42:57.960]  потом два, потом один. Мы все время на два делим, поэтому логариф. И потом еще добавляем,
[42:57.960 --> 43:04.480]  который не вошел в степень двойки. Да, если бы мы добились здесь до степени двойки, было бы
[43:04.480 --> 43:10.720]  шестнадцать элементов, к примеру, то у нас было бы ровно, потому что это девятка объединялась ровно
[43:10.720 --> 43:18.160]  как вот эти элементы слева. Ясно? Да, спасибо. Отлично. Еще есть вопросы какие-то к мерджу?
[43:18.160 --> 43:29.800]  Хорошо. Теперь перейдем к самой сортировке вообще. Как это выглядит? Сама сортировка
[43:29.800 --> 43:35.720]  заключается на рекурсии как раз таки тоже. Она рекурсивно начинает сама себя вызывать и в какой-то
[43:35.720 --> 43:46.400]  момент делать мердж. Делается это достаточно просто. И здесь важно понимать вообще, а что
[43:46.400 --> 44:05.520]  происходит, иначе вы можете запутаться. Значит, смотрите. Что делает мердж? У нас есть такой мердж,
[44:05.560 --> 44:16.760]  нам необходимо рекурсивно его вызвать. MergeSorts вообще сам по себе. Мы туда передаем что? Мы
[44:16.760 --> 44:26.240]  передаем туда массив и количество элементов, к примеру, в этом массиве. То есть это все,
[44:26.240 --> 44:33.080]  что нам нужно. Но просто количество в принципе нормально, если вы пишете,
[44:33.080 --> 44:40.760]  ну если я пишу псевдокода, то есть вы сейчас поймете почему. То есть у меня есть такой вот
[44:40.760 --> 44:52.920]  MergeSort. И что я делаю? Я делаю условия остановки. Если у меня там, к примеру, n равно 1, то есть
[44:52.920 --> 45:05.840]  один элемент, то вернуть. Иначе, что я делаю? Я говорю, что здесь вот сложно мне просто так это
[45:05.840 --> 45:16.840]  сказать, как это правильно вам написать. Ну давайте так. B и C. B это у нас элементы. B это у нас
[45:16.840 --> 45:34.760]  A от 0 до n пополам. C это элементы A от n пополам до n минус 1. Понятно, что я имею в виду?
[45:34.760 --> 45:45.080]  Ну я делю массив пополам. А почему не AB, если мы скроем обозначение из мерджа,
[45:45.080 --> 45:52.760]  которое написали? Ну хорошо, давайте AB, пожалуйста. Просто я A маленько использовал,
[45:52.760 --> 46:06.000]  думал, что вас это спутает. 2 из 2 пуска. Так, и что я с ними делаю? Я должен с ними как раз
[46:06.000 --> 46:13.040]  таки сделать так, чтобы они мерджились. Но они могут мерджиться только, начиная после того,
[46:13.040 --> 46:20.800]  как разделятся на единички. Почему мы n минус 1 не включили? Да, кстати. Ой, да, спасибо.
[46:26.920 --> 46:32.800]  То есть, что мы делаем? Мы здесь должны вызывать рекурсивно наш Merge Sort.
[46:32.800 --> 46:37.120]  Merge Sort.
[46:37.120 --> 46:46.920]  От чего? От A и n пополам. Merge Sort.
[46:46.920 --> 46:49.680]  Merge Sort.
[46:49.680 --> 46:55.360]  От B и n пополам. И Merge.
[46:55.360 --> 46:58.680]  Чего?
[46:58.680 --> 47:01.920]  A и B.
[47:01.920 --> 47:05.240]  A и B, да?
[47:05.240 --> 47:16.840]  Merge Sort работает просто. Он делит пополам, доходит до одного и начинает их мерджить между собой.
[47:16.840 --> 47:21.760]  Этого достаточно. Понятно?
[47:21.760 --> 47:26.480]  У нас какая-то ошибка. Почему у нас Merge A и B? Это же два массива.
[47:26.480 --> 47:31.760]  А у нас должно быть функция 1 указательный массив и еще и n.
[47:31.760 --> 47:34.880]  Merge. Подожди.
[47:34.880 --> 47:35.880]  А, все, понял.
[47:35.880 --> 47:41.480]  Merge. Вот, таким образом получается Merge Sort.
[47:41.480 --> 47:51.000]  А если у нас нечетная качество элементов, то у нас Merge Sort B и n пополам. Там же не n пополам элементов.
[47:52.000 --> 47:56.720]  А какая разница? У меня Merge работает для любых количеств.
[47:56.720 --> 48:02.880]  Я поняла. Мы вторым аргументом передам количество элементов. Правильно?
[48:02.880 --> 48:08.040]  Хорошо. Здесь тогда должно быть n равно 1 или n равно 0.
[48:08.040 --> 48:10.040]  А, все, понятно. Хорошо.
[48:10.040 --> 48:17.560]  Я правильно понимаю, что мы не передаем в Merge размеры A и B в силу того, что это псевдокод?
[48:17.560 --> 48:18.560]  Да.
[48:19.400 --> 48:21.600]  Вообще, по-хорошему, как это должно делаться?
[48:21.600 --> 48:29.880]  То есть, смотрите, если вы говорите о коде на плюсах, то этот код должен выглядеть как передача массива.
[48:29.880 --> 48:34.760]  И здесь должна быть левая граница, правая граница и серединка.
[48:34.760 --> 48:47.200]  И вот здесь Merge должен использовать левую половину, а левую часть серединку и от серединки до правой части ровно как в Quick Sort.
[48:48.720 --> 48:53.320]  То есть, вы как будто бы не делите массив, не присваиваете A и B.
[48:53.320 --> 48:57.520]  Но я в силу того, что мы Merge так написали, я уже так пишу. Понятно?
[49:00.280 --> 49:01.280]  Все.
[49:02.520 --> 49:10.680]  Вот, но это не все про Merge Sort. Смотрите, обладает ли Merge вообще стабильностью?
[49:10.680 --> 49:13.000]  Давайте вернемся чуть-чуть назад.
[49:13.000 --> 49:17.000]  Обладает ли этот Merge стабильностью?
[49:17.080 --> 49:18.080]  Да.
[49:20.920 --> 49:31.400]  Потому что мы сначала, в случае равенства, мы сначала записываем элементы из A, а потом из B.
[49:31.400 --> 49:38.920]  Да, то есть, смотрите, у нас элементы A идут до B, поэтому вот это условие – это гарантия стабильности.
[49:41.560 --> 49:42.560]  Стабильность.
[49:47.160 --> 49:58.400]  А стабильность нам гарантирует, когда мы будем, ну, не знаю, сортировать какие-нибудь определенные структуры и так далее.
[49:58.400 --> 50:03.600]  Это достаточно полезно, чтобы вот если вы напишете меньше, то это будет уже нестабильная сортировка.
[50:03.600 --> 50:10.200]  Поэтому за этим иногда надо следить, какие вы знаки им напишете, иначе будет все плохо. Понятно?
[50:10.200 --> 50:17.800]  Так, смотрите, давайте сделаем еще один пяти-минутный, нет, давайте десяти-минутный перерыв.
[50:17.800 --> 50:26.800]  Вот, ну, то есть, мы как бы час и перерыв десять минуток, потому что иначе вы на следующем умрете.
[50:26.800 --> 50:29.800]  Что нас ожидает? Давайте я просто сразу скажу.
[50:29.800 --> 50:36.800]  Нас ожидает все также сортировка, но следующего вида.
[50:37.400 --> 50:49.400]  Это in-place merge, который вам придется реализовать потом в домашке точно где-нибудь.
[50:49.400 --> 50:53.400]  In-place merge, что он сделает?
[50:53.400 --> 50:59.400]  In-place merge будет мержить без дополнительной памяти только рекурсия.
[50:59.400 --> 51:03.400]  Только рекурсия ему понадобится, то есть там будет память немного по-другому.
[51:03.400 --> 51:09.400]  И еще важный момент, как вы думаете, вот количество свопов когда-нибудь играет очень важную роль?
[51:11.400 --> 51:12.400]  А в чем?
[51:12.400 --> 51:16.400]  Ну, вот у нас есть сортировки, к примеру.
[51:16.400 --> 51:22.400]  У нас есть сортировки, играет ли там важную роль количество свопов, или это просто так, типа вы придумали и все?
[51:22.400 --> 51:27.400]  Ну, количество свопов, оно достаточно сильно влияет на симпозицию.
[51:27.400 --> 51:32.400]  Да, оно может этот коэффициент очень сильно влиять.
[51:32.400 --> 51:41.400]  И вот один раз была задачка на межнаре такая, что там нужно было то ли отсортировать две структуры,
[51:41.400 --> 51:43.400]  но там надо было это применить, короче.
[51:43.400 --> 51:50.400]  И по итогу все пытались сделать какую-то быструю сортировку, а нужен был коэффициент.
[51:50.400 --> 51:52.400]  Сортировку выбором надо было сделать.
[51:52.400 --> 51:57.400]  Она работает за N квадрат, но зато у нее свопов всего N.
[51:57.400 --> 52:01.400]  Это немного, потому что N лог N не заходило.
[52:01.400 --> 52:05.400]  Вот, так что аккуратнее с тем, когда вы какую сортировку применяете.
[52:05.400 --> 52:08.400]  Даже квадратичные сортировки очень полезны.
[52:08.400 --> 52:09.400]  Окей.
[52:09.400 --> 52:10.400]  Так.
[52:10.400 --> 52:11.400]  Вот.
[52:11.400 --> 52:12.400]  Вот.
[52:12.400 --> 52:15.400]  Так что аккуратнее с тем, когда вы какую сортировку применяете.
[52:15.400 --> 52:18.400]  Даже квадратичные сортировки очень полезны.
[52:18.400 --> 52:19.400]  Окей.
[52:19.400 --> 52:20.400]  Так.
[52:20.400 --> 52:23.400]  Смотрите, одно важное уточнение.
[52:23.400 --> 52:27.400]  То, что я написал про Merge Sort, вообще как он выглядит.
[52:27.400 --> 52:30.400]  Там есть одна фатальная ошибка.
[52:30.400 --> 52:35.400]  Если кто-то из вас ее поймет, то все будет хорошо, когда вы будете ее писать.
[52:35.400 --> 52:37.400]  Какая ошибка?
[52:37.400 --> 52:38.400]  Я сделаю вам подсказку.
[52:38.400 --> 52:42.400]  То есть смотрите, Merge сам по себе написанный.
[52:42.400 --> 52:49.400]  Но Merge Sort возвращает у нас с вами так-то то, как он должен выглядеть.
[52:49.400 --> 52:52.400]  Какую-то цель.
[52:52.400 --> 52:53.400]  Вот.
[52:53.400 --> 52:55.400]  И надо понять, куда его вставить.
[52:55.400 --> 52:58.400]  Вот это вам небольшое задание надо.
[52:58.400 --> 53:01.400]  Относительно того, как это сделать.
[53:01.400 --> 53:05.400]  На следующей лекции по алгоритму я, естественно, вам напишу, как это должно выглядеть.
[53:05.400 --> 53:07.400]  Но подумайте, пожалуйста, самостоятельно.
[53:07.400 --> 53:11.400]  Вот на тем, как нам совместить вообще Merge.
[53:11.400 --> 53:16.400]  А теперь поехали говорить про In-Place Merge.
[53:16.400 --> 53:19.400]  Что такое In-Place Merge?
[53:19.400 --> 53:24.400]  Мы с вами говорили, что In-Place Sort это та, которая не требует памяти в каком-то хранилище.
[53:24.400 --> 53:26.400]  То есть просто не выделяется память просто так.
[53:26.400 --> 53:32.400]  То есть там не нужно создавать массив C, в котором мы будем класть результат.
[53:32.400 --> 53:34.400]  Как же это делать?
[53:34.400 --> 53:39.400]  Ну, здесь важный момент.
[53:39.400 --> 53:50.400]  Давайте мы, во-первых, предположим, что у нас есть, как в обычном Merge, два отсортированных кусочка.
[53:50.400 --> 53:53.400]  Два отсортированных кусочка.
[53:53.400 --> 53:58.400]  А и Б.
[53:58.400 --> 54:04.400]  Но в памяти они идут в подряд.
[54:04.400 --> 54:20.400]  То есть если мы возьмем, к примеру, A объединенное с B, то они идут за другом.
[54:20.400 --> 54:24.400]  Элементы я имею в виду.
[54:24.400 --> 54:31.400]  Это хорошо и это классно, потому что, в принципе, мы так Merge и делали.
[54:31.400 --> 54:34.400]  Но смотрите, что я имею в виду.
[54:34.400 --> 54:38.400]  В обычном Merge мы строили вот такую вот штуку.
[54:38.400 --> 54:45.400]  Но согласитесь, никто мне не мешал вот этот пятый элемент с девятым, например, совместить и оставить третий без всего.
[54:45.400 --> 54:48.400]  То есть мы могли совмещать вообще любые два элемента.
[54:48.400 --> 55:00.400]  Сейчас я буду требовать то, что мы будем Merge именно соседние элементы, а потом соседние массивы, а потом соседние еще другие массивы и так далее.
[55:00.400 --> 55:06.400]  Это важно понимать, что вот именно в этом будет заключаться первое свойство Inplace Merge Short.
[55:06.400 --> 55:10.400]  Мы хотим, чтобы эти элементы шли друг за другом.
[55:10.400 --> 55:13.400]  Это первое, что нам необходимо.
[55:13.400 --> 55:15.400]  Второе, что нам нужно.
[55:15.400 --> 55:22.400]  Нам нужно понимать, что такое Lower Bound, я его напишу LB, и Upper Bound.
[55:22.400 --> 55:34.400]  Скажите, точнее так, поднимите руку, тут есть такая функция, или напишите плюсик в чат те, кому не знакома бинарный поиск.
[55:34.400 --> 55:36.400]  Бинарный поиск.
[55:41.400 --> 55:42.400]  Понял.
[55:42.400 --> 55:44.400]  Не знаком.
[55:44.400 --> 55:46.400]  Не знаком.
[55:46.400 --> 55:50.400]  Видимо все плюсики ставят здесь, потому что знакомы, или представляют, что это.
[55:50.400 --> 55:51.400]  Но я сейчас расскажу.
[55:51.400 --> 55:55.400]  Смотрите, что касается бинарного поиска.
[55:55.400 --> 55:57.400]  Бинарный поиск.
[55:57.400 --> 56:00.400]  Представьте, у меня есть отсортированный массив.
[56:00.400 --> 56:06.400]  1, 3, 4, 6, 8.
[56:06.400 --> 56:10.400]  И мне нужно найти 6 в этом массиве.
[56:10.400 --> 56:12.400]  Как бинпоиск работает?
[56:12.400 --> 56:18.400]  Я сейчас объясняю просто сам алгоритм, не пишу его псевдокод, он не очень сложный, я думаю, вы справитесь.
[56:18.400 --> 56:22.400]  Мы берем средний элемент, так как массив отсортирован уже.
[56:22.400 --> 56:35.400]  Мы берем средний элемент и смотрим, если он больше нашего элемента, который мы ищем, то мы идем влево, потому что левее находятся все элементы меньше.
[56:35.400 --> 56:42.400]  Если он больше, чем элемент в серединке, то мы идем вправо.
[56:42.400 --> 56:44.400]  И рассматриваем уже эту часть.
[56:45.400 --> 56:47.400]  Первый у меня такой массив.
[56:47.400 --> 56:48.400]  1, 3, 4, 6, 8.
[56:48.400 --> 56:49.400]  6 больше 4.
[56:49.400 --> 56:54.400]  Поэтому я рассматриваю только оставшуюся часть.
[56:54.400 --> 56:57.400]  Оставшуюся часть у меня выглядит следующим образом.
[56:57.400 --> 57:01.400]  Это просто 6 и 8.
[57:01.400 --> 57:06.400]  В зависимости от того, как у вас написан бинпоиск, у вас может быть указатель либо на 6, либо на 8.
[57:06.400 --> 57:10.400]  Но если на 8, то 8 больше 6.
[57:10.400 --> 57:12.400]  Я ищу 6.
[57:12.400 --> 57:14.400]  8 больше 6.
[57:14.400 --> 57:16.400]  Поэтому я иду левее.
[57:16.400 --> 57:18.400]  И у меня остается только кусочек из 6.
[57:18.400 --> 57:21.400]  И таким образом я нашел этот элемент.
[57:24.400 --> 57:27.400]  Lower bound и upper bound от X.
[57:27.400 --> 57:29.400]  Что это такое?
[57:29.400 --> 57:34.400]  Lower bound от X это...
[57:34.400 --> 57:38.400]  Кто-то подключается, кто-то отключается, что такое?
[57:38.400 --> 57:42.400]  Lower bound от X это у нас...
[57:42.400 --> 57:46.400]  Первый элемент, который больше либо равен X.
[57:49.400 --> 57:56.400]  Первый элемент, который больше либо равен X.
[57:56.400 --> 58:00.400]  А вот upper bound это у нас...
[58:00.400 --> 58:01.400]  Что?
[58:01.400 --> 58:04.400]  Это первый элемент, строго больше X.
[58:08.400 --> 58:13.400]  Ну или давайте так, сейчас я скажу.
[58:13.400 --> 58:16.400]  Строго больше X.
[58:16.400 --> 58:18.400]  Ну вообще, наверное, да.
[58:18.400 --> 58:20.400]  Давайте так.
[58:20.400 --> 58:22.400]  Первый элемент...
[58:22.400 --> 58:24.400]  Больше либо равен X или меньше?
[58:24.400 --> 58:26.400]  Да, больше либо равен X.
[58:28.400 --> 58:33.400]  То есть смотрите, что такое upper bound и lower bound в моем случае.
[58:33.400 --> 58:36.400]  Давайте я это сотру пример.
[58:36.400 --> 58:38.400]  Сейчас нарисую другой.
[58:38.400 --> 58:40.400]  С одинаковыми какими-то элементами.
[58:42.400 --> 58:43.400]  Представьте следующее.
[58:43.400 --> 58:50.400]  У меня есть массив 1, 3, 3, 3, 4, 6, 8.
[58:50.400 --> 58:53.400]  Так вот lower bound от трех это вот это.
[58:53.400 --> 58:55.400]  Upper bound от трех это вот это.
[58:58.400 --> 59:01.400]  Lower bound, upper bound.
[59:04.400 --> 59:05.400]  Это понятно?
[59:05.400 --> 59:06.400]  Это понятно?
[59:08.400 --> 59:09.400]  Ну то есть...
[59:09.400 --> 59:11.400]  А разве не меньше либо равен?
[59:12.400 --> 59:14.400]  Первый элемент, где именно?
[59:14.400 --> 59:15.400]  Ты о чем?
[59:15.400 --> 59:17.400]  Lower bound, наверное.
[59:17.400 --> 59:18.400]  А, lower bound?
[59:18.400 --> 59:20.400]  Да, хорошо, меньше либо равен.
[59:20.400 --> 59:21.400]  Окей.
[59:25.400 --> 59:27.400]  Сейчас, момент.
[59:30.400 --> 59:32.400]  Тогда это последний элемент.
[59:32.400 --> 59:34.400]  Если таким образом...
[59:34.400 --> 59:35.400]  А, нет.
[59:35.400 --> 59:36.400]  Нет, все правильно.
[59:36.400 --> 59:38.400]  Это первый элемент больше либо равный.
[59:38.400 --> 59:39.400]  Вы меня запутали.
[59:45.400 --> 59:49.400]  Если такого элемента нет, то upper bound и lower bound совпадают.
[59:51.400 --> 59:52.400]  Всегда.
[59:56.400 --> 01:00:00.400]  Обычно вы обозначили один раз AP, а другой раз AB.
[01:00:01.400 --> 01:00:06.400]  Ой, upper bound, потому что я не умею в английском.
[01:00:07.400 --> 01:00:08.400]  Иногда.
[01:00:08.400 --> 01:00:11.400]  А upper bound и lower bound.
[01:00:12.400 --> 01:00:13.400]  Это пока понятно?
[01:00:15.400 --> 01:00:16.400]  Да.
[01:00:16.400 --> 01:00:17.400]  Чудно.
[01:00:20.400 --> 01:00:21.400]  Следующий момент.
[01:00:23.400 --> 01:00:25.400]  И теперь мы можем переходить вообще к in-place merger.
[01:00:26.400 --> 01:00:29.400]  У нас с вами есть два отсортированных куска.
[01:00:30.400 --> 01:00:34.400]  A и отсортированный B.
[01:00:40.400 --> 01:00:45.400]  В этом случае мы с вами говорим о следующем.
[01:00:46.400 --> 01:00:52.400]  Что in-place merge должен как-то соединить эти кусочки внутри себя
[01:00:52.400 --> 01:00:55.400]  и построить это C просто внутри.
[01:00:56.400 --> 01:01:00.400]  То есть не заводя новую память, не заводя что-либо,
[01:01:00.400 --> 01:01:03.400]  он должен внутри себя сделать.
[01:01:03.400 --> 01:01:06.400]  Для этого мы сделаем следующий шаг.
[01:01:07.400 --> 01:01:10.400]  Давайте я их рядышком нарисую, будет получше.
[01:01:14.400 --> 01:01:15.400]  Вот так.
[01:01:15.400 --> 01:01:18.400]  Они два отсортированных куска.
[01:01:18.400 --> 01:01:21.400]  Я выбираю в центре какой-то X.
[01:01:22.400 --> 01:01:28.400]  То есть X это у меня A от там N пополам в центре.
[01:01:30.400 --> 01:01:37.400]  Обозначу вот этот кусок это C1, вот этот кусок это C2.
[01:01:40.400 --> 01:01:41.400]  Они оба размером.
[01:01:42.400 --> 01:01:43.400]  Что еще раз?
[01:01:43.400 --> 01:01:44.400]  N это размер A.
[01:01:45.400 --> 01:01:46.400]  N это размер A, да.
[01:01:49.400 --> 01:01:51.400]  Давайте напишу это.
[01:01:52.400 --> 01:02:10.400]  N это у меня вот такой кусочек, и здесь у меня еще один кусочек.
[01:02:11.400 --> 01:02:12.400]  N пополам, извините.
[01:02:13.400 --> 01:02:14.400]  N пополам.
[01:02:16.400 --> 01:02:17.400]  И здесь N пополам.
[01:02:18.400 --> 01:02:31.400]  А дальше я выбираю границу, которая у меня является lower bound от X.
[01:02:34.400 --> 01:02:43.400]  И обозначаю эти кусочки как C1 и C3 и C4.
[01:02:44.400 --> 01:02:45.400]  Хорошо.
[01:02:50.400 --> 01:02:54.400]  Но смотрите, я все это могу делать при каких-то условиях.
[01:02:54.400 --> 01:02:58.400]  То есть мне нужны, вы понимаете, что у нас будет рекурсия впереди, я думаю.
[01:02:59.400 --> 01:03:05.400]  А это означает, что нам понадобится понять, ой, понадобится какое-то остановочное действие.
[01:03:06.400 --> 01:03:15.400]  Например, следующее, что если у меня A или B пустой, то у меня уже отсортировано все как надо?
[01:03:21.400 --> 01:03:22.400]  Ну, наверное, да.
[01:03:23.400 --> 01:03:24.400]  Ну, не наверное, а да.
[01:03:25.400 --> 01:03:28.400]  Представьте, у меня A пустой, а B уже отсортирован.
[01:03:29.400 --> 01:03:32.400]  Логично, что у нас оно отсортировано, правда?
[01:03:32.400 --> 01:03:46.400]  То есть я напишу здесь следующее, что если у меня размер A равен нулю или размер B равен нулю, то в этом случае я могу сделать сектор.
[01:03:49.400 --> 01:03:50.400]  И все.
[01:03:50.400 --> 01:03:52.400]  Как бы мне больше ничего не беспокоит.
[01:03:52.400 --> 01:03:57.400]  А lower bound, он первый элемент больше X где?
[01:03:57.400 --> 01:03:59.400]  То есть почему он находится в месте?
[01:03:59.400 --> 01:04:01.400]  Он меньше, он больше либо равен X.
[01:04:02.400 --> 01:04:03.400]  В B.
[01:04:03.400 --> 01:04:04.400]  Я ищу такой игрок.
[01:04:04.400 --> 01:04:05.400]  Больше или равен?
[01:04:05.400 --> 01:04:07.400]  А, в B?
[01:04:07.400 --> 01:04:08.400]  В B, в B.
[01:04:10.400 --> 01:04:11.400]  Вот.
[01:04:14.400 --> 01:04:15.400]  Следующий момент.
[01:04:15.400 --> 01:04:29.400]  Смотрите, если у меня A равно одному или, ой, и B равно одному, то есть если и в A, и в B находится один элемент, тогда что я делаю?
[01:04:30.400 --> 01:04:31.400]  Я просто проверяю.
[01:04:31.400 --> 01:04:40.400]  Если у меня A равен нулю или B равен нулю, то в этом случае я могу сделать сектор.
[01:04:41.400 --> 01:04:42.400]  То есть еще раз.
[01:04:42.400 --> 01:04:49.400]  Если у меня просто есть два элемента типа 5 и 3, то в этом случае я могу сделать сектор.
[01:04:49.400 --> 01:04:50.400]  А нулевое?
[01:04:50.400 --> 01:04:51.400]  А нулевое?
[01:04:51.400 --> 01:04:52.400]  А нулевое?
[01:04:52.400 --> 01:04:53.400]  А нулевое?
[01:04:53.400 --> 01:04:54.400]  А нулевое?
[01:04:54.400 --> 01:04:55.400]  А нулевое?
[01:04:55.400 --> 01:04:56.400]  А нулевое?
[01:04:56.400 --> 01:04:57.400]  А нулевое?
[01:04:57.400 --> 01:04:58.400]  А нулевое?
[01:04:58.400 --> 01:04:59.400]  А нулевое?
[01:04:59.400 --> 01:05:00.400]  А нулевое?
[01:05:00.400 --> 01:05:01.400]  А нулевое?
[01:05:01.400 --> 01:05:02.400]  А нулевое?
[01:05:02.400 --> 01:05:03.400]  И B?
[01:05:03.400 --> 01:05:04.400]  Нулевое?
[01:05:04.400 --> 01:05:11.400]  То есть еще раз, если у меня просто есть два элемента типа 5 и 3, вот они оба отсортированы.
[01:05:11.400 --> 01:05:14.400]  Вот это A, вот это B.
[01:05:14.400 --> 01:05:17.400]  То я их должен просто принять местами и получить 3, 5.
[01:05:17.400 --> 01:05:19.400]  Это тоже отсортированный кусок.
[01:05:19.400 --> 01:05:20.400]  Вот.
[01:05:20.400 --> 01:05:25.400]  Для этого я их свапаю между собой и все, и тоже возвращаю.
[01:05:25.400 --> 01:05:26.400]  То есть пишу тоже.
[01:05:26.400 --> 01:05:51.240]  Вот это я назову все условия окончания рекурсии, самые
[01:05:51.240 --> 01:05:53.480]  простые случаи с вами рассмотреть рекурсии.
[01:05:53.480 --> 01:06:00.280]  Вот, а теперь, а теперь мы с вами будем рассматривать следующее.
[01:06:00.280 --> 01:06:17.600]  Следующий момент. Пусть, пусть. У меня A больше, чем B. Ну,
[01:06:17.680 --> 01:06:26.520]  больше либо равен. Тогда я как раз смотрю на те разделения, которые до этого делал.
[01:06:26.520 --> 01:06:38.680]  Давайте я здесь еще раз повторю. У меня есть A, у меня есть B. Я здесь убираю элемент X,
[01:06:38.680 --> 01:06:54.080]  здесь убираю lower bound, lower bound от X и обозначаю C1, C2, C3, C4. Смотрите,
[01:06:54.080 --> 01:07:03.400]  о чем, что из этого я могу сказать. Если у меня X это просто серединка, то у меня здесь все
[01:07:03.400 --> 01:07:10.760]  элементы меньше либо равны X, правильно? А здесь больше либо равны X. Но я это могу
[01:07:10.760 --> 01:07:25.840]  гарантировать. C3 это lower bound, значит все элементы здесь меньше XA. Почему? Потому что X, ну,
[01:07:25.960 --> 01:07:32.720]  потому что граница у нас lower bound. Lower bound это первый из больше либо равных X.
[01:07:36.560 --> 01:07:43.120]  Понятно? Что люди начинают, как будто бы все плохо. Так,
[01:07:43.120 --> 01:07:54.520]  окей. У нас здесь меньше X. И у нас есть C4. И здесь, когда мы выбрали lower bound, у нас здесь будет
[01:07:54.520 --> 01:08:03.000]  больше либо равно XA. Ну, потому что lower bound убирается, там все элементы больше либо равны.
[01:08:03.000 --> 01:08:10.640]  Чисто из выбора lower bound. Таким образом у нас получились вот такие вот штуки. Вот.
[01:08:10.640 --> 01:08:22.360]  А более формально давайте сейчас это напишем. Что у нас X равно A от N. Ну, давайте я напишу
[01:08:22.360 --> 01:08:32.760]  NA делить на 2, чтобы вы понимали, что это количество элементов AA. Вот. А C1 это у нас
[01:08:32.760 --> 01:08:56.680]  A от нуля до NA пополам. C2 это у нас A от NA пополам до NA минус 1. Давайте напишу просто до
[01:08:56.840 --> 01:09:22.840]  NA и не возьму этот отрезок. C3 это у нас B от нуля до lower bound X. И C4 это у нас B от lower bound X до
[01:09:22.840 --> 01:09:31.520]  количество элементов B. Получается lower bound возвращает ID. Ну, это необходимые элементы.
[01:09:31.520 --> 01:09:39.640]  Индекс, да. Ну, то есть в этом плане индекс, да. Правда. Вот. Таким образом мы с вами поучили.
[01:09:39.640 --> 01:09:47.640]  А теперь давайте сделаем следующее. Мы хотим так, чтобы у нас все работало, все было классно,
[01:09:47.640 --> 01:09:55.560]  все было хорошо, к примеру. Вот. И нам необходимо это как-то отсортировать внутри себя, чтобы мы
[01:09:55.560 --> 01:10:04.600]  могли рекурсивно вызывать in-place merge. Для этого нам необходимо сделать какие-то кусочки,
[01:10:04.600 --> 01:10:12.200]  плюс-минус равные, которые будут разделены чем-то. Это будет очень похоже на quicksort. Почему? Потому
[01:10:12.200 --> 01:10:22.600]  что я хочу поменять местами, поменять местами C2 и C4. Что получу тогда в этом случае? Я получу
[01:10:22.600 --> 01:10:38.760]  следующее. У меня есть C1, у меня есть C2, у меня есть C3 и у меня есть C4. В этом случае у меня C1
[01:10:38.760 --> 01:10:45.360]  меньше либо равен XA, C2 меньше XA, C3 больше либо равен XA, C4 больше либо равен XA.
[01:10:54.640 --> 01:11:07.640]  А почему C2 меньше XA? Ой, извините, здесь C3, а здесь C2. Так. Так лучше? А, сейчас. Да,
[01:11:07.640 --> 01:11:17.120]  теперь да. Вот. Теперь все правильно. И смотрите, мы по факту разделили их от нашего XA. Просто вот
[01:11:17.120 --> 01:11:32.560]  здесь вот у нас встал на место наш X. Какой-то. Потому что он находится в самом начале C2. Все. То
[01:11:32.560 --> 01:11:43.440]  есть нам необходимо дописать вот этот псевдокод. Некий свод. Код C2 и C3. А почему X может быть в
[01:11:43.440 --> 01:11:54.800]  конце C1? Мы так выбрали. Ну, смотри, вот C2, это A, N, A пополам. Начинать. А то, что вы нарисовали,
[01:11:54.800 --> 01:12:01.840]  это будет типа A отсортированное или пока еще нет? Вот просто. Ну, вот он нарисовал C11, C3, C2, C4.
[01:12:01.840 --> 01:12:09.920]  Так, конечно же, отсортированное. А почему, если C2 все больше либо равно X и C4 больше,
[01:12:09.920 --> 01:12:16.960]  то как из этого следует, что там отсортированное? Смотри, A массив отсортированный. Ага. C1 и C2 это
[01:12:16.960 --> 01:12:25.960]  часть A. Идущий подряд. Да? Да. Ну, значит, C2 отсортированное. Ну да, но почему не может быть
[01:12:25.960 --> 01:12:33.040]  такое, что какой-то элемент из C2 больше, чем какой-то элемент из C4? Это может быть. Я не говорю о том,
[01:12:33.040 --> 01:12:43.840]  что X стал в серединку. Плюс-минус. Да, нам хочется. Вот. А после этого, после этого я рекурсивно
[01:12:43.840 --> 01:13:05.560]  вызову мой in place merge от C1, C3. То есть вот от этих двух кусочков. И вызову in place merge
[01:13:05.560 --> 01:13:21.480]  от C2 и C4. От этих вот кусочков. Можно вопрос? Как мы выбираем AX? Это первый элемент? То есть это
[01:13:21.480 --> 01:13:29.200]  первый такой элемент? То есть для чего мы пишем, что C1 меньше и равно X? Мы выбираем не первый X?
[01:13:29.200 --> 01:13:37.560]  Мы выбираем просто средний элемент из A. А, просто средний. Просто средний. Просто серединка. Вот у
[01:13:37.560 --> 01:13:45.720]  меня в начале написано X равно A от NA делить пополам. Это просто какой-то средний элемент. И смотрите,
[01:13:45.720 --> 01:13:55.080]  когда я буду вызывать вот такую вот внутреннюю, так сказать, буду вызывать эту рекурсию, у меня
[01:13:55.080 --> 01:14:00.920]  есть условия остановки, которые вот были написаны вот здесь. Ой, не вот здесь. Что у меня как-то он
[01:14:00.920 --> 01:14:08.880]  припрыгивает очень сильно. Я, видимо, плохо сделал. Ладно. Условия окончания рекурсии. То есть мы в
[01:14:08.880 --> 01:14:15.320]  начале пишем условия окончания рекурсии, а после этого тот, ту штуку, которую мы сделали вот здесь.
[01:14:15.320 --> 01:14:24.760]  А можете объяснить, что происходит с вот этим X, который мы нашли?
[01:14:24.760 --> 01:14:39.160]  Вот мы нашли. А почему он не будет относиться к C2? Нет, X у нас относится к C2. Но еще раз,
[01:14:39.160 --> 01:14:44.520]  ты вряд ли сможешь выбрать серединку так, что это будет первый элемент. Правда?
[01:14:44.520 --> 01:14:52.120]  Он всегда понял, почему она останется на месте. Ну, то есть у нас C1 не двигается. C1 остается на
[01:14:52.120 --> 01:14:59.720]  месте всегда. У нас между собой меняется C2 и C3. Зачем это вообще делается? Вот у нас было два
[01:14:59.720 --> 01:15:04.400]  сортированных, а получилось и ничего не отсортировано. Почему ничего не отсортировано?
[01:15:04.400 --> 01:15:11.520]  Мы с вами и косетили в середину относительно в этой X. Слева все меньше либо равно, справа все
[01:15:11.520 --> 01:15:20.400]  больше либо равно. Не напоминаешь? Все понятно. Окей, хорошо. И теперь мы вызываем рекурсивно от двух
[01:15:20.400 --> 01:15:29.440]  других частей, но это все равно merge sort. Почему это merge? Потому что у нас есть остановка рекурсии,
[01:15:29.440 --> 01:15:37.200]  похожая именно на слоп, где просто наслопаются два элемента. Мы с вами merge кусочки, маленькие,
[01:15:37.200 --> 01:15:42.880]  маленькие кусочки. Мы с вами просто берем и merge между собой для того, чтобы получить что-то
[01:15:42.880 --> 01:15:57.560]  что-то большое и отсортированное. Мы начинаем с малого. Что такое swap C2 и C3? Как происходит
[01:15:57.560 --> 01:16:08.120]  вообще сортировка? Точнее их просто swap между собой. Представьте, у меня есть массив A, к нему
[01:16:08.120 --> 01:16:14.840]  прибавлен массив B. И вот мне нужно сделать так, чтобы у меня получился массив B, а здесь массив A.
[01:16:14.840 --> 01:16:28.400]  Как это можно легко сделать? Кто-нибудь знает? Может как-то через указатель? Нет, здесь не надо
[01:16:28.400 --> 01:16:35.960]  прям через указатель. Есть вопрос. Зачем мы вообще делаем swap C2 и C3, если мы вызываем
[01:16:35.960 --> 01:16:48.440]  in-place merge C1-C3 и C2-C4? Потому что эти куски у тебя in-place merge работает только если кусочки
[01:16:48.440 --> 01:16:55.640]  находятся друг за другом. У нас будет условие, что они отсортированы и находятся друг за другом.
[01:16:55.640 --> 01:17:14.280]  Помнишь? Или нет? Меня спущает молчание. Я что-то напутал с этими штуками. В следующий раз
[01:17:14.280 --> 01:17:22.280]  буду лучше делать. У нас было два отсортированных куска и они идут друг за другом. Это было важное
[01:17:22.280 --> 01:17:27.920]  свойство. Мы не можем делать in-place merge для кусочков, которые не друг за дружкой,
[01:17:27.920 --> 01:17:38.280]  поэтому нам нужно поменять C2 и C3. Обязательно. Смотрите. Здесь же наверное реверс кусочков,
[01:17:38.280 --> 01:17:45.520]  а потом реверс всего массива. Можно так, а можно сначала реверс всего массива, а потом реверс
[01:17:45.520 --> 01:17:59.600]  кусочков. Смотрите. Первое решение всего этого – это реверс. Если это массив C, то это будет
[01:17:59.600 --> 01:18:07.760]  реверс. Давайте не C, а D, а то вы запутаетесь. Реверс D. Это пишется достаточно легко. Я думаю,
[01:18:07.760 --> 01:18:25.000]  вы понимаете, как до серединки дойти и свопать между собой. После этого реверс A и реверс B. Что
[01:18:25.000 --> 01:18:32.400]  под этим подразумевается? У меня есть A1, A2. Давайте на каком-нибудь простом примере. Лучше
[01:18:32.400 --> 01:18:43.040]  с чиселками. Думаю, так легче запоминается. У меня есть 3, 5, 6, 8, 1, 4, 3. Мне нужно получить
[01:18:43.040 --> 01:18:52.840]  1, 4, 3, 3, 5, 8, 3, 5, 6, 8. Я просто взял пока рандомные кусочки, просто как своп работает.
[01:18:52.840 --> 01:19:07.920]  Я реверсю все, получаю 3, 4, 1, 3, 4, 1, 8, 6, 5, 8, 3. После этого я должен зареверсить
[01:19:07.920 --> 01:19:15.660]  каждый из кусочков. Я сначала реверсю A, это получаю 3, 6, 5, 8, и реверсю B – это 1,
[01:19:15.660 --> 01:19:26.060]  3, 1, 4, 3. Получил. Понятно, как это работает? Там разве не 3, 5, 6? Как осуществляется реверс?
[01:19:26.060 --> 01:19:44.780]  3, 5, 6, 8. Как осуществляется реверс? 4 int i равное 0, i меньше чем n пополам,
[01:19:44.780 --> 01:20:11.020]  plus plus i swap a, i, t, i, a, i, t, n, minus i, minus 1. Есть ли еще какие-то вопросы?
[01:20:11.020 --> 01:20:19.900]  Да, можете еще раз повторить, почему C2 и C3 мы не можем in-place merge местами поменять,
[01:20:19.900 --> 01:20:27.740]  почему нам нужен именно этот swap. Так, в смысле еще раз, почему C2 и C3…
[01:20:27.740 --> 01:20:35.020]  C3 мы именно swap'ом, а не in-place merge. А как мы можем in-place merge поставить его в нужное место?
[01:20:35.020 --> 01:20:44.500]  Смотрите, еще раз, у нас есть 4 кусочка. Нужно C3 и C2 поменять местами,
[01:20:44.500 --> 01:20:48.340]  чтобы слева стояло все меньше либо равное x, справа все больше либо равное x.
[01:20:48.340 --> 01:21:01.780]  Это непонятно или понятно? Нет, это понятно. Но мы же знаем границы C2 и C3.
[01:21:01.780 --> 01:21:08.420]  А, типа как swap сделать эти кусочки? Нет, swap – это я понял, вы сейчас говорили
[01:21:08.420 --> 01:21:14.100]  про реверс. А почему нельзя in-place merge сделать от C2 и C3?
[01:21:14.100 --> 01:21:19.860]  Еще раз, in-place merge работает для кусочков, которые идут друг за другом.
[01:21:19.860 --> 01:21:26.380]  Да, они идут друг за другом. У нас массива IBA идут друг за другом,
[01:21:26.380 --> 01:21:31.540]  C23 отсортированы. В чем проблема? Почему нельзя in-place merge применить? Правда?
[01:21:31.540 --> 01:21:40.420]  Давайте еще раз, я не понял вопроса тогда. Смотрите, у нас A и B идут друг за другом.
[01:21:40.420 --> 01:21:44.420]  Да. Получается C3 идет за C2.
[01:21:44.420 --> 01:21:49.580]  Да. Вот, у нас C2 и C3 тоже в принципе отсортированы.
[01:21:49.580 --> 01:21:53.220]  Да. Часть A и B. Почему нельзя
[01:21:53.220 --> 01:21:57.420]  использовать in-place merge для C2 и C3, чтобы поменять их местами?
[01:21:57.420 --> 01:22:05.580]  Он отсортирует C2 и C3, где C3 – это все меньше X, а C2 – это все больше либо равно X.
[01:22:05.580 --> 01:22:12.500]  А зачем, если ты точно знаешь, что C3 меньше X, а C2 больше либо равно X?
[01:22:12.500 --> 01:22:18.140]  Ну, то есть ты точно знаешь, что C2 больше либо равно X, а C3 меньше?
[01:22:18.140 --> 01:22:23.980]  Ты знаешь, что они не на своих местах. Да, и поэтому я in-place merge как раз
[01:22:23.980 --> 01:22:32.900]  поставлю все элементы C3 влево, а C2 вправо. А кто сказал, что ты их сможешь поставить in-place merge?
[01:22:32.900 --> 01:22:39.300]  Ну, типа, либо я не понимаю, что ты именно хочешь сделать, либо зачем нам нужно вызывать
[01:22:39.300 --> 01:22:47.180]  in-place merge C2-C3, в принципе, если мы точно уверены, что в C2 больше либо равно X, в C3 меньше X.
[01:22:47.180 --> 01:22:52.700]  Мы их так поменяем местами. Мы отсортируем часть C2-C3.
[01:22:52.700 --> 01:23:00.300]  Для того, чтобы менять местами, типа, in-place merge, для чего мы делаем?
[01:23:00.300 --> 01:23:06.220]  Потому что мы не знаем, как внутри что устроено. Мы не представляем, у нас нет представления об этом.
[01:23:06.220 --> 01:23:13.580]  C2 и C3, по факту, мы знаем об их представлении, что один меньше X, а другой больше либо равно X.
[01:23:13.580 --> 01:23:18.180]  И C2 еще и начинается с X. Да, я на основе этого как раз делаю вывод,
[01:23:18.180 --> 01:23:21.740]  что все элементы C3 встанут влево, а C2 вправо от X.
[01:23:21.740 --> 01:23:28.700]  А если ты будешь делать in-place merge? Или просто merge?
[01:23:28.700 --> 01:23:35.540]  Какой ты будешь делать там? От C2 и C3.
[01:23:35.540 --> 01:23:42.340]  In-place merge? Да, они идут друг за другом, сами по себе отсортированы.
[01:23:42.340 --> 01:23:46.220]  У нас все условия для in-place merge, они соблюдены.
[01:23:46.220 --> 01:23:51.700]  Получается, результатом как раз будет C3 и C2 наоборот.
[01:23:51.700 --> 01:23:55.860]  Объясни мне зачем? Сколько работает?
[01:23:55.860 --> 01:23:59.660]  Вы поменять их местами. Вместо swap сделать in-place merge.
[01:23:59.660 --> 01:24:03.980]  Ты понимаешь, сколько работает in-place merge? Нет еще.
[01:24:03.980 --> 01:24:11.060]  Но в этом вся проблема. Ты очень сильно загрубишь еще больше свою программу. Почему?
[01:24:11.060 --> 01:24:14.220]  Потому что in-place merge и так работает за NLogin.
[01:24:14.220 --> 01:24:20.100]  Все, вот теперь понятно. Swap нужен для корридии.
[01:24:20.100 --> 01:24:26.500]  Работает за OTN. Понятно? Ну типа понятно почему за OTN хотя бы.
[01:24:26.500 --> 01:24:37.500]  Вот. Поэтому здесь мы используем эту штуку.
[01:24:37.500 --> 01:24:44.700]  In-place merge. Смотрите. То есть он для A и B. Что? Еще раз вопрос.
[01:24:44.700 --> 01:24:50.700]  Мы low bound и up bound реализуем через bin поиск. Да.
[01:24:50.700 --> 01:24:55.420]  Но это обычный bin поиск, просто там надо понять меньше или больше уровня.
[01:24:55.420 --> 01:24:57.700]  Ну, меньше или меньше уровня. Ну, типа такого.
[01:24:57.700 --> 01:25:02.940]  Вопрос связанный с этим. А если мы не найдем такой элемент LBX?
[01:25:02.940 --> 01:25:08.820]  То есть, например, вот у нас есть массив, состоящий из девятки, а другой массив условно 1, 2, 3.
[01:25:08.820 --> 01:25:19.260]  Так еще раз. Говорят, что lower bound это первый элемент, который больше либо равен XA.
[01:25:19.260 --> 01:25:23.140]  Ну, мы его ищем в B. Да.
[01:25:23.140 --> 01:25:28.940]  Ну, вот если у нас, например, массив A состоит только из девяти, и X по сути это 9.
[01:25:28.940 --> 01:25:32.820]  А в B у нас только элементы, например, только три штуки. 1, 2, 3.
[01:25:32.820 --> 01:25:37.700]  Тогда B пустое, C4 пустое. Да, тогда.
[01:25:37.700 --> 01:25:45.020]  А когда ты будешь объединять C2 и C4, у тебя есть условие окончания рекурсии.
[01:25:45.020 --> 01:25:48.140]  Что если один из них пуст, то мы возвращаемся.
[01:25:48.140 --> 01:25:50.900]  Все хорошо. Спасибо.
[01:25:50.900 --> 01:26:01.220]  Так, смотрите, за сколько работает merge sort. Давайте с этим разберемся.
[01:26:01.220 --> 01:26:06.500]  Ну, достаточно быстро мы на самом деле с этим разберемся.
[01:26:06.500 --> 01:26:12.980]  Смотрите, A больше либо равно B. То есть, у A как минимум N пополам элементов от всего этого массивчика.
[01:26:12.980 --> 01:26:17.380]  Правильно? Ну, это логичная вывод.
[01:26:18.100 --> 01:26:25.940]  Это означает, что у нас в C1 и в C2 не больше, чем N пополам элементов.
[01:26:25.940 --> 01:26:31.780]  То есть, тут больше либо равно N пополам. И тут больше либо равно N пополам.
[01:26:31.780 --> 01:26:36.180]  Н на 4. N это всего. A и B.
[01:26:36.260 --> 01:26:38.260]  Вот так напишу.
[01:26:38.260 --> 01:26:46.900]  А условие, что A больше либо равняется B, мы сами такое условие создаем?
[01:26:46.900 --> 01:26:51.940]  Да, это одно из условий. Я сейчас объясню, что делать, если A меньше бы. Я объясню.
[01:26:51.940 --> 01:26:55.860]  Вот, таким образом, C1 и C2 больше либо равно N на 4.
[01:26:55.860 --> 01:27:00.900]  То есть, вот этот кусочек больше либо равен, чем N на 4.
[01:27:01.540 --> 01:27:03.540]  Больше либо равен, чем N на 4.
[01:27:03.540 --> 01:27:07.540]  Этот C2 больше либо равен N на 4.
[01:27:07.540 --> 01:27:10.740]  Но в то же время B меньше, чем N пополам.
[01:27:10.740 --> 01:27:19.780]  Поэтому, в общем, вот эта вот штука, вот эта, она меньше либо равна, чем 3N на 4.
[01:27:19.780 --> 01:27:24.980]  И вот эта вот штука тоже меньше либо равна, чем 3N на 4.
[01:27:25.940 --> 01:27:33.860]  То есть, размер каждой из частей уменьшается, как минимум, в 4 третьих раз.
[01:27:33.860 --> 01:27:35.860]  Понятно, почему 3N на 4?
[01:27:35.860 --> 01:27:38.580]  То есть, это N на 4 плюс N пополам.
[01:27:38.580 --> 01:27:40.580]  Ну, мы прям так грубо оценили.
[01:27:43.300 --> 01:27:45.940]  Потому что B у нас меньше, чем N пополам.
[01:27:47.460 --> 01:27:49.460]  N пополам плюс N на 4. 3N на 4.
[01:27:49.860 --> 01:27:55.540]  То есть, каждый раз мы уменьшаем эти части в 4 третьих раз.
[01:27:57.540 --> 01:27:59.540]  То есть, давайте напишу.
[01:27:59.540 --> 01:28:01.540]  Размер.
[01:28:01.540 --> 01:28:03.540]  Размер. Каждый.
[01:28:05.540 --> 01:28:07.540]  Каждый.
[01:28:07.540 --> 01:28:09.540]  Из частей.
[01:28:09.540 --> 01:28:11.540]  Из частей.
[01:28:13.540 --> 01:28:15.540]  В.
[01:28:19.540 --> 01:28:21.540]  Ну, уменьшается.
[01:28:21.540 --> 01:28:23.540]  Давайте так.
[01:28:29.540 --> 01:28:31.540]  Не более.
[01:28:33.540 --> 01:28:35.540]  3 четвертых N.
[01:28:35.540 --> 01:28:37.540]  Следовательно.
[01:28:37.540 --> 01:28:39.540]  Уменьшается.
[01:28:41.540 --> 01:28:43.540]  Уменьшается.
[01:28:43.540 --> 01:28:45.540]  В 4 третьих.
[01:28:45.540 --> 01:28:47.540]  Следовательно.
[01:28:47.620 --> 01:28:49.620]  А. Глубина рекурсии.
[01:28:51.620 --> 01:28:53.620]  Глубина.
[01:28:53.620 --> 01:28:55.620]  Рекурсии.
[01:28:55.620 --> 01:28:57.620]  Рекурсии.
[01:28:57.620 --> 01:29:01.620]  А. Меньше либо равна, чем логариф.
[01:29:01.620 --> 01:29:03.620]  4 третьих от N.
[01:29:05.620 --> 01:29:07.620]  N это длина нашего массивчика.
[01:29:07.620 --> 01:29:09.620]  Вместе A и B.
[01:29:09.620 --> 01:29:11.620]  Вот. То есть, у нас.
[01:29:11.620 --> 01:29:13.620]  Уменьшается в 4 третьих.
[01:29:13.620 --> 01:29:15.620]  Это что и по сравнению с чем?
[01:29:17.620 --> 01:29:19.620]  Уменьшается в 4 третьих.
[01:29:19.620 --> 01:29:21.620]  Вот этот кусок.
[01:29:21.620 --> 01:29:23.620]  C1, C3.
[01:29:23.620 --> 01:29:25.620]  Который у нас новый получился.
[01:29:25.620 --> 01:29:27.620]  По сравнению со всем.
[01:29:27.620 --> 01:29:29.620]  Понятно?
[01:29:29.620 --> 01:29:31.620]  То есть, мы каждый раз уменьшаем, уменьшаем.
[01:29:31.620 --> 01:29:33.620]  Меньше либо равно, чем логариф.
[01:29:33.620 --> 01:29:35.620]  От N по основанию 4 третьих.
[01:29:35.620 --> 01:29:37.620]  Таким образом.
[01:29:37.620 --> 01:29:39.620]  Мы говорим, что у нас глубина рекурсии.
[01:29:39.620 --> 01:29:41.620]  Меньше, чем логариф.
[01:29:41.620 --> 01:29:43.620]  Следовательно.
[01:29:43.620 --> 01:29:45.620]  Память на рекурсе.
[01:29:45.700 --> 01:29:47.700]  Память.
[01:29:47.700 --> 01:29:49.700]  На рекурсе.
[01:29:49.700 --> 01:29:51.700]  Рекурсию.
[01:29:53.700 --> 01:29:55.700]  О большое от логарифа.
[01:29:55.700 --> 01:29:57.700]  N.
[01:29:57.700 --> 01:29:59.700]  Ну, не важно какое основание для нас.
[01:29:59.700 --> 01:30:01.700]  Вот.
[01:30:01.700 --> 01:30:03.700]  А время работы.
[01:30:03.700 --> 01:30:05.700]  Это O от N,
[01:30:05.700 --> 01:30:07.700]  лог N.
[01:30:07.700 --> 01:30:09.700]  Одного N place.
[01:30:09.700 --> 01:30:11.700]  Merge.
[01:30:11.780 --> 01:30:13.780]  А теперь.
[01:30:13.780 --> 01:30:15.780]  Очень важный вопрос.
[01:30:15.780 --> 01:30:17.780]  За сколько работает тогда сортировка?
[01:30:27.780 --> 01:30:29.780]  А?
[01:30:29.780 --> 01:30:31.780]  За N лог N.
[01:30:31.780 --> 01:30:33.780]  Тогда.
[01:30:33.780 --> 01:30:35.780]  Merge.
[01:30:35.780 --> 01:30:37.780]  Работает.
[01:30:37.860 --> 01:30:39.860]  Работает.
[01:30:41.860 --> 01:30:43.860]  За.
[01:30:45.860 --> 01:30:47.860]  O от N логариф.
[01:30:47.860 --> 01:30:49.860]  Квадрат N.
[01:30:49.860 --> 01:30:51.860]  Почему?
[01:30:51.860 --> 01:30:53.860]  Еще раз.
[01:30:53.860 --> 01:30:55.860]  У нас количество уровней.
[01:30:55.860 --> 01:30:57.860]  Логариф N.
[01:30:57.860 --> 01:30:59.860]  Одна, один merge работает
[01:30:59.860 --> 01:31:01.860]  за N лог N.
[01:31:01.860 --> 01:31:03.860]  Ну, типа, вот именно внутри
[01:31:03.860 --> 01:31:05.860]  merge, вот то, что у нас есть N place.
[01:31:05.940 --> 01:31:07.940]  Это означает, что они
[01:31:07.940 --> 01:31:09.940]  просто перемножаются.
[01:31:09.940 --> 01:31:11.940]  То есть N лог N на лог N.
[01:31:11.940 --> 01:31:13.940]  Получается N лог квадрат N.
[01:31:13.940 --> 01:31:15.940]  Это N place merge.
[01:31:15.940 --> 01:31:17.940]  То есть у нас памяти не требуется дополнительно.
[01:31:17.940 --> 01:31:19.940]  И это также стабильная
[01:31:19.940 --> 01:31:21.940]  сортировка. Потому что мы все время
[01:31:21.940 --> 01:31:23.940]  от X.
[01:31:23.940 --> 01:31:25.940]  Смотрите, от X.
[01:31:25.940 --> 01:31:27.940]  У нас слева мы выбрали
[01:31:27.940 --> 01:31:29.940]  X в C1 и так
[01:31:29.940 --> 01:31:31.940]  все, что было меньше либо равно X находилось
[01:31:31.940 --> 01:31:33.940]  слева от X.
[01:31:34.020 --> 01:31:36.020]  Правда? Ну, типа, даже если там был
[01:31:36.020 --> 01:31:38.020]  X еще где-то, то он и так находился
[01:31:38.020 --> 01:31:40.020]  слева первоначально.
[01:31:40.020 --> 01:31:42.020]  В C2
[01:31:42.020 --> 01:31:44.020]  оно все так же
[01:31:44.020 --> 01:31:46.020]  сохранило порядок. И C4
[01:31:46.020 --> 01:31:48.020]  все так же больше либо равно X, а также
[01:31:48.020 --> 01:31:50.020]  находится правее X.
[01:31:50.020 --> 01:31:52.020]  То есть стабильность
[01:31:52.020 --> 01:31:54.020]  сохранена, потому что в C3 все меньше.
[01:31:54.020 --> 01:31:56.020]  Это уже что-то
[01:31:56.020 --> 01:31:58.020]  другое и нам не важно для стабильности.
[01:31:58.020 --> 01:32:00.020]  Для стабильности нам нужно смотреть только
[01:32:00.020 --> 01:32:02.020]  на равные кусочки.
[01:32:02.100 --> 01:32:04.100]  На swap только 1,
[01:32:04.100 --> 01:32:06.100]  C2 и C3.
[01:32:06.100 --> 01:32:08.100]  В C3 нету равных
[01:32:08.100 --> 01:32:10.100]  X. Вот и все.
[01:32:10.100 --> 01:32:12.100]  Таким образом у нас с вами получается
[01:32:12.100 --> 01:32:14.100]  вот такая вот штука, что мы
[01:32:14.100 --> 01:32:16.100]  получили с вами in-place merge
[01:32:16.100 --> 01:32:18.100]  in-place merge sort
[01:32:18.100 --> 01:32:20.100]  за N лог квадрат N.
[01:32:20.100 --> 01:32:22.100]  Так, пожалуйста, вот
[01:32:22.100 --> 01:32:24.100]  первый логарифм, это глубина?
[01:32:24.100 --> 01:32:26.100]  Глубина
[01:32:26.100 --> 01:32:28.100]  in-place merge. Смотрите,
[01:32:28.100 --> 01:32:30.100]  in-place merge это сам по себе merge.
[01:32:32.100 --> 01:32:34.100]  То есть у нас был merge,
[01:32:34.100 --> 01:32:36.100]  который работал за O от N,
[01:32:36.100 --> 01:32:38.100]  правильно?
[01:32:38.100 --> 01:32:40.100]  И получалось, что вся сортировка работает
[01:32:40.100 --> 01:32:42.100]  за N лог N.
[01:32:42.100 --> 01:32:44.100]  А теперь у нас вместо merge
[01:32:44.100 --> 01:32:46.100]  in-place merge, который работает за N
[01:32:46.100 --> 01:32:48.100]  лог N.
[01:32:48.100 --> 01:32:50.100]  А сортировка работает за N
[01:32:50.100 --> 01:32:52.100]  лог квадрат N.
[01:32:56.100 --> 01:32:58.100]  Что касается типа
[01:32:58.100 --> 01:33:00.100]  что будет если
[01:33:00.180 --> 01:33:02.180]  у нас A меньше, чем B?
[01:33:02.180 --> 01:33:04.180]  Если у нас A меньше, чем B,
[01:33:04.180 --> 01:33:06.180]  то нам необходимо lower bound
[01:33:06.180 --> 01:33:08.180]  заменить на upper bound
[01:33:10.180 --> 01:33:12.180]  заменить на upper bound
[01:33:12.180 --> 01:33:14.180]  после чего
[01:33:14.180 --> 01:33:16.180]  и A и B
[01:33:16.180 --> 01:33:18.180]  поменять местами. Все.
[01:33:18.180 --> 01:33:20.180]  Ну, я имею ввиду вот здесь вот.
[01:33:20.180 --> 01:33:22.180]  То есть мы будем
[01:33:22.180 --> 01:33:24.180]  выбирать X из B
[01:33:24.180 --> 01:33:26.180]  и вот здесь вот
[01:33:26.180 --> 01:33:28.180]  ставить upper bound.
[01:33:28.260 --> 01:33:30.260]  Почему так?
[01:33:30.260 --> 01:33:32.260]  Ну, вы просто распишите
[01:33:32.260 --> 01:33:34.260]  опять меньше X, больше X и так далее
[01:33:34.260 --> 01:33:36.260]  и вы поймете когда что.
[01:33:36.260 --> 01:33:38.260]  Также нужно будет свапнуть C23.
[01:33:38.260 --> 01:33:40.260]  Вот.
[01:33:40.260 --> 01:33:42.260]  То есть вы выберите X в B
[01:33:44.260 --> 01:33:46.260]  X выберите в B
[01:33:46.260 --> 01:33:48.260]  а upper bound будет
[01:33:48.260 --> 01:33:50.260]  делить A.
[01:33:50.260 --> 01:33:52.260]  И он будет делить
[01:33:52.260 --> 01:33:54.260]  как вам необходимо.
[01:33:54.260 --> 01:33:56.260]  Понятно?
[01:33:58.260 --> 01:34:00.260]  Вот.
[01:34:00.260 --> 01:34:02.260]  Таким образом мы с вами разобрали
[01:34:02.260 --> 01:34:04.260]  A и B мы меняем местами с open.
[01:34:04.260 --> 01:34:06.260]  Да, то есть A и B сами по себе
[01:34:06.260 --> 01:34:08.260]  не меняются с точки зрения вот этих
[01:34:08.260 --> 01:34:10.260]  треугольничков. Но они вот здесь
[01:34:10.260 --> 01:34:12.260]  меняются, грубо говоря.
[01:34:14.260 --> 01:34:16.260]  Еще раз upper bound, lower bound
[01:34:16.260 --> 01:34:18.260]  мы как выбираем тогда?
[01:34:18.260 --> 01:34:20.260]  Вместо lower bound у вас будет upper bound.
[01:34:24.260 --> 01:34:26.260]  То есть вы имеете ввиду
[01:34:26.340 --> 01:34:28.340]  C1, C2, там будет B от A?
[01:34:28.340 --> 01:34:30.340]  Да, да, да.
[01:34:30.340 --> 01:34:32.340]  Ну, то есть смотрите, здесь немножко
[01:34:32.340 --> 01:34:34.340]  поменяется местами. Тут будет C1, C2
[01:34:34.340 --> 01:34:36.340]  здесь будет C3, C4
[01:34:36.340 --> 01:34:38.340]  то есть здесь важно просто
[01:34:38.340 --> 01:34:40.340]  с этими индексами поиграться правильно.
[01:34:40.340 --> 01:34:42.340]  По факту надо будет
[01:34:42.340 --> 01:34:44.340]  менять все так же серединку.
[01:34:46.340 --> 01:34:48.340]  Вот и все.
[01:34:48.340 --> 01:34:50.340]  То есть вам необходимо
[01:34:50.340 --> 01:34:52.340]  здесь будет чуть-чуть подумать
[01:34:52.340 --> 01:34:54.340]  как это дописать. Понятно?
[01:34:56.340 --> 01:34:58.340]  Вот.
[01:34:58.340 --> 01:35:00.340]  Смотрите. Одни
[01:35:00.340 --> 01:35:02.340]  самых сложных сортировок по факту
[01:35:02.340 --> 01:35:04.340]  закончились, осталась только одна
[01:35:04.340 --> 01:35:06.340]  впереди. Вот.
[01:35:06.340 --> 01:35:08.340]  И это всего лишь hip sort
[01:35:08.340 --> 01:35:10.340]  который достаточно понятный
[01:35:10.340 --> 01:35:12.340]  и
[01:35:12.340 --> 01:35:14.340]  приятный, назовем это так.
[01:35:14.340 --> 01:35:16.340]  Вот. Я думаю вам больше
[01:35:16.340 --> 01:35:18.340]  понравится, чем вот in-place merge.
[01:35:18.340 --> 01:35:20.340]  Но in-place merge
[01:35:20.340 --> 01:35:22.340]  очень полезная функция. Почему?
[01:35:22.340 --> 01:35:24.340]  Смотрите, она меньше всего
[01:35:24.420 --> 01:35:26.420]  облигает память от себя
[01:35:26.420 --> 01:35:28.420]  и
[01:35:28.420 --> 01:35:30.420]  с точки зрения того,
[01:35:30.420 --> 01:35:32.420]  как она может объединять одновременно
[01:35:32.420 --> 01:35:34.420]  какие-то файлики и так далее, она очень
[01:35:34.420 --> 01:35:36.420]  хорошо заходит с большими данными.
[01:35:36.420 --> 01:35:38.420]  И вообще
[01:35:38.420 --> 01:35:40.420]  merge sort, если вы
[01:35:40.420 --> 01:35:42.420]  когда-нибудь
[01:35:42.420 --> 01:35:44.420]  на самом деле, скорее всего, в следующем
[01:35:44.420 --> 01:35:46.420]  семестре, когда вам разрешат
[01:35:46.420 --> 01:35:48.420]  это сделать, вы посмотрите
[01:35:48.420 --> 01:35:50.420]  на функцию std
[01:35:50.420 --> 01:35:52.420]  stable
[01:35:52.500 --> 01:35:54.500]  sort, стабильная
[01:35:54.500 --> 01:35:56.500]  сортировка. Она реализована
[01:35:56.500 --> 01:35:58.500]  по факту на merge sort.
[01:35:58.500 --> 01:36:00.500]  И там сказано, причем вот
[01:36:00.500 --> 01:36:02.500]  внутри std сказано, что
[01:36:02.500 --> 01:36:04.500]  если
[01:36:04.500 --> 01:36:06.500]  у вас
[01:36:06.500 --> 01:36:08.500]  позволяет
[01:36:08.500 --> 01:36:10.500]  память
[01:36:10.500 --> 01:36:12.500]  ну дополнительно o от n памяти
[01:36:12.500 --> 01:36:14.500]  то работает за
[01:36:14.500 --> 01:36:16.500]  n log n
[01:36:16.500 --> 01:36:18.500]  если не позволяет
[01:36:18.500 --> 01:36:20.500]  то за n log квадрат n
[01:36:20.580 --> 01:36:22.580]  то есть там внутри реализованы как раз
[01:36:22.580 --> 01:36:24.580]  эти две сортировки merge sort
[01:36:24.580 --> 01:36:26.580]  и
[01:36:26.580 --> 01:36:28.580]  ну и обычный
[01:36:28.580 --> 01:36:30.580]  inplace merge
[01:36:30.580 --> 01:36:32.580]  sort
[01:36:32.580 --> 01:36:34.580]  вот таким образом у нас получается две такие вот вещи
[01:36:34.580 --> 01:36:36.580]  это понятно?
[01:36:36.580 --> 01:36:38.580]  все ясно?
[01:36:38.580 --> 01:36:40.580]  тогда смотрите
[01:36:40.580 --> 01:36:42.580]  просто еще раз повторить
[01:36:42.580 --> 01:36:44.580]  почему merge работает
[01:36:44.580 --> 01:36:46.580]  за o от n log квадрат
[01:36:46.580 --> 01:36:48.580]  ну то есть почему там логарифмы
[01:36:48.660 --> 01:36:50.660]  перемножаются, а они складываются
[01:36:50.660 --> 01:36:52.660]  то есть почему они
[01:36:52.660 --> 01:36:54.660]  складываются
[01:36:54.660 --> 01:36:56.660]  еще раз inplace merge
[01:36:56.660 --> 01:36:58.660]  он
[01:36:58.660 --> 01:37:00.660]  merge между собой два массива
[01:37:00.660 --> 01:37:02.660]  да?
[01:37:02.660 --> 01:37:04.660]  да
[01:37:04.660 --> 01:37:06.660]  сколько таких раз он это
[01:37:06.660 --> 01:37:08.660]  делает? Он делает это логарифм раз?
[01:37:08.660 --> 01:37:10.660]  да
[01:37:10.660 --> 01:37:12.660]  ну значит n log n умножить на log n
[01:37:12.660 --> 01:37:14.660]  сколько раз он делает это
[01:37:14.660 --> 01:37:16.660]  чудо
[01:37:16.740 --> 01:37:18.740]  вот
[01:37:18.740 --> 01:37:20.740]  а обычный merge работает за n поэтому
[01:37:20.740 --> 01:37:22.740]  там n log n
[01:37:22.740 --> 01:37:24.740]  там же глубина n log n
[01:37:24.740 --> 01:37:26.740]  и merge работает за то
[01:37:26.740 --> 01:37:28.740]  вот таким образом у нас с вами получилась
[01:37:28.740 --> 01:37:30.740]  вот такая вот
[01:37:30.740 --> 01:37:32.740]  интересная сортировка
[01:37:32.740 --> 01:37:34.740]  вот
[01:37:34.740 --> 01:37:36.740]  следующее занятие будет
[01:37:36.740 --> 01:37:38.740]  посвящено astdsort
[01:37:38.740 --> 01:37:40.740]  на чем реализована astdsort, часть всего реализована
[01:37:40.740 --> 01:37:42.740]  quicksort
[01:37:42.740 --> 01:37:44.740]  так что считайте, что вы
[01:37:44.820 --> 01:37:46.820]  пишете стдшную библиотеку
[01:37:46.820 --> 01:37:48.820]  это очень круто, это очень классно
[01:37:48.820 --> 01:37:50.820]  вот будете этим
[01:37:50.820 --> 01:37:52.820]  заниматься как раз в первом
[01:37:52.820 --> 01:37:54.820]  домашнем задании по алгоритму
[01:37:54.820 --> 01:37:56.820]  а следующее задание будет через неделю
[01:37:56.820 --> 01:37:58.820]  получается? Ну примерно так
[01:37:58.820 --> 01:38:00.820]  потому что четвертая там вроде как праздник
[01:38:00.820 --> 01:38:02.820]  да, у нас четвертого нет
[01:38:02.820 --> 01:38:04.820]  лекции, это правда
[01:38:04.820 --> 01:38:06.820]  четвертая праздник поэтому
[01:38:06.820 --> 01:38:08.820]  лекции не будет, будет 11
[01:38:08.820 --> 01:38:10.820]  значит
[01:38:10.820 --> 01:38:12.820]  вот, мы с вами рассмотрим сортировки
[01:38:12.900 --> 01:38:14.900]  будем уже переходить к другим темам
[01:38:14.900 --> 01:38:16.900]  потому что мы как-то застряли
[01:38:16.900 --> 01:38:18.900]  ну много их
[01:38:18.900 --> 01:38:20.900]  вот
[01:38:20.900 --> 01:38:22.900]  и впереди нас ждут
[01:38:22.900 --> 01:38:24.900]  еще интересней темы
[01:38:24.900 --> 01:38:26.900]  на самом деле, все будет очень хорошо
[01:38:26.900 --> 01:38:28.900]  так что
[01:38:28.900 --> 01:38:30.900]  всем спасибо, всем удачи
[01:38:30.900 --> 01:38:32.900]  и до встречи
