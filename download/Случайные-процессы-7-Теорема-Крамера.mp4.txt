[00:00.000 --> 00:10.000]  Так, ребят, ну давайте начинать. Значит, мы с вами продолжаем заниматься фурье анализом
[00:10.000 --> 00:19.120]  стационарных процессов. Я напомню, что на предыдущей лекции я анонсировал одно из важнейших
[00:19.120 --> 00:26.080]  свойств стационарных процессов. То, что стационарные процессы, ну по крайней мере непрерывные,
[00:26.080 --> 00:36.840]  они не могут быть всякими. Они представляются как суммы или ряды или интегралы некоторых комплексных
[00:36.840 --> 00:44.160]  экспонент с некоррелированными коэффициентами. И, более того, корреляционная функция таких
[00:44.160 --> 00:50.680]  процессов имеет тот же самый вид, что и сам процесс. Единственное это то, что вот этот коэффициент,
[00:50.680 --> 00:58.200]  естественно, здесь не случайен, а он равен математическому ожиданию квадрата модуля коэффициента,
[00:58.200 --> 01:04.880]  по которым раскладывается сам процесс. Сегодня мы вот эти теоремы с вами сформулируем. Одну из них
[01:04.880 --> 01:10.840]  мы докажем в разложении процесса. Рассмотрим их более внимательно. И первая теорема, которую я
[01:10.840 --> 01:18.800]  сформулирую, она пойдет без доказательства, это теорема о разложении корреляционной функции
[01:18.800 --> 01:35.840]  непрерывного стационарного процесса. Теорема Хинччина. Значит, для того, чтобы непрерывная функция
[01:35.840 --> 02:00.280]  РТ представляла собой корреляционную функцию некоторого СК непрерывного стационарного в широком
[02:00.280 --> 02:26.680]  смысле процесса, необходимой достаточно, чтобы она имела вид. РТ равно интеграл от минус бесконечности
[02:26.680 --> 02:35.880]  до плюс бесконечности е в степени и лямбда t на ds от лямбда. Это интеграл Рима-настельтьеса,
[02:35.880 --> 02:58.040]  где s от лямбда это с точностью до неотрицательного множителя функция распределения некоторой
[02:58.040 --> 03:13.360]  случайной величины. Вот. То есть это критерий быть корреляционной функцией непрерывного
[03:13.360 --> 03:19.240]  стационарного процесса. Мы с вами уже в прошлый раз обсуждали, какой критерий, правда, не для
[03:19.240 --> 03:24.240]  непрерывных процессов, а для любых процессов. Функция является корреляционной функцией
[03:24.240 --> 03:28.320]  некоторого процесса, неважно, стационарного или нестационарного, если она неотрицательно
[03:28.320 --> 03:43.120]  определена. Вот. Это критерий для процессов непрерывных. Вот. Значит, вот это можно
[03:43.120 --> 03:53.320]  переформулировать. Например, где s от лямбда это функция ограниченная, неотрицательная,
[03:53.320 --> 04:01.200]  непрерывная слева, монотонно неубывающая, начинающаяся от нуля. Функция. Вот. Но это много слов,
[04:01.200 --> 04:07.320]  но мы знаем из теории вероятности, что это просто равносильно тому, чтобы это была функция
[04:07.320 --> 04:14.040]  распределения, если она от нуля до единицы. Вот. Но здесь я хочу написать именно так, где эта
[04:14.040 --> 04:17.960]  функция с точностью до неотрицательного множителя, функция распределения некоторой
[04:17.960 --> 04:24.720]  случайной величины. Откуда это? Что это такое? А вот смотрите. Вот мы на прошлой лекции рассматривали
[04:24.720 --> 04:33.880]  процессы стационарные, непрерывные, которые просто экспонента, умноженная на какую-то кси, или сумма
[04:33.880 --> 04:38.960]  экспонент со своими кси1, кси2 некоррелированными. Вот у нас там входили просто лямда, лямда 1,
[04:38.960 --> 04:48.560]  лямда 2. Так вот. Вот эта вещь, s от лямда, она с точностью до вот этого множителя сдает распределение
[04:48.560 --> 04:54.520]  над частотами лямдами. Вот если у тебя просто лямда 1, лямда 2, это как будто у тебя есть случайная
[04:54.520 --> 05:04.440]  величина, которая принимает значение лямда 1, лямда 2. Если у тебя ряд, ну или сумма ксиитых на
[05:04.440 --> 05:10.320]  е в степени и лямда житая t, то это значит, что тебе дали случайную величину, которая принимает
[05:10.320 --> 05:16.320]  значение лямда 1, лямда 2, лямда 3 и так далее. Но в общем случае, вот этот спектр над лямдами,
[05:16.320 --> 05:23.280]  он может быть непрерывный. И у тебя может быть целый непрерывный спектр лямд. И вот этот спектр,
[05:23.280 --> 05:29.200]  это распределение над частотами над лямдами, он как раз задается вот этой функцией s,
[05:29.200 --> 05:34.640]  которая совпадает с точностью до индициативного множителя с функцией распределения случайной
[05:34.640 --> 05:41.200]  величины. Что это такое за распределение случайной величины? Что это за случайная величина?
[05:41.200 --> 05:50.280]  Вот она определяет распределение над частотами. Так, вот эта s от лямда называется спектральной
[05:50.280 --> 06:05.400]  функцией. Называется спектральной функцией. Значит, у вот этой функции распределение может быть
[06:05.400 --> 06:13.120]  плотность. То есть распределение может быть абсолютно непрерывным. То есть если существует
[06:13.120 --> 06:20.080]  ρ от лямда неотрицательная функция, абсолютно интегрируемая полибегу на всей числовой оси,
[06:20.080 --> 06:26.080]  такая что s от лямда равняется интегралу минус бесконечности до лямда, значит,
[06:26.080 --> 06:36.400]  ρ от лямда до лямда, то вот эту ρ, то ρ от лямда называют спектральной плотностью.
[06:36.400 --> 06:48.160]  Называется спектральной плотностью. Вот у тех процессов, которые у нас были в прошлый раз,
[06:48.160 --> 06:56.360]  вот эти конечные суммы, экспонент, там нет плотности. Вот там f, точнее вот это s от лямда,
[06:56.360 --> 07:03.240]  это некоторая кусочно постоянная функция, как у случайной величины, которая принимает конечное
[07:03.240 --> 07:10.000]  число значений каких-то, это кусочно постоянная функция. Вот, но процессы могут иметь вот какую-то
[07:10.000 --> 07:15.600]  ρ от лямда. Значит, эта функция, она неотрицательная, абсолютно интегрируемая на всей числовой оси.
[07:16.000 --> 07:21.680]  Она не обязана быть гладкой, непрерывной или что-то там, она может быть вообще всякая. И всякая
[07:21.680 --> 07:28.800]  неотрицательная функция, абсолютно интегрируемая на числовой оси, задает некую функцию s от лямда,
[07:28.800 --> 07:35.520]  и если мы ее подставим в это выражение, мы получаем функцию r от t, которая, как следует из этой теоремы,
[07:35.520 --> 07:42.080]  является корреляционной функцией некоторого непрерывного стационарного в широком смысле процесса.
[07:42.080 --> 07:52.320]  Вот. Пример приведу один. Какой может быть, например, вот эта плотность ρ от лямда? Вот такая.
[07:52.320 --> 08:00.080]  Допустим, вот она от минус лямда ноль до лямда ноль определена, здесь она какая-то постоянная,
[08:00.080 --> 08:09.240]  здесь она равна нулю. Вот просто пример, такой тривиальный пример функции плотности. Значит,
[08:09.240 --> 08:19.440]  вне этих частот она равна нулю, здесь она равна какой-то постоянной, то есть это значит,
[08:19.440 --> 08:23.800]  что у нас как будто есть некое излучение, которое во всех частотах одинаково вещает.
[08:23.800 --> 08:35.120]  Вот. Случайные процессы вот с такой плотностью спектральной называются белыми шумами. Белый шум.
[08:35.120 --> 08:40.400]  Ну вообще-то белый шум это целый класс процессов, они могут быть и дискретными,
[08:40.400 --> 08:45.520]  и необязательно с непрерывным временем. Ну вот такие процессы, они относятся к белым шумам.
[08:45.520 --> 08:55.920]  Белый шум. Белый шум. Вот. Ну там посмотрите, у меня какая у него будет плотность. Это там
[08:55.920 --> 09:07.520]  что-то типа sin t делить на t у rt. Вот. Есть модели, в которых лямда считается не конечной,
[09:07.520 --> 09:13.000]  а на бесконечности находится, но при этом константа, она не ноль, а какая-то. Ну тогда эта
[09:13.000 --> 09:18.480]  функция не является абсолютно интегрируемой, и в строгом смысле этого слова спектральной
[09:18.480 --> 09:25.440]  функции у такого процесса не существует. Вот. Если вообще сам такой процесс существует. Вот.
[09:25.440 --> 09:32.880]  Но тем не менее, есть обобщение случайных процессов, обобщенные процессы случайные. Вот.
[09:32.880 --> 09:43.440]  У которых там спектральная функция или корредиционная функция вернее, она описывается в терминах
[09:43.440 --> 09:50.520]  обобщенных функций. Вот. То есть такое вот расширение на вот эти случаи, когда нам полезно считать,
[09:50.520 --> 09:57.560]  что лямда ноль, оно не какое-то конечное, оно на бесконечности, когда находится. Вот. Но мы такие
[09:57.560 --> 10:01.960]  процессы изучать не будем, с ними связываться тоже не будем, но у меня в PDF-ках можете найти там
[10:01.960 --> 10:08.400]  ссылки, где об этом можно почитать, как это все формализуется. Но для инженеров это очень полезная
[10:08.400 --> 10:12.440]  модель на самом деле. То есть либо ты можешь считать, что лямда ноль у тебя конечная, но просто очень
[10:12.440 --> 10:18.800]  большой, а ты работаешь где-то вот в более узком пространстве, что в принципе для приложений это
[10:18.800 --> 10:23.800]  как раз тот самый случай. Ну либо тебе, например, удобно считать, что лямда ноль на бесконечности,
[10:23.800 --> 10:27.800]  но тогда у тебя появляются обобщенные функции, с которыми нужно просто аккуратно работать. Вот и все.
[10:27.800 --> 10:33.680]  То есть не нужно думать, что если плотности нет, то мы ничего не можем делать, никак с этим работать.
[10:33.680 --> 10:44.320]  Нет, конечно, люди придумали некие обобщения. Вот. На интересные случаи. Так. Хорошо. Значит,
[10:44.320 --> 10:54.120]  вот эта теорема, ее можно доказать. Доказательства можно найти у Ширяева в теории случайных процессов.
[10:54.120 --> 11:03.400]  Вот. Значит, оно очень техническое. Я не буду ее доказывать. Очень техническое доказательство. Вот.
[11:03.400 --> 11:14.120]  И она никак не опирается в своем доказательстве на тот факт, что процесс можно разложить тоже
[11:14.120 --> 11:19.480]  в интеграл с комплексными экспонентами, где коэффициенты будут некоррелированы. Теорема Крамера,
[11:19.480 --> 11:23.880]  которую я сформулирую чуть позднее. То есть это как бы независимая теорема. Вот ее можно доказать.
[11:23.880 --> 11:40.680]  Все. Вот. Вот ее можно доказать. Так. Хорошо. Да. Нет, вот я написал для нее функцию. Ну, какие-то
[11:40.680 --> 11:47.920]  задачки, может быть, вы на семинарах порешаете с ней сделать. А потому что излучает во всех частотах
[11:47.920 --> 11:55.920]  на отрезке и нет приоритетов одних частот перед другими. Вот и все. Вот почему называется белым
[11:55.920 --> 12:04.400]  шумом. То есть если ты будешь выделять из этого сигнала частоты, то увидишь, что у тебя вот такой
[12:04.400 --> 12:12.240]  спектр. То есть нет приоритетов одних частот перед других. Шум. Белый шум. Бывает много других
[12:12.240 --> 12:17.960]  шумов. Там красные шумы бывают, синие шумы бывают. Ну, там у них плотность, соответственно, где-то
[12:17.960 --> 12:28.880]  она сдает уже приоритеты перед какими-то частотами. То есть если частота низкая, то что красный шум,
[12:28.880 --> 12:37.800]  дат. В таких терминах можно работать уже. Вот. И смотрите еще какое здесь интересное наблюдение. Вот
[12:37.800 --> 12:43.560]  r от, так как она корреляционная функция, она не отрицательно определена. Не путайтесь с неотрицательностью.
[12:43.560 --> 12:47.880]  Она не отрицательно определена в том смысле, который у нас был на прошлой лекции. Вот эта
[12:47.880 --> 12:57.600]  функция не отрицательная. А еще вот эта вещь, если мы сюда подставим вместо ds-rho от лямда до лямда,
[12:57.600 --> 13:03.760]  то можно увидеть, что r от является преобразованием фурье, ну или обратным преобразованием фурье,
[13:03.760 --> 13:10.240]  смотря как определять функции rho. Но мы вроде как помним, что и rho можно выразить через r от.
[13:10.240 --> 13:18.560]  Если нам дали r от, как найти rho? Вот. Значит, вот если у тебя r от представляет в таком виде,
[13:18.560 --> 13:25.200]  то не всегда rho от лямда является обратным преобразованием фурье r от. Есть условия,
[13:25.200 --> 13:30.840]  они формулируются в курсе математического анализа, условия, при которых можно записать
[13:30.840 --> 13:36.160]  rho через r. Ну это будет тоже интеграл, 1 делить на 2pi, вот тут минус поставить, и тут r от написать.
[13:36.160 --> 13:45.960]  Вот. Но это определенные условия, когда это можно делать. Вот. Ну какие условия есть?
[13:45.960 --> 13:52.920]  Их очень много разнообразных условий. Например, если r от непрерывно дифференцируемая,
[13:52.920 --> 14:03.040]  по-моему, если она всюду... Сейчас. Как там, например, было? Сейчас. Например, да, если r от всюду
[14:03.040 --> 14:11.640]  непрерывно дифференцируемая, тогда вот эта rho от лямда, она равна тоже такому же интегралу,
[14:11.640 --> 14:16.120]  только уже от r от, а вот тут с минусом, 1 делить на 2pi, то есть обратным преобразованием фурье справедливо.
[14:16.120 --> 14:24.400]  Вот. Есть другие как бы условия. Например, если мы запишем обратное преобразование фурье,
[14:24.400 --> 14:28.440]  получим некую функцию, это наша функция rho от лямда, если она абсолютно интегрируемая.
[14:28.440 --> 14:35.400]  Вот. Тогда тоже вот это обратное преобразование существует. Вот. Есть там более общие условия,
[14:35.400 --> 14:41.200]  типа там условия Dini. В общем, но это уже касается курса математического анализа и к нам никак не
[14:41.200 --> 14:47.720]  относится, поэтому туда и не пойду. Но одну теорему я сформулирую о связи неотрицательной
[14:47.720 --> 14:55.800]  определенности функции и неотрицательности ее фурье преобразования. Вот. Такую теорему. Давайте мы
[14:55.800 --> 15:09.200]  сформулируем. Я ее сформулирую, докажу. То есть, пусть функция r от t, всюду непрерывно,
[15:09.200 --> 15:34.040]  абсолютно интегрируема на r и пусть для нее выполнены условия разложения в интеграл фурье.
[15:39.200 --> 15:49.600]  Ну, то есть, r от t равняется интегралу минус бесконечности до плюс бесконечности e в степени лямда t rho от лямда
[15:49.600 --> 15:58.080]  до лямда, и rho от лямда равняется интегралу от минус бесконечности единицы на 2 pi e в степени минус
[15:58.080 --> 16:05.520]  и лямда t r от t до t. Вот эти слова выполнены условия, то есть, если выполнено вот это. Ну, какие-то
[16:05.520 --> 16:11.240]  условия там, может быть, дополнительные там на функции накладываются. Так главное, чтобы вот это
[16:11.240 --> 16:25.440]  было выполнено. Вот. Тогда r от t неотрицательно определена тогда и только тогда, когда rho от лямда
[16:25.440 --> 16:33.320]  неотрицательно. Вот. Ну, если это, как бы, видите, эта теорема не совсем из случайных процессов,
[16:33.320 --> 16:40.240]  здесь нет ничего про процессы, вот, какова общая теорема математического анализа, но она
[16:40.240 --> 16:48.440]  триальнейшим образом доказывается, зная вот эту теорему, теорему хиничного наказательства. Ну,
[16:48.440 --> 16:56.080]  смотрите, в одну сторону практически очевидно, ну, как всегда это бывает, да, то есть, пусть rho от
[16:56.080 --> 17:05.240]  лямда неотрицательно оказалось, пусть rho от лямда неотрицательно. Вот. Тогда, если мы посмотрим
[17:05.240 --> 17:11.400]  вот на это выражение, то оно имеет вон тот вид. То есть, тогда вот эту вещь мы можем записать как ds
[17:11.400 --> 17:17.920]  от лямда, ввести s как интеграл rho от лямда до лямда, и это будет функция, которая с точностью до
[17:17.920 --> 17:22.840]  неотрицательного множителя совпадает с функцией распределения. То есть, это будет какая-то ограниченная,
[17:22.840 --> 17:33.760]  вот, ограниченная, всюду там неубывающая, непрерывная и так далее функция. Вот. Так что получается,
[17:33.760 --> 17:47.480]  следовательно, r от t имеет вид из теоремы хинчина, вот, имеет вид из теоремы хинчина,
[17:47.480 --> 17:55.200]  а это значит, что r от t это не просто какая-то функция, она является корреляционной функцией
[17:55.200 --> 18:02.920]  некоторого процесса. Следовательно, r от t это корреляционная функция некоторого процесса,
[18:02.920 --> 18:08.880]  а такие функции, как мы знаем, являются неотрицательно определенными. Следовательно,
[18:08.880 --> 18:26.160]  r от t неотрицательно определена. Вот так вот. Хорошо. Теперь второе.
[18:26.160 --> 18:42.720]  А может быть, и можно. Если она неотрицательно определена, значит, она корреляционная функция,
[18:42.720 --> 18:52.240]  значит, она имеет вон тот вид. Ну да, смотрите, да, можно повернуть, но мы должны здесь сослаться
[18:52.240 --> 18:58.200]  на то, что это разложение, оно единственное. Вот. Это разложение единственное. Вот. Да,
[18:58.200 --> 19:03.160]  то есть и наоборот. Ну давайте, да, давайте мы так и сделаем. То есть r от t неотрицательно
[19:03.160 --> 19:08.640]  определена. Отсюда следует, что она корреляционная функция. Отсюда следует,
[19:08.640 --> 19:19.760]  что она имеет вид из теоремы хинчина. И если вот это следствие, оно просто остается, то вот это
[19:19.760 --> 19:30.520]  следствие. К нему комментарий, что разложение в интеграл единственное. Вот. Ну вот это то, что
[19:30.520 --> 19:34.080]  единственное разложение, ну это уже из курса математического анализа. Мы просто знаем,
[19:34.080 --> 19:38.760]  что вот эти разложения, они единственные. Другого быть не может. Так что если мы представили его в
[19:38.760 --> 19:44.160]  таком виде, и с другой стороны у нас представлены r от t вот в таком виде по условию теоремы,
[19:44.160 --> 19:55.560]  то нам некуда деваться. Всё получается. Вот. Ещё маленький комментарий. Здесь у меня не явно
[19:55.560 --> 20:01.600]  используется то, что r от λ абсолютно интегрировано, но это просто следует из-за того,
[20:01.600 --> 20:23.160]  что r абсолютно интегрируема. Вот. Прирывно. Так. Так, хорошо. Ну всё. На этом тогда всё.
[20:23.160 --> 20:39.400]  Движемся дальше. Теперь переходим к важной для нас теореме, теореме Крамера о разложении процесса.
[20:53.160 --> 21:06.440]  А нет, даже проще. Смотрите. Последний комментарий. Она интегрируема просто потому,
[21:06.440 --> 21:12.040]  что если существует r от t в таком виде, мы можем вместо t подставить 0, и здесь получится некий
[21:12.040 --> 21:18.520]  интеграл. Ну r от 0 это какое-то число. Поэтому r от λ интегрируема. Вот. Даже так. Давайте так.
[21:18.920 --> 21:28.000]  Такой комментарий оставим. Ну это нам нужно, чтобы вот эта s от лямда была ограничена.
[21:28.000 --> 21:53.360]  Теорема Крамера. Так. Теорема Крамера. Вот у Крамера есть книжка замечательнейшая. Вот. На русском
[21:53.360 --> 22:01.400]  языке классическая книжка. Просто, ну отлично написана. Я вам её просто рекомендую. Если туда
[22:01.400 --> 22:07.680]  залезть, что-то почитать, то много узнаете. Это, кстати, одна из немногих книг, про которые я могу
[22:07.680 --> 22:17.080]  сказать, что читая её, ты можешь учиться тому, как писать книги. То есть настолько всё ясно,
[22:17.080 --> 22:23.720]  понятно. Ну вот просто, ну да нельзя. Но при этом всё математически обосновано, строго, не
[22:23.720 --> 22:28.840]  пускается ни в какие излишние формализмы. Знаете, вот как вот любят некоторые навести формализму.
[22:28.840 --> 22:34.680]  Много формул, там абстракции всяких, за которыми ничего не видно. Вот у него какое-то вот удачное
[22:34.680 --> 22:43.640]  сочетание между ними. У нас будет ещё одна книжка с такими свойствами хорошими. Ой, да там типа
[22:43.640 --> 22:51.760]  теория стационарных случайных процессов, что-то такое. Да, если её гуглить, то сразу найдёшь. Так,
[22:51.760 --> 23:04.680]  ну и у меня на ноушене в списке литературы там тоже она есть. Значит, любому стационарному широком
[23:04.680 --> 23:23.840]  смысле СК непрерывному процессу X от T с математическим ожиданием МХ соответствует случайный
[23:23.840 --> 23:36.280]  процесс. Сейчас я поясню, что это такое. С ортогональными приращениями В от лямда.
[23:36.280 --> 23:43.880]  Эта штука непрерывный аналог конечного числа некоррелируемых случайных величин. Процесс
[23:43.880 --> 24:01.720]  с ортогональными приращениями такой, что с вероятностью единица выполняется равенством. Вот такое.
[24:01.720 --> 24:11.400]  X от T равняется МХ, мат ожидания, плюс интеграл от минус бесконечности до бесконечности е в степени лямда
[24:11.400 --> 24:28.760]  T на dV от лямда. Значит, d интеграл понимается как СК интеграл Римана стильтиеса. А процесс с
[24:28.760 --> 24:33.640]  ортогональными приращениями это процесс с центрированной, то есть нулевым,
[24:33.640 --> 24:44.760]  мат ожиданиями такой, что мат ожидания V лямда 3 минус V лямда 2 на V лямда 2 минус V от лямда 1
[24:44.760 --> 24:58.840]  равно 0 для любых лямда 1, лямда 2, лямда 3. Ой, подождите. Что-то я не то. Четыре же вроде было.
[24:58.840 --> 25:08.040]  Ну можно на самом деле так и так. Нет, давай четыре сделаем. Потому что так наверное более
[25:08.040 --> 25:17.160]  общая. 4, 3, 2, 1, 1, 2, 3, 4. И вот тут сопряжение комплекса. Это комплексный процесс, вообще говоря.
[25:17.160 --> 25:23.400]  Это определение процесса с ортогональными приращениями. Мы будем так называть процесса
[25:23.400 --> 25:28.560]  центрированной. Ну, центрированность, она тут не принципиальна, но давайте мы, как классики,
[25:28.560 --> 25:33.920]  это определяли, пойдем, что вдруг это где-то, ну да, мы на самом деле этим воспользуемся здесь.
[25:33.920 --> 25:37.920]  Да, центрированный процесс, то есть процесс с нулевым от ожидания, и такое, что вот это
[25:37.920 --> 25:42.260]  выполнено. То есть ортогональный в смысле скалярного произведения. Вот это ожидание
[25:42.260 --> 25:48.600]  произведения случайной величины на ее сопряженное, вот это вот, это скалярное произведение этих двух
[25:48.600 --> 25:56.000]  случайных величин. Вот скалярное произведение приращений на вот таких вот интервалах, оно равно 0.
[25:56.000 --> 26:02.000]  То есть ортогональное приращение, ортогональное. То есть тут аналогия, она очень простая.
[26:02.000 --> 26:12.280]  Значит, я придумал доказывать эту теорему в этот раз с использованием визуальных инструментов.
[26:12.280 --> 26:22.600]  Будем сейчас рисовать. О чем мы только формулы пишем? Давайте немножко порисуем.
[26:26.000 --> 26:36.800]  Нам нужно будет еще и место для того, чтобы все-таки какие-то отдельные формулы написать.
[26:36.800 --> 26:39.960]  Значит, доказательства.
[26:39.960 --> 26:54.480]  Значит, в основе доказательства лежит введение двух пространств Гильбертовых
[26:54.480 --> 27:00.800]  с скалярными произведениями, линейных, и установление между ними взаимоднодоначного соответствия.
[27:00.800 --> 27:05.640]  И это не случайно так мы делаем. То, что помните, опять же, на прошлой лекции возвращаемся.
[27:05.640 --> 27:11.800]  Процессы раскладываются в суммы ряды интегралы по комплексным экспонентам,
[27:11.800 --> 27:17.160]  и корреляционные функции раскладываются точно так же. Только коэффициент уже не случайной
[27:17.160 --> 27:24.240]  величины, а от ожидания квадратов. Поэтому хочется какое-то соответствие между ними
[27:24.240 --> 27:29.880]  установить. Вот это делается вот в этой теореме. Значит, мы нарисуем один большой кружочек.
[27:29.880 --> 27:37.560]  Здесь это будет одно пространство. Сейчас мы его будем наполнять. Какие случайные величины,
[27:37.560 --> 27:45.640]  что мы сюда добавим. И другое пространство. Мы его тоже будем наполнять. Вот это для случайных
[27:45.640 --> 27:53.040]  величин и процесса. Вот это для корреляционной функции. Будем устанавливать между ними
[27:53.040 --> 28:00.200]  соответствие. Итак, введем два пространства. Одно из них, сейчас я вспомню, как оно мне
[28:00.200 --> 28:11.440]  обозначается. Одно из них мы обозначим за h х-центрированное. Другое мы обозначим за h от s.
[28:11.440 --> 28:26.880]  Значит, s это спектральная функция х. Спектральная функция х, которая из теоремы Хинччина. Здесь нам
[28:26.880 --> 28:32.560]  понадобится то, что спектральная функция существует, она определяется как теорема Хинччина.
[28:32.560 --> 28:43.480]  Вот что мы добавим вот в это пространство. Для каждого t мы сюда добавим, давайте тут по центру
[28:43.480 --> 28:52.920]  сделаем, х-центрированное от t. Ну это х от t-mx. Вот такую величину. И для всех t мы добавим в это
[28:52.920 --> 28:59.440]  пространство все вот такие случайные величины. Давайте нам еще пригодится, для удобства введем
[28:59.440 --> 29:05.240]  х-центрированное от t. На самом деле t пробегает все значения. Здесь много-много точечек для каждого t.
[29:05.240 --> 29:12.880]  Ну вот одна из них. Ну для какого-то s, скажем, неравного t. Значит, здесь будут лежать все
[29:12.880 --> 29:23.080]  сечения центрированного процесса. Сюда же добавим а1 х-центрированное от t1 плюс и так далее
[29:23.080 --> 29:33.960]  а1 х-центрированное от tn для любых комплексных альф, для любых n, для любых t. То есть не просто добавим сюда
[29:33.960 --> 29:42.120]  сечения центрированного процесса, но все линейные комбинации вот такого вида, все сечения с всеми
[29:42.120 --> 29:48.200]  коэффициентами комплексными тоже сюда добавим. Они все будут лежать для всех t, n, альф вот в этом
[29:48.200 --> 29:59.880]  пространстве. И более того, добавим сюда также sk пределы всевозможных последовательностей среди
[29:59.880 --> 30:09.320]  всех этих случайных величин, которые мы сейчас ввели и предел которых имеет второй момент. То есть
[30:09.320 --> 30:17.640]  мы ввели сюда вот эти все случайные величины и также добавим в это пространство h х-центрированное
[30:17.640 --> 30:26.560]  их sk пределы, если эти sk пределы имеют конечный второй момент. То есть замкнем это пространство,
[30:26.560 --> 30:33.080]  добавим сюда все предельные точки в sk смысле, которые имеют конечный второй момент. Ну вот и
[30:33.080 --> 30:41.240]  ведем вот на этом пространстве скалярное произведение по очень простому правилу. То есть мы
[30:41.240 --> 30:50.800]  будем считать, что это 1, это 2, это будет для нас математическое ожидание, это 1,
[30:50.800 --> 30:57.360]  а это 2 сопряженное. То есть это состоит из случайных величин, у всех у них конечный
[30:57.360 --> 31:03.640]  второй момент. Значит между ними всеми можно ввести вот такое скалярное произведение.
[31:03.640 --> 31:08.560]  Это скалярное произведение будет на этом пространстве. Это линейное пространство,
[31:08.560 --> 31:15.880]  очевидно, с вот таким скалярным произведением. Такое Гильбертово пространство мы ведем. Вот мы
[31:15.880 --> 31:21.480]  будем считать два элемента тождественными, если расстояние между ними равно нулю, но расстояние,
[31:21.480 --> 31:27.400]  которое генерируется вот этим скалярным произведением. То есть если математическое
[31:27.400 --> 31:35.240]  ожидание модуля это 1 минус это 2 в квадрате равно нулю, то мы будем считать эти два элемента
[31:35.240 --> 31:41.240]  тождественными. То есть они могут отличаться на множестве меры ноль, на самом деле, но вот мы
[31:41.240 --> 31:48.880]  будем считать, что они как бы одинаковые. Нули равны источнице почти наверное. Так,
[31:48.880 --> 31:56.000]  я обращаю внимание на то, что все элементы здесь имеют нулевое математическое ожидание. Теперь
[31:56.000 --> 32:03.680]  мы образуем вот это множество, вот это пространство. Что это будет за пространство? Это пространство
[32:03.680 --> 32:15.240]  функций, у которых существует, то есть пространство функций g, для которых конечен вот этот интеграл.
[32:15.240 --> 32:21.800]  То есть это множество функций, интегрируемых по римму, но с функции s от лямда. Где s от лямда,
[32:21.800 --> 32:26.360]  это не просто какая-то функция, это именно спектральная функция вот этого самого изучаемого
[32:26.360 --> 32:34.400]  нами процесса x. Это важно. Кстати говоря, то, что функция s существует, и мы ее здесь используем,
[32:34.400 --> 32:38.720]  это благодаря тому, что мы рассматриваем непрерывные процессы. Вот где у нас используется
[32:38.720 --> 32:44.280]  непрерывность. Дальше вы можете не понять, где у нас непрерывность, причем непрерывность. Мы ее
[32:44.280 --> 32:59.640]  используем, потому что мы вводим s, спектральную функцию. Вот, и давайте мы, да. Значит, вот эта вещь,
[32:59.640 --> 33:08.360]  вот это, это пространство функций вот таких. Все такие функции лежат здесь. Вот, там мы как-то
[33:08.360 --> 33:13.720]  вот индуктивно вводили, да, такую, такую, такие там пределы, все. Здесь мы сразу говорим,
[33:13.720 --> 33:21.360]  все пространство состоит вот из таких функций. И на этом пространстве мы введем тоже скалярное
[33:21.360 --> 33:30.480]  произведение g1 g2 как интеграл минус бесконечность плюс бесконечность g1 от лямда, g2 от лямда
[33:30.480 --> 33:41.880]  сопряженная на ds от лямда. Вот такое скалярное произведение введем. Вот. А теперь самое интересное.
[33:41.880 --> 33:50.360]  Давайте установим взаимнооднозначное соответствие между вот этими пространствами. Взаимнооднозначное.
[33:50.360 --> 33:56.160]  То есть нам на самом деле в некотором смысле все равно с чем работать, с этой штукой или с этой.
[33:56.160 --> 34:09.680]  Значит, смотрите, х от t мы сопоставим функцию E в степени И лямбда t, как функцию лямбды,
[34:09.680 --> 34:18.120]  потому что если мы t зафиксируем, вот это будет случайная величина, и в случайной величине мы
[34:18.120 --> 34:27.640]  сопоставим функцию. Функцию лямбды. Вот такую. t здесь параметр фиксированный. Лямда это переменная,
[34:27.640 --> 34:32.880]  которая меняется. Это функция лямды. Вот она наша g от лямда. Она здесь лежит. Просто потому что если мы
[34:32.880 --> 34:38.640]  подставим, здесь будет единица, интеграл ds. Эта штука, она ограничена. Будет s от бесконечности,
[34:38.640 --> 34:43.080]  минус s от минус бесконечности. Это какое-то конечное число. Значит, эта функция в этом пространстве лежит.
[34:43.080 --> 34:49.120]  Так что давайте мы вот этой вещью сопоставим вот эту функцию. Соответственно, какому-нибудь
[34:49.120 --> 34:58.480]  x-центрированное s с другим временным параметром поставится в соответствие E в степени И лямбда s.
[34:58.480 --> 35:08.760]  Вот. А теперь смотрите, что тут самое-то важное. Хорошо, между этими штуками мы соответственно
[35:08.760 --> 35:18.960]  установили. Но скалярное произведение x-центрированное t, x-центрированное s в том пространстве,
[35:18.960 --> 35:29.520]  это есть мат ожидания x-центрированное t, x-центрированное s сопряженное. Так. Но это
[35:29.520 --> 35:40.800]  по определению корреляционная функция x-а в точке t, s. Здесь не просто что-то написано, это какая-то r,
[35:40.800 --> 35:55.320]  x, t, s. Но процесс стационарный. Значит, получается, что это есть. Что такое? Что это можно выразить
[35:55.320 --> 36:03.160]  через r, x, t минус s, где это соответствующая функция одного аргумента, потому что процесс
[36:03.160 --> 36:15.240]  стационарный. Вот. Так. А по теореме Хинччина, вот эта вещь, это есть интеграл, потому что у нас все
[36:15.240 --> 36:21.200]  условия выполнены для теоремы Хинччина. Тоже мы снова этим пользуемся непрерывностью, стационарностью.
[36:21.200 --> 36:29.480]  И это есть интеграл от минус бесконечности до плюс бесконечности, e в степени i лямбда на t минус s,
[36:29.480 --> 36:41.920]  ds от лямбда, где s это спектральная функция x-а, та самая, которая здесь и везде у нас. Вот. Но вот
[36:41.920 --> 36:51.920]  эта экспонента, это e в степени i t лямбда на e в степени i s лямбда сопряженная. То есть, видите,
[36:51.920 --> 37:02.840]  интеграл функции на сопряженную ds. Но это является образом x от t, эта штука является образом x от s.
[37:02.980 --> 37:11.500]  Это есть скалярное произведение вот в этом пространстве, e в степени i t лямбда e в
[37:11.500 --> 37:18.120]  степени i s лямбда. Это функция лямбда, это функция лямбда, просто у них параметры разные,
[37:18.120 --> 37:22.140]  а это скалярное произведение здесь. Получается, что скалярное произведение там равно скалярному
[37:22.140 --> 37:28.160]  произведению здесь. Ну, для, по крайней мере, для вот этих элементов. Для элементов, которые сечение.
[37:28.160 --> 37:33.500]  Вот так что вот это преобразование сохраняет
[37:33.500 --> 37:38.100]  скалярное произведение, по крайней мере, между сетчениями.
[37:38.100 --> 37:42.500]  А раз скалярное произведение сохраняется между ними,
[37:42.500 --> 37:45.180]  то и расстояние сохраняются между ними.
[37:45.180 --> 37:50.980]  То есть расстояние между этими штуками равно расстоянии
[37:50.980 --> 37:53.860]  между этими штуками.
[37:53.860 --> 37:55.860]  Расстояние между этими штуками...
[37:55.860 --> 37:57.200]  Давайте мы обозначим, что это такое.
[37:57.200 --> 38:11.120]  такое там от ожидания модуль x центрированная t минус x центрированная s вот а расстояние
[38:11.120 --> 38:21.800]  между этими штоками это есть интеграл модуль g ну получается е в степени и t лямбда минус
[38:21.800 --> 38:29.480]  е в степени и с лямбда в квадрате ds от лямбда и так как скалярные произведения равны то и вот
[38:29.480 --> 38:36.480]  эта штука равна вот этому интегралу в от ожидания вот этого квадрата равно вот этому и если одно
[38:36.480 --> 38:43.880]  ноль то и другое ноль значит если вы рассматриваете равные функции здесь давайте сегодня без перерыва
[38:43.880 --> 38:52.700]  зато попозже закончим значит если функции равны здесь в смысле вот этого расстояния значит и
[38:52.700 --> 39:01.920]  соответствующие образы будут равны в смысле вот этого расстояния и наоборот вот установили
[39:01.920 --> 39:11.840]  здесь соответствие ну а дальше на самом деле все ну просто тривиально потому что вот этой
[39:11.840 --> 39:23.480]  вещи давайте мы сопоставим ну естественно вот такую вещь альфа 1 е в степени и значит t 1
[39:23.480 --> 39:33.720]  лямбда плюс и так далее плюс альфа n е в степени и tn лямбда вот такую функции лямбда сопоставим и
[39:33.720 --> 39:43.160]  если мы будем смотреть скалярные произведения между вот такими штуками а это кстати является
[39:43.160 --> 39:50.880]  частным случаем такой штуки то в силу линейности математического ожидания мы снова получим что
[39:50.880 --> 39:56.360]  скалярные произведения сохраняются при таком преобразовании то есть скалярное произведение
[39:56.360 --> 40:03.560]  между этими здесь равно скалярному произведения между соответствующими функциями здесь просто
[40:03.560 --> 40:09.560]  в силу линейности математического ожидания и интеграла но я не буду это расписывать но мне
[40:09.560 --> 40:15.680]  кажется что это понятно взять мот ожидания этой штуки умножить на ее сопряженную раскрыть там
[40:15.680 --> 40:20.360]  все эти скобки значит расписать посмотреть на каждый элемент в отдельности потом все собрать
[40:20.360 --> 40:25.560]  обратно все тривиально так что скалярное произведение сохраняется и между такими
[40:25.560 --> 40:33.920]  тоже вещами вот ну и соответственно расстояние между подобными вещами в этом пространстве
[40:33.920 --> 40:41.960]  совпадает с расстоянием между соответствующими функциями в этом пространстве все остается только
[40:41.960 --> 40:53.720]  разобраться с sk пределами то есть как их сопоставить друг другу ну смотрите тут все на самом
[40:53.720 --> 41:01.880]  деле тоже очень просто ведь если здесь вот из таких штук мы сделаем последовательность случайных
[41:01.880 --> 41:08.840]  величин которая куда-то в среднем квадратичном сходится да то есть если это n сходится к эти
[41:08.840 --> 41:15.400]  среднем квадратичном смысле ну и пусть как по по определению того пространства квадрат
[41:15.400 --> 41:24.760]  мот ожидания квадрат этой штуки ограни существует ограниченно вот то это значит что математическое
[41:24.760 --> 41:32.800]  ожидание модуля это n минус это m в квадрате сходится к нулю принадлежит бесконечности свойств
[41:32.800 --> 41:36.800]  фундаментальности последовательности то что в sk смысле она фундаментально но у нас это было
[41:36.800 --> 41:45.200]  какая-то лемма 2 что ли на лекции 4 такой да вот это в силу фундаментальности но это есть
[41:45.200 --> 41:52.160]  ничто иное как расстояние между ними расстояние между ними а мы знаем что расстояние сохраняются
[41:52.160 --> 41:58.760]  вот для вот таких вот величин мы это уже показали расстояние между ними сохраняются это будет
[41:58.760 --> 42:04.440]  интеграл от минус бесконечности до плюс бесконечности модуль gn который соответствует
[42:04.440 --> 42:11.960]  эти n минус gm который соответствует эти m в квадрате ds от лямбда и это штука будет стремиться к нулю
[42:11.960 --> 42:24.320]  это вот эти это вот эти то есть это стечение линейной комбинации для которых мы уже доказали вот
[42:24.320 --> 42:31.320]  эти соответствия вот только они сюда входят это будет равно вот этому где gn соответствует
[42:31.620 --> 42:36.900]  эти на gm соответствует это m они равны потому что это расстояние между ними в этом пространстве
[42:36.900 --> 42:40.700]  расставления между не менее в этом пространстве равен вас до расстояниев между пространствами
[42:40.700 --> 42:47.800]  мы доказали при этом преобразовании но опять же мы получаем фундаментальную по следовUNDV
[42:47.800 --> 42:54.080]  этом пространстве а она тоже сходится потому что этоimb 2 полное пространство
[42:54.080 --> 42:59.400]  всё нормально. Вот, и это получается сходится к нулевую. Значит, существует предел и здесь.
[42:59.400 --> 43:06.560]  Существует предел. Предел в смысле вот этого расстояния. Какой-то g от лямбда.
[43:06.560 --> 43:18.440]  И последний шажок, который мы здесь делаем. Давайте мы сопоставим вот этому эти, вот эту g от лямбда.
[43:18.440 --> 43:25.160]  Предел в этом пространстве, сопоставим предел в этом пространстве. Вот наш последний шаг.
[43:25.160 --> 43:30.720]  Мы сопоставили между тривиальными сетчениями, потом между линейными комбинациями,
[43:30.720 --> 43:43.600]  потом между пределами. Вот, потом между пределами. Так, хорошо.
[43:43.600 --> 43:55.920]  Хорошо, предел этот элемент мы сопоставим обратно.
[43:55.920 --> 44:08.400]  Значит, любой элемент из этого пространства является sk пределом некоторой последовательности этих
[44:08.400 --> 44:15.600]  штук. Но на самом деле xt тоже является пределом последовательности, просто постоянной последовательности xt, xt, xt и так далее.
[44:15.600 --> 44:23.480]  Так что на самом деле любой элемент вот этой вещи является sk пределом вот таких вот штук.
[44:23.480 --> 44:32.920]  В общем-то здесь то же самое. Любой элемент этого пространства является sk, является вот в этом
[44:32.920 --> 44:42.920]  смысле пределом вот таких вещей. Вот, является пределом таких вещей. Соответствиями между ними установили.
[44:42.920 --> 44:52.560]  Так, распространение соответствия. Так, ну и почему у нас будут расстояния? Ну, это просто следует и
[44:52.560 --> 44:57.440]  свойств сходимости. То есть, если мы установили сходимость для простых объектов, вот таких вот,
[44:57.640 --> 45:04.160]  которые сходятся к более сложным объектам sk пределам, то тогда вот это свойство сохраняемости скалярных
[45:04.160 --> 45:13.520]  произведений, оно распространяется и туда тоже. Вот, то есть мы там можем записать, например, это n на эту
[45:13.520 --> 45:22.080]  предел там равняется и так далее. Ну и перейти к пределу по n и мы получаем то, что нужно. То есть,
[45:22.080 --> 45:29.280]  короче говоря, по свойствам sk сходимости и сходимости в том пространстве мы получаем, что если вот эти
[45:29.280 --> 45:33.720]  свойства сохраняемости скалярных произведений расстояния справедливы над элементами, то они
[45:33.720 --> 45:42.720]  справедливы над их пределами. Вот. Так. Хорошо. Но это мы сделали соответственно. Но причем тут
[45:42.720 --> 45:47.440]  эта теорема вообще о том, что мы раскладываем процесс. То есть, это мы сделали некие подготовления.
[45:47.440 --> 45:52.720]  То есть, для нас теперь все равно где работать. Здесь или там. И мы знаем между ними соответствия.
[45:52.720 --> 45:58.280]  Мы можем взять элемент отсюда и знать, что ему соответствует какой-то элемент отсюда и наоборот.
[45:58.280 --> 46:03.280]  Мы можем взять здесь последовательность, которая куда-то сойдется. Мы можем взять соответствующую
[46:03.280 --> 46:07.720]  последовательность здесь, она сойдется туда тоже, куда надо и так далее. То есть, мы можем всем этим
[46:07.720 --> 46:19.240]  пользоваться. Да. То есть, мы знаем, что пусть предел здесь существует, тогда мы через
[46:19.240 --> 46:24.560]  фундаментальность показали, что пределы соответствующих g куда-то существуют. И вот
[46:24.560 --> 46:32.000]  сопоставим вот этому это куда-то. Куда-то сошлось. Неконструктивно получается. То есть,
[46:32.000 --> 46:46.000]  предел существует какой-то. Вот мы вот эту штуку то и сопоставим. Да. И это будет соответствие,
[46:46.000 --> 46:51.800]  а взаимнооднозначность будет просто потому, что свойства скалярного произведения расстояния,
[46:51.800 --> 47:01.560]  они распространятся еще и на вот эти СК-пределы. То есть, мы установили соответствие для этих,
[47:01.560 --> 47:14.200]  это тривиально. Да, да, да. То есть, расстояние между этими равно расстоянию между теми,
[47:14.200 --> 47:18.040]  просто в разных пространствах. Если здесь расстояние равно нулю, то есть, они совпадают
[47:18.040 --> 47:23.720]  почти, наверное, то значит, и там расстояние равно нулю. То есть, они совпадают с мыслью вон того
[47:23.720 --> 47:33.680]  расстояния. Ну, как бы с точностью значений в отдельных лямбдах функции могут быть разные,
[47:33.680 --> 47:39.680]  но вот в смысле такого расстояния они совпадают. То есть, в этом смысле взаимнооднозначности.
[47:39.680 --> 47:47.960]  Не буквальная взаимнооднозначность, а вот в смыслах вот этих вот расстояний взаимнооднозначности.
[47:48.040 --> 47:58.600]  Мы не различаем объекты, расстояние между которыми равно нулю. Вот. Так, хорошо. Теперь давайте я тут
[47:58.600 --> 48:08.520]  лишнее сотру. Теперь что мы сделаем? Ну, вы можете нарисовать снова две или рисовать туда же,
[48:08.720 --> 48:20.840]  но я не хочу тут перерисовывать и я добавлю сюда. Я оставлю X от T, но вы, наверное, лучше нарисуйте
[48:20.840 --> 48:27.920]  снова. Теперь мы будем работать с этими кружочками, зная, что между ними есть взаимнооднозначное
[48:27.920 --> 48:40.320]  соответствие. X от T мы оставим, и то, что ему соответствует E в степени и лямбда T мы тоже
[48:40.320 --> 48:53.160]  оставим. А теперь, вот в этом пространстве давайте мы возьмем вот такую функцию. Имеем право.
[48:53.160 --> 49:01.200]  G с индексом лямбда 0. Сейчас поясню почему. От лямбда равно индикатор, а лямбда меньше
[49:01.200 --> 49:07.960]  либо равно лямбда 0. Эта функция принадлежит вот этому пространству, потому что интеграл от нее
[49:07.960 --> 49:15.640]  будет равен интегралу от минус бесконечности до лямбда 0. Ну, в общем, это получается S от лямбда
[49:15.640 --> 49:21.960]  0 минус S от минус бесконечности. Что существует конечно и все хорошо. Значит, эта функция лежит
[49:21.960 --> 49:28.400]  в этом пространстве. Вот просто захотели и взяли. Лямбда 0 здесь параметр, лямбда переменная,
[49:28.400 --> 49:44.440]  это есть функция лямбды. А теперь, вот этой функцией кто-то соответствует там V от лямбда 0. Почему?
[49:44.440 --> 49:54.920]  Потому что, если мы лямбда 0 зафиксируем, это будет какая-то, это будет какая-то функция. Этой
[49:54.920 --> 50:02.200]  функцией сопоставляется случайная величина. Она может зависеть от лямбды 0. Если мы лямбда 0
[50:02.200 --> 50:09.840]  меняем, функция меняется. Ну и тогда меняется и эта случайная величина. Если мы будем варьировать
[50:09.840 --> 50:20.520]  лямбду 0, мы получим как бы множество функций для разных лямбда 0. Множество функций. Но это будет
[50:20.520 --> 50:28.480]  отражаться на вариациях здесь. Мы получим разные случайные величины для разных лямбда 0. Получается,
[50:28.480 --> 50:37.600]  что на V можно посмотреть как на процесс, который зависит от переменной лямбда 0. Понятно? Вот как
[50:37.600 --> 50:43.680]  получается. На V можно посмотреть как на процесс, который зависит от лямбда 0. Так вот, оказывается,
[50:43.680 --> 50:49.880]  что V это есть процесс с артагональными приращениями. Он лежит в этом пространстве,
[50:49.880 --> 50:55.880]  поэтому его мотождание равно 0. Так? И оказывается, что это процесс
[50:55.880 --> 51:07.240]  с артагональными приращениями. Почему? Докажем это. Это просто. Это просто доказать.
[51:07.240 --> 51:12.240]  Вот это я сотру, это уже нам не нужно.
[51:27.680 --> 51:28.360]  Где еще раз?
[51:28.360 --> 51:37.880]  Да, для него вот лямбда 0 это время.
[51:37.880 --> 51:54.440]  Возьмем произвольные лямбда 1, лямбда 2, лямбда 3, лямбда 4 и рассмотрим математическое ожидание
[51:54.440 --> 52:05.960]  V от лямбда 4 минус V от лямбда 3, V от лямбда 2 минус V от лямбда 1. Сопряженное.
[52:05.960 --> 52:14.800]  То есть скалярное произведение вот этих приращений. Мы с вами выяснили,
[52:14.800 --> 52:23.160]  что скалярное произведение здесь равно скалярному произведению соответствующих функций там.
[52:23.160 --> 52:30.720]  Так что переходим теперь туда. Это есть интеграл от минус бесконечности до плюс
[52:30.720 --> 52:39.880]  бесконечности. От чего? Значит, G, которая соответствует лямбде 4 минус G,
[52:39.880 --> 52:48.800]  которая соответствует лямдии 3, на g, которая соответствует лямдии 2, g, которая
[52:48.800 --> 52:57.880]  соответствует лямдии 1. Перешли сюда. Ну потому что что такое процесс v, мы не
[52:57.880 --> 53:01.720]  понимаем с вами, что такое абстрактная какая-то v, она существует,
[53:01.720 --> 53:12.200]  ну кто она неясна. Вот кто она неясна. А вот что такое g, мы знаем, это индикатор. Ну и давайте
[53:12.200 --> 53:17.800]  вычислим этот интеграл. Но давайте мы вот что заметим. Вот что такое, например, вот эта разность,
[53:17.800 --> 53:26.840]  когда у нас лямда больше, чем лямда 1. Вот чему она равна? Давайте мы разберемся с вами. То есть у нас
[53:26.840 --> 53:37.840]  есть прямая лямда, лямда 1, лямда 2. Если лямда очень большая, индикатор равны нулю. То есть и обе
[53:37.840 --> 53:49.040]  функции, ой, обе функции равны нулю. Ноль и ноль. Если лямды очень маленькие, оба индикатора равны
[53:49.040 --> 53:58.960]  единицы. А если лямда промежуточная, то тогда один из них ноль, другой один, правильно? Ну кто из них кто?
[53:58.960 --> 54:11.480]  Значит у этого лямда побольше, поэтому здесь g лямда 2 равно 1, а здесь g лямда 1 равно 0. Потому что
[54:11.480 --> 54:19.800]  мы больше лямда 1, он ноль. Но для этого мы меньше, чем лямда 2, поэтому тот 1. Значит это получается,
[54:19.800 --> 54:28.280]  смотрите, индикатор того, что лямда принадлежит, ну я тут не знаю, открыто, не открыто, неважно с
[54:28.280 --> 54:37.840]  точностью этих отдельных точек. Значит лямда 1 запятая лямда 2. Во, абсолютно аналогично вот
[54:37.840 --> 54:49.040]  эта вещь, это есть индикатор того, что лямда принадлежит от лямда 3 до лямда 4. Но эти отрезки
[54:49.040 --> 54:57.120]  не пересекаются, ну быть может только вот в одной точке, но на интеграл это не влияет. Значит это ноль,
[54:57.120 --> 55:10.160]  видите, это ноль. Просто потому что мы взяли вот такую хитрую функцию g, индикаторную, что ее разность
[55:10.160 --> 55:19.760]  это вот такая вещь. Вот, значит это процесс с ортогональными приращениями. Ну и последнее,
[55:19.760 --> 55:30.400]  давайте мы наконец-таки возьмем, давайте мы возьмем частичную сумму того интеграла,
[55:30.400 --> 55:40.400]  про который нам надо доказать, что он равен х с кружочком от t. Так, только мне бы где-нибудь
[55:40.400 --> 55:51.240]  будет тут писать-то, я не знаю где. Там как-то узковато, ну или ладно, добавлю.
[55:51.240 --> 56:18.040]  Так, а вот мы сейчас это докажем, сейчас мы это докажем. Значит мы возьмем эту как сумму,
[56:18.040 --> 56:28.160]  по памяти ничего не помню. Примерно понятно, но чтобы не тратить время, значит от единицы до n,
[56:28.160 --> 56:41.120]  e в степени i, t мы зафиксируем, но возьмем разные лямбды, gt, на v от лямбды g плюс 1 минус v от лямбды
[56:41.120 --> 56:49.520]  gt. Вот рассмотрим вот такую случайную величину. Это частичная сумма того, что у нас стоит в теории
[56:49.520 --> 56:59.000]  микрамера, правильно? Вот, значит эта вещь принадлежит hx центрированная, ну потому что здесь
[56:59.000 --> 57:08.600]  просто линейные комбинации e с какими-то комплексными коэффициентами. Вот это наши альфы,
[57:08.600 --> 57:18.200]  для каждого g это какая-то альфы g. А нет, стоп, нет, нет, нет, я вру, вру, вру, вру, вру. Не это
[57:18.200 --> 57:27.440]  конечно альфа, альфа это детерминированные величины. Это получается линейные комбинации v и v лямбды g
[57:27.440 --> 57:33.320]  плюс 1 и v лямбды g. Ну и ничего страшного, потому что v лежат в нашем пространстве, значит любые их
[57:33.320 --> 57:42.520]  линейные комбинации тоже лежат в этом пространстве. t фиксировано, да, здесь t фиксировано. Так вот,
[57:42.520 --> 57:51.760]  вот эта штука лежит вот здесь, хорошо. Ну это является пределом чего-то, это является пределом
[57:51.760 --> 57:56.560]  чего-то, понятно, что их разность является пределом чего-то, все тут нормально. Ну так вот,
[57:56.560 --> 58:06.760]  вот этой эти, вот этой эти, давайте мы ее эту возьмем, эту, ей кто соответствует здесь, в этом
[58:06.760 --> 58:16.280]  пространстве? Какая-то функция g от лямбда, которая равна чему? Ну смотрите, как мы соответствия
[58:16.280 --> 58:25.120]  распространяли, соответствующим образом. Получается, сейчас, сейчас, сейчас, сейчас,
[58:25.120 --> 58:36.320]  это будет е в степени и t лямбда gt, когда лямбда принадлежит, а нет, и t лямбда, когда лямбда принадлежит
[58:36.320 --> 58:46.240]  от лямбда g до лямбда g плюс один и ноль иначе. Вот, потому что вот этой разности соответствует
[58:46.240 --> 58:55.000]  индикатор лямбда, принадлежащий отсюда-досюда, вот, умноженный на е. Ну и здесь получается,
[58:55.000 --> 59:02.240]  что g это сумма таких индикаторов, вот это, то есть получается, что g от лямбда это сумма
[59:02.240 --> 59:08.320]  экспонент, умноженных на индикаторы того, что лямбда лежит в этом отрезке. Так вот,
[59:08.320 --> 59:14.480]  эта сумма индикаторов с этими коэффициентами, ее можно записать вот так. То есть, если лямбда
[59:14.480 --> 59:22.800]  лежит вот в этом, а нет, сейчас, что-то все равно не то. Тут лямбда g стоит, значит, здесь лямбда g,
[59:22.800 --> 59:27.920]  вот так, вот так правильно. То есть, если лямбда попадает в этот интервал, то здесь будет е в степени
[59:27.920 --> 59:35.280]  лямбда g. Например, эта функция равна е в степени it лямбда 1, когда мы от лямбда 1 до лямбда 2. Эта
[59:35.280 --> 59:41.000]  функция равна е в степени it лямбда 2, когда мы принадлежим от лямбда 2 до лямбда 3. Ну и так далее.
[59:41.000 --> 59:57.520]  Да, это как бы получается в этом пространстве кусочно постоянная функция. То есть,
[59:57.520 --> 01:00:04.360]  на вот этом отрезке она принимает одно какое-то комплексное значение, на другом отрезке она
[01:00:04.360 --> 01:00:11.520]  принимает другое комплексное значение. Понятно, да? Вот. То есть, это кусочно постоянная функция,
[01:00:11.520 --> 01:00:26.760]  вот здесь стоит. Но теперь, если мы возьмем разбиение на множестве лямбд, значит, от лямбда 1
[01:00:26.760 --> 01:00:42.120]  до лямбда n, в каких-то пределах от минус a до a, устремим мелкость к нулю, n к бесконечности,
[01:00:42.120 --> 01:00:50.040]  после этого устремим a к плюс бесконечности. Все это можно описать как некий СК-предел,
[01:00:50.040 --> 01:00:58.560]  в конце концов. То мы получим, что это сходится к интегралу от минус бесконечности до плюс
[01:00:58.560 --> 01:01:05.560]  бесконечности e в степени it лямбда на dv от лямбда, просто по определению вот этой сходимости.
[01:01:05.560 --> 01:01:13.200]  Так, когда мы ввели разбиение, вот эти а устремили к бесконечности, мы получили,
[01:01:13.200 --> 01:01:23.200]  что это стремится вот сюда. То есть, это стремится к интегралу от минус бесконечности
[01:01:23.200 --> 01:01:32.840]  к плюс бесконечности e в степени it лямбда dv от лямбда. А куда устремится g от лямбда? Это кусочно
[01:01:32.840 --> 01:01:40.120]  постоянная функция, которая на вот этой штуке, на этом отрезке. Если мы лямбда устремим, если мы
[01:01:40.120 --> 01:01:51.520]  мелкостью устремим к нулю, то вся эта кусочная постоянность сожмется, и g от лямбда сойдется к
[01:01:51.520 --> 01:01:59.240]  e в степени it лямбда. За счет того, что a устремится к плюс-минус бесконечности, у нас пропадет вот
[01:01:59.240 --> 01:02:06.560]  этот ноль, потому что это ноль вне всех вот этих отрезков. Но так как a увеличивается и все больше
[01:02:06.560 --> 01:02:14.560]  лямбда попадает на всю большую часть числовой оси, то вот этот ноль он просто пропадет. Это я как бы
[01:02:14.560 --> 01:02:21.800]  интуитивно понятно рассказываю, но если немножечко напрячься, то это все аналитически там в одну строчку
[01:02:21.800 --> 01:02:30.600]  получается. Главное, чтобы вот в этих деталях не запутаться. Главное тут что? Что это ушло вон туда,
[01:02:30.600 --> 01:02:44.560]  а g от лямбда ушла не просто куда-то, а вот сюда, к e в степени it лямбда. Но соответствие-то
[01:02:44.560 --> 01:02:51.800]  взаимно однозначное. e в степени it лямбда. Смотрите, наша самая первая стрелочка. Кому соответствует?
[01:02:51.800 --> 01:03:04.200]  x центрированная t. Значит вот эти вещи это одно и то же. В смысле вот этого расстояния. То есть они
[01:03:04.200 --> 01:03:19.040]  совпадают почти наверное. Итак еще раз. Еще раз. Мы вели частичную сумму эту. Ей соответствует вот
[01:03:19.040 --> 01:03:29.840]  эта функция. Эта вещь сходится вот к этому интегралу. Эта вещь сходится вот к этой функции. Но эта
[01:03:29.840 --> 01:03:38.280]  функция соответствует вот этой случайной величине. Так? Расстояние между этими в этом пространстве
[01:03:38.280 --> 01:03:43.840]  устремилось к нулю. Значит расстояние между этими вещами в этом пространстве тоже обязано
[01:03:43.840 --> 01:03:49.280]  устремиться к нулю. Потому что расстояние сохраняется при этом преобразовании. Значит эта
[01:03:49.280 --> 01:03:55.000]  точка она должна быть здесь. Ну или по крайней мере расстояние между ними в смысле этого определения
[01:03:55.000 --> 01:04:05.240]  равно нулю. Все. Вот такая теорема. Итак схемы как бы этой теоремы на следующие. Ввести два у таких
[01:04:05.240 --> 01:04:11.240]  пространства, установить между ними взаимнооднозначное соответствие. Дальше вводим вот такие
[01:04:11.240 --> 01:04:16.880]  индикаторы и замечаем, что при варьировании лямбда 0 они соответствуют артагональному процессу.
[01:04:16.880 --> 01:04:22.080]  Процессу с артагональными приращениями вернее. Вот. Теперь берем частичные суммы такие,
[01:04:22.080 --> 01:04:28.760]  какие нам нужны. Они с одной стороны сходятся вот сюда. С другой стороны функция им соответствующая
[01:04:28.760 --> 01:04:35.320]  сходится сюда. А она отвечает вот этой вещи. Значит они равны. Почти, наверное. Все. Конец. Вот и вся
[01:04:35.320 --> 01:04:42.760]  теорема. Идейно она вся такая. Но все остальное это вот эти вот технические мелкие детали. Все они
[01:04:42.760 --> 01:04:53.360]  несложные. Вот так. Понятно? Ну хотя бы общий скетч. Понятно, что там есть технические моменты. Вы
[01:04:53.360 --> 01:04:58.760]  когда будете разбираться, вы может быть не сразу что-то поймете. Но сейчас, вот когда вы сейчас
[01:04:58.760 --> 01:05:04.960]  здесь сидите, главное вам вот общую мысль понять, вот как это все делается. Вот она вот такая. Вот это
[01:05:04.960 --> 01:05:18.720]  общая мысль. Красиво, да? Это теорема Крамера. Так. Хорошо. Мы движемся дальше. У меня остается не
[01:05:18.720 --> 01:05:27.600]  очень много времени. Значит у меня в ПДФ-ках вы, я думаю, сами прочитаете один абзац о физическом
[01:05:27.600 --> 01:05:33.440]  смысле спектральной плотности. Ну я немножечко уже об этом сказал. Что-то вот спектры, да там,
[01:05:33.440 --> 01:05:39.440]  вот эти всякие фурье преобразования. Это все из физики. Вот эти все функции, которые вы тут встретите,
[01:05:39.440 --> 01:05:46.000]  они все очень похожи. Там сильно стоит делить на Т, как из оптики. Вот. Но это вы почитаете. Там у
[01:05:46.000 --> 01:05:51.520]  меня про это написано. Ну пробелы, шум и обобщенные процессы тут тоже написано. Это тоже, как бы,
[01:05:51.520 --> 01:06:00.200]  вы сами прочитаете и разберетесь. Я не думаю, что на это стоит тратить время мне. Вот. А самое
[01:06:00.200 --> 01:06:09.320]  главное, что я расскажу, это одно из приложений всей вот этой теории. Линейная теория о стационарных
[01:06:09.320 --> 01:06:16.520]  процессах. То, что для инженеров это просто хлеб. То есть это то, что для инженеров является их
[01:06:16.520 --> 01:06:22.320]  основным инструментарем. Ну нет, не только, конечно, инженеров, вообще математиков, которые занимаются,
[01:06:22.320 --> 01:06:30.600]  например, обработкой сигналов. Это вот базовая теория. Линейная теория. И мы просто получили для нее
[01:06:30.600 --> 01:06:40.720]  некий фундамент. И вот буквально вот совсем такие элементы, элементы, элементы, элементы этой
[01:06:40.720 --> 01:06:44.240]  линейной теории, я здесь сейчас вам скажу.
[01:06:44.240 --> 01:07:11.760]  Значит так, так, так, так, так, так.
[01:07:11.760 --> 01:07:28.160]  Линейная теория о стационарных процессах. Значит первое, что я, может быть, стоило об этом сказать во
[01:07:28.160 --> 01:07:38.280]  время доказательства. Ну ладно, неважно, сейчас скажу. Значит вот мы установили, что х, центрированное
[01:07:38.280 --> 01:07:58.360]  от t, есть интеграл вот такого вот вида. Так, есть интеграл вот такого вида. Так, и смотрите, как
[01:07:58.360 --> 01:08:08.440]  интересно получается. Вот видите, х, центрированное от t. Вот здесь стоит тот, кому он соответствует. Вот это
[01:08:08.440 --> 01:08:16.560]  образ вот этой вещи в нашей теореме. Это не просто так, это образ в нашем отображении вот этой вещи.
[01:08:16.560 --> 01:08:25.080]  Можно доказать, но я это опускаю, это не тривиально, но мы это примем без доказательства, что на самом
[01:08:25.080 --> 01:08:36.080]  деле можно написать даже так. Для любого это из пространства х, центрированное, будет интеграл, это
[01:08:36.080 --> 01:08:46.440]  будет равно интегралу g от лямбда на dv от лямбда, где вот это g является образом вот этой этой, более
[01:08:46.440 --> 01:08:52.920]  сильные условия, понимаете, да. То есть мы установили соответствие между этими, нам никаких там
[01:08:52.920 --> 01:08:59.560]  сверхусилий, никаких теорем, лемок, дополнительных нам здесь не потребовалось. Но это можно и обобщить. Это
[01:08:59.560 --> 01:09:04.800]  лишь один из элементов этого пространства h, но на самом деле это равностно распространяется на любые,
[01:09:04.800 --> 01:09:21.760]  где вот это образ, образ это. Давайте мы это примем без доказательства. Вот такое наблюдение. Но отсюда
[01:09:21.760 --> 01:09:32.280]  что в частности следует, что если вы, допустим, умножите этот процесс на какую-то величину альфа,
[01:09:32.280 --> 01:09:41.120]  то это значит, что это перенесется и сюда тоже. Вот, то есть это означает, что эта вещь будет равна
[01:09:41.120 --> 01:09:48.480]  интегралу от минус бесконечности до плюс бесконечности альфа-е в степени и лямбда-т. Ну, в общем-то в силу
[01:09:48.480 --> 01:09:55.600]  линейности интеграла это и так понятно, что это вынесется туда. Это условие, оно более общее, но здесь
[01:09:55.600 --> 01:10:01.240]  мы видим как бы частный случай вот этого условия, сам по себе очевидный, что мы можем альфа внести
[01:10:01.240 --> 01:10:12.160]  внутрь dv от лямбда. Но когда мы умножаем процесс на альфу, то его корреляционная функция увеличивается
[01:10:12.160 --> 01:10:23.120]  в модуль альфа в квадрате раз. То есть это означает, что rx от t перейдет в модуль альфа в квадрате rx от t.
[01:10:23.120 --> 01:10:32.600]  И если rx от t у нас представляется в виде интегралы лямбда-т ds лямбда, то получается, что при этом
[01:10:32.600 --> 01:10:41.560]  преобразовании этот будет интегралом e в степени лямбда-т модуль альфа в квадрате ds от лямбда.
[01:10:41.560 --> 01:10:55.600]  Вот перейдет вот сюда. Ну и отсюда следует, что если мы обозначим за y альфа x центрированный от t,
[01:10:55.600 --> 01:11:06.760]  давайте тоже просто чисто для симметрии его обозначим y от t, то это означает, что ds y от лямбда
[01:11:06.760 --> 01:11:17.400]  это есть модуль альфа в квадрате ds x от лямбда, просто в силу однозначности разложения r. Вот.
[01:11:17.400 --> 01:11:28.340]  Ну и если у них есть плотности у y и у x, то тогда ρу лямбда равняется модуле альфа в квадрате
[01:11:28.340 --> 01:11:36.620]  ρх от лямбда. Вот. То есть такое вот линейное преобразование, оно меняет спектральную функцию
[01:11:36.620 --> 01:11:44.380]  вот таким вот образом. В линейной теории рассматривается обобщение вот таких вот линейных
[01:11:44.380 --> 01:11:51.940]  преобразований и вводят вот такой оператор l. Допустим, у нас есть некоторый линейный оператор l,
[01:11:51.940 --> 01:12:02.100]  который действует на x центрированное, в результате чего мы получаем следующую вещь.
[01:12:02.100 --> 01:12:12.980]  Интеграл от минус бесконечности до плюс бесконечности l, которая действует уже на е в степени и лямбда t на d
[01:12:12.980 --> 01:12:23.780]  в вот этого x от лямбды. Вот пусть нам дали оператор l такой, что он действует вот таким образом,
[01:12:23.780 --> 01:12:30.940]  то есть что его можно внести внутрь интеграла и что все его действия концентрируются только на
[01:12:30.940 --> 01:12:37.460]  действие на вот эту экспоненту. Вот это частный случай такого оператора умножения на некоторую
[01:12:37.460 --> 01:12:42.940]  постоянную альфа. И видите как получилось, что он по сути действует только вот на эту экспоненту.
[01:12:42.940 --> 01:12:49.860]  И есть такой целый класс линейных преобразований, тоже у Крамера можно посчитать, не только у него,
[01:12:49.860 --> 01:12:55.380]  что это такие за преобразования, которые позволяют внести это внутрь и представить это в таком виде.
[01:12:55.380 --> 01:13:05.620]  И пусть вот эта вещь, это есть phi от лямбда на е в степени и лямбда t. Вот не все преобразования
[01:13:05.620 --> 01:13:15.580]  таковы, но пусть это будет так. Опять же здесь мы это видим, это вот действие этого оператора на
[01:13:15.580 --> 01:13:21.180]  экспоненту, это некая функция лямбда, вообще говоря, а в нашем случае это просто константа лямбда,
[01:13:21.180 --> 01:13:38.340]  умножить на ту же самую экспоненту е. То есть да, пусть l такова. И на самом деле таких l очень много,
[01:13:38.340 --> 01:13:53.220]  про которые можно так сказать. Ну вот тогда, ну просто примеров много. И есть теория,
[01:13:53.220 --> 01:14:01.700]  которая описывает такие l. То есть всякие суммы, умножения, даже дифференцирование относятся к
[01:14:01.700 --> 01:14:13.500]  таким вещам. А что существование? Вот умножение на альфу уже существует хотя бы одно. Так,
[01:14:13.500 --> 01:14:22.980]  ну хорошо. И тогда мы получаем, что наш процесс у от t, который равен l эксцентрированный от t,
[01:14:22.980 --> 01:14:33.980]  это есть интеграл от минус в бесконечности до плюс в бесконечности, фи лямбда е в степени и лямбда
[01:14:33.980 --> 01:14:48.020]  t на dvx от t. Это с одной стороны, а с другой стороны это есть то же самое и лямбда t на dvy от t. И в силу
[01:14:48.020 --> 01:14:56.060]  однозначности разложения мы можем записать, что фи лямбда dvx, ой от t, от лямбда, извините,
[01:14:56.060 --> 01:15:09.620]  от лямбда равно dvx от лямбда равняется dvy от лямбда. Вот. Можно так это воспринять? Ну и
[01:15:09.620 --> 01:15:19.380]  по-другому можно воспринять. Мы знаем, что просто интеграл e dvx равен x центрированное от t и ему
[01:15:19.380 --> 01:15:32.660]  соответствует некая r от x. А если мы умножим ее на фи от лямбда, вот это, так сейчас, если мы умножим
[01:15:32.660 --> 01:15:50.100]  f от лямбда, это тоже будет элемент нашего пространства h. Так. Сейчас-сейчас-сейчас. Как бы мне это
[01:15:50.100 --> 01:16:04.660]  ввести, так чтобы было понятно. Не хочу делать несколько шагов вместе. Сейчас, одну секундочку.
[01:16:04.660 --> 01:16:19.900]  Подумаю, как бы мне это ввести. А, вот, наверное. Да, точно. Так, ну хорошо, мы на этом... Здесь
[01:16:19.900 --> 01:16:33.860]  мы на этом остановимся. Теперь вот что сделаем. Значит, v и x и y в пространстве h находятся, и
[01:16:33.860 --> 01:16:41.660]  расстояние между ними соответствует расстояниям для s. Значит, математическое ожидание модуля v от
[01:16:41.660 --> 01:16:54.100]  лямбда2-v от лямда1 в квадрате равно... значит, значит, значит... равно, равно, равно интегралу
[01:16:54.100 --> 01:17:01.060]  от минус бесконечности до плюс бесконечности вот этих наших g от лямбда. Помните? g от лямда2 от
[01:17:01.060 --> 01:17:11.060]  лямда минус g лямда1 от лямда в квадрате ds от лямда. Но вот эта вещь, это, индикатор того,
[01:17:11.060 --> 01:17:16.980]  что лямбда лежит в этом отрезке, значит это получается интеграл от лямбда 1 до лямбда 2
[01:17:16.980 --> 01:17:28.340]  ds от лямбда. то есть s от лямбда 2 минус s от лямбда 1. вот это мне сейчас понадобится. то есть
[01:17:28.340 --> 01:17:39.180]  получается, что математическое ожидание модуля v лямбда 2 любого x и y на v от лямбда 1 в квадрате
[01:17:39.180 --> 01:17:51.460]  равняется s от лямбда 2 минус s от лямбда 1. вот и вот эту вещь еще можно записать,
[01:17:51.460 --> 01:17:59.380]  просто использовать такую запись. она означает вот эту для конечных дифференциалов. модуль dv
[01:17:59.380 --> 01:18:09.420]  значит от лямбда в квадрате равняется ds от лямбда. то есть символ ds можно заменять на вот эту
[01:18:09.420 --> 01:18:19.460]  штуку, если при записи частных частичных сумм мы будем писать не разность s, а мат. ожидание модуля
[01:18:19.460 --> 01:18:25.580]  квадрата разности v. то есть мы можем записать, мы можем заменять в частичных суммах вот эту
[01:18:25.580 --> 01:18:30.420]  разность вот такой штукой, которая не разность, а квадрат разности мат. ожидания. ну в общем,
[01:18:30.420 --> 01:18:39.980]  понятно. ну так вот, я это к чему веду, что при переходе к y мы берем x и умножаем его на phi от
[01:18:39.980 --> 01:18:52.880]  лямбда. так? значит как поменяется s? это означает, что ds y от лямбда, это есть тот же самый ds x от
[01:18:52.880 --> 01:19:00.440]  лямбда. но вот эта v, которая внутри стоит, она умножится на phi. так что здесь получается модуль в
[01:19:00.440 --> 01:19:11.280]  квадрате phi. phi от лямбда в квадрате. вот. вот эту формулу запомните. ну плотности, если они существуют,
[01:19:11.280 --> 01:19:18.000]  они также связаны. плотность y равняется плотность x умножить на вот этот коэффициент. к чему я все
[01:19:18.000 --> 01:19:24.720]  это рассказываю веду? и в чем содержательный смысл всей этой теории? смотрите. в линейной
[01:19:24.720 --> 01:19:31.200]  теории стационарных процессов вот эти линейные операторы характеризуются своими функциями
[01:19:31.200 --> 01:19:39.840]  phi от лямбда. вот эта штука еще называется частотной характеристикой. вот это частотная
[01:19:39.840 --> 01:19:49.160]  характеристика. преобразование l. вот, например, у такого преобразования альфа, да, просто,
[01:19:49.160 --> 01:19:55.400]  просто умножение, у него частотная характеристика, вот она тривиальна, phi от лямбда равно вот этому
[01:19:55.400 --> 01:20:02.640]  альфе. так? тогда как преобразуется ds? модуль phi в квадрате, то есть модуль альфи в квадрате. вот
[01:20:02.640 --> 01:20:12.480]  у нас здесь появился. но у других преобразований у них может быть своя частотная характеристика. во
[01:20:12.480 --> 01:20:19.440]  временной области процесс, он может видоизменяться очень сложным образом. то есть линейное преобразование
[01:20:19.440 --> 01:20:26.300]  над процессом, вот, например, производное, sk производное или почти наверное производное, если они
[01:20:26.300 --> 01:20:34.780]  совпадают, это довольно сложное преобразование процесса. но оказывается, что это линейная, в смысле вот
[01:20:34.780 --> 01:20:41.900]  этих всех действий, операция. и этой производной соответствует тоже некоторая частотная характеристика.
[01:20:41.900 --> 01:20:47.180]  значит, если эту производную можно вносить внутрь интеграла, и там у меня в подъявках, посмотрите,
[01:20:47.180 --> 01:20:52.060]  там тривиальные условия, интеграл там квадрата лямбда на плотность должна быть ограничена,
[01:20:52.060 --> 01:21:02.620]  сходится. вот, то тогда, то есть для l, которая равна производной, которая совпадает с sk и совпадает, пусть
[01:21:02.620 --> 01:21:10.260]  почти наверное, производной, то для нее фи от лямбда, смотрите, если производную мы подействуем на
[01:21:10.260 --> 01:21:15.940]  экспоненту, то у нас вынесется и лямбда, и экспонента останется. это значит, что частотная характеристика
[01:21:15.940 --> 01:21:28.980]  равна и лямбда. вот, это значит тогда, что dsy от l равняется модуле лямбда в квадрате на dsx от лямбда.
[01:21:28.980 --> 01:21:34.460]  ну, и соответственно, плотности тоже так зависит. ρу от лямбда равно модуле лямбда в квадрате на
[01:21:34.460 --> 01:21:44.500]  ρх от лямбда. вот, это вот такой пример. но для того, чтобы это все работало, там нужно, чтобы вот
[01:21:44.500 --> 01:21:50.380]  такой интеграл был конечным. но это вы у меня уже, вот эти всякие детали технические, это вы
[01:21:50.380 --> 01:21:57.700]  посмотрите в моих pdf. вот, вот я прокомментировал вот эту теорию. то есть, все сводится к тому,
[01:21:57.700 --> 01:22:04.420]  что мы над процессом совершаем какие-то линейные операции и выражаем их в терминах вот этой
[01:22:04.420 --> 01:22:10.540]  функции phi. процесс во временной области может меняться очень сложно, но в частотной области
[01:22:10.540 --> 01:22:17.940]  он меняется тривиально. ты просто умножаешь свою спектральную плотность на квадрат модуля
[01:22:17.940 --> 01:22:24.460]  частотной характеристики этого преобразования. и вот над процессом ты можешь совершать
[01:22:24.460 --> 01:22:29.380]  целую серию линейных преобразований. дифференцирование, интегрирование, умножение,
[01:22:29.380 --> 01:22:35.100]  сложение, сдвиги. там кучу всяких операций ты можешь делать. и во временной области процесс
[01:22:35.100 --> 01:22:40.260]  и его свойством от ожидания, корреляционная функция там, ну хрен знает, что происходит с ней.
[01:22:40.260 --> 01:22:48.140]  но в частотной области у тебя просто наращиваются множители перед спектральной плотностью. если ты
[01:22:48.140 --> 01:22:55.740]  знаешь, если ты знаешь частотные характеристики преобразований, которые ты накладываешь процессу,
[01:22:55.740 --> 01:23:02.860]  то новый твой процесс, это просто процесс как бы старый, с плотностью старой, но умноженный
[01:23:03.060 --> 01:23:10.620]  последовательно на функции вот эти вот частотные характеристики. вот почему вот эта теория, она
[01:23:10.620 --> 01:23:17.700]  интересна. в частотной области все просто, проще, чем во времной. перешел в частотную область,
[01:23:17.700 --> 01:23:22.300]  сделал тут все, что тебе надо, а потом вернулся обратно, например, по теореме об обратном
[01:23:22.300 --> 01:23:28.180]  преобразовании. ты можешь найти r через rho. если ты нашел rho, ты находишь r, просто через
[01:23:28.180 --> 01:23:37.420]  интеграл, ну конечно. а так вот ты переходишь в частотную область и в ней работаешь. теория
[01:23:37.420 --> 01:23:42.100]  сигналов, она во многом построена на вот этих вот идеях. перейти в частотную область и там
[01:23:42.100 --> 01:23:52.700]  работать, если это оказывается удобным, а это часто оказывается удобным. вот такие дела, ребята.
[01:23:52.700 --> 01:24:04.900]  значит так, на этом мы с вами первое задание завершаем. торжественно вам объявляю. первое
[01:24:04.900 --> 01:24:13.100]  задание мы закончили. на следующей неделе будет контрольная работа, потоковая. значит в этой
[01:24:13.100 --> 01:24:21.700]  аудитории, в это время, 12-20, место как бы лекции получается. значит, я вашим семинаристам уже
[01:24:21.700 --> 01:24:31.500]  разослал правила. значит, это контрольная, вы за нее не можете получить штрафы, если вы не придете
[01:24:31.500 --> 01:24:38.060]  или придете, но плохо напишете, никаких штрафов вы не получаете. вот, я всем семинаристам об этом
[01:24:38.060 --> 01:24:44.260]  сказал. так, но вы можете получить какие-то плюшки за это. может быть какой-то преподаватель скажет,
[01:24:44.260 --> 01:24:49.580]  что вот вы решили все задачи, я вам засчитываю первое задание без всяких сдач. такой вариант
[01:24:49.580 --> 01:24:56.860]  возможен. вот, единственное, что за хорошее написание этой контрольной вы не можете получить
[01:24:56.860 --> 01:25:07.060]  плюс один балл в ведомостной экзамене. вот ограничение такое. но получить какие-то локальные
[01:25:07.060 --> 01:25:12.940]  плюшки за сдачу зданий, это вы уже обсудите со своими семинаристами. все семинаристы вольны
[01:25:12.940 --> 01:25:19.060]  по-своему это учитывать. кто-то может вообще скажет, что это все туфта и не будет никак учитывать. но это
[01:25:19.060 --> 01:25:24.340]  вы уже там сами разбирайтесь. вот, по крайней мере штрафа не может быть какого. а так вы можете
[01:25:24.340 --> 01:25:29.300]  прийти и попробовать ее написать и обсудить ее со мной. например, эту контрольную задачки просто
[01:25:29.300 --> 01:25:36.580]  свои силы померятся, задачки будут несложными абсолютно. никаких творческих элементов олимпиадного
[01:25:36.580 --> 01:25:42.860]  вот этого там не будет. то есть это будут стандартные задачи на стандартные темы. то есть
[01:25:42.860 --> 01:25:49.060]  абсолютно спокойные нормальные задачи. вы не можете на контрольной ничем пользоваться,
[01:25:49.060 --> 01:25:55.380]  но вы можете задавать вопросы поясняющего характера преподавателям, которые здесь будут
[01:25:55.380 --> 01:26:00.580]  присутствовать. например, вы что-то не понимаете в условии или вы там забыли какую-то теорему,
[01:26:00.580 --> 01:26:07.140]  вам ее могут напомнить. и вы ее тогда примените. то есть препод за вас не может решить вашу задачу,
[01:26:07.140 --> 01:26:12.020]  но просто какие-то моменты подсказать, в том числе теории, какие-то определения, теоремы,
[01:26:12.020 --> 01:26:20.100]  он может. это вполне нормально. у нас так было всегда. вот такие вот условия. а так гаджетами там
[01:26:20.100 --> 01:26:25.820]  и книжками и конспектами пользоваться нельзя. вот это будет контролироваться. ну все тогда.
