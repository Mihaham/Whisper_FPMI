[00:00.000 --> 00:13.520]  Приветствую всех, собравшихся в Zoom и собравшихся здесь на нашем воскресном занятии. Сегодня мы
[00:13.520 --> 00:20.720]  хотим продолжить нашу историю про конкарнси, а чуть точнее историю про средство выражения
[00:20.720 --> 00:26.400]  конкарнси в коде. Как именно мы в коде хотим описывать какие-то обработчики запросов,
[00:26.400 --> 00:32.840]  ну или любые активности, которые чередуются друг с другом, которые соперничают за ядра процессора,
[00:32.840 --> 00:38.440]  которые выполняют вот вывод, ждут каких-то таймеров, общаются друг с другом через каналы,
[00:38.440 --> 00:46.040]  блокируют общий mutex и так далее. У нас было два больших механизма, один из них мы сейчас уже
[00:46.040 --> 00:52.240]  почти целиком написали, это файберы, другой механизм был это фьючи, и мы этим займемся в
[00:52.240 --> 00:59.080]  самом ближайшем будущем, в смысле, напишем их. Сегодня нас ждет еще один механизм,
[00:59.080 --> 01:05.240]  который называется stackful-крутины. Ну и чтобы мотивировать их возникновение, давайте вспомним,
[01:05.240 --> 01:11.360]  точнее даже не вспомним, посмотрим на файберы перед нами. А расширил ли я экран в Zoom?
[01:11.360 --> 01:24.800]  Да, совершенно верно. Вот, теперь мы на месте. Итак, смотрим на файберы, которые мы сейчас пишем,
[01:24.800 --> 01:29.480]  которые мы уже может быть написали, они умеют запускаться, они умеют синхронизироваться через
[01:29.480 --> 01:37.360]  mutex и через weight-группы, они скоро научатся, у кого-то научатся, у кого-то нет, синхронизироваться
[01:37.360 --> 01:43.800]  через каналы, блокироваться на селектах в ожидании сообщения одного из каналов. И мы сейчас,
[01:43.800 --> 01:48.880]  на прошлой лекции, мы говорили про то, как устроен планировщик для Groot-In-Go, и у нас
[01:48.880 --> 01:52.640]  появилось домашнее задание, где нужно написать для вот этих файберов хороший планировщик,
[01:52.640 --> 01:58.960]  который шардирован, в котором мало синхронизации, мало коммуникации между ядрами, где каждый
[01:58.960 --> 02:05.000]  ядро, каждый поток worker на своем ядре по умолчанию старается работать со своей локальной очередью.
[02:05.000 --> 02:10.400]  За счет этого у нас получается физически гораздо больше параллелизма, ну и файберы
[02:10.400 --> 02:15.880]  исполняются эффективно, потому что файберы – короткие задачи, им хороший планировщик
[02:15.880 --> 02:20.160]  необходим, а обычного предпола недостаточно. Но это долгая история, мы в прошлый раз про нее
[02:20.160 --> 02:27.440]  поговорили, а сейчас смотрим именно на файберы с их примитивами синхронизации и думаем, на чем
[02:27.440 --> 02:33.720]  вся эта конструкция вообще держится. Ну вот эти файберы, они в конце концов где-то исполняются,
[02:33.720 --> 02:37.840]  исполняются они в некотором планировщике, как было сказано. Этот планировщик – это threadpool,
[02:37.840 --> 02:42.720]  но сами файберы про threadpool ничего не знают, про конкретный threadpool ничего не знают, да и вообще
[02:42.720 --> 02:48.200]  наверное про threadpool, потому что они умеют запускаться в произвольном экзекутере.
[02:48.200 --> 02:59.560]  Что это за экзекутер – совершенно неважно. Этот экзекутер умеет исполнять задачи.
[02:59.560 --> 03:11.920]  Эти задачи, ну в новой задачи про планировщик, вот этот шаблон уже был опубликован, это
[03:11.920 --> 03:18.280]  интрузивные задачи, которые реализуют интерфейс itask, умеют запускаться, ну либо отбрасываться,
[03:18.280 --> 03:23.920]  потому что планировщик решил быстро остановить работу. И эти задачи, они интрузивные, то есть в них
[03:23.920 --> 03:30.720]  интегрируются указатели, которые позволяют задачам связываться в какие-то структуры данных,
[03:30.720 --> 03:38.400]  ну и вот просто встраиваться без лишних локаций во внутренности планировщика. Вот это про runtime,
[03:38.400 --> 03:44.800]  про то, где исполняются файберы, исполняются не в виде задач. А дальше, с другой стороны,
[03:44.800 --> 03:52.720]  нужно вспомнить, как устроены файберы над планировщиком, то есть как устроены все эти
[03:52.720 --> 03:59.640]  мютоксы, вейт-группы, каналы, ну про каналы мы еще не знаем. В конце концов, все вот эти файберы
[03:59.640 --> 04:08.560]  превращаются на уровне планировщиков задачи. И как эти задачи устроены? Ну вернее, как устроено
[04:08.560 --> 04:13.920]  исполнение файбера? Он бежит, бежит, бежит, встречает какой-нибудь мютокс и пытается его
[04:13.920 --> 04:20.040]  захватить. Если этот мютокс свободен, он захватывает этот файбер, его и бежит дальше. Если же мютокс
[04:20.040 --> 04:27.680]  уже оказывается захвачен, то файбер должен остановиться. Он добавляет себя в очередь мютокса
[04:27.680 --> 04:33.920]  и останавливается. Что значит останавливается? Ну вот мы говорили, как эту остановку реализовать.
[04:33.920 --> 04:40.560]  Нам нужен примитив, который называется корутина или сопрограмма. Это такой волшебный вызов функции,
[04:40.560 --> 04:47.640]  который может запуститься, а потом в середине сказать «я останавливаюсь», сказать suspend. Вот давайте
[04:47.640 --> 04:58.640]  вспомним про корутина немного. Вот корутина, которая делала первый шаг, ну тут второй шаг,
[04:58.640 --> 05:05.400]  но для нее первый. Говорила корутина suspend и останавливала свое выполнение. Мы запускали эту
[05:05.400 --> 05:11.040]  корутину с помощью вызова резюм. Она делала первый шаг, говорила suspend. Этот suspend возвращал
[05:11.040 --> 05:17.600]  управление вот этот резюм. Резюм завершался. Вот потом мы говорили второй резюм, и корутина
[05:17.600 --> 05:23.240]  возобновлялась с той точки, где она остановилась ранее. Ну то есть корутина – это был такой механизм,
[05:23.240 --> 05:31.280]  который позволял, который обобщал сам по себе понятие обычных функций, сопрограмма, подпрограмма,
[05:31.280 --> 05:39.320]  если переводить дословно и параллельно обозначать. И мы эти сопрограммы, корутины,
[05:39.320 --> 05:44.960]  использовали для реализации файберов. В нашем экзекьюторе, какой бы сложный он ни был,
[05:44.960 --> 05:50.760]  задача для файберов – это задача, которая резюмит корутину файбера. И в этой корутине
[05:50.760 --> 05:55.720]  исполняется какой-то код пользователя. Этот код пользователя встречает mutex. На mutex мы
[05:55.720 --> 06:00.360]  добавляемся в очередь и останавливаем корутину. И шаг файбера завершается, задача завершается,
[06:00.360 --> 06:06.680]  и файбер когда-нибудь будет запланирован снова, когда другой файбер достанет его, достанет что-то
[06:06.680 --> 06:14.720]  из очереди, и наш файбер разбудит, то есть запланирует резюм корутины в трэдпул. Так? Это мы
[06:14.720 --> 06:18.880]  все вроде понимаем. Но тут много слов, довольно сложно, хуже звучит, но к этой стадии курса,
[06:18.880 --> 06:29.160]  кажется, мы уже должны это в голове аккумулировать. Теперь нужно сделать еще один шаг и подумать,
[06:29.160 --> 06:37.280]  вот на чем. Что такое корутина? Ну, вернее, не что такое корутина, а как она реализована. Вот пока
[06:37.280 --> 06:45.000]  может быть в нашем понимании корутина как-то связана неразрывно с понятием переключения контекста.
[06:45.000 --> 06:54.080]  Когда мы говорим резюм, мы активируем некоторый контекст заранее подготовленный, где на своем
[06:54.080 --> 06:58.560]  собственном стэке запускается какая-то пользовательская функция. Потом эта пользовательская
[06:58.560 --> 07:06.800]  функция выполняется, встречает корутин suspend, ну и что там происходит? Там мы сохраняем текущий
[07:06.800 --> 07:15.480]  контекст в поле класса, в поле корутины, и активируем контекст того кода, который корутина вызывал,
[07:15.480 --> 07:25.600]  резюмил ее. Вот я сегодня предлагаю подумать, вот на чем. Что такая связь корутина и переключение
[07:25.600 --> 07:31.960]  контекста? Она совершенно нефундаментальная, и понятие корутины, оно гораздо более общее и более
[07:31.960 --> 07:39.000]  универсальное, чем механизм переключения контекста. Переключение контекста для корутины,
[07:39.000 --> 07:48.160]  ну, корутина вполне может быть реализована без механизма переключения контекста. И мы сегодня
[07:48.160 --> 07:54.960]  поговорим как раз про другой тип корутин, который этот механизм не использует. Это stackless
[07:54.960 --> 08:04.200]  корутины, которые вы, наверное, видели в C++. Ну, вот смотрите, тут написано coroutines as stackless,
[08:04.200 --> 08:13.440]  а наша корутина stackful. Вот в самом основании всех наших файберов лежит понятие корутины,
[08:13.440 --> 08:21.240]  и вот сейчас мы хотим это понятие корутины по-другому реализовать. Это наш план на сегодня.
[08:21.240 --> 08:29.520]  И разобраться, как, собственно, этот механизм работает в языке C++, потому что язык C++ вам
[08:29.520 --> 08:35.840]  приносит вот эти самые stackless корутины. И это важно, что это происходит именно на уровне языка. Ну,
[08:35.840 --> 08:42.720]  вот это то, к чему мы сегодня придем. Итак, давайте подумаем, в чем разница stackful, разберемся,
[08:42.720 --> 08:49.840]  в чем разница stackful корутины stackless корутины. Разница очень простая. Вот посмотрим на пример,
[08:49.840 --> 09:01.880]  например, с итератором, который у нас был. У нас было дерево, у нас был итератор по дереву,
[09:01.880 --> 09:07.840]  мы говорили move to next, и этот итератор двигался по узлам. Мы тогда, когда это обсуждали, говорили,
[09:07.840 --> 09:12.640]  что удобно итерироваться по дереву рекурсивно, но, правда, тогда не напишешь линейный итератор.
[09:12.640 --> 09:18.680]  Как же написать линейный итератор, который бы внутри был реализован как рекурсивная функция? Ну,
[09:18.680 --> 09:24.560]  видимо, нужно воспользоваться корутинами. Видимо, нужно запустить рекурсивную функцию, а когда мы
[09:24.560 --> 09:30.060]  хотим, когда мы доходим до очередного узла, просто корутину остановить, вызвать здесь коротень
[09:30.060 --> 09:39.060]  саспенд, выпрыгнуть, и вот здесь мы будем, мы, получается, встали в рекурсии в новый узел
[09:39.060 --> 09:44.580]  дерева, и нужно вернуть пользователю данные из этого узла. Вот stackful корутины — это корутина,
[09:44.580 --> 09:53.660]  которая... Этот пример иллюстрирует stackfulness корутины. Ну, давайте сразу сделаю замечание.
[09:53.660 --> 09:59.140]  Stackful корутины и stackless корутины не означают, что у корутины есть stack или нет stack. У любого
[09:59.140 --> 10:03.540]  кода, любому коду, чтобы исполняться, нужен stack. В смысле, процессору, чтобы исполнить код,
[10:03.540 --> 10:11.420]  нужен stack. Это никуда не денется. Разница в том, что как по отношению к stack вызовов ведет себя
[10:11.420 --> 10:17.300]  к рутина, которая останавливается. Вот разница в этом. Stackful корутина, когда останавливается,
[10:17.300 --> 10:26.300]  останавливает не только вот свой вызов, вот этот вот вызов, текущий триволк, в смысле, самый глубокий,
[10:26.300 --> 10:31.900]  а останавливает все вызовы по stack выше. То есть замораживает весь stack и выпрыгивает куда-то
[10:31.900 --> 10:41.620]  в колер, который снаружи вызвал резюм, где-то здесь. Stackless корутина, наоборот, когда она
[10:41.620 --> 10:49.260]  останавливается, она останавливает только саму себя, то есть только самый вложенный вызов. То,
[10:49.260 --> 10:57.140]  что выше по stack живет своей жизни дальше. Это, может быть, пока не очень понятно,
[10:57.140 --> 11:03.860]  но чтобы это почувствовать, нужно разобраться в механике корутина, stackless корутина. И как можно
[11:03.860 --> 11:11.740]  было бы поступить? Можно было бы взять stackless корутина C++ и разбираться, как они устроены. Мы
[11:11.740 --> 11:20.300]  к этому придем, но начнем мы совершенно с другого. Мы попробуем сами реализовать stackless корутины,
[11:20.300 --> 11:26.260]  просто руками их написать. Я объясню, почему это не самая очевидная вещь, но чуть позже, наверное.
[11:26.260 --> 11:38.180]  Вот смотрите, давайте рассмотрим такой абстрактный пример. У нас есть функция foo, у нас есть
[11:38.180 --> 11:44.380]  функция bar, у нас есть функция baz, и у нас есть некоторая корутина. Функция, которая принимает
[11:44.380 --> 11:51.140]  аргумент, вызывает функцию foo, потом останавливается, потом вызывает функцию bar от результата функции foo,
[11:51.140 --> 11:56.660]  вызова функции foo, потом снова останавливается, потом вызывает функцию baz, куда передает
[11:56.660 --> 12:03.140]  вычисленные ранее a, b и аргумент x, потом вводит получившийся на экран. Оно закомментировано,
[12:03.140 --> 12:09.540]  потому что это некоторые псевдокод. Это наше намерение. Мы хотим в языке нашем, в программе
[12:09.540 --> 12:17.780]  C++ выразить такую корутину. Что мы можем сделать? Ну, мы можем воспользоваться stackful корутинами,
[12:17.780 --> 12:25.060]  которые у нас уже есть, которые мы с вами писали. Вот мы пишем там вызов foo, потом мы останавливаем
[12:25.060 --> 12:29.780]  корутины, потом вызов bar, потом останавливаем корутины, потом вызов baz, печатаем на экран. И
[12:30.020 --> 12:38.380]  вот мы запускаем этот код, и он делает три шага, разумеется, и выводит ответ. Ну, я не стану проверять,
[12:38.380 --> 12:45.340]  наверное, он правильный. Вот мы такую корутину выразились помощью stackful реализации. Как она
[12:45.340 --> 12:49.380]  устроена, мы тоже хорошо знаем. Там переключение контекста, локация и стэков, вся эта история.
[12:49.380 --> 12:56.980]  А теперь мы хотим написать альтернативную реализацию корутины, альтернативную реализацию,
[12:56.980 --> 13:03.180]  которая была бы stackless. Причем эта реализация, которую мы сейчас напишем,
[13:03.180 --> 13:16.740]  она будет реализацией конкретно этой корутины. Вот наш класс stackful корутин или просто корутин,
[13:16.740 --> 13:21.060]  это был такой универсальный класс, в котором мы передавали лямбду, и эта лямбда работала
[13:21.060 --> 13:30.020]  как корутина. Сейчас мы хотим написать корутину прям голыми руками и конкретно эту. Но, возможно,
[13:30.020 --> 13:37.500]  мы сможем сделать это эффективнее. Вот давайте подумаем, как выглядела бы реализация идеальная,
[13:37.500 --> 13:45.580]  вот конкретно этой корутины. Она получится не общей, очень конкретной, но вот конкретно для
[13:45.580 --> 13:57.660]  этой корутины можно было написать этот класс. Ну, прямо так, да, но это уж прям совсем конкретно,
[13:57.660 --> 14:05.620]  нужно чуть более общую схему наметить. Итак, нам нужен вызов резюм, и этот вызов резюм запускает
[14:05.620 --> 14:11.460]  очередной шаг, потом корутина доходит до точки остановки и останавливается. Давайте подумаем,
[14:11.460 --> 14:21.340]  как выглядит, как можно описать наиболее компактно состояние вот такой вот остановленной корутины,
[14:21.340 --> 14:25.140]  вот конкретно этой корутины, как можно было писать ее состояние.
[14:25.140 --> 14:35.780]  Ну, у нас есть локальные переменные, они потом используются, видимо, состояние остановленной
[14:35.780 --> 14:44.900]  корутины, это состояние локальных переменных, там A, B, C. A, B, C это локальные переменные,
[14:44.900 --> 14:50.260]  ну, соптимизировал бы у меня, возможно, сейчас к этому придем. У нас еще есть аргумент,
[14:50.260 --> 14:56.860]  который тоже нужно запоминать, чтобы потом функцию bus вызвать, ну, и видимо, в вызове резюм нужно
[14:56.860 --> 15:11.220]  помнить, какой шаг мы сейчас выполняем. Итого, у нас состояние такой корутины, чем образовано? Во-первых,
[15:11.220 --> 15:20.740]  это локальные переменные, ну ладно, в нулевых это аргументы, во-первых, это локальные переменные,
[15:20.740 --> 15:27.180]  и во-вторых, это, ну, напишем так, instruction pointer. Ну, instruction pointer тут, конечно, не буквально
[15:27.180 --> 15:32.620]  нужно понимать, а вот некоторые абстакты, instruction pointer, который указывает на номер
[15:32.620 --> 15:40.420]  очередного шага. Вот давайте мы такую корутину сейчас и напишем. У нее есть аргументы,
[15:40.420 --> 15:55.700]  у нее есть локальные переменные, и у нее есть instruction pointer, который будет выглядеть
[15:55.700 --> 16:07.180]  несколько проще, просто вот так. Ассоциация корутины строится, она получает аргумент,
[16:07.180 --> 16:22.260]  давайте мы его запомним в поле. А дальше мы хотим эту корутину утерировать в резюм. Ну,
[16:22.260 --> 16:28.100]  и что мы здесь напишем? Посмотрим, какой шаг нам сейчас нужно сделать. Если это нулевой шаг,
[16:28.100 --> 16:37.780]  первый шаг логически, мы вызовем функцию foo, а потом мы должны остановиться. Как мы остановимся?
[16:37.780 --> 16:47.020]  Просто return напишем. Это и есть наш suspend. Да, ну нужно, чтобы в следующем резюме мы
[16:47.020 --> 16:49.940]  продолжили работать с правильного места, поэтому перед тем, как мы остановимся, мы
[16:49.940 --> 16:54.060]  продвинем label вперед. А дальше, если нас запустили второй раз, то мы проверим, что,
[16:54.060 --> 17:00.820]  если label теперь единица, то мы вызовем, видимо, вызов bar, сделаем вызов bar,
[17:00.820 --> 17:24.220]  снова продвинем label и остановимся. Ну, и наконец, мы здесь вызовем bus от a, b, x,
[17:31.820 --> 17:40.100]  ну вот, похоже на корутину, да? И можно теперь ее запустить и посмотреть, что результат не
[17:40.100 --> 17:46.620]  поменялся. Ну, если мы нигде не ошиблись, разумеется. Не поменялся. Ну вот, мы написали ту же самую
[17:46.620 --> 17:51.100]  корутину по-другому. Беда в том, что класс этот переиспользовать нельзя, он какой-то очень
[17:51.100 --> 18:02.340]  конкретный, но зато, кажется, он реализован оптимально. Правда? Вот, и это реализация,
[18:02.340 --> 18:08.660]  это stackless реализация, вот такой вот корутина. А теперь нужно увидеть некоторую общую
[18:08.660 --> 18:16.300]  конструкцию. Как может быть реализована корутина, которая, останавливаясь, останавливает только себя?
[18:16.300 --> 18:22.700]  Ну, она, эта корутина, этот вызов функции, он теперь имеет некоторое состояние в
[18:22.700 --> 18:32.380]  установленном виде. Это состояние мы описываем в виде класса. Вот, для нашей корутины нужен state.
[18:32.380 --> 18:39.540]  Что в этом state будет? Будут аргументы, будут локальные переменные. Ну вот, кстати, локальные
[18:39.540 --> 18:45.420]  перемены здесь можно было бы и немного сэкономить, потому что зачем делать с полем класса, можно же
[18:45.420 --> 18:53.020]  просто оставить буквально локальный перемен, потому что между разными шагами она не используется.
[18:53.020 --> 19:00.660]  И нужен такой instruction pointer в виде просто лейбла, который указывает, вот какой шаг сейчас происходит.
[19:00.660 --> 19:06.380]  Ну, если у нас есть цикл этот лейбл, он, конечно, немного сложнее меняется, но не суть.
[19:06.380 --> 19:17.540]  Вот, в общем виде реализация stackless корутины. CarRoutingState, у которого есть в полях аргументы,
[19:17.540 --> 19:26.100]  локальные переменные и лейбл. Проблема пока в том, что мы сгенерировали такой класс руками. Вот у нас
[19:26.100 --> 19:32.140]  такая крафтовая корутина получилась конкретно для вот этого примера. Каждый раз писать мы,
[19:32.140 --> 19:36.820]  наверное, так не хотим, но с другой стороны, вот преобразование из этого условного псевдокода,
[19:36.820 --> 19:45.140]  из этого не существующего в C++ синтаксе со спендами, в такой класс преобразование может выполнить,
[19:45.140 --> 19:53.580]  скажем, сам компедиатор абсолютно механически. Вот в этом идее, в том, чтобы научить компедиатор
[19:53.580 --> 20:02.740]  преобразовывать специально описанные функции с некоторыми специальными маркерами, которые указывают
[20:02.740 --> 20:08.780]  компедиатору, что это необычная функция корутина, вот такой вот класс, который дальше можно было бы
[20:08.780 --> 20:22.620]  запускать и который бы мог в своем вызове остановиться. Я бы сказал, что, во-первых, шаблоны
[20:22.620 --> 20:28.340]  это отдельная история, не нужно ее сюда привязывать, это скорее похоже на лямбды,
[20:28.340 --> 20:33.940]  потому что у нас есть на поверхности языка вот эти самые анонимные функции, а компедиатор
[20:33.940 --> 20:39.540]  просто их переписывает на функции, тоже на классы. Ну вот здесь мы берем какую-то функцию специальную и
[20:39.540 --> 20:46.380]  переписываем ее в виде класса. Ну пока вручную, а хотели бы делегировать это компедиатором. Вот.
[20:46.380 --> 20:52.780]  Реализация получается всегда такой и простой, потому что нам не нужно думать о том, что будет
[20:52.780 --> 20:59.740]  с вызовами выше по стеку. Нас всегда беспокоит только конкретный наш вызов. Один и единственный.
[20:59.740 --> 21:11.380]  Итак, с этим разбрались, да? Этот пример понятен. Что происходит, тоже понятно. Но единственное,
[21:11.380 --> 21:17.140]  что нужно сделать, это указать компедиатору каким-то образом, где именно корутина будет
[21:17.140 --> 21:27.300]  останавливаться, чтобы он мог вот разбить ее тело на вот такие фрагменты. Но, прямо скажем, вот
[21:27.300 --> 21:34.420]  корутины с таким интерфейсом нам не особенно полезны. Кажется, что мы в курсе не особенно
[21:34.420 --> 21:40.620]  занимались тем, что корутины итерировали вот резюмами. Ну то есть как? Мы в конце концов это
[21:40.620 --> 21:50.220]  делали где-то в недрах наших файберов. Но вообще-то файберы, вообще-то для конкуренции, а нам все-таки
[21:50.220 --> 21:56.780]  корутины нужны не абстрактно, а для конкуренции. Нам нужен был немного, нам нужна была немного
[21:56.780 --> 22:09.620]  другая логика. Вот допустим, давайте посмотрим на какой-нибудь пример и посмотрим на пример сейчас.
[22:09.620 --> 22:26.620]  Например, в файберах. Ну вот, мы файберы, мы отправляем сообщение в канал, мы получаем сообщение из
[22:26.620 --> 22:35.380]  канала. Вот здесь мы блокируемся. Вот когда мы говорим про файберы и мы понимаем, что за ними
[22:35.380 --> 22:43.020]  стоят корутины, нас, как правило, не интересуют отдельные резюмы. Нас интересует такая логика. Мы
[22:43.020 --> 22:54.260]  хотим остановиться и запланировать свое возобновление. Иначе говоря, мы хотим чего-то дождаться. Вот дождаться
[22:54.260 --> 22:59.740]  каким образом? Остановившись и запланировав возобновление. Когда мы встречаем ресив на канале,
[22:59.740 --> 23:08.300]  или когда мы встречаем, ну, например, вейт на вейт-группе. Вот пусть вейт на вейт-группе. Мы хотим
[23:08.300 --> 23:16.780]  остановиться и так, чтобы нас потом разбудили, когда счетчик вейт-группы опустится до нуля. Дождаться
[23:16.780 --> 23:24.980]  некоторого события мы хотим. Или, скажем, мы хотим заблокироваться до тех пор, когда пока не
[23:24.980 --> 23:30.660]  выполнится фьюча с тайм-аутом. У нас есть фьюча Void. Она наполняется Void, когда проходит тайм-аут
[23:30.660 --> 23:39.940]  250 миллисекунд. И мы хотим заблокировать файбер на 250 миллисекунд. Дождаться, пока во фьюче
[23:39.940 --> 23:48.660]  появится значение. Остановиться и подписаться на нее. Опять. Некоторое событие. Вот мы хотим сейчас
[23:48.660 --> 23:55.740]  для наших stackless корутин такую же логику. Мы не хотим для них вот этот ручной резьюм делать. Мы
[23:55.740 --> 24:03.060]  хотим, чтобы эти корутины могли запускаться и останавливаться, дожидаясь некоторого события.
[24:03.060 --> 24:10.220]  Иначе, говорю, мы хотим на них конкарнции писать. Вот давайте я покажу пример, чего мы хотим. Вот мы
[24:10.220 --> 24:18.900]  запускаем корутины. Вот у них есть свои собственные... Ну, смотрите. Тут префикс гор – это горрутины.
[24:18.900 --> 24:27.540]  Давайте я поясню, что имею в виду. Это уже не корутины. Ну, это корутины C++. Но мы их здесь называем,
[24:27.540 --> 24:37.780]  пожалуйста, это шутка. Горрутины, потому что корутины C++, вот stackless корутины, принес горнешанов.
[24:37.780 --> 24:47.420]  Он, кажется, то ли на аватарке, то ли на... На аватарке то ли канала, то ли чата. Канала. Вот этот
[24:47.420 --> 24:52.980]  человек, который драйвил, проповзал stackless корутин C++. Вот этот самый дизайн, который мы
[24:52.980 --> 24:59.980]  сегодня изучаем. Вот это его работа. И мы в честь него, значит, говорим про горрутины. То есть это
[24:59.980 --> 25:06.300]  такие корутины, которые используются в конкарнсе. Для конкарнсии. Они конкурируют между собой. Мы их
[25:06.300 --> 25:13.660]  запускаем. И они борются за мьютексы. Они лочат мьютексы, блокируют друг друга. Ну, блокируют, в смысле,
[25:13.660 --> 25:19.700]  останавливают друг друга. А другие корутины, горрутины продолжают исполняться. Вот код похож на
[25:19.700 --> 25:29.500]  файберы. Только у нас здесь написано ключевое слово coawait.mutex.log. Вот это тот синтаксис,
[25:29.500 --> 25:37.180]  который мы на самом деле хотим вместо suspend. Нам suspend не нужен. Нам нужен await. Остановить
[25:37.180 --> 25:46.540]  корутину до тех пор, пока не реализуется некоторое событие. Пока не освободится мьютекс. Понятен
[25:46.540 --> 25:55.260]  замысел? Вот. Так что на самом деле мы хотим, чтобы компилятор переписывал... Тут нужно прыгать
[25:55.260 --> 26:01.580]  между репозиториями. Простите. Чтобы компилятор не такие функции переписывал. Вот в такие классы.
[26:01.580 --> 26:13.060]  А чтобы он переписывал вот такие функции. Вот у нас была функция корутина. Она получила
[26:13.060 --> 26:22.060]  аргументом threadpool. Она в своем теле вызвала функцию asyncvia. Asyncvia — это очень простая
[26:22.060 --> 26:29.680]  функция. Она взяла threadpool, взяла лямбду. Построила promise и future и бросила в threadpool задачу,
[26:29.680 --> 26:37.020]  где запустила вот это вычисление, а потом его результат положила в promise. А пользователь отдала
[26:37.020 --> 26:46.380]  future. Понятно? Ну то есть мы запускаем функции asyncvia, асинхронное вычисление в threadpool и
[26:47.340 --> 26:56.100]  отдаем пользователю future. А пользователь — это корутина. И вот она хочет этой future дождаться с
[26:56.100 --> 27:05.660]  помощью coawate. И распаковать эту future, этот future int, просто в int. Давайте я опять пример покажу.
[27:05.660 --> 27:18.740]  Кажется, он у меня под боком должен… Ну это future get, только future get блокирует поток. Сейчас,
[27:18.740 --> 27:29.660]  где я нахожусь? Да, вот. Future get блокирует поток, а мы не хотим блокировать поток. Мы хотим остановить
[27:29.660 --> 27:34.740]  текущую корутину. Вот это причина, по которой корутина на самом деле хочет остановиться. Она
[27:34.740 --> 27:42.860]  хочет дождаться события. Вот этот пример. coawate future. Вот у нас есть future int. Мы можем, конечно,
[27:42.860 --> 27:49.860]  вызвать здесь get и заблокироваться, но мы не хотим. Мы хотим написать coawate future. И вот этот
[27:49.860 --> 27:56.860]  coawate остановит текущую корутину, только ее, не заблокировав поток. А когда future реализуется,
[27:56.860 --> 28:03.820]  когда там появится значение, то корутина возобновит свое исполнение. Вот мы хотим,
[28:03.820 --> 28:11.500]  чтобы компилятор переписывал для нас в некоторые автоматы вот такой вот код. Ну и давайте теперь
[28:11.500 --> 28:17.140]  снова поработаем за компилятором. Посмотрите, ну, смотрите, как устроена наша лекция. Мы не просто…
[28:17.140 --> 28:24.340]  Я бы мог рассказать, как… я бы мог рассказать, как… какой код напишет здесь компилятор. Но этот код
[28:24.340 --> 28:30.820]  мы не видим. Все-таки он где-то в недрах компилятора написан, он сложный. Поэтому мы сейчас сделаем
[28:30.820 --> 28:38.900]  следующее. Мы вернемся к нашим примерам и сами вручную попробуем поработать за компилятор и
[28:38.900 --> 28:50.620]  переписать вот эту функцию в автомат голыми руками. Опять как мы сделали здесь, но только уже для кода
[28:50.620 --> 29:09.060]  с фьючами. Ну, давайте думать, что тут должно быть. Опять, когда корутина переписывается,
[29:09.060 --> 29:17.060]  стеклос корутина переписывается в автомат, нужно запомнить в полях этого автомата аргумент и
[29:17.060 --> 29:20.980]  локальные перемены. Но аргумент тут, в данном случае, трэдпул.
[29:20.980 --> 29:48.900]  Итак, что сделать корутина на первом своем шаге?
[29:48.900 --> 30:15.780]  Ну, она вызывает функцию AsyncVIA. Да, у нас немного пробилось форматирование. Ну,
[30:15.780 --> 30:25.740]  pull это теперь не аргумент, это локальные перемены, это поле класса. Мы получили фьючу. Давайте
[30:25.740 --> 30:31.420]  вот так напишем. У нас было значение V, которое мы хотим в конце концов вычислить, а у нас пока есть
[30:31.420 --> 30:43.980]  просто будущее значение в фьюче. Что нам с ним дальше делать? Ну, что значит дождаться?
[30:43.980 --> 30:59.540]  А? Мы хотим дождаться этой фьючи. Но смысл корутины в том, что вот когда мы дожидаемся чего-то,
[30:59.540 --> 31:09.900]  мы останавливаем только корутину. Так вот, вопрос, что мне делать дальше? Вот я в прошлом
[31:09.900 --> 31:12.900]  примере, ну, у меня просто корутина останавливалась, потом она возобновлялась снаружи.
[31:12.900 --> 31:17.580]  Пользователь ему так вот, безусловно, руками. А теперь мы хотим, чтобы резюмка
[31:17.580 --> 31:24.300]  корутины был вызван автоматически, когда во фьюче появится значение. Ну, вот std фьюча,
[31:24.300 --> 31:29.580]  она не умеет, она здесь ничего не поможет, а вот наш фьюч, хороший, который мы все еще не написали,
[31:29.580 --> 31:35.380]  но вот займемся этим скоро-скоро-скоро, она умеет subscribe. То есть, мы можем подвесить на нее callback,
[31:35.380 --> 31:40.380]  который будет вызван, когда во фьюче появится значение. То есть, когда в трэдпуле закончится
[31:40.380 --> 31:52.140]  вычисление. Поэтому, что сделаем? Что мы сделаем? Мы скажем, что вот where future subscribe и тогда мы
[31:52.140 --> 31:58.460]  передаем callback, который получает result. Result это контейнер, который содержит либо значение типа
[31:58.460 --> 32:06.460]  t, либо int, либо ошибку. И что же мы напишем в этом subscribe? Что мы напишем в callback,
[32:06.460 --> 32:14.180]  который будет вызван, когда в трэдпуле закончится вычисление. Ну, мы должны, видимо,
[32:14.180 --> 32:22.940]  зарезюмить корутину, да, вот себя просто. И будет вызван снова этот, будет вызов продолжен,
[32:22.940 --> 32:34.980]  но мы должны к нему подготовиться. Видимо, мы хотим уже сейчас обновить лейбл, да. Вот у нас
[32:34.980 --> 32:42.180]  первый шаг корутины, вот второй шаг корутины. И если мы, ну, subscribe, он же подписывается на
[32:42.180 --> 32:47.100]  фьючу, а вычисление может быть вызвано, может быть, может завершиться очень быстро, поэтому
[32:47.100 --> 32:51.060]  резюм может случиться очень быстро. Поэтому мы должны уже к этому моменту подготовить лейбл.
[32:51.060 --> 33:02.940]  Вот. Ну и после этого можно будет написать return. Только нужно после этого самого резюма как-то
[33:02.940 --> 33:09.660]  вот здесь получить значение. Как нам это сделать? Ну, видимо, нужно завести, ну, это в конце концов
[33:09.660 --> 33:18.180]  локальная переменная, да, локальная переменная должна стать полем класса, поэтому мы пишем здесь
[33:18.180 --> 33:27.700]  v и перед возобновлением распаковываем результат. Ну, вообще говоря, там ошибка может быть,
[33:27.780 --> 33:37.820]  если на исключение игнорирую, ошибки игнорирую, считаю, что все хорошо. Не делайте так, ну, для
[33:37.820 --> 33:46.540]  наших целей подойдет. Ну что, а теперь можно вывести результат, да, наверное. Если мы нигде не
[33:46.540 --> 34:06.020]  ошиблись, то все должно работать. Ну, давайте проверим, что она работает. Вот. И к рутину нужно,
[34:06.020 --> 34:12.700]  ну, мы не будем ее резюмить, скорее, это операция start более уместно, которая делает резюм. И мы
[34:12.700 --> 34:39.580]  к рутину стартуем. Работает, да? Ну, давайте убедимся, что точно работает. Вот, код должен
[34:39.580 --> 34:51.820]  повисеть три секунды сейчас. Вот, никакого блокирующего ожидания в этом коде нет. Видно,
[34:51.820 --> 35:06.220]  да? Вопрос, где выполнится первый шаг к рутине? Ну, здесь, да? Внутри вызова start. А где вызовется
[35:06.220 --> 35:14.620]  второй шаг к рутине? Выполнится второй шаг к рутине, вот этот вот. Он в thread pool выполнится,
[35:14.620 --> 35:18.740]  потому что в thread pool мы запустим вычисления, в thread pool эта задача добежит, выполнит фьючу,
[35:18.740 --> 35:31.220]  у фьюча вызовется callback, а в этом callback к рутине продолжится. Ну, вообще-то, это должно
[35:32.020 --> 35:38.540]  подплакнуть к такому выводу, что вот этот код, возможно, не очень хорош. Ну, точнее, мы к рутину
[35:38.540 --> 35:52.580]  все еще не дописали. Но у меня код собран с адрес санитайзера, мы получили stack user
[35:52.580 --> 35:58.500]  scope. Почему? Потому что вот мы сделали здесь первый шаг, подписались на фьючу, вышли из этого вызова,
[35:58.500 --> 36:05.740]  а потом, ну, случилось понятно что. К рутине разрушилась, а потом в thread pool выполнилась
[36:05.740 --> 36:10.260]  задача, она нас зарезюмила, а зарезюмить, ну, записала в поле, а писать в поле уже нельзя,
[36:10.260 --> 36:19.900]  потому что никакого поля нет, потому что объекта уже давно нет. Поэтому мы пишем здесь что. Да,
[36:19.900 --> 36:30.060]  нам нужно прибрать за собой, вот мы где-то, да, и вот, видимо, этот код мы забываем и говорим следующее.
[36:30.060 --> 36:55.020]  Вот это уже более разумно, и сейчас код должен работать, и память не должна не карабтиться,
[36:55.020 --> 37:05.980]  не утекать. Ну вот, мы говорим про крутины, не просто про крутины, которые запускаются и
[37:05.980 --> 37:10.580]  ничего полезного не делают, мы говорим про крутины, которые работают с синхронностью,
[37:10.580 --> 37:17.580]  которые останавливаются, потому что они чего-то ждут. И в этом случае время жизни таких крутин
[37:17.580 --> 37:22.060]  становится динамическим. Мы не знаем сколько оно проживет, потому что мы не знаем когда закончатся
[37:22.060 --> 37:27.420]  операции это синхронные там в поле потоков или когда пройдет время или что угодно. Поэтому,
[37:27.420 --> 37:33.300]  естественно, что стейт крутины начинает алоцироваться в динамической памяти.
[37:33.300 --> 37:44.900]  Что еще мы можем заметить любопытного здесь? Что... ну вот, зачем я вам это показываю? Потому что,
[37:44.900 --> 37:54.140]  потому что, потому что вот здесь происходит нечто такое же, ну должно происходить,
[37:54.140 --> 37:59.500]  потому что а что иначе здесь может еще быть написано? Вот мы пытаемся разобраться,
[37:59.500 --> 38:05.820]  как устроена такая строчка. Вот кажется, что она должна быть устроена вот каким-то таким... ну то
[38:05.820 --> 38:18.900]  есть эта функция должна развернуться в какой-то подобный код. Что еще тут интересного? Вот писали
[38:18.900 --> 38:28.740]  ли вы файберные фьючи, файберные мютоксы? Вот, и вы там даже в слепфоре еще и в мютоксе уж точно
[38:28.740 --> 38:35.500]  сталкивались с проблемой, что если вы запланируете возобновление файбера до остановки крутины,
[38:35.500 --> 38:40.580]  то может получиться неприятность. Вы активируете контекст в другом потоке, который еще не сохранен,
[38:40.580 --> 38:45.820]  и поэтому вам нужно было сначала аккуратно остановить крутину и только потом подписаться,
[38:45.820 --> 38:53.700]  ну запланировать ее возобновление. Смотрите, у нас здесь крутина устроена проще. Suspend
[38:53.700 --> 39:05.700]  stackless крутины, это просто return. Так? Вот, и нормально, если в другом потоке крутина зарезюмится,
[39:05.700 --> 39:12.580]  когда в первом потоке она еще не остановилась. Потому что что такое suspend? Просто return. Что
[39:12.580 --> 39:17.340]  такое resume? Просто call. Вы можете в другом потоке вызвать функцию, которая еще не завершилась в
[39:17.340 --> 39:26.540]  другом потоке. Ну вот, да, нужно сначала аккуратно обновить лейбл, сохранить все нужные поля,
[39:26.540 --> 39:33.460]  а потом уже не нужно волноваться, что resume может произойти до suspenda, потому что suspend
[39:33.460 --> 39:41.740]  return, resume это call, слишком простые инструкции, там нечему ломаться уже. Чувствуете разницу,
[39:41.740 --> 39:45.700]  да? Вот потому что, ну вот, здесь никакого переключения контекста нет, здесь просто то,
[39:45.700 --> 39:48.780]  что у нас было переключением контекста, сохранением контекста, активации контекста,
[39:48.780 --> 39:56.100]  теперь стало просто call и return. Но правда, как это достигается? Это достигается вот генерации
[39:56.100 --> 40:02.740]  такого кода, пока вручную голыми руками. Но мы бы хотели, чтобы в конечном итоге этот код сгенерировал
[40:02.740 --> 40:09.500]  для нас комперятор. Но абсолютно же невозможно, чтобы он по такой функции сгенерировал вот такой
[40:09.500 --> 40:23.820]  вот код. Правда? Смотрите, он вообще-то может сгенерировать много кода здесь. То есть понятно,
[40:23.820 --> 40:27.860]  что он, увидев кое вейт, поймет, что это не просто функция, это корутина, что нужно переписать ее
[40:27.860 --> 40:32.340]  на автомат, что нужно для локальной переменной завести поле, что нужно для аргумента завести
[40:32.340 --> 40:36.740]  поле, что нужно завести лейбл, что нужно написать resume, что нужно алоцировать, может быть,
[40:36.740 --> 40:46.980]  стоит на куче, что нужно вызвать асинквиа, что он не сможет сам написать. Но он не понимает,
[40:46.980 --> 40:53.420]  это же комперятор, в конце концов, откуда он знает про то, как нужно дожидаться future, откуда же он
[40:53.420 --> 40:59.660]  знает, когда именно нужно резюмить корутину. Вот никакого subscriba вот в этом коде не написано.
[40:59.660 --> 41:08.300]  Поэтому мы хотим, чтобы в конце концов в Core State Machine в этом классе был написан такой код,
[41:08.300 --> 41:14.660]  который компилятор сам в состоянии написать. Ну, с некоторыми подсказками, но минимальными. Вот,
[41:14.660 --> 41:24.340]  и это наш следующий шаг. Давайте этот код попытаемся немного иначе структурировать,
[41:24.340 --> 41:34.380]  так чтобы вот в самом, в самом классе Core State Machine не было ничего специфичного именно для наших future.
[41:34.380 --> 41:47.340]  Так, это тот же самый пример,
[41:47.340 --> 42:02.540]  это тот же самый код, ну, почти. Беда в том, что здесь написан subscrib, про который компилятор
[42:02.540 --> 42:07.860]  ничего понимать не может. Давайте подумаем, как можно избавить компилятор от знания про
[42:07.860 --> 42:15.660]  это subscrib. Ну, что вообще происходит? Смотрите, у нас есть в корутине строчка, там некоторое
[42:15.660 --> 42:23.300]  значение равно co-await некоторые вызов, некоторые expression. Вот у expression один тип, future от int,
[42:23.300 --> 42:32.540]  у вот этого значения другой тип, просто int. И мы написали между ними co-await, то есть мы хотим
[42:32.540 --> 42:40.620]  остановиться и каким-то образом возглавить корутину позже, а потом и распаковать значение. Вот эту
[42:40.620 --> 42:49.900]  логику должен, эту логику, как именно это сделать, может предоставить только сам пользователь. Компилятор
[42:49.900 --> 42:56.100]  про нее ничего не знает. Поэтому мы хотим, чтобы эта логика, она была как-то инкапсулирована в
[42:56.100 --> 43:01.060]  некоторую стратегию, которую компилятор мог бы использовать. Эта стратегия называется avator.
[43:01.060 --> 43:09.020]  Avator — это сущность, стратегия, которая говорит, как же именно нужно дожидаться некоторого значения,
[43:09.020 --> 43:25.380]  как именно, имея future, дождаться из нее int. Вот давайте мы сейчас напишем класс future avator,
[43:25.380 --> 43:33.540]  который инициализируется, который получает future
[43:43.540 --> 43:52.420]  и помогает компилятору, ну или нам, написать тело нашей корутины.
[43:55.380 --> 44:09.940]  Итак, у нас есть future. Вот мы хотим это значение v заменить на future avator.
[44:09.940 --> 44:22.180]  Причем он будет ленивый инициализироваться, когда появляется future.
[44:22.180 --> 44:40.060]  Вот, компилятор вызвал код, получил future, а теперь он должен как-то трансформировать ее в int,
[44:40.060 --> 44:44.900]  ну дождавшись, когда там этот int появится. Компилятор не знает, как это делать, поэтому он
[44:44.900 --> 44:55.060]  говорит, вот avator, разбирайся с этим, вот тебе future значение, а теперь, пожалуйста, avator запланируй
[44:55.060 --> 45:14.260]  меня, когда можно будет. Кого это меня? Ну, корутину некоторую.
[45:14.260 --> 45:41.140]  Вот так вот, да, но не сработало, потому что не заплатили.
[45:45.140 --> 45:53.180]  Ну, avator нас возобновит здесь с помощью avatesuspend, ну, точнее, запланирует возобновление,
[45:53.180 --> 46:02.020]  и нам после возобновления нужно откуда-то взять v. Откуда мы его возьмем? Ну, опять спросим у
[46:02.020 --> 46:09.100]  avator, раз уж ты нас разбудил, то, пожалуйста, скажи нам, какое значение нужно взять.
[46:09.100 --> 46:21.940]  То есть, вот avator получал future t, а отдает нам теперь t. Каким образом? Ну, пусть он его в поле
[46:21.940 --> 46:31.540]  сохранит. Да, тут опять этот результат конструируется лениво.
[46:31.540 --> 47:00.820]  А, да, простите. И здесь мы распаковываем раз,
[47:00.820 --> 47:05.620]  распаковываем два. Первая звездочка это, чтобы из optional распаковать, вторая, чтобы изрезал
[47:05.620 --> 47:13.820]  это значение. Распаковать. Я здесь снова благополучно игнорирую ошибки. Что?
[47:13.820 --> 47:28.860]  Возможно, да. Нет. Зачем?
[47:28.860 --> 47:45.980]  Ну вот. Вот мы избавили класс корутина от конкретных деталей, как именно нужно дожидаться
[47:45.980 --> 47:55.580]  возобновления и откуда именно брать значение. Мы строим avator, передаем ему то, что было справа
[47:55.580 --> 48:03.940]  от коэвейта. Вызываем await suspend, и этот await suspend должен запланировать возобновление корутина,
[48:03.940 --> 48:09.940]  когда вот она будет готова, когда реализуется future в данном случае. И когда корутина запустится,
[48:09.940 --> 48:17.860]  мы можем с помощью await resume из avator достать то значение, которое мы хотели. Сейчас оно уже
[48:17.860 --> 48:34.820]  готово. Давайте проверим, что мы ничего не разломали здесь. Раз, два, три. Работает.
[48:38.820 --> 48:47.100]  Ну что скажете? Ну, во-первых, только что состоялся разбор задачи fiber mutex,
[48:47.100 --> 48:52.940]  потому что там нужно писать avatars, и вот avatars должны делать как раз... Ну, avatars должны быть вот
[48:52.940 --> 49:00.820]  как-то так устроены. И у нас тоже был fiber handle, у нас тоже были avatars, там тоже должен быть await
[49:00.820 --> 49:08.420]  suspend, который планирует возобновление. Вот это абсолютно общий механизм, который интегрируется
[49:08.420 --> 49:13.940]  с корутинами stackless или корутинами stackful. Вот совершенно неважно, как именно корутина
[49:13.940 --> 49:20.220]  устроена. Так что вот ожидайте, но рассчитывайте, что у вас должен быть вот этот await suspend.
[49:20.220 --> 49:26.260]  Ну, await resume там пока не нужен, потому что в нашем... в mutex ничего не возвращают после пробуждения,
[49:26.260 --> 49:35.060]  да. Но в общем случае await resume, наверное, нужен. Почему названия такие await suspend и await resume?
[49:35.060 --> 49:40.780]  Ну, потому что этот код вызывается в точке, когда корутина останавливается, а этот код вызывается,
[49:40.780 --> 49:44.940]  когда корутина возобновляется. А await, потому что включилось слово await.
[49:44.940 --> 50:00.940]  Ну вот, мы написали теперь то, что на самом деле сгенерирует компилятор, вот для... сложно. Вот
[50:00.940 --> 50:15.940]  для такой функции. Хороший вопрос. Откуда компилятор вообще поймет, что нужно взять... вот нужно
[50:15.940 --> 50:23.500]  использовать awaiter, вот такой конкретный. Откуда возьмет этот тип? Ну, мы сейчас... то есть нужно
[50:23.500 --> 50:34.660]  некоторое правило, которое позволяет компилятору по future получить future awaiter. Ну, давайте посмотрим.
[50:34.660 --> 50:44.020]  Хоба. Ну, мы сейчас перемещаемся уже, мы прекращаем там на время писать корутину собственными руками и
[50:44.020 --> 50:51.940]  переходим к тому, как работает корутина C++, stackless корутина C++. Вот если... если вы в своем коде
[50:51.940 --> 51:00.140]  stackless корутины пишете coawait и некоторый объект, то вы должны для этого... ну, для этого типа,
[51:00.140 --> 51:09.460]  в данном случае это future, реализовать оператор coawait, который возвращает awaiter. И этот awaiter,
[51:09.460 --> 51:14.900]  смотрите, что... как он устроен, вот он устроен вот ровно так же. Этот код уже не игрушечный, ну не
[51:14.900 --> 51:21.100]  в смысле игрушечный, и тот был не особенно игрушечный, но это уже код, который интегрирован с корутинами
[51:21.100 --> 51:31.420]  C++. Когда в коде написан coawait вот такой вот, то компилятор его разворачивает. Давайте я покажу
[51:31.420 --> 51:43.660]  сейчас во что. Это блок Льюиса Бейкера, еще одного из авторов корутин C++, у него есть такое очень
[51:43.660 --> 51:50.100]  подробная серия постов про то, как корутины устроены. И вот второй пост про оператор coawait. Что же
[51:50.100 --> 52:03.540]  компилятор вставляет вместо coawait? Ну, тут не слишком понятно. Слишком непонятно, возможно. Есть
[52:03.540 --> 52:10.540]  coawait expression. Вот, по этому expression, вот по value, в котором вычисляется этот expression,
[52:10.540 --> 52:19.060]  нужно каким-то образом получить awaiter. Ну, в частности, с помощью оператора coawait. Вот,
[52:19.060 --> 52:26.180]  компилятор знал value, знал его тип, получил awaiter по этому типу. И что он сделал? Сначала
[52:26.180 --> 52:35.140]  он спросил await ready. Await ready возвращает true, если корутина, корутине вообще не нужно ничего ждать,
[52:35.140 --> 52:42.460]  если она готова запуститься сразу. Может быть, мы ждали future, она сразу готова. Ну, мы в нашем коде
[52:42.460 --> 52:51.940]  говорим, что нет, будем ждать. Ну, тут тоже можно некоторую оптимизацию сделать, но мы ленивые. Так вот,
[52:51.940 --> 53:02.020]  если все-таки future не готова, то есть awaiter говорит, что нет, нужно ждать, то дальше мы вызываем
[53:02.020 --> 53:14.660]  await suspend до awaiter и передаем туда объект, который называется coroutine handle. Coroutine handle
[53:14.660 --> 53:25.220]  зависит от того, где вы живете. Если вы живете в более-менее современном мире с современной
[53:25.220 --> 53:31.540]  стандартной библиотекой компилятором, то там это уже не experimental, а у меня на маке это experimental.
[53:31.540 --> 53:37.620]  Coroutine handle у него, ну, я бы сказал, что один метод, по сути, важный, но для нас сейчас это
[53:37.620 --> 53:43.620]  resume. Ладно, я вру не один, конечно, и другие тоже важны, на самом деле, но вот прямо сейчас
[53:43.620 --> 53:50.340]  resume. Возвновить корутину. Вот fiber handle вы уже видели в домашке, и fiber handle в домашке
[53:50.340 --> 53:57.060]  ровно по мотивам вот этого дизайна. Смысл точно такой же. Мы в await suspend, в awaiter получаем
[53:57.060 --> 54:06.540]  coroutine handle, и когда событие реализуется, во future появится значение, мы на этом handle скажем
[54:06.540 --> 54:16.020]  resume, и корутина вот здесь прямо возобновится и продолжит бежать. Она стартует, и давайте вернемся
[54:16.020 --> 54:32.300]  в псевдокод. Она стартует, и из await resume возьмет значение. Вот, это уже абсолютно честный код,
[54:32.300 --> 54:56.900]  и вот этот пример, ну, давайте его запустим. Он так работает. Ну вот, спустя некоторое время
[54:56.900 --> 55:09.460]  напечаталось 42. Вот, и это уже настоящий компилятор C++, вот вместе, переписал эту функцию вот так вот,
[55:09.460 --> 55:16.700]  и вот awaiter у нас точно такой же получился. Вот awaiter наш ручной, для нашей ручной корутины,
[55:16.700 --> 55:26.820]  и вот awaiter, который мы написали, чтобы корутина C++ работала. Вот, разницы никакой
[55:26.820 --> 55:34.580]  нет, только тут coroutine handle, который прячет от нас конкретный класс корутины. Так же,
[55:34.580 --> 55:39.580]  как и в нашей домашке, fiber handle прячет от нас, от пользователя конкретный класс файбера.
[55:39.580 --> 55:52.660]  Ну вот, мне кажется, что вот с помощью этого примера мы разобрались, как именно работает
[55:52.660 --> 55:58.780]  компилятор, когда он компилирует корутины. Вот, можно было бы по документации это изучать,
[55:58.780 --> 56:06.340]  по этой документации, или еще хуже, по вот этой документации, но я не уверен, что это закончится
[56:06.340 --> 56:11.380]  хорошо. Вот, а с другой стороны, если написать все голыми руками, ну, такой игрушечный пример,
[56:11.380 --> 56:17.020]  но голыми руками зато, то вот вся скрытая механика становится явной. Вот этого кода,
[56:17.020 --> 56:22.060]  вот этого кода нигде не увидеть, потому что этот код пишет компилятор во время компиляции. У вас
[56:22.060 --> 56:29.220]  есть в языке вот такой синтаксис на поверхности языка, а дальше компилятор его переписывает вот в
[56:29.220 --> 56:35.380]  такой вот класс. Вот, мы это, к сожалению, наблюдать не способны, это не часть библиотеки,
[56:35.380 --> 56:39.500]  это часть компилятора, но мы способны это воспроизвести вот в таком примере.
[56:39.500 --> 56:50.500]  Он выделяет память на старте корутины, когда мы ее вызываем. Ну вот мы... Смотри,
[56:50.580 --> 56:55.740]  я пока немного жульничаю, я рассказываю, что происходит, когда корутина зовет коэвейт,
[56:55.740 --> 57:00.420]  а есть отдельная история, что происходит, когда корутина стартует, и что происходит,
[57:00.420 --> 57:06.580]  когда она завершается. Вот, и это еще одно из мерений сложности, про это вторая половина занятия.
[57:06.580 --> 57:14.060]  А пока мы говорим просто про сам коэвейт. И вот коэвейт, мы, кажется, разобрали, и я обращаю
[57:14.060 --> 57:20.220]  внимание, что вот эта вся трансформация, которую делает компилятор, она вот чисто механическая,
[57:20.220 --> 57:27.580]  собственно, поэтому мы компилятору и доверяем ее. Он может сделать это бездумно. Во-вторых,
[57:27.580 --> 57:38.300]  компилятор, когда он компилирует вот этот код, вот в такой код, ну переписывает вернее, то он же
[57:38.300 --> 57:46.700]  совершенно не понимает, чем корутина занимается. Он не знает ничего про фьючее, про мютоксе, вот
[57:46.700 --> 58:07.420]  в этом примере. Корутины C++ — это, внимание, фича языка. Она полностью декомпозирована
[58:07.420 --> 58:14.700]  от какого-то не было конкретного применения. В смысле, от там фьюч, мютоксов, там event loop'ов
[58:14.700 --> 58:21.980]  каких-то. Ну вот это просто некоторая механическая трансформация кода. Компилятор видит коэвейт и
[58:21.980 --> 58:29.500]  переписывает функцию в класс. А чего именно эта корутина дожидается, каких там событий, как она
[58:29.500 --> 58:36.820]  там конкурирует с другими корутинами в каком-то тредпуле — этого всего нет в языке C++. Этого
[58:36.820 --> 58:41.700]  даже нет в стандартной библиотеке до сих пор, никакого готового фреймворка. И вот корутины C++ — они
[58:41.700 --> 58:47.740]  интегрируются абсолютно с любым фреймворком. В частности, с нашим, который мы пишем. Почему бы
[58:47.740 --> 58:53.660]  их не интегрировать туда? Там же есть тредпул, в котором корутины выполняются. Ну не корутины,
[58:53.660 --> 58:59.380]  а задачи выполняются. Вот наш тредпул будет признан хорошим, если в нем можно выполнять и корутины.
[58:59.380 --> 59:09.740]  Разумно звучит? Ну вот, давайте посмотрим. Давайте посмотрим на еще один пример.
[59:09.740 --> 59:22.100]  А давайте сначала ASIO посмотрим. Вот ASIO. Какой-то runtime, event loop у нас есть. Вот есть его контекст.
[59:22.100 --> 59:28.820]  Вот я запускаю корутину. Вот эта корутина строит таймер,
[59:28.820 --> 59:35.300]  заводит его на две секунды и говорит co-await таймер. Что бы в этом месте хотели? Видимо,
[59:35.300 --> 59:41.780]  чтобы корутина остановилась на две секунды. Ну для этого нужно написать оператор co-await для таймера.
[59:41.780 --> 59:58.580]  Давайте его напишем. Вот, пожалуйста, контролируйте, что вы понимаете, что я пишу и что вообще
[59:58.580 --> 01:00:08.220]  происходит. Если не понимаете, то нужно срочно спрашивать. А? Ссылка, да. Вот. Awaiter — это класс,
[01:00:08.220 --> 01:00:15.380]  который реализует контракт Awaiter. Три метода. Await Ready, Await Suspend, Await Resume. Await Ready.
[01:00:15.380 --> 01:00:22.980]  Что нужно вернуть? Ну, я не знаю, есть ли у таймера что-нибудь готовое?
[01:00:22.980 --> 01:00:46.100]  Ну нет, не видно, да, ничего? Ну мы его здесь завели. Ну ладно, false так false. В домашке у вас
[01:00:46.100 --> 01:00:54.340]  все равно будет повод написать не true здесь и не false. Что-то более нетривиальное. Нужно останавливаться.
[01:00:54.340 --> 01:01:07.460]  Пишем Await Suspend. Получаем здесь CarRoutingHandle на корутину. Когда мы ее возобновим? Когда
[01:01:07.460 --> 01:01:13.540]  пройдет таймер? Когда он закончится? Ну можно подписаться на него. Handle — это очень легкий
[01:01:13.540 --> 01:01:20.100]  объект. Он внутри держит pointer на некоторую реализацию конкретную, но этот тип мы не знаем,
[01:01:20.100 --> 01:01:25.940]  так же как мы не знаем в C++ тип лямбды, тип функтора, который генерируется для лямбды. Но нам это и не важно,
[01:01:25.940 --> 01:01:33.540]  у нас есть Handle и мы здесь говорим, да, мы игнорируем ошибку снова.
[01:01:33.540 --> 01:01:49.060]  Видимо так. Await Resume, он, кажется, ничего не возвращает, потому что Quay Await ничего не возвращает.
[01:01:49.060 --> 01:01:58.100]  Ну, давайте посмотрим.
[01:02:04.780 --> 01:02:12.260]  Начинается. Ну ладно, давайте... Сейчас не получилось, я в перерыве попробую это починить,
[01:02:12.260 --> 01:02:25.140]  все же сложно с ASIO. Не используйте header-only библиотеки. Ну, это мое личное мнение. Ну потому
[01:02:25.140 --> 01:02:37.260]  что ошибки не отложиваются. Ладно, давайте по-другому. Давайте по-другому. Давайте вернемся
[01:02:37.260 --> 01:02:48.620]  к трэдпулу. И вот мы решили связать карутины C++ с нашим трэдпулом, который мы делали. И сейчас
[01:02:48.620 --> 01:02:56.180]  у нас есть такая задача. Вот карутина здесь запускается. Запускается карутина, ну вот она
[01:02:56.180 --> 01:03:01.580]  запускается в том же самом смысле, как она запускалась вот здесь. То есть выполняется первый шаг.
[01:03:01.580 --> 01:03:13.180]  Выполняется первый шаг всегда в том же потоке, который карутину первый раз вызвал, карутину
[01:03:13.180 --> 01:03:22.340]  сконструировал. Так что вот эта карутина, она запускается в трэде, который выполняет функцию main.
[01:03:22.340 --> 01:03:33.220]  А дальше мы хотим, чтобы эта карутина переехала в трэдпул. Каким образом это можно сделать? Ну вот
[01:03:33.220 --> 01:03:39.100]  вызывать какой-то метод там submit или execute, как он там у нас называется, неважно, мы все же не
[01:03:39.100 --> 01:03:48.140]  хотим. Потому что ну submit и execute работают с какими-то задачами абстрактными, а у нас все же карутина. Вот
[01:03:48.140 --> 01:03:54.700]  идеоматичный способ сказать ко эвэйт телепорту и оказаться в пуле. А телепорту должен вернуть
[01:03:54.700 --> 01:03:58.780]  эвэйтер, который и должен запланировать карутину как задачу в трэдпул.
[01:04:18.780 --> 01:04:25.820]  А в эвэйтерэйде здесь точно false, карутина должна остановиться, потому что она должна оказаться в трэдпуле.
[01:04:25.820 --> 01:04:40.420]  И вот здесь, что мы напишем?
[01:04:40.420 --> 01:04:47.340]  Ну у нас нет никакого submit, у нас executor давно в курсе.
[01:04:47.340 --> 01:04:55.220]  Вот. Мы хотим запланировать, ну пока мы напишем очень неэффективно, а я объясню, что мы хотим сделать,
[01:04:55.220 --> 01:05:05.420]  что мы хотим сделать следующим шагом. У нас есть handle, и мы его захватим в лямбду и лямбду бросим в пул.
[01:05:05.420 --> 01:05:13.660]  И уже в этой лямбде мы скажем handle resume.
[01:05:13.660 --> 01:05:26.540]  Вот. А в эвэйтер резьем мы снова ничего не делаем, потому что ко эвэйт не должен ничего возвращать.
[01:05:43.660 --> 01:05:54.540]  Вот. То есть карутина стартовала в мейне, потом переехала в пул, в поток пула.
[01:05:54.540 --> 01:06:03.340]  Видите ли вы в этом коде некоторую неоптимальность?
[01:06:03.340 --> 01:06:11.660]  Вот, кстати, можно я еще замечание сделаю? Я показывал вам код с грутинами, горрутинами,
[01:06:11.660 --> 01:06:19.180]  которые... Вот они становились грутинами, когда они переехали как раз в планировщик. Вот с этого они и
[01:06:19.180 --> 01:06:25.300]  начинались. Они сначала перепланируются в планировщик, планировщик — это пул потоков, а дальше уже там
[01:06:25.300 --> 01:06:29.300]  сражаются за общий мюдекс.
[01:06:32.820 --> 01:06:47.220]  Окей. Где я? Нужно вернуться сюда. Давайте подумаем, есть ли здесь некоторая неоптимальность.
[01:06:47.940 --> 01:07:00.980]  Что? Мы просто подождем 5 секунд. А что должно измениться? Не очень понимаю.
[01:07:07.060 --> 01:07:13.620]  Ну все хорошо вроде. Вот мы здесь были в мейне, этот код исполняется в мейне, этот код исполняется уже в пуле поток.
[01:07:13.620 --> 01:07:15.540]  Вот здесь мы в пуле поток.
[01:07:15.540 --> 01:07:26.140]  Видите ли вы неоптимальность в этом коде? Ну зависит, конечно, от того, насколько вы
[01:07:26.140 --> 01:07:36.260]  продвинулись в реализации интуизивных задач в пуле потоков. Смотрите. Вернемся
[01:07:36.260 --> 01:07:47.020]  в экзекьюторы. Вернемся в задачи. И говорим, что задачи — это наследники класса, наследники
[01:07:47.020 --> 01:07:53.060]  интерфейса itask, которые умеют запускаться. Наследники, которые умеют запускаться. Ну и еще
[01:07:53.060 --> 01:07:58.180]  они в себя интегрируют указатель для того, чтобы связываться с другими задачами в какие-то
[01:07:58.180 --> 01:08:06.940]  структуры внутри самого планировщика. Почему интрузивность разумна? Ну, во-первых, файберы,
[01:08:06.940 --> 01:08:14.900]  они лоцируются на куче, и файберы запускаются. Вот почему бы файберу не унаследоваться от задачи,
[01:08:14.900 --> 01:08:22.700]  не реализовать в себе метатран, и там не резюмить корутины? И при планировании бросать просто
[01:08:22.700 --> 01:08:31.700]  поинтер на себя в тредпул самому быть задачей. Тогда не нужна будет аллокация при сабмите,
[01:08:31.700 --> 01:08:36.260]  при экзекюте, и не нужна будет аллокация внутри тредпула, потому что мы там будем какие-то
[01:08:36.260 --> 01:08:44.620]  односвязанные списки мастерить и всего этого. А дальше вспомним про корутины. Вот в частности
[01:08:44.620 --> 01:08:55.940]  вспомним вот этот пример. Чему он нас научил? Что корутина, стейт корутины тоже должен
[01:08:55.940 --> 01:09:04.380]  лоцироваться на куче, потому что лайфтайм корутины какой-то вот непредсказуемый динамический. И вот
[01:09:04.380 --> 01:09:11.340]  корутина лоцируется на куче один раз, а потом много раз возобновляется. На каждом коэвейте
[01:09:11.340 --> 01:09:18.500]  она перепланируется. Ну, видимо, та же самая история должна быть. Видимо, мы должны иметь
[01:09:18.500 --> 01:09:25.340]  возможность планировать ее в тредпул без лишних аллокаций, потому что в корутине уже есть аллокация.
[01:09:25.340 --> 01:09:36.300]  Давайте посмотрим на код, на библиотеку Сипипикора. Она на самом деле уже мертва,
[01:09:36.300 --> 01:09:43.980]  но она не... не настолько. Она не поддерживается. Просто она писалась с Льюисом Бейкером, одним
[01:09:43.980 --> 01:09:50.740]  из авторов корутин, в качестве вот такого... доказательства того, что корутины работают,
[01:09:50.740 --> 01:09:57.540]  что их можно принести в C++. То есть это был ронтайм для корутин. Вот в языке делают фичу,
[01:09:57.540 --> 01:10:04.460]  и для этих... для этой фичи пишут ронтайм для конкурентных корутин. И вот можно проверить,
[01:10:04.460 --> 01:10:09.860]  что все в совокупности работает, что задача решается. И в этой библиотеке был тредпул.
[01:10:09.860 --> 01:10:15.380]  Этот тредпул был, смотрите, ну что с ним можно было делать? В него можно было планировать корутины.
[01:10:15.500 --> 01:10:27.820]  Причем это был тредпул, специальный тредпул для корутин. То есть когда мы вызывали Shadow,
[01:10:27.820 --> 01:10:38.100]  к корутине возвращалась... возвращался авейтор ShadowOperation, и дальше уже корутина звала на нем
[01:10:38.100 --> 01:10:46.700]  CoAwait. Смотрите, как устроен этот ShadowOperation. В нем есть поле CarRoutingHandle корутина,
[01:10:46.700 --> 01:10:55.380]  есть поле Next на другой ShadowOperation. И что происходит, когда мы зовем CoAwait? Ну,
[01:10:55.380 --> 01:11:00.500]  вызывается оператор await... вызывается метод awaitSuspend на авейторе, на ShadowOperation.
[01:11:00.500 --> 01:11:12.140]  Давайте найдем ShadowOperation, awaitSuspend. Понятно ли, что мы сейчас делаем? Мы сейчас просто
[01:11:12.140 --> 01:11:18.740]  смотрим, как работает тредпул, специально заточенный под исполнение в нем корутина. Вот,
[01:11:18.740 --> 01:11:28.260]  он в методе Shadow возвращает нам ShadowOperation, на котором корутина назовет CoAwait, ShadowOperation,
[01:11:28.260 --> 01:11:35.580]  на котором назовет awaitSuspend. И этот awaitSuspend, во-первых, запоминает в поле ShadowOperation
[01:11:35.580 --> 01:11:52.700]  Handle корутины вот здесь вот. А во-вторых, делает что? Shadow Impulse this. А здесь уже,
[01:11:52.700 --> 01:12:00.620]  вы, кажется, можете углядеть некоторый знакомый вам код, потому что здесь, смотрите, если текущий
[01:12:00.620 --> 01:12:07.260]  поток — это поток тредпула, то мы кладем ShadowOperation в локальную очередь, иначе мы кладем в
[01:12:07.260 --> 01:12:15.820]  remoting, в глобальную очередь. То есть, у нас тут появляется планировщик с локальными глобальными
[01:12:15.820 --> 01:12:24.740]  очередями, и мы планируем ShadowOperation, мы просто ShadowOperation как узел списка добавляем вот в
[01:12:24.740 --> 01:12:30.300]  глобальную очередь планировщика. Тут какой-то лог-фри простое написано, какой-то лог-фристек или
[01:12:30.300 --> 01:12:44.300]  что-то в этом духе. Понимаете, что произошло или нет? Давайте, вот я еще раз проговорю, а потом
[01:12:44.300 --> 01:12:51.300]  картинку покажу, и, может быть, станет понятнее. Вот у вас был тредпул, у вас была корутина.
[01:12:51.300 --> 01:13:02.540]  Тредпул в методе Shadow вернул корутине объект ShadowOperation. Это Awaiter. Это вот теперь локальная
[01:13:02.540 --> 01:13:08.380]  переменная в корутине. Ну, потому что CoAwaitExpression это разворачивается. Появляется локальная
[01:13:08.380 --> 01:13:19.140]  переменная Awaiter, и на этом Awaiter-е зовется AwaitSuspend. Этот AwaitSuspend записывает в этот Awaiter,
[01:13:19.140 --> 01:13:27.740]  в этот ShadowOperation pointer на корутину, на саму себя, и этот ShadowOperation бросает как такой
[01:13:27.740 --> 01:13:35.100]  интрузивный узел в планировщик, а планировщик там дальше его провязывает с какими-то другими узлами,
[01:13:35.100 --> 01:13:45.860]  с другими задачами, которые нужно выполнить. Почему ShadowOperation все еще жив? Вот мы здесь с ним
[01:13:45.860 --> 01:13:56.300]  работаем, а он же на стейке живет. ShadowOperation — это Awaiter. Awaiter — это локальная переменная в
[01:13:56.300 --> 01:14:04.580]  корутине, а локальная переменная в корутине превращается в поле класса, CoroutineState. Так что,
[01:14:04.580 --> 01:14:10.460]  а CoroutineState алоцируется на куче. Итого, у нас есть корутина, она алоцировалась на куче в виде
[01:14:10.460 --> 01:14:19.260]  CoroutineState, и у нее есть поле ShadowOperation теперь, и в нем написан pointer на другие ShadowOperation.
[01:14:19.260 --> 01:14:37.700]  Давайте, вот пришло время для картинки, а браузер не хочет сворачиваться. Ну вот, на самом деле,
[01:14:37.700 --> 01:14:44.940]  все работает так. Вот у вас есть три корутины, они разные толщины, потому что, ну, в конце концов,
[01:14:44.940 --> 01:14:48.540]  корутины могут быть разные, там может быть разное количество полей, разное количество
[01:14:48.540 --> 01:14:55.260]  аргументов, локальных переменных. Это вот три разные корутины, и все они решили запланироваться
[01:14:55.260 --> 01:15:04.980]  в пул потоков. Каждая из них получила Awaiter, ShadowOperation, запомнила там себя,
[01:15:04.980 --> 01:15:19.940]  и через поле Next связалась с другими корутинами. А в ThreadPool, в глобальной его очереди, есть,
[01:15:19.940 --> 01:15:24.940]  в конце концов, какая-нибудь переменная Head или Tail, ну, неважно, и вот она держит ссылку
[01:15:24.940 --> 01:15:30.620]  на ShadowOperation. И вот так вот мы построили, по сути, интрузивный список из корутин.
[01:15:30.620 --> 01:15:40.780]  Вот тут много скрытой механики, тут это должно быть понятно, да, потому что вот, ну, в ThreadPool
[01:15:40.780 --> 01:15:45.660]  нет никаких корутин, ShadowOperation нет никаких корутин-стейтов, это все тоже скрыто компилятором
[01:15:45.660 --> 01:15:53.420]  от нас. Но вот если все это в голове развернуть, то появляется такая конструкция, появляется
[01:15:53.420 --> 01:16:01.540]  такой неявный интрузивный список. Вот, но мы должны сделать домашки еще лучше, потому что, ну,
[01:16:01.540 --> 01:16:08.740]  почему мы должны сделать лучше? Потому что здесь ThreadPool вот прямо конкретно с корутинами работает,
[01:16:08.740 --> 01:16:18.020]  он возвращает нам ShadowOperation, Awaiter. А мы хотим написать все еще вот такие максимально абстрактные
[01:16:18.020 --> 01:16:26.060]  экзекутеры с максимально абстрактными задачами и сделать так, чтобы корутины без всякого
[01:16:26.060 --> 01:16:36.780]  оверхеда в них тоже можно было бы планировать. И вот это будет служить доказательством того,
[01:16:36.780 --> 01:16:42.620]  что наш дизайн, вот наши экзекутеры, наши интрузивные задачи, это хороший дизайн,
[01:16:42.620 --> 01:16:48.660]  потому что вот они подходят для файберов с одной стороны, а с другой стороны они одинаково,
[01:16:48.660 --> 01:16:54.180]  оптимально подходят для стеклоскорутина C++. Совершенно другого механизма реализованного,
[01:16:54.180 --> 01:16:58.740]  там не в библиотеке, не нами, а вообще в компиляторе, но при этом в силу того,
[01:16:58.740 --> 01:17:05.340]  что мы подобрали правильные абстракции, правильные интерфейсы, мы получим интеграцию, причем
[01:17:05.340 --> 01:17:12.300]  интеграцию оптимальную, без каких-то дополнительных накладных расходов на ненужные аллокации. Вот,
[01:17:12.300 --> 01:17:19.780]  в очередной задаче вы сможете это попробовать сделать. Ну, то есть вы должны в задачи экзекутера
[01:17:19.780 --> 01:17:26.900]  все-таки докрутить интрузивность, а потом взять тредпул оттуда и вот встроить, интегрировать его
[01:17:26.900 --> 01:17:33.180]  с корутиными. Ну, а в конце концов у нас получится, вы, наверное, чувствуете, что происходит,
[01:17:33.180 --> 01:17:40.900]  что все задачи собираются вместе, потому что вот все аккуратно, аккуратно продумано,
[01:17:40.900 --> 01:17:56.580]  все совсем сочетается. Вопрос. Ну, потому что нечего исключения бросать. Мы говорим,
[01:17:56.580 --> 01:18:00.500]  что задача сама должна разобраться, если там прошли исключения, она пусть сама думает,
[01:18:00.500 --> 01:18:05.660]  как с ним работать, потому что, ну вот, необработанные исключения в файбере — это
[01:18:05.660 --> 01:18:12.780]  проблема файбера, необработанные исключения там в крути. Ну, короче, это проблема того кода,
[01:18:12.780 --> 01:18:17.420]  тех сущностей, которые исполняются в тредпуле. Тредпул не может адекватно реагировать на это,
[01:18:17.420 --> 01:18:23.140]  и он может только разломаться. Ну, разломать в смысле вообще все, если пользователь не аккуратен.
[01:18:23.140 --> 01:18:37.260]  Ну, потому что мне хватает одного поинтера Next. Зачем мне Next и Pref? Я не собираюсь писать
[01:18:37.260 --> 01:18:42.940]  двусвязанные лукфри списки, это забава. Ну, короче, так все равно не выйдет. Вот, в общем,
[01:18:42.940 --> 01:18:49.180]  мне достаточно для всех моих целей. И для Strand достаточно, и для этот пула хорошего достаточно.
[01:18:49.180 --> 01:18:56.380]  Вот, ну и в этом коде тоже, в общем, один поинтер Next. Односвязанных списков хватает.
[01:18:56.380 --> 01:19:11.540]  Ну что, давайте сейчас зафиксируем наш прогресс. Мы разобрали, мы вроде бы понимаем,
[01:19:11.540 --> 01:19:15.780]  что такое stackless-крутина. Теперь крутина, которая останавливается только вот в своем
[01:19:16.140 --> 01:19:24.340]  вызове, не трогая вызова выше по stack, и которая умеет через оператор CoEv8 остановиться и
[01:19:24.340 --> 01:19:30.820]  запланировать свое возобновление с помощью специальной сущности овейтера. Ну, всю эту механику,
[01:19:30.820 --> 01:19:35.620]  всю механику крутина реализована, по сути, в компеляторе. Компелятор переписывает тело крутина
[01:19:35.620 --> 01:19:41.860]  в некоторый служебный класс, алоцирует его на куче, подставляет в CoEv8 вызов овейтеров,
[01:19:41.860 --> 01:19:48.140]  которые берет через оператор CoEv8, ну а дальше вы, реализовывая овейтеры для своих типов,
[01:19:48.140 --> 01:19:54.100]  кастомизируете поведение вот вашей конкретной крутины, которая работает с вашими конкретными
[01:19:54.100 --> 01:20:02.580]  объектами. Там таймер мизайсио, тредпулами, фьючами, мьютоксами, чем угодно. Вот после перерыва
[01:20:02.580 --> 01:20:10.220]  мы поговорим про вторую половину нашей проблемы, а именно про то, как крутину стартовать, завершить
[01:20:10.220 --> 01:20:19.220]  и как вернуть из нее какое-то значение. Давайте через 10 минут продолжим. Продолжаем, и за время
[01:20:19.220 --> 01:20:29.780]  перерыва мы починили ASIO, раздуманную часть ООН, а не наш код с крутинами. Вот, теперь все работает,
[01:20:29.780 --> 01:20:36.620]  теперь таймерам можно дожидаться. Вот таймер овейтер, вот мы, еще один пример, как можно дожидаться
[01:20:36.620 --> 01:20:41.980]  чего-то, в частности таймера, мы подписываемся в овейтерспенде на таймер, в колбеке мы резюмим
[01:20:41.980 --> 01:20:52.540]  крутину через короутинг-хэндл. И вот теперь можно запустить этот код, он скомпилируется,
[01:20:52.540 --> 01:21:02.580]  он поспит и напечатает привет через две секунды. Почему этот пример важен? Ну, важен не он,
[01:21:02.580 --> 01:21:11.780]  не пример, не ASIO, в смысле, не ASIO с таймером, вот таким вот с клипом, а пример чуть более общий,
[01:21:11.780 --> 01:21:20.580]  с которого и начинается, собственно, документация, референс про крутины C++. Это пример эхо-сервера
[01:21:20.580 --> 01:21:27.900]  на сокетах, на асинхронных сокетах с кое овейтами. Это код, который выглядит абсолютно как
[01:21:27.900 --> 01:21:34.980]  синхронный, но давайте разберемся, как он работает. Вот мы здесь видим сокет асинкрицам,
[01:21:34.980 --> 01:21:44.300]  но давайте я покажу это вот здесь, вот у нас где-то здесь будет такой же класс,
[01:21:44.300 --> 01:21:52.500]  он называется HandleClient, здесь мы в цикле, у нас есть локальные переменные, буфер, мы в цикле
[01:21:52.500 --> 01:21:59.180]  читаем из сокета с помощью операции асинкрицам и перед этим ставим кое овейт, а потом пишем
[01:21:59.180 --> 01:22:04.980]  сокет, тоже перед этим ставим кое овейт. Код выглядит как синхронный, код выглядит как
[01:22:04.980 --> 01:22:22.100]  блокирующий эхо-сервер, написанный на том же ASIO, разве что появляются вот эти самые кое овейт.
[01:22:22.100 --> 01:22:26.780]  Но мы знаем, что кое овейт — это как раз место, где прячется асинхронность, где мы останавливаем
[01:22:26.780 --> 01:22:31.100]  корутину, а потом ее возобновляем, поэтому нужно посмотреть, как ведет себя овейтер,
[01:22:31.100 --> 01:22:38.260]  который возвращает операция асинкрицам. Овейтер этот устроен каким-то очень предсказуемым образом,
[01:22:38.260 --> 01:22:44.580]  он связан с сокетом, с сокетом, буфером, и мы из сокета стартуем, для сокета стартуем асинхронную
[01:22:44.580 --> 01:22:53.940]  операцию чтения в буфер и подвешиваем кулбэк, в котором мы резюмим корутину. Корутина останавливается
[01:22:53.940 --> 01:23:02.340]  при вызове кое овейт от асинкрицам, возобновляется, когда в ивентлупе из епола будет
[01:23:02.340 --> 01:23:13.300]  достанут сокет с этим клиентом, он будет готов к чтению, из него прочитают, вызовут обработчик,
[01:23:13.300 --> 01:23:19.980]  в этом обработчике будет вызван handle резюм, и корутина продолжит свое исполнение вот с этого места.
[01:23:19.980 --> 01:23:28.380]  Вот мы опять с помощью нашего примитива, ну вот в данном случае стекл с корутина,
[01:23:28.380 --> 01:23:34.100]  ну мы и со стекл корутиной делали то же самое, мы трансформировали асинхронный код в асинхронный,
[01:23:34.100 --> 01:23:43.940]  так же, как мы делали в slip4, в одноименной задачи. Но смотрите, что важно, вот возьмем,
[01:23:43.940 --> 01:23:54.300]  например, наши стекл с корутиной и возьмем пример с мьютоксами и запустим его,
[01:23:54.300 --> 01:24:01.180]  посмотрим, где он тратит время. Ну вот мы на Flame Graph в прошлый раз смотрели уже,
[01:24:01.180 --> 01:24:27.980]  нет, это не он. Это workload с мьютоксами, ну мы на прошлой лекции про планировщик смотрели,
[01:24:27.980 --> 01:24:34.980]  насколько быстро работает код, где там 13 групп потоков по 100 штук, соревнуются за свои мьютоксы.
[01:24:34.980 --> 01:24:42.060]  В общем, мы видели, что в хорошем планировщике большую часть времени тратится на код пользователя,
[01:24:42.060 --> 01:24:48.140]  и вот какое-то время тратится на код планировщика самого, на процедуру планирования в Worker,
[01:24:48.140 --> 01:24:55.860]  и из самого кода пользователя еще есть обращение к runtime, и тут они тоже вот где-то торчат.
[01:24:55.860 --> 01:25:10.620]  Увижу ли я здесь то, что я хочу, или здесь слишком мелко все это? Ну вот тут он нашелся,
[01:25:10.620 --> 01:25:15.740]  он какой-то короткий, но тут меньше процента. В общем, есть вот какой-то overhead, который вносит
[01:25:15.740 --> 01:25:21.420]  сами корутины, вот наши stackful корутины, я имею в виду, реализованные через механизм переключения
[01:25:21.420 --> 01:25:30.780]  контекста. А давайте подумаем, какой overhead вносит stackful корутины вот в такую реализацию.
[01:25:30.780 --> 01:25:37.620]  Относительно вот оптимальной реализации, которая написана вот непосредственно на
[01:25:37.620 --> 01:25:44.500]  асинхронных операциях в ASIO. Мы ее разбирали, сейчас подробно разбирать не буду. Там,
[01:25:44.500 --> 01:25:53.940]  я напомню, у нас была функция session в синхронном коде, и она переписывалась в class session, в котором
[01:25:53.940 --> 01:25:59.860]  был start, там был дурид, дурид планировал первую асинхронную операцию чтения, в колбеке
[01:25:59.860 --> 01:26:05.060]  планировал, в колбеке запускал следующую асинхронную операцию записи, и так вот по циклам
[01:26:05.060 --> 01:26:14.380]  эти задачки запускались в event loop, и исполнение бежало вперед, обрабатывался клиент. Что же
[01:26:14.380 --> 01:26:20.140]  происходит при исполнении вот такого кода? Даже не то что про исполнение, вот при компериации
[01:26:20.140 --> 01:26:26.100]  этого кода. Вот мы написали такую функцию handleClient или session, если вам так угодно,
[01:26:26.100 --> 01:26:33.580]  чтобы больше соответствует. И дальше мы написали в ней coawait. Компиратор увидел этот coawait,
[01:26:33.580 --> 01:26:41.860]  он понял, что перед ним корутина. Это означает, что ее нужно переписать на автомат, то есть нужно
[01:26:41.860 --> 01:26:48.260]  для нее завести класс, в котором полями будут локальные переменные этой корутины. И вот,
[01:26:48.260 --> 01:26:56.500]  у нас появляется класс, у которого полем будет буфер дата. Вот пока все это очень похоже на то,
[01:26:56.500 --> 01:27:05.460]  что есть в этом примере. У нас здесь был class session, и у него есть локальные из поля дата для буфера.
[01:27:05.460 --> 01:27:12.580]  Класс этот алоцируется на куче, потому что вот непонятно, сколько клиентов мы будем обслуживать,
[01:27:12.580 --> 01:27:19.620]  lifetime динамический. Что происходит с корутиной? Опять, корутина свой state алоцирует на куче,
[01:27:19.620 --> 01:27:29.060]  потому что lifetime динамический. Что написано, что происходит с вызовом coawait при чтении сокета?
[01:27:29.060 --> 01:27:38.660]  Но вот он разворачивается вот в такой код, то есть появляется awaiter в качестве локальной
[01:27:38.660 --> 01:27:47.700]  переменной. Awaiter, который выглядит вот так. У него есть await ready, но он возвращает false.
[01:27:47.700 --> 01:27:59.020]  Этот await ready, он просто inline-ится в тело корутины. Ну и раз в теле корутины есть строчка if not false,
[01:27:59.020 --> 01:28:03.980]  то, видимо, этот if вообще просто стирается и остается только то, что написано вот здесь,
[01:28:03.980 --> 01:28:11.260]  просто вызов await suspend. А что написано в await suspend? Он ведь тоже inline-ится. Тут написано
[01:28:11.260 --> 01:28:24.500]  socket asyncretesum и handle-resue. Итого, у нас появляется класс для этой функции, у него полем служит,
[01:28:24.500 --> 01:28:33.100]  буфер служит полем этого класса, а в функции, ну условно resume, в этом классе методе resume,
[01:28:33.100 --> 01:28:43.220]  у нас есть код, где мы вызываем на сокете сразу же socket asyncretesum и в кулбеке планируем возобновление.
[01:28:43.220 --> 01:28:53.180]  Вот смотрите, буквально если трансформировать этот код в state-машину, которую пишет комператор,
[01:28:53.180 --> 01:28:58.540]  если заинлайнить все вызовы, которые мы не прятали в другие единицы трансляции, то комператор,
[01:28:58.540 --> 01:29:06.020]  в конце концов, напишет за нас вот просто буквально эту программу. То есть он увидит эту
[01:29:06.020 --> 01:29:14.380]  программу, а напишет вот эту в итоге и скомпилирует вот эту. И это очень неплохо, потому что кажется,
[01:29:14.380 --> 01:29:20.060]  что это решение оптимально, потому что вот ничего лучше, чем event-loop с кулбеками придумать нельзя.
[01:29:20.060 --> 01:29:25.820]  Вот так устроена операционная система, она дает асинхронные API для сокетов, и хорошее
[01:29:25.820 --> 01:29:29.900]  масштабируемое решение используют этот API. Мы его используем в виде библиотеки ASIO,
[01:29:29.900 --> 01:29:34.380]  но вот в таком виде писать код нам не очень удобно, поэтому мы придумываем абстракцию
[01:29:34.380 --> 01:29:40.660]  к routine, которые с помощью co-events вправляют поток управления обратно, делают исполнение как будто
[01:29:40.660 --> 01:29:48.460]  бы синхронным, но только на поверхности языка оно синхронное. А под капотом уже вот компилируется код,
[01:29:48.460 --> 01:29:54.300]  который получен переписыванием этого кода на автоматы, и компилируется код вот этот вот,
[01:29:54.300 --> 01:30:00.860]  то есть оптимальный асинхронный. Мы пишем код простой синхронный, а компилируем код оптимальный
[01:30:00.860 --> 01:30:10.020]  асинхронный. И вот вся абстракция co-routine в этом примере стирается на стадии компиляции. Вот наши
[01:30:10.020 --> 01:30:16.020]  co-routines, они stackful, они присутствуют в исполнении, там элоцируются стэки, там переключаются контексты,
[01:30:16.020 --> 01:30:23.100]  сохраняются, намазываются регистры, это все никуда не девается. Здесь же от co-routines следов не остается,
[01:30:23.100 --> 01:30:32.900]  ну потому что они существуют только на поверхности языка, что кажется довольно неплохо. То есть это,
[01:30:32.900 --> 01:30:40.780]  stackless co-routines, это решение, которое предлагает C++ для реализации асинхронного, для программирования
[01:30:40.780 --> 01:30:47.460]  асинхронности. Это абстракция, которая позволяет комбинироваться с произвольным рантаймом,
[01:30:47.460 --> 01:30:53.540]  с произвольными там фьючами, планировщиками, вводом-выводом. И при этом абстракция,
[01:30:53.540 --> 01:30:58.900]  которая при компиляции просто стирается, избавляет пользователя от всякого оверхеда.
[01:30:58.900 --> 01:31:04.340]  Но если, конечно, пользователь позаботился и аккуратно все написал. То есть co-routines могут
[01:31:04.340 --> 01:31:09.900]  быть бесплатными здесь. У нас остаются только аллокации самих co-routines, а это, кажется,
[01:31:09.900 --> 01:31:16.580]  вот вещь неизбежная, потому что у нас появляются какие-то операции конкурентные, которые,
[01:31:16.580 --> 01:31:20.220]  неизвестно сколько будут работать, у них динамическое время жизни.
[01:31:20.220 --> 01:31:30.500]  Хорошо. Значит, это все по-прежнему co-awaits, длинная история про co-awaits. А теперь давайте
[01:31:30.500 --> 01:31:40.060]  посмотрим, например, с пулом потоков, который был немного сложнее. Вот мы здесь написали
[01:31:40.060 --> 01:31:45.860]  оператор, здесь написали awaiter, который перепланировал co-routines в threadpool. Она
[01:31:45.860 --> 01:31:52.740]  начинала снаружи исполняться, потом прыгала в threadpool и бежала уже там. Но в конце есть еще
[01:31:52.740 --> 01:32:00.620]  одна примечательная конструкция, co-return. Мы пишем co-routines, но это как будто бы функция,
[01:32:00.620 --> 01:32:09.700]  из функции можно вернуть значение. В чем сложность? В том, что co-routines вот здесь,
[01:32:09.700 --> 01:32:17.460]  запускаясь, сразу что-то возвращает. Но вот этот вызов co-routines, это же не... он же не блокирует
[01:32:17.460 --> 01:32:23.340]  поток, пока co-routines завершится. Вызов co-routines, это всего лишь первый шаг co-routines до точки остановки.
[01:32:23.340 --> 01:32:32.140]  Вот. И эта co-routines вообще планирует спать, ну давайте в пять секунд и берем все же. Секунду
[01:32:32.140 --> 01:32:41.380]  собирается спать. Она не может сразу вернуть вот этот сейм пользователю. Она синхронная. Но при
[01:32:41.380 --> 01:32:47.740]  этом вызов сам по себе что-то возвращает. Итого, смотрите, у co-routines есть два возвращаемых
[01:32:47.740 --> 01:32:55.940]  значения. Одно, ну как бы, не знаю, настоящее как это назвать. Одно, которое она вернет в конце концов,
[01:32:55.940 --> 01:33:01.660]  которое она вычисляет, это сейм. А есть некоторое значение, которое она должна вернуть сразу
[01:33:01.660 --> 01:33:09.940]  пользователю. Ну и здесь, на самом деле, вот этот пример, он почти что не отличается от
[01:33:09.940 --> 01:33:25.020]  вернемся к примерам, к co-routines, от AsyncVIA. AsyncVIA это такая асинхронная функция, которая
[01:33:25.020 --> 01:33:30.620]  что-то вычисляет в фоне там в тредполе. Она вычисляет срок 2, она возвращает future от int,
[01:33:30.620 --> 01:33:37.540]  вместо int. Потому что сам int еще не готов. Видимо, похожая история должна быть с co-routines,
[01:33:37.540 --> 01:33:42.100]  потому что здесь co-routines такая же асинхронная операция, только она уже умеет останавливаться
[01:33:42.100 --> 01:33:49.100]  внутри себя во время своего исполнения. Но нам снова нужно разделить вот итоговое значение и
[01:33:49.100 --> 01:33:54.380]  некоторые типы этого значения int и мгновенный результат, который вернет co-routines при запуске. И
[01:33:54.380 --> 01:34:01.620]  что нужно выбрать, что можно выбрать, но кажется, что разумно выбрать future. Потому что future это
[01:34:01.620 --> 01:34:09.420]  представление для будущего значения. Мы, вызывая функцию, сразу получаем future, а потом мы блокируемся
[01:34:09.420 --> 01:34:16.820]  до тех пор, пока co-routine не завершится, в эту future не положат значения, и мы его здесь не прочитаем,
[01:34:16.820 --> 01:34:27.220]  не разблокируем поток. Отлично. Теперь осталось разобраться, как это все работает. И теперь мы
[01:34:27.220 --> 01:34:32.980]  возвращаемся снова к нашим примерам, где мы в рукопашную писали все эти co-routines. Мы хотим,
[01:34:32.980 --> 01:34:44.220]  видимо, наш пример еще немного доработать. Ну вот давайте посмотрим. Тут все написано уже,
[01:34:44.220 --> 01:34:53.780]  дела. Ну тогда придется прочитать. Писать не будем. Что должна сделать co-routine при запуске? Наша,
[01:34:54.340 --> 01:35:05.860]  наша игрушечная, ручная co-routine, она должна вернуть v пользователю, но v вычисляется асинхронно,
[01:35:05.860 --> 01:35:16.500]  поэтому она возвращает future от v. Это означает, что при старте co-routine, ну вот как обычно,
[01:35:16.500 --> 01:35:24.340]  она алоцирует свое состояние на куче. Это первый шаг при запуске. Дальше co-routine стартует,
[01:35:24.340 --> 01:35:34.140]  но перед этим мы из co-routines забираем return object. Это объект, который представляет собой,
[01:35:34.140 --> 01:35:44.740]  ну как бы, представление будущего результата. И в данном случае return object это future. Вот future
[01:35:44.740 --> 01:35:56.180]  мы получаем отсюда. А дальше, когда co-routine завершается, вот в точке, где в коде написано
[01:35:56.180 --> 01:36:04.300]  co-return v plus 1, мы должны в эту future положить значение, ну в промес этой future положить значение.
[01:36:04.300 --> 01:36:14.100]  Вот появляется такая логика. Нужно при старте co-routines построить некоторый объект
[01:36:14.420 --> 01:36:20.540]  будущего значения, ну я условно говорю, это не обязательно future, а при завершении co-routines
[01:36:20.540 --> 01:36:30.700]  нужно передать пользователю вот итоговый ответ. Это отдельная часть логики, и понятно,
[01:36:30.700 --> 01:36:37.580]  что она снова для co-routines кастомизируется снаружи. Потому что co-routine, еще раз повторяю,
[01:36:37.580 --> 01:36:44.820]  это языковая фича, она не может зависеть от каких-то там std future или чего-то подобного. Сам
[01:36:44.820 --> 01:36:51.860]  пользователь решает, какую семантику co-routine имеет. Вот в случае co-await пользователь кастомизирует
[01:36:51.860 --> 01:36:57.140]  поведение с помощью сущности avator. Он там для своих future, для своих mutex пишет свои avatars,
[01:36:57.140 --> 01:37:04.220]  и компаниятор их использует, вызывает их методы. С вызовом и возвратом значения та же самая
[01:37:04.220 --> 01:37:11.300]  история. Должна быть некоторая внешняя стратегия, в которой описано, как мы представляем будущий
[01:37:11.300 --> 01:37:18.220]  результат, и как мы пробрасываем в этот будущий результат значение итоговое. И этот объект,
[01:37:18.220 --> 01:37:26.060]  эта сущность для co-routines называется promise type, promise object. У каждой co-routines есть promise
[01:37:26.060 --> 01:37:34.900]  object, и в наших игрушечных co-routines, в наших ручных co-routines, это два метода. GetReturnObject
[01:37:34.900 --> 01:37:42.900]  и ReturnValue. GetReturnObject вызывается при старте co-routines, и он возвращает тот объект,
[01:37:42.900 --> 01:37:52.100]  который должен быть отдан пользователю на старте. А ReturnValue вызывается из самой co-routines в
[01:37:52.100 --> 01:37:58.300]  точке, где пользователем был написан co-return. Коррутина подошла к концу, хочет завершиться и
[01:37:58.300 --> 01:38:05.260]  возвращает ответ, но поскольку ответ асинхронный, нужна какая-то логика, которая пробросит его
[01:38:05.260 --> 01:38:10.580]  пользователю. Но в данном случае это promise, мы его в GetReturnObject построили, пару promise future,
[01:38:10.580 --> 01:38:18.420]  promise запомнили, future отдали, а здесь мы в promise, в ReturnValue положили значение. И вот как уже
[01:38:18.420 --> 01:38:27.020]  выглядит наша co-routine. Вот уже более полный код. Это автомат, плюс это запуск. Вот когда мы пишем в
[01:38:27.020 --> 01:38:41.420]  вот здесь кора от пула, то под капотом происходит вот просто такая механика. Вот написано разбор,
[01:38:41.420 --> 01:38:48.100]  как бы развертка всего этого кода, который сгенерирует комператор. Алоцировали на куче state.
[01:38:48.100 --> 01:38:57.420]  В state есть promise type. Мы из него взяли GetReturnObject, то есть future, вернули пользователю,
[01:38:57.420 --> 01:39:01.340]  стартовали co-routine. Когда co-routine добежала до конца, то есть в конце первого шага,
[01:39:01.340 --> 01:39:09.380]  мы написали promise type ReturnValue v plus 1, и в этом ReturnValue записали значение в promise. Оно
[01:39:09.380 --> 01:39:22.660]  полетело пользователю во future, и пользователь вот здесь его дождался. Ну как? Понятно?
[01:39:22.660 --> 01:39:31.100]  То есть это еще одна точка кастомизации, а вейтер указывает, как именно дожидаться конкретного
[01:39:31.100 --> 01:39:39.260]  объекта, конкретного события там таймером utux future, а promise type говорит, как co-routine
[01:39:39.260 --> 01:39:51.900]  взаимодействует с вызывающим ее кодом. Нет, это работает не так. То есть вопрос, звучит так,
[01:39:52.460 --> 01:40:03.460]  как именно компилятор связывает конкретную co-routine с конкретным типом promise type. В случае
[01:40:03.460 --> 01:40:12.140]  овейтеров у нас был оператор co-avait для типа. В случае promise type… Ну вообще, чем определяется
[01:40:12.140 --> 01:40:18.620]  promise type? Вот есть co-routine, вот оно написано. Ну или давайте посмотрим прямо на настоящую co-routine,
[01:40:18.620 --> 01:40:33.260]  вот написано… Вот написана настоящая co-routine. Правда, она возвращает, черт и что еще? Ничего не
[01:40:33.260 --> 01:40:41.820]  возвращает даже, черт возьми. Давайте тогда смотреть все же сюда. Она возвращает вот future,
[01:40:41.820 --> 01:40:50.820]  внутри вызывает async via, получает future, дожидается ее, co-routine 2.1. От чего отталкивается компилятор,
[01:40:50.820 --> 01:41:03.620]  когда он ищет promise type? Нет. Сейчас аккуратнее скажи. Я просто двумя способами тебя понял. Да,
[01:41:04.020 --> 01:41:18.740]  компилятор смотрит, какой тип вы возвращаете, и по нему находит уже promise type. Как именно… Ну вот
[01:41:18.740 --> 01:41:30.140]  давайте я здесь покажу, если вроде бы было. У меня есть future, и вот co-routine возвращает future. Это значит,
[01:41:30.140 --> 01:41:41.260]  что должен быть promise type, реализованный для std future. Вот он. И есть специализация
[01:41:41.260 --> 01:41:51.580]  co-routine traits для std future. Вот если мы хотим поддержать некоторый тип в качестве возвращаемого
[01:41:51.580 --> 01:41:59.060]  значения для co-routine, мы должны написать специализацию co-routine traits и там указать,
[01:41:59.060 --> 01:42:06.940]  что promise type для вот этой future будет служить вот этот класс, в котором будут методы,
[01:42:06.940 --> 01:42:13.380]  но в котором будет promise в данном случае, getReturnObject будет строить по нему future,
[01:42:13.380 --> 01:42:22.740]  а return value будет… ну вот это для void специализация, для произвольного t, а в return value мы
[01:42:22.740 --> 01:42:28.220]  будем просто в promise класть значение. Но правда, co-routine может разными способами закончиться,
[01:42:28.220 --> 01:42:35.740]  может быть exception брошен, может быть… может быть брошен exception, и тогда тоже нужно какой-то
[01:42:35.740 --> 01:42:43.060]  способ, которым можно exception прокинуть, вернуть пользователю. Поэтому promise type, он помимо
[01:42:43.060 --> 01:42:54.780]  getReturnObject и return value может реализовать еще вот setException, unhandledException. Почему называется
[01:42:54.780 --> 01:43:01.340]  promise type? Ну потому что такой очевидный результирующий тип для future и для co-routine это future,
[01:43:01.340 --> 01:43:13.300]  вот. А promise type для co-routine, который возвращает future, будет просто promise. Поэтому… ну это странный
[01:43:13.300 --> 01:43:20.020]  выбор, потому что мы как будто бы связываем co-routine с… co-routine с синхронностью, хотя в общем случае это
[01:43:20.020 --> 01:43:26.860]  делать не обязательно. Ну я подозреваю, что название promise object, promise type выбрано именно
[01:43:26.860 --> 01:43:31.620]  по этой причине. Ну вот давайте посмотрим сущности, которые участвуют. У нас здесь promise object,
[01:43:31.620 --> 01:43:39.100]  co-routine handle, co-routine state. Вот все эти сущности вроде бы проговорили, которые участвуют в
[01:43:39.100 --> 01:43:52.180]  механике, задействованные в механике co-routine. Понятно, да? Да, вообще говоря, promise type зависит
[01:43:52.180 --> 01:43:59.540]  от всей сигнатуры, то есть еще и от аргументов. Но в данном случае не зависит. То есть для всех типов,
[01:43:59.540 --> 01:44:05.500]  ну для всех аргументов, если возвращаем его из значения future, то promise type будет служить вот
[01:44:05.500 --> 01:44:15.340]  такой код, то есть по сути… по сути это promise. Ну потому что там нет set value с аргументом,
[01:44:15.340 --> 01:44:27.380]  и там return void, а не return value вызывается. Ну void – это специальный тип. Void – это беда для
[01:44:27.380 --> 01:44:34.540]  шаблонов. Вот есть… смотри, есть типы населенные многими значениями, есть тип void без значений,
[01:44:34.540 --> 01:44:44.540]  а есть тип unit с одним значением. Вот. И ну в этом большая неудача, что у нас здесь не… что мы future,
[01:44:44.540 --> 01:44:51.980]  которые ничего не возвращают, а возвращают void, а не unit. Ну или функции, которые не возвращают,
[01:44:51.980 --> 01:44:56.540]  возвращают void, а не unit. Если бы не возвращали unit, было бы гораздо приятнее всем. Ну это…
[01:44:56.540 --> 01:45:07.940]  Я вообще-то серьезно отвечаю, как вот хорошие языки это делают. Вот хорошие языки… На самом
[01:45:07.940 --> 01:45:13.260]  деле, сложный вопрос, он про дизайн языков, он не про то, что там какой-нибудь костыль приделать. Вот
[01:45:13.260 --> 01:45:17.820]  в разумных языках функции, которые ничего не возвращают, возвращают unit на самом деле,
[01:45:17.820 --> 01:45:22.020]  потому что unit может быть… ну короче, это с expression хорошо матчится. В общем, там можно дальше
[01:45:22.020 --> 01:45:29.580]  композицию функций делать. Отдельная история. В шаблонах C++ void – это всегда большая боль,
[01:45:29.580 --> 01:45:34.220]  потому что он сильно отличается от остальных синтактически, его обработка сильно отличается,
[01:45:34.220 --> 01:45:41.740]  поэтому приходится специализация. Вот поэтому здесь отдельная специализация для void. Ну и
[01:45:41.740 --> 01:45:52.620]  return void вместо return value. Итак, вот promise object, и он в механике вот используется так. Он
[01:45:52.620 --> 01:45:59.660]  является… становится полем картины при старте. Мы из него достаем return object, возвращаем его,
[01:45:59.660 --> 01:46:09.020]  а при завершении мы через return value прокидываем ответ пользователя. А теперь еще немного глубже
[01:46:09.020 --> 01:46:17.160]  погружаемся в реальность и узнаем. Ну например, из стандарта C++, что на самом деле, когда вы
[01:46:17.160 --> 01:46:24.740]  компилируете коррутину, комп vest компилирует не тело вашей коррутины. Ну то есть не только тело
[01:46:24.740 --> 01:46:31.260]  вашей коррутины, не прямо тело вашей коррутины трансформирует в автомат. А на самом деле берет
[01:46:31.260 --> 01:46:36.940]  тело вашей коррутины, оборачивает ее в некоторый служебный код и уже ее трансформирует в автомат.
[01:46:36.940 --> 01:46:45.640]  Ну и в частности, тут появляется локальная переменная promise object, и она становится полем
[01:46:45.640 --> 01:46:50.940]  класса. То есть это не какое-то специальное правило, просто мы сделали ее полем, поэтому вот здесь
[01:46:50.940 --> 01:46:58.140]  оно есть, как любая другая локальная переменная. А что еще интересно, здесь появляются две
[01:46:58.140 --> 01:47:05.300]  дополнительные точки остановки, два новых коэвейта. То есть плюс ко всем вашим в крутине есть еще два
[01:47:05.300 --> 01:47:16.420]  служебных коэвейта, initial suspend и final suspend. То есть крутина может остановиться еще до запуска
[01:47:16.420 --> 01:47:21.940]  вот, в общем, вашего кода, который вы написали, и может зачем-то остановиться в самом конце перед
[01:47:21.940 --> 01:47:30.340]  завершением. И когда мы пишем promise, ну вот у нас здесь этого не было, он был упрощенный,
[01:47:30.340 --> 01:47:38.740]  этот самый promise. Когда мы пишем настоящий promise, то мы должны указать, но мы должны вернуть
[01:47:38.740 --> 01:47:43.660]  какие-то овейтеры из initial suspend и final suspend. У нас есть две дополнительные функции, которые
[01:47:43.660 --> 01:47:52.260]  решают, которые определяют, как именно крутина будет действовать в точке начальной остановки и в
[01:47:52.260 --> 01:48:00.420]  точке финальной остановки. И здесь мы возвращаем такой готовый овейтер suspend never, который в
[01:48:00.420 --> 01:48:08.380]  await ready говорит всегда true. Ну просто крутина игнорирует эти точки старта и финальной остановки.
[01:48:08.380 --> 01:48:17.700]  То есть как будто бы их нет. Но на самом деле тут можно что-то более умное написать, и мы чуть
[01:48:17.700 --> 01:48:30.140]  позже разберемся, что именно. Это нетривиально. А давайте разбираться, собственно. Давайте поговорим
[01:48:30.140 --> 01:48:40.380]  про нечто совершенно другое. Забудем про всякие сейчас future promises. Поговорим про stackless природу
[01:48:40.380 --> 01:48:46.700]  крутина. Мы как-то, ну, сказали, что вот крутина останавливает только свой вызов, не тормозит stack
[01:48:46.700 --> 01:48:53.060]  вызовов над собой, а дальше начали их писать, и все упрощается, потому что состояние остановленной
[01:48:53.060 --> 01:48:59.420]  крутины — это всего лишь состояние вот одного stack-ового фрейма. Поэтому нам не нужно
[01:48:59.420 --> 01:49:07.860]  close stack держать. Но с другой стороны, смотрите, в чем есть некоторая сложность. Предположим,
[01:49:07.860 --> 01:49:20.620]  что у нас есть функция bar, которая является крутиной, и функция foo вызывает функцию bar.
[01:49:26.140 --> 01:49:34.620]  Когда у вас в функции bar может быть написан кое вейт какой-нибудь. В чем подвох? В чем сложность?
[01:49:34.620 --> 01:49:41.420]  Ну, в случае stackful крутин никакой проблемы не было. Если вы вызывали функцию, она... та вызывала
[01:49:41.420 --> 01:49:47.100]  функцию, та вызывала функцию, и в конце концов где-то в недрах этого stack вызова был написан suspend,
[01:49:47.100 --> 01:49:51.660]  то просто исполнение останавливалось, stack замораживалось, и мы выпрыгивали куда-то наверх.
[01:49:51.660 --> 01:49:59.820]  А теперь представьте, что вы вызываете функцию, а это не функция крутина на самом деле. И она
[01:49:59.820 --> 01:50:09.540]  стартует, а потом решает остановиться в середине. Она останавливается, а вы-то нет? То есть когда вы
[01:50:09.540 --> 01:50:15.860]  вызываете крутину в своем коде, вот я говорил уже об этом здесь, то синхронно выполняется только
[01:50:15.860 --> 01:50:23.540]  первый ее шаг до первого кое вейта, на котором крутина становится. Вот, мы здесь вызвали, и все,
[01:50:23.540 --> 01:50:28.620]  исполнение побежало дальше. Но, может быть, мы к этому не готовы, может быть, мы хотим все-таки
[01:50:28.780 --> 01:50:40.380]  вызвать крутину, и мы вызываем функцию, а она крутиной вдруг оказалась. Как нам быть?
[01:50:44.380 --> 01:50:51.940]  Вот, если вы пока не поняли, о чем я говорю, давайте я вам посоветую одну отличную статью
[01:50:51.940 --> 01:50:57.540]  чудесного человека с чудесным блогом, который написал книжку crafting interpreters про то,
[01:50:57.540 --> 01:51:04.980]  как писать интерпретаторы и ратуальные машины великолепны. Вот, читайте ее сегодня же. У него
[01:51:04.980 --> 01:51:10.860]  есть очень известная, очень старая статья What color is your function? Пожалуйста, непременно с ней
[01:51:10.860 --> 01:51:21.300]  знакомьтесь, если вы работаете с крутинами. В любом языке, неважно, какой. Смотрите. Утверждается,
[01:51:21.300 --> 01:51:28.420]  что в вашем языке, в нашем языке C++ есть разноцветные функции. Есть функции красные,
[01:51:28.420 --> 01:51:39.300]  есть функции синие. И правила вызова красных и синих функций отличаются. Ну, пока не страшно,
[01:51:39.300 --> 01:51:45.780]  дальше начинаются уже трудности, что если у вас функция красная, то из нее можно звать синию
[01:51:45.780 --> 01:51:54.140]  функцию. А если функция синия, то красную звать уже нельзя. Это чем-то плохим закончится. И вообще,
[01:51:54.140 --> 01:52:06.980]  красные звать как-то больно, больнее, чем обычные функции. Что-то затрудняет их вызов. Вот мир в таких
[01:52:06.980 --> 01:52:11.500]  языках, да, но вот и библиотеки, вот работать с библиотеками и некоторые функции, в них красные.
[01:52:11.500 --> 01:52:22.220]  Вот статья про такое общее наблюдение. Что такое красные и синие функции? О чем идет речь?
[01:52:22.220 --> 01:52:29.820]  Это функции синхронные и асинхронные. Вот у вас есть функция синхронная, вы вызвали вызов,
[01:52:29.820 --> 01:52:35.340]  завершился всё. Операция завершена какая-то, логическая. А есть функции асинхронные,
[01:52:35.340 --> 01:52:40.420]  которые у нас представлены в языке крутинами. Мы их вызываем, они стартуют, а потом останавливаются,
[01:52:40.420 --> 01:52:47.540]  и потом где-то асинхронно продолжают работать. Но прямо сейчас нам колеру сообщают, что вызов
[01:52:47.540 --> 01:52:56.580]  завершился как будто бы. Вот, ну и разумеется, вы можете в крутине позвать некрутинную функцию,
[01:52:56.580 --> 01:53:04.260]  обычную. И там стэк будет наращиваться. В этом проблемы никакой нет. Stackless крутина может
[01:53:04.260 --> 01:53:10.820]  вызывать другие функции и копить стэк, разумеется. Но в какой-то момент она захочет остановиться,
[01:53:10.820 --> 01:53:17.220]  и таким образом она создаст некоторую проблему колеру. Вот обычная функция не может вызвать
[01:53:17.220 --> 01:53:27.300]  асинхронную. Тогда как быть обычной функцией? Ну, видимо, ей придется тоже стать асинхронной.
[01:53:27.300 --> 01:53:33.220]  То есть, если она вызывает крутину, то видимо, она сама должна быть крутиной тоже. Потому что
[01:53:33.220 --> 01:53:41.220]  вызываемая крутина может остановиться, а значит, нужно остановиться и ей колеру. И вот так начинает
[01:53:41.220 --> 01:53:46.820]  распространяться синтактическое заражение этими co-awaitами. Вот у вас где-то появился co-return,
[01:53:46.820 --> 01:53:55.020]  и вы в функции foo вызывали этот бар, и этот бар тоже становится крутиной. И функция,
[01:53:55.020 --> 01:54:00.740]  которая вызывает эту foo, тоже становится крутиной. И тоже должна дожидаться каждую вызываемую
[01:54:00.740 --> 01:54:07.620]  функцию. Проблема в том, что наверху этого стека находится main, а main — это синяя функция,
[01:54:07.620 --> 01:54:16.860]  разумеется, не асинхронная. Поэтому где-то вы должны провести черту. Вот. Ну и тут ничего
[01:54:16.860 --> 01:54:24.700]  неожиданного, и вот здесь мы используем для всей этой композиции future. Future, для которой поддержан
[01:54:24.700 --> 01:54:33.460]  оператор co-await. Вот с этим самым future-авейтором, который делает subscribe и резюмит крутину в колбеке.
[01:54:33.460 --> 01:54:41.380]  Мы вызываем крутину, она возвращает future — потенциально асинхронная операция. Если мы вызываем
[01:54:41.380 --> 01:54:50.820]  функцию bar и хотим дождаться ее синхронно, то мы говорим co-await и сами блокируемся до тех пор,
[01:54:50.820 --> 01:54:56.340]  пока в этой future не появится значение. А если мы хотим, ну и вот так все происходит по стеку выше,
[01:54:56.340 --> 01:55:02.180]  все это тоже крутины красные, а в какой-то момент мы вызываем из main вот функцию,
[01:55:02.180 --> 01:55:07.260]  которая не хочет быть крутиной, и она уже вот здесь блокируется, честно. Мы здесь проводим
[01:55:07.260 --> 01:55:12.900]  границу между синей функцией и красной функцией. Мы говорим, хватит, будем ждать, блокируемся на
[01:55:12.900 --> 01:55:21.060]  future. Вот поэтому возвращаемое значение нам должно позволять выполнять две вот эти операции.
[01:55:21.060 --> 01:55:28.060]  С одной стороны, дождаться с помощью co-await, блокируя крутину, а с другой стороны, блокировать
[01:55:28.060 --> 01:55:32.900]  поток, чтобы ну просто провести черту между красным и синим миром, между синем и красным,
[01:55:33.060 --> 01:55:43.300]  чтобы это заражение остановить. Понятно? Ну а теперь перейдем к сложным вещам.
[01:55:43.300 --> 01:55:54.620]  Смотрите, утверждается, что вот так можно делать, в смысле можно использовать future в качестве
[01:55:54.620 --> 01:55:59.580]  возвращаемого значения для крутин. Также утверждается, что это очень неэффективно.
[01:55:59.580 --> 01:56:10.700]  Почему? Причины много. Ну причины в дизайне future. Что такое future? Ну future, она в паре с
[01:56:10.700 --> 01:56:16.440]  промессом. И задумка какая? У вас асинхронная операция, ну есть два потока. Один консюмер,
[01:56:16.440 --> 01:56:22.300]  другой продюсер. И вот в этом потоке что-то вычисляется, этот поток что-то ждет. Ну не то,
[01:56:22.300 --> 01:56:25.860]  что вычисляется, может быть там вот вывод делается, может быть вычисляется, может быть таймер
[01:56:25.860 --> 01:56:30.500]  какой-нибудь. Ну в общем, есть два потока, и где-то здесь происходит событие, а здесь его ждут.
[01:56:30.500 --> 01:56:37.740]  И поэтому мы строим между ними канал, здесь promise, здесь future, и можно из промесса future
[01:56:37.740 --> 01:56:45.780]  передать какую-то информацию, результат, ошибку или без значения. Как устроены future, точнее как
[01:56:45.780 --> 01:56:53.580]  устроены API, которые работают с future? Устроены они обычно так. Возвращаемся к примеру с
[01:56:53.580 --> 01:57:01.940]  гаррутинами. Вот мы здесь получаем future, когда мы стартуем асинхронную операцию. И если у нас
[01:57:01.940 --> 01:57:07.620]  уже есть future, то это означает, что где-то уже стартовала асинхронная операция, есть какой-то
[01:57:07.620 --> 01:57:15.460]  другой поток, возможно у которого есть promise, и мы уже с ним гоняемся. Мы можем вот здесь подвешивать
[01:57:15.460 --> 01:57:24.700]  кулбэк к future, а из пола потоков могут вкладить значение в эту future, ну в shared state между ними.
[01:57:24.700 --> 01:57:33.300]  Вот есть уже гонка. И если вы решали уже самую простую, хотя бы future, а другую еще не могли, то
[01:57:33.300 --> 01:57:37.620]  вы знаете, что этот shared state лоцируется на куче, потому что динамический lifetime, потому что непонятно,
[01:57:37.620 --> 01:57:42.660]  кто раньше умрет. В общем, есть shared state, динамическая локация. На него держатся сильные ссылки,
[01:57:42.660 --> 01:57:48.900]  shared pointers с атомик счетчиками. И просто внутри shared state есть синхронизация между
[01:57:48.900 --> 01:57:59.060]  продюсером и консюмером. А локация, подсчет ссылок, синхронизация. А теперь смотрим на этот
[01:57:59.060 --> 01:58:10.300]  пример, не на этот, на этот пример. У нас здесь есть функция foo, она вызывает функцию bar. Вообще-то,
[01:58:10.300 --> 01:58:17.260]  здесь время жизни функцию foo покрывает время жизни функции bar. Время исполнения функции foo
[01:58:17.260 --> 01:58:23.740]  покрывает время исполнения функции bar. Нужна динамическая локация? Не нужна. Нужен подсчет
[01:58:23.740 --> 01:58:30.500]  ссылок, кто раньше умрет? Не нужен. Нужна синхронизация? Ну, на самом деле, тоже нет.
[01:58:30.500 --> 01:58:40.100]  Что такое co-await bar? Мы резюмим к рутину, но перед этим подписываемся на... Мы останавливаем
[01:58:40.100 --> 01:58:45.060]  текущую к рутину foo и подписываемся на future, который возвращает нам bar.
[01:58:45.060 --> 01:58:58.300]  Bar как будто бы уже может исполняться в этот момент. Ну, давайте не будем так делать просто.
[01:58:58.300 --> 01:59:08.260]  Давайте мы не будем исполнять foo до тех пор, пока мы в этом co-await не подвесили callback к future.
[01:59:08.260 --> 01:59:18.900]  То есть, смотрите, вот... Какова семантика? Мы вызываем асинхронную функцию, а мы вызываем
[01:59:18.900 --> 01:59:24.780]  в асинхронную функцию другую асинхронную функцию и хотим дождаться завершения функции bar. Как это
[01:59:24.780 --> 01:59:33.180]  было бы оптимально сделать? Оптимально было бы получить future каким-то образом, без синхронизации
[01:59:33.180 --> 01:59:38.420]  спокойно повесить на нее callback, что когда future готова, нужно запустить текущую к рутину,
[01:59:38.420 --> 01:59:48.340]  а после этого уже зарезюмить к рутину bar, чтобы она начала бежать. Вот future это все не делают,
[01:59:48.340 --> 01:59:53.420]  потому что future... Ну, в них уже есть shared state, есть уже локация, еще чехсылок, синхронизация,
[01:59:53.420 --> 02:00:01.300]  поэтому нам нужна не future. Нам нужен некоторый другой класс, который мы назовем task. Он по
[02:00:01.300 --> 02:00:08.660]  смыслу похож, то есть он представляет из себя будущее значение, но он вот прям для к рутин создан.
[02:00:08.660 --> 02:00:18.460]  Вот я здесь пишу пример, я вызываю в цикле к рутину и блокируюсь до тех пор, пока она не завершится,
[02:00:18.460 --> 02:00:31.220]  но опять представим себе, что она асинхронная. Что сделает этот task? Ну вот, он должен работать
[02:00:31.220 --> 02:00:37.980]  вот так, как я говорю. То есть, когда мы вызываем subwork, сама к рутину не должна стартовать,
[02:00:37.980 --> 02:00:44.420]  она должна только возвращать task, не начиная исполняться, потому что, когда начнут исполняться,
[02:00:44.420 --> 02:00:53.180]  она уже может куда-то убежать в другие потоки. Вот мы хотим сначала получить от этого вложенного
[02:00:53.180 --> 02:01:02.100]  вызова task, подписаться, что мы хотим себя возобновить, когда в task появится значение,
[02:01:02.100 --> 02:01:11.580]  а потом стартовать дочернюю к рутину, которая уже начнет исполняться, и потом этот task заполнит
[02:01:11.580 --> 02:01:24.380]  значение. Понятно, чего я хочу? Вот, а теперь начинается реализация этого. Ну это сложная
[02:01:24.380 --> 02:01:35.220]  часть, давайте попробуем, по крайней мере, не отрубиться. Ну нужно сейчас вот собрать
[02:01:35.220 --> 02:01:41.460]  все вместе, все, чтобы он на занятии, все в кучу собрать. И знания и про фьюч, и про асинхронности,
[02:01:41.460 --> 02:01:52.260]  и про таски, и про промиссы, и про вейтеры, про все это вместе. Я боюсь, что я не смогу 5 минут
[02:01:52.260 --> 02:01:58.100]  сейчас повторять еще раз. Но я хочу получить композицию к рутин, избавившись от накладных расходов
[02:01:58.100 --> 02:02:09.340]  фьюч. А именно, мне не нужна динамическая локация shared state для фьюча, мне не нужна...
[02:02:09.340 --> 02:02:17.740]  Еще раз, понятно, что все это лишнее. Вот, я хочу все этого избежать. И я объяснил даже,
[02:02:17.740 --> 02:02:23.820]  как. По смыслу это тоже представление для будущего значения. Но как его извлечь это
[02:02:23.820 --> 02:02:32.900]  будущее значение? Вызвать кое вейт. А кое вейт на таске должен запустить под задачу, должен
[02:02:32.900 --> 02:02:41.300]  сначала подписать нашу коррутину на появление значения и вызвать под задачу. При этом никаких
[02:02:41.300 --> 02:02:49.020]  shared state делать не нужно, потому что... Ну просто у нас lifetime и коррутин вложены друг в друга,
[02:02:49.020 --> 02:02:55.620]  bar вложен foo. В общем, в случае с фьючами это не так, поэтому там динамическая локация есть здесь,
[02:02:55.620 --> 02:03:08.260]  у нас она не нужна. Ну вот, смотрите, когда мы вызываем кое вейт sub work, мы вызываем кое вейт
[02:03:08.260 --> 02:03:16.020]  на таске. И хотим, видимо, в этом кое вейт от таски остановить текущую коррутину до тех пор,
[02:03:16.180 --> 02:03:24.540]  пока не будет завершена эта коррутина. Но мы хотим сначала подписаться на возобновления,
[02:03:24.540 --> 02:03:32.500]  а потом уже стартовать дочернюю коррутину. И вот тут мы вспоминаем, что у коррутин не просто так,
[02:03:32.500 --> 02:03:49.940]  есть initial suspend. Вот если мы пишем task, если мы пишем task, то вот у него есть promise type.
[02:03:49.940 --> 02:04:06.740]  И у него есть initial suspend. И он suspend always. То есть коррутина просто всегда останавливается при
[02:04:06.740 --> 02:04:16.300]  своем вызове. Вот если коррутина возвращает таску, то она при запуске останавливается в точке initial
[02:04:16.300 --> 02:04:24.460]  suspend. То есть вообще не доходит до исполнения кода пользователя. Но зато сразу отдаёт пользователю
[02:04:24.460 --> 02:04:35.660]  объект task, отдаёт колеру объект task. Это понятно? То есть вызывая sub work, мы на самом деле останавливаем
[02:04:35.660 --> 02:04:45.340]  коррутину до ещё выполнения этого тела, но уже отдаём колеру task. А колера вызывает на этом
[02:04:45.340 --> 02:04:55.380]  task co-await. И что происходит дальше? Ну, видимо, нужно смотреть, как реализован авейтер для таски.
[02:04:55.380 --> 02:05:02.980]  Да, давайте только посмотрим, как именно таска получается. Вот у нас есть task promise,
[02:05:02.980 --> 02:05:14.940]  и у него есть у него есть initial suspend, который останавливает под задачу всегда.
[02:05:14.940 --> 02:05:27.540]  А ещё есть get return object, который отдаёт что-то пользователю. Вот смотрите, что мы отдаём. Мы
[02:05:27.540 --> 02:05:41.380]  отдаём пользователю task, собственно, в котором мы запоминаем handle вот себя. То есть пользователю
[02:05:41.380 --> 02:05:55.460]  отдаётся task, у которого есть поле. Давайте мы сейчас его будем искать. Вот task. У него есть поле
[02:05:55.460 --> 02:06:10.780]  coroutine handle. Это sub work, и вот он остановился в initial suspend перед запуском, но вернул пользователю
[02:06:10.780 --> 02:06:18.820]  object task, внутри которого лежит handle вот этой коррутины. То есть work может возобновить через этот
[02:06:18.820 --> 02:06:30.100]  handle sub work. И, наверное, мы это и делаем в co-await. Смотрим теперь на авейтер для класса task. Вот у
[02:06:30.100 --> 02:06:43.780]  нас есть class task, у него есть авейтер, и у него есть await suspend. Но я расскажу сейчас не его,
[02:06:43.780 --> 02:06:49.940]  а на самом деле, что бы мы хотели там написать. Давайте подумаем, что бы мы там хотели написать,
[02:06:49.940 --> 02:07:01.260]  на самом деле. Вот у нас, смотрите, у нас есть, вот в этом месте компилятор запустил sub work,
[02:07:01.260 --> 02:07:10.580]  остановил sub work перед первой строчкой вашего кода и вернул наверх объект task, в котором лежит
[02:07:10.580 --> 02:07:23.340]  coroutine handle для sub work. А теперь вы work, вызываете co-await на объекте, на авейтере для task.
[02:07:23.340 --> 02:07:31.460]  Ну вот что вы сделаете в co-await для task? Давайте логически рассуждать. Что вы хотите? Вы хотите
[02:07:31.460 --> 02:07:39.420]  остановиться сами, вот вы текущая коррутина work, хотите остановиться и возобновиться тогда,
[02:07:39.420 --> 02:07:48.540]  когда закончится sub work, но он даже не запустился еще. Поэтому, видимо, мы должны sub work сказать,
[02:07:48.540 --> 02:07:56.700]  что «пожалуйста, вот я, коррутина work, вот мой handle, когда ты завершишься, запусти меня после
[02:07:56.700 --> 02:08:06.340]  этого. Я пока засыпаю, а ты возобновляйся». То есть мы сначала говорим sub work, чтобы он запомнил
[02:08:06.340 --> 02:08:13.900]  handle на нас, у нас его handle есть, и мы через него говорим sub work, чтобы он нас возобновил в конце,
[02:08:13.900 --> 02:08:24.460]  а сами засыпаем. Вот. Вот видите, у нас есть awaiting, coroutine, это collar, это work, это то,
[02:08:24.460 --> 02:08:33.160]  что снаружи, и мы засыпаем, и мы resume sub work, дочернюю коррутину. Но почему-то написан код
[02:08:33.160 --> 02:08:39.880]  задом наперед. Почему-то мы сначала возобновляем ребенка, а потом мы к нему подвешиваем себя,
[02:08:39.880 --> 02:08:50.280]  хотя могли бы сделать наоборот. Это тайна, которая останется на время домашней, до домашней,
[02:08:50.280 --> 02:08:57.760]  окутанной мраком, потому что ответ смешной. Я дам вам возможность насладиться им самостоятельно,
[02:08:57.760 --> 02:09:03.800]  он для тех, кто решит. Давайте думать, ну, можно написать, как я сказал, сначала подвешиваем,
[02:09:03.800 --> 02:09:10.680]  потом резюмим. Увидите, чем это закончится. Что происходит, ну, ребенок запускается, sub work
[02:09:10.680 --> 02:09:19.720]  запускается, он работает, работает, работает, а потом приходит в final suspend. Что происходит в
[02:09:20.480 --> 02:09:32.040]  final suspend? В final suspend мы возвращаем final awaitable, еще один awaiter, и как он устроен?
[02:09:32.040 --> 02:09:52.400]  Ну, во-первых, коррутина дочерне резюмит коррутину родительскую. Это был план. Sub work завершился,
[02:09:52.400 --> 02:10:01.960]  и теперь sub work пришел в final suspend, а теперь резюмит колера work, вот здесь вот. Тут есть
[02:10:01.960 --> 02:10:15.200]  какой-то еще exchange, опять не думайте о нем. И при этом sub work засыпает, засыпает вот здесь,
[02:10:15.200 --> 02:10:21.800]  в final suspend, он не выходит оттуда. Он мог бы завершиться, написать дредзис, но он так не делает.
[02:10:21.800 --> 02:10:29.960]  Почему он так не делает? Ответ очень хитрый, и мне кажется, очень важный для понимания эффективности
[02:10:29.960 --> 02:10:40.120]  коррутины, почему вот дизайн такой навороченный. Смотрите, даже если мы вот написали хороший таск,
[02:10:40.120 --> 02:10:44.400]  я вроде бы там объяснил, как он работает, если вы отрубились, ну, ничего страшного,
[02:10:44.400 --> 02:10:53.600]  это сложно сходу понимать, я бы не понял точно. Смотрите, в чем еще есть проблема. Что такое запуск
[02:10:53.600 --> 02:11:00.960]  коррутины? Вот мы с вами писали развертку, и вот здесь мы видим, что запуск коррутины любой,
[02:11:00.960 --> 02:11:11.440]  это аллокация стейта на куче, возврат значений, но аллокация стейта. И вот у нас есть
[02:11:11.440 --> 02:11:26.280]  вызов сабворка в цикле, и вроде бы вложенная функция, вложенная функция — это вызов коррутины,
[02:11:26.280 --> 02:11:32.080]  вот этот вызов — это вызов коррутины, это значит аллокация, по идее, ее стекового фрейма на куче,
[02:11:32.080 --> 02:11:37.640]  динамическая аллокация. Но с другой стороны, тут же динамические аллокации вроде как не нужны,
[02:11:37.640 --> 02:11:41.040]  потому что все друг друга вложено логически, ну, то есть у нас такое структурное программирование,
[02:11:41.040 --> 02:11:48.400]  вложенные вызовы, вызовы вложены друг к другу, образуют иерархию такую. Поэтому зачем нужен final
[02:11:48.400 --> 02:11:59.560]  suspend? Когда на самом деле коррутина сабворк разрушается, вот в этом примере, в реализации
[02:11:59.560 --> 02:12:13.160]  таска, она разрушается в деструктуре таска. Когда таск разрушается, тогда вызывается дестроид
[02:12:13.160 --> 02:12:22.880]  для коррутины. И вот это важно к империатору. Почему? Потому что, смотрите, при вызове сабворк
[02:12:22.880 --> 02:12:30.880]  компилиатор понимает, что нужно алоцировать state для дочерней коррутины, а при разрушении объекта
[02:12:30.880 --> 02:12:38.000]  таск, локальной переменной, компилиатор понимает, что коррутина, что дочерняя коррутина разрушается.
[02:12:38.000 --> 02:12:45.360]  Ну, как бы сам таск позаботился, чтобы это было корректно. И все, теперь компилиатор знает,
[02:12:45.360 --> 02:12:53.720]  что lifetime вложенной коррутины покрывается lifetime-ом нашей коррутины. Вот за счет того,
[02:12:53.720 --> 02:12:58.640]  что мы это явно написали своими руками в деструктуре. Явно вызвали destroy, не the read this,
[02:12:58.640 --> 02:13:05.480]  который для компилиатора плохо предсказуем, а вот прямо destroy нашими руками, нашими в смысле
[02:13:05.480 --> 02:13:10.800]  родительской коррутины. Понимаете, о чем я? То есть, есть цикл, в нем есть внутри аллокация state,
[02:13:11.680 --> 02:13:18.960]  а потом разрушение state. И компилиатор понимает, что на самом деле lifetime вложены, и поэтому за счет
[02:13:18.960 --> 02:13:27.760]  этого он inline state дочерней коррутины в родительскую коррутину. И в итоге у вас как бы есть цепочка
[02:13:27.760 --> 02:13:39.600]  вызовов. Ну, вот такая тут цепочка из одного вызова, а может быть вот такая вот. И компилиатор,
[02:13:40.240 --> 02:13:47.400]  если в коде с тасками, знает, что все эти вызовы образуют иерархию вложенной друг друга, и поэтому не
[02:13:47.400 --> 02:13:55.480]  нужно алоцировать state для коррутины каждый раз новый. Нужно просто zinline-ить все в один. И в итоге
[02:13:55.480 --> 02:14:04.440]  у нас получается такой большой коррутин state для родительской коррутины, в которой вложены,
[02:14:04.440 --> 02:14:11.000]  по сути, стейты всех дочерних коррутин. Ну и там еще компилиатор, это может как-то пооптимизировать.
[02:14:11.000 --> 02:14:22.520]  Он понимает, потому что мы пишем не future, а мы пишем task, а в task есть destroy, и этот destroy
[02:14:22.520 --> 02:14:36.520]  появляется как бы в скопе родительской функции. Ну, видимо, компилиаторы понимают,
[02:14:36.520 --> 02:14:45.000]  что mkRouting все-таки инициализирована, потому что если она не инициализирована,
[02:14:45.160 --> 02:14:53.880]  в общем, компилиатору будет ясно, что в mkRouting что-то есть. Вот за счет того, что компилиатор знает,
[02:14:53.880 --> 02:15:03.120]  что lifetime вложены, потому что мы воспользовались вот этим final suspend, то он может применить вот
[02:15:03.120 --> 02:15:09.920]  эту иуристику с вкладыванием стейтов и избежать динамических локаций. И в итоге в этом синхронном
[02:15:09.920 --> 02:15:19.800]  коде, написанном на тасках, в этом коде написанном на тасках динамических локаций не будет вообще.
[02:15:19.800 --> 02:15:30.520]  Вот, и это хорошо. Ну а если они нужны, если мы все-таки синхронный код пишем, то там локации
[02:15:30.520 --> 02:15:36.000]  уже будут, потому что lifetime уже не будут вложены друг в друга. Ну, например, не будут вложены.
[02:15:36.000 --> 02:15:45.720]  Вот. С другой стороны, есть некоторая проблема, что решение о том, алоцировать ли динамический
[02:15:45.720 --> 02:15:51.280]  память или нет, то есть где размещать коротин стейт на стеке текущего вызова или динамической
[02:15:51.280 --> 02:15:58.680]  памяти, решает сам компилиатор. И мы, разработчики, этим не управляем. А мы в C++ к такому не привыкли.
[02:15:58.680 --> 02:16:05.760]  Мы привыкли, что мы всем управляем. Где байтики скопируются, где память алоцируется, где сторож каждого
[02:16:05.760 --> 02:16:12.040]  объекта. Вот для крутины мы такую возможность теряем, и это одна из причин, почему этот дизайн
[02:16:12.040 --> 02:16:18.680]  критикуют. Потому что мы доверяем оптимизации компилиатора, мы не можем управлять этим сами. Ну,
[02:16:18.680 --> 02:16:25.640]  вообще говоря, это проблема в хорошем дизайне. Здесь вот он такой. То есть, возможно, я вам только
[02:16:25.640 --> 02:16:32.600]  что объяснял какие-то кастыри полчаса. Ну, так тоже на это можно смотреть в каком-то смысле. Вот.
[02:16:32.600 --> 02:16:36.920]  Но, тем не менее, в C++ у нас вот такая вот механика. Вот есть эти промесы, есть вот эти таски,
[02:16:36.920 --> 02:16:43.280]  которые к крутиным должны обязательно быть, и с помощью них можно крутины комбинировать.
[02:16:43.280 --> 02:16:51.400]  Ну, runtime нужен, вот вся эта история. Может быть, последнее замечание такое лирическое отступление
[02:16:51.400 --> 02:16:59.840]  совсем про другое, чтобы вы почувствовали связь. На лекции про future мы делали future, и мы их
[02:16:59.840 --> 02:17:06.520]  связывали в цепочке с помощью зэнов. А еще мы говорили, что вот есть обработка ошибок, есть
[02:17:06.520 --> 02:17:15.400]  result, или есть там expected C++, каким он будет. И для него, в общем, тоже нужно... секунду...
[02:17:15.400 --> 02:17:27.640]  Мне нужен expected. А у меня нет expected, да? С другой стороны, есть обработка ошибок.
[02:17:27.640 --> 02:17:36.520]  И expected или result и future, они друг на друга похожи. Потому что есть операция связывания,
[02:17:36.520 --> 02:17:45.080]  есть контейнер для значения, resultT или futureT, и есть функция, которая ожидает распакованного
[02:17:45.080 --> 02:17:53.840]  значения. Просто T на входе. И в случае с future мы используем комбинатор Zen специальный. В случае
[02:17:53.840 --> 02:18:05.120]  с result мы проверяем, что в result, в expected здесь нет ошибки, и вот передаем распакованные значения.
[02:18:05.120 --> 02:18:11.920]  Ну, так или иначе, возникает такая логика связывания. И вот для result ее тоже можно переписать
[02:18:11.920 --> 02:18:18.600]  в таком вот виде, с помощью опять зэнов. Ну, map and zen, там есть некоторая тонкая разница. Давайте
[02:18:18.600 --> 02:18:25.920]  сейчас не будем подробностей. Важно, что вот и result и future — это представители вот одного
[02:18:25.920 --> 02:18:32.880]  некоторого такого класса, общего класса монады, который описывает контейнер, ну и определенные
[02:18:32.880 --> 02:18:40.640]  правила связывания. А теперь вспомним следующее, что... Ну, я когда говорил про то, где монады
[02:18:40.640 --> 02:18:47.040]  появились, говорил про то, что они появились... У меня их аскера здесь нет, что ли? Не может быть.
[02:18:47.040 --> 02:19:08.880]  Кто готовил эту реакцию? Ну, допустим, что-нибудь найдется хорошее, да? Ну, что-то мне хотелось бы
[02:19:08.880 --> 02:19:20.320]  более оформленное. Да, для монад в хаскере есть удобный синтактический сахар до нотации,
[02:19:20.320 --> 02:19:28.480]  где вот делаются такие как будто бы императивные шаги последовательные, а на самом деле есть
[02:19:28.480 --> 02:19:36.920]  функциональная композиция, которая просто скрыта от пользователя. Вот, то есть есть удобный синтаксис
[02:19:36.920 --> 02:19:46.640]  общий для произвольных монад, то есть для типов, которые там реализуют некоторый контракт. Так вот,
[02:19:46.640 --> 02:19:57.680]  смотрите, future — это монада, и result — это монада, и есть некоторый синтаксис у нас, который позволяет,
[02:19:57.680 --> 02:20:05.720]  скажем, подождать future. И я говорю, что этот синтаксис коэвейт, он реализован на уровне, ну вот
[02:20:05.880 --> 02:20:13.880]  коэвейт — это языковая фича, которая от конкретной семантики избавлена, то есть просто овейтерам задается
[02:20:13.880 --> 02:20:23.280]  поведение корутины в точке коэвейта. Ну, видимо, можно через коэвейт, в коэвейте поддержать не
[02:20:23.280 --> 02:20:29.160]  только какие-то примитивы для асинхронности, а еще и вот тот же самый result или тот же самый
[02:20:29.160 --> 02:20:39.360]  expected и писать код. Ну, это у меня точно есть. Вот так вот. Смотрите, у нас есть функция f1,
[02:20:39.360 --> 02:20:50.000]  она возвращает значение int или ошибку. Есть функция f2, которая ожидает просто int. И вот нам
[02:20:50.000 --> 02:20:58.480]  нужно их связать. Что здесь происходит? f1 возвращает expected. А что делает коэвейт? Он либо
[02:20:58.480 --> 02:21:05.840]  распаковывает expected в int, либо просто корутину останавливает, завершает ее. И здесь уже мы
[02:21:05.840 --> 02:21:12.600]  вызываем f2 от x, где x — это int. Получаем expected, распаковываем его с помощью коэвейта. Короче,
[02:21:12.680 --> 02:21:20.840]  коэвейт — он называется коэвейт, но ko потому что обратная совместимость, все такое, а вейт
[02:21:20.840 --> 02:21:27.640]  потому что как будто бы чего-то ждем. Это, понятно, про асинхронность, мы чего-то ждем. Но на самом деле
[02:21:27.640 --> 02:21:33.000]  коэвейт абсолютно свободен от такой семантики ожидания, и можно вложить в нее другое поведение
[02:21:33.000 --> 02:21:39.680]  и реализовать вот такую поддержку для обработки ошибок, чтобы не писать вот эти if. То есть вместо
[02:21:39.760 --> 02:21:52.080]  вот этого кода и вместо этого кода можно писать еще и вот такой код. Так они спрятаны в этом и
[02:21:52.080 --> 02:22:04.880]  смысл. Их здесь, в этом коде ошибок нет. В этом коде нет expected. То есть expected появляется после
[02:22:04.880 --> 02:22:14.120]  вызова из функции f1, и он разворачивается с помощью коэвейта в просто значение типа x. Здесь интересно,
[02:22:14.120 --> 02:22:21.280]  что вот этот коэвейт — это вот механизм для манипуляции потоком управления. Мы в коэвейте для
[02:22:21.280 --> 02:22:27.360]  фьючей останавливали корутину и потом возобновляли ее где-то в каком-то пуле потоков. Здесь мы
[02:22:27.360 --> 02:22:33.360]  останавливаем корутину, либо сразу же ее продолжаем. То есть коэвейт на expected, где в котором
[02:22:33.360 --> 02:22:40.800]  содержится значение, просто в await ready говорит true. А в await suspend, видимо, корутину нужно просто
[02:22:40.800 --> 02:22:49.640]  разрушить. Потому что все, вот мы вышли из корутины. Ошибка. Вот, так что механизм на самом деле более
[02:22:49.640 --> 02:22:57.600]  общий. Нужно видеть, что вот если вы видите монады, если вы видите синтез, из которой похож на донотацию,
[02:22:57.600 --> 02:23:06.360]  видимо, можно это все в голове совместить и поддержать. Обобщить коэвейт на... и произвольные монады
[02:23:06.360 --> 02:23:18.240]  тоже на result можно обобщить. На result, на expect. Ну что ж, пожалуй, на этом все. Спасибо вам.
[02:23:18.240 --> 02:23:27.920]  Ну можно на вопросы задавать еще, если они у вас есть, конечно.
[02:23:27.920 --> 02:23:39.320]  Ну что ты делаешь, когда ты увидишь ошибку в функции? Ты из нее выходишь, покидаешь эту функцию. Она проклята. Ну вот.
[02:23:48.240 --> 02:24:04.800]  Ну я не знаю. Ты пишешь ассинхронный эхо-сервер. Там есть async-write. А async-write может в цикле звать
[02:24:04.800 --> 02:24:09.760]  async-write-sum. Ну потому что не бывает write в сокет неограниченного размера. Может быть write
[02:24:09.760 --> 02:24:19.000]  какой-то частичный. Ну вот, например. Ну это не значит, что это лучшая реализация, но это вот какая-то реализация.
[02:24:19.000 --> 02:24:27.640]  Ну или просто у тебя функция, которая там обращается к пяти подряд микросервисом. К первому,
[02:24:27.640 --> 02:24:31.960]  ко второму, к третьему. Ты любишь микросервисы. А потом ты вот пишешь еще какую-то логику сверху,
[02:24:31.960 --> 02:24:38.080]  но в общем, все это. Можно декомпозировать и выделять функции. Поэтому такая задача возникает.
[02:24:38.080 --> 02:24:45.120]  Задача, в смысле, вызывать синхронные функции. Ну и там появляется таск, и вот вся эта история.
[02:24:45.120 --> 02:24:57.320]  Проблема какая?
[02:25:08.080 --> 02:25:21.840]  Ну почему он не нужен? Ну какая разница? У нас ошибка, то есть optional или expect. Проблема тут
[02:25:21.840 --> 02:25:30.440]  скорее в другом. Она в том, что очень сложно в одном коде жить. Смотрите, у нас есть future,
[02:25:30.520 --> 02:25:39.520]  в чем подвох. У нас есть future, мы дожидаемся ее, распаковываем ваш табл result. А теперь нужно
[02:25:39.520 --> 02:25:48.280]  распаковывать result. Что сделано в Rust? В Rust нет универсального такого монодического синтаксиса,
[02:25:48.280 --> 02:26:11.480]  там есть для... ну ладно, опять я проиграл. В Rust есть оператор вопросик. Сейчас мы его найдем.
[02:26:11.480 --> 02:26:19.920]  Вот, мы открываем файл, и Бог знает, чем это может завершиться. Файла может не быть,
[02:26:19.920 --> 02:26:26.080]  файл может быть на сетевом устройстве, у нас сейчас нет интернета, но ошибка может возникнуть,
[02:26:26.080 --> 02:26:32.680]  поэтому нам возвращает result. Если ошибка возникла, то мы, может быть, не хотим продолжать эту
[02:26:32.680 --> 02:26:39.160]  функцию, мы хотим вернуть ее наверх. Но мы не хотим писать return голыми руками, поэтому нам нужна
[02:26:39.160 --> 02:26:46.560]  некоторая поддержка, то есть поддержка вот такого control flow. Ну вот C++ мы бы написали уродливый
[02:26:46.560 --> 02:26:52.560]  макрос, оборачивающий весь этот вызов, и это совершенно непригодно для жизни. Вот в Rust
[02:26:52.560 --> 02:26:57.640]  сделали специальный оператор вопрос, который, получая result, распаковывает его в том смысле,
[02:26:57.640 --> 02:27:04.600]  что если в result была ошибка, то мы пробрасываем ее на уровень вверх, выходим из текущей функции.
[02:27:04.600 --> 02:27:17.120]  А для future там есть await, и он очень любопытный, есть ли здесь await, кстати. Ну что ж.
[02:27:30.680 --> 02:27:32.440]  Ну я хочу более интересный пример.
[02:27:32.440 --> 02:27:38.960]  Я хочу await со знаком вопроса.
[02:27:38.960 --> 02:27:51.560]  Я не сомневаюсь.
[02:27:51.560 --> 02:28:06.640]  Ладно. Смотрите, что... Ну я попытаюсь сейчас найти еще. Смотрите, что интересно. Await — это
[02:28:06.640 --> 02:28:11.200]  ключевое слово, да? Ну то есть с помощью него, с помощью такого синтактического маркера компилятор
[02:28:11.200 --> 02:28:15.160]  понимает, что перед ним не просто функция, а какая-то особенная функция, асинхронная,
[02:28:15.160 --> 02:28:20.760]  которая умеет останавливаться и нужно ее переписать в автомат. И в большинстве языков,
[02:28:20.920 --> 02:28:26.640]  которые поддерживают вот такую асинхронность из теклос корутины — это ключевое слово await,
[02:28:26.640 --> 02:28:31.120]  и оно ставится перед выражением C++, оно еще изуродовано вот этим ко, но бог с ним.
[02:28:31.120 --> 02:28:37.040]  Суть не меняется. В расти поступили очень интересно, там ключевое слово await с точки
[02:28:37.040 --> 02:28:42.720]  начинается и постфиксное. Это, кажется, первый такой мейнстрим язык, который взял и сделал себе
[02:28:42.720 --> 02:28:48.320]  ключевое слово, начиная с точки и постфиксное, похожее на вызов метода. Там очень долго на это
[02:28:48.320 --> 02:28:54.560]  решались, там полгода думали, обсуждали, писали просто обсуждения на форумах, но в конце концов
[02:28:54.560 --> 02:29:01.520]  решились. И почему? Потому что у них была проблема, что, ну вот смотрите, у нас есть await,
[02:29:01.520 --> 02:29:08.200]  который распаковывает future, а есть вопросик, который распаковывает result, а future распаковывается
[02:29:08.200 --> 02:29:14.040]  в result обычно. И как написать асинхронную функцию, которая распаковывает сначала future, а потом result?
[02:29:14.040 --> 02:29:22.080]  Вот писать await, потом скобочки, потом вопросик — это совершенно мучительно. Вот поэтому они
[02:29:22.080 --> 02:29:28.800]  решили сделать постфиксный вызов, чтобы это все хорошо чейнилось. Это совершенно блестящая идея,
[02:29:28.800 --> 02:29:34.200]  абсолютно безумная на первый взгляд, ну в смысле делать такое ключевое слово. Но вот они решили,
[02:29:34.200 --> 02:29:40.800]  что у языка любого есть такой бюджет на странности, его тратить очень нужно осторожно, чтобы люди не
[02:29:40.800 --> 02:29:45.600]  отпугнуть от своего языка. Но вот в этом месте нужно его потратить, потому что это самое лучшее
[02:29:45.600 --> 02:29:51.520]  решение. Довольно смелый дизайн, но вот он в итоге реализовался. Я вот хотел найти await с вопросиком,
[02:29:51.520 --> 02:30:00.120]  но почему-то мне примеры не показывают. Вот, то есть один универсальный синтаксис, возможно,
[02:30:00.120 --> 02:30:04.560]  это не самая лучшая идея, то есть она не решает всех проблем. Это скорее, ну вот это скорее,
[02:30:04.560 --> 02:30:12.360]  конечно, баловство, чем... Нет, expect — это не баловство, это очень серьезно. Вот это скорее
[02:30:12.360 --> 02:30:20.840]  баловство. Но если это баловство так серьезно обдумать, то можно получить другой немного синтаксис,
[02:30:20.840 --> 02:30:26.640]  но при этом смысл будет тот же самый. Мы вот реализуем такую специальную нотацию,
[02:30:26.640 --> 02:30:38.840]  которая распаковывает контейнеры, которые делают связывания вот для мэн. Еще, может быть, вопрос?
[02:30:38.840 --> 02:30:52.160]  Мы про... Я не знаю, может быть, задачку сделаем про него, а может быть, может быть, нет. Ну,
[02:30:52.240 --> 02:31:00.920]  в C++ много всего интересного. Мы все-таки фокусируемся на ассинхронных применениях.
[02:31:00.920 --> 02:31:08.120]  — А койоут? — Ну койоут — это ж про генераторы история.
[02:31:08.120 --> 02:31:19.640]  Ну, питон тут ни при чем. Питон — это всего лишь язык, в котором есть стеклоскрутина. То есть,
[02:31:19.640 --> 02:31:23.240]  в смысле он здесь ничем не отличается. Можно сказать, что питон в C++ можно говорить теперь.
[02:31:23.240 --> 02:31:29.560]  Вот. Ну, это иронично, конечно. То есть, не то чтобы вот как в питоне. Питон — это просто
[02:31:29.560 --> 02:31:33.280]  иллюстрация вот одного общего подхода — стеклосподхода до корутина.
[02:31:33.280 --> 02:31:45.440]  Ну что, если вопросы закончились, то можно я последнее покажу вам, если сейчас найду быстро.
[02:31:45.440 --> 02:32:11.080]  Документация буста. Ну ладно, сойдет. Вдруг мне… Короче, ну такой спойлер. Я надеюсь,
[02:32:11.080 --> 02:32:15.320]  что про это сделаю задачку, не обещаю, но очень постараюсь. Это скорее в мае случится,
[02:32:15.320 --> 02:32:25.000]  когда уже можно баллостом заниматься. Можно написать на C++ стеклоскрутина на макросах. Ну,
[02:32:25.000 --> 02:32:30.120]  как бы, стеклоскрутина — это же преобразование вот… Ну кодогенерация, по сути, мы берем вот одно
[02:32:30.120 --> 02:32:34.800]  описание, встроим другое описание. Как делается кодогенерация на C++? Макросы. Для этого макросы
[02:32:34.800 --> 02:32:40.560]  и нужны C++, чтобы код писать автоматически. Ну вот, можно написать такие хитрые макросы,
[02:32:40.560 --> 02:32:49.120]  чтобы код был… выглядел бы как вот корутиный, написать там свои авейты, и в итоге получится
[02:32:49.120 --> 02:32:57.120]  корутина. И кажется, что ASIO то ли поддерживал, то ли поддерживает вот такой API на вот этих своих
[02:32:57.120 --> 02:33:02.480]  макросных корутинах для библиотеки. Я не думаю, что им сейчас это нужно, потому что зачем уже есть
[02:33:02.480 --> 02:33:13.520]  плюсовые корутины, нужно использовать их. Ну… Нет, по-моему, это… Ну ладно, я не буду врать. Ну в
[02:33:13.520 --> 02:33:19.960]  общем, так можно, и можно ради любопытств попробовать переписать это все своими руками. Там очень
[02:33:19.960 --> 02:33:30.400]  любопытные вещи возникают. Как можно… Это даже не макрос, это макрос, это давдевайс. Там расширяет
[02:33:30.400 --> 02:33:35.640]  сознание, если можно так сказать. Ну в общем, если получится, мы это попробуем сделать. А так вот,
[02:33:35.640 --> 02:33:42.160]  по плану, я думаю, что совсем скоро, в ближайшие дни даже, я выложу задачу про то, чтобы сделать вот…
[02:33:42.160 --> 02:33:57.160]  Потерялся. Вот такие корутины, у которых есть… Ну, «гор-рутина», в смысле, корутины имени Гора
[02:33:57.160 --> 02:34:02.720]  Нишанова, в которых есть мютексы, в которых есть вейт-группы, которые умеют работать с нашим
[02:34:02.720 --> 02:34:11.880]  пулом потоков, с нашим, ну в смысле, нашим плохим и вашим будущим хорошим. Вот, с произвольными
[02:34:11.880 --> 02:34:17.040]  экзекьюторами. И к ним мы отдельной задачкой напишем класс-таск, а потом все это можно вместе
[02:34:17.040 --> 02:34:21.720]  собрать, и потом вместе можно создать вообще большую библиотеку, где будет все, и все будет
[02:34:21.720 --> 02:34:27.600]  друг с другом сочетаться. Так что, пожалуйста, попробуйте это сделать. У нас осталось не очень
[02:34:27.600 --> 02:34:33.240]  много времени, к сожалению, но вот то, что можно сделать, можно сделать еще очень много и очень
[02:34:33.240 --> 02:34:38.840]  сложно, поэтому вот, не знаю, выберите, что вам по вкусу. Я все еще рекомендую делать планировщик
[02:34:38.840 --> 02:34:42.600]  прямо сейчас, потому что, ну, это же огромная радость пооптимизировать вот весь этот код,
[02:34:42.600 --> 02:34:47.120]  который мы пишем сейчас. Все наши файбер. Все, закругляемся.
