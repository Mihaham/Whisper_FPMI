[00:00.000 --> 00:15.160]  Я его даже не знаю, хотелось бы сказать, что это ободряюще,
[00:15.160 --> 00:18.880]  представляя сегодняшние политические события.
[00:18.880 --> 00:23.800]  Не могу сказать много, надеюсь, что все из вас доучатся,
[00:23.800 --> 00:27.520]  по крайней мере, буквовряд, никого по крайней мере вашу
[00:27.520 --> 00:28.720]  личную жизнь это не затронет.
[00:28.720 --> 00:30.600]  Очень сильно это, надеюсь.
[00:30.600 --> 00:33.880]  Вот, а пока давайте делать вид, что все нормально.
[00:50.880 --> 00:56.040]  Итак, насколько я знаю, вам на плюсах рассказывали про он-ордер рецепт,
[00:56.040 --> 01:00.720]  и нам надо понять, что лежит там внутри, поэтому давайте вот сегодняшний лекции
[01:00.720 --> 01:05.200]  так будет не очень вписываться в общую канву, но сегодня про хэштаблицу поговорим.
[01:05.200 --> 01:21.680]  Итак, представьте, ну давайте вспомним нашу задачу, когда мы про дерево поиска
[01:21.680 --> 01:26.120]  как разговаривали, есть у нас какие-то ключи, и мы хотим уметь делать три самые
[01:26.120 --> 01:27.120]  главные операции.
[01:27.120 --> 01:32.520]  Давайте напомним, что это были деревья поиска у нас.
[01:32.520 --> 01:37.920]  Там был insert, erase и find.
[01:37.920 --> 01:43.640]  Ну find, то есть проверить, лежит ли элемент в множестве в текущем.
[01:43.640 --> 01:46.240]  Считаем, что дубликатов нет, то есть если какой-то элемент
[01:46.240 --> 01:48.000]  вставляется два раза, то он, на самом деле, множество
[01:48.000 --> 01:50.080]  только один раз, то есть не мульти множество, а обычное
[01:50.080 --> 01:51.080]  множество.
[01:51.520 --> 01:53.720]  Чтобы дубликатов не было.
[01:53.720 --> 01:56.920]  Мы решали это всякими там декартовыми деревьями, сплей деревьями
[01:56.920 --> 01:57.920]  и так далее.
[01:57.920 --> 02:01.400]  У нас там получалось, что все запросы отвечаются, обрабатываются
[02:01.400 --> 02:02.400]  за алгорифм.
[02:02.400 --> 02:04.560]  Там либо амортизированный, либо вероятностный, либо
[02:04.560 --> 02:07.160]  чистый, как в красно-черном AVL.
[02:07.160 --> 02:10.880]  А сегодня мы будем решать ту же самую задачу с помощью
[02:10.880 --> 02:15.960]  хэштаблиц с целью улучшить еще время работ, время работ
[02:15.960 --> 02:18.840]  у нас будет от единицы.
[02:18.840 --> 02:24.280]  Время обработки всех этих запросов будет от единицы
[02:24.280 --> 02:26.080]  в хэштаблице.
[02:26.080 --> 02:32.920]  Но это от единицы будет, во-первых, вероятностная,
[02:32.920 --> 02:33.920]  во-вторых, амортизированная.
[02:33.920 --> 02:36.320]  То есть, во-первых, здесь будет звездочка в том же понимании,
[02:36.320 --> 02:38.680]  в котором была в прошлом семестре, амортизированный
[02:38.680 --> 02:39.680]  анализ.
[02:39.680 --> 02:41.200]  То есть каждая конкретная операция может работать
[02:41.200 --> 02:44.560]  долго, но в среднем они работают суммарно за линейное время.
[02:44.560 --> 02:47.120]  Если каждый за единицу, то суммарно все за линейное
[02:47.120 --> 02:48.120]  время.
[02:48.120 --> 02:51.520]  А вероятность в том смысле, что только мотождание
[02:51.520 --> 02:55.160]  времени работы будет таким, то есть мотождание времени
[02:55.160 --> 02:58.240]  работы с учетом делений на все количество операций
[02:58.240 --> 02:59.240]  будет единицами на операцию.
[02:59.240 --> 03:05.000]  Здесь совмещение и амортизационного анализа из сплей дерева
[03:05.000 --> 03:07.680]  и вероятностный подход из декартового дерева, то
[03:07.680 --> 03:11.280]  есть только мотождание времени работы будет таким.
[03:11.280 --> 03:14.640]  Но бывают случаи, когда какие-то операции вываливаются
[03:14.640 --> 03:17.440]  из этих границ, из золотой единицы, работают подольше.
[03:17.440 --> 03:19.960]  Но тем не менее.
[03:19.960 --> 03:21.760]  Тут есть два основных подхода.
[03:21.760 --> 03:36.440]  Это хэширование таблицы цепочками и с открытой адресацией.
[03:36.440 --> 03:55.760]  Мы начнем с цепочек.
[03:55.760 --> 03:56.760]  Идея такая.
[03:56.760 --> 03:57.760]  Вот смотрите.
[03:57.760 --> 03:59.520]  Пусть все наши ключи – это элементы какого-то универсума
[03:59.520 --> 04:00.520]  U.
[04:01.520 --> 04:09.440]  Все ключи принадлежат U.
[04:09.440 --> 04:11.120]  То есть те элементы, которые вы вставляете и удаляете
[04:11.120 --> 04:14.320]  в ваше множество – это обязательно элементы U.
[04:14.320 --> 04:18.520]  Тогда давайте попытаемся как-нибудь закодировать
[04:18.520 --> 04:23.680]  все элементы U числами от 0 до M-1.
[04:23.680 --> 04:25.000]  Давайте я прям множество напишу.
[04:25.000 --> 04:27.760]  0, 1 и так далее.
[04:27.760 --> 04:28.760]  M-1.
[04:28.840 --> 04:29.840]  Мы придумаем какую-нибудь функцию.
[04:29.840 --> 04:33.320]  Назовем ее H от слова хэш-функция.
[04:33.320 --> 04:38.120]  А на каждому ключу из U ставится соответствие какое-то
[04:38.120 --> 04:41.520]  маленькое натуральное число от 0 до M-1.
[04:41.520 --> 04:44.960]  Ну M небольшое, грубо говоря, 10 в пятую, давайте я напишу
[04:44.960 --> 04:48.000]  там 10 в шестой примерно, а U может быть большим.
[04:48.000 --> 04:53.360]  Например, U – это все, что помещается в тип int, до 2
[04:53.360 --> 04:56.360]  в 32 примерно.
[04:57.040 --> 05:01.160]  То есть мы всем ключам, всем вот этим товарищам
[05:01.160 --> 05:03.120]  назначаем какое-нибудь маленькое число.
[05:03.120 --> 05:05.000]  Понятно, что тогда будет коллизия, в том смысле, что
[05:05.000 --> 05:07.840]  разным ключам может соответствовать одно и то же хэш-значение.
[05:07.840 --> 05:10.640]  H от X может быть равно H от Y, понятно дело, это не может
[05:10.640 --> 05:13.040]  быть инъекцией, поскольку размеры этого множества
[05:13.040 --> 05:14.760]  сильно меньше размера вот этого множества.
[05:14.760 --> 05:17.160]  Значит, будет много таких коллизий, когда две стрелочки
[05:17.160 --> 05:18.920]  ведут в один и тот же элемент.
[05:18.920 --> 05:21.720]  Но тем не менее, мы вот так будем считать, что чтобы
[05:21.720 --> 05:24.080]  хранить какое-то множество U, чтобы хранить какое-то
[05:24.080 --> 05:26.080]  множество ключей в нашей структуре, мы давайте
[05:26.080 --> 05:28.640]  вместо них будем хранить хэши просто.
[05:28.640 --> 05:32.000]  Просто вместо элементов U мы будем хранить их хэш-значение.
[05:32.000 --> 05:34.080]  И тогда, поскольку у меня здесь элементов мало, мы
[05:34.080 --> 05:36.480]  можем просто завести массив длины 10 в шестой, вот этой
[05:36.480 --> 05:40.400]  вот M, такой большой массивчик длины M.
[05:40.400 --> 05:43.440]  И здесь для каждого хэша будем хранить, есть ключ
[05:43.440 --> 05:47.440]  с таким хэшом или нет, есть ли ключ с таким хэш-значением.
[05:47.440 --> 05:57.080]  Более формально, у нас будет массив длины M, это и будет
[05:57.080 --> 05:58.080]  наша хэш-таблица.
[05:58.080 --> 06:06.120]  И эта ячейка этого массива будет представлять собой
[06:06.120 --> 06:08.640]  односвязанный список тех элементов, в которых хэш
[06:08.640 --> 06:09.640]  равен И.
[06:10.640 --> 06:33.640]  И это элемент массива, односвязанный список ключей с хэшем равным
[06:33.640 --> 06:34.640]  И.
[06:34.640 --> 06:39.440]  То есть если нас тогда просят какой-то элемент вставить,
[06:40.440 --> 06:45.440]  то мы сначала от него считаем хэш, h от x, значит мы понимаем
[06:45.440 --> 06:48.440]  в какую ячейку за этих вот M этот ключ принадлежит,
[06:48.440 --> 06:49.440]  в какую ячейку он принадлежит.
[06:49.440 --> 06:52.440]  Дальше смотрим, то есть мы посчитали h от x, здесь какой-то
[06:52.440 --> 06:53.440]  односвязанный список.
[06:53.440 --> 06:55.440]  Ну, односвязанный список, я такого не говорил раньше,
[06:55.440 --> 06:58.440]  но это вот то, как мы реализовывали стэк.
[06:58.440 --> 07:01.440]  У меня есть какая-то структурка, у которой есть хранящееся
[07:01.440 --> 07:03.440]  значение и ссылка на следующее значение.
[07:03.440 --> 07:06.440]  То есть вот есть там какая-то голова нашего списка и указательно
[07:06.440 --> 07:07.440]  на следующую вершинку.
[07:07.440 --> 07:09.440]  Здесь тоже эта вершина, у нее есть значение и указательно
[07:09.440 --> 07:10.440]  на следующую.
[07:10.440 --> 07:11.440]  Значение и указательно на следующую.
[07:11.440 --> 07:14.440]  И у последней вершины указателей будет там в науптр, ну куда-то
[07:14.440 --> 07:16.440]  в пустоту, означает, что это последний элемент нашего
[07:16.440 --> 07:17.440]  списка.
[07:17.440 --> 07:19.440]  В общем, так как мы реализовывали стэк, мы, собственно, можно
[07:19.440 --> 07:22.440]  даже говорить, что мы тут просто стэк храним, а не односвязанный
[07:22.440 --> 07:25.440]  список, но только с доступом там вот.
[07:25.440 --> 07:27.440]  Стэк, у которого есть еще возможность пройти все
[07:27.440 --> 07:28.440]  элементы.
[07:30.440 --> 07:33.440]  Ну вот, и тогда, чтобы вставить элемент, мне нужно куда-нибудь
[07:33.440 --> 07:35.440]  в этот список добавить новый х.
[07:35.440 --> 07:39.440]  Здесь вообще лежат все ключи с хэшом равным h от х, и
[07:39.440 --> 07:41.440]  чтобы добавить сюда х, мне нужно куда-то сюда в этот
[07:41.440 --> 07:43.440]  список этот х новый вставить.
[07:43.440 --> 07:45.440]  Чтобы там, скажем, удалить ключ, мне нужно пройтись по
[07:45.440 --> 07:47.440]  вот этой цепочке, найти, где в этой цепочке лежит тот
[07:47.440 --> 07:51.440]  самый ключ, который надо удалить, и сделать удаление
[07:51.440 --> 07:53.440]  элемента из списка.
[07:53.440 --> 07:55.440]  Например, если надо удалить вот этот, вот этот какой-нибудь
[07:55.440 --> 07:56.440]  y надо удалить.
[07:56.440 --> 07:59.440]  То есть если h от х равно h от y, они лежат в одном вот этом
[07:59.440 --> 08:02.440]  вот списке, мне нужно удалить y.
[08:02.440 --> 08:05.440]  Тогда я перехожусь по этому списку, нахожу y, удаляю
[08:05.440 --> 08:07.440]  его, ну и, соответственно, перенаправляю стрелки.
[08:07.440 --> 08:10.440]  Очень легко вот в этом списке удалить произволенный
[08:10.440 --> 08:12.440]  элемент, надо просто перенаправить там какую-то стрелочку.
[08:12.440 --> 08:13.440]  Вот это удаление.
[08:13.440 --> 08:15.440]  Ну и поиск, соответственно, нужно просто всю эту цепочку пройти.
[08:17.440 --> 08:20.440]  И, значит, наш дальнейший анализ, ну такой, мы не
[08:20.440 --> 08:23.440]  будем ничего доказывать, скорее всего, он покажет нам,
[08:23.440 --> 08:26.440]  что вот эти вот длинные цепочки, длины всех цепочек
[08:26.440 --> 08:29.440]  при должном выборе m и при должном выборе h, все длинные
[08:29.440 --> 08:31.440]  цепочек будут не очень большими.
[08:31.440 --> 08:32.440]  Вот.
[08:32.440 --> 08:34.440]  И это значит, что время работы, время ответа на все запросы
[08:34.440 --> 08:35.440]  будет маленьким.
[08:35.440 --> 08:38.440]  Значит, давайте теперь все это конкретизируем.
[08:38.440 --> 08:40.440]  Как работает у нас find?
[08:40.440 --> 08:44.440]  Find x, то есть проверить, есть ли элемент x в нашей х-таблице.
[08:44.440 --> 08:55.440]  Находим, давайте я напишу i равно h от x, проходим по
[08:55.440 --> 09:03.440]  итому списку, проходим по итому списку в поисках
[09:03.440 --> 09:04.440]  x.
[09:04.440 --> 09:08.440]  Ну потому что если x где-то и лежит в нашей х-таблице,
[09:08.440 --> 09:10.440]  то он обязательно будет в этом итом, итом списке.
[09:10.440 --> 09:13.440]  Если мы весь список прошли, его там не оказалось, то
[09:13.440 --> 09:15.440]  его вообще нету в нашей х-таблице.
[09:15.440 --> 09:17.440]  Иначе вот мы его нашли и локализовали в х-таблице.
[09:17.440 --> 09:19.440]  Окей?
[09:19.440 --> 09:27.440]  Insert x, insert x.
[09:27.440 --> 09:35.440]  Находим опять таких х-ж значения, h от x.
[09:35.440 --> 09:36.440]  Вот.
[09:36.440 --> 09:40.440]  И самое простое, это надо будет просто добавить x в
[09:40.440 --> 09:43.440]  начало списка, в начало вот этого вот списка.
[09:43.440 --> 09:45.440]  Ну при условии, что его там нет.
[09:45.440 --> 09:47.440]  То есть давайте проверим сначала.
[09:47.440 --> 09:53.440]  Проверим, что x нет в итом списке.
[09:53.440 --> 09:56.440]  Нет в итом списке.
[09:56.440 --> 10:01.440]  Потому что если он есть, то ничего вставлять не нужно.
[10:01.440 --> 10:02.440]  Вот.
[10:02.440 --> 10:05.440]  Иначе вставим его в начало нашего списка.
[10:05.440 --> 10:10.440]  Иначе вставим в начало.
[10:10.440 --> 10:14.440]  Ну здесь тоже очень просто реализуется.
[10:14.440 --> 10:16.440]  Есть у вас такой списочек, представьте, что здесь
[10:16.440 --> 10:17.440]  x нету.
[10:17.440 --> 10:19.440]  Там какой-нибудь z, a и b.
[10:19.440 --> 10:21.440]  А вам нужно новый элемент x сюда добавить.
[10:21.440 --> 10:24.440]  Тогда вы заводите новую ноду, ну как бы новую структурку,
[10:24.440 --> 10:25.440]  новый указатель.
[10:25.440 --> 10:27.440]  Пишете в нем значение x.
[10:27.440 --> 10:29.440]  И начинаете ссылаться вот этой штукой сюда.
[10:29.440 --> 10:32.440]  И при этом еще говорите, что теперь вот эта ячейка
[10:32.440 --> 10:34.440]  начинается не с этого элемента, а вот с этого.
[10:34.440 --> 10:38.440]  Ну то есть список ваш сдвигается на один элемент вверх,
[10:38.440 --> 10:40.440]  по сути.
[10:40.440 --> 10:42.440]  Так.
[10:50.440 --> 10:51.440]  Вот.
[10:51.440 --> 10:55.440]  Ну и race тоже просто здесь реализуется.
[10:55.440 --> 10:59.440]  Нужно просто посчитать х значение, пройтись по
[10:59.440 --> 11:03.440]  списку соответствующему и вытащить оттуда ненужную
[11:03.440 --> 11:05.440]  вершинку.
[11:10.440 --> 11:14.440]  Пройтись по этому списку в поисках x.
[11:16.440 --> 11:18.440]  Удалить его.
[11:20.440 --> 11:23.440]  Ну в том смысле, в котором я рисовал, что если вы
[11:23.440 --> 11:26.440]  нашли какой-то x, он на кого-то ссылается, и кто-то
[11:26.440 --> 11:29.440]  ссылается на него, тогда нужно x вырезать из картинки
[11:29.440 --> 11:33.440]  и перенаправить вот этот указатель сюда.
[11:33.440 --> 11:35.440]  Вот.
[11:35.440 --> 11:37.440]  Вот такая несложная реализация.
[11:37.440 --> 11:41.440]  Нам нужно просто M односвязанных списков поддерживать
[11:41.440 --> 11:43.440]  и все.
[11:43.440 --> 11:45.440]  Хорошо.
[11:51.440 --> 11:53.440]  Значит, что я хочу сказать?
[11:53.440 --> 11:55.440]  Что я хочу сказать?
[11:55.440 --> 11:57.440]  Что все сейчас у нас есть.
[11:57.440 --> 11:59.440]  Что все сейчас у нас есть.
[11:59.440 --> 12:01.440]  Что все сейчас у нас есть.
[12:01.440 --> 12:03.440]  Что все сейчас у нас есть.
[12:03.440 --> 12:06.440]  Что все сейчас у нас очень сильно зависит от этих
[12:06.440 --> 12:10.440]  двух параметров, от h и от m.
[12:10.440 --> 12:14.440]  Понятно, что функция h, в ней обязательно будут какие-то
[12:14.440 --> 12:16.440]  коллизии, как я сказал, потому что это множество
[12:16.440 --> 12:18.440]  сильно больше, чем то, поэтому многие элементы будут
[12:18.440 --> 12:19.440]  склеиваться.
[12:19.440 --> 12:21.440]  И понятно, нам хотелось бы, чтобы разным элементам
[12:21.440 --> 12:23.440]  соответствовали разные х-значения, потому что в
[12:23.440 --> 12:26.440]  идеале, если у всех ключей отсюда, или по крайней мере
[12:26.440 --> 12:29.440]  те, которые поступают к нам в запросы, разные х-значения,
[12:29.440 --> 12:31.440]  то у нас все списки имеют длину максимума единицы.
[12:31.440 --> 12:33.440]  И тогда вообще все работает за чистую единицу.
[12:33.440 --> 12:35.440]  Но, конечно, бывают коллизии.
[12:35.440 --> 12:37.440]  Какие-то цепочки могут быть достаточно длинными.
[12:37.440 --> 12:40.440]  Это как раз те ключи, у которых хэши совпали.
[12:40.440 --> 12:44.440]  Потому что каждая цепочка, это множество, по сути,
[12:44.440 --> 12:46.440]  множество ключей с одинаковым х-значением.
[12:46.440 --> 12:48.440]  Мы хотим, чтобы этого было не очень много.
[12:48.440 --> 12:50.440]  Ну и чего?
[12:50.440 --> 12:55.440]  Тогда надо h как-то поаккуратнее работать.
[12:55.440 --> 12:58.440]  Нужно говорить, какая у нас функция h.
[12:58.440 --> 13:00.440]  И понятно, что если h какая-то детерминированная,
[13:00.440 --> 13:03.440]  вот, не знаю, я там напишу, функция h такая функция.
[13:03.440 --> 13:06.440]  Не знаю, какая-нибудь функция кермана или еще чего-нибудь.
[13:06.440 --> 13:08.440]  Что-нибудь я тут написал.
[13:08.440 --> 13:12.440]  Тогда, если злоумышленник знает, как у вас устроена h,
[13:12.440 --> 13:15.440]  он может вам посылать такие запросы, что все вот эти товарищи
[13:15.440 --> 13:17.440]  выстраиваются в одну большую цепочку.
[13:17.440 --> 13:19.440]  Потому что у них у всех хэш-значения одинаковые.
[13:19.440 --> 13:23.440]  И тогда вы на все запросы отвечаете за линейное время.
[13:23.440 --> 13:26.440]  В общем, никакого выигрыша от хэш-таблицы у вас нет.
[13:27.440 --> 13:32.440]  Поэтому, чтобы такого не было, чтобы наш злоумышленник
[13:32.440 --> 13:34.440]  не смог нам ничего противопоставить,
[13:34.440 --> 13:37.440]  мы будем h убирать случайно.
[13:39.440 --> 13:41.440]  Общая идея.
[13:45.440 --> 13:49.440]  Функция h случайна.
[13:50.440 --> 13:54.440]  Ну, поскольку террорвера еще вроде как у нас не было,
[13:54.440 --> 13:57.440]  давайте я немножечко поясню, что имеется в виду.
[13:57.440 --> 13:59.440]  Имеется в виду следующее.
[13:59.440 --> 14:02.440]  Мы рассматриваем какое-то семейство функций h.
[14:02.440 --> 14:04.440]  Просто какое-то семейство функций.
[14:04.440 --> 14:07.440]  Семейство функций того же типа.
[14:07.440 --> 14:10.440]  Из u в маленькие натуральные числа.
[14:13.440 --> 14:16.440]  Вот есть у нас какое-то семейство функций.
[14:16.440 --> 14:18.440]  h1, h2 и так далее.
[14:19.440 --> 14:22.440]  И когда я говорю, что h случайная,
[14:22.440 --> 14:24.440]  я имею в виду следующее.
[14:24.440 --> 14:26.440]  Когда наш алгоритм начинает работу,
[14:26.440 --> 14:28.440]  когда мы делаем его какой-то запуск,
[14:28.440 --> 14:31.440]  он выбирает случайно и равновероятно
[14:31.440 --> 14:33.440]  одну из функций вот этого множества.
[14:33.440 --> 14:35.440]  То есть там вот есть, не знаю, 10 функций.
[14:35.440 --> 14:38.440]  Тогда он каждую из них возьмет с одной и той же вероятностью одна десятая.
[14:38.440 --> 14:40.440]  То есть вот бросает, не знаю, там многогранный кубик,
[14:40.440 --> 14:42.440]  у которого грани столько же, сколько вот этот h.
[14:42.440 --> 14:44.440]  Соответственно, все грани выпадают равновероятно.
[14:44.440 --> 14:47.440]  Соответственно, каждая функция выбирает с одной и той же вероятностью.
[14:47.440 --> 14:49.440]  И пишем, что алгоритм
[14:51.440 --> 14:52.440]  выбирает
[14:54.440 --> 14:55.440]  h
[14:57.440 --> 14:58.440]  случайно
[15:00.440 --> 15:02.440]  равновероятно
[15:04.440 --> 15:06.440]  из h. Из h красиво.
[15:08.440 --> 15:11.440]  И тогда, поскольку наш контрагент не знает,
[15:11.440 --> 15:13.440]  какую мы h выбираем,
[15:13.440 --> 15:16.440]  потому что мы ее выбрали и оппоненту не сообщаем,
[15:16.440 --> 15:17.440]  можно так сказать,
[15:17.440 --> 15:20.440]  тогда он не сможет никакую последовательность,
[15:20.440 --> 15:23.440]  то есть он не может предоставить гарантированную какую-то последовательность запросов,
[15:23.440 --> 15:25.440]  которая нас выродит,
[15:25.440 --> 15:27.440]  которая сделает очень длинную цепочку,
[15:27.440 --> 15:30.440]  потому что не знают, какая h, мы ее выбрали случайно, все хорошо.
[15:32.440 --> 15:34.440]  Ну и, значит, здесь
[15:34.440 --> 15:36.440]  есть какие-то результаты.
[15:39.440 --> 15:41.440]  Давайте я их все-таки сформулирую,
[15:41.440 --> 15:43.440]  чтобы понимать вообще, насколько важно,
[15:43.440 --> 15:45.440]  насколько важно, какой у нас h.
[15:45.440 --> 15:46.440]  Значит, определение.
[15:48.440 --> 15:50.440]  Семейство хэш-функций
[15:52.440 --> 15:53.440]  h
[15:54.440 --> 15:56.440]  называется универсальным,
[16:02.440 --> 16:03.440]  если
[16:05.440 --> 16:07.440]  для любых различных элементов
[16:08.440 --> 16:10.440]  для любых различных элементов
[16:10.440 --> 16:12.440]  нашего универсума
[16:14.440 --> 16:16.440]  вероятность того, что h от х
[16:16.440 --> 16:18.440]  равно h от у
[16:20.440 --> 16:22.440]  не больше одной m-той,
[16:23.440 --> 16:25.440]  не больше одной m-той.
[16:27.440 --> 16:29.440]  Значит, мы
[16:29.440 --> 16:32.440]  вольны фиксировать любые два различных ключа из у
[16:32.440 --> 16:34.440]  из универсума,
[16:34.440 --> 16:36.440]  и мы хотим, чтобы вероятность равенства
[16:36.440 --> 16:38.440]  вот этих вот хэш-взначений
[16:38.440 --> 16:40.440]  была не очень большим, не большим одной m-той.
[16:42.440 --> 16:44.440]  И здесь вероятность берется
[16:44.440 --> 16:46.440]  как раз таки по h.
[16:46.440 --> 16:48.440]  Давайте подпишем, что вероятность
[16:49.440 --> 16:51.440]  по случайной h,
[16:51.440 --> 16:53.440]  потому что все остальное у нас здесь диссерминировано.
[16:53.440 --> 16:55.440]  х и у мы фиксировали в самом начале,
[16:55.440 --> 16:58.440]  и случайность здесь вся исключительно по h.
[16:58.440 --> 17:00.440]  Вот такая странная
[17:01.440 --> 17:03.440]  конструкция, что
[17:03.440 --> 17:05.440]  у нас случайная функция,
[17:05.440 --> 17:07.440]  это не элементы как бы случайные,
[17:07.440 --> 17:09.440]  а вот сама функция,
[17:09.440 --> 17:11.440]  которая действует на эти элементы, случайная.
[17:11.440 --> 17:13.440]  Значит, более
[17:13.440 --> 17:15.440]  неформально, да, а что это значит
[17:15.440 --> 17:17.440]  с точки зрения нашей простой вероятности,
[17:17.440 --> 17:19.440]  вот этой равномерной?
[17:19.440 --> 17:21.440]  Это значит, что если мы посчитаем,
[17:21.440 --> 17:23.440]  для скольких функций из h красивого
[17:23.440 --> 17:25.440]  выполняется равенство,
[17:25.440 --> 17:27.440]  то их доля во всем h красивом
[17:27.440 --> 17:29.440]  не больше, чем вот такое.
[17:29.440 --> 17:31.440]  Давайте напишу, что значит эта штука,
[17:31.440 --> 17:33.440]  если вас смущает значок вероятности.
[17:33.440 --> 17:35.440]  Значит, значиство,
[17:35.440 --> 17:37.440]  ну, мощность множества тех h,
[17:37.440 --> 17:39.440]  что h от x равно h от y,
[17:41.440 --> 17:43.440]  не превосходит
[17:43.440 --> 17:45.440]  m этой доли
[17:45.440 --> 17:47.440]  всего множество h большое.
[17:49.440 --> 17:51.440]  Ну, это как раз то самое и значит,
[17:51.440 --> 17:53.440]  что если вы берете случайную функцию отсюда,
[17:53.440 --> 17:55.440]  то вот это событие происходит с маленькой вероятностью.
[17:55.440 --> 17:57.440]  То есть есть все функции h красивые,
[17:57.440 --> 17:59.440]  а есть плохие функции,
[17:59.440 --> 18:01.440]  на которых h от x равно h от y.
[18:01.440 --> 18:03.440]  И вот эта вот облачка
[18:03.440 --> 18:05.440]  занимает маленький объем по сравнению со всем
[18:05.440 --> 18:07.440]  пространственным функцией.
[18:07.440 --> 18:09.440]  Не больше, чем 1m
[18:09.440 --> 18:11.440]  от всего объема функций.
[18:11.440 --> 18:13.440]  Вот это универсальное семейство.
[18:27.440 --> 18:29.440]  Ну и тогда можно сравнивать
[18:29.440 --> 18:31.440]  пути арему.
[18:31.440 --> 18:33.440]  Если h
[18:35.440 --> 18:37.440]  это универсальное семейство
[18:37.440 --> 18:39.440]  хэш функций,
[18:39.440 --> 18:41.440]  так, мне не лень писать
[18:41.440 --> 18:43.440]  семейство хэш функций, вот так напишу,
[18:43.440 --> 18:45.440]  то
[18:47.440 --> 18:49.440]  математическое ожидание времени обработки
[18:49.440 --> 18:51.440]  всех запросов, инсерта, эрейза и файнда,
[18:55.440 --> 18:57.440]  математическое ожидание
[18:57.440 --> 18:59.440]  времени
[18:59.440 --> 19:01.440]  обработки
[19:03.440 --> 19:05.440]  всех запросов,
[19:09.440 --> 19:11.440]  есть
[19:11.440 --> 19:13.440]  O от 1
[19:13.440 --> 19:15.440]  плюс альфа,
[19:15.440 --> 19:17.440]  где альфа
[19:17.440 --> 19:19.440]  это m делить
[19:19.440 --> 19:21.440]  на мощность универсума,
[19:21.440 --> 19:23.440]  еще называется load factor,
[19:23.440 --> 19:25.440]  степень загруженности нашей
[19:25.440 --> 19:27.440]  таблицы,
[19:27.440 --> 19:29.440]  наш хэш таблица.
[19:31.440 --> 19:33.440]  То есть вот, да, мы знаем, что у нас всего,
[19:33.440 --> 19:35.440]  пардон, извините, не нау,
[19:35.440 --> 19:37.440]  виноват, глупо сказал, на n,
[19:39.440 --> 19:41.440]  где n это количество вставленных ключей.
[19:45.440 --> 19:47.440]  n
[19:47.440 --> 19:49.440]  количество
[19:49.440 --> 19:51.440]  вставленных
[19:51.440 --> 19:53.440]  ключей.
[19:53.440 --> 19:55.440]  Вот, то есть, смотрите, если у меня
[19:55.440 --> 19:57.440]  поступило n запросов инсерт,
[19:57.440 --> 19:59.440]  то понятно, что у меня суммарная длина
[19:59.440 --> 20:01.440]  вот этих моих цепочек, она n,
[20:01.440 --> 20:03.440]  да, потому что каждый ключ, ну, то есть,
[20:03.440 --> 20:05.440]  если не было дубликатов, то у меня n
[20:05.440 --> 20:07.440]  вершинок суммарно
[20:07.440 --> 20:09.440]  во всех односвязанных списках.
[20:09.440 --> 20:11.440]  Вот, если мы поделим
[20:11.440 --> 20:13.440]  m на n, то это как бы средняя загруженность
[20:13.440 --> 20:15.440]  одной ячейки.
[20:15.440 --> 20:17.440]  Ну, точнее, видимо, будет n на m, ну, вот, неважно,
[20:17.440 --> 20:19.440]  давайте такое обратно, обратно напишу.
[20:19.440 --> 20:21.440]  Вот.
[20:23.440 --> 20:25.440]  Понятно, что если, если вот эта штука
[20:27.440 --> 20:29.440]  слишком большая,
[20:29.440 --> 20:31.440]  так, сейчас, момент, m на n, да?
[20:33.440 --> 20:35.440]  Вот, вот, вот.
[20:37.440 --> 20:39.440]  Вот, да, сейчас
[20:39.440 --> 20:41.440]  как-то странно, да, что нам хорошо, когда
[20:41.440 --> 20:43.440]  альфа маленькая. Нет, ну, да, да, да.
[20:43.440 --> 20:45.440]  То есть, нам, нам хорошо, когда
[20:49.440 --> 20:51.440]  кто-то меня обманывает, мне кажется.
[20:51.440 --> 20:53.440]  Извините, я сегодня
[20:55.440 --> 20:57.440]  волнуюсь, n на m, конечно,
[20:57.440 --> 20:59.440]  n на m, да. Наоборот,
[20:59.440 --> 21:01.440]  число вставленных ключей делить на
[21:01.440 --> 21:03.440]  количество элементов. Так как, как раз, вот это
[21:03.440 --> 21:05.440]  средняя длина всех цепочек, да, потому что если
[21:05.440 --> 21:07.440]  суммарная длина n, всего m цепочек,
[21:07.440 --> 21:09.440]  в смысле m списков, тогда лот фактора
[21:09.440 --> 21:11.440]  вот такой, средняя длина каждой цепочки
[21:11.440 --> 21:13.440]  n делить на m.
[21:13.440 --> 21:15.440]  Ну, вот. И нам как раз
[21:15.440 --> 21:17.440]  хорошо, да, что если m растет,
[21:17.440 --> 21:19.440]  то эта штука убывает, время работы как бы
[21:19.440 --> 21:21.440]  будет меньше. Вот такой результат.
[21:21.440 --> 21:23.440]  Значит,
[21:23.440 --> 21:25.440]  что обычно, что обычно делают? Во-первых,
[21:25.440 --> 21:27.440]  фиксирует альфа
[21:27.440 --> 21:29.440]  непревосходящим какой-нибудь константы, обычно
[21:29.440 --> 21:31.440]  меньше единицы. Вот.
[21:31.440 --> 21:33.440]  Ну, зависит от того, что вы хотите
[21:33.440 --> 21:35.440]  в разных, в разных реализациях по-разному.
[21:35.440 --> 21:37.440]  Ну, давайте там считать, что альфа всегда
[21:37.440 --> 21:39.440]  не больше, чем там 0,95, например.
[21:39.440 --> 21:41.440]  То есть, в нашей х-таблице
[21:41.440 --> 21:43.440]  поддерживается вот такое вот соотношение, что
[21:43.440 --> 21:45.440]  число вставленных ключей,
[21:45.440 --> 21:47.440]  деленное на общий размер таблицы,
[21:47.440 --> 21:49.440]  не больше 0,95.
[21:49.440 --> 21:51.440]  И тогда время работы, ну, от ожидания,
[21:51.440 --> 21:53.440]  по крайней мере, время работы будет всегда
[21:53.440 --> 21:55.440]  от единицы.
[21:55.440 --> 21:57.440]  Но проблема возникает в том,
[21:57.440 --> 21:59.440]  что нам нужно будет еще вот это вот как-то
[21:59.440 --> 22:01.440]  научиться поддерживать, потому что если мы
[22:01.440 --> 22:03.440]  m фиксировали где-то в начале и сказали,
[22:03.440 --> 22:05.440]  что вот у нас х-таблица такого размера,
[22:05.440 --> 22:07.440]  то после многих инсертов у меня нарушится,
[22:07.440 --> 22:09.440]  что лод-фактор не превышает какой-то констант.
[22:09.440 --> 22:11.440]  Значит, нам нужно будет, на самом деле, m
[22:11.440 --> 22:13.440]  увеличивать. Ну, и здесь будет очень простая
[22:13.440 --> 22:15.440]  идея, если у меня была какая-то х-таблица размера m,
[22:15.440 --> 22:17.440]  и она перегрузилась,
[22:17.440 --> 22:19.440]  то есть альфа превысила какой-то допустимый
[22:19.440 --> 22:21.440]  порог, тогда мы просто создаем
[22:21.440 --> 22:23.440]  таблицу два раза большего размера,
[22:23.440 --> 22:25.440]  2m,
[22:25.440 --> 22:27.440]  и делаем, ну, процедуру
[22:27.440 --> 22:29.440]  rehash.
[22:29.440 --> 22:31.440]  То есть мы просто выбираем новую хэш-функцию,
[22:31.440 --> 22:33.440]  если раньше у меня хэш-функция била в
[22:33.440 --> 22:35.440]  множество 0 и минус 1, то теперь она
[22:35.440 --> 22:37.440]  будет бить в множество от 0 до 2 и минус 1.
[22:37.440 --> 22:39.440]  Взяли новую хэш-функцию, и
[22:39.440 --> 22:41.440]  все элементы вот этой вот старой хэш-таблицы
[22:41.440 --> 22:43.440]  перекинули в новую, а про старую
[22:43.440 --> 22:45.440]  забыли.
[22:45.440 --> 22:47.440]  Вот это очень похоже на то, что мы делали в векторе,
[22:47.440 --> 22:49.440]  у нас что-то там переполняется,
[22:49.440 --> 22:51.440]  превышает какой-то порог, тогда давайте
[22:51.440 --> 22:53.440]  мы просто выделим в себя два раза больше памяти,
[22:53.440 --> 22:55.440]  все старые элементы перекинем в новую таблицу.
[22:55.440 --> 22:57.440]  Ровно то же самое происходит здесь, только мы еще
[22:57.440 --> 22:59.440]  обновляем нашу хэш-функцию, потому что раньше у меня
[22:59.440 --> 23:01.440]  хэш-функция принимала m значений,
[23:01.440 --> 23:03.440]  теперь мы хотим, чтобы хэш-функция принимала 2m значений.
[23:03.440 --> 23:05.440]  Ну и, соответственно,
[23:05.440 --> 23:07.440]  алгоритм будет такой. Мы поддерживаем
[23:07.440 --> 23:09.440]  текущее отношение n делить на m.
[23:10.440 --> 23:12.440]  Как теперь обрабатывать запрос?
[23:12.440 --> 23:14.440]  Обрабатывать запрос точно так же, как было на этой доске написано,
[23:14.440 --> 23:16.440]  insert, find и erase.
[23:16.440 --> 23:18.440]  Но если вдруг альфа, loadFactor
[23:18.440 --> 23:20.440]  превысила вот эту константу, то мы
[23:20.440 --> 23:22.440]  временно останавливаемся, перестанем
[23:22.440 --> 23:24.440]  вычислять на запрос и делаем rehash.
[23:24.440 --> 23:26.440]  Расширяем в два раза нашу хэш-таблицу,
[23:26.440 --> 23:28.440]  перекидываем, то есть у нас, в частности,
[23:28.440 --> 23:30.440]  вот эти все цепочки перегруппируются,
[23:30.440 --> 23:32.440]  потому что у меня теперь поменялась хэш-функция,
[23:32.440 --> 23:34.440]  и, скорее всего, те
[23:34.440 --> 23:36.440]  ключи у которых была раньше одинаковая хэш-функция
[23:36.440 --> 23:38.440]  старая, они, скорее всего, теперь будут лежать
[23:38.440 --> 23:40.440]  в разных корзинках, в разных списках
[23:40.440 --> 23:42.440]  в новой хэш-таблице.
[23:42.440 --> 23:44.440]  Делаем rehash, все переложили, понятно, что это работает
[23:44.440 --> 23:46.440]  за n, ну, за n плюс m, на самом деле.
[23:46.440 --> 23:48.440]  За n плюс m.
[23:48.440 --> 23:50.440]  Потому что нам нужно выделить память,
[23:50.440 --> 23:52.440]  переложить n элементов туда, и еще вот эту память
[23:52.440 --> 23:54.440]  освободить в идеале.
[23:54.440 --> 23:56.440]  Вот.
[23:56.440 --> 23:58.440]  Отсюда возникает амортизация.
[23:58.440 --> 24:00.440]  Отсюда возникает амортизация, потому что
[24:00.440 --> 24:02.440]  да, средняя, обычная, простая операция,
[24:02.440 --> 24:04.440]  в антаждании времени работы это вот константа.
[24:04.440 --> 24:06.440]  Если мы альфа ограничим
[24:06.440 --> 24:08.440]  каким-то порогом, то время работы будет константа.
[24:08.440 --> 24:10.440]  Вот.
[24:10.440 --> 24:12.440]  Но там
[24:12.440 --> 24:14.440]  в среднем, там сколько получается?
[24:14.440 --> 24:16.440]  Каждую, первую, вторую, четвертую,
[24:16.440 --> 24:18.440]  восьмую и так далее, ну, то есть по степеням двойки
[24:18.440 --> 24:20.440]  операции мы посмотрим,
[24:20.440 --> 24:22.440]  нам нужно будет делать rehash.
[24:22.440 --> 24:24.440]  Поэтому возникает амортизация, и опять вот мы можем
[24:24.440 --> 24:26.440]  так же, как в векторе, размазать вот это вот
[24:26.440 --> 24:28.440]  время по
[24:28.440 --> 24:30.440]  более простым операциям, где не нужен rehash.
[24:30.440 --> 24:32.440]  Значит, давайте
[24:32.440 --> 24:34.440]  все это напишем.
[24:36.440 --> 24:38.440]  Выполняем
[24:38.440 --> 24:40.440]  операции
[24:40.440 --> 24:42.440]  как обычно.
[24:46.440 --> 24:48.440]  Но если
[24:48.440 --> 24:50.440]  альфа превышает порог,
[24:54.440 --> 24:56.440]  ну, тут какая-то константа, она,
[24:56.440 --> 24:58.440]  еще раз повторю, не очень существенная,
[24:58.440 --> 25:00.440]  можно там 0,5 писать, я привык 0,5
[25:00.440 --> 25:02.440]  писать.
[25:02.440 --> 25:04.440]  Ну, если мы
[25:04.440 --> 25:06.440]  на практике что-то более близко к единице,
[25:06.440 --> 25:08.440]  там 0,75 можно здесь написать,
[25:08.440 --> 25:10.440]  короче, что-то такое,
[25:10.440 --> 25:12.440]  то делаем
[25:12.440 --> 25:14.440]  rehash,
[25:14.440 --> 25:16.440]  расширяем
[25:18.440 --> 25:20.440]  таблицу в два раза,
[25:24.440 --> 25:26.440]  в два раза,
[25:28.440 --> 25:30.440]  генерируем новую hash функцию,
[25:30.440 --> 25:32.440]  генерируем новую hash функцию,
[25:36.440 --> 25:38.440]  новую hash функцию,
[25:40.440 --> 25:42.440]  перекладываем элементы.
[25:46.440 --> 25:48.440]  Вот, и здесь тогда как раз получается
[25:48.440 --> 25:50.440]  та самая симпотика, про которую я говорил
[25:50.440 --> 25:52.440]  в самом начале, что, во-первых, она
[25:52.440 --> 25:54.440]  вероятностная, что мы от ожидания константа,
[25:54.440 --> 25:56.440]  но, с другой стороны, она еще и на каких-то
[25:56.440 --> 25:58.440]  конкретных запросах может
[26:00.440 --> 26:02.440]  работать долго,
[26:02.440 --> 26:04.440]  поэтому нам нужна амортизация.
[26:04.440 --> 26:06.440]  В итоге амортизированная
[26:06.440 --> 26:08.440]  от ожидания
[26:10.440 --> 26:12.440]  есть, ну, я напишу
[26:12.440 --> 26:14.440]  от единицы в том смысле,
[26:14.440 --> 26:16.440]  что то альфа, которая там написана,
[26:16.440 --> 26:18.440]  оно не ограничено таким порогом,
[26:18.440 --> 26:20.440]  поэтому от ожидания будет тоже ограничено
[26:20.440 --> 26:22.440]  от единицы. Понятно?
[26:24.440 --> 26:26.440]  Вот, ну да, это, конечно, без доказательства,
[26:26.440 --> 26:28.440]  потому что тервера
[26:28.440 --> 26:30.440]  тервер мы пока трогать не хотим.
[26:32.440 --> 26:34.440]  Так, ну и все, то есть мы поняли, что
[26:34.440 --> 26:36.440]  нам достаточно выполнение
[26:36.440 --> 26:38.440]  какого-то требования на семейство
[26:38.440 --> 26:40.440]  hash функций,
[26:40.440 --> 26:42.440]  и давайте
[26:42.440 --> 26:44.440]  напишем, что нам, например, подойдет.
[26:50.440 --> 26:52.440]  Пример универсального семейства.
[26:58.440 --> 27:00.440]  Здесь давайте считать, что
[27:00.440 --> 27:02.440]  у это zp,
[27:02.440 --> 27:04.440]  ну или, по крайней мере, вложено в zp,
[27:04.440 --> 27:06.440]  то есть это
[27:06.440 --> 27:08.440]  числа от 0 до
[27:08.440 --> 27:10.440]  поминус 1, где p простое.
[27:16.440 --> 27:18.440]  Тогда
[27:18.440 --> 27:20.440]  семейство будет таким у нас.
[27:20.440 --> 27:22.440]  Это все функции вида
[27:22.440 --> 27:24.440]  ax плюс b
[27:24.440 --> 27:26.440]  по модулю m,
[27:26.440 --> 27:28.440]  где a не нулевое
[27:28.440 --> 27:30.440]  число из zp,
[27:30.440 --> 27:32.440]  а b произвольное число из zp.
[27:40.440 --> 27:42.440]  Вот это будет универсальный
[27:42.440 --> 27:44.440]  семейство hash функций.
[27:44.440 --> 27:46.440]  То есть функция очень простая, да,
[27:46.440 --> 27:48.440]  вот есть у меня, то есть я считаю, что все ключи
[27:48.440 --> 27:50.440]  у меня, это числа
[27:50.440 --> 27:52.440]  натуральные,
[27:52.440 --> 27:54.440]  и у меня есть
[27:54.440 --> 27:56.440]  числа натуральные,
[27:56.440 --> 27:58.440]  и что там, p это
[27:58.440 --> 28:00.440]  какой-то простой, который больше всех
[28:00.440 --> 28:02.440]  элементов из нашего универсума.
[28:02.440 --> 28:04.440]  Тогда просто рассмотрим такую линию функцию,
[28:04.440 --> 28:06.440]  вот это вот имеется в виду,
[28:06.440 --> 28:08.440]  ну опять-таки это вычисление
[28:08.440 --> 28:10.440]  происходит в zp, то есть, по сути, я
[28:10.440 --> 28:12.440]  сначала умножаю два числа, потом прибавляю
[28:12.440 --> 28:14.440]  b, потом беру остаток, по-моему, для p.
[28:14.440 --> 28:16.440]  Вот эти вот все вычисления производятся в zp.
[28:16.440 --> 28:18.440]  В zp более формально я мог бы написать так,
[28:18.440 --> 28:20.440]  ax плюс b
[28:20.440 --> 28:22.440]  в процент p, потом еще
[28:22.440 --> 28:24.440]  в процент m.
[28:30.440 --> 28:32.440]  Вот сначала вот это вот вычисление
[28:32.440 --> 28:34.440]  производится по моделю p,
[28:34.440 --> 28:36.440]  и потом еще по моделю m берется.
[28:36.440 --> 28:38.440]  По моделю m берется.
[28:38.440 --> 28:40.440]  Вот.
[28:40.440 --> 28:42.440]  То есть, по сути, просто линейные функции,
[28:42.440 --> 28:44.440]  ну афинные функции, ax плюс b,
[28:44.440 --> 28:46.440]  где старший коэффициент не нулевой.
[28:46.440 --> 28:48.440]  Оказывается, что это универсальное семейство,
[28:48.440 --> 28:50.440]  и значит, в общем-то, уже нам
[28:50.440 --> 28:52.440]  очень простую реализацию там hash таблицы
[28:52.440 --> 28:54.440]  написать. Мы сначала
[28:54.440 --> 28:56.440]  ну там определяем p
[28:56.440 --> 28:58.440]  достаточно большое, то есть, если нам, скажем, гарантируем,
[28:58.440 --> 29:00.440]  что ключи это числа от 0 до 29,
[29:00.440 --> 29:02.440]  мы можем сказать, что p это, скажем, 10 и 9
[29:02.440 --> 29:04.440]  плюс 7 или что-нибудь такое, ну какое-нибудь простое,
[29:04.440 --> 29:06.440]  побольше чем универсум.
[29:06.440 --> 29:08.440]  Генирируем случайные a и b
[29:08.440 --> 29:10.440]  вот с такими вот условиями.
[29:10.440 --> 29:12.440]  Получаем тем самым случайную функцию из a
[29:12.440 --> 29:14.440]  красиво, ну и потом работаем вот в соответствии
[29:14.440 --> 29:16.440]  с тем, что я рассказывал.
[29:16.440 --> 29:18.440]  Да.
[29:20.440 --> 29:22.440]  Ну единственное условие там
[29:22.440 --> 29:24.440]  вот такое на самом деле возникает.
[29:24.440 --> 29:26.440]  Но
[29:26.440 --> 29:28.440]  оно не существенное.
[29:28.440 --> 29:30.440]  То есть, смотрите еще раз, да, что мы делаем.
[29:30.440 --> 29:32.440]  Что имеется в виду?
[29:32.440 --> 29:34.440]  Имеется в виду, что ключи, которые мы хотим хранить в hash таблице,
[29:34.440 --> 29:36.440]  это, скажем, числа от 0 до 10 и 9.
[29:36.440 --> 29:38.440]  А m
[29:38.440 --> 29:40.440]  это размер hash таблицы.
[29:40.440 --> 29:42.440]  Любой, каким мы его хотим, мы его таким и выбираем.
[29:42.440 --> 29:44.440]  10 и 5, например.
[29:44.440 --> 29:46.440]  Чтобы большое множество поместилось в каком-то маленьком.
[29:46.440 --> 29:48.440]  Пусть m это 10 и 5.
[29:48.440 --> 29:50.440]  Тогда чтобы посчитать hash значение
[29:50.440 --> 29:52.440]  какого-то конкретного числа,
[29:52.440 --> 29:54.440]  вы заранее
[29:54.440 --> 29:56.440]  генерируете вот эти a и b,
[29:56.440 --> 29:58.440]  неприсходящие p,
[29:58.440 --> 30:00.440]  то есть, неприсходящие 10 в 9 плюс 6, грубо говоря.
[30:00.440 --> 30:02.440]  Затем вы для данного
[30:02.440 --> 30:04.440]  x считаете вот это значение по моделю p
[30:04.440 --> 30:06.440]  и потом берете его еще раз по моделю m.
[30:06.440 --> 30:08.440]  И это и будет
[30:08.440 --> 30:10.440]  та ячейка hash таблицы, в которой
[30:10.440 --> 30:12.440]  надо этот x положить.
[30:12.440 --> 30:14.440]  По сути, это независимые сущности.
[30:14.440 --> 30:16.440]  m это всегда размер hash таблицы,
[30:16.440 --> 30:18.440]  а p это то, по чему мы делаем вычисления.
[30:18.440 --> 30:20.440]  Да?
[30:20.440 --> 30:22.440]  А если у нас x будут одинаковые,
[30:22.440 --> 30:24.440]  то у нас получают основные члены?
[30:24.440 --> 30:26.440]  x и x одинаковые или их hash значение одинаковое?
[30:26.440 --> 30:28.440]  Но если x и x одинаковые,
[30:28.440 --> 30:30.440]  то мы говорим, что у нас без дубликатов все.
[30:30.440 --> 30:32.440]  То есть мы храним множество,
[30:32.440 --> 30:34.440]  а не мультим множество.
[30:34.440 --> 30:36.440]  Если бы мы хотели хранить мультим множество,
[30:36.440 --> 30:38.440]  то в пару с каждым x можно было бы хранить слой его копий.
[30:38.440 --> 30:40.440]  Вот.
[30:44.440 --> 30:46.440]  Ну вот не будет.
[30:46.440 --> 30:48.440]  Мы дожидаем, что эта штука универсальная,
[30:48.440 --> 30:50.440]  а значит, по теореме,
[30:50.440 --> 30:52.440]  мы дожидаем время работы вот такое.
[30:52.440 --> 30:54.440]  Это, грубо говоря,
[30:54.440 --> 30:56.440]  средняя длина всех цепочек,
[30:56.440 --> 30:58.440]  значит, и коллизий там будет немного.
[30:58.440 --> 31:00.440]  Вообще говоря, конечно,
[31:00.440 --> 31:02.440]  у этой штуки,
[31:02.440 --> 31:04.440]  я могу сказать следующее,
[31:04.440 --> 31:06.440]  что если вы фиксировали a и b,
[31:06.440 --> 31:08.440]  ну так, неформально,
[31:08.440 --> 31:10.440]  это не очень верно,
[31:10.440 --> 31:12.440]  но вот эта вот штука,
[31:12.440 --> 31:14.440]  префиксированных a и b,
[31:14.440 --> 31:16.440]  заметает примерно равномерно
[31:16.440 --> 31:18.440]  все вот это вот m.
[31:18.440 --> 31:20.440]  То есть, грубо говоря,
[31:20.440 --> 31:22.440]  если вы варьируете x от 0 до p-1,
[31:22.440 --> 31:24.440]  считаете вот это значение по моделю m,
[31:24.440 --> 31:26.440]  то у вас примерно равномерно все ячейки заполнятся,
[31:26.440 --> 31:28.440]  и в каждой ячейке будет
[31:28.440 --> 31:30.440]  что-то типа p делить на m ключей.
[31:30.440 --> 31:32.440]  Из-за этой равномерности
[31:32.440 --> 31:34.440]  у нас, как раз, если возьмете
[31:34.440 --> 31:36.440]  наизвольные n ключи, которые вы вставляете,
[31:36.440 --> 31:38.440]  у вас степень загруженности
[31:38.440 --> 31:40.440]  будет вот такая. Это как раз альфа.
[31:42.440 --> 31:44.440]  Поэтому, да, конечно, коллизии есть,
[31:44.440 --> 31:46.440]  но из-за универсальности, которую мы не доказываем,
[31:48.440 --> 31:50.440]  то есть нам важнее разобраться с тем,
[31:50.440 --> 31:52.440]  как это работает,
[31:52.440 --> 31:54.440]  из-за универсальности будет такое,
[31:54.440 --> 31:56.440]  что в среднем коллизий будет немного.
[31:58.440 --> 32:00.440]  Вот такие дела.
[32:00.440 --> 32:02.440]  Это хэширование с цепочками.
[32:04.440 --> 32:06.440]  Ок, теперь давайте
[32:06.440 --> 32:08.440]  поговорим про совершенное хэширование.
[32:08.440 --> 32:10.440]  Немножко другая задача,
[32:10.440 --> 32:12.440]  но тоже с цепочками будет у нас.
[32:26.440 --> 32:28.440]  Совершенное хэширование.
[32:34.440 --> 32:36.440]  Тут постановка немножко
[32:36.440 --> 32:38.440]  не такая, как
[32:38.440 --> 32:40.440]  была раньше,
[32:40.440 --> 32:42.440]  а именно здесь нам известно заранее,
[32:42.440 --> 32:44.440]  с какими ключами нам придется работать.
[32:44.440 --> 32:46.440]  Постановка такая, значит, нам даны
[32:46.440 --> 32:48.440]  изначально какие-то ключи,
[32:48.440 --> 32:50.440]  давайте я их назову A1 и так далее, An,
[32:50.440 --> 32:52.440]  а потом поступают запросы
[32:52.440 --> 32:54.440]  и гарантируется, что все запросы работают
[32:54.440 --> 32:56.440]  только с этими ключами.
[32:58.440 --> 33:00.440]  Далее
[33:00.440 --> 33:02.440]  запросы
[33:02.440 --> 33:04.440]  запросы
[33:04.440 --> 33:06.440]  запросы
[33:06.440 --> 33:08.440]  только с этими ключами.
[33:18.440 --> 33:20.440]  То есть все вот эти вот иксы, которые
[33:20.440 --> 33:22.440]  insert, erase и refind, они все обязательно
[33:22.440 --> 33:24.440]  лежат в этом вот маленьком множестве.
[33:24.440 --> 33:26.440]  То есть вам изначально сообщили,
[33:26.440 --> 33:28.440]  с чем надо уметь работать,
[33:28.440 --> 33:30.440]  с какими ключами, то есть не со всем универсумом U,
[33:30.440 --> 33:32.440]  а с этими. И потом запросы поступают,
[33:32.440 --> 33:34.440]  где параметры X только в этом множестве всегда.
[33:34.440 --> 33:36.440]  То есть это в каком-то смысле
[33:36.440 --> 33:38.440]  похоже на работу оффлайн,
[33:38.440 --> 33:40.440]  в том плане, что вам как бы
[33:40.440 --> 33:42.440]  известны все запросы заранее,
[33:42.440 --> 33:44.440]  или там не все запросы, а по крайней мере все ключи,
[33:44.440 --> 33:46.440]  с которыми придется работать. Вот вам они откуда-то
[33:46.440 --> 33:48.440]  известны, и дальше нужно
[33:48.440 --> 33:50.440]  что-то с ними сделать, как-то
[33:50.440 --> 33:52.440]  сделать какую-то предобработку, и потом
[33:52.440 --> 33:54.440]  как можно быстрее отвечать на все запросы.
[33:54.440 --> 33:56.440]  То есть это как бы оффлайн, что нам известны все вот эти ключи.
[33:56.440 --> 33:58.440]  На самом деле это вполне реалистичная
[33:58.440 --> 34:00.440]  установка, потому что, например,
[34:00.440 --> 34:02.440]  вы организуете какое-то
[34:02.440 --> 34:04.440]  соревнование, у вас люди
[34:04.440 --> 34:06.440]  до какого-то момента регистрируются,
[34:06.440 --> 34:08.440]  после какого-то момента все, регистрация закончена.
[34:08.440 --> 34:10.440]  Соответственно, вам известны имена всех участников,
[34:10.440 --> 34:12.440]  и дальше это множество никак меняться не будет.
[34:12.440 --> 34:14.440]  А дальше во время соревнования происходят какие-то события.
[34:14.440 --> 34:16.440]  Один человек кого-то обогнал,
[34:16.440 --> 34:18.440]  сдал задачку, что-то такое.
[34:18.440 --> 34:20.440]  Соответственно, множество ключей у вас всегда фиксировано,
[34:20.440 --> 34:22.440]  а события выступают только с ними,
[34:22.440 --> 34:24.440]  и это в принципе что-то реалистичное.
[34:24.440 --> 34:26.440]  Вот, и здесь
[34:26.440 --> 34:28.440]  давайте я
[34:28.440 --> 34:30.440]  пропишу еще раз,
[34:30.440 --> 34:32.440]  какие у нас есть запросы.
[34:34.440 --> 34:36.440]  x это всегда аи для
[34:36.440 --> 34:38.440]  кода i,
[34:38.440 --> 34:40.440]  для кода i.
[34:42.440 --> 34:44.440]  Ну и тут понятно, как можно было бы решать
[34:44.440 --> 34:46.440]  за алгорифом. Можно было бы
[34:46.440 --> 34:48.440]  посредствовать этот массив,
[34:48.440 --> 34:50.440]  построить дальше там массив
[34:50.440 --> 34:52.440]  0 единиц вот этого размера,
[34:52.440 --> 34:54.440]  и x искать бы им поиском в этом массиве,
[34:54.440 --> 34:56.440]  соответственно, понимать, какой у него номер
[34:56.440 --> 34:58.440]  в ацертуральном порядке.
[34:58.440 --> 35:00.440]  Ну, я не буду это записывать, потому что все равно
[35:00.440 --> 35:02.440]  бесполезно. Но, короче, за алгорифом можно
[35:02.440 --> 35:04.440]  легко делать. Сортировка,
[35:04.440 --> 35:06.440]  потом bin поиском определяем номер в этом ацертурном порядке,
[35:06.440 --> 35:08.440]  а значит знаем, как бы, ну то есть
[35:08.440 --> 35:10.440]  для каждого числа храним там 0 и ледничку,
[35:10.440 --> 35:12.440]  есть он в массиве или нет, есть он множество или нет.
[35:12.440 --> 35:14.440]  И дальше по bin поискам понимаем, какой тут
[35:14.440 --> 35:16.440]  хранится бит.
[35:16.440 --> 35:18.440]  Вот, но это все равно алгорифом, да, и особо выигрыша
[35:18.440 --> 35:20.440]  по сравнению с деревом поиска даже нет.
[35:20.440 --> 35:22.440]  А мы сделаем следующее,
[35:22.440 --> 35:24.440]  мы за линейный
[35:24.440 --> 35:26.440]  предпочет,
[35:26.440 --> 35:28.440]  за o от n,
[35:28.440 --> 35:30.440]  построим такую структуру, которая потом на все запросы
[35:30.440 --> 35:32.440]  отвечает за единицу, прям за чистую единицу,
[35:32.440 --> 35:34.440]  без вероятностей
[35:34.440 --> 35:36.440]  и без
[35:36.440 --> 35:38.440]  амортизации.
[35:40.440 --> 35:42.440]  Построим
[35:42.440 --> 35:44.440]  за o от n
[35:44.440 --> 35:46.440]  в среднем
[35:46.440 --> 35:48.440]  такую структуру,
[35:56.440 --> 35:58.440]  которая будет отвечать на все запросы за чистую единицу.
[36:16.440 --> 36:18.440]  Чистое значит невероятностное,
[36:18.440 --> 36:20.440]  не амортизированное.
[36:22.440 --> 36:24.440]  Идея следующая, мы проведем
[36:24.440 --> 36:26.440]  двухуровневое хэширование.
[36:26.440 --> 36:28.440]  Во-первых, мы заведем
[36:28.440 --> 36:30.440]  хэштаблицу,
[36:30.440 --> 36:32.440]  у которой m равно n.
[36:34.440 --> 36:36.440]  В ней будет ячеек столько же, сколько ключей
[36:36.440 --> 36:38.440]  вообще в нашем универсуме.
[36:38.440 --> 36:40.440]  Ну вот, то самое a1, так далее, an.
[36:40.440 --> 36:42.440]  И пусть здесь какая-то, здесь будет h,
[36:42.440 --> 36:44.440]  не знаю, hout,
[36:44.440 --> 36:46.440]  внешняя хэш-функция.
[36:46.440 --> 36:48.440]  Сначала все наши ключи
[36:48.440 --> 36:50.440]  распихаются как-то по этой хэштаблице
[36:50.440 --> 36:52.440]  в какие-то цепочки.
[36:54.440 --> 36:56.440]  То есть давайте сделаем вид, что вот эти h
[36:56.440 --> 36:58.440]  изначально добавляются в эту хэштаблицу.
[36:58.440 --> 37:00.440]  Тогда понятно, что
[37:00.440 --> 37:02.440]  время работы у нас будет тем
[37:02.440 --> 37:04.440]  лучше, чем короче самые длинные
[37:04.440 --> 37:06.440]  из этих цепочек. Если нам вдруг
[37:06.440 --> 37:08.440]  удастся так подгадать вот этот hout,
[37:08.440 --> 37:10.440]  что вот эти все
[37:10.440 --> 37:12.440]  цепочки будут короткие,
[37:12.440 --> 37:14.440]  то это будет очень хорошо.
[37:14.440 --> 37:16.440]  Тогда потом мы на все запросы
[37:16.440 --> 37:18.440]  будем отвечать за длину
[37:18.440 --> 37:20.440]  цепочки.
[37:20.440 --> 37:22.440]  Вот, ну хорошо.
[37:24.440 --> 37:26.440]  Сейчас продолжаем.
[37:28.440 --> 37:30.440]  Пусть
[37:30.440 --> 37:32.440]  hout
[37:32.440 --> 37:34.440]  фиксирована,
[37:38.440 --> 37:40.440]  а, скажем, cit
[37:40.440 --> 37:42.440]  это количество
[37:42.440 --> 37:44.440]  ключей, которые попали в эту
[37:44.440 --> 37:46.440]  ячейку.
[37:46.440 --> 37:48.440]  Более формально это мощность множества тех g,
[37:48.440 --> 37:50.440]  что hout
[37:50.440 --> 37:52.440]  от ajt
[37:52.440 --> 37:54.440]  равно i.
[37:56.440 --> 37:58.440]  Количество тех ключей из исходного
[37:58.440 --> 38:00.440]  множества, у которых h значение
[38:00.440 --> 38:02.440]  по действиям этой функции в точности i,
[38:02.440 --> 38:04.440]  которые попали в эту цепочку.
[38:06.440 --> 38:08.440]  Тогда первый шаг будет такой.
[38:08.440 --> 38:10.440]  hout
[38:10.440 --> 38:12.440]  нужно выбрать так,
[38:20.440 --> 38:22.440]  нужно выбрать так,
[38:22.440 --> 38:24.440]  чтобы
[38:28.440 --> 38:30.440]  сумма квадратов
[38:30.440 --> 38:32.440]  длины всех цепочек не превосходила
[38:32.440 --> 38:34.440]  4n.
[38:34.440 --> 38:36.440]  Такая пока странная магическая формула,
[38:36.440 --> 38:38.440]  давайте пока не будем задумываться, что это значит.
[38:38.440 --> 38:40.440]  Значит, сумма квадратов
[38:40.440 --> 38:42.440]  всех цепочек не превосходит
[38:42.440 --> 38:44.440]  4n.
[38:44.440 --> 38:46.440]  И это мы будем делать следующим тупым
[38:46.440 --> 38:48.440]  образом. Повторюсь, у меня
[38:48.440 --> 38:50.440]  фиксированы какие-то n ключи.
[38:50.440 --> 38:52.440]  Я хочу найти какую-то
[38:52.440 --> 38:54.440]  hout, какую-то первую хэш-функцию,
[38:54.440 --> 38:56.440]  что после ее применения
[38:56.440 --> 38:58.440]  мои ключи разбиваются вот в эти вот ячейки,
[38:58.440 --> 39:00.440]  в эти односвязанные списки,
[39:00.440 --> 39:02.440]  я хочу, чтобы сумма квадратов размеров
[39:02.440 --> 39:04.440]  всех списков была не больше чем 4n.
[39:04.440 --> 39:06.440]  А алгоритм поиска такой hout
[39:06.440 --> 39:08.440]  будет очень простой. Давайте случайно
[39:08.440 --> 39:10.440]  hout генерить до тех пор, пока
[39:10.440 --> 39:12.440]  не будет выполняться это неравенство.
[39:14.440 --> 39:16.440]  Ну, в общем, просто генерируем
[39:18.440 --> 39:20.440]  hout
[39:20.440 --> 39:22.440]  снова и снова,
[39:26.440 --> 39:28.440]  пока неравенство не выполнится.
[39:30.440 --> 39:32.440]  Пока неравенство
[39:32.440 --> 39:34.440]  не выполнится.
[39:36.440 --> 39:38.440]  Вот. И оказывается, что
[39:38.440 --> 39:40.440]  вот это вот событие
[39:40.440 --> 39:42.440]  происходит с вероятностью хотя бы
[39:42.440 --> 39:44.440]  одна вторая. Если наше семейство
[39:44.440 --> 39:46.440]  функций h универсально,
[39:46.440 --> 39:48.440]  если наше семейство функций
[39:48.440 --> 39:50.440]  h универсально, то есть вот те самые
[39:50.440 --> 39:52.440]  наши ax плюс b по модулю m подойдет,
[39:52.440 --> 39:54.440]  тогда вот это событие происходит
[39:54.440 --> 39:56.440]  с вероятностью, по крайней мере, одна вторая.
[39:56.440 --> 39:58.440]  Если вы берете случайную функцию hout,
[39:58.440 --> 40:00.440]  то в половине случаев,
[40:00.440 --> 40:02.440]  хотя бы в половине случаев, это выполнится.
[40:02.440 --> 40:04.440]  Значит, количество раз, которые вам придется
[40:04.440 --> 40:06.440]  перегенерировать эту самую h,
[40:06.440 --> 40:08.440]  оно маленькое. Ну, то есть, представьте,
[40:08.440 --> 40:10.440]  вы подбрасываете монетку и дожидаетесь
[40:10.440 --> 40:12.440]  первого выпадения орла. Понятно, что
[40:12.440 --> 40:14.440]  там решка, ну, там несколько
[40:14.440 --> 40:16.440]  первых раз выпадет, но потом
[40:16.440 --> 40:18.440]  довольно скоро выпадет орел.
[40:18.440 --> 40:20.440]  Более того, математическое ожидание
[40:20.440 --> 40:22.440]  числа, в общем, этих перебрасываний
[40:22.440 --> 40:24.440]  будет ровно два.
[40:24.440 --> 40:26.440]  Это несложно установить. Да, то есть, еще раз, у вас есть
[40:26.440 --> 40:28.440]  монетка, у вас есть хорошие события,
[40:28.440 --> 40:30.440]  которые происходят с вероятностью хотя бы одна вторая,
[40:30.440 --> 40:32.440]  и есть плохое. И вы ее много раз
[40:32.440 --> 40:34.440]  подбрасываете, дожидаясь
[40:34.440 --> 40:36.440]  первого хорошего события. То есть,
[40:36.440 --> 40:38.440]  это то же самое, что бросать о монетку, дожидаетесь
[40:38.440 --> 40:40.440]  первого орла. Ну, понятно, что там
[40:40.440 --> 40:42.440]  первый орел очень-очень,
[40:42.440 --> 40:44.440]  короче, рано выпадет.
[40:44.440 --> 40:46.440]  Его сильно долго ждать
[40:46.440 --> 40:48.440]  не придется. Вот.
[40:48.440 --> 40:50.440]  Давайте я напишу, что это происходит
[40:52.440 --> 40:54.440]  происходит с вероятностью
[40:54.440 --> 40:56.440]  с вероятностью хотя бы
[40:56.440 --> 40:58.440]  одна вторая.
[40:58.440 --> 41:00.440]  Вот. Окей.
[41:00.440 --> 41:02.440]  Получается, первый шаг сделан.
[41:02.440 --> 41:04.440]  Теперь у меня сумма квадратов всех длин,
[41:04.440 --> 41:06.440]  всех цепочек, не больше чем 4n.
[41:14.440 --> 41:16.440]  А дальше делаем следующее.
[41:16.440 --> 41:18.440]  В каждом, в каждой ячейке,
[41:18.440 --> 41:20.440]  в каждой ячейке
[41:20.440 --> 41:22.440]  нашего вот этого внешнего массива
[41:22.440 --> 41:24.440]  после разбивания по hout,
[41:24.440 --> 41:26.440]  мы построим еще одну хэш-функцию.
[41:28.440 --> 41:30.440]  Для каждого i
[41:32.440 --> 41:34.440]  построим
[41:36.440 --> 41:38.440]  свою хэш-таблицу
[41:42.440 --> 41:44.440]  размера как раз
[41:44.440 --> 41:46.440]  такие c в квадрате.
[41:46.440 --> 41:48.440]  Размера c и t в квадрате.
[41:48.440 --> 41:50.440]  Ну и поскольку мы гарантировали,
[41:50.440 --> 41:52.440]  что сумма квадратов размеров не больше,
[41:52.440 --> 41:54.440]  чем линия от n,
[41:54.440 --> 41:56.440]  то и сумма длин вот этих хэш-таблиц
[41:56.440 --> 41:58.440]  будет тоже не очень большая.
[41:58.440 --> 42:00.440]  Значит, смотрите, давайте я, чтобы было понятнее,
[42:00.440 --> 42:02.440]  какой-нибудь пример, наверное, нарисую.
[42:02.440 --> 42:04.440]  Пусть у меня n равно
[42:06.440 --> 42:08.440]  Так, сейчас. Что будет содержать?
[42:08.440 --> 42:10.440]  Ну давайте скажем
[42:10.440 --> 42:12.440]  6.
[42:12.440 --> 42:14.440]  m равно тоже получается 6.
[42:14.440 --> 42:16.440]  Соответственно, у меня есть 6 ключей.
[42:16.440 --> 42:18.440]  Раз, два, три, четыре, пять,
[42:18.440 --> 42:20.440]  шесть.
[42:20.440 --> 42:22.440]  Есть 6 ключей,
[42:22.440 --> 42:24.440]  6 ячеек
[42:24.440 --> 42:26.440]  во внешней хэш-таблице,
[42:26.440 --> 42:28.440]  и мы подбираем функцию hout так,
[42:28.440 --> 42:30.440]  чтобы сумма квадратов длин всех ячеек
[42:30.440 --> 42:32.440]  была не больше, чем 24.
[42:32.440 --> 42:34.440]  Например, может быть что-нибудь такое.
[42:34.440 --> 42:36.440]  Вот здесь 4 элемента, а здесь 2.
[42:36.440 --> 42:38.440]  Такой нам подойдет.
[42:38.440 --> 42:40.440]  То есть, если наша hout
[42:40.440 --> 42:42.440]  на каких-то
[42:42.440 --> 42:44.440]  четырех элементах возвращает вот это значение,
[42:44.440 --> 42:46.440]  а на каких-то двух еще вот это,
[42:46.440 --> 42:48.440]  то такая hout нам подойдет.
[42:48.440 --> 42:50.440]  Например, вот эта вот hout сгодится.
[42:50.440 --> 42:52.440]  Такая hout
[42:52.440 --> 42:54.440]  сгодится.
[42:56.440 --> 42:58.440]  Ну потому что здесь квадрат этого размера
[42:58.440 --> 43:00.440]  это 16, здесь квадрат этого размера 4,
[43:00.440 --> 43:02.440]  сумма 20 не превосходит 4n.
[43:02.440 --> 43:04.440]  Это окей.
[43:04.440 --> 43:06.440]  Ну смысл как раз таки такой, что
[43:06.440 --> 43:08.440]  длинных ячеек здесь не будет.
[43:08.440 --> 43:10.440]  Раз сумма квадратов у меня ограничена 4n,
[43:10.440 --> 43:12.440]  то в частности каждый квадрат ограничен корнем,
[43:12.440 --> 43:14.440]  в частности все вот эти штуки не больше, чем корень.
[43:14.440 --> 43:16.440]  Это уже в принципе не очень плохо.
[43:18.440 --> 43:20.440]  Дальше я делаю следующее. Смотрите.
[43:20.440 --> 43:22.440]  Что это значит? Что значит hout?
[43:22.440 --> 43:24.440]  Что для каких-то четырех ключей
[43:24.440 --> 43:26.440]  у меня одна и та же hout.
[43:26.440 --> 43:28.440]  То есть, они по действиям первой функции
[43:28.440 --> 43:30.440]  попали бы в одну ячейку.
[43:30.440 --> 43:32.440]  Тогда давайте сделаем следующее.
[43:32.440 --> 43:34.440]  Вот здесь заведем хэштаблицу на 16 элементов,
[43:34.440 --> 43:36.440]  размера 16.
[43:38.440 --> 43:40.440]  И подберем еще внутри такую внутреннюю функцию h,
[43:40.440 --> 43:42.440]  которая бы эти четыре элемента
[43:42.440 --> 43:44.440]  раскидывала по этой хэштаблице
[43:44.440 --> 43:46.440]  внутренней, без коллизий.
[43:48.440 --> 43:50.440]  Я завожу как раз для каждого i,
[43:50.440 --> 43:52.440]  строю свою хэштаблицу размера квадратичного,
[43:52.440 --> 43:54.440]  то есть здесь будет таблица размера 16,
[43:54.440 --> 43:56.440]  и подбираю в ней внутреннюю
[43:56.440 --> 43:58.440]  хэштаблицу h, которая бы их раскидывала
[43:58.440 --> 44:00.440]  без коллизий.
[44:00.440 --> 44:02.440]  Далее
[44:02.440 --> 44:04.440]  подбираю
[44:06.440 --> 44:08.440]  hi
[44:08.440 --> 44:10.440]  так,
[44:10.440 --> 44:12.440]  чтобы
[44:14.440 --> 44:16.440]  она
[44:18.440 --> 44:20.440]  не давала коллизий.
[44:24.440 --> 44:26.440]  То есть, по сути, у меня будет
[44:26.440 --> 44:28.440]  здесь содержать будет две хэш-функции,
[44:28.440 --> 44:30.440]  то есть здесь я определяю h0, не важно какой h1,
[44:30.440 --> 44:32.440]  вот у меня важна будет h2 и h4.
[44:32.440 --> 44:34.440]  Мне нужна такая функция h2,
[44:34.440 --> 44:36.440]  которая действует
[44:36.440 --> 44:38.440]  в 16-элементное множество
[44:38.440 --> 44:40.440]  с одной стороны, с другой стороны
[44:40.440 --> 44:42.440]  вот эти четыре элемента
[44:42.440 --> 44:44.440]  отображают без коллизий.
[44:44.440 --> 44:46.440]  Отображают без коллизий.
[44:46.440 --> 44:48.440]  Ну и здесь то же самое, эта штука должна действовать
[44:48.440 --> 44:50.440]  в множестве размера 4 и так, чтобы вот эти
[44:50.440 --> 44:52.440]  два элемента отобразились в разные множества.
[44:54.440 --> 44:56.440]  И опять утверждается, что
[44:56.440 --> 44:58.440]  за счет вот этого квадратичного
[44:58.440 --> 45:00.440]  запаса, то есть, по сути, что мне нужно?
[45:00.440 --> 45:02.440]  Мне нужно k элементов,
[45:02.440 --> 45:04.440]  вот скажем, вот эти k элементов
[45:04.440 --> 45:06.440]  разместить в хэштаб лист у размера k квадрат.
[45:06.440 --> 45:08.440]  Ну и тогда как бы интуитивно понятно,
[45:08.440 --> 45:10.440]  что случайная хэш-функция подойдет.
[45:10.440 --> 45:12.440]  То есть, если у вас есть 4 элемента,
[45:12.440 --> 45:14.440]  а у вас есть 16 корзинок,
[45:14.440 --> 45:16.440]  то понятно, что случайное отображение
[45:16.440 --> 45:18.440]  их раскидает без коллизий.
[45:18.440 --> 45:20.440]  Ну, неформально, но тем не менее.
[45:20.440 --> 45:22.440]  Теорема опять-таки без заказательства.
[45:22.440 --> 45:24.440]  Если
[45:28.440 --> 45:30.440]  х1 и так далее,
[45:30.440 --> 45:32.440]  х1 и так далее, хк
[45:34.440 --> 45:36.440]  различные ключи,
[45:38.440 --> 45:40.440]  m равно k квадрат,
[45:40.440 --> 45:42.440]  а h это универсальное семейство
[45:42.440 --> 45:44.440]  хэш-функций,
[45:48.440 --> 45:50.440]  то опять вероятность того, что
[45:52.440 --> 45:54.440]  у вас не произошло коллизий,
[45:54.440 --> 45:56.440]  то есть, все h от x различны.
[45:56.440 --> 45:58.440]  Давайте от xj напишу, различны.
[45:58.440 --> 46:00.440]  Хотя бы одна вторая.
[46:04.440 --> 46:06.440]  Вероятность того, что
[46:06.440 --> 46:08.440]  после выбора случайной хэш-функции,
[46:08.440 --> 46:10.440]  то здесь опять вероятность идет по выбору h,
[46:10.440 --> 46:12.440]  по выбору случайной h,
[46:12.440 --> 46:14.440]  вероятность того,
[46:14.440 --> 46:16.440]  что у вас не произойдет коллизий,
[46:16.440 --> 46:18.440]  то есть, хэш значения для всех х будут различны,
[46:18.440 --> 46:20.440]  она хотя бы одна вторая.
[46:20.440 --> 46:22.440]  Поэтому здесь работает тот же самый трюк.
[46:22.440 --> 46:24.440]  То есть, это второй шаг для каждого,
[46:24.440 --> 46:26.440]  и мы много раз пытаемся
[46:26.440 --> 46:28.440]  подобрать свою функцию h так,
[46:28.440 --> 46:30.440]  чтобы она раскидала все ключи,
[46:30.440 --> 46:32.440]  попавшие в эту ячейку без коллизий.
[46:32.440 --> 46:34.440]  Второй шаг.
[46:34.440 --> 46:36.440]  Для каждого i
[46:36.440 --> 46:38.440]  от 0 до n-1
[46:40.440 --> 46:42.440]  подбираем
[46:44.440 --> 46:46.440]  h и t
[46:46.440 --> 46:48.440]  так, чтобы не было коллизий.
[46:56.440 --> 46:58.440]  Ну и за счет того,
[46:58.440 --> 47:00.440]  что случайная функция подходит вероятностью
[47:00.440 --> 47:02.440]  одна вторая, опять тот же самый аргумент
[47:02.440 --> 47:04.440]  с монетками,
[47:04.440 --> 47:06.440]  хотя бы половина хэш-функций хорошая,
[47:06.440 --> 47:08.440]  значит, если вы просто будете брать случайную
[47:08.440 --> 47:10.440]  и перегенерировать, если она плохая,
[47:10.440 --> 47:12.440]  то математическое ожидание числа
[47:12.440 --> 47:14.440]  попыток будет константным.
[47:14.440 --> 47:16.440]  То есть, вы взяли какой-то h,
[47:16.440 --> 47:18.440]  попытались его примерить на роль h и t,
[47:18.440 --> 47:20.440]  не подошло, пытайтесь новое,
[47:20.440 --> 47:22.440]  не подошло, пытайтесь новое, не подошло, пытайтесь новое и так далее.
[47:22.440 --> 47:24.440]  Очень скоро подойдет.
[47:24.440 --> 47:26.440]  Поскольку каждое событие
[47:26.440 --> 47:28.440]  происходит с вероятностью одна вторая,
[47:28.440 --> 47:30.440]  вы хотите дождаться его выпадения,
[47:30.440 --> 47:32.440]  то очень скоро оно произойдет.
[47:32.440 --> 47:34.440]  То же самое дождание, когда орел выпадет.
[47:34.440 --> 47:36.440]  Ну и все.
[47:36.440 --> 47:38.440]  Тогда алгоритм суммарно будет такой.
[47:38.440 --> 47:40.440]  Мы сначала строим такую структуру,
[47:40.440 --> 47:42.440]  что мы сначала находим hout,
[47:42.440 --> 47:44.440]  потом здесь в каждой штуке строим квадратичного размера хэштаблицу,
[47:44.440 --> 47:46.440]  то есть тут не 4 будет аж 16,
[47:46.440 --> 47:48.440]  а здесь будет 4.
[47:48.440 --> 47:50.440]  Здесь 4, тут 16.
[47:50.440 --> 47:52.440]  Вот есть такая
[47:52.440 --> 47:54.440]  доумерная хэштаблица.
[47:54.440 --> 47:56.440]  Значит сначала, если у меня есть какой-то x,
[47:56.440 --> 47:58.440]  я сначала считаю его hout,
[47:58.440 --> 48:00.440]  понимаю, в какой
[48:00.440 --> 48:02.440]  внутренней хэштаблице он лежит,
[48:02.440 --> 48:04.440]  скажем, в какой-то там it.
[48:04.440 --> 48:06.440]  И затем, если я понимаю, что он лежит в этой хэштаблице,
[48:06.440 --> 48:08.440]  то я понимаю, что нужно на него навесить еще hita,
[48:08.440 --> 48:10.440]  чтобы понять, где он лежит в этой хэштаблице.
[48:10.440 --> 48:12.440]  Такое двухступенчатое хэширование.
[48:12.440 --> 48:14.440]  Сначала понимаем,
[48:14.440 --> 48:16.440]  какая хэш функция нам нужна,
[48:16.440 --> 48:18.440]  из вот этих вот n, то есть какой маленькой хэштаблице он лежит,
[48:18.440 --> 48:20.440]  а потом навесим ту хэш функцию,
[48:20.440 --> 48:22.440]  которая ему соответствует.
[48:22.440 --> 48:24.440]  И как раз таки получается,
[48:24.440 --> 48:26.440]  что время работного запроса будет...
[48:26.440 --> 48:28.440]  Да, давайте.
[48:32.440 --> 48:34.440]  Нет, смотрите еще раз, здесь множество ключей фиксировано.
[48:34.440 --> 48:36.440]  У меня всегда n ключей,
[48:36.440 --> 48:38.440]  поэтому никакого rehash не происходит.
[48:38.440 --> 48:40.440]  Не понял.
[48:46.440 --> 48:48.440]  А тут некуда улучшать,
[48:48.440 --> 48:50.440]  у нас время работы единицы на запрос.
[48:50.440 --> 48:52.440]  Лучше некуда.
[48:52.440 --> 48:54.440]  Ну можно, но не понятно зачем.
[48:54.440 --> 48:56.440]  Да, значит, еще раз.
[48:56.440 --> 48:58.440]  Как тогда...
[48:58.440 --> 49:00.440]  За сколько мы отвечаем на каждый запрос?
[49:00.440 --> 49:02.440]  Скажем, insert x.
[49:02.440 --> 49:04.440]  Сначала мы считаем hashout от x,
[49:04.440 --> 49:06.440]  скажем, он попадает куда-нибудь сюда.
[49:06.440 --> 49:08.440]  Тогда мы понимаем, что чтобы понять его,
[49:08.440 --> 49:10.440]  где он лежит в этой хэштаблице,
[49:10.440 --> 49:12.440]  нужно взять от него h4 от x,
[49:12.440 --> 49:14.440]  где h4 у нас где-то сохранена,
[49:14.440 --> 49:16.440]  просто ее применяем и понимаем,
[49:16.440 --> 49:18.440]  что он лежит в этой хэштаблице.
[49:18.440 --> 49:20.440]  Все. И поскольку нет коллизий,
[49:20.440 --> 49:22.440]  тут можно считать, что это опять хэштаблица с цепочками,
[49:22.440 --> 49:24.440]  но длина каждой цепочки максимум единица,
[49:24.440 --> 49:26.440]  поскольку нет коллизий.
[49:26.440 --> 49:28.440]  Никакая цепочка не будет иметь длину больше одного.
[49:28.440 --> 49:30.440]  Значит, мы однозначно понимаем,
[49:30.440 --> 49:32.440]  где он лежит,
[49:32.440 --> 49:34.440]  и все, мы получаем ответственный запрос за единицу.
[49:34.440 --> 49:36.440]  То есть либо говорим, что этот элемент добавился,
[49:36.440 --> 49:38.440]  либо удалился,
[49:38.440 --> 49:40.440]  либо надо проверить, что он там есть или нет.
[49:40.440 --> 49:42.440]  Время работы ответа,
[49:42.440 --> 49:44.440]  точнее время обработки каждого запроса,
[49:44.440 --> 49:46.440]  чисто единица, а предпочет у меня
[49:46.440 --> 49:48.440]  линейный, ну и по времени и по памяти.
[49:48.440 --> 49:50.440]  Потому что мы поняли, что
[49:50.440 --> 49:52.440]  количество перегенерации будет константа,
[49:52.440 --> 49:54.440]  поэтому суммарно первый и второй шаг работает
[49:54.440 --> 49:56.440]  за линию в среднем, за отn.
[49:56.440 --> 49:58.440]  Ну и память тоже, понятное дело, линейна,
[49:58.440 --> 50:00.440]  потому что мы вот эту вот штуку поддерживаем.
[50:00.440 --> 50:02.440]  Сумма квадратов размеров,
[50:02.440 --> 50:04.440]  это как раз таки вся память нужная
[50:04.440 --> 50:06.440]  на нашей х-таблице,
[50:06.440 --> 50:08.440]  она линейна. Значит, время и память линейны,
[50:08.440 --> 50:10.440]  все хорошо, и ответный запрос за единицу.
[50:10.440 --> 50:12.440]  Понятно?
[50:14.440 --> 50:16.440]  Окей.
[50:16.440 --> 50:18.440]  Давайте еще один пример приведу, зачем это может быть нужно.
[50:18.440 --> 50:20.440]  Например, у нас есть
[50:20.440 --> 50:22.440]  граф какой-то,
[50:22.440 --> 50:24.440]  то есть какие-то вершины и ребра между ними,
[50:24.440 --> 50:26.440]  и нам граф заранее известен.
[50:26.440 --> 50:28.440]  И нам поступают запросы,
[50:28.440 --> 50:30.440]  вида, проверить, есть ли какой-то
[50:30.440 --> 50:32.440]  элемент, точнее, есть ли ребро между двумя вершинами.
[50:32.440 --> 50:34.440]  То есть вот есть граф фиксированный,
[50:34.440 --> 50:36.440]  в нем ребра не добавляются, не удаляются,
[50:36.440 --> 50:38.440]  нам известен граф,
[50:38.440 --> 50:40.440]  и поступают запросы, проверить наличие
[50:40.440 --> 50:42.440]  кого-то ребра, есть ли ребро в графе или нет.
[50:42.440 --> 50:44.440]  Тогда вот как раз таки вот эта
[50:44.440 --> 50:46.440]  конструкция идеально ложится,
[50:46.440 --> 50:48.440]  что у нас есть фиксированное множество ключей,
[50:48.440 --> 50:50.440]  мы сначала можем построить
[50:50.440 --> 50:52.440]  должного вида х-таблицу,
[50:52.440 --> 50:54.440]  вот такую вложенную по всем ребрам,
[50:54.440 --> 50:56.440]  вставить все элементы в эту х-таблицу,
[50:56.440 --> 50:58.440]  все будет линейное пока что.
[50:58.440 --> 51:00.440]  А дальше, чтобы проверить наличие ребра,
[51:00.440 --> 51:02.440]  мне нужно два раза прочитать х-функцию
[51:02.440 --> 51:04.440]  и понять, есть этот элемент в х-таблице или нет.
[51:08.440 --> 51:10.440]  Понятно?
[51:12.440 --> 51:14.440]  Так, хорошо.
[51:14.440 --> 51:16.440]  Хорошо, хорошо, хорошо.
[51:16.440 --> 51:18.440]  Что дальше?
[51:24.440 --> 51:26.440]  Да, дальше про открытую адресацию будем.
[51:28.440 --> 51:30.440]  Так.
[51:42.440 --> 51:44.440]  Да, значит, следующий сюжет
[51:44.440 --> 51:46.440]  это х-таблица с открытой адресацией.
[51:58.440 --> 52:00.440]  Вот, значит, здесь мы отказываемся
[52:00.440 --> 52:02.440]  от цепочек, мы отказываемся
[52:02.440 --> 52:04.440]  от адрес разных списков,
[52:04.440 --> 52:06.440]  и наша х-таблица будет
[52:06.440 --> 52:08.440]  просто представлять собой массив длины m
[52:08.440 --> 52:10.440]  без всяких там внутренних структур,
[52:10.440 --> 52:12.440]  просто массив чисел.
[52:12.440 --> 52:14.440]  Массив чисел.
[52:18.440 --> 52:20.440]  Тогда смотрите,
[52:20.440 --> 52:22.440]  как работают всякие инсерты.
[52:22.440 --> 52:24.440]  Например, чтобы вставить какой-то х,
[52:24.440 --> 52:26.440]  ну, я как всегда генерирую какую-то случайную
[52:26.440 --> 52:28.440]  функцию h, это у нас будет всегда одинаково,
[52:28.440 --> 52:30.440]  генерируем какой-то h случайно-равноверательно
[52:30.440 --> 52:32.440]  и сфиксированно множество функций.
[52:32.440 --> 52:34.440]  Чтобы вставить х, я считаю h от x,
[52:34.440 --> 52:36.440]  то есть мы получаем какую-то ячейку
[52:36.440 --> 52:38.440]  в нашем массиве.
[52:38.440 --> 52:40.440]  Если она пустая, если тут никого нет,
[52:40.440 --> 52:42.440]  то я туда могу смело положить х.
[52:42.440 --> 52:44.440]  Если, скажем,
[52:44.440 --> 52:46.440]  мне потом поступает запрос insert y,
[52:46.440 --> 52:48.440]  и так оказалось, что h от x равно h от y,
[52:48.440 --> 52:50.440]  то мне, ну, как бы вот, как раз
[52:50.440 --> 52:52.440]  произошла коллизия,
[52:52.440 --> 52:54.440]  мне, по сути, нужно вставить y сюда же,
[52:54.440 --> 52:56.440]  но вместо того, чтобы создавать здесь цепочку
[52:56.440 --> 52:58.440]  вот такую вот вниз, не x,
[52:58.440 --> 53:00.440]  к нему подвешено y и так далее,
[53:00.440 --> 53:02.440]  а я лучше просто y возьму и положу в соседнюю клетку.
[53:02.440 --> 53:04.440]  То есть вот сюда.
[53:04.440 --> 53:06.440]  Не важно, что здесь, на самом деле,
[53:06.440 --> 53:08.440]  по сути, другие...
[53:08.440 --> 53:10.440]  что здесь другое hash значение,
[53:10.440 --> 53:12.440]  просто вот я его положу в соседнюю.
[53:12.440 --> 53:14.440]  Ну, если там было свободно, конечно.
[53:14.440 --> 53:16.440]  Если там приходит опять z, у которого
[53:16.440 --> 53:18.440]  hash функция опять такая же,
[53:18.440 --> 53:20.440]  то я вновь встаю сюда, понимаю, что здесь
[53:20.440 --> 53:22.440]  занято, иду направо, понимаю, что здесь занято, иду направо
[53:22.440 --> 53:24.440]  и так далее. Короче, я прохожу до тех пор,
[53:24.440 --> 53:26.440]  пока не увижу первую свободную клетку, и туда ее вставляю.
[53:26.440 --> 53:28.440]  Вот такое очень тупое хеширование.
[53:28.440 --> 53:30.440]  Вместо того, чтобы создавать какую-то нормальную структуру
[53:30.440 --> 53:32.440]  внутри каждой ячейки,
[53:32.440 --> 53:34.440]  я просто буду идти вправо и класть в первую свободную.
[53:34.440 --> 53:36.440]  Вот такой будет инсерт.
[53:36.440 --> 53:38.440]  Соответственно, find работает
[53:38.440 --> 53:40.440]  очень просто.
[53:40.440 --> 53:42.440]  Мы считаем hash,
[53:42.440 --> 53:44.440]  встаем сюда, ну, понимаем,
[53:44.440 --> 53:46.440]  что здесь может лежать не x, а просто
[53:46.440 --> 53:48.440]  тот, у кого hash значение такое же,
[53:48.440 --> 53:50.440]  поэтому просто пойдем направо
[53:50.440 --> 53:52.440]  до первой свободной клетки и проверим,
[53:52.440 --> 53:54.440]  что никто из них не x, ну, или, соответственно, есть ли там x.
[53:54.440 --> 53:56.440]  То есть теперь,
[53:56.440 --> 53:58.440]  поскольку у меня
[53:58.440 --> 54:00.440]  здесь не обязательно
[54:00.440 --> 54:02.440]  лежит x, то мне придется идти вправо до тех пор,
[54:02.440 --> 54:04.440]  пока я не найду первую свободную клетку,
[54:04.440 --> 54:06.440]  где никого не лежит, и мне нужно проверить,
[54:06.440 --> 54:08.440]  есть там x или нет.
[54:08.440 --> 54:10.440]  И наконец, erase тут самое тонкое,
[54:10.440 --> 54:12.440]  что если мне нужно сделать erase y вот этого вот,
[54:12.440 --> 54:14.440]  то я опять считаю от него hash,
[54:14.440 --> 54:16.440]  иду направо, нахожу, где он лежит в таблице,
[54:16.440 --> 54:18.440]  и я не могу просто эту ячейку
[54:18.440 --> 54:20.440]  освободить, потому что если я просто скажу,
[54:20.440 --> 54:22.440]  что здесь никого нет, то я потом z не найду,
[54:22.440 --> 54:24.440]  потому что чтобы найти z, мне нужно от x пройти
[54:24.440 --> 54:26.440]  до z, и чтобы все эти клетки были заняты.
[54:26.440 --> 54:28.440]  То есть я вот так сделать не смогу.
[54:28.440 --> 54:30.440]  Поэтому я просто скажу, что этот элемент
[54:30.440 --> 54:32.440]  мертвый, то есть я положу на него
[54:32.440 --> 54:34.440]  отгробный камень, что называется tombstone,
[54:36.440 --> 54:38.440]  скажу, что он мертвый, его в нашей
[54:38.440 --> 54:40.440]  hash таблице нет, то есть число там лежит,
[54:40.440 --> 54:42.440]  но оно нужно только для того, чтобы
[54:42.440 --> 54:44.440]  вот этот вот там проход в инсерте
[54:44.440 --> 54:46.440]  или в файнде понимал, что нужно идти дальше,
[54:46.440 --> 54:48.440]  что это не свободная клетка, нужно идти дальше.
[54:48.440 --> 54:50.440]  Вот и все.
[54:50.440 --> 54:52.440]  Давайте это тоже как-нибудь напишем.
[54:52.440 --> 54:54.440]  Ну и надо не забывать, что нужно делать иногда
[54:54.440 --> 54:56.440]  rehash'ы, если load factor
[54:56.440 --> 54:58.440]  превысил какую-то константу,
[54:58.440 --> 55:00.440]  то понятное дело,
[55:00.440 --> 55:02.440]  что нужно m увеличивать и
[55:02.440 --> 55:04.440]  перекладывать все элементы.
[55:04.440 --> 55:06.440]  Итак,
[55:06.440 --> 55:08.440]  давайте insert
[55:10.440 --> 55:12.440]  insert x.
[55:12.440 --> 55:14.440]  Считаем
[55:16.440 --> 55:18.440]  так, я вот не хочу здесь
[55:18.440 --> 55:20.440]  и писать, давайте напишу
[55:20.440 --> 55:22.440]  j
[55:22.440 --> 55:24.440]  равно h от x.
[55:24.440 --> 55:26.440]  Встаем в j-ту ячейку,
[55:26.440 --> 55:28.440]  идем направо в поисках первой свободной.
[55:30.440 --> 55:32.440]  Значит, идем
[55:32.440 --> 55:34.440]  направо,
[55:34.440 --> 55:36.440]  то есть по сути мы перебираем клетки
[55:36.440 --> 55:38.440]  j, j plus 1, j plus 2
[55:38.440 --> 55:40.440]  и так далее.
[55:40.440 --> 55:42.440]  В поисках первой свободной
[55:42.440 --> 55:44.440]  клетки.
[55:44.440 --> 55:46.440]  То есть там, где никакой элемент не лежит.
[55:46.440 --> 55:48.440]  Ну свободной или той,
[55:48.440 --> 55:50.440]  которая помечена tombstone.
[55:50.440 --> 55:52.440]  Или клетки
[55:52.440 --> 55:54.440]  с tombstone.
[55:54.440 --> 55:56.440]  То есть tombstone
[55:56.440 --> 55:58.440]  это тот элемент, который был удален,
[55:58.440 --> 56:00.440]  значит, на место него можно положить новый,
[56:00.440 --> 56:02.440]  соответственно, tombstone надо снять.
[56:02.440 --> 56:04.440]  То есть ячейку
[56:04.440 --> 56:06.440]  ячейку ячейку ячейку
[56:06.440 --> 56:08.440]  ячейку ячейку
[56:08.440 --> 56:10.440]  ячейку ячейку
[56:10.440 --> 56:12.440]  ячейку ячейку
[56:12.440 --> 56:14.440]  соответственно, tombstone надо снять.
[56:14.440 --> 56:16.440]  Тогда
[56:16.440 --> 56:18.440]  его надо снять.
[56:22.440 --> 56:24.440]  Понятно?
[56:26.440 --> 56:28.440]  Ну, с find
[56:28.440 --> 56:30.440]  все аналогично.
[56:30.440 --> 56:32.440]  Считаем hash функцию.
[56:32.440 --> 56:34.440]  И просто идем
[56:34.440 --> 56:36.440]  слева направо, опять-таки, по вот этим
[56:36.440 --> 56:38.440]  вот ячейкам в поисках
[56:38.440 --> 56:40.440]  первой свободной клетки.
[56:42.440 --> 56:44.440]  Идем
[56:44.440 --> 56:46.440]  по g, g плюс 1,
[56:46.440 --> 56:48.440]  и так далее,
[56:48.440 --> 56:50.440]  в поисках x
[56:52.440 --> 56:54.440]  или первой свободной.
[56:58.440 --> 57:00.440]  Значит, тогда понятно, что мы обязательно,
[57:00.440 --> 57:02.440]  если x был в таблице, мы его найдем,
[57:02.440 --> 57:04.440]  потому что мы начинаем вот с этой клетки,
[57:04.440 --> 57:06.440]  и если x когда-то добавлялся,
[57:06.440 --> 57:08.440]  то он обязательно лежит вот в одной из этих клеток
[57:08.440 --> 57:10.440]  до первой свободной, потому что
[57:10.440 --> 57:12.440]  первая свободная
[57:12.440 --> 57:14.440]  могла быть только с самого начала,
[57:14.440 --> 57:16.440]  то есть мы за нее раньше не проходили,
[57:16.440 --> 57:18.440]  значит, теперь нет смысла идти дальше
[57:18.440 --> 57:20.440]  первой свободной.
[57:20.440 --> 57:22.440]  Так, ну и raise,
[57:22.440 --> 57:24.440]  я уже говорил, что просто находим и кладем tombstone.
[57:24.440 --> 57:26.440]  Не удаляем явным образом из таблицы,
[57:26.440 --> 57:28.440]  а просто помечаем, что этот элемент
[57:28.440 --> 57:30.440]  сейчас неживой,
[57:30.440 --> 57:32.440]  и его не надо учитывать
[57:32.440 --> 57:34.440]  в ответе
[57:34.440 --> 57:36.440]  на запрос find.
[57:40.440 --> 57:42.440]  Значит, то же самое
[57:46.440 --> 57:48.440]  только кладем tombstone.
[58:00.440 --> 58:02.440]  Вот такая штука.
[58:04.440 --> 58:06.440]  Ну и да, не забываем про
[58:10.440 --> 58:12.440]  проли хэш.
[58:12.440 --> 58:14.440]  То есть если у нас
[58:14.440 --> 58:16.440]  load factor слишком большой,
[58:16.440 --> 58:18.440]  но здесь load factor, кажется, близко к единице
[58:18.440 --> 58:20.440]  брать даже плохо, потому что если он близко к единице,
[58:20.440 --> 58:22.440]  тогда у нас довольно большие
[58:22.440 --> 58:24.440]  все вот эти вот сплошные блоки будут,
[58:24.440 --> 58:26.440]  но здесь как раз таки альфа выгодно брать
[58:26.440 --> 58:28.440]  что-то в районе 1 и 2.
[58:28.440 --> 58:30.440]  Если альфа превышает 1 и 2,
[58:30.440 --> 58:32.440]  то нужно создать новую хэш таблицу,
[58:32.440 --> 58:34.440]  новую хэш функцию и переложить все старые ключи
[58:34.440 --> 58:36.440]  в новую хэш таблицу.
[58:40.440 --> 58:42.440]  Так, окей.
[58:42.440 --> 58:44.440]  Это вот открытая адресация.
[58:46.440 --> 58:48.440]  Тут тоже есть теоремы,
[58:48.440 --> 58:50.440]  говорящие о том, насколько
[58:50.440 --> 58:52.440]  это все эффективно, насколько это быстро.
[58:52.440 --> 58:54.440]  Но для этого
[58:54.440 --> 58:56.440]  нужно еще вести одно определение.
[58:58.440 --> 59:00.440]  Определение семейства
[59:02.440 --> 59:04.440]  хэш функций,
[59:06.440 --> 59:08.440]  аж красивая,
[59:08.440 --> 59:10.440]  называется k независимым,
[59:16.440 --> 59:18.440]  если
[59:22.440 --> 59:24.440]  для любых k различных
[59:24.440 --> 59:26.440]  х,
[59:26.440 --> 59:28.440]  для любых k различных ключей,
[59:28.440 --> 59:30.440]  различные ключи
[59:30.440 --> 59:32.440]  случайной величины
[59:38.440 --> 59:40.440]  h от x1,
[59:40.440 --> 59:42.440]  h от x2,
[59:42.440 --> 59:44.440]  и так далее,
[59:44.440 --> 59:46.440]  h от xk
[59:46.440 --> 59:48.440]  независимы в совокупности.
[59:48.440 --> 59:50.440]  Вот это формальное
[59:50.440 --> 59:52.440]  определение из Тервера.
[59:52.440 --> 59:54.440]  На пальцах это означает следующее,
[59:54.440 --> 59:56.440]  что даже если у вас фиксированы значения
[59:56.440 --> 59:58.440]  всех предыдущих хэш функций,
[59:58.440 --> 01:00:00.440]  то есть h от x1,
[01:00:00.440 --> 01:00:02.440]  и так далее, h от xk-1,
[01:00:02.440 --> 01:00:04.440]  тогда про вот этого значения
[01:00:04.440 --> 01:00:06.440]  вы ничего сказать не можете.
[01:00:06.440 --> 01:00:08.440]  То есть информация
[01:00:08.440 --> 01:00:10.440]  о значениях h
[01:00:10.440 --> 01:00:12.440]  в каких-то других функциях
[01:00:12.440 --> 01:00:14.440]  или в других функциях
[01:00:14.440 --> 01:00:16.440]  или в других функциях,
[01:00:16.440 --> 01:00:18.440]  о значениях h в каких-то других точках
[01:00:18.440 --> 01:00:20.440]  в какой-то k-1 точке,
[01:00:20.440 --> 01:00:22.440]  не дает никакой информации
[01:00:22.440 --> 01:00:24.440]  о том, чему равно значение h в точке xk.
[01:00:26.440 --> 01:00:28.440]  Если, например,
[01:00:28.440 --> 01:00:30.440]  мы знаем, что h от xk
[01:00:30.440 --> 01:00:32.440]  равномерно распределена в множестве 0,
[01:00:32.440 --> 01:00:34.440]  и так далее, минус 1,
[01:00:34.440 --> 01:00:36.440]  то есть, по сути, вот это значение
[01:00:36.440 --> 01:00:38.440]  равновероятно принимает все возможные ячейки
[01:00:38.440 --> 01:00:40.440]  из хэштаблицы,
[01:00:40.440 --> 01:00:42.440]  то, по сути, это означает, что
[01:00:42.440 --> 01:00:44.440]  вне зависимости от того,
[01:00:44.440 --> 01:00:46.440]  что вы знаете, куда попали,
[01:00:46.440 --> 01:00:48.440]  то про этот вы ничего предсказать не можете.
[01:00:48.440 --> 01:00:50.440]  То есть, не зная h, вы не можете предсказать,
[01:00:50.440 --> 01:00:52.440]  чему равно значение вот этого штуки.
[01:00:52.440 --> 01:00:54.440]  Значит, такая независимость.
[01:01:02.440 --> 01:01:04.440]  Так, и вот тут есть результаты
[01:01:06.440 --> 01:01:08.440]  про то, что у нас
[01:01:08.440 --> 01:01:10.440]  было про открытую адресацию,
[01:01:10.440 --> 01:01:12.440]  про линейное пробирование.
[01:01:14.440 --> 01:01:16.440]  То есть, теоремы для
[01:01:16.440 --> 01:01:18.440]  линейного
[01:01:18.440 --> 01:01:20.440]  пробирования.
[01:01:24.440 --> 01:01:26.440]  Это вот то самое, когда мы встали
[01:01:26.440 --> 01:01:28.440]  в точку g, то есть, посчитали х-функцию,
[01:01:28.440 --> 01:01:30.440]  встали в точку g, потом пытаемся положить
[01:01:30.440 --> 01:01:32.440]  в g плюс 1, g плюс 2, и так далее, и так далее.
[01:01:32.440 --> 01:01:34.440]  То есть, просто идем слева направо.
[01:01:34.440 --> 01:01:36.440]  Давайте напишу так, что
[01:01:36.440 --> 01:01:38.440]  run it
[01:01:38.440 --> 01:01:40.440]  равно h от x
[01:01:40.440 --> 01:01:42.440]  плюс i процент m.
[01:01:42.440 --> 01:01:44.440]  То есть,
[01:01:44.440 --> 01:01:46.440]  у меня есть какое-то х значение
[01:01:46.440 --> 01:01:48.440]  х, и чтобы попытаться
[01:01:48.440 --> 01:01:50.440]  его положить в х таблицу, или чтобы найти, где он там
[01:01:50.440 --> 01:01:52.440]  лежит, я сначала смотрю в клетку
[01:01:52.440 --> 01:01:54.440]  h от x, потом в h тк плюс 1, h тк плюс 2,
[01:01:54.440 --> 01:01:56.440]  и так далее, и так далее. По модуле
[01:01:56.440 --> 01:01:58.440]  значит, что если я дошел до конца, то я начинаю сначала.
[01:01:58.440 --> 01:02:00.440]  Мне же нужно его куда-то положить. То есть, если дошел
[01:02:00.440 --> 01:02:02.440]  до конца, то я начинаю опять с нулевых элементов.
[01:02:02.440 --> 01:02:04.440]  Ну а run это значит,
[01:02:04.440 --> 01:02:06.440]  что я бегу слева направо в поисках вот как раз первой
[01:02:06.440 --> 01:02:08.440]  свободной клетки.
[01:02:08.440 --> 01:02:10.440]  Итак, если
[01:02:10.440 --> 01:02:12.440]  семейство
[01:02:12.440 --> 01:02:14.440]  h
[01:02:14.440 --> 01:02:16.440]  является 5 независимым,
[01:02:20.440 --> 01:02:22.440]  то
[01:02:24.440 --> 01:02:26.440]  амортизированное
[01:02:26.440 --> 01:02:28.440]  математическое ожидание
[01:02:30.440 --> 01:02:32.440]  времени обработки каждого запроса
[01:02:32.440 --> 01:02:34.440]  есть от 1.
[01:02:40.440 --> 01:02:42.440]  Звездочку
[01:02:42.440 --> 01:02:44.440]  тоже дорисую, чтобы
[01:02:44.440 --> 01:02:46.440]  подчеркнуть, что амортизированное.
[01:02:46.440 --> 01:02:48.440]  Вот, и здесь
[01:02:48.440 --> 01:02:50.440]  уже нам нужно более сильные условия.
[01:02:50.440 --> 01:02:52.440]  То есть, в цепочках нам было достаточно
[01:02:52.440 --> 01:02:54.440]  универсальности, а здесь нужна 5 независимость.
[01:02:54.440 --> 01:02:56.440]  То есть, скорее всего,
[01:02:56.440 --> 01:02:58.440]  на практике вам достаточно
[01:02:58.440 --> 01:03:00.440]  и универсальности, чтобы у вас
[01:03:00.440 --> 01:03:02.440]  было достаточно быстро.
[01:03:02.440 --> 01:03:04.440]  Но теоретически умеют доказывать только,
[01:03:04.440 --> 01:03:06.440]  что если оно 5 независимое, то получается
[01:03:06.440 --> 01:03:08.440]  единица на запрос.
[01:03:08.440 --> 01:03:10.440]  То есть, скорее всего, на практике вам
[01:03:10.440 --> 01:03:12.440]  подойдет почти любое семейство,
[01:03:12.440 --> 01:03:14.440]  ну, такое адекватное, как вот было
[01:03:14.440 --> 01:03:16.440]  с a и x плюс b.
[01:03:16.440 --> 01:03:18.440]  Но, еще раз, с точки зрения теории,
[01:03:18.440 --> 01:03:20.440]  вот здесь умеют доказывать только, что
[01:03:20.440 --> 01:03:22.440]  если оно 5 независимое.
[01:03:22.440 --> 01:03:24.440]  Так, что-то еще
[01:03:24.440 --> 01:03:26.440]  хотел сказать.
[01:03:26.440 --> 01:03:28.440]  5 независимое.
[01:03:28.440 --> 01:03:30.440]  А, да, как
[01:03:30.440 --> 01:03:32.440]  такие семейства можно, например, строить?
[01:03:32.440 --> 01:03:34.440]  Ну, смотрите, вот это вот то, что у нас было
[01:03:34.440 --> 01:03:36.440]  a и x плюс b, оно на самом деле 2 независимое.
[01:03:36.440 --> 01:03:38.440]  А x плюс b по модулю m,
[01:03:38.440 --> 01:03:40.440]  оно на самом деле было
[01:03:40.440 --> 01:03:42.440]  2 независимое.
[01:03:42.440 --> 01:03:44.440]  А если мы возьмем вот здесь вот не ленинный многочлен,
[01:03:44.440 --> 01:03:46.440]  а многочлен на четвертой степени от x,
[01:03:46.440 --> 01:03:48.440]  то у нас получится уже 5 независимое
[01:03:48.440 --> 01:03:50.440]  семейство. То есть, если мы будем
[01:03:50.440 --> 01:03:52.440]  считать не ленинную функцию,
[01:03:52.440 --> 01:03:54.440]  а функцию четвертой степени,
[01:03:54.440 --> 01:03:56.440]  вот такую вот,
[01:03:56.440 --> 01:03:58.440]  так, c d e
[01:03:58.440 --> 01:04:00.440]  по модулю m,
[01:04:00.440 --> 01:04:02.440]  то это уже будет 5 независимое
[01:04:02.440 --> 01:04:04.440]  семейство.
[01:04:06.440 --> 01:04:08.440]  Ну и интуитивно это означает следующее,
[01:04:08.440 --> 01:04:10.440]  что, если вы знаете значение
[01:04:10.440 --> 01:04:12.440]  многочлена в четвертой степени
[01:04:12.440 --> 01:04:14.440]  в четырех точках,
[01:04:14.440 --> 01:04:16.440]  то про значения его в пятой точке
[01:04:16.440 --> 01:04:18.440]  вы ничего сказать не можете, потому что
[01:04:18.440 --> 01:04:19.440]  четвертая степень определяется только
[01:04:19.440 --> 01:04:21.440]  по 5 точкам.
[01:04:21.440 --> 01:04:23.440]  Зная значение этого многочлена в четырех точках
[01:04:23.440 --> 01:04:25.440]  про значение в пятой точке вы не можете сказать
[01:04:25.440 --> 01:04:27.440]  ровным счетом ничего, потому что
[01:04:27.440 --> 01:04:28.440]  многочлен однозначно определяется
[01:04:28.440 --> 01:04:30.440]  только по 5 точкам.
[01:04:30.440 --> 01:04:32.440]  Нагочлен в четвертой степени
[01:04:32.440 --> 01:04:34.440]  однозначно определяется 5 точками.
[01:04:34.440 --> 01:04:44.440]  Поэтому, в принципе, это не бог весть какое ограничение, можно, в принципе, если вы хотите быть уверенными, что у вас все работает за единицу, то можно вместо такой хеш-функции использовать такую.
[01:04:44.440 --> 01:04:52.440]  Да, тут чуть дольше считать, но не сильно больше, не сильно это страшнее.
[01:04:52.440 --> 01:04:57.440]  Вот это пролинейное пробирование, когда мы просто идем слева-направо с шагом 1.
[01:04:57.440 --> 01:05:02.440]  Есть еще другие пробирования, значит, есть квадратичные пробирования.
[01:05:09.440 --> 01:05:14.440]  Ну, еще раз, это качественное объяснение, понятно, что там нужно повозиться.
[01:05:14.440 --> 01:05:21.440]  Да, то есть формально нам надо было бы не брать по моделю M, тогда бы все однозначно задавалось.
[01:05:21.440 --> 01:05:26.440]  Но еще раз, это такое объяснение на пальцах, почему это семейство 5 независимое.
[01:05:26.440 --> 01:05:35.440]  Не претендую на то, что это полная доказательств, но вот идея такая, квадратичная пробирование.
[01:05:38.440 --> 01:05:46.440]  Ну, здесь формула для рана такая, h от x плюс i квадрат по моделю M.
[01:05:46.440 --> 01:05:53.440]  То есть если раньше мы шли точка, следующая, после следующей и так далее, просто слева-направо с шагом 1, то здесь мы будем делать так.
[01:05:53.440 --> 01:06:03.440]  Сначала мы пытаемся положить x в точку h от x, потом h от x плюс 1, потом h от x плюс 4, потом плюс 9, ну и так далее.
[01:06:07.440 --> 01:06:10.440]  Почему это, не знаю, хоть сколько это осмысленно, зачем так делать?
[01:06:10.440 --> 01:06:20.440]  Ну, например, потому что если у вас есть какие-то два ключа с похожими хэж значениями, например, у вас есть ключ, у которого хэж вот такой, есть ключ, у которого хэж вот такой,
[01:06:20.440 --> 01:06:25.440]  то мы, наверное, хотим, чтобы их вот эти раны были не совпадающими.
[01:06:25.440 --> 01:06:32.440]  Потому что раньше, когда у меня было линейное пробирование, и было два элемента с соседними хэшами, h от x и h от x плюс 1, то у них раны одинаковые.
[01:06:32.440 --> 01:06:35.440]  Мы встаем и просто идем слева-направо, пока не встретим первую свободную клетку.
[01:06:36.440 --> 01:06:45.440]  И в смысле цепочек, это как бы означает, что у меня две цепочки склеились в одну, x и x плюс 1, по сути они склеились в один длинный ряд до первой свободной клетки.
[01:06:45.440 --> 01:06:54.440]  А здесь у меня как бы вот эта вот цепочка x и вот эта цепочка, они на самом деле разделяют только один общий элемент,
[01:06:54.440 --> 01:07:02.440]  потому что здесь прыжки будут h от x плюс 2, h от x плюс 5, то есть вот эти вот, получается, ну и так далее.
[01:07:02.440 --> 01:07:04.440]  То есть они пересекаться не будут.
[01:07:05.440 --> 01:07:09.440]  И есть еще более хорошее, есть двойное хэширование.
[01:07:16.440 --> 01:07:20.440]  Это когда у вас есть две хэш-функции, h1 и h2.
[01:07:23.440 --> 01:07:31.440]  И вы говорите, что run it, это h1 от x плюс i на h2 от x.
[01:07:35.440 --> 01:07:45.440]  Соответственно, прыжки у вас все одинаковые длины, но длина этого прыжка зависит от значения хэш-функций в x, точнее равна просто h2 от x.
[01:07:46.440 --> 01:07:48.440]  Просто равна h2 от x.
[01:07:48.440 --> 01:08:00.440]  Вот, но это опять то же самое, что если у вас два товарища попали в соседние ячейки, то есть у них хэш значения по первой функции отличается на единицу,
[01:08:00.440 --> 01:08:08.440]  то скорее всего у них h2 разные, ну там сильно разные, тоже неформально, но грубо говоря, если у них близкие h1, то у них скорее всего различные h2.
[01:08:08.440 --> 01:08:12.440]  И поэтому у них вот эти скачки будут не пересекаться.
[01:08:13.440 --> 01:08:19.440]  И для вот этого двойного хэширования на самом деле достаточно два независимости, тогда результат будет точно такой же.
[01:08:20.440 --> 01:08:30.440]  Теорема опять без доказательства, что для двойного хэширования достаточно два независимости.
[01:08:35.440 --> 01:08:39.440]  Тогда будет опять-таки выполняться, что амортизированным от ожиданий это единица.
[01:08:43.440 --> 01:08:45.440]  Для квадратичного я не знаю результатов.
[01:08:48.440 --> 01:08:55.440]  Вот, то есть лучше всего, то есть тут понятно нужно какое-то более сильное условие, а здесь подойдет наше на самом деле просто ax плюс b.
[01:08:55.440 --> 01:09:03.440]  Поэтому лучше всего, если вы хотите написать открытую адресацию, делать следующее, завести семейство хэш-функций, скажем вот такое, вот такое нам подойдет,
[01:09:03.440 --> 01:09:16.440]  и делать двойное хэширование, то есть для того, чтобы положить x в нашу таблицу, мы сначала считаем h1 от x, потом прыгаем с шагом длины h2 от x в поисках первой свободной клетки и туда его вставляем.
[01:09:18.440 --> 01:09:19.440]  Вопросы?
[01:09:24.440 --> 01:09:26.440]  Хорошо, ну и тогда последний обзорный кусок.
[01:09:34.440 --> 01:09:38.440]  Последний обзорный кусок это фильтр Блума.
[01:09:46.440 --> 01:09:47.440]  Фильтр Блума.
[01:09:47.440 --> 01:10:06.440]  Тут опять все то же самое, что и в обычных хэш-таблице нам нужно вставлять. Нет, сейчас, момент. Да, тут не будет удаления, тут будет только вставка и проверка наличия, insert и find.
[01:10:06.440 --> 01:10:32.440]  Вот, но мы хотим работать супер быстро, но при этом возможно иногда ошибаться. Позволим себе неправильно отвечать на запросы типа find.
[01:10:37.440 --> 01:10:38.440]  Find x.
[01:10:42.440 --> 01:10:44.440]  Вот это в принципе не очень страшно.
[01:10:45.440 --> 01:10:54.440]  По следующей причине. Что мы им конкретно разрешим себе? Мы разрешим себе так называемое false positive.
[01:10:59.440 --> 01:11:04.440]  То есть когда мы ложно возвращаем, что элемент есть в таблице, его на самом деле нет, а мы ложно сообщаем, что он есть.
[01:11:05.440 --> 01:11:10.440]  False, то есть говорим ложь, при этом говорим, что ответ да, что x есть в таблице, false positive.
[01:11:11.440 --> 01:11:15.440]  Вот, и разрешаем мы это себе с некоторой небольшой вероятностью epsilon.
[01:11:17.440 --> 01:11:24.440]  Формально мы хотим от структуры следующее, чтобы мы умели туда вставлять и проверять наличие со следующими условиями.
[01:11:25.440 --> 01:11:39.440]  Что если x в таблице, то мы обязательно говорим да, мы для x-ов, лежащих в таблице, всегда говорим правильный ответ, а для x-ов не в таблице, не лежащих в множестве, мы можем ошибиться, то есть выдать неправильный ответ, что он там есть, хотя на самом деле его нет.
[01:11:40.440 --> 01:11:48.440]  То есть мы можем выдать false positive с некоторой маленькой вероятностью epsilon, ну там, один процент или какие-то десятые доли процента, например.
[01:11:49.440 --> 01:11:52.440]  Тогда работает следующая интересная структура.
[01:11:52.440 --> 01:11:54.440]  Работает такая структура.
[01:11:55.440 --> 01:12:05.440]  Значит, давайте мы выберем k hash функций и заведем один массив длины m из нулей единиц.
[01:12:06.440 --> 01:12:08.440]  Массив bit.
[01:12:09.440 --> 01:12:11.440]  Массив bit.
[01:12:11.440 --> 01:12:21.440]  Тогда чтобы вставить какой-то элемент, insert x, чтобы сделать, давайте мы посчитаем его hash значения от всех k функций и поставим единицы во все вот эти вот коклетки.
[01:12:22.440 --> 01:12:28.440]  То есть вот я взял x, посчитал от него h1 от x, поставил сюда единицу, изначально считаю, что все нули.
[01:12:28.440 --> 01:12:35.440]  Дальше посчитал h2 от x, поставил сюда единицу, посчитал h3 от x, поставил сюда единицу и так далее.
[01:12:36.440 --> 01:12:41.440]  То есть для того, чтобы вставить x, я прохожусь по всем моим k функциям и ставлю единички в теме 100, которые они посчитали.
[01:12:42.440 --> 01:12:46.440]  Ставлю единички в теме 100, ну в общем, в значениях hash функций.
[01:12:47.440 --> 01:12:53.440]  Вот тогда это работает, ну, понятное дело, за от k, за количество хеш функций.
[01:12:54.440 --> 01:13:01.440]  Дальше, чтобы проверить наличие x, давайте я просто опять посчитаю от него все моих к hash функций и проверю, что здесь везде стоит единица.
[01:13:02.440 --> 01:13:04.440]  Проверю, что здесь везде стоит единица.
[01:13:04.440 --> 01:13:10.280]  за от k, за количество хэш-функций. Дальше, чтобы проверить наличие х, давайте я просто
[01:13:10.280 --> 01:13:14.440]  опять посчитаю от него все мои хэш-функции и проверю, что здесь везде стоит единица.
[01:13:14.440 --> 01:13:21.000]  Понятно, что если х лежит в таблице, то обязательно на этих местах единица, а если он не
[01:13:21.000 --> 01:13:26.560]  лежит в таблице, то, возможно, мы себя обманули. То есть вполне может быть такое, что там какие-то
[01:13:26.560 --> 01:13:32.200]  единицы пришли от y, какая-то единица пришла от z, и тем не менее вот эти все три единицы
[01:13:32.200 --> 01:13:36.960]  выставлены, и мы как бы считаем, что х тоже есть. Это, понятное дело, ошибка, но такое будет
[01:13:36.960 --> 01:13:43.120]  происходить редко. Если наши хэш-функции случайны, m достаточно велико по сравнению с числом ключей,
[01:13:43.120 --> 01:13:53.400]  то такое будет происходить редко. Идея такая, что давайте я пропишу, как мы делаем все операции,
[01:13:53.400 --> 01:14:05.640]  insert x. По всем i от одного дока мы выполняем просто, давайте a от h i t от x равно единице.
[01:14:05.640 --> 01:14:09.000]  Мы выставляем bit с номером h i t от x единицей.
[01:14:23.400 --> 01:14:36.440]  Find работает так. Мы проходим опять-таки по всем этим ячейкам и проверяем, что они все единицы.
[01:14:36.440 --> 01:14:55.400]  Давайте я напишу вот так ans равно true for i от одного до k ans ant равно a h i t от x return ans.
[01:14:55.400 --> 01:15:10.720]  То есть я пробегаюсь по всем k ячейкам по значениям х от x, проверяю, что они все единицы,
[01:15:10.720 --> 01:15:14.680]  соответственно, если они все единицы, то вернется единица, если хоть кто-то ноль, то вернется ноль.
[01:15:14.680 --> 01:15:22.600]  Вот, и действительно получается, что если х лежит в таблице, лежит в фильтре, давайте напишу,
[01:15:22.600 --> 01:15:41.000]  если х лежит в фильтре, то find точно вернет true, то find точно вернет true, иначе с неплохой вероятностью вернет false.
[01:15:41.880 --> 01:15:49.640]  Иначе, давайте напишу наоборот, ошибется с маленькой вероятностью.
[01:15:49.640 --> 01:15:55.400]  Я не лезу в детали того, почему она маленькая, почему она равна, но на пальцах вот действительно,
[01:15:55.400 --> 01:16:02.360]  что если у нас много, ну там не много, а скорее m достаточно велико, мы случайные точки разбрасываем эти единицы,
[01:16:02.360 --> 01:16:08.360]  то вряд ли уж для кого-то х, которого мы не добавляли, все вот эти вот k значения будут истинными.
[01:16:08.360 --> 01:16:12.520]  Это очень неформально, но как бы качественно, качественно вот так.
[01:16:12.520 --> 01:16:30.360]  Так, хорошо, ну и вот давайте, да, еще раз, ну вот так себе он поддерживается, да, я поэтому его и не дал,
[01:16:30.360 --> 01:16:36.360]  потому что, не, ну вообще пересечения, конечно, бывают, то есть скажем, значения х функции от х,
[01:16:36.360 --> 01:16:42.360]  а значения х функции от у могут вполне себе пересекаться, если мы вот это затрем, то мы в частности удалим у,
[01:16:42.360 --> 01:16:50.360]  а это, ну в том смысле, что по крайней мере у нас будет тогда и false негатив, что возможно иногда мы,
[01:16:50.360 --> 01:16:56.360]  если мы сотрем вот эти единицы, то мы для у тоже ошибемся.
[01:16:56.360 --> 01:17:04.360]  Ну вот, вот в этой структуре вот именно такая постановка, мы ничего не удаляем, мы только, иногда можем выдавать false позитив, все.
[01:17:04.360 --> 01:17:07.360]  Сейчас я приведу примеры, зачем это может быть нужно.
[01:17:07.360 --> 01:17:13.360]  Итак, что я хотел сказать, а, я хотел написать формулы, какие оптимально здесь выбирать.
[01:17:19.360 --> 01:17:25.360]  Так, тут я спешу, это тоже заучивать не надо, просто чтобы понимать порядок вот этих величин.
[01:17:25.360 --> 01:17:44.360]  Если вставляется н ключи, то оптимально, а, и мы хотим, мы еще фиксируем false позитив rate,
[01:17:44.360 --> 01:18:03.360]  а ошибаться можно с вероятностью небольшим эпсилон, вот так.
[01:18:03.360 --> 01:18:09.360]  То есть мы фиксировали число ключей и фиксировали вот этот процент погрешности, с какой вероятностью можем ошибаться.
[01:18:09.360 --> 01:18:14.360]  То, что оптимально выбрать.
[01:18:14.360 --> 01:18:42.360]  Вот так.
[01:18:42.360 --> 01:18:49.360]  То есть M пропорционально числу ставленных ключей, но еще растет по мере того, как убывает эпсилон.
[01:18:49.360 --> 01:18:55.360]  Понятно, что чем меньше эпсилон, тем больше нужна нам точность, соответственно, тем возрастает 1 делит на эпсилон.
[01:18:55.360 --> 01:18:57.360]  Поэтому растет логарифм.
[01:18:57.360 --> 01:19:01.360]  Чем меньше эпсилон, тем больше вот этот логарифм 1 делит на эпсилон.
[01:19:01.360 --> 01:19:10.360]  Ну и с K то же самое, что чем больше нужна точность, тем больше нам нужно выбрать х-функции.
[01:19:10.360 --> 01:19:19.360]  То есть логарифм 2 здесь, здесь логарифм 2 в квадрате.
[01:19:19.360 --> 01:19:25.360]  Тогда получается, что время ответа на все запросы это от K.
[01:19:25.360 --> 01:19:37.360]  Время ответа на запрос это всегда есть от K, потому что, ну просто смотрим на вот эти два кусочка кода,
[01:19:37.360 --> 01:19:41.360]  как х-функции считаем, тут выставляем единицы, там берем and к значениям.
[01:19:41.360 --> 01:19:48.360]  Это от K, но с точки зрения эпсилона это логарифм 1 делит на эпсилон.
[01:19:48.360 --> 01:19:52.360]  Вот.
[01:19:52.360 --> 01:19:57.360]  Такая вот структура. Зачем она может быть нужна?
[01:19:57.360 --> 01:19:59.360]  Зачем она может быть нужна?
[01:19:59.360 --> 01:20:06.360]  Ну, например, чтобы создавать там какие-нибудь базы, спам почт или, наоборот, вайт-листы почт.
[01:20:06.360 --> 01:20:10.360]  То есть вы сидите там на какой-нибудь почте, который скоро заблокирует,
[01:20:10.360 --> 01:20:17.360]  и хотите фильтровать сообщения со спам-ящиков.
[01:20:17.360 --> 01:20:23.360]  Тогда, смотрите, вы хотите, чтобы, например...
[01:20:23.360 --> 01:20:28.360]  Ну да, например, вы хотите создать фильтр спам-ящиков, спам-адресов,
[01:20:28.360 --> 01:20:32.360]  и тогда уметь туда вставлять и запрашивать find.
[01:20:32.360 --> 01:20:35.360]  То есть вам какое-то пришло письмо, вы хотите понять, оно спам или нет.
[01:20:35.360 --> 01:20:40.360]  Тогда вы берете адрес этого письма отправителя, задаете запрос к фильтру.
[01:20:40.360 --> 01:20:44.360]  Если он говорит да, то скорее всего это спам, если нет, то, скорее всего, нормальное письмо.
[01:20:44.360 --> 01:20:47.360]  То есть если нет, то, точнее, точно нормальное письмо.
[01:20:47.360 --> 01:20:52.360]  И если у вас эпсилон достаточно маленькая, там десятая доля процента,
[01:20:52.360 --> 01:20:56.360]  то вы почти все, точнее, вы все спам-письма точно удалите
[01:20:56.360 --> 01:21:01.360]  и удалите небольшую долю нормальных писем от нормальных людей.
[01:21:02.360 --> 01:21:07.360]  Ну, тогда лучше наоборот, конечно. Можно наоборот создать, получается, вайт-лист ящиков.
[01:21:07.360 --> 01:21:10.360]  Для нормальных ящиков вы точно получите от них сообщения
[01:21:10.360 --> 01:21:16.360]  и еще небольшую долю от спам-адресов.
[01:21:22.360 --> 01:21:28.360]  Ну вот в этом и проблема, что скорее вы можете легко добавить спам в какой-то фильтр,
[01:21:28.360 --> 01:21:33.360]  в спам-фильтр, чем нормальный ящик добавить, потому что вы не сможете от него получить.
[01:21:33.360 --> 01:21:38.360]  Ну вот, тут, короче, надо выбирать, что либо вы какие-то нормальные письма ударяете,
[01:21:38.360 --> 01:21:47.360]  либо вам нужно еще заморачиваться с ставкой новых адресов, которых никогда не было.
[01:21:47.360 --> 01:21:52.360]  Ну вот, тогда, наверное, на этом давайте закончим. Всем успехов!
