[00:00.000 --> 00:14.920]  Итак, доброе утро. В прошлый раз сами определили, что такое линейное пространство и линейное
[00:14.920 --> 00:23.240]  подпространство и остановились на вопросе, что такое линейная оболочка. Напоминаю,
[00:23.240 --> 00:34.240]  что по определению, я повторю на всякий случай, линейная оболочка какого-то подпрошества m,
[00:34.240 --> 00:43.800]  она определяется, она обозначается вот таким вот образом, м в угловых скобках, и это есть
[00:43.800 --> 00:51.360]  пересечение всех подпространств, меньше или равно мы обозначаем именно подпространство,
[00:51.360 --> 01:02.440]  которое содержит m. Ну и мы с вами сказали, что по сути дела это наименьшее подпространство,
[01:02.440 --> 01:14.280]  которое содержит m. Вот очень часто у нас будут такие понятия возникать, в большинстве случаев
[01:14.280 --> 01:25.040]  такое понятие допускают посредственное описание и вот сейчас тоже. Так, давайте прежде чем я напишу
[01:25.040 --> 01:36.040]  теорему, давайте я сделаю замечание и спрошу, а что такое линейная оболочка пустого множества?
[01:42.040 --> 01:43.840]  То есть пересечение просто таки
[01:47.680 --> 01:54.840]  всех подпространств, правильно? В пространстве v. Что это такое, какое самое маленькое подпространство
[01:54.840 --> 02:11.240]  v? Никто мне не может сказать. Если какой-нибудь элемент вообще во всех подпространствах в 0,
[02:11.240 --> 02:19.240]  правильно? Вектор содержится в любом подпространстве, мы это с вами знаем, потому что
[02:19.240 --> 02:26.440]  нейтральный элемент содержится в подгруппе, правильно? Ну а кроме того там ничего и нет,
[02:26.440 --> 02:38.240]  потому что вектор сам по себе, множество из одного нулевого, извините, вектора само по себе
[02:38.240 --> 02:45.040]  является подпространством. Если мы будем складывать его элементы или умножать их на констанцию,
[02:45.040 --> 02:54.240]  то на скаляр, то будем получать его же. Значит это он и есть, нулевое подпространство, самое маленькое
[02:54.240 --> 03:03.720]  подпространство v, ну линейная оболочка пустого множества, это оно и есть. Так вот теперь общая теорема,
[03:03.720 --> 03:20.000]  значит пусть v это линейное пространство над полем f, m это произвольное под множество v,
[03:20.000 --> 03:31.320]  тогда линейная оболочка множества m это не что иное, как, давайте я сначала напишу формулу,
[03:31.520 --> 03:51.240]  а потом мы проинтерпретируем множество всех вот таких вот выражений. То есть множество,
[03:51.240 --> 04:02.760]  как мы это скажем, линейных комбинаций элементов из m. Обратите, пожалуйста, внимание, вот тут у нас
[04:02.760 --> 04:08.800]  появляется некоторое число k, но не зафиксировано, то есть мы можем брать совершенно произвольное,
[04:08.800 --> 04:17.920]  мы можем брать любой конечный набор элементов из m и брать произвольную его линейную комбинацию
[04:17.920 --> 04:26.080]  с коэффициентами произвольными скалярами из m. Вот говорят, что все эти линейные комбинации
[04:26.080 --> 04:41.880]  и образуют в точности линейную оболочку множества m. Давайте доказывать, ну для доказательства давайте
[04:41.880 --> 04:53.600]  мы обозначим правую часть через u и тогда нам нужно, как обычно, чтобы доказать, что два множества
[04:53.600 --> 05:04.160]  равны, очень часто мы показываем, что одно содержится в другом и другое содержится в первом. Вот давайте
[05:04.160 --> 05:18.560]  мы для этого первым делом поймем, что то, что у нас написано справа, само по себе является под пространством v.
[05:18.560 --> 05:30.000]  То есть вот такое множество линейных комбинаций это под пространство. Ну действительно, во-первых,
[05:30.000 --> 05:42.880]  оно пусто, ибо в нем точно содержится ноль. Мы, как обычно, вот стандартное соглашение. Что такое
[05:42.880 --> 05:56.000]  сумма нуля элементов? Сумма пустого множества элементов это что такое? Ну нейтральный элемент,
[05:56.000 --> 06:04.160]  то есть нолик. То есть даже если мы возьмем просто линейную комбинацию пустого множества векторов,
[06:04.160 --> 06:16.880]  мы все равно получим ноль. Этот ноль там просто по определению лежит. Ну а дальше, если u1 и u2
[06:16.960 --> 06:24.800]  содержатся в u, то есть если u1 и u2 являются линейными комбинациями элементов множества f,
[06:24.800 --> 06:37.040]  то естественно u1-u2 тоже будет там лежать, ну потому что мы просто сложим эти две линейных
[06:37.040 --> 06:47.600]  комбинации, правильно? Минус u1 тоже будет лежать в u по тем же самым причинам. Если мы возьмем
[06:47.600 --> 06:53.840]  минус такую линейную комбинацию, это что означает? Я просто должен на минус 1 все коэффициенты,
[06:53.840 --> 07:01.080]  правильно? И тоже получится линейная комбинация элементов множества m. Эти два существа,
[07:01.080 --> 07:09.560]  напоминаю, уже говорят нам, что u это подгруппа в, ну а чтобы проверить, что оно пространство,
[07:09.560 --> 07:20.160]  что нам нужно же еще проверить, что оно выдерживает умножение на скаляр, правильно? И для любого
[07:20.160 --> 07:29.160]  альфа на u1 также лежит в u. Если мы альфу умножим на вот эту линейную комбинацию,
[07:29.160 --> 07:37.160]  это что такое? То же самое, что умножить альфу на каждый коэффициент, правильно? Значит,
[07:37.160 --> 07:43.360]  я напоминаю сразу, что вот сейчас мы существенно пользуемся теми свойствами линейного пространства,
[07:43.360 --> 07:50.960]  которые мы с вами выписали. То есть вот давайте я, например, вот это вот свойство проверю,
[07:50.960 --> 08:01.600]  чтобы пояснить этот момент. Если я альфу умножаю на сумму альфа линейных веитых,
[08:01.600 --> 08:10.480]  это что означает? Это я могу альфу умножить на каждый линейный коэффициент, и это одно из
[08:10.480 --> 08:16.200]  свойств, одна из доказательств нашего линейного пространства, что скаляр умножить на сумму
[08:16.200 --> 08:21.920]  нескольких векторов, это сумма каждого из этих векторов, умноженного на скаляр. То есть я говорю,
[08:21.920 --> 08:28.280]  что эта сумма по и от 1 до k альфа умножить на альфа итые веитые, вот я одной аксиомой вот
[08:28.280 --> 08:34.520]  пользуюсь, правильно? А после этого другая аксиома говорит, что если я вектор умножаю на одну,
[08:34.520 --> 08:39.760]  на один скаляр, а потом на другой скаляр, это то же самое, что я умножаю на произведение этих
[08:39.760 --> 08:47.520]  скаляров, правильно? Альфа альфа итые умножить на выитые. И вот теперь мы уже получили снова
[08:47.520 --> 08:53.320]  линейную комбинацию элементов нашего множества. Ну вот так же совсем формально можно проверить и
[08:53.320 --> 09:01.920]  остальные свойства, я предлагаю каждому, кто не уверен в том, что это так, это проделать. Итак,
[09:02.000 --> 09:11.440]  мы с вами получили, давайте разбираться. У это подпространство в В, не просто подноюство,
[09:11.440 --> 09:26.160]  а подпространство. Ну и естественно в У содержится М. Почему? Потому что каждый элемент является такой
[09:26.160 --> 09:34.080]  линейной комбинации. Мы его умножим на единичку, а остальных брать не будем. Правда? У содержится М.
[09:34.080 --> 09:45.400]  Значит, в частности, это самое У участвует в этом определении. Оно является пространством,
[09:45.400 --> 09:55.600]  и оно содержит М, правильно? Значит, мы в частности уже получили, что линейная оболочка М содержится
[09:55.600 --> 10:18.720]  У. Наоборот, если я возьму какое-то пространство В, которое содержит М, то для любых скаляров,
[10:18.720 --> 10:29.040]  если я выберу любые скаляры из Ф и выберу любые элементы из М, то вот такая вот линейная комбинация
[10:29.040 --> 10:40.680]  также будет лежать в У-штрих. Просто потому что если я подпространство, если в нем лежат все эти ВИ,
[10:40.680 --> 10:47.520]  то в нем будут лежать и все вот такие вот произведения альфаито-эновито. Ну а значит,
[10:47.520 --> 10:53.480]  их сумма тоже будет лежать, потому что подпространство замкнуто относительно всех этих операций.
[10:53.480 --> 11:01.880]  И таким образом мы получаем, что в произвольном таком У-штрих, извините, вот здесь У-штрих, конечно же,
[11:01.880 --> 11:08.600]  должно содержать М, да? В произвольном таком У-штрих, который содержит М, мы получаем,
[11:08.600 --> 11:17.800]  что У тоже содержится. Ну а значит, когда мы здесь будем пересекать все такие,
[11:17.800 --> 11:23.840]  давайте я ради ясности здесь У-штрих, потому что У у нас уже фиксированное подпространство,
[11:23.840 --> 11:32.040]  когда мы будем пересекать все такие У-штрих, У тоже будет содержаться. То есть это означает,
[11:32.040 --> 11:39.960]  что У держится вот в этом пересечении, то есть в линейной оболочке. Все, мы нашу теорему доказали,
[11:39.960 --> 11:46.520]  мы поняли, что каждый из этих двух подмножеств содержится в другом, а значит они совпадают.
[11:46.520 --> 11:53.080]  Ну и таким образом, еще раз повторюсь, мы доказали, то есть мы можем пользоваться
[11:53.080 --> 11:59.640]  любым из этих двух определений, по сути дела. Либо линейная оболочка множества это вот такое
[11:59.640 --> 12:06.400]  пересечение, либо линейная оболочка множества это просто множество всех линейных комбинаций
[12:06.400 --> 12:21.800]  элементов из этого множества. Следующее определение, которое мы в частном виде уже видели,
[12:21.800 --> 12:36.920]  это определение базица пространства. Итак, пусть В это линейное пространство над F, тогда система
[12:36.920 --> 12:47.920]  векторов, которую мы будем чаще всего опять обозначить через Е, Е1 и так далее, ЕН,
[12:47.920 --> 13:08.560]  где все ЕИТ, это элементы В, называются базисом, если выполнены все те же самые два свойства,
[13:08.560 --> 13:18.880]  которые мы уже в свое время называли. Первых, это система линейно-независима, ни один ее элемент
[13:18.880 --> 13:25.240]  не выражается через другие, или что-то то же самое, не тривиальная их линейная комбинация, не давна нулю.
[13:25.240 --> 13:34.480]  И при этом, как у нас там было второе условие, что все векты выражаются через Е, правильно?
[13:34.480 --> 13:40.480]  И с учетом того, что мы только что говорили, как это можно переформулировать второе условие?
[13:40.480 --> 13:51.480]  Именно так, линейная оболочка Е, это как раз точность множества всех линейных комбинаций этих векторов,
[13:51.480 --> 14:08.480]  линейная оболочка Е равна В. Базис, вот такое вот понятие. Я сразу хочу сказать, что мы сейчас с вами
[14:08.480 --> 14:19.480]  дали определение базиса для конечной системы В, потому что мы с вами во всяком случае в этом учебном году
[14:19.480 --> 14:29.480]  в основном будем работать с пространствами, у которых есть такой базис. Такие пространства, ну вот сейчас мы поговорим про такие пространства.
[14:29.480 --> 14:35.480]  В принципе, можно дать такое же определение и для бесконечного множества.
[14:35.480 --> 15:03.480]  Замечание, порой это определение нужно обобщить на бесконечную систему векторов.
[15:03.480 --> 15:11.480]  Иногда полезно говорить и про бесконечный базис в пространстве, в котором конечного базиса не будет.
[15:11.480 --> 15:20.480]  Ну вот об этом мы скоро поговорим. Мы сейчас этого делать не будем и говорить про бесконечные базисы в пространствах не будет,
[15:20.480 --> 15:29.480]  но вот я делаю замечание, что это возможно. Там только стоит сказать, вот в этой ситуации, давайте я это проговорю сейчас,
[15:29.480 --> 15:39.480]  что означает, что бесконечная система линейно-независима. Мы же с вами умеем брать только линейные комбинации конечного набора векторов,
[15:39.480 --> 15:49.480]  поэтому когда говорят про бесконечную линейно-независимую систему, имеют в виду, что никакая ее конечная линейная комбинация,
[15:49.480 --> 15:55.480]  то есть мы из этой системы можем выбрать конечный набор векторов и взять их с какими-то коэффициентами,
[15:55.480 --> 16:01.480]  никакая их нетривиальная линейная комбинация конечного набора из них не равна нулю.
[16:01.480 --> 16:07.480]  Вот это вот называется линейной независимостью в более общем случае.
[16:07.480 --> 16:13.480]  И для этого более общего случая тоже верны те утверждения, которые мы сейчас будем доказывать,
[16:13.480 --> 16:18.480]  ну вот я еще раз повторяю, сейчас мы этим заниматься не будем.
[16:18.480 --> 16:23.480]  Итак, то есть для нас базис всегда будет конечным.
[16:23.480 --> 16:38.480]  И я сразу напоминаю, что если E это базис в пространстве V,
[16:38.480 --> 16:46.480]  то для каждого вектора из V, ну вот скажем, если такой базис из N элементов,
[16:46.480 --> 16:58.480]  для каждого вектора из V существует столбец из скаляров такой, что V это E на альфа,
[16:58.480 --> 17:02.480]  то есть линейная комбинация этих векторов с какими-то коэффициентами.
[17:02.480 --> 17:07.480]  Это напрямую написано у нас во втором условии, правильно?
[17:07.480 --> 17:11.480]  Каждый вектор является их линейной комбинацией.
[17:11.480 --> 17:21.480]  Ну и поскольку E линейно независима, линейная независимая система,
[17:21.480 --> 17:27.480]  такой столбец единственен.
[17:27.480 --> 17:37.480]  Дальше-таки мы это с вами уже доказали, доказательства дословно проходят и в этом случае тоже.
[17:37.480 --> 17:43.480]  Каждому вектору соответствует ровно один такой столбец,
[17:43.480 --> 18:02.480]  ну и называется он также альфа, это по-прежнему корридиатный столбец вектора V в базисе E.
[18:02.480 --> 18:10.480]  Ну и обозначение этого понятия будет тем же самым.
[18:10.480 --> 18:15.480]  Так, замечательно, двигаемся дальше.
[18:15.480 --> 18:25.480]  Нам потребуется для того, чтобы описать пространства, в которых есть конечный базис,
[18:25.480 --> 18:31.480]  нам потребуется еще следующее определение.
[18:31.480 --> 18:50.480]  Пусть V это линейное пространство над пулем F, тогда это пространство называется
[18:50.480 --> 19:08.480]  неформально, если оно порождается конечным набором векторов.
[19:08.480 --> 19:11.480]  То есть, если формально, что означает?
[19:11.480 --> 19:22.480]  Существует такое подмноженство V, конечное подмноженство V,
[19:22.480 --> 19:30.480]  что его линейная оболочка это все V.
[19:30.480 --> 19:40.480]  Ну то есть, если вектор из V, можно выразить через конечный набор векторов.
[19:40.480 --> 19:48.480]  Ну и сразу давайте докажем полезное утверждение.
[19:48.480 --> 19:56.480]  Я еще раз это явным образом проговорю, во всяком случае в этом и в следующем семестре
[19:56.480 --> 20:00.480]  мы в основном будем работать именно с такими пространствами,
[20:00.480 --> 20:11.480]  с пространствами, которые порождаются конечным набором векторов.
[20:11.480 --> 20:33.480]  Небольшое утверждение, в любом конечно порожденном линейном пространстве есть базис.
[20:33.480 --> 20:42.480]  Базис, в смысле вот именно, что конечный базис.
[20:42.480 --> 20:45.480]  Доказательства.
[20:45.480 --> 20:49.480]  Давайте пользоваться тем, что оно конечно порождено.
[20:49.480 --> 21:02.480]  Пусть наше пространство V это линейная оболочка конечного набора векторов.
[21:02.480 --> 21:08.480]  Почему этот конечный набор еще не базис?
[21:08.480 --> 21:12.480]  Второе условие для него уже точно выполнено,
[21:12.480 --> 21:18.480]  поэтому может не быть выполнено только первое условие.
[21:18.480 --> 21:29.480]  Если M линейно независимо, то M уже базис.
[21:29.480 --> 21:33.480]  Здесь я допускаю небольшую неформальность,
[21:33.480 --> 21:37.480]  потому что базис – это упорядоченная система векторов.
[21:37.480 --> 21:41.480]  Под множество в принципе не упорядочена, конечно.
[21:41.480 --> 21:47.480]  Но если мы его упорядочим как угодно, то получится уже базис.
[21:47.480 --> 21:57.480]  Иначе, если M линейно независимо, то существует вектор из M,
[21:57.480 --> 22:03.480]  который выражается через остальные векторы в M.
[22:03.480 --> 22:06.480]  Нам это теперь кратко записать.
[22:06.480 --> 22:12.480]  Что означает, что вектор M выражается через остальные векторы?
[22:12.480 --> 22:20.480]  Как записать эту линейную выразимость?
[22:20.480 --> 22:22.480]  Можно так сказать, да.
[22:22.480 --> 22:25.480]  Но я не хочу, чтобы с линейной комбинацией уже писать.
[22:25.480 --> 22:27.480]  У нас есть для этого удобный язык.
[22:27.480 --> 22:31.480]  У нас есть язык линейной оболочки.
[22:31.480 --> 22:34.480]  То есть не базница только, а вот этого множества.
[22:35.480 --> 22:41.480]  Берем все остальные векторы из M и берем их в линейную оболочку.
[22:41.480 --> 22:49.480]  Если вы выражается через остальные векторы, записываем ровно так.
[22:49.480 --> 22:53.480]  Вы лежите в линейной оболочке этих остальных векторов.
[22:53.480 --> 22:56.480]  Ну что это означает?
[22:56.480 --> 23:03.480]  Это означает, что это линейная оболочка без него.
[23:03.480 --> 23:08.480]  Это в точности то же самое, что линейная оболочка M.
[23:08.480 --> 23:17.480]  На любом из этих двух языков, которые мы тут написали, это на самом деле можно понять.
[23:17.480 --> 23:23.480]  Но действительно, если берем произвольную линейную комбинацию векторов из M,
[23:23.480 --> 23:28.480]  если даже в ней участвует V, то мы его можем выразить через остальные векторы.
[23:28.480 --> 23:34.480]  То есть представить ее как линейную комбинацию векторов, не включающих V.
[23:34.480 --> 23:40.480]  На этом языке это тоже можно записать.
[23:40.480 --> 23:45.480]  Потому что если в каком-то подпространстве лежит все M без V, то V в нем тоже лежит.
[23:45.480 --> 23:49.480]  Оно является линейной комбинацией остальных.
[23:49.480 --> 23:55.480]  Значит, когда мы будем представлять эти две линейные оболочки как пересечения подпространств,
[23:55.480 --> 23:58.480]  мы будем пересекать одни и те же подпространства.
[23:58.480 --> 24:03.480]  Ну и значит, эти линейные оболочки совпадают.
[24:03.480 --> 24:07.480]  И мы, что мы с вами нашли?
[24:07.480 --> 24:15.480]  Мы нашли порождающее множество, то есть вот такое вот множество, порождающее все V.
[24:15.480 --> 24:23.480]  Мы нашли порождающее множество меньшей мощности.
[24:26.480 --> 24:30.480]  А именно NsV.
[24:30.480 --> 24:33.480]  Ну тогда можем продолжить процесс.
[24:33.480 --> 24:37.480]  Если это множество линейно-независимо, то мы нашли базис.
[24:37.480 --> 24:42.480]  Если оно линейно-зависимо, мы можем еще один вектор из него выкинуть.
[24:43.480 --> 24:55.480]  Продолжая также далее в итоге придем к базису.
[24:55.480 --> 25:03.480]  Рано или поздно наше порождающее множество станет линейно-независимым.
[25:03.480 --> 25:09.480]  Ну в конце концов, может быть, мы придем к пустому множеству, и тогда оно станет точно линейно-независимым.
[25:09.480 --> 25:13.480]  Скорее всего, это произойдет ранее.
[25:13.480 --> 25:17.480]  Мы придем к линейно-независимому множеству, которое останется порождающим.
[25:17.480 --> 25:20.480]  То есть по-прежнему будет порождать все V.
[25:20.480 --> 25:24.480]  Ну и значит мы придем к базису.
[25:26.480 --> 25:30.480]  Итого мы доказали наше утверждение.
[25:30.480 --> 25:34.480]  На самом деле мы доказали даже большее.
[25:34.480 --> 25:38.480]  Давайте уж мы сформулируем, кое-что мы доказали чуть большее.
[25:38.480 --> 25:49.480]  Мы доказали не просто, что в нашем пространстве существует базис,
[25:49.480 --> 26:03.480]  а что в любом конечном порождающем множестве содержится базис.
[26:03.480 --> 26:11.480]  Потому что мы могли с произвольного порождающего множеству начать этот процесс и в результате прийти к базису.
[26:15.480 --> 26:24.480]  Замечательно. Мы уже поняли, что в всяком случае во всех конечно порожденных пространствах есть базис.
[26:25.480 --> 26:33.480]  И следующий вопрос, который нужно осветить, но мы его пока что осветим не полностью.
[26:35.480 --> 26:40.480]  Надеюсь, что сегодня еще, может быть, доберемся до того, чтобы разобраться с ним до конца.
[26:40.480 --> 26:42.480]  Благо у нас две лекции.
[26:46.480 --> 26:49.480]  Следующее важное понятие.
[26:50.480 --> 27:01.480]  Пусть V1 и V2, это два линейного пространства, над одним и тем же полем F,
[27:01.480 --> 27:20.480]  тогда отображение F из V1 в V2 называется знакомое слово изоморфизмом линейных пространств.
[27:20.480 --> 27:32.480]  Я думаю, что слушатели могут и сами уже дополнить это определение, если что.
[27:38.480 --> 27:40.480]  Какие условия должны быть у FIT?
[27:41.480 --> 27:44.480]  Во-первых, это должна быть BX, правильно.
[27:44.480 --> 27:50.480]  Во-вторых, она должна сохранять операции.
[27:52.480 --> 27:54.480]  Сейчас мы это распишем.
[27:55.480 --> 27:57.480]  Сохраняющие операции.
[27:58.480 --> 28:01.480]  Это вот общее определение изоморфизма.
[28:02.480 --> 28:05.480]  Но давайте мы в данном случае это распишем.
[28:06.480 --> 28:08.480]  Что у нас такое линейное пространство?
[28:08.480 --> 28:12.480]  Это, во-первых, группа A, правильно.
[28:13.480 --> 28:15.480]  То есть, FIT, это должен быть изоморфизм.
[28:18.480 --> 28:19.480]  Групп.
[28:22.480 --> 28:25.480]  V1 плюсом и V2 с плюсом.
[28:26.480 --> 28:29.480]  То есть, сумму векторов оно переводит в сумму.
[28:30.480 --> 28:34.480]  Противоположный вектор по сложению переводит в противоположный вектор по сложению.
[28:35.480 --> 28:44.480]  А еще оно должно сохранять умножение на скаляр.
[28:45.480 --> 28:58.480]  То есть, для любого скаляра из V1 мы должны сказать, что фи от альфа в это то же самое, что альфа на фи от V.
[28:59.480 --> 29:05.480]  Если вектор умножился на скаляр, то и образ этого вектора тоже умножился на скаляр.
[29:07.480 --> 29:20.480]  Ну и, как и раньше, если у вас есть два изоморфных линейных пространства, то любое вычисление в одном из них можно повторить в другом при помощи вот этого самого изоморфизма.
[29:20.480 --> 29:30.480]  То есть, они выглядят с точки зрения вот этих вот линейных операций одинаково.
[29:33.480 --> 29:43.480]  Да, ну и пространства, говорим, V1 и V2 изоморфные.
[29:44.480 --> 29:50.480]  Записывается это, как и раньше, вот так вот.
[29:52.480 --> 29:59.480]  Если между ними есть изоморфизм.
[29:59.480 --> 30:11.480]  Я тут сделаю замечание, которое стоило сделать раньше, когда мы обсуждали изоморфизм групп и так далее.
[30:12.480 --> 30:15.480]  Но давайте хотя бы здесь это замечание сделаем.
[30:16.480 --> 30:19.480]  Оно, естественно, общее, оно работает не только для пространства, но и для других объектов.
[30:20.480 --> 30:29.480]  Если V1 изоморфно V2, то, разумеется, V2 изоморфно V1.
[30:30.480 --> 30:33.480]  Где он, этот второй изоморфизм?
[30:34.480 --> 30:36.480]  Это просто обратное отображение, правильно?
[30:37.480 --> 30:43.480]  Фи у нас биекция, у нее существует обратное отображение, ну и свойства переписываются средства.
[30:43.480 --> 30:51.480]  Например, вот это же самое свойство говорит, и что фи в минус 1 тоже сохраняет умножение на скаляр, естественно.
[30:52.480 --> 30:54.480]  То же самое и с группами.
[30:55.480 --> 31:08.480]  Ну и давайте уж я тогда сразу допишу, что если V1 изоморфно V2, а то изоморфно V3, то V1 изоморфно и V3 тоже,
[31:09.480 --> 31:14.480]  потому что мы можем взять композицию наших изоморфизмов, правильно?
[31:18.480 --> 31:21.480]  Ну и, естественно, каждое пространство изоморфно само себе.
[31:22.480 --> 31:24.480]  Тут изоморфизм строится тривиально.
[31:25.480 --> 31:31.480]  Ну и таким образом, значит, изоморфизм, изоморфность – это отношение эквивалентности.
[31:32.480 --> 31:34.480]  Это, еще раз повторю, общее свойство.
[31:35.480 --> 31:41.480]  Оно работает для любых изоморфизмов, не только для изоморфизмов линейных пространств.
[31:44.480 --> 31:52.480]  Ну и тут сразу возникает вопрос, а как же нам классифицировать наше линейное пространство?
[31:53.480 --> 32:05.480]  Как объявить для каждого из них какой-нибудь канонический представитель этого класса изоморфности?
[32:06.480 --> 32:14.480]  И мы на этот вопрос ответим полностью вскоре, а пока что ответим частично.
[32:15.480 --> 32:36.480]  Итак, утверждение, пусть V – это линейное пространство над F, в котором есть базис E, N элементов.
[32:37.480 --> 32:39.480]  Я его пишу, E1 и так далее.
[32:40.480 --> 32:48.480]  Я напоминаю, что пространство, в котором есть базис, – это в точности, конечно, порожденное пространство,
[32:50.480 --> 32:56.480]  если оно, конечно, порождено, в нем есть базис, если в нем есть базис, то оно, естественно, им порождено.
[32:56.480 --> 33:16.480]  Правильно. Пусть В – это пространство, в котором есть базис Е1 и далее Еn, тогда вот изоморфна просто-напросто пространство столбцов длины N, которое, я напоминаю, мы обозначаем F.
[33:16.480 --> 33:32.480]  Где он этот изоморфизм? В координатах, вон он у нас написан, правильно?
[33:32.480 --> 33:42.480]  Дело, наверное, проще даже сказать так.
[33:42.480 --> 34:08.480]  Определим отображение Fn, которое каждому столбцу сопоставляет вектор в нашем базисе, то есть вектор, который имеет в нашем базисе ровно такой координатный столбец.
[34:08.480 --> 34:31.480]  Давайте проверять, правда ли, что Фи – это изоморфизм. А давайте разбираться, правда ли, что Фи – это секция?
[34:31.480 --> 34:45.480]  Почему? Потому что через базис можно выразить любой вектор. Сюръекция следует из того, что линейная оболочка Е – это все В, правильно?
[34:45.480 --> 34:58.480]  И любой вектор выражается через Е, значит, когда мы от него столбца будем брать Фи, то как его координатного столбца будем брать Фи, раз получим его.
[34:58.480 --> 35:16.480]  И инъекция. Почему? Потому что у каждого вектора единственное координатное представление, правильно?
[35:16.480 --> 35:40.480]  Ибо у любого вектора единственный координатный столбец. Если бы Фи от двух столбцов был одним и тем же вектором, это значило бы, что оба этих столбца – это его координатные столбцы, правильно, вот этого самого вектора.
[35:40.480 --> 36:07.480]  А это не так. Сохраняет операцию вроде как тривиально, правильно? Фи на альфа 1 плюс альфа 2 – это Е на альфа 1 плюс альфа 2, ну а это то же самое, что Е на альфа 1 плюс Е на альфа 2.
[36:07.480 --> 36:17.480]  Здесь мы опять же воспользовались аксиомами линейного пространства много где. Я вот призываю всех осознавать, где мы этим пользовались.
[36:17.480 --> 36:30.480]  Ну, Фи от минус альфа – это Е на минус альфа. Это то же самое, что минус Е на альфа. Это мы с вами даже уже более-менее доказывали.
[36:47.480 --> 36:57.480]  Ну, Фи от минус альфа – это Е на минус альфа. Это то же самое, что мы уже более-менее доказывали.
[37:17.480 --> 37:27.480]  Ну, Фи от минус альфа – это Е на минус альфа. Это то же самое, что мы уже более-менее доказывали.
[37:47.480 --> 37:57.480]  Ну, Фи от минус альфа – это Е на минус альфа. Это то же самое, что мы уже более-менее доказывали.
[38:17.480 --> 38:27.480]  Ну, Фи от минус альфа – это Е на минус альфа. Это то же самое, что мы уже более-менее доказывали.
[38:47.480 --> 38:57.480]  Ну, Фи от минус альфа – это Е на минус альфа. Это то же самое, что мы уже более-менее доказывали.
[39:17.480 --> 39:23.480]  Это то же самое, что мы уже более-менее доказывали.
[39:47.480 --> 39:53.480]  Это то же самое, что мы уже более-менее доказывали.
[41:18.480 --> 41:26.480]  Итак, давайте я еще раз повторю. Мы остановились в развитии вот этой теории.
[41:26.480 --> 41:35.480]  На вопросе может ли случиться, что у одного и того же пространства есть два базиса из разного количества элементов.
[41:35.480 --> 41:53.480]  И мы откладываем решение этого вопроса немного и переходим к теме, которая полезна сама по себе и которая нам в последствии поможет на этот вопрос ответить.
[41:53.480 --> 42:01.480]  Это тема системы линейных уравнений.
[42:01.480 --> 42:10.480]  Мы с вами уже немного говорили про системы линейных уравнений, когда обсуждали правила Крамера.
[42:10.480 --> 42:15.480]  Сейчас у нас ситуация будет несколько более общая.
[42:15.480 --> 42:24.480]  Но тем не менее матричная интерпретация, которая у нас была, она, естественно, тоже поможет.
[42:24.480 --> 42:36.480]  Я сейчас веду несколько понятий и в частности несколько сокращений.
[42:36.480 --> 42:53.480]  Итак, для начала все-таки система линейных уравнений, которую мы будем сокращать вот таким вот образом.
[42:53.480 --> 43:01.480]  Это, ну, просто система.
[43:01.480 --> 43:07.480]  Так, давайте я сразу скажу над полем f.
[43:07.480 --> 43:11.480]  Это система следующего вида.
[43:11.480 --> 43:15.480]  Давайте я даже без сумм напишу.
[43:15.480 --> 43:29.480]  Альфа 1, 1, x1, альфа 1, 2, x2, плюс и так далее, плюс альфа 1, пусть будет n, xn равно b1.
[43:29.480 --> 43:42.480]  И несколько таких же самых уравнений такого же вида, последний из которых будет у нас, например, альфа k1, x1, альфа k2, x2,
[43:42.480 --> 43:46.480]  альфа kn, xn равно bk.
[43:46.480 --> 43:52.480]  То есть первый индекс говорит нам номер уравнения, по сути дела, здесь.
[43:52.480 --> 43:56.480]  x и t это переменные.
[43:56.480 --> 43:59.480]  Давайте я это напишу.
[43:59.480 --> 44:13.480]  x и t это переменные, а альфа и ж и t, и b и t это элементы нашего поля.
[44:13.480 --> 44:25.480]  Ну и естественно набор альфа 1 и так далее, альфа n.
[44:25.480 --> 44:47.480]  Такой вот столбец из fn называется частным решением системы линейных уравнений.
[44:47.480 --> 45:02.480]  Если понятное дело, альфы плохо, давайте я напишу, лучше a1 и т.д., альфа у нас уже есть.
[45:02.480 --> 45:16.480]  Такой столбец называется частным решением, если подстановка x и t равно a и t дает верное равенство.
[45:16.480 --> 45:36.480]  Ну и естественно, как обычно, решение системы линейных уравнений это множество всех ее частных решений.
[45:36.480 --> 45:44.480]  Прежде чем переходить к хорошему языку, я дам еще одно полезное определение.
[45:44.480 --> 45:55.480]  Система линейных уравнений называется однородной.
[45:55.480 --> 46:05.480]  Так и будем писать однородная система линейных уравнений.
[46:05.480 --> 46:17.480]  Если все свободные члены, так называемые, все быитые, нули.
[46:17.480 --> 46:32.480]  Ну и я напоминаю, что мы с вами можем, давайте напишу в качестве напоминания, записать эту систему уравнений в матричном видео.
[46:32.480 --> 46:52.480]  То есть если мы возьмем все коэффициенты при х, запишем в матрицу, это будет матрица размера, скажите мне, какого?
[46:52.480 --> 46:56.480]  К на n, естественно, правильно.
[46:56.480 --> 47:10.480]  Над полем f, если мы возьмем, обозначим через b столбец b1 и так далее bk, t.
[47:10.480 --> 47:15.480]  Ну и обозначим через x столбец неизвестных.
[47:15.480 --> 47:23.480]  Я уже не пишу лежащий f в n, потому что это столбец из неизвестных, а не из элементов поля.
[47:23.480 --> 47:43.480]  То есть получаем матричную запись нашей системы в виде a на x равно b.
[47:43.480 --> 47:52.480]  При этом матрица a называется просто матрицей системы.
[47:52.480 --> 48:00.480]  Но эта матрица содержит неполную информацию, она не учитывает столбец свободных членов, правильно?
[48:00.480 --> 48:06.480]  Поэтому кроме матрицы системы мы будем рассматривать еще вот такую матрицу.
[48:06.480 --> 48:10.480]  Мы к a припишем справа столбец b.
[48:10.480 --> 48:18.480]  Благо мы можем это сделать, правильно? Столбцы в a тоже длины k, так же, как и длина столбца b.
[48:18.480 --> 48:27.480]  Мы к a приписываем b и принято для того, чтобы визуально их как бы отделять, рисовать черту.
[48:27.480 --> 48:36.480]  Но все равно мы имеем в виду, что это матрица размера k на n плюс 1.
[48:36.480 --> 48:51.480]  Эта матрица называется расширенной матрицей системы.
[48:51.480 --> 49:03.480]  Наша глобальная цель сейчас это, естественно, найти, хорошо описать решение нашей системы линейных уравней.
[49:03.480 --> 49:12.480]  Иногда, допуская нестрогость, частные решения тоже называют решением системы,
[49:12.480 --> 49:18.480]  и тогда говорят, что нужно найти все решения нашей системы.
[49:18.480 --> 49:23.480]  Таким языком тоже порой пользуются, вот я об этом предупреждаю.
[49:23.480 --> 49:28.480]  Итак, наша глобальная задача это найти все решения.
[49:28.480 --> 49:45.480]  Прежде чем мы это сделаем, давайте мы сразу с вами выясним, как выглядят эти решения.
[49:45.480 --> 49:50.480]  Итак, первое утверждение.
[49:50.480 --> 49:59.480]  Решение любой однородной системы уравнений, то есть системы вида ax равно 0,
[49:59.480 --> 50:07.480]  система однородная, когда этот столбец состоит из нулей, то есть столбец нулевой.
[50:07.480 --> 50:22.480]  Решение однородной системы уравнений это подпространство, в пространстве столбцов длины, естественно, n.
[50:22.480 --> 50:27.480]  Подпространство имеется в виду, естественно, линейное подпространство.
[50:27.480 --> 50:32.480]  Других у нас пока не предусмотрено.
[50:32.480 --> 50:34.480]  Доказательство очень простое.
[50:34.480 --> 50:41.480]  То нам нужно проверить, чтобы проверить, что какое-то подмножество является подпространством.
[50:41.480 --> 50:45.480]  Проверить, что оно замкнуто относительно операции.
[50:45.480 --> 50:53.480]  Итак, пусть u – это решение нашей системы уравнений.
[50:53.480 --> 50:58.480]  Почему оно не пусто?
[50:58.480 --> 51:00.480]  Естественно, есть тривиальное решение.
[51:00.480 --> 51:04.480]  Одной системой решения всегда есть хотя бы нулевое, правильно?
[51:04.480 --> 51:08.480]  Если мы возьмем нулевой столбец, мы получим верное равенство.
[51:08.480 --> 51:14.480]  В нем есть 0, то есть оно уже не пусто.
[51:14.480 --> 51:27.480]  Ну и теперь, если α и β – это два частных решения нашей системы уравнений,
[51:27.480 --> 51:33.480]  это означает, что а на альфа и а на бета – это нули.
[51:33.480 --> 51:40.480]  Ну а тогда а на альфа плюс бета – это будет просто а на альфа плюс а на бета.
[51:40.480 --> 51:44.480]  То есть тоже будет 0.
[51:44.480 --> 51:49.480]  А на минус альфа – это то же самое, что минус а на альфа.
[51:49.480 --> 51:52.480]  То есть тоже будет 0.
[51:52.480 --> 52:03.480]  Ну и для любого скаляра лямда, а на лямда альфа – то же самое, что лямда на альфа.
[52:03.480 --> 52:10.480]  Ну и мы с вами таким образом проверили, что если два частных решения у нас есть,
[52:10.480 --> 52:18.480]  то альфа плюс бета, минус альфа и лямда на альфа также являются частными решениями.
[52:18.480 --> 52:26.480]  Это и означает, что у – это подпространство.
[52:26.480 --> 52:29.480]  Ну естественно, в пространстве всех столбцов, правильно?
[52:29.480 --> 52:36.480]  У – это явно под множество всех столбцов длины n.
[52:36.480 --> 52:47.480]  Итого, любое решение нашей однородной системы линейных уравнений всегда подпространство,
[52:47.480 --> 52:56.480]  и поэтому, чтобы его компактно описать, мы всегда будем предъявлять базис этого пространства.
[52:56.480 --> 53:03.480]  Если мы предъявим базис, понятно, как выражаются все его элементы, как его линейные комбинации, правильно?
[53:03.480 --> 53:08.480]  Ну и заодно мы, кстати, выясним, что этот базис всегда существует.
[53:08.480 --> 53:14.480]  В принципе, изначально-то это не очень понятно.
[53:14.480 --> 53:19.480]  Так, это мы с вами сразу описали.
[53:19.480 --> 53:31.480]  Давайте я вынесу то, что я сказал, в определение.
[53:31.480 --> 53:54.480]  А фундаментальной системой решений, сокращается это до ФСР,
[53:54.480 --> 54:21.480]  то есть однородной системы АХ равно нулю называется базис вот этого вот самого пространства, заданного как АХ равно нулю.
[54:21.480 --> 54:29.480]  Еще раз, мы в принципе с вами пока не знаем, что этот базис существует, мы не знаем, что это пространство конечно порождено.
[54:29.480 --> 54:34.480]  Но это мы вскоре узнаем.
[54:34.480 --> 54:59.480]  Ну и удобным представлением этой фундаментальной системы решений называется так называемая фундаментальная матрица этой системы.
[54:59.480 --> 55:05.480]  Это просто матрица, в столбцы которой записаны фундаментальная система решений.
[55:05.480 --> 55:24.480]  То есть это матрица, в столбцы которой образуют фундаментальную систему решений.
[55:24.480 --> 55:36.480]  Ну и собственно говоря, когда мы будем решать однородную систему линейных уравнений, нашей целью будет в точности найти ее фундаментальную матрицу.
[55:36.480 --> 55:41.480]  Так, это вопросы связаны с однородной системой линейных уравнений.
[55:41.480 --> 55:54.480]  Вот так вот у нас же выглядит решение не однородной системы. Извините, давайте-ка я еще одно определение дам, которое я забыл сказать.
[55:54.480 --> 56:00.480]  Очень важное определение, про существование которого иногда забывают.
[56:00.480 --> 56:22.480]  Линейных уравнений называется совместной, если ее решение не пусто.
[56:22.480 --> 56:30.480]  Ну то есть если у нее есть хотя бы одно частное решение, может быть много, но хотя бы одно есть.
[56:30.480 --> 56:49.480]  И вот в частности то, что мы с вами уже сказали, давайте повторим в виде замечания однородная система линейных уравнений всегда совместна.
[56:49.480 --> 56:57.480]  Потому что у нее всегда есть тривиальное решение, то самое нулевое. Не однородное уже не так.
[56:57.480 --> 57:20.480]  Так вот утверждение, пусть ax равно b, это совместная система линейных уравнений.
[57:20.480 --> 57:41.480]  Пусть у это пространство решений соответствующей однородной системы линейных уравнений, а x равно нулю.
[57:41.480 --> 57:50.480]  То есть если мы возьмем произвольную не однородную систему, мы можем рассмотреть соответствующую однородную систему линейных уравнений.
[57:50.480 --> 58:06.480]  И наконец пусть x ноль это какое-то частное решение не однородной системы.
[58:06.480 --> 58:19.480]  То есть пусть мы с вами знаем все решения однородной системы линейных уравнений, они образуют подпространство, и пусть мы знаем какое-то одно частное решение не однородное.
[58:19.480 --> 58:44.480]  Тогда решение нашей исходной системы линейных уравнений, это в точности x ноль плюс u. То есть множество всех столбцов вида x ноль плюс u.
[58:44.480 --> 58:54.480]  Чтобы получить все частные решения не однородной системы, нам нужно к одному добавить все решения однородные.
[58:54.480 --> 59:13.480]  Доказательства очень простые.
[59:13.480 --> 59:21.480]  Ну вот я еще раз напоминаю, что мы в очередной раз пользуемся вот таким вот обозначением.
[59:21.480 --> 59:33.480]  x ноль плюс целое множество u, это множество всех столбцов вида x ноль плюс u, где u маленькое и u большое.
[59:33.480 --> 59:52.480]  Доказательства. Давайте мы просто выясним, что означает, что ax равно b, если мы знаем частное решение нашей системы, если мы знаем какое-то x ноль.
[59:52.480 --> 01:00:05.480]  Тогда ax равно b, равносильно тому, что ax равно ax ноль, потому что ax ноль как раз равно b, это равносильно.
[01:00:05.480 --> 01:00:15.480]  Мы можем перенести все в левую часть и вынести a за скобки, потому что a на x минус x ноль равно 0.
[01:00:15.480 --> 01:00:25.480]  Ну а это означает, что x минус x ноль – это решение однородной системы линейных уравнений, правильно?
[01:00:25.480 --> 01:00:37.480]  x минус x ноль лежит в u в точности, правильно? Ну а это в точности означает, что x лежит в x ноль плюс u.
[01:00:37.480 --> 01:00:49.480]  Поэтому x, столбец уже из коляров, является решением в точности тогда, когда он лежит здесь. Это и означает, что наше утверждение верно.
[01:00:49.480 --> 01:01:03.480]  И ввиду этого, если мы хотим решить однородную систему линейных уравнений, то мы хотим найти ее фундаментальную матрицу, то есть базис пространства решений.
[01:01:03.480 --> 01:01:10.480]  Если мы ее найдем, то мы систему уже полностью решили. Мы однозначно описали все решения.
[01:01:10.480 --> 01:01:20.480]  Если мы хотим решить не однородную систему, нам кроме этой фундаментальной матрицы достаточно найти еще одно частное решение нашей системы.
[01:01:20.480 --> 01:01:27.480]  Тогда мы уже все решение этой системы выпишем вот в таком виде.
[01:01:27.480 --> 01:01:35.480]  Итого решение нашей системы свелось к нахождению этих двух объектов.
[01:01:35.480 --> 01:02:03.480]  Итого, чтобы решить систему ax равно b, достаточно найти ее фундаментальную матрицу, которая обозначается большой греческой буквой phi.
[01:02:03.480 --> 01:02:16.480]  И частное решение x0.
[01:02:16.480 --> 01:02:44.480]  Все частные решения будут иметь вид x равно x0 плюс 100.
[01:02:44.480 --> 01:02:54.480]  Плюс произвольная линейная комбинация столбцов матрицы phi.
[01:02:54.480 --> 01:03:01.480]  А как описать все линейные комбинации столбцов матрицы phi?
[01:03:01.480 --> 01:03:11.480]  Да, умножить на столбец правильно. Брать линейную комбинацию столбцов это все равно, что умножить справа на столбец.
[01:03:11.480 --> 01:03:22.480]  Плюс phi на гамма, где гамма это столбец того размера, сколько у нас столбцов phi.
[01:03:22.480 --> 01:03:27.480]  Итого, общее решение системы линейных уравнений всегда будет выглядеть так.
[01:03:27.480 --> 01:03:37.480]  Осталось мелочь его найти, но для этого нам еще что-то придется сделать.
[01:03:37.480 --> 01:03:46.480]  Итак, как мы теперь будем решать нашу систему линейных уравнений?
[01:03:46.480 --> 01:03:58.480]  Мы будем работать, естественно, с ее матрицей и с расширенной матрицей, которую я еще не стер, приводя ее к хорошему виду.
[01:03:58.480 --> 01:04:06.480]  И перед тем, как мы будем приводить, нужно понять, чем мы будем приводить.
[01:04:06.480 --> 01:04:20.480]  И вот предмет для следующего определения.
[01:04:20.480 --> 01:04:47.480]  Комментарное преобразование строк матрицы это преобразование нашей матрицы, если нам дана какая-то матрица.
[01:04:47.480 --> 01:04:54.480]  Это преобразование одного из трех типов.
[01:04:54.480 --> 01:05:01.480]  У нас существуют элементарные преобразования трех типов.
[01:05:02.480 --> 01:05:30.480]  Это мы к этой строке, к некоторой строке матрицы, можно прибавить житую ее строку, умноженную на некоторый скаляр альфа.
[01:05:30.480 --> 01:05:33.480]  Параметры у нас здесь такие.
[01:05:33.480 --> 01:05:35.480]  Параметры этого преобразования.
[01:05:35.480 --> 01:05:38.480]  Во-первых, это вот этот самый скаляр альфа.
[01:05:38.480 --> 01:05:42.480]  А во-вторых, пара номеров строк и ижи.
[01:05:42.480 --> 01:05:50.480]  Понятное дело, что и не равно жи.
[01:05:50.480 --> 01:05:54.480]  Второй тип.
[01:05:54.480 --> 01:06:04.480]  И твою строку можно умножить на некоторый скаляр.
[01:06:04.480 --> 01:06:13.480]  Параметрами здесь опять же таки являются номер строки и скаляр лямбда, который, внимание, я пишу, лежит в f со звездой.
[01:06:13.480 --> 01:06:19.480]  Это не нулевой элемент поля f.
[01:06:19.480 --> 01:06:23.480]  Ну и, наконец, третий тип.
[01:06:23.480 --> 01:06:34.480]  Итую и житую строки можно поменять местами.
[01:06:34.480 --> 01:06:39.480]  Ну, формально я, наверное, тоже напишу, что и не равно жи.
[01:06:39.480 --> 01:06:46.480]  Хотя можно было бы итную строку с этой поменять местами, ничего бы страшного не произошло.
[01:06:46.480 --> 01:06:54.480]  Элементарное преобразование строк нашей матрицы – это преобразование вот таких вот трех типов.
[01:06:54.480 --> 01:06:58.480]  Мы с ними сейчас будем некоторое время работать.
[01:06:58.480 --> 01:07:15.480]  И чтобы было понятнее, какими свойствами они обладают, полезно эти преобразования описать в некотором другом виде.
[01:07:15.480 --> 01:07:29.480]  Значит, давайте я делаю следующее замечание.
[01:07:29.480 --> 01:07:53.480]  Оказывается, сейчас мы это проверим, что элементарное преобразование строк матрицы A это осуществляется в точности домножением.
[01:07:53.480 --> 01:08:09.480]  А на некоторую матрицу слева.
[01:08:09.480 --> 01:08:25.480]  То есть на самом деле, для того чтобы осуществить любое из этих преобразований, нам достаточно матрицу A слева умножить на фиксированную матрицу.
[01:08:25.480 --> 01:08:33.480]  И вот сейчас я как раз и скажу, что это за матрица.
[01:08:33.480 --> 01:08:41.480]  Для этого мне полезно ввести следующее обозначение.
[01:08:41.480 --> 01:08:45.480]  Это обозначение стандартное.
[01:08:45.480 --> 01:08:55.480]  Если мы уже работаем с матрицами фиксированного размера N на K, то через E и G очень часто обозначается матрица,
[01:08:55.480 --> 01:09:13.480]  в которой единица стоит на пересечении этой строки ежитого столбца, а все остальные элементы равны нулю.
[01:09:13.480 --> 01:09:23.480]  Ну давайте уж я в качестве примера скажу, что матрица E это сумма.
[01:09:23.480 --> 01:09:33.480]  Вот через такие матрицы как можно ее выразить?
[01:09:33.480 --> 01:09:43.480]  Е и И, конечно.
[01:09:43.480 --> 01:09:55.480]  Так вот, теперь я могу предъявить явным образом, вот у меня элементарные преобразования трех типов написаны.
[01:09:55.480 --> 01:10:15.480]  Итак, я тогда вот здесь вот на соседней доске немножко нелинейно запишу матрицы, которые соответствуют этим трем типам.
[01:10:15.480 --> 01:10:39.480]  Определением элементарная матрица размера N на N это матрица одного из трех типов.
[01:10:39.480 --> 01:10:53.480]  Ну а давайте мы с вами осознаем сами, как осуществлять вот эти вот преобразования.
[01:10:53.480 --> 01:10:59.480]  Вот давайте я левую доску отведу именно для этого.
[01:10:59.480 --> 01:11:23.480]  Мы же с вами знаем, что когда мы умножаем какую-нибудь матрицу на матрицу A слева,
[01:11:23.480 --> 01:11:37.480]  то в итоге у нас получается матрица, строки которой это линейные комбинации строк матрицы A.
[01:11:37.480 --> 01:11:49.480]  Мы в свое время это с вами уже выясняли. И коэффициенты эти линейные комбинации как раз стоят в той матрице, на которую мы а домножаем.
[01:11:49.480 --> 01:11:59.480]  Так вот давайте мы посмотрим, на что нам нужно домножить. Давайте я напишу это D и G от лямбда.
[01:11:59.480 --> 01:12:09.480]  На какую матрицу нам нужно домножить матрицу A, чтобы к ее итой строке добавилась житая строка?
[01:12:09.480 --> 01:12:19.480]  Все строки кроме итой должны остаться неизменными, такими как были, правильно?
[01:12:19.480 --> 01:12:30.480]  Это что означает? Это означает, что в этой матрице, кроме итой строки, я должен написать коэффициенты, которые оставляют строку неизменной.
[01:12:30.480 --> 01:12:40.480]  Что это означает? Я должен написать в первой строке коэффициенты 1 и куча нулей, чтобы оставить первую строку неизменной.
[01:12:40.480 --> 01:12:48.480]  Во второй строке 0 и 1 куча нулей. Короче, я должен написать те же строки, что и в единичной матрице.
[01:12:48.480 --> 01:12:58.480]  Что я должен написать в этой строке? Я должен написать по-прежнему единичку на итом месте, потому что эта строка осталась, к ней только добавляется житая.
[01:12:58.480 --> 01:13:08.480]  Что я еще должен там написать? Только не лямду, а альфу, потому что мы умножаем ее на альфу.
[01:13:08.480 --> 01:13:16.480]  Альфа в житом элементе этой строки, правильно?
[01:13:16.480 --> 01:13:31.480]  Если я умножаю матрицу вот на такую строку, это я как раз беру линейную комбинацию строк нашей матрицы с вот такими коэффициентами.
[01:13:31.480 --> 01:13:40.480]  Единичка на единичку умножается итой, итая строка на альфу, домножается житая строка нашей матрицы.
[01:13:40.480 --> 01:13:44.480]  Ну вот, давайте я напишу, что альфа стоит в житом столбце.
[01:13:44.480 --> 01:13:48.480]  Значит, вот на такую матрицу нам и нужно домножить.
[01:13:48.480 --> 01:13:51.480]  Формально я это могу записать следующим образом.
[01:13:51.480 --> 01:14:04.480]  Эта матрица есть Е, плюс альфа, Е и житая, абсолютно верно.
[01:14:04.480 --> 01:14:11.480]  Так, это у нас была матрица первого типа.
[01:14:11.480 --> 01:14:18.480]  Для второго типа П, и это от альфа, от лямда.
[01:14:18.480 --> 01:14:28.480]  Как должна выглядеть матрица, домножение которой умножает итую строку на лямду?
[01:14:28.480 --> 01:14:32.480]  Да, у нас должна быть та же самая единичная матрица.
[01:14:32.480 --> 01:14:37.480]  Она ничего не делает со всеми строками, кроме итой, правильно?
[01:14:37.480 --> 01:14:45.480]  А в итой строке вместо единички стоит лямда.
[01:14:45.480 --> 01:14:59.480]  Формально я должен написать, что это Е, плюс, видимо, лямда минус один на Е и итая, правильно?
[01:14:59.480 --> 01:15:06.480]  Потому что единичку на итом месте, на диагонали, я должен заменить на лям.
[01:15:06.480 --> 01:15:21.480]  Ну и наконец, третий тип, я должен переставить две строки местами.
[01:15:21.480 --> 01:15:26.480]  Для этого мне должна помочь матрица Ку и Житая.
[01:15:26.480 --> 01:15:34.480]  Как она будет выглядеть?
[01:15:34.480 --> 01:15:43.480]  Да, в итой строке везде будет точно то же самое, что в единичной матрице, кроме строк итой и Житой, правильно?
[01:15:43.480 --> 01:15:49.480]  В итой строке должен быть нолик на итом месте и единичка на Житом, правильно?
[01:15:49.480 --> 01:15:54.480]  Потому что вместо итой строки я должен поставить Житую строку.
[01:15:54.480 --> 01:16:00.480]  Здесь должна быть единичка на итом месте, нолик на Житом.
[01:16:00.480 --> 01:16:05.480]  А в остальном она выглядит как единичная мат.
[01:16:05.480 --> 01:16:15.480]  Если я очень хочу записать это формально, то я должен написать, что это Е, плюс Е и Житая, плюс Е Житая.
[01:16:15.480 --> 01:16:25.480]  Поставил единичку вот на эти места, минус Е и Итая, минус Е Житая.
[01:16:25.480 --> 01:16:37.480]  Ну и вот то, что мы с вами сейчас говорили, по сути дела, можно резюмировать в такое утверждение.
[01:16:37.480 --> 01:17:00.480]  Элементарное преобразование строк матрицы есть точности домножения ее слева на соответствующую элементарную матрицу.
[01:17:00.480 --> 01:17:06.480]  Мы, по сути дела, проговорили, что это такое.
[01:17:06.480 --> 01:17:16.480]  На всякий случай давайте я сделаю замечание, а после этого мы уже будем переходить в другую аудиторию.
[01:17:16.480 --> 01:17:22.480]  Да тут что-то другое будет происходить.
[01:17:22.480 --> 01:17:29.480]  Нет, нельзя.
[01:17:29.480 --> 01:17:34.480]  А, нет, нам будет нужно. Ну ладно, значит придется эти матрицы еще раз выписать там.
[01:17:34.480 --> 01:17:46.480]  Замечание, на котором мы останавливаемся в этой аудитории, как быстро вспомнить, что это за матрицы.
[01:17:46.480 --> 01:18:08.480]  Элементарные матрицы получаются естественно применением элементарного преобразования соответствующего к матрице Е.
[01:18:08.480 --> 01:18:30.480]  Если мы говорим, что мы эту матрицу на что угодно домножаем и получаем результат применения элементарного преобразования к нему, то если мы ее домножим на Е, то мы получим с одной стороны ее любую матрицу умножить на Е, а с другой стороны получится результат применения элементарного преобразования к Е.
[01:18:30.480 --> 01:18:40.480]  Поэтому каждый из этих матриц это в точности то, что будет, если наши элементарные преобразования применить к единичной матрице Е.
[01:18:40.480 --> 01:18:44.480]  Так это, наверное, проще всего запомнить.
[01:18:44.480 --> 01:18:48.480]  Как мы будем работать с элементарными преобразованиями?
[01:18:48.480 --> 01:18:50.480]  Убыхим!
