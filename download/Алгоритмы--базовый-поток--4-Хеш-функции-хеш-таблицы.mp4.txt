[00:00.000 --> 00:15.040]  Так, всем добрый вечер. В прошлый раз мы разошлись на довольно печальной ноте. Мы построили алгоритм,
[00:15.040 --> 00:24.240]  который не работает. Я напомню, у нас было простое равномерное хеширование. В чем его идея?
[00:24.240 --> 00:40.000]  У нас есть множество всевозможных хэш-функций, где к – это соответственно множество ключей,
[00:40.000 --> 00:43.840]  которые теоретически может сохранить наш хэштаблицу данную, и хэштаблицу, соответственно,
[00:43.840 --> 00:51.960]  как у нас было устроено. Это был просто массивчик размера m. И в каждой ячейке,
[00:51.960 --> 01:00.440]  которого у нас хранится список элементов, которые попадают в эту ячейку. Грубо говоря,
[01:00.440 --> 01:08.960]  список значений, обладающих одним и тем же хэшом. В данном случае у нас есть h от x,
[01:08.960 --> 01:13.160]  значение h от x совпадает с значением h от y, совпадает с значением h от z,
[01:13.160 --> 01:21.240]  и все они равны значению 2. Такая ситуация называется коллизией. Мы сказали, что хорошо,
[01:21.320 --> 01:25.040]  у нас есть коллизия, давайте просто-напросто все элементы с одинаковыми хешами хранить в списке,
[01:25.040 --> 01:30.840]  а соответственно поиск будет рассуждаться следующим образом. Мы идем в соответствующий
[01:30.840 --> 01:38.520]  элемент массива, и дальше обычным линейным поиском в этом списке ищем элемент. И соответственно
[01:38.520 --> 01:43.760]  вставка, удаление происходит абсолютно точно так же. У нас была с вами теорема,
[01:43.760 --> 01:48.080]  которая говорила о том, что если из этого множества выбирать хэш-функцию абсолютно случайно,
[01:48.960 --> 01:52.240]  равновероятно, то есть каждая функция имеет одинаковую вероятность быть взятой,
[01:52.240 --> 02:01.120]  то в этом случае у нас достигает следующая оценка, что на среднее время работа find
[02:01.120 --> 02:11.480]  являлась о большим от 1 плюс n деленное на m. Дальше мы сказали, что если мы вот этот
[02:11.480 --> 02:16.880]  коэффициент альфа n на m поддерживаем, скажем так, меньше либо равным единице,
[02:16.880 --> 02:21.520]  как мы это делаем, просто при необходимости расширяем нашу таблицу, вот эту m соответственно
[02:21.520 --> 02:30.760]  увеличиваем вместе с n. В этом случае соответственно у нас получается, что время работы тех операций от
[02:30.760 --> 02:39.040]  единицы, но при этом в среднем. Опять же повторюсь, к сожалению, просто равномерно
[02:39.040 --> 02:45.600]  хэш-функции на практике недостижимо, его практически невозможно реализовать на практике,
[02:45.600 --> 02:50.760]  поэтому приходится выдумывать нечто иное. Сегодня мы как раз-таки, во-первых, разберемся с
[02:50.760 --> 02:57.760]  этой проблемой, построим все-таки множество хэш-функций, которые будут тультворять вот этим
[02:57.760 --> 03:03.240]  всем соотношением, то есть мы эти оценки на самом деле, мы добьемся этих самых оценок. Кроме того,
[03:03.240 --> 03:09.360]  мы построим структуру данных, которая позволит нам хэшировать так, что у нас в худшем случае
[03:09.360 --> 03:13.120]  поезд будет отчисляться за единицу, то есть единица будет не в среднем, а в худшем случае.
[03:13.120 --> 03:17.000]  Но давайте обо всем порядке. Сначала давайте поговорим про так называемые универсальные
[03:17.000 --> 03:24.000]  семейства хэш-функций. Тут повторена проблема, которая была в прошлый раз. Действительно,
[03:24.000 --> 03:28.440]  мы рассмотрели просто равномерное хэширование и поняли, что на практике его сложно добиться по
[03:28.440 --> 03:34.240]  нескольким причинам. Во-первых, как минимум, его достаточно сложно реализовать, в том смысле,
[03:34.240 --> 03:41.600]  что если мы хотим сохранить какую-нибудь функцию из вот этого множества, то нам, соответственно,
[03:41.600 --> 03:43.920]  понадобится очень много памяти. Но, соответственно, в этом месте, где много памяти,
[03:43.920 --> 03:47.720]  нам требуется много времени просто на то, чтобы создать единственную функцию,
[03:47.720 --> 03:55.400]  которая не подойдет. Ну, и, вообще говоря, если мы воспользуемся тем планом, который у нас был
[03:55.400 --> 04:01.960]  до этого, то скажем, нам приходит какой-то элемент, мы его запоминаем и запоминаем его
[04:01.960 --> 04:05.680]  хэш-взначение, а если нам приходит какой-то новый элемент, то соответственно мы генерируем для него
[04:05.680 --> 04:10.160]  новое хэш-взначение. Но как мы приходим к тому, что нам в принципе для того, чтобы реализовать
[04:10.160 --> 04:14.960]  хэш-функцию, нужно реализовать хэш-таблицу. Да, то есть такой парадокс. В общем, проблемы вспомнили.
[04:14.960 --> 04:21.120]  Как мы будем решать? В общем-то, идея на самом деле очень простая. Идея, которую мы будем следовать на
[04:21.120 --> 04:25.600]  сегодняшней лекции, будет такая. Ну хорошо, смотрите, вот это вот множество множества всех хэш-функций,
[04:25.600 --> 04:31.400]  вот оно, множество хэш-функций, оно довольно большое. Да, его довольно сложно представить в памяти,
[04:31.400 --> 04:35.080]  то есть как бы его довольно сложно хранить в памяти, к минимуму, да. То есть, если все-таки у вас
[04:35.080 --> 04:40.000]  функции случайные, то, наверное, это означает, что для каждого элемента, для каждого входного данного,
[04:40.400 --> 04:46.080]  вам нужно хранить его соответствующие, ну соответствующие отображения. Да, вот. Ну а давайте
[04:46.080 --> 04:51.040]  воспользуемся следующей идеей. Ну хорошо, вот это множество хранить очень сложно, но принципе его
[04:51.040 --> 04:54.920]  описать довольно сложно. А давайте из этого множества выделим какое-нибудь небольшое
[04:54.920 --> 05:00.800]  подмножество, маленькое подмножество, которое, во-первых, будет просто описано, ну допустим,
[05:00.800 --> 05:05.080]  это множество всех линейных функций или множество всех квадратичных функций. Да, короче говоря,
[05:05.080 --> 05:08.560]  просто выделим какое-то подможество функций из огромного, ну из всевозможных
[05:08.560 --> 05:12.480]  функций. Это во-первых. А во-вторых, давайте скажем, что вот это вот маленькое множество
[05:12.480 --> 05:16.120]  пусть обладает тем же самым свойством, что и наше исходное большое множество.
[05:16.120 --> 05:19.600]  Ну а каким приятным свойством обладает наше исходное большое множество? Ну она
[05:19.600 --> 05:22.200]  обладает тем свойством, что если мы случайно из него выбираем хэш-функцию,
[05:22.200 --> 05:26.280]  то вероятность того, что у двух произвольных элементов, не равных друг
[05:26.280 --> 05:31.280]  другу, будет коллизия, она равна 1 на m. Ну собственно, по сути, из этого следовала
[05:31.380 --> 05:37.920]  вот эта самая оценка в теореме. Мы говорили, что так как вероятность совпадения
[05:37.920 --> 05:42.800]  двух хэш-взначений на двух разных элементов равна 1 на m, то
[05:42.800 --> 05:45.760]  соответственно отсюда следовала вот эта оценка. Ну и скажем, давайте следующую
[05:45.760 --> 05:48.920]  вещь. Давайте тоже возьмем какое-нибудь маленькое подможество из этого большого
[05:48.920 --> 05:52.960]  множества и скажем, что если вероятность вероятность совпадения хэш-взначений
[05:52.960 --> 05:55.760]  вот в этом маленьком множестве будет меньше равной чем 1 на m, то
[05:55.760 --> 06:02.240]  соответственно, мы победили. У нас будет та же самая оценка. Согласны? Давайте формально
[06:02.240 --> 06:10.240]  опишем, что я хочу сказать. Пусть, как обычно, у нас есть множество k. Вот это множество
[06:10.240 --> 06:14.640]  всех ключей. Ну и размер каштаблицы m. Ну что такое размер каштаблицы? Это просто
[06:14.640 --> 06:25.640]  размер вот этого массива списков. Далее, m-1. Вот. Тогда скажем следующее, что семейство
[06:25.640 --> 06:31.720]  функций h, которое является под множеством всевозможных хэш-функций, называется
[06:31.720 --> 06:37.280]  универсальным. Вот это семейство. В том случае, если для любых x и y, таких, что x не равно y,
[06:37.280 --> 06:41.440]  при равновероятном выборе h из этого множества будет выполнено следующее. Вероятность того,
[06:41.440 --> 06:47.680]  что h от x будет равен h от y меньше вероятно, чем 1 на m. Окей? То есть мы взяли какое-то
[06:47.680 --> 06:52.000]  под множество из исходного большого множества, ну грубо говоря, мешок функций. Даже случайно
[06:52.000 --> 06:56.400]  взяли. Дальше проводим следующий эксперимент. Случайно выбираем функцию из этого мешка,
[06:56.400 --> 07:01.760]  да, и смотрим, соответственно, совпало ли у меня h от x с h от y. При этом x и y они фиксированы,
[07:01.760 --> 07:05.280]  да, какие-то. Ну абсолютно произвольные, фиксированные. Вот берем произвольные,
[07:05.280 --> 07:09.920]  фиксированные x и y и вытаскиваем оттуда хэш-функции. Вот. И смотрим, в каких случаях у нас эти
[07:09.920 --> 07:15.600]  хэш-взначения совпали. И вот если доля случаев, в которых у меня хэш-взначения для x и y
[07:15.600 --> 07:19.360]  совпали меньше, чем 1 на m, то мы будем говорить, что вот этот мешок с функциями, то есть вот этот
[07:19.360 --> 07:28.120]  семейство функций, оно будет в универсальном. Окей? Понятно определение? Какой вопрос?
[07:28.120 --> 07:37.440]  Окей. Да, ну то есть смысл такой, что какую бы вы пару x и y не взяли, доля функций вот в этом множестве
[07:37.440 --> 07:41.560]  функций h, на которых они дают коллизию, не превосходит 1 делить на m. То есть, грубо говоря,
[07:41.560 --> 07:45.760]  для любой пары x и y у вас количество функций, на которых вот на этой конкретной паре будет
[07:45.760 --> 07:54.720]  достигаться коллизия, очень мало. Ну очень мало, это 1 деленное на m в наших терминах. Окей? Вот. Ну
[07:54.720 --> 08:00.360]  соответственно, я думаю, пометую о прошлой лекции, вы можете задать естественный вопрос. А такое
[08:00.360 --> 08:06.160]  существует? Если простого равномерного кшера нет, может и такого не существует в принципе. Вот. Но
[08:06.160 --> 08:12.560]  сейчас я покажу, что на самом деле пример вот такого семейства привести можно. И, собственно,
[08:12.560 --> 08:19.600]  вот он. Вот он пример. Давайте о нем, давайте просто смотрим на пример, а вывод будем
[08:19.600 --> 08:25.200]  параллельно делать. Значит, давайте рассмотрим следующую задачу. Вот пусть у меня множество
[08:25.200 --> 08:32.400]  ключей, в конкретном случае, пусть у меня множество ключей. Это система вычетов по модулю p. Ну то есть,
[08:32.400 --> 08:39.040]  грубо говоря, просто значение 0, 1, 2 и так далее. p-1. Ну где p это некоторое простое число.
[08:39.040 --> 08:48.240]  Вот. И, значит, давайте я скажу следующее. Давайте в качестве универсального семейства хэш-функции,
[08:48.240 --> 08:53.080]  точнее в качестве множества хэш-функций допустимых, возьму вот такое множество. Значит,
[08:53.080 --> 09:02.520]  это будут все такие функции h, которые сдаются следующим уравнением. Значит, h от x у нас равно
[09:02.520 --> 09:14.440]  ax плюс b, остаток отделения на p. И от этого всего еще берем остаток отделения на. Вот. При этом
[09:14.440 --> 09:21.880]  a и b пробегают в следующее значение. Значит, a лежит в том же самом zp, но без нуля, а b абсолютно
[09:21.880 --> 09:31.680]  произвольная из zp. Вот. Вот. Обратите внимание, смотрите, согласны ли вы, что не любая функция,
[09:31.680 --> 09:37.880]  не любая функция, отображающая k в 0 и так далее, m-1, описана вот здесь. Согласны, что это
[09:37.880 --> 09:42.640]  некоторая подножество все-таки всевозможных функций. Это, во-первых. А, во-вторых, это множество
[09:42.640 --> 09:47.640]  очень легко описать. Точнее произвольную функцию h отсюда очень легко описать. Ну давайте там в
[09:47.640 --> 09:53.160]  терминах вашего любимой c++. Вот как сохранить функцию h, которая сдается вот таким вот уравнением.
[09:53.160 --> 09:59.200]  Да, мы просто храним на самом деле, то есть тут по сути есть такое отражесление между функцией h и
[09:59.200 --> 10:05.280]  парой чисел ab. То есть, грубо говоря, вы просто храните 2 int. Все. То есть мы избавились от этой проблемы,
[10:05.280 --> 10:09.120]  что на то, чтобы хранить отдельную хэш-функцию, вам требуется много памяти. Вот чтобы сохранить
[10:09.120 --> 10:13.160]  вот любую хэш-функцию из этого множества, вам достаточно всего лишь сохранить 2 int и все. На самом
[10:13.160 --> 10:19.840]  деле, да, 2 unsigned int. Вот. Понятно? Вот. Но осталось лишь убедиться в том, что действительно, если я
[10:19.840 --> 10:25.120]  буду выбирать случайно хэш-функцию из вот этого множества, а не из всего большого множества, то у
[10:25.120 --> 10:30.200]  меня будут очень маленькие вероятности коллизий. Вот это осталось доказать. Давайте, собственно,
[10:30.200 --> 10:42.240]  это проведем. Значит, как мы это будем доказывать? Ну, во-первых, по определению универсального
[10:42.240 --> 10:48.400]  семейства хэш-функции, что мы должны сказать? Мы должны сказать, что для любой пары x и y мы должны
[10:48.400 --> 10:54.480]  показать, что вероятность того, что хэш значение от x совпадает с хэш значением от y с очень малой
[10:54.480 --> 11:05.760]  вероятностью. Ну, давайте возьмем просто произвольные. Возьмем и зафиксируем произвольные
[11:05.760 --> 11:17.280]  x и y, принадлежащие к, ну, при этом x не равны y, естественно. Вот. Давайте для конкретной
[11:17.280 --> 11:23.440]  произвольной пары докажем, что вероятность коллизий на них будет мала. Значит, ну, давайте еще
[11:23.440 --> 11:34.120]  отдельно рассмотрим значение х штрих, которое будет равно ax плюс b процент p, и y штрих равный
[11:34.120 --> 11:44.440]  ay плюс b процент p. Ну, просто это х-начение, да, без вот этого последнего взятия остатка.
[11:44.440 --> 11:59.560]  Вот. Значит, чего начнем? Давайте первым делом покажем, что х штрих не равно y штрих. Пока
[11:59.560 --> 12:06.080]  мы забудем про него. Пока они меня интересуют о х штрих и y штрих. Понятно ли, что х штрих не
[12:06.080 --> 12:11.400]  равен y штрих 100% без всяких вероятностей? То есть, какую бы я хэш функцию не взял, у меня
[12:11.400 --> 12:16.120]  гарантированно х штрих не будет совпадать с y штрих. Ну, почему это так? Ну, давайте, хорошо,
[12:16.120 --> 12:20.680]  давайте просто наоборот рассмотрим х штрих минус y штрих и покажем, что оно не равно нулю.
[12:20.680 --> 12:26.920]  Значит, вот если я вычитаю два остатка, то все рифметику остатка знают, что разность двух
[12:26.920 --> 12:31.600]  остатков это просто остаток разности. Давайте, собственно, просто возьмем разность вот этих
[12:31.600 --> 12:43.880]  штук и получим ax-y%p. Согласны? Ну, бшки ушли, осталось ax-y%p. Ну, а вы верите, что вот эта штука не
[12:43.880 --> 12:51.640]  равна нулю? Ну, не равна нулю. Ну, действительно, почему? Давайте вот тут. Можно уже спойлер посмотреть.
[12:51.640 --> 12:55.800]  Ну, действительно, вот эта штука не равна нулю. Почему? Потому что х, во-первых, не совпадает с
[12:55.800 --> 13:02.200]  y, а это два вычта. То есть, если вы один вычет вычитаете другого, при этом они не равны другому,
[13:02.200 --> 13:08.960]  то, естественно, ноль вы не получите. Ну, и при этом a, заметьте, а у нас вот такое,
[13:08.960 --> 13:16.440]  а не равно нулю, да, а гарантирован не делитель p. Соответственно, а не делитель p, x-y, простите,
[13:16.440 --> 13:22.600]  а p не делит a, и также p не делит x-y, и при этом p простое, поэтому, соответственно, произведение
[13:22.600 --> 13:33.320]  тоже не делится на p. Окей? Что еще раз? А у нас гарантирован вот отсюда. А это какой-то
[13:33.320 --> 13:37.920]  остаток пределения на p, но при этом не нулевой. То есть, ну, грубо говоря, а не делится на p. Вот все.
[13:37.920 --> 13:43.600]  А не делится на p, x-y не делится на p. Так как p простое, то и произведение тоже не делится на p.
[13:43.600 --> 13:50.520]  Логично? Все, следовательно, разность х' и y' не равна нулю, соответственно, х не равен y'. Все.
[13:50.520 --> 13:52.040]  Вопрос?
[13:58.400 --> 14:02.720]  А как x-y может быть равен p, если x и y лежат в остаком множестве?
[14:02.720 --> 14:11.080]  x и y это два вычета, это два вычета, причем различные. Они не могут быть равны нулю априори.
[14:11.080 --> 14:28.800]  Второй пункт. Неочевидный. Вот, смотри, давайте посмотрим вот на эти два уравнения. И вот я утверждаю,
[14:28.800 --> 14:34.960]  что, на самом деле, вот эти два уравнения, они задают мне объекцию между, давайте так скажу,
[14:34.960 --> 14:46.000]  парами x' и y' всевозможными и AB. Ну, естественно, прификсированным x и y.
[14:46.000 --> 14:55.400]  Ну, короче, грубо говоря, вот у меня есть какие-то x и y фиксированные, и если я буду перебирать
[14:55.400 --> 14:59.960]  всевозможные пары A и B, то это будет означать, что я на самом деле перебираю всевозможные пары
[14:59.960 --> 15:09.400]  x' и y'. Понятно? То есть, любому заранее заданному x' и y', я могу подобрать такие A и B. И наоборот.
[15:09.400 --> 15:14.720]  Собственно, произвольные A и B, ну это естественно, произвольные AB задаст мне какую-то пару x' и y'.
[15:14.720 --> 15:21.560]  Понятно? То есть, грубо говоря, мне даны какие-то произвольные абсолютно x и y, а я всегда могу
[15:21.560 --> 15:27.880]  подобрать такие A и B. Ну, мне даны произвольные x и y, вот. И дальше я хочу получить какие-то
[15:27.880 --> 15:32.840]  x' и y'. И вот утверждается, что я всегда смогу подобрать такие A и B, что у меня такое получится
[15:32.840 --> 15:47.720]  преобразование. Переобразование из x и y в x' и y'. Вот, мне дают фиксированный x и y. Вот вы даете
[15:47.720 --> 15:53.280]  мне произвольный x и y, 5-10. Вот. А я хочу, чтобы они в итоге отображались у меня в, не знаю, там,
[15:53.280 --> 16:04.160]  7 и 8. Я всегда смогу подобрать такие A и B, что у меня такое получится. Вот. Вот. Ну, грубо
[16:04.160 --> 16:09.240]  говоря, вот это вот, то есть, грубо говоря, вот это вот соотношение задает необъекцию между парами A и B
[16:09.240 --> 16:14.160]  и x' и y'. Ну, естественно, при условии, что у меня x, y и p, они фиксированы. Но они у меня
[16:14.160 --> 16:20.000]  фиксированы, потому что я их заранее выбрал и зафиксировал. Окей? Вот. Давайте вот покажем. Ну,
[16:20.000 --> 16:24.920]  на самом деле, показать это несложно. Давайте просто насмотрим систему уравнений вот эту.
[16:24.920 --> 16:43.280]  AX плюс B процент P. AY плюс B процент P равно x' и y'. Ну, и тут можно рассуждать по-разному.
[16:43.280 --> 16:48.080]  Можно сказать, что, на самом деле, система вычетов, там, она образует поле, поэтому тут можно применить
[16:48.080 --> 16:52.960]  ваш любимый метод и решение системы линейных уравнений, там, неважно, через детерминат или
[16:52.960 --> 16:57.800]  через что-то еще. Вот. И показать, что эта система имеет единственное решение. А можно просто просто
[16:57.800 --> 17:04.160]  в тупую выразить, не знаю, там, либо B, либо A из первого уравнения и поставить его во второе. Вот. То есть,
[17:04.160 --> 17:11.400]  грубо говоря, ну, как бы вы не рассуждали, да, смотрите, что вот отсюда можно сказать. Ну,
[17:11.400 --> 17:22.560]  давайте через матрицу пойдем. Вот тут чему равна матрица? Тут матрица у меня x1 и y1. Да? Вот. Если
[17:22.560 --> 17:28.120]  A и B, то у меня, на самом деле, эти самые переменные. Вот. То перед A стоит коэффициент x, перед B стоит
[17:28.120 --> 17:32.280]  коэффициент 1, перед Y стоит коэффициент A, перед B стоит коэффициент 1. Вот. В итоге получается такая
[17:32.280 --> 17:35.200]  матрица. Эта матрица, естественно, детерминат этой матрицы, естественно, не равен нулю.
[17:35.200 --> 17:54.160]  Прогласны? Почему? Потому что у меня x не равен y. Не шокируйтесь. Вот. Ну все, из-за этого, собственно,
[17:54.160 --> 18:02.440]  следует, что вот эта система имеет ровно одно решение. Окей? Для любого x' и y' я могу подобрать
[18:02.440 --> 18:07.120]  только единственный A и B, который даст к нему такое преобразование. Окей? Нормально?
[18:19.240 --> 18:20.920]  Так, это что мы сейчас таким образом доказали?
[18:20.920 --> 18:41.000]  Мы доказали, что у вас есть множество x' и y', и у вас есть множество пар A, B. И мы показали,
[18:41.000 --> 18:48.960]  что мы, на самом деле, показали вот так, что любому элементу отсюда соответствует единственный
[18:48.960 --> 18:57.960]  элемент вот отсюда. Да? Вот. Но осталось нам показать, что действительно все элементы из A, B,
[18:57.960 --> 19:03.160]  они будут соответствовать каким-то элементам из x' и y'. Окей? Но это на самом легко видеть. Почему?
[19:03.160 --> 19:12.880]  Потому что если мы посмотрим на мощность множества всех пар A, B, то почему она равна? Ну не совсем.
[19:12.880 --> 19:20.880]  P на P-1. Почему? Ну, правила произведены, во-первых, во-вторых, потому что у A не
[19:20.880 --> 19:32.480]  может равняться нулю, а B может быть произвольным вычетом по модулю P. Окей? Что? Нет, панофиксировано.
[19:32.480 --> 19:41.760]  Вот нам просто дано такое множество K. Вот нам известно, что все элементы, которые будут
[19:41.760 --> 19:46.920]  переходить к нам в кэш-таблицу, они вот лежат вот в таком множестве, где P это некоторое простое число.
[19:46.920 --> 19:59.840]  Ну оно по условию задачи нам дано. Вам сказано, что, не знаю, вам подаются на вход все числа от 0 до 16.
[19:59.840 --> 20:09.160]  Вот. Значит, в этом случае P равно 17. Короче говоря, можете считать, что если вы обработаетесь
[20:09.160 --> 20:16.880]  на то, то можете считать, что P это какое-нибудь очень большое число, простое. Вот мы сейчас, соответственно,
[20:16.880 --> 20:23.200]  тут помещаются все инты и так далее. Но P заранее фиксированное число, мы его не подбираем. Оно вот в условии
[20:23.200 --> 20:32.800]  задачи нам дано. Вот это это условие задачи. Вот. А чему равно множество всевозможных пар х' и х'?
[20:32.800 --> 20:52.560]  Вот. Вот это х'. Какое количество пар х' и х'? Почему P-1? Да, потому что мы в первом боксе доказали,
[20:52.560 --> 20:58.640]  что х' не может быть равно х'. Это единственное ограничение, окей? Все, а всего количество пар,
[20:58.640 --> 21:07.040]  всего количества несовпадающих пар х' и х', где х' принадлежит от 0 до P-1, и х' принадлежит от 0 до P-1,
[21:07.040 --> 21:11.160]  и при этом они совпадают вот в точно все равно вот это. То есть, на самом деле, вот эти множества,
[21:11.160 --> 21:16.720]  они совпадают, да, и у вас для каждого, для произвольного х' и х' существует ровно один Аб,
[21:16.720 --> 21:24.680]  в который он отворажается. Окей? Вот. Соответственно, доказали биективность.
[21:29.520 --> 21:33.360]  Окей, нормально. Смотрите, что таким образом получилось.
[21:35.360 --> 21:40.280]  Что мы сказали? Мы с вами сказали, что вот у нас есть вот это множество, вот это универсальное множество,
[21:40.280 --> 21:45.680]  пока оно универсальное, да, просто какое это множество. Как я генерирую случайную функцию из него,
[21:45.680 --> 21:52.200]  из этого множества? Ну, как загенерирую случайную функцию из этого множества?
[21:54.120 --> 21:57.000]  Да, просто случайно генерируем А и случайно генерируем evenly нужен,
[21:57.000 --> 22:00.240]  А просто случайно генерируем a, и случайно генерируем b, вот.
[22:00.240 --> 22:02.960]  А теперь смотрите, что мы показали во втором пункте.
[22:02.960 --> 22:04.800]  А во втором пункте мы показали следующее.
[22:04.800 --> 22:08.320]  Смотрите, вот мне приходит какой-то x и какой-то y, абсолютно произвольно, я их не знаю.
[22:08.320 --> 22:09.800]  Они приходят и так далее.
[22:09.800 --> 22:12.000]  И я случайно выбираю a и b.
[22:12.000 --> 22:13.760]  Что это на самом деле означает?
[22:13.760 --> 22:19.440]  Если я случайно выбираю a и b, то я на самом деле абсолютно случайно выбираю их образы, согласны?
[22:19.440 --> 22:21.560]  Случайно выбираю образы x' и y'.
[22:21.560 --> 22:23.920]  То есть что получается, вы мне подавите на вход x и y,
[22:23.920 --> 22:28.400]  а я абсолютно случайным образом перевожу их в какие-то другие два числа.
[22:29.280 --> 22:29.880]  Понятно?
[22:29.880 --> 22:30.880]  Абсолютно рандомно.
[22:32.160 --> 22:32.680]  Согласны?
[22:33.400 --> 22:37.520]  Но так как a и b я выбираю случайно, а между a и b и x' и y' у меня существует би-эксия,
[22:37.520 --> 22:40.040]  то это означает, что по сути я x' и y' выбираю случайно.
[22:41.880 --> 22:42.400]  Окей?
[22:43.280 --> 22:45.840]  Все, то есть теперь я на самом деле могу просто анализировать тот случай,
[22:45.840 --> 22:48.720]  в котором у меня x' и y' абсолютно случайно.
[22:48.720 --> 22:50.400]  Ну вот ровно то, о чем мы говорили в прошлый раз, да?
[22:50.400 --> 22:53.840]  То есть мы, вообще говоря, не можем говорить о том, что у нас данные какие-то случайные.
[22:53.880 --> 22:58.520]  Потому что нам обязательно кто-нибудь подсунет какие-нибудь, в общем, стремные случаи,
[22:58.520 --> 23:00.520]  на которых у нас, конечно, таблица будет падать.
[23:00.520 --> 23:02.520]  Ну, будет работать долго.
[23:02.520 --> 23:05.720]  А тут я говорю, что мне, вообще говоря, неважно, какие вы мне x' и y' не дали,
[23:05.720 --> 23:09.520]  я все равно подкину монетку и переведу их в абсолютно два случайных числа.
[23:10.240 --> 23:12.240]  И вот тут я уже могу анализировать средний случай.
[23:13.920 --> 23:17.120]  Могу анализировать, что у меня происходит там, с какой вероятностью.
[23:18.680 --> 23:21.120]  Ну, соответственно, давайте третий пункт, последний.
[23:22.080 --> 23:24.080]  Наконец, докажем то, чего мы хотим.
[23:24.080 --> 23:26.080]  А хотим мы следующего.
[23:26.080 --> 23:28.080]  Мы хотим, чтобы вероятность...
[23:28.080 --> 23:30.080]  Ну, мы хотим проверить, что вероятность того,
[23:30.080 --> 23:34.080]  что h от x будет равно h от y,
[23:34.080 --> 23:36.080]  будет меньше вероятно, чем 1 на m.
[23:36.080 --> 23:40.080]  Вот это мы должны доказать.
[23:40.080 --> 23:42.080]  Ну, давайте начнем.
[23:42.080 --> 23:46.080]  h от x равно h от y.
[23:46.080 --> 23:48.080]  Ну, это мы перепишем следующим образом.
[23:49.040 --> 23:55.040]  x' процент m равно y' процент m.
[23:55.040 --> 23:57.040]  Согласны?
[23:57.040 --> 23:59.040]  Ну, вот, определение x',
[23:59.040 --> 24:01.040]  вот такое.
[24:01.040 --> 24:03.040]  А функция h, она вот такая.
[24:03.040 --> 24:05.040]  То есть, по сути, x' процент m.
[24:05.040 --> 24:07.040]  Вот.
[24:07.040 --> 24:09.040]  Ну, и тут, смотрите, у меня x' абсолютно случайное,
[24:09.040 --> 24:13.040]  y' абсолютно случайное, при этом они не равны друг другу.
[24:14.000 --> 24:16.000]  С кой вероятностью совпадают
[24:16.000 --> 24:18.000]  остатки случайного числа x'
[24:18.000 --> 24:20.000]  и случайного числа y'?
[24:22.000 --> 24:24.000]  Ну, 1 на m пока слишком сильно.
[24:30.000 --> 24:32.000]  Так.
[24:34.000 --> 24:36.000]  Давайте порисуем.
[24:38.000 --> 24:40.000]  Вот у меня есть числовая прямая.
[24:40.000 --> 24:42.000]  Ну, пусть тут.
[24:42.960 --> 24:48.960]  m, m, 3m, и так далее.
[24:48.960 --> 24:52.960]  Тут какой-то km, и тут значение p.
[24:52.960 --> 24:54.960]  Вот, ну давайте еще вот так.
[24:58.960 --> 25:00.960]  Ну, смотрите, тут давайте снова воспользуемся
[25:00.960 --> 25:02.960]  не меньшим, а давайте просто равно пока напишем.
[25:04.960 --> 25:06.960]  Воспользуемся обычным школьным определением вероятости.
[25:06.960 --> 25:08.960]  Количество благоприятных сходов
[25:08.960 --> 25:10.960]  деленное на общее количество сходов.
[25:12.960 --> 25:14.960]  Что у нас тут будет являться исходом?
[25:14.960 --> 25:16.960]  Ну, исходом будет являться
[25:16.960 --> 25:18.960]  просто какая-то пара x' и y', окей?
[25:20.960 --> 25:22.960]  Какое количество пары x' и y' у меня существует?
[25:22.960 --> 25:24.960]  Уже считали.
[25:24.960 --> 25:26.960]  Да, то есть p на p-1.
[25:28.960 --> 25:30.960]  А теперь давайте посчитаем количество пар x' и y',
[25:30.960 --> 25:32.960]  у которых будут одинаковые остатки определений на m.
[25:32.960 --> 25:34.960]  Ну, смотрите, ну тут все просто.
[25:34.960 --> 25:36.960]  Сколькими способами можно выбрать x?
[25:36.960 --> 25:38.960]  p.
[25:38.960 --> 25:40.960]  То есть выбираем произвольный x.
[25:41.920 --> 25:43.920]  Но, допустим, он попал куда-то вот сюда.
[25:47.920 --> 25:49.920]  Вот где-то здесь x.
[25:51.920 --> 25:53.920]  Вот для этого конкретного x
[25:53.920 --> 25:55.920]  сколько существует y'
[25:57.920 --> 25:59.920]  которые совпадают с ним по остатку?
[26:03.920 --> 26:05.920]  Сколько?
[26:07.920 --> 26:09.920]  Ну, давайте просто нарисуем.
[26:10.880 --> 26:12.880]  Да, вот этот y подходит.
[26:12.880 --> 26:14.880]  А вот этот y подходит.
[26:14.880 --> 26:16.880]  Нет, x' не совпадает с x'.
[26:16.880 --> 26:18.880]  Еще подходит вот этот y,
[26:18.880 --> 26:20.880]  ну и, возможно, вот этот y, да?
[26:20.880 --> 26:22.880]  Ну, тут не факт,
[26:22.880 --> 26:24.880]  но теоретически может быть.
[26:24.880 --> 26:26.880]  Так вот сколько тут деленных точек всего?
[26:28.880 --> 26:30.880]  Да, целая часть
[26:30.880 --> 26:32.880]  p деленная на m
[26:32.880 --> 26:34.880]  окурленная вверх.
[26:34.880 --> 26:36.880]  Это если вот эта точка попадается.
[26:36.880 --> 26:38.880]  Ну, еще, на самом деле, надо вычислить
[26:38.880 --> 26:40.880]  x1, почему?
[26:40.880 --> 26:42.880]  Потому что эта точка у нас не устраивает.
[26:42.880 --> 26:44.880]  Да?
[26:44.880 --> 26:46.880]  Вот.
[26:46.880 --> 26:48.880]  Так.
[26:48.880 --> 26:50.880]  Сейчас напишу вот такую вещь.
[26:50.880 --> 26:52.880]  Целую часть мне неудобна.
[26:52.880 --> 26:54.880]  Кто знает, как целую часть можно ограничить?
[26:54.880 --> 26:56.880]  Ну, точнее,
[26:56.880 --> 26:58.880]  p деленная на m, округленная вверх.
[26:58.880 --> 27:00.880]  Как можно ограничить сверху?
[27:02.880 --> 27:04.880]  Нет, это слишком грубо.
[27:04.880 --> 27:06.880]  Давайте так.
[27:08.880 --> 27:10.880]  Вот так, согласны?
[27:14.880 --> 27:16.880]  Вот.
[27:16.880 --> 27:18.880]  Вы уже видите, что тут получается, нет?
[27:20.880 --> 27:22.880]  Нет?
[27:22.880 --> 27:24.880]  Хорошо.
[27:24.880 --> 27:26.880]  Минус один.
[27:26.880 --> 27:28.880]  Минус один это m деленно на m.
[27:28.880 --> 27:30.880]  p плюс m
[27:30.880 --> 27:32.880]  минус один минус m
[27:32.880 --> 27:34.880]  деленно на m.
[27:34.880 --> 27:36.880]  Приводим к общему знаменателю.
[27:36.880 --> 27:38.880]  Теперь намек понятен.
[27:38.880 --> 27:40.880]  Что мы делаем?
[27:42.880 --> 27:44.880]  p сократить?
[27:44.880 --> 27:46.880]  Ну, давайте сократим.
[27:46.880 --> 27:48.880]  Раз, раз.
[27:48.880 --> 27:50.880]  И на самом деле, вот эта штука тоже сократится.
[27:50.880 --> 27:52.880]  Согласны?
[27:52.880 --> 27:54.880]  И что вот так получится?
[27:56.880 --> 27:58.880]  Ну, кажется, не обманул.
[27:58.880 --> 28:00.880]  Один на m.
[28:00.880 --> 28:02.880]  Вот.
[28:02.880 --> 28:04.880]  Вот такая история.
[28:32.880 --> 28:34.880]  Вот.
[28:34.880 --> 28:36.880]  Вот.
[28:36.880 --> 28:38.880]  Вот.
[28:38.880 --> 28:40.880]  Вот.
[28:40.880 --> 28:42.880]  Вот.
[28:42.880 --> 28:44.880]  Вот.
[28:44.880 --> 28:46.880]  Вот.
[28:46.880 --> 28:48.880]  Вот.
[28:48.880 --> 28:50.880]  Вот.
[28:50.880 --> 28:52.880]  Вот.
[28:52.880 --> 28:54.880]  Вот.
[28:54.880 --> 28:56.880]  Вот.
[28:56.880 --> 28:58.880]  Вот.
[28:58.880 --> 29:00.880]  Вот.
[29:00.880 --> 29:02.880]  Вот.
[29:02.880 --> 29:04.880]  Вот.
[29:04.880 --> 29:06.880]  Вот.
[29:06.880 --> 29:08.880]  Вот.
[29:08.880 --> 29:10.880]  Вот.
[29:10.880 --> 29:12.880]  Вот.
[29:12.880 --> 29:14.880]  Вот.
[29:14.880 --> 29:16.880]  Вот.
[29:16.880 --> 29:18.880]  Вот.
[29:18.880 --> 29:20.880]  Вот.
[29:20.880 --> 29:22.880]  Вот.
[29:22.880 --> 29:24.880]  Вот.
[29:24.880 --> 29:26.880]  Вот.
[29:26.880 --> 29:28.880]  Вот.
[29:28.880 --> 29:30.880]  Вот.
[29:30.880 --> 29:32.880]  Вот.
[29:32.880 --> 29:34.880]  Вот.
[29:34.880 --> 29:36.880]  Вот.
[29:36.880 --> 29:38.880]  Вот.
[29:38.880 --> 29:40.880]  Вот.
[29:40.880 --> 29:42.880]  Вот.
[29:42.880 --> 29:44.880]  Вот.
[29:44.880 --> 29:46.880]  Вот.
[29:46.880 --> 29:48.880]  Вот.
[29:48.880 --> 29:50.880]  Вот.
[29:50.880 --> 29:52.880]  Вот.
[29:52.880 --> 29:54.880]  Вот.
[29:56.880 --> 29:58.880]  Вот.
[29:58.880 --> 30:00.880]  Вот.
[30:00.880 --> 30:02.880]  Вот.
[30:02.880 --> 30:04.880]  Вот.
[30:04.880 --> 30:06.880]  Вот.
[30:06.880 --> 30:08.880]  Вот.
[30:08.880 --> 30:10.880]  Вот.
[30:10.880 --> 30:12.880]  Вот.
[30:12.880 --> 30:14.880]  Вот.
[30:14.880 --> 30:16.880]  Вот.
[30:16.880 --> 30:18.880]  Вот.
[30:18.880 --> 30:20.880]  Вот.
[30:20.880 --> 30:22.880]  Вот.
[30:22.880 --> 30:24.880]  Вот.
[30:24.880 --> 30:26.880]  Вот.
[30:26.880 --> 30:28.880]  Вот.
[30:28.880 --> 30:30.880]  Вот.
[30:30.880 --> 30:32.880]  Вот.
[30:32.880 --> 30:34.880]  Вот.
[30:34.880 --> 30:36.880]  Вот.
[30:36.880 --> 30:38.880]  Вот.
[30:38.880 --> 30:40.880]  Вот.
[30:40.880 --> 30:42.880]  Вот.
[30:42.880 --> 30:44.880]  Вот.
[30:44.880 --> 30:46.880]  Вот.
[30:46.880 --> 30:48.880]  Вот.
[30:48.880 --> 30:50.880]  Вот.
[30:50.880 --> 30:52.880]  Вот.
[30:52.880 --> 30:54.880]  Вот.
[30:54.880 --> 30:56.880]  Вот.
[30:56.880 --> 30:58.880]  Вот.
[30:58.880 --> 31:00.880]  Вот.
[31:00.880 --> 31:02.880]  Вот.
[31:02.880 --> 31:04.880]  Вот.
[31:04.880 --> 31:06.880]  Вот.
[31:06.880 --> 31:08.880]  Вот.
[31:08.880 --> 31:10.880]  Вот.
[31:10.880 --> 31:12.880]  Вот.
[31:12.880 --> 31:14.880]  Вот.
[31:14.880 --> 31:16.880]  Вот.
[31:16.880 --> 31:18.880]  Вот.
[31:18.880 --> 31:20.880]  Вот.
[31:20.880 --> 31:22.880]  Вот.
[31:22.880 --> 31:24.880]  Вот.
[31:24.880 --> 31:26.880]  Вот.
[31:26.880 --> 31:28.880]  Вот.
[31:28.880 --> 31:30.880]  Вот.
[31:30.880 --> 31:32.880]  Вот.
[31:32.880 --> 31:34.880]  Вот.
[31:34.880 --> 31:36.880]  Вот.
[31:36.880 --> 31:38.880]  Вот.
[31:38.880 --> 31:40.880]  Вот.
[31:40.880 --> 31:42.880]  Вот.
[31:42.880 --> 31:44.880]  Вот.
[31:44.880 --> 31:46.880]  Вот.
[31:46.880 --> 31:48.880]  Вот.
[31:48.880 --> 31:50.880]  Вот.
[31:50.880 --> 31:52.880]  Вот.
[31:52.880 --> 31:54.880]  Вот.
[31:54.880 --> 31:56.880]  Вот.
[31:56.880 --> 31:58.880]  Вот.
[31:58.880 --> 32:00.880]  Вот.
[32:00.880 --> 32:02.880]  Вот.
[32:02.880 --> 32:04.880]  Вот.
[32:04.880 --> 32:06.880]  Вот.
[32:06.880 --> 32:08.880]  Вот.
[32:08.880 --> 32:10.880]  Вот.
[32:10.880 --> 32:12.880]  Вот.
[32:12.880 --> 32:14.880]  Вот.
[32:14.880 --> 32:16.880]  Вот.
[32:16.880 --> 32:18.880]  Вот.
[32:18.880 --> 32:20.880]  Вот.
[32:20.880 --> 32:22.880]  Вот.
[32:22.880 --> 32:24.880]  Вот.
[32:24.880 --> 32:26.880]  Вот.
[32:26.880 --> 32:28.880]  Вот.
[32:28.880 --> 32:30.880]  Мы выбираем произвольное b
[32:30.880 --> 32:32.880]  Какое? Мы не выбираем b
[32:32.880 --> 32:34.880]  Мы случайно выбираем h
[32:40.880 --> 32:42.880]  Сейчас, что значит произвольное hb?
[32:42.880 --> 32:44.880]  А b – некоторые паралии, с которыми мы барьируем
[32:44.880 --> 32:48.880]  То есть это параметрическая стимейсия
[32:50.880 --> 32:54.880]  Ну, p мы фиксируем, x или y мы фиксируем
[32:54.880 --> 32:58.880]  И дальше у нас есть мешок вот этих функций
[32:58.880 --> 33:04.880]  И мы должны сказать, что для любых наборов
[33:04.880 --> 33:08.880]  что для любого b, любого m, любого x, любого y
[33:08.880 --> 33:10.880]  у нас вероятность, что это будет меньше, чем одна вторая
[33:10.880 --> 33:14.880]  А тут я привел пример конкретного x и y
[33:14.880 --> 33:18.880]  на которых, соответственно, у меня вероятность большая
[33:18.880 --> 33:24.880]  Пример ящик?
[33:30.880 --> 33:32.880]  Итак, ну и итог
[33:34.880 --> 33:36.880]  Что по итогу?
[33:36.880 --> 33:38.880]  А по итогу у нас получается следующее
[33:38.880 --> 33:42.880]  Смотрите, у нас просто было время
[33:46.880 --> 33:54.880]  У нас было время, чтобы при простом равномерном пушировании
[33:54.880 --> 34:02.880]  в тремя время работы
[34:02.880 --> 34:06.880]  Ваин
[34:06.880 --> 34:10.880]  Поставлял
[34:10.880 --> 34:12.880]  Да?
[34:12.880 --> 34:14.880]  И было же такое
[34:14.880 --> 34:16.880]  Вот я тут знаю, что если делать вот простое
[34:16.880 --> 34:20.880]  равномерное пуширование, заменим на универсалитке
[34:20.880 --> 34:30.880]  То есть при равновероятном пушире h из h большого
[34:30.880 --> 34:38.880]  в среднем равномерном пушире h из h большого
[34:38.880 --> 34:40.880]  в среднем равномерном пушире h из h большого
[34:40.880 --> 34:42.880]  в среднем равномерном пушире h из h большого
[34:42.880 --> 34:46.880]  То есть утверждение теоремы полностью справится
[34:46.880 --> 34:48.880]  Потому что единственное место, где нам требовалось
[34:48.880 --> 34:50.880]  самая вероятность
[34:50.880 --> 34:52.880]  Соответственно, где нам требовались
[34:52.880 --> 34:54.880]  какие-то свойства расширения
[34:54.880 --> 34:56.880]  Это была последняя сторона
[34:56.880 --> 34:58.880]  Потому что там начисляли что?
[34:58.880 --> 35:00.880]  Вот там, где мы делали почки
[35:00.880 --> 35:02.880]  Да, было платье
[35:02.880 --> 35:04.880]  В итоге приходили к свередине соотношения
[35:04.880 --> 35:06.880]  То есть это просто основа
[35:06.880 --> 35:08.880]  Твоя делится до n
[35:08.880 --> 35:10.880]  Роя, x
[35:12.880 --> 35:14.880]  Ну, было такое, да?
[35:14.880 --> 35:16.880]  Да
[35:16.880 --> 35:18.880]  И вот тут раньше
[35:18.880 --> 35:20.880]  Вот эта штука
[35:20.880 --> 35:22.880]  Она раз в сумме
[35:22.880 --> 35:24.880]  Вот n
[35:24.880 --> 35:26.880]  1 на n, где x и y
[35:26.880 --> 35:28.880]  1 на n, где x и y
[35:28.880 --> 35:30.880]  1 на n, где x и y
[35:30.880 --> 35:32.880]  1 на n, где x и y
[35:32.880 --> 35:34.880]  1 на n, где x и y
[35:34.880 --> 35:36.880]  Я что-то про то разомерно кширил
[35:36.880 --> 35:38.880]  Но нам показывают, что
[35:38.880 --> 35:40.880]  вероятность, что 2 случайные
[35:40.880 --> 35:42.880]  что вероятность попадения в 2 случайных чисел
[35:42.880 --> 35:44.880]  Который поднимает значение
[35:44.880 --> 35:46.880]  1 на n, 2 на n
[35:46.880 --> 35:48.880]  1 на n
[35:48.880 --> 35:50.880]  А тут, поскольку мы просто те ли
[35:50.880 --> 35:52.880]  изменили
[35:52.880 --> 35:54.880]  Меньше неправда
[35:54.880 --> 35:56.880]  Меньше неправда, чем от 1 на n
[36:00.880 --> 36:02.880]  Понятно?
[36:08.880 --> 36:10.880]  Ну, минус, что вам нужно для
[36:10.880 --> 36:12.880]  для каждого прежнего кота
[36:14.880 --> 36:16.880]  придумать свой аж
[36:16.880 --> 36:18.880]  Сейчас я привел пример
[36:18.880 --> 36:20.880]  уникальных смесей
[36:20.880 --> 36:22.880]  для аж пушей, когда у меня
[36:22.880 --> 36:24.880]  ключи
[36:24.880 --> 36:26.880]  и целые числа вот с такого множества
[36:26.880 --> 36:28.880]  Если у вас ключи это трое
[36:28.880 --> 36:30.880]  то, соответственно, для троих нужно придумать
[36:30.880 --> 36:32.880]  свое универсальное смесь
[36:32.880 --> 36:34.880]  У нас более этого делать не нужно
[36:34.880 --> 36:36.880]  в целом не нужно целые числа реализовать
[36:36.880 --> 36:38.880]  Все
[36:38.880 --> 36:40.880]  Нет
[36:44.880 --> 36:46.880]  Вот он
[36:46.880 --> 36:48.880]  Это подтверждение понятно?
[36:48.880 --> 36:50.880]  По сути получить другую теорию
[36:50.880 --> 36:52.880]  просто на которую отличается вот в одном символе
[36:52.880 --> 36:54.880]  На вот здесь
[36:54.880 --> 36:56.880]  Все
[36:56.880 --> 36:58.880]  То есть в условии заменяя просто равномерное
[36:58.880 --> 37:00.880]  кширование на универсальное смесь этой функции
[37:00.880 --> 37:02.880]  и меняем два краевеса
[37:02.880 --> 37:04.880]  У нас два краевеса здесь все
[37:04.880 --> 37:06.880]  Мы получили рабочую схему
[37:06.880 --> 37:08.880]  Полностью рабочую схему
[37:08.880 --> 37:10.880]  Давайте ее проговорим
[37:10.880 --> 37:12.880]  Что мы делаем?
[37:12.880 --> 37:14.880]  Нам нужно построить пару данных
[37:14.880 --> 37:16.880]  Которые умеют делать
[37:16.880 --> 37:18.880]  Inter, Raise
[37:18.880 --> 37:20.880]  и Fine
[37:20.880 --> 37:22.880]  Что мы делаем?
[37:22.880 --> 37:24.880]  Мы заводим массив списков
[37:24.880 --> 37:26.880]  Мы случайно выбираем
[37:26.880 --> 37:28.880]  кэш-функцию из универсального смеси
[37:28.880 --> 37:30.880]  То есть нам известно много ключей
[37:30.880 --> 37:32.880]  которые теоретически могут к нам проходить
[37:32.880 --> 37:34.880]  Мы соответственно строим
[37:34.880 --> 37:36.880]  универсальные смеси такой шнукции
[37:36.880 --> 37:38.880]  для этого множества ключей
[37:38.880 --> 37:40.880]  Так что согласно этой шнукции
[37:40.880 --> 37:42.880]  мы распределяем наши элементы
[37:42.880 --> 37:44.880]  по картинам
[37:44.880 --> 37:46.880]  Их два элемента попали в эту картинку
[37:46.880 --> 37:48.880]  если там архитектурный список
[37:48.880 --> 37:50.880]  Списки элементов, которые туда попали
[37:50.880 --> 37:52.880]  И соответственно чтобы удерживать
[37:52.880 --> 37:54.880]  вот это вот соотношение
[37:54.880 --> 37:56.880]  небольшим
[37:56.880 --> 37:58.880]  чтобы оно не раствовало
[37:58.880 --> 38:00.880]  Мы говорим следующую вещь
[38:00.880 --> 38:02.880]  Если кэш-таблица стала равно
[38:02.880 --> 38:04.880]  в ддн-ке
[38:04.880 --> 38:06.880]  то мы увеличиваем
[38:06.880 --> 38:08.880]  кэш-таблицу два раза
[38:08.880 --> 38:10.880]  и производим перепишивание
[38:10.880 --> 38:12.880]  Мы выбираем другую кэш-функцию
[38:12.880 --> 38:14.880]  которая уже отображает
[38:14.880 --> 38:16.880]  во множество окулятых 2м
[38:16.880 --> 38:18.880]  Ну и даже продолжаем оставлять
[38:18.880 --> 38:20.880]  пока не найдем того размера 2m
[38:20.880 --> 38:22.880]  У нас остались элементы
[38:22.880 --> 38:24.880]  кэш-таблицы ровно 2m
[38:24.880 --> 38:26.880]  чтобы увеличивать два раза
[38:26.880 --> 38:28.880]  У нас обучение включает
[38:28.880 --> 38:30.880]  что может быть ограниченным
[38:30.880 --> 38:32.880]  Ну я здесь думал
[38:32.880 --> 38:34.880]  что может быть бесконечным
[38:34.880 --> 38:36.880]  Но на практике у нас ничего бесконечного нет
[38:36.880 --> 38:38.880]  Если вы знаете, например
[38:38.880 --> 38:40.880]  вам нужно хранить имплей
[38:40.880 --> 38:42.880]  Или вы знаете, что вам нужно
[38:42.880 --> 38:44.880]  хранить комплектные вещи
[38:46.880 --> 38:48.880]  Но если вы когда-то продаёте
[38:48.880 --> 38:50.880]  то не знаю, берите
[38:50.880 --> 38:52.880]  Кэш-таблица
[38:52.880 --> 38:54.880]  Я буду хранить целые кэш-таблицы
[38:54.880 --> 38:56.880]  Вот и всё
[38:56.880 --> 38:58.880]  То есть ваш атак
[38:58.880 --> 39:00.880]  это целые кэш-таблицы
[39:00.880 --> 39:02.880]  Понятно?
[39:02.880 --> 39:04.880]  Сколько это?
[39:04.880 --> 39:06.880]  Внимание 20 секунд
[39:06.880 --> 39:08.880]  Ну...
[39:08.880 --> 39:10.880]  Я в своем веке
[39:10.880 --> 39:12.880]  Ну...
[39:12.880 --> 39:14.880]  Я в своем веке
[39:14.880 --> 39:16.880]  Я в своем веке
[39:16.880 --> 39:18.880]  Я в своем веке
[39:18.880 --> 39:20.880]  Я в своем веке
[39:24.880 --> 39:26.880]  Доли этой строго можно придумать
[39:26.880 --> 39:28.880]  свою специальную интервью
[39:32.880 --> 39:34.880]  Так, что остается вопроса?
[39:38.880 --> 39:40.880]  Когда берём?
[39:40.880 --> 39:42.880]  Так, на второй части мы поговорим про
[39:42.880 --> 39:44.880]  идеальное хэширование статического множества
[39:46.880 --> 39:48.880]  Это немного другой урод задачи
[39:48.880 --> 39:50.880]  Которую мы решим
[39:50.880 --> 39:52.880]  соответственно более эффективно, чем
[39:52.880 --> 39:54.880]  исходную
[39:56.880 --> 39:58.880]  Значит, задача ставится следующим образом
[39:58.880 --> 40:00.880]  Дано некоторое важно
[40:00.880 --> 40:02.880]  фиксированное множество х
[40:02.880 --> 40:04.880]  Ну...
[40:04.880 --> 40:06.880]  Ну...
[40:06.880 --> 40:08.880]  Ну...
[40:08.880 --> 40:10.880]  Фиксированное множество х
[40:10.880 --> 40:12.880]  То есть вот до этого мы рассматривали
[40:12.880 --> 40:14.880]  кэш-таблицы, в которые мы
[40:14.880 --> 40:16.880]  периодически появлялись новые элементы
[40:16.880 --> 40:18.880]  из которых удалялись старые элементы
[40:18.880 --> 40:20.880]  Тут нам заранее говорят
[40:20.880 --> 40:22.880]  что вот есть такое множество
[40:22.880 --> 40:24.880]  и оно фиксировано
[40:24.880 --> 40:26.880]  Ничего в него добавляться, ничего из него удаляться не будет
[40:26.880 --> 40:28.880]  Оно такое множество
[40:28.880 --> 40:30.880]  И всё, что вам нужно сделать, это быстро отвечать на вопрос
[40:30.880 --> 40:32.880]  на findX
[40:32.880 --> 40:34.880]  То есть быстро отвечать на вопросы, типа
[40:34.880 --> 40:36.880]  есть ли ваше хэш-таблице это значение, или нет его
[40:36.880 --> 40:38.880]  Никаких вставок, удалений нет
[40:38.880 --> 40:40.880]  То есть естественно
[40:40.880 --> 40:42.880]  какая-то задача тоже можно применить в тот метод
[40:42.880 --> 40:44.880]  который мы обсуждали до этого
[40:44.880 --> 40:46.880]  То есть просто построить хэш-таблицу цепочками
[40:46.880 --> 40:48.880]  то есть выбрать случайную хэш-функцию
[40:48.880 --> 40:50.880]  построить хэш-таблицу, ну и всё
[40:50.880 --> 40:52.880]  То есть теорема нам говорит, что в среднем у нас будет
[40:52.880 --> 40:54.880]  соответственно поиск работать за единицу
[40:54.880 --> 40:56.880]  Но проблема в том, что в худшем случае
[40:56.880 --> 40:58.880]  возможно такая ситуация, при которой у вас
[40:58.880 --> 41:00.880]  поиск, при которой у вас поиск будет работать
[41:00.880 --> 41:02.880]  за линейное время
[41:02.880 --> 41:04.880]  То есть почти все элементы грубо говоря попали в одну корзину
[41:04.880 --> 41:06.880]  От кого никто не застрахован
[41:06.880 --> 41:08.880]  То есть вы всё-таки хэш-функцию выбираете абсолютно случайно
[41:08.880 --> 41:10.880]  Этого бы хотелось избежать
[41:10.880 --> 41:12.880]  Всё-таки хочется, наверное, если вам много что известно заранее
[41:12.880 --> 41:14.880]  наверное хочется его как-то просмотреть
[41:14.880 --> 41:16.880]  и как-то подобрать специальную хэш-функцию
[41:16.880 --> 41:18.880]  ну или как-то подобрать структуру данных
[41:18.880 --> 41:20.880]  которая бы гарантированно сдавала от единицы
[41:20.880 --> 41:22.880]  в худшем случае, то есть за какое-то константное время
[41:22.880 --> 41:24.880]  давала вам чёткий ответ, либо да, либо нет
[41:24.880 --> 41:26.880]  за какое-то константное
[41:26.880 --> 41:28.880]  разумное время
[41:28.880 --> 41:30.880]  То есть грубо говоря
[41:30.880 --> 41:32.880]  мы хотим построить кэш-таблицу
[41:32.880 --> 41:34.880]  в которой бы не было совсем коллизий
[41:34.880 --> 41:36.880]  Ну, мне кажется, цель благородная
[41:36.880 --> 41:38.880]  Давайте обсудим, как её можно
[41:38.880 --> 41:40.880]  как её можно достичь
[41:42.880 --> 41:44.880]  Тут сейчас будет много теории
[41:44.880 --> 41:46.880]  но в конце, я думаю, будет катарсис
[41:46.880 --> 41:48.880]  построим интересную
[41:48.880 --> 41:50.880]  полезную структуру данных
[41:50.880 --> 41:52.880]  Вот, начну давайте
[41:52.880 --> 41:54.880]  несколько поделений
[41:54.880 --> 41:56.880]  несколько утверждений
[41:56.880 --> 41:58.880]  Взря ты спойлер дал
[41:58.880 --> 42:00.880]  Давайте вместе как-то разбираться
[42:00.880 --> 42:02.880]  Давайте я за С
[42:06.880 --> 42:08.880]  Давайте я за С обозначу
[42:10.880 --> 42:12.880]  количество
[42:14.880 --> 42:16.880]  коллизий
[42:18.880 --> 42:20.880]  кэш-таблицы
[42:20.880 --> 42:22.880]  Вот, то есть
[42:22.880 --> 42:24.880]  вот у меня есть множество х
[42:24.880 --> 42:26.880]  у меня есть множество х
[42:26.880 --> 42:28.880]  х1, х2 и так далее
[42:28.880 --> 42:30.880]  хн
[42:30.880 --> 42:32.880]  и какая-то хэш-функция h, которая
[42:32.880 --> 42:34.880]  отображает множество k
[42:34.880 --> 42:36.880]  2 множество 0
[42:36.880 --> 42:38.880]  1 и так далее
[42:38.880 --> 42:40.880]  и минус 1
[42:40.880 --> 42:42.880]  Вот, ну и на самом деле
[42:42.880 --> 42:44.880]  c
[42:44.880 --> 42:46.880]  c это просто количество пара
[42:46.880 --> 42:48.880]  x и g, на которых у меня h
[42:48.880 --> 42:50.880]  даёт один и тот же ответ
[42:50.880 --> 42:52.880]  просто наоборот определение коллизий
[42:52.880 --> 42:54.880]  Начну, утверждение 1
[42:54.880 --> 42:56.880]  заключается в том, что
[42:56.880 --> 42:58.880]  нужно расписать так
[43:00.880 --> 43:02.880]  h от x и
[43:02.880 --> 43:04.880]  равно h от x и g
[43:04.880 --> 43:06.880]  и меньше, чем g
[43:06.880 --> 43:08.880]  Ну, я пояснять думаю не буду
[43:08.880 --> 43:10.880]  Ну, я надеюсь, это понятно
[43:10.880 --> 43:12.880]  Это просто по определению
[43:12.880 --> 43:14.880]  коллизий. Вы переврать все возможные пары
[43:14.880 --> 43:16.880]  и g и смотрите, есть у вас коллизия или нет
[43:16.880 --> 43:18.880]  Ну, с индикаторной функцией в прошлый раз знакомились
[43:18.880 --> 43:20.880]  То есть она равна 1 если true
[43:20.880 --> 43:22.880]  и 0 если false
[43:22.880 --> 43:24.880]  С этим согласны
[43:24.880 --> 43:26.880]  Второй пункт
[43:26.880 --> 43:28.880]  Второе утверждение
[43:28.880 --> 43:30.880]  Вот, смотрите, давайте я теперь h
[43:30.880 --> 43:32.880]  пусть теперь у меня h
[43:32.880 --> 43:34.880]  выбрана случайно
[43:34.880 --> 43:36.880]  из универсального семейства
[43:36.880 --> 43:38.880]  Вот сейчас, начиная с текущего момента
[43:38.880 --> 43:40.880]  мы, когда я буду говорить про случайную хэш-функцию
[43:40.880 --> 43:42.880]  всегда подразумеваем универсальное семейство
[43:42.880 --> 43:44.880]  Потому что простого равномерокшери не существует
[43:44.880 --> 43:46.880]  Всё, что у нас есть, это универсальное семейство
[43:48.880 --> 43:50.880]  Пусть h
[43:50.880 --> 43:52.880]  выбрана
[43:56.880 --> 43:58.880]  равновероятно
[43:58.880 --> 44:00.880]  из универсального семейства
[44:00.880 --> 44:02.880]  h большое
[44:02.880 --> 44:04.880]  Вот
[44:04.880 --> 44:06.880]  Тогда
[44:06.880 --> 44:08.880]  среднее значение
[44:08.880 --> 44:10.880]  среднее количество коллизий в хэштаблице
[44:10.880 --> 44:12.880]  будет равно
[44:14.880 --> 44:16.880]  n на m-1
[44:16.880 --> 44:18.880]  зеленая на 2m
[44:20.880 --> 44:22.880]  Ну, доказательство просто следует
[44:22.880 --> 44:24.880]  из утверждения 1
[44:24.880 --> 44:26.880]  то есть среднее значение c
[44:26.880 --> 44:28.880]  это есть среднее значение этой суммы
[44:28.880 --> 44:30.880]  по утверждению 1
[44:38.880 --> 44:40.880]  Дальше я знак среднего
[44:40.880 --> 44:42.880]  могу внести под знак суммы
[44:42.880 --> 44:44.880]  это мы в прошлый раз обсуждали
[44:44.880 --> 44:46.880]  средняя сумма и то же самое, что сумма средних
[44:46.880 --> 44:48.880]  Ну а среднее значение, величины, который
[44:48.880 --> 44:50.880]  среднее значение либо единицы, либо ноль, чему равно
[44:50.880 --> 44:52.880]  Тоже в прошлый раз обсуждали
[44:54.880 --> 44:56.880]  Просто вероятность вот этого события
[44:56.880 --> 44:58.880]  Это есть не что иное
[44:58.880 --> 45:00.880]  Просто сумма по имени с чем g
[45:00.880 --> 45:02.880]  вероятность h от x
[45:02.880 --> 45:04.880]  равно
[45:04.880 --> 45:06.880]  h от x g
[45:10.880 --> 45:12.880]  Ну а это есть не что иное
[45:12.880 --> 45:14.880]  Это не превосходит n-1
[45:14.880 --> 45:16.880]  пополам умножить
[45:16.880 --> 45:18.880]  1 на m
[45:18.880 --> 45:20.880]  Понятно, откуда последнее взялось?
[45:24.880 --> 45:26.880]  Но вот эта штука, каждый из слагаемых
[45:26.880 --> 45:28.880]  не превосходит 1 на m. Почему?
[45:28.880 --> 45:30.880]  Потому что h у меня из универсального семейства
[45:30.880 --> 45:32.880]  Просто по пределам универсального семейства
[45:32.880 --> 45:34.880]  у нас вероятность совпадения
[45:34.880 --> 45:36.880]  двух элементов,
[45:36.880 --> 45:38.880]  двух значений,
[45:38.880 --> 45:40.880]  аргументов, которых не равны друг другу
[45:40.880 --> 45:42.880]  не превосходит 1 на m
[45:42.880 --> 45:44.880]  Но всего членов в этой сумме
[45:44.880 --> 45:46.880]  н-1 пополам
[45:46.880 --> 45:48.880]  Общее количество пар
[45:48.880 --> 45:50.880]  по множеству x1, тогда xn
[45:50.880 --> 45:52.880]  и n-1 пополам
[45:52.880 --> 45:54.880]  Понятно?
[46:02.880 --> 46:04.880]  Поэтому есть вопросы?
[46:04.880 --> 46:06.880]  Что можно?
[46:06.880 --> 46:08.880]  Вот
[46:14.880 --> 46:18.880]  Давайте проанализируем этот результат
[46:18.880 --> 46:20.880]  Что мы на самом деле получаем?
[46:20.880 --> 46:22.880]  Мы получаем следующую вещь
[46:22.880 --> 46:24.880]  Вот вы взяли кэш-таблицу
[46:24.880 --> 46:26.880]  и при этом кэш-таблицу размера m
[46:26.880 --> 46:28.880]  То есть у вас есть
[46:28.880 --> 46:30.880]  множество из n элементов
[46:30.880 --> 46:32.880]  и вы взяли кэш-таблицу размера m
[46:32.880 --> 46:34.880]  То есть массив размера m
[46:34.880 --> 46:36.880]  И дальше случайным образом
[46:36.880 --> 46:38.880]  выбираете хэш-функцию и смотрите
[46:38.880 --> 46:40.880]  сколько эта хэш-функция дает вам коллизий
[46:40.880 --> 46:42.880]  То есть мы во что целимся?
[46:42.880 --> 46:44.880]  Мы хотим построить кэш-таблицу
[46:44.880 --> 46:46.880]  которая бы вообще не давала коллизий
[46:46.880 --> 46:48.880]  А тут мы видим, что среднее значение коллизий
[46:48.880 --> 46:50.880]  примерно равно
[46:50.880 --> 46:52.880]  n на n-1 делено n2m
[46:52.880 --> 46:54.880]  То есть кажется, что из этого следует
[46:54.880 --> 46:56.880]  что m должно быть достаточно большим
[46:56.880 --> 46:58.880]  чтобы у вас среднее количество коллизий
[46:58.880 --> 47:00.880]  было достаточно маленьким
[47:00.880 --> 47:02.880]  То есть m должна быть как минимум n2
[47:02.880 --> 47:04.880]  Наверное
[47:04.880 --> 47:06.880]  Понятно?
[47:06.880 --> 47:08.880]  Но интерпретация, понятно?
[47:08.880 --> 47:10.880]  Чтобы у вас количества коллизий было мало
[47:10.880 --> 47:12.880]  Размер самой кэш-таблицы был достаточно большим
[47:14.880 --> 47:16.880]  Ну ладно, пока запомню этот результат
[47:16.880 --> 47:18.880]  Пойдем дальше
[47:18.880 --> 47:20.880]  Следующий результат
[47:20.880 --> 47:22.880]  будет не совсем из алгоритмов
[47:22.880 --> 47:24.880]  а будет из теории вероятности
[47:24.880 --> 47:26.880]  Но нам понадобится
[47:26.880 --> 47:28.880]  Лемма Маркова
[47:36.880 --> 47:38.880]  Пусть x
[47:38.880 --> 47:40.880]  из случайной величины
[47:40.880 --> 47:42.880]  Тут я делаю оговорку
[47:42.880 --> 47:44.880]  что я не вожу формально понять
[47:44.880 --> 47:46.880]  что такое случайная величина
[47:46.880 --> 47:48.880]  Я просто обращаюсь к вашей интуиции
[47:48.880 --> 47:50.880]  То есть это просто некоторая величина
[47:50.880 --> 47:52.880]  которая принимает случайные значения
[47:52.880 --> 47:54.880]  Из случайной величины
[47:54.880 --> 47:56.880]  принимающее
[48:00.880 --> 48:02.880]  значение
[48:02.880 --> 48:04.880]  из
[48:04.880 --> 48:06.880]  Ну давайте еще ноль включим
[48:06.880 --> 48:08.880]  Грубо говоря, случайная величина
[48:08.880 --> 48:10.880]  это дать некоторого случайного эксперимента
[48:10.880 --> 48:12.880]  Ну, например, подбрасывание монетки
[48:12.880 --> 48:14.880]  выбор какой-нибудь случайной функции
[48:14.880 --> 48:16.880]  измерение силы тока на лабах и так далее
[48:16.880 --> 48:18.880]  Понятно?
[48:18.880 --> 48:20.880]  Вот, понимаешь, что значение
[48:20.880 --> 48:22.880]  из n0
[48:22.880 --> 48:24.880]  Что я хочу сказать?
[48:24.880 --> 48:26.880]  Хочу сказать, что тогда
[48:26.880 --> 48:28.880]  для любого епсилон больше нуля
[48:28.880 --> 48:30.880]  вероятность того, что x
[48:30.880 --> 48:32.880]  будет больше чем епсилон
[48:32.880 --> 48:34.880]  ну, больше любра равно чем епсилон
[48:34.880 --> 48:36.880]  Больше любра равно чем
[48:36.880 --> 48:38.880]  среднее значение величины x
[48:38.880 --> 48:40.880]  зеленой епсилон
[48:40.880 --> 48:42.880]  Вот, можно сразу посмотреть на эту формулировку
[48:42.880 --> 48:44.880]  и проинтерпретировать этот результат
[48:44.880 --> 48:46.880]  Что этот результат нам говорит?
[48:46.880 --> 48:48.880]  Зачем он нам нужен?
[48:48.880 --> 48:50.880]  А он нам нужен для того, чтобы мы по-среднему могли
[48:50.880 --> 48:52.880]  как-то оценивать вероятности
[48:52.880 --> 48:54.880]  То есть что нам эта штука говорит?
[48:54.880 --> 48:56.880]  Что говорит о том, что если у вас вдруг
[48:56.880 --> 48:58.880]  среднее значение какой-то величины мало
[48:58.880 --> 49:00.880]  если вы понимаете, что вы проводите эксперимент
[49:00.880 --> 49:02.880]  и у вас в среднем получается какое-то маленькое значение
[49:02.880 --> 49:04.880]  то же будет мало
[49:04.880 --> 49:06.880]  Вы на самом деле не явно используете этот результат
[49:06.880 --> 49:08.880]  например, когда говорили про
[49:08.880 --> 49:10.880]  не знаю, быструю сортировку
[49:10.880 --> 49:12.880]  То есть вы говорили, что быстрая сортировка в среднем работает за n log n
[49:12.880 --> 49:14.880]  Ну и в целом говорили, что вероятность больших значений
[49:14.880 --> 49:16.880]  вероятность того, что сортировка будет работать за n квадрат
[49:16.880 --> 49:18.880]  крайне мала
[49:18.880 --> 49:20.880]  Вот, собственно, это некоторые следствия из этого
[49:20.880 --> 49:22.880]  Понятно?
[49:22.880 --> 49:24.880]  Окей?
[49:24.880 --> 49:26.880]  Ну, доказательство тоже простое
[49:28.880 --> 49:30.880]  Давайте распишем среднее
[49:30.880 --> 49:32.880]  Среднее x это
[49:32.880 --> 49:34.880]  есть не что иное, как сумма по x
[49:34.880 --> 49:36.880]  от 0 до бесконечности
[49:36.880 --> 49:38.880]  То есть у меня x принимает значение из натуральных чисел
[49:38.880 --> 49:40.880]  с 0
[49:40.880 --> 49:42.880]  Поэтому я просуммирую по всем значениям
[49:42.880 --> 49:44.880]  И, соответственно
[49:44.880 --> 49:46.880]  умножу конкретное значение
[49:46.880 --> 49:48.880]  на вероятность всего появления
[49:48.880 --> 49:50.880]  Это в чисто виде среднее
[49:50.880 --> 49:52.880]  Тоже в прошлый раз обсуждали
[49:52.880 --> 49:54.880]  Вот
[49:54.880 --> 49:56.880]  Так, вы давайте из этой суммы
[49:56.880 --> 49:58.880]  я выкину лишнее
[49:58.880 --> 50:00.880]  Лишнее это те значения x, которые меньше, чем епсилон
[50:10.880 --> 50:12.880]  Просто из этой суммы выкинули какие-то маленькие значения
[50:12.880 --> 50:14.880]  Понятное дело, что я ее не уменьшил
[50:14.880 --> 50:16.880]  Почему? Потому что у меня x от приории больше, чем 0
[50:18.880 --> 50:20.880]  Ну и сейчас я еще сильнее
[50:20.880 --> 50:22.880]  уменьшу эту сумму
[50:22.880 --> 50:24.880]  Посмотрите, если у меня все x больше, чем епсилон
[50:24.880 --> 50:26.880]  Согласны ли вы, что я могу x заменить на епсилон
[50:26.880 --> 50:28.880]  Тем самым я сумму только уменьшу
[50:28.880 --> 50:30.880]  Да?
[50:30.880 --> 50:32.880]  Давайте я просто все x заменю на епсилон
[50:32.880 --> 50:34.880]  Ну и сразу вытащу эту константу за скоб
[50:34.880 --> 50:36.880]  Так получу сумма
[50:36.880 --> 50:38.880]  по всем x больше, чем епсилон
[50:38.880 --> 50:40.880]  x большое
[50:40.880 --> 50:42.880]  равно конкретному x малому
[50:42.880 --> 50:44.880]  Так
[50:44.880 --> 50:46.880]  А вот это что?
[50:46.880 --> 50:48.880]  Чему равна сумма вероятности
[50:48.880 --> 50:50.880]  x большое, случайная величина
[50:50.880 --> 50:52.880]  равна значению x
[50:52.880 --> 50:54.880]  Если я буду суммировать по всем x больше,
[50:54.880 --> 50:56.880]  то я получу сумму
[51:00.880 --> 51:02.880]  Ну что такое вот эта сумма?
[51:02.880 --> 51:04.880]  Да, ну это просто
[51:04.880 --> 51:06.880]  вероятность того, что у меня x большое
[51:06.880 --> 51:08.880]  будет больше, чем епсилон, согласны?
[51:18.880 --> 51:20.880]  Ну все
[51:24.880 --> 51:26.880]  Есть вопросы?
[51:30.880 --> 51:32.880]  Все нормально?
[51:32.880 --> 51:34.880]  Окей
[51:36.880 --> 51:38.880]  Ну да, тут нужно сказать, что
[51:38.880 --> 51:40.880]  лемма на самом деле верна
[51:40.880 --> 51:42.880]  и в произвольной случае, когда у вас
[51:42.880 --> 51:44.880]  есть произвольная, неотрицательная, случайная величина
[51:44.880 --> 51:46.880]  То есть она не обязательно должна быть дискретной
[51:46.880 --> 51:48.880]  и так далее, но это уже
[51:48.880 --> 51:50.880]  на теорию вероятности вам останется
[51:50.880 --> 51:52.880]  Все? Можем дальше идти?
[51:56.880 --> 51:58.880]  Так
[51:58.880 --> 52:00.880]  Давайте формулировку оставим
[52:02.880 --> 52:04.880]  Теперь я, значит,
[52:04.880 --> 52:06.880]  готов сделать следующее заявление
[52:06.880 --> 52:08.880]  Заявление будет такое
[52:08.880 --> 52:10.880]  Если возьмете хэш-таблицу
[52:10.880 --> 52:12.880]  размера n квадрат
[52:12.880 --> 52:14.880]  то с очень маленькой вероятностью
[52:14.880 --> 52:16.880]  в ней будет хоть одна коллизия
[52:16.880 --> 52:18.880]  Точнее, давайте так
[52:18.880 --> 52:20.880]  с очень большой вероятностью
[52:20.880 --> 52:22.880]  в ней вообще не будет коллизий
[52:22.880 --> 52:24.880]  Нормально?
[52:26.880 --> 52:28.880]  Теорема
[52:28.880 --> 52:30.880]  1
[52:30.880 --> 52:32.880]  Ну, снова традиционно
[52:32.880 --> 52:34.880]  пусть h
[52:36.880 --> 52:38.880]  равновероятно
[52:38.880 --> 52:40.880]  выбрана
[52:40.880 --> 52:42.880]  из универсального смеси
[52:42.880 --> 52:44.880]  большое
[52:44.880 --> 52:46.880]  и
[52:46.880 --> 52:48.880]  соответственно
[52:48.880 --> 52:50.880]  и размер хэш-таблицы
[52:50.880 --> 52:52.880]  равен квадрату количества элементов
[52:52.880 --> 52:54.880]  которые в ней хранится
[52:56.880 --> 52:58.880]  Тогда вероятность того, что
[52:58.880 --> 53:00.880]  число коллизий будет
[53:00.880 --> 53:02.880]  больше равно, чем единица
[53:02.880 --> 53:04.880]  то есть вероятность того, что будет хотя бы одна коллизия
[53:04.880 --> 53:06.880]  меньше, чем
[53:06.880 --> 53:08.880]  одна вторая
[53:08.880 --> 53:10.880]  То есть можно
[53:10.880 --> 53:12.880]  прочитать наоборот
[53:12.880 --> 53:14.880]  что больше, чем одна вторая
[53:14.880 --> 53:16.880]  у вас в хэш-таблице вообще не будет коллизий
[53:16.880 --> 53:18.880]  Понятно? Вот выбираете случайную функцию
[53:18.880 --> 53:20.880]  случайную хэш-функцию
[53:20.880 --> 53:22.880]  и вот собирается больше чем 50%
[53:22.880 --> 53:24.880]  вы говорите, что в моей хэш-таблице коллизий вообще не будет
[53:24.880 --> 53:26.880]  Нормально?
[53:28.880 --> 53:30.880]  Доказательство
[53:30.880 --> 53:32.880]  Ну, доказательство простое
[53:32.880 --> 53:34.880]  Тут мы просто применяем левую маркову
[53:34.880 --> 53:36.880]  В поле марковы
[53:40.880 --> 53:42.880]  В поле марковы
[53:42.880 --> 53:44.880]  такую вероятность можем оценить как?
[53:44.880 --> 53:46.880]  как среднее значение
[53:46.880 --> 53:48.880]  С, деленное единицу
[53:48.880 --> 53:50.880]  Эпилон, парной единицы
[53:50.880 --> 53:52.880]  Согласны?
[53:52.880 --> 53:54.880]  Только что доказали
[54:00.880 --> 54:02.880]  А по утверждению 2
[54:02.880 --> 54:04.880]  Мы доказывали, как можно ограничить среднее значение
[54:04.880 --> 54:06.880]  среднее число коллизий
[54:06.880 --> 54:08.880]  Даже не ограничить, по-моему там равенство было, да?
[54:08.880 --> 54:10.880]  Нет, неравенство
[54:10.880 --> 54:12.880]  Почему оно было равно?
[54:16.880 --> 54:18.880]  n на n-1 на 2m
[54:18.880 --> 54:20.880]  Все, теперь вспоминаем, что
[54:20.880 --> 54:22.880]  у нас m это n квадрат
[54:22.880 --> 54:24.880]  Получаем n на n-1
[54:24.880 --> 54:26.880]  деленное на 2n квадрат
[54:26.880 --> 54:28.880]  меньше, чем одна вторая
[54:28.880 --> 54:30.880]  Последний переход, упражнение
[54:30.880 --> 54:32.880]  Окей?
[54:36.880 --> 54:38.880]  Вот
[54:40.880 --> 54:42.880]  Да, смысл обсудили
[54:42.880 --> 54:44.880]  Если возьмете кэш-таблицу
[54:44.880 --> 54:46.880]  у которой размер равен квадрату
[54:46.880 --> 54:48.880]  количеству ее элементов, то все
[54:48.880 --> 54:50.880]  у вас гарантированно коллизий не будет
[54:50.880 --> 54:52.880]  Вы можете сказать следующую вещь
[54:52.880 --> 54:54.880]  Это все равно случайный процесс
[54:54.880 --> 54:56.880]  Вы взяли кэш-функцию, и вам не повезло
[54:56.880 --> 54:58.880]  в ней есть коллизий, что делать?
[54:58.880 --> 55:00.880]  Давайте я буду убрать хэш-функцию
[55:00.880 --> 55:02.880]  если получившись хэш-таблицы, у меня есть коллизии
[55:02.880 --> 55:04.880]  я буду строить хэш-таблицу заново
[55:04.880 --> 55:06.880]  возьму другую хэш-функцию
[55:06.880 --> 55:08.880]  и, соответственно, построю theyол к хэш-таблицу заново
[55:08.880 --> 55:10.880]  Если и в ней есть коллизии, то снова возьму хэш-функцию
[55:10.880 --> 55:12.880]  и построю заново
[55:12.880 --> 55:14.880]  Понятное дело, что
[55:14.880 --> 55:16.880]  теоретически такой процесс может Mercedes бесконечно
[55:16.880 --> 55:18.880]  но с учетом того, что у вас
[55:18.880 --> 55:26.880]  с предвир ¿
[55:26.880 --> 55:34.880]  рацией, согласны? План понятен? Конечно, таблица размерами квадрат. Вытаскиваем из мешка
[55:34.880 --> 55:39.000]  случайный кэш-функт до тех пор, пока вам не повезет. А повезти вам, согласно этой теории,
[55:39.000 --> 55:42.600]  должно быть достаточно быстро, потому что вам не везет с вероятностью умеющего 1 на 2.
[55:57.880 --> 56:05.280]  Нет, ну нет, подождите, у вас, не знаю, у вас количество интов 4 миллиарда, а за хэш-функт вам нужно всего лишь
[56:05.280 --> 56:15.640]  тысячу из них. Тогда m равно миллиону, нормально. Ну, m может быть больше, чем n? Давайте напишем такое
[56:15.720 --> 56:23.240]  отношение. m больше, чем n, но меньше, чем мощность k. Даже много меньше можно написать.
[56:23.240 --> 56:30.520]  У вас наверняка тут что-то смущает, что?
[56:30.520 --> 56:47.320]  Разве вот это не смущает, нет? Ну хорошо. Сколько элементов вы таким образом можете сохранить в хэш-таблице,
[56:47.320 --> 57:01.400]  не попадая под мл на 27-м тесте? Это спойлер. Ну сколько? Ну, n равное тысяче, m равное миллион,
[57:01.400 --> 57:08.160]  ну терпимо. n равно 10 тысяч, ну 100 миллионов, ну терпимо. n равно 10 пятый, все, без шансов.
[57:08.160 --> 57:17.080]  Логично. То есть, смотрите, на самом деле n у вас, вы не можете захэшировать достаточно
[57:17.080 --> 57:23.000]  большое множество. То есть, даже множество размера миллион или 100 тысяч, это уже все, конец. То есть,
[57:23.000 --> 57:27.720]  это уже слишком сложно. Вообще, вы должны, наверное, еще с первого семестра понимать, что квадратичная
[57:27.720 --> 57:38.280]  сложность это как-то ну тумач, вот чего-то быстрее. Вот. Поэтому это все хорошо, но у нас будет другой
[57:38.280 --> 57:46.080]  план. В смысле, это нам пригодится, вот, но мы будем действовать по-другому. Значит, если мы будем
[57:46.080 --> 57:52.880]  строить одну большую кэш-таблицу размера n квадрат, будет очень плохо. Я предложу следующую вещь.
[57:52.880 --> 58:01.840]  Давайте построим обычную маленькую кэш-таблицу. Ну вот, для тех элементов, которые попали вот
[58:01.840 --> 58:09.080]  в каждый конкретный элемент, в каждую конкретную корзину, я построю свою кэш-таблицу уже размера
[58:09.080 --> 58:15.400]  n квадрат. То есть, у меня будет кэш-таблица кэш-таблиц. То есть, у меня будет не одна большая
[58:15.400 --> 58:19.480]  кэш-таблица размера n квадрат, а будет много маленьких кэш-таблиц, каждый из которых будет
[58:19.480 --> 58:34.600]  иметь размер квадратик от количества элементов, которые у него попало. Окей? Вот. Нет, нам ничего не
[58:34.600 --> 58:40.280]  попадает. Нам множество уже дано, куда-нибудь добавляется. Какой вопрос еще был?
[58:40.280 --> 58:50.200]  Все, будем действовать так. Построим маленькую кэш-таблицу, а внутри каждой ячейки построим
[58:50.200 --> 58:55.400]  такую кэш-таблицу, которая будет иметь размер квадрата от количества элементов, которые
[58:55.400 --> 59:01.320]  у него попали. Возникнет естественный вопрос. А почему эта кэш-таблица не может иметь большой
[59:01.320 --> 59:05.720]  размер? Ну окей, мы понимаем, что n квадрат может быть большим. А если я просумирую квадраты,
[59:05.720 --> 59:13.040]  это число же тоже теоретически может быть большим. Вот. Вот следующее утверждение. 1 квадрат
[59:13.040 --> 59:22.600]  хуже, чем много маленьких квадратчиков. Утверждение такое. Теорема 2. Ну да, как обычно,
[59:22.600 --> 59:29.480]  давайте я преамбулу опущу. Ну про h вы все понимаете. h берется случайно, равновероятно из
[59:29.480 --> 59:38.960]  универсального семейства хэш-функций. Вот. Дальше. Пусть у меня n равно n. То есть я беру обычную
[59:38.960 --> 59:43.880]  кэш-таблицу, которая имеет размер соответствующий ровно количеству элементов, которые нам нужно
[59:43.880 --> 01:00:05.720]  захэшировать. Вот. Значит, пусть в эту ячейку попало n и элементов. Вот мне хочется понять,
[01:00:05.720 --> 01:00:11.560]  если я по всем ячейкам просумирую квадраты их размеров, получится у меня большое число или
[01:00:11.560 --> 01:00:16.400]  небольшое число? Значит, утверждение, что будет небольшое число, а именно среднее значение суммы
[01:00:16.400 --> 01:00:30.920]  квадратов по i от единицы до n будет меньше, чем 2n. Вот. Если вы просумируете квадраты всех размеров
[01:00:30.920 --> 01:00:35.960]  ячеек, ну и усредните по нескольким экспериментам, по нескольким запускам, то вы на самом деле всего лишь
[01:00:35.960 --> 01:00:41.160]  получите значение, не превосходящее 2n. То есть размер на самом деле будет линейный относительно
[01:00:41.160 --> 01:00:49.480]  количества элементов, которые хранится в хэш-таблице. Доказательства. Давай для начала напишем вот так.
[01:00:49.480 --> 01:01:05.680]  Давайте вот эту сумму я распишу по-другому. 2 сумма i единицы до m, ni на ni минус 1 пополам
[01:01:05.680 --> 01:01:20.960]  плюс 1 на единицы. Так, вот это всем понятно. На двоих я может не обращать внимания, они там
[01:01:20.960 --> 01:01:27.120]  сокращаются. Тут стоит сумма ni на ni минус 1, и я из нее, из этой суммы ni квадрат, вытащил просто ni.
[01:01:27.120 --> 01:01:34.880]  Понятно? Понятно, что вот эта вот штука и вот эта штука сумме дает ni квадрате. Не сложно.
[01:01:34.880 --> 01:01:50.320]  Тут есть два слагаммера. Вот это и вот это. Давайте к самой сообразительной. Кто скажет мне,
[01:01:50.320 --> 01:02:01.480]  чему равна вот эта штука? Вот эта. Чему равна сумма размеров каждой ячейки? n. Всего у меня элементов
[01:02:01.480 --> 01:02:08.880]  n, поэтому если я просуммирую размеры каждой ячейки, то получу n. Отлично. Замечательно. Так,
[01:02:08.880 --> 01:02:19.400]  теперь для более сообразительных. Нет, давайте вот так. Чему равна вот эта штука?
[01:02:20.120 --> 01:02:23.840]  Давайте так. В чем смысл вот этой штуки? Как вы можете проинтерпретировать это значение?
[01:02:23.840 --> 01:02:35.800]  Отлично. Замечательно. А почему-то более конкретно. Давайте в терминах коллизий. В терминах
[01:02:35.800 --> 01:02:51.400]  коллизий. Чему это равно? Хорошо. Вот у вас есть ячейка с кодовым названием i. И в ней есть,
[01:02:51.400 --> 01:03:03.880]  давайте вот так изброшу, мешочек. В этом мешочке и элементов. Давай так. Комминаторика была? Какой
[01:03:03.880 --> 01:03:12.760]  комминаторный смысл вот этой штуки? Число сочетаний, число двоек. Число двоек, число пар. Неупорядочно.
[01:03:12.760 --> 01:03:24.640]  А чему равно число неупорядочных пар вот в этом мешочке? Согласны, что это количество коллизий,
[01:03:24.640 --> 01:03:32.760]  которое образует вот эти элементы между собой? Взял произвольный элемент отсюда, взял произвольные два
[01:03:32.760 --> 01:03:39.800]  элемента. Согласны ли вы, что они образуют коллизию? Сейчас, подождите. Они образуют коллизию,
[01:03:39.800 --> 01:03:46.680]  согласны? Взял еще пару элементов, они образуют коллизию. Если я просуммирую все возможные пары
[01:03:46.680 --> 01:03:52.040]  вот здесь, то я получу количество коллизий вот в этом мешочке. Согласны? А если я просуммирую число
[01:03:52.040 --> 01:03:59.840]  коллизий по всем мешочкам? Это общее количество коллизий. Согласны? То есть, это ничто иное как два на
[01:03:59.840 --> 01:04:11.440]  С. Так, это понятно? Смотрите. Давайте я возьму два мешочка. Вот я возьму произвольный элемент отсюда
[01:04:11.440 --> 01:04:16.360]  и произвольный элемент отсюда. Образуют ли они коллизию между собой или нет? Нет, потому что они
[01:04:16.360 --> 01:04:20.520]  у них разные херозначения, они в разных мешках. Соответственно, коллизии могут образовываться
[01:04:20.520 --> 01:04:25.760]  только для элементов в одном мешке. Согласны? А сколько всего тут коллизий? Всего тут коллизий — это
[01:04:25.760 --> 01:04:31.320]  ровно количество пар. Количество пар элементов отсюда. А количество пар элементов отсюда — это вот краски
[01:04:31.320 --> 01:04:39.760]  вот эта штука. Число сочетаний по два. Если я просуммировал это по всем, по каждой ячейке, по каждому
[01:04:39.760 --> 01:04:54.480]  мешочку, то я получу краски С. Ну, двойка она вот отсюда возникла. Понятно? Допустим. Так, теперь вот от этого всего
[01:04:54.480 --> 01:05:13.080]  нужно взять среднее. Так, вот эту сумму я расписал вот так. Соответственно, это среднее от 2c плюс
[01:05:13.080 --> 01:05:22.320]  среднее значение n. Так, снова проявляем смекалку. Чему равно среднее значение n? n — отлично. n — это
[01:05:22.320 --> 01:05:26.160]  константа. Это не случайная величина. Она, как ни крути, всегда будет n. Как бы вы х-функцию не
[01:05:26.160 --> 01:05:36.200]  убирали. Так, а среднее значение, а среднее значение, среднее удвоенное значение числа коллизий? Мы считали.
[01:05:36.200 --> 01:05:44.600]  Но это n на n минус 1, деленное на 2m, но двойка убивается, поэтому тут получается просто m. А m у нас равно n?
[01:05:44.600 --> 01:05:52.400]  m равно n. Соответственно, я получаю 2n минус 1, что меньше, чем 2n. Это тоже упражнение.
[01:05:57.640 --> 01:05:58.160]  Получилось?
[01:05:58.160 --> 01:06:27.920]  Окей, окей, окей. Так, слайды закончились.
[01:06:28.160 --> 01:06:40.040]  Ну все, смотрите, смотрите, что мы получили. Еще раз напоминаю наш план. Мы берем х-таблицу размера
[01:06:40.040 --> 01:06:49.480]  равную n. Распределяем все элементы по этой самой х-таблице. А дальше внутри каждой ячейки, в каждом
[01:06:49.480 --> 01:06:56.920]  вот этом мешочке, трое свою х-таблицу, но размера n квадрат. Вот. Почему это хорошо? Ну то есть
[01:06:56.920 --> 01:07:02.720]  почему это сработает? Потому что, если вы просуммируете размеры всех х-таблиц суммарно, то
[01:07:02.720 --> 01:07:11.480]  у вас получится не n квадрат, а получится что-то типа 2n. Ну даже меньше, чем 2n. Понятно? Ну давайте
[01:07:11.480 --> 01:07:18.640]  тут еще надо следствие на самом деле показать. Этого не совсем достаточно. Следствие, вероятность
[01:07:18.640 --> 01:07:31.840]  того, что сумма ni в квадрате от 1 до n будет больше либо равна, чем 4n, меньше, чем вот.
[01:07:31.840 --> 01:07:42.120]  То есть, грубо говоря, с очень большой вероятностью у вас сумма ni в квадрате будет меньше, чем 4n. Ну со
[01:07:42.120 --> 01:07:46.360]  средним все-таки непонятно, как работает, да? То есть, я говорю, что, ну в среднем у меня размер
[01:07:46.360 --> 01:07:50.880]  х-таблицы меньше, чем 2n. На, ну у вас на самом деле возможный случай, когда у меня размер х-таблицы
[01:07:50.880 --> 01:07:55.520]  будет больше, чем 2n и так далее. Ну вот, вот это следствие говорит о том, что у вас с очень маленькой
[01:07:55.520 --> 01:08:01.520]  вероятностью размер х-таблицы будет превосходить чем, будет, будет, будет превосходить 4n. Вот. Ну тут на самом
[01:08:01.520 --> 01:08:08.880]  деле все просто. Тут просто лему Маркова тоже применяем, и все. Сумма ni в квадрате больше
[01:08:08.880 --> 01:08:17.440]  либо равна, чем 4n. Меньше либо равна, чем это полемя Маркова. Среднее значение суммы
[01:08:17.440 --> 01:08:29.440]  ni в квадрате, деленное на 4n. Вот. А по теореме эта штука меньше, чем 2n на 4n. Ну то есть, вторая.
[01:08:38.880 --> 01:08:49.240]  Так, по теореме есть вопрос? Все, это была последняя теорема, последнее следствие. Сейчас алгоритм выпишем и все.
[01:08:49.240 --> 01:09:04.640]  По теории есть вопросы? Окей. Так. Алгоритм построения.
[01:09:04.640 --> 01:09:17.960]  Я помню, что он называется FKS. По именам авторов. Авторов, честно говоря, я не помню. Вот. Короче, FKS.
[01:09:17.960 --> 01:09:44.000]  Первый шаг. Выбираем случайную h и справляем х-таблицу с m равную n.
[01:09:44.000 --> 01:10:03.920]  Второй пункт. Если сумма ni в квадрате оказалась больше, чем 4n, то повторяем пункт 1.
[01:10:03.920 --> 01:10:14.960]  Смотрите, мы хотим, чтобы х-таблица была маленькой. При этом мы знаем, что х-таблица будет маленькой с очень большой вероятностью.
[01:10:14.960 --> 01:10:21.680]  Вот. Вы выбрали случайную х-таблицу и распроделили свои элементы по бакетам. Вот по этим корзинам.
[01:10:21.680 --> 01:10:26.960]  И в итоге обнаружили, что х-таблица внезапно большая. Сумма ni в квадрате больше, чем 4n.
[01:10:26.960 --> 01:10:31.840]  Далее мы говорим, что мы отказываемся от этой хэш-функции, берем новую хэш-функцию и строим хэш-таблицу заново.
[01:10:31.840 --> 01:10:47.680]  Первый пункт. За сколько работает? За 5n, согласна. А сколько раз мне в худшем случае, не в худшем случае,
[01:10:47.680 --> 01:10:53.360]  сколько раз средними придется перестраивать мою хэш-таблицу? Примерно два раза, да?
[01:10:54.000 --> 01:10:56.240]  Потому что мне не везет с вероятностью меньше, чем одна вторая.
[01:10:56.240 --> 01:10:59.440]  Но соответственно, мне везет с вероятностью больше, чем одна вторая.
[01:10:59.440 --> 01:11:03.760]  Но примерно на второй попытке я уже найду хорошую хэш-функцию. Согласны?
[01:11:03.760 --> 01:11:11.280]  Примерно со второй попытки. Средней давайте напишем.
[01:11:11.280 --> 01:11:33.280]  Так, дальше третий пункт. Для любого i, принадлежащего от 0 до m-1, строим хэш-таблицу, нет, давайте так.
[01:11:33.280 --> 01:11:59.280]  Случайно выбираем h-i и строим i-ты ячейки, хэш-таблицу размера m.
[01:11:59.280 --> 01:12:23.760]  m-i равная m-i в квадрате. Давайте еще раз поясню, что n-i это число элементов i-той корзине.
[01:12:23.760 --> 01:12:34.240]  Ну то есть я распределил мои элементы по корзинам, и теперь я хочу, чтобы внутри каждой корзины у меня не было коллизий.
[01:12:34.240 --> 01:12:38.800]  То есть хочу их закашировать так, чтобы каждый из них отправлялся в свою ячейку.
[01:12:38.800 --> 01:12:49.280]  Ну для этого по теореме 1 мне утверждает, чтобы гарантировать, что с большой вероятностью не будет коллизий, мне нужно взять хэш-таблицу размер n-квадрат.
[01:12:49.280 --> 01:12:56.800]  Ну все, раз вытую ячейку, у меня попало n и t элементов, соответственно, я должен взять хэш-таблицу размера n и t в квадрате.
[01:12:56.800 --> 01:13:18.800]  Ну и четвертый пункт. Если для какого-то и получились коллизии, то что делаем?
[01:13:18.800 --> 01:13:37.280]  Что делаем? Да, то переделаем вот эту хэш-табличку маленькую, вот то, перестраиваем, ну давайте то повторяем.
[01:13:37.760 --> 01:13:45.760]  Повторяем пункт 3, для этого и.
[01:13:53.760 --> 01:13:57.760]  Давайте определимся, за сколько работает пункт 3 и пункт 4. Пункт 3 за сколько работает?
[01:13:58.240 --> 01:14:04.240]  За тета от n, а почему?
[01:14:04.240 --> 01:14:10.240]  Да, потому что после второго пункта у меня гарантирована размер хэш-таблицы не больше чем 4n,
[01:14:10.240 --> 01:14:14.240]  поэтому сумма n и t в квадрате гарантирована не больше чем 4n.
[01:14:14.240 --> 01:14:20.240]  Соответственно, все хэш-таблицы я суммарно построю не дольше, чем за 4n, согласны?
[01:14:20.720 --> 01:14:26.720]  Ну и пункт 4 у меня выполнится примерно со второй итерацией.
[01:14:30.720 --> 01:14:34.720]  Но здесь та же самая история. Я повторяю пункт 3 до тех пор, пока мне не попадется хорошая хэш-таблица.
[01:14:34.720 --> 01:14:38.720]  А хорошая хэш-таблица мне попадается с большой вероятностью,
[01:14:38.720 --> 01:14:42.720]  поэтому уже с первого раза с большой вероятностью я получу хорошую хэш-таблицу.
[01:14:42.720 --> 01:14:46.720]  Но если на первом и в первом, то я получу хорошую хэш-таблицу.
[01:14:46.720 --> 01:14:49.760]  на самом деле уже с первого раза, с большой вероятностью, я получу хорошую хэштаблицу.
[01:14:49.760 --> 01:14:51.600]  Но если на первый раз не повезло, то со второго повезет.
[01:14:51.600 --> 01:14:54.800]  Так или иначе, меня достаточно быстро должно повезти, потому что у меня вероятность большая.
[01:14:54.800 --> 01:15:03.200]  Итак, итог. Так, алгоритм весь понятен?
[01:15:03.200 --> 01:15:09.280]  Ну, вот так получается здесь.
[01:15:09.280 --> 01:15:15.600]  Здесь 4хn, мне гарантирована вероятность плохой хэштаблицы будет меньше, чем одна вторая.
[01:15:15.600 --> 01:15:21.440]  В принципе, можно подобрать, не знаю, там 8n, 10n, тогда вероятность будет еще больше.
[01:15:21.440 --> 01:15:22.880]  Ну, хэштаблица тогда тоже будет еще больше.
[01:15:22.880 --> 01:15:31.040]  Ну, 4n не из потолка взялась, а вот отсюда из следствия.
[01:15:31.040 --> 01:15:36.240]  Так, алгоритма, есть вопросы?
[01:15:36.480 --> 01:15:47.120]  Ну, окей, тогда давайте анализ, давайте с простого начнем.
[01:15:47.120 --> 01:15:53.840]  Время работы файнк.
[01:15:53.840 --> 01:15:59.120]  За сколько у меня будет работать файнк в такой хэштаблице?
[01:15:59.120 --> 01:16:02.880]  Почему в среднем?
[01:16:03.520 --> 01:16:07.520]  У меня теперь пояс гарантированно работает за единицу, согласна?
[01:16:07.520 --> 01:16:11.520]  Ну, почему? Потому что как работает поиск?
[01:16:11.520 --> 01:16:17.520]  Вот у меня есть внешняя хэштаблица, и вот в каждой ячейке, давайте вот эту изображу,
[01:16:17.520 --> 01:16:21.520]  у нее хранится еще одна хэштаблица размера mi5 в квадрате.
[01:16:22.160 --> 01:16:24.160]  Как у меня происходит поиск хэштаблицы?
[01:16:24.160 --> 01:16:30.160]  Я сначала беру исходную кэшфункцию h, она меня введет в какую-то ячейку i.
[01:16:30.160 --> 01:16:36.160]  А дальше в этой ячейке i я беру кэшфункцию h, i, t и выпадаю в какую-то ячейку вот здесь.
[01:16:36.160 --> 01:16:42.160]  И соответственно там либо лежит, может быть, или нет, или нет, или есть, или нет.
[01:16:42.800 --> 01:16:48.800]  А дальше в этой ячейке i я беру кэшфункцию h, i, t и выпадаю в какую-то ячейку вот здесь.
[01:16:48.800 --> 01:16:52.800]  И соответственно там либо лежит мое значение, либо не лежит, согласна?
[01:16:52.800 --> 01:16:58.800]  То есть, по сути, за два шага я гарантированно узнаю, есть ли элемент в хэштаблице или нет его.
[01:16:58.800 --> 01:17:00.800]  Понятно?
[01:17:00.800 --> 01:17:02.800]  Понятно, что я делаю не больше чем два шага.
[01:17:02.800 --> 01:17:04.800]  То есть у меня тут никаких цепочек нет.
[01:17:04.800 --> 01:17:08.800]  Почему? Потому что вот в этой внутренней хэштаблице гарантированно нет коллизий.
[01:17:09.440 --> 01:17:11.440]  А если там гарантированно нет коллизий, то я по цепочкам никаким не прохожусь.
[01:17:11.440 --> 01:17:13.440]  Всё.
[01:17:18.440 --> 01:17:20.440]  А зачем, если у вас уже и так успех?
[01:17:22.440 --> 01:17:24.440]  Можете сделать.
[01:17:24.440 --> 01:17:26.440]  Можете.
[01:17:30.440 --> 01:17:32.440]  Так, в худшем случае.
[01:17:35.440 --> 01:17:37.440]  Так, теперь память.
[01:17:38.080 --> 01:17:44.080]  Сколько память занимает эта структура данных?
[01:17:50.080 --> 01:17:52.080]  Ну сколько? n², n log n.
[01:17:54.080 --> 01:17:58.080]  Так, это от n, почему в среднем?
[01:18:00.080 --> 01:18:02.080]  Так, у нас была сумма.
[01:18:02.080 --> 01:18:04.080]  А если посмотреть на алгоритм?
[01:18:04.720 --> 01:18:06.720]  Я согласен, что у нас была оценка,
[01:18:06.720 --> 01:18:08.720]  что среднее значение n² меньше, чем 2n.
[01:18:10.720 --> 01:18:12.720]  А могу ли я что-то гарантировать в худшем случае?
[01:18:15.720 --> 01:18:17.720]  В худшем случае, да.
[01:18:17.720 --> 01:18:19.720]  Смотрите, я же гарантировал уже тут, на втором пункте,
[01:18:19.720 --> 01:18:21.720]  что у меня сумма n² точно не больше, чем 4n.
[01:18:22.720 --> 01:18:24.720]  То есть второй пункт,
[01:18:24.720 --> 01:18:26.720]  это от n в худшем случае.
[01:18:28.720 --> 01:18:30.720]  Это гарантирует
[01:18:34.720 --> 01:18:36.720]  пункт два.
[01:18:36.720 --> 01:18:38.720]  Почему?
[01:18:38.720 --> 01:18:40.720]  Если вдруг мне попалась большая х-таблица,
[01:18:40.720 --> 01:18:42.720]  то я просто ее заново перестраиваю.
[01:18:42.720 --> 01:18:44.720]  До тех пор, пока у меня х-таблица не будет маленькой.
[01:18:46.720 --> 01:18:48.720]  То есть уже в втором пункте
[01:18:48.720 --> 01:18:50.720]  мне точно известно, что сумма n²,
[01:18:50.720 --> 01:18:52.720]  то есть размер, общий размер х-таблицы,
[01:18:52.720 --> 01:18:54.720]  точно не больше, чем 4n.
[01:18:54.720 --> 01:18:56.720]  Но если он не больше, чем 4n, то ну все.
[01:18:58.720 --> 01:19:00.720]  Победа.
[01:19:00.720 --> 01:19:02.720]  Так, ну и наконец.
[01:19:03.360 --> 01:19:05.360]  Время построения.
[01:19:11.360 --> 01:19:13.360]  За сколько строится эта х-таблица?
[01:19:15.360 --> 01:19:17.360]  Это от n тоже.
[01:19:19.360 --> 01:19:21.360]  А вот тут я могу сказать, что в худшем случае?
[01:19:25.360 --> 01:19:27.360]  Могу ли я гарантировать, что вот точно
[01:19:27.360 --> 01:19:29.360]  за какое-то разумное линейное время она построится?
[01:19:29.360 --> 01:19:31.360]  Почему?
[01:19:33.360 --> 01:19:35.360]  Да, потому что
[01:19:35.360 --> 01:19:37.360]  тут, к сожалению, есть
[01:19:37.360 --> 01:19:39.360]  все-таки элемент случайности.
[01:19:39.360 --> 01:19:41.360]  Элемент случайности, он есть
[01:19:41.360 --> 01:19:43.360]  в пункте 2 и в пункте 4.
[01:19:43.360 --> 01:19:45.360]  То есть теоретически, теоретически
[01:19:45.360 --> 01:19:47.360]  она может катастрофически не вести.
[01:19:47.360 --> 01:19:49.360]  То есть это происходит с маленькой, вероятно,
[01:19:49.360 --> 01:19:51.360]  все, но теоретически, возможно, такое,
[01:19:51.360 --> 01:19:53.360]  что вы берете хэш-функции, берете, берете, берете,
[01:19:53.360 --> 01:19:55.360]  и постоянно вам подаются плохие хэш-функции,
[01:19:55.360 --> 01:19:57.360]  которые дают вам большое значение здесь.
[01:19:57.360 --> 01:19:59.360]  И поэтому пункт два теоретически
[01:19:59.360 --> 01:20:01.360]  может продолжаться бесконечно.
[01:20:02.000 --> 01:20:04.000]  Ну, не бесконечно, но вы можете
[01:20:04.000 --> 01:20:06.000]  достаточно долго перебирать все
[01:20:06.000 --> 01:20:08.000]  эти хэш-функции.
[01:20:08.000 --> 01:20:10.000]  Поэтому мы понимаем, что в среднем
[01:20:10.000 --> 01:20:12.000]  со второй попытки, ну, с первой со второй попытки
[01:20:12.000 --> 01:20:14.000]  вам уже повезет.
[01:20:14.000 --> 01:20:16.000]  Да, потому что вероятность везения довольно большая.
[01:20:16.000 --> 01:20:18.000]  Ну, а теоретически?
[01:20:18.000 --> 01:20:20.000]  Теоретически, к сожалению, гарантировать
[01:20:20.000 --> 01:20:22.000]  быструю исходимость не получится.
[01:20:22.000 --> 01:20:24.000]  Поэтому вот тут мы пишем
[01:20:24.000 --> 01:20:26.000]  только в среднем.
[01:20:26.000 --> 01:20:28.000]  Вот.
[01:20:28.000 --> 01:20:30.000]  Ну, я думаю, это уже неплохо.
[01:20:30.640 --> 01:20:32.640]  Хотя бы
[01:20:32.640 --> 01:20:34.640]  find за единицу в худшем случае мы сделали.
[01:20:34.640 --> 01:20:36.640]  То есть эта хэш-таблица гарантированно
[01:20:36.640 --> 01:20:38.640]  позволяет вам искать
[01:20:38.640 --> 01:20:40.640]  за единицу.
[01:20:40.640 --> 01:20:42.640]  То есть никаких худших линейных случаев и так далее нет.
[01:20:42.640 --> 01:20:44.640]  Но в постановке у вас
[01:20:44.640 --> 01:20:46.640]  множество известно заранее.
[01:20:46.640 --> 01:20:48.640]  Ну, тут надо сказать что замечание, что есть модификация
[01:20:48.640 --> 01:20:50.640]  алгоритма FKS, которая работает и
[01:20:50.640 --> 01:20:52.640]  в динамическом случае, то есть
[01:20:52.640 --> 01:20:54.640]  если вам все-таки нужно добавлять элементы,
[01:20:54.640 --> 01:20:56.640]  удалять элементы, то, ну, примерно похожий
[01:20:56.640 --> 01:20:58.640]  алгоритм, он работает и
[01:20:59.280 --> 01:21:01.280]  в динамическом случае.
[01:21:01.280 --> 01:21:03.280]  Только там надо динамически там переширять, перехешировать.
[01:21:03.280 --> 01:21:05.280]  Но об этом можете почитать отдельно.
[01:21:05.280 --> 01:21:07.280]  Ну, а пока все.
