[00:00.000 --> 00:12.040]  Сегодня последняя короткая лекция. Большого счета аппендикса предыдущей. Мы на предыдущей
[00:12.040 --> 00:20.340]  лекции с вами обсудили тему NoSQL в общих чертах. Тема, в принципе, большая. Там много всяких
[00:20.340 --> 00:29.040]  нюансов, связанных с конкретными видами нерелиционных баз данных. Мы прошлись по самым верхам.
[00:29.360 --> 00:39.960]  Посмотрели на самый-самый верхний срез того, что есть. Какие есть решения, в связи с чем они
[00:39.960 --> 00:52.400]  сформировались. Обсудили коротко теорему PEP и base подход. Теорему PEP, теорему Brewer и подход
[00:52.400 --> 01:02.000]  base к проектированию систем управления даже базами данных, нежели самих баз данных. Сейчас с вами
[01:02.000 --> 01:15.000]  посмотрим еще на три популярных решения для работы в формате NoSQL, которые массово используются
[01:15.000 --> 01:25.360]  на настоящий момент. Как вы помните, Redis и MongoDB это лидеры в своих категориях. Категория
[01:25.360 --> 01:35.160]  хранилищ ключи значения и документов баз данных. ClickHouse это решение Яндекса для колончатых,
[01:35.160 --> 01:53.840]  ну или как они себя называют столкцовых баз данных. Немножко пару слов о Neo4j. В прошлый раз у нас
[01:53.840 --> 02:01.600]  возник вопрос по поводу того, как отличать узлы одни от других. По большому счету никак.
[02:05.160 --> 02:12.480]  Здесь, как я говорил на прошлой лекции, вы можете сделать просто листинг всех узлов,
[02:12.480 --> 02:19.480]  посмотреть какие есть в вашем графе, ну или в графе, с которым вы работаете, и добавлять
[02:19.480 --> 02:26.120]  данные туда. Но на самом деле надо оговориться вот о чем, о том, что у нас, если мы пытаемся
[02:26.120 --> 02:40.680]  перевести данные из релиционной базы в графовую базу вида Neo4j, то рациональным
[02:40.680 --> 02:48.560]  использованием структуры графовой будет добавление каждой новой записи в виде таблицы,
[02:48.560 --> 02:53.960]  в виде отдельного узла. Отдельный узел при этом будет содержать в себе имя таблицы,
[02:53.960 --> 03:04.960]  имя отношения, а запретов на дублирование такого рода узлов у нас, по большому счету, нет.
[03:04.960 --> 03:16.640]  Поэтому вопрос о том, если мы хотим добавить данные в один и тот же свойство, в один и тот же узел,
[03:16.640 --> 03:22.400]  как нам его найти? Ну, в принципе, с точки зрения парадигма графа, графовая база данных,
[03:22.400 --> 03:28.000]  подходы Neo4j по большому счету никак. Можно просто создать новый узел, но здесь главное,
[03:28.000 --> 03:38.480]  чтобы у нас теги, лейблы, заголовки узла совпадали, чтобы мы по поиску заголовка одноименного искали
[03:38.480 --> 03:44.160]  именно подходящие отношения, ну или в данном случае, наверное, удобнее говорить класс, сущность,
[03:44.160 --> 03:54.520]  искали подходящую сущность, чтобы у нас был лейбл, был заголовок Person, но не было заголовка Human,
[03:54.520 --> 04:04.560]  например, чтобы мы не попадали в проблемы, связанные с таким вот семантической двуйственностью
[04:04.560 --> 04:18.200]  названия узловерния. Подробнее можно посмотреть, ссылка приведена на документацию Neo4j и пример
[04:18.200 --> 04:24.920]  на слайде показан, где, как вы видите, у нас в принципе нет, опять же, пример из документации,
[04:24.920 --> 04:31.120]  здесь нет какого-то принципиального запрета на то, чтобы у нас Person был только одним узлом,
[04:31.120 --> 04:40.320]  и вот у нас здесь есть узлы Person, которые обозначают тех или иных актеров, и они соответственно
[04:40.320 --> 04:46.760]  для каждого актера представлены своим узлом, и более того, для каждого фильма еще у нас есть
[04:46.760 --> 04:57.080]  отдельные узлы и также там для режиссера. Хорошо, давайте поговорим еще вот о чем,
[04:57.840 --> 05:07.840]  немаловажный, наверное, составляющий при работе с нерелационными базами данных, а не поскольку у
[05:07.840 --> 05:20.160]  нас, как опять же вы, наверное, помните из нашей глобальной таблицы, стоит DB Engines все-таки не такие
[05:20.160 --> 05:25.520]  распространенные, как SQL решения, то есть SQL просто по умолчанию больше и выбора больше и
[05:25.880 --> 05:39.520]  популярного выбора, причем из Open Source сегмента тоже больше, чем вариантов NoSQL решений,
[05:39.520 --> 05:49.160]  и поэтому у нас в NoSQL встает вопрос лицензирования, особенно на настоящий момент. К сожалению,
[05:49.160 --> 05:56.800]  не все у нас доступно, а то, что доступно, не все доступно для коммерческого использования,
[05:56.800 --> 06:05.560]  поэтому нужно смотреть, если вы что-то собираетесь самостоятельно разрабатывать и принимать
[06:05.560 --> 06:12.640]  самостоятельные решения о том, продукции какого вендера пользоваться, обязательно посмотрите
[06:12.640 --> 06:18.440]  на раздел License, на GitHub, если это Open Source проект, либо на сайте поищите. Самый простой
[06:18.440 --> 06:25.480]  способ это просто открыть англоязычную статью википедии по тому или иному продукту, посмотреть,
[06:25.480 --> 06:31.640]  там всегда пишется лицензия, по некоторым продуктам лицензии, они как бы необычные,
[06:31.640 --> 06:39.680]  Open Source лицензии и не просто праприетарные, а как бы такие, вроде бы Open Source,
[06:39.680 --> 06:44.840]  но со своими особенностями, скажем так, и здесь, конечно, нужно читать, но по умолчанию,
[06:44.840 --> 06:53.440]  для проектов, для чего-то некоммерческого вполне себе большую часть решений можно использовать,
[06:53.440 --> 07:00.120]  скажем так, ну или также нужно смотреть на среду, в которой планируется развертывание сервисов,
[07:00.120 --> 07:05.520]  вот для Яндекса у нас, например, есть поддержка, вернее, от Яндекса, от Яндекса облака есть
[07:05.520 --> 07:13.440]  поддержка кластеров MongoDB, но, правда, несколько более старых версий, пятый и шестой, сейчас
[07:13.440 --> 07:20.520]  версия седьмая, выпущена пятая и шестая, шестая, по-моему, если я не ошибаюсь,
[07:20.520 --> 07:29.520]  21-го года выпуска, версия шесть, и то есть, в принципе, пользоваться можно и, да,
[07:29.520 --> 07:37.880]  MongoDB предоставляет свои облачные решения, и это входит как раз в один из платных планов,
[07:37.880 --> 07:47.480]  там есть Mongo Atlas, облако, где развертываются сервера Mongo с MongoDB, соответственно,
[07:47.480 --> 07:55.360]  Яндекс предоставляет сейчас такую замену такого рода сервису, но, опять же, да, вот с уговоркой,
[07:55.360 --> 08:03.160]  что чуть более ранние версии Mongo используются, но по большому счету, да, для каких-то,
[08:03.160 --> 08:12.160]  с глобальной точки зрения и так тоже неплохо, это не версия десятилетней давности, в принципе,
[08:12.160 --> 08:23.160]  довольно актуальные версии, вполне используемые в широком продакшене, скажем так, так что обращайте
[08:23.160 --> 08:31.440]  на это внимание. Ну а пэд-проекты, да, или что-то некоммерческое на одного человека, или, может быть,
[08:31.440 --> 08:41.400]  на какую-то небольшую команду некоммерческую можно устанавливать практически вполне без боязни.
[08:41.400 --> 08:48.880]  Так, хорошо, давайте пройдемся буквально кратенько в двух словах, чтобы уже, да, не перегружать,
[08:48.880 --> 08:54.520]  сразу оговорюсь у нас тоже, да, оговорюсь, что у нас по этой лекции не будет никаких неформ отчетности,
[08:54.520 --> 09:02.400]  ничего, просто введем вас в курс дела того, что происходит с теми или иными решениями.
[09:02.400 --> 09:10.800]  А Redis, вот первый будет на слайде, соответственно, то, откуда взялась, по сути дела, аббревиатура,
[09:10.800 --> 09:19.680]  то есть название аббревиатура от словосочетания remote dictionary server и хранилище ключезначения,
[09:19.680 --> 09:27.440]  которое в оперативной памяти функционирует, можно его сохранять на диск, возможна репликация
[09:27.440 --> 09:36.720]  по схеме master-slave, поддерживается также событийный механизм по схеме подписки,
[09:36.720 --> 09:50.160]  работает на UNIX, в Windows, если захотите установить, то нужно WSL, то есть Windows Subsystem for Linux
[09:50.160 --> 09:59.480]  и открытый исходный код есть на GitHub, они, кстати, вот Redis буквально 20 марта перешли на более
[09:59.480 --> 10:07.880]  жесткую свою новую лицензию, она все равно как бы считается еще такой, не совсем, не до конца
[10:07.880 --> 10:14.080]  праприетарной, но уже стала более закрытой, там более агрессивной с точки зрения того,
[10:14.080 --> 10:19.680]  если вы хотите использовать Redis, то там нужно делать в плане того, что открытый исходный код вашего
[10:19.680 --> 10:25.320]  приложения, но подробнее, если вам будет интересно в таких аспектах разобраться,
[10:25.320 --> 10:33.160]  отсылаю вас к GitHub'у Redis к пайлу лицензирования, но для каких-то ПЭД-проектов вполне
[10:33.160 --> 10:43.800]  Redis можно использовать пока что безбоясно, что называется, не считаясь наружителем авторских
[10:43.800 --> 10:50.760]  прав. Архитектурный Redis представляет два процесса собой, серверный процесс, который,
[10:50.760 --> 10:58.560]  собственно говоря, слушает порты, отвечает за хранение и обработку данных, и Redis клеит,
[10:58.560 --> 11:03.320]  если хотите работать с командной строкой с терминалом, либо есть, конечно же, куча
[11:03.320 --> 11:08.560]  всевозможных пакетов для различных языков программирования, наиболее распространенных,
[11:08.560 --> 11:18.200]  можно работать из-под рентайма вашего языка, назовем это так. Некоторые команды основные,
[11:18.200 --> 11:25.760]  это подключение к базе данных из командной строки, добавление приведено максимально,
[11:25.760 --> 11:33.840]  здесь просто, set, get, добавление и чтение данных. bike 2.1 это ключ, несмотря на наличие 2.1. После
[11:33.840 --> 11:42.800]  пробелы идет значение. Команда hset позволяет нам добавлять словарь, здесь у нас первое значение
[11:42.800 --> 11:56.800]  идет, первая запись идет после hget, идет ключ такой головной, назовем это так, ключ записи,
[11:56.800 --> 12:06.880]  а дальше внутри записи есть поля, по которым мы можем получить доступ к информации по тому
[12:06.880 --> 12:12.080]  или иному полю. Это такие прям верхнеуровневые команды, что называются самые простые,
[12:12.080 --> 12:19.600]  можно сканить записи, есть вариант сканирования даже не записи, а ключей, можно делать индексы,
[12:20.480 --> 12:28.120]  сознательно здесь не привожу всю полноту, уже не имеет большого смысла сейчас в это погружаться,
[12:28.120 --> 12:34.120]  потому что это с одной стороны тема на отдельную лекцию, с другой стороны повторюсь, у нас
[12:34.960 --> 12:42.520]  такой момент, но как вы видите здесь принципиально то, что у нас с точки зрения структуры данных,
[12:42.520 --> 12:51.160]  которые хранятся, это либо запись, либо словарь, вот собственно и все, и то и другое доступно по ключу,
[12:51.160 --> 12:57.720]  что мы можем делать с записями, есть некоторое количество операций, можно, повторюсь,
[12:57.720 --> 13:02.320]  завод сканирования, можно ключ, если это числовое значение, инкрементировать,
[13:02.320 --> 13:10.600]  декрементировать можно, ну понятно, удаление записи тоже там возможно по ключу, отдельно
[13:10.600 --> 13:15.120]  записи или записи с ключом и так далее и тому подобное, все, что вы делаете, ну условно говоря,
[13:15.120 --> 13:22.960]  там со словариком на питоне доступно, грубо говоря, тоже в Redis, и зачем это все нам в принципе нужно,
[13:22.960 --> 13:34.240]  Redis удобен для каширования и для каширования данных для нескольких процессов тех или иных
[13:34.240 --> 13:41.040]  приложений, соответственно, вы можете подключить несколько своих приложений к общему кэшу или
[13:41.040 --> 13:50.520]  несколько процессов одного приложения к общему кэшу и удобно таким образом пользоваться вот этой
[13:50.640 --> 14:03.000]  общей памятью, за что будет отвечать у вас Redis, возможно также масштабировать систему тоже за
[14:03.000 --> 14:09.200]  счет в принципе этого свойства, вступление Redis в качестве кэша, в общем-то, наверное,
[14:09.200 --> 14:18.640]  все должно быть понятно, словарик, хранящийся в оперативной памяти, и который также как словарь
[14:18.640 --> 14:24.480]  можно использовать, что нам удобствует в первую очередь в том, что мы не работаем, условно говоря,
[14:24.480 --> 14:31.720]  с прямой адресацией памяти или с адресацией памяти из приложения, не пытаемся, не знаю,
[14:31.720 --> 14:43.880]  на C или C++ делать аллокацию памяти, запускать в каком-то общем процессе делать какие-то,
[14:43.960 --> 14:55.360]  как-то его сложно использовать, у нас есть интерфейс, мы с ним работаем, все довольно очевидно,
[14:55.360 --> 15:03.880]  скажем так, ну понятно, да, есть дополнительное осветление по репликации, по шардированию того,
[15:03.880 --> 15:09.520]  как это делается в Redis, своя специфика, но мы подробно об этом с вами в принципе не говорили,
[15:09.520 --> 15:15.600]  поэтому тоже не будем сейчас с вами на этом останавливаться, просто есть тоже свои определенные
[15:15.600 --> 15:22.160]  особенности, за ними целая у вас, они технического плана, они такие неконцептуальные, целая у вас
[15:22.160 --> 15:31.840]  документация, ребята. ClickHouse, Vendor Yandex, наш такой вот отечественный, что называется,
[15:31.840 --> 15:40.680]  решение столбцовое, как я и говорил, система управления базами данных для OLAP-запросов,
[15:40.680 --> 15:47.680]  как сами разработчики пишут, это по-настоящему столбцовый СУБД, то есть у нас действительно
[15:47.680 --> 15:53.600]  все, они этим прямо заморочились максимально в том плане, что у нас файлы физические,
[15:53.600 --> 15:59.880]  на диске хранятся именно в виде, ну не в виде, конечно, а в файлах хранятся записи именно о
[15:59.880 --> 16:12.120]  столбцах без какой-то эмуляции каких-то сложных структур, последовательное хранение записи в
[16:12.120 --> 16:18.920]  рамках колонки, ну оптимальное сжатие данных, хранение на диске, параллельная обработка
[16:18.920 --> 16:26.040]  запросов на многих процессорных ядрах, то есть в принципе на это ClickHouse затачивался, поддержка,
[16:26.040 --> 16:38.960]  и вот о чем мы тоже с вами оговаривались, поддержка SQL, то есть мы можем безбоязненно
[16:38.960 --> 16:53.000]  использовать ClickHouse, зная то, что мы знаем о SQL-синдексе, и таким образом здесь
[16:53.000 --> 17:03.000]  порог входа после релиционных баз данных минимален, ну и в принципе ClickHouse, как мы с вами и говорили,
[17:03.000 --> 17:13.000]  да, у нас колончатый и уайт колонн базы данных, они в отличие от остальных решений наиболее близки
[17:13.000 --> 17:19.440]  вот такой релиционной что ли парадигме, потому что у нас здесь принципиально только момент
[17:19.440 --> 17:36.640]  с физическим хранением данных, нежели с тем, как эти данные переносятся в схему данных, как из данных
[17:36.640 --> 17:44.360]  формируется схема, какие там ограничения, какие условия на типы данных и так далее, это все берем
[17:44.360 --> 17:52.360]  из курса про релиционный, да, из теории релиционных баз данных, просто особенности физического хранения
[17:52.360 --> 18:00.160]  позволяют удобнее работать с аналитическим запросами, то есть запросами на массовое чтение данных
[18:00.160 --> 18:10.360]  в больших столбцах, в длинных таких столбцах, а какие потенциальные недостатки, на это, собственно,
[18:10.360 --> 18:15.320]  опять же сами разработчики явно указывают при описании своего продукта, то есть здесь нет
[18:15.320 --> 18:20.560]  полноценных транзакций, да, то есть вот эти вот наши ACID-принципы не гарантируются в данном случае,
[18:20.560 --> 18:32.400]  но это обусловлено, опять же, тем, что мы здесь click-aus не работаем с данными в режиме OLTP,
[18:32.400 --> 18:40.040]  то есть он онлайн транзакцион процессы, нам не важно в данном случае записать данные и
[18:40.040 --> 18:48.120]  обеспечить конкурентный доступ к данным во время записи и вместе с тем там сохранить данные
[18:48.120 --> 18:55.160]  непротиворечивыми и так далее, и так далее, у нас выгрузка в click-aus происходит реже,
[18:55.160 --> 19:02.440]  но более массово, скажем так, да, и наоборот, у нас операция чтения, как я уже сказал,
[19:02.440 --> 19:08.680]  происходит чаще, чем операция записи, значительно чаще, и поэтому нам в первую очередь важно
[19:08.680 --> 19:18.000]  обеспечить оптимальное чтение больших массивов данных, которые мы пытаемся анализировать. Есть
[19:18.000 --> 19:27.480]  особенности по изменению удалению ранее записанных данных сниз, ранее записанных данных,
[19:27.480 --> 19:36.280]  то есть здесь не гарантируется быстрота таких операций и массовое удаление изменения данных
[19:36.280 --> 19:49.680]  привычными средствами SQL здесь не поддерживается в прямом виде, есть специфические средства массового
[19:49.680 --> 19:59.160]  удаления, просто по операции delete заблюрить, так сказать, строки, убрать их из явной выдачи,
[19:59.160 --> 20:14.080]  а потом сделать вакуум или анализ и подтянуть статистику, удалив все помеченные в рамках
[20:14.080 --> 20:22.280]  операции delete данные, здесь такого нет, все это работает несколько иначе и не так эффективно,
[20:22.280 --> 20:31.000]  как в нашем позгрессе, который мы с вами изучали, есть также разряженный индекс,
[20:31.000 --> 20:38.840]  и здесь не очень удобно за счет него читать одиночные строки по ключам, ну и в принципе,
[20:38.840 --> 20:46.080]  опять же, мы с вами тоже оговаривали, что в колончатых и вайт-колонн базах данных чтение строк
[20:46.080 --> 20:50.960]  это не оптимальная операция именно в связи с особенностями физического хранения, именно в связи
[20:50.960 --> 21:00.000]  с тем, что мы нацелены на аналитику, то есть аналитика подразумевает агрегацию, абстрагирование
[21:00.000 --> 21:12.480]  от конкретного значения и формулирование выводов на основании каких-то таких собирательных,
[21:12.480 --> 21:20.400]  с какой-то собирательной информации о предметной области. Некоторые команды здесь,
[21:20.400 --> 21:30.720]  кроме вот подключения и каких-то специфических команд tutelite для терминала, о которых мы не
[21:30.720 --> 21:38.720]  будем отдельно гонхлеть, опять же, по большому счету их и нет, вот создание и наполнение таблицы,
[21:38.720 --> 21:47.920]  приведенные в примере. Как вы видите, здесь минимальное различие здесь появляется спецификом
[21:47.920 --> 21:54.200]  в виде engine, вот в конце команды create, merge tree, order by, id, специфика создания таблицы,
[21:54.200 --> 22:03.880]  как это все будет храниться на диске и учитываться при операциях order by, но по большому счету,
[22:04.240 --> 22:12.920]  не вникая в подробности, такого рода, если уж не создание, то наполнение точно ничем не
[22:12.920 --> 22:22.920]  отличается принципиально от команды наполнения, команды insert, inter в нашем посгрысе,
[22:22.920 --> 22:32.160]  в обычном SQL характерном для посгрыса. Как уже говорилось, здание не поддерживает традиционное
[22:32.160 --> 22:38.680]  удаление строк с помощью delete click house, но вместо этого можно делать всяческие лайфхаки,
[22:38.680 --> 22:45.800]  не очень сложные, но опять же, это будет просто неэффективно. Сразу можно оговориться, опять же,
[22:45.800 --> 22:54.920]  в силу, повторюсь, особенностей, в силу специфики хранения данных и alter table мы можем изменить
[22:54.920 --> 23:03.720]  с помощью этой команды какую-то таблицу, сделав удавление по условию, но так, пожалуй, делать без
[23:03.720 --> 23:11.840]  крайней необходимости не надо, операция, повторюсь, не оптимальная. MongoDB, последний наш кандидат на такой
[23:11.840 --> 23:22.400]  краткий сравнительный обзор. Да, вот с Redis-ом говорили, что они 20 марта буквально изменили
[23:22.400 --> 23:32.320]  лицензию, ужесточили ее. MongoDB у нас, в принципе, отключили поддержку своего облачного сервиса еще два
[23:32.320 --> 23:41.740]  года назад, но и Redis и MongoDB их доступны на GitHub, то есть, по большому счету, если сильно захотеть,
[23:41.740 --> 23:52.020]  можно сделать форк при необходимой правовой экспертизе добиться изменения, достаточного
[23:52.020 --> 23:58.660]  изменения исходного кода, чтобы считать это новым продуктом. Это такой фантазийный немножко
[23:58.660 --> 24:05.380]  сценарий, но, тем не менее, изменив минимальным необходимым образом исходный код Mongo,
[24:05.380 --> 24:12.060]  можно какую-то свою документную базу данных сформировать, но, ладно, хватит фантазии,
[24:12.060 --> 24:21.340]  что называется, давайте к сухим фактам. Mongo, повторюсь, поддерживается у нас в частности в облаке
[24:21.340 --> 24:39.900]  Яндекса, так что тоже вполне себе рабочий вариант для предприятий, для издания community, в принципе,
[24:39.900 --> 24:46.100]  можно все это установить на свой сервер, на свою машину и пользоваться. Так, вопрос.
[24:46.100 --> 25:03.100]  Лицензия там SSPL, и это лицензия, которая ограничена, такой, как бы, промежуточный вариант,
[25:03.100 --> 25:14.660]  промежуточный вариант между open-source лицензиями и между proprietary, скажем так. Там, если кратко,
[25:14.660 --> 25:22.820]  то ситуация, похожая с Redis, нужно открывать весь исходный код, если вы работаете с базовой
[25:22.820 --> 25:33.460]  версией MongoDB, и, наверное, такое первое и принципиальное ограничение нельзя, если я не ошибаюсь,
[25:33.460 --> 25:45.940]  менять не как Mongo, исходный код Mongo, и за остальным, да, я вас все-таки отошлю к документации Гитхаба,
[25:45.940 --> 25:58.500]  потому что есть. Давайте так, да, вот сейчас на практике некоторое количество времени используется
[25:58.500 --> 26:07.500]  решение иностранных вендоров или поддерживаемые иностранными вендорами, скажем так, с некоторыми
[26:07.500 --> 26:17.940]  оговорками с точки зрения правового режима. Поэтому, если вы хотите разворачивать какой-то
[26:17.940 --> 26:28.420]  коммерческий проект и для этого ищете подходящее решение, то лучше всего возможно обратиться на
[26:28.420 --> 26:36.580]  прямую к юристам и потратить на это какое-то количество денег, либо потратить какое-то количество
[26:36.580 --> 26:45.740]  своего времени, чтобы вчитаться в лицензионное соглашение, которое висит в Гитхабе, и четко понять,
[26:45.740 --> 26:53.300]  вообще, какие права и обязанности у вас могут возникнуть при использовании. Если же вы делаете
[26:53.300 --> 26:59.700]  просто какой-то крайне коммерческий проект, все это у вас лежит на Гитхабе и Гитлабе в открытом
[26:59.700 --> 27:10.100]  доступе, все рассмотренное сейчас и рассмотренное в прошлом, до прошлой лекции, они пригодны для
[27:10.100 --> 27:18.100]  такого использования. То есть, не знаю, делайте какой-нибудь сервис, собирайте какую-то статистику,
[27:18.100 --> 27:28.980]  ну что там сейчас актуально, какой-нибудь криптовалюта, DeFi-приложение, делайте форк сайта
[27:28.980 --> 27:34.540]  DeFiLab, не знаю вообще, он в открытом доступе или нет, ну вот так, да, пофантазируем, что это такое,
[27:34.540 --> 27:39.300]  можете посмотреть в интернете, это вообще отдельно, это совсем другая тема, не будем углубляться,
[27:39.300 --> 27:46.260]  и делайте форк какого-нибудь сайта, начинаете агрегировать данные, используете один из
[27:46.260 --> 27:53.620]  вариантов того, что мы с вами оговорили, и если вы не получаете доходы от рекламы, если у вас
[27:53.620 --> 27:57.980]  открытый исходный под и вы явно говорите, что вы используете, у вас никаких проблем не будет,
[27:57.980 --> 28:07.300]  если вы собираетесь работать в коммерции у крупных коммерческих фирм, есть свои политики
[28:07.300 --> 28:11.460]  современные по использованию такого рода приложений, вам просто не нужно будет по этому
[28:11.460 --> 28:17.900]  поводу париться, если вы именно собираетесь делать какой-то свой маленький подряд, уходить
[28:17.900 --> 28:25.580]  в какой-то свой маленький консалтинг, тогда проанализируйте, здесь я не специалист в
[28:25.580 --> 28:33.180]  лицензировании ПО, поэтому это не моя епархия, я просто опозначаю вам риски, говорю о полюсах,
[28:33.180 --> 28:39.180]  то есть один полюс это, да, о краях спектра, один полюс это полностью некоммерческое,
[28:39.180 --> 28:42.500]  полностью открытое использование, у вас полностью открытый проект, здесь все нормально,
[28:42.500 --> 28:49.860]  никаких проблем не будет, или вы сотрудник в какой-то крупной компании, где свои политики,
[28:49.860 --> 28:54.780]  где там свои департаменты занимаются тем, чтобы исключить всевозможные риски и так далее,
[28:54.780 --> 28:59.820]  здесь проблема, наверное, где-то посередине между этими диапазонами, ну посередине, повторюсь,
[28:59.820 --> 29:06.380]  либо читать самостоятельно и тратить время, либо попытаться обратиться за квалифицированной
[29:06.380 --> 29:16.780]  помощью, в принципе, я думаю, такую можно найти, это, кажется, насущный вопрос в современных
[29:16.780 --> 29:22.580]  условиях, ну понятно, стоимость проекта, может быть, это удорожит на каком-то этапе, вот так
[29:22.580 --> 29:29.780]  угодно, правовая экспертиза, но тем не менее, лучше за ней обратиться, так что вот так,
[29:29.780 --> 29:38.660]  резюмируя ответ на ваш вопрос, лицензия у MongoDB пограничная, но для pet проекта подойдет.
[29:38.660 --> 29:53.180]  Так, хорошо, вернемся к MongoDB, данные хранятся в формате, похожем на JSON, по сути дела, у нас и
[29:53.180 --> 30:01.500]  доступ идет к данным, вот такого рода нотация, которая к нам из C пришла через точку, когда мы
[30:01.500 --> 30:10.060]  к полям структуры обращались через точку, по-моему, C едва ли не первый был язык,
[30:10.060 --> 30:16.660]  предложившись такой синтаксизм, но во всяком случае, Керниган и Ричи, кажется, говорили об этом как,
[30:16.660 --> 30:26.940]  не то, что новации, но если я не ошибаюсь, попрошу заранее меня извинить, но, кажется,
[30:26.940 --> 30:36.580]  они говорили об этом как такой синтаксический, что ли, фичи языка C на тот момент. Хорошо,
[30:36.580 --> 30:42.300]  про то, что сейчас покажу несколько команд, оптимальная поддержка горизонтального
[30:42.300 --> 30:51.420]  масштабирования, и sharding в частности поддерживается, когда у нас данные разнесены по нескольким
[30:51.420 --> 30:59.540]  серверам, не просто реплицированы, когда у нас полная копия на двух-трех серверах стоит,
[30:59.540 --> 31:08.460]  спереди идет балансировка через какой-нибудь nginx, и все это раскидывается по загруженности серверов,
[31:08.460 --> 31:14.460]  одни запросы, которые потенциально могут к одним и тем же данным обращаться, раскидываются на
[31:14.460 --> 31:21.660]  разные сервера, нет, у нас, именно, возможно, оптимальное распределение данных по различным
[31:21.660 --> 31:28.180]  узлам нашей какой-то внутренней сети, все это потому, что у нас Монга яркий представитель,
[31:28.180 --> 31:32.580]  как раз, нашей base парадигмы, о которой мы говорили, то есть базовая доступность и
[31:32.580 --> 31:44.540]  согласованность в конечном итоге. В конечном итоге согласованность будет, но здесь, возможно,
[31:44.540 --> 31:52.460]  возможно проблемы с тем, как пропагация, как распространение по узлам информации будет
[31:52.460 --> 31:58.220]  происходить. Ну или статистическая, по крайней мере, информация, раз уж мы говорим, что
[31:58.220 --> 32:03.020]  шардирование это разнесение порции данных, то нам нужна, по крайней мере, какая-то статистика,
[32:03.020 --> 32:12.500]  где у нас какие данные хранятся. Понятно, что мы не будем записывать все данные, переписывать
[32:12.500 --> 32:19.980]  с одного узла на другой в случае с шардированием. Так, доступна поддержка транзакции, начиная с
[32:19.980 --> 32:28.140]  версии, да, Монга также, в принципе, мы можем ужесточить внутренние политики, так сказать,
[32:28.140 --> 32:36.260]  назовем это так, Монга, и заставить его исполнять ACID-транзакции, если мы захотим, но это уже такие,
[32:36.260 --> 32:42.780]  да, навороты в сторону реверанса, в сторону ACID, в сторону какой-то не то чтобы релиционности,
[32:42.780 --> 32:49.940]  но вот жесткости и возможности поддержания непротиворечивости, характерной для релиционных
[32:49.940 --> 33:01.380]  СОБД. Примеры команд, ну, здесь, да, опять же, вот просто, то ли немножко так посмотреть,
[33:01.380 --> 33:11.580]  как это выглядит, потому что, безусловно, палитра команд, их сильно больше, возможностей у Монга
[33:11.580 --> 33:18.940]  довольно много, штука удобная, если вы, конечно, да, не, если вы понимаете, зачем вы это используете,
[33:18.940 --> 33:25.780]  и понимаете, что на каком-то этапе развития вашего сервиса вы перейдете на релиционную модель,
[33:25.780 --> 33:34.500]  потому что сделать просто вот какое-то невразумительное хранилище вообще никак не
[33:34.500 --> 33:43.020]  соответствующими друг другу документами, из Монга можно довольно просто привести это потом в вид,
[33:43.020 --> 33:49.940]  который будет удобно поддерживать, то есть, что-то похожее на релиционную модель, довольно
[33:49.940 --> 33:54.380]  проблематично с точки зрения ресурсов, по крайней мере, точно, то есть, затрата будут довольно
[33:54.380 --> 34:04.980]  большими, а поэтому лучше, ну, это такая заметка на полях, это не то что прям жесткая установка,
[34:04.980 --> 34:10.420]  но рекомендация такая, что Монг, конечно, лучше использовать все-таки, наверное, на проектах
[34:10.420 --> 34:24.500]  небольшого или среднего объема, потому что он удобен для быстроты разработки, но для того,
[34:24.500 --> 34:35.180]  чтобы обеспечивать непротиворечимость данных, их неизбыточность, чтобы мы были уверены,
[34:35.180 --> 34:43.820]  что мы добавляем новую записи, она у нас правильно распределится в нашей базе данных, аккуратно
[34:43.820 --> 34:49.940]  все ляжет, не создаст никаких коллизий, не будет никаких проблем с точки зрения там чтения записи,
[34:49.940 --> 34:57.780]  что у нас не будет противоречивых данных внутри самой базы, вот с этим Монг ГДБ справляется не
[34:57.780 --> 35:03.260]  очень хорошо, ну, не то что не очень хорошо, он не заточен изначально на то, чтобы с этим
[35:03.260 --> 35:08.260]  расправляться, поэтому мы теоретически из Монга ДБ можем сделать просто месиво из данных,
[35:08.260 --> 35:19.860]  что, конечно, очень неудобно при росте их объема. Ладно, long story short, собственно,
[35:19.860 --> 35:25.180]  подключению к процессу просто команды Монга из терминала, дальше переключаем контекст на базу
[35:25.180 --> 35:32.820]  данных конкретную, и вот подразумевая, что DB это имя нашей базы, мы соответственно дальше,
[35:32.820 --> 35:48.060]  в коллекцию users мы можем добавлять поля, можем удалять поля, можем искать все документы или
[35:48.060 --> 35:54.940]  один документ со соответствующими полями, можем создавать индекс по полям, ну, по полю,
[35:54.940 --> 36:02.620]  да, можем делать запросы на агрегацию данных, как показано в последнем буллите, то есть,
[36:02.620 --> 36:12.980]  в принципе, то, что мы базово делали в реалиционной СОБД-Позгресс, мы теоретически можем делать в
[36:12.980 --> 36:23.620]  Монга DB, но никаких ограничений на то, чтобы мы создали два абсолютно одинаковых, скажем так,
[36:23.620 --> 36:32.020]  как бы это лучше сформулировать, даже не то чтобы одинаковых, да, никаких ограничений на то,
[36:32.020 --> 36:38.420]  чтобы мы создали две противоречивые записи, например, о человеке по имени Джон в возрасте
[36:38.420 --> 36:45.540]  30 лет и с имейлом john-example.com у нас нет, мы можем создавать такие записи, ну, здесь,
[36:45.540 --> 36:52.300]  понятно, скорее всего будет по имейлу, что называется, идентификация, вот если имейл будет одинаков,
[36:52.300 --> 36:57.420]  а разные будут набирать телефонов, вон, где тебе будут проблемы, в принципе, и в Позгрессе можем
[36:57.420 --> 37:03.660]  такое месиво создавать, да, благо у нас есть возможность создания сорокатных ключей и,
[37:03.660 --> 37:10.580]  пожалуйста, инкриментируем на единичку и с каждой новой записью у нас об одном и том же дне идет
[37:10.580 --> 37:19.460]  новая информация, но разные телефоны, но все-таки все-таки базовая реализационная модель больше
[37:19.460 --> 37:29.140]  подходит для хранения однотипных данных, там больше возможностей из коробки, что называется,
[37:29.140 --> 37:38.260]  ну, и с точки зрения теории для того, чтобы избежать дублирования. Так, хорошо, это получается
[37:38.260 --> 37:45.860]  последний слайд, на этом мы с вами, в принципе, базово, ну, вот так, по верхам, да, повторюсь,
[37:45.860 --> 37:55.020]  такой аппендикс небольшой к нашей предыдущей лекции про NoSQL, базово по верхам мы посмотрели,
[37:55.020 --> 38:03.460]  а наиболее, наверное, интересное, ну, с моей точки зрения, я бы сказал, все-таки Neo4j,
[38:03.460 --> 38:08.900]  я никого не призываю, да, безусловно, здесь вопрос в том, что вы хотите сделать,
[38:08.900 --> 38:17.740]  MongoDB очень хорош на начальных этапах, например, какой-то вашего стартапа, поэтому Neo4j,
[38:17.740 --> 38:24.020]  наверное, использовать не стоит, лучше сделать MongoDB и туда вот скидывать какие-то данные в
[38:24.020 --> 38:32.700]  надежде, что потом, там, когда вы MVP сделаете, покажете, потом будет время и инвестиции,
[38:32.700 --> 38:38.980]  чтобы сделать какую-то, какую-то революционную базу данных или, да, не знаю, более что-то
[38:38.980 --> 38:44.780]  сделать, основанное на какой-то более жесткой схеме, там, те же графовые базы данных,
[38:44.780 --> 38:55.820]  а для начала MongoDB вполне себе хорошо, а Redis это каширование, каширование каких-нибудь чатов,
[38:55.820 --> 39:06.900]  сообщений, в этом смысле хорошая штука, в принципе, по большому счету, когда-то это
[39:06.900 --> 39:15.860]  использовалось и для формирования очередей задач, но это уже такая, ну, не то что использовалось,
[39:15.860 --> 39:20.140]  да, были варианты такого использования, но это уже, конечно, совсем другая история, сейчас есть
[39:20.140 --> 39:27.660]  профильные решения, и Redis так, конечно, лучше не использовать. Так, ну, ClickHouse, это скорее решение
[39:27.660 --> 39:44.140]  для DWH структур, для хранилищ данных, причем, опять же, да, вспоминая вот наш слайд со схемой того,
[39:44.140 --> 39:50.900]  что такое DWH, как вот слева на слайде, помните, у нас там были операционные приложения, потом через
[39:50.900 --> 40:01.300]  ETL-процесс данные загружались на DWH-сервер, и из DWH у нас в OLAP-приложение в какие-то
[40:01.300 --> 40:11.100]  аналитические отчеты данные поступали, вот ClickHouse, это что-то вроде, либо как довесок к DWH
[40:11.100 --> 40:20.540]  на сервере, там условно говоря, да, или в структуре серверов хранилища данных, он будет стоять либо
[40:20.540 --> 40:29.500]  у вас где-то уже ближе к виталином данных, то есть это решение, пожалуй, не для работы, может быть,
[40:29.500 --> 40:37.340]  с чем-то, в рамках каких-то небольших проектов, а решение скорее для, ну, такого, да,
[40:37.340 --> 40:46.900]  Enterprise уровня предприятия, но, в принципе, популярное решение, решающая возложные на него задачи.
[40:46.900 --> 41:01.500]  Наверное, на этом мы, пожалуй, закончим, курс наш подошел к концу, мы основные вещи с
[41:01.500 --> 41:08.820]  вами затруднули, посмотрели, надеюсь, было в каких-то вещах все-таки интересно, ну, понятно,
[41:08.820 --> 41:16.700]  что какие-то вещи, они такие тривиальные, повторяли либо семинарские занятия, либо,
[41:16.700 --> 41:21.380]  наоборот, семинарские занятия дублировали то, что мы здесь с вами рассказывали, либо, в принципе,
[41:21.380 --> 41:27.660]  синдексис, например, SQL, вещь, не имеющая какой-то теоретической подоплеки, по сути, делает просто
[41:27.660 --> 41:33.620]  список команд и правила их использования. Ну, вещь такая, да, не очень, наверное, интересная,
[41:33.620 --> 41:38.540]  но с которой нужно все равно было познакомиться, сделать какой-то минимальный обзор,
[41:38.540 --> 41:46.940]  и которую, ну, да, после этого можно уже осваивать путем практического применения.
