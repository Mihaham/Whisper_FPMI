[00:00.000 --> 00:08.480]  Но закончили мы тем, что в каком-то смысле доказали
[00:08.480 --> 00:12.560]  теорему Балабаша про случай P равно 1-2, как ведет себя
[00:12.560 --> 00:16.560]  хроматическое число случайного графа, когда P равно 1-2, то
[00:16.560 --> 00:18.880]  есть когда все графы равновероятны.
[00:18.880 --> 00:22.540]  Но дело упёрлось в мощную лему, которую можно кратко
[00:22.540 --> 00:25.200]  охарактеризовать даже в маленьком кусочке, если
[00:25.200 --> 00:26.200]  сно орех.
[00:26.520 --> 00:28.160]  Помните такой факт?
[00:28.160 --> 00:31.440]  В маленьком кусочке есть сно орех, это вот так лемма,
[00:31.440 --> 00:34.080]  ее кодовое название, или в маленьком кусочке есть
[00:34.080 --> 00:35.080]  сно орех.
[00:35.080 --> 00:38.760]  Что утверждение я напоминаю, вероятность того, что для
[00:38.760 --> 00:43.960]  любого множества s, входящего как под множество в множество
[00:43.960 --> 00:47.560]  вершин нашего случайного графа, вот здесь n вершин,
[00:47.560 --> 00:52.760]  а здесь я сейчас скажу, сколько мощность s равняется m, ну
[00:52.760 --> 00:56.040]  либо больше, либо равняется m, это как раз неважно.
[00:56.040 --> 01:01.640]  Выполнено, что аж, ограниченного на s, больше либо равняется
[01:01.640 --> 01:07.600]  k1, вот эта вероятность стремится к единице при n, стремящемся
[01:07.600 --> 01:12.160]  к бесконечности, где, напоминаю, здесь я думаю, что придется
[01:12.160 --> 01:19.480]  это держать на доске, вот такое вот у нас m, это как раз
[01:19.480 --> 01:25.160]  маленький кусочек, а лесной орех это k1, то есть картинка
[01:25.160 --> 01:29.800]  то вот такая, у нас всего n вершин, маленький кусочек
[01:29.800 --> 01:34.840]  это кусочек размера m, это произвольная s, и утверждается,
[01:34.840 --> 01:40.080]  что в каждом таком произвольном s, какое бы мы ни взяли, обязательно
[01:40.080 --> 01:43.840]  найдется лесной орех, то есть кусочек размера k1,
[01:43.840 --> 01:45.920]  в котором нет ни одного ребра.
[01:45.920 --> 01:49.320]  Вот мы этим чудом воспользовались в прошлый раз для того, чтобы
[01:49.320 --> 01:53.320]  покрасить каждый граф нужное число цветов, почти каждый
[01:53.320 --> 01:54.320]  граф.
[01:54.320 --> 01:59.200]  Так, друзья, я не очень монотонно рассказываю, понятно все,
[01:59.200 --> 02:03.200]  а то вроде как заладил, как пономарь, каждый граф,
[02:03.200 --> 02:06.920]  каждый граф, каждый граф, нормально, ну хорошо.
[02:06.920 --> 02:10.760]  Так, про k1 сейчас достаточно, наверное, помнить то, что
[02:10.760 --> 02:17.200]  во-первых, k1 асимптотически 2 лог 2-ичный n или m, это одно
[02:17.280 --> 02:21.480]  и то же с точки зрения асимптотики логарифма, и про k1 еще надо
[02:21.480 --> 02:28.480]  помнить, что вот у нас есть такая функция fk от m, была
[02:28.480 --> 02:30.480]  такая функция?
[02:30.480 --> 02:33.120]  Она равна по определению мат ожидания Икс-Катова,
[02:33.120 --> 02:37.120]  то есть среднему числу независимых множеств на k вершинах в случайном
[02:37.120 --> 02:38.120]  графе.
[02:38.120 --> 02:42.120]  Хорошая новость.
[02:43.040 --> 02:47.920]  Так, которая напоминает c из m по k на 2 в степени
[02:47.920 --> 02:49.640]  минус c из k по 2.
[02:49.640 --> 02:55.800]  Так вот, k1 подбиралось таким образом, чтобы fk1 от m было
[02:55.800 --> 03:02.120]  больше либо равно m в степени 3, плюс или малое от 1 что-ли,
[03:02.120 --> 03:03.120]  вот так.
[03:03.120 --> 03:04.120]  Было такое?
[03:04.120 --> 03:05.440]  А то сейчас опять навру.
[03:05.440 --> 03:12.040]  А, видите, вот наврал в обозначение, хорошо, да,
[03:12.040 --> 03:20.680]  было fmt от k, соответственно, здесь будет fmt от k1, а в остальном
[03:20.680 --> 03:21.680]  вроде все хорошо.
[03:21.680 --> 03:26.360]  Да, друзья, спасибо, я не помню, это ж неважно как
[03:26.360 --> 03:29.040]  обозначить, я уже немножко подзабыл.
[03:29.040 --> 03:31.920]  Все, вот это вот все, что надо помнить про параметры,
[03:31.920 --> 03:35.480]  но это тоже не сразу выстрелище ружье, оно выстрелит сильно
[03:35.480 --> 03:36.480]  позже.
[03:36.480 --> 03:39.040]  Вот, сейчас нам нужно доказать как-то вот эту лему.
[03:39.040 --> 03:46.040]  Давайте, где бы мне начать, вот тут начну доказательство,
[03:46.040 --> 03:51.200]  я напишу вероятность противоположного события, как всегда, существует
[03:51.200 --> 04:02.920]  s из v мощности m, такое, что альпа от g на s, чего, меньше
[04:02.920 --> 04:07.560]  чем k1, да, и я хочу доказать, что эта вероятность стремится
[04:07.560 --> 04:08.560]  к нулю.
[04:08.560 --> 04:13.280]  Ну, смысл утверждения я уже не комментирую, потому
[04:13.280 --> 04:16.080]  что в прошлый раз он был максимально ярко прокомментирован,
[04:16.080 --> 04:18.440]  сейчас надо просто вот взять и тупо это попытаться
[04:18.440 --> 04:19.440]  доказать.
[04:19.440 --> 04:21.520]  Оно не очень тупо, оно весьма тонко.
[04:21.520 --> 04:29.720]  Так, ну, что можно сразу сказать, и с этим вряд ли
[04:29.720 --> 04:32.760]  что-то удастся сделать, никакой формулы включения
[04:32.760 --> 04:34.400]  и исключения мы здесь не напишем.
[04:34.800 --> 04:37.600]  Так, друзья, вы помните, что если под знаком вероятности
[04:37.600 --> 04:41.160]  стоит квантор существования, то это фактически объединение
[04:41.160 --> 04:45.200]  событий, вероятность которого оценивается как сумма.
[04:45.200 --> 04:51.600]  Ну, вот я так и напишу, это сумма по всем s, вот так
[04:51.600 --> 04:59.800]  я выделяю, чтобы она большим казалась, мощности m, а чего
[04:59.800 --> 05:00.800]  надо суммировать?
[05:01.200 --> 05:08.120]  А, ну, что суммировать, вероятность того, что альфа вот g на s меньше
[05:08.120 --> 05:09.120]  чем k1.
[05:09.120 --> 05:12.120]  Так, друзья, согласны?
[05:12.120 --> 05:16.040]  Ну, на самом деле, смотрите, что значит g, ограниченное
[05:16.040 --> 05:19.800]  на какой-то свой кусок, у которого задан размер,
[05:19.800 --> 05:22.800]  задано количество вершин, мы берем и случайный граф
[05:22.800 --> 05:24.840]  ограничиваем на какую-то подсордельку.
[05:24.840 --> 05:30.240]  Вы согласны, что ограничить его на эту подсордельку
[05:30.240 --> 05:33.520]  и ограничить его на эту подсордельку, это ведь одно
[05:33.520 --> 05:34.520]  и то же.
[05:34.520 --> 05:39.400]  Вы понимаете, что за счет своей однородности случайный
[05:39.400 --> 05:45.160]  граф, будучи ограниченным на кусок множества вершин,
[05:45.160 --> 05:47.920]  превратится просто в случайный граф с этим количеством
[05:47.920 --> 05:48.920]  вершин.
[05:48.920 --> 05:53.240]  То есть, фактически, здесь написано просто c из n по
[05:53.240 --> 05:57.040]  m, это количество способов выбрать s большой, мощности
[05:57.880 --> 06:01.480]  m маленькое, количество слагаемых в этой сумме, а все слагаемые
[06:01.480 --> 06:02.480]  одинаковые.
[06:02.480 --> 06:06.440]  Это вероятность того, что, ну давайте, чтобы вам легче
[06:06.440 --> 06:11.120]  было воспринимать альфа от h меньше чем k1, и вот здесь
[06:11.120 --> 06:14.720]  вот вероятность уже берется на, давайте я вот так напишу,
[06:14.720 --> 06:19.840]  h это случайный граф на множестве из m вершин с вероятностью
[06:19.840 --> 06:22.960]  ребра 1 на 2.
[06:23.840 --> 06:28.120]  Ну я для красоты вместо g написал h, хотя казалось
[06:28.120 --> 06:30.760]  бы какая разница, но просто чтобы вам легче было потом
[06:30.760 --> 06:31.760]  это воспринимать.
[06:31.760 --> 06:40.560]  Вот это p, вот это p, оно на n вершинах, а вот это p, оно
[06:40.560 --> 06:43.920]  уже на m вершинах, давайте это просто для себя запомним
[06:43.920 --> 06:46.080]  и никаких лишних индексов рисовать не станем.
[06:46.080 --> 06:48.720]  Хорошо так?
[06:48.720 --> 06:49.720]  Нормально?
[06:50.480 --> 06:52.600]  Так, ну что делать-то?
[06:52.600 --> 06:54.800]  А, ну так что делать?
[06:54.800 --> 06:56.920]  Я сейчас перепишу это.
[06:56.920 --> 07:07.800]  Это равно c из n по m, вероятность того, что x с индексом k1 равняется
[07:07.800 --> 07:08.800]  нулю.
[07:12.800 --> 07:14.600]  Так, еще раз, что такое xk1?
[07:14.600 --> 07:15.600]  Вот оно там есть.
[07:16.480 --> 07:23.760]  По определению, xk1 – это количество независимых множеств
[07:23.760 --> 07:24.760]  на k1 вершинах.
[07:24.760 --> 07:32.320]  Ну согласитесь, что если максимальный размер независимого
[07:32.320 --> 07:35.360]  множества меньше, чем k1, то это прямо в точности
[07:35.360 --> 07:39.040]  то же самое, что независимых множеств, у которых k1 вершин
[07:39.040 --> 07:42.280]  нет, нет таких множеств.
[07:42.280 --> 07:43.280]  Их ноль.
[07:43.960 --> 07:45.160]  Это одно и то же.
[07:45.160 --> 07:48.960]  Альфа строго меньше, чем k1, и на k1 вершине нет ни
[07:48.960 --> 07:50.320]  одного независимого множества.
[07:52.320 --> 07:53.320]  Согласны?
[07:53.320 --> 07:57.960]  Так, теперь, я и в прошлом году так читал, и вам так
[07:57.960 --> 07:58.960]  прочитаю.
[07:58.960 --> 08:00.760]  Вы не зря сюда пришли, вы хоть послушаете смысл
[08:00.760 --> 08:01.760]  происходящего.
[08:01.760 --> 08:05.440]  Потому что даже те, кто будут пересматривать, это место
[08:05.440 --> 08:07.480]  могут при желании прокрутить.
[08:07.480 --> 08:10.200]  Потому что я вам сейчас расскажу неправильное продолжение
[08:10.200 --> 08:11.200]  рассуждения.
[08:11.600 --> 08:13.640]  И вообще даже вот эта часть уже неправильная.
[08:13.640 --> 08:17.080]  То есть она правильная в том смысле, что xk1 равно
[08:17.080 --> 08:20.280]  0, действительно равносильно тому, что альфа-отаж меньше
[08:20.280 --> 08:21.280]  чем k1.
[08:21.280 --> 08:23.680]  Тут никакого подвоха нет, это правильно.
[08:23.680 --> 08:26.120]  Другое дело, что если мы сейчас попробуем работать
[08:26.120 --> 08:29.160]  именно с этой случайной величиной, то у нас ничего
[08:29.160 --> 08:30.160]  не получится.
[08:30.160 --> 08:35.240]  Можно я вот продолжу некое рассуждение, и вы увидите,
[08:35.240 --> 08:38.600]  что ничего не получится.
[08:38.600 --> 08:42.200]  Потом мы его зачерикаем и сделаем что-то ужасное.
[08:42.200 --> 08:46.200]  Ну что, казалось бы, как, естественно, xk1.
[08:46.200 --> 08:47.200]  Взять, записать.
[08:47.200 --> 08:52.720]  Ну давайте, значит, действуем, как не так давно делали,
[08:52.720 --> 08:55.440]  но я уже не помню, это пару лекций назад было.
[08:55.440 --> 08:58.520]  Сначала делаем пустопорожные перегонки.
[08:58.520 --> 09:06.720]  Во-первых, пишем xk1 не превосходит нуля, потом пишем вероятность
[09:06.720 --> 09:11.440]  того, что xk1 со знаком минус больше либо равняется нуля,
[09:11.440 --> 09:14.520]  ну то есть домножаем на минус единицу, просто неравенство
[09:14.520 --> 09:18.080]  под знаком вероятности, и добавляем константу слева
[09:18.080 --> 09:20.680]  и справа, равную математическому ожиданию.
[09:20.680 --> 09:31.680]  p от мат ожидания xk1 минус xk1 больше либо равняется,
[09:31.680 --> 09:35.120]  нет, не ноль, зараза, не лезет.
[09:35.240 --> 09:39.760]  Конечно, мат ожидания е, xk, t, e1, оно не лезет, но ничего,
[09:39.760 --> 09:40.760]  вот это вот я продолжил.
[09:40.760 --> 09:44.440]  Так, друзья, все ж просто, да?
[09:44.440 --> 09:46.040]  Я к чему хочу привести?
[09:46.040 --> 09:47.040]  К неравенству Чебышова.
[09:47.040 --> 09:50.840]  Потому что ну что мы знаем кроме неравенства Чебышова?
[09:50.840 --> 09:51.840]  Ну кое-что знаем.
[09:51.840 --> 09:55.320]  Ну давайте попробуем неравенство Чебышова оценить.
[09:55.320 --> 10:02.360]  Получится c из n по m умножить на дисперсию xk1 и поделить
[10:02.400 --> 10:05.040]  на мат ожидания xk1 в квадрате.
[10:05.040 --> 10:08.480]  Так, надеюсь, что неравенство Чебышова все понимают,
[10:08.480 --> 10:09.480]  как я применю.
[10:09.480 --> 10:10.480]  Все понимают?
[10:10.480 --> 10:14.320]  Ну как, разность, больше либо равна какого-то числа,
[10:14.320 --> 10:16.560]  вероятность этого не больше, чем дисперсия, а поделить
[10:16.560 --> 10:18.040]  на квадрат этого числа.
[10:18.040 --> 10:19.520]  Стандартное неравенство Чебышова.
[10:19.520 --> 10:22.720]  Теперь смотрите, квадрат этого числа, я пошел назад,
[10:22.720 --> 10:24.680]  вот сюда вот, это вот эта штука.
[10:24.680 --> 10:34.560]  М в шестой, а дисперсия тоже не нулевая уж, конечно.
[10:34.560 --> 10:39.960]  То есть оценка, которая у нас получилась, вот эта
[10:39.960 --> 10:44.920]  вот, ну это может быть что-то стремящееся к нулю, но даже
[10:44.920 --> 10:47.920]  если оно и стремится к нулю, там это надо проверять,
[10:47.920 --> 10:50.480]  дисперсию считать как-то, даже если оно и стремится
[10:50.480 --> 10:53.600]  к нулю, то уж точно не быстрее, чем моногочлен
[10:53.600 --> 10:54.600]  от м.
[10:54.600 --> 10:57.680]  Друзья, это понятно?
[10:57.680 --> 11:01.200]  А теперь смотрите, с из не по м.
[11:01.200 --> 11:05.200]  Я не буду вас мучить, но мы ж с вами занимались
[11:05.200 --> 11:07.280]  асимптотиками всякими.
[11:07.280 --> 11:11.240]  М у нас, ну конечно, это не константа, помноженная
[11:11.240 --> 11:14.720]  на не, а это не поделить на что-то медленно растущее,
[11:14.720 --> 11:18.880]  но в общем это близко к экспоненте, товарищи, в общем это близко
[11:18.880 --> 11:19.880]  к экспоненте.
[11:19.880 --> 11:23.580]  То есть подставить вместо м, н деленное на что-то медленно
[11:23.580 --> 11:27.020]  растущее, или там n поделенное на миллион, при маленьких
[11:27.020 --> 11:30.980]  n это одно и то же, а если вы подставляете n поделенное
[11:30.980 --> 11:34.700]  на миллион, то в самой первой лекции мы с вами доказали,
[11:34.700 --> 11:36.340]  что такая c растет экспоненциально.
[11:36.340 --> 11:40.300]  То есть, наверное, с из не по м это не экспонента,
[11:40.300 --> 11:44.780]  а какая-то субэкспонента, но уж точно не моногочлен.
[11:44.780 --> 11:46.540]  Моногочленом она не забьется.
[11:46.540 --> 11:49.540]  Наша-то цель доказать, что все это стремится к нулю,
[11:49.540 --> 11:51.900]  извините, я бегаю, поэтому за мной приходится вводить
[11:51.900 --> 11:52.900]  камеру.
[11:53.700 --> 11:57.340]  Должно стремиться к нулю, но в фигушке вы почти экспоненциально
[11:57.340 --> 12:01.340]  растущую функцию укокаете до нуля, деля ее на какой-то
[12:01.340 --> 12:03.300]  несчастный многочлен м в шестой степени.
[12:03.300 --> 12:07.020]  Я понятно объяснил?
[12:07.020 --> 12:14.420]  А с какими еще штуковинами мы имели дело, которые значительно
[12:14.420 --> 12:18.780]  опережают действие неравенства Чебышова?
[12:18.780 --> 12:24.180]  Это вот помните, да, неравенство Азумы?
[12:24.180 --> 12:27.180]  Помните неравенство Азумы?
[12:27.180 --> 12:30.180]  Забыли уже.
[12:30.180 --> 12:33.860]  Ну, было такое, да, было неравенство Азумы, которое
[12:33.860 --> 12:39.860]  говорило, что если вы возьмете какую-то функцию в случайном
[12:39.860 --> 12:45.980]  графе, ну, то есть, в случайную величину, вычтите из нее
[12:45.980 --> 12:48.020]  ее математическое ожидание.
[12:48.020 --> 12:50.820]  Ну, собственно, как мы здесь и сделали.
[12:50.820 --> 12:54.580]  И сравните это дело с какой-нибудь константой, то это будет не
[12:54.580 --> 12:58.820]  больше, чем e в степени минуса квадрат поделить на нечто.
[12:58.820 --> 12:59.820]  А вот на что поделить?
[12:59.820 --> 13:03.980]  Может, вы там отлеснули уже, вспомнили?
[13:03.980 --> 13:07.940]  Но может быть на 2 и на минус 1, да, так бывает, а еще бывает
[13:07.940 --> 13:08.940]  по-другому.
[13:08.940 --> 13:12.500]  Бывает, e в степени минуса квадрат поделить на 2 c
[13:12.500 --> 13:13.500]  из n по 2.
[13:13.500 --> 13:17.100]  И вот так лучше, а так хуже, но это уж как повезет.
[13:17.300 --> 13:20.980]  Потому, что вот такое неравенство выполняется в случае Липшицевости
[13:20.980 --> 13:24.760]  по вершинам, а такое в случае Липшицевости по ребрам.
[13:24.760 --> 13:28.260]  Очень легко запоминать, вершин n, ребра полного графа
[13:28.260 --> 13:29.560]  c из n под в.
[13:29.560 --> 13:33.620]  Поэтому если f Липшицево по ребрам, то имеет место
[13:33.620 --> 13:36.220]  такое неравенство, оно похуже, потому что в знаменателе
[13:36.220 --> 13:40.060]  стоит большое число, а оно со знаком минус.
[13:40.060 --> 13:41.060]  Вот.
[13:41.060 --> 13:44.140]  И если Липшицево по вершинам, тогда в знаменателе стаять
[13:44.140 --> 13:49.180]  относительно маленькое число и со знаком минус дает очень хорошую оценку, но даже эта оценка
[13:49.180 --> 13:58.660]  хороша. Так, друзья, я сколько-нибудь понятен или я только для себя рассказываю? Понятно, да? Вот это
[13:58.660 --> 14:04.340]  важно просто прочувствовать. Вот мы хотим этим воспользоваться, но первая трагедия, которая нас
[14:04.340 --> 14:11.980]  подстерегает и у которой будет катарсис, все будет хорошо. Первая трагедия состоит в том, что х, она
[14:11.980 --> 14:22.380]  Липшицева хоть по кому-нибудь, число независимых множеств на данном количестве вершин. Очевидно,
[14:22.380 --> 14:28.500]  что она не является Липшицевой ни в каком смысле слова. Ну, потому что представьте себе, что у вас
[14:28.500 --> 14:35.620]  есть какое-то ребро, например, и вот на нем сидит одно независимое множество, то есть куча вершин,
[14:35.620 --> 14:41.100]  между которыми только вот это одно ребро и присутствует, другое независимое множество,
[14:41.100 --> 14:47.340]  опять куча вершин, которые портятся только вот этим одним единственным ребром. Третье какое-то множество
[14:47.340 --> 14:58.100]  вершин опять без ребер, чпок, и все стали независимыми. Одно ребро покоцали, а величина изменилась
[14:58.100 --> 15:05.860]  катастрофически, не на единицу, а насколько хотите, на 3, на 10, на 100. Друзья, помните, что такое Липшицево
[15:05.860 --> 15:12.020]  по вершинам, давайте я напомню, по ребрам. Что такое Липшицево по ребрам? Это значит, вы удаляете одно
[15:12.020 --> 15:18.580]  ребро из графа или добавляете к нему одно ребро, и ваша величина не меняется или меняется на
[15:18.580 --> 15:25.300]  единичку, но не больше того. Вот это Липшицевость по ребрам. Я в свое время говорил, даже количество
[15:25.300 --> 15:33.020]  треугольников, очевидно, не Липшицево по ребрам. Ну, по вершинам тем более, потому что там
[15:33.020 --> 15:38.900]  разрешается портить окрестность любой вершины. То есть мы не можем вот эту всю схемотехнику
[15:38.900 --> 15:45.260]  провернуть, довести до сюда и сказать, давайте использовать неравенство Азумы. Хотелось бы
[15:45.260 --> 15:50.660]  вот в этом месте вместо неравенства Чебышова использовать неравенство Азумы. Вместо вот этой
[15:50.660 --> 15:55.420]  дроби будет экспонента от нее же, только от перевернутой и уже экспонента от отрицательного
[15:55.420 --> 16:03.580]  многочлена. Ух ты, это круто. Понятно говорю, да? А не можем, потому что Xкатая первая, к сожалению,
[16:03.580 --> 16:12.020]  не является Липшицевой отнюдь ни в каком смысле. Так, друзья, ну это все философия. То есть если бы я
[16:12.020 --> 16:17.780]  хотел просто формально доказать теорему, то я бы этого всего не говорил, а сказал, давайте рассмотрим
[16:17.780 --> 16:23.700]  какую-то ужасную случайную величину и будем с ней работать. Вот сейчас я это и сделаю. То есть вот была
[16:23.700 --> 16:31.980]  философия-философия, теперь я это все стираю. Ну, Азуму не стираю, там пригодится. Так,
[16:31.980 --> 16:41.860]  знаете, а тут не стираю пока. Давайте я введу случайную величину Yкатая вместо Xкатого.
[16:41.860 --> 16:49.100]  Ну, она, естественно, случайная величина на множестве графов, поэтому аргумент ее это граф.
[16:49.100 --> 16:59.500]  Какой? Я без модуля нарисовал, поэтому коэффициент 2 не нужен. Ну, имеется в виду,
[16:59.500 --> 17:03.780]  что минуса будет с той же вероятностью, а с модулем удвоенной. Да-да-да, правильно.
[17:03.780 --> 17:17.140]  Вот Yкатая, по определению, это вот что такое у нас будет. Это будет максимальное такое число,
[17:17.140 --> 17:34.140]  давайте T, например, что существует набор множеств А1 и так далее Аt среди вершин нашего графа,
[17:34.140 --> 17:53.340]  каждая из которых имеет мощность, равную K1, вот этому самому K1, Yкатая первая, равная K1. Так,
[17:53.340 --> 18:02.700]  но это еще не все. Для любых Ij, я поясню смысл, все будет понятно, Аитая пересеченная с Ажитым
[18:02.700 --> 18:13.380]  имеет мощность не большую единицы. Сейчас не большую единицу, а больше или равную двойке,
[18:13.380 --> 18:19.800]  сейчас наоборот не больше единицы, правильно. Существует множество пересекающиеся не более
[18:19.800 --> 18:35.680]  чем по одной вершине, но и Аитая независима. То есть картина вот такая, есть множество вершин,
[18:35.680 --> 18:47.760]  в нем есть какие-то подмножества А1 размера К1, А2 размера К1 и так далее. Вот так вот нарисую
[18:47.760 --> 18:58.080]  как-нибудь по одной вершине. Аn тоже размера К1, но извините, оно такое тоненькое, поэтому того же
[18:58.080 --> 19:05.320]  размера. Но так что вот они все независимые, каждая из них независимая, нет ребер внутри,
[19:05.320 --> 19:12.840]  и при этом каждые два пересекаются не больше чем по одной вершине. Вот нас интересует максимальная
[19:12.840 --> 19:22.400]  мощность такой совокупности А1, Аt, что каждая Аитая независима нужной мощности К1, и при этом
[19:22.400 --> 19:31.520]  каждые два из них, если пересекаются, то только по одной вершине. Жуть какая-то, да? Не, ничего, понятно.
[19:31.520 --> 19:41.200]  Друзья, ну вот я хочу сказать, что вот можно так поправить. Нет, что-то Y у меня не было. Пусть будет
[19:41.200 --> 19:51.080]  вот так. Если бы я сразу так написал, ну вы бы мне сказали, что я сумасшедший. Почему не X? Вот те из вас,
[19:51.080 --> 19:56.400]  кто вдумывается и успевает просто так быстро сообразить, ну точно бы сказали, а почему не X-то?
[19:56.400 --> 20:05.160]  Вот а потому не X, что с X-ом работать нельзя, он не Липшицев. А Y Липшицева, но она равна нулю тоже
[20:05.200 --> 20:12.320]  тогда и только тогда, когда у нас просто нет ни одного независимого множества. Согласитесь?
[20:12.320 --> 20:20.360]  Что в этом смысле онаrilky же самую роль, что X, она равна нулю уже только тогда, когда нет ни одного
[20:20.360 --> 20:26.040]  независимого множества. Если есть хотя бы одно независимое множество, то t равно единице, мы уже
[20:26.040 --> 20:33.000]  можем взять, вот взяли одно независимое множество. Все получилось, все хорошо. Поэтому это правильное
[20:33.000 --> 20:38.360]  равенство, но теперь согласитесь, что yкт первая так хитро устроена, что она
[20:38.360 --> 20:45.680]  липшится по кому? По ребрам, конечно, да. Именно ради этого требование, чтобы
[20:45.680 --> 20:52.400]  мощность пересечения каждых двух была не больше единицы. Ни у каких двух нет
[20:52.400 --> 20:59.160]  общего потенциального ребра, поэтому удаление одного ребра или добавление
[20:59.160 --> 21:05.040]  одного ребра не поменяет эту цепочку больше чем на единицу максимально. Одно
[21:05.040 --> 21:09.440]  множество может добавиться, но два множества добавиться не могут, потому что
[21:09.440 --> 21:15.840]  тогда бы они имели общее ребро. Друзья, понятно говорю? Вот, то есть yкт первая
[21:15.840 --> 21:20.920]  липшицева по ребрам. Вот, то есть мы такое неравенство будем применять, но только
[21:20.920 --> 21:34.720]  с заменой на м. Липшицева, я очень люблю этот, как подпись, да, липшицева по ребрам. Поэтому
[21:34.720 --> 21:39.640]  будем использовать вот такое неравенство. Ну какое? Давайте я здесь подотру, я специально
[21:39.640 --> 21:48.240]  ничего не трогал. Я вместо х напишу y, все будет то же самое. Здесь тоже вместо
[21:48.240 --> 22:03.800]  x и y. Здесь везде вместо x и y. Это уже стало противно немножко. Тут вместо x и y. А вот это вот
[22:03.800 --> 22:14.800]  нужно переписать. На е в какой степени? Минус модуль еукт первая в квадрате, это
[22:14.800 --> 22:33.000]  вот а наше, с которым мы сравниваем. А наше. Поделить на что? На два. С и зен по два. Так, друзья, тут
[22:33.000 --> 22:41.640]  что-нибудь видно или оно смешалось? Как бы это так отделить? С и зен такую сейчас штучку надо
[22:41.640 --> 22:57.360]  правильно отделить. Вот так. Вот так вот. Получилось? Видно? Ну вот тут вот еукт первая,
[22:58.240 --> 23:05.320]  оно сверху. А здесь еукт первая в квадрате, показатели отрицательные экспоненты, поделенные на два
[23:05.320 --> 23:20.680]  с и зен по два. Ну это, товарищи, меньше, конечно, чем два в н-й на е в степени. Той же самый еукт первая
[23:20.680 --> 23:29.120]  в квадрате поделить на два с и зен по два. То есть я с и зен по м совсем халявно оцениваю. Я долго
[23:29.120 --> 23:35.360]  рассуждал, что это почти экспонента, поэтому на самом деле уж очень большой халявы тут нет. А мы
[23:35.360 --> 23:42.800]  сейчас так хорошо оценим вот эту отрицательную экспоненту, что нам станет наплевать. Понятно
[23:42.800 --> 23:49.360]  говорю, да? Но это нам предстоит, потому что, с одной стороны, мы вроде преуспели, мы получили
[23:49.360 --> 23:55.120]  экспоненциально убывающую величину, но мы замели пока что пыль под ковер. Мы же не понимаем,
[23:55.120 --> 24:01.600]  насколько она реально убывает. Мы же не знаем мат ожидания y-катова первого, мы знаем мат ожидания
[24:01.600 --> 24:10.240]  x-катова первого, и оно вот такое. Вот бы мат ожидания y-катова первого было, если не такое,
[24:10.240 --> 24:18.600]  то хоть какое-нибудь похожее. Тогда было бы хорошо. Так, понятна цель? Давайте я напишу ее реализацию,
[24:18.600 --> 24:26.200]  то есть еще одну лемму в лемме, которую мы сегодня докажем. Так, чего надо стирать? Вот это можно стирать.
[24:26.200 --> 24:47.800]  Так, лемма в лемме. Вот так. Мы доказываем лемму, а для того, чтобы доказать, формулируем лемму.
[24:47.800 --> 24:56.240]  Это лемма вот в этой лемме. Лемма утверждает, что мат ожидания y-катова первого больше либо равняется
[24:56.240 --> 25:04.360]  с точностью до асимптотики вот такой величины m в квадрате поделить на 2k1 в четвертой степени.
[25:04.360 --> 25:12.880]  Но прежде всего, давайте убедимся, что если это верно, то мы победили вот здесь, и это стремится к
[25:12.880 --> 25:18.880]  нулю. То есть нам останется доказать только лемму в лемме. Мы убедимся, что это стремится к нулю,
[25:18.880 --> 25:26.120]  и тогда останется доказать лемму в лемме. Ну, действительно, давайте я все-таки перепишу. У нас
[25:26.120 --> 25:32.240]  2 в степени n, а тут мы вот эту штуку подставляем с квадратом, то есть будет какая-то асимптотика.
[25:32.240 --> 25:43.720]  Так, дальше будет m в четвертой степени поделить на 4k1 в восьмой, и еще надо будет поделить на 2c из m
[25:43.720 --> 25:53.760]  по 2. Это вот здесь у нас 2c из m по 2, правильно? Так, друзья, может вы сразу понимаете или не очевидно?
[25:53.760 --> 26:01.520]  Ну ладно, не очевидно. Равно 2 в степени n на e в степени... Сейчас я чуть-чуть другую асимптотику
[26:01.520 --> 26:08.760]  напишу. Ну какая разница? Все равно это будет асимптотика. Будет вот так. m в четвертой поделить
[26:08.760 --> 26:18.760]  на 8k1 в восьмой и на m в квадрате. Я просто хочу сказать, что c из m по 2... А, надо было пополам,
[26:18.760 --> 26:26.440]  ладно. c из m по 2 это m квадрат пополам. В асимптотике. А асимптотику я сюда загнал. То есть вот это
[26:26.440 --> 26:31.480]  то малое от единицы, и вот эта суть разные вещи. Ну какая разница? И то, и другое стремится к ноль.
[26:31.480 --> 26:43.040]  Ну мне кажется сегодня стало лучше, по крайней мере с теми временами, когда я здесь умирал. Друзья,
[26:43.040 --> 26:49.720]  вам как? Хорошо? Вам нормально? Ну тогда значит нормально. Я-то понятно прыгаю, чем холоднее,
[26:49.720 --> 26:58.280]  тем лучше. Вам комфортно? Друзья, понятно, что произошло? Ну то есть вот эту двойку,
[26:58.280 --> 27:07.360]  конечно, надо было здесь написать, просто 4 и все. Вот так. Чпок-чпок. Тут двоечка. А, 2вн,
[27:07.360 --> 27:14.040]  н потерялась. Тут двоечка. Ну смотрите, а k1, я специально ведь напомнил, что оно примерно
[27:14.040 --> 27:20.640]  два лог двоечной н, да? Ну примерно в смысле вот с точностью размножения на 1 плюс о малое от единицы.
[27:20.640 --> 27:32.640]  Ну то есть все можно переписать вот так. Это 2 в степени n на e в степени минус 1 плюс о малое,
[27:32.640 --> 27:41.480]  даже не 1 плюс о малое, я вот так напишу. m в степени 2 плюс о малое от единицы. Мы уже так делали. Я
[27:41.480 --> 27:46.680]  вот это m в квадрате делю на какую-то степень логарифма, то есть реально это не плюс, а минус,
[27:46.680 --> 27:51.880]  но мне плевать там. Плюс-минус. Важно, что это функция, которая стремится к нулю. Степень логарифма,
[27:51.880 --> 28:00.880]  она влияет только так. Ну и все. m. Смотрите, какое m. Это опять n поделенное на степень логарифма. То
[28:00.880 --> 28:06.800]  есть я могу в свою очередь это вот так переписать. 2 в степени n на e в степени минус n квадрат и
[28:06.800 --> 28:15.080]  к квадрату добавленного малой от единицы. m отличается от n делением на какую-то степень
[28:15.080 --> 28:21.680]  логарифма. Она вся уходит вот в этого малой от единицы. Это стандартный анализ. Стандартный
[28:21.680 --> 28:27.440]  анализ? Проходили ведь в прошлый раз? Мы с вами прям проверяли. Ну согласитесь,
[28:27.440 --> 28:37.280]  что это с огромным свистом летит в ноль, то есть это докажем будем в героях. Вот. Так,
[28:37.280 --> 28:43.680]  ну что? Вот это определение не хотелось бы стирать, а все остальное стереть можно.
[28:43.680 --> 29:04.880]  Чтобы вам было еще, может быть, содержательно понятнее, давайте я сперва не докажу эту лему.
[29:04.880 --> 29:13.440]  Опять будет такая врезочка чисто на понимание происходящего. Можно? Можете записывать,
[29:13.440 --> 29:18.640]  можете не записывать, но вот эта штука запишет, наверное, если батарейки не сядут. Вот я хочу,
[29:18.640 --> 29:26.920]  чтобы суть происходящего понимали. Что на самом деле такое вот это e, y, k, t первое? Как это
[29:26.920 --> 29:35.120]  можно интерпретировать? Можно интерпретировать это вот как. Давайте k с индексом m, это полный
[29:35.120 --> 29:40.680]  граф на ме вершинах, как всегда, просто стандартное обозначение. Так? Давайте,
[29:40.680 --> 29:46.040]  если я над ним нарисую черту, то это, наоборот, пустой граф, то есть такое независимое множество
[29:46.040 --> 29:51.720]  из отдельных вершин, которых мэш стук. k, m с чертой стерли все ребра. Ну как обычно,
[29:51.720 --> 29:57.360]  j с чертой это инвертированный граф, ребра стерли, каких не было, наоборот, провели. Но тут все были,
[29:57.360 --> 30:03.320]  поэтому если все ребра стерли, осталось пустое множество. Ребр, а вершина отдельная. Вот такой
[30:03.320 --> 30:19.840]  k, m с чертой. Вот что такое y, k, t от вот этого графа? Давайте подумаем. Ну k, t, k, t первое там не
[30:19.840 --> 30:29.200]  так важно, просто пусть какое-то k дано, например, k первое. Вот что такое y, k, t от пустого графа? Здесь
[30:29.200 --> 30:36.160]  напоминается определение. Это фактически нам нужно просто взять максимальное количество k-элементных
[30:36.160 --> 30:46.360]  подмножеств, попарные пересечения которых имеют мощности не больше, чем единица. Ну потому что
[30:46.360 --> 30:51.640]  тут все множества независимые, и вот это условие про то, что они являются независимыми, никакого
[30:51.640 --> 30:57.840]  смысла сейчас не имеет. Просто нас интересует максимальное количество k-элементных подмножеств,
[30:57.840 --> 31:04.160]  сколько элементного множества, me-элементного множества, me-элементного множества. Так что они
[31:04.160 --> 31:09.120]  попарно пересекаются не больше, чем по одному элементу. Может быть вы вспоминаете задачку
[31:09.120 --> 31:17.280]  теоретагирования, которую я рассказывал. Я про пьяниц даже говорил, наверное, что там тройки
[31:17.280 --> 31:28.280]  пьяниц какие-то. Вот это оно самое. Ну очевидно, ну или почти очевидно, сейчас я напишу очевидно,
[31:28.280 --> 31:33.400]  мне кажется, что очевидно, но это обычно не очевидно. Людям почему-то не очевидно, что это не
[31:33.400 --> 31:43.800]  больше, чем c из m по 2 поделить на c из k по 2. Это очень простое упражнение на дирихле. Значит,
[31:43.800 --> 31:52.440]  как это получается? Если у вас сарделька из me-вершин, как угодно представлена вот в виде
[31:52.440 --> 31:58.920]  таких k-вершинных подмножеств, пересечение каждых двух из которых либо пусто, либо по одной вершине,
[31:58.920 --> 32:06.020]  то у них нет общих пар вершин, правильно? Но вот мы посчитаем количество пар вершин в каждой под
[32:06.020 --> 32:14.780]  сардельке. Оно вот такое, c из k по 2. Просто пары вершин. Берем пару вершин, берем другую пару
[32:14.780 --> 32:22.580]  вершин. Сколько всего пар вершин в множестве из k-вершин? Ну c из k по 2, очевидно. При этом общих пар
[32:22.580 --> 32:29.820]  вершин у этих сарделек нет. Ну все, поэтому получается, что самих этих сарделек точно не больше,
[32:29.820 --> 32:34.660]  чем количество всех пар вершин на огромную сардельку поделить на количество пар вершин,
[32:34.660 --> 32:43.300]  подающих каждую. Друзья, я понятно объяснил? Это просто банальный принцип дирекле. Ну это примерно,
[32:43.300 --> 32:50.180]  особенно если m и k стремятся к бесконечности, как это происходит у нас, тогда это можно писать тильда.
[32:50.180 --> 32:58.260]  Ну можно по-разному, да, но это примерно m квадрат на k квадрат, друзья, это понятно? Так вот,
[32:58.260 --> 33:08.100]  я утверждаю, что если в качестве k взять k1 и y брать не на k с чертой, то есть на графе,
[33:08.100 --> 33:17.660]  в котором вообще ребер нет, а даже на случайном его подграфе, половину ребер провести в среднем,
[33:17.660 --> 33:26.100]  то все равно оценка снизу будет почти такая же, как оценка сверху в самом лучшем случае.
[33:26.100 --> 33:35.740]  Самый лучший случай, это когда ребер вообще нет, тогда yкт самое большое, конечно. На случайном
[33:35.740 --> 33:42.820]  подграфе yкт скорее всего поменьше, но утверждается, что в среднем оно и снизу оценивается почти так,
[33:42.820 --> 33:50.380]  как в лучшем случае оно оценивается сверху. Ну потерялся квадрат, да, вот тут k квадрат,
[33:50.380 --> 33:57.020]  а тут k4. Сейчас, друзья, вот эту интуицию я объяснил, да, это не обязательно понимать,
[33:57.020 --> 34:01.500]  но это полезно понимать, это не нужно будет знать на экзамене, но если вы это прочувствуете,
[34:01.500 --> 34:13.100]  вы лучше поймете теорию. Такой вот происходит, да, гипотеза до сих пор не доказана, что здесь
[34:13.100 --> 34:20.180]  можно заменить k4 на k в квадрате, но пожертвовав какой-то... Эту гипотезу до сих пор никто не
[34:20.180 --> 34:27.700]  умеет доказывать. Открытая проблема. Ну ладно, нам-то все равно, видите, какой тут свист получился,
[34:27.700 --> 34:33.620]  нам плевать в какую степень логарифом возводить в квадрат или в сотую, все пойдет вот в этого маленькой
[34:33.620 --> 34:40.140]  от единицы, но а n в квадрате, конечно, забивает с большим запасом. Вот, поэтому это было такое
[34:40.140 --> 34:48.980]  лирическое отступление врезко, теперь я ее стираю и формально аккуратно доказываю лему. Так,
[34:48.980 --> 34:55.220]  давайте формально докажем то, что здесь написано, но это очень красиво на самом деле,
[34:55.220 --> 35:00.100]  то есть если вы поймете сейчас прям вот сейчас доказательство, то оно вас тоже в какой-то
[35:00.100 --> 35:12.540]  мере должно проканать. Потому что для того, чтобы доказать вот это неравенство, а неравенство
[35:12.540 --> 35:18.460]  вроде как утверждает что-то про случайные объекты, то есть про случайные графы, мы сейчас применим
[35:18.460 --> 35:27.100]  вероятностный метод, то есть добавим еще случайности, но это само по себе неожиданно. То есть мы
[35:27.100 --> 35:35.500]  дополнительно усредним в каком-то смысле, но давайте сейчас я объясню о чем идет речь. Так,
[35:35.500 --> 35:48.420]  что же мы сделаем? Давайте обозначим как-нибудь вот так k1 прямое и так далее,
[35:48.420 --> 36:00.020]  но большое. Прямое, но большое или и большое. k большое с индексом виноват c из m по k1,
[36:00.020 --> 36:09.240]  но обозначение, конечно, несколько громоздкие, но я хочу просто взять и перечислить все под
[36:09.240 --> 36:22.940]  множество мощности k1 в графе нам и вершинах. Это просто все под множество. Что? Нет,
[36:22.940 --> 36:28.980]  ну индикатор тут фиг получится с индикаторами, но фиг получится с индикаторами, потому что нас
[36:28.980 --> 36:34.740]  интересуют не отдельные под множество, а их такие цепочки что ли совокупности. Тут вот как,
[36:34.740 --> 36:40.540]  какие тут индикаторы-то брать для совокупности, а нас интересует же не мощность, а максимальная
[36:40.540 --> 36:46.100]  мощность, то есть это явно не минейность мат ожидания, конечно, тут что-то будет похитрее. Пока
[36:46.100 --> 36:52.020]  я просто ввожу обозначение для всех под множество мощности k1, ну на множество вершин,
[36:52.020 --> 36:59.860]  которых у нас m штук. Все под множество мощности k1, а уж где понятно. У нашей большой сардельки,
[36:59.860 --> 37:04.700]  которая все время символизирует множество из m вершин. Всего вершин в графе m штук,
[37:04.700 --> 37:15.620]  и вот мы берем все k1 элементные под множество. Так, давайте скажем, что yk1 в этих черненах
[37:15.620 --> 37:26.820]  можно вот так сказать, что такое yk1adj. Это максимальное количество множества отсюда,
[37:26.820 --> 37:34.020]  которые пересекаются попарно не больше, чем по одному элементу. То есть просто можно вот так
[37:34.020 --> 37:45.220]  написать, это максимальная t опять, такое, что существует там k и t первое, k и t с номером t.
[37:45.220 --> 37:54.980]  А, нет, сейчас, подожди, не, не надо так писать, извините, вот это пусть будет, а так писать не надо,
[37:54.980 --> 38:02.740]  все, так писать не надо, виноват. Так, сейчас, сейчас, секунду, я подумаю, как лучше сказать,
[38:02.740 --> 38:14.740]  чуть-чуть я поторопился, значит, все под множество мощности k1, это, конечно, хорошо. Так, так, так, так, так, так.
[38:14.740 --> 38:32.300]  Ага, ой, сейчас. Я же обещал вероятностный метод, вот давайте его сразу запустим, а зачем,
[38:32.300 --> 38:42.140]  это потом будет понятно. Так, давайте возьмем какое-нибудь число, назовем его q, но q плохо,
[38:42.140 --> 38:48.780]  потому что оно путается с p, правда у нас p нет, у нас p равно 1 второй, может и неплохо. Я не знаю, q,
[38:48.780 --> 38:58.180]  можно взять число q или q со звездочкой лучше? Лучше q, да? А q с крышечкой не хотите? Шучу, шучу. Давайте
[38:58.180 --> 39:03.980]  просто q, хорошо, но q это не один минус p, пожалуйста, только не путайте, это не один минус p, у нас p никакого
[39:03.980 --> 39:11.060]  нет, у нас вероятность ребра одна-вторая, поэтому q это будет тоже какая-то вероятность, но какая,
[39:11.340 --> 39:27.020]  я сейчас скажу. Сейчас, аааааааааааааааааааааааааааааааа, елки-палки, черт, я что-то путаю,
[39:27.020 --> 39:38.420]  сейчас не так надо сделать, не так, во, q будет сейчас, q будет в секунду, что-то я отраможу,
[39:38.420 --> 39:47.700]  извините, друзья, не знаю почему. Давайте еще k красивое возьмем. Ну, друзья, я вот и у тех,
[39:47.700 --> 39:52.420]  кто потом слушать будет, прошу прощения, чуть путаюсь. Сейчас все расставим по полочкам,
[39:52.420 --> 39:57.500]  все будет очень аккуратно. Значит, вот есть эти k прямые, это просто все k 1 элементные под
[39:57.500 --> 40:04.080]  множество. А давайте у нас есть какой-то граф. Ну, случайный, не случайный. Давайте введем такое
[40:04.080 --> 40:22.000]  множество k красивое от g. Это множество тех k прямое, даже некрасивое, потому что рука
[40:22.000 --> 40:28.160]  сорвалась. Видите, какое некрасивое оно получилось и не совсем прямое. Ну ладно,
[40:28.580 --> 40:44.600]  множество тех k прямое it вот отсюда, что k it является независимым в графе g. Вот так.
[40:44.600 --> 40:50.660]  Значит, смотрите, пока у нас случайен граф, он случайен, конечно, мы каждое ребро проводим
[40:50.660 --> 40:56.180]  независимо от остальных, с вероятностью одна вторая, но даже представим себе, что мы граф зафиксировали
[40:56.180 --> 41:02.240]  и просто рассмотрели вот такое множество тех его k 1 элементных под множество, которые в нем
[41:02.240 --> 41:08.360]  образуют независимое множество, то есть не соединены ребра внутри. Так понятно, что такое k от g, да?
[41:08.360 --> 41:15.840]  Как красивое от g вам дан граф, вы просто смотрите все его k 1 элементные независимые под множество.
[41:15.840 --> 41:22.920]  Ну, я как-то немножко нечетко просто выражался, но k от g, вот вроде понятно, что такое. А теперь я
[41:22.920 --> 41:29.300]  возьму те независимые множества, которые попали в этот вот граф и их прорежу в некотором смысле,
[41:29.300 --> 41:35.380]  а именно вот эта чиселка q, которая будет служить вероятностью, она будет служить вероятностью того,
[41:35.380 --> 41:42.420]  что каждое отдельное множество, попавшее вот в это k красивое, мы сохраним независимо от всех остальных.
[41:42.420 --> 41:50.980]  То есть вот есть какое-то k красивое от g, фиг знает, как обозначить его элементы, это какие-то там
[41:50.980 --> 42:00.240]  не знаю, а1 и так далее. А, кстати, можно сказать, с каким последним индексом, какой последний индекс,
[42:00.240 --> 42:10.760]  понимаете, как его написать? Сколько всего независимых множеств в графе g? Нет, альфа это максимальный размер.
[42:10.760 --> 42:25.960]  А что такое, хе, это хроматическое число, что ли? Нет, это x с индексом k1 от g, ха-ха, ну xk1 от g это количество
[42:25.960 --> 42:31.960]  независимых множеств размера k1 в графе g, просто по определению, вот тот самый, который мы забанили и
[42:31.960 --> 42:46.760]  заменили на y. Сейчас узнали его, да? Это x, да, x это количество независимых, ну каждая аи-т принадлежит вот этому множеству k1, kc, см по k1.
[42:46.760 --> 42:59.200]  Вот, то есть размер этого k от g это, конечно, xkt1 от g, а вот оно же, вот же оно. Друзья, я специально его берег.
[42:59.200 --> 43:06.760]  Сейчас, друзья, я медленно рассказываю, но я надеюсь, что пока все понятно. Чуть-чуть я путался, но сейчас уже не путаюсь.
[43:06.760 --> 43:18.360]  Теперь, смотрите, мы это множество начинаем прореживать, то есть мы бросаем монетку, которая с вероятностью q кокает нам очередное множество.
[43:18.360 --> 43:25.240]  Бросаем монетку, если реализовалась вероятность q, мы это множество просто не вытаскиваем оттуда и похереваем.
[43:25.240 --> 43:32.440]  Если, наоборот, реализовалась противоположная вероятность, мы его вытаскиваем и бережно сохраняем.
[43:32.440 --> 43:43.480]  Так, я могу, конечно, заподозрить, что некоторые считают, что похерить это плохое слово. Это хорошее слово, это поставить крест.
[43:43.480 --> 43:50.040]  Ну, поксерить, да, это не поставить крест. Вот смотрите, как интересно вы предложили.
[43:50.040 --> 43:55.840]  Значит, если вероятность q, то мы похериваем, а если вероятность 1-q, то мы поксериваем.
[43:55.840 --> 44:03.360]  Ну, в смысле, что мы его отправляем в некоторое новое строющееся множество, которое давайте назовем, например, c от g.
[44:03.360 --> 44:13.480]  Нет, нет, не вершина, еще раз. k от g состоит из k1 элементных множеств вершин.
[44:13.920 --> 44:24.040]  И мы каждое множество либо выбираем вот сюда, все множество, либо не выбираем. Понятно? Всем сейчас понятно?
[44:24.040 --> 44:37.320]  Отлично. Вот это случайное подмножество в множестве независимых множеств вершин случайного графа g.
[44:38.160 --> 44:45.360]  Простите меня за такой пафос, но это же мощно. Был случайный граф, в нем были случайные множества.
[44:45.360 --> 44:53.680]  А мы еще из них случайным образом часть выбрали, а часть похерили. Я настаиваю на этом слове.
[44:53.680 --> 44:59.720]  Ну, то есть, друзья, если вы хотите понять, как устроено вероятностное пространство в итоге, то устроено оно, конечно, очень просто.
[44:59.720 --> 45:06.840]  У вас есть граф, вероятность которого считается стандартным образом, как 1 поделить на 2 в степени c из m по 2.
[45:07.360 --> 45:14.360]  И к этому графу еще приляпан вот этот набор случайно выбранных из него независимых множеств.
[45:14.360 --> 45:20.360]  Взяли и некоторым образом случайно его как бы проредили, прорешиваем.
[45:22.360 --> 45:27.360]  То есть, вероятность такой пары, это вероятность графа умножить на вероятность вот этой штуки.
[45:27.360 --> 45:32.360]  А вероятность этой штуки, ну, это q в степени на 1 минус q в степени. Ну, стандартная, биномиальная.
[45:32.880 --> 45:36.880]  Так, понятно, как устроено пространство? То есть, мы добавили такой вот случайности.
[45:36.880 --> 45:42.880]  Добавили случайности. Так, сейчас будет еще один смешной момент с точки зрения обозначений.
[45:42.880 --> 45:50.880]  Вот, смотрите, здесь есть fmt от k, есть exk, есть его явная формула. Это уже три обозначения.
[45:52.880 --> 46:00.880]  Давайте, если сюда подставить вместо k k1, назовем то, что получится для максимальной краткости.
[46:01.400 --> 46:05.400]  Оно же вот такое еще получится, но это мы тоже пока не будем помнить.
[46:09.400 --> 46:13.400]  Это случайный набор множеств. Он случайный, да.
[46:13.400 --> 46:18.400]  Если мы граф зафиксировали, то c.adj тоже не фиксировано.
[46:18.400 --> 46:22.400]  k красивое adj фиксировано, а c.adj все равно случайно.
[46:22.400 --> 46:30.400]  И его вероятность это q в степени его мощность на 1 минус q в степени xkt первое adj минус его мощность.
[46:30.920 --> 46:34.920]  Для конкретного графа xkt первое adj это конкретное число.
[46:34.920 --> 46:38.920]  Поэтому вероятность вот этой штуки, вот этой штуки,
[46:38.920 --> 46:43.920]  это еще раз повторяю q в степени ее мощности, вот на конкретном графе,
[46:43.920 --> 46:50.920]  на 1 минус q в степени xkt первое adj минус ее мощность.
[46:50.920 --> 46:57.920]  Вот так. Ну давайте я напишу, чтобы точно это можно было воспроизвести, не на слух, а так вот в записи.
[46:58.440 --> 47:00.440]  То есть мы знаем кучу всего.
[47:00.440 --> 47:08.440]  Если мы сюда подставим k1, k1, k1, k1, то это три одинаковых числа и плюс они еще все не меньше, чем вот это.
[47:08.440 --> 47:15.440]  Это мы все знаем, но тем не менее я сейчас коротенько-коротенько все эти четыре штуки обозначу мю.
[47:15.440 --> 47:17.440]  Буквой мю.
[47:17.440 --> 47:19.440]  Можно?
[47:19.440 --> 47:21.440]  мю
[47:21.440 --> 47:23.440]  мю
[47:23.440 --> 47:25.440]  Так.
[47:25.960 --> 47:31.960]  Если я введу такое обозначение мю, ну я вот здесь напишу fm от k1,
[47:31.960 --> 47:33.960]  это будет мю.
[47:33.960 --> 47:35.960]  Ну мю просто так, определим.
[47:35.960 --> 47:38.960]  Там с вероятностью q не брали.
[47:38.960 --> 47:40.960]  Нет, с вероятностью q брали.
[47:40.960 --> 47:42.960]  А, ладно.
[47:42.960 --> 47:45.960]  А я неправильно сказал, да?
[47:45.960 --> 47:50.960]  А, я сказал с вероятностью q похериваем, а 1 минус q поксериваем.
[47:50.960 --> 47:52.960]  Ой, Господи.
[47:52.960 --> 47:54.960]  Ну извините, да, я, конечно, может быть, оговорился.
[47:54.960 --> 48:00.960]  Нет, это, может быть, мне так вот это q понравилось, что оно q, нет, q это вероятность успеха сейчас.
[48:00.960 --> 48:04.960]  Если считать успехом, все-таки не похерить, а поксерить.
[48:04.960 --> 48:11.960]  Да-да-да, q это вероятность того, что мы сохраняем жизнь каждому отдельно взятому независимому множеству.
[48:11.960 --> 48:13.960]  Сейчас, друзья, нормально, не запутал?
[48:13.960 --> 48:14.960]  Нормально.
[48:14.960 --> 48:17.960]  Ну вот хорошо, что я это написал, а то потом были бы разночтения.
[48:17.960 --> 48:23.960]  Ну, в общем, я ввожу четвертое обозначение для одного и того же, которое совсем коротенькое мю, но чем плохо.
[48:23.960 --> 48:25.960]  Ну, хочу ввести, ввожу.
[48:25.960 --> 48:27.960]  Мне так короче писать.
[48:27.960 --> 48:36.960]  Ну, смотрите, давайте обсудим, каково математическое ожидание мощности c.
[48:36.960 --> 48:39.960]  Это очень легко сказать.
[48:39.960 --> 48:44.960]  Это вопрос к аудитории, на которой есть надежда, что она сумеет ответить.
[48:47.960 --> 48:52.960]  Ну, я стараюсь последовательно рассказывать.
[48:52.960 --> 48:57.960]  Я вначале чуть-чуть запутался, но дальше-то я очень последовательно рассказываю.
[48:57.960 --> 49:01.960]  Ну, а мат ожидания x-то чему равно?
[49:01.960 --> 49:03.960]  Только что говорил?
[49:03.960 --> 49:04.960]  Мю.
[49:04.960 --> 49:06.960]  Ку-мю, правильно.
[49:06.960 --> 49:08.960]  Да, ответ ку-мю.
[49:08.960 --> 49:11.960]  Ку на мю, конечно.
[49:11.960 --> 49:13.960]  Ку на мю.
[49:14.960 --> 49:19.960]  Ку это вероятность успеха, а мю это математическое ожидание вот этой штуки.
[49:19.960 --> 49:23.960]  То есть мы как бы дважды усредняем.
[49:23.960 --> 49:26.960]  Вот тут используется линейность, товарищи.
[49:26.960 --> 49:29.960]  Вот тут используется линейность.
[49:29.960 --> 49:31.960]  Ку умножить на мю.
[49:31.960 --> 49:36.960]  Сейчас я виноват, введу еще два множества, но потерпите, они очень естественные.
[49:36.960 --> 49:39.960]  Значит, w будет зависеть просто от графа.
[49:39.960 --> 49:44.960]  И это будет множество таких пар.
[49:44.960 --> 49:48.960]  k-i-t, k-j-t.
[49:48.960 --> 49:51.960]  Видите, они прямые, это прямые k-i-t.
[49:51.960 --> 49:54.960]  То есть они относятся под множеством мощности k1.
[49:54.960 --> 49:58.960]  Такие, что...
[49:58.960 --> 50:01.960]  Давайте только пары будем считать неупорядочными.
[50:01.960 --> 50:03.960]  Вот так их напишем.
[50:03.960 --> 50:05.960]  Неважно, в каком порядке их взять.
[50:05.960 --> 50:07.960]  k-i-t, k-j-t.
[50:07.960 --> 50:15.960]  Такие, что k-i-t, k-j-t принадлежит k красивому от g.
[50:15.960 --> 50:23.960]  И k-i-t, пересеченная с k-j-t, имеет мощность больше либо равную двойке.
[50:23.960 --> 50:27.960]  Вот количество таких пар возьмем в графе g.
[50:29.960 --> 50:31.960]  Что это за пары, товарищи?
[50:31.960 --> 50:34.960]  Вот я специально не стирал y-k-t первое.
[50:34.960 --> 50:40.960]  Это пары, которых не должно быть в цепочке максимальную длину,
[50:40.960 --> 50:42.960]  которой дает нам y.
[50:42.960 --> 50:44.960]  Их не должно быть.
[50:44.960 --> 50:47.960]  Пары должны пересекаться тут не больше, чем по одному элементу.
[50:47.960 --> 50:50.960]  При этом мы говорим о парах как раз k1 вершинных множеств,
[50:50.960 --> 50:53.960]  каждая из которых независима.
[50:53.960 --> 50:56.960]  Здесь мы говорим тоже о парах k1 вершинных множеств,
[50:56.960 --> 50:58.960]  каждая из которых независима.
[50:58.960 --> 51:00.960]  Но при этом говорим о плохих парах.
[51:00.960 --> 51:02.960]  То есть их бы изничтожить.
[51:04.960 --> 51:06.960]  Понятно сказал, что такое w от g.
[51:06.960 --> 51:08.960]  Это множество вредных пар.
[51:08.960 --> 51:13.960]  Тех пар, которые не должны встречаться в определении y.
[51:13.960 --> 51:19.960]  И точно также введем w штрих от g запятая c от g.
[51:19.960 --> 51:21.960]  То есть на том вероятностном пространстве,
[51:21.960 --> 51:25.960]  в котором появилась дополнительная случайность с прореживанием.
[51:26.960 --> 51:28.960]  Абсолютно все то же самое.
[51:28.960 --> 51:30.960]  Вот просто 1 в 1.
[51:30.960 --> 51:33.960]  Только вот здесь вот c от g.
[51:33.960 --> 51:36.960]  А дальше опять все то же самое.
[51:36.960 --> 51:38.960]  То есть это снова множество вредных пар,
[51:38.960 --> 51:43.960]  но уже попадающих обоими своими множествами в прорежанное c от g.
[51:43.960 --> 51:45.960]  Прорежанную совокупность.
[51:48.960 --> 51:49.960]  Услеживаете?
[51:49.960 --> 51:52.960]  В самом графе было много независимых множеств.
[51:52.960 --> 51:57.960]  Какие-то из них образовывали пары, имеющие неподобающие пересечения.
[51:57.960 --> 52:01.960]  Эти пары не могут встречаться в цепочках, которые нас интересуют.
[52:01.960 --> 52:04.960]  Но мы затем не только взяли граф,
[52:04.960 --> 52:10.960]  а еще проредили, зачем-то вот так искусственно, проредили его множество независимых подмножеств.
[52:10.960 --> 52:12.960]  И теперь мы смотрим на количество вредных пар,
[52:12.960 --> 52:17.960]  только таких, у которых каждая каитая, кожитая попадает вот в эти прореженные.
[52:17.960 --> 52:21.960]  Но формально я все написал, и смысл, надеюсь, уже понятен.
[52:21.960 --> 52:24.960]  Вот надо от этих избавиться.
[52:24.960 --> 52:27.960]  Тогда мы будем иметь какую-то оценку у.
[52:27.960 --> 52:36.960]  Так, давайте я введу обозначение для математического ожидания мощности w.
[52:36.960 --> 52:39.960]  Обозначение будет вот такое.
[52:39.960 --> 52:43.960]  Дельта пополам.
[52:44.960 --> 52:48.960]  Более идиотского обозначения не придумать, конечно,
[52:48.960 --> 52:50.960]  но я поясню, в чем смысл несколько позже.
[52:50.960 --> 52:58.960]  Пополам, потому что я в качестве дельта буду брать как раз мат ожидания для случая упорядоченных пар.
[52:58.960 --> 53:01.960]  То есть у меня в w неупорядоченные пары,
[53:01.960 --> 53:05.960]  но дельта это будет мат ожидания в случае, когда здесь были круглые скобки,
[53:05.960 --> 53:08.960]  то есть пары были кортежами, упорядоченными парами.
[53:08.960 --> 53:13.960]  Ну, естественно, такое дельта от искомого мат ожидания отличается в два раза.
[53:13.960 --> 53:16.960]  Это, я надеюсь, понятно?
[53:18.960 --> 53:21.960]  Что если фигурные скобки здесь заменить на круглые,
[53:21.960 --> 53:24.960]  то новое мат ожидания отличается от искомого в два раза.
[53:24.960 --> 53:29.960]  Вот это новое я обозначу дельта, но разделю пополам, чтобы получить то, которое нас интересует.
[53:29.960 --> 53:32.960]  Теперь, друзья, хватит занудствовать.
[53:32.960 --> 53:36.960]  Ну-ка, скажите мне, что такое мат ожидания мощности w штрих?
[53:41.960 --> 53:47.960]  Дельта на два, q, но это близко к правильному, но неправильному.
[53:47.960 --> 54:03.960]  Мю обозначение, да, мю, что за мю?
[54:03.960 --> 54:08.960]  Нет, тут вот дельта, правильно, что дельта на два участвует, это правильно,
[54:08.960 --> 54:12.960]  но только не на q, а на q квадрат, конечно.
[54:12.960 --> 54:18.960]  Мы же интересуемся парами, и оба элемента пары должны попасть в c.
[54:18.960 --> 54:22.960]  Вероятность того, что k и t попадают в c, это q.
[54:22.960 --> 54:26.960]  Вероятность того, что k и jt попадают в c, это q.
[54:26.960 --> 54:30.960]  А что они обе попадают в c, это q квадрат.
[54:31.960 --> 54:37.960]  Согласитесь, что мат ожидания w, в котором нас интересуют все независимые множества графа,
[54:37.960 --> 54:41.960]  отличается от мат ожидания w штрих ровно в q квадрат раз.
[54:41.960 --> 54:45.960]  Просто вероятность того, что эти товарищи и сюда тоже попали.
[54:45.960 --> 54:48.960]  Это опять линейность.
[54:48.960 --> 54:52.960]  Ну, что такое дельта, я пока не знаю.
[54:52.960 --> 54:58.960]  Сейчас, где бы мне стереть, даже уже и не знаю.
[54:58.960 --> 55:04.960]  Ха-ха, где же мне стереть?
[55:05.960 --> 55:09.960]  Ну, вот здесь, наверное, могу стереть, мне кажется, это понятно.
[55:09.960 --> 55:11.960]  Это уже понятно.
[55:14.960 --> 55:17.960]  Ничего-ничего, почти победа.
[55:17.960 --> 55:20.960]  Ну, не совсем, конечно, но почти.
[55:20.960 --> 55:24.960]  Так, давайте знаете, что сделаем.
[55:24.960 --> 55:32.960]  Давайте, вот у нас есть c от g, а от него возьмем, это последнее будет действие,
[55:32.960 --> 55:36.960]  не переживайте, и перейдем к c со звездочкой от g.
[55:36.960 --> 55:40.960]  Сейчас скажу, по какому принципу, очень естественному.
[55:40.960 --> 55:48.960]  Мы просто вот в этом множестве c от g найдем все пары, которые принадлежат множеству w штрих.
[55:50.960 --> 55:58.960]  Так, смотрите на w штрих, это множество тех пар из c от g, которые пересекаются не так, как хотелось бы.
[55:58.960 --> 56:06.960]  Вот возьмем все пары из этого w штрих, и у каждой выдернем по херям.
[56:06.960 --> 56:08.960]  Один элемент.
[56:08.960 --> 56:15.960]  Из каждой неупорядоченной пары, оба элемента, которые попали в c от g,
[56:15.960 --> 56:22.960]  один, не важно какой, каитая, кожитая, она же неупорядоченная, по херям, удалим из c от g.
[56:22.960 --> 56:30.960]  Ну может так случиться, что убивая какие-то две разных пары, мы кокнем только одно каитое.
[56:30.960 --> 56:33.960]  Ну и слава богу, значит мы еще быстрее все расколкаем.
[56:33.960 --> 56:44.960]  Короче, вот это вот c со звездочкой от g получается из множества c от g путем удаления по одному элементу из каждой пары, принадлежащей w штрих.
[56:44.960 --> 56:54.960]  У нас такая идея уже случалась, как минимум один раз, когда мы доказывали теорему Эрдерша про обхват.
[56:54.960 --> 56:57.960]  Когда мы там разрушали что-то лишнее.
[56:57.960 --> 57:00.960]  Ну вот здесь тоже разрушаем вредные пары.
[57:00.960 --> 57:09.960]  Слушайте, ну согласитесь, что yкт первое от g больше не поравняется, чем мощность c со звездочкой от g.
[57:14.960 --> 57:17.960]  Так, yкт первое я не стер.
[57:17.960 --> 57:26.960]  Это максимальное количество k1 элементных подмножеств, пересечение которых по парной имеют мощность не больше чем единица, и все они независимы.
[57:26.960 --> 57:29.960]  Но c со звездочкой ведь так и строилось.
[57:29.960 --> 57:41.960]  Оно строилось из совокупности независимых множеств, после чего эта независимая совокупность прореживалась, удалялись элементы из каждой вредной пары, из каждой пары, в которой пересечение большое.
[57:41.960 --> 57:46.960]  Друзья, точно успеваете за мыслью?
[57:46.960 --> 57:53.960]  То есть, конечно, мы не знаем, где yкт первое достигается, но мы точно знаем, что это нижняя оценка.
[57:53.960 --> 57:59.960]  Мы предъявили некоторую вероятностную процедуру, которая позволяет эту оценку получить.
[57:59.960 --> 58:08.960]  Ну то есть, математическое ожидание, которое нас интересует, больше либо равняется математическому ожиданию,
[58:09.960 --> 58:23.960]  которое в свою очередь больше либо равняется, нежели математическое ожидание c мощности c, минус математическое ожидание мощности w штрих по линейности.
[58:23.960 --> 58:34.960]  Именно больше либо равняется, потому что, как я уже говорил, в c со звездочкой может получиться и больше элементов, чем если из c вычитать w,
[58:34.960 --> 58:40.960]  потому что одно и то же множество может разорвать сразу несколько вредных пар.
[58:40.960 --> 58:46.960]  Поэтому здесь больше либо равно. Согласны?
[58:46.960 --> 58:49.960]  Ну, это нас устраивает, только хорошо.
[58:49.960 --> 58:52.960]  Так, это равно miu на ku.
[58:56.960 --> 59:01.960]  Да-да-да, без мат ожидания тоже верно, надо было так и написать.
[59:01.960 --> 59:02.960]  Да-да-да.
[59:02.960 --> 59:07.960]  Так, miu на ku минус дельта ku квадрат пополам.
[59:09.960 --> 59:10.960]  Верно?
[59:13.960 --> 59:15.960]  Не, ну вроде все пока хорошо.
[59:17.960 --> 59:19.960]  Слушайте, а что такое ku?
[59:19.960 --> 59:24.960]  Ну это какое-то число, вот мы взяли какое-то число, мы же его никак не конкретизировали, правда?
[59:24.960 --> 59:28.960]  То есть его выбор в каком-то смысле, это в нашей власти?
[59:29.960 --> 59:36.960]  Ну какая оценка будет самой лучшей, если тут по ku, извините, парабола вот такого вида?
[59:36.960 --> 59:38.960]  В вершине параболы, правильно?
[59:38.960 --> 59:44.960]  То есть ku надо по-хорошему выбрать так, чтобы вот эта разность достигала своему максимума.
[59:45.960 --> 59:47.960]  Miu делить на дельта, правильно?
[59:47.960 --> 59:53.960]  В качестве ku надо взять, вот здесь давайте возьмем, miu делить на дельта.
[59:54.960 --> 59:59.960]  Тогда что у нас тут получится, если подставить вместо ku miu делить на дельта?
[59:59.960 --> 01:00:01.960]  Miu квадрат на 2 дельта, правильно?
[01:00:03.960 --> 01:00:05.960]  Miu квадрат на 2 дельта.
[01:00:06.960 --> 01:00:07.960]  Шикарно.
[01:00:07.960 --> 01:00:09.960]  А наша цель доказать?
[01:00:09.960 --> 01:00:12.960]  Вот такое вот неравенство, дорогие товарищи.
[01:00:15.960 --> 01:00:16.960]  Такое?
[01:00:20.960 --> 01:00:22.960]  Да, вот надо сейчас сопоставить.
[01:00:22.960 --> 01:00:25.960]  Сейчас надо догадаться, чему равняется miu.
[01:00:25.960 --> 01:00:27.960]  Нет, чему равняется miu мы знаем.
[01:00:27.960 --> 01:00:29.960]  Miu вот оно.
[01:00:30.960 --> 01:00:32.960]  Сейчас наконец вот это ружье непонятное.
[01:00:32.960 --> 01:00:38.960]  Помните, мы в прошлый раз долго дискутировали, откуда там эта третья степень, как она там растет в ме примерно раз.
[01:00:38.960 --> 01:00:40.960]  Ну разобрались в конце концов.
[01:00:41.960 --> 01:00:43.960]  Вот это сейчас ружье как раз выстрелит.
[01:00:44.960 --> 01:00:48.960]  Сейчас это знание о том, чему равняется miu нам очень сильно поможет.
[01:00:49.960 --> 01:00:50.960]  Так.
[01:00:53.960 --> 01:00:55.960]  Но что я хочу сказать?
[01:00:55.960 --> 01:01:03.960]  Я-то хочу, чтобы это равнялось, ну или асимпатически равнялось miu в квадрате на 2 к1 в четвертой,
[01:01:03.960 --> 01:01:06.960]  ну а асимпатически это значит тут 1 плюс о малой от единицы.
[01:01:06.960 --> 01:01:08.960]  Это я хочу.
[01:01:08.960 --> 01:01:10.960]  Значит, чего такое отсюда дельта?
[01:01:10.960 --> 01:01:16.960]  Давайте сообразим, какое отсюда дельта получается, если мы хотим, чтобы получилось такое равенство.
[01:01:17.960 --> 01:01:20.960]  Ну вернее, надо вот так писать, конечно, извините.
[01:01:20.960 --> 01:01:23.960]  Дельта равно чему-то, следовательно, это равно.
[01:01:24.960 --> 01:01:26.960]  Чему равно дельта?
[01:01:28.960 --> 01:01:30.960]  Почему м в четвертой?
[01:01:30.960 --> 01:01:32.960]  Нет, давайте в терминах miu, да?
[01:01:33.960 --> 01:01:38.960]  Ну, наверное, miu в квадрат, чтобы miu в квадрат сократилось.
[01:01:38.960 --> 01:01:43.960]  Наверное, пополам не надо, потому что двойки там общие, они сократятся.
[01:01:45.960 --> 01:01:46.960]  Да?
[01:01:46.960 --> 01:01:47.960]  Miu в квадрат.
[01:01:47.960 --> 01:01:49.960]  И на что-то надо поделить.
[01:01:49.960 --> 01:01:53.960]  Надо поделить на m в квадрате, да?
[01:01:56.960 --> 01:01:59.960]  И умножить на k1 в четвертой.
[01:01:59.960 --> 01:02:00.960]  Плохо.
[01:02:00.960 --> 01:02:03.960]  Ну тут вот напишу k1 в четвертой.
[01:02:03.960 --> 01:02:04.960]  Вот так.
[01:02:05.960 --> 01:02:06.960]  Видно?
[01:02:11.960 --> 01:02:14.960]  Ну k1 в четвертой на miu в квадрат на m в квадрате, да?
[01:02:14.960 --> 01:02:17.960]  Так, согласны, что если я сюда вместо дельта...
[01:02:17.960 --> 01:02:19.960]  Ну, а я вот сейчас сотру это и тильно напишу.
[01:02:19.960 --> 01:02:21.960]  Тогда будет совсем правильно.
[01:02:21.960 --> 01:02:25.960]  Если я вместо дельта подставлю асимпатическую вот такую штуковину,
[01:02:25.960 --> 01:02:27.960]  то miu в квадрат у меня сократится,
[01:02:27.960 --> 01:02:30.960]  m в квадрат прыгнет наверх, двойка останется,
[01:02:30.960 --> 01:02:32.960]  а k1 в четвертой прыгнет вниз.
[01:02:32.960 --> 01:02:33.960]  Ну, вроде все хорошо.
[01:02:34.960 --> 01:02:36.960]  Значит, дельта должно быть вот таким.
[01:02:37.960 --> 01:02:38.960]  Так.
[01:02:39.960 --> 01:02:41.960]  Охреново знает, почему оно такое покажет.
[01:02:41.960 --> 01:02:44.960]  Ну, должно же быть таким, иначе ничего не получится.
[01:02:44.960 --> 01:02:45.960]  Правда, товарищи?
[01:02:46.960 --> 01:02:48.960]  Должно быть таким.
[01:02:48.960 --> 01:02:49.960]  Значит, будет.
[01:02:50.960 --> 01:02:51.960]  Ну, значит, будет.
[01:02:51.960 --> 01:02:55.960]  Сейчас, друзья, сейчас будет микрокатарсис или макро.
[01:02:55.960 --> 01:02:56.960]  Я уж не знаю.
[01:02:56.960 --> 01:02:58.960]  Сейчас смотрите, какая чудесная вещь сейчас произойдет.
[01:02:58.960 --> 01:02:59.960]  Смотрите.
[01:03:00.960 --> 01:03:01.960]  Смотрите.
[01:03:01.960 --> 01:03:03.960]  Значит, мы выяснили, что дельта обязана таким быть.
[01:03:03.960 --> 01:03:05.960]  Нам это, видимо, предстоит объяснить каким-то образом,
[01:03:05.960 --> 01:03:07.960]  но, видимо, уже не сейчас.
[01:03:07.960 --> 01:03:10.960]  А что будет катарсисом?
[01:03:10.960 --> 01:03:11.960]  Вы смотрите.
[01:03:11.960 --> 01:03:14.960]  Мы куположили равным mu поделить на дельта.
[01:03:14.960 --> 01:03:16.960]  А мы вообще имели право так сделать?
[01:03:19.960 --> 01:03:20.960]  Нет.
[01:03:20.960 --> 01:03:21.960]  Не в том дело.
[01:03:21.960 --> 01:03:25.960]  Дело в том, что эта вероятность, она должна быть меньше единицы.
[01:03:26.960 --> 01:03:30.960]  Вам не кажется, что если это больше единицы, то все, что мы делаем, это хрень?
[01:03:32.960 --> 01:03:33.960]  Вот, дайте посмотрим.
[01:03:33.960 --> 01:03:35.960]  Значит, дельта обязана быть таким.
[01:03:35.960 --> 01:03:40.960]  Поэтому mu, поделенная на дельта, асимпатически ведет себя следующим образом.
[01:03:40.960 --> 01:03:43.960]  Это mu m в квадрате дважды...
[01:03:43.960 --> 01:03:45.960]  А, как куда дважды? Двойки нет.
[01:03:45.960 --> 01:03:53.960]  mu m в квадрате просто поделить на k1 в четвертый mu квадрат.
[01:03:53.960 --> 01:03:54.960]  Согласны?
[01:03:56.960 --> 01:03:57.960]  Чего?
[01:03:57.960 --> 01:03:59.960]  Вот оно отправилось вниз, да.
[01:03:59.960 --> 01:04:01.960]  Вот k1 в четвертый mu квадрат отправилось вниз,
[01:04:01.960 --> 01:04:04.960]  а вверх прыгнуло m в квадрате, ну и mu осталось.
[01:04:05.960 --> 01:04:07.960]  Сейчас, друзья, видно, нет?
[01:04:10.960 --> 01:04:16.960]  Это равно m в квадрате поделить на k1 в четвертый mu.
[01:04:17.960 --> 01:04:22.960]  И вот теперь мы вспоминаем, что mu не меньше, чем m в кубе.
[01:04:23.960 --> 01:04:26.960]  С точностью до какой-то там логарифмической фигни.
[01:04:26.960 --> 01:04:38.960]  То есть это все не больше, чем m в квадрате поделить на k1 в четвертый на m в степени 3 плюс о малой от единицы.
[01:04:38.960 --> 01:04:44.960]  А это равно 1 поделить на m в степени 1 плюс о малой от единицы.
[01:04:44.960 --> 01:04:48.960]  И это, конечно, не только меньше единицы, но даже стремится к нулю.
[01:04:48.960 --> 01:04:53.960]  Ну, мы считаем, что mu достаточно большое, чтобы это стало меньше единицы.
[01:04:53.960 --> 01:04:54.960]  Это не равно?
[01:04:54.960 --> 01:04:55.960]  Нет, равно.
[01:04:55.960 --> 01:05:01.960]  Потому что я k1 в четвертый вот в эту малую от единицы загнал, поменяв его там немножечко.
[01:05:02.960 --> 01:05:06.960]  Друзья, я объяснил, зачем мы мучились-то с выбором параметра.
[01:05:06.960 --> 01:05:09.960]  Зачем нам нужно было это не сейчас на m в кубе.
[01:05:10.960 --> 01:05:13.960]  Вот сейчас это наконец выстрелило.
[01:05:13.960 --> 01:05:15.960]  Ну слушайте, ну это круто.
[01:05:15.960 --> 01:05:20.960]  Чтобы вот это вероятностью было, надо чтобы такая штучка росла хотя бы как m в кубе.
[01:05:20.960 --> 01:05:22.960]  Ну можно m в десятый, это неважно.
[01:05:22.960 --> 01:05:25.960]  Но я для красоты вот прям так впритык подобрал.
[01:05:28.960 --> 01:05:31.960]  Еще раз, k1 в четвертый – это логарифм в четвертой степени.
[01:05:31.960 --> 01:05:35.960]  Я его вот сюда загнал, как в известном ролике.
[01:05:35.960 --> 01:05:37.960]  Ну извините, он сюда прыгает.
[01:05:40.960 --> 01:05:42.960]  Ну так вот, надо к этому привыкнуть.
[01:05:42.960 --> 01:05:45.960]  Логарифм – это m в степени о малой от единицы.
[01:05:45.960 --> 01:05:50.960]  m в степени сумма двух о малых от единицы – это тоже m в степени о малой от единицы.
[01:05:50.960 --> 01:05:53.960]  То есть вот это о малой и вот это о малой – они разные.
[01:05:53.960 --> 01:05:55.960]  Ну какая разница, все равно все хорошо.
[01:05:56.960 --> 01:06:00.960]  Значит, нам осталось теперь доказать, что дельта вот такая.
[01:06:01.960 --> 01:06:04.960]  Ну это уже дел техники, только времени не хватает, по-моему.
[01:06:05.960 --> 01:06:08.960]  Я сейчас напишу, что нам осталось сделать.
[01:06:08.960 --> 01:06:11.960]  И в следующий раз мы быстро с этим расправимся.
[01:06:11.960 --> 01:06:14.960]  Потому что совсем точную выкладку я писать не буду.
[01:06:14.960 --> 01:06:15.960]  Это скучно.
[01:06:16.960 --> 01:06:21.960]  На самом деле дельта, оно так вот, в принципе, естественным образом обозначено.
[01:06:21.960 --> 01:06:23.960]  Это в каком-то смысле дисперсия.
[01:06:23.960 --> 01:06:26.960]  Потому что мы считаем количество пар каких-то объектов.
[01:06:26.960 --> 01:06:30.960]  А пары объектов – это всегда дисперсия или второй момент.
[01:06:32.960 --> 01:06:33.960]  Это кавариация.
[01:06:33.960 --> 01:06:35.960]  Ну кавариация, да-да, как хотите.
[01:06:35.960 --> 01:06:39.960]  В общем, е от мощности w.
[01:06:39.960 --> 01:06:45.960]  Ну, это действительно одна вторая.
[01:06:45.960 --> 01:06:47.960]  Как считать?
[01:06:47.960 --> 01:06:49.960]  Математическое ожидание числа пар.
[01:06:49.960 --> 01:06:51.960]  Ну просто по линейности.
[01:06:51.960 --> 01:06:53.960]  То есть надо перебрать все пары.
[01:06:53.960 --> 01:06:57.960]  Оно уже тут не сохранилось, но вот здесь было перечисано все.
[01:06:57.960 --> 01:07:00.960]  k1 и так далее, kcsm по k1.
[01:07:01.960 --> 01:07:03.960]  Надо перебрать все-все-все пары.
[01:07:04.960 --> 01:07:07.960]  Но только такие, которые имеют вот это пересечение.
[01:07:07.960 --> 01:07:12.960]  И для каждой пары посчитать вероятность того, что она состоит из независимых множеств.
[01:07:13.960 --> 01:07:14.960]  Давайте я напишу.
[01:07:14.960 --> 01:07:17.960]  Это я успею написать, прокомментировать.
[01:07:17.960 --> 01:07:24.960]  Смотрите, мы буковкой t теперь обозначим не то, что здесь обозначено, а размер пересечения.
[01:07:24.960 --> 01:07:27.960]  Ну, естественно, он не больше, чем k1-1.
[01:07:27.960 --> 01:07:29.960]  То есть давайте я сразу картину нарисую.
[01:07:29.960 --> 01:07:30.960]  Вот мы вершин.
[01:07:30.960 --> 01:07:41.960]  Мы выбираем одно множество мощности k1 и выбираем второе множество мощности k1 так, чтобы вот здесь было t общих элементов.
[01:07:41.960 --> 01:07:43.960]  И t должно быть не меньше двойки.
[01:07:43.960 --> 01:07:46.960]  Вот мы зафиксировали сначала само t.
[01:07:47.960 --> 01:07:53.960]  Дальше мы выбираем из m k1-вершин для первого множества.
[01:07:53.960 --> 01:07:59.960]  Потом из этих k1-вершин мы выбираем t-вершин, которые окажутся общими.
[01:08:02.960 --> 01:08:07.960]  И, наконец, после того как эта общая часть двух сардельчик зафиксирована,
[01:08:07.960 --> 01:08:15.960]  оставшуюся часть второй сардельки, естественно, выбираем вот здесь на множестве из m, минус k1-вершин.
[01:08:15.960 --> 01:08:18.960]  Но выбрать нам остается k1-t-вершин.
[01:08:19.960 --> 01:08:27.960]  Вот произведение трех таких цешек это способ фиксации какой-то пары с имеющей t общих элементов.
[01:08:27.960 --> 01:08:31.960]  И теперь надо умножить это, ну как по линейности считают в мат ожидания,
[01:08:31.960 --> 01:08:36.960]  на вероятность того, что и тут нет ни одного ребра, и тут нет ни одного ребра.
[01:08:36.960 --> 01:08:39.960]  Что оба этих множества независимы.
[01:08:40.960 --> 01:08:49.960]  Эта вероятность, это одна вторая в степени дважды csk1 по 2, минус cst по 2.
[01:08:52.960 --> 01:08:57.960]  Ну, мы складываем, сколько есть ребер тут, которые должны отсутствовать, сколько есть ребер тут.
[01:08:57.960 --> 01:09:01.960]  И, естественно, мы посчитали лишний раз те ребра, которые находятся целиком в пересечении.
[01:09:02.960 --> 01:09:04.960]  Вот я их вычел.
[01:09:04.960 --> 01:09:06.960]  Ну, следили?
[01:09:07.960 --> 01:09:11.960]  Значит, смотрите, я сейчас не успеваю ни с комков нормально рассказать.
[01:09:11.960 --> 01:09:24.960]  На следующей лекции, за первые 10 минут буквально, я расскажу, почему при t равном 2 мы получаем ровно ту самую асимптотику, которую ожидаем.
[01:09:24.960 --> 01:09:28.960]  Вот эту. Она будет уже при t равном 2.
[01:09:28.960 --> 01:09:31.960]  Она будет уже при t равном 2.
[01:09:31.960 --> 01:09:36.960]  А дальше я с вашего позволения скажу без доказательства, потому что скучный анализ.
[01:09:36.960 --> 01:09:42.960]  Я не хочу вас перегружать анализом, я хочу, чтобы вы усваивали идеи.
[01:09:42.960 --> 01:09:49.960]  Скучный анализ показывает, что все остальные слагаемые до какого-то момента сильно меньше,
[01:09:49.960 --> 01:09:56.960]  поэтому сумму можно оценить главным членом асимптотику, которого мы нашли, вот тем, который при t равном 2.
[01:09:56.960 --> 01:10:01.960]  Умноженным там на сумму какой-то бесконечной убывающей геометрической прогрессии.
[01:10:01.960 --> 01:10:06.960]  Настолько хорошо все последующие члены оцениваются по отношению к предыдущему,
[01:10:06.960 --> 01:10:11.960]  что там получается убывающая геометрическая прогрессия, которая на асимптотику не влияет.
[01:10:11.960 --> 01:10:17.960]  Но это до какого-то момента. Потом наступает перегиб, и там снова эти штуки начинают расти.
[01:10:17.960 --> 01:10:24.960]  Но если посчитать правый конец, вот эту верхнюю границу суммирования, там все-таки будет сильно меньше, чем при t равном 2.
[01:10:24.960 --> 01:10:30.960]  В общем, вот эта хрень могла бы занять всю следующую лекцию. Естественно, я это делать не собираюсь.
[01:10:30.960 --> 01:10:35.960]  Я посчитаю только t равно 2, а про остальное оставлю без доказательств.
[01:10:39.960 --> 01:10:47.960]  Ну, я тоже так думаю. Тут идей нет. Главное, чтобы вы понимали, что при t равном 2 максимум, дальше оно настолько маленькое,
[01:10:47.960 --> 01:10:52.960]  что все доминируется строго этим t равном 2. И все это считать никто на экзамене, конечно, не потребует.
[01:10:52.960 --> 01:11:01.960]  Это маразм, это неинтересно. Но главное, чтобы вся суть происходящего понятна. Все на сегодня. Спасибо.
