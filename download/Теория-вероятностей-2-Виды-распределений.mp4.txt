[00:00.000 --> 00:13.800]  Так, ну, на чем мы в прошлый раз остановились? Значит, ага, да, точно.
[00:13.800 --> 00:26.000]  Такое, значит, функция распределения, мы с вами определили, что такое функция распределения,
[00:26.000 --> 00:31.000]  и выяснили, что она однозначно задает распределение. Вот, давайте поговорим про ее свойства.
[00:31.000 --> 00:46.720]  Дверь потом закройте, чтобы потише было, спасибо. Которые, ну, необходимые достаточные, да,
[00:46.720 --> 00:49.480]  то есть эти свойства, с одной стороны, свойства функции распределения, с другой стороны,
[00:49.480 --> 00:54.200]  если есть функция с такими свойствами, то она будет функцией распределения для некоторого
[00:54.200 --> 00:59.680]  распределения вероятности. Значит, что это за свойства такие? Ну, они, вообще говоря,
[00:59.680 --> 01:06.760]  практически очевидные, но дают некоторое наглядное представление о том, как выглядит
[01:06.760 --> 01:18.120]  функция распределения. Значит, во-первых, она не убывает, во-вторых, она непрерывна справа,
[01:18.120 --> 01:36.360]  и, в-третьих, предел в минус бесконечности равен нулю, а в плюс бесконечности единице.
[01:36.360 --> 01:54.840]  Вот, давайте докажем, что действительно так сперва. Ну, неубывание понятно, да, это следует
[01:54.840 --> 02:00.640]  из свойства вероятности, заключается в том, что если есть два множества, одно в другом содержится,
[02:00.640 --> 02:06.040]  то вероятность первого не превосходит вероятности второго. И это как раз к нам относится, потому что
[02:06.040 --> 02:16.840]  если мы возьмем два действительных числа х меньше чем у и посмотрим на f от у и на f от x,
[02:16.840 --> 02:27.480]  то мы увидим, что f от у это есть вероятность интервала от минус бесконечности до у. Но в силу
[02:27.480 --> 02:31.560]  того, что этот луч, он содержит в себе луч от минус бесконечности до х, то эта вероятность
[02:31.560 --> 02:37.720]  больше чем равна, чем вероятность интервала от минус бесконечности до х, что есть f от х.
[02:37.720 --> 02:48.240]  Да, то действительно мы получаем неубывание. Во-вторых, непрерывность справа. Ну, все предельные
[02:48.240 --> 02:56.600]  свойства следует из непрерывности вероятности. Да, вы знаете, что если вы будете рассматривать
[02:56.600 --> 03:02.360]  последовательность вложенных множеств и возьмете их пересечение, то вероятность этого пересечения
[03:02.360 --> 03:06.280]  будет равным пределам вероятности. Это, в общем-то, и есть все вот эти вот и второе и третье свойства.
[03:06.280 --> 03:12.560]  Ну почему так? Давайте непрерывность справа сперва. Смотрите, у нас функция не убывает,
[03:12.560 --> 03:16.640]  поэтому нам достаточно взять любую последовательность. То есть я могу взять какую-то
[03:16.640 --> 03:23.680]  последовательность xn, которая стремится к x справа, но я даже могу на самом деле взять ее вообще
[03:23.680 --> 03:34.960]  не возрастающей. Да, то есть вот так вот я могу нарисовать, имея в виду, что вот эта последовательность
[03:34.960 --> 03:41.720]  убывает. Убывает и стремится к x. То есть каждый следующий член, он меньше, чем предыдущий. Почему
[03:41.720 --> 03:45.440]  достаточно такие последовательности рассматривать? То есть я сейчас хочу перейти к пределу. Да,
[03:45.440 --> 03:51.040]  конечно, предел функции в точке xn равен значениям функции в точке x. Почему этого достаточно?
[03:51.040 --> 03:54.360]  Потому что функции не убывают. Дальше, если я буду брать любую-другую последовательность,
[03:54.360 --> 03:58.240]  то в силу монотонности функции у меня будет тот же самый предел.
[03:58.240 --> 04:15.880]  Придел предыдущей мячности бесконечности f от xn. По определению, это есть предел вероятности.
[04:15.880 --> 04:29.080]  Придел такой вероятности. И так у меня xn убывает, вот эти все, вот эти все лучи,
[04:29.080 --> 04:33.800]  они вложены. Да, каждый следующий он меньше, чем предыдущий. И по непрерывности я могу перейти
[04:33.800 --> 04:45.240]  к пределу и написать, что это есть вероятность пересечения всех этих лучей. То есть,
[04:45.240 --> 04:59.160]  собственно, вероятность луча от бесконечности до x. Что есть f от x, что и требовалось. Понятно,
[04:59.160 --> 05:03.320]  что такой же трюк с непрерывности слева не пройдет, потому что если вы возьмете,
[05:03.320 --> 05:08.840]  наоборот, возрастающую последовательность и перейдете здесь к пределу,
[05:08.840 --> 05:14.040]  у вас получится перейти к пределу, нет проблем, только будет вероятность объединения. У вас будет
[05:14.040 --> 05:19.960]  лучи увеличиваться, и вы говорите, что тогда предел вероятности, это есть вероятность объединения.
[05:19.960 --> 05:26.960]  Но вероятность объединения лучей вот этих вот замкнутых, это будет открытый интервал, то есть
[05:26.960 --> 05:37.640]  точка x не будет включаться. То есть предел вероятности вот здесь будет равен вероятности
[05:37.640 --> 05:44.400]  от бесконечности до x, не включая x. И если в точке x вероятность не нулевая, то это не будет равно f
[05:44.400 --> 05:51.200]  от x, это будет строго меньше, чем f от x. Поэтому, в принципе, разрывы в каких-то точках могут быть.
[05:51.200 --> 05:54.800]  Но мы об этом сегодня подробно еще поговорим про разрывы. Давайте третий пункт.
[05:54.800 --> 06:09.120]  Ну, в принципе, аналогично. Например, чтобы доказать вот эту штуку, опять же, в силу монотонности f,
[06:09.120 --> 06:13.360]  достаточно просто рассмотреть любую убывающую последовательность. То есть если я рассмотрю
[06:13.360 --> 06:18.600]  последовательность, которая стремится к минус бесконечности и убывает, то по аналогичным
[06:18.600 --> 06:29.280]  соображениям я получаю, что предел функции распления точке xn, это есть вероятность пересечения
[06:29.280 --> 06:41.720]  всех этих лучей, это есть 0, это вероятность пустого множества. Они не пересекаются,
[06:41.720 --> 06:47.520]  они вложены, но пересечение пустое множество. И то же самое с плюс бесконечности. Теперь,
[06:47.600 --> 06:59.160]  если я рассмотрю возрастающую последовательность, то предел функции распления в точке xn, это есть
[06:59.160 --> 07:08.760]  теперь вероятность объединения всех таких интервалов, а это вероятность всего r. То есть мы все такие
[07:08.760 --> 07:16.440]  лучи объединим, мы получим все эти стыдные числа, и вероятность равна единице. Собственно,
[07:16.440 --> 07:25.160]  все. Очевидные свойства, но вот несмотря на их очевидность, они являются важными, потому что они
[07:25.160 --> 07:29.800]  говорят о том, что если мы возьмем произвольную функцию с такими свойствами, то она будет
[07:29.800 --> 07:34.160]  функцией распления для некоторого распления вероятностей. Давайте это запишем.
[07:34.160 --> 07:43.640]  Если у нас есть какая-то функция f, при этом можно сказать, что она пусть из r в r действует,
[07:43.640 --> 07:49.160]  а не из r в 0,1, потому что за счет того, что она не убывает, есть третье свойство, она не может
[07:49.160 --> 07:54.320]  выйти за границы отрезка 0,1, поэтому можно написать, что она действует в 0,1, можно написать в r,
[07:54.320 --> 08:03.360]  это одно и то же. С точки зрения этой теоремы, если функция из r в r такова, что выполнено
[08:03.360 --> 08:12.040]  свойство 1,3, то f является функцией распления для некоторого распления вероятностей.
[08:24.320 --> 08:42.640]  Я не знаю, рассказывали ли вам в теории меры доказательств этой теоремы, но вам рассказывали
[08:42.640 --> 08:51.080]  теорему о продолжении с меры с полукольца на кольцо, что-нибудь такое, на сигму алгебру, не суть.
[08:51.080 --> 09:01.760]  Суть в том, что давайте просто положим, возьмем p и определим ее вот на этих лучах равной f
[09:01.760 --> 09:07.280]  от x, это точно надо сделать, и увидим, что она после этого единственным образом продолжается,
[09:07.280 --> 09:14.680]  но мы сначала ее сделаем конечно-аддитивной, в том смысле, что мы скажем, что вот у нас есть
[09:14.680 --> 09:20.160]  конечное объединение интервалов, и вероятность их объединения будет равна сумме их вероятностей.
[09:20.160 --> 09:27.760]  Я не хочу сейчас это аккуратно доказывать, чтобы не тратить время на такие технические вещи,
[09:27.760 --> 09:33.120]  и сегодня будет еще ряд подобных утверждений, которые практически очевидны, то есть следует
[09:33.120 --> 09:36.800]  из того, что вас было в курсе теории меры. Чтобы не тратить много времени, я просто буду
[09:36.800 --> 09:44.920]  схематично объяснять, почему это так. Еще раз, мы говорим, что давайте вероятность, положим,
[09:44.920 --> 09:53.320]  вероятность получает, есть f от x, определим вот так. Ну и дальше просто продолжим это на всю
[09:53.320 --> 09:58.400]  сигму алгебру. Сначала мы увидим, что если мы возьмем любой интервал, так как вероятность должна
[09:58.400 --> 10:05.400]  быть аддитивной, в котором b включается, а не включается, это будет f от b минус f от a.
[10:05.400 --> 10:16.120]  Дальше мы скажем, ну хорошо, если у нас есть конечное объединение таких интервалов,
[10:16.120 --> 10:31.840]  1b1 и так далее, akbk, я имею в виду, что эти интервалы не пересекаются,
[10:31.840 --> 10:40.400]  то опять по аддитивности это должно будет быть равно сумме f от b и t, а минус f от a и t.
[10:40.400 --> 10:53.920]  А дальше по теории о продолжении полукольца на кольцо мы продолжим нашу вероятность единственным
[10:53.920 --> 10:59.360]  образом на всю сигму алгебру. Вот собственно и все, то есть понятно, что за счет того,
[10:59.440 --> 11:08.120]  что вот эта штука не отрицательная, так у нас вероятность не убывает, то это определение будет
[11:08.120 --> 11:20.400]  корректным. Вот, ну хорошо. Давайте теперь посмотрим на эти три свойства и поймем,
[11:20.400 --> 11:27.040]  что они некоторым образом говорят о том, как может выглядеть график функции распределения,
[11:27.040 --> 11:32.000]  ну как бы мы рисовали график такой функции, если мы его рисовали непрерывной, то он бы выглядел
[11:32.000 --> 11:41.240]  вот так. Вот у нас есть единица, выше нее мы не уходим, мы приближаемся к нулю, а оттуда мы
[11:41.240 --> 11:46.480]  приближаемся к единице, и функция должна не убывать. В принципе, ничто ей не мешает в какой-то
[11:46.480 --> 11:50.560]  момент стать нулем, она не обязана прямо стремиться к нулю, она может в какой-то момент сравняться
[11:50.560 --> 11:54.800]  с нулем и дальше просто быть равной нулю, а может и стремиться к нулю, может эта точка никогда не
[11:54.800 --> 12:02.000]  достигать той же самой с единицей. Она не обязана быть разрывной, то есть в принципе мы можем где-нибудь ее
[12:02.000 --> 12:20.400]  разорвать, нарисовать скажем вот так. Это тоже будет функция распределения. Вот, ну вот такие два
[12:20.400 --> 12:26.960]  важных частных случая. Первый это непрерывный, а второй это когда у нее вообще нет никаких участков,
[12:26.960 --> 12:35.200]  где бы у нее была производная не ноль, то есть я имею в виду когда она представляет в виде ступенек.
[12:35.200 --> 12:39.960]  Первый случай это непрерывный, второй случай это дискретный. Давайте поговорим об этих двух случаях
[12:39.960 --> 12:55.520]  отдельно. Начнем с дискретных распределений. Я сейчас поясню, почему это важный случай. Мы с ним
[12:55.520 --> 13:03.120]  уже сталкивались, когда решали какие-то комбинаторные задачи. Значит, это случай, когда вся мера,
[13:03.120 --> 13:07.440]  значит вся вероятность, она сосредоточена в не более чем счетном множестве точек. Ну например,
[13:07.640 --> 13:14.120]  допустим, вы подбрасываете монетку десять раз, и у вас есть два в десятой степени разных исходов.
[13:14.120 --> 13:18.800]  Выбрали все нули где-то в одном месте единичек, в двух местах единичек и так далее. Два в десятой
[13:18.800 --> 13:24.560]  разных исходов. Ну вот такое распределение вероятности, там у каждого из этих два в десятой исходов будет
[13:24.560 --> 13:29.040]  какая-то своя вероятность. Или подбросили кубик, или еще что-то произошло. Короче, допустим,
[13:29.040 --> 13:33.280]  есть какое-то конечное количество исходов. Или оно может быть бесконечное, но счетное, и у вас
[13:33.280 --> 13:38.240]  вероятности, они просто, то есть у вас есть атомы такие, в которых вероятность не нулевая,
[13:38.240 --> 13:44.120]  а во всем остальном множество действительно числа 0. Вот это будет дискретное распределение
[13:44.120 --> 13:57.760]  вероятности. Значит, пусть х не более чем счетное множество. Значит, распределение вероятности
[13:57.760 --> 14:16.000]  P называется дискретным, если P от х равно единице. Вот, то есть, ну, правильно написать, наверное,
[14:16.000 --> 14:25.440]  перенести вот это сюда. Здесь написать существует. Распределение дискретное, если для него найдется
[14:25.440 --> 14:31.160]  какое-то множество не более чем счетного, не более чем счетное. Такая, что вся мера равна единице
[14:31.160 --> 14:37.520]  на нем, а больше нигде нет ни по вероятности. Остальное имеет меру 0. Вот, ну давайте поймем,
[14:37.520 --> 14:42.840]  как будет выглядеть функция распределения у дискретного распределения. Понятно, что нам
[14:42.840 --> 14:51.360]  будет выглядеть вот так. Вот есть какие-то у вас точки, там пусик 5, скажем, в которых вероятность не
[14:51.360 --> 15:00.400]  0. Во всех остальных точках вероятность 0. Что это значит? Ну, давайте еще раз посмотрим. А вот,
[15:00.400 --> 15:06.000]  есть. Вот что такое функция распределения. Понятно, что если вот эта точка Y, она лежит левее всех
[15:06.000 --> 15:12.800]  точек, где у вас вероятность не 0, то вероятность этого луча 0. То есть, чтобы вероятность была не
[15:12.800 --> 15:19.480]  0, в него должны какие-то попасть точки, в которых она не 0. Поэтому вот до этой точки функция распределения
[15:19.480 --> 15:25.160]  ведет себя вот так. Дальше, как только вы за эту точку заходите, то есть вы уже вот прямо смотрите
[15:25.160 --> 15:30.560]  значение функции распределения в нем, уже одна точка в этот луч попала, в котором вероятность не 0.
[15:30.560 --> 15:40.520]  У вас происходит прыжок. И если я назову эти точки X1, X2 и так далее, то высота вот этого скачка — это
[15:40.520 --> 15:47.560]  в точности вероятность попадания в эту точку. Вот эта высота — это есть вероятность X1.
[15:47.560 --> 15:55.360]  Какое-то множество, под множество действительно, действительно чисел счетные или конечные.
[15:55.360 --> 16:08.480]  Вот у меня на рисунке здесь X большой состоит из пяти точек. X1, X2, X5. Да, то, где не 0 — вероятность
[16:08.480 --> 16:17.960]  номера. Просто не 0, а вообще 1. То есть в каждой точке не 0, а в сумме 1. Дальше у вас понятно,
[16:17.960 --> 16:24.040]  что до точки X2 опять идет просто горизонтальный отрезок, и в точке X2 происходит скачок ровно
[16:24.040 --> 16:30.200]  на вероятность попасть вот именно в точку X2. То есть высота этого скачка — это вероятность X2.
[16:30.200 --> 16:45.480]  Ну и так далее. И так далее. Если у вас точек всего 5, то в конечном итоге это станет единицей.
[16:45.480 --> 16:54.840]  То есть это на уровне единицы идет. Это прямая. Куда будет вывели график пунктов распределения?
[16:54.840 --> 16:58.160]  Понятно, что высота этих скачков может быть разная. Если вероятности разные, если эти
[16:58.160 --> 17:04.560]  вероятности все одинаковые, то и все эти скачки тоже одинаковые. Ну и так, у вас
[17:04.560 --> 17:11.120]  возможность X пусть состоит из каких-то действительных чисел X1, X2 и так далее.
[17:11.120 --> 17:22.720]  И тогда ваше распределение однооднозначно задается вероятностью попадания в эти точки.
[17:22.720 --> 17:26.560]  Ну с одной стороны понятно, что если вы знаете вероятность попадания в эти точки,
[17:26.800 --> 17:32.920]  то вы однозначно рисуете функцию распределения, знаете вот эти прыжки и знаете эти значения —
[17:32.920 --> 17:37.240]  знайте эти И или И. Поэтому вы однозначно рисуете функцию распределения,
[17:37.240 --> 17:42.000]  сам Мы однозначно восстанавливаем все распределения вероятностей.
[17:42.000 --> 17:46.080]  Ну на другой стороны — еще раз, если вы знаете вероятности всех этих точек,
[17:46.080 --> 17:49.120]  вы можете просто восстановить вероятность любого множества.
[17:49.120 --> 17:52.080]  Так, в какое бы баррельское множество ни взяли, вероятность попадания в него это
[17:52.080 --> 17:55.860]  просто сумма вероятностей точек, вот этих X-ов, которые в этом множестве находятся.
[17:55.860 --> 18:03.200]  Поэтому в случае дискретного расплетения еще более удобно смотреть на
[18:03.200 --> 18:07.080]  вероятность этих точек, чем смотреть на функцию
[18:07.080 --> 18:10.580]  распределения. Функция расплетения это функция, которая определена на
[18:10.820 --> 18:13.800]  континуме точек, а тут будет просто последовательность, то есть счетная последовательность
[18:13.800 --> 18:18.040]  задает однозначно расплетение вероятностей. Но давайте её как-нибудь
[18:18.040 --> 18:31.120]  запишем. Пусть P от x и t это есть вероятность попадания в точку x и t. Ну и вот понятно,
[18:31.120 --> 18:36.560]  что вот эта последовательность она просто однозначно задает распределение вероятностей.
[18:48.040 --> 18:55.880]  Ну то есть, какой бы у вас ни было баррельовское множество, вы можете просто написать следующее.
[18:55.880 --> 19:04.560]  Вероятность этого множества, это есть просто сумма вероятностей точек x и t,
[19:04.560 --> 19:12.760]  которые в это множество попали. Сумма по всем i таким, что x и t попадает в P от x и t.
[19:12.760 --> 19:20.680]  Ну и коль скоро у нас есть такая замечательная последовательность,
[19:20.680 --> 19:24.480]  с помощью которой мы понимаем какое у нас распределение, давайте рассмотрим какие-то
[19:24.480 --> 19:29.640]  примеры жизненные, в которых дискретное распределение возникает и будем их задавать
[19:29.640 --> 19:31.240]  именно с помощью вот этих последовательностей.
[19:42.760 --> 20:01.720]  Значит, примеры. Ну первое, что приходит в голову, это распределение Bernoulli,
[20:01.720 --> 20:07.520]  первое, что мне приходит в голову, я имею ввиду. То есть подбрасывай мне одну монетку всего один раз.
[20:07.520 --> 20:17.120]  Это распределение обозначается часто вот так. P это параметр распределения, какое-то число,
[20:17.120 --> 20:23.880]  ну в отрезке или в интервале. Если 0 или 1 брать, то это получится тривиально какое-то распределение,
[20:23.880 --> 20:33.600]  поэтому можно не брать. Будем считать, что P лежит в интервале от 0 до 1. И x это множество значений,
[20:33.600 --> 20:39.320]  которые ваше спиление, в котором оно имеет нелёгую вероятность. Ну орёл или решка, или давайте 0 или 1.
[20:39.320 --> 20:46.360]  0 или 1, вероятность единицы P, вероятность 0 или 1 минус P.
[20:46.360 --> 20:57.240]  Ну понятно, как будет выглядеть функция распределения.
[20:57.240 --> 21:08.840]  У вас будут две точки 0 и 1, в которых будет меняться значение. До 0 будет 0, а здесь станет 1 минус P,
[21:08.840 --> 21:22.920]  а здесь станет 1. Есть какие-то вопросы? Хорошо.
[21:22.920 --> 21:28.840]  Следующее на ум приходит равномерное распределение на любом конечном множестве.
[21:28.840 --> 21:42.040]  Пусть ух это какое-то конечное множество под множество r, и распределение обозначается вот так.
[21:42.040 --> 21:51.000]  У от х. Это обозначение равномерного распределения на множестве х. Что это за распределение такое?
[21:51.320 --> 21:57.080]  Равномерное значит, что вероятности всех точек внутри х просто одинаковые. И отсюда понятно, в чём должно быть конечное.
[21:57.080 --> 22:02.440]  Потому что если оно бесконечное, то получится вероятность всех точек просто 0, и тогда в своём будет 0.
[22:02.440 --> 22:13.960]  Поэтому должно быть конечное. И как будет задаваться вероятность? Ну понятно, она должна быть одинаковая.
[22:14.040 --> 22:16.760]  То есть единиц поедет на мощность х.
[22:26.280 --> 22:33.000]  Но я не буду рисовать график, так понятно, что он будет выглядеть вот как-то так, и все вот эти вот скачки будут просто одинаковые.
[22:43.960 --> 23:02.840]  Так, далее. Биномиальное распределение, у него два параметра n и p.
[23:02.840 --> 23:08.840]  Что такое биномиальное распределение? Это просто количество решек, если вы n раз подбросили монетку.
[23:08.920 --> 23:13.720]  Вот n раз подбросили, посмотрели сколько решек. У этого количества будет биномиальное распределение с параметрами n и p.
[23:17.720 --> 23:21.160]  n – это какое-то натуральное число произвольное, это количество, сколько раз вы подбросили.
[23:23.160 --> 23:27.480]  А p – это число 1 единицы, это вероятность решки при одном подбрасывании.
[23:30.280 --> 23:37.480]  Что будет х носителем вашего распределения, где вероятности положительные?
[23:38.120 --> 23:50.120]  Ну понятно, что это число от 0 до n, потому что у вас столько может быть решек, у вас не может быть их отрицательного количества, не может быть больше n.
[23:52.120 --> 23:58.120]  И для любого х из их большого вероятность х – это что?
[23:58.760 --> 24:06.760]  Да, c из n пока на p в степени k, на 1 – p в степени n – k.
[24:08.760 --> 24:12.760]  Это я от c из n пока так написал, так тоже пишут.
[24:16.760 --> 24:22.760]  Ну понятно, да, то есть это просто количество решек при n подбрасываниях монетки, если вероятность решки равна p.
[24:28.760 --> 24:30.760]  Еще раз.
[24:30.760 --> 24:32.760]  Да, спасибо, конечно.
[24:32.760 --> 24:36.760]  Ну kx похоже, да, можно было и не заметить.
[24:36.760 --> 24:38.760]  Да, вот так.
[24:40.760 --> 24:42.760]  Хорошо, давайте еще.
[24:42.760 --> 24:48.760]  Ну опять как-то вот так будет выглядеть, но уже будут вот эти вот скачки, они будут уже неодинаковые.
[24:48.760 --> 24:52.760]  То есть у биномаильного распределения у него самая большая вероятность в середине.
[24:53.400 --> 25:03.400]  То есть прыжок в середине будет большой, а к краям будут они все уменьшаться, уменьшаться, уменьшаться.
[25:03.400 --> 25:09.400]  Ну схематично будет выглядеть, понятное дело, также функция распределения.
[25:09.400 --> 25:13.400]  И теперь давайте еще раз берем пример какого-нибудь счетного носителя.
[25:13.400 --> 25:17.400]  То есть здесь все ситуации были x-конечные, пусть теперь x-счетные.
[25:17.400 --> 25:19.400]  Поговорим про Пуассоновское распределение.
[25:20.040 --> 25:24.040]  Я сейчас сразу объясню откуда оно берется.
[25:30.040 --> 25:36.040]  Вот, ну тут можно порассуждать на тему каких-то, какой-нибудь теорий массового обслуживания.
[25:36.040 --> 25:40.040]  Там полезно оказывается Пуассоновское распределение.
[25:40.680 --> 25:48.680]  Ну вот если есть очередь в Макдональдс, скажем, и там есть какие-нибудь кассы,
[25:48.680 --> 25:52.680]  которые обслуживают, и там какой-то поток клиентов,
[25:52.680 --> 25:56.680]  вот это такие задачи можно моделировать в вероятностных терминах
[25:56.680 --> 25:58.680]  с помощью так называемой теории массового обслуживания.
[25:58.680 --> 26:00.680]  И в общем, там где Пуассоновское распределение возникает.
[26:00.680 --> 26:04.680]  Как правило, считается по некоторым причинам, что Пуассоновское распределение
[26:04.680 --> 26:08.680]  это количество клиентов, которые заходят за какой-то промежуток времени.
[26:09.320 --> 26:11.320]  То есть вы берете единицу времени, смотрите,
[26:11.320 --> 26:15.320]  сколько за это время зашло клиентов, и оно будет иметь Пуассоновское распределение.
[26:17.320 --> 26:19.320]  Предположительно.
[26:19.320 --> 26:21.320]  Оказывается, эта модель часто хорошо работает.
[26:21.320 --> 26:25.320]  Вот давайте я здесь о чем-то более строгом поговорю.
[26:25.320 --> 26:29.320]  В какой еще ситуации возникает Пуассоновское распределение,
[26:29.320 --> 26:31.320]  которое нам понятно.
[26:31.320 --> 26:33.320]  Это в ситуации, когда в биомиальном распределении
[26:33.320 --> 26:37.320]  вероятность обратно пропорционально количества подбрасываний.
[26:39.320 --> 26:41.320]  То есть представьте себе, что вы миллион раз подбрасываете,
[26:41.320 --> 26:43.320]  а вероятность решки 1 миллионная.
[26:45.320 --> 26:49.320]  Но выглядит, наверное, немного искусственно,
[26:49.320 --> 26:55.320]  но, например, в физике возникают всякие задачи про взаимодействующие частицы,
[26:55.320 --> 26:59.320]  когда очень много частиц, между ними какие-то слабые взаимодействия.
[26:59.320 --> 27:05.320]  И такие вещи хорошо моделируются с помощью вот этого Пуассоновского распределения.
[27:05.320 --> 27:08.320]  Но с формальной точки зрения мы просто берем вероятность обратно
[27:08.960 --> 27:12.960]  количество подбрасываний и устремляем n бесконечности и в пределе получим вот это.
[27:12.960 --> 27:14.960]  Давайте это увидим.
[27:14.960 --> 27:16.960]  Сначала напишу, что мы получим, потом увидим, что это действительно так.
[27:18.960 --> 27:20.960]  Итак, что здесь?
[27:20.960 --> 27:22.960]  Здесь x – это множество целых неотрясательных чисел.
[27:25.960 --> 27:27.960]  И для любого x-а
[27:29.960 --> 27:34.960]  его вероятность – это есть λ в степени x, e в степени минус λ,
[27:34.960 --> 27:36.960]  поделить на x-факториал.
[27:38.960 --> 27:48.960]  Ну, значит, я утверждаю, что на самом деле это то же самое,
[27:48.960 --> 27:56.960]  что вот эту штуку, найти пределы этой штуки при n стремящемся бесконечности
[27:56.960 --> 27:58.960]  и P равным λ поделить на n.
[27:58.960 --> 28:00.960]  Давайте увидим, что это действительно так.
[28:00.960 --> 28:02.960]  Такое утверждение докажем.
[28:03.600 --> 28:07.600]  Что если P – это λ поделить на n,
[28:11.600 --> 28:19.600]  то предел при n стремящемся бесконечности c из n по x
[28:19.600 --> 28:23.600]  P в степени x на 1-P в степени n-x
[28:23.600 --> 28:27.600]  это в точности λ в степени x
[28:27.600 --> 28:29.600]  на e в степени минус λ поделить на x-факториал.
[28:33.600 --> 28:37.600]  Так, ну что, просто пределы найдем, да?
[28:37.600 --> 28:39.600]  Здесь имейте в виду, что x – это константа какая-то.
[28:39.600 --> 28:43.600]  Мы же, мы здесь вероятность находим для любого конкретного x.
[28:43.600 --> 28:46.600]  То есть мы фиксируем x, а потом устремляем n бесконечности.
[28:46.600 --> 28:48.600]  То есть вот это x, оно от этого никак не зависит.
[28:49.240 --> 28:59.240]  И поэтому c из n по x на P в степени x на 1-P в степени n-x
[28:59.240 --> 29:01.240]  это есть симпатически.
[29:01.240 --> 29:05.240]  Я пишу такую волну, я имею в виду симпатическое равенство.
[29:05.240 --> 29:09.240]  То есть если я сейчас напишу здесь некоторые выражения
[29:09.240 --> 29:11.240]  и составлю их отношения, то в пределе получится единица.
[29:11.240 --> 29:13.240]  Вот что я имею в виду, когда я пишу волну.
[29:13.240 --> 29:15.240]  Что если я поделю одно от другое,
[29:15.240 --> 29:17.240]  я в пределе единицу.
[29:17.880 --> 29:19.880]  Ну, я могу вместо c из n по x написать n в степени x
[29:19.880 --> 29:21.880]  поделить на x факториал.
[29:25.880 --> 29:27.880]  Ну, потому что что такое c из n по x?
[29:27.880 --> 29:33.880]  Это произведение n на n-1, на n-2, x раз и делить на x факториал.
[29:33.880 --> 29:35.880]  Так как x – это какое-то фиксированное число,
[29:35.880 --> 29:39.880]  то понятно, что асимпатически я получаю такое выражение.
[29:39.880 --> 29:43.880]  P в степени x – у меня P – это λ поделить на n.
[29:43.880 --> 29:45.880]  Я подставлю.
[29:46.520 --> 29:48.520]  Я получу λ в степени x поделить на n в степени x.
[29:52.520 --> 29:54.520]  Ну и здесь просто второй замечательный предел.
[29:54.520 --> 29:56.520]  Это 1 – λ поделить на n в степени n,
[29:56.520 --> 29:58.520]  что в пределе равно e в степени – λ.
[30:04.520 --> 30:06.520]  Ну прекрасно, n в степени x сокращается
[30:06.520 --> 30:08.520]  и остается то, что мы хотели.
[30:08.520 --> 30:12.520]  λ в степени x на e в степени – λ поделить на x факториал.
[30:16.520 --> 30:18.520]  Пит, вопросы?
[30:18.520 --> 30:20.520]  Вот!
[30:26.520 --> 30:28.520]  Не понял.
[30:28.520 --> 30:30.520]  Вопрос?
[30:30.520 --> 30:32.520]  Ну это максимальная форма строгости,
[30:32.520 --> 30:34.520]  максимально не бывает.
[30:36.520 --> 30:38.520]  Что? Как это?
[30:38.520 --> 30:40.520]  Как это?
[30:40.520 --> 30:42.520]  Как это?
[30:42.520 --> 30:44.520]  Как это?
[30:45.160 --> 30:49.160]  Какое именно место я доказал нестрого, на мой взгляд?
[30:51.160 --> 30:53.160]  Какой переход нестрогий?
[30:53.160 --> 30:55.160]  Вот этот?
[30:55.160 --> 30:57.160]  Вряд ли этот.
[30:57.160 --> 30:59.160]  С этим, наверное, все в порядке.
[30:59.160 --> 31:01.160]  Вот этот нестрогий.
[31:01.160 --> 31:03.160]  Еще раз.
[31:03.160 --> 31:05.160]  c из n по x.
[31:05.160 --> 31:07.160]  Что значит эта волна?
[31:07.160 --> 31:09.160]  Если я поделю вот эту штуку на вот эту,
[31:09.160 --> 31:11.160]  я в пределе единицы получу.
[31:11.160 --> 31:13.160]  Я вместо c из n по x написал n в степени x поделить на x факториал.
[31:13.800 --> 31:15.800]  От n в степени x.
[31:15.800 --> 31:17.800]  А знаете, стоит x факториал.
[31:17.800 --> 31:19.800]  Поэтому вот эту штуку поделить на n в пределе 1.
[31:19.800 --> 31:21.800]  Окей?
[31:21.800 --> 31:23.800]  Строго или не очень?
[31:23.800 --> 31:25.800]  Значит, здесь
[31:25.800 --> 31:27.800]  p стремится к нулю.
[31:27.800 --> 31:29.800]  Поэтому –x на предел не влияет.
[31:33.800 --> 31:35.800]  То есть вместо 1 – λ поделить на n в степени n,
[31:35.800 --> 31:37.800]  по второму замечательному пределу –
[31:37.800 --> 31:39.800]  это e в степени – λ.
[31:39.800 --> 31:41.800]  Это надо объяснять, почему 1 – λ поделить на n
[31:42.440 --> 31:44.440]  и λ стремится к e в степени – λ.
[31:44.440 --> 31:46.440]  Прям стремяще бесконечности.
[31:46.440 --> 31:48.440]  Надо.
[31:56.440 --> 31:58.440]  Ну то есть, конечно, если вас на экзамене это спросит,
[31:58.440 --> 32:00.440]  вам придется это отвечать.
[32:00.440 --> 32:02.440]  Но я надеюсь, что здесь все умеют
[32:02.440 --> 32:04.440]  все-таки пределы считать.
[32:04.440 --> 32:06.440]  Вот, значит, λ – это константа.
[32:06.440 --> 32:08.440]  Поэтому, премяще бесконечности, вот эта штука
[32:08.440 --> 32:10.440]  под степенью стремится к 1 делить на e.
[32:11.080 --> 32:13.080]  И так как это тоже константа, то предел нас следует.
[32:13.080 --> 32:15.080]  Значит, предел будет e в степени – л.
[32:17.080 --> 32:19.080]  Но я не думаю, что экзаминаторы будут вас
[32:19.080 --> 32:21.080]  такие вещи спрашивать. Они вам верят,
[32:21.080 --> 32:23.080]  что вы умеете пределы считать.
[32:23.080 --> 32:25.080]  Я бы назвал это не
[32:25.080 --> 32:27.080]  степенью строгости.
[32:27.080 --> 32:29.080]  Я бы это назвал просто подробностями.
[32:29.080 --> 32:31.080]  Этих подробностей достаточно.
[32:31.080 --> 32:33.080]  Но если вдруг экзаминатор вас начнет
[32:33.080 --> 32:35.080]  дотошно спрашивать, как пределы считаются,
[32:35.080 --> 32:37.080]  придется объяснять.
[32:41.080 --> 32:43.080]  Так.
[32:47.080 --> 32:49.080]  Хорошо, значит.
[32:49.080 --> 32:51.080]  Ну, функция распределения,
[32:51.080 --> 32:53.080]  в отличие от всех остальных случаев,
[32:53.080 --> 32:55.080]  она никогда не достигнет 1.
[32:55.080 --> 32:57.080]  Да, если
[32:57.080 --> 32:59.080]  для всех предыдущих распределений
[32:59.080 --> 33:01.080]  у нас носитель был конечный,
[33:01.080 --> 33:03.080]  поэтому там вот конечное множество
[33:03.080 --> 33:05.080]  иксов мы отмечали на оси абсцисс.
[33:05.080 --> 33:07.080]  И после последнего икса
[33:07.080 --> 33:09.080]  функция становится конечной.
[33:09.720 --> 33:11.720]  После последнего икса функция
[33:11.720 --> 33:13.720]  становится 1.
[33:13.720 --> 33:15.720]  Здесь она никогда 1 не достигнет,
[33:15.720 --> 33:17.720]  потому что у вас носитель бесконечный.
[33:17.720 --> 33:19.720]  У вас существует сколько угодно большое икс,
[33:19.720 --> 33:21.720]  для которого вероятность не нулевая.
[33:21.720 --> 33:23.720]  Вот.
[33:23.720 --> 33:25.720]  Какие-то вопросы?
[33:25.720 --> 33:27.720]  Хорошо.
[33:27.720 --> 33:29.720]  Тогда давайте поговорим теперь про
[33:29.720 --> 33:31.720]  второй вид распределений.
[33:31.720 --> 33:33.720]  Абсолютно непрерывный.
[33:33.720 --> 33:35.720]  На самом деле нас интересует
[33:35.720 --> 33:37.720]  чуть более сильное
[33:38.360 --> 33:40.360]  свойство, чем непрерывность.
[33:40.360 --> 33:42.360]  Абсолютная непрерывность.
[33:42.360 --> 33:44.360]  Сейчас я поясню, что это такое.
[33:44.360 --> 33:46.360]  Но вы, наверное, знаете.
[33:52.360 --> 33:54.360]  На семинаре вы имеете в виду?
[33:54.360 --> 33:56.360]  Или где?
[33:56.360 --> 33:58.360]  Или что была за предыдущей парой?
[33:58.360 --> 34:00.360]  А, сказали вам,
[34:00.360 --> 34:02.360]  что такое абсолютно непрерывная функция.
[34:02.360 --> 34:04.360]  А кто матан ведет?
[34:04.360 --> 34:06.360]  Кто?
[34:07.000 --> 34:09.000]  Вы поняли, что такое абсолютно непрерывная функция?
[34:09.000 --> 34:11.000]  А какое определение?
[34:17.000 --> 34:19.000]  Понятно.
[34:19.000 --> 34:21.000]  Да, но
[34:21.000 --> 34:23.000]  вы на матанализме
[34:23.000 --> 34:25.000]  занимаетесь функциями.
[34:29.000 --> 34:31.000]  Вы считаете, что у вас какая-нибудь
[34:31.000 --> 34:33.000]  мера или бега,
[34:33.000 --> 34:35.000]  и там все на R.
[34:35.640 --> 34:37.640]  Вы можете обобщать на какие-то другие пространства,
[34:37.640 --> 34:39.640]  другие меры.
[34:39.640 --> 34:41.640]  То определение, которое вам дают,
[34:41.640 --> 34:43.640]  очень универсальное.
[34:43.640 --> 34:45.640]  Но одно и то же, если сконцентрируйтесь
[34:45.640 --> 34:47.640]  только на тех функций, которые вы рассматриваете.
[34:47.640 --> 34:49.640]  А более универсальное определение я сейчас формулирую.
[34:49.640 --> 34:51.640]  Абсолютно непрерывная
[34:51.640 --> 34:53.640]  является функцией распределения.
[34:53.640 --> 34:55.640]  Если мы говорим, что функция
[34:55.640 --> 34:57.640]  распределения не прерывна, то и само распределение.
[34:57.640 --> 34:59.640]  Что это значит?
[34:59.640 --> 35:10.120]  Распыление называется абсолютно неправильным, если у него есть плотность.
[35:10.120 --> 35:12.120]  Что такое плотность?
[35:12.120 --> 35:20.120]  Значит, если существует такая функция P, которая действует из r в r+, такая что
[35:20.120 --> 35:28.120]  для любого x из r, f от x,
[35:28.120 --> 35:34.120]  где f это пункция распления, которая соответствует вот этому расплению P,
[35:34.120 --> 35:40.120]  это есть интеграл от минус бесконечности до x, P от t dt,
[35:40.120 --> 35:46.120]  где вот этот интеграл, его надо воспринимать как интеграл Лебега.
[35:46.120 --> 35:52.120]  Мы вообще все интегралы воспринимаем как интеграл Лебега, но повезло, что он считается как обычный интеграл Риммана,
[35:52.120 --> 36:02.120]  но когда мы пишем интеграл, мы имеем в виду интеграл Лебега, это более общее понятие.
[36:02.120 --> 36:08.120]  Ну и сама функция распления называется абсолютно непрерывной, и расприление P тоже называется абсолютно непрерывным.
[36:08.120 --> 36:14.120]  Я сейчас поясню сакральный смысл этого понятия.
[36:14.120 --> 36:20.120]  f это тоже абсолютно непрерывная функция.
[36:20.120 --> 36:26.120]  Смотрите, давайте вспомним, у нас было определение дискретного распределения,
[36:26.120 --> 36:34.120]  но вот появилась в нем вот эта вот буква P, и вот здесь тоже у меня есть буква P.
[36:34.120 --> 36:42.120]  Только вот эта буква P, это есть последовательность, которая задана на множество x большое,
[36:42.120 --> 36:48.120]  у нас есть какой-то носитель, и для каждого элемента этого носителя P от x положительное число какое-то.
[36:48.120 --> 36:56.120]  Смотрите, если я попытаюсь как бы размазать, допустим, у меня есть равномерное распределение,
[36:56.120 --> 37:06.120]  на отрезке от 0 до 1 с шагом 1n, то есть я беру числа 0, 1, 1, 1n, 2 поделить на n, 3 поделить на n и так далее.
[37:06.120 --> 37:10.120]  И говорю, что вот дискретное распределение на отрезке от 0 до 1 равномерное.
[37:10.120 --> 37:14.120]  И дальше начинаю n увеличивать, и у меня отрезок начинает дробиться.
[37:14.120 --> 37:18.120]  Да, на нем все больше и больше и больше и больше точек возникает.
[37:18.120 --> 37:26.120]  И вот есть у меня эта функция P, которая равна 1 поделить на n плюс 1, видимо, в каждой из этих точек.
[37:26.120 --> 37:30.120]  Но понятно, что если я стремлю к бесконечности, эта функция стремится к нулю.
[37:30.120 --> 37:36.120]  Да, но распределение, оно не устремится к нулю, оно станет равномерным на всем отрезке.
[37:36.120 --> 37:40.120]  И тогда вместо функции P мы будем рассматривать другую функцию, вот эту.
[37:40.120 --> 37:44.120]  Когда мы здесь считаем какую-то вероятность, она равна сумме вероятностей.
[37:44.120 --> 37:47.120]  А когда мы здесь считаем вероятность, она равна интегралу.
[37:47.120 --> 37:49.120]  То есть просто сумма превращается в интеграл.
[37:49.120 --> 37:54.120]  В каком-то смысле вот эта функция P – это просто аналог вот этого P.
[37:54.120 --> 37:57.120]  То есть это такая дискретная плотность, ее иногда называют дискретной плотностью.
[37:57.120 --> 38:03.120]  А это плотность для в обычном смысле абсолютно неприливного распределения.
[38:03.120 --> 38:09.120]  Но если вместо меры Либега рассмотреть так называемую считающую меру.
[38:09.120 --> 38:10.120]  Что это такое?
[38:10.120 --> 38:12.120]  Что такое мера Либега, вы знаете.
[38:12.120 --> 38:14.120]  А считающая мера – это следующее.
[38:14.120 --> 38:20.120]  Мы просто будем говорить, что мера любого множества – это количество целых чисел, которые в него попало.
[38:20.120 --> 38:26.120]  Вот если мы возьмем такую меру, то вот эта штука – это будет плотность только относительно этой меры.
[38:26.120 --> 38:32.120]  Да, вот эта плотность относительно меры Либега, а вот эта вот плотность относительно так называемой считающей меры.
[38:32.120 --> 38:36.120]  То есть это на самом деле одно и то же, просто для разных мер.
[38:36.120 --> 38:40.120]  Вот это вот для такой так называемой считающей меры, а это для меры Либега.
[38:40.120 --> 38:46.120]  Но естественность вот этого распределения нужно воспринимать на мой взгляд именно так.
[38:46.120 --> 38:50.120]  То есть давайте сначала возьмем дискретное распределение, например такое.
[38:50.120 --> 38:52.120]  Будем дробить, дробить, дробить все сильнее, сильнее, сильнее.
[38:52.120 --> 38:55.120]  И в пределе у нас получится абсолютно неприливное распределение.
[38:55.120 --> 38:59.120]  И вот в некотором смысле вот эта штука превратится вот в эту штуку.
[39:00.120 --> 39:10.120]  Вот, значит, давайте поговорим про свойства и про примеры, чтобы немного пощупать, чтобы немного пощупать это распределение.
[39:15.120 --> 39:20.120]  Примеры сделают его естественным, чтобы увидеть, что возникают какие-то относительно жизненные ситуации,
[39:20.120 --> 39:27.120]  в которых это распление возникает, а свойства помогут с ним проще работать, какие-то вероятности считать в частности.
[39:30.120 --> 39:33.120]  По классическому меру Либега. Да, имеется в виду классическую меру Либега.
[39:39.120 --> 39:44.120]  То есть когда мы просто пишем dt, когда мы не уточняем, какая мера, мы имеем в виду классическую меру Либега.
[39:44.120 --> 39:54.120]  Так, свойства. Ну, во-первых, значит, функция P, все про нее можно сказать, она не отрицательна, она принимает неотрицательные значения.
[39:54.120 --> 39:57.120]  И еще одна вещь. Интеграл от P равен единице.
[40:06.120 --> 40:09.120]  Понятно, почему. Вот у нас есть функция распределения.
[40:09.120 --> 40:13.120]  У нас есть свойства. Третье, что предел в плюс бесконечности равен 1.
[40:14.120 --> 40:17.120]  То есть мы напишем здесь предел при стремящейся в плюс бесконечности мы получим 1.
[40:17.120 --> 40:20.120]  Это и есть интеграл от минуса бесконечности до плюс бесконечности.
[40:22.120 --> 40:31.120]  Во-вторых, вы можете считать не только функцию распределения с помощью плотности, вы можете считать вероятность любого множества.
[40:31.120 --> 40:38.120]  Во-вторых, вы можете считать не только функцию распределения с помощью плотности, вы можете считать вероятность любого множества.
[40:38.120 --> 41:00.120]  Какое бы вы ни взяли барреллерское множество, его вероятность будет равна интегралу по нему p от t до t.
[41:00.120 --> 41:06.120]  Смотрите, еще раз, где я пишу формально доказательства, это значит, что я полностью что-то доказываю.
[41:06.120 --> 41:15.120]  Вот эти свойства и много еще чего-то другое, просто за не менее времени я не хочу по-другому все доказательства писать, но я схематично буду это рассказывать.
[41:15.120 --> 41:18.120]  На экзамене от вас требуется, конечно, то же самое.
[41:18.120 --> 41:23.120]  Смотрите, почему второе свойство верно? Кто может объяснить?
[41:23.120 --> 41:31.120]  Правильно.
[41:31.120 --> 41:35.120]  Да, абсолютно верно.
[41:35.120 --> 41:41.120]  Давайте подумаем, что это не p, а это хоть p с волной.
[41:42.120 --> 41:47.120]  Определим так. Положим p с волной равно этой штуке.
[41:47.120 --> 41:52.120]  Тогда это вероятность. По определению вероятности можно увидеть, что это счетно-адидитивная штука.
[41:52.120 --> 41:58.120]  Интеграл ли бега, он счетно-адидитивен, поэтому это вероятностная мера.
[41:58.120 --> 42:10.120]  Мы умеем единственным образом продолжать функцию распределения на распределение вероятности, поэтому она совпадает с p.
[42:10.120 --> 42:16.120]  Ещё раз. Давайте возьмём какую-то...
[42:16.120 --> 42:22.120]  Вот мы не знаем, что это p, что p от b равно этой штуке, мы не знаем, мы ещё не доказали.
[42:22.120 --> 42:27.120]  Рассмотрим функцию p с волной, которая множеству b ставит в соответствии такой интеграл.
[42:27.120 --> 42:38.120]  На лучах это совпадёт, то есть p с волной от минус бесконечности до x, оно совпадает с p от минус бесконечности до x.
[42:38.120 --> 42:43.120]  Это по определению. Мы говорим, что наш функция распределения равна этой штуке.
[42:43.120 --> 42:49.120]  Поэтому эти штуки на лучах совпадают, но при этом p с волной это тоже вероятность.
[42:49.120 --> 42:54.120]  Интеграл является счетно-адидитивным. Если вы будете такие интегралы складывать по непересекающимся множеству,
[42:54.120 --> 43:02.120]  вы получите интеграл по объединению этих множеств. Поэтому p с волной это вероятность.
[43:02.120 --> 43:12.120]  А раз p с волной это вероятность, и p это вероятность, и они совпадают на лучах, значит они совпадают везде.
[43:12.120 --> 43:15.120]  А значит p равно p с волной.
[43:15.120 --> 43:32.120]  Теперь по поводу того, откуда эту плотность взять и в каких случаях она вообще существует.
[43:32.120 --> 43:38.120]  Есть замечательное утверждение, что если функция f дифференцируема, то p это производ от неё.
[43:38.120 --> 43:43.120]  Ну я думаю, это всем очевидно. Есть такая формула Ньютна-Лебница.
[43:43.120 --> 43:47.120]  Давайте я это запишу.
[43:47.120 --> 43:50.120]  Чего?
[43:50.120 --> 44:01.120]  Ну доказали? Я не говорю, что формула Ньютна-Лебница очевидна. Я говорю, что из неё это очевидно следует.
[44:01.120 --> 44:06.120]  Но вы её ещё не в полной общности доказали.
[44:06.120 --> 44:11.120]  Вы доказали для абсолютно неприимных функций или для дифференции? А, для абсолютно неприимных. Прекрасно.
[44:11.120 --> 44:17.120]  Прекрасно, да. Ну вообще замечательно.
[44:17.120 --> 44:21.120]  Вообще замечательно. Да, значит утверждение. Вы это знаете.
[44:21.120 --> 44:34.120]  Если f дифференцируемо, то сказать, что плотность равна производной, конечно, не совсем правильно.
[44:34.120 --> 44:39.120]  Потому что это определение не предполагает единственности плотности.
[44:39.120 --> 44:49.120]  Оно говорит, вот плотность это такая функция. Кстати, я не написал. Эта функция называется плотностью.
[44:49.120 --> 44:54.120]  Определение такое, плотность это такая функция, что выпнут это равенство.
[44:54.120 --> 44:59.120]  Ну понятно, что таких функций дофига. В частности, я могу взять и в одной точке изменить его значение.
[44:59.120 --> 45:02.120]  От этого это никак на этот интеграл не повлияет.
[45:02.120 --> 45:11.120]  Поэтому таких функций много, и формально надо говорить, что не тогда плотность равна, а в качестве плотности можно выбрать.
[45:11.120 --> 45:14.120]  Но если я буду говорить, что плотность равна, я буду это иметь в виду.
[45:14.120 --> 45:26.120]  То есть можно говорить, что есть у нас класс эквивалентности, что вот те плотности, которые подходят для одного и того же распиления, они образуют один класс эквивалентности.
[45:26.120 --> 45:32.120]  Я беру любого представителя и равенство здесь воспринимаю именно как равенство классов эквивалентности.
[45:32.120 --> 45:35.120]  И в этом смысле я могу говорить про равенство.
[45:35.120 --> 45:40.120]  И я просто напишу, что плотность производного функции распиления.
[45:40.120 --> 45:53.120]  Что, очевидно, следует из формулы Ньюта-Лебницы. Если вы сюда подставите производный функции распиления, вы получите верное равенство.
[45:53.120 --> 46:08.120]  Еще одно утверждение, что вот было у нас утверждение, что если есть функция распиления, то бишь функция, которая обладает тремя свойствами, то она является функцией распиления для некоторого распиления вероятности.
[46:08.120 --> 46:14.120]  То же самое можно сказать про плотность. Возьмем вообще произвольную функцию вот такую.
[46:14.120 --> 46:18.120]  Тогда она единственным образом задает некоторое распиление вероятности.
[46:18.120 --> 46:40.120]  Значит, пусть P действует из R в R+, и интеграл от P равен единице, тогда существует единственное распиление вероятности P.
[46:40.120 --> 46:50.120]  Такое, что P маленькая это его плотность.
[46:50.120 --> 47:07.120]  Ну тоже, в общем-то, несложно. Давайте это аккуратно докажем.
[47:07.120 --> 47:17.120]  Ну смотрите, если мы однозначным образом восстановим функцию распределения, то мы, конечно, однозначным образом восстановим и распиление вероятности.
[47:17.120 --> 47:29.120]  Ну давайте просто положим f от x равно интегралу от минус бесконечности до x пт dt.
[47:29.120 --> 47:38.120]  Имеем право, так как у нас интеграл по всему R есть, и так как функция не отрицательна, то мы можем интегрировать по любому подмножисту по определению интеграла Либега.
[47:38.120 --> 47:43.120]  Никаких проблем здесь нет. Поэтому такая функция, конечно, существует, мы можем ее определить.
[47:44.120 --> 47:51.120]  Что осталось? Осталось проверить, что три свойства выполнены. Если выполнено три свойства функции распиления, то все доказано.
[47:51.120 --> 47:56.120]  Свойства номер один говорит, что f не убывает.
[47:56.120 --> 48:11.120]  Значит, если x меньше, чем y, то, ну понятно, разность этих интегралов, это в точности интеграл от x до y,
[48:11.120 --> 48:18.120]  f от t до t. И так как p не отрицательно, то и интеграл тоже не отрицательный. Прекрасно. Значит, функция не убывает.
[48:42.120 --> 48:45.120]  Еще что? Непрерывность справа.
[48:51.120 --> 48:55.120]  Непрерывность справа. Что-что?
[48:56.120 --> 49:00.120]  Непрерывность справа. Что-что?
[49:04.120 --> 49:10.120]  Да. Сюда. Вместо p подставляем f'.
[49:15.120 --> 49:20.120]  f от минус бесконечности это ноль по свойствам функции распиления.
[49:21.120 --> 49:30.120]  Это не нагло, это дано. Если f функция распиления здесь имеет в виду, не просто оба какая функция дифференцируемая,
[49:30.120 --> 49:36.120]  тогда это утверждение бессмысленное. Значит, утверждение такое, пусть есть распределение, у него есть функция распиления f,
[49:36.120 --> 49:42.120]  которая дифференцируема, тогда плотность этого распиления можно найти как производная функция распиления.
[49:51.120 --> 49:58.120]  Ну, вообще, здесь будет не просто непрерывность справа, здесь будет просто непрерывность. И слева, и справа везде.
[49:58.120 --> 50:15.120]  Если вы считаете предел при х, стремящемся к x0, f от x, то бишь, предел при х, стремящемся к x0, интеграл от минус бесконечности
[50:15.120 --> 50:27.120]  f от минус бесконечности до х, f от t dt, то по тереме Лебега это есть интеграл от минус бесконечности до x0,
[50:27.120 --> 50:41.120]  f от t dt. По тереме Лебега вы можете менять местами пределы интегралов. Вот, что я и сделал, и это есть f от x0.
[50:41.120 --> 50:56.120]  Что? Чем-то ограничиваясь сверху. Мы можем самой функции p ограничить.
[50:56.120 --> 51:04.120]  Мы здесь берем функцию p не на всем r, и мы ее ограничим функцией p на всем r, который не отрицательный.
[51:04.120 --> 51:14.120]  У нас за счет того, что p не отрицательный, нам не надо ничего ограничить. У нас там еще лемма фату есть и прочее, которые там говорят, что если у нас ограниченность снизу, то нам не надо ограничивать везде.
[51:14.120 --> 51:24.120]  То есть, если у нас функция не отрицательная, то мы можем ее пользоваться. Если мы хотим прямо явно применять терема Лебега, мы ее можем ограничить самой вот этой функцией p от t, но на всем r.
[51:24.120 --> 51:34.120]  Ну, формально смотрите, что у нас тут написано. Давайте чуть аккуратнее напишу, чтобы вы увидели, что это явно я применяю терема Лебега.
[51:34.120 --> 51:43.120]  Можно левее применять, да. Но вот я все это не помню на самом деле, всех этих там лемм. То есть, если я сейчас сяду, я, конечно, докажу терема Лебега за какое-то ограниченное время.
[51:43.120 --> 51:51.120]  Но я помню терема Лебега, и в принципе, можно там во многих ситуациях, конечно, к ней сводить, и вот здесь тоже можно. Вы правы, что можно без этого обойтись.
[51:51.120 --> 51:59.120]  Но давайте я покажу на всякий случай, как это сводится к тереме Лебега.
[51:59.120 --> 52:04.120]  Значит, давайте будем говорить про интеграл от меня за бесконечность до бесконечность.
[52:04.120 --> 52:11.120]  Тогда вместо p-ми нужно написать p от t умножить на индикатор того, что t меньше 0, чем x.
[52:11.120 --> 52:18.120]  Да, и вот у меня есть на самом деле последовательность таких функций по разным их сам.
[52:18.120 --> 52:26.120]  И все они ограничены функцией p от t. Давай вот эта штука на меньше 0, чем p от t.
[52:26.120 --> 52:29.120]  Я не должен никакой модуль ставить, она не отрицательна, тут все хорошо.
[52:29.120 --> 52:37.120]  И интеграл p от t по условияр n единицы, поэтому я могу применять терема Лебега и заношу внутрь интеграла предел.
[52:37.120 --> 52:58.120]  Ну, предел этой функции, это есть просто p от t умножить на индикатор того, что t меньше 0, чем x0.
[52:58.120 --> 53:11.120]  А это есть искомый интеграл от минус бесконечности до x0, p от t до t, что и требуется.
[53:11.120 --> 53:18.120]  Вот, но то же самое в минус бесконечности и в плюс бесконечности, вы просто применяете терема Лебега.
[53:19.120 --> 53:22.120]  Ну, например, в плюс бесконечности.
[53:22.120 --> 53:46.120]  Опять вы меняете местами интеграл и предел и получаете просто интеграл от минус бесконечности
[53:46.120 --> 53:50.120]  до плюс бесконечности, что равно единице.
[53:57.120 --> 54:01.120]  Ну и с нулем то же самое.
[54:01.120 --> 54:18.120]  А это есть предел при x от минус бесконечности, интеграл от минус бесконечности до x, p от t до t.
[54:18.120 --> 54:24.120]  Опять меняем местами интеграл и предел, получая 0.
[54:31.120 --> 54:39.120]  Погейно, да. То есть я беру любую подпоследовательность на самом деле.
[54:39.120 --> 54:48.120]  Имея это в виду в голове, я беру любую подпоследовательность, любую последовательность стремяческих с 0 и все это проделываю.
[54:48.120 --> 54:53.120]  Но давайте не будем опускаться до полного формализма в этом плане.
[54:53.120 --> 55:03.120]  Не так понятно, что теория Малибега о мажоривом исходимости обобщается не только на последовательности, но и на такие пределы просто из-за определения предела по геймерам.
[55:12.120 --> 55:19.120]  Ну прекрасно. Смотрите, как здорово. Здорово что? Здорово то, что мы можем считать всякие вероятности, имея плотность.
[55:19.120 --> 55:23.120]  Ну во-первых, если у нас есть плотность, она задает распределение вероятностей.
[55:23.120 --> 55:26.120]  То есть вместо того, чтобы функцию распределения задавать, можно просто плотность задать.
[55:26.120 --> 55:31.120]  Мы сейчас увидим, что это естественно и во многих ситуациях гораздо проще.
[55:35.120 --> 55:45.120]  Чего? Единственное. Смотрите, что я доказал. Я доказал, что вот эта штука это функция распределения.
[55:45.120 --> 55:50.120]  Давайте где-то допишу, да? Я положил вот это, и то, что я только что доказал.
[55:50.120 --> 55:54.120]  Это то, что это функция распределения. Вот.
[55:54.120 --> 55:57.120]  Функция распределения единственным образом восстанавливает распределение.
[56:06.120 --> 56:10.120]  Она единственным образом восстанавливает распределение. То есть во-первых, вы единственным образом восстановили F.
[56:10.120 --> 56:17.160]  F. По определению F должна быть такая, что вот такая должна быть F. Чтобы P была плотность,
[56:17.160 --> 56:22.000]  F должна быть вот такой. И мы ее такой и взяли. Никакой другой F быть не может. Мы никакую другую
[56:22.000 --> 56:26.800]  функцию распределения получить не могли. А из F P восстановились единственным образом,
[56:26.800 --> 56:45.360]  ну значит оно действительно единственное. Да, что я там говорил? Я говорил, что ну прекрасно,
[56:45.360 --> 56:49.080]  вот мы можем во-первых, теперь когда будем какие-то примеры разбирать, мы можем сказать,
[56:49.080 --> 56:52.440]  а давайте возьмем такую плотность, и вот это будет какое-нибудь распределение с каким-то
[56:52.440 --> 56:56.440]  красивым названием. Это первое, что мы можем делать. А второе, что мы можем делать, это вероятность.
[56:56.560 --> 57:01.480]  С помощью вот этого свойства мы можем убирать с любого множества. Почитайте,
[57:01.480 --> 57:11.880]  если у нас есть плотность. Давайте этим мы займемся. Ну, начну я с примера равномерного
[57:11.880 --> 57:20.440]  распределения. Я не зря говорил про эту ситуацию, а давайте мы разобьем отрезок 0,1 на n под
[57:20.440 --> 57:24.520]  отрезочков и будем менять бесконечности в пределе… Сначала у нас есть равномерное
[57:24.520 --> 57:28.400]  распределение в этих точках, в пределе типа получим равномерное распределение на всем отрезке.
[57:28.400 --> 57:31.280]  Вот давайте с равномерного распределения на отрезке начнем.
[57:45.280 --> 57:50.600]  Начнем с равномерного распределения на отрезке от A до B. Ну, в принципе, вы можете в качестве,
[57:50.680 --> 57:55.160]  вот этот отрезок – это параметр распределения, вы в качестве этого параметра можете брать не
[57:55.160 --> 57:59.040]  только отрезок, вы можете взять, например, интервал. Или вы можете взять несколько отрезков,
[57:59.040 --> 58:05.280]  не пересекающихся, объединить их, и на нем сдать равномерное распределение. Все по аналогии. Но я
[58:05.280 --> 58:10.120]  здесь не пытаюсь какую-то общую картину показать, просто какие-то примеры, чтобы это было проще
[58:10.120 --> 58:16.080]  почувствовать. Если я тут кучу интервалов сейчас напишу, будет сложнее это почувствовать. Что это такое?
[58:16.080 --> 58:21.080]  Ну, распределение равномерное вполне естественно положить, что плотность просто одинакова во всех
[58:21.080 --> 58:28.200]  точках этого отрезка. Что такое плотность? Ну, это как масло вы на хлеб мажете. Если вы
[58:28.200 --> 58:33.200]  мажете масло на хлеб, то где-то масло мало, где-то масло много. Где там много масла, там у вас
[58:33.200 --> 58:39.880]  больше вероятности. Где у вас мало масла, там у вас меньше вероятности. А плотность – это высота
[58:39.880 --> 58:45.600]  вашего масла. Разрежьте посередине, посмотрите, а вот здесь вот большая высота, здесь много масла,
[58:45.600 --> 58:52.240]  здесь меньше. И в любом месте вашего бутерброда у вас вероятность будет равна просто количеству
[58:52.240 --> 58:57.680]  масла, которое у вас в этом месте намазано, и это будет интеграл от высоты этого масла. Поэтому
[58:57.680 --> 59:00.960]  чем больше у вас плотность, тем у вас больше вероятность в этом месте. Если вы хотите сделать
[59:00.960 --> 59:06.680]  равномерную вероятность, у вас плотность должна быть константой на всем вашем множестве. Как сделать
[59:06.680 --> 59:10.800]  плотность константой на всем этом множестве. Но у вас интеграл должен быть единиц равен.
[59:10.800 --> 59:26.600]  Да, надо единиц поделить на длину. Понятное дело, что рассуждение с маслом не является доказательством
[59:26.600 --> 59:31.760]  вот этого равенства. Это я просто его, чтобы была интуиция, откуда это берется, это определение.
[59:31.760 --> 59:37.840]  Это просто определение равномерного распиления на отрезке от A до B. И понятно, что если у вас будет
[59:37.840 --> 59:43.000]  любое другое множество, на котором вы можете задать равномерное распиление, вы просто скажете,
[59:43.000 --> 59:51.200]  что плотность это единиц поделить на меру этого множества, умножить на индикатор того,
[59:51.200 --> 01:00:00.160]  что вы в это множество попадаете. Хорошо, какая будет функция распиления, давайте посчитаем для
[01:00:00.160 --> 01:00:11.640]  упражнения. Ну, что надо делать по определению плотности? Надо проинтегрировать функцию распиления,
[01:00:11.640 --> 01:00:19.600]  есть интеграл от минус бесконечности до x. Ну, во-первых, понятно, что там, где нет бутерброда,
[01:00:19.600 --> 01:00:27.400]  там вероятность ноль. То есть, иными словами, если у вас эта точка х на левее чем А, туда отрезок
[01:00:27.400 --> 01:00:36.680]  Аб не попала никакая его часть, и значит, будет просто интеграл равен нулю. Вот так. Теперь,
[01:00:36.680 --> 01:00:45.880]  если попали, если ваш х попал в отрезок от A до B, вы просто интегрируете от A до х 1 поделить на
[01:00:45.880 --> 01:01:03.520]  B-A dt при х от A до B. Ну, если вы попали правее точки B, то ваш отрезок попал целиком внутрь
[01:01:03.520 --> 01:01:12.400]  интеграла, значит, будет единица при х больше чем B. Вот, но здесь, если посчитать, получится что?
[01:01:12.400 --> 01:01:24.120]  Получится х-а поделить на B-а. Ну, то есть, получаем, что функция распиления на отрезке от А до B это отрезок
[01:01:24.120 --> 01:01:30.600]  прямой, что естественно, раз у вас распределение является равномерным. У вас должна линейно
[01:01:30.600 --> 01:01:49.560]  накапливаться вероятность с ростом х. Значит, до А это ноль, а в точке B это один, и дальше,
[01:01:49.560 --> 01:01:56.800]  и между А и B это просто отрезок прямой. Вот, хочу обратить внимание, что эта функция не является
[01:01:56.800 --> 01:02:01.520]  дифференцируемой. Да, у нее есть вот эта точка A и точка B, в которых она не дифференцируема, так что в явном
[01:02:01.520 --> 01:02:06.880]  виде пункт один, вот это утверждение, извиняюсь, один, которое там слева в углу написано, его нельзя
[01:02:06.880 --> 01:02:11.920]  прямо тут взять и прямо вот ни о чем не думая применить. То есть, я имею в виду, что если у вас такая
[01:02:11.920 --> 01:02:15.240]  функция распиления есть, вы по этому утверждению не можете прямо сразу сказать, ага, ну, значит,
[01:02:15.240 --> 01:02:22.720]  плотность равна вот этому. А давайте продиференцируем на этих участках. Но на самом деле, вы уже умные,
[01:02:22.720 --> 01:02:26.720]  вы уже прекрасно знаете, что если у вас есть такая ситуация, когда у вас кусочно дифференцируемая
[01:02:26.720 --> 01:02:32.120]  функция, у вас есть какие-то точки, в которых производа не существует, но в них функция непрерывна,
[01:02:32.120 --> 01:02:35.840]  то все хорошо, можно на всех этих участках продиференцировать и вы все равно получите плотность.
[01:02:35.840 --> 01:02:40.480]  То есть, на самом деле, можно продиференцировать на каждом из этих участков и получить плотность.
[01:02:40.480 --> 01:02:46.840]  Так, это равномерное распределение. Ну, пояснять, наверное, нечего, естественная вещь, давайте
[01:02:46.840 --> 01:02:57.680]  двинемся дальше. Нормальное распределение. Вот тут с ходу нормальность нормального распиления
[01:02:57.680 --> 01:03:07.360]  не очевидна. Ну, и под нормальность я подразумеваю адекватность. Сейчас какая-то страшная формула будет,
[01:03:07.360 --> 01:03:13.320]  но я объясню, откуда она берется, пока на пальцах, но в курсе у нас будет теорема, которая называется
[01:03:13.320 --> 01:03:16.960]  центральная предельная теорема. У меня сейчас пока не хватает инструментов, чтобы ее доказать,
[01:03:16.960 --> 01:03:23.920]  но они появятся. Вот, поэтому я просто объясню на пальцах, откуда это берется, а формулу мы пока
[01:03:23.920 --> 01:03:51.400]  запомним. Формула для плотности, я имею в виду. Так, второе. Это буква N, если что. Значит, это
[01:03:51.400 --> 01:03:56.720]  нормальное распиление с параметром a и sigma квадрат. Значит, почему sigma квадрат? Ну, потому что
[01:03:56.720 --> 01:04:02.920]  второй параметр положительный. Значит, а это какое-то действительное число, а sigma квадрат это какое-то
[01:04:02.920 --> 01:04:07.800]  положительное число. И это такое неразрывное определение sigma и сверху двоечка. Это просто
[01:04:07.800 --> 01:04:11.800]  объединение, просто sigma не пишут. Если вы хотите корень из этого взять, ну, вы так пишете, корень и
[01:04:11.800 --> 01:04:17.920]  sigma квадрат. Цельное обозначение. Значит, как дается плотность? Ну, плотность дается вот так.
[01:04:17.920 --> 01:04:32.080]  Единиц поделить на корень из 2 pi sigma в квадрате, e в степени минус xt, t минус a в квадрате,
[01:04:32.080 --> 01:04:44.180]  делить на 2 sigma в квадрате. Ну вот, да, такая вот странная формула плотности. Для начала нужно
[01:04:44.180 --> 01:04:51.600]  поверить, что интеграл от него равен единице. Давайте поверим. Но я не знаю, вам доказывали,
[01:04:51.600 --> 01:04:57.680]  а у вас комплексного анализа не было, да? Ну, не важно. В общем, есть инструменты, которые позволяют
[01:04:57.680 --> 01:05:01.080]  доказать, что интеграл от этой штуки равен единице. В принципе, это несложное утверждение.
[01:05:01.080 --> 01:05:13.840]  Интеграл Плассона, да. Или там еще как-нибудь по-разному называют. Ну понятно, да? И там всем известен,
[01:05:13.840 --> 01:05:19.480]  что интеграл от e в степени минус x в квадрате пополам, это корень из 2 pi. Вот. Дальше надо там, ну,
[01:05:19.480 --> 01:05:29.880]  заменку сделать. Получится, что интеграл от этой штуки это единица. Вот. Да, хорошо. Значит,
[01:05:29.880 --> 01:05:33.960]  откуда берется это нормальное распределение? Давайте посмотрим. Во-первых, давайте сначала
[01:05:33.960 --> 01:05:38.520]  нарисуем график этой плотности, чтобы это была не просто символная запись, чтобы мы это уже как
[01:05:38.520 --> 01:05:45.400]  картинку себе представляли. Значит, график плотности выглядит вот так. Вот есть точка А, это очень важная
[01:05:45.400 --> 01:05:56.600]  точка. Относительно вот такой прямой вертикальной наша плотность будет симметрична и будет
[01:05:56.600 --> 01:06:08.960]  выглядеть она вот как-то так. Будет выглядеть она как-то так. Да, она симметрична относительно вот
[01:06:08.960 --> 01:06:16.040]  этой прямой. И, значит, что такое А? Понятно, это точка, относительно которой симметрична. Что
[01:06:16.040 --> 01:06:22.400]  значит, что такое симму квадрат? Симму квадрат отвечает за то, насколько сильно у вас плотность
[01:06:22.400 --> 01:06:29.840]  прижата, насколько сильно она у вас прижата к А. Да, ну вот, смотрите, если я стигму начну
[01:06:29.840 --> 01:06:34.160]  увеличивать, вот если я А равно нулю поставлю, я чего получу? Я получу 1, посмотрите, на корень из 2 pi
[01:06:34.160 --> 01:06:40.360]  симму квадрат. Если я стигму начну увеличивать, эта штука начинает уменьшаться. То есть высота,
[01:06:40.360 --> 01:06:45.760]  высота этого горбика, она начнет уменьшаться, а сам горбик начнет шире становиться. То есть если я
[01:06:45.760 --> 01:06:50.440]  увеличиваю сигму, у меня эта штука становится ниже, а эта штука становится шире. Если я стигму уменьшаю,
[01:06:50.440 --> 01:06:59.680]  у меня вот эта штука становится выше, а сам график становится ужин. Значит, то есть сигма отвечает
[01:06:59.680 --> 01:07:05.240]  за разброс вероятности относительно этой прямой. Когда вы смотрите на плотность, вы понимаете,
[01:07:05.240 --> 01:07:09.200]  что ну окей, это у меня бутерброд, у меня это бутерброд на масло, на хлеб намазано, вот здесь
[01:07:09.200 --> 01:07:18.800]  дофига масла, а по краям мало. Да, поэтому чем у меня больше сигма, тем будет ровнее намазано
[01:07:18.800 --> 01:07:24.920]  масло. Чем у меня меньше сигма, тем больше будет масла в одном месте. То есть сигма это разброс
[01:07:24.920 --> 01:07:31.480]  относительно вот этого центра бутерброда, разброс вашей вероятности. Чем меньше сигмы, тем меньше разброс.
[01:07:31.480 --> 01:07:47.640]  Хорошо, значит теперь откуда это берется? При стремлении сигмы к нулю, это штука, когда эта
[01:07:47.640 --> 01:08:06.880]  функция сойдется. Сигма равно нулю. Сигма равно нулю, это вообще можно здесь написать сигму х2
[01:08:06.880 --> 01:08:12.440]  большего нуля и воспринимать ситуацию, когда сигма равно нулю, как тоже нормальное распределение.
[01:08:12.440 --> 01:08:17.680]  Нормальное распределение будет, на самом деле, просто одна точка, в которой вероятность равна
[01:08:17.680 --> 01:08:22.080]  единице. То есть если вы устремите сигму к нулю, вы в пределе получите, что вероятность точки
[01:08:22.080 --> 01:08:26.440]  А равно нулю равна единице. То есть это будет дискретное распределение, на самом деле всего с одним
[01:08:26.440 --> 01:08:32.240]  атомом. Вот есть одна точка, вероятность которой один, константа короче. И есть утверждение о том,
[01:08:32.240 --> 01:08:36.600]  что про сходимость распределения, что если у вас есть сходимость нормальных распределений,
[01:08:36.600 --> 01:08:41.320]  вы в пределе снова нормальное распределение получите. Поэтому ответ на ваш вопрос да, и тут есть
[01:08:41.320 --> 01:08:47.000]  некоторый смысл за этим, но мы об этом еще позже поговорим. Теперь откуда берется вот этого,
[01:08:47.000 --> 01:08:51.400]  ну как оно выглядит понятно, откуда он взялось. Вот смотрите, какой интересный парадокс. Если
[01:08:51.400 --> 01:08:59.600]  монетку много раз подбрасывать, ну вы знаете, что у вас теперь у авролаплаца была? Ну прекрасно,
[01:08:59.600 --> 01:09:03.960]  а вы знаете откуда это берется? Что я объясняю? Ну короче, да, если вы монетку много раз подбрасываете,
[01:09:03.960 --> 01:09:11.160]  то конечно примерно в половине случаев у вас будет решка. Короче, если вы миллион раз
[01:09:11.160 --> 01:09:15.160]  подбросите, поделите количество решек на миллион, получится ну примерно одна вторая. Насколько
[01:09:15.160 --> 01:09:28.800]  примерно? Насколько примерно отвечает на этот вопрос в частности т.е. мавролапласа? Я ее еще вам
[01:09:28.800 --> 01:09:38.680]  сформулирую в курсе и докажу попозже. Сейчас давайте еще раз послушаем. Вот примерно в половине
[01:09:38.680 --> 01:09:42.040]  случаев у вас будет решка. В том смысле, что если вы количество решек поделите на миллион,
[01:09:42.040 --> 01:09:50.680]  то это будет примерно одна вторая. Насколько примерно? Ну вот получится там 0, 4, 9, 8 и что-нибудь
[01:09:50.680 --> 01:09:59.840]  еще скажем. Получится какое-нибудь такое число. А может ли получиться не 9, здесь а 7? Вероятность
[01:09:59.840 --> 01:10:05.000]  того, что что-нибудь такое получится, очень маленькое. С гораздо большей вероятностью здесь будет 9.
[01:10:05.000 --> 01:10:12.920]  И связано это с тем, что выполна следующее утверждение, что если вы посмотрите на количество решек,
[01:10:12.920 --> 01:10:18.840]  давайте назначим его за х, х это количество решек, миллион раз я подбросил, миллион раз я подбросил,
[01:10:18.840 --> 01:10:29.800]  я должен вычесть из этого половину миллиона, т.е. 500 тысяч и поделить это дело на корень из
[01:10:29.800 --> 01:10:48.760]  250 тысяч, т.е. на 500, то это будет примерно нормальная случайная величина. Что это значит? Это значит,
[01:10:48.760 --> 01:10:56.680]  что если я посмотрю на вероятность того, что эта штука лежит между А и B, то это будет примерно.
[01:10:56.680 --> 01:11:03.400]  Есть, я здесь не имею в виду ничего строго, когда я пишу это пример, на самом деле есть
[01:11:03.400 --> 01:11:07.640]  прямо утверждение о том, насколько сильно мы здесь ошибаемся. Вот здесь можно нечто
[01:11:07.640 --> 01:11:14.000]  точное написать вместо этого примерно. 1 поделить на корень из 2p интеграл, или давайте интеграл
[01:11:14.000 --> 01:11:18.760]  слева напишем. Интеграл от A до B, 1 поделить на корень из 2p, e в 7-t в квадрате в половину dt.
[01:11:18.760 --> 01:11:28.160]  Если вы посмотрите на это выражение, вместо sigma квадрат поставить единичку, а вместо
[01:11:28.160 --> 01:11:36.120]  подставить 0, вы получите ровно вот эту функцию, которая здесь написана. Причем здесь вот эта
[01:11:36.120 --> 01:11:41.560]  ошибка, но это на самом деле оно и есть. Я с помощью этого утверждения могу понять, насколько сильно я
[01:11:41.560 --> 01:11:50.400]  здесь ошибаюсь. Если я понимаю, что если я здесь напишу минус 3, а здесь 3, то это будет
[01:11:50.400 --> 01:12:02.640]  примерно 1. Да, это значит, что с очень большой вероятностью выполна вот это неравенство и
[01:12:02.640 --> 01:12:09.920]  значит х у меня лежит между 500 тысяч минус полторы тысячи и 500 тысяч плюс полторы тысячи, и вот
[01:12:09.920 --> 01:12:20.280]  отсюда у меня берется 0,498. Поэтому 4,47, вероятность этого крайне мала. Здесь должна быть девятка.
[01:12:20.280 --> 01:12:26.040]  Отсюда берется нормальное распределение. Вообще есть, мы сейчас про монетки говорили,
[01:12:26.040 --> 01:12:31.800]  но на самом деле центральная определенная теория, которую мы в курсе докажем, утверждает следующее,
[01:12:31.800 --> 01:12:37.520]  что какие у вас вообще ни были ваши независимые эксперименты, монетки, чего-либо еще, на
[01:12:38.080 --> 01:12:42.680]  значение температуры вы смотрите, то есть ваши случайные объекты могут непрерывно распределены
[01:12:42.680 --> 01:12:49.160]  быть, как угодно еще. Если вы делаете эксперименты независимо, то получается то же самое. Если вы
[01:12:49.160 --> 01:12:55.160]  считаете количество успехов или еще что-нибудь связанное с N независимым экспериментами,
[01:12:55.160 --> 01:12:59.960]  вы получите тоже в пределе нормальный закон. Вот отсюда берется нормальное распределение.
[01:12:59.960 --> 01:13:05.640]  Эта ситуация, когда А равна нулю аси мх единицы, это называется стандартное нормальное распределение.
[01:13:05.640 --> 01:13:27.480]  Значит N01, стандартное нормальное распределение. Вот, что можно сказать про пункцию распределения.
[01:13:27.480 --> 01:13:32.640]  Ну, что можно хорошенько сказать? Ну, это интеграл от плотности, ничего лучшего не скажешь,
[01:13:32.640 --> 01:13:37.480]  ожидая интеграл, это штуки не берется. Но можно нарисовать график. Вот если плотность
[01:13:37.480 --> 01:13:45.760]  выглядит вот так, то функция распределения выглядит следующим образом. Опять,
[01:13:45.760 --> 01:13:54.760]  давайте отметим точку А и подумаем вот о чем. Значит у нас этот график симметричный, поэтому
[01:13:54.760 --> 01:14:00.200]  слева от этой прямой и справа от этой прямой одинаковое количество вероятности. То есть раз
[01:14:01.000 --> 01:14:07.920]  сумме должно быть единицы, значит здесь вот одна вторая, и здесь тоже одна вторая. Вероятность попа,
[01:14:07.920 --> 01:14:11.560]  с иными словами, вероятность попасть в интервал от минус бесконечности до А,
[01:14:11.560 --> 01:14:16.320]  совпадает с вероятностью попасть в интервал от А до плюс бесконечности. Ну,
[01:14:16.320 --> 01:14:19.920]  а это и есть функция распределения в точке А. То есть значение функции распределения в точке А,
[01:14:19.920 --> 01:14:31.640]  одна вторая. Вот, и дальше понятно, что график должен быть симметричен относительно этой точки.
[01:14:31.640 --> 01:14:38.780]  Правда же? Ну, что я имею в виду? Я имею в виду, что если я возьму вот такую точку, отступлю от
[01:14:38.780 --> 01:14:46.520]  а на какой-нибудь епсилон, влево и вправо, то площадь вот здесь будет совпадать с площадью
[01:14:46.520 --> 01:14:59.720]  вот здесь. Да, то есть иными словами f от x и 1 минус, сейчас, f от a минус x и 1 минус f от a плюс x
[01:14:59.720 --> 01:15:09.320]  это одно и то же. То есть эта функция, она будет выглядеть вот так. Сейчас. Значит, вот так. А здесь
[01:15:09.320 --> 01:15:16.280]  она ломается как бы, да, потом идет вот так. Не ломается, а перегибается, правильнее сказать.
[01:15:16.280 --> 01:15:21.680]  Вот так будет выглядеть функция распределения и понятность, за что будет отвечать sigma. За ту же
[01:15:21.680 --> 01:15:27.200]  самую прижатость вот к этой прямой. Да, с одной стороны, вы можете прижиматься к этой прямой,
[01:15:27.200 --> 01:15:33.880]  с другой стороны, вы можете от нее отдаляться. Вот. Чем у вас больше sigma, тем вы сильнее от нее
[01:15:33.880 --> 01:15:40.120]  отдаляйтесь, чем она меньше, тем вы сильнее к ней прижимаетесь. Вот. Ну, давайте еще одно распределение
[01:15:40.120 --> 01:15:55.360]  и на этом закончим. Ну, она есть. Неспроста я 3 написал, да. Так, экспоненциальное распределение.
[01:15:55.360 --> 01:16:02.920]  Вот это распределение опять отсыл.. Здесь видите то же самое лямбда, что было в полусалонском
[01:16:02.920 --> 01:16:07.920]  устранении, это неспроста. Это опять отсылка к этой теории массового обслуживания. И вот здесь я
[01:16:07.920 --> 01:16:14.800]  уже не буду, будьте здоровы, и вот здесь я уже не буду какие-то строгие вещи доказывать, я просто
[01:16:14.800 --> 01:16:20.160]  скажу, что вот есть некоторое свойство этого экспоненциального распределения о потере памяти,
[01:16:20.160 --> 01:16:26.640]  и значит, оно за счет этого свойства хорошо моделируется вот те же самые системы массового
[01:16:26.640 --> 01:16:32.240]  обслуживания, а именно за экспоненциальное распределение, за экспоненциальное распределение
[01:16:32.240 --> 01:16:42.600]  отвечает вероятность того, что за заданный интервал времени кто-нибудь зайдет. Сейчас,
[01:16:42.600 --> 01:16:46.720]  правильно? Нет, неправильно говорю. Значит, за экспоненциальное распределение отвечает момент
[01:16:46.720 --> 01:16:52.400]  первого захода человека. Вот у вас дошел кто-нибудь в Макдональдс, и вы начинаете считать время,
[01:16:52.400 --> 01:16:57.520]  когда следующий зайдет, и вот это время, оно имеет экспоненциальное распределение. Что это значит?
[01:16:57.520 --> 01:17:01.760]  Значит, оно экспоненциально уменьшается с ростом времени, чем больше происходит времени,
[01:17:01.760 --> 01:17:08.600]  тем меньше вероятность, и уменьшается она экспоненциально. То есть плотность вот такая,
[01:17:08.600 --> 01:17:18.320]  ну, на индикаторе того, что t не отрицательна. Значит, у вас не может быть отрицательное время,
[01:17:18.320 --> 01:17:23.840]  вот у вас один чувак зашел, вы смотрите, когда следующий зайдет, и время между ними,
[01:17:23.840 --> 01:17:27.680]  оно, конечно, не отрицательное, поэтому здесь стоит этот индикатор. Этот параметр лямбда
[01:17:27.680 --> 01:17:32.560]  нужен для того, чтобы распределение может быть разным. Нужен какой-то параметр, это просто скорость
[01:17:32.560 --> 01:17:38.000]  экспоненциального убывания к нулю. А здесь лямбда возникает просто из-за того, чтобы интеграл
[01:17:38.000 --> 01:17:41.880]  должен быть равен единице. Вы хотите эту штуку проинтегрировать, получить единицу, поэтому здесь лямба стоит.
[01:17:41.880 --> 01:17:50.880]  Давайте найдем функцию распределения. Ну, функцию распределения, напомню, это интеграл от минус
[01:17:50.880 --> 01:18:05.120]  бесконечности до x плотности, и это есть что? Это есть 1 минус e в степени минус лямбда x,
[01:18:05.120 --> 01:18:14.640]  умножительный индикатор того, что x не отрицательна. Ну, можно график нарисовать,
[01:18:14.640 --> 01:18:22.440]  значит, плотность будет выглядеть вот так, в точке 0 лямбда, и дальше она экспоненциально
[01:18:22.440 --> 01:18:40.240]  убывает, это плотность, а функция распределения, значит, в нуле 0, до нуля тоже 0, а потом она вот
[01:18:40.240 --> 01:18:50.520]  так себя ведет. Да, у нее есть излом в нуле, в нуле она формально не дифференцируема, вот дальше она
[01:18:50.520 --> 01:19:02.640]  экспоненциально стремится к единице. Есть какие-то вопросы? Это плотность, это функция распределения.
[01:19:11.240 --> 01:19:19.640]  Так, ну, в общем-то, времени осталось немного, на этом я, наверное, закончу, но напоследок пару слов
[01:19:19.640 --> 01:19:24.000]  скажу про многомерное распределение, которым мы сейчас плавно перейдем. Я в прошлый раз о них
[01:19:24.000 --> 01:19:29.080]  начал говорить, давайте я закончу на том же самом, на чем я в прошлый раз закончил, значит,
[01:19:29.080 --> 01:19:33.840]  многомерное распределение тоже есть функция распределения. Давайте я это запишу и на этом закончу.
[01:19:33.840 --> 01:19:42.360]  А то вы там на семинарах сейчас многомерное распределение начнете разбирать, чтобы у вас
[01:19:42.360 --> 01:19:51.800]  осталось с лекцией интуиция того, что там происходит. Значит, все очень просто, потому что все
[01:19:51.800 --> 01:19:57.680]  аналогично. Одномерное распределение, это просто частный случай многомерного распределения, да,
[01:19:57.680 --> 01:20:05.200]  я напомню, что многомерное распределение это просто вероятностная мера на баррелиско-сигма
[01:20:05.200 --> 01:20:21.880]  алгебре ВРН. Вот, это н-мерное распределение. У него тоже есть функция распределения,
[01:20:21.880 --> 01:20:25.400]  и я сейчас определю и скажу, что он однозначно восстанавливает распределение, и на этом мы
[01:20:25.400 --> 01:20:36.080]  закончим. Начнёт следующий объект. Это функция, которая действует из РН в 0,1. Следующим образом f
[01:20:36.080 --> 01:20:44.320]  от x1 от далее xn, да, теперь у нас n аргументов, это есть вероятность декартового произведения
[01:20:44.320 --> 01:20:54.360]  лучей от минус бесконечности dx1 и так далее от минус бесконечности dxn. Значит, утверждение,
[01:20:54.360 --> 01:21:12.240]  что она однозначно соответствует распределению вероятностей, то есть если p1, p2 распределение
[01:21:12.240 --> 01:21:33.680]  с функциями распределения f1, f2 и f1 совпадает с f2, то и p1 тоже совпадает с p2. Вот. И вот там
[01:21:33.680 --> 01:21:38.040]  будет всё то же самое, дискретный, абсолютно непрерывный свойств, из которых всё однозначно
[01:21:38.040 --> 01:21:44.480]  восстанавливается. Дальше будет всё аналогично, значит, ну и это мы обсудим в следующий раз.
[01:21:44.480 --> 01:21:52.680]  Есть какие-то вопросы? Если вопросов нет, то всем спасибо, до следующей пятницы. Кубота.
