[00:00.000 --> 00:08.000]  Вроде со связью все пока что нормально, будем надеяться, так и продолжится.
[00:08.000 --> 00:14.000]  Сегодня мы продолжаем говорить про виды задач в буквооптимизации.
[00:14.000 --> 00:18.000]  Начнем с классического линейного программирования.
[00:18.000 --> 00:28.000]  Сегодня я стараюсь писать на доске, если потребуется я переключусь на слайды.
[00:28.000 --> 00:34.000]  Надеюсь, что получится обойтись доской сегодня.
[00:34.000 --> 00:38.000]  Важно, что целевая функция линейная.
[00:38.000 --> 00:42.000]  В наших задачах всегда ограничение равенства только линейные,
[00:42.000 --> 00:46.000]  но вместе с тем ограничение неравенства тоже линейные.
[00:46.000 --> 00:52.000]  Важно, что это стандартный вид задачи.
[00:52.000 --> 01:00.000]  Очень много различных преобразований для того, чтобы какие-то другие виды задач.
[01:00.000 --> 01:04.000]  Можно сказать, что...
[01:04.000 --> 01:06.000]  Вот рассмотреть вот такую вот задачу.
[01:06.000 --> 01:10.000]  AX равно B, CX меньше либо равно D.
[01:10.000 --> 01:14.000]  Такая задача может быть приведена к такой задаче.
[01:14.000 --> 01:16.000]  Давайте посмотрим, как это делается.
[01:16.000 --> 01:18.000]  Смотрите, что надо сделать.
[01:18.000 --> 01:20.000]  Целевая функция, понятно, не изменится.
[01:20.000 --> 01:22.000]  Целевая функция, понятно, не изменится.
[01:22.000 --> 01:26.000]  Вся магия произойдет с функциями, которые ограничение задают.
[01:26.000 --> 01:30.000]  То есть надо CX плюс некоторая переменная U равна D.
[01:30.000 --> 01:32.000]  При этом U станет больше либо равно нуля.
[01:32.000 --> 01:38.000]  То есть мы, по сути дела, избавились от ограничений неравенств,
[01:38.000 --> 01:42.000]  в которых конфигурировала некоторая матрица.
[01:42.000 --> 01:44.000]  Понятен этот переход.
[01:44.000 --> 01:46.000]  У нас что-то меньше другого.
[01:46.000 --> 01:48.000]  Мы добавляем некоторый вектор положительный по компонентам.
[01:48.000 --> 01:50.000]  По компонентам, поэтому становится равенство.
[01:50.000 --> 01:52.000]  Поставьте минус, если непонятно.
[01:52.000 --> 01:54.000]  Ну окей, вроде минусов пока таких нет.
[01:54.000 --> 01:56.000]  Быстрых.
[01:56.000 --> 01:58.000]  Ну а дальше что?
[01:58.000 --> 02:02.000]  Вот это вот две штуки, это по сути означает, что у нас вот такая вот система.
[02:02.000 --> 02:06.000]  Из блочных матриц, которые умножаются на такой вот новый вектор.
[02:06.000 --> 02:08.000]  И тут B и D, соответственно.
[02:08.000 --> 02:10.000]  Вроде я ничего не попутал.
[02:10.000 --> 02:12.000]  Переменные у нас U больше либо равно нуля.
[02:12.000 --> 02:14.000]  А тут у нас...
[02:14.000 --> 02:16.000]  То есть вот тут есть некоторое разночтение.
[02:16.000 --> 02:18.000]  И на x у нас никаких ограничений нет.
[02:18.000 --> 02:20.000]  В этом случае надо сказать следующее, что x можно...
[02:20.000 --> 02:22.000]  То есть если у нас нет ограничений на знак,
[02:22.000 --> 02:26.000]  то мы можем представить соответствующую переменную как разность,
[02:26.000 --> 02:28.000]  типа v-w,
[02:28.000 --> 02:32.000]  где v больше либо равно нуля и w больше либо равно нуля.
[02:32.000 --> 02:36.000]  Соответственно, подставляя вот это выражение вместо x,
[02:36.000 --> 02:38.000]  мы получаем итоговую задачу.
[02:38.000 --> 02:40.000]  Минимум c, видимо...
[02:40.000 --> 02:44.000]  Ну да, в общем, c транспонированное v-w.
[02:44.000 --> 02:46.000]  То есть что у нас чего?
[02:46.000 --> 02:50.000]  v-w-u больше либо равно нуля.
[02:50.000 --> 02:54.000]  И матрица преобразуется в a0,
[02:54.000 --> 02:56.000]  что там, c,
[02:56.000 --> 02:58.000]  единичная.
[02:58.000 --> 03:00.000]  Вот здесь образуется v-w,
[03:00.000 --> 03:02.000]  здесь образуется u.
[03:02.000 --> 03:04.000]  Ну и понятно, что раз у нас
[03:04.000 --> 03:06.000]  образовалось три переменных,
[03:06.000 --> 03:08.000]  то матрица будет 3 на 3.
[03:08.000 --> 03:10.000]  Это равняется BD.
[03:10.000 --> 03:12.000]  Ну то есть что надо сделать?
[03:12.000 --> 03:14.000]  Это...
[03:14.000 --> 03:16.000]  Как правильно делать?
[03:16.000 --> 03:18.000]  Ну типа a-a, что ли, да?
[03:18.000 --> 03:20.000]  0, а тут будет c-с,
[03:20.000 --> 03:24.000]  а вектор будет v-w.
[03:24.000 --> 03:26.000]  Ну вроде так, да?
[03:26.000 --> 03:28.000]  Вроде ничему не противоречит.
[03:28.000 --> 03:30.000]  Равняется BD.
[03:30.000 --> 03:32.000]  Ну в общем, все как мы любим,
[03:32.000 --> 03:36.000]  в том плане, что число строк mn и m меньше n,
[03:36.000 --> 03:38.000]  поэтому там подпространство какое-то образуется.
[03:38.000 --> 03:40.000]  Ну и видно, что...
[03:40.000 --> 03:42.000]  Видимо, просто нет.
[03:42.000 --> 03:44.000]  Так, понятно ли преобразование,
[03:44.000 --> 03:46.000]  которое мы проделали,
[03:46.000 --> 03:48.000]  и тот результат, который получился?
[03:48.000 --> 03:50.000]  Поставьте плюс, если понятно, и минус, если нет.
[03:50.000 --> 03:52.000]  Ну окей, вроде всем все понятно, это прекрасно.
[03:52.000 --> 03:54.000]  Смотрите, что важно.
[03:54.000 --> 03:56.000]  Важно понимать, что, в принципе,
[03:56.000 --> 03:58.000]  все эти преобразования,
[03:58.000 --> 04:00.000]  они меняют структуру,
[04:00.000 --> 04:02.000]  но не приводят к тому,
[04:02.000 --> 04:04.000]  что у вас растет количество переменных,
[04:04.000 --> 04:06.000]  количество данных, которые надо хранить.
[04:06.000 --> 04:08.000]  То есть вам достаточно отследить,
[04:08.000 --> 04:10.000]  для нее нет ограничений никакого,
[04:10.000 --> 04:12.000]  то это значит, что в матрице,
[04:12.000 --> 04:14.000]  в структуре матрицы появятся
[04:14.000 --> 04:16.000]  не такие вот соответствующие блоки,
[04:16.000 --> 04:18.000]  при этом физически вы, понятное дело, их не дублируете.
[04:18.000 --> 04:20.000]  Физически у вас как было хранение матрицы,
[04:20.000 --> 04:22.000]  а так оно и осталось.
[04:22.000 --> 04:24.000]  Как у вас была матрица C,
[04:24.000 --> 04:26.000]  так она эта матрица C у вас здесь и осталась.
[04:26.000 --> 04:28.000]  То есть важно, чтобы
[04:28.000 --> 04:30.000]  если вдруг вы когда-нибудь
[04:30.000 --> 04:32.000]  надо будет что-то подобное реализовывать,
[04:32.000 --> 04:34.000]  что не надо ничего дублировать,
[04:34.000 --> 04:36.000]  надо просто грамотно прокидывать указатели
[04:36.000 --> 04:38.000]  то, как эти указатели взаимодействуют
[04:38.000 --> 04:40.000]  для соответствующих переменных.
[04:40.000 --> 04:42.000]  Ну, в общем, понятно, что размерность
[04:42.000 --> 04:44.000]  была вот такая,
[04:44.000 --> 04:46.000]  типа x стало x у w,
[04:46.000 --> 04:48.000]  разрослось все.
[04:48.000 --> 04:50.000]  Ну и вам, понятное дело, надо будет в конце,
[04:50.000 --> 04:52.000]  когда вы все это решите, вытащить
[04:52.000 --> 04:54.000]  v-w, это будет ваше решение.
[04:54.000 --> 04:56.000]  Ну и по построению оно будет не отрицательным.
[04:56.000 --> 04:58.000]  Вот.
[04:58.000 --> 05:00.000]  А, да, точнее неправильно я говорю.
[05:00.000 --> 05:02.000]  Смотрите. А, нет, все правильно я говорю.
[05:02.000 --> 05:04.000]  То есть оно не будет не отрицательным,
[05:04.000 --> 05:06.000]  но
[05:06.000 --> 05:08.000]  этого ограничения у нас в нашей
[05:08.000 --> 05:10.000]  задачи исходной и не было.
[05:10.000 --> 05:12.000]  То есть тут не было требований отрицательности на x.
[05:12.000 --> 05:14.000]  Вот. В итоге, что здесь надо подсветить еще раз,
[05:14.000 --> 05:16.000]  что у нас основные приемы
[05:16.000 --> 05:18.000]  перевода различного знача классическим,
[05:18.000 --> 05:20.000]  классическому виду это вот добавление
[05:20.000 --> 05:22.000]  чего-то положительного, умножение
[05:22.000 --> 05:24.000]  на минус единичку, разумеется, если знак не тот.
[05:24.000 --> 05:26.000]  Вот. Ну и вот разбиение
[05:26.000 --> 05:28.000]  на разбиение переменной,
[05:28.000 --> 05:30.000]  для которой нет ограничений, на разность
[05:30.000 --> 05:32.000]  двух переменных, каждую из которых
[05:32.000 --> 05:34.000]  есть ограничение отрицательности.
[05:34.000 --> 05:36.000]  Вот. И это ключевые
[05:36.000 --> 05:38.000]  моменты про линейное
[05:38.000 --> 05:40.000]  программирование, про то, как его
[05:40.000 --> 05:42.000]  переводить и
[05:42.000 --> 05:44.000]  переводить к стандартному виду и как этот
[05:44.000 --> 05:46.000]  стандартный вид, собственно, используется.
[05:46.000 --> 05:48.000]  Именно он используется в пакетах,
[05:48.000 --> 05:50.000]  которые это все делают. Вот. То есть эта задача,
[05:50.000 --> 05:52.000]  она довольно важная на практике.
[05:52.000 --> 05:54.000]  Именно там всякие задачи в расписаниях
[05:54.000 --> 05:56.000]  получаются, решаются.
[05:56.000 --> 05:58.000]  Ой, прошу прощения. Вот.
[05:58.000 --> 06:00.000]  И в целом
[06:00.000 --> 06:02.000]  в индустрии очень много всего
[06:02.000 --> 06:04.000]  делается именно линейное программирование.
[06:04.000 --> 06:06.000]  Понятно, что от него не очень далеко
[06:06.000 --> 06:08.000]  до... То есть это был
[06:08.000 --> 06:10.000]  LP. Давайте я так буду аббревиатуру
[06:10.000 --> 06:12.000]  тоже сразу писать. Вот. Но от него
[06:12.000 --> 06:14.000]  не очень далеко к задачам типа
[06:14.000 --> 06:16.000]  MILP. Вот. Тоже такая важная аббревиатура.
[06:16.000 --> 06:18.000]  Может быть, вы ее будете встречать в дальнейшем.
[06:18.000 --> 06:20.000]  Которая, по сути, все то же самое.
[06:20.000 --> 06:22.000]  Вот. Только тут есть типа
[06:22.000 --> 06:24.000]  некоторые вот так, а некоторые
[06:24.000 --> 06:26.000]  другие индексы, типа...
[06:26.000 --> 06:28.000]  В общем, для некоторых индексов,
[06:28.000 --> 06:30.000]  короче, есть дополнительные ограничения столчисленности.
[06:30.000 --> 06:32.000]  Давайте даже не 01 я сделаю.
[06:32.000 --> 06:34.000]  Просто типа Z. Вот.
[06:34.000 --> 06:36.000]  Там Z+, да, получается. У нас
[06:36.000 --> 06:38.000]  целых чисел не отрицательных. Вот.
[06:38.000 --> 06:40.000]  Ну и, соответственно,
[06:40.000 --> 06:42.000]  понятно же, что
[06:42.000 --> 06:44.000]  вот это гораздо сложнее, чем LP.
[06:44.000 --> 06:46.000]  Вот. И геометрия
[06:46.000 --> 06:48.000]  у этих задач она тоже отличается.
[06:48.000 --> 06:50.000]  То есть если в LP мы имели бы
[06:50.000 --> 06:52.000]  какой-то там многоугольничек, вот.
[06:52.000 --> 06:54.000]  Ну, например, вот здесь вот, да.
[06:54.000 --> 06:56.000]  Вот. И решение у нас было бы в какой-нибудь вершине
[06:56.000 --> 06:58.000]  их со звездочкой, и нам не так важно
[06:58.000 --> 07:00.000]  где этот вершин находится.
[07:00.000 --> 07:02.000]  Вот это LP-случай. Вот. Если же мы про Милб
[07:02.000 --> 07:04.000]  говорим, то нам важно, чтобы те координаты,
[07:04.000 --> 07:06.000]  которые вот здесь вот отмечены,
[07:06.000 --> 07:08.000]  они попадали идеально в некоторые
[07:08.000 --> 07:10.000]  столчисленные точки. Вот.
[07:10.000 --> 07:12.000]  Поэтому так уже не получится просто
[07:12.000 --> 07:14.000]  решить. Но вот эту штуку
[07:14.000 --> 07:16.000]  с ней борется тем, что решает
[07:16.000 --> 07:18.000]  последовательность некоторую...
[07:18.000 --> 07:20.000]  последовательность LP задачи. Вот.
[07:20.000 --> 07:22.000]  Ну и идея у методов,
[07:22.000 --> 07:24.000]  которые в основном такие задачи решают,
[07:24.000 --> 07:26.000]  может быть они не очень... может быть не самые
[07:26.000 --> 07:28.000]  лучшие, но на основе этих методов
[07:28.000 --> 07:30.000]  как бы все остальные методы строятся
[07:30.000 --> 07:32.000]  и более такие, наверное, продвинутые.
[07:32.000 --> 07:34.000]  Вот. Заключается след в том, что мы вот
[07:34.000 --> 07:36.000]  берем как бы вот... сейчас.
[07:36.000 --> 07:38.000]  Че, надо вырезать. Берем вот эту вот картиночку,
[07:38.000 --> 07:40.000]  да. Сбирать. Вот.
[07:40.000 --> 07:42.000]  Берем вот эту картиночку, и вот у нас
[07:42.000 --> 07:44.000]  получился X со звездочковой-то кривой.
[07:44.000 --> 07:46.000]  Вот. При этом мы знаем, что
[07:46.000 --> 07:48.000]  нам, типа, это не подходит.
[07:48.000 --> 07:50.000]  И мы берем, и на основе некоторой там дополнительной
[07:50.000 --> 07:52.000]  информации проводим дополнительные... добавляем
[07:52.000 --> 07:54.000]  некоторые ограничения к этой задачи.
[07:54.000 --> 07:56.000]  Ну, не знаю, типа, говорим, что
[07:56.000 --> 07:58.000]  теперь наше множество, которое мы хотим...
[07:58.000 --> 08:00.000]  Ну, в общем, этот X нам не подходит.
[08:00.000 --> 08:02.000]  Давайте мы возьмем какой-нибудь другой.
[08:02.000 --> 08:04.000]  То есть, не правильный, говорю.
[08:04.000 --> 08:06.000]  Этот X не подходит, поэтому давайте мы проведем
[08:06.000 --> 08:08.000]  какой-нибудь дополненный разрез. Так, надо другой цвет выбрать.
[08:10.000 --> 08:12.000]  Ну, типа, вот давайте такой.
[08:12.000 --> 08:14.000]  Вот. Какое-нибудь вот такое вот
[08:14.000 --> 08:16.000]  дополнительное ограничение, так что
[08:16.000 --> 08:18.000]  теперь мы будем решать нашу новую задачу
[08:18.000 --> 08:20.000]  уже... уже на вот... вот... вот здесь.
[08:20.000 --> 08:22.000]  То есть, вот тот X, который...
[08:22.000 --> 08:24.000]  со звездочкой нам не... не... не... не повезло
[08:24.000 --> 08:26.000]  с ним, вот, то
[08:26.000 --> 08:28.000]  мы его, как бы, отсекаем.
[08:28.000 --> 08:30.000]  Вот. И решаем уже здесь.
[08:30.000 --> 08:32.000]  Снова решаем, получаем снова какой-то X.
[08:32.000 --> 08:34.000]  Тут давайте X1.
[08:34.000 --> 08:36.000]  Какой-нибудь вот здесь, например, X2 со звездочкой.
[08:36.000 --> 08:38.000]  Смотрим, подходит он под наше
[08:38.000 --> 08:40.000]  целочное ограничение или нет. Если не подходит, то снова встроим
[08:40.000 --> 08:42.000]  некоторый разрез, который
[08:42.000 --> 08:44.000]  дополнительно... дополнительно будет нам
[08:44.000 --> 08:46.000]  отсекать неподходящую точку.
[08:46.000 --> 08:48.000]  И решаем. И таким образом мы, как бы, локализуем решение
[08:48.000 --> 08:50.000]  по счёт множества набора вот этих вот отрезов
[08:50.000 --> 08:52.000]  из нашего допустимого множества.
[08:52.000 --> 08:54.000]  Понятно ли в целом, как это работает?
[08:54.000 --> 08:56.000]  Чем мил поотличается толпе?
[08:56.000 --> 08:58.000]  И, в принципе,
[08:58.000 --> 09:00.000]  почему это тяжелее? Тут, наверное, почему это
[09:00.000 --> 09:02.000]  тяжелее, вам должен быть понятный
[09:02.000 --> 09:04.000]  экскурс по сложности вычислений. Ну, дискретная оптимизация,
[09:04.000 --> 09:06.000]  она, типа, переборная в основном вся.
[09:06.000 --> 09:08.000]  Так. Если никогда
[09:08.000 --> 09:10.000]  не наскривёмся, значит нет решения.
[09:10.000 --> 09:12.000]  Такое множество такое бывает. Но там, типа, есть
[09:12.000 --> 09:14.000]  проблема в том, что...
[09:14.000 --> 09:16.000]  Ну, не проблема, скорее, а про там
[09:16.000 --> 09:18.000]  отдельно проверяется разрешимость. То есть там
[09:18.000 --> 09:20.000]  можно проверить разрешимость.
[09:20.000 --> 09:22.000]  И понятно, что это я, типа, нарисовал
[09:22.000 --> 09:24.000]  в 2D, но когда у вас, типа, там, миллионные
[09:24.000 --> 09:26.000]  пространства, там, типа, скорее всего
[09:26.000 --> 09:28.000]  вы на что-то наткнётесь.
[09:28.000 --> 09:30.000]  То есть вы, скорее всего, у вас получится ситуация,
[09:30.000 --> 09:32.000]  когда ваша вот эта вот допустимая
[09:32.000 --> 09:34.000]  множество одержит, например, одну точку
[09:34.000 --> 09:36.000]  с целыми координатами. Эта точка, понятно, будет
[09:36.000 --> 09:38.000]  то, что вам надо, потому что она единственная допустимая с целыми
[09:38.000 --> 09:40.000]  координатами. Вот, наверное, правильно так сказать.
[09:40.000 --> 09:42.000]  Я надеюсь, я как-то пояснил, может быть, не достаточно
[09:42.000 --> 09:44.000]  подробно, но идею постарался донести.
[09:44.000 --> 09:46.000]  Так, есть ли какие-то вопросы?
[09:46.000 --> 09:48.000]  Слушайте, просто
[09:48.000 --> 09:50.000]  линейное программирование, там в
[09:50.000 --> 09:52.000]  ограничении cx плюс уровну,
[09:52.000 --> 09:54.000]  c – это не c транспонированная,
[09:54.000 --> 09:56.000]  это одна и та же линейная.
[09:56.000 --> 09:58.000]  Сейчас, смотрите, c транспонированная
[09:58.000 --> 10:00.000]  здесь, это маленькая буква c,
[10:00.000 --> 10:02.000]  это типа вектор, а тут c большой – это матрица,
[10:02.000 --> 10:04.000]  если я правильно понимаю вопрос.
[10:04.000 --> 10:06.000]  Ага, всё, спасибо.
[10:06.000 --> 10:08.000]  Отлично. Да, может быть, я тут немножко масштабы
[10:08.000 --> 10:10.000]  габариты снёс. Ну, сейчас я поправлю.
[10:10.000 --> 10:12.000]  Ну, как-то так.
[10:12.000 --> 10:14.000]  Так, ещё комментарии, вопросы.
[10:14.000 --> 10:16.000]  Вот если останется время, про вот это всё
[10:16.000 --> 10:18.000]  будем на следующей лекции, когда про методы будем
[10:18.000 --> 10:20.000]  говорить, может быть, я немножко подробнее покажу
[10:20.000 --> 10:22.000]  и картинки какие-нибудь реализации.
[10:22.000 --> 10:24.000]  Это, в принципе, несложно делается.
[10:24.000 --> 10:26.000]  Так, 30 секунд на вопросы,
[10:26.000 --> 10:28.000]  минусы, плюсы, любой фидбек
[10:28.000 --> 10:30.000]  годится. Так, сейчас пока 4
[10:30.000 --> 10:32.000]  человек как-то откликнулись.
[10:32.000 --> 10:34.000]  Тут у нас остальными
[10:34.000 --> 10:36.000]  12, видимо,
[10:36.000 --> 10:38.000]  как вы там поживаете.
[10:38.000 --> 10:40.000]  Так, окей, вижу, что вроде
[10:40.000 --> 10:42.000]  понимание почему-то приходит, это прекрасно.
[10:42.000 --> 10:44.000]  Ладно, это был небольшой экскурс ленина
[10:44.000 --> 10:46.000]  программирования, мы как-бы периодически не можем
[10:46.000 --> 10:48.000]  возвращаться. Следующий пункт
[10:48.000 --> 10:50.000]  нашей программы, это понятное дело, квадратичное
[10:50.000 --> 10:52.000]  программирование, тут как бы неудивительно,
[10:52.000 --> 10:54.000]  неудивительное усложнение логики.
[10:54.000 --> 10:56.000]  Причём будем
[10:56.000 --> 10:58.000]  ключевой как бы аббревиатуры, quadratic
[10:58.000 --> 11:00.000]  programming, quadratic constraint.
[11:00.000 --> 11:02.000]  Сейчас я правильно сформулирую,
[11:02.000 --> 11:04.000]  наоборот, квадратик или
[11:04.000 --> 11:06.000]  constraint, quadratic programming. То есть вот такие
[11:06.000 --> 11:08.000]  вот буквы, это типа,
[11:08.000 --> 11:10.000]  не знаю, писать или расшифровку.
[11:10.000 --> 11:12.000]  Сейчас напишу.
[11:12.000 --> 11:14.000]  Собственно, вот почему, так называется.
[11:14.000 --> 11:16.000]  Ну и задача тоже довольно понятная.
[11:16.000 --> 11:18.000]  Хотим минимизировать некоторую квадратичную
[11:18.000 --> 11:20.000]  форму. Сейчас я обозначение сверю.
[11:20.000 --> 11:22.000]  Понятно.
[11:22.000 --> 11:24.000]  Минимизировать квадратичную форму при
[11:24.000 --> 11:26.000]  квадратичных условиях. Понятно, что
[11:26.000 --> 11:28.000]  у нас вся эта история будет
[11:28.000 --> 11:30.000]  выпухла только когда все функции
[11:30.000 --> 11:32.000]  поиты будут выпухл... все матрицы
[11:32.000 --> 11:34.000]  поиты будут симметрично положительно определены.
[11:34.000 --> 11:36.000]  Вот так
[11:36.000 --> 11:38.000]  поита х
[11:38.000 --> 11:40.000]  плюс там, поита
[11:40.000 --> 11:42.000]  транспонентная х плюс.
[11:42.000 --> 11:44.000]  Вот. Выпукло
[11:44.000 --> 11:46.000]  при поитых
[11:46.000 --> 11:48.000]  принадлежащих сн плюс.
[11:48.000 --> 11:50.000]  Вот. Ну то есть
[11:50.000 --> 11:52.000]  основка такая. Вот.
[11:52.000 --> 11:54.000]  Все это матрицы, векторы.
[11:54.000 --> 11:56.000]  Понятно, где векторы,
[11:56.000 --> 11:58.000]  где числа, где матрицы, я надеюсь,
[11:58.000 --> 12:00.000]  из размерностей. Вот. И
[12:00.000 --> 12:02.000]  понятно, наверное, что раз мы вот
[12:02.000 --> 12:04.000]  здесь вот жили на конусе, получается
[12:04.000 --> 12:06.000]  каком... Ну, все это так или иначе сводилось
[12:06.000 --> 12:08.000]  к
[12:08.000 --> 12:10.000]  рн плюс, вот. То вот это все
[12:10.000 --> 12:12.000]  будет сводиться, понятно, наверное, что
[12:12.000 --> 12:14.000]  к конусу к2, то есть конус, который порожден
[12:14.000 --> 12:16.000]  второй нормой. Вот. Я надеюсь, рн плюс
[12:16.000 --> 12:18.000]  не надо напоминать, а вот про что такое
[12:18.000 --> 12:20.000]  к2 я напомню все-таки.
[12:20.000 --> 12:22.000]  рн r плюс
[12:22.000 --> 12:24.000]  вторая норма меньше либо равно t. Вот такая
[12:24.000 --> 12:26.000]  штука. Вот. Ну и будет
[12:26.000 --> 12:28.000]  отделаться с помощью
[12:28.000 --> 12:30.000]  преобразований
[12:30.000 --> 12:32.000]  каких. Так. Ну что надо сделать? Первое
[12:32.000 --> 12:34.000]  будет преобразовать вот эту штуку, ну
[12:34.000 --> 12:36.000]  самое главное, да, к виду, что
[12:36.000 --> 12:38.000]  некоторая, некоторая линейная
[12:38.000 --> 12:40.000]  функция... Так, ладно, сейчас давайте
[12:40.000 --> 12:42.000]  не буду, не буду
[12:42.000 --> 12:44.000]  перебегать
[12:44.000 --> 12:46.000]  стороны в сторону, давайте последовательно идем.
[12:46.000 --> 12:48.000]  Ну, что еще ясно? Ясно, что если у вас
[12:48.000 --> 12:50.000]  p и t
[12:50.000 --> 12:52.000]  равны нулю, следовательно,
[12:52.000 --> 12:54.000]  получаем lp. Это всем видно,
[12:54.000 --> 12:56.000]  что если у нас матрицы за нуляются,
[12:56.000 --> 12:58.000]  то мы получаем линию программирования.
[12:58.000 --> 13:00.000]  Поставьте плюс, если вам это видно.
[13:00.000 --> 13:02.000]  Вот. Ну, то есть, соответственно, можно сказать,
[13:02.000 --> 13:04.000]  что вот это вот, вот эти или
[13:04.000 --> 13:06.000]  constrain, что lp
[13:06.000 --> 13:08.000]  под множество этой штуки.
[13:08.000 --> 13:10.000]  В общем, будем сейчас иерархию устроить до
[13:10.000 --> 13:12.000]  максимально широкого класса
[13:12.000 --> 13:14.000]  задач, вида задач, которая
[13:14.000 --> 13:16.000]  будет включать себя все выше перечисления. Поэтому
[13:16.000 --> 13:18.000]  идем по степени, по направлению
[13:18.000 --> 13:20.000]  усложнения постановок. Вот.
[13:20.000 --> 13:22.000]  Значит, что еще здесь важно?
[13:22.000 --> 13:24.000]  Ну, примеры. Почему это вообще
[13:24.000 --> 13:26.000]  куда такое берется? Вот. Ну,
[13:26.000 --> 13:28.000]  то, что мы уже несколько раз, я кажется, упоминал
[13:28.000 --> 13:30.000]  или не упоминал. Ну, если не упоминал, то еще
[13:30.000 --> 13:32.000]  буду упоминать. Вот. Примеры.
[13:32.000 --> 13:34.000]  Вот. Ну, все, что касается про минимизацию
[13:34.000 --> 13:36.000]  там каких-то норм, вторых,
[13:36.000 --> 13:38.000]  например, там наименьшие квадраты,
[13:38.000 --> 13:40.000]  стандартная задача. А это было, наверное,
[13:40.000 --> 13:42.000]  на первой лекции я упоминал, да?
[13:42.000 --> 13:44.000]  Вот. Это все квадратичное.
[13:44.000 --> 13:46.000]  Вот. Сюда можно добавлять понятные ограничения,
[13:46.000 --> 13:48.000]  где лежит у нас
[13:48.000 --> 13:50.000]  x it. Вот. Это все подходит
[13:50.000 --> 13:52.000]  под, под
[13:52.000 --> 13:54.000]  тот тип, который был ранее записан.
[13:54.000 --> 13:56.000]  Вот. Можно еще
[13:56.000 --> 13:58.000]  искать решение минимальной нормы,
[13:58.000 --> 14:00.000]  то есть, если у вас задача
[14:00.000 --> 14:02.000]  переопределенная, ну, типа у вас
[14:02.000 --> 14:04.000]  ax равно b, и вы знаете,
[14:04.000 --> 14:06.000]  что у вас x-ов очень много. Ну, это наша стандартная
[14:06.000 --> 14:08.000]  ситуация, когда матрица A
[14:08.000 --> 14:10.000]  имеет вот такой вот вид. Это вот m,
[14:10.000 --> 14:12.000]  это n, и m сильно меньше
[14:12.000 --> 14:14.000]  n. Вот.
[14:14.000 --> 14:16.000]  Так. Здесь видно, да? Вот такой
[14:16.000 --> 14:18.000]  вот вид. Х – это целое подпространство.
[14:18.000 --> 14:20.000]  И чтобы как-то конкретизировать,
[14:20.000 --> 14:22.000]  какое решение нам подходит, мы говорим,
[14:22.000 --> 14:24.000]  что, окей, нам нужно решение минимальной нормы. Вот.
[14:24.000 --> 14:26.000]  Решение тоже, соответственно, квадратичная функция.
[14:26.000 --> 14:28.000]  Вот. И тут как бы
[14:28.000 --> 14:30.000]  ключевое место – это, конечно же, выбор
[14:30.000 --> 14:32.000]  того, какая здесь норма. То есть, из-за того, что есть вторая норма,
[14:32.000 --> 14:34.000]  у нас получается именно квадратичное
[14:34.000 --> 14:36.000]  программирование. Вот. И поэтому
[14:36.000 --> 14:38.000]  естественным образом задаться вопросом, а что будет,
[14:38.000 --> 14:40.000]  если, например, захотеть искать
[14:40.000 --> 14:42.000]  минимальную норму, типа бесконечной, или первую?
[14:42.000 --> 14:44.000]  Вы думаете, какой задачи такой,
[14:44.000 --> 14:46.000]  такая обстановка сведется? Вот это
[14:46.000 --> 14:48.000]  что такое будет? Пишите варианты в комментариях.
[14:48.000 --> 14:50.000]  Ну, линейное будет. Ну, линейное будет, конечно.
[14:50.000 --> 14:52.000]  Давайте приведем это к линейному.
[14:52.000 --> 14:54.000]  Кто понимает, как это делать?
[14:54.000 --> 14:56.000]  Давайте. Третьих слов на то, чтобы подумать
[14:56.000 --> 14:58.000]  и потом обсудим. Так, ну что?
[14:58.000 --> 15:00.000]  Давайте тогда обсудим,
[15:00.000 --> 15:02.000]  что делать надо. Но сначала, понятное дело,
[15:02.000 --> 15:04.000]  надо написать определение. Если это
[15:04.000 --> 15:06.000]  мин, максимум нормы х этого,
[15:06.000 --> 15:08.000]  да, по И, минимум по х.
[15:08.000 --> 15:10.000]  Представим, что х равно b. Вот.
[15:10.000 --> 15:12.000]  Ну, то есть, раз тут стоит какой-то максимум,
[15:12.000 --> 15:14.000]  то, если у нас максимум
[15:14.000 --> 15:16.000]  чему-то равен, то это значит, что
[15:16.000 --> 15:18.000]  мы, по сути, хотим минимизировать
[15:18.000 --> 15:20.000]  некоторое t, кое-что.
[15:20.000 --> 15:22.000]  Ну, понятно, х равно b.
[15:22.000 --> 15:24.000]  И х и t меньше либо равно t.
[15:24.000 --> 15:26.000]  Вот. Ну, а дальше,
[15:26.000 --> 15:28.000]  я думаю, понятно более-менее, что
[15:28.000 --> 15:30.000]  раз это минимум t, здесь
[15:30.000 --> 15:32.000]  ах равно b. И если модуль
[15:32.000 --> 15:34.000]  меньше либо равен числа, то это значит, что
[15:34.000 --> 15:36.000]  само число от минус t до t. Вот.
[15:36.000 --> 15:38.000]  Ну, и соответственно, вы тут, что, х и t.
[15:38.000 --> 15:40.000]  Ну, вот. В общем, получили не на программирование.
[15:40.000 --> 15:42.000]  Понятно, что привести это к стандартной
[15:42.000 --> 15:44.000]  форме дополнительно некоторая работа.
[15:44.000 --> 15:46.000]  Вот. Рекомендую, кстати, потренироваться
[15:46.000 --> 15:48.000]  и проделать. Это, может быть, достаточно полезно,
[15:48.000 --> 15:50.000]  как-то руку набить. Вот, может быть.
[15:50.000 --> 15:52.000]  Ну, тренироваться с пользой стандартных приемов.
[15:52.000 --> 15:54.000]  Понятно, что, скорее всего, размерность как-то сильно
[15:54.000 --> 15:56.000]  возрастет в результате.
[15:56.000 --> 15:58.000]  Но, как бы, не так важно сейчас это.
[15:58.000 --> 16:00.000]  Так. Понятно ли, какие преобразования были
[16:00.000 --> 16:02.000]  проделаны и почему они привели к успеху?
[16:02.000 --> 16:04.000]  Поставьте плюс или минус.
[16:04.000 --> 16:06.000]  Так, окей. Вроде все в порядке.
[16:06.000 --> 16:08.000]  Ну, соответственно,
[16:08.000 --> 16:10.000]  следующий пример квадратичных задач
[16:10.000 --> 16:12.000]  это всякие задачи. Ой.
[16:12.000 --> 16:14.000]  Задачи про финансы
[16:14.000 --> 16:16.000]  и составление оптимального портфеля. Вот.
[16:16.000 --> 16:18.000]  У нас есть там, как обычно было...
[16:18.000 --> 16:20.000]  Ой, третий пример, да?
[16:20.000 --> 16:22.000]  Есть инактивов. Вот.
[16:22.000 --> 16:24.000]  И у нас есть там
[16:24.000 --> 16:26.000]  информация о том, что изменение
[16:26.000 --> 16:28.000]  цены это по с чертой.
[16:28.000 --> 16:30.000]  Вот.
[16:30.000 --> 16:32.000]  Это типа средняя цена.
[16:32.000 --> 16:34.000]  Треднее изменение цены.
[16:34.000 --> 16:36.000]  Вот. И сигма – это соответственно
[16:36.000 --> 16:38.000]  кавируционный матриц этого случайного вектора.
[16:38.000 --> 16:40.000]  Вот. То есть раз это кавируционный матрица,
[16:40.000 --> 16:42.000]  то она там СН++.
[16:42.000 --> 16:44.000]  Вот. И чтобы...
[16:44.000 --> 16:46.000]  В общем, значит, наш минимизирует риск
[16:46.000 --> 16:48.000]  под риском... Риск.
[16:48.000 --> 16:50.000]  Риск – это вот такая штука.
[16:50.000 --> 16:52.000]  Вот. Где наш ИКС –
[16:52.000 --> 16:54.000]  это некоторое распределение
[16:54.000 --> 16:56.000]  средств по активам.
[16:56.000 --> 16:58.000]  Вот. То есть мы смотрим на то,
[16:58.000 --> 17:00.000]  как бы нам разложить
[17:00.000 --> 17:02.000]  наши средства по
[17:02.000 --> 17:04.000]  активам так, чтобы суммарный
[17:04.000 --> 17:06.000]  риск был минимален.
[17:06.000 --> 17:08.000]  Мы хотим минимизировать эту штуку
[17:08.000 --> 17:10.000]  при условии, что
[17:10.000 --> 17:12.000]  мы хотим получить некоторый гарантированный доход.
[17:12.000 --> 17:14.000]  Вот. А гарантированный доход – это наш
[17:14.000 --> 17:16.000]  ПС чертой ИКС больше любви
[17:16.000 --> 17:18.000]  чем некоторый РС чертой. Минимальный доход.
[17:18.000 --> 17:20.000]  Вот. Ну ИКС, соответственно, распределение,
[17:20.000 --> 17:22.000]  поэтому для него выполнены
[17:22.000 --> 17:24.000]  соответствующие условия нормировки. Вот. Но видите, тоже
[17:24.000 --> 17:26.000]  как бы квадратичная задача на самом деле,
[17:26.000 --> 17:28.000]  потому что целевая функция квадратична,
[17:28.000 --> 17:30.000]  все остальное – линия. Вот. Поэтому здесь тоже
[17:30.000 --> 17:32.000]  это все... То есть это типа
[17:32.000 --> 17:34.000]  задачи тоже подпадает под наше определение
[17:34.000 --> 17:36.000]  квадратичной оптимизации
[17:36.000 --> 17:38.000]  с квадратичными ограничениями.
[17:38.000 --> 17:40.000]  Вот. Значит, вот такой
[17:40.000 --> 17:42.000]  еще пример. Да.
[17:42.000 --> 17:44.000]  Еще один пример. Давайте про классификацию
[17:44.000 --> 17:46.000]  немножко поговорим. Вот. Что у нас есть
[17:46.000 --> 17:48.000]  стандартный там
[17:48.000 --> 17:50.000]  SVM, классический SVM-классификатор.
[17:50.000 --> 17:52.000]  То задачи его обучения
[17:52.000 --> 17:54.000]  также сводятся к
[17:54.000 --> 17:56.000]  квадратичной оптимизации с
[17:56.000 --> 17:58.000]  нескольких сторон. Сейчас посмотрим
[17:58.000 --> 18:00.000]  с одной. Вот. Возможно, у кого-то на
[18:00.000 --> 18:02.000]  семинарах в домашнем здании там где-то будут разобраны
[18:02.000 --> 18:04.000]  почему там с другой стороны
[18:04.000 --> 18:06.000]  это тоже квадратичная задача. Вот.
[18:06.000 --> 18:08.000]  Но еще ничего у нас есть. Так. Тут, возможно, кстати,
[18:08.000 --> 18:10.000]  стоит уже сайты показать, потому что тут
[18:10.000 --> 18:12.000]  важна картинка. То есть картинок, наверное,
[18:12.000 --> 18:14.000]  это может быть тяжело воспринимать.
[18:14.000 --> 18:16.000]  Так. Стоп.
[18:16.000 --> 18:18.000]  Так. Сейчас я тут все выпилю.
[18:18.000 --> 18:20.000]  Share screen.
[18:20.000 --> 18:22.000]  Так. Где эта лекция? Это вот.
[18:22.000 --> 18:24.000]  Вот. Ну, короче, у нас есть выборка, то есть набор
[18:24.000 --> 18:26.000]  из векторов и чиселок.
[18:26.000 --> 18:28.000]  Чиселки плюс-минус единицы.
[18:28.000 --> 18:30.000]  И мы хотим гиперплоскость построить, чтобы
[18:30.000 --> 18:32.000]  для одних элементов у нас был больше 0,
[18:32.000 --> 18:34.000]  а значение для других был меньше 0.
[18:34.000 --> 18:36.000]  То есть стандартное определение
[18:36.000 --> 18:38.000]  разделяющей гиперплоскости вот только
[18:38.000 --> 18:40.000]  не на множествах, а на
[18:40.000 --> 18:42.000]  просто наборе точек.
[18:42.000 --> 18:44.000]  Ну, соответственно, вот они как-то могут быть
[18:44.000 --> 18:46.000]  нарисованы. Ну и понятно, что если такая
[18:46.000 --> 18:48.000]  идеальная конструкция, то
[18:48.000 --> 18:50.000]  мы можем гиперплоскость очень по-разному проводить.
[18:50.000 --> 18:52.000]  Можно вот так проводить, можно вот так,
[18:52.000 --> 18:54.000]  можно вот даже вот так.
[18:54.000 --> 18:56.000]  И, собственно,
[18:56.000 --> 18:58.000]  закономерный вопрос, как эту
[18:58.000 --> 19:00.000]  разделяющую гиперплоскость однозначно образом задать,
[19:00.000 --> 19:02.000]  чтобы у нас как бы не было произвола.
[19:02.000 --> 19:04.000]  Пожалуйста, напишите, какие варианты
[19:04.000 --> 19:06.000]  и задания, как однозначно задать
[19:06.000 --> 19:08.000]  гиперплоскость вы можете предложить
[19:08.000 --> 19:10.000]  в чате, пожалуйста.
[19:10.000 --> 19:12.000]  30 секунд-минута на то, чтобы
[19:12.000 --> 19:14.000]  какой-то подумать над этим.
[19:14.000 --> 19:16.000]  То есть вопрос, что будет являться критерием
[19:16.000 --> 19:18.000]  единственности и оптимальности.
[19:18.000 --> 19:20.000]  Вот почему, может быть, как понять,
[19:20.000 --> 19:22.000]  вот эта вот желтая гиперплоскость,
[19:22.000 --> 19:24.000]  зеленая гиперплоскость, она лучше
[19:24.000 --> 19:26.000]  или хуже красная или нет? То есть как
[19:26.000 --> 19:28.000]  вот оценить качество гиперплоскости
[19:28.000 --> 19:30.000]  надо понять, и отсюда получится критерия
[19:30.000 --> 19:32.000]  единственности, критерии, которые надо
[19:32.000 --> 19:34.000]  оптимизировать, чтобы получить
[19:34.000 --> 19:36.000]  единственного кандидата.
[19:36.000 --> 19:38.000]  Да, осталось только
[19:38.000 --> 19:40.000]  маржины, и как это связано
[19:40.000 --> 19:42.000]  с той картинкой, которая сейчас изображена.
[19:42.000 --> 19:44.000]  Продемонстрируйте свой уровень понимания того,
[19:44.000 --> 19:46.000]  что у вас было на вашем обучении,
[19:46.000 --> 19:48.000]  и вы найдете правильный ответ.
[19:48.000 --> 19:50.000]  Гадите, от всех до всех y итых,
[19:50.000 --> 19:52.000]  а что что-то с...
[19:52.000 --> 19:54.000]  сейчас, а что за...
[19:54.000 --> 19:56.000]  от прямой до всех...
[19:56.000 --> 19:58.000]  сейчас не очень понятно.
[19:58.000 --> 20:00.000]  Там не y итые, а x итые, я так понимаю.
[20:00.000 --> 20:02.000]  Да,
[20:02.000 --> 20:04.000]  минимизирует расстояние,
[20:04.000 --> 20:06.000]  знаковое расстояние до разделяющей
[20:06.000 --> 20:08.000]  гиперплоскости, положительное для
[20:08.000 --> 20:10.000]  правильного. А что такое?
[20:10.000 --> 20:12.000]  Расстояние до...
[20:12.000 --> 20:14.000]  по модулю проекцию вектор на нормаль
[20:14.000 --> 20:16.000]  к прямой для каждого класса.
[20:16.000 --> 20:18.000]  Очень интересно. По модулю
[20:18.000 --> 20:20.000]  проекцию векторов точек на
[20:20.000 --> 20:22.000]  нормаль. Да я вижу.
[20:22.000 --> 20:24.000]  Так, ладно, пишите, пишите.
[20:24.000 --> 20:26.000]  Да, интересно почитать.
[20:26.000 --> 20:28.000]  Просто марж
[20:28.000 --> 20:30.000]  расстояние до разделяющей. А от чего
[20:30.000 --> 20:32.000]  расстояние? Непонятно от чего.
[20:32.000 --> 20:34.000]  По модулю от точки.
[20:34.000 --> 20:36.000]  А какой? Ее точку еще-то найти какую-то?
[20:36.000 --> 20:38.000]  Каждой точке свой марж.
[20:38.000 --> 20:40.000]  Ну хорошо, а максимум только почему
[20:40.000 --> 20:42.000]  берется? Точки выборки.
[20:42.000 --> 20:44.000]  Нет, да, хорошо. А как это гиперплоскость
[20:44.000 --> 20:46.000]  относится? То есть как максимум
[20:46.000 --> 20:48.000]  по выборке брать?
[20:48.000 --> 20:50.000]  Можно как-то... Во-во-во!
[20:50.000 --> 20:52.000]  Вот тут про ширину полосы что-то начинает
[20:52.000 --> 20:54.000]  писать. Это вот... Это понятнее,
[20:54.000 --> 20:56.000]  как, наверное, представить, да?
[20:56.000 --> 20:58.000]  Все точки в эту полосу оценивались.
[20:58.000 --> 21:00.000]  То есть оценивались.
[21:00.000 --> 21:02.000]  Как оценивались? Ну хорошо, давайте
[21:02.000 --> 21:04.000]  так, простые вопросы. Как параметризуется
[21:04.000 --> 21:06.000]  гиперплоскость? Что такое модуль?
[21:06.000 --> 21:08.000]  Короче говоря, вопрос простой. Какие у нас
[21:08.000 --> 21:10.000]  переменные, которые мы хотим определить?
[21:10.000 --> 21:12.000]  Так, прошу прощения. Вроде...
[21:12.000 --> 21:14.000]  Алло, алло. Тест, тест.
[21:14.000 --> 21:16.000]  А сейчас нормально? Ой-ой, печаль.
[21:16.000 --> 21:18.000]  Так, ладно. Прямо сейчас? Да.
[21:18.000 --> 21:20.000]  Ладно, будем наде... Вроде получше стало.
[21:20.000 --> 21:22.000]  Окей, спасибо.
[21:22.000 --> 21:24.000]  Так, ну хорошо. Смотрите, более-менее я
[21:24.000 --> 21:26.000]  понял, что вы хотели написать выше.
[21:26.000 --> 21:28.000]  Вот. Если сейчас будут какие-то проблемы,
[21:28.000 --> 21:30.000]  пока я буду говорить, вы тоже скажите,
[21:30.000 --> 21:32.000]  чтобы как бы заодно...
[21:32.000 --> 21:34.000]  Заодно можно было бы проконтролировать,
[21:34.000 --> 21:36.000]  что связь устаканивалась более-менее
[21:36.000 --> 21:38.000]  стабильная.
[21:38.000 --> 21:40.000]  В общем, идея очень простая.
[21:40.000 --> 21:42.000]  На самом деле, вот из всех этих
[21:42.000 --> 21:44.000]  гиперплоскостей мы выбираем, типа,
[21:44.000 --> 21:46.000]  тут ближайшие друг другу точки
[21:46.000 --> 21:48.000]  из двух множеств.
[21:48.000 --> 21:50.000]  Что-то никто по мне не сказал.
[21:50.000 --> 21:52.000]  Вот. И пытаемся найти
[21:52.000 --> 21:54.000]  такую гиперплоскость.
[21:54.000 --> 21:56.000]  Вот.
[21:56.000 --> 21:58.000]  Так, чтобы параллельно,
[21:58.000 --> 22:00.000]  если мы параллельно ей проведем
[22:00.000 --> 22:02.000]  гиперплоскости по этим точкам,
[22:02.000 --> 22:04.000]  то расстояние между ними будет максимально.
[22:04.000 --> 22:06.000]  То есть зазор, тот, который там
[22:06.000 --> 22:08.000]  пытались сформулировать, что это такое,
[22:08.000 --> 22:10.000]  прознаковое расстояние
[22:10.000 --> 22:12.000]  и все прочее.
[22:12.000 --> 22:14.000]  Это просто-напросто та самая ширина
[22:14.000 --> 22:16.000]  полосы, которая тоже упоминалась.
[22:16.000 --> 22:18.000]  Вот формализация этой ширины полосы
[22:18.000 --> 22:20.000]  это, собственно, расстояние между
[22:20.000 --> 22:22.000]  большими точками, это расстояние
[22:22.000 --> 22:24.000]  между гиперплоскостями,
[22:24.000 --> 22:26.000]  проведенными через ближайшие точки
[22:26.000 --> 22:28.000]  параллельно разделяющими.
[22:28.000 --> 22:30.000]  То есть как это формализовать?
[22:30.000 --> 22:32.000]  Формализуется очень просто. Вводится в понятие
[22:32.000 --> 22:34.000]  оборных объектов. Это, собственно, те самые
[22:34.000 --> 22:36.000]  объекты, на которых будет выполнено
[22:36.000 --> 22:38.000]  наше требование. То есть так можно сделать,
[22:38.000 --> 22:40.000]  потому что мы всегда можем отнормировать A и B,
[22:40.000 --> 22:42.000]  так чтобы тут были справа единички.
[22:42.000 --> 22:44.000]  Ну и дальше, поскольку они параллельны,
[22:44.000 --> 22:46.000]  то мы знаем формулу из аналитической геометрии
[22:46.000 --> 22:48.000]  про то, как считается расстояние между гиперплоскостями.
[22:48.000 --> 22:50.000]  Считается, как норма
[22:50.000 --> 22:52.000]  свободных членов здесь.
[22:52.000 --> 22:54.000]  Делить на модуль разности
[22:54.000 --> 22:56.000]  между свободными членами
[22:56.000 --> 22:58.000]  в правой части.
[22:58.000 --> 23:00.000]  Делить на норму нормальной к гиперплоскости.
[23:00.000 --> 23:02.000]  Поскольку тут можно,
[23:02.000 --> 23:04.000]  так нам повезло, что это 1-1,
[23:04.000 --> 23:06.000]  то эта штука просто двоечка равна.
[23:06.000 --> 23:08.000]  Нам надо, по сути, максимизировать
[23:08.000 --> 23:10.000]  это замечательное расстояние.
[23:10.000 --> 23:12.000]  А теперь давайте поймем, почему
[23:12.000 --> 23:14.000]  максимизация вот этого
[23:14.000 --> 23:16.000]  расстояния, довольно естественная
[23:16.000 --> 23:18.000]  репция, приводит нас к такой вот задаче.
[23:18.000 --> 23:20.000]  Понятно, что максимизация вот этой штуки
[23:20.000 --> 23:22.000]  то же самое, что минимизация
[23:22.000 --> 23:24.000]  обратной величины.
[23:24.000 --> 23:26.000]  А дальше нам надо потребовать, чтобы
[23:26.000 --> 23:28.000]  для всех элементов,
[23:28.000 --> 23:30.000]  для которых мы это все записывали,
[23:30.000 --> 23:32.000]  было выполнено правильное неравенство,
[23:32.000 --> 23:34.000]  поскольку это опорные объекты,
[23:34.000 --> 23:36.000]  и в них выполнено
[23:36.000 --> 23:38.000]  строгое равенство, а во всех остальных местах
[23:38.000 --> 23:40.000]  должно быть выполнение неравенства.
[23:40.000 --> 23:42.000]  Ну и, соответственно, поскольку у нас Y знаковый,
[23:42.000 --> 23:44.000]  то вот это произведение, которое мы здесь
[23:44.000 --> 23:46.000]  написали, должно быть больше, чем на единицах.
[23:46.000 --> 23:48.000]  Вот это, видимо, этап, когда вы писали
[23:48.000 --> 23:50.000]  про максимизацию,
[23:50.000 --> 23:52.000]  ну, когда вы писали про
[23:52.000 --> 23:54.000]  то, что максимум по выборке считается,
[23:54.000 --> 23:56.000]  ну вот он как бы не совсем максимум по выборке,
[23:56.000 --> 23:58.000]  он вот скорее в качестве ограничений сюда заходит.
[23:58.000 --> 24:00.000]  Ну и получается, что мы, опять же,
[24:00.000 --> 24:02.000]  минимизируем некоторую квадратичную функцию
[24:02.000 --> 24:04.000]  при линейных ограничениях.
[24:04.000 --> 24:06.000]  То есть это, опять же, получается
[24:06.000 --> 24:08.000]  квадратичная задача оптимизации.
[24:08.000 --> 24:10.000]  Вот если ее решать, то получается вот такая вот картинка.
[24:10.000 --> 24:12.000]  То вот у вас по опорным объектам проходят
[24:12.000 --> 24:14.000]  параллельные гиберплоскости.
[24:14.000 --> 24:16.000]  Ну и та самая разделяющая,
[24:16.000 --> 24:18.000]  ну если их несколько, то любой подойдет.
[24:18.000 --> 24:20.000]  Если они выстроились,
[24:20.000 --> 24:22.000]  если они выстроились как бы в такие вот прямые,
[24:22.000 --> 24:24.000]  ну не страшно, любой подойдет.
[24:24.000 --> 24:26.000]  Да, и, соответственно, серединка между ними
[24:26.000 --> 24:28.000]  как раз таки будет считаться
[24:28.000 --> 24:30.000]  как раз таки и оптимальной
[24:30.000 --> 24:32.000]  разделяющей гиберплоскостью.
[24:32.000 --> 24:34.000]  В общем, простой пример.
[24:34.000 --> 24:36.000]  Понятно, что на вашем обучении вам рассказывали,
[24:36.000 --> 24:38.000]  что делать, если выборки нелинейно-разделимы.
[24:38.000 --> 24:40.000]  Ну в общем,
[24:40.000 --> 24:42.000]  рекомендую еще раз это вспомнить
[24:42.000 --> 24:44.000]  и увидеть, что в принципе
[24:44.000 --> 24:46.000]  на класс итоговой задачи оптимизации
[24:46.000 --> 24:48.000]  это никак не влияет. То есть как у вас была квадратичная задача,
[24:48.000 --> 24:50.000]  так она и останется с некоторыми поправками.
[24:50.000 --> 24:52.000]  Вот, так, есть ли вопросы?
[24:52.000 --> 24:54.000]  Так, дальше да. Дальше как раз таки более
[24:54.000 --> 24:56.000]  нагруженный слайд.
[24:56.000 --> 24:58.000]  Поэтому хочется все вопросы по
[24:58.000 --> 25:00.000]  примеру с картинками
[25:00.000 --> 25:02.000]  решить сейчас.
[25:02.000 --> 25:04.000]  Так, ну, вопросов каких-то,
[25:04.000 --> 25:06.000]  комментариев я пока не вижу.
[25:06.000 --> 25:08.000]  Наверное, надеюсь, что понятно.
[25:08.000 --> 25:10.000]  Значит, смотрите, следующий пример
[25:10.000 --> 25:12.000]  это, собственно, сразу
[25:12.000 --> 25:14.000]  как-то сразу, не сразу,
[25:14.000 --> 25:16.000]  явным образом записанная задача
[25:16.000 --> 25:18.000]  оптимизации именно на конусе второго порядка.
[25:18.000 --> 25:20.000]  Так как order-con-programming, так называемый.
[25:20.000 --> 25:22.000]  Давайте-ка я все это попытаюсь сейчас записать
[25:22.000 --> 25:24.000]  явно в доске,
[25:24.000 --> 25:26.000]  потому что тут надо, возможно, что-то будет пояснять.
[25:26.000 --> 25:28.000]  Так, давайте-ка я сейчас
[25:28.000 --> 25:30.000]  как-нибудь это все снова
[25:30.000 --> 25:32.000]  расшарю правильным образом.
[25:32.000 --> 25:34.000]  Так, сейчас сначала вот так,
[25:34.000 --> 25:36.000]  что елочка гори, есть уран.
[25:36.000 --> 25:38.000]  Так, пишу слайды.
[25:38.000 --> 25:40.000]  Вот.
[25:40.000 --> 25:42.000]  Так, да, следующий пункт
[25:42.000 --> 25:44.000]  это
[25:44.000 --> 25:46.000]  second-order
[25:46.000 --> 25:48.000]  cone.
[25:50.000 --> 25:52.000]  Так, cone
[25:52.000 --> 25:54.000]  programming
[25:54.000 --> 25:56.000]  second-order
[25:56.000 --> 25:58.000]  cone-programming.
[25:58.000 --> 26:00.000]  Ну, как вы, наверное, уже догадались,
[26:00.000 --> 26:02.000]  тут все то же самое, что у нас было до этого
[26:02.000 --> 26:04.000]  в линейном программировании.
[26:04.000 --> 26:06.000]  То есть тут ax равно b.
[26:06.000 --> 26:08.000]  Только теперь ограничения
[26:08.000 --> 26:10.000]  неравенства у нас вот такие.
[26:10.000 --> 26:12.000]  c i t транспонированный
[26:12.000 --> 26:14.000]  x там плюс d i t, например.
[26:14.000 --> 26:16.000]  Вот так.
[26:16.000 --> 26:18.000]  То есть все, что у нас тут есть,
[26:18.000 --> 26:20.000]  так и тут двоечек стоит.
[26:20.000 --> 26:22.000]  Означает напрямую, что
[26:22.000 --> 26:24.000]  вот эта штука, конкретно вот это
[26:24.000 --> 26:26.000]  ограничение, это что означает?
[26:26.000 --> 26:28.000]  Это означает, что вектор вида
[26:28.000 --> 26:30.000]  ax b плюс b i t
[26:30.000 --> 26:32.000]  запитает c i t транспонированный
[26:32.000 --> 26:34.000]  c i t больше либо равно
[26:34.000 --> 26:36.000]  нуля, в смысле k 2.
[26:36.000 --> 26:38.000]  Вот. То есть вот это вот k 2, оно вот как раз
[26:38.000 --> 26:40.000]  таки по определению, то есть мы
[26:40.000 --> 26:42.000]  как я уже вот тут упоминал,
[26:42.000 --> 26:44.000]  где у нас тут был конус, то я записывал.
[26:44.000 --> 26:46.000]  Вот. Вот-вот-вот. Напоминаю.
[26:46.000 --> 26:48.000]  Вот у нас был конус k 2, и мы просто взяли и
[26:48.000 --> 26:50.000]  афином образом преобразовали аргументы.
[26:50.000 --> 26:52.000]  Вот афинное преобразование ничего не меняет,
[26:52.000 --> 26:54.000]  как мы уже выяснили ранее.
[26:54.000 --> 26:56.000]  Поэтому можно записать в максимально общем виде
[26:56.000 --> 26:58.000]  именно таким образом. Понятно ли,
[26:58.000 --> 27:00.000]  так, я надеюсь, сейчас все видно,
[27:00.000 --> 27:02.000]  понятно ли постановка задачи
[27:02.000 --> 27:04.000]  и то, почему она выглядит именно так,
[27:04.000 --> 27:06.000]  как связана с конусом? Так, ну поставьте
[27:06.000 --> 27:08.000]  плюсы, если понятно. Алло-алло, а сейчас?
[27:08.000 --> 27:10.000]  Ага, так, а в каком
[27:10.000 --> 27:12.000]  в каком месте...
[27:12.000 --> 27:14.000]  Короче, не важно, какой интернет, главное,
[27:14.000 --> 27:16.000]  чтобы связь останавливалась так или иначе.
[27:16.000 --> 27:18.000]  Так, а на каком месте я пропал? В общем,
[27:18.000 --> 27:20.000]  еще раз. Задача оптимизации на конусе
[27:20.000 --> 27:22.000]  второго порядка заключается в следующем,
[27:22.000 --> 27:24.000]  что мы по-прежнему пытаемся работать
[27:24.000 --> 27:26.000]  линейными целевыми функциями,
[27:26.000 --> 27:28.000]  у нас по-прежнему линейные ограничения
[27:28.000 --> 27:30.000]  типа равенства, а не равенства, которые
[27:30.000 --> 27:32.000]  записаны в виде вот такой вот
[27:32.000 --> 27:34.000]  связанной со второй
[27:34.000 --> 27:36.000]  нормы здесь.
[27:36.000 --> 27:38.000]  Они переписываются просто как вот, что вот такой
[27:38.000 --> 27:40.000]  вот вектор больше либо равен нуля
[27:40.000 --> 27:42.000]  в смысле конуса K2. Вот. Конус K2
[27:42.000 --> 27:44.000]  собственно, я уже показывал, покажу еще раз,
[27:44.000 --> 27:46.000]  чего страшного, это вот такая штука.
[27:46.000 --> 27:48.000]  Вот. И проделаны, по сути дела,
[27:48.000 --> 27:50.000]  просто афинные преобразования
[27:50.000 --> 27:52.000]  аргументов. Они проделаны
[27:52.000 --> 27:54.000]  и получилась вот такая штука. Это
[27:54.000 --> 27:56.000]  опечатка. Теперь там K2 должно
[27:56.000 --> 27:58.000]  быть на самом деле. Почему больше либо
[27:58.000 --> 28:00.000]  равно? А, ну потому что у нас было,
[28:00.000 --> 28:02.000]  когда мы про конусы говорили, вот,
[28:02.000 --> 28:04.000]  сейчас, может быть, там будет меньше либо равно,
[28:04.000 --> 28:06.000]  но, по-моему, должно все-таки больше.
[28:06.000 --> 28:08.000]  Идея была в том, что если,
[28:08.000 --> 28:10.000]  то есть, еще раз, вот эта штука
[28:10.000 --> 28:12.000]  в смысле нуля
[28:12.000 --> 28:14.000]  это равносильно тому, что X лежит
[28:14.000 --> 28:16.000]  в конусе. Вот. Кажется,
[28:16.000 --> 28:18.000]  теперь все должно быть понятно. Или еще
[28:18.000 --> 28:20.000]  нет? Ну, то есть, для того, чтобы как
[28:20.000 --> 28:22.000]  наше классическое больше либо равно нуля
[28:22.000 --> 28:24.000]  стало бы эквивалентом, что X лежит в Rn+.
[28:24.000 --> 28:26.000]  Да, сейчас секундочку про применение.
[28:26.000 --> 28:28.000]  Пару слов скажу тоже. То есть, вот
[28:28.000 --> 28:30.000]  чтобы вот эта вот эквивалентность, она как бы
[28:30.000 --> 28:32.000]  была перенесена по аналогии, то
[28:32.000 --> 28:34.000]  поэтому, типа, здесь меньше либо равно,
[28:34.000 --> 28:36.000]  а тут больше либо равно в смысле конуса. Так,
[28:36.000 --> 28:38.000]  Никита, стало ли понятнее? Плюс-минус.
[28:38.000 --> 28:40.000]  Так, интересно. А что не очень понятно?
[28:40.000 --> 28:42.000]  То есть, давайте тогда еще раз я продублирую определение
[28:42.000 --> 28:44.000]  нашего конуса.
[28:44.000 --> 28:46.000]  Ну вот. То есть,
[28:46.000 --> 28:48.000]  здесь в конусе
[28:48.000 --> 28:50.000]  стоит знак меньше
[28:50.000 --> 28:52.000]  либо равно. Но если у нас
[28:52.000 --> 28:54.000]  A+.
[28:54.000 --> 28:56.000]  А, да. Вроде дошло. Окей.
[28:56.000 --> 28:58.000]  Это прекрасно.
[28:58.000 --> 29:00.000]  Так. А как мы сравним
[29:00.000 --> 29:02.000]  результат скалярного произведения?
[29:02.000 --> 29:04.000]  Скаляр по конусу.
[29:04.000 --> 29:06.000]  Результат скалярного произведения?
[29:06.000 --> 29:08.000]  А где у нас есть скалярное произведение по конусу?
[29:08.000 --> 29:10.000]  Я не очень понял.
[29:10.000 --> 29:12.000]  Я как раз правильно написал A+.
[29:12.000 --> 29:14.000]  Вот дальше.
[29:14.000 --> 29:16.000]  Давай еще раз показали определение.
[29:16.000 --> 29:18.000]  Все-все-все.
[29:18.000 --> 29:20.000]  Да-да. Прекрасно. Я теперь...
[29:20.000 --> 29:22.000]  Спасибо, что прокомментировали.
[29:22.000 --> 29:24.000]  Так. Вроде бы остался вопрос только про применение.
[29:24.000 --> 29:26.000]  Ну, смотрите. Во-первых,
[29:26.000 --> 29:28.000]  поскольку эта штука...
[29:28.000 --> 29:30.000]  Вот эта штука, она в каком смысле стандартна,
[29:30.000 --> 29:32.000]  потому что формулируется через конус.
[29:32.000 --> 29:34.000]  К ней сводится то, что мы до этого
[29:34.000 --> 29:36.000]  обсуждали про квадратические задачи.
[29:36.000 --> 29:38.000]  Сейчас я попытаюсь
[29:38.000 --> 29:40.000]  как раз продемонстрировать,
[29:40.000 --> 29:42.000]  каким образом мы можем привести
[29:42.000 --> 29:44.000]  вот это в
[29:44.000 --> 29:46.000]  вот этот вид и воспользоваться
[29:46.000 --> 29:48.000]  солверами, которые, собственно, сделаны
[29:48.000 --> 29:50.000]  специально образом для вот этого.
[29:50.000 --> 29:52.000]  Ну, здесь всего плюс-минус...
[29:52.000 --> 29:54.000]  Ну, проблема понятна.
[29:54.000 --> 29:56.000]  То есть надо преобразовать вот эту штуку,
[29:56.000 --> 29:58.000]  которая у нас была,
[29:58.000 --> 30:00.000]  в то, что какой-то вектор
[30:00.000 --> 30:02.000]  будет лежать в K2.
[30:02.000 --> 30:04.000]  И тут нам сейчас честно образом поможет то,
[30:04.000 --> 30:06.000]  что если у нас есть матрица
[30:06.000 --> 30:08.000]  строго положительно определенная,
[30:08.000 --> 30:10.000]  то у нее есть там разложение Халецкого
[30:10.000 --> 30:12.000]  верхнюю и нижнюю треугольную матрицу.
[30:12.000 --> 30:14.000]  То есть это нижнюю треугольную, это, соответственно,
[30:14.000 --> 30:16.000]  верхнюю треугольную. Это некоторый факт, который
[30:16.000 --> 30:18.000]  приведет. Вот. Тогда мы можем, понятное дело,
[30:18.000 --> 30:20.000]  записать вот так. Ой,
[30:20.000 --> 30:22.000]  ничего не видно.
[30:22.000 --> 30:24.000]  Плюс, чтобы это Х, плюс
[30:24.000 --> 30:26.000]  Р, да? Вот. Ну, а дальше хочется, как будто
[30:26.000 --> 30:28.000]  полный квадрат выделить. Вот.
[30:28.000 --> 30:30.000]  И давайте сейчас попытаемся это проделать
[30:30.000 --> 30:32.000]  и поймем, почему это все дело приведет.
[30:32.000 --> 30:34.000]  Что еще у нас тут есть? У нас тут есть
[30:34.000 --> 30:36.000]  LTX транспонированный на
[30:36.000 --> 30:38.000]  LTX, да?
[30:38.000 --> 30:40.000]  Потом идет плюс удвоенное произведение
[30:40.000 --> 30:42.000]  LTX на какой-то,
[30:42.000 --> 30:44.000]  видимо, Q.
[30:44.000 --> 30:46.000]  Типа транспонированное, да?
[30:46.000 --> 30:48.000]  На Q и плюс
[30:48.000 --> 30:50.000]  Q транспонированное Q.
[30:50.000 --> 30:52.000]  Ну, давайте сейчас просто внимательно
[30:52.000 --> 30:54.000]  посмотрим и
[30:54.000 --> 30:56.000]  поймем, что
[30:56.000 --> 30:58.000]  все это как бы будет означать.
[30:58.000 --> 31:00.000]  Да, я не пропал. Я умышленно
[31:00.000 --> 31:02.000]  замьючил микрофон, чтобы
[31:02.000 --> 31:04.000]  не шуметь, пока вы, возможно, пытаетесь
[31:04.000 --> 31:06.000]  вывести полный квадрат самостоятельно. Так.
[31:06.000 --> 31:08.000]  Короче говоря, я немножко переписал
[31:08.000 --> 31:10.000]  то, что было до этого написано.
[31:10.000 --> 31:12.000]  Смотрите, вот у нас, типа, первый умножитель,
[31:12.000 --> 31:14.000]  вот он здесь сидит. Вот. Вот у нас, типа,
[31:14.000 --> 31:16.000]  второй умножитель. Ой. Вот он, второй
[31:16.000 --> 31:18.000]  умножитель, который пошел сюда.
[31:18.000 --> 31:20.000]  И, учитывая то, что у нас там было неравенство
[31:20.000 --> 31:22.000]  менее шлюра нуля, он пошел вот сюда.
[31:22.000 --> 31:24.000]  Ну и минус R просто перенеслось. Вот.
[31:24.000 --> 31:26.000]  Отсюда что следует? Отсюда следует, что у нас
[31:26.000 --> 31:28.000]  как бы, если мы теперь попробуем
[31:28.000 --> 31:30.000]  это все дело свести, у нас получится, что у нас
[31:30.000 --> 31:32.000]  там LTX,
[31:32.000 --> 31:34.000]  вроде. Алло, алло. Так.
[31:34.000 --> 31:36.000]  А сейчас, а сейчас слышно?
[31:36.000 --> 31:38.000]  Тест-тест. Алло. Есть ли контакт
[31:38.000 --> 31:40.000]  какой-то? Тест-тест.
[31:40.000 --> 31:42.000]  Сейчас. Что-нибудь слышно? Алло.
[31:42.000 --> 31:44.000]  Дайте знак, какой-нибудь, пожалуйста.
[31:44.000 --> 31:46.000]  Так. Ну вот сейчас, вроде, все должно было вернуться.
[31:46.000 --> 31:48.000]  Пожалуйста, проверьте и откликнитесь.
[31:48.000 --> 31:50.000]  Что меня там слышно, видно?
[31:50.000 --> 31:52.000]  Ну, сейчас видно. Слышно, видно.
[31:52.000 --> 31:54.000]  Отлично. Все. Слышу. Здорово.
[31:54.000 --> 31:56.000]  Так. Сейчас я перевернусь. Ой.
[31:56.000 --> 31:58.000]  Перекручу. Да. Вот сейчас точно пропали.
[31:58.000 --> 32:00.000]  Все. На этом мы закончили. Так.
[32:00.000 --> 32:02.000]  Ну, короче, я вроде получилась
[32:02.000 --> 32:04.000]  выделить полный квадрат.
[32:04.000 --> 32:06.000]  Вот я тут попытался что-то
[32:06.000 --> 32:08.000]  подсветить какие-то одинаковые
[32:08.000 --> 32:10.000]  компоненты. То есть первое слагаем,
[32:10.000 --> 32:12.000]  второе слагаемое.
[32:12.000 --> 32:14.000]  Квадрат второго. Поскольку тут меньше либо равно,
[32:14.000 --> 32:16.000]  то...
[32:16.000 --> 32:18.000]  Так, а давайте я лучше вот так здесь напишу.
[32:18.000 --> 32:20.000]  Меньше либо равно нуля, да.
[32:20.000 --> 32:22.000]  Потом мы как бы прибавляем к обеим частям одно и то же.
[32:22.000 --> 32:24.000]  В частности, вот это. Вот. И R переносится вот сюда.
[32:24.000 --> 32:26.000]  Вот. Поэтому тут в итоге
[32:26.000 --> 32:28.000]  образуется выражение вида
[32:28.000 --> 32:30.000]  LTX
[32:30.000 --> 32:32.000]  плюс L
[32:32.000 --> 32:34.000]  минус T
[32:34.000 --> 32:36.000]  с волной, да, квадрат
[32:36.000 --> 32:38.000]  и меньше либо равно, чем
[32:38.000 --> 32:40.000]  ну, собственно, вот это вот L-1
[32:40.000 --> 32:42.000]  с волной,
[32:42.000 --> 32:44.000]  минус R. Вот.
[32:44.000 --> 32:46.000]  В общем, в итоге
[32:46.000 --> 32:48.000]  это все линейное преобразование
[32:48.000 --> 32:50.000]  вроде бы свели
[32:50.000 --> 32:52.000]  к тому самому конусу,
[32:52.000 --> 32:54.000]  который нам был нужен. Вот.
[32:54.000 --> 32:56.000]  То есть если у вас есть вот такая вот задача,
[32:56.000 --> 32:58.000]  то вам надо там проделать
[32:58.000 --> 33:00.000]  разложение Халецкого для каждой матрицы,
[33:00.000 --> 33:02.000]  получить с волной,
[33:02.000 --> 33:04.000]  который связан с B, понятно,
[33:04.000 --> 33:06.000]  я надеюсь, как там, типа, надбойку надо, конечно, поделить.
[33:06.000 --> 33:08.000]  Вот. И, возможно, там
[33:08.000 --> 33:10.000]  с треугольной линией с тем решить.
[33:10.000 --> 33:12.000]  И отсюда получатся
[33:12.000 --> 33:14.000]  ингредиенты, которые уже будут участвовать
[33:14.000 --> 33:16.000]  в построении концентрального порядка.
[33:16.000 --> 33:18.000]  То есть отсюда следует,
[33:18.000 --> 33:20.000]  то у нас было вот такое.
[33:20.000 --> 33:22.000]  Вот. Но сейчас будет еще вот такое.
[33:22.000 --> 33:24.000]  Вот. Да. На самом деле
[33:24.000 --> 33:26.000]  давайте вставим это в качестве упражнений.
[33:26.000 --> 33:28.000]  Если вы не придумаете, в следующий раз я, может быть,
[33:28.000 --> 33:30.000]  что-то про это расскажу. Вот здесь видите
[33:30.000 --> 33:32.000]  вот этот вот значечек. В общем,
[33:32.000 --> 33:34.000]  упражнение, привести пример
[33:34.000 --> 33:36.000]  или объяснить почему. Почему.
[33:36.000 --> 33:38.000]  То есть, типа, задача, давайте я обозначу
[33:38.000 --> 33:40.000]  какой-нибудь фигурной буквой P. P
[33:40.000 --> 33:42.000]  принадлежит вот такому семейству,
[33:42.000 --> 33:44.000]  но, но P
[33:44.000 --> 33:46.000]  не может быть представима как вот так.
[33:46.000 --> 33:48.000]  То есть, хочется понять, где зазор. Вот.
[33:48.000 --> 33:50.000]  Подумайте, это, наверное, будет полезно.
[33:50.000 --> 33:52.000]  Так. Все ли понятно по поводу
[33:52.000 --> 33:54.000]  сведения и того, как они
[33:54.000 --> 33:56.000]  с друг с другом связаны с задачей?
[33:56.000 --> 33:58.000]  Алё, меня слышно сейчас? Вижу плюсики, отлично.
[33:58.000 --> 34:00.000]  Гуд, спасибо. Да.
[34:00.000 --> 34:02.000]  Давайте
[34:02.000 --> 34:04.000]  вопросы. Так. Ну, окей. Давайте
[34:04.000 --> 34:06.000]  пойдём дальше. Наверное, геометрические
[34:06.000 --> 34:08.000]  задачи я пока пропущу.
[34:08.000 --> 34:10.000]  Вот. Там потому, что надо много всего
[34:10.000 --> 34:12.000]  вводить. И
[34:12.000 --> 34:14.000]  в общем, они, я бы не
[34:14.000 --> 34:16.000]  сказал, что очень часто, наверное,
[34:16.000 --> 34:18.000]  встречаются. Вот. Ну, в общем, в слайдах
[34:18.000 --> 34:20.000]  это есть. Поэтому, если кому интересно, может
[34:20.000 --> 34:22.000]  в слайде в описании там всё довольно подробно написано
[34:22.000 --> 34:24.000]  со ссылочками, со всеми делами. То есть, в общем,
[34:24.000 --> 34:26.000]  разобраться можно. Вот. Если будут какие-то вопросы,
[34:26.000 --> 34:28.000]  просто в чат напишите. Я там прокомментирую
[34:28.000 --> 34:30.000]  что-то. Вот. А сейчас давайте перейдём
[34:30.000 --> 34:32.000]  как раз временно это осталось.
[34:32.000 --> 34:34.000]  К следующему конусу, который у нас был,
[34:34.000 --> 34:36.000]  это задача с DP. Вот.
[34:36.000 --> 34:38.000]  Semi-definite. Semi-definite
[34:38.000 --> 34:40.000]  programming. Вот. Ну, и тут как бы
[34:40.000 --> 34:42.000]  два варианта есть, как обычно. Ну,
[34:42.000 --> 34:44.000]  не как обычно, конечно, но по-прежнему
[34:44.000 --> 34:46.000]  ищем X. Вот. Только теперь...
[34:46.000 --> 34:48.000]  Извините, а можете на секунду поднять на
[34:48.000 --> 34:50.000]  страницу? Да могу, конечно.
[34:50.000 --> 34:52.000]  В чём проблема? Вообще легко. Презентации лежат
[34:52.000 --> 34:54.000]  на GitHub, ёлки-палки. Ссылки вроде бы
[34:54.000 --> 34:56.000]  в прикреплённом сообщении
[34:56.000 --> 34:58.000]  в чате. Ну и временный вопрос
[34:58.000 --> 35:00.000]  почти к концу первой
[35:00.000 --> 35:02.000]  половины, где лежат презентации.
[35:02.000 --> 35:04.000]  Сейчас я проверю.
[35:04.000 --> 35:06.000]  Ну, спасибо. Слушайте, ну да, вот в
[35:06.000 --> 35:08.000]  прикреплённом сообщении в первом, там куча
[35:08.000 --> 35:10.000]  ссылок. И вот первая ссылка у нас
[35:10.000 --> 35:12.000]  на репетиторию с слайдами лекций.
[35:12.000 --> 35:14.000]  Всё закреплённо. Ну, по крайней мере, у меня
[35:14.000 --> 35:16.000]  получилось. Вряд ли у меня какие-то...
[35:16.000 --> 35:18.000]  Там надо просто несколько раз нажать. Так, всё.
[35:18.000 --> 35:20.000]  Вроде все всё спасали, что хотели.
[35:20.000 --> 35:22.000]  И, соответственно, хитрость в том,
[35:22.000 --> 35:24.000]  что ограничение, которое мы сейчас здесь
[35:24.000 --> 35:26.000]  встретим, оно имеет довольно жуткий вид
[35:26.000 --> 35:28.000]  на первый взгляд. А именно вот такой
[35:28.000 --> 35:30.000]  там хит, давайте
[35:30.000 --> 35:32.000]  на фит. Больше ли бы равно
[35:32.000 --> 35:34.000]  нуля, где ж
[35:34.000 --> 35:36.000]  и фит все симметрично.
[35:36.000 --> 35:38.000]  Вот. То есть смотрите, что произошло.
[35:38.000 --> 35:40.000]  У нас внезапно наши
[35:40.000 --> 35:42.000]  иксы некоторым образом взвешивают
[35:42.000 --> 35:44.000]  симметричные матрицы,
[35:44.000 --> 35:46.000]  так чтобы в результате получилась положительно
[35:46.000 --> 35:48.000]  полуопределённая матрица.
[35:48.000 --> 35:50.000]  Чувствуете, насколько пошло усложнение?
[35:50.000 --> 35:52.000]  То есть теперь у нас тут, типа, неопределённость
[35:52.000 --> 35:54.000]  надо проверять. Ну, другая форма записи,
[35:54.000 --> 35:56.000]  смысл которой мы поймём
[35:56.000 --> 35:58.000]  через, наверное, две недели, я надеюсь,
[35:58.000 --> 36:00.000]  может быть, а может уже и на следующий поймём.
[36:00.000 --> 36:02.000]  Вот. Она вот так вот выглядит.
[36:02.000 --> 36:04.000]  То есть мы минимизируем
[36:04.000 --> 36:06.000]  некоторый след. То есть тут уже
[36:06.000 --> 36:08.000]  перемена эта матрица. Вот.
[36:08.000 --> 36:10.000]  При условии, что сама матрица положительно
[36:10.000 --> 36:12.000]  полуопределена, а след
[36:12.000 --> 36:14.000]  вот такой штуки равен там
[36:14.000 --> 36:16.000]  условно быитому. Вот. То есть
[36:16.000 --> 36:18.000]  так. Всё. Окей.
[36:18.000 --> 36:20.000]  Значит, ещё раз. У нас такая задача,
[36:20.000 --> 36:22.000]  где целевая функция всё ещё
[36:22.000 --> 36:24.000]  линейна. А в другой постановке
[36:24.000 --> 36:26.000]  та же самая задача. Через некоторое время
[36:26.000 --> 36:28.000]  поймом почему это та же самая задача. Там тоже
[36:28.000 --> 36:30.000]  целевая функция линейна, только она линейна по натрице.
[36:30.000 --> 36:32.000]  То есть вот эта штука, это ведь, на самом деле,
[36:32.000 --> 36:34.000]  есть не что иное как скалярное произведение
[36:34.000 --> 36:36.000]  между матрицами. И вот это тоже это скалярное
[36:36.000 --> 36:38.000]  произведение между матрицами. То есть в принципе
[36:38.000 --> 36:40.000]  можно углядеть, что вот то, что
[36:40.000 --> 36:42.000]  мы здесь видим справа, есть
[36:42.000 --> 36:44.000]  не что иное, как об highlight линейного программирования
[36:44.000 --> 36:46.000]  на случай переменной,
[36:46.000 --> 36:48.000]  которая является матрицей. Тем или видно и понятно,
[36:48.000 --> 36:52.680]  аналогия. Оставьте, пожалуйста, плюсики, если понятно. Вижу четыре плюсика. Интересно, это все кто
[36:52.680 --> 36:59.760]  остался в живых. Так, вижу пятый, но не уловил идею. В втором случае x это матрица, это правда,
[36:59.760 --> 37:07.640]  да, x из Rn, тут вот надо написать x из Rn на n. Да, но идея в том, что вот у нас было линейное
[37:07.640 --> 37:12.480]  программирование, вот видите, что мы тут в самом начале делали. У нас было скалярное произведение
[37:12.480 --> 37:17.440]  между векторами, линейное ограничение, которое тоже как бы набор скалярных произведений между
[37:17.440 --> 37:23.480]  строками матрица и столбцом x и то, что x больше либо ровно нуля. А теперь, если мы хотим это
[37:23.480 --> 37:27.160]  обобщить на уровне матрицы, то мы что делаем? Мы говорим, что окей, у нас теперь про скалярное
[37:27.160 --> 37:31.640]  произведение между матрицами, скалярное произведение между, вместо строк матрицы у нас
[37:31.640 --> 37:36.480]  типа сами матрицы появились, аиты, и вместо того, чтобы x у нас был больше либо равно нуля,
[37:36.480 --> 37:41.360]  мы потребуем положительную полуопределенность. То есть как бы пытаемся обобщить то, что мы
[37:41.360 --> 37:47.520]  хорошо знаем? Стало ли понятной идеи? Процесс симметричный? Да, да, да, все симметрично. Ага, вижу, окей. Так, ну
[37:47.520 --> 37:54.840]  окей, давайте дальше пройдем. Вот, значит, что нам это все даст? Это нам даст, во-первых, ну мы понятно,
[37:54.840 --> 37:59.080]  что если у нас есть такая задача, то мы можем с легкостью получить lp. Каким образом получить lp?
[37:59.080 --> 38:08.640]  Если, что надо сказать, ну уже 0. Ой, вот сейчас будем про левую форму говорить. Вот, ну не плюс,
[38:08.640 --> 38:15.000]  конечно. И if it, ну выдавайте, что должно произойти с if it, и какой вид они должны
[38:15.000 --> 38:18.520]  иметь, чтобы в итоге мы получили линейное программирование. То есть, смотрите, нам нужно
[38:18.520 --> 38:23.000]  сделать так, чтобы не отрицательно приносить некоторые матрицы, выродилось в требовании,
[38:23.000 --> 38:27.920]  чтобы все x и больше либо равно нуля. Что это за матрица такая? Диагональная. Совершенно верно,
[38:27.920 --> 38:33.560]  диагональная. Что на диагонале должно стоять? Положительные числа. Не совсем. Как с x это связано?
[38:33.560 --> 38:41.280]  Как диагональ связана с x? Да, именно так. То есть, да, на i-той позиции будет 1, то есть,
[38:41.280 --> 38:47.240]  это на самом деле диагональная матрица, только у них везде 0, 1 только на i-той позиции. Вот если
[38:47.240 --> 38:50.960]  мы зададим таким образом, то мы сведем нашу задачу к линейному программированию. Поэтому lp,
[38:50.960 --> 38:59.280]  понятно, тоже от множества sdp. Вот, теперь более хитрая штука про то, как свести sdp к конусу второго
[38:59.280 --> 39:05.160]  порядка. Точнее, ну да, как свести sdp к конусу второго порядка. Тут надо знать некоторые специальные
[39:05.160 --> 39:09.800]  факты, названием, что такое дополнение по шуру. Шур комплимент еще так называемый. Давайте я напишу
[39:09.800 --> 39:15.920]  сразу правильное название. Шур комплимент. Вот, это значит такая история. Если у вас есть блочная
[39:15.920 --> 39:23.040]  матрица симметричная, то, значит, если c положительно определена, то вот положительная
[39:23.040 --> 39:27.280]  определенность вот тогда, прошу прощения, что это какие-то проблемы со связью. Так, в общем,
[39:27.280 --> 39:33.280]  я остановился на том, что, сейчас я покажу картинку, что у нас будет сейчас заполнение по шуру,
[39:33.280 --> 39:38.800]  в котором мы рассмотрим блочную матрицу, и, рассмотрев правильную блочную матрицу,
[39:38.800 --> 39:43.640]  мы сведем полупределенную задачу, полупределенную оптимизацию к конусу второго порядка.
[39:43.640 --> 39:51.520]  Можете еще раз? Можно еще дописать предыдущую? Да, конечно, вот, пожалуйста. Видно, да, все?
[39:51.520 --> 40:00.760]  Понятно было про fit и почему единичная на нужном месте должна стоять. Так, можно продолжить? Да.
[40:00.760 --> 40:08.280]  Отлично, спасибо. Вот, смотрите, это нам поможет в следующем моменте, что мы представим, что наше
[40:08.280 --> 40:13.880]  вот ограничение основное, которое было, вот меньше либо равно t, это на самом деле будет нам
[40:13.880 --> 40:22.520]  равносильно тому, что вот такая матрица t, x, x-транспонированная t на единичную матрицу,
[40:22.520 --> 40:29.600]  будет положить на полупределенную. Вот, ну, то есть, смотрите, что произошло. Вот здесь роль, ну,
[40:29.600 --> 40:34.440]  типа, понятно, что результат про c таким же образом преобразуется в результат про a,
[40:34.440 --> 40:42.080]  только надо комплимент считать относительно a, а не c. Вот, и поэтому вот эта штука, как вот это
[40:42.080 --> 40:47.600]  связано с вот этим. Давайте рассмотрим, сейчас давайте поймем, что надо рассмотреть. Собственно,
[40:47.600 --> 40:54.600]  что у нас здесь положить на определенную? Ну, вот это положение поделено, да? Вот, только, да, только
[40:54.600 --> 41:00.160]  не это надо будет сейчас рассматривать. То есть у нас положить на определенный блок строго вот
[41:00.160 --> 41:06.400]  вот это t, а t больше нуля у нас. Вот, давайте посмотрим, что это значит. Что мы должны взять,
[41:06.400 --> 41:13.080]  а, все было правильно, сейчас. Вот, давайте сравним вот эти две матрицы. Вот эту матрицу и вот эту
[41:13.080 --> 41:18.640]  матрицу. Вот, и запишем вот это выражение. Не тот стиль. Вот, то есть, что у нас тут такое? А это t
[41:18.640 --> 41:25.400]  минус b, b это xt, умножается на c в минус первый. c в минус первый это единица на t на единичную
[41:25.400 --> 41:32.960]  матрицу, на bt, bt это x. Эта штука, это же число, я надеюсь, это понятно, больше либо равно нуля. Ну, и это
[41:32.960 --> 41:38.840]  напрямую, напрямую означает, что t квадрат больше либо равно квадрат рефлидовой нормы x. Понятно ли,
[41:38.840 --> 41:44.440]  какие преобразования были сделаны? Вроде бы понятно. Вот, ну, соответственно, если мы проделаем
[41:44.440 --> 41:50.360]  линейные, ну, линейные преобразования аргументов, то матрица, понятно, как изменится. То здесь просто
[41:50.360 --> 42:01.880]  появится. А почему, если матрица a, b, b транспонирована, c положительно определенная, то верное неравенство? Ну, то есть, не отрицательное. Ну, то есть вопрос, почему это верно, да? Да. Ну,
[42:01.880 --> 42:07.480]  давайте сейчас попытаемся доказать своевременный вопрос. Вот. Ну, значит, это все связано с так называемым
[42:07.480 --> 42:15.400]  площным исключением. Вот. И, в общем, сейчас давайте я подумаю, насколько тут обе стороны действительно
[42:15.400 --> 42:26.160]  важно. Сейчас. Бам-бам-бам-бам-бам. Ну, наверное, давайте начнем тогда с... Сейчас, секунду. Рассмотрим вот эту
[42:26.160 --> 42:34.320]  вот матрицу сейчас. Попробуем доказательство какое-то провести. Может быть, не до конца, но вот. И пусть вот это
[42:34.320 --> 42:39.200]  выполнено. Значит, тогда что мы знаем? Мы знаем, что раз квадратичная форма положить на полуопределенное, то у нас
[42:39.200 --> 42:46.480]  есть что для любого вектора x... Рассмотрим блочный вектор. Теперь x, y. И мы имеем, что выполнено вот это.
[42:46.480 --> 42:55.880]  Там, по-моему, двойка должна появиться. ytbx плюс ytcy, да? Это будет больше либо равна нуля. Теперь, если мы
[42:55.880 --> 43:03.320]  рассмотрим функцию... Да, собственно, возьмем, проминимизируем вот эту штуку по y, то есть это будет там
[43:03.320 --> 43:08.240]  g от x и y. Вот раз эта штука больше либо равна нуля, то эта штука тоже будет больше либо равна нуля. Это
[43:08.240 --> 43:14.360]  будет некоторая функция f от x. Надеюсь, пока что все было понятно. Ну, то есть у нас функция от блочного
[43:14.360 --> 43:19.280]  вектора. Мы взяли квадратичную форму. Поскольку она больше либо равна нуля всегда для любого, то мы взяв
[43:19.280 --> 43:26.400]  минимум по одному блоку, мы положительность не сломаем и получим новую некоторую функцию от оставшегося
[43:26.400 --> 43:34.160]  блока. Вот все, что произошло. Да, понятно. Окей. Значит, смотрите, теперь важный может быть момент,
[43:34.160 --> 43:43.480]  что при каждом фиксированном x наш функция g, она будет выпукла. Поэтому мы можем явным
[43:43.480 --> 43:49.880]  образом решить эту задачу при каждом фиксированном x. Ну, ответ... Ну, то есть, понятно, взять... А, мы пока не
[43:49.880 --> 43:57.720]  можем решить эту задачу, конечно. В общем, я надеюсь, что вспомнив какие-то азы матанализа, более-менее
[43:57.720 --> 44:04.200]  понятно, что раз эта будет функция выпукла, то нам достаточно найти локальный минимум, а локальный минимум
[44:04.200 --> 44:10.000]  мы ищем тем, что у нас градиент блочки должен быть ноль. Я как раз хотел успеть, возможно даже успею это
[44:10.000 --> 44:16.200]  показать более аккуратно. В общем, нам достаточно посчитать градиент этой штуки по y, приравнить его к нулю
[44:16.200 --> 44:22.120]  и получить тот результат, что y со звездочкой у нас будет равен, подгляжу, понятное дело, своей
[44:22.120 --> 44:29.360]  записи, минус c в минус первый bx. Вот. Вот этому будет равен y со звездочкой. Соответственно, если мы
[44:29.360 --> 44:34.720]  теперь подставим этот y со звездочкой в g, то получим, что наш f от x будет равно следующей
[44:34.720 --> 44:39.920]  штуке. Вы не поверите, но это будет ровно то, что нам надо продемонстрировать. x транспонировано a
[44:39.920 --> 44:46.240]  минус bc минус первый bt, если я правильно проставил транспонирование. Нет, конечно, неправильно. Вот, на x.
[44:46.240 --> 44:51.720]  И эта штука всегда больше 0. А значит, эта штука положить на полуопределена по определению положить
[44:51.720 --> 44:57.360]  на полуопределенную квадратичную форму. Понятна ли логика? Если нужно провести какие-то детальные
[44:57.360 --> 45:01.840]  выплотки, вы, пожалуйста, скажите. То есть, тут два места, где их надо может быть провести, вот здесь. Давайте
[45:01.840 --> 45:07.200]  я поставлю галочку. Вот. И вот здесь. Давайте я поставлю две галочки. Понятно ли, что надо делать
[45:07.200 --> 45:12.720]  с каждым из этих этапов? Вот. Или не очень понятно? Пожалуйста, поясните. Наверное, не очень понятно. Не
[45:12.720 --> 45:17.760]  очень понятно. Да. Ну, смотрите тогда, давайте. Значит, вот как мы получили y со звездочкой? Получаем
[45:17.760 --> 45:26.320]  y со звездочкой. Мы берем g штрих по y от x, y. Вот. Ну, градиент. Понятно, что все, что зависит от x,
[45:26.320 --> 45:32.640]  у нас улетает благополучно. От квадратичной формы у нас остается 20y. Вот. От линейной функции у нас
[45:32.640 --> 45:44.120]  остается плюс два, что тут еще остается-то? x транспонирован bx, я понимаю, да? Вот. Равно нулю. Вот.
[45:44.120 --> 45:49.560]  Ну, отсюда y со звездочкой, вот он равен блестящим образом минус c в минус первый bx. Вот. Понятно ли,
[45:49.560 --> 45:55.040]  что здесь произошло? Да. Очень хорошо. Вот. Ну, теперь давайте это все добро подставлять. Так. Тут, видимо,
[45:55.040 --> 46:03.280]  мне нужно немножко сжать, чтобы все было видно. Ну, смотрите, x транспонирован аx плюс два, y
[46:03.280 --> 46:08.080]  транспонирован. Ну, в первую очередь, минус появляется. Вот. Минус сейчас нам поможет. Что тут?
[46:08.080 --> 46:17.560]  x транспонирован, b транспонирован, c минус транспонирован на bx и плюс. Ну, тут плюс останется,
[46:17.560 --> 46:25.880]  потому что 2a минусы сократятся. x транспонирован, что там, b транспонирован, c минус транспонирован
[46:25.880 --> 46:34.480]  на c на c минус первый bx. Вот. Такое выражение. Я надеюсь, я нигде не напортачил. Вот. Ну, сейчас
[46:34.480 --> 46:39.920]  все должно сократиться моментально. Сейчас мы это поймем. Вот. Ну, что тут происходит? Ну, во-первых,
[46:39.920 --> 46:48.080]  вот это в единичку уходит очевидным образом. Остается x транспонирован на ax минус 2 x
[46:48.080 --> 46:58.400]  транспонирован на btc-tbx плюс. Что осталось? x транспонирован на btc-tbx. Вот. Чудо. Вот это
[46:58.400 --> 47:07.440]  совпадает с вот этим. Поэтому это значит, что это все дело равно x транспонирован на a минус btc-t.
[47:07.920 --> 47:13.360]  Ну, минус t уходит в минус единицу, потому что там симметричность есть. Насколько я понимаю,
[47:13.360 --> 47:22.320]  да, симметричность там точно есть. Вот. Поэтому тут я потом давайте это допишу. b и x. Вот это уходит
[47:22.320 --> 47:28.640]  в c минус первую, так как это симметричная. Вот. Вот получилось такое выражение, которое я вроде
[47:28.640 --> 47:34.800]  где-то вы же там и записал. Стало ли понятнее? Да, спасибо. Окей, супер. Так, good. Это было, значит,
[47:34.800 --> 47:40.560]  доказательство прошел комплимент. Вот. Да, это было только в одну сторону. Что делать в другую
[47:40.560 --> 47:46.240]  сторону? В другую сторону там, по-моему, делается что-то от противного. Давайте тогда в другую,
[47:46.240 --> 47:52.960]  в обратную сторону я в следующий раз с этого начну. Вот. А сейчас так, я тут хотел еще рассказать про
[47:52.960 --> 47:59.360]  много чего. Да, давайте расскажу еще про всякие забавные вещи. Да, и тут, наверное, уже писать
[47:59.360 --> 48:06.480]  ничего не надо будет. Топ шер и... А можете показать еще раз? Экран чуть-чуть пониже. Слушайте,
[48:06.480 --> 48:11.600]  а давайте я выложу просто запись и все. Давайте, было бы вообще шикарно. Прекрасно. Все остальные,
[48:11.600 --> 48:18.520]  кстати, тоже надо будет выкладывать. Что-то я это забыл об этом. Так, лекция. Да, вот, лекция. Вот.
[48:18.520 --> 48:24.400]  Короче, задач MaxCut. Пояс максимального разреза граф. Я надеюсь, все в курсе, что такой граф и что
[48:24.400 --> 48:31.640]  такое его разрез. Вот. И, собственно, надо найти, по сути, такой набор ребер, так чтобы сумма весов
[48:31.640 --> 48:37.240]  была максимальной, и они разделяли бы вершины на два не пересекающихся множества. Вот. Собственно,
[48:37.240 --> 48:41.840]  MaxCut формулируется вот таким вот образом. Видите, тут все дискретное. Вот. Мы с этой задачей еще поговорим,
[48:41.840 --> 48:47.640]  встретимся ближе к концу курса, когда будем про выпукла и релаксации обсуждать, и сдача из
[48:47.640 --> 48:54.880]  DP туда же пойдет. Вот. Идея в том, что мы суммируем. Собственно, у нас X это наши вершинки. Вот. И они либо
[48:54.880 --> 49:00.360]  в одном ношусь, либо в другом. И нам нужно максимизировать сумму весов тех ребер, которые
[49:00.360 --> 49:06.520]  их соединяют. Вот. Соответственно, если X одного знака, то эта штука зануляется, и мы вес не учитываем.
[49:06.520 --> 49:11.960]  Если они разного знака, то эта штука отрицательна. Вот. Поэтому тут одна вторая стоит. Вот. На самом деле,
[49:11.960 --> 49:16.200]  тут, возможно, надо еще... А, ну да, тут одна вторая стоит, и мы суммируем только, ну, понятное,
[49:16.200 --> 49:20.800]  повторяющиеся пары мы не учитываем. Поэтому одна вторая достаточно. Понятная ли пословка задачи?
[49:20.800 --> 49:28.080]  Вы слишком быстро. Почему выбираете одна вторая? Потому что, если X разного знака, то это все в сумме
[49:28.080 --> 49:33.320]  дают двоечку. И нам нужно, ну, чтобы сумма весов была честная, нам нужно двоечку поделить. Ага. Так.
[49:33.320 --> 49:40.000]  Еще к вопросу. Так. Ну, вопросов вроде нет. Окей. Вот это все можно переписать в матричной векторном
[49:40.000 --> 49:44.640]  виде. Вот эту целевую функцию. Явным образом. Вот таким вот. Вот таким вот. Потому что, ну,
[49:44.640 --> 49:50.560]  понятно, что max, тут стоит минус, поэтому мы переписываем в мин. А x, i, t, x, z, z на w и z,
[49:50.560 --> 49:56.240]  это просто кадротичная форма. Вот. Понятно, что, если мы уберем здесь i и z, то тут появится одна
[49:56.240 --> 50:01.320]  четвертая. Вот. Ну, в принципе, наверное, стоит вообще убрать эту константу и уже не мучиться с ней.
[50:01.320 --> 50:06.440]  Вот. Соответственно, какой будет эквивалентный вид у этого выражения? Ну, мы можем воспользоваться
[50:06.440 --> 50:14.320]  свойством следа и перенести x сюда. И записать, что это след от x, x-транспонированной w. Вот. Обозначив,
[50:14.320 --> 50:20.880]  а, то есть, наоборот, w на x, x-транспонированной. Так будет лучше. Вот. Обозначим x, x-транспонированной
[50:20.880 --> 50:25.160]  за большую матрицу, x большой. И скажем, что она у нас положительно полуопределена. Ее диагона
[50:25.160 --> 50:30.040]  равна единице, потому что все x либо плюс, либо минус один. Ее ранг равен единице. Понятно ли,
[50:30.040 --> 50:34.520]  почему этого достаточно? Алло, меня вообще слышно? Да, слышно. Так, это хорошо. А есть ли
[50:34.520 --> 50:38.720]  понимание, почему такое-такая перезапись, она правомерна? Вот люди, почему-то начинают
[50:38.720 --> 50:43.640]  писать, что вроде понятно. То есть, мы, по сути, ввели новое обозначение для матрицы ранга 1 и
[50:43.640 --> 50:49.320]  навесили все необходимые ограничения на эту матрицу. Вот. А дальше домашнее упражнение — понять,
[50:49.320 --> 50:55.400]  что множество матриц фиксированного ранга образует невыпуклое множество. Вот. И чтобы,
[50:55.400 --> 50:59.800]  как бы, нам все-таки можно было как-то решить задачу методами оптимизации, мы просто берем и
[50:59.800 --> 51:04.600]  говорим, окей, давайте мы откажемся от этого ограничения на ранг. Вот. Но получим какое-то
[51:04.600 --> 51:08.800]  решение, а дальше будем смотреть, каким образом можно восстановить исходный вектор. Про то,
[51:08.800 --> 51:12.160]  как он восстанавливается, мы посмотрим на одной из последних лекций. Там довольно
[51:12.160 --> 51:17.080]  знаменитый алгоритм его восстановления существует, вероятно, знаете. Вот. Это про
[51:17.080 --> 51:23.800]  MaxCAD и то, почему, как связана задача с ДП, с этой задачей. Вот. Так. Вопросы какие-нибудь есть
[51:23.800 --> 51:29.680]  по тому, что мы только что проделали? Так. Вопросов вроде бы нет. Ну ладно. Так. Ну и последнее,
[51:29.680 --> 51:34.280]  что хочется показать, красивую картину, конечно же. Вот. Смотрите. Такая задачка, короче, есть набор
[51:34.280 --> 51:41.360]  точек. Вот. И хочется построить такой эллипсоид, чтобы его площадь была минимальна, но он покрывал бы
[51:41.360 --> 51:46.120]  все эти точки. То есть, короче, хочется получить вот это. Понятно ли задача на неформальном уровне?
[51:46.120 --> 51:51.840]  То есть, как из вот такого набора точек получить вот такую картинку? Все. Замечательно. Отлично. Я
[51:51.840 --> 51:57.120]  понял. Замечательно картинках объяснять. Кажется, это гораздо быстрее приходит понимание. Ну вот.
[51:57.120 --> 52:02.160]  Теперь как это, собственно, происходит формально? Формально надо немножко поднапрячься. Поскольку
[52:02.160 --> 52:07.560]  у нас, то есть, мы хотим найти эллипс. Эллипс – это трансформированный круг. Площадь эллипса,
[52:07.560 --> 52:13.520]  она параметризуется детерминатом матрицы преобразования обратной, которой был преобразован
[52:13.520 --> 52:18.480]  шарик. Помните такое в матанализе было, да, что там типа мы замены переменных делали в интеграле,
[52:18.480 --> 52:23.360]  и надо было на детерминат матрицы якобы умножить. Было такое. Ну вот. Есть та же самая история.
[52:23.360 --> 52:28.480]  Поскольку мы хотим сделать минимальную площадь, то нам надо минимизировать детерминат обратной
[52:28.480 --> 52:33.120]  матрицы. Вот. Детерминат является выпуклой, не вогнутой функцией. Тоже домашнее упражнение,
[52:33.120 --> 52:38.360]  проверьте, что это так. Вот. Однако его логорифм, его логорифм – это монотонная функция, поэтому
[52:38.360 --> 52:42.560]  точку минимума это не изменит. Вот. Но минус логорифм детермината – уже выпуклая функция. Мы это вроде
[52:42.560 --> 52:46.640]  бы даже показывали на одной из прошлых лекций. Поэтому вместо… Поэтому, по сути, в чем задача
[52:46.640 --> 52:53.000]  заключается? Нам нужно найти такую матрицу и такой вектор B так, чтобы логоринат детермината,
[52:53.000 --> 52:57.840]  который как бы прокси-функция для площади, был поменьше. При этом матрица была положить на
[52:57.840 --> 53:03.840]  определенной. А все точки, которые лежат в эллипсе, то есть для которых вот это вот… Ну то есть то,
[53:03.840 --> 53:07.680]  что они лежат в эллипсе, означает, что, грубо говоря, вот эта штука меньше единицы. Вот. Единица
[53:07.680 --> 53:11.760]  здесь выбрана чисто условно, потому что мы всегда можем отшкалировать, поделив на какую-нибудь
[53:11.760 --> 53:16.320]  константу, для того, чтобы, ну как бы, было это нераянство выполнено. Вот и все. То есть мы,
[53:16.320 --> 53:20.360]  по сути, минимизируем логорину детермината. То есть минус… Ну, логорина детермината в минус
[53:20.360 --> 53:26.960]  первой – это минус логорины детермината A. Понятно. Я надеюсь. Понятно же, да? Так. Детермината в
[53:26.960 --> 53:31.640]  минус первой – это там единичка на детерминат, поэтому логорифм… Да, все. Минус… Минус вроде
[53:31.640 --> 53:36.200]  понятно. Вот. Поэтому мы это минимизируем. И вот получаем выпуклую… Задачу выпуклой оптимизации,
[53:36.200 --> 53:40.200]  которая сходу не очень понятна, к чему относится. Ну, судя по тому, что есть такое ограничение,
[53:40.200 --> 53:44.760]  это будет СДП, очевидно. Но там будет также конус со второго порядка. То есть это такой будет
[53:44.760 --> 53:50.080]  микс конусов, который будут каким-то образом взаимодействовать, и таким образом финальный
[53:50.080 --> 53:53.880]  конус, который будет получаться, будет позволять так изоще решать. Вот. Поэтому, в общем, получается
[53:53.880 --> 53:57.880]  вот такое решение, довольно красивое. Вот. Применение у этой достаточно геометрической
[53:57.880 --> 54:03.120]  постановки следующее. Ну, обычное. Какое приводит? Наверняка есть много разных других. Ну, первое,
[54:03.120 --> 54:09.280]  там это вся в какой-нибудь статистике. Там надо что-то оценить разбросы, где кто находится. Вот.
[54:09.280 --> 54:16.960]  Из какой-то более-менее инженерии это типа у вас есть набор этих потребителей. Ну, типа мобильной
[54:16.960 --> 54:24.440]  связи, например. Вот. И вам нужно понять, куда поставить там, условно, эту вышку. Вот. Так,
[54:24.440 --> 54:30.280]  чтобы минимизировать потребление энергии. Но так, чтобы все потребители были в охвате этой
[54:30.280 --> 54:34.720]  самой вышки. Вот. Ну, вот как бы понятно, что построив такой эллипс, вы можете понять, где у
[54:34.720 --> 54:41.160]  него какие-то фокусы, центры. Вот. И таким образом оценить, сколько, какая мощная сигнала вам нужна
[54:41.160 --> 54:45.920]  для того, чтобы покрыть всех потребителей. Вот. Ну, я надеюсь, понятно ли пример на приложение? Ну да,
[54:45.920 --> 54:49.720]  вот кому-то понятно. Это прекрасно. Наверное, все остальные уже убежали на следующую пару. Хотя,
[54:49.720 --> 54:56.160]  да, сейчас уже будем заканчивать. Так. Два человека что-то осознали. Все понятно. Это прекрасно. Вот.
[54:56.160 --> 55:01.480]  Так. Это я уже сегодня сказал. Да. Ура. Мы вроде добили эту лекцию. Тогда, значит, следующая лекция
[55:01.480 --> 55:06.920]  будет самой такой, наверное, тяжелой и теоретически нагруженной. Вот. Плюс меня в обратную сторону этот
[55:06.920 --> 55:12.000]  факт. Вом от противного как-то все делается. Сейчас сходу не хочу отображать. Вот. Лучше в следующий
[55:12.000 --> 55:17.120]  раз аккуратно все покажу. Вот. В следующий раз на чем-то слое оптимальностей. Вот. Я надеюсь, как-нибудь
[55:17.120 --> 55:22.160]  и двойцами скоснемся. Вот. Поэтому пока что мы более-менее, я надеюсь, освоились тем, что
[55:22.160 --> 55:27.680]  так выпуклые задачи. Вот. Как они могут выглядеть. Какие конусы с ними связаны. Как они друг к другу
[55:27.680 --> 55:34.040]  переходят. Вот. То есть, в следующий раз смотрим, как их решать. Через раз там двойственность. Потом
[55:34.040 --> 55:39.840]  солверы. И потом начнем уже методы. То есть, да, плюс неделя, немножко надержки. Но я надеюсь,
[55:39.840 --> 55:45.600]  что на условиях оптимальности. Я самое сложное доказательство выложил в PDF. Вот. Поэтому там
[55:45.600 --> 55:50.360]  мы и двойственность немножко захватим в более как бы активном образе. Все. Всем спасибо, что
[55:50.360 --> 55:54.040]  подключились. Я постараюсь в следующий раз как-то купировать все эти разрывы,
[55:54.040 --> 55:58.440]  которые довольно раздражают сильно. Вот. И постараюсь, чтобы была более гладкая связь.
