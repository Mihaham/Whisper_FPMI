[00:00.000 --> 00:14.400]  Сегодня поговорим на тему, которая немножко особняком стоит. Эта тема называется схемная сложность.
[00:30.000 --> 00:46.400]  Глобально оставшиеся три апрельские лекции будут посыщены различным вероятностным вычислением.
[00:46.400 --> 00:57.400]  Поговорим про вероятностные классы, про их соотношения с разными классами, которые мы изучили,
[00:57.400 --> 01:05.400]  и в том числе с этими схемными классами. Поэтому мы их сейчас немножко обсудим.
[01:06.400 --> 01:15.400]  Еще будет тема про интерактивные доказательства. Насколько я понимаю, в одной группе про них уже пытались поговорить на семинарах,
[01:15.400 --> 01:24.400]  но мы про них какие-то базовые вещи изучим, которые пригодятся осенью на курсе по криптографии.
[01:24.400 --> 01:31.400]  Поэтому про схемную сложность я расскажу не очень много, какие-то самые базовые вещи, которые нам будут нужны
[01:31.400 --> 01:40.400]  в теме про вероятностные вычисления. В некотором смысле эта тема стоит особняком,
[01:40.400 --> 01:52.400]  потому что здесь вообще другая модель вычислений. Не совсем другая, но существенно отличная.
[01:53.400 --> 01:59.400]  Это называют неравномерные вычисления.
[02:12.400 --> 02:17.400]  Что это означает? Что за неравномерность, что за неравномерность?
[02:17.400 --> 02:26.400]  Вообще мы все знаем, так как часть определения алгоритма, что алгоритм применяется одинаково к любым входам,
[02:26.400 --> 02:36.400]  в том числе ко входам любой длины. А вот здесь, если совсем грубо говорить, то может быть свой алгоритм для каждой длины.
[02:36.400 --> 02:42.400]  И зависимость от длины может быть какая угодно, даже неучислимая.
[02:42.400 --> 02:57.400]  Интуиция такая, что свой алгоритм для входов каждой длины.
[03:06.400 --> 03:15.400]  Но и соответственно зависимость алгоритма от длины может быть даже неучислимой.
[03:15.400 --> 03:29.400]  Зависимость алгоритма от длины может быть неучислимой,
[03:29.400 --> 03:37.400]  но сам алгоритм должен быть в некотором смысле простым.
[03:37.400 --> 03:49.400]  Если у вас фиксирована длина, то у вас конечное число вообще входов, и в принципе можно хоть таблицей задать, что для такого-то входа такой-то ответ.
[03:49.400 --> 03:56.400]  Но эта таблица называется таблица истинности, и у нее будет длина экспоненциальная от длины.
[03:56.400 --> 04:07.400]  Соответственно мы хотим, чтобы для каждой длины был какой-то короткий алгоритм, который существенно короче, чем полный список ответов.
[04:07.400 --> 04:15.400]  Тогда это все-таки не все функции будут вычислимы в этом смысле, а только какие-то в некотором смысле простые.
[04:15.400 --> 04:25.400]  Зависимость алгоритма от длины может быть неучислимой, но в каждой конкретной длине алгоритм простой.
[04:25.400 --> 04:40.400]  В каждой конкретной длине алгоритм в каком-то смысле простой.
[04:40.400 --> 04:56.400]  Теперь может быть три разных подхода, которые все эквивалентны к тому, как мы понимаем, что в каждой длине свой алгоритм.
[04:56.400 --> 05:10.400]  Три эквивалентных подхода.
[05:10.400 --> 05:29.400]  Это схемы из функциональных элементов.
[05:29.400 --> 05:42.400]  Это прямолинейные программы.
[05:42.400 --> 05:56.400]  И это машины тьюринга с подсказками.
[05:56.400 --> 06:06.400]  Схемы это некоторое такое обобщение формул, где можно под формулу переиспользовать.
[06:06.400 --> 06:27.400]  Схемы это обобщение формул с возможностью переиспользования под формул.
[06:27.400 --> 06:32.400]  Как это достигается?
[06:32.400 --> 06:38.400]  Это достигается тем, что вместо дерева строится граф без циклов.
[06:38.400 --> 06:52.400]  Формула может представлять как дерево, что в узлах связки из двух или одной или нескольких подформул получается некоторая составная формула.
[06:52.400 --> 06:58.400]  В случае со схемами вместо дерева получается граф без циклов.
[06:58.400 --> 07:07.400]  Ориентированный граф без циклов, где одна и та же формула как узел графа может быть использована потом в разных новых узлах.
[07:07.400 --> 07:23.400]  Это получается, что дан ориентированный граф без циклов.
[07:23.400 --> 07:42.400]  Например, можно договориться, что будет n источников, то есть n вершин со входящей степенью 1 и 1 сток.
[07:42.400 --> 07:47.400]  1 сток, наоборот, не единица, а ноль.
[07:47.400 --> 07:54.400]  Источник в входящей степени ноль, сток в исходящей степени ноль.
[07:54.400 --> 08:06.400]  Ориентированный граф без циклов, n источников, где входящая степень равна нулю.
[08:06.400 --> 08:16.400]  1 сток, где исходящая степень равна нулю.
[08:16.400 --> 08:29.400]  На всех вершинах, которые не источники, стоит метка с какой-то бульвой функций.
[08:29.400 --> 08:46.400]  Если вершина не источник, стоит метка, например, конъюнция, дезюнция или отрицание.
[08:46.400 --> 08:51.400]  Если отрицание, то обязательно входящая степень 1.
[08:51.400 --> 09:06.400]  Если конъюнция, дезюнция, то можно договориться, что входящей степень обязательно 2, либо какая угодно положительная.
[09:06.400 --> 09:17.400]  Если метка отрицания, то тогда входящая степень равна 1.
[09:17.400 --> 09:33.400]  Если метка конъюнция или дезюнция, тогда входящая степень 2, ну или вариант, что любая больше нуля.
[09:33.400 --> 09:47.400]  Даже равную нулю можно разрешить, но если равна нулю, то это будет отдельно как источник.
[09:47.400 --> 09:56.400]  Если на источнике написать какие-то бульво значения, то дальше можно, так сказать,
[09:56.400 --> 10:01.400]  отсортировав вершину этого графа, вычислять значение бульвых функций.
[10:01.400 --> 10:28.400]  Если на источниках заданы бульво значения, то можно топологически отсортировав.
[10:28.400 --> 10:46.400]  Вершины. Можно последовательно вычислить значения в них во всех, ну и в том числе вот в этой самом стоке.
[10:46.400 --> 11:06.400]  Можно последовательно вычислить значения во всех вершинах.
[11:06.400 --> 11:25.400]  Согласно меткам. Примени функции согласно меткам.
[11:25.400 --> 11:33.400]  Ну и значение в стоке это как бы ответ.
[11:33.400 --> 11:41.400]  Значит ответ это значение в стоке.
[11:41.400 --> 11:50.400]  Так, ну примерно понятно, да? Вот, тогда в такой схемы есть два параметра количественных.
[11:50.400 --> 11:58.400]  Значит две количественные характеристики.
[11:58.400 --> 12:11.400]  Размер и глубина.
[12:11.400 --> 12:23.400]  Значит размер это просто число вершин.
[12:23.400 --> 12:33.400]  А глубина это максимальная длина пути от источника к стоку.
[12:33.400 --> 12:43.400]  Максимальная длина пути от источника к стоку.
[12:43.400 --> 12:55.400]  Ну и вот нас интересует, для каких задач какого размера и какой глубины могут быть семейства схем.
[12:55.400 --> 13:05.400]  Говорят, что множество или язык А распознается семейством схемы.
[13:05.400 --> 13:15.400]  А распознается семейством схем.
[13:15.400 --> 13:24.400]  Значит СН.
[13:24.400 --> 13:30.400]  Так, наверное нужно от единицы, потому что когда ноль входов, то это выраженный случай.
[13:30.400 --> 13:35.400]  Надо считать, что один вход все-таки будет.
[13:35.400 --> 13:44.400]  Ну с другой стороны, когда ноль входов.
[13:44.400 --> 13:49.400]  В смысле нет, почему нельзя?
[13:49.400 --> 13:55.400]  А когда ноль входов?
[13:55.400 --> 14:01.400]  Ну непонятно вообще, что будет.
[14:01.400 --> 14:07.400]  Действительно, в любом органазе без циклов есть источник, поэтому ноль входов быть не может.
[14:07.400 --> 14:14.400]  Соответственно либо мы случай вообще запретим, мы исключим из рассмотрения.
[14:14.400 --> 14:21.400]  Либо можно чуть-чуть поменять модель.
[14:21.400 --> 14:29.400]  То есть можно разрешить там тоже разные метки. Либо метка, что это вход, либо метка, что это константа.
[14:29.400 --> 14:37.400]  И тогда, соответственно, число входов это число источников с меткой вход, а все остальные будут нулями или единицами.
[14:37.400 --> 14:42.400]  В общем, в любом случае это выраженный случай, не важно, что там происходит.
[14:42.400 --> 14:48.400]  Так вот, значит, язык А распознается семейством схем.
[14:48.400 --> 14:54.400]  Если верно, следующее. Если для любого х...
[14:54.400 --> 15:02.400]  Значит, верно, что х лежит в А тогда и только тогда, когда, если мы возьмем соответствующую схему,
[15:02.400 --> 15:13.400]  соответствующую длине х, и на х запустим, то выдадим единицу.
[15:18.400 --> 15:23.400]  Так, ну ничего, понятно определение?
[15:23.400 --> 15:31.400]  Так, хорошо, значит, это первый подход. Это первый подход, когда у нас схема как обобщение формул.
[15:31.400 --> 15:36.400]  Так, второй подход, это прямолинейные программы.
[15:36.400 --> 15:42.400]  Значит, прямолинейные программы это программы без каких-либо разветвлений.
[15:42.400 --> 15:47.400]  То есть там нет циклов, нет условных переходов, а есть только присваивание.
[15:47.400 --> 15:57.400]  Значит, что такая-то новая переменная равна такой-то функции вот таких-то уже имеющихся переменных.
[15:57.400 --> 16:05.400]  Соответственно, функция у нас тоже будет из какого-то небольшого набора.
[16:05.400 --> 16:12.400]  Например, такого же, конъюнца-дезюнца, импликация.
[16:12.400 --> 16:24.400]  И, соответственно, нужно постепенно вычислять значение все новых и новых переменных.
[16:24.400 --> 16:29.400]  Ну а в конце будет ответ.
[16:29.400 --> 16:35.400]  Сейчас каких ограничений?
[16:35.400 --> 16:40.400]  Нет, это уже будут конкретные классы.
[16:40.400 --> 16:45.400]  Есть одни классы, где ограничивается размер, другие, где глубина.
[16:45.400 --> 16:48.400]  А, давайте пока вот что поймем.
[16:49.400 --> 17:04.400]  То есть простое утверждение, что для любой вообще функции, для любого языка,
[17:05.400 --> 17:18.400]  для любого языка существует распознающее его семейство схем.
[17:18.400 --> 17:36.400]  Значит, глубины, видимо, 3, как я написал.
[17:36.400 --> 17:42.400]  Это в предположении того, что здесь в скобках.
[17:42.400 --> 17:46.400]  Если у конъюнца-дезюнца может быть любая входящая степень.
[17:46.400 --> 18:01.400]  Значит, если любая, то глубина будет 3, а размер 2 в степени n.
[18:01.400 --> 18:20.400]  Значит, это при произвольном числе аргументов конъюнца и дезюнца.
[18:20.400 --> 18:32.400]  Ну или если если ровно два аргумента, то будет глубина n, видимо, и размер 2 в степени n.
[18:32.400 --> 18:51.400]  Значит, или глубины n и размера 2 в степени n, если конъюнца и дезюнца с двумя аргументами.
[18:51.400 --> 18:59.400]  Из чего это следует? Ну просто из KNF или DNF.
[18:59.400 --> 19:06.400]  Значит, смотрите, если у нас n фиксировано, то получается просто какая-то объяснительность для 2 степени n.
[19:06.400 --> 19:14.400]  Соответственно, получается бульевая функция. Любую бульевую функцию можно представить в виде KNF.
[19:14.400 --> 19:23.400]  Ну а дальше, если KNF просто переделать в дерево, то там как раз будет глубина 3.
[19:23.400 --> 19:28.400]  Сначала отрицание, потом дезюнкция, потом конъюнция.
[19:28.400 --> 19:35.400]  Ну а размер, в принципе, пополам можно поделить, если или KNF, или DNF рассматривать.
[19:35.400 --> 19:38.400]  Но неважно. В общем, такое максимальное число скобок.
[19:38.400 --> 19:46.400]  Ну и для каждой скобки будет, соответственно, одна связка.
[19:46.400 --> 19:52.400]  И еще одна, чтобы взять конъюнцию всех скобок вместе.
[19:52.400 --> 19:58.400]  Вот. Соответственно, если...
[19:58.400 --> 20:06.400]  А, тут, кстати, давайте я о большой напишу, потому что тут вообще n плюс лог n будет.
[20:06.400 --> 20:12.400]  Значит, если у нас двоичные связки, то нам нужно много взять на конъюнцию большого числа,
[20:12.400 --> 20:16.400]  то нужно превратить двоичное дерево.
[20:16.400 --> 20:19.400]  Ну конъюнцию у нас как раз максимум вот такого числа.
[20:19.400 --> 20:25.400]  И еще логарифм n нужен будет для дезюнкции на внутреннем уровне.
[20:25.400 --> 20:31.400]  Потому что дезюнкты для n, соответственно, там нужен логарифм n.
[20:31.400 --> 20:39.400]  Ну и, соответственно, размер тоже получается побольше.
[20:39.400 --> 20:47.400]  Ну потому что у нас каждая...
[20:47.400 --> 20:53.400]  Ну тут тоже сейчас будет какая-то константа. Давайте я о большой напишу.
[20:53.400 --> 20:58.400]  Какая-то константа, потому что у нас каждая скобка длины n.
[20:58.400 --> 21:08.400]  Но там, соответственно, n будет... там n минус 1 будет знак дезюнкции.
[21:08.400 --> 21:13.400]  Ну и с каждому знаку будет соответствовать элемент...
[21:13.400 --> 21:16.400]  А, нет, тут даже не нужно большое. Да, не нужно.
[21:16.400 --> 21:26.400]  Просто каждому знаку будет соответствовать вершина вот в этом графе.
[21:26.400 --> 21:32.400]  А знаков будет как раз столько. Ну, может быть, меньше, конечно.
[21:32.400 --> 21:35.400]  Вместо большого можно меньше леброном написать.
[21:35.400 --> 21:43.400]  Чего? Где логарифмы?
[21:55.400 --> 22:03.400]  Правильно, когда у нас дезюнкты, там будет n элементов, и поэтому будет логарифм n.
[22:03.400 --> 22:08.400]  Но когда берём конъюнкцию, там будет 2 в степени n элементов, и будет логарифм на 2 в степени n.
[22:08.400 --> 22:13.400]  Если вы про глубину, то тут будет вот этого большое, это n плюс лог n.
[22:13.400 --> 22:15.400]  Потому что они не умножаются, они складываются.
[22:15.400 --> 22:21.400]  Сначала дерево для дезюнкции, потом большое дерево для конъюнкции.
[22:26.400 --> 22:31.400]  Да, да, да, логарифм на 2 в степени n, то есть как раз m.
[22:31.400 --> 22:41.400]  Так, значит, дальше есть теоремы, значит, теоремы Шинона.
[22:47.400 --> 22:53.400]  Так, я что-то не помню, как он обычно пишется по-русски, через e или через е.
[22:53.400 --> 22:59.400]  Да, в общем, Шинона и Лупанова.
[23:02.400 --> 23:08.400]  Теорема такая, если мы нижнее рассматриваем,
[23:08.400 --> 23:17.400]  теорема Шинона говорит о том, что существует a,
[23:17.400 --> 23:38.400]  для которого нужны схемы размера ω от 2 в степени n делить на n.
[23:38.400 --> 23:44.400]  То есть хотя бы такого размера.
[23:44.400 --> 23:47.400]  Здесь было умножение на n, здесь деление на n.
[23:47.400 --> 23:56.400]  Но это я доказывать не буду, но у Шинона несложная идея.
[23:56.400 --> 24:03.400]  Идея просто в принципе дирихле, что мы считаем комбинаторно,
[24:03.400 --> 24:09.400]  считаем общий количество, оцениваем как-то общий количество схем такого размера,
[24:09.400 --> 24:13.400]  и оказывается, что оно меньше, чем число функций.
[24:13.400 --> 24:17.400]  То есть всего функций там 2 в степени 2 в степени n,
[24:17.400 --> 24:23.400]  но если не такого размера, то если аккуратно посчитать, то будет меньше.
[24:23.400 --> 24:50.400]  Теорема Лупанова обратная, что для любого a достаточно схем размера ω от 2 в степени n делить на n.
[24:51.400 --> 24:55.400]  То есть если схитриться и скомбинировать, то такого уже достаточно.
[24:55.400 --> 24:58.400]  То есть тут просто верхние и нижние оценки совпадают друг с другом.
[24:58.400 --> 25:05.400]  Ну конечно, если смотреть на константу, то константа вот здесь будет немножко больше, чем константа вот здесь.
[25:05.400 --> 25:13.400]  В ином случае вообще и противоречие было бы, но равенства константа там нет.
[25:13.400 --> 25:17.400]  Но было бы удивительно, если бы оно было с такой точностью.
[25:17.400 --> 25:21.400]  Да, вообще не часто бывает, что верхние и нижние оценки совпадают.
[25:28.400 --> 25:31.400]  Хорошо, но Теорема Лупанова я тем более не буду доказывать.
[25:31.400 --> 25:34.400]  Там какое-то такое мутурное рассуждение на 15 страниц.
[25:34.400 --> 25:40.400]  Как-то каким образом искать какие-то общие паттерны в разных штуках, как-то их объединять.
[25:40.400 --> 25:44.400]  И что всегда обязательно их найдется достаточно много, чтобы получилось вот так вот.
[25:50.400 --> 25:52.400]  Так, хорошо.
[25:54.400 --> 26:02.400]  Значит у нас будут вот еще два подхода.
[26:03.400 --> 26:05.400]  Значит еще два подхода.
[26:10.400 --> 26:18.400]  Это прямолинейные программы и машинтюрнинг с подсказками.
[26:18.400 --> 26:22.400]  Так, давайте я попробую так кратенько рассказать.
[26:22.400 --> 26:28.400]  Прямолинейные программы это просто цепочки присваиваний.
[26:40.400 --> 26:45.400]  Прямолинейные программы это последовательности присваиваний.
[26:52.400 --> 26:54.400]  То есть какая-то новая переменная.
[26:58.400 --> 27:01.400]  Значит, xкт.
[27:01.400 --> 27:04.400]  Да, это какая-то функция f.
[27:04.400 --> 27:12.400]  Вот каких-то там x и первая, и так далее, x и nt.
[27:16.400 --> 27:19.400]  То есть просто такая программа, что есть какие-то исходные переменные.
[27:19.400 --> 27:25.400]  И в каждой строчка берется новая переменная, она равняется какой-то функции от старых.
[27:25.400 --> 27:30.400]  Ну есть, конечно.
[27:30.400 --> 27:41.400]  То есть те функции, которые здесь были, как метки, те же будут и здесь.
[27:41.400 --> 27:48.400]  Ну, в принципе, как и там, так и тут, можно какой-нибудь другой базис рассмотреть.
[27:49.400 --> 27:55.400]  То есть можно рассмотреть какой-то базис, но чтобы любой функций, да, их использовать.
[27:55.400 --> 28:14.400]  Значит, f, соответственно, в стандартном случае одна из отрицаний конъюнкции и дизюнкции.
[28:14.400 --> 28:22.400]  Но с той же оговоркой про конъюнкцию и дизюнкцию, что может быть либо два аргумента, либо произвольное количество.
[28:22.400 --> 28:29.400]  Соответственно, для отрицания m равно 1, значит, для конъюнкции либо 2, либо произвольное,
[28:29.400 --> 28:32.400]  и для дизюнкции тоже либо 2, либо произвольное.
[28:33.400 --> 28:38.400]  Вот.
[28:38.400 --> 28:46.400]  Хорошо. Ну, значит, утверждается, что применение на программы это, на самом деле, просто другой способ представления схемы.
[28:46.400 --> 28:50.400]  Значит, каким образом?
[28:50.400 --> 28:55.400]  Ну, по схеме я там фактически написал, что нужно ее топологически отсортировать,
[28:55.400 --> 28:59.400]  так чтобы сначала были все источники, а в самом конце сток.
[28:59.400 --> 29:04.400]  Дороги не важно, и просто мы как бы для новой вершины завозим переменную
[29:04.400 --> 29:10.400]  и прям пишем, что эта переменная равняется той функции, метка которой в вершине,
[29:10.400 --> 29:17.400]  от, соответственно, тех вершин, из которых идут ребра в нашу.
[29:17.400 --> 29:23.400]  Ну, наверное, понятно. В обратном сторону примерно так же.
[29:23.400 --> 29:32.400]  Если есть применение на программы, то нужно вместо каждой новой строчки заводить вершину
[29:32.400 --> 29:41.400]  и, соответственно, на ней ставить ту же метку, которая здесь функции, и вести ребра из вот этих вот вершин.
[29:41.400 --> 29:49.400]  Вообще, когда рисуют, то обычно и стрелки не пишут на ребрах, а просто считают, что сверху вниз вычисляется,
[29:49.400 --> 29:53.400]  что все ребра идут сверху вниз.
[29:53.400 --> 29:59.400]  Так, ну хорошо. Ладно, можно дальше не писать.
[29:59.400 --> 30:12.400]  Ну и третий подход, машинтюринг с подсказками.
[30:19.400 --> 30:28.400]  Ну, это просто тут м от х и какого-то аэнного.
[30:28.400 --> 30:36.400]  Два аргумента, но в отличие от NP, где сертификат свой для каждого х,
[30:36.400 --> 30:44.400]  а еще его можно отвергнуть или не отвергнуть, значит, здесь аэнное одно и то же для всех слов длины m.
[30:49.400 --> 31:04.400]  Значит, аэнное одно и то же для слов длины n.
[31:04.400 --> 31:08.400]  Ну и, соответственно, нужно следующее.
[31:08.400 --> 31:19.400]  Значит, нужно, чтобы х лежал в а, как мы говорим, что нож в а распознается.
[31:19.400 --> 31:24.400]  Значит, х лежит в а тогда и только тогда.
[31:24.400 --> 31:34.400]  Сначала существует последняя стоянная, тоже по n от 1 или от 0, если хотите до бесконечности.
[31:34.400 --> 31:40.400]  То есть х лежит в а тогда и только тогда, когда м, то есть надо написать так,
[31:40.400 --> 31:55.400]  значит, существует м, стоянная, что м от х и а с индексом длины х равно единице.
[31:55.400 --> 32:03.400]  То есть подсказка должна быть одна и та же для всех слов длины.
[32:03.400 --> 32:14.400]  Так, но вот это, что это то же самое, это немножко хитрее.
[32:14.400 --> 32:17.400]  Но в одну сторону это несложно.
[32:17.400 --> 32:29.400]  Если уж у нас есть схемы, то вот эту машину m можно понимать как просто вычислитель схем.
[32:29.400 --> 32:40.400]  То есть m вычисляет значение схемы на входе х.
[32:40.400 --> 33:02.400]  А в другую сторону нужно, наоборот, машину тюринга преобразовать в схему.
[33:02.400 --> 33:10.400]  Так, ну, значит, соответственно, схемы в машине тюринга.
[33:10.400 --> 33:16.400]  Значит, тут просто получается, что аn равняется той же самой схеме cn.
[33:16.400 --> 33:19.400]  Да, кстати, схема это circuit.
[33:19.400 --> 33:23.400]  Если вы будете переводить на английский, то scheme это неправильный перевод.
[33:23.400 --> 33:25.400]  Правильный перевод circuit.
[33:25.400 --> 33:27.400]  Это типа как электросхема.
[33:27.400 --> 33:30.400]  Электросхема тоже circuit.
[33:30.400 --> 33:32.400]  Поэтому cn не s.
[33:32.400 --> 33:43.400]  Значит, подсказка это cn, ну а, соответственно, машина вот x и cn это просто cn от x.
[33:43.400 --> 33:47.400]  Ну и нужно рассмотреть одну единую машину для всех языков,
[33:47.400 --> 33:53.400]  которая занимается тем, что просто вычисляет значение схемы.
[33:53.400 --> 33:59.400]  Ну и понятно, что такую машину можно написать.
[33:59.400 --> 34:04.400]  Ну а топологическую шестировку вы, наверное, умеете делать у графа.
[34:04.400 --> 34:09.400]  Да, и дальше просто идти и вычислять тоже понятно как.
[34:09.400 --> 34:12.400]  Вот, хорошо.
[34:12.400 --> 34:22.400]  Значит, соответственно, машина тюринга, схемы.
[34:22.400 --> 34:27.400]  Ну, это, на самом деле, аналогично теореме Куклевина.
[34:27.400 --> 34:33.400]  Значит, вот эта конструкция у нас уже несколько раз была.
[34:33.400 --> 34:44.400]  Аналогично теореме Куклевина.
[34:44.400 --> 34:54.400]  Вот, но как бы тут у нас исходно есть x.
[34:54.400 --> 35:01.400]  Значит, x1, x2, x3 там и так далее, xn.
[35:01.400 --> 35:08.400]  Вот, дальше еще нужно дописать начальное состояние на там q.
[35:08.400 --> 35:12.400]  Старт какой-нибудь.
[35:12.400 --> 35:22.400]  Вот, соответственно, тут еще нужно дописать там какие-то.
[35:22.400 --> 35:28.400]  Тут, в отличие от теорем Куклевина, не будет никакого второго аргумента.
[35:28.400 --> 35:31.400]  Будет только один аргумент.
[35:31.400 --> 35:35.400]  А, нет, подождите, будет же второй аргумент, что я напишу.
[35:35.400 --> 35:38.400]  Будет.
[35:38.400 --> 35:43.400]  Так, а n это как бы номер.
[35:43.400 --> 35:46.400]  Будет второй аргумент.
[35:46.400 --> 35:54.400]  Давайте я сверху что линдекс напишу, а первое, а второе, и так далее.
[35:54.400 --> 36:04.400]  И потом еще какие-то пустые клетки.
[36:04.400 --> 36:09.400]  А нам известно заранее.
[36:09.400 --> 36:14.400]  Смотрите, у нас есть машина, есть x.
[36:14.400 --> 36:18.400]  Нет, x нет, x это аргумент.
[36:18.400 --> 36:23.400]  Вот это будут входные символы.
[36:23.400 --> 36:32.400]  Остальное это либо константы, либо это константы, если разрешаем константы.
[36:32.400 --> 36:35.400]  Если мы не разрешаем константы, то их нужно вычислить.
[36:35.400 --> 36:40.400]  По закону исключенного третьего 1 и 0 получить.
[36:40.400 --> 36:46.400]  Ну и дальше соответственно мы...
[36:46.400 --> 36:58.400]  Помните, что у нас из четырех таких штук это вычисляется так же.
[36:58.400 --> 37:05.400]  И потом каждый из них...
[37:05.400 --> 37:13.400]  То, что у нас было, что в каждой клетке значение определяется четырьмя более высокими.
[37:13.400 --> 37:16.400]  Такую штуку нужно сверху вниз написать.
[37:16.400 --> 37:20.400]  И дальше еще в конце небольшой модуль, что нужно сравнить,
[37:20.400 --> 37:24.400]  сравнить то, что получилось с принимающим состоянием.
[37:24.400 --> 37:29.400]  А если где-то в конце получилось принимать состояние, то вывести единицу.
[37:29.400 --> 37:35.400]  А глубина у нас получается такая, какая максимальная время вычисления?
[37:35.400 --> 37:43.400]  Да, глубина получается как время вычисления.
[37:43.400 --> 37:48.400]  Ладно, дайте перерыв. Делаем небольшой...
[37:56.400 --> 38:02.400]  Таким образом схемы приделываются в машину и обратно.
[38:02.400 --> 38:06.400]  Какие же классы отсюда получаются?
[38:06.400 --> 38:17.400]  Можно формулировать классы в терминах размера семейства схем или глубины.
[38:17.400 --> 38:23.400]  Можно формулировать в терминах машин тюринга.
[38:23.400 --> 38:30.400]  Например, есть вот такое стандартное обозначение.
[38:30.400 --> 38:53.400]  Это означает, что существует машина тюринга, распознающая язык,
[38:53.400 --> 38:57.400]  который как раз в этом классе, конечно.
[38:57.400 --> 39:21.400]  С подсказкой длины U' от A от N за время U' от T от N.
[39:21.400 --> 39:27.400]  Ну и самый главный язык обозначается вот так.
[39:27.400 --> 39:35.400]  Вот P слэш поля. Чтут соответственно и T от N, и A от N должны быть пильномянами.
[39:35.400 --> 39:39.400]  То есть это объединение под C и D.
[39:39.400 --> 39:47.400]  Чтутся STD time от N степени C слэш N степени D.
[39:47.400 --> 39:58.400]  И это будет то же самое, что языки, распознаваемые семейством схем, полимерного размера.
[39:58.400 --> 40:06.400]  Эти рассуждения позволяют доказать, что это одно и то же.
[40:07.400 --> 40:13.400]  Так, хорошо.
[40:13.400 --> 40:20.400]  Кроме того, эта переделка машин тюрингов схемы показывает следующее.
[40:20.400 --> 40:28.400]  Значит, что P у нас вложено в P слэш поле.
[40:28.400 --> 40:34.400]  Потому что практически P то же самое, только без подсказки.
[40:35.400 --> 40:41.400]  Более того, она строго вложена.
[40:41.400 --> 40:49.400]  Более того, P не равно P слэш поля.
[40:49.400 --> 40:52.400]  Почему?
[40:52.400 --> 41:03.400]  Потому что в P как раз зависимость подсказки от N должна быть вычислимой.
[41:03.400 --> 41:07.400]  А в P слэш поле может быть какой угодно и даже не вычислимой.
[41:07.400 --> 41:12.400]  Простейший пример следующий.
[41:12.400 --> 41:21.400]  Можно использовать какую-нибудь неразрешимую задачу.
[41:21.400 --> 41:25.400]  Например, проблему остановки.
[41:25.400 --> 41:35.400]  U halt это будет множество из N единиц подряд.
[41:35.400 --> 41:43.400]  Давайте так напишем.
[41:43.400 --> 41:54.400]  M кодирует пару mx такую, что m от x останавливается.
[41:54.400 --> 42:12.400]  Смотрите, получается, что если эта пара mx лежит в halt,
[42:12.400 --> 42:22.400]  то тогда один в степени N, то есть один повторенный N раз, лежит в U halt.
[42:23.400 --> 42:27.400]  Ну а если там 0, то это точно не лежит.
[42:27.400 --> 42:37.400]  Соответственно, функция будет конъюнкцией.
[42:37.400 --> 42:46.400]  U halt ограничена на N, распознается конъюнкцией.
[42:46.400 --> 42:51.400]  А конъюнкция всех ходов, как раз если все единицы, то будет единица.
[42:51.400 --> 42:55.400]  Если хотя бы один ноль, то будет ноль.
[42:55.400 --> 43:06.400]  Соответственно, если m от x не лежит в halt,
[43:06.400 --> 43:16.400]  и эта штука не лежит в U halt, а с нулями тоже не лежат,
[43:16.400 --> 43:26.400]  ну и тогда U halt, ограничена на N, распознается тождественным нулем.
[43:26.400 --> 43:33.400]  Таким образом получается, что и в том, и в другом случае, схема будет маленькая.
[43:33.400 --> 43:39.400]  Да, и у конъюнкции всех ходов маленький размер, у тождества 0 тем более маленький размер.
[43:39.400 --> 43:44.400]  Но мы только не знаем, какая именно маленькая схема нам нужна.
[43:44.400 --> 43:52.400]  Ну как-нибудь закодируем.
[43:52.400 --> 43:56.400]  Но слушайте, мы это изучали много раз.
[43:56.400 --> 43:59.400]  Как-нибудь так, чтобы было однозначно.
[43:59.400 --> 44:03.400]  Да, то есть так, чтобы по N можно было понять, является ли оно кодом хоть чего-нибудь,
[44:03.400 --> 44:17.400]  а если является, то какая там машина и какой там x.
[44:17.400 --> 44:21.400]  На самом деле, тут вообще совершенно не важно, какой язык.
[44:21.400 --> 44:26.400]  Если он унарный, то он точно лежит в P slash поле.
[44:26.400 --> 44:32.400]  То есть можно даже не брать конкретно проблему остановки и не брать никакую другую конкретную неразрешимую задачу,
[44:32.400 --> 44:40.400]  а просто из соображений мощности сказать, что у нас P вложено в разрешимое,
[44:40.400 --> 44:51.400]  поэтому P это счетное множество, а P slash поле будет не счетное,
[44:51.400 --> 44:55.400]  потому что уже унарных языков будет не счетное число.
[44:55.400 --> 45:02.400]  Для каждого N слово из N единиц может лежать или не лежать.
[45:02.400 --> 45:06.400]  В этом смысле для этого примера даже не важно, как вы кодируете.
[45:06.400 --> 45:18.400]  Важно только, чтобы только для одной пары N было кодом, иначе будет просто непонятно, как определить.
[45:18.400 --> 45:32.400]  Что дальше?
[45:32.400 --> 45:59.400]  Это очень важно утверждение, что заведомо P slash поле шире, чем P, и более того, содержит даже неразрешимые языки.
[45:59.400 --> 46:19.400]  Дальше давайте, наверное, изучим вот такую вот теорему Карпа Липтона.
[46:19.400 --> 46:24.400]  Значит, возникает вопрос. Ну хорошо, а где здесь NP?
[46:24.400 --> 46:34.400]  Может и так быть, что NP вложено в P slash поле? Ну а вообще, в принципе, может быть.
[46:34.400 --> 46:40.400]  Ну и соответственно, зато если оно не вложено, то точно P не равно NP.
[46:40.400 --> 46:46.400]  То есть вот в 80-х думали, что можно попытаться доказать, что P не равно NP,
[46:46.400 --> 47:00.400]  взяв какую-нибудь NP-полную задачу, типа задача выполнимости, и доказав, что эта задача не решается семейством маленького размера.
[47:00.400 --> 47:11.400]  Если мы это докажем, то получится, что все P вложено в P slash поле, а в NP мы нашли какую-то точку, которая не в P slash поле.
[47:11.400 --> 47:23.400]  Вот так. Понятно, да? Но вот Карп и Липтон показали, что на это не стоит уж прям так надеяться.
[47:23.400 --> 47:36.400]  Значит, они показали следующее, что если NP вложено в P slash поле, то тогда sigma2 polynomial равняется P2 polynomial.
[47:36.400 --> 47:40.400]  То есть, что тогда polynomial hierarchy слопывается.
[47:44.400 --> 47:47.400]  Так, ну давайте докажем прямо.
[47:56.400 --> 47:59.400]  Так, доказательства.
[47:59.400 --> 48:07.400]  Значит, мы рассмотрим задачу P2-сад.
[48:07.400 --> 48:19.400]  То есть мы докажем, что P2-сад лежит в sigma2 polynomial.
[48:19.400 --> 48:26.400]  Ну, получается, что P2 полное значение лежит в sigma2, значит они равны.
[48:26.400 --> 48:32.400]  Так, напомним, что такое P2-сад.
[48:32.400 --> 48:47.400]  P2-сад, потому что таки формул phi, что для любого х существует y такой, что phi от x и y.
[48:47.400 --> 48:51.400]  Значит, х это группа переменных, y это группа переменных.
[48:51.400 --> 49:03.400]  Соответственно, для любой фиксации значений первой группы можно выбрать значение второй группы, чтобы это равнялось единице, чтобы форма была верна.
[49:03.400 --> 49:10.400]  Так, ну теперь смотрите, теперь мы х как бы перенесем в левую часть.
[49:10.400 --> 49:19.400]  Теперь множество пар phi и x таких, что существует y, phi от x и y.
[49:19.400 --> 49:27.400]  Значит, вот это вот множество, значит оно уже лежит просто в SAT.
[49:27.400 --> 49:31.400]  Если оно не лежит в SAT, извините, оно лежит в NP.
[49:31.400 --> 49:36.400]  Ну, это скорее под множество SAT в некотором смысле.
[49:36.400 --> 49:42.400]  В общем, оно лежит в NP.
[49:42.400 --> 49:54.400]  Так, что из этого следует? Из этого следует, что оно лежит в P-слэш-поле.
[49:54.400 --> 50:02.400]  Значит, есть схема, которая проверяет, существует такое y или нет.
[50:02.400 --> 50:09.400]  Так, дальше я, наверное, шаг в доказательстве оставлю в качестве упражнения.
[50:09.400 --> 50:17.400]  Дальше нужно показать, что не только можно проверять, существует y или нет, то можно и искать.
[50:17.400 --> 50:25.400]  Вот у нас было несколько примеров на как сводить поиск к распознаванию.
[50:25.400 --> 50:28.400]  Ну а вот здесь он тоже применим.
[50:28.400 --> 50:38.400]  Ну, если вкратце, идея такая, что мы как бы отдельный бит y переносим отсюда сюда.
[50:38.400 --> 50:46.400]  И говорим, что вот у нас есть phi, у нас есть x, и еще мы фиксируем y1 равное 0, например.
[50:46.400 --> 50:53.400]  И тогда вопрос, можно ли все остальные y зафиксировать так, чтобы форма была верна.
[50:53.400 --> 50:58.400]  Это задача такого же типа, соответственно, для нее есть схема.
[50:58.400 --> 51:03.400]  Соответственно, если да, то мы рекурсивно найдем оставшиеся y.
[51:03.400 --> 51:11.400]  Если нет, то мы скажем, что тогда y1 равно 1, и мы тоже найдем оставшиеся y.
[51:11.400 --> 51:16.400]  Так, ну, примерно понятно, да? Или как?
[51:16.400 --> 51:22.400]  Ну, это так для выполнимости делалось, а здесь почти то же самое.
[51:22.400 --> 51:28.400]  Да, то есть еще раз, пусть мы умеем проверять выполнимость, когда искать выполняющий набор.
[51:28.400 --> 51:35.400]  Нужно фиксировать очередную переменную 0 или единицей и смотреть, что можно еще дополнить до выполняющего набора.
[51:35.400 --> 51:40.400]  То, что можно фиксировать, если нельзя, то фиксировать противоположное.
[51:40.400 --> 51:44.400]  Ну, и так постепенно ходить, так здесь тоже найдется.
[51:44.400 --> 51:50.400]  Отсюда следует, что существует схема, ну, точнее, семейство схем.
[51:54.400 --> 52:02.400]  Значит, cn, которые прям таки ищут y.
[52:02.400 --> 52:08.400]  Смотрите, в принципе, можно обобщить схемы с бинарного ответа на любой другой,
[52:08.400 --> 52:13.400]  просто увеличив число выходных вершин.
[52:13.400 --> 52:17.400]  У нас будет не одна выходная вершина, а десять, тогда у нас ответ будет не один бит, а десять битов.
[52:17.400 --> 52:22.400]  И в том числе битов может быть выходной столько, сколько у нас битов в y.
[52:22.400 --> 52:26.400]  Значит, существует схема cn.
[52:26.400 --> 52:38.400]  Значит, такое, что cn от φх равняется y.
[52:38.400 --> 52:44.400]  Соответственно, что φ от xy равняется единице.
[52:44.400 --> 52:53.400]  Причем, заметьте, что вообще это семейство, оно либо будет выдавать такое y,
[52:53.400 --> 52:56.400]  либо будет выдавать, что такого y нет.
[52:56.400 --> 53:00.400]  Но в данном случае у нас есть условие, что для любого существует y.
[53:00.400 --> 53:06.400]  То есть оно всегда будет именно y выдавать, потому что оно всегда существует.
[53:06.400 --> 53:14.400]  Значит, тут получается всегда y, а не ошибку.
[53:14.400 --> 53:18.400]  Значит, так как для любого x существует y.
[53:27.400 --> 53:32.400]  Это правда, но я утверждаю, что это будет равносильно тому, что φ лежит в нашем языке.
[53:32.400 --> 53:43.400]  Значит, смотрите, я утверждаю следующее, что теперь φ лежит в π20 тогда и только тогда,
[53:43.400 --> 53:48.400]  когда существует c.
[53:48.400 --> 53:57.400]  Ну ладно, я напишу cn, но на самом деле n это будет просто суммарной длины записи φх.
[54:02.400 --> 54:06.400]  Ну я про это упоминал.
[54:06.400 --> 54:15.400]  Нет, не семейство-семейство, а просто схема не с одной выходной вершины, а не с несколькими выходными вершинами.
[54:15.400 --> 54:21.400]  Просто в семействе-семействе там будет повторное использование одного и того же.
[54:21.400 --> 54:27.400]  А здесь будет просто одна схема, но у нее не один выход, а много выходов.
[54:27.400 --> 54:40.400]  Значит, существует cn такое, что для любого x φ от x и cn от x равно 1.
[54:40.400 --> 54:44.400]  Или можно просто ничего не писать, да, истинно.
[54:44.400 --> 54:50.400]  Слева направо я уже доказал, а справа налево...
[54:50.400 --> 54:59.400]  Ну смотрите, если уж такой ценный существует, если существуют такие схемы, которые выдают решение для любого x,
[54:59.400 --> 55:02.400]  то значит решение всегда существует.
[55:02.400 --> 55:06.400]  И поэтому φ лежит в π20.
[55:06.400 --> 55:18.400]  Ну а вот это как раз получилась σ2 формула.
[55:18.400 --> 55:26.400]  И главное, что схемы полиномиального размера, поэтому квантор полиномиален по cn,
[55:26.400 --> 55:36.400]  и вычисления ценные тоже полиномиален, потому что ценные полиномиального размера.
[55:36.400 --> 55:42.400]  Ну вот, значит, все получилось.
[55:42.400 --> 55:52.400]  Да, π2 вложено в σ2, но дальше, если перейти к дополнению, то получается, что σ2 вложено в π2, иначе они не совпадают.
[55:52.400 --> 56:04.400]  А вот здесь у нас cn, нам не надо все cn перебирать в этом существовании, нам нужно только...
[56:04.400 --> 56:14.400]  Ну да, все n не надо перебирать, нужно то n, которое равно там длине fi плюс длина x.
[56:22.400 --> 56:26.400]  А вот здесь у нас cn перебирает.
[56:26.400 --> 56:30.400]  А вот здесь у нас cn перебирает.
[56:30.400 --> 56:33.400]  А вот здесь у нас cn перебирает.
[56:33.400 --> 56:36.400]  А вот здесь у нас cn перебирает.
[56:36.400 --> 56:39.400]  А вот здесь у нас cn перебирает.
[56:39.400 --> 56:42.400]  А вот здесь у нас cn перебирает.
[56:42.400 --> 56:44.400]  Так.
[57:06.400 --> 57:08.400]  Так.
[57:12.400 --> 57:23.400]  Ну, там еще теремма Меера, я, наверное, не буду ее доказывать, но сформулирую.
[57:23.400 --> 57:35.400]  Значит, тут у нее будет более сильное условие и более сильное заключение.
[57:35.400 --> 57:38.400]  Я доказывать не буду, но я немножко обслужу ее значение.
[57:39.400 --> 57:56.400]  Значит, смотрите, теремма такая, что если exp вложено в p-slash-поле, то тогда exp равняется σ2.
[57:56.400 --> 58:07.400]  Значит, у нее более сильное условие, что не только nph, а же на все exp попало в p-slash-поле.
[58:07.400 --> 58:12.400]  Значит, удивительно, что мы не умеем это провергать.
[58:12.400 --> 58:25.400]  То есть не умеем доказывать, что экспоненциальные равномерные вычисления не моделируют с пальными альмами неравномерными.
[58:26.400 --> 58:30.400]  Вот это никто не умеет делать.
[58:30.400 --> 58:33.400]  Но, конечно, и утверждение тоже более сильное.
[58:33.400 --> 58:43.400]  Не только если σ равна p2, то пальмяльная аерархия слопается, а это еще больше, аж экспоненция совпадает с σ2.
[58:43.400 --> 58:46.400]  И это тоже не умеет это провергать.
[58:46.400 --> 58:51.400]  Но что тут можно заметить?
[58:51.400 --> 58:57.400]  Что из этого будет следовать, что p не равно np.
[59:01.400 --> 59:03.400]  Почему?
[59:03.400 --> 59:09.400]  Потому что, смотрите, если p равно np, то p равно ph, и σ2 в частности.
[59:09.400 --> 59:12.400]  А если еще exp равно σ2, то p равно exp.
[59:12.400 --> 59:17.400]  Но про p и exp у нас есть теория об аерархии, которая говорит, что p не равно exp.
[59:17.400 --> 59:20.400]  Вы ее на семерах обсуждали?
[59:20.400 --> 59:22.400]  Нет?
[59:22.400 --> 59:27.400]  Ну ладно, тогда без доказательств идет.
[59:27.400 --> 59:35.400]  Теория об аерархии, что если больше времени, то значит шире класс.
[59:35.400 --> 59:38.400]  То есть p не равно exp.
[59:38.400 --> 59:43.400]  Поэтому будет противоречие, если п равно np.
[59:43.400 --> 59:52.400]  И это пример того, что Скотт Арнсон называет иеронической теорией сложности.
[59:52.400 --> 59:58.400]  Как из верхней оценки происходит нижняя оценка.
[59:58.400 --> 01:00:03.400]  То, что exp вложено в p-slash-поле, это верхняя оценка.
[01:00:03.400 --> 01:00:14.400]  То есть на все языки exp оценка пальномиальная на размер схемы, которые эти языки распознают.
[01:00:14.400 --> 01:00:16.400]  Это верхняя оценка.
[01:00:16.400 --> 01:00:19.400]  А то, что панировано np, это нижняя оценка.
[01:00:19.400 --> 01:00:22.400]  То есть для задачи выполнимости нет пальномиального алгоритма.
[01:00:22.400 --> 01:00:26.400]  То есть любой детерминированный алгоритм для выполнимости сверхпальномиален.
[01:00:26.400 --> 01:00:28.400]  Это нижняя оценка.
[01:00:28.400 --> 01:00:32.400]  И вообще нижняя оценка – это самое сложное, что есть в этой теории.
[01:00:32.400 --> 01:00:35.400]  Ну и тут что получается?
[01:00:35.400 --> 01:00:41.400]  Получается, что мы из верхней оценки получили нижнюю.
[01:00:41.400 --> 01:00:47.400]  Но не стоит надеяться так доказать, что p не равно np, потому что вряд ли это верно.
[01:00:47.400 --> 01:00:50.400]  Можете еще раз рассказать о рассуждении?
[01:00:50.400 --> 01:00:52.400]  Еще раз о рассуждении.
[01:00:52.400 --> 01:00:55.400]  Если вдруг p равно np, то тогда p равно ph.
[01:00:55.400 --> 01:00:59.400]  Мы это обсуждали в пальномиальной арахе.
[01:00:59.400 --> 01:01:01.400]  В частности, p равно σ2.
[01:01:01.400 --> 01:01:05.400]  Тогда p равно exp, но это противоречит теоремы «я просто аерархия».
[01:01:07.400 --> 01:01:10.400]  Ну об аерархии по времени это называется.
[01:01:15.400 --> 01:01:21.400]  Ну ладно, и в последние 15 минут я бы хотел немножко сказать про еще одну аерархию,
[01:01:21.400 --> 01:01:24.400]  которая связана с глубиной.
[01:01:24.400 --> 01:01:29.400]  Значит, это называется nc или nc.
[01:01:29.400 --> 01:01:39.400]  И аерархия – это удивительным образом в честь конкретного человека.
[01:01:39.400 --> 01:01:45.400]  Названо, значит, nc – это nix-класс.
[01:01:48.400 --> 01:01:51.400]  Значит, в честь ник – это Николас Пипинджер.
[01:01:54.400 --> 01:01:59.400]  Там история такая.
[01:01:59.400 --> 01:02:05.400]  Пипинджер приехал на стажировку к Стивену Куку, который как раз из Теремку-Клевина.
[01:02:05.400 --> 01:02:11.400]  И Стив ему поручил это изучить и назвал Никс-класс.
[01:02:11.400 --> 01:02:19.400]  А потом через некоторое время Пипинджер в ответ некоторый класс назвал Стивс-класс,
[01:02:19.400 --> 01:02:21.400]  в честь Стивена Кука.
[01:02:25.400 --> 01:02:32.400]  Стивс-класс – это, по-моему, одновременно по линомиальным времени поле логарифмической памяти.
[01:02:32.400 --> 01:02:42.400]  То есть это шире, шире, чем l, но зато уже и чем p, и чем поле l.
[01:02:42.400 --> 01:02:47.400]  Так, хорошо. Значит, что такое nc?
[01:02:47.400 --> 01:02:52.400]  Здесь, на самом деле, две аерархии, которые друг с другом переплетены.
[01:02:52.400 --> 01:02:57.400]  Значит, есть понятие nc dt.
[01:02:57.400 --> 01:03:04.400]  Значит, это означает поле линомиальный размер.
[01:03:04.400 --> 01:03:12.400]  Поле линомиальный размер и, значит, глубина
[01:03:12.400 --> 01:03:19.400]  большого логарифма в степени d от n.
[01:03:19.400 --> 01:03:23.400]  Смотрите, как мы изучили уже в начале.
[01:03:23.400 --> 01:03:29.400]  Если у нас размер какой угодно, то глубина может быть константой.
[01:03:35.400 --> 01:03:40.400]  Хотя только сейчас. Тут еще важно, значит, глубина большая.
[01:03:40.400 --> 01:03:49.400]  Но при этом у каждой вершины с метками конъюнция и дезъюнция
[01:03:49.400 --> 01:04:00.400]  вершины с конъюнцией и дезъюнцией имеют входящую степень равную двум.
[01:04:00.400 --> 01:04:12.400]  А еще есть ac dt. Тут уже a, правда, не в честь кого-нибудь.
[01:04:12.400 --> 01:04:18.400]  Хотя были гипотезы, народная этимология, что a это в честь
[01:04:18.400 --> 01:04:23.400]  Аллана Бородина, который с ними там же работал.
[01:04:23.400 --> 01:04:27.400]  Но это неправда. Буква просто значит альтернирование.
[01:04:27.400 --> 01:04:47.400]  А c dt это аналогично, но конъюнция и дезъюнция имеют произвольную входящую степень.
[01:04:47.400 --> 01:05:04.400]  Ну и уж по крайней мере для ac у нас точно есть, что если мы не ограничиваем размер, то глубина у нас константа.
[01:05:04.400 --> 01:05:11.400]  Для nc такого не будет. Поэтому важно, что размер тоже полиномиальный.
[01:05:11.400 --> 01:05:19.400]  Еще есть вариации с равномерностью. Неравномерная версия это просто как написано.
[01:05:19.400 --> 01:05:29.400]  А еще может быть, например, полиномиально равномерная версия.
[01:05:29.400 --> 01:05:49.400]  И это означает, что схема cn вычислима за время полинома t.
[01:05:49.400 --> 01:05:58.400]  А может быть даже логарифмически равномерная версия, когда на логарифмической памяти вычислила.
[01:05:58.400 --> 01:06:12.400]  Поскольку тут размер полиномиальный, то это точно все внутри p-slash поле происходит.
[01:06:12.400 --> 01:06:17.400]  Пока я стираю, давайте обсудим, почему альтернирование. Дело в следующем.
[01:06:17.400 --> 01:06:23.400]  Во-первых, отрицание можно все по закону деморгана перенести на самый верх.
[01:06:23.400 --> 01:06:35.400]  Можно сказать, что у нас с самого начала есть переменная, у каждой переменной есть отрицание, а дальше у нас только конъюнция и дезъюнция.
[01:06:35.400 --> 01:06:39.400]  Это, во-первых, отрицание все на самом верху.
[01:06:39.400 --> 01:06:52.400]  А после этого, если у нас подряд две одинаковых метки, например, в одном из... да, конъюнция, из нее метка тоже конъюнция.
[01:06:52.400 --> 01:07:00.400]  Тогда их можно просто склеить, потому что у нас неважно, сколько выходит.
[01:07:00.400 --> 01:07:12.400]  Точнее, наоборот, если у нас, я не говорю, что если у нас вот так вот, конъюнция, скажем, вот так вот, а здесь тоже конъюнция.
[01:07:12.400 --> 01:07:17.400]  Тогда это можно в одну склеить и вот эти перенести сюда.
[01:07:17.400 --> 01:07:21.400]  Поэтому все идущие подряд можно склеить, а тогда они как раз будут альтернироваться.
[01:07:21.400 --> 01:07:27.400]  Конъюнция, дезюнция, конъюнция, дезюнция. Вот поэтому АС.
[01:07:27.400 --> 01:07:32.400]  Вот, соответственно, почему это иерархия?
[01:07:32.400 --> 01:07:39.400]  Ну, ясно. Да, D может быть равно нулю.
[01:07:39.400 --> 01:07:42.400]  D может быть равно нулю, тогда будет глубина константа.
[01:07:42.400 --> 01:07:51.400]  Значит, Nc0 вложено в Ac0, это вложено в Nc1, вложено в Ac1 и так далее.
[01:07:51.400 --> 01:08:01.400]  Ну и вообще, в целом, NcDt вложено в Acdt, вложено в Ncd1.
[01:08:01.400 --> 01:08:04.400]  Вот такая будет иерархия.
[01:08:04.400 --> 01:08:08.400]  Так, значит, почему это так?
[01:08:08.400 --> 01:08:20.400]  Ну, значит, NcDt вложено в Acdt, это просто потому что 2 – это частный случай произвольного числа.
[01:08:20.400 --> 01:08:29.400]  Валентность 2 – это частный случай.
[01:08:29.400 --> 01:08:42.400]  Так, значит, Acdt вложено в Ncd1.
[01:08:42.400 --> 01:08:49.400]  Ну тоже понятно. Вот тут мы и распользуемся полиномиальностью размера.
[01:08:49.400 --> 01:08:56.400]  Что тут, конечно, произвольная входящая степень, но тем не менее полиномиальная.
[01:08:56.400 --> 01:09:02.400]  Тут, соответственно, входящая степень полиномиальная,
[01:09:02.400 --> 01:09:12.400]  и она преобразуется в двоичное дерево глубины логарифа полинома, то есть обольшое от логарифма N.
[01:09:12.400 --> 01:09:25.400]  Значит, дерево глубины обольшое от логарифма N.
[01:09:25.400 --> 01:09:30.400]  Вот.
[01:09:30.400 --> 01:09:33.400]  Так, надо найти то, что понятно.
[01:09:33.400 --> 01:09:47.400]  Возникает вопрос, насколько эти строгие, насколько эти вложения строгие.
[01:09:47.400 --> 01:09:57.400]  Ну вот то, что Nc0 не равно Ac0, это вообще почти очевидно.
[01:09:57.400 --> 01:10:08.400]  Потому что такое Nc0? Это означает, что глубина константная и при этом еще валентность 2.
[01:10:08.400 --> 01:10:18.400]  Но это означает, что если у вас глубина c, то каждый раз у вас удваивается число аргументов,
[01:10:18.400 --> 01:10:22.400]  значит, он точно не превысит 2 в степени c.
[01:10:22.400 --> 01:10:30.400]  То есть вот из Nc0 все языки, они зависят только от фиксированного числа булевых аргументов.
[01:10:30.400 --> 01:10:44.400]  Тут зависимость от фиксированного числа булевых аргументов.
[01:10:44.400 --> 01:10:51.400]  Ну а, конечно, если мы возьмем, например, конъюнцию на конъюнцию всех,
[01:10:51.400 --> 01:10:56.400]  то конъюнция все-таки от всех аргументов зависит, а не от фиксированного числа.
[01:10:56.400 --> 01:11:01.400]  И это может быть фиксировано большое, то есть у нас может быть там глубина 100, тогда это будет 2 в сотый.
[01:11:01.400 --> 01:11:06.400]  Но у нас же асимпатическая теория, поэтому есть числы больше, чем 2 в сотый.
[01:11:06.400 --> 01:11:14.400]  Соответственно, у вас конъюнция там 2 в 101, уже будет от всех 2 в 101 аргументов зависеть,
[01:11:14.400 --> 01:11:21.400]  и она в Nc0 будет, потому что там и 2 в 101 тоже может быть аргументов, а в Nc0 не будет.
[01:11:22.400 --> 01:11:29.400]  Получается, не содержит просто конъюнцию.
[01:11:29.400 --> 01:11:35.400]  Ну а ac0 содержит по определению.
[01:11:35.400 --> 01:11:42.400]  Ac0 содержит, конечно, конъюнцию.
[01:11:42.400 --> 01:11:47.400]  Дальше, что еще известно?
[01:11:47.400 --> 01:11:54.400]  Еще известно, что ac0 не равняется Nc1.
[01:11:54.400 --> 01:12:00.400]  Но вот это уже значительно более сложная теорема.
[01:12:01.400 --> 01:12:10.400]  Так, там какая-то куча авторов.
[01:12:10.400 --> 01:12:15.400]  First, Sax, еще кто-то.
[01:12:15.400 --> 01:12:20.400]  Aitai, Semeredi, что ли.
[01:12:20.400 --> 01:12:25.400]  Или кто-то еще.
[01:12:25.400 --> 01:12:30.400]  Так, неважно.
[01:12:30.400 --> 01:12:35.400]  Мы ее не будем доказывать, она действительно не простая,
[01:12:35.400 --> 01:12:45.400]  но можно даже за 3 минуты, оставшись, понять, что функция XOR с N аргументами,
[01:12:45.400 --> 01:12:52.400]  она лежит в Nc1.
[01:12:52.400 --> 01:12:57.400]  Значит, почему?
[01:12:57.400 --> 01:13:02.400]  Потому что, смотрите, что такое XOR2.
[01:13:02.400 --> 01:13:07.400]  У нас есть Y, дальше вы берете отрицание.
[01:13:07.400 --> 01:13:12.400]  Ну и дальше, например, берете вот так конъюнцию, берете вот так конъюнцию
[01:13:12.400 --> 01:13:17.400]  и берете вот так дизюнцию.
[01:13:17.400 --> 01:13:23.400]  Значит, XOR2 это глубина 3 получилась.
[01:13:23.400 --> 01:13:32.400]  Ну а XORN это как раз дерево из XOR2,
[01:13:32.400 --> 01:13:37.400]  значит, глубины как раз логарифм M.
[01:13:37.400 --> 01:13:46.400]  Значит, XOR тоже ассоциативная операция, так что ее можно вычислять двоечным деревом.
[01:13:47.400 --> 01:13:52.400]  Поэтому XORN в Nc1 лежит.
[01:13:52.400 --> 01:14:02.400]  Ну а то, что XORN не лежит в AC0,
[01:14:02.400 --> 01:14:09.400]  это не простая теорема, но идея следующая.
[01:14:10.400 --> 01:14:17.400]  Идея состоит в том, что XOR это очень чувствительная функция.
[01:14:17.400 --> 01:14:28.400]  Значит, XORN очень чувствительная функция.
[01:14:28.400 --> 01:14:34.400]  Просто изменить любого аргумента меняет значение функции.
[01:14:34.400 --> 01:14:36.400]  Да, ну XOR так устроен.
[01:14:36.400 --> 01:14:46.400]  Изменение любого аргумента меняет значение функции.
[01:14:52.400 --> 01:14:56.400]  А в AC0 таких чувствительных быть не может.
[01:14:56.400 --> 01:14:58.400]  Это вот как раз надо показывать.
[01:15:03.400 --> 01:15:09.400]  В AC0 таких чувствительных нет.
[01:15:09.400 --> 01:15:16.400]  Но тут как бы идея такая, что как раз конъюнкция и дизъюнкция, они, наоборот, очень нечувствительные.
[01:15:16.400 --> 01:15:20.400]  То есть это только где-то на краю меняется значение.
[01:15:20.400 --> 01:15:29.400]  Так типично, если вы случайно аргументы взяли, то у конъюнкции будет результат 0, а у дизъюнкции 1.
[01:15:29.400 --> 01:15:34.400]  И даже если вы один поменяете, то все равно будет у конъюнкции результат 0 и у дизъюнкции 1.
[01:15:34.400 --> 01:15:38.400]  Только на самом краю, когда у вас все, кроме одного, одинаковые,
[01:15:38.400 --> 01:15:41.400]  вот тогда замена этого одного поменяет значение.
[01:15:41.400 --> 01:15:45.400]  Соответственно, у конъюнкции и дизъюнкции чувствительность очень низкая.
[01:15:45.400 --> 01:15:50.400]  Ну и дальше нужно доказать, что константной глубины не хватит, чтобы это чувствительно сильно нарастить
[01:15:50.400 --> 01:15:53.400]  до такой, которая нужна для ксора.
[01:15:53.400 --> 01:15:58.400]  Вот такая общая идея, но дальше всякие сложные алгебры и так далее.
[01:16:04.400 --> 01:16:07.400]  На самом деле дальше ничего не известно.
[01:16:07.400 --> 01:16:13.400]  Начиная с НЦ1, неизвестно тут, строго или нестрого,
[01:16:13.400 --> 01:16:21.400]  и даже неизвестно, лежит ли вообще все УНП в НЦ1.
[01:16:21.400 --> 01:16:24.400]  Это не умеет опровергать.
[01:16:27.400 --> 01:16:33.400]  Тут даже между АЦ0 и НЦ1 есть еще некоторые промежуточные классы.
[01:16:33.400 --> 01:16:40.400]  Была очень большая, очень успешная теорема,
[01:16:40.400 --> 01:16:48.400]  что НЭКСП не вложено в АЦЦ0.
[01:16:48.400 --> 01:16:56.400]  АЦЦ0 – это такой класс, где вы добавили вот такой ксор,
[01:16:56.400 --> 01:17:03.400]  и еще, кажется, сравнение по любому простому модулю.
[01:17:03.400 --> 01:17:08.400]  То есть у вас есть такие еще элементы, у которых сколько угодно аргументов,
[01:17:08.400 --> 01:17:14.400]  и они вам говорят, число единиц среди аргументов делится на по или не делится.
[01:17:14.400 --> 01:17:21.400]  АЦЦ0 – это тоже 0, значит, константная глубина, а элементы – это конъюнкция, дизъюнкция и вот такие вот сравнители.
[01:17:21.400 --> 01:17:27.400]  То есть ксор – это сравнитель по модулю 2, а сравнитель по любому другому модулю там тоже есть.
[01:17:27.400 --> 01:17:34.400]  И была не такая давняя теорема, это 2011 год.
[01:17:34.400 --> 01:17:39.400]  Теорем Уильямса доказал.
[01:17:39.400 --> 01:17:47.400]  И там буквально вообще все техники, которые известны ученым, они были тут использованы.
[01:17:47.400 --> 01:17:57.400]  Но тут нам-то мы хотим, что NP не равняется P, а еще лучше, чтобы NP не вложено в P слэш поле.
[01:17:57.400 --> 01:18:05.400]  И тогда NP гораздо меньше, чем NX, а P слэш поле гораздо больше, чем вот эта штука, чем АЦЦ0.
[01:18:05.400 --> 01:18:11.400]  То есть это то, что мы хотим, невообразимо дальше от того, что мы умеем.
[01:18:11.400 --> 01:18:17.400]  Но, возможно, при нашей жизни это изменится.
[01:18:17.400 --> 01:18:23.400]  Все, на этом лекция заканчивается.
[01:18:23.400 --> 01:18:31.400]  Я обсужу с семинаристами. Мы не успели пройти только всякие маленькие схемы для конкретных функций,
[01:18:31.400 --> 01:18:37.400]  например, для двоечного сложения. Двоечное сложение оно где-то вот тут.
[01:18:37.400 --> 01:18:41.400]  Ну или даже вот тут, если постараться.
[01:18:41.400 --> 01:18:45.400]  Но вот здесь точно.
[01:18:45.400 --> 01:18:49.400]  И умножение там же.
[01:18:49.400 --> 01:18:55.400]  Посмотрим, либо я это на первой половине в следующий раз расскажу, либо мы сразу про вероятность начнем.
[01:18:55.400 --> 01:18:59.400]  Все, спасибо за внимание.
