[00:00.000 --> 00:07.960]  Мы будем говорить о решении уравнений эллиптического
[00:07.960 --> 00:08.960]  типа.
[00:08.960 --> 00:17.360]  Это в основном стационарные задачи математической
[00:17.360 --> 00:19.720]  физики, не только математической физики.
[00:19.720 --> 00:28.360]  С помощью этих задач решаются задачи о генерации расчетных
[00:28.360 --> 00:32.080]  сеток в разных областях интегрирования.
[00:32.080 --> 00:40.280]  Ну и задачи типа проводности, только стационарной диффузии
[00:40.280 --> 00:43.280]  стационарной.
[00:43.280 --> 00:46.440]  Ну еще целый ряд задач, в том числе, конечно, и задач
[00:46.440 --> 00:49.440]  электростатики.
[00:49.440 --> 00:54.120]  Вы встречались, конечно, с этими уравнениями.
[00:54.120 --> 01:03.880]  Давайте начнем с уравнения плацсона, наиболее характерное
[01:03.880 --> 01:09.720]  уравнение и поставим задачу Дерехре для уравнения
[01:09.720 --> 01:10.720]  плацсона.
[01:10.720 --> 01:17.760]  То есть мы имеем вот такое уравнение, здесь нет производной
[01:17.760 --> 01:18.760]  по времени.
[01:18.760 --> 01:22.520]  То есть задача принципиально стационарная.
[01:22.920 --> 01:24.960]  Какой-нибудь пример простой, представьте себе, что у
[01:24.960 --> 01:30.840]  вас есть вот такой кубик, чисто тестовая задача,
[01:30.840 --> 01:36.160]  и каждая сторона кубика нагревается на свою температуру
[01:36.160 --> 01:37.160]  ТАИТА.
[01:37.160 --> 01:41.400]  Задача найти распределение температуры в этом кубике.
[01:41.400 --> 01:42.400]  Вот это типичная задача.
[01:42.400 --> 01:46.120]  Только у меня здесь двумерная задача, а я изобразил трехмерную
[01:46.120 --> 01:47.120]  задачу.
[01:47.120 --> 01:50.120]  Ну я могу написать, сюда добавить еще производную
[01:50.120 --> 01:53.160]  по третьему направлению, тогда у меня будет задача
[01:53.160 --> 01:58.840]  до трехмерной, неважно, и так далее.
[01:58.840 --> 02:03.800]  Обязательно ставится граничное условие у на г, давайте напишем
[02:03.800 --> 02:08.920]  как f от x и y.
[02:08.920 --> 02:15.960]  Ну пусть здесь у нас x и y принадлежат некой области
[02:15.960 --> 02:19.240]  g, это внутренние точки.
[02:19.360 --> 02:22.760]  Здесь x и y принадлежат границе области интегрирования
[02:22.760 --> 02:30.160]  g, ну и вся область интегрирования давайте обозначим g с волной,
[02:30.160 --> 02:36.600]  это есть объединение двух областей g и g.
[02:36.600 --> 02:41.600]  Ну вот это и будет постановка задачи Дерехлет для уравнения
[02:41.600 --> 02:42.600]  поусона.
[02:42.600 --> 02:46.720]  Ну к этим же задачам относятся, на самом деле, и так называемые
[02:46.720 --> 02:54.720]  уравнения Гюнгольца, то есть добавляется еще вот
[02:54.720 --> 02:58.600]  такой член, это будет уравнение Гюнгольца, которое очень
[02:58.600 --> 03:03.840]  расставлено в задачах электростатики, диффузии и так далее.
[03:03.840 --> 03:14.000]  Ну и записывается, конечно, я уже записал более коротко,
[03:14.000 --> 03:20.600]  но в операторном виде, операторного пласа записывается
[03:20.600 --> 03:25.600]  более коротко, пока равняется, то есть вот в операторном
[03:25.600 --> 03:28.400]  виде эта задача записывается более коротко.
[03:28.400 --> 03:33.400]  Ну давайте, чтобы не писать лишнего сегодня, обозначим
[03:33.400 --> 03:42.800]  нашу область интегрирования как единичную, то есть x и y,
[03:42.800 --> 03:54.040]  пусть подлежат единичному квадратику, вот это наша
[03:54.040 --> 03:55.040]  задача.
[03:55.040 --> 03:57.880]  Теперь давайте опроксимировать эту задачу.
[03:57.880 --> 04:01.200]  Ну вообще говоря, опроксимировать эту задачу вы уже умеете,
[04:01.200 --> 04:07.560]  я вам скорее всего напомню, как это, например, делается.
[04:07.560 --> 04:17.960]  Опроксимируются производные по x и по y, ну например, уm-1l-2uml
[04:17.960 --> 04:37.480]  плюс m-1l, делим на hx в квадрате, и плюс уm-1l-2uml плюс uml-1l-2ml.
[04:37.480 --> 04:51.800]  Делим на h y в квадрате, и равняется это fml для точек xm, yl,
[04:51.800 --> 04:57.880]  подлежащих области g, ну давайте g-tau назовем, то
[04:57.880 --> 05:02.800]  есть это все узлы, которые входят во внутреннюю часть
[05:02.800 --> 05:06.040]  области интегрирования, g-tau.
[05:07.000 --> 05:19.080]  Ну и уm-l, это границы, равняется fml для точек xm, yl, которые
[05:19.080 --> 05:23.720]  принадлежат множеству g-tau.
[05:23.720 --> 05:27.240]  Ну здесь можно было назвать gh, но давайте, мы уже начали
[05:27.240 --> 05:35.680]  обозначать множество индексом tau, то есть tau означает множество
[05:35.680 --> 05:38.240]  дискретно множества точек, это не означает шаг, это
[05:38.240 --> 05:41.160]  означает дискретно множество точек.
[05:41.160 --> 05:48.320]  Ну и опять же множество g-tau, это есть объединение множества
[05:48.320 --> 05:53.800]  основной g-tau и границы tau.
[05:53.800 --> 06:01.960]  Это будет постановка задачи уже апроксимирующих.
[06:01.960 --> 06:04.960]  Она записывается, и мы это делаем в более таком
[06:04.960 --> 06:08.200]  компактном виде, то есть первая, вторая производная
[06:08.200 --> 06:15.400]  может быть записана в виде оператора, λxx здесь уm-l
[06:15.400 --> 06:25.120]  плюс лямда yy уm-l равняется fml, это вот во внутренних
[06:25.120 --> 06:32.080]  точках, на граничных точках тоже самое, или даже еще более
[06:32.080 --> 06:40.640]  компактно, лямда ум-l равняется fml, где оператор лямда, это
[06:40.640 --> 06:46.040]  есть сумма операторов по направлениям лямда xx и лямда
[06:46.040 --> 06:47.040]  yy.
[06:47.040 --> 06:52.480]  Ну то есть задача может быть записана вот так, ну или
[06:52.480 --> 07:00.200]  в операторном виде лямда tau у tau равняется ff tau, это
[07:00.200 --> 07:04.080]  в форме записи наша задача.
[07:04.080 --> 07:17.000]  Так, теперь я вам хотел напомнить наши сентябрьские лекции.
[07:17.000 --> 07:23.360]  Вспомните о численных методах решения системы
[07:23.360 --> 07:25.040]  линейных алгебрических уравнений.
[07:25.040 --> 07:32.800]  В частности, методы якоби, зейделя и релаксации, вешней
[07:32.800 --> 07:33.800]  релаксации.
[07:33.800 --> 07:36.600]  Вспоминается что-нибудь, нет?
[07:36.600 --> 07:38.600]  Почему я об этом вспомнил?
[07:38.600 --> 07:41.400]  Потому что то, что я сейчас вам записал, это если что
[07:41.400 --> 07:45.440]  иное, как система линейных алгебрических уравнений.
[07:45.440 --> 07:51.880]  m и l меняются от 1 до m-1, то есть это система алгебрических
[07:51.880 --> 07:53.960]  уравнений с сильно разреженной матрицы.
[07:53.960 --> 08:03.120]  Давайте их тоже для простоты ограничим.
[08:03.120 --> 08:12.680]  М-большое, матрица сильно разреженная, но здесь тоже
[08:12.680 --> 08:16.840]  не проходит алгоритм прогонки в чистом виде, здесь и все
[08:16.840 --> 08:21.120]  эти задачи решаются, как правило, методами итерационными.
[08:21.440 --> 08:25.440]  Поэтому я вспомнил итерационные методы якоби, зейделя и вешней
[08:25.440 --> 08:26.920]  релаксации.
[08:26.920 --> 08:30.400]  Давайте я вам напомню об этих методах.
[08:30.400 --> 08:33.640]  В верхнюю часть доски стирать не буду, поскольку здесь
[08:33.640 --> 08:37.000]  уже выписана у меня практическая система линейных алгебрических
[08:37.000 --> 08:39.480]  уравнений с сильно разреженной матрицы.
[08:52.120 --> 08:56.120]  Наверное, уже подзабыли, поэтому я напомню.
[08:56.120 --> 09:01.120]  Если мы имеем такую систему алгебрических уравнений
[09:01.120 --> 09:07.120]  u и f, это векторы, предлежат векторному пространству,
[09:07.120 --> 09:13.640]  а это матрица, предлежащая пространству линейных матриц
[09:13.640 --> 09:19.440]  в квадратах n на n, то мы якоби предложили матрицу представлять
[09:19.440 --> 09:24.960]  в виде суммы матриц, нижней диагональной, диагональной
[09:24.960 --> 09:41.960]  и верхней диагональной.
[09:41.960 --> 09:44.560]  Сам итерационный процесс в этом случае выглядит
[09:44.560 --> 09:46.880]  следующим образом.
[09:46.880 --> 09:57.960]  Элементы, стоящие на диагональ, мы обозначаем итерационным
[09:57.960 --> 10:03.560]  индексом i плюс 1, здесь i и i, и это итерационный индекс.
[10:03.560 --> 10:07.400]  То есть и это 0, 1, ну и так далее.
[10:07.400 --> 10:12.880]  Разумеется, обязательно задается начальное приближение.
[10:12.880 --> 10:23.760]  Что это означает для нашей системы уравнений линейных?
[10:23.760 --> 10:31.640]  Диагональные элементы, вот они, я сверху ставлю
[10:31.640 --> 10:38.640]  итерационный индекс i плюс 1, здесь i и i и i.
[10:38.640 --> 10:41.840]  Вот, собственно говоря, итерационный процесс якоби
[10:41.840 --> 10:42.840]  на доске.
[10:42.840 --> 11:04.480]  Это я вам напомнил сентябрьские лекции, что предложил сделать
[11:05.480 --> 11:11.400]  Он предложил нижние диагональные элементы тоже пометить,
[11:11.400 --> 11:15.960]  тоже сделать с индексом i плюс 1, то есть вот сюда поставить
[11:15.960 --> 11:26.320]  индекса i плюс 1, что позволяет вычислять, то есть использовать
[11:27.280 --> 11:32.120]  в вычислениях уже вычисленные значения функций.
[11:32.120 --> 11:40.640]  Что касается процесса якоби, ну я не буду выводить, поскольку
[11:40.640 --> 11:48.240]  у нас сегодня большое объем знаний, скажу, что количество
[11:48.240 --> 11:52.080]  линейных действий для процесса якоби, это примерно
[11:52.080 --> 11:57.800]  2m квадрат на пи квадрат на логарифм эфсиум минус
[11:57.800 --> 12:04.400]  1, где эфсиум это точность, ну, например, 10 минус 6.
[12:04.400 --> 12:07.640]  Ну обычно это примерно, да, обычно делают так, поскольку
[12:07.640 --> 12:10.640]  это целое число, то ставят квадратные скобки и добавляют
[12:10.640 --> 12:11.640]  единицу.
[12:11.640 --> 12:16.120]  То есть количество линейных действий в варианте якоби
[12:16.120 --> 12:17.680]  оценивается вот такой величиной.
[12:17.680 --> 12:26.080]  В методе Зейделя нет двойки, то есть он вдвой быстрее
[12:26.080 --> 12:27.080]  имеется Зейделя.
[12:27.080 --> 12:30.320]  Для данного уровня, не вообще он вдвой быстрее, а для данной
[12:30.320 --> 12:31.320]  конкретной задачи.
[12:31.320 --> 12:34.640]  Это существенный момент.
[12:34.640 --> 12:41.560]  Теперь третий момент, метод верхней релаксации, он позволяет
[12:41.560 --> 12:45.600]  заметно ускорить итерационный процесс, и особенно вот
[12:45.600 --> 12:50.600]  для нашей задачи, особенно для нашей задачи.
[12:50.600 --> 12:54.520]  Давайте вот написем это же уравнение только в более
[12:54.520 --> 12:59.000]  удобном виде, для как раз вот метода релаксации.
[12:59.000 --> 13:06.200]  Так это у нас будет, на самом деле метод релаксации это
[13:06.200 --> 13:11.800]  есть не что иное, как ускоренный метод Зейделя с введением
[13:11.800 --> 13:13.520]  итерационного параметра.
[13:13.520 --> 13:18.880]  То есть я сначала пишу как бы метод Зейделя в несколько
[13:18.880 --> 13:23.920]  ином виде, а потом ввожу итерационный параметр,
[13:23.920 --> 13:26.440]  который позволяет ускорить, для данной конкретной задачи
[13:26.440 --> 13:29.440]  он позволяет существенно ускорить итерационный
[13:29.440 --> 13:30.440]  процесс.
[13:30.440 --> 13:42.680]  Это важно, а здесь у нас будет минус, минус 4 на h квадрат,
[13:42.840 --> 13:59.200]  если я здесь просто напишу u и плюс 1 mL, равняется fmL,
[13:59.200 --> 14:02.480]  это будет не что иное, как метод Зейделя, а вот если
[14:02.480 --> 14:08.120]  я введу сюда итерационный параметр, значит в следующем
[14:08.120 --> 14:14.120]  образом давать ее введу, квадратные скобки здесь
[14:14.120 --> 14:19.400]  u и плюс 1 mL делим на tau, tau это итерационный параметр
[14:19.400 --> 14:30.840]  плюс 1 минус 1 на tau u и mL, равняется fmL, это уже будет
[14:30.840 --> 14:33.640]  итерационный параметр, это уже будет ускоренный
[14:33.640 --> 14:38.240]  процесс Зейделя, ускоренный с помощью итерационного
[14:38.240 --> 14:42.200]  параметра, ну и если вы помните, то этот итерационный параметр
[14:42.200 --> 14:50.400]  его границы от 1 до 2, в этом случае итерационный
[14:50.400 --> 14:56.400]  процесс устойчив, вот и количество арифметических
[14:56.400 --> 15:02.120]  действий вот здесь существенно уменьшается, существенно
[15:02.680 --> 15:07.680]  уменьшается, то есть становится пропроцентальным не m квадрат,
[15:07.680 --> 15:13.520]  а m, то есть количество арифметических действий, это уже очень существенное
[15:13.520 --> 15:16.880]  ускорение итерационного процесса, но это правда
[15:16.880 --> 15:20.840]  характерно именно для этой задачи, то есть для какой-то
[15:20.840 --> 15:24.640]  произвольной системы линейных уравнений, это будет как-то
[15:24.640 --> 15:28.160]  по-другому, ну вот это я вам напомню, как можно решать
[15:28.160 --> 15:31.680]  эту задачу, что касается медно-верхней релаксации,
[15:31.680 --> 15:35.280]  сразу скажу, ее очень любят инженеры, любят физики,
[15:35.280 --> 15:37.720]  почему, потому что он очень прост, во-первых, просто
[15:37.720 --> 15:41.280]  математически, во-вторых, очень прост алгоритмически,
[15:41.280 --> 15:44.600]  да, то есть и в принципе вы делаете некие циклы,
[15:44.600 --> 15:50.280]  так сказать, довольно простые, программистские, и он работает,
[15:50.280 --> 15:54.160]  но метод Зейделья тоже относится к рабочим методам,
[15:54.160 --> 15:58.000]  тоже их используется, но гораздо реже, почему, потому
[15:58.000 --> 16:02.440]  как он существенно медленнее, метод якобы используется
[16:02.440 --> 16:05.920]  в основном в учебнометодических целях, хотя якобы все это
[16:05.920 --> 16:11.040]  начал, с него пошло, но метод, конечно, требует слишком
[16:11.040 --> 16:15.880]  много итераций, слишком много итераций, поэтому его,
[16:15.880 --> 16:20.440]  ну как вот помните, метод лакса в уравнении переноса
[16:20.440 --> 16:22.920]  в чистой видне используется, но используется активно
[16:22.920 --> 16:25.240]  в учебнометодических целях и для построения других
[16:25.240 --> 16:27.800]  методов, то же самое и здесь.
[16:27.800 --> 16:32.800]  Так, ну идем дальше, разумеется, математики не остановились
[16:32.800 --> 16:37.120]  на этом, ну трудно упрекать, конечно, якобы Зейделья
[16:37.120 --> 16:40.080]  в том, что они на этом остановились, тогда не было компьютеров,
[16:40.080 --> 16:46.400]  собственно говоря, вот решалось все на коленке, как говорится,
[16:46.400 --> 16:52.640]  вот, но потом начали появляться компьютеры и начали, и появилась
[16:52.640 --> 16:57.760]  потребность ускорений методов, вот давайте
[16:57.760 --> 17:05.480]  перейдем к разному способу ускорения, к разному способу
[17:05.480 --> 17:10.880]  ускорения, но прежде чем перейти, замечу еще такую
[17:10.880 --> 17:17.360]  важную деталь, опроксимация и порядок опроксимации,
[17:17.360 --> 17:22.000]  и первое дифференциальное приближение, я о них несколько
[17:22.000 --> 17:26.480]  слов скажу, хотя для вас это уже, так сказать, ну такой
[17:26.480 --> 17:30.000]  понятная вещь, мы уже неоднократно об этом говорили, но давайте
[17:30.000 --> 17:40.400]  все-таки еще раз об этом напомним, если мы напишем
[17:40.400 --> 17:50.920]  наши опроксимирующие уравнения в такой виде, ну а h из квадрата
[17:50.920 --> 18:02.760]  плюс u, значит, m, l, минус 1, минус 2, u, m, l, плюс u, m, l, плюс 1,
[18:02.760 --> 18:12.240]  делим на h, y в квадрате, и я захотел бы его исследовать
[18:12.240 --> 18:16.360]  на порядок опроксимации, и найти первое дифференциальное
[18:16.360 --> 18:19.120]  приближение, что я делаю, я поступаю так же, как вы
[18:19.120 --> 18:25.640]  всегда поступали, то есть вот в этой разности соотношения
[18:25.640 --> 18:30.040]  я оставлю проекцию точного решения, ну проекцию точного
[18:30.040 --> 18:37.360]  решения мы традиционно обозначаем u и далее я раскладываю все
[18:37.360 --> 18:43.400]  функции в окрестностей точки u, m, l, ну давайте так, один
[18:43.400 --> 18:47.280]  раз я разложу, вы уже раскладывали много раз, вы это все без меня
[18:47.280 --> 18:56.560]  легко сделаете, это будет, ну, например, u, m, l, плюс h, x в квадрате
[18:56.560 --> 19:05.760]  на u, 4х, m, l, плюс h, x, ну h, x это значит h, y, h, x, h, y это
[19:05.760 --> 19:09.960]  соответственно, как вы догадались, шаги по координату x, по координату
[19:09.960 --> 19:22.520]  y, так здесь делим на 2, u, 2, 4x, m, l, плюс h в кубе, h, x в кубе
[19:22.520 --> 19:30.560]  на 6, ну третья производная по x, m, l, ну давайте еще плюс
[19:30.560 --> 19:36.120]  h, с четвертой на 24 нам потребуется эта производная, это уже
[19:36.120 --> 19:41.720]  четвертая производная будет по x, m, l, и плюс о большое
[19:41.720 --> 19:47.520]  вот h в пятой степени, ну и то же самое делаем со
[19:47.520 --> 19:56.840]  остальные функциями, и ставим их в разнообразное уравнение, что мы получим, ну вы уже
[19:56.840 --> 20:01.840]  давно прекрасно знаете, что мы должны получить наше исходное дифференциальное
[20:01.840 --> 20:14.960]  уравнение в точке m, l, и плюс, вот это погрешность r tau, r tau тоже точкой m, l, значит если мы все это
[20:15.000 --> 20:23.240]  аккуратно сделаем, я уже делать не буду, поскольку это такая уже простая алгебра, то мы получим, что наша r tau
[20:23.240 --> 20:35.240]  погрешность, это будет следующее выражение, это будет следующее выражение h, x в квадрате на 24, здесь
[20:35.240 --> 20:48.120]  четвертая производная по x, и h, y в квадрате на 24, здесь тоже четвертая производная по y,
[20:48.120 --> 21:00.360]  так, ну разумеется плюс о большое, вот h, x, четвертая плюс h, y, четвертая, ну я на этом ограничусь,
[21:00.360 --> 21:07.720]  ограничусь, то есть здесь у меня понятно, что опроксимация второго порядка, второго порядка,
[21:07.720 --> 21:17.280]  да, вот, и по обеим переменам h, x и h, y, но здесь у меня h, четвертый и y, четвертый, отсюда можно
[21:17.280 --> 21:25.960]  сделать, значит, еще один вывод, первое дифференциальное приближение, как оно будет выглядеть, что есть
[21:26.900 --> 21:32.640]  дифференциальное приближение, это вот наше дифференциальное уравнение и плюс, главный
[21:32.640 --> 21:41.740]  член ошибке опроксимации, главный член ошибки опроксимации у нас нет, вот такой, то есть этоko есть
[21:41.740 --> 21:47.740]  дельта у минус f и минус и минус
[21:47.740 --> 21:59.480]  давайте так напишем 1 24 здесь hx в квадрате так на у 4 производной по x
[21:59.480 --> 22:05.540]  плюс hy в квадрате на 4 производную по y
[22:05.540 --> 22:09.900]  равняется 0 вот это вот то уравнение которое мы реально решаем
[22:09.900 --> 22:15.020]  проведя такую опроксимацию то есть у нас вот погрешность то есть к нашему
[22:15.020 --> 22:25.420]  уровню и добавляется чего такая вот вот такого слагаемая да ну и вот вспомните
[22:25.420 --> 22:31.740]  как мы получали тем более высокого порядка точности да как поднимали зная
[22:31.740 --> 22:39.060]  выражение для главного члена ошибки опроксимации для главного члена ошибки
[22:39.060 --> 22:42.620]  опроксимации что мы делаем для этого
[22:45.820 --> 22:51.620]  да мы мы опроксимировали вот этот главный член ошибки опроксимации по
[22:51.620 --> 22:59.580]  точкам по нашим узлам и уносили его в левую часть и получали что получали уже
[22:59.580 --> 23:04.460]  схему более высокого порядка опроксимации в данном случае четвертого порядка точно
[23:04.460 --> 23:15.700]  то же самое мы можем сделать и здесь да то есть как это будет выглядеть вот вот
[23:15.700 --> 23:22.380]  у нас наша разностная схема да ну давайте ее напишем в таком более но
[23:22.380 --> 23:31.760]  оператор на виде у м и минус вот этот главный член ошибки опроксимации это у
[23:31.760 --> 23:42.800]  нас будет 1 24 аши квадрат а здесь уже не четвертая производная ее опроксимация
[23:42.800 --> 23:48.080]  четвертой производной обозначается так ну мы ее обозначали когда-то вот четвертая
[23:48.080 --> 23:56.200]  опроксимация по их здесь аши квадрат четвертая опроксимация по игрок то есть
[23:56.200 --> 24:04.680]  опроксимация четвертой производной по игрок равняется вот собственно говоря мы
[24:04.680 --> 24:10.360]  получили разностную схему уже четвертого порядка опроксимации чем мы расплатились
[24:10.360 --> 24:19.760]  за повышенный порядок опроксимации расширенем шаблон в данном случае решение шаблону чем-то
[24:19.760 --> 24:25.920]  обязательно расплачивается можно чтобы нашли по координатам это более просто можно по
[24:25.920 --> 24:33.120]  времени делать третий слой водитель но здесь время у нас нет поэтому здесь у нас мы только по
[24:33.120 --> 24:46.640]  координатам уже расширять шаблон но вот пока на этом закончу первую часть наше на нашей темы и
[24:46.640 --> 24:54.800]  теперь переходим к построению итерационных процессов с выбором оптимальных итерационных
[24:54.800 --> 25:00.000]  параметров то есть как можно ускорить итерационный процесс выбирая определенным образом
[25:00.000 --> 25:06.640]  итерационные параметры в принципе мы уже эту тему когда-то с вами касались когда говорили
[25:06.640 --> 25:12.320]  о методах о вариационных методах решение системы линейных агебаритческой ровнений мы там тоже
[25:12.320 --> 25:19.160]  выбирали итерационные параметры когда один на все итерации а когда на каждой итерации
[25:19.160 --> 25:25.520]  вычислялся свой итерационный параметр вот это позволяет ускорить наш итерационный процесс вот
[25:25.520 --> 25:36.480]  что-то подобное мы попробуем сделать и сейчас то есть выбирать итерационные параметры которые
[25:36.480 --> 25:48.040]  бы ускоряли наш итерационный процесс но вот первый метод фактически это такой более методический
[25:48.400 --> 25:56.520]  метод от которого мы будем отталкиваться в дальнейшем это один итерационный параметр
[25:56.520 --> 26:04.840]  так
[26:04.840 --> 26:15.120]  я представляю наш итерационный процесс для решения системы линейных уравнений следующим
[26:15.120 --> 26:32.160]  образом и это итерационный параметр здесь у меня будет у и и стал там это итерационный
[26:32.160 --> 26:41.800]  параметр а здесь я выписываю на собственно нашу систему линейных агебаритческих уравнений
[26:41.800 --> 26:53.760]  при у и плюс один минус у это по некой норме стремящимся к нулю при и стремящимся к
[26:53.760 --> 26:59.400]  бесконечности ну мы получаем решение нашей системы линейных агебаритческих уравнений
[26:59.400 --> 27:12.240]  если мы пишем следующим образом то есть норма решения на двух и это раса х меньше
[27:12.240 --> 27:18.840]  оранья цепь всего то имеется ввиду что мы задаем некую точность решения например 10 минус 5 10
[27:18.840 --> 27:34.240]  минус судьбой например вот так далее если мы пишем уитой минус у уитой мл минус у мл где
[27:34.240 --> 27:47.720]  у мл это проекция точно решение на сетку мы чтобы такое писали с вами осенью да то есть это
[27:47.720 --> 27:54.200]  есть не что иное как сходимость определение сходимости нуку здесь у нас параметр который
[27:54.200 --> 28:02.120]  меняется от нуля до единицы чтобы была сходимость а ц это как обычно некий параметр у большой вот
[28:02.120 --> 28:09.520]  единицы в этом случае мы будем иметь сходимость сходимость это рационного процесса ну и исходя
[28:09.520 --> 28:18.880]  из вот этих двух неравен с можно оценить примерно конечно оценить обычно сверху оценки
[28:18.880 --> 28:26.720]  проводится количестве тарас это будет логарифм и все он делит на ц едем на логарифм ну и еще
[28:26.720 --> 28:36.480]  чаще упрощает логарифм и делить на логарифм поскольку ц обычно лишь константа порядка
[28:36.880 --> 28:43.320]  ну таким образом вот по этой несложной формуле оценивается количество итерации в итерационном
[28:43.320 --> 29:02.080]  процессе так далее далее очень важно получить оценку для эволюции погрешности итерационного
[29:02.080 --> 29:09.280]  процесса на каждой итерации для этого из верхнего соотношения мы вычитаем очевидное
[29:09.280 --> 29:22.120]  тоже у мэй равняется у мэй и устал а здесь лямбда у мэй минус fм и так
[29:22.120 --> 29:36.000]  ну видимо вы догадались если вы читаем то вот такая величина давайте я обозначу
[29:36.880 --> 29:50.240]  равная у с 1 м и у мэй это погрешность погрешность нашего решения и мы можем теперь
[29:50.240 --> 29:58.320]  получить уравнение для ее эволюции то есть это будет и и плюс 1 м и правой части р и
[29:58.320 --> 30:13.280]  м и устал а здесь будет лямбда и м и сокращается ну и не еще более коротко
[30:13.280 --> 30:24.520]  оператор на видео и устал я буду вверх и вот это очень важное уравнение для эволюции погрешности
[30:24.520 --> 30:33.480]  для эволюции погрешности ну давайте в операторном виде она удобно смотрится так
[30:33.480 --> 30:42.040]  довольно компактно но обычно его переводит нормы и плюс 1 м и в норов меньше равняется
[30:42.040 --> 30:51.160]  норме не плюс стало лямбда по нормам оператора что там все равно что если бы хотим что-то
[30:51.160 --> 30:58.720]  оценить но все равно придется в нормах работать норма это чеснок которая дает оценку в каком-то
[30:58.720 --> 31:04.720]  смысле вот работа нашего оператора да поэтому все равно он придется к нуку но он переходить так
[31:04.720 --> 31:17.680]  и здесь у нас норма р и м и но отсюда не сложно понять что р и м и можно в нормах это будет
[31:17.680 --> 31:29.880]  норма и плюс стал лямбда в тепени и на р 0 м и то есть на норму начального приближения
[31:29.880 --> 31:43.600]  ну и разумеется нам бы хотелось чтобы норма вот вот этого оператора перехода будем его называть
[31:43.600 --> 31:52.720]  к оттал была в модуле меньше единицы больше нуля тогда наш процесс операционной будет
[31:52.720 --> 32:03.560]  сходиться аж будет сходиться хорошо давайте значит тогда вот искать эту норму давайте не искать
[32:03.560 --> 32:14.240]  для этого для этого мы представим вот у нас появилось появилась норма начального приближения
[32:14.240 --> 32:22.720]  да давайте вот это начальное приближение есть такая палочка вручалочка называется разложение
[32:22.720 --> 32:29.360]  функций в ряды пульет ну действительно по порой выручает и позволяет решать огромное
[32:29.360 --> 32:35.560]  количество задач когда разлагается в функции ну в религии там пейлора макарона маклорена
[32:35.560 --> 32:44.240]  фурье но фурье наиболее часто разлагает вот мы тоже разложим представим на нашу начальник
[32:44.240 --> 32:55.240]  приближения в виде такого частичного ряда при я сумма по п и к ну цей пейку это коэффициенты
[32:55.240 --> 33:01.800]  которую мы назовем коэффициенты фурье что такое омега омега это есть собственные функции нашего
[33:01.800 --> 33:09.600]  оператора нашего оператора лямбда ну помните лямбда на уровне айцаев да это тот оператор
[33:09.600 --> 33:16.400]  которого мы вводили то есть это сумма двух операторов лямбда икс икс плюс лямбда и греки оказывается
[33:16.400 --> 33:23.000]  эти операторы все но первых обладают замечательными свойствами они все симметричные положительно
[33:23.000 --> 33:29.080]  определены но это несложная алгебрическая задача вы ее можете доказать просто выписав эти
[33:29.080 --> 33:36.760]  оператор в чем явно видим вот а это означает что у них должны быть собственные вещественные
[33:36.760 --> 33:42.520]  собственные числа и собственные функции это действительно так вот например для оператора
[33:42.520 --> 33:51.520]  лямбда икс икс собственное число лямбда по давать напишем выиграем следующим образом 4
[33:51.520 --> 34:03.520]  делим на аж квадрат здесь синус квадрат и делим на 2 ну по этому параметр который меняется от
[34:03.520 --> 34:11.280]  единицы до м большой минус 1 и большой минус 1 но давайте для простоты положим что аж икс
[34:11.280 --> 34:21.080]  равняюсь аж игры то есть по по обеим координатам шаги шаги одни и те же это проверяется
[34:21.080 --> 34:33.520]  непосредственно подстановка со соотношение и и лямбда игрок игрок также обладает тем же
[34:33.520 --> 34:44.720]  свойствами лямбда допомерку 4 наш квадрат синус квадрат здесь у нас будет купе на 2
[34:44.720 --> 34:54.600]  тоже это все проверяется непосредственно постановка ну поскольку это хорошо знаете да а омега равняется
[34:55.200 --> 35:07.360]  форму должны знать эту даже если вас кровати поднимут во сне до линии алебры и и кроме того
[35:07.360 --> 35:16.600]  вот еще одно замечание важное тоже проверяется на панапамер непосредственно постановкой
[35:16.600 --> 35:26.400]  собственное число вот нашего суммарного оператора этого давайте обозначим так это
[35:26.400 --> 35:35.360]  уже двумерный оператор поэтому две переменных лямбда пеху это будет сумма наших двух операторов
[35:35.360 --> 35:49.640]  лямбда п плюс лямбда куп кроме того кроме того все три оператора имеют собственные функции
[35:49.640 --> 35:58.640]  коли не имею собственное значение то имею собственные функции давайте их обозначим следующим образом
[35:59.120 --> 36:13.320]  собственные функции для оператора лямбда xx это будет омега п м для оператора лямбда
[36:13.320 --> 36:27.120]  y и для суммарного оператора лямбда это будет функция уже двумерная
[36:27.120 --> 36:39.200]  омега большой давайте обозначим п ку внизу м это будет произведение п м на омега к
[36:39.200 --> 36:46.800]  вот то что это все собственные функции собственные числа проявляется непосредственная постановка эту
[36:46.800 --> 36:55.000]  самую формулу хорошо известную из линейной алгебры вот вид конкретно их конкретный омег мы
[36:55.000 --> 37:00.600]  можем получить но она пока он не нужен я по я не буду сейчас на это ратифе моно просто не нужен
[37:00.600 --> 37:10.520]  его можно вычислить вот идем дальше идем дальше так мы разложили нашу функцию вот такой частичный
[37:10.520 --> 37:21.680]  ряд фолье по в ряд по собственным функциям по собственному нас в дальнейшем очень сильно выручит
[37:21.680 --> 37:31.280]  это собственно говоря я излагаю ничто иной как метод нахождения вот таких так называемых
[37:31.280 --> 37:37.360]  оптимальных итерационных параметров то есть я выписал итерационный процесс с итерационным
[37:37.360 --> 37:45.680]  параметром но вопрос вычисления его если мы можете мы можем любой параметр ввести да и
[37:45.680 --> 37:51.400]  самое простое что мы можем сделать взять и экспериментально его искать да то есть от
[37:51.400 --> 37:57.120]  минус нет нет нет минус от нуля до плюс бесконечности и чисто перебирать и смотреть
[37:57.120 --> 38:02.480]  какой параметр лучше но это наверное все-таки не оптимальное решение лучше его все-таки вычислить
[38:02.480 --> 38:08.400]  и иметь конкретную конкретную форму этим мы сейчас и займемся так вот значит у нас
[38:09.280 --> 38:19.120]  это нам потребуется так а далее нам нужно будет ну давайте один шаг итерационный сделаем и
[38:19.120 --> 38:34.680]  вычислил r 1 это будет у нас что соответствие после этой формы е плюс лямбда на р 0
[38:34.680 --> 38:48.600]  вместо 0 мы будем ставить вот частичную сумму ряда фурье это будет у нас е плюс лямбда
[38:48.600 --> 39:04.160]  так а здесь сумма тп кум на омега м и так идем дальше знак оператора вносим под скобки нам
[39:04.160 --> 39:18.720]  его нужно раскрыть это оператор это в общем то можем можно просто просто
[39:18.720 --> 39:23.400]  показать если выписать в явном виде оператор но оператор можно выписать виде матрицы да
[39:23.400 --> 39:30.800]  мэтр матрицы и показать просто непосредственно постановкой матрица на омига равняется лямбда
[39:30.800 --> 39:36.900]  что это будут вот вещественные числа в общем-то это нужно но это понимать это
[39:36.900 --> 39:42.400]  упражнение дя как аскурса линейная алгебра вы это можете сделать в качестве
[39:42.400 --> 39:46.400]  упражнений может быть даже у вас такая задача раньше было может быть еще и
[39:46.400 --> 39:51.880]  сейчас стоит сейчас стоит но вообще говоря оператор симметричный положительно
[39:51.880 --> 39:58.920]  определенный вот если это так то у него должны быть вещественные все собственные
[39:58.920 --> 40:05.000]  числа вещественные ну и соответственно собственные функции но это вот те ремы
[40:05.000 --> 40:11.320]  которые вам доказывают и так вносим знак оператора под знак суммы получаем
[40:11.320 --> 40:26.200]  тп у здесь у нас е плюс тау оператор лямда большое на собственные функции
[40:26.200 --> 40:32.960]  омега паку а здесь омега л ну сумма по паку естественно берется паку меняется от
[40:32.960 --> 40:40.560]  единицы до м и минус 1 а вот здесь смотрите здесь у нас произведение
[40:40.560 --> 40:47.600]  оператора на собственные функции да очень и очень ничего не напоминает вам
[40:47.800 --> 40:53.060]  что вместо этого произведения хорошо бы подставить
[40:53.560 --> 40:58.220]  лямбда на собственные функции да оператор это всё таки не совсем конкретно
[40:58.220 --> 41:03.560]  конкретно да это это оператор а если не поставим лямбда то есть собственное
[41:03.560 --> 41:07.440]  число вот этого оператора ты будешь и умножим на собственную функцию то это уже
[41:07.440 --> 41:13.200]  будет нечто более конкретное вот давайте это сделаем
[41:13.200 --> 41:19.280]  Опять же, оказывается собственной функцией, то есть собственным числом вот этого
[41:19.280 --> 41:25.160]  оператора является следующее, что тоже легко проверить непосредственно
[41:25.160 --> 41:30.600]  постановкой. Здесь цпq, а вот это собственное число, единица мин уставу
[41:30.600 --> 41:37.040]  навязана по этому. Вот эта единица мин уставу навязана по q, оказывается, есть не что
[41:37.040 --> 41:43.800]  иное, как собственное число этого оператора. Это уже легче, теперь уже легче разговаривать
[41:43.800 --> 41:52.520]  с вами. Мы уже вместо оператора имеем конкретное число. А вот теперь нам
[41:52.520 --> 41:58.800]  хотелось бы, давайте я здесь, уже с утру, часть заски.
[41:58.800 --> 42:27.600]  Вот так. Теперь хотелось бы нам определить норму оператора R1.
[42:27.600 --> 42:37.000]  Для этого мы введем по понятной формуле норму оператора R0, то есть норму оператора R0ML,
[42:37.000 --> 42:43.440]  ну и аналогичную, естественно, норму любого оператора. Будем вводиться на любой погрешности.
[42:43.440 --> 42:52.760]  Это есть скалерное произведение R0 на R0, но скалерное произведение R0 на R0 это,
[42:52.760 --> 43:07.480]  что будет? Это будет корень квадратный, то есть это евклидовая норма, из цепок q в квадрате.
[43:07.480 --> 43:15.320]  Ну, также это будет и норма, то есть норма погрешности нулевой, это есть не что иное,
[43:15.320 --> 43:21.080]  как вот евклидовая норма, которая определяется через коэффициенту фурье. Она же будет новой
[43:21.880 --> 43:29.840]  точно так же мы определим и норму погрешности R1. Так мы ее вот в таком виде определили,
[43:29.840 --> 43:43.760]  давайте ее распишем дальше. R1ML это у нас. Это у нас что будет? Вот у нас выражение.
[43:43.760 --> 43:53.480]  Это у нас будет следующее, корень квадратный из суммы. Тпq тоже в коэффициенте фурье на 1
[43:53.480 --> 44:03.400]  минус tau лямба пq корень квадратный. Вот здесь давайте неравенство поставим.
[44:03.400 --> 44:14.240]  Вынесем, здесь тоже квадрат. За скобки собственные числа нашего оператора. Это будет меньше
[44:14.240 --> 44:24.680]  равняется максимум по лямбда вот такой абсолютно веничной единицы минус лямбда пq. А здесь у нас будет
[44:24.680 --> 44:36.840]  сумма цпq в квадрате. То есть это будет ни что иное, как норма R0ML. Мы эту норму
[44:36.840 --> 44:47.280]  вставили. Так, то есть еще раз, это значит у нас будет у нас будет максимум по лямбда
[44:47.280 --> 45:01.680]  этой функции tau единицы минус tau лямбда пq. Лямбда известна, это функция tau. И на норму R0ML.
[45:01.680 --> 45:11.400]  Теперь уже мы пришли к более конкретным выражениям, которые можно вычислять, скажем так. Уже у нас
[45:11.400 --> 45:21.240]  операторы заменили на собственные числа, собственные функции и так далее. Еще одно упрощение,
[45:21.240 --> 45:32.880]  которое можно сделать. Эта функция tau имеет очень простой вид. Если на графике нарисовать,
[45:32.880 --> 45:43.800]  что это вот такой модуль, вот такой вид имеет. И по виду этой функции, если вы внимательно
[45:43.800 --> 45:54.680]  посмотрите, то можно определить, что своего максимума эта функция достигает на краях либо при лямбда
[45:54.680 --> 46:01.680]  равном минимальном значении своем и либо при максимальном значении. Вот эта функция. Ну,
[46:01.680 --> 46:10.040]  можно мы определить вот этот диапазон или спектр. То есть значение можем. Для этого я вам и
[46:10.040 --> 46:17.280]  выписывал выражение для лямб, исключительно с этой целью. Напомню. Так, здесь я, наверное,
[46:17.280 --> 46:22.240]  могу стирать уже, да? Я, наверное, могу стирать. Давайте вспомним выражение для
[46:22.240 --> 46:34.160]  спектра собственных значений наших операторов. И определим ее минимум и максимум. Так,
[46:34.160 --> 46:45.680]  собственное значение лямбда p равняется 4 на h квадрат. Здесь синус квадрат p на p на 2m.
[46:45.680 --> 47:00.240]  Как p меняется от 1 до m минус 1? Как мы определим минимум и максимум этого значения? Минимум при
[47:00.240 --> 47:11.760]  p равном 1, максимум при p равном n минус 1. Если p, давайте так, лямбда минимум назовет 4 на h
[47:11.760 --> 47:20.400]  квадрат. Ну, если p равняется 1, то синус будем полагать малым. Вместо синуса напишем просто p
[47:20.400 --> 47:30.960]  квадрат на 4m квадрат. Ну, действительно, если это единица, p это p, а m это какое-то большое число.
[47:30.960 --> 47:36.540]  Это количество разбиений узлов на нашей сетке. Поэтому p на m это число малое, поэтому мы
[47:36.540 --> 47:43.560]  синус можем заменить на значение аргумента. Так что получится, четверки сокращаются, m квадрат
[47:43.560 --> 47:53.840]  и h квадрат. Это одно и то же. Получаем p квадрат. Вот, лямбда минимум. А лямбда минимум
[47:53.840 --> 48:03.200]  это лямбда минимум от одномерного оператора. Вот давайте так уточним. А лямбда минимум от
[48:03.200 --> 48:09.720]  двумерного оператора, вот этот лямбда, ну давайте его назовем l для простоты. Это будет сумма
[48:09.720 --> 48:17.280]  и квадрата и q квадрата. То есть сумма двух операторов одномерных. Лямбда х и лямбда у и у. Это
[48:17.280 --> 48:26.240]  будет 2q квадрата. Так, теперь лямбда максимум. Значит вместо p мы ставим m минус 1. Ну, в силу
[48:26.240 --> 48:33.040]  того, что m и m минус 1 числа большие, мы их просто можем приблизительно сократить. Да, поэтому лямбда
[48:33.040 --> 48:40.360]  максимум, ну здесь только приблизительно нужно ставить знак. Приблизительно это 4 на h квадрат,
[48:40.360 --> 48:53.320]  здесь sin квадрат и пополам. То есть это будет у нас 4m квадрат. Ну, m это единица от h квадрат,
[48:53.320 --> 49:03.280]  либо h это единица от m. Так, это у нас будет, что это максимальное число, а соответственно это
[49:03.280 --> 49:09.680]  максимальное число от одномерного оператора. А если брать лямбда максимум от оператора
[49:09.680 --> 49:17.000]  двумерного, вот лямбда, ну давайте обозначим его l большое, чтобы меньше писать. Это будет
[49:17.000 --> 49:31.800]  дома двух собственных чисел, то есть 8m квадрат. Так, а теперь вспомните, что такое отношение двух
[49:31.800 --> 49:40.280]  собственных чисел матрицы максимального и минимального, что оно означает. Вспомните или
[49:40.280 --> 49:47.800]  нет, это тоже материал наших сентябрьских занятий. Обусловленность, совершенно верно,
[49:47.800 --> 49:54.680]  это параметр обусловленности, либо число обусловленности матрицы, ну либо оператора нашего. И вот видите,
[49:54.680 --> 50:03.880]  каково оно. Оно на самом деле безрадостно. Это примерно что получается, 4m квадрат на phi квадрат.
[50:03.880 --> 50:10.080]  То есть число обусловленности очень большое, то есть на задачи наши очень плохо обусловленные.
[50:10.080 --> 50:18.640]  Это вот с одной стороны безрадостное явление, пессимистичная информация, которую мы получили,
[50:18.640 --> 50:28.400]  но с другой стороны люди думали над этим и все-таки сообразили, как с этим бороться. Что значит число
[50:28.400 --> 50:35.280]  обусловленности большое для итерационного процесса, который тем не менее сходится к решению задачи.
[50:35.280 --> 50:42.040]  Это означает, что он будет сходиться итерационного процесса, но будет сходиться долго. То есть количество
[50:42.040 --> 50:51.000]  итерации будет большое. Вот это действительно так. И конечно вот математике довольно долго
[50:51.000 --> 51:01.200]  думали над тем, как количество итерации уменьшить. Например, количество итерации для того же
[51:01.200 --> 51:07.320]  медоякоби, о котором я только что говорил, давайте какую-то конкретную цифру. Например,
[51:07.320 --> 51:17.400]  Е пусть будет примерно 10 минус 5 степени, а М равняется 100. Количество итерации для медоякоби
[51:17.400 --> 51:25.080]  будет порядка, по-моему, двойка на 10 четвертой степени. Непринципиально, что двойка. По-моему,
[51:25.080 --> 51:31.560]  я правильно писал. То есть количество итерации примерно 10 тысяч. Это большое количество
[51:31.560 --> 51:42.720]  итерации для медоякоби. Для медоазея оно вдвое меньше без двойки, ну а мед, если мы введем
[51:42.720 --> 51:50.360]  параметр итерационный, то мы можем уменьшить на порядок количество итерации. То есть вот это
[51:50.360 --> 52:01.960]  как делается. И делается очень эффективно. Идем дальше. Итак, на чем мы остановились?
[52:01.960 --> 52:13.240]  Так максимум. Так вот мы остановились на том, что максимум этой функции, модуль единицы
[52:13.240 --> 52:20.440]  минус 100 на лямбда, будет достигаться либо при лямбда минимум, либо при лямбда максимум.
[52:20.440 --> 52:40.840]  Так, сейчас давайте место свободим. Это уже что-то совсем конкретное. Совсем близко к истине. То есть
[52:40.840 --> 52:48.400]  мы можем написать, что этот максимум, это если что-то как максимум. Вот l малое, l большое.
[52:48.400 --> 52:55.520]  А здесь напишем так. Единиц. Это максимум с двух функций. Единица минус стал l. L это
[52:55.520 --> 53:06.040]  минимальное собственное значение по модулю. Единица минус стал l большое. Вот. И умножить
[53:06.040 --> 53:15.800]  на норму R0ML. Ну это уже совсем хорошо. Потому что максимум такой функции из двух модулей мы
[53:15.800 --> 53:23.080]  найти уже можем школьными методами. Просто взять, нарисовать график этих двух функций и посмотреть,
[53:23.080 --> 53:30.360]  где там будет максимум. Но нам нужен не совсем максимум. Давайте обозначим вот эту функцию.
[53:30.360 --> 53:37.680]  Я ее уже обозначал. Co-tau это та самая функция, которая нам хотелось бы, чтобы она была поменьше,
[53:37.680 --> 53:47.000]  чтобы как раз мы могли реализовать наш интерационный процесс сходящимся. То есть у нас
[53:47.000 --> 53:56.280]  получается, что R1 по норме меньше равняется Co-tau на R0 по норме. Соответственно можно написать,
[53:56.280 --> 54:07.480]  что норма R1ML меньше равняется здесь, что у нас Co-tau в степени I на норму R0ML.
[54:07.480 --> 54:22.200]  Вот уже мы все ближе и ближе к конкретному результату идем. Хотя и медленно, но все ближе и ближе.
[54:22.200 --> 54:30.000]  Итак, смотрите, у нас есть Co-tau, это есть максимум из этих двух функций. Но нам бы хотелось
[54:30.000 --> 54:35.720]  его сделать минимальным. А что это означает? Это означает, что мы хотим решить задачу
[54:35.720 --> 54:51.400]  минимаксовому. То есть минимум Po-tau от максимума по LL, вот этих двух функций,
[54:51.400 --> 55:03.560]  единица минус tau L и единица минус tau LL. Вот нам бы хотелось решить эту задачу и найти отсюда
[55:03.560 --> 55:10.200]  вот как раз tau, то есть тот самый параметр оптимальный, который нам бы дал с нашей точки
[55:10.200 --> 55:33.240]  зрения наилучшее ускорение. Наилучшее ускорение. Мы можем написать, что это
[55:33.240 --> 55:43.000]  есть не что иное, как аргумент от минимума по tau, максимума, мы это уже писали с вами,
[55:43.000 --> 55:52.720]  LL, когда говорили методах оптимизации из двух функций, единица минус tau L и единица минус tau,
[55:52.720 --> 56:04.320]  вот такое. Теперь давайте найдем минимум от максимума. Нужно всего лишь нам нарисовать
[56:04.320 --> 56:11.320]  график. Пусть здесь у нас некая функция будет tau, первая функция, они проходят через денечку,
[56:11.320 --> 56:18.400]  вот это будет первая функция, здесь будет у нас L в минус первой степени, а вот это будет вторая
[56:18.400 --> 56:27.480]  функция. Это будет L тоже в минус первой степени. Максимум они будут достигать вот на этих этвях,
[56:27.480 --> 56:34.080]  это максимум, а минимум на этих двух этвях, где достигается, вот в этой точке. То есть там,
[56:34.080 --> 56:42.880]  где эти две функции пересекаются, то есть при единице минус tau L по модулю равном единице
[56:42.880 --> 56:54.880]  минус tau L по модулю. Решите такое равенство? Решите наверняка. Решите, это tau оптимальный,
[56:54.880 --> 57:02.000]  из этого равенства мы находим, это есть два, делаем на LL, вот он оптимальный параметр,
[57:02.000 --> 57:13.040]  мы нашли уже совершенно конкретно его численное значение, сколько у нас времени,
[57:13.040 --> 57:25.680]  кое-что есть. Это вот у нас оптимальный параметр. Теперь давайте найдем q tau, q tau это тот самый
[57:25.680 --> 57:33.360]  параметр, который, собственно, определяет скорость сходимости. То есть q tau оптимальное,
[57:33.360 --> 57:47.680]  это будет единица минус tau на L. Выписывали мы с вами выражение для tau. Для tau это tau на L.
[57:47.680 --> 57:59.200]  Значит tau это что у нас? Единица минус два на L плюс L и умножить на L. Что это у нас будет? Это
[57:59.200 --> 58:09.360]  будет L большое плюс L малое, минус два L малое, внизу L большой плюс L малое, опять же это будет L
[58:09.360 --> 58:18.400]  большой минус L малое на L большой плюс L малое. Давайте сделаем так. Единица минус L малое на L
[58:18.400 --> 58:26.360]  большой, единица минус плюс L малое на L большой. L большой кальмалый это параметр mu,
[58:26.360 --> 58:31.280]  поэтому можно написать, что это есть единица минус mu в минус первой степени,
[58:31.280 --> 58:36.840]  единица плюс mu в первой степени, в тоже минус первой степени. Идем дальше.
[58:36.840 --> 58:53.480]  Давайте получим эту форму, она не сложная. Это будет единица плюс mu в минус первой степени,
[58:53.480 --> 59:01.400]  минус два mu в минус первой степени, здесь единица плюс mu в минус первой степени. Это будет
[59:01.400 --> 59:10.360]  приблизительно единица минус два mu в минус первой степени. Здесь mu в минус первой степени,
[59:10.360 --> 59:16.400]  немного больше единицы, поэтому можно написать приближенные разницы. Вот что такое будет Q.
[59:16.400 --> 59:22.720]  Ну и в зависимости от mu в минус первой степени мы можем определить,
[59:22.720 --> 59:32.120]  ну например, для тех параметров, для которых я писал, ну это будет 0,999 примерно, то есть не
[59:32.120 --> 59:39.360]  очень высокая скорость сходимости, тем не менее. Ну как можно определить, например,
[59:39.360 --> 59:44.880]  количество итераций для данного итерационного процесса. Давайте тоже это один раз сделаем,
[59:44.880 --> 59:50.880]  потом будете делать уже без меня. Значит, и количество итераций мы писали, что оно
[59:50.880 --> 01:00:01.560]  оценивается как Q, а Q мы знаем. Так, это будет у нас логарифм, здесь логарифм,
[01:00:01.560 --> 01:00:09.360]  единица минус два mu в минус первой степени. Приблизительно это опять же логарифм,
[01:00:10.200 --> 01:00:23.120]  здесь приблизительно разложим логарифм до первого члена, это будет примерно минус два в минус
[01:00:23.120 --> 01:00:33.440]  первой степени. Это опять же как минус, давайте под знак логарифма уберем, а здесь будет у нас mu
[01:00:33.440 --> 01:00:41.920]  пополам на логарифм, единица минус первой степени, давайте, поскольку это число целое,
[01:00:41.920 --> 01:00:46.600]  количество итераций мы сделаем в квадратной скобке и добавим 1. Ну вот так вот оценивается
[01:00:46.600 --> 01:00:53.240]  количество итераций в итерационном процессе, если мы задаем точность епсимум, и можно
[01:00:53.240 --> 01:01:01.680]  вычислять Q, то есть параметр, который определяет как раз скорость итерации. Чаще всего их можно
[01:01:02.320 --> 01:01:08.640]  оценить и соответственно оценить количество итераций и так далее. Ну вот это первое,
[01:01:08.640 --> 01:01:17.120]  у нас здесь итерационный параметр один, оказывается с одним итерационным параметром
[01:01:17.120 --> 01:01:24.240]  скорость все-таки получается не очень высокая в сходимости, ну примерно близко к меду зрителя,
[01:01:24.240 --> 01:01:34.960]  но как можно ускорить ситуацию, так же как мы когда-то делали на каждой итерации выбирать
[01:01:34.960 --> 01:01:41.400]  свой итерационный параметр по какому-то признаку, и таким образом действительно можно ускорить очень
[01:01:41.400 --> 01:01:49.640]  существенно итерационный процесс, то есть существенно уменьшить количество итераций,
[01:01:49.640 --> 01:01:54.920]  ну давайте вот для примера сделаем эту задачу, опять же эта задача была решена ЧДШО,
[01:01:54.920 --> 01:02:05.040]  вот и вот результаты решения этой задачи используется в итерационных процессах до сих пор,
[01:02:05.040 --> 01:02:13.080]  ну она действительно была принесла огромные успехи в теории итерационных процессов,
[01:02:13.080 --> 01:02:17.640]  позволила уменьшить количество итераций напорядку.
[01:02:36.640 --> 01:02:37.960]  так так
[01:02:43.080 --> 01:03:08.800]  мы теперь итерационно простой процесс строим следующим образом, пока все аналогично тому,
[01:03:08.800 --> 01:03:13.960]  что мы делаем для одного итерационного параметра, теперь вместо tau мы ставим
[01:03:13.960 --> 01:03:21.000]  tau внизу индекс и плюс один, то есть на каждой итерации мы будем выбирать свой параметр,
[01:03:21.000 --> 01:03:36.200]  вот так вот, вновь мы из этого как и раньше итерационного соотношения вычитаем очевидное
[01:03:36.200 --> 01:03:48.800]  множество, омл это есть омл плюс tau и плюс один на янда омл минус fml,
[01:03:48.800 --> 01:04:02.320]  напоминаю, что погрешность мы обозначали r и мл, это будет у и это итерационный параметр
[01:04:02.440 --> 01:04:09.640]  омл минус проекция точного решения у большое так и здесь у нас будет
[01:04:09.640 --> 01:04:18.280]  следующие и для погрешности выражение для эволюции погрешности, что нас интересует,
[01:04:18.280 --> 01:04:29.800]  которое мы желаем уменьшить так r и плюс один омл это будет у нас r и м и плюс tau и плюс один
[01:04:29.800 --> 01:04:51.840]  на лямбда на р и м и ну либо в опературном виде и плюс tau и плюс один лямбда на r и м и так вот
[01:04:51.840 --> 01:05:04.120]  вот что у нас получилось, это соотношение между двумя погрешностями на и плюс первой и это итерация
[01:05:04.120 --> 01:05:12.360]  а вот если мы захотим получить выражение для погрешности r и м, то здесь у нас мы не можем
[01:05:12.360 --> 01:05:19.920]  просто так взять и поставить значок и в степень и возвести, поскольку у нас эти скобочки будут
[01:05:19.920 --> 01:05:33.400]  разные, из-за того что параметры разные, поэтому это будет произведение и и плюс один здесь лямбда
[01:05:33.400 --> 01:05:42.080]  так произведение только есть не плюс один, а давайте поставим индекс g, а g у нас будет
[01:05:42.080 --> 01:05:50.800]  меняться от единицы до и, вот так вот и здесь будет у нас и r 0 м и вот что у нас будет тогда,
[01:05:50.800 --> 01:05:57.120]  то есть у нас будет произведение, произведение вот таких погрешностей, ну вот а теперь давайте
[01:05:57.120 --> 01:06:04.160]  следующее сделаем, вот будем исходить из вот этой формулы, опять же прибежим, то есть будем
[01:06:04.160 --> 01:06:13.760]  прилегать к нашей спасительной формулы разложение в ряд фурье, наши погрешности на и плюс первой
[01:06:13.760 --> 01:06:21.760]  и это рация и на это и это рация, значит на и плюс первой и это рация, это что будет cp q и плюс один
[01:06:21.760 --> 01:06:39.240]  на омега пq м это и разлагаем и плюс первую погрешность, а здесь у нас будет так оператор
[01:06:39.240 --> 01:06:56.560]  e плюс tau и плюс один на лямбда и нас в разложении фурье cp q и здесь омега пq м, так давайте
[01:06:56.560 --> 01:07:03.520]  внесем опять оператор под знак суммы, как мы это раньше делали, то у нас получится у нас получится
[01:07:03.520 --> 01:07:20.720]  сумма и пq на этой и это рации, здесь e плюс tau и плюс один на лямбда на омега пq на м л, так и опять обратите
[01:07:20.720 --> 01:07:27.820]  внимание тоже сумму по пq, которая меняется с 1 и минус с 1, опять же некая скобочка умножить на
[01:07:27.820 --> 01:07:36.100]  собственный вектор, собственно значение оператора мы уже с вами обговариваем, что это такое, это единица
[01:07:36.100 --> 01:07:51.020]  минус 2 и плюс один на лямбда пq, поэтому так и пишем сумма и пq на пq здесь единица минус tau и плюс один
[01:07:51.020 --> 01:08:04.980]  на лямбда пq, лямбда пq собственно значение нашего общего оператора суммарного, лямбда большое, пq, м, и так вот
[01:08:04.980 --> 01:08:15.740]  и отсюда мы можем вынести вот что, что такое, то есть как вычисляется коэффициент фурье c и плюс один
[01:08:16.340 --> 01:08:29.660]  на и плюс первый разумеется и это рации, это у нас будет и и т пq на единицу минус tau лямбда п и плюс один пq
[01:08:29.660 --> 01:08:44.300]  так вот что это будет, то есть это соотношение между коэффициентом и фурье на разных итерациях
[01:08:44.300 --> 01:09:00.500]  на разных итерациях так, чтобы не забыть, друзья, не забудь, я вам литературу давал по всем темам
[01:09:00.500 --> 01:09:08.580]  по этой теме, но на мой взгляд наиболее такая конкретная и понятная литература это учебник
[01:09:08.580 --> 01:09:16.380]  Радио Петровича Федоренко введение в вычислительную физику, именно вот по этой, ну не только по этой, но и в частности по этой
[01:09:16.380 --> 01:09:33.300]  части, по этой части, по стационарным задачам, так, так, ну давайте здесь, так, так, так, ну давайте теперь уберем
[01:09:33.300 --> 01:09:39.860]  вот эти записи, то нам досок не хватает
[01:09:56.260 --> 01:09:59.100]  вот так, так, так, так
[01:09:59.100 --> 01:10:11.940]  ну и вот мы, значит, вычислили это соотношение, теперь мы можем вычислить и ци и пq, как это
[01:10:11.940 --> 01:10:20.740]  будет выглядеть, это будет произведение единица минус tau житых на лямбда
[01:10:20.740 --> 01:10:39.300]  на ци ноль по, на ци ноль как у произведения по, так, по житых от единицы до и, от единицы до и, ну, а зная
[01:10:39.300 --> 01:10:48.140]  коэффициенты Хурье, значит, чрезначальные коэффициенты, соотношение мы можем вычислить и то, что нам
[01:10:48.140 --> 01:11:12.100]  хотелось бы, р и т, то есть погрешность на и т литерации, это у нас будет ци и пq на омега пq мл пq, это будет, так, значит, ци и пq, вот это
[01:11:12.100 --> 01:11:24.420]  все произведение мы честно выписываем, значит, пq и здесь, соответственно, мы все это переписываем, т ноль пq на
[01:11:24.420 --> 01:11:42.060]  произведение единицы минус tau жи лямбда пq на омега пq мл, так, ну, и в нормах, переходим к нормам, чтобы
[01:11:42.060 --> 01:12:10.140]  получить уже конкретные результаты, то есть мы берем тот же погрешность р и т в нормах, нормы р и м, это будет
[01:12:10.140 --> 01:12:19.580]  вносим произведение наше за знак суммы, это будет максимум вот такое произведение единицами
[01:12:19.580 --> 01:12:45.740]  минус tau жи лямбда пq, произведение по жи по знакам модуля и на сумму ци и пq ноль на омега пq мл, ну, что это такое, мы хорошо знаем, это есть норма
[01:12:45.740 --> 01:13:11.500]  р ноль мл, р ноль мл, ну, а что стоит под знаком модуля, произведение, а что это означает это произведение, это полином относительно tau, и вот задача
[01:13:11.500 --> 01:13:41.260]  ставится такая, как нам минимизировать значение максимума вот этого полинома, а вот теперь попробуйте вспомнить, как минимизируется полинома, тяжелый вопрос, или нет, так громче, метод активизация хорошая идея, это правильно, без сомнения, так и есть
[01:13:41.740 --> 01:14:10.700]  но как, но вспомните, что такое, что если представляет полином, наименее уклоняющийся от нуля, помните такой полином, полином, наименее уклоняющийся от нуля, то есть он по некой норме будет наиболее близок к нулю, да, да, это полином Чебашева, что это означает, это означает, что если мы в качестве нулей этого полинового возьмем
[01:14:10.700 --> 01:14:40.620]  нули полинового Чебашева, то мы получим как раз решение той самой задачи на оптимизацию, о которой вы говорили, то есть мы решим задачу, минимум, минимаксовую задачу, и вот этот вот прием дает, вообще говоря, очень-очень большой, большой выигрыш в итерационном процессе, то есть он там практически на порядке,
[01:14:40.700 --> 01:15:10.620]  на порядок уменьшает количество итераций, то есть вот в этой задаче, если я писал в значении 10-4, то там уже для полинового Чебашева, это где-то порядка там, ну где-то на порядок меньше, даже больше, немного больше, на порядок меньше, количество итераций, то есть вот полинового Чебашева в итерационном процессе играет очень-очень большую и очень-очень важную роль, ну вот
[01:15:10.700 --> 01:15:40.700]  вот это у нас в времени, просто этот итерационный, так ну давайте вот попробую еще вам рассказать один метод, который частично вам знаком, ну его называют методом Писана Рэкпорда, поскольку как раз он использует схему переменных направлений, но интересно то, что именно этот метод, это опять Райни Петрович Федоренко, ну молодец конечно, нашел
[01:15:40.700 --> 01:16:10.220]  где-то в журнале записки Санкт-Петербургского университета где-то начала прошлого века или даже конца позапрошлого статью очень известного математика ученика Чебышева Золотарева, который к сожалению очень-очень рано погиб, вот оказалось, что вот Золотарев еще в конце позапрошлого века предложил этот метод, то есть не имея ни компьютерных мощностей, ничего, ничего,
[01:16:10.220 --> 01:16:40.220]  вот то есть праздник назвать методом Золотарева, вот у него есть свои полиномы Золотарева и так далее, которые тоже используются в итерационных процессах, ну вот давайте я это скажу, ну вот сначала скажу такую вещь, которая на самом деле на пасах хорошо понятна, хотя формально она доказывается, ну представьте себе, что вы решаете задачу
[01:16:40.220 --> 01:17:03.220]  нестационарную, ну например, уровень антипопроводности двумерной, нестационарную, но ставите стационарные граничные условия, что вы получите, решение какой задачи, в конечном итоге при устремлении времени к бесконечности, например,
[01:17:04.220 --> 01:17:26.220]  у вас есть уравнение параболического типа нестационарное, ну мы недавно с вами ими занимались, да, нестационарное уровень антипопроводности, ну например, одномерное или двумерное, а краевое шлое вы ставите стационарное, что вы в конечном итоге получите, решение какой задачи,
[01:17:27.220 --> 01:17:42.220]  стационарное, конечно, да, интуитивное, это просто и понятно, да, ну хотя это надо доказывать, и это доказывается, не сложно, этот метод называется методом установления, а вот та у шага по времени называется в этом случае итерационным параметром,
[01:17:42.220 --> 01:18:01.220]  и таким образом получается итерационный процесс, который называется методом установления, итерационный метод установления, опять же мы на этот раз имеем вот такое уравнение параболического типа,
[01:18:01.220 --> 01:18:23.220]  и вспомните продольно-поперечный метод, как он выглядит, следующим образом выглядит, только вместо временного индекса здесь стоя, я ставлю индекс итерационный, то есть вместо времени у меня будет, вместо шага по времени у меня будет итерационный индекс,
[01:18:23.220 --> 01:18:44.220]  и это будет лямбда х х, ну и плюс одна вторая, мл плюс лямбда y y и мл, так это значит у нас предиктор, так только здесь одна вторая,
[01:18:44.220 --> 01:19:06.220]  предиктор, как раз предиктор продольно-поперечного метода, и продольно-поперечная схема, и корректор у и плюс один, мл минус у и плюс одна вторая, мл е на тал, это будет лямбда х х у и плюс одна вторая,
[01:19:06.220 --> 01:19:23.220]  мл плюс лямбда y y на у и плюс один, мл, вот предиктор, то есть первый этап, и корректор, и корректор, первый этап.
[01:19:23.220 --> 01:19:45.220]  Так, опять же, из этих двух уравнений я вычитаю очевидное точество. Точество, которое мы писали, у м л минус у м л на тал равняется лямбда х х у м л плюс лямбда y y у м л.
[01:19:45.220 --> 01:20:04.220]  Ну и с первого и с второго, ну давайте напишем для первого, например, чтобы для погрешности, в первом случае, то есть предиктор, мы получим р и плюс одна вторая м л минус р и м л е на тал.
[01:20:04.220 --> 01:20:25.220]  Здесь лямбда х х у и плюс одна вторая м л плюс лямбда y y на у и м л. Ну и такое же выражение получим и подобное выражение для второго уравнения, то есть для корректора.
[01:20:25.220 --> 01:20:42.220]  Ну я не пишу, оно похоже. Давайте я вот это уравнение перепишу в операторном виде. Это будет у нас е минус тал лямбда х х на р и плюс одна вторая м л.
[01:20:42.220 --> 01:20:57.220]  А здесь равняется е плюс тал лямбда y y на у и м л.
[01:20:57.220 --> 01:21:22.220]  Теперь, значит, опять же, р, вот эти погрешности, я разлагаю частичный ряд в курье и проделываю точно те же операции, что и раньше. То есть вношу знаки оператора под знаки суммы и проделываю все те же операции.
[01:21:22.220 --> 01:21:37.220]  В конечном итоге я получу. Я уже только конечный итог надеюсь, что тал оптимальный. Вот этот шаг, это на самом деле не шаг по времени, а итерационный параметр.
[01:21:37.220 --> 01:21:49.220]  Это будет делиться, делить на корень из l малая на l большой. То есть довести задачу вы можете своими силами до конца.
[01:21:49.220 --> 01:22:04.220]  Там тоже будет точно такая же минимаксовая задача, о которой мы говорили. Из нее мы получаем вот этот шаг. Что интересно, что вот этот метод также позволяет ускорить итерационный процесс.
[01:22:04.220 --> 01:22:18.220]  Так сейчас посмотрите, как у нас немного времени осталось, я его вот нашел, потрачу. Я вам дам табличку итерационных процессов.
[01:22:18.220 --> 01:22:30.220]  Итерационных процессов. Метод и количество итераций.
[01:22:30.220 --> 01:22:37.220]  Метод якобы первый. Метод якобы.
[01:22:37.220 --> 01:22:49.220]  И приблизительно 2m квадрат на pi квадрат, логарифм f в минус первой степени плюс один.
[01:22:49.220 --> 01:22:56.220]  То есть здесь количество итераций просто надо m квадрат.
[01:22:57.220 --> 01:23:03.220]  Второй метод зайдали. Ну правильно, гаусса зайдали.
[01:23:03.220 --> 01:23:14.220]  Количество итераций здесь m квадрат на pi квадрат, так на логарифм.
[01:23:14.220 --> 01:23:24.220]  Эпсилум минус первая и плюс единичка. Эпсилум, как вы помните, это точность m, это количество разбиений.
[01:23:24.220 --> 01:23:31.220]  Метод верхней ревоксации.
[01:23:31.220 --> 01:23:45.220]  И это приблизительно 2m на pi квадрат на логарифм f в минус один плюс единица.
[01:23:45.220 --> 01:24:05.220]  Дальше метод итерации с Чебушевским набором итерационных параметров.
[01:24:05.220 --> 01:24:13.220]  Это у нас какой? Четвертый. Чебушевские итерационные параметы.
[01:24:13.220 --> 01:24:24.220]  И приблизительно m большой делим на пи на логарифм. Эпсилум минус один и плюс единичка.
[01:24:24.220 --> 01:24:41.220]  Далее метод итерации, метод переменных направлений, о котором мы только что говорили, с оптимальным итерационным параметром.
[01:24:41.220 --> 01:24:55.220]  Это примерно 1 вторая м на пи. Все уменьшаем количество итераций. Эпсилум минус первая и плюс один.
[01:24:55.220 --> 01:25:02.220]  Ну и чего я не договорил, но это довольно долгая история.
[01:25:02.220 --> 01:25:10.220]  Это в последнем методе вместо одного итерационного параметра нужно взять набор Чебушевских итерационных параметров.
[01:25:10.220 --> 01:25:14.220]  И вот там получается совершенно удивительный результат.
[01:25:14.220 --> 01:25:22.220]  В нем получается, что количество итераций пропорционально не m квадрат, а пропорционально логарифму m.
[01:25:22.220 --> 01:25:26.220]  Это, конечно, совершенно блестящий результат.
[01:25:26.220 --> 01:25:30.220]  Вот его как раз получил Золотарев, ученище большого.
[01:25:33.220 --> 01:25:35.220]  Вопросы?
