[00:00.000 --> 00:10.380]  Чем мы с вами занимались? Так, это у нас третья лекция. Мы с вами в прошлый раз занимались формулой
[00:10.380 --> 00:18.600]  метеоровероятности. Первое, что мы с вами забрали эту форму, это условная вероятность.
[00:18.600 --> 00:32.480]  Условная вероятность события А при условии события В. В случае, если событие В не нулевой
[00:32.480 --> 00:41.760]  вероятности, оно определяется как частная вероятность пересечения события А и В и вероятности
[00:41.760 --> 00:47.120]  условий. Тогда же мы с вами поговорили о том, что на самом деле это есть некоторые проблемы в
[00:47.120 --> 01:01.560]  этом определении, потому что если у нас событие В нулевой вероятности, тогда интуитивно понятно,
[01:01.560 --> 01:08.320]  что вот этот объект, но так его определить мы не можем. Примеры я приводил. Вы научитесь строить
[01:08.320 --> 01:14.640]  условную вероятность ситуации, когда вероятность условия будет нулевая, но это будет где-то в
[01:14.640 --> 01:19.880]  середине курса математической статистики. То есть даже в курсе тервера это сделать пока не будете уметь.
[01:19.880 --> 01:31.960]  Второе, что мы с вами разобрали, это формула полной вероятности. Работает она в ситуации,
[01:31.960 --> 01:41.480]  если у вас есть разбиение, причем неважно конечное или бесконечное разбиение Омега.
[01:41.480 --> 01:51.880]  Мы с вами обсуждали такое разбиение Омега, это набор непересекающихся событий БКТ, то есть все они
[01:51.880 --> 02:03.280]  должны быть элементами Ф. Причем такие, что тогда для любого события А верно следующую форму.
[02:03.280 --> 02:11.480]  Вероятность события А можно расписать как сумму, ну в зависимости от того наше разбиение конечное
[02:11.480 --> 02:17.760]  или бесконечное, таких произведений. Условных вероятностей А по условии БКТ и на вероятность БКТ.
[02:17.760 --> 02:27.920]  Пример этой формулы мы с вами не успели разобрать, давайте быстро его разберем. Есть такое народное
[02:27.920 --> 02:35.480]  творчество, что если у нас с вами есть, ну предположим, три студента, которых, ну то есть есть
[02:35.480 --> 02:42.480]  преподаватели, которые только этих трех студентов выспрашивают на семинарах. Условных назовем умный,
[02:42.480 --> 02:55.720]  веселый, с большой буквы, без уважения, ну и старост. Но имя старости преподаватель всегда
[02:55.720 --> 03:08.200]  знает, поэтому проще вызывать старость. Ну вот, и что такое БКТ? То есть это кого вызовет семинарист?
[03:08.200 --> 03:18.800]  Ну предположим, что семинарист хороший, то есть он старается научить людей, поэтому веселого он.
[03:18.800 --> 03:26.000]  Давайте у нас первый будет умный, второй веселый, а третий старост. То есть вероятность того,
[03:26.000 --> 03:33.720]  что он вызывает веселого, ну веселые они всегда не очень умные, ну вот, поэтому давайте вот его
[03:33.720 --> 03:40.880]  он вызывает с вероятностью одна вторая, умную он вызывает с вероятностью одна шестая, ну это когда
[03:40.880 --> 03:46.600]  совсем сложная задача, надо, чтобы ее все-таки человек пришел. Ну вот, ну а старосту во всех
[03:46.600 --> 03:52.640]  оставшихся ситуациях это вроде одна треть. Там получается единицы, да? Ну понятно, что БКТ всегда
[03:52.640 --> 03:58.080]  сумма их вероятности равна единице, потому что они в объединении дают всю ОМЕГ. Что тогда такое
[03:58.080 --> 04:04.480]  условная вероятность А при условии БКТ? То есть это вероятность того А. Какое нас интересует
[04:04.480 --> 04:13.960]  событие А? Ответ был дан. То есть какой-то там вопрос преподаватель задает, нас интересует,
[04:13.960 --> 04:22.360]  как бы он получил ответ на свой вопрос правильно, естественно, или нет. Что такое А при условии БКТ?
[04:22.360 --> 04:30.000]  Какова вероятность того, что ответ будет дан, если отвечает умный? Какая тут вероятность у нас?
[04:30.000 --> 04:41.920]  Ну обычно. Как смешно. Единицы. Ну мы считаем то, что как бы у нас же математическая модель,
[04:41.920 --> 04:52.640]  идеальные истории. Поэтому мы считаем то, что умный всегда отвечает на вопрос. Весело отвечает
[04:52.640 --> 05:12.080]  на них редко. Вот сейчас у нас идеальная модель же, да? Ну вот. Старосты... Ну ладно, ладно, так хорошо.
[05:12.080 --> 05:17.960]  Не, ну старосты, эти люди ответственны и никак не связаны с учебой. То есть его преподаватель часто
[05:17.960 --> 05:22.320]  вызывает просто потому, что знает, как зовут человека, поэтому чтобы не было неловко, то вызывают
[05:22.320 --> 05:28.480]  его. Ну и погнали. Считать вероятность события А по этой формуле. Я не буду формулу расписывать,
[05:28.480 --> 05:36.720]  да, вот именно буквенно. То есть получается у нас сумма из трёх слагаемых, где вероятности условий
[05:36.720 --> 05:42.520]  домножаются на условную вероятность. То есть у нас Б1 это что такое? 1 шестая умножить на 1,
[05:42.520 --> 05:51.880]  но это редко происходит. Дальше Б2, 1 вторая на 1 десятую. И Б3 у нас получается 1 треть на 1 треть.
[05:51.880 --> 06:01.080]  Так, ну сейчас самое сложное, надо это сложить, господи боже мой. Это 1 шестая, плюс 1 двадцатая,
[06:01.080 --> 06:09.280]  плюс 1 девятая. Лучше я не смог подобрать чисел, я прошу за это прощение. Вот, ну по-моему,
[06:09.280 --> 06:20.000]  всё плохо, да? Нет, ну давайте досчитаем всё-таки. Это тяжело. То есть у нас что будет 2 тройки,
[06:20.000 --> 06:31.680]  2 двойки, да, господи, 1 пятёрка. 180. Ну 2 тройки, 2 двойки, 1 пятёрка, да, 180.
[06:31.680 --> 06:40.160]  Здесь мы умножаем на сколько? На 30, да, тут мы умножаем на 9, да, а тут на 20. Так, и сумма у
[06:40.160 --> 06:50.720]  нас получается 59, 180. Ну то есть это почти, ну поскольку 59 это почти 60, да, то есть это почти 1 треть.
[06:50.720 --> 07:00.880]  Могли ли мы ожидать такое? То есть смотрите, умный отвечает всегда, но вызывает его редко. Конечно,
[07:00.880 --> 07:13.760]  я тут нехорошо сделал. Умный отвечает всегда, но вызывает его редко. Весёлый, его вызывают в
[07:13.760 --> 07:18.640]  половине случаев, отвечает он вообще крайне редко. Ну вот, ну здесь у нас соответственно по 1 треть.
[07:18.640 --> 07:25.960]  То есть ответ, то что он будет близок 1 треть, можно было предугадать именно, потому что вот здесь
[07:25.960 --> 07:31.960]  у нас эта единичка занижается за счёт 1 шестой, а здесь и 1 десятая, она сильно влияет за счёт вот
[07:31.960 --> 07:47.280]  этой 1 второй. Ну и получилась в итоге 1 треть. История ясна? Ну мы же всегда чем-то пренебрегаем,
[07:47.280 --> 08:02.640]  когда... Ну слушай, ну преподаватель старенький может быть. Так, погнали дальше. Следующая,
[08:02.640 --> 08:16.760]  третья формула, формула Байс. Это так называемая формула на нахождение пастериозной вероятности,
[08:17.160 --> 08:21.720]  пожалуйста, поднимите руки, кто различает вот эти два понятия, философских, априорные и
[08:21.720 --> 08:30.280]  пастериозные. Это философские термины, ну вот вы с ними пересечётесь, ну получается там на четвёртом
[08:30.280 --> 08:38.840]  курсе, но вообще на самом деле надо знать, это как-то неприлично. То есть это вещи такие известные. Это
[08:38.840 --> 08:44.280]  латинские термины, соответственно априори это доопытные, ну как бы дословно по-латыни это
[08:44.280 --> 08:49.440]  доопыта, а пастериорные это послеопыта. Соответственно знания подразумевается априорные,
[08:49.440 --> 08:54.200]  те которые вложены в вас, а пастериорные это те которые получены вследствие опыта.
[08:54.200 --> 09:00.040]  Соответственно там философии, там постоянные шли, раньше что сейчас там происходит я не знаю,
[09:00.040 --> 09:04.280]  но когда нам преподавали философию, я поступал в госпитальнатуру, мне надо было её выучить,
[09:04.280 --> 09:09.960]  так что я в этом разбирался, они всё время спорили о том, что какие знания у нас априорные,
[09:10.920 --> 09:21.280]  и вообще существует ли априорные знания изначально. Это тоже вот наподумать потом,
[09:21.280 --> 09:29.280]  если вы будете в электричке ехать, делать будет нечего. Когда Ньютон, там непонятно Ньютон или
[09:29.280 --> 09:32.800]  Лейбенис, в выпуске Ньютона они соответственно дифференциальные и интегральные исчисления
[09:32.800 --> 09:38.960]  как бы написали, никто не понял вообще, что было сделано. Потом постепенно, постепенно, поскольку
[09:38.960 --> 09:45.600]  это всё применялось активно, человечество начало постигать всё то, что было сделано. Иронично,
[09:45.600 --> 09:51.000]  что сейчас для вас вообще вопрос интегрального и дифференциального исчисления это какая-то
[09:51.000 --> 09:58.120]  банальность, согласитесь, покивайте. Боже мой, вы это делали в 10-м, кто-то в 10-м, кто-то в 11-м
[09:58.120 --> 10:05.920]  классе, в зависимости от той программы, по которой вы учились. Это что вопрос о том, что люди раньше
[10:05.920 --> 10:10.640]  были тупее, если они с таким трудом понимали то, что сделан Ньютон. Ну, предположим, там,
[10:10.640 --> 10:17.320]  сколько-то лет после того, как были опубликованы работы. Казалось бы, нет, да, но то есть многие даже
[10:17.320 --> 10:24.440]  считают из старшего поколения то, что раньше дети были умнее. Иронично, я сейчас пришёл с
[10:24.440 --> 10:30.880]  предпосветом, мы как раз именно это обсуждали, да, со старшеками, да, то, что студенты пошли не те.
[10:30.880 --> 10:39.240]  Но с другой стороны, ведь очевидно то, что вы воспринимаете эти сложные действительно вещи куда
[10:39.240 --> 10:46.040]  легче, чем поколение до этого. Почему это так происходит? Ну вот именно потому, что как бы у вас
[10:46.040 --> 10:52.760]  на генетическом уровне вот это вот закладывается. Ну то есть есть какие-то апостериорные знания,
[10:52.760 --> 10:59.400]  которые ну постепенно выкапываются, да. Ну вот, я честно не шарю в этой теме, вот вот честно,
[10:59.440 --> 11:06.120]  вот я тогда философию прошёл, но просто вот эта тема с апостериорным знанием, она очень,
[11:06.120 --> 11:10.000]  с апостериорным, извините, с апостериорным знанием, потому что с апостериорным всё понятно,
[11:10.000 --> 11:17.840]  чего, у вас был опыт, вы не знали, вы узнали, вообще неинтересно. А априорное знание, пишется там,
[11:17.840 --> 11:30.760]  идёт априори, там по-моему как слышится, так и пишется, априори и апостериори. Я вот не помню
[11:30.760 --> 11:39.560]  окончания какие, но это латынь, поэтому кто-нибудь посмотрите, пожалуйста. Ну вот, то есть это после
[11:39.560 --> 11:51.040]  опыта, это до опыта. И соответственно, одна из обязательных частей любого курса философии — это
[11:51.040 --> 11:57.960]  критика чистого разума Канта, ну слышали такой мануэл Канта, ну слышали, ну вот. Там вот тоже
[11:57.960 --> 12:04.520]  вот рассуждения идут о том, что какие знания в нас заложены, то есть представление о пространстве
[12:04.520 --> 12:09.680]  и времени, они тоже. Вот ребёнок рождается, новорождённый, вот пространство и время,
[12:09.680 --> 12:14.560]  оно в него заложено, представление о том, как это всё происходит, или оно тоже постепенно у него
[12:14.560 --> 12:21.160]  складывается в процессе роста. На философии всё пройдёте, я не специалист. Хорошо,
[12:21.160 --> 12:29.920]  почему я сейчас вот это, почему апостериорное знание? Вернёмся вот к той истории. Предположим,
[12:29.920 --> 12:36.240]  вопрос в том, что преподаватель ну совсем старенький, он не отметил, кто отвечал. И у него
[12:36.240 --> 12:40.920]  просто напротив задач стоит плюсик и минусик, но эту задачу справились, разобрали, здесь не
[12:40.920 --> 12:45.960]  справились, не разобрали, ну и так далее. И вы задаёте следующим вопросом, а какова вероятность
[12:45.960 --> 12:55.120]  того, что с учётом того, что как бы задача была решена, её рассказывал, ну давайте старость.
[12:55.120 --> 13:04.640]  То есть ещё раз, случайность осталась из-за чего? Из-за того, что вы не знаете в точности результат
[13:04.640 --> 13:08.720]  эксперимента, да, то есть как бы вы знаете, только бывает или не бывает решена задача,
[13:08.720 --> 13:14.960]  но какие-то тонкости от вас ушли, ну как в покеры, помните я объяснял, да, то есть как бы вы часть кар
[13:14.960 --> 13:20.160]  знаете, а что там закрыто и не знаете. Здесь тоже самое, вы знаете результат, кончательный такой
[13:20.160 --> 13:25.200]  результат эксперимента, но как вы к нему пришли неизвестно. Это понятно? Понятно, почему называется
[13:25.200 --> 13:32.200]  опространение. И вопрос, как искать вот такие вероятности, если нам известны, но те же вещи,
[13:32.200 --> 13:40.960]  которые были объявлены до этого. Доказательство формулы короче, чем её формулировка, поэтому я
[13:40.960 --> 13:47.600]  буду формулировать и доказывать сразу, хорошо? Это условная вероятность, ну условная вероятность,
[13:47.720 --> 13:55.840]  пока про неё немного знаем, поэтому пишем просто по определению. То есть это вероятность pour
[13:55.840 --> 14:01.640]  сечение делить на вероятность условия. Соответственно, здесь у нас есть ещё
[14:01.640 --> 14:05.240]  замечание, что вероятность А больше нуля, но всегда, когда мы пишем условный вероятность,
[14:05.240 --> 14:11.140]  сейчас у нас вероятность условия всегда положительна. Так, вероятность пересечение в
[14:11.140 --> 14:16.880]  точке того, что мы знаем, только вы inflict условия и условные вероятности, вероятность
[14:16.880 --> 14:22.560]  мы можем расписать как произведение вероятности
[14:22.560 --> 14:27.760]  условия на условную вероятность.
[14:27.760 --> 14:28.760]  Это есть?
[14:28.760 --> 14:29.760]  Хорошо.
[14:29.760 --> 14:34.640]  Вероятные события мы можем расписать по форму ли полной
[14:34.640 --> 14:35.640]  вероятности.
[14:35.640 --> 14:38.000]  То есть это сумма PoCat единички, ну там либо до n, либо до
[14:38.000 --> 14:43.480]  бесконечности вероятности А при условии BeCat на вероятности
[14:43.480 --> 14:44.480]  BeCat.
[14:44.480 --> 14:53.800]  Ну то есть если вот мы возьмем наш пример, какова вероятность
[14:53.800 --> 14:56.480]  того, что вызвали старость, если ответ на вопрос все-таки
[14:56.480 --> 14:57.480]  был дан.
[14:57.480 --> 14:59.720]  Ну погнали считать.
[14:59.720 --> 15:06.680]  Так, примеры тот же самый, B3 при условии A, что у нас
[15:06.680 --> 15:14.080]  получается в числителе 1 3 1 3, знаменатели 1 3 1, а
[15:14.080 --> 15:30.080]  если 1 3, нет 59, 180, извините, что у нас получилось, 20, 59,
[15:30.080 --> 15:32.280]  да?
[15:32.280 --> 15:33.280]  Есть да?
[15:33.280 --> 15:34.280]  Вору, не вору?
[15:34.280 --> 15:35.280]  Вроде не вору.
[15:35.280 --> 15:42.320]  Ну то есть примерно 1 3 вышло, история ясна, какие-то
[15:42.320 --> 15:44.920]  комментарии будут по поводу эту?
[15:44.920 --> 15:49.520]  Ну вот у меня, когда я как бы слушал курс тезуеды,
[15:49.520 --> 15:51.200]  у меня были комментарии по поводу эту формулу.
[15:51.200 --> 15:59.720]  Значение похоже, потому что я вместо того, чтобы
[15:59.720 --> 16:01.920]  сесть и подобрать хорошие коэффициенты, выдумываю
[16:01.920 --> 16:04.240]  их на ходу, смотря на разных старост.
[16:04.240 --> 16:09.360]  И плохие получились, ну плохое сочетание чисел
[16:09.360 --> 16:11.360]  не видно, ну плохо.
[16:11.400 --> 16:15.680]  Ну давайте сделаем попроще, как вы думаете, какова будет
[16:15.680 --> 16:20.760]  вероятность того, что вызвали, ну кого, веселого, давайте
[16:20.760 --> 16:23.640]  возьмем этого, умного, лучше умного, какова вероятность
[16:23.640 --> 16:26.720]  того, что вызвали умные, если ответ был дан?
[16:26.720 --> 16:31.720]  Эта вероятность должна быть какая, большая, маленькая?
[16:31.720 --> 16:32.720]  Давайте посчитаем.
[16:32.720 --> 16:40.840]  Ну ответ же был дан.
[16:41.320 --> 16:45.240]  Веселые ответы практически не дают, а старости их дают
[16:45.240 --> 16:46.240]  редко.
[16:46.240 --> 16:49.720]  То есть кажется, что вероятность все-таки должна быть велика,
[16:49.720 --> 16:52.840]  ведь у нас условная, потому что ответ был дан.
[16:52.840 --> 16:56.280]  Давайте просто найдем честно, то есть здесь у нас получается,
[16:56.280 --> 17:01.640]  что вероятность, то есть 1 шестая на 1, а тут у нас,
[17:01.640 --> 17:07.240]  ну по-прежнему наша почти 1 треть, 59, 180.
[17:07.640 --> 17:11.640]  Если мы 180 закинем наверх, у нас там что получается?
[17:11.640 --> 17:14.640]  Мы на 6 делим, 30, да?
[17:14.640 --> 17:17.640]  30, 59, почти 1 вторая.
[17:17.640 --> 17:20.640]  То есть если ответ был дан, вероятность того, что его
[17:20.640 --> 17:26.240]  дал умный, 1 вторая, хотя его вызывают крайне редко.
[17:26.240 --> 17:27.240]  Почему 1 вторая?
[17:27.240 --> 17:30.280]  Потому что старости редко отвечают, а веселого практически
[17:30.280 --> 17:31.280]  не отвечают.
[17:31.280 --> 17:35.720]  Да, это бывает, но редко.
[17:36.200 --> 17:39.200]  Есть ли еще какие-то замечания по поводу вот этого?
[17:45.200 --> 17:48.200]  Ну мы же идеализируем модель, когда строим.
[17:48.200 --> 17:53.200]  Еще раз смотрите, мы живем в рамках какой-то идеальной
[17:53.200 --> 17:54.200]  модели.
[17:54.200 --> 17:56.680]  Когда вы будете решать задачки на подбрасывание
[17:56.680 --> 17:59.160]  монеток, у вас не будет элементарных исходов в соответствующей
[17:59.160 --> 18:01.600]  ситуации, то что монетка застряла между половицами
[18:01.600 --> 18:05.360]  паркета на полу, потому что это бывает редко.
[18:05.360 --> 18:09.480]  Иногда вы идеализируете модель, потому что вы посчитать
[18:09.480 --> 18:11.480]  иначе не можете.
[18:11.480 --> 18:14.520]  У меня было, мы же как, у нас на Мехмате, так же как
[18:14.520 --> 18:17.200]  и у вас, мы распределяемся по кафетам после второго
[18:17.200 --> 18:19.840]  курса, и я сначала пошел к мужику, который занимается
[18:19.840 --> 18:22.200]  провожением теории вероятности в химии-биологии.
[18:22.200 --> 18:25.200]  А у моих родителей доктора химических наук, я думаю,
[18:25.200 --> 18:27.480]  ха, у меня такие консультанты шикарные.
[18:27.480 --> 18:31.200]  И дальше была беда, он мне говорит, что скорость реакции
[18:31.200 --> 18:33.040]  пропорциональна концентрации.
[18:33.040 --> 18:35.160]  Я говорю, это не так.
[18:35.160 --> 18:39.320]  Ну то есть, как бы, часто это так, но есть куча реакций,
[18:39.320 --> 18:40.320]  в которых это не так.
[18:40.320 --> 18:43.640]  Он говорит, забей, потому что мы работаем с математической
[18:43.640 --> 18:45.600]  моделью, которая там ля-ля-ля-ля-ля-ля-ля.
[18:45.600 --> 18:50.040]  Ну вот, я тогда, будучи третий курсник, вообще не понял,
[18:50.040 --> 18:51.040]  что мне говорят.
[18:51.040 --> 18:53.680]  Ну потому что у нас тервер начинался с того, что вот
[18:53.680 --> 18:57.040]  вам как бы Омега ФП, и пошли, погнали математикой.
[18:57.040 --> 18:58.600]  Это была чисто математическая дисциплина.
[18:58.600 --> 19:05.000]  И вот эта связка между экспериментом и мат-моделью, у нас она
[19:05.000 --> 19:06.800]  не прострадалась, но потому что она нам в принципе не
[19:06.800 --> 19:08.800]  нужна, мы математики.
[19:08.800 --> 19:11.360]  Я вам толкал речь о том, что вы обделенные, ну в смысле
[19:11.360 --> 19:12.360]  не вы, а помышленники.
[19:12.360 --> 19:13.360]  Это правда.
[19:13.360 --> 19:16.360]  Ну то есть, я даже тогда не понял, кстати, я как бы
[19:16.360 --> 19:20.680]  ушел, занялся, я как бы сменил после третьего курса и диплом
[19:20.680 --> 19:22.600]  писал у другого научного руководителя.
[19:22.600 --> 19:23.600]  Я не смог.
[19:23.600 --> 19:25.840]  Теперь я понимаю, потому что, то есть, это как бы не
[19:25.840 --> 19:27.080]  он не молодец, а я не молодец.
[19:27.080 --> 19:34.320]  Вот, это в тему мат-моделей еще раз сказали.
[19:34.440 --> 19:36.560]  Еще есть какие-то замечания по поводу этого?
[19:36.560 --> 19:37.880]  На самом деле есть.
[19:37.880 --> 19:40.440]  У вас нет ощущения, что что-то фигня какая-то?
[19:40.440 --> 19:44.760]  Вот у меня на самом деле, то есть, нам рассказали эту
[19:44.760 --> 19:49.280]  форуму Байлса, окей, доказали, решили пару задач, доказали
[19:49.280 --> 19:50.280]  на экзамене.
[19:50.280 --> 19:51.880]  После этого я с ней не пересекался вообще никогда.
[19:51.880 --> 19:56.000]  То есть, я же потом кандидатский минимум сдавал, диссертацию
[19:56.000 --> 19:57.400]  писал, защищал и так далее.
[19:57.400 --> 19:59.320]  И ни разу не пересекался с форуму Байлса.
[19:59.320 --> 20:01.520]  Хотя все остальные вещи, которые мы с вами будем
[20:01.520 --> 20:04.040]  проходить, они очень прикладные, они вылезают везде и всюду.
[20:04.040 --> 20:09.400]  Потом я о ней вспомнил, только когда начал вести семинары
[20:09.400 --> 20:11.600]  на Мехмате, потом здесь читать лекции и так далее.
[20:11.600 --> 20:17.200]  Плюс в математической статистике есть такой Байлсовский
[20:17.200 --> 20:20.640]  подход к оценению, вы будете его проходить, и он в середине
[20:20.640 --> 20:26.360]  прошлого века, по-моему там 60-е, 70-е годы, там аккуратно
[20:27.360 --> 20:32.880]  описали этот способ построения оценок, все, ура, и сказали
[20:32.880 --> 20:37.000]  эти оценки, Найфки никому не нужны, потому что у нас
[20:37.000 --> 20:39.040]  есть оценки, которые строятся методом максимального
[20:39.040 --> 20:43.080]  предподобия, там наименьшее дисперсии, эти оценки
[20:43.080 --> 20:44.080]  бесполезные.
[20:44.080 --> 20:47.760]  Ну, в принципе, построили, люди диссертации защитили,
[20:47.760 --> 20:50.680]  все хорошо, живем дальше, так в науке часто бывает.
[20:50.680 --> 20:53.160]  То есть, проработали какую-то тему, там люди диссертации
[20:53.160 --> 20:57.280]  защитили, там сели на должность профессора, и дальше спокойно
[20:57.280 --> 20:58.280]  живут.
[20:58.280 --> 21:01.080]  А потом, что оказалось, когда начался весь этот
[21:01.080 --> 21:03.040]  бум с машинным обучением, оказалось, что вот этот
[21:03.040 --> 21:07.720]  Байлсовский подход к оцениванию, в машинном обучении вероятностные
[21:07.720 --> 21:10.480]  подходы, они там, на них все зиждется, и оказались
[21:10.480 --> 21:13.880]  то, что эти Байлсовские методы вообще безумно применимы.
[21:13.880 --> 21:17.440]  Я в силу своей убогости не знаю, как применимы.
[21:17.440 --> 21:19.920]  Ну, то есть, как бы я в машинке не шарю, вообще никак.
[21:19.920 --> 21:26.680]  Ну, это все идет отсюда, то есть, чтобы вы прониклись
[21:26.680 --> 21:30.160]  вот этой историей, то есть, потом вы с ней пересечетесь,
[21:30.160 --> 21:32.040]  на мат-статистике у вас будет Байлсовский подход
[21:32.040 --> 21:34.080]  к оцениванию, там вообще шаманство полнейшее.
[21:34.080 --> 21:38.720]  Вот реально, там у вас, как бы, вы подбираете распределение
[21:38.720 --> 21:42.880]  параметра, чтобы там что-то с оценкой было, ну, то есть,
[21:42.880 --> 21:45.800]  шаманство полное, а потом это вылезает в машинке,
[21:45.800 --> 21:47.920]  ну, вот, знаешь, и люди даже знают.
[21:47.920 --> 21:50.560]  Просто запомните, как бы, то, что вот это вот, потом
[21:50.560 --> 21:52.720]  будет вылезать отовсюду, хотя сейчас это кажется
[21:52.720 --> 21:53.720]  какой-то фигней.
[21:53.720 --> 21:55.720]  История ясна?
[21:55.720 --> 21:56.720]  Запомните.
[21:56.720 --> 21:59.680]  И четвертая, это формула умножения вероятности,
[21:59.680 --> 22:00.680]  которую мы сегодня разберем.
[22:00.680 --> 22:14.960]  Форма умножения вероятности.
[22:14.960 --> 22:15.960]  Сразу начнем с задачки.
[22:15.960 --> 22:27.080]  Так, нам нужен мышка какая-нибудь, ну, в смысле, таком будем
[22:27.080 --> 22:28.920]  экспериментировать.
[22:28.920 --> 22:30.400]  Давайте на вас, хорошо.
[22:30.400 --> 22:31.760]  Берем простую задачку.
[22:31.760 --> 22:36.720]  У нас есть уровня, в которой у нас есть сколько белых
[22:36.720 --> 22:37.720]  и сколько красных шаров.
[22:37.720 --> 22:46.400]  Семь белых и, хотите, семь, ну, черт тогда, я сегодня
[22:46.400 --> 22:49.640]  не попадаю ни в числа, ни в людей, в суть, ну ладно.
[22:49.640 --> 22:52.160]  Так, семь белых и семь красных.
[22:52.160 --> 22:54.920]  И мы вытаскиваем три штуки.
[22:54.920 --> 22:57.560]  Издается вопрос о том, какова вероятность вытащить
[22:57.560 --> 22:59.600]  такую последовательность шаров.
[22:59.600 --> 23:07.640]  Белый, вслед за ним красный, вслед за ним белый.
[23:07.640 --> 23:18.480]  Дальше, как говорил профессор Терелони из Гарри Путера,
[23:18.480 --> 23:22.080]  освободите свой разум и скажите, какой будет ответ.
[23:22.080 --> 23:23.800]  Ну, то есть, что мне нужно сделать, чтобы посчитать
[23:23.800 --> 23:24.800]  вот эту вероятность.
[23:24.800 --> 23:29.320]  Давайте все-таки не семь, давайте вот здесь девять.
[23:29.320 --> 23:32.320]  Ну, просто то, что было.
[23:33.320 --> 23:38.320]  Да, извини, пожалуйста, без возвращения, то есть,
[23:38.320 --> 23:40.840]  мы последовательно вынули, положили и вот нам нужно
[23:40.840 --> 23:42.320]  получить последовательность трех шариков.
[23:42.320 --> 23:48.160]  А можно диктовать числа?
[23:48.160 --> 23:58.600]  Ну, я свожу, ладно.
[23:58.600 --> 24:14.080]  Ну вот, поднимите, пожалуйста, руки те, кто сказал бы то
[24:14.080 --> 24:15.960]  же самое, что сказал докладчик.
[24:15.960 --> 24:18.800]  Ну, если бы я вот выбрал не его, а вас, то есть, практически
[24:18.800 --> 24:19.800]  все.
[24:19.800 --> 24:21.800]  А теперь мы пытаемся понять, почему это вообще правда.
[24:21.800 --> 24:23.240]  То есть, мы умножаем вероятность.
[24:23.240 --> 24:24.240]  А почему мы, кстати, умножаем?
[24:24.240 --> 24:27.240]  А как вас зовут?
[24:27.880 --> 24:28.880]  Гера.
[24:28.880 --> 24:29.880]  Гера.
[24:29.880 --> 24:30.880]  Гера.
[24:30.880 --> 24:31.880]  Почему мы умножаем?
[24:31.880 --> 24:37.960]  Потому что способ выбрать второй шар не зависит от
[24:37.960 --> 24:41.960]  самого, как он от первой.
[24:41.960 --> 24:42.960]  Это верно?
[24:42.960 --> 24:47.680]  Это, кстати, вот это говорят практически все.
[24:47.680 --> 24:49.080]  Ну, я короче скажу.
[24:49.080 --> 24:50.560]  Ну, это же независимая вещь.
[24:50.560 --> 24:51.560]  Почему умножаем вероятность?
[24:51.560 --> 24:54.680]  Мы независимость еще не брали, но все же знают то, что
[24:55.120 --> 24:58.240]  если событие независимое, мы вероятности умножаем.
[24:58.240 --> 24:59.240]  Ну, вы это знаете.
[24:59.240 --> 25:02.080]  Я думаю, в школе, курсе, террере, все проходили.
[25:02.080 --> 25:05.080]  Все проходили в школе, курсе, террере.
[25:05.080 --> 25:09.080]  Приду в голосу прямо, да?
[25:09.080 --> 25:10.080]  Хорошо.
[25:10.080 --> 25:12.600]  И практически все говорят, как и Гера.
[25:12.600 --> 25:13.600]  Почему мы умножаем?
[25:13.600 --> 25:14.600]  Ну, они же независимые.
[25:14.600 --> 25:16.400]  С другой стороны, если вы задумаетесь хотя бы на
[25:16.400 --> 25:19.600]  три секунды, вы также как Тихон скажете, ну нет, конечно.
[25:19.600 --> 25:22.720]  Ну, потому что ведь, смотрите, вот когда мы пишем вот эту
[25:23.240 --> 25:26.840]  Понятно то, что мы учитываем информацию о том, что уже
[25:26.840 --> 25:30.040]  белый в уровне пропал один.
[25:30.040 --> 25:31.840]  Мы же как бы девять из пятнадцати.
[25:31.840 --> 25:35.880]  То есть у нас теперь в уровне не шестнадцать шаров, а пятнадцать,
[25:35.880 --> 25:37.600]  причем пропавший именно белый.
[25:37.600 --> 25:39.960]  Так что сказать то, что вот эта вещь не зависит от этой,
[25:39.960 --> 25:40.960]  да нифига.
[25:40.960 --> 25:41.960]  Вот мы же зависим.
[25:41.960 --> 25:45.880]  Тогда почему умножаем?
[25:45.880 --> 25:49.560]  И всегда вот в этот момент повисает тишина.
[25:49.560 --> 25:51.960]  То есть люди не понимают, почему умножаем.
[25:51.960 --> 25:55.800]  При этом каждый, каждый человек, которому вы зададите
[25:55.800 --> 25:58.760]  этот вопрос, дает такое решение, и оно правильное.
[25:58.760 --> 26:01.040]  Мы сейчас с вами докажем, почему это действительно
[26:01.040 --> 26:02.040]  работает.
[26:02.040 --> 26:04.280]  Вот это вещь, которую я понять не могу, если честно.
[26:04.280 --> 26:06.760]  То есть это тоже какой-то как бы память на уровне
[26:06.760 --> 26:07.760]  генома.
[26:07.760 --> 26:10.440]  Ну, как бы, да, действительно, вероятность не надо считать
[26:10.440 --> 26:12.480]  так, причем почему, никто объяснить не может.
[26:12.480 --> 26:14.920]  Ну, если только вы не сильно задумаетесь и не докажете
[26:14.920 --> 26:16.880]  то, что мы сейчас с вами докажем.
[26:16.880 --> 26:19.600]  Вот так с полточка Фика объяснишь.
[26:19.600 --> 26:22.240]  А объяснение стандартной независимости, естественно,
[26:22.240 --> 26:23.240]  бред.
[26:23.240 --> 26:28.320]  Слушай, можно делать все, что угодно.
[26:28.320 --> 26:29.320]  Вопрос откуда?
[26:29.320 --> 26:32.520]  Почему вы все даете правильный ответ, хотя, когда вы пытаетесь
[26:32.520 --> 26:34.840]  обосновать, вы говорите очевидную неправду.
[26:34.840 --> 26:44.520]  Теорем, погнали, теорем.
[26:44.520 --> 26:52.240]  Если а1 и так далее аn события, то есть это есть элемент
[26:52.240 --> 27:02.040]  f, при этом они все положительная вероятность для любого i,
[27:02.040 --> 27:05.720]  то тогда для того, чтобы посчитать вероятность пересечения
[27:05.720 --> 27:14.120]  их всех, все ли помнят о том, что когда между множествами
[27:14.120 --> 27:16.800]  никакая теоретика множественной операции не написана, это
[27:16.800 --> 27:17.800]  значит, что там пересечение.
[27:17.800 --> 27:25.080]  Ну, это так, если множество не написано, так же, как
[27:25.080 --> 27:28.200]  с умножением, если ничего нет между там 2х, это значит
[27:28.200 --> 27:32.760]  2 умножить на х событие с множествами точно так
[27:32.760 --> 27:33.760]  же.
[27:33.760 --> 27:35.680]  Если написано а, а, б, это значит, а пересекаем
[27:35.680 --> 27:36.680]  с б.
[27:36.680 --> 27:37.680]  Хорошо?
[27:37.680 --> 27:39.880]  Ну, вот как это считается?
[27:39.880 --> 27:43.200]  Мы берем вероятность первого, которую потом домножаем
[27:43.200 --> 27:46.360]  на вероятность второго при условии первого, которую
[27:46.360 --> 27:49.440]  потом домножаем на вероятность третьего при условии и
[27:49.440 --> 27:54.280]  первого, и второго, и это значит пересечение и так
[27:54.280 --> 27:55.280]  далее.
[27:55.280 --> 27:57.440]  Последний множитель это вероятность последнего
[27:57.440 --> 27:59.360]  при условии всех предыдущих.
[27:59.360 --> 28:18.600]  Где что-нибудь не так, я не понимаю?
[28:18.600 --> 28:23.720]  Это было а1, может, не очень внятно, было а1, ну ладно.
[28:23.720 --> 28:27.160]  Доказательства, ну, примерно, тут как бы очевидно, смотри,
[28:27.160 --> 28:28.160]  да.
[28:28.240 --> 28:32.220]  Если мы сейчас вот начнем расписывать вот это вот
[28:32.220 --> 28:36.320]  произведение, соответственно, первый множитель это вероятность
[28:36.320 --> 28:39.220]  а1, второй множитель как условная вероятность
[28:39.220 --> 28:45.020]  мы расписываем как отношение пересечения к вероятности
[28:45.020 --> 28:46.020]  условия.
[28:46.020 --> 28:52.560]  Третью вероятность тоже расписываем как вероятность
[28:52.560 --> 28:56.240]  пересечения на вероятность условия и так далее.
[28:56.240 --> 29:00.920]  и так далее. Последний множитель в числителе у нас получается пересечение всех
[29:01.760 --> 29:04.840]  делить на вероятность пересечения всех, кроме последнего.
[29:07.240 --> 29:13.120]  Легко видеть то, что знаменатель каждой последующей дроби будет сокращаться с числителем предыдущей,
[29:16.280 --> 29:18.760]  и в результате у нас останется только числитель последней дроби.
[29:19.640 --> 29:21.640]  То есть это то, что мы и хотели.
[29:22.360 --> 29:25.840]  То есть доказательство очевидно и при этом понятно, что
[29:26.400 --> 29:31.620]  герой делал именно вот это. Что это? Вероятность того, что 1 выточенный будет белым.
[29:32.220 --> 29:37.400]  Это вероятность того, что выточенный будет красный при условии, что предыдущий выточенный был белый.
[29:38.300 --> 29:45.320]  Ну и так далее. А это то, что 3-й будет вытащенный белый при условии, что до этого мы выточили белый и красный.
[29:46.760 --> 29:48.400]  История ясна?
[29:48.400 --> 29:50.480]  Вот это, на самом деле, для меня какая-то локальная
[29:50.480 --> 29:51.480]  тайна.
[29:51.480 --> 29:54.440]  Я не могу сказать, что я сильно пытался найти ответ
[29:54.440 --> 29:55.440]  на этот вопрос.
[29:55.440 --> 30:08.320]  Если ты поймаешь человека на улице, он тебе даст точно
[30:08.320 --> 30:09.320]  такой же ответ.
[30:09.320 --> 30:12.680]  Ну, не совсем бабушку, но какой-нибудь, предположим,
[30:12.680 --> 30:16.240]  возьмете школьника совсем среднего, он скажет то же
[30:16.240 --> 30:17.240]  самое.
[30:17.440 --> 30:28.760]  А можно отнестись к этому как и у шепсту.
[30:28.760 --> 30:33.520]  Ну вот, вы можете поэкспериментировать на самом деле.
[30:33.520 --> 30:36.680]  Возьмите, не знаю, родители, если у вас родители, люди
[30:36.680 --> 30:40.280]  не близкие к математике, попробуйте задать им этот
[30:40.280 --> 30:41.280]  вопрос.
[30:41.280 --> 30:44.520]  Хотя, скорее всего, родители пошлют, потому что надо
[30:44.520 --> 30:46.560]  задумываться хотя бы над сюжетной линией, что
[30:46.560 --> 30:47.560]  там происходит.
[30:47.560 --> 30:54.560]  Ладно, с формулами это все, то есть это те вещи, которыми
[30:54.560 --> 30:55.960]  вам нужно пользоваться.
[30:55.960 --> 30:59.680]  Причем я напомню присутствующим то, что мы с вами все, что
[30:59.680 --> 31:03.200]  мы делали, мы делали в двух случаях.
[31:03.200 --> 31:07.200]  Либо у нас модель, которую мы с вами построили, была
[31:07.200 --> 31:08.200]  дискретно.
[31:08.200 --> 31:11.000]  Причем дискретно у нас там два случая, либо она у
[31:11.000 --> 31:13.840]  вас конечная, и тогда событие это любое подмножество
[31:13.840 --> 31:16.600]  и вероятность, ну там всего два свойства, вероятность
[31:16.600 --> 31:19.960]  всего единичка и вероятность объединений двух непересекающихся
[31:19.960 --> 31:20.960]  сумма.
[31:20.960 --> 31:23.840]  Либо у вас дискретно в том плане то, что у вас счетное
[31:23.840 --> 31:27.440]  множество, счетное Омега большое, но тогда у вас еще
[31:27.440 --> 31:31.160]  добавляется требование вот этой вот счетной аддитивности
[31:31.160 --> 31:32.160]  P.
[31:32.160 --> 31:35.240]  Ну то есть, если вероятность счетного объединения, то
[31:35.240 --> 31:37.040]  там тоже это будет сумма вероятности.
[31:37.040 --> 31:41.600]  И последнее, мы когда делали с геометрической вероятностью
[31:42.360 --> 31:44.760]  то есть вот только для этих трех типов моделей мы выводим
[31:44.760 --> 31:47.000]  то, что мы сейчас выводим, просто потому что других
[31:47.000 --> 31:48.000]  моделей мы не знаем.
[31:48.000 --> 31:49.000]  Это ясно?
[31:49.000 --> 32:03.760]  Все, что мы делаем, оно будет верно всегда, да, конечно.
[32:03.760 --> 32:05.840]  Просто делать мы это можем только для таких, потому
[32:05.840 --> 32:09.960]  что большего матапарата у нас нет.
[32:10.320 --> 32:17.280]  Так, следующий объект – независимость.
[32:17.280 --> 32:20.640]  По сути главный объект вероятности, почему сейчас объясню.
[32:20.640 --> 32:22.480]  Начинаем мы с независимости событий.
[32:22.480 --> 32:29.800]  Еще раз, что подозревается под событиями?
[32:29.800 --> 32:31.560]  У вас есть математическая модель.
[32:31.560 --> 32:38.560]  Омега, пространство элементарных исходов f, это событие, которое
[32:38.560 --> 32:41.640]  под множество омега большое, и p – это функция, определенная
[32:41.640 --> 32:43.960]  на f со значениями в 0,1.
[32:43.960 --> 32:47.000]  Пока у нас только омега может быть, то, что я проговорил,
[32:47.000 --> 32:50.440]  счетная или под множество rn, f – это множество всех
[32:50.440 --> 32:54.280]  под множество случаев дискретно, и p мы определяем просто
[32:54.280 --> 32:57.720]  поточечным в случае дискретных моделей.
[32:57.720 --> 33:00.080]  Если геометрическая вероятность, тогда тоже там обсудили
[33:00.080 --> 33:01.080]  как определять.
[33:01.080 --> 33:06.400]  И сейчас нам нужно вести понятие независимости.
[33:06.400 --> 33:09.040]  Что значит то, что событие А независимо с событием
[33:09.040 --> 33:10.040]  Б?
[33:10.040 --> 33:17.320]  С понятием независимости возникает из-за того, что
[33:17.320 --> 33:23.280]  очень большое… Ну вот, на памяти.
[33:23.280 --> 33:26.760]  Про независимость вы слышали, начиная какого-то с раннего
[33:26.760 --> 33:27.760]  возраста.
[33:27.760 --> 33:31.000]  Во взрослой жизни тебе нужно быть независимым, зарабатывать
[33:31.000 --> 33:34.560]  много денег, и у вас как бы независимость въелась
[33:34.560 --> 33:38.080]  в мозг именно с чистой человеческой точки зрения.
[33:38.080 --> 33:42.280]  И поэтому в те веры бывает тяжело, когда выводите понятие
[33:42.280 --> 33:44.440]  независимости, потому что все время вот этот хвост
[33:44.440 --> 33:49.040]  жизненного опыта, особенно вот подросткового опыта,
[33:49.040 --> 33:53.000]  когда тема независимости особенно остро воспринимается,
[33:53.000 --> 33:54.000]  он вас тянет назад.
[33:54.000 --> 33:57.160]  Но сначала давайте попробуем вообще сообразить, о чем
[33:57.160 --> 33:58.160]  речь.
[33:58.160 --> 34:01.720]  То есть вот у вас есть два события А и Б, и мы говорим
[34:01.720 --> 34:05.400]  о том, что события А независимы от события Б.
[34:05.400 --> 34:07.320]  Что бы это могло быть?
[34:07.320 --> 34:13.320]  Вот у вас есть омега большая, вот есть события А и события
[34:13.320 --> 34:14.320]  Б.
[34:14.320 --> 34:16.160]  Вот если они не пересекаются, можно говорить о том, что
[34:16.160 --> 34:17.160]  они независимы?
[34:17.160 --> 34:18.160]  Ну, идейно, почему нет?
[34:18.160 --> 34:19.160]  И что?
[34:19.160 --> 34:20.160]  Ну конечно.
[34:20.160 --> 34:31.000]  Ну то есть если у нас случилось событие А, что значит случилось
[34:31.000 --> 34:32.600]  событие А?
[34:32.600 --> 34:35.280]  Было реализовано омега маленький, который из А.
[34:35.280 --> 34:37.760]  Что мы тогда можем сказать про Б?
[34:37.760 --> 34:39.680]  Ну его точно нет.
[34:39.680 --> 34:42.440]  Поэтому если они не пересекаются, называть их независимыми
[34:42.440 --> 34:43.440]  вообще странно.
[34:43.440 --> 34:47.240]  Потому что если произошло А, то Б точно не произошло.
[34:47.240 --> 34:50.640]  То есть мы можем сделать какой-то вывод А, Б, по тому
[34:50.640 --> 34:53.000]  произошло или не произошло А.
[34:53.000 --> 34:54.000]  Хорошо.
[34:54.000 --> 34:57.000]  То есть кажется, что они должны пересекаться.
[34:57.000 --> 35:00.600]  Ну хорошо, а если они будут пересекаться, то какое
[35:00.600 --> 35:08.880]  естественное определение независимости А и Б?
[35:08.880 --> 35:11.160]  Ну тут только можно знать правильный ответ, как бы
[35:11.160 --> 35:13.240]  дойти до этой мысли на самом деле тяжело.
[35:13.240 --> 35:15.440]  То есть если мы рассмотрим недавно введенный нами
[35:15.440 --> 35:18.080]  объект, условную вероятность А при условии Б, ну будем
[35:18.080 --> 35:23.480]  считать, что вероятность события Б больше нуля.
[35:23.480 --> 35:25.480]  Вероятность условная А относительно Б.
[35:25.480 --> 35:28.080]  То есть какова вероятность А, если мы знаем, что произошло
[35:28.080 --> 35:29.800]  событие Б?
[35:29.800 --> 35:32.440]  Если мы считаем, что А и Б независимы, то что мы
[35:32.440 --> 35:35.720]  ожидаем от этой вероятности?
[35:35.720 --> 35:37.360]  Что она будет равна вероятности А.
[35:37.360 --> 35:40.280]  То есть информация о том, произошло или не произошло
[35:40.280 --> 35:44.840]  событие Б, не должно повлиять на вероятность А.
[35:44.840 --> 35:46.840]  Идейно понятно?
[35:46.840 --> 35:49.400]  Минус этого определения очевиден, потому что независимость
[35:49.400 --> 35:55.000]  событий должно быть очевидна симметричным отношением.
[35:55.000 --> 35:57.920]  Понятно, что я сказал, да?
[35:57.920 --> 36:02.600]  Да, то есть почему мы сейчас будем раскрывать?
[36:02.600 --> 36:04.400]  Потому что здесь у нас, во-первых, есть требования
[36:04.400 --> 36:07.640]  на Б, во-вторых, это как бы условие, что А не зависит
[36:07.640 --> 36:08.640]  от Б.
[36:08.640 --> 36:11.240]  А нам хочется, ну мы же сейчас понимаем, что мы хотим,
[36:11.240 --> 36:14.080]  нам хочется, чтобы понятие независимости событий было
[36:14.080 --> 36:15.080]  симметричным.
[36:15.080 --> 36:22.960]  Поэтому мы распишем условную вероятность, ну и умножим
[36:22.960 --> 36:23.960]  на знаменатель.
[36:23.960 --> 36:27.320]  И именно вот это вот равенство становится определением
[36:27.320 --> 36:40.680]  независимости события А и Б, то есть определением.
[36:40.680 --> 36:50.000]  События А и Б называются независимыми, если вероятность
[36:50.000 --> 36:54.120]  их пересечения равна произведению их вероятности.
[36:54.120 --> 37:01.800]  Обозначается, ну вот так, как я писал, ну это как
[37:01.800 --> 37:04.200]  антагональность, только с двумя вертикальным палочками.
[37:04.200 --> 37:12.400]  Обычно тут никакой эмоциональной реакции у людей не возникает,
[37:12.400 --> 37:16.000]  потому что мы как бы вводим новые объекты и исследуем
[37:16.000 --> 37:17.000]  их свойства.
[37:17.000 --> 37:19.920]  Это просто какое-то новое понятие в науке, ладно,
[37:19.920 --> 37:20.920]  хорошо.
[37:20.920 --> 37:25.080]  Но в самом деле это центральное понятие тервера, потому
[37:25.080 --> 37:27.720]  что все, чем мы будем заниматься потом, это и есть вот тот
[37:27.720 --> 37:29.880]  действительный анализ, о котором я говорю, потому
[37:29.880 --> 37:32.720]  что мы будем работать с вами со случайными величинами,
[37:32.720 --> 37:34.120]  это будут измеримые функции.
[37:34.120 --> 37:36.160]  Математическое ожидание, всякие дисперсии и так
[37:36.160 --> 37:39.120]  далее – это интеграл либег, случайные величины – это
[37:39.120 --> 37:41.960]  будут измеримые функции, я уже говорил об этом, ну
[37:41.960 --> 37:42.960]  вот, извините.
[37:42.960 --> 37:47.560]  Ну вот, вероятность – это просто там будут сигмоаддитивные
[37:47.560 --> 37:48.560]  меры напрямую.
[37:48.600 --> 37:51.720]  Что это понятие действительного анализа, который является
[37:51.720 --> 37:53.400]  частью функционального анализа?
[37:53.400 --> 37:57.120]  И вот понятие, которого нету в этих науках, это понятие
[37:57.120 --> 37:59.320]  независимости множеств.
[37:59.320 --> 38:03.440]  Оно вообще не логично с точки зрения действительного
[38:03.440 --> 38:05.040]  анализа, потому что посмотрите вот на эту запись.
[38:05.040 --> 38:06.680]  Мы с вами когда будем заниматься?
[38:06.680 --> 38:10.520]  Ведь идейная мера – это продолжение понятия площади,
[38:10.520 --> 38:12.720]  ну, идейно, это понятно?
[38:12.720 --> 38:15.440]  Ну вот, а давайте посмотрим, что здесь получается, то
[38:15.440 --> 38:19.600]  есть как бы площадь пересечения множества равна произведению
[38:19.600 --> 38:20.600]  площадей.
[38:20.600 --> 38:23.800]  То есть это какой-то бред с точки зрения именно
[38:23.800 --> 38:27.400]  вот и функционального действительного анализа, они даже такого
[38:27.400 --> 38:28.400]  не изучали.
[38:28.400 --> 38:30.440]  И, собственно говоря, вот мой семинарист, он же ваш
[38:30.440 --> 38:34.800]  лектор на продвинутом потоке, ну вот, мы когда действительного
[38:34.800 --> 38:37.400]  анализа занимались, он сказал то, что, ну в принципе
[38:37.400 --> 38:40.440]  этот ваш тер веры, он как бы это под множество нашего
[38:40.440 --> 38:42.640]  великого функционального анализа, но блин, да, там
[38:42.640 --> 38:45.040]  есть вот понятие независимости.
[38:45.040 --> 38:46.680]  Вот то, чего нет.
[38:46.680 --> 38:49.200]  Вот, чтобы вы поняли, что это центральная вещь.
[38:49.200 --> 38:52.720]  И если вы смотрите там какие-то публикации современной
[38:52.720 --> 38:55.640]  тер веры, ну современной я вру, когда я занимался
[38:55.640 --> 38:59.640]  тер верой, было очень много, игрались с понятием независимости,
[38:59.640 --> 39:02.840]  то есть самая простая ситуация, когда там случайная величина,
[39:02.840 --> 39:04.160]  мы попозже разберем, независимая.
[39:04.160 --> 39:07.800]  Хорошо, а если они зависимы, то как они зависимы?
[39:07.800 --> 39:10.680]  Водится понятие слабой зависимости, сильной зависимости,
[39:10.680 --> 39:12.600]  там такие метрики специальные есть.
[39:12.600 --> 39:14.280]  А что происходит, когда слабая зависимость, когда
[39:14.280 --> 39:17.800]  сильная зависимость, и играются именно вот с этой
[39:17.800 --> 39:18.800]  вещью.
[39:18.800 --> 39:21.600]  Так что это центральное понятие в тер веры, чтобы
[39:21.600 --> 39:22.600]  вы осознали.
[39:22.600 --> 39:23.600]  Так.
[39:23.600 --> 39:24.600]  С чем?
[39:24.600 --> 39:38.280]  Ну то есть, что мы получили благодаря такому определению?
[39:38.280 --> 39:41.800]  Мы получили то, что мы можем сейчас рассматривать ситуации,
[39:41.800 --> 39:45.160]  когда а и б события нулевой вероятности, и при этом все
[39:45.160 --> 39:46.160]  хорошо.
[39:46.160 --> 39:48.640]  Давайте посмотрим, если у вас событие b нулевой вероятности,
[39:48.640 --> 39:51.840]  вот это хрень обнуляется, а что происходит с этим?
[39:51.840 --> 39:54.000]  Она тоже обнуляется, то есть мы получили свойство
[39:54.000 --> 39:57.840]  о том, что у вас события нулевой вероятности независимы
[39:57.840 --> 39:58.840]  с любым событием.
[39:58.840 --> 40:02.120]  Это плохо, если так глубоко задуматься.
[40:02.120 --> 40:10.720]  Ну да, оно же никогда не происходит, пока оно не произойдет.
[40:10.720 --> 40:16.400]  Поэтому именно в качестве определения зависимости
[40:16.400 --> 40:18.920]  берется это, а не это, потому что включают в себя вот
[40:18.920 --> 40:21.800]  эти неприятные случаи, когда событие у вас вероятности
[40:21.800 --> 40:22.800]  ноль.
[40:22.800 --> 40:23.800]  Пример.
[40:23.800 --> 40:43.400]  И что такое схема испытаний b нулевой?
[40:43.400 --> 40:47.560]  Это математическая модель, соответствующая эксперименту,
[40:47.560 --> 40:55.120]  когда вы проводите n независимых испытаний, результат каждого
[40:55.120 --> 40:59.520]  испытания у вас 0 или e1, при этом вероятность единички
[40:59.520 --> 41:00.520]  у вас p.
[41:00.520 --> 41:02.160]  Помните, как мы строили?
[41:02.160 --> 41:04.600]  Ну вот, и как у нас там было?
[41:04.600 --> 41:07.960]  Элементальный исход – это был набор из нулей единиц.
[41:07.960 --> 41:15.280]  Соответственно, там мощность омега у вас была 2 в степени
[41:15.280 --> 41:17.540]  n.
[41:17.540 --> 41:20.900]  Моя мощность омега определялась, вероятность определялась
[41:20.900 --> 41:23.420]  по точке, поскольку это дискретная модель, конечную
[41:23.420 --> 41:26.740]  вероятность определяем в каждой точке.
[41:26.740 --> 41:31.500]  Она определялась как p в степени сумма ежитых пожирит
[41:31.500 --> 41:34.980]  единички до n на единичку минус p в степени n минус
[41:34.980 --> 41:35.980]  суммы ежитых.
[41:35.980 --> 41:46.620]  p соответственно – это параметр нашей математической модели,
[41:46.620 --> 41:50.160]  а эта чиселка от 0 до 1.
[41:50.160 --> 41:51.160]  Это ясно?
[41:51.160 --> 41:54.820]  Но вы же помните, что когда мы эту модель строили, мы
[41:54.820 --> 41:57.740]  начали с классической модели, потом увидели, что так сложно
[41:57.740 --> 42:00.420]  не надо, и можно работать с такой моделью.
[42:00.420 --> 42:01.420]  Согласны?
[42:01.420 --> 42:04.660]  Ну то есть при построении модели, вот здесь, мы вроде
[42:04.660 --> 42:08.020]  как вот эту независимость не учитывали.
[42:08.020 --> 42:10.700]  Давайте сейчас проверим, она сохранилась или нет.
[42:10.700 --> 42:13.380]  Ну то есть, я сейчас осматриваю два события.
[42:13.380 --> 42:14.380]  Событие А.
[42:14.380 --> 42:15.380]  Оно состоит в чем?
[42:15.380 --> 42:18.260]  Мы рассматриваем все такие омега, что и первое равно
[42:18.260 --> 42:19.260]  одному.
[42:19.260 --> 42:24.700]  Ну то есть, первый был успех, а событие Б, мы рассмотрим
[42:24.700 --> 42:27.420]  это такие элементарные сходы, что последний был
[42:27.420 --> 42:28.420]  успех.
[42:28.420 --> 42:33.940]  Ну вообще, идейно, как бы независимость должна
[42:33.940 --> 42:34.940]  быть.
[42:34.940 --> 42:39.500]  Но блин, у нас как бы независимость, есть сейчас математическое
[42:39.500 --> 42:41.400]  понятие, для того чтобы проверить, нужно просто тупо
[42:41.400 --> 42:42.500]  проверить равенство.
[42:42.500 --> 42:43.500]  Погнали проверять.
[42:44.420 --> 42:47.100]  То есть для этого нам нужно посчитать три вероятности
[42:47.100 --> 42:48.100]  и проверить это.
[42:48.100 --> 42:51.620]  Как посчитать вероятность события А?
[42:51.620 --> 42:55.460]  Мы ее считали, это было, какие-то мучения были, складывали.
[42:55.460 --> 42:58.380]  Она у нас получилась П, вероятность события Б тоже получилась
[42:58.380 --> 42:59.380]  П.
[42:59.380 --> 43:03.620]  Ну а теперь давайте посчитаем вероятность А пересеченной
[43:03.620 --> 43:04.620]  с Б.
[43:04.620 --> 43:07.380]  Ну то есть это что?
[43:07.380 --> 43:09.620]  Мы должны просуммировать по всем омегамальникам
[43:09.620 --> 43:12.500]  таким, что у них на первой позиции единица и на последней
[43:12.500 --> 43:17.260]  позиции единица вероятности этих омег маленьких, то
[43:17.260 --> 43:23.020]  есть сумма по ежитых по ж от единички до n, n минус
[43:23.020 --> 43:27.940]  сумма по ж от единички до n и житых.
[43:27.940 --> 43:30.460]  Ну теперь смотрим, мы прекрасно понимаем, что вот в этой сумме
[43:30.460 --> 43:36.340]  первое слагаемое, последнее слагаемое, это у нас единички.
[43:36.340 --> 43:41.460]  Ну то есть для каждого слагаемого, вот первое и последнее
[43:41.460 --> 43:44.100]  слагаемое вот в этих суммах кривых мы знаем.
[43:44.100 --> 43:48.100]  Окей, получается, я могу вынести.
[43:48.100 --> 43:53.180]  Вот здесь вот у нас будет, то есть получается П в квадрате,
[43:53.180 --> 43:57.740]  сумма у нас получается П в степени сумма по ж от
[43:57.740 --> 44:04.380]  двойки до n минус 1 из житых на единичка минус П в степени.
[44:04.380 --> 44:07.940]  Ну вот здесь вот у нас первое и последнее двойка.
[44:07.940 --> 44:08.940]  Черт, как неудачно.
[44:08.940 --> 44:12.620]  Можно я сейчас вот так сделаю.
[44:12.620 --> 44:21.140]  На единичка минус П в степени n минус 2 минус сумма по ж
[44:21.140 --> 44:24.220]  от двойки до n минус 1 и житых.
[44:24.220 --> 44:27.220]  Так, вы видите то, что пишется, да?
[44:27.220 --> 44:29.020]  Ну если не видите, то догадывайтесь.
[44:29.020 --> 44:33.940]  Ну ладно, видно, вот последнее вообще видно.
[44:33.940 --> 44:39.740]  А теперь давайте посмотрим, почему идет суммирование.
[44:39.740 --> 44:43.740]  Суммирование идет по всем наборам i2 и так далее i n
[44:43.740 --> 44:46.020]  минус 1.
[44:46.020 --> 44:51.940]  По всем возможным наборам от i2 до i n минус 1, согласны?
[44:51.940 --> 44:55.820]  А мы с вами разбирали то, что суммы вот такого вида
[44:55.820 --> 44:59.700]  какие, чему будут равны суммы такого вида.
[44:59.700 --> 45:03.140]  Еще раз смотрите, вы суммируете по всем наборам длины n минус
[45:03.140 --> 45:08.220]  2, П в степени сумма и житых в этом наборе на единицу
[45:08.220 --> 45:11.500]  минус П в степени n минус 2 на сумму и житых в этом
[45:11.500 --> 45:12.500]  наборе.
[45:12.500 --> 45:18.100]  Ну там через бином мы получаем, что это будет единичка.
[45:18.100 --> 45:20.540]  Это еще не бином, тут ц никаких нету, но через
[45:20.540 --> 45:22.860]  бином мы с вами доказывали, что вот такая сумма будет
[45:22.860 --> 45:25.060]  равна одному.
[45:25.060 --> 45:26.060]  Кивайте, что было.
[45:26.060 --> 45:27.060]  Окей.
[45:27.060 --> 45:28.860]  Ну то есть в результате у нас получилась П квадрат.
[45:29.580 --> 45:30.580]  Ура!
[45:30.580 --> 45:33.740]  Ну то есть действительно мы получили то, что вероятность
[45:33.740 --> 45:36.260]  пересечения равна произведению вероятности.
[45:36.260 --> 45:40.180]  Так что в ответ на вопрос Тихона, как мы это делаем,
[45:40.180 --> 45:41.180]  сидим и проверяем.
[45:41.180 --> 45:44.180]  А разве это не делает процесс бессмысленности?
[45:44.180 --> 45:45.180]  В смысле?
[45:45.180 --> 45:49.180]  Ну мы же хотели, например, задача была не то чтобы проверить
[45:49.180 --> 45:52.180]  независимые события, а посчитать вероятность того, что первые
[45:52.180 --> 45:53.180]  и последние единицы.
[45:53.180 --> 45:58.180]  Я бы такой, ну события независимые значат П умножить на П.
[45:58.500 --> 46:01.500]  Ну вот теперь ты знаешь, что они независимы.
[46:01.500 --> 46:05.500]  Ну теперь смотри, то есть как обычно, то есть если
[46:05.500 --> 46:07.900]  ты математик и ты работаешь сразу в математической
[46:07.900 --> 46:10.820]  модели, тебе там уже сразу говорится о том, кто с кем
[46:10.820 --> 46:11.820]  там независим.
[46:11.820 --> 46:16.500]  Ну такие условия задач.
[46:16.500 --> 46:28.500]  Если только одно из них не пуст.
[46:28.500 --> 46:35.300]  Ну да, очень важное замечание, спасибо.
[46:35.300 --> 46:40.100]  Если только кто-то из них не является нулевой вероятностью.
[46:40.100 --> 46:48.940]  Ну, идейно да, но у нас есть вот этот вот выраженный
[46:48.940 --> 46:54.300]  случай с вероятностью, с событием нулевой вероятности,
[46:54.300 --> 46:56.540]  но окей, мы будем считать, что событие нулевой вероятности
[46:56.540 --> 46:57.540]  независимо с любым.
[46:57.540 --> 47:02.860]  То есть в нашем виде это ничему не противоречит.
[47:02.860 --> 47:04.780]  Именно поэтому мы взяли в качестве определения
[47:04.780 --> 47:11.140]  не вот это, а вот это.
[47:11.140 --> 47:15.500]  Так и следующая история, это когда у вас событий
[47:15.500 --> 47:19.380]  больше.
[47:19.380 --> 47:22.980]  Давайте возьмем n событий.
[47:22.980 --> 47:25.420]  То есть расширим немножко понятие независимости
[47:25.420 --> 47:28.460]  событий на большее количество событий.
[47:28.460 --> 47:32.700]  А теперь второй случай.
[47:32.700 --> 47:33.700]  Когда у вас n событий.
[47:34.620 --> 47:37.020]  Да, а вон видишь, там было написано единичка событий.
[47:37.020 --> 47:42.100]  Я буду стараться писать аккуратнее.
[47:42.100 --> 47:46.380]  Тут возникает два понятия.
[47:46.380 --> 47:51.940]  Независимость попарная.
[47:51.940 --> 48:02.900]  Так, события a1 и так далее an, называются независимыми
[48:03.100 --> 48:04.100]  попарно.
[48:04.100 --> 48:09.260]  Но тут прост.
[48:09.260 --> 48:19.980]  Если для любых и j, ну и неравно j конечно, они независимы
[48:19.980 --> 48:20.980]  между собой.
[48:20.980 --> 48:25.020]  Потому что когда у вас событий 2, мы знаем, что такое независимость.
[48:25.140 --> 48:37.180]  И второе определение события, называются независимыми
[48:37.180 --> 48:46.780]  в совокупности, независимыми в совокупности, называются
[48:46.780 --> 48:52.300]  независимыми в совокупности, если для любого их количества
[48:52.300 --> 49:01.780]  и любого их набора.
[49:01.780 --> 49:18.660]  Понятно, то есть i1 и k зажаты между единичкой и n, и они
[49:18.660 --> 49:20.660]  между собой неравны.
[49:20.660 --> 49:26.780]  Будет выполна следующее, что вероятность пересечения
[49:26.780 --> 49:35.100]  ашек с этими индексами, равно произведению вероятности
[49:35.100 --> 49:36.100]  этих ашек.
[49:36.100 --> 49:48.500]  Вопрос, какое понятие сильнее.
[49:48.500 --> 49:59.780]  Из того, что следует.
[49:59.780 --> 50:16.020]  Какая непрерывность сильнее, равномерная или обычная?
[50:16.540 --> 50:19.420]  Если у вас функция непрерывная равномерно, то она непрерывно
[50:19.420 --> 50:20.420]  прост.
[50:20.420 --> 50:27.220]  Давайте мы обозначим это определение 1, вот это
[50:27.220 --> 50:30.220]  определение 2.
[50:30.220 --> 50:34.420]  Из кого что следует?
[50:34.420 --> 50:40.140]  Из второго следует первое.
[50:40.140 --> 50:45.300]  Из второго следует первое, почему?
[50:45.300 --> 50:49.220]  Конечно, можно просто брать k равной 2, но как бы для
[50:49.220 --> 50:53.100]  любого их количества, то есть частности для 2, для
[50:53.100 --> 50:59.060]  любых двух будет выполнено вот это.
[50:59.060 --> 51:06.380]  В обратную сторону неверно, вы будете в этом убеждаться
[51:06.380 --> 51:09.380]  постоянно, есть классические примеры, называются пример
[51:09.380 --> 51:10.380]  Бернштейна.
[51:10.380 --> 51:22.900]  Их можно много построить, но это такой стандартный
[51:22.900 --> 51:24.620]  и он визуализируется хорошо.
[51:24.620 --> 51:28.460]  Давайте возьмем с вами тетрайдер, чьи вершины мы покрасим
[51:28.460 --> 51:29.460]  в три цвета.
[51:29.460 --> 51:35.180]  Давайте мы возьмем серый, какие вы унылые на самом
[51:35.180 --> 51:37.180]  деле, только сейчас это понял.
[51:37.180 --> 51:46.740]  Паярчина, оранжевый и синий, нет, черный, хорошо, а третью
[51:46.740 --> 51:50.820]  вершину покрасим в три цвета, будет серый, черный и оранжевый.
[51:50.820 --> 52:00.100]  Элементарный исход это вершинка, вероятность каждой
[52:00.100 --> 52:03.540]  вершинки у нас одна четвертая, то есть такая равновероятность
[52:04.180 --> 52:07.540]  И мы будем насматривать в качестве событий, какого
[52:07.540 --> 52:15.380]  цвета вершина, то есть А это вершина у нас оранжевая,
[52:15.380 --> 52:24.180]  Б вершина черная и С это у нас вершина синяя.
[52:24.180 --> 52:33.780]  Я на следующей лекции приду в красном бомбере, в ярко
[52:33.780 --> 52:35.300]  красном, чтобы было веселее.
[52:35.300 --> 52:41.540]  Погнали, вероятности А, Б и С чему равны?
[52:41.540 --> 52:47.340]  Ну то, что вероятность оранжевая, одна вторая, либо это, либо
[52:47.340 --> 52:48.340]  это вершина.
[52:48.340 --> 52:50.980]  Соответственно, вероятности всех этих событий у нас
[52:50.980 --> 52:53.900]  получаются одна вторая.
[52:53.900 --> 53:02.900]  Вероятность их пересечения, всех троих, это одна четвертая,
[53:02.900 --> 53:04.620]  потому что только одна вершинка обладает всеми
[53:04.620 --> 53:05.620]  тремя свойствами.
[53:05.620 --> 53:12.060]  При этом, если мы будем брать пересечение любых двух,
[53:12.060 --> 53:14.660]  вероятность А и Б, то есть это вероятность и оранжевая,
[53:14.660 --> 53:15.660]  и черная.
[53:15.660 --> 53:18.500]  Такая только одна, вот эта.
[53:18.500 --> 53:22.020]  Эта вероятность получается тоже одна четвертая.
[53:22.020 --> 53:26.740]  А, С, А, Б и Б, С.
[53:26.740 --> 53:28.460]  И что у нас с вами получается?
[53:28.460 --> 53:32.580]  Получается, что попарная независимость у вас выполнена,
[53:32.580 --> 53:35.540]  потому что для любой пары вероятность пересечения
[53:35.540 --> 53:37.140]  будет равна произведению вероятности.
[53:37.140 --> 53:42.780]  А вероятности независимости в совокупности нет, потому
[53:42.780 --> 53:46.340]  что если мы возьмем в качестве К тройку, тогда мы у нас,
[53:46.340 --> 53:50.540]  если мы берем все три события, то вероятность пересечения
[53:50.540 --> 53:57.540]  всех трёх не равна произведению вероятности этих трёх.
[53:57.540 --> 53:58.540]  Ну всё.
[53:58.540 --> 54:26.100]  Ну модель просто непрозрачная, ты не понимаешь какая там
[54:26.100 --> 54:28.420]  была сюжетная линия раскраски этих вершин.
[54:28.420 --> 54:32.900]  Ну, кстати, такое бывает, действительно, если вы
[54:32.900 --> 54:36.340]  вам просто описывают мат-модель, вот именно то, что вы берёте,
[54:36.340 --> 54:39.460]  предположим, там отрезок прямой, берёте такие множества
[54:39.460 --> 54:43.300]  и такие множества, считаете, они получаются у вас почему-то
[54:43.300 --> 54:49.460]  независимыми, хотя вы вообще не видите, почему они независимы,
[54:49.460 --> 54:50.460]  это связано с чем?
[54:50.460 --> 54:53.740]  С тем, что вы вот этой реальной задачи не видели, которая
[54:53.780 --> 54:55.620]  привела к этой математической модели.
[54:55.620 --> 54:56.620]  Понятно?
[54:56.620 --> 55:01.700]  Ну то есть мысль в том, что вот это понятие независимости,
[55:01.700 --> 55:07.420]  оно естественно соответствует тому понятию независимости,
[55:07.420 --> 55:10.460]  которое из жизни пришло, потому что всё-таки тервер
[55:10.460 --> 55:16.220]  это у нас, да, это идеальная модель, но всё-таки это
[55:16.220 --> 55:19.020]  идеальная модель случайного эксперимента, который мы
[55:19.020 --> 55:20.580]  видим всё время вокруг себя.
[55:20.580 --> 55:22.980]  Это ясно?
[55:23.060 --> 55:26.700]  Просто если вы начинаете докапываться вот тут, становится
[55:26.700 --> 55:27.700]  очень тяжело.
[55:27.700 --> 55:30.620]  Вы же можете, ну так же, как я докопался там до своего
[55:30.620 --> 55:33.820]  научерка с тем, что вы мне модели строите, которые
[55:33.820 --> 55:37.780]  не соответствуют реальности, так и там в геометре вы можете
[55:37.780 --> 55:43.700]  докопаться, у нас не бывает линий нулевой толщиной,
[55:43.700 --> 55:46.220]  но работает вся эта наука, потом, когда вы начинаете
[55:46.220 --> 55:47.500]  применять в жизни, она работает.
[55:47.500 --> 55:58.420]  Это всё в тему того, вот то, что я про ПМФ вам говорил.
[55:58.420 --> 56:07.460]  Пока всё, то есть вот понятие вели, ну вот будете на семинарах
[56:07.460 --> 56:08.460]  с ним работать.
[56:08.460 --> 56:13.140]  Следующее понятие, с которым мы с вами сталкиваемся, это
[56:13.140 --> 56:14.140]  понятие случайной величины.
[56:15.140 --> 56:18.500]  Да, случайной величины.
[56:18.500 --> 56:21.380]  У независимости будет третий пункт, но там будет независимость
[56:21.380 --> 56:23.580]  случайных величин, для этого сначала нужно ввести, что
[56:23.580 --> 56:24.580]  такое случайная величина.
[56:24.580 --> 56:35.660]  Цель полагания очень простая, то есть случайная величина
[56:35.660 --> 56:39.340]  это какая-то числовая характеристика случайного эксперимента,
[56:39.340 --> 56:40.340]  который у вас есть.
[56:40.340 --> 56:43.820]  Потому что одна из проблем, с которыми мы с вами столкнулись,
[56:43.820 --> 56:44.820]  вообще в чём?
[56:44.820 --> 56:48.500]  То, что мы с вами работаем с вероятностным пространством,
[56:48.500 --> 56:51.100]  с математической моделью случайного эксперимента.
[56:51.100 --> 56:54.820]  И в этой модели омега маленькая, ну элемент омега большого
[56:54.820 --> 57:02.820]  это кто?
[57:02.820 --> 57:04.500]  Элемент омега большого, это всё, что мы можем о нём
[57:04.500 --> 57:05.500]  сказать.
[57:05.500 --> 57:07.300]  То есть какой-то элемент множества, природа которого
[57:07.300 --> 57:08.300]  неизвестна.
[57:08.300 --> 57:11.060]  То есть ожидать то, что омега маленькая это число, да
[57:11.060 --> 57:13.380]  нифига, у нас было сколько задач, где омега это там
[57:13.380 --> 57:20.020]  кортежи или это часть прямой или ещё что-то, это понятно
[57:20.020 --> 57:21.020]  сейчас?
[57:21.020 --> 57:24.140]  И это основная проблема, потому что вся та математика,
[57:24.140 --> 57:25.980]  которую вы наработали к данному моменту, она плюс-минус
[57:25.980 --> 57:26.980]  бесполезна.
[57:26.980 --> 57:32.980]  Ну потому что главный предмет предыдущего года, да, не
[57:32.980 --> 57:37.420]  катечен, не ваш, Господи, кому это надо, а именно математический
[57:37.420 --> 57:38.420]  анализ.
[57:38.420 --> 57:40.380]  И там построен огромный математический аппарат,
[57:40.380 --> 57:41.380]  который здесь оказался бесполезным.
[57:42.380 --> 57:43.380]  Это же обидно.
[57:43.380 --> 57:44.380]  Это во-первых.
[57:44.380 --> 57:47.660]  Во-вторых, почему всё-таки именно матан – самая важная
[57:47.660 --> 57:48.660]  дисциплина?
[57:48.660 --> 57:53.380]  Потому что все всегда работают с числовыми, с числами, то
[57:53.380 --> 57:56.540]  есть если даже у вас какая-то жизненная история, всё равно
[57:56.540 --> 57:59.020]  вы стараетесь какую-то там метрику придумать, чтобы
[57:59.020 --> 58:02.020]  у вас числа были, потому что с числами работать хорошо
[58:02.020 --> 58:03.020]  удобно.
[58:03.020 --> 58:08.940]  И здесь та же самая история, да, у вас случайный эксперимент,
[58:08.940 --> 58:10.900]  он соответствует каждому результату случайного эксперимента
[58:10.900 --> 58:12.900]  соответствует какому-то омега маленькому, какой-то
[58:12.900 --> 58:16.380]  хренью какой-то быть, но вам обычно всё-таки нужны
[58:16.380 --> 58:17.780]  числовые характеристики.
[58:17.780 --> 58:21.460]  Ну, предположим, вы кидаете кости, вас интересует сумма
[58:21.460 --> 58:25.300]  или схемы испытаний Бернуля, вас интересует количество
[58:25.300 --> 58:26.300]  успехов.
[58:26.300 --> 58:29.300]  Идея ясна?
[58:29.300 --> 58:54.060]  Поэтому, определение, если омега не более чем счётно,
[58:54.060 --> 58:56.700]  и любое под множество омега большое является событием,
[58:56.700 --> 59:14.980]  то случайной величиной мы назовём любую функцию
[59:14.980 --> 59:17.500]  числовую, определённую на пространстве элементарных
[59:17.500 --> 59:18.500]  исходов.
[59:18.500 --> 59:27.940]  Ну, пример стандартный, я его проговорил, если мы
[59:27.940 --> 59:35.020]  рассмотрим схему испытаний Бернуля, ну, то есть когда
[59:35.020 --> 59:48.100]  у вас омега маленькая, это набор из 0 единиц, на самом
[59:48.100 --> 59:50.900]  деле, нас ведь обычно не интересует, на каком шаге
[59:50.900 --> 59:57.460]  был успех, на какое бывание удачи, нас интересует количество.
[59:57.460 --> 01:00:04.100]  То есть вот, пожалуйста, у вас числовая характеристика,
[01:00:04.100 --> 01:00:15.660]  это будет число, ну, то есть даже вот так, вот это вот
[01:00:15.660 --> 01:00:17.260]  яркий пример случайной величины.
[01:00:17.260 --> 01:00:24.540]  С какими проблемами мы здесь сталкиваемся?
[01:00:24.540 --> 01:00:32.900]  Что напрягает в том определении, которое я написал?
[01:00:32.900 --> 01:00:33.900]  Любая.
[01:00:33.900 --> 01:00:37.940]  Не, область определения, вот написано.
[01:00:37.940 --> 01:00:43.100]  То есть это функция, которая каждому элементарному исходу
[01:00:43.100 --> 01:00:44.420]  ставит в соответствии чиселку.
[01:00:44.420 --> 01:00:50.620]  То есть хорошие примеры, некорректные, но хорошие,
[01:00:50.620 --> 01:00:57.340]  то есть, ну да, вот эта оговорка что-то нас раздражает,
[01:00:57.340 --> 01:01:01.180]  да, то есть мы же хотим всё-таки давать определение, как
[01:01:01.180 --> 01:01:04.980]  вводить понятие, которое потом будут продолжаться
[01:01:04.980 --> 01:01:11.820]  на общий случай, а что будет, когда оно не такое.
[01:01:11.900 --> 01:01:15.340]  Потом опять же, мы же с вами работали не только с дискретными
[01:01:15.340 --> 01:01:18.420]  моделями, у нас была модель геометрической вероятности,
[01:01:18.420 --> 01:01:19.420]  помните?
[01:01:19.420 --> 01:01:22.900]  Когда Омега это под множество РН, я его сюда не включил.
[01:01:22.900 --> 01:01:25.460]  Казалось бы, с моделью работали, а как бы случайную величину
[01:01:25.460 --> 01:01:27.500]  для неё не определяете.
[01:01:27.500 --> 01:01:32.340]  А я, я и Иван Генрихич нехорошо.
[01:01:32.340 --> 01:01:34.340]  Чем вызваны проблемы?
[01:01:34.340 --> 01:01:40.500]  Смотрите, ещё раз, значение числовой характеристики,
[01:01:40.500 --> 01:01:42.380]  но мы всё равно знать не будем, у нас же случайный
[01:01:42.380 --> 01:01:44.540]  эксперимент, мы не знаем Омега маленького.
[01:01:44.540 --> 01:01:47.580]  Ну то есть, если вы знаете результат случайного эксперимента,
[01:01:47.580 --> 01:01:50.380]  он перестал быть случайным, всё, вот вы там, предположим,
[01:01:50.380 --> 01:01:52.660]  вы ездите, вот вы попали в ДТП, вот вы уже в этом
[01:01:52.660 --> 01:01:56.380]  ДТП сидите, вас в этот момент вообще эти вероятности попадания
[01:01:56.380 --> 01:01:59.500]  в ДТП не интересуют, вас интересует, когда приедет
[01:01:59.500 --> 01:02:05.540]  эти, ну мужчины эти, подними, плохо звучало, извините.
[01:02:05.540 --> 01:02:11.940]  Ну вот, то есть нас интересует до проведения опыта, то есть
[01:02:11.940 --> 01:02:14.300]  какая вероятность того, что мы попадём в этот ДТП,
[01:02:14.300 --> 01:02:17.220]  то же самое с значениями к себе от Омега, вы не знаете
[01:02:17.220 --> 01:02:18.220]  значения.
[01:02:18.220 --> 01:02:21.460]  А тогда что вас будет интересовать?
[01:02:21.460 --> 01:02:25.100]  Интересуют обычно вероятности про случайную величину.
[01:02:25.100 --> 01:02:28.420]  Ну давайте рассмотрим, вот предположим, Омега маленькая
[01:02:28.420 --> 01:02:33.060]  это у вас, например, некорректный, но хороший для понимания
[01:02:33.060 --> 01:02:37.260]  результат вашей сессии, эмоционально близко, поэтому
[01:02:37.260 --> 01:02:38.260]  хорошо воспринимается.
[01:02:38.260 --> 01:02:42.860]  То есть, ну предположим, сколько у нас оценок обычно?
[01:02:42.860 --> 01:02:43.860]  10?
[01:02:43.860 --> 01:02:44.860]  Ну за сессию.
[01:02:44.860 --> 01:02:47.420]  Ну там, дивзачёты, экзамены порядка 10, ну то есть вот
[01:02:47.420 --> 01:02:51.580]  10 оценок с порядком, ну не совсем корректно, давайте
[01:02:51.580 --> 01:02:52.580]  пример.
[01:02:52.580 --> 01:02:58.420]  То есть Омега маленькая это набор И1 и так далее
[01:02:58.420 --> 01:03:04.140]  и Н, и 10, где соответственно и житые это оценка за житые
[01:03:04.140 --> 01:03:05.140]  экзамены.
[01:03:05.140 --> 01:03:11.700]  Ну вот, соответственно, какие числовые характеристики
[01:03:11.700 --> 01:03:15.460]  от Омега у нас бывают, которые вас интересуют?
[01:03:15.460 --> 01:03:21.260]  Например, средняя, когда нам нужно средняя?
[01:03:21.260 --> 01:03:23.460]  Когда?
[01:03:23.460 --> 01:03:25.460]  Для обрамовки.
[01:03:25.460 --> 01:03:26.460]  Правильно?
[01:03:26.500 --> 01:03:28.500]  Там же сколько сейчас надо?
[01:03:28.500 --> 01:03:32.500]  9, 8, 9, ну сколько было в предыдущем смеси?
[01:03:32.500 --> 01:03:33.500]  8,6, 8,5.
[01:03:33.500 --> 01:03:34.500]  8,6?
[01:03:34.500 --> 01:03:39.220]  Фистеф уже не тот просто, ладно, ну вот, раньше 9 было,
[01:03:39.220 --> 01:03:40.220]  ну вот.
[01:03:40.220 --> 01:03:42.220]  Например, это, ну вот, кто может предположить ещё
[01:03:42.220 --> 01:03:46.660]  одну как бы, ну это для отличников, а для максимум, когда максимум
[01:03:46.660 --> 01:03:47.660]  кого интересовал?
[01:03:47.660 --> 01:03:51.740]  Ну честно, ну нет, минимум интересует, минимум да,
[01:03:51.740 --> 01:03:54.740]  почему минимум интересует?
[01:03:55.740 --> 01:03:58.740]  Ну какой меркантильный, ужас просто.
[01:04:02.740 --> 01:04:04.740]  Ну минимум на что влияет?
[01:04:07.740 --> 01:04:10.740]  Ну это всё-таки как бы, мы сессию берём в окончании
[01:04:10.740 --> 01:04:11.740]  сессии.
[01:04:11.740 --> 01:04:14.740]  Передачи есть, передачи нет.
[01:04:14.740 --> 01:04:15.740]  Ну вот.
[01:04:20.740 --> 01:04:23.740]  Ну вот, например, для обрамовки ответ на какой вопрос нас
[01:04:23.740 --> 01:04:24.740]  интересует.
[01:04:24.740 --> 01:04:26.740]  То есть, кси от омега, ну сколько говорите, 8,6, да?
[01:04:26.740 --> 01:04:29.740]  Ну то есть, какова вероятность того, что кси от омега, это
[01:04:29.740 --> 01:04:33.740]  я перебозначу, кси от омега больше либо равно 8,6.
[01:04:33.740 --> 01:04:36.740]  Других будет интересовать вероятность того, что это
[01:04:36.740 --> 01:04:38.740]  от омега строго больше двух.
[01:04:41.740 --> 01:04:46.740]  То есть, обычно нас интересуют ответы вот на такие вопросы.
[01:04:46.740 --> 01:04:47.740]  Согласны?
[01:04:47.740 --> 01:04:50.740]  Теперь давайте как бы всё-таки вернёмся как бы к математике.
[01:04:50.740 --> 01:04:51.740]  Что такое п?
[01:04:51.740 --> 01:04:54.740]  П – это функция, определённая для событий.
[01:04:55.740 --> 01:04:57.740]  А здесь я ненавинство пишу.
[01:05:00.740 --> 01:05:02.740]  У нас есть такое событие…
[01:05:04.740 --> 01:05:06.740]  Сейчас, извините, там…
[01:05:06.740 --> 01:05:08.740]  Так лучше?
[01:05:11.740 --> 01:05:13.740]  Но это же не средний, это минимум.
[01:05:15.740 --> 01:05:18.740]  У нас не бывает, у нас же целые оценки ставят в зачётку.
[01:05:18.740 --> 01:05:20.740]  И зачёток больше нет.
[01:05:21.740 --> 01:05:23.740]  Так, ещё раз.
[01:05:23.740 --> 01:05:26.740]  Кто понимает, что тут написано «событие» на самом деле?
[01:05:28.740 --> 01:05:31.740]  То есть, это вероятность всех таких омег маленьких,
[01:05:31.740 --> 01:05:35.740]  что кси от омега больше либо равно 8,6.
[01:05:35.740 --> 01:05:39.740]  То есть, вот эта вот хрень является под множеством омега
[01:05:39.740 --> 01:05:40.740]  большого.
[01:05:40.740 --> 01:05:43.740]  Ну да, это набор каких-то омег маленьких, на которых
[01:05:43.740 --> 01:05:46.740]  кси от омега принимает такие значения, что выполнять не нравится.
[01:05:46.740 --> 01:05:47.740]  Окей?
[01:05:48.740 --> 01:05:49.740]  А теперь вопрос.
[01:05:49.740 --> 01:05:53.740]  Если вот это не выполнено, то есть, если не любое под
[01:05:53.740 --> 01:05:57.740]  множество омега большого является событием, то кто
[01:05:57.740 --> 01:06:01.740]  вам сказал, что это элемент f?
[01:06:01.740 --> 01:06:03.740]  Почему важно быть элементом f?
[01:06:03.740 --> 01:06:06.740]  Потому что p определена на f.
[01:06:06.740 --> 01:06:08.740]  Давайте вспомним геометрическую вероятность.
[01:06:08.740 --> 01:06:11.740]  Помните, почему мы упёрлись вот в эту проблему с этой
[01:06:11.740 --> 01:06:13.740]  несчастной f и p?
[01:06:13.740 --> 01:06:16.740]  Потому что если у вас геометрическая вероятность,
[01:06:16.740 --> 01:06:19.740]  то там вероятность считается как отношение этих
[01:06:19.740 --> 01:06:21.740]  либеговских мер множеств.
[01:06:21.740 --> 01:06:24.740]  Но у нас же не все множества измеримы по либегу.
[01:06:24.740 --> 01:06:27.740]  Поэтому в качестве f мы можем брать множество всех
[01:06:27.740 --> 01:06:28.740]  подмножеств.
[01:06:28.740 --> 01:06:29.740]  Это понятно?
[01:06:29.740 --> 01:06:33.740]  А теперь вот здесь вот кто вам сказал, что конкретно
[01:06:33.740 --> 01:06:36.740]  вот это подмножество омега большого будет являться
[01:06:36.740 --> 01:06:37.740]  элементом f?
[01:06:37.740 --> 01:06:38.740]  Никто не обещал.
[01:06:38.740 --> 01:06:44.740]  И поэтому определение случайной величины потом у вас
[01:06:44.740 --> 01:06:45.740]  будет выглядеть как?
[01:06:45.740 --> 01:06:46.740]  В теории вероятности.
[01:06:46.740 --> 01:06:50.740]  То есть кси, которая является какой-то функцией изомегавер,
[01:06:50.740 --> 01:06:53.740]  будет называться случайной величиной, если выполна
[01:06:53.740 --> 01:06:55.740]  следующее требование.
[01:06:55.740 --> 01:06:57.740]  Простите меня за то, что я сейчас скажу.
[01:06:57.740 --> 01:07:02.740]  Для любого баррелевского множества напрямой будет
[01:07:02.740 --> 01:07:03.740]  выполнено вот это требование.
[01:07:03.740 --> 01:07:07.740]  Кси в минус первое от b будет являться элементом f.
[01:07:07.740 --> 01:07:08.740]  Но почему кси в минус первое?
[01:07:08.740 --> 01:07:12.740]  Смотрите, вот это вот множество можно сделать вот так.
[01:07:12.740 --> 01:07:18.740]  Кси в минус первое от множества от 8,6 до 10.
[01:07:18.740 --> 01:07:21.740]  Ну потому что наш средний балл не может быть больше
[01:07:21.740 --> 01:07:22.740]  10.
[01:07:22.740 --> 01:07:25.740]  10 бывало, знал людей.
[01:07:25.740 --> 01:07:26.740]  Недолго правда, но бывало.
[01:07:26.740 --> 01:07:30.740]  Так вы понимаете, что вот это равенство верно?
[01:07:30.740 --> 01:07:32.740]  Я одно и то же записал.
[01:07:32.740 --> 01:07:33.740]  Еще раз.
[01:07:33.740 --> 01:07:36.740]  Прообраз чисел больше либо равных 8,6.
[01:07:36.740 --> 01:07:40.740]  Это и есть те омега маленькие, на которых выполнено вот
[01:07:40.740 --> 01:07:41.740]  это неравенство.
[01:07:41.740 --> 01:07:42.740]  Вы это понимаете?
[01:07:42.740 --> 01:07:43.740]  Окей.
[01:07:43.740 --> 01:07:46.740]  То есть вот прообраз какого-то отрезка.
[01:07:46.740 --> 01:07:53.740]  Вот он должен быть элементом f большое для того, чтобы
[01:07:53.740 --> 01:07:55.740]  вот эта вероятность была определена.
[01:07:55.740 --> 01:07:59.740]  Дальше там возникает законный вопрос, а для каких множеств
[01:07:59.740 --> 01:08:00.740]  мы будем это требовать?
[01:08:00.740 --> 01:08:04.740]  Ответ на это для баррелевских множеств.
[01:08:04.740 --> 01:08:06.740]  А что такое баррелевские множества?
[01:08:06.740 --> 01:08:07.740]  Узнайте через месяц.
[01:08:07.740 --> 01:08:09.740]  Ну кто-то быстрее.
[01:08:09.740 --> 01:08:14.740]  Это множество наименьшей сигма алгебры на прямой,
[01:08:14.740 --> 01:08:16.740]  которое содержит все хорошие множества.
[01:08:16.740 --> 01:08:18.740]  Хорошие множества у нас на прямой какие?
[01:08:18.740 --> 01:08:19.740]  Очевидные, нужные для нас.
[01:08:19.740 --> 01:08:22.740]  Ну это совсем хорошее.
[01:08:22.740 --> 01:08:24.740]  То есть баррелевское поменьше.
[01:08:24.740 --> 01:08:29.740]  Одно из определений баррелевского множества – это наименьшее
[01:08:29.740 --> 01:08:32.740]  сигма алгебра, содержащее все открытые множества.
[01:08:32.740 --> 01:08:35.740]  Но это сложно, потому что открытые множества, их
[01:08:35.740 --> 01:08:36.740]  что-то там много и тяжело.
[01:08:36.740 --> 01:08:39.740]  Это наименьшие сигма алгебры, содержащие все отрезки
[01:08:39.740 --> 01:08:42.740]  или все интервалы, или все лучи.
[01:08:42.740 --> 01:08:46.740]  Тяжко.
[01:08:46.740 --> 01:08:48.740]  Вот именно для этого нужен этот курс, потому что я
[01:08:48.740 --> 01:08:52.740]  говорю, что когда на третьей паре теории вероятности
[01:08:52.740 --> 01:08:55.740]  людям выкатывает такое определение, они запоминают
[01:08:55.740 --> 01:08:56.740]  только вот это.
[01:08:56.740 --> 01:08:59.740]  То есть да, они потом к экзамену выучивают.
[01:08:59.740 --> 01:09:01.740]  Нет, ну реально, что это просто…
[01:09:01.740 --> 01:09:03.740]  Ну это истинная суть случайной личности.
[01:09:03.740 --> 01:09:05.740]  Это числовая характеристика эксперимента.
[01:09:05.740 --> 01:09:06.740]  Да, окей.
[01:09:06.740 --> 01:09:07.740]  И они это понимают.
[01:09:07.740 --> 01:09:09.740]  А вот этот вот доресок, они вообще не понимают.
[01:09:09.740 --> 01:09:10.740]  Это что за хрень?
[01:09:10.740 --> 01:09:11.740]  Зачем это надо?
[01:09:11.740 --> 01:09:12.740]  Зачем это надо?
[01:09:12.740 --> 01:09:15.740]  Потому что у нас есть глобальные проблемы с ФП.
[01:09:15.740 --> 01:09:19.740]  И из-за этого может получиться так, что мы возьмем такую
[01:09:19.740 --> 01:09:21.740]  УКСИ, что вот эта вещь вообще не определена.
[01:09:21.740 --> 01:09:23.740]  А если она не определена, то нафиг нам вообще этот
[01:09:23.740 --> 01:09:25.740]  весь тервер нужен, если мы не сможем отвечать на
[01:09:25.740 --> 01:09:30.740]  вопрос о том, какая вероятность того, что у нас будет обрамовка.
[01:09:30.740 --> 01:09:32.740]  Идея ясна?
[01:09:32.740 --> 01:09:33.740]  Хорошо.
[01:09:33.740 --> 01:09:37.740]  Я напомню еще раз, зачем нужен вот этот вот кусок
[01:09:37.740 --> 01:09:38.740]  с тервером.
[01:09:38.740 --> 01:09:41.740]  Мы как бы обозначаем проблемы, которые мы будем решать.
[01:09:41.740 --> 01:09:44.740]  И один из больших кусков нашей второй части курса
[01:09:44.740 --> 01:09:46.740]  – это будут измеримые отображения.
[01:09:46.740 --> 01:09:49.740]  Вот эта вот вещь – это требование измеримости отображения
[01:09:49.740 --> 01:09:51.740]  УКСИ.
[01:09:51.740 --> 01:09:56.740]  Измеримые отображения, какие там есть свойства,
[01:09:56.740 --> 01:09:59.740]  там то, что есть, вы складываете измеримый, получается
[01:09:59.740 --> 01:10:02.740]  измеримый и так далее.
[01:10:02.740 --> 01:10:05.740]  Теперь следующие объекты, которые у нас связаны
[01:10:05.740 --> 01:10:07.740]  со случайной величиной.
[01:10:07.740 --> 01:10:11.740]  Это определение, оно выглядит довольно случайно.
[01:10:11.740 --> 01:10:14.740]  Вы выбрали какое-то множество, которое мы считаем приятным
[01:10:14.740 --> 01:10:15.740]  и красивым.
[01:10:15.740 --> 01:10:16.740]  Для всех?
[01:10:16.740 --> 01:10:17.740]  Нет.
[01:10:17.740 --> 01:10:18.740]  Б.
[01:10:18.740 --> 01:10:19.740]  Бетатер.
[01:10:19.740 --> 01:10:22.740]  Это просто что, с чем мы такие…
[01:10:22.740 --> 01:10:24.740]  Это то, что нам нужно.
[01:10:24.740 --> 01:10:26.740]  Это еще раз.
[01:10:26.740 --> 01:10:28.740]  Берелевская сигма алгебра – это сигма алгебры, которая
[01:10:28.740 --> 01:10:30.740]  содержит все множества, которые нам в принципе
[01:10:30.740 --> 01:10:31.740]  могут понадобиться.
[01:10:31.740 --> 01:10:38.740]  Ну то есть, еще раз, мы не можем определить для всех
[01:10:38.740 --> 01:10:40.740]  под множество прямой, потому что, как мы выяснили
[01:10:40.740 --> 01:10:42.740]  в случае неизмеримого полебегу, есть множество, которым
[01:10:42.740 --> 01:10:45.740]  даже представить себе не множим, но они хреновы.
[01:10:45.740 --> 01:10:47.740]  У них даже там полебегу не измерим.
[01:10:47.740 --> 01:10:50.740]  Так и не надо с ними работать.
[01:10:50.740 --> 01:10:52.740]  Не нужны они.
[01:10:52.740 --> 01:10:54.740]  Мы же все-таки для провожений делаем.
[01:10:54.740 --> 01:10:56.740]  А людям нужно отвечать вот на такие вопросы.
[01:10:56.740 --> 01:10:59.740]  Больше, меньше чисел, принадлежат отрезку.
[01:10:59.740 --> 01:11:01.740]  Этого достаточно.
[01:11:01.740 --> 01:11:03.740]  То есть часто у меня вот там…
[01:11:03.740 --> 01:11:06.740]  Ну вот мы читали у химиков теории вероятности.
[01:11:06.740 --> 01:11:08.740]  На химфаке у нас была предпрактика.
[01:11:08.740 --> 01:11:11.740]  И там, знаете, как определяли Берелевскую сигму алгебру?
[01:11:11.740 --> 01:11:13.740]  Сигма алгебра состоящая из хороших множеств.
[01:11:13.740 --> 01:11:15.740]  Это прямо определение было написано.
[01:11:15.740 --> 01:11:19.740]  Не, ну слушайте, им вот это вообще нереально рассказать.
[01:11:19.740 --> 01:11:22.740]  При этом человек, который читал, он как бы ученый,
[01:11:22.740 --> 01:11:24.740]  профессор и так далее, он не мог ахинею нести.
[01:11:24.740 --> 01:11:27.740]  Ну, в плане написать.
[01:11:27.740 --> 01:11:29.740]  Поэтому он писал Берелевскую сигму алгебру,
[01:11:29.740 --> 01:11:31.740]  когда у него спрашивали, что это такое, он говорил,
[01:11:31.740 --> 01:11:33.740]  ну это все хорошие множества напрямую.
[01:11:33.740 --> 01:11:35.740]  И достаточно.
[01:11:35.740 --> 01:11:38.740]  Вот у вас будет отдельный семинар, посвященный к тому,
[01:11:38.740 --> 01:11:40.740]  что вы разобрались с ней,
[01:11:40.740 --> 01:11:42.740]  потому что поняли, из чего она состоит.
[01:11:42.740 --> 01:11:44.740]  Хорошо?
[01:11:44.740 --> 01:11:47.740]  Так, следующее это распределение случайной величины.
[01:11:50.740 --> 01:11:52.740]  Распределение случайной величины.
[01:11:52.740 --> 01:11:56.740]  Я вернусь к мысли о том, что нас не очень интересует
[01:11:56.740 --> 01:11:58.740]  значение,
[01:11:58.740 --> 01:12:01.740]  конкретное значение кси от омега.
[01:12:01.740 --> 01:12:03.740]  Почему мы омегу не знаем?
[01:12:06.740 --> 01:12:08.740]  Тут что возникает?
[01:12:08.740 --> 01:12:10.740]  На том, что если у вас есть случайная величина,
[01:12:10.740 --> 01:12:15.740]  то вслед за ней получается множество значений.
[01:12:16.740 --> 01:12:18.740]  Случайной величины.
[01:12:20.740 --> 01:12:23.740]  Поскольку мы сейчас работаем только лишь в этой ситуации,
[01:12:23.740 --> 01:12:26.740]  когда у нас омега это дискретное
[01:12:26.740 --> 01:12:28.740]  вероятностное пространство,
[01:12:28.740 --> 01:12:31.740]  то и значение у нас тоже не более чем счетное количество.
[01:12:31.740 --> 01:12:33.740]  Это понятно?
[01:12:33.740 --> 01:12:35.740]  Кивните.
[01:12:35.740 --> 01:12:37.740]  Я сейчас бы сказал простую вещь.
[01:12:37.740 --> 01:12:39.740]  Область определения функций не более чем счетный,
[01:12:39.740 --> 01:12:42.740]  значит множество значений функций тоже не более чем счетно.
[01:12:46.740 --> 01:12:48.740]  И тогда что получается?
[01:12:48.740 --> 01:12:50.740]  Каждому значению
[01:12:50.740 --> 01:12:52.740]  к каждому значению
[01:12:52.740 --> 01:12:54.740]  случайной величины
[01:12:54.740 --> 01:12:56.740]  мы можем поставить в соответствии
[01:12:56.740 --> 01:12:59.740]  вероятность, с которой принимается это значение.
[01:12:59.740 --> 01:13:01.740]  Что такое по ката?
[01:13:01.740 --> 01:13:03.740]  Это вероятность того,
[01:13:03.740 --> 01:13:05.740]  что кси от омега
[01:13:05.740 --> 01:13:07.740]  равняется х ката.
[01:13:14.740 --> 01:13:16.740]  То есть значение случайной величины
[01:13:16.740 --> 01:13:19.740]  и вероятность этих значений.
[01:13:19.740 --> 01:13:21.740]  Давайте по примерам пойдем.
[01:13:25.740 --> 01:13:27.740]  Примеры.
[01:13:27.740 --> 01:13:30.740]  Первая это Бернулевская случайная величина.
[01:13:30.740 --> 01:13:32.740]  Не путайте с Берномиальной.
[01:13:32.740 --> 01:13:34.740]  Бернулевская.
[01:13:34.740 --> 01:13:36.740]  Извините, Бернулевская распределение.
[01:13:36.740 --> 01:13:38.740]  Ой, ей плохо. Извините.
[01:13:38.740 --> 01:13:40.740]  Бернулевская распределение.
[01:13:42.740 --> 01:13:44.740]  То есть у вас два значения.
[01:13:44.740 --> 01:13:46.740]  То есть это подбрасывание монетки кривой.
[01:13:48.740 --> 01:13:50.740]  Х ката у вас
[01:13:50.740 --> 01:13:52.740]  извините
[01:13:52.740 --> 01:13:54.740]  состоит из двух значений
[01:13:54.740 --> 01:13:56.740]  нолика и единичка.
[01:13:56.740 --> 01:13:58.740]  При этом вероятность нолика
[01:13:58.740 --> 01:14:00.740]  у вас единичка минус п.
[01:14:00.740 --> 01:14:02.740]  Вероятность единички у вас п.
[01:14:02.740 --> 01:14:04.740]  П это какая-то чиселка от 0 до 1.
[01:14:14.740 --> 01:14:18.740]  Х ката.
[01:14:18.740 --> 01:14:20.740]  Еще раз.
[01:14:20.740 --> 01:14:22.740]  У вас к пробегает
[01:14:22.740 --> 01:14:24.740]  либо конечное, либо счетное множество значений
[01:14:26.740 --> 01:14:28.740]  которые соответствуют номеру значения
[01:14:28.740 --> 01:14:30.740]  своей случайной величины.
[01:14:30.740 --> 01:14:32.740]  А п ката это вероятность
[01:14:32.740 --> 01:14:34.740]  этого значения.
[01:14:34.740 --> 01:14:36.740]  Хорошо, с тем же самым индексом.
[01:14:36.740 --> 01:14:38.740]  Первый это Бернулевское распределение.
[01:14:38.740 --> 01:14:40.740]  Будет иногда в задачах
[01:14:40.740 --> 01:14:42.740]  вылезать.
[01:14:42.740 --> 01:14:44.740]  conquer это биномеальное распределение.
[01:14:52.740 --> 01:14:54.740]  Биномеальное распределение
[01:14:54.740 --> 01:14:56.740]  у каждого распределения
[01:14:56.740 --> 01:14:58.740]  естественно своей физический смысл
[01:14:58.740 --> 01:15:00.740]  это распределение числа успеха
[01:15:00.740 --> 01:15:02.740]  в схеме испытаний Бернуля.
[01:15:02.740 --> 01:15:04.740]  Бернулиское распределение здесь,
[01:15:04.740 --> 01:15:06.740]  а здесь биномеальное это
[01:15:06.740 --> 01:15:08.740]  число успеха в схеме испытаний Бернуля.
[01:15:08.740 --> 01:15:10.740]  Постарайтесь не путаться пожалуйста,
[01:15:10.740 --> 01:15:22.940]  сложное, я понимаю, распределение числа успехов в схеме испытаний
[01:15:22.940 --> 01:15:29.940]  Берноль.
[01:15:29.940 --> 01:15:32.900]  Ну давайте его как бы найдем, хотя вы его и так уже знаете,
[01:15:32.900 --> 01:15:48.980]  мы его несколько раз выводили, то есть у вас омега это есть и 1 и так далее и n,
[01:15:48.980 --> 01:15:57.980]  и кси от омега это есть сумма и жидкость, то есть количество успехов, успех у нас это единичка.
[01:15:57.980 --> 01:16:13.340]  Ну то есть смотрим кси от омега какие значения принимает от 0 до n, ну то есть n плюс одно значение,
[01:16:13.340 --> 01:16:24.100]  то есть получается хкт у вас равно просто k, где k принадлежит множеству от 0 до n. Теперь погнали
[01:16:24.100 --> 01:16:31.700]  вероятности, то есть тогда у нас пкт это будет вероятность того, что кси от омега равно ну просто
[01:16:31.700 --> 01:16:36.500]  k. Мы с вами это считали, а на чему там было равно?
[01:16:36.500 --> 01:16:48.180]  Был такой, да? Это мы с вами выводили даже.
[01:16:48.180 --> 01:17:07.780]  Так, третье, полосоновское распределение, нет давайте геометрическое, геометрическое распределение.
[01:17:07.780 --> 01:17:32.340]  Сумма пкт всегда единица. Ну давайте посмотрим, хкты это все значения случайной величины,
[01:17:32.340 --> 01:17:42.180]  так? Если мы просуммируем все пкты, что мы получим? То есть это сумма по всем хкт принадлежащим х,
[01:17:42.180 --> 01:17:50.500]  вероятности того, что кси равняется хкт. То есть получается эта вероятность получается какого события?
[01:17:50.500 --> 01:17:56.700]  Они же все не пересекаются между собой, кси одномоменно не может принимать два значения,
[01:17:56.700 --> 01:18:01.940]  то есть эти все события между собой не пересекаются, это видно? Хорошо, и если, то есть мы их можем
[01:18:01.940 --> 01:18:06.340]  вместе собрать, эти события, поскольку мы складываем эти вероятности, вот если мы их вместе соберем,
[01:18:06.340 --> 01:18:18.740]  мы получим какое событие? А чему равна вероятность того, что что-то произошло? Да, мы говорили,
[01:18:18.740 --> 01:18:28.020]  что вероятность всего Омега у нас 1 обязательно. Так, геометрическое распределение, помните,
[01:18:28.020 --> 01:18:36.580]  мы с вами строили модельку, в которой Тихон Безобразничий играл, пока не выиграет, было такое.
[01:18:36.580 --> 01:18:46.340]  Ну то есть опять же тут можно случайно начинать, это что такое? Это номер эксперимента, на котором
[01:18:46.340 --> 01:18:54.140]  Тихон выиграет, да? Ура! То есть получается у нас хкт, это что? Номер, на котором он выиграет,
[01:18:54.140 --> 01:18:59.820]  это либо первый бросок, либо второй, и так далее до бесконечности. Ну то есть это первое распределение,
[01:18:59.820 --> 01:19:09.900]  где у нас бесконечное число значений. Какие пкт получались? То есть пкт это вероятность того,
[01:19:09.900 --> 01:19:23.300]  что кси равно ка, то есть Тихон выиграл на катом шаге. Чему она там была равна? 1-p в степени k-1 умножить
[01:19:23.300 --> 01:19:34.340]  на p. Всё. Тут есть небольшие, так, во-первых, как бы два замечания. Первое, геометрическая
[01:19:34.340 --> 01:19:38.740]  вероятность и геометрическое распределение, это вообще разные вещи, никак с собой не связаны.
[01:19:38.740 --> 01:19:45.780]  Геометрическая вероятность это такое короткое название вот той вот модели, когда мы точку бросали
[01:19:45.780 --> 01:19:53.180]  на под множество rn, конечные меры. Помните, да? Вот это вот как бы геометрическая вероятность,
[01:19:53.180 --> 01:19:57.260]  а геометрическое распределение, это вот такое вот дискретное распределение, у которого такие
[01:19:57.260 --> 01:20:03.700]  значения с такими вероятностями. Это понятно? И четвертый пункт, это Пуассоновское распределение.
[01:20:03.700 --> 01:20:12.420]  Мы его напишем, разойдемся. Что такое Пуассоновское распределение? Я думаю, на семинарах вы
[01:20:12.420 --> 01:20:20.980]  с ними уже пересекались? Нет? Ну, то есть у нас здесь x катор, это есть 0, 1, извините,
[01:20:20.980 --> 01:20:31.060]  принадлежит. 0, 1, 2 и так далее. Что-то я, слушайте, если я какую-то дичь пишу, правьте меня, пожалуйста, ладно?
[01:20:31.060 --> 01:20:40.900]  То есть значения у нас вот такие, а вероятности у нас вот такие. Лямда в степени k делить на k
[01:20:40.900 --> 01:20:56.020]  факториал на e в степени минус лямда. Лямда это какая-то чиселка больше нуля. Вот это самая
[01:20:56.020 --> 01:21:01.460]  правильная реакция, которая должна быть на эту строчку. То есть если вы откроете как бы вот любую
[01:21:01.460 --> 01:21:07.100]  там книжку по терверу, там вот эта вот вещь, рассмотрим Пуассоновское распределение. Пуассоновское
[01:21:07.100 --> 01:21:13.220]  распределение это вот такое. Можно, кстати, проверить, что это действительно распределение,
[01:21:13.220 --> 01:21:18.380]  то есть сумма действительно будет 1. Давайте это просуммируем быстро. Сумма пока от нуля до плюс
[01:21:18.380 --> 01:21:24.180]  бесконечности, лямда в степени k на k факториал на e в степени минус лямда. Кто в состоянии
[01:21:24.180 --> 01:21:29.900]  просуммировать этот ряд? Ваши предшественники очень плохо, кстати, справлялись? Ну типа мы знаем
[01:21:29.900 --> 01:21:40.220]  ответ. Да, это хорошо. А как единицу из этого получить? Кто узнал экспоненту? Ну то есть, ну почти.
[01:21:40.220 --> 01:21:46.540]  Вот если вот эту хрень вынести, она же от k не зависит. Это нормирующий множитель. Если вынести за
[01:21:46.540 --> 01:21:50.980]  знак суммирования, это в чистом виде экспонента, то есть e в степени лямда. А вот это e в степени
[01:21:50.980 --> 01:21:56.060]  минус лямда это просто нормирующий множитель. И действительно получается 1. То есть это действительно
[01:21:56.060 --> 01:22:01.460]  распределение. То есть вот значение, вот их вероятности, вероятности больше нуля, сумма равна
[01:22:01.460 --> 01:22:07.980]  единице, все хорошо. Но как бы реакция какая должна быть? Откуда эта дичь взялась? Ну ладно,
[01:22:07.980 --> 01:22:11.820]  хорошо, мы взяли распределение экспонента, но у нас много каких распределений есть. Причем
[01:22:11.820 --> 01:22:17.060]  тут вообще нафиг экспонент? А это мы узнаем в следующей лекции. Все приходите.
