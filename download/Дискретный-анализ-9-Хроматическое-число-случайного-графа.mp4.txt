[00:00.000 --> 00:09.520]  Мы продолжаем, товарищи, заниматься хроматическим числом случайного графа,
[00:09.520 --> 00:16.640]  и мы дошли до момента, когда у нас p равняется c поделить на n. С этим моментом мы подробно в
[00:16.640 --> 00:22.800]  прошлый раз разбирались. Вот сейчас я сформулирую совершенно замечательный результат, который
[00:22.800 --> 00:28.800]  доказан уже для случая, когда p все еще стремится к нулю, но стремится к нулю медленнее, чем c поделить
[00:28.800 --> 00:40.600]  на n. Теорема, наверное, в самом лучшем, который известен сейчас в своем виде, она звучит так.
[00:40.600 --> 00:54.960]  Пусть p как функция от n, p это вероятность ребра, естественно, по-прежнему, это есть n в степени
[00:54.960 --> 01:14.080]  минус альфа, где альфа принадлежит вот такому вот интервалу от 1 и 2 до единицы. Ну, то есть альфа
[01:14.080 --> 01:18.960]  строго меньше единицы, это означает, что n в степени минус альфа, если не стремится к нулю,
[01:18.960 --> 01:24.800]  конечно, стремится к нулю, то во всяком случае медленнее, чем единица поделить на n. Но все-таки
[01:24.800 --> 01:31.720]  альфа это не ноль. Альфа больше 1 и 2, это стремится к нулю с достаточно большой скоростью. Так вот,
[01:31.720 --> 01:47.840]  тогда существует такая у, которая зависит от n и от альфа. Ну, некоторая функция t и от альфы
[01:47.840 --> 01:59.320]  для каждого альфа своя, то асимпатически почти, наверное, хроматическое число случайного
[01:59.320 --> 02:10.320]  графа, здесь g, это g от n, p, случайный граф, принадлежит вот такому вот множеству. Ну, я в прошлый
[02:10.320 --> 02:17.560]  раз очень старательно давил на то, что хроматическое число плотно концентрируется. Помните, я много раз
[02:17.560 --> 02:25.880]  произносил такие слова. Но тогда оно концентрировалось в одном значении вообще. То есть, сначала оно
[02:25.880 --> 02:31.480]  равнялось единице асимпатически почти, наверное, потом двойке, потом тройке. Оказывается, что если
[02:31.480 --> 02:37.120]  перескочить через вот этот вот порог c поделить на n и отправиться к нулю по вероятности ребра
[02:37.120 --> 02:42.040]  медленнее, то возникает уже некая функция. Эта функция на самом деле стремится к бесконечности,
[02:42.760 --> 02:49.720]  при n стремящемся к бесконечности. Но тем не менее, несмотря на то, что она растет из множества всех
[02:49.720 --> 02:56.840]  значений, какие могло бы принимать хроматическое число, а их n штук, оно выбирает почти всегда
[02:56.840 --> 03:05.800]  только эти два. Тоже высочайшая плотность концентрации, но чуть-чуть более низкая в двух значениях. И это
[03:05.800 --> 03:12.520]  по делу, там действительно два значения. То есть концентрации в одном значении там нет. Это тяжелая
[03:12.520 --> 03:18.280]  теорема. В такой формулировке я не буду ее доказывать. Я докажу более простой, тоже совершенно
[03:18.280 --> 03:23.560]  нетривиально. Тоже может быть опущу некоторые детали, но там очень красиво, там очень важная
[03:23.560 --> 03:32.240]  идея с концентрацией меры. Я докажу вариант, когда а больше чем две третих, то есть слабее не
[03:32.240 --> 03:38.600]  больше, чем одна вторая, а больше, чем две третьих. Более узкий интервал будет. И я докажу,
[03:38.600 --> 03:48.080]  что концентрация в четырех значениях имеет место, а не в двух, как мы сейчас знаем. Четырех.
[03:48.080 --> 03:56.800]  Но это слабее, но все равно круто, потому что не растет множество значений, не стремится к
[03:56.800 --> 04:04.240]  бесконечности. Значения самого У при разных Н разные. Они растут, стремятся к бесконечности. Но
[04:04.240 --> 04:11.040]  множество значений самого хроматического числа все время остается мощности 4 или даже меньше. Вот мы
[04:11.040 --> 04:18.480]  знаем, что два, но два не докажем. Докажем 4. Но это мы, боюсь, не сегодня докажем, хотя черт его знает,
[04:18.480 --> 04:24.800]  может повезет. Это непростой результат. Тут нужно будет сделать некоторое количество лирических
[04:24.800 --> 04:30.680]  отступлений, но не совсем лирических, конечно, а математических. Вот мы с вами пользовались чем? Мы
[04:30.680 --> 04:38.800]  с вами пользовались неравенством Чебышова до сих пор. Когда мы доказывали концентрацию меры,
[04:38.800 --> 04:45.280]  что с вероятностью стремящести к единице что-то там тесно очень принимает значение около своего
[04:45.280 --> 04:51.520]  среднего, мы пользовались неравенством Чебышова. Вот сейчас я как раз хочу доказать эту теорему,
[04:52.000 --> 04:58.680]  показав, что неравенство Чебышова в ней не сработает. То есть это такой результат, который не может быть
[04:58.680 --> 05:06.560]  получен с помощью неравенства Чебышова. Там потребуется более сильная оценка концентрации меры.
[05:06.560 --> 05:13.640]  Вот я обращусь к слушателям. Было ли у вас в курсе теории вероятности что-нибудь кроме неравенства
[05:13.640 --> 05:20.200]  Чебышова? Оценки уклонений какие-нибудь или еще что-то? Это иногда бывает рассказано.
[05:20.200 --> 05:27.520]  Случайные блуждания. Но тогда я расскажу. Я люблю это рассказывать. Нам это все равно потребуется
[05:27.520 --> 05:34.400]  еще потом, когда раскрасками, другими там для гиперграфов будем заниматься. В общем, там много
[05:34.400 --> 05:37.960]  для чего это нужно. История начинается со случайного блуждания.
[05:43.960 --> 05:44.600]  Напрямую.
[05:44.600 --> 06:05.160]  Что имеется в виду? Очень простой процесс. Есть обычная бесконечная прямая. На ней имеются целые
[06:05.160 --> 06:17.000]  числа, целые точки. Ну, в шуточной интерпретации можно сказать так, что вот здесь в начале координат
[06:17.000 --> 06:25.280]  находится кабак. Из этого кабака выходит пьяница, который настолько пьян, что ему уже, в общем,
[06:25.280 --> 06:31.080]  совершенно без разницы идти направо или идти налево. Ну, соответственно, с вероятностью 1,
[06:31.080 --> 06:40.560]  2 он отправляется в точку 1. С вероятностью 1, 2 он перемещается в точку минус 1. Дальше в
[06:40.560 --> 06:47.040]  соответствующей точке, куда он отправился, чуть-чуть покачался. И снова, по независящим ни от чего,
[06:47.040 --> 06:54.360]  ну как сказать, обстоятельствам, в общем, принял решение идти куда-то дальше. Например, пришел
[06:54.360 --> 07:00.760]  сюда сначала, покачался, пошел обратно. Или нет, может быть, пошел сюда. И так каждый раз с
[07:00.760 --> 07:08.440]  вероятностью 1, 2 он смещается то ли направо, то ли налево. Ну, можно, конечно, обобщать эту
[07:08.440 --> 07:14.160]  ситуацию. Представить себе, например, что дорога не стопроцентно ровная, как здесь нарисована,
[07:14.160 --> 07:18.520]  а какая-нибудь вот такая. Тогда он с большей вероятностью покатится вниз, чем станет
[07:18.520 --> 07:25.400]  подниматься наверх. Ну, то есть, можно заменить 1, 2, 1, 2 на какие-то пояку. Фактически мы будем
[07:25.400 --> 07:34.680]  иметь дело со схемой испытаний Бернуль. Вот. Ну, или можно так описать этот процесс. Есть кси1,
[07:34.680 --> 07:45.840]  так далее, ксен, независимые случайные величины, независимые в совокупности, то есть,
[07:45.840 --> 07:54.320]  взаимно независимые, не попарно там, взаимно независимые. Вот. Которые устроены следующим
[07:54.320 --> 08:03.400]  образом. Кси1 равняется плюс 1 с вероятностью 1, 2 и минус 1 тоже с вероятностью 1, 2.
[08:03.400 --> 08:17.360]  Тогда это с индексом n равное кси1, плюс и так далее, плюс ксен, это положение пьяницы в момент
[08:17.360 --> 08:27.920]  времени, точка, в которую он пришел. Вот пафос, который я всегда сюда вкладываю. Ну, то ли почему
[08:27.920 --> 08:36.680]  пить меньше надо, то ли почему алкоголизм случается. Дело в том, что этот процесс устроен
[08:36.680 --> 08:44.480]  следующим образом. Крайне мала вероятность, с которой пьяница далеко уйдет от кабака. А вот
[08:44.480 --> 08:49.440]  насколько она мала, действительно, вот очень естественный вопрос. Мы хотим посчитать вероятность,
[08:49.440 --> 08:58.260]  которой это n больше какого-то, или может быть, больше либо равняется. Ну, первое,
[08:58.260 --> 09:07.600]  что приходит в голову, это использовать неравенство Чебышова. Написать, давайте,
[09:07.600 --> 09:19.200]  как написать? А вот так написать. Минус мат ожидания это n больше, чем а минус мат ожидания это n.
[09:19.200 --> 09:25.200]  Ну, просто тупо вычитаем мат ожидания слева справа, правильно? Неравенство. Но
[09:25.200 --> 09:39.320]  чему равно мат ожидания это n? Нулю, конечно, да. Ну, потому что мат ожидания линейна, а тут они еще
[09:39.320 --> 09:46.160]  и независимая, но она всегда линейна. То есть, мат ожидания каждой это 0, очевидно, сумма нулей это
[09:46.160 --> 09:55.200]  тоже 0. Ну, то есть, фактически, это можно вот так написать вероятность того, что это n. Здесь 0 не
[09:55.200 --> 10:01.520]  писать, а вычесть все-таки мат ожидания, а справа убрать мат ожидания, вспомнив, что оно равно нулю.
[10:01.520 --> 10:07.360]  Вот тогда это предельно похоже на неравенство Чебышова. То есть, это получается не больше,
[10:07.360 --> 10:16.480]  чем вероятность, с которой модуль этой разности больше, чем а, а это по неравенству Чебышова не
[10:16.480 --> 10:28.040]  больше, чем d это n, n поделить на а в квадрате. Так, дисперсия этой n какая? Они независимы,
[10:28.040 --> 10:38.160]  поэтому дисперсия суммы это сумма дисперсий. Ну, какая дисперсия у каждой из них? Мат ожидания
[10:38.160 --> 10:46.560]  0, а мат ожидания квадрата, то есть, второй момент один же, но из-за единицы вычитаем 0, получаем
[10:46.560 --> 10:57.800]  единицу и складываем n таких единиц. То есть, будет n поделить на а в квадрате. Ну, вроде неплохо,
[10:57.800 --> 11:04.040]  то есть, вероятность удалиться на расстояние больше, чем корень из n по порядку, она уже стремится к нулю.
[11:04.040 --> 11:24.560]  Так, а я утверждаю, это теория, то вероятность, которой это n больше, чем а, она не превосходит
[11:24.560 --> 11:33.200]  куда-как меньшей величины, а именно вот такой. Я в степени минуса квадрат поделить на двое.
[11:39.920 --> 11:45.200]  Ну, это узнаваемо в принципе, то есть, у вас видимо была какая-нибудь там предельная теория
[11:46.080 --> 11:55.080]  или не было? Не было, да? Ну, не важно. Ну, вы знаете, нормальное распределение, там оно как-то вот так
[11:55.080 --> 12:02.360]  выглядит, е в степени минус х квадрат пополам. То есть, что-то такое узнаваемое, но почему это просто
[12:02.360 --> 12:09.040]  несопоставимо меньше, чем то, что нам дает неравенство Чебышова. С точки зрения, понимаете, той границы,
[12:09.040 --> 12:14.000]  начиная с которой вероятность стремится к нулю, ничего нового не случилось. Как здесь а должно
[12:14.000 --> 12:19.000]  быть больше-больше, чем корень из n. Так и здесь, конечно, а должно быть больше-больше, чем корень из n.
[12:19.000 --> 12:24.520]  Иначе стремления к нулю не будет. Но здесь оно как бы сверхэкспоненциальное, а здесь оно полином.
[12:24.520 --> 12:32.000]  Ну, можно просто явный пример привести. Представьте себе, что n это 10 в шестой, а это 10 в четвертый.
[12:32.000 --> 12:39.480]  То есть, пьянице предоставлено время порядка 12 суток, если он каждую секунду перемещается в каждую
[12:40.480 --> 12:46.480]  Ну, делает очередной шаг. Если он делает очередной шаг раз в секунду, то это 12 суток нетрезвения.
[12:46.480 --> 12:57.480]  Какой ужас. С какой вероятностью, спрашивается, за миллион шагов он отойдет от кабака хотя бы на расстоянии 10 в четвертый.
[12:57.480 --> 13:06.480]  Но неравенство Чебышова нам говорит, давайте разделим 10 в шестой на 10 в восьмой и получим одну сотую.
[13:07.480 --> 13:14.480]  Ну, это, в общем, маленькая вероятность. А неравенство, которое я утверждаю, что на самом деле верно и уже почти не улучшаемо.
[13:14.480 --> 13:24.480]  Это теорема близка к точной. Это е в степени минус 50. Ну, потому что здесь стоит то же самое.
[13:24.480 --> 13:30.480]  10 в восьмой поделить на 10 в шестой. Это 100, но пополам еще 50. Это е в минус 50 степени.
[13:30.480 --> 13:39.480]  То есть, если глядя на это, пьяница может сказать, ну дайте мне 120 дней, я 100 раз напьюсь и каждый раз по 12 дней буду ходить.
[13:39.480 --> 13:49.480]  Не трезвее, да? Ну, какой-то шанс уже есть, что вероятность может приблизиться к единице того, что я уйду на расстоянии 10 тысяч.
[13:49.480 --> 13:56.480]  Но когда мы ему показываем вот это, он понимает, что это все. Это уже, знаете, есть такая история про квадриллион километров.
[13:56.480 --> 14:06.480]  Это все. Это он никогда не пройдет. Ну или когда-нибудь пройдет. Тот-то прошел, может этот пройдет, но немножко грустно.
[14:06.480 --> 14:17.480]  Да. Вот. Сейчас я это докажу. Доказывается очень красиво, очень просто, но неожиданно.
[14:17.480 --> 14:24.480]  То есть, ты не придумаешь сам такое, если не знаешь ответ. В каком-то смысле ответ подсказывает, как нужно доказывать.
[14:24.480 --> 14:29.480]  Но тоже, конечно, это круто.
[14:34.480 --> 14:43.480]  Так, доказываем. Надо как-то... А, сейчас затру. Отделяем. Уже не нужно.
[14:43.480 --> 14:46.480]  Так, доказательства.
[14:46.480 --> 15:01.480]  Ну, вероятность того, что это n больше, чем a, это разумеется вероятность того, что лямбда это n больше, чем лямбда a, если лямбда это какая-то положительная величина любая.
[15:01.480 --> 15:05.480]  Просто взял и домножил на положительное число.
[15:05.480 --> 15:15.480]  Но тот ход, до которого трудно додуматься, это, конечно, мистика некая. Давайте возьмем экспоненту от каждой из частей неравенства.
[15:15.480 --> 15:28.480]  Ну, экспонентом анатонная функция, поэтому это корректное действие. E в степени лямбда это n больше, чем E в степени лямбда. Это тоже правильно.
[15:28.480 --> 15:38.480]  А тут применим неравенство банальное, Чебышовское по сути, неравенство Маркова. То есть Чебышова же применим, но вот к такой хитрой штуке.
[15:38.480 --> 15:46.480]  Ну, не совсем Чебышова, прототип Чебышова, прообраз Маркова. Это же положительно значная случайная величина, это положительное число.
[15:46.480 --> 16:03.480]  Значит, можно применить неравенство Маркова. У нас получится E в степени минус лямбда А на математическое ожидание E в степени лямбда это n.
[16:03.480 --> 16:09.480]  Это же неравенство Маркова. Ну, мы берем мат ожидания того, что здесь, и делим на то, что справа.
[16:09.480 --> 16:14.480]  Но поделить на E в степени лямбда это умножить на E в степени минус лямбда.
[16:14.480 --> 16:20.480]  Так, ну здесь вот все замечательно и просто, потому что E в степени лямбда это n.
[16:20.480 --> 16:29.480]  Это E в степени сумма кси один кси n. А кси один кси n независимы, и тут важно уже, что совокупности.
[16:29.480 --> 16:35.480]  Потому что E в степени суммы это произведение.
[16:35.480 --> 16:47.480]  E в степени минус лямбда А на произведение по E от единицы до n E в степени лямбда кси. Вот так.
[16:47.480 --> 16:53.480]  Ой, мат ожидания потерялась. Вот так.
[16:54.480 --> 16:58.480]  А мат ожидания произведения независимых случайных величин.
[16:58.480 --> 17:03.480]  Ну, очевидно, что если кси это независимо, то и экспоненты от лямбда кси это тоже независимые величины.
[17:03.480 --> 17:09.480]  Мат ожидания именно произведения независимых совокупностей величин, это произведение мат ожидания.
[17:09.480 --> 17:19.480]  То есть мы можем вот так переписать E в степени минус лямбда А на произведение по E от единицы до n.
[17:20.480 --> 17:23.480]  Ожидание E в степени лямбда кси.
[17:23.480 --> 17:28.480]  Какое же математическое ожидание у E в степени лямбда кси?
[17:28.480 --> 17:32.480]  Ну, кси это принимает всего два значения, плюс-минус один.
[17:32.480 --> 17:41.480]  Каждая с вероятностью одна-вторая. То есть мы просто подставляем сюда единичку, делим пополам, и плюс подставляем сюда минус единичку, делим пополам.
[17:41.480 --> 17:45.480]  Вообще сумма, которая получится, называется чосинус.
[17:45.480 --> 17:49.480]  Ну, E в степени минус лямбда плюс E в степени лямбда, и все пополам.
[17:49.480 --> 17:55.480]  Ну, нам не так важно. Давайте я лучше распишу, потому что я лично не помню наизусть ряд Тейлора для чосинуса.
[17:55.480 --> 17:58.480]  А для каждой из экспонентов, которые получится, я помню.
[17:58.480 --> 18:01.480]  И как он свернется, ну, вот так и будет для чосинуса.
[18:01.480 --> 18:05.480]  Сейчас нам это понадобится. E в степени минус лямбда А.
[18:05.480 --> 18:11.480]  Произведение по E от единицы до n.
[18:11.480 --> 18:18.480]  Так, E в степени лямбда плюс E в степени минус лямбда пополам.
[18:18.480 --> 18:21.480]  Ну, и вообще говоря, перемножается-то одно и то же.
[18:21.480 --> 18:25.480]  Поэтому давайте я вот так припишу. E в степени минус лямбда А.
[18:25.480 --> 18:33.480]  E в степени лямбда плюс E в степени минус лямбда пополам в n.
[18:33.480 --> 18:40.480]  Так, ну, давайте считать в каком-то смысле в уме.
[18:40.480 --> 18:43.480]  Я вспоминаю, ну, в уме не в уме.
[18:43.480 --> 18:50.480]  Сумма по k от нуля до бесконечности лямбда вкатый на k факториал.
[18:50.480 --> 18:54.480]  Это экспоненты E в степени лямбда по Тейлору.
[18:54.480 --> 18:59.480]  А если брать E в степени минус лямбда, то будет так вот.
[19:00.480 --> 19:05.480]  Ну, то есть при нечетных k они друг друга убивают,
[19:05.480 --> 19:10.480]  а при четных складываются, удваиваются и потом делятся пополам.
[19:10.480 --> 19:13.480]  То есть у нас получается вот так.
[19:13.480 --> 19:16.480]  E в степени минус лямбда А.
[19:16.480 --> 19:22.480]  Сумма по k от нуля до бесконечности лямбда в степени 2k.
[19:22.480 --> 19:25.480]  Поделить на 2k факториал.
[19:25.480 --> 19:27.480]  И все это в n.
[19:29.480 --> 19:33.480]  Только четные слагаемые остаются вот здесь вот.
[19:35.480 --> 19:39.480]  Так, оцениваем это замечательно следующим образом.
[19:39.480 --> 19:43.480]  E в степени минус лямбда А, оно все время за нами ходит.
[19:43.480 --> 19:46.480]  Так, пойду-ка я сюда, то не влезет.
[19:46.480 --> 19:54.480]  Так, а здесь напишу сумма по k от нуля до бесконечности лямбда в 2к
[19:54.480 --> 19:59.480]  на 2к на k факториал в n.
[19:59.480 --> 20:03.480]  Но я абсолютно тривиально оценил снизу удвоенный k факториал,
[20:03.480 --> 20:08.480]  2k факториал величиной 2к на k факториал.
[20:08.480 --> 20:10.480]  Хуже некуда, казалось бы.
[20:10.480 --> 20:14.480]  Но надо вот так вот это изображать.
[20:14.480 --> 20:17.480]  Всегда такое орешек арахис получается.
[20:21.480 --> 20:23.480]  Ну или хотите сарделька.
[20:24.480 --> 20:28.480]  Я имею ввиду лямбда квадрат поделить на 2 и все это в катой степени.
[20:28.480 --> 20:30.480]  Видно же, да?
[20:30.480 --> 20:32.480]  Лямбда квадрат пополам в катой степени.
[20:32.480 --> 20:34.480]  То есть это снова ряд Тейлова.
[20:35.480 --> 20:38.480]  Только для E в степени лямбда квадрат пополам.
[20:38.480 --> 20:40.480]  Тут что-то появилось.
[20:40.480 --> 20:42.480]  А куда двойков знаменатели делать?
[20:42.480 --> 20:44.480]  Какая двойка знаменателя? Вот эта.
[20:44.480 --> 20:52.480]  А я же сказал, если мы складываем с нечетным k, то они кок друг друга.
[20:52.480 --> 20:57.480]  А если кочетная, они складываются и удваиваются, после чего делятся пополам.
[20:57.480 --> 21:00.480]  То есть эта двойка просто сократилась с той двойкой,
[21:00.480 --> 21:03.480]  которая могла бы возникнуть в числителе, но не возникла.
[21:05.480 --> 21:07.480]  Никакой двойки в знаменателе уже нет.
[21:07.480 --> 21:11.480]  Ну, я, конечно, могу сказать, что это меньше либо равно, чем двойка в знаменателе,
[21:11.480 --> 21:14.480]  но на самом деле она честно сократилась.
[21:14.480 --> 21:16.480]  То есть тут никаких огрублений нет.
[21:16.480 --> 21:17.480]  Действительно сократилась.
[21:17.480 --> 21:22.480]  То есть у нас получается E в степени минус лямбда вот отсюда.
[21:22.480 --> 21:29.480]  И давайте я прям вот тут, в одной и той же экспоненте, напишу лямбда квадрат пополам умножить на n.
[21:29.480 --> 21:35.480]  Лямбда квадрат пополам умножить на n.
[21:35.480 --> 21:38.480]  Это все в показателе экспонента.
[21:38.480 --> 21:40.480]  Согласны?
[21:40.480 --> 21:45.480]  Но это верно для любого лямбда положительного.
[21:45.480 --> 21:48.480]  Это такой параметр оптимизации, если хотите.
[21:48.480 --> 21:52.480]  Мы вольны выбрать лямбда так, чтобы нам было лучше всего.
[21:52.480 --> 21:53.480]  Когда нам лучше всего?
[21:53.480 --> 21:57.480]  Когда минимально выражение, стоящее в показателе экспонента.
[21:57.480 --> 22:03.480]  Нам нужна верхняя оценка, и она тем лучше, чем меньше выражение, стоящее в показателе.
[22:03.480 --> 22:06.480]  Такая-то парабола.
[22:06.480 --> 22:09.480]  Вот такая.
[22:09.480 --> 22:11.480]  Где она минимальна?
[22:11.480 --> 22:13.480]  При каком лямбда?
[22:13.480 --> 22:15.480]  Ну, там есть такая замечательная мандра.
[22:15.480 --> 22:18.480]  Называется минус b поделить на 2a.
[22:18.480 --> 22:21.480]  Но минус b здесь это a виноват.
[22:21.480 --> 22:25.480]  А 2a это n. То есть надо брать a поделить на n.
[22:25.480 --> 22:27.480]  В общем, точку, где производная зануляется.
[22:27.480 --> 22:28.480]  Понятное дело.
[22:28.480 --> 22:34.480]  Но если мы возьмем в качестве лямбда вот именно эту самую точку, где достигается минимум, то получится, товарищи.
[22:34.480 --> 22:36.480]  Но можете посчитать в аккурат вот это.
[22:36.480 --> 22:38.480]  Ну, все.
[22:43.480 --> 22:45.480]  Ну, не знаю, видно же, да.
[22:45.480 --> 22:47.480]  a квадрат поделить на n с минусом.
[22:47.480 --> 22:51.480]  А тут a квадрат поделить на 2n с плюсом.
[22:51.480 --> 22:56.480]  Поэтому все-таки будет с минусом, но на 2a.
[22:56.480 --> 23:04.480]  Вот такая вот замечательная совершенно теорема, которая говорит, что на самом деле мера гораздо плотнее концентрируется около среднего,
[23:04.480 --> 23:08.480]  чем то гарантирует неравенство Чебышова в некоторых специальных ситуациях.
[23:08.480 --> 23:10.480]  Это же очень специальная ситуация.
[23:10.480 --> 23:12.480]  Это случайное блуждание.
[23:12.480 --> 23:15.480]  Мы складываем независимые такие вот простые индикаторы.
[23:15.480 --> 23:16.480]  Плюс-минус единица.
[23:16.480 --> 23:18.480]  Ну, не совсем индикаторы, понятно.
[23:18.480 --> 23:19.480]  Ну, вот такие функтуации.
[23:19.480 --> 23:20.480]  Да, туда-обратно.
[23:20.480 --> 23:29.480]  Конечно, если случайная величина устроена гораздо сложнее, она может и лучше, чем Чебышов, не оцениваться.
[23:29.480 --> 23:32.480]  Но вот здесь получилось очень круто.
[23:32.480 --> 23:35.480]  Очень высокая плотная концентрация мира.
[23:35.480 --> 23:38.480]  Но это в каком-то смысле так, чтобы, может, нагляднее было.
[23:38.480 --> 23:44.480]  Может, знаете, что почти весь объем апельсина сконцентрирован в его корке.
[23:44.480 --> 23:46.480]  Слышали такое утверждение?
[23:46.480 --> 23:48.480]  Это вот оно же.
[23:48.480 --> 23:52.480]  Что объем шара – это тонкий слой на его поверхности.
[23:52.480 --> 23:54.480]  Это весь объем шара.
[23:54.480 --> 23:58.480]  И вот далеко идущее обобщение – это все вот про это.
[23:59.480 --> 24:02.480]  Так, ну ладно.
[24:02.480 --> 24:04.480]  Это, конечно, прекрасно.
[24:04.480 --> 24:06.480]  Но к чему бы я это?
[24:06.480 --> 24:15.480]  Мне нужно как-то на самом деле обобщить эту историю со случайным блужданием так, чтобы она помогала работать со случайными графами.
[24:15.480 --> 24:19.480]  Но со случайными графами это уже посложнее.
[24:29.480 --> 24:36.480]  Я в последние годы вот так рассказываю, как сейчас буду рассказывать, во всей полноте.
[24:36.480 --> 24:41.480]  Я не готов давать доказательства, потому что это займет много времени и вас кокнет.
[24:41.480 --> 24:43.480]  Но, может, и не кокнет.
[24:43.480 --> 24:44.480]  Я могу, конечно, дать.
[24:44.480 --> 24:48.480]  Но вот я не знаю, нужно это делать или нет, потому что все-таки второй курс.
[24:48.480 --> 24:51.480]  Но, в принципе, ничего такого технически прямо сложного там нет.
[24:51.480 --> 24:54.480]  Тем не менее, я много довольно нетривиальных вещей рассказываю.
[24:55.480 --> 25:01.480]  Значит, как для случайного графа в каком-то смысле обобщается эта история?
[25:01.480 --> 25:09.480]  Ну, это просто придется поверить пока что, потому что доказательства здесь я дал, а там давать не буду.
[25:09.480 --> 25:11.480]  Так, смотрите.
[25:11.480 --> 25:13.480]  Это обобщение для случайного графа.
[25:16.480 --> 25:19.480]  Обобщение плотной концентрации меры, скажем так.
[25:19.480 --> 25:23.480]  Для случайного графа.
[25:25.480 --> 25:27.480]  Ну, я еще подумаю, может, я и успею рассказать.
[25:27.480 --> 25:28.480]  Посмотрим.
[25:32.480 --> 25:33.480]  История такая.
[25:33.480 --> 25:35.480]  Вот есть множество всех графов на n-вершинах.
[25:44.480 --> 25:48.480]  Можно, конечно, его интерпретировать, как мы, собственно, и делаем в нашей науке.
[25:48.480 --> 25:53.480]  Интерпретировать его как, собственно, пространство элементарных событий.
[25:53.480 --> 25:56.480]  Все графы на n-вершинах это элементарные события.
[25:56.480 --> 26:00.480]  Поэтому, если мы задаем на этом множестве какую-то функцию,
[26:02.480 --> 26:06.480]  то при желании мы, конечно, можем говорить, что это случайная величина.
[26:06.480 --> 26:14.480]  Любая функция на множестве элементарных событий, если она измерима, называется случайной величиной.
[26:14.480 --> 26:19.480]  Но она измерима, потому что ω конечная, и мы рассматриваем все множества в ω как события.
[26:20.480 --> 26:22.480]  Вопросов с измеримостью не возникает.
[26:22.480 --> 26:25.480]  Любая функция может расцениваться как случайная величина,
[26:25.480 --> 26:27.480]  а можно просто говорить функция на графике.
[26:27.480 --> 26:30.480]  Число ревер, число вершин, но это константа.
[26:33.480 --> 26:38.480]  Число треугольников, хроматическое число, кликовое число и так далее.
[26:38.480 --> 26:40.480]  Любая функция может быть рассмотрена.
[26:41.480 --> 26:44.480]  Теперь, смотрите, давайте назовем эту функцию липшицовой.
[26:46.480 --> 26:47.480]  Ну, или случайную величину.
[26:47.480 --> 26:49.480]  Назовем липшицовой.
[26:52.480 --> 26:55.480]  Я, конечно, могу расстараться и написать липшицово нормально.
[26:56.480 --> 26:59.480]  Я всегда так пишу, потому что я так пишу.
[27:00.480 --> 27:03.480]  Конечно, я могу очень постараться написать вот так.
[27:07.480 --> 27:09.480]  Но это вот как подпись.
[27:11.480 --> 27:16.480]  Назовем ее липшицовой не в том смысле, в каком это обычно понимается в курсе аналогии,
[27:16.480 --> 27:20.480]  в курсе анализов. У вас, наверное, было такое понятие, да, в слове липшица?
[27:21.480 --> 27:25.480]  Ну, может, на дифурах. Не знаю, как здесь построено в этом смысле.
[27:25.480 --> 27:28.480]  Не вникал в такие детали, где обычно это рассказывают.
[27:28.480 --> 27:31.480]  Ну, это такой вот аналог гладкости, только чуть более слабый.
[27:31.480 --> 27:35.480]  Да, а здесь это комбинаторное же определение. Тут гладкости никакой нет.
[27:35.480 --> 27:40.480]  Значит, мы будем говорить, что F липшицово по ребрам
[27:42.480 --> 27:44.480]  и отдельно по вершинам.
[27:46.480 --> 27:50.480]  Два варианта липшицовости бывают. Бывает по ребрам, бывает по вершинам.
[27:50.480 --> 27:55.480]  Вот если в первом случае...
[27:55.480 --> 27:57.480]  Ну, давайте даже и в первом, и во втором.
[27:57.480 --> 28:03.480]  Модуль F от G минус F от G штрих не превосходит единице.
[28:04.480 --> 28:06.480]  Но что такое G и G штрих?
[28:06.480 --> 28:10.480]  Вот здесь лучше сопетую поставить и писать что-нибудь, типа, коль скоро.
[28:10.480 --> 28:19.480]  Коль скоро G и G штрих отличаются
[28:23.480 --> 28:25.480]  тут вот в одном ребре.
[28:27.480 --> 28:29.480]  Это когда мы говорим липшицово по ребрам.
[28:32.480 --> 28:34.480]  В окрестности одной вершины.
[28:34.480 --> 28:38.480]  Это когда мы говорим, что липшицово по вершинам.
[28:40.480 --> 28:51.480]  А, ну это какая-то известный ход.
[28:51.480 --> 28:54.480]  Пошло дело. Я говорю, в зуме лучше.
[28:54.480 --> 28:58.480]  Если только туда кто-нибудь тоже не проникнет, у нас был тут случай ужасный совершенно просто.
[28:58.480 --> 29:02.480]  Я думал, я провалюсь сквозь землю.
[29:02.480 --> 29:04.480]  Что там было?
[29:04.480 --> 29:06.480]  Да, вот видите как.
[29:06.480 --> 29:08.480]  Ну, что значит в одном ребре?
[29:08.480 --> 29:12.480]  То есть мы взяли граф G, у них одинаковое количество вершин, множество всех графов на N вершинах.
[29:12.480 --> 29:17.480]  Теперь вот мы взяли какой-то граф G на N вершинах и одно ребро из него выкинули.
[29:17.480 --> 29:19.480]  Получился G штрих.
[29:19.480 --> 29:21.480]  Или наоборот, взяли и одно ребро добавили.
[29:21.480 --> 29:23.480]  Ну понятно, это все симметрично.
[29:23.480 --> 29:26.480]  Получился G штрих. Вот не больше единицы.
[29:26.480 --> 29:30.480]  То есть если увеличение или уменьшение идет не больше чем на единицу,
[29:30.480 --> 29:34.480]  то мы говорим, что это липшицово по ребрам случайная величина F.
[29:35.480 --> 29:37.480]  А что значит в окрестности одной вершины?
[29:37.480 --> 29:40.480]  Ну это значит, что мы взяли какую-то одну вершину.
[29:40.480 --> 29:43.480]  Вот в графе G была такая окрестность, например.
[29:43.480 --> 29:47.480]  Мы можем какие-то ребра удалить, а какие-то новые добавить.
[29:47.480 --> 29:51.480]  Вот что бы такое мы не сделали, но только в окрестности одной вершины.
[29:51.480 --> 29:55.480]  Как бы мы ее не попортили, часть ребер удалив, часть ребер добавив,
[29:55.480 --> 29:58.480]  мы получим все равно отличие не больше чем на единицу.
[29:58.480 --> 30:02.480]  Но я вот сейчас пояснил, что значит разняться в одной вершине.
[30:04.480 --> 30:07.480]  У нас просто задержка идет в YouTube всегда.
[30:07.480 --> 30:10.480]  Это мне неудобно, я понимаю, что студентам удобнее смотреть в YouTube,
[30:10.480 --> 30:12.480]  а мне неудобно, потому что идет задержка,
[30:12.480 --> 30:16.480]  и вопрос появляется, когда я на него уже ответил.
[30:18.480 --> 30:19.480]  Вот.
[30:19.480 --> 30:21.480]  Ну примеры вроде бы совершенно очевидные.
[30:21.480 --> 30:24.480]  Липшицовость по ребрам – это, например, множество числа,
[30:24.480 --> 30:25.480]  Да?
[30:25.480 --> 30:26.480]  Да, конечно.
[30:26.480 --> 30:30.480]  Нет, ну ладно, можно взять какое-нибудь хроматическое число Графа,
[30:30.480 --> 30:34.480]  оно, заметьте, и по вершинам Липшиццева, и по ребрам.
[30:37.480 --> 30:40.480]  Если только в окрестности одной вершины покоцать,
[30:40.480 --> 30:45.480]  то хроматическое число в крайнем случае изменится только на цвет этой вершины.
[30:47.480 --> 30:50.480]  Тем более, если покоцать только на вершины шелка Все Area,
[30:50.480 --> 30:56.780]  этой вершины, на один. Тем более, если покоцать только в одном ребре. Ясно, что
[30:56.780 --> 31:01.780]  хроматическое число больше, чем на единице, не вырастет или не уменьшится.
[31:01.780 --> 31:05.700]  Вот, ну и можно массу других примеров приводить. А вот, скажем, число
[31:05.700 --> 31:16.540]  треугольников не является липшитом, но потому что вы можете вот такую корону
[31:16.540 --> 31:25.140]  иметь. Извините за плохие ассоциации, иметь корону. Вот иметь такую корону,
[31:25.140 --> 31:35.980]  извините. Вот, убрали одно ребро и куча треугольников долой. Ну и с вершинами
[31:35.980 --> 31:47.940]  то же самое. Там будет не корона, там будет орден такой. Удалили одну вершину,
[31:47.940 --> 31:52.180]  пропали все треугольники. То есть не все, конечно, функции липшитцевые. Бывают
[31:52.180 --> 31:59.020]  липшитцевые только по ребрам, но не по вершинам, ну и так далее. Вот, оказывается,
[31:59.020 --> 32:04.500]  что если f такая, то она в некотором смысле хорошо концентрируется, а именно
[32:04.500 --> 32:12.900]  имеет место сразу ну два утверждения, потому что для липшитцевых по ребрам одно, а по вершинам
[32:12.900 --> 32:38.340]  другое. Ну давайте я назову это теория М1 и 2. Неважно, пусть
[32:38.340 --> 33:03.220]  f липшитцево по ребрам, тогда вероятность того, что модуль f-ef больше либровняется a,
[33:03.220 --> 33:16.500]  ну это, конечно, любого а больше нуля, вероятность уклонения не больше, чем не в степени, а нет,
[33:16.500 --> 33:24.540]  давайте здесь, наверное, дважды, не в степени минуса квадрат на 2. Так, липшитцево по ребрам,
[33:24.540 --> 33:29.980]  здесь будет c из n по 2. c из n по 2 это количество ребра полного графа. Ну вот оно здесь вылез.
[33:29.980 --> 33:37.860]  Так, если удалось одну вершину, то удалить одну вершину, то окрестность других вершин изменится.
[33:37.860 --> 33:44.580]  Нет, мы не вершину удаляем. Смотрите, вот Эрнес спрашивает, мы не вершину удаляем, вершина-то
[33:44.580 --> 33:52.460]  остается. В определении липшитцевости по вершинам мы не трогаем вершину. Граф по-прежнему на n вершинах,
[33:52.460 --> 33:57.980]  мы трогаем ребра, находящиеся в ее окрестности. Мы какие-то из этих ребер можем удалить,
[33:57.980 --> 34:03.700]  а новые ребра, которых не было раньше, можем добавить в любом количестве, но вершина при этом
[34:03.700 --> 34:13.180]  сохраняется. Вершин все время n. У нас зафиксирована омега, но я думаю, что я ответил. Вот, не буду ждать,
[34:13.180 --> 34:21.620]  когда задержка закончится. Такое вот утверждение о концентрации меры значений липшитцевых функций
[34:21.620 --> 34:31.580]  на случайных графах около своих средних значений. Теорема 2. Точно такая же, только для липшитцевости по вершинам.
[34:31.580 --> 34:52.420]  Липшитцева по вершинам. Тогда для любого а больше 0 вероятность того, что модуль f-ef
[34:52.420 --> 35:03.420]  больше либо равняется a, не превосходит 2, на f в степени минус a квадрат на дважды n-1.
[35:03.420 --> 35:10.060]  Ну, почему именно n-1? Это я вряд ли сейчас поясню. Но она по вершинам. Вершин всего n.
[35:10.060 --> 35:18.180]  n-1 это примерно n. По ребрам тут c из n по 2. Ну, я же не доказываю пока эти утверждения. В них пока
[35:18.180 --> 35:23.740]  предлагается просто поверить, что вот есть такие удивительные, интересные, далеко идущие обобщения
[35:23.740 --> 35:31.860]  концентрации меры в духе теоремы об уклонении случайного блуждания от кабака, но на графах для
[35:31.860 --> 35:39.300]  липшитцевых функций. Да, хочу еще заметить, что если, понятное дело, если модуль снять, то вот эта
[35:39.300 --> 35:47.140]  двойка пропадет. Я могу каждую из этих теорем еще переформулировать отдельно для случая f-ef
[35:47.140 --> 35:56.620]  больше a и случая f-ef меньше, чем минус a. Отклониться вправо далеко и отклониться влево далеко
[35:56.620 --> 36:03.620]  симметрично маловероятно. Двойка пропадает в оценке вероятности, а для модуля это как раз
[36:03.620 --> 36:09.380]  происходит сложение до двойки. И здесь то же самое. Давайте осознаем, какое из двух утверждений
[36:09.380 --> 36:26.660]  мощнее с точки зрения плотности концентрации? Ну, где правая часть меньше? Первый? А по-моему,
[36:26.660 --> 36:32.820]  второй. Во-второй, потому что знаменатель у нее меньше, чем у этой, стало быть дробь больше,
[36:32.820 --> 36:39.540]  а она со знаком минус в показателе экспонента. Поэтому здесь получается большое отрицательное
[36:39.540 --> 36:45.660]  число, большое по модулю отрицательное число. Ну, это и соответствует нашей интуиции, потому что,
[36:45.660 --> 36:51.020]  конечно, если случайная величина липшитцевого по вершинам, то она тем более липшитцевого по
[36:51.020 --> 36:57.220]  ребрам. А вот, наоборот, неверно. Бывают такие, которые липшитцевого по ребрам и при этом не
[36:57.220 --> 37:03.420]  липшитцевого по вершинам. Поэтому если нам посчастливилось найти такую случайную величину,
[37:03.420 --> 37:09.300]  которая еще и по вершинам липшитцевого, она даст офигенную концентрацию. Если не посчастливилось,
[37:09.300 --> 37:15.660]  ну тоже будет ничего. И пользоваться можно и тем, и другим. И мы будем в дальнейшем пользоваться
[37:15.660 --> 37:24.540]  и тем, и другим. Но пока я не хочу это доказывать. Так, если в целом это понятно, тогда давайте,
[37:24.540 --> 37:30.220]  наверное, вернемся к теореме. Кстати, я забыл сказать важную вещь. Теорема, которая была вот
[37:30.220 --> 37:35.900]  здесь написана и на месте которой появились эти вот концентрационные неравенства, она предлежит
[37:35.900 --> 37:43.820]  Балабашу в том случае, который мы сейчас собираемся доказывать, то есть четырьмя значениями. Автор
[37:43.820 --> 37:54.300]  Болло Баш, один из классиков теории случайных графов, неоднократно бывавший в нашей стране,
[37:54.300 --> 38:02.540]  причем в первый раз в году, в 69-м, а в последующие разы по нашим приглашениям. То есть он еще в
[38:02.540 --> 38:08.180]  69-м году приезжал в Россию, в Советскую, и тут учился. Он в Венгаро по происхождению учился,
[38:08.180 --> 38:15.420]  стажировался скорее в институте, по-моему, в стекловке. Причем у математика Гильфанда, который,
[38:15.420 --> 38:20.020]  может вы слышали там линейный алгебра учебник есть, ну такой великий известный математик,
[38:20.020 --> 38:26.820]  никакими графами не занимавшийся. И он занимался, и по сью пору занимается, Балабаш, я имею в виду,
[38:26.820 --> 38:33.820]  и функциональным анализом, и случайными графами. Но в случайных графах он очень знаменит. И в
[38:33.820 --> 38:38.220]  частности он доказал ту теорему, которую мы по модулю вот этих результатов, которые я сформулировал,
[38:38.220 --> 38:48.500]  но не доказываю. Собираемся полностью доказать. Так, ну ладно, липшица вести я сотру. У нас
[38:48.500 --> 38:54.740]  прозвенел звонок, но я как-то не очень понимаю, нужно ли нам устраивать перерыв, когда здесь народ
[38:54.740 --> 39:01.940]  не сидит. Какой смысл-то? Ну из ютубов все равно можно всегда ненадолго отойти, я не знаю.
[39:01.940 --> 39:27.660]  Ой, уронил. Так. Пишется, кстати, Балабаш вот так.
[39:27.660 --> 39:42.700]  По-венгерски он считается как Ше, но живет он в Англии в основном, в Кембридже. Так,
[39:42.700 --> 39:52.140]  чего начать? Начнем с леммы, потому что она проясняет структуру дальнейшего рассуждения.
[39:52.140 --> 40:17.380]  Так, что утверждает лемма? Лемма утверждает следующее. Ну, конечно, пусть P равняется n в
[40:17.380 --> 40:23.380]  степени минус альфа, альфа больше, чем две третих. На самом деле, не обязательно меньше единицы,
[40:23.380 --> 40:34.700]  просто больше, чем две третих и все. Тогда существует n нулевое такое, что для любого n,
[40:34.700 --> 40:43.740]  больше либо равного n нулевого, вероятность которой выполнена следующее событие больше,
[40:43.740 --> 40:50.220]  чем один минус один поделить н-логариф n. Ладно, сейчас допишем событие. Для любого s,
[40:50.220 --> 41:03.900]  являющегося под множеством вершин нашего случайного графа, и имеющего мощность не большую,
[41:03.900 --> 41:09.580]  чем корень z-н-логариф n, то есть относительно маленькую по сравнению с количеством всех вершин,
[41:09.580 --> 41:17.380]  для любого достаточно маленького в некотором смысле множества вершин. Что выполнено? Выполнено
[41:17.380 --> 41:29.240]  и от графа, индуцированного этим множеством вершин, так, меньше либо равняется тройке. Вот так,
[41:29.240 --> 41:35.340]  меньше либо равняется тройке. Вот эта вероятность больше либо равна, как я уже сказал, один минус один
[41:35.340 --> 41:42.440]  делить на логариф m. Ну, я мог бы сказать, асимптотически, почти наверно, выполняется вот это
[41:42.440 --> 41:50.300]  событие, стоящее в скобках. Но мне важно не просто, что асимптотика единица, а прям вот явно
[41:50.300 --> 41:55.660]  оценить хоть как-нибудь, пусть начиная с некоторого n. То есть асимптотика-то единичная,
[41:55.660 --> 42:01.580]  начиная с некоторого n и ладно. Но вот мне хочется явную оценку получить. Она грубая,
[42:01.580 --> 42:08.020]  тут ничего страшного. То есть утверждение такое, каждое относительно маленькое множество можно
[42:08.020 --> 42:14.300]  покрасить в три цвета. Изначально это ничего не значит про раскраску всех n вершин. Мало ли,
[42:14.300 --> 42:20.700]  что каждый кусочек можно покрасить в три цвета правильным образом. А может быть на весь граф
[42:20.700 --> 42:26.100]  потребуется три цвета на один кусочек, три цвета на другой кусочек, и там суммарно получится три
[42:26.100 --> 42:32.740]  корни из n поделить на алгоритм n. То есть офигенно много. Мы не знаем, но каждый маленький кусочек
[42:32.740 --> 42:40.700]  красятся в какие-то три цвета. С очень высокой вероятностью. Доказательства оно не потребует всей
[42:40.700 --> 42:45.820]  вот этой техники. Это такая лемма, которая на самом деле объясняет, зачем нам нужно, чтобы альфа
[42:45.820 --> 42:55.300]  было больше двух третей. Для концентрации мира нужно другое. Она не совсем тривиальная, но она
[42:55.300 --> 43:00.740]  техническая. То есть мне ничего такого сильно умного нет. Я, как обычно, буду доказывать
[43:00.740 --> 43:06.260]  противоположное неравенство. То есть напишу отрицание вот этого события, оценю сверху единицы
[43:06.260 --> 43:17.020]  поделить на алгоритм. Так, я пишу вероятность того, что существует s мощности. Я уже не буду писать
[43:17.020 --> 43:27.580]  откуда, но понятно, что отсюда мощности больше, чем корень. Чем больше? Меньше либо равно. Здесь-то
[43:27.580 --> 43:39.460]  зачем отрицать? Глупость написал. Да, такое, что и от g на s больше либо равняется четверке. Так,
[43:39.460 --> 43:47.260]  это надо отделить вот так вот. Разучился отрицание событий писать. Конечно, для любого s какой-то
[43:47.260 --> 43:53.980]  мощности, отрицание существует и с такой же мощностью. Так, я надеюсь, никого не смущает.
[43:53.980 --> 44:01.540]  Теперь я хочу это оценить сверху, но давайте я пока напишу точное равенство. Я напишу вероятность того,
[44:01.540 --> 44:10.060]  ну, во-первых, совсем напишу тривиальную вещь, то существует s, у которого мощность лежит вот в
[44:10.060 --> 44:23.740]  таких пределах и такое, что g на s больше либо равняется четверке. Но я думаю, это совсем понятно,
[44:23.740 --> 44:28.740]  почему в таких пределах вряд ли хроматическое число графа, имеющее не больше трех вершин,
[44:28.740 --> 44:34.860]  может оказаться четверкой выше. Поэтому, конечно, s точно не менее четырех вершин имеет,
[44:34.860 --> 44:42.300]  тут уж явно деваться некуда. Ну, на самом деле нам бы для выкладки хватило, что мощность s
[44:42.300 --> 44:46.740]  больше либо равняется даже единицы, наверное, ну да бог с ним. Но двойки, во всяком случае,
[44:46.740 --> 44:53.340]  единицы вряд ли, а вот двойки, двойки хватит. Ну, неважно. Вот, это неинтересно, это понятно.
[44:53.340 --> 45:00.660]  Чуть-чуть более нетривиальное утверждение, которое простое, но почему-то ряд людей на нем
[45:00.660 --> 45:07.580]  спотыкаются. Я могу даже написать, ну ладно, я буду, ну хорошо, давайте s. Существует s,
[45:07.580 --> 45:16.940]  мощность которого лежит в уже известных пределах, я вот так напишу, многоточие это вот. Так, такое,
[45:16.940 --> 45:35.300]  что и от g на s больше либо равняется 4, но для любого x принадлежащего s и от g ограниченного
[45:35.300 --> 45:45.380]  на s без этого x все-таки меньше либо равно трех. Вот так. Длинное такое условие немножко
[45:45.380 --> 45:54.500]  не полезно, но видно, да? На экране видно тоже нормально. Вот. Ну, что утверждается?
[45:54.500 --> 45:59.140]  Утверждается просто, что если мы можем найти хоть какое-то s, которое не красятся в три цвета,
[45:59.140 --> 46:05.780]  то можно из множества таких s выбрать минимальное. То есть здесь стоит объединение каких-то событий,
[46:05.780 --> 46:11.300]  здесь стоит объединение формально других событий, но эти объединения очевидно совпадают. Потому что
[46:11.300 --> 46:17.660]  если вы нашли такое s, ну значит какое-то s вы нашли. Если вы нашли какое-то s, последовательно
[46:17.660 --> 46:23.620]  просто убираете из него лишние вершины и получаете вот такое минимальное, с точки зрения свойства не
[46:23.620 --> 46:30.220]  красятся в три цвета. Минимальное по включению. То есть вот оно в три цвета еще не красятся,
[46:30.220 --> 46:44.300]  но любое его собственное подмужство уже красятся. Понятно? Сейчас вы поймете, для чего мне нужно было так сделать.
[47:00.220 --> 47:28.820]  Ой, картину, что ли, нарисовать. Вот картина. Так, ладно, это вершин нашего случайного графа.
[47:28.820 --> 47:38.260]  Вот мы взяли какое-то s, мы знаем, что у него хроматическое число не меньше четырех, у него в смысле
[47:38.260 --> 47:45.580]  вот этого индуцированного под графа. Но мы знаем, что если взять любую вершинку х, принадлежащую
[47:45.580 --> 47:53.620]  этому множеству, то у оставшейся части вот этой хроматическое число не больше тройки. Знаем,
[47:53.620 --> 48:02.580]  причем для любой х. Что можно сказать про степень вершины х, тем самым? Про степень не
[48:02.580 --> 48:11.180]  внутри всего графа, а внутри этого множества s. Сколько ребер внутри множества s может выходить
[48:11.180 --> 48:22.140]  из х? Может выходить два ребра? Нет, потому что если из х выходит только два ребра,
[48:22.140 --> 48:36.020]  то смотрите, мы вот эту часть-то в три цвета покрасили, а тут только два ребра. Ну так возьмите
[48:36.020 --> 48:41.820]  и покрасьте эту вершину в третий цвет, и опять получится не больше трех, вопреки тому, что мы считаем,
[48:41.820 --> 48:48.620]  что не меньше четырех. То есть следствием из вот этого кошмарного подлиннее, казалось бы,
[48:48.620 --> 48:56.500]  нетривиальности утверждения, следствие из вот этого всего, я не буду переписывать,
[48:56.500 --> 49:05.500]  следствие состоит в том, что существует s, мощность которого принадлежит, понятно,
[49:05.500 --> 49:13.780]  от четверки до корени Зэмла Гарриф Мэн, тут все как было. Такое, что, а я вот так напишу,
[49:13.780 --> 49:24.260]  количество ребер в графе g на s больше либо равняется трижды мощность s пополам.
[49:24.260 --> 49:31.540]  Ну гораздо более простое условие, чем то, которое было написано с хроматическими числами,
[49:31.540 --> 49:38.060]  то есть следствие вот этой минимальности по включению, что все красятся минимум в четыре цвета,
[49:38.060 --> 49:43.420]  но при удалении одной вершины остается раскраска в три цвета, является тот факт, что у каждой
[49:43.420 --> 49:50.780]  вершины внутри s есть как минимум три соседки, а значит суммарное количество ребер в этом графе g,
[49:50.780 --> 49:57.940]  ограниченном на s, не меньше, чем трижды мощности s пополам. Сумма степеней вершин,
[49:57.940 --> 50:06.220]  а то удвоенное количество ребер. Ну или можно еще знаете, как написать, существует s маленькая,
[50:06.220 --> 50:21.180]  принадлежащая от 4 до корень из n на логариф mn, существует s большое мощности, s маленькая такое,
[50:21.180 --> 50:30.900]  что количество ребер уже на s большом не меньше, чем 3s маленькая пополам. Вот так тоже можно написать
[50:30.900 --> 50:37.380]  чуть более подробно. А тогда вероятность, которую мы хотим оценить, как вы, наверное, еще помните,
[50:37.380 --> 50:43.340]  сверху, вот эта вероятность, мы хотим ее оценить сверху, как один поделитель на логариф mn. Она,
[50:43.340 --> 50:53.420]  конечно, оценивается сверху, вот я так перетащу сюда, оценивается сверху, вероятностью вот этого
[50:53.420 --> 50:59.540]  события. Если из одного события следует другое, то его вероятность не больше, чем вероятность
[50:59.540 --> 51:08.100]  следствия. Так, ну, как обычно, если стоят квантеры существования, это значит, речь идет про
[51:08.100 --> 51:16.820]  объединение, и мы просто оцениваем вероятность, как сумму. Это не больше, чем сумма, то есть
[51:16.820 --> 51:21.780]  технически это простая лемма со стандартными идеями, которые у нас не раз уже бывали. Сумма
[51:21.780 --> 51:32.420]  по s от четверки до корени z на логариф mn, сумма по s большим мощности, s маленькая. Так, а здесь
[51:32.420 --> 51:41.980]  стоит вероятность того, что e, ограниченное на g, e, g, ограниченного на s, больше либо равняется
[51:41.980 --> 51:55.500]  3s маленькая попало. Вот так. Так, до сюда понятно? Харе, а вот эта вероятность как оценить? У
[51:55.500 --> 52:02.260]  всего графа n вершин, но у этого s. Мы уже ограничились на кусочек размера s маленькая. С какой
[52:02.260 --> 52:06.660]  вероятностью в этом кусочке не менее, чем столько рёдер? Ну, вы мне сейчас скажете, давайте писать
[52:06.860 --> 52:20.260]  сумму страшную, но я сверху хочу оценить. Число рёбер не меньше, чем 3s пополам. Но знаете,
[52:20.260 --> 52:30.620]  как можно сказать, существуют 3s пополам рёбер, правильно? Вот это вот, это в g на s существуют
[52:30.620 --> 52:40.300]  3s пополам рёбер. Это в точности то самое событие. Если количество рёбер не меньше, чем 3s пополам,
[52:40.300 --> 52:47.700]  то в графе найдутся 3s пополам рёбер. Ну, поборники аккуратности могут мне сказать, что здесь надо
[52:47.700 --> 52:55.740]  нарисовать целую часть, потому что мало ли вдруг s на 2 не делится. Но имейте в виду, что кто-нибудь
[52:55.740 --> 53:01.180]  может, но суть это не поменяет, а я не хочу громоздкие выкладки делать. Там очень легко все
[53:01.180 --> 53:06.940]  преобразует, если нарисовать целую часть, но просто писать будет гораздо больше, а смысла никакого нет.
[53:06.940 --> 53:13.700]  Так, существует 3s пополам рёбер, но как оценить вероятность того, что существует 3s пополам рёбер?
[53:13.700 --> 53:20.700]  Это опять объединение по всем способам выбрать 3s пополам рёбер, какие могут возникнуть на множестве
[53:20.700 --> 53:28.540]  и засвершить. Ну, короче, я сейчас напишу, а вы мне скажете, понятно или нет. Маленькая четвёрка,
[53:28.540 --> 53:40.620]  там даже понятно, корень из n, сумма по s большая. Так, а я напишу вот так, c из c из s по 2 по 3s
[53:40.700 --> 53:45.020]  пополам на p в степени 3s пополам.
[53:51.020 --> 54:00.420]  Существуют 3s пополам рёбер. Его рёбер у полного графа c из s по 2. Вот мы из них выбираем какие-то 3s пополам,
[54:00.420 --> 54:07.900]  в объединении будет столько множеств. И вероятность каждого отдельного события, это просто вероятность
[54:07.900 --> 54:13.780]  того, что именно эти конкретные 3s пополам рёбер реализовались, но это по f в степени 3s пополам.
[54:13.780 --> 54:25.100]  Вот. Ну, как видите, от внутреннего суммирования, от его переменной, вот эта величина никак не зависит,
[54:25.100 --> 54:30.900]  это мощность с большого. Слушайте, а можно я вот так сделаю?
[54:37.900 --> 54:44.460]  Ну, я убрал это суммирование, потому что в нём складываются одинаковые величины, а количество этих величин равно
[54:44.460 --> 54:50.500]  просто количеству способов зафиксировать сардельку из-за маленькой элементов в большой сардельке мощности n.
[54:50.500 --> 54:57.300]  Это c из n по n. Вот дальше мы грубости пока таких не будем допускать, мы сейчас оценим каждую c.
[54:57.300 --> 55:07.100]  Оценим мы её, используя стандартное неравенство c из a по b не больше чем ea поделить на b в степени b.
[55:07.100 --> 55:18.980]  Узнаётся такое? Может, не узнаётся. Ладно, c из a по b, то узнаётся не больше чем a в степени b поделить на b факториал.
[55:18.980 --> 55:27.580]  Это точно узнаётся. Но b факториал, конечно, не меньше, и это я тоже говорил, по индукции доказывается,
[55:27.580 --> 55:34.300]  b поделить на e в степени b. Подставляем это в знаменатель и получаем то, что я написал.
[55:35.220 --> 55:37.220]  e это число e.
[55:37.220 --> 55:44.940]  Так, мне кажется, я могу вот эту часть стереть, чтобы не переходить на другую доску.
[55:44.940 --> 55:47.940]  Оставить только вот это, а верхнюю часть стереть.
[56:04.300 --> 56:28.420]  Давайте это меньше либо равно, и поехали сюда. Сумма с маленькому от четвёрки до чего-то будет e n поделить на s в степени s.
[56:28.540 --> 56:36.540]  Это я применил вот это неравенство c из n по s, а c из s по 2 по 3s пополам, оно применяется вот так.
[56:36.540 --> 56:44.540]  e на c из s по 2 поделить на 3s пополам в степени 3s пополам. Правильно?
[56:44.540 --> 56:48.540]  Так, тут появился, скажите, какой-то вопрос.
[56:48.540 --> 56:55.540]  А, нет, всё то же самое. Тут показалось, что больше строчек. Ну и слава богу.
[56:55.660 --> 56:59.660]  Я стараюсь медленно, по в степени 3s пополам.
[56:59.660 --> 57:03.660]  Но мы же крутые, значит, мы можем не совсем медленно.
[57:03.660 --> 57:09.660]  Так, ну тут много всякой бяки, я сейчас её в уме посчитаю, ладно.
[57:09.660 --> 57:13.660]  c из s по 2 меньше, чем s квадрат пополам.
[57:15.660 --> 57:18.660]  А тут тоже пополам, значит, пополам сократилось.
[57:18.660 --> 57:20.660]  Тут s квадрат пополам и тут пополам.
[57:20.660 --> 57:22.660]  И s сократилось.
[57:22.780 --> 57:26.780]  В общем, вот это всё, это s. Ну, меньше, чем s.
[57:26.780 --> 57:32.780]  Меньше, чем s, e поделить на 3 меньше 1, ну давайте считать, что всё меньше, чем s.
[57:32.780 --> 57:37.780]  Я пишу это меньше, чем summa по s в понятных пределах.
[57:37.780 --> 57:49.780]  e n на s в s-тый, а здесь s в степени 3s пополам и p в степени 3s пополам.
[57:49.900 --> 57:52.900]  Ну и давайте я теперь то, что стоит под знаком суммирования,
[57:52.900 --> 57:55.900]  занесу в одну такую здоровую скобку, а к северо-востоку
[57:55.900 --> 57:57.900]  от этой скобки будет стоять буквка s.
[57:57.900 --> 58:00.900]  Ну, то есть всё под степень s занесу.
[58:00.900 --> 58:05.900]  Значит, это будет равно, по-прежнему, summa по нашим s вот этим.
[58:05.900 --> 58:13.900]  Вот будет вот так, e n поделить на s, умножить на s в степени 3 вторых
[58:14.020 --> 58:24.020]  и это в степени s. Загнал под одну общую степень s.
[58:24.020 --> 58:32.020]  Ну, тут у нас вот так вот сократилось s в степени 3 вторых на s.
[58:32.020 --> 58:37.020]  И в итоге a. И давайте я вот это s в степени 1 вторая,
[58:37.020 --> 58:40.020]  которая осталась в скобках, вот именно этот корень из s,
[58:40.140 --> 58:43.140]  оценю как корень из самого большого значения,
[58:43.140 --> 58:46.140]  какое может принимать s в рамках суммирования.
[58:46.140 --> 58:51.140]  То есть это меньше либо равно summa по s.
[58:51.140 --> 58:56.140]  А здесь e n, вот это оно вышло, e умножить на n.
[58:56.140 --> 58:59.140]  А корень из s заменяем на корень из вот этого выражения.
[58:59.140 --> 59:04.140]  То есть будет n в степени 1 четверть на корень из логарифма n.
[59:04.140 --> 59:09.140]  Так, и на p в степени 3 вторых, которые давайте я заменю.
[59:09.260 --> 59:12.260]  p, у нас n в степени минус альфа, это кто-то еще помнит,
[59:12.260 --> 59:19.260]  ну значит минус 3 вторых альфа и все это в степени s.
[59:20.140 --> 59:24.260]  Вот это вот, это n в степени 5 четвертых,
[59:24.260 --> 59:29.260]  а здесь смотрите, 5 четвертых – минус 3 вторых альфа.
[59:29.260 --> 59:32.260]  Вот 5 четвертых – минус 3 вторых альфа.
[59:32.260 --> 59:40.380]  минус 3 вторых альфа. Я 2 третьих написал, я чушь написал. Не две третих, виноват,
[59:40.380 --> 59:45.180]  хуже. Не две третих, 5 шестых. 5 шестых мы будем доказывать. Это у меня какой-то
[59:45.180 --> 59:49.260]  сбой случился, виноват. Еще хуже будем доказывать. Не две третих, а 5 шестых,
[59:49.260 --> 59:53.180]  товарищи, виноват. Во всех формулировках, которые мы будем доказывать, там не две
[59:53.180 --> 59:59.700]  третих, а 5 шестых. К сожалению, ну ничего. Конечно, да, если сюда подставить 5 шестых,
[59:59.700 --> 01:00:04.620]  это будет меньше нулю. Ну равно нулю, а если альфа больше, чем 5 шестых, то это меньше нуля.
[01:00:04.620 --> 01:00:12.620]  То есть у нас вот в этих скобках появилось выражение n в какой-то степени, фиксированной
[01:00:12.620 --> 01:00:17.900]  альфа мы задали раз и навсегда. n в какой-то фиксированной степени, которая строго меньше нуля.
[01:00:17.900 --> 01:00:22.740]  Ну давайте я это нормально напишу, а то трудно воспринимать все-таки на слух.
[01:00:33.740 --> 01:00:35.460]  У нас получилось, что это равно
[01:00:35.460 --> 01:00:49.860]  сумма по s. Ну давайте здесь напишу от четверки до корени z-логарифа n. Тут e на n, давайте в степени
[01:00:49.860 --> 01:00:58.900]  минус бета. Где бета? Это вот это. Ну вот это минус бета. Виноват. Вот эта вот разность, это
[01:00:58.900 --> 01:01:03.980]  минус бета. А бета сама положительная. Я просто хочу подчеркнуть, что вот такая штука стремится
[01:01:03.980 --> 01:01:09.900]  к нулю, как n в какой-то фиксированной степени, фиксированной отрицательной степени. Дальше у меня
[01:01:09.900 --> 01:01:18.260]  еще живет корень из логарифма n, дурацкий, и это все в степени s. Ну что я могу сказать? Понятно же,
[01:01:18.260 --> 01:01:25.580]  что n в степени минус бета, как бы близко изначально альфа ни было к 5 шестым, n в степени минус бета,
[01:01:25.580 --> 01:01:30.540]  пусть даже бета очень маленькая, очень близкая к нулю, n в степени минус бета, начиная с какого-то
[01:01:30.540 --> 01:01:37.060]  момента, сколько угодно хорошо укокивает вот этот корень из логарифма. То есть, например, можно
[01:01:37.060 --> 01:01:44.620]  сказать, что это меньше, чем сумма в тех же пределах. Она укокивает не только корень из логарифма,
[01:01:44.620 --> 01:01:51.300]  тем более она укокивает вот эту несчастную ешку, которая все-таки выжила. Вот. Можно вот так написать n
[01:01:51.300 --> 01:01:59.780]  в степени минус бета пополам степени s. Ну и здесь, конечно, n, начиная с какого-то n первого. Вот
[01:01:59.780 --> 01:02:08.300]  верно, начиная с какого-то n первого. Я просто хочу сказать, что n в степени бета пополам точно больше,
[01:02:08.300 --> 01:02:15.460]  чем корень из логарифма n на е, начиная с какого-то момента. Вроде ничего сложного нет. А эта сумма
[01:02:15.460 --> 01:02:24.940]  геометрической прогрессии в очередной раз стартующая с четверки. То есть, это, ну давайте, меньше
[01:02:24.940 --> 01:02:34.460]  либо равняется. Подставляем s равное четверке. Получаем n в степени минус 2 бета. Это подставили
[01:02:34.460 --> 01:02:43.820]  просто. Первый член. Ну а дальше, если хотите, можно написать 1 поделить на 1 минус n в степени
[01:02:43.820 --> 01:02:50.300]  минус бета пополам. Ну то есть, как обычно, мне больше нравится оценить сумму конечной геометрической
[01:02:50.300 --> 01:03:01.580]  прогрессии, суммой бесконечной. Но это же правильно. Это примерно единица при больших n. Вот это.
[01:03:01.580 --> 01:03:12.340]  Что это стремится к нулю? К единице, к единице. Ну а это-то меньше, чем 1 поделить на логарифм n. Это же n в степени
[01:03:12.340 --> 01:03:19.580]  минус 2 бета. Ну тоже может быть не сразу, а начиная там с какого-то n нулевого. Но мы же это и заявляли
[01:03:19.580 --> 01:03:29.420]  вот здесь. Начиная с n нулевого. Это конечно меньше, чем 1 поделить на логарифм n, начиная с какого-то n нулевого.
[01:03:29.420 --> 01:03:38.300]  Конечно, n нулевое зависит от альфы. Ну и здесь также надо читать. Пусть p равняется n в степени
[01:03:38.300 --> 01:03:43.100]  минус альфа. Альфа фиксирована больше 5 шестых. Тогда найдется n нулевое. Естественно,
[01:03:43.100 --> 01:03:51.300]  зависящее от альфа такое что. Но альфа у нас фиксирована, поэтому нам не страшно. Вот такую
[01:03:51.300 --> 01:04:02.780]  лемму доказали. Как у меня осталось времени? 15 минут, да? Ну за 15 минут можно что-то успеть.
[01:04:02.780 --> 01:04:12.100]  Все, не успеем. Так, лемму я точно оставлю, а вот эти я не хочу стирать. Хотя, может,
[01:04:12.100 --> 01:04:15.820]  я их не успею применить, но это уж как повезет, тут я не знаю.
[01:04:15.820 --> 01:04:39.500]  Я начну доказывать теорию. У нас есть лемма, и нам где-то должно понадобиться это суперружье
[01:04:39.500 --> 01:04:58.460]  концентрации мира. Доказательства теории. Ну давайте фиксируем альфа больше 5 шестых,
[01:04:58.460 --> 01:05:07.700]  фиксируем какое-то n. Ну оно точно больше либо равное n нулевого, иначе мы не сможем применить
[01:05:07.860 --> 01:05:14.940]  лему. Ну может быть и там еще больше, неважно, фиксируем n нулевое штрих. Подразумевает,
[01:05:14.940 --> 01:05:20.700]  что просто n достаточно большое, в частности больше чем n нулевое, но может быть потребуется
[01:05:20.700 --> 01:05:30.780]  его взять еще большим для каких-то целей. Это мы потом проясним. Понятно? Теория у нас
[01:05:30.780 --> 01:05:35.580]  асимпатическая, поэтому мы можем считать, что работаем с достаточно большим n. Мы лишь говорим,
[01:05:35.580 --> 01:05:40.780]  что нечто выполняется асимпатически почти наверно, но это не значит, что при маленьких n оно
[01:05:40.780 --> 01:05:46.060]  должно иметь высокую вероятность. То есть если мы докажем все, что нам нужно при больших n,
[01:05:46.060 --> 01:05:50.460]  то при маленьких n нам плевать, как оценивается вероятность, потому что все равно стремление
[01:05:50.460 --> 01:05:56.100]  к единице будет. Ну чуть-чуть непрактичный, конечно, в этом смысл, но я не хочу ковыряться в
[01:05:56.100 --> 01:06:00.860]  конкретных оценках, для чего бы нам это было. Главная идея понять, а поковыряться это уже каждый
[01:06:00.860 --> 01:06:09.740]  сможет при необходимости. Вот, считаем, что n достаточно велико. Так, теперь давайте определим,
[01:06:09.740 --> 01:06:21.380]  найдем u. Ну оно, конечно, окажется, зависящим от n и от альфа, но мы n и альфа зафиксировали,
[01:06:21.380 --> 01:06:28.820]  в общем, неважно, что оно от них зависит. Вот, определим u следующим образом. Это минимальная
[01:06:28.820 --> 01:06:42.100]  число натуральная. Такое, что вероятность, которой хроматическое число случайного графа в нашей
[01:06:42.100 --> 01:06:53.980]  ситуации. Так, сейчас не ошибиться, наверное, не превосходит. Сейчас разберемся. Вероятностью
[01:06:53.980 --> 01:07:08.060]  больше, чем один поделитель на логарифумы. Но абсолютно неявное, конечно, определение,
[01:07:08.060 --> 01:07:15.780]  но поскольку n и альфа зафиксированы, то в каком-то смысле полным перебором уже ищется. Ну просто
[01:07:15.780 --> 01:07:22.620]  тупо посчитать вероятность вот этого события, складывая все вероятности графов, которые этому
[01:07:22.620 --> 01:07:29.540]  неравенству удовлетворяют. Это пойди, сделай чисто алгоритмически, но формально же вещь, не вещь,
[01:07:29.540 --> 01:07:37.300]  а величина корректно определена, правда? Минимальное натуральное число такое, что вероятность вот
[01:07:37.300 --> 01:07:46.580]  этого события все еще больше чего-то. Это корректно или нет? Ну смотрите, если бы здесь стояло не у, а n. Вот
[01:07:46.580 --> 01:07:52.660]  представьте себе, что здесь не у, а n стоит. Число вершин. Тогда вероятность этого события это просто
[01:07:52.660 --> 01:07:59.180]  один. Вероятность того, что хроматическое число не больше n. У всех графов хроматическое число не
[01:07:59.180 --> 01:08:04.660]  больше, чем n. Но вероятность этого события один. Мы начинаем потихоньку уменьшать это число,
[01:08:04.660 --> 01:08:13.140]  и вероятность начинает падать, когда n превращается, ну я не знаю, там в ноль, например. Вероятность того,
[01:08:13.140 --> 01:08:17.860]  что хроматическое число не больше нуля, это ноль. Потому что не бывает графов с хроматическим числом
[01:08:17.860 --> 01:08:23.980]  ноль, кроме пустых. Но у нас n-вершина, n-натуральная, в нормальном смысле слова. То есть, ну, не придерешься.
[01:08:23.980 --> 01:08:31.220]  То есть, эта вероятность монотонно убывает от единицы к нулю. Но, значит, есть такой граничный момент,
[01:08:31.220 --> 01:08:36.900]  до которого вероятность, до которого включительна, вероятность все еще больше, чем один на логариф МН,
[01:08:36.900 --> 01:08:43.300]  но как только мы спрыгиваем ниже, она становится меньше либо равна. Согласны? Да, вроде все корректно.
[01:08:43.300 --> 01:08:48.500]  Ну, смотрите, значит, тогда действительно вероятность того, что... Я утверждаю, что вот это то
[01:08:48.500 --> 01:08:56.260]  самое у, которое нам нужно в теореме. То есть, такое, что у, у плюс один, у плюс два, у плюс три,
[01:08:56.260 --> 01:09:03.620]  это те самые четыре значения, в которые хи от g попадает с вероятностью стремящейся к единице.
[01:09:03.620 --> 01:09:13.380]  Понятно? В теореме заявлено, что если альфа больше, чем 5 шестых, то асимптатически почти,
[01:09:13.380 --> 01:09:19.380]  наверное, хи принимает значение от какого-то у до у плюс четырех. Я утверждаю, что вот это хитро
[01:09:19.380 --> 01:09:30.420]  определенное у есть то самое. Сейчас. Ну, в теореме, которое в самом начале было, там говорилось о
[01:09:30.420 --> 01:09:34.980]  концентрации в двух значениях, но потом я сказал, что мы будем доказывать теорему Балабаша о
[01:09:34.980 --> 01:09:42.900]  концентрации в четырех. Вот это то самое у, около которого в четырех точно концентрируется. Может
[01:09:42.900 --> 01:09:50.620]  и в двух, но мы докажем, что в четырех. Понятно? Нет, почему это так? И понятно абсолютно. Я утверждаю,
[01:09:50.620 --> 01:09:56.180]  что мы нашли это у, а почему сейчас буду доказывать? И сейчас, и в следующий раз. Но сейчас я кое-что
[01:09:56.180 --> 01:10:04.900]  скажу. Ясно, что и от g не превосходит у минус один с вероятностью меньше либо равной один на логариф
[01:10:04.900 --> 01:10:11.420]  мэн, потому что у было минимальным, я это прям явно проговаривал. Последнее такое значение, что
[01:10:11.420 --> 01:10:19.100]  вероятность все еще больше. Взяли на единичку меньше и вероятность уже не превосходит. Дальше. Ну,
[01:10:19.100 --> 01:10:26.380]  значит, вероятность того, что хиадже больше либо равняется у, то есть я пишу отрицание вот этого
[01:10:26.380 --> 01:10:36.220]  события. Хиадже целое число, у тоже целое число. Она не меньше, чем один минус один на логариф мэн.
[01:10:36.220 --> 01:10:40.820]  Я стараюсь просто для красоты унифицировать оценки. Смотрите, и тут один минус один на
[01:10:40.820 --> 01:10:47.740]  логариф. Мы тут один минус один на логариф. Это не обязательно, но это создает большую запоминаемость
[01:10:47.740 --> 01:10:56.060]  рассуждения. У меня уже есть два события, у которых у обоих вероятность очень близка к единице,
[01:10:56.060 --> 01:11:01.660]  причем в одних и тех же терминах. В терминах величины один поделитель на логариф мэн. Но это
[01:11:01.660 --> 01:11:07.620]  пока тоже ничего не понятно. Понятно только то, что хиадже не меньше, чем у. Но нам-то хотелось бы
[01:11:07.620 --> 01:11:13.060]  доказать, что оно еще и не больше, чем у плюс четыре, и тоже как бы с вероятностью стремящейся к единице.
[01:11:13.060 --> 01:11:22.860]  Вот как это доказать? Вот для этого нужна концентрация и время. А времени нет. Поэтому
[01:11:22.860 --> 01:11:26.700]  я сейчас что-нибудь напишу, а дальше мы продолжим в следующий раз.
[01:11:37.620 --> 01:11:59.380]  Ну, что ж я напишу. Ну давайте я дам определение, веду такую случайную величину y-адже.
[01:11:59.380 --> 01:12:07.020]  В следующий раз, видимо, придется напоминать ее определение, но ничего страшного. Это будет
[01:12:07.020 --> 01:12:26.180]  минимальное такое, какую бы букву K, то существует S под множество множества вершин случайного
[01:12:26.180 --> 01:12:46.940]  графа, имеющая мощность K, и такое, что хроматическое число графа G, ограниченного на 1, 2, N, без вот этого S,
[01:12:46.940 --> 01:13:10.500]  не превосходит U. Так, надо нарисовать картину. Вот дан какой-то конкретный граф на N вершинах,
[01:13:10.500 --> 01:13:18.100]  да? Что такое y от этого графа? Пункция просто на этом графе какое значение принимает, что мы ищем? Мы
[01:13:18.100 --> 01:13:26.340]  хотим найти самое маленькое по мощности множество вершин, удаление которого из графа,
[01:13:26.340 --> 01:13:37.780]  удаление которого из графа, удаление, видите, да? Оставляет, вот граф, вот этот G на удаленном,
[01:13:37.780 --> 01:13:44.100]  вот я его закрасил, отставляет под граф, который красится в не более чем у цветов.
[01:13:44.100 --> 01:13:53.060]  Но оно жутковатое в том смысле, что если вы задумаете как-нибудь, например, с помощью,
[01:13:53.060 --> 01:13:59.380]  не дай бог, линейности, посчитать мат ожиданий у, то вы обломитесь на первом же вздохе, так сказать,
[01:13:59.380 --> 01:14:04.900]  потому что какая тут линейность? Вообще ничего не понятно, это же не количество чего-то, это минимум
[01:14:04.900 --> 01:14:13.100]  какой-то сложный, согласна, да? Но смысл этой величины очень понятный. Мы берем и у каждого
[01:14:13.100 --> 01:14:19.380]  графа ищем самый маленький кусочек, удаление которого оставляет красящийся вуд цветов под
[01:14:19.380 --> 01:14:27.100]  граф. Я ж так написал, да? Минимальная мощность множество, удаление которого, и получили
[01:14:27.100 --> 01:14:35.180]  как раскраску вуд цветов, но не больше, чем у. Уму это вот то самое. Теперь, смотрите, я не буду
[01:14:35.180 --> 01:14:40.540]  ничего больше считать, даже не буду рассуждать про Липшицева, хотя Y Липшицева, это надо подумать,
[01:14:40.540 --> 01:14:46.500]  вот, но это ладно. Я другое хочу сказать, я хочу сказать идею дальнейших рассуждений, которые мы
[01:14:46.500 --> 01:14:53.780]  провернем через чуть больше недели. У нас же что случилось? У нас случилось, что четвертое неожиданно
[01:14:53.780 --> 01:14:58.620]  перестало быть праздником. То есть, с одной стороны, мы имеем нерабочие дни, в которые надо
[01:14:58.620 --> 01:15:03.940]  беречься от коронавируса, но с другой стороны, мы имеем эти дни учебными, но только в дистанте.
[01:15:03.940 --> 01:15:10.940]  Соответственно, прежний приказ юридически утратил силу, и четвертое не является праздником,
[01:15:10.940 --> 01:15:17.500]  а является таким же нерабочим, но учебным днем. И теоретически, я мог бы четвертого читать эту
[01:15:17.500 --> 01:15:23.020]  лекцию, как сегодня, но я уже там запланировал другое мероприятие давно, поэтому я читать
[01:15:23.020 --> 01:15:27.860]  четвертого не буду. А читать я буду в понедельник восьмого, если ничего не сломается по дороге.
[01:15:27.860 --> 01:15:33.420]  Но это уже забронировано. То есть, я считал, что у меня четвертое пропадает, я считал, что у меня
[01:15:33.420 --> 01:15:40.260]  восемнадцатое пропадает. Там праздник был тоже некий, 75-летие фистеха. А сейчас непонятно,
[01:15:40.260 --> 01:15:45.220]  может, ничего не пропадает, но я восьмого все равно прочитаю, а четвертого не буду. Соответственно,
[01:15:45.220 --> 01:15:50.620]  следующая встреча будет в понедельник восьмого числа. Большая вероятность такая же, но я не знаю
[01:15:50.620 --> 01:15:55.060]  пока. Может быть, все-таки выпустят. Так вот, смотрите, какая замечательная идея. Предположим,
[01:15:55.060 --> 01:16:01.740]  нам удалось доказать, предположим, нам удалось доказать, вот восьмому мы это сделаем, что у,
[01:16:01.740 --> 01:16:10.180]  вот этот, от g, с высокой вероятностью не больше, чем корень из n на логариф mn. Ну, то есть,
[01:16:10.180 --> 01:16:15.740]  вот, например, нам удалось доказать вот такое неравенство. Это, конечно, совершенно непонятно,
[01:16:15.740 --> 01:16:21.460]  пока откуда следует, но вдруг нам удалось доказать такое неравенство. Опять, с такой же правой частью,
[01:16:21.460 --> 01:16:30.780]  как везде, для красоты слога. Что бы это означало? Это бы означало, что с высокой вероятностью из
[01:16:30.780 --> 01:16:36.660]  графа можно удалить всего лишь столько вершин, чтобы оставшаяся часть красилась в у цветов,
[01:16:36.660 --> 01:16:44.900]  но мы же знаем, что любые столько вершин, любые столько вершин, красятся в три цвета. Опять же,
[01:16:44.900 --> 01:16:52.340]  с высокой вероятностью. Ну, значит, пересекая вот это событие, вот это, какое там, вот это
[01:16:52.340 --> 01:17:00.020]  событие и вот это событие, ну, мы увидим, что это пересечение, конечно, тоже имеет высокую вероятность,
[01:17:00.020 --> 01:17:06.860]  мы получим графы, которые одновременно не красятся меньше, чем в у цветов и такие,
[01:17:06.860 --> 01:17:13.940]  что значимая их часть красятся в у цветов, а оставшаяся в три и будет у плюс три.
[01:17:13.940 --> 01:17:22.900]  Смог объяснить, нет идеи. Мы берем граф, который одновременно обладает вот этим
[01:17:22.900 --> 01:17:31.580]  свойством, вот этим свойством и вот этим свойством. Ну, тогда у него точно хиаджи не меньше, чем у. Это
[01:17:31.580 --> 01:17:36.340]  я потом повторю в следующий раз все подробно. У него точно хиаджи не меньше, чем у, потому что он
[01:17:36.340 --> 01:17:41.220]  обладает этим свойством. С другой стороны, у него каждое множество из стольких вершин красятся в
[01:17:41.220 --> 01:17:47.900]  три цветов какие-то, и есть множество не более, чем такой мощности, удаление которого оставляет
[01:17:47.900 --> 01:17:53.060]  раскраску в у цветов. То есть мы удаляем это множество, красим в у цветов, это множество
[01:17:53.060 --> 01:17:59.220]  берем, оно же три цвета красятся, все, значит у плюс три получается. Вот такая идея. Но как вот это
[01:17:59.220 --> 01:18:05.740]  доказать? Это, конечно, вызов. Вот чтобы это доказать, нужно воспользоваться теориям 1 и 2,
[01:18:05.740 --> 01:18:14.940]  этого проделаем в следующий раз. Но вроде вопросов там больше не было, может я правда всех кокнул,
[01:18:14.940 --> 01:18:23.180]  да и множество тех, кого надо было кокнуть, я боюсь, было не очень большим. А, 14, это хорошо.
[01:18:23.180 --> 01:18:29.580]  Ну ладно, друзья, тогда до встречи. Видимо, надеюсь, в понедельник, но не этот, а восьмой.
