[00:00.000 --> 00:09.120]  Во-первых, я поздравлю вас тем, что вы закончили ваш страншедший период
[00:09.120 --> 00:15.120]  передачи. Дальше. Процессорная архитектура. Есть два основных класса. CISCRISK. Там еще
[00:15.120 --> 00:22.880]  выделяется Very Long and Strangest World. Это Intanium Elbrus. Зачем нужно такое количество разных
[00:22.880 --> 00:30.560]  архитектур. Есть процессоры, которые продаются в том числе и в рознице не только производителям
[00:30.560 --> 00:37.480]  компьютеров. Делают их в основном Intel, AMD. Причем и компания Intel, и компания AMD производят
[00:37.480 --> 00:44.880]  их по полному циклу. То есть и разрабатывают процессоры. Есть у них свои фабрики. Ну и по сути,
[00:44.880 --> 00:54.120]  они являются почти монополистами на рынке x86. Есть еще компании, которые делают только ядра,
[00:54.120 --> 00:59.960]  но не производят сами процессоры. То есть они занимаются только разработкой, но не производством.
[00:59.960 --> 01:05.240]  Классический пример. Это компания ARM, которую не так давно купила компания Nvidia. Которая
[01:05.240 --> 01:12.600]  продает уже готовые ядра разным производителям чипов для смартфонов. И некоторые компании,
[01:13.040 --> 01:19.000]  были когда-то такие процессоры MIPS. Они использовались в рабочих станциях Silicon
[01:19.000 --> 01:25.080]  Graphics. Сейчас уже они уже давно ничего не производят. Просто лицензируют свою архитектуру,
[01:25.080 --> 01:32.640]  которую уже сторонние компании, такие как Broadcom, развивают. Ну и недавно еще появилась,
[01:32.640 --> 01:38.960]  точнее появилась архитектура достаточно давно. Это RISC-5. Но очень долго не существовала реализации.
[01:38.960 --> 01:45.560]  Не так давно эти реализации уже появились. В основном это благодаря китайцам и русским.
[01:45.560 --> 01:52.880]  Так вот, у нас есть огромное количество архитектур, и откуда они берутся, и почему они до сих пор не
[01:52.880 --> 02:01.360]  вымерли. Ну если смотреть на архитектуру Intel AMD x86, то во-первых, архитектура не самая удачная,
[02:01.360 --> 02:10.200]  не самая современная. И больше она распространена из-за того, что накоплено огромное количество как
[02:10.200 --> 02:16.120]  прикладного софта, так и средств для разработки. И просто взять и отказаться. Одномоментно от этого
[02:16.120 --> 02:24.040]  не получается. Кроме того, когда вы покупаете уже какую-то готовую микросхему, то никто не
[02:24.040 --> 02:30.880]  гарантирует, что в этих микросхемах нет никаких секретных блоков, которые могут делать что-то,
[02:30.880 --> 02:37.920]  что не описано в документации. И проверить это очень сложно. В то же время, если вы покупаете уже
[02:37.920 --> 02:47.440]  некоторые ядра, которые вы штампуете на своих микросхемах рядом с чем-нибудь, то задача по
[02:47.440 --> 02:54.960]  верификации таких ядер немного упрощается, но тем не менее все равно там могут быть какие-то
[02:54.960 --> 03:03.880]  скрытые подводные камни и очень хорошо запрятанные тайники. В этом плане намного лучше архитектуры,
[03:03.880 --> 03:12.840]  которые вы реализуете сами. И в частности, этим занимаются китайцы из компании Лунгсу. А также
[03:12.840 --> 03:18.720]  в России еще в 90-е годы архитектура MIX была куплена научно-исследовательским институтом
[03:18.720 --> 03:27.240]  системных исследований. И Neisseran делает процессоры, которые по современным меркам очень слабые,
[03:27.240 --> 03:35.080]  но зато эти процессоры выдерживают достаточно приличную радиацию, поэтому они могут летать в космос
[03:35.080 --> 03:47.320]  и вообще их ставят туда, что должно летать где-то высоко, стрелять. В общем, такие вещи можно даже
[03:47.320 --> 03:54.920]  воспроизвести, но для этого опять же требуется лицензия. Где процессоры можно производить? Можно
[03:54.920 --> 04:03.560]  и в России, но дешевле это сделать на форсе в Тайване. И что произойдет, если вдруг нам запретят
[04:03.560 --> 04:11.840]  производить процессоры по какой-то американской лицензии? А произвести это может в любой момент.
[04:11.840 --> 04:22.720]  Ну, тогда все. Мы, конечно, можем это делать и в России, но ни одна коммерческая компания мировая
[04:22.720 --> 04:28.240]  просто за этот заказ не возьмется. Китайцы уже давно поняли, когда началась вся эта история с
[04:28.240 --> 04:36.000]  компанией Huawei и начали развивать уже open source. Вот чем хорош open source? Это общественное
[04:36.000 --> 04:41.280]  достояние, и никто не может заявить о том, что вы нарушаете какие-то лицензионные ограничения,
[04:41.280 --> 04:52.480]  и поэтому с этой компанией запрещено работать, запрещено производить их чипы по заказу. Ну и вот
[04:52.480 --> 04:57.840]  компания C5 это китайская, ну и есть еще российская компания, которая называется Micron, которая тоже
[04:57.840 --> 05:06.320]  недавно начала делать микроконтроллеры на базе ядра RISC-V. Ну и я думаю, что в ближайшее время,
[05:06.320 --> 05:12.920]  ну я не имею в виду не прямо сейчас, не до конца нового года, в ближайшие несколько лет, эта
[05:12.920 --> 05:19.920]  архитектура станет очень популярной. Кроме того, под архитектуру RISC-V уже давно существуют все
[05:19.920 --> 05:26.600]  средства разработки, на самом деле она достаточно старая, но долгое время существовала только на
[05:26.600 --> 05:36.440]  эмуляторах. Под все это дело нужно еще как-то писать программы. Ну когда-то писали программы в
[05:36.440 --> 05:42.560]  машинных кодах на языках ассемблера, причем у каждой архитектуры язык ассемблера свой. Когда-то этот
[05:42.560 --> 05:51.240]  бардак решили устранить и написали такой ассемблер, который работает на всех существовавших
[05:51.240 --> 05:59.880]  архитектурах. Называется ассемблер язык C. Было это очень давно, еще в 1972 году, на самом деле язык C не был
[05:59.880 --> 06:07.200]  первым, в котором предпринимались попытки сделать какой-то кроссподформенный язык, на котором можно
[06:07.200 --> 06:15.320]  писать программы под разные процессоры. До этого существовал язык B, очень похожий на C, и язык C
[06:15.320 --> 06:21.000]  является дальнейшим продолжением, как следует из названия. А вот языка по названиям A, ну как бы логично,
[06:21.000 --> 06:29.200]  буквы A, B, C в английском фолиете. Вот языка A не было. Язык B это синтаксически приоработанный язык BCPL,
[06:29.200 --> 06:36.600]  и в чем роднит, в чем общее искусство этих языков, то, что на них можно писать очень
[06:36.600 --> 06:42.720]  низкоуровневую программу. Ну а дальше уже историю вы, наверное, сами знаете. В какой-то момент появился
[06:42.720 --> 06:49.400]  язык C++, которым у вас теперь учат. Дальше еще появился язык D, но он популярным особо не стал,
[06:49.400 --> 06:57.320]  потому что примерно в то же время начал активно развиваться язык C++, начиная с 11 стандарта. Один
[06:57.320 --> 07:03.280]  из авторов языка D, Андрей Александреску, начал активно принимать участие в стандартизации
[07:03.280 --> 07:10.160]  языка C++ и его развитие. Ну и кроме того, существует огромное количество всяких разных других
[07:10.160 --> 07:15.880]  языков. И вот с одной стороны, у нас есть огромное количество процессорных архитектур, с другой стороны,
[07:15.880 --> 07:21.000]  есть огромное количество языков программирования, то есть получаем некоторые двудольные графы,
[07:21.000 --> 07:29.440]  и если у нас огромное количество вершин из левого и справа, то, наверное, у нас должно существовать
[07:29.440 --> 07:42.320]  огромное количество ребер. И некоторой помощью такой единой точкой является внутреннее представление,
[07:42.320 --> 07:50.160]  он же язык под названием LLVM. Это некоторый фреймворк, который позволяет легко создавать компиляторы.
[07:50.160 --> 07:56.280]  Ну как легко? Я в свое время участвовал в разработке одного из компиляторов, в том числе с использованием
[07:56.280 --> 08:02.600]  LLVM. Я бы не сказал, что это прямо такое приятное удовольствие, потому что фреймворк с точки зрения
[08:02.600 --> 08:09.560]  программной реализации достаточно отвратительный. У него с каждой мажорной, в то время еще минорной версии,
[08:09.560 --> 08:16.880]  меняется API, причем иногда в самых странных местах, типа заглавную вубовь меняли на строчную,
[08:16.880 --> 08:23.080]  или еще что-нибудь, и совместимость сломают. В общем, LLVM это фреймворк, который, с одной стороны,
[08:23.080 --> 08:31.320]  состоит из наборов компиляторов, которые его используют. Это может быть все семейство C-подобных
[08:31.320 --> 08:40.800]  языков, то есть C+, Objective C, также Rust, Swift и еще много других языков. В принципе, почитайте
[08:40.800 --> 08:47.520]  Википедию, там где-то наверняка аспирки есть. И с другой стороны, у нас после того, как мы
[08:47.520 --> 08:53.480]  генерируем какое-то промежуточное представление, оно более-менее стандартизовано, мы можем из этого
[08:53.480 --> 09:02.160]  внутреннего представления генерировать код для каких-то уже целевых архитектур. Это x86,
[09:02.160 --> 09:09.200]  ARM, MIPS, а также огромное количество всяких разных других процессов. И с одной стороны,
[09:09.200 --> 09:15.480]  можно бы общелять, что вот это промежуточный язык представления является каким-то универсальным,
[09:15.480 --> 09:24.440]  принять его как единый международный стандарт. Но, тем не менее, этого до сих пор не произошло,
[09:24.440 --> 09:32.120]  и более того, в разных версиях framework-allegium этот язык тоже модифицируется, и он не может
[09:32.120 --> 09:37.120]  быть использован как что-то промежуточное, что можно доставлять на целевое устройство пользователей.
[09:37.120 --> 09:44.080]  В этом плане существует еще один промежуточный язык, который называется Java Bytecode,
[09:44.080 --> 09:50.840]  то есть есть такой язык программирования Java, который используется в том числе в Android,
[09:50.840 --> 09:59.120]  только в Android там не классическая Java-машина, немножко другая. Так вот, исходная идея этого
[09:59.120 --> 10:03.840]  языка программирования в том, что вы можете написать какую-то программу, дальше эту программу
[10:03.840 --> 10:07.960]  скомпилировать в некоторое промежуточное представление, которое является строго
[10:07.960 --> 10:14.560]  стандартизированным, и запускать этот код вы можете на любой архитектуре, где есть виртуальная
[10:14.560 --> 10:21.640]  Java-машина. Устроена Java-машина достаточно тривиальным образом, именно это стековый автомат,
[10:21.640 --> 10:26.560]  то есть у нас есть простая программа, которая вычисляет какое-то выражение, превращается в
[10:26.560 --> 10:31.600]  некоторый код, который, кстати, точно также может быть дезасимблирован в текстовое представление,
[10:31.600 --> 10:39.440]  и дальнейшие вычисления выполняются уже с использованием стека. С одной стороны,
[10:39.440 --> 10:48.600]  это хорошее представление, потому что реализовать такую примитивную Java-машину достаточно просто,
[10:48.600 --> 10:56.840]  но в то же время стековый автомат, он не лишен недостатков, например, его реализация в явном
[10:56.840 --> 11:05.480]  виде, она не очень эффективная с точки зрения производительности. Ну и зачем вообще понимать,
[11:05.480 --> 11:10.240]  как у нас что-то устроено на ассемблере, и когда вам это может пригодиться в реальной жизни? То есть,
[11:10.240 --> 11:16.960]  с одной стороны, общее развитие это полезно, понимать, как устроены программы тоже полезно,
[11:16.960 --> 11:23.000]  но когда может возникнуть ситуация, когда вы действительно ничего не сможете написать,
[11:23.000 --> 11:31.160]  кроме как на ассемблере. Такие случаи, они очень редкие, в основном это если вы взаимодействуете
[11:31.160 --> 11:37.880]  напрямую с оборудованием, то есть если вы пишете что-то для микроконтроллеров, то иногда у вас
[11:37.880 --> 11:44.040]  возникают задачи, что вам нужно взаимодействовать с портами ввода-вывода, прерываниями, выполнять
[11:44.040 --> 11:51.040]  системные вызовы, и здесь, кроме как низкоурованными инструкциями, пользоваться не можете. Почему? Потому
[11:51.040 --> 11:58.920]  что в высокоуровнях языках программирования, таких как C, C++, просто нет никаких устроенных
[11:58.920 --> 12:07.000]  универсальных инструментов, которые будут работать в УСГ. Ну и когда-то еще ассемблер использовали для
[12:07.000 --> 12:15.120]  небольших вставок с использованием векторных инструкций. Векторные инструкции нужны были для того,
[12:15.120 --> 12:22.920]  чтобы делать наш код быстрее. Что такое векторные инструкции? Что такое регистры, вы знаете,
[12:22.920 --> 12:29.960]  регистры позволяют хранить данные определенного типа. Точнее, тут даже не важно какой тип, они
[12:29.960 --> 12:35.080]  просто хранят данные определенного размера. Какой там тип, тоже определяется отдельными инструкциями.
[12:35.080 --> 12:43.160]  Регистров мало, они очень дефицитные, но с ними работать очень быстро, и можно сделать просто
[12:43.160 --> 12:53.360]  какой-то большой регистр, замкнуть на него блоки, которые существуют в процессоре стандартные,
[12:53.360 --> 12:58.960]  и сделать так, чтобы эти блоки одновременно выполняли операцию сразу над несколькими частями
[12:58.960 --> 13:04.160]  регистр. Поскольку сделать это достаточно недорого с точки зрения схемотехники,
[13:04.160 --> 13:10.680]  но за счет этого мы получаем существенное ускорение производительности, потому что,
[13:10.680 --> 13:16.680]  если у нас требуется выполнять какие-то операции, причем операции одинаковые на
[13:16.680 --> 13:22.080]  каким-то большим объемам данных, то мы можем сделать это параллельно. И, как раз таки,
[13:22.080 --> 13:29.680]  регистры называются векторными, они имеют размер от 128 бит и выше, и позволяют внутри себя хранить
[13:29.680 --> 13:39.560]  данные разных размеров, то есть этому будет либо большее количество 300 битных значений,
[13:39.560 --> 13:46.240]  либо меньшее количество 700 битных, но при этом вы все равно получаете заметную ускорение.
[13:46.240 --> 13:53.920]  И бывают два вида операций. Это либо вертикальные операции, когда вы берете два вектора и
[13:53.920 --> 14:02.080]  оперируете над ними как над какими-то множествами разных значений, либо горизонтальные операции,
[14:02.080 --> 14:07.200]  когда вам нужно полвекторы получить какой-то скаляр. Примеры скалярных горизонтальных операций,
[14:07.200 --> 14:14.560]  это, например, поиск минимального или максимального значения, ну или в какой-то степени скалярное
[14:14.560 --> 14:21.240]  произведение, если у вас только два вектора. И вот такие векторные инструкции, они когда-то
[14:21.240 --> 14:26.800]  впервые появились в идолской архитектуре, на самом деле они есть и в других архитектурах,
[14:26.800 --> 14:35.520]  и почему такие вещи не обязательно писать на ассемблере. Ну, во-первых, какие бывают у нас
[14:35.520 --> 14:52.400]  инструкции. Есть регистры XMM, есть еще регистры YMM, ZMM. Как понять, какие наборы команд у вас
[14:52.400 --> 14:58.440]  поддержит процессор. Если у вас система Linux, то у вас есть файл-система Procfs,
[14:58.440 --> 15:08.440]  и внутри нее есть текстовый файл cpu-info, который отображает информацию о вашем процессоре,
[15:08.440 --> 15:15.480]  точнее о нескольких процессорах. Так, когда я говорю несколько процессоров, вы понимаете,
[15:15.480 --> 15:20.600]  что это не несколько микросхем установленных в вашем компьютере, а несколько ягер, но с
[15:20.600 --> 15:26.520]  логической точки зрения они представляются собой как отдельные процессоры. Так вот, и тут есть
[15:26.520 --> 15:35.720]  такой параметр в выводе как Flux, который в том числе содержит информацию о том, какие расширения,
[15:35.720 --> 15:43.520]  какие дополнительные наборы инструкций процессор поддерживают. Скорее всего, у вас на произвольной
[15:43.520 --> 15:51.120]  взятом компьютере, неважно насколько он старый, как минимум есть инструкции MMX, SSE разных версий,
[15:51.120 --> 15:59.640]  и набор инструкций AVX, ну и AVX2. Если у вас относительно свежий ноутбук, то еще есть инструкции,
[15:59.640 --> 16:08.240]  которые начинаются с префикса AVX512. Там тоже есть несколько разных наборов. На самом деле,
[16:08.240 --> 16:15.680]  поддержка таких расширений, она не обязательно по стандарту, и если вы пишете софт, который должен
[16:15.680 --> 16:21.760]  поддерживать, который должен выполнять операции с использованием векторных инструкций, то по-хорошему
[16:21.760 --> 16:25.600]  нужно проверять, а поддерживает ли процессор векторные инструкции, если нет, то скатываться на
[16:25.600 --> 16:36.480]  фолбек-реализацию. Ну и что за большие векторные регистры, которые вы можете использовать? Чаще
[16:36.480 --> 16:44.200]  всего используются 128-битные регистры, которые называются XMM, которые позволяют либо хранить
[16:44.200 --> 16:50.960]  264-битные значения, либо 438-битных. В этом плане, на самом деле, тип данных float,
[16:50.960 --> 16:56.800]  который представляет собой вещественные числа с не самой высокой точностью, внезапно оказался
[16:56.800 --> 17:04.800]  очень полезным, поскольку если вы пишете, например, обработку видео, либо делаете игрушку, то вам
[17:04.800 --> 17:11.720]  важнее, чтобы обработка выполнялась быстрее, при этом не важно, что вы немножко теряете в
[17:11.720 --> 17:19.760]  качестве изображения, это не такие уж большие потери, но за счет вдвое меньшего размера типа
[17:19.760 --> 17:25.880]  данных, вы позволяете вдвое быстрее обрабатывать эти данные на процессоре используемых векторных
[17:25.880 --> 17:34.360]  инструкций. Ну и в середине нулевых регистр SSE стал в два раза больше, набор команд обозвали AVX,
[17:34.360 --> 17:43.760]  при этом вы можете использовать младшие части AVX регистров с использованием обычных SSE
[17:43.760 --> 17:51.760]  либо MMX команд, ну и современная версия процессоров еще позволяет использовать 12-битные регистры,
[17:51.760 --> 17:57.400]  но это уже узкоспециализированные инструкции и задачи обычно используются в задачах связанных
[17:57.400 --> 18:06.000]  с криптографией. Как использовать такие инструкции? Ну либо писать на ассемблере, что бывает очень
[18:06.000 --> 18:13.680]  часто не очень удобно, либо вы можете продолжать использовать высоковолновые языки C и C++ и делать
[18:13.680 --> 18:21.120]  некоторые вставки использованием так называемых интерсиктов, то есть конструкции, которые оформлены
[18:21.120 --> 18:27.120]  в виде оси ишных функций, но при этом функциями не являются. То есть когда компилятор включает
[18:27.120 --> 18:34.480]  так называемые интерсикты, которые он распознает, если компилятор это поддерживает, то он подставляет
[18:34.480 --> 18:41.800]  вместо них синтексические эквалентные ассемблерные векторные инструкции, но при этом на самом деле
[18:41.800 --> 18:50.680]  никакого вызова реального функции через инструкцию call не происходит. Что делает программа? Она считает
[18:50.680 --> 19:00.120]  скалярное произведение двух векторов. Кто помнит, что такое скалярное произведение? Так молодцы, что это такое?
[19:00.120 --> 19:11.480]  Ну берем попарное произведение всех элементов и считаем их суммой. То есть на самом деле эту
[19:11.480 --> 19:20.400]  программу можно реализовать через обычный цикл, но цикл будет требовать достаточно много инструкций,
[19:20.400 --> 19:28.560]  если мы напишем то же самое с использованием векторных инструкций. Вот та же самая программа,
[19:28.560 --> 19:35.320]  написанная через интерсикты, компилируется. Да, вот для компиляции здесь уже требуется небольшая
[19:35.320 --> 19:42.720]  магия, потому что если вы просто так попросите компилятор gc скомпилировать код, то на интерсикты
[19:42.720 --> 19:49.240]  он нам скажет, что неизвестная инструкция, потому что требуется включить дополнительный набор
[19:49.240 --> 20:03.080]  инструкций с помощью опции минус msse в нужной версии 4.1 или бава x. Вот значение 7, если это
[20:03.080 --> 20:08.280]  произведение 1 умножить на 5, плюс 2 умножить на 6, плюс 3 умножить на 7, плюс 4 умножить на 8.
[20:08.280 --> 20:16.040]  Очень простая программа с простым результатом. На самом деле здесь интереснее посмотреть на тот
[20:16.040 --> 20:24.920]  код, который у нас генерируется. Причем я еще добавляю опцию минус o0 для того, чтобы компилятор
[20:24.920 --> 20:32.040]  ни в коем случае не вздумал никак оптимизировать код и сделать что-то неочевидное. Так, компилируем и
[20:32.040 --> 20:42.520]  смотрим теперь во что этот код у нас превратился. Так, ну и превратился в этот код некоторую
[20:42.520 --> 20:51.600]  пеленку, в которой нет ни одной функции call. Точнее где-то она в конце есть, но это вызов уже
[20:51.600 --> 21:04.680]  принфа для вывода на экран. На самом деле вот ни одна из этих функций, вот ups или dpps, она не
[21:04.680 --> 21:11.880]  вызывается именно как функции. Как сделать скалярное произведение? Мы просто загружаем четыре значения
[21:11.880 --> 21:19.200]  из памяти в один векторный регистр, два массива, два векторных регистр. Дальше выполняем скалярное
[21:19.200 --> 21:24.880]  умножение. Последний параметр в этом случае это некоторая битовая маска, которая указывает,
[21:24.880 --> 21:32.760]  какие из элементов должны участвовать в произведении. Это вот старшие 4 бита и младшие биты указывают,
[21:32.760 --> 21:40.120]  куда, в какую часть этого большого вектора нам нужно записать результат. Можно в принципе
[21:40.120 --> 21:48.440]  растиражировать по всем, но либо использовать только один из них. Кроме неновской архитектуры,
[21:48.440 --> 21:55.520]  бывают еще другие архитектуры, в которых тоже предусмотрены векторные инструкции. Самый
[21:55.520 --> 22:02.520]  распространенный из них это ARM Neon, присутствует практически во всех мобильных телефонах,
[22:02.520 --> 22:10.720]  ну и планшетах тоже. Причем в случае с архитектурой ARM тут есть два разных набора инструкций. Один из них
[22:10.720 --> 22:16.800]  предназначен для использования в потребительской бытовой технике, то есть смартфоны, планшеты,
[22:16.800 --> 22:26.400]  макбуки. И есть еще отдельный набор инструкций под ангелем, который решает примерно те же самые
[22:26.400 --> 22:35.200]  задачи, но уже в микроконтроллерах. Вот архитектуры Cortex-ARM это обычные процессоры широкого
[22:35.200 --> 22:42.160]  спектра назначения, и минус M это микроконтроллер. То есть у нас получается есть интерсикты для
[22:42.160 --> 22:49.200]  интеллоских процессоров, есть два разных вида интерсиктов для ARM, для архитектуры RISC-V так
[22:49.200 --> 22:55.040]  вообще нет никакого стандарта, поскольку стандартная эта архитектура описывает только минимальный
[22:55.040 --> 22:59.920]  необходимый набор инструкций, а все остальное решается расширениями. Ну и еще есть всякие
[22:59.920 --> 23:05.120]  там разные PowerPC, MIPS. Ладно, конечно мы про них можем забыть как про достоинство истории,
[23:05.120 --> 23:12.560]  но тем не менее. У нас уже получается, что если мы хотим использовать векторные инструкции, нам
[23:12.560 --> 23:20.400]  придется сделать три разных реализации для интелл ARM и RISC-V, что уже не очень удобно и спрашивается,
[23:20.400 --> 23:24.720]  зачем вообще тогда было изобретать язык C, если мы в конечном итоге все равно скатились в
[23:24.720 --> 23:30.720]  необходимость использования платформы зависимых каких-то инструкций, то есть по сути ничем не
[23:30.720 --> 23:40.000]  отличаемся от Assembler. Ну есть некоторые решения, в частности это стандарт по названию OpenMP,
[23:40.000 --> 23:48.120]  который позволяет писать обычные программы с циклами и вставлять некоторые дополнительные
[23:48.120 --> 23:55.200]  директивы, так называемые прагмы, которые распознаются компилятором и по этим прагмам
[23:55.200 --> 24:02.920]  происходит преобразование кода с использованием уже как симпт инструкции, так и распроявлевание
[24:02.920 --> 24:10.080]  с использованием многопоточности. Ну распроявление с использованием многопоточности, оно в сочетании
[24:10.080 --> 24:17.600]  с OpenMP не очень распространено, поскольку это проще сделать вручную, а вот распроявление на
[24:17.600 --> 24:27.320]  уровне симпт инструкции с помощью OpenMP достаточно часто используется и если вы еще сдадите две сессии,
[24:27.320 --> 24:31.920]  то вы доживете до третьего курса, на третьем курсе у вас будет курс по названиям проявление
[24:31.920 --> 24:36.880]  распроявления вычисления, про OpenMP вам в том числе будет тоже рассказывать, у вас на этом даже будут
[24:36.880 --> 24:49.200]  домашки. Так, ну и поскольку набор задач, которые решаются с помощью векторных вычислений,
[24:49.200 --> 24:57.640]  он достаточно ограничен, то есть у нас не так много команд на самом деле и решают они что-то,
[24:57.640 --> 25:08.040]  что можно писать математическим языком, по сути это вся линейная алгебра, то есть уже готов в библиотеке,
[25:08.040 --> 25:18.000]  которые реализуют большую часть того, что вам, что вы могли бы писать вручную. Называется стандарт
[25:18.000 --> 25:32.040]  Basic Learner Programs, очень старая библиотека под названием NetBlast, которая дала этот стандарт и первую
[25:32.040 --> 25:38.560]  реализацию. Впоследствии эту реализацию переписали под разные процессорозависимые
[25:38.560 --> 25:47.800]  архитектуры, в том числе под GPU. И где используется Blast? На самом деле, если у вас установлен Python,
[25:47.800 --> 25:54.200]  если у вас установлена библиотека NumPy, то скорее всего она у вас использует именно интерфейс Blast,
[25:54.200 --> 26:03.200]  но маловероятно, что у вас стоит реализация NumPy, которая его не использует. И вот как раз в этих
[26:03.200 --> 26:10.600]  библиотеках, которые могут быть в том числе и закрытыми, а не опенсорсными, реализуется вся
[26:10.600 --> 26:18.640]  функциональность, которая используется Data Sanitizer. Ну и в свою очередь накладываются еще некоторые
[26:18.640 --> 26:27.800]  ограничения на данные, то есть как можно еще ускорить работу с большим объемом данных. Если у вас
[26:27.800 --> 26:36.400]  есть векторы, векторные регистры большого размера, то понятно, что удобнее загружать данные из памяти
[26:36.400 --> 26:44.000]  и сохранять обратно в память таким образом, чтобы процессор не проходилось пересчитывать адреса,
[26:44.000 --> 26:52.840]  выполнять какие-то сдвиги, то есть сделать данные в памяти выровненные по размеру регистра.
[26:52.840 --> 27:01.680]  Стулкой выравнивания данных вы с этим уже сталкивались, когда мы смотрели вызов каких-то
[27:01.680 --> 27:07.640]  функций с использованием стека и часто натакались на ограничение, что стек должен быть выровнен по
[27:07.640 --> 27:18.080]  границе 16 байт. 16 байта как раз 128 бит и на самом деле, если вы поставите себе откладывающую
[27:18.080 --> 27:25.080]  информацию для стандартной AC библиотеки и сделаете стек не выровненным по границе 16 байт, то под
[27:25.080 --> 27:33.240]  откладчиком вы увидите, что падение с этим связанное происходит где-то при использовании векторных
[27:33.240 --> 27:40.400]  инструкций, а именно стандартной AC библиотеки, когда вы делаете вызов какой-нибудь функции,
[27:40.400 --> 27:48.560]  то многие функции просто выполняют целиком копирование какого-то набора векторов, в том
[27:48.560 --> 27:56.680]  числе векторных, сохранение в стек и за счет того, что стек у вас не выровнен по границе 16 байт,
[27:56.680 --> 28:03.200]  происходит проблема, связанная с функциями чтения и загрузки вот как раз именно векторных.
[28:03.200 --> 28:11.920]  Ну можно конечно выровнивать и делать в том числе явным образом для этих данных, а не только для
[28:11.920 --> 28:20.520]  стека, но во-первых, если вы делаете память в куче, то это сильно упрощает вам задачу, вы можете либо
[28:20.520 --> 28:28.920]  просто выделить память с запасом и пересчитать указатель, либо использовать уже готовые функции
[28:28.920 --> 28:37.080]  из POSIX, либо стандартной AC библиотеки, если вы выделяете память на стеке, то в языках AC и C++
[28:37.080 --> 28:44.400]  есть еще одно специальное ключевое слово aligns, которое предназначено для указания, как именно
[28:44.400 --> 28:52.680]  данные должны быть выровнены при размещении на стеке. И для чего нужно выравнивать? Ну во-первых,
[28:52.680 --> 28:58.280]  для использования векторных инструкций, во-вторых, если вы аккуратно понимаете, как у вас данные
[28:58.280 --> 29:05.120]  выровнены в памяти, то это может еще положительно сказаться на том, как данные у вас размещаются в
[29:05.120 --> 29:15.680]  кэш. И кэш-память на самом деле это достаточно важное понятие в архитектуре. В самых первых
[29:15.680 --> 29:19.960]  процессорах, ну и вообще в современных микроконтроллерах кэш-память не используется,
[29:19.960 --> 29:31.280]  она важна только там, где требуется хоть какая-то более-менее адекватная производительность и из
[29:31.280 --> 29:38.680]  каких соображений она появляется. Начнем с того, что у нас бывают два разных типа памяти. Это
[29:38.680 --> 29:46.320]  память статическая и память динамическая. Одна ячейка статической памяти это от 4 до 8 транзисторов,
[29:46.320 --> 29:55.600]  достаточно сложная такая конструкция. Чем она примечательна? Для чтения требуется один такт,
[29:55.600 --> 30:02.280]  для записи требуется два такта и с какой частотой может работать эта ячейка памяти. Но фактически
[30:02.280 --> 30:08.640]  с той частотой, с которой у вас работает процессор или еще какой-то вычислительный элемент. Здесь
[30:08.640 --> 30:13.240]  все ограничивается только уже физическими возможностями, то есть размерами транзисторов,
[30:13.240 --> 30:23.440]  которые у вас на микросхеме. Чем такая память плоха? Несколько транзисторов, они кушают много
[30:23.440 --> 30:30.240]  электроэнергии, во-первых, во-вторых, их просто много и поскольку у вас ограниченная площадь
[30:30.240 --> 30:36.320]  кристалла, то много памяти в этом разместить не сможет. В противоположности этому динамическая
[30:36.320 --> 30:41.880]  память это совершенно тупейшая вещь, просто конденсатор, на самом деле конденсатор в микросхемах,
[30:41.880 --> 30:50.280]  это отсутствующий элемент, поскольку может быть реализован просто расстояние между двумя проводниками,
[30:50.280 --> 30:58.880]  соседними. То есть фактически это один транзистор плюс как-то хитро расположенный проводник. Очень
[30:58.880 --> 31:03.760]  простая схема, поэтому динамической памяти вы можете на ту же площадь кристалла разместить
[31:03.760 --> 31:13.400]  намного больше. И как эта штука работает? Она просто заряжает конденсатор, при чтении он
[31:13.400 --> 31:22.600]  разряжается, его нужно перезарядить. Все, достаточно просто. Поставить 1 или 0, это значит либо разрядить
[31:22.600 --> 31:27.680]  конденсатор, то есть примедительно прочитать и никуда не запомнить результат, либо его наоборот
[31:27.680 --> 31:35.000]  подзарядить. Очень простая ячейка, поэтому динамической памяти вы можете напихать очень много.
[31:35.000 --> 31:43.580]  Какие здесь недостатки? Во-первых, время заряда и разряду конденсатора, оно не нулевое, поэтому такая
[31:43.580 --> 31:50.760]  память работает медленнее. И кроме того, требуются еще циклы перезарядки. То есть на микросхему
[31:50.760 --> 31:54.600]  динамической памяти требуется еще завести дополнительную микросхему, которая будет периодически
[31:54.600 --> 32:03.720]  через определенные интервалы перезаряжать конденсаторы, то есть читать значения и записывать их
[32:03.720 --> 32:12.240]  заново. Достаточно громоздкая схема. И где какие микросхемы используются? Микросхемы динамической
[32:12.240 --> 32:17.800]  памяти используются практически везде, где мы говорим про слово память. То есть оперативная
[32:17.800 --> 32:22.040]  память, которая у вас несколько гигабайт установлена в телефоне или в ноутбуке, или еще
[32:22.040 --> 32:28.000]  где-нибудь. Это все динамическая память, потому что она дешевая, мы можем ее в больших количествах
[32:28.000 --> 32:36.040]  достаточно недорого использовать. В то же время бывают устройства, например, микроконтроллеры,
[32:36.040 --> 32:43.240]  в которых не требуется много памяти, поэтому там используется только статистическая память. И
[32:43.240 --> 32:48.960]  здесь получается экономия за счет того, что нам не требуется дополнительная схемотехника. Вот как
[32:48.960 --> 32:57.600]  раз для перезарядки конденсаторов и для того, чтобы после чтения как-то временно буферизовать эти
[32:57.600 --> 33:01.120]  дамы. То есть там, где у вас есть небольшой микроконтроллер, скорее всего, с динамической
[33:01.120 --> 33:05.200]  памяти нет, там только статистическая память просто за счет простоты, потому что много памяти
[33:05.200 --> 33:10.360]  вам не требуется. И кроме того, поскольку статистическая память работает во много раз быстрее
[33:10.360 --> 33:17.160]  динамической, то она остается в качестве промежуточного буфера между процессором и
[33:17.160 --> 33:23.960]  между ядром процессора и оперативной памяти для того, чтобы ускорить доступ к каким-то
[33:23.960 --> 33:36.600]  часто используемым фрагментам. Но как можно получить информацию о кэш-память вашего
[33:36.600 --> 33:45.320]  процессора? Опять же, если у вас есть система Linux, а не BSD, не Mac, не Windows, то вы можете зайти
[33:45.320 --> 33:56.160]  в виртуальную файловую систему slash sys, там есть у вас такой подкаталог devices, который описывает
[33:56.160 --> 34:04.800]  все устройства, которые у вас доступны из ядра операционной системы, там есть дальше система
[34:04.800 --> 34:12.880]  и процессор. Процессоров, причем может быть несколько, CPU 0, CPU 1, CPU 2, CPU 3, на самом деле это один
[34:12.880 --> 34:19.520]  тот же процессор, просто разные его ядра. По какому из них смотреть информацию не особо принципиально,
[34:19.520 --> 34:27.040]  поскольку у большинства процессоров все ядра одинаковые, но за исключением ARM, у которых
[34:27.040 --> 34:33.760]  бывают ядра быстрые, бывают ядра энергоэффективные. Итак, мы заходим информацию по процессору,
[34:33.760 --> 34:44.920]  что мы можем узнать. Нас интересует на этой лекции кэш-память, и кэш-память у нас бывает
[34:44.920 --> 34:52.200]  несколько уровней, каждый подкаталог содержит набор текстовых файлов, соответствующих каждому
[34:52.200 --> 35:00.520]  конкретному уровню. 0, 1, 2, 3 – это разные уровни кэш-памяти, на самом деле их всего три,
[35:00.520 --> 35:05.720]  а просто первый уровень в интеловских процессорах делится еще на две части – отдельный кэш для данных
[35:05.720 --> 35:12.240]  и отдельный кэш для инструкций. Вот в каждом подкаталоге есть файл по названиям type, в котором
[35:12.240 --> 35:19.200]  написано предназначение этого кэша. Вот дейта означает, что это кэш для данных, индекс 0, кэш 1,
[35:19.200 --> 35:29.640]  написано instruction – это кэш только для инструкций, но кэши более верхнего уровня 2 и 3 уже предназначены
[35:29.640 --> 35:35.680]  для того, чтобы хранить смешанные данные без разбора на данные инструкции, они называются Unified.
[35:35.680 --> 35:46.440]  Какие у нас бывают уровни кэши? Самый далекий от процессора, но ближе всего располагающийся к
[35:46.440 --> 35:53.640]  памяти уровень L3 используется всеми ядрами процессора. Когда процессоры были одноядерными,
[35:53.640 --> 35:59.480]  то обычно под кэшем L3 поджимались какие-то дополнительные платы, которые устанавливают
[35:59.480 --> 36:06.680]  системную плату. Кроме того, у каждого ядра может быть свой кэш, в который никто другой
[36:06.680 --> 36:14.680]  лазить не может. Ну и самый близкий к ядру кэш в некоторых процессорах делится на две части,
[36:14.680 --> 36:22.240]  в некоторых нет. Обычно имеет самый небольшой размер, но к нему самый быстрый доступ. Казалось бы,
[36:22.240 --> 36:28.000]  одни и те же микросхемы статической памяти, доступ может быть очень быстрый ко всем уровням,
[36:28.000 --> 36:35.480]  но здесь мы еще теряем некоторое время на то, чтобы выполнить преобразование из адресного
[36:35.480 --> 36:41.120]  пространства внутри кэшированных данных в адресное пространство, которое у нас реально
[36:41.120 --> 36:47.920]  физическое на всю память. И в этом плане у нас L1 быстрее, чем L2 и L3. Ну и в L3 еще требуются
[36:47.920 --> 36:58.080]  механизмы синхронизации между разными ядрами. Так вот, на что у нас влияют, какие у нас бывают
[36:58.080 --> 37:03.960]  характеристики кэша. Во-первых, это у нас может быть уровень кэша, либо ближе всего к ядру,
[37:03.960 --> 37:10.600]  либо дальше от него. Дальше у нас какие-то ядра, какие-то уровни кэша могут использоваться
[37:10.600 --> 37:18.320]  несколькими ядрами, либо только одни. Вот shared list CPU — это некоторая характеристика,
[37:18.320 --> 37:26.360]  которая указывает, каким инут мэп это генар убитая маска. Если у нас процессов с индексом 0,
[37:26.360 --> 37:34.400]  то shared list CPU для его локального кэша будет 0, для первого 1, если мы посмотрим на кэш третьего
[37:34.400 --> 37:40.480]  уровня, то он уже используется сразу двумя, либо четырьмя, либо еще с какими-нибудь ядрами.
[37:40.480 --> 37:51.000]  Что еще интересного? Ну и размер кэша. Какие характерыны есть размеры у кэша? Это либо
[37:51.000 --> 37:59.920]  несколько килобайт для кэша L1, который самый быстрый, а вот для кэша самого последнего уровня
[37:59.920 --> 38:07.040]  тут все зависит от того, сколько стоит ваш процессор. В бюджетных моделях это может быть всего
[38:07.040 --> 38:15.760]  пара мегабайт, в дорогих процессорах, например в Intel Xeon в прошлом году из того, что можно было
[38:15.760 --> 38:21.240]  реально купить в Москве, самые большие были порядка 35 мегабайт, в этом году, конечно, уже и побольше,
[38:21.240 --> 38:31.960]  но все равно это не гигабайты, то есть размер кэша на три порядка десятичной записи дороже,
[38:31.960 --> 38:36.280]  чем оперативная память, которая является динамической. И тут возникает естественная
[38:36.280 --> 38:43.160]  проблема, а как запихать невпихуемое? То есть у вас есть вся оперативная память,
[38:43.160 --> 38:48.680]  которая может быть много гигабайт, и если вы пишете какую-то большую программу, то возможно,
[38:48.680 --> 38:55.120]  что несколько гигабайт вам может потребоваться даже в рамках одного процесса. И возникает проблема
[38:55.120 --> 39:02.760]  с тем, как выбирать данные, которые должны попадать в кэш. И естественное при обращении к какому-то
[39:02.760 --> 39:10.120]  произвольному участку в памяти у вас может возникать ситуация, что данные в кэш не загружены,
[39:10.120 --> 39:18.800]  потому что это место уже было кем-то занято. И вот такая ситуация, которая называется кэш промах,
[39:18.800 --> 39:24.960]  из-за чего может возникать? Ну, во-первых, вы могли еще ни разу не обратиться к какой-то участку
[39:24.960 --> 39:30.960]  физической памяти, поэтому данные не были закэшированы. Но это не страшно, вы один раз
[39:30.960 --> 39:36.280]  прочитали, все, после этого данные находятся в кэше, вы можете с ними в кэше работать и радоваться
[39:36.280 --> 39:42.720]  жизни. В какой-то момент данные из кэша могут выгружаться просто потому, что место закончилось,
[39:42.720 --> 39:50.680]  и надо загрузить другие данные, а размер кэша у вас сильно меньше, чем размер памяти. Либо
[39:50.680 --> 39:59.160]  данные были выгружены из кэша из-за нарушения свойства ассоциативности, поскольку процессор
[39:59.160 --> 40:04.440]  тоже делает какие-то предположения о том, какие данные должны быть в кэше, а какие нет, для того,
[40:04.440 --> 40:11.760]  чтобы увеличить вероятность того, что он будет всегда работать с актуальными данными. И вот что
[40:11.760 --> 40:18.960]  такое ассоциативность и как она связана с тем, что у вас в кэше располагается? Вся кэш-память
[40:18.960 --> 40:28.200]  делится на некоторые ячейки, некоторые минимальные блоки. Размер блока, он определяется, опять же в
[40:28.200 --> 40:37.800]  этом файле вы можете найти геринси line size. Для индовского процессора это будет всегда 64 байта,
[40:37.800 --> 40:47.160]  причем я смотрел в разных процессорах, и зионах, и i5, и ватонах, они везде 64 байта. Если не Intel,
[40:47.160 --> 40:52.200]  AMD, ну возможно там могут быть какие-то другие значения. Так вот, есть некоторые небольшие блоки,
[40:52.360 --> 40:59.640]  некоторые минимально возможные адресуемые куски, которые попадают в кэш-память. Размером по 64 байта,
[40:59.640 --> 41:09.920]  а вот сам блок, плюс метаданные, которые определяют, где этот блок находится реально в памяти, называется
[41:09.920 --> 41:17.880]  кэш-линия. Из кэш-линии у нас образуются некоторые горизонтальные участки, некоторые наборы,
[41:17.880 --> 41:24.440]  и количество наборов оно может быть занято определенным процессом, который у вас в текущем
[41:24.440 --> 41:30.080]  моменте выполняется. Поскольку у вас одновременно в памяти может находиться сразу несколько программ,
[41:30.080 --> 41:40.560]  они могут выполняться на разных ядрах. Мы можем объединять при этом какие-то кэш-линии по вертикали,
[41:40.560 --> 41:55.040]  и вот одна строка, это так называемые Ways of Associativity, это некоторое множество различных
[41:55.040 --> 42:03.240]  возможных вариантов доступа, то есть вы выполняете какую-то программу, и вашей программе одновременно
[42:03.240 --> 42:12.120]  может быть нужно до 12 разных кусков из разных участков физической памяти. Поскольку эти блоки
[42:12.120 --> 42:20.080]  могут быть далеко отстоящими друг от друга, то каждый такой столбец в организации кэша,
[42:20.080 --> 42:25.680]  который доступен вашему процессу, может ссылаться на разные достаточно далеко
[42:25.680 --> 42:32.000]  разнесенные друг от друга участки физической памяти, например, стэк, плюс какая-то часть кучи,
[42:32.000 --> 42:38.760]  плюс код программ, плюс библиотека, плюс кроме того есть еще в каждой программе таблица отображения
[42:38.760 --> 42:44.040]  из виртуального распространения физическую память. На самом деле достаточно много разных частей,
[42:44.040 --> 42:51.040]  которые нужно одновременно адресовать, но количество таких независимых участков, оно ограничено
[42:51.040 --> 42:59.000]  для каждого процессора, и в инвалидских процессорах их не более чем 12, и на самом деле это очень мало.
[42:59.000 --> 43:11.680]  Поэтому возникает проблема о том, как наиболее эффективно использовать кэш, и любой софт должен
[43:11.680 --> 43:19.640]  писаться с учетом того, что вы не можете никак повлиять на кэш, но вы можете сделать так,
[43:19.640 --> 43:25.320]  чтобы данные с большей вероятностью в кэш попадали, эти данные были актуальны и действительно
[43:25.320 --> 43:31.720]  востребованы. Как этого добиться? Во-первых, данные нужно располагать непрерывным куском,
[43:31.720 --> 43:38.440]  чтобы они не были разбросаны по всей оперативной памяти, во-вторых, для того чтобы данные быстрее в
[43:38.440 --> 43:47.320]  кэш память загружались, то желательно сделать их выровненными по границе кратной размеру кэш линии
[43:47.320 --> 43:54.080]  процессора. Размер кэш линии для инвалидских процессоров это 64 байта, что мы можем 64 байта
[43:54.080 --> 44:06.000]  запихать? Достаточно много, либо 4 SSE регистра, либо один большой 512 битный регистр. И как еще
[44:06.000 --> 44:12.720]  можно эффективно использовать кэш? В первую очередь располагать связанные между собой данные как
[44:12.720 --> 44:22.160]  можно ближе друг к другу. И повлиять как-то на использование кэша вы не можете даже если будете
[44:22.160 --> 44:26.480]  писать программу на Assembler. То есть нет таких инструкций, которые указывают процессор явным
[44:26.480 --> 44:33.520]  образом такой-то кусок памяти загрузить в кэш. Это можно делать только косвенным образом. Например,
[44:33.520 --> 44:42.680]  оптимизирующие компиляторы C, C++ при обращении к каким-то данным просто генерируют в определенной
[44:42.680 --> 44:49.320]  период времени какие-то инструкции, которые должны подтягивать данные, просто обычные инструкции
[44:49.320 --> 44:55.040]  загрузки. И вставляют инструкции загрузки так, чтобы они хронологически следовали
[44:55.040 --> 45:05.480]  немного заранее, чем эти данные должны быть доступны. И таким образом можно как-то косвенно
[45:05.480 --> 45:13.320]  управлять кэшируем. Опять же компилятор сделает лучше, чем если вы будете делать вручную. Вручную
[45:13.320 --> 45:20.520]  надо посмотреть на программу, на артикуру программы в целом. И классический пример правильного или
[45:20.520 --> 45:26.520]  неправильного использования кэша это когда вы работаете с какими-то алгоритмами, которые
[45:26.520 --> 45:35.320]  требуют двумерные массивы. Канонически такой пример на плюсах. Как реализовать матрицу,
[45:35.320 --> 45:42.040]  умножение двух матриц. С алгоритмической точки зрения здесь приведен не самая лучшая
[45:42.040 --> 45:50.400]  реализация, потому что требует время порядка от n в кубе. Кстати, две матрицы можно, за какое время
[45:50.400 --> 46:04.760]  можно. Да, есть алгоритмы Штрасена, поэтому два в степени 2 и 7. Можно сделать лучше, но мы сейчас
[46:04.760 --> 46:11.080]  не рассматриваем алгоритмическую вставляющую этой программы. Нас интересует только техническая
[46:11.080 --> 46:20.600]  вставляющая. И вот чем плох вектор векторов, двумерный массив, тем что у нас данные просто разбросаны
[46:20.600 --> 46:27.320]  по памяти. Вектор векторов это по сути массив указателей, если переводить плюсовый язык
[46:27.320 --> 46:34.160]  анонсичный. И каждый указатель на какой-то произвольный участок в куче, где уже непрерывно
[46:34.160 --> 46:40.280]  лежат данные. И это очень плохая ситуация с точки зрения кэширования, потому что у вас данные
[46:40.280 --> 46:48.760]  разбросаны по кэшу как попало, и будет требоваться дополнительное время на загрузку, и меньше
[46:48.760 --> 46:57.480]  вероятность того, что все данные будут в кэше. Ситуация много улучшается, если вы, зная размер
[46:57.480 --> 47:04.960]  матрицы, храните ее в виде одномерного массива каким-то одним большим непрерывным куском в памяти.
[47:04.960 --> 47:17.720]  Да, ну и еще есть некоторое ограничение на использование кэша, как данные у вас изменяются
[47:17.720 --> 47:23.920]  либо не изменяются. Вот в языках CAC++ есть ключевое слово const, которое что означает?
[47:23.920 --> 47:31.600]  Оно не означает ровно ущербно для компилятора ничего, кроме того, что нужно дополнительно ваш
[47:31.600 --> 47:36.720]  код проверить и отругаться, выдать ошибку. На самом деле, если вы пишете const, то это никакой
[47:36.720 --> 47:42.520]  константости не гарантирует, и компилятор не имеет права делать никаких оптимизаций.
[47:42.520 --> 47:50.200]  Есть еще ключевое слово под названием restrict в языке C. В плюсах такого ключевого слова нет,
[47:50.200 --> 47:57.440]  там есть некоторые нестандартные для разных компиляторов аналоги. Вот это ключевое слово
[47:57.440 --> 48:04.760]  означает, что вы гарантируете, что данные из вне не будут меняться, поэтому компилятор вправе
[48:04.760 --> 48:11.360]  сгенерирует дополнительный код, чтобы предзагрузить что-то в кэш-память. Так вот, возвращаясь к правильной
[48:11.360 --> 48:19.400]  реализации, когда мы сделаем программу для умножения матриц или вообще для работы с
[48:19.400 --> 48:27.680]  двумерными массивами, но будем представлять массив в одномерном виде, даст нам достаточно заметное
[48:27.680 --> 48:36.200]  улучшение в плане производительности. Теперь вопрос в том, насколько мы что-то сможем улучшить.
[48:36.200 --> 48:45.640]  Вот две реализации. Во-первых, неоптимизированная реализация. Давайте перемножим две матрицы
[48:45.640 --> 48:55.440]  размером 1000 на 1000, используя обычный вектор векторов, то есть двумерный массив. Да, современный
[48:55.440 --> 49:03.600]  процесс это корой-5, просто умножает две матрицы. Казалось бы, миллионы инструкций в секунду. Тем не менее,
[49:03.600 --> 49:09.200]  6,5 секунд понадобилось для того, чтобы всего лишь перемножить две матрицы 1000 на 1000.
[49:09.200 --> 49:24.560]  Окей, давайте сделаем теперь все то же самое, но уже с использованием одномерного массива.
[49:24.560 --> 49:38.120]  И точно также замерим время, сколько у нас займет это умножение. Так, тоже достаточно
[49:38.120 --> 49:48.400]  долго, но уже четыре с половиной секунды. Разница в полтора раза. Просто за счет того,
[49:48.400 --> 49:56.320]  что мы грамотно используем кэшпад. И вот таких мелочей в ваших программах может быть очень много,
[49:56.320 --> 50:03.440]  они не только могут быть связаны с использованием кэширования, на самом деле слабых мест у вас может
[50:03.440 --> 50:13.080]  быть сколько угодно много. И как вообще выяснять, а где у вас слабые места? Что такое валгренд? Вы,
[50:13.080 --> 50:20.760]  наверное, уже знаете, вас, наверное, валгрендом уже много раз мучили. Когда вы отправляете какие-то
[50:20.760 --> 50:24.600]  задачи в контест, они у вас не заходят, потому что какие-то проблемы с памятью, на которые вы не
[50:24.600 --> 50:31.440]  обратили внимание, хотя локально все работало. Так вот, валгренд это инструмент, предназначенный
[50:31.440 --> 50:41.600]  для виртуализации каких-то отдельных инструкций и для контролируемого выполнения, и может быть
[50:41.600 --> 50:49.280]  использован не только для проверки проблем с памятью, но и для анализа ваших программ,
[50:49.280 --> 50:55.880]  что именно там происходит. И вот один из инструментов, который входит в валгренд,
[50:55.880 --> 51:01.560]  называется кэшгренд. Как им пользоваться? Давайте теперь найдем, а где у нас слабое место в нашей
[51:01.560 --> 51:13.440]  неоптимизированной программе. Для этого нужно запустить валгренд, один из инструментов для
[51:13.440 --> 51:22.040]  профилирования, в частности кэшгренд, ну и неоптимизированная версия программы, только я не
[51:22.040 --> 51:30.280]  буду запускать на тысячи, иначе мы тут уснем. Поскольку валгренд выполняет программу с некоторой
[51:30.280 --> 51:41.120]  долей интерпретации, то выполнение даже обычной программы в режиме поиска проблем с памятью это
[51:41.120 --> 51:52.440]  уже сильное замедление. Профилировка работает еще медленнее. Запускаем на 500, дальше ждем. Если
[51:52.440 --> 52:00.920]  у вас есть вопросы, вы можете пока их задавать. Валгренд в данном случае используется не как
[52:00.920 --> 52:10.120]  санитазер, а как профилировщик. Есть еще гну профайлер, но он уже давно не развивается,
[52:10.120 --> 52:15.160]  поэтому насколько он хорош, я вам подсказать не смогу. Так, ладно, достаточно долго от нас
[52:15.160 --> 52:22.480]  работал валгренд, причем на меньших количествах данных, и мы получили какой-то файл. Запускался
[52:22.480 --> 52:32.160]  процесс speed 8308, и после себя кэшгренд оставил файл, который называется kagegrnd.out.processid
[52:32.160 --> 52:40.480]  того процесса, который у нас запускался. Используя инструмент под названием kagegrnd,
[52:40.480 --> 52:48.240]  это если у вас линукс, инструмент с графическим интерфейсом, поэтому требуется настоящая система
[52:48.240 --> 52:56.760]  с гуями. Есть аналог под Windows и под Mac, который называется qkagegrnd, то есть буквы k меняем на q,
[52:56.760 --> 53:04.080]  позволяет анализировать дальше полученные файлы с отчетами. Так, cold not connected display,
[53:04.080 --> 53:18.040]  логично, потому что это ssh. Если вы хотите запустить удаленно какую-то программу с
[53:18.040 --> 53:24.800]  графическим интерфейсом, требуется опция ssh-x. В этом случае ssh будет
[53:24.800 --> 53:31.760]  пробрасываться еще порт для x-сервера, да, но при этом еще если у вас Windows и Mac требуется
[53:31.760 --> 53:39.720]  доставить штуку под названием x-сервер, но тем не менее эта штука будет работать. Так, ладно,
[53:39.720 --> 53:48.160]  открываем файл с отчетом и смотрим где у нас там слабые места. Так, слабые места у нас,
[53:48.160 --> 53:58.000]  так, смотрим по стеку вызовов и самое жесткое, это вот как раз 74 процента времени у нас занимает
[53:58.000 --> 54:09.560]  операция вычисления суммы текущего элемента, то есть доступа к элементу массива, но казалось
[54:09.560 --> 54:16.600]  быть для умножения матрицы достаточно очевидно. Если у вас достаточно большой проект, то слабое
[54:16.600 --> 54:23.800]  место в коде у вас может быть не очень очевидным и кроме как с помощью профайлера вы никак это не
[54:23.800 --> 54:34.720]  найдете. Так, ну и что у нас проходит? У нас 71 процент вероятности того, что в кэше 1 дейта мисс
[54:34.720 --> 54:47.480]  на чтение, для инструкции все более-менее хорошо. То есть у нас получается проблема именно в доступе
[54:47.480 --> 55:03.040]  к данным, доступ к кэшу, так, там все делось, ладно, файл перед или один кэш мисс, на доступ к, на запись у нас
[55:03.040 --> 55:19.280]  слабое место получается опять же внутри дод. Так, слабое место 99 процентов времени, как раз вот
[55:19.280 --> 55:31.320]  доступ к элементам массива. Что еще можно делать с помощью кэдж гринда и когринда? Кроме проблем,
[55:31.320 --> 55:37.040]  связанных с производительностью в кэш памяти, у вас может быть просто не очень эффективный код,
[55:37.040 --> 55:43.560]  который опять же вы сходу не всегда увидите. В этом случае вы немножко меняете команду для
[55:43.560 --> 55:49.280]  запуска валгрен, меняете кэш на кол. Колгрент это еще один инструмент внутри валгренда,
[55:49.280 --> 55:55.800]  который предназначен для профилировки программ в общем случае, а не применительно к кэшу. То
[55:55.800 --> 55:59.800]  есть анализируется время выполнения отдельных инструкций, которые соответствуют отдельным
[55:59.800 --> 56:07.320]  функциям. Работает немножко быстрее, чем кэдж гринд и позволяет опять же находить слабые места.
[56:07.320 --> 56:15.320]  Что нужно знать при любом проектировании любых программ, при их написании. Вот до того,
[56:15.320 --> 56:22.000]  как вы реально запустите код под профайлером, никогда не вздумайте делать оптимизацию. Потому
[56:22.000 --> 56:30.800]  что, во-первых, если вы как-то вручную оптимизируете код, делаете какие-то неочевидные вещи, которые
[56:30.800 --> 56:36.800]  вроде как должны что-то улучшить, во-первых, вы делаете работу за компилятор. И может так
[56:36.800 --> 56:43.040]  получиться, что тот же самый код, написанный намного проще, намного короче, превратится в то
[56:43.040 --> 56:51.000]  же самое, но при этом вы только зря сделаете ваш код более сложным, сделаете менее читабельным.
[56:51.000 --> 56:59.080]  Традиционное правило вообще любого программиста – преждевременная оптимизация – это зло.
[56:59.080 --> 57:03.480]  Так, а этого зайца зовут Бо. Если вы увидите, значит лекция закончилась.
