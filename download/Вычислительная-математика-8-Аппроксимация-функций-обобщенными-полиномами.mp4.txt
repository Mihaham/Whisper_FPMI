[00:00.000 --> 00:12.080]  Так, значит, сегодняшняя лекция посвящена той же теме «опроксимация функций в функциональных».
[00:12.080 --> 00:18.360]  Сегодня мы будем говорить о интерполяции функций, обобщенной париномом.
[00:18.360 --> 00:23.280]  Эта тема несколько отличается от той темы, о которой мы говорили в прошлой лекции.
[00:23.280 --> 00:33.680]  Так, давайте сначала сделаем постановку задачи для функций одной переменной,
[00:33.680 --> 00:43.040]  чтобы было понятно, о чем идет речь. Пусть у нас будет тетка ωm,
[00:43.040 --> 00:54.080]  как мы ее обычно назначаем tn, то есть ntau, nм меняется от 0 до nбольшого,
[00:54.080 --> 01:02.280]  ttau – шаг в сетке. Давайте возьмем для простоты равномерный шаг, но это не обязательно.
[01:02.280 --> 01:15.800]  Шаг может быть и неравномерным. Далее t0 равняется a, и tn равняется b. Вот такая сетка.
[01:15.800 --> 01:26.440]  Шаг может быть и неравномерным. Далее у нас есть функция fat, определенная на отрезке ab.
[01:26.440 --> 01:32.200]  Пока для простоты она будет одномерной, то есть и функция одной переменной.
[01:32.200 --> 01:38.120]  Мы эту функцию проецируем на нашу сетку и получаем таблицу.
[01:38.120 --> 01:49.040]  Делаем это с помощью оператора, который называется оператор ограничения или restriction,
[01:49.040 --> 02:01.600]  английское название. Я здесь короткое замечание сделаю, что сетка в одномерном случае строится
[02:01.600 --> 02:08.080]  всегда просто. Вообще говоря, например, в трехмерном случае построение сетки является очень непростой
[02:08.080 --> 02:16.200]  задачей, особенно в таких областях. В кубе это построить прямоугольники просто, а в общем-то
[02:16.200 --> 02:24.920]  есть области, в которые строить ее очень непросто, по таким методам построения сеток,
[02:24.920 --> 02:36.720]  даже международные конференции проводятся. Давайте коротко будем обозначать таблицу tn, f, fn.
[02:36.720 --> 02:44.480]  Мы получили таблицу fn, tn, tt, ft. Вот такую таблицу мы получили.
[02:44.480 --> 02:58.880]  И вот теперь, имея таблицу fn, мы строим, получили таблицы метовую функцию f от t,
[02:58.880 --> 03:03.880]  которая называется интерполирующей функцией или коротко интерполянтом.
[03:03.880 --> 03:14.840]  Интерполянт. Пока я не говорю о функциях, о свойствах этих функций, чуть позже я об этом скажу.
[03:14.840 --> 03:23.640]  И так у нас получается такая схема. Есть функция f от t, мы с помощью оператора
[03:23.640 --> 03:32.440]  получаем таблицу fn и по ней строим некую функцию, которую называем интерполянтом
[03:32.440 --> 03:40.160]  с помощью оператора интерполяции. Иногда используют такие слова, как восстановление функции
[03:40.160 --> 03:48.080]  или восполнение функции. Восполнение функции соответствует действительно ситуации. Восстановление
[03:48.080 --> 03:52.480]  это не совсем так. Поскольку мы ее не восстанавливаем, мы ее именно восполняем.
[03:52.480 --> 03:59.800]  Ну, либо проксимируем, либо проксимируем. И, разумеется, эти функции должны совпадать в узлах.
[03:59.800 --> 04:11.920]  f от t ката должно быть равно f ката от 0 до n. Но между узлами они вообще-то совпадать не обязаны.
[04:11.920 --> 04:25.080]  Вот в чем проблема. Поэтому встает вопрос следующий. Как отличаются эти две функции на нашем отрезке АВ?
[04:25.080 --> 04:34.880]  Действительно, можно представить себе, что есть несколько точек заданных. Функция f от t какая-то такая.
[04:34.880 --> 04:42.520]  Мы ее спроецировали на наши узлы. Я их поставил. А функция f от t может быть какой-нибудь вот такой,
[04:42.520 --> 04:50.160]  например. То есть функции не обязаны между узлами совпадать. А вот отличия мы их должны уметь
[04:50.160 --> 04:58.120]  оценивать. Отличия интерполянта и интерполируемой функции. Чтобы знать, что происходит. Чуть позже вы узнаете,
[04:58.120 --> 05:03.880]  я вам расскажу, что это очень важно. Оценивать вот эту... Ну, вообще говоря, я здесь поставил модуль,
[05:03.880 --> 05:11.240]  ну, вообще говоря, здесь лучше поставить норм. В более общем случае лучше поставить норм. Разность.
[05:11.240 --> 05:18.600]  Так. Ну и теперь, как я обычно это делаю, давайте я приведу какой-нибудь очень простой пример.
[05:18.600 --> 05:30.240]  Самый простой, чтобы было все понятно. Начнем с простых примеров. Потом будем усложнять ситуацию,
[05:30.240 --> 05:38.280]  и вы увидите, что задача интерполяции на самом деле очень-очень непростая. Это не проведение. Пора было
[05:38.280 --> 05:48.760]  через три точки. Это гораздо все сложнее. И задача, конечно, имеет огромное количество приложений.
[05:48.760 --> 06:00.800]  Во всех областях. И физики, механики, инженерии, экономики и так далее. Давайте построим функцию
[06:00.800 --> 06:13.760]  на отрезке Tn, Tn плюс один с задными значениями в этих двух узлах. Tfn и fn plus 1. Это значение функции
[06:13.760 --> 06:20.800]  в этих двух узлах. То есть самая простая задача, которую я мог придумать. Вот интерполянт f от t.
[06:20.800 --> 06:28.640]  Так мы обозначаем в выгоде следующим образом. Ну, вы без труда и без меня, конечно, можете написать.
[06:28.640 --> 06:46.320]  Ну, давайте я напишу один раз этот интерполянт. Так, здесь у нас fn, tn плюс 1 минус t. И делим на tn плюс 1 минус t.
[06:46.320 --> 06:55.400]  Эта разница обычно обозначается как tau n, значит шаг в сетке. То есть это линейный интерполянт.
[06:55.400 --> 07:03.000]  Мы приблизили нашу функцию. Вот такой линейный простенькой функции. А вот теперь давайте ответим
[07:03.000 --> 07:10.200]  вот для этого простейшего случая. Ради этого я это и пишу. Оценим разность между интерполянтом
[07:10.200 --> 07:14.840]  и интерполированной функцией. Там в простом случае. Потом, конечно, мы будем переходить к более сложным,
[07:14.840 --> 07:21.800]  более сложным случаям. Ну, пока давайте вот простейший случай оценим. Для этого докажем
[07:21.800 --> 07:31.480]  такую небольшую тему. Пусть функция f от x липшится непрерывно. То есть f от x минус f от y меньше или равно
[07:31.480 --> 07:39.920]  t на x минус y. Ну, помогли все, конечно. То есть пока только вот одно условие. Липшица непрерывности.
[07:39.920 --> 07:45.680]  Больше мы пока о гладкости этой функции не говорим. Потом, разумеется, будем говорить. Но чуть позже.
[07:45.680 --> 07:56.160]  Так, в этом случае. В этом случае модуль разности интерполянта и интерполированных функций.
[07:56.160 --> 08:07.920]  Вот это вот линейный. Меньше или равно t на tau пополам. То есть вот такая оценка
[08:07.920 --> 08:16.800]  разности. Норма разности или модуля разности между интерполянтом и интерполированной функцией.
[08:16.800 --> 08:25.240]  Если у нас имеет место быть линейная интерполяция по двум точкам, то здесь у нас интерполянт линейный.
[08:25.240 --> 08:31.240]  Так, то давайте доказательства проведем. Оно несложное. Давайте его один раз делаем. Оно нам в
[08:31.240 --> 08:43.720]  дальнейшем пригодится. Итак, вот модуль f от t минус f малое от t. Давайте сделаем так, для удобства.
[08:43.720 --> 08:50.760]  Функцию f от t интерполянт мы представим, поскольку она линейная, в таком виде.
[08:50.760 --> 09:03.800]  Альфа разумеется меняется от нуля до единицы. То есть такой весовой коэффициент.
[09:03.800 --> 09:11.640]  Вот так мы ее представим, альфа плюс единица минус альфа.
[09:11.640 --> 09:20.920]  И у нас функция f от t. Функцию f от t мы для удобства представим в аналогичном виде.
[09:20.920 --> 09:32.520]  Альфа f от t плюс единица минус альфа тоже на f от t. Просто удобно для дальнейших выкладок.
[09:32.520 --> 09:41.120]  Здесь глубокого смысла нет в таком представлении. Смысл в одном, чтобы так быстро и аккуратно сделать выкладки.
[09:41.120 --> 09:52.720]  Дальнейший. Получить результат. Функцию f от t представим. Теперь я пишу функцию f малое.
[09:52.720 --> 10:02.720]  Это альфа f от t и минус единица минус альфа тоже на f от t. По модулю меньше и равняется.
[10:02.720 --> 10:13.920]  Теперь давайте вот меньше и равняется. Здесь у нас модуль альфа. f малое от n плюс 1 я представляю понятным образом.
[10:13.920 --> 10:26.080]  Это будет fn плюс tau. Это есть tn плюс 1. Теперь единица минус альфа на fn.
[10:26.080 --> 10:42.000]  Это f от tn. Дальше единица минус альфа. Вот альфа на f от t. А вот t я представлю в следующем виде.
[10:42.000 --> 10:54.400]  Для меня удобно. tn плюс альфа tau. Альфа тоже от 0 до 1. f от tn плюс альфа tau.
[10:54.560 --> 11:10.640]  Единица минус альфа и тоже f от t. f от t плюс альфа tau. Меньше или равно.
[11:10.640 --> 11:20.320]  Здесь я объединил слагаемые с альфа и соединился минус альфа.
[11:20.480 --> 11:25.520]  Для альфа у меня будет следующая альфа.
[11:25.520 --> 11:45.760]  Теперь давайте вот так сделаем в последующем. f от tn плюс tau минус f от tn плюс альфа tau.
[11:45.840 --> 11:53.200]  Это слагаемые с альфа и здесь единица минус tau слагаемая так.
[11:57.920 --> 12:13.440]  Здесь не перепутать. Здесь у нас будет f от tn минус f от tn плюс альфа tau.
[12:13.520 --> 12:19.680]  Меньше или равно. А теперь мы используем липчатую непрерывность функции f малая.
[12:19.680 --> 12:27.760]  Здесь будет альфа, коэффициент липчатся. Разница аргументов это будет у нас tau на единицы минус альфа.
[12:27.760 --> 12:40.480]  Следующая слагаемая тоже мы используем условия липчатся. Единица минус альфа на коэффициент липчатся и на альфа tau.
[12:40.480 --> 12:48.080]  В конечном итоге мы получили 2 c tau на альфа на единицы минус альфа.
[12:48.080 --> 12:54.720]  Это будет перевернутая парабола. Вы найдете максимум. Это будет c tau пополам.
[12:54.720 --> 13:02.880]  Если мы простейшую интерполяцию делаем линейную, то мы имеем интерполяцию первого порядка.
[13:03.120 --> 13:09.200]  У большой от tau, то есть tau в первой степени, интерполяция первого порядка.
[13:09.200 --> 13:25.440]  Это самый простейший случай. Я говорю простейший случай, но на самом деле вот этот простейший случай линейной интерполяции очень активно используется в одном из самых известных честных методов, которые сейчас работают.
[13:26.080 --> 13:32.800]  Причем и для обыкновенных дифференциальных уровней, и для частных производных, и т.д. метод конечных объемов.
[13:32.800 --> 13:52.640]  В этом методе интерполян представляется вот в таком виде, fn на fn от t, сумма по n от 0 до n, fn это значение функции, а fn это так называемые функции крышки.
[13:52.640 --> 13:59.840]  Они имеют вот такой вид. Это линейные функции крышки. Вот такой вид имеют, типа модула lix, плюс что-то.
[13:59.840 --> 14:07.200]  И вот такое представление решения оказывается очень-очень успешным.
[14:07.200 --> 14:15.600]  Этой идеей предложил этого метода более 100 лет назад русский математик Галеркин.
[14:16.560 --> 14:31.440]  Вот Рябинький Виктор Самовыч, профессор, который на футболке читал лекции почти 20 лет, не использовал фразу метод конечных элементов, он говорил метод Галеркина.
[14:31.440 --> 14:38.960]  Что верно, но на самом деле здесь его немного американцы видоизменили, чуть-чуть, и назвали методом конечных элементов.
[14:39.320 --> 14:54.320]  Получился прекрасный метод. Впрочем, Галеркин взял свое, сейчас один из самых полярных честных методов, как называемый разрывный метод Галеркина, который также основывается на аналогичных представлениях.
[14:54.320 --> 15:02.320]  Теперь мы перейдем к интерполяции более высоких порядков.
[15:02.680 --> 15:12.680]  То есть вот с линейной интерполяцией в общем особых проблем у нас никаких нет, но еще линейная интерполяция используется как кусочная линейная интерполяция.
[15:12.680 --> 15:27.680]  То есть когда мы просто соединяем узлы, сетки прямыми отрезками, это тоже иногда используется, такая так называемая кусочная линейная интерполяция.
[15:32.680 --> 15:52.680]  Обычно в более сложных случаях используется тоже обобщенный полиног, то есть наш интерполян представляется в виде обобщенного полинога ОН на φн от t.
[15:53.040 --> 16:03.040]  Ну Н малая, как всегда меняется от 0 до 2 большого, значит ОН коэффициент, который нужно каким-то образом вычислить, ну каким мы в этом будем с вами говорить.
[16:03.040 --> 16:14.040]  А фен это система базисных линейно-независимых функций, это все слова здесь важны, базисные линейно-независимые функции.
[16:14.400 --> 16:33.400]  Они могут быть степенные, они могут быть экспоненциальные, в ранее физике скажем используются комплексные экспоненты, региометрические функции, используются часто и успешно, но часто используются и степенные функции.
[16:33.760 --> 16:43.760]  Актуальная физики там для опроксимации коэффициентов, уравнений состояния и так далее, ну и разумеется в экономике тоже степенные функции используются как правило.
[16:44.120 --> 17:01.120]  Ну вот, поэтому мы имеем вот такой интерполянт, и этот интерполянт в соответствии с условиями интерполяции должен в узлах нашей сетки совпадать с развлечениями нашей функции.
[17:01.120 --> 17:12.120]  Вот что мы имеем, других условий мы никаких не имеем, только равенство в узлах интерполянта и интерполирующей функции.
[17:12.480 --> 17:16.480]  Ну или это можно записать следующим образом.
[17:25.480 --> 17:29.480]  Ну и давайте в скалебном виде распишем, он нам будет нужен.
[17:42.480 --> 17:44.480]  Ну плюс многоточие.
[17:53.480 --> 17:59.480]  Это первое уравнение в нашей системе, то есть это я написал, в самом деле, систему уравнений.
[18:03.480 --> 18:05.480]  Второе уравнение будет выглядеть аналогично.
[18:12.480 --> 18:40.480]  Т1 плюс многоточие УН и Н, Т1 равняется f1, ну и так далее до Н-го уравнения У0, Т0, ТН, плюс, давайте коротко записываем, многоточие УН, ТН и Н.
[18:40.840 --> 18:44.840]  N равняется fN.
[18:44.840 --> 18:47.840]  То есть вот такая система получилась.
[18:47.840 --> 18:52.840]  Ну в отличие от метода на меньше квадратах, вы видите, что матрица у этой системы квадратная.
[18:52.840 --> 19:01.840]  То есть нам не нужно, хочется использовать какие-то другие методы, нам достаточно этой системы.
[19:02.200 --> 19:06.200]  Ну а теперь давайте посмотрим на матрицу вектора.
[19:06.200 --> 19:15.200]  Ну вектор U и f, f вектор правых частей, вектор U это вектор наших коэффициентов, нашего общенного повинного.
[19:15.200 --> 19:21.200]  Ну, разумеется, они принадлежат n-мерному линейному векторному пространству.
[19:23.200 --> 19:30.200]  Вот, матрица A имеет размерность N на N и имеет вот такой вид.
[19:30.560 --> 19:32.560]  Давайте ее вид напишем, он важен.
[19:32.560 --> 19:34.560]  Так это у нас что?
[19:34.560 --> 19:44.560]  phi0 на T0, phi1 на T0, многоточие phiN на T0.
[19:44.560 --> 19:50.560]  Ну дальше там phi0 на T1, я уже все переписывать не буду, сокращенно буду писать.
[19:50.560 --> 19:54.560]  Так здесь phiN тоже на T1.
[19:54.920 --> 20:04.920]  Ну и последняя строка матрицы phi0 на Tn, многоточие phiN на Tn.
[20:04.920 --> 20:06.920]  Ну вот такая матрица.
[20:06.920 --> 20:12.920]  Ну в линейной алгебре, вы наверное помните, доказывается теорема.
[20:12.920 --> 20:16.920]  Осуществование единственности, решение такой системы линейных уравнений.
[20:16.920 --> 20:19.920]  Помните, что для этого требуется?
[20:20.280 --> 20:26.280]  Чтобы такая система уравнений, которую мы получили,
[20:26.280 --> 20:32.280]  а у равняется f, имела единственное решение.
[20:34.280 --> 20:36.280]  Почти.
[20:36.280 --> 20:44.280]  Ну чтобы система функций f-катах была линейно-независима.
[20:44.280 --> 20:46.280]  Все что требуется.
[20:46.640 --> 20:50.640]  Система Байснер-Кутца должна быть линейно-независима.
[20:50.640 --> 20:53.640]  То есть линейная независимость системы функций.
[20:53.640 --> 20:59.640]  При этом мы получаем единственное решение данной системы.
[20:59.640 --> 21:01.640]  То есть здесь все хорошо.
[21:01.640 --> 21:05.640]  Фактически мы сейчас доказали теорему о существовании единственности,
[21:05.640 --> 21:09.640]  решение задачи интерполяции.
[21:10.000 --> 21:12.000]  Вот.
[21:12.000 --> 21:14.000]  Часто так и облекаю.
[21:14.000 --> 21:18.000]  То, что я сейчас вам показал в виде теоремы.
[21:18.000 --> 21:20.000]  Теорема существования единственности.
[21:20.000 --> 21:22.000]  Вот.
[21:22.000 --> 21:30.000]  Но давайте еще вот сделаем небольшое замечание.
[21:34.000 --> 21:39.000]  С помощью опять же той же симметризации по гауссу,
[21:39.360 --> 21:41.360]  эту задачу можно упростить.
[21:41.360 --> 21:43.360]  Правда, не всегда это удается.
[21:43.360 --> 21:45.360]  Но иногда удается.
[21:45.360 --> 21:50.360]  Я, помните, вам рассказывал о системе ортогональных функций.
[21:50.360 --> 21:54.360]  Здесь ее тоже, оказывается, можно использовать, если, конечно, это возможно.
[21:54.360 --> 21:57.360]  Просто в реальных задачах не всегда возможно их использовать.
[21:57.360 --> 22:01.360]  Но есть задачи, в которых их вполне можно использовать.
[22:01.360 --> 22:03.360]  Вот.
[22:03.360 --> 22:08.360]  Давайте проведем симметризацию нашей системы уравнений по гауссу.
[22:08.720 --> 22:10.720]  У вас озвездует сопряженная матрица.
[22:10.720 --> 22:15.720]  Ну, в честном случае это просто транспанированная матрица.
[22:15.720 --> 22:17.720]  Транспанированная матрица.
[22:17.720 --> 22:19.720]  Ну вот.
[22:19.720 --> 22:22.720]  С одной стороны, мы, конечно, задачу усложнили.
[22:22.720 --> 22:28.720]  Но если я обозначу на дм произведения вот этих двух матриц,
[22:28.720 --> 22:32.720]  то что у меня получится?
[22:33.080 --> 22:40.080]  Элементой матриц будут являться кадровные произведения
[22:40.080 --> 22:46.080]  фи и на фи ж и и и ж от 0 до n.
[22:46.080 --> 22:50.080]  Ну, чтобы знакомое.
[22:50.080 --> 22:56.080]  Но на всякий случай напомню, что под кадровые произведения
[22:56.080 --> 23:02.080]  фи и на фи ж вы понимали тумму фи и т от t.
[23:02.440 --> 23:06.440]  Пятое на фи ж и т от t.
[23:06.440 --> 23:08.440]  Пятое.
[23:08.440 --> 23:09.440]  Вот так это.
[23:09.440 --> 23:11.440]  Тумму фука.
[23:11.440 --> 23:15.440]  То есть эта матрица состоит из кадровных произведений.
[23:15.440 --> 23:17.440]  Это матрица грамма.
[23:17.440 --> 23:20.440]  То есть мы опять пришли к нашей любимой матрице грамма.
[23:20.440 --> 23:23.440]  Она, конечно, очень хороша тем, что она положительно
[23:23.440 --> 23:26.440]  определенная, симметричная и так далее.
[23:26.440 --> 23:28.440]  Но есть некоторые детали.
[23:28.800 --> 23:32.800]  Дело в том, что если матрица плохо обусловлена,
[23:32.800 --> 23:34.800]  то произведение двух плохо обусловленных матриц
[23:34.800 --> 23:37.800]  даст еще более плохо обусловленную матрицу.
[23:37.800 --> 23:42.800]  Это вот такой подводный камешек имеется в этом деле.
[23:42.800 --> 23:45.800]  Но что здесь хорошо или ради чего я все-таки
[23:45.800 --> 23:47.800]  симметризацию по гауссу привел?
[23:47.800 --> 23:49.800]  А хорошо вот что.
[23:49.800 --> 23:53.800]  Если мы выбираем систему ортогональных функций,
[23:54.160 --> 23:57.160]  ортогональные функции, в этом случае будет
[23:57.160 --> 23:59.160]  кадровное произведение.
[23:59.160 --> 24:03.160]  Это есть тело кронекера.
[24:03.160 --> 24:06.160]  Если нам удастся использовать
[24:06.160 --> 24:09.160]  ортогональные функции, например,
[24:09.160 --> 24:11.160]  ортогональные пальновые.
[24:11.160 --> 24:13.160]  Лаграджа, Лежандра, Рамиточи, Вышова.
[24:13.160 --> 24:19.160]  То мы получим единичную матрицу.
[24:19.160 --> 24:21.160]  То есть решать ничего не нужно.
[24:21.160 --> 24:23.160]  Решение будет выписано.
[24:23.520 --> 24:25.520]  Уровняется асо звездой.
[24:25.520 --> 24:27.520]  Иногда это удается сделать.
[24:27.520 --> 24:30.520]  Но в радиофизике это используется очень часто,
[24:30.520 --> 24:33.520]  поскольку в качестве байсных функций
[24:33.520 --> 24:35.520]  радиофизики используют комплекс экспонента
[24:35.520 --> 24:37.520]  либо тригонометрические функции.
[24:37.520 --> 24:39.520]  И там это удается.
[24:39.520 --> 24:41.520]  Удается это сделать тогда,
[24:41.520 --> 24:44.520]  когда можно использовать ортогональные полиномы,
[24:44.520 --> 24:46.520]  типа Лаграджа, Лежандра.
[24:46.520 --> 24:48.520]  К сожалению, это не всегда удается делать,
[24:48.520 --> 24:50.520]  но когда удается, то же мы получаем
[24:50.520 --> 24:52.520]  довольно простое решение.
[24:52.880 --> 24:55.880]  Но что делать, когда нам
[24:55.880 --> 24:59.880]  нужно решать систему и вычислять?
[25:06.880 --> 25:08.880]  Нам нужно решать систему линейных
[25:08.880 --> 25:10.880]  логибрических уравнений.
[25:10.880 --> 25:12.880]  Ну хорошо, если система невысокого порядка,
[25:12.880 --> 25:14.880]  два, три, четыре и так далее,
[25:14.880 --> 25:20.880]  вы ее просто решаете на руках, на коленке, как говорят.
[25:21.240 --> 25:24.240]  Плохо, если она имеет высокий порядок.
[25:24.240 --> 25:26.240]  Высокий порядок тогда.
[25:26.240 --> 25:29.240]  Ну, во-первых, нужно ее решать численно,
[25:29.240 --> 25:31.240]  но численно решать тоже, так сказать,
[25:31.240 --> 25:33.240]  в среднем порядке, ничего страшного.
[25:33.240 --> 25:35.240]  Нет метод гаусс, это рассудный метод.
[25:35.240 --> 25:37.240]  Мы с вами говорили.
[25:37.240 --> 25:39.240]  Но какие здесь могут быть, опять же,
[25:39.240 --> 25:41.240]  проблемы?
[25:41.240 --> 25:43.240]  Проблема есть одна.
[25:43.240 --> 25:45.240]  Давайте положим, что
[25:45.240 --> 25:47.240]  система базисных функций у нас
[25:47.240 --> 25:49.240]  это степенные функции.
[25:49.600 --> 25:51.600]  Это степенные функции.
[25:54.600 --> 25:56.600]  И там будет все хорошо понятно.
[25:56.600 --> 25:58.600]  То есть
[25:58.600 --> 26:00.600]  phi n
[26:00.600 --> 26:02.600]  это есть x в степени n.
[26:04.600 --> 26:06.600]  Что мы при этом получим?
[26:06.600 --> 26:08.600]  Какую систему уравнений мы получим?
[26:08.600 --> 26:10.600]  Которую я выписал.
[26:10.600 --> 26:12.600]  Мы получим следующую систему уравнений.
[26:12.600 --> 26:14.600]  u0
[26:14.600 --> 26:16.600]  u1 на t0
[26:16.600 --> 26:18.600]  u2 t0
[26:18.600 --> 26:20.600] SN square
[26:20.600 --> 26:21.600]  н
[26:21.600 --> 26:23.600]  plus многоточие
[26:23.600 --> 26:25.600]  здесь уn
[26:25.600 --> 26:27.600]  t0 в степени n
[26:27.600 --> 26:29.600]  равняется f0
[26:31.600 --> 26:33.600]  второе уравнение ux1
[26:33.600 --> 26:35.600]  first t1
[26:35.600 --> 26:37.600]  plus u2
[26:37.600 --> 26:39.600]  first t1
[26:39.600 --> 26:41.600]  IB
[26:41.600 --> 26:43.600]  u1
[26:43.600 --> 26:45.600]  first c1
[26:45.600 --> 26:47.600]  t1
[26:47.600 --> 26:58.160]  У1tn плюс, давайте многоточки поставлю, Уntn в степени n равняется fn.
[26:58.160 --> 27:05.600]  Вот такая система уравнений у нас получилась, но обратите внимание на матрису.
[27:05.600 --> 27:14.400]  У нас опять же получилась система уравнения а уравняется f, у f это вектора н-мерного пространства,
[27:14.400 --> 27:19.400]  а у матрицы n на n, и вовлекто на следующем образом.
[27:19.400 --> 27:42.400]  1t0t0 в квадрате многоточия, t0 в степени n, 1t1t1 в квадрате, t1 в степени n, 1tntn в квадрате, tn в степени n.
[27:42.400 --> 27:47.400]  Вот такая у нас матрица нашей линейной системы по гибридическому уравнению.
[27:47.400 --> 27:51.400]  Посмотрите на нее внимательно, что незнакомое есть в ней.
[27:51.400 --> 27:57.400]  Встречали такую матрицу? Громче? Конечно, да.
[27:57.400 --> 28:03.400]  Как вычисляется определить вандормонты этой матрицы вы прекрасно знаете.
[28:03.400 --> 28:17.400]  Детиминант этой матрицы это, если что иное, как произведение t и t-t, gt и g, от 0 до n по i неравного g.
[28:17.400 --> 28:22.400]  То есть опять же матрица получилась хорошей.
[28:22.400 --> 28:30.400]  Она не выражена, и поэтому мы опять всегда можем утверждать, что у нас есть решение и решение единственное.
[28:30.400 --> 28:36.400]  Это фактически тоже некое следствие теории, которую мы только что доказали.
[28:36.400 --> 28:43.400]  А теперь посмотрите повнимательнее чуть-чуть, какие могут встретиться проблемы в решении этой системы уравнений,
[28:43.400 --> 28:46.400]  если n у нас не 2, а 3, а какой-нибудь большой.
[28:46.400 --> 28:50.400]  Например, 20, 30 и так далее.
[28:50.400 --> 28:58.400]  Подсказка. Пусть, давайте мы отмасштабируем нашу матрицу, пусть t лежит от 0 до 1.
[28:58.400 --> 29:02.400]  Посмотрите, пожалуйста, на последний столбец. Чему он будет равен?
[29:02.400 --> 29:10.400]  Если n у нас будет большой, он будет близок к 0, то есть матрица будет близка к вырождению,
[29:10.400 --> 29:13.400]  либо просто выродится с машиной точностью.
[29:13.400 --> 29:22.400]  Вот что проблема. То есть мы опять встречаемся с плохо обусловленной системой единых уравнений.
[29:22.400 --> 29:25.400]  То есть вот от природы не уйдешь.
[29:25.400 --> 29:30.400]  То есть мы хотим решить задачу опроксимации, мы ее решаем частично.
[29:30.400 --> 29:35.400]  Для невысоких степеней интерпозиционного полинома она решается прекрасно.
[29:35.400 --> 29:48.400]  Но если говорить о таком усредненном опыте, то где-то обычно степенные полиномы до пятой,
[29:48.400 --> 29:50.400]  но может быть максимум семой степени используются.
[29:50.400 --> 29:54.400]  Дальше там начинаются проблемы. Сейчас мы об этих проблемах будем говорить.
[29:54.400 --> 30:00.400]  А может быть и при меньшей степенях проблемы могут начаться.
[30:00.400 --> 30:04.400]  Именно по этой причине. Из-за плохой обусловленности матрицы.
[30:04.400 --> 30:12.400]  Ну, разумеется, вы помните имя Гильберта, который привел пример самой плохой обусловленной матрице.
[30:12.400 --> 30:15.400]  Ну, наверное, можно еще более плохую матрицу провести.
[30:15.400 --> 30:18.400]  Еще более плохо обусловленную, но так, чтобы это имело смысл.
[30:18.400 --> 30:21.400]  Гильберта привел матрицу, которая имеет смысл.
[30:22.400 --> 30:29.400]  Но над этой проблемой начали думать два великих ума.
[30:29.400 --> 30:34.400]  Лагранш и Ньютон. На самом деле гораздо больше математиков думали над эту тему.
[30:34.400 --> 30:38.400]  Но первыми, видимо, начали над этой темой думать Лагранш и Эльдер.
[30:38.400 --> 30:46.400]  И вот что они предложили. Действительно, задачу эту ситуацию существенно упростили.
[30:46.400 --> 31:02.400]  Но когда математики начали исследовать их решение, оказалось, что природу все-таки не обманет.
[31:02.400 --> 31:08.400]  Но решение задачи резко упростилось. Сейчас мы об этом поговорим.
[31:08.400 --> 31:14.400]  Очень красиво решение предложили Лагранш и Ньютон. После них тоже были предложения.
[31:14.400 --> 31:20.400]  Самое красивое, забегай вперед, скажу, что самый красивый интерполиционный полином.
[31:20.400 --> 31:26.400]  Но красивый не в смысле красоты какой-то внешне, а в смысле эффективности работы.
[31:26.400 --> 31:29.400]  Предложил наш математик Пафнут Львович Чебышов.
[31:29.400 --> 31:33.400]  Об этом историческом полиноме, разумеется, я расскажу.
[31:33.400 --> 31:39.400]  Математики французские XIX века называли полином изюминкой математического анализа.
[31:39.400 --> 31:43.400]  Он действительно поразительный по своим свойствам.
[31:43.400 --> 31:48.400]  Причем Чебышов получил его, решая совсем другую задачу.
[31:48.400 --> 31:53.400]  Ну вот так бывает. Теория групп тоже возникла при решении других задач.
[31:53.400 --> 31:58.400]  Ну как кто-то сказал, из математиков искали нефть, нашли газ.
[31:58.400 --> 32:05.400]  Ну вот, давайте теперь поговорим о том решении, которое предложил Лагранш.
[32:05.400 --> 32:08.400]  Потом о предложении Ньютона.
[32:08.400 --> 32:13.400]  Лагранш предложил искать обобщенный полином.
[32:13.400 --> 32:20.400]  Этот полином по имени Лагранша традиционно так и пишут.
[32:20.400 --> 32:26.400]  В виде разложения по базительным функциям Лагранш.
[32:29.400 --> 32:32.400]  Чтобы обойти решение системы линейных уравнений.
[32:32.400 --> 32:34.400]  То есть выписать сразу решение.
[32:34.400 --> 32:37.400]  И он его выписал. Вот что получилось.
[32:38.400 --> 32:44.400]  Сумма fn на phi н большой.
[32:44.400 --> 32:49.400]  Сумма по н от 0 до n.
[32:49.400 --> 32:54.400]  Причем f малое – это значение нашей функции в узлах.
[32:54.400 --> 32:59.400]  А phi н – это некие базисные функции.
[32:59.400 --> 33:02.400]  То есть у нас что должно получиться?
[33:02.400 --> 33:07.400]  Во всех узлах fк так должно быть равно fк.
[33:07.400 --> 33:12.400]  К от 0 до n меняется.
[33:12.400 --> 33:22.400]  То есть значение полинома в некой точке k должно быть равно значению функции в этой точке.
[33:22.400 --> 33:28.400]  Причем в этом случае базисная функция должна быть четко равна 1.
[33:28.400 --> 33:31.400]  А в других точках базисная функция должна быть равна 0.
[33:31.400 --> 33:43.400]  То есть если это написать просто, то получается, что наша функция fn от k это просто должно быть символ кронейкера.
[33:43.400 --> 33:47.400]  Ну можете несколько секунд подумать, придумать такую функцию.
[33:47.400 --> 33:49.400]  Легко ее придумать или нет?
[33:49.400 --> 33:53.400]  Потом они получили название базисной функции Лагранш.
[33:53.400 --> 34:00.400]  Полинома Лагранша – это за ними забито название интерполюционных полиновок, а это базисные функции.
[34:00.400 --> 34:04.400]  Ну, я вам подскажу.
[34:04.400 --> 34:10.400]  В качестве базисной функции Лагранш предложил полиному вот такого вида.
[34:10.400 --> 34:16.400]  t-tk-t, tn-tk-t.
[34:16.400 --> 34:19.400]  t от 0 до n.
[34:19.400 --> 34:24.400]  Звонка не было?
[34:24.400 --> 34:27.400]  Здесь плохо за ног слышно.
[34:27.400 --> 34:33.400]  Так, вот базисные функции Лагранш. Они удовлетворяют тем требованиям, о которых я только что говорил.
[34:33.400 --> 34:41.400]  В этом случае значения интерполянта в наших узлах точно совпадают с значениями функции в этих же узлах.
[34:41.400 --> 34:46.400]  То есть задача в общем-то с первого взгляда решена.
[34:46.400 --> 34:52.400]  Она действительно вроде бы решена.
[34:52.400 --> 34:59.400]  Ну, как всегда, в учительной математике имеются всегда какие-то подводы декаде.
[34:59.400 --> 35:08.400]  Решение красивое, простое и так далее.
[35:08.400 --> 35:24.400]  Ну, можно написать полиновый Лагранш в полной виде fn на произведение t-tk-tn-tk-t.
[35:24.400 --> 35:30.400]  Произведение по k, сумма по n.
[35:30.400 --> 35:34.400]  Ну, давайте я тоже приведу какой-нибудь простой пример.
[35:34.400 --> 35:38.400]  Например, полиновый Лагранш первого порядка.
[35:38.400 --> 35:40.400]  Линейный полиновый Лагранш.
[35:40.400 --> 35:43.400]  l1 от t.
[35:43.400 --> 35:45.400]  Что это будет? Это будет следующее.
[35:45.400 --> 35:53.400]  f1 t2-t t2-t.
[35:53.400 --> 35:57.400]  t1, простите, t2, плюс f.
[35:57.400 --> 35:59.400]  Это подвод точек, я имею в виду.
[35:59.400 --> 36:01.400]  У нас здесь две точки t1 t2.
[36:01.400 --> 36:05.400]  И значения функции в этих точках f1 и f2.
[36:05.400 --> 36:07.400]  Вот я выписываю полиновый Лагранш.
[36:07.400 --> 36:22.400]  f2 здесь t1-t, t2-t-t1.
[36:22.400 --> 36:37.400]  Полиновый Лагранш в таком виде первого порядка.
[36:37.400 --> 36:42.400]  Ну, к недостаткам вот этой записи полинового формы Лагранш обычно относят то,
[36:42.400 --> 36:47.400]  что если мы захотим перенумеровать точки, то нам придется перестраивать весь полиновый раз.
[36:47.400 --> 36:52.400]  И во-вторых, если мы, скажем, из полинового первого порядка захотим получить полинового второго порядка,
[36:52.400 --> 36:56.400]  нам тоже придется перестраивать весь полиновый.
[36:56.400 --> 37:03.400]  Интересно то, что вот этого недостатка лишен полинового, который выписывал Ньютон.
[37:03.400 --> 37:09.400]  Он называется интерпольсионный полином в форме Ньютона.
[37:34.400 --> 37:44.400]  Прежде чем только выписывать, нам придется ввести одно важное понятие, которое нам пригодится в течение всего курса.
[37:44.400 --> 37:48.400]  Ввести понятие разделенных разностей.
[37:48.400 --> 37:50.400]  Разделенных разностей.
[37:50.400 --> 37:58.400]  Оно было введено Эллером в XVII веке, но вот мне китаеведы подарили книгу китайских математиков.
[37:58.400 --> 38:02.400]  Оказалось, что китайские математики его ввели еще в XIV века.
[38:02.400 --> 38:07.400]  Как и формулу Еруна.
[38:07.400 --> 38:11.400]  Вот давайте, что это такое.
[38:11.400 --> 38:14.400]  Разделенная радость нулевого порядка в точке Tn.
[38:14.400 --> 38:17.400]  Вот это есть просто значение функции в точке Tn.
[38:17.400 --> 38:25.400]  Разделенная радность первого порядка Ftn Tn и Tn плюс один.
[38:25.400 --> 38:27.400]  Она вот так обозначается.
[38:27.400 --> 38:29.400]  Это есть вот что.
[38:29.400 --> 38:45.400]  Значит, в числителе Ftn плюс один минус Ftn делим на Tn плюс один минус Tn.
[38:45.400 --> 38:49.400]  Разделенная радость первого порядка.
[38:49.400 --> 38:52.400]  Чуть позже я объясню, зачем их вводим.
[38:52.400 --> 38:55.400]  Разделенная радость давайте второго порядка ввешем.
[38:55.400 --> 39:02.400]  Ftn Tn плюс один Tn плюс два.
[39:02.400 --> 39:06.400]  Это будет разность первых разделенных разностей.
[39:06.400 --> 39:12.400]  Ftn плюс один Tn плюс два.
[39:12.400 --> 39:18.400]  Это первая разделенная разность и минус тоже первая разделенная разность.
[39:18.400 --> 39:23.400]  Раздельная разность Ftn Tn плюс один.
[39:23.400 --> 39:25.400]  Это, опять же, числитель.
[39:25.400 --> 39:33.400]  Ознаменитый стоит разность Tn плюс два минус Tn.
[39:33.400 --> 39:38.400]  Ну, если повнимательнее посмотрите, можете догадаться, чему я веду.
[39:38.400 --> 39:40.400]  Что они будут означать.
[39:40.400 --> 39:41.400]  Ну и так далее.
[39:41.400 --> 39:45.400]  Дальше я могу ввести разделенную разность третьего, четвертого порядка и так далее.
[39:45.400 --> 39:50.400]  Ну, давайте напишем разделенную разность в каком порядке.
[39:50.400 --> 40:00.400]  Ftn Tn плюс один многоточие Tn плюс к.
[40:00.400 --> 40:03.400]  Это будет разность от двух разностей.
[40:03.400 --> 40:10.400]  Ftn плюс один многоточие Tn плюс к.
[40:10.400 --> 40:19.400]  Минус Ftn многоточие Tn плюс к и минус единица.
[40:19.400 --> 40:20.400]  Это числитель.
[40:20.400 --> 40:26.400]  Ну и знаменатель разности Tn плюс к минус Tn.
[40:26.400 --> 40:34.400]  Это разделенная разность N порядка.
[40:34.400 --> 40:44.400]  Ну, для того, чтобы их вычислять, была придумана вот такая простая табличка.
[40:44.400 --> 40:50.400]  F0, F1, F2.
[40:50.400 --> 40:54.400]  Это вот разделенная разность N порядка.
[40:54.400 --> 40:56.400]  Ну, можно и дальше продолжить.
[40:56.400 --> 40:57.400]  F3, F4.
[40:57.400 --> 41:01.400]  Я просто, чтобы не терять время, только 3 обозначил.
[41:01.400 --> 41:08.400]  По этим двум разностям мы находим разность первого порядка.
[41:08.400 --> 41:11.400]  Две разности первого порядка.
[41:11.400 --> 41:18.400]  Ft0 T1 и Ft1 T2.
[41:18.400 --> 41:24.400]  И по разделенным разностям первого порядка мы находим разделенную разность второго порядка.
[41:24.400 --> 41:28.400]  Ft0 T1 T2.
[41:28.400 --> 41:31.400]  Это чисто такая удобная табличка.
[41:31.400 --> 41:38.400]  Вы в нее ставите числа и вот рекуррентным образом находите разделенную разность в виде чисел.
[41:38.400 --> 41:42.400]  Это чисто, можно программку сделать и так далее.
[41:42.400 --> 41:45.400]  Ну и я здесь 3 обозначил числа.
[41:45.400 --> 41:51.400]  Можно обозначить их много и найти разделенную разность N порядка.
[41:51.400 --> 41:53.400]  В общем-то есть формула общая для них.
[41:53.400 --> 41:57.400]  Но я ее не пишу, поскольку она тяжелая и она не очень нужна.
[41:57.400 --> 42:01.400]  Поскольку они рассчитываются с помощью этой таблички проще.
[42:01.400 --> 42:03.400]  Так, и теперь главный вопрос.
[42:03.400 --> 42:05.400]  Зачем я вам все это рассказываю?
[42:05.400 --> 42:07.400]  Про разделенные разности.
[42:07.400 --> 42:09.400]  Рассказываю я вот зачем.
[42:09.400 --> 42:14.400]  Пока не догадались еще, на что похожи эти разделенные разности.
[42:14.400 --> 42:16.400]  На практимацию чего?
[42:16.400 --> 42:18.400]  Я скажу так.
[42:18.400 --> 42:19.400]  Не догадались, да?
[42:19.400 --> 42:28.400]  Смотрите, если я умножу разделенную разность катого порядка на K факториал.
[42:28.400 --> 42:31.400]  Ну здесь у нас будет Tn.
[42:31.400 --> 42:33.400]  Tn плюс K.
[42:33.400 --> 42:36.400]  Это разделенная разность катого порядка.
[42:36.400 --> 42:45.400]  Катого порядка я могу ей приблизить к производную катого порядка на отрезке.
[42:45.400 --> 42:48.400]  На отрезке Tn.
[42:48.400 --> 42:52.400]  Tn плюс K.
[42:52.400 --> 42:58.400]  То есть это будет ничто иное, как апоксимация производной на этом отрезке.
[42:58.400 --> 43:03.400]  Правда, доказывается еще более удивительная теория.
[43:03.400 --> 43:18.400]  Оказывается, есть точка на этом отрезке Xi такова, что приближенная равенство можно заменить на точное равенство.
[43:18.400 --> 43:27.400]  Существует на отрезке Tn. Tn плюс K точка Xi, когда вот это выполняется точное равенство.
[43:27.400 --> 43:32.400]  K факториал на разделенную разность равняется катой производной.
[43:32.400 --> 43:37.400]  Громче-громче спрашивайте.
[43:37.400 --> 43:41.400]  Почему K факториал появился?
[43:41.400 --> 43:45.400]  Скажу так, это доказывается, разумеется, теорема.
[43:45.400 --> 43:52.400]  Теорема, которую я не хочу доказывать, потому что у нас очень много времени уйдет на доказательство.
[43:52.400 --> 43:59.400]  Кстати говоря, можете сами эту теорему доказать в качестве алгебраической задачи.
[44:00.400 --> 44:13.400]  Существует такая точка на отрезке Tn. Tn плюс K, Xi, что K факториал на разделенную разность это есть лишь что-нибудь как производная точка Xi.
[44:13.400 --> 44:16.400]  Можете доказать эту теорему совсостоятельно.
[44:16.400 --> 44:20.400]  Это типичная теорема математического анализа.
[44:20.400 --> 44:24.400]  То есть мы с помощью разделенных разностей аппроксимируем производные.
[44:24.400 --> 44:27.400]  Вот их главное предназначение.
[44:27.400 --> 44:32.400]  Еще я приведу пример так называемых конечных разностей.
[44:32.400 --> 44:34.400]  Они тоже нам очень будут нужны.
[44:34.400 --> 44:41.400]  Разделенные разности это объекты, которые я показал.
[44:41.400 --> 44:45.400]  Есть еще такие объекты как конечные разности.
[44:45.400 --> 44:48.400]  Они также используются для аппроксимации производных.
[44:48.400 --> 44:51.400]  Давайте я тоже их покажу.
[44:53.400 --> 44:55.400]  Конечная разность первого порядка.
[44:55.400 --> 45:00.400]  Это есть разность fn плюс 1 минус fn.
[45:01.400 --> 45:05.400]  Ее еще называют правой разностью, она может быть и левой.
[45:11.400 --> 45:14.400]  Какую разность называют левой разницей.
[45:14.400 --> 45:17.400]  Их называют конечной разностью.
[45:17.400 --> 45:19.400]  Это конечная разность первого порядка.
[45:19.400 --> 45:22.400]  Конечная разность второго порядка.
[45:22.400 --> 45:28.300]  дельта 2 fn, это есть разность двух конечных разностей первого порядка
[45:28.300 --> 45:37.340]  дельта fn плюс 1 минус дельта fn ну и если мы сюда поставим значение этих
[45:37.340 --> 45:47.340]  конечных разностей первого порядка мы получим fn плюс 2 минус 2 fn плюс 1 и плюс
[45:47.340 --> 45:57.900]  fn и плюс fn конечная разность третьего порядка это разность двух конечных
[45:57.900 --> 46:09.500]  разностей второго порядка дельта 2 fn плюс 1 минус дельта 2 fn ну это равняется fn
[46:09.500 --> 46:15.620]  плюс 3 минус 3 то сюда если мы все это все поставим эти значение конечных
[46:15.620 --> 46:19.520]  разностей второго порядка то я просто окончательный ответ пишу в этом можете
[46:19.520 --> 46:31.420]  сделать и без меня разумеется плюс 3 fn плюс 1 и минус fn и минус fn это конечная
[46:31.420 --> 46:37.500]  разность третьего порядка но нам еще потребуется через какое-то время конечные
[46:37.500 --> 46:44.380]  разности четвертого порядка не на этом ограничить это будет разность опять двух
[46:44.380 --> 46:53.620]  разностей уже третьего порядка дельта 3 fn плюс 1 и дельта 3 fn если их поставить и раскрыть то
[46:53.620 --> 47:11.180]  получится следующее fn плюс 4 минус 4 fn плюс 3 плюс 6 fn плюс 2 минус fn плюс 1 и плюс fn ну кстати
[47:11.180 --> 47:16.460]  говоря на коэффициенты можете посмотреть я могу разность 5 шестого написать но не буду
[47:16.460 --> 47:21.980]  это уже делать если нужно будет сделать уже сами коэффициенты ни о чем не говорят этих этих
[47:21.980 --> 47:29.820]  разложений конечных разностей ни на что ничего не напоминают конечно конечно бином ньютона это
[47:29.820 --> 47:33.980]  биномиальные коэффициенты поэтому конечные разности тоже выписывают через биномиальные
[47:33.980 --> 47:39.860]  коэффициенты в общей виде но тоже формула там достаточно сложная и то сказать не очень нужна
[47:39.860 --> 47:48.660]  не очень нужна чуть позже объясню что существует тоже схема эйкина эйкина типа вот той схемы для
[47:48.660 --> 47:56.820]  разделенных разности которые позволяет строить такие удобные таблицы вычислить ну вот теперь
[47:56.820 --> 48:04.940]  значит зачем я рассказал про конечную разность вот зачем оказывается если я возьму конечную
[48:04.940 --> 48:16.900]  разность картового порядка и разделю ее на степени к тав это тн плюс 1 минус тн будем
[48:16.900 --> 48:22.940]  считать что шаг у нас здесь постоянно для простоты в случае разделенных разностей я его не полагал
[48:22.940 --> 48:32.380]  постоянно здесь я положил его постоянно то есть тау везде одинаково оказывается это есть
[48:32.380 --> 48:40.580]  приближает карту производную на том же отрезке тн тн плюс к и опять же существует точка ксих
[48:40.580 --> 48:47.460]  где приближенное раненство можно заменить на точное раненство как и в случае разделенных разностей
[48:47.460 --> 48:52.620]  поэтому и конечная разность и разделенные разности используется в первую очередь для
[48:52.620 --> 48:59.060]  для опроксимации производных это тоже про опроксимацию функции функциональных пространств только с
[48:59.060 --> 49:10.500]  помощью интерполянтов интерполянтов которые вот предложили наши математики так теперь вот я
[49:10.500 --> 49:20.820]  могу переходить к полиному в форме который предложил дюйма полином в форме дюйма
[49:20.820 --> 49:34.940]  тогда решили были очень популярные задачи небесной механики когда работали лагран шедер лакласс
[49:34.940 --> 49:42.500]  небесная механика была была такой перекладной важнейшей областью которые очень любили
[49:42.500 --> 49:50.300]  математики потом появилась гидродинамика механика сплошных сред уравнений частно производных и
[49:50.300 --> 50:02.540]  появилась еще одна прикладная важнейшая область для вычислительной математики но тогда
[50:02.540 --> 50:06.900]  компьютеров не было приходилось больше думать так теперь поле нов в форме ньютона вот как он
[50:06.900 --> 50:15.420]  записывается в общей виде но опять же всего уважение к великому дюйму по ином за поляном
[50:15.420 --> 50:25.060]  ньютона вот забит вот такой название и большой поэтому я пишу малая гнезду по ином ньютона
[50:25.060 --> 50:33.940]  давайте чтобы меньше писать и проще я нумерацию веду в соединечке разделенная разность нулевого
[50:33.940 --> 50:43.020]  порядка точке ты один это просто значение функции интерполируем точка п 1 плюс разделенная разность
[50:43.020 --> 51:01.060]  первого порядка 1 минус плюс разделенная разность второго порядка f от 1 t 2 t 3 на t минус
[51:01.060 --> 51:10.780]  t 1 и минус t и минус 2 ну и плюс многоточие как вы догадываетесь здесь многоточие будет
[51:10.780 --> 51:29.620]  следовать разделенная разность но порядка т 1 и на т и минус t 1 ну поляном будет здесь и минус
[51:29.620 --> 51:42.420]  вот это будет по ином форме ньютона но посмотреть на него внимательно вспомните что разделенная
[51:42.420 --> 51:48.860]  разность это что есть это есть опроксимация производная делить на ка факториал да то здесь
[51:48.860 --> 51:54.820]  можно поставить приближено значение производной делить на ка факториал ничего не напоминает вот
[51:54.820 --> 52:01.700]  этот частично сумма никакого ряда не напоминает хорошо известный да более вам известный и лора
[52:01.700 --> 52:10.620]  да это действительно вот интерполюционный поле но мьютон очень похож на ряд тейлора но интересно
[52:10.620 --> 52:18.180]  что вот были попытки вот как раз назвать интерполюционный поле но мьютона дискретно
[52:18.180 --> 52:25.100]  опроксимация ряда тейлора но как-то не прижилось не прижились не прижились хотя он очень похож
[52:25.100 --> 52:34.980]  действительно на ряда тейлора точнее на частичную сумму ряда тейлора что в нем удобств какие в нем
[52:34.980 --> 52:45.820]  удобства вот вы видите но смотрите например если я напишу по ином мьютона первого порядка это что
[52:46.220 --> 52:54.620]  будет valor с разделенной разность первого порядка но давайте ты два минуты один минус
[52:56.260 --> 53:02.480]  до это будет по ином ньютона первого порядка то есть прямой вот теперь я захочу написать по ином
[53:02.480 --> 53:10.060]  ньютона второго порядка это что будет это будет по ином не утон vídeos как потому
[53:10.060 --> 53:30.060]  плюс разделенная разность второго порядка, t3-t1, а здесь будет f3-f2, t3-t2-f2-f1 на t2-t1.
[53:30.060 --> 53:38.060]  То есть вы видите, что мне не приходится перестраивать полиновый, если я буду переходить к полиновому более высокого порядка.
[53:38.060 --> 53:40.060]  Я просто добавляю еще одно слагаемое.
[53:41.060 --> 53:50.060]  Конкретно это разделенная разность, умноженная на полином t-t1, и так далее. Я его вам выписал.
[53:51.060 --> 53:57.060]  Это вот удобство. Полином идет, но и второе удобство связано с разделенными разностями.
[53:57.060 --> 54:04.060]  То есть я вам сказал, что если я перенумирую точки, то значение разделенной разности от этого не поменяется.
[54:04.060 --> 54:06.060]  Это тоже определенное удобство.
[54:06.060 --> 54:11.060]  Поэтому в практике полином Ньютона чаще используется, чем полином Лагранжа.
[54:12.060 --> 54:14.060]  Точнее говорить, форма полинома.
[54:14.060 --> 54:17.060]  Это два абсолютно одинаковых полинома.
[54:17.060 --> 54:20.060]  И полином Лагранжа, и полином Ньютона.
[54:20.060 --> 54:22.060]  Но записаны в разных формах.
[54:22.060 --> 54:26.060]  Потом появились еще и формы записи интерпозиционных полиновов.
[54:26.060 --> 54:30.060]  Но основные вот эти. Я пока буду говорить об этих.
[54:30.060 --> 54:32.060]  Хотя у нас еще будет полином.
[54:33.060 --> 54:38.060]  Ну и, казалось бы, все здорово.
[54:38.060 --> 54:42.060]  Задача решена. Можно закрывать тело.
[54:42.060 --> 54:45.060]  Ну не такова вычислительная математика.
[54:45.060 --> 54:50.060]  Теперь вот о чем нужно поговорить.
[54:50.060 --> 54:56.060]  Появился такой вот очень внимательный французский математик Лебек,
[54:56.060 --> 55:02.060]  который решил проверить, исследовать такую задачу.
[55:02.060 --> 55:09.060]  А что если нам значение функций интерполируют данные с некой погрешностью?
[55:09.060 --> 55:18.060]  Как эта погрешность будет меняться в зависимости от изменения степени полинома?
[55:20.060 --> 55:25.060]  И он представил полином Лагранжа вот в таком виде.
[55:25.060 --> 55:32.060]  Полином Лагранжа – это есть сумма Fn на базисные функции Лагранжа.
[55:32.060 --> 55:35.060]  Сумма Pn. Не буду писать плюс.
[55:35.060 --> 55:42.060]  Вот такая сумма Dfn на Cnn.
[55:42.060 --> 55:44.060]  То есть давайте обозначим так.
[55:45.060 --> 55:51.060]  То есть погрешность интерполяции относительно ошибок входных данных.
[55:51.060 --> 55:56.060]  Но входные данные, вы прекрасно знаете, всегда имеют погрешность.
[55:56.060 --> 56:03.060]  Когда вы работаете с компьютерами, там ну как минимум машинная ошибка.
[56:03.060 --> 56:07.060]  Ну вот давайте модуль этой погрешности.
[56:07.060 --> 56:13.060]  Это будет что у нас? Это будет модуль суммы Dfn на Cnn.
[56:14.060 --> 56:28.060]  Меньше или равно? Меньше или равно максимума модуля Dfn по нашему отрезку.
[56:28.060 --> 56:31.060]  Ну давайте сюда перейдем.
[56:31.060 --> 56:38.060]  На нижнюю строчку, на максимум тоже по отрезку вот этой суммы Pn.
[56:38.060 --> 56:40.060]  Н большой.
[56:40.060 --> 56:42.060]  Сумма Pn.
[56:44.060 --> 56:48.060]  Что касается максимума погрешности, мы его можем оценить сверху.
[56:48.060 --> 56:51.060]  Например, написать, что он меньше или равен дельта ноль.
[56:51.060 --> 56:53.060]  Это некая константа.
[56:53.060 --> 57:03.060]  А вот эту максимум функцию обозначили как Ln и назвали постоянная Лебега.
[57:03.060 --> 57:05.060]  Она у нас не константа.
[57:05.060 --> 57:13.060]  Она у нас в зависимости от степени полинома может меняться и, к сожалению, даже расти.
[57:13.060 --> 57:16.060]  Вот это значит въедливый Лебег заметил.
[57:16.060 --> 57:27.060]  Что оказывается, вот эта составляющая погрешности для расчетных сеток с постоянным шагом растет.
[57:27.060 --> 57:30.060]  И не просто растет, а растет очень хорошо.
[57:31.060 --> 57:35.060]  Это вот исследовали Лебега к этому приюбе.
[57:47.060 --> 57:52.060]  Оказалось, ну это опять же я доказывать не буду, я поведу результат Лебега.
[57:52.060 --> 58:00.060]  Что N, что постоянная Лебега для равномерной сетки растет пропорционально 2 в степени N.
[58:00.060 --> 58:03.060]  То степенную рост дает.
[58:03.060 --> 58:05.060]  Что это означает?
[58:05.060 --> 58:11.060]  Это означает, что в узлах там мы действительно добились решением задачи интерполяции совпадения.
[58:11.060 --> 58:15.060]  Интерполянта и значение интерполянта и интерполирующая функция.
[58:15.060 --> 58:18.060]  Между узлами вот что творится.
[58:18.060 --> 58:23.060]  Между узлами наш интерполянт начинает увеличивать свою амплитуду.
[58:23.060 --> 58:26.060]  Это нам конечно же нравится не может.
[58:26.060 --> 58:34.060]  И вот здесь вспомните, ну я вам говорил, что если мы решаем систему линейных уравнений, решая задачи интерполяции,
[58:34.060 --> 58:37.060]  мы приходим к плохо обусловленной системе уравнений.
[58:37.060 --> 58:43.060]  Лагранш пытался обойти эту правилебу, частично они ее обошли, но только частично.
[58:43.060 --> 58:48.060]  Но они вот встретились с другой проблемой.
[58:48.060 --> 58:54.060]  Эту проблему Лебек назвал неустойчивостью интерполяционного процесса.
[58:54.060 --> 59:03.060]  То есть интерполяционный процесс для высоких степеней интерполяции оказывается неустойчивым.
[59:03.060 --> 59:14.060]  Вот это для высоких степеней интерполяции.
[59:14.060 --> 59:20.060]  И вот эту проблему практически решил повкнуть Львович Чебушов.
[59:20.060 --> 59:28.060]  То есть он нашел такое расположение условий интерполяции, я забегаю вперед, я говорю,
[59:28.060 --> 59:37.060]  что постоянно Лебега оказалась пропорционально всего лишь логарифом не степенной степени, а логарифом N.
[59:37.060 --> 59:41.060]  Это для сетки, правильно вы сказали, для неравномерной сетки.
[59:41.060 --> 59:49.060]  Какой сейчас, скажем, я чуть-чуть вперед забежал, поскольку результат Чебушова был действительно удивительный.
[59:49.060 --> 59:52.060]  Удивил математический мир, когда он это получил.
[59:52.060 --> 59:58.060]  Хотя сейчас, конечно, то, что было гениально 200 лет назад, кажется, просто ясно.
[59:58.060 --> 01:00:00.060]  Тогда это было не совсем ясно.
[01:00:00.060 --> 01:00:02.060]  Ну вот, в чем здесь дело?
[01:00:02.060 --> 01:00:06.060]  Давайте сначала поговорим о погрешности интерполяции.
[01:00:06.060 --> 01:00:11.060]  Или, как говорят, получим вид остаточного члена интерполяции.
[01:00:11.060 --> 01:00:16.060]  Ну или погрешности интерполяции.
[01:00:16.060 --> 01:00:26.060]  И потом перейдем к неравномерным сеткам, что они могут дать.
[01:00:32.060 --> 01:00:42.060]  Ну вот, погрешность интерполяции или традиционное его название остатки члена интерполяции обозначается вот следующим образом.
[01:00:42.060 --> 01:00:45.060]  Ну и покажем следующую теорию.
[01:00:45.060 --> 01:00:55.060]  Пусть интерполированная функция FRP имеет n плюс 1 непрерывную производную на отрезке AB.
[01:00:55.060 --> 01:01:01.060]  То есть принадлежит пространству n плюс 1 раз непрерывно дифференцируемой функции.
[01:01:01.060 --> 01:01:06.060]  Это пространство функции еще называют Чебушовским пространством.
[01:01:06.060 --> 01:01:24.060]  В этом случае остатки члена интерполяции RNOT определяется как n плюс 1 производная в некоторой точке x отрезка интерполяции.
[01:01:24.060 --> 01:01:28.060]  Делим на n плюс 1 факториал.
[01:01:28.060 --> 01:01:42.060]  И здесь умножаем на поле t минус t0, t минус t1, многоточие t минус tn.
[01:01:42.060 --> 01:01:56.060]  Ну если t0, то здесь t минус 1 будет.
[01:01:56.060 --> 01:01:59.060]  Вот так выглядит погрешность интерполяции.
[01:01:59.060 --> 01:02:04.060]  Давайте эту тюрему докажем, тем более что она доказывается довольно просто.
[01:02:04.060 --> 01:02:13.060]  Доказательство такое быстрое и простое предложил Раид Петрович Федеренко, который многие годы читал дексы у нас по учительной математике.
[01:02:13.060 --> 01:02:24.060]  Построим следующую функцию, phi от t равняется f от x минус по линому Lagrange.
[01:02:24.060 --> 01:02:32.060]  Ну интерполяционный по линому тоже от x, а здесь остаток член, который зависит от t.
[01:02:32.060 --> 01:02:58.060]  И вот такая функция в числителе x минус t0, x минус t1, x минус tn, а в знаменателе по линому t минус t0, t минус t1, t минус t, t минус tn.
[01:02:58.060 --> 01:03:04.060]  Вот построим такую функцию. Почему она понравилась?
[01:03:04.060 --> 01:03:13.060]  Но если внимательно посмотрите, то увидите, что она имеет n плюс 2 нуля.
[01:03:13.060 --> 01:03:21.060]  Какие-то нули. Это точки x, kt равняются t, kt.
[01:03:21.060 --> 01:03:30.060]  Это есть погрешность интерполяции либо остаток член интерполяции.
[01:03:30.060 --> 01:03:35.060]  То есть погрешность интерполяции называют остаток членом интерполяции.
[01:03:36.060 --> 01:03:43.060]  Вот она погрешность. Сейчас вы увидите, что это есть погрешность.
[01:03:43.060 --> 01:03:47.060]  Сейчас мы ее получим.
[01:03:47.060 --> 01:03:53.060]  Это n плюс 1 нуль и x равняется t, n плюс 2 нуль.
[01:03:53.060 --> 01:03:57.060]  Почему это так? Проверьте. Проверяется просто.
[01:03:57.060 --> 01:04:06.060]  Между каждыми двумя нулями функции обязательно находится ноль ее производной.
[01:04:06.060 --> 01:04:15.060]  То есть какую-то экстрему. Поэтому производная функция имеет n плюс 1 нуль.
[01:04:15.060 --> 01:04:21.060]  Вторая производная соответственно имеет n нулей. Ну и так далее.
[01:04:21.060 --> 01:04:29.060]  Если мы будем количество нулей уменьшать и продеференцируем эту функцию n плюс 1 раз, то мы получим 1 единица ноль.
[01:04:29.060 --> 01:04:41.060]  То есть мы получим, что в некой точке x производной этой функции x равняется 0.
[01:04:41.060 --> 01:04:45.060]  Теперь нам осталось ее продеференцировать эту функцию.
[01:04:45.060 --> 01:04:49.060]  Тогда вы поймете, зачем мы эту функцию строили.
[01:04:49.060 --> 01:04:54.060]  Сразу получим вид остаточного члена интерполяции.
[01:05:00.060 --> 01:05:04.060]  Давайте продеференцируем эту функцию.
[01:05:04.060 --> 01:05:10.060]  Н плюс 1 раз.
[01:05:10.060 --> 01:05:15.060]  Ну соответственно здесь будет n плюс 1 производной это ноль.
[01:05:15.060 --> 01:05:22.060]  Здесь будет n плюс 1 производной нашей функции.
[01:05:22.060 --> 01:05:26.060]  n плюс 1 производной интерполяционного паренома это ноль.
[01:05:26.060 --> 01:05:31.060]  А здесь будет что у нас? Rn от t.
[01:05:31.060 --> 01:05:37.060]  Производное от вот такого произведения скобок.
[01:05:37.060 --> 01:05:42.060]  Как по-вашему? Чего равно, если продеференцировать вот n скобок?
[01:05:42.060 --> 01:05:45.060]  Точнее n плюс 1 скобка сверху.
[01:05:45.060 --> 01:05:48.060]  Что это будет?
[01:05:48.060 --> 01:05:54.060]  Если например выписать этот пареном в ряд.
[01:05:54.060 --> 01:05:58.060]  Это производной будет n плюс 1 факториал.
[01:05:58.060 --> 01:06:01.060]  Проверьте, что это так.
[01:06:01.060 --> 01:06:05.060]  А внизу пареном t и минус.
[01:06:05.060 --> 01:06:08.060]  t и n малое.
[01:06:08.060 --> 01:06:12.060]  Производное произведение по n.
[01:06:12.060 --> 01:06:14.060]  Вот что получилось.
[01:06:14.060 --> 01:06:19.060]  Ну и отсюда мы легко определяем, что такое Rn.
[01:06:19.060 --> 01:06:24.060]  Что такое остаточный член интерполяции?
[01:06:24.060 --> 01:06:29.060]  Что такое остаточный член интерполяции?
[01:06:29.060 --> 01:06:33.060]  Это есть Rn от t.
[01:06:33.060 --> 01:06:36.060]  n плюс 1 производная.
[01:06:36.060 --> 01:06:41.060]  В некой точке кси на отрезке интерполирования.
[01:06:41.060 --> 01:06:43.060]  n плюс 1 факториал.
[01:06:43.060 --> 01:06:51.060]  И на произведении t минус tкт кат 0 до n.
[01:06:51.060 --> 01:06:54.060]  Вот что это такое.
[01:06:54.060 --> 01:06:59.060]  Теперь посмотрите на эту погрешность интерполяции.
[01:06:59.060 --> 01:07:02.060]  С одной стороны вроде бы простое выражение.
[01:07:02.060 --> 01:07:11.060]  Где здесь есть какая-то неприятность?
[01:07:11.060 --> 01:07:18.060]  В этой погрешности.
[01:07:18.060 --> 01:07:20.060]  n плюс 1 производная.
[01:07:20.060 --> 01:07:27.060]  То есть вообще говоря, если мы хотим аппроксимировать функцию пареного высокого порядка,
[01:07:27.060 --> 01:07:35.060]  то эта функция должна иметь n плюс 1 непрерывную производную.
[01:07:35.060 --> 01:07:39.060]  Это не всегда бывает.
[01:07:39.060 --> 01:07:41.060]  Возьмите какую-нибудь функцию.
[01:07:41.060 --> 01:07:43.060]  Я вам только что рисовал функцию крышка.
[01:07:43.060 --> 01:07:45.060]  Типа модуль х.
[01:07:45.060 --> 01:07:47.060]  Его первого производного уже нет.
[01:07:47.060 --> 01:07:50.060]  Но бывают конечно функции париномернообразные.
[01:07:50.060 --> 01:07:53.060]  Типа sin x и так далее.
[01:07:53.060 --> 01:07:59.060]  У которых есть необходимое количество производных.
[01:07:59.060 --> 01:08:00.060]  Тогда хорошо.
[01:08:00.060 --> 01:08:05.060]  Но далеко не все функции имеют большое количество производных.
[01:08:05.060 --> 01:08:15.060]  И причина того, что интерпольсионный процесс может оказаться неустойчивым.
[01:08:15.060 --> 01:08:18.060]  И вот на это обратил внимание как раз Чебышов.
[01:08:18.060 --> 01:08:21.060]  Где-то в середине XIX века.
[01:08:21.060 --> 01:08:29.060]  И стал думать над задачей, как минимизировать погрешность интерполяции.
[01:08:29.060 --> 01:08:31.060]  Как можно ее минимизировать?
[01:08:31.060 --> 01:08:34.060]  Посмотрите.
[01:08:34.060 --> 01:08:37.060]  Плюс первого производного есть, плюс первого производного.
[01:08:37.060 --> 01:08:39.060]  Мы ее оцениваем по максимуму.
[01:08:39.060 --> 01:08:45.060]  И соответственно по максимуму оцениваем погрешность интерполяции.
[01:08:45.060 --> 01:08:48.060]  Но n плюс 1 факториал это просто констант.
[01:08:48.060 --> 01:08:51.060]  То есть у нас остается только одно.
[01:08:51.060 --> 01:08:53.060]  Парином.
[01:08:53.060 --> 01:09:03.060]  Что мы можем сделать с парином, чтобы уменьшить его значение по модулю.
[01:09:03.060 --> 01:09:06.060]  И можем ли мы что-нибудь сделать?
[01:09:06.060 --> 01:09:08.060]  Казалось, с парином и с парином.
[01:09:08.060 --> 01:09:11.060]  Да что с ним можно сделать?
[01:09:11.060 --> 01:09:15.060]  Можно поменять расположение узлов.
[01:09:15.060 --> 01:09:16.060]  Все.
[01:09:16.060 --> 01:09:18.060]  Это все, что мы можем сделать.
[01:09:18.060 --> 01:09:20.060]  Этим и занялся.
[01:09:20.060 --> 01:09:22.060]  И занялся пафнуть Любовь Чебышов.
[01:09:22.060 --> 01:09:27.060]  Он поставил следующую задачу.
[01:09:27.060 --> 01:09:31.060]  В дальнейшем он поставил целый ряд важнейших задач у аппроксимации функций.
[01:09:31.060 --> 01:09:32.060]  И решил.
[01:09:32.060 --> 01:09:38.060]  А здесь он действительно нашел совершенно поразительный полином.
[01:09:38.060 --> 01:09:40.060]  Он предложил следующую задачу.
[01:09:40.060 --> 01:09:49.060]  Давайте минимизируем наш полином по системе узлов.
[01:09:49.060 --> 01:10:07.060]  То есть найдем минимум от баксибуба по отрезку AB модуля P на P минус T.
[01:10:07.060 --> 01:10:10.060]  Ка от 0 до n.
[01:10:10.060 --> 01:10:15.060]  То есть по другому T системе узлов Tn.
[01:10:15.060 --> 01:10:18.060]  Это есть аргумент.
[01:10:18.060 --> 01:10:27.060]  Минимум по узлам максимума модуля полинома.
[01:10:27.060 --> 01:10:30.060]  И минус T.
[01:10:30.060 --> 01:10:33.060]  От 0 до n.
[01:10:33.060 --> 01:10:36.060]  Вот какую задачу поставил Чебышов.
[01:10:46.060 --> 01:11:00.060]  Вот чтобы решить эту задачу он как раз исследовал как от расположения узлов зависит значение полинома.
[01:11:00.060 --> 01:11:04.060]  В результате пришел вот такому полиному.
[01:11:04.060 --> 01:11:09.060]  Которое сначала представляется некой тригонометрической функцией.
[01:11:09.060 --> 01:11:19.060]  Косинус под n арккосинусов T.
[01:11:19.060 --> 01:11:21.060]  Или его выписывают так.
[01:11:21.060 --> 01:11:28.060]  Косинус под n арккосинус обозначает T.
[01:11:28.060 --> 01:11:32.060]  Это и есть арккосинус.
[01:11:32.060 --> 01:11:37.060]  Арккосинус T.
[01:11:37.060 --> 01:11:40.060]  Сразу видно что T0 это есть единица.
[01:11:40.060 --> 01:11:43.060]  T1 это есть T.
[01:11:43.060 --> 01:11:48.060]  А вот чтобы определить T2, T3 и так далее остальные полиномы.
[01:11:48.060 --> 01:11:52.060]  Нам нужно предложить некую рекламную формулу.
[01:11:52.060 --> 01:11:54.060]  Как ее предложить?
[01:11:54.060 --> 01:12:00.060]  Поскольку видите что это полинома и тригонометрическая функция.
[01:12:00.060 --> 01:12:04.060]  И степенной полином получается.
[01:12:04.060 --> 01:12:09.060]  Мы используем формулу, известную вам кодисума косинусов.
[01:12:09.060 --> 01:12:16.060]  Tn-1 от T сложим Tn-1 от T это что будет?
[01:12:16.060 --> 01:12:18.060]  Это будет сумма косинусов.
[01:12:18.060 --> 01:12:28.060]  Косинус n-1θ плюс косинус n-1θ.
[01:12:28.060 --> 01:12:36.060]  И если вы сумму косинусов выпишете по известной школьной формуле.
[01:12:36.060 --> 01:12:45.060]  Вы получите что это есть 2T на Tn.
[01:12:45.060 --> 01:12:49.060]  Вот вам рекламная формула Tn-1 плюс Tn-1.
[01:12:49.060 --> 01:12:52.060]  Это есть 2T на Tn от T.
[01:12:52.060 --> 01:12:55.060]  Сложите косинус и получите.
[01:12:55.060 --> 01:13:01.060]  А если это так, то мы можем выписать полином T2.
[01:13:01.060 --> 01:13:05.060]  Полином T2 это будет 2T в кубе минус 1.
[01:13:05.060 --> 01:13:14.060]  T3 это будет полином T4 T в кубе минус 3.
[01:13:14.060 --> 01:13:16.060]  Ну и так далее.
[01:13:16.060 --> 01:13:19.060]  Можно выписывать дальнейшие полиномы.
[01:13:19.060 --> 01:13:24.060]  А также Чебышов вел так называемый нормированный полином.
[01:13:24.060 --> 01:13:33.060]  С чертой его обозначает обычно 1 на 2 в степени n на полином Чебышова.
[01:13:33.060 --> 01:13:40.060]  То есть мы коэффициент при члене со старшую степенью делаем единичный.
[01:13:40.060 --> 01:13:46.060]  То есть он как бы нормированный. Его так и называют нормированный полином Чебышова.
[01:13:46.060 --> 01:13:52.060]  Нормированный полином Чебышова.
[01:13:52.060 --> 01:13:57.060]  В нем его особенность относительно других полиномов.
[01:13:57.060 --> 01:14:02.060]  Но Чебышов доказал замечательную тюрему.
[01:14:02.060 --> 01:14:06.060]  Я доказывать не буду, но приведу.
[01:14:06.060 --> 01:14:10.060]  Среди всех полиномов в степени n больше или равной единице
[01:14:10.060 --> 01:14:16.060]  коэффициентом при члене со старшей степенью n равном единице
[01:14:16.060 --> 01:14:22.060]  наименее уклоняется от нуля полином, о котором сейчас шла вещь.
[01:14:22.060 --> 01:14:25.060]  Сейчас мы его называем полином Чебышовым.
[01:14:25.060 --> 01:14:29.060]  Но когда Чебышов доказывал тюрему, он еще не назывался полиномом Чебышовым.
[01:14:30.060 --> 01:14:41.060]  И максимум вот этого нормированного полинома t на отрезке всегда будет меньше
[01:14:41.060 --> 01:14:49.060]  максимума любого другого полинома на этом же отрезке.
[01:14:49.060 --> 01:14:56.060]  Вот что означает полином наименее уклоняется от нуля.
[01:14:56.060 --> 01:15:00.060]  Его максимум всегда меньше максимума любого другого полинома.
[01:15:00.060 --> 01:15:04.060]  Этой же степени, какого бы ни взяли.
[01:15:04.060 --> 01:15:07.060]  Ну это вот один результат.
[01:15:07.060 --> 01:15:10.060]  Далее следует...
[01:15:10.060 --> 01:15:12.060]  Так, что еще здесь надо сказать?
[01:15:12.060 --> 01:15:14.060]  А, вот еще важный момент.
[01:15:14.060 --> 01:15:17.060]  Нули полинома Чебышова tm.
[01:15:17.060 --> 01:15:21.060]  Вы просто берете и вот с этого функции полином Чебышова прибавляет к нулю.
[01:15:21.060 --> 01:15:28.060]  Получаете cos2m-1 на 2np.
[01:15:28.060 --> 01:15:35.060]  Ну m номер корня 1 от 1 до n меняется.
[01:15:35.060 --> 01:15:37.060]  Это нули полинома Чебышова.
[01:15:37.060 --> 01:15:39.060]  Зачем они нужны?
[01:15:39.060 --> 01:15:45.060]  Если мы их сделаем узлами нашего интерполюционного полинома,
[01:15:45.060 --> 01:15:52.060]  то мы получим интерполюционный полином наименее уклоняющийся от нуля.
[01:15:52.060 --> 01:15:54.060]  То есть минимальный по модулю полином.
[01:15:54.060 --> 01:15:55.060]  Это очень важно.
[01:15:55.060 --> 01:16:00.060]  То есть погрешность его будет меньше всегда, чем погрешность любого другого полинома.
[01:16:00.060 --> 01:16:01.060]  Она тоже оценена.
[01:16:01.060 --> 01:16:06.060]  Я об этом тоже разумеется скажу.
[01:16:06.060 --> 01:16:09.060]  Ну вот уже советская математика Бридштейн,
[01:16:09.060 --> 01:16:13.060]  который, так сказать, это вторая половина 20 века,
[01:16:13.060 --> 01:16:21.060]  доказал тюрему о замечательном свойстве полинома Чебышова.
[01:16:25.060 --> 01:16:27.060]  Вот из тюремы Бридштейна следует,
[01:16:27.060 --> 01:16:38.060]  что постоянно либега меньше или равна 8 плюс 4 делить на π в логарифме n плюс 1.
[01:16:38.060 --> 01:16:42.060]  Это вот Иоанна Бридштейна.
[01:16:42.060 --> 01:16:56.060]  То есть погрешность 4 делить на π.
[01:16:56.060 --> 01:16:58.060]  То есть та погрешность, та постоянная либега,
[01:16:58.060 --> 01:17:03.060]  которая растет степенным образом для равномерной сетки,
[01:17:03.060 --> 01:17:07.060]  для сетки Чебышовской, она вот всего лишь как логарифм растет.
[01:17:07.060 --> 01:17:12.060]  Результат сам по себе очень впечатляющий.
[01:17:12.060 --> 01:17:14.060]  Очень впечатляющий.
[01:17:14.060 --> 01:17:16.060]  Это раз.
[01:17:16.060 --> 01:17:23.060]  Далее для функции f равняется модуль t.
[01:17:23.060 --> 01:17:32.060]  Тоже Бридштейн показал, что предел модуля полинома,
[01:17:32.060 --> 01:17:37.060]  например, на n минус эта функция, модуль,
[01:17:37.060 --> 01:17:42.060]  стремится к бесконечности при m, стремящемся к бесконечности.
[01:17:42.060 --> 01:17:45.060]  Эта функция не имеющая первой производной.
[01:17:45.060 --> 01:17:49.060]  И показал, что для сетки Чебышова это не так.
[01:17:49.060 --> 01:17:51.060]  Это не выполняется.
[01:17:51.060 --> 01:17:53.060]  То есть если мы возьмем сетку на Чебышова,
[01:17:53.060 --> 01:17:56.060]  то вот эта разность не будет стремиться к бесконечности.
[01:17:56.060 --> 01:17:58.060]  Тоже результат совершенно замечательный.
[01:17:58.060 --> 01:18:01.060]  То есть функция не имеет даже первой производной.
[01:18:01.060 --> 01:18:04.060]  Производные стоят в остаточном члене,
[01:18:04.060 --> 01:18:08.060]  но тем не менее погрешность не стремится к 0.
[01:18:08.060 --> 01:18:12.060]  Результат тоже совершенно замечательный.
[01:18:12.060 --> 01:18:15.060]  На самом деле, в ваших лабораторных вы будете делать
[01:18:15.060 --> 01:18:18.060]  такую интерполяцию на Чебышовской сетке и увидите,
[01:18:18.060 --> 01:18:21.060]  что результат там просто бросается в глаза.
[01:18:21.060 --> 01:18:23.060]  Блестящий результат.
[01:18:23.060 --> 01:18:26.060]  Как меняется свойство интерполяционного полинома,
[01:18:26.060 --> 01:18:30.060]  если вместо равномерности сетки будем брать Чебышовскую сетку.
[01:18:30.060 --> 01:18:34.060]  То есть узлы полиного Чебышова.
[01:18:34.060 --> 01:18:39.060]  Ну и если брать РН, то есть остаточный член оценивать,
[01:18:39.060 --> 01:18:43.060]  как Берштейн этим задачами занимался,
[01:18:43.060 --> 01:18:48.060]  то на отрезке минус 1.1
[01:18:52.060 --> 01:18:56.060]  остаточный член для функции Чебышова
[01:18:56.060 --> 01:18:59.060]  будет оцениваться следующим образом.
[01:18:59.060 --> 01:19:01.060]  Здесь будет стоять максимум.
[01:19:01.060 --> 01:19:03.060]  Давайте я его как новую возьму.
[01:19:03.060 --> 01:19:07.060]  Н плюс 1 производной делим на N плюс 1 факториал.
[01:19:07.060 --> 01:19:11.060]  А здесь единица делить на 2 степени N.
[01:19:11.060 --> 01:19:15.060]  Но, разумеется, при наличии N плюс 1 производной.
[01:19:15.060 --> 01:19:19.060]  То есть погрешность интерполяционного полинома Чебышова,
[01:19:19.060 --> 01:19:23.060]  ну вы видите, в разъединятеле стоит N факториал и 2 степени N.
[01:19:23.060 --> 01:19:27.060]  То есть убывает с огромной скоростью.
[01:19:27.060 --> 01:19:30.060]  Ну и если сравнить равномерно с сеткой,
[01:19:30.060 --> 01:19:34.060]  то, конечно, сравнение очень-очень впечатляет.
[01:19:34.060 --> 01:19:36.060]  Очень впечатляет.
[01:19:38.060 --> 01:19:41.060]  Так, у нас время осталось еще или нет?
[01:19:43.060 --> 01:19:45.060]  Пять минут осталось?
[01:19:45.060 --> 01:19:47.060]  А, все уже, да.
[01:19:47.060 --> 01:19:49.060]  Ну ладно, озвонок тогда.
[01:19:49.060 --> 01:19:51.060]  На сегодня мы закончим.
