[00:00.000 --> 00:08.880]  Доказательства, но не завершили технику, правильно?
[00:08.880 --> 00:12.560]  Так, ну чего у нас там была за сумма, давайте я попробую
[00:12.560 --> 00:14.120]  наизусть ее вспомнить.
[00:14.120 --> 00:18.720]  Значит, это была сумма по k от единицы до n пополам,
[00:18.720 --> 00:24.800]  c из n по k, 1 минус p в степени k на n минус k.
[00:24.800 --> 00:27.800]  Наша цель была доказать, что она стремится к нулю,
[00:27.800 --> 00:32.180]  и в прошлый раз я сказал, что идейно надо ее разбить
[00:32.180 --> 00:39.280]  на две части по некоторым причинам, n поделить на корень
[00:39.280 --> 00:46.000]  из логарифма n, плюс по k от n на корень из логарифма
[00:46.000 --> 00:52.760]  n плюс 1, до n попало, так было?
[00:52.760 --> 00:55.200]  Причем в первом суммировании предполагалось оценивать
[00:55.200 --> 00:58.880]  аккуратно с помощью геометрической прогрессии, а во втором
[00:58.880 --> 01:01.920]  суммировании тяп-ляп, вот давайте второе суммирование
[01:01.920 --> 01:02.920]  оценим тяп-ляп.
[01:02.920 --> 01:11.040]  Тяп-ляп это вот как, c из n по k на 1 минус p в степени
[01:11.040 --> 01:18.640]  k на n минус k меньше, чем 2 в n степени, но c из n по k
[01:18.640 --> 01:23.440]  меньше, чем 2 в n, любая цешка меньше, чем сумма всех цешек,
[01:23.440 --> 01:24.440]  правда?
[01:24.800 --> 01:33.720]  А тут напишем e в степени минус p, k на n минус k, так с
[01:33.720 --> 01:37.920]  такой скоростью понятно, как мы 1 минус p оценили,
[01:37.920 --> 01:40.600]  но e в степени логарифма от 1 минус p, а логарифма от
[01:40.600 --> 01:44.520]  1 минус p не больше, чем минус p, стандартная оценка.
[01:44.520 --> 01:49.200]  Так, и еще мы должны заметить, что k у нас, ну чего там, не
[01:49.200 --> 01:53.720]  больше, чем n пополам, поскольку k вот здесь идет с плюсом,
[01:53.780 --> 01:57.560]  минус на минус дает плюс, то вот эту кашечку я оценю
[01:57.560 --> 01:59.160]  сверху, как n пополам.
[02:00.900 --> 02:05.480]  Экому хочу вот так, это меньше либо равно, renew либо равно
[02:05.480 --> 02:13.880]  2 в степени n, на e в степени минус p, k, n пополам, это вот
[02:13.880 --> 02:16.320]  эту кашечку я оценил сверху, как n пополам.
[02:16.320 --> 02:19.720]  А вот эту кашечку я оценю снизу, как n поделите на
[02:19.720 --> 02:27.600]  корень из логарифма. Тоже будет оценка сверху. 2 в степени n на e в степени
[02:27.600 --> 02:38.600]  минус p, n квадрат, поделить на 2 корня из логарифма n, да? Ну вроде так.
[02:38.600 --> 02:44.920]  Так, надо еще вспомнить, что p у нас в теореме все время равняется c логарифм n
[02:44.920 --> 02:51.880]  поделить на n. Ну, мы знаем, что c в текущей ситуации что там больше единицы, но сейчас
[02:51.880 --> 02:57.520]  это не очень будет важно. Просто какая-то константа c, поэтому можем подставить.
[02:57.520 --> 03:03.680]  Давайте я так напишу. e в степени n логарифм 2. Это 2 в степени n, представленное
[03:03.680 --> 03:15.240]  в таком виде. Ну и минус, так, c логарифм n на n, подставил просто p, умножить на n в
[03:15.240 --> 03:23.320]  квадрате и поделить на 2 корни из логарифма. Ну, вот тут объясняется, почему я
[03:23.320 --> 03:27.920]  заходил именно корень из логарифма писать. Очень удобно сокращать.
[03:27.920 --> 03:36.760]  Смотрите, шлёп, шлёп. Я могу с таким же успехом на самом деле написать повторный
[03:36.760 --> 03:41.360]  логарифм вот здесь, например. И здесь тоже написать повторный логарифм, но так красиво
[03:41.360 --> 03:45.640]  оно не сократится. Вот разница только в этом. Как именно разбивать на две части
[03:45.640 --> 03:51.080]  суммирования? Важно, как я говорил в прошлый раз, чтобы вот это было маленькое от n, а уж
[03:51.080 --> 03:58.400]  какое именно у маленькое. Но тут красиво сокращается, тут тоже хлоп, хлоп. Ну и мы с
[03:58.400 --> 04:03.800]  лёгкостью видим, что из величины порядка n вычитается величина n, умноженная на корень из
[04:03.800 --> 04:08.960]  логарифма, то есть в пределе получается минус бесконечность, а поскольку это в показателе
[04:08.960 --> 04:16.320]  экспоненты, то всё это отправляется в ноль. Но не совсем нам это нужно, чтобы отправлялось в ноль,
[04:16.320 --> 04:22.920]  нам же надо всю сумму оценить, но каждая слагаемая мы оценили вот таким образом, значит вся сумма
[04:22.920 --> 04:34.000]  не больше, чем n, скажем, умножить вот на это. Ну а n это вообще фигня. n это е в степени логарифм n.
[04:34.000 --> 04:44.840]  Так, я концовку не скомкал, понятно? Ну я оценивал сначала каждая слагаемая,
[04:44.840 --> 04:48.920]  оно, конечно, стремится к нулю, потому что показатель экспонента стремится к минус бесконечности,
[04:48.920 --> 04:53.800]  но даже если мы каждая слагаемая, вот так оцененная, умножим на количество слагаемых,
[04:53.800 --> 05:00.680]  загрубленное до n, то n это просто е в степени логарифм n. Логарифм n, он даже вот этому n в подмётке
[05:00.680 --> 05:07.320]  не годится, уж тем более убивает таким отрицательным. То есть всё там с асфистом в ноль, асфальт. Но это
[05:07.320 --> 05:12.200]  не всё, это мы разобрались вот с этим вторым слагаемым, это хвостик. Вот хвостик уже настолько
[05:12.200 --> 05:16.400]  маленький, что можно очень грубо оценивать, и всё равно замечательно всё стремится к нулю.
[05:16.400 --> 05:25.080]  Конечно, нас больше интересует вот эта сумма, пока от единицы до n на корень из логарифма n,
[05:25.080 --> 05:36.960]  опять же c из n по k, 1 минус m в степени k на n минус k. Ну вы помните идею или уже забыли? Надо
[05:36.960 --> 05:44.520]  следующее слагаемое разделить на предыдущее, k плюс первое на k, и увидеть, что это очень
[05:44.520 --> 05:53.880]  хорошо само тоже стремится к нулю. Ну давайте, c из n по k плюс 1, 1 минус p в степени k плюс 1
[05:53.880 --> 06:16.560]  на n минус k минус 1. Поделить на c из n по k, 1 минус p в степени k на n минус k. Так, ну что-то
[06:16.560 --> 06:22.080]  здесь совсем легко сокращается. Видите, вот тут есть тянфакториал, и тут есть тянфакториал.
[06:22.080 --> 06:30.880]  Можно не буду писать. Тут есть k плюс 1 факториал, но он в знаменателе на самом деле. А тут есть k
[06:30.880 --> 06:36.000]  факториал, он в знаменателе, но он прыгает в чувствитель, поэтому в знаменателе остается в
[06:36.000 --> 06:41.280]  живых только k плюс 1. Ну если на слух это трудно воспринимать, можете просто расписать и
[06:41.280 --> 06:48.840]  посокращать. Вот, что еще есть? Вот здесь в знаменателе есть n минус k факториал, но он опять же
[06:48.840 --> 06:54.440]  прыгает наверх. Тут вот появляется n минус k факториал, а в настоящем знаменателе оказывается
[06:54.440 --> 07:04.240]  n минус k минус 1 факториал. Ну то есть вверху выживает n минус k, а все остальное сокращается. Все,
[07:04.320 --> 07:13.760]  цшки я сократил, теперь пэшки. Так, ну смотрите, я вот так подчеркну, это прямо в точности то же
[07:13.760 --> 07:27.600]  самое. Сократи. Так, что у меня остается? Остается вот это минус k и плюс вот это n минус k минус 1. Все,
[07:27.600 --> 07:36.520]  больше ничего не остается. Согласны? Вот, ну в очередной раз вспоминаем, что c у нас константа,
[07:36.520 --> 07:43.440]  поэтому вот эта дробь она стремится к нулю, конечно. И в общем, ну чего, можно написать,
[07:43.440 --> 07:50.800]  например, что это асимптатически равно n минус k поделить на k плюс 1, так это минус, n минус k
[07:50.800 --> 08:01.000]  поделить на k плюс 1, 1 минус p в степени n минус 2k. Ну дальше можно сказать, что это меньше,
[08:01.000 --> 08:08.120]  а мы не знаем, чего меньше вот эта дробь на самом деле, потому что k-то у нас в очень большом
[08:08.120 --> 08:14.040]  промежутке присутствует. Мы не знаем, k может быть маленьким, k может быть большим. Ну в общем,
[08:14.040 --> 08:19.600]  это меньше, чем n просто, ничего лучшего я сказать не могу. А, я могу сказать лучше. Я могу сказать,
[08:19.600 --> 08:25.160]  что это меньше, чем n пополам, но это вряд ли нам что-то даст, потому что нас интересует
[08:25.160 --> 08:33.840]  стремление к нулю оценки. Поэтому давайте напишем тупо, это меньше, чем n, умноженное на 1 минус p
[08:33.840 --> 08:44.920]  в степени n минус 2k. И вот в этом месте замечаем, что k у нас, о маленькое от n, неважно, n на корень
[08:44.920 --> 08:52.400]  из логарифма n, на логарифм повторный, на что хотите. Но важно, что оно маленькое от n. Поэтому
[08:52.400 --> 09:00.840]  фактически это, ну конечно можно так написать, это меньше, чем n умножить на 1 минус p в степени
[09:00.840 --> 09:08.960]  n минус n на корень из логарифма n. И это правда. Но важно, что вот эта вот фигня по сравнению с этим.
[09:08.960 --> 09:19.760]  И важно, что вот это все уже от k никак не зависит. Если хотите, я вот это q от n обозначу. По-моему,
[09:19.760 --> 09:25.400]  q это обозначалось в прошлый раз, когда я рассказывал идею. Знаменатель геометрической прогрессии.
[09:25.400 --> 09:36.080]  Вот это будет q от n. Вот эти елки-палки, давайте я еще раз напишу q от n. Это есть просто n на 1
[09:36.080 --> 09:44.360]  минус p в степени n, помноженное на единиц плюсов малое от единиц. Да не смутит никого плюс,
[09:44.360 --> 09:51.480]  потому что малое от единиц может быть отрицательным, как оно здесь и оказывается. Ну а мы же знаем,
[09:51.480 --> 10:00.600]  что такая штука при c большего единицы стремится к нулю. Но мы без вот этого считали с n минус единичкой,
[10:00.600 --> 10:09.000]  но какая разница, какое здесь 1 плюсов малое от единицы. Помните, что c больше единицы гарантирует,
[10:09.000 --> 10:14.000]  что мат ожидания числа изолированных вершин стремится к нулю. А это по сути оно и есть,
[10:14.000 --> 10:21.080]  но так получилось просто. С точностью до умножения вот на эту ерунду. А она не влияет, то есть при наших
[10:21.080 --> 10:27.560]  условиях это таки стремится к нулю. И вся идеология, которая была предложена в прошлый раз в геометрической
[10:27.560 --> 10:36.440]  прогрессии оказывается реализуемой. То есть вся сумма вот эта оказывается меньше, чем n на единицы
[10:36.440 --> 10:47.320]  минус p в степени n минус 1. Это мы k равные единички подставили. Умножить на сумму 1 плюс q от n плюс q
[10:47.320 --> 11:01.720]  квадрат от n плюс и так далее. А это меньше, чем n на 1 минус p в n минус 1 на 1 поделить на 1 минус q от n.
[11:01.720 --> 11:09.640]  Это стремится к нулю, q от n по тем же причинам стремится к нулю. Значит все стремится к нулю.
[11:09.640 --> 11:19.480]  Но вся тонкость находится здесь. Вот здесь дважды нужно, чтобы c было больше единицы. Дважды это нужно.
[11:19.480 --> 11:29.480]  А хвостик оценивается тяпляк. Слушайте, ну я вроде доказал. По-моему теорема доказана полностью. Давайте я
[11:29.480 --> 11:36.040]  сформулирую еще одну теорему, но не буду ее доказывать. Она очень важная. Есть еще один важный
[11:36.040 --> 11:41.400]  фазовый переход. Важная пороговая вероятность, которая очень существенным образом меняет свойства
[11:41.400 --> 11:48.360]  случайного графа. Это важно в том числе и для прикладных каких-то моментов. А именно пусть теперь
[11:48.360 --> 12:02.760]  c поделить на n. Логорифм пропал из числителя. То есть это меньше гораздо. Логорифм n раз меньше.
[12:02.760 --> 12:10.760]  Понятное дело, что c снова константа, большее нуля. Понятное дело, что в этом режиме граф связанным не будет.
[12:11.720 --> 12:19.240]  Ну не будет асимпатически почти наверх. С вероятностью стремящихся единиц граф не связан, потому что
[12:19.240 --> 12:24.360]  логорифм пропал, но ясно мы находимся в ситуации, в которой наверное даже не только изолированные
[12:24.360 --> 12:29.080]  вершины есть, но есть еще масса всего. Вот это мы обсудим потом, что именно там появляется.
[12:29.080 --> 12:36.760]  Но вот пусть p такое. Все-таки есть важные очень переключения. А именно первое. Если
[12:36.760 --> 12:47.720]  c меньше единицы, опять единица отвечает за пазовый переход, чуть-чуть оторвались в одну сторону, то
[12:47.720 --> 12:57.480]  существует такая константа бета, большее нуля, что асимпатически почти наверное
[12:57.480 --> 13:00.960]  в каждой
[13:00.960 --> 13:14.280]  связанной компоненте случайного графа. Каждой связанной компоненте случайного графа не больше,
[13:14.280 --> 13:25.320]  чем бета логорифм n вершин. Мало того, что он не является связанным, у него еще каждая компонента
[13:25.320 --> 13:32.520]  крошечная. Всего n вершин, а в каждой компоненте какое-то логорифмическое количество, порядка
[13:32.520 --> 13:42.800]  логорифма может меньше. То есть вот этот случайный мир, он разваливается на кучу отдельных таких
[13:42.800 --> 13:55.400]  маленьких кусочков. Я потом картинку беру. Вот. А переключение происходит следующего рода. Если
[13:55.400 --> 14:08.600]  c больше единицы, то существует бета, большее нуля опять, и существует гамма, лежащая на интервале
[14:08.600 --> 14:14.560]  от нуля до единицы. То есть значение 1 она не принимает, но вот есть некоторые еще одна константа,
[14:14.560 --> 14:24.920]  строго положительная, но меньше единицы. Такие, что асимпатически почти наверное ровно одна
[14:24.920 --> 14:40.080]  компонента, ровно одна компонента имеет не меньше, чем гамма помножить на n вершин,
[14:40.080 --> 14:51.120]  а размер каждой оставшейся компоненты, то есть число вершин, а размер каждой
[14:51.120 --> 15:02.680]  оставшейся компоненты, ну кадры из оставшихся компонент, кадры из оставшихся компонент снова
[15:02.680 --> 15:13.240]  не больше, чем бета-логорифмен. Видите какая удивительная ситуация, какая удивительная эволюция
[15:13.240 --> 15:21.800]  случайного графа, как при этом говорит, но это как обычно множество вершин. И даже я бы сказал,
[15:21.800 --> 15:29.320]  ну может и сарделька, кстати, да. То есть при c меньшем единице граф разваливается вот на
[15:29.320 --> 15:37.120]  такие кусочки, которые ничтожно малы все по сравнению с общим количеством вершин. Ну вы
[15:37.120 --> 15:43.920]  можете сказать, что это огурец, а никакая не сарделька. С другой стороны бывает такой объект,
[15:43.920 --> 15:52.000]  который называется шпикачка, так что может быть это все-таки сарделька. Вот. Эта ситуация c меньше единиц,
[15:52.000 --> 15:58.280]  а в ситуации, когда c больше единиц, мы вроде чуть-чуть совсем проэволюционировали, буквально
[15:58.280 --> 16:05.480]  перескочили через порог единица поделить на n по вероятности ребра, и вдруг взяли и все почти,
[16:05.480 --> 16:13.880]  что вот эти крошечные компоненточки как-то склеились в одну такую вот огромную-огромную
[16:13.880 --> 16:19.360]  компоненту, которая по порядку имеет столько же вершин, сколько во всем графе. Но здесь, конечно,
[16:19.360 --> 16:25.600]  важно, что гамма строго меньше единицы, потому что граф по-прежнему не связан. Гамма не может
[16:25.600 --> 16:32.520]  равняться единицам. Но случается вот такое вот резкое замыкание этих крошечных компонентов,
[16:32.520 --> 16:40.160]  а что-то гигантское. Вот эта компонента единственная, единственная, видите, ровно одна компонента
[16:40.160 --> 16:45.440]  имеет не меньше, чем гамма n вершин. Она прямо официально называется гигантской компонентой
[16:45.440 --> 16:56.360]  случайного графа. По-английски giant component. Гигантская компонента случайного графа,
[16:56.360 --> 17:01.600]  а остальные по-прежнему крошечные. То есть я очень люблю это в каком-то смысле в шутку,
[17:01.600 --> 17:10.320]  хотя в этом есть доля правды. Интерпретировать в таких, знаете, терминах, стратегических что-ли,
[17:10.320 --> 17:17.920]  ну то есть картинка такая. Есть два порога, один поделить на n и logarithm n поделить на n.
[17:17.920 --> 17:26.400]  Вот до этого порога имеет место феодализм. Вот где-то здесь в промежутке имеет место империя.
[17:26.400 --> 17:32.040]  Гигантская компонента вполне естественно интерпретируется как империя, а когда
[17:32.040 --> 17:42.440]  империя захватывает все свои окраины, это называется мировое господство. Вот так вот устроен случайный
[17:42.440 --> 17:47.440]  граф. И это на самом деле такое явление природы. То есть вот физики, например, очень часто изучают
[17:47.440 --> 17:53.920]  эти явления, называя их фазовыми переходами. И для физиков это очень важный момент. Для математиков
[17:53.920 --> 18:00.080]  тоже, потому что это работает при изучении различных сетей, которые возникают в природе.
[18:00.080 --> 18:07.640]  То есть интернет такая сеть, социум такая сеть. Да елки-палки, распространение эпидемий тоже
[18:07.640 --> 18:18.520]  образует фазовый переход, как вы, наверное, понимаете. Так, несмотря на то, что я не собираюсь
[18:18.520 --> 18:23.920]  доказывать эту теорему. И, кстати, заодно вы сейчас спросите, а что будет при ц равном единице,
[18:23.920 --> 18:30.320]  я не отвечу. Потому что прямо вот в точности при ц равном единице не очень понятно, что сказать.
[18:30.320 --> 18:35.920]  Там надо аккуратно параметризовать внутри вот этого окошечка фазового перехода функцию
[18:35.920 --> 18:41.720]  вероятности. И тогда там будет интересный двойной, как выражал Свердов скачок. То есть сначала все
[18:41.720 --> 18:46.520]  разваливается на крошечные компоненты, как я и говорил. Потом они начинают склеиваться в
[18:46.520 --> 18:52.720]  компоненты порядка n в степени 2 третьих. И вот уже в конечном итоге, когда С строго больше единицы,
[18:52.720 --> 19:04.720]  образуется гигант. Но это долго и тяжело рассказывать. Бета, наверное, довольно легко выразить,
[19:04.720 --> 19:10.160]  но я сейчас не могу сообразить, какое оптимальное, просто на память не помню. А гамма точно умеем
[19:10.160 --> 19:15.640]  выражать через С. Я только боюсь ошибиться, но скоро вы увидите, откуда это берется,
[19:15.640 --> 19:32.160]  что-то типа вот такого уравнения, что-то типа того. Не помню. Но это можно выразить. Гамму можно
[19:32.160 --> 19:37.120]  через С выразить совершенно явно, как решение некоего уравнения. Какое уравнение появится,
[19:37.120 --> 19:42.840]  я чуть позже скажу. Я не очень хочу вас мучить подробным доказательством этой теории, потому что
[19:42.840 --> 19:50.360]  это довольно технически трудно. Но некоторую интуицию я попробую создать. Откуда логарифм берется
[19:50.360 --> 19:57.480]  и как, например, Бету оценить. Вот это я сейчас попробую сделать, но я это сделаю в связке с любимым
[19:57.480 --> 20:03.280]  хроматическим числом, которое сейчас к нам вернется. Помните, что у нас было хроматическое число?
[20:03.280 --> 20:10.720]  Что мы уже знаем про хроматическое число, давайте вспомним. Мы знаем, что его лучше оценивать с
[20:10.720 --> 20:17.760]  помощью n поделить на альфа, если оценка внизу. Помните такой факт? Не омегой оценивать, а дробью n
[20:17.760 --> 20:26.600]  поделить на альфа, где альфа-число независно. Дальше мы знаем, а что мы еще знаем про хроматическое
[20:26.600 --> 20:33.960]  число, что его хорошо считать с помощью жадного алгоритма. Это мы долго обсуждали. Ну и что бывают
[20:33.960 --> 20:39.120]  графы, у которых хроматическое число наперед заданное и при этом нет вообще циклов коротких.
[20:39.120 --> 20:41.120]  Вот это все, что мы знаем на самом деле.
[20:46.120 --> 20:53.120]  Да, да, да, такое было, но это мы поговорили и сейчас об этом тоже говорить не будет.
[20:53.120 --> 20:59.120]  А мы подумаем, а как вообще ведет себя хроматическое число в разных режимах для случайного графа.
[20:59.120 --> 21:04.120]  Это важно тоже понимать, потому что в зависимости от того, как устроена ваша исходная сеть,
[21:04.120 --> 21:11.120]  для которой вам нужно посчитать хроматическое число, могут получаться разные результаты.
[21:11.120 --> 21:15.120]  И соответствующие алгоритмы тоже можно будет за счет каких-то евристик улучшать.
[21:21.120 --> 21:26.120]  То есть мы не забываем про ту теорему, она пусть посветится там какое-то время, но параллельно
[21:26.120 --> 21:32.120]  вернемся к обсуждению хроматического числа в том ключе, как оно ведет себя на случайном графе.
[21:32.120 --> 21:37.120]  В зависимости от того, как устроена вероятность ребра. Маленькая, она большая и так далее.
[21:37.120 --> 21:44.120]  Ну, самый простой случай, это пусть
[21:44.120 --> 21:49.120]  п такая функция от n, вероятность ребра,
[21:49.120 --> 21:53.120]  что n квадрат, умноженное на p, стремится к нулю.
[21:53.120 --> 21:58.120]  Ну то есть это очень быстро, стремящееся к нулю, но не экспоненциально.
[21:58.120 --> 22:03.120]  Достаточно, чтобы она была маленькой от единицы, поделить на n в квадрате.
[22:03.120 --> 22:08.120]  Хотите пусть будет экспоненциально, но от этого уже точно ничего не поменяет.
[22:08.120 --> 22:13.120]  Потому что, товарищи, как вы думаете, какое будет хроматическое число у этого случайного графа
[22:13.120 --> 22:18.120]  и вообще, что он из себя будет в зависимости от этого?
[22:18.120 --> 22:23.120]  Набор вершин, да. Весь граф будет одним огромным независимым множеством.
[22:23.120 --> 22:30.120]  Смотрите, с какой вероятностью случайный граф не содержит ребр.
[22:30.120 --> 22:35.120]  Ну вообще не имеет ни одного ребра. Не содержит ребра.
[22:35.120 --> 22:40.120]  Ну, в общем, это очень просто.
[22:40.120 --> 22:47.120]  Случайный граф не содержит ребр. Ну вообще не имеет ни одного ребра.
[22:47.120 --> 22:50.120]  Не содержит ребр.
[22:50.120 --> 22:54.120]  Ну это, конечно, 1 минус p в степени c из n по 2.
[22:54.120 --> 22:58.120]  Нет ни одного ребра. Согласны?
[22:58.120 --> 23:03.120]  Ну, я не знаю, это очевидно не меньше, чем 1 минус p на c из n по 2, например.
[23:03.120 --> 23:08.120]  Ну, как очевидно, не равенство. Бернули там какое-то, надо вспомнить.
[23:08.120 --> 23:17.120]  Но c из n по 2 это же величина n в квадрате пополам.
[23:17.120 --> 23:23.120]  То есть, когда вы p умножаете на c из n по 2, вы фактически умножаете его по порядку на n в квадрате.
[23:23.120 --> 23:29.120]  А это стремится к 0. Значит, вот эта разность стремится к 1, тривиальным образом.
[23:29.120 --> 23:38.120]  А симпатически почти, наверное, в таком режиме, в случайном графе нет вообще ни одного ребра.
[23:38.120 --> 23:51.120]  Ну, значит, хроматическое число 1.
[23:51.120 --> 23:56.120]  Все вершины красим в один и тот же цвет, ребр нет, никаких противоречий.
[23:56.120 --> 24:07.120]  Ну, то есть, из всего многообразия тех значений, какие в принципе может принимать хроматическое число, случайный граф в этом режиме предпочитает выбрать только одно, единица.
[24:07.120 --> 24:18.120]  Причем тривиальным образом, потому что на нас с неба при таком режиме сваливаются только пустые графы, и лишь изредка не пустые.
[24:18.120 --> 24:30.120]  Чуть более интересный случай, но вообще более интересный случай. Вот сейчас мы его попробуем в связке с той теоремой обсудить.
[24:30.120 --> 24:41.120]  Так, там, наверное, сейчас...
[24:41.120 --> 24:46.120]  Это наша замечательная лаборатория комбинаторных и геометрических структур.
[24:46.120 --> 24:53.120]  Приехал наконец-то наш международный руководитель Яна Шпах.
[24:53.120 --> 24:59.120]  Но не мог из-за заковидных ограничений они проникают в свою лабораторию с большим шумом.
[24:59.120 --> 25:04.120]  Радостно. Ну, может, они не будут больше шуметь, надо, наверное, открыть дверь, но неважно.
[25:04.120 --> 25:13.120]  Так, пусть теперь p это снова функция от n. Ну, любая p-функция от n, даже констант, это функция чего уж там.
[25:13.120 --> 25:18.120]  Но теперь такая, что n, помноженное на p, стремится к нулю.
[25:18.120 --> 25:22.120]  Давайте пока просто n, помноженное на p, стремится к нулю.
[25:22.120 --> 25:32.120]  Ну, или по-другому говоря, можно написать, что p равняется c поделить на n, но где c стремится к нулю при n, стремящемся к бесконечности.
[25:32.120 --> 25:37.120]  То есть это не константа, как в той теории. Согласны?
[25:37.120 --> 25:45.120]  Вот что из себя представляет структурно такой случайный граф, какое у него в том числе хроматическое число?
[25:45.120 --> 25:55.120]  Я утверждаю, что в этом графе вообще нет циклов. Асимптатически, почти наверно.
[25:55.120 --> 26:03.120]  Но если я это докажу, то это будет означать, что он имеет хроматическое число 2, то есть все его компоненты суть деревья.
[26:03.120 --> 26:07.120]  Правильно? Если вообще не имеет циклов, то это лес.
[26:07.120 --> 26:16.120]  Ну, давайте докажем, что он лес. Давайте обозначим х от g число простых циклов.
[26:16.120 --> 26:22.120]  Мы похожую выкладку делали, но она у нас тогда была ограничена длиной простого цикла.
[26:22.120 --> 26:29.120]  Это когда мы доказывали теорему про то, что бывают графы с задным хроматическим числом и не имеющие коротких циклов.
[26:29.120 --> 26:34.120]  А сейчас нас интересуют циклы хоть короткие, хоть длинные, хоть какие.
[26:34.120 --> 26:41.120]  Чему равно математическое ожидание такого х по линейности?
[26:41.120 --> 26:46.120]  Ну, по идее, всем уже должно быть понятно, что оно вот такое.
[26:46.120 --> 26:54.120]  Я сейчас напишу, но если непонятно, что-нибудь обсудим, что будет непонятно.
[26:54.120 --> 26:58.120]  Я утверждаю, что оно такое.
[26:58.120 --> 27:07.120]  Вообще еще раз повторяю, мы ровно с такой формулой встречались при доказательстве теоремы Эрдеши.
[27:07.120 --> 27:13.120]  От тройки, потому что простые циклы в обыкновенном графе не могут иметь длину меньше трех.
[27:13.120 --> 27:19.120]  С и z по r, это мы фиксируем r-вершин цикла, потом фиксируем циклический порядок.
[27:19.120 --> 27:26.120]  И дальше считаем вероятность того, что все r-рёбер этого конкретного цикла присутствуют в графе.
[27:26.120 --> 27:29.120]  Нормэ, да? Ну хоры.
[27:29.120 --> 27:36.120]  Так, как и в прошлый раз, как и при доказательстве теоремы Эрдеши, оцениваем это довольно-таки тупо.
[27:36.120 --> 27:40.120]  А именно, здесь заменяем просто на r-факториал.
[27:40.120 --> 27:47.120]  С и z по r, это n в степени r, на r-факториал поделить, остается np-вертой.
[27:47.120 --> 27:58.120]  Но при доказательстве теоремы Эрдеши мы дальше сказали, что np-вертой меньше, чем np в степени равный верхнему пределу,
[27:58.120 --> 28:00.120]  и дальше умножили на этот верхний предел.
[28:00.120 --> 28:03.120]  Вот так здесь ни в коем случае делать нельзя.
[28:03.120 --> 28:09.120]  Потому что сейчас n, умноженное на p, это стремящаяся к нулю, увеличена.
[28:09.120 --> 28:14.120]  Тогда как в теории Эрдеши она была больше единицы.
[28:14.120 --> 28:19.120]  А раз она стремится к нулю, то наверху вовсе не максимум, а минимум.
[28:19.120 --> 28:22.120]  Поэтому вот здесь надо оценивать геометрической прогрессии.
[28:22.120 --> 28:25.120]  Ну просто считать геометрическую прогрессию.
[28:25.120 --> 28:32.120]  Ну поскольку я не люблю считать конечную геометрическую прогрессию, я таки оценю бесконечную.
[28:36.120 --> 28:38.120]  Вот так.
[28:38.120 --> 28:44.120]  Ну более короткая запись чуть-чуть получается, когда записываешь сумму бесконечной геометрической прогрессии.
[28:47.120 --> 28:50.120]  Но она начинается с p в кубе, поэтому вот так.
[28:50.120 --> 28:55.120]  p стремится к нулю, n, p стремится к нулю, но тут единицы, тут ноль. То есть все вместе это ноль.
[28:56.120 --> 29:02.120]  По неравенству Маркова, стало быть, с вероятностью стремяющейся к нулю в графе есть хотя бы один простой цикл.
[29:05.120 --> 29:11.120]  А симпатически почти наверное получается лес, у которого хроматическое число не больше.
[29:20.120 --> 29:43.120]  Но смотрите, вот этот первый случай и второй случай пересекаются, правда же?
[29:43.120 --> 29:48.120]  Потому что n, p стремится к нулю, это же не значит, что n², p не стремится к нулю.
[29:50.120 --> 29:59.120]  А вот что будет, как вы думаете, если n, p стремится к нулю, но n², p стремится к бесконечности?
[29:59.120 --> 30:04.120]  То есть мы рассматриваем дополнение в каком-то смысле до случая номер один.
[30:07.120 --> 30:11.120]  Ну если n, p стремится к нулю, мы знаем х и не больше двойки.
[30:11.120 --> 30:17.120]  А если при этом n², p стремится к бесконечности? Плюс, конечно, бесконечности.
[30:20.120 --> 30:26.120]  Ну очевидно, наверное, что должно быть. Наверное, в этом случае есть хотя бы одно ребро.
[30:29.120 --> 30:33.120]  Равно в точности два, да, потому что есть хотя бы одно ребро.
[30:33.120 --> 30:39.120]  А как это, кстати, доказать? Какой интересный вопрос.
[30:39.120 --> 30:43.120]  Задачка на экзамен или сейчас обсудить.
[30:43.120 --> 30:49.120]  Вот давайте я напишу. n², p стремится к бесконечности, но n, p по-прежнему стремится к нулю.
[30:49.120 --> 30:54.120]  Мы точно знаем, что асимпатически почти, наверное, это лес.
[30:54.120 --> 30:58.120]  Следовательно, х и не больше двойки.
[30:58.120 --> 31:01.120]  Но на сей раз n², p стремится к бесконечности.
[31:01.120 --> 31:09.120]  Хочется верить, что с высокой вероятностью, стремящейся к единице, случайный граф содержит хотя бы одно ребро.
[31:09.120 --> 31:14.120]  Хочется верить в это? А как это доказать?
[31:14.120 --> 31:19.120]  Ну, это легко доказать в данном-то случае.
[31:19.120 --> 31:25.120]  С какой вероятностью случайный граф содержит хотя бы одно ребро?
[31:25.120 --> 31:29.120]  Ну, или не содержит ребро.
[31:29.120 --> 31:34.120]  1-p по-прежнему в степени c и n².
[31:34.120 --> 31:38.120]  Ну и чего? Не получается ничего, да?
[31:44.120 --> 31:50.120]  Ну, знаете как, что вас должно смущать?
[31:50.120 --> 31:56.120]  Что 1-n², p теперь будет стремиться к минус бесконечности, да?
[31:56.120 --> 32:02.120]  Хреновая оценка, вот и все. Оценка плохая.
[32:02.120 --> 32:08.120]  Ну хорошо, а мат ожидания числа ребер. Хорошо, пусть х это число ребер в данном случае.
[32:08.120 --> 32:12.120]  Число просто ребер графа.
[32:12.120 --> 32:17.120]  Чему равняется мат ожидания числа ребер случайного графа? Это очевидный вопрос.
[32:17.120 --> 32:22.120]  Оно равняется, конечно, вот этому. В аккурат.
[32:22.120 --> 32:28.120]  c и n². Так, это все, надеюсь, понимают.
[32:28.120 --> 32:33.120]  Самый простой случай линейности.
[32:33.120 --> 32:37.120]  Конечно, среднее число ребер вот такое.
[32:37.120 --> 32:41.120]  И здесь, фактически, мы просто сказали, что оно стремится к нулю.
[32:41.120 --> 32:47.120]  Поэтому, а симпатически, почти наверно, ребер нет. Можно было не пользоваться неравенством Бернуля, а можно было написать неравенством Маркова.
[32:47.120 --> 32:50.120]  Это оно и было бы как раз. Неравенство Бернуля.
[32:50.120 --> 32:54.120]  Вот, но теперь у нас эта штука стремится к бесконечности.
[32:54.120 --> 32:58.120]  Вам ничего не напоминает?
[32:58.120 --> 33:06.120]  Первый пункт теоремы, второй пункт, который мы сегодня в начале лекции завершили доказывать.
[33:06.120 --> 33:09.120]  Наоборот, мы сейчас завершили доказывать этого первого пункта.
[33:09.120 --> 33:12.120]  А то был второй пункт, да?
[33:12.120 --> 33:15.120]  А я говорю загадками, вы все забыли за неделю.
[33:15.120 --> 33:18.120]  Ну еще раз, помните, была вот такая у нас теорема.
[33:18.120 --> 33:21.120]  p равняется c логариф men поделить на n.
[33:21.120 --> 33:24.120]  Была такая теорема. p равняется c логариф men поделить на n.
[33:24.120 --> 33:30.120]  c больше единицы, а симпатически, почти наверно, связан.
[33:30.120 --> 33:37.120]  c меньше единицы, а симпатически, почти наверно, есть изолированные вершины и, стало быть, не связан.
[33:37.120 --> 33:42.120]  Мы считали математическое ожидание числа изолированных вершин.
[33:42.120 --> 33:45.120]  И оно стремилось к плюс бесконечности.
[33:45.120 --> 33:50.120]  Но я говорил этого недостаточно для того, чтобы доказать, что хотя бы одна изолированная вершина есть.
[33:50.120 --> 33:53.120]  Нужно еще неравенство плотной концентрации.
[33:53.120 --> 33:58.120]  Причем самое простое, а именно Чебышовское.
[33:58.120 --> 34:02.120]  Я плохо выражаюсь, непонятно, да?
[34:02.120 --> 34:10.120]  Я очень хочу, чтобы народ прочувствовал, что происходит, а не только я формально доказывал какие-то теоремы, которые вы потом формально выучите.
[34:10.120 --> 34:17.120]  Вот когда я доказывал этот пункт теоремы про связанность, что связанности нет, потому что появляются изолированные вершины.
[34:17.120 --> 34:20.120]  Мы считали не только математическое ожидание.
[34:20.120 --> 34:24.120]  Здесь это было число изолированных вершин.
[34:24.120 --> 34:31.120]  Мы убеждались в том, что там это была величина вот такая, что эта штука стремится к плюс бесконечности,
[34:31.120 --> 34:34.120]  коль скоро мы находимся вот в этих условиях.
[34:34.120 --> 34:36.120]  Это мы делали, конечно.
[34:36.120 --> 34:40.120]  Но этого нам не хватило, и мы еще применяли неравенство Чебышова.
[34:40.120 --> 34:46.120]  А именно мы брали дисперсию х и делили ее на квадрат математического ожидания х.
[34:46.120 --> 34:48.120]  Можете это у себя найти?
[34:48.120 --> 34:50.120]  Видите такое, да?
[34:50.120 --> 34:55.120]  И я тогда специально подчеркну, нам не важно, что х это число изолированных вершин.
[34:55.120 --> 35:03.120]  Это неравенство верно для любой случайной величины, которая принимает неотрицательные целые значения.
[35:03.120 --> 35:05.120]  0, 1, 2 и так далее.
[35:05.120 --> 35:11.120]  Не важно, это число изолированных вершин, или это число ребер, или это число треугольников, что хотите.
[35:11.120 --> 35:19.120]  Если случайная величина такая, и вот эта штука стремится к нулю, а мат ожидания при этом стремится к бесконечности,
[35:19.120 --> 35:25.120]  тогда мы можем утверждать, что х как минимум единица с высокой вероятностью.
[35:25.120 --> 35:27.120]  Понятно?
[35:27.120 --> 35:34.120]  Вот это вот гарантирует нам, что вот эта вероятность стремится к единице.
[35:34.120 --> 35:37.120]  Это я фактически доказал на прошлой лекции.
[35:37.120 --> 35:45.120]  Поэтому фактически, если мы хотим доказать, что хроматическое число в точности равно двойке, они просто ее не превосходят,
[35:45.120 --> 35:51.120]  нам еще надо убедиться в том, что вот эта дробь стремится к нулю в случае, когда мы говорим про число ребер.
[35:51.120 --> 35:55.120]  Но, дорогие товарищи, чему равна дисперсия числа ребер?
[35:55.120 --> 36:00.120]  В случайном графе. У вас есть курс теории вероятностей.
[36:00.120 --> 36:07.120]  Вы там проходили биномиальные случайные величины?
[36:07.120 --> 36:10.120]  Проходили?
[36:10.120 --> 36:13.120]  Это те, у которых n и p, да?
[36:13.120 --> 36:17.120]  А что мат ожидания n умножить на p, вы помните?
[36:17.120 --> 36:24.120]  Ну, у нас n – это вот c из n подвала, потому что испытание не n, а c из n подвала, мы столько раз бросаем монетку.
[36:24.120 --> 36:29.120]  Значит, вы помните, что вот такое мат ожидания фактически – это вот оно прямо из курса теории вероятностей.
[36:29.120 --> 36:31.120]  Понятно, да?
[36:31.120 --> 36:35.120]  А дисперсия какая?
[36:35.120 --> 36:38.120]  Не могли не считать?
[36:38.120 --> 36:40.120]  Npq, да.
[36:40.120 --> 36:42.120]  Npq.
[36:42.120 --> 36:44.120]  Помните npq?
[36:44.120 --> 36:49.120]  Может, вам даже предельную теорему уже сформулировали была такая?
[36:49.120 --> 36:57.120]  Ну, где число успехов вычитает c и np, делится на корень из npq, и там что-то происходит.
[36:57.120 --> 36:59.120]  Было такое, нет?
[36:59.120 --> 37:02.120]  Вот, вот там np, корень из npq, корень из дисперсии.
[37:02.120 --> 37:11.120]  Дисперсия, значит, это просто c из n подва на p на 1-p, ну, на pq.
[37:11.120 --> 37:14.120]  Вот эта дисперсия, вы ее знаете.
[37:14.120 --> 37:17.120]  Потому что это просто в чистом виде схемы обернули, бросание монетки.
[37:17.120 --> 37:24.120]  c из n подва раз бросаем монетку, сколько раз монетка решкой кверху выпала, столько ребер и будет.
[37:24.120 --> 37:30.120]  Вот так и чего, если такую дисперсию поделить на квадрат математического ожидания?
[37:30.120 --> 37:40.120]  На квадрат математического ожидания.
[37:40.120 --> 37:45.120]  Так, 1-p куда будет стремиться?
[37:45.120 --> 37:49.120]  В нашем случае к единице.
[37:49.120 --> 38:04.120]  То есть это симпатически равно 1 поделить на c из n подва на p, а это мат ожидания, оно стремится к бесконечности.
[38:04.120 --> 38:10.120]  Это наше мат ожидания, и оно в нашей ситуации стремится к бесконечности.
[38:10.120 --> 38:15.120]  Значит, это стремится к нулю, и мы проверили, что действительно хотя бы одно ребро обязательно есть.
[38:16.120 --> 38:20.120]  Ну, не обязательно, а с вероятностью близко к единице.
[38:20.120 --> 38:26.120]  То есть вот в этой ситуации, если мы как бы существенно ограничились от первого случая,
[38:26.120 --> 38:32.120]  в этой ситуации, а симпатически почти наверное, х просто равняется двойке.
[38:32.120 --> 38:37.120]  В точности равняется, принимает опять же всего лишь одно значение.
[38:37.120 --> 38:43.120]  Из всего огромного множества возможностей оно предпочитает выбрать только двойку.
[38:43.120 --> 38:45.120]  Но одно ребро это тоже лес.
[38:51.120 --> 38:57.120]  Вот это случайная величина х. Количество ребров в случайном графе имеет биномиальное распределение, конечно.
[38:57.120 --> 39:06.120]  Это количество успехов в схеме из c из n подвого испытаний Бернули с вероятностью успеха p.
[39:06.120 --> 39:10.120]  Сколько раз монетка выпала решкой кверху, столько и будет у нас ребер.
[39:10.120 --> 39:17.120]  Мы из полного графа, в котором c из n подвого ребер, каждое ребро выбираем независимо от остальных с вероятностью p.
[39:17.120 --> 39:24.120]  Так что х, конечно, имеет биномиальное распределение, именно поэтому ее мат ожидания такое, а дисперсия такая.
[39:24.120 --> 39:29.120]  Я могу это пересчитать, но зачем, вы же это знаете.
[39:31.120 --> 39:36.120]  То есть на самом деле опять строго одно значение, очень высокая концентрация.
[39:36.120 --> 39:41.120]  Но в данном случае для доказательства этой концентрации хватает посчитать дисперсию.
[39:41.120 --> 39:44.120]  Я хочу, чтобы вы это все отразили у себя в сознании.
[39:44.120 --> 39:51.120]  Для доказательства концентрации в одном значении нам хватило посчитать дисперсию, теорему нельзя стирать.
[39:54.120 --> 39:57.120]  Слушайте, а у нас что, не было звонка, что ли?
[39:57.120 --> 40:04.120]  Давайте обсудим немножко вот эту теорему, которая выжила на доске, про гигантскую компоненту.
[40:04.120 --> 40:07.120]  А именно про случай c меньше единицы.
[40:07.120 --> 40:17.120]  Но для упрощения расчетов выкладок я буду считать, что даже не c меньше единицы, а c это функция, стремящаяся к нулю.
[40:19.120 --> 40:23.120]  Ну то есть мы находимся как бы в той ситуации, которую только что обсуждали.
[40:23.120 --> 40:25.120]  Давайте я ее еще раз выпишу.
[40:26.120 --> 40:35.120]  Мы находимся в ситуации, когда p равняется c поделить на n, и c стремится к нулю при n, стремящемся к бесконечности.
[40:35.120 --> 40:38.120]  Ну или что то же самое, pn стремится к нулю.
[40:38.120 --> 40:40.120]  Мы находимся в этой ситуации.
[40:40.120 --> 40:45.120]  Мы уже знаем, что все компоненты в этом случае являются деревьями.
[40:45.120 --> 40:48.120]  А симпатически, конечно, почти, наверное.
[40:48.120 --> 40:50.120]  Все компоненты деревьев.
[40:50.120 --> 41:02.120]  Вот это знание нам сейчас поможет достаточно легко доказать, что их размеры не более чем логарифмические,
[41:02.120 --> 41:05.120]  заодно при желании как-то оценить бету в зависимости от c.
[41:05.120 --> 41:08.120]  Ну c правда не константа, но все-таки оценить.
[41:08.120 --> 41:28.120]  Значит, с какой вероятностью каждая компонента имеет не менее чем бета логарифменвер?
[41:28.120 --> 41:34.120]  Не каждая. Не каждая. Виноват. Не каждая. Я же отрицание пишу сейчас.
[41:34.120 --> 41:40.120]  Неравенство в нужную сторону написал, а каждая неправильно. Не каждая, а существует.
[41:40.120 --> 41:48.120]  Существует компонента, имеет, плохо. Придется это тоже стереть.
[41:48.120 --> 41:53.120]  Я люблю русский язык. Ну имеющая, наверное, правильно.
[41:53.120 --> 41:59.120]  Существует компонента. А я вот так напишу такая, что сойдет.
[41:59.120 --> 42:01.120]  Тоже не совсем по-русски, но сойдет.
[42:01.120 --> 42:06.120]  Больше по-английски сойдет. Это больше по-английски. По-русски так нехорошо.
[42:06.120 --> 42:14.120]  Ну ладно. В общем, существует такая компонента, что в ней не меньше чем бета логарифменвершин.
[42:14.120 --> 42:17.120]  Я хочу доказать, что эта вероятность стремится к нулю.
[42:17.120 --> 42:26.120]  Тогда вероятность, которую я ошибочно начал писать, вот эта самая, что каждая компонента связанности имеет не больше, чем столько вершин,
[42:26.120 --> 42:29.120]  будет таки стремиться к единице. Все замечательно.
[42:29.120 --> 42:37.120]  Так я понятно выразился? Здесь утверждается, что каждая компонента имеет маленький размер, а симпатически почти наверное.
[42:37.120 --> 42:44.120]  А тут я хочу, наоборот, доказать, что а симпатически почти никогда найдется компонента, в которой много вершин.
[42:44.120 --> 42:50.120]  Но мы при этом уже знаем, что все компоненты, с вероятностью стремящиеся к единице, являются деревьями.
[42:50.120 --> 42:53.120]  Это мы знаем.
[42:54.120 --> 42:58.120]  Что-что? Об эту потом подгоним. Я так ее не помню.
[42:58.120 --> 43:03.120]  Как-нибудь. Тяп-ляп. Мы же ее оптимально считать не будем.
[43:03.120 --> 43:12.120]  Вероятность того, что нечто существует, очевидно, всегда оценивается сверху суммой вероятностей соответствующих событий.
[43:12.120 --> 43:17.120]  Потому что, как всегда, существование – это объединение вот этих событий.
[43:17.120 --> 43:21.120]  Мы уже с этим много раз сталкивались. Я считаю, что это понятно. Нет?
[43:21.120 --> 43:25.120]  Существует. Это значит, мы объединяем соответствующие события.
[43:28.120 --> 43:36.120]  Поэтому тут получается вот так. Сумма по к от бета логариф Мэн.
[43:36.120 --> 43:40.120]  Ну, тут можно целую часть нарисовать для красоты, но понятно, что это значит.
[43:40.120 --> 43:58.120]  Вероятность того, что существует древесная компонента.
[43:58.120 --> 44:01.120]  Древесная, но в смысле, что являющаяся деревом.
[44:01.120 --> 44:05.120]  Могу, конечно, подробнее написать. Существует древесная компонента на кавершинах.
[44:11.120 --> 44:18.120]  Древесная – это значит, что вот на этих кавершинах реализовано ровно какое-то конкретное дерево.
[44:18.120 --> 44:23.120]  Компонента целиком и полностью формирует дерево на кавершинах.
[44:23.120 --> 44:29.120]  Поэтому никаких других ребер там нету, но поскольку это компонента, то наружу тоже никакие ребра не идут.
[44:29.120 --> 44:34.120]  Понятно, почему я имею право написать, что она древесная.
[44:34.120 --> 44:43.120]  Мы доказали, что событие, состоящее в том, что в графе есть не древесная компонента, имеет вероятность стремящегося к нулю.
[44:43.120 --> 44:50.120]  Мы можем считать, что мы находимся в событии, которые имеют предельную вероятность 1,
[44:50.120 --> 44:53.120]  и в котором все графы состоят только из деревьев.
[44:53.120 --> 45:02.120]  Поэтому вероятность наличия большой компоненты – это вероятность наличия большой древесной компоненты, фактически, для этих графов.
[45:02.120 --> 45:15.120]  Ну и снова квантор существования мы оцениваем суммой пока от бета-лагориф-мэн до n.
[45:15.120 --> 45:20.120]  Ну до n можно не суммировать, вообще говоря, но это неважно.
[45:20.120 --> 45:26.120]  Где вот это почему не равенство?
[45:26.120 --> 45:33.120]  Ну потому что в одном и том же графе может существовать несколько разных компонентов.
[45:33.120 --> 45:39.120]  Поэтому те события, объединения которых здесь рассматривается, они пересекаются, конечно.
[45:39.120 --> 45:47.120]  Здесь объединяются события как множество графов, события это множество графов, в которых есть вот такие вот компоненты.
[45:53.120 --> 45:55.120]  Ну я же это вроде произнес.
[45:55.120 --> 46:06.120]  Ну еще раз, мы знаем, что у почти любого графа, вот в этом режиме, мы это доказали до звонка, у почти любого графа в этом режиме все компоненты являются деревьями.
[46:06.120 --> 46:13.120]  Вот я говорю, давайте рассмотрим просто множество тех графов, у которых все компоненты деревья.
[46:13.120 --> 46:16.120]  Просто вот рассмотрим такое множество.
[46:16.120 --> 46:19.120]  Ну если хотите, пересечем его вот с этим.
[46:19.120 --> 46:26.120]  Вероятность от этого в асимптотике не поменяется, потому что вы взяли какое-то событие, ну не знаю, назовем его A.
[46:26.120 --> 46:33.120]  Есть другое событие B, которое состоит из всех графов, имеющих своими компонентами, только деревья.
[46:33.120 --> 46:40.120]  Ну, вероятность B стремится к единице при N, стремящемся к бесконечности, если хотите BN.
[46:40.120 --> 46:43.120]  И здесь тоже AN.
[46:43.120 --> 46:52.120]  Ну значит, вероятность AN, пересеченного с BN, тоже стремится к единице.
[46:52.120 --> 46:56.120]  Если мы докажем, что нет, это неправильно.
[46:56.120 --> 47:04.120]  Сейчас, если мы докажем, что вот эта вот вероятность стремится к нулю, то из этого будет следовать, что вероятность AN тоже стремится к нулю.
[47:04.120 --> 47:07.120]  Если совсем подробно и формально.
[47:07.120 --> 47:17.120]  Ну можно формулу полной вероятности написать, ну конечно можно, но я как предполагал, что это понятно.
[47:17.120 --> 47:21.120]  О! Вроде бы действительно простое упражнение по теории вероятностей.
[47:21.120 --> 47:26.120]  Если у нас есть последовательности событий, вероятности которых стремятся к единице,
[47:26.120 --> 47:33.120]  то доказывать про какую-то другую последовательность событий, что вероятность этих событий стремится к нулю,
[47:33.120 --> 47:39.120]  равносильно тому, чтобы доказывать вот такую стремление к нулю.
[47:39.120 --> 47:44.120]  Ну можно написать и формулу полной вероятности и как угодно.
[47:44.120 --> 47:46.120]  Я не знаю. Понятно, нет?
[47:57.120 --> 48:01.120]  Хотите, чтобы я написал меньше или асимптотически равно? Ну давайте я так напишу.
[48:03.120 --> 48:08.120]  Да, это все про асимптотики. Да, если вот с учетом этого давайте я здесь напишу вот так.
[48:08.120 --> 48:15.120]  Согласен. Да, нет, это действительно хорошее замечание. Согласен.
[48:15.120 --> 48:18.120]  Ну как бы я здесь еще не делал этого пересечения, а здесь сделал.
[48:18.120 --> 48:22.120]  Формально действительно надо аккуратно написать. Спасибо. Да, это я согласен.
[48:22.120 --> 48:29.120]  Согласен. Да, это так. Немножко проглотил просто этот момент.
[48:29.120 --> 48:35.120]  Так, ну что, можем переходить дальше? Теперь понятно? Нет вопросов?
[48:35.120 --> 48:42.120]  Так, ну давайте переходить дальше. Здесь, наверное, все уже понятно будет без каких-то комментариев, но как хотите, спрашивайте, не жалко.
[48:42.120 --> 48:47.120]  Значит, c и z пока это количество способов зафиксировать вершины для компоненты.
[48:47.120 --> 48:53.120]  Дальше, выбрав эти k вершины, надо зафиксировать дерево. Это мы умеем делать.
[48:53.120 --> 48:58.120]  У нас с вами была формула Kelly. Видите, когда это начинает пригождаться.
[48:58.120 --> 49:05.120]  Значит, k в степени k минус 2. А дальше, ну что надо? Надо написать p в степени k минус 1.
[49:05.120 --> 49:12.120]  Это вероятность того, что k минус 1 ребро вот этого конкретного зафиксированного дерева есть в случайном графе.
[49:12.120 --> 49:20.120]  Ну а тут еще надо умножить на 1 минус p, потому что никаких других ребер быть не должно.
[49:20.120 --> 49:26.120]  Ну, никаких других ребер быть не должно. Сколько их?
[49:26.120 --> 49:32.120]  Их, во-первых, k умножить на n минус k, это те ребра, которые идут из компонента наружу.
[49:32.120 --> 49:35.120]  Ну, прям вот как в доказательской предыдущей теории.
[49:35.120 --> 49:40.120]  А еще будут, но это не очень важно, но я все-таки аккуратно напишу вот так.
[49:40.120 --> 49:49.120]  Это ребра, которых не хватает до полного графа на вот этих k вершинах, где реализовалось дерево как компонента.
[49:49.120 --> 49:55.120]  У вас на k вершинах реализовалось k минус 1 ребро, других ребер там быть не должно.
[49:55.120 --> 50:01.120]  У полного графа c искаподов ребер, и вот эти k минус 1 мы выкидываем, они как раз вот-вот они.
[50:10.120 --> 50:14.120]  Ну бяка какая-то получилась. Ну бяка оценивается.
[50:14.120 --> 50:19.120]  Давайте я напишу вот так. Это меньше, я сотру.
[50:19.120 --> 50:46.120]  Бета логарифм m до n. Тут n вкат, и поделить давайте на k-фактриал пока что, а то проглачу опять будет непонятно.
[50:46.120 --> 50:56.120]  К в степени k минус 2, здесь c вk минус 1 на n вk минус 1, потому что у нас p такое, p это c поделить на n.
[50:56.120 --> 51:04.120]  Так, и 1 минус c поделить на n. Давайте я все-таки вот на этот аккуратизм забью.
[51:04.120 --> 51:08.120]  1 минус p в этой степени оценю единицей просто тупо.
[51:08.120 --> 51:12.120]  Ну меньше единицы, конечно меньше. 1 минус p в такой степени.
[51:12.120 --> 51:16.120]  Я оставлю просто k на n минус k.
[51:16.120 --> 51:25.120]  Ну это оправдано, потому что даже если здесь вычитается k квадрат, то тут-то прибавляется только k квадрат пополам, он ничего не компенсирует.
[51:25.120 --> 51:30.120]  Поэтому забить на это это ничего особенно не потерять, не даст нам это ничего.
[51:30.120 --> 51:32.120]  Реально в выкладке это не поможет.
[51:32.120 --> 51:37.120]  А вот убирать это k не получится, потому что k может быть большим, вообще говоря.
[51:37.120 --> 51:40.120]  Поэтому приходится писать k на n минус k.
[51:40.120 --> 51:46.120]  Я же не могу сказать, что число меньше единицы в степени минус k квадрат меньше одного.
[51:46.120 --> 51:47.120]  Это неправда.
[51:47.120 --> 51:50.120]  Поэтому вот это минус k, оно играет некую существенную роль.
[51:50.120 --> 51:53.120]  Им пренебречь я не умею.
[51:53.120 --> 51:55.120]  А положительными слагаемыми, почему бы нет?
[51:55.120 --> 51:57.120]  Мне жалко.
[51:57.120 --> 51:59.120]  Так, ну что-то у нас тут сокращается.
[51:59.120 --> 52:01.120]  Смотрите, как хорошо.
[52:01.120 --> 52:03.120]  Одно n только выжило.
[52:03.120 --> 52:05.120]  Причем n оно же от k не зависит.
[52:05.120 --> 52:13.120]  Мы его можем вот сюда вытащить и дальше написать сумму по k от beta logarithm n до n.
[52:13.120 --> 52:18.120]  Так, давайте даже вот так напишем меньше либо равно.
[52:18.120 --> 52:22.120]  А воспользуемся мы вот таким неравенством.
[52:22.120 --> 52:26.120]  Мы его с вами обсуждали, по-моему, да?
[52:26.120 --> 52:30.120]  Было такое обсуждение в какой-то момент давно-давно?
[52:30.120 --> 52:32.120]  Ну, на самой первой лекции.
[52:32.120 --> 52:36.120]  На самой первой лекции, конечно, это просто по индукции доказывается.
[52:36.120 --> 52:38.120]  Это просто по индукции доказывается.
[52:38.120 --> 52:41.120]  Поэтому меньше либо равно, а k факториал у нас в знаменателе.
[52:41.120 --> 52:43.120]  То есть знак неравенства правильный.
[52:43.120 --> 52:49.120]  У нас остается k в степени k-2 от числа деревьев по формуле Kelly.
[52:49.120 --> 52:52.120]  Внизу остается k в степени k.
[52:52.120 --> 52:54.120]  Вот это k в степени k.
[52:54.120 --> 52:56.120]  А e вкатый прыгает наверх.
[52:56.120 --> 52:59.120]  Вот тут получается e вкатой степени.
[52:59.120 --> 53:04.120]  Вот тут получается c в k-1 степени.
[53:04.120 --> 53:08.120]  Ну и вот это вот произведение.
[53:08.120 --> 53:13.120]  Возведение в степени 1-c на n в степени k на n-k.
[53:13.120 --> 53:16.120]  Наверное, произведение я имел в виду то, которое в показателе.
[53:16.120 --> 53:18.120]  k на n-k.
[53:18.120 --> 53:20.120]  Так, ну ладно, это тоже очень неплохо.
[53:20.120 --> 53:23.120]  Смотрите, шлёп, шлёп.
[53:23.120 --> 53:25.120]  k квадрат отправилась в знаменатель.
[53:25.120 --> 53:28.120]  И вообще, я считаю, что оно отправляется в тартарары.
[53:28.120 --> 53:30.120]  Я настолько аккуратно считать не буду.
[53:30.120 --> 53:34.120]  То есть я сейчас скажу, что это всё меньше, чем n.
[53:34.120 --> 53:39.120]  На сумму по k от бета логариф men до n.
[53:39.120 --> 53:42.120]  И тут у меня будет...
[53:42.120 --> 53:44.120]  Ой-ой-ой.
[53:44.120 --> 53:48.120]  Давайте я вот одной ешечкой тут тоже пренебрегу.
[53:48.120 --> 53:50.120]  Потому что у меня же как квадрат в знаменателе.
[53:50.120 --> 53:51.120]  Ну что там?
[53:51.120 --> 53:53.120]  А k большое.
[53:53.120 --> 53:56.120]  Видите, тут вот e вкатый, а тут c вk-1.
[53:56.120 --> 53:58.120]  Как-то некрасиво.
[54:00.120 --> 54:02.120]  Или ладно.
[54:02.120 --> 54:04.120]  Интересный вопрос.
[54:04.120 --> 54:06.120]  Очень интересный.
[54:06.120 --> 54:08.120]  Пренебречь или нет.
[54:08.120 --> 54:10.120]  Ладно, давайте я вытащу е.
[54:10.120 --> 54:12.120]  Жалко что ли.
[54:12.120 --> 54:14.120]  От этого ничего не поменяется, конечно.
[54:14.120 --> 54:18.120]  Тут будет ce вкатый или в k-1.
[54:18.120 --> 54:22.120]  Это важно, потому что ce у нас стремится к нулю, но не очень существенно.
[54:22.120 --> 54:27.120]  Ну и на 1 минус c на n в степени k на n минус k.
[54:27.120 --> 54:32.120]  Вот довольно приятное уже выражение получилось в результате всех выкладок.
[54:32.120 --> 54:35.120]  Много всего посокращали.
[54:35.120 --> 54:41.120]  Но, честно говоря, я боюсь, что я поторопился.
[54:41.120 --> 54:42.120]  Что?
[54:42.120 --> 54:47.120]  Да.
[54:47.120 --> 54:50.120]  Но 1 на k квадрат меньше одного.
[54:50.120 --> 54:52.120]  Да, просто вот совсем тупо.
[54:52.120 --> 54:57.120]  Я только подумал, что может быть очень нехорошо, что я заранее тоже сумму на две части не разбил.
[54:57.120 --> 54:59.120]  Сейчас у меня может кое-что не получиться.
[54:59.120 --> 55:00.120]  Но сейчас вместе разберемся.
[55:00.120 --> 55:02.120]  Все будет хорошо.
[55:02.120 --> 55:04.120]  Да-да-да, может кое-что не получиться.
[55:04.120 --> 55:07.120]  Значит, давайте смотреть вот на эту часть.
[55:07.120 --> 55:10.120]  1 минус c на n в степени k на n минус k.
[55:10.120 --> 55:14.120]  Чуть-чуть я, наверное, поторопился, но я думаю, мы не запутаемся.
[55:14.120 --> 55:28.120]  Ну, смотрите, если k маленькое, ну как маленькое, даже меньшее, чем n пополам, вот пусть k не превосходит n пополам,
[55:28.120 --> 55:31.120]  то давайте это оценим так.
[55:31.120 --> 55:33.120]  Это меньше либо равно.
[55:33.120 --> 55:34.120]  Вот этот совмножитель.
[55:34.120 --> 55:36.120]  Он меньше либо равен чего?
[55:36.120 --> 55:42.120]  Если k не больше, чем n пополам, то со знаком минус получается не меньше, но чиселка меньше единицы возводится.
[55:42.120 --> 55:50.120]  Так что вот так пишем 1 минус c на n, k на n пополам.
[55:50.120 --> 55:58.120]  Это если k не превосходит n пополам, что будет в оставшейся части суммы.
[55:58.120 --> 56:00.120]  Это мы еще посмотрим.
[56:00.120 --> 56:03.120]  Значит, если k не превосходит n пополам, то получается вот так.
[56:03.120 --> 56:08.120]  Ну, а это не больше, чем е в степени минус c на n.
[56:08.120 --> 56:17.120]  Абсолютно стандартная уже много раз сегодня даже применявшаяся выкладка умножить на k и умножить на n пополам.
[56:17.120 --> 56:20.120]  Хлоп-хлоп.
[56:20.120 --> 56:24.120]  Узнаете эту выкладку, что 1 минус p не больше, чем е в степени минус p.
[56:24.120 --> 56:28.120]  1 минус c на n не больше, чем е в степени минус c на n.
[56:28.120 --> 56:34.120]  Вот, n-ка сократилась, осталось е в степени минус ck пополам.
[56:34.120 --> 56:37.120]  Все-таки мне лучше, наверное, писать так.
[56:37.120 --> 57:01.120]  Ага. Ну, тогда в этом случае ce в k минус 1 умноженное вот на эту хрень k на n-ка меньше либо равняется ce в k минус 1 на е в степени минус ck.
[57:04.120 --> 57:08.120]  Сейчас успеваете? Все нормально, вроде все просто очень.
[57:08.120 --> 57:15.120]  Ну, скучная немножко выкладка, простите, пожалуйста.
[57:15.120 --> 57:18.120]  Какая верхняя?
[57:18.120 --> 57:21.120]  Вот эта?
[57:21.120 --> 57:27.120]  Смотрите, видите, здесь n в степени k сократилось с n в k минус 1, остался вот это n.
[57:27.120 --> 57:31.120]  Дальше я переписываю все, учитывая вот эту оценку.
[57:31.120 --> 57:37.120]  И вот это умножить, оно отправляется вот сюда, просто не влезло вот в эту верхнюю строчку.
[57:37.120 --> 57:42.120]  Вот эта вот часть, она прыгнула сюда вниз немножко, все, дальше пошла выкладка.
[57:42.120 --> 57:46.120]  Что?
[57:46.120 --> 57:54.120]  Что мы забыли?
[57:54.120 --> 57:58.120]  Ой.
[57:58.120 --> 58:00.120]  А, это вот эта вот штука.
[58:00.120 --> 58:03.120]  Как забили? Конечно, забыли.
[58:03.120 --> 58:08.120]  Тут-то забыли, да, тут забыли, конечно. Да, ck пополам, извините.
[58:08.120 --> 58:11.120]  Так, сейчас все понятно, что на доске написано?
[58:11.120 --> 58:14.120]  Извините, ну вроде просто все.
[58:14.120 --> 58:17.120]  Да, немножко я может запутался где, но пока вроде нет.
[58:17.120 --> 58:20.120]  Ничего такого страшного.
[58:20.120 --> 58:24.120]  Пока не путался. Сейчас может запутался, но это скоро.
[58:24.120 --> 58:31.120]  А пока вроде не путался.
[58:31.120 --> 58:35.120]  Так. Такая история.
[58:35.120 --> 58:38.120]  Ох ты господи, так.
[58:38.120 --> 58:41.120]  Так.
[58:41.120 --> 58:44.120]  Управняется.
[58:44.120 --> 58:46.120]  Твуф ты господи.
[58:46.120 --> 58:49.120]  С
[58:49.120 --> 58:52.120]  е
[58:52.120 --> 58:55.120]  в степени 1, минус С пополам
[58:55.120 --> 59:00.120]  вкатый
[59:00.120 --> 59:03.120]  поделить на Се,
[59:03.120 --> 59:11.120]  и это все.
[59:11.120 --> 59:14.120]  Так, согласны с этим переходом?
[59:14.120 --> 59:17.120]  Ну, я просто представил Се вк, минус 1,
[59:17.120 --> 59:20.120]  как Се вк, поделить на Се.
[59:20.120 --> 59:23.120]  Вот оно поделить на Се, вот оно Се вк,
[59:23.120 --> 59:27.120]  а вот Е в степени минус Ск пополам, который мы чуть не потеряли.
[59:27.120 --> 59:30.120]  Но вы уловили вовремя. Это оно в точности.
[59:30.120 --> 59:34.120]  Это оно в точности. Ну, вспоминаем, что С у нас стремится к нулю.
[59:34.120 --> 59:39.120]  Поэтому вот это произведение, все, оно стремится к нулю.
[59:39.120 --> 59:44.120]  С, как функция от Н, стремится к нулю.
[59:44.120 --> 59:47.120]  Знаете?
[59:47.120 --> 59:50.120]  Ну, значит, 1 минус С пополам стремится к единице,
[59:50.120 --> 59:53.120]  то есть тут получается что-то очень близкое к Е,
[59:53.120 --> 59:56.120]  а тут что-то, стремящееся к нулю.
[59:56.120 --> 01:00:02.120]  То есть вот это стремится к нулю и возводится еще вкатую степень.
[01:00:02.120 --> 01:00:07.120]  Вот это примерно Се вкатый, а это Се.
[01:00:07.120 --> 01:00:13.120]  Ну, если хотите, наверное, можно было бы даже вернуть эту К минус первую, что ли, степень,
[01:00:13.120 --> 01:00:16.120]  а симптотику просто написать как-нибудь.
[01:00:16.120 --> 01:00:21.120]  Се вкатый, вот это вот, практически Се вкатый, а это Се.
[01:00:21.120 --> 01:00:25.120]  То есть это величина, которая очень быстро стремится к нулю.
[01:00:25.120 --> 01:00:31.120]  Ну, как геометрическое прогрессие, причем с убывающим знаменателем.
[01:00:31.120 --> 01:00:35.120]  Поэтому сумма от B, до логариф МН, до серединки, до N пополам,
[01:00:35.120 --> 01:00:41.120]  ну точно стремится к нулю по стандартным соображениям.
[01:00:41.120 --> 01:00:44.120]  Нужны какие-то подробности?
[01:00:44.120 --> 01:00:46.120]  Понятно?
[01:00:46.120 --> 01:00:52.120]  Но надо что-то сделать еще с серединкой, да.
[01:00:52.120 --> 01:00:57.120]  Делим, ну сейчас, давайте я напишу какую-нибудь оценку, чтобы не надо было делить.
[01:00:57.120 --> 01:01:04.120]  Давайте я, наоборот, под К минус первую, что ли, степень загоню все, чтобы все получилось.
[01:01:04.120 --> 01:01:08.120]  Давайте я, наоборот, напишу вот так, раз вас это все-таки смущает.
[01:01:08.120 --> 01:01:12.120]  Значит, вот будет К минус первая степень.
[01:01:12.120 --> 01:01:15.120]  Здесь у нас Се, вот здесь у нас Се.
[01:01:15.120 --> 01:01:17.120]  А что будет здесь?
[01:01:17.120 --> 01:01:24.120]  Будет Е в степени минус СК на два К минус один.
[01:01:24.120 --> 01:01:26.120]  Вот так вот, да?
[01:01:26.120 --> 01:01:31.120]  По-моему, так. То есть если наоборот, под К минус первую степень вот это все загнать,
[01:01:31.120 --> 01:01:35.120]  то здесь останется Се, а тут будет Е в степени вот такой вот.
[01:01:35.120 --> 01:01:40.120]  Но К у нас заведома растущая величина, потому что она не меньше, чем бета-логариф-мен.
[01:01:40.120 --> 01:01:44.120]  Поэтому вот эта вот дробь асимптатически равна единице.
[01:01:44.120 --> 01:01:48.120]  При Н, стремящемся к бесконечности, это примерно единичка.
[01:01:48.120 --> 01:01:52.120]  Можно написать какое-нибудь неравенство, начиная с достаточно большого Н.
[01:01:52.120 --> 01:01:55.120]  Но понятно, что это асимптатическая единичка.
[01:01:55.120 --> 01:02:01.120]  И вот мы получаем С умножить на Е в степени один минус С на один плюс о малой от единицы.
[01:02:01.120 --> 01:02:03.120]  Вот так, совсем аккуратно напишу.
[01:02:03.120 --> 01:02:10.120]  С на Е в степени один минус С, а пополам, да, С пополам, на один плюс о малой от единицы.
[01:02:10.120 --> 01:02:14.120]  Вот так вот. И это все в К минус первой степени.
[01:02:14.120 --> 01:02:16.120]  Ну какая разница, в КАТ и в К минус первой?
[01:02:16.120 --> 01:02:18.120]  Все равно геометрическая прогрессия.
[01:02:18.120 --> 01:02:22.120]  А эта штука по-прежнему стремится к нулю.
[01:02:22.120 --> 01:02:25.120]  Если так убедительнее, давайте я так скажу.
[01:02:25.120 --> 01:02:27.120]  Действительно, может, было меньше понятно.
[01:02:27.120 --> 01:02:29.120]  Давайте я так скажу.
[01:02:29.120 --> 01:02:35.120]  То есть покуда К не превосходит Н пополам, мы стандартным образом все можем оценить геометрической прогрессией.
[01:02:35.120 --> 01:02:37.120]  Все хорошо.
[01:02:37.120 --> 01:02:41.120]  Ну важно, что при...
[01:02:41.120 --> 01:02:44.120]  А, откуда бета-то посчитать?
[01:02:44.120 --> 01:02:47.120]  Вот что вы, наверное, не понимаете, откуда бета посчитать.
[01:02:47.120 --> 01:02:50.120]  Но у нас, каже, больше ли бы равно бета-лагориф-мена, то очень важно.
[01:02:50.120 --> 01:02:53.120]  Если бы К было маленькое, ничего бы не получилось.
[01:02:53.120 --> 01:02:55.120]  Смотрите, откуда бета посчитать.
[01:02:55.120 --> 01:02:58.120]  Мы подставляем сюда К вот такого вида.
[01:02:58.120 --> 01:03:02.120]  Здесь стоит что-то меньшее, чем любая наперед заданная константа.
[01:03:02.120 --> 01:03:04.120]  Ну хотите меньше одной-второй.
[01:03:04.120 --> 01:03:08.120]  И вот у вас написано одна-вторая в степени бета-лагориф-мена.
[01:03:08.120 --> 01:03:12.120]  И вам же нужно кокнуть вот это Н.
[01:03:12.120 --> 01:03:15.120]  Вот это Н-то надо кокнуть.
[01:03:15.120 --> 01:03:18.120]  Нам не просто нужно, чтобы сумма стремилась к нулю.
[01:03:18.120 --> 01:03:21.120]  А нам надо, чтобы она убивала вот это Н.
[01:03:21.120 --> 01:03:26.120]  То есть чтобы, например, вот это было с запасом меньше, чем 1 на N в квадрате.
[01:03:26.120 --> 01:03:29.120]  Вот подбираете такое бета, чтобы было выполнено это неравенство.
[01:03:29.120 --> 01:03:31.120]  Понятно, откуда лагориф-мен?
[01:03:31.120 --> 01:03:35.120]  Ради этого я старался. Если бы я сейчас это забыл, я был бы полный идиот.
[01:03:35.120 --> 01:03:39.120]  Какая-то дурацкая выкладка, всем понятная, но скучная.
[01:03:39.120 --> 01:03:43.120]  А смысл, именно откуда берется лагориф-мен в размере крошечной компоненты.
[01:03:43.120 --> 01:03:47.120]  Вот ровно отсюда, что суммирование начинается ровно с того момента,
[01:03:47.120 --> 01:03:51.120]  когда вот эта штука, которую мы оценили, по сути, экспоненты от K,
[01:03:51.120 --> 01:03:55.120]  действительно при подстановке этого момента становится меньше,
[01:03:55.120 --> 01:03:58.120]  чем любая наперед заданная отрицательная степень N,
[01:03:58.120 --> 01:04:00.120]  и с запасом вот это Н убивает.
[01:04:00.120 --> 01:04:03.120]  Но можно подобрать бета прямо на грани.
[01:04:03.120 --> 01:04:06.120]  И тут не одну вторую написать.
[01:04:06.120 --> 01:04:08.120]  Понятно, тут С стремится к нулю.
[01:04:08.120 --> 01:04:10.120]  Можно писать что-то поменьше.
[01:04:10.120 --> 01:04:12.120]  Но мы не знаем, как быстро С стремится к нулю.
[01:04:12.120 --> 01:04:15.120]  Оно может очень-очень медленно стремиться к нулю.
[01:04:15.120 --> 01:04:19.120]  Тогда одна вторая это не дурацкая оценка.
[01:04:19.120 --> 01:04:21.120]  Понятно?
[01:04:21.120 --> 01:04:24.120]  Откуда лагориф-мен, откуда бета.
[01:04:24.120 --> 01:04:27.120]  Вот, ну последнее, с чем осталось разобраться,
[01:04:27.120 --> 01:04:30.120]  это что делать, все-таки, если K больше, чем N пополам?
[01:04:30.120 --> 01:04:32.120]  Это-то почему маленькое?
[01:04:32.120 --> 01:04:35.120]  Это я, честно говоря, поторопился немножко.
[01:04:35.120 --> 01:04:39.120]  Вот в этом месте я действительно чуть-чуть неаккуратно рассказал,
[01:04:39.120 --> 01:04:43.120]  что надо делать, если K больше, чем N пополам.
[01:04:43.120 --> 01:04:48.120]  А вот здесь, когда K заменили на N пополам вот в этом месте.
[01:04:48.120 --> 01:04:52.120]  Это очень важно, потому что если мы сюда подставим K равное N,
[01:04:52.120 --> 01:04:56.120]  то вся вот эта штуковина превратится вообще в единицу,
[01:04:56.120 --> 01:04:58.120]  перестанет как-либо помогать.
[01:04:58.120 --> 01:05:00.120]  А она очень существенно помогает.
[01:05:00.120 --> 01:05:04.120]  Именно за счет этого становятся меньше единицы при больших N.
[01:05:04.120 --> 01:05:06.120]  То, что стоит в основании.
[01:05:06.120 --> 01:05:08.120]  Смеваетесь, товарищи?
[01:05:08.120 --> 01:05:11.120]  Понятно, что вот эта часть очень важна.
[01:05:11.120 --> 01:05:15.120]  Мы здесь очень по делу воспользовались тем, что K не превосходит N пополам.
[01:05:15.120 --> 01:05:20.120]  Ну ладно, давайте я проведу отдельно просто выкладку на самом-то деле.
[01:05:20.120 --> 01:05:26.120]  Настолько уже все маленькое становится дальше, что ничего страшного, что мы это теряем.
[01:05:26.120 --> 01:05:31.120]  Сейчас я отдельно проведу выкладку для K больше, чем N пополам.
[01:05:31.120 --> 01:05:38.120]  Ну, мы получили оценку для каждого слагаемого, но каждое последующее во столько раз больше, меньше вернее.
[01:05:38.120 --> 01:05:44.120]  То есть мы, как обычно, как сегодня уже делали, оцениваем суммой бесконечной геометрической прогрессии.
[01:05:44.120 --> 01:05:50.120]  Вся сумма – это первая слагаемая, которая меньше чем 1 на N квадрат
[01:05:50.120 --> 01:05:52.120]  и убивает к тем самым вот эту часть.
[01:05:52.120 --> 01:05:57.120]  Вся сумма – это первая слагаемая, которая меньше чем 1 на N квадрат
[01:05:57.120 --> 01:06:01.120]  и убивает к тем самым вот эту часть.
[01:06:01.120 --> 01:06:05.120]  Вся сумма – это вот это, вот это.
[01:06:05.120 --> 01:06:12.120]  И дальше в скобках 1 плюс вот это, плюс вот это в квадрате, плюс вот это в кубе.
[01:06:12.120 --> 01:06:14.120]  А это стремится к нулю.
[01:06:14.120 --> 01:06:16.120]  Ну это вот как было уже сегодня.
[01:06:16.120 --> 01:06:18.120]  Это Q от N, которое стремится к нулю.
[01:06:18.120 --> 01:06:24.120]  И мы оцениваем просто все вот этим умноженным на 1, плюс Q, плюс Q квадрат, плюс и так далее.
[01:06:24.120 --> 01:06:26.120]  Ну это 1 на 1 минус Q.
[01:06:26.120 --> 01:06:28.120]  И это стремится к единице.
[01:06:28.120 --> 01:06:30.120]  Это не влияет на всю сумму никак.
[01:06:30.120 --> 01:06:34.120]  Вся сумма симпатически равна своему первому слагаемому.
[01:06:34.120 --> 01:06:37.120]  Я это несколько раз проговорил, но на слух, наверное, трудно.
[01:06:37.120 --> 01:06:39.120]  Вот сейчас написал.
[01:06:39.120 --> 01:06:43.120]  Так, вернемся прямо к самому началу, наверное.
[01:06:43.120 --> 01:06:48.120]  Пусть теперь K больше чем N пополам.
[01:06:48.120 --> 01:06:54.120]  Тогда мы скажем, что C из N пока на K в степени K минус 2,
[01:06:54.120 --> 01:07:00.120]  на C в степени K минус 1, на N в K минус 1,
[01:07:00.120 --> 01:07:05.120]  на 1 минус P в какой-то степени.
[01:07:05.120 --> 01:07:09.120]  Так, наверное, вот так достаточно сказать.
[01:07:09.120 --> 01:07:16.120]  Меньше, чем 2 в степени N, на K в степени K минус 2,
[01:07:16.120 --> 01:07:22.120]  на N в K минус 1, на C в K минус 1.
[01:07:22.120 --> 01:07:29.120]  Так, я возвращаюсь прямо как бы к самому началу, вот к этому.
[01:07:29.120 --> 01:07:32.120]  И смотрю, что будет при K больше чем N пополам.
[01:07:32.120 --> 01:07:37.120]  Я говорю, что при K больше чем N пополам я не хочу заморачиваться вот такой оценкой C.
[01:07:37.120 --> 01:07:40.120]  А я скажу, что C из N пока меньше чем 2 в N.
[01:07:40.120 --> 01:07:44.120]  Тоже сегодня к такой истории прибегали, помните?
[01:07:44.120 --> 01:07:49.120]  Ну, меньше, чем 2 в N.
[01:07:49.120 --> 01:07:52.120]  Так, что?
[01:07:52.120 --> 01:07:54.120]  1 минус P мы забыли, да.
[01:07:54.120 --> 01:07:55.120]  Вообще забыли.
[01:07:55.120 --> 01:07:59.120]  Потому что K может равняться N.
[01:07:59.120 --> 01:08:04.120]  И тогда нам придется его забыть все равно.
[01:08:04.120 --> 01:08:08.120]  Я забыл его, да, забил на него все.
[01:08:08.120 --> 01:08:11.120]  Я не забыл его, я его сознательно забыл, забил.
[01:08:11.120 --> 01:08:13.120]  Все, нет его.
[01:08:13.120 --> 01:08:15.120]  Вот так осталось.
[01:08:15.120 --> 01:08:22.120]  Но, смотрите, что я теперь могу сказать.
[01:08:22.120 --> 01:08:25.120]  K у меня больше.
[01:08:25.120 --> 01:08:29.120]  Ой, сейчас, что-то я туплю, секунду.
[01:08:29.120 --> 01:08:31.120]  Вроде должно было все получиться.
[01:08:31.120 --> 01:08:33.120]  А, нет.
[01:08:33.120 --> 01:08:35.120]  Сейчас все получится.
[01:08:35.120 --> 01:08:38.120]  Сейчас все получится.
[01:08:38.120 --> 01:08:40.120]  О!
[01:08:40.120 --> 01:08:42.120]  Так, до сюда понятно?
[01:08:42.120 --> 01:08:44.120]  Сейчас, друзья, понятно?
[01:08:44.120 --> 01:08:47.120]  Очень грубая оценка вроде.
[01:08:47.120 --> 01:08:49.120]  Черт, замучил, да, не понимаете?
[01:08:49.120 --> 01:08:51.120]  Грубая оценка ведь, правда же?
[01:08:51.120 --> 01:08:55.120]  Теперь, смотрите, давайте вот в этом месте K вообще по-идиотски оценим.
[01:08:55.120 --> 01:08:57.120]  K меньше чем N.
[01:08:57.120 --> 01:09:00.120]  По-моему, сейчас этого хватит, смотрите.
[01:09:00.120 --> 01:09:07.120]  Меньше, чем 2 в N степени на N в N минус 2 поделить на N.
[01:09:07.120 --> 01:09:10.120]  А, нет.
[01:09:10.120 --> 01:09:13.120]  Нет, не так, не так.
[01:09:13.120 --> 01:09:16.120]  N в K минус 2, а здесь N в K минус 1.
[01:09:16.120 --> 01:09:21.120]  То есть вот эту K я оцениваю сверху N, а K минус 2 у меня остается вот так.
[01:09:21.120 --> 01:09:23.120]  Но это тоже правильно, конечно.
[01:09:23.120 --> 01:09:26.120]  Так, и на C в K минус 1, и все, и мы в героях.
[01:09:26.120 --> 01:09:34.120]  Это равняется 2 в степени N поделить на N умножить на C в K минус 1,
[01:09:34.120 --> 01:09:38.120]  где C меньше единицы и больше того стремится к нулю,
[01:09:38.120 --> 01:09:41.120]  а K у меня больше чем N пополам.
[01:09:41.120 --> 01:09:44.120]  То есть если хотите это меньше, чем 2 в степени N поделить на N,
[01:09:44.120 --> 01:09:47.120]  умножить на C в степени N пополам минус 1.
[01:09:47.120 --> 01:09:50.120]  Вот так.
[01:09:50.120 --> 01:09:53.120]  K больше чем N пополам, C меньше единицы,
[01:09:53.120 --> 01:09:57.120]  поэтому C в K минус 1 меньше, чем C в степени N пополам минус 1.
[01:09:57.120 --> 01:10:01.120]  Подставляем нижнюю оценку K, получаем верхнюю оценку экспоненты.
[01:10:01.120 --> 01:10:03.120]  Ну и все.
[01:10:03.120 --> 01:10:11.120]  Это меньше, чем 2 корня из C.
[01:10:11.120 --> 01:10:13.120]  Сейчас вы мне опять скажете, что я делю на C.
[01:10:13.120 --> 01:10:16.120]  Нет, трагедия просто.
[01:10:16.120 --> 01:10:20.120]  Придется, как вы любите, писать, чтобы трагедии не случилось.
[01:10:20.120 --> 01:10:22.120]  Ой, боже ты мой.
[01:10:22.120 --> 01:10:25.120]  Так, что делать?
[01:10:25.120 --> 01:10:29.120]  Так, это C в степени N минус 2 пополам,
[01:10:29.120 --> 01:10:32.120]  а это 4 на 2 в степени N минус 2.
[01:10:32.120 --> 01:10:37.120]  Вот давайте я так напишу, а то вы меня съедите.
[01:10:37.120 --> 01:10:40.120]  Все, N в знаменателе я пренебрег.
[01:10:40.120 --> 01:10:42.120]  Значит, это C в степени N минус 2 пополам,
[01:10:42.120 --> 01:10:44.120]  а это 2 в степени N минус 2 умножить на 4.
[01:10:44.120 --> 01:10:46.120]  Ой, как хорошо.
[01:10:46.120 --> 01:10:52.120]  4 на 2 корня из C в степени N минус 2.
[01:10:52.120 --> 01:10:57.120]  Я сумел все привести к приятному вам основанию экспоненты.
[01:10:57.120 --> 01:11:03.120]  Но 2 корня из C стремится к нулю, да еще в N степени.
[01:11:03.120 --> 01:11:05.120]  Таких слагаемых N пополам,
[01:11:05.120 --> 01:11:09.120]  это же я каждое слагаемое оценил, но таких слагаемых меньше, чем N,
[01:11:09.120 --> 01:11:12.120]  каждый из них вон, а как убывает,
[01:11:12.120 --> 01:11:16.120]  когда вы умножите на N, все равно будет убывать.
[01:11:16.120 --> 01:11:20.120]  То есть этот хвостик оценивается на тяп-ляп.
[01:11:20.120 --> 01:11:23.120]  Вы поняли, откуда Battle of Garry's Man?
[01:11:23.120 --> 01:11:27.120]  Но я сильно, товарищи, упростил нам с вами жизнь,
[01:11:27.120 --> 01:11:30.120]  все время предполагая, что C стремится к нулю.
[01:11:30.120 --> 01:11:34.120]  Все то же самое можно сделать с C строго меньшим единице,
[01:11:34.120 --> 01:11:36.120]  как и было заявлено в той теореме,
[01:11:36.120 --> 01:11:38.120]  но это сложнее технически.
[01:11:38.120 --> 01:11:41.120]  И то я вас замучил.
[01:11:41.120 --> 01:11:45.120]  Ладно, я не буду больше подробностей про это рассказывать.
[01:11:45.120 --> 01:11:47.120]  Хорошо, да?
[01:11:47.120 --> 01:11:50.120]  Так, последнее на сегодня, что я скажу,
[01:11:50.120 --> 01:11:53.120]  но тоже это будет таким продвинутым упражнением,
[01:11:53.120 --> 01:11:57.120]  хотите решайте, хотите нет, как кому интересно.
[01:11:57.120 --> 01:12:00.120]  Это третий пункт.
[01:12:00.120 --> 01:12:06.120]  Пусть теперь P, это C, поделить на N,
[01:12:06.120 --> 01:12:10.120]  и C строго меньше единицы, но уже не стремится к нулю.
[01:12:10.120 --> 01:12:13.120]  C не стремится к нулю.
[01:12:13.120 --> 01:12:15.120]  Вот давайте так считать.
[01:12:15.120 --> 01:12:18.120]  Я утверждаю, но не буду это доказывать,
[01:12:18.120 --> 01:12:22.120]  потому что это уже не стремится к нулю.
[01:12:22.120 --> 01:12:24.120]  Вот давайте так считать.
[01:12:24.120 --> 01:12:27.120]  Я утверждаю, но не буду это доказывать,
[01:12:27.120 --> 01:12:29.120]  потому что опять будут противные выкладки,
[01:12:29.120 --> 01:12:31.120]  вам станет грустно, скучно, не хочу.
[01:12:31.120 --> 01:12:33.120]  Я хочу красивые вещи рассказывать,
[01:12:33.120 --> 01:12:35.120]  чтобы вас не кокало.
[01:12:35.120 --> 01:12:38.120]  Но я утверждаю, что в этом случае жизнь устроена так.
[01:12:38.120 --> 01:12:41.120]  А симптатически почти, наверное,
[01:12:41.120 --> 01:12:47.120]  все компоненты случайного графа
[01:12:47.120 --> 01:12:52.120]  являются деревьями
[01:12:52.120 --> 01:12:57.120]  или унициклическими графами.
[01:12:57.120 --> 01:13:00.120]  Не зря их тоже изучали.
[01:13:00.120 --> 01:13:03.120]  Другое дело, что я уж не буду подставлять
[01:13:03.120 --> 01:13:06.120]  эти корень из P на 8 куда-то в страшную выкладку,
[01:13:06.120 --> 01:13:09.120]  но вы можете, если захотите,
[01:13:09.120 --> 01:13:11.120]  или унициклическими.
[01:13:11.120 --> 01:13:15.120]  То есть, а симптатически почти, наверное,
[01:13:15.120 --> 01:13:19.120]  хроматическое число не превосходит тройке,
[01:13:19.120 --> 01:13:21.120]  потому что если граф дерева,
[01:13:21.120 --> 01:13:23.120]  то он красится в два цвета,
[01:13:23.120 --> 01:13:25.120]  а если граф содержит только один цикл,
[01:13:25.120 --> 01:13:27.120]  то он, очевидно, красится в три цвета.
[01:13:27.120 --> 01:13:29.120]  Очевидно это?
[01:13:29.120 --> 01:13:31.120]  Цикл-то красится в три цвета, а он только один.
[01:13:31.120 --> 01:13:33.120]  Поэтому весь граф тоже красится в три цвета.
[01:13:33.120 --> 01:13:35.120]  И можно доказать,
[01:13:35.120 --> 01:13:37.120]  больше того, более того,
[01:13:37.120 --> 01:13:39.120]  если C не стремится к нулю,
[01:13:39.120 --> 01:13:45.120]  более того, а симптатически почти, наверное,
[01:13:45.120 --> 01:13:47.120]  это опять надо дисперсию считать,
[01:13:47.120 --> 01:13:49.120]  циклы есть,
[01:13:51.120 --> 01:13:53.120]  и даже есть нечетные циклы.
[01:13:55.120 --> 01:13:57.120]  Надо просто посчитать отношение дисперсии
[01:13:57.120 --> 01:13:59.120]  к квадратума от ожидания числа
[01:13:59.120 --> 01:14:01.120]  вот этих самых нечетных циклов.
[01:14:01.120 --> 01:14:03.120]  И даже есть нечетные циклы.
[01:14:03.120 --> 01:14:05.120]  А симптатически почти, наверное,
[01:14:05.120 --> 01:14:09.120]  хроматическое число равняется тройке в точности,
[01:14:09.120 --> 01:14:11.120]  то есть опять высочайшая плотность концентрации
[01:14:11.120 --> 01:14:13.120]  хроматического числа.
[01:14:13.120 --> 01:14:15.120]  Но это без доказательств.
[01:14:15.120 --> 01:14:17.120]  Я сказал, что произойдет.
[01:14:17.120 --> 01:14:19.120]  В принципе, у нас все подсчеты,
[01:14:19.120 --> 01:14:21.120]  которые ведут к выкладкам,
[01:14:21.120 --> 01:14:23.120]  дающим этот результат, есть.
[01:14:23.120 --> 01:14:25.120]  Ну, захотите попробуйте,
[01:14:25.120 --> 01:14:27.120]  попробуйте,
[01:14:27.120 --> 01:14:29.120]  попробуйте,
[01:14:29.120 --> 01:14:31.120]  попробуйте,
[01:14:31.120 --> 01:14:33.120]  ну, захотите, попробуйте,
[01:14:33.120 --> 01:14:35.120]  проверить, не интересно, забейте,
[01:14:35.120 --> 01:14:37.120]  я не буду мучать.
[01:14:37.120 --> 01:14:39.120]  Понятно?
[01:14:39.120 --> 01:14:41.120]  Но это не самое красивое.
[01:14:41.120 --> 01:14:43.120]  Самое красивое будет в следующий раз.
