[00:00.000 --> 00:09.360]  Мы продолжаем говорить про кучи. Сейчас поговорим про биномиальную кучу, которая
[00:09.360 --> 00:16.400]  умеет чуть больше, чем бинарная. Но сначала одна интересная задачка, которую можно решать и даже
[00:16.400 --> 00:25.480]  в бинарной куче. Значит, задача такая. По факту, в дополнение ко всем четырем стандартным запросам
[00:25.480 --> 00:35.760]  кучи insert, get-min, extract-min и что-то еще дикрестки, можно добавить запрос erase. Erase x. Запрос
[00:35.760 --> 00:44.800]  очень простой. Удалить x из кучи. Но давайте мы наложим обязательства, что этот x обязательно
[00:44.800 --> 00:53.400]  в куче присутствует. x был в куче. То есть мы не будем просить от структуры удалить те элементы,
[00:53.400 --> 00:58.000]  которые в нем, которые в ней отсутствуют. Давайте такую договоренность сделаем. Ну, вроде логично.
[00:58.000 --> 01:04.960]  Значит, тут есть два случая. По указателю, по значению. Первый довольно простой.
[01:04.960 --> 01:15.600]  Значит, представьте себе, что x задается не значением, как число там 120, а указателем на какую-то
[01:15.600 --> 01:21.200]  вершину кучи. То есть вот есть у вас куча, которая на самом деле в виде массива представлена,
[01:21.200 --> 01:28.920]  и вам говорят не x, а какое-то аи. Вам говорят, что вот в этой вершине аи лежит то самое число,
[01:28.920 --> 01:33.920]  которое мне нужно удалить. Пожалуйста, удали его. Скажите, пожалуйста, как используя все те операции,
[01:33.920 --> 01:48.200]  которые мы уже знаем, как можно число удалить? Вот так будет супер. Спасибо. Мы скажем,
[01:48.760 --> 01:51.640]  что аи равно минус бесконечность, где минус бесконечность это такое число,
[01:51.640 --> 01:56.800]  которое заведомо меньше всех элементов кучи. Затем мы поднимем ее с помощью сфтапа.
[01:56.800 --> 02:06.720]  тогда оно обязательно всплывет в корень кучи. Если я положил сюда минус бесконечность и поднимаю
[02:06.720 --> 02:10.360]  ее с помощью сфтапа, то, поскольку минус бесконечность самое маленькое число в куче,
[02:10.360 --> 02:14.120]  оно обязательно поднимется в корень. Ну, а корень, я удалять умею, это экстракт мин.
[02:14.120 --> 02:24.680]  экстракт-мин удаляет корень дерева, то есть элемент является минимальным, в нашем случае это
[02:24.680 --> 02:29.800]  всегда корень, поэтому он эту минус бесконечность как раз и удалит. Вот, добились того, чего хотели.
[02:29.800 --> 02:36.680]  Но это, повторю, все в случае только если у меня дается указатель. Мне дается не только число x,
[02:36.680 --> 02:42.360]  но и кто-то мне тыкает в кучу и говорит, вот этот x вот тут вот лежит, вот его удали, пожалуйста.
[02:42.360 --> 02:47.920]  Не просто какое-то там число 120, которое где-то в куче лежит, а вот оно, вот я прям показываю,
[02:47.920 --> 02:54.040]  вот его индекс и вот его удали. Другое дело, когда меня просят именно по значению удалить.
[02:54.040 --> 03:02.160]  Когда мне не сообщают индекс, где в куче это число лежит, а просто говорят, вот есть где-то у тебя x в
[03:02.160 --> 03:09.080]  куче, удали его, пожалуйста. Где он конкретно лежит, мне не говорят. Здесь мы опять встречаемся с
[03:09.080 --> 03:14.680]  проблемой, что мне нужно в каком-то смысле найти элемент по значению в нашей структуре данных. Мы
[03:14.680 --> 03:20.280]  это видели, когда писали односвязанные списки. По значению искать в списке как-то не очень понятно.
[03:20.280 --> 03:24.280]  Нужно пройти все элементы, в худшем случае проверить на равенстве x. То же самое в куче.
[03:24.280 --> 03:29.600]  Если я вам говорю x, то проверить его наличие или найти, как-то его локализовать внутри кучи не очень
[03:29.600 --> 03:34.960]  понятно как. Потому что все, что вы знаете, это что при спуске вниз у вас что увеличивается. Ну понятно,
[03:34.960 --> 03:40.240]  можно до каких-то пор спускаться вниз, но непонятно даже, куда раздваиваться, идти влево или вправо,
[03:40.240 --> 03:44.600]  потому что из слева больше элементов, из права больше элементов, где x непонятно. В худшем случае
[03:44.600 --> 03:49.600]  опять-таки вам пришлось бы всю кучу обходить. Это бред, мы не хотим делать операции, которые работают
[03:49.600 --> 03:56.040]  за линейное время, это слишком долго. Вместо этого давайте заведем дополнительную кучу удаленных
[03:56.040 --> 04:07.040]  элементов. У меня будет две кучи. В одной куче a я буду хранить те элементы, которые туда добавляются,
[04:07.040 --> 04:23.440]  добавленные элементы, а в куче d просто удаленные. И тогда для обработки запроса erase x я всего лишь
[04:23.600 --> 04:32.840]  добавлю x в кучу d. Просто сделаю d insert x. Я вставлю число x в множество удаленных, в кучу удаленных.
[04:32.840 --> 04:44.200]  Такое странное действие. Я в каком-то смысле пометил x удаленным, поместил его в кучу удаленных.
[04:44.200 --> 04:50.240]  Что делать дальше? Ну смотрите, вообще говоря, мы можем в каком-то смысле продолжать спокойно
[04:50.240 --> 04:55.440]  работать с кучей a. Если меня просят найти минимум в куче или что-нибудь в нее добавить или удалить
[04:55.440 --> 05:01.680]  минимум, то обычно куча d на нее не влияет. Например, если x было не самым маленьким числом в куче,
[05:01.680 --> 05:07.160]  то, например, get min и extract min в a будут работать точно так же, как если бы x не удалялся. А я
[05:07.160 --> 05:13.400]  там какое-то число удалил, далеко не минимальное, тогда минимум остается в a таким же, как был.
[05:13.400 --> 05:19.280]  То есть, вообще говоря, куча a не сильно от этого изменяется. Но, конечно, если, скажем, x это
[05:19.280 --> 05:24.080]  минимальное число, то нужно что-то сделать. Нужно его из кучи, наверное, извлечь. Поэтому давайте
[05:24.080 --> 05:30.320]  сделаем следующее. Каждый раз, когда приходит какой-то запрос изменения кучи a, get min или
[05:30.320 --> 05:45.960]  extract min, давайте напишу при обработке запроса get min или extract min, мы запустим следующую процедуру.
[05:46.280 --> 05:57.200]  А именно, мы будем удалять минимальные элементы из a и из d, пока они одинаковы. Пока a.get min
[05:57.200 --> 06:06.800]  равно d.get min, я пишу на псевдокоде, на самом деле здесь равно-равно в большинстве языков,
[06:06.800 --> 06:13.920]  но мне лень, я пишу просто равно. Пока у них равны минимумы, я их оба извлекаю. a.extract min
[06:13.920 --> 06:16.880]  и d.extract min.
[06:26.520 --> 06:30.640]  Смотрите, по крайней мере, если у них совпадают минимальные элементы, значит, я в какой-то момент
[06:30.640 --> 06:37.080]  этот x добавил в a, потом говорю удали его из кучи, но я его добавляю в d, но на самом деле его
[06:37.080 --> 06:41.240]  нужно удалить и оттуда и оттуда, потому что это тот элемент, который я добавил, но его нужно удалить.
[06:41.240 --> 06:46.240]  И вот я вижу, ага, минимальный элемент в a и в d одинаковый, значит, я его когда-то добавил,
[06:46.240 --> 06:50.420]  потом удалил. Ну, значит, давайте его отовсюду удалим, то есть мы увидели, что они совпадают,
[06:50.420 --> 06:57.560]  удалили их из обеих куч. Тем самым, учли его удаление. В момент, когда у них минимумы не равны,
[06:57.560 --> 07:03.520]  я понимаю, что в a лежит правильный минимум. То есть, в момент, когда они не равны, значит,
[07:03.520 --> 07:08.640]  здесь минимум меньше, чем здесь, в куче a меньше, чем в куче d, значит, в a лежит минимум, который мы
[07:08.640 --> 07:14.200]  еще не удаляли. Значит, его и надо вывести. Иллюстрируется следующей простой картинкой.
[07:14.200 --> 07:24.920]  Давайте я нарисую числовую ось. Давайте засечками я поставлю элементы а, а крестиками обозначу те из
[07:24.920 --> 07:30.120]  их, которые удалялись. Вот это удалил, вот это удалил, вот это удалил, этот не стал удалять,
[07:30.120 --> 07:36.760]  этот не стал удалять, удалил вот этот. То есть в куче d лежат крестики, в куче а лежат засечки.
[07:36.760 --> 07:44.640]  Ну тогда понятно, как извлечь минимум из кучи а. Мне нужно пока минимум в обеих кучах совпадают,
[07:44.640 --> 07:50.320]  удалить, удалить, удалить. Вот это впервые минимум в а, отличный от минимума в d. Они уже не
[07:50.320 --> 07:55.060]  совпадают, это значит, что этот минимум когда-то добавлен, но еще не удален. Значит, он на самом
[07:55.060 --> 08:04.940]  деле настоящий минимум. Здесь в принципе не обязательно, главное, что если вы какой-то x несколько
[08:04.940 --> 08:10.340]  раз добавляете, то он в куче несколько раз учтен. Например, если вы x дважды добавили в а и всего один
[08:10.340 --> 08:14.940]  раз в d, то у вас будет две засечки и один крестик. Одна засечка уничтожится с одним крестиком,
[08:14.940 --> 08:25.780]  останется одна засечка. Ничего страшного с тем, что дублируете. Именно севтап, я его в корень
[08:25.780 --> 08:36.540]  поднимаю, потом удаляю. А как мы два раза удалим элемент, я не понял.
[08:36.540 --> 09:00.140]  Так, извините, два вопроса, давайте вы сначала. Еще раз, я считаю, что мои запросы правильные,
[09:00.140 --> 09:06.020]  что не бывает такого, что я удаляю несуществующие элементы. Иначе это все не работает. Справедливое
[09:06.020 --> 09:10.700]  замечание, смотрите, если меня попросили удалить, например, даже вот так вот, если меня попросили
[09:10.700 --> 09:16.060]  удалить вот этот элемент, которого в куче нет, тогда его в d добавлю и никогда его из d не удалю.
[09:16.060 --> 09:20.220]  Буду всегда считать, что это минимум и вообще у меня все сломается. Так вот, я хочу, чтобы такого
[09:20.220 --> 09:27.420]  не было. Я считаю, что все мои запросы корректные. И более формально, d всегда под множество a. Множество
[09:27.420 --> 09:35.060]  удаленных всегда под множество добавленных. Теперь ваш вопрос. Нет, хорошо. Почему что?
[09:35.060 --> 09:46.940]  Не будет ломать чего? Смотрите, сифтап я запускаю только в декрестки, правильно? Ну что меняется
[09:46.940 --> 09:53.900]  от декрестки? Смотрите, в куче декрестки я не запускаю. Может быть такое, что меня просят запустить
[09:53.900 --> 09:59.580]  декрестки от удаленного элемента. Но это опять бред. Это некорректный запрос. То есть я считаю,
[09:59.580 --> 10:03.860]  что все мои запросы, я явно не формулирую, но я считаю, что запросы корректные. У меня не удаляются
[10:03.860 --> 10:08.140]  недобавленные элементы. У меня не уменьшаются удаленные элементы. То есть я не делаю чего-то
[10:08.140 --> 10:13.340]  незаконного. Тогда что значит декрестки? Декрестки может прийти либо сюда, к элементу, который не
[10:13.340 --> 10:19.300]  удален, и на самом деле лежит в «а, ну окей, я вам переместить куда-то сюда». Ничего страшного. А декрестки
[10:19.300 --> 10:23.700]  к элементу, который уже удален, я запрещаю просто. Но это неправильный запрос. Не может быть такого,
[10:23.700 --> 10:26.740]  что вы сначала удалили, потом уменьшили. Это бред. Я такое запрещаю. Да.
[10:26.740 --> 10:39.100]  Просто две кучи есть. В первую я добавляю все элементы, которые приходят на insert,
[10:39.100 --> 10:44.380]  во вторую добавляю все, которые приходят на erase. То есть когда меня просят сделать erase x,
[10:44.380 --> 10:49.420]  я делаю insert x в кучу d. У меня есть две кучи. В одну добавляю, во вторую тоже добавляю. Потом,
[10:49.420 --> 11:03.020]  пока в них минимумы одинаковые, я оба минимума извлекаю. Ну как? Это две кучи. У них есть
[11:03.020 --> 11:12.660]  процедура getmin. Пока они одинаковые, я их оба извлекаю. Вот картинка. Засечка это элементы
[11:13.620 --> 11:20.480]  д. Это удаленные элементы. Первые несколько элементов a на самом деле удалены. Это как раз вот
[11:20.480 --> 11:24.620]  пока засечка совпадает с крестиком, пока минимальный добавлент совпадает с минимальным
[11:24.620 --> 11:29.200]  удаленным, я их стираю. Вот этот я вижу добавлен и удален. ОК, забыли про него,
[11:29.200 --> 11:33.340]  потому что он удален. Этот добавлен и удалён, забыл. Этот забыл. А дальше
[11:33.340 --> 11:37.700]  я вижу элемент, который добавлен, но не удалён. То есть не верно, что минимум в а, равен
[11:37.700 --> 11:44.140]  д, значит был добавлен какой-то элемент, который сейчас минимален, но при этом не удален. Значит,
[11:44.140 --> 12:05.020]  он и есть минимум. Справедливо, ну как есть. Ну что значит у отн? У меня все равно, если как бы в два
[12:05.020 --> 12:09.420]  раза больше памяти. Ну типа, ну ладно. Ну не очень хорошо, но по-другому не получается, по крайней мере.
[12:09.420 --> 12:18.420]  Когда еще придется ставить дополнительную проверку во всех функциях кучи a, что этого элемента нет в куче d, это же еще дополнительные действия.
[12:18.420 --> 12:23.660]  Нет, нет, нет, я нигде не проверяю отсутствие элементов в куче d, я делаю ровно вот это. У меня в коде больше ничего нет.
[12:23.660 --> 12:30.500]  Ну тогда вы же по-настоящему не удаляете. Конечно, я не говорю, что я удаляю, я делаю так, что я отвечаю на все запросы правильно.
[12:30.500 --> 12:38.660]  Так, хорошо, смотрите, вот такую задачку мы поняли, как решать. Просто поддерживаем кучу удаленных.
[12:38.660 --> 12:44.980]  Окей, теперь давайте перейдем к еще одной реализации кучи, называется биномиальная куча,
[12:44.980 --> 12:57.220]  которая умеет делать все то же, что бинарная, но еще чуть больше. А именно, она умеет делать,
[12:57.220 --> 13:14.100]  конечно, insert, get min, extract min, decrease key и новая процедура merge, процедура слияния двух куч.
[13:14.100 --> 13:24.940]  Слияние двух куч. Что это значит? Представьте себе, что у вас были независимые какие-то две кучи,
[13:24.940 --> 13:31.260]  одна-вторая. Вы хотите создать новую структуру данных, которая равна их объединению в каком-то смысле.
[13:31.260 --> 13:36.700]  Вот все элементы, которые валялись здесь или здесь, вы хотите все слить в одну кучу, построить одну
[13:36.700 --> 13:42.180]  новую большую кучу. Вот это merge. Есть элементы в одной, в другой вы хотите их все объединить в одну
[13:42.180 --> 13:51.780]  большую. Это merge, склеивание двух куч. Давайте подумаем, например, про бинарную кучу. Почему тут
[13:51.780 --> 14:01.020]  непонятно как делать? Потому что непонятно. Лучшее, что приходит на ум, это взять все элементы одной
[14:01.020 --> 14:05.700]  кучи и итеративно по одному заинсертировать в другую. Берем первый элемент, добавляем, второй
[14:05.700 --> 14:10.620]  добавляем через insert, третий, четвертый и так далее. Как-то долговато. Лучше вроде ничего не
[14:10.620 --> 14:15.700]  придумывается. Если у вас есть две бинарные кучи как массивы, можно их состыковать, запустить
[14:15.700 --> 14:20.460]  hipify, построить кучу, но это опять линия, опять не очень быстро. На бинарной куче это вроде не
[14:20.460 --> 14:26.620]  получается. Давайте разберемся с биномиальной, в ней это быстренько получится сделать. Итак,
[14:26.620 --> 14:38.900]  значит, определение. Давайте начнем с биномиального дерева ранга K. Биномиальное дерево ранга K.
[14:38.900 --> 14:56.180]  Я буду обозначать его через tk. Значит, t0 это просто вершина. Одна вершина без детей. t1 это вершина
[14:56.180 --> 15:10.620]  с одним сыном. t2 это следующая картинка. И так далее. В общем виде верно следующее,
[15:10.620 --> 15:18.620]  что дерево следующего ранга K плюс 1 получается подвешиванием одного дерева ранга tk в качестве
[15:18.620 --> 15:25.900]  сына к корню другого дерева ранга tk. Чтобы получить дерево K плюс 1 ранга, я беру два
[15:25.900 --> 15:31.580]  дерева одинакового предыдущего ранга tk и подвешиваю одно из них к другому в качестве сына,
[15:31.580 --> 15:37.180]  получаю тем самым дерево ранга K плюс 1. Ровно так у меня построены вот эти вот два первых дерева.
[15:37.180 --> 15:45.300]  Как получить t1? Я беру t0 и t0 соединяю их ребром. Как получить t2? Я беру t1 и t1 соединяю их ребром,
[15:45.300 --> 15:49.780]  получается t2. В общем случае конструкция такая. Беру два дерева предыдущего ранга, склеиваю
[15:49.780 --> 16:03.380]  ребром. Значит также в вершинах дерева расположены числа, давайте напишу расположены элементы,
[16:03.380 --> 16:10.300]  и они должны удовлетворять требованию кучи. То есть как обычно, что значение в вершине меньше
[16:10.300 --> 16:20.300]  либо равно, чем все, что находится его по дереву. Они должны удовлетворять требованию кучи.
[16:20.300 --> 16:34.900]  Давайте нарисую какой-нибудь пример t3. Так, ну я должен справиться. Так, вот оно. Нет сейчас,
[16:34.900 --> 16:48.180]  бред. Кажется это корректное t3, потому что вот t2 и вот еще t2 соединил ребром. В вершинах
[16:48.180 --> 16:54.620]  расположены какие-то числа. Такие, что числа ниже больше, чем число в вершине. Тогда как
[16:54.620 --> 16:57.980]  обычно у меня минимум будет в корне. Например, давайте скажем, что здесь какое-нибудь число 3.
[16:57.980 --> 17:09.820]  Здесь будут какие-нибудь 4, 8 и 20. Здесь пусть будет 10, здесь там 25 и 23. Например так. Это будет
[17:09.820 --> 17:16.300]  корректное биномальное дерево ранга 3. Структура у него жестко фиксирована, то есть какие вершины
[17:16.300 --> 17:20.420]  являются новьями кого, строго софиксировано по вот этому определению, что я подвешиваю дерево
[17:20.420 --> 17:27.060]  предыдущего ранга к себе же. Ну а числа какие-то, главное чтобы опять вершина, число в вершине
[17:27.060 --> 17:33.420]  меньше, чем все, что в поддерега. Тройка меньше, чем все вот эти вот. 8 меньше, чем 10. 20 меньше, чем 25-23.
[17:33.420 --> 17:42.420]  Дурак, потому что наверное. А, да, извините. Давайте вот так вот сделаю быстренько. Да,
[17:42.420 --> 17:47.300]  спасибо. Склеились у меня. Там две вершины, там разные числа какие-то. Спасибо.
[17:47.300 --> 18:02.220]  Вот это биномиальное дерево. Одно дерево. А куча. Куча. Это набор биномиальных деревьев по парам
[18:02.220 --> 18:19.180]  различных рангов. Биномиальная куча. Это набор биномиальных деревьев по парам различных рангов.
[18:19.180 --> 18:35.020]  То есть я запрещаю иметь себе два дерева одинакового ранга. Нельзя иметь Т2 и Т2 одновременно. Они
[18:35.020 --> 18:45.220]  обязательно все различные. Например, можно иметь Т0, Т3, Т4. Это хорошо. А иметь Т1, Т2. Т2 нехорошо,
[18:45.300 --> 18:48.700]  потому что есть два дерева одного ранга. Я запрещаю себе иметь деревья одинакового ранга.
[18:48.700 --> 19:00.980]  Вот. И это будет биномиальная куча. Дальше. Как я буду хранить у себя в памяти? Ну,
[19:00.980 --> 19:07.420]  смотрите. Поскольку куча это набор деревьев, я давайте как-нибудь буду эти деревья хранить
[19:07.420 --> 19:15.840]  сами по себе. А их корни сложу, ну, например, в список, если нужно двухсвязанных. Так что корень
[19:15.840 --> 19:19.820]  первого дерева ссылается на корень второго, корень второго на корень третьего, корень третьего
[19:19.820 --> 19:24.460]  на корень четвертого, а корень четвертого уже никуда не ссылается, потому что куча кончилась. Итак,
[19:24.460 --> 19:32.300]  я свяжу корни всех моих деревьев в список. Они будут ссылаться друг на друга. Если нужно,
[19:32.300 --> 19:37.180]  список двунаправленный. Вроде бы это не нужно, но как бы мы понимаем, что одно от другого не
[19:37.180 --> 19:56.700]  сильно отличается. Если надо, мы добавим обратные ребра. Так. Замечание. Смотрите.
[19:56.700 --> 20:13.780]  Сколько вершин в дереве ранга k? Два степени k. В дереве tk ровно два вкаты вершин. Тривиальный
[20:13.780 --> 20:20.620]  факт доказывает по индукции, если в t0 одна вершина, а tk плюс 1, то есть это из двух копий одинаковых по
[20:20.620 --> 20:25.820]  структуре деревьев tk и tk, то значит число вершин с каждым шагом удваивается и становится в два раза
[20:25.820 --> 20:32.020]  больше. В дереве k легко понять, что вершин ровно два степени k. Теперь, если у меня все деревья
[20:32.020 --> 20:40.420]  попарно различных рангов, то сколько всего может быть деревьев, не больше, чем логарифм? Если всего
[20:40.420 --> 21:07.300]  в куче n элементов, то деревьев не больше, чем логарифм. Почему деревьев не больше, чем логарифм?
[21:07.300 --> 21:12.820]  Давайте рассмотрим самые маленькие деревья. Представьте, у нас есть t0, t1, t2, t3 и так далее. У них
[21:12.820 --> 21:17.780]  размеры это степени двойки 1, 2, 4, 8 и так далее. Какое наибольшее количество различных степеней
[21:17.780 --> 21:23.660]  двойки вы можете набрать, чтобы не превысить n? Ну, ясно? Логарифм. Как раз минимальная степень
[21:23.660 --> 21:31.900]  двойки 1, 2, 4 и так далее вплоть до 2 в степени логарифм. Значит, деревьев мало. Вот этих вот корней,
[21:31.900 --> 21:37.820]  вот этих деревьев, которые я связываю с собой, их мало, их всего логарифм. Это здорово. Более того,
[21:37.820 --> 21:44.020]  можно заметить, что глубина всех этих деревьев тоже логарифмическая. Точнее, глубина катого
[21:44.020 --> 21:55.340]  дерева это в точности k. Глубина tk равна k. Ну, также по индукции здесь глубина 0, здесь глубина,
[21:55.340 --> 22:00.100]  то есть самый длинный путь вниз. Какое наибольшее время у нас занимало бы, скажем, сивдаун? Какая
[22:00.100 --> 22:06.340]  самая длинная длина пути сверху вниз? Здесь одно ребро, тут два ребра. Ну, тут понятно,
[22:06.340 --> 22:17.540]  1 плюс сколько ребер в k? То есть какой ранг, такая глубина? Окей, ну вот такая структура. Теперь
[22:17.540 --> 22:20.980]  давайте поймем, как здесь все работает, как наши операции можно быстренько проводить.
[22:20.980 --> 22:35.500]  Давайте начнем сразу с мерч. Представьте, что у меня есть две биномиальные кучи, представленные
[22:35.500 --> 22:39.940]  вот в таком виде, что у меня есть список корней, которые друг на друга ссылаются. Каждый корень
[22:39.940 --> 22:45.860]  — это корень своего биномиального дерева. Как их быстренько склеить? Ну, смотрите, идеальный
[22:45.860 --> 22:51.380]  случай, если в этих двух кучах, в этих двух списках корней, все ранги попарно различны.
[22:51.380 --> 22:58.100]  Скажем, в левом есть только t0, t3, t4, в правом есть только t1, t2. Тогда делать ничего не нужно,
[22:58.100 --> 23:01.300]  это у вас будет корректная биномиальная куча. Вы просто все деревья сваливаете в один большой
[23:01.300 --> 23:07.060]  список. Если дубликатов нет, если нет деревьев одинакового ранга в двух разных кучах, то даже
[23:07.060 --> 23:12.020]  ничего делать не нужно. Теперь что делать, если дубликаты есть? Представьте, что в обеих кучах
[23:12.020 --> 23:19.260]  было дерево ранга k. Тогда, понятно, вы не можете их оставить, вам нужно что-то сделать. Ну,
[23:19.260 --> 23:24.500]  понятно, их можно слить в одно дерево большего ранга. Вы можете, имея два вот таких дерева, за
[23:24.500 --> 23:30.500]  единицу построить вот такое. Вот просто этой картинкой. Есть одно корректное биномиальное
[23:30.500 --> 23:34.580]  дерево, есть другое. Вам нужно подвесить одно к другому, чтобы получить дерево ранга k плюс 1.
[23:34.580 --> 23:39.460]  Единственное, здесь важно, что к чему подвешивать. Вам нужно сравнить числа, расположенные в корнях
[23:39.460 --> 23:44.660]  этих деревьев, ну и к тому, которое меньше подвесит другое, потому что иначе требования кучи
[23:44.660 --> 23:48.980]  нарушатся. Ну, это простая проверка. Что к чему подвешивать, это просто. Надо просто сравнить два
[23:48.980 --> 23:54.880]  числа. Но мораль такая, что если есть дубликаты, если есть деревья одинаковых рангов, то их можно
[23:54.880 --> 24:03.180]  склеить и получить ранг k1 побольше. На этом основывается алгоритм. Давайте я скажу, что вот
[24:03.180 --> 24:07.700]  эти вот деревья в списке, которые у меня лежат, они идут в порядке возрастания рангов. Например,
[24:07.820 --> 24:15.020]  t0, t3, t4, t10. Здесь тоже самое t1, t2, t5, t17. Идут в порядке возрастания рангов. Тогда давайте
[24:15.020 --> 24:19.340]  одновременно двумя указателями идти по этим двум кучам. Вот есть одна куча, вот есть другая.
[24:19.340 --> 24:28.660]  И как-нибудь их сливать. Например, если мы видим, что здесь есть t0, а там нет t0, то я могу t0
[24:28.660 --> 24:32.780]  спокойно перекопировать в ответ, потому что t0 точно ни с кем не склеится, у него нет дубликатов,
[24:32.780 --> 24:39.940]  я t0 просто оставляю. Затем здесь вижу t3, а здесь t1. Значит, у t1 пары нет, я могу t1 спокойно оставить.
[24:39.940 --> 24:46.940]  Давайте напишем какой-то пример. 1, 3. Значит, видим, у 0 и 1 пар нет, поэтому я их спокойно
[24:46.940 --> 24:51.540]  оставляю в результате. У меня будет отдельно дерево t0, отдельно дерево t1. Потом я вижу,
[24:51.540 --> 24:59.460]  ага, у меня есть две кучи одинакового размера, t3 и t3. Давайте их склеим. Получим дерево t4. Затем
[24:59.460 --> 25:05.420]  видим опять, ага, у меня есть еще дерево t4. Давайте опять их склеим. Получим t5. Ну и так далее.
[25:05.420 --> 25:12.180]  По факту все, что мы сделали, это сложили два числа в двоичной системе в столбик, начиная от
[25:12.180 --> 25:16.980]  младших битов к старшим. То есть представьте, что вот это номера включенных битов в двоичной
[25:16.980 --> 25:22.180]  системе числения. Я иду по двум числам слева направо, начиная от младших битов, идя к старшим.
[25:22.180 --> 25:26.700]  Если я вижу два включенных бита в этой позиции, то я их складываю и переношу в следующий разряд,
[25:26.860 --> 25:33.540]  из itv v1. Если я вижу, что v1 опять что-то стоит, то я, если надо, опять склеиваю. Это ровно
[25:33.540 --> 25:39.580]  сложение двух чисел в столбик в зависимости от младших числений. Согласны? Если есть одинаковые,
[25:39.580 --> 25:44.460]  то есть в катом разряде включены оба бита, я их склеиваю и получаю бит в следующем k1.
[25:44.460 --> 25:51.980]  Ну и все. Получается, что таким линейным проходом по обоим спискам я могу их склеить,
[25:51.980 --> 25:55.940]  могу слить деревья, если нужно. И все это работает опять-таки за логарифмическое время,
[25:55.940 --> 26:01.580]  потому что длина обоих списков у меня логарифм. Значит, я прохожусь по одному
[26:01.580 --> 26:04.460]  за логарифмическое время, по другому за логарифмическое время и, если надо,
[26:04.460 --> 26:09.660]  что-то склеиваю. Получается, суммарный список размера логарифм, я его получил за логарифмическое время.
[26:09.660 --> 26:20.500]  Если у них одинаковые ранги, то сливаем, да. То не сливаем, их не нужно сливать,
[26:20.500 --> 26:24.900]  если у вас есть t0 и t1, то мы их просто так же перекопируем в ответ. Их не нужно сливать,
[26:24.900 --> 26:29.340]  они и так уникальные, мы их просто оставляем в ответе как корни новой кучи.
[26:29.340 --> 26:41.620]  Ну у нас у меня один указатель в первой куче, один во второй. Они оба двигаются монотонно
[26:41.620 --> 26:46.540]  слева направо. Если видят одинаковые кучи, кучи одинакового ранга, то сливают и получают кучу
[26:46.540 --> 26:50.940]  следующего ранга. Если они различные, то меньше из них копируют в ответ, и указатель сдвигается
[26:50.940 --> 27:06.860]  вправо в той куче, откуда скопировался. Если здесь, смотрите, мы начинаем отсюда. У меня 0 и 1 не равны.
[27:06.860 --> 27:12.060]  Значит, 0 ни с кем не парится, я его спокойно копирую в ответ, переношу указатель сюда. Затем смотрю,
[27:12.060 --> 27:16.500]  кто из них меньше? Один меньше. У него нет пары, я его копирую в ответ, сдвигаю указатель. У двое
[27:16.500 --> 27:23.940]  пары нет, я его копирую в ответ, сдвигаю указатель. Опа, три-три. И теперь мы их склеиваем,
[27:23.940 --> 27:29.180]  получаем т4. И оба указателя двигаем сюда. То есть у меня в памяти хранится т4, и вот еще
[27:29.180 --> 27:37.140]  четверка, если надо, опять их склеиваю. Получаем уже пятерку, она опять в свою очередь склеивается
[27:37.700 --> 27:44.500]  И в итоге у нас будет 0, 1, 2, 6. Да, верно, верно, верно.
[27:44.500 --> 27:52.060]  Спасибо. То есть у меня правильно понимать, если у меня были две кучи, в одной все возможные двери
[27:52.060 --> 27:59.700]  от одного руками судим, а в другой все возможные от одного руками, то в конце получится куча с одним
[27:59.700 --> 28:09.220]  деревом как 1. Да, вы сейчас сказали, как складываются числа в двоичной системе
[28:09.220 --> 28:13.580]  счастливения 1, 1, 1, 1, и 1, 1, еще одна единичка. Ну вот ровно так они складываются, что там будет 0.
[28:13.580 --> 28:19.780]  Ну конечно, да, потому что здесь ровно это и происходит. Если вот это вот считать номером бита в
[28:19.780 --> 28:23.500]  двоичной системе счастливения, то мы ровно это и делаем. Если видим два включенных бита в двух
[28:23.500 --> 28:27.780]  числах, то они складываются и переносятся в следующий разряд. Ровно это мы и делаем. tk t
[28:27.780 --> 28:30.100]  plus tk равно tk плюс 1. В следующий разряд переходим.
[28:30.100 --> 28:50.340]  Да, ну смотрите, на самом деле можно хранить просто это все в ответе, то есть вот у меня есть две кучи.
[28:50.340 --> 28:56.420]  Я храню еще кучу ответа, список ответов. Я туда свалил 0, 1, потом увидел 3, 3, склеил, получил t4,
[28:56.420 --> 29:02.260]  положил в ответ. Дальше вижу, ага, там есть четверка. Если в ответе есть четверка, то я склеиваю и
[29:02.260 --> 29:23.700]  переношу ответ в t5. На последний бит, на старший бит. Еще раз? Ну да, не понял вопрос. Мы идем слева
[29:23.700 --> 29:33.740]  направо от меньших ранок к большим, это правда. Потому что мы проводим одно ребро.
[29:33.740 --> 29:49.580]  Массивы? Я понял, я это не сказал, но на самом деле, конечно, такую штуку в массиве мы хранить не
[29:49.580 --> 29:55.740]  можем. У меня представление в виде массива есть только для бинарной кучи. Когда вот там есть хорошая
[29:55.740 --> 30:00.540]  картинка, что элементы a1, a2 и так далее, а n, очень легко представить в виде бинарной кучи. Когда у вас
[30:00.540 --> 30:07.340]  дерево вот такое, вы же это не в массиве храните, вы храните явно какую-то структуру вершина, какой-то
[30:07.340 --> 30:12.180]  черный ящик вершина, которая в свою очередь ссылается на каких-то детей, которые у нее есть. То
[30:12.180 --> 30:16.220]  есть это уже не массив, а именно вот отдельная сущность, вершина, которая имеет несколько детей.
[30:16.220 --> 30:20.900]  Это имеет несколько детей, это несколько детей и так далее. Но добавить очередного сына справа
[30:20.900 --> 30:25.660]  можно очень легко, можно просто к этому списку добавить еще одного сына справа. Но это уже не
[30:25.660 --> 30:34.620]  массив будет. Нет, не придется, если мы правильно будем делать подвешивание, то у меня требования
[30:34.620 --> 30:41.740]  кучи нигде не нарушатся. Если у меня есть две кучи с числом x и y в корне и x меньше y, то требования
[30:41.740 --> 30:53.540]  нигде не нарушатся. Я по другому подвешу, значит x к y подвешу. Так, можно дальше? Прекрасно. Дальше,
[30:53.540 --> 30:56.980]  значит, это я про мерчу все сказал. Теперь давайте все остальные операции быстренько обсудим,
[30:56.980 --> 31:04.220]  как реализовывать. Значит, что делать с инсертом? Очень просто. Давайте мы создадим отдельную кучу,
[31:04.220 --> 31:12.860]  добавим в ней дерево t0 и скажем, что единственная вершина в ней это x. И запустим мерч вот этого
[31:12.860 --> 31:21.460]  дерева с нашей исходной кучей. Тогда мы победим. Мы завели тривиальную кучу, она, конечно, корректная,
[31:21.460 --> 31:27.260]  это биномиальная куча, потому что состоит из одного дерева ранга t0. И после мерча я как раз
[31:27.260 --> 31:41.300]  этот x добавлю в нашу исходную кучу. Работает за логарифом. Да? Декрестки. Ну, здесь вообще думать
[31:41.300 --> 31:45.940]  не нужно. Если мне по указателю говорят уменьшаемый элемент, то есть меня тыкают в какую-то вершину
[31:45.940 --> 31:51.980]  моего дерева и говорят уменьшу на 3. Я такой, хорошо, уменьшаю на 3, а дальше севтап. Благо севтап
[31:51.980 --> 32:00.180]  у меня работает. У меня сохраняется моя процедура севтап, которая просто берет и исправляет все
[32:00.180 --> 32:05.380]  ошибки с родителем, пока они есть. Пока это число меньше родителя, я их свопаю и поднимаюсь наверх
[32:05.380 --> 32:12.220]  рекурсивно, пока все эти ошибки не исправлю. Работает опять-таки за логарифом, потому что
[32:12.220 --> 32:18.220]  глубина дерева логарифмическая. Куда бы мне изначально не тыкнули в моем дереве, глубина дерева
[32:18.220 --> 32:24.020]  ранга k максимум k, поскольку k всегда не больше чем логарифм, потому что нельзя иметь дерево ранга
[32:24.020 --> 32:31.980]  больше чем логарифм. Значит глубина логарифмическая, поэтому севтап работает за логарифм. Так, что дальше?
[32:31.980 --> 32:49.420]  Ну get mean. Ничего не надо понимать. Смотрите, мы просто запускаем мерч. Мы уже доказали,
[32:49.420 --> 32:54.180]  что мерч работает за логарифм. Не надо это еще раз передоказывать. Как-то он там работает
[32:54.180 --> 33:01.380]  за логарифм. Вот мы это используем, получаем сразу логарифмическое время. Так, get mean. Ну смотрите,
[33:01.380 --> 33:09.100]  тривиальная оценка от логарифма, потому что можно пройти по всем деревьям и найти минимальное
[33:09.100 --> 33:14.700]  значение из корней. Деревья в логарифм, в них в каждом дереве достаточно проверить только корень,
[33:14.700 --> 33:18.780]  потому что корень это минимум в своем дереве. Ну и поскольку все логарифм, то можно за логарифм
[33:18.780 --> 33:35.740]  это все сделать, просто пройдя по всем корням. Вот, это за логарифм. На самом деле, если постараться,
[33:35.740 --> 33:43.940]  эту штуку можно было бы написать и за единицу, но тут пришлось бы несколько повозиться. Чтобы
[33:43.940 --> 33:50.020]  написать get mean за единицу, я могу всегда поддерживать указатель на минимальный корень. Я понимаю,
[33:50.020 --> 33:54.740]  что минимум всегда это один из корней. Вот у меня есть много деревьев. Минимум точно в одном из
[33:54.740 --> 34:00.420]  корней, потому что корень это минимум в своем дереве. Давайте просто поддерживать указатель на
[34:00.420 --> 34:06.340]  минимум и аккуратно его поддерживать, когда происходят всякие разные запросы изменения.
[34:06.340 --> 34:10.900]  Вот когда происходит мерч, как пересчитать указатель на минимум? У вас была одна куча,
[34:10.900 --> 34:15.540]  вы знали где минимум, другая вы знали где минимум, вы ее полностью перестраиваете,
[34:15.540 --> 34:19.760]  проходите по всем корням, как-то их сливаете и получаете новый список корней. Понятно, где-то
[34:19.760 --> 34:24.580]  минимум. Вы все эти корни так прошли, вы знаете, какой из них минимальный. Мы знаем указатель на
[34:24.580 --> 34:29.500]  минимум. Что происходит в дикриске, как поддерживать указатель на минимум? У вас число поднимается,
[34:29.500 --> 34:35.580]  если оно дошло до корня, то надо посмотреть, а не стал ли этот корень новым минимумом. Если стал,
[34:35.580 --> 34:40.500]  то нужно указатель на него переправить. В общем, это все несложно. Давайте попишу,
[34:40.500 --> 35:00.180]  если хранить указатель на минимальный корень. Вот сейчас к этому перейдем. Да,
[35:00.180 --> 35:08.260]  спасибо. Мне остался только экстракт-мин. Надо сначала понять, как он работает, а потом,
[35:08.260 --> 35:15.540]  как мы этот указатель поддерживаем. Как работает экстракт-мин? Смотрите, есть у меня моя куча из
[35:15.540 --> 35:21.660]  нескольких разных деревьев. Я знаю, кто из них минимальный. У меня поддерживается указатель на
[35:21.660 --> 35:26.940]  минимум из всех этих корней. Вот скажем вот это. Что я хочу в идеале сделать, что я на самом деле
[35:26.940 --> 35:36.420]  буду делать? Я говорю, окей, это какая-то вершина. У нее есть несколько сыновей. Давайте мы эту вершину
[35:36.420 --> 35:41.660]  удалим, а все вот эти вот деревья сложим в отдельную биномиальную кучу. Скажем, что это новая
[35:41.660 --> 35:53.260]  биномиальная куча h, штрих какой-нибудь, и смержем ее со всем оставшимся. Еще раз, как работает
[35:53.260 --> 35:59.420]  экстракт-мин? Мы знаем, какой корень был минимальным, что вот это число минимальное. Я его удаляю,
[35:59.420 --> 36:04.420]  но мне же нужно сохранить всех его детей, мне нужно сохранить всех потомков. Я говорю, хорошо,
[36:04.420 --> 36:11.620]  давайте все вот эти деревья вырежем, сложим в новую кучу h, штрих и склеим все, что осталось,
[36:11.620 --> 36:17.020]  то есть вот это, вот это и вот это, с кучей h, штрих. Благо процедура мерч у меня есть, мы умеем
[36:17.020 --> 36:24.180]  объединять две биномиальные кучи. Но здесь нужно сказать немножко аккуратнее, почему я имею право
[36:24.180 --> 36:29.620]  всех вот этих вот детей минимума выносить в отдельную кучу h, штрих. Мне нужно сказать, что это
[36:29.620 --> 36:36.540]  вот будет корректной биномиальной кучей, потому что я имею право сложить в h, штрих только биномиальную
[36:36.540 --> 36:40.780]  кучу. h, штрих это биномиальная куча должна быть. Значит, в частности, все вот эти вот деревья,
[36:40.780 --> 36:46.220]  которые являются сыновьями минимума, они должны быть все биномиальными деревьями, причем попарно
[36:46.220 --> 36:53.580]  различных рангов. Давайте проверим, что это выполняется. Я утверждаю, что картинка всегда
[36:53.580 --> 36:58.940]  имеет такой вид. Если я рассматриваю дерево k-того ранга, то оно всегда имеет следующую структуру,
[36:58.940 --> 37:06.740]  это корень, а дальше к нему подвешено дерево ранга 0, дерево ранга 1, дерево ранга 2 и так далее
[37:06.740 --> 37:20.860]  вплоть до ранга k-1. То есть, дети, вершины, pardon, дети, корня tk, это все меньшее деревье, t0 и так
[37:20.860 --> 37:27.620]  далее, tk-1. Если я это докажу, то такой подход будет корректным, потому что все эти поддеревья,
[37:27.620 --> 37:31.860]  это корректные биномиальные деревья, попарно различных рангов, значит, я их могу свалить в h,
[37:31.860 --> 37:35.860]  штрих, а потом все замерзнуть. Не будет проблем с тем, что у меня h, штрих это не куча, потому что это
[37:35.860 --> 37:42.660]  куча. Но почему это верно? Давайте опять по индукции докажем. k равно 0 тривиально, потому что у
[37:42.660 --> 37:48.700]  k равно 0 нет детей, собственно, ровно это и нужно показать, потому что k-1 это будет минус 1. Переход.
[37:48.700 --> 37:55.700]  Пусть для tk это верно. Как доказать для tk плюс 1? Я знаю, как получается tk плюс 1. Что такое tk плюс
[37:55.700 --> 38:04.220]  1? Это tk, к которому еще справа подвешено tk. Вроде понятно тогда, если вот это вот, это вот,
[38:04.220 --> 38:09.660]  это вот, то как раз у меня получилось, что к корню подвешено сначала t0, t1, t2 и так далее tk-1,
[38:09.660 --> 38:18.740]  а еще справа добавлен tk. Переход индукции завершен. Итак, значит, еще раз. Как реализую
[38:18.740 --> 38:23.620]  экстракт мин? Нахожу минимум, смотрю на всех детей, понимаю, что это попарно различных рангов
[38:23.620 --> 38:28.220]  биномиальные деревья, выношу их в отдельную кучу и потом сливаю все с помощью мерч. Значит,
[38:28.220 --> 38:35.100]  это тоже работает за логарифмическое время от Луган. Ну и, как вы правильно заметили,
[38:35.100 --> 38:40.340]  поддерживать указатель на минимум, на минимальный корень после вот этого всего несложно. Но если
[38:40.340 --> 38:44.980]  я в мерч что-то делаю, то раз я его вызываю, то минимальный корень тоже автоматически посчитается
[38:44.980 --> 38:57.220]  правильно. Да, в отдельную новую кучу аш-стрих, а потом склеиваю то, что осталось, и аш-стрих.
[38:57.220 --> 39:07.100]  С помощью мерч. Ну конечно, да, вот эти вот все, кроме вот этого вот, я вот эти вот все
[39:07.100 --> 39:10.860]  склеиваю с аш-стрих. По факту я ровно минимум только и высек, только его и удалил.
[39:10.860 --> 39:19.660]  А экстракт-мин для биномиальной кучи, мы берем какой-то минимальный корень среди всех корней?
[39:19.660 --> 39:24.700]  Конечно, это минимум, минимум. Минимальное значение среди всех. Экстракт-мин, он что такое? Это
[39:24.700 --> 39:30.140]  найти минимальный элемент в куче и удалить его. Только минимальный. Но, если я договариваюсь,
[39:30.140 --> 39:34.980]  что у меня есть указатель на минимум, вот то, что я тут говорил, что я за единицу знаю указатель
[39:34.980 --> 39:39.460]  на минимум. Если его всегда поддерживаю, то это не проблема, я знаю, где он. Вот этот минимум,
[39:39.460 --> 39:56.380]  я у него вырезаю детей. Давайте. Я это упоминал, в дереве, сейчас, вот, глубина от дерева ТК равна
[39:56.380 --> 40:02.980]  К. Но осталось сказать, что К не больше, чем логарифм, потому что в дереве ТК два вкаты вершин. У вас не
[40:02.980 --> 40:06.580]  может быть ранг больше, чем логарифм, потому что в нем вершин слишком много, больше, чем Н.
[40:09.460 --> 40:19.540]  Еще раз, почему что? Ребят, можно потише просто? Я не слышу вопросов даже. Да. Почему сфтап за
[40:19.540 --> 40:23.860]  логарифм работает? Ну, смотрите, вот у вас есть какое-то длинное дерево. Ну, как длинное, вы знаете,
[40:23.860 --> 40:28.900]  что углу на логарифм. Вас ткнули вот сюда. Что вам нужно сделать? Вам нужно, пока вы не поднялись в
[40:28.900 --> 40:35.260]  корень, сравнивать вот этого чувака и родителя, если надо свопать их значение. Окей, потом вот
[40:35.260 --> 40:40.860]  этого чувака и его родителя, если надо свопнуть значение. Но это в точности путь от вершины до корня.
[40:40.860 --> 40:47.020]  Раз глубина логарифмическая, значит этот путь тоже максимум логарифмический. Потому что глубина
[40:47.020 --> 41:01.940]  это просто самый длинный путь от корня вниз, а вы идете снизу вверх. Так, хорошо. Все, значит,
[41:01.940 --> 41:06.140]  тогда я считаю, что мы с биномиальной кучей разобрались. Мы скорее всего вернемся к ней
[41:06.140 --> 41:10.220]  где-нибудь на следующей лекции, когда будем говорить про кучу фибоначи. Это тоже куча,
[41:10.220 --> 41:15.180]  основанная во многом на биномиальной, но с некоторыми еще модификациями. Пока чтобы к
[41:15.180 --> 41:19.500]  этому перейти, мне нужен некоторый матаппарат, который я сейчас буду вводить. Это то, что я
[41:19.500 --> 41:28.980]  называю амортизационный анализ. Амортизационный анализ. И то, что я когда-то уже упоминал.
[41:28.980 --> 41:38.660]  Итак, представьте себе такую конструкцию. Вы хотите хранить некоторую структуру данных,
[41:38.660 --> 41:46.900]  которая будет означать некоторые запросы. Но на разные запросы, или даже, точнее, на запросы одного
[41:46.900 --> 41:52.540]  и того же типа, она может отвечать за разное время. Какие-то запросы одного и того же типа
[41:52.540 --> 42:01.060]  обработают быстро, какие-то долго. Так вот, можно тогда в некотором смысле их усреднить. Можно
[42:01.060 --> 42:04.940]  сказать, что есть некоторая функция, которая сверху оценивает суммарное время выполнения всех
[42:04.940 --> 42:10.020]  запросов. Даже когда внутри типа запроса возникает вот такой дисбаланс, что какие-то быстро,
[42:10.020 --> 42:14.820]  какие-то долго, вы можете их в каком-то смысле усреднить и сказать, что в среднем они работают
[42:14.820 --> 42:21.900]  быстро. Вот ровно это я сейчас буду определять. Итак, пусть S это какая-то структура данных,
[42:21.900 --> 42:45.540]  которая умеет обрабатывать ка типов запросов. Давайте я их занумеру, типы запросов это один,
[42:45.540 --> 42:52.220]  два и так далее. Это вот, например, то, что у меня было в куче, это insert, extract mean, get mean,
[42:52.220 --> 42:57.420]  decrease key. Четыре типа запросов, они какие-то, они что-то делают с нашей структурой.
[42:57.420 --> 43:09.500]  Значит, тогда будем говорить, что функции a1, давайте я с круглыми скобочками их напишу,
[43:09.500 --> 43:32.540]  a1, a2 и так далее, ak являются амортизационными или иначе учетными стоимостьями выполнения
[43:32.540 --> 43:51.060]  всех запросов. Если, идейно смотрите следующее, если вы вот эти вот функции a1, a2, a3, ak воспринимаете
[43:51.060 --> 43:57.700]  как настоящее время работы, то это дает вам оценку сверху на реальное время работы. То есть,
[43:57.700 --> 44:04.820]  даже если какой-то итый запрос может выполняться не за время, а итое, а за какое-то другое, но вот
[44:04.820 --> 44:09.700]  суммарно, если вы все эти ашки просуммируете, то получится хотя бы столько, сколько реально было
[44:09.700 --> 44:18.060]  времени работы. Формально, если для любого n, для любой последовательности запросов
[44:18.060 --> 44:32.180]  типов i1 и так далее, i n, то есть я говорю, что к структуре поступает n запросов, их типы это i1 и так
[44:32.180 --> 44:37.740]  далее, i n, например, insert, decrease, extract и так далее, вот это типы, я не говорю какие у них
[44:37.740 --> 44:42.220]  характеристики, там x, дельта и так далее, только типы, первый тип, второй, третий,
[44:43.100 --> 44:57.740]  вот если такие типы поступают, то реальное время работы есть o от суммы всех этих ишек,
[44:57.740 --> 45:08.060]  ну точнее от суммы a с этими индексами. Сумма пожи от 1 до n, а итое житое от n.
[45:21.460 --> 45:27.700]  Наитый тип запроса, да. Ну и смысл ровно такой, который я придался этому дать. Смотрите,
[45:27.700 --> 45:33.180]  вот есть какие-то функции, взятые из потолка, они на самом деле не имеют ничего общего с тем,
[45:33.180 --> 45:36.660]  как на самом деле работают эти запросы, как они обрабатываются. Они обрабатываются,
[45:36.660 --> 45:42.220]  бог пойми, за какое время, за какое-то. Я говорю, вот эти функции я тебе даю, из космоса взял,
[45:42.220 --> 45:48.380]  вот они хорошие, они учетные время работы, если когда вы их складываете с аргументом n,
[45:48.380 --> 45:53.700]  то есть вот в скобке подставляете n как число запросов, а индексы берете такие, какие были
[45:53.700 --> 45:59.380]  типы запросов. Пришел insert, вы в сумму добавили a insert от n. Пришел decrease key, вы добавили a
[45:59.380 --> 46:04.500]  decrease key от n. То есть каждый индекс это свой тип запроса. Вот если вы просуммировали эти ашки по
[46:04.500 --> 46:09.500]  всем запросам, то у вас должно быть хотя бы реальное время работы. То есть на самом деле время
[46:09.500 --> 46:15.340]  работы настоящее, это o от суммы этих ашек. То есть эти функции какие-то из космоса прилетели,
[46:15.340 --> 46:20.780]  волшебные. Но если они внезапно удовлетворяют вот такому условию, что они сверху ограничивают
[46:20.780 --> 46:29.780]  время работы настоящее, то это учетные стоимости. А с индексом i, с индексом g.
[46:29.780 --> 46:48.340]  Давайте какой-то пример из рубрики уже пройденного. Давайте вспомним, как мы реализовали очередь на
[46:48.340 --> 46:59.820]  двух стэках. Я говорю, что я завожу два стэка. Первый и второй. Insert я обрабатываю просто
[46:59.820 --> 47:08.940]  добавлением элемента сюда. A pop или top я обрабатываю тем, что в случае пустого второго стэка я сначала
[47:08.940 --> 47:13.020]  перекладываю все элементы из первого во второй. А дальше со вторым работаю просто доставая из
[47:13.020 --> 47:19.940]  начала. Давайте скажем следующее. Понятное дело, что insert всегда работает за от единицы, потому что
[47:19.940 --> 47:24.220]  insert это просто добавить элемент в первый стэк. Ничего никуда не перекладываю, просто insert это push
[47:24.220 --> 47:38.620]  в первый стэк. А top или pop, каждый конкретный такой запрос, он может быть очень долгий,
[47:38.620 --> 47:44.460]  время работы может быть долгим. Потому что, еще раз, если внезапно второй стэк пустой, а в первом
[47:44.460 --> 47:50.860]  что-то лежит там x, y, z, t, то я сначала все эти элементы по одному вот так вот тихонечко скрупулезно
[47:50.860 --> 47:57.260]  по одному перекладываю сюда. T, потом z, потом y, потом x. Но понимаешь, что это не от единицы. А время
[47:57.260 --> 48:01.300]  работы пропорционально число элементов в первом стэке. Оно может быть большим. Но я утверждаю,
[48:01.300 --> 48:09.500]  что если A здесь положить, то есть A с индексом top и A с индексом pop, назначить единицей, то это
[48:09.500 --> 48:14.340]  будут учетные стоимости. То есть реальное время не единиц, видно, что здесь сколько элементов,
[48:14.340 --> 48:23.180]  столько это и работает. Но учетно будет за единицу. Учетное время работы операции top и операции pop
[48:23.180 --> 48:27.820]  будет единицей. Ну почему? Давайте докажем. Я на самом деле это уже доказывал. Потому что давайте
[48:27.820 --> 48:33.700]  рассмотрим какую-то последовательность из N операций. Фиксируем N. Фиксируем последовательность
[48:33.700 --> 48:42.460]  из N запросов. Инсерты, топы и попы. Пуши, да, извиняюсь, пуши вместо инсертов. Рассматриваю. Но я
[48:42.460 --> 48:48.020]  доказываю, что все это суммарно работает за O от N. Потому что каждый конкретный элемент x, он может
[48:48.020 --> 48:52.820]  максимум один раз пушнуться в первый стэк, потом перенестись во второй и потом из него извлечься.
[48:52.820 --> 48:57.740]  Но с ним происходит там три или четыре действия, в зависимости от того, как вы считаете. Добавился сюда,
[48:57.740 --> 49:03.740]  удалился, добавился, удалился. Значит, суммарно, если всего было N операций, давайте так напишу,
[49:03.740 --> 49:17.740]  если было всего N операций, то всего добавлено не больше, чем N элементов. А дальше я говорю,
[49:17.740 --> 49:21.820]  что каждый элемент участвует максимум в четырех действиях. Добавился сюда, удалился,
[49:21.820 --> 49:26.420]  добавился сюда, удалился. Значит, суммарно произведено не больше, чем 4N действий.
[49:26.420 --> 49:38.780]  4N – это реальное время работы. Понятное дело, что 4N – это O от суммы единичек по всем запросам,
[49:38.780 --> 50:00.940]  где A равно единице. Ну всё. Попросы? Ну супер.
[50:00.980 --> 50:12.140]  Вот я буду обозначать амортизационное время работы за o звёздочка. Вот это вот всё я буду обозначать
[50:12.140 --> 50:16.200]  как o звёздочка от единицы. То есть реальное время работы, может быть, бог знает каким,
[50:16.200 --> 50:21.220]  мне это не важно. Я говорю только, что учётно это работает как будто бы за единицу. В том смысле,
[50:21.220 --> 50:25.540]  что, если я считаю, что работа за единицу, то суммарно, это даст правильную оценку на время
[50:25.540 --> 50:29.600]  работы. А каждая конкретная, может быть, долга, но суммарно, как будто бы каждая за единицу.
[50:29.600 --> 50:46.520]  Так, хорошо. Давайте рассмотрим метод, как можно выводить вот эти вот ашки, как можно получать
[50:46.520 --> 50:50.960]  какое-то учетное время работы на разные операции. Это называется метод монеток,
[50:50.960 --> 51:11.920]  ну или иначе метод бухгалтерского учета. Сливать можно. Во-первых, можно сливать,
[51:11.920 --> 51:17.040]  чего не умеет бинарная куча. Во-вторых, на ее основе мы реализуем фибоначевую кучу,
[51:17.040 --> 51:23.880]  которая быстрее работает, но во многом наследуется от биномиальной. То есть у нее дикриски работает
[51:23.880 --> 51:32.840]  за единицу амортизировано. Но это мы в следующий раз еще посмотрим. Так, хорошо. Бухгалтерский
[51:32.840 --> 51:39.200]  учет работает следующим образом. Представьте себе, что вы клиент банка, и кроме выполнения
[51:39.200 --> 51:43.800]  операции над вашей структурой, вы можете делать какие-то операции в банке. Вы можете класть туда
[51:43.800 --> 51:49.840]  деньги, класть туда монетки или забирать туда монетки. Смысл монет такой, если вы когда-то
[51:49.840 --> 51:54.360]  понимаете, что операция слишком простая и у вас есть еще много времени перед тем, как придет
[51:54.360 --> 51:59.160]  следующий запрос, вы можете в банк несколько монеток положить. Вы говорите, ага, мне пришла
[51:59.160 --> 52:05.280]  простая операция, ну тогда я подсекономлю себе денег на будущее, положу в банк немножечко денег,
[52:05.280 --> 52:10.520]  и дальше, если что, буду расплачиваться вот этими монетками, которые я положил себе на будущее. То
[52:10.520 --> 52:15.280]  есть если простая операция, то вы кладете несколько монеток в банк. Если приходит сложная операция,
[52:15.280 --> 52:21.480]  как вот здесь, вам нужно переложить кучу элементов во второй стэк. Вы говорите такое, окей, я может
[52:21.480 --> 52:25.400]  быть сейчас поработаю долго, но у меня в банке есть много денег, давайте я буду из него занимать
[52:25.400 --> 52:30.000]  деньги, и в каком-то смысле за эти деньги буду выполнять операции. То есть у меня в банке много
[52:30.000 --> 52:35.280]  денег, я себе накопил какую-то сумму, я потихонечку оттуда достаю монеты, и как бы за эту стоимость
[52:35.280 --> 52:44.920]  выполняю операции. Вот такая аналогия. Формально давайте скажем следующее. Пусть ТИ, это реальное
[52:44.920 --> 52:57.800]  время выполнения этого запроса, время выполнения этого запроса, позволим себе кроме выполнения,
[52:57.800 --> 53:02.320]  то есть кроме ответа на запросы, позволим также класть деньги в банк и снимать деньги из банка.
[53:02.320 --> 53:12.480]  Значит пусть ДИ, это число монет, которые мы кладем в банк во время этого запроса,
[53:12.480 --> 53:23.720]  а ВИ, это наоборот снимаем число монет,
[53:23.720 --> 53:45.440]  которые мы снимаем из банка, снимаем со счета, снимаем со счета. Тогда А равное Т плюс Д минус
[53:45.440 --> 53:59.280]  В является учетной стоимостью. То есть если А задать по такому правилу, то они удовлетворяют
[53:59.280 --> 54:06.960]  определению амортизационной стоимости на самой левой доске. Значит что тут написано, смотрите,
[54:06.960 --> 54:13.520]  учетное время складывается из реального времени работы, плюс то сколько монеток я себе даю на
[54:13.520 --> 54:18.720]  будущее, в случае, если операция простая, я вот окей, мне пришла простая операция, Т маленькая,
[54:18.720 --> 54:23.120]  я такой, хорошо, давай я несколько монеток себе отложу на будущее, тем самым здесь немножко
[54:23.120 --> 54:27.600]  увеличу время работы А, вот это учетное время работы я себе увеличу, но ненамножко, так что,
[54:27.600 --> 54:32.440]  не знаю, если здесь 5, то здесь тоже 5, например, пожелал себе еще 5 монеток на будущее. А дальше,
[54:32.440 --> 54:37.280]  если приходит трудная операция, то я расплачиваюсь, я уменьшаю А за счет снятия денег со счета,
[54:37.280 --> 54:44.680]  я вычитаю W, чем больше W, тем сильнее я уменьшаю свое учетное время работы. Ну и вот утверждение
[54:44.680 --> 54:53.520]  простое, что если баланс в банке всегда не отрицательный, если баланс на счете всегда
[54:53.520 --> 54:59.480]  не отрицательен, то действительно эти Ашки можно рассматривать как учетное время работы,
[54:59.480 --> 55:19.680]  а И, да, это амортизационные стоимости. Это все в течение ИТ операции, индекс И, значит все
[55:19.680 --> 55:23.480]  происходит в течение ИТ операции. Мне пришла операция, я сначала на нее ответил за время ТИ,
[55:23.480 --> 55:40.960]  потом делаю что-то с банком, возможно снимаю, возможно кладу деньги. Достаточно, достаточно.
[55:40.960 --> 55:46.160]  Но давайте так, мы все равно никогда не будем делать отрицательный баланс в банке, это странно,
[55:46.160 --> 55:50.960]  нам это и не нужно. Доказательство очень простое, смотрите, давайте, у меня баланс всегда не
[55:50.960 --> 55:58.280]  отрицателен и Ашки определены таким образом. Тогда давайте просуммируем все Ашки. Просуммируем
[55:58.280 --> 56:03.200]  все учетное время работы вот ровно так, как здесь у меня написано. У меня там написано, что реальное
[56:03.200 --> 56:09.200]  время работы это о от суммы Ашек. Давайте все Ашки просуммируем. Что здесь получится? Это сумма
[56:09.200 --> 56:15.920]  реальных времен работы, плюс сколько я денег положил в банк суммарно, минус сколько я суммарно
[56:15.920 --> 56:26.560]  снял из банка. Дальше это не отрицательно, потому что мой баланс не отрицательен. Я положил хотя бы
[56:26.560 --> 56:32.560]  столько, сколько снял, а мой баланс не отрицательен, то есть сумма Дшек больше, чем сумма Двшек. Значит,
[56:32.560 --> 56:43.040]  сумма Таитых не больше суммы Аитых. Что ей требовалось? Сумма реальных времен работы не
[56:43.040 --> 56:50.600]  превосходит сумму учетных стоимости. Что ей требовалось по определению? Как правильно заметили,
[56:50.600 --> 56:55.920]  мне на самом деле не нужно обязательно, чтобы всегда была не отрицательная сумма. Мне важно только,
[56:55.920 --> 57:01.960]  чтобы в конце, чтобы суммарно за всю программу, за все время работы программы я положил больше
[57:01.960 --> 57:07.560]  ровно, чем я снял. От того, что я потребовал, что всегда не отрицательно, ничего не сломается,
[57:07.560 --> 57:12.000]  и я всегда на самом деле так и буду делать. Я никогда не буду занимать из банка. Там у меня
[57:12.000 --> 57:27.840]  всегда будет не отрицательная сумма на счету. Давайте, например, вот здесь вот поймем,
[57:27.840 --> 57:33.240]  как можно было бы монетками получить то же самое. Как с помощью метода бухучета понять,
[57:33.240 --> 57:42.640]  что А равна единице является амортизованной стоимостью? Надо придерживаться ровно той
[57:42.640 --> 57:47.720]  самой логики. Если поступает простая операция, то мы несколько монет кладем себе в банк. А если
[57:47.720 --> 57:53.840]  сложная, то я выполняю все операции именно за счет того, что у меня есть много денег в банке. Я
[57:53.840 --> 58:01.480]  снимаю деньги со счета, тем самым виртуально уменьшая время работы на запрос. Давайте сделаем
[58:01.480 --> 58:08.600]  следующее. Когда нам поступает х, это простая операция. Пуш работает за чистую единицу.
[58:08.600 --> 58:19.560]  Когда поступает запрос, я добавлю элемент х в стек, а также положу на него две монетки,
[58:19.560 --> 58:30.040]  кажется. Давайте вместе с х я положу на него две монетки. Дальше, когда приходит топ или поп к
[58:30.040 --> 58:38.040]  не пустому второму стеку, если тут есть какой-то элемент, тогда его удаляю просто за единицу. Если
[58:38.040 --> 58:42.600]  эта операция проста, я просто удаляю и ничего не делаю. А если операция сложная, и мне нужно сначала
[58:42.600 --> 58:47.560]  все элементы по одному из первого стека перешить во второй, то я это делаю за счет тех монет,
[58:47.560 --> 58:53.280]  которые на этих элементах лежат. Здесь у меня на каждом элементе по две монетки. Я элемент достаю,
[58:53.280 --> 59:00.800]  за счет той монеты, которая на нем лежит, я выполняю перенос, и тем самым у меня остается на нем
[59:00.800 --> 59:07.000]  монета, и как будто бы я эту операцию сделал бесплатно. То есть я сделал одно действие и расплатился
[59:07.000 --> 59:11.440]  за это одной монеткой. То есть у меня t равно единицы и w равно единицы. Они сократились, поэтому я как
[59:11.440 --> 59:17.640]  будто бы это сделал за ноль. То есть я за одну монетку перенес х во второй стек. То же самое
[59:17.640 --> 59:22.200]  с остальными. У меня на элементе лежат две монетки, я перекладываю в другой стек, расплачиваясь за
[59:22.200 --> 59:27.680]  этой той монеткой, которая на нем лежит. Даже получается одной монетки хватало, то есть я просто
[59:27.680 --> 59:35.600]  достаю элемент, снимаю с него монетку, которую как бы из банка. То есть я из банка снимаю монетку,
[59:35.600 --> 59:40.720]  вывожу из банка монетку, перекладываю сюда, как будто бы за ноль. Ну и получается как раз,
[59:40.720 --> 59:47.080]  что у меня время работы примерно равно числу снятых монеток на t равно w, число перекладывания
[59:47.080 --> 59:53.800]  равно числу монеток, которые я снимаю, значит a равно нулю просто будет в этом случае. Вот, то есть
[59:53.800 --> 01:00:04.520]  просто по формуле t плюс d это ноль, t равно w, поэтому a равно нулю в случае тяжелой операции. Ну да-да-да-да-да-да.
[01:00:04.520 --> 01:00:09.160]  Ну окей, ну тогда нужно там две монетки как раз достали и добавили. Ну это все детали, конечно.
[01:00:09.160 --> 01:00:18.560]  Так, понятно? Хорошо, давайте переходим тогда к следующему примеру получается. Это динамический
[01:00:18.560 --> 01:00:34.880]  массив. Динамический массив, он же вектор. Задача, вам нужно поддерживать массив переменной длины,
[01:00:34.880 --> 01:00:42.000]  который умеет добавлять элементы в конец и удалять элементы из конца. В формале вам нужно
[01:00:42.000 --> 01:00:46.840]  поддерживать множество элементов, которые как-то проиндексированы и уметь быстро отвечать на
[01:00:46.840 --> 01:00:52.800]  следующие типы запросов. Первый запрос это квадратные скобки, то есть по индексу и сообщить аит,
[01:00:52.800 --> 01:01:07.760]  сообщить аит, по индексу вывести элемент. Второе это pushback x, добавить x в конец массива,
[01:01:07.760 --> 01:01:23.280]  добавить x в конец массива. Ну и последний запрос, наоборот popback удалить последний
[01:01:23.280 --> 01:01:37.080]  элемент из массива, удалить последний элемент из массива. Вот такая задача. Ну мы будем на
[01:01:37.080 --> 01:01:42.920]  самом деле это делать на базе массива, но массива, который будет частично заполнен. У нас не будет
[01:01:42.920 --> 01:01:47.400]  такого, что все элементы лежат в массиве и все, то есть вот здесь вот край массива, здесь последний
[01:01:47.400 --> 01:01:52.920]  элемент и вправо от него ничего нет. У нас, наоборот, у нас будет выделено для нас некоторая удобная
[01:01:52.920 --> 01:01:59.240]  память, подряд идущий набор ячеек. Первые несколько ячеек будут содержать элементы массива,
[01:01:59.240 --> 01:02:06.520]  а дальше будет свободная доступная для меня память. Вот давайте скажем, что элементов занятых у меня
[01:02:06.520 --> 01:02:13.360]  будет s, от слова size, размер массива будет s, а всего я себе выделил c ячеек памяти, всего c.
[01:02:13.360 --> 01:02:21.880]  Тогда, ну понятно, что если это все дело на базе массива, то квадратные скобки тривиально работают,
[01:02:21.880 --> 01:02:26.680]  нужно просто вывести a и t. Раз это в массиве, то это работает за единицу. Можно сразу указать,
[01:02:26.680 --> 01:02:30.720]  что это работает за чистая от единицы, не амортизированная, не учетная, а именно чистая
[01:02:30.720 --> 01:02:36.000]  от единицы. Потому что, ну мы работаем в такой в рам модели, то есть random access, мы по индексу
[01:02:36.000 --> 01:02:44.360]  и можем сказать, что там лежит. Вот, что делать с push и pop back? Ну в простом случае, например,
[01:02:44.360 --> 01:02:50.280]  когда у меня приходит push и s меньше, чем c, я могу просто вот в эту свободную ячейку добавить x,
[01:02:50.280 --> 01:02:58.600]  ну и соответственно сдвинуть s на единичку, сказать, что s переходит в s плюс 1. В случае простого pop,
[01:02:58.600 --> 01:03:02.640]  я могу наоборот, вот был у меня последний элемент, я знаю, где он лежит, давайте я скажу,
[01:03:02.640 --> 01:03:07.040]  что я наоборот s на единичку уменьшу, а про этот элемент забуду, скажу, что как будто там ничего нет,
[01:03:07.040 --> 01:03:13.760]  и наоборот s поменяю на s минус 1. Это будет pop. Я по факту просто сдвигаю указатель с последнего
[01:03:13.760 --> 01:03:18.920]  элемента на предпоследний, уменьшая размер массива на 1. То есть я его оставляю лежать здесь,
[01:03:18.920 --> 01:03:23.040]  считаю, что здесь доступная для меня память, но говорю, типа там ничего нет, туда не ходи,
[01:03:23.040 --> 01:03:30.680]  массив заканчивается вот здесь. Это простые случаи. Теперь, что происходит в случае сложного push
[01:03:30.680 --> 01:03:45.120]  back и сложного pop back? Значит, что такое сложный push back? В идеале надо, но мы до этого подойдем,
[01:03:45.120 --> 01:03:52.720]  да. Ну сейчас, если массив не перестраивается, то есть если у меня c остается таким же,
[01:03:52.720 --> 01:03:59.400]  то в принципе эту память пока я ее, скажем так, пока я работаю с этим массивом, здесь можно ничего
[01:03:59.400 --> 01:04:03.200]  не чистить, потому что я ее забрал у системы, я сказал, это моя память, я делаю здесь все,
[01:04:03.200 --> 01:04:07.440]  что хочу. Если мы хотим этот массив удалить, куда-то перекопировать или что-то с ним сделать,
[01:04:07.440 --> 01:04:12.400]  тогда, да, всю эту память надо будет очистить. До этого мы еще дойдем. Итак, что такое тяжелый push
[01:04:12.400 --> 01:04:22.480]  back? Что такое тяжелый push back? Ну, это просто случай s равно c, когда у меня заполнена вся выделенная
[01:04:22.480 --> 01:04:27.400]  память. Я не могу добавить вправо в конец еще один элемент, но нет такой возможности. Ну,
[01:04:27.400 --> 01:04:34.360]  решение нехитрое. Давайте мы попросим у системы массив вдвое больше длины, 2c. Перекопируем туда
[01:04:34.360 --> 01:04:40.480]  все мои с-элементы, которые были изначально, и добавим с плюс первый в конец. Значит, решение
[01:04:40.480 --> 01:04:50.880]  очень простое. Значит, запросим у системы, ну или иными словами, выделим массив длины 2c,
[01:04:50.960 --> 01:05:00.360]  массив длины 2c. То есть у меня был массив длины c полностью заполненный. Я выделяю массив вдвое
[01:05:00.360 --> 01:05:09.920]  больше длины. Сначала копирую все свои старые данные. Значит, копируем старые данные. Копируем
[01:05:09.920 --> 01:05:18.120]  старые данные. Ну и в конец сюда после всего, что добавил, добавляю x. Можно.
[01:05:20.880 --> 01:05:31.120]  Нет, нет, нет, конечно, никак не 2 в степени, потому что, смотрите, если, например, приходит n раз pushback,
[01:05:31.120 --> 01:05:38.560]  представьте, у вас было изначально массив длины 1, вы потом сделали 2. Хорошо, нет, конечно, не 2 в
[01:05:38.560 --> 01:05:47.640]  степени, линейно, да. Ну, не очень хорошо, но по-другому как не особо получается. Но, раз мы про
[01:05:47.640 --> 01:05:53.400]  память заговорили, вот эту память давайте очистим и вернем в системе. Да, то есть мы не будем ее за
[01:05:53.400 --> 01:05:57.760]  собой сохранять, мы ее больше не будем использовать, и чтобы у нас не текла память, чтобы у нас не
[01:05:57.760 --> 01:06:02.240]  оставались выделенные участки памяти, которые мы не используем, давайте его удалим и вернем в
[01:06:02.240 --> 01:06:12.120]  системе. Ну там зависит от языка, c++ это типа delete. Вот эту память вернем в системе. В том смысле,
[01:06:12.120 --> 01:06:16.320]  что мы просто скажем, с этой памятью я больше не работаю, ее, пожалуйста, не учитывая в мой memory
[01:06:16.320 --> 01:06:21.000]  limit. Вот, я сейчас ограничен вот здесь. Этим я не пользуюсь, и, пожалуйста, забери его, я больше
[01:06:21.000 --> 01:06:27.600]  вообще туда смотреть не буду. Ну, понятно, что это работает за что-то типа ООЦ. На самом деле,
[01:06:27.600 --> 01:06:32.000]  реальное время работы это ООЦ. Ну, потому что я тут копирую, создаю массивы и так далее, это ООЦ.
[01:06:32.000 --> 01:06:40.680]  Но, если бы у нас, например, были только pushback, это происходит очень редко. Давайте вернемся к
[01:06:40.680 --> 01:06:45.680]  примеру. Пусть изначально массив длины 1 и поступают только pushback, pushback 1, 2, 3, 4 и так далее.
[01:06:45.680 --> 01:06:51.720]  Тогда сначала я массив длины 1 превращу в массив длины 2. Потом, когда он полностью заполнится,
[01:06:51.720 --> 01:06:58.200]  в массив длины 4, потом длины 8, ну и так далее. По степеням 2 я пойду. Ну и тогда это происходит
[01:06:58.200 --> 01:07:03.640]  все реже и реже. Если у меня массив длины 8, то мне нужно сначала 4 новых pushback получить,
[01:07:03.640 --> 01:07:09.760]  целиком его заполнить, и только после этого я выделяю новый массив. Это происходит все реже и реже,
[01:07:09.760 --> 01:07:14.920]  экспоненциально редко становится. Если у меня только pushback, тогда мне нужно по степеням 2 идти,
[01:07:14.960 --> 01:07:19.800]  и это происходит все реже и реже. Поэтому, кажется, что это не очень страшно. На самом деле так и есть,
[01:07:19.800 --> 01:07:37.160]  учетно будет все за единицу. Смотрите, мы говорим следующее. У меня был массив длины 8,
[01:07:37.160 --> 01:07:42.760]  я создал массив длины 16, а этот очистил, вернул в системе. Тогда у меня здесь задействовано 9 из
[01:07:42.760 --> 01:07:49.880]  16, но это все еще моя память, я ее контролирую. Если мне приходят еще pushback, то я 10, 11, 12,
[01:07:49.880 --> 01:07:58.160]  все сюда буду класть. Она не то, что утекла. Утекла, это когда вы потеряли на нее указатель,
[01:07:58.160 --> 01:08:01.880]  а вы знаете указатель, у вас все элементы вот здесь лежат, вы знаете, сколько их, где они
[01:08:01.880 --> 01:08:06.000]  начинаются, где заканчиваются, вы все это контролируете, все в вашей власти. Если их не приходит,
[01:08:06.000 --> 01:08:10.320]  ну не очень хорошо, но ничего страшного, вы всего лишь в два раза больше памяти используете, чем
[01:08:10.320 --> 01:08:15.760]  можно было бы, 16 вместо 9. Но потом, когда ваш алгоритм закончится, вы эту память очистите,
[01:08:15.760 --> 01:08:20.160]  тем самым у вас все указатели вывернули в системе, у вас ничего не утекло, просто не максимально
[01:08:20.160 --> 01:08:33.840]  эффективно. Ну что поделаешь, константа 2 не очень страшна. Так, хорошо, на самом деле на это можно
[01:08:33.840 --> 01:08:41.840]  было бы и закончить, потому что, если я не ошибаюсь, в C++, по крайней мере, процедура pop back
[01:08:41.840 --> 01:08:48.600]  реализована просто уменьшением s на единичку, то есть буквально pop back это s минус равно 1.
[01:08:48.600 --> 01:08:56.320]  Ну ровно это мы и хотим, мы хотим, чтобы последний элемент забылся, мы сдвигаем указатель с последнего
[01:08:56.320 --> 01:09:02.880]  на предпоследний, уменьшаем размер на единицу. Это в принципе не очень плохо, это может быть
[01:09:02.880 --> 01:09:08.000]  неоптимально только в случае, когда, например, представьте, у вас пришло много push backs, вы сделали
[01:09:08.000 --> 01:09:13.160]  большой массив, потом много pop backs, вы удаляете, удаляете, удаляете, получаете маленький массив. То есть,
[01:09:13.160 --> 01:09:18.000]  если у вас много pop backs, тогда у вас массив может быть такой, у вас заполнена очень маленькая память,
[01:09:18.000 --> 01:09:29.120]  s маленькая, а c большое. Ну как-то странно, не очень хорошо. Вы у системы забрали вот столько ячеек,
[01:09:29.120 --> 01:09:40.440]  чтобы хранить вот столько. Ну что-то вы странное делаете. Да, я вот, написано же буквально, запросим новый
[01:09:40.440 --> 01:09:47.320]  массив, то есть создадим новый массив, перекопируем и сотрем старый. Ну потому что я не могу вот эту
