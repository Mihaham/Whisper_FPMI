[00:00.000 --> 00:16.000]  Отлично, у нас сегодня первая лекция, как я и обещал в прошлый раз, в прошлый раз я ничего не объяснял, а сегодня я обещаю, что я постараюсь объяснить, поэтому лекция будет очень простая и очень скучная.
[00:16.000 --> 00:25.000]  Если вы не любите скучные лекции, то срочно покиньте аудиторию. Но нам сегодня важно понять некоторые азы, некоторую базу, без которой жить дальше невозможно.
[00:25.000 --> 00:32.000]  Дальше мы будем говорить про какие-то более хитроумные вещи, а вот сегодня самый-самый простый класс для первой лекции.
[00:32.000 --> 00:38.000]  Но прежде чем мы перейдем к этому, вот смотрите картинка, тут какие-то процессоры сражаются за ячеек памяти.
[00:38.000 --> 00:43.000]  И о чем я хочу поговорить? Потому что я вижу эту картинку перед собой.
[00:43.000 --> 00:54.000]  Я вспомнил, что эта картинка из слайдов, сделанных для курса по замечательной книжке, которая называется Art of Multiprocessor Programming.
[00:54.000 --> 01:03.000]  Это книжка про concurrency, про то, как можно синхронизировать потоки и писать какие-то затеревы и структуры данных.
[01:03.000 --> 01:09.000]  Это очень любопытно, это очень интересно, особенно если вы любите алгоритмы, но курс наш не про это.
[01:09.000 --> 01:14.000]  Возможно, вы будете сожалеть, но вот чтобы вы не сожалели, вы можете открыть эту книжку и почитать ее.
[01:14.000 --> 01:19.000]  Она очень классная, там всякие деревья, списки, хэштаблицы мастерятся.
[01:19.000 --> 01:25.000]  Это увлекательно, но все-таки не совсем для промышленного программирования, поэтому мы это оставляем в стороне.
[01:25.000 --> 01:30.000]  Но если вдруг вам интересно, то почитайте, пожалуйста, она будет прям великолепна.
[01:30.000 --> 01:38.000]  Ну а мы говорим сегодня про более приземленные вещи, мы не будем сегодня делать лог-фри хэштаблицы, к сожалению.
[01:38.000 --> 01:41.000]  Мы поговорим про задачу взаимного исключения.
[01:41.000 --> 01:51.000]  У вас в первой домашней работе в задачах уже есть мьютексы, вы уже, возможно, учились пользоваться,
[01:51.000 --> 01:55.000]  но мы сегодня проговорим, как именно мы это делаем.
[01:55.000 --> 01:59.000]  И начнем мы с такого простого соображения.
[01:59.000 --> 02:03.000]  На первом семинаре, надеюсь, вы поговорили про то, что такое исполнение.
[02:03.000 --> 02:07.000]  У вас есть компьютер, там есть процессор, у него есть ядра, ядра работают с памятью,
[02:07.000 --> 02:11.000]  я читаю через instruction pointer инструкцию, у них есть call stack, чтобы выходить по коду.
[02:11.000 --> 02:18.000]  И за исполнение чего бы то ни было на этих ядрах отвечает операционная система.
[02:18.000 --> 02:22.000]  Там есть некоторые компоненты планировщик, которые пока для нас выглядят довольно магически,
[02:22.000 --> 02:26.000]  мы не понимаем, какой он устроен, мы до этого дойдем, а пока мы просто считаем,
[02:26.000 --> 02:31.000]  что он планирует наши процессы, наши задачи.
[02:31.000 --> 02:35.000]  В Linux можно корректно говорить task на эти самые ядра.
[02:35.000 --> 02:40.000]  И, конечно же, у планировщика задача, чтобы все таски, чтобы все процессы в системе,
[02:40.000 --> 02:45.000]  чтобы все потоки во всех процессах имели доступ к, собственно, процессору.
[02:45.000 --> 02:50.000]  Поэтому их периодически нужно снимать, этого процессора, переключать друг на друга.
[02:50.000 --> 02:53.000]  И с этим есть некоторая беда.
[02:53.000 --> 02:59.000]  Вот точки переключения потоков, они нами не наблюдаются, нами в смысле разработчика,
[02:59.000 --> 03:03.000]  нами в смысле программой. Это все происходит как-то скрыто через механизмы прерываний,
[03:03.000 --> 03:07.000]  но вот вы, когда пишете код, не думайте о прерываниях никаких, вы пишете просто в предположении,
[03:07.000 --> 03:11.000]  что у вас есть свой виртуальный процессор, который исполняет функцию main.
[03:11.000 --> 03:16.000]  Это некоторая абстракция, которая для вас операционную систему поддерживает.
[03:16.000 --> 03:20.000]  Но мы-то знаем, что это все немножко не так, что у нас нет своего процессора,
[03:20.000 --> 03:23.000]  что мы делим его с другими. И если вдруг у нас есть конкуренция,
[03:23.000 --> 03:27.000]  то мы понимаем, что потоки все-таки могут переключаться и перемешиваться.
[03:27.000 --> 03:29.000]  Собственно, возникает ситуация конкуренции.
[03:29.000 --> 03:33.000]  И в этой ситуации есть проблема, если эти потоки, если эти две операции,
[03:33.000 --> 03:37.000]  вот красные и синие, работают с какими-то общими данными.
[03:37.000 --> 03:44.000]  Пока может быть даже непонятно, что это за общие данные, но какой-то случай
[03:44.000 --> 03:51.000]  вы можете представить себе уже сейчас, если вы вообще писали какую-то программу в своей жизни.
[03:51.000 --> 03:54.000]  Вот представьте, что вы запускаете разные потоки, они что-то делают,
[03:54.000 --> 03:59.000]  может быть даже разные, может быть даже не работают с какими-то вашими данными общими.
[03:59.000 --> 04:03.000]  Но при этом у них есть все-таки некоторые общие данные, с которыми они работают,
[04:03.000 --> 04:10.000]  некоторое общее состояние. Вот понимаете ли вы, о чем я говорю?
[04:10.000 --> 04:14.000]  Вот может быть вы не сделали какую-то общую структуру данных,
[04:14.000 --> 04:19.000]  в которой эти потоки ходят, но тем не менее у них есть некоторый сервис,
[04:19.000 --> 04:23.000]  с которым они работают, который общий и внутри которого синхронизация
[04:23.000 --> 04:26.000]  между этими потоками все же необходима.
[04:26.000 --> 04:29.000]  Но это все же происходит внутри операционной…
[04:29.000 --> 04:32.000]  Во-первых, я не понял, что ты имел в виду.
[04:32.000 --> 04:37.000]  Какие-то структуры данных ядра, но они в ядре.
[04:37.000 --> 04:39.000]  В ядре конечно конкаренности очень много.
[04:39.000 --> 04:42.000]  В какой-то смысле очень правильный ответ, и можно закрыть тему.
[04:42.000 --> 04:46.000]  Но вот в твоей программе.
[04:46.000 --> 04:51.000]  Вот если твои потоки вообще алоцируют память динамическую,
[04:51.000 --> 04:54.000]  то видимо они посещают один и тот же аллокатор.
[04:54.000 --> 04:56.000]  Аллокаторы устроены, конечно, по-разному.
[04:56.000 --> 05:00.000]  Не то чтобы все устроены одинаково, но в конце концов,
[05:00.000 --> 05:04.000]  где-то в недрах аллокаторов все равно нужна синхронизация между потоками.
[05:04.000 --> 05:07.000]  Вот можно себе представить хоть наивный аллокатор,
[05:07.000 --> 05:11.000]  который выделяет разом себе арены памяти,
[05:11.000 --> 05:14.000]  с помощью вызова мэп получает себе много страниц,
[05:14.000 --> 05:17.000]  нарезает их на кусочки, и когда программа приходит в вызов new,
[05:17.000 --> 05:22.000]  вы пишете new или malloc, то вы приходите в аллокатор,
[05:22.000 --> 05:27.000]  и аллокатор вот из какой-то арена оторвает кусочек и дает его вам.
[05:27.000 --> 05:32.000]  А потом вы говорите free или de-read, и этот кусочек от аллокатора возвращается.
[05:32.000 --> 05:34.000]  Что делать с этими кусочками аллокатор?
[05:34.000 --> 05:38.000]  Вот у него была большая арена памяти, она была разбита на маленькие фрагменты,
[05:38.000 --> 05:42.000]  и теперь часть из них используется программой, а часть не используется.
[05:42.000 --> 05:46.000]  Опять, аллокаторы действуют по-разному, в них много слоев,
[05:46.000 --> 05:52.000]  может быть, мы на одной из лекций даже про это поговорим в контексте забавного лог-фри бага.
[05:52.000 --> 05:56.000]  Но в первом приближении можно представить себе, что в аллокаторе, наверное,
[05:56.000 --> 05:59.000]  где-то есть список свободных блоков, что вот есть список, и у него провязываются блоки.
[05:59.000 --> 06:04.000]  И вы с этим списком работаете, ну, в смысле, вы потоки, которые обращаются к аллокатору за памятью.
[06:04.000 --> 06:07.000]  Вот это уже место, где нужно делать синхронизацию.
[06:07.000 --> 06:11.000]  Этим, конечно, занимаетесь не вы, а разработчики аллокаторов, тем не менее, синхронизация есть.
[06:11.000 --> 06:16.000]  И вот есть этот общий список. Ну и давайте подумаем, что делать,
[06:16.000 --> 06:20.000]  что будет происходить с этим списком, если к нему будут приходить разные потоки.
[06:20.000 --> 06:24.000]  Пусть список даже самый элементарный, пусть он односвязный.
[06:24.000 --> 06:27.000]  Вот у меня здесь какой-то код, я не знаю, видите его, хорошо видите?
[06:27.000 --> 06:29.000]  Или нужно сделать крупнее?
[06:32.000 --> 06:35.000]  Не стесняйтесь, пока есть возможность.
[06:37.000 --> 06:39.000]  Давайте попробуем.
[06:41.000 --> 06:43.000]  Ну, чуть-чуть лучше стало.
[06:43.000 --> 06:45.000]  Вот список.
[06:45.000 --> 06:47.000]  Ну, он такой абсолютно игрушечный, и в аллокаторе его не можно,
[06:47.000 --> 06:49.000]  потому что в аллокаторе вы не можете использовать Нью,
[06:49.000 --> 06:51.000]  потому что вы реализуете Нью, в конце концов.
[06:51.000 --> 06:53.000]  Списки должны быть интрузивными, если вы знаете, что это.
[06:53.000 --> 06:58.000]  Ну, вот просто пример односвязанного списка, в узлах которого ничего нет.
[06:58.000 --> 07:04.000]  Мы просто умеем делать пуш, алоцировать новый узел, привязывать его к старой голове, менять голову.
[07:04.000 --> 07:10.000]  И мы можем извлекать первый узел из этого списка, ударять его.
[07:10.000 --> 07:12.000]  Ну, а теперь что мы делаем?
[07:12.000 --> 07:14.000]  Мы проверяем, что он как-то работает, это не очень интересно.
[07:14.000 --> 07:19.000]  А дальше мы запускаем потоки, которые на разных ядрах, может быть параллельно, может быть конкурентно,
[07:19.000 --> 07:21.000]  будут с этим списком работать.
[07:21.000 --> 07:24.000]  Они будут сто пятьсот раз добавлять в него узел, потом извлекать.
[07:24.000 --> 07:29.000]  Ну, очевидно, что список никогда не бывает... никогда не бывает underflow в этом списке,
[07:29.000 --> 07:31.000]  что мы никогда не извлекаем из пустого.
[07:31.000 --> 07:33.000]  Так что тест, в общем, похож на корректный, да?
[07:33.000 --> 07:35.000]  Ну, вот мы запустим эту программу.
[07:35.000 --> 07:37.000]  Что с ней может пойти не так?
[07:41.000 --> 07:45.000]  Ну, давайте запустим. Тут сборка с адрес-санитайзером.
[07:45.000 --> 07:47.000]  Вот видите, heap-news of the free.
[07:47.000 --> 07:49.000]  Вот возникла какая-то ошибка.
[07:49.000 --> 07:53.000]  Вот. Давайте попробуем вытрясти другую ошибку.
[07:53.000 --> 07:56.000]  Не знаю, когда это получится, может быть, никогда.
[07:56.000 --> 07:58.000]  Может быть, меня будет бесконечно долго не вести.
[07:58.000 --> 07:59.000]  Такое тоже возможно.
[07:59.000 --> 08:00.000]  Ну, в конце концов, я брошу.
[08:00.000 --> 08:01.000]  Ну, вдруг повезет.
[08:01.000 --> 08:03.000]  О, смотрите, double free получился.
[08:03.000 --> 08:06.000]  Вот видите, проблемы в этом коде есть, они разные.
[08:06.000 --> 08:10.000]  И проблема, видимо, в том, что мы не синхронизируем доступ к этому объекту.
[08:10.000 --> 08:12.000]  И вот что может случиться?
[08:12.000 --> 08:14.000]  Ну, вот смотрите, давайте с push-а начнем.
[08:14.000 --> 08:17.000]  Что может пойти не так с push-ем?
[08:26.000 --> 08:28.000]  Вот пусть у нас два push-а конкурируют.
[08:28.000 --> 08:30.000]  К чему это может привести?
[08:30.000 --> 08:35.000]  Вот конкурирует, это означает, что, смотрите, у нас планировщик может снять нас поток
[08:35.000 --> 08:36.000]  с ядра в любой момент.
[08:36.000 --> 08:39.000]  Ну, то есть буквально между каждыми двумя строчками.
[08:43.000 --> 08:45.000]  Ну, что такое атомарно, это интересный вопрос.
[08:45.000 --> 08:48.000]  И мы, собственно, к этому хотим прийти рано или поздно.
[08:48.000 --> 08:54.000]  Ну, вот пока можно считать, наверное, что вот это присваивание – это атомарная операция.
[08:54.000 --> 08:58.000]  Вот никто не может наблюдать ее посередине.
[08:58.000 --> 09:01.000]  У нас есть регистр, в котором уже прочитана, пусть голова списка,
[09:01.000 --> 09:04.000]  мы пишем ее в какую-то память, в какой-то ячейку памяти,
[09:04.000 --> 09:06.000]  но вот это происходит, допустим, атомарно.
[09:11.000 --> 09:13.000]  Так я говорю, давайте два push-а возьмем.
[09:27.000 --> 09:29.000]  Ну, вот у нас есть два push-а.
[09:29.000 --> 09:31.000]  Они алоцировали два узла памяти.
[09:31.000 --> 09:35.000]  И они оба выполняют вторую строчку этого push-а.
[09:35.000 --> 09:39.000]  И вот так получилось, что сначала они выполнили первые строчки,
[09:39.000 --> 09:41.000]  а потом они оба выполнили вторые строчки.
[09:41.000 --> 09:45.000]  И в итоге оказалось, что вот так вот, что они теперь привязались к одной и той же голове.
[09:49.000 --> 09:50.000]  Плохо это?
[09:52.000 --> 09:54.000]  Ну, кажется, у нас утечка памяти.
[09:55.000 --> 09:58.000]  То есть у нас узел, который теперь недостижим из головы.
[10:00.000 --> 10:01.000]  Неприятно.
[10:04.000 --> 10:07.000]  Давайте теперь подумаем, что может произойти с конкуренцией POP.
[10:09.000 --> 10:11.000]  Вот, мы потеряли один из узлов.
[10:13.000 --> 10:15.000]  Тут вообще уже разные варианты могут быть.
[10:15.000 --> 10:19.000]  И вот те ошибки, которые у нас выпали, они вот выпали в разных сценариях.
[10:19.000 --> 10:22.000]  То есть у нас проблема, конечно, не детерминированная,
[10:22.000 --> 10:24.000]  но в зависимости от того, как именно не детерминированно
[10:24.000 --> 10:26.000]  планировщик будет перевершать эти потоки,
[10:26.000 --> 10:28.000]  реализуется либо одна проблема, либо другая.
[10:28.000 --> 10:30.000]  Вот давайте какую-нибудь выберем.
[10:33.000 --> 10:35.000]  Ну, вот опять похожая ситуация.
[10:35.000 --> 10:37.000]  Выполнили по первой строчке, выполнили по второй строчке.
[10:39.000 --> 10:41.000]  И что теперь получилось?
[10:42.000 --> 10:45.000]  Два потока собираются удалить один и тот же первый узел.
[10:46.000 --> 10:48.000]  Это вот ситуация как раз double free.
[10:48.000 --> 10:52.000]  Мы вызываем на одной и той же памяти, дважды освобождаем одну и ту же память.
[10:53.000 --> 10:57.000]  Ну, конечно, на C++, если вы просто соберете программу и там сделаете double free,
[10:57.000 --> 10:59.000]  то никакой ошибки double free.
[10:59.000 --> 11:01.000]  Вот с таким вот стеком у вас не будет, конечно.
[11:01.000 --> 11:04.000]  Это специально инструментированный код,
[11:04.000 --> 11:06.000]  который в runtime еще поддерживает какие-то структуры данных.
[11:06.000 --> 11:09.000]  Это называется адрес санитайзера, общий санитайзер C++.
[11:09.000 --> 11:11.000]  Необходимый для разработки инструмент.
[11:11.000 --> 11:13.000]  Вот про него пойдет речь на одном из семинаров.
[11:13.000 --> 11:15.000]  Поэтому, пожалуйста, не пропустите его.
[11:15.000 --> 11:18.000]  Ну, вот он для нас показывает, что возникло double free.
[11:18.000 --> 11:20.000]  Другая проблема.
[11:21.000 --> 11:23.000]  Видите ли вы ее?
[11:24.000 --> 11:26.000]  Она в какой-то степени похожа,
[11:26.000 --> 11:28.000]  но вот все-таки
[11:29.000 --> 11:31.000]  она не в локаторе, допустим, возникает.
[11:32.000 --> 11:35.000]  Вот вызвали мы delete под хеда,
[11:35.000 --> 11:39.000]  а потом в другом параллельном процессе пытаемся по этому же адресу.
[11:39.000 --> 11:42.000]  Ну, чуть аккуратнее. Мы про потоки говорим здесь.
[11:42.000 --> 11:44.000]  С процессами мы их не путаем.
[11:44.000 --> 11:48.000]  Ну, вот один поток, первый поток прочел хед, второй прочел хед.
[11:49.000 --> 11:52.000]  А дальше первый поток прошел весь поп до конца.
[11:52.000 --> 11:55.000]  То есть он перекинул ссылку и удалил этот первый узел.
[11:56.000 --> 12:00.000]  А теперь второй узел, второй поток идет и читает next
[12:00.000 --> 12:02.000]  за старым хедом.
[12:02.000 --> 12:05.000]  Вот эта память, в которой живет поле next,
[12:05.000 --> 12:07.000]  в которой живет алоцированный ранее узел,
[12:07.000 --> 12:09.000]  она уже отдана локатору.
[12:10.000 --> 12:12.000]  Ну, это явно проблема, да?
[12:12.000 --> 12:14.000]  То есть явно в программе баг.
[12:14.000 --> 12:18.000]  Но довольно плохо, что если вы вот соберете
[12:18.000 --> 12:21.000]  программу вашу без инструментации, без санитайзера,
[12:21.000 --> 12:24.000]  то, скорее всего, бага у вас не будет. Почему?
[12:24.000 --> 12:26.000]  Потому что когда вы...
[12:26.000 --> 12:28.000]  Не то, что бага не будет, баг будет, разумеется.
[12:28.000 --> 12:30.000]  Ошибки не будут во время исполнения,
[12:30.000 --> 12:32.000]  потому что вы отдадите память локатору.
[12:32.000 --> 12:34.000]  А что он с ней сделает?
[12:34.000 --> 12:36.000]  Он же не отдаст ей операционной системе.
[12:36.000 --> 12:38.000]  Он просто запомнит, что этот блок свободен
[12:38.000 --> 12:40.000]  и потом выдаст его кому-то другому.
[12:42.000 --> 12:44.000]  Вот. И вот вы прочитаете какой-то совершенно
[12:44.000 --> 12:46.000]  мусорный адрес потом из этого блока.
[12:46.000 --> 12:48.000]  И что, возможно, еще хуже.
[12:48.000 --> 12:51.000]  Потому что у вас вот проблема распространяется
[12:51.000 --> 12:53.000]  по вашей программе.
[12:53.000 --> 12:55.000]  Какие из этого уроки?
[12:55.000 --> 12:57.000]  Что нужно синхронизировать потоки,
[12:57.000 --> 12:59.000]  и нужно падать как можно раньше.
[12:59.000 --> 13:01.000]  Это только ошибка возникла, лучше сразу упасть.
[13:01.000 --> 13:03.000]  Вот санитайзер здесь вам помогает.
[13:03.000 --> 13:05.000]  Без санитайзера было бы довольно печально.
[13:05.000 --> 13:07.000]  Ну и что же мы в такой ситуации можем сделать,
[13:07.000 --> 13:10.000]  если мы хотим все-таки этот список заставить работать?
[13:10.000 --> 13:12.000]  У нас для этого есть очень наивное,
[13:12.000 --> 13:14.000]  очень простое решение.
[13:14.000 --> 13:16.000]  Нам нужен Mutex.
[13:16.000 --> 13:18.000]  Вот мы хотим, чтобы наши операции
[13:18.000 --> 13:20.000]  были логически атомарными.
[13:20.000 --> 13:22.000]  Вот чтобы случался push,
[13:22.000 --> 13:24.000]  либо случался pop,
[13:24.000 --> 13:26.000]  и как будто разом друг относительно друга.
[13:26.000 --> 13:28.000]  Вот атомарность, я здесь говорю
[13:28.000 --> 13:30.000]  не в каком-то строгом смысле.
[13:30.000 --> 13:32.000]  На самом деле, атомарность слова можно формализовать
[13:32.000 --> 13:34.000]  и можно формализовать по-разному.
[13:34.000 --> 13:36.000]  И скажем, в курсе про сприлетные системы
[13:36.000 --> 13:38.000]  я буду говорить очень четко,
[13:38.000 --> 13:40.000]  очень сложные определения.
[13:40.000 --> 13:42.000]  Но пока мы считаем,
[13:42.000 --> 13:44.000]  что атомарность в каком-то таком
[13:44.000 --> 13:46.000]  естественном смысле для нас
[13:46.000 --> 13:48.000]  интуитивно понятном.
[13:48.000 --> 13:50.000]  Но я сразу замечу, что атомарность
[13:50.000 --> 13:52.000]  всегда относительно чего-то.
[13:52.000 --> 13:54.000]  Вот нет абсолютно атомарности.
[13:54.000 --> 13:56.000]  Вот мы, конечно же, не можем сделать
[13:56.000 --> 13:58.000]  эти методы атомарными,
[13:58.000 --> 14:00.000]  потому что там несколько инструкций процессора.
[14:00.000 --> 14:02.000]  Тамолокатор вызывается.
[14:02.000 --> 14:04.000]  Сложная логика.
[14:04.000 --> 14:06.000]  Но мы хотим, чтобы относительно друга
[14:06.000 --> 14:08.000]  эти операции выполнялись атомарно.
[14:08.000 --> 14:10.000]  Это мы можем достичь.
[14:10.000 --> 14:12.000]  Но всегда есть уровень ниже,
[14:12.000 --> 14:14.000]  где атомарности уже, конечно, никакой нет.
[14:18.000 --> 14:20.000]  Ну, я не знаю, насколько вообще в мире
[14:20.000 --> 14:22.000]  много всего действительно атомарного,
[14:22.000 --> 14:24.000]  и с какого уровня все начинается.
[14:24.000 --> 14:26.000]  Ну, явно на уровне этого кода,
[14:26.000 --> 14:28.000]  на уровне компьютера там ничего атомарного нет.
[14:28.000 --> 14:30.000]  В конце концов, у тебя есть процессор,
[14:30.000 --> 14:32.000]  он дико сложный,
[14:32.000 --> 14:34.000]  там вот много всего происходит.
[14:34.000 --> 14:36.000]  Конечно же, запись ячейки в памяти
[14:36.000 --> 14:38.000]  это не атомарное действие,
[14:38.000 --> 14:40.000]  в смысле физически не атомарное.
[14:40.000 --> 14:42.000]  Там много всего задействовано.
[14:42.000 --> 14:44.000]  Но вот мы хотим, чтобы
[14:44.000 --> 14:46.000]  логически эти операции были атомарными.
[14:46.000 --> 14:48.000]  И для этого у нас...
[14:48.000 --> 14:50.000]  Ну, вот смотрите, что есть.
[14:50.000 --> 14:52.000]  У нас есть mutex.
[14:52.000 --> 14:54.000]  Что он позволяет нам сделать?
[14:54.000 --> 14:56.000]  Он дает нам всего лишь два метода.
[14:56.000 --> 14:58.000]  Log и Unlock.
[14:58.000 --> 15:00.000]  То есть это
[15:00.000 --> 15:02.000]  некоторый разделаемый объект,
[15:02.000 --> 15:04.000]  ссылку на который держат оба потока,
[15:04.000 --> 15:06.000]  которые обращаются с общими данными.
[15:06.000 --> 15:08.000]  И перед тем, как обращаться
[15:08.000 --> 15:10.000]  к разделяемым данным, мы говорим mutex log
[15:10.000 --> 15:12.000]  или захватываем mutex.
[15:12.000 --> 15:14.000]  А когда мы закончим
[15:14.000 --> 15:16.000]  с разделяемыми данными, мы отпускаем
[15:16.000 --> 15:18.000]  log.
[15:18.000 --> 15:20.000]  Тот код, который оказался посередине, мы называем
[15:20.000 --> 15:22.000]  критической секцией.
[15:22.000 --> 15:24.000]  Да.
[15:26.000 --> 15:28.000]  Ну, нужно, наверное, разобраться,
[15:28.000 --> 15:30.000]  каких свойств мы от этих операций ожидаем.
[15:30.000 --> 15:32.000]  Нас интересует в первую очередь наблюдаемое поведение,
[15:32.000 --> 15:34.000]  а не как они реализованы.
[15:34.000 --> 15:36.000]  А как они реализованы, ты напишешь
[15:36.000 --> 15:38.000]  в домашней работе.
[15:38.000 --> 15:40.000]  Так что всему свое время.
[15:44.000 --> 15:46.000]  Как запустить поток?
[15:46.000 --> 15:48.000]  Мы вроде бы
[15:48.000 --> 15:50.000]  смотрели в прошлый раз.
[15:50.000 --> 15:52.000]  Секундочку.
[15:54.000 --> 15:56.000]  Давай я еще раз покажу.
[16:02.000 --> 16:04.000]  Вот мы сконструировали поток,
[16:04.000 --> 16:06.000]  он запустился.
[16:06.000 --> 16:08.000]  Ну, как именно...
[16:08.000 --> 16:10.000]  Что именно происходит,
[16:10.000 --> 16:12.000]  когда мы запустим поток,
[16:12.000 --> 16:14.000]  что именно происходит в этот момент,
[16:14.000 --> 16:16.000]  это сложный вопрос. Мы откладываем его
[16:16.000 --> 16:18.000]  на четвертую лекцию.
[16:18.000 --> 16:20.000]  Пока,
[16:20.000 --> 16:22.000]  можно считать, что мы пользуемся
[16:22.000 --> 16:24.000]  такой магией, мы запускаем потоки
[16:24.000 --> 16:26.000]  вот так, конструируя экземпляры std.red.
[16:26.000 --> 16:28.000]  Но я
[16:28.000 --> 16:30.000]  на следующей лекции уже объясню, как
[16:30.000 --> 16:32.000]  на самом деле мы запускаем потоки, и что мы их запускать
[16:32.000 --> 16:34.000]  вообще-то не хотим. Это
[16:34.000 --> 16:36.000]  странная затея для наших целей, потому что я
[16:36.000 --> 16:38.000]  на прошлой лекции объяснял, что
[16:38.000 --> 16:40.000]  если мы запускаем много поток,
[16:40.000 --> 16:42.000]  это что-то неэффективное, мы хотим не потоки
[16:42.000 --> 16:44.000]  запускать. В общем, у нас будет
[16:44.000 --> 16:46.000]  полпоток, там мы все это проговорим.
[16:46.000 --> 16:48.000]  Пока достаточно какого-то
[16:48.000 --> 16:50.000]  вот такого базового представления.
[16:50.000 --> 16:52.000]  Конструируем std.red, передаем туда
[16:52.000 --> 16:54.000]  функцию, лямбду, и она
[16:54.000 --> 16:56.000]  исполняется независимо.
[16:58.000 --> 17:00.000]  Это нам даже не
[17:00.000 --> 17:02.000]  столько важно. Нам главное сейчас понимать,
[17:02.000 --> 17:04.000]  что может быть на двух ядрах
[17:04.000 --> 17:06.000]  или даже на одном, но
[17:06.000 --> 17:08.000]  с вытеснением, с переключениями
[17:08.000 --> 17:10.000]  контекста, два исполнения,
[17:10.000 --> 17:12.000]  которые живут в одном и том же
[17:12.000 --> 17:14.000]  виртуальном адресном пространстве, которые работают
[17:14.000 --> 17:16.000]  с общими ящиками памяти.
[17:18.000 --> 17:20.000]  Если это понятно, окажется, после
[17:20.000 --> 17:22.000]  семинара это должно быть понятно, что
[17:22.000 --> 17:24.000]  такое исполнение, то можно представить
[17:24.000 --> 17:26.000]  себя, что их два, что память у них
[17:26.000 --> 17:28.000]  общая, виртуальная,
[17:28.000 --> 17:30.000]  и вот они обращаются к некоторой
[17:30.000 --> 17:32.000]  структуре данных.
[17:32.000 --> 17:34.000]  И она после этого ломается.
[17:34.000 --> 17:36.000]  Ну вот,
[17:36.000 --> 17:38.000]  вернемся к
[17:38.000 --> 17:40.000]  Mutex.
[17:42.000 --> 17:44.000]  В чем его замысел?
[17:44.000 --> 17:46.000]  Mutex, почему он так называется? Взаимные исключения.
[17:46.000 --> 17:48.000]  Видимо,
[17:48.000 --> 17:50.000]  он пытается гарантировать следующее
[17:50.000 --> 17:52.000]  простое свойство, что между
[17:52.000 --> 17:54.000]  вызовами lock и unlock
[17:54.000 --> 17:56.000]  может находиться только один поток.
[17:58.000 --> 18:00.000]  Если какой-то поток сейчас
[18:00.000 --> 18:02.000]  уже захватил Mutex, владеет
[18:02.000 --> 18:04.000]  им, находится между этими
[18:04.000 --> 18:06.000]  вызовами, то другой поток,
[18:06.000 --> 18:08.000]  который пришел и вызвал lock,
[18:08.000 --> 18:10.000]  будет ждать, пока первый не вызовет
[18:10.000 --> 18:12.000]  unlock. Ну то есть, вот эти методы
[18:12.000 --> 18:14.000]  lock и unlock, они как-то могут пересекаться
[18:14.000 --> 18:16.000]  во времени, критические секции не могут.
[18:18.000 --> 18:20.000]  Пока первый поток не отпустит Mutex, второй его захватить
[18:20.000 --> 18:22.000]  не сможет. Он будет дожидаться.
[18:24.000 --> 18:26.000]  Если вопросы есть, самые простые,
[18:26.000 --> 18:28.000]  задавайте, пожалуйста.
[18:28.000 --> 18:30.000]  Чтобы всем было понятно.
[18:32.000 --> 18:34.000]  Ну и
[18:34.000 --> 18:36.000]  стоит, наверное, лексику еще
[18:36.000 --> 18:38.000]  прокомментировать, говорят часто, что Mutex
[18:38.000 --> 18:40.000]  защищает разделяемый объект. Ну вот есть картинка,
[18:40.000 --> 18:42.000]  где Mutex, вот этот дядька с ружьем,
[18:42.000 --> 18:44.000]  он
[18:44.000 --> 18:46.000]  короче,
[18:48.000 --> 18:50.000]  контролирует ситуацию.
[18:50.000 --> 18:52.000]  Здесь есть явно вот этот пренек,
[18:52.000 --> 18:54.000]  это кто? Это поток,
[18:54.000 --> 18:56.000]  вот эта кабинка, это критическая секция, там
[18:56.000 --> 18:58.000]  то, что находится внутри, это видим разделяемые данные
[18:58.000 --> 19:00.000]  какие-то, которым не нужно обращаться
[19:00.000 --> 19:02.000]  именно. Вот это
[19:02.000 --> 19:04.000]  Mutex. В общем, все очень понятно.
[19:04.000 --> 19:06.000]  Ну и вот, еще раз прокомментирую,
[19:06.000 --> 19:08.000]  лексика защищает, захватывает, отпускает.
[19:08.000 --> 19:10.000]  Вот так люди говорят, и вы тоже
[19:10.000 --> 19:12.000]  можете говорить. Ну и имеем
[19:12.000 --> 19:14.000]  Mutex, мы можем любой
[19:14.000 --> 19:16.000]  структуру данных сделать потока безопасной.
[19:16.000 --> 19:18.000]  Каким образом?
[19:18.000 --> 19:20.000]  Мы можем просто все операции, которые должны быть
[19:20.000 --> 19:22.000]  атомарны, т.е. на друг друга, завернуть в критическую секцию.
[19:22.000 --> 19:24.000]  Вот у нас есть Mutex,
[19:26.000 --> 19:28.000]  у нас есть, точнее, вот голова,
[19:28.000 --> 19:30.000]  у нас есть Mutex, который будет защищать
[19:30.000 --> 19:32.000]  работу с этой головой,
[19:32.000 --> 19:34.000]  ну и как бы наивно
[19:34.000 --> 19:36.000]  можем поступить, написать вот такой вот код.
[19:36.000 --> 19:38.000]  Так не надо делать,
[19:38.000 --> 19:40.000]  но пока пусть так.
[19:40.000 --> 19:42.000]  Помогло ли это нам?
[19:46.000 --> 19:48.000]  Ну кажется, что помогло.
[19:52.000 --> 19:54.000]  Но, конечно же, вот
[19:54.000 --> 19:56.000]  прям так код писать не нужно.
[19:56.000 --> 19:58.000]  Ну и, конечно,
[19:58.000 --> 20:00.000]  мы можем
[20:00.000 --> 20:02.000]  все операции, которые должны быть
[20:02.000 --> 20:04.000]  атомарны, т.е. на друг друга,
[20:04.000 --> 20:06.000]  ну и как бы наивно
[20:06.000 --> 20:08.000]  мы можем просто
[20:08.000 --> 20:10.000]  так код писать не нужно.
[20:10.000 --> 20:12.000]  Вот совсем не стоит
[20:12.000 --> 20:14.000]  так писать код. Почему?
[20:16.000 --> 20:18.000]  Нет, вот, как раз
[20:18.000 --> 20:20.000]  два разных Mutex не нужны.
[20:20.000 --> 20:22.000]  Что?
[20:24.000 --> 20:26.000]  Это
[20:26.000 --> 20:28.000]  хорошее замечание, вот да,
[20:28.000 --> 20:30.000]  давайте
[20:30.000 --> 20:32.000]  вот можно написать так,
[20:32.000 --> 20:34.000]  так будет лучше.
[20:34.000 --> 20:36.000]  Ну и лучше не в этом смысле,
[20:36.000 --> 20:38.000]  потому что это будет оптимальней.
[20:38.000 --> 20:40.000]  Да, действительно, мы можем с локатором
[20:40.000 --> 20:42.000]  работать параллельно. Если локатор хорошо написан,
[20:42.000 --> 20:44.000]  он действительно вот распараллельно
[20:44.000 --> 20:46.000]  два этих вызывания из разных поток,
[20:46.000 --> 20:48.000]  потому что там какие-то радолокальные кэши.
[20:48.000 --> 20:50.000]  Но я скорее про то,
[20:50.000 --> 20:52.000]  как Mutex'ам пользоваться, в смысле,
[20:52.000 --> 20:54.000]  лок и анлок вызывать.
[20:54.000 --> 20:56.000]  Вот можно делать так наивно,
[20:56.000 --> 20:58.000]  но это попирает все
[20:58.000 --> 21:00.000]  идиомы языка C++,
[21:00.000 --> 21:02.000]  а именно идиомы райя.
[21:02.000 --> 21:04.000]  Захват ресурс, есть инициализация.
[21:04.000 --> 21:06.000]  Вот знаете ли вы про умные указатели?
[21:06.000 --> 21:08.000]  Вот они вам
[21:08.000 --> 21:10.000]  позволяют выделить память и потом ее
[21:10.000 --> 21:12.000]  освободить тогда, когда она больше не нужна.
[21:12.000 --> 21:14.000]  Когда разрушится единственный веник
[21:14.000 --> 21:16.000]  pointer или когда пропадет последняя разделяемая ссылка
[21:16.000 --> 21:18.000]  в виде shared pointer на объект.
[21:18.000 --> 21:20.000]  То есть мы связываем
[21:20.000 --> 21:22.000]  время жизни некоторого объекта
[21:22.000 --> 21:24.000]  и некоторые операции.
[21:24.000 --> 21:26.000]  То есть мы
[21:26.000 --> 21:28.000]  владеем ресурсом в течение некоторого времени
[21:28.000 --> 21:30.000]  и это вот владение выражено в lifetime
[21:30.000 --> 21:32.000]  какого-то объекта, lifetime объект разрушается
[21:32.000 --> 21:34.000]  и ресурс освобождается.
[21:34.000 --> 21:36.000]  Вот здесь у нас тоже есть
[21:36.000 --> 21:38.000]  некоторые разделяемые...
[21:38.000 --> 21:40.000]  некоторые ресурсы, мы хотим завладеть
[21:40.000 --> 21:42.000]  доступом к некоторому объекту
[21:42.000 --> 21:44.000]  и время нашего владения ограничено
[21:44.000 --> 21:46.000]  вызовом функции, у нее есть какой-то
[21:46.000 --> 21:48.000]  понятный scope. Что мы для этого делаем?
[21:48.000 --> 21:50.000]  Мы используем рай, мы говорим...
[21:50.000 --> 21:52.000]  Вот, код абсолютно эквивалентный.
[21:54.000 --> 21:56.000]  Что здесь происходит? В конструкторе
[21:56.000 --> 21:58.000]  этого объекта мы вызываем lock,
[21:58.000 --> 22:00.000]  в деструкторе мы вызываем unlock.
[22:00.000 --> 22:02.000]  В итоге mutex unlock вызывается
[22:02.000 --> 22:04.000]  вот где-то
[22:04.000 --> 22:06.000]  здесь.
[22:06.000 --> 22:08.000]  Но это вы тоже, наверное, знаете, да?
[22:08.000 --> 22:10.000]  Если вы решали первый раз
[22:10.000 --> 22:12.000]  что-то делать, то это
[22:12.000 --> 22:14.000]  будет очень сложно.
[22:14.000 --> 22:16.000]  Но если вы решили второй раз, то это
[22:16.000 --> 22:18.000]  будет очень сложно.
[22:18.000 --> 22:20.000]  Ну, если вы решали первую домашню,
[22:20.000 --> 22:22.000]  то вы вот что-то уже знаете.
[22:22.000 --> 22:24.000]  Хорошо. Пожалуйста, обращаю
[22:24.000 --> 22:26.000]  ваше внимание, что
[22:26.000 --> 22:28.000]  вот нужно использовать
[22:28.000 --> 22:30.000]  именно LockGuard, а не
[22:30.000 --> 22:32.000]  Uniclock, который похож и который также
[22:32.000 --> 22:34.000]  можно здесь написать.
[22:36.000 --> 22:38.000]  И тоже все будет работать.
[22:40.000 --> 22:42.000]  Вот если вы читали документацию
[22:42.000 --> 22:44.000]  про Uniclock и про LockGuard,
[22:44.000 --> 22:46.000]  скажите мне,
[22:46.000 --> 22:48.000]  было такое?
[22:48.000 --> 22:50.000]  А про Uniclock нет?
[22:50.000 --> 22:52.000]  Ну, возможно и рано,
[22:52.000 --> 22:54.000]  оно пригодится в следующий раз.
[22:54.000 --> 22:56.000]  Есть два объекта, они оба в конструкторе
[22:56.000 --> 22:58.000]  берут lock, в деструкторе освобождают lock.
[22:58.000 --> 23:00.000]  Но вот LockGuard занимается
[23:00.000 --> 23:02.000]  только этим.
[23:02.000 --> 23:04.000]  Он ничего больше не умеет,
[23:04.000 --> 23:06.000]  я надеюсь.
[23:06.000 --> 23:08.000]  Почти, да?
[23:08.000 --> 23:10.000]  Вроде не умеет.
[23:10.000 --> 23:12.000]  Вот только этого нам сейчас
[23:12.000 --> 23:14.000]  не хватало, если честно.
[23:14.000 --> 23:16.000]  Есть конструктор и деструктор,
[23:16.000 --> 23:18.000]  методов нет. Он создается,
[23:18.000 --> 23:20.000]  захватывает lock, разрушается, отпускает lock.
[23:20.000 --> 23:22.000]  Есть Uniclock, который делает то же самое,
[23:22.000 --> 23:24.000]  но у него есть вот ручка,
[23:24.000 --> 23:26.000]  чтобы отпустить lock.
[23:26.000 --> 23:28.000]  И можно использовать, в принципе,
[23:28.000 --> 23:30.000]  тот и другой, но не нужно.
[23:30.000 --> 23:32.000]  Вот нужно использовать тот класс,
[23:32.000 --> 23:34.000]  которого достаточно.
[23:34.000 --> 23:38.000]  И у него есть
[23:38.000 --> 23:40.000]  класс, которого достаточно.
[23:40.000 --> 23:42.000]  Если вам нужно только залочить,
[23:42.000 --> 23:44.000]  а в конце скопа разлочит Mutex,
[23:44.000 --> 23:46.000]  то вы используете LockGuard.
[23:46.000 --> 23:48.000]  А если вы используете Uniclock,
[23:48.000 --> 23:50.000]  то помните, что вы пишете код
[23:50.000 --> 23:52.000]  не для компьютера, не для компилятора,
[23:52.000 --> 23:54.000]  а для коллеги вашего, который будет его читать.
[23:54.000 --> 23:56.000]  Если он увидит у вас другой класс Uniclock,
[23:56.000 --> 23:58.000]  а вы не пользуетесь его
[23:58.000 --> 24:00.000]  какой-то избыточной функциональностью,
[24:00.000 --> 24:02.000]  то он будет гадать, зачем же вы сделали именно так.
[24:08.000 --> 24:10.000]  Ну, в зависимости от того,
[24:10.000 --> 24:12.000]  как у тебя написан код,
[24:12.000 --> 24:14.000]  если ты хочешь вот...
[24:14.000 --> 24:16.000]  Если тебе нужно после этого блока
[24:16.000 --> 24:18.000]  Mutex отпустить и сделать что-то
[24:18.000 --> 24:20.000]  еще уже без Mutex,
[24:20.000 --> 24:22.000]  то, конечно, тебе, наверное,
[24:22.000 --> 24:24.000]  стоит написать вот такой вот код.
[24:26.000 --> 24:28.000]  Но если здесь ничего нет,
[24:28.000 --> 24:30.000]  вот просто здесь конец функции,
[24:30.000 --> 24:32.000]  то зачем?
[24:32.000 --> 24:34.000]  Ну...
[24:34.000 --> 24:36.000]  Ну, смысловую нагрузку
[24:36.000 --> 24:38.000]  это будет нести точно так же, как MutexLock
[24:38.000 --> 24:40.000]  и MutexUnlock.
[24:40.000 --> 24:42.000]  Ну, в смысле, это такой вариант,
[24:42.000 --> 24:44.000]  но Uniclock, LockGuard
[24:44.000 --> 24:46.000]  ровно это и делает.
[24:48.000 --> 24:50.000]  Потому что это
[24:50.000 --> 24:52.000]  идеоматичный C++.
[24:52.000 --> 24:54.000]  Ну, вот, смотри.
[24:54.000 --> 24:56.000]  Есть вот такой вот код.
[24:56.000 --> 24:58.000]  Тут он, кажется, не дописан.
[25:00.000 --> 25:02.000]  Вот.
[25:02.000 --> 25:04.000]  Вот представьте себе,
[25:04.000 --> 25:06.000]  что мы в этом коде
[25:06.000 --> 25:08.000]  использовали бы MutexLock, MutexUnlock.
[25:08.000 --> 25:10.000]  С какими проблемами вы бы столкнулись?
[25:10.000 --> 25:12.000]  Ну, да.
[25:12.000 --> 25:14.000]  Его нужно писать
[25:14.000 --> 25:16.000]  перед каждым ретерном,
[25:16.000 --> 25:18.000]  и это довольно хрупкий код,
[25:18.000 --> 25:20.000]  потому что...
[25:20.000 --> 25:22.000]  Ну, может быть, вы даже не забудете
[25:22.000 --> 25:24.000]  это сделать.
[25:24.000 --> 25:26.000]  Ну, да.
[25:26.000 --> 25:28.000]  Ну, вот.
[25:28.000 --> 25:30.000]  Вот.
[25:30.000 --> 25:32.000]  Вы даже не забудете это сделать.
[25:32.000 --> 25:34.000]  Ну, неприятно, что уже два раза нужно
[25:34.000 --> 25:36.000]  повторяться.
[25:36.000 --> 25:38.000]  Неприятно, что нужно быть аккуратным.
[25:38.000 --> 25:40.000]  А еще есть такая проблема, что этот код сложнее
[25:40.000 --> 25:42.000]  поддерживать. Кто-то будет его рефакторить,
[25:42.000 --> 25:44.000]  переписывать, добавлять if, и вдруг забудет.
[25:44.000 --> 25:46.000]  Потому что он от Mutex не писал.
[25:46.000 --> 25:48.000]  Представьте, что этот код не из 10 строчек,
[25:48.000 --> 25:50.000]  а из там... Ну, это не самый хороший код,
[25:50.000 --> 25:52.000]  наверное, ну, там, из 200.
[25:52.000 --> 25:54.000]  И вот можно легко
[25:54.000 --> 25:56.000]  попасть в просак.
[25:56.000 --> 25:58.000]  Ну, кроме того, это, наверное, не очень актуально
[25:58.000 --> 26:00.000]  для Mutex все же, но исключение.
[26:00.000 --> 26:02.000]  Если у вас полетает исключение,
[26:02.000 --> 26:04.000]  разматывается стэк,
[26:04.000 --> 26:06.000]  то если вы пишете он лог руками,
[26:06.000 --> 26:08.000]  то он не вызовется. Если вы написали
[26:08.000 --> 26:10.000]  log guard, то при размотке стэка будет
[26:10.000 --> 26:12.000]  вызван деструктор, и
[26:12.000 --> 26:14.000]  лог отпустится.
[26:22.000 --> 26:24.000]  Ну что, вопросы есть?
[26:24.000 --> 26:26.000]  А другие языки переняли?
[26:26.000 --> 26:28.000]  Ага.
[26:32.000 --> 26:34.000]  Ну вот, скажем, а я не знаю, мне кажется,
[26:34.000 --> 26:36.000]  у меня пример с Go здесь был прям
[26:36.000 --> 26:38.000]  готовый.
[26:38.000 --> 26:40.000]  Вот.
[26:42.000 --> 26:44.000]  Мы захватываем лог
[26:44.000 --> 26:46.000]  и говорим, что в конце вызова
[26:46.000 --> 26:48.000]  функций нужно вызвать Mutex.
[26:50.000 --> 26:52.000]  Ну вот, в разных языках есть
[26:52.000 --> 26:54.000]  какие-то разные способы, разные синтексы
[26:54.000 --> 26:56.000]  для того, чтобы как-то связывать
[26:56.000 --> 26:58.000]  скопы лексические
[26:58.000 --> 27:00.000]  с какой-то логикой, с каким-то
[27:00.000 --> 27:02.000]  владением ресурсов, но вот
[27:02.000 --> 27:04.000]  это все довольно индивидуально. Все плюс-плюс,
[27:04.000 --> 27:06.000]  есть рай, и мы обязаны им пользоваться.
[27:10.000 --> 27:12.000]  Прежде чем перейти
[27:14.000 --> 27:16.000]  к свойствам Mutex,
[27:16.000 --> 27:18.000]  хотя это, наверное, может быть, самое важное
[27:18.000 --> 27:20.000]  сейчас,
[27:20.000 --> 27:22.000]  все-таки скажу про
[27:22.000 --> 27:24.000]  еще кое-что про его использование.
[27:24.000 --> 27:26.000]  Ну вот, мы можем вызывать lock-unlock, мы можем
[27:26.000 --> 27:28.000]  использовать рай
[27:28.000 --> 27:30.000]  для того, чтобы делать
[27:30.000 --> 27:32.000]  это аккуратнее и безопаснее.
[27:32.000 --> 27:34.000]  Но в домашней работе вы видели, что
[27:34.000 --> 27:36.000]  можно поставить вопрос вообще несколько иначе.
[27:36.000 --> 27:38.000]  Что у нас есть
[27:40.000 --> 27:42.000]  Mutex и есть данные, которые
[27:42.000 --> 27:44.000]  этим Mutex мы защищаются.
[27:44.000 --> 27:46.000]  И вот в коде, скажем,
[27:46.000 --> 27:48.000]  который мы пишем, эта связь,
[27:48.000 --> 27:50.000]  она никак не выражена. Вот есть просто Mutex
[27:50.000 --> 27:52.000]  и есть просто вот какое-то поле.
[27:52.000 --> 27:54.000]  И, видимо, мы
[27:54.000 --> 27:56.000]  написали код так, чтобы при обращении
[27:56.000 --> 27:58.000]  к этим полям, к этим разделенным данным, мы
[27:58.000 --> 28:00.000]  используем один и тот же Mutex, который изолирует
[28:00.000 --> 28:02.000]  разные конкурирующие
[28:02.000 --> 28:04.000]  операции. Но вот
[28:04.000 --> 28:06.000]  в коде эта связь никак не выражена.
[28:06.000 --> 28:08.000]  И это, вообще говоря, большая проблема,
[28:08.000 --> 28:10.000]  потому что
[28:10.000 --> 28:12.000]  это не помогает писать безопасный код.
[28:12.000 --> 28:14.000]  Вообще, если вы следите за языками
[28:14.000 --> 28:16.000]  программирования, за тем, которые развиваются сейчас,
[28:16.000 --> 28:18.000]  то есть некоторый тренд на то, чтобы делать языки
[28:18.000 --> 28:20.000]  безопасными.
[28:20.000 --> 28:22.000]  Цель не только в том, чтобы сделать
[28:22.000 --> 28:24.000]  код, чтобы код исполнялся эффективно,
[28:24.000 --> 28:26.000]  а еще и в том, чтобы
[28:26.000 --> 28:28.000]  сложнее было написать
[28:28.000 --> 28:30.000]  некорректную программу.
[28:30.000 --> 28:32.000]  И
[28:32.000 --> 28:34.000]  в данном случае C++ нам никак
[28:34.000 --> 28:36.000]  не помогает. Он никак не связывает
[28:36.000 --> 28:38.000]  этот Mutex и эту голову.
[28:38.000 --> 28:40.000]  Мы можем, конечно, написать комментарий здесь.
[28:48.000 --> 28:50.000]  Вот. И это человек, который
[28:50.000 --> 28:52.000]  читает код поможет.
[28:52.000 --> 28:54.000]  Но оказывается, что можно сделать хитрее.
[28:54.000 --> 28:56.000]  Смотрите, что, например,
[28:56.000 --> 28:58.000]  умеет
[28:58.000 --> 29:00.000]  Clang.
[29:00.000 --> 29:02.000]  Вот в
[29:02.000 --> 29:04.000]  Clang можно написать вот так вот.
[29:04.000 --> 29:06.000]  GuardedBy.
[29:06.000 --> 29:08.000]  Ну, почти что комментарий.
[29:08.000 --> 29:10.000]  Вот давайте я
[29:10.000 --> 29:12.000]  покажу этот пример.
[29:12.000 --> 29:14.000]  Вот тут какой-то класс
[29:14.000 --> 29:16.000]  банковский аккаунт. Он немного в другом
[29:16.000 --> 29:18.000]  виде написан. Ничего не поделать.
[29:18.000 --> 29:20.000]  Мы можем
[29:20.000 --> 29:22.000]  положить деньги на счет, снять деньги
[29:22.000 --> 29:24.000]  со счета. Мы можем перевести
[29:24.000 --> 29:26.000]  с счета на счет.
[29:26.000 --> 29:28.000]  Вот. Пример
[29:28.000 --> 29:30.000]  абсолютно бесполезный, но
[29:30.000 --> 29:32.000]  он здесь не для этого. Он для того, чтобы показать,
[29:32.000 --> 29:34.000]  что вот есть состояние некоторое
[29:34.000 --> 29:36.000]  и есть Mutex, который его защищает.
[29:36.000 --> 29:38.000]  И мы можем сделать нечто лучшее,
[29:38.000 --> 29:40.000]  чем просто написать комментарий.
[29:40.000 --> 29:42.000]  Мы можем написать
[29:42.000 --> 29:44.000]  с помощью некоторых специальной аннотации
[29:44.000 --> 29:46.000]  для комператора, что вот эти данные
[29:46.000 --> 29:48.000]  защищаются этим Mutex,
[29:48.000 --> 29:50.000]  а потом мы можем
[29:50.000 --> 29:52.000]  поставить на вызов функции
[29:52.000 --> 29:54.000]  в его сигнатуру добавить некоторую аннотацию,
[29:54.000 --> 29:56.000]  что для того, чтобы этот метод
[29:56.000 --> 29:58.000]  можно было вызвать,
[29:58.000 --> 30:00.000]  нужно Mutex'ом владеть.
[30:00.000 --> 30:02.000]  И вот если это
[30:02.000 --> 30:04.000]  свойство нарушается,
[30:04.000 --> 30:06.000]  вот как, например, здесь
[30:06.000 --> 30:08.000]  мы берем Mutex
[30:08.000 --> 30:10.000]  для текущего аккаунта
[30:10.000 --> 30:12.000]  и не берем Mutex для аккаунта,
[30:12.000 --> 30:14.000]  с которого мы забираем деньги.
[30:14.000 --> 30:16.000]  И вот в этом случае появляется
[30:16.000 --> 30:18.000]  ворнинг,
[30:18.000 --> 30:20.000]  но
[30:20.000 --> 30:22.000]  если мы собираем программу
[30:22.000 --> 30:24.000]  с флажком в эррор, то есть мы трактуем ворнинги
[30:24.000 --> 30:26.000]  как ошибки,
[30:26.000 --> 30:28.000]  а, я надеюсь,
[30:28.000 --> 30:30.000]  в любом хорошем проекте так и происходит,
[30:30.000 --> 30:32.000]  в конце концов, то эти ворнинги
[30:32.000 --> 30:34.000]  превращаются в ошибки и ваш код не компилируется,
[30:34.000 --> 30:36.000]  потому что вы вызываете метод
[30:36.000 --> 30:38.000]  без лока.
[30:38.000 --> 30:40.000]  Это вообще выглядит как будто
[30:40.000 --> 30:42.000]  какая-то кастомная проверка
[30:42.000 --> 30:44.000]  и действительно
[30:44.000 --> 30:46.000]  в данном случае так оно и есть.
[30:46.000 --> 30:48.000]  Но вообще это иллюстрация
[30:48.000 --> 30:50.000]  некоторого общего метода, который называется
[30:50.000 --> 30:52.000]  Reference Copabilities,
[30:52.000 --> 30:54.000]  когда вы
[30:54.000 --> 30:56.000]  можете статически анализировать
[30:56.000 --> 30:58.000]  программу и присваивать
[30:58.000 --> 31:00.000]  некоторым сущностям в ней некоторые свойства.
[31:00.000 --> 31:02.000]  Короче говоря,
[31:02.000 --> 31:04.000]  как вам коротко это объяснить,
[31:04.000 --> 31:06.000]  это теория языков программирования,
[31:06.000 --> 31:08.000]  теория типов довольно сложная,
[31:08.000 --> 31:10.000]  там можно очень сложные вещи делать.
[31:10.000 --> 31:12.000]  Вот можно
[31:12.000 --> 31:14.000]  есть, посмотрите, такая
[31:14.000 --> 31:16.000]  интуиция, что вообще говоря
[31:16.000 --> 31:18.000]  можно думать о функциях
[31:18.000 --> 31:20.000]  в языке программирования,
[31:20.000 --> 31:22.000]  о сигнатурах, как о некоторых утверждениях,
[31:22.000 --> 31:24.000]  а о теле функции,
[31:24.000 --> 31:26.000]  как о доказательстве
[31:26.000 --> 31:28.000]  этого утверждения. И вот это можно определённым
[31:28.000 --> 31:30.000]  образом формализовать и научить компилятор
[31:30.000 --> 31:32.000]  проверять, что действительно свойства
[31:32.000 --> 31:34.000]  выполнены. Ну вот
[31:34.000 --> 31:36.000]  Copabilities — это
[31:36.000 --> 31:38.000]  некий такой механизм из вот этой
[31:38.000 --> 31:40.000]  сложной теории.
[31:40.000 --> 31:42.000]  И в Clang вот он частично реализован,
[31:42.000 --> 31:44.000]  и он позволяет вам
[31:44.000 --> 31:46.000]  какие-то наивные ошибки
[31:46.000 --> 31:48.000]  не допускать. Вот в стандартной библиотеке C++
[31:48.000 --> 31:50.000]  такие аннотации на Мютоксах, Кодварах есть.
[31:50.000 --> 31:52.000]  Кажется, что в случае с работы
[31:52.000 --> 31:54.000]  с Clang вы можете
[31:54.000 --> 31:56.000]  в своём проекте такие аннотации
[31:56.000 --> 31:58.000]  использовать.
[31:58.000 --> 32:00.000]  Наверное, вы и без них
[32:00.000 --> 32:02.000]  бы справились,
[32:02.000 --> 32:04.000]  но с ними всё же приятнее, с ними всё-таки
[32:04.000 --> 32:06.000]  безопаснее, особенно если кодовая база большая,
[32:06.000 --> 32:08.000]  и с ней работает много людей.
[32:08.000 --> 32:10.000]  Мне кажется, что
[32:10.000 --> 32:12.000]  нет.
[32:12.000 --> 32:14.000]  Ну и по поводу интерфейса
[32:14.000 --> 32:16.000]  Мютокса, вы опять
[32:16.000 --> 32:18.000]  в задаче видели, что можно
[32:18.000 --> 32:20.000]  вообще-то интерфейс от Мютокса придумать
[32:20.000 --> 32:22.000]  немного иной.
[32:22.000 --> 32:24.000]  И вообще говоря,
[32:24.000 --> 32:26.000]  связать просто Мютокс и данные.
[32:26.000 --> 32:28.000]  Вот пример из языка
[32:28.000 --> 32:30.000]  Rust. Там Мютокс имеет
[32:30.000 --> 32:32.000]  другой IP. Вот у нас в домашней работе
[32:32.000 --> 32:34.000]  была обёртка Mutex,
[32:34.000 --> 32:36.000]  которая не позволяла обращаться к объекту,
[32:36.000 --> 32:38.000]  пока вы Мютокса не захватили явно.
[32:38.000 --> 32:40.000]  Но вот
[32:40.000 --> 32:42.000]  в языке Rust, в стандартной библиотеке
[32:42.000 --> 32:44.000]  Mutex, он только такой.
[32:44.000 --> 32:46.000]  Вот он именно такой.
[32:46.000 --> 32:48.000]  Чтобы обратиться к данным,
[32:48.000 --> 32:50.000]  вы должны вызвать лог сначала.
[32:50.000 --> 32:52.000]  И только тогда вы получите
[32:52.000 --> 32:54.000]  мутабельную ссылку.
[32:54.000 --> 32:56.000]  С Rust вообще интересная
[32:56.000 --> 32:58.000]  ситуация, потому что там
[32:58.000 --> 33:00.000]  некоторый радикальный подход к конкуренции,
[33:00.000 --> 33:02.000]  который позволяет вам избегать
[33:02.000 --> 33:04.000]  некоторых ошибок просто статически,
[33:04.000 --> 33:06.000]  очень большого класса ошибок.
[33:06.000 --> 33:08.000]  Но вот если вам интересно, вы можете
[33:08.000 --> 33:10.000]  однажды это изучить.
[33:10.000 --> 33:12.000]  Да, я кое-что
[33:12.000 --> 33:14.000]  забыл, мне нужно, мне хочется это проговорить
[33:14.000 --> 33:16.000]  обязательно. Вернёмся к этому примеру.
[33:16.000 --> 33:18.000]  Вот ошибки, которые
[33:18.000 --> 33:20.000]  здесь возникали, у них есть специальные названия,
[33:20.000 --> 33:22.000]  и давайте мы их сразу запомним.
[33:22.000 --> 33:24.000]  Вот в этом коде,
[33:24.000 --> 33:26.000]  когда у нас происходила какая-то конкуренция,
[33:26.000 --> 33:28.000]  потоки переключались,
[33:28.000 --> 33:30.000]  они чередовали друг с другом на ядре,
[33:30.000 --> 33:32.000]  и из-за этого чередования
[33:32.000 --> 33:34.000]  мы нарушали какие-то инварианты структуры данных,
[33:34.000 --> 33:36.000]  вот такой класс ошибок
[33:36.000 --> 33:38.000]  называется RaceCondition.
[33:44.000 --> 33:46.000]  Но дело
[33:46.000 --> 33:48.000]  не только в нём. Вот если из этого кода
[33:48.000 --> 33:50.000]  мютексы убрать, вернуть всё как было,
[33:50.000 --> 33:52.000]  то проблема не только в том,
[33:52.000 --> 33:54.000]  что потоки конкурируют,
[33:54.000 --> 33:56.000]  и вот из-за интерливингов
[33:56.000 --> 33:58.000]  возникают вот такие нарушения инвариантов
[33:58.000 --> 34:00.000]  на уровне структуры данных.
[34:00.000 --> 34:02.000]  Это не единственная проблема. Вторая проблема
[34:02.000 --> 34:04.000]  называется DataRace.
[34:04.000 --> 34:06.000]  Вот конкурентные
[34:06.000 --> 34:08.000]  баги, они как правило, либо
[34:08.000 --> 34:10.000]  RaceCondition, либо DataRace.
[34:10.000 --> 34:12.000]  И вот
[34:12.000 --> 34:14.000]  что такое RaceCondition, я могу вам неформально
[34:14.000 --> 34:16.000]  объяснить, и это вот именно такое понятие
[34:16.000 --> 34:18.000]  не строгое. Вот из-за конкуренции,
[34:18.000 --> 34:20.000]  из-за чередования нарушаются ваши
[34:20.000 --> 34:22.000]  инварианты. DataRace, напротив,
[34:22.000 --> 34:24.000]  это очень конкретное понятие.
[34:24.000 --> 34:26.000]  Вот если говорить совсем коротко,
[34:26.000 --> 34:28.000]  оно про то, что два потока
[34:28.000 --> 34:30.000]  без синхронизации
[34:30.000 --> 34:32.000]  обращаются просто к одной и той
[34:32.000 --> 34:34.000]  же ячейке памяти. И что важно,
[34:34.000 --> 34:36.000]  одно из этих обращений — запись.
[34:36.000 --> 34:38.000]  То есть две записи без синхронизации — это DataRace.
[34:38.000 --> 34:40.000]  Запись и чтение без синхронизации —
[34:40.000 --> 34:42.000]  это DataRace. Параллельное
[34:42.000 --> 34:44.000]  чтение одной и той же ячейки — это
[34:44.000 --> 34:46.000]  допустимо.
[34:46.000 --> 34:48.000]  Так вот, здесь и то, и другое есть.
[34:50.000 --> 34:52.000]  Но, пожалуйста, разделяйте
[34:52.000 --> 34:54.000]  эти вещи. DataRace — это
[34:54.000 --> 34:56.000]  проблема на уровне отдельной маленькой
[34:56.000 --> 34:58.000]  ячейки. RaceCondition —
[34:58.000 --> 35:00.000]  это проблема на уровне инвариантов
[35:00.000 --> 35:02.000]  какого-то вашего кода.
[35:02.000 --> 35:04.000]  И они могут сочетаться, могут
[35:04.000 --> 35:06.000]  быть независимы друг от друга.
[35:06.000 --> 35:08.000]  Чуть позже, когда мы поговорим про DataRace
[35:08.000 --> 35:10.000]  в модели памяти, это отдельная сложная
[35:10.000 --> 35:12.000]  тема, мы сможем строго
[35:12.000 --> 35:14.000]  их различать.
[35:16.000 --> 35:18.000]  Вот RaceCondition — это когда ты считаешь,
[35:18.000 --> 35:20.000]  что у тебя каждая строчка атомарна,
[35:20.000 --> 35:22.000]  но просто из-за того, что они как-то переплелись
[35:22.000 --> 35:24.000]  на процессоре, у тебя там, не знаю,
[35:24.000 --> 35:26.000]  дважды что-то удалилось.
[35:26.000 --> 35:28.000]  Или потерялась вставка, она
[35:28.000 --> 35:30.000]  недоступна теперь из головы.
[35:30.000 --> 35:32.000]  Вот это RaceCondition.
[35:32.000 --> 35:34.000]  А DataRace — это ситуация, когда у тебя есть
[35:34.000 --> 35:36.000]  просто ячейка памяти, вот 64-битная,
[35:36.000 --> 35:38.000]  на твоем современном
[35:38.000 --> 35:40.000]  процессоре, и с ней работают
[35:40.000 --> 35:42.000]  два потока без синхронизации, и, по крайней мере,
[35:42.000 --> 35:44.000]  один из них пишет.
[35:44.000 --> 35:46.000]  Это не строгое определение, потому что
[35:46.000 --> 35:48.000]  нужно формализовать что такое без синхронизации.
[35:48.000 --> 35:50.000]  Тут речь не только про мютоксы,
[35:50.000 --> 35:52.000]  но пока можно думать
[35:52.000 --> 35:54.000]  только про мютоксы, раз уж мы больше
[35:54.000 --> 35:56.000]  ничего не знаем.
[35:58.000 --> 36:00.000]  DataRace и RaceCondition независимы
[36:00.000 --> 36:02.000]  друг от друга.
[36:02.000 --> 36:04.000]  Ну, какие варианты мы нарушаем,
[36:04.000 --> 36:06.000]  когда мы работаем с одной ячейкой из разных потоков
[36:06.000 --> 36:08.000]  без синхронизации, непонятно.
[36:12.000 --> 36:14.000]  Это разные вещи. DataRace про одну маленькую ячейку
[36:14.000 --> 36:16.000]  и обращение без синхронизации и RaceCondition —
[36:16.000 --> 36:18.000]  это какие-то переключения я,
[36:18.000 --> 36:20.000]  очередования.
[36:22.000 --> 36:24.000]  Ну, хорошо, давайте
[36:24.000 --> 36:26.000]  пойдем дальше.
[36:26.000 --> 36:28.000]  Чего мы от мютокса ожидаем? Мы пока говорим про то,
[36:28.000 --> 36:30.000]  как им пользоваться,
[36:30.000 --> 36:32.000]  не говорим, как он
[36:32.000 --> 36:34.000]  реализован, но чего мы от него ждем?
[36:34.000 --> 36:36.000]  Мы от него ждем двух свойств. Одно я уже озвучил.
[36:36.000 --> 36:38.000]  Это взаимное исключение,
[36:38.000 --> 36:40.000]  поэтому его название.
[36:40.000 --> 36:42.000]  Между вызовами Lock и Unlock может находиться
[36:42.000 --> 36:44.000]  только один поток.
[36:44.000 --> 36:46.000]  Но есть второе свойство —
[36:46.000 --> 36:48.000]  свобод от взаимной блокировки.
[36:48.000 --> 36:50.000]  Вот эти два свойства, они проразны.
[36:50.000 --> 36:52.000]  Смотрите, первое свойство про то,
[36:52.000 --> 36:54.000]  что никогда не происходит ничего плохого.
[36:54.000 --> 36:56.000]  Если два потока находятся
[36:56.000 --> 36:58.000]  между Lock и Unlock одновременно,
[36:58.000 --> 37:00.000]  то, видимо,
[37:00.000 --> 37:02.000]  наши вызовы уже не одномарны друг относительно друга.
[37:02.000 --> 37:04.000]  Но есть и
[37:04.000 --> 37:06.000]  другая проблема, а именно
[37:06.000 --> 37:08.000]  на нужен прогресс.
[37:08.000 --> 37:10.000]  Вот если мютокс свободен сейчас,
[37:10.000 --> 37:12.000]  из-за него соревнуются
[37:12.000 --> 37:14.000]  несколько потоков, то, по крайней мере,
[37:14.000 --> 37:16.000]  один из вызовов Lock должен завершиться.
[37:16.000 --> 37:18.000]  Не может быть такого, что
[37:18.000 --> 37:20.000]  все они вызвались и мешают друг другу,
[37:20.000 --> 37:22.000]  и никто не завершается вечно.
[37:22.000 --> 37:24.000]  Еще раз, это свойство safety,
[37:24.000 --> 37:26.000]  свойство liveness. Ничего плохого
[37:26.000 --> 37:28.000]  не происходит никогда, и когда-нибудь
[37:28.000 --> 37:30.000]  происходит что-то хорошее. Нас, конечно,
[37:30.000 --> 37:32.000]  волнует оба этих свойства.
[37:32.000 --> 37:34.000]  Что значит, что поток
[37:34.000 --> 37:36.000]  захватывает мюток?
[37:36.000 --> 37:38.000]  Как можно мюток заходить?
[37:38.000 --> 37:40.000]  Вызвать Lock и завершить этот вызов.
[37:40.000 --> 37:42.000]  Ну вот, смотрите, тут был слайд с лексикой.
[37:42.000 --> 37:44.000]  Поток захватывает мютокс, вызывая Lock.
[37:48.000 --> 37:50.000]  Ну, поток исполняется, а мютокс
[37:50.000 --> 37:52.000]  это объект. Видимо, поток захватывает
[37:52.000 --> 37:54.000]  мютокс. В смысле, под.
[37:56.000 --> 37:58.000]  Можно
[37:58.000 --> 38:00.000]  интерпретировать по-разному. Как правильно
[38:00.000 --> 38:02.000]  сказать, чтобы не было доусмысленности?
[38:02.000 --> 38:04.000]  Мютокс захватывается
[38:04.000 --> 38:06.000]  потоком, а поток
[38:06.000 --> 38:08.000]  захватывает мютокс.
[38:08.000 --> 38:10.000]  Все, получилось. Ура.
[38:12.000 --> 38:14.000]  Ну вот, значит, такие свойства Safety Linus.
[38:14.000 --> 38:16.000]  И мы с вами
[38:16.000 --> 38:18.000]  в домашнем задании сталкиваемся
[38:18.000 --> 38:20.000]  с двумя задачами, которые
[38:20.000 --> 38:22.000]  моделируют нарушение
[38:22.000 --> 38:24.000]  этих свойств.
[38:24.000 --> 38:26.000]  Первая проблема, которая возникает
[38:26.000 --> 38:28.000]  с свойством Safety, с свойством взаимноисключения,
[38:28.000 --> 38:30.000]  это взаимная блокировка.
[38:30.000 --> 38:32.000]  Что я говорю?
[38:34.000 --> 38:36.000]  Мы говорим, конечно, про гарантии прогресса.
[38:36.000 --> 38:38.000]  Вот, гарантии прогресса могут нарушаться
[38:38.000 --> 38:40.000]  немного по-разному. Вот есть
[38:40.000 --> 38:42.000]  взаимная блокировка,
[38:42.000 --> 38:44.000]  deadlock и есть lifelock.
[38:44.000 --> 38:46.000]  С deadlock мы уже столкнулись. Это ситуация,
[38:46.000 --> 38:48.000]  когда потоки блокируют друг друга
[38:48.000 --> 38:50.000]  и не могут больше ничего сделать.
[38:50.000 --> 38:52.000]  Прогресса не бывает больше.
[38:52.000 --> 38:54.000]  Вот потоки пришли
[38:54.000 --> 38:56.000]  в какое-то терминальное состояние,
[38:56.000 --> 38:58.000]  выйти из него они уже не могут.
[38:58.000 --> 39:00.000]  И есть другая проблема, она называется
[39:00.000 --> 39:02.000]  lifelock. Она про то, что
[39:02.000 --> 39:04.000]  все же потоки могут выйти
[39:04.000 --> 39:06.000]  из вот некоторые ситуации,
[39:06.000 --> 39:08.000]  где ни один из них не совершает прогресса.
[39:08.000 --> 39:10.000]  Но
[39:10.000 --> 39:12.000]  случится это или нет? Точнее, когда это
[39:12.000 --> 39:14.000]  случится, мы не знаем. Все зависит
[39:14.000 --> 39:16.000]  от того, как потоки планируются планировщикам
[39:16.000 --> 39:18.000]  на ядра, когда они именно
[39:18.000 --> 39:20.000]  переключаются.
[39:24.000 --> 39:26.000]  Нет, не может.
[39:28.000 --> 39:30.000]  Ну, в смысле, тебя, наверное, смущают машинки, да?
[39:34.000 --> 39:38.000]  Ну, я согласен.
[39:38.000 --> 39:40.000]  Разница между этими картинками в том,
[39:40.000 --> 39:42.000]  что здесь машины назад
[39:42.000 --> 39:44.000]  двигаться не могут.
[39:44.000 --> 39:46.000]  Ну, по крайней мере,
[39:46.000 --> 39:48.000]  имелось авторами это в виду.
[39:48.000 --> 39:50.000]  А здесь они могут отъехать и попробовать заново.
[39:50.000 --> 39:52.000]  Но если они сделают это симметрично все,
[39:52.000 --> 39:54.000]  ну, и там, неудачно в некотором смысле,
[39:54.000 --> 39:56.000]  то снова они вот окажутся в той же ситуации
[39:56.000 --> 39:58.000]  и вот продолжат так мучиться.
[39:58.000 --> 40:00.000]  Ну, не представь себя, вот lifelock есть такое
[40:00.000 --> 40:02.000]  очень простой жизненный пример. Два человека идут по коридору
[40:02.000 --> 40:04.000]  навстречу друг к другу.
[40:04.000 --> 40:06.000]  Им нужно разойтись. Что они делают?
[40:06.000 --> 40:08.000]  Они идут в одну сторону сначала, отходят.
[40:08.000 --> 40:10.000]  И снова мешают друг другу, потом в другую.
[40:10.000 --> 40:12.000]  Ну, и так может продолжаться некоторое время.
[40:12.000 --> 40:14.000]  Скорее всего, не вечно, но непредсказуемо долго.
[40:14.000 --> 40:16.000]  Вот это lifelock.
[40:16.000 --> 40:18.000]  А deadlock — это когда уже все.
[40:18.000 --> 40:20.000]  Вот deadlock вы уже
[40:20.000 --> 40:22.000]  симулировали в домашней работе,
[40:22.000 --> 40:24.000]  поэтому вы понимаете, что вот из него выхода
[40:24.000 --> 40:26.000]  уже никакого нет. Вы вызвали там
[40:26.000 --> 40:28.000]  lock на разных mutex,
[40:28.000 --> 40:30.000]  в разных потоках, и вот
[40:30.000 --> 40:32.000]  они уже не завершатся.
[40:32.000 --> 40:34.000]  Никогда.
[40:34.000 --> 40:36.000]  Тут нужно уточнить,
[40:36.000 --> 40:38.000]  что вот гарантия прогресса,
[40:38.000 --> 40:40.000]  которую мы вот так определили,
[40:40.000 --> 40:42.000]  она может быть
[40:42.000 --> 40:44.000]  двух видов.
[40:44.000 --> 40:46.000]  Вот здесь мы говорим, что
[40:46.000 --> 40:48.000]  если несколько потоков вызвали mutex lock,
[40:48.000 --> 40:50.000]  то кто-нибудь из них должен преуспеть.
[40:50.000 --> 40:52.000]  Кто из них нам не важно.
[40:52.000 --> 40:54.000]  Но может быть мы хотим
[40:54.000 --> 40:56.000]  чуть более сильной гарантии, а именно
[40:56.000 --> 40:58.000]  мы хотим, чтобы каждый вызов lock завершался.
[40:58.000 --> 41:00.000]  Вот разница здесь
[41:00.000 --> 41:02.000]  между гарантией глобального прогресса,
[41:02.000 --> 41:04.000]  кто-то захватывает mutex,
[41:04.000 --> 41:06.000]  по крайней мере кто-нибудь,
[41:06.000 --> 41:08.000]  или каждый захватывает mutex.
[41:10.000 --> 41:12.000]  Вот если какой-то поток может бесконечно
[41:12.000 --> 41:14.000]  долго ждать, то мы говорим, что он голодает.
[41:14.000 --> 41:16.000]  Ну и вот та задача,
[41:16.000 --> 41:18.000]  которую вы увидели в домашней работе
[41:18.000 --> 41:20.000]  про философов, она исходная как раз про голодание,
[41:20.000 --> 41:22.000]  поэтому такая вот гастрономическая
[41:22.000 --> 41:24.000]  ситуация у них там.
[41:24.000 --> 41:26.000]  Они едят что-то вилками.
[41:26.000 --> 41:28.000]  Мы эту задачу используем как демонстрацию
[41:28.000 --> 41:30.000]  взаимной блокировки,
[41:30.000 --> 41:32.000]  и вот ищем способ вывести
[41:32.000 --> 41:34.000]  некоторое универсальное правило,
[41:34.000 --> 41:36.000]  по которому можно захватывать блокировки,
[41:36.000 --> 41:38.000]  не попадая в deadlock.
[41:38.000 --> 41:40.000]  Но вот изначально задача посвящена
[41:40.000 --> 41:42.000]  голоданию философу.
[41:44.000 --> 41:46.000]  Такое техническое скорее замечание,
[41:46.000 --> 41:48.000]  не знаю насколько оно нам прямо сейчас важно,
[41:48.000 --> 41:50.000]  что
[41:50.000 --> 41:52.000]  свойства сейфти
[41:52.000 --> 41:54.000]  не зависят от поведения планировщика.
[41:54.000 --> 41:56.000]  Вот как бы планировщик потоки не переключал,
[41:56.000 --> 41:58.000]  вот все равно
[41:58.000 --> 42:00.000]  два потока не могут, не должны
[42:00.000 --> 42:02.000]  ни в коем случае оказаться в критической секции.
[42:02.000 --> 42:04.000]  Когда мы говорим про лайвность,
[42:04.000 --> 42:06.000]  то мы все-таки ожидаем кое-чего от планировщика,
[42:06.000 --> 42:08.000]  что он,
[42:08.000 --> 42:10.000]  то есть мы не можем, мы можем
[42:10.000 --> 42:12.000]  гарантировать лайвность в своем коде только в предположении,
[42:12.000 --> 42:14.000]  что сам планировщик действует
[42:14.000 --> 42:16.000]  в некотором смысле честно и дает каждому
[42:16.000 --> 42:18.000]  потоку время исполняться.
[42:20.000 --> 42:22.000]  Зачем я сейчас
[42:22.000 --> 42:24.000]  об этом говорю? Ну, потому что в будущем
[42:24.000 --> 42:26.000]  некоторым мы будем говорить про гарантии
[42:26.000 --> 42:28.000]  лог-фри,
[42:28.000 --> 42:30.000]  и это очень ловкая, очень интересная
[42:30.000 --> 42:32.000]  тема, и там вся соль будет в том,
[42:32.000 --> 42:34.000]  чтобы обеспечить прогресс
[42:34.000 --> 42:36.000]  операциям, но при этом не полагаться,
[42:36.000 --> 42:38.000]  что планировщик будет исполнять каждый из потоков.
[42:38.000 --> 42:40.000]  Это более сложно, нам придется
[42:40.000 --> 42:42.000]  от мьютоксов потом избавиться,
[42:42.000 --> 42:44.000]  для этого придется избавиться,
[42:44.000 --> 42:46.000]  поэтому сейчас такое замечание.
[42:46.000 --> 42:48.000]  Ну ладно, значит мы понимаем, что такое
[42:48.000 --> 42:50.000]  мьютокс, мы понимаем примерно как им пользоваться,
[42:50.000 --> 42:52.000]  что мы от них вообще хотим,
[42:52.000 --> 42:54.000]  а теперь пора их сделать.
[42:54.000 --> 42:56.000]  Вопрос только в том, из чего мы будем
[42:56.000 --> 42:58.000]  их делать.
[42:58.000 --> 43:00.000]  Ну вот, в конце концов,
[43:00.000 --> 43:02.000]  под нами есть процессоры, ячейки памяти,
[43:02.000 --> 43:04.000]  какие-то инструкции.
[43:04.000 --> 43:06.000]  Мы сейчас будем из этого мастерить
[43:06.000 --> 43:08.000]  реализацию мьютокса.
[43:08.000 --> 43:10.000]  Достаточно наивно.
[43:10.000 --> 43:12.000]  Но прежде чем к этому приступить,
[43:12.000 --> 43:14.000]  нам нужно сделать еще одну оговорку,
[43:14.000 --> 43:16.000]  очень важную.
[43:16.000 --> 43:18.000]  Как мы вообще представляем себе работу
[43:18.000 --> 43:20.000]  с памятью?
[43:20.000 --> 43:22.000]  Вот как вы себе это представляете?
[43:22.000 --> 43:24.000]  Ну в смысле, параллельную работу
[43:24.000 --> 43:26.000]  процессора с разных ядер с общей разделяемой памятью?
[43:30.000 --> 43:32.000]  Это правда,
[43:32.000 --> 43:34.000]  но здесь
[43:34.000 --> 43:36.000]  вопрос-то не о том,
[43:36.000 --> 43:38.000]  как отдельное ядро работает
[43:38.000 --> 43:40.000]  с памятью, это все правильно было сказано.
[43:42.000 --> 43:44.000]  А нужно ли как-то учитывать, что
[43:44.000 --> 43:46.000]  разные ядра физически
[43:46.000 --> 43:48.000]  параллельно одновременно работают,
[43:48.000 --> 43:50.000]  обращаются к одним и тем же общим ячейкам памяти?
[43:50.000 --> 43:52.000]  Как мы можем
[43:52.000 --> 43:54.000]  об этом думать?
[43:54.000 --> 43:56.000]  Ну вот наивный способ об этом думать вот такой вот.
[43:56.000 --> 43:58.000]  Он наивный, но он
[43:58.000 --> 44:00.000]  такой интуитивный,
[44:00.000 --> 44:02.000]  и если человека попросить
[44:02.000 --> 44:04.000]  промоделировать в голове все исполнения
[44:04.000 --> 44:06.000]  многоточной программы, то он, скорее всего,
[44:06.000 --> 44:08.000]  будет рассуждать так, что
[44:08.000 --> 44:10.000]  вроде бы потоков у него много,
[44:10.000 --> 44:12.000]  ядер может быть много,
[44:12.000 --> 44:14.000]  но все равно он делает шаги
[44:14.000 --> 44:16.000]  с другими потоками по очереди.
[44:16.000 --> 44:18.000]  Сначала первый поток походит, потом
[44:18.000 --> 44:20.000]  еще раз первый, потом второй, потом еще раз второй,
[44:20.000 --> 44:22.000]  потом снова первый, потом второй, потом третий
[44:22.000 --> 44:24.000]  и так далее.
[44:24.000 --> 44:26.000]  То есть у вас ядер много,
[44:26.000 --> 44:28.000]  но вы как-то об этом не думаете,
[44:28.000 --> 44:30.000]  вы все равно каким-то таким одним курсором
[44:30.000 --> 44:32.000]  прыгаете по программе.
[44:32.000 --> 44:34.000]  То есть как будто бы у вас
[44:34.000 --> 44:36.000]  память как одно большое
[44:36.000 --> 44:38.000]  целое атомарно,
[44:38.000 --> 44:40.000]  и как будто бы мы с ней физически
[44:40.000 --> 44:42.000]  параллельно не работаем.
[44:42.000 --> 44:44.000]  Но эта модель хороша,
[44:44.000 --> 44:46.000]  потому что она избавляет нас
[44:46.000 --> 44:48.000]  от необходимости думать
[44:48.000 --> 44:50.000]  про параллелизм.
[44:50.000 --> 44:52.000]  Мы думаем только про переключение.
[44:52.000 --> 44:54.000]  Нам нужно просчитать все возможные варианты,
[44:54.000 --> 44:56.000]  когда мы переключаемся между разными потоками.
[44:58.000 --> 45:00.000]  Но вообще-то, как мы скоро узнаем,
[45:00.000 --> 45:02.000]  но я сегодня уже покажу,
[45:02.000 --> 45:04.000]  а обсудим мы это на серьезном уровне
[45:04.000 --> 45:06.000]  гораздо позже.
[45:06.000 --> 45:08.000]  Вот такая модель, она просто несправедлива
[45:08.000 --> 45:10.000]  в реальности. Вот реальность устроена не так.
[45:10.000 --> 45:12.000]  Компьютер так не работает.
[45:12.000 --> 45:14.000]  Вот люди так рассуждают
[45:14.000 --> 45:16.000]  о его работе, но компьютер так сам по себе
[45:16.000 --> 45:18.000]  не работает.
[45:18.000 --> 45:20.000]  Поэтому мы сейчас будем делать
[45:20.000 --> 45:22.000]  бьютэксе, но мы будем использовать не просто
[45:22.000 --> 45:24.000]  ячейки памяти, ну там int
[45:24.000 --> 45:26.000]  или bool, а мы будем
[45:26.000 --> 45:28.000]  использовать вот такую вот обертку
[45:28.000 --> 45:30.000]  atomic int, atomic bool, что-то подобное.
[45:30.000 --> 45:32.000]  Какой-то atomic, шаблонный класс.
[45:32.000 --> 45:34.000]  В прошлый раз спрашивали,
[45:34.000 --> 45:36.000]  что такое atomic? Я говорил, ну это ячейка памяти,
[45:36.000 --> 45:38.000]  с которой можно совершать атомарную операцию.
[45:38.000 --> 45:40.000]  Поэтому она так и называется.
[45:40.000 --> 45:42.000]  Ну и давайте посмотрим на методы атомика,
[45:42.000 --> 45:44.000]  ну точнее на какой это метод атомика.
[45:44.000 --> 45:46.000]  У него есть методы store и load.
[45:46.000 --> 45:48.000]  Мы можем в атоме что-то записать,
[45:48.000 --> 45:50.000]  простите, записать
[45:50.000 --> 45:52.000]  и прочитать.
[45:52.000 --> 45:54.000]  Ну как с ячейкой памяти.
[45:54.000 --> 45:56.000]  Но вот оказывается,
[45:56.000 --> 45:58.000]  что без этого атомика,
[45:58.000 --> 46:00.000]  вот без
[46:00.000 --> 46:02.000]  этого шаблона
[46:02.000 --> 46:04.000]  мы не можем написать мьютэкс.
[46:04.000 --> 46:06.000]  К этому мы чуть позже вернемся.
[46:06.000 --> 46:08.000]  Но парадокс здесь
[46:08.000 --> 46:10.000]  некоторый в том, что на уровне
[46:10.000 --> 46:12.000]  представления,
[46:12.000 --> 46:14.000]  то есть в компьютере в конце концов,
[46:14.000 --> 46:16.000]  нет разницы между объектом
[46:16.000 --> 46:18.000]  типа int и объектом
[46:18.000 --> 46:20.000]  переменной типа int
[46:20.000 --> 46:22.000]  и переменной типа atomic int.
[46:22.000 --> 46:24.000]  То есть в конце концов в компьютере
[46:24.000 --> 46:26.000]  они представлены абсолютно одинаково.
[46:26.000 --> 46:28.000]  Это просто 64-битное слово.
[46:28.000 --> 46:30.000]  Но при этом
[46:30.000 --> 46:32.000]  без атомика мы жить не можем.
[46:32.000 --> 46:34.000]  Где-то здесь есть подвох,
[46:34.000 --> 46:36.000]  он действительно есть,
[46:36.000 --> 46:38.000]  он действительно очень хитрый.
[46:38.000 --> 46:40.000]  И вы, кстати,
[46:40.000 --> 46:42.000]  можете этот подвох
[46:42.000 --> 46:44.000]  вскоре увидеть,
[46:44.000 --> 46:46.000]  прямо сегодня,
[46:46.000 --> 46:48.000]  когда вы будете решать задачу,
[46:48.000 --> 46:50.000]  которая называется спинлог.
[46:50.000 --> 46:52.000]  Вот там вас как раз просят
[46:52.000 --> 46:54.000]  написать свой атомик,
[46:54.000 --> 46:56.000]  а не спинлог, как можно подумать.
[46:56.000 --> 46:58.000]  Вы напишите атомик
[46:58.000 --> 47:00.000]  и надеюсь лучше разберетесь,
[47:00.000 --> 47:02.000]  что это на самом деле такое.
[47:02.000 --> 47:04.000]  С одной стороны, а с другой стороны
[47:04.000 --> 47:06.000]  у вас должно поселиться какое-то
[47:06.000 --> 47:08.000]  сомнение глубокое.
[47:08.000 --> 47:10.000]  Там для этого есть вопросы в условии.
[47:10.000 --> 47:12.000]  Вот если вы на них ответите, подумаете,
[47:12.000 --> 47:14.000]  то вас неизбежно они фрустрируют.
[47:14.000 --> 47:16.000]  Вот это так и должно быть.
[47:16.000 --> 47:18.000]  Ну вот, значит, пока опять какое-то
[47:18.000 --> 47:20.000]  колдовство, какая-то магия,
[47:20.000 --> 47:22.000]  пишем везде атомики, хотя это вроде бы те же самые ячейки памяти.
[47:22.000 --> 47:24.000]  Ну да, я нигде не вру,
[47:24.000 --> 47:26.000]  противоречия здесь нет.
[47:26.000 --> 47:28.000]  Идем дальше.
[47:28.000 --> 47:30.000]  Спасибо за вопрос.
[47:30.000 --> 47:32.000]  Если мы работаем с мьютоксами,
[47:32.000 --> 47:34.000]  то нам никакие атомики не нужны.
[47:34.000 --> 47:36.000]  Атомики, грубо говоря,
[47:36.000 --> 47:38.000]  для тех случаев,
[47:38.000 --> 47:40.000]  когда у вас есть ячейка памяти
[47:40.000 --> 47:42.000]  и с ней без синхронизации
[47:42.000 --> 47:44.000]  работают разные потоки.
[47:44.000 --> 47:46.000]  Вот если мы возьмем
[47:46.000 --> 47:48.000]  список и обернем
[47:48.000 --> 47:50.000]  эти методы в критические секции
[47:50.000 --> 47:52.000]  с помощью мьютокса,
[47:52.000 --> 47:54.000]  то таких ситуаций не будет.
[47:54.000 --> 47:56.000]  Не бывает такого.
[47:56.000 --> 47:58.000]  Этим полем
[47:58.000 --> 48:00.000]  работают одновременно разные потоки.
[48:00.000 --> 48:02.000]  Работает только один,
[48:02.000 --> 48:04.000]  который владеет мьютоксом.
[48:04.000 --> 48:06.000]  Но вот если мы хотим сделать
[48:06.000 --> 48:08.000]  мьютокс сами,
[48:08.000 --> 48:10.000]  то все-таки мы, видимо, должны работать
[48:10.000 --> 48:12.000]  без синхронизации
[48:12.000 --> 48:14.000]  одновременно с одними теми же ячейками,
[48:14.000 --> 48:16.000]  одними теми же ячейками,
[48:16.000 --> 48:18.000]  и для этого нам нужны атомики.
[48:18.000 --> 48:20.000]  Вот они это позволяют.
[48:20.000 --> 48:22.000]  Ну, разумеется,
[48:22.000 --> 48:24.000]  потому что в конце концов мьютокс
[48:24.000 --> 48:26.000]  же должен из чего-то быть сделан.
[48:26.000 --> 48:28.000]  А что у нас здесь в компьютере?
[48:28.000 --> 48:30.000]  Ячейки памяти и инструкции процессора.
[48:30.000 --> 48:32.000]  Вот мы из этого сейчас и будем
[48:32.000 --> 48:34.000]  мастерить блокировку.
[48:42.000 --> 48:44.000]  Так нет никакого слова кэш.
[48:46.000 --> 48:48.000]  Ну, то есть оно есть,
[48:48.000 --> 48:50.000]  и в компьютере есть кэши, их много,
[48:50.000 --> 48:52.000]  они сложно устроены, но это
[48:52.000 --> 48:54.000]  не то, чем мы сейчас занимаемся, к сожалению.
[48:54.000 --> 48:56.000]  Вот кэш — это такая штука,
[48:56.000 --> 48:58.000]  которой можно не знать и не думать.
[49:00.000 --> 49:02.000]  Конечно, в реальности нужно знать и думать,
[49:02.000 --> 49:04.000]  и мы к этому придем,
[49:04.000 --> 49:06.000]  но прям не то чтобы обязательно.
[49:06.000 --> 49:08.000]  И мы сейчас этим пользуемся тем, что
[49:08.000 --> 49:10.000]  не обязательно.
[49:14.000 --> 49:16.000]  Мы считаем, что есть процессор,
[49:16.000 --> 49:18.000]  есть память, и они
[49:18.000 --> 49:20.000]  напрямую так соединены.
[49:20.000 --> 49:22.000]  Ну ладно.
[49:24.000 --> 49:26.000]  Так все это слишком сложно, чтобы сейчас
[49:26.000 --> 49:28.000]  пояснять, потому что я не могу объяснить.
[49:28.000 --> 49:30.000]  Мне потребуется на это 3 часа и только спустя
[49:30.000 --> 49:32.000]  2 месяца, к сожалению.
[49:32.000 --> 49:34.000]  Это сложная тема, это один из самых
[49:34.000 --> 49:36.000]  сложных аспектов C++.
[49:36.000 --> 49:38.000]  Вот я не знаю, правда это или нет.
[49:38.000 --> 49:40.000]  С чем можно сравнить?
[49:40.000 --> 49:42.000]  По сложности.
[49:46.000 --> 49:48.000]  Ну в общем, это такая довольно
[49:48.000 --> 49:50.000]  сложная математическая модель, которая касается
[49:50.000 --> 49:52.000]  семантики языка,
[49:52.000 --> 49:54.000]  которую мало кто понимает по-настоящему,
[49:54.000 --> 49:56.000]  которая супер неинтуитивна для новичка,
[49:56.000 --> 49:58.000]  и ее нужно объяснять
[49:58.000 --> 50:00.000]  действительно 3 часа, а лучше 9,
[50:00.000 --> 50:02.000]  и то после того, когда вы уже
[50:02.000 --> 50:04.000]  какой-то опыт получите. Поэтому
[50:04.000 --> 50:06.000]  пока я просто могу вам сказать, пожалуйста,
[50:06.000 --> 50:08.000]  верьте в атомики, без атомиков нельзя.
[50:08.000 --> 50:10.000]  Простите меня за это.
[50:10.000 --> 50:12.000]  Ладно, давайте сделаем
[50:12.000 --> 50:14.000]  мютекс наконец. Вот у нас есть...
[50:14.000 --> 50:16.000]  Мы хотим сделать мютекс для двух потоков сначала.
[50:16.000 --> 50:18.000]  Давайте ограничим
[50:18.000 --> 50:20.000]  свои амбиции
[50:20.000 --> 50:22.000]  и скажем, что мы просто хотим синхронизировать
[50:22.000 --> 50:24.000]  два потока.
[50:26.000 --> 50:28.000]  Ну давайте посмотрим
[50:28.000 --> 50:30.000]  на какую-то заготовку, как можно было бы
[50:30.000 --> 50:32.000]  это делать.
[50:32.000 --> 50:34.000]  Вот смотрите, первая реализация.
[50:34.000 --> 50:36.000]  У нас есть
[50:36.000 --> 50:38.000]  два атомика
[50:40.000 --> 50:42.000]  с индексами 0 и 1.
[50:42.000 --> 50:44.000]  У нас есть два потока.
[50:44.000 --> 50:46.000]  И у них есть пусть даже номера.
[50:46.000 --> 50:48.000]  Это классическая задача, которая
[50:48.000 --> 50:50.000]  непонятно зачем нужна,
[50:50.000 --> 50:52.000]  потому что она не практичная абсолютно,
[50:52.000 --> 50:54.000]  но все-таки мы на ее примере кое-что сможем увидеть.
[50:54.000 --> 50:56.000]  У нас мютекс
[50:56.000 --> 50:58.000]  с немного таким странным
[50:58.000 --> 51:00.000]  API, метод лог принимает аргумент,
[51:00.000 --> 51:02.000]  какой именно поток его захватывает,
[51:02.000 --> 51:04.000]  либо нулевой, либо первый,
[51:04.000 --> 51:06.000]  чтобы мютексу было проще.
[51:06.000 --> 51:08.000]  Ну и вот смотрите реализацию
[51:08.000 --> 51:10.000]  метода лог.
[51:10.000 --> 51:12.000]  Мы ставим флажок, что мы текущий,
[51:12.000 --> 51:14.000]  вот мы поток с индексом index
[51:16.000 --> 51:18.000]  хотим получить лог,
[51:18.000 --> 51:20.000]  а потом мы ждем,
[51:20.000 --> 51:22.000]  если другой поток тоже хочет.
[51:24.000 --> 51:26.000]  В методе unlock мы сбрасываем свой флажок.
[51:26.000 --> 51:28.000]  Ну вот такая незатейливая реализация.
[51:28.000 --> 51:30.000]  Что мы про нее скажем?
[51:36.000 --> 51:38.000]  Нарушает ли эта реализация свойства
[51:38.000 --> 51:40.000]  safety, взаимное исключение?
[51:40.000 --> 51:42.000]  Какие потоки находятся между lock и unlock одновременно?
[51:42.000 --> 51:44.000]  Нет, не могут,
[51:44.000 --> 51:46.000]  потому что какой-то из потоков напишет
[51:46.000 --> 51:48.000]  в want вторым,
[51:48.000 --> 51:50.000]  ну в предположении, что мы живем
[51:50.000 --> 51:52.000]  в такой модели чередования,
[51:52.000 --> 51:54.000]  когда есть первый и второй всегда.
[51:54.000 --> 51:56.000]  И тогда тот, кто записывал
[51:56.000 --> 51:58.000]  вторым, обязан увидеть флажок первого.
[51:58.000 --> 52:00.000]  Поэтому через этот while не пройдет.
[52:00.000 --> 52:02.000]  Но здесь
[52:02.000 --> 52:04.000]  нет прогресса, потому что
[52:04.000 --> 52:06.000]  есть исполнение, где два потока
[52:06.000 --> 52:08.000]  сначала пишут в своей флажке, потом
[52:08.000 --> 52:10.000]  друг друга. Вот из этого
[52:10.000 --> 52:12.000]  состояния они уже не выйдут по этому коду.
[52:12.000 --> 52:14.000]  Можно сделать чуть лучше.
[52:14.000 --> 52:16.000]  Не то, что лучше, по-другому можно
[52:16.000 --> 52:18.000]  сделать.
[52:20.000 --> 52:22.000]  У нас здесь только один atomic victim
[52:22.000 --> 52:24.000]  и поток, когда приходит
[52:24.000 --> 52:26.000]  в lock, говорит, что вот я жертва,
[52:26.000 --> 52:28.000]  я жертвую собой в пользу другого.
[52:32.000 --> 52:34.000]  Гарантирует ли эта реализация взаимное исключение?
[52:38.000 --> 52:40.000]  Уже не очевидно, да?
[52:48.000 --> 52:50.000]  Почему это?
[52:52.000 --> 52:54.000]  Ну давай докажем, что
[52:54.000 --> 52:56.000]  гарантирует.
[52:56.000 --> 52:58.000]  Давай докажем, что гарантирует.
[52:58.000 --> 53:00.000]  Вот здесь два потока, они находятся
[53:00.000 --> 53:02.000]  между lock и unlock. Почему они находятся
[53:02.000 --> 53:04.000]  между lock и unlock? Потому что они
[53:04.000 --> 53:06.000]  увидели разные
[53:06.000 --> 53:08.000]  диктимы, да?
[53:08.000 --> 53:10.000]  Это же единственный способ пройти через
[53:10.000 --> 53:12.000]  этот цикл?
[53:16.000 --> 53:18.000]  Ну это будет удивительно, конечно.
[53:18.000 --> 53:20.000]  Я бы не стал это тратить на это время,
[53:20.000 --> 53:22.000]  честно говоря.
[53:32.000 --> 53:34.000]  А причем тут safety?
[53:36.000 --> 53:38.000]  Нет, то, что где-то кто-то зависнет,
[53:38.000 --> 53:40.000]  это не гарантия safety. Safety это то, что
[53:40.000 --> 53:42.000]  между lock и unlock двух потоков быть не может.
[53:42.000 --> 53:44.000]  Вот если два потока между lock и unlock
[53:44.000 --> 53:46.000]  находятся, то
[53:46.000 --> 53:48.000]  среди них есть тот, кто написал
[53:48.000 --> 53:50.000]  victim первым, и тот, кто написал
[53:50.000 --> 53:52.000]  вторым. Ну так второй не пройдет дальше.
[53:52.000 --> 53:54.000]  Так вот, еще раз, мы учимся разделять
[53:54.000 --> 53:56.000]  два свойства safety и liveness.
[53:56.000 --> 53:58.000]  Гарантия безопасности, гарантия прогресса.
[53:58.000 --> 54:00.000]  Безопасность здесь снова есть,
[54:00.000 --> 54:02.000]  прогресса снова нет.
[54:02.000 --> 54:04.000]  Но прогресса нет в другом смысле.
[54:04.000 --> 54:06.000]  Вот здесь прогресса не было, потому что
[54:06.000 --> 54:08.000]  до потока могли друг другу помешать.
[54:08.000 --> 54:10.000]  То есть, когда они находятся
[54:10.000 --> 54:12.000]  между lock и lock,
[54:12.000 --> 54:14.000]  то они находятся в другом смысле.
[54:14.000 --> 54:16.000]  И вот здесь мы можем
[54:16.000 --> 54:18.000]  определить, что это гарантия
[54:18.000 --> 54:20.000]  safety и liveness.
[54:20.000 --> 54:22.000]  То есть, когда они
[54:22.000 --> 54:24.000]  блокировали друг друга, то они
[54:24.000 --> 54:26.000]  в смысле потоки зависали,
[54:26.000 --> 54:28.000]  когда их было двое.
[54:28.000 --> 54:30.000]  Здесь же, когда потоков двое, один из них
[54:30.000 --> 54:32.000]  точно не зависнет. Один из них точно пройдет.
[54:32.000 --> 54:34.000]  Но если поток один, то он
[54:34.000 --> 54:36.000]  захватить на Мютекс не сможет, что довольно тупо.
[54:36.000 --> 54:38.000]  Вот, поэтому мы приходим
[54:38.000 --> 54:40.000]  к Мютексу Петерсена, классическому,
[54:40.000 --> 54:42.000]  самому старому протоколу взаимного
[54:42.000 --> 54:44.000]  исключения, где совмещаются
[54:44.000 --> 54:46.000]  два неправильных метода.
[54:46.000 --> 54:48.000]  Мы выполняем и первую строчку, и вторую, и совмещаем
[54:48.000 --> 54:50.000]  условия ожидания. То есть, мы ждем
[54:50.000 --> 54:52.000]  другого, если другой тоже
[54:52.000 --> 54:54.000]  хочет попасть в критическую секцию,
[54:54.000 --> 54:56.000]  и при этом жертвует
[54:56.000 --> 54:58.000]  о мы. То есть, мы пришли последними.
[54:58.000 --> 55:00.000]  То есть, мы проходим
[55:00.000 --> 55:02.000]  либо если мы не
[55:02.000 --> 55:04.000]  пришли последними, либо
[55:04.000 --> 55:06.000]  наш сосед не хочет, наш конкурент
[55:06.000 --> 55:08.000]  не хочет захватить блокировку.
[55:08.000 --> 55:10.000]  Ну и, конечно, это не универсальный
[55:10.000 --> 55:12.000]  способ, в смысле совмещать два неправильных
[55:12.000 --> 55:14.000]  решения, обычно это не работает. Но здесь
[55:14.000 --> 55:16.000]  это работает.
[55:16.000 --> 55:18.000]  Ну и давайте, я не знаю, подумаем, почему
[55:18.000 --> 55:20.000]  это работает.
[55:20.000 --> 55:22.000]  Ну, это
[55:22.000 --> 55:24.000]  два флажка атомарных,
[55:24.000 --> 55:26.000]  которые означают, что поток,
[55:26.000 --> 55:28.000]  который в них что-то записал, желает захватить
[55:28.000 --> 55:30.000]  блокировку. Смысл у них такой,
[55:30.000 --> 55:32.000]  поэтому такое название.
[55:34.000 --> 55:36.000]  Мы сбрасываем флажок
[55:36.000 --> 55:38.000]  снова, что мы не хотим
[55:40.000 --> 55:42.000]  больше.
[55:42.000 --> 55:44.000]  Мы сбрасываем этот флажок, и если нас ждали,
[55:44.000 --> 55:46.000]  то мы пробегаем, то другой пробегает вперед.
[55:50.000 --> 55:52.000]  Один минус индекс
[55:52.000 --> 55:54.000]  это наш конкурент. Ну, то есть, если
[55:54.000 --> 55:56.000]  у нас номер индекс, а
[55:56.000 --> 55:58.000]  load – это чтение ячейки памяти, чтение
[55:58.000 --> 56:00.000]  атомика. Store и load – две операции.
[56:00.000 --> 56:02.000]  Запись чтения.
[56:10.000 --> 56:12.000]  Такое, конечно, может быть.
[56:12.000 --> 56:14.000]  Но мы же перечитаем его здесь,
[56:14.000 --> 56:16.000]  мы же в цикле крутимся.
[56:18.000 --> 56:20.000]  Да?
[56:22.000 --> 56:24.000]  Ну, давайте подумаем, почему это
[56:24.000 --> 56:26.000]  работает.
[56:28.000 --> 56:30.000]  Опять, пусть два потока нарушают
[56:30.000 --> 56:32.000]  взаимные исключения, находятся между локом
[56:32.000 --> 56:34.000]  и отлоком. Ну, давайте
[56:34.000 --> 56:36.000]  среди них выберем тот, кто записал
[56:36.000 --> 56:38.000]  виктим последним.
[56:42.000 --> 56:44.000]  Тогда что происходит?
[56:56.000 --> 56:58.000]  Ну, тогда, видимо, другой поток
[56:58.000 --> 57:00.000]  обязан сейчас
[57:00.000 --> 57:02.000]  аккуратно.
[57:06.000 --> 57:08.000]  Нет, жертва через вайл не может пройти
[57:08.000 --> 57:10.000]  как раз.
[57:10.000 --> 57:12.000]  Все кроме жертвы могут пройти через вайл,
[57:12.000 --> 57:14.000]  ну, в смысле, все другой поток.
[57:22.000 --> 57:24.000]  Ну, вот.
[57:24.000 --> 57:26.000]  Два потока.
[57:26.000 --> 57:28.000]  Мы предполагаем, что если мы используем
[57:28.000 --> 57:30.000]  атомики, то мы можем
[57:30.000 --> 57:32.000]  рассуждать об исполнении этой
[57:32.000 --> 57:34.000]  программы с помощью модели чередования.
[57:34.000 --> 57:36.000]  То есть, как будто бы все шаги происходят
[57:36.000 --> 57:38.000]  по одному. Ну, и что мы дальше
[57:38.000 --> 57:40.000]  говорим? Посмотрим на поток, который записал
[57:40.000 --> 57:42.000]  виктим вторым.
[57:42.000 --> 57:44.000]  Предположение, что здесь первый и второй.
[57:44.000 --> 57:46.000]  Не по индексам, а вот
[57:46.000 --> 57:48.000]  по порядку записи в этой
[57:48.000 --> 57:50.000]  ячейку памяти.
[57:50.000 --> 57:52.000]  И он при этом между локом и отлоком.
[57:52.000 --> 57:54.000]  Но что же он увидит в этом цикле?
[57:54.000 --> 57:56.000]  Если он записал
[57:56.000 --> 57:58.000]  виктим вторым, то, во-первых, он
[57:58.000 --> 58:00.000]  видит здесь себя,
[58:00.000 --> 58:02.000]  а еще он знает, что его...
[58:02.000 --> 58:04.000]  Ну, не то, что он знает, он не знает, но мы знаем
[58:04.000 --> 58:06.000]  по нашему предположению, что другой поток
[58:06.000 --> 58:08.000]  уже сделал запись виктим,
[58:08.000 --> 58:10.000]  а значит, он сделал запись в флажок want
[58:10.000 --> 58:12.000]  в свою ячейку. И значит,
[58:12.000 --> 58:14.000]  мы этот флажок видим, и снова он нам мешает
[58:14.000 --> 58:16.000]  пройти. Нам и это правило мешает пройти,
[58:16.000 --> 58:18.000]  и это правило мешает пройти, и тогда непонятно,
[58:18.000 --> 58:20.000]  как же мы оказались, как же мы
[58:20.000 --> 58:22.000]  завершили вызов лог.
[58:22.000 --> 58:24.000]  Вот, то есть,
[58:24.000 --> 58:26.000]  эта
[58:26.000 --> 58:28.000]  реализация обеспечивает сейфти все еще,
[58:28.000 --> 58:30.000]  но теперь она обеспечивает и лайвнес,
[58:30.000 --> 58:32.000]  то есть, она обеспечивает прогресс, потому что
[58:32.000 --> 58:34.000]  если поток один, то он уже не может бесконечно
[58:34.000 --> 58:38.600]  кружиться в этом цикле, потому что у соседа не будет флажка вон.
[58:38.600 --> 58:42.280]  Если же потоков двое, то они не смогут оба кружиться,
[58:42.280 --> 58:48.280]  потому что для этого они должны видеть разные значения виктима.
[58:48.280 --> 58:54.280]  Только тут двойной лог, он сработает, как если бы он был анлоком в некотором смысле.
[58:54.280 --> 58:57.280]  Сейчас, я вот это не готов понимать.
[58:57.280 --> 59:00.680]  Если в одном потоке вызвать лог два раза подряд...
[59:00.680 --> 59:02.680]  то это получается undefined behavior.
[59:02.680 --> 59:07.680]  В смысле, не делайте так, не рассуждайте так, что будет, если вызвать лог дважды,
[59:07.680 --> 59:11.680]  или вызвать анлок без лока, это все все плюс-плюс неопределенное поведение.
[59:11.680 --> 59:15.680]  В конкретной реализации будет что-то конкретное, а в общем случае никаких гарантий вам не дается.
[59:15.680 --> 59:18.680]  Это просто неправильное использование мютокса.
[59:18.680 --> 59:22.680]  У вас должны быть лог, потом анлок. Вот и все.
[59:22.680 --> 59:26.680]  А это вообще, кстати говоря, хорошо, что вы просто постоянно в айле крутимся?
[59:26.680 --> 59:30.680]  Это плохо, но до этого нужно еще дойти. Это вообще никуда не годится.
[59:30.680 --> 59:34.680]  Так писать не нужно, только код нужно удалять сразу.
[59:34.680 --> 59:38.680]  Но давайте пока маленькую логическую задачу решим.
[59:38.680 --> 59:42.680]  Вот у нас есть мютокс для двух потоков. Как сделать мютокс для N потоков?
[59:42.680 --> 59:47.680]  Опять же, мы живем в предположении, что у нас потоки пронумерованы, это нам сильно упрощает жизнь.
[59:47.680 --> 59:54.680]  Вот есть потоки с номерами от 0 до N, минус 1, и нам нужно собрать мютокс для N потоков.
[59:54.680 --> 59:58.680]  Вот такая вот бесполезная разминка для ума, ну почти бесполезная.
[59:58.680 --> 01:00:02.680]  Делать логариф Максом мютокс?
[01:00:02.680 --> 01:00:05.680]  Как-нибудь попроще объясни мне свою мысль, чтобы я понял.
[01:00:05.680 --> 01:00:11.680]  Я хочу, чтобы у каждого мютокса был номер, и он представлялся в виде двоичной последовательности.
[01:00:11.680 --> 01:00:15.680]  И вот мютокс на каждый разряд.
[01:00:15.680 --> 01:00:23.680]  Ну это похоже, это можно описать гораздо проще. Можно дерево построить, вот ты же про это на самом деле говоришь.
[01:00:23.680 --> 01:00:29.680]  И мы собираем такое вот дерево, Tournament Tree, из этих блоков мютоксов Петерсена,
[01:00:29.680 --> 01:00:34.680]  и поток по нему взбирается, обыгрывая конкурентов, и в конце концов падает в критическую секцию.
[01:00:34.680 --> 01:00:38.680]  В этом нет никакого смысла, вот просто забудьте это сейчас же.
[01:00:38.680 --> 01:00:41.680]  И вот это почти что можно забыть.
[01:00:41.680 --> 01:00:46.680]  Наша цель не в этом. Наша цель была вот сейчас в этом примере продемонстрировать,
[01:00:46.680 --> 01:00:49.680]  ну вот этими примерами продемонстрировать две вещи.
[01:00:49.680 --> 01:00:57.680]  Первая мысль. Видите, нам чтобы сделать взаимное исключение для n потоков,
[01:00:57.680 --> 01:01:00.680]  нужно удобно знать их номера.
[01:01:00.680 --> 01:01:05.680]  Ну мы не пытались иначе, я просто так условия задал, но это было удобно.
[01:01:05.680 --> 01:01:11.680]  Но в Mutex Log и Mutex Unlock этого нет, никаких номеров в стандартной библиотеке.
[01:01:11.680 --> 01:01:15.680]  А еще нам потребовалось много ячеек памяти.
[01:01:15.680 --> 01:01:20.680]  Вот у нас здесь линейное количество Mutex,
[01:01:20.680 --> 01:01:27.680]  и для этих Mutex по 3 ячейки внутри можно ли эффективнее сделать?
[01:01:27.680 --> 01:01:38.680]  Ну или по-другому, можно ли сделать эффективнее, если использовать что-то кроме обычных операций Store и Load у Atomic?
[01:01:38.680 --> 01:01:44.680]  Ну вот мы к этому и идем. Сейчас к тому, что в процессоре есть более эффективные операции,
[01:01:44.680 --> 01:01:47.680]  чем Load и Store, просто чтение и запись.
[01:01:47.680 --> 01:01:52.680]  Для синхронизации, возможно, можно придумать что-то эффективнее.
[01:01:52.680 --> 01:01:57.680]  Но это вторая мысль, которую я хочу прийти и дальше продолжить.
[01:01:57.680 --> 01:02:04.680]  А пока маленькая, ну то ли шутка, это не шутка, на самом деле, очень не смешно вообще то, что сейчас будет.
[01:02:04.680 --> 01:02:15.680]  Вот смотрите, в теории у вас есть лог Петерсона, и мы вроде бы сейчас доказали, что он обеспечивает взаимные исключения.
[01:02:15.680 --> 01:02:18.680]  Мы не должны в этом сомневаться, да?
[01:02:18.680 --> 01:02:23.680]  Вы сомневаетесь, да?
[01:02:23.680 --> 01:02:27.680]  Там вроде не в чем сомневаться, все слишком просто.
[01:02:27.680 --> 01:02:32.680]  Но смотрите, я вам сейчас покажу некоторый код.
[01:02:32.680 --> 01:02:39.680]  Вот две ячейки памяти X и Y, типа IN.
[01:02:39.680 --> 01:02:51.680]  Два потока. Мы в первом потоке читаем, пишем в X единицу, сначала там ноль, потом читаем из Y, в свою локальную переменную.
[01:02:51.680 --> 01:02:56.680]  То есть с этими ячейками работают оба потока, а второй поток делает симметрично.
[01:02:56.680 --> 01:02:59.680]  Он пишет в Y и читает из X.
[01:02:59.680 --> 01:03:05.680]  Вот R1 и R2 – это такие локальные ячейки памяти для потоков, с ними работает только T1 и T2.
[01:03:05.680 --> 01:03:10.680]  X и Y – они разделяемые. Мы здесь пишем, вы здесь читаем из X.
[01:03:10.680 --> 01:03:12.680]  Они не атомики.
[01:03:12.680 --> 01:03:19.680]  Но смотрите, процессор вообще-то пишет в 64-битные слова выровненные, а компилятор, конечно, это выравнивает все.
[01:03:19.680 --> 01:03:34.680]  Атомарно. Вот если вы пишете в INT из одного потока, а из другого вы читаете, то нет никаких шансов, что чтение будет половину записи, половину бит от старого значения, половину от нового.
[01:03:34.680 --> 01:03:37.680]  Нет, так не будет.
[01:03:37.680 --> 01:03:49.680]  Я же говорю, что атомик INT представляется в памяти как просто INT, они одинаково представлены, просто ячейка памяти.
[01:03:49.680 --> 01:03:55.680]  И вот я написал такой код. Почему он мне интересен? На что он похож?
[01:03:55.680 --> 01:04:10.680]  Вот мы только что делали мьютинг для двух потоков. Вот мы здесь, смотрите, пишем свой флажок, читаем из соседнего, из флажка соседа, конкурента нашего.
[01:04:10.680 --> 01:04:16.680]  Вот здесь же тоже самое написано, правда? Пишем в X, читаем из Y, пишем в Y, читаем из X.
[01:04:16.680 --> 01:04:27.680]  А потом проверяем, верно ли, что R1, R2 равны нулю оба. И если так, то наш процессор сломан.
[01:04:27.680 --> 01:04:41.680]  Ну, потому что, ну как, у нас первые шаги в обоих потоках – это запись либо X, либо Y. Как же здесь можно прочесть оба нуля, спросите вы, да?
[01:04:41.680 --> 01:04:49.680]  Ну, это такая вывернутая логика, так, надеюсь, люди не рассуждают. Вот если бы показать, не знаю, ребенку такой код, то что он подумает?
[01:04:49.680 --> 01:05:00.680]  Может ли получиться два нуля? Конечно же, нет. Вот. Ну, давайте узнаем. Давайте.
[01:05:00.680 --> 01:05:15.680]  Ну, вообще этот… Не, сломался. Вот тут очень сильно зависит от того, как он нагружен. Вот если не записывать видео и не открывать 10 приложений, то падает быстрее.
[01:05:15.680 --> 01:05:21.680]  Ну, в общем, два нуля получились. Процессор сломан, и Mutex не работает, Петерсона. Это довольно печально.
[01:05:21.680 --> 01:05:31.680]  Вот. Ну, то есть, можно сделать так, чтобы прямо Mutex с Петерсоном не работал. Можно его переписать на просто Bool и Insight, St, не важно.
[01:05:31.680 --> 01:05:46.680]  А вы С0 собирали? Что? Вы С0 собирали или чем повыше? С0, ну он даже с 0 упал. Да, тут есть, на самом деле, некоторая тонкость, потому что все-таки тут еще кое-что нужно написать.
[01:05:46.680 --> 01:05:56.680]  То есть, тут есть какой-то барьер для компилятора, чтобы было совсем честно. Но вот он есть, а все равно ломается. Это такая…
[01:05:56.680 --> 01:06:09.680]  В аудитории появился очень хитрый студент, который забегает далеко вперед. Фенсы, заборы, вот эти барьеры памяти – это сложная история.
[01:06:09.680 --> 01:06:18.680]  Это сложная история, и цель наших лекций про модели памяти, которая будет еще когда-то, состоит в том, чтобы вы не думали про барьеры памяти.
[01:06:18.680 --> 01:06:24.680]  Это неправильный способ об этом рассуждать. Но да, если поставить барьер памяти, то, конечно, эта проблема исправится.
[01:06:24.680 --> 01:06:34.680]  Собственно, для этого они и существуют в процессоре. Но вот сам по себе процессор, смотрите, он гарантирует, что работа с каждым отдельным интом атомарна,
[01:06:34.680 --> 01:06:42.680]  действительно, каждый отдельный ячейк памяти атомарна, но почему-то об их совокупности больше нельзя рассуждать в модели чередования.
[01:06:42.680 --> 01:06:52.680]  Вот вам об этом говорят прямо в документации процессора. На ARM еще веселее, там гораздо больше таких сценариев странных.
[01:06:52.680 --> 01:07:03.680]  Вот почему так? Это сложный вопрос, но пока вот просто имейте в виду, что рассуждать об исполнении программы как вот о таком последовательном исполнении всех инструкций
[01:07:03.680 --> 01:07:08.680]  с перепрыгиванием между потоками, вот эта модель, она в реальности не работает.
[01:07:08.680 --> 01:07:23.680]  Ну, Мьютокс Петерсон, он в верных предположениях, что вот у нас модель чередования. Модель чередования прямо из коробки в процессоре не работает, не обеспечивается.
[01:07:23.680 --> 01:07:33.680]  Чтобы она работала, чтобы ей можно было пользоваться, нужно соблюсти ряд довольно хитрых условий, которые невозможно сейчас объяснить, а в первом приближении нужно использовать атомики.
[01:07:33.680 --> 01:07:43.680]  Ну ладно, перестанем о плохом говорить, поговорим о хорошем. Мы хотим все-таки сделать что-то, ну в смысле Мьютокс как-то эффективнее.
[01:07:43.680 --> 01:07:47.680]  А с атомиками работает Мьютокс Петерсон?
[01:07:47.680 --> 01:08:00.680]  Да, работает. Ну разумеется. Ну в смысле потому что атомики дают, я сказал, почти сами по себе дают модель чередования, а в модели чередования мы доказали, что Мьютокс корректен.
[01:08:00.680 --> 01:08:05.680]  Ну Мьютокс Петерсон на самом по себе никому не нужен, он скорее нужен для демонстрации этого примера.
[01:08:05.680 --> 01:08:10.680]  А вот то, что мы сейчас поговорим, очень полезно и полезно, например, в ядре. Линуксы используются повсюду.
[01:08:10.680 --> 01:08:24.680]  Мы хотим сделать протокол взаимоскучения эффективнее в том смысле, что мы хотим использовать меньше ячеек памяти и сделать быстрый путь, когда, например, Мьютокс свободен гораздо эффективнее, чем подъем по этому странному дереву.
[01:08:24.680 --> 01:08:31.680]  Для этого в процессоре, собственно, есть такая понятная задача сделать протокол взаимоскучения.
[01:08:31.680 --> 01:08:38.680]  Раз уж процессор дал вам ядра, он вам дает и какие-то дополнительные механизмы, чтобы эту задачу эффективно решать.
[01:08:38.680 --> 01:08:45.680]  Эти инструменты называются Read-Modify-Write-операция.
[01:08:45.680 --> 01:08:54.680]  То есть вы можете в ячеек памяти не только записать что-то и прочесть, вы можете сделать что-то более хитрое из трех шагов.
[01:08:54.680 --> 01:08:59.680]  Прочесть, как-то модифицировать, а потом записать и сделать это атомарно.
[01:08:59.680 --> 01:09:05.680]  Ну и тут можно обратиться к документации, посмотреть на Atomic.
[01:09:05.680 --> 01:09:11.680]  Вот тут есть какие-то вызовы Store, Load. Store, Load мы уже обсудили. Есть Exchange, есть Comperexchange.
[01:09:11.680 --> 01:09:17.680]  Есть FetchAdd, FetchSub, какие-то разные Fetch что-то, что-нибудь.
[01:09:17.680 --> 01:09:23.680]  Вот давайте коротко по ним прибежим. Store и Load – это понятно. Это записи, чтения, соответственно.
[01:09:23.680 --> 01:09:29.680]  А вот есть FetchAdd. Это атомарная операция, которая читает значение ячеек памяти Atomic,
[01:09:29.680 --> 01:09:36.680]  добавляет к нему аргумент и записывает результат обратного Atomic – ячеек памяти.
[01:09:36.680 --> 01:09:43.680]  И все это происходит атомарно в том смысле, что другие операции, скажем, другие лоды не могут увидеть…
[01:09:43.680 --> 01:09:50.680]  Два FetchAd не могут как-то странно пересечься. Они не могут, скажем, увидеть одно и то же исходное значение.
[01:09:50.680 --> 01:09:58.680]  Если вы делаете FetchAdd единица, то вот оба FetchAd, двух потока, то оба FetchAd обязаны вернуть разные значения.
[01:09:58.680 --> 01:10:03.680]  Они не могут вернуть одно и то же. Они атомарны друг относительно друга.
[01:10:03.680 --> 01:10:10.680]  Есть операция xchange, которая про то, чтобы атомарно прочесть старое значение и записать новое значение.
[01:10:10.680 --> 01:10:18.680]  Ну и что мы можем с ними делать? Мы можем с помощью этих операций делать так называемые спинлоги.
[01:10:18.680 --> 01:10:23.680]  Вот давайте воспользуемся операцией xchange.
[01:10:23.680 --> 01:10:32.680]  Это Read, а это Write. А это Modify.
[01:10:32.680 --> 01:10:37.680]  Ну вот потому что они вот так вот называются.
[01:10:37.680 --> 01:10:43.680]  Три шага. Здесь два шага, здесь по одному шагу.
[01:10:43.680 --> 01:10:46.680]  Ну вот. Простейший спинлог.
[01:10:46.680 --> 01:10:51.680]  Как сделать протокол взаимного исключения с помощью одного единственного AtomicBool,
[01:10:51.680 --> 01:10:56.680]  по сути, логически одного бита, имея атомарную операцию xchange.
[01:10:56.680 --> 01:10:59.680]  Атомарно прочесть и записать новое значение.
[01:10:59.680 --> 01:11:04.680]  Ну вот так вот. Давайте посмотрим на нее несколько секунд и поймем, как она работает.
[01:11:04.680 --> 01:11:19.680]  Ну вот. Тут единственное поле, Locked. Там написано, верно ли, что спинлог сейчас захвачен или он свободен.
[01:11:19.680 --> 01:11:22.680]  Если True, то захвачен, если False, то свободен.
[01:11:22.680 --> 01:11:26.680]  Если мы хотим его захватить, то мы атомарно пытаемся записать в него True.
[01:11:26.680 --> 01:11:31.680]  И если мы записали True, а там был False, то мы захватили его, мы были первыми.
[01:11:31.680 --> 01:11:36.680]  Если мы были не первыми, то мы записали True все же, но при этом и прочитали True.
[01:11:36.680 --> 01:11:41.680]  И значит спинлог был захвачен кем-то другим уже. Мы попробуем снова.
[01:11:41.680 --> 01:11:45.680]  Мы опять сейчас с Валей сидим.
[01:11:45.680 --> 01:11:50.680]  Совершенно верно. Мы по-прежнему ничего хорошего здесь не написали.
[01:11:50.680 --> 01:11:57.680]  Но наш код стал гораздо проще. Вот такой код освоит любой первоклассник.
[01:11:57.680 --> 01:12:00.680]  Понятно ли он?
[01:12:00.680 --> 01:12:04.680]  Хорошо. Есть ли в нем недостатки?
[01:12:04.680 --> 01:12:11.680]  Кроме того, что он вращается в этом цикле, греет процессор.
[01:12:11.680 --> 01:12:16.680]  Он не гарантирует, что поток, который зашел в Lock, когда-нибудь из него выйдет.
[01:12:16.680 --> 01:12:19.680]  Прямо скажем, маловероятно, что кто-то будет постоянно проигрывать,
[01:12:19.680 --> 01:12:22.680]  а другие будут его опережать бесконечно долго.
[01:12:22.680 --> 01:12:27.680]  Но все же гарантии прогресса для каждого потока здесь нет.
[01:12:27.680 --> 01:12:34.680]  Как обеспечить прогресс для каждого потока?
[01:12:34.680 --> 01:12:36.680]  Поставить их в очередь.
[01:12:36.680 --> 01:12:38.680]  Поставить их в очередь, да.
[01:12:38.680 --> 01:12:44.680]  И для этого есть...
[01:12:44.680 --> 01:12:47.680]  Для этого есть другая операция. Она называется...
[01:12:47.680 --> 01:12:53.680]  Сейчас, по-другому немного.
[01:12:53.680 --> 01:12:56.680]  Давайте откатимся на один шаг назад.
[01:12:56.680 --> 01:12:59.680]  И прежде чем делать очередь с помощью другой атомарной операции,
[01:12:59.680 --> 01:13:01.680]  поговорим, собственно, про эту атомарную операцию.
[01:13:01.680 --> 01:13:02.680]  Вот фич ad.
[01:13:02.680 --> 01:13:07.680]  Атомарно прочесть, увеличить или уменьшить, записать.
[01:13:07.680 --> 01:13:09.680]  Новое значение.
[01:13:09.680 --> 01:13:12.680]  Вот где такая операция может быть...
[01:13:12.680 --> 01:13:16.680]  Уже могла быть вами использована, даже если вы об этом не знаете.
[01:13:16.680 --> 01:13:20.680]  Оказывается, что shared pointer для счетчика ссылок
[01:13:20.680 --> 01:13:24.680]  использует атомарные инкременты и декременты,
[01:13:24.680 --> 01:13:27.680]  даже если это вам не нужно.
[01:13:27.680 --> 01:13:30.680]  Это не заслуга shared pointer, это его изъян.
[01:13:30.680 --> 01:13:33.680]  Но вот, тем не менее, счетчик ссылок там атомарен,
[01:13:33.680 --> 01:13:36.680]  потому что с shared pointer в определенных границах
[01:13:36.680 --> 01:13:38.680]  можно работать из разных потоков.
[01:13:38.680 --> 01:13:41.680]  Так вот, фич это нужен, потому что сама по себе
[01:13:41.680 --> 01:13:44.680]  операция инкремента не атомарна.
[01:13:44.680 --> 01:13:46.680]  Мы сначала должны загрузить значение в регистр,
[01:13:46.680 --> 01:13:49.680]  увеличить регистр на единицу, потом загрузить из регистр
[01:13:49.680 --> 01:13:52.680]  обратно в память значение новое.
[01:13:52.680 --> 01:13:55.680]  И вот точно так же, как со строчками в списке,
[01:13:55.680 --> 01:13:58.680]  вот эти инструкции могут...
[01:13:58.680 --> 01:14:01.680]  Эти три инструкции, исполняемые параллельно на двух ядрах,
[01:14:01.680 --> 01:14:03.680]  могут переплетаться друг с другом.
[01:14:03.680 --> 01:14:05.680]  И в итоге мы можем дважды загрузить одно и то же значение,
[01:14:05.680 --> 01:14:08.680]  дважды его увеличить, потом дважды записать одно и то же.
[01:14:08.680 --> 01:14:10.680]  И мы потеряем один инкремент.
[01:14:10.680 --> 01:14:13.680]  Два инкремента исполнятся, но эффект будет как от одного.
[01:14:13.680 --> 01:14:16.680]  Ну, если у нас есть все же операция,
[01:14:16.680 --> 01:14:19.680]  которая умеет делать такой инкремент атомарно
[01:14:19.680 --> 01:14:22.680]  и возвращать при этом старое значение,
[01:14:22.680 --> 01:14:26.680]  то мы можем сделать из этой операции ticket log.
[01:14:26.680 --> 01:14:29.680]  Вот буквально очередь, которую вы можете наблюдать,
[01:14:29.680 --> 01:14:31.680]  не знаю, где-нибудь в Сбербанке.
[01:14:31.680 --> 01:14:34.680]  Вы приходите, отрываете себе номерок,
[01:14:34.680 --> 01:14:37.680]  то есть говорите фич add,
[01:14:37.680 --> 01:14:40.680]  добавляете свой уникальный монотонный номер,
[01:14:40.680 --> 01:14:42.680]  который не может повториться,
[01:14:42.680 --> 01:14:45.680]  потому что все фич add атомарны, они стоят на друг друга.
[01:14:45.680 --> 01:14:48.680]  А дальше просто смотрите на табло и ждете, когда ваш номер совпадет.
[01:14:48.680 --> 01:14:51.680]  Итого вам нужно два атомика.
[01:14:53.680 --> 01:14:57.680]  Один из них говорит, какой номерок будет следующим,
[01:14:57.680 --> 01:15:02.680]  а второй атомик говорит, кто сейчас владеет блокировкой.
[01:15:02.680 --> 01:15:06.680]  Ну и вот вы приходите, говорите с помощью фич add,
[01:15:06.680 --> 01:15:09.680]  с помощью фич add получаете номерок,
[01:15:09.680 --> 01:15:12.680]  а дальше ждете, пока он не сгорится на табло.
[01:15:12.680 --> 01:15:16.680]  Кто двигает табло вперед, тот, кто вызывает анлок.
[01:15:20.680 --> 01:15:24.680]  — А что делать, если мы дойдем до максимального значения?
[01:15:24.680 --> 01:15:28.680]  — Мы никогда не дойдем до максимального значения N64.
[01:15:28.680 --> 01:15:30.680]  Нет.
[01:15:30.680 --> 01:15:33.680]  Но вы можете посчитать, взять свой процессор,
[01:15:33.680 --> 01:15:36.680]  тактовую частоту, взять диапазон значений,
[01:15:36.680 --> 01:15:39.680]  поделить, посмотреть, сколько лет потребуется.
[01:15:39.680 --> 01:15:42.680]  Нет, этого не случится.
[01:15:52.680 --> 01:15:55.680]  — Можно ли использовать N84?
[01:15:55.680 --> 01:15:56.680]  — А?
[01:15:56.680 --> 01:15:59.680]  — Можно ли использовать N84?
[01:15:59.680 --> 01:16:02.680]  — Ну, чтобы стало хуже?
[01:16:02.680 --> 01:16:04.680]  — Ну, тогда мы дойдем.
[01:16:04.680 --> 01:16:07.680]  — Может быть не 128, вот не знаю.
[01:16:07.680 --> 01:16:10.680]  — 128 вот можешь, но не везде.
[01:16:10.680 --> 01:16:13.680]  Так, ну у нас заканчивается время,
[01:16:13.680 --> 01:16:16.680]  а мы не поговорили про самое важное,
[01:16:16.680 --> 01:16:18.680]  что нам так хотелось узнать.
[01:16:18.680 --> 01:16:21.680]  Вот нас беспокоит, смотрите, что мы пишем вот такие спинлоки,
[01:16:21.680 --> 01:16:24.680]  они очень простые, но при этом у нас здесь какая-то тупизна написана.
[01:16:24.680 --> 01:16:27.680]  Мы крутимся в цикле, греем процессор.
[01:16:27.680 --> 01:16:30.680]  Можно здесь написать что-то лучшее?
[01:16:30.680 --> 01:16:33.680]  — Конечно, можно, да.
[01:16:33.680 --> 01:16:36.680]  И вот смотрите, что можно сделать в первую очередь.
[01:16:36.680 --> 01:16:39.680]  Ну, во-первых, вот то, что мы сделали,
[01:16:39.680 --> 01:16:42.680]  называется busy weighting, и вот это называется спинлоки.
[01:16:42.680 --> 01:16:45.680]  Вот спинлок — это когда вы крутитесь на процессоре,
[01:16:45.680 --> 01:16:48.680]  то есть вы хотите получить блокировку,
[01:16:48.680 --> 01:16:52.680]  но при этом вы верите, что надолго
[01:16:52.680 --> 01:16:55.680]  и другие потоки не займут, поэтому вы лучше покрутитесь
[01:16:55.680 --> 01:16:58.680]  и дождетесь прямо на процессоре, не снимаясь с него.
[01:16:58.680 --> 01:17:01.680]  Ну вот, чтобы крутиться было приятнее процессору,
[01:17:01.680 --> 01:17:04.680]  а не вам, у процессора есть специальная инструкция,
[01:17:04.680 --> 01:17:07.680]  которая называется пауз.
[01:17:07.680 --> 01:17:10.680]  Вот я сейчас открою документацию для нее.
[01:17:13.680 --> 01:17:17.680]  Она про то, чтобы, ну грубо говоря,
[01:17:17.680 --> 01:17:20.680]  логическое гиперядро, гипертрединг в смысле,
[01:17:20.680 --> 01:17:23.680]  гиперпоток в процессоре,
[01:17:23.680 --> 01:17:26.680]  встал на небольшую паузу,
[01:17:26.680 --> 01:17:29.680]  отдал инструкции своему соседу,
[01:17:29.680 --> 01:17:32.680]  другому гипертреду.
[01:17:32.680 --> 01:17:35.680]  Ну, в общем, поменьше тратил,
[01:17:35.680 --> 01:17:38.680]  уменьшил энергопотребление,
[01:17:38.680 --> 01:17:41.680]  и отдал процессору возможность
[01:17:41.680 --> 01:17:44.680]  исполнять сейчас что-то другое.
[01:17:44.680 --> 01:17:47.680]  То есть вы говорите явно, то есть у вас есть хинт
[01:17:47.680 --> 01:17:50.680]  для процессора, что вот вы буквально написали спинлок
[01:17:50.680 --> 01:17:53.680]  и вы там ждете. Вот в процессоре для этого есть специальная
[01:17:53.680 --> 01:17:56.680]  инструкция. Я поток, в спинлоке кручусь.
[01:17:56.680 --> 01:17:59.680]  Можно как-то на меня тратить меньше ресурсов.
[01:17:59.680 --> 01:18:02.680]  Можно не прогружать там конвейер.
[01:18:02.680 --> 01:18:05.680]  Зачем мне конвейер?
[01:18:05.680 --> 01:18:08.680]  Но если вы будете крутиться долго, все равно вы пожираете ядро,
[01:18:08.680 --> 01:18:11.680]  вы занимаете место, которое могли бы занять другие.
[01:18:11.680 --> 01:18:14.680]  Что у вас есть дальше?
[01:18:20.680 --> 01:18:23.680]  В этом курсе не будет сигналов.
[01:18:23.680 --> 01:18:26.680]  Давайте мы про них забудем сразу навсегда.
[01:18:26.680 --> 01:18:29.680]  Есть вызов yield. Но yield вы уже наверное с ним познакомились
[01:18:29.680 --> 01:18:32.680]  в другом контексте, но смысл тот же самый.
[01:18:32.680 --> 01:18:35.680]  Вы говорите, я готов уступить ядро другому потоку,
[01:18:35.680 --> 01:18:38.680]  потому что прямо сейчас мне делать нечего.
[01:18:38.680 --> 01:18:41.680]  Я готов уйти с ядра.
[01:18:41.680 --> 01:18:44.680]  Разумно на практике их комбинировать.
[01:18:44.680 --> 01:18:47.680]  В смысле сначала некоторое время крутиться на ядре,
[01:18:47.680 --> 01:18:50.680]  потом перепланироваться через планировщик.
[01:18:50.680 --> 01:18:53.680]  Потом с ядра уходить. Делать это не сразу,
[01:18:53.680 --> 01:18:56.680]  потому что если критическая секция короткая у другого потока,
[01:18:56.680 --> 01:18:59.680]  если прямо сейчас почти мютекс спинлок освободится,
[01:18:59.680 --> 01:19:02.680]  вы тут же его подхватите и начнете делать полезную работу.
[01:19:02.680 --> 01:19:05.680]  Скажем, если вы пишете на языке,
[01:19:05.680 --> 01:19:08.680]  на языке Rust, там есть библиотека, которая называется Crossbeam,
[01:19:08.680 --> 01:19:11.680]  таких вот базовых примитивов для синхронизации, очень низкоуровневых.
[01:19:11.680 --> 01:19:14.680]  И там есть объект, который называется Backoff,
[01:19:14.680 --> 01:19:17.680]  который позволяет крутиться более эффективно.
[01:19:17.680 --> 01:19:20.680]  Ну в смысле сначала адаптивно делать пауз,
[01:19:20.680 --> 01:19:23.680]  потом переключаться на yield.
[01:19:23.680 --> 01:19:26.680]  В домашних работах, пожалуйста, для этого используйте
[01:19:26.680 --> 01:19:29.680]  вот такой вот класс, который делает то же самое.
[01:19:29.680 --> 01:19:32.680]  Вы его создаете, вы его используете,
[01:19:32.680 --> 01:19:35.680]  и крутитесь, вызывая вот оператор кругу из скобочки,
[01:19:35.680 --> 01:19:38.680]  а он там делает то, что он считает разумным.
[01:19:38.680 --> 01:19:41.680]  Это лучше, чем просто писать ничего.
[01:19:41.680 --> 01:19:44.680]  Вот, но теперь последнее, самое главное.
[01:19:44.680 --> 01:19:47.680]  Если же вы все-таки устали крутиться,
[01:19:47.680 --> 01:19:50.680]  то что разумно сделать?
[01:19:50.680 --> 01:19:53.680]  Ну все-таки покинуть ядро и не исполняться до тех пор,
[01:19:53.680 --> 01:19:56.680]  пока не наступит событие.
[01:19:56.680 --> 01:19:59.680]  Событие другого не исполняется.
[01:19:59.680 --> 01:20:02.680]  Вот не исполняться и ожидать чего-то,
[01:20:02.680 --> 01:20:05.680]  это то, что вы не можете сделать C++,
[01:20:05.680 --> 01:20:08.680]  потому что, ну как и в случае с yield,
[01:20:08.680 --> 01:20:11.680]  вы должны обратиться к планировщику,
[01:20:11.680 --> 01:20:14.680]  только планировщик вам может помочь.
[01:20:14.680 --> 01:20:17.680]  Поэтому у вас есть сискол,
[01:20:17.680 --> 01:20:20.680]  который называется FUTEX.
[01:20:20.680 --> 01:20:23.680]  Он очень сложный, но грубо говоря,
[01:20:23.680 --> 01:20:26.680]  у него есть две операции,
[01:20:26.680 --> 01:20:29.680]  которые в атомике тоже есть,
[01:20:29.680 --> 01:20:32.680]  и выглядят они немного иначе.
[01:20:32.680 --> 01:20:35.680]  Это операция wait и notify.
[01:20:35.680 --> 01:20:38.680]  Симантика такая,
[01:20:38.680 --> 01:20:41.680]  вы блокируете поток,
[01:20:41.680 --> 01:20:44.680]  если в атомике прямо сейчас лежит значение,
[01:20:44.680 --> 01:20:47.680]  которое равно вот этому.
[01:20:47.680 --> 01:20:50.680]  Это очень странно, что вы почему-то сравниваете
[01:20:50.680 --> 01:20:53.680]  с каким-то значением.
[01:20:53.680 --> 01:20:56.680]  Вы видите, что это не странно,
[01:20:56.680 --> 01:20:59.680]  что это очень естественно,
[01:20:59.680 --> 01:21:02.680]  но для этого нужно как-то подумать.
[01:21:02.680 --> 01:21:05.680]  И у вас есть парный вызов notify,
[01:21:05.680 --> 01:21:08.680]  который будет поток, который ждет в wait.
[01:21:08.680 --> 01:21:11.680]  Правда, wait потом просыпается и перепроверяет,
[01:21:11.680 --> 01:21:14.680]  что значение изменилось.
[01:21:14.680 --> 01:21:17.680]  Если не изменилось, то снова засыпает.
[01:21:17.680 --> 01:21:20.680]  Вот это чуть больше, чем вызов FUTEX делает,
[01:21:20.680 --> 01:21:23.680]  в домашке, вы там можете это все подробнее подсчитать.
[01:21:23.680 --> 01:21:26.680]  И вот тогда вы получаете то,
[01:21:26.680 --> 01:21:29.680]  что называется sleep lock или MUTOX.
[01:21:29.680 --> 01:21:32.680]  MUTOX спят, спинлоки крутятся и не засыпают.
[01:21:32.680 --> 01:21:35.680]  В этом разница.
[01:21:35.680 --> 01:21:38.680]  Ну ладно, мы задержались, я кое-что не успеваю рассказать.
[01:21:38.680 --> 01:21:41.680]  Давайте расскажу, зачем нам MUTOX
[01:21:41.680 --> 01:21:44.680]  и как мы будем дальше с ними работать.
[01:21:44.680 --> 01:21:47.680]  С помощью MUTOX мы будем делать синхронизацию,
[01:21:47.680 --> 01:21:50.680]  в домашке вы попробуете написать свои MUTOX
[01:21:50.680 --> 01:21:53.680]  и свои атомики, и вот неизбежно поймете, что это.
[01:21:53.680 --> 01:21:56.680]  Ну а дальше у нас цель такая,
[01:21:56.680 --> 01:21:59.680]  я вот обещал, что мы хотим написать свой маленький GO,
[01:21:59.680 --> 01:22:02.680]  и там будут свои маленькие MUTOX.
[01:22:02.680 --> 01:22:05.680]  И смысл всей этой конструкции в том, что они будут легковесными,
[01:22:05.680 --> 01:22:08.680]  в смысле мы можем блокировать наш легковесный поток,
[01:22:08.680 --> 01:22:11.680]  Fiber, при этом не погружаясь в ядро,
[01:22:11.680 --> 01:22:14.680]  не спрашивая операционную систему,
[01:22:14.680 --> 01:22:17.680]  а просто в очередь заснуть, подождать,
[01:22:17.680 --> 01:22:20.680]  мы должны будем делать это сами в user space.
[01:22:20.680 --> 01:22:23.680]  И вот вы сначала сделаете MUTOX сами для потоков,
[01:22:23.680 --> 01:22:26.680]  поймете, как их делать с помощью FUTOX,
[01:22:26.680 --> 01:22:29.680]  а потом когда-нибудь, когда вы дойдете до этого,
[01:22:29.680 --> 01:22:32.680]  мы переизобретем FUTOX и напишем их сами,
[01:22:32.680 --> 01:22:35.680]  и тогда получится уже runtime GO
[01:22:35.680 --> 01:22:38.680]  прямо в user space, прямо вашими руками.
[01:22:38.680 --> 01:22:41.680]  И второе направление, в котором мы улучшим MUTOX,
[01:22:41.680 --> 01:22:45.680]  это спинлок, вот такой вот спинлок, совершенно примитивный.
[01:22:45.680 --> 01:22:48.680]  Можно очень сильно оптимизировать,
[01:22:48.680 --> 01:22:51.680]  если вы знаете, как устроен процессор и память,
[01:22:51.680 --> 01:22:54.680]  как устроено их взаимодействие.
[01:22:54.680 --> 01:22:57.680]  Это не просто процессор и память,
[01:22:57.680 --> 01:23:00.680]  между ними много всего происходит еще сложного.
[01:23:00.680 --> 01:23:03.680]  И если вы понимаете, как работает компьютер, как устроен процессор,
[01:23:03.680 --> 01:23:06.680]  то вы можете буквально написать одну строчку или полторы строчки,
[01:23:06.680 --> 01:23:09.680]  и эта конструкция станет гораздо-гораздо эффективней.
[01:23:09.680 --> 01:23:12.680]  Спинлок, он, конечно же, никуда не годится.
[01:23:12.680 --> 01:23:15.680]  Не пишите его никуда, на работе пока.
[01:23:15.680 --> 01:23:18.680]  Ладно, все, спасибо большое.
[01:23:18.680 --> 01:23:21.680]  До свидания всем.
