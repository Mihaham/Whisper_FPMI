[00:00.000 --> 00:15.480]  Сегодня у нас, соответственно, седьмая лекция, восьмая по счету, в которой мы поговорим о том,
[00:15.480 --> 00:21.720]  как вообще архитектура процессора, архитектура платформы, под которую вы
[00:21.720 --> 00:28.000]  разрабатываете, может повлиять на архитектуру операционной системы.
[00:28.000 --> 00:38.560]  То есть типичное классическое представление, грубо говоря. У разработчика пакет поддержки
[00:38.560 --> 00:48.480]  аппаратуры, также называется TSP, сводится к тому, что есть некоторый процессор, нужно, соответственно,
[00:48.480 --> 00:54.960]  узнать, как у него работает сериал порт, то есть некоторое устройство, последовательный порт,
[00:54.960 --> 01:01.280]  он же UART, он же, соответственно, COM порт, в зависимости от конкретной железки. После этого понять,
[01:01.280 --> 01:08.920]  как работает memory management unit, настроить трансляцию из виртуальных адресов в физические,
[01:08.920 --> 01:19.440]  соответственно, завести аллокатор памяти и плюс-минус завести таймеры, после этого операционная
[01:19.440 --> 01:28.840]  система уже будет в каком-то виде работать. После этого там заводятся вещи типа доступ к периферийным
[01:28.840 --> 01:34.680]  устройствам, то есть появляются какие-то там шины фактически, ядра и так далее, то есть там
[01:34.680 --> 01:40.400]  расширяется поддержка контроллера прерываний, то есть появляются там всякие поддержки многоядерности,
[01:40.840 --> 01:50.240]  прерывания периферийных устройств, возможно, power management, но вот в целом такой базовый взгляд
[01:50.240 --> 02:02.040]  на архитектуру операционной системы, он сохраняется. К сожалению, это с одной стороны такой хороший путь,
[02:02.040 --> 02:11.120]  и все примерно там ему следуют, но не редки ситуации, когда какие-то особенности вот процессора,
[02:11.120 --> 02:18.880]  там архитектуры, там целевой платформы, они достаточно сильно влияют на устройство операционной
[02:18.880 --> 02:27.240]  системы и заставляют вас это устройство операционной системы переделывать. Вот, соответственно,
[02:27.240 --> 02:41.040]  сегодня мы поговорим о современных архитектурах процессоров с точки зрения разработчика
[02:41.040 --> 02:48.000]  операционной системы и конкретно немножко сфокусируемся на таких вещах, как атаки по
[02:48.000 --> 02:56.520]  побочным или они же сторонние, собственно, каналы. Для того, чтобы понять, вот как изменение в
[02:56.520 --> 03:02.840]  процессоре может привести к тому, что нам придется переделывать достаточно значимые
[03:02.840 --> 03:09.240]  куски операционной системы, от этого, в общем-то, никак не скрыться. Кроме этого, мы также поговорим
[03:09.240 --> 03:18.840]  про конвейеризацию, ну, я, по крайней мере, напомню про кэширование, о том, что не любое обращение
[03:18.840 --> 03:24.720]  к оперативной памяти, оно имеет одинаковую цену, и каким образом, вообще, достигаются
[03:24.720 --> 03:34.920]  достаточная производительность в современных учлительных системах. Почему это хорошо,
[03:34.920 --> 03:47.600]  почему это иногда бывает больно. Итак, ну, все вы знаете классическое сопоставление архитектур
[03:47.600 --> 03:54.520]  набора команд у процессоров, то есть, есть процессоры, которые умеют в риск, то есть,
[03:54.520 --> 04:00.200]  reduced instruction set, есть, соответственно, процессоры, которые умеют в циск, соответственно,
[04:00.200 --> 04:11.120]  complex instruction set. Яркие примеры, как раз перечисленные в скобочках, кто-нибудь слышал про такую
[04:11.120 --> 04:23.840]  архитектуру, которая называется IRC из присутствующих. Так, но, к счастью, у вас архитектура это плюс-минус
[04:23.840 --> 04:32.720]  весь езде. То есть, например, на том же процессоре Intel у вас есть Power Management Controller, который работает
[04:32.720 --> 04:41.840]  как раз под архитектурой Argonaut Risk Course или IRC. То есть, это одна из риск архитектур, которая
[04:41.840 --> 04:48.600]  применяется в встраиваемых устройствах, встраиваемых технике, в основном в небольших
[04:48.600 --> 04:58.840]  устройствах. Бывает там либо 16-битная, либо 300-битная. Соответственно, ARM, ну, как минимум, соответственно,
[04:58.840 --> 05:10.600]  у вас во всех телефонах. MIPS, ну, в основном всякие станки, CPU, различные управляющие системы,
[05:10.600 --> 05:21.320]  в том числе промышленные, оборонные промышленности. Power плотно занял две ниши. Соответственно, первая
[05:21.320 --> 05:32.600]  ниша – это суперкомпьютерные системы производства IBM. IBM Power 8, IBM Power 9. Вторая ниша – это
[05:32.600 --> 05:42.640]  automotive ниша, то есть всякая авианика, то есть большие там авиалайнеры, Airbus 320 какой-нибудь,
[05:42.640 --> 05:51.760]  всякие там машины, автомобили. Кроме этого, соответственно, у всех на слуху есть архитектура
[05:51.760 --> 06:01.960]  Risk5 и, в общем-то, некоторые другие. Вот это наиболее яркие представители Reduced Instruction Set в случае с
[06:01.960 --> 06:12.360]  CISC. Ну, наверное, наиболее яркий представитель – это x86, то есть, в общем-то, те машины, которые мы
[06:12.360 --> 06:19.880]  сейчас используем в повседневной жизни. Ну и, в принципе, там некоторые, скажем, относительно
[06:19.880 --> 06:34.440]  похожие на них, типа там вот Zilog Z80, но уже они там потихоньку отмирают. Чем характеризуются CISC и RISC SA?
[06:34.440 --> 06:42.400]  То есть, ну, CISC исторически появились раньше, и x86, ну, наверное, такой, один из немногих
[06:42.640 --> 06:50.360]  представителей CISC архитектур, который есть и по сей день, прекрасно применяется, прекрасно
[06:50.360 --> 07:00.400]  используется. Соответственно, у CISC архитектур большое количество инструкций, ну, то есть,
[07:00.400 --> 07:08.760]  большое количество оцепленных команд, которые предназначены там в первую очередь для того,
[07:08.760 --> 07:16.360]  чтобы программисту было удобно писать на ассемблере, когда же, соответственно,
[07:16.360 --> 07:23.400]  там в RISC архитектурах у вас, наоборот, набор, соответственно, инструкций достаточно небольшой,
[07:23.400 --> 07:33.760]  и когда вы на них пишете, вы вынуждены фактически делить свои операции там на несколько под
[07:33.760 --> 07:38.320]  операцией. Ну, там простейший пример, там, если выполнять там какое-нибудь умножение на
[07:38.320 --> 07:46.000]  CISC архитектуре, то вы можете написать там одну инструкцию типа там mall, дальше участок памяти
[07:46.000 --> 07:53.440]  и там какая-нибудь константа в качестве двух оперантов. В случае же, там, с RISC архитектурой,
[07:53.440 --> 08:00.040]  то у вас, соответственно, получится, например, там, четыре инструкции. Первые две инструкции будут
[08:00.040 --> 08:08.160]  загружать в ваши регистры, соответственно, там сначала участок памяти, который вы хотите
[08:08.160 --> 08:13.960]  умножить, потом, соответственно, вот эту вот самую константу, после этого будет инструкция номер
[08:13.960 --> 08:21.080]  три, которая выполнит умножение, и еще одна инструкция, чтобы записать результат. Как,
[08:21.080 --> 08:29.760]  в принципе, понятно, что у RISC архитектур достаточно сложный, соответственно, должен быть
[08:29.760 --> 08:37.000]  компилятор, в свою очередь компилятор для CISC архитектур может быть написать проще. То есть,
[08:37.000 --> 08:45.200]  в целом, это было так, там, условно, 50 лет назад, сейчас компиляторы сложные для тех и других,
[08:45.200 --> 08:55.040]  потому что планирование инструкций для CISC архитектур, оно все равно очень сильно непростое. Вот,
[08:55.040 --> 09:06.200]  и разница, там, между RISC и CISC архитектурами, она потихоньку-потихоньку становится все меньше
[09:06.200 --> 09:12.560]  и меньше. Например, вот один из классических подходов, который приводит в пример, как
[09:12.560 --> 09:20.920]  различия между там CISC и RISC, что, соответственно, в CISC существует микрокод. То есть, некоторая
[09:20.920 --> 09:29.120]  программа, которая зашивается в процессор, и, фактически, на одной из стадий конвейера у
[09:29.120 --> 09:38.680]  процессора возникает деление, то есть декодирование, некоторые большой инструкции, деление ее на
[09:38.680 --> 09:47.080]  несколько микроопераций, которые, собственно, этот микрокод и исполняет. Соответственно, в случае
[09:47.080 --> 09:55.080]  с RISC архитектуром никакого микрокода нет, но, там, если посмотреть на ARM, то, хотя у него там нет
[09:55.080 --> 10:03.800]  никакого микрокода, то есть, в ARM, там, постоянно добавляют больше и больше команд, и, в общем-то,
[10:03.800 --> 10:08.040]  это само устройство, то есть, управляющего устройства, устройство-управляющего устройства,
[10:08.040 --> 10:18.000]  я не знаю, афтология, оно постоянно растет по сложности, и, в целом, там, не то чтобы сильно уступает
[10:18.000 --> 10:27.800]  сложности, условно, у некоторых микрокодных операций, там, в том же x86. То есть, мы все знаем,
[10:27.800 --> 10:34.840]  что сейчас нормальным для любого, там, процессора, в том числе мобильного, является, там, содержать
[10:34.840 --> 10:46.640]  инструкции типа, там, векторных операций, всякие, там, AVX в том же Intel или, там, Neon в том же ARM,
[10:46.640 --> 10:54.240]  при этом оно не очень чтобы легко так вот соотносится к классическому пониманию, там, RISC
[10:54.240 --> 11:03.840]  и ЦИСК-архитектур. Соответственно, у RISC-архитектур размер инструкций одинаковый, то есть,
[11:03.840 --> 11:12.240]  практически всегда, там, у вас размер фиксирован, ну, обычно, например, там, 4 байта, хотя есть,
[11:12.240 --> 11:19.480]  опять же, некоторые исключения из этого правила, например, в 32-битном арме у вас есть, там, два
[11:19.480 --> 11:26.800]  режима ARM и FAM. Вот, в режиме FAM у вас, там, были, например, двухбайтовые инструкции. То есть,
[11:26.800 --> 11:34.120]  они были одинаковые, но для, там, какого-то конкретного режима. Вот. Но за счет этого, в принципе,
[11:34.120 --> 11:40.920]  конвейер может быть несколько проще, соответственно, писать, потому что упрощается, там, процесс,
[11:40.920 --> 11:49.040]  собственно, instruction fetch, то есть, упрощается процесс извлечения инструкций. Вот. А в случае
[11:49.040 --> 11:57.480]  с ЦИСК-архитектурами у вас размер инструкций переменный, и за счет этого декодер может быть
[11:57.480 --> 12:03.440]  очень сильно сложным, и в том числе, там, этот декодер может быть реализован, там, во многом,
[12:03.440 --> 12:12.000]  на уровне микрокода. Простейший пример, который разбирали, там, в начале года, как можно, там,
[12:12.000 --> 12:21.440]  обращаться из 16-битного режима, там, Intel к 32-битным регистрам, там, 80, 386. Ну, вот, добавили
[12:21.440 --> 12:25.960]  специальный префикс для инструкций, соответственно, там, более новый процессор видит префикс и
[12:25.960 --> 12:34.560]  начинает обращаться к более, соответственно, там, широким регистрам. Вот. Соответственно,
[12:34.560 --> 12:46.800]  это все так, но, если, например, посмотреть, там, современные x86, то он устроен так, что,
[12:46.800 --> 12:55.200]  грубо говоря, те инструкции, на которых вы пишете, то есть, assembler x86, он быстро перекодируется
[12:55.200 --> 13:02.600]  в некоторый набор микроопераций, в том числе, с использованием микрокода, и конвейер работает
[13:02.600 --> 13:08.160]  уже на уровне этих микроопераций. При этом, эти сами микрооперации, они уже представляют собой
[13:08.160 --> 13:17.080]  некоторый риск архитектуры. Так что, здесь мы видим, что и циск, и риск, они, в общем-то,
[13:17.080 --> 13:23.520]  продолжают двигаться, как бы, навстречу друг к другу, и берут, в общем-то, все то хорошее,
[13:23.520 --> 13:35.200]  что, соответственно, есть у особенности построения этих архитектур. Особняком, то есть, скажем так,
[13:35.200 --> 13:44.160]  отдельно от вот этих вот двух, есть еще несколько направлений. Одно из этих направлений это, там,
[13:44.160 --> 13:52.560]  Very Long Instruction Word. Ну, наверное, про E2K все слышали. Кто слышал про E2K?
[13:52.560 --> 14:02.400]  Ну, кто-то наверняка слышал, я слышал. Ну, соответственно, про тот же самый архитектур
[14:02.400 --> 14:12.320]  про Elbrus 2000 или он же E2K, в общем-то, все плюс-минус слышали. То есть, слышали про Intel
[14:12.320 --> 14:20.800]  Ethereum, который, к сожалению, уже умер. Ну, может, не совсем, к сожалению, но это факт. Но это,
[14:20.800 --> 14:30.600]  в принципе, не единственные примеры архитектур, логика которых построится на том, что есть
[14:30.600 --> 14:37.840]  некоторый явный параллелизм, когда компилятор перекладывает задачу распараллеливания инструкций
[14:37.840 --> 14:44.600]  на себя. Вместо процессора как-то происходит фриск и циск. И, соответственно, явно упаковывает
[14:44.600 --> 14:52.520]  инструкции так, чтобы они исполнялись наиболее быстро. Еще одним примером такой архитектуры,
[14:52.520 --> 15:04.320]  например, является hexagon, ну, квалкомовский. И он прекрасно применяется в всяких обработках
[15:04.320 --> 15:11.680]  сигнала, то есть, некоторых фактически DSP. И у него вот как раз тоже very long
[15:11.680 --> 15:20.960]  instruction work архитектура. Если это, соответственно, процессор общего назначения, то в Ливе вполне
[15:20.960 --> 15:32.720]  может быть конлеер, вполне может быть, в общем-то, даже и микрокод. Но, грубо говоря, так как
[15:32.720 --> 15:39.160]  процессоров на такой архитектуре достаточно немного, сейчас осталось полтора, скажем так,
[15:39.160 --> 15:48.360]  то вводить какие-то общие критерии, кроме именно вот явного параллелизма, достаточно сложно.
[15:48.360 --> 16:02.200]  Соответственно, в процессорах для обработки сигнала, ну, таких
[16:02.200 --> 16:13.440]  как DSP, можно встретить что-то совсем экзотическое. То есть, например, когда у вас команды просто
[16:13.440 --> 16:22.920]  подаются одним, соответственно, блоком на вход процессора и при этом нет классического,
[16:22.920 --> 16:27.360]  например, instruction pointer. То есть, вы просто подаете данные, через какой-то момент на выходе
[16:27.360 --> 16:36.160]  забираете значение. И, собственно, тому подобные вещи, но там в целом это очень специализированные
[16:36.160 --> 16:43.760]  архитектуры и они предназначены в первую очередь для того, чтобы код, который под них, соответственно,
[16:43.760 --> 16:51.200]  пишется, он писался, грубо говоря, там один раз для какой-то специализированной задачи и после
[16:51.200 --> 16:59.040]  этого менялся достаточно нерегулярно. Потому что, ну, написать эффективный кодбюлятор для таких
[16:59.040 --> 17:05.480]  архитектур в наши дни, ну, в целом можно, но это очень недревиальная задача, которая плохо ложится
[17:05.480 --> 17:14.120]  на современные языки программирования, такие как, ну, в общем-то, тот же язык C. Соответственно,
[17:14.120 --> 17:24.120]  даже вот архитектура Very Long Instruction Word, даже ее, в общем-то, очень тяжело адаптировать под
[17:24.120 --> 17:31.280]  современные компиляторы. Например, мы все знаем, что для того же E2K до сих пор там нет открытой
[17:31.280 --> 17:39.320]  реализации в каком-нибудь GCC или в кланге, хотя набор команд он был уже открыт достаточно
[17:39.320 --> 17:48.160]  продолжительный период, просто не работает достаточно эффективно. Соответственно, идя дальше,
[17:48.160 --> 17:59.160]  я все-таки напомню те вещи, которые вы уже знаете, ну, про конвейеры, я думаю, что вам точно должны
[17:59.160 --> 18:06.960]  были рассказывать. Но, на всякий случай, кто не знает, что такое конвейер-процессора? Есть такие,
[18:06.960 --> 18:14.720]  или можно так, кто знает, что такое конвейер-процессора? Ну, в общих чертах, скорее всего, все конкретикам,
[18:14.720 --> 18:21.200]  конкретные процессоры, мало кто. Ну, да, соответственно, в общих чертах, действительно,
[18:21.200 --> 18:26.920]  там, примерно все представляют, что такое конвейер, то есть конвейер — это такой некоторый метод
[18:26.920 --> 18:35.480]  обеспечения, там, ускорения вычислений, построенный на том, что инструкции, в общем-то,
[18:35.480 --> 18:44.160]  можно выполнять параллельно, если достаточно грамотно спроектировать архитектуру процессора.
[18:44.160 --> 18:53.680]  Но вот конвейер обычно характеризуется двумя чиселками, и обычно это в смысле в литературе,
[18:53.680 --> 19:01.000]  в реальности все гораздо сложнее, но, тем не менее, первая чиселка — это, соответственно,
[19:01.000 --> 19:08.520]  глубина или количество стадий. Соответственно, грубо говоря, у нас есть некоторая инструкция,
[19:08.520 --> 19:14.960]  мы ее можем поделить на несколько под инструкцией. Вот на экране, соответственно,
[19:14.960 --> 19:20.960]  каждая инструкция поделена на пять стадий. То есть instruction fetch, то есть, соответственно,
[19:20.960 --> 19:27.600]  извлечь инструкцию из оперативной памяти или, там, из кэша, неважно, откуда. Потом instruction
[19:27.600 --> 19:34.560]  decode, то есть декодировать инструкцию и понять, что это за инструкция. После этого execute,
[19:34.560 --> 19:42.520]  выполнить эту инструкцию. Memory access, то есть обеспечить доступ к памяти, в риск, соответственно,
[19:42.520 --> 19:47.560]  обеспечить доступ к памяти можно либо на ввод, либо на вывод. Соответственно, у вас на четвертом
[19:47.560 --> 19:52.760]  шаге, если у вас инструкция load, то, соответственно, происходит извлечение данных с памяти. Если,
[19:52.760 --> 20:00.920]  соответственно, store, то, соответственно, запись в них. И writeback, соответственно, запись обновления
[20:00.920 --> 20:06.640]  содержимого регистров по результатам выполнения этой инструкции, флагов или выходных регистров
[20:06.640 --> 20:14.720]  и так далее. Считалось, что для риска, по крайней мере, классических архитектур, количество стадий
[20:14.720 --> 20:22.680]  должно быть константным, то есть это некоторое число. В современных процессорах это не так,
[20:22.680 --> 20:27.480]  то есть у вас для разных инструкций вполне нормально, что существует разное количество стадий
[20:27.480 --> 20:36.040]  конвейера, но в любом случае вот понятие глубины, оно сохраняется. Соответственно, вторая чиселка
[20:36.040 --> 20:49.960]  это ширина. Соответственно, ширина это то, фактически, сколько параллельно задач вы можете
[20:49.960 --> 20:58.360]  выполнять на стадии. Вот на, соответственно, экране, то есть на слайде, как раз пять стадий,
[20:58.360 --> 21:06.640]  то есть глубина и, собственно, одна, то есть ширина равна единице. Понятно, как изменится
[21:06.640 --> 21:15.640]  эта картинка, чтобы ширина, собственно, равнялась двум. Или не очень понятно?
[21:15.640 --> 21:27.600]  Ну, смотрите, сдвиньте вот строчку, которая два, на шаг влево, после этого сдвиньте строчку
[21:27.600 --> 21:36.280]  три на шаг влево, сдвиньте строчку четыре на два шага влево. У вас, соответственно, на первом такте
[21:36.280 --> 21:41.560]  будут выполняться, соответственно, инструкцион фетчи первой и второй инструкции, соответственно,
[21:41.560 --> 21:48.000]  на втором такте у вас будет выполняться инструкцион декод первой и второй инструкции и
[21:48.000 --> 22:01.800]  инструкцион фетч третьей и четвертой инструкции, ну и так далее. Так, понятно? Ну, соответственно,
[22:01.800 --> 22:11.240]  идея в том, что конвейер, в общем-то, тоже можно параллелить и при достаточно, собственно,
[22:11.240 --> 22:18.240]  грамотном построении архитектуры можно не просто увеличить количество стадий конвейера,
[22:18.240 --> 22:24.080]  как раньше, например, тот же какой-нибудь пентиум, у него был очень глубокий конвейер,
[22:24.080 --> 22:30.040]  например, в свое время, то есть старались идти в глубину, то сейчас там современные
[22:30.040 --> 22:36.080]  конвейеры, они, в общем-то, очень даже неплохо идут в ширь и, например, когда у вас говорят,
[22:36.080 --> 22:43.320]  что у того же нового Macbook на M1 у него очень такой широкий конвейер или там широкий
[22:43.320 --> 22:49.640]  pipeline, вот, собственно, подразумевает, что он может обрабатывать несколько инструкций в,
[22:49.640 --> 23:02.760]  собственно, несколько юнитов на одной стадии, достаточно параллельно. Понятно, что устройство
[23:02.760 --> 23:12.480]  процессора таким образом, то есть его конвейеризация, она дается некоторой ценой,
[23:12.480 --> 23:22.080]  соответственно, возникают вещи, которые называются hazard или конфликты, и, в общем-то,
[23:22.080 --> 23:30.240]  конфликты, они бывают разного рода, то есть классический там пример конфликтов, их еще также
[23:30.240 --> 23:37.560]  называют зависимости по данным, это, собственно, несколько операций, следующих друг за другом,
[23:37.560 --> 23:43.880]  ну, там, read-after-read, read-after-write, write-after-read и, соответственно, write-after-write.
[23:43.880 --> 23:53.880]  Каждый конфликт имеет, скажем так, свою степень влияния на архитектуру процессора,
[23:53.880 --> 24:02.280]  ну, можете привести там пример конфликта, например, read-after-read.
[24:08.560 --> 24:14.480]  Ну, простое же. Может, мы пытаемся два раза из порта что-нибудь почитать?
[24:14.480 --> 24:25.600]  Да, вот последнее, это на самом деле ближе, то есть, смотрите, вот вы читаете, соответственно,
[24:25.600 --> 24:32.000]  из памяти, соответственно, потом еще раз читаете из памяти, при этом совершенно не значит,
[24:32.000 --> 24:36.760]  что память между этими операциями чтения не изменилась, то есть, возможно, она с точки
[24:36.920 --> 24:41.920]  зрения вас, как, ну, грубо говоря, процессорного ядра не изменилась, то есть, у вас шел пайплайн,
[24:41.920 --> 24:47.240]  у вас все как бы хорошо, все нормально, но при этом у вас, например, есть другое ядро,
[24:47.240 --> 24:53.080]  соответственно, в рамках другого ядра произошло изменение там в этом участке памяти,
[24:53.080 --> 24:58.240]  вам нужно поддерживать конкретность кэшей с этим ядром, соответственно, у вас, соответственно,
[24:58.240 --> 25:05.560]  есть там какое-нибудь MMIO, соответственно, вы прочитали память, вы снова хотите там, грубо
[25:05.560 --> 25:09.880]  говоря, прочитать память, но при этом это не означает, что какое-нибудь периферийное устройство
[25:09.880 --> 25:14.280]  в этот момент эту память не обновило, или у вас, например, произошла какая-нибудь DMA запись
[25:14.280 --> 25:25.160]  с устройства в оперативной памяти. Ну, это классический пример read-after-read. Он несколько
[25:25.160 --> 25:31.920]  отличается от других, соответственно, видов конфликтов, потому что, скажем так, рассматривает не
[25:31.920 --> 25:37.880]  только там конвейер в рамках вот одного ядра процессора, но, соответственно, заставляет думать
[25:37.880 --> 25:47.640]  о том, что вокруг процессора одного конкретного ядра еще что-то есть. Самый, соответственно,
[25:47.640 --> 25:55.480]  наверное, болезненный для разработчиков процессора это, соответственно, read-after-write,
[25:55.480 --> 26:01.920]  то есть тогда, когда у вас происходит некоторая операция записи, и после этого нужно произвести
[26:01.920 --> 26:06.640]  чтение. Соответственно, пока эта операция записи не завершится, вы, соответственно, прочитать
[26:06.640 --> 26:17.120]  данные не сможете. Соответственно, у вас возникают так называемые pipeline stalling, то есть конвейер
[26:17.120 --> 26:25.160]  ждет, фактически и простаивает, пока, собственно, у вас эти данные не появятся, и их нельзя будет
[26:25.160 --> 26:33.760]  прочитать. Соответственно, в некоторых процессорах pipeline stalling либо не знают,
[26:33.760 --> 26:39.440]  либо предпочитают игнорировать по причине усложнения устройства конвейера, и тогда возникают
[26:39.440 --> 26:48.480]  неприятные ситуации, когда, собственно, в ваших процессорах считываются совершенно неправильные
[26:48.480 --> 26:56.480]  данные. Если вы там напишете сначала команду записи, а потом чтение, и потом внезапно в
[26:56.480 --> 27:04.720]  компиляторе появляются всякие команды типа mfix, и дальше какая-нибудь чиселка, которая говорит,
[27:04.720 --> 27:12.720]  что данная команда чинит, соответственно, генерацию команд под конкретный процессор вот такой-то-такой-то,
[27:12.720 --> 27:19.200]  потому что этот процессор не может pipeline stalling. Вот если почитаете там документацию на GCC,
[27:19.200 --> 27:32.880]  то увидите много похожего. Точно также существует write after read, только в данном случае, собственно,
[27:32.880 --> 27:39.160]  ситуация обратная, то есть если вы будете, соответственно, записывать память, и у вас
[27:39.160 --> 27:44.560]  конвейер достаточно глубокий, то может возникнуть ситуация, что вы перезапишете память, при этом
[27:44.560 --> 27:54.760]  read ее еще не успеет прочитать. И write after write, который также еще называется проблемой
[27:54.760 --> 28:00.760]  переименования или, соответственно, register name conflict, то есть конфликтом имен регистров, то есть
[28:00.760 --> 28:07.840]  когда, собственно, вы записываете какое-то значение, но при этом вы его записываете в один и тот же
[28:07.840 --> 28:15.840]  регистр, но в разное время, а между этими операциями есть какие-то еще операции. И вот эти промежуточные
[28:15.840 --> 28:23.680]  операции должны видеть именно тот регистр или тот участок памяти, который был после предыдущей
[28:23.680 --> 28:32.320]  операции, но до следующей. Классический пример решения данной проблемы — это использовать
[28:32.320 --> 28:40.400]  переименование регистров, то есть когда у вас конфликтующие, собственно, регистры имеют какие-то
[28:40.400 --> 28:48.880]  на самом деле другие имена, то есть внутренние, и тем самым вы избегаете вот обращения к не тем
[28:48.880 --> 28:57.800]  регистрам или не тем участкам памяти. С конфликтами по данным, я думаю, все понятно. Кроме конфликтов
[28:57.800 --> 29:07.400]  по данным есть еще структурные конфликты, то есть это вот как раз про то, что мы ломимся в один и тот же
[29:07.400 --> 29:15.280]  порт, но ломиться, соответственно, можно только в тот порт, который свободен, соответственно. Один
[29:15.280 --> 29:23.240]  порт вам позволяет обрабатывать группу 2.1 до какой-то там операции, а не несколько сразу. Порт и
[29:23.240 --> 29:30.000]  unit — это синонимы, просто порт это используется в терминологии x86 для тех, кто немножко
[29:30.000 --> 29:36.280]  запутался. И, соответственно, pipeline и conveyor — это тоже самое, это тоже синонимы, просто русский,
[29:36.280 --> 29:44.360]  соответственно, английский перевод. Классический пример свободного винта — вот у вас есть умножитель,
[29:44.360 --> 29:50.320]  например, аэфематически-логически скалярный умножитель, то есть недавно находящийся в валу,
[29:50.320 --> 29:59.440]  или умножитель floating-point-units, находящийся в GPU. У вас, соответственно, может быть достаточно
[29:59.440 --> 30:05.120]  широкий conveyor, но при этом в рамках этого conveyorа, например, умножитель всего один.
[30:05.120 --> 30:13.200]  Если у вас там одна операция — это, допустим, чтение, а вторая операция — это, соответственно,
[30:13.200 --> 30:18.320]  умножение, то у вас не происходит структурного конфликта. А если у вас подряд оказываются две
[30:18.320 --> 30:22.360]  операции умножения, то, соответственно, у вас возникает структурный конфликт,
[30:22.360 --> 30:28.960]  потому что вы не можете параллельно умножать, у вас всего один умножитель. Ну вот, соответственно,
[30:28.960 --> 30:37.840]  этот пример структурного конфликта. Кроме этого, есть еще конфликты управления. Соответственно,
[30:37.840 --> 30:47.640]  если у вас нет информации о том, какую следующую инструкцию выполнять, то чаще всего вы будете,
[30:47.640 --> 30:54.240]  точнее не вы, а ваш процессор будет заниматься в угадайку. То есть он будет спекулятивно пытаться
[30:54.240 --> 31:00.960]  выполнить ту или иную вещь. И если он, соответственно, не угадает, такое не часто,
[31:00.960 --> 31:07.160]  но в целом происходит, то возникнет ситуация, когда процессор выполнил достаточно большое
[31:07.160 --> 31:12.120]  количество инструкций вперед, но он их выполнил совершенно не из того места, ему, соответственно,
[31:12.120 --> 31:20.680]  нужно откатываться назад и выполнять уже другие инструкции, про которые он не угадал. Это,
[31:20.680 --> 31:30.920]  соответственно, конфликт управления. Здесь стоит сказать, что вам, как разработчиком операционных
[31:30.920 --> 31:40.280]  систем, про это нужно знать, в первую очередь, как то, что эти вещи существуют. В 99 случаях вам
[31:40.280 --> 31:47.560]  не придется писать код так, чтобы он избегал максимального количества конфликтов,
[31:47.560 --> 31:54.360]  программировать наиболее эффективное использование пайплайна и так далее. Не придется, в первую очередь,
[31:54.360 --> 32:01.680]  потому что, собственно, компиляторы это делают сейчас в достаточной мере эффективности. И в
[32:01.680 --> 32:08.440]  ситуации, где вы даже можете выиграть несколько тактов, переупорядочек, например, инструкций,
[32:08.440 --> 32:17.360]  у вас, скорее всего, не возникнут. Они возникают в основном при каких-то арифметических вычислениях,
[32:17.360 --> 32:25.240]  и не нужно заниматься, скажем так, преждевременной оптимизацией до того, как вы все запрофилируете и
[32:25.240 --> 32:37.480]  действительно не найдете, что нужно оптимизировать там. При этом это не означает, что особенностью
[32:37.480 --> 32:44.720]  устройства конвейера они на вас никак не влияют. Вот, когда мы, соответственно, доберемся сегодня
[32:44.720 --> 32:55.080]  до спекулятивных атак, там как раз конвейер может играть достаточно значимую роль, и за счет,
[32:55.080 --> 33:00.520]  собственно, обеспечения его сброса вы можете, скажем так, починить, например, безопасность
[33:00.520 --> 33:07.840]  операционной системы при условии, что в процессоре где-то не доглядели ту или
[33:07.840 --> 33:14.400]  иную особенность. Но об этом буквально на следующих слайдах. Соответственно,
[33:14.400 --> 33:27.960]  что вообще означает для вас наличие конвейера? Наличие конвейера, оно, как и другие инструменты,
[33:27.960 --> 33:37.240]  предназначено для оптимизации, соответственно, производительности вычислений, и необходимость
[33:37.240 --> 33:45.720]  она, в общем-то, есть. То есть, даже когда вы обращаетесь к просто оперативной памяти,
[33:45.720 --> 33:52.560]  мы помним, что, например, риск процессора, они постоянно обращаются к оперативной памяти,
[33:52.560 --> 34:03.560]  потому что у них много load, store команд за счет их простоты, а циск же, при этом,
[34:03.560 --> 34:10.080]  могут делать меньше обращений к оперативной памяти просто за счет более сложных команд
[34:10.080 --> 34:18.400]  у себя внутри. Соответственно, каждое вот такое обращение, оно у вас займет несколько
[34:18.400 --> 34:26.280]  наносекунд. Ну вот, примерные значения, соответственно, для разных уровней кэша на x86,
[34:26.280 --> 34:33.640]  они приведены на слайде, то есть, ну, например, там, где-то меньше полутора наносекунд это l1,
[34:33.640 --> 34:40.880]  там, менее там 5 это l2, соответственно, менее там 20 это l3. Здесь приведены значения для
[34:40.880 --> 34:49.920]  comet lake, для rocket lake значения чуть хуже, соответственно, текущее поколение, а для
[34:49.920 --> 34:56.280]  alder lake еще пока нет хороших результатов, потому что память новая, соответственно,
[34:56.280 --> 35:04.960]  новой памяти ни у кого нет и, соответственно, кэши, собственно, процессоры тоже еще не вышли,
[35:04.960 --> 35:12.640]  соответственно, нет данных про кэши тоже. Соответственно, оперативная память, но это самое,
[35:12.640 --> 35:25.000]  но это где-то 30-100 наносекунд, причем все помнят про вещи типа CL, тайминги и вот это все. То есть,
[35:25.000 --> 35:32.080]  в целом, от роста объемов оперативной памяти у вас будут расти тайминги, потому что их нужно
[35:33.000 --> 35:38.480]  синхронизировать, соответственно, ту оперативную память, которая у вас есть, поэтому рассчитывайте,
[35:38.480 --> 35:46.840]  что там, ну, условно, там для набора 16 гигабайт у вас будет там 40 наносекунд скорее, а там 64
[35:46.840 --> 35:54.240]  гигабайта, ну, скорее, ближе к 80. И это так хорошая оперативная память, на медленной,
[35:54.240 --> 36:02.800]  то есть на мейнстримской оперативной памяти у вас будут гораздо худшие результаты. Если ни кэшей,
[36:02.800 --> 36:08.880]  ни памяти вам не хватает, то вам светит своп или вы, соответственно, загружаете какие-то кэшированные
[36:08.880 --> 36:19.480]  данные с носителей или загружаете программу. Это счет уже на микросекунды и какой-нибудь там
[36:19.480 --> 36:29.640]  NVMe SSD подключенной к CIE 4.0 шине, вам даст, соответственно, десятки микросекунд в задержках.
[36:29.640 --> 36:38.600]  В свою очередь там жесткий диск, это уже миллисекунды и здесь можно рассчитывать на
[36:38.600 --> 36:45.880]  десятки, соответственно, миллисекунд. Ну, 10, там, 12 это очень хороший HDD и вам, скажем так,
[36:45.880 --> 36:56.120]  сильно повезло. Вот. В свою очередь никто не отменяет задержки к обращения к RAM еще
[36:56.120 --> 37:03.960]  из-за использования виртуальных адресов, но в целом там это компенсируется отдельным кэшем,
[37:03.960 --> 37:11.520]  под названием TLB, про который мы в прошлый раз достаточно много говорили. В случае там с
[37:11.520 --> 37:18.760]  отдельными архитектурами можно даже узнать, как именно там этот TLB устроен. В случае с Intel
[37:18.760 --> 37:26.640]  придется вполне возможно, что просто профайлить различными способами, пытаясь, соответственно,
[37:26.640 --> 37:38.880]  вычислить это алгоритмически. Говоря об Intel и вообще о современных конвейерах, то нужно сказать,
[37:38.880 --> 37:48.720]  что устройство процессоров достаточно сложное и кроме конвейеров у вас будет вообще множество
[37:48.720 --> 37:58.480]  юнитов в рамках микроархитектуры, которые выполняют свои операции. Можно на это смотреть,
[37:58.480 --> 38:05.360]  как теоретически, что это все какая-то часть конвейера, но, например, тоже переименовывание
[38:05.360 --> 38:14.320]  регистров, но это отдельный юнит, соответственно, Out of Order исполнение тоже отдельный юнит. И вот это
[38:14.320 --> 38:23.400]  все, в принципе, вы легко встретите при разработке операционных систем и вам придется
[38:23.400 --> 38:32.680]  считать на них документацию, просто хотя бы из-за того, что, например, вы записали какие-то
[38:32.680 --> 38:38.520]  данные в оперативную память. Например, вы записали программу, то есть новый процесс,
[38:38.520 --> 38:47.560]  вы его создаете, размещаете его в оперативной памяти. Если у вас там Nix86, то вам придется сбросить
[38:47.560 --> 38:57.680]  кэши процессора в области этого участка памяти. Вам там придется сбросить, соответственно,
[38:57.680 --> 39:07.960]  branch prediction, то есть спекулятивное выполнение инструкций перед переходом на этот участок
[39:07.960 --> 39:15.200]  памяти, потому что иначе процессор может думать, что там еще находятся какие-то старые
[39:15.200 --> 39:24.680]  данные или старая программа, она у вас уже изменилась. И вот все вот это вот у вас очень сильно
[39:24.680 --> 39:33.160]  вылезает при программировании на реальном железе в сравнении с эмуляторами, где такие вещи как кэши
[39:33.160 --> 39:43.080]  или спекулятивное выполнение и так далее. Их достаточно сложно реализовать эффективно,
[39:43.080 --> 39:51.480]  и в 99 эмуляторах их просто нет. То есть эмуляторы бывают либо на уровне ISA, то есть то, что у нас
[39:51.480 --> 40:00.040]  есть QEMO, либо на уровне микроархитектуры. Микроархитектурные эмуляторы медленнее на
[40:00.040 --> 40:06.960]  несколько порядков и, соответственно, использовать их там для запуска полноценных операционных
[40:06.960 --> 40:17.880]  систем для отладки не всегда рационально. Так, соответственно, говоря о интеле, то есть как
[40:17.880 --> 40:26.560]  вообще выглядит конвейер в достаточно современном процессоре. То есть мы видели на начальных слайдах
[40:27.400 --> 40:36.480]  пример конвейера, который вы видите в литературе. В свою очередь там в современном процессоре
[40:36.480 --> 40:44.720]  сверху это не Halium, а соответственно там внизу это Silvermont. Silvermont это атомы,
[40:44.720 --> 40:54.080]  Nehalium это, по-моему, первое поколение Core. Нет, по-моему, даже до Core это было.
[40:54.080 --> 41:01.680]  Второе поколение Core это Sandy Bridge. Наверное, все-таки Nehalium это первое поколение Core.
[41:01.680 --> 41:15.320]  Вы здесь видите, что, например, Instruction Fetch в интеле имеет, например, там три порта.
[41:15.320 --> 41:22.680]  Соответственно, там два порта могут использоваться для произвольных инструкций. Соответственно,
[41:22.680 --> 41:29.680]  там третий порт, например, для специализированных инструкций, таких как SSE, AVX и подобные вещи.
[41:29.680 --> 41:41.760]  Точно так же там три параллельных декодера. То есть есть операции расположения инструкций
[41:41.760 --> 41:54.680]  на дальнейших вычислительных юнитах. Есть работа с кэшами, обработка исключений.
[41:54.680 --> 42:04.840]  Появляется понимание Retire и Commit. Retire это завершить выполнение всех инструкций.
[42:04.840 --> 42:12.600]  Завершить выполнение конкретной инструкции на конвейере. В этот момент процессор перестает
[42:12.600 --> 42:23.920]  ее в конвейере держать, он ее может выкинуть. При этом до Commit эта инструкция все равно не
[42:23.920 --> 42:29.800]  считается выполненной, потому что кроме соответственно отработки самого конвейера еще должны произойти
[42:29.800 --> 42:37.720]  какие-нибудь внешние устройства. Например, если в инструкции явно сказано, что она должна записать
[42:37.720 --> 42:45.600]  в оперативную память, то есть синхронизировать не только кэши, но и добраться до оперативной
[42:45.600 --> 42:51.520]  памяти, то произойдет какая-то дополнительная задержка на обращение к каким-то сторонним
[42:51.520 --> 43:02.920]  устройствам. Кому хочется узнать побольше о современных конвейерах, процессорах,
[43:02.920 --> 43:10.560]  ну вот можно сходить по ссылке, почитать. Там достаточно наглядно расписано, как с этим
[43:10.560 --> 43:16.720]  работать. Если вы хотите программировать какие-то математические алгоритмы,
[43:16.720 --> 43:26.400]  то вполне возможно, что вы к этому придете. Нас же в свою очередь интересует немножко другой аспект.
[43:26.400 --> 43:36.720]  Соответственно, аспект того, как все вот эти вот особенности могут привести к неприятным
[43:36.720 --> 43:44.800]  последствиям, ну скорее к последствиям, когда вполне себе корректно работающая система, то есть
[43:44.800 --> 43:53.560]  без каких-то явных уязвимостей в алгоритме, то есть никаких переполнений буфера там нет,
[43:53.560 --> 44:00.360]  никаких ошибок в POA нет. Соответственно, алгоритм работает правильно, реализован,
[44:00.560 --> 44:08.600]  дедуктивно его верифицировали и доказали математически, что он корректен,
[44:08.600 --> 44:21.600]  что он завершается и так далее. Но при этом из особенностей работы вашего процессора,
[44:21.600 --> 44:34.800]  например, возникают какие-то внутренние свойства системы, которые могут быть извлечены и в
[44:34.800 --> 44:42.000]  дальнейшем, соответственно, использованы для атакующего, то есть для извлечения какой-то
[44:42.000 --> 44:47.760]  информации или, например, для внесения какой-то новой информации, соответственно, с целью
[44:47.760 --> 44:58.480]  компрометации работы вашей целевой системы. Кто-нибудь может привести какой-нибудь пример
[44:58.480 --> 45:05.480]  атаки по сторонним каналам из реальной жизни? Есть идеи, что это может быть?
[45:05.480 --> 45:15.960]  Из реальной не очень, но я помню про ISLR, там же тоже была какая-то штука, что измеряли
[45:15.960 --> 45:25.880]  задержки конвейера и через это как раз искались адреса. Да, это, собственно, было. Я сейчас не
[45:25.880 --> 45:36.320]  воспроизведу, какая конкретная там атака была, но, в принципе, с ISLR-ом, да, там были особенности.
[45:36.320 --> 45:49.640]  Нет, РОП это вполне прямая атака. Давайте лучше говорить. Я сталкивался с тем, что криптографию
[45:49.640 --> 45:56.760]  на этих embedded устройствах расковыривались за счет энергопотребления, анализа энергопотребления.
[45:56.760 --> 46:03.600]  Да, вот это уже ближе, соответственно, когда там, грубо говоря, процессор выполняет какую-то,
[46:03.600 --> 46:10.040]  соответственно, ресурсноемку и операцию, то он, соответственно, потребляет больше энергии,
[46:10.040 --> 46:19.240]  потому что, как и вам, собственно, людям, чтобы посчитать какую-нибудь одну чиселку, умножить
[46:19.240 --> 46:24.720]  другую, вам нужно головой подумать. Точно так же, соответственно, процессор должен думать,
[46:24.720 --> 46:31.000]  соответственно, когда он думает, он кушает больше электричества. И вот от того, что, соответственно,
[46:31.120 --> 46:35.840]  процессор кушает больше электричества, можно, соответственно, сделать некоторые косвенные выводы,
[46:35.840 --> 46:44.040]  что, например, банально на процессоре происходит какое-то вычисление. В некоторых случаях эти вещи
[46:44.040 --> 46:55.080]  можно сделать более подробно. Но тем не менее, то есть в реальной жизни все гораздо проще,
[46:55.080 --> 47:05.480]  но, соответственно, на слайде есть три фотографии. Первая фотография, она, возможно, не столь
[47:05.480 --> 47:11.760]  удачная, потому что не совсем отражает суть того, что здесь происходит. Но когда, например, медвежатник
[47:11.760 --> 47:20.880]  профессиональный ломает замок, например, слушая, соответственно, то, как кликает механизм вот этого
[47:20.880 --> 47:26.240]  самого замка в процессе, собственно, работы его там отмычкой или, например, он просто крутит,
[47:26.240 --> 47:34.840]  если это какой-нибудь сейф с крутящимся замком, он просто крутит эту ручку и слушает, соответственно,
[47:34.840 --> 47:42.640]  звуки замка, находящегося в этом сейфе. Он фактически выявляет некоторые промежуточные
[47:42.640 --> 47:50.920]  состояния, то есть между известными нам основными, то есть прямым каналом открыт сейф или закрыт сейф.
[47:50.920 --> 47:56.920]  Появляется некоторый промежуточный канал связи, то есть вот эти вот самые клики,
[47:56.920 --> 48:07.080]  соответственно, которые нам позволяют узнать, собственно, насколько сейчас этот замок открыт.
[48:07.080 --> 48:12.360]  То есть вы там слышите, о, соответственно, там клик есть, соответственно, на первый,
[48:12.360 --> 48:16.680]  клик есть на второй, клик есть на третий, о, клик на четвертый, все, ну замок открыт.
[48:16.680 --> 48:28.480]  Например. На второй картинке, соответственно, это нашумевший, там, отличный подарок, соответственно,
[48:28.480 --> 48:39.720]  наших доблестных спецслужб в посольство США, то есть когда красивый вот такой вот деревянный герб
[48:39.720 --> 48:49.520]  был подарен послу и, соответственно, поставлен прямо в их комнате, соответственно, внутри герба
[48:49.520 --> 48:58.200]  находился пассивный резонатор, на который, соответственно, подавали там мощный высокочастотный импульс,
[48:58.200 --> 49:02.800]  но физики у нас здесь есть, они лучше меня объяснят, как это работает, но, по существу,
[49:02.800 --> 49:10.360]  оно работало как такой хороший микрофон, позволявший, соответственно, нам прослушивать там
[49:10.360 --> 49:18.880]  в 50-е года вот ровно все, что произносилось в комнате с этой красивой деревянной дощечкой.
[49:18.880 --> 49:29.920]  Вот. На третьей картинке нарисован полиграф, соответственно, наше тело это, в общем-то,
[49:29.920 --> 49:40.600]  такой хороший, прекрасный, соответственно, источник некоторых побочных, соответственно,
[49:40.600 --> 49:49.960]  изменений, то есть когда мы о чем-то говорим, то есть наши там мимика, жесты, там температура,
[49:49.960 --> 50:02.320]  не знаю, дыхание, наш взгляд, все вот это вот оно каким-то образом реагирует на наше, собственно,
[50:02.320 --> 50:09.720]  физиологическое там состояние, и ну вот полиграф это один из таких инструментов, который позволяет
[50:09.720 --> 50:16.800]  в общем-то фиксировать это изменение в физиологическом состоянии человека, когда мы там с ним
[50:16.800 --> 50:23.400]  разговариваем. На самом деле, больше он ничего не делает, и все вот эти вот там попытки сказать,
[50:23.400 --> 50:29.720]  что вот там можно, наблюдая за человеком, найти какие-то закономерности. Ну да, с одной стороны,
[50:29.720 --> 50:36.720]  это правда, с другой стороны, там во многих случаях вероятность такова, что как монетку бросить,
[50:36.720 --> 50:44.720]  примерно с такой же вероятности. Но тем не менее, там какие-то, собственно, вот такие, можно сказать,
[50:44.720 --> 50:54.520]  атаки по сторонним каналам в жизни, они имеют уже довольно такую многовековую историю, эффективно
[50:54.520 --> 51:00.840]  применяются, и вот в общем-то как вот в быту, ну не знаю, там ключи забыли от дома вам, медвежатник
[51:00.840 --> 51:06.080]  помог. Так и в какой-то там профессиональной деятельности, когда вы там взяли соседу дощечку,
[51:06.080 --> 51:19.960]  подарили, она его слушать будет. Тем не менее, кроме реальной жизни, эти же техники нашли свой,
[51:19.960 --> 51:28.720]  собственно, путь и там в программно-аппаратных комплексах, ну вот в случае с, там скажем,
[51:28.720 --> 51:37.240]  программным обеспечением, там начало формально, то есть по факту существовало и раньше, но формально,
[51:37.240 --> 51:44.240]  официально, так и по сторонним каналам на программное обеспечение существует там с 96-го года.
[51:44.240 --> 51:54.840]  Был такой гражданин Пол Кочер, который, собственно, использовал время, там, шифровать
[51:54.840 --> 52:02.640]  некоторого сообщения для того, чтобы раскрыть информацию, вот насколько длинный ключ,
[52:02.640 --> 52:09.640]  допустим, RSA, он там несколько шифров использовал, использовался вот для шифрования этого письма.
[52:09.640 --> 52:15.720]  Ну понятно, что чем больше, соответственно, ключ, тем дольше происходило шифрование, потому что
[52:15.720 --> 52:24.040]  реализация была в тот момент наивная, и она не ждала там какое-то время для того, чтобы снизить
[52:24.040 --> 52:30.480]  вот эту вот возможность раскрыть информацию. Вот, соответственно, с этой даты и началась,
[52:30.480 --> 52:40.240]  соответственно, скажем так, охота на различные свободные каналы в программном обеспечении,
[52:40.240 --> 52:47.520]  и если там вот в том же Нистовском документе вы увидите две картинки, вот одна из которых есть
[52:47.520 --> 52:55.200]  сейчас, это традиционная там модель криптосистемы, то есть есть некоторое там сообщение, которое Алиса
[52:55.200 --> 53:01.680]  хочет передать Бобу, соответственно, там Алиса, соответственно, его там каким-то образом шифрует,
[53:01.680 --> 53:07.440]  допустим, у нее есть ключ свой, соответственно, там M это сообщение, E это, соответственно,
[53:07.440 --> 53:14.960]  encrypt, D это decrypt, соответственно, Алиса и Боб это отправитель и получатель, Evo, соответственно,
[53:14.960 --> 53:20.040]  это некоторый там eavesdropper, то есть некоторая подслушивающая сторона, которая пытается
[53:20.040 --> 53:26.240]  это сообщение перехватить. Все замечательно, в традиционной модели криптосистемы, если у нас
[53:26.240 --> 53:35.000]  стойкий алгоритм шифрования, если у нас там неизвестны ключи, то мы можем спокойно передать
[53:35.000 --> 53:44.240]  там сообщение, там и Evo ничего не сможет узнать из этого сообщения, но просто даже если мы
[53:44.240 --> 53:53.600]  посмотрим на эту схему, то мы сразу видим, что в этой схеме, например, там уже не скрывается сам
[53:53.600 --> 54:01.520]  факт ведения переписки, то есть то, что мы передали, соответственно, Evo какое-то сообщение означает
[54:01.520 --> 54:09.520]  в том, что у нас это сообщение было, там будем мы там достаточно регулярно передавать, соответственно,
[54:09.520 --> 54:17.880]  там не Evo, прошу прощения, Бобу, будем достаточно регулярно передавать сообщение там между Алисой
[54:17.880 --> 54:24.160]  и Бобой, выяснится, что мы о чем-то замышляем, то есть мы замышляем что-то нехорошее, значит,
[54:24.160 --> 54:32.320]  соответственно, вызываем больше подозрений, поэтому классическая схема там, которая сейчас там,
[54:32.320 --> 54:40.360]  грубо говоря, рассматривается, она выглядит похожим вот примерно на эту, то есть нужно
[54:40.360 --> 54:50.200]  смотреть, а какой, собственно, там такие вещи, как там температура, свет, электромагнитное излучение,
[54:50.200 --> 55:01.640]  звук, у вас со связью очень плохо, я вас практически не слышу, я не знаю,
[55:01.640 --> 55:27.440]  я, к сожалению, не слышу, там был какой-то вопрос, если, а, понял, окей, ну, на самом деле,
[55:27.440 --> 55:32.720]  если там какие-то сложности микрофона вообще бывают, то можно, в принципе, и в чате тоже
[55:32.720 --> 55:41.360]  писать вопросы, то есть можно произносить так и, собственно, писать в чате, то есть у нас ничего в этом
[55:41.360 --> 55:46.480]  плане не изменилось, единственно, появился новый канал, и он даже не побочный, а вполне себе прямой,
[55:46.480 --> 55:52.240]  вот, соответственно, современные модели криптосистемы, вот у вас появляются такие дополнительные
[55:52.240 --> 55:58.520]  факторы, дополнительные каналы, как, соответственно, звук, свет, радиация, потребление
[55:58.520 --> 56:04.480]  электричества, время выполнения, основные, соответственно, выводы, дополнительные выводы,
[56:04.480 --> 56:10.800]  в конце концов сообщение об ошибке, то есть то, что мы там неправильно расшифровали, какое там
[56:10.800 --> 56:17.320]  сообщение об ошибке будет, будет у вас, например, неправильная длина ключа, вот мы, соответственно,
[56:17.320 --> 56:25.160]  раскрыли информацию о том, что ключ должен быть другого размера и так далее, ну, то есть,
[56:25.160 --> 56:35.640]  как классический пример, то есть, когда раньше, там, в время Второй мировой войны еще, там, я уже не
[56:35.640 --> 56:47.640]  помню, по-моему, в Германии, что ли, да, использовалась вот эта несчастная инигма, там, немцы очень радостно
[56:47.640 --> 56:54.400]  начинали свой канал связи с того, что передавали погоду, и в свое время, там, Алан Тьюринг,
[56:54.400 --> 57:00.640]  который занимался криптоанализом этой инигмы, вот как раз увидел некоторую закономерность в том,
[57:00.640 --> 57:10.800]  что, соответственно, каждый, там, регулярный, там, канал связи, он начинается, там, с схожих,
[57:10.800 --> 57:20.600]  скажем так, сообщений, и вот это знание позволило произвести, собственно, частотный анализ криптоалгорифма,
[57:20.600 --> 57:30.520]  использованного в той же инигме. Другой пример, когда военные, там, делали какой-то аппаратный
[57:30.520 --> 57:41.120]  механизм шифрования и выяснили, что, ну, там, при шифровании, там, этого самого сообщения происходит
[57:41.120 --> 57:48.720]  достаточно характерный шум, вот как раз то, что говорилось в одном из ответов на вопрос, и этот
[57:48.720 --> 57:56.320]  характерный шум позволял, собственно, раскрыть и, собственно, сам ключ, и то сообщение, которое, там,
[57:56.320 --> 58:03.920]  происходит. Ну, тут есть, на самом деле, два пути, то есть, там, первый путь — это, там, инженерное
[58:03.920 --> 58:11.680]  решение, то есть, пытаться максимально заизолировать, там, помехи, то есть, увеличить частоты,
[58:11.680 --> 58:19.120]  там, добавить, там, различные способы снижения, вот это вот, подание этой информации, там, в звуковое
[58:19.120 --> 58:25.640]  пространство. Пытались, пытались, пытались, вроде, в принципе, решения нашли, но, там, заменить
[58:25.640 --> 58:33.520]  несколько десятков тысяч машинок по всему миру было, в целом, нереалистично. Кончилось все тем,
[58:33.520 --> 58:42.720]  что пришли к некоторому административному решению, соответственно, там, в радиусе 30 метров не должно
[58:42.720 --> 58:49.360]  быть, там, войск противника в момент использования, соответственно, машинки шифрования. Ну, дошло до
[58:49.360 --> 58:58.920]  смешного. Буквально через несколько лет обнаружили, что кроме, вот, соответственно, звукового профиля
[58:58.920 --> 59:05.960]  точно такие же сообщения, собственно, то есть, точно такие же помехи позволяют раскрыть информацию,
[59:05.960 --> 59:18.200]  соответственно, сообщений в электромагнитном поле. Ну, увеличили с 30 метров до 60 метров. Просто, но
[59:18.200 --> 59:28.640]  работает. Поэтому борьба с атаками такого рода, она происходит не только на уровне, собственно,
[59:28.640 --> 59:37.160]  там, кому-то техническом, но вполне может происходить и на других уровнях, потому что сами атаки достаточно
[59:37.160 --> 59:47.240]  разнообразны, и, там, подходы к митигации, собственно, этих атак, они не всегда тревожны. Подробнее, как раз,
[59:47.240 --> 59:54.960]  написано, вот, ссылочки на слайде, там, из НИСовский отчет. Я рекомендую посмотреть, будет достаточно
[59:54.960 --> 01:00:09.760]  интересно. Но возвращаясь к тому, какие вообще атаки бывают. То есть, атаки по сторонним каналам
[01:00:09.760 --> 01:00:18.040]  они имеют, там, свойства. То есть, например, есть там свойства физические. Например, время. Мы
[01:00:18.040 --> 01:00:23.680]  померили время. То есть, там, время больше, время меньше. Мы узнали, соответственно, информацию,
[01:00:23.680 --> 01:00:30.160]  там, о длине хэша, например, или о том, когда, соответственно, мы, сколько успехов, там, букв
[01:00:30.160 --> 01:00:37.040]  этого хэша, мы успели проверить. Есть, там, свойства логические. Ну, вот, например, какие-нибудь, там,
[01:00:37.040 --> 01:00:42.760]  статистические данные, такие, как количество, там, прерываний, объем потребляемой памяти,
[01:00:42.760 --> 01:00:49.200]  соответственно, сообщения об ошибках, которые нам появляются. Вот, они разные. Они сообщают о
[01:00:49.200 --> 01:00:54.440]  разных ошибках. Соответственно, мы можем по ним предугадать, а где именно эта ошибка произошла.
[01:00:54.440 --> 01:01:01.440]  И, соответственно, мы прошли дальше, или, собственно, раньше. Они также отличаются по
[01:01:01.440 --> 01:01:09.280]  способу эксплуатации. То есть, вот, например, там, у вас способ эксплуатации может быть, там,
[01:01:09.280 --> 01:01:17.280]  аппаратным. Но, вот, есть, там, атака, соответственно, для излечения, соответственно, там, содержимого
[01:01:17.280 --> 01:01:23.440]  оперативной памяти, там, по непрямому каналу, вот, с помощью, там, жидкого азота, там, для акулбута.
[01:01:23.440 --> 01:01:28.440]  Это, вот, аппараты, например, атаки. С другой стороны, там, у вас все может происходить полностью
[01:01:28.440 --> 01:01:33.160]  программно. Когда вы замеряете, там, время выполнения каким-нибудь встроенным таймером, там,
[01:01:33.160 --> 01:01:43.040]  на процессоре просто выполняется, там, в отдельном потоке. У вас отличаются по способу
[01:01:43.040 --> 01:01:49.480]  расположения нарушителя. Соответственно, там, нарушитель может быть локальный. То есть, например,
[01:01:49.480 --> 01:01:56.360]  вот, он играет с напряжением, и, там, процессор, соответственно, либо что-то раскрывает, либо,
[01:01:56.360 --> 01:02:03.040]  наоборот, начинает ходить по каким-то не тем веткам, по которым он должен был быть.
[01:02:03.040 --> 01:02:09.520]  Вот, пример аппаратных кличей. Соответственно, либо, там, может быть, удаленный. Соответственно,
[01:02:09.520 --> 01:02:14.720]  у нас находится некоторый удаленный сервер, там, который может быть, может быть, за несколько
[01:02:14.720 --> 01:02:22.680]  десятков километров от нас, и мы за время его ответа можем прикинуть, какие операции он выполнял
[01:02:22.680 --> 01:02:33.320]  для того, чтобы нам ответить. При этом также еще часто считается, что атаки по сторонним
[01:02:33.320 --> 01:02:41.920]  каналам — это про то, как что-то можно узнать. То есть, вот вы, там, слушаете, там, кого-нибудь,
[01:02:41.920 --> 01:02:49.800]  там, наблюдаете что-то, то есть, и узнаете, вот, какую-то информацию, которую они должны знать.
[01:02:49.800 --> 01:02:58.120]  Ну, там, то есть, что они пассивные, фактически, имеют пассивную реализацию. На самом деле,
[01:02:58.120 --> 01:03:07.680]  есть и немало атак, так называемых, активных, которые, вот, собственно, приводят к каким-то
[01:03:07.680 --> 01:03:17.280]  изменениям в работе системы, соответственно, для, там, нашего удобства. Ну, вот, как пример,
[01:03:17.280 --> 01:03:26.160]  там, вот, как раз аппаратные гличчи буквально в третьем разделе. И Rowhammer, например. Про Rowhammer
[01:03:26.160 --> 01:03:37.440]  кто-нибудь слышал? Про такую атаку. Ну, даже если не слышали, то не волнуйтесь, скорее всего,
[01:03:37.440 --> 01:03:46.040]  ваш компьютер ей подвержен за редким исключением, если у вас, там, ECC, то есть, оперативная память,
[01:03:46.040 --> 01:03:51.560]  то есть, память с коррекцией ошибок. То есть, идея заключается в том, что, если достаточно активно
[01:03:51.560 --> 01:04:01.360]  менять состояние оперативной памяти, то есть, менять состояние каких-то битов, то из-за счет
[01:04:01.360 --> 01:04:09.080]  физического устройства оперативной памяти может произойти изменение соседних бит. Вот так. И,
[01:04:09.080 --> 01:04:15.800]  соответственно, от этой атаки, там, в различных ее модификациях, там, подвержены, в общем-то,
[01:04:15.800 --> 01:04:23.320]  все виды памяти, там, вплоть до DDR5, там, при условии, что у вас, там, нету более-менее нормального
[01:04:23.320 --> 01:04:41.080]  работающего ECC, то есть, RF correction кода. Вот. Из этого нужно выяснить одну простую вещь. Что, вот,
[01:04:41.080 --> 01:04:52.440]  если у вас есть некоторый вычислительный процесс, который происходит, там, с какими-то данными,
[01:04:52.440 --> 01:04:58.640]  на разделяемых ресурсах, то есть, кроме вашего вычислительного процесса, есть что-то еще.
[01:04:58.640 --> 01:05:09.720]  Вот. Особенность устройства всех этих систем, она всегда приведет к каким-то атакам посторонним
[01:05:09.720 --> 01:05:16.400]  каналам. У вас так физика работает. Ну, просто, сам даже, просто, кремний, который вычисляет,
[01:05:16.400 --> 01:05:22.080]  он работает неравномерно. И, соответственно, у вас, там, напряжение скачет, у вас, соответственно,
[01:05:22.080 --> 01:05:32.920]  там, частоты меняются, там, допустим. У вас, там, электропотребление разное, у вас время выполнения,
[01:05:32.920 --> 01:05:41.120]  там, не знаю, операции, там, умножения и так далее, оно тоже разное. И, в общем-то, для того, чтобы
[01:05:41.120 --> 01:05:50.200]  решить вот эти вот, там, проблемы фундаментально, не знаю, там, темным кремнем каким-то положиться,
[01:05:50.200 --> 01:06:02.400]  нужны совершенно другие порядки стоимости оборудования. И даже они, там, с долей вероятности
[01:06:02.400 --> 01:06:09.320]  вам никак не помогут решить все вот эти вот проблемы. То есть, все равно какие-то останутся,
[01:06:09.520 --> 01:06:17.200]  про которые вы и не узнаете. Поэтому нужно понимать, что любая система, она будет этому подвержена
[01:06:17.200 --> 01:06:27.440]  всегда. И то, грубо говоря, насколько она этому будет подвержена, там, будет определять, соответственно,
[01:06:27.440 --> 01:06:34.000]  вашу возможность по митигации вот этих вот атак и, соответственно, по вашему желанию их,
[01:06:34.000 --> 01:06:41.800]  собственно, вот изолировать. Но, как пример, там, сейчас, например, в всех, там, процессорах Intel
[01:06:41.800 --> 01:06:50.600]  современных, там сломан Hyper-Trading. Знаете про то, что, там, в кедре процессора можно выполнять
[01:06:50.600 --> 01:06:57.440]  несколько виртуальных поток. Вот, соответственно, производительность падает, ну, там, почти что вдвое,
[01:06:57.440 --> 01:07:04.960]  если его отключить. В случае с, там, десктопными компьютерами, ну, никто так не делает, потому что
[01:07:04.960 --> 01:07:12.480]  просто не готовы пожертвовать этой производительностью. В случае, там, с серверными решениями, это может
[01:07:12.480 --> 01:07:19.800]  быть вполне нормально, просто из-за того, что, там, для серверных решений куда важнее, там, даже
[01:07:19.800 --> 01:07:33.280]  безопасность и изоляция клиентов друг от друга. Как раз наличие, собственно, атак по побочным
[01:07:33.280 --> 01:07:41.440]  каналам, оно еще лучше иллюстрирует, почему, там, вынос фактически, там, криптографических
[01:07:41.440 --> 01:07:49.280]  операций, там, на отдельный процессор, это гораздо безопаснее, чем пытаться, там, запихать эти
[01:07:49.280 --> 01:07:56.000]  операции, там, с какой-нибудь trusted execution engine, то есть, там, 5e, там, слой, там, или system
[01:07:56.000 --> 01:08:01.120]  management mode, то есть, какой-то специальный режим процессора, который будет, там, условно программно
[01:08:01.120 --> 01:08:08.200]  аппаратно изолирован от всей прочей конструкции. Оно не будет работать или будет работать достаточно
[01:08:08.200 --> 01:08:16.000]  плохо и приведет к неприятным атакам, про которые вы узнаете достаточно поздно. Соответственно,
[01:08:16.000 --> 01:08:23.000]  современные атаки, они чаще всего используют особенности устройства микроархитектуры,
[01:08:23.000 --> 01:08:32.560]  в частности, там, конвейера, кэшей, там, branch prediction, кэшей, там, микроопераций, там,
[01:08:32.560 --> 01:08:40.400]  способы, там, доступа к данным, там, особенности, там, предсказания ветвлений, там, для раскрытия
[01:08:40.400 --> 01:08:46.600]  какой-то информации, ну, в первую очередь, там, раскрытие, там, чужой оперативной памяти и,
[01:08:46.600 --> 01:08:53.360]  в основном, их используют для построения более сложных атак. То есть, мы какую-то информацию
[01:08:53.360 --> 01:08:59.600]  раскрыли, после этого нужно ее, соответственно, куда-то передать и, там, в дальнейшем она может
[01:08:59.600 --> 01:09:08.000]  быть уже использована против вас. Приведем несколько примеров. Ну, наверное, такой простой и при
[01:09:08.000 --> 01:09:20.000]  этом очень понятный пример. Это атака TPM Fail, которая проводилась на внешнее устройство TPM,
[01:09:20.000 --> 01:09:29.880]  в задачу которых в том числе входит вычисление, там, некоторые, там, подписи от тех данных,
[01:09:29.880 --> 01:09:37.320]  которые вы на этот TPM передаете. Ну, то есть, идея какая? Мы сгенерировали некоторый ключ
[01:09:37.320 --> 01:09:44.200]  в TPM, то есть, ну, некоторый приватный ключ, он хранится в нем, его нельзя извлечь,
[01:09:44.200 --> 01:09:49.480]  потому что нет для этого интерфейса, но при этом мы извлекли из него приватный ключ.
[01:09:49.480 --> 01:09:55.160]  Ой, вот тут прошу прощения. Мы приватный ключ, сгенерировали ключевую пару, приватный ключ
[01:09:55.160 --> 01:10:02.760]  хранится на TPM, его нельзя извлечь, а публичный ключ, который позволяет, собственно, подтвердить,
[01:10:02.760 --> 01:10:11.160]  что все сообщения подписаны действительно тем приватным ключом, он, соответственно,
[01:10:11.160 --> 01:10:19.760]  доступен снаружи. Это удобная схема, которая позволяет нам защитить максимально, соответственно,
[01:10:19.760 --> 01:10:25.240]  приватный ключ, не давая, собственно, там, возможность атакующим его получить и при этом
[01:10:25.240 --> 01:10:31.480]  безопасно подписывать сообщения и отдавать их там наружу. Это используется, например,
[01:10:31.480 --> 01:10:38.880]  там, каким-нибудь Strong Sloan, это один из VPN-клиентов, точнее, VPN-клиентированный,
[01:10:38.880 --> 01:10:48.000]  то есть, для аутентификации пользователей. Вот, там, в спецификации TPM 2.0 есть один из
[01:10:48.000 --> 01:10:58.400]  алгоритмов на там, шифрование, то есть, на базе эллиптических привых и CDSA, вот, и если,
[01:10:58.400 --> 01:11:06.800]  ну, классический, там, пример, соответственно, там, шифрование с ключевой парой, то есть,
[01:11:06.800 --> 01:11:13.600]  симметричного шифрования, это, там, у вас есть некоторый приватный ключ, у вас есть, соответственно,
[01:11:13.600 --> 01:11:20.440]  там, некоторое сообщение, вы, соответственно, этим приватным ключом шифруете это сообщение,
[01:11:20.440 --> 01:11:27.880]  там, передаете, соответственно, получателю, он с помощью публичного ключа расшифровывает и,
[01:11:27.880 --> 01:11:34.560]  соответственно, там, все хорошо. У вас есть некоторые, грубо говоря, приватные ключи,
[01:11:34.560 --> 01:11:44.880]  которые нельзя никому показывать. У CDSA немножко другая схема, кроме приватного ключа,
[01:11:44.880 --> 01:11:50.320]  который нельзя никому показывать, у него есть еще такая штука под названием nonce. Ну, фактически,
[01:11:50.320 --> 01:11:58.360]  это некоторое случайное значение, которое тоже никому нельзя показывать, которое не должно
[01:11:58.360 --> 01:12:06.080]  повторяться, и оно, соответственно, участвует в вычислении, собственно, криптографической
[01:12:06.080 --> 01:12:12.600]  подписи в механизме CDSA. Для нас это, в принципе, не так важно, за исключением того, что вот есть
[01:12:12.600 --> 01:12:20.320]  некоторый приватный ключ, есть, соответственно, некоторое случайное число, оно каждый раз разное,
[01:12:20.320 --> 01:12:28.880]  там, при подписи, соответственно, разных сообщений, и при этом, имея nonce, можно также
[01:12:28.880 --> 01:12:36.520]  вычислить, имея пару, соответственно, подписанное сообщение, имея nonce, при наличии публичного
[01:12:36.520 --> 01:12:41.400]  ключа, вы можете, соответственно, тут, имея тройку, вы можете вычислить, в том числе, приватный ключ.
[01:12:41.400 --> 01:12:56.620]  Проблема здесь заключается вот в чем. Вот если вас там попросят умножить 8 399 на 9, вы в уме
[01:12:56.620 --> 01:13:07.840]  умножите, что быстрее, вот это число на вот это или, например, там на 342. Ну, очевидно, что вам
[01:13:07.840 --> 01:13:18.120]  гораздо быстрее в уме посчитать первое, чем второе, и, в общем-то, компьютер, он не исключительно,
[01:13:18.120 --> 01:13:29.480]  то есть, в некоторых TPM, подпись, соответственно, CDSA считалась заметно быстрее, если nonce был
[01:13:29.480 --> 01:13:37.680]  маленьким, ну или, точнее, содержал много нулей в начале. Ну, вот пример, соответственно, там слева
[01:13:37.680 --> 01:13:49.920]  это, не помню, как фирма называется, но это один из, соответственно, внешних TPM модулей, а справа
[01:13:49.920 --> 01:14:00.240]  как раз это график с Intel'овым FMV TPM, которые вели себя по-разному в зависимости от того, насколько
[01:14:00.240 --> 01:14:10.560]  маленький, собственно, nonce у вас сгенерировался. Как итог, соответственно, атакующие просто набрали
[01:14:10.560 --> 01:14:18.120]  достаточно количество сообщений, для которых nonce получался с достаточно небольшим количеством нулей,
[01:14:18.120 --> 01:14:27.640]  тем самым сузили себе пространство поиска, и в итоге раскрыли сам приватный ключ, решив достаточно
[01:14:27.640 --> 01:14:34.360]  такую объемную, но вполне себе решаемую систему линейных уровней. При этом, соответственно,
[01:14:34.360 --> 01:14:39.360]  эти все TPM'ы, они были оттестованы, причем некоторые там оттестованы по максимальному уровню
[01:14:39.360 --> 01:14:46.840]  безопасности, и в свое время буквально два года назад атака наделала огромное количество шума,
[01:14:46.840 --> 01:14:54.920]  потому что безопасные системы внезапно оказались очень сильно опасными. С помощью такой атаки ребята
[01:14:54.920 --> 01:15:04.000]  просто ломали, например, VPN сервера, которые у вас работали, использовали TPM в качестве хранили
[01:15:04.000 --> 01:15:13.040]  щекучий. Это не единственный пример атаки, то есть другим примером атаки, который объясняется
[01:15:13.040 --> 01:15:24.280]  на пальцах, это атака meltdown, точнее уязвимость meltdown, которая может быть проэксплуатирована
[01:15:24.280 --> 01:15:37.200]  вот таким способом. Соответственно, здесь схема заключается в следующем. Вот в ядре у вас есть
[01:15:37.200 --> 01:15:44.160]  некоторая там оперативная память, которая, как мы вот в прошлой лекции говорили, она часто
[01:15:44.160 --> 01:15:55.400]  располагается в том же самом, соответственно, пространстве, что и пользовательский код,
[01:15:55.400 --> 01:16:03.720]  но при этом права доступа к этой памяти у вас отсутствуют, то есть с привилегиями пользователей
[01:16:03.720 --> 01:16:10.800]  эту память нельзя прочитать. Соответственно, если мы каким-то образом сможем прочитать эту память,
[01:16:10.800 --> 01:16:23.560]  то собственно мы нашли уязвимость. Вот как работает meltdown? То есть мы выбираем там некоторые
[01:16:23.560 --> 01:16:31.080]  значения, то есть мы выбираем некоторые адресы ядра, которые мы хотим прочесть. Соответственно,
[01:16:31.080 --> 01:16:38.840]  катор имеет тип там unsigned char звездочка, то есть это некоторые указатели на байт. В дальнейшем у
[01:16:38.840 --> 01:16:48.560]  нас есть некоторый probe array. Probe array фактически это некоторая память, которая изначально не
[01:16:48.560 --> 01:16:57.240]  закаширована и имеет размер, соответственно, 256 умножить на 4096 байт. Здесь, соответственно,
[01:16:57.240 --> 01:17:08.320]  4096 байт это размер страницы, а 256 это соответственно диапазон одного восьми битного значения,
[01:17:08.320 --> 01:17:19.520]  нуля до 255. Кстати, probe array называется так, потому что вот эта вот атака, это называется там
[01:17:19.520 --> 01:17:24.960]  атака prime plus probe. То есть сначала мы выбираем некоторые значения, после этого мы его пробим.
[01:17:24.960 --> 01:17:35.040]  Вот. Соответственно, здесь probe array он полностью сначала не закаширован. А как мы помним,
[01:17:35.040 --> 01:17:45.160]  у нас обращение к оперативной памяти, это собственно там несколько сотен нано секунд,
[01:17:45.160 --> 01:17:54.680]  ну там условно 60-80, а если память медленно, то того больше. Поэтому мы достаточно легко можем
[01:17:54.680 --> 01:18:01.760]  отличить, когда происходит обращение к кашированной памяти, то есть это одна нано секунда,
[01:18:01.760 --> 01:18:11.800]  и к некашированной памяти. То есть как получить в собственной области этой памяти некашированную
[01:18:11.800 --> 01:18:16.720]  память. Это очень просто, вы можете просто обращаться к другой памяти достаточно долго,
[01:18:16.720 --> 01:18:26.160]  и за счет этого у вас кэш процессора просто выкинет probe array из своего кэша, просто он
[01:18:26.160 --> 01:18:33.160]  ему станет не нужен. Потому что кэш он ограниченный, соответственно, у вас есть ограниченный объем данных,
[01:18:33.160 --> 01:18:40.560]  который вы можете хранить в кэше. Соответственно, здесь что происходит, у вас есть два потока. Вот
[01:18:40.560 --> 01:18:48.440]  код одного потока как раз представлен на слайде, и он выглядит так, то есть там raise exception,
[01:18:48.440 --> 01:18:59.160]  условно там может быть написан int3, например. И дальше там, например, mov, eax, который будет
[01:18:59.160 --> 01:19:06.600]  читать из этого probe array кадр на 4096. То есть, фактически, некоторые там access, то есть некоторое
[01:19:06.600 --> 01:19:16.000]  чтение данных из оперативной памяти. Здесь схема заключается в том, что за счет ограничений
[01:19:16.000 --> 01:19:29.080]  работы вашего, собственно, режима вы никогда не имеете права разыменовывать ядерный указатель
[01:19:29.080 --> 01:19:37.320]  в пространстве пользователя. Но для ускорения работы, собственно, процессора, когда мы выполняли
[01:19:37.320 --> 01:19:44.280]  операции спекулятивно, то есть мы просто фактически кэшировали выполнение некоторых операций, чтобы
[01:19:44.280 --> 01:19:49.880]  после этого их просто применить в тот момент, когда мы до них дойдем. То есть, в некоторое
[01:19:49.880 --> 01:19:57.240]  кэширование, которое мы говорили ранее, то есть спекулятивное выполнение, то процессор эти права
[01:19:57.280 --> 01:20:06.840]  доступа не проверял. И тем самым возникала интересная ситуация, что, хотя мы никогда,
[01:20:06.840 --> 01:20:13.280]  собственно, сюда не могли попасть при реальном выполнении, процессор при спекулятивном выполнении
[01:20:13.280 --> 01:20:26.800]  этот код выполнял, и тем самым содержимое probe array с некоторым индексом, оно попадало в кэш
[01:20:26.800 --> 01:20:37.800]  процессора, то есть становилось закэшировано. То есть, на суде понятно, как можно узнать, собственно,
[01:20:37.800 --> 01:20:47.240]  какое значение у ядерного адреса, то есть по этому ядерному адресу находилось у русской аудитории.
[01:20:47.240 --> 01:20:56.200]  На слайде написано. На слайде написано, ну да, в принципе, окей. Но схема действительно такая,
[01:20:56.200 --> 01:21:02.440]  что у вас работает некоторый другой поток, и он просто там замеряет, сколько времени там обращения
[01:21:02.440 --> 01:21:08.240]  вот к этому участку памяти, сколько к этому участку памяти. Если у вас достаточно маленький кэш,
[01:21:08.240 --> 01:21:15.480]  то нужно, соответственно, сделать там несколько проверок, потому что, соответственно, к моменту,
[01:21:15.480 --> 01:21:23.400]  когда вы проверите, грубо говоря, там несколько значений, у вас они там уже выкинут то значение,
[01:21:23.400 --> 01:21:28.600]  которое у вас закэшировалось вот в момент, соответственно, пробинга, то есть в момент
[01:21:28.600 --> 01:21:37.400]  вот этого операции access. То есть, атака достаточно небыстрая, но позволяет, собственно, там с очень
[01:21:37.400 --> 01:21:42.600]  высокой долей вероятности прочитать абсолютно любую ядерную память при условии, что у вас есть
[01:21:42.600 --> 01:21:52.200]  выполнение в пользовательском пространстве на процессорах x86. Вот так, да защищались.
[01:21:52.200 --> 01:22:01.080]  Это все страшно, но, соответственно, как вот от этого защищаться? Ну, правда жизни,
[01:22:01.080 --> 01:22:06.800]  наверное, такова, что защищаться действительно никак, никак в том плане, что нельзя защититься
[01:22:06.800 --> 01:22:13.960]  глобально от атак этого класса, как буквально я говорил несколько слайдов назад. Конкретно от
[01:22:13.960 --> 01:22:22.920]  вот той атаки, которая появилась сегодня, вчера, позавчера, можно защититься каким-то
[01:22:22.920 --> 01:22:31.440]  специфичным образом. От того же TPM Fail защитились тем, что обновили прошивки на TPM и использовали
[01:22:31.440 --> 01:22:38.280]  там константную криптографию, то есть криптографию, которая выполнялась за фиксированное время.
[01:22:38.280 --> 01:22:46.520]  Как раз, если по ссылке сходите, которая была на слайде, там того же TPM Fail, там рассказывается,
[01:22:46.520 --> 01:22:54.280]  какие вообще операции можно использовать в C, чтобы у вас код выполнялся за константное время.
[01:22:54.280 --> 01:23:02.760]  В случае с мелдауном, ну вот, есть, конечно, вариант с аппаратной защитой. То есть, в общем-то,
[01:23:02.760 --> 01:23:07.080]  то, что спекулятивный доступ не должен обходить права доступа к памяти, это как бы все понимали,
[01:23:07.080 --> 01:23:13.080]  но понимали в тот момент, когда мы рассказали о том, что вот, возможно, такая атака под названием
[01:23:13.080 --> 01:23:21.160]  сейчас мелдауна называется. Со старыми процессорами что делать? Ну вот, со старыми
[01:23:21.160 --> 01:23:29.200]  процессорами пришлось ядерное и пользовательское адресное пространство располагать в разных CR3.
[01:23:29.200 --> 01:23:39.600]  И вот мы пришли к тому, что сейчас, когда ваш фактически пользовательский код дергает какие-то
[01:23:39.600 --> 01:23:49.360]  системные вызовы, у вас происходит изменение CR3. То есть, соответственно, вы вынуждены сбрасывать
[01:23:49.360 --> 01:23:57.600]  весь TLB, если у вас процессор достаточно медленный, если у вас процессор достаточно старый, который не
[01:23:57.600 --> 01:24:07.680]  может хранить идентификаторы задач, то есть фактически теги задач в вашем TLB. И, как результат,
[01:24:07.680 --> 01:24:16.080]  mitigation будет достаточно медленным и производительности вам не прибавят. Ну, для других атак, соответственно,
[01:24:16.080 --> 01:24:23.600]  используются другие способы, но я думаю, что мы об этом еще поговорим, когда будем говорить о
[01:24:23.600 --> 01:24:32.800]  микроакадемических атаках в одной из следующих лекций, если по крайней мере успеем. На этом у меня
[01:24:32.800 --> 01:24:40.160]  на сегодня все. Какие, собственно, вопросы? Интересно было бы узнать про уязвимость
[01:24:40.160 --> 01:24:46.040]  спектра, потому что она появилась где-то в то же время, как и молдаун. Да, я, соответственно,
[01:24:46.040 --> 01:24:54.760]  для спектра оставил буквально два слайда, которые есть у вас на ForgeStress.ru, в том числе у вас есть
[01:24:54.760 --> 01:25:01.200]  презентация. Но сегодня мы просто спектр не успеем, но когда будет, соответственно,
[01:25:01.200 --> 01:25:10.400]  лекция про микроархитектурные атаки, то я не расскажу. Это будет, ну вот, через, наверное,
[01:25:10.400 --> 01:25:24.520]  две или три лекции. Да, да. Я, соответственно, на этом предлагаю закончить тогда запись.
[01:25:26.520 --> 01:25:30.280]  Всем спасибо и переходим к практической части.
