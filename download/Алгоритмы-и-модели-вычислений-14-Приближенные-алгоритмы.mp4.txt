[00:00.000 --> 00:26.480]  Сегодня поговорим про сложность задач опроксимации или про
[00:26.480 --> 00:40.960]  приближенные алгоритмы. Ну и тут как обычно в теории сложности вычислений
[00:40.960 --> 00:46.560]  значит идет двустороннее движение. С одной стороны находится все больше и
[00:46.560 --> 00:50.680]  больше задач, которые можно решать приближенно, но с другой стороны для
[00:50.680 --> 00:59.880]  большего и большего числа задач показывает, что это невозможно, если только p не равно
[00:59.880 --> 01:09.200]  np. Вообще изначально задачи опроксимации воспринимались как ну такой как бы ключ
[01:09.200 --> 01:16.360]  к проблеме p и np, то есть если p не равно np, то вроде как многие задачи не решаются,
[01:16.360 --> 01:23.400]  в том числе многие задачи оптимизации, но на практике и не нужно решать задачи
[01:23.400 --> 01:29.880]  оптимизации точно, значит достаточно решить с какой-то точностью. Например,
[01:29.880 --> 01:35.720]  если есть задача минимизации расходов там на что-нибудь, ну например задача Коми-Ваежора,
[01:35.720 --> 01:42.960]  значит где Коми-Ваежор должен проехать минимальное расстояние и посетить все
[01:42.960 --> 01:48.840]  города. Соответственно, если эта задача взялась на практике, где реально нужно что-то объехать,
[01:48.840 --> 01:58.840]  и вы, например, умеете ее решать не прямо-таки находя минимум, а находя минимум там плюс не
[01:58.840 --> 02:05.640]  больше 5%, то это уже очень хорошо и на практике особо больше ничего не надо. То есть какие-то
[02:05.640 --> 02:11.840]  там высчитывать копейки, снижать точность с 5% до 3%, это в общем обычно не нужно.
[02:11.840 --> 02:19.800]  Вот. Но с другой стороны, если ваш путь, например, там в 5 раз длиннее минимального,
[02:19.800 --> 02:27.160]  да, то это уже не очень хорошо. Да, хорошо бы, чтобы все-таки что-то близко к оптимуму находилось.
[02:27.160 --> 02:35.080]  Вот. Ну и, соответственно, это предполагалось как некоторый такой ключ, на что если даже мы не
[02:35.080 --> 02:40.480]  умеем решать задачи точно, но умеем делать это приближенно, то тогда в общем не страшно,
[02:40.480 --> 02:46.640]  что P не равно NP, но мы как-то решим что-то приемлемое получим и будем использовать.
[02:46.640 --> 02:56.800]  Вот, вообще такая была идея в 70-х, но потом к началу 90-х оказалось, что для некоторых задач
[02:56.800 --> 03:03.520]  это так происходит, но для других задач приближение сверх какой-то точности уже будет NP трудным.
[03:03.520 --> 03:13.600]  Вот. То есть тут, вот про это я хочу сегодня поговорить. Значит, что такое вообще задача оптимизации,
[03:13.600 --> 03:21.400]  да, и связана с ней задача опроксимации. Так, значит, задача оптимизации,
[03:21.400 --> 03:36.880]  значит, известна некоторая функция f от x и y, значит, известна некоторая функция f от x и y
[03:36.880 --> 03:48.320]  с значениями, ну, каких-то числах, да, натуральных, там, рациональных, значит, функции f от x и y,
[03:48.320 --> 04:07.400]  ну, с числовыми значениями. Вот. Ну и, соответственно, дано x, значит, а найти нужно,
[04:07.400 --> 04:22.240]  значит, либо максимум f от x и y по y. Ну и тут предполагается, значит, тут, как обычно, очень много умолчаний,
[04:22.240 --> 04:30.640]  да, то есть предполагается, что функция вычислимая и заполинальное время длины x, значит, вычислимо за
[04:30.640 --> 04:46.200]  время полином от длины x, именно x, а не всего входа, да, потому что это нам дает и ограничение y полинной
[04:46.200 --> 04:56.680]  длиной, да, то есть тут, соответственно, длина y меньше либо равна, чем какой-то полином от длины x,
[04:56.680 --> 05:01.960]  и это дает нам конечную область, которую мы максимизируем, и, соответственно, максимум
[05:01.960 --> 05:12.600]  точно достигается. Вот. Ну, соответственно, вот это, когда я говорю, найти максимум, то это прям найти
[05:12.600 --> 05:22.720]  значение максимальное, вот, или другой вариант, когда нужно найти arg максимум, то есть точку максимума,
[05:22.720 --> 05:37.200]  вот, ну или минимум может быть, да, то есть всегда можно, в принципе, сменить знак у функции и свести
[05:37.200 --> 05:45.320]  задачу максимизации к минимизации наоборот. Вот, значит, это задача апроксимация, вот, а задача
[05:45.320 --> 05:53.080]  оптимизации, ой, задача оптимизации, задача апроксимации несколько более со слабыми требованиями.
[05:53.080 --> 06:13.720]  В общем, задача апроксимации, значит, с параметром rho от нуля до единицы, да, означает, ну, что нужно
[06:13.720 --> 06:29.560]  найти у, да, значит, вот пусть опт, это оптимальное значение, значит, вот опт равняется,
[06:29.560 --> 06:45.480]  то есть, как раз, максимум по y, f от x и y, и соответственно, нужно найти, значит, найти нужно число какое-то,
[06:45.480 --> 07:01.800]  ну, такое тка большое в интервале от rho умножить на опт, то опт, это все для задачи
[07:01.800 --> 07:18.280]  максимизации, ну, или y, или y такое, что f от x и y, ну, тут смотрите, когда я пишу
[07:18.280 --> 07:23.920]  найти число, то нужно обязательно, чтобы он не превысило оптимум, если я конкретно y нахожу,
[07:23.920 --> 07:28.480]  то там значение точно оптимум не превысят, и поэтому можно в одну сторону писать, что это
[07:28.480 --> 07:38.720]  больше либо равно rho умножить на опт, ну, число у нас же функции с частотами значениями,
[07:38.720 --> 07:47.280]  не, не взять даже одно из значений, просто заведомо, чтобы оно попало в этот интервал,
[07:47.280 --> 07:52.560]  смотрите, это не так легко, как кажется, да, значит, потому что нужно заведомо не перескочить вот
[07:52.560 --> 07:58.960]  этот опт, если бы у нас было только нижнее ограничение, то можно было там максимально
[07:58.960 --> 08:07.760]  возможное значение взять и сказать, что это решение, вот, но нам нужно обязательно не превысить вот
[08:07.760 --> 08:22.920]  эту границу, не, ну, вот так вот, но опт вычислено по f, и вот нужно найти k в этом интервале,
[08:22.920 --> 08:32.640]  любое k в этом интервале подойдет как решение, но нужно заведомо, чтобы алгоритм давал число именно
[08:32.640 --> 08:42.640]  в этом интервале, ну, типа того, да, конечно, то есть вот, да, вот с задачей оптимизации у нас
[08:42.640 --> 08:48.640]  бывает два варианта, либо это само значение максимальное, либо точка, на которую оно
[08:48.640 --> 08:54.880]  достигается, вот, вот если мы первые приближаем до значения, то нам нужно все-таки не превысить
[08:54.880 --> 09:04.120]  абсолютный максимум, да, но при этом быть больше, чем rho от него, вот, если мы прям ищем, если на задачу
[09:04.120 --> 09:11.360]  поиска нужно найти y, тогда только односторонняя граница, потому что вторая автоматически соблюдется,
[09:11.360 --> 09:21.840]  вот, ну, а если минимизация, то, ну, либо там делить на rho нужно и все менять местами, либо считать,
[09:21.840 --> 09:29.400]  что rho тогда больше единицы, и, соответственно, нужна, давайте я напишу, значит, если минимизация,
[09:29.400 --> 09:41.720]  тогда тут k должно быть соответственно от opt до opt делить на rho, значит, ну, это вот если мы
[09:41.720 --> 09:47.680]  хотим, чтобы rho было всегда 0.2 единицы, либо можно сказать, что rho будет больше единицы, и на него нужно умножать,
[09:47.680 --> 09:54.200]  вот, а вообще тут как бы не сложилось такого универсального подхода, да, то есть для
[09:54.200 --> 10:01.200]  максимизации обычно вот так вот, все-таки rho будет меньше единицы, и говорит, ну, да и даже бывает,
[10:01.200 --> 10:07.880]  да, там если это rho близко к единице, то иногда там, наоборот, на 1 минус rho смотрят, да, то есть
[10:07.880 --> 10:13.200]  приблизить 0.5 процентов это не значит 5 процентов от максимума, а наоборот 95 процентов от максимума,
[10:13.200 --> 10:20.240]  такая обычно, вот, ну, а здесь, соответственно, когда у нас минимизация, то могут говорить
[10:20.240 --> 10:24.040]  приближение с точностью две трети, а могут говорить приближение с точностью три вторых,
[10:24.040 --> 10:30.160]  в зависимости от того, тут мы делим на rho или умножаем, вот, в общем, тут
[10:30.160 --> 10:39.880]  не сложилось прям универсальных обозначений, да, то есть часто для, ну, отдельно авторы в своих
[10:39.880 --> 10:45.120]  книгах или в отдельных задачах, в общем, своих договоренностей, которые как-то друг с другом
[10:45.120 --> 10:53.160]  не стыкуются, но обычно из контекста понятно, что имеется в виду, вот, да, ну, и, соответственно,
[10:53.160 --> 11:10.960]  допишу, а f от x и y будет меньше либо равно, чем opt делить на rho, вот, хорошо,
[11:10.960 --> 11:22.720]  значит, ну, как я понимаю, вот, мы на лекции пропустили, а на сценариях была дарандомизация,
[11:22.720 --> 11:29.480]  и там как раз задачи аппроксимации решались, так, а был, видимо, только была задача максимальном
[11:29.480 --> 11:39.120]  разрезе, а еще что-нибудь было, например, max3sat, например, было, и 7-8 там прям было, да, а 7-8 было
[11:39.120 --> 11:53.160]  очень хорошо, тогда будем считать, что вы знаете, вот, так, ну, хорошо, значит, тогда я этот пример не буду
[11:53.160 --> 12:05.520]  повторять, вот, а покажу пример, когда вообще ни для какого rho нет приближения, значит, пример
[12:09.120 --> 12:28.520]  когда нет приближения, значит, это задача комива-ежора с произвольными стоимостьями, да, с произвольными весами,
[12:28.520 --> 12:40.920]  значит, задача комива-ежора с произвольными весами,
[12:40.920 --> 12:59.080]  значит, тут, что имеется в виду, ну, вы можете считать, что просто есть матрица,
[12:59.080 --> 13:16.520]  она там w, может быть, даже несимметричная, значит, w это матрица такая, что w и gt это стоимость проезда
[13:16.520 --> 13:36.920]  из и в ж, ну, может даже считать, что и на диагональ не обязательно нули стоят, вот, но можете считать, что нули, так, давайте считать, что эти все
[13:36.920 --> 14:06.920]  w и gt больше брона нуля, вот, хотя, если у нас задача комива-ежора и нужно один раз все обойти, то даже это не важно, можно к ним ко всем прибавить одно и то же значение, так, чтобы они стали больше нуля, даже если были меньше нуля, да, то есть, вообще, если, то, то есть, тут смотрите, чем плохи отрицательные веса, тем, что может получиться отрицательный цикл, а поэтому в отрицательном циклу дальше, как бы, можно ходить и накручивать сколько
[14:06.920 --> 14:30.920]  угодно маленькое расстояние, но если мы потребуем, что нужно ровно один раз попасть в каждой вершине, тогда это не важно, да, тогда мы не сможем накручивать, вот, но все-таки, так, привычно, чтобы это были не отрицательные величины, так, ну, и, соответственно, нужно
[14:36.920 --> 14:42.920]  ну, задача, значит, нужно минимизировать
[14:42.920 --> 14:49.920]  нужно минимизировать
[14:49.920 --> 14:51.920]  тумму
[14:51.920 --> 14:54.920]  по и объединится до n
[14:54.920 --> 14:59.920]  w и t сигма от и t
[14:59.920 --> 15:06.920]  по всем сигма, значит, по всем
[15:06.920 --> 15:12.920]  перестановкам сигма, состоящим из одного цикла
[15:12.920 --> 15:17.920]  да, значит, можно вот так вот
[15:17.920 --> 15:22.920]  вот, ну, соответственно, эта задача
[15:22.920 --> 15:24.920]  непотрудная
[15:24.920 --> 15:30.920]  ну, сейчас давайте покажу, что даже приближенные решения тоже непотрудные
[15:30.920 --> 15:32.920]  причем с любым весом
[15:32.920 --> 15:38.920]  ну, соответственно, там, не с любым весом в смысле, а с любой точностью, а с любым rho
[15:38.920 --> 15:41.920]  вот, значит, это вот точная задача
[15:41.920 --> 15:48.920]  ну, а приближенная, соответственно, найти какой-то, это минимизация, да, так что, найти какой-то минимизация
[15:48.920 --> 15:52.920]  то есть, что мы будем делать
[15:52.920 --> 15:55.920]  вот, значит, это вот точная задача
[15:55.920 --> 16:05.920]  ну, а приближенная, соответственно, найти какой-то, это минимизация, да, так что, найти либо величину вот здесь вот, да, либо какой-то путь найти, который будет
[16:05.920 --> 16:10.920]  не длиннее вот этого
[16:10.920 --> 16:19.920]  вот, значит, ну, соответственно, это
[16:19.920 --> 16:21.920]  эта задача
[16:22.920 --> 16:24.920]  NP трудна
[16:29.920 --> 16:31.920]  любой точностью
[16:33.920 --> 16:37.920]  ну, не знаю, или для любой точности, да, давай выводится лучше
[16:42.920 --> 16:45.920]  для любой точности задача NP трудна
[16:46.920 --> 16:48.920]  значит, почему?
[16:48.920 --> 16:50.920]  ну, потому что можно к ней свести гамильтонов цикл
[17:01.920 --> 17:03.920]  сведем гамильтонов цикл
[17:06.920 --> 17:08.920]  каким образом мы это сделаем?
[17:09.920 --> 17:12.920]  ну, мы просто скажем, что WGT
[17:18.920 --> 17:22.920]  равно единице, опять, вообще, если ноль разрешить, то можно даже
[17:22.920 --> 17:25.920]  даже для неконстантных РО
[17:25.920 --> 17:27.920]  можно это доказать
[17:28.920 --> 17:32.920]  значит, WGT равно единице, если
[17:33.920 --> 17:35.920]  было ребро ИGT
[17:36.920 --> 17:38.920]  значит, если в графе
[17:42.920 --> 17:44.920]  есть ребро ИGT
[17:48.920 --> 17:52.920]  иначе получится, значит, на счет WGT
[17:53.920 --> 17:55.920]  равно какому-то большому числу
[17:56.920 --> 17:58.920]  равняется n большому
[18:00.920 --> 18:03.920]  вот, ну, это получается, что если гамильтонов цикл есть
[18:19.920 --> 18:22.920]  есть гамильтонов цикл, тогда минимальный вес
[18:25.920 --> 18:27.920]  равен m
[18:28.920 --> 18:32.920]  значит, потому что можно по нему пройти, и каждый ребро до склада 1
[18:32.920 --> 18:34.920]  суммарно будет m, маленькое
[18:34.920 --> 18:36.920]  n маленькое в смысле число вершин
[18:37.920 --> 18:39.920]  а вот если нет гамильтонов цикла
[18:39.920 --> 18:41.920]  ну, тогда, соответственно, в любом цикле, обходящем все вершины
[18:41.920 --> 18:43.920]  у нас будет хотя бы одно неребро
[18:43.920 --> 18:45.920]  и это неребро даст вклад n большое
[18:47.920 --> 18:49.920]  значит, тогда минимальный вес
[18:51.920 --> 18:53.920]  больше ли равной n большого
[18:54.920 --> 18:56.920]  ну, и, соответственно, варьируя n большое
[18:57.920 --> 18:59.920]  можно добиться любого отношения
[19:01.920 --> 19:03.920]  вот, ну, а далее
[19:04.920 --> 19:06.920]  если у нас есть гамильтонов циклов
[19:07.920 --> 19:09.920]  вот, ну, а дальше
[19:09.920 --> 19:11.920]  то есть, вы смотрите, что нужно
[19:13.920 --> 19:15.920]  значит, если у меня n
[19:17.920 --> 19:19.920]  n делить на ρ меньше
[19:20.920 --> 19:22.920]  чем n большое
[19:23.920 --> 19:26.920]  тогда получится, что по приближенному решению
[19:29.920 --> 19:31.920]  по приближенному решению
[19:31.920 --> 19:32.920]  можно найти
[19:36.920 --> 19:38.920]  есть ли гамильтонов циклов графия
[19:49.920 --> 19:52.920]  ну, потому что алгоритм, даже если он только число выдает
[19:53.920 --> 19:55.920]  выдаст либо
[19:56.920 --> 19:58.920]  приближенный алгоритм
[20:02.920 --> 20:04.920]  выдаст
[20:06.920 --> 20:08.920]  либо
[20:11.920 --> 20:13.920]  k меньше, либо равно, чем n делить на ρ
[20:16.920 --> 20:18.920]  либо k больше, равно, чем n большое
[20:22.920 --> 20:24.920]  ну, и, соответственно
[20:24.920 --> 20:26.920]  взяв такие сравнения, можно понять
[20:26.920 --> 20:28.920]  что именно имеет место
[20:29.920 --> 20:31.920]  ну, вот, соответственно
[20:36.920 --> 20:38.920]  отсюда получается, что ρ
[20:40.920 --> 20:42.920]  больше
[20:42.920 --> 20:44.920]  не, лучше не относительно ρ
[20:44.920 --> 20:46.920]  относительно n большое
[20:46.920 --> 20:48.920]  а, собственно, уже все написано
[20:48.920 --> 20:50.920]  относительно n большого
[20:50.920 --> 20:52.920]  то есть, если есть n маленькое
[20:52.920 --> 20:54.920]  и ρ
[20:54.920 --> 20:56.920]  тогда, взяв n большое
[20:56.920 --> 20:58.920]  вот таким вот
[20:58.920 --> 21:00.920]  можно получить, что задача будет n п трудной
[21:02.920 --> 21:04.920]  ну, то есть
[21:04.920 --> 21:06.920]  итог
[21:08.920 --> 21:10.920]  то
[21:10.920 --> 21:12.920]  при n
[21:12.920 --> 21:14.920]  больше, чем n делить на ρ
[21:18.920 --> 21:20.920]  задача ρ приближения
[21:20.920 --> 21:22.920]  будет
[21:24.920 --> 21:26.920]  n п трудней
[21:32.920 --> 21:34.920]  вот
[21:38.920 --> 21:40.920]  так, ну что, прямо в понятном?
[21:44.920 --> 21:46.920]  так, хорошо, с другой стороны
[21:46.920 --> 21:48.920]  если рассмотреть не общую задачу мива и жора
[21:48.920 --> 21:50.920]  а какой-нибудь частный случай
[21:50.920 --> 21:52.920]  то тогда можно вполне с какой-то точностью решить
[21:54.920 --> 21:56.920]  значит, например, можно рассмотреть
[21:56.920 --> 21:58.920]  метрическую задачу кумива и жора
[22:10.920 --> 22:12.920]  метрическая задача кумива и жора
[22:12.920 --> 22:14.920]  значит, что там неравенство треугольника
[22:14.920 --> 22:16.920]  выполняется
[22:16.920 --> 22:18.920]  то есть w и jt
[22:18.920 --> 22:20.920]  плюс w jk
[22:20.920 --> 22:22.920]  будет больше
[22:22.920 --> 22:24.920]  чем w и kt
[22:24.920 --> 22:26.920]  вот
[22:26.920 --> 22:28.920]  это, конечно, для нашего примера
[22:28.920 --> 22:30.920]  предыдущего не подходит
[22:30.920 --> 22:32.920]  потому что может быть так, что
[22:32.920 --> 22:34.920]  тут 2 ребра есть и будет 2 единицы
[22:34.920 --> 22:36.920]  а тут будет n большое
[22:36.920 --> 22:38.920]  и, конечно, неравенство нарушается
[22:38.920 --> 22:40.920]  вот
[22:40.920 --> 22:42.920]  значит, тогда есть очень простой алгоритм
[22:42.920 --> 22:44.920]  приближения с точностью 2
[22:56.920 --> 22:58.920]  значит, алгоритм приближения с точностью 2
[23:08.920 --> 23:10.920]  вот
[23:10.920 --> 23:12.920]  но я не хочу в подробности вдаваться
[23:12.920 --> 23:14.920]  на идеи, там следующее
[23:14.920 --> 23:16.920]  вначале нужно
[23:22.920 --> 23:24.920]  вначале нужно найти
[23:24.920 --> 23:26.920]  минимально остовное дерево
[23:28.920 --> 23:30.920]  и для этого есть специальный алгоритм
[23:30.920 --> 23:32.920]  я знаю, вы это изучали
[23:32.920 --> 23:34.920]  там есть, я не знаю
[23:34.920 --> 23:36.920]  там есть, я не знаю
[23:36.920 --> 23:38.920]  вы это изучали
[23:38.920 --> 23:40.920]  там алгоритм
[23:40.920 --> 23:42.920]  что еще раз?
[23:42.920 --> 23:44.920]  ну там разное есть
[23:52.920 --> 23:54.920]  сейчас
[23:54.920 --> 23:56.920]  мне кажется, вы что-то другое хотите рассказать
[23:56.920 --> 23:58.920]  чем-то, что я хочу рассказать
[24:00.920 --> 24:02.920]  да
[24:02.920 --> 24:04.920]  да, это правильная фамилия
[24:06.920 --> 24:08.920]  сейчас
[24:08.920 --> 24:10.920]  вы хотите сразу для цикла
[24:10.920 --> 24:12.920]  или для остованного дерева сначала?
[24:12.920 --> 24:14.920]  а, ну хорошо
[24:16.920 --> 24:18.920]  да, в общем
[24:18.920 --> 24:20.920]  они есть разные
[24:20.920 --> 24:22.920]  а, вы прямо вот это рассказывали
[24:26.920 --> 24:28.920]  а, на натуральном курсе
[24:28.920 --> 24:30.920]  хорошо
[24:30.920 --> 24:32.920]  да, в общем
[24:32.920 --> 24:34.920]  есть разные
[24:34.920 --> 24:36.920]  да, например
[24:36.920 --> 24:38.920]  можно найти остовное дерево
[24:38.920 --> 24:40.920]  и потом его обойти
[24:40.920 --> 24:42.920]  два раза
[24:42.920 --> 24:44.920]  и потом еще сократить
[24:48.920 --> 24:50.920]  например
[24:58.920 --> 25:00.920]  найти остовное дерево
[25:04.920 --> 25:06.920]  и
[25:06.920 --> 25:08.920]  обойти
[25:14.920 --> 25:16.920]  и ребра
[25:16.920 --> 25:18.920]  дважды
[25:20.920 --> 25:22.920]  ну если это потом сократить
[25:22.920 --> 25:24.920]  да
[25:24.920 --> 25:26.920]  ну я обгадал, когда у нас есть не раз треугольник
[25:26.920 --> 25:28.920]  то вместо того, чтобы идти в вершину потом
[25:28.920 --> 25:30.920]  следующую можно прямую пройти
[25:30.920 --> 25:32.920]  и это будет уменьшение
[25:32.920 --> 25:34.920]  по крайней мере
[25:34.920 --> 25:36.920]  значит
[25:36.920 --> 25:38.920]  потом сократить
[25:40.920 --> 25:42.920]  путь
[25:44.920 --> 25:46.920]  вот, значит на самом деле
[25:46.920 --> 25:48.920]  есть даже
[25:48.920 --> 25:50.920]  алгрит с точностью
[25:50.920 --> 25:52.920]  3 вторых
[25:52.920 --> 25:54.920]  как недавно выяснилось
[25:54.920 --> 25:56.920]  значит этот алгоритм
[25:56.920 --> 25:58.920]  десятки лет
[25:58.920 --> 26:00.920]  назывался алгоритм Кристофидоса
[26:00.920 --> 26:02.920]  вот, а потом оказалось, что
[26:02.920 --> 26:04.920]  независимо от Кристофидоса
[26:04.920 --> 26:06.920]  в Новосибирске
[26:06.920 --> 26:08.920]  математик Сердюков тоже его придумал
[26:08.920 --> 26:10.920]  и опубликовал там
[26:10.920 --> 26:12.920]  в какой-то локальном издании
[26:12.920 --> 26:14.920]  вот, а потом
[26:14.920 --> 26:16.920]  в Новосибирске
[26:16.920 --> 26:18.920]  вот, а потом
[26:18.920 --> 26:20.920]  в Новосибирске
[26:20.920 --> 26:22.920]  в каком-то локальном издании
[26:22.920 --> 26:24.920]  вот, так что
[26:24.920 --> 26:26.920]  и это в общем признано
[26:32.920 --> 26:34.920]  признано сообществом
[26:34.920 --> 26:36.920]  так что теперь этот алгоритм
[26:36.920 --> 26:38.920]  называется
[26:38.920 --> 26:40.920]  алгоритм Кристофида Сердюкова
[26:42.920 --> 26:44.920]  вот
[26:50.920 --> 26:52.920]  значит
[26:52.920 --> 26:54.920]  так же там
[26:54.920 --> 26:56.920]  есть какое-то недавнее
[26:56.920 --> 26:58.920]  достижение
[26:58.920 --> 27:00.920]  где
[27:00.920 --> 27:02.920]  вероятностный алгоритм
[27:02.920 --> 27:04.920]  и там получается
[27:04.920 --> 27:06.920]  3 вторых минус эпсилон
[27:06.920 --> 27:08.920]  для очень-очень маленького эпсилона
[27:08.920 --> 27:10.920]  вот,
[27:10.920 --> 27:12.920]  реально очень маленького
[27:12.920 --> 27:14.920]  10 минус 30
[27:14.920 --> 27:16.920]  или что-то такое
[27:16.920 --> 27:18.920]  в таком духе
[27:18.920 --> 27:20.920]  это театрическое достижение
[27:20.920 --> 27:22.920]  вот, но с другой стороны
[27:22.920 --> 27:24.920]  с другой стороны
[27:24.920 --> 27:26.920]  именно
[27:26.920 --> 27:28.920]  ограничение с другой стороны
[27:28.920 --> 27:30.920]  что с точностью вот такой вот
[27:30.920 --> 27:32.920]  122-121
[27:32.920 --> 27:34.920]  значит
[27:34.920 --> 27:36.920]  это будет НВ трудно
[27:42.920 --> 27:44.920]  вот, но вот
[27:44.920 --> 27:46.920]  между этими величинами
[27:46.920 --> 27:48.920]  разрыв происходит
[27:48.920 --> 27:50.920]  то есть вот это 122-121
[27:50.920 --> 27:52.920]  она тоже увеличилась
[27:52.920 --> 27:54.920]  ну в смысле наоборот
[27:54.920 --> 27:56.920]  дробь увеличилась
[27:56.920 --> 27:58.920]  а числа уменьшались
[27:58.920 --> 28:00.920]  там было сначала
[28:00.920 --> 28:02.920]  200 с чем-то
[28:02.920 --> 28:04.920]  потом там 180
[28:04.920 --> 28:06.920]  но здесь вот имеется разрыв
[28:08.920 --> 28:10.920]  и вот это на самом деле
[28:10.920 --> 28:12.920]  довольно типичная ситуация
[28:12.920 --> 28:14.920]  бывает так, что разрыва нету
[28:14.920 --> 28:16.920]  вот как для 7-8
[28:16.920 --> 28:18.920]  для Max-3SAT
[28:18.920 --> 28:20.920]  там 7-8 есть
[28:20.920 --> 28:22.920]  алгоритм, а 7-8
[28:22.920 --> 28:24.920]  плюс эпсилон ЖНП трудно
[28:24.920 --> 28:26.920]  вот, либо может быть
[28:26.920 --> 28:28.920]  разрыв, либо вообще может быть
[28:28.920 --> 28:30.920]  только с одной стороны что-нибудь
[28:30.920 --> 28:32.920]  так, ну надо сейчас дать прерыв
[28:32.920 --> 28:34.920]  сделаем потом поговорим
[28:34.920 --> 28:36.920]  что-то еще бывает
[28:36.920 --> 28:38.920]  может еще пара задач обсудим
[28:38.920 --> 28:40.920]  так, я еще хочу немножко
[28:40.920 --> 28:42.920]  про задачку
[28:42.920 --> 28:44.920]  Комиевоежора
[28:44.920 --> 28:46.920]  забыл сказать одну вещь
[28:48.920 --> 28:50.920]  есть еще и частный случай
[28:50.920 --> 28:52.920]  метрической задачи Комиевоежора
[28:52.920 --> 28:54.920]  это Евклидова задача Комиевоежора
[29:02.920 --> 29:04.920]  Евклидова задача
[29:04.920 --> 29:06.920]  Комиевоежора
[29:06.920 --> 29:08.920]  значит Евклидова означает
[29:08.920 --> 29:10.920]  что все веса это просто расстояние
[29:10.920 --> 29:12.920]  в Евклидовом пространстве
[29:12.920 --> 29:14.920]  в каком-то может быть многомерном
[29:14.920 --> 29:16.920]  может быть прям на плоскости
[29:16.920 --> 29:18.920]  что собственно всей представляет
[29:18.920 --> 29:20.920]  глядя на географическую карту
[29:20.920 --> 29:22.920]  да, то есть тут
[29:22.920 --> 29:24.920]  W ежито
[29:24.920 --> 29:26.920]  это просто какое-то расстояние
[29:26.920 --> 29:28.920]  от точек там и к слиту
[29:28.920 --> 29:30.920]  и к сжито
[29:30.920 --> 29:32.920]  вот, так вот в этом случае
[29:32.920 --> 29:34.920]  все равно сдача НП трудная
[29:34.920 --> 29:36.920]  точная оптимизация
[29:36.920 --> 29:38.920]  да, значит тут соответственно
[29:44.920 --> 29:46.920]  точная задача все равно
[29:46.920 --> 29:48.920]  НП трудная
[29:50.920 --> 29:52.920]  но при этом для любого Эпсилона
[29:54.920 --> 29:56.920]  для любого Эпсилона 1 минус Эпсилон
[29:56.920 --> 29:58.920]  приближения
[30:00.920 --> 30:02.920]  уже Пальномиальная задача
[30:02.920 --> 30:04.920]  но при этом Пальномиальная
[30:04.920 --> 30:06.920]  она будет
[30:06.920 --> 30:08.920]  от размера матрицы
[30:08.920 --> 30:10.920]  то есть от N
[30:10.920 --> 30:12.920]  но не от Эпсилон
[30:12.920 --> 30:14.920]  то есть тут
[30:16.920 --> 30:18.920]  Пальномиальная от N
[30:18.920 --> 30:20.920]  и экспоненциальная
[30:20.920 --> 30:22.920]  от 1 дель на Эпсилон
[30:24.920 --> 30:26.920]  то есть если Эпсилон фиксирована
[30:26.920 --> 30:28.920]  то тогда это Паленом от N
[30:28.920 --> 30:30.920]  но если у нас и Эпсилон
[30:30.920 --> 30:32.920]  тоже стремится к нулю
[30:32.920 --> 30:34.920]  даже как там 1Н
[30:34.920 --> 30:36.920]  то все равно
[30:36.920 --> 30:38.920]  это будет экспонента в итоге
[30:38.920 --> 30:40.920]  но если Эпсилон стремится к нулю
[30:40.920 --> 30:42.920]  как 1 дель на логариф МН например
[30:42.920 --> 30:44.920]  то это будет
[30:44.920 --> 30:46.920]  Паленомиальная задача
[30:48.920 --> 30:50.920]  в общем для таких случаев
[30:50.920 --> 30:52.920]  используют аббревиатуру ПТАС
[30:56.920 --> 30:58.920]  ПТАС означает
[30:58.920 --> 31:00.920]  Полиномиал тайм апроксимейшн с ким
[31:02.920 --> 31:04.920]  то есть схема апроксимации
[31:04.920 --> 31:06.920]  за полиномиальное время
[31:10.920 --> 31:12.920]  ну вот
[31:12.920 --> 31:14.920]  Евкриза. комовые жоры
[31:14.920 --> 31:16.920]  один из известных примеров
[31:16.920 --> 31:18.920]  такой ситуации
[31:18.920 --> 31:20.920]  бывает еще
[31:20.920 --> 31:22.920]  FПТАС
[31:22.920 --> 31:24.920]  FПТАС
[31:24.920 --> 31:26.920]  это если бы
[31:26.920 --> 31:28.920]  от 1 Эпсилона
[31:28.920 --> 31:30.920]  было бы не экспонента
[31:30.920 --> 31:32.920]  а полином
[31:32.920 --> 31:34.920]  но такое уж совсем редко встречается
[31:36.920 --> 31:38.920]  хорошо
[31:38.920 --> 31:40.920]  теперь я хочу поговорить
[31:40.920 --> 31:42.920]  про разные задачи
[31:44.920 --> 31:46.920]  в частности про задачу
[31:46.920 --> 31:48.920]  МАКС-3САТ
[31:52.920 --> 31:54.920]  задача МАКС-3САТ заключается в том
[31:54.920 --> 31:56.920]  что на 3 КНФ
[31:56.920 --> 31:58.920]  и нужно максимизировать
[31:58.920 --> 32:00.920]  число истинных скобок
[32:08.920 --> 32:10.920]  нужно
[32:10.920 --> 32:12.920]  максимизировать
[32:12.920 --> 32:14.920]  число истинных скобок
[32:18.920 --> 32:20.920]  при этом
[32:20.920 --> 32:22.920]  3 тут реально 3
[32:22.920 --> 32:24.920]  в каждой скобке ровно 3 литерала
[32:30.920 --> 32:32.920]  ровно 3 литерала
[32:34.920 --> 32:36.920]  в каждой скобке
[32:46.920 --> 32:48.920]  тогда как вы изучали
[32:48.920 --> 32:50.920]  на семинарах
[32:50.920 --> 32:52.920]  есть полиномиальный метод решения
[32:56.920 --> 32:58.920]  можно решить
[33:00.920 --> 33:02.920]  за полиномиальное время
[33:06.920 --> 33:08.920]  с точностью
[33:08.920 --> 33:10.920]  7 восьмых
[33:20.920 --> 33:22.920]  7 восьмых плюс Эпсилон
[33:24.920 --> 33:26.920]  это называется PCP теорема
[33:34.920 --> 33:36.920]  с точностью
[33:36.920 --> 33:38.920]  7 восьмых плюс Эпсилон
[33:38.920 --> 33:40.920]  это будет NP трудно
[33:42.920 --> 33:44.920]  эта теорема
[33:44.920 --> 33:46.920]  реально сложная
[33:46.920 --> 33:48.920]  даже если тут не для 7 восьмых плюс Эпсилона
[33:48.920 --> 33:50.920]  а просто для какого-то
[33:52.920 --> 33:54.920]  множество
[33:56.920 --> 33:58.920]  то
[33:58.920 --> 34:00.920]  все равно это дело
[34:00.920 --> 34:02.920]  много лекций
[34:02.920 --> 34:04.920]  нужно изучить некоторую технику
[34:04.920 --> 34:06.920]  под названием техника экспандеров
[34:08.920 --> 34:10.920]  и даже с этой техникой
[34:10.920 --> 34:12.920]  много нужно повозиться
[34:14.920 --> 34:16.920]  я иногда читаю спецкурс
[34:18.920 --> 34:20.920]  семестр доказывает теорему
[34:20.920 --> 34:22.920]  изучая попутно
[34:22.920 --> 34:24.920]  все что для него нужно
[34:24.920 --> 34:26.920]  а вторую половину
[34:26.920 --> 34:28.920]  и еще всякие другие
[34:32.920 --> 34:34.920]  приложения, уточнения
[34:38.920 --> 34:40.920]  почему PCP?
[34:40.920 --> 34:42.920]  и это само по себе очень интересно
[34:42.920 --> 34:44.920]  PCP означает
[34:44.920 --> 34:46.920]  какие-то совершенно не связанные
[34:46.920 --> 34:48.920]  с этим слова
[34:48.920 --> 34:50.920]  а именно PCP это
[34:50.920 --> 34:52.920]  probabilisticly checkable proofs
[34:52.920 --> 34:54.920]  то есть вероятностно проверяемые доказательства
[34:56.920 --> 34:58.920]  там нет ни слова про
[34:58.920 --> 35:00.920]  проксимацию, про NP полноту
[35:00.920 --> 35:02.920]  какие-то вероятностно проверяемые доказательства
[35:04.920 --> 35:06.920]  и то, что это про одно и то же
[35:06.920 --> 35:08.920]  это само по себе
[35:08.920 --> 35:10.920]  некоторое интересное достижение
[35:16.920 --> 35:18.920]  в общем
[35:18.920 --> 35:20.920]  про это я сейчас не буду говорить
[35:20.920 --> 35:22.920]  подробнее
[35:24.920 --> 35:26.920]  а вот про что скажу
[35:26.920 --> 35:28.920]  это про связь, вот это приближение
[35:28.920 --> 35:30.920]  7 восьмых плюс эпсилом
[35:30.920 --> 35:32.920]  с другими задачами
[35:36.920 --> 35:38.920]  связь
[35:46.920 --> 35:48.920]  связь Max3SAT
[35:48.920 --> 35:50.920]  с другими
[35:52.920 --> 35:54.920]  задачами
[35:54.920 --> 35:56.920]  так, ну и план у меня такой
[35:56.920 --> 35:58.920]  что я сначала поговорю
[36:02.920 --> 36:04.920]  про вершинное покрытие
[36:06.920 --> 36:08.920]  значит
[36:08.920 --> 36:10.920]  minimum vertex cover
[36:10.920 --> 36:12.920]  вот
[36:14.920 --> 36:16.920]  а потом
[36:16.920 --> 36:18.920]  проговорю про максимум
[36:18.920 --> 36:20.920]  максимально независимое множество
[36:22.920 --> 36:24.920]  maximum independent set
[36:24.920 --> 36:26.920]  вот
[36:26.920 --> 36:28.920]  и оказывается, что в случае
[36:28.920 --> 36:30.920]  с вершинным покрытием там тоже есть
[36:30.920 --> 36:32.920]  некоторое другое пороговое значение
[36:32.920 --> 36:34.920]  которое точно так же
[36:34.920 --> 36:36.920]  разделяет
[36:36.920 --> 36:38.920]  вот
[36:38.920 --> 36:40.920]  а в случае
[36:42.920 --> 36:44.920]  а точнее
[36:44.920 --> 36:46.920]  нет сейчас
[36:46.920 --> 36:48.920]  это я немножко преувеличиваю
[36:48.920 --> 36:50.920]  потому что
[36:50.920 --> 36:52.920]  тут
[36:52.920 --> 36:54.920]  как бы вот это вот
[36:54.920 --> 36:56.920]  7 восьмых плюс эпсил
[36:56.920 --> 36:58.920]  я переведу в некоторое другое значение
[36:58.920 --> 37:00.920]  но вот этот алгоритм, который 7 восьмых
[37:00.920 --> 37:02.920]  он не перейдет в алгоритм
[37:02.920 --> 37:04.920]  с такой же точностью
[37:04.920 --> 37:06.920]  там есть разрыв такой же
[37:06.920 --> 37:08.920]  как для метрического комевого эжора
[37:08.920 --> 37:10.920]  хотя и поменьше
[37:10.920 --> 37:12.920]  ну а максимум independent set
[37:12.920 --> 37:14.920]  получится, что на самом деле
[37:14.920 --> 37:16.920]  ни с какой точностью не будет аппроксимации
[37:20.920 --> 37:22.920]  то есть вот это будет NP трудно
[37:24.920 --> 37:26.920]  при достаточно
[37:26.920 --> 37:28.920]  хорошей точности
[37:28.920 --> 37:30.920]  вот
[37:30.920 --> 37:32.920]  а это водит NP трудно
[37:34.920 --> 37:36.920]  при любой точности
[37:40.920 --> 37:42.920]  вот
[37:42.920 --> 37:44.920]  ну и в некотором смысле
[37:44.920 --> 37:46.920]  вообще вся эта область
[37:46.920 --> 37:48.920]  теории она повторяет
[37:48.920 --> 37:50.920]  просто теория NP полноты
[37:52.920 --> 37:54.920]  но тут
[37:54.920 --> 37:56.920]  сводимости разрабатывают с таким расчетом
[37:56.920 --> 37:58.920]  чтобы они сохраняли и
[37:58.920 --> 38:00.920]  разрыв в приближении
[38:00.920 --> 38:02.920]  то есть чтоб не только
[38:02.920 --> 38:04.920]  точное решение одной задачи
[38:04.920 --> 38:06.920]  превращалось в точное решение в другое
[38:06.920 --> 38:08.920]  но и приближенное превращалось в приближенное
[38:08.920 --> 38:10.920]  может быть и другим множителем
[38:10.920 --> 38:12.920]  вот
[38:12.920 --> 38:14.920]  и в зависимости от того
[38:14.920 --> 38:16.920]  насколько это можно
[38:16.920 --> 38:18.920]  превратить
[38:18.920 --> 38:20.920]  насколько этот разрыв
[38:20.920 --> 38:22.920]  сохраняется при переходе
[38:22.920 --> 38:24.920]  на ту или иную сводимость
[38:24.920 --> 38:28.920]  мы будем получать разные результаты для разных задач.
[38:28.920 --> 38:32.920]  Так, ну хорошо.
[38:32.920 --> 38:36.920]  Значит, минимум vertex cover.
[38:36.920 --> 38:40.920]  Минимальное вершинное покрытие потребует некоторой
[38:40.920 --> 38:44.920]  специальной свадимости. Значит,
[38:44.920 --> 38:48.920]  не такой, как мы изучали раньше.
[38:54.920 --> 38:58.920]  Ну,
[38:58.920 --> 39:02.920]  ну,
[39:02.920 --> 39:06.920]  ну,
[39:06.920 --> 39:10.920]  ну,
[39:10.920 --> 39:14.920]  ну,
[39:14.920 --> 39:18.920]  ну,
[39:18.920 --> 39:22.920]  ну,
[39:22.920 --> 39:26.920]  ну,
[39:26.920 --> 39:30.920]  ну,
[39:30.920 --> 39:34.920]  ну,
[39:34.920 --> 39:48.280]  будет следующее, первое для мини-вертых скавор, значит
[39:48.280 --> 40:05.280]  тут n переменных m скобок превратится в 7m вершин.
[40:05.280 --> 40:09.320]  Ну а ребер уж сколько получится, а вот n не влияет на, но n повлияет
[40:09.320 --> 40:12.280]  на число ребер косвенно, но точно так же, как и в то
[40:12.280 --> 40:13.280]  какие скобки.
[40:13.280 --> 40:17.280]  Вот так что число ребер там не фиксировано уж какое
[40:17.280 --> 40:18.280]  получится.
[40:18.280 --> 40:25.280]  Вот, значит смотрите, у нас с каждой скобкой вязано
[40:25.280 --> 40:28.280]  7 значений, при которых она истинна, то есть скобка
[40:28.280 --> 40:33.280]  это 1,2,3, там 3 аргумента, 8 возможных наборов значений,
[40:33.280 --> 40:36.280]  из них для одного будет 0, а для семи остальных будет
[40:36.280 --> 40:46.280]  0, то есть например, значит p или не q или r, значит нам
[40:46.280 --> 40:54.280]  даст значение так 0,0,0, и это же будут вершины, почему
[40:54.280 --> 40:57.280]  7m, потому что 7 это число выполняющих наборов в одной
[40:57.280 --> 40:58.280]  скобке.
[40:58.280 --> 41:08.280]  Так, 0,0,0,0,1, дальше 0,1,0 как раз пропускается, потому
[41:08.280 --> 41:23.280]  что 0,1,0 даст 3,0, значит 0,1,1, и дальше значит 1,0,0, 1,0,1,1,1,1,1.
[41:23.280 --> 41:33.280]  Вот, и они все друг с другом соединены, да, значит я тут
[41:33.280 --> 41:37.280]  уж не буду прям клик рисовать, ну там какое-то количество
[41:37.280 --> 41:46.280]  проведу, да, значит это клик.
[41:46.280 --> 41:55.280]  Вот, и так для каждой скобки, то есть например тут будет
[41:55.280 --> 42:03.280]  какая-нибудь другая, скажем не p или r или не s, да, значит
[42:03.280 --> 42:10.280]  тут соответственно будет все кроме 1,0,1, то есть тут
[42:10.280 --> 42:24.280]  0,0,0,0, 0,1,0, 0,1,0, 0,1,0, 0,1,0, дальше 1,0,1 пропускается,
[42:24.280 --> 42:34.280]  потому что даёт 3,0 здесь и соответственно 1,1,0, и
[42:34.280 --> 42:46.080]  соответственно тут тоже тоже клика вот а теперь ну и так для каждой
[42:46.080 --> 42:53.640]  скупки я уж не буду больше рисовать значит важно какие скупки мы друг другу
[42:53.640 --> 42:59.560]  соединяем значит соединяем мы те которые противоречат друг другу
[42:59.560 --> 43:07.440]  да значит например вот это вот мы соединяем вот с этим да значит потому
[43:07.440 --> 43:12.160]  что здесь да значит смотрите тут цифр который здесь написано значение
[43:12.160 --> 43:16.560]  переменных не значение литералов на то есть вот тут вот сказано что п равно
[43:16.560 --> 43:26.640]  нулю а тут вот здесь вот сказано что п равно 1 и соответственно если значение
[43:26.640 --> 43:37.520]  в двух наборах противоречит друг другу то это мы соединяем ребром вот или
[43:37.520 --> 43:47.720]  например значит например вот это вот вот это мы тоже соединяем вот с этим но
[43:47.720 --> 43:54.840]  не за п да п и там и там равно единица а противоречие возникает в эр значит
[43:54.840 --> 44:00.840]  здесь вот и р тут на третьем месте поэтому тут р равно единице а тут р на
[44:00.840 --> 44:11.200]  втором месте тут р равно нулю ну и так соответственно все пары которых
[44:11.200 --> 44:17.200]  противоречащие друг другу значению одной переменной мы соединяем ребром вот
[44:17.280 --> 44:20.280]  но вот такой граф получается
[44:23.800 --> 44:30.600]  может быть конечно и два противоречия сразу вот у этого с этим сразу два
[44:30.600 --> 44:34.180]  противоречия значит тут п равно единицы и р равно
[44:34.180 --> 44:41.040]  единица вот а тут п равно нулю и р равно нулю
[44:42.600 --> 44:45.600]  вот
[44:48.200 --> 44:58.520]  вот так устроим граф начинает думать с понятием теперь вопрос
[44:58.520 --> 45:05.920]  что тут с вершинным покрытием но утверждает что формула сначала давайте без
[45:05.920 --> 45:13.880]  приближения просто вообще свадебность значит формул выполнимо
[45:14.880 --> 45:27.720]  форму выполнимо тогда я только тогда когда в графе есть вершинные покрытия
[45:30.720 --> 45:35.720]  из 6 им вершин
[45:35.720 --> 45:49.960]  значит всего 7 вершин а покрытие 6 им вершин значит почему ну одну сторону
[45:49.960 --> 45:57.920]  пусть порно выполнимо тогда есть выполняющий набор тогда что мы сделаем
[45:57.920 --> 46:04.680]  значит у этого выполняющего набора есть соответствующий ему вершина в каждой
[46:04.680 --> 46:09.960]  вот такой вот клике что выполняющий набор значение каждой переменной вообще
[46:09.960 --> 46:15.440]  а мы для трех из данной скобки выбираем фрагмент этого
[46:15.440 --> 46:23.000]  выполняющего набора и все остальные 6 вершин мы включим вершины покрытия тогда
[46:23.000 --> 46:27.240]  что получится получится что внутри клик мы все ребра покрыли потому что мы 6
[46:27.240 --> 46:31.320]  из 7 вершин взяли если с каждой у каждого ребра хотя бы один конец
[46:31.320 --> 46:40.000]  попал вот а вот такие вот ребра между кликами не покрытыми остаться быть не
[46:40.000 --> 46:44.480]  могут потому что они друг другу противоречат значение какой-то
[46:44.480 --> 46:48.600]  переменной а то чтобы не покрыли совпадает друг другом по значению
[46:48.600 --> 46:52.720]  переменной потому что мы взяли фрагменты домой того же выполняющего
[46:52.720 --> 46:56.920]  набора вот поэтому и все ребра внутри клик
[46:56.920 --> 47:04.840]  покрыто и между кликами тоже покрыто получается вершинное покрытие вот ну
[47:04.840 --> 47:13.520]  значит это поэтому получается свадимость у нас ангель тоже самое то же самое
[47:13.520 --> 47:19.320]  рассуждение можно обобщить на апроксимацию
[47:56.920 --> 48:12.120]  да а подождите я только одну сторону доказал да я только сверху вниз
[48:12.120 --> 48:16.240]  доказал но снизу я что же получается потому что смотрите в каждой клике нужно
[48:16.240 --> 48:22.200]  хотя бы 6 вершин взять иначе там будет 5 из 7 две не покрытое нам между ними
[48:22.200 --> 48:27.080]  ребра не покрыто поэтому если у меня ровно 6 тем вершин значит ровно по 6
[48:27.080 --> 48:32.480]  каждой клике вот ну а тогда оставшиеся не покрытыми должны быть согласованы
[48:32.480 --> 48:39.640]  друг с другом иначе скажем если вот это не покрыто и вот это не покрыто да то
[48:39.640 --> 48:50.720]  вот между ними ребра не покрытое вот а раз они да значит ну вот значит если и
[48:50.720 --> 48:55.120]  не согласованы друг с другом не покрытое то это не вершинное покрытие
[48:55.120 --> 48:58.800]  вот значит они должны быть согласованы друг с другом то есть у каждой переменной
[48:58.800 --> 49:03.800]  ровно одно значение во всех непокрытых и можно его взять как выполняющий набор
[49:03.800 --> 49:09.440]  и это действительно будет полнейший набор потому что ну как бы все все вот
[49:09.440 --> 49:18.800]  эти 7 фрагментов выполняющие для скобки вот не выполняющим и заранее
[49:18.800 --> 49:28.520]  исключили вот так ничего понятно ну вот хорошо значит все-таки туда и туда и
[49:28.520 --> 49:37.120]  обратно посуждение выполнено вот а для приближения получается так что в
[49:37.280 --> 49:54.520]  значит формуля значит формуля выполнима значит доля скобок доля скобок больше
[49:54.520 --> 50:06.400]  либо равно чем ров вот это будет равносильно тому что у графа у графа есть
[50:06.400 --> 50:10.960]  вершинное покрытие
[50:10.960 --> 50:22.320]  размера меньше либо равно чем 7 минус р умножить на им
[50:22.320 --> 50:28.560]  то что мы уже доказали частный случай для ров равно единице
[50:28.560 --> 50:35.040]  вот почему же это в общем случае выполняется
[50:43.040 --> 50:50.520]  ну потому что смотрите но пусть пусть выполним вот опять же сверху не сначала пусть выполним
[50:50.520 --> 50:56.640]  вот такая доля скобок но мы возьмем в плаще на возьмем набор при котором выполнена такая
[50:56.720 --> 51:03.000]  доля скобок и тогда для тех скобок которые выполнены мы как раз возьмем 6 вершин все
[51:03.000 --> 51:07.440]  кроме той 3 которые соответствуют фрагменту этого набора а для тех где которые не
[51:07.440 --> 51:17.280]  выполнено просто все 7 возьмем вот ну и тогда получится что в случае рома взяли да значит
[51:17.360 --> 51:18.880]  получится что ровно жить на
[51:18.880 --> 51:30.960]  рон аэм да значит рон аэм число скобок и умножить на 6 не плюс 1 минус ро на им
[51:30.960 --> 51:44.720]  на 7 вот это раз и будет 7 минус рон аэм 7 минус рон аэм вот
[51:44.720 --> 51:56.400]  и это будет по тем же самым причинам что и раньше это будет вершины покрытия на то что
[51:56.400 --> 52:02.280]  все где 7 они там вообще все покрыто а у тех где 6 не покрыты не могут соединить
[52:02.280 --> 52:06.960]  ребра между собой так как они друг другу согласованы вот ну и другую сторону тоже
[52:06.960 --> 52:13.040]  примерно также да опять же 5 вершин из клики у нас не может быть то есть если вот такое
[52:13.040 --> 52:21.680]  число вершин взято то значит как раз 6 будет 6 вершин из вот такого числа клик и 7 вершин
[52:21.680 --> 52:28.460]  из всех остальных и вот эти вот не покрытые вершины друг другу согласованы не дадут
[52:28.460 --> 52:35.200]  набор при котором как раз все скобки которым соответствуют вот эти клики будут выполнены
[52:35.200 --> 52:42.800]  вот и что же в итоге значит в итоге разрыв ро
[52:42.800 --> 53:11.920]  значит разрыв между ро и единицей превращается в разрыв между 6 и 7 минус ро да и можно сократить
[53:11.920 --> 53:23.560]  вот но получается например если если ро у нас 7 восьмых то тогда тут получается
[53:23.560 --> 53:34.360]  есть и есть и одна восьмая да это у нас 49 48 получается да
[53:34.360 --> 54:01.600]  ой не сейчас не сорок восьмых сейчас нет чуть-чуть 49 восьмых 6 49 восьмых то есть
[54:01.600 --> 54:10.160]  вот это вот как бы если мы еще на 6 поделим на то множество получается 49 48 собственно
[54:10.160 --> 54:15.680]  вот видите вот тут было там 122 121 это вот не случайно не так это на самом
[54:15.760 --> 54:21.880]  121 получалось зазор вот а вот здесь зазор одна сорок одна сорок восьмая получается
[54:27.880 --> 54:38.720]  значит зазор это смотрите тут одна восьмая тут одна сорок восьмая это как бы какую часть на
[54:38.720 --> 54:47.320]  какую часть от вот этого будет больше вот это да то есть мы фактически 49 восьмых еще на 6
[54:47.320 --> 54:58.360]  поделили значит получили 49 48 вот а зазор получается одна сорок восьмая но то есть
[54:58.360 --> 55:04.720]  больше получается что-то больше и точностью будет np трудно приблизить задачу о вершинном покрытии
[55:04.720 --> 55:16.280]  потому что если приблизили с большей точностью то тогда получится что мы с точностью больше
[55:16.280 --> 55:23.240]  чем 7 восьмых решили задачу макстриса то это невозможно попись пятиоремии если только пони равно np
[55:35.720 --> 55:43.960]  ну вот хорошо значит и теперь последние 10 минут немножко я поговорю про максимально
[55:43.960 --> 55:55.920]  независимое множество значит я напомню что дополнение вершинного покрытия независимое множество
[55:55.920 --> 56:15.200]  дополнение вершинного покрытия это независимое множество соответственно
[56:15.200 --> 56:23.960]  ну как бы автоматически из предыдущих конструкций получается тоже разрыв причем как бы назад все
[56:23.960 --> 56:33.800]  переворачивается и снова те же самые 7 восьмых получается из предыдущей из предыдущей конструкции
[56:33.800 --> 56:39.640]  получаем разрыв
[56:39.640 --> 56:55.680]  м и или роем на потому что всего всего 7 м вершин соответственно мы вычитаем либо 6 м либо 7 минус
[56:55.680 --> 57:03.440]  ро на м и обратно получается либо м либо роем то есть то есть единицы или ро снова 7 восьмых
[57:03.440 --> 57:16.280]  вот но после этого можно его увеличить значит можно разрыв
[57:16.280 --> 57:29.400]  нарастить значит а именно это называется возведение графов степень некоторым специальным
[57:29.400 --> 57:40.440]  образом значит из графа g можно перейти в же степень и к значит здесь вершины
[57:40.600 --> 57:53.880]  да что-то это вот же а же это будет ве вершины же в степени к это к элементные
[57:53.880 --> 57:59.560]  к элементные под множество в
[57:59.680 --> 58:08.760]  вот ну и дальше значит
[58:08.760 --> 58:15.640]  пара ст соедина ребром
[58:15.640 --> 58:29.400]  точнее дайте я так напишу она не принадлежит значит не соедина
[58:29.400 --> 58:41.160]  ребром если и осуглеение ст это независимое множество в графе g то есть если есть хоть одно
[58:41.160 --> 58:49.400]  ребро в том числе внутри s то тогда с и т соединены ребром да в частности значит если
[58:49.400 --> 58:54.440]  само себе с не независимое множество то она вообще со всеми соединено ребрами можно в принципе
[58:54.440 --> 59:08.320]  вообще исключить вот а если с и т оба независимая но убедения уже не будут независимы тогда тоже
[59:08.320 --> 59:14.280]  ребро между ним проводится вот дать грубо говоря получается что любое ребро из
[59:14.280 --> 59:20.800]  ст поднимается ну из одной вершины с какую-то вершину т поднимается до либра между с и
[59:20.800 --> 59:27.560]  т и если внутри с внутри ты есть ребра то они тоже поднимаются до с и т есть ничего нет тогда
[59:27.560 --> 59:37.680]  ребра нету вот значит ну ясно что если к фиксировано если к фиксировано то число сочетания
[59:38.160 --> 59:42.280]  пока это полином поэтому сводимость полиномиальная при фиксированном к
[59:42.280 --> 59:47.840]  при
[59:47.840 --> 59:53.880]  при фиксированном ка сводимость
[59:53.880 --> 01:00:05.760]  полиномиальная вот ну а дальше утверждение такое
[01:00:05.760 --> 01:00:31.680]  утверждение что если альфа это число независимости же то тогда число сочетаний из альфа пока это
[01:00:31.680 --> 01:00:36.880]  число независимости же в степени к
[01:00:36.880 --> 01:00:54.160]  но это как раз мы максимально но размер максимально независимого множества вот значит почему это так а
[01:00:55.000 --> 01:01:00.200]  значит если мы докажем то дальше там некоторая выкладка в том что вот если
[01:01:00.200 --> 01:01:14.200]  сейчас в общем выкладка такая что дальше с из ро м пока поделить на цзм пока это будет
[01:01:14.200 --> 01:01:22.960]  иметь порядок рог степени к ну комбинаторное такое утверждение вроде должно быть понятно откуда
[01:01:22.960 --> 01:01:29.280]  оно следует вот и тогда соответственно у нас рог было 7 восьмых а беряка все больше и больше
[01:01:29.280 --> 01:01:38.760]  меток ну любому стремлять вот из чего же следует утверждение но во-первых если в графе же было
[01:01:38.760 --> 01:01:45.240]  независимое множество размера альфа то все его к элементные под множество образуют независимое
[01:01:45.240 --> 01:01:51.640]  множество в же степени к потому что все это объедение будет вложено в независимое множество да и
[01:01:51.640 --> 01:02:00.840]  соответственно ребер не будет вот поэтому отсюда получается нижняя оценка значит нижняя оценка
[01:02:00.840 --> 01:02:09.240]  будет вот такая вот но верно и верхняя оценка значит потому что если будет еще больше множество
[01:02:09.240 --> 01:02:16.200]  к элементных то они все в объединение да может сказать так что есть у меня есть независим множество
[01:02:16.200 --> 01:02:21.800]  вот в этом же степени к то объединив все эти множества я получу независим множество в исходном
[01:02:21.800 --> 01:02:28.920]  графе вот но если их будет больше чем столь кто там точек будет больше чем альфа но тоже такая
[01:02:28.920 --> 01:02:34.120]  комбинаторика значит нужно оценить что но это более-менее более-менее понятно да что если у
[01:02:34.120 --> 01:02:39.040]  меня альфа точек то у меня вот столько к элементных множества есть у меня больше множества мне нужно
[01:02:39.040 --> 01:02:49.120]  больше точек потому что альфа бы не хватило вот и тогда получилось бы больше чем альфа независимое
[01:02:49.120 --> 01:02:57.920]  множество в исходном графе ну вот вот такая вот идея получается что независимое множество
[01:02:57.920 --> 01:03:07.000]  но как следствие клика тоже это вот задача трудно поддающаяся аппроксимации вот что отнюдь не так
[01:03:07.000 --> 01:03:11.280]  очевидно как для комивого ежора где все следует из гамильтонного цикла
[01:03:15.280 --> 01:03:25.840]  вот ну и это действительно так то есть это и на практике сложная задача то есть насколько
[01:03:25.840 --> 01:03:33.080]  я понимаю может быть так что у вас сеть скажем из 10 тысяч вершин и заведомо известно да то есть
[01:03:33.080 --> 01:03:40.160]  как бы одна сторона берет какую-то случайную сеть или там какую-нибудь в общем какую-то сеть из
[01:03:40.160 --> 01:03:49.560]  10 тысяч вершин и туда прям намеренно устраивает клику из 50 вершин вот и предлагается теперь ее
[01:03:49.560 --> 01:03:59.400]  найти вот они получается получается максимум 25 найти задача встроенной клике что известно
[01:03:59.400 --> 01:04:06.640]  что в граф встроена клика ну например можно можно взять например случайный граф там будет
[01:04:06.640 --> 01:04:17.400]  по теореме средняя там клика будет так такого-то размера вот ну не средняя среднем по испытаниям
[01:04:17.400 --> 01:04:23.280]  размер максимальный клики будет такой-то а мы устраиваем сильно больше и пытаемся его найти и
[01:04:23.280 --> 01:04:35.520]  вот мне не получается вот но говорят что это может быть важная задача для спецслужб что находить
[01:04:35.520 --> 01:04:44.920]  да это самое какой-то сети контактов находить скрытые клики которые возможно делать то что не
[01:04:44.920 --> 01:04:52.520]  нравится спецслужбам но вот к счастью ли к сожалению значит это задача трудно решается так что
[01:04:52.520 --> 01:05:02.840]  это не решить не получится вот так ну все значит на этом курс завершается спасибо что слушали
[01:05:02.840 --> 01:05:12.840]  значит получается что у нас остается контрольная и какой-то там чего вопрос
[01:05:15.920 --> 01:05:17.680]  вот
[01:05:17.680 --> 01:05:28.400]  возможно я буду читать спецкурс осенью может быть как раз вот про это вот прописи пе может
[01:05:28.400 --> 01:05:33.320]  нет это выложил канал там уж какой-нибудь опрос буду проводить что хотят слушать граждане
[01:05:33.320 --> 01:05:36.240]  все спасибо
