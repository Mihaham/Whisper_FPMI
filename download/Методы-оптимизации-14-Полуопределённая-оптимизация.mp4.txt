[00:00.000 --> 00:10.360]  все отлично на запись поставлю запись включена теперь давайте начнем наше занятие сегодняшнее и
[00:10.360 --> 00:17.760]  сегодня обсудим полуопределенную оптимизацию так сейчас надо выводить правильный цвет и
[00:17.760 --> 00:31.040]  правильную толщину полуопределенную оптимизация ну это может быть не самый удачный это прекрасно
[00:31.040 --> 00:52.720]  не самый удачный перевод термина семи-дефинит-семи-дефинит-програминг-программинг-проблемс
[00:52.720 --> 01:01.040]  вот то есть как бы их СДП вот то есть у нас были разные конусы и когда у нас был конус положительно
[01:01.040 --> 01:06.800]  полуопределенных матриц то мы называли такие задачи именно полуопределенной оптимизации сегодня
[01:06.800 --> 01:12.240]  мы про них поподробнее поговорим но самое главное пытаемся понять зачем они нужны и какая ну какие
[01:12.240 --> 01:18.760]  они какие приложения существует у подобного рода задачи вот значит ну давайте начнем немножко
[01:18.760 --> 01:23.560]  издалека и скажем откуда вообще их можно вывести что ли как каким образом можно
[01:23.560 --> 01:28.240]  получать подобного рода задачи вот ну вот смотрите у нас было линейное программирование
[01:28.240 --> 01:35.200]  в какой-то момент когда мы минимизировали линейную функцию при условии что у нас было
[01:35.200 --> 01:41.400]  линейное ограничение равенства и условия отрицательности вот и тут у нас был переменным
[01:41.400 --> 01:49.200]  понятное дело что у нас был xzrn вот и мы искали вектор значит теперь если мы переходим от вот
[01:49.200 --> 01:59.000]  этого конуса который у нас rn плюс к точнее неправильно не до стрелочка вот так а rn плюс у нас
[01:59.000 --> 02:05.320]  перейдет в sn плюс то есть конус полосимметричных положительно полуопределенных матриц то что
[02:05.320 --> 02:11.960]  изменится то есть у нас переменная становится матрицей вот и отсюда получается что в этом
[02:11.960 --> 02:17.560]  случае у нас мы минимизируем скалярные произведения по-прежнему а скалярный прием между
[02:17.560 --> 02:26.200]  матрицами это след от их произведения вот это раз второе что происходит это вот вот эта штука
[02:26.200 --> 02:34.440]  ой вот эта штука она переписывается как так что то есть здесь что написано сомнелись
[02:34.440 --> 02:41.560]  написан набор скалярных произведений строк матрицы а на x равный боитому вот опять все
[02:41.560 --> 02:47.520]  свели к скалярным произведениям для того чтобы потом просто заменить скалярное произведение
[02:47.520 --> 02:56.360]  строк матрицы а на x на скалярный произведение между некоторым матрицами аитами умноженными на x
[02:56.360 --> 03:01.520]  и сказать что это равно тем же самому тому же самому числу боитому вот ну и соответственно
[03:01.520 --> 03:06.920]  не отрицательность по элементное которая является коническим ограничением она переписывается
[03:06.920 --> 03:13.760]  просто что у нас x не отрицает на определенные матрицы вот таким образом можно обобщить задачу
[03:13.760 --> 03:17.280]  линейного программирования стандартной то есть вот это вот лп задачи
[03:21.280 --> 03:27.960]  в канонической или стандартной форме вот и из нее мы получаем собственно с дп задачу в
[03:27.960 --> 03:37.000]  я конечно забывать терминологию в стандартной форме да потому что есть еще не совсем стандартный
[03:37.000 --> 03:44.040]  который мы сейчас с вами получим записав двойственную к этой задаче все у нас лежит в
[03:44.040 --> 03:51.600]  сн и все аиты тоже симметричны ну это будет просто-напросто нужно чтобы мы всегда по умолчанию
[03:51.600 --> 03:57.280]  живем в мире симметричных матриц для того чтобы у нас были прекрасные характеристики симметрики
[03:57.280 --> 04:02.920]  прекрасные характеристики определенности связанные со спектром вот понятно ли какие
[04:02.920 --> 04:06.560]  преобразования мы проделали почему-то в общем-то все это более-менее работает
[04:13.680 --> 04:20.480]  так прекрасным теперь давайте поймем каким образом мы можем двойственно получить к этой
[04:20.480 --> 04:28.200]  задаче вот наше любимое занятие это настроение двойственных задач к исходным для того чтобы
[04:28.200 --> 04:36.160]  затем используя прямо двойственные методы которые мы видимо поговорим в следующий раз
[04:36.160 --> 04:41.080]  которые одновременно обновляют и прямые двойственные переменные ну то есть решает
[04:41.080 --> 04:46.880]  одновременно и прямые задачи двойственную получить гарантии в терме зазора двойственности на
[04:46.880 --> 04:53.720]  сходимость вот ну что обычно пишется лагранжан возможно мы это уже какое-то время назад делали
[04:53.720 --> 05:06.960]  вот ну давайте быстро повторим пишем не будет след а и т x минус б и т и минус скалярные произведения
[05:06.960 --> 05:19.440]  лямбада на x вот ну здесь тоже след поэтому мы просто выносим все что связано с x а именно
[05:19.440 --> 05:32.880]  c плюс сумма лямбда и т а и т минус лямбда большое это все умножается на x вот и остаток остается
[05:32.880 --> 05:42.960]  остается только минус ой не равно а минус сумма лямбда и т б и т вот из чего следует что когда
[05:42.960 --> 05:48.600]  мы будем минимизировать это все дело по прямым переменам то есть по иксу по вот этому то у нас
[05:48.600 --> 05:57.040]  останется только вот эта штука вот а вот все вот это вот благополучно благополучно должно быть
[05:57.040 --> 06:05.200]  за нулено за счет убирания вот это вот коэффициенты которые в рамочке находится вот есть наша двойственная
[06:05.200 --> 06:11.800]  задача будет максимизировать отрицательную линейную линейное выражение относительно лямбд вот и
[06:11.800 --> 06:21.560]  потребовать дополнительно чтобы что чтобы ц плюс сумма лямбда и т а и т было бы равно лямбаде и
[06:21.560 --> 06:27.360]  ну и лямбда было бы не отрицать напрямую как нож селила гранжа вот то есть вот такая вот довольно
[06:27.360 --> 06:35.920]  прямолинейная прямолинейная форма будет у двойственной задачи понятно ли что здесь происходило так
[06:35.920 --> 06:43.880]  отлично можно также немножко сказать сравнить просто вот то с чего мы начинали вот это вот
[06:43.880 --> 06:51.640]  все вот это вот сравнить с тем что у нас получилось в случае когда может так типа лп с дп
[06:51.640 --> 07:01.080]  вот здесь у нас допустимое множество это многогранник
[07:01.080 --> 07:11.240]  но гол гранник вот то есть у нас подпространство и мы вырезаем отрицательный актант в этом
[07:11.240 --> 07:16.360]  подпространстве вот здесь допустимое множество что-то странное то есть здесь допустим но что
[07:16.360 --> 07:28.360]  не многогранник вот и оно выражается более сложным некоторым образом так так так так так так так
[07:28.360 --> 07:34.560]  так так все ли я правильно написал бом бом бом больше либо равна нуля
[07:34.560 --> 07:51.920]  ну да двойственная форма правильная да здесь допустим но что некоторые сложно структуру имеет
[07:51.920 --> 08:04.400]  потому что у нас переменами является уже матрица и запись уравнений на их коэффициенты
[08:04.400 --> 08:09.600]  и это что-то ну будет какая-то нелинейная поверхность будет ограничивать наша выпуклая
[08:09.600 --> 08:15.520]  множество скорее всего там будут если так пытаться в 2d на 2d что-то набрасывать то это
[08:15.520 --> 08:20.440]  будут какие-нибудь там типа кривые второго порядка которые будут как-то вот там пересекаться хитрым
[08:20.440 --> 08:28.040]  образом и в результате пересечения образовывается равно некоторое вот такое вот выпуклое множество
[08:28.040 --> 08:33.920]  вот то есть кривые возникнут понятное дело из критерии сельвестр не дорицательной определенности
[08:33.920 --> 08:40.320]  о котором как бы который собственно явным образом и задает нам допустимое допустимое множество так
[08:40.320 --> 08:46.040]  понятно ли почему так получается так хорошо про допустимое множество поговорили теперь следующий
[08:46.040 --> 08:49.960]  пункт нашей программы это двойственность какие результаты про двойственность у нас были
[08:49.960 --> 08:55.240]  в линейном программировании и насколько они прямолинейно переносится на полупределенную
[08:55.240 --> 09:03.760]  оптимизацию здесь у нас так здесь у нас была всегда сильная двойственность
[09:03.760 --> 09:10.440]  потому что условия сеттера всегда выполнялась
[09:10.440 --> 09:18.880]  вот поскольку там было пространство и всегда можно было найти точку который внутри него лежит
[09:18.880 --> 09:30.480]  с положительными собственно коэффициантами здесь не всегда то здесь возможны возможен больше 0
[09:30.480 --> 09:41.880]  давайте так возможен зазор двойственности больше нуля вот то есть ну и мы вроде бы
[09:41.880 --> 09:49.880]  какие-то подобные обсуждали ранее про то что здесь может случиться так что переменная которая
[09:49.880 --> 09:58.280]  будет давать допустимую точку будет ее давать только строго ну только в выраженном виде то есть
[09:58.280 --> 10:03.600]  не найдется ни одного допустимого икса для при котором матрица будет строго положительно
[10:03.600 --> 10:13.400]  определена вот это первый факт возможен так и возможно недостижимость минимума
[10:13.400 --> 10:34.520]  вот то есть можно привести примеры в котором соответственно что произойдет мы будем
[10:34.520 --> 10:40.320]  икс бесконечно нам куда-то устремлять и мы все еще будем допустить множество но тем не менее
[10:40.720 --> 10:49.400]  целевая функция все будет уменьшаться уменьшаться и мы как бы до этого мимикой дойдем вот это тоже
[10:49.400 --> 10:55.240]  некая особенность полу определенно оптимизация так это был собственно первый пункт второй пункт
[10:55.240 --> 11:01.880]  третий пункт алгоритмический для линейного программирования есть условно simplex метод
[11:01.880 --> 11:12.440]  идея которого в том чтобы многогранник в многограннике гулять по вершинам
[11:12.440 --> 11:20.680]  перепрыгивая из вершины вершину так чтобы значение целевая функция уменьшалась вот у
[11:21.560 --> 11:32.400]  простой идеи есть довольно непростая геометрическая геометрической геометрической
[11:32.400 --> 11:36.720]  понятная интерпретация не очень простая гиброрической интерпретации через соответственно
[11:36.720 --> 11:44.160]  элементы задачи то есть через запись матрицы через запись матрицы а и б и вектора ц таким
[11:44.160 --> 11:50.160]  образом это все дело обеспечивается то есть как вот эти вот вершинки связаны с векторами столбца
[11:50.160 --> 11:57.160]  матрица это не очень простая история вот но идея очень простая давайте поэтому пока что на этом
[11:57.160 --> 12:05.000]  остановимся что мы просто переходим из вершины вершину вот и за конечное число шагов гарантированно
[12:05.000 --> 12:13.240]  доходим до до решения вот поскольку вершин конечное число то в худшем случае мы всех
[12:13.240 --> 12:20.320]  просто переберем вот и получим соответственно встретимся так или иначе с решением и это будет
[12:20.320 --> 12:28.800]  наш ответ понятно ли основная идея метода и то почему он будет сходить за конечные шагов так
[12:28.800 --> 12:44.680]  прекрасно к сожалению в так ну тут вот про конечные ну да наверное правильная аргументация то есть
[12:44.680 --> 12:48.840]  есть патологические случаи когда симпелисмерт начинает зацикливаться и гулять по диме тем же
[12:48.840 --> 12:54.960]  вершинам вот но с этим есть есть способы который позволяет с этим пороться диме за конечное число
[12:54.960 --> 13:05.600]  число вот а здесь к сожалению такого нет нет никаких поскольку видите допустим но что более
[13:05.600 --> 13:12.600]  сложное вот то никаких результатов про то что мы должны каких-то там угловых точек пересечения
[13:12.600 --> 13:23.120]  поверхностей которые задают наши границы что-то искать никаких результатов нет вот и поэтому
[13:23.600 --> 13:29.800]  сложно что-то сложно предполучить такую же аналогию с такими же замечательными
[13:29.800 --> 13:35.880]  теортическими гарантиями как это было для для линии на программирование поэтому здесь работают
[13:35.880 --> 13:42.960]  методы внутренней точки интерационные специально это отмечу что это интерационные методы вот
[13:42.960 --> 13:53.320]  которые могут давать решение только с некоторой точностью вот ну и внутренние точки они потому
[13:53.320 --> 14:01.080]  что их идея это не гулять по пограни по граничным точкам ну то есть по точкам которые жанр границ
[14:01.080 --> 14:09.120]  в частности в случае симпелисмерт это были вершины а идти изнутри и куда-то вот у нас какой-то
[14:09.120 --> 14:18.000]  страны множество и мы начинаем с некоторого x 0 и потом постепенно у нас x 1 потом какой-то
[14:18.000 --> 14:24.320]  x 2 потом уж какой-то x 3 и потом мы куда-то там бла бла бла бла приходим ну например сюда
[14:24.320 --> 14:33.840]  везапную x n большое вот почему мы не как каким образом мы гарантируем что мы точно не выйдем
[14:33.840 --> 14:40.320]  из границы множества вот это делать с помощью называемых барьерных функций про которые я
[14:40.320 --> 14:48.480]  возможно поподробнее расскажу в следующий раз вот сейчас только пример раз на им приведу вот
[14:48.480 --> 14:53.040]  это такие функции которые опроксимируют индикаторную функцию множество которым мы
[14:54.040 --> 15:03.840]  про которую хорошо раз говорили плюс бесконечности x не лежит в ц и 0 если x лежит в ц вот барьерные
[15:03.840 --> 15:15.760]  функции короче опроксимируют индикаторную функцию вот поэтому как только но вот и в случае причем
[15:15.760 --> 15:22.720]  опроксимировать так что как только мы находимся то есть давайте то есть рисовать если мы хотим
[15:22.720 --> 15:28.720]  чтобы у нас x был строго больше либо равно нуля вот то наша барьерная функция на типа вот какой-то
[15:28.720 --> 15:36.040]  такой вот вид может иметь например то есть при приближении границы значит при x стремящимся к
[15:36.040 --> 15:44.320]  границе множество наша барьерная функция должна стремиться к плюс бесконечности вот это важно
[15:44.320 --> 15:53.320]  потому что если мы перейдем к задаче минимизации от x плюс б мю от x то вот за счет вот этой штуки
[15:53.320 --> 16:00.000]  у нас x точно будет лежать множество иначе мы получим просто бесконечности понятно ли мотивация
[16:00.000 --> 16:07.520]  построения такого рода объектов так хорошо может быть вы примеры предложите что это за пример
[16:07.520 --> 16:12.480]  таких функций ну например для вот линейного программирования где у нас x больше вернули
[16:12.480 --> 16:19.560]  ограничение можно просто сумму один поделить на x и t так первый вариант годится да действительно
[16:19.560 --> 16:27.080]  есть такая есть такой подход называется 1 на x и t поделить так хорошо это называется там ну как
[16:27.080 --> 16:35.280]  обратная функция не обратно и пербаллический что ли это называется барьер вот хорошо еще
[16:35.280 --> 16:47.000]  наверное можно так еще раз не расслышал второй вариант а мамика динамиком есть
[16:47.000 --> 16:53.760]  наверное можно обобщить и сделать один дилет на x и t в п этой степени где и поэтому давайте
[16:53.760 --> 17:01.560]  я вот тут по и поставлю еще даток можно степень степень подкрутить хорошо еще чем можно сделать
[17:01.560 --> 17:06.680]  ну то есть вот это вот единственное условие тут кстати вот если я просто нарисую графику сразу
[17:06.680 --> 17:12.240]  поймите какой ответ вот поэтому хочется чтобы вы только на основе того чтобы мы хотим вот это бы
[17:12.240 --> 17:19.520]  что-нибудь еще предложили ну для каких функций у нас еще есть условия что они там куда-то стремятся
[17:19.520 --> 17:32.040]  при иксе который там около нуля но может быть я просто может что-нибудь с экспонентой сделать
[17:32.040 --> 17:39.480]  тогда уж если ну минус логариф но минус логариф конечно да все правильно минус логариф вот
[17:39.480 --> 17:47.040]  называется логарифмический барьер и как раз таки логарифмический барьер именно он чаще всего
[17:47.040 --> 17:58.200]  используется на практике вот для собственно для рэн плюс вот ну а для соответственно нашего
[17:58.200 --> 18:08.040]  конуса для сн плюс используется барьер под названием минус логариф терминанта x вот и именно вот
[18:08.040 --> 18:13.800]  эта штука которая мы кажется уже несколько раз ее встречали она нужна именно для этого чтобы
[18:13.800 --> 18:20.840]  предотвратить вылеты множество которая представляет из себя не относительно конус положительно
[18:20.840 --> 18:27.520]  конус симметричных положительных полупрелых матриц вот нет все это рационный процесс будет
[18:27.520 --> 18:34.880]  который будет сходиться к решению там доказывается некоторым некоторым не очень не очень сложно
[18:34.880 --> 18:41.280]  образом возможно все еще раз я как раз таки это все выкутки попытаюсь провести вот и отсюда следует
[18:41.280 --> 18:48.640]  что в отличие от линейного программирования здесь у нас только интерационный метод и только
[18:48.640 --> 18:59.240]  сходимый с некоторым точностью вот так это еще один пункт далее полезные упражнения упражнения
[18:59.240 --> 19:08.680]  это показать что с дп на максимум наиболее общий является наиболее общим конусом по сравнению
[19:08.680 --> 19:15.600]  со всеми полусами которые мы до этого обсуждали то есть лп под множество задач на положить на конус
[19:15.600 --> 19:22.560]  второго порядка и это все под множество с дп задачи вот возможно тоже это уже было когда мы говорили
[19:22.560 --> 19:30.480]  про конус и но сейчас про это очень своевременно вспомнить вот ну теперь несколько приложений
[19:30.480 --> 19:35.760]  все этой технологии вот в частности там примеры давайте
[19:38.360 --> 19:42.240]  пример номер один давайте мы попытаемся минимизировать спектральный радиус
[19:42.240 --> 19:52.840]  вот у чего есть интерпретация с точки зрения энергии потому что грубо говоря если у вас есть так
[19:52.960 --> 19:56.920]  была какая-то физика кстати то еще спор энергии начинает говорить при этом я еще понимаю
[19:56.920 --> 20:02.680]  только школьная у нас в программе физики нет а у вас в программе физики нет все понятно ладно
[20:02.680 --> 20:12.560]  хорошо тогда давайте так ей у нас допустим есть несколько некоторая некоторая динамическая
[20:12.560 --> 20:21.160]  сеть а дефуру у вас были да дефуру были уже хорошо есть некоторая динамическая система которая
[20:21.160 --> 20:26.000]  записывается динамик который записывается официальным уравнением линейным и там еще есть
[20:26.000 --> 20:33.440]  дополнительный контрол управление через вектор у вот то есть мы варьируя вектор у с помощью и
[20:33.440 --> 20:39.240]  преобразовывая матрица б можем как бы влиять на динамику понятно да и надеюсь то есть если бы было
[20:39.240 --> 20:48.200]  если бы было без вот этого у нас была просто там как бы линейная система с понятным свойством
[20:48.200 --> 20:53.600]  сходимости и расходимость зависит от свой сфекта матрица вот а если у нас появляется
[20:53.600 --> 20:58.880]  дополнительная слагаемая вида б на у это типа считается называется управлением вот ну если
[20:58.880 --> 21:03.920]  вы там второй закону распишите то у вас в это управление отправится просто величины которые
[21:03.920 --> 21:09.480]  связаны с внешними силами вот так понятно куда-то берется
[21:13.480 --> 21:22.880]  окей вот и бывает нужно что управление как бы представляет себя некоторую супер позицию
[21:22.880 --> 21:29.440]  неких нескольких разных управлений вот которые например формируется за счет там линейные
[21:29.440 --> 21:37.600]  комбинации некоторых матриц то есть типа и и вот и где все это нет симметричное вот и вот
[21:37.600 --> 21:43.680]  иногда бывает нужно найти никаких коэффициентов скульптуральный радиус у этой штуки будет как
[21:43.680 --> 21:50.560]  можно меньше вот этого есть там свои интерпретации уже в теории не хочу сильно глубоко погружаться
[21:50.560 --> 21:58.240]  вот если мы хотим вот так сделать с минимизировать максимальное собственное значение вот такой вот
[21:58.240 --> 22:03.160]  матрице по иксу то есть найти коэффициенты с которыми надо сложить известный матриц так чтобы
[22:03.160 --> 22:10.960]  результаты был поменьше поменьше максимально собственное значение вот то причем тут с дп вот
[22:10.960 --> 22:17.680]  оно тут при том что вот это тоже самое сейчас давайте поим почему что искать минимум числа
[22:17.680 --> 22:25.400]  т при условии что вот это наша матрица от икс минус т на единичную матрицу является отрицательно
[22:25.400 --> 22:33.560]  определенной вот то есть с одной стороны мы ищем икс а с другой стороны мы ищем т вот причем
[22:33.560 --> 22:41.240]  так чтобы вот это было выполнено это ограничение собственно задает нам положение ну экивалентным
[22:41.240 --> 22:47.240]  образом преобразуется в ограничение положительной полуопределенности понятно ли почему так
[22:56.360 --> 23:05.880]  ага вижу отлично вот ну и так он это я верну уже всего вот второй пример к на который мы еще
[23:05.880 --> 23:13.600]  потратим наверное оставшуюся часть занятия заключается в том что если у нас есть какая-то
[23:13.600 --> 23:21.760]  не выпуклая задача квадратичного программирования вот типа двойчика да второй пример вот есть у
[23:21.760 --> 23:32.320]  нас вот такая вот задача икс т а икс плюс бета икс при условии что какие-то квадратичные
[23:32.320 --> 23:42.800]  ограничения икс т а и икс плюс бы это транспонированный смешали б равно нуля вот и при этом это все не
[23:42.800 --> 23:50.280]  выпукло ну какие могут быть причины матрица а какая-нибудь либо а либо и ты они не положительно
[23:50.280 --> 23:57.200]  полуопределены например мы все еще считаем что у нас и матрица симметрична пока что вот как
[23:57.200 --> 24:02.720]  только они перестают положительно определенно хотя бы одна из их вы сразу вываливаемся в область
[24:02.720 --> 24:08.400]  не выпуклых задач с которыми очень понятно что делать вот при этом можно построить некоторую
[24:08.400 --> 24:15.240]  некоторое приближение которое будет с помощью которого можно некоторым образом приблизить
[24:15.240 --> 24:24.200]  решение исходной задачи каким образом это делается давайте заметим что вот это все числа раз это
[24:24.200 --> 24:32.200]  все числа то мы можем добавить операцию взятия следа что мы уже не разделали по моему вот и
[24:32.200 --> 24:40.480]  сказать что это след от а икс икс т то есть след некая матрица которая нам была дана на некоторую
[24:40.480 --> 24:50.680]  неизвестную матрицу x из большой вот то есть равносильным преобразованием привести задача по
[24:50.680 --> 25:15.040]  такому виду и икс равно икс икс транспонированная вот кто понимает в каком месте куда мы перенесли
[25:15.040 --> 25:21.800]  проблемы с выпуклостью понятно вообще откуда это все взялось то я вот понаписал может быть
[25:21.800 --> 25:26.640]  какие-то преобразования непонятны не преобразование непонятны так преобразование понятно прекрасно
[25:26.640 --> 25:36.200]  скажите теперь пожалуйста до стипа ясно ли что вот это вот и вот это вот это выпуклое функции по
[25:36.200 --> 25:42.760]  матрице сейчас но просто у нас это функции еще берут себя x маленькая которая может быть не
[25:42.760 --> 25:48.520]  однозначно останавливается из x это правда но это мы сейчас отдельно обговорим то здесь у
[25:48.520 --> 25:54.960]  нас переменных 2 x большой x маленькая просто вот эти функции они зависит только ну можно
[25:54.960 --> 26:00.040]  написать там плюс 0 умножить на x маленькой окей а тут уже есть x маленькой да ну в любом случае
[26:00.040 --> 26:07.720]  они выпуклые ясно икс маленько считать независимо то но это просто это же ну а след у нас выпуклый
[26:07.720 --> 26:15.120]  ну это вот хороший вопрос давайте ну а их нас афина то есть я забуду ждать что все выпукло значит
[26:15.120 --> 26:23.360]  я должен быть выпуклый ну будет ли свет выпуклым или нет след будет выпуклым так как сумма выпукла
[26:23.360 --> 26:31.000]  да прекрасно ура забрались то есть вот здесь все остается выпуклым то есть становится выпуклым
[26:31.000 --> 26:37.060]  по сравнению с тем каким оно могло быть кривым косым вот здесь вот и вся не выпуклась она
[26:37.060 --> 26:47.540]  упирается вот в ограничении на ран на самом деле вот то есть здесь давайте это как-то красненьким
[26:47.540 --> 27:01.700]  обведу вот это не выпукло ограничение вот и чтобы сделать его выпуклым использует следующий прием
[27:01.700 --> 27:18.820]  называется выпукла релаксация гречень типа ранга так выпукла релаксации вот и говорят что давайте
[27:18.820 --> 27:26.660]  мы все оставим а вот в нашем ограничении который у нас есть на ранг мы кое-что подправим и будем
[27:26.660 --> 27:35.180]  надеяться что получившиеся выкукло задачи будет не сильно хуже чем то что у нас был до этого так
[27:35.180 --> 27:40.980]  вот так и икс становится минус икс икс транспонирование положительно определенной
[27:40.980 --> 27:49.700]  матрице вопрос подводу вопрос как на внимательность что ли почему теперь вот это стало выпуклым
[27:49.700 --> 28:08.420]  ограничению просто тех кто внимательно слушал предыдущие лекции кажется давайте какие будут
[28:08.420 --> 28:18.140]  идеи но по иксу большому просто линейно но вот правда но проблема лежит вот здесь потому что
[28:18.140 --> 28:25.700]  произведение иксов это плохо любые произведения переменных это чаще всего плохо вот в таком виде но
[28:25.700 --> 28:31.500]  к счастью чаще всего это преобразуется в более комфорт компактный вид который позволяет это
[28:31.500 --> 28:38.020]  все записать выпуклой форме вопрос как именно она может рассмотрим для произвольного вектора а
[28:39.020 --> 28:43.420]  а что вы хотите рассмотреть
[28:43.420 --> 28:52.020]  транспонированный на эту штуку на цейск а что должно быть больше ну больше рана нуля уже число
[28:52.020 --> 28:57.140]  просто определение распишем нет и сегодня определенность не не это чё у вас будет бесконечно
[28:57.140 --> 29:04.060]  много ограничений что ли это грустно и из этого получим аналитически что-то более удобное но
[29:04.060 --> 29:11.660]  опять же вектор цель убой мы от этого вряд ли куда-нибудь избавитесь видите проблему
[29:17.900 --> 29:23.420]  так ладно чтобы вас не томить давайте я скажу как это как с этим работать я потом покажу пример
[29:23.420 --> 29:31.260]  как как solver выпуклой задачи таким справляется смотрите вот эта штука это на самом деле
[29:31.260 --> 29:37.140]  дополнение пошуру в некоторые блочные матрицы может быть не самый очевидный ход вот ну давайте
[29:37.140 --> 29:42.780]  сейчас я это все ой все это запишу так помните что такое дополнение пошуру или надо допомнить
[29:42.780 --> 29:53.700]  напомнить надо так не помнить понятно мы это обсуждали когда когда что
[29:53.700 --> 30:04.180]  я уже забыл когда мы это обсуждали лучше напомнить да ну давайте сейчас то есть у нас есть такая
[30:04.180 --> 30:09.860]  блочная матрица так про сори меня могло сейчас быть плохо слышно когда у нас есть такая блочная
[30:09.860 --> 30:21.180]  матрица вот то для некоторого блока например а мы можем записать так называемые дополнение
[30:21.180 --> 30:30.260]  пошуру которая по сути дела является результатом процедуры блочного исключения вот когда мы
[30:30.260 --> 30:37.380]  решаем блочную системы линии в сравнении с такой блочной матрицей то у нас там может возникнуть
[30:37.380 --> 30:47.460]  необходимость выразить одни переменные через другие вот и промежуточная система которая
[30:47.460 --> 30:53.140]  возникает в процессе такого исключения она называется дополнение пошуру для той матрицы
[30:53.140 --> 31:04.740]  которая которая исключалась вот и сейчас давайте я постараюсь это все дело сформулировать более
[31:04.740 --> 31:18.220]  менее аккуратно так там правда ведь не я забываю с какой стороны там что начинается вот думаю
[31:18.220 --> 31:29.020]  сейчас все получится то есть да например да тут еще важно что это сделал симметрично поэтому
[31:29.020 --> 31:36.340]  я тут напрасно написал это тут на самом деле б транспонированная должно быть вот и соответственно
[31:36.340 --> 31:46.820]  если у нас дополнение пошуру ну например к матрице д то мы делаем следующие мы говорим что берем
[31:46.820 --> 31:56.180]  мат берем матрицу которая напротив по диагонали и вычитаем из нее б да и минус 1 б транспонированная
[31:56.180 --> 32:03.540]  то есть грубо говоря берем вот эту матрицу потом идем по кругу по часовой стрелке вот и
[32:03.540 --> 32:12.500]  конструируем такого рода выражение вот и собственно результат который мы будем использовать заключается в
[32:12.500 --> 32:19.020]  том что если в данном случае у нас д положительно полуопределивать строго положительно оправдана
[32:19.020 --> 32:26.260]  потому что мы тут обратно считаем вот то это будет м то не отрицательная определенность
[32:26.260 --> 32:37.940]  м равносильна тому что соответствующие дополнение пошуру тоже не отрицательно определено вот то есть
[32:37.940 --> 32:47.300]  смотрите вот здесь фигурирует какие-то произведения а здесь фигурирует сама матрица и поэтому мы
[32:47.300 --> 32:54.980]  можем благополучно записать наше исходное выражение x минус x и транспонировано больше
[32:54.980 --> 33:06.420]  это то же самое что и и матрица блочно x икс икс транспонирована единичка больше либо равна нуля
[33:06.420 --> 33:19.660]  вот потому что мы строим дополнение пошуру для единицы тут стоит икс и мы пишем икс
[33:19.660 --> 33:25.860]  большое минус икс единичка минус первая единичка на икс транспонированная получаем
[33:25.860 --> 33:31.740]  дополнение пошуру и оно не отрицательно определено поэтому вот это вот выражение которое у нас
[33:31.740 --> 33:36.940]  обозначена звездочкой можно заменить на выражение который обозначена крики плюсиком то есть
[33:36.940 --> 33:42.860]  звездочку у нас переходит в плюсик а плюсик уже явным образом это блочная матрица которая не
[33:42.860 --> 33:48.900]  отрицательно это выпукло ограничение потому что когда мы потом используем матрицу x и матрицу
[33:48.900 --> 33:55.220]  и вектор матрицу к большой вектор x малая по отдельности то это тоже самое что и вырезать из
[33:55.220 --> 34:01.940]  большой блочной матрицы куски а это вырезание эквивалентно линейному преобразованию который
[34:01.940 --> 34:11.020]  ничего не меняет понятно ли это кажется да так это хорошо вот теперь я хотел показать пример
[34:11.020 --> 34:19.020]  кода когда как бы solver понимает с одной стороны в одном с чем понимать что ему дана выпукло задача
[34:19.020 --> 34:23.540]  другой страна не понимает что ему дана выпукло задача так раз таки в зависимости от того в какой
[34:23.540 --> 34:35.300]  форме вы ее записали так ой не то так сейчас попробовал быстро набросать так 942 но надеюсь
[34:35.300 --> 34:43.740]  что все успеется несмотря на и некоторые перерывом так ну вот короче говоря cx пой наш пакет который все
[34:43.740 --> 34:55.820]  будет нам делать x будет наша переменная доумерной давайте для простоты а x большое будет наша матрица
[34:58.580 --> 34:59.080]  ой
[35:03.340 --> 35:03.860]  вот
[35:03.860 --> 35:19.100]  да да но мы еще знаем что она положительно определена поэтому такой ключ можно написать что
[35:19.100 --> 35:28.140]  она true позитив сами дефицит вот и значит чего у нас будет проблема которую будем решать
[35:28.140 --> 35:35.340]  вот а перед тем как мы ее решим и надо создать проблему точек solver
[35:35.340 --> 35:47.180]  так ну хочется что-нибудь ой проблему равняется cvx точка минимай
[35:47.260 --> 35:50.180]  проблем
[35:50.180 --> 36:06.220]  x точка минимайс так ну минимайс 0 это не как бы неважно или можно какой-нибудь там
[36:06.220 --> 36:16.060]  рандомный вектор умноженный на x давайте ц равняется так он да сейчас нам по s&p
[36:16.060 --> 36:33.900]  нп рей тогда что-нибудь там не знаю один минус один например ну не знаю для простоты так
[36:33.900 --> 36:43.940]  а экран ты видно да видно да это хорошо вот ну и соответственно давайте ц на x будем
[36:43.940 --> 36:48.820]  минимизировать но самое интересное будет в ограничение то есть в одном случае давайте в объем то
[36:48.820 --> 36:58.540]  как мы это понимаем что у нас x минус cvx outer по моему там есть такая функция сейчас зато проверим
[36:58.540 --> 37:04.180]  если он там или нет положительно полуопределена вот видите есть специальный значок который
[37:04.180 --> 37:08.980]  отвечает за положительную полуопределенность то есть можно задавать вот так может быть вот так
[37:08.980 --> 37:15.620]  пробуем решить по идее сейчас должен сломаться а да сломалась но не по той причине по которой
[37:15.620 --> 37:23.740]  должен должен был сломаться так нет автора понятно ну давайте сделаем вот так я еще очень не
[37:23.740 --> 37:40.180]  люблю так делать но видимо в этот раз придется 2 1 ладно посмотрим я надеюсь что что он справится
[37:40.180 --> 37:50.580]  если не справится прирус чинить дополнительно так 2 1 на 1 2 транспонировано во ведь он написал
[37:50.580 --> 37:55.580]  что нельзя проверить на выпуклость потому что вот есть такая такое вот выражение которое
[37:55.580 --> 38:02.060]  произведение переменных а произведение переменных нельзя проверить на выпуклость
[38:02.060 --> 38:08.820]  если нет каких-то полных ограничений это собственно то что хотелось хотелось продемонстрировать вот с
[38:08.820 --> 38:13.780]  другой стороны если теперь мы вместо этой штуки напишем другу штуку который ей полностью
[38:14.780 --> 38:25.260]  только что написали это называется кажется бимат типа блочная матрица так осталось понять
[38:25.260 --> 38:38.540]  какая она там блочная икс так давайте икс там столбец запятая строка 1 и вот это вот бимат
[38:38.540 --> 38:43.540]  который здесь образовался он не отрицает на определен так
[38:48.060 --> 38:55.740]  так я догадываю еще проблемы довольно неприятно но видим и без этого никак не обойтись
[39:01.140 --> 39:02.140]  так что ли
[39:05.380 --> 39:06.260]  все еще не так
[39:08.540 --> 39:13.100]  на пеже был конструктор единичный матрица
[39:15.100 --> 39:18.900]  да но тут не единичный матрица единичка число и надо чтобы она а вы хотите
[39:18.900 --> 39:22.780]  сказать запихнуть и давайте так что ли
[39:22.780 --> 39:41.860]  нет ему еще что-то не нравится сейчас 2 1 икс 2 2 икс т 1 2 и ай
[39:41.860 --> 39:52.740]  хочется сказать что все в порядке но ему что-то не нравится сейчас как бимат работает
[39:52.740 --> 40:09.460]  есть примерчик тут нет он как-то парсит это все добро и вываливается лен лен моутол
[40:09.460 --> 40:19.700]  дам давить это афинная функция через аж так записывается пам пам пам так так не помогло
[40:19.700 --> 40:28.940]  так он давайте пойдем просто в севикспай туториал и да посмотрим на то на то как
[40:28.940 --> 40:38.580]  бимат работает просто хотелось бы поспользоваться без каких-либо дополнительных дополнительных
[40:38.580 --> 40:50.700]  проверок но видимо так чего то миг фанкшнс так вот видите сколько этих атомик фанкшнс тут
[40:50.700 --> 41:00.740]  вот есть макс и всякие логедеты и прочее нам нужно более хитрая штука а именно бимат вот
[41:00.740 --> 41:08.940]  вектор матриц фанкшнс вот видите типа бимат она афинная и она увеличен типа инкриментал так
[41:08.940 --> 41:19.340]  не слушать действительно икс 1 1 икс 1 ку то есть вот так идем потом следующие строки так что все
[41:19.340 --> 41:27.460]  было в общем-то правильно еще правда аж стэк вот такой вот хитрый может быть коризонтал да
[41:27.460 --> 41:35.940]  коризонтал стэк которая просто в ряд всех дел кладет и наверное есть стэк который кладет это
[41:35.940 --> 41:46.260]  все в большой большой столбец вот так когда ставить эту штуку компилиться правильно так
[41:46.260 --> 41:56.460]  все-таки тут был правильно икс тут правильно икс транспонированный может тут какой-нибудь
[41:56.460 --> 41:57.500]  шейп показать
[42:08.340 --> 42:25.340]  дает скажут и неправильно пример ай так икс т.д. здесь тяну и ай же наверное правильно мне все создаст
[42:25.340 --> 42:32.620]  и на 1 так хорошо если я вот так сделаю
[42:32.620 --> 42:39.420]  так все еще мимо
[42:55.580 --> 42:56.060]  икс
[43:06.860 --> 43:08.780]  но не работает
[43:08.780 --> 43:22.260]  возможно этот бумаг не предназначен для таких но блог матрицы не только для них то он и предназначен
[43:22.260 --> 43:31.660]  как бы то есть иначе он не очень пойду чем нужен вот сейчас надо куда-то так 952 уже
[43:31.660 --> 43:39.020]  потому что не весь другом метку какой-нибудь разрешает не одинаковые размеры не не с
[43:39.020 --> 43:49.940]  размерами вроде все в порядке сутки проблема что и чернул лист и стэк коризонтали стэк
[43:50.540 --> 43:59.380]  ну все нормально вроде икс у нас 2 1 это столбец
[43:59.380 --> 44:06.260]  может я здесь двойчик сейчас уберу и все заработает очень конечно это верить
[44:06.260 --> 44:10.220]  нет так это просто
[44:10.220 --> 44:18.500]  может поменять икс икс т.д. попробовать просто-то я
[44:18.500 --> 44:25.580]  пробовал что-то вроде не заработала на не заработала
[44:36.020 --> 44:38.900]  на поразительно так точно есть
[44:38.900 --> 44:42.820]  единица да
[44:51.060 --> 44:55.820]  так слушайте ладно давайте сейчас я не буду тратить это больше времени я после лекции пришлю
[44:55.820 --> 45:01.220]  ссылочку на актуальный примерчик вы сможете его там подопускать настоятельно вот ну короче это
[45:01.220 --> 45:08.180]  все будет будет нормально работать вот просто какие-то проблемы с индексом 2 я решу их там
[45:08.180 --> 45:18.260]  после лекции в чем не сложно вот и таким образом конструирование такой матрицы оно
[45:18.260 --> 45:26.620]  позволяет продемонстрировать что все будет работать с точки зрения выпуклости так давайте
[45:26.620 --> 45:33.620]  последний попытка кое-что я хочу проверить может получится так ладно это я к чему это я к тому что
[45:33.620 --> 45:41.460]  мы сейчас преобразовали это все выпуклой задача вот в результате которой у нас что получится у нас
[45:41.460 --> 45:47.060]  получится их большой со звездочкой и маленькой со звездочкой и в идеале у нас должно будет
[45:47.060 --> 45:55.580]  получиться что вот будет такое вот равенство вот понятное дело что в реальности скорее
[45:55.580 --> 46:01.540]  всего такого в точности нравится не будет вот отсюда возникает резонный вопрос каким
[46:01.540 --> 46:12.040]  образом нам из получившихся матрицы вектора доставать решение исходной задачи вот есть
[46:12.040 --> 46:23.060]  понятное дело разные подходы вот и один из наиболее успешных для наиболее что ли интересной интересной
[46:23.060 --> 46:31.740]  задачи я сейчас попытаюсь оставший 20 минут рассказать вот задача называется понятная max
[46:31.740 --> 46:39.700]  кат то есть ищем максимальный разрез график вот формально это все дело ставится как
[46:39.700 --> 46:54.700]  кимизация некоторого вектора x 1 четвертая сумма две суммы по и и по g w и g на 1 минус x и x g
[46:54.700 --> 47:05.820]  где соответственно x и лежит в множестве плюс 1 минус 1 ну то есть w это соответственно матрица
[47:05.820 --> 47:06.860]  весов симметричной
[47:14.060 --> 47:15.940]  понятно ли постановкой почему она такая
[47:19.940 --> 47:33.100]  прекрасный вопрос смотрите если у нас иксы разных знаков тут получается двойка и у нас
[47:33.100 --> 47:39.420]  сумма весов как будто боится поэтому одна двойка отсюда берется а под а вторая двойка
[47:39.420 --> 47:43.660]  берется из-за того что мы идем по всем индексам ну то есть дважды учитываем одно и то же
[47:43.660 --> 47:58.020]  вот я надеюсь всем видно что это очень-то квадратичная сдача вот вот эту силу того
[47:58.020 --> 48:06.020]  что у нас вот вот x и на x g это куда и w i j это квадратичная сдача которая записывает
[48:06.020 --> 48:13.540]  цену то есть которые следы ранее обозначенной технологии она переписывается в куклу с следующим
[48:13.540 --> 48:21.740]  образом мы говорим что мы максимизируем теперь уже по иксу маленькому и иксу большому вот где у
[48:21.740 --> 48:34.220]  нас одна черта остается сумма по и сумма по жи ой я тут махнул как-то сильно и остается
[48:34.220 --> 48:44.220]  w i j единицы минус x i j вот и соответственно тут у нас икс большой равняется x икс транспонированная и
[48:44.220 --> 48:57.540]  икс и т во-прежнему равняется плюс ну с одним вот собственно как побороться с этим ограничением
[48:57.540 --> 49:03.780]  как побороться с явным наличием вот этого ограничения очень просто достаточно заметить
[49:03.780 --> 49:08.740]  что есть это правда то из этого следует что диагональ у матрицы x равна и векторе всех единиц
[49:08.740 --> 49:17.820]  ну диагонали потому что икс и т в квадрате вот и соответственно получаем что достаточно
[49:17.820 --> 49:23.180]  сказать что на единичке на диагонали и хватит понятно ли это
[49:23.180 --> 49:39.580]  отлично во значит ну и плюс у нас вот это вот не выпук ограничения которое понятное
[49:39.580 --> 49:51.700]  дело что заменяет всего лишь на ну на например либо на то что у нас было до этого что не
[49:51.700 --> 49:58.300]  отрицательная определенность и выполнение по шуру либо же говорят что просто не отрицательно
[49:58.300 --> 50:03.820]  определенной какой там рамк не важно вот то есть выпуклая релаксация в одном из вариантов
[50:03.820 --> 50:11.420]  прием ну как бы общего потребимых скажем так это вот табло ю а и джей единицы минус икс а и джей а
[50:11.420 --> 50:18.020]  понятно что вот эта штука и вот это это просто след ну понятно до следа с произведением матрицы
[50:19.020 --> 50:29.860]  вот при условии что диагональ у матрицы икс равна ой я тороплюсь немножко диагональ у икса равна
[50:29.860 --> 50:37.460]  веку всех единиц и например икс не отрицательно по длину ну например вот так значит в дальнейшем
[50:37.460 --> 50:45.820]  оптимальное значение вот этой вот для вот этой вот задачи которая еще не ослабленная исходной
[50:45.820 --> 50:52.820]  п со звездочкой тимальное значение то есть значение целевой функции так сейчас секундочку может
[50:52.820 --> 51:04.740]  быть я вам с обозначением немножко да прошу прощения здесь будет с давайте все со звездочка
[51:04.740 --> 51:13.300]  здесь оптимальное значение и п со звездочки тут оптимальное значение выпуклая релаксация
[51:13.300 --> 51:25.620]  как связано п со звездочкой со со звездочкой какой между ними знак ну конечно п со звездочкой
[51:25.620 --> 51:32.380]  сейчас да по со звездочкой больше или равно по большому нам что именно так именно так поскольку
[51:32.380 --> 51:39.980]  мы сказали что у нас икс икс не не ровно ранга 1 а какой-то нет и сайт на определенный то конечно
[51:39.980 --> 51:43.940]  мы допустим множество расширили поэтому п со звездочкой будет больше поскольку мы
[51:43.940 --> 51:49.220]  максимизируем вот окей это наш первое первое важное неравенство которое нам понадобится в
[51:49.220 --> 51:55.060]  дальнейшем теперь самое интересное вот решили мы вот эту задачу мы умеем решать сейчас я покажу
[51:55.060 --> 52:00.580]  как делается на тестовом примере вот у нас получилась некоторая матрица икс большой со
[52:00.580 --> 52:09.580]  звездочкой возникает резонный вопрос а как отсюда вытащить разрез я думаю что разрез у нас это
[52:09.580 --> 52:20.060]  вектор из плюс-минус единиц вот и на помощь приходит алгоритм джомонса вудемсона это два разных
[52:20.060 --> 52:20.500]  человека
[52:20.500 --> 52:40.100]  который звучит максимально просто и скажем так не очень очевидно почему это будет что-то нам
[52:40.100 --> 52:48.740]  разумное давать вот мы постараемся доказать первые шаг генерируем случайный вектор на сфере
[52:48.740 --> 52:51.220]  на единиче
[53:06.100 --> 53:14.940]  и второе формируем наш разрез из ну один из понятных разрезов из тех индексов таких что
[53:14.940 --> 53:24.740]  скалярное произведение векторов с соответствующим вектором уитом будет больше ли бравнули где уит
[53:24.740 --> 53:40.220]  это столбцы матрицы у такой что икс представляется видим у транспонированная у икса звездочкой то есть
[53:40.220 --> 53:45.740]  вот это вот вот этот икс со звездочки он вот сюда улетает то есть мы получили икс со звездочкой
[53:45.740 --> 53:54.780]  факторизовали в произведении у транспонированная у а потом берем столбцы и считаем набор скалярных
[53:54.780 --> 54:01.460]  произведений с случайным вектором единичной сфере вот индексы для которых это больше либо равна
[54:01.460 --> 54:07.740]  нуля это будут единички все остальные будут минути и получили разрез вот вот такой алгоритм
[54:07.740 --> 54:19.980]  всего два шага но оказывается что работает удивительно хорошо вот в частности в частности
[54:19.980 --> 54:28.260]  справедливость оценка что вот эта штука дает намеки разрез которые соответствует
[54:28.260 --> 54:33.580]  р со звездочкой значение целевой функции значение
[54:47.300 --> 54:48.900]  или функции на полученном разрезе
[54:58.260 --> 55:06.020]  так алгоритм понятен или есть вопросы значит справедливая оценка что c со звездочкой напоминает
[55:06.020 --> 55:14.260]  наши исходные задачи ну как бы самое правильное больше либо равно чем r со звездочкой то есть он
[55:14.260 --> 55:21.260]  оценку снизу нам некоторые дает ну что разумно и это что самое интересное больше либо равно
[55:21.260 --> 55:34.020]  чем 0 8 7 8 умножить на п со звездочкой то есть получили связь между идеальным решением
[55:34.020 --> 55:46.020]  идеальное решение сейчас покрасить идеальное решение то что легко посчитать и то что дает наш
[55:46.020 --> 55:57.980]  метод понятно так что это за что означает каждый этих буквок и самое замечательное что в общем
[55:57.980 --> 56:04.700]  вот это вот вся история вот про оценку про вот этот алгоритм это премия фолкерсона в 2000 году
[56:04.700 --> 56:10.260]  авторы получили за то что вот предложили такой метод получения разреза это одна из таких жемчужин
[56:10.260 --> 56:18.900]  жемчужин на получение дискретных решений из непрерывных релаксации вот не совсем немного задач
[56:18.900 --> 56:27.020]  которые для которых такое существует вот я поэтому решил включить это наш курс вот значит давайте
[56:27.020 --> 56:38.780]  посмотрим как это происходит давайте доказательств что я не знаю что происходит в этом методе этот
[56:38.780 --> 56:52.380]  метод предлагает нам некоторым случайным образом отобразить столбец в плюс-минус один вот а раз
[56:52.380 --> 56:59.060]  у нас тут вектор и вы случайно то можно общать мотождание разреза ну то есть мотождание нашей
[56:59.060 --> 57:08.860]  целевой функции по распределению вектор в что это такое ну собственно мотождание тут уже будет
[57:08.860 --> 57:22.460]  одна вторая сейчас увидите почему тут опять две суммы потому что только только от повторного
[57:22.460 --> 57:28.980]  суммирования останется ношитель дубль выжитая а тут остается что остается индикатор индикатор
[57:28.980 --> 57:44.980]  того что знак у этой транспонированная в не равен знаку у житые транспонированная в так понятно
[57:44.980 --> 57:51.700]  ли запись так вижу 1 плюс вижу второй прекрасно простым от ожидания то мы можем его по сути
[57:51.700 --> 57:58.300]  дел явно образом записать что это есть одна вторая ну то есть поскольку вот эта штука равна
[57:58.300 --> 58:10.340]  единице и один или ноль том от ожидания вырождает ну вырождается сводится к просто взвешенами
[58:10.340 --> 58:17.860]  вероятность из сумме вероятности того ну что собственно то написано что знак у этой транспонированной
[58:17.860 --> 58:30.420]  в не равен знаку у житой транспонированная в вот и все так теперь осталось вероятностями
[58:30.420 --> 58:37.940]  разобраться давайте посчитаем эти самые вероятности на основе геометрической интерпретации вот сейчас
[58:37.940 --> 58:45.940]  может быть он не сам кружочек нарисую о класс получился ровный кружочек это это здорово у нас
[58:45.940 --> 58:55.700]  значит есть случайный вектор в какой-то да который как-то торчит ну так себе да это вектор в что
[58:55.700 --> 59:04.100]  такое что знак скалярного произведения двух векторов уита и у житая отличается
[59:04.100 --> 59:15.820]  что это говорит о взаимном положении этих самых векторов что не в разных полу полу окружности
[59:15.820 --> 59:23.740]  относительно перпендикулярно к в давайте да отличность в вот у нас есть такой перпендикуляр
[59:23.740 --> 59:30.500]  кривенький конечно но я думаю понятно вот и у нас есть два век то есть есть два вектора у
[59:30.500 --> 59:37.980]  которого как бы грубо говоря заштриховать область и понять чему равна эта самая вероятность если вы
[59:37.980 --> 59:43.780]  уже осознали то можно сказать итоговое выражение а вы у нас равномерно распределена на единичной
[59:44.100 --> 59:44.820]  именно так
[59:59.180 --> 01:00:10.060]  равно давайте даже может быть не так неправильно нарисовал все-таки у нас же в случае поэтому давайте
[01:00:10.060 --> 01:00:17.740]  я лучше нарисую то что фиксировано а фиксировано с два вектора типа у и ну и например как-то
[01:00:17.740 --> 01:00:25.540]  тут направлен уже во наверное так будет правильнее вот есть как есть какой-то вектор в который типа
[01:00:25.540 --> 01:00:36.380]  куда-то смотрит вот сюда куда-то например вот где какую область какую область он может попасть так
[01:00:36.380 --> 01:00:42.820]  чтобы скалярное произведение отличалось вот так вот так правильный вопрос формулирует но
[01:00:42.820 --> 01:00:47.980]  перпендикуляр к нему должен лежать между уже ты и уитая то есть слева и справа симметричной области
[01:00:47.980 --> 01:00:54.460]  такого же углового размера как расстояние меньшее между понимаем мы типа вот так вот надо сделать да
[01:00:54.460 --> 01:01:06.540]  нет скрипки на 90 градусов углы там будут одни и те же конечно же вы наверное так понимаете что
[01:01:06.540 --> 01:01:12.220]  это будет минус то же самое так ну давайте я как-то поближе в н рисую чтобы перпендикуляры
[01:01:12.220 --> 01:01:20.740]  смотрелись как-то по аккуратнее так блин так радикально решим вопрос с тем где лежит в
[01:01:20.740 --> 01:01:29.940]  давайте его сюда отправим так вот здесь 13 не очень я успеваю так вот один будет
[01:01:29.940 --> 01:01:45.060]  смотреть сюда а другой будет смотреть например сюда да я правильно рисовал смотри давайте так
[01:01:45.060 --> 01:01:51.380]  высоко уровневая будет некоторая дробь что будет в знаменателе или тропе и ну 2 пи да давайте
[01:01:51.380 --> 01:01:59.860]  2 пи будет знаменателе вот а что будет в чистить в счастливе образуется наверное понятно и
[01:01:59.860 --> 01:02:09.380]  в счастливе два угла между ну именно так именно так два угла уитая уже все верно все гениально это
[01:02:09.380 --> 01:02:15.460]  это и требовалось осознать что по сути дела мы ограничен тем какую то с чем больше угол
[01:02:15.460 --> 01:02:20.180]  чем больше вероятность что мы попадем на случайный вектор будет иметь одинаковые скалярные произведения
[01:02:20.180 --> 01:02:28.340]  я думаю довольно довольно прямолинейно все так геометрия понятно или нужно еще что-то подробнее
[01:02:28.340 --> 01:02:37.860]  нарисовать в итоге у нас получается что здесь сидит угол у и уже делить на пи вот а угол мы
[01:02:37.860 --> 01:02:46.660]  знаем чему равен угол рай наркосинус от скалярного произведения соответственно у и транспонированные уже
[01:02:46.660 --> 01:02:53.620]  ну потому что мы дополнительно можем тут как бы прикинуть что вектора будет нормирно там
[01:02:53.620 --> 01:03:00.260]  а снормированный короче аркосинус от скалярного произведения да нормально делить на пи все это
[01:03:00.260 --> 01:03:07.820]  почти что победа потому что так надо теперь вот так сделать чтобы было все видно потому что мы
[01:03:07.820 --> 01:03:17.540]  можем записать нашему от ожидания замечательную с которой все начиналось как одну вторую сумма по и по
[01:03:17.540 --> 01:03:31.820]  и джей дабл ю ай джей а дальше смотрите следить за руками два аркосинуса собственно у ай транспонированные
[01:03:31.820 --> 01:03:40.980]  у джей делить на пи а сюда добавим один минус у ай транспонированные у джей а сюда добавим
[01:03:40.980 --> 01:03:48.820]  один минус у ай транспонированные у джей делить пополам то есть вот это вот выражение нам нужно
[01:03:48.820 --> 01:03:54.980]  ровно для того чтобы приблизиться к тому с чем мы начинали а именно с вот этого выражения где
[01:03:54.980 --> 01:04:00.500]  было как были какие-то произведения вот и далее рассмотрим вот такую вот прекрасную функцию
[01:04:00.500 --> 01:04:15.580]  ашат икс которая равняется два аркосинус ой икс делить на пи 1 минус x то есть вот вот вот
[01:04:15.580 --> 01:04:22.900]  эта штука некоторая функция вот минимум который мы сейчас будем искать ну я сейчас просто покажу
[01:04:22.900 --> 01:04:28.620]  как она будет выглядеть так где-то у меня была картинка заранее подготовленная которую куда-то
[01:04:28.620 --> 01:04:45.340]  делать сейчас обычно во картинку нашел сейчас я ее покажу вот так выглядит функция аш ну у нас
[01:04:45.340 --> 01:04:50.700]  икс от минус одного до одного понятное дело потому что роги метракосинусов вот то есть видите что
[01:04:50.700 --> 01:04:55.580]  при единичке она понятное дело стремится к безконечности потому что мы делим на 1 минус x но
[01:04:55.580 --> 01:05:03.740]  у нее есть какой-то минимум вот тут вот где-то вот видите да так если вы видите что есть
[01:05:03.740 --> 01:05:07.780]  какой-то минимум плюс поставьте пожалуйста так окей увидели что есть минимум это замечательно
[01:05:07.780 --> 01:05:18.980]  вот теперь если вернуться к нашим формулам то становится ну и в общем этот минимум на самом
[01:05:18.980 --> 01:05:29.540]  деле что аш от икса звездочки примерно там численно если искать примерно 8 8 8 7 8 5 обозначим
[01:05:29.540 --> 01:05:37.220]  это число как альфа gw вот значит из этого тогда ночь можно ценить что нашим от ожидания от
[01:05:37.220 --> 01:05:47.340]  разреза больше либо равно чем вот это вот альфа gw умножить на 1 четвертую две суммы ай джей
[01:05:47.340 --> 01:05:56.420]  дабл ю ай джей единицы минус у ай транспонированная у джей что в точности да и равно и икса и джей
[01:05:56.420 --> 01:06:04.780]  который был ранее поэтому это равняется альфа gw на п со звездочкой что в свою очередь так же
[01:06:04.780 --> 01:06:12.100]  больше либо равно чем альфа gw умножить на ц со звездочек в силу соотношения между п и ц вот в
[01:06:12.100 --> 01:06:26.060]  итоге в общем практически получить то что в точности то что нам надо вот да далее поскольку наш
[01:06:26.060 --> 01:06:35.340]  метод дает какой-то разрез вот то ну то есть для мот ожидания справедливо что там ц со звездочки
[01:06:35.340 --> 01:06:41.900]  будет больше либо равно чем это самое мот ожидания тоже же среднем они самые лучшие больше либо
[01:06:41.900 --> 01:06:48.900]  равно чем ну в общем то же самое что я сейчас просто перепишу что мы получилась альфа звездочки на
[01:06:48.900 --> 01:06:58.300]  п и больше либо равно соответственно чем альфа joman williamson ц со звездочкой то есть если мы
[01:06:58.300 --> 01:07:05.620]  теперь все понятно ли логика получения тех не равенств то есть хотим оценить то насколько у
[01:07:05.620 --> 01:07:11.940]  нас большой зазор между тем что мы в идеале можем получить если дискретную задачу решим с тем что
[01:07:11.940 --> 01:07:18.220]  мы получаем после всех этих аппроксимаций сначала в непрерывную задачу а потом получение
[01:07:18.220 --> 01:07:24.620]  дискретного приближения из joman williamson в итоге что если мы теперь все это сложим то получится что
[01:07:24.620 --> 01:07:33.660]  ц со звездочки меньше либо равно п со звездочкой который меньше либо равен чем один альфа jw ц со
[01:07:33.660 --> 01:07:46.780]  звездочкой вот а это уже в свою очередь примерно 1 1382 ц со звездочкой то есть то решение которое
[01:07:46.780 --> 01:07:53.220]  мы получаем просто из дискретной из непрерывной релаксации оно вот всего лишь там на 14 процентов
[01:07:53.220 --> 01:08:01.180]  да правильно говорю 14 процентов отличается от ну или больше ну то есть лежит от правильного
[01:08:01.180 --> 01:08:10.060]  решения до вот почему таков так понятно ли это то есть некоторые дополнительная оценка которая
[01:08:10.060 --> 01:08:17.740]  позволяет понять насколько мы вот вот насколько грубо мы вот это вот оценили то есть где где где
[01:08:17.740 --> 01:08:23.900]  вот тут отцанк сверху относительно ц со звездочки она оказывается вот какая то есть это не так
[01:08:23.900 --> 01:08:34.020]  много как на самом деле ну как принципе гипотезически могло показаться так финальное финальное
[01:08:34.460 --> 01:08:42.180]  финальное завершение в общем в завершении хочется показать картинки сейчас я их покажу
[01:08:42.180 --> 01:08:50.540]  ой так так так так так так так а тут картинок нет потому что их отдельно решил я их решил
[01:08:50.540 --> 01:09:05.980]  отдельно да все открыть так сейчас и будет так кажется это демо и нет с дп тест
[01:09:05.980 --> 01:09:12.620]  на это с дп тест окей сейчас а что в демо тогда
[01:09:12.620 --> 01:09:29.460]  так как будто бы то же самое ну ладно так парам пам пам сейчас он не скажет что что-то
[01:09:29.460 --> 01:09:37.940]  не установлено приятно так ладно видимо тогда мне придется казаться т.д. все это запустить прям
[01:09:37.940 --> 01:09:46.660]  онлайн да поскольку времени уже нет а то я бы конечно все это был запускал давайте я тогда
[01:09:46.660 --> 01:09:55.020]  покажу как оно есть короче говоря смотреть что происходит берем генерируем случайный граф
[01:09:55.020 --> 01:10:04.220]  регулярный такой что каждая вершина соединена с какими-то тремя другими вершинами вот вытаскиваем
[01:10:04.420 --> 01:10:11.420]  смежности и строим специальную матрицу название лоплосиан вот вот тут визуализация графа и
[01:10:11.420 --> 01:10:21.100]  визуализация его матрицы его лоплосианом можно показать я это сейчас не привел потому что там
[01:10:21.100 --> 01:10:27.860]  еще выколотки минут на 10 наверное пояснений вот что наш разрез это на самом деле квадратичная
[01:10:27.860 --> 01:10:37.460]  форма от лоплосианом вот и мы можем генерирует рандомный разрез вот он раз мы его сгенерируем
[01:10:37.460 --> 01:10:43.740]  можем посчитать значение ну типа 38 и нарисовать как именно разбиваются на два подножия вершинки
[01:10:43.740 --> 01:10:49.940]  вот теперь если мы сделаем с дп релаксации смотрите вот здесь вот почему-то оно работалось
[01:10:49.940 --> 01:11:00.580]  таким вот образом вот ладно я еще проверю и пришлю ссылочку на актуальную актуальную новость
[01:11:00.580 --> 01:11:07.900]  вот значит трейс скалярного произведения диагональ и не отрицательно определенно все как мы писали
[01:11:07.900 --> 01:11:16.100]  формулу решаем теперь эту штуку все решается как-то там получается икс получали так получилось такой
[01:11:16.100 --> 01:11:23.220]  икс что ли от него свд и увидели что ранг действительно не один а раз два три три ранга
[01:11:23.220 --> 01:11:29.420]  оказался равен трем все остальное типа 10 с 8 что очень мало поэтому считаем нулями вот ну
[01:11:29.420 --> 01:11:37.260]  картинка этих сингулярных значений вот потом мы считаем матрицу у и показываем что действительно
[01:11:37.260 --> 01:11:43.460]  она удовлетворяет тому свойство которое нам было нужно вот а дальше начинаем сэмплировать много
[01:11:43.460 --> 01:11:54.420]  разных векторов на ящине сфере вот и используя алгоритм джома сулимсона смотреть на на что
[01:11:54.420 --> 01:12:03.940]  на назначение разреза полученные для соответственно р на норму р нормировка у транспонированное это
[01:12:03.940 --> 01:12:10.620]  собственно по элементу по числению скалярных произведений вот из взятия знака это плюс или
[01:12:10.620 --> 01:12:21.260]  минус один вот после чего мы берем среднее берем дисперсию и максимально значение в итоге
[01:12:21.260 --> 01:12:28.980]  получаем что у нас среднем разрез равен 63 с лишним максимально же значение 67 вот если на всякий
[01:12:28.980 --> 01:12:35.060]  100 грамм кто но вот так вот так вот выглядит вот это сэмплирование по собственно много разных
[01:12:35.060 --> 01:12:43.340]  случайных векторов на сфере взяли вот давайте проверим то есть наше значение 89 поправка
[01:12:43.340 --> 01:12:56.100]  81 средний 63 максимум 67 и 113 это 76 вот то есть все соотношения выполняются самое интересное
[01:12:56.100 --> 01:13:02.740]  сравнить с рандомом то есть в принципе могли бы на рандомить наши случайные разрезы и построить
[01:13:02.740 --> 01:13:08.380]  то же самое гистограмму так вот оказывается если рандомить совсем рандомить просто случайный
[01:13:08.380 --> 01:13:14.300]  брет разрезы то распределение вот такой то есть они где-то в районе 30 и 40 расположены а если
[01:13:14.300 --> 01:13:19.540]  рандомить случайные векторы на сфере использовать джомас уильямсон то они вот как распределили то
[01:13:19.540 --> 01:13:25.780]  есть видите тут существенный зазор между тем что вы будете рандомить просто рандомить и тем что
[01:13:25.780 --> 01:13:32.220]  вы будете рандомить на сфере и использовать джомас уильямсона к результату выпукла релаксации
[01:13:32.220 --> 01:13:39.660]  понятно ли картинка так хорошо это прекрасно что картинка понятно вот если возвращаться к
[01:13:39.660 --> 01:13:49.740]  теории всего этого дела последняя последняя ремарка заключается в том что забавный факт что
[01:13:49.740 --> 01:13:55.620]  неизвестно можно ли получить оценку лучше чем алгоритм джомас уильямсон для этой задачи то
[01:13:55.620 --> 01:14:02.540]  есть нельзя неизвестно можно ли получить лучше но известно что получение оценки в 16 17 от
[01:14:02.540 --> 01:14:07.820]  оптимального уже непосложная задача то есть известно отрицательный результат что вот на уровне
[01:14:07.820 --> 01:14:13.940]  16 17 все плохо а вот между этим уровнем и тем что джомас уильямсон еще насколько я знаю является
[01:14:13.940 --> 01:14:22.940]  открытой проблемой вот поэтому значит надеюсь понятно что за мета что за задача вот и также
[01:14:22.940 --> 01:14:28.100]  понятно зачем с дп использует как с дп может может помочь для релаксации задачи искренней
[01:14:28.100 --> 01:14:38.020]  оптимизации вот так наверное сегодня все спасибо большое за внимание слайды в смысле записи я
[01:14:38.020 --> 01:14:44.540]  пришлю и ссылочку на коллаб где все будет работать сравнение двух эквивалентных записи одно и
[01:14:44.540 --> 01:14:51.660]  то же задачи которые в одном случае проглатывается солвером в другом случае нет тоже выложу все если
[01:14:51.660 --> 01:14:58.180]  есть какие-то вопросы то давайте обсудим можно написать в чат и спросить если вопросов нет то
[01:14:58.180 --> 01:14:59.300]  можно заканчивать
