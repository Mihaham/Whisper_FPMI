[00:00.000 --> 00:12.000]  Сегодня мы говорим про новую задачу, точнее новую постановку задачи, хотя на самом деле
[00:12.000 --> 00:16.800]  окажется, что она очень тесно связана с постановкой, которую мы уже знаем.
[00:16.800 --> 00:35.800]  Сегодня говорим про задачу LCA или lowest common star. Самый нижний общий предок.
[00:35.800 --> 00:53.800]  В чём заключается задача? Дано. Некоторое дерево, ну или давайте так напишем, корневое дерево.
[00:53.800 --> 01:01.800]  Ну что такое корневое дерево? В прошлом семестре, я думаю, обсуждали, это просто некоторый граф,
[01:01.800 --> 01:11.800]  у которого есть некоторая выделенная вершина, из которой исходят какие-то другие вершины,
[01:11.800 --> 01:19.800]  из этих вершин в свою очередь исходят другие вершины, ну и так далее.
[01:19.800 --> 01:25.800]  Значит, вот дано некоторое корневое дерево, и соответственно, что нужно?
[01:25.800 --> 01:53.800]  Нужно для любой пары XY, которые являются вершинами дерева, найти самого низкого общего предка.
[01:53.800 --> 02:01.800]  Ну, что это означает? Это означает, что вот, допустим, мы рассматриваем вершины вот эту X и вот эту вершину Y.
[02:01.800 --> 02:07.800]  Вот. Какие у них есть общие предки? Ну, понятное дело, что вот эта вершина является общим предком,
[02:07.800 --> 02:11.800]  и корень является общим предком, вообще говоря, любой пары вершин. Вот.
[02:11.800 --> 02:19.800]  Так вот, задача LCA, или точнее запрос LCA от XY, просит вас найти самый нижний среди всех предков.
[02:19.800 --> 02:26.800]  То есть, понятное дело, что если вы рассматриваете произвольную пару вершин XY, то как выглядит путь до них?
[02:26.800 --> 02:30.800]  То есть, есть некоторый общий путь, и дальше он в какой-то момент вот разветляется.
[02:30.800 --> 02:33.800]  То есть, один путь ведет в X, другой путь идет в Y.
[02:33.800 --> 02:43.800]  Вот. Как раз задача заключается в том, чтобы найти вот этот самый момент, при котором у вас XY идут по абсолютно разным путям.
[02:43.800 --> 02:47.800]  То есть, найти минимального или самого низкого общего предка.
[02:48.800 --> 02:51.800]  Задача понятна? Вот.
[02:51.800 --> 02:56.800]  Ну, вообще говоря, наверное, сразу вот отсюда можно уже сделать некоторый вывод о том, что, наверное,
[02:56.800 --> 02:59.800]  эта задача будет как-то похожа на задачу RMQ. Вот. Почему?
[02:59.800 --> 03:03.800]  Ну, потому что задача RMQ, что у нас было? У нас был некоторый массив.
[03:03.800 --> 03:19.800]  Если мы условно так изобразим массив, вот, ну где по оси Y мы отложим, собственно, сами значения, значения этого массива,
[03:19.800 --> 03:25.800]  то понятное дело, что задача поиска минимума на этом отрезке, она сводится к тому, чтобы найти самый минимальный элемент,
[03:25.800 --> 03:30.800]  ну или, грубо говоря, найти некоторый условно выделенный элемент, который является меньше всех остальных.
[03:30.800 --> 03:40.800]  То же самое, только задача, по сути, сводится к тому, чтобы вот на данном интервале узлов найти узел, у которого наименьшая глубина.
[03:40.800 --> 03:48.800]  Ну, об этом чуть позже поговорим. Давайте пока рассмотрим непосредственно задачу LCA и как ее можно решать.
[03:48.800 --> 03:56.800]  Начну. Классическим решением здесь является решение с помощью так называемого метода двоичных подъемов.
[04:00.800 --> 04:10.800]  Метод двоичных подъемов. Так, в чем этот метод заключается?
[04:10.800 --> 04:18.800]  Ну, смотрите, давайте снова, нам дано некоторое дерево, нам дана вершина X, нам дана какая-то вершина Y,
[04:18.800 --> 04:26.800]  вот, тут есть какой-то путь, тут есть какой-то путь, и вот есть некоторый общий путь, нужно найти вот эту вершину.
[04:27.800 --> 04:35.800]  Значит, в чем будет заключаться идея? Давайте для каждой вершины будем дополнительно хранить глубину, на которой она находится.
[04:36.800 --> 04:54.800]  То есть первый шаг для каждой вершины, посчитаем ее глубину.
[04:54.800 --> 05:02.800]  На самом деле это сделать несложно, я думаю, ну, то есть это может делать рекурсивно.
[05:02.800 --> 05:08.800]  Понимаете, просто спускаемся от корня до детей, у детей делаем глубину на один больше, чем у родителей, ну и так далее.
[05:08.800 --> 05:20.800]  Ну, то есть формулы пересчета, я думаю, давайте напишем D от X, это просто есть D от P от X плюс 1,
[05:20.800 --> 05:32.800]  ну, где P от X это родитель X, ну и D от корня будем полагать равным нулю.
[05:32.800 --> 05:40.800]  Ну, хорошо, для каждой вершины посчитали ее глубину, то есть вот у нас есть вершина X находится на глубине D от X,
[05:40.800 --> 05:46.800]  есть вершина Y, которая находится на глубине D от Y.
[05:46.800 --> 05:52.800]  Ну и метод двоичных подъемов на самом деле очень похож на такой, на метод двоичного поиска, то есть на бинарный поиск,
[05:52.800 --> 05:59.800]  бинарные подъемы и бинарный поиск. Что говорит бинарный поиск? Давайте возьмем и прыгнем на какую-то степень двойки,
[05:59.800 --> 06:04.800]  нарежем наш общий мастив пополам и попробуем посмотреть туда, попали мы куда нужно или нет.
[06:04.800 --> 06:08.800]  Ну и вместо того, попали мы куда нужно или нет, мы будем там идти либо влево, либо вправо.
[06:08.800 --> 06:22.800]  Вот давайте попробуем что-то подобное придумать здесь. Вот давайте предположим, пусть D от X совпадает D от Y, ну для простоты.
[06:22.800 --> 06:29.800]  Вот есть вершины Y, есть вершины X, они находятся на одной глубине. Что можно придумать?
[06:29.800 --> 06:36.800]  Ну вот давайте допустим мы каким-то образом, пока неизвестно каким, но умеем из какой-то вершины подниматься сразу на несколько шагов наверх, за единицу.
[06:36.800 --> 06:41.800]  Вот допустим мы из X-а можем прыгнуть сразу сюда и из Y тоже можем прыгнуть сразу сюда.
[06:41.800 --> 06:48.800]  И мы попали в какую-то такую вершину, то есть вершину, в которой прыжок из X и прыжок из Y совпадает.
[06:48.800 --> 06:53.800]  Что можно сказать про эту вершину? Является она ответом или нет?
[06:53.800 --> 06:57.800]  Ну в данном случае нет, но вообще говоря, может являться ответом.
[06:57.800 --> 07:05.800]  Но вообще говоря, тот факт, что мы попали в одну и ту же вершину из X-а и из Y, не дает никакой информации о том, является ответом или нет.
[07:05.800 --> 07:08.800]  То есть это может являться ответом, а может не являться ответом.
[07:08.800 --> 07:17.800]  А что если я прыгну, скажем, вот куда-то сюда? Я прыгнул сюда и прыгнул сюда. Есть у меня какая-то определенность или нет?
[07:17.800 --> 07:22.800]  Да, вот тут уже есть некоторая определенность, то есть я точно знаю, что тут ответа нет.
[07:22.800 --> 07:26.800]  Поэтому идея будет заключаться в следующем.
[07:26.800 --> 07:37.800]  Давайте будем искать самый длинный прыжок такой, что, грубо говоря, у меня вот эти родители, родители X-а и родители Y, не совпадают.
[07:37.800 --> 07:42.800]  Потому что если они совпадают, то у меня нет никакой информации о том, попал я куда нужно или нет.
[07:42.800 --> 07:50.800]  Дальше я постараюсь сделать как можно более длинный прыжок отсюда, по родителям, так, чтобы у меня снова эти родители не совпадали.
[07:50.800 --> 07:57.800]  Ну и так далее. И вот в тот момент, когда я не смогу сделать такой прыжок, допустим, здесь, что это будет означать?
[07:57.800 --> 08:01.800]  Это означает, что я нашел самых первых родителей, которые не совпадают.
[08:01.800 --> 08:06.800]  Это значит, что их родители это и есть общий предок. Согласны?
[08:06.800 --> 08:08.800]  Ну план такой.
[08:08.800 --> 08:16.800]  Теперь как мы будем реализовывать? И вообще, как мы можем прыгать на произвольное расстояние, скажем, не за линейное время?
[08:16.800 --> 08:34.800]  Ну давайте вторым пунктом посчитаем. Для любой вершины V посчитаем следующую характеристику.
[08:34.800 --> 08:53.800]  Это будет родитель, который находится на расстоянии 2 степняка шагов вверх.
[08:53.800 --> 09:05.800]  Нам будет достаточно хранить не всевозможные прыжки, то есть прыжок на 1, прыжок на 2, прыжок на 3, то есть это слишком дорого.
[09:05.800 --> 09:10.800]  То есть у нас получится квадратичное сложение, если мы для каждой вершины хранили всевозможные прыжки.
[09:10.800 --> 09:15.800]  Так вот идея заключается в том, что давайте для каждой вершины хранить всего лишь логарифмическое количество прыжков,
[09:15.800 --> 09:18.800]  ровно так, как мы это делали в разреженной таблице.
[09:18.800 --> 09:23.800]  Так что для каждой вершины будем знать, куда мы попадем, если мы прыгнем на 1 шаг, на 2 шага, на 4 шага и так далее.
[09:23.800 --> 09:29.800]  Как посчитать эту характеристику? На самом деле тоже очень просто, по сути как вот эту рекуррентную.
[09:29.800 --> 09:45.800]  Как будем считать? Ну, во-первых, понятно, что для любой вершины v, v.up от 0, чему будет равно?
[09:45.800 --> 09:54.800]  Чему равен прыжок на 2 в степень 0 из любой вершины? Да, это просто родители этой вершины.
[09:55.800 --> 10:03.800]  Если v.parent. То есть это такая некоторая база индукции. Для 0 мы знаем, как все посчитать.
[10:03.800 --> 10:10.800]  Теперь, если мне хочется посчитать, куда я прыгну, если я буду...
[10:10.800 --> 10:17.800]  То есть характеристику v.up от k. То есть куда я попаду, если я буду прыгать на 2 степень k шагов вверх.
[10:17.800 --> 10:22.800]  Ну, допустим, я посчитал все это для всех k штрих меньше, чем k.
[10:25.800 --> 10:37.800]  Прилагается взять v.up от k-1 и parent. Похоже на правду?
[10:37.800 --> 10:45.800]  Но кажется, что нет. Что вот это означает? То, что здесь написано.
[10:45.800 --> 10:52.800]  Вот мы находимся в вершине v. То есть мы хотим попасть вот куда-то сюда. То есть 2 в степень k.
[10:52.800 --> 10:59.800]  v.up от k-1 мы попадаем вот сюда. Если мы берем parent, то мы падаем вот только сюда.
[10:59.800 --> 11:06.800]  Что нужно сделать? Да, еще раз вызвать v.up от k-1.
[11:06.800 --> 11:11.800]  То есть если у нас v.up от k-1 уже посчитано, то нам вот эта штука вернет некоторую вершину.
[11:11.800 --> 11:17.800]  Из этой вершины нам нужно снова прыгнуть на 2 степень k-1 шаг наверх.
[11:17.800 --> 11:26.800]  То есть точка v.up от k-1.
[11:26.800 --> 11:34.800]  Ну и понятно, что это тоже можно посчитать рекурсивно, так как если вы находитесь на каком-то пути до вершины v,
[11:34.800 --> 11:40.800]  если вы рекурсивно запускаетесь от каждой вершины, то в тот момент, когда вы будете вызываться от вершины v,
[11:40.800 --> 11:44.800]  все остальные характеристики.up на этом пути будут уже посчитаны.
[11:44.800 --> 11:51.800]  Поэтому мы корректно можем вызывать как up от k-1 для этой вершины, так как по предположению индукции мы для всех меньших k уже все посчитали.
[11:51.800 --> 11:55.800]  То есть мы корректно сможем вот для этой вершины, в которой мы пойдем тоже посчитать, точнее тоже вызвать,
[11:55.800 --> 11:59.800]  а под k-1 он тоже будет посчитан.
[11:59.800 --> 12:02.800]  То есть это мы научились прыгать из произвольной вершины.
[12:02.800 --> 12:09.800]  Давайте тут напишем, что это тоже занимает уатен, но это естественно тоже занимает линейное время.
[12:09.800 --> 12:14.800]  То есть за линейное время мы научились, во-первых, считать глубину каждого элемента,
[12:14.800 --> 12:19.800]  во-вторых, прыгать на степень двойки из каждой вершины.
[12:19.800 --> 12:22.800]  Так, давайте сюда.
[12:28.800 --> 12:31.800]  Ну и третий шаг.
[12:31.800 --> 12:34.800]  Давайте уже алгоритм напишем.
[12:36.800 --> 12:44.800]  LCA от x, y.
[12:45.800 --> 12:57.800]  Так, ну смотрите, я писал некоторым образом алгоритм или идею алгоритма в случае, когда у меня глубина вершины x и глубина вершины y совпадает.
[12:57.800 --> 13:09.800]  Но жизнь устроена немного сложнее, и вообще говоря, глубина y и глубина x могут отличаться.
[13:09.800 --> 13:13.800]  Что можно сделать в этом случае? Как будем действовать?
[13:14.800 --> 13:19.800]  Да, поднимем y на высоту x, отлично.
[13:19.800 --> 13:24.800]  Ну вы согласны, что на какой бы глубине у меня находился y здесь,
[13:24.800 --> 13:29.800]  я всегда могу залогрифмическое количество шагов поднять до вот той же самой глубины?
[13:29.800 --> 13:31.800]  Согласны?
[13:31.800 --> 13:36.800]  Поэтому давайте напишем следующую вещь.
[13:38.800 --> 13:41.800]  Давайте напишем так.
[13:44.800 --> 13:52.800]  Давайте так, если d от x больше, чем d от y,
[13:52.800 --> 14:00.800]  то сделаем swap x, y, чтобы в y всегда находилась наиболее глубокая вершина.
[14:00.800 --> 14:04.800]  Ну а далее, давайте я так напишу,
[14:04.800 --> 14:18.800]  up y равно up от y на d от y минус dx.
[14:19.800 --> 14:35.800]  Это поднять y на dy минус dx шагов вверх.
[14:38.800 --> 14:43.800]  Все понимают, что эта строчка может быть выполнена залогрифмическое время, или расписать.
[14:43.800 --> 14:48.800]  Верите ли вы, что если вы знаете, на какое количество шагов вам нужно прыгнуть,
[14:48.800 --> 14:52.800]  имея прыжки два степенника, имея прыжки размера степени двойки,
[14:52.800 --> 14:55.800]  вы всегда залогрифмическое количество шагов сможете тогда прыгнуть.
[14:55.800 --> 15:01.800]  Ну просто как бы раскладываете вот эти числа по степеням двойки и вот прыгаете на эти шаги.
[15:01.800 --> 15:05.800]  Таким образом, вот здесь мы уже гарантировали, вот на этом уровне,
[15:05.800 --> 15:10.800]  мы гарантировали, что d от y обязательно совпадает с d от x.
[15:10.800 --> 15:18.800]  Ну отлично, осталось теперь реализовать вон ту идею, про которую мы говорили, что мы делали.
[15:18.800 --> 15:30.800]  Ну во-первых, если x уже совпадает с y, то в этом случае мы уже можем вернуть x или y.
[15:30.800 --> 15:38.800]  То есть если вершины совпадают, то в принципе самый низкий общий предок это есть одна из этих вершин.
[15:40.800 --> 15:43.800]  Вот, а далее сделаем следующую вещь.
[15:46.800 --> 16:00.800]  Давайте сделаем так, for k целая часть логарифма n до нуля.
[16:00.800 --> 16:24.800]  Если x.up от k не равно y.up от k, то я перехожу в эти самые вершины.
[16:30.800 --> 16:38.800]  Вот. Что здесь происходит?
[16:38.800 --> 16:41.800]  Ну по сути здесь происходит перебор, давайте здесь нарисую.
[16:41.800 --> 16:51.800]  По сути здесь как раз происходит перебор прыжков, на которые я могу прыгнуть.
[16:51.800 --> 17:00.800]  Ну то есть снова есть некоторый путь. Есть x, есть y.
[17:00.800 --> 17:04.800]  И я пытаюсь прыгнуть, начиная с наиболее возможного прыжка.
[17:04.800 --> 17:12.800]  Понятно, что если у вас в дереве всего n элементов, то самый длинный прыжок, который вы можете сделать, это вот k равное логарифму двоичного n.
[17:12.800 --> 17:15.800]  То есть мы пытаемся сделать самый длинный прыжок.
[17:15.800 --> 17:29.800]  Ну и дальше уменьшаем этот самый прыжок до тех пор, пока мы не встретим различающиеся вершины.
[17:29.800 --> 17:33.800]  Ну вот ровно здесь это и написано. То есть мы берем самый длинный прыжок.
[17:33.800 --> 17:39.800]  Если то, куда мы попали из x и из y не совпадает, то это значит, что этот уровень нас устраивает, и мы идем дальше.
[17:40.800 --> 17:44.800]  Возникает вопрос, что у меня тут цикл вроде как один.
[17:44.800 --> 17:56.800]  То есть допустим я в какой-то момент для какого-то k' нашел хороший прыжок для x и хороший прыжок для y.
[17:56.800 --> 18:02.800]  Что произойдет у меня на следующей террации? На следующей террации я буду рассматривать k равное k'-1.
[18:02.800 --> 18:07.800]  Вопрос, а не нужно ли мне заново начинать этот цикл?
[18:07.800 --> 18:15.800]  Ну в принципе теоретически я, наверное, могу взять какой-то вот такой прыжок, у которого k больше, чем k', и попасть в какую-то хорошую точку.
[18:15.800 --> 18:17.800]  Или нет?
[18:23.800 --> 18:34.800]  Да, смотрите. То есть смотрите, если у меня какой-то k', вот тут устраивает, то значит на следующей террации k' и все большие элементы k' меня устраивать не будут.
[18:34.800 --> 18:38.800]  Поэтому следующий как, который мне нужно рассматривать, это k'-1. Почему это так?
[18:38.800 --> 18:40.800]  Ну, смотрите.
[18:44.800 --> 18:47.800]  Вот смотрите, что означает, что меня k' в прошлый раз устроил?
[18:47.800 --> 19:01.800]  Это значит, что когда я прыгал на k', это был первый прыжок, первый по величине прыжок, ну то есть наибольший прыжок, на который я могу прыгнуть,
[19:01.800 --> 19:05.800]  так что я не выхожу за пределы вот этого неравенства.
[19:05.800 --> 19:09.800]  То есть это наибольший прыжок, который меня не выводит вот на этот путь.
[19:09.800 --> 19:15.800]  Ну это значит, что какой-то прыжок больше длины k'-1 попадал куда-то сюда.
[19:19.800 --> 19:22.800]  Зафиксировали. Теперь я попал сюда.
[19:23.800 --> 19:28.800]  Почему на следующей террации мне не имеет смысла рассматривать прыжок на k', на k' и больше?
[19:29.800 --> 19:33.800]  Ну потому что если я отсюда прыгну на k', то я тоже попаду вот сюда.
[19:33.800 --> 19:35.800]  А эту точку я уже рассматривал.
[19:37.800 --> 19:44.800]  Поэтому следующий как, который я должен рассматривать отсюда, это, как минимум, k'-1.
[19:46.800 --> 19:47.800]  Понятно?
[19:49.800 --> 19:51.800]  Поэтому я обхожусь одним циклом.
[19:51.800 --> 19:56.800]  То есть я одним циклом просто спускаю k от логарифма двоечного n до 0
[19:56.800 --> 19:59.800]  и обновляю x и y при необходимости.
[20:04.800 --> 20:06.800]  Ну и что у меня получится в конце?
[20:06.800 --> 20:08.800]  Что у меня получится в конце, когда я закончил этот цикл?
[20:08.800 --> 20:09.800]  Что мне нужно вернуть?
[20:22.800 --> 20:24.800]  Ну вот, я что делал?
[20:25.800 --> 20:30.800]  Я пропрыгал всевозможными прыжками
[20:33.800 --> 20:35.800]  и дошел до какой-то точки.
[20:36.800 --> 20:38.800]  Слева и справа.
[20:44.800 --> 20:49.800]  Вот, при этом последний прыжок у меня был наименее возможный,
[20:49.800 --> 20:51.800]  так, чтобы у меня все вершины не совпадали.
[20:51.800 --> 20:53.800]  То есть, что я рассматривал в качестве последнего шага?
[20:53.800 --> 21:00.800]  В качестве последнего шага у меня был k'0.
[21:00.800 --> 21:05.800]  То есть, точнее так, у меня были последние шаги k'1, k'2 и так далее.
[21:06.800 --> 21:08.800]  Что это означает?
[21:09.800 --> 21:17.800]  Это означает, что я наиболее близким образом подошел к наименьшему общему предку.
[21:19.800 --> 21:21.800]  То есть, если бы я мог еще ближе подойти,
[21:21.800 --> 21:25.800]  то я бы смог прыгнуть на какое-то большее количество шагов и так далее.
[21:25.800 --> 21:27.800]  Но так как я все k рассмотрел,
[21:27.800 --> 21:29.800]  то это означает, что я вот это расстояние,
[21:29.800 --> 21:31.800]  по сути, вот это расстояние d,
[21:31.800 --> 21:33.800]  я как раз разбил по степеням двойки.
[21:34.800 --> 21:36.800]  Но так как любое число я могу покрыть степенями двойки,
[21:36.800 --> 21:39.800]  то это означает, что я как раз дошел до нужного места.
[21:41.800 --> 21:43.800]  Тогда что мне нужно вернуть в качестве ответа?
[21:45.800 --> 21:47.800]  Ну, x parent.
[21:49.800 --> 21:51.800]  Да?
[21:51.800 --> 21:53.800]  Ну, или x parent, или y parent.
[21:55.800 --> 21:59.800]  Ну почему? Потому что этот цикл мне всегда приводит в вершину,
[21:59.800 --> 22:03.800]  в которую у меня x не совпадает с y.
[22:07.800 --> 22:10.800]  Ну и плюс вот таким вот двоичным подъемом я дошел до точки,
[22:10.800 --> 22:12.800]  точнее, до наиболее высокой точки,
[22:12.800 --> 22:14.800]  ну или точнее так, наиболее низкой точки,
[22:14.800 --> 22:17.800]  в которую у меня родитель x и родитель y расходятся.
[22:17.800 --> 22:19.800]  Но раз это наиболее низкая точка,
[22:19.800 --> 22:21.800]  в которой x и y расходятся,
[22:21.800 --> 22:23.800]  это значит, что точка выше
[22:23.800 --> 22:25.800]  обязательно склеивает x и y вместе.
[22:25.800 --> 22:27.800]  Согласны?
[22:27.800 --> 22:29.800]  Разумно?
[22:33.800 --> 22:35.800]  Ну вот.
[22:35.800 --> 22:37.800]  В этом заключается алгоритм двоичного подъема.
[22:37.800 --> 22:39.800]  Ну и понятно, что
[22:41.800 --> 22:43.800]  сам вот этот цикл
[22:43.800 --> 22:45.800]  работает за алгоритмическое время,
[22:45.800 --> 22:47.800]  плюс из вершины y
[22:47.800 --> 22:49.800]  на произвольное количество шагов
[22:49.800 --> 22:51.800]  мы поднимаемся тоже
[22:51.800 --> 22:53.800]  за алгоритмическое время,
[22:53.800 --> 22:55.800]  поэтому
[22:55.800 --> 22:57.800]  в общее время запроса
[22:57.800 --> 22:59.800]  есть алгоритм n.
[22:59.800 --> 23:01.800]  Вот.
[23:03.800 --> 23:05.800]  Да.
[23:13.800 --> 23:15.800]  Ну да, на самом деле достаточно алгоритма,
[23:15.800 --> 23:17.800]  но давайте предполагать, что если такого прыжка нет,
[23:17.800 --> 23:19.800]  то там
[23:19.800 --> 23:21.800]  ну там либо 0 птр,
[23:21.800 --> 23:23.800]  либо просто корень и так далее.
[23:23.800 --> 23:25.800]  Ну да, ну в принципе понятно, что
[23:25.800 --> 23:27.800]  вот тут можно начинать
[23:27.800 --> 23:29.800]  с алгоритма d,
[23:29.800 --> 23:31.800]  где d это вот глубина x.
[23:31.800 --> 23:33.800]  Ну это неважно, на симпатику не влияет.
[23:33.800 --> 23:35.800]  Вот.
[23:35.800 --> 23:37.800]  Еще вопросы?
[23:45.800 --> 23:47.800]  А как это может быть?
[23:47.800 --> 23:49.800]  Давайте рассмотрим, ну смотрите.
[23:51.800 --> 23:53.800]  Давайте
[23:53.800 --> 23:55.800]  ну вот общий предок,
[23:55.800 --> 23:57.800]  и вот тут какой-то путь до x,
[23:57.800 --> 23:59.800]  и вот тут какой-то путь
[23:59.800 --> 24:01.800]  до y.
[24:01.800 --> 24:03.800]  Ну вот пусть
[24:03.800 --> 24:05.800]  длина от x до
[24:05.800 --> 24:07.800]  вот этого элемента,
[24:07.800 --> 24:09.800]  не знаю какая,
[24:09.800 --> 24:11.800]  ну d пусть будет.
[24:11.800 --> 24:13.800]  И тут тоже d.
[24:13.800 --> 24:15.800]  Ну то есть мы это гарантировали
[24:15.800 --> 24:17.800]  вот этой строчкой.
[24:17.800 --> 24:19.800]  Что по сути делает этот цикл?
[24:19.800 --> 24:21.800]  Ну этот цикл по сути раскладывает
[24:21.800 --> 24:23.800]  d по степням двойки.
[24:23.800 --> 24:25.800]  То есть мы сначала ищем
[24:25.800 --> 24:27.800]  наибольшую степень двойки,
[24:27.800 --> 24:29.800]  которая меньше, чем d.
[24:29.800 --> 24:31.800]  То есть если d имеет какое-то там
[24:31.800 --> 24:33.800]  битовое представление,
[24:33.800 --> 24:35.800]  то мы сначала найдем вот эту единицу.
[24:35.800 --> 24:37.800]  Потом мы спускаемся по k,
[24:37.800 --> 24:39.800]  находим вот эту единицу.
[24:39.800 --> 24:41.800]  То есть находим минимальную степень двойки,
[24:41.800 --> 24:43.800]  которая вот нас приводит в d.
[24:43.800 --> 24:45.800]  Ну и так далее.
[24:45.800 --> 24:47.800]  Ну так как у нас есть 2 степени k,
[24:47.800 --> 24:49.800]  давайте ка 0,
[24:49.800 --> 24:51.800]  плюс 2 степень k1 и так далее,
[24:51.800 --> 24:53.800]  вот все эти ка мы находим.
[24:53.800 --> 24:55.800]  Но это означает, что в конце мы в любом случае придем вот сюда.
[24:55.800 --> 24:57.800]  Ну собственно цикл так устроен.
[24:59.800 --> 25:01.800]  Поэтому для любого d
[25:01.800 --> 25:03.800]  мы попадем туда, куда надо.
[25:07.800 --> 25:09.800]  Еще.
[25:15.800 --> 25:17.800]  Ну окей.
[25:19.800 --> 25:21.800]  Так.
[25:21.800 --> 25:23.800]  Ну в общем-то,
[25:23.800 --> 25:25.800]  что касается классического
[25:25.800 --> 25:27.800]  решения задачи LCA,
[25:29.800 --> 25:31.800]  мне сказать вам больше нечего.
[25:31.800 --> 25:33.800]  В принципе есть и другие алгоритмы,
[25:33.800 --> 25:35.800]  но я думаю этого достаточно.
[25:35.800 --> 25:37.800]  То есть он линейный,
[25:37.800 --> 25:39.800]  он делает запрос в логографическое время и так далее.
[25:39.800 --> 25:41.800]  Возможно в следующем симметре,
[25:41.800 --> 25:43.800]  когда мы будем говорить про графы,
[25:43.800 --> 25:45.800]  ну с некоторыми из вас,
[25:45.800 --> 25:47.800]  мы поговорим про какие-то другие алгоритмы,
[25:47.800 --> 25:49.800]  использовать другие идеи,
[25:49.800 --> 25:51.800]  о которых мы как раз в следующем симметре поговорим.
[25:51.800 --> 25:53.800]  А сейчас давайте перейдем
[25:53.800 --> 25:55.800]  к вот какому вопросу.
[25:57.800 --> 25:59.800]  Поговорим о тесной связи задачи LCA
[25:59.800 --> 26:01.800]  и задачи RMQ.
[26:01.800 --> 26:03.800]  Значит пункт
[26:03.800 --> 26:05.800]  связь
[26:05.800 --> 26:07.800]  RMQ
[26:07.800 --> 26:09.800]  и LCA.
[26:09.800 --> 26:11.800]  Да, я кстати не сделал анонс.
[26:11.800 --> 26:13.800]  Вообще говоря, по идее,
[26:13.800 --> 26:15.800]  если мы успеем,
[26:15.800 --> 26:17.800]  хочется прийти к тому,
[26:17.800 --> 26:19.800]  что я обещал на первой лекции посещенное RMQ,
[26:19.800 --> 26:21.800]  а именно решение сдачи RMQ
[26:21.800 --> 26:23.800]  статической за линейное время
[26:23.800 --> 26:25.800]  и за единичный запрос.
[26:25.800 --> 26:27.800]  То есть если вы помните, когда мы рассматривали разреженную таблицу,
[26:27.800 --> 26:29.800]  там, ну во-первых, классическая разреженная таблица,
[26:29.800 --> 26:31.800]  она работает за n log n и
[26:31.800 --> 26:33.800]  с запросом за единицу,
[26:33.800 --> 26:35.800]  мы смогли ее улучшить там до, давайте,
[26:35.800 --> 26:37.800]  у нас было n log n,
[26:37.800 --> 26:39.800]  и вот единица потом,
[26:39.800 --> 26:41.800]  нам удалось ее улучшить
[26:41.800 --> 26:43.800]  за O от n,
[26:43.800 --> 26:45.800]  и вот логарифма n,
[26:45.800 --> 26:47.800]  и в конце
[26:47.800 --> 26:49.800]  у нас был
[26:49.800 --> 26:51.800]  log log n,
[26:51.800 --> 26:53.800]  и вот единица.
[26:53.800 --> 26:55.800]  Вот.
[26:55.800 --> 26:57.800]  Ну вот сегодня
[26:57.800 --> 26:59.800]  я стремлюсь к тому, чтобы
[26:59.800 --> 27:01.800]  рассказать некоторый алгоритм, который работает
[27:01.800 --> 27:03.800]  вот так, то есть
[27:03.800 --> 27:05.800]  наиболее эффективным образом.
[27:05.800 --> 27:07.800]  Понятное дело, что быстрее нельзя.
[27:07.800 --> 27:09.800]  Если у вас есть массив размера n, то быстрее, чем за n,
[27:09.800 --> 27:11.800]  вы его не сможете обработать, ну и плюс запросы быстрее, чем за константа
[27:11.800 --> 27:13.800]  и права это нельзя.
[27:13.800 --> 27:15.800]  Удивительным образом оказывается, что это можно сделать,
[27:15.800 --> 27:17.800]  если усмотреть некоторую связь
[27:17.800 --> 27:19.800]  с задачей RMQ и задачей LCA.
[27:19.800 --> 27:21.800]  Вот, давайте о ней поговорим.
[27:25.800 --> 27:27.800]  Так.
[27:27.800 --> 27:29.800]  Давайте для начала,
[27:29.800 --> 27:31.800]  не знаю, давайте, например, для начала
[27:31.800 --> 27:33.800]  покажем, что
[27:33.800 --> 27:35.800]  задачу RMQ
[27:35.800 --> 27:37.800]  можно свести к задачей LCA.
[27:41.800 --> 27:43.800]  Ну то есть, допустим, вы пропустили
[27:43.800 --> 27:45.800]  все прошлые лекции,
[27:45.800 --> 27:47.800]  вот, и только сейчас узнали про LCA.
[27:47.800 --> 27:49.800]  Вот.
[27:49.800 --> 27:51.800]  И а у вас в контесте задача только на RMQ.
[27:51.800 --> 27:53.800]  Так вот, любую задачу RMQ
[27:53.800 --> 27:55.800]  вы можете решить с помощью алгоритма,
[27:55.800 --> 27:57.800]  который решает LCA. Вот.
[27:57.800 --> 27:59.800]  А как это можно сделать?
[27:59.800 --> 28:01.800]  Ну, смотрите, что мне дано в задаче RMQ?
[28:01.800 --> 28:03.800]  Ну, в задаче RMQ мне дано некоторый массив,
[28:03.800 --> 28:05.800]  там, не знаю, а0,
[28:05.800 --> 28:07.800]  1,
[28:07.800 --> 28:09.800]  а2 и так далее, аi-1.
[28:09.800 --> 28:11.800]  Вот.
[28:11.800 --> 28:13.800]  Мне нужно отвечать на запрос,
[28:13.800 --> 28:15.800]  вида, найти минимум
[28:15.800 --> 28:17.800]  на отрезке от L до R.
[28:17.800 --> 28:19.800]  Вот.
[28:19.800 --> 28:21.800]  Как умею решать LCA?
[28:21.800 --> 28:23.800]  Решить эту задачу.
[28:23.800 --> 28:25.800]  Так вот,
[28:25.800 --> 28:27.800]  внезапно нам потребуется
[28:27.800 --> 28:29.800]  декартово дерево.
[28:29.800 --> 28:31.800]  Значит, давайте возьмем
[28:31.800 --> 28:33.800]  и
[28:35.800 --> 28:37.800]  построим
[28:37.800 --> 28:39.800]  декартово дерево
[28:39.800 --> 28:41.800]  по неявному ключу.
[28:45.800 --> 28:47.800]  Ну, или,
[28:47.800 --> 28:49.800]  если вас не устраивает неявный ключ,
[28:49.800 --> 28:51.800]  то вам можно просто взять
[28:51.800 --> 28:55.800]  или с ключами
[28:55.800 --> 28:57.800]  индексами массива.
[29:07.800 --> 29:09.800]  А
[29:09.800 --> 29:11.800]  с приоритетами
[29:15.800 --> 29:17.800]  yi
[29:17.800 --> 29:19.800]  равными ai.
[29:21.800 --> 29:23.800]  Ну, то есть, возьмем и построим декартово дерево
[29:23.800 --> 29:25.800]  на следующих парах.
[29:25.800 --> 29:27.800]  Ну, то есть, на парах 0,
[29:27.800 --> 29:29.800]  а0, на парах 1,
[29:29.800 --> 29:31.800]  а1, ну и так далее.
[29:31.800 --> 29:33.800]  n-1,
[29:33.800 --> 29:35.800]  an-1.
[29:35.800 --> 29:37.800]  Ну, так как ключи у нас индексы,
[29:37.800 --> 29:39.800]  то в принципе индексы можем опустить.
[29:39.800 --> 29:41.800]  В прошлый раз обсуждали, что эта идея называется
[29:41.800 --> 29:43.800]  декартово дерево по неявному ключу.
[29:43.800 --> 29:45.800]  Давайте построим такое декартово дерево.
[29:45.800 --> 29:47.800]  Что у нас получится?
[29:47.800 --> 29:49.800]  Получится какое-то
[29:51.800 --> 29:53.800]  дерево.
[29:55.800 --> 29:57.800]  Вот.
[29:57.800 --> 29:59.800]  То есть, спроецируем
[29:59.800 --> 30:01.800]  на ось
[30:03.800 --> 30:05.800]  на ось x.
[30:07.800 --> 30:09.800]  То есть, это нулевой элемент.
[30:09.800 --> 30:11.800]  Это первый, второй, третий,
[30:11.800 --> 30:13.800]  четвертый, пятый, шестой,
[30:13.800 --> 30:15.800]  седьмой.
[30:15.800 --> 30:17.800]  Ну, а здесь написаны, собственно, значения нашего массива.
[30:17.800 --> 30:19.800]  Значения вот этого массива.
[30:19.800 --> 30:21.800]  Ну, и эти значения массива
[30:21.800 --> 30:23.800]  мы полагаем,
[30:23.800 --> 30:25.800]  точнее, эти значения массива
[30:25.800 --> 30:27.800]  мы используем в качестве приоритетов.
[30:27.800 --> 30:29.800]  В качестве значений, а именно в качестве приоритетов.
[30:29.800 --> 30:31.800]  Например, один, два,
[30:31.800 --> 30:33.800]  три, четыре,
[30:33.800 --> 30:35.800]  пять, шесть, семь,
[30:35.800 --> 30:37.800]  восемь. Это приоритеты.
[30:41.800 --> 30:43.800]  Вот.
[30:43.800 --> 30:45.800]  И на самом деле уже
[30:45.800 --> 30:47.800]  видна некоторая структура.
[30:47.800 --> 30:49.800]  Что мы знаем про декартово дерево?
[30:49.800 --> 30:51.800]  Что у нас находится в корне любого поддерева?
[30:53.800 --> 30:55.800]  Нам дано некоторое поддерево.
[30:55.800 --> 30:57.800]  Например, вот это.
[30:57.800 --> 30:59.800]  Что мы знаем про его корень?
[31:01.800 --> 31:03.800]  Нет, не в ту степь.
[31:03.800 --> 31:05.800]  Это произвольное декартово дерево без RMQ, RSQ.
[31:05.800 --> 31:07.800]  То есть, это декартово дерево, которое хранит...
[31:07.800 --> 31:09.800]  Ну, что такое декартово дерево? Давайте.
[31:09.800 --> 31:11.800]  Это структура данных,
[31:11.800 --> 31:13.800]  которая хранит ключи.
[31:13.800 --> 31:15.800]  В данном случае у нас декартово дерево по дневному ключу
[31:15.800 --> 31:17.800]  и хранит приоритеты.
[31:17.800 --> 31:19.800]  По приоритетам оно является чем?
[31:19.800 --> 31:21.800]  Бинарной пирамидой
[31:21.800 --> 31:23.800]  с минимумом в корне.
[31:23.800 --> 31:25.800]  В корне любого поддерева хранится минимум.
[31:27.800 --> 31:29.800]  Все, то есть декартово дерево уже, по сути,
[31:29.800 --> 31:31.800]  обладает некоторой структурой,
[31:31.800 --> 31:33.800]  которая хороша для нашей задачи RMQ.
[31:33.800 --> 31:35.800]  То есть с задачи RMQ мы хотим находить минимумы.
[31:35.800 --> 31:37.800]  Соответственно, декартово дерево в корнях поддеревьев
[31:37.800 --> 31:39.800]  уже хранит минимальные элементы.
[31:41.800 --> 31:43.800]  Давайте разбираться как...
[31:45.800 --> 31:47.800]  Точнее, все, тут разбираться нечего.
[31:47.800 --> 31:49.800]  Мы, по сути, решили задачу.
[31:49.800 --> 31:51.800]  Утверждение заключается в следующем.
[31:51.800 --> 31:53.800]  Вот если мы так сделали,
[31:53.800 --> 31:57.800]  то утверждение такое...
[31:59.800 --> 32:01.800]  RMQ LR
[32:03.800 --> 32:07.800]  это то же самое, что LCA LR.
[32:07.800 --> 32:09.800]  То есть если я хочу найти минимум
[32:09.800 --> 32:13.800]  на отрезке от 0 до...
[32:13.800 --> 32:15.800]  от 1 до 3,
[32:15.800 --> 32:17.800]  то что мне нужно сделать?
[32:17.800 --> 32:19.800]  Мне нужно взять вершину
[32:19.800 --> 32:21.800]  с индексом 1,
[32:21.800 --> 32:23.800]  вершину с индексом 3
[32:23.800 --> 32:25.800]  и найти их LCA.
[32:27.800 --> 32:29.800]  Понятно?
[32:29.800 --> 32:31.800]  То есть запрос RMQ просто-напросто
[32:31.800 --> 32:33.800]  сводится к поиску LCA
[32:33.800 --> 32:35.800]  в декартовом дереве.
[32:35.800 --> 32:37.800]  Ну, давайте
[32:37.800 --> 32:39.800]  докажем, почему так.
[32:43.800 --> 32:45.800]  Ну, во-первых,
[32:45.800 --> 32:47.800]  что можно сказать?
[32:47.800 --> 32:51.800]  Давайте обозначим LCA LR
[32:53.800 --> 32:55.800]  какой-то буквой,
[32:55.800 --> 32:57.800]  не знаю, L, L маленькой.
[32:57.800 --> 32:59.800]  Вот пусть L маленькая,
[32:59.800 --> 33:01.800]  это результат запроса LR.
[33:03.800 --> 33:05.800]  Это L большого.
[33:05.800 --> 33:07.800]  Что можно сказать про L?
[33:09.800 --> 33:11.800]  Так как L
[33:13.800 --> 33:15.800]  корень
[33:17.800 --> 33:19.800]  под дерево,
[33:25.800 --> 33:27.800]  так как L корень под дерево,
[33:27.800 --> 33:29.800]  то понятное дело,
[33:29.800 --> 33:31.800]  что L меньше равно, чем L маленькая,
[33:31.800 --> 33:33.800]  и это меньше равно, чем R большое.
[33:33.800 --> 33:35.800]  Ну, что это означает?
[33:35.800 --> 33:37.800]  Это означает, что, смотрите,
[33:37.800 --> 33:39.800]  буквально следующая вещь.
[33:39.800 --> 33:41.800]  Вот у вас есть LCA,
[33:41.800 --> 33:43.800]  у вас есть L, у вас есть R.
[33:43.800 --> 33:45.800]  При этом L большое находится влево
[33:45.800 --> 33:47.800]  и R большое находится в правом по дереве.
[33:47.800 --> 33:49.800]  Ну, а так у вас декартовое дерево
[33:49.800 --> 33:51.800]  является бинарным деревом поиска,
[33:51.800 --> 33:53.800]  то это означает, что L как раз таки зажата
[33:53.800 --> 33:55.800]  между этими двумя индексами.
[33:55.800 --> 33:57.800]  То есть этот элемент лежит на этом отрезке.
[33:57.800 --> 33:59.800]  В чем заключается корректность задачи RMQ?
[33:59.800 --> 34:01.800]  RMQ должен вам найти элемент,
[34:01.800 --> 34:03.800]  который находится именно в этом отрезке,
[34:03.800 --> 34:05.800]  и он должен быть минимальным
[34:05.800 --> 34:07.800]  среди всех элементов этого отрезка.
[34:07.800 --> 34:09.800]  Первый пункт мы уже гарантировали.
[34:09.800 --> 34:11.800]  То есть если мы нашли LCA,
[34:11.800 --> 34:13.800]  то этот узел обязательно находится
[34:13.800 --> 34:15.800]  в этом отрезке. Согласны?
[34:15.800 --> 34:17.800]  Ну так, это корень под дерево,
[34:17.800 --> 34:19.800]  в котором находятся элементы LR,
[34:19.800 --> 34:21.800]  и при этом LR находятся,
[34:21.800 --> 34:23.800]  вообще говоря, в разных под деревьях.
[34:25.800 --> 34:27.800]  Так, ну и теперь надо показать,
[34:27.800 --> 34:29.800]  что в L действительно хранится минимум
[34:29.800 --> 34:31.800]  на отрезке вот LDR.
[34:31.800 --> 34:33.800]  Ну, как выглядит L?
[34:33.800 --> 34:35.800]  Значит, вот есть где-то L большое,
[34:35.800 --> 34:37.800]  есть где-то R большое.
[34:37.800 --> 34:39.800]  Вот.
[34:41.800 --> 34:43.800]  И выглядит как-то все так.
[34:57.800 --> 34:59.800]  Значит,
[34:59.800 --> 35:01.800]  так как
[35:01.800 --> 35:03.800]  L корень
[35:07.800 --> 35:09.800]  по L точка Y
[35:11.800 --> 35:13.800]  минимален
[35:21.800 --> 35:23.800]  во всем под деревя L.
[35:23.800 --> 35:25.800]  А под дерева L
[35:29.800 --> 35:31.800]  содержит
[35:33.800 --> 35:35.800]  отрезок
[35:35.800 --> 35:37.800]  LDR.
[35:37.800 --> 35:39.800]  То есть понятно, что если у вас есть
[35:39.800 --> 35:41.800]  некоторое под дерево,
[35:41.800 --> 35:43.800]  и под дерево при этом содержит ключи L и R,
[35:43.800 --> 35:45.800]  то, понятное дело, что все промежуточные ключи
[35:45.800 --> 35:47.800]  тоже содержат под дерева L,
[35:47.800 --> 35:49.800]  а под дерева L содержат
[35:49.800 --> 35:51.800]  под дерева L и R.
[35:51.800 --> 35:53.800]  То, понятное дело, что все промежуточные ключи
[35:53.800 --> 35:55.800]  тоже лежат здесь.
[35:55.800 --> 35:57.800]  То есть не может быть такое, что элемент,
[35:57.800 --> 35:59.800]  который находится между L и R, находится где-то вот здесь
[35:59.800 --> 36:01.800]  или где-то вот здесь, ну где-то за пределами этого под дерева.
[36:01.800 --> 36:03.800]  Ну, это просто свой стабинарный дерево поиска.
[36:05.800 --> 36:07.800]  Поэтому L содержит полностью
[36:07.800 --> 36:09.800]  отрезок LR, ну и плюс, возможно, еще что-то.
[36:09.800 --> 36:11.800]  И при этом L, вот на этом всем
[36:11.800 --> 36:13.800]  большом отрезке, является минимум.
[36:13.800 --> 36:15.800]  Ну, соответственно, L является минимум и на этом отрезке.
[36:15.800 --> 36:17.800]  Согласны?
[36:17.800 --> 36:19.800]  Ну, все.
[36:19.800 --> 36:21.800]  Из этого следует.
[36:21.800 --> 36:23.800]  L
[36:23.800 --> 36:25.800]  является
[36:27.800 --> 36:29.800]  минимумом
[36:29.800 --> 36:31.800]  и на
[36:33.800 --> 36:35.800]  L и R.
[36:37.800 --> 36:39.800]  Ну, все.
[36:41.800 --> 36:43.800]  То есть, если мы рассмотрим LCA
[36:43.800 --> 36:45.800]  для L и R,
[36:45.800 --> 36:47.800]  то про этот LCA мы знаем,
[36:47.800 --> 36:49.800]  что он лежит в пределах L до R,
[36:49.800 --> 36:51.800]  так это корень этого под дерево,
[36:53.800 --> 36:55.800]  то есть вот этот элемент,
[36:55.800 --> 36:57.800]  ну, это элемент массива, лежит между L и R.
[36:57.800 --> 36:59.800]  Это, во-вторых.
[36:59.800 --> 37:01.800]  А, во-вторых, мы точно знаем, что это элемент минимальный,
[37:01.800 --> 37:03.800]  минимальный на этом отрезке. Почему?
[37:03.800 --> 37:05.800]  Потому что он минимальный во всем под дереве, а L и R
[37:05.800 --> 37:07.800]  целиком лежат в этом под дереве.
[37:07.800 --> 37:09.800]  L минимален и на этом отрезке.
[37:09.800 --> 37:34.800]  Вот так. Есть вопросы? Давайте еще раз поговорим. Что мы сделали? Мы свели задачу RMQ с задачей LCA.
[37:34.800 --> 37:39.800]  Как это делается? Во-первых, мы время еще не обсудили, давайте обсудим тоже параллельно.
[37:39.800 --> 37:46.800]  Что мы делаем? Во-первых, мы строим декартовое дерево по неявному ключу, ну или используя в качестве ключей индексы массива.
[37:46.800 --> 37:51.800]  Строить декартовое дерево мы умеем за линейное время, то есть в случае, когда у нас ключи отсортированы.
[37:51.800 --> 38:03.800]  Поэтому первый шаг занимает OT. На самом деле все. Весь припроцессник сводится к тому, что мы на этом массиве строим некоторое декартовое дерево.
[38:03.800 --> 38:08.800]  Дальше запрос. Ну а запрос показан здесь. За какое время он работает?
[38:08.800 --> 38:15.800]  За какое время работает этот запрос? Ну LCA, с самой задачей LCA мы умеем решать как минимум за долгорифмическое время.
[38:15.800 --> 38:22.800]  Ну поэтому запрос RMQ тоже будет работать за долгорифмическое время.
[38:22.800 --> 38:30.800]  То есть как выглядит запрос RMQ на массиве? Ну то есть если вам нужно найти минимум на массиве от LDR,
[38:30.800 --> 38:37.800]  то вы ищете узлы соответствующими индексами, ну допустим вот L и R.
[38:37.800 --> 38:41.800]  Дальше запускаете поиск LCA, ну например с помощью двоичных подъемов.
[38:41.800 --> 38:47.800]  Вот, находите эту вершину и смотрите, ну не знаю, либо приоритет этой вершины, если вам нужно само значение вернуть,
[38:47.800 --> 38:51.800]  либо индекс этой вершины, то есть какое увеличение вершины она является.
[38:51.800 --> 38:57.800]  Вот, соответственно, ну тогда находите индекс. Вот.
[38:57.800 --> 39:03.800]  Значит, вот так выглядит сведение задачи RMQ с задачей LCA.
[39:03.800 --> 39:16.800]  Следующий пункт, это сведение задачи LCA к задачи RMQ.
[39:16.800 --> 39:24.800]  Значит, допустим, вы пропустили пять минут первой лекции, а потом, в общем, наоборот, не пропустили первые пять минут, а потом все пропустили.
[39:24.800 --> 39:32.800]  Значит, как решить задачи LCA, если вы умеете решать задачу RMQ? Все тоже довольно просто.
[39:32.800 --> 39:37.800]  Смотрите, значит, в чем заключается постановка задачи LCA?
[39:37.800 --> 39:47.800]  Значит, у вас есть какое-то дерево. Вот какое-то дерево.
[39:47.800 --> 39:54.800]  И вам нужно для любой пары вершин уметь определять самого низкого общего предка.
[39:54.800 --> 39:56.800]  Как мы поступим? Поступим мы следующим образом.
[39:56.800 --> 40:06.800]  Во-первых, давайте снова, как и раньше, для каждой вершины посчитаем ее глубину.
[40:06.800 --> 40:24.800]  Давайте в качестве первого пункта посчитаем глубину вершин за линейное время.
[40:24.800 --> 40:32.800]  А дальше мы выполним... Вы же проходили всякий in-order, pre-order, post-order обходы графа?
[40:32.800 --> 40:37.800]  А вот тут мы выполним все order обход графа, то есть и post-order, и pre-order, и in-order.
[40:37.800 --> 40:43.800]  Давайте напомним краткое напоминание, что если у вас есть pre-order обход,
[40:43.800 --> 41:01.800]  то это означает, что вы условно делаете принт вершины, а потом рекурсивно обходите левую часть и pre-order.
[41:01.800 --> 41:07.800]  Обходите правую часть.
[41:07.800 --> 41:18.800]  Post-order это то же самое, но только принт вы делаете в конце.
[41:18.800 --> 41:24.800]  Сначала запускаете от левого сына, от правого сына, и потом вершину.
[41:24.800 --> 41:36.800]  Ну и in-order. Сначала обходите левого сына, потом печатаете саму вершину, а потом заходите в правого сына.
[41:36.800 --> 41:43.800]  Ну просто проходим в порядке. Есть какой-то естественный порядок на вершинах.
[41:43.800 --> 41:49.800]  Если у вас больше двух детей, то скорее всего вы их храните в отдельных полях или в массиве.
[41:49.800 --> 41:53.800]  Каким-то образом проходите.
[41:53.800 --> 42:01.800]  Ну короче говоря, в pre-order что происходит? Вы сначала обходите саму вершину, а потом в каком-то порядке обходите детей.
[42:01.800 --> 42:07.800]  В post-order вы сначала обходите детей, а потом обходите саму вершину.
[42:07.800 --> 42:11.800]  Это просто напоминание. Мы будем делать другую вещь.
[42:11.800 --> 42:19.800]  Мы будем выполнять сразу все обходы. В том смысле, что после каждого посещения ребенка мы будем посещать себя еще раз.
[42:19.800 --> 42:25.800]  Вообще этот обход называется либо Эйлеров обход, либо обход DFS.
[42:25.800 --> 42:34.800]  Давайте его называть Эйлеровым.
[42:34.800 --> 42:46.800]  Я напишу в случае бинарного дерева. В случае, когда у вас больше детей, вы просто вставите соответствующий обход между каждым вызовом от детей.
[42:46.800 --> 43:00.800]  То есть мы делаем print node, коротко напишу Эйлер от node left,
[43:00.800 --> 43:18.800]  потом print node, потом снова заходим уже в правого сына, ну и потом возвращаемся в себя же.
[43:18.800 --> 43:22.800]  Ну давайте схематично изобразим, как выглядит этот обход.
[43:22.800 --> 43:24.800]  И этот обход выглядит следующим образом.
[43:24.800 --> 43:34.800]  Ну сначала мы идем и посещаем вершину 0, рекурсивно запускаемся от единицы, ну точнее от левого сына.
[43:34.800 --> 43:38.800]  Печатаем единицу, рекурсивно запускаемся от левой части.
[43:38.800 --> 43:47.800]  Так, только тут надо, давайте пронумеруем вершины, это нам нужно, нам уже нужны номера вершин.
[43:47.800 --> 43:58.800]  Давайте так, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9.
[43:58.800 --> 44:00.800]  Вот еще раз, как выглядит обход?
[44:00.800 --> 44:05.800]  Ну смотрим, сначала стартуем с корня, пишем 0.
[44:05.800 --> 44:11.800]  Дальше спускаемся в левого сына, печатаем единицу, спускаемся еще раз в левого сына, печатаем четверку.
[44:11.800 --> 44:15.800]  Все, рекурсивный вызов закончился, выходим.
[44:15.800 --> 44:20.800]  Запускаемся от единицы, а точнее вот вернулись единицу снова.
[44:20.800 --> 44:27.800]  После того как мы закончили рекурсивный вызов, мы снова печатаем ту же самую вершину.
[44:27.800 --> 44:29.800]  То есть снова печатаем единицу.
[44:29.800 --> 44:35.800]  Идем вправо, печатаем двойку, то есть обход выглядит как-то вот так.
[44:35.800 --> 44:40.800]  То есть спустились двойку, грубо говоря мы будем дерево обходить вот так по контуру.
[44:40.800 --> 44:43.800]  То есть Эллеров...
[44:43.800 --> 44:45.800]  Что?
[44:45.800 --> 44:48.800]  Да, пятерку надо печатать.
[44:48.800 --> 44:52.800]  То есть Эллеров обход, он грубо говоря обходит дерево вот так вот по контуру.
[44:52.800 --> 44:58.800]  То есть вы сначала спускаетесь по левым детям, потом идете вправо, возвращаетесь снова в родителя.
[44:58.800 --> 45:00.800]  Давайте допишем.
[45:00.800 --> 45:04.800]  Давайте здесь будем писать.
[45:04.800 --> 45:08.800]  0, 1, 4, 1, 5.
[45:08.800 --> 45:10.800]  0, 1, 4, 1, 5.
[45:10.800 --> 45:15.800]  Дальше снова 1, снова 0.
[45:15.800 --> 45:21.800]  Что-то я слишком большое дерево нарисовал, давайте...
[45:21.800 --> 45:23.800]  Чуть уменьшим.
[45:34.800 --> 45:38.800]  Ну нет, если нет детей, то мы как бы заходим и сразу выходим.
[45:38.800 --> 45:44.800]  Ну там дополнительно еще должны быть вставлены проверки, что если ребенок есть, то...
[45:44.800 --> 45:46.800]  Ну я это пропустил просто, понятно, что...
[45:46.800 --> 45:50.800]  Понятно, что если у вас нет левого ребенка или правого ребенка, то обходить рекурсивно в него не нужно.
[45:50.800 --> 45:52.800]  Поэтому только один раз печатаем.
[45:52.800 --> 45:54.800]  0, 1, 4, 1, 5.
[45:54.800 --> 45:57.800]  Дальше снова 1, дальше 0.
[45:57.800 --> 46:02.800]  Дальше заходим в центральных детей, то есть 2, 6.
[46:02.800 --> 46:05.800]  Ну и дальше поднимаемся обратно, 2, 0.
[46:05.800 --> 46:11.800]  То есть грубо говоря просто обходим там 0, 1, 4, 1, 5, 1, 0, 2, 6, 2, 0.
[46:11.800 --> 46:15.800]  И дальше 3, 7, 3, 0.
[46:20.800 --> 46:22.800]  Вот.
[46:25.800 --> 46:27.800]  Вот такой Эйлеров обход.
[46:28.800 --> 46:30.800]  То есть второй пункт.
[46:34.800 --> 46:39.800]  Запускаем Эйлеров обход.
[46:42.800 --> 46:46.800]  Печатаем вершины, и самое важное сейчас, печатаем...
[46:50.800 --> 46:53.800]  Вершины и их глубины.
[46:56.800 --> 47:01.800]  То есть дополнительно помимо того, что мы напечатали каждую вершину, мы еще рядом с ней напечатали ее глубину.
[47:01.800 --> 47:07.800]  То есть для нуля это 0, для единицы это 1.
[47:07.800 --> 47:10.800]  Дальше для двойки-тройки тоже 1.
[47:14.800 --> 47:19.800]  Вот. Ну для всех остальных 4, 5, 6, 7 это 2.
[47:20.800 --> 47:22.800]  Вот.
[47:31.800 --> 47:35.800]  Ну, понятно, что Эйлеров обход работает за сколько?
[47:35.800 --> 47:37.800]  Он тоже работает за линейное время.
[47:37.800 --> 47:39.800]  Хотя, казалось бы, он там печатает слишком много всего.
[47:39.800 --> 47:41.800]  То есть мы каждую вершину печатаем по несколько раз.
[47:41.800 --> 47:46.800]  Но при этом, заметьте, что каждую вершину мы напечатаем ну сколько?
[47:47.800 --> 47:53.800]  Ну, не более чем ее степень.
[47:53.800 --> 48:00.800]  Когда мы печатаем вершину, когда мы только в нее приходим, и когда мы возвращаемся в нее из детей.
[48:00.800 --> 48:05.800]  То есть вот мы в нее вошли, дальше вернулись единицы, вернулись из двойки, вернулись из тройки.
[48:05.800 --> 48:09.800]  А что будет, если мы просуммируем все степени всех вершин?
[48:09.800 --> 48:13.800]  У нас будет просто общее количество ребер, умноженное на 2.
[48:13.800 --> 48:19.800]  А общее количество ребер у нас не более чем 2 от количества всех вершин.
[48:19.800 --> 48:21.800]  Давайте напишем.
[48:21.800 --> 48:46.800]  Сделали этот шаг.
[48:46.800 --> 48:50.800]  Ну и теперь запрос.
[48:50.800 --> 48:57.800]  То есть, по сути, вот мы построили такой массив.
[48:57.800 --> 49:02.800]  Значит, утверждение звучит в том, что чтобы найти LCA для любых двух вершин,
[49:02.800 --> 49:07.800]  например, для четверки и тройки, мне достаточно найти какую-то четверку вот здесь,
[49:07.800 --> 49:11.800]  ну, допустим, вот эту, и какую-то тройку здесь, вот эту.
[49:11.800 --> 49:16.800]  А дальше вот на этом отрезке найти RMQ.
[49:16.800 --> 49:20.800]  Что? По глубинам, да, естественно.
[49:20.800 --> 49:25.800]  В данном случае, например, это ноль.
[49:25.800 --> 49:28.800]  Давайте докажем, что это действительно так.
[49:28.800 --> 49:50.800]  А LCA от XY, это есть RMQ от IDXX и, давайте просто, и от X, и от Y.
[49:50.800 --> 50:13.800]  Ну, это некоторые позиции XY в построенном, ну, давайте RMQD.
[50:13.800 --> 50:16.800]  Ну, в том смысле, что мы берем минимум по глубинам.
[50:16.800 --> 50:21.800]  То есть, ну, в качестве назначения массива используем вот эти значения.
[50:21.800 --> 50:24.800]  Так.
[50:24.800 --> 50:30.800]  Ну, почему это так?
[50:30.800 --> 50:33.800]  Ну, во-первых, давайте поймем следующую вещь.
[50:33.800 --> 50:38.800]  Вот я взял, в данном конкретном примере я взял четверку и тройку, да?
[50:38.800 --> 50:41.800]  Я взял какую-то четверку и какую-то тройку.
[50:41.800 --> 50:45.800]  Вот если я рассмотрю последовательность 4, 1, 5, 1, 0, 2, 6, 2, 0, 3 и так далее,
[50:45.800 --> 50:47.800]  вот что это будет?
[50:47.800 --> 50:50.800]  Вот просто там без относительной задачи, вот просто смотрим на это дерево,
[50:50.800 --> 50:54.800]  и я вам говорю, 4, 1, 5, 1, 0, 2, 6, вот.
[50:54.800 --> 50:58.800]  Что это будет с точки зрения дерева?
[50:58.800 --> 51:00.800]  Ну, не совсем под дерево.
[51:00.800 --> 51:03.800]  Это просто будет некоторый путь из четверки в тройку.
[51:03.800 --> 51:05.800]  Согласны?
[51:05.800 --> 51:08.800]  Вот давайте это напишем.
[51:08.800 --> 51:30.800]  Что отрезок и от х, и от у задает путь из х в у.
[51:30.800 --> 51:36.800]  А что можно сказать про любой путь из х в у, вот вообще про любой?
[51:36.800 --> 51:47.800]  Вот я беру произвольные вершины в дереве, и вот я иду из х в у.
[51:47.800 --> 51:56.800]  Да. Согласны ли вы, что он обязательно должен пройти по наименьшему общему предку?
[51:56.800 --> 52:00.800]  Ну, потому что наименьший общий предок это по сути та вершина, которая связывает х с у.
[52:00.800 --> 52:05.800]  Ну или можно воспользоваться утверждением, что в дереве между любыми двумя вершинами есть только один простой путь.
[52:05.800 --> 52:09.800]  Вот. Но этот простой путь, естественно, проходит через общего предка.
[52:09.800 --> 52:30.800]  Вот. Ну, а любой путь в дереве проходит через LCA xy.
[52:30.800 --> 52:36.800]  Ну, любой путь, давайте путь, из х в у.
[52:36.800 --> 52:40.800]  Любой путь из xy в дереве проходит через LCA xy. Всё. То есть что мы знаем?
[52:40.800 --> 52:47.800]  Мы знаем, что вот на этом отрезке, на котором мы ищем RMQ, у нас гарантированно есть LCA.
[52:47.800 --> 52:50.800]  Что осталось показать?
[52:50.800 --> 52:54.800]  Осталось показать, что у него будет наименьшая глубина среди всех вершин, которые здесь перечислены.
[52:54.800 --> 53:02.800]  То есть мы сказали, что тут есть какой-то LCA, но при этом пока непонятно, почему у этой вершины обязательно будет минимальная глубина.
[53:02.800 --> 53:06.800]  Да, вдруг мы поднимались куда-то выше. На самом деле выше мы не поднимемся.
[53:06.800 --> 53:14.800]  Почему?
[53:14.800 --> 53:17.800]  Почему мы не можем подняться выше LCA?
[53:17.800 --> 53:21.800]  Есть догадки?
[53:21.800 --> 53:24.800]  Ну, это да. А поподробней?
[53:24.800 --> 53:50.800]  Ну, в целом да. То есть можно проще.
[53:50.800 --> 53:58.800]  Можно сказать, что если наш рекурсивный вызов от какой-либо вершины закончился, то мы в эту вершину больше никогда не вернемся.
[53:58.800 --> 54:00.800]  Согласны?
[54:00.800 --> 54:02.800]  Давайте напишем следующую вещь.
[54:02.800 --> 54:15.800]  Во-первых, наблюдение. Вот то, что я сказал.
[54:15.800 --> 54:19.800]  Если вызов...
[54:19.800 --> 54:21.800]  Ну короче, давайте так. Не так.
[54:21.800 --> 54:50.800]  Эллеров обход не вызывается два раза от одной и той же вершины.
[54:50.800 --> 54:52.800]  Эллеров обход два раза не вызывает одной и той же вершины.
[54:52.800 --> 54:57.800]  Ну, откуда это следует? Ну, это следует вот из самого алгоритма.
[54:57.800 --> 55:08.800]  Если я запускаюсь от вершины node, то есть я печатаю вершину, запускаюсь от левого сына, и вот от левого сына я больше никогда не запущусь.
[55:08.800 --> 55:13.800]  Все, если этот вызов у меня закончен, то я в эту потерю больше никогда не вернусь.
[55:13.800 --> 55:15.800]  Понятно?
[55:15.800 --> 55:20.800]  Если я запускаюсь от левого сына, то я всего левого сына обошел и возвращаюсь обратно.
[55:20.800 --> 55:22.800]  Все, от него я больше никогда вызываться не буду.
[55:22.800 --> 55:26.800]  И вот после того, как вот этот вот рекурсивный вызов у меня закончится, от вершины node я тоже никогда не буду вызываться.
[55:26.800 --> 55:30.800]  Ну, ровно по этой причине. Понятно?
[55:30.800 --> 55:33.800]  То есть вот эта сама функция, то есть не функция print.
[55:33.800 --> 55:36.800]  То есть print это просто печатать, это не обход.
[55:36.800 --> 55:38.800]  Обход это вот эта функция, error.
[55:38.800 --> 55:43.800]  А вот функция error никогда два раза от одной и той же вершины не вызывается.
[55:43.800 --> 55:47.800]  То есть error обход не вызывается два раза от одной и той же вершины.
[55:47.800 --> 55:50.800]  Ну а что это значит?
[55:50.800 --> 56:06.800]  Допустим, на этом пути, который мы рассматриваем, ну я напомню, мы взяли какую-то вершину x,
[56:06.800 --> 56:10.800]  в массиве взяли какую-то вершину y в массиве, и рассмотрели путь от x в y.
[56:10.800 --> 56:27.800]  Вот допустим, на этом пути есть вершина выше LCA.
[56:27.800 --> 56:29.800]  То есть что это значит?
[56:29.800 --> 56:37.800]  Вот у меня здесь LCA от x и y, и вот есть вершина выше нее.
[56:37.800 --> 56:44.800]  Здесь где-то x, здесь где-то y.
[56:44.800 --> 56:49.800]  Что это означает?
[56:49.800 --> 56:51.800]  Как я мог попасть в эту вершину?
[56:51.800 --> 56:58.800]  Это означает, что я от x как-то попал в эту вершину, да?
[56:58.800 --> 57:07.800]  А потом спустился в y.
[57:07.800 --> 57:21.800]  Давайте, давайте здесь.
[57:21.800 --> 57:41.800]  То есть error обход поднялся в родителя LCA.
[57:41.800 --> 57:43.800]  Еще раз повторю.
[57:43.800 --> 57:45.800]  Я стартовал свой путь из x.
[57:45.800 --> 57:50.800]  Дальше, где-то посередине, этот путь забрел в родителей LCA.
[57:50.800 --> 57:51.800]  Ну что это значит?
[57:51.800 --> 57:57.800]  Значит, что я зашел в LCA, а потом из LCA поднялся в родителя.
[57:57.800 --> 58:05.800]  А что это означает?
[58:05.800 --> 58:13.800]  То есть в каком случае я поднимаюсь от потомка к родителю?
[58:13.800 --> 58:21.800]  Вот что означает вот этот подъем в терминах error обхода?
[58:21.800 --> 58:25.800]  Да, это означает, что у меня завершился рекурсивный вызов.
[58:25.800 --> 58:29.800]  То есть по пути поднимаюсь я вверх только в случае, когда у меня завершается рекурсивный вызов.
[58:29.800 --> 58:53.800]  То есть рекурсивный вызов error от LCA был завершен.
[58:53.800 --> 58:55.800]  Вот.
[58:55.800 --> 59:00.800]  То есть еще раз останавливаемся, понимаем, что происходит.
[59:00.800 --> 59:02.800]  Мы были в вершине x.
[59:02.800 --> 59:05.800]  Из вершины x мы каким-то образом добрались до родителей LCA.
[59:05.800 --> 59:11.800]  Так мы добрались до родителей LCA, это означает, что у нас рекурсивный вызов от этой вершины был завершен.
[59:11.800 --> 59:14.800]  То есть все, мы это дерево больше не обходим.
[59:14.800 --> 59:17.800]  Все видят противоречие.
[59:17.800 --> 59:21.800]  Но противоречие заключается в том, что после того, как я из x пошел в родителя,
[59:21.800 --> 59:25.800]  у меня оказывается, что я из этого родителя потом как-то еще попал в y.
[59:25.800 --> 59:30.800]  Ну а как я мог попасть в y, если я не могу снова возвращаться по этому самому ребру?
[59:30.800 --> 59:31.800]  Понятно?
[59:31.800 --> 59:34.800]  То есть у меня error в путь два раза в одну и ту же вершину не заходит.
[59:34.800 --> 59:37.800]  Ну все, противоречие.
[59:37.800 --> 59:43.800]  То есть рекурсивный вызов error от LCA x, y был завершен.
[59:43.800 --> 59:45.800]  А потом
[59:47.800 --> 59:49.800]  вновь
[59:49.800 --> 59:51.800]  был
[59:53.800 --> 59:54.800]  запущен.
[59:54.800 --> 59:56.800]  Ну давайте напишем, что так как
[01:00:00.800 --> 01:00:02.800]  так как после
[01:00:04.800 --> 01:00:06.800]  был
[01:00:07.800 --> 01:00:09.800]  напечатан y.
[01:00:10.800 --> 01:00:12.800]  Все, ну противоречие.
[01:00:12.800 --> 01:00:15.800]  Противоречие с наблюдением, да?
[01:00:19.800 --> 01:00:21.800]  Наблюдение.
[01:00:23.800 --> 01:00:24.800]  Все.
[01:00:25.800 --> 01:00:28.800]  Давайте еще раз проговорим доказать.
[01:00:28.800 --> 01:00:31.800]  На самом деле простой, тут много слов получилось, но идея простая.
[01:00:31.800 --> 01:00:33.800]  Значит мы находим...
[01:00:33.800 --> 01:00:35.800]  То есть у нас есть некоторый массив.
[01:00:35.800 --> 01:00:37.800]  Массив error обхода.
[01:00:37.800 --> 01:00:40.800]  А вы берем какое-то вхождение x туда, какое-то вхождение y.
[01:00:41.800 --> 01:00:43.800]  Вот эта последовательность
[01:00:43.800 --> 01:00:45.800]  последовательность вершин, которые мы посетили, задает некоторый путь.
[01:00:45.800 --> 01:00:47.800]  Некоторый путь изy.
[01:00:47.800 --> 01:00:50.800]  Значит первый пункт очевидный, этот путь обязательно проходит через LCA.
[01:00:50.800 --> 01:00:53.800]  Теперь второй пункт нужно доказать, почему этот путь
[01:00:53.800 --> 01:00:55.800]  никогда не проходит
[01:00:55.800 --> 01:00:57.800]  по вершинам, которые находятся выше LCA.
[01:00:57.800 --> 01:00:59.800]  Ну очень просто.
[01:00:59.800 --> 01:01:02.800]  Значит допустим он проходит через вершину, который находится выше ЛCA.
[01:01:02.800 --> 01:01:04.800]  Это значит что мы из x поднялись вот сюда.
[01:01:04.800 --> 01:01:11.800]  Но если мы поднялись вот сюда, то есть если мы в какую-то вершину поднялись обратно, то по этому же пути, то есть вот по этому ребру мы никогда не пройдем.
[01:01:11.800 --> 01:01:14.800]  Ну вот так устроен Euler's обход.
[01:01:14.800 --> 01:01:19.800]  Ну то есть если вот этот вызов завершился, то все, сюда мы больше никогда не попадем.
[01:01:19.800 --> 01:01:23.800]  Ну все, а это значит, что отсюда мы никак в игры попасть снова не могли.
[01:01:23.800 --> 01:01:26.800]  Да? Но это противоречие с тем, что у нас путь устроен так.
[01:01:26.800 --> 01:01:29.800]  Х поднимается сюда, а потом каким-то образом падает сюда.
[01:01:29.800 --> 01:01:31.800]  Вот, противоречие.
[01:01:31.800 --> 01:01:37.800]  Все, следовательно, LCA – это вершина с минимальной глубиной, которую мы посещали.
[01:01:37.800 --> 01:01:42.800]  Ну все, это значит, что мы можем свести задачу LCA к поиску просто RMQ вот на этом массиве.
[01:01:42.800 --> 01:01:44.800]  Точнее, на этом подотреске.
[01:01:45.800 --> 01:01:46.800]  Окей?
[01:01:49.800 --> 01:01:50.800]  Отлично.
[01:01:52.800 --> 01:01:54.800]  Ну, по сути, вот.
[01:01:56.800 --> 01:02:00.800]  То есть по сути мы доказали что? Мы доказали, что задачи LCA и RMQ по сути эквалентны.
[01:02:00.800 --> 01:02:05.800]  Да, то есть если вы умеете решать одну задачу, то вы обязательно умеете решать и другую задачу.
[01:02:05.800 --> 01:02:07.800]  Вот.
[01:02:07.800 --> 01:02:11.800]  Теперь давайте начнем наш путь.
[01:02:11.800 --> 01:02:13.800]  Все, последний пункт.
[01:02:13.800 --> 01:02:18.800]  Начнем наш путь к тому, что попробуем решить задачу RMQ за линейное время.
[01:02:18.800 --> 01:02:21.800]  И тут нам внезапно потребуется сведение к LCA.
[01:02:21.800 --> 01:02:25.800]  То есть небольшой спойлер.
[01:02:25.800 --> 01:02:27.800]  Как мы будем решать задачу RMQ за линейное время?
[01:02:27.800 --> 01:02:31.800]  Мы возьмем задачу RMQ, сведем ее к LCA,
[01:02:31.800 --> 01:02:35.800]  потом LCA сведем к RMQ, и вот его мы решим за линейное время.
[01:02:37.800 --> 01:02:38.800]  Сложно.
[01:02:38.800 --> 01:02:39.800]  Давайте...
[01:02:42.800 --> 01:02:43.800]  Давайте поясню.
[01:02:45.800 --> 01:02:47.800]  Значит, на самом деле...
[01:02:48.800 --> 01:02:52.800]  Я утверждаю, что вот это сведение LCA к RMQ на самом деле сведение не к RMQ.
[01:02:52.800 --> 01:02:56.800]  На самом деле мы свели задачу к, наверное, чуть более простой.
[01:02:57.800 --> 01:02:59.800]  Что можете сказать про этот массив?
[01:03:01.800 --> 01:03:04.800]  Вот я утверждаю, что вот этот массив устроен несколько особенным образом.
[01:03:07.800 --> 01:03:08.800]  Во.
[01:03:08.800 --> 01:03:13.800]  Все понимают, что соседние элементы, обязательно, элементы, которые находятся в этом массиве,
[01:03:13.800 --> 01:03:15.800]  они либо спускаются вниз, либо поднимаются наверх.
[01:03:15.800 --> 01:03:18.800]  И вот такая познавка задач называется плюс-минус один RMQ.
[01:03:19.800 --> 01:03:20.800]  Давайте замечание.
[01:03:29.800 --> 01:03:32.800]  Задача, то есть давайте здесь напишем RMQ плюс-минус один.
[01:03:35.800 --> 01:03:36.800]  Задача...
[01:03:38.800 --> 01:03:39.800]  Задача...
[01:03:40.800 --> 01:03:41.800]  Задача,
[01:03:45.800 --> 01:03:46.800]  которой
[01:03:49.800 --> 01:03:50.800]  свелась
[01:03:54.800 --> 01:03:55.800]  LCA
[01:04:00.800 --> 01:04:01.800]  называется
[01:04:03.800 --> 01:04:05.800]  RMQ плюс-минус один.
[01:04:06.800 --> 01:04:07.800]  Так как
[01:04:09.800 --> 01:04:10.800]  соседние элементы
[01:04:23.800 --> 01:04:25.800]  отличаются на плюс-минус один.
[01:04:26.800 --> 01:04:27.800]  Вот.
[01:04:34.800 --> 01:04:36.800]  Так, и вот
[01:04:39.800 --> 01:04:41.800]  задачу RMQ плюс-минус один
[01:04:43.800 --> 01:04:44.800]  можно решить эффективно
[01:04:45.800 --> 01:04:46.800]  за линейное время.
[01:04:47.800 --> 01:04:48.800]  Вот давайте этим
[01:04:49.800 --> 01:04:50.800]  займемся.
[01:05:00.800 --> 01:05:01.800]  Еще один пункт
[01:05:03.800 --> 01:05:04.800]  RMQ
[01:05:05.800 --> 01:05:06.800]  плюс-минус один.
[01:05:06.800 --> 01:05:08.800]  Значит, алгоритм, с помощью которого мы будем решать эту задачу,
[01:05:09.800 --> 01:05:10.800]  вот эту задачу мы сейчас решим за линейное время,
[01:05:11.800 --> 01:05:13.800]  ну, в смысле, за построение за линейное время и
[01:05:14.800 --> 01:05:15.800]  ответный запрос за единицу.
[01:05:16.800 --> 01:05:17.800]  Вот.
[01:05:17.800 --> 01:05:18.800]  Значит, алгоритм, который мы рассмотрим,
[01:05:21.800 --> 01:05:22.800]  называется алгоритмом
[01:05:24.800 --> 01:05:25.800]  Farah, Colton и Bender.
[01:05:37.800 --> 01:05:38.800]  Вот.
[01:05:42.800 --> 01:05:43.800]  На всякий случай.
[01:05:44.800 --> 01:05:46.800]  Значит, как работает этот алгоритм?
[01:05:48.800 --> 01:05:49.800]  Алгоритм работает
[01:05:50.800 --> 01:05:52.800]  ну, очень похожим образом, как мы обсуждали на первой лекции.
[01:05:53.800 --> 01:05:55.800]  Значит, на первой лекции мы обсуждали SQRT декомпозицию.
[01:05:56.800 --> 01:05:57.800]  Помните?
[01:05:58.800 --> 01:05:59.800]  Что мы делали?
[01:06:00.800 --> 01:06:01.800]  Вот у нас был массив.
[01:06:03.800 --> 01:06:04.800]  Далее мы его разбивали на
[01:06:04.800 --> 01:06:05.800]  кусочки размера B.
[01:06:13.800 --> 01:06:14.800]  B.
[01:06:15.800 --> 01:06:16.800]  Тут B.
[01:06:18.800 --> 01:06:19.800]  Ну, этот кусочек, возможно,
[01:06:20.800 --> 01:06:21.800]  тоже B.
[01:06:22.800 --> 01:06:24.800]  Этот кусочек, возможно, меньше равен, чем B.
[01:06:25.800 --> 01:06:26.800]  Что мы делали?
[01:06:27.800 --> 01:06:29.800]  Ну, мы просто брали и считали минимум
[01:06:30.800 --> 01:06:31.800]  в каждом из этих кусочков.
[01:06:34.800 --> 01:06:35.800]  То есть размер этого массива N.
[01:06:37.800 --> 01:06:38.800]  Размер этого массива
[01:06:40.800 --> 01:06:41.800]  N делённый на B.
[01:06:42.800 --> 01:06:43.800]  Ну, давайте отдельно как-то
[01:06:44.800 --> 01:06:45.800]  ещё раз поясним.
[01:06:50.800 --> 01:06:51.800]  Разбиваем
[01:06:52.800 --> 01:06:53.800]  на подмассивы
[01:06:54.800 --> 01:06:55.800]  размера B.
[01:07:00.800 --> 01:07:01.800]  На каждом
[01:07:05.800 --> 01:07:06.800]  подмассиве
[01:07:14.800 --> 01:07:15.800]  разбиваем
[01:07:17.800 --> 01:07:18.800]  на подмассивы
[01:07:23.800 --> 01:07:24.800]  ищем минимум.
[01:07:26.800 --> 01:07:27.800]  Ну и третий пункт.
[01:07:28.800 --> 01:07:29.800]  Вот давайте вот на этом массиве, как и раньше,
[01:07:30.800 --> 01:07:31.800]  вот на этом массиве
[01:07:32.800 --> 01:07:33.800]  построим разреженную таблицу.
[01:07:38.800 --> 01:07:39.800]  Строим
[01:07:41.800 --> 01:07:42.800]  на полученном
[01:07:45.800 --> 01:07:46.800]  массиве
[01:07:47.800 --> 01:07:48.800]  sports table.
[01:07:54.800 --> 01:07:55.800]  Так.
[01:07:56.800 --> 01:07:57.800]  Начну и
[01:07:58.800 --> 01:07:59.800]  сколько времени это занимает?
[01:08:00.800 --> 01:08:01.800]  Давайте T при процессинга
[01:08:02.800 --> 01:08:03.800]  от N и B.
[01:08:04.800 --> 01:08:05.800]  Значит, как и раньше, это нас занимало,
[01:08:06.800 --> 01:08:07.800]  понятное дело, там, линейное время
[01:08:08.800 --> 01:08:09.800]  на то, чтобы посчитать всевозможные минимумы
[01:08:10.800 --> 01:08:12.800]  на каждом из этих подотресков.
[01:08:13.800 --> 01:08:14.800]  Ну и плюс мы строим разреженную таблицу
[01:08:15.800 --> 01:08:16.800]  на массиве размера N делённый на B,
[01:08:17.800 --> 01:08:18.800]  но разреженную таблицу мы строим
[01:08:19.800 --> 01:08:22.800]  за вот такое время.
[01:08:23.800 --> 01:08:24.800]  Так.
[01:08:25.800 --> 01:08:26.800]  И, ну, весь основной вопрос у нас заключался в том,
[01:08:27.800 --> 01:08:28.800]  что мы делаем с этими небольшими кусочками.
[01:08:29.800 --> 01:08:30.800]  Да?
[01:08:31.800 --> 01:08:32.800]  То есть в классе, в простом варианте
[01:08:33.800 --> 01:08:34.800]  мы просто считаем там банальным образом,
[01:08:35.800 --> 01:08:36.800]  то есть примитивным образом,
[01:08:37.800 --> 01:08:38.800]  то есть просто если нам нужно,
[01:08:39.800 --> 01:08:40.800]  точнее так, давайте напомним,
[01:08:41.800 --> 01:08:42.800]  что если вам нужно найти минимум на каком-то отрезке,
[01:08:43.800 --> 01:08:44.800]  то вы этот запрос вводите к поиску минимума
[01:08:45.800 --> 01:08:46.800]  на вот этих подотресках,
[01:08:47.800 --> 01:08:48.800]  то есть, по сути, вот на вот этих элементах,
[01:08:49.800 --> 01:08:50.800]  на маленьких элементах.
[01:08:51.800 --> 01:08:52.800]  На вот этих вот остатках,
[01:08:53.800 --> 01:08:54.800]  на этих остатках вы считаете минимум
[01:08:55.800 --> 01:08:56.800]  каким-то другим образом,
[01:08:57.800 --> 01:08:58.800]  ну, например, там, ну, просто линейно проходитесь,
[01:08:59.800 --> 01:09:00.800]  ну, либо на вот этих маленьких кусочках
[01:09:01.800 --> 01:09:02.800]  в свою очередь строите свою Spark таблицу.
[01:09:03.800 --> 01:09:04.800]  Вот это то, что было раньше.
[01:09:05.800 --> 01:09:06.800]  Значит, Farah, Colton и Bender
[01:09:07.800 --> 01:09:08.800]  предлагают другую вещь.
[01:09:09.800 --> 01:09:11.800]  Давайте, наконец, воспользуемся тем фактом,
[01:09:12.800 --> 01:09:13.800]  что у нас задача RMQ плюс-минус один.
[01:09:16.800 --> 01:09:18.800]  Значит, ключевой вопрос следующий.
[01:09:23.800 --> 01:09:41.800]  Что делать с массивами размера B?
[01:09:42.800 --> 01:09:43.800]  То есть, что делать с вот этими друзьями?
[01:09:45.800 --> 01:09:47.800]  Значит, тут давайте воспользуемся тем фактом,
[01:09:48.800 --> 01:09:49.800]  что у нас задача плюс-минус один.
[01:09:50.800 --> 01:09:51.800]  То есть, все соседние элементы отличаются
[01:09:51.800 --> 01:09:52.800]  от плюс-минус один или минус один.
[01:09:53.800 --> 01:09:54.800]  Пример.
[01:10:16.800 --> 01:10:17.800]  Чем отличаются эти массивы?
[01:10:21.800 --> 01:10:22.800]  Ну, то есть, согласны, что с точки зрения,
[01:10:23.800 --> 01:10:25.800]  что вообще говоря, с точки зрения задачи RMQ плюс-минус один,
[01:10:26.800 --> 01:10:27.800]  эти массивы ничем не отличаются.
[01:10:28.800 --> 01:10:30.800]  Ну, то есть, и этот, и этот массив
[01:10:31.800 --> 01:10:32.800]  можно закодировать следующим образом.
[01:10:33.800 --> 01:10:35.800]  Плюс один, минус один, минус один, минус один,
[01:10:36.800 --> 01:10:37.800]  минус один, плюс один.
[01:10:37.800 --> 01:10:42.800]  Ну, то есть и этот, и этот массив можно закодировать следующим образом.
[01:10:42.800 --> 01:10:49.800]  Плюс один, минус один, минус один, минус один, минус один, плюс один.
[01:10:52.800 --> 01:10:54.800]  Согласны?
[01:10:54.800 --> 01:10:57.800]  Что и этот массив, и этот массив имеют вот такой вид.
[01:10:57.800 --> 01:11:00.800]  То есть нам не важно, чтобы найти минимум на произвольном отрезке,
[01:11:00.800 --> 01:11:03.800]  нам вообще говоря не важен начальный элемент.
[01:11:03.800 --> 01:11:06.800]  То есть нам важно то, как ведут себя эти элементы.
[01:11:06.800 --> 01:11:09.800]  Какой у них график условный.
[01:11:09.800 --> 01:11:12.800]  И это нас наталкивает на следующую мысль.
[01:11:12.800 --> 01:11:17.800]  Что в принципе, количество таких различных последовательностей,
[01:11:17.800 --> 01:11:20.800]  вот такого вида, наверное, не очень много.
[01:11:20.800 --> 01:11:21.800]  Согласны?
[01:11:21.800 --> 01:11:24.800]  То есть разнообразие массивов у вас не очень большое.
[01:11:24.800 --> 01:11:26.800]  То есть в случае, когда вы решаете обычную задачу RMQ,
[01:11:26.800 --> 01:11:30.800]  то соседние элементы могут отличаться на плюс пять, на плюс четыре и так далее.
[01:11:30.800 --> 01:11:33.800]  А если у вас массив отличается на плюс-минус один,
[01:11:33.800 --> 01:11:38.800]  то вы любой массив можете закодировать вот таким образом.
[01:11:38.800 --> 01:11:41.800]  И ответ не будет зависеть от конкретного вида.
[01:11:41.800 --> 01:11:45.800]  То есть ответ будет зависеть лишь от такой маски.
[01:11:45.800 --> 01:11:48.800]  Плюс-минус один. Согласны?
[01:11:48.800 --> 01:11:50.800]  Есть контакт?
[01:11:51.800 --> 01:11:53.800]  Давайте напишем.
[01:11:53.800 --> 01:11:55.800]  Любой массив
[01:12:00.800 --> 01:12:02.800]  можно закодировать
[01:12:14.800 --> 01:12:16.800]  последовательностью
[01:12:16.800 --> 01:12:19.800]  из b-1
[01:12:22.800 --> 01:12:24.800]  последовательностью плюс-минус один.
[01:12:27.800 --> 01:12:29.800]  Как это математически пишется?
[01:12:31.800 --> 01:12:34.800]  В степени b-1. Похоже на правду?
[01:12:39.800 --> 01:12:44.800]  Последовательностью из b-1 элемента
[01:12:46.800 --> 01:12:50.800]  принадлежащего множеству минус один и плюс один.
[01:12:53.800 --> 01:12:55.800]  Согласны?
[01:13:00.800 --> 01:13:03.800]  И вы, наверное, сейчас ждете чего-то умного.
[01:13:03.800 --> 01:13:05.800]  Есть массивы плюс-минус один,
[01:13:05.800 --> 01:13:08.800]  и мы сейчас как-то очень круто на них сможем построить запросы.
[01:13:08.800 --> 01:13:10.800]  Ну вот фиг вам.
[01:13:10.800 --> 01:13:14.800]  Мы сейчас возьмем, переберем все такие последовательности,
[01:13:14.800 --> 01:13:16.800]  переберем всевозможные пары LR
[01:13:16.800 --> 01:13:18.800]  и посчитаем на них ответы.
[01:13:18.800 --> 01:13:20.800]  Тупым перебором.
[01:13:24.800 --> 01:13:26.800]  Переберем.
[01:13:26.800 --> 01:13:28.800]  Прямо подчеркну, втупую.
[01:13:35.800 --> 01:13:37.800]  Все последовательности,
[01:13:39.800 --> 01:13:41.800]  все эти последовательности
[01:13:45.800 --> 01:13:47.800]  и все пары LR.
[01:13:53.800 --> 01:13:55.800]  Все эти последовательности, все пары LR.
[01:13:56.800 --> 01:13:58.800]  И предподсчитаем ответы.
[01:14:09.800 --> 01:14:12.800]  Все, то есть условно, если у вас b равно, не знаю там,
[01:14:12.800 --> 01:14:14.800]  b равно 5,
[01:14:14.800 --> 01:14:16.800]  то что мы делаем?
[01:14:16.800 --> 01:14:18.800]  Мы перебираем 2 в степени 4,
[01:14:20.800 --> 01:14:22.800]  16 возможных массивов,
[01:14:24.800 --> 01:14:26.800]  и для каждого массива,
[01:14:26.800 --> 01:14:28.800]  для каждого из этих 16 массивов
[01:14:28.800 --> 01:14:30.800]  перебираем всевозможные пары.
[01:14:30.800 --> 01:14:32.800]  То есть как мы на самом первом лекции говорили,
[01:14:32.800 --> 01:14:34.800]  самый тупой алгоритм.
[01:14:34.800 --> 01:14:36.800]  Вот мы делаем самый тупой алгоритм.
[01:14:36.800 --> 01:14:38.800]  Но только мы сохраняем все результаты в отдельную таблицу.
[01:14:38.800 --> 01:14:40.800]  Окей?
[01:14:40.800 --> 01:14:42.800]  Сколько памяти на это уйдет?
[01:14:42.800 --> 01:14:44.800]  Ну и сколько времени?
[01:14:48.800 --> 01:14:50.800]  Ну вообще говоря, это занимает сколько?
[01:14:50.800 --> 01:14:52.800]  Ну сколько всего таких последовательностей размера b-1?
[01:14:52.800 --> 01:14:54.800]  Ну почему b-1, кстати?
[01:14:54.800 --> 01:14:56.800]  Все понимают.
[01:14:56.800 --> 01:14:58.800]  У нас же последовательство размера b.
[01:14:58.800 --> 01:15:00.800]  Ну потому что у нас первый элемент,
[01:15:00.800 --> 01:15:02.800]  он ни на что не влияет.
[01:15:02.800 --> 01:15:04.800]  То есть нас интересует только вот этот хост,
[01:15:04.800 --> 01:15:06.800]  плюс-минус один.
[01:15:06.800 --> 01:15:08.800]  Сколько всего таких последовательностей размера b-1?
[01:15:08.800 --> 01:15:10.800]  Два в степени b-1.
[01:15:10.800 --> 01:15:12.800]  Ну в терминах онотации давайте просто напишем
[01:15:12.800 --> 01:15:14.800]  2 в степени b.
[01:15:14.800 --> 01:15:16.800]  Ну у большой 2 в степени b.
[01:15:16.800 --> 01:15:18.800]  На минус 1 забьем.
[01:15:18.800 --> 01:15:20.800]  А сколько всего возможных пар LR нам нужно рассмотреть?
[01:15:24.800 --> 01:15:26.800]  Ну b квадрат.
[01:15:26.800 --> 01:15:28.800]  На константы забиваем b квадрат.
[01:15:30.800 --> 01:15:32.800]  То есть вот такой предпочет.
[01:15:32.800 --> 01:15:34.800]  То есть для каждой возможной
[01:15:34.800 --> 01:15:36.800]  последовательности всего таких последовательностей
[01:15:36.800 --> 01:15:38.800]  2 в степени b,
[01:15:38.800 --> 01:15:40.800]  ну 2 в степени b-1, ну пишем 2 в степени b,
[01:15:40.800 --> 01:15:42.800]  мы перебираем всевозможные пары LR
[01:15:42.800 --> 01:15:44.800]  и сохраняем ответ.
[01:15:44.800 --> 01:15:46.800]  То есть нам нужно вот столько памяти и вот столько времени,
[01:15:46.800 --> 01:15:48.800]  естественно.
[01:15:48.800 --> 01:15:50.800]  То есть вот сюда добавляется еще член
[01:15:50.800 --> 01:15:52.800]  2 в степени b на b в квадрате.
[01:15:58.800 --> 01:16:00.800]  Алгоритм закончен.
[01:16:00.800 --> 01:16:02.800]  То есть вот алгоритм такой.
[01:16:02.800 --> 01:16:04.800]  Давайте еще раз проговорим.
[01:16:04.800 --> 01:16:06.800]  Берем массив размера n, делим его
[01:16:06.800 --> 01:16:08.800]  на куски размера b.
[01:16:08.800 --> 01:16:10.800]  Значит внутри каждого куска, точнее
[01:16:10.800 --> 01:16:12.800]  по каждому куску считаем минимум, сохраняем в отдельный массив.
[01:16:12.800 --> 01:16:14.800]  Вот поэтому получившемуся массиву
[01:16:14.800 --> 01:16:16.800]  строим спарс таблицу.
[01:16:16.800 --> 01:16:18.800]  Теперь вопрос, как отвечать на запросы
[01:16:18.800 --> 01:16:20.800]  внутри вот этих подотресков?
[01:16:20.800 --> 01:16:22.800]  То есть когда у меня получаются вот такие остатки?
[01:16:22.800 --> 01:16:24.800]  Очень просто.
[01:16:24.800 --> 01:16:26.800]  Фара Колтенбендер предлагает просто-напросто
[01:16:26.800 --> 01:16:28.800]  взять всевозможные такие последовательности
[01:16:28.800 --> 01:16:30.800]  и предпочитать ответ
[01:16:30.800 --> 01:16:32.800]  на них.
[01:16:32.800 --> 01:16:34.800]  То есть ответ на запрос вот на такой маленьком
[01:16:34.800 --> 01:16:36.800]  участке будет занимать
[01:16:36.800 --> 01:16:38.800]  от единицы. Это что? Ну то есть почему так?
[01:16:38.800 --> 01:16:40.800]  Ну я просто буду смотреть, что это за
[01:16:40.800 --> 01:16:42.800]  массив такой.
[01:16:42.800 --> 01:16:44.800]  То есть какую массу он имеет.
[01:16:44.800 --> 01:16:46.800]  То есть как он закодирован в терминах плюс-минус единицы.
[01:16:46.800 --> 01:16:48.800]  И дальше обращаться к соответствующей
[01:16:48.800 --> 01:16:50.800]  ячейке lr.
[01:16:50.800 --> 01:16:52.800]  То есть запрос
[01:16:54.800 --> 01:16:56.800]  работает всегда
[01:16:56.800 --> 01:16:58.800]  за от единицы.
[01:16:58.800 --> 01:17:00.800]  Ну почему? Потому что это одно обращение к спарс таблице
[01:17:00.800 --> 01:17:02.800]  и максимум два обращения
[01:17:02.800 --> 01:17:04.800]  к вот этой предпочитной
[01:17:04.800 --> 01:17:06.800]  таблице размера 2 в степени b на b квадрат.
[01:17:06.800 --> 01:17:08.800]  Все.
[01:17:08.800 --> 01:17:10.800]  Запрос за единицу проговорили. Теперь
[01:17:12.800 --> 01:17:14.800]  в качестве задания на после перерыва
[01:17:14.800 --> 01:17:16.800]  попробуем понять
[01:17:16.800 --> 01:17:18.800]  почему вот эта штука,
[01:17:18.800 --> 01:17:20.800]  ну как эту штуку можно сделать линейной?
[01:17:20.800 --> 01:17:22.800]  Тут в перерыве задали
[01:17:22.800 --> 01:17:24.800]  вопрос. Я это не проговорил, но
[01:17:24.800 --> 01:17:26.800]  давайте скажем. Ну смотрите,
[01:17:26.800 --> 01:17:28.800]  был такой вопрос.
[01:17:28.800 --> 01:17:30.800]  Ну смотрите, у меня есть...
[01:17:30.800 --> 01:17:32.800]  То есть я хочу отвечать на запросы вот на таких маленьких отрезках.
[01:17:32.800 --> 01:17:34.800]  Но чтобы ответить на запрос
[01:17:34.800 --> 01:17:36.800]  на этой маленькой отрезке, мне нужно сначала понять
[01:17:36.800 --> 01:17:38.800]  какому типу он принадлежит.
[01:17:38.800 --> 01:17:40.800]  То есть по сути потратить время равное b.
[01:17:40.800 --> 01:17:42.800]  А потом только обратиться в таблицу.
[01:17:42.800 --> 01:17:44.800]  На самом деле тут тоже можно
[01:17:44.800 --> 01:17:46.800]  все сделать за единицу, точнее нужно делать за единицу.
[01:17:46.800 --> 01:17:48.800]  В том смысле, что вы можете заранее
[01:17:48.800 --> 01:17:50.800]  для каждого этого подотреска понять
[01:17:50.800 --> 01:17:52.800]  какому типу он относится.
[01:17:52.800 --> 01:17:54.800]  Окей?
[01:17:54.800 --> 01:17:56.800]  Это отрезок относится к типу m1,
[01:17:56.800 --> 01:17:58.800]  этот относится к типу m2, m3 и так далее.
[01:17:58.800 --> 01:18:00.800]  То есть заранее предпочитать для каждого
[01:18:00.800 --> 01:18:02.800]  такого отрезка
[01:18:02.800 --> 01:18:04.800]  его маску.
[01:18:04.800 --> 01:18:06.800]  И дальше уже, когда вам поступает конкретный запрос,
[01:18:06.800 --> 01:18:08.800]  скажем, вот на таком отрезке,
[01:18:08.800 --> 01:18:10.800]  на таком подотреске, вы просто
[01:18:10.800 --> 01:18:12.800]  уже знаете маску этого отрезка и просто обращаете
[01:18:12.800 --> 01:18:14.800]  к соответствующим элементам lr.
[01:18:14.800 --> 01:18:16.800]  Поэтому тут тоже все за единицу.
[01:18:16.800 --> 01:18:18.800]  Поэтому
[01:18:18.800 --> 01:18:20.800]  операция запроса
[01:18:20.800 --> 01:18:22.800]  действительно выполняется за единицу, так как
[01:18:22.800 --> 01:18:24.800]  к вот такому массиву у нас
[01:18:24.800 --> 01:18:26.800]  sparse таблица обращение за единицу.
[01:18:26.800 --> 01:18:28.800]  И вот к этим элементам мы тоже, так как все предпочитали,
[01:18:28.800 --> 01:18:30.800]  это просто одно обращение
[01:18:30.800 --> 01:18:32.800]  к трехмерному массиву.
[01:18:32.800 --> 01:18:34.800]  Осталась непонятная следующая вещь.
[01:18:34.800 --> 01:18:36.800]  Вот смотрите.
[01:18:36.800 --> 01:18:38.800]  Время построения.
[01:18:38.800 --> 01:18:40.800]  Мы
[01:18:40.800 --> 01:18:42.800]  строим sparse таблицу за время nb
[01:18:42.800 --> 01:18:44.800]  на алгорифм n деленное на b.
[01:18:46.800 --> 01:18:48.800]  А после этого
[01:18:48.800 --> 01:18:50.800]  на таких маленьких отрезках,
[01:18:50.800 --> 01:18:52.800]  и точнее не на них, а вот просто перебираем
[01:18:52.800 --> 01:18:54.800]  всевозможные маленькие отрезки,
[01:18:54.800 --> 01:18:56.800]  всего их 2 в степени b.
[01:18:56.800 --> 01:18:58.800]  И для каждой пары lr считаем на них ответ.
[01:18:58.800 --> 01:19:00.800]  То есть 2 в степени b на b квадрат.
[01:19:00.800 --> 01:19:02.800]  Вопрос. Что нужно взять в качестве b,
[01:19:02.800 --> 01:19:04.800]  чтобы у нас все получилось?
[01:19:04.800 --> 01:19:06.800]  Ну смотрите, как бы в прошлый раз,
[01:19:06.800 --> 01:19:08.800]  когда мы обсуждали такую технику,
[01:19:08.800 --> 01:19:10.800]  мы говорили, что в принципе в качестве b
[01:19:10.800 --> 01:19:12.800]  неплохо бы взять
[01:19:12.800 --> 01:19:14.800]  алгорифм n, да?
[01:19:14.800 --> 01:19:16.800]  Ну почему? Какая логика была?
[01:19:16.800 --> 01:19:18.800]  Ну вот если мы возьмем b равное алгорифму n,
[01:19:18.800 --> 01:19:20.800]  то просто получится. У нас тут получится n
[01:19:20.800 --> 01:19:22.800]  деленное на алгорифм n,
[01:19:22.800 --> 01:19:24.800]  умноженное на алгорифм n
[01:19:24.800 --> 01:19:26.800]  деленное на алгорифм n.
[01:19:26.800 --> 01:19:28.800]  Так, можно тише, пожалуйста?
[01:19:28.800 --> 01:19:30.800]  Так.
[01:19:30.800 --> 01:19:32.800]  И что у нас получалось? У нас вот этот алгорифм сокращался вот этим алгорифмом,
[01:19:32.800 --> 01:19:34.800]  да, и получалась просто
[01:19:34.800 --> 01:19:36.800]  линейная симптотика.
[01:19:38.800 --> 01:19:40.800]  Но проблема вот в чем. Если я возьму алгорифм,
[01:19:40.800 --> 01:19:42.800]  да, и вот здесь, что будет, если
[01:19:42.800 --> 01:19:44.800]  возьму что-то большее, чем алгорифм?
[01:19:44.800 --> 01:19:46.800]  Ну по симптотике. Ну, например, там
[01:19:46.800 --> 01:19:48.800]  какой-нибудь, не знаю,
[01:19:48.800 --> 01:19:50.800]  алгорифм в квадрате.
[01:19:58.800 --> 01:20:00.800]  Ну b станет
[01:20:00.800 --> 01:20:02.800]  b большим, да?
[01:20:02.800 --> 01:20:04.800]  Там у нас на самом деле был другой член,
[01:20:04.800 --> 01:20:06.800]  в общем, ладно. Раньше мы брали в качестве b алгорифм,
[01:20:06.800 --> 01:20:08.800]  у нас все устраивало. Значит, утверждается,
[01:20:08.800 --> 01:20:10.800]  что взять алгорифм сейчас
[01:20:10.800 --> 01:20:12.800]  не получится.
[01:20:12.800 --> 01:20:14.800]  Почему? Потому что если я в качестве b
[01:20:14.800 --> 01:20:16.800]  возьму алгорифм, то тут у меня возникнет что?
[01:20:16.800 --> 01:20:18.800]  Два степени алгорифма это n,
[01:20:18.800 --> 01:20:20.800]  и еще алгорифм в квадрате n.
[01:20:20.800 --> 01:20:22.800]  Беда.
[01:20:22.800 --> 01:20:24.800]  То есть алгорифм сейчас
[01:20:24.800 --> 01:20:26.800]  оказывается слишком большой.
[01:20:26.800 --> 01:20:28.800]  Ну, давайте попробуем взять
[01:20:28.800 --> 01:20:30.800]  что-то меньше, чем алгорифм.
[01:20:30.800 --> 01:20:32.800]  Если возьмем что-то меньше, чем алгорифм,
[01:20:32.800 --> 01:20:34.800]  то...
[01:20:34.800 --> 01:20:36.800]  Ну, давайте здесь.
[01:20:36.800 --> 01:20:38.800]  Если я возьму что-то меньше, чем алгорифм,
[01:20:38.800 --> 01:20:40.800]  то что у меня получится здесь?
[01:20:40.800 --> 01:20:42.800]  Если b по асимптотике меньше, чем алгорифм,
[01:20:42.800 --> 01:20:44.800]  то вот этого сокращения у меня не получится.
[01:20:44.800 --> 01:20:46.800]  И вот тут возникнет
[01:20:46.800 --> 01:20:48.800]  нечто, что больше, чем n.
[01:20:48.800 --> 01:20:50.800]  Понятно?
[01:20:50.800 --> 01:20:52.800]  То есть возникает такой затык.
[01:20:52.800 --> 01:20:54.800]  С одной стороны,
[01:20:54.800 --> 01:20:56.800]  брать алгорифм хорошо, потому что
[01:20:56.800 --> 01:20:58.800]  здесь тогда будет n,
[01:20:58.800 --> 01:21:00.800]  но тут будет n лог в квадрат n.
[01:21:00.800 --> 01:21:02.800]  Если я захочу уменьшить вот этот член,
[01:21:02.800 --> 01:21:04.800]  то есть возьму что-то меньше, чем алгорифм,
[01:21:04.800 --> 01:21:06.800]  то у меня вот этот член вырастет,
[01:21:06.800 --> 01:21:08.800]  он будет больше, чем линейный.
[01:21:08.800 --> 01:21:10.800]  Что делать?
[01:21:12.800 --> 01:21:14.800]  Не зря же написана эта формула.
[01:21:14.800 --> 01:21:16.800]  Как ее победить?
[01:21:16.800 --> 01:21:18.800]  Как все свести к линейному случаю?
[01:21:22.800 --> 01:21:24.800]  Предлагаю алгорифм в степени меньше единицы.
[01:21:26.800 --> 01:21:28.800]  Давайте попробуем взять алгорифм...
[01:21:32.800 --> 01:21:34.800]  Опять же, меньше, чем алгорифм нельзя.
[01:21:34.800 --> 01:21:36.800]  Допустим, корень алгорифма.
[01:21:36.800 --> 01:21:38.800]  Тут будет n деленное на корень из лог n.
[01:21:42.800 --> 01:21:44.800]  Тут будет лог n,
[01:21:44.800 --> 01:21:46.800]  минус, не важно там,
[01:21:46.800 --> 01:21:48.800]  n деленное на корень из лог n.
[01:21:50.800 --> 01:21:52.800]  Вот этот алгорифм сократится
[01:21:52.800 --> 01:21:54.800]  с этим корнем,
[01:21:54.800 --> 01:21:56.800]  то есть этот алгорифм сократится с этим корнем
[01:21:56.800 --> 01:21:58.800]  из лог n, и тут будет член...
[01:21:58.800 --> 01:22:00.800]  Точнее, тут будет замножитель вида корня из лог n.
[01:22:00.800 --> 01:22:02.800]  Само n степени меньше единицы.
[01:22:02.800 --> 01:22:04.800]  О, а это уже хорошо.
[01:22:06.800 --> 01:22:08.800]  Идея такая.
[01:22:10.800 --> 01:22:12.800]  Идея взять n в степени, ну скажем,
[01:22:12.800 --> 01:22:14.800]  1 вторая.
[01:22:14.800 --> 01:22:16.800]  Давайте не так, давайте сделаем так.
[01:22:16.800 --> 01:22:18.800]  Давайте возьмем b равная 1 вторая
[01:22:18.800 --> 01:22:20.800]  от лог n.
[01:22:22.800 --> 01:22:24.800]  Вроде как предыдущая интуиция,
[01:22:24.800 --> 01:22:26.800]  не знаю, как у вас,
[01:22:26.800 --> 01:22:28.800]  наверное, на основании предыдущих курсов,
[01:22:28.800 --> 01:22:30.800]  предыдущих алгоритмов кажется, что константа ни на что не влияет.
[01:22:30.800 --> 01:22:32.800]  Ну действительно, если мы посмотрим сюда,
[01:22:32.800 --> 01:22:34.800]  то какая разница?
[01:22:34.800 --> 01:22:36.800]  Возникнет константа, тут возникнет константа.
[01:22:36.800 --> 01:22:38.800]  У нас в терминах онотации везде
[01:22:38.800 --> 01:22:40.800]  константы убиваются.
[01:22:42.800 --> 01:22:44.800]  Но не для экспонент.
[01:22:44.800 --> 01:22:46.800]  Вот для экспонент константы крайне важны.
[01:22:48.800 --> 01:22:50.800]  Смотрите, добавив всего лишь 1 вторую,
[01:22:50.800 --> 01:22:52.800]  то есть заменив лог n на 1 вторую лог n,
[01:22:52.800 --> 01:22:54.800]  что я получу здесь?
[01:22:54.800 --> 01:22:56.800]  Здесь я получу все то же самое o от n.
[01:22:56.800 --> 01:22:58.800]  Да, потому что тут будет логарифм,
[01:22:58.800 --> 01:23:00.800]  и логарифм с логарифм сократится, получится просто n.
[01:23:00.800 --> 01:23:02.800]  А что будет здесь?
[01:23:02.800 --> 01:23:08.800]  Тут будет 2 в степени 1 вторая лог n,
[01:23:08.800 --> 01:23:12.800]  умноженная на 1 вторая лог n в квадрате.
[01:23:14.800 --> 01:23:16.800]  Чему равно 2 в степени логарифм n пополам?
[01:23:16.800 --> 01:23:18.800]  Корень из n.
[01:23:20.800 --> 01:23:22.800]  Корень из n на логарифм в квадрате n.
[01:23:24.800 --> 01:23:26.800]  А что можно сказать про эту функцию?
[01:23:26.800 --> 01:23:28.800]  Смотрим.
[01:23:30.800 --> 01:23:32.800]  Да, любая степень логарифма растет медленнее,
[01:23:32.800 --> 01:23:34.800]  чем любая степень n.
[01:23:34.800 --> 01:23:36.800]  Понятно?
[01:23:36.800 --> 01:23:38.800]  То есть можно сказать, что это асимптатически
[01:23:38.800 --> 01:23:40.800]  растет медленней,
[01:23:40.800 --> 01:23:42.800]  чем, ну скажем, корень из n, умноженный на корень из n.
[01:23:44.800 --> 01:23:46.800]  Еще раз. Любая степень логарифма растет медленней,
[01:23:46.800 --> 01:23:48.800]  чем любая степень n.
[01:23:52.800 --> 01:23:54.800]  То есть это означает, что вот эту штуку
[01:23:54.800 --> 01:24:07.180]  и мы победили, все. То есть как выглядит полный алгоритм? Мы уберем изначально, то есть мы хотим
[01:24:07.180 --> 01:24:11.840]  решить задачу RMQ плюс-минус один, то есть у нас массиве все элементы соседние отличаются на плюс
[01:24:11.840 --> 01:24:17.940]  один или минус один. Что мы делаем? Весь массив разбиваем на подмассивы размера b, значит
[01:24:17.940 --> 01:24:22.980]  внутри каждого подмассива считаем минимум, строим на получившейся массиве спарс таблицу,
[01:24:22.980 --> 01:24:31.660]  разреженную таблицу. Дальше для всевозможных подмассивов b, ну точнее для их маск,
[01:24:31.660 --> 01:24:38.380]  предпочтим ответ. Предпочтен ответ занимает 2 в степень b умножить на b квадрат. Таким образом,
[01:24:38.380 --> 01:24:43.260]  полное построение занимает вот такое время. Если я в качестве b возьму одну вторую на алгоритм n,
[01:24:43.260 --> 01:24:49.340]  то у меня второй член будет n и третий член будет оцениваться сверху как n. В итоге суммарное
[01:24:49.340 --> 01:25:02.740]  построение есть от n. Вот. Таким образом, удалось решить задачу rmq плюс-минус один за
[01:25:02.740 --> 01:25:10.740]  линейное время. Ну почти как обещал. Остался последний пункт, вот действительно самый последний,
[01:25:10.740 --> 01:25:16.420]  это понять как решить произвольную задачу rmq за линейное время при процессинге, точнее статик
[01:25:16.420 --> 01:25:23.300]  rmq за линейное время при процессинге и за единицу запроса. Ну я уже немного проспойлерил, но давайте
[01:25:23.300 --> 01:25:49.820]  напишем. Значит пункт последний. Решение статик rmq
[01:25:49.820 --> 01:26:12.380]  за при процессинг от n и запрос от единицы. Все очень просто. Была у нас задача rmq. Сведем ее к
[01:26:12.380 --> 01:26:22.660]  задаче lca. Мы умеем сводить задачу rmq к задаче lca за линейное время. Ну помните, да? Просто строим
[01:26:22.660 --> 01:26:32.220]  декартовое дерево. Дальше. Что мы умеем делать с задачей lca? Да, мы умеем ее сводить к задаче rmq
[01:26:32.220 --> 01:26:40.140]  плюс минус один. Тоже за линейное время. Рмq плюс минус один. А что мы умеем делать с задачей rmq
[01:26:40.140 --> 01:26:46.860]  плюс минус один? Да, мы умеем ее решать с помощью алгоритма Farah-Colton-Bender. Все.
[01:26:46.860 --> 01:27:15.580]  Farah-Colton-Bender. Все. Вот такая история. Ну, естественно, на практике так никто не
[01:27:15.580 --> 01:27:20.980]  делает. Вот. Поэтому я как бы сделал анонс, что лекция больше теоретической. То есть с точки
[01:27:20.980 --> 01:27:27.100]  зрения теории можно решить задачу rmq за максимально оптимальное время. То есть за линейное время
[01:27:27.100 --> 01:27:32.860]  процессинга и за единицу. То есть, в принципе, если покопаться в различных математических,
[01:27:32.860 --> 01:27:38.180]  алгоритмических статьях, то есть много предлагаемых решений, той же самой задачи rmq и так далее.
[01:27:38.180 --> 01:27:44.060]  Ну это, наверное, самое классическое. Оно, наверное, встречается во многих курсах. Ну и плюс, наверное,
[01:27:44.060 --> 01:27:48.900]  одно из самых простых. Ну, по крайней мере, из того, что я видел. Вот. Есть еще один алгоритм,
[01:27:48.900 --> 01:27:53.900]  который описан на Codeforces. Я могу после лекции скинуть в чат. Если интересно,
[01:27:53.900 --> 01:27:59.100]  почитайте. Ну, там какие-то народные умельцы, в общем, описали алгоритм, который может решать
[01:27:59.100 --> 01:28:07.500]  ту же самую задачу rmq за линейное время и за вот единицы запроса. Вот. Но там, нам, кстати,
[01:28:07.500 --> 01:28:13.660]  используется точно такая же идея, но уже без сведения к LCA и тому подобное. Но как бы первоисточников
[01:28:13.660 --> 01:28:25.260]  я не нашел, поэтому рассказывать не стал. Вот. Ну, что еще можно сказать в заключении? Ну все,
[01:28:25.260 --> 01:28:29.300]  мы полностью, по сути, рассмотрели задачу rmq, рассмотрели задачу LCA. Да, поняли, что, на самом
[01:28:29.300 --> 01:28:34.420]  деле, с задачей LCA ничем не отличается с задачей rmq, то есть они взаимно друг другу сводятся. Вот.
[01:28:34.420 --> 01:28:38.700]  Ну и по поводу этого метода тоже, наверное, стоит сказать, что это довольно распространенный метод
[01:28:38.700 --> 01:28:43.740]  решения различных алгоритмических и других задач, который называется алгоритмом четырех
[01:28:43.740 --> 01:28:48.620]  русских. Вот. Ну, то есть в чем идея? Идея стоит в том, что если у вас есть какая-то большая задача на
[01:28:48.620 --> 01:28:53.940]  массиве, на матрице и так далее, то вы ее разбиваете на какие-то мелкие подмассивы, подматрицы. Дальше
[01:28:53.940 --> 01:28:58.740]  каждую отдельную подзадачу решаете в тупую, то есть просто предпочитываете там всевозможные ответы
[01:28:58.740 --> 01:29:03.380]  и так далее. И за счет этого каким-то образом достигаете ускорения результата. Вот. То есть,
[01:29:03.380 --> 01:29:07.620]  можно сказать, вот алгоритм Faraholten-Bender является там применением метода четырех русских вот к
[01:29:07.620 --> 01:29:15.580]  задаче rmq плюс-минус один. Вот. Поэтому, когда вы встретите там какой-нибудь алгоритм, то, может,
[01:29:15.580 --> 01:29:22.380]  какие-то аналогии найдете. Вот. Ну а на этом все, лекционная часть закончена. В общем, все,
[01:29:22.380 --> 01:29:29.140]  что я планировал так или иначе рассказать вот в этом семестре, я рассказал. Ну все, всем спасибо.
[01:29:33.380 --> 01:29:34.000]  Аплодисменты.
