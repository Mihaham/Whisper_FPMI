[00:00.000 --> 00:16.560]  У нас сегодня предпоследняя лекция в курсе. Разберем с вами в NoSQL парадигму, назовем ее так,
[00:16.560 --> 00:28.200]  и посмотрим сегодня на Neo4j, а в следующей лекции на еще, наверное, три варианта NoSQL
[00:28.200 --> 00:43.840]  базы данных, пастелирующих различные концепции. Ну что, давайте приступим. Итак, что такое NoSQL?
[00:43.840 --> 00:52.880]  Мы с вами, в принципе, закончили все темы, связанные с SQL, и, как вы знаете, SQL это у нас
[00:52.880 --> 01:02.440]  на самом деле не модель, а язык. И язык, который работает с представлением данных в виде релационной
[01:02.440 --> 01:14.600]  модели. NoSQL это такой mismatch, наверное, с точки зрения терминологии, потому что NoSQL обозначает
[01:14.600 --> 01:23.880]  у нас как раз ни язык, ни отсутствие SQL языка, который может быть в базах данных, реализующих
[01:23.880 --> 01:30.120]  релизационную модель. Ну как бы технически у нас релизационная модель не зависит от выбранного языка
[01:30.120 --> 01:39.280]  или используемого языка запросов. NoSQL говорит нам о том, что существуют целые другие парадигмы
[01:39.280 --> 01:45.160]  проектирования баз данных, представления данных и, соответственно, несколько иной способ
[01:45.160 --> 01:50.800]  манипулирования этими данными, ну просто потому что у нас SQL, он заточен именно на табличное
[01:50.800 --> 01:59.160]  представление, на представлении в виде отношений. NoSQL говорит о том, что язык может быть совершенно
[01:59.160 --> 02:06.960]  другой, именно потому что объекты, над которыми совершаются операции, не похожи на отношение
[02:06.960 --> 02:20.040]  в релизационной модели. В принципе, тоже можно такую несколько любопытную, ироничную,
[02:20.040 --> 02:26.080]  что может быть в исторической и исторической перспективе. Вещь отметить, что по большому
[02:26.080 --> 02:39.040]  счёту у нас SQL это база данных, ну или релизионные как нас таки. Это вот под период на протяжении
[02:39.040 --> 02:44.560]  большого периода развития систем управления данными, которые начали появляться, как мы помним
[02:44.560 --> 02:52.160]  из прошлых, из первых лекций, с шестидесятых ещё годов двадцатого века. И, конечно, первые
[02:52.160 --> 02:57.560]  модели, первые системы управления данными, они не были никакими релизионными, были, как вы
[02:57.560 --> 03:03.040]  помните, иерархическими сетевыми в первом приближении, ну не говоря уже до права. Системы,
[03:03.040 --> 03:10.920]  файловые системы первые файлы, первые варианты файловых систем. И только в 1969 году, тере семидесятом
[03:10.920 --> 03:19.200]  Edgar Cot опубликовал свою статью сначала в НУРИ корпоративном, её изложил, представил, потом
[03:19.200 --> 03:26.800]  опубликовал уже, так сказать, в широкой печати. И с тех пор началось развитие классической
[03:26.800 --> 03:34.400]  релизионной модели и релизионных систем управления баз данными. Но у SQL базы данных у нас
[03:34.400 --> 03:41.520]  появляются, то есть они были до 1969 года, можно говорить смело, и они у нас вновь, ну и продолжили
[03:41.520 --> 03:51.080]  даже на своё существование и после 69-80-го. И они у нас вновь появляются как мейнстримовое
[03:51.080 --> 03:58.840]  направление, где-то в районе начала 21-го века, конце 90-х годов, 20-го, начале 21-го века.
[03:58.840 --> 04:12.360]  Ну вот тоже маленькая историческая здесь напоминалка на слайде, а тоже таймлайн небольшой из того,
[04:12.360 --> 04:34.200]  что мы вот сказали. Сам термин, причём, сам термин, его атрибутируют некоему Карлу Стротце и по датировке
[04:34.200 --> 04:44.080]  о возникновении указывать на 98-м год. Но SQL так называлась как раз-таки релизионная СОБД,
[04:44.080 --> 04:54.720]  разрабатываемая Карлом Стротце, и которая не использовала как раз-таки язык SQL. И вместе с тем,
[04:54.720 --> 05:03.960]  опять же, как мы сказали ранее, вот этот мисмэтч в терминологии по поводу NoSQL,
[05:03.960 --> 05:10.120]  некоторые говорят о том, что последовательнее и логичнее было бы называть базы данных,
[05:10.120 --> 05:18.000]  не использующие релизионную парадигму NoRel, NonRelational, а не NoSQL. Но, тем не менее,
[05:18.000 --> 05:24.040]  термины прижились, термин прижился, и теперь всё, что не является релизионным, называется,
[05:24.040 --> 05:32.560]  по общему правилу, NoSQL. А в чём причина появления NoSQL-парадигмы? Ну, на самом деле,
[05:32.560 --> 05:39.720]  здесь есть определённые параллели с тем, почему появлялись хранилища данных. Единственно,
[05:40.400 --> 05:49.560]  если хранилища данных всё-таки появлялись как способ агрегации больших массивов информации
[05:49.560 --> 05:56.200]  в крупных компаниях, и, конечно, они не могли себе позволить легко и просто отказаться от
[05:56.200 --> 06:06.880]  такой наезженной, накатной дорожки строить SQL-подобные, релизионно подобные базы и хранилища.
[06:07.120 --> 06:15.560]  Как вы помните, Уильям Эйнман говорил о том, что DWH Data Warehouse должен быть,
[06:15.560 --> 06:23.760]  просто погрубляя, должен быть нормализованной до третьей формы базой данных релизионной.
[06:23.760 --> 06:30.200]  У Ральфа Кимпбала немножко более гибкий подход. Но, тем не менее, всё это базируется на таблицах,
[06:30.200 --> 06:41.880]  на отношениях и на каких-то базовых аспектах релизионной модели. SQL от всего этого отказывается,
[06:41.880 --> 06:47.400]  но тоже здесь в качестве причин возникновения это и Big Data большие объёмы данных,
[06:47.400 --> 06:59.640]  требующие легкой масштабируемости систем и частых операций чтения записи и наличия
[06:59.640 --> 07:08.680]  возникновения распространения повсеместно к концу 90-х уже годов интернета и веб-ресурсов
[07:08.680 --> 07:14.520]  в разработке, развитие новых парадигм разработки программного обеспечения,
[07:14.520 --> 07:27.680]  в частности Agile, потому что спроектировать хорошую, корректную с точки зрения релизионной модели
[07:27.680 --> 07:36.320]  схему базы данных, штука довольно непростая, прямо скажем. Это не просто какой-то небольшой
[07:36.320 --> 07:45.280]  учебный проектик на 3, 5, 7 таблиц, там могут быть десятки и сотни таблиц. Технически это
[07:45.280 --> 07:54.920]  довольно сложно, если особенно исповедовать топ-даун подход сверху вниз. Снизу вверх это
[07:54.920 --> 07:59.160]  ещё и проблемы налагают на то, как вы будете в последствии развивать вашу релизионную базу
[07:59.160 --> 08:05.440]  данных, потому что в принципе релизионная модель не очень гибкая с точки зрения её доработки
[08:05.440 --> 08:13.200]  в последующем. То есть вы как сформировали схему, концептуальную, логическую, физическую модель
[08:13.200 --> 08:18.320]  сформулировали, а если вы хотите как-то быстро поменять сущности, ну быстро у вас не получится,
[08:18.320 --> 08:25.800]  вам придется заниматься копированием данных, переформатированием этих данных возможно,
[08:25.800 --> 08:31.600]  то есть какие-то манипуляции, строить провежуточные хранилища и так далее.
[08:31.600 --> 08:39.360]  А парадигме Agile и в принципе с учётом увеличения скорости бизнес-процессов,
[08:39.360 --> 08:45.520]  скорости разработки, у нас нет времени на то, чтобы сидеть и разрабатывать нашу гениальнейшую
[08:45.520 --> 08:53.400]  базу данных на все случаи жизни нашего стартапа с прицелом на то, что он станет многомиллиардной,
[08:53.400 --> 08:59.840]  прошу прощения, корпорацией. Поэтому у нас должна быть какая-то иная технология
[09:00.600 --> 09:04.960]  разработки нашего хранилища информации,
[09:04.960 --> 09:11.760]  кое собственные были разработаны и представлены в конце девяностых, в начале нулевых годов первого
[09:11.760 --> 09:18.320]  варианта. Принцип работы религационной базы данных, вы помните, это ACID-концепция, это Misty
[09:18.320 --> 09:27.920]  Consistency Isolation Durability и первая поддержка всех этих принципов, реализованных в 1973 году в IBM,
[09:27.920 --> 09:39.840]  IMS-системе, но есть так называемая теорема CAP, CAP, теорема Брюер, мы о ней с вами уже говорили в
[09:39.840 --> 09:49.680]  рамках разговора про ACID-концепцию, но повторим немножко, то есть если мы попытаемся подняться
[09:49.680 --> 09:56.160]  на одну ступень выше, абстрагируясь от вот этих вот принципов религационной СОБД, это ACID
[09:56.160 --> 10:04.320]  свойств, то у нас получится, что да, что почему это теорема, на самом деле это тоже
[10:04.320 --> 10:09.920]  такой вводящий в заблуждение термин, это не теорема, это вот если вы откроете прям википедию,
[10:09.920 --> 10:14.880]  там с черным по белому написано, это евристическое утверждение, ну собственно так оно и есть,
[10:14.880 --> 10:22.880]  википедия это конечно в данном случае не такое нарушение аргументации, за отсылка к авторитету,
[10:22.880 --> 10:29.240]  но как бы по сути своей, это конечно никакая не теорема, никто ее не доказывал, никаких там
[10:29.240 --> 10:39.280]  аксиом и следствия из нее, ну таких вот в математическом смысле нет, но вот логически
[10:39.280 --> 10:44.200]  рассуждая, можно говорить, что есть три основных свойства, характеризующих любую базу данных или
[10:44.200 --> 10:50.640]  СОБД, вне зависимости от того, религационная она или нет, это consistency, availability и partition
[10:50.640 --> 10:55.200]  tolerance, то есть согласованность данных и доступности, устойчиваясь к разделению и
[10:55.200 --> 11:00.960]  максимизировать мы можем не более двух из них, можно это использовать вот этот вот такой
[11:00.960 --> 11:12.400]  категорийный подход к тому, чтобы классифицировать базы данных по указанным свойствам, и мы когда
[11:12.400 --> 11:18.560]  пытаемся максимизировать два из возможных свойств, то у нас здесь получается либо религиозные
[11:18.560 --> 11:24.440]  какие-то модели, например, когда мы говорим, что мы максимизируем согласованность и доступность,
[11:24.440 --> 11:31.480]  либо какие-то варианты NoSQL баз данных, в зависимости от того, какие свойства мы тоже
[11:31.480 --> 11:40.880]  пытаемся выкручить на максимум, на слайде, соответственно, показаны варианты такой вот,
[11:40.880 --> 11:45.680]  тоже не очень формальной, но разбивки по группам, потому что по большому счету,
[11:45.840 --> 11:50.880]  а у нас мы когда максимизируем два из трех свойств, это не значит, что у нас третье
[11:50.880 --> 11:58.000]  отваливается, то есть у нас все равно наши SQL базы данных, они все равно устойчивы к разделению,
[11:58.000 --> 12:06.560]  тем не менее, там просто будут проблемы с точки зрения параллельной обработки запросов,
[12:06.560 --> 12:12.600]  но тем не менее, кому-то придется может быть ждать, чтобы записать или прочитать,
[12:12.600 --> 12:19.920]  тем не менее, разделить ресурсы мы тоже можем, разделить процессы и ресурсы имеется в виду
[12:19.920 --> 12:28.560]  хранимые данные. Недостаток к максимизации параметров, здесь как бы понятно, если мы
[12:28.560 --> 12:36.920]  максимизируем доступность и согласованность, то у нас возникают проблемы, связанные с тем,
[12:36.920 --> 12:45.640]  что сеть и проблемы с сетью, например, могут застопорить систему, остановить работу система,
[12:45.640 --> 12:55.080]  воспрепятствовать ей серьезно. Если мы максимизируем согласованность и устойчивость к разделению,
[12:55.080 --> 13:01.600]  то у нас есть вероятность, что некоторые данные в моменте могут стать недоступными,
[13:01.600 --> 13:10.040]  или если мы максимизируем устойчивость к разделению и доступность, возможно,
[13:10.040 --> 13:20.080]  что у нас данные станут не согласованными. Если мы говорим о максимизации, рассматриваем
[13:20.080 --> 13:28.560]  сторону одной из сторон этого треугольника, и противолежащая вершина у нас уходит в минус,
[13:28.560 --> 13:36.960]  она, можно сказать, определяет нашу проблему. Мы максимизируем PEC, у нас A-availability
[13:36.960 --> 13:44.640]  становится вариантом, становится проблемой доступности и так далее.
[13:44.640 --> 13:56.520]  Опять же, рассуждая в категориях CAP теоремы, теоремы Брюера, мы говорим, что с одной стороны
[13:56.840 --> 14:10.200]  ее вариантом максимизации доступности и согласованности является реализованная модель,
[14:10.200 --> 14:17.560]  и тогда у нас по сути дела следствием является ACID-концепция. Но если мы
[14:17.560 --> 14:25.760]  подумаем еще, какие варианты мы сможем максимизировать, мы получим бейс-модель.
[14:25.760 --> 14:35.400]  Ей в некотором смысле руководствуется при проектировании NoSQL с УБД, но именно с точки
[14:35.400 --> 14:41.120]  зрения противопоставления ACID. То есть это концепция конкурирующая, и что такое бейс?
[14:41.120 --> 14:46.920]  Basically Available, то есть базовая доступность, мы гарантируем ответ на каждый запрос к данным,
[14:46.920 --> 14:52.920]  soft state – неустойчивое состояние, то есть данные могут меняться в отсутствие операции ввода,
[14:52.920 --> 14:59.160]  и eventual consistency – согласованность в конечном счете. Что это все значит более подробно?
[14:59.160 --> 15:06.680]  А почему soft state? Наверное, с этим разберемся сначала. Почему данные могут меняться в
[15:06.680 --> 15:11.520]  отсутствие операции ввода новой информации? Потому что у нас есть согласованность в конечном
[15:11.520 --> 15:18.160]  счете. То есть это значит, что у нас есть распределенная система, ее узлы в моменте,
[15:18.160 --> 15:23.920]  когда, например, в какую-то запись вносится изменение на каком-то узле, в моменте
[15:23.920 --> 15:31.320]  общее состояние всей этой системы может быть не согласованным, и в моменте у нас меняется только
[15:31.320 --> 15:37.040]  запись, только в конкретном узле, и мы этим самым гарантируем всегда, что у нас Basically Available
[15:37.040 --> 15:46.040]  свойство будет работать без проблем. Но поскольку у нас данные изменились только в одном узле,
[15:46.040 --> 15:53.440]  а нам нужно распространить на всю нашу сеть, которую собой представляет наша база данных,
[15:53.440 --> 16:00.000]  то под капотом всей нашей subd начинают происходить какие-то внутренние процессы,
[16:00.000 --> 16:05.240]  которые эти изменения от узла к узлу передают, и в конечном итоге на каком-то шаге у нас все узлы
[16:05.240 --> 16:12.200]  придут в состояние согласованности с теми первичными изменениями, которые произошли в узле номер 0.
[16:12.200 --> 16:21.800]  Вот так это на пальцах, на словах работает. Опять же, с точки зрения категории общих.
[16:21.800 --> 16:31.720]  Давайте перейдем посмотрим на какие-то конкретные варианты баз данных на ОСКЛ. Во-первых,
[16:31.720 --> 16:41.160]  существует множество категорий, то есть нельзя говорить о какой-то классификации.
[16:41.160 --> 16:50.440]  Классификация подразумевает основание деления, по которому мы подразделяем наш общий класс на
[16:50.440 --> 16:57.800]  члены деления. Но здесь мы не можем, наверное, все классы, исчерпывающие, описать. Какие-то
[16:57.800 --> 17:14.680]  появляются вновь какие-то, являются у нас мутанты, реализующие в себе свойства не одной конкретной
[17:14.680 --> 17:24.440]  модели, а нескольких. Но принято делить или можно разделить новый SQL базы данных на те варианты,
[17:24.440 --> 17:31.240]  которые на слайде приведены. K-value stores или storages – это хранилища ключа значения,
[17:31.240 --> 17:38.120]  то есть максимально простая штука. По сути дела, грубо говоря, это хранилища, хранение данных на
[17:38.120 --> 17:48.280]  хэштаблицах. Основная фишка, основное свойство, что у нас есть ключ, по которому мы всегда легко
[17:48.280 --> 17:57.720]  найдем значение. То есть, грубо говоря, это то свойство, которое гарантирует нам хэштаблицы. Там
[17:57.720 --> 18:01.560]  не обязательно, конечно, что все одна большая хэштаблица, какие-то более интересные и сложные
[18:01.560 --> 18:07.560]  алгоритмы реализованы, но базово можно рассматривать их как большие, большие сложные хэштаблицы.
[18:07.560 --> 18:18.040]  Column-oriented базы данных, то есть колончатые базы данных, в них еще выделяют, ну или как подвид,
[18:18.040 --> 18:25.000]  или как вариант, white-column базы данных, то есть широко колончатые, если прямо переводить на
[18:25.000 --> 18:32.200]  русский. Но это такие более частные, наверное, вопросы. Мы об этом сейчас поговорим через слайд
[18:32.200 --> 18:38.160]  буквально. Смысл в том, что здесь, в отличие от реализационных баз данных, физическое хранение
[18:38.160 --> 18:44.160]  данных организовано иначе. То есть, в реализационных базах данных у нас физически хранится, на каждой
[18:44.160 --> 18:54.240]  странице в файле хранится у нас строка. Наш вот этот tuple, nefcartage, строка таблицы. Колончатых,
[18:54.240 --> 19:00.600]  соответственно, друг с другом хранятся значения колонки. Значение внутри колонки имеется в виду,
[19:00.600 --> 19:06.920]  а не значение def из колонки. Значения там, конечно, дискретные по каждой ячейке. То есть,
[19:06.920 --> 19:12.920]  друг с другом хранятся значения внутри одной колонки. Ну, сами понимаете, в чем здесь плюс.
[19:12.920 --> 19:20.760]  Плюс в том, что у нас однотипные значения хранятся вместе. Проще, дисковые операции
[19:20.760 --> 19:26.920]  становятся заметно проще в том смысле, что у нас данные одного размера всегда хранятся рядом
[19:26.920 --> 19:35.020]  друг с другом. Возможно, может быть, проще в зависимости от типа данных. Может быть,
[19:35.020 --> 19:42.760]  проще их как-то заархивировать или компактнее хранить. И операции агрегации проводить на
[19:42.760 --> 19:49.160]  такого типа данных проще, потому что агрегация, как вы помните из всего нашего предыдущего курса,
[19:49.160 --> 19:56.120]  по сути, дело своей работает на колонках, а не на строках. Наши агрегатные функции,
[19:56.120 --> 20:09.720]  даже какие-то запросы Order By, запросы партиции, мы делаем их по колонкам как таковым, а не по
[20:09.720 --> 20:20.520]  строкам. Document Store с документно-ориентированной базой данных, документное хранилище. Смысл не в том,
[20:20.520 --> 20:28.120]  что мы храним файл в формате .docx. Вордовский файл или Excel файл или что-то в этом роде. Смысл в
[20:28.120 --> 20:35.800]  том, что у нас сущность несколько иная в этих базах данных. Называется она document. Там меняется
[20:35.800 --> 20:44.360]  в связи с этим структура хранения и сильно отличаются операции. Но если проводить какую-то
[20:44.360 --> 20:51.320]  аналогию, то, наверное, можно говорить, ну, очень так приближенно, что это похоже на JSON формат,
[20:51.320 --> 20:56.880]  скажем так. Графовые базы данных. Ну, здесь все понятно из названия, то есть бити графов у нас
[20:56.880 --> 21:02.200]  представлены на модели. И как раз сегодня мы о Neo4j с вами поговорим, чтобы пример был грубый и
[21:02.200 --> 21:13.640]  зримый, что называется. RDF stores данные представлены в стройках. Это уже что-то похожее больше на
[21:13.640 --> 21:25.520]  хранилище знаний, субъект, парадекат объект. Хотя хранилище знаний немножко иной подход. Объект,
[21:25.520 --> 21:35.160]  свойства значения, но тем не менее. Native XML, то есть база данных, ориентированная на работу с
[21:35.160 --> 21:45.400]  XML форматом строк или вот просто XML форматом значений. Не обязательно, что это именно строки,
[21:45.400 --> 21:57.320]  как строки будут представлены внутри. Хранилище контента целиком и search engines и поисковые
[21:57.320 --> 22:05.440]  движки. Например, Elastic Search. Content stores это такие условные штуки. Это что-то уже ближе к болотам
[22:05.440 --> 22:14.720]  данных и к озерам. Упоминаем мы здесь о них. По утилитарной на самом деле причине. Сейчас мы чуть
[22:14.720 --> 22:24.360]  ниже опустимся. По презентации вы увидите ссылку на сайт, сайт-агрегатор информации о различных
[22:24.360 --> 22:36.840]  типах баз данных. Категории этих No-Scale баз приведены в соответствии с тем, как на
[22:36.840 --> 22:44.240]  этом агрегаторе строится категоризация для удобства какого-то отталкивания от какого-то
[22:44.240 --> 22:53.720]  какого-то основания. Content stores предлагается выделять как специфический тип хранилища,
[22:53.720 --> 23:03.200]  но по большому счету. Он скорее больше похож на key value, но может быть. Просто у нас здесь нет
[23:03.200 --> 23:13.000]  ограничения по типу данных в атрибуте value.
[23:14.240 --> 23:26.560]  Мы там можем хранить условно говоря видео файл данной презентации, pdf, pptx, расшифровку
[23:26.560 --> 23:40.000]  речи лектора и так далее. Search engines тоже здесь вопрос больше к тому, что мы считаем No-SQL,
[23:40.000 --> 23:45.800]  потому что по большому счету search engine не обязательно база данных. Там конечно используется
[23:45.800 --> 23:53.520]  структура хранения, пресловутые инвертированные индексы, как собственно говоря правда и в
[23:53.520 --> 24:05.400]  самой Postgres. В Postgres это способ индексации, вариант индекса, а в поисковых движках инвертированные
[24:05.400 --> 24:14.800]  индексы. Это все-таки скорее основной способ доступа, основной способ контекстного поиска в
[24:14.800 --> 24:27.360]  базовой модели булева поиска. Базовая модель вот такой. Informational retrieval. Поиск информации по
[24:27.360 --> 24:37.600]  текстовым данным. Окей, мы с вами посмотрим на четыре моделя. Сегодня, повторюсь, графовая база
[24:37.600 --> 24:48.800]  данных NeoForge. На следующей лекции еще три оставшиеся. Сейчас просто общая обзорная
[24:48.800 --> 24:54.600]  характеристика каждого из перечисленных видов. Сейчас немножко углубимся с вами в
[24:54.600 --> 25:01.000]  column-oriented white-column DB, чтобы просто чуть-чуть лучше понимать, чем разница, потому что далее
[25:01.000 --> 25:12.720]  будем говорить с вами сегодня о white-column. И колончатые базы данных оптимизированы,
[25:12.720 --> 25:20.080]  как было сказано ранее, для операции агрегации аналитических запросов. По столбцам хранения
[25:20.080 --> 25:30.560]  данных тоже производится, позволяет удобную агрегацию изжать и осуществлять. Для ширококолончатых
[25:30.560 --> 25:38.560]  баз данных, в принципе, все тоже самое работает, но у нас более гибкая система с точки зрения того,
[25:38.560 --> 25:53.840]  что мы можем хранить данные в столбцах, но сами эти столбцы, они реализуют, в каждой строке,
[25:53.840 --> 25:57.760]  то есть все равно мы можем и строку считать. Просто, конечно, для колончатых баз данных это
[25:57.760 --> 26:03.960]  неэффективная операция, в отличие от классических реализованных. Но в каждой строке может быть разное
[26:03.960 --> 26:12.040]  число колонок, причем физически, что тоже позволяет, за счет именно физического не хранения лишних
[26:12.040 --> 26:20.120]  данных, пустых данных в той или иной строке, мы более оптимально и лучше с ними работаем,
[26:20.120 --> 26:30.640]  с данными хранимых и производим запросы. Ну и вот тоже здесь в классических колончатых
[26:30.640 --> 26:34.680]  структурах фиксировано и однородно, каждая запись или строка содержит данные для каждого
[26:34.680 --> 26:40.160]  столбца в ширококолончатых, каждая строка может иметь различный набор столбцов и так далее.
[26:40.160 --> 26:51.160]  А семейство столбцов в ширококолончатых базах тоже имеет место быть, то есть могут быть связанные
[26:51.160 --> 27:02.440]  столбцы, которые хранятся физически опять же вместе для более удобных операций чтения записи.
[27:02.440 --> 27:11.040]  Ну хорошо, разобрались с вами с вот таким небольшим различием колончатых и ширококолончатых.
[27:11.040 --> 27:16.960]  В принципе, это тоже такое условное несколько деление, потому что по большому счету мы можем
[27:16.960 --> 27:25.760]  настроить одну базу данных для работы так или иначе, одну колончатую или ширококолончатую,
[27:25.760 --> 27:31.680]  по сути дела это как правило, это даже часто одни и те же, там были, конечно, примеры и разные
[27:31.680 --> 27:36.720]  на предыдущем слайде, но по сути дела мы можем настроить часто ту или иную базу данных для
[27:36.720 --> 27:45.200]  работы с колонками в том или ином режиме. Хорошо, Key Value Stores, данные по рэнкингу
[27:45.200 --> 27:55.200]  соответствующих баз данных, это агрегация запросов, агрегация данных с гид репозиториев,
[27:55.200 --> 28:02.600]  где соответствующие проекты хранятся и так далее, то есть в принципе довольно авторитетный,
[28:02.600 --> 28:08.160]  скажем так, ресурс DB Engines, австрийская консалтинговая компания его ведет,
[28:08.160 --> 28:16.960]  ресурс с которым можно доверять с точки зрения общей информации по различным вариантам баз данных,
[28:16.960 --> 28:23.320]  и вот Key Value первое место Redis с большим довольно отрывом, и она много лет, собственно говоря,
[28:23.320 --> 28:31.680]  на первом месте и находится. Здесь, что еще можно отметить, Database Model,
[28:31.680 --> 28:37.280]  наверное, то есть если вы обратитесь вот этой колонке, вы увидите, что здесь есть либо
[28:37.280 --> 28:44.960]  multimodal, либо не одно, а несколько значений, но здесь только два Key Value и multimodal, но о чем это
[28:44.960 --> 28:51.240]  говорит? О том, что в принципе вот это все разделение, оно не то чтобы прям совсем
[28:51.240 --> 28:57.640]  условно и никому не нужно, все-таки Redis это часто именно как Key Value, но теоретически,
[28:57.640 --> 29:04.080]  если бы сильно захотим, мы можем нашу изначально колончатую базу данных Redis взять и сделать
[29:04.080 --> 29:11.680]  multimodal. Это будет не очень удобно, это будет не очень может быть эффективно, но теоретически
[29:11.680 --> 29:17.840]  это возможно, если, не знаю, там грубо говоря, у вас хорошая команда редисистов, я извиняюсь,
[29:17.840 --> 29:24.200]  сидит, и вы не хотите тратиться на то, чтобы приглашать специалистов по условному позгрызу и
[29:24.200 --> 29:31.880]  переливать данные в позгрыз, формировать какую-то классическую революционную схему данных и
[29:31.880 --> 29:40.600]  применять ее на практике в вашем бизнес процессе. А плюсы, наиболее простой вид из прочих, принцип
[29:40.600 --> 29:44.400]  работы аналогичного ассоциативного массива на хэштаблицах, отсутствует какая-либо схема
[29:44.400 --> 29:49.040]  данных, а value может быть любой объект, в качестве ключа могут выступать не единичные значения,
[29:49.040 --> 29:57.120]  а массивы. Минусы, за счет необходимости просмотра всей хэштаблицы, при чтении может не очень
[29:57.120 --> 30:02.880]  хорошо масштабироваться, подходит запрос при чтении соответствует, подходит только для очень
[30:02.880 --> 30:10.200]  простых данных, ну простых в том плане, не в том смысле, да, мы можем в принципе и архив какой-нибудь
[30:10.200 --> 30:19.320]  засунуть в value, поместить в раздел value и в архиве там можем накидать все что угодно,
[30:19.320 --> 30:26.680]  любой информации и по сути дела обойти вот так это ограничение. Но про простоту данных речь
[30:26.680 --> 30:32.760]  именно о том, что сложно структурированные данные, которые удобно не просто логически хранить,
[30:32.760 --> 30:39.040]  хотя наверное все-таки, которые удобно именно в первую очередь логически хранить раздельно,
[30:39.160 --> 30:43.680]  и именно за счет этого раздельного хранения мы можем строить какие-то осмысленные запросы. Вот
[30:43.680 --> 30:49.720]  для такого рода данных к value конечно не подходит. Понятно, что особенно с учетом того,
[30:49.720 --> 30:56.520]  что мы можем массивы использовать в качестве ключей, можно придумать историю, когда мы вот этот
[30:56.520 --> 31:10.760]  key value store берем и искусственными методами превращаем в что-то такое вот реалиционно подобное,
[31:10.760 --> 31:17.000]  что ли, да, делая сложные ключи, какие-то взаимосвязи и так далее. Но у нас все равно остается проблема,
[31:17.000 --> 31:22.680]  заключающаяся в том, что key value по умолчанию не оптимизирован для такого рода вещей. И если у
[31:22.680 --> 31:35.320]  вас возникает соблазн наводить сложные функциональные зависимости между значениями, хранящимися в вашей базе
[31:35.320 --> 31:41.520]  данных key value формата, то подумайте о том, чтобы все-таки использовать что-то иное, а не key value.
[31:41.520 --> 31:46.280]  Сложность с построением сложных запросов, ну, собственно, да, она протекает из того факта,
[31:46.280 --> 31:52.120]  что key value на это и не заточены. Все, что мы с вами попытаемся заточить, я извиняюсь,
[31:52.120 --> 31:57.400]  будет противоречить парадигме key value и будет выражаться просто-напросто в сложной логике
[31:57.400 --> 32:03.880]  поддержания всего этого, с одной стороны, и сложной обработке запросов, физически сложной,
[32:03.880 --> 32:15.240]  процедурно сложной для процесса, с другой стороны. WhiteColumnDB тоже с этого же сайта
[32:15.240 --> 32:23.360]  ranking DB engines. Здесь, опять же, тоже лидер привычный — это Кассандра. EdgeBase тоже, в принципе,
[32:23.360 --> 32:35.560]  довольно популярное решение, ну, популярное на практике, имеется в виду у нас. У нас, как бы так
[32:35.560 --> 32:48.680]  сказать, скажем так, по крайней мере, популярное было точно, скажем так, популярным. Вот как бы
[32:48.680 --> 32:55.800]  так аккуратно оговоримся обо всем этом. Но, тем не менее, тоже, как вы видите, в database module у
[32:55.800 --> 33:05.480]  нас есть варианты multimodule по отношению к некоторым участникам этого рэнкинга. Опять же,
[33:05.480 --> 33:15.880]  Microsoft Azure или Azure, Cosmos DB, как вы видите, и здесь занимает топ-позицию, при том, что это multimodule,
[33:15.880 --> 33:28.040]  опять же. Ну и, в принципе, это облачное решение от Microsoft популярное довольно-таки в бизнес-среде.
[33:28.040 --> 33:38.320]  Что здесь еще можно заметить? Да, пожалуй, наверное, и все. Перейдем к характеристикам. Плюс — это
[33:38.320 --> 33:42.520]  гибкость в физическом хранении данных. Строки таблиц распределяются по разным серверам. В строке
[33:42.520 --> 33:50.440]  могут быть колонки разных типов данных. Ну это тоже как бы такой, понимаете, условный плюс или минус.
[33:50.440 --> 33:56.960]  Где-то он может быть... Ну, собственно, сейчас мы об этом и скажем в минусах. Где-то он может быть
[33:56.960 --> 34:04.200]  плюсом, где-то может быть минусом. Быстрота обработки запросов по колонкам и хорошее сжатие. А минусы —
[34:04.200 --> 34:11.600]  долгая обработка запросов, извлекающих строки целиком. Ну, собственно, двулекий янус. Колонки
[34:11.600 --> 34:19.880]  можем хранить на разных серверах. Можем хранить раздельные даже на разных серверах, но может быть
[34:19.880 --> 34:27.880]  неэффективно. Долгая запись данных в строку и почти полная невозможность создания композитных
[34:27.880 --> 34:36.760]  индексов. То есть индексов там по более чем одной колонке. Ну тоже, да, вот понятные ограничения,
[34:36.760 --> 34:43.840]  проистекающие из, собственно, решения хранить данные физически по колонкам, а не по строкам.
[34:43.840 --> 34:50.320]  Но по большому счету можно еще сказать про колончатые базы данных, что это, наверное,
[34:50.320 --> 35:00.960]  одна из наиболее близких парадигм к SQL, к релиционной модели, по сравнению с остальными, которые мы здесь
[35:00.960 --> 35:07.600]  рассматриваем сейчас. Просто вот здесь может быть даже в большей степени вопрос в физическом
[35:07.600 --> 35:22.360]  разделении данных для работы с большими массивами данных однотипных. Документно-ориентированные базы
[35:22.360 --> 35:31.640]  данных. Опять же, здесь лидер, я думаю, известный, если не всем вам, то многим MongoDB. Также,
[35:31.640 --> 35:40.440]  как вы видите, есть и наш предыдущий участник Microsoft от Microsoft, и CosmosDB, и амазоновская
[35:40.440 --> 35:48.360]  DynamoDB тоже их решение для облачного сервиса. Ну тоже здесь, в общем-то, как вы видите,
[35:48.360 --> 35:53.720]  здесь данные за предыдущие годы, они практически, вот эти вот тройка, пятерка, получается,
[35:53.720 --> 36:04.200]  восьмерка лидеров не поменялось на протяжении трех лет, ну, двух, да, двух лет, и забесис тоже
[36:04.200 --> 36:12.200]  никаких с BDD дебла. Документно-ориентированные, здесь нет поддержки схемы данных, вообще никакой,
[36:12.200 --> 36:20.120]  да, то есть, если K-value это все-таки ключ значения, мы как-то, какие-то у нас наметки на некую,
[36:20.120 --> 36:27.800]  хотя бы, примитивную схему есть, есть какие-то ключи, есть, опять же, да, вот, по сути дела,
[36:27.800 --> 36:33.160]  поддержка релиционных операций и релиционного представления в колончатых базах данных,
[36:33.160 --> 36:41.560]  документно-ориентированных, такого нет. Храним мы документы в виде, в MongoDB, в виде JSON,
[36:41.560 --> 36:46.640]  например, и она хорошо для этого приспособлена. Быстрые чтения записи, удобные репликации,
[36:46.640 --> 36:52.240]  шардирования, но здесь нет никаких схем данных, опять же, это уже как видос идет,
[36:52.240 --> 36:59.280]  потому что мы их можем создавать только искусственно, непросто, да, вот, там, рисуя ограничения,
[36:59.280 --> 37:07.480]  как мы делали при создании таблиц и, формируя первичные внешние ключи, здесь и такого даже
[37:07.480 --> 37:15.120]  нету. Здесь все будет, ну, условно, все будет делать с руками. Плохая поддержка SQL подобных
[37:15.120 --> 37:21.920]  запросов, собственно говоря, да, вот, простекающие из предыдущих плюсов и минусов, у нас нет схемы,
[37:21.920 --> 37:28.480]  мы не можем сделать запрос по схеме. SQL-запрос, а это, по сути дела, следование некой схеме данных,
[37:28.480 --> 37:35.800]  по крайней мере, в логике запроса. Мы должны понимать, да, вот, какие у нас там есть отношения
[37:35.800 --> 37:45.040]  и хотя бы примерно, как они друг с другом взаимодействуют. Документ DB у нас, поскольку
[37:45.040 --> 37:50.680]  нет отношений и взаимодействия, мы такого рода запроса не то что построить не можем, можем,
[37:50.680 --> 37:55.960]  конечно, просто аппаратных, программных, да, программных средств СУБД для их оптимизации,
[37:55.960 --> 38:05.200]  вероятнее всего, не будет. Графовые базы данных, опять же, в очередной раз мы видим космос DB,
[38:05.200 --> 38:13.200]  вопрос о multimodal, о следовании парадигме мультимодальности в тех или иных вариантах.
[38:13.200 --> 38:23.160]  Ну, правда, в сетевых таких вот вендорных базах данных сложно сказать о поддержке мультимодальности,
[38:23.160 --> 38:32.800]  скорее, может быть, разные модули будут работать с теми или иными типами запросов и пользователи или
[38:32.800 --> 38:38.400]  разработчик просто, да, там, имея единый интерфейс, по сути дела взаимодействует с
[38:38.400 --> 38:44.240]  несколькими разными базами данных. Ну, ладно, это такие частости и спекуляции, а здесь первую
[38:44.240 --> 38:50.000]  строчку занимает уже много лет, даже вот помимо этого рейтинга, явно приведенного, просто много
[38:50.000 --> 38:57.160]  лет занимает Neo4j, как и, в принципе, на топовых местах в предыдущих табличках, те базы,
[38:57.160 --> 39:04.640]  которые представлены, они, как правило, с первого места очень много лет не смещаются.
[39:04.640 --> 39:12.680]  Плюсы, у нас строгая математическая модель, возможно, я бы даже сказал, более строгая в некоторых
[39:12.680 --> 39:21.320]  вещах, чем релиционная алгебра, релиционная модель, строить удобно специфические предметные
[39:21.320 --> 39:28.120]  области базы знаний, и что очень важно, гораздо удобнее расширять модель данных,
[39:28.120 --> 39:32.240]  мы, конечно, можем и там в документно-ориентированной базе данных расширять нашу модель,
[39:32.240 --> 39:39.960]  и в K-value, там, постоянно добавляя новые ключи, можно сказать, расширяем нашу вот такую привитивнейшую,
[39:39.960 --> 39:50.800]  одноуровневую модель. А здесь мы, сохраняя нашу строгость, математическую строгость графа,
[39:50.800 --> 39:56.480]  мы можем постоянно добавлять новые узлы, и при этом у нас будут работать все наши графовые алгоритмы,
[39:56.480 --> 40:08.480]  и таким образом очень удобно пополнять постоянно базы знаний, как отмечено, можно постоянно какие-то
[40:08.480 --> 40:15.400]  новые данные вносить, это удобно обрабатывать, это не будет влиять принципиально на скорость работы
[40:15.400 --> 40:24.440]  в рамках сложности работы того или иного алгоритма на графе и его реализации. Но есть, конечно, и минусы
[40:24.440 --> 40:34.000]  свои. Разнородные языки запросов у каждой графовой базы данных, нет стандарта по отрасли,
[40:34.000 --> 40:42.200]  ну, это, в принципе, так сказать, и для других баз данных, для других вариантов нового SQL
[40:42.200 --> 40:49.600]  баз данных характерно, но здесь может быть проблема именно в том, что на стандартную математику нашу,
[40:49.600 --> 40:59.840]  дискретную, всем известную, ложится слой семантики, которую нужно от продукта к продукту изучать,
[41:00.800 --> 41:09.840]  немножко знанного, скажем так. Не поддерживают абстракцию транзакций, такой более технический,
[41:09.840 --> 41:17.080]  наверное, момент, не будем, пожалуй, о нем подробно, ну, как бы не поддерживают, по-моему, молчание. То есть,
[41:17.080 --> 41:27.400]  вот эта вот атомарность, consistency, durability, isolation, и так далее, посложно обчитывать запросы с
[41:27.400 --> 41:38.560]  агрегированием, ну, потому что мы можем пройтись по всему графу нашему и подцеплять просто очень
[41:38.560 --> 41:45.360]  большое количество данных, а тогда как даже в стандартной революционной модели, вернее, базе
[41:45.360 --> 41:51.720]  данных, мы могли бы стандартным запросам, привычным надо это сделать, но самое главное,
[41:51.720 --> 41:59.280]  просто алгоритмы под капотом революционной базы данных, удобно бы собрали данные для агрегации.
[41:59.280 --> 42:08.840]  SQL и против новой SQL реальное положение дела. Что нам говорит этот слайд? Во-первых, опять же,
[42:08.840 --> 42:13.760]  обратите внимание на database model, здесь многие модели мультимодальные, многие базы данных,
[42:13.760 --> 42:21.800]  но, тем не менее, мультимодальность все-таки, и здесь она поставлена на второе место, и, по сути
[42:21.800 --> 42:27.440]  дела, так оно и есть, потому что вот все, что представлено в первой десятке, почти все,
[42:27.440 --> 42:36.320]  ну, за исключением, пожалуй, MongoDB и Redis, да и Elasticsearch, ну хорошо, большая часть из того,
[42:36.320 --> 42:41.220]  что представлено в первой десятке, это классические революционные базы данных, о которых вы либо
[42:41.220 --> 42:48.500]  слышали когда-то вообще, в принципе, они на слуху, либо мы о них прямо говорили, ну вот,
[42:48.500 --> 42:58.340]  на курсе, вот, о MySQL, а SQLite мы точно упоминали в таком общем беглом разборе различий на первых
[42:58.340 --> 43:05.820]  лекциях. Microsoft SQL Server, Oracle, просто популярные, известные решения, опустим их в доступность,
[43:05.820 --> 43:15.500]  да, это рейтинг такой общемировой, и понятно, что он не поменяется принципиально в зависимости
[43:15.500 --> 43:23.580]  там от доступности, недоступности того или иного продукта в том или ином регионе. Ну, не говоря
[43:23.580 --> 43:33.140]  уже там про всякие как бы варианты с лицензированием. А что нам это говорит, что нам говорит эта табличка,
[43:33.140 --> 43:37.340]  почему она интересна для нас, потому что, как вы видите, несмотря на большое количество различных
[43:37.340 --> 43:53.460]  парадигм, и вот этот вот score, он, скажем так, в одном пространстве, то есть он для всех баз
[43:53.460 --> 44:00.180]  данных в общем-то применим даже с независимости от того, что там та или иная парадигма используется,
[44:00.180 --> 44:05.580]  то есть мы можем по нему абсолютного победителя найти. Абсолютный победитель — это наша такая
[44:05.580 --> 44:10.980]  большая четверка классических реляционных баз данных. От реляционных моделей и баз никто не
[44:10.980 --> 44:20.380]  отказывается, это все равно наиболее популярная модель для бизнеса уж точно, и поэтому, да, вот в
[44:20.380 --> 44:27.820]  первую очередь, конечно, необходимо знать реляционную модель, уметь работать с реляционными базами
[44:27.820 --> 44:35.340]  данных, но и топовые решения по NoSQL, конечно, в общем виде хотя бы надо себе представлять.
[44:35.340 --> 44:43.100]  Так, хорошо. NoSQL — достоинство. Позволяет хранить большие объемы слабо структурированной
[44:43.100 --> 44:48.900]  информации в более-менее связанном виде, удобство масштабирования в сравнении с реляционными
[44:48.900 --> 44:53.300]  базами и системами управления баз данных, удобство репликации шардирования, быстрота
[44:53.300 --> 45:02.020]  разработки. Недостатки. Не требует проектирования схемы предметной области, поощряют накопление
[45:02.020 --> 45:06.780]  несогласованной информации в БД. Для сложных предметных областей схема данных стремится к
[45:06.780 --> 45:11.820]  реляционной по сути дела. Ну, вот так вот на практике складывается. Ну, либо как бы можно
[45:11.820 --> 45:17.300]  условно тоже сказать, что к графовой модели, может быть, она могла бы стремиться, и как мы с вами
[45:17.300 --> 45:22.860]  говорили, может быть, вы вспомните на первой лекции, что по большому счету то, что мы с вами видим на
[45:22.860 --> 45:28.020]  схеме наших данных, не что иное на схеме реляционных наших данных, когда вы проектируете,
[45:28.020 --> 45:32.940]  не что иное как граф, просто его вершина представлена сложным объектом в виде реляции,
[45:32.940 --> 45:40.540]  в виде отношений, в виде таблиц, но по большому счету все равно наш граф. Поэтому вот здесь такая
[45:40.540 --> 45:47.900]  есть взаимопродикновение на концептуальном уровне, но предметно, по сути, все равно нам,
[45:47.900 --> 45:55.060]  когда мы говорим о каких-то реальных данных, бизнес значимых, в крайней мере, у нас модель
[45:55.060 --> 46:03.780]  точно будет стремиться к реляционной. Поэтому мы, конечно, можем начать с MongoDB для нашего Agile,
[46:03.780 --> 46:14.140]  для нашего Agile, Scrum Scripts, Sprint, вернее, и pet-проектов или там стартапов использовать
[46:14.140 --> 46:23.740]  MongoDB, использовать еще что-нибудь, и проблема просто в том, что на каком-то этапе мы все равно
[46:23.740 --> 46:29.740]  поймем, что нужно все переделывать и ставить классический наш пресловутый Postgres, а то,
[46:29.740 --> 46:36.300]  может быть, еще и какой-нибудь Green Palm в качестве DWH, и переписывать то, что у нас есть,
[46:36.300 --> 46:41.860]  в понятную стандартную реляционную модель. Согласовываясь с конечным счетем,
[46:41.860 --> 46:48.260]  BASE принцип вносит риски и ошибок, но это то, что должно быть понятно из описания BASE,
[46:48.260 --> 46:59.020]  которое было дано выше. У нас может быть ситуация, когда у нас данные есть на одном узле и нет на
[46:59.020 --> 47:07.700]  других, и, соответственно, пока информация не пройдет, не распространится по всем узлам нашей
[47:07.700 --> 47:15.660]  сети, нашей системы, мы не узнаем, есть ли проблема в выданных пользователю данных, нет ли проблемы,
[47:15.660 --> 47:28.900]  не сможем даже, по сути дела, что-то сказать по существу. И напоследок, с точки зрения общего
[47:28.900 --> 47:37.220]  обзора, по крайней мере, это так называемые векторные базы данных. Здесь, скажем так,
[47:37.220 --> 47:46.340]  есть такая интересная история. Наверное, пару-тройку лет назад это было очень, наверное,
[47:46.340 --> 47:54.660]  интересно и перспективно. Сейчас, на текущий момент, по крайней мере, лично мне кажется,
[47:54.660 --> 48:01.220]  что это уже чуть менее перспективно с учетом развития больших языковых моделей, но о чем речь,
[48:01.220 --> 48:06.540]  давайте все-таки последовательно. Векторные базы данных, то есть мы хотим оптимизировать
[48:06.540 --> 48:13.260]  хранение и извлечение данных, представленных в векторном виде, то есть мы какие-то наши данные,
[48:13.260 --> 48:22.740]  как правило, текстовые, строковые, давайте более общий, может быть, термин возьмем, строковые
[48:22.740 --> 48:29.980]  данные могут быть чисто в этих строках. Строковые данные хотим превратить в эмбидинги, с помощью
[48:29.980 --> 48:37.660]  какой-то нейросетевой модели мы их превращаем, то есть они у нас становятся векторами в каком-то
[48:37.660 --> 48:42.900]  вот таком гиперпространстве, в многомерном пространстве, и мы хотим их хранить, мы хотим в них
[48:42.900 --> 48:54.220]  проводить быстрые операции, искать ближайших соседей, хотя сравнивать их по направленности векторов,
[48:54.220 --> 49:01.420]  по косинусу угла между ними. Как нам это все сделать? Можно говорить в этом смысле о векторных базах
[49:01.420 --> 49:06.060]  данных, но это примерно ситуация как с колончатыми и широко колончатыми базами, по сути дела это
[49:06.060 --> 49:15.180]  все еще кэй вэлью, скорее всего кэй вэлью база данных под капотом, а где просто будет храниться,
[49:15.180 --> 49:26.620]  хранится в качестве вэлью, в качестве значения вектора, мы да вот как бы некоторые механизмы там
[49:26.620 --> 49:34.340]  специфически конечно будут, там механизмы хранения, дата стор, индексирование, механизмы запросов,
[49:34.340 --> 49:40.740]  но это наверное не столь принципиально, здесь какой-то новый концепции, новый парадигмы того,
[49:40.740 --> 49:45.460]  как хранить данные, как это все представлять, по большому счету нет, мы просто удобно храним
[49:45.460 --> 49:53.820]  вектора и предоставляем их удобным тоже образом, по крайней мере физически удобным образом,
[49:53.820 --> 50:02.020]  для того чтобы обрабатывать алгоритмом. Вот стандартный вариант Facebook e-similarity search,
[50:02.020 --> 50:13.180]  ну скажем так, до последнего времени все еще стандартный, по которому мы с помощью этого алгоритма
[50:13.180 --> 50:21.460]  мы найдем по нашему запросу, тоже представленному в векторном виде, вектора, похожие на наш вектор
[50:21.460 --> 50:33.580]  запроса. Важное отличие от иных типов BD, мы при запросе получаем не стопроцентно правильный
[50:33.580 --> 50:40.340]  результат, ну по отношению к данным, хранящимся в нашей иной базе данных, мы либо получим в иных
[50:40.340 --> 50:46.980]  базах данных, либо получим по существу какой-то ответ, и он будет прям стопроцентно точно,
[50:47.540 --> 50:54.700]  мы сколько бы не повторяли наш запрос, при условии неизменности данных, наши ответы будут
[50:54.700 --> 51:03.500]  всегда идентичными. Здесь в принципе тоже при условии неизменности данных будут ответы
[51:03.500 --> 51:12.620]  идентичными, окей, но вероятность соответствия нашего ответа нашему запросу, она носит
[51:12.620 --> 51:21.140]  проблематичный характер, и в зависимости от того, как мы там изменим семантику вопроса, вернее даже
[51:21.140 --> 51:27.500]  не семантику синтакса, семантика может остаться такой же, у нас может поменяться сильно характер
[51:27.500 --> 51:33.820]  результатов из-за того, что вектора представления поменяются, и будет иной результат при сравнении
[51:33.820 --> 51:43.380]  вектора запроса, с векторами хранящимся в базе данных. Ну ладно, такие технические, может быть,
[51:43.380 --> 51:47.340]  излишние подробности, в принципе ничего сложного нет, просто храним вектора для того, чтобы удобно
[51:47.340 --> 51:56.860]  было искать как минимум к ближайших соседей, или просто к конкретному вектору, конкретный вектор
[51:56.860 --> 52:06.180]  сравнить с другим конкретным вектором. Типичные решения на текущий момент Мильвус, Пайнкон, Вивайт,
[52:06.180 --> 52:19.540]  ну или Пинкон. Вивайт, возможно, я неправильно произношу заранее, прошу меня извинить, не работал,
[52:19.540 --> 52:29.820]  честно говоря, с этой базой данных, но просто она есть, она в числе таких вот и более распространенных
[52:29.820 --> 52:39.420]  на данный момент. Давайте кратко посмотрим теперь на то, как в Neo4j представляются данные,
[52:39.420 --> 52:49.220]  и как с ними происходит взаимодействие. Neo4j получается, это наша графовая база данных,
[52:49.220 --> 52:57.140]  топовая графовая база данных. Как мы уже с вами сказали, здесь есть сильная подлежащая математика,
[52:57.140 --> 53:06.060]  теория графов. Она, если не интересно нам с точки зрения, может быть, построения базы данных
[53:06.060 --> 53:14.180]  самой по себе, то она точно нам интересна с точки зрения того, что мы можем, не боясь строить базы
[53:14.180 --> 53:22.140]  знаний, строить какие-то гибкие расширяемые модели, и нам будет с ними удобно-комфортно работать
[53:22.140 --> 53:30.820]  впоследствии, потому что математика, даже может быть не математика, уже алгоритмика какая-то,
[53:30.820 --> 53:38.620]  вот работа с графами, она позволяет довольно просто, ну понятно и предсказуемо с ними обращаться.
[53:38.620 --> 53:47.180]  А что у нас такое, что у нас с моделью данных в Neo4j? Данные и отношения между ними представлены
[53:47.180 --> 53:55.780]  в виде трех объектов модели. Узлов, ну или вершин в графе, отношений и свойств. То есть,
[53:55.780 --> 54:11.100]  у нас есть узел, это на рисунке в данном случае. В данном случае это вот такие кружки, отношения
[54:11.100 --> 54:21.180]  это стрелочки или ребра, и свойство это то, что у нас находится в, ну те данные о кружках, скажем так,
[54:21.220 --> 54:33.540]  об узлах, которые мы записываем. Узлы представляют собой сущности или объектов в графе, они похожи
[54:33.540 --> 54:42.060]  на записи или объекты в традиционной базе данных. Ну давайте для простоты записи. Узлы это все
[54:42.060 --> 54:46.420]  равно что записи, и каждый узел может иметь одну или несколько меток, которые определяют его роль
[54:46.420 --> 54:51.980]  и тип в графе. Метки помогают эффективно организовывать и запрашивать данные. Узлы могут
[54:51.980 --> 54:56.420]  иметь свойства, которые представляют собой пары ключезначения, представляющие дополнительную
[54:56.420 --> 55:06.460]  информацию об узле. То есть, вот здесь Person и Actor это метки, Name и Board, это соответственно наши
[55:06.460 --> 55:15.220]  записи, наши свойства, работающие по типу ключезначения. Узлы могут иметь метки Labels и
[55:15.220 --> 55:26.620]  пример синтекса создания узла Create, Person, Actor и вот метки, и внутри узла ключезначения Name,
[55:26.620 --> 55:34.900]  Tom Hanks, Born 1956 год. Про это свойства. Это пары ключезначения, которые используются для хранения
[55:34.900 --> 55:40.580]  данных об узлах и отношениях. Значение свойства может содержать различные типы данных, такие как
[55:40.580 --> 55:47.100]  число, строка или булевые значения, и содержать список или массив, состоящий, например, из строк,
[55:47.100 --> 55:53.140]  чисел или булевых значений. Компоненты должны принадлежать при этом к одному типу. Вот пример
[55:53.140 --> 55:58.420]  создания свойств со значениями разных типов. Ну опять же, мы по большому счету создаем именно
[55:58.420 --> 56:10.140]  узел, да, новый, с меткой Example, и внутри него свойства. A, единичка, C, строка, B, число
[56:10.140 --> 56:20.420]  с плавающей точкой. Действительное число, да, будем все-таки по-русски, наверное, выражаться.
[56:20.420 --> 56:32.660]  И F это массив, как пример. Отношение, опять же, описываются в связи. Узел может иметь петлю,
[56:32.660 --> 56:42.020]  отношение с самим собой. Звучит, наверное, не очень. Отношение узла может замыкаться на рем само,
[56:42.020 --> 56:47.060]  скажем так. Отношения всегда направлены и имеют начальный узел, то есть наш граф всегда
[56:47.060 --> 56:56.260]  ориентированный. По большому счету мы, конечно, можем это игнорировать, как бы не используя некоторые
[56:56.260 --> 57:07.540]  уловки. Но по умолчанию это ориентированный граф, и тоже отношения у нас могут иметь и тип, и метку,
[57:07.540 --> 57:16.740]  и могут иметь соответственно свойства, которые вот представлены на слайде в виде синкса,
[57:16.740 --> 57:27.700]  на примере синтакса создания отношения. Вот у нас метка или тип, acted in, и свойство roles forest
[57:27.700 --> 57:46.060]  performance 5. Ну да, вот это про Тома Хэнкса, собственно, что он играл, в какой роли, и performance значимость,
[57:46.060 --> 57:50.340]  может быть, исполнение какая-то дополнительная техническая информация. И в данном случае
[57:50.340 --> 57:59.060]  здесь слева и справа должны быть некие узлы, они в примере не показаны, но слева, очевидно,
[57:59.060 --> 58:06.060]  должен быть Том Хэнкс, справа должен быть Форест Гамп, фильм. Ну или, вернее, слева будет
[58:06.060 --> 58:15.340]  actor-person-узел, а справа будет узел-фильм. И вот здесь пример создания элементарной базы
[58:15.340 --> 58:21.780]  данных, то, о чем мы только что сказали. Вот узлы, ну, в общем-то, то, что было, наверное,
[58:21.780 --> 58:28.620]  на предыдущих слайдах, на начальном слайде про Neo4j. Вот мы создаем узел, причем мы сразу
[58:28.620 --> 58:38.380]  обратите внимание, создаем все, что показано на иллюстрации, мы создаем одним запросом. Это
[58:38.380 --> 58:46.660]  не обязательно, но вот можно и так, скажем. А мы создаем person-actor, Том Хэнкс, именно дата
[58:46.660 --> 58:56.620]  рождения, где играл, какую роль исполнял. Дальше показываем, к какому узлу относятся отношения,
[58:56.620 --> 59:06.460]  относится наш первый узел, это узел-фильмы, здесь у него есть свойство названия фильма,
[59:06.540 --> 59:16.660]  и с другой стороны у нас тоже к этому же узлу фильмы дополнительно есть отношения с новым узлом,
[59:16.660 --> 59:24.300]  это, по сути, своей режиссер, но здесь обозначено как просто персону, то есть, по сути, дело мы,
[59:24.300 --> 59:30.140]  для чего это сделано, person-person, для, опять же, вот, это метки, это такая, в некотором смысле,
[59:30.140 --> 59:37.780]  техническая информация, потому что, когда мы будем задавать вопрос по людям, система СУБД у
[59:37.780 --> 59:45.020]  нас отработает лучше, если мы не просто скажем, что здесь у нас актер, а здесь режиссер, а мы еще
[59:45.020 --> 59:51.660]  укажем, что они к одному классу принадлежат, то есть, к классу персон, к классу физических
[59:51.660 --> 01:00:00.300]  лиц, к классу людей, например, но можно здесь, в этом узле было бы добавить еще и директор,
[01:00:00.300 --> 01:00:18.100]  метку для дополнительной информации. Для наших запросов используется собственный язык Neo4j,
[01:00:18.100 --> 01:00:26.700]  используется Cypher Query Language, CQL, он немного похож, ну, вы уже, собственно, и видели на SQL,
[01:00:26.700 --> 01:00:40.020]  что-то вот такое смутно, смутно похожее на Create Table, было в слове Create, что-то похожее на
[01:00:40.020 --> 01:00:46.780]  Command Create Table, в виде Create, Command Create для создания узла используется, ключевые слова также есть
[01:00:46.780 --> 01:00:54.860]  в виде Match, Where, Create, Delete, Return и другие. Пример поиска по паттерну, приведен на слайде,
[01:00:54.860 --> 01:01:08.860]  Match, Me, Nodes, Nose и Remote Friend, то есть, нужно найти такие вот узлы, которые у нас соответствуют
[01:01:08.860 --> 01:01:24.380]  приведенному отношению, где имя первого узла это Филиппа, а нужно найти, по сути дела,
[01:01:24.380 --> 01:01:37.260]  всех друзей, вот так скажем, всех друзей некоей Филиппы, которая у нас еще и итеративно будем
[01:01:37.260 --> 01:01:51.260]  проходить по нашему графу. Есть агрегирующие функции? Можем ли мы конкретный узел найти,
[01:01:51.260 --> 01:01:57.500]  вы имеете в виду? Вопрос, да, есть у вершины или ребер что-то вроде первичных ключей или
[01:01:57.500 --> 01:02:06.620]  идентификаторов? Ну, как бы, точно есть на физическом уровне, безусловно, а с точки зрения того,
[01:02:06.700 --> 01:02:12.620]  можем ли мы найти какой-то конкретный узел, который нас интересует, просто вот сказав,
[01:02:12.620 --> 01:02:22.220]  задав запрос типа Find там ID такой-то, но мы можем сделать лист всех узлов и выбрать нужный,
[01:02:22.220 --> 01:02:25.820]  если мы не знаем схему. Если мы знаем схему, то теоретически у нас должна быть где-то
[01:02:25.820 --> 01:02:32.300]  графическая модель, как вариант, но техническая информация, безусловно, есть, просто вопрос здесь
[01:02:32.300 --> 01:02:40.860]  такой, как бы, да, зачем она нам нужна. Не совсем может быть понятным, повторюсь,
[01:02:40.860 --> 01:02:48.660]  мы можем список узлов построить и выбрать, есть два варианта, повторюсь, мы знаем схему и нам
[01:02:48.660 --> 01:02:54.180]  не нужен ID-шник, потому что мы просто-напросто знаем, у нас есть какой-то, не знаю, рисунок,
[01:02:54.180 --> 01:03:00.860]  какая-то схема графическая, где у нас там все узлы. Мы не знаем схему, тогда нам нужно, как минимум,
[01:03:00.860 --> 01:03:06.420]  сделать список узлов, мы можем это построить и уже по конкретному узлу найти что-то похожее на то,
[01:03:06.420 --> 01:03:15.660]  что нас интересует. Технически, безусловно, есть ID какой-то, там ID записи на диске, ID внутри
[01:03:15.660 --> 01:03:26.060]  системы, которая будет значима для системы, но напрямую мы его можем просто физически и искусственно
[01:03:26.060 --> 01:03:27.060]  добавить, пожалуй, так.
[01:03:27.060 --> 01:03:41.180]  Так, если кто-то что-то сказал, то да, я не слышу, к сожалению, ребят, почему-то.
[01:03:41.180 --> 01:03:44.860]  Сейчас меня тоже, да, я слышу.
[01:03:44.860 --> 01:03:59.380]  Поэтому либо повторите запрос в чат по поводу слышимости, но на вопрос с ID-шником, мне кажется,
[01:03:59.380 --> 01:04:10.540]  нельзя добавить узел с уже существующим узлом. Не совсем понимаю, узел у нас,
[01:04:10.540 --> 01:04:14.940]  узел это вершина, что значит добавить вершину с уже существующим вершиной?
[01:04:14.940 --> 01:04:26.060]  Запрос, да, вот дополнительно уточняющий запрос, если получается нельзя добавить связь,
[01:04:26.060 --> 01:04:36.620]  а связь с уже существующим узлом. Почему? Нет, мы можем добавить новую связь. Нет,
[01:04:37.100 --> 01:04:43.620]  не обязательно нам указывать все связи с новым узлом, не совсем понимаю. Просто у нас будет,
[01:04:43.620 --> 01:04:55.700]  грубо говоря, команда Create, где мы, для простоты, будет Create какой-то узел, и от него будет
[01:04:55.700 --> 01:05:07.540]  вот там стрелочка, где будет соответственно адрес назначения в виде существующего узла.
[01:05:07.540 --> 01:05:12.020]  Ну, не знаю, извините, может быть, не совсем понимаю, но давайте
[01:05:12.020 --> 01:05:17.220]  двигаемся дальше, сейчас, может быть, вернемся, или станет понятнее, о чем речь.
[01:05:28.420 --> 01:05:37.900]  Просто указав узел. Ну ладно, ребят, давайте сейчас договоримся и вернемся к этому чуть-чуть,
[01:05:37.980 --> 01:05:45.300]  чуть-чуть попложе, здесь немного осталось. Так, есть агрегирующие функции, допустимо,
[01:05:45.300 --> 01:05:53.740]  использовать стандартные операторы, сравнение логические операторы. Да, вот match и вот where и
[01:05:53.740 --> 01:06:01.540]  order by вообще очень похожи на то, что бы с вами видели в релиционных, вернее, в нашем SQL. Здесь все,
[01:06:01.540 --> 01:06:16.700]  соответственно, все узлы с соответствующим типом найдутся при условии, что некое свойство больше
[01:06:16.700 --> 01:06:28.300]  10. Помимо Create, для определения данных используется также конструкция set, delete и merge. Используется
[01:06:28.300 --> 01:06:32.420]  для исключения дубирования данных, в примере вышки узел не будет создан, если в BD уже есть
[01:06:32.420 --> 01:06:52.460]  узел с аналогичными свойствами. Я понял, да, по умолчанию Create создаст новый узел одноименный,
[01:06:52.460 --> 01:07:02.140]  здесь нужно использовать либо set, либо merge, например, в примере. Не обязательно использовать,
[01:07:02.140 --> 01:07:15.660]  то есть Create создает заново, просто другая команда будет использоваться. Смотрите,
[01:07:15.700 --> 01:07:26.340]  у нас допускает создание пользовательских функций, еще раз возвращаемся. Если будет
[01:07:26.340 --> 01:07:36.780]  просто Create использоваться, то у нас будет создаваться новый узел. При этом,
[01:07:36.820 --> 01:07:55.340]  когда мы используем Create для создания отношения, она работает более осмысленно. Если вы укажете
[01:07:55.340 --> 01:08:08.180]  просто метку узла, то у вас он не будет создаваться заново, он будет найден и по нему
[01:08:08.180 --> 01:08:19.140]  будет создано отношение. Если метки совпадают, система выдаст уточнение, уточняющий запрос и
[01:08:19.140 --> 01:08:28.020]  попросит вас как-то специфицировать, но по идее метки, скорее всего, совпадать не будут,
[01:08:28.020 --> 01:08:32.100]  потому что иначе не совсем понятно, вернее, они в принципе не могут совпадать вот так,
[01:08:32.100 --> 01:08:36.940]  потому что не совсем понятно, как тогда эти узлы классифицировать. Если у вас будет 2 Person
[01:08:36.940 --> 01:08:44.380]  и Actor, то непонятно, зачем они, как бы логически непонятно, и система не даст вам это создать
[01:08:45.100 --> 01:08:57.220]  Любое добавление информации в Person и Actor будет всегда идти в раздел с ключ значения и все. Поэтому
[01:08:57.220 --> 01:09:05.260]  если вы хотите связь именно создать, вам нужно указать метки, которые вы указывали при создании
[01:09:05.260 --> 01:09:12.260]  узла. И по сути дела метками у вас специфицируется ваша связь. Ну конечно, там можно сразу начинать
[01:09:12.260 --> 01:09:17.580]  думать о том, что, а если у нас десяток меток? Если у нас десяток меток, тогда есть вопрос в том,
[01:09:17.580 --> 01:09:23.900]  насколько у вас адекватно с вашей предметной области спроектирована ваша база данных.
[01:09:23.900 --> 01:09:31.580]  Действительно ли там должно быть 10 меток для узла или может быть должно быть 5 узлов по 2 метки
[01:09:31.580 --> 01:09:39.060]  и просто со связями между ними. Поэтому здесь вот так вот. Так что ваши ID-шники, по сути дела,
[01:09:39.060 --> 01:09:55.020]  это Person и Actor. Также еще вы можете дополнительно создавать связи. Что еще здесь? Мерч, мы сказали,
[01:09:55.020 --> 01:10:09.020]  да, позволяет исключать дублирование. Ну как бы да, хорошо прощение тогда. Получается все-таки
[01:10:09.020 --> 01:10:14.940]  Create можно создать, окей. Create можно создать дублирующий узел, лучше тогда использовать мерч
[01:10:14.940 --> 01:10:20.900]  для того, чтобы создавать новые узлы в незнакомых по крайней мере вам базе данных. И
[01:10:20.900 --> 01:10:40.020]  связь у нас будет специфицирована опять же метками. Насколько я знаю, насколько я с этим работал,
[01:10:40.020 --> 01:10:48.980]  это не был какой-то большой продакшн, признаюсь честно, но метками специфицируют вершины. И по
[01:10:48.980 --> 01:10:54.060]  большому счету все. Вы можете создать дубль, вы можете использовать мерч, чтобы дубль не
[01:10:54.060 --> 01:11:01.500]  создавать. Вы можете командой Set создать какие-то дополнительные лейблы назначить. Ну вот как-то так.
[01:11:01.500 --> 01:11:10.380]  Смотрите, давайте общий ответ, наверное, будет такой. Если вы хотите прям досконально в командах
[01:11:10.380 --> 01:11:15.180]  разобраться, все-таки здесь не буду кривить душой, лучше использовать документацию. Ну у нас такая
[01:11:15.180 --> 01:11:26.580]  обзорная задача, пожалуй, так. Отличаются узлы у нас все-таки только метками на уровне запросов. Мы
[01:11:26.580 --> 01:11:34.460]  ID-шник. Технически, наверное, можно указать какой-то ID, какая-то специальная команда точно
[01:11:34.460 --> 01:11:41.300]  должна быть, но в более-менее реальной ситуации это будет просто скорее всего метка. Те метки,
[01:11:41.300 --> 01:11:54.020]  которые вы назначили на узел, по ним следует ориентироваться. Ничего не мешает. Мы можем
[01:11:54.020 --> 01:12:05.100]  создать совершенно справедливо новый узел Person Actor. Он будет дублироваться. И как раз
[01:12:05.100 --> 01:12:11.180]  команда Merge используется для исключения дублирования данных. В примере Wish узел не будет создан,
[01:12:11.180 --> 01:12:19.580]  то есть вот в этом примере. Merge Movie Title Matrix ER 1999. Узел не будет создан, если в BD уже есть
[01:12:19.580 --> 01:12:35.380]  узел с аналогичными свойствами. Вот, собственно, вот так вот. Так. Хорошо, давайте мы двинемся
[01:12:35.380 --> 01:12:43.380]  чуть дальше. У нас будет лекция. Я чуть-чуть подробнее тогда синтаксис. Буквально один слайд
[01:12:43.380 --> 01:12:49.820]  сделаю по командам. В целом, что у нас еще? Допускается создание индекса? Да, допускается
[01:12:49.820 --> 01:12:53.700]  создание. Так, ну это я уже говорил. Единственное, может быть, меня не было слышно, но, в общем-то,
[01:12:53.700 --> 01:13:00.820]  здесь все на слайде описано. Давайте немножко просто запросов. Посмотрим, как они работают.
[01:13:00.820 --> 01:13:15.060]  Match John Thorson. Name John. Match John Friend. Friend. Нужно найти имя друга, и будет оно выдано как
[01:13:15.060 --> 01:13:28.540]  Friend Name в колонке. Вот у Джода есть узел, персона, имя John, и мы соответственно ищем по отношению
[01:13:28.540 --> 01:13:48.820]  Friend всех друзей Джона, которые у нас предыдущим графом представлены. И Match John Thorson и Name John
[01:13:48.820 --> 01:13:57.180]  у нас будет соответственно выдано, только наш верхний узел будет выдан. По узлу, это три разных
[01:13:57.180 --> 01:14:11.620]  запроса, если что. По узлу у нас... Рекурсия по графу? Да нет, графовые алгоритмы не обязательно
[01:14:11.620 --> 01:14:24.100]  рекурсивные. Ну еще раз, это три разных запроса. Это раз. Два? Не обязательно. Не скажу сейчас,
[01:14:24.300 --> 01:14:39.420]  как под капотом работает Matching в Neo4j. Да-да-да, три разных. Но нет, на базовых графовых алгоритмах,
[01:14:39.420 --> 01:14:49.780]  если вы помните рекурсии, по-моему, обход ширину, длину, там можно все это... В принципе,
[01:14:49.780 --> 01:15:02.740]  ну ладно, это немножко уже другая история. Мы по связи друг ищем друзей Джона, и вот у нас
[01:15:02.740 --> 01:15:14.540]  появляется John и Friend, Sarah и Joe. Вот Sarah, вот Joe. Мария и Стив – это друзья, соответственно,
[01:15:14.540 --> 01:15:25.980]  Sarah и Joe, поэтому они у нас не попадут во второй запрос. И то же самое. Здесь раз два запроса,
[01:15:25.980 --> 01:15:36.140]  три третий запроса. Это, по сути дела, прикрепляется ко второму. Это вариант второго,
[01:15:36.140 --> 01:15:42.180]  когда у нас просто выдача изменится. Мы таким вот Return форматируем то, что у нас появляется.
[01:15:42.180 --> 01:15:46.860]  Ну, такая немножко техническая история. Прошу прощения, два запроса, по сути дела.
[01:15:46.860 --> 01:15:59.900]  Еще пример запроса. Мы ищем персону, где имя начинается с буквы J, и мы создаем для этой
[01:15:59.900 --> 01:16:11.540]  персоны, для этого человека друга с именем JJ. Что у нас получается? Вот сначала у нас находится
[01:16:11.540 --> 01:16:19.940]  запрос. Вот на этой стадии запроса... Прошу прощения. Сначала у нас находятся люди с именами
[01:16:19.940 --> 01:16:28.860]  Jay, начинающиеся. Вот у нас промежуточная стадия, такой результат. Вот мы нашли Joe и John из нашего
[01:16:28.860 --> 01:16:35.220]  предыдущего графа. Остальных друзей мы не нашли. Но если бы у нас был здесь какой-нибудь
[01:16:35.220 --> 01:16:49.860]  Joy, женское имя, тоже бы это попало в нашу выдачу. У нас было бы здесь вот так вот три узла из пяти.
[01:16:49.860 --> 01:17:00.420]  Дальше наш запрос создает новых друзей для людей с именем John, с именем на John и Jay,
[01:17:00.420 --> 01:17:10.980]  с именем на Jay. И создаются вот PersonNameJJ, PersonNameJJ. В принципе, получается, что у нас
[01:17:10.980 --> 01:17:19.180]  здесь дублируется наш узел. Не очень, наверное, хорошо. Но мы его впоследствии можем смёржить
[01:17:19.460 --> 01:17:29.180]  и сделать в один. У нас будет две связи. Один узел. Здесь немного другая история. Здесь такого
[01:17:29.180 --> 01:17:36.940]  примера не будет. Что еще можно вспомнить? У нас на первом слайде были рекомендации по
[01:17:36.940 --> 01:17:41.420]  интерпретации релиционных данных в графовые. Прямо вот из официального руководства,
[01:17:41.940 --> 01:17:50.940]  если перейдете по ссылке, то увидите, что проку в нашей таблице можно интерпретировать как вершину.
[01:17:50.940 --> 01:18:00.300]  Таблицу в релиционной базе можно, вернее, имя таблицы в релиционной базе можно интерпретировать как
[01:18:00.300 --> 01:18:14.140]  имя, как метку вершины. То есть, имя-отношение – это метка вершины. Join или foreign key – это
[01:18:14.140 --> 01:18:21.900]  операция. Foreign key – это ограничение. Но, тем не менее, там можно интерпретировать как дугу,
[01:18:21.900 --> 01:18:33.340]  как вот эту вот связь, стрелочку, которая у нас на слайде показана. Почитать еще официальная
[01:18:33.340 --> 01:18:43.420]  документация Google. Вопросы были заданы. Я их запомнил из всех попрашающих. Давайте я немножко
[01:18:43.420 --> 01:18:49.980]  обновлю, потому что, честно скажу, довольно продолжительное время назад пользовался
[01:18:49.980 --> 01:18:56.580]  Neo4j. Штука интересная, любопытная. Она с точки зрения того, как на релиционную нашу привычную
[01:18:56.580 --> 01:19:04.780]  модель, которую мы уже, в принципе, восприняли, ложится в голове, интересна. И чуть-чуть, вот буквально
[01:19:04.780 --> 01:19:15.580]  на слайде, на следующей лекции сделаю примеров, покажу, как что работает для наглядности,
[01:19:15.980 --> 01:19:27.060]  чтобы закрыть Neo4j. На следующей лекции у нас тогда колончатые документные и key value и ключ
[01:19:27.060 --> 01:19:35.100]  значения будет по одному примеру. Наверное, radius ключ значения, колончатые, click house и,
[01:19:35.100 --> 01:19:42.060]  что еще у нас, документно ориентированные. Наверное, Mongo.
