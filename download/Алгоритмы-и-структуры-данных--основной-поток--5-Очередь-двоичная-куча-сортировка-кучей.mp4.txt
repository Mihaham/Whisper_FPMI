[00:00.000 --> 00:07.120]  У меня остался небольшой долг с прошлого раза, про
[00:07.120 --> 00:08.600]  очередь я не успел рассказать.
[00:08.600 --> 00:16.400]  Значит, очередь очень похожа на стэк структура, только
[00:16.400 --> 00:18.480]  с другого конца приходят запросы.
[00:18.480 --> 00:21.720]  Значит, очередь это такая структура данных, которую
[00:21.720 --> 00:23.800]  мы будем отвечать опять-таки на запросы.
[00:23.800 --> 00:27.160]  Мы очень часто будем структуру описывать функционалом,
[00:27.160 --> 00:29.060]  то есть, что мы от них требуем, на какие запросы они должны
[00:29.060 --> 00:30.060]  отвечать.
[00:30.060 --> 00:32.660]  Вот очередь один из таких примеров.
[00:32.660 --> 00:34.860]  Значит, во-первых, мы хотим уметь добавлять элемент
[00:34.860 --> 00:40.140]  в очередь, push x, это добавить x в очередь.
[00:40.140 --> 00:48.900]  Давайте я пишу в конец очереди, в конец, значит, front это
[00:48.900 --> 00:57.020]  узнать элемент из начала очереди, узнать элемент
[00:57.020 --> 01:03.820]  из начала, начальный элемент, самый первый из начала.
[01:03.820 --> 01:07.420]  И последний pop это удалить начальный элемент.
[01:07.420 --> 01:21.180]  То есть, это буквально реализация очереди.
[01:21.180 --> 01:23.820]  Представьте себе, у вас есть очередь к кассе, вот
[01:24.380 --> 01:27.480]  здесь стоит кассир, сюда приходят люди, они добавляются
[01:27.480 --> 01:29.860]  в конец, то есть, когда происходит push они добавляются
[01:29.860 --> 01:33.320]  в конец очереди, а обслуживаются, она начинает с начала.
[01:33.320 --> 01:36.000]  То есть, есть начало, начало очереди.
[01:36.000 --> 01:40.220]  И клиенты обслуживаются, начиная вот отсюда.
[01:40.220 --> 01:41.660]  Первой, второй, третий и так далее.
[01:41.660 --> 01:43.460]  Добавляются в конец, удаляются из начала.
[01:43.460 --> 01:48.060]  В отличие от 스�ека, где удаление и добавление происходили
[01:48.060 --> 01:49.860]  в одной и той же стороне.
[01:49.860 --> 01:53.800]  В стэке и удаление, и добавление были вот здесь, здесь удаления
[01:53.800 --> 02:01.500]  в одной стороне, продон, добавление в одной стороне, удаление в другой. Вот. Ну, как бы, не
[02:01.500 --> 02:08.620]  шибко сложнее, чем stack. Опять-таки, можно очень легко реализовать на списке. Можно реализовать на
[02:08.620 --> 02:19.460]  списке. Ну, просто вот все вот эти вот объектики представляем отдельными коробочками, да,
[02:19.460 --> 02:24.060]  отдельными нодами, которые друг на друга ссылаются в порядке слева направо. Добавляем в конец,
[02:24.060 --> 02:29.620]  удаляем из начала. Все так же, как в обычном списке происходит. Вот. Ну и, соответственно,
[02:29.620 --> 02:38.020]  все такие операции будут работать за единицу, а за вот единицу. Вот. Давайте посмотрим на то,
[02:38.020 --> 02:44.060]  как можно было бы очередь по-другому реализовать. А именно, очередь на двух stack.
[02:44.060 --> 03:00.860]  Вот. Это нам будет нужно для того, чтобы уметь поддерживать минимум в очереди. Потому что мы
[03:00.860 --> 03:05.780]  знаем, как в stack поддерживать минимум. В прошлый раз у нас это было, что если мы просто каждый раз
[03:05.780 --> 03:10.340]  будем добавлять не только элемент, но и минимум во всем, что под ним, среди всего, что под ним,
[03:10.340 --> 03:14.860]  то у меня в stack можно будет поддерживать минимум из всего, что там есть. Тогда, соответственно,
[03:14.860 --> 03:19.700]  если я научусь реализовывать очередь через stack, ну или через два stack, тогда я сразу научусь
[03:19.700 --> 03:23.340]  поддерживать минимум в очереди. Потому что вообще говоря, минимум в очереди на такой
[03:23.340 --> 03:27.780]  тривиальной реализации на списке не очень понятно, как делать. Потому что когда у вас добавляются
[03:27.780 --> 03:35.060]  элементы здесь, а удаляются отсюда, у вас есть некое окошко, в которое сейчас активные элементы,
[03:35.060 --> 03:39.660]  то есть оно двигается влево при удалении и вправо при добавлении. И непонятно,
[03:39.660 --> 03:42.700]  как в нем поддерживать минимум, потому что удаляются отсюда, а добавляются вот здесь.
[03:42.700 --> 03:49.260]  Минимум здесь, ну как минимум, не очень ясно, как делать. Я не умею за единицу это делать на списке,
[03:49.260 --> 03:56.380]  скажем так. Вот, а со stack все просто. Значит, смотрите, какая идея. Давайте мы заведем два stack,
[03:56.380 --> 04:05.620]  ну я их назову просто первый-второй. В первый stack мы будем добавлять элементы,
[04:05.620 --> 04:15.540]  ну то есть делать операцию push. Если приходит push x, то мы его просто добавляем в первый stack,
[04:15.540 --> 04:28.180]  а из второго будем удалять. И тогда смотрите, как будет выглядеть история работы с такой очередью,
[04:28.180 --> 04:32.580]  реализована на двух stack. Вот представьте, сначала у нас приходит несколько push, несколько элементов
[04:32.580 --> 04:37.020]  мы добавляем сначала в очередь. Ну приходят люди в очередь, мы их добавляем в первый stack. Причем
[04:37.020 --> 04:41.620]  они в stack добавляются, но они в этом stack будут в перевернутом порядке. Если первый элемент
[04:41.620 --> 04:46.540]  пришел, самым первым будет лежать на дне stack, над ним второй, третий, четвертый и так далее. То есть
[04:46.540 --> 04:50.060]  если я их буду доставать, они будут доставаться в неправильном порядке, в противоположном, потому
[04:50.060 --> 04:55.460]  что надо было бы их доставать порядка 1, 2, 3, 4. Ну окей, пока как есть, пока мы их не достаём,
[04:55.460 --> 05:02.180]  пока мы их просто сложили. Дальше, в момент, когда впервые меня просят удалить начальный элемент или
[05:02.180 --> 05:07.100]  просто узнать его значение, то есть front или pop запрос приходит, я буду смотреть на второй stack и
[05:07.100 --> 05:14.300]  буду работать с его верхним элементом. Если этот stack пустой, как в самом начале, я сделаю следующее,
[05:14.300 --> 05:19.500]  я все элементы из первого stack переложу во второй. Ну вот просто пока первый stack не пустит, я все
[05:19.500 --> 05:24.060]  элементы перекладываю из него во второй. Я отсюда достаю четверку, кладу его на дно второго stack,
[05:24.060 --> 05:30.180]  достал тройку, переложил сюда, двойку, единицу. И теперь смотрите, здесь порядок элементов такой,
[05:30.180 --> 05:35.900]  как мне нужно. На как раз 1, 2, 3, 4. Удалять я буду первый прошедший элемент, потом за ним второй,
[05:35.900 --> 05:41.620]  третий и так далее. То есть когда я добавлял в stack, у меня порядок элементов заменился на
[05:41.620 --> 05:45.420]  противоположный. Теперь я еще раз добавляю в stack, и он еще раз меняется на противоположный,
[05:45.420 --> 05:49.820]  то есть становится правильным. Я как бы два раза перевернул список, он стал таким, как надо. Теперь
[05:49.820 --> 05:54.020]  в начале вот этого stack будет правильный элемент, тот, который самым первым пришел. Ну и тогда,
[05:54.020 --> 05:58.820]  по крайней мере, первые четыре операции удаления я точно смогу правильно обработать. Удаляю pop,
[05:58.820 --> 06:05.380]  pop, pop, pop. У меня удалится все в правильном порядке. Вот, параллельно этим pop приходят push
[06:05.380 --> 06:11.900]  какие-то. Пришел push 5, 6, 7, 8 и так далее. Я все push делаю в первый список, в первый stack.
[06:11.900 --> 06:17.860]  Потом, когда этот stack опустошился, то есть у меня произошло четыре запроса pop, все эти
[06:17.860 --> 06:23.900]  элементы удалились, и опять приходит запрос front или pop. Давайте я опять все вот эти элементы,
[06:23.900 --> 06:28.260]  которые успели накопиться в первом stack, я их переложу во второй, они опять поменяют
[06:28.260 --> 06:33.580]  свой порядок с неправильного на правильный, потому что развернется список. Будет на донышке 9,
[06:33.580 --> 06:38.660]  потом 8, потом 7, потом 6, потом 5. И первый stack опустошится. И здесь опять такие в правильном
[06:38.660 --> 06:49.020]  порядке все элементы лежат. Ну а понятная идея. Да, вот давайте я это быстренько напишу,
[06:49.020 --> 06:55.500]  что если приходит push x, то я просто добавляю x в первый stack, добавляем x в первый stack,
[06:55.500 --> 07:10.740]  а когда приходит pop или front, я делаю запрос ко второму stack. Но если внезапно второй stack
[07:10.740 --> 07:18.220]  пустой, то я перекладываю все с первого во второй. Но если второй stack пуст,
[07:18.220 --> 07:35.220]  то сначала перекладываем все элементы с первого во второй. Все элементы из 1 в 2. Все,
[07:35.220 --> 07:43.420]  вот такая нехитрая реализация. Понятно? Вот, супер. Ну и теперь понятно, что если мы на stack
[07:43.420 --> 07:48.180]  умеем поддерживать минимумы, то мы умеем и в очереди тоже поддерживать минимум. Потому что
[07:48.180 --> 07:52.780]  если у меня вот здесь вот, там следующие числа приходят, я знаю на них минимум,
[07:52.780 --> 07:59.340]  я знаю на них минимум, тогда минимум во всей очереди, глобальный минимум, это минимум из
[07:59.340 --> 08:03.220]  минимума здесь и здесь. То есть если я знаю минимум здесь, минимум здесь, то мне нужно взять
[08:03.220 --> 08:08.420]  из них самое маленькое вывести в качестве ответа. Поэтому в дополнение к этим операциям я еще
[08:08.420 --> 08:20.060]  научился отвечать на запросы минимума во всей очереди. Минимум во всей очереди. Так, хорошо.
[08:20.060 --> 08:31.140]  На stack мы в прошлый раз научились поддерживать минимум на stack. Если я знаю минимум здесь и здесь,
[08:31.140 --> 08:41.540]  то минимум во всей очереди, это минимум из этих двух минимумов. Хорошо. Строится у меня только
[08:41.540 --> 08:47.780]  перекладываниями из первого. Если второй stack пустой, я останавливаю все выполнение и по одному
[08:47.780 --> 08:51.620]  перекладываю элементы из первого во второй. Достаю, достаю, достаю, пока первый не пустошится.
[08:51.620 --> 09:01.700]  Да, ровно так мы и делаем. Если второй stack не пустой, то я в него ничего не перекладываю,
[09:01.700 --> 09:06.540]  я из него только удаляю. Я в него что-то перекладываю только в момент, когда второй пустой и к нему
[09:06.540 --> 09:12.900]  поступает запрос удаления или посмотреть первый элемент. Если второй stack пустой, то я перекладываю,
[09:12.900 --> 09:20.180]  иначе ничего не делаю. Надо сделать еще замечание насчет времени работы, потому что если раньше на
[09:20.180 --> 09:27.660]  списках у меня все операции работали за чистую единицу, добавить ноду, удалить ноду, посмотреть
[09:27.660 --> 09:32.660]  на первый элемент, это все работало за единицу. Теперь, как видим, у меня вот эта штука перекладывания
[09:32.660 --> 09:38.540]  элементов из одного stack в другой, она работает не за единицу, она работает за столько, сколько было
[09:38.540 --> 09:45.020]  элементов в первом stack. Поэтому, в принципе, каждая конкретная операция может работать довольно
[09:45.020 --> 09:52.340]  долго, потому что мне нужно весь первый stack вычерпать, исчерпать и положить во второй. Но понятно,
[09:52.340 --> 09:57.660]  что суммарно это будет тоже быстро, это будет линейное время, если мне поступает n запросов,
[09:57.660 --> 10:03.660]  то суммарно работает за o от n. Потому что каждый элемент, давайте проследим историю каждого
[10:03.660 --> 10:09.660]  элемента x. Он сначала один раз попал сюда, потом он переместился один раз сюда, и потом он один
[10:09.660 --> 10:16.580]  раз удалился. То есть время, затрачиваемое на каждый конкретный элемент x, это константа. Это push
[10:16.580 --> 10:21.420]  в первый stack, pop из первого stack, push во второй, pop из второго stack. То есть это 4 действия на
[10:21.420 --> 10:29.220]  элемент. Значит, хотя каждая конкретная операция, вот эти вот операции, они работают, каждая конкретная
[10:29.220 --> 10:36.460]  может работать долго, но суммарно все эти n операции, если к очереди такой поступит n операции, то
[10:36.460 --> 10:41.020]  суммарно они работают за o от n. Потому что каждый элемент поучаствовал максимум в четырех перекладываниях.
[10:41.020 --> 10:48.780]  Согласны? Это то, что у нас будет, я чуть позже буду вводить, амортизированное время работы, это когда
[10:48.780 --> 10:54.500]  каждая конкретная операция может работать долго, но суммарно, то есть я могу долго перекладывать,
[10:54.500 --> 10:59.580]  но суммарно, если я много переложил, тогда здесь, в течение многих следующих операций, я сюда ничего
[10:59.580 --> 11:03.740]  перекладывать не буду, потому что здесь большой stack, я могу отсюда спокойно удалять. И вот эта
[11:03.740 --> 11:08.980]  вот логика, что мы за счет какой-то дорогой операции, то есть если я долго перекладываю с первого
[11:08.980 --> 11:15.060]  во второй, я потом в течение многих операций не буду нуждаться опять с перекладыванием. То есть если
[11:15.060 --> 11:19.460]  я сделаю одну долгую операцию, то много следующих будет дешевыми, я смогу отсюда удалять по одному
[11:19.460 --> 11:25.060]  без проблем. Такая вот идея баланса, что если была дорогая операция, то потом много следующих простые,
[11:25.060 --> 11:29.460]  это то, что у нас чуть позже будет, как амортизированное время работ. Давайте я пока это оставлю,
[11:29.460 --> 11:40.300]  просто как заклинание. Добавили, ну что такое переложили? Это надо, значит, сделать pop и потом push.
[11:40.300 --> 11:52.780]  Ну это не важно, как бы константа, амортизированное время работы каждого запроса.
[11:59.780 --> 12:05.340]  Четыре действия с объектом. Мы сначала положили сюда, потом достали отсюда, потом положили,
[12:05.340 --> 12:14.260]  потом достали. Вот, значит, амортизированное время работы за единицу, то есть если к очереди,
[12:14.260 --> 12:32.860]  давайте так напишу, то есть n операций обрабатываются за вот n. Каждая конкретная может быть дорогой,
[12:32.860 --> 12:38.140]  но суммарно не больше, чем n на константу, n на 4 в нашем случае, потому что каждый объект
[12:38.140 --> 12:45.020]  участвует в четырех действиях. Окей? Давайте я вот здесь еще поставлю звездочку. Я буду амортизированно
[12:45.020 --> 12:58.820]  всегда звездочку обозначать. Так, вопросы есть? После pop slash front. Запрос ко второму стэку.
[12:58.820 --> 13:09.860]  Так, хорошо. Тогда переходим к еще одной структуре данных, которая называется куча.
[13:09.860 --> 13:18.820]  Опять давайте подойдем с функциональной точки зрения. Чего мы хотим от кучи? Мы пока ничего не
[13:18.820 --> 13:27.380]  хотим, но в принципе, чего люди могут хотеть? Это следующий набор операций. Мы будем хранить,
[13:27.380 --> 13:37.020]  давайте напишу, что в скобочках хранится мультимножество s. То есть множество, возможно
[13:37.020 --> 13:42.260]  с повторениями. Там конкретный элемент x может несколько раз туда входить. Чтобы не запариваться
[13:42.260 --> 13:49.700]  про кратность, я скажу, что это мультимножество. Запрос первый. Insert x. Это просто добавить x в
[13:49.700 --> 14:02.860]  наше множество s. Запрос второй. Узнать минимум. Get min. Вывести значение минимального элемента,
[14:02.860 --> 14:17.060]  который есть в s. Давайте так напишу. Узнать минимальное значение y по всем y из s. Формальная
[14:17.060 --> 14:25.660]  запись. Надо найти самое минимальное по значению элемент в множестве s. Третье. Этот элемент удалить.
[14:25.660 --> 14:34.780]  Extract min. Extract от слова извлечь. Извлечение минимума. Давайте так напишу. Удалить минимум из кучи.
[14:34.780 --> 14:54.900]  Удалить минимум из s. Четвертый. Декрески. Запрос. Уменьшить какой-то элемент. То есть в множестве
[14:54.900 --> 15:03.820]  s было какое-то число, был какой-то элемент. Я хочу научиться уменьшать. Какой синтаксис у
[15:03.820 --> 15:12.700]  этой процедуры, у этого запроса? Он принимает, давайте напишу, ptr и дельту, которые значат следующее.
[15:12.700 --> 15:22.380]  ptr это указатель на тот элемент, который хочется уменьшить. То есть смотрите, в s как-то лежат
[15:22.380 --> 15:27.300]  элементы. Вот я хочу, чтобы мне сообщали указатель на то место в памяти, где лежит конкретный
[15:27.300 --> 15:32.460]  элемент, который пользователь хочет удалить. У нас такого же было, когда мы удаляли из списка.
[15:32.460 --> 15:37.220]  Нам надо, чтобы нам показывали на конкретный элемент, на конкретную ноду, на конкретную
[15:37.220 --> 15:42.580]  вершину. То же самое здесь показывают на конкретный элемент в s. Не просто говорят число x уменьшить,
[15:42.580 --> 15:50.460]  а говорят, где оно лежит в s. Это указатель, ссылка, адрес уменьшаемого элемента. Дельта это
[15:50.460 --> 15:56.100]  какое-то неотрезательное число, на которое надо элемент уменьшить. Напишу, давайте здесь.
[15:56.100 --> 16:10.460]  Уменьшить элемент, лежащий по адресу ptr, на дельту.
[16:10.460 --> 16:28.020]  То есть был какой-то элемент, я его хочу сделать чуть поменьше, на дельту. Пока такая магия. Смотри,
[16:28.020 --> 16:35.340]  зачем это может быть, например, нужно. Ну это нужно, например, при обработке более-менее
[16:35.340 --> 16:42.660]  чего угодно. При обработке каких-то заказов, задач, чего-то. Вот представьте, в s у вас лежат какие-то
[16:42.660 --> 16:48.980]  объекты, которые вам надо делать. Детальки какие-нибудь на заводе вы сидите, вам надо делать детальки. И вы
[16:48.980 --> 16:52.940]  каждый раз, вы один человек, вы в любом момент времени можете делать только одну детальку, и вам
[16:52.940 --> 16:58.020]  надо каждый раз действовать как-то оптимально. Выполнять деталь, которая, например, приносит
[16:58.020 --> 17:04.380]  максимальную стоимость или там, у которой наиболее близкий дедлайн. В этом смысле вам нужно уметь
[17:04.380 --> 17:10.980]  добавлять элементы в ваше множество, то есть добавлять задания, детали в ваше множество. Узнавать
[17:10.980 --> 17:16.860]  и извлекать самый ближайший, тот, который самый выгодный, в каком-то смысле оптимальный из кучи,
[17:16.860 --> 17:23.660]  например, самую дорогую деталь или ту, которой дедлайн ближе всего. И до крески, ну пока выглядит
[17:23.660 --> 17:27.500]  несколько абстрактно, ну, например, там у какой-то детали изменилась какая-нибудь характеристика,
[17:27.500 --> 17:33.940]  ее надо сделать раньше. Дедлайн перенесли пораньше, надо ее сделать пораньше. Ну что-то такое. Как бы
[17:33.940 --> 17:42.620]  странно это ни было. Вот. Ну, это такая более-менее притяжка за уши к реальной жизни. На самом деле это
[17:42.620 --> 17:45.940]  нужно будет нам в куче других алгоритмов. Во втором семестре у нас будут всякие алгоритмы
[17:45.940 --> 17:57.060]  на графах. Давайте напишу, что в частности это нужно в алгоритмах прима и дэкстры. Вот. Это будет
[17:57.060 --> 18:03.660]  там через полгода. Ну и в этом сместоре чуть позже нам это тоже будет нужно, когда будем
[18:03.660 --> 18:11.860]  рассматривать деревья поиска, там кучи тоже будут очень нужны в какой-то момент. Так, есть вопросы
[18:11.860 --> 18:20.020]  к тому, что надо от кучи? Хорошо, а давай тогда ее реализуем. Давайте напишем конкретную бинарную
[18:20.020 --> 18:38.620]  кучу. Бинарная, она же двоичная куча. Это следующее. Я буду моемножство s хранить на самом деле просто
[18:38.620 --> 18:47.820]  в массиве. И сегодня, извините, у меня будет опять один индексация от 1 до n. Элементы s я буду хранить
[18:47.820 --> 18:59.020]  в массиве от 1 до n. И в голове у себя буду представлять, что эти элементы на самом деле сложны каким-то
[18:59.020 --> 19:07.180]  образом в дерево. А именно следующим образом. А1 лежит в корне дерева, дальше у него есть два ребенка.
[19:07.180 --> 19:10.060]  Так, давайте я картинку здесь нарисую побольше.
[19:22.060 --> 19:35.060]  А1 в корне, дальше у А1 есть два сына, А2 и А3. Дальше у А2 опять есть два сына, А4 и А5. У А3 будут
[19:35.060 --> 19:46.060]  сыновья А6 и А7. Ну и так далее. Например, давайте нарисую картинку. Если n равно 10, у меня будет вот
[19:46.060 --> 20:00.140]  такое дерево. То есть я буду строить это дерево сверху вниз, слева направо. Это получается такое
[20:00.220 --> 20:06.820]  бинарное дерево в том смысле, что у каждой вершины есть два сына, левый и правый. Ну и вот оно так сверху вниз
[20:06.820 --> 20:15.860]  жадно построено. Мы идем слева направо по вершинам одного уровня, строим у них сыновей. Дальше переходим
[20:15.860 --> 20:21.180]  к следующему уровню, продолжаем строить сыновей, пока весь массив не исчерпается. Важно, что это
[20:21.180 --> 20:26.980]  дерево я явным образом не строю. Я не завожу отдельных каких-то классов, которые бы хранили это
[20:26.980 --> 20:32.580]  дерево. Я не провожу эти ребра. Я просто говорю, что вот тот массив соответствует этому дереву. И
[20:32.580 --> 20:37.580]  эта картинка у меня будет всегда на самом деле в голове только. Она будет виртуальная. Я это дерево
[20:37.580 --> 20:41.940]  нигде не храню. Потому что я показал, как они однозначно друг другу соответствуют. Что по такому
[20:41.940 --> 20:46.420]  массиву можно построить такое дерево. Ну и понятно, если есть такое дерево, то надо просто выписать число
[20:46.420 --> 20:48.420]  лежащие вот в этих вершинах, получится массив.
[20:48.420 --> 20:58.420]  Скажите, пожалуйста, почему такое построение дерева корректно? Почему, допустим, два разных элемента случайно не положим в какой-то один?
[20:58.420 --> 21:08.420]  Не очень понял вопрос. Смотрите, как устроено дерево. Оно устроено так, что если есть какая-то вершина, в которой написано число с индексом v,
[21:08.420 --> 21:14.420]  то у него есть два сына. Левый сын это a с индексом 2v, правый сын это a с индексом 2v плюс 1.
[21:14.420 --> 21:40.420]  Смотрите, давайте скажу так. Давайте построим полное бесконечно-бинарное дерево. Вот такое бесконечное. У каждой вершины два сына до бесконечности.
[21:40.420 --> 21:50.420]  Тогда что такое куча на одном элементе? Это вот этот элемент. Что такое куча на двух? Это вот это. На трех вот это, на четырех вот это, ну и так далее.
[21:50.420 --> 21:59.420]  То есть у вас для любого n вам нужно взять целиком несколько первых слоев на несколько первых уровней, а потом несколько вершин на следующем уровне.
[21:59.420 --> 22:08.420]  Вот, окей. Так всегда для любого n, собственно, это дерево будет устроено. Если я просто вот таким образом провожу ребра, то у меня ровно так дерево и всегда и будет выглядеть.
[22:08.420 --> 22:24.420]  Так, хорошо. Значит, это виртуальное представление такого дерева, нашего массива точнее. И давайте я скажу следующее, что на этом дереве должно выполняться требование кучи.
[22:24.420 --> 22:38.420]  Требование кучи. Это следующее простое требование. Что элементы, лежащие ниже конкретного, его больше либравны.
[22:38.420 --> 22:46.420]  Значит, а1 должно быть меньше либравно, чем все вот в этом вот по дереву, то есть чем все остальные элементы, а2 должно быть меньше либравно, чем все вот это вот по дереву.
[22:46.420 --> 22:54.420]  То есть все, что лежит, все, что ниже его, все, что достижено из него вниз по ребрам, все должно быть его больше либравно. То есть а2 самое маленькое вот в этом по дереве.
[22:54.420 --> 23:03.420]  Дальше, вот здесь а3 меньше чем а6, ну, меньше либравно, чем а6 меньше, меньше, чем а7, а4 меньше либравно, чем это и это, ну и так далее.
[23:03.420 --> 23:21.420]  Значит, давайте спишу так, что для любой вершины v, av меньше либравно, чем au, для любой u в под дереве v.
[23:21.420 --> 23:30.420]  Ну, что такое в под дереве, значит, что если я вот, вот есть у меня какая-то вершина v, где написано число av, все, что достижимо вниз по каким-то путям, вниз, влево, вправо, могу ходить.
[23:30.420 --> 23:38.420]  Вот если я могу вниз дойти до вершины au, сверху вниз от v до u, тогда обязательно должно выполняться вот такое вот неравенство, av не больше чем au.
[23:38.420 --> 23:48.420]  То есть всегда, когда я прохожу вниз в моем этом дереве, у меня значение может только возрастать. Ну, не строго.
[23:48.420 --> 24:08.420]  Вот. Значит, это будет требование кучи. Ну и давайте сразу напишу, что я буду называть массив корректной кучей, вот тот вот массив корректной кучей, если в этом дереве выполняется требование кучи.
[24:08.420 --> 24:23.420]  Значит, a1 и так далее, an назовем корректным, назовем корректной кучей, если в соответствующем дереве выполнено требование кучи.
[24:23.420 --> 24:47.420]  Так, ну вроде все, определение ввел. Теперь скажите, пожалуйста, можем ли мы хотя бы на какой-то из этих запросов быстро отвечать?
[24:47.420 --> 25:05.420]  Да. Мы теперь очень быстро умеем отвечать на getmin, потому что это всегда a1. Потому что, коль скоро массив удовлетворяет требованию кучи, ну точнее, является корректной кучей, то в корне всегда число меньше либо равно, чем все остальные, то есть минимум.
[25:05.420 --> 25:31.420]  Ну хорошо, уже хоть что-то. Еще раз? Да, там еще придется позаморачиваться с этим. Да, в итоге будет лог везде, но тут везде надо будет повозиться. Пока давайте с getmin, остановимся.
[25:31.420 --> 25:45.420]  Значит, для остальных запросов мне будут нужны две вспомогательные процедуры, которые будут чинить кучу, если она внезапно поломалась. Давайте введем две вспомогательные процедуры.
[25:45.420 --> 25:54.420]  Ну хорошо, давайте вообще поймем, зачем они нужны. Ну вот вы говорите про extract min. Вот давайте сделаем вот здесь. Вот у меня была корректная куча, допустим. Здесь был минимум.
[25:54.420 --> 26:03.420]  Как этот элемент можно из кучи удалить? Ну хотелось бы типа его удалить, поставить на его место какое-то другое число и кучу перестроить.
[26:03.420 --> 26:16.420]  Ну типа, например, на a10 я могу вот отсюда удалить, переместить его сюда. Но тогда у меня a10, число, которое по идее должно быть довольно большим, раз оно вот здесь вот низко лежит, когда я его переставляю в корень, у меня наверняка какие-то неравенства нарушатся.
[26:16.420 --> 26:24.420]  У меня в корень поместилось большое число. Мне нужно как-то кучу перестроить. Мне нужно опять как-то его, наверное, опустить, что-то поменять. Короче, непонятно.
[26:24.420 --> 26:31.420]  Вот ровно для этого я ввожу две вспомогательные процедуры, которые будут чинить мою кучу, если я с ней что-то непристойное сделаю.
[26:31.420 --> 26:49.420]  Первая очень простая, называется сифтап. Сифтап, сифт, от слова просеивать. Смысл такой, вот есть какая-то v, вершина, где мы что-то испортили, мы поменяли значение этого av, и причем мы его уменьшили.
[26:49.420 --> 26:59.420]  Тогда понятно, что этот элемент будет стремиться всплывать вверх в этом дереве. Если я значение элемента уменьшил, понятно, что меньше элементы у меня лежат ближе к корню.
[26:59.420 --> 27:08.420]  Корень минимальный, здесь там какие-то вторые по минимальности, грубо говоря. То есть минимальные они будут стремиться всплывать вверх. Вот давайте я буду просеивать элемент наверх.
[27:08.420 --> 27:18.420]  Значит работает следующим образом. Ну, во-первых, если внезапно v равно единице, то делать нечего.
[27:18.420 --> 27:29.420]  Нам всплывать некуда, мы и так уже в корне, выше некуда. Дальше. Дальше давайте посмотрим на v и родителя v.
[27:29.420 --> 27:36.420]  Давайте сначала поймем, какой у него номер вообще. Вот если v это не корень, то какой номер у его родителя?
[27:36.420 --> 27:44.420]  v пополам, да, нацело, все верно. Значит a с индексом v пополам, где это округление вниз.
[27:44.420 --> 27:55.420]  Ну понятно, что если у вершины v дети это 2v и 2v плюс 1, то как раз обратный переход от детей к родителю, это деление пополам, нацело с отбрасыванием остатка, чтобы 2v плюс 1 тоже перешло в v.
[27:55.420 --> 28:03.420]  Поэтому давайте сделаю следующее. Давайте я заведу номер родителя, то есть v пополам, и сделаю следующую простую штуку.
[28:03.420 --> 28:12.420]  Если в av значение меньше, чем в родителя, то их надо будет поменять. А это неправильно, как раз плохой случай.
[28:12.420 --> 28:17.420]  Вот представьте себе. Представьте, что вот здесь значение меньше, чем в родителя. Так не должно быть.
[28:17.420 --> 28:21.420]  У нас, наоборот, сверху должны быть маленькие элементы. По требованию кучи, чем выше, тем меньше.
[28:21.420 --> 28:27.420]  А тут, наоборот, вот сломалось неравенство. Давайте его починим простым свопом. Просто поменяем местами эти два числа.
[28:27.420 --> 28:39.420]  Значит если av меньше, чем ap, так, ну я в строчку напишу, извините, не хватает места.
[28:39.420 --> 28:49.420]  Значит я просто свопну эти два значения. Своп av, ap и запущу севта под p.
[28:49.420 --> 29:03.420]  Севта под p. Конец.
[29:03.420 --> 29:11.420]  То есть процедура по смыслу очень простая. Она берет элемент и поднимает его наверх, пока текущий элемент меньше родителя.
[29:11.420 --> 29:18.420]  То есть пока он меньше родителя, его есть смысл поднимать выше, ближе к корню.
[29:18.420 --> 29:26.420]  То есть мы посмотрели на v и родителя. Если у них было плохо неравенство, то давайте я их свопну и запущусь рекурсивно от родителя p.
[29:26.420 --> 29:34.420]  Если опять у ap и его родителя, то есть у ap пополам была проблема, то я их опять свопаю и опять продолжаю подниматься рекурсивно отсюда.
[29:34.420 --> 29:46.420]  Если это неравенство было не нарушено, то здесь было правильное неравенство, p было меньше, чем av, тогда у меня рекурсивный вызов заканчивается и выше не идет.
[29:46.420 --> 29:51.420]  Так, хорошо. Ну теперь sieve down.
[29:51.420 --> 30:09.420]  Вы забегаете вперед. Я еще пока не описывал, как мы будем удалять. Давайте пока вот вспомогать и потом их будем применять к тому, чтобы отвечать на запросы, которые были.
[30:09.420 --> 30:15.420]  Так, sieve down. Это, соответственно, движение в обратную сторону. Это когда нужно вершину просеять вниз.
[30:15.420 --> 30:23.420]  Когда у нее значение большое, больше, чем надо, ее нужно, наоборот, ниже к листьям протолкнуть, просеять вниз.
[30:23.420 --> 30:33.420]  Так, ну опять давайте напишем условия выхода, что если, внезапно, у v вообще нет детей, когда у v нет детей, скажите, пожалуйста.
[30:33.420 --> 30:43.420]  Ну давайте без логарифмов. n меньше, чем 2v, да. Ну давайте напишу 2v больше, чем n.
[30:43.420 --> 30:58.420]  Потому что у v два ребенка, 2v и 2v плюс 1, их нет, когда оба числа больше, чем n, то есть когда меньше из них больше, чем n. Нет детей.
[30:58.420 --> 31:04.420]  Ну опять, по смыслу, дальше вниз некуда, и так на дне уже, ниже некуда.
[31:04.420 --> 31:12.420]  Вот. Хорошо, картинка. Было вот у меня av. Дальше у меня есть либо два сына, либо один сын.
[31:12.420 --> 31:20.420]  Потому что вот при n равно 10 у меня у каких-то совершенно один сын всего. То есть может быть у меня два сына, может быть один только левый.
[31:20.420 --> 31:28.420]  Значит 2v, это 2v плюс 1. Давайте я сначала посчитаю, какой из них минимальный.
[31:28.420 --> 31:32.420]  То есть если у меня два сына, давайте я пойму, в каком из них лежит меньшее число.
[31:32.420 --> 31:36.420]  А дальше, ну представьте, не знаю, давайте картинка. Пусть здесь 5, а здесь 3 лежит.
[31:36.420 --> 31:43.420]  Тогда понятно, что мне нужно свопнуть вот эти два числа местами, ну по крайней мере интуитивно хочется вот эту тройку поднять и пятерку опустить.
[31:43.420 --> 31:50.420]  Ну ровно так я и сделаю. Я найду, какой из этих двух сыновей меньше и перемещу вот эту пятерку в того сына, который меньше.
[31:50.420 --> 31:54.420]  Ровно так мне сейчас и сделаю. Я это делаю следующим образом.
[31:54.420 --> 31:59.420]  Я сначала говорю, что u это 2v. То есть я по умолчанию считаю левого сына меньшим.
[31:59.420 --> 32:04.420]  А дальше, если правый сын существует и еще меньше, тогда u равно правому сыну.
[32:05.420 --> 32:09.420]  Значит как проверить, что правый сын существует?
[32:09.420 --> 32:13.420]  Видимо вот так, что его номер не больше, чем размер кучи.
[32:13.420 --> 32:23.420]  И число там лежащее меньше, чем число лежащее в 2v.
[32:23.420 --> 32:30.420]  В таком случае я сделаю u равно 2v плюс 1.
[32:30.420 --> 32:33.420]  Ну то есть теперь в u лежит наименьшее из двух сыновей.
[32:33.420 --> 32:36.420]  Причем я это сделал безопасно. То есть я по умолчанию считаю, что левый сын минимальный.
[32:36.420 --> 32:41.420]  А дальше, если правый существует и там еще меньшее число, то я говорю, что u это правый сын.
[32:41.420 --> 32:44.420]  Вот, значит в u всегда минимальный сын.
[32:44.420 --> 32:55.420]  Ну и теперь я делаю следующее, что если в au число меньше, чем в av, то есть как раз нарушается требование кучи ниже,
[32:55.420 --> 32:58.420]  то значит число меньшее, чем в v.
[32:58.420 --> 33:04.420]  Тогда мне их нужно свопнуть, поменять местами эти два числа, ауто и авото.
[33:07.420 --> 33:11.420]  Ну и видимо рекурсивно запустится вот в этот раз.
[33:11.420 --> 33:13.420]  Всегда нату.
[33:15.420 --> 33:17.420]  Конец.
[33:26.420 --> 33:31.420]  Так, вопросы есть по реализации?
[33:31.420 --> 33:35.420]  Пока вот просто две такие процедуры, которые интуитивно делают вот ровно это.
[33:35.420 --> 33:39.420]  Маленькие числа с помощью севтапа я поднимаю вверх, ближе к корню.
[33:39.420 --> 33:43.420]  Большие с помощью севдауна просеиваю вниз, ближе к листьям.
[33:45.420 --> 33:47.420]  Так, хорошо.
[33:47.420 --> 33:53.420]  Теперь давайте попробуем, давайте сначала попробуем реализовать наши вот эти операции.
[33:53.420 --> 33:57.420]  Предполагаю интуитивно, что вот севтап и севдаун в каком-то смысле правильно чинят кучу.
[33:57.420 --> 33:59.420]  Потом мы все правильно, потом мы все докажем.
[33:59.420 --> 34:02.420]  Давайте сначала интуицию слоем здесь.
[34:02.420 --> 34:04.420]  Значит, давайте пропишу все еще раз.
[34:04.420 --> 34:07.420]  Гетмин мы умеем отвечать.
[34:07.420 --> 34:11.420]  Знаете, гетмин это всегда просто ретёрн, а первая.
[34:12.420 --> 34:16.420]  Давайте с экстрактом попробуем придумать, что делать.
[34:16.420 --> 34:18.420]  Здесь был корень, минимальное значение.
[34:18.420 --> 34:20.420]  Надо его как-то удалить из кучи.
[34:22.420 --> 34:24.420]  Но давайте я начну так.
[34:24.420 --> 34:26.420]  Давайте мы найдем, где лежит АН.
[34:26.420 --> 34:32.420]  Ну, то есть, да, вот самый низкий лист, последний элемент просто кучи.
[34:32.420 --> 34:38.420]  Давайте мы поменяем местами А1 и АН.
[34:38.420 --> 34:40.420]  Тем самым, что мы сделали?
[34:40.420 --> 34:44.420]  Мы то число, которое раньше было минимальным, поместили куда-то в хвост.
[34:44.420 --> 34:46.420]  Ну, вот сюда.
[34:46.420 --> 34:49.420]  А в корень подняли какое-то большое число.
[34:49.420 --> 34:52.420]  Что теперь нужно сделать, чтобы починить кучу?
[34:52.420 --> 34:55.420]  Просеять вниз корень.
[34:55.420 --> 34:57.420]  Севдаун единицы.
[34:57.420 --> 34:59.420]  Ну, все очень интересно.
[34:59.420 --> 35:01.420]  Ну, вот так вот.
[35:01.420 --> 35:03.420]  Ну, вот так вот.
[35:03.420 --> 35:05.420]  Вниз корень.
[35:05.420 --> 35:07.420]  Севдаун единицы.
[35:07.420 --> 35:09.420]  Ну, все очень естественно.
[35:09.420 --> 35:11.420]  Мы подняли в корень большое число.
[35:11.420 --> 35:13.420]  Теперь давайте его просеем вниз так, чтобы все неравенства починились.
[35:13.420 --> 35:15.420]  Ну, и оно спустилось куда надо.
[35:15.420 --> 35:17.420]  Вот.
[35:17.420 --> 35:19.420]  Ну, и здесь я еще добавлю строчку.
[35:19.420 --> 35:21.420]  Минус минус N.
[35:21.420 --> 35:23.420]  Ну, или там N минус равно единица.
[35:23.420 --> 35:25.420]  Что одно и то же.
[35:25.420 --> 35:27.420]  Уменьшаю размер кучи.
[35:27.420 --> 35:29.420]  То есть, если раньше у меня в куче было N элементов,
[35:29.420 --> 35:31.420]  то теперь у меня в ней N минус один элемент.
[35:31.420 --> 35:33.420]  То есть, у меня в перемене N всегда будет храниться текущий размер кучи.
[35:33.420 --> 35:37.420]  Справедливо.
[35:37.420 --> 35:39.420]  Не буду чистить.
[35:39.420 --> 35:41.420]  Я ленивый.
[35:41.420 --> 35:43.420]  Это вам надо будет санитайзерами,
[35:43.420 --> 35:45.420]  а я буду делать, как хочу.
[35:45.420 --> 35:47.420]  Сейчас.
[35:51.420 --> 35:53.420]  Да, конечно.
[35:53.420 --> 35:55.420]  Формально, как это у меня в памяти лежит,
[35:55.420 --> 35:57.420]  я считаю, что у меня есть, на самом деле, бесконечный массив.
[35:57.420 --> 35:59.420]  Ну, понятно, на самом деле.
[35:59.420 --> 36:01.420]  Массив элементов.
[36:01.420 --> 36:03.420]  Куда я буду складывать все мои
[36:03.420 --> 36:05.420]  элементы массива?
[36:05.420 --> 36:07.420]  А 1, а 2, и так далее, а.
[36:07.420 --> 36:09.420]  Потом, если что-то внезапно удаляется,
[36:09.420 --> 36:11.420]  то я просто говорю, окей, у меня массив теперь не здесь заканчивается,
[36:11.420 --> 36:13.420]  а вот здесь вот.
[36:13.420 --> 36:15.420]  А здесь продолжает лежать то число.
[36:15.420 --> 36:17.420]  Потом, если мне приходит инсерт,
[36:17.420 --> 36:19.420]  то я буду его вот сюда вот расширять,
[36:19.420 --> 36:21.420]  и эти элементы буду перезаписываться.
[36:21.420 --> 36:23.420]  То есть, я как бы эту память не теряю,
[36:23.420 --> 36:25.420]  она все еще моя.
[36:25.420 --> 36:27.420]  Я в нее, если не надо, что-то еще буду записывать.
[36:27.420 --> 36:29.420]  Да.
[36:35.420 --> 36:37.420]  Мы сделали вот это, поэтому не может.
[36:39.420 --> 36:41.420]  Абсолютно согласен.
[36:41.420 --> 36:43.420]  Да.
[36:47.420 --> 36:49.420]  Да, спасибо, это важно.
[36:49.420 --> 36:51.420]  Да.
[36:51.420 --> 36:53.420]  То есть, я сначала уменьшил n,
[36:53.420 --> 36:55.420]  чтобы как раз сказать, все, дальше вот этой границы
[36:55.420 --> 36:57.420]  не ходи дальше, память куда не надо лезть.
[36:59.420 --> 37:01.420]  А потом уже севдаун, и он это n воспринимает
[37:01.420 --> 37:03.420]  как правильный текущий размер.
[37:03.420 --> 37:05.420]  Поэтому сначала уменьшить, потом сделать так.
[37:05.420 --> 37:07.420]  Да, спасибо.
[37:07.420 --> 37:09.420]  Хорошо, с экстрактом разобрались.
[37:09.420 --> 37:11.420]  Да.
[37:15.420 --> 37:17.420]  Еще раз.
[37:17.420 --> 37:19.420]  Да, да, да.
[37:19.420 --> 37:21.420]  У нас было вот это, мы его поместили сюда,
[37:21.420 --> 37:23.420]  а это, наоборот, сюда поменяли их местами.
[37:23.420 --> 37:25.420]  Забыли про i и n, уменьшили,
[37:25.420 --> 37:27.420]  сдвинули указатель на 1, забыли про это число.
[37:27.420 --> 37:29.420]  Дальше про семя вниз,
[37:29.420 --> 37:31.420]  потому что в корне число больше, чем надо.
[37:31.420 --> 37:33.420]  Может быть.
[37:33.420 --> 37:35.420]  Так, теперь инсерт x.
[37:35.420 --> 37:37.420]  Ну, начало очень похоже.
[37:37.420 --> 37:39.420]  Представьте, что у меня была какая-то куча.
[37:39.420 --> 37:41.420]  Давайте я сначала вот сюда,
[37:41.420 --> 37:43.420]  вот в конец, после последнего элемента, добавлю x.
[37:43.420 --> 37:45.420]  То есть, по факту, я просто дорисую
[37:45.420 --> 37:47.420]  еще один лист, положу в него значение x.
[37:47.420 --> 37:49.420]  Что тогда надо сделать?
[37:49.420 --> 37:51.420]  Сифтап отсюда.
[37:51.420 --> 37:53.420]  У меня появилась новая вершина,
[37:53.420 --> 37:55.420]  где какое-то значение лежит.
[37:55.420 --> 37:57.420]  Понятно, что вниз его просеивать
[37:57.420 --> 37:59.420]  нет смысла, потому что оно и так внизу.
[37:59.420 --> 38:01.420]  Возможно, оно достаточно маленькое,
[38:01.420 --> 38:03.420]  чтобы подняться вверх.
[38:03.420 --> 38:05.420]  Поэтому давайте мы от него запустимся сифтапу.
[38:05.420 --> 38:07.420]  Это делается следующим образом.
[38:07.420 --> 38:09.420]  Я сначала увеличу n.
[38:11.420 --> 38:13.420]  Потом положу в последний элемент
[38:13.420 --> 38:15.420]  тот самый x, который меня просят добавить.
[38:15.420 --> 38:17.420]  Ну и запущу x.
[38:17.420 --> 38:19.420]  И добавить.
[38:19.420 --> 38:21.420]  Ну и запущу сифтап от n.
[38:23.420 --> 38:25.420]  Тем самым этот элемент x, возможно,
[38:25.420 --> 38:27.420]  поднимется на какое-то количество шагов наверх,
[38:27.420 --> 38:29.420]  потому что, если он достаточно маленький,
[38:29.420 --> 38:31.420]  он будет подниматься наверх.
[38:35.420 --> 38:37.420]  Так, ну и остался дикрестки, тоже очень простой.
[38:47.420 --> 38:49.420]  Значит, дикрестки уменьшить ключ,
[38:49.420 --> 38:51.420]  уменьшить значение
[38:51.420 --> 38:53.420]  по указателю и дельте.
[38:53.420 --> 38:55.420]  Что такое указатель в нашем смысле?
[38:55.420 --> 38:57.420]  По факту это просто номер вершины,
[38:57.420 --> 38:59.420]  номер элементов в массиве.
[38:59.420 --> 39:01.420]  У меня однозначно
[39:01.420 --> 39:03.420]  по индексу в массиве
[39:03.420 --> 39:05.420]  восстанавливается вершина в дереве.
[39:05.420 --> 39:07.420]  У нас есть очень простые между ними соответствия.
[39:07.420 --> 39:09.420]  Поэтому в качестве ПТР
[39:09.420 --> 39:11.420]  я буду просто воспринимать
[39:11.420 --> 39:13.420]  номер вершины,
[39:13.420 --> 39:15.420]  индекс элементов.
[39:15.420 --> 39:17.420]  В этом смысле
[39:17.420 --> 39:19.420]  как раз опять, смотрите,
[39:19.420 --> 39:21.420]  это не значение
[39:21.420 --> 39:23.420]  числа, которое нужно изменить.
[39:23.420 --> 39:25.420]  Мне нужно поменять не 5
[39:25.420 --> 39:27.420]  на 3, например, а мне нужно поменять
[39:27.420 --> 39:29.420]  АВТ, то есть вот тот конкретный момент,
[39:29.420 --> 39:31.420]  который лежит ровно на В этой позиции.
[39:31.420 --> 39:33.420]  Не просто какую-то пятерку найти в куче и уменьшить,
[39:33.420 --> 39:35.420]  а именно тот число, который лежит на месте В.
[39:35.420 --> 39:37.420]  Потому что пятерку
[39:37.420 --> 39:39.420]  найти в массиве это сложно.
[39:39.420 --> 39:41.420]  Представьте, у вас большой массив, вас просят
[39:41.420 --> 39:43.420]  найдите в нем пятерку, поменяйте на тройку.
[39:43.420 --> 39:45.420]  Но это более сложная задача, чем я вас тыкаю
[39:45.420 --> 39:47.420]  лицом в конкретный индекс В
[39:47.420 --> 39:49.420]  и вам надо вот это конкретное АВТ
[39:49.420 --> 39:51.420]  поменять. Ну понятно, разная задача.
[39:57.420 --> 39:59.420]  Не-не, никакого бинпоиска у вас
[39:59.420 --> 40:01.420]  массив-то не отсортированный.
[40:01.420 --> 40:03.420]  Тут как раз вот в куче поиск
[40:03.420 --> 40:05.420]  вообще никак не работает.
[40:05.420 --> 40:07.420]  Поэтому кроме вот этого особо
[40:07.420 --> 40:09.420]  других способов и нет.
[40:09.420 --> 40:11.420]  Ну чего, тут все совсем просто.
[40:11.420 --> 40:13.420]  Мы уменьшаем на дельту
[40:13.420 --> 40:15.420]  и запускаем видимо сифтап,
[40:15.420 --> 40:17.420]  потому что значение уменьшилось.
[40:17.420 --> 40:19.420]  Единственное, что могло произойти, это оно могло подняться наверх.
[40:19.420 --> 40:21.420]  Сифтап от В.
[40:21.420 --> 40:23.420]  Кажется, все.
[40:25.420 --> 40:27.420]  Вот, здесь уточню, что дельта всегда
[40:27.420 --> 40:29.420]  не отрицательная. У нас не даром
[40:29.420 --> 40:31.420]  называется процедура дикризские от слова уменьшить.
[40:31.420 --> 40:33.420]  Мы уменьшаем значение элемента.
[40:33.420 --> 40:35.420]  Уменьшаем ключ.
[40:35.420 --> 40:37.420]  Потенциально, если бы дельта
[40:37.420 --> 40:39.420]  могла быть отрицательной, то есть
[40:39.420 --> 40:41.420]  меня просили бы увеличивать, наоборот, ключ,
[40:41.420 --> 40:43.420]  тогда надо было бы запускать сифтдаун.
[40:43.420 --> 40:45.420]  Потому что вот был элемент, мне нужно, наоборот,
[40:45.420 --> 40:47.420]  ближе к одну просеять.
[40:47.420 --> 40:49.420]  Надо было бы тогда вызывать сифтдаун.
[40:49.420 --> 40:51.420]  Но мне на самом деле,
[40:51.420 --> 40:53.420]  где нужно вот это все, там достаточно дикризские.
[40:55.420 --> 40:57.420]  Инкризские в каких-то кучах можно писать,
[40:57.420 --> 40:59.420]  но на практике это не нужно.
[40:59.420 --> 41:01.420]  То есть во всех реальных задачах,
[41:01.420 --> 41:03.420]  если у вас есть такой пакет операций,
[41:03.420 --> 41:05.420]  то вам хватает дикриза, а инкриз вам не нужен.
[41:05.420 --> 41:07.420]  Вот как-то так волшебно получается, что инкриз обычно не нужен.
[41:09.420 --> 41:11.420]  Так, вопросы есть?
[41:11.420 --> 41:13.420]  Потому что мы вот здесь делали?
[41:13.420 --> 41:15.420]  Хорошо.
[41:15.420 --> 41:17.420]  Так, ну тогда давайте
[41:17.420 --> 41:19.420]  доказывать.
[41:19.420 --> 41:21.420]  Давайте доказывать, что это все корректно.
[41:23.420 --> 41:25.420]  Что такая реализация запросов
[41:25.420 --> 41:27.420]  через вспомогательный сифтап и сифтдаун
[41:27.420 --> 41:29.420]  на самом деле всегда
[41:29.420 --> 41:31.420]  делает наш куч корректный.
[41:35.420 --> 41:37.420]  Ну давайте
[41:37.420 --> 41:39.420]  лемма это назовем.
[41:39.420 --> 41:41.420]  Лемма.
[41:41.420 --> 41:43.420]  Значит, пусть
[41:43.420 --> 41:45.420]  a1 и так далее, an
[41:45.420 --> 41:47.420]  был корректной кучей.
[41:47.420 --> 41:49.420]  Представьте, что у нас был
[41:49.420 --> 41:51.420]  массив, который был корректной кучей.
[41:51.420 --> 41:53.420]  То есть для него выполнялось требование,
[41:53.420 --> 41:55.420]  что все вершины ниже данной,
[41:55.420 --> 41:57.420]  ее могут быть только больше.
[41:57.420 --> 41:59.420]  Больше равны.
[41:59.420 --> 42:01.420]  Значит, пусть
[42:01.420 --> 42:03.420]  av
[42:03.420 --> 42:05.420]  изменилась
[42:05.420 --> 42:07.420]  ну давайте
[42:07.420 --> 42:09.420]  напишу так, становится x.
[42:09.420 --> 42:11.420]  Становится x.
[42:11.420 --> 42:13.420]  То есть я меняю значение одного
[42:13.420 --> 42:15.420]  элемента.
[42:15.420 --> 42:17.420]  Тогда
[42:17.420 --> 42:19.420]  пункт 1
[42:19.420 --> 42:21.420]  если x
[42:21.420 --> 42:23.420]  ну если av уменьшилось,
[42:27.420 --> 42:29.420]  то, то есть у меня было
[42:29.420 --> 42:31.420]  какое-то значение, я поменял
[42:31.420 --> 42:33.420]  его на что-то меньшее.
[42:33.420 --> 42:35.420]  Да, я утверждаю, что после сифтапа
[42:35.420 --> 42:37.420]  от v
[42:37.420 --> 42:39.420]  после сифтапа от v
[42:39.420 --> 42:41.420]  куча вновь станет корректной.
[42:41.420 --> 42:43.420]  Массив вновь станет корректной кучей.
[42:45.420 --> 42:47.420]  Вновь станет
[42:47.420 --> 42:49.420]  корректным.
[42:49.420 --> 42:51.420]  Ну и аналогично наоборот,
[42:51.420 --> 42:53.420]  если av увеличилась, то есть я положил число
[42:53.420 --> 42:55.420]  больше, чем то, что там было,
[42:55.420 --> 42:57.420]  то после сифтдауна массив станет
[42:57.420 --> 42:59.420]  корректной кучей.
[42:59.420 --> 43:01.420]  В противном случае
[43:03.420 --> 43:05.420]  если
[43:05.420 --> 43:07.420]  после сифтдаун
[43:07.420 --> 43:09.420]  от v
[43:09.420 --> 43:11.420]  массив станет корректной кучей.
[43:25.420 --> 43:27.420]  Если мы это докажем,
[43:27.420 --> 43:29.420]  то мы докажем корректность всего,
[43:29.420 --> 43:31.420]  что мы делали до этого.
[43:31.420 --> 43:33.420]  У меня в самом начале была корректная куча.
[43:33.420 --> 43:35.420]  Вот представьте, что до выполнения, например,
[43:35.420 --> 43:37.420]  декрестки у меня была корректная куча.
[43:37.420 --> 43:39.420]  Приходит запрос декрестки
[43:39.420 --> 43:41.420]  по указателю, по номеру вершины v.
[43:41.420 --> 43:43.420]  Тогда что?
[43:43.420 --> 43:45.420]  Тогда я меняю значение в av,
[43:45.420 --> 43:47.420]  ну и вызываю сифтап, по лемме
[43:47.420 --> 43:49.420]  куча вновь станет корректной.
[43:49.420 --> 43:51.420]  Экстракт мин.
[43:51.420 --> 43:53.420]  Я забыл про существование a1,
[43:53.420 --> 43:55.420]  на место корня поставил
[43:55.420 --> 43:57.420]  какое-то большее число.
[43:57.420 --> 43:59.420]  Понятно, что an большее равно, чем a1,
[43:59.420 --> 44:01.420]  вызвал сифтдаун.
[44:01.420 --> 44:03.420]  По лемме куча вновь стала корректной,
[44:03.420 --> 44:05.420]  потому что если число увеличил и вызвал сифтдаун,
[44:05.420 --> 44:07.420]  то куча стала корректной.
[44:07.420 --> 44:09.420]  Все остальные тривиально будут следовать за этой леммой.
[44:11.420 --> 44:13.420]  Да?
[44:13.420 --> 44:15.420]  Ну, я бы не сказал.
[44:15.420 --> 44:17.420]  Давайте доказывать.
[44:19.420 --> 44:21.420]  Случа 1, когда av уменьшается,
[44:23.420 --> 44:25.420]  я буду доказывать индукция по v.
[44:29.420 --> 44:31.420]  Ну, она не сложная,
[44:31.420 --> 44:33.420]  но тут надо какие-то рассуждения привести, тем не менее.
[44:33.420 --> 44:35.420]  Значит, индукция по v.
[44:37.420 --> 44:39.420]  База v равна 1.
[44:39.420 --> 44:41.420]  Тривиально.
[44:41.420 --> 44:43.420]  Потому что если v равна 1,
[44:43.420 --> 44:45.420]  то мы в корне,
[44:45.420 --> 44:47.420]  и значение в корне уменьшилось.
[44:47.420 --> 44:49.420]  Так это вообще прекрасно.
[44:49.420 --> 44:51.420]  Если значение в корне уменьшилось,
[44:51.420 --> 44:53.420]  то куча осталась точно корректной.
[44:53.420 --> 44:55.420]  В корне и так лежит минимум,
[44:55.420 --> 44:57.420]  мы меняем минимум, он становится еще меньше,
[44:57.420 --> 44:59.420]  от этого куча корректной быть не перестает.
[45:01.420 --> 45:03.420]  А у нас все неравенства по-прежнему выполнены,
[45:03.420 --> 45:05.420]  потому что чем ниже, тем больше.
[45:05.420 --> 45:07.420]  Ну, понятно, что в случае v равной 1
[45:07.420 --> 45:09.420]  куча не перестает быть корректной,
[45:09.420 --> 45:11.420]  а, как мы помним,
[45:11.420 --> 45:13.420]  shift-up от единицы,
[45:13.420 --> 45:15.420]  туда же до сих пор написано,
[45:15.420 --> 45:17.420]  shift-up от единицы ничего не делает.
[45:17.420 --> 45:19.420]  Поэтому, что в куче ничего не произошло,
[45:19.420 --> 45:21.420]  что shift-up ничего не сделал, все хорошо.
[45:21.420 --> 45:23.420]  Переход.
[45:23.420 --> 45:25.420]  Вот какой-то av.
[45:25.420 --> 45:27.420]  Давайте была такая картинка.
[45:27.420 --> 45:29.420]  Вот было av,
[45:29.420 --> 45:31.420]  был у него родитель ap.
[45:31.420 --> 45:33.420]  Ну, понятно, p это v пополам,
[45:33.420 --> 45:35.420]  не хочу писать v пополам,
[45:35.420 --> 45:37.420]  будет p, родитель.
[45:37.420 --> 45:39.420]  И вот это вот число
[45:39.420 --> 45:41.420]  меняется на x.
[45:43.420 --> 45:45.420]  Но давайте рассмотрим два случая.
[45:45.420 --> 45:47.420]  Во-первых, если x внезапно
[45:47.420 --> 45:49.420]  больше равной, чем ap.
[45:49.420 --> 45:51.420]  Тогда я утверждаю, что куча остается корректной,
[45:51.420 --> 45:53.420]  и shift-up тоже ничего не делает.
[45:53.420 --> 45:55.420]  Ну, смотрите, вот у меня была корректная куча,
[45:55.420 --> 45:57.420]  внезапно вот это значение уменьшилось,
[45:57.420 --> 45:59.420]  стало x.
[45:59.420 --> 46:01.420]  Но вот это вот неравенство
[46:01.420 --> 46:03.420]  осталось верным.
[46:03.420 --> 46:05.420]  То есть как оно было верно раньше,
[46:05.420 --> 46:07.420]  потому что была корректная куча,
[46:07.420 --> 46:09.420]  чем ниже, тем больше.
[46:09.420 --> 46:11.420]  Ну и теперь, если x по-прежнему
[46:11.420 --> 46:13.420]  больше равной, чем ap,
[46:13.420 --> 46:15.420]  то здесь такое неравенство,
[46:15.420 --> 46:17.420]  то здесь такое неравенство,
[46:17.420 --> 46:19.420]  ниже больше, чем выше,
[46:19.420 --> 46:21.420]  тогда я утверждаю,
[46:21.420 --> 46:23.420]  что куча остается корректной.
[46:23.420 --> 46:25.420]  Ну, потому что более-менее понятно,
[46:25.420 --> 46:27.420]  мы только это неравенство могли нарушить.
[46:31.420 --> 46:33.420]  Справедливо.
[46:33.420 --> 46:35.420]  Мы потенциально могли нарушить эти два неравенства.
[46:35.420 --> 46:37.420]  Но, смотрите, что такое неравенство?
[46:37.420 --> 46:39.420]  Мне нужно, чтобы здесь было меньше, чем здесь.
[46:39.420 --> 46:41.420]  Но я это-то уменьшил, значит здесь
[46:41.420 --> 46:43.420]  подавно все неравенства остались.
[46:47.420 --> 46:51.420]  А я предположил, что я уменьшил до х, который тем не менее больше в ноль, чем ап.
[46:51.420 --> 46:56.420]  То есть я поменял только это значение. Очевидно, что неравенство с детьми у меня не испортились,
[46:56.420 --> 47:00.420]  потому что здесь стало только меньше, а неравенство с этим не испортилось по предположению.
[47:00.420 --> 47:02.420]  Я говорю, что х больше в ноль, чем ап.
[47:02.420 --> 47:06.420]  В этом случае куча остается корректной, и все хорошо.
[47:06.420 --> 47:11.420]  Куча остается корректной, но соответственно севтап ничего не делает, и все правильно делает.
[47:11.420 --> 47:13.420]  Севтап ничего не делает.
[47:13.420 --> 47:16.420]  То есть х меньше, чем ап предыдущая, но больше, чем ап.
[47:16.420 --> 47:20.420]  Да, да, да, все правильно.
[47:20.420 --> 47:26.420]  Так, случай второй как раз менее приятный, когда х меньше, чем ап.
[47:26.420 --> 47:28.420]  То есть когда вот это неравенство нарушилось.
[47:28.420 --> 47:30.420]  Давайте картинка.
[47:30.420 --> 47:38.420]  Тут ав, которое поменялось на х, и ап, и теперь х меньше, чем ав.
[47:38.420 --> 47:42.420]  Ну тогда понятно, его хочется как раз поднимать.
[47:42.420 --> 47:46.420]  Так, давайте картинку побольше нарисую.
[47:46.420 --> 47:49.420]  Вот у меня есть ап, вот у меня есть ав, которое заменилось на х,
[47:49.420 --> 47:55.420]  и вот там есть еще куда-то выше и ниже есть наша большая куча.
[47:55.420 --> 47:58.420]  Смотрите, давайте я сделаю две следующие вещи.
[47:58.420 --> 48:06.420]  Действие первое. Давайте я заменю вот это вот на ап.
[48:06.420 --> 48:10.420]  Согласны ли вы, что это корректная куча?
[48:10.420 --> 48:14.420]  Да, потому что я уменьшил значение здесь, не нарушив этого неравенства.
[48:14.420 --> 48:17.420]  Здесь по-прежнему это число меньше, чем вот это.
[48:17.420 --> 48:20.420]  То есть менять ав на родителя всегда можно.
[48:20.420 --> 48:22.420]  То есть это неравенство остается таким, как надо.
[48:22.420 --> 48:25.420]  А с детьми опять-таки ничего не нарушилось, потому что это стало еще меньше.
[48:25.420 --> 48:28.420]  Значит с детьми точно проблемы не было.
[48:28.420 --> 48:33.420]  Дальше возьму и поменяю вот это вот на х.
[48:33.420 --> 48:36.420]  Тогда с одной стороны я сделал ровно то, что нужно.
[48:36.420 --> 48:42.420]  Потому что по сравнению с исходным деревом я избавился от ав, но поставил х.
[48:42.420 --> 48:44.420]  А ап просто спустился вниз.
[48:44.420 --> 48:51.420]  То есть я избавился от ав, но добавил х в мое дерево, но я этот х уже поставил на место ап.
[48:51.420 --> 48:54.420]  А дальше предположение индукции.
[48:54.420 --> 48:58.420]  То есть у меня в этот момент, смотрите, в момент, когда у меня куча вот такая,
[48:58.420 --> 49:00.420]  когда здесь и здесь ап, это корректная куча,
[49:00.420 --> 49:06.420]  дальше я меняю число на меньшее, я меняю ап на меньшее число х.
[49:06.420 --> 49:12.420]  Значит по предположению индукции рекурсивный запуск сифтапа от п сделает кучу корректной.
[49:16.420 --> 49:17.420]  Давайте еще раз.
[49:17.420 --> 49:19.420]  Значит давайте я в два шага это сделал.
[49:19.420 --> 49:21.420]  Шаг первый.
[49:21.420 --> 49:29.420]  Заменить ав на ап.
[49:29.420 --> 49:31.420]  То есть картинка сейчас вот такая.
[49:31.420 --> 49:36.420]  Да, у меня на месте ав стоит такое же число, которое в родителе ап стояло.
[49:36.420 --> 49:38.420]  Значит понятно, что это будет корректная куча.
[49:38.420 --> 49:40.420]  Получим корректную кучу.
[49:40.420 --> 49:43.420]  Получим корректную кучу.
[49:43.420 --> 49:48.420]  Ну потому что по сравнению с исходной кучей все, что я поменял, это ав поменялось на ап.
[49:48.420 --> 49:53.420]  Понятно, что если поменять это число на родителя, то все не равны сохраняться такими, как надо.
[49:53.420 --> 49:55.420]  Значит у меня есть корректная куча.
[49:55.420 --> 49:57.420]  Второй шаг.
[49:57.420 --> 49:59.420]  Я заменяю верхнее ап.
[49:59.420 --> 50:01.420]  Значит заменить верхнее ап.
[50:01.420 --> 50:05.420]  Ну из вот этих двух верхнее ап.
[50:05.420 --> 50:07.420]  На х.
[50:10.420 --> 50:13.420]  А этот шаг я уже умею делать по предположению индукции.
[50:13.420 --> 50:15.420]  То есть я что сделал?
[50:15.420 --> 50:21.420]  По факту я заменяю уже не вот это вот более низкое число на х, а более высокое число меняю на х.
[50:22.420 --> 50:26.420]  И поскольку я из корректной кучи одно число уменьшил на х,
[50:26.420 --> 50:30.420]  то по предположению индукции для этой вершины я же иду в порядке увеличения номеров вершин.
[50:30.420 --> 50:33.420]  Ну в частности, п меньше чем v,
[50:33.420 --> 50:35.420]  п меньше чем все его дети.
[50:35.420 --> 50:39.420]  Поэтому по предположению индукции, когда сифта прикурсивно запускается вот этой вершины,
[50:39.420 --> 50:43.420]  она ее поднимает вверх и восстанавливает корректность кучу.
[50:46.420 --> 50:48.420]  А их два, как видите.
[50:48.420 --> 50:50.420]  После первого шага их как будто бы два.
[50:50.420 --> 50:52.420]  Вот я вот это вот заменяю на х.
[50:52.420 --> 50:54.420]  И это то же самое, что с кучей происходит.
[50:54.420 --> 50:58.420]  Я спустил верхнее ап вниз, а х поднял вот сюда.
[51:04.420 --> 51:06.420]  По предположению индукции,
[51:09.420 --> 51:13.420]  после сифтапа от п,
[51:15.420 --> 51:17.420]  куча вновь станет корректной.
[51:21.420 --> 51:23.420]  Вот.
[51:23.420 --> 51:26.420]  Ну и собственно, ровно это и делает наш сифтап.
[51:26.420 --> 51:28.420]  Потому что сифтап,
[51:28.420 --> 51:30.420]  ну то есть он на самом деле, конечно, сюда ап явным образом не ставит.
[51:30.420 --> 51:32.420]  Он говорит следующее.
[51:32.420 --> 51:34.420]  Он видит, что это число, которое здесь х,
[51:34.420 --> 51:36.420]  меньше чем в родителе,
[51:36.420 --> 51:38.420]  поэтому оно свопает и рекурсивно запускается от п.
[51:38.420 --> 51:40.420]  Ну мы по факту ровно это и сделали.
[51:40.420 --> 51:42.420]  Мы сюда записали ап, сюда х, и рекурсивно запустились от родителя.
[51:42.420 --> 51:44.420]  Ровно это, то, что мы здесь это писали,
[51:44.420 --> 51:46.420]  ровно это делает сифтап.
[51:46.420 --> 51:48.420]  Он сначала поменял местами х и ап,
[51:48.420 --> 51:50.420]  потом запускается рекурсивно от п.
[51:50.420 --> 51:52.420]  Да.
[51:52.420 --> 51:54.420]  Еще раз?
[52:00.420 --> 52:02.420]  Вот этот?
[52:02.420 --> 52:04.420]  Или ребенок?
[52:08.420 --> 52:10.420]  Так а что его рассматривать?
[52:10.420 --> 52:12.420]  Смотрите.
[52:12.420 --> 52:14.420]  В момент, когда я заменяю av на ap,
[52:14.420 --> 52:16.420]  я поменял только вот это число.
[52:16.420 --> 52:18.420]  Понятно, что мне надо рассматривать
[52:18.420 --> 52:20.420]  только вот эти три неравенства с детьми и с родителем.
[52:20.420 --> 52:22.420]  Они не испортились, потому что это
[52:22.420 --> 52:24.420]  число уменьшилось, значит с детьми всё только лучше
[52:24.420 --> 52:26.420]  стало, а с родителем тоже не испортилось,
[52:26.420 --> 52:28.420]  потому что они равны.
[52:28.420 --> 52:30.420]  Теперь у меня была корректная куча. Я поменял это число
[52:30.420 --> 52:32.420]  на х.
[52:32.420 --> 52:34.420]  Но опять, это число уменьшилось, по предположению,
[52:34.420 --> 52:36.420]  х меньше, чем ап, значит это число уменьшилось,
[52:36.420 --> 52:38.420]  и нарушение может быть только
[52:38.420 --> 52:40.420]  с родителем, а нарушение с родителем
[52:40.420 --> 52:42.420]  у меня как раз фиксится сифтапом.
[52:42.420 --> 52:44.420]  Отлично.
[52:50.420 --> 52:54.420]  Ну это неважно, конечно. Здесь я нигде не пользовался тем, что это слева, а не справа.
[53:00.420 --> 53:03.420]  Я пользовался только тем, что вы это сын пей и все.
[53:04.420 --> 53:07.420]  Как они друг от друга относительно расположены, слева справа, я не пользовался.
[53:08.420 --> 53:10.420]  Проверите, если не верите.
[53:11.420 --> 53:12.420]  Ау?
[53:14.420 --> 53:16.420]  А вроде и не надо пока.
[53:18.420 --> 53:21.420]  Так, все, идем дальше. Доказываем про увеличение.
[53:22.420 --> 53:27.420]  Ну тут как бы более-менее та же логика, только у меня будет индукция, наоборот, от листьев к корню.
[53:28.420 --> 53:34.420]  Если сейчас я рассуждал от корня к листьям, доказал для корня, потом для более низких вышин и все, более-более низких сверху вниз шел.
[53:35.420 --> 53:37.420]  Теперь, наоборот, будет индукция снизу вверх.
[53:37.420 --> 53:39.420]  Значит, индукция.
[53:40.420 --> 53:42.420]  Я напишу от листьев к корню,
[53:45.420 --> 53:48.420]  ну то есть формально, по типу n-v.
[53:51.420 --> 53:54.420]  Чем больше в этом, раньше я рассматриваю этот элемент.
[53:59.420 --> 54:00.420]  Вот.
[54:01.420 --> 54:02.420]  Ну чего, база.
[54:03.420 --> 54:06.420]  База, если v-лист, то все тривиально.
[54:07.420 --> 54:12.420]  Потому что если мы находимся в листе, и там значение увеличилось, то никакие неравенства не нарушились.
[54:13.420 --> 54:15.420]  Сивдаун ничего не делает, все хорошо.
[54:16.420 --> 54:20.420]  Вот я был листом, у меня есть только родитель, с которым неравенство могло нарушиться, а детей нет.
[54:21.420 --> 54:25.420]  Если я здесь число только увеличиваю, то неравенство с родителем становится еще только более хорошим,
[54:26.420 --> 54:28.420]  то есть оно еще более строго становится, сын меньше, чем родитель.
[54:29.420 --> 54:31.420]  А с детьми ничего не нарушается, потому что их нет.
[54:32.420 --> 54:36.420]  Ну и сивдаун делает то же самое, сивдаун смотрит, проверяет, что детей нет, сразу делает ретёрн.
[54:37.420 --> 54:38.420]  Поэтому в этом случае все хорошо.
[54:39.420 --> 54:41.420]  Если v-лист, то у нас все тривиально, ничего не происходит, куча остается корректной.
[54:42.420 --> 54:43.420]  Переход.
[54:44.420 --> 54:46.420]  Пусть у v есть дети.
[54:47.420 --> 54:49.420]  Так, ну тут нужна опять картинка.
[54:50.420 --> 54:56.420]  Значит, вот пусть есть ap, а v, которая потом меняется на x, есть какие-то дети.
[54:56.420 --> 55:01.420]  Ну, детей 2 или 1, давайте в общем случае рассмотрю 2 ребенка.
[55:02.420 --> 55:04.420]  Случай одного ребенка ничем не отличается.
[55:09.420 --> 55:10.420]  Второй случай.
[55:11.420 --> 55:13.420]  У меня число увеличилось.
[55:14.420 --> 55:15.420]  Уменьшилось, это первый случай.
[55:16.420 --> 55:17.420]  Я рассмотрю второй, когда значение увеличилось только.
[55:18.420 --> 55:22.420]  Так, вот, значит, av увеличилось, стало x.
[55:23.420 --> 55:26.420]  Значит, давайте я скажу, что au – это минимальный из двух сыновей.
[55:27.420 --> 55:32.420]  Ну, мы помним, что в процедуре сивдаун я из двух детей выбираю минимальный, пусть au – это как раз минимальный.
[55:33.420 --> 55:35.420]  Пусть au – это минимальный из сыновей.
[55:36.420 --> 55:40.420]  au – минимальный из сыновей.
[55:41.420 --> 55:45.420]  Минимальный в смысле значение в нём меньше и равно, чем в другом сыне, если он есть.
[55:46.420 --> 55:48.420]  То есть не важно, что он стоит справа?
[55:49.420 --> 55:50.420]  Не важно, конечно, он может быть здесь.
[55:50.420 --> 55:54.420]  Здесь на ориентацию мне пофиг, кто слева, кто справа.
[55:55.420 --> 55:56.420]  Может быть здесь.
[56:05.420 --> 56:06.420]  Конечно.
[56:07.420 --> 56:08.420]  Абсолютно не важно.
[56:09.420 --> 56:10.420]  Неравенство уже выполняются?
[56:11.420 --> 56:12.420]  Что слева направо?
[56:13.420 --> 56:14.420]  Нет, это значение я.
[56:15.420 --> 56:16.420]  Это не индексы, а значение.
[56:16.420 --> 56:20.420]  Ага, хорошо.
[56:21.420 --> 56:24.420]  Так, ну опять два случая.
[56:25.420 --> 56:26.420]  Значит, случай первый.
[56:27.420 --> 56:33.420]  Представьте себе, что x, хоть это число и увеличилось до x, но x всё равно меньше и равно, чем au.
[56:34.420 --> 56:36.420]  То есть вот такое вот неравенство есть.
[56:37.420 --> 56:40.420]  Тогда я утверждаю, что куча осталась корректной.
[56:41.420 --> 56:45.420]  Куча осталась корректной.
[56:46.420 --> 56:49.420]  Но вроде понятно, это значение только увеличилось, поэтому это неравенство осталось.
[56:50.420 --> 56:58.420]  А поскольку au минимальный из сыновей и x меньше и равно, чем au, то x тем более меньше и равно, чем другой сын, потому что сын больше.
[56:59.420 --> 57:00.420]  Да.
[57:06.420 --> 57:09.420]  Нет, нет, было av стало x.
[57:10.420 --> 57:11.420]  Там даже написано, становится x.
[57:12.420 --> 57:14.420]  Я специально переписывал, именно становится x.
[57:14.420 --> 57:15.420]  Вот.
[57:16.420 --> 57:18.420]  Значит, в этом случае все неравенства сохранились.
[57:19.420 --> 57:20.420]  И shift down ничего не делает.
[57:21.420 --> 57:22.420]  Там была отдельная проверка.
[57:23.420 --> 57:25.420]  Если значение в вершине меньше и равно, чем в минимальном сыне, то return.
[57:26.420 --> 57:27.420]  Ну, точнее, там ничего не делаем.
[57:28.420 --> 57:30.420]  И опять-таки shift down ничего не делает.
[57:31.420 --> 57:32.420]  Что и надо.
[57:33.420 --> 57:34.420]  Shift down 2 ничего не делает.
[57:35.420 --> 57:36.420]  Как и надо.
[57:45.420 --> 57:46.420]  Так.
[57:47.420 --> 57:48.420]  Ну, второй случай.
[57:49.420 --> 57:51.420]  x больше, чем au.
[57:54.420 --> 57:56.420]  Ну, давайте опять я сделаю трюк с заменой.
[57:57.420 --> 58:01.420]  Давайте я рассмотрю вот такое вот дерево.
[58:02.420 --> 58:04.420]  Ну, точнее, такую кучу.
[58:04.420 --> 58:07.420]  Значит, я в этой вершине напишу au.
[58:09.420 --> 58:13.420]  Первый шаг опять заменить av на au.
[58:17.420 --> 58:18.420]  Куча останется корректной.
[58:19.420 --> 58:22.420]  Потому что, смотрите, я поднял сюда.
[58:23.420 --> 58:26.420]  То есть я вместо av написал au, которое было больше обыкновенной, чем av.
[58:27.420 --> 58:30.420]  Я считаю, что в этой вершине у меня остался ау.
[58:30.420 --> 58:33.420]  То есть я вместо av написал au, которое было больше обыкновенной, чем av.
[58:34.420 --> 58:35.420]  Я считаю, что куча изначально была корректной.
[58:36.420 --> 58:37.420]  Поэтому это число больше обыкновенной, чем differentiate.
[58:38.420 --> 58:39.420]  Я сюда поднял его же.
[58:40.420 --> 58:41.420]  Значит, это неравенство стало более грубым.
[58:42.420 --> 58:44.420]  Если я это число увеличил, значит, это неравенство точно сохранилось.
[58:45.420 --> 58:47.420]  Но поскольку из двух детей я выбрал наименьшего,
[58:48.420 --> 58:50.420]  то и это неравенство тоже сохранилось.
[58:51.420 --> 58:53.420]  Поскольку я сюда поднял наименьшего из двух детей,
[58:54.420 --> 58:56.420]  значит, m меньше равен другого сына.
[58:57.420 --> 58:58.420]  Значит, здесь неравенство сохранилось.
[58:58.420 --> 59:13.140]  поэтому куча осталась корректной. Ну а дальше я заменяю нижнее вхождение ау на х, заменить
[59:13.140 --> 59:26.120]  нижнее вхождение ау на х. А дальше предположение индукции. У меня была корректная куча, я поменял
[59:26.120 --> 59:32.300]  это число на х, увеличил его причем. Заметь, х больше чем старое значение ау, я увеличиваю это
[59:32.300 --> 59:44.280]  значение и запускаю рекурсивно си в даун от у. Значит по предположению индукции я починю всю
[59:44.280 --> 59:47.960]  кучу. После завершения этого запуска у меня куча станет корректной по предположению индукции
[59:47.960 --> 59:57.320]  просто потому что эта вершина ближе к листьям чем в. Кажется конец. Тот же самый трюк я на самом деле
[59:57.320 --> 01:00:01.960]  сделал. Я просто сказал, что вместо того чтобы их посвопать, я сначала подниму вот это число сюда,
[01:00:01.960 --> 01:00:06.600]  куча будет корректной, а потом это заменю на х. А дальше по предположению индукции, потому что
[01:00:06.600 --> 01:00:12.960]  вот в этом поддереве это уже более низкая вершина чем это, то по индукции вот это вот станет
[01:00:12.960 --> 01:00:24.120]  корректной кучей, значит все станет корректной кучей. Успех? Нет? Давайте вопрос тогда. Да,
[01:00:24.120 --> 01:00:39.960]  написано где-то было. Мы же сказали, что ав стало х и оно увеличилось, т.е. х больше чем ав, да,
[01:00:39.960 --> 01:00:49.920]  это правда. Мы живем, пункт 2 это значит х больше чем ав. А 2 что вы сказали? Нет, х больше чем ав,
[01:00:49.920 --> 01:01:01.960]  не нравится написано. Как раз нарушится, но нарушится также как в этом пункте 2. У меня
[01:01:01.960 --> 01:01:08.720]  было ау, я его меняю на х, т.е. я его увеличиваю. Это ровно то, что я сейчас доказываю. У меня была
[01:01:08.720 --> 01:01:15.040]  корректная куча, я поменял какое-то значение на х, причем оно увеличилось. В случае 2. А дальше
[01:01:15.040 --> 01:01:32.320]  там рекурс или индукция, вот здесь вот станет корректная куча по индукции. Вы про индукцию?
[01:01:32.320 --> 01:01:39.680]  А, ну это вы передоказали принцип мат индукции? Да, можно и так конечно, но мне не очень хочется
[01:01:39.680 --> 01:01:52.240]  сделать. Так, ну чудно. Вот, все доказали. Значит, с корректностью разобрались, теперь давайте про
[01:01:52.240 --> 01:01:57.440]  асимптотику скажу. Ну а асимптотика ответов на все запросы, кроме гетмина, это будет логарифом.
[01:01:57.440 --> 01:02:02.720]  Значит, гетмин у меня будет за единицу, потому что это просто обращение к ячейке памяти,
[01:02:02.720 --> 01:02:16.920]  а остальные, значит, экстрактмин, инсерт и декрески, у меня работают от логарифма. Ну логарифм,
[01:02:16.920 --> 01:02:21.680]  потому что у меня у дерева будет логарифмическая глубина, и каждый из них я свел по факту либо к
[01:02:21.680 --> 01:02:28.160]  севтапу, либо к севдауну. Они работают за время пропорциональной глубине дерева. Понятно,
[01:02:28.160 --> 01:02:42.840]  почему глубина логарифма, или надо это расписать? Ну отлично. Потому что так работает. Ну я где-то
[01:02:42.840 --> 01:02:46.400]  это использовал. Я использовал, что ау минимальный, потому что, например, вот здесь вот я когда меняю
[01:02:46.400 --> 01:02:51.960]  это на х, и это не больше, чем ау, то оно точно не больше, чем это, потому что ау минимальный.
[01:02:51.960 --> 01:02:56.600]  Ну вот тут если аккуратно проследить, то минимальность, ну, играет роль. Если бы я
[01:02:56.600 --> 01:03:10.040]  брал произвольно, то там бы что-то сломалось. Так, ну супер, супер. Так, хорошо. Дальше давайте
[01:03:10.040 --> 01:03:24.920]  тогда перейдем к сортировке кучей. Она же хип-сорт. Ну хип, потому что по-английски куча это хип.
[01:03:24.920 --> 01:03:43.240]  Так, значит очень простой алгоритм сортировки кучей. Вот представьте себе, что у вас есть
[01:03:43.240 --> 01:03:50.720]  последовательство элементов а1, а2 и так далее, ан. Как ее отсортировать с помощью кучи? Решение,
[01:03:50.720 --> 01:03:57.440]  давайте мы n раз сделаем insert, insert а1, insert а2 и так далее, insert ан, потом n раз сделаем
[01:03:57.440 --> 01:04:01.960]  экстракт мин. На каждом шаге мы выводим минимум из оставшихся, то есть и ту статистику, и ту
[01:04:01.960 --> 01:04:10.280]  упрятную статистику на каждом шаге. Значит insert а1 и так далее ан, потом n раз экстракт мин.
[01:04:10.280 --> 01:04:20.200]  Поскольку экстракт сначала вывел минимум, удалил его из кучи, потом получается минимум из оставшихся,
[01:04:20.200 --> 01:04:24.600]  то есть второй минимум, а вторую порядку статистику, потом его удалил, потом минимум из оставшихся,
[01:04:24.600 --> 01:04:28.800]  то есть третью порядку статистику, ну и так далее. Значит в конце вот то, что выведут все эти
[01:04:28.800 --> 01:04:40.360]  экстракт-мин, это как раз порядок сортировки. Согласны? Что? Да, что? Надо сделать что еще раз?
[01:04:40.360 --> 01:04:46.880]  Сначала экстракт вывести, а потом же удалять. А, да, ну в смысле вы имеете в виду get-min, да,
[01:04:46.880 --> 01:04:53.080]  выводить? Ну, я имею в виду, ну понятно, что как бы экстракт с печатанием элемента, да, да,
[01:04:53.080 --> 01:04:57.280]  это справедливо, что надо скорее делать get-min, потом экстракт-min, но можно сказать, что экстракт
[01:04:57.280 --> 01:05:03.400]  выводит сразу число, он удаляет и выводит число, которое удалил. Вот. Ну и работает, конечно, за n
[01:05:03.400 --> 01:05:08.920]  log n, потому что, как мы сказали, все запросы, что insert, что экстракт, работают за единицу в кучу.
[01:05:08.920 --> 01:05:19.240]  Фу ты, за алгорифм, за алгорифм. У нас n insert, n extract, sum of n log n. Вот, очень простой такой алгоритм
[01:05:19.240 --> 01:05:29.280]  получился. Следствие, очень интересное, что в частности, если ваша куча основана на сравнениях,
[01:05:29.280 --> 01:05:35.240]  то есть так же, как и раньше, про числа мы умеем говорить только то, что их можно сравнивать,
[01:05:35.240 --> 01:05:41.320]  про элементы мы умеем только сравнивать их, тогда не существует такой реализации кучи,
[01:05:41.320 --> 01:05:50.880]  который бы insert и extract обрабатывал за единицу. Не существует кучи, я скажу так, реализации кучи,
[01:05:50.880 --> 01:06:04.240]  реализации кучи, основаны на сравнениях, в которой экстракт и insert работают за единицу.
[01:06:04.240 --> 01:06:19.280]  Insert работает за от единицы, потому что иначе мы бы научились сортировать числа за от n.
[01:06:19.280 --> 01:06:26.240]  Даже не числа, а просто объекты. А мы знаем, что если мы умеем их только сравнивать, то быстрее,
[01:06:26.240 --> 01:06:38.400]  чем мы их сравниваем, не обойтись. Да? Вот, очень простое следствие. Хорошо. Ну, еще раз, доказательства,
[01:06:38.400 --> 01:06:43.240]  потому что иначе, если бы и insert, и extract я бы делал за единицу, тогда бы я научился сортировать
[01:06:43.240 --> 01:06:48.680]  за линию. n insert за единицу, n extract за единицу, суммарно-линиейное время работы, а я бы сортировал
[01:06:48.680 --> 01:07:05.960]  массив. Не понял? Не, еще раз, еще раз, смотрите, мне достаточно, наоборот, здесь достаточно какой-то
[01:07:05.960 --> 01:07:11.560]  реализации сортировки, потому что если вдруг существует куча, в которой insert и extract работают
[01:07:11.560 --> 01:07:17.600]  за единицу, то я умею сортировать за от n. Неважно, возможно еще более эффективные алгоритмы,
[01:07:17.600 --> 01:07:25.280]  тогда еще быстрее, чем за линию мне сортировать. Ну и бог с ним. Уже противоречие. Да, по отдельности,
[01:07:25.280 --> 01:07:31.640]  по отдельности, ну по крайней мере, с insert точно, да, с extract если заморочишься, тоже можно за единицу,
[01:07:31.640 --> 01:07:38.240]  да, ну это по крайней мере за учетную, за амортизировано вот это вот. Так, хорошо, значит вот это в принципе
[01:07:38.240 --> 01:07:45.120]  есть какой-то результат. Теперь, смотрите, hip-сорт можно еще несколько соптимизировать. Давайте мы
[01:07:45.120 --> 01:07:53.120]  первое, что сделаем, это научимся вот это вот делать за от n. То есть вместо того, чтобы n раз
[01:07:53.120 --> 01:07:57.720]  вставлять, давайте мы сразу воспользуемся тем знанием, что у меня все элементы даны заранее,
[01:07:57.720 --> 01:08:05.320]  и давайте опишем процедуру hipify, как это обычно называется, это процедура, строящая кучу на
[01:08:05.320 --> 01:08:17.920]  массиве заранее заданном. Ну по факту построить кучу, построить кучу на а1 и так далее а n. Вот, ну то есть
[01:08:17.920 --> 01:08:22.000]  мы не будем пользоваться insert, который уже встроен в кучу и по одному элементу добавляет,
[01:08:22.000 --> 01:08:27.840]  давайте мы напишем отдельную процедуру, которая по массиву строит кучу на нём. Алгоритм работает
[01:08:27.840 --> 01:08:42.320]  следующим образом. В порядке убывания всех ишек запустите в даун, а ты. Конец. То есть смотрите,
[01:08:42.320 --> 01:08:47.760]  вот пусть у меня был массив а1 и так далее а n. Я хочу на этой же памяти, вот в этих же ячейках
[01:08:47.760 --> 01:08:53.960]  памяти так их переставить, эти элементы, чтобы выполнялось требование кучи. Но вот я утверждаю,
[01:08:53.960 --> 01:09:00.080]  что если просто написать вот эти две строчки, то после их выполнения здесь станет корректной куча.
[01:09:00.080 --> 01:09:15.480]  Нет, нет, там более тонкой будет. Да, вопрос какой-то ещё был. Севдаун и, да, вот то и,
[01:09:15.480 --> 01:09:20.040]  которое бежит по циклу, оно ж севдаунец. Значит, давайте сначала докажем, что это вообще корректно.
[01:09:20.040 --> 01:09:32.840]  Но это не очень сложно. Я утверждаю, что после и-то итерации цикла под дерево вершины и будет
[01:09:32.840 --> 01:09:49.760]  корректной кучей. Почему? Ну индукция опять в порядке убывания и.
[01:09:49.760 --> 01:09:56.720]  Понятно, что если и это лист, то после севдауна ты и всё под дерево будет кучей. Потому что если
[01:09:56.720 --> 01:10:00.960]  и это лист, у него в под дереве ничего нет, это корректная куча. Здесь никакие неразрешения
[01:10:00.960 --> 01:10:05.600]  нарушаются. Возможно с родителями, но они выше, они не в под дереве. Значит, для листи всё хорошо.
[01:10:05.600 --> 01:10:11.560]  Дальше. Представьте, что мы доказали для всех и, там не знаю, n, n-1 и так далее, там n-200. Давайте
[01:10:11.560 --> 01:10:20.280]  докажем для n-201. То есть вот у меня есть какой-то аи. Для всех больших и, для всех больших индексов
[01:10:20.280 --> 01:10:26.600]  я уже севдаун и вызвал, и там у всех корректные кучи. В частности, у детей корректные кучи. Вот
[01:10:26.600 --> 01:10:34.760]  это вот а2и, это а2и плюс один. Поскольку у них индексы больше, я от них запускал севдаун раньше,
[01:10:34.760 --> 01:10:39.760]  и по предположению индукции могу считать, что здесь корректная куча. Здесь корректная куча,
[01:10:39.760 --> 01:10:45.520]  и здесь корректная куча. Ну а дальше, что я делаю? Смотрите, у меня есть две корректные кучи. Я их
[01:10:45.520 --> 01:10:50.840]  склеиваю через одно какое-то число. Фиг пойми какое. Единственное, что может нарушаться, это то,
[01:10:50.840 --> 01:10:55.320]  что это число может быть слишком большим, чтобы быть корнем этого дерева. Потому что, если оно
[01:10:55.320 --> 01:10:59.680]  меньше равно обоих сыновей, то делать ничего не надо, и так корректная куча. Единственное, что
[01:10:59.680 --> 01:11:05.200]  может сломаться, это что, если это число больше, чем какой-то из сыновей, тогда севдаун это исправит.
[01:11:05.200 --> 01:11:12.440]  Потому что, если бы это у меня была корректная куча, потом я сюда ставлю аи и запускаю севдаун
[01:11:12.440 --> 01:11:16.040]  от и. Единственное, что может сломаться, это что, если это число слишком большое. Вот севдаун это
[01:11:16.040 --> 01:11:27.120]  починит. Убедительно? Ну вроде все. Значит, тогда после всех этих севдаунов у меня куча будет корректной.
[01:11:27.120 --> 01:11:43.880]  Так, еще раз. Почему идем в таком порядке? Потому что так работает. Второй вопрос не понял про индекса.
[01:11:43.880 --> 01:11:52.240]  Упражнений на семинар. Что если делать в другом порядке, или если запускать сифтап, то можно
[01:11:52.240 --> 01:11:56.600]  подобрать пример, на котором это будет некорректно. А в таком порядке будет корректно. Вот это только
[01:11:56.600 --> 01:12:03.920]  что пытаюсь доказывать, по крайней мере. После и-тетрации цикла под дерево вершины и будет
[01:12:03.920 --> 01:12:10.600]  корректной кучей. То есть вот и и все, что ниже, все, что в под дереве, это корректная куча. С индексами
[01:12:10.600 --> 01:12:15.320]  не очень понял вопрос. Наверное, вы про то, что вот, ну как бы, я считаю, что это уже уже куча. То есть я
[01:12:15.320 --> 01:12:19.600]  представляю этот массив как кучу вот в том смысле, что это дерево большое, в котором, возможно,
[01:12:19.600 --> 01:12:25.040]  какие-то неравенства нарушаются. Дальше я беру и запускаю севдауны в обратном порядке. Для n, n-1,
[01:12:25.040 --> 01:12:34.040]  и так далее, вплоть до единицы. Не обязательно, но довольно большой элемент, который меньше,
[01:12:34.040 --> 01:12:41.600]  чем вот все, что выше. Да, это правда. Да, конечно, извините, да, больше, чем все его предки. Хорошо.
[01:12:41.600 --> 01:12:52.240]  Мы не меняем, не меняем индекса. Всегда он меняет значение элементов, но не индексы.
[01:12:52.240 --> 01:13:00.920]  Да, мне так и надо. У меня вот здесь было нарушение неравенства. Там, не знаю, здесь 5, здесь 3.
[01:13:00.920 --> 01:13:09.960]  Но я их беру и меняю местами. Числа меняю местами. Да. Да.
[01:13:09.960 --> 01:13:24.880]  В дереве отрезка длина массива n. Ну, еще раз, это у меня индексация такая же, как в кучу. У меня
[01:13:24.880 --> 01:13:30.760]  всегда сыновья i, это 2i и 2i плюс 1. Я здесь никакого откровения не делаю. У меня всегда номерация такая.
[01:13:30.760 --> 01:13:40.480]  Давайте без дерева отрезков, пожалуйста. Давайте без дерева отрезков, пожалуйста. Мы в куче сегодня живем.
[01:13:40.480 --> 01:13:55.440]  Еще раз. Да, да, да. Можно здесь оптимизировать и запускаться от первого нелеста, например. Да,
[01:13:55.440 --> 01:14:03.480]  можно не париться. В этот момент я считаю, что я доказал, что Hippie-Fi строит корректную кучу на той же памяти,
[01:14:03.480 --> 01:14:08.880]  где исходно был массив. Причем, заметьте, еще раз, я переставляю исходные элементы, я не завожу новый
[01:14:08.880 --> 01:14:13.920]  массив, куда я складываю кучу, как было вот в этой реализации. У меня были числа, я заводил отдельно
[01:14:13.920 --> 01:14:20.280]  память для кучи и туда все сваливал заново, как будто бы с чистого листа. Так вот, нет, в этой
[01:14:20.280 --> 01:14:26.200]  реализации я все делал на той же памяти, где исходно был массив. Так, это была корректность.
[01:14:26.200 --> 01:14:33.760]  Теперь докажем, что это все работает суммарно за O от N. Вот этот цикл работает за O от N.
[01:14:33.760 --> 01:14:42.600]  Ну, понятна оценка N log N. Мы знаем, что каждый севдаун работает за логарифм, за O от логарифма.
[01:14:42.600 --> 01:14:47.440]  Если суммировать, получится O от N log N. Но это грубая оценка, потому что понятно, что севдауны,
[01:14:47.440 --> 01:14:52.200]  например, для листьев работают за единицу. Если и это лист, то там нечего делать, мы работаем за единицу.
[01:14:52.200 --> 01:14:57.760]  Ну и вообще, если вершина внезапно находится на глубине там, то есть если от нее расстояние до
[01:14:57.760 --> 01:15:06.280]  листьев это K, то время севдауна ограничено точным числом K. Это O от K. Если от вершины и до листьев
[01:15:06.280 --> 01:15:13.280]  вниз расстояние K, то севдаун работает за O от K. Давайте вот это тогда аккуратненько просуммируем.
[01:15:13.280 --> 01:15:29.480]  Значит, смотрите, давайте я нарисую какое-то дерево. Я понимаю, что у него, ну давайте полное.
[01:15:29.480 --> 01:15:38.160]  Давайте для простоты буду считать, что у меня дерево полное, то есть на первом уровне одна вершина,
[01:15:38.160 --> 01:15:44.000]  на втором два и так далее до степени двойки. Ну такая, самая красивая картинка. Тогда понятно,
[01:15:44.000 --> 01:15:50.720]  что на последнем уровне у меня будет N пополам вершин. Ну примерно N пополам, округлите верх,
[01:15:50.720 --> 01:15:57.400]  ну короче примерно N пополам. На них на всех время работы будет единица. Ну это вот как раз то
[01:15:57.400 --> 01:16:02.080]  замечание, что севдаун от листьев ничего не делает, и суммарное время работы севдаун на всех
[01:16:02.080 --> 01:16:07.720]  листьях это N пополам на единицу. Дальше, когда мы запускаем севдаун от вот этих вот вершин,
[01:16:07.720 --> 01:16:14.240]  да, спредпоследнем уровне, их здесь уже понятно в два раза меньше. Их здесь N на четыре и севдаун для
[01:16:14.240 --> 01:16:20.000]  каждого из них работает за два, ну потому что надо как бы, глубина до листьев это два,
[01:16:20.000 --> 01:16:26.200]  окей, там один, два, неважно, два, буду считать, что два, время работы будет двойка. Значит, здесь
[01:16:26.200 --> 01:16:31.920]  на следующем уровне вверх будет N на 8 умножить на 3, ну и так далее. То есть по факту суммарное
[01:16:31.920 --> 01:16:48.120]  время моих вот этих вот севдаунов всех, это следующий ряд. Согласны? Ну опять повторю,
[01:16:48.120 --> 01:16:55.280]  это все в идеальной парадигме, что у меня дерево полное, если оно не полное, то, ну окей,
[01:16:55.280 --> 01:16:59.000]  здесь просто будет не N пополам, а еще меньше будет листьев. На листьев тогда будет еще меньше вот
[01:16:59.000 --> 01:17:03.160]  на этом уровне, поэтому здесь даже еще меньшее время получается. Здесь меньше N пополам,
[01:17:03.160 --> 01:17:07.160]  здесь N на четыре на два или даже на один вот для этих вершин. Ну короче, тогда будет еще только
[01:17:07.160 --> 01:17:14.960]  проще мне это делать, поэтому я рассматриваю худший случай. Так, хорошо, ну давайте я вот с этим
[01:17:14.960 --> 01:17:42.880]  рядом немножко какую-то магию сделаю. Давайте из всех этих слагаемых вытащу одно из них. То есть
[01:17:42.880 --> 01:17:47.160]  вот здесь вот я представлю N на четыре как N на четыре плюс N на четыре, вот это слагаемое,
[01:17:47.160 --> 01:17:53.080]  здесь N на 8 плюс 2 N на 8, здесь N на 16 плюс 3 N на 16 и так далее. Что у меня получится? У меня
[01:17:53.080 --> 01:17:58.960]  получится с одной стороны, то есть я вот из всех этих множителей вытаскиваю одно слагаемое. У меня
[01:17:58.960 --> 01:18:06.560]  тогда будет N пополам плюс N на четыре плюс N на 8 плюс N на 16 плюс так далее, а останется вот
[01:18:06.560 --> 01:18:13.680]  этот вот ряд с уменьшенными на один вот этими вторыми множителями. Останется в скобках N на
[01:18:13.680 --> 01:18:21.920]  четыре на один плюс N на 8 на два плюс N на 16 на три плюс так далее. Еще раз, я все вот эти вот
[01:18:21.920 --> 01:18:27.800]  произведения из всех этих произведений расщепил на два слагаемых. Просто первый
[01:18:27.800 --> 01:18:33.680]  множитель и соответственно произведение вот этого на это минус 1. Тогда сумма сохранилась.
[01:18:33.680 --> 01:18:43.680]  Вы знаете, что это? Это N. Ну там N минус немножечко, давайте напишу, что это не больше, чем N,
[01:18:43.680 --> 01:18:50.480]  потому что это сумма геометрической прогрессии просто. Что дальше? Давайте вот с этой штукой
[01:18:50.480 --> 01:18:56.200]  сделаем то же самое. Давайте здесь извлечем, давайте здесь разобьем все эти произведения. Ну так
[01:18:56.200 --> 01:19:01.160]  что отщепим по одному слагаемому из каждого из них. Здесь будет тогда N на четыре плюс N на
[01:19:01.160 --> 01:19:10.760]  восемь плюс N на 16 плюс по степеням двойки, плюс останутся вот эти вот все слагаемые с на
[01:19:10.760 --> 01:19:19.520]  единичку меньшим вторым множителем. N на восемь на один, N на 16 на два, ну и так далее. Вы знаете,
[01:19:19.520 --> 01:19:26.160]  что вот это такое? Это N пополам даже, ну N пополам, ну потому что это в два раза меньше, чем вот это.
[01:19:26.160 --> 01:19:35.040]  Если с этим сделать то же самое, то получится там N на восемь плюс N, pardon, N на четыре, N на восемь
[01:19:35.040 --> 01:19:48.640]  и так далее. И это мы опять знаем, что это 2N. Так что вот это все, не больше 2N. Такой хак.
[01:19:50.640 --> 01:19:57.000]  То есть еще раз, я рассматриваю вот так вот сумму такого вида, разбиваю все произведения,
[01:19:57.000 --> 01:20:02.280]  так что я отщепляю первый множитель, ну и все, что осталось. Тогда сначала у меня вылезет
[01:20:02.280 --> 01:20:06.440]  сумма N, что-то останется. Если я здесь сделал то же самое, у меня вылезет сумма N пополам,
[01:20:06.440 --> 01:20:12.000]  что-то останется. Здесь, ну то есть это по факту то же самое, только поделенное вот это вот от
[01:20:12.000 --> 01:20:16.360]  исходного. Отличается типа на, просто делением на четыре. Вот это поделение на четыре, это вот это.
[01:20:16.360 --> 01:20:21.800]  Ну соответственно то же самое, когда выделяю, здесь получается на четыре, потом еще раз выделяю на восемь
[01:20:21.800 --> 01:20:25.680]  и так далее. В сумме вот эти все слагаемые дадут 2N. Хорошо?
[01:20:25.680 --> 01:20:30.360]  А можете еще раз объяснить, почему такой ряд?
[01:20:30.360 --> 01:20:36.800]  Почему такой ряд? Смотрите, вот давайте, вот рассмотрим вот такое дерево. В нем листьев примерно
[01:20:36.800 --> 01:20:40.840]  половина, N пополам вот всех вершин. Ну потому что здесь один, два, четыре, восемь, на последнем
[01:20:40.840 --> 01:20:45.880]  уровне половина от всех. Для них всегда он работает за единицу, поэтому суммарное время работает
[01:20:45.880 --> 01:20:51.040]  всегда он на листьях вот это, N пополам на один. Сколько вершин на предпоследнем уровне? Вот столько,
[01:20:51.080 --> 01:20:56.520]  в два раза меньше. Но на них всегда он работает за два действия. Ну не больше, чем за два действия.
[01:20:56.520 --> 01:21:01.760]  На третьем с конца уровня вершин N на восемь, и там всегда он работает за три действия. Ну и так далее.
[01:21:01.760 --> 01:21:11.280]  Вот, вот и ряд получился. Так, хорошо. Давайте быстренько, я попробую, ну поскольку все равно мы
[01:21:11.280 --> 01:21:20.120]  больше не успеем, сейчас или успеем, а что надо-то? Нет ладно, давайте я скажу следующее. То есть мы
[01:21:20.120 --> 01:21:27.720]  доказали, что хиппифай работает за линию. Вот, хиппифай работает за линию. Все, а дальше давайте
[01:21:27.720 --> 01:21:33.280]  вернемся вот к хипсорту. Что мы получается сделали? Мы вот эту вот часть заменили на хиппифай за линию,
[01:21:33.280 --> 01:21:45.960]  хиппифай за ОАТН. Так, дальше остается N раз экстракт минов. Ну, это мы сильно оптимизировать не
[01:21:45.960 --> 01:21:54.080]  будем, но мы сделаем следующее замечание. Смотрите, вот экстракт мин выдает какое-то число. Ну то есть я
[01:21:54.080 --> 01:21:58.800]  считаю, что там перед экстрактом я сначала getMin вызываю, он печатает число, которое удаляет, потом
[01:21:58.800 --> 01:22:06.000]  его удаляет из кучи. Так вот, но мы знаем, что экстракт на самом деле, он не совсем удаляет
[01:22:06.000 --> 01:22:10.240]  число из кучи, он на самом деле его перемещает на последнее место и как бы про него забывает,
[01:22:10.240 --> 01:22:13.920]  уменьшает размер массива на один. То есть на самом деле само это число никуда не девается, оно в массиве
[01:22:13.920 --> 01:22:21.680]  лежит. Получается, что после первого экстракт мина, какое число будет на N месте? Минимум. Потому что я
[01:22:21.680 --> 01:22:26.120]  извлекаю минимум и кладу его на N место, на последнее место массива. То есть после первого экстракт мина
[01:22:26.120 --> 01:22:33.200]  у меня в последней клетке будет лежать первая порядка статистика. Я извлекаю минимум, вспоминаем,
[01:22:33.200 --> 01:22:39.520]  как работает экстракт мин. Он меняет местами корень и N элемент и уменьшает размер массива на один.
[01:22:39.520 --> 01:22:45.040]  То есть он корень поместил вот сюда, он минимум поместил сюда. Что делает второй экстракт мин? Он
[01:22:45.040 --> 01:22:50.720]  корень, то есть минимум в оставшемся массиве, помещает вот сюда. Поскольку корень это минимум,
[01:22:50.720 --> 01:22:55.680]  то есть вторая порядка статистика, вторая порядка статистики перемещается ровно вот сюда и так далее.
[01:22:55.680 --> 01:23:05.260]  На и-том шаге мы достаем из кучи и-ту статистику и кладем ее на и-тое с конца места. Поэтому N раз
[01:23:05.260 --> 01:23:10.140]  применен на экстракт мин, по факту тоже сортирует массив только в порядке убывания. Если его теперь
[01:23:10.140 --> 01:23:18.300]  развернуть, то мы получим сортировку этого же массива. И ее прелесть в том, что это так названа
[01:23:18.300 --> 01:23:26.860]  сортировка in place. На месте, то есть без доп памяти. В отличие от всяких там сортировок типа слиянием,
[01:23:26.860 --> 01:23:32.460]  когда мне нужно было для слияния двух массивов построить третий, куда надо сливать, здесь никакой
[01:23:32.460 --> 01:23:37.500]  доп памяти нет, потому что хиппи-фай у меня без доп памяти. Я кучу построил на том же массиве,
[01:23:37.500 --> 01:23:42.300]  который мне был дан. Потом я вызываю экстракты, но они эти элементы просто перемещаются в порядке
[01:23:42.300 --> 01:23:48.660]  справа налево. И опять на той же памяти у меня лежит отсортированная версия массива. Только нужно
[01:23:48.660 --> 01:23:53.060]  в конце будет поменять порядок, сделать реверс, поменять местами это и это, это и это и так далее.
[01:23:53.060 --> 01:24:01.260]  И получается у меня сортировка на месте без доп памяти. А то есть от единицы дополнительной памяти.
[01:24:01.260 --> 01:24:14.300]  Еще раз, чем плоха доп память? Ну, типа, ну вдруг она дорогая, вдруг у вас ее нет, вдруг у вас
[01:24:14.300 --> 01:24:19.260]  настолько большой массив, что вы не можете себе позволить ничего еще выделять. Все, спасибо,
