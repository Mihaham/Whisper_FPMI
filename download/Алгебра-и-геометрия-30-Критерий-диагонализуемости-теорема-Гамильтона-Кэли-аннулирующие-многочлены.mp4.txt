[00:00.000 --> 00:12.400]  Итак, добрый день, давайте начинать. Со звуку у нас там всё в порядке, правильно, на сей раз? И со всем
[00:12.400 --> 00:23.360]  остальным всё в порядке. Я напоминаю, на чём мы остановились. Мы с вами изучаем собственные
[00:23.360 --> 00:31.600]  значения, собственные векторы оператора, и в частности мы хотим понять, когда
[00:31.600 --> 00:42.600]  оператор диагонализуем, то есть у него есть, для него есть базис, в котором его матрица имеет
[00:42.600 --> 00:48.840]  диагональный вид. Ну вот мы говорили, что тогда у него достаточно простой геометрический смысл,
[00:48.840 --> 00:57.520]  и вроде как мы в прошлый раз сформулировали, но не доказали теорему. Правильно я помню? Давайте
[00:57.520 --> 01:12.360]  я её вкратце напишу уже. Для оператора ФИ равносильны следующие утверждения. Во-первых,
[01:12.360 --> 01:30.040]  ФИ диагонализуем. Во-вторых, в В есть базис из собственных векторов нашего
[01:30.040 --> 01:47.360]  преобразования ФИ. Третье условие, что В есть прямая сумма собственных подпространств. Ну и четвёртое,
[01:47.360 --> 01:58.360]  самое длинное условие, но зато наиболее, возможно, полезное на практике, это то, что характеристический
[01:58.360 --> 02:10.520]  многочлен раскладывается на линейное сомножителе, произведение там лямбда ИТ минус Х в каких-то
[02:10.520 --> 02:18.080]  степенях. Вот давайте я даже так напишу. Раз у нас К собственных значений, то характеристический
[02:18.080 --> 02:24.600]  многочлен раскладывается, у характеристического многочлена корнями служат лямбда 1 и так далее,
[02:24.600 --> 02:31.360]  лямбда К, я их всех различных перечислил. И тогда, если он раскладывается на линейные
[02:31.360 --> 02:43.760]  сомножители, то линейные сомножители должны быть именно вот такими. И при этом алгебраическая
[02:43.760 --> 02:58.760]  кратность каждого собственного значения равна его геометрической кратности. Но я на всякий случай
[02:58.760 --> 03:06.840]  напомню, что алгебрическая кратность собственного значения лямбда ИТ, это в точности вот что это
[03:06.840 --> 03:16.800]  такое в терминологию, которая уже на доске введена? Что? Альфа ИТ, конечно, правильно. Это как раз кратность
[03:16.800 --> 03:27.080]  корня в характеристическом многочлене. В четвертом пункте нам говорят, что геометрическая кратность
[03:27.080 --> 03:46.760]  лямбда ИТ есть альфа ИТ. Ну и давайте мы докажем, что все эти четыре утверждения равносильны. На самом
[03:46.760 --> 03:53.560]  деле у нас как-то немножко необычно, потому что на самом деле нам сейчас будет удобнее не как
[03:53.560 --> 04:00.360]  всегда мы доказывали по циклу, а просто доказать равносильность сначала первых трех по отдельности,
[04:00.360 --> 04:11.200]  а затем понять, что происходит с четвертым. Почему первое условие равносильно второму? Потому
[04:11.200 --> 04:19.440]  что на самом деле, вот что означает, что фи диагонализуем, это означает, что есть первое
[04:19.440 --> 04:32.560]  условие, означает, что есть базис Е такой, что фи в этом базисе имеет диагональную матрицу. Давайте
[04:32.560 --> 04:45.640]  я ради ясности другие числа поставлю, мио 1, мио 2 и так далее, мио n. Ну а это вот просто для
[04:45.640 --> 04:55.200]  базиса Е то, что фи имеет в этом базисе такую матрицу. Давайте я этот базис, элементы этого
[04:55.200 --> 05:03.120]  базиса обозначу через Е, 1 и так далее, Е, n. Вот то, что в этом базисе, в каком-то фиксированном,
[05:03.120 --> 05:14.680]  фи имеет диагональную матрицу равносильно тому, что фи от ЕИТ есть что такое. В ИТ столце у нас
[05:14.680 --> 05:24.720]  стоит мио ИТ на ИТ месте, правильно? Поэтому это есть мио ИТ на ЕИТ при И от 1 до n. Ну то есть
[05:24.720 --> 05:33.640]  равносильно тому, что ЕИТ это собственный вектор с собственным значением мио ИТ. Ну и что у нас
[05:33.640 --> 05:42.000]  получается? То, что фи диагонализуем, равносильно существованию вот такого вот базиса. Ну а базис
[05:42.080 --> 05:50.000]  такой ровно тогда, когда он состоит из собственных векторов. Поэтому если мы диагонализовали наш
[05:50.000 --> 05:57.000]  оператор, то мы автоматически нашли базис собственных векторов, и наоборот, если мы нашли базис
[05:57.000 --> 06:03.120]  собственных векторов, то в этом самом базисе фи имеет диагональный вид. Так что первое, два
[06:03.120 --> 06:12.880]  два утверждения, очевидно, равносильны. Значит, второе и третье утверждения
[06:14.240 --> 06:22.320]  равносильны. Вот по каким причинам. Давайте я сразу напомню. Мы с вами
[06:22.320 --> 06:29.800]  доказывали в прошлый раз, что сумма V лямбда первого плюс и так далее плюс V
[06:29.800 --> 06:43.480]  лямбда Катова прямая всегда. Какой бы я ни взял оператор phi, для него сумма
[06:43.480 --> 06:48.720]  собственных подпространств прямая, ну и соответственно нам нужно доказать только,
[06:48.720 --> 06:56.840]  что есть базис из собственных векторов тогда и только тогда, когда эта прямая сумма совпадает
[06:56.840 --> 07:03.040]  совсем V. То есть, видимо, если этого базиса не будет, то эта прямая сумма будет давать
[07:03.040 --> 07:12.240]  нам в итоге меньше, чем всё пространство, правильно? Ну и давайте мы это будем доказывать. Значит,
[07:12.240 --> 07:30.200]  если V есть прямая сумма наших собственных подпространств, то мы с вами помним, что если
[07:30.200 --> 07:37.280]  мы выберем базис в каждом из прямых слагаемых и объединим их, то есть возьмем контакт нацию этих
[07:37.280 --> 07:45.000]  базисов, то получим базис всей суммы, то есть базис пространства, правильно? Значит, объединяя
[07:45.000 --> 08:04.360]  базисы в V лямбда 1 и так далее V лямбда Катая, мы получим базис в прямой сумме, раз она прямая,
[08:04.360 --> 08:10.360]  это вот у нас был один из критериев прямой суммы, напоминаю. Мы получим базис в пространстве V,
[08:10.360 --> 08:19.160]  ну и поскольку мы элементы базисов брали из собственных подпространств, то все эти элементы
[08:19.160 --> 08:29.960]  собственные векторы, правильно? Его элементы являются собственными векторами. Наоборот,
[08:29.960 --> 08:51.520]  если в V существует базис E, состоящий из собственных векторов, то, глядите,
[08:51.520 --> 09:01.560]  что происходит. Каждый вектор в этом базисе собственный, поэтому он лежит в каком-то из наших
[09:01.560 --> 09:10.400]  прямых слагаемых, правильно? А коль скоро так, то он лежит и в их сумме. Значит, E содержится в сумме
[09:10.400 --> 09:23.520]  этих собственных подпространств, правильно? Ну а это означает, что эта сумма совпадает,
[09:23.520 --> 09:33.000]  давайте так скажу, в этой сумме содержится и линейная оболочка нашего базиса, то есть V. Ну в итоге
[09:33.000 --> 09:38.720]  мы получили, что наша сумма, во-первых, прямая, это мы знаем всегда, а во-вторых, эта сумма
[09:38.720 --> 09:50.120]  совпадает с V, потому что больше, чем V она дать нам не может, конечно же, правильно? Здесь? Если в V
[09:50.120 --> 09:55.120]  существует базис из собственных векторов, что такое собственный вектор? Каждый собственный вектор
[09:55.120 --> 10:00.400]  лежит в одном из вот этих вот собственных подпространств, правильно? Ну значит, каждый вектор
[10:00.400 --> 10:07.480]  нашего базиса лежит в этой сумме. Все, значит, конечно же, поскольку сумма это подпространство,
[10:07.480 --> 10:18.040]  то и линейная оболочка нашего базиса тоже там лежит, а это все V. Ну и поэтому V есть сумма всех
[10:18.040 --> 10:25.680]  этих подпространств, ну и более того, прямая сумма, потому что их сумма прямая всегда. Так,
[10:25.680 --> 10:34.080]  здесь у нас уже все было доказано, здесь у нас тоже доказано. Значит, давайте мы теперь выясним,
[10:34.080 --> 10:48.880]  почему у нас, например, из первого пункта следует четвертый, давайте мы поймем, что это так. Значит,
[10:48.880 --> 11:01.760]  если phi диагонализуем, то есть в некотором базе C и E его матрица имеет вид μ1 и так далее,
[11:01.760 --> 11:11.600]  μn, давайте мы эту матрицу обозначим через A, то характеристический многочлен нашего phi это
[11:11.600 --> 11:19.560]  просто-напросто характеристический многочлен этой матрицы, ну а он понятно, как выглядит,
[11:19.560 --> 11:29.440]  правильно? Это просто μ1-x, μ2-x и так далее, μn-x. Напоминаю, что характеристический многочлен
[11:29.440 --> 11:38.000]  это определитель A-xE, правда? Мы берем просто-напросто определитель диагональной матрицы,
[11:38.000 --> 11:50.400]  разумеется, он раскладывается на линейные сомножители. Ну и давайте я сразу скажу,
[11:50.400 --> 12:00.720]  что мы можем, вот все эти μиты, конечно же, являются собственными значениями, то есть они являются
[12:00.720 --> 12:08.520]  кем-то из λ, лямбда первого и так далее до лямбда катова, взятых соответствующее количество раз,
[12:08.520 --> 12:18.040]  правильно? Если у нас лямбда первая, скажем, встречается на этой диагонали альфа первое раз,
[12:18.040 --> 12:26.280]  то она, то вот соответствующий множитель и входит в характеристический многочлен в степени альфа
[12:26.280 --> 12:36.760]  первое. Ну и давайте мы сразу скажем, что мы можем эти μиты переставить так, чтобы сначала шли все
[12:36.760 --> 12:43.120]  лямбда первое, потом шли все лямбда второе, потом все лямбда третий и так далее. Что означает переставить
[12:43.120 --> 12:51.840]  эти миты? Что нужно сделать с базисом, чтобы миты переставились? Векторы базиса просто переставить
[12:51.840 --> 12:57.760]  местами, правильно? Сначала в нашем базисе собрать все векторы собственным значением лямбда первое,
[12:57.760 --> 13:03.400]  потом все векторы собственным значением лямбда второе и так далее. Переставляя
[13:03.400 --> 13:16.360]  элементы базиса, нам ничего не нужно сделать, кроме как переставить их местами, правильно? Мы считаем,
[13:16.360 --> 13:28.320]  что наша матрица А выглядит так. Сначала там идут по диагонали, давайте лучше это запишу с
[13:28.320 --> 13:38.240]  использованием обозначения, которые мы уже ввели. А это диагональная матрица, у которой по диагонали
[13:38.240 --> 13:46.320]  идут сначала лямбда первая, потом лямбда вторая и так далее. При этом, еще раз обращаю внимание,
[13:46.320 --> 13:54.800]  если мы считаем, что характеристический многочлен выглядит вот таким вот образом, то это означает,
[13:54.800 --> 14:04.840]  что лямбда первая здесь будет встречаться как раз а1, потому что в нашем многочлене будет
[14:04.840 --> 14:11.840]  а1 вот таких вот сомножителей лямбда 1-х. Лямбда вторая будет встречаться а2 раз, ну и так далее.
[14:11.840 --> 14:28.360]  Что это в свою очередь означает? Тогда, например, для первого собственного значения, если я возьму
[14:28.360 --> 14:38.520]  первые а1 векторов нашего базиса, в котором мы эту матрицу записали, они все будут соответствовать
[14:38.520 --> 14:50.400]  собственному значению лямбда 1, правильно? То есть они все будут лежать в В лямбда первом. Ну и они,
[14:50.400 --> 14:58.760]  естественно, линейно независимы. Следовательно, размерность В лямбда первого больше или равна,
[14:58.760 --> 15:05.680]  чем а1. Мы в ней нашли а1 в линейне независимых векторов, правильно? С другой стороны,
[15:05.680 --> 15:15.720]  эта размерность В лямбда первого, это и есть геометрическая кратность нашего корня лямбда 1,
[15:15.720 --> 15:25.640]  не превосходит алгебравической кратности всегда. Следовательно, геометрическая кратность лямбда
[15:25.640 --> 15:33.640]  первого равна алгебравической кратности лямбда первого. Мы проверили наши условия для лямбда
[15:33.640 --> 15:38.200]  первого, но для остальных оно, естественно, проверяется точно так же. Просто нужно взять
[15:38.200 --> 15:49.760]  соответствующую группу векторов из нашего базы. Ну и таким образом мы с вами доказали,
[15:49.760 --> 15:59.080]  что из первого утверждения следует четвертое. Давайте мы из четвертого выведем, например,
[15:59.080 --> 16:07.640]  третье. И этим мы уже завершим все доказательство. Как из четвертого вывести третье?
[16:07.640 --> 16:14.120]  Значит, если у нас выполнено вот это первое условие, если характеристический многочлен
[16:14.120 --> 16:24.040]  раскладывается на линейное сомножитель, то мы знаем сумму степеней этих сомножителей,
[16:24.040 --> 16:29.400]  правильно? Мы знаем сумму кратностей наших корней, алгебравических кратностей. Поскольку
[16:29.400 --> 16:39.800]  характеристический многочлен раскладывается на линейные сомножители, мы понимаем, что сумма
[16:39.800 --> 16:55.400]  альфаитых равна n. Ну, через n мы, как обычно, обозначаем размерность пространства. Ну а это значит,
[16:55.400 --> 17:07.120]  что если мы возьмем прямую сумму наших собственных подпространств, мы, напоминаю, еще раз, знаем,
[17:07.120 --> 17:17.240]  что она всегда прямая, правильно? Размерность прямой суммы всегда равна сумме размерности прямых
[17:17.240 --> 17:30.680]  слагаемых, а они являются геометрическими кратностями наших собственных значений. Ну и значит,
[17:30.680 --> 17:36.400]  они совпадают с алгебравическими кратностями. Мы предполагаем, что четвертое условие выполнено,
[17:36.400 --> 17:45.680]  правильно? То есть, эта сумма размерностей, это то же самое, что сумма просто-напросто альфаитых,
[17:45.680 --> 17:52.880]  здесь мы воспользовались тем, что алгебравические кратности совпадают с геометрическими, а здесь
[17:52.880 --> 17:59.080]  мы пользуемся тем, что характеристически многочлен раскладывается на линейные сомножители,
[17:59.080 --> 18:07.200]  правильно? Мы этим уже воспользовались здесь. Значит, эта сумма равна размерности v. Ну что мы
[18:07.200 --> 18:13.000]  получили? Мы получили, что вот эта прямая сумма – это подпространство v размерности той же,
[18:13.080 --> 18:21.720]  что и v. Это и означает, что эта прямая сумма равна всему нашему пространству. Итак, v – это
[18:21.720 --> 18:34.680]  прямая сумма, и мы третий пункт таким образом доказали. Ну и критерии диагонализуемости
[18:34.680 --> 18:51.520]  оператора мы тоже уже полностью доказали. Ну и, наверное, на этом все, что мы могли сказать про
[18:51.520 --> 18:58.080]  диагонализуемый оператор. Еще раз напоминаю, что если оператор диагонализуем, то выбрав этот
[18:58.080 --> 19:03.400]  собственный базис, вы получаете очень простую картинку. Оператор есть просто растяжение вдоль
[19:03.400 --> 19:09.400]  соответствующих осей в соответствующее количество рас, лямбда ит. То есть его
[19:09.400 --> 19:19.440]  геометрический смысл простой и работать с ним очень просто. Осталось нам разобраться с тем,
[19:19.440 --> 19:29.880]  что происходит, когда вот эти вот четвертые условия, в частности, не выполняются. Что в
[19:29.880 --> 19:35.320]  такой ситуации можно делать с оператором. Мы уже приводили примеры, которые показывают,
[19:35.320 --> 19:44.800]  что эти четвертые условия могут не выполняться. Ну точнее, давайте я сразу сделаю некоторое замечание.
[19:44.800 --> 20:14.440]  Любое из условий в пункте 4 может не выполниться. У нас мы всегда
[20:14.440 --> 20:19.040]  помним, что алгебрическая кратность не меньше геометрической. И мы уже приводили пример того,
[20:19.040 --> 20:24.480]  что алгебрическая кратность может оказаться больше геометрической кратности какого-то лямбда.
[20:24.480 --> 20:33.960]  И в таком случае понятное дело, что диагонализуемости у нас не будет. Итак, алгебрическая кратность
[20:33.960 --> 20:45.160]  бывает больше, чем геометрическая кратность. Это мы уже видели. Ну и, естественно,
[20:45.160 --> 20:52.360]  характеристический многочлен может оказаться, что у него он не раскладывается на линейные
[20:52.360 --> 21:10.840]  смножители. Может оказаться даже, что у него нет корней совсем у, скажем, поворота двумерного
[21:10.840 --> 21:25.160]  вещественного пространства на угол альфа, ну скажем, строго от нуля до пим. Давайте мы
[21:25.160 --> 21:37.040]  посмотрим на этот поворот. Напоминаю, что матрица его в ортонормированном базе имеют вот такой
[21:37.040 --> 21:43.600]  вот вид. Ну и, соответственно, если вы характеристически многочлен, ее посчитаете,
[21:43.600 --> 21:52.040]  то у вас получится... Давайте мы его посчитаем. Мне нужно по диагонали вычесть из диагональных
[21:52.040 --> 22:00.240]  элементов х, то есть косинус альфа минус х в квадрате и добавить синус квадрат альфа. Получится х
[22:00.240 --> 22:07.960]  квадрат минус 2 косинус альфа плюс один, потому что здесь будет косинус квадрат альфа и будет
[22:07.960 --> 22:22.080]  синус квадрат альфа. У него вещественных корней нет, ну и это согласуется с нашей геометрической
[22:22.080 --> 22:28.480]  интуиции, потому что мы с вами знаем, что если мы поворачиваем плоскость на угол альфа, вот такое
[22:28.680 --> 22:36.120]  то каждый вектор переходит в неколинярное себе, собственных векторов нет. Однако вот такая ситуация
[22:36.120 --> 22:46.440]  еще не очень плохая, потому что, глядите, у этого многочлена нету вещественных корней, зато у него
[22:46.440 --> 22:54.920]  есть корни комплексные. У любого, скажем, вещественного многочлена мы с вами знаем, есть
[22:54.920 --> 23:01.320]  обязательно комплексные корни, то есть такой многочлен разложится на линейные сомножители над
[23:01.320 --> 23:23.480]  полем С. Однако у него есть комплексные корни, ну и в такой ситуации они даже имеют свое название,
[23:24.120 --> 23:48.280]  они обычно называются характеристическими числами оператора. Ну и в такой ситуации,
[23:48.880 --> 23:57.680]  что можно сделать? Если вы хотите хорошо описать такой оператор, ну этот-то еще достаточно простой,
[23:57.680 --> 24:04.320]  а в более сложной ситуации может оказаться, что он выглядит ужасно, в такой ситуации можно сделать
[24:04.320 --> 24:14.600]  следующее, можно формально рассмотреть оператор на двумерном комплексном пространстве с той же
[24:14.600 --> 24:30.920]  самой матрицей, правильно? Тогда можно рассмотреть оператор на двумерном комплексном пространстве
[24:30.920 --> 24:52.920]  с той же матрицей. И для него то самое первое условие из нашего четвертого пункта окажется
[24:52.920 --> 24:58.160]  уже выполненным, характеристически многочлен будет раскладываться на линейные сомножители. В нашем
[24:58.160 --> 25:05.440]  случае, например, он даже окажется диагонализуемым. То есть у него как бы будут два собственных вектора,
[25:05.440 --> 25:13.880]  правда, с комплексными координатами в обычном базисе, в том базисе, в котором оператор задан этой
[25:13.880 --> 25:25.400]  матрицей. Тем не менее с ним тоже может быть удобно работать. Он может быть, не всегда, конечно же,
[25:25.400 --> 25:36.960]  даже будет диагонализуемым. То есть вот мораль этой истории заключается в том, что если у
[25:36.960 --> 25:43.840]  характеристического многочлена нету n корней с учетом кратности, если он не раскладывается на
[25:43.840 --> 25:50.560]  линейные сомножители, то можно попытаться перейти к большему полю и найти корни в этом самом большем
[25:50.560 --> 25:57.880]  поле. Как мы через некоторое время выясним, такой процесс возможен всегда. Всегда, если у вас есть
[25:57.880 --> 26:05.920]  поле, если у вас есть многочлен над этим полем, то всегда можно это поле расширить так, чтобы
[26:05.920 --> 26:11.360]  многочлен над уже расширенным полем разложился на линейные сомножители. Так что вот эта проблема
[26:11.360 --> 26:18.240]  у нас может решиться подобной заменой. А другая проблема, которая заключается в том, что
[26:18.240 --> 26:26.320]  алгебраическая кратность больше геометрической, такой заменой решиться, конечно же, не может.
[26:26.320 --> 26:37.440]  Почему? Ну хотя бы потому, что если вы будете вычислять алгебраическую кратность, то есть находить
[26:37.440 --> 26:42.880]  кратность корня в многочлене, и если вы будете вычислять геометрическую кратность, то есть искать
[26:42.880 --> 26:51.120]  собственное подпространство, решать систему кратности не совпадают с геометрическими.
[26:51.120 --> 26:59.240]  Ну вот, непосредственно к этому вопросу мы подставимся чуть попозже. Сначала нам придется
[26:59.240 --> 27:09.000]  выяснить некоторые дополнительные сведения. Ну и я вот после того, как небольшое замечание
[27:09.000 --> 27:22.760]  сделал, говорю вот что. Значит, с этого момента мы считаем, что вот описанной проблемы здесь,
[27:22.760 --> 27:30.600]  про то, что характеристический многочлен не раскладывается на множители, нету. То есть мы
[27:30.600 --> 27:39.520]  всегда считаем, что у нашего оператора характеристический многочлен раскладывается на
[27:39.520 --> 27:49.000]  линейные сомноживатели. Ну и даже мы с вами ввели сразу определение, правильно? То есть мы говорим,
[27:49.000 --> 28:02.520]  что лямбда 1 и так далее, лямбда каты, это собственное значение нашего оператора фи, а альфаиты их
[28:02.520 --> 28:13.800]  алгебраические кратности. Ну опять же, через некоторое время мы поговорим про то, что делать,
[28:13.800 --> 28:22.640]  то есть как можно работать, если это не так. Ну вот вкратце я уже сказал. С этого момента мы
[28:22.640 --> 28:32.040]  пока считаем, что мы находимся вот в этой ситуации. В частности, если мы работаем в линейном
[28:32.040 --> 28:38.760]  пространстве над полем комплексных чисел, то мы всегда находимся в этой ситуации. Любой
[28:38.760 --> 28:48.160]  линейный оператор на комплексном пространстве, он именно такой, как у нас сейчас написано. Так,
[28:48.160 --> 28:55.600]  ну давайте разбираться, к какому виду, то есть наша главная цель, конечно же, выяснить,
[28:55.600 --> 29:02.800]  какому виду можно привести матрицу линейного оператора, если он вот этому условию удовлетворяет,
[29:02.800 --> 29:12.440]  но он при этом не диагонализуем. И первым делом мы дойдем не до самого конца, а просто увидим,
[29:12.440 --> 29:25.960]  что хоть какому-то удобному виду его привести можно. С этой целью давайте мы докажем вот какую
[29:25.960 --> 29:29.800]  лему, точнее давайте мы сначала докажем следующее вспомогательное утверждение,
[29:30.320 --> 29:38.680]  затем лему, а затем приведем к нужному виду. Утверждение такое, пусть, значит,
[29:38.680 --> 29:48.160]  какой буквы у нас еще не было, бета, это некоторый скаляр, а фи, это как мы уже привыкли,
[29:48.160 --> 30:04.120]  линейный оператор на пространстве В. Тогда под пространство В инвариантно относительно фи,
[30:04.120 --> 30:16.320]  тогда и только тогда, когда оно инвариантно относительно фи минус бета. То есть если я из
[30:16.320 --> 30:23.360]  оператора вычитаю скаляр, ну я напоминаю, что означает скаляр. Скаляр это бета умножить на
[30:23.360 --> 30:30.840]  тождественный оператор, правда ведь? Если я из оператора вычитаю скаляр, то инвариантное
[30:30.840 --> 30:40.680]  подпространство, набор инвариантных подпространств не меняется. Доказательство очень простое, пусть
[30:40.680 --> 30:50.760]  у нас, естественно, я докажу только слева направо, потому что этого достаточно. Что будет,
[30:50.760 --> 30:56.240]  если я докажу слева направо? Если я докажу, что если уинвариантно относительно фи, то уинвариантно
[30:56.240 --> 31:03.720]  относительно фи минус бета. Почему и наоборот тоже будет выполняться? Потому что можно вычесть
[31:03.720 --> 31:09.440]  минус бета, правильно? Вот этот оператор получается из этого добавлением бета, то есть ровно такой
[31:09.440 --> 31:24.920]  же операции, правильно? Просто обратное утверждение будет аналогично. Итак, ну пусть у уинвариантно
[31:24.920 --> 31:37.280]  относительно фи, давайте докажем, что оно инвариантно относительно фи минус бета. Очень просто,
[31:37.280 --> 31:46.880]  если мы взяли какой-то вектор у маленькой из нашего пространства, это означает, что фи от у
[31:46.880 --> 32:00.520]  лежит в у большом, поскольку у большое инвариантно. Ну а тогда, если я из фи от у, давайте я так скажу
[32:00.520 --> 32:08.920]  лучше. Если я применю к нашему у фи минус бета, то что это означает? Это у нас здесь должно быть
[32:08.920 --> 32:19.160]  написано фи от у минус бета, умноженное на у. Ну и оба этих товарища у нас лежат в у, правильно?
[32:19.160 --> 32:26.200]  Фи от у по нашему условию, бета на у, потому что у лежит в у, правда? Значит, оба этих товарища
[32:26.200 --> 32:32.440]  лежат в у большом, а значит их разность тоже лежит в у большом. Мы доказали то, что нам нужно,
[32:32.440 --> 32:38.760]  если какой-то вектор лежит в у большом, то и фи минус бета от этого вектора тоже лежит в у
[32:38.760 --> 32:49.000]  большом. Таким образом утверждение у нас уже доказано. Это утверждение нам пригодится для
[32:49.000 --> 32:50.880]  доказательства вот какой леммы.
[32:50.880 --> 33:08.640]  Плохой мел.
[33:08.640 --> 33:27.480]  Пусть фи, вот на самом деле сейчас я противоречу сам себе, для этой лему мне не нужно условия,
[33:27.480 --> 33:36.080]  что характеристически многошлен раскладывается на линейные с обножителя. Мне важно, что это
[33:36.080 --> 33:50.560]  произвольный, давайте я на всякий случай это напишу, произвольный оператор, у которого есть
[33:50.560 --> 34:08.800]  собственный вектор. Тогда, ну если мы как обычно обозначим через n размерность v, то у нашего фи есть
[34:08.800 --> 34:24.000]  n-одномерное инвариантное подпространство. То есть подпространство размерности на единичку меньше,
[34:24.000 --> 34:37.240]  чем размерность v, еще принято говорить, что это подпространство ко размерности 1. Сразу я хочу
[34:37.280 --> 34:48.600]  оставить предостережение. Очень бы хотелось, вот если я вижу такую лему и хочу ее доказывать,
[34:48.600 --> 34:58.400]  очень бы хотелось доказать ее вот каким образом. Если v это тот самый собственный вектор у фи,
[34:58.400 --> 35:04.840]  который есть, то очень бы хотелось искать это n-одномерное инвариантное подпространство,
[35:04.840 --> 35:20.280]  как какое-то прямое дополнение к линейной оболочке v, правильно? Хотелось бы искать такое
[35:20.280 --> 35:31.560]  инвариантное подпространство u, как прямое дополнение к линейной оболочке v. Так вот,
[35:31.560 --> 35:40.000]  предостережение. Этот путь ведет в тупик. Это, возможно, не всегда. Это, возможно,
[35:40.000 --> 35:53.680]  не всегда. Ну и примером служит та же самая матрица, которую мы с вами уже рисовали,
[35:53.680 --> 36:03.880]  которая носит название жардановой клетки размера 2. Потому что если мы взяли оператор с вот такой
[36:03.880 --> 36:13.400]  вот матрицей, то e1 это собственный вектор. Ну e1 это первый вектор базиса, в котором оператор имеет
[36:13.400 --> 36:22.520]  такую матрицу, правильно? Значит, тогда e1 будет собственным вектором, но не существует такого
[36:22.520 --> 36:32.680]  собственного вектора e2, чтобы их линейные оболочки образовывали прямую сумму. Если бы мы хотели
[36:32.680 --> 36:39.160]  найти вот это вот подпространство, как прямое дополнение, я понимаю, что в этой ситуации у нас
[36:39.160 --> 36:45.640]  уже есть инвинус одномерный. Но если бы мы хотели его искать как прямое дополнение, то оно должно
[36:45.640 --> 36:50.920]  было быть тоже одномерным, то есть тоже порождаться собственным вектором. А вот такого вектора здесь
[36:50.920 --> 36:59.000]  нет. Здесь все собственные векторы пропорциональны e1. Так что таким образом эту лему не доказать,
[36:59.000 --> 37:23.600]  и мы ее докажем немного более хитрым образом, пойдем в обход. Итак, доказываем лему. Нам главное,
[37:23.600 --> 37:30.080]  на самом деле, не то, что у phi есть собственный вектор. Если есть у phi собственный вектор,
[37:30.080 --> 37:40.560]  то у него есть и собственное значение, правильно? Давайте я быстренько это доказательство скажу.
[37:40.560 --> 37:59.720]  Возьмем собственное значение нашего оператора phi. Что это означает? Это означает, что phi-λ вырожденный
[37:59.720 --> 38:20.960]  оператор, в частности, размерность его образа меньше, чем n. Ну а раз меньше, чем n, то мы можем
[38:20.960 --> 38:36.600]  выбрать подпространство u. Такое, что оно, во-первых, содержит этот самый образ, а во-вторых,
[38:36.600 --> 38:46.320]  что его размерность равна n-1. Ну просто будем, например, добавлять по одному. Вот есть у нас
[38:46.320 --> 38:52.400]  какой-то этот образ. Будем добавлять туда новый вектор и брать линейную оболочку. От этого размерность
[38:52.400 --> 39:03.440]  будет увеличиваться на единичку, правильно? Когда-нибудь она доберется до n-1. Мы с вами уже
[39:03.440 --> 39:09.320]  доказывали, что не только образ оператора инвариантен относительно него, но и все,
[39:09.320 --> 39:17.720]  что содержит образ тоже инвариантно относительно этого оператора. Поскольку u содержит образ phi-λ,
[39:17.720 --> 39:28.520]  ну и естественно является подпространством, то u будет инвариантным относительно phi-λ. Ну а по
[39:28.520 --> 39:42.880]  нашему утверждению, тогда u инвариантно и относительно phi. Все, мы завершили наше доказательство.
[39:42.880 --> 39:52.960]  Размерность u оказалась равной n-1, и оно инвариантно относительно phi. Лемма доказана,
[39:52.960 --> 40:00.200]  что из леммы следует. Давайте увидим после 5-ти минутного перерыва. Разумеется, если есть
[40:00.200 --> 40:11.040]  вопросы, то задавайте. Давайте я сначала докажу один и тот же факт на двух разных языках. Ну,
[40:11.040 --> 40:32.720]  точнее, сначала докажу на одном, потом переведу на другой. Итак, теорема. Пусть phi это линейный
[40:32.720 --> 40:39.560]  оператор, ну и давайте мы, это вот наше условие того, что характеристически многошленно раскладывается
[40:39.560 --> 40:50.240]  на линейные сомножители, обратно включим. Удовлетворяющий звездочка, конечно же. Тогда
[40:50.240 --> 41:15.160]  в существует вот какой хороший базис. Существует базис e1 и так далее, en такой, что при всех k от 1 до n
[41:15.160 --> 41:25.880]  линейная оболочка префикса этого базиса, то есть линейная оболочка первых k элементов этого базиса
[41:25.880 --> 41:34.520]  инвариантно относительно phi. То есть линейная оболочка первого вектора инвариантно,
[41:34.520 --> 41:46.160]  линейная оболочка первых двух векторов инвариантно и так далее. Что это значит для матрицы нашего оператора,
[41:46.160 --> 41:53.720]  мы поймем чуть попозже. Давайте сначала докажем. Доказательства очень простое. Теперь уже после того,
[41:53.720 --> 42:08.040]  как мы лему сделали, оно идет индукцией по n, то есть по, естественно, размерности v, как обычно,
[42:08.040 --> 42:25.520]  правильно? Для базы, если n равно 1, то доказывать нечего, правильно? Нам нужен просто любой базис,
[42:25.520 --> 42:30.760]  потому что нам нужно, чтобы линейная оболочка первого вектора, то есть все пространство,
[42:30.880 --> 42:47.480]  был инвариант. Любой базис годится. Пусть теперь n больше единицы. Глядите, что мы можем сказать.
[42:47.480 --> 42:55.680]  Наш характеристический многошлен раскладывается на линейные совножители. В частности, у него есть
[42:55.680 --> 43:06.400]  хотя бы один корень, правильно? А значит, есть хотя бы одно собственное значение. В общем,
[43:06.400 --> 43:23.640]  в любом случае, согласно Лемме, у нас есть подпространство у размерности n-1
[43:23.640 --> 43:50.120]  инвариантное относительно phi. Давайте мы рассмотрим ограничение phi на это подпространство,
[43:50.120 --> 44:02.120]  обозначим его через psi. Это уже линейное преобразование подпространства у. И давайте я сразу
[44:02.120 --> 44:11.240]  замечу, что характеристический многочлен psi, мы с вами знаем, характеристический многочлен
[44:11.240 --> 44:16.680]  ограничения на инвариантное подпространство, делит характеристический многочлен исходного
[44:16.680 --> 44:22.360]  оператора, правильно? Характеристический многочлен psi делит характеристический многочлен phi.
[44:22.360 --> 44:44.440]  И следовательно, характеристический многочлен psi тоже раскладывается на линейные
[44:44.440 --> 44:54.320]  совмножители. Мы с вами знаем, что характеристический многочлен phi раскладывается на линейные
[44:54.320 --> 44:59.800]  совмножители, ну а тогда из основной теоремы арифметики, из единственности разложения на
[44:59.800 --> 45:05.280]  совмножители, мы знаем, что любой его делитель, это тоже произведение некоторых из этих скобок,
[45:05.280 --> 45:10.880]  правильно? Поэтому любой его делитель тоже раскладывается на линейные совмножители,
[45:10.880 --> 45:16.000]  и поэтому к psi мы можем применить предположение индукции.
[45:16.000 --> 45:26.000]  psi уже действует на n-одномерном подпространстве, правильно? К нему предположение применять можно.
[45:26.000 --> 45:41.800]  Применяя предположение индукции psi, находим базис E1, и так далее,
[45:41.800 --> 45:53.520]  E n-1 в U, какой надо. То есть такой, что любой его префикс порождает инвариантное подпространство.
[45:54.120 --> 46:01.840]  Но для того, чтобы сделать то, что нам нужно, достаточно его дополнить до базиса V как угодно.
[46:01.840 --> 46:26.760]  Мы уже получаем требуемое, потому что вот в этом вот списке подпространств,
[46:26.760 --> 46:34.480]  про которые нам нужно потребовать, чтобы они были инвариантными, там первый E n-1 подпространство
[46:34.480 --> 46:39.400]  уже инвариантный, потому что мы их так построили, правильно, по предположению индукции. Ну а n-ное
[46:39.400 --> 46:44.200]  подпространство, которое линейная оболочка всех векторов, оно все V, оно конечно же инвариантное,
[46:44.200 --> 46:50.640]  правильно? Так что вот если мы в U такой базис построили, то дополняем его как угодно и уже
[46:50.640 --> 47:08.640]  получаем то, что нам нужно. Итак, теорема наша с помощью леммы уже доказана, вследствие это просто
[47:08.640 --> 47:20.280]  переформулировка этой теоремы на другой язык. Если наш линейный оператор удовлетворяет нашему
[47:20.280 --> 47:30.160]  условию, то есть его характеристический многочлен раскладывается на линейные сомножители, то существует
[47:30.160 --> 47:44.600]  базис E в пространстве V такой, что матрица phi в этом базисе верхне треугольная. Давайте я напишу,
[47:44.600 --> 47:53.360]  скажем, μ1 и так далее, μn стоят на диагонали, сверху может стоять все что угодно, снизу стоят,
[47:53.360 --> 48:13.400]  снизу от диагонали стоят нули. То есть это верхняя треугольная матрица. Ну, тут все очень просто,
[48:13.400 --> 48:18.200]  просто тот самый базис, который мы нашли в теореме и годится.
[48:18.200 --> 48:47.960]  Итак, доказательства. Базис E из теоремы годится. Почему это так? Давайте поймем.
[48:48.120 --> 48:58.520]  Если мы возьмем произвольный вектор из этого базиса, скажем, екатый, что мы знаем? Что phi от
[48:58.520 --> 49:07.600]  екатого лежит в линейной оболочке первых K базисных векторов, правильно? Просто потому,
[49:07.600 --> 49:13.000]  что эта линейная оболочка это инвариантное подпространство, а екатый там лежит. Ну,
[49:13.040 --> 49:21.920]  значит и phi от екатого тоже там лежит. Ну, а коль скоро это так, то значит, когда мы будем строить
[49:21.920 --> 49:29.400]  матрицу нашего оператора, мы же в катом столбце будем писать как раз образ катого вектора,
[49:29.400 --> 49:36.000]  екатого, разложенного по этому же самому базису. И это значит, что здесь первые K координат могут
[49:36.000 --> 49:41.640]  быть какими угодно, а вот дальше уже точно пойдут нули. Раз phi от екатого выражается только через
[49:41.640 --> 49:50.000]  первые K базисных векторов, правильно? Ну и поскольку это случится для любого K одновременно,
[49:50.000 --> 49:57.800]  то у нас как раз и получится вот эта вот главная диагональ, образуя нам ступеньки, ниже которой
[49:57.800 --> 50:08.440]  точно будут стоять нули. Ну а сверху будет стоять все что угодно. То есть на самом деле, обратите
[50:08.440 --> 50:16.640]  внимание, матрица оператора в каком-то базисе верхне треугольна тогда и только тогда, когда
[50:16.640 --> 50:23.280]  этот базис удовлетворяет вот этим вот условиям, когда все подпространства инвариантны. Другое
[50:23.280 --> 50:32.480]  объяснение этому факту можно сказать следующим образом. Что означает, что подпространство,
[50:32.480 --> 50:39.800]  порожденное E1, инвариантно? Согласно нашему критерию, это означает, что вот здесь в матрице есть
[50:39.800 --> 50:46.400]  угол нулей, правильно? Размера 1, точнее n-1 на 1. Что означает, что подпространство E1, E2,
[50:46.400 --> 50:52.920]  порожденное E1, E2, инвариантно? Это означает, что у нас здесь есть вот такой вот угол нулей и так
[50:52.920 --> 51:00.080]  далее. Эти углы нулей как раз и замастят нам все пространство под главной диагональ. Поэтому
[51:00.080 --> 51:05.600]  инвариантность этих подпространств равносильна тому, что базис удовлетворяет условиям теории.
[51:05.600 --> 51:16.560]  Так, мюиты мне, которые я там написал, не потребовались, но я их ввел для того,
[51:16.560 --> 51:33.240]  чтобы сейчас сделать небольшое замечание. Разумеется, характеристический многочлен phi — это
[51:33.240 --> 51:40.240]  характеристический многочлен вот ровно той самой матрицы, которую мы построили. Давайте мы ее обозначим
[51:40.240 --> 51:55.280]  через А. А характеристический многочлен верхней треугольной матрицы считается настолько же
[51:55.280 --> 52:01.240]  просто, насколько и характеристический многочлен диагональной матрицы, потому что мы знаем,
[52:01.240 --> 52:06.560]  что определитель верхней треугольной матрицы — это просто произведение ее диагональных
[52:06.560 --> 52:19.640]  элементов. То есть это будет произведение u, g от 1 до n, u, g – x. То есть, если мы, наш оператор привели
[52:19.640 --> 52:25.760]  в некотором базисе к верхней треугольному виду, если мы выбрали базис, в котором матрица
[52:25.760 --> 52:32.920]  верхней треугольная, то на диагонали этой матрицы обязаны стоять никто иные как собственное значение,
[52:32.920 --> 52:39.760]  корню характеристического многочлена. Причем не просто собственное значение, а еще и с нужными
[52:39.760 --> 52:47.280]  кратностями. Если собственное значение кратности альфа, то и на этой диагонали она встретится ровно
[52:47.280 --> 52:53.560]  альфа раз, потому что такой смножитель должен встретиться в характеристическом многочлене ровно альфа раз.
[53:03.400 --> 53:06.720]  На диагонали нашей верхней треугольной матрицы
[53:06.720 --> 53:27.120]  стоят просто-напросто собственное значение фи в количествах,
[53:27.120 --> 53:51.000]  равных их алгебраическим кратностям. Ну и более того, хочется еще заодно заметить,
[53:51.000 --> 54:01.880]  если мы для какого-то оператора нашли базис, в котором его матрица верхней треугольная, то тогда
[54:01.880 --> 54:08.680]  характеристический многочлен его обязательно раскладывается на линейные смножители. Поэтому
[54:08.680 --> 54:15.360]  на самом деле вот это следствие можно было бы сформулировать так, что если я взял произвольный
[54:15.360 --> 54:23.200]  оператор, то его можно привести к верхней треугольному виду, то есть можно найти базис,
[54:23.200 --> 54:27.880]  в котором его матрица верхней треугольная, тогда и только тогда, когда его характеристический
[54:27.880 --> 54:39.080]  многочлен раскладывается на линейные смножители. Более того, утверждение теоремы выполняется
[54:39.080 --> 54:53.880]  тогда и только тогда, когда фи удовлетворяет нашей звездочке, то есть когда харм многочлен
[54:53.880 --> 55:02.280]  раскладывается на линейные смножители. Так, замечательно, с этим мы разобрались. Глядите,
[55:02.280 --> 55:07.960]  если не получается привести к диагональному виду, то уж хоть к верхней треугольному виду,
[55:07.960 --> 55:17.960]  у нас привести точно получилось. А из этого мы сейчас немедленно выведем еще одно очень
[55:17.960 --> 55:33.440]  интересное утверждение. Теорема, которая по-русски называется теоремой Гамельтона Келли, а по-английски
[55:33.440 --> 55:44.360]  их переставляют местами, потому что алфавитный порядок такой. Давайте я сделаю так, я сейчас делаю
[55:44.360 --> 55:50.160]  небольшую небрежность, но через некоторое время я ее поправлю. То есть я сейчас сформулирую теорему
[55:50.160 --> 55:55.120]  Гамельтона Келли в полной общности, а докажу сейчас в частном случае, а в полной общности
[55:55.120 --> 56:03.440]  докажу чуть-чуть попозже. Итак, в полной общности теорема Гамельтона Келли говорит вот что. Пусть
[56:03.440 --> 56:18.320]  phi это оператор на каком-то пространстве v, тогда если я в его характеристический многочлен подставлю
[56:18.320 --> 56:31.640]  его, мы же умеем в многочлене подставлять оператор, правильно? Вот мы его и подставили, то получится 0.
[56:31.640 --> 56:46.680]  Удивительное утверждение, потому что мы какой-то взяли определитель, что-то там такое,
[56:46.680 --> 56:57.760]  сделали, а потом вот в этот многочлен, который получился из определителя, внезапно подставляем
[56:57.760 --> 57:04.080]  снова характеристический многочлен. То есть снова наш оператор и мистическим образом получаем 0.
[57:04.080 --> 57:16.120]  Доказательства я сейчас расскажу, но перед тем как я расскажу доказательства, давайте я
[57:16.120 --> 57:30.560]  расскажу неверное доказательство. Что такое характеристический многочлен? На самом деле,
[57:30.560 --> 57:36.840]  вот глядите, извините, давайте я сделаю сразу замечание, прежде чем рассказывать неверное
[57:36.840 --> 57:45.360]  доказательство. Как по-другому можно сформулировать вот это? Естественно, если мы подставляем
[57:45.360 --> 57:50.400]  характеристический многочлен оператора, если мы подставляем в какой-то многочлен
[57:50.400 --> 57:55.900]  оператор, если мы подставляем в какой-то многочлен матрицу этого оператора, то,
[57:55.900 --> 57:59.800]  в результате, естественно и получается какой-то новый оператор, и его матрица в том же самом
[57:59.800 --> 58:06.240]  базе. Правильно? Потому что мы знаем, что когда мы делаем операции с операторами, то соответствующие
[58:06.240 --> 58:10.240]  эти операции проделываются и с их матрицами.
[58:10.240 --> 58:14.240]  Поэтому равносильная форма
[58:18.240 --> 58:25.240]  теоремы Гамильтона Кэля говорит нам, что если я возьму матрицу размера n на n
[58:25.240 --> 58:31.240]  над произвольным полем f, то, подставив
[58:31.240 --> 58:39.240]  ее в ее характеристический многочлен, я получу 0, правда?
[58:39.240 --> 58:45.240]  Так вот неверное доказательство, давайте я вот этот факт и докажу.
[58:45.240 --> 58:50.240]  Но мы же с вами знаем, что такое характеристический многочлен матрицы.
[58:50.240 --> 58:55.240]  Я должен взять определитель a-х на g.
[58:55.240 --> 59:01.240]  Подставить сюда матрицу a проще простого.
[59:14.240 --> 59:22.240]  Получится нулевая матрица, естественно, этот определитель равен 0, правильно?
[59:22.240 --> 59:28.240]  Конец доказательства.
[59:28.240 --> 59:32.240]  Естественно, упражнение для каждого.
[59:32.240 --> 59:37.240]  Объясните, почему это доказательство в корне неверно.
[59:37.240 --> 59:43.240]  Разумеется, доказывать так нельзя, но почему
[59:43.240 --> 59:48.240]  каждый может ответить самостоятельно,
[59:48.240 --> 59:52.240]  в частности, спросив, что такое вот этот 0.
[01:00:06.240 --> 01:00:12.240]  Теперь давайте верное доказательство все-таки выясним.
[01:00:12.240 --> 01:00:17.240]  Итак, еще раз говорю, сейчас я доказываю
[01:00:17.240 --> 01:00:23.240]  теорему Гамильта Накэли, в частном случае, то есть при нашем условии,
[01:00:23.240 --> 01:00:28.240]  которое мы с вами ввели. Мы считаем, что характеристический многочлен
[01:00:28.240 --> 01:00:33.240]  раскладывается на линейные сомножечия.
[01:00:33.240 --> 01:00:38.240]  Коль скоро это так, коль скоро характеристический многочлен раскладывается
[01:00:38.240 --> 01:00:43.240]  на линейные сомножители, то в нашем пространстве V
[01:00:43.240 --> 01:00:48.240]  существует тот самый базис E1, и так далее, E, N.
[01:00:48.240 --> 01:00:53.240]  Такой, что все подпространения, которые мы делаем,
[01:00:53.240 --> 01:00:58.240]  они раскладываются на линейные сомножители.
[01:00:58.240 --> 01:01:03.240]  Такой, что все подпространства,
[01:01:03.240 --> 01:01:08.240]  давайте я еще раз это повторяю, чтобы обозначить эти пространства,
[01:01:08.240 --> 01:01:13.240]  все подпространства вида VKT, линейная оболочка первых K
[01:01:13.240 --> 01:01:18.240]  векторов базиса, инвариантная относительно K.
[01:01:18.240 --> 01:01:23.240]  Мне даже сейчас не нужен в явном виде
[01:01:24.240 --> 01:01:29.240]  треугольный вид матрицы, я скорее буду работать с...
[01:01:29.240 --> 01:01:34.240]  А нет, нужен мне в явном виде
[01:01:34.240 --> 01:01:39.240]  треугольный вид, извините, пожалуйста, лучше все-таки с ним.
[01:01:39.240 --> 01:01:44.240]  Можно бы было без него, но давайте все-таки с ним.
[01:01:44.240 --> 01:01:49.240]  Потому что я хочу сказать,
[01:01:49.240 --> 01:01:54.240]  что в этом базисе
[01:01:54.240 --> 01:01:59.240]  phi имеет верхнетреугольную матрицу
[01:02:05.240 --> 01:02:10.240]  с какими-то скалярами на главной диагонали,
[01:02:10.240 --> 01:02:15.240]  и мы знаем с вами, что характеристический многочлен
[01:02:15.240 --> 01:02:20.240]  его это в точности произведения
[01:02:20.240 --> 01:02:25.240]  аµg-x
[01:02:25.240 --> 01:02:30.240]  по g от 1 до m.
[01:02:30.240 --> 01:02:35.240]  Так вот давайте я и буду пользоваться тем,
[01:02:35.240 --> 01:02:40.240]  что наш характеристический многочлен имеет такой вид.
[01:02:40.240 --> 01:02:45.240]  Я докажу следующее несложное утверждение.
[01:02:45.240 --> 01:02:50.240]  Если я...
[01:02:50.240 --> 01:02:55.240]  Извините, я сразу скажу.
[01:02:55.240 --> 01:03:00.240]  Чем нам это хорошо?
[01:03:00.240 --> 01:03:05.240]  Это будет наш оператор phi.
[01:03:05.240 --> 01:03:10.240]  И мы можем сказать, что характеристический многочлен phi,
[01:03:10.240 --> 01:03:15.240]  если я в него подставлю phi, это будет произведение
[01:03:15.240 --> 01:03:20.240]  по g от 1 до n µg-phi.
[01:03:20.240 --> 01:03:25.240]  Теперь обратите внимание, у нас µg-t резко сменила свою роль.
[01:03:25.240 --> 01:03:30.240]  Это кто?
[01:03:30.240 --> 01:03:35.240]  Это оператор умножения каждого вектора на µg-t.
[01:03:35.240 --> 01:03:40.240]  Мы с вами знаем, что как раз если мы многочлен подставляем
[01:03:40.240 --> 01:03:45.240]  любой элемент произвольной алгебры, то все такие равенства остаются верными.
[01:03:45.240 --> 01:03:50.240]  И вот это для нас ключевой факт.
[01:03:50.240 --> 01:03:55.240]  Это формально не очень хорошая вещь.
[01:03:55.240 --> 01:04:00.240]  Мы с вами знаем, что операторы это не коммутируют.
[01:04:00.240 --> 01:04:05.240]  Вот я здесь написал произведение. В каком порядке я должен их писать?
[01:04:05.240 --> 01:04:10.240]  Фи сам с собой коммутирует и с константами тоже.
[01:04:10.240 --> 01:04:15.240]  Поэтому на самом деле здесь все саммножители тоже коммутируют друг с другом.
[01:04:15.240 --> 01:04:20.240]  Поэтому мы можем их писать в произвольном порядке.
[01:04:20.240 --> 01:04:25.240]  Когда мы характеристически многочлены раскладывали на саммножители,
[01:04:25.240 --> 01:04:30.240]  мы могли как для многочлена написать их в произвольном порядке.
[01:04:30.240 --> 01:04:35.240]  В любое такое разложение мы могли бы подставить фи
[01:04:35.240 --> 01:04:40.240]  и получить верное равенство.
[01:04:41.240 --> 01:04:46.240]  Это еще одно объяснение, почему в каком порядке мы эти саммножители не напишем.
[01:04:46.240 --> 01:04:51.240]  Все равно будет правда в произвольном порядке.
[01:04:58.240 --> 01:05:03.240]  Это мы еще доказывали, когда мы с многочленами работали.
[01:05:03.240 --> 01:05:08.240]  Мы говорили, что такое значение многочлена в алгебре.
[01:05:08.240 --> 01:05:13.240]  Мы можем фи подставить в этот многочлен.
[01:05:13.240 --> 01:05:18.240]  Давайте я еще раз очень вкратце объясню, что означает это равенство.
[01:05:18.240 --> 01:05:23.240]  Это равенство означает, что если мы раскроем все скобки,
[01:05:23.240 --> 01:05:28.240]  то с левой и с правой получим одну и ту же многочлен,
[01:05:28.240 --> 01:05:33.240]  одну и ту же запись этого многочлена через степени х.
[01:05:33.240 --> 01:05:38.240]  Все скобки, скобки мы здесь умеем раскрывать,
[01:05:38.240 --> 01:05:43.240]  все сколяры коммутируются с любым фи,
[01:05:43.240 --> 01:05:48.240]  то мы получим ровно такие же записи, в которых вместо х подставлено фи.
[01:05:48.240 --> 01:05:53.240]  На идеологическом уровне это вот так.
[01:05:53.240 --> 01:05:58.240]  С многочленами от оператора мы такие фокусы умеем производить
[01:05:58.240 --> 01:06:03.240]  и мы этим еще неоднократно будем пользоваться,
[01:06:03.240 --> 01:06:08.240]  потому что в равномногочлене мы уже много чего выяснили.
[01:06:08.240 --> 01:06:13.240]  Теперь я говорю несложное утверждение, из которого очень быстро все у вас последует.
[01:06:13.240 --> 01:06:18.240]  Если я μжитое минус фи применю к подпространству вожитое,
[01:06:18.240 --> 01:06:23.240]  то есть к линейной оболочке префикса sg векторов,
[01:06:23.240 --> 01:06:28.240]  то мы попадем в sg минус 1.
[01:06:33.240 --> 01:06:38.240]  Давайте понимать, почему это так.
[01:06:38.240 --> 01:06:43.240]  Для этого нам достаточно выяснить,
[01:06:43.240 --> 01:06:48.240]  почему если я применю мюжитое минус фи
[01:06:48.240 --> 01:06:52.240]  к базисному вектору в выжитом,
[01:06:52.240 --> 01:06:57.240]  то образ попадет в sg минус 1.
[01:06:57.240 --> 01:07:02.240]  Это достаточно проверить для базиса нашего выжитого,
[01:07:02.240 --> 01:07:07.240]  то есть для векторов e1 и т.д. e житое.
[01:07:07.240 --> 01:07:12.240]  Если я возьму какой-то вектор с меньшим номером,
[01:07:12.240 --> 01:07:17.240]  то мюжитое минус фи от какого-то еитого
[01:07:17.240 --> 01:07:22.240]  вот этого вот еитого с меньшим номером,
[01:07:22.240 --> 01:07:27.240]  это у нас мюжитое еитое, какое-то кратное ему,
[01:07:27.240 --> 01:07:32.240]  минус фи от еитого.
[01:07:32.240 --> 01:07:37.240]  И это все лежит в инвариантном от пространства v и t.
[01:07:37.240 --> 01:07:42.240]  v и t, линейная оболочка первых i векторов, у нас была инвариантным,
[01:07:42.240 --> 01:07:47.240]  поэтому фи от еитого туда попадает.
[01:07:47.240 --> 01:07:52.240]  Ну и вот этот товарищ тоже туда, конечно, попадает, правильно?
[01:07:52.240 --> 01:07:57.240]  Поэтому для всех i меньше g мы автоматом попадаем в e1,
[01:07:57.240 --> 01:08:02.240]  т.е. и в g минус 1 тоже попадаем.
[01:08:02.240 --> 01:08:07.240]  Осталось нам понять, что будет такое фи от ежитого,
[01:08:07.240 --> 01:08:12.240]  если мы посмотрим на нашу матрицу.
[01:08:12.240 --> 01:08:17.240]  Координаты фи от ежитого написаны в житом столбце матрицы, правильно?
[01:08:17.240 --> 01:08:22.240]  И это будет сколько-то e1 плюс сколько-то e2,
[01:08:22.240 --> 01:08:27.240]  вот я беру элементы из этого столбца, плюс и так далее,
[01:08:27.240 --> 01:08:32.240]  и когда я доберусь до ежитого, я его должен умножить на мюжитое.
[01:08:32.240 --> 01:08:37.240]  Ну а значит, если я как раз мюжитое минус фи применю к ежитому,
[01:08:37.240 --> 01:08:42.240]  то это у меня будет мюжитое ежитое минус фи от ежитого,
[01:08:42.240 --> 01:08:47.240]  и как раз ежитое у меня сократится, правильно?
[01:08:47.240 --> 01:08:52.240]  Останутся только векторы от e1 до eg-1.
[01:08:52.240 --> 01:08:57.240]  Поэтому это дело лежит в g-1.
[01:08:57.240 --> 01:09:02.240]  Утверждение у нас доказано,
[01:09:02.240 --> 01:09:07.240]  ну а теперь уже и теорему доказать не так сложным.
[01:09:07.240 --> 01:09:12.240]  Итак, мы вернемся к теорему.
[01:09:15.240 --> 01:09:18.240]  Что означает?
[01:09:18.240 --> 01:09:23.240]  Что это значит?
[01:09:23.240 --> 01:09:26.240]  Что это значит?
[01:09:26.240 --> 01:09:31.240]  Это значит, что мы уже перемещаемся к теорему.
[01:09:31.240 --> 01:09:46.900]  Что означает, что какой-то многочлен от phi равен нулю?
[01:09:46.900 --> 01:09:52.680]  Это означает просто, что если я вот этот оператор
[01:09:52.680 --> 01:09:59.720]  применю к всему пространству v,
[01:09:59.720 --> 01:10:08.400]  то получим ноль, правильно? Все векторы должны перейти в ноль.
[01:10:08.400 --> 01:10:14.600]  Давайте понимать, что это такое. Если я характеристический многочлен от phi
[01:10:14.600 --> 01:10:24.040]  применяю к v, записываем наше произведение, давайте я его
[01:10:24.040 --> 01:10:33.120]  вот так вот запишу. Я первый n-1-ый сомножитель оставлю на месте в нашей формуле,
[01:10:33.120 --> 01:10:44.240]  а последний сомножитель выделю отдельно и применю это дело к v, то есть к vn.
[01:10:44.240 --> 01:10:56.840]  По нашему утверждению, вот этот вот товарищ содержится в n-1, правда?
[01:10:56.840 --> 01:11:02.640]  Ну а значит, если я после этого к нему еще применю все остальные операторы, то у меня
[01:11:02.640 --> 01:11:12.080]  получится, что все это дело содержится вот в таком вот безобразии.
[01:11:12.080 --> 01:11:18.760]  Вот vn-1, ну и здесь мы можем сделать тот же самый финтушами, отделяем
[01:11:18.760 --> 01:11:35.640]  последний сомножитель. Извините, mu n-1-и от vn-1. Опять же, применяем утверждение,
[01:11:35.640 --> 01:11:41.760]  получаем, что когда мы применяем к vn-1 вот этот сомножитель, мы попадаем в vn-2.
[01:11:41.760 --> 01:11:59.800]  Ну и так далее. В самом конце мы получим, что мы применяем mu n-1-и
[01:11:59.800 --> 01:12:10.320]  к подпространству v1. По нашему утверждению, мы его к g равному единице
[01:12:10.320 --> 01:12:15.000]  тоже можем применить, только у нас получится v0-е. Кто такое v0-е должно быть?
[01:12:15.000 --> 01:12:23.680]  Это 0, правильно? Потому что мы просто проверим, что фи от е1-го. Смотрите внимательно на матрицу,
[01:12:23.680 --> 01:12:30.960]  фи от е1-го это просто mu 1-е на е1-е, правильно? И значит, mu 1-е минус фи от него будет 0.
[01:12:30.960 --> 01:12:45.160]  Соединяется v0-е, v0-е это 0. Все, мы наше утверждение доказали. Еще раз, суть того,
[01:12:45.160 --> 01:12:51.000]  что произошло здесь, заключается вот в чем. Я беру все наше пространство, применяю к нему сначала
[01:12:51.000 --> 01:13:00.080]  mu n-е минус фи, попадаю внутрь подпространства vn-1, правильно? Применяю к нему mu n-1-е минус
[01:13:00.080 --> 01:13:07.960]  фи, попадаю уже в vn-2 и так далее. Когда я применю все n-сомножителей, я уже обязан попасть в 0.
[01:13:07.960 --> 01:13:17.920]  Таким образом, теорема Гамильтона Келли доказана. Ну и давайте я сразу сделаю замечание, которое
[01:13:17.920 --> 01:13:28.120]  объясняет, почему можно пока поверить в то, что теорема Гамильтона Келли работает не только
[01:13:28.120 --> 01:13:32.440]  при условии, когда характеристические многошления раскладываются на линейные
[01:13:32.440 --> 01:13:55.840]  смножители, но и в любом случае. Замечание, значит, для произвольного оператора,
[01:13:55.840 --> 01:14:11.040]  то есть теорему можно доказать так. Если мы хотим доказать, что его характеристический
[01:14:11.040 --> 01:14:17.640]  многошлен, примененный к нему, равен нулю, это равносильно тому, что характеристический
[01:14:17.640 --> 01:14:26.840]  многошлен его матрицы, примененный к этой матрице, равен нулю, а это матрица фи в каком-то базе.
[01:14:26.840 --> 01:14:38.920]  А это матрица n на n над нашим полем f. И теперь, вот как я уже говорил, но мы пока что еще не
[01:14:38.920 --> 01:14:55.680]  доказали. Вот я использую факт. Существует, так говорят, расширение, или по-другому можно сказать,
[01:14:55.680 --> 01:15:11.920]  над полем k поля f. Мы можем поле f расширить до какого-то нового поля k такое, чтобы характеристический
[01:15:11.920 --> 01:15:27.760]  многошлен этой матрицы раскладывался на линейные смножители над k. То есть,
[01:15:27.760 --> 01:15:36.720]  глядите, у нас А это матрица с элементами из f. Характеристический многочлен ее это,
[01:15:36.720 --> 01:15:44.160]  естественно, многочлен с коэффициентами из f. Но все многочлены с коэффициентами из f являются
[01:15:44.160 --> 01:15:54.240]  также многочленами с коэффициентами из k, правильно? И матрицу А мы тоже можем воспринимать как матрицу
[01:15:54.240 --> 01:16:04.120]  с элементами из k, поскольку поле f вложено в k, правда? Ну, наконец, естественно, вот это стоит
[01:16:04.120 --> 01:16:10.160]  заметить. Если мы начнем ее характеристический многочлен искать над k, то это будет тот же самый
[01:16:10.160 --> 01:16:15.160]  характеристический многошлен, потому что мы будем проделывать те же самые действия, и в наших
[01:16:15.160 --> 01:16:21.680]  вычислениях мы за рамки поля f не выйдем, правда? Ее характеристический многочлен не зависит
[01:16:21.680 --> 01:16:28.560]  рассматривать ее как матрицу над f или как матрицу над k. Но над k-то уже наше утверждение верно,
[01:16:28.560 --> 01:16:39.640]  но над k мы с вами уже знаем, что характеристический многочлен этой матрицы, примененный к ней, дает 0.
[01:16:39.640 --> 01:16:48.400]  Ну и наконец, что у нас тут такое написано? У нас здесь написана какая-то алгебрическая выкладка,
[01:16:48.400 --> 01:16:53.640]  у которой все коэффициенты, все скаляры, которые здесь встречаются из поля f,
[01:16:53.640 --> 01:17:00.840]  значит, это выкладка и в поле f тоже. Для доказательства этого утверждения, обратите,
[01:17:00.840 --> 01:17:06.600]  пожалуйста, внимание, вот для того, чтобы вся вот эта вот машинирия прошла, нам приходится выходить из
[01:17:06.600 --> 01:17:14.400]  поля f, но в результате формула, которую мы докажем, все элементы этой формулы содержатся в поле f,
[01:17:14.400 --> 01:17:21.680]  и значит, она в поле f тоже верна. Вот такой вот финтушами можно провернуть,
[01:17:21.680 --> 01:17:30.600]  и такие рассуждения на самом деле весьма популярны в алгебре. Все, что для него нам нужно, это...
[01:17:30.600 --> 01:17:41.880]  Чего нам не хватает, чтобы мы уметь находить вот этот надполе. Нам нужен вот этот факт,
[01:17:42.360 --> 01:17:49.280]  все остальное мы на самом деле уже сказали. То есть вот теперь наша вера в теорему Гамильтона Кэли
[01:17:49.280 --> 01:17:56.600]  сводится к вере во вполне конкретный факт, более простой, который мы на самом деле через некоторое
[01:17:56.600 --> 01:18:03.760]  время еще и докажем. Ну а пока что теорему мы доказали, как раз пора идти на перерыв.
[01:18:03.760 --> 01:18:15.440]  Так, значит, мы с вами доказали теорему Гамильтона Кэли, и она открывает нам какие-то новые возможности
[01:18:15.440 --> 01:18:23.440]  в исследовании нашего оператора. Оказывается, вот сейчас мы об этом еще немножко поговорим,
[01:18:23.440 --> 01:18:35.200]  оказывается, на то, что происходит с оператором, важное влияние оказывает то, какие многочлены
[01:18:35.200 --> 01:18:44.920]  этот оператор обнуляет. И вот давайте мы немного о подобных многочленах поговорим,
[01:18:44.920 --> 01:19:07.320]  они называются аннулирующими многочленами. Итак, определение. Пусть у нас фи произвольный оператор
[01:19:07.320 --> 01:19:26.720]  на В. Многочлен, ну скажем, П, естественно, над полем, над которым у нас пространство В, да,
[01:19:26.720 --> 01:19:44.280]  вот это всегда полем, над которым пространство В называется аннулирующим для фи, для оператора фи,
[01:19:44.280 --> 01:20:04.480]  если, понятное дело, П от фи равно нулю. Ну, то есть давайте я сделаю замечание, значит, если мы верим в теорему
[01:20:04.480 --> 01:20:27.640]  Гамильта Накэли, то мы получаем, что характеристический многочлен Фи аннулирующий для фи. Но даже если в Гамильта Накэли не верить,
[01:20:27.640 --> 01:20:35.560]  мы пока не знаем, ну, формально мы не знаем полного доказательства для случая, когда многочлены
[01:20:35.560 --> 01:20:41.760]  раскладываются на линейные со множители, правильно? Даже если в теорему Гамильта Накэли не верить,
[01:20:41.760 --> 01:20:59.640]  все равно нетрудно понять, что такой многочлен у нас существует. Даже без теоремы ясно, что такие
[01:20:59.640 --> 01:21:16.080]  не нулевые, естественно, многочлены найдутся. Это можно понять просто из соображений размерности.
[01:21:16.080 --> 01:21:27.960]  Вот, глядите, размерность пространства линейных операторов на В, это то же самое, что размерность
[01:21:27.960 --> 01:21:37.160]  пространства матриц размера n на n, но n естественная размерность В, правильно? То есть эта размерность равна
[01:21:37.160 --> 01:21:51.440]  n квадрат, естественно. Ну а значит, если мы возьмем в этом пространстве следующие n квадрат плюс
[01:21:51.440 --> 01:22:01.680]  один элемент, а именно один, фи, фи квадрат и так далее, фи в степени n квадрат, то эти вот
[01:22:01.680 --> 01:22:09.880]  n квадрат элементов окажутся линейно зависимыми. Ну то есть система из вот этих вот n квадрат
[01:22:09.880 --> 01:22:17.520]  из одного элемента формально, да, линейно зависима. Но если мы эту линейную зависимость запишем,
[01:22:17.520 --> 01:22:29.840]  то мы получим аннулирующий многочлен, правильно? Запись этой линейной зависимости и дает
[01:22:29.840 --> 01:22:38.280]  аннулирующий многочлен. Если мы запишем эту линейную зависимость, то мы скажем, что просто сумма
[01:22:38.280 --> 01:22:48.820]  pi от 0 до n квадрата, правильно? Каких-то альфаитых на фи витый равно нулю. Ну значит,
[01:22:48.820 --> 01:23:02.640]  вот сумма альфаита х витый и есть аннулирующий. Так что без теории Мегамельта Накэлья мы понимаем,
[01:23:02.640 --> 01:23:17.240]  что есть аннулирующий многочлен в степени не выше чего? n квадрата, правильно? А если использовать
[01:23:17.240 --> 01:23:25.000]  теорию Мегамельта Накэлья, то, конечно же, мы с вами найдем аннулирующий многочлен в степени n,
[01:23:25.000 --> 01:23:30.280]  правильно? Потому что характеристический многочлен у нас имеет степень n. Так что даже
[01:23:30.280 --> 01:23:35.520]  аннулирующий многочлен в степени n у нас на самом деле есть, хотя пока что мы это доказали только
[01:23:35.520 --> 01:23:49.360]  для частного случая немного. Еще одно определение. Мы с вами увидели, что аннулирующий многочлен
[01:23:49.360 --> 01:24:04.440]  уж точно есть. Опять же таки пусть фи, это линейный оператор, его минимальный многочлен
[01:24:04.440 --> 01:24:33.800]  это не нулевой аннулирующий многочлен на и меньшей степени. То есть берем все
[01:24:33.800 --> 01:24:41.000]  не нулевые аннулирующие многочлены для нашего фи, выбираем из них многочлен на и меньшей степени.
[01:24:41.000 --> 01:24:50.080]  Давайте мы чуть-чуть сразу этот минимальный многочлен поисследуем. На самом деле для того,
[01:24:50.080 --> 01:24:59.920]  чтобы понять, кто такие аннулирующие многочлены у нашего фи, нам достаточно знать только его
[01:24:59.920 --> 01:25:07.920]  минимальный многочлен. И это мы сейчас первым делом и докажем. Только сначала давайте мы его обозначим.
[01:25:07.920 --> 01:25:19.080]  Обозначается он, раз он минимальный, мюфи. Ну это естественно какой-то многочлен. Еще раз подчеркиваю
[01:25:19.080 --> 01:25:24.000]  минимальный многочлен, конечно же не нулевой. Мы выбираем его из не нулевых многочленов.
[01:25:24.000 --> 01:25:40.160]  Полезное утверждение, пусть фи это произвольный оператор, мюфи его минимальный многочлен,
[01:25:40.160 --> 01:26:04.200]  а п это какой-то его аннулирующий многочлен. Тогда минимальный многочлен делит п. Ну я бы мог
[01:26:04.200 --> 01:26:10.640]  сразу сформулировать. Давайте в качестве замечания скажу, что наоборот, конечно, тоже верно.
[01:26:10.640 --> 01:26:27.560]  Обратное тоже верно. Если многочлен п это мюфи умножить на какой-то ку, то разумеется,
[01:26:27.560 --> 01:26:37.400]  поставив сюда фи, я получаю, что п от фи это мюфи от фи на ку от фи. А этот оператор уже нулевой,
[01:26:37.400 --> 01:26:45.560]  раз мюфи минимальный, то есть аннулирующий. То есть это будет ноль. То есть на самом деле мы
[01:26:45.560 --> 01:26:52.240]  можем сказать, что многочлен является аннулирующим тогда и только тогда, когда он делится на мюфи.
[01:26:52.240 --> 01:27:10.200]  Доказательство этого очень простое. Давайте мы разделим п на мюфи с остатком. Напоминаю,
[01:27:10.200 --> 01:27:19.560]  что мы умеем делить на любой ненулевой многочлен. П это ку умножить на мюфи плюс р,
[01:27:19.560 --> 01:27:32.560]  где степень р строго меньше, чем степень мюфи. Давайте в это равенство опять же таки подставим
[01:27:32.560 --> 01:27:39.640]  фи. Мы опять же таки делаем тот же самый трюк. Мы берем равенство каких-то многочленов,
[01:27:39.640 --> 01:27:45.080]  а потом вот в это равенство в каждый многочлен по отдельности подставляем фи. И вот мы уже говорили,
[01:27:45.080 --> 01:27:51.640]  что тоже должно получиться верное равенство. Это все было у нас зашито в утверждении о том,
[01:27:51.640 --> 01:28:01.000]  как именно мы считаем значение многочленов в свое время. П от фи это будет ку от фи на мюфи
[01:28:01.000 --> 01:28:11.080]  от фи плюс р от фи. Давайте смотреть, что у нас тут написано. П от фи это 0, потому что
[01:28:11.080 --> 01:28:18.320]  п аннулирующий. Мюфи от фи это тоже 0, ну а значит и все вот это вот это тоже 0, правда?
[01:28:18.320 --> 01:28:31.160]  Значит, мы получаем, что r от фи это 0. Как это может быть? r многочлен степени меньше,
[01:28:31.160 --> 01:28:39.760]  чем мюфи, а мю был многочленом минимальной степени, который обнулял наше фи. Мы получили
[01:28:39.760 --> 01:28:47.680]  противоречие с исключением одного случая, когда r равен нулю, правильно? Потому что мы же выбирали
[01:28:48.360 --> 01:28:56.280]  многочлен в минимальной степени из не нулевых аннулирующих. r тоже аннулирующий, r в степени
[01:28:56.280 --> 01:29:04.680]  меньше, чем мю, извините. Значит, r это нулевой многочлен. Ну а это и есть то, что нам было нужно.
[01:29:04.680 --> 01:29:16.840]  Мы поняли, что p делится на мю, потому что остаток у нас нулевой. Это из минимальности мю.
[01:29:16.840 --> 01:29:30.720]  Как следствие, ну как нулевое следствие, вот я уже сказал, многочлен аннулирующий тогда и только
[01:29:30.720 --> 01:29:37.960]  тогда, когда он делится на минимальный. Как следствие, мы можем сказать, что минимальный
[01:29:37.960 --> 01:29:45.680]  многочлен всегда делит характеристический многочлен. Ну во всяком случае, для всех фид,
[01:29:45.680 --> 01:29:52.440]  для которых мы знаем теорему Гаметана Келли, правильно, как обычно? Поскольку характеристически
[01:29:52.440 --> 01:30:09.360]  тогда будет об нулять. А второе следствие, которое хочется сказать, что в принципе у нас в определении
[01:30:09.360 --> 01:30:19.040]  была некоторая неточность. Дело в том, что таких многочленов может быть много. Многочленов
[01:30:19.040 --> 01:30:26.920]  минимальной степени, которые обнуляют фи. Но естественно, на самом деле, все эти многочлены
[01:30:26.920 --> 01:30:32.640]  ассоциированы друг с другом, то есть получаются друг из друга умножением на ненулевой скаляр.
[01:30:32.640 --> 01:31:00.360]  Если мю1 и мю2 это минимальные многочлены для оператора фи, то они ассоциированы. То есть мю1,
[01:31:00.360 --> 01:31:11.960]  это мю2 на какую-то альфу, где альфа не нулевой скаляр. Но это так просто потому, что давайте
[01:31:11.960 --> 01:31:20.520]  быстренько докажем, потому что раз они оба минимальные, то их степени, конечно же, равны,
[01:31:20.520 --> 01:31:28.240]  и при этом один делит другой, правильно? Этот минимальный, этот аннулирующий, значит первый
[01:31:28.240 --> 01:31:35.560]  делит второй. Но если многочлен делит другой многочлен той же самой степени,
[01:31:35.560 --> 01:31:44.520]  то в частном получается как раз константа, правильно? Поэтому минимальный многочлен определен,
[01:31:44.520 --> 01:31:50.640]  но вот так же, как и нот двух многочленов. Он определен однозначной с точностью до ассоциированности,
[01:31:50.640 --> 01:31:59.200]  правильно? Ну и мы обычно через мюфе обозначаем любой из них. Нам не важно какой, главное,
[01:31:59.200 --> 01:32:04.720]  что мы вот его один раз зафиксировали и после этого это обозначение используем.
[01:32:04.720 --> 01:32:16.160]  Так, значит, глядите, что мы с вами поняли? Мы с вами поняли, что минимальный многочлен,
[01:32:16.160 --> 01:32:21.840]  в частности, делит характеристический, то есть, скажем, если наш характеристический
[01:32:21.840 --> 01:32:28.360]  раскладывается на линейные сомножители, то в минимальные многочлены войдут некоторые из них,
[01:32:28.360 --> 01:32:35.480]  правильно? Некоторые из них, и если там те входили в каких-то степенях, то в минимальные они могут
[01:32:35.480 --> 01:32:43.280]  войти в меньших степенях, правильно? Однако давайте заметим, что эта степень не может уменьшиться до нуля.
[01:32:43.280 --> 01:32:53.000]  Давайте мы докажем вот какое утверждение. Пусть у нас есть произвольный оператор и пусть лямбда
[01:32:53.000 --> 01:33:07.680]  это его собственное значение. Тогда лямбда это корень минимального многочлена. То есть,
[01:33:07.680 --> 01:33:15.840]  если какой-то сомножитель вида лямбда минус х сидел в характеристическом многочлене, то и в
[01:33:15.840 --> 01:33:20.440]  минимальном он тоже обязательно будет сидеть, возможно, в меньшей степени, но в не нулевой обязательно.
[01:33:20.440 --> 01:33:34.160]  Доказательства не очень сложные опять же таким. Давайте мы наоборот теперь по собственному
[01:33:34.160 --> 01:33:42.720]  значению выберем собственный вектор. Пусть v это собственный вектор с собственным значением лямбда.
[01:33:42.720 --> 01:33:46.560]  Мы знаем, что каждое собственное значение это ровно то, для которого есть собственный вектор,
[01:33:46.560 --> 01:33:59.960]  но и я напоминаю, что он не нулевой, правильно? Давайте мы ради ясности распишем наш минимальный
[01:33:59.960 --> 01:34:07.040]  многочлен. Пусть это будет альфа катая на х в катой, плюс и так далее, плюс альфа нулевой.
[01:34:07.040 --> 01:34:23.040]  Тогда глядите, какая ситуация у нас получается. Давайте мы вот что сделаем. Может быть,
[01:34:23.040 --> 01:34:38.880]  расписал я это зря. А давайте я лучше, как и раньше, разделю на сей раз уже мюфитое на х минус лямбда.
[01:34:38.880 --> 01:34:58.920]  Напоминаю, что мы при доказательстве теоремы безу уже говорили, что у нас получится мюфитое есть,
[01:34:58.920 --> 01:35:08.720]  какое-то неполное частное на х минус лямбда и плюс какой-то остаток. Но на самом деле,
[01:35:09.560 --> 01:35:17.680]  что такое остаток? Во-первых, он скаляр, правильно? Поскольку мы делим на линейные многочлены,
[01:35:17.680 --> 01:35:23.200]  мы получаем многочлен в меньшей степени, то есть скаляр. А на самом деле, мы знаем,
[01:35:23.200 --> 01:35:29.240]  кто это такой. Это значение нашего многочлена в этой самой лямбде. Просто подставив сюда
[01:35:29.240 --> 01:35:40.920]  лямбду, мы получим то, что тут написано. Это какой-то скаляр. Ну а теперь давайте мы подставим
[01:35:40.920 --> 01:35:46.280]  вот в этого травенства, давайте я для ясности опять же таки напишу, что мы имеем дело с
[01:35:46.280 --> 01:35:53.160]  многочленами от х, а здесь у нас многочленов от х нет, это просто скаляр. И вот сюда теперь
[01:35:53.160 --> 01:36:09.920]  подставим фи. И более того, мы подставим фи сюда, получим какой-то оператор. Хотя давайте сначала
[01:36:09.920 --> 01:36:18.720]  по очереди. Сначала подставим фи, получим, естественно, что мюфи от фи, то есть ноль,
[01:36:18.720 --> 01:36:37.440]  есть какой-то код фи на фи минус лямбда плюс скаляр мюфи от лямбда. А вот теперь этот оператор,
[01:36:37.440 --> 01:36:48.000]  давайте мы применим к нашему собственному вектору В. Если я этот оператор применяю к В,
[01:36:48.000 --> 01:36:54.600]  то с одной стороны применяю к В нулевой оператор и, следовательно, должен получить нулевой вектор.
[01:36:54.600 --> 01:37:10.520]  А с другой стороны я применяю вот этот оператор, код фи, фи минус лямбда, все это от В, плюс скаляр мюфи от лямбда, умноженный на В.
[01:37:10.520 --> 01:37:19.680]  Ну что означает это произведение? Что я к В применяю сначала один оператор, потом другой,
[01:37:19.680 --> 01:37:31.360]  и уже когда я применяю первый оператор, у меня получается нулевой вектор. В, собственно,
[01:37:31.360 --> 01:37:37.440]  и с собственным значением лямбда, это в точности означает, что фи минус лямбда его обнуляют. Вот это
[01:37:37.440 --> 01:37:42.560]  вот уже ноль. Если я к нулю применю произвольный линейный оператор, то, естественно, тоже получу
[01:37:42.560 --> 01:37:50.320]  ноль правильной. Значит, здесь у меня написано ноль плюс мюфи от лямбда на В. Значит, вот этот
[01:37:50.320 --> 01:37:56.400]  товарищ равен нулю, это может случиться только тогда, когда мюфи от лямбда равно нулю.
[01:37:56.400 --> 01:38:05.760]  Ровно потому, напоминаю, что, согласно нашему определению, собственный вектор всегда не нулевой.
[01:38:05.760 --> 01:38:25.920]  Всё, мы наше утверждение доказали. Ну и как следствие, давайте уж мы сразу это дело проговорим.
[01:38:25.920 --> 01:38:42.320]  Как следствие, если выполняется наша любимая формула, если характеристический многошлен фи
[01:38:42.320 --> 01:39:02.160]  раскладывается на линейные сомножители лямбда ИТ минус Х в степени альфа ИТ? Нет. Почему мюфи Т
[01:39:02.160 --> 01:39:10.720]  не обязательно тот же самый? Это не Х, это Хи. Корни могут повторяться в другое количество раз,
[01:39:10.720 --> 01:39:19.200]  правильно? Значит, глядите, если мы с вами знаем, что минимальный многочлен делит характеристически,
[01:39:19.200 --> 01:39:26.840]  делители у вот такого многочлена мы прекрасно знаем. Это произведение всех вот этих вот скобок в
[01:39:26.840 --> 01:39:34.920]  каких-то может быть других степенях, правильно? Меньших, чем альфа ИТ. Так вот, мюфи Т это у нас
[01:39:34.920 --> 01:39:43.000]  будет произведение по И от 1 до К. Этих же самых скобок в каких-то других степенях бета ИТ,
[01:39:43.000 --> 01:39:51.720]  где давайте понимать, что мы знаем про бета ИТ. Бета ИТ, во-первых, не больше, чем альфа ИТ,
[01:39:51.720 --> 01:40:01.000]  чтобы мю делил Хи, правильно? Но с другой стороны, бета ИТ никак не меньше, чем единица. Это вот то
[01:40:01.000 --> 01:40:06.320]  самое утверждение, которое мы с вами только что доказали. Если эта скобка в какой-то степени здесь
[01:40:06.320 --> 01:40:14.520]  была, то она обязана быть и здесь, но, возможно, в меньшей степени, не нулевой. Вот такое важное
[01:40:14.520 --> 01:40:24.640]  утверждение мы с вами получили. Так, замечательно, мы с вами немножко поговорили про аннулирующие
[01:40:24.640 --> 01:40:34.600]  многочлены. Давайте мы сейчас увидим, что они достаточно сильно, что они еще сильнее, чем нам
[01:40:34.600 --> 01:40:46.960]  казалось раньше, влияют на то, как ведет себя наш оператор. Так, успеем мы это, не знаю, успеем ли
[01:40:46.960 --> 01:41:02.000]  доказать самую полезную теорему, но давайте к ней хотя бы будем стремиться. Давайте для начала докажем
[01:41:02.000 --> 01:41:10.160]  вот какое утверждение. Значит, пусть П и Ку.
[01:41:24.160 --> 01:41:25.520]  Одну минутку.
[01:41:32.000 --> 01:41:56.720]  Буквально одну минутку. Да, конечно. Пусть П и Ку это многочлены над нашим полем F, и они взаимно
[01:41:56.720 --> 01:42:18.320]  просты. Ну, то есть их нот равен единице. Ну и пусть Фи, это линейный оператор на каком-то
[01:42:18.320 --> 01:42:28.640]  пространстве В, естественно, над полем F. Тогда вот если эти многочлены взаимно просты, то внимание,
[01:42:28.640 --> 01:42:44.960]  ядра вот таких вот операторов П от Фи и Ку от Фи пересекаются только по нулю. То есть эти два
[01:42:44.960 --> 01:42:59.960]  ядра образуют прямую сумму. Доказательства, ну давайте мы вспомним, что означает, что нот двух
[01:42:59.960 --> 01:43:11.840]  многочленов равен единице. Мы с вами знаем, что если у нас есть нот двух многочленов, то мы его можем
[01:43:11.840 --> 01:43:20.040]  линейно выразить через эти многочлены, правильно? То есть мы можем написать, что это П на С плюс Ку на Т,
[01:43:20.040 --> 01:43:38.520]  где С и Т это какие-то многочлены над нашим полем. Ну и подставив Фи, мы теперь получаем,
[01:43:38.520 --> 01:43:49.120]  что единица есть, давайте я лучше переставлю наши многочлены, С от Фи П от Фи плюс Т от Фи Ку от Фи,
[01:43:49.120 --> 01:43:59.040]  разумеется, правильно? Здесь единица это уже, разумеется, тождественный оператор, правильно?
[01:43:59.040 --> 01:44:17.760]  Ну что у нас равенство в алгебре операторов. Ну а теперь пусть какой-то вектор В лежит и в ядре П от Фи и в ядре Ку от Фи.
[01:44:17.760 --> 01:44:37.800]  Тогда давайте мы применим вот этот оператор, тождественный к нашему вектору В. В левой части раз единица это тождественный оператор,
[01:44:37.800 --> 01:44:49.520]  то мы получим В. А здесь мы получим С от Фи П от Фи, применённый к В, плюс Т от Фи на Ку от Фи,
[01:44:49.520 --> 01:44:58.440]  применённый к В. Ну как и раньше, П от Фи, применённый к В, это уже ноль, потому что вылежит в ядре П от Фи.
[01:44:58.440 --> 01:45:14.520]  Значит здесь у нас получился ноль уже, правильно? В первом слагаемом. И во втором слагаемом у нас тоже получился ноль.
[01:45:14.520 --> 01:45:26.720]  И наше утверждение уже доказано. Ну и давайте я сформулирую следующую уже теорему. Если не успеем доказать,
[01:45:26.720 --> 01:45:37.280]  то докажем в следующий раз, а может даже и успеем. Не так её долго и доказывать.
[01:45:37.280 --> 01:45:59.360]  Итак, теорема. Вот там у нас по ИК были произвольные многочлены. Ну в частности вполне могло быть,
[01:45:59.360 --> 01:46:05.000]  что вот эти вот ядра просто тривиальные, правильные. Утверждение не очень интересное для таких ядер могло
[01:46:05.000 --> 01:46:15.000]  получиться. А вот теперь пойдёт уже интереснее. Ну там тоже интересно, да? Ядра-то могли быть не нулевыми.
[01:46:15.000 --> 01:46:26.360]  Итак, пусть Фи – это линейный оператор, П – это какой-то его аннулирующий многочлен. Мне не важно,
[01:46:26.360 --> 01:46:37.640]  минимальный он или нет. А ИП представляется в виде произведения двух многочленов, которые взаимно просты.
[01:46:37.640 --> 01:47:01.080]  Тогда у меня тут В представляется в виде прямой суммы следующих двух подпространств.
[01:47:07.640 --> 01:47:21.560]  Извините. Разумеется, если нот равен единице, то будет что-то не так. Разумеется, нот равен единице, они взаимно просты.
[01:47:21.560 --> 01:47:47.480]  Тогда В раскладывается в прямую сумму двух ядер, вот таких вот операторов, ну и естественно ВИТ, оба этих ВИТ инвариантны относительно Фи.
[01:47:47.480 --> 01:47:59.400]  Это будет у нас очевидно, но тем не менее. То есть, глядите, что у нас получается, если мы сейчас эту теорему докажем.
[01:47:59.400 --> 01:48:08.120]  Мы с вами взяли какой-то оператор Фи, взяли его аннулирующий многочлен, разложили его на два взаимно простых сомножителя.
[01:48:08.600 --> 01:48:16.920]  Тогда мы пространство В можем разложить в прямую сумму двух инвариантных. Это мы с вами видели уже очень здорово.
[01:48:16.920 --> 01:48:29.160]  Причем, глядите, что получается. Если я возьму, скажем, Фи ограничено ВИТ, то есть Пси первое от ограничения Фи на инвариантное подпространство ВИП,
[01:48:29.240 --> 01:48:36.120]  а Пси второе ограничение на инвариантное подпространство В второе, то что у нас будет?
[01:48:36.120 --> 01:48:43.400]  Мы видим, что если ПИТ от Фи подействует на ВИТ, на любой вектор ВИТ, то получится ноль.
[01:48:43.400 --> 01:48:49.000]  То есть, П первое от Пси первого, это будет уже нулевой оператор.
[01:48:49.000 --> 01:49:02.360]  Просто потому, что ПсиИТ это ограничение Фи на вот такое вот ядро, но и, естественно, П второе от Пси второго тоже будет ноль.
[01:49:02.360 --> 01:49:09.640]  То есть, мы с вами при помощи этой теории, мы что можем сделать?
[01:49:09.800 --> 01:49:14.840]  Мы можем вместо того, чтобы исследовать действия Фи на все пространство В,
[01:49:14.840 --> 01:49:24.440]  теперь изучать действия на два меньших подпространства, на которых у нас есть меньше аннулирующие многочлены,
[01:49:24.440 --> 01:49:28.840]  многочлены меньшей степени, правильно? И они должны быть устроены проще.
[01:49:28.840 --> 01:49:32.840]  Вот в этом прелесть этой теоремы.
[01:49:32.840 --> 01:49:36.840]  Давайте мы ее сейчас докажем.
[01:49:37.560 --> 01:49:50.040]  То, что ВИТ инвариантное, это, извините, не очевидно, а уже было доказано.
[01:49:50.040 --> 01:49:57.560]  Мы с вами доказывали, что если есть два коммутирующих многочлена, Фи и Пси, то ядро Пси инвариантное относительно Фи.
[01:49:57.560 --> 01:50:01.560]  Здесь у нас Фи коммутирует с ПИТом от Фи, правильно?
[01:50:02.280 --> 01:50:06.280]  И поэтому ядро вот этого ПИТого от Фи является инвариантным относительно Фи.
[01:50:06.280 --> 01:50:10.280]  Это, конечно же, понятно.
[01:50:10.280 --> 01:50:20.280]  Более того, по нашему утверждению, которое мы уже доказали,
[01:50:20.280 --> 01:50:30.280]  сумма В1 и В2 является прямой суммой.
[01:50:31.000 --> 01:50:35.000]  Значит, нам осталось доказать, что эта сумма совпадает со всем В.
[01:50:35.000 --> 01:50:41.000]  А для этого давайте мы опять запишем
[01:50:47.000 --> 01:50:53.000]  представление нода П1 и П2, линейное представление вот этого нода.
[01:50:53.720 --> 01:51:15.720]  И применим вот этот оператор теперь к произвольному вектору из нашего В.
[01:51:15.720 --> 01:51:21.720]  Если В это элемент нашего пространства,
[01:51:22.440 --> 01:51:26.440]  то применяя вот это вот самое равенство,
[01:51:26.440 --> 01:51:32.440]  получаем вот что.
[01:51:32.440 --> 01:51:38.440]  Что В есть П1.
[01:51:38.440 --> 01:51:44.440]  А, применяем, потому что не это равенство, а равенство с подставленным ФИ, разумеется, правильно?
[01:51:44.440 --> 01:51:48.440]  То есть мы, как и раньше, подставляем в это равенство Фи,
[01:51:49.160 --> 01:51:53.160]  получаем здесь тождественный оператор.
[01:51:53.160 --> 01:51:59.160]  Даже вот здесь я могу написать от ФИ, от ФИ, от ФИ и от ФИ.
[01:51:59.160 --> 01:52:13.160]  Вот теперь подставляем В, получаем вот это вот плюс П2 от ФИ на Т от ФИ от В.
[01:52:13.880 --> 01:52:17.880]  Давайте я обозначу эти векторы через В1 и В2.
[01:52:17.880 --> 01:52:19.880]  Что я утверждаю?
[01:52:19.880 --> 01:52:35.880]  Я утверждаю, что если применить П2 от ФИ к В1, то что у меня получится?
[01:52:36.600 --> 01:52:44.600]  П2 от ФИ, П1 от ФИ, С от ФИ от В, правда?
[01:52:44.600 --> 01:52:48.600]  Здесь у меня написано не что иное, как П от ФИ.
[01:52:48.600 --> 01:52:52.600]  А П от ФИ это нулевой многочлен.
[01:52:52.600 --> 01:52:56.600]  То есть нулевой оператор, извините, потому что П был аннулирующим многочленом.
[01:52:56.600 --> 01:53:00.600]  Значит, здесь у меня написано не что иное, как ноль.
[01:53:01.320 --> 01:53:09.320]  То есть В1 лежит в ядре П2 от ФИ, то есть В2.
[01:53:09.320 --> 01:53:13.320]  Извините за такую путаницу в обозначениях.
[01:53:13.320 --> 01:53:23.320]  Аналогично В2 лежит в В1.
[01:53:23.320 --> 01:53:27.320]  Итак, что мы с вами доказали?
[01:53:28.040 --> 01:53:36.040]  Мы с вами доказали, что произвольный вектор из нашего пространства В лежит в прямой сумме В1 и В2.
[01:53:36.040 --> 01:53:38.040]  Сумма прямая, это мы доказали.
[01:53:38.040 --> 01:53:44.040]  Каждый вектор там лежит, потому что вот мы его разложили в сумму двух векторов оттуда.
[01:53:44.040 --> 01:53:50.040]  Значит, В1 в прямой сумме с В2 дает В.
[01:53:50.760 --> 01:53:56.760]  Наши утверждения уже доказаны.
[01:54:04.760 --> 01:54:12.760]  Давайте я закончу сегодняшнюю лекцию.
[01:54:20.760 --> 01:54:26.760]  Давайте я оставлю следующее упражнение.
[01:54:32.760 --> 01:54:46.760]  Мы с вами в этой теореме охарактеризовали В и Т как ядра П и Т от ФИ.
[01:54:47.480 --> 01:54:51.480]  На самом деле можно их охарактеризовать и по-другому.
[01:54:51.480 --> 01:54:59.480]  В1 это не только ядро П1 от ФИ, но еще и образ П2 от ФИ.
[01:55:03.480 --> 01:55:09.480]  В2 это будет образ П1 от ФИ.
[01:55:10.200 --> 01:55:14.200]  В качестве подсказки я хочу сразу сказать.
[01:55:14.200 --> 01:55:16.200]  Посмотрите сюда.
[01:55:16.200 --> 01:55:22.200]  Когда мы раскладывали произвольный вектор В по векторам из В2 и В1,
[01:55:22.200 --> 01:55:28.200]  вот этот вектор, который мы получили, лежит в образе П1 от ФИ.
[01:55:28.200 --> 01:55:32.200]  Потому что это П1 от ФИ, примененный к чему-то еще.
[01:55:32.200 --> 01:55:36.200]  А вот этот вектор лежит в образе П2 от ФИ.
[01:55:36.920 --> 01:55:42.920]  Если на это грамотно посмотреть, то это упражнение сразу получается.
[01:55:46.920 --> 01:55:50.920]  Давайте я сформулирую следствие.
[01:55:50.920 --> 01:55:54.920]  А докажем его уже в следующий раз, потому что сейчас звонок произведет.
[01:55:54.920 --> 01:56:00.920]  То же самое верно разумеется и для разложения на несколько совножителей,
[01:56:01.640 --> 01:56:05.640]  если П в тех же самых условиях.
[01:56:05.640 --> 01:56:11.640]  ФИ это линейный оператор, П его аннулирующий многочлен.
[01:56:11.640 --> 01:56:17.640]  Если П раскладывается в произведении нескольких многочленов,
[01:56:17.640 --> 01:56:25.640]  причем нот ПИ и ПЖ это единица при I не равном G,
[01:56:25.640 --> 01:56:29.640]  то есть если эти многочлены попарно взаимно просты,
[01:56:30.360 --> 01:56:40.360]  то тогда пространство раскладывается в прямую сумму ядер соответствующих многочленов.
[01:56:40.360 --> 01:56:48.360]  То есть ядро П1 от ФИ, прямая сумма ядро П2 от ФИ,
[01:56:50.360 --> 01:56:56.360]  прямая сумма и так далее, ядро ПК от ФИ.
[01:56:57.080 --> 01:57:01.080]  Ну и давайте уж я заодно наполню или введу обозначение.
[01:57:01.080 --> 01:57:07.080]  Вот такая вещь кратко обозначается вот таким вот образом.
[01:57:09.080 --> 01:57:11.080]  Следствие докажем в следующий раз.
[01:57:11.080 --> 01:57:15.080]  Здесь еще нужно один небольшой шажок сделать, поэтому нельзя сказать,
[01:57:15.080 --> 01:57:17.080]  что оно сразу очевидно.
[01:57:17.080 --> 01:57:19.080]  А на сегодня все, если есть вопросы задавайте.
[01:57:26.360 --> 01:57:29.080]  Спасибо за внимание.
