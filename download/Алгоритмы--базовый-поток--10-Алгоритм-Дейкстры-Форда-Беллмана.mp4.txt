[00:00.000 --> 00:12.000]  Добрый день, давайте начинать сегодня по плану продолжения плана предыдущей лекции.
[00:12.000 --> 00:20.000]  Мы продолжаем говорить про полезную информацию на графах, то есть так называемые взвешенные графы,
[00:20.000 --> 00:26.000]  графы, на которых на ребрах написаны какие-то чиселки, которые что-то значат.
[00:26.000 --> 00:31.000]  В прошлый раз мы рассматривали задачу поиска минимального основного дерева,
[00:31.000 --> 00:36.000]  то есть такого дерева, такого основного под графа, который, во-первых, является деревом,
[00:36.000 --> 00:43.000]  который, во-вторых, соответственно, имеет минимальный возможный вес для всех таких деревьев.
[00:43.000 --> 00:48.000]  Сегодня мы рассмотрим, наверное, самую очевидную задачу, которую можно поставить на графах,
[00:48.000 --> 00:55.000]  это поиск кратчайшего пути в графе. Мы уже решали эту задачу методом обхода в ширину.
[00:55.000 --> 01:01.000]  То есть у нас был граф, при этом граф был невзвешенный, и, соответственно, мы в нем искали
[01:01.000 --> 01:05.000]  минимальные реберные расстояния, то есть как-то идти от одной вершины до второй,
[01:05.000 --> 01:08.000]  при этом потратив минимальное количество шагов по ребрам.
[01:08.000 --> 01:13.000]  Ну и у нас там были какие-то приколы, связанные с тем, что эту задачу можно решать,
[01:13.000 --> 01:19.000]  если у нас, соответственно, ребра имеют какую-то целую длину, соответственно, ограниченную как-то сверху.
[01:19.000 --> 01:22.000]  То есть, соответственно, можно на этом что-то придумать.
[01:22.000 --> 01:28.000]  При этом у нас асимптотика сильно зависела от максимального веса ребра.
[01:28.000 --> 01:34.000]  Сейчас мы решим эту задачу без всякого предположения, что у нас ребра какие-то целые
[01:34.000 --> 01:37.000]  или, скажем, ребра имеют какую-то ограниченную длину.
[01:37.000 --> 01:41.000]  В самом общем случае постараемся решить задачу поиск кратчайшего пути.
[01:41.000 --> 01:43.000]  Ну давайте начнем.
[01:43.000 --> 01:46.000]  В общем, задача, на самом деле, постановка задачи очень простая.
[01:46.000 --> 01:51.000]  Дан некоторый граф, ориентированный или не ориентированный, неважно, на котором задана весовая пункция.
[01:51.000 --> 01:58.000]  Давайте пока считать, что весовая пункция устроена так, что она отображает ребра в некоторые неотрицательные чиселки.
[01:58.000 --> 02:01.000]  Давайте пока предполагать, что у меня на ребрах написаны неотрицательные числа.
[02:01.000 --> 02:03.000]  Позже мы это ограничение снимем.
[02:03.000 --> 02:08.000]  Ну просто если мы допускаем наличие отрицательных ребр, там возникают какие-то проблемы, о которых мы поговорим.
[02:08.000 --> 02:13.000]  Пока давайте не задуматься об этом, просто у нас на ребрах написаны неотрицательные числа.
[02:13.000 --> 02:19.000]  Соответственно, есть некоторая выделенная вершина, из которой мы хотим найти кратчайшие пути.
[02:19.000 --> 02:23.000]  Такая задача обычно называется single-source задачей, задачей одного источника.
[02:23.000 --> 02:29.000]  То есть у вас есть некоторая выделенная вершина, из которой вы хотите найти пути до всех остальных.
[02:29.000 --> 02:31.000]  Что значит найти кратчайший путь?
[02:32.000 --> 02:39.000]  Нужно построить такую функцию, которая для любого V находит минимальный путь.
[02:39.000 --> 02:45.000]  Вес пути считается как сумма ребер, которые лежат на этом пути.
[02:45.000 --> 02:48.000]  Думаю, все понятно.
[02:48.000 --> 02:54.000]  Давайте с коду рассмотрим первый алгоритм, как можно такую задачу решать.
[02:54.000 --> 02:58.000]  Первый алгоритм — это алгоритм Dx.
[02:58.000 --> 03:08.000]  Сразу откажу, что алгоритм Dx очень похож на алгоритм Prima, который мы рассматривали в прошлый раз.
[03:08.000 --> 03:10.000]  В чем идея?
[03:10.000 --> 03:13.000]  Давайте задачу будем решать итеративно.
[03:13.000 --> 03:17.000]  А если быть точнее, то скажем таким динамическим алгоритмом.
[03:17.000 --> 03:21.000]  Давайте скажем так, что у нас есть некоторое множество вершин S.
[03:21.000 --> 03:31.000]  Постановка задачи. У нас есть какая-то вершина, фиксированная.
[03:31.000 --> 03:35.000]  Нам нужно из нее найти кратчайшие пути до всех остальных вершин.
[03:35.000 --> 03:44.000]  Из нуля можно добраться до пятерки за 7 шагов.
[03:44.000 --> 03:51.000]  А можно предъявить сам путь в виде самих ребер или вершин, которые мы посещаем.
[03:51.000 --> 03:53.000]  В зависимости от установки задачи.
[03:53.000 --> 03:58.000]  Алгоритм Dx. Как устроена алгоритм Dx?
[03:58.000 --> 04:00.000]  Алгоритм Dx установлено очень просто.
[04:00.000 --> 04:08.000]  Предположим, что у нас есть некоторое множество вершин S, до которых мы знаем кратчайшее расстояние.
[04:08.000 --> 04:17.000]  Вот, естественно, где-то есть вершин S, и соответственно, есть вершины, до которых мы точно знаем кратчайшее расстояние.
[04:17.000 --> 04:19.000]  Что мы будем делать?
[04:19.000 --> 04:27.000]  На каждой итерации, и плюс, у нас есть какие-то другие вершины, до которых мы знаем следующую характеристику.
[04:27.000 --> 04:32.000]  Пусть это вершина V, и для каждой такой вершины V мы знаем следующую штуку.
[04:32.000 --> 05:01.000]  Мы знаем кратчайший путь из S в, который проходит только по вершинам из множества S.
[05:01.000 --> 05:05.000]  Для каждой вершины, вне этого множества, мы знаем следующую штуку.
[05:05.000 --> 05:09.000]  У меня есть вершина S, и я знаю такую вещь.
[05:09.000 --> 05:15.000]  Я знаю, как кратчайшим образом добраться до вершины V, при этом используя только вершины вот отсюда.
[05:15.000 --> 05:20.000]  Допустим, у меня есть такая картина.
[05:20.000 --> 05:23.000]  Что утверждает алгоритм Dx?
[05:23.000 --> 05:34.000]  Если у меня есть такая картина, то, соответственно, если я среди всех таких вершин V1, V2, V3, V4, V5 возьму наименьшую,
[05:34.000 --> 05:44.000]  то есть я возьму V со звездой равная аргмин D от V, где V не принадлежит множеству S,
[05:44.000 --> 05:52.000]  то тогда D от V со звездой будет точно совпадать с истинным кратчайшим расстоянием
[05:52.000 --> 05:54.000]  от вершины S до вершины V со звездой.
[05:54.000 --> 05:57.000]  То есть алгоритм очень простой.
[05:57.000 --> 06:00.000]  У меня есть некоторое множество вершин, да которых я нашел кратчайшее расстояние,
[06:00.000 --> 06:03.000]  соответственно, у меня есть множество вершин, до которых я знаю кратчайшее расстояние,
[06:03.000 --> 06:06.000]  но с всем ограничением, что я мою проходить только по этому множеству.
[06:06.000 --> 06:10.000]  Дальше, соответственно, по каждой и Foiter Deck буду выбирать вершину с наименьшим весом
[06:10.000 --> 06:16.400]  с наименьшим весом, и добавлять ее в множество s, ну и так далее. Согласен, что это очень похоже на алгоритм Прима, да?
[06:16.400 --> 06:24.400]  То есть мы в нем тоже, собственно, у нас было некоторое множество, то есть мы строили разрез, у нас были в одном разрезе вершины, и ребра, которые торчали в остальные.
[06:24.400 --> 06:31.000]  Мы среди всех этих ребер выбирали минимальное, добавляли в множество, ну и так далее. Здесь, по сути, то же самое, только вместо длины ребер мы используем длину пути.
[06:31.000 --> 06:33.000]  Окей? Окей.
[06:34.800 --> 06:40.080]  Да, будем поддерживать массив d от v, которых они к длину кратчайшего пути, проходящего только по вершинам из s.
[06:41.040 --> 06:43.600]  Ну, соответственно, можно, давайте приведем пример, чтобы
[06:44.880 --> 06:50.160]  точно все понимали. Ну, давайте вот для этого графа построим массив d.
[06:55.240 --> 06:57.240]  Вершины до 5.
[07:01.000 --> 07:03.000]  4, 5.
[07:06.320 --> 07:11.200]  Давайте считать, что мы ищем кратчайший путь из вершины 0. d от нуля чему равно?
[07:12.440 --> 07:18.040]  Ну, очевидно, 0, да? Почему? Потому что кратчайший путь из вершины в нее саму, ну, он очевидно, равен 0.
[07:18.720 --> 07:20.720]  Чему равен d от единицы?
[07:20.720 --> 07:22.720]  d от единицы.
[07:28.680 --> 07:33.080]  Еще раз, что такое d? d от v, d от вершины, это длина кратчайшего пути
[07:33.600 --> 07:38.720]  из старта вершины, ну мы считаем, что старта вершины у нас 0, которая проходит только по вершинам из s.
[07:39.960 --> 07:45.600]  Ну, то есть, давайте, ну, тут мы будем использовать, ну, мы будем использовать, ну, мы будем использовать,
[07:46.000 --> 07:48.000]  которую проходит только по вершинам из s.
[07:49.320 --> 07:54.720]  Ну, ты, давайте, ну, тут, может, не совсем корректно, но в качестве промежуточных вершин можно использовать только вершины из s.
[07:54.720 --> 07:58.120]  Понятно дело, что, когда мы выходим из этого нож, то мы можем как бы ребра использовать.
[08:00.760 --> 08:04.840]  6, нет, смотрите, 6, действительно, смотрите, какие, давайте просто наблюдаем по смотрке, у нас пути есть в единицу.
[08:05.400 --> 08:12.480]  Ну, понятное дело, что есть короткий путь, который идет вот так 2, 2, 1, да, то есть, 5, но тут в качестве промежуточной используется вершина номер 4,
[08:12.480 --> 08:16.280]  4, то есть она не подходит, то есть путь через эту вершину проходить не может,
[08:16.280 --> 08:23.160]  окей, значит есть путь 2, 2, 3, да, то есть длины 7, но есть путь 3, 3, вот, то есть тут в качестве
[08:23.160 --> 08:26.800]  промежуточных используется только вершины из самого множества s, и это самый кратчайший путь
[08:26.800 --> 08:40.320]  среди всех таких, согласны? То есть 6, окей, ну для двойки, соответственно, 3, а для тройки 2,
[08:40.320 --> 08:54.320]  до четверки, до четверки 4, да, наконец 5, да, от пятерки до бесконечности, то есть не надо стесняться,
[08:54.320 --> 08:57.640]  то есть все, действительно, то есть если мы из старта до вершины не можем добраться до вершины,
[08:57.640 --> 09:01.600]  проходясь только по вершинам из этого множества, ну, используя их в качестве промежуточных, то
[09:01.600 --> 09:05.080]  соответственно считаем, что расстояние до вот этой вершины равно бесконечности, ну,
[09:05.080 --> 09:07.320]  действительно, у меня вообще в принципе не существуют пути из нуля до пятерки,
[09:07.320 --> 09:13.680]  которые бы не затрагивал вот эти вот вершины, согласны? То есть я не могу напрямую из этого множества
[09:13.680 --> 09:20.160]  попасть в вершину 5, вот, поэтому дай от пятерки равно бесконечности, ну, вот, да, ну, если, конечно,
[09:20.160 --> 09:24.040]  что говорит алгоритм Dx, алгоритм Dx мне говорит, ну, смотрите, у меня тут, то есть я предполагаю,
[09:24.040 --> 09:30.040]  что для вершины 0, 2 и 3 я уже нашел корректные кратчайшие пути, соответственно, алгоритм Dx
[09:30.040 --> 09:34.320]  мне говорит следующее, что я среди оставшихся вершин, то есть, среди вот этой wearing, вот этой,
[09:34.320 --> 09:38.400]  вот этой, вichtig, выбрать вершину, до которой, до которой расстояние минимально, но это соответственно
[09:38.400 --> 09:45.520]  эта вершина, 4, соответственно, вершина 4, кратчайший путь раменно 4, соответственно мы четверку
[09:45.520 --> 09:55.000]  добавим во множество s, обновим расстояние вот этих вершин, и соответственно мы продолжим алгоритм, понятно?
[09:55.000 --> 10:00.240]  В общем, алгоритм D extra, если коротко, выглядит так.
[10:00.240 --> 10:03.120]  Ну, инициализация понятна. Как чему равно изначально множество s?
[10:03.120 --> 10:05.280]  До каких вершин мы, гарантированно, знаем путь?
[10:05.280 --> 10:08.280]  У нас есть только одна такая вершина, и это вершина s. Согласны?
[10:08.280 --> 10:11.080]  То есть до вершины s мы, гарантированно, знаем путь, и он равен нулю.
[10:11.080 --> 10:14.560]  Все, то есть изначально инициализируем множество s с одной вершинкой s маленькая.
[10:14.560 --> 10:19.080]  Ну а для всех остальных вершин инициализируем вот этот массив d. Каким образом?
[10:19.080 --> 10:23.000]  Просто-напросто длиной ребра из s до b. Согласны?
[10:23.960 --> 10:30.120]  Ну потому что чему равна длина пути из вершины s, из множества s,
[10:30.120 --> 10:32.960]  которая состоит из одной вершины, до всех остальных вершин,
[10:32.960 --> 10:35.080]  если можно двигаться только внутри вот этого множества?
[10:35.080 --> 10:38.520]  Ну понятно, дело в том, что совпадает длина ребра из вот этой вершины до остальных.
[10:38.520 --> 10:42.040]  Соответственно, если этого ребра нет, то считаем, что расстояние равно бесконечности.
[10:42.040 --> 10:43.040]  Окей?
[10:43.040 --> 10:51.560]  Ну дальше, собственно, как я сказал, мы из среди этого вот этой массива ищем аргумент
[10:51.560 --> 10:54.920]  по всем вершинам, которые не лежат в нашем множестве s,
[10:54.920 --> 10:57.840]  вот добавляем найденную вершину вам множество s.
[10:57.840 --> 11:03.840]  Дальше обновляем расстояние d а с, в, то есть так, как мы добавили в нашем множество s новую вершину,
[11:03.840 --> 11:08.160]  если мы эту вершину добавили во множество s, то соответственно, у нас из этой вершины
[11:08.160 --> 11:11.600]  может быть торчат ещё какие-то ребра до этих вершин.
[11:11.600 --> 11:14.020]  Соответственно мы можем до этих вершин обновить расстояние. Согласны?
[11:14.020 --> 11:18.520]  Вот. Соответственно вот, для остальных вершин обновляем расстояние как минимум из текущего расстояния
[11:18.520 --> 11:23.520]  и d от u плюс w, u, v. Понятно, почему такая формула.
[11:23.520 --> 11:27.520]  Ну, d от u — это, соответственно, истинное найденное расстояние до вершины u.
[11:27.520 --> 11:32.520]  Давайте, вот тут вот. Нарешу эту вершину u.
[11:32.520 --> 11:36.520]  Вот, до вершины u мы знаем уже точно кратчайшее расстояние. Вот оно, d от u.
[11:36.520 --> 11:39.520]  И плюс, возможно, до остальных вершин, до остальных вершин.
[11:39.520 --> 11:43.520]  Вот до этой вершины, до этой, до этой мы смогли обновить кратчайший путь.
[11:43.520 --> 11:49.520]  Мы говорим, что это расстояние до вершины u плюс одно ребро из вершины u в вершину v.
[11:49.520 --> 11:53.520]  Соответственно, если этот путь новый оказался короче, чем старый путь для вершины v,
[11:53.520 --> 11:56.520]  то мы его обновляем. Понятно, да?
[11:56.520 --> 12:00.520]  Ну, то есть банальное просто обновление путей для остальных вершин.
[12:00.520 --> 12:07.520]  То есть мы предполагаем, что из вершины u мы теоретически можем как-то обновить расстояние до других вершин.
[12:07.520 --> 12:10.520]  То есть если смогли обновить, то обновили, если не смогли, то не обновили.
[12:10.520 --> 12:14.520]  Вот. Ну и все, по сути. Повторяем все пункты 1, 2, 3.
[12:14.520 --> 12:17.520]  То есть продолжаем искать r минимум, добавляем в множество s и так далее.
[12:17.520 --> 12:20.520]  Пока, соответственно, не перенесем все вершины в множество s.
[12:20.520 --> 12:26.520]  То есть как только у нас множество s станет равно t ум в множество вершин, значит, что мы закончили алгоритм.
[12:26.520 --> 12:30.520]  Ну, то есть множество s, по сути, по определению множества вершин, до которых мы знаем точно корректный путь.
[12:30.520 --> 12:33.520]  Понятно? Отлично.
[12:33.520 --> 12:37.520]  Так, ну давайте посмотрим на какой-нибудь пример.
[12:41.520 --> 12:48.520]  Ну давайте будем формировать множество s и массив d.
[13:01.520 --> 13:05.520]  Так. Ну изначально в множестве s у нас стоит вершина 0.
[13:05.520 --> 13:08.520]  Только вершина 0. Вот.
[13:08.520 --> 13:10.520]  Ну и чему у нас будет равен массив d?
[13:10.520 --> 13:13.520]  Значит, расстояние до вершины 0 очевидно равно 0.
[13:13.520 --> 13:16.520]  Расстояние до вершины 3 равно 2.
[13:16.520 --> 13:18.520]  До вершины 4 равно 6.
[13:18.520 --> 13:21.520]  До вершины 7 равно 5.
[13:21.520 --> 13:23.520]  Да?
[13:23.520 --> 13:27.520]  2, 6, 7, 5.
[13:27.520 --> 13:31.520]  Остальные расстояния равны бесконечности.
[13:31.520 --> 13:33.520]  Вот.
[13:33.520 --> 13:36.520]  Окей, ну начинаем. Смотрим на этот нож.
[13:36.520 --> 13:38.520]  Давайте помечать, что вот так вот.
[13:38.520 --> 13:41.520]  Пометим, что эта вершина уже лежит во множестве s.
[13:41.520 --> 13:46.520]  Значит, смотрим на этот массив и ищем в нем, соответственно, минимум.
[13:46.520 --> 13:50.520]  Минимум равен тройке, поэтому тройку мы добавляем во множество,
[13:50.520 --> 13:53.520]  до которых мы нашли корректное расстояние.
[13:53.520 --> 13:56.520]  Теперь, соответственно, так как тройка лежит в нашем множестве s,
[13:56.520 --> 13:59.520]  то есть теперь в нашем множестве s состоит вот из этих вершин.
[13:59.520 --> 14:01.520]  Понятно, да?
[14:01.520 --> 14:05.520]  Соответственно, все возможные пути, которые проходят через ноль, мы рассмотрели.
[14:05.520 --> 14:08.520]  Теперь давайте обновим расстояние до остальных вершин с помощью тройки.
[14:08.520 --> 14:10.520]  Ну, это по порядку.
[14:10.520 --> 14:12.520]  Из тройки ведет ребро в четверку.
[14:12.520 --> 14:14.520]  Соответственно, до тройки расстояние 2.
[14:14.520 --> 14:19.520]  Соответственно, путь из тройки до четверки, точнее, из нуля до четверки будет равен 2 плюс 3.
[14:19.520 --> 14:21.520]  То есть 5.
[14:21.520 --> 14:23.520]  То есть обновляем.
[14:23.520 --> 14:25.520]  Смогли обновить.
[14:25.520 --> 14:28.520]  Идем дальше. Из тройки есть еще ребро в шестерку.
[14:28.520 --> 14:31.520]  До тройки расстояние 2 мы видим.
[14:31.520 --> 14:35.520]  И в шестерку еще есть ребро длиной 1.
[14:35.520 --> 14:38.520]  То есть путь до шестерки равен 3.
[14:38.520 --> 14:40.520]  Ну, соответственно, бесконечность больше, чем 3.
[14:40.520 --> 14:42.520]  Обновляем.
[14:42.520 --> 14:44.520]  Ну, и наконец, до семерки.
[14:44.520 --> 14:46.520]  Значит, до тройки расстояние 2 плюс ребро 3.
[14:46.520 --> 14:48.520]  Соответственно, до семерки расстояние 5.
[14:48.520 --> 14:51.520]  Значит, было тоже 5, поэтому до семерки расстояние не обновилось.
[14:51.520 --> 14:53.520]  Вот. Окей.
[14:53.520 --> 14:55.520]  Следующая итерация.
[14:55.520 --> 14:57.520]  Снова смотрим на наш массив.
[14:57.520 --> 14:59.520]  И еще у него минимум.
[14:59.520 --> 15:01.520]  6.
[15:01.520 --> 15:03.520]  Это шестая вершина.
[15:03.520 --> 15:05.520]  Поэтому добавляем шестерку в множество s.
[15:05.520 --> 15:07.520]  И говорим, что до нее мы нашли корректное расстояние.
[15:07.520 --> 15:09.520]  Ну, окей. То же самое.
[15:09.520 --> 15:11.520]  Смотрим ребра, которые торчат из шестерки.
[15:11.520 --> 15:13.520]  И пытаемся обновить расстояние до остальных вершин.
[15:13.520 --> 15:15.520]  Смотрим ребро 1 ведет в вершину номер 2.
[15:15.520 --> 15:17.520]  То есть до шестерки расстояние 3.
[15:17.520 --> 15:19.520]  Еще плюс 1. То есть 4.
[15:19.520 --> 15:21.520]  Вот.
[15:21.520 --> 15:23.520]  Обновляем бесконечность до 4.
[15:29.520 --> 15:31.520]  Окей.
[15:31.520 --> 15:33.520]  И шестерка еще и с ребровой в пятерку.
[15:33.520 --> 15:35.520]  На пятерке было расстояние бесконечность.
[15:35.520 --> 15:37.520]  То есть до шестерки расстояние 3.
[15:37.520 --> 15:39.520]  Плюс 4. 7.
[15:39.520 --> 15:41.520]  Обновляем.
[15:41.520 --> 15:43.520]  Ставим семерку.
[15:43.520 --> 15:45.520]  Все.
[15:45.520 --> 15:47.520]  Кажется. Да.
[15:47.520 --> 15:49.520]  Ну, снова смотрим на наш массив.
[15:49.520 --> 15:51.520]  Ищем минимальное значение,
[15:51.520 --> 15:53.520]  которого нет во множестве s.
[15:53.520 --> 15:55.520]  Ну, соответственно, это значение вот это.
[15:55.520 --> 15:57.520]  То есть добавляем двойку.
[15:57.520 --> 15:59.520]  До двойки мы уже нашли корректный путь.
[15:59.520 --> 16:01.520]  Где у нас двойка? Вот она.
[16:01.520 --> 16:03.520]  Ну, с помощью ребра обновляем расстояние до семерки.
[16:03.520 --> 16:05.520]  До двойки у нас длина пути 4.
[16:05.520 --> 16:07.520]  Плюс 1. 5.
[16:07.520 --> 16:09.520]  Ну, до семерки снова расстояние 5.
[16:09.520 --> 16:11.520]  Мы ничего не обновили.
[16:11.520 --> 16:13.520]  На этом завершаем работу.
[16:13.520 --> 16:15.520]  Следующая итерация. Снова выбираем минимальное значение.
[16:15.520 --> 16:17.520]  Тут уже не важно.
[16:17.520 --> 16:19.520]  Давайте выберем четверку.
[16:19.520 --> 16:21.520]  Добавляем ее в множество s.
[16:21.520 --> 16:23.520]  Из четверки у нас...
[16:23.520 --> 16:25.520]  Из четверки у нас ребер нет.
[16:25.520 --> 16:27.520]  Из четверки у нас ребер нет.
[16:27.520 --> 16:29.520]  Поэтому, соответственно, обновлять нечего.
[16:29.520 --> 16:31.520]  Завершаем работу.
[16:31.520 --> 16:33.520]  Следующая итерация.
[16:33.520 --> 16:35.520]  Берем семерку.
[16:35.520 --> 16:37.520]  Добавляем во множество s.
[16:37.520 --> 16:39.520]  Из семерки пытаемся обновить расстояние до остальных вершин.
[16:39.520 --> 16:41.520]  Расстояние до шестерки...
[16:41.520 --> 16:43.520]  Ну, в принципе, до шестерки не имеет смысла проверять.
[16:43.520 --> 16:45.520]  Потому что до шестерки уже нашли корочеше расстояние.
[16:45.520 --> 16:47.520]  Ну, в принципе, все.
[16:47.520 --> 16:49.520]  Из семерки больше никаких ребер нет.
[16:49.520 --> 16:51.520]  Поэтому завершаем.
[16:51.520 --> 16:53.520]  Ну, и последняя вершина, которую мы достаем, это пятерка.
[16:53.520 --> 16:55.520]  За Collect, а на этом завершаем работу...
[16:55.520 --> 16:57.520]  И на этом завершаем работу алгоритма.
[16:59.520 --> 17:01.520]  Да, не завершаем.
[17:01.520 --> 17:03.520]  В смысле, у нас есть еще форм数 следующий итерация,
[17:03.520 --> 17:05.520]  на который мы достаем единицу.
[17:05.520 --> 17:07.520]  Соответственно, единицу добавляем.
[17:07.520 --> 17:09.520]  С расстоянию никого нет.
[17:09.520 --> 17:11.520]  Здесь растояние равно бесконечно,
[17:11.520 --> 17:13.520]  из нуля до единицы добраться невозможно.
[17:15.520 --> 17:17.520]  Соответственно, утверждается...
[17:17.520 --> 17:19.520]  Пока니다 доказано, но я утверждаю,
[17:19.520 --> 17:21.520]  что данный массив,
[17:21.520 --> 17:27.520]  то данный массив будет содержать всегда корректные расстояния до всех вершин из вершины 0.
[17:27.520 --> 17:28.520]  То есть, я утверждаю, что
[17:34.520 --> 17:36.520]  кратчайшем пути из s до v.
[17:37.520 --> 17:39.520]  Остались вопросы?
[17:41.520 --> 17:44.520]  Ну и доказательства корректности. Почему на самом деле вот этот массив,
[17:44.520 --> 17:49.520]  почему этот алгоритм приводит нас к корректному результату?
[17:50.520 --> 17:54.520]  Теорема проста. Если ребрографы не отрицательны, то по завершению работы алгоритма
[17:54.520 --> 18:02.520]  все элементы массива D точно совпадают с длиной кратчайшего пути из вершины s до вершины v.
[18:03.520 --> 18:05.520]  Ну давайте доказывать.
[18:05.520 --> 18:07.520]  Ну докажем по индукции.
[18:11.520 --> 18:13.520]  Ну база индукции простая.
[18:14.520 --> 18:19.520]  База изначально во множестве s у меня содержится только вершины s.
[18:20.520 --> 18:27.520]  Ну и соответственно, что я знаю? Я знаю, что D от s равно 0, но это в точности совпадает с process.
[18:27.520 --> 18:31.520]  То есть изначально во множестве s у меня до всех вершин найдено расстояние корректно.
[18:32.520 --> 18:34.520]  Теперь переход.
[18:35.520 --> 18:43.520]  Переход. Пусть для любой вершины v из s верно, что D от v равно process v.
[18:44.520 --> 18:49.520]  То есть пусть для любой вершины из множества s большого, то есть для любой вершины v
[18:49.520 --> 18:54.520]  из s верно, что D от v равно process v.
[18:55.520 --> 18:59.520]  То есть пусть для любой вершины из множества s большого у меня верно все кратчайшие стояния.
[19:00.520 --> 19:14.520]  Ну и обозначим за u argmin od от x по всем x, не принадлежащим s большого.
[19:15.520 --> 19:17.520]  То есть на очередную итерацию достаем вершину u.
[19:17.520 --> 19:19.520]  Теперь докажем, что нам нужно доказать.
[19:19.520 --> 19:22.520]  Нам нужно доказать, что до этой вершины у нас расстояние найдено корректно.
[19:23.520 --> 19:27.520]  То есть мы предполагаем, что во множестве s у都 всех вершин найдено корректно.
[19:28.520 --> 19:30.520]  Давайте теперь предположим, что для вершин вы millenn剛я, великое introdu�� Wort권ка.
[19:31.520 --> 19:32.520]  Мы тоже нашли на расстоянии коррект ReadyC menstrual per cognizant.
[19:33.520 --> 19:35.520]  То есть мы эту вершину можно raw fol Raw flay hpleel.
[19:36.520 --> 19:38.520]  gravy о exile
[19:39.520 --> 19:42.520]  Ну давайте, собственно, смотреть, что здесь.
[19:43.520 --> 19:46.520]  Давайте изобразим вот такую картину.
[19:46.520 --> 19:54.400]  есть вершина С, есть вершина У. Давайте рассмотрим истинный кратчайший путь
[19:54.400 --> 20:04.520]  из вершины С до вершины У. Вот он выглядит как-то так. То есть мы идем-идем, тут вершина Х, дальше
[20:04.520 --> 20:09.600]  ребро XY, ну и дальше соответственно каким-то образом, ну не важно, может как-то вот так,
[20:09.600 --> 20:14.440]  ну в общем случае, как-то вот так находим, доходим до вершины У. Вот пусть это истинный
[20:14.440 --> 20:25.760]  кратчайший путь до вершины У. Давайте пропишем. Пусть кратчайший путь из С до У
[20:25.760 --> 20:46.240]  пересекает разрез С В без С по ребру, по ребру XY. Так, ну давайте рассуждать,
[20:46.240 --> 20:56.120]  давайте, давайте рассуждать, что у нас, что мы знаем? Мы знаем, что,
[20:56.120 --> 21:23.480]  так, ну давайте так скажем, что у нас D от, что у нас РОСY, так, нет, секунду,
[21:27.120 --> 21:38.280]  так, во-первых, мы знаем, что D от X точно совпадает с РОСY, так как X лежит во множестве С.
[21:38.280 --> 21:56.520]  Это первый момент. Далее, далее, что мы знаем? Мы знаем, что соответственно у нас расстояние
[21:56.520 --> 22:11.960]  D Y, оно, во-первых, меньше либо равно, чем, смотри, когда мы добавляли X, когда мы добавляли X в множество S,
[22:11.960 --> 22:17.800]  да, мы в том числе обновляли расстояние из X до Y, да, то есть мы писали, мы писали,
[22:17.800 --> 22:40.200]  D Y равно минимум из D Y и D X плюс, плюс W XY согласно, вот, поэтому расстояние до
[22:40.200 --> 22:56.960]  вершины Y меньше либо равно, чем D X плюс, соответственно, плюс W XY, соответственно, равно
[22:56.960 --> 23:25.520]  РОСX плюс W XY, вот, может, давайте. Да, секунду, сейчас, секунду, разберемся.
[23:25.520 --> 23:42.800]  Да, все, какой вопрос был? Да, соответственно, вот, а что я хочу показать? Я хочу, смотрите,
[23:42.800 --> 23:50.080]  вот эта штука, вот я утверждаю, что вот эта штука, продолжаем рассуждение, точно равна РОСY. Почему?
[23:50.080 --> 23:56.800]  Смотрите, D от Y тоже точно не меньше либо равен, чем D от X плюс W XY, согласно. Почему? Потому что
[23:56.800 --> 24:03.480]  когда я добавлял вершину X, я обновляю расстояние до всех вершин, то есть в том числе до Y я
[24:03.480 --> 24:08.840]  обновлял, то есть у меня расстояние как минимум вот такое, ну, не более такого, вот, соответственно,
[24:08.840 --> 24:16.160]  дальше я знаю, что D от X точно все равно РОСX, я писал вот так. А теперь смотрите, что я знаю?
[24:16.160 --> 24:22.560]  Я знаю, что я рассматриваю кратчайший путь от S до Y, и у меня, соответственно, на этом пути
[24:22.560 --> 24:29.320]  попадается ребро XY, но согласно, что подпуть кратчайшего пути тоже является кратчайшим путем. Задача,
[24:29.320 --> 24:34.840]  она оптимальна по подзадачам, да, то есть если я каким-то образом добрался от S до U оптимальным
[24:34.840 --> 24:41.280]  образом, то это означает, что я до Y тоже добрался оптимальным образом, согласны? Вот, ну, а это,
[24:41.280 --> 24:47.840]  собственно, означает, что расстояние до вершины Y точно совпадает с РОСХ плюс WXY. Нормально?
[24:51.840 --> 24:57.320]  То есть вот это понятно, вот это тоже понятно следует вот отсюда. Теперь почему у нас есть вот такой
[24:57.320 --> 25:03.320]  переход? Ну, почему вот эта штука равна вот этой штуке? Снова, кратчайшее расстояние от S до Y
[25:03.320 --> 25:10.800]  оно устроено именно вот так, да, потому что это подпуть кратчайшего пути от S до U, поэтому кратчайший
[25:10.800 --> 25:21.200]  путь от S до Y это кратчайший путь от S до X плюс WXY, то, собственно, тут и написано. Нормально? Вот,
[25:21.200 --> 25:26.640]  то есть мы пока, да, а в свою очередь вот эта штука меньше равна, чем D от Y,
[25:26.640 --> 25:35.320]  ну, по очевидным причинам, потому что в D у нас хранится путь, который проходит только по вершинам
[25:35.320 --> 25:41.040]  из S, а РОСХ это вообще произвольный, точнее не произвольный, а вообще глобальный кратчайший путь.
[25:41.040 --> 25:46.280]  Ну, понятное дело, что более ограниченный кратчайший путь, он никак не меньше, чем глобальный кратчайший
[25:46.280 --> 25:53.280]  путь, согласна? Ну, все, то есть отсюда мы получаем, то есть это вот, что у нас было, а отсюда мы получили
[25:53.280 --> 26:11.000]  логическим образом, что D от Y совпадается РОСХ. Вот. Давайте дальше. Так, это мы знаем,
[26:11.000 --> 26:29.040]  и это мы знаем. Картинка у нас вот такая. С, Х, вершина У. Ну, а далее рассуждаем,
[26:29.040 --> 26:32.160]  далее рассуждаем в следующем образе. Вот у меня есть вершина, а вот у меня есть расстояние D от U.
[26:32.160 --> 26:49.720]  Что я знаю про D от U? Про D от U я знаю, что это меньше чем равно, чем D от Y. Почему это так? Да, потому что
[26:49.720 --> 26:55.760]  Аргмин. У это как раз такая вершина, которая обладает минимальной дешкой среди всех вершин, которые не
[26:55.760 --> 27:04.240]  попали во множество S. Поэтому она точно никак не больше, чем D от Y, согласна? Так, а D от Y это у меня...
[27:04.240 --> 27:25.880]  Нет. Нет, все нормально. Вот. Соответственно, АD от Y я доказал, что это равно РОСY. А РОСY в точности меньше
[27:25.880 --> 27:30.580]  либо равен... Ну, не в точности, а просто меньше бы равен, чем РОСУ. Потому что путь от S до Y это под
[27:30.580 --> 27:45.260]  путь, пути от S до U. Согласна? Ну, вот. Давайте поясним каждый. Значит, вот это следует из того, что U это
[27:45.260 --> 27:52.820]  Аргмин. Дальше. Почему D от Y равно РОСY? Это мы доказали ранее.
[27:52.820 --> 28:13.340]  Дальше. Почему РОСY меньше равно, чем РОСУ? Потому что SY это под путь SU. Согласна?
[28:13.340 --> 28:25.660]  А вот это почему? Да, по определению кратчайшего пути. Ну, то есть, какой-то путь не может быть
[28:25.660 --> 28:39.980]  меньше, чем самый короткий путь. Согласна? Ну, и что получили? U равно РОСУ. Ну, что-то D. Нормально?
[28:39.980 --> 28:49.900]  Так. Ну, давайте. Ну, вроде не набагали нигде. Ну, короче, давайте еще раз коротко прибежимся.
[28:49.900 --> 28:55.500]  Доказываем по индукции. База индукции очень простая. У нас изначально в множестве S
[28:55.500 --> 28:59.980]  всего лишь одна вершина S маленькая. Расстояние до нее мы знаем. Оно равно нулю. Дальше. Предположим,
[28:59.980 --> 29:06.540]  что пусть теперь у нас есть какое-то множество S. И предположим, что для каждой вершины из
[29:06.540 --> 29:11.180]  этого множества S мы знаем кратчайший путь. Вот. Соответственно, возьмем вершину U, которая не
[29:11.180 --> 29:17.940]  лежит в этом множестве, у которой Аргмин по всем D. Вот. Докажем, что до этой вершины мы корректно
[29:17.940 --> 29:22.740]  нашли путь. То есть мы докажем, что действительно мы обоснуем корректность алгоритма. То есть докажем,
[29:22.740 --> 29:26.100]  что до вершины U действительно все найдено верно. Ну, значит, предположим, что у нас существует
[29:26.100 --> 29:30.100]  какой-то кратчайший путь из вершины S до U. И, понятное дело, он в какой-то момент должен пересечь
[29:30.100 --> 29:35.820]  наш разрез. Должен пересечь, должен выйти из множества S, скажем так, наружу. Вот. Предположим,
[29:35.820 --> 29:42.860]  он пересекает этот разрез по ребру X, Y. Вот. Соответственно, что мы знаем про вершину Y? Мы
[29:42.860 --> 29:49.540]  знаем, что D от Y меньше равно, чем D от X плюс WXY, потому что в какой-то момент мы из X
[29:49.540 --> 29:54.740]  обновляли расстояние до Y и обновляли его вот таким значением. Но, возможно, у нас была какая-то
[29:54.740 --> 29:59.380]  другая вершина, с помощью которой мы тоже обновляли до Y. Поэтому у нас, как максимум, вот такая вот
[29:59.380 --> 30:05.780]  длина. Ну окей. Но что мы знаем про X? X лежит в множестве S, поэтому до него мы нашли кратчайший путь
[30:05.780 --> 30:14.340]  верма. Поэтому D от X равно rho SX. Дальше. Что мы знаем? Мы знаем, что SY это подпуть
[30:14.340 --> 30:22.300]  пути из S до U. Поэтому путь SX, а дальше Y, соответственно, является кратчайшим путем. Ну все,
[30:22.300 --> 30:29.220]  соответственно, вот этот путь, rho SX, а дальше WXY, точности равен кратчайшим пути вот S до Y. Ну а кратчайший
[30:29.220 --> 30:35.900]  путь от S до Y никак не может быть больше, чем какой-либо путь. Ну, не важно какой. Ну все, в итоге пришли
[30:35.900 --> 30:42.820]  к вот такому соотношению. Вот. Ну а дальше, собственно, написали те же самые, по сути, те же самые неравенства,
[30:42.820 --> 30:49.220]  но для вершины U. D от U никак не больше, чем D от U. Ну, по определению, так мы U взяли,
[30:49.220 --> 30:54.540]  как аргумент. Дальше D от Y мы доказали, что равен rho SY, а rho SY никак не больше, чем rho SU.
[30:54.540 --> 31:01.060]  Ну, а rho SU не больше, чем D от U. Ну все, получили цепочку неравенства, из которой пришли из начала в
[31:01.060 --> 31:06.420]  конец, то есть, к тому себя. Ну, соответственно, тут везде стоит, значит, тут везде стоит равенство и доказали,
[31:06.420 --> 31:15.820]  что D от U равно rho SU. Вот. Все понятно? Тогда вопрос вам. А в какой момент мы вообще, ну, смотрите, вот,
[31:15.820 --> 31:21.580]  утверждение теоремы говорится следующее. Если ребрографы не отрицательные, то все окей. А в какой
[31:21.580 --> 31:28.660]  момент мы вообще говоря использовали не отрицательность ребр? Предпоследним, то есть, вот здесь. Да.
[31:28.660 --> 31:40.460]  Вот здесь. Да. Все понятно, почему вот тут мы использовали не отрицательность ребр. То есть, мы на самом
[31:40.460 --> 31:46.060]  деле, то есть, вот тут мы сказали следующую вещь, что у меня есть путь от S до Y и есть путь от S до U. И
[31:46.060 --> 31:51.340]  вот этот вот более длинный путь по количеству ребр, он обязательно будет длиннее, чем путь от S до Y. То
[31:51.340 --> 31:56.700]  есть, вот этот вот путь обязательно будет не отрицательным. И это как раз следует из-за того,
[31:56.700 --> 32:01.660]  что у меня все ребра не отрицательные. Понятно? Если у меня ребра были отрицательные, то вот
[32:01.660 --> 32:05.940]  здесь вот я такого не смог утверждать, соответственно, доказать это было бы некорректно. Ну, и вообще говоря,
[32:05.940 --> 32:11.540]  алгоритм сам был неверным. Понятно? Поэтому в случае отрицательных ребр алгоритм, соответственно,
[32:11.540 --> 32:22.660]  не работает. Ну, и соответственно, реализация алгоритма Dijkstra, ну, по сути, ничем не отличается
[32:22.660 --> 32:28.780]  от реализации алгоритма Prima. У нас есть массив dist, в котором у нас все значения равны бесконечности,
[32:28.780 --> 32:33.540]  кроме элемента, который стоит на позиции S. Ну, дополнительно, можно хранить массив предков,
[32:33.540 --> 32:38.900]  помните, да, массив предков, чтобы можно было восстановить кратчайший путь. Храним массив предков.
[32:38.900 --> 32:43.340]  Ну, и соответственно, как мы будем искать минимум? А минимум мы будем искать с помощью пирамиды.
[32:43.340 --> 32:51.220]  У нас в алгоритме есть поиск аргумина. Давайте искать минимум быстро. Ну, а быстро это, как правило,
[32:51.220 --> 32:57.540]  пирамида. Соответственно, доведем пирамиду, и в пирамиде будем хранить пару из расстояния до вершины
[32:57.540 --> 33:03.580]  и саму вершину. Ну, дальше, собственно, все просто. Пока у меня хипа не пустая, пока у меня пирамида
[33:03.580 --> 33:09.940]  не пустая, я достаю оттуда минимум, то есть беру тот самый аргумин. Ну и, по сути, прохожусь по всем
[33:09.940 --> 33:15.100]  соседним от вершины и пытаюсь обновить расстояние. То есть если расстояние до вершины u больше,
[33:15.100 --> 33:20.780]  чем расстояние до вершины v, плюс w в у, то я обновляю расстояние до вершины u. Ну, собственно,
[33:20.780 --> 33:25.620]  обновление мы показывали. И говорю, что до вершины u, то есть предком вершины u, является вершина v.
[33:25.620 --> 33:35.940]  Ну и дальше говорю декрит скейдинг. То есть у меня в пирамиде есть ключ, который соответствует
[33:35.940 --> 33:43.300]  вершине u. Я его изменяю, то есть уменьшаю до такой величины. Ну и так далее и я. Понятно, да?
[33:43.300 --> 33:53.540]  Есть вопросы? Окей. Ну и, соответственно, ровно как и в алгоритме Прима, соответственно,
[33:53.540 --> 33:58.460]  сложность этого алгоритма при использовании бинарной пирамиды e log v. Почему? Ну давайте еще раз
[33:58.460 --> 34:05.420]  проговорим это. Соответственно, общее количество вот этого цикла, общее количество, давайте так,
[34:05.420 --> 34:13.500]  по порядку. Какое количество раз я достану из хипы, соответственно, вершины? Ну не более в раз,
[34:13.500 --> 34:21.540]  потому что, не более в раз, потому что, соответственно, ну когда я дошел, когда я нашел кратчащий
[34:21.540 --> 34:26.900]  состояние до вершины, мне уже нет смысла его обратно класть в пирамиду. Окей? Вот. То есть
[34:26.900 --> 34:31.820]  вот этот цикл while выполняется в раз. Дальше. За сколько работает extract min? Extract min работает
[34:31.820 --> 34:48.340]  за алгоритм. Да, поэтому я получаю v log v. V log v это на Extract min. Вот. А дальше у меня, соответственно,
[34:48.340 --> 34:54.340]  есть вот такой вот цикл, и вот он суммарно, суммарно, за все циклы while выполняется e или 2e раз,
[34:54.340 --> 34:58.220]  в зависимости от того, ориентированных граф или нет. Согласно, да? Потому что я для каждой вершины
[34:58.220 --> 35:02.420]  просматриваю ее соседей. Ну в худшем случае для каждой вершины я просморю всех соседей. Вот. Ну и на
[35:02.420 --> 35:06.740]  каждой итерации, ну в худшем случае, опять же, я сделаю decrease k. А decrease k тоже делается за
[35:06.740 --> 35:19.820]  алгоритм v. То есть e на log v это уже decrease. Вот. Да, ну и, соответственно, если я использую
[35:19.820 --> 35:24.460]  фибоначевую пирамиду, то у меня получается асимптотика e plus v log v. То есть вот этот v log v остается,
[35:24.460 --> 35:33.980]  а тут будет e, если у меня f hip. Ну потому что decrease k в фибоначевой пирамиде делается за единицу.
[35:33.980 --> 35:50.340]  Амортизирован. Понятно, да? Вот тут? В общем случае, e log v. Ну, окей, да, можно писать e plus v log v,
[35:50.340 --> 35:56.060]  но предполагается, что, не знаю, интуитивно предполагается, что в графе ребер, как правило,
[35:56.060 --> 36:05.020]  больше, чем число вершин. Ну да, можно писать v plus e log v. Ну, на самом деле, да, на самом деле,
[36:05.020 --> 36:13.740]  тут есть еще один момент. Вообще говоря, тут есть такая история, что вот я сказал, что у вас в хипе
[36:13.740 --> 36:19.300]  в каждом момент времени больше, чем v вершин. Вот. На самом деле, это не всегда правда, потому что на
[36:19.300 --> 36:23.340]  самом деле на практике проще, ну смотрите, что нужно делать? Когда вы встречаете очередную вершину,
[36:23.340 --> 36:28.540]  вам нужно проверить там, а лежит ли она во множестве s или нет. То есть, грубо говоря,
[36:28.540 --> 36:33.260]  нашли вы до нее кратчайшее расстояние уже или нет. Соответственно, если вы до нее уже нашли кратчайшее
[36:33.260 --> 36:38.620]  расстояние, то ее добавлять в хипу не имеет смысла. Ну, логично. Но, в принципе, на самом деле,
[36:38.620 --> 36:44.300]  вы можете это не проверять. То есть, вы можете просто на это добить и просто-напросто добавлять
[36:44.300 --> 36:50.300]  хипу все то, что вам попадается под руку. Вот. И тогда, соответственно, у вас вы в хипу добавить
[36:50.300 --> 36:57.340]  максимум e ключей. Вот. И, соответственно, эта точка будет с точностью e логуя. Ну, это уже на семинарах
[36:57.340 --> 37:01.900]  обсудить, значит, детали реализации. Ну, в общем, грубо говоря, можно, ну, короче говоря, можно не проверять,
[37:01.900 --> 37:09.020]  там лежит у вас что-то в хипе или нет. То есть, точнее так, вот decrease k делать. Ну, кто на самом деле в
[37:09.020 --> 37:15.980]  реальности реализовывал decrease k в пирамиде или где-нибудь? decrease k. Ну, decrease k — это неприятная
[37:15.980 --> 37:21.420]  операция. Вот. Поэтому можно обойтись без decrease k и просто-напросто добавить, ну, в смысле, не делать
[37:21.420 --> 37:29.180]  decrease k, а можно просто добавить в пирамиду еще одну пару. Ну, уже там обновленный дистат u и u. Понятно, да?
[37:29.180 --> 37:41.740]  Ну, типа у вас в пирамиде где-то хранится значение 10 и вершина 5. Допустим, до вершины 5 вы нашли
[37:41.740 --> 37:45.980]  новый кратчайший путь, который равен 8. Предполагается делать так. Давайте просто-напросто
[37:45.980 --> 37:53.820]  возьмем, добавим пару 8, 5. Вот. А с этой парой ничего делать не будем. Пусть она там лежит,
[37:53.820 --> 38:00.300]  все равно она будет, но все равно мы ее достанем позже, чем вот эту пару. Согласны? Поэтому вот эта пара нам
[38:00.300 --> 38:07.540]  ничего не испортит. Понятно, что я пытался сказать? Впрочем, можно забить на decrease k и просто-напросто вместо
[38:07.540 --> 38:14.580]  вот этого decrease k сделать insert, то есть добавить хипу. И если вы вместо decrease k используете
[38:14.580 --> 38:20.100]  соответственно insert, то у вас получается так, что у вас максимальный размер хипы равен не v, а e,
[38:20.100 --> 38:30.940]  поэтому тут yellow v – это честная оценка. Ну, это уже такие практические детали, которые будете
[38:30.940 --> 38:39.940]  обсуждать на семинарах. Вот. Ну, смотрите, ровно как и с алгоритмом Prima, в алгоритме Dextre можно
[38:39.940 --> 38:45.500]  вместо пирамиды использовать просто массив. Ну, скажем, ну зачем нам мучиться с пирамидой? Давайте
[38:45.500 --> 38:50.020]  просто-напросто заведем массив. Ну, в смысле у нас так есть, у нас есть массив. Давайте, собственно,
[38:50.020 --> 38:55.260]  не будем ничего выдумывать, не будем искать минимум за алгоритмическое время пирамиде, а давайте
[38:55.260 --> 38:59.620]  просто-напросто возьмем и старым дедовским способом честно будем проходиться по массиву и искать
[38:59.620 --> 39:04.300]  в нем минимум. Ну, то есть, тут у меня совсем нет хипы, поэтому я просто-напросто храню, ну,
[39:04.300 --> 39:10.220]  грубо говоря, размер, просто храню в отдельной переменной размер построенного множества s. Дальше
[39:10.220 --> 39:17.980]  я, у меня есть массив dist, я беру в нем argmin, честный argmin, линейный, за линейное время. Вот. Ну,
[39:17.980 --> 39:32.180]  и, соответственно, дальше. Почему? Нет, смотрите, аргмин вы в любом случае достанете, если у вас,
[39:32.180 --> 39:37.940]  ну, в смысле бесконечности, вы в любом случае будете доставать, так или иначе. Ну, это детали
[39:37.940 --> 39:42.380]  псевдокода, ну, короче, не обязательно граф связный, вот. В смысле, что если вы, ну, то есть,
[39:42.380 --> 39:47.340]  тут while может заменить на цикл, когда вы ищете минимум, а минимум равен бесконечности. Если минимум
[39:47.340 --> 39:50.780]  равен бесконечности, то, соответственно, можно завершить работу. То есть, ну, это особо неважно.
[39:50.780 --> 39:56.020]  Вот. Ну, и да, соответственно, тут мы не используем операцию decrease k, а просто-напросто
[39:56.020 --> 40:01.580]  сразу, непосредственно, меня обновляем dist в самом массиве. Вот. Ну, и, соответственно, как
[40:01.580 --> 40:08.540]  обсуждали тоже в прошлый раз, к чему это приводит? Да, у нас аргмин теперь считается дольше. То есть,
[40:08.540 --> 40:13.940]  раньше он считался dllq суммарно, а теперь он суммарно считается 2 квадрата. Да, потому что,
[40:13.940 --> 40:21.300]  вообще, так, вообще не перерыв. У нас общее количество итерации while не более чем v, и, собственно,
[40:21.300 --> 40:26.860]  и, собственно, сам пояс минимум занимает v, поэтому v квадрат. Вот. А тут, с другой стороны,
[40:26.860 --> 40:31.460]  мы избавляемся от логарифмичности в пользу единицы. Да, поэтому получается просто v квадрат
[40:31.460 --> 40:38.100]  плюс e. Ну, и ровно как в алгоритме prima мы получаем следующую картину. То в случае разреженного
[40:38.100 --> 40:45.540]  графа, реализация на бинарной пирамиде работает за v логв, а в случае массива работает за v квадрат.
[40:45.540 --> 40:51.060]  А в случае плотного графа, бинарная пирамида работает за v квадрат логв, массив работает за v квадрат.
[40:51.060 --> 40:55.020]  Ну, то есть, получается ситуация, что в зависимости от того, разреженного графа или плотный,
[40:55.020 --> 41:07.060]  вы должны выбрать там либо реализацию на бинарной пирамиде, либо на массиве. Окей. Вот. Но это тоже
[41:07.060 --> 41:12.060]  такая вот эта строчка, да. Но это чисто техническая деталь, чтобы в следующий раз я ее не вытащил по аргмину.
[41:12.060 --> 41:17.820]  То есть, таким образом, я просто ее помечаю, что она лежит во множестве вес, и ее в следующий раз
[41:17.820 --> 41:29.220]  доставать не нужно. Окей. Вот. Да, но тут, видимо, из-за этого будет баг, да, вот тут. Короче, да,
[41:29.220 --> 41:34.460]  вот этот пункт надо поменять. То есть, вот этот надо как-то заменить на то, что мы должны игнорировать
[41:34.460 --> 41:45.380]  элементы, которые лежат в множестве веса. Окей. Все ясно? Ну, тогда перерыв.
[41:47.380 --> 41:52.180]  Короче, пути при любых обстоятельствах данных, любых графов, неважно, ориентированные,
[41:52.180 --> 41:59.100]  неориентированные, при этом вне зависимости там от длинных ребер, да, то есть, неважно, целые,
[41:59.100 --> 42:06.380]  рациональные, хоть какие, в общем, позволяет найти кратчайший путь. И при этом мы с вами поговорили о том,
[42:06.380 --> 42:11.420]  что в случае разрешенных графов эффективнее всего использовать бинарную пирамиду, в случае плотных
[42:11.420 --> 42:18.100]  графов эффективнее использовать массив. Вот. Ну, значит, алгоритм Dijkstra, у него есть ограничение,
[42:18.100 --> 42:23.460]  которое стоит в том, что алгоритм Dijkstra умеет работать только в ситуации, когда ребра не отрицательны.
[42:23.460 --> 42:28.740]  Давайте поговорим теперь о том, что делать, если у нас есть отрицательные ребра, и вообще в чем там
[42:28.740 --> 42:35.220]  проблема, да, то есть, почему на самом деле задача поиска кратчайшего пути в графе с отрицательными
[42:35.220 --> 42:42.340]  ребрами, она, ну, скажем так, значительно сложнее, чем задача поиска кратчайшего пути в графе,
[42:42.340 --> 42:53.780]  в котором отрицательных ребер нет. Задача поиска... Ну, что значит актуальная? Насколько она актуальная?
[42:53.780 --> 43:00.020]  Нет, в смысле, что вы имеете в виду под актуальной? В смысле, встречается она на практике или нет?
[43:00.020 --> 43:07.140]  Нет, на самом деле, на практике, ну, естественно, то есть, как бы, не знаю, можно привести банальные
[43:07.140 --> 43:12.260]  какой-нибудь игровой примеры, да, то есть, вы можете двигаться, ну, смотрите, у вас есть как бы две
[43:12.260 --> 43:15.940]  стратегии, да, то есть, вы можете двигаться просто там, бесконечно по пути, то есть, если, опять же,
[43:15.940 --> 43:19.500]  представить какую-нибудь угонку, типа Formula 1, да, вы можете просто двигаться, и тогда вы просто,
[43:19.820 --> 43:25.460]  все быстрее и быстрее приближаетесь к цели, да, можете, собственно, какое-то время, условно, остановиться и,
[43:25.460 --> 43:32.540]  там, не знаю, до заправиться. Отвестного, вот тогда ваши ребра графа, это условно... длина ребра положительная,
[43:32.540 --> 43:36.900]  если вы там на этом пути что-то теряете, да, теряете, не знаю, какую-то массу, какую-то ценность,
[43:36.900 --> 43:41.540]  какую-то стоимость, и так далее... а ребра отрицательная, если вы это приобретаете, и, вот, естественно,
[43:41.540 --> 43:46.740]  вам выгоднее там ходить по отрицательным ребрам в этом случае, чем по положительным. То есть, скажем так,
[43:46.740 --> 43:50.140]  Тут возникает такая двоярская ситуация. С одной стороны, вам выгоднее как можно быстрее добраться до финиша,
[43:50.140 --> 43:56.140]  то есть двигаясь по положительным ребрам, а с другой стороны, вы можете двигаться чуть более долго,
[43:56.140 --> 44:00.900]  в смысле, количеству ребр, но при этом передвигаясь по отрицательным ребрам, и тут уже непонятно,
[44:00.900 --> 44:04.740]  какая стратегия будет оптимальна. То есть, постановок на самом деле тут масса, нет такого,
[44:04.740 --> 44:09.300]  что у нас есть только положительные ребра, а отрицательные ребра до практики не имеют смысла.
[44:09.300 --> 44:20.420]  Нет. Понятно, да? В общем, задача такая. По-прежнему мы пытаемся найти кратчайший путь или кратчайшее
[44:20.420 --> 44:25.940]  состояние, но при этом снимаем ограничения с того, что у нас есть, с того, что у нас только
[44:25.940 --> 44:31.740]  не отрицательные ребра. Как вы думаете, в чем проблема? Вот просто заменили R+, на R.
[44:31.740 --> 44:41.140]  Вот, да, смотрите, у нас есть, да, действительно. Давайте подумаем вот о чем. Вот у меня есть какая-то вершина,
[44:41.140 --> 44:51.980]  соответственно, один, и вот, не знаю, какая-то вот такая вот ситуация. Один.
[44:51.980 --> 45:13.700]  Чему равен кратчайший путь от S до T? Ну нет, на самом деле его не существует, потому что, как
[45:13.700 --> 45:17.740]  правило, мы рассматриваем конечные пути, да, ну и в любом случае, как бы, не существует пути,
[45:17.740 --> 45:21.900]  который каким-то образом доводил вас до T, да, потому что вам выгоднее бесконечно
[45:21.900 --> 45:26.820]  количество раз бегать вот тут, соответственно, вы до T так, на самом деле, никогда и не доберетесь.
[45:26.820 --> 45:32.620]  Вот. Поэтому, действительно, в случае, если у вас есть отрицательные ребра, то, вообще говоря,
[45:32.620 --> 45:38.580]  задача не совсем корректна. В общем, пословка задачи, которую мы ставили исходно, она не совсем
[45:38.580 --> 45:42.540]  корректна в том смысле, что минимального пути может, в принципе, не существовать, да, то есть вы,
[45:42.540 --> 45:45.980]  в принципе, не можете предоставить там какой-то путь, который будет обладать тем свойством,
[45:45.980 --> 45:51.100]  что он меньше любого другого пути, да, то есть задача поиска минимального пути, она становится
[45:51.100 --> 45:56.580]  некорректной как раз из-за наличия вот таких вот, из таких вот отрицательных циклов. Вот. Окей, значит,
[45:56.580 --> 46:01.500]  ну смотрите, окей, мы поняли, что в кратчайшей пути вот эта дата не существует, потому что мы тут
[46:01.500 --> 46:05.740]  можем бегать бесконечно еще раз, постоянно там набивая все более и более короткий путь. Но
[46:05.740 --> 46:10.260]  можно поставить задачу другую. Давайте поставим такую задачу. Давайте будем искать не просто
[46:10.260 --> 46:15.060]  кратчайший путь, а будем искать кратчайший простой путь. Ну что такое простой путь? Простой путь – это путь,
[46:15.060 --> 46:19.540]  который не проходит по циклам. Давайте просто запретим бегать по циклам и скажем, ну давайте
[46:19.540 --> 46:25.100]  искать минимальный простой путь. Ну согласен, что в этом случае задачи поставлены корректно.
[46:25.100 --> 46:29.940]  Количество простых путей всегда конечное число в графе, ну в конечном графе всегда количество
[46:29.940 --> 46:33.700]  простых путей конечное, да, но соответственно в конечном множестве всегда можно найти минимальный
[46:33.700 --> 46:45.900]  элемент. Прогласны? В чем тут проблема? Проблема заключается в том, что задача поиска простого пути
[46:45.900 --> 46:54.420]  непосложная. Ну в том смысле, что задача, может, корректно поставлена, но никто не знает,
[46:54.420 --> 46:59.300]  как ее решать эффективно. К сожалению, задача поиска простого пути, но несмотря на то, что она звучит
[46:59.300 --> 47:06.060]  проще, то есть найти не произвольный путь, а вот простой путь, но в этой постановке задача
[47:06.060 --> 47:15.340]  эффективно нерешаемая, давайте так говорить, к сожалению. Поэтому, как ни крути, отрицательные
[47:15.340 --> 47:19.940]  ребра приводят, не всегда, но правда, отрицательные ребра приводят нас к проблемам. Если у нас есть
[47:19.940 --> 47:24.100]  отрицательные циклы, то задача либо некорректно поставлена, либо эффективно не решается.
[47:24.100 --> 47:34.660]  Соответственно, давайте договоримся вот о чем. Когда мы будем говорить про задачу поиска
[47:34.660 --> 47:40.140]  кратчайших путей в случае отрицательных ребер, мы всегда будем заранее договариваться в том,
[47:40.140 --> 47:44.860]  что в нашем графе нет отрицательных циклов, потому что если в нашем графе отрицательные циклы есть,
[47:44.860 --> 47:49.780]  то задача поставлена корректно. Давайте я докажу следующее утверждение, что на самом деле
[47:49.780 --> 47:53.780]  отрицательные циклы это самое худшее, что может с вами случиться при решении этих задач.
[47:53.780 --> 48:02.220]  Ну, помимо там CE и так далее. Ну и ML, вот это все заскобки. Вот с алгоритмической точки зрения самое
[48:02.220 --> 48:05.540]  плохое, что может произойти, это собственно наличие отрицательного цикла. Если отрицательных циклов
[48:05.540 --> 48:12.540]  нет, то задача вполне себе решается, то есть вполне себе имеет единственное решение. Вот, блин, тут уже
[48:12.540 --> 48:15.740]  спойлер, ну давайте, ладно, абсолютно. Задача поиска кратчайших путей корректна только тогда,
[48:15.740 --> 48:20.020]  когда в графе нет циклов отрицательного веса. Ну, значит, в одну сторону понятно, только что я все
[48:20.180 --> 48:25.340]  проговорил. Т.е. если эта задача корректна, то вAM offered циклов отрицательного веса,
[48:26.140 --> 48:29.060]  потому что все пути у меня находятся корректно, все пути восстанавливаются однозначно,
[48:29.060 --> 48:33.620]  но все же означает, что у меня не существует ситуации, при которой я там бесконечно бегаю
[48:34.540 --> 48:39.460]  по отрицательным циклам. Ну и в обратную сторону значит, если в графе нет циклов отрицательного веса,
[48:39.460 --> 48:44.780]  то что это означает? Это означает, что у меня в графе любой путь простой, согласны? Ну,
[48:44.780 --> 48:46.780]  Любой кратчайший путь – это простой путь.
[48:46.780 --> 48:51.780]  Давайте так предположим, что у меня кратчайший путь в графе не простой, то есть в него он содержит цикл.
[48:51.780 --> 48:57.780]  Ну а вопрос, а нафига ты содержишь цикл, если он не отрицательный?
[48:57.780 --> 49:00.780]  Если цикл не отрицательный, то это значит, что он либо положитель, либо нулевой.
[49:00.780 --> 49:04.780]  В любом случае, от него можно избавиться просто и сделать из него простой путь. Согласны?
[49:04.780 --> 49:10.780]  Если у вас нет цикла по отрицательному весу, то тогда можно рассматривать только простые пути.
[49:10.780 --> 49:13.780]  Простые пути – все конечны, то есть их общее количество конечно,
[49:13.780 --> 49:16.780]  но соответственно в конечном множестве мы всегда можем найти минимум.
[49:16.780 --> 49:19.780]  Всегда можем предъявить самый кратчайший путь, поэтому задача поставлена корректно.
[49:19.780 --> 49:22.780]  Понятно? Окей.
[49:22.780 --> 49:27.780]  Ну и собственно алгоритм, которым мы будем решать задачу поиска кратчайших путей
[49:27.780 --> 49:32.780]  в случае, если у нас есть отрицательные ребра – это алгоритм Порда Беллмана.
[49:32.780 --> 49:38.780]  И, к счастью, это, наверное, один из самых простых алгоритмов, который мы будем рассматривать в нашем курсе.
[49:38.780 --> 49:44.780]  По сути, он состоит из одной процедуры под названием Relax.
[49:44.780 --> 49:47.780]  Процедура довольно просто устроена.
[49:47.780 --> 49:54.780]  Допустим, у вас есть вершина В и есть вершина У.
[49:54.780 --> 50:00.780]  И у вас есть какой-то путь до вершины В и какой-то путь до вершины У.
[50:01.780 --> 50:05.780]  Это В.
[50:05.780 --> 50:09.780]  Допустим. Вы нашли какой-то путь до вершины В и какой-то путь до вершины У.
[50:09.780 --> 50:11.780]  В чем состоит релаксация ребра ВУ?
[50:11.780 --> 50:16.780]  Релаксация ребра ВУ состоит в том, что мы пытаемся с помощью ребра ВУ
[50:16.780 --> 50:19.780]  обновить расстояние до вершины У.
[50:19.780 --> 50:25.780]  То есть, если расстояние до вершины Уbaarше, чем расстояние до вершины В, плюс вот это ребро,
[50:25.780 --> 50:29.780]  то есть, если вот по этому пути пройти быстрее, чем вот по этому пути,
[50:29.780 --> 50:33.780]  по этому пути, то мы это ребро, что называется, релаксируем. То есть, что это
[50:33.780 --> 50:39.620]  означает? Мы обновляем расстояние до вершины u, забываем вот этот путь и говорим, что вот этот путь
[50:39.620 --> 50:47.340]  теперь тогда от u. Ну и, при необходимости, обновляем предка. Ну, еще заодно, говорим,
[50:47.340 --> 50:50.780]  возвращаем true или false, если ребро отрелаксировалось или не отрелаксировалось.
[50:50.780 --> 50:57.140]  Ну, простая процедура. То есть, можем не с помощью этого ребра обновить путь до вершины u.
[50:57.140 --> 51:05.620]  Окей? Вот. Ну и, соответственно, алгоритм for the blame заключается на следующей идее. Ну, смотрите,
[51:05.620 --> 51:11.900]  если у нас задача поставлена корректно, то это означает, что если у нас есть кратчайший путь
[51:11.900 --> 51:19.420]  от вершины s до какой-либо другой вершины, то он состоит не более чем v-1 ребра. А это, собственно,
[51:19.420 --> 51:25.540]  означает что? Это означает, что мне всего лишь достаточно v-1 раз отрелаксировать все ребра. Ну,
[51:25.540 --> 51:33.940]  смотрите, вот у меня есть вершина s. Вот у нее есть, допустим, какой-то кратчайший путь до вершины v.
[51:33.940 --> 51:40.340]  Ну, изначально я не знаю никаких кратчайших путей, и, допустим, у меня все кратчайшие
[51:40.340 --> 51:46.260]  путей равны бесконечности. Давайте я просто возьму и тупо отрелаксирую все ребра. Ну, просто втыкли
[51:46.260 --> 51:51.700]  возьму, все ребра пройду и все их отрелаксирую. Что у меня получится? Согласны ли вы, что у меня,
[51:51.700 --> 51:58.340]  как минимум, обязательно отрелаксируется вот это ребро. Ну, расстояние дает вершину бесконечности,
[51:58.340 --> 52:02.460]  это ребро, естественно, имеет какую-то конечную длину, поэтому это ребро в любом случае отрелаксируется.
[52:02.460 --> 52:11.100]  Нормально? Теперь так. Снова возьму все ребра и снова их все прорелаксирую. Ну, согласны,
[52:11.100 --> 52:14.740]  что на второй итрации у меня обязательно отрелаксируются, ну, не обязательно,
[52:15.160 --> 52:22.700]  на второй итрации, будет отрелаксирано 1-2-й. То есть до первой вершины я уже
[52:22.700 --> 52:26.060]  нашел кратчайший пут и, соответственно, на следующей итрации, возможно,
[52:27.400 --> 52:33.240]  за первые два итрации я найду кратчайший пут до второй вершины, согласны? Ну и так далее.
[52:33.240 --> 52:34.240]  дальше возьму снова тирелоксирую все
[52:34.240 --> 52:36.240]  ребра, miles то есть таким образом я гарантирую
[52:36.240 --> 52:37.240]  что будет от реалоксировано вот это
[52:37.240 --> 52:39.300]  ребро,
[52:39.300 --> 52:40.320]  но от реалоксирую все ребра гарантирую что
[52:40.320 --> 52:41.320]  меня будет отреалоксировано это ребро,
[52:41.320 --> 52:43.420]  ну и так далее будет от реалоксировано это
[52:43.420 --> 52:45.240]  ребро соответственно за V- 1
[52:45.240 --> 52:46.800]  атерацию я гарантирую на 2 крufficient муть
[52:46.800 --> 52:48.900]  до вершины V. Girls
[52:48.900 --> 52:50.380] 11
[52:50.380 --> 52:56.200]  не согласно, observим идеи, понятно?
[52:56.200 --> 52:58.680]  т.е. так как любой крφ состоит не более
[52:58.680 --> 53:00.560]  из чем В RE, мне достаточно
[53:00.560 --> 53:02.320]  просто взять и В¹ раз отреалоксировать
[53:02.320 --> 53:06.760]  рёбра. В произвольном порядке. Просто релаксирую все рёбра и всё.
[53:06.760 --> 53:12.840]  Но, собственно, алгоритм как слышится, так и пишется. Весь алгоритм. У нас есть
[53:12.840 --> 53:17.320]  массив расстояния, дист, массив предков, преф. Дальше в цикле проходим,
[53:17.320 --> 53:21.920]  заводим цикл на выминус одну итерацию и, собственно, внутри этого цикла
[53:21.920 --> 53:26.360]  проходим по всем рёбрам и релаксируем каждое ревро. Всё.
[53:26.800 --> 53:33.400]  Гарантируется, что этот алгоритм найдёт все кратчайшие расстояния. Нормально?
[53:33.400 --> 53:37.480]  Ну, если сложить этот алгоритм, естественно, v умножить на e. Почему? Потому что внешний цикл
[53:37.480 --> 53:40.920]  делает по-минус одну итерацию, а внутренний цикл мы проходим по всем рёбрам,
[53:40.920 --> 53:44.720]  соответственно, e итерацией. Нормально?
[53:46.440 --> 53:50.040]  Ну и доказательта корректности. Ну, по сути, корректность я уже проговорил.
[53:50.040 --> 53:53.440]  Если в графе g отсутствует цикл от официального места, то по завершении работы алгоритма
[53:53.440 --> 53:57.480]  дист от v, то есть расстояние до любой вершины, ну, дист, который я нашёл, в точь
[53:57.480 --> 54:01.560]  совпадает с истинным кратчайшим расстоянием. Ну, по сути, доказательства я уже
[54:01.560 --> 54:06.280]  проговорил. То есть, можно разжечь по индукции. То есть, докажем, что после k
[54:06.280 --> 54:11.560]  итерации, после k итерации и релаксации всех рёбер, мы обязательно найдём дист vk.
[54:11.560 --> 54:20.880]  Ну, где vk? Это, соответственно, v1, v2, v3, v4, ну, и так далее.
[54:21.880 --> 54:27.880]  То есть, дист vk – это вершина, которая находится на расстоянии k-рёбер от старта вершины.
[54:27.880 --> 54:31.440]  Ещё докажем, что, соответственно, я найду корректное расстояние.
[54:31.440 --> 54:35.800]  На k итерации я найду корректное расстояние. Ну, по индукции рассуждать очень просто.
[54:35.800 --> 54:39.160]  То есть, на нулевой итерации у меня, корректно, найден путь до вершины s.
[54:39.160 --> 54:42.760]  Соответственно, так как я на нулевой итерации нашёл корректный путь до вершины s,
[54:42.760 --> 54:47.760]  то после первой итерации я корректно иду путь до вершины v1. Почему?
[54:47.760 --> 54:51.320]  Потому что, так как я релаксирую все рёбра, то это ребро я тоже гарантированно отрелаксирую.
[54:51.320 --> 54:56.440]  Согласны? То есть, после первой итерации у меня кратчайшее расстояние до вершины v1 будет
[54:56.440 --> 55:03.640]  корректно найдено. Ну, и по индукции и дальше. Вот, допустим, у меня найден кратчайший путь до вершины vk-1.
[55:03.640 --> 55:16.360]  Так как до вершины vk я нашёл кратчайший путь, корректно, по предположению индукции, то на следующий трат,
[55:16.360 --> 55:20.480]  когда я буду релаксировать все рёбра, вот это ребро мне тоже гарантированно будет отрелаксировано.
[55:20.480 --> 55:26.840]  Ну, в смысле, будет запущена от неё процедура релакс. Вот. Но, соответственно, так как это ребро будет отрелаксировано,
[55:26.840 --> 55:47.480]  то я и найду кратчайший путь до вершины vk. Несортированно. Смотрите, теорема утверждает, что после k-итерации
[55:47.480 --> 55:53.560]  я корректно найду путь до каты вершин, до вершин, которые находятся на расстоянии k-рёбер от исходной.
[55:54.280 --> 56:01.880]  Да какой-то. Смотрите, теорема утверждает, что я обязательно после k-итерации найду корректный путь до любой вершины,
[56:01.880 --> 56:07.000]  которая находится на расстоянии k. Но, как вы правильно заметили, мне может повести,
[56:07.000 --> 56:11.480]  представьте себе, что у меня снова такая картина. Давайте заново перельцую.
[56:11.480 --> 56:19.480]  Смотрите, мне может теоретически повести так, что я буду релаксировать рёбра в строгом таком порядке.
[56:20.380 --> 56:24.880]  Сначала отрелаксирую вот это ребро, потом вот это ребро, потом вот это, потом вот это, потом вот это и хоп,
[56:24.900 --> 56:30.920]  за одну итерацию я нашел все кратчайшие пути. Но теорема утверждает, что в худшем случае
[56:30.920 --> 56:36.400]  за v-одно итерацию я гарантированно всё найду. Понятно? Т.е. это лучший случай.
[56:36.400 --> 56:41.880]  В лучшем случае действительно я за одну итерацию уже всё найду. Но в худшем случае, какой у меня худший случай?
[56:41.880 --> 56:46.320]  Если, допустим, у меня ребра отформированы так, что я всегда релаксирую в обратном порядке,
[56:46.320 --> 56:52.340]  вот это ребро не откину. Давайте. Бесконечность, бесконечность. Что у меня произойдет?
[56:52.340 --> 56:56.340]  Попытаюсь отрелаксировать это ребро. Не релаксируется, не релаксируется, не релаксируется, не релаксируется.
[56:56.340 --> 57:01.560]  Вот это релаксируется. То есть тут, не знаю, хоть D1. Дальше. Снова иду в обратном порядке.
[57:01.560 --> 57:08.580]  Нет, нет, нет, да. Ну и так далее. Понятно.
[57:09.060 --> 57:14.060]  То есть в худшем случае я буду продвигаться только на одно ребро вперед.
[57:14.060 --> 57:18.060]  Но не хуже. То есть я в любом случае всегда хотя бы на одно ребро вперед двигаюсь,
[57:18.060 --> 57:22.060]  потому что я все ребра в любом случае отрелаксирую. Понятно?
[57:22.060 --> 57:27.060]  Поэтому да. В худшем случае это когда я сделаю V-итерации, но, в принципе, возможность ситуации, при которой,
[57:27.060 --> 57:35.060]  ну, может, так повезет, что вот я за одну итерацию сразу все нашел. Но это вряд ли. Нормально?
[57:35.060 --> 57:42.060]  Окей. Ну вот, по сути, корректность алгоритма и вот, вот сам алгоритм.
[57:42.060 --> 57:50.060]  Обсуждать, я думаю, в нем больше нечего. Давайте обсудим другую постать этого.
[57:50.060 --> 58:00.060]  Что? Сейчас мы об этом поговорим. У меня будут слайды про эффективность, но, к сожалению, асимпатически нет.
[58:00.060 --> 58:04.060]  С точки зрения константа и так далее можно придумать что-то лучше.
[58:04.060 --> 58:10.060]  Асимпатически, к сожалению, я, кстати, давно этим вопросом не интересовался, но, по крайней мере,
[58:10.060 --> 58:16.060]  на момент, год назад или два назад, в общем, не было. Асимпатически, по крайней мере.
[58:19.060 --> 58:27.060]  Вот смотрите, мы с вами говорили о том, что алгоритм Порда Белмана работает корректно в том и только в том случае,
[58:27.060 --> 58:31.060]  если у вас нет циклов отрицательного веса.
[58:31.060 --> 58:36.060]  Но не все задачи устроены так, что они гарантируют вам отсутствие циклов отрицательного веса.
[58:36.060 --> 58:42.060]  Представьте, вам дается произвольный град, и вам, собственно, нужно на нем найти кратчайший путь,
[58:42.060 --> 58:45.060]  либо сообщать о том, что кратчайший путь найти невозможно.
[58:45.060 --> 58:49.060]  По сути, задача сводится к тому, чтобы сначала определить, если у вас цикл отрицательного веса,
[58:49.060 --> 58:53.060]  а потом запустить какой-то алгоритм. Ну или, наоборот, в процессе работы алгоритма
[58:53.060 --> 58:56.060]  как-то определить наличие отрицательного цикла.
[58:56.060 --> 59:01.060]  Вопрос вам, как вы думаете, может ли как-то в процессе работы алгоритма Порда Белмана
[59:01.060 --> 59:04.060]  определить наличие или отсутствие цикла отрицательного веса?
[59:04.060 --> 59:24.060]  План нормальный, но, мне кажется, есть небольшой изъян.
[59:24.060 --> 59:32.060]  Давайте рассмотрим вот такой цикл.
[59:32.060 --> 59:37.060]  Допустим, 1, 1, 1, минус 10.
[59:37.060 --> 59:42.060]  На первой итерации я отрелаксирую вот это ребро.
[59:42.060 --> 59:44.060]  На второй итерации я отрелаксирую вот это ребро.
[59:44.060 --> 59:46.060]  На третьей итерации я отрелаксирую вот это ребро.
[59:46.060 --> 59:49.060]  А так как я делаю В-1 итерацию, то до этого ребра у меня дела вообще не дойдет.
[59:50.060 --> 59:54.060]  Понятно, что я имею в виду.
[59:54.060 --> 59:59.060]  То есть вроде как цикл отрицательного веса есть, но так как я делаю всего 3 итерации,
[59:59.060 --> 01:00:08.060]  то, соответственно, ребро отрицательного веса до него может в очередь даже не дойти.
[01:00:08.060 --> 01:00:12.060]  Есть еще предложение?
[01:00:13.060 --> 01:00:19.060]  Смотрите, можно на самом деле воспользоваться просто доказательством той теоремы.
[01:00:19.060 --> 01:00:21.060]  Что нам теорема утверждала?
[01:00:21.060 --> 01:00:26.060]  Теорема утверждала следующее, что если у нас задача поставлена корректно,
[01:00:26.060 --> 01:00:30.060]  то алгоритм все корректно найдет.
[01:00:30.060 --> 01:00:34.060]  И что из этого следует?
[01:00:34.060 --> 01:00:38.060]  Как вы думаете, алгоритм как работает?
[01:00:38.060 --> 01:00:41.060]  Я делаю В-1 итерацию, релаксирую все ребра и на этом завершаю работу.
[01:00:41.060 --> 01:00:46.060]  А как вы думаете, что произойдет, если, скажем, я релаксирую чуть дольше,
[01:00:46.060 --> 01:00:55.060]  как и в жизни, то если я сделаю процедуру релакс еще несколько раз?
[01:00:59.060 --> 01:01:04.060]  Если мы точно знаем, что за В-1 итерацию мы находим все корректно,
[01:01:04.060 --> 01:01:07.060]  то следующие итерации ничего нового мне не должны дать, согласны?
[01:01:07.060 --> 01:01:11.060]  Какая разница? Я сделаю В-1 итерацию, В-2 итерацию, ничего мне не изменится.
[01:01:11.060 --> 01:01:15.060]  Я уже нашел все кратчайшие пути, у меня граф стабилизировался,
[01:01:15.060 --> 01:01:18.060]  больше ничего более короткого найти нельзя.
[01:01:18.060 --> 01:01:20.060]  Но если у меня есть циклы отрицательного веса,
[01:01:20.060 --> 01:01:22.060]  как вы думаете, будет ли что-то меняться или нет?
[01:01:22.060 --> 01:01:25.060]  Скорее всего, будет, и это является примером.
[01:01:25.060 --> 01:01:29.060]  Я сделал три итерации, вроде как на этом алгоритм завершился.
[01:01:29.060 --> 01:01:33.060]  А если я уже сделаю еще одну итерацию, то тут уже возникнет проблема.
[01:01:33.060 --> 01:01:36.060]  Я найду еще более короткий путь, хотя мне теорема утверждала,
[01:01:36.060 --> 01:01:38.060]  что за В-1 итерацию я все найду.
[01:01:38.060 --> 01:01:43.060]  Идея краски заключается в том, чтобы просто выполнить
[01:01:43.060 --> 01:01:46.060]  еще одну итерацию релаксации всех ребер.
[01:01:46.060 --> 01:01:49.060]  То есть, вот это обычный Форд Белман.
[01:01:49.060 --> 01:01:52.060]  То есть, мы В-1 шаг, релаксируем все ребра.
[01:01:52.060 --> 01:01:55.060]  А после того, как мы все ребра отрелаксировали В-1 раз,
[01:01:55.060 --> 01:01:58.060]  выполним еще один раз процедуру релаксации всех ребер.
[01:01:58.060 --> 01:02:03.060]  И вот если на этой дополнительной итерации у нас хотя бы одно ребро релаксируется,
[01:02:03.060 --> 01:02:06.060]  то значит у нас есть цикл отрицательного веса.
[01:02:06.060 --> 01:02:07.020]  Если нет, то нет.
[01:02:07.020 --> 01:02:11.020]  Идея понятна?
[01:02:11.020 --> 01:02:13.020]  Это мысль довольно неочевидна.
[01:02:13.020 --> 01:02:17.020]  Оно вроде как звучит разумно, но и не очевидно.
[01:02:17.020 --> 01:02:19.020]  Если у меня есть цикл отрицательного веса,
[01:02:19.020 --> 01:02:21.020]  то на этой итерации у меня обязательно что-то пререлаксируется
[01:02:21.020 --> 01:02:22.020]  И наоборот.
[01:02:22.020 --> 01:02:24.020]  То есть, верно ли ut если что-то прелаксировалось,
[01:02:24.020 --> 01:02:26.020]  то у меня есть обязательно цикл отрицательного веса.
[01:02:26.020 --> 01:02:27.020]  57
[01:02:27.020 --> 01:02:30.020]  Это надо доказывать, чем мы сейчас займемся.
[01:02:30.020 --> 01:02:33.020]  Алгоритм корректно определяет наличие отсутствия цикла отрицательного веса,
[01:02:33.020 --> 01:02:38.020]  Ну, алгоритм выше. Давайте доказывать.
[01:02:38.020 --> 01:02:44.020]  Ну, давайте так. Первый шаг.
[01:02:44.020 --> 01:02:49.020]  Если отрицательного цикла нет,
[01:02:49.020 --> 01:02:55.020]  то у теориями 1
[01:02:55.020 --> 01:03:02.020]  после v-1 итерации
[01:03:02.020 --> 01:03:07.020]  все пути,
[01:03:07.020 --> 01:03:12.020]  все кратчайшие пути
[01:03:12.020 --> 01:03:17.020]  найдены.
[01:03:17.020 --> 01:03:22.020]  И дальнейшие итерации
[01:03:22.020 --> 01:03:27.020]  ничего не изменят.
[01:03:27.020 --> 01:03:32.020]  Ну, это следует просто на практике скорректности алгоритма.
[01:03:32.020 --> 01:03:37.020]  Да, что если у меня нет циклов отрицательного веса, то, соответственно,
[01:03:37.020 --> 01:03:42.020]  за v-1 итерацию я все найду, но дальнейшие итерации мне ничего не дадут.
[01:03:42.020 --> 01:03:47.020]  Ну, самое интересное, это второй пункт, что если у меня есть цикл отрицательного веса?
[01:03:47.020 --> 01:03:52.020]  Если есть цикл отрицательного веса.
[01:03:52.020 --> 01:03:57.020]  Вообще говоря, не очевидно, что если у меня есть цикл отрицательного веса,
[01:03:57.020 --> 01:04:02.020]  почему именно на бета итерации у меня обязательно что-то прелаксируется, согласны?
[01:04:02.020 --> 01:04:07.020]  Ну, давайте я это докажу. Вот рассмотрим его.
[01:04:07.020 --> 01:04:12.020]  Ну, пусть от цикл v-1, v-2 и т.д.
[01:04:12.020 --> 01:04:17.020]  vk.
[01:04:17.020 --> 01:04:22.020]  И допустим,
[01:04:22.020 --> 01:04:27.020]  допустим, не случилось
[01:04:27.020 --> 01:04:32.020]  ни одной релаксации.
[01:04:38.020 --> 01:04:43.020]  Допустим, не случилось ни одной релаксации. Что это означает?
[01:04:43.020 --> 01:04:48.020]  Вот, то есть, д v2 меньше
[01:04:48.020 --> 01:04:53.020]  либо равно, чем d v1 плюс w v1 v2,
[01:04:53.020 --> 01:04:58.020]  то есть, я реалксировал в это ребро, но оно не было отреалксировано.
[01:04:58.020 --> 01:05:03.020]  Дальше, d v3 меньше либо равно, чем d v2
[01:05:03.020 --> 01:05:08.020]  плюс w v2 v3,
[01:05:08.020 --> 01:05:11.020]  То есть я релаксировал вот это ребро, и оно тоже не было отрелаксировано.
[01:05:11.020 --> 01:05:14.020]  Ну и так далее есть для всех ребров, запишу.
[01:05:14.020 --> 01:05:17.020]  Значит, в конце у меня будет вот это последнее ребро.
[01:05:17.020 --> 01:05:22.020]  То есть dv1 меньше равно, чем dvk
[01:05:22.020 --> 01:05:27.020]  плюс wvkv1.
[01:05:27.020 --> 01:05:29.020]  Согласны?
[01:05:29.020 --> 01:05:31.020]  То есть если у меня не случилась ни одной релаксации,
[01:05:31.020 --> 01:05:34.020]  то это означает, что эти ребра тоже не были релаксированы.
[01:05:34.020 --> 01:05:37.020]  А они не были релаксированы, так как у меня выполняются вот эти неравенства.
[01:05:37.020 --> 01:05:39.020]  Да?
[01:05:39.020 --> 01:05:41.020]  Окей?
[01:05:41.020 --> 01:05:43.020]  А теперь давайте сделаем следующий вид.
[01:05:43.020 --> 01:05:45.020]  Давайте просто возьмём эти неравенства с ложем.
[01:05:47.020 --> 01:05:48.020]  Окей?
[01:05:48.020 --> 01:05:50.020]  Просумируем.
[01:05:52.020 --> 01:05:54.020]  Не-не-не, просто вот взяли цикл,
[01:05:54.020 --> 01:05:57.020]  мы просто пронумеровали по движению цикла.
[01:06:00.020 --> 01:06:02.020]  Ну а это неважно.
[01:06:02.020 --> 01:06:04.020]  Я же тут не предполагал,
[01:06:04.020 --> 01:06:07.020]  давайте я просто наоборот все эти неравенства переставлю в другом порядке.
[01:06:09.020 --> 01:06:12.020]  Я просто говорю, что для каждого ребра у меня не выполнилось релаксация,
[01:06:12.020 --> 01:06:15.020]  значит для каждого ребра выполнялось такое соотношение.
[01:06:15.020 --> 01:06:17.020]  Что произойдёт, если я всё просуммирую?
[01:06:27.020 --> 01:06:29.020]  Что у меня будет слева?
[01:06:32.020 --> 01:06:34.020]  Сумма всех ДВИ, да?
[01:06:34.020 --> 01:06:36.020]  Сумма по всем вершинам.
[01:06:36.020 --> 01:06:38.020]  Вот из этого цикла.
[01:06:38.020 --> 01:06:40.020]  Сумма
[01:06:40.020 --> 01:06:42.020]  ДВИ
[01:06:42.020 --> 01:06:44.020]  ну и от изницы до ка.
[01:06:46.020 --> 01:06:48.020]  Ну а неравенство сохраняется.
[01:06:48.020 --> 01:06:50.020]  А что будет справа?
[01:06:50.020 --> 01:06:52.020]  Та же самая сумма ДВИ, да?
[01:06:52.020 --> 01:06:54.020]  И сумма всех ребр.
[01:06:54.020 --> 01:06:56.020]  Ну сумма весов всех ребр.
[01:06:56.020 --> 01:06:58.020]  Та же самая сумма
[01:06:58.020 --> 01:07:00.020]  ДВИ
[01:07:00.020 --> 01:07:02.020]  плюс сумма
[01:07:02.020 --> 01:07:04.020]  ВИ
[01:07:12.020 --> 01:07:14.020]  ВИ
[01:07:14.020 --> 01:07:16.020]  ВИ плюс 1.
[01:07:18.020 --> 01:07:20.020]  Ну понятно,
[01:07:20.020 --> 01:07:22.020]  предполагаем, что давайте напишем, что
[01:07:22.020 --> 01:07:24.020]  ВК плюс 1
[01:07:24.020 --> 01:07:26.020]  предполагаем равным В1.
[01:07:26.020 --> 01:07:28.020]  Так.
[01:07:28.020 --> 01:07:30.020]  И что дальше делаем?
[01:07:34.020 --> 01:07:36.020]  Ну шлёп-шлёп, да, вот.
[01:07:36.020 --> 01:07:38.020]  Это сокращается, это сокращается.
[01:07:38.020 --> 01:07:40.020]  Получаем ноль. Меньше равно, чем сумма
[01:07:40.020 --> 01:07:42.020]  ВВ, ВИ
[01:07:42.020 --> 01:07:44.020]  ВИ плюс 1.
[01:07:44.020 --> 01:07:46.020]  О!
[01:07:46.020 --> 01:07:48.020]  А что такое?
[01:07:48.020 --> 01:07:50.020]  Да, вы же предположили,
[01:07:50.020 --> 01:07:52.020]  что есть цикл отрицательного веса.
[01:07:52.020 --> 01:07:54.020]  Более того, вот он.
[01:07:54.020 --> 01:07:56.020]  Мы сказали, бот — это цикл отрицательного веса.
[01:07:56.020 --> 01:07:58.020]  Давайте мы его рассмотрим.
[01:07:58.020 --> 01:08:00.020]  Предположили, что не случилось ни одной релаксации
[01:08:00.020 --> 01:08:02.020]  и доказали, что на самом деле цикл отрицательного веса
[01:08:02.020 --> 01:08:04.020]  ни фига не цикл отрицательного веса.
[01:08:04.020 --> 01:08:06.020]  Понятно?
[01:08:06.020 --> 01:08:08.020]  Ну всё.
[01:08:08.020 --> 01:08:10.020]  Говорить же
[01:08:10.020 --> 01:08:12.020]  Ну, следовательно, соответственно, хотя бы одна
[01:08:12.020 --> 01:08:14.020]  релаксация обязательно должна
[01:08:14.020 --> 01:08:16.020]  случиться. Понятно?
[01:08:16.020 --> 01:08:18.020]  Ну всё.
[01:08:18.020 --> 01:08:20.020]  Соответственно,
[01:08:20.020 --> 01:08:22.020]  корректность обосновали.
[01:08:26.020 --> 01:08:28.020]  Вопросы?
[01:08:34.020 --> 01:08:36.020]  Так, что у нас по времени?
[01:08:38.020 --> 01:08:40.020]  Так, есть ли вопросы?
[01:08:42.020 --> 01:08:44.020]  Окей, тогда давайте
[01:08:44.020 --> 01:08:46.020]  давайте, давайте, давайте
[01:08:46.020 --> 01:08:48.020]  посмотрим ещё
[01:08:48.020 --> 01:08:50.020]  кое-что.
[01:08:52.020 --> 01:08:54.020]  Значит, вот тут задавали вопрос про то,
[01:08:54.020 --> 01:08:56.020]  а можно ли лучше?
[01:08:56.020 --> 01:08:58.020]  Вот у нас есть алгоритм Форда Белмана,
[01:08:58.020 --> 01:09:00.020]  ну или Белмана Форда,
[01:09:00.020 --> 01:09:02.020]  который работает за ВАЕ.
[01:09:02.020 --> 01:09:04.020]  Можно ли лучше?
[01:09:04.020 --> 01:09:06.020]  Опять же, как я уже сказал, лучше можно,
[01:09:06.020 --> 01:09:08.020]  но как бы
[01:09:08.020 --> 01:09:10.020]  улучшения касаются только, скажем,
[01:09:10.020 --> 01:09:12.020]  каких-то эвристик или улучшений
[01:09:12.020 --> 01:09:14.020]  в какое-то константное количество раз.
[01:09:14.020 --> 01:09:16.020]  Вот давайте их обсудим,
[01:09:16.020 --> 01:09:18.020]  если всё успеем.
[01:09:18.020 --> 01:09:20.020]  Значит, есть?
[01:09:20.020 --> 01:09:22.020]  Соответственно,
[01:09:22.020 --> 01:09:24.020]  алгоритм под названием
[01:09:24.020 --> 01:09:26.020]  Shortest Faster Algorithm,
[01:09:26.020 --> 01:09:28.020]  то есть SPFA, ну или под названием
[01:09:28.020 --> 01:09:30.020]  более известный как SPFA,
[01:09:30.020 --> 01:09:32.020]  это алгоритм, который основан на алгоритме
[01:09:32.020 --> 01:09:34.020]  Белмана Форда, но
[01:09:34.020 --> 01:09:36.020]  добавляет просто некоторую эвристику,
[01:09:36.020 --> 01:09:38.020]  некоторые улучшения.
[01:09:38.020 --> 01:09:40.020]  Ну смотрите, в чём проблема?
[01:09:40.020 --> 01:09:42.020]  Тут же всё написано, в общем, согласитесь,
[01:09:42.020 --> 01:09:44.020]  что мы, когда релаксируем все ребра,
[01:09:44.020 --> 01:09:46.020]  мы довольно часто
[01:09:46.020 --> 01:09:48.020]  выполняем действия впустую.
[01:09:48.020 --> 01:09:50.020]  Ну то есть, на самом деле у нас,
[01:09:50.020 --> 01:09:52.020]  если посмотреть на то, как работает алгоритм
[01:09:52.020 --> 01:09:54.020]  форда Белмана, вообще говоря, у нас очень часто возникает
[01:09:54.020 --> 01:09:56.020]  такая ситуация, что мы делаем бесполезную
[01:09:56.020 --> 01:09:58.020]  релаксацию. Но бесполезная в том смысле, что
[01:09:58.020 --> 01:10:00.020]  релаксация не успешная.
[01:10:00.020 --> 01:10:02.020]  Ну действительно, смотрите, в чём соль.
[01:10:02.020 --> 01:10:04.020]  Вот, было у меня ребро ВУ.
[01:10:12.020 --> 01:10:14.020]  И соответственно, в какой-то итерации
[01:10:14.020 --> 01:10:16.020]  я попытался отрелаксировать ребро ВУ.
[01:10:16.020 --> 01:10:18.020]  Ну, релаксация была неуспешной.
[01:10:18.020 --> 01:10:20.020]  Допустим, мы перешли на следующую итерацию,
[01:10:20.020 --> 01:10:22.020]  но при этом мы знаем следующую вещь.
[01:10:22.020 --> 01:10:24.020]  Допустим, мы знаем, что расстояние до вершины В
[01:10:24.020 --> 01:10:26.020]  никак не изменилось.
[01:10:26.020 --> 01:10:28.020]  Вопрос, имеет ли смысл
[01:10:28.020 --> 01:10:30.020]  снова делать релаксацию ребра ВУ?
[01:10:34.020 --> 01:10:36.020]  Ну нет, да, почему? Потому что
[01:10:36.020 --> 01:10:38.020]  на предыдущей итерации я написал
[01:10:38.020 --> 01:10:40.020]  то ДУ, ну это минимум,
[01:10:40.020 --> 01:10:42.020]  из ДУ
[01:10:42.020 --> 01:10:44.020]  и D от В
[01:10:44.020 --> 01:10:46.020]  плюс
[01:10:46.020 --> 01:10:48.020]  ДУ.
[01:10:48.020 --> 01:10:50.020]  Вот.
[01:10:50.020 --> 01:10:52.020]  То есть на предыдущей итерации я это уже отрелаксировал.
[01:10:52.020 --> 01:10:54.020]  Вот.
[01:10:54.020 --> 01:10:56.020]  А если, если у меня в течение этой итерации
[01:10:56.020 --> 01:10:58.020]  расстояние до вершины В не изменилось,
[01:10:58.020 --> 01:11:00.020]  то и вот эта штука тоже не могла измениться.
[01:11:00.020 --> 01:11:02.020]  Да, соответственно,
[01:11:02.020 --> 01:11:04.020]  релаксировать с этим ребром не имеет никакого смысла. Согласны?
[01:11:04.020 --> 01:11:06.020]  Поэтому издевать довольно естественная идея.
[01:11:06.020 --> 01:11:08.020]  А давайте релаксировать только те ребра,
[01:11:08.020 --> 01:11:10.020]  которые торчат из вершин,
[01:11:10.020 --> 01:11:12.020]  расстояние до которых реально поменялось.
[01:11:12.020 --> 01:11:14.020]  Потому что если расстояние до вершин не поменялось,
[01:11:14.020 --> 01:11:16.020]  то релаксировать из него я тоже ничего не смогу.
[01:11:16.020 --> 01:11:18.020]  Окей?
[01:11:18.020 --> 01:11:20.020]  Собственно, вот в этом и заключается
[01:11:20.020 --> 01:11:22.020]  идея алгоритма СПФ.
[01:11:22.020 --> 01:11:24.020]  И на самом деле алгоритм СПФ внезапно очень похож на алгоритм BFS.
[01:11:24.020 --> 01:11:26.020]  По сути, он его повторяет.
[01:11:26.020 --> 01:11:28.020]  То есть у меня есть массив расстояния,
[01:11:28.020 --> 01:11:30.020]  есть массив предков,
[01:11:30.020 --> 01:11:32.020]  и есть некоторая очередь.
[01:11:32.020 --> 01:11:34.020]  Очередь вершин, до расстояния которых у меня поменялось.
[01:11:34.020 --> 01:11:36.020]  Вот.
[01:11:36.020 --> 01:11:38.020]  Соответственно, я пишу,
[01:11:38.020 --> 01:11:40.020]  что пока у меня очередь не опустела,
[01:11:40.020 --> 01:11:42.020]  я достаю вершину из очереди,
[01:11:42.020 --> 01:11:44.020]  и отрелаксирую ее соседям.
[01:11:44.020 --> 01:11:46.020]  Если, соответственно, у меня удалось отрелаксировать ребро ВУ,
[01:11:46.020 --> 01:11:48.020]  то я добавляю вершину У в очередь.
[01:11:48.020 --> 01:11:50.020]  Но почему я ее добавляю в очередь?
[01:11:50.020 --> 01:11:52.020]  Потому что я говорю, что расстояние до вершины У у меня изменилось.
[01:11:52.020 --> 01:11:54.020]  Соответственно, теоретически из нее я смогу еще что-то прелаксировать.
[01:11:54.020 --> 01:11:56.020]  Понятно?
[01:12:00.020 --> 01:12:02.020]  Ну, на самом деле...
[01:12:02.020 --> 01:12:04.020]  Ну, на самом деле нет.
[01:12:04.020 --> 01:12:06.020]  Наверное.
[01:12:08.020 --> 01:12:10.020]  Ну, кажется, нет.
[01:12:10.020 --> 01:12:12.020]  Да.
[01:12:12.020 --> 01:12:14.020]  Хотя, стойте.
[01:12:18.020 --> 01:12:20.020]  Ну, в общем, надо подумать.
[01:12:24.020 --> 01:12:26.020]  Я могу пояснить, почему работает алгоритм с очередью.
[01:12:26.020 --> 01:12:28.020]  Потому что мы таким образом моделируем
[01:12:28.020 --> 01:12:30.020]  основной алгоритм Форда Белмана.
[01:12:30.020 --> 01:12:32.020]  Потому что если мы релаксируем все ребра,
[01:12:32.020 --> 01:12:34.020]  то у меня изначально в очереди находятся
[01:12:34.020 --> 01:12:36.020]  только те вершины, до которых я...
[01:12:36.020 --> 01:12:38.020]  В общем, такая ситуация.
[01:12:40.020 --> 01:12:42.020]  Вершина С, из нее торчат какие-то ребра.
[01:12:44.020 --> 01:12:46.020]  И вот что обычный Форд Белман
[01:12:46.020 --> 01:12:48.020]  с алгоритмом СПФ
[01:12:48.020 --> 01:12:50.020]  обновит расстояние вот до этих вершин.
[01:12:52.020 --> 01:12:54.020]  Понятно?
[01:12:54.020 --> 01:12:56.020]  На следующей трассе я возьму вот эти вершины
[01:12:56.020 --> 01:12:58.020]  и, соответственно, с помощью них буду обновлять
[01:12:58.020 --> 01:13:00.020]  другие расстояния.
[01:13:00.020 --> 01:13:02.020]  Естественно, что алгоритм СПФ, что алгоритм Форда Белмана
[01:13:02.020 --> 01:13:04.020]  тоже по сути построит вот такие вот
[01:13:04.020 --> 01:13:06.020]  новые вершины и так далее.
[01:13:06.020 --> 01:13:08.020]  Вот.
[01:13:08.020 --> 01:13:10.020]  Что Испорт действительно использует вместо очереди С
[01:13:10.020 --> 01:13:12.020]  так я не могу, но кажется, что все будет нормально.
[01:13:12.020 --> 01:13:14.020]  Этот вопрос можно поисследовать.
[01:13:14.020 --> 01:13:16.020]  Ну, в целом, понятно, да?
[01:13:16.020 --> 01:13:18.020]  Идея.
[01:13:18.020 --> 01:13:20.020]  Ну, смотрите, в общем случае
[01:13:20.020 --> 01:13:22.020]  асимптотика также остается от В плюс Е.
[01:13:22.020 --> 01:13:24.020]  То есть, опять же, в худшем случае у меня будет
[01:13:24.020 --> 01:13:26.020]  В итерация.
[01:13:26.020 --> 01:13:28.020]  На каждой итерации в худшем случае я сделаю
[01:13:28.020 --> 01:13:30.020]  е-релаксации.
[01:13:30.020 --> 01:13:32.020]  Ну, на практике на случайных графах работает быстрее.
[01:13:32.020 --> 01:13:34.020]  На случайных графах в среднем работает
[01:13:34.020 --> 01:13:36.020]  за от Е, то есть, за ней на от количества ребер
[01:13:36.020 --> 01:13:38.020]  время.
[01:13:38.020 --> 01:13:40.020]  Окей, да?
[01:13:40.020 --> 01:13:42.020]  То есть, алгоритм СПФ
[01:13:42.020 --> 01:13:44.020]  полностью эквалиден алгоритмом Форда Белмана
[01:13:44.020 --> 01:13:46.020]  с в среднем чуть более
[01:13:46.020 --> 01:13:48.020]  лучшей, ну как,
[01:13:48.020 --> 01:13:50.020]  случайных графов с лучшей асимптотикой.
[01:13:50.020 --> 01:13:52.020]  Ну, а в случае там обычно графов
[01:13:52.020 --> 01:13:54.020]  в среднем константа чуть более
[01:13:54.020 --> 01:13:56.020]  приятная. Вот.
[01:14:00.020 --> 01:14:02.020]  Да, вот тут, кстати,
[01:14:02.020 --> 01:14:04.020]  не понятно, как проверять наличие такого
[01:14:04.020 --> 01:14:06.020]  веса, но тут на самом деле можно
[01:14:08.020 --> 01:14:10.020]  просто хранить
[01:14:10.020 --> 01:14:12.020]  для каждой вершины
[01:14:12.020 --> 01:14:14.020]  хранить количество раз
[01:14:14.020 --> 01:14:16.020]  сколько раз я обновил расстояние до этой вершины.
[01:14:16.020 --> 01:14:18.020]  Как только я превысил какой-то определенный
[01:14:18.020 --> 01:14:20.020]  порог, то есть, я понимаю, что
[01:14:20.020 --> 01:14:22.020]  до вершины я не могу обновить расстояние больше
[01:14:22.020 --> 01:14:24.020]  определенного количества раз.
[01:14:24.020 --> 01:14:26.020]  Можно считать по количеству итераций.
[01:14:26.020 --> 01:14:28.020]  Смотрите, я точно знаю, что
[01:14:28.020 --> 01:14:30.020]  в худшем случае
[01:14:30.020 --> 01:14:32.020]  в корректном
[01:14:32.020 --> 01:14:34.020]  корректном алгоритме
[01:14:34.020 --> 01:14:36.020]  у меня будет не более чем
[01:14:38.020 --> 01:14:40.020]  v-1 на e итерация, v-1 на e релактация.
[01:14:40.020 --> 01:14:42.020]  Ну, согласна.
[01:14:42.020 --> 01:14:44.020]  Соответственно, если как только у меня появляется v-1
[01:14:44.020 --> 01:14:46.020]  умножить на e плюс первая итерация,
[01:14:46.020 --> 01:14:48.020]  то это значит, что все, я точно куда-то не туда поехал.
[01:14:52.020 --> 01:14:54.020]  Так. Но остальные улучшения
[01:14:54.020 --> 01:14:56.020]  давайте поговорим в следующий раз,
[01:14:56.020 --> 01:14:58.020]  начнем с них. Перерыв.
