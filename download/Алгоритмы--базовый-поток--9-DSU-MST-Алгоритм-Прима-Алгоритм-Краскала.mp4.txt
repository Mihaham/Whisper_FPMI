[00:00.000 --> 00:10.000]  Своиста дерева. Своиста дерева состоит в том, что у каждого элемента ровно один родитель.
[00:10.000 --> 00:14.000]  Давайте просто обрабатываем нашу кукуту.
[00:14.000 --> 00:21.000]  Выведем размер, который совпадает со размером общей системы непосекающих новостей, то есть общего количества элементов.
[00:21.000 --> 00:27.000]  И просто для каждого элемента в ячейке массива будем хранить его родителя.
[00:27.000 --> 00:33.000]  Для любого элемента родителем является двойка, поэтому написано двойка.
[00:33.000 --> 00:38.000]  Для четверки родителем является восьмерка, поэтому тут записано восьмерка.
[00:38.000 --> 00:41.000]  И так далее.
[00:41.000 --> 00:48.000]  Аналогично в этой структуре данных можно помечать узлы, которые являются корнями.
[00:48.000 --> 00:56.000]  Например, тут представлен вариант, когда вы говорите, что у вас корень зациклен сам на себя.
[00:56.000 --> 01:01.000]  Если родителем элемента является эта вершина, то соответственно этот корень.
[01:01.000 --> 01:04.000]  Вы можете там представлять себе это другим образом.
[01:04.000 --> 01:06.000]  Либо хранить какие-то наны, либо минус единицу.
[01:06.000 --> 01:10.000]  Просто каким-то образом вы помечаете, что это корень дерева, то есть выше уже подняться нельзя.
[01:10.000 --> 01:16.000]  И вот таким образом я на самом деле представляю все дерева, которые есть в моей теме перескальшим родцам.
[01:16.000 --> 01:18.000]  Понятно?
[01:18.000 --> 01:22.000]  То есть всего лишь один массив, и я сразу же все понимаю.
[01:22.000 --> 01:28.000]  Допустим, на как-то удалось организовать все множество видов таких вот деревьев,
[01:28.000 --> 01:31.000]  и соответственно эту структуру данных очень легко представлять в виде просто массива,
[01:31.000 --> 01:37.000]  в каждом элементе, в этом индексе которого мы просто храним предка этого элемента.
[01:37.000 --> 01:40.000]  Надо посмотреть, вот для единицы шестерка, вот для единицы шестерка.
[01:40.000 --> 01:44.000]  Ну тройка соответственно корень, поэтому там хранить тройка ну либо минус единицы,
[01:44.000 --> 01:47.000]  либо как-то еще мы помечаем, что это корень.
[01:47.000 --> 01:49.000]  Другой вопрос.
[01:49.000 --> 01:52.000]  Другой вопрос, да.
[01:52.000 --> 01:54.000]  Другой вопрос стоит следующим образом.
[01:54.000 --> 01:58.000]  Ну хорошо, допустим у нас есть такая структура данных, давайте обсудим то,
[01:58.000 --> 02:00.000]  как можно выполнять те или иные операции.
[02:00.000 --> 02:03.000]  Понимаете ли вы, как можно выполнить операцию, например, make set?
[02:03.000 --> 02:05.000]  Как создать новое одноэлементное множество?
[02:07.000 --> 02:11.000]  Да, соответственно вот тут у нас в примере всего 9 элементов,
[02:11.000 --> 02:15.000]  соответственно мы создаем новую вершинку,
[02:15.000 --> 02:17.000]  ну и говорим, что это дерево зациклено само у себя.
[02:17.000 --> 02:20.000]  Вектор делаем pushback в девятке.
[02:20.000 --> 02:22.000]  То есть make set это просто pushback.
[02:22.000 --> 02:25.000]  На pushback вот в этот вектор родителей.
[02:25.000 --> 02:29.000]  Теперь соответственно давайте поговорим про find set.
[02:31.000 --> 02:34.000]  Нет, звездочками тут просто помечено, что это корни дерева.
[02:34.000 --> 02:37.000]  То есть тут имеется в виду, что вот тут вы можете поступать по-разному.
[02:37.000 --> 02:40.000]  То есть либо вершина может ссылаться само на себя,
[02:40.000 --> 02:42.000]  если она корень, можете там писать минус единицу,
[02:42.000 --> 02:43.000]  можете ставить на ан.
[02:43.000 --> 02:46.000]  В общем, каким-то образом просто умеете, что это корень.
[02:46.000 --> 02:49.000]  Ну тут для удобства я сделал так, что мне так удобнее,
[02:49.000 --> 02:51.000]  что вершина ссылается на само себя.
[02:51.000 --> 02:54.000]  Если вершина ссылается на само себя, значит у нас сама себе корень.
[02:54.000 --> 02:56.000]  Вот.
[02:56.000 --> 02:58.000]  Окей.
[02:58.000 --> 02:59.000]  Давайте теперь поговорим про другие операции.
[02:59.000 --> 03:02.000]  Ну короче, с make set все понятно, все просто
[03:02.000 --> 03:03.000]  давайте поговорим про find set.
[03:03.000 --> 03:06.000]  Давайте напомним, что такое find set.
[03:06.000 --> 03:09.000]  Значит find set возвращает некоторый идентификатор множества,
[03:09.000 --> 03:10.000]  в котором лежит x.
[03:10.000 --> 03:13.000]  Т.е. find set от x это идентификатор множца, в котором лежит x.
[03:13.000 --> 03:15.000]  То есть главное свойство find set – это то,
[03:15.000 --> 03:17.000]  что find set от x равно find set от y,
[03:17.000 --> 03:20.000]  тогда и только тогда, когда x и y лежат в одном множестве.
[03:20.000 --> 03:22.000]  Что можно возвращать в качестве ответа у find sets?
[03:22.000 --> 03:24.000]  Если у нас есть вот такая вот структура.
[03:24.000 --> 03:27.000]  Допустим я прошу find set от 5, и find set от 4.
[03:27.000 --> 03:31.000]  Что мне можно вернуть от 5 и от 4, чтобы как бы изменить
[03:31.000 --> 03:40.000]  чтобы их индексы совпадали. Если у нас каждое множество организованно в виде некоторого корневого дерева,
[03:40.000 --> 03:46.000]  то у всех вершин будет один общий корень, согласны? И поэтому если я для каждой вершины, для каждого элемента
[03:46.000 --> 03:52.000]  буду возвращать корень соответствующего дерева, то соответствующего элемента из одного множества будет один и тот же представитель.
[03:52.000 --> 03:59.000]  То есть, грубо говоря, это еще иногда называют представителями, а не родителями. У всех элементов здесь один общий представитель.
[03:59.000 --> 04:05.000]  Здесь у всех элементов один представитель – это шестерка, здесь у всех элементов один представитель – это тройка.
[04:05.000 --> 04:11.000]  Соответственно, мы для двух элементов возвращаем просто корень соответствующего дерева. Если корни различные, значит они лежат в разных множествах,
[04:11.000 --> 04:18.000]  если корни один и тот же, значит они лежат в одном множестве. Просто? Окей, давайте посмотрим, как это выглядит.
[04:18.000 --> 04:27.000]  Ну, соответственно, find set. Вот find set выглядит очень просто. Меня спросили find set от x, и я говорю, что пока у меня x не совпадает со своим собственным…
[04:27.000 --> 04:32.000]  пока x не является своим собственным представителем, то есть пока я не дошел до корня, я поднимаюсь наверх.
[04:32.000 --> 04:36.000]  Вот только я поднялся наверх, я возвращаю, собственно, x. Вот здесь сам корень.
[04:36.000 --> 04:43.000]  Ну и как вы понимаете, время работы одной операции find set – это от h от x, где h от x – это глубина, на которой находится элемент x.
[04:43.000 --> 04:52.000]  Прогласны? Окей. Следующая операция – это union. Давайте посмотрим… ну давайте нарисуем здесь картинку.
[04:52.000 --> 04:57.000]  Допустим, у меня есть какие-то два множества.
[05:02.000 --> 05:10.000]  Допустим, здесь x, тут y. Я говорю union x, y.
[05:10.000 --> 05:16.000]  Напомню, что делает union. Union объединяет два множества, то есть множество, в котором находится x, и множество, в котором находится y.
[05:16.000 --> 05:22.000]  То есть теперь эти элементы должны лежать в одном множестве, плюс все элементы, в которых они раньше держались, тоже должны лежать в одном множестве.
[05:22.000 --> 05:25.000]  То есть грубо говоря, я беру все это множество и должен объединиться со всем этим множеством.
[05:30.000 --> 05:39.000]  Да, и тут в этой постановке, в таком построении нашей структуры данных, тоже достаточно просто реализовать эту операцию.
[05:39.000 --> 05:43.000]  То есть достаточно просто, например, этот корень привязать к этому корню, ну либо наоборот.
[05:43.000 --> 05:46.000]  То есть достаточно всего лишь добавить одну ссылку. Согласны?
[05:58.000 --> 06:02.000]  Сейчас тут проблемы будут, но пока давайте просто поговорим про базовую реализацию.
[06:02.000 --> 06:04.000]  Базовая реализация действительно очень простая.
[06:05.000 --> 06:11.000]  Значит, во-первых, если я говорю union x, y, не нужно взять представителя x, a.
[06:11.000 --> 06:15.000]  Надо взять корень дерева, в котором лежит x, взять корень, в котором дерево, в котором лежит y,
[06:15.000 --> 06:21.000]  и, например, привязать дерево y к x.
[06:24.000 --> 06:27.000]  Ну либо наоборот, взять period от y равно x.
[06:34.000 --> 06:38.000]  Вот, да, это действительно хороший вопрос.
[06:38.000 --> 06:42.000]  Давайте пока констатируем тот факт, что время работы это theta от h от x плюс h от y.
[06:42.000 --> 06:46.000]  Почему? Потому что файнцет первый работает за h от x,
[06:46.000 --> 06:50.000]  второй файнцет работает за h от y, ну глубину находится y,
[06:50.000 --> 06:52.000]  ну а это, соответственно, вот единица, в этом ничего страшного.
[06:52.000 --> 06:55.000]  Соответственно, теперь понятно, как у нас возникают вот такие вот деревья.
[06:55.000 --> 06:57.000]  Как у нас строятся деревья, понятно.
[06:57.000 --> 07:03.000]  То есть изначально у нас есть просто набор отдельных вершин,
[07:04.000 --> 07:08.000]  а потом в какие-то моменты мы вызываем union и, соответственно,
[07:08.000 --> 07:12.000]  у нас возникают вот такие вот иерархические структуры.
[07:12.000 --> 07:15.000]  Понятно, да? Просто одно дерево подвешено к другому дереву,
[07:15.000 --> 07:18.000]  и, соответственно, у нас возникают вот такие вот конструкции.
[07:18.000 --> 07:22.000]  Понятно, да? Вот.
[07:22.000 --> 07:26.000]  Так, ну действительно, собственно, прозвучало уже небольшое опасение,
[07:26.000 --> 07:29.000]  ну как небольшое, большое опасение, которое заключалось в том, что,
[07:29.000 --> 07:32.000]  ну вообще говоря, если мы действуем вот по такой-то поискеме,
[07:32.000 --> 07:34.000]  то есть, ну окей, да, union работает,
[07:34.000 --> 07:39.000]  union работает, ну в смысле, вот, сама значимая часть union работает довольно быстро.
[07:39.000 --> 07:42.000]  Да, но вот find set у нас может работать теоретически долго. Почему?
[07:42.000 --> 07:45.000]  Потому что работает за глубину, за глубину соответствующей вершины.
[07:45.000 --> 07:48.000]  Да? Ну и, на самом деле, легко представить себе ситуацию,
[07:48.000 --> 07:53.000]  при которой у нас соответствующие деревья будут вырождаться в цепочку.
[07:53.000 --> 07:57.000]  Например, вот я сделал, я объединил вот так, ну давайте наоборот.
[07:58.000 --> 08:04.000]  Я объединил вот этот элемент вот этим элемент, привязал он к этому корню,
[08:04.000 --> 08:06.000]  дальше я решил объединить вот это дерево с вот этим деревом,
[08:06.000 --> 08:11.000]  и привязал вот так. Дальше объединил вот это дерево с вот этим элементом
[08:11.000 --> 08:13.000]  и учу такую ситуацию. Ну и так далее.
[08:13.000 --> 08:18.000]  В итоге у меня дерево вырождается в список.
[08:18.000 --> 08:21.000]  Соответственно, find set работает за линейное время от размера самого
[08:21.000 --> 08:23.000]  дерева или от размера самого множества.
[08:23.000 --> 08:26.000]  Ну естественно, это, наверное, не то, чего мы хотим.ering foundation.
[08:26.000 --> 08:30.000]  Давайте подумаем, как мы можем это улучшить.
[08:30.000 --> 08:34.000]  Ну да, проблема. Возможно, действительно, линейный рост глубинных деревьев.
[08:34.000 --> 08:38.000]  То есть у аташ вырождается вот это. То есть если у нас есть какая-то цепочка,
[08:38.000 --> 08:44.000]  и мы ее, соответственно, подвешиваем к дереву, то у нас длина цепочки, соответственно, увеличивается.
[08:44.000 --> 08:50.000]  Давайте подумаем, как это можно исправить.
[08:50.000 --> 08:54.000]  Ну, исправить на самом деле это очень просто.
[08:54.000 --> 09:00.000]  Ну, смотрите, какая у нас проблема тут возникает. Давайте переписуем.
[09:00.000 --> 09:04.000]  Вот, допустим, у меня есть какое-то очень большое дерево. Есть маленькое дерево.
[09:04.000 --> 09:08.000]  Ну, большое в смысле глубины и маленькое в смысле глубины.
[09:08.000 --> 09:12.000]  А какое дерево какому выгоднее всего подвешивать?
[09:12.000 --> 09:18.000]  Маленькое к большому или, наоборот, большое к маленькому?
[09:18.000 --> 09:22.000]  Да, маленькое к большому. Почему?
[09:22.000 --> 09:28.000]  Потому что если пусть здесь глубина этого дерева равна 10,
[09:28.000 --> 09:34.000]  а глубина этого дерева, скажем, равна 5,
[09:34.000 --> 09:36.000]  тогда когда мы подвешиваем маленькое дерево к большому,
[09:36.000 --> 09:40.000]  у нас глубина под дерева увеличивается на 1, и глубина всего дерева не изменяется никак.
[09:40.000 --> 09:46.000]  Потому что глубина была равна 10, и у того дерева она тоже стала равна 10-ти.
[09:46.000 --> 09:50.000]  Но если я поступлю наоборот, если я буду, наоборот, большое дерево подвешивать к маленькому,
[09:50.000 --> 09:58.000]  то возникает беда. У меня был большой поддерево глубины 10, и оно увеличило свою глубину на единицу.
[09:58.000 --> 10:04.000]  Соответственно, чтобы у меня максимальная глубина поддеревьев не увеличивалась,
[10:04.000 --> 10:07.000]  мне выгоднее подвешивать маленькое дерево к большому.
[10:07.000 --> 10:10.000]  В этом заключается ранговая ивристика.
[10:10.000 --> 10:18.000]  Что такое ранг? Ранг – это просто верхняя оценка на глубину дерева.
[10:18.000 --> 10:24.000]  Почему верхняя оценка станет понятна позже? Пока у нас ранг в точности будет совпадать с глубиной дерева.
[10:24.000 --> 10:29.000]  В последствии он станет просто верхней оценкой. Давайте считать, что ранг – это глубина дерева.
[10:29.000 --> 10:31.000]  К верхней оценке перейдем потом.
[10:31.000 --> 10:40.000]  Для каждой вершины храним ранг. Что такое ранг? Ранг – это глубина дерева, в котором глубина соответствующего под дерево.
[10:40.000 --> 10:45.000]  Что мы делаем? Переходим к корням деревьев.
[10:45.000 --> 10:48.000]  x равно фанцет от x, y равно фанцет от y.
[10:48.000 --> 10:51.000]  Перешли к корням деревьев x и y.
[10:51.000 --> 10:59.000]  Если глубина дерева x меньше, чем глубина дерева y, то подвешиваем x к y.
[10:59.000 --> 11:05.000]  Если ранг y меньше, чем ранг x, то подвешиваем y к x.
[11:05.000 --> 11:10.000]  Понятно ли последние условия else?
[11:10.000 --> 11:13.000]  На самом деле, картина не настолько радужная.
[11:13.000 --> 11:18.000]  Действительно, мы понимаем, что если мы маленькое дерево подвешиваем к большому, то у нас глубина не изменяется.
[11:18.000 --> 11:21.000]  А что делать, если у нас глубины одинаковые?
[11:21.000 --> 11:25.000]  Скажем, и тут 5, и тут 5.
[11:25.000 --> 11:28.000]  Ну да, именно оно.
[11:28.000 --> 11:34.000]  Если у вас глубина первого дерева меньше, чем второго, то мы первое подвешиваем к второму.
[11:34.000 --> 11:38.000]  Если глубина второго дерева меньше, чем глубина первого, то подвешиваем второе к первому.
[11:38.000 --> 11:44.000]  А если глубины одинаковые, то это единственная есть ситуация, когда нам все равно, что к чему подвешивать.
[11:44.000 --> 11:47.000]  У нас, как ни крути, глубина дерева увеличится на единицу.
[11:47.000 --> 11:56.000]  В последнем else это и написано, что если у меня все-таки ранги совпадают, то, например, я x подвешиваю к y, и ранг y увеличиваю на единицу.
[11:59.000 --> 12:01.000]  Что сделать?
[12:01.000 --> 12:03.000]  Да.
[12:13.000 --> 12:16.000]  Но тут проблема в том, что количество сыновей может быть большое.
[12:21.000 --> 12:26.000]  Если, короче говоря, у вас у корня количество сыновей увеличивается, когда вы это дерево будете подвешивать к другому,
[12:26.000 --> 12:31.000]  то, понятное дело, вам нужно будет пройтись еще, короче, снова по этим сыновьям, которых стало много,
[12:31.000 --> 12:34.000]  что, соответственно, увеличится темп-тотику.
[12:34.000 --> 12:38.000]  Мы, на самом деле, с этим поборемся, у нас получится хорошая темп-тотика, и без этого.
[12:38.000 --> 12:41.000]  Пока глубина увеличивается, это норм.
[12:41.000 --> 12:44.000]  То есть как бы это нормально.
[12:44.000 --> 12:49.000]  Мы либо увеличиваем количество детей, что на самом деле тоже плохо, либо увеличиваем глубину.
[12:49.000 --> 12:53.000]  И это не так страшно, как могло бы казаться.
[12:53.000 --> 13:00.000]  Утверждение состоит в том, что, если вы используете ранговую эваристику,
[13:00.000 --> 13:07.000]  то у вас размер дерева всегда больше равен, чем 2 в степени глубина этого самого дерева.
[13:10.000 --> 13:14.000]  Давайте докажем. На самом деле утверждение довольно простое.
[13:14.000 --> 13:17.000]  Доказывается по индукции.
[13:18.000 --> 13:21.000]  Изначально
[13:27.000 --> 13:30.000]  рамка x равен 0,
[13:30.000 --> 13:32.000]  и, соответственно,
[13:32.000 --> 13:35.000]  size of x равен 1.
[13:35.000 --> 13:42.000]  Ну, соответственно, понятное дело, что 1 больше равен, чем 0.
[13:43.000 --> 13:46.000]  Далее. Переход.
[13:50.000 --> 13:53.000]  Пусть, соответственно, для деревьев
[13:57.000 --> 14:00.000]  x вибрик
[14:00.000 --> 14:03.000]  верно следующее.
[14:06.000 --> 14:08.000]  Size of x
[14:08.000 --> 14:11.000]  больше равен, чем 2 в степени
[14:11.000 --> 14:14.000]  рамка x
[14:14.000 --> 14:19.000]  и size of y больше равен, чем 2 в степени
[14:19.000 --> 14:22.000]  рамка от y.
[14:22.000 --> 14:26.000]  А что, когда мы объединяем два дерева, что у нас происходит?
[14:26.000 --> 14:29.000]  Размер итогового дерева, давайте так напишем,
[14:29.000 --> 14:32.000]  size от объединения tx и ty
[14:32.000 --> 14:35.000]  точно совпадает с
[14:35.000 --> 14:38.000]  size x плюс
[14:38.000 --> 14:41.000]  size y.
[14:41.000 --> 14:44.000]  Значит, по предположению, это все больше или равно, чем 2 в степени
[14:44.000 --> 14:46.000]  давайте так напишу, r от x
[14:46.000 --> 14:49.000]  плюс 2 в степени r от y.
[14:53.000 --> 14:56.000]  А это, соответственно, больше или равно
[14:56.000 --> 14:59.000]  давайте без ограничений общности
[14:59.000 --> 15:02.000]  считать, что r от x
[15:02.000 --> 15:05.000]  больше или равно, чем r от y.
[15:05.000 --> 15:08.000]  Тогда что происходит?
[15:08.000 --> 15:11.000]  Когда я меньше под дерево подвешиваю к большему под дерево,
[15:11.000 --> 15:14.000]  у меня глубина не увеличивается.
[15:14.000 --> 15:17.000]  А если у меня r от x равно r от y,
[15:17.000 --> 15:20.000]  то у меня глубина может увеличиться на единицу.
[15:20.000 --> 15:23.000]  Согласно, что вот тут я могу написать следующую вещь.
[15:23.000 --> 15:26.000]  Я могу написать, что это больше или равно, чем 2 r от x
[15:26.000 --> 15:29.000]  плюс 1.
[15:30.000 --> 15:33.000]  На самом деле, я это могу написать просто так, давайте так напишем.
[15:37.000 --> 15:40.000]  Да, спасибо.
[15:46.000 --> 15:49.000]  2 r от y плюс 1.
[15:52.000 --> 15:55.000]  Что еще раз?
[15:55.000 --> 15:58.000]  Нет, r от x больше или равно, чем r от y.
[16:00.000 --> 16:03.000]  Вот.
[16:03.000 --> 16:06.000]  Вот-вот-вот.
[16:11.000 --> 16:14.000]  Так, что мы хотели? Мы бы хотели доказать,
[16:14.000 --> 16:17.000]  говоря, что это...
[16:17.000 --> 16:20.000]  Так, если у нас r от x больше или равно, чем r от y,
[16:20.000 --> 16:23.000]  то мы, соответственно, y подвешиваем к x.
[16:29.000 --> 16:32.000]  Так, тогда размер...
[16:54.000 --> 16:57.000]  Что?
[16:59.000 --> 17:02.000]  Да-да-да, давайте так, давайте так поступим.
[17:02.000 --> 17:05.000]  Давайте так поступим.
[17:08.000 --> 17:11.000]  Так, значит, вот это верно.
[17:11.000 --> 17:14.000]  Теперь давайте рассмотрим два случая.
[17:14.000 --> 17:17.000]  Если у нас,
[17:17.000 --> 17:20.000]  если у нас,
[17:20.000 --> 17:23.000]  если у нас,
[17:23.000 --> 17:26.000]  если у нас,
[17:26.000 --> 17:29.000]  если у нас,
[17:29.000 --> 17:32.000]  если у нас r от x
[17:32.000 --> 17:35.000]  больше, чем r от y,
[17:35.000 --> 17:38.000]  вот, то что у нас получается?
[17:38.000 --> 17:41.000]  Мы тогда, соответственно, под дерево y
[17:41.000 --> 17:44.000]  подвешиваем к x.
[17:44.000 --> 17:47.000]  Вот.
[17:47.000 --> 17:50.000]  И, соответственно, вот эта вещь тогда у нас априори
[17:50.000 --> 17:53.000]  будет больше или равна, чем...
[17:53.000 --> 17:56.000]  от степени r от tx объединенное.
[17:56.000 --> 17:59.000]  Так, давайте так пушу.
[17:59.000 --> 18:02.000]  Это больше или равно, чем 2r от x.
[18:02.000 --> 18:05.000]  Вот, да, давайте так, давайте так сделаем.
[18:08.000 --> 18:11.000]  Все, получили такое соотношение.
[18:11.000 --> 18:14.000]  Значит, дальше давайте напишем так.
[18:14.000 --> 18:17.000]  Первое, если r от x
[18:17.000 --> 18:20.000]  больше, чем r от y,
[18:20.000 --> 18:23.000]  то r от tx плюс
[18:23.000 --> 18:26.000]  объединенность ty
[18:26.000 --> 18:29.000]  объединенность ty
[18:29.000 --> 18:32.000]  равно r от x, согласны?
[18:32.000 --> 18:35.000]  Вот. Ну а, соответственно,
[18:35.000 --> 18:38.000]  2r от x
[18:38.000 --> 18:41.000]  плюс 2r от y
[18:41.000 --> 18:44.000]  больше или равно, чем r от tx
[18:44.000 --> 18:47.000]  объединенность ty
[18:48.000 --> 18:51.000]  Вот. Это очевидно, да?
[18:56.000 --> 18:59.000]  2 в степени, да, 2 в степени r от x.
[18:59.000 --> 19:02.000]  Тут 2 в степени r и 2 в степени r от x.
[19:02.000 --> 19:05.000]  Окей? То есть, неравенство выполнено.
[19:05.000 --> 19:08.000]  То есть, я доказал, что размер объединения двух деревьев
[19:08.000 --> 19:11.000]  больше или равно, чем 2 в степени rank этого дерева.
[19:11.000 --> 19:14.000]  Ну а, соответственно, второй случай,
[19:14.000 --> 19:17.000]  равен r от y. Ну, точнее, тут, понятное дело, есть симметричный случай,
[19:17.000 --> 19:20.000]  когда r от y больше, чем r от x, но аналогично абсолютно.
[19:20.000 --> 19:23.000]  А если ранги равны, то, соответственно,
[19:23.000 --> 19:26.000]  что у меня получается? У меня получается, что 2r от x
[19:26.000 --> 19:29.000]  плюс 2r от y
[19:29.000 --> 19:32.000]  равно 2 в степени r от x плюс 1.
[19:32.000 --> 19:35.000]  Но когда я объединяю
[19:35.000 --> 19:38.000]  два дерева с одинаковым рангом, у меня ранг увеличивается на единицу.
[19:38.000 --> 19:41.000]  То есть, r от x плюс 1 – это в точности есть ранг
[19:41.000 --> 19:44.000]  объединенного дерева. То есть, равно 2 в степени r
[19:44.000 --> 19:47.000]  от x объединенной с t y.
[19:57.000 --> 20:00.000]  Ну да, собственно, рассмотрим два случая.
[20:00.000 --> 20:03.000]  Если r от x больше, чем r от y, то, соответственно,
[20:03.000 --> 20:06.000]  r от объединенного дерева – это есть r от x.
[20:06.000 --> 20:09.000]  Но, соответственно, понятное дело, что по предположению индукции
[20:09.000 --> 20:12.000]  два ранга 2 в степени r от x плюс 2 в степени r от y
[20:12.000 --> 20:15.000]  больше равен, чем r от x.
[20:15.000 --> 20:18.000]  А если ранги равны, то, соответственно, сумма рангов будет равна
[20:18.000 --> 20:21.000]  2 в степени r от x плюс 1, а это в точности совпадает новому рангу.
[20:21.000 --> 20:24.000]  Потому что, когда у меня ранги равны, у меня ранг
[20:24.000 --> 20:27.000]  итоговый дерево увеличивается на единицу.
[20:27.000 --> 20:30.000]  То есть, это доказали.
[20:30.000 --> 20:33.000]  Ну и, собственно, следствие заключается в чем?
[20:33.000 --> 20:36.000]  Следствие заключается в следующем, что
[20:36.000 --> 20:39.000]  по глубина дерева,
[20:39.000 --> 20:42.000]  точнее, глубина дерева у меня не больше, чем
[20:42.000 --> 20:45.000]  ранг дерева.
[20:45.000 --> 20:48.000]  То есть, у меня получается, что
[20:48.000 --> 20:51.000]  время на выполнение
[20:51.000 --> 20:54.000]  mindset у меня занимает
[20:54.000 --> 20:57.000]  логарифмическое время от размера x.
[20:57.000 --> 21:00.000]  Ну и, грубо говоря, если я просто
[21:00.000 --> 21:03.000]  прологарифмируем обе части, получится, что
[21:03.000 --> 21:06.000]  ранг не превосходит логарифма size.
[21:06.000 --> 21:09.000]  Ну а, соответственно, ранг – это есть верхняя оценка
[21:09.000 --> 21:12.000]  на время поиска mindset.
[21:12.000 --> 21:15.000]  На глубину дерева. Все.
[21:15.000 --> 21:18.000]  То есть, с помощью ранговой ивристики мы смогли
[21:18.000 --> 21:21.000]  улучшить асимптотику с линейной в худшем случае
[21:21.000 --> 21:24.000]  до алгоритмической в худшем случае, да, до алгоритмической,
[21:24.000 --> 21:27.000]  от размера множества.
[21:27.000 --> 21:30.000]  Ну и теперь, собственно, будет ивристика, которая
[21:30.000 --> 21:33.000]  изменит вообще все.
[21:33.000 --> 21:36.000]  Значит, смотрите, ивристика – жатия путей.
[21:36.000 --> 21:39.000]  В чем стоит эта ивристика? Ну давайте
[21:39.000 --> 21:42.000]  посмотрим и поймем, что мы можем сделать.
[21:42.000 --> 21:45.000]  Ну вот представьте себе, что у меня
[21:45.000 --> 21:48.000]  x находится где-то вот здесь, и, соответственно,
[21:48.000 --> 21:51.000]  ну а это, ну не знаю, давайте назовем x' – это представитель x.
[21:51.000 --> 21:54.000]  Когда я вызываю, то есть давайте посмотрим
[21:54.000 --> 21:57.000]  на алгоритм предыдущий,
[21:57.000 --> 22:00.000]  на алгоритм предыдущий кодер.
[22:00.000 --> 22:03.000]  Вот как у нас работает
[22:03.000 --> 22:06.000]  findSet. Вот здесь.
[22:06.000 --> 22:09.000]  Значит, findSet устроен следующим образом.
[22:09.000 --> 22:12.000]  Я нахожусь здесь, дальше, собственно, я рекурсивно
[22:12.000 --> 22:15.000]  поднимаюсь, ну либо рекурсивно, либо итеративно поднимаюсь наверх,
[22:15.000 --> 22:18.000]  соответственно, спрашиваю findSet вот этого элемента.
[22:18.000 --> 22:21.000]  Дальше спрашиваю findSet от этого элемента, findSet от этого элемента,
[22:21.000 --> 22:24.000]  и как только у меня findSet совпадает с самим элементом,
[22:24.000 --> 22:27.000]  вот. Смотрите, в чем дело.
[22:27.000 --> 22:30.000]  Смотрите, вот в процессе подъема
[22:30.000 --> 22:33.000]  мы же на самом деле получается так, что мы узнаем
[22:33.000 --> 22:36.000]  представителя, ну, самого главного представителя, не только для этого элемента,
[22:36.000 --> 22:39.000]  но и вообще для всех сразу, согласны?
[22:39.000 --> 22:42.000]  То есть, в принципе, что мне мешает сказать, что, ну, как минимум
[22:42.000 --> 22:45.000]  сказать так, что вот я для x нашел представителя самого главного,
[22:45.000 --> 22:48.000]  а давайте я сделаю так, вот когда мне в следующий раз попросят findSet от x,
[22:48.000 --> 22:51.000]  я не хочу снова подниматься по этому пути, а давайте я просто
[22:51.000 --> 22:54.000]  возьму вот эту связь, удалю, и x непосредственно привяжу
[22:54.000 --> 22:57.000]  к самому главному представителю.
[22:57.000 --> 23:01.000]  Логично? Ну, допустим, меня два раза подряд попросили findSet от x, findSet от y,
[23:01.000 --> 23:04.000]  findSet от x, и снова findSet от x.
[23:04.000 --> 23:07.000]  Смыслом мне два раза подниматься по одному и другое пути.
[23:07.000 --> 23:10.000]  Я могу просто взять этот элемент и сразу же подсоединить его к орне.
[23:10.000 --> 23:13.000]  Да.
[23:13.000 --> 23:16.000]  Ну потому что
[23:16.000 --> 23:19.000]  Ну как почему? Потому что вот представьте, у вас есть одно дерево,
[23:19.000 --> 23:22.000]  у вас есть второе дерево,
[23:22.000 --> 23:25.000]  за сколько времени вы будете подсоединять все элементы вот сюда.
[23:25.000 --> 23:28.000]  А тут я предлагаю, как бы, ну вот мы же всё равно, смотрите, у нас
[23:28.000 --> 23:32.000]  вот эта вот штука, подъём по этим или подъём
[23:32.000 --> 23:35.000]  от кокового до элемента до корня,
[23:35.000 --> 23:38.000]  у одного элемента до корня,
[23:38.000 --> 23:41.000]  а с учетом этого мы должны перешепливать
[23:41.000 --> 23:47.560]  от какого-то элемента до корня, занимает время h от x. То есть я все равно вот это время h от x потрачу.
[23:47.560 --> 23:53.000]  Давайте я не буду тратить его пустую, а давайте я его грубо говоря сомартизирую.
[23:53.000 --> 23:58.360]  Давайте я подсоединю x к корню, потом вот этот элемент подсоединю к корню, вот этот элемент к корню и вот этот элемент к корню.
[23:58.360 --> 24:03.160]  То есть грубо говоря добавлю еще h от x времени, а симптомикой это не изменит.
[24:03.160 --> 24:07.320]  Но зато это уменьшить время для будущих файнсетов, согласны?
[24:08.200 --> 24:13.880]  Короче говоря, идея состоит в том, чтобы не только для того элемента, для которого мы нашли представителя,
[24:13.880 --> 24:17.400]  присоединить его к корню, но и вообще для всех элементов, для которых мы определили представителя,
[24:17.400 --> 24:21.720]  сразу же подсоединить их к корню.
[24:28.760 --> 24:35.480]  Понятная идея. Ну и соответственно реализуется она тоже довольно просто.
[24:35.480 --> 24:40.840]  Называется это все ивристикой жатия путей.
[24:40.840 --> 24:44.120]  Ивристика жатия путей.
[24:44.120 --> 24:47.640]  Давайте поступим следующим образом.
[24:47.640 --> 24:53.960]  Как построить файнсет от x? Если я уже нахожусь в корне, то этот корень я возвращаю в качестве ответа.
[24:53.960 --> 25:00.440]  Если я нахожусь не в корне, то давайте я напишу так. Я напишу parent от x равно файнсет от parent от x.
[25:00.680 --> 25:06.040]  При условии, что присваивание у меня как c++ возвращает результат присваивания.
[25:06.040 --> 25:11.960]  Когда я нахожусь не в корне, я говорю, что давайте я найду представителя своего родителя,
[25:11.960 --> 25:17.480]  а потом сразу же присоединю себя к тому, что я нашел.
[25:17.480 --> 25:23.080]  Процедура рекурсивная. Она по сути рекурсивна. Каждого родителя, каждого предка
[25:23.160 --> 25:25.720]  подсоединит непосредственно к корню.
[25:25.720 --> 25:32.200]  Понятно? По сути, я рекурсивно поднимаюсь и каждого подсоединяю к корне, вот как здесь.
[25:32.200 --> 25:36.360]  То есть, вначале я вызвал файнсет от x, файнсет от x вызвал файнсет от y,
[25:36.360 --> 25:40.840]  файнсет от y вызвал файнсет от z, вот файнсет от z вызвал файнсет от t.
[25:40.840 --> 25:44.680]  Соответственно z в качестве представителя вернулся t, но z уже подсоединен к t.
[25:44.680 --> 25:48.120]  Дальше y в качестве ответа вернулся t, я сразу же y подсоединил t.
[25:48.360 --> 25:52.680]  Дальше x в качестве ответа вернулся t, и я сразу же присвоил сюда t.
[25:56.680 --> 26:00.200]  Грубо говоря, можно считать, что это идея на такая амортизация.
[26:00.200 --> 26:04.200]  То есть, если я для какого-то элемента уже посчитал его представителя, то в следующий раз
[26:04.200 --> 26:05.720]  я представителя посчитаю за единицу.
[26:09.720 --> 26:14.920]  И, соответственно, утверждение второе без доказательства заключается в следующем,
[26:14.920 --> 26:22.200]  что если вы используете ранговую ивристику, ту, которую мы сейчас обсудили чуть-чуть ранее,
[26:22.200 --> 26:26.520]  и используете одновременно с этим ивристику сжатия путей, то амортизационная сложность
[26:26.520 --> 26:31.400]  операции файнсет есть O от αn, где α – это обратная функция кирмана.
[26:31.400 --> 26:35.000]  Все понятно?
[26:35.000 --> 26:40.200]  Поясню, что такое функция кирмана. Это очень замечательная обратная функция кирмана.
[26:40.200 --> 26:44.360]  Это очень замечательная функция. Чем знаменитая функция кирмана?
[26:44.360 --> 26:47.160]  Функция кирмана знаменита тем, что она очень быстро растет.
[26:47.160 --> 26:50.680]  Растет очень-очень быстро.
[26:50.680 --> 26:55.560]  Но, соответственно, про обратную функцию кирмана можно сказать следующее, что она, наоборот,
[26:55.560 --> 26:57.560]  растет очень медленно. Ну, давайте посмотрим.
[26:57.560 --> 27:02.040]  Например, альфа от единицы равно нулю, альфа от трех равно единице, альфа от семи равно двойке,
[27:02.040 --> 27:06.040]  альфа от шестидесяти одному равно тройке. Ну, казалось бы, нормальный рост.
[27:10.840 --> 27:14.360]  А вот четверке эта функция равна уже вот при таком значении.
[27:14.360 --> 27:18.360]  Ну, такой рост, ну, понимаете, да?
[27:18.360 --> 27:28.360]  Да, в общем, определение можете почитать в «Икипедии», там, в общем, да.
[27:28.360 --> 27:32.360]  Определяется рекурсивно, все верно.
[27:32.360 --> 27:36.360]  Вообще, на самом деле, скорее диагональная функция кирмана, ну ладно.
[27:36.520 --> 27:38.520]  Функция кирмана на двух аргументах.
[27:40.520 --> 27:42.520]  Ну, в общем, вы понимаете, да, к чему я клоню.
[27:42.520 --> 27:48.520]  В общем, это, на самом деле, число, оно гораздо-гораздо больше, чем число атомов, видимо, части вселенной.
[27:48.520 --> 27:54.520]  Поэтому, в общем, я гарантирую, что в наших контестах, вот, это число никогда не будет больше четверки.
[27:54.520 --> 27:58.520]  Даже если я очень сильно хотел, я бы не смог сделать так, чтобы оно было больше четверки.
[27:58.520 --> 28:04.520]  Поэтому, на практике, вообще говоря, на практике считается, что, ну, короче говоря,
[28:04.680 --> 28:06.680]  люди считают, что это лодки единицы, просто-напросто.
[28:06.680 --> 28:14.680]  Потому что у нас пока нет таких данных, чтобы, короче говоря, достичь роста этой функции.
[28:14.680 --> 28:16.680]  Но формально, формально это растущая функция.
[28:16.680 --> 28:22.680]  То есть, чем больше у вас размеров множества, тем дольше работает пайнсет в эмортизационном смысле.
[28:22.680 --> 28:28.680]  Ну, на практике можно считать, что пайнсет работает эмортизационно за константное время.
[28:30.680 --> 28:32.680]  Все ясно, да?
[28:32.840 --> 28:36.840]  Но это верно. Опять же, повторюсь, давайте еще раз поговорим про утверждение.
[28:36.840 --> 28:38.840]  То есть, какую структуру данных мы построили?
[28:38.840 --> 28:42.840]  Мы построили структуру данных, которые организованы в виде леса, не пересекающихся множеств.
[28:42.840 --> 28:46.840]  То есть, у нас каждое множество организовано в виде некоторого дерева.
[28:46.840 --> 28:48.840]  Дерево деревья корневые.
[28:48.840 --> 28:51.840]  Соответственно, мы их представляем в виде массива предков.
[28:51.840 --> 28:55.840]  То есть, для каждого элемента мы храним ее непосредственного предка.
[28:55.840 --> 28:57.840]  А дальше, соответственно, мы используем две эвристики.
[28:58.000 --> 29:00.000]  Первая эвристика – это ранговая эвристика.
[29:00.000 --> 29:04.000]  То есть, мы подвешиваем маленькое дерево к большому дереву, а не наоборот.
[29:04.000 --> 29:06.000]  Вот этот первый момент.
[29:06.000 --> 29:08.000]  А второй момент заключается в том, что мы используем эвристику жатия пусей.
[29:08.000 --> 29:10.000]  То есть, если мы для каких-то элементов...
[29:10.000 --> 29:14.000]  То есть, когда в процессе пайнсет мы находим представителя для каждого элемента,
[29:14.000 --> 29:18.000]  мы его сразу же подвешиваем непосредственно к его корню.
[29:21.000 --> 29:24.000]  Да, ну и тут еще нужно сказать следующую вещь.
[29:24.000 --> 29:26.000]  Вот как раз таки про ранги.
[29:26.160 --> 29:28.160]  То есть, мы говорили, что ранг от X...
[29:32.160 --> 29:34.160]  Ранг от X – это...
[29:37.160 --> 29:39.160]  глубина дерева...
[29:39.160 --> 29:41.160]  глубина дерева X.
[29:41.160 --> 29:44.160]  Значит, смотрите, когда мы делаем эвристику жатия пусей,
[29:44.160 --> 29:47.160]  мы вообще говоря ранги не обновляем.
[29:47.160 --> 29:49.160]  И это может показаться странным.
[29:49.160 --> 29:51.160]  Да?
[29:51.160 --> 29:55.160]  Ну, смотрите, ну вот у меня, допустим, было какое-то вот такое вот дело.
[29:55.320 --> 29:59.320]  Так что получилось так, что у меня дерево было слишком глубоким.
[30:01.320 --> 30:03.320]  Какая-то такая история.
[30:03.320 --> 30:05.320]  После того, как я сделал пайнсет от X,
[30:05.320 --> 30:07.320]  после того, как я сделал пайнсет,
[30:07.320 --> 30:10.320]  я все вот эти элементы подсоединил к корню дерева.
[30:10.320 --> 30:13.320]  Естественно, у этого дерева, ну и плюс у всех вот этих вот деревьев,
[30:13.320 --> 30:15.320]  глубина уменьшилась.
[30:15.320 --> 30:17.320]  Глубина не увеличилась.
[30:17.320 --> 30:19.320]  Но, тем не менее, утверждается, что ранг менять...
[30:19.320 --> 30:21.320]  что изменять ранг, соответственно, обновлять ранг,
[30:21.320 --> 30:24.320]  высчитывать новую глубину и так далее не нужно.
[30:24.480 --> 30:26.480]  В общем, достаточно пользоваться старым рангом,
[30:26.480 --> 30:28.480]  и тогда просто ранг меняется не на глубину дерева,
[30:28.480 --> 30:30.480]  а на верхнюю оценку.
[30:32.480 --> 30:34.480]  Оценка...
[30:35.480 --> 30:37.480]  глубины дерева.
[30:37.480 --> 30:39.480]  Вот. Окей?
[30:39.480 --> 30:42.480]  То есть теперь в ранге хранится у меня не истинная глубина дерева,
[30:42.480 --> 30:44.480]  а всего лишь оценка сверху.
[30:44.480 --> 30:47.480]  То есть, какой максимальной глубины это дерево может быть?
[30:47.480 --> 30:49.480]  Но теоретически, ну как?
[30:49.480 --> 30:51.480]  И практически оно будет меньше,
[30:51.640 --> 30:53.640]  то есть у вас постоянно дерево сжимается.
[30:53.640 --> 30:55.640]  Окей?
[30:55.640 --> 30:57.640]  Вот.
[30:57.640 --> 30:59.640]  Есть ли вопрос с такой стукверданах?
[31:03.640 --> 31:07.640]  Окей, тогда давайте вернемся графом.
[31:15.640 --> 31:18.640]  И поговорим про минимально острые деревья.
[31:18.800 --> 31:20.800]  Значит, задача формулируется
[31:20.800 --> 31:22.800]  следующим образом.
[31:22.800 --> 31:24.800]  Данный ориентированный граф...
[31:24.800 --> 31:26.800]  А, да, давайте сделаем небольшой анонс.
[31:26.800 --> 31:28.800]  После перерыва получается.
[31:28.800 --> 31:30.800]  Вот.
[31:30.800 --> 31:32.800]  Перерыв.
[31:32.800 --> 31:34.800]  Время вышло.
[31:34.800 --> 31:36.800]  Про что будет,
[31:36.800 --> 31:38.800]  собственно,
[31:38.800 --> 31:40.800]  следующая завершающая часть
[31:40.800 --> 31:42.800]  нашего курса по алгоритму,
[31:42.800 --> 31:44.800]  которая посвящена графу.
[31:44.800 --> 31:46.800]  Вот мы до этого рассматривали графы,
[31:46.960 --> 31:48.960]  и при этом интересовались только,
[31:48.960 --> 31:50.960]  скажем, исключительно
[31:50.960 --> 31:52.960]  структурой графа.
[31:52.960 --> 31:54.960]  Какие у него компоненты связанности,
[31:54.960 --> 31:56.960]  компоненты сильной связанности,
[31:56.960 --> 31:58.960]  какие соединены ли вершины,
[31:58.960 --> 32:00.960]  не соединены ли вершины,
[32:00.960 --> 32:02.960]  как можно топологически ассортировать графы и так далее.
[32:02.960 --> 32:04.960]  Без привязки какой-то полезной информации,
[32:04.960 --> 32:06.960]  которую граф может хранить.
[32:06.960 --> 32:08.960]  Скажем, у нас интересовали
[32:08.960 --> 32:10.960]  так называемые ввешенные графы.
[32:10.960 --> 32:12.960]  На ребрах, на самом деле,
[32:12.960 --> 32:14.960]  может быть написана какая-то информация,
[32:14.960 --> 32:16.960]  о которой мы будем в дальнейшем говорить.
[32:16.960 --> 32:18.960]  Сколько единиц чего-либо
[32:18.960 --> 32:20.960]  может протечь по этому ребру,
[32:20.960 --> 32:22.960]  либо по весу ребра.
[32:22.960 --> 32:24.960]  Насколько это ребро важнее, чем второе ребро и так далее.
[32:24.960 --> 32:26.960]  Насколько дороже там проходить по этому ребру,
[32:26.960 --> 32:28.960]  чем по второму.
[32:28.960 --> 32:30.960]  Будем переходить к таким алгоритмам.
[32:30.960 --> 32:32.960]  Первым алгоритмом из них будет
[32:32.960 --> 32:34.960]  алгоритм построения минимального
[32:34.960 --> 32:36.960]  основного дерева.
[32:36.960 --> 32:38.960]  В чем заключается задача?
[32:38.960 --> 32:40.960]  Нам данен некоторый неориентированный граф,
[32:40.960 --> 32:42.960]  и при этом дополнительно
[32:42.960 --> 32:44.960]  еще на ребрах задана некоторая весовая пункция.
[32:44.960 --> 32:46.960]  Просто некоторое отображение из множества
[32:46.960 --> 32:48.960]  ребер во множество, скажем,
[32:48.960 --> 32:50.960]  деспительных чисел.
[32:50.960 --> 32:52.960]  Соответственно, что такое останный подграф?
[32:52.960 --> 32:54.960]  Первое определение.
[32:54.960 --> 32:56.960]  Подграф графа g' называется
[32:56.960 --> 32:58.960]  останым, если он содержит все
[32:58.960 --> 33:00.960]  исходные вершины графа g.
[33:00.960 --> 33:02.960]  То есть мы взяли исходный граф,
[33:02.960 --> 33:04.960]  выделили из него вершины и, возможно,
[33:04.960 --> 33:06.960]  оставили еще какие-то ребра.
[33:06.960 --> 33:08.960]  Такой граф называется останым, который сохраняет все
[33:08.960 --> 33:10.960]  прежние вершины исходного графа.
[33:10.960 --> 33:12.960]  Что такое минимально останое дерево?
[33:12.960 --> 33:14.960]  Это останный подграф,
[33:14.960 --> 33:16.960]  который, во-первых, является деревом,
[33:16.960 --> 33:18.960]  а в треке который имеет наименьший
[33:18.960 --> 33:20.960]  вес среди все возможных останых деревьев.
[33:20.960 --> 33:22.960]  Мы скажем,
[33:22.960 --> 33:24.960]  вот у нас есть граф,
[33:24.960 --> 33:26.960]  из него можно каким-то образом выделить подграф,
[33:26.960 --> 33:28.960]  который будет являться деревом.
[33:28.960 --> 33:30.960]  Среди всех таких деревьев мы выделяем
[33:30.960 --> 33:32.960]  именно такой подграф дерева,
[33:32.960 --> 33:34.960]  который обладает наименьшим весом,
[33:34.960 --> 33:36.960]  у которого сумма весов ребер минимальна.
[33:36.960 --> 33:38.960]  На данном примере
[33:38.960 --> 33:42.960]  вот такой подграф, который обозначен зеленым цветом.
[33:42.960 --> 33:49.960]  А нет, наоборот, он является острым деревом, но при этом он не является минимальным.
[33:49.960 --> 33:52.960]  Почему он не является минимальным?
[33:52.960 --> 33:57.960]  Как из него можно сделать еще более минимальное острое дерево меньшего веса?
[33:57.960 --> 34:02.960]  Да, можно убрать DAC и поменять на DA, а еще?
[34:02.960 --> 34:06.960]  Да, убрать вот это ребро и добавить вот это ребро.
[34:06.960 --> 34:11.960]  Вот этот граф будет действительно являться минимальным острым деревом.
[34:16.960 --> 34:20.960]  Теперь мы потихоньку переходим к алгоритму.
[34:20.960 --> 34:23.960]  Всем понятно, что такое минимальное острое дерево?
[34:23.960 --> 34:27.960]  В принципе, как обычно, задача довольно понятна, непонятно, как ее решать.
[34:27.960 --> 34:31.960]  Давайте введем несколько определений и утверждений, которые нам помогут это сделать.
[34:31.960 --> 34:35.960]  Пусть у нас есть подграф некоторого минимального острого дерева.
[34:35.960 --> 34:38.960]  Минимально острого дерева еще называют MST.
[34:52.960 --> 34:57.960]  Соответственно, пусть у нас есть некоторое минимально острое дерево.
[34:57.960 --> 35:01.960]  HH3 – это подграф этого минимального острого дерева.
[35:01.960 --> 35:04.960]  Это именно подграф неисходного.
[35:04.960 --> 35:07.960]  Во-первых, он является подграфом исходного графа,
[35:07.960 --> 35:11.960]  во-вторых, он является подграфом некоторого оптимального острого дерева.
[35:11.960 --> 35:15.960]  Значит, реброба U называется безопасным,
[35:15.960 --> 35:19.960]  если при его добавлении в граф HH3 этот граф останется подграфом
[35:19.960 --> 35:22.960]  некоторого минимально острого дерева.
[35:22.960 --> 35:25.960]  Грубо говоря, история такая.
[35:25.960 --> 35:29.960]  Давайте, как это все применяется к алгоритму, который мы будем строить.
[35:29.960 --> 35:32.960]  Минимально острого дерева мы будем строить икаративно,
[35:32.960 --> 35:35.960]  постепенно добавляя все более и более новые ребра.
[35:35.960 --> 35:38.960]  Понятное дело, что мы добавили какие-то ребра,
[35:38.960 --> 35:42.960]  у нас появился подграф, который еще не является деревом, но к нему стремится.
[35:42.960 --> 35:45.960]  Что такое минимальное ребро?
[35:45.960 --> 35:49.960]  Минимальное ребро – это такое, которое я могу добавить в этот строящийся граф,
[35:49.960 --> 35:54.960]  так что у меня этот граф по-прежнему будет стремиться к некоторому минимальному острому дереву.
[35:54.960 --> 35:56.960]  Понятно?
[35:56.960 --> 35:59.960]  И уже этот граф, как ни крути, не станет минимально острым деревом,
[35:59.960 --> 36:02.960]  соответственно, это ребро безопасно не является.
[36:02.960 --> 36:06.960]  И, соответственно, если мы рассмотрим такой подграф,
[36:06.960 --> 36:11.960]  то для него безопасными являются ребра AD и CE, как мы сказали.
[36:11.960 --> 36:15.960]  Если мы в этот подграф зеленый добавим ребро BE,
[36:15.960 --> 36:20.960]  то полученный граф уже никак не будет подграфом минимально острого дерева.
[36:20.960 --> 36:23.960]  Потому что минимально острого дерева этого ребра вообще, говоря, нет.
[36:23.960 --> 36:29.960]  Поэтому вот это ребро не является безопасным, вот это ребро не является безопасным,
[36:29.960 --> 36:31.960]  то есть единственные безопасными ребрами, здесь вот это и вот это.
[36:35.960 --> 36:39.960]  Ну и, соответственно, план на самом деле очень простой.
[36:39.960 --> 36:42.960]  У нас изначально есть просто вершина.
[36:42.960 --> 36:45.960]  Возьмём эти самые вершины и выберём какое-нибудь безопасное ребро.
[36:45.960 --> 36:47.960]  Добавим безопасное ребро в наш граф.
[36:47.960 --> 36:51.960]  Возьмём второе безопасное ребро, добавим наш граф.
[36:51.960 --> 36:56.160]  И так далее, будем давать безопасные ребра до тех пор, пока мы не построим минимально остальное дерево.
[36:57.720 --> 36:59.560]  Круто?
[36:59.560 --> 37:04.360]  План очень простой. Остается неясным единственный вопрос, а как найти безопасное ребро?
[37:07.200 --> 37:10.760]  Это хорошая идея, но не все дешевые ребра на самом деле полезны.
[37:15.440 --> 37:21.280]  Вот, это уже близко к правде. То есть действительно на самом деле можно считать, что
[37:22.720 --> 37:27.080]  в случае построения минимального остого дерева подходит такой, можно сказать, почти жадный алгоритм.
[37:27.080 --> 37:30.080]  То есть мы действительно будем на каждой итерации, то есть на каждом этапе, выбирать
[37:30.600 --> 37:35.760]  минимальное по весу ребро. Но не просто минимальное по весу ребро, а который будет творять определенным критериям.
[37:36.600 --> 37:38.600]  Критериям он такой.
[37:39.120 --> 37:41.120]  Лемма о безопасном ребре.
[37:41.800 --> 37:46.840]  Для начала давайте определимся с еще несколькими понятиями. Во-первых, разрез графа.
[37:46.840 --> 37:49.400]  Расрез графа – это просто разбиение
[37:52.040 --> 37:54.400]  вершин
[37:54.400 --> 37:56.400]  на два не пересекающих множества.
[37:58.720 --> 38:02.040]  Множество С и множество В без С. Вот это разбиение графа.
[38:02.480 --> 38:06.720]  То есть мы взяли вершины графа, разбили на два множства. Это называется разбиение. Вот вот. КПар множества.
[38:06.720 --> 38:17.720]  Ну, соответственно, будем говорить, что ребро в У пересекает разрез, если один конец ребра лежит в одном множестве разреза, а второй конец ребра лежит в втором множестве.
[38:17.720 --> 38:25.720]  То есть, грубо говоря, есть у вас вот такая вот картина.
[38:25.720 --> 38:35.720]  Лемма о безопасном ребре дает нам необходимые и достаточные условия для того, чтобы мы могли находить безопасные ребра.
[38:35.720 --> 38:41.720]  Пусть же штрих – это подграф некоторого минимального основного поддерева графа G.
[38:41.720 --> 38:43.720]  То есть, опять же, история такая же, как я сказал.
[38:43.720 --> 38:48.720]  У нас есть какой-то подграф, и нам известно, что его можно достроить до минимального основного дерева.
[38:48.720 --> 38:56.720]  Возникает вопрос, какое ребро можно у него добавить, чтобы он по-прежнему оставался способным быть достроенным до минимального основного дерева.
[38:56.720 --> 39:01.720]  Есть такой ж-штрих подграф, и также есть некоторый разрез.
[39:01.720 --> 39:07.720]  Причём этот разрез устроен так, что никакое ребро из ж-штрих не пересекает этот разрез.
[39:07.720 --> 39:16.720]  То есть, грубо говоря, у меня есть разрез какой-то, и все ребра из ж-штрих лежат строго вот в одной компоненте разреза.
[39:16.720 --> 39:20.720]  Ну или вот только здесь.
[39:20.720 --> 39:24.720]  Вот таких вот ребер у меня не существует.
[39:28.720 --> 39:38.720]  У меня есть граф ж-штрих, я каким-то образом разбил множество вершин на два множества так, что ни одно ребро из ж-штрих не пересекает эти два множества.
[39:38.720 --> 39:52.720]  Если я среди всех таких ребер, которые пересекают этот разрез, выберу минимальное по весу, то вот такое ребро будет безопасным.
[39:52.720 --> 39:58.720]  То есть такое ребро я могу спокойно добавить в мой граф ж-штрих. Понятно?
[39:59.720 --> 40:03.720]  Смотрите, есть граф ж-штрих.
[40:05.720 --> 40:07.720]  Давайте так.
[40:09.720 --> 40:11.720]  Зелёным цветом.
[40:13.720 --> 40:15.720]  Есть граф ж-штрих.
[40:18.720 --> 40:20.720]  У него есть какие-то ребра.
[40:21.720 --> 40:27.720]  При этом все ребра лежат либо внутри вот этой компоненты, либо внутри вот этой компоненты.
[40:27.720 --> 40:30.720]  То есть не существует ребра, которая бы проходила отсюда-сюда.
[40:32.720 --> 40:34.720]  Вот в этом графе.
[40:34.720 --> 40:40.720]  Тогда я рассмотрю все ребра, которые на самом деле этот разрез пересекают в исходном графе g.
[40:43.720 --> 40:45.720]  У меня есть граф g.
[40:45.720 --> 40:49.720]  Ж-штрих – это под множество t, которое является под множеством графа g.
[40:49.720 --> 40:53.720]  Вот g – это мой граф. Это тот граф, который нам дали.
[40:53.720 --> 40:57.720]  А ж-штрих – это то, что я хочу построить, достроить до t.
[40:57.720 --> 41:03.720]  Соответственно, тут есть какие-то ребра черные, но при этом они не лежат ж-штрих.
[41:03.720 --> 41:08.720]  Вот если я среди всех таких ребер выберу минимальное, то я могу спокойно его взять и добавить ж-штрих.
[41:08.720 --> 41:10.720]  И при этом ничего не испортить.
[41:11.720 --> 41:15.720]  Давайте докажем, почему это так.
[41:20.720 --> 41:23.720]  Давайте рассмотрим тот на разрез.
[41:23.720 --> 41:31.720]  Множество s и множество u равное v без s.
[41:31.720 --> 41:59.720]  Ну и пусть e – это минимальное ребро, пересекающее разрез v-u.
[42:01.720 --> 42:04.720]  Нет, почему-то давайте s.
[42:07.720 --> 42:10.720]  Пересекающий разрез s-u.
[42:10.720 --> 42:30.720]  Вот. Пусть e не попало в минимальное основное дерево.
[42:30.720 --> 42:38.720]  Допустим, что e – это минимальное ребро, и вот так получилось, что e не принадлежит минимальному основному дереву у моего графа.
[42:38.720 --> 42:40.720]  Вот так получилось.
[42:40.720 --> 42:44.720]  А вот тогда что я могу сказать? У меня обязательно существует ребро e-штрих,
[42:44.720 --> 42:50.720]  который ведет из компонента s компонента u. Почему это так?
[42:50.720 --> 42:57.720]  Что? Да, потому что не то, что граф g связан, а потому что у меня дерево должно быть связано.
[42:57.720 --> 42:59.720]  Вот.
[42:59.720 --> 43:07.720]  Соответственно, тогда найдется e-штрих такое, что...
[43:07.720 --> 43:18.720]  Давайте так напишем. e-штрих равное v-u такое, что v принадлежит s, а u принадлежит u.
[43:18.720 --> 43:23.720]  И при этом e-штрих не равно e.
[43:23.720 --> 43:25.720]  Вот.
[43:25.720 --> 43:33.720]  Так напишем e-штрих, принадлежащее минимально основному дереву.
[43:33.720 --> 43:36.720]  Вот. Что можно сказать тогда?
[43:36.720 --> 43:38.720]  Ну, смотрите.
[43:38.720 --> 43:42.720]  Что можно сказать тогда?
[43:42.720 --> 43:44.720]  Давайте добавим...
[43:54.720 --> 43:57.720]  Добавим e в полученный mst.
[44:03.720 --> 44:07.720]  Вот. То есть мы предположили, что g в нашем минимальном основном дереве не лежит.
[44:07.720 --> 44:11.720]  Соответственно, без e получилось вроде как нормальное минимально основное дерево.
[44:11.720 --> 44:16.720]  А давайте мы этот e добавим в наш минимально основное дерево.
[44:16.720 --> 44:18.720]  Что мы тогда получим?
[44:18.720 --> 44:22.720]  Ну, мы вообще получим не дерево тогда. У нас появится в любом случае цикл.
[44:22.720 --> 44:24.720]  Согласны?
[44:24.720 --> 44:27.720]  Ну, то есть вот у меня тут...
[44:27.720 --> 44:32.720]  У меня тут был какой-то путь, и тут был какой-то путь.
[44:32.720 --> 44:35.720]  Соответственно, из этого следует...
[44:36.720 --> 44:38.720]  Получили...
[44:42.720 --> 44:44.720]  Получили цикл.
[44:48.720 --> 44:50.720]  Получили цикл.
[44:50.720 --> 44:52.720]  То есть получили какую-то вот такую вот...
[44:52.720 --> 44:54.720]  Получили какую-то вот такую вот ситуацию.
[44:54.720 --> 44:55.720]  Да?
[44:55.720 --> 44:57.720]  А теперь смотрите.
[44:57.720 --> 44:59.720]  Что у меня получается?
[44:59.720 --> 45:03.720]  Вес ребра e-штрих больше и бравее, чем вес ребра e.
[45:03.720 --> 45:07.720]  Что произойдет, если я уберу ребро e-штрих?
[45:10.720 --> 45:13.720]  Ну, у меня граф останется связанным. Согласны?
[45:13.720 --> 45:22.720]  Все. То есть если уберем e-штрих, то граф...
[45:22.720 --> 45:26.720]  Ну, точнее, ну да, граф останется связанным.
[45:26.720 --> 45:28.720]  Что станет с его весом?
[45:28.720 --> 45:31.720]  Не увеличится, скорее.
[45:31.720 --> 45:33.720]  А вес не увеличится.
[45:33.720 --> 45:35.720]  А вес...
[45:35.720 --> 45:37.720]  ...Не увеличится.
[45:37.720 --> 45:39.720]  То есть что получили?
[45:39.720 --> 45:45.720]  Если вес не изменится, то это на самом деле означает, что e-штрих спокойно можно было заменить на e.
[45:45.720 --> 45:47.600]  Кстати, если вы посмотрите на bangs
[45:47.600 --> 45:49.720]  А вот они эти provided😅
[45:49.720 --> 45:54.840]  А если вес не изменится, то это на самом деле означает, что е штрих
[45:54.840 --> 45:58.680]  спокойно можно было заменить на е. То есть на самом деле е тоже является
[45:58.680 --> 46:02.960]  безопасным ревром. То есть е можно было спокойно добавить в наш граф,
[46:02.960 --> 46:06.280]  и тогда бы ничего не изменилось. Мы по-прежнему могли бы смогли его достроить до минимального основного дерева.
[46:06.280 --> 46:12.280]  Вот я его предъявил. То есть удалили е штрих, добавили е. Все нормально, согласны?
[46:12.280 --> 46:16.400]  А если тут стоял наоборот знак больше,
[46:16.400 --> 46:20.480]  тогда бы мы пришли к противоречию. На самом деле мы предположили, что без е
[46:20.480 --> 46:25.200]  получается нормальное минимальное основное дерево, но оказывается, что нет.
[46:25.200 --> 46:27.680]  С помощью е можно было построить еще меньшее минимальное основное дерево,
[46:27.680 --> 46:32.600]  что является противоречием. То есть как ни крути, получается такая ситуация, что е
[46:32.600 --> 46:35.880]  в любом случае можно было спокойно добавить в наш граф и спокойно
[46:35.880 --> 46:39.280]  достроить его до минимального основного дерева. Из этого следует,
[46:39.280 --> 46:45.080]  что е было безопасно.
[46:53.480 --> 46:56.480]  Ну вот.
[46:59.600 --> 47:07.360]  Мы получили способ получения безопасных ревер,
[47:07.360 --> 47:11.920]  но одновременно с этим мы получили способ, на самом деле целую кучу способов
[47:11.920 --> 47:16.360]  построения минимального основного дерева. В чем он заключается? Он заключается в том,
[47:16.360 --> 47:23.240]  чтобы построить хороший разрез, то есть разбить вершины графа так, чтобы в текущем
[47:23.240 --> 47:26.600]  построенном под графе у нас не было ревер из одной компоненты в другой,
[47:26.600 --> 47:31.680]  и устрелить всех этих ревер, найти минимальное. Потом снова построить каким-то образом разрез,
[47:31.680 --> 47:35.440]  в этом разрезе найти минимальное ребро и добавить его в наш граф.
[47:35.440 --> 47:40.040]  Ну и так далее и я. Но вопрос, как строить разрезы? Краски отдается на откуп
[47:40.040 --> 47:44.760]  конкретным алгоритмам. Давайте на них посмотрим. Всего на ваш суд я
[47:44.760 --> 47:50.840]  предложу три алгоритма. Первый с них это алгоритм Прима.
[47:51.160 --> 47:56.320]  Алгоритм Прима работает следующим образом. Давайте наш разрез инициализируем
[47:56.320 --> 48:02.000]  следующим образом. Пусть, давайте тут нарисую.
[48:02.720 --> 48:14.160]  Пусть во множестве s лежит одна вершина 0, а во множестве v без s лежат все остальные вершины.
[48:14.640 --> 48:23.720]  Изначально так. Согласны ли вы, что выполняются все требования для лемы
[48:23.720 --> 48:28.000]  о безопасном ребре? То есть у нас ни одно ребро вот этого под графа пустого
[48:28.000 --> 48:36.800]  изначально не пересекает разрез. Ну и что мы делаем? Рассматриваем все
[48:36.800 --> 48:46.120]  ребра, которые торчат из вершины 0. И среди них выбираем минимальное.
[48:47.840 --> 48:52.600]  Изначально у нас была одна вершина, так как изначально у нас граф пустой,
[48:52.600 --> 49:01.240]  то можно просто взять минимальное среди всех ребр, которые торчат из конкретной вершины 0.
[49:01.240 --> 49:07.400]  Давайте добавим это ребро. Допустим, минимальное ребро это вот это ребро.
[49:07.400 --> 49:17.080]  Добавим его в наш граф и, соответственно, перенесем эту вершину в левую часть разреза.
[49:17.080 --> 49:34.880]  Ребро оказалось здесь. Как у нас изменилось множество ребр, которые пересекают разрез?
[49:34.880 --> 49:51.560]  У нас появились ребра, которые торчат из вершины 0, согласны? Давайте просто
[49:51.560 --> 49:59.440]  просто возьмем и все их добавим вот так. И теперь уже найдем минимальное среди всех ребр,
[49:59.440 --> 50:07.400]  которые ведут из вершин 0 и из вершин 1. Снова, допустим, это какое-то вот такое ребро.
[50:07.400 --> 50:14.440]  Все, соответственно, вот это ребро добавляем в наш граф же штрих и, соответственно,
[50:14.440 --> 50:34.520]  перенесем эту вершину в множество s. Ну и, соответственно, добавим ребра, которые ведут из этой вершины
[50:34.520 --> 50:40.040]  во все остальные вершины. Ну и снова продолжим алгоритм. Снова найдем среди вот этих всех ребр
[50:40.040 --> 50:45.040]  минимальное, добавим, ну и так далее, пока не получим минимально остальное дело.
[50:45.040 --> 50:56.320]  Разрез устроен очень просто. Мы просто-напросто берем и по одному добавляем вершину в левую часть разреза.
[50:56.320 --> 51:00.040]  То есть вначале там находится только одна вершина 0. Дальше по какому-то ребру нашли новую вершину,
[51:00.040 --> 51:04.200]  перенесли эту вершину в множество s. Дальше, соответственно, снова у нас есть торчащие ребра
[51:04.200 --> 51:08.840]  вот в эту компоненту. Нашли какое-то новое ребро. То есть понятное дело, что ребер вот тут внутри
[51:08.840 --> 51:13.840]  уже новых появиться не может. Потому что иначе возникнет цикл, согласны?
[51:13.840 --> 51:18.840]  Поэтому среди этих ребер выбираем новое, новое ребро. Минимальное соответственно переносим вершину сюда.
[51:18.840 --> 51:23.840]  Ну и так далее, пока все вершины не перейдут отсюда вот сюда. Нормально?
[51:23.840 --> 51:28.840]  Ищем минимальное ребро среди всех, которые перестекают разрез. Добавляем это ребро в минимально остальное дерево,
[51:28.840 --> 51:35.840]  а конец ребра переносим из вот этого конца, вот сюда. Ну и повторяем до тех пор, пока вот в этой части разреза
[51:35.840 --> 51:41.840]  не окажется все наше множество вершин. План примерно понятен?
[51:41.840 --> 51:49.840]  Давайте посмотрим, как это выглядит на практике. На практике алгоритм работает...
[51:49.840 --> 51:54.840]  Ну давайте, не знаю, может быть приведем пример.
[51:54.840 --> 51:59.840]  Ладно, давайте сначала рассмотрим середокод, а потом на примере разберем, как он работает.
[51:59.840 --> 52:06.840]  Алгоритм довольно простой. Давайте просто навестом заведем массивдист.
[52:06.840 --> 52:10.840]  В массивдист будем для каждой вершины хранить минимальный вес ребра, который в нее ведет.
[52:10.840 --> 52:18.840]  Для каждой вершины будем хранить вес минимального ребра, который в нее ведет.
[52:18.840 --> 52:20.840]  Ну вот здесь вот.
[52:20.840 --> 52:26.840]  Вот для каждой вершины отсюда мы знаем
[52:26.840 --> 52:28.840]  бес минимального ребра, который в нее ведет.
[52:28.840 --> 52:32.840]  Да, вот из s вот сюда.
[52:32.840 --> 52:34.840]  Скажем, вот у меня есть какая-то вершина, в нее
[52:34.840 --> 52:38.840]  ведет там три ребра. Не знаю, три, пять, один.
[52:38.840 --> 52:42.840]  Соответственно, в 10 от v будем хранить значение 1.
[52:42.840 --> 52:46.840]  Дальше, преф. В преф мы будем хранить
[52:46.840 --> 52:48.840]  начало соответствующего ребра.
[52:48.840 --> 52:51.840]  Скажем, вот для вершины v мы знаем, что в нее ведет
[52:51.840 --> 52:53.840]  минимальное ребро размера 1.
[52:53.840 --> 52:57.840]  И для нее мы знаем ее соответствующее начало.
[52:57.840 --> 52:59.840]  Это вершина u.
[52:59.840 --> 53:02.840]  То есть для каждой вершины мы знаем, во-первых,
[53:02.840 --> 53:04.840]  вес минимального ребра, который в нее ведет,
[53:04.840 --> 53:08.840]  а во-вторых, начало этого самого минимального ребра.
[53:08.840 --> 53:10.840]  Конечно, такой дистый преф.
[53:10.840 --> 53:12.840]  Ну а теперь, собственно, главный вопрос.
[53:12.840 --> 53:14.840]  А каким образом мы будем искать минимум?
[53:14.840 --> 53:16.840]  Вот какие у нас есть варианты?
[53:16.840 --> 53:19.840]  Какая структура данных позволяет нам эффективно искать минимум?
[53:21.840 --> 53:23.840]  Ну, пирамида, да, условно.
[53:23.840 --> 53:25.840]  Вот, познакомьтесь, вот, hip.
[53:25.840 --> 53:30.840]  То есть все вот эти вот ребра, все вот эти ребра мы будем хранить в hip'е.
[53:32.840 --> 53:36.840]  То есть hip будет упорядочен у нас по дисту.
[53:36.840 --> 53:40.840]  Ну и соответственно, в качестве второго элемента пара мы будем хранить
[53:40.840 --> 53:45.840]  соответствующую вершину, в которую ведет данное ребро.
[53:45.840 --> 53:47.840]  Вот.
[53:48.840 --> 53:50.840]  Окей?
[53:52.840 --> 53:54.840]  Нормально?
[53:54.840 --> 53:56.840]  Ну вот.
[53:56.840 --> 53:58.840]  Ну и что мы делаем в цикле?
[53:58.840 --> 54:00.840]  Пока у нас очередь, пока у нас приоритетная очередь,
[54:00.840 --> 54:02.840]  или пока у нас пирамида не опустела,
[54:02.840 --> 54:04.840]  мы достаем оттуда минимальное,
[54:04.840 --> 54:06.840]  мы достаем оттуда минимальное, минимальное ребро.
[54:06.840 --> 54:08.840]  Вот, из этого множества ребер.
[54:10.840 --> 54:12.840]  Достаем минимальное ребро.
[54:13.840 --> 54:15.340]  Вот.
[54:15.340 --> 54:17.840]  Ну и соответственно, если у этого ребра есть какой-то начальт,
[54:17.840 --> 54:21.840]  мы добавляем его в минимально, в минимально ост실ное дерево.
[54:21.840 --> 54:24.840]  Ну что значит, у ребра есть начальт, но это значит, что мы достали не нулевую вершину.
[54:25.840 --> 54:26.840]  Да?
[54:26.840 --> 54:29.880]  То есть изначально мы просто достаём нулевую вершину и нулевую вершину кладём ну
[54:29.880 --> 54:31.880]  ну ну нуjuno tanta нав spur на нуλевую вершину,
[54:31.880 --> 54:34.500]  не имея смысла добавлять приоритетную очередь.
[54:34.500 --> 54:36.500]  Поэтому просто, ну как бы не знаю какой кастырь.
[54:36.500 --> 54:38.500]  Окей?
[54:38.500 --> 54:41.840]  Ну потому что изначально мы знаем только расстояние до нулевой вершины.
[54:41.840 --> 54:49.840]  Ну а дальше поступаем следующим образом. Вот мы добавили во множество s, то есть вот мы вытащили вершину v
[54:49.840 --> 55:00.840]  И что нужно сделать? Нам нужно обновить множество ребер, которые ведут из этой компоненты вот сюда
[55:00.840 --> 55:07.840]  Вот мы взяли вершину отсюда, перенесли вот сюда, и следственно у нас появились новые ребра, которые пересекают разрез
[55:07.840 --> 55:14.840]  Нужно их все добавить, согласны? Вот соответственно в этом цикле я добавляю все эти ребра
[55:14.840 --> 55:19.840]  То есть просто прохожусь по всем соседям вершины v
[55:19.840 --> 55:33.840]  Если вершина u лежит в приоритетной очереди, и с помощью вот этого ребра я смог обновить минимальное расстояние, то я его обновляю
[55:34.840 --> 55:35.840]  Окей?
[55:35.840 --> 56:00.840]  То история такая, вот я достал вершину v, точнее не то что я достал, я добавил очередное ребро в минимально остальное дерево
[56:00.840 --> 56:05.840]  И перенес вершину v отсюда вот сюда
[56:05.840 --> 56:17.840]  Теперь мне нужно что сделать? Мне нужно просмотреть все ребра, которые торчат из вершины v, и обновить минимальное расстояние до вот этих вот вершин
[56:17.840 --> 56:21.840]  Вот раньше до этой вершины минимальное расстояние было 3, до этой 5, до этой 7
[56:21.840 --> 56:26.840]  Вот тут ребра имеют размер 5, 2, 8
[56:26.840 --> 56:37.840]  Вот это ребро оно не обновляет расстояние до вот этой вершины, потому что до этой вершины ведет какое-то более короткое ребро размера 3, согласны?
[56:37.840 --> 56:42.840]  Поэтому вот это ребро оно никогда в принципе не будет безопасным, поэтому я его игнорирую
[56:42.840 --> 56:52.840]  Вот раньше до этой вершины было какое-то ребро длины 5, а из вершины v в него торчит ребро размера 2
[56:52.840 --> 56:56.840]  Поэтому между вот этим ребром и вот этим ребром, естественно, я буду выбирать ребро 2
[56:56.840 --> 57:02.840]  Поэтому, соответственно, я обновляю дист до этой вершины и обновляю ее преф
[57:02.840 --> 57:10.840]  Теперь я говорю, что до этой вершины теперь у меня расстояние не 5, а 2, и в нее ведет ребро из вершины v
[57:10.840 --> 57:16.840]  Понятная история? Ну вот
[57:17.840 --> 57:21.840]  Ну и в кипе я делаю decrease k
[57:21.840 --> 57:27.840]  Нормально?
[57:27.840 --> 57:32.840]  Сдайте вопросы, все ли понятно
[57:32.840 --> 57:41.840]  То есть я просто-напросто по одному достаю вершины из приоритетной очереди, дальше прокажу все к ее соседе и обновляю расстояние до всех остальных вершин
[57:41.840 --> 57:46.840]  Ну и на самом деле вопрос заключается в следующем
[57:46.840 --> 57:48.840]  Сколько это все работает?
[57:48.840 --> 57:52.840]  Если мы работаем с обычной, вот, важный момент, внимание
[57:52.840 --> 57:56.840]  Для чего нам нужна была фибоначчика пирамида? Вот здесь
[57:56.840 --> 58:05.840]  Это первый и единственный момент, когда нам пригодится фибоначчика пирамида чисто для того, чтобы теоретически посмотреть, что у нас получается
[58:05.840 --> 58:09.840]  Если мы используем обычную бинарную пирамиду, то выходит следующее
[58:09.840 --> 58:11.840]  Сколько раз всего выполняется этот цикл?
[58:11.840 --> 58:14.840]  Этот цикл выполняется всего не более в раз
[58:14.840 --> 58:17.840]  Согласны, да?
[58:17.840 --> 58:20.840]  Да, не более в раз, потому что мы...
[58:20.840 --> 58:23.840]  Каждое ребро, потому что у нас в дереве сколько ребр?
[58:23.840 --> 58:28.840]  В-1, да, поэтому, соответственно, мы минимально у нас на дереве добавляем всего в-1 ребро
[58:28.840 --> 58:31.840]  Ну а так на каждую итерацию мы добавляем одно ребро
[58:31.840 --> 58:34.840]  У нас всего будет в-1 итерации, ну на самом деле в итерации
[58:34.840 --> 58:37.840]  И с того, что мы еще на левую июшу добавляем, ну ладно
[58:37.840 --> 58:41.840]  А вот, всего, соответственно, в итерации
[58:41.840 --> 58:43.840]  В итерации
[58:43.840 --> 58:47.840]  Дальше, за сколько у нас выполняется экстракт мин в бинарной пирамиде?
[58:47.840 --> 58:50.840]  Низ как звездит
[58:50.840 --> 58:54.840]  Мы удаляем, еще нам нужно просеять кто-то вверх
[58:54.840 --> 58:56.840]  Ой, наоборот, низ
[58:56.840 --> 59:00.840]  Да, то есть все это работает за логарифм от чего?
[59:00.840 --> 59:03.840]  За логарифм от размера пирамиды
[59:03.840 --> 59:06.840]  Ну размер пирамиды в худшем случае у нас E, согласны?
[59:06.840 --> 59:11.840]  Ну в худшем случае у нас в пирамиде лежат, ну не, на самом деле лог В
[59:11.840 --> 59:14.840]  Да, все нормально, лог Е
[59:14.840 --> 59:19.840]  Потому что в худшем случае мы в пирамиду сложили все ребра
[59:19.840 --> 59:21.840]  Вот
[59:21.840 --> 59:23.840]  Ну ладно, пусть так будет
[59:23.840 --> 59:25.840]  Лог Е, лог В, на самом деле одно и то же
[59:25.840 --> 59:27.840]  Окей, что дальше?
[59:27.840 --> 59:30.840]  Дальше мы, собственно, в цикле проходимся по всем вершинам
[59:30.840 --> 59:46.840]  То есть в лог Е это суммарное время экстракт мин
[59:46.840 --> 59:48.840]  Дальше
[59:48.840 --> 59:51.840]  Теперь давайте посмотрим суммарное время работы вот этого цикла
[59:51.840 --> 59:53.840]  Сколько всего итерации сделает этот цикл?
[59:53.840 --> 59:56.840]  Вообще всего-всего, за все время работает алгоритм
[59:57.840 --> 01:00:00.840]  У нас уже встречалась такая штука
[01:00:00.840 --> 01:00:03.840]  Сколько?
[01:00:03.840 --> 01:00:06.840]  Ну E или 2E, почему?
[01:00:06.840 --> 01:00:09.840]  Потому что мы берем вершину и проходим по всем ее соседям
[01:00:09.840 --> 01:00:12.840]  То есть по сути мы суммируем количество степеней для каждой вершины
[01:00:12.840 --> 01:00:15.840]  Ну а сумма всех степеней равна 2E
[01:00:15.840 --> 01:00:18.840]  То есть суммарно этот цикл выполнит E итерации
[01:00:18.840 --> 01:00:20.840]  Понятно почему, да? Опять же
[01:00:20.840 --> 01:00:22.840]  Всего E итерации
[01:00:22.840 --> 01:00:25.840]  А на каждой итерации какое количество работы мы совершаем?
[01:00:25.840 --> 01:00:28.840]  Вот так работает decrease k в бинарной пирамиде
[01:00:28.840 --> 01:00:31.840]  Ну тоже за алгоритм, да?
[01:00:31.840 --> 01:00:35.840]  Поэтому у нас получается E умноженное на лог Е
[01:00:35.840 --> 01:00:38.840]  Ну или лог В, в общем, как угодно
[01:00:38.840 --> 01:00:41.840]  Давайте напишу лог В
[01:00:41.840 --> 01:00:47.840]  Ну скобка, давайте укажем, что лог Е совпадает по порядку с лог В
[01:00:47.840 --> 01:00:51.840]  Почему? Потому что E это порядка либо В, либо В квадрат
[01:00:51.840 --> 01:00:54.840]  Алгоритм от В и от В квадрат
[01:00:54.840 --> 01:00:57.840]  Понятно, да? Отличается с константу раз всего
[01:00:57.840 --> 01:01:07.840]  Это что? Это суммарное время decrease k
[01:01:10.840 --> 01:01:15.840]  Ну соответственно, В умножено на лог В плюс E умножено на лог В получается E лог В
[01:01:15.840 --> 01:01:18.840]  Потому что количество ребер у нас заведомо больше, чем число вершин
[01:01:18.840 --> 01:01:19.840]  Согласны?
[01:01:19.840 --> 01:01:23.840]  Поэтому в случае бинарной пирамиды время работы E лог В
[01:01:23.840 --> 01:01:24.840]  Нормально?
[01:01:24.840 --> 01:01:28.840]  Теперь фибоначевая пирамида, внимание
[01:01:28.840 --> 01:01:33.840]  Давайте теперь представим себе, что вместо бинарной пирамиды мы используем фибоначевую пирамиду
[01:01:33.840 --> 01:01:36.840]  Что можно сказать про время работы экстракт-мин?
[01:01:36.840 --> 01:01:40.840]  За сколько работает экстракт-мин?
[01:01:40.840 --> 01:01:43.840]  Нет, не угадали
[01:01:43.840 --> 01:01:48.840]  Да, экстракт-мин – это единственная операция, которая работает за алгоритмом в амортизированном смысле
[01:01:48.840 --> 01:01:51.840]  Поэтому это суммарное время работы экстракт-мин в любом случае
[01:01:51.840 --> 01:01:53.840]  А за сколько работает дикрискей?
[01:01:53.840 --> 01:01:56.840]  А вот дикрискей для фибоначевой пирамиды работает как раз за единицу
[01:01:56.840 --> 01:01:59.840]  Поэтому тут логарифм уходит
[01:01:59.840 --> 01:02:02.840]  Для фибоначевой пирамиды
[01:02:05.840 --> 01:02:09.840]  Поэтому для фибоначевой пирамиды получается совсем дотика E плюс В лог В
[01:02:09.840 --> 01:02:13.840]  То в логарифм раз лучше, чем…
[01:02:13.840 --> 01:02:18.840]  Если у вас E больше, чем В, то в логарифм раз лучше, чем просто бинарная пирамида
[01:02:18.840 --> 01:02:21.840]  Но с вами говорили, что на практике фибоначевая пирамида обладает большой констант
[01:02:21.840 --> 01:02:25.840]  И поэтому на практике бинарной пирамиды работает гораздо лучше
[01:02:25.840 --> 01:02:28.840]  Ну а симпатически фибоначевая пирамида круче
[01:02:36.840 --> 01:02:39.840]  Ну ладно, другие алгоритмы мы не успеем, значит, на семинарах разберете
[01:02:39.840 --> 01:02:41.840]  Но давайте пока с примой разберемся
[01:02:41.840 --> 01:02:45.840]  Нет, все алгоритмы на самом деле они очень похожи по сути
[01:02:45.840 --> 01:02:48.840]  Смотрите, такая история
[01:02:48.840 --> 01:02:51.840]  А как вам такой план?
[01:02:51.840 --> 01:02:55.840]  Давайте я просто забью на бинарную пирамиду
[01:02:55.840 --> 01:02:58.840]  Ну из-за чего нам нужна была бинарная пирамида?
[01:02:58.840 --> 01:03:01.840]  Для того чтобы эффективно искать минимум
[01:03:01.840 --> 01:03:05.840]  Ну а насколько сильно станет хуже, если я от бинарной пирамиды избавлюсь?
[01:03:05.840 --> 01:03:08.840]  Как вы думаете?
[01:03:08.840 --> 01:03:12.840]  Ну давайте я избавлюсь от бинарной пирамиды, на что это повлияет?
[01:03:12.840 --> 01:03:17.840]  Ну бинарная пирамида мне нужна в двух местах, вот здесь и вот здесь, согласны?
[01:03:17.840 --> 01:03:21.840]  Давайте я избавлюсь от бинарной пирамиды и буду просто-напросто искать минимум в тупую
[01:03:21.840 --> 01:03:25.840]  То есть вот у меня есть массив dist, массив дистанции
[01:03:25.840 --> 01:03:30.840]  Давайте я минимум буду искать в ней в тупую, то есть просто буду линейным образом проходиться по ней и искать там минимум
[01:03:30.840 --> 01:03:33.840]  За сколько будет работать extract min тогда?
[01:03:33.840 --> 01:03:35.840]  За линию, окей
[01:03:35.840 --> 01:03:37.840]  Давайте отдельно напишем
[01:03:37.840 --> 01:03:41.840]  То есть всего итерации у нас v, и за линию работает extract min
[01:03:41.840 --> 01:03:47.840]  То есть v умножить на v, то есть v квадрат, это время
[01:03:47.840 --> 01:03:53.840]  extract min
[01:03:53.840 --> 01:03:57.840]  для массива
[01:03:57.840 --> 01:04:02.840]  Окей, ну вроде как хуже, но v квадрат не очень приятно
[01:04:02.840 --> 01:04:04.840]  Ну ладно, давайте рассуждать дальше
[01:04:04.840 --> 01:04:09.840]  А decrease k, за сколько работает в массиве?
[01:04:09.840 --> 01:04:15.840]  Вот у меня есть конкретная ячейка, я хочу в ней уменьшить значение, за сколько это работает для массива?
[01:04:15.840 --> 01:04:21.840]  За единицу, смотрите, для пирамиды это работает долго, ну то есть для бинарной пирамиды, за алгорифом
[01:04:21.840 --> 01:04:26.840]  Ну потому что мне нужно изменить уменьшить значение ключа и просеять вверх
[01:04:26.840 --> 01:04:30.840]  А в массиве ничего делать не надо, то есть я просто ввижу ячейку, уменьшил в ней значение и все
[01:04:30.840 --> 01:04:33.840]  Соответственно decrease k теперь работает за единицу
[01:04:33.840 --> 01:04:42.840]  То есть получается e умножить на 1, это время decrease k
[01:04:42.840 --> 01:04:47.840]  То есть суммарно получается e плюс v квадрат
[01:04:47.840 --> 01:04:49.840]  Согласны?
[01:04:49.840 --> 01:04:55.840]  То есть в случае пирамиды у нас было e log v, а теперь получилось e плюс v квадрат
[01:04:55.840 --> 01:04:57.840]  Вот реализация с массивом
[01:04:57.840 --> 01:05:01.840]  То есть теперь я тут, грубо говоря, экстракт-мин заменил просто на arg-мин
[01:05:01.840 --> 01:05:05.840]  Ну а decrease k заменил просто на изменение в массиве Дист
[01:05:08.840 --> 01:05:11.840]  E плюс v квадрат то же самое, что v квадрат
[01:05:11.840 --> 01:05:15.840]  Ну можно и так сказать
[01:05:15.840 --> 01:05:18.840]  Короче говоря, мой вопрос вот в чем
[01:05:18.840 --> 01:05:21.840]  Есть реализация на массиве?
[01:05:21.840 --> 01:05:25.840]  Есть реализация на пирамиде?
[01:05:28.840 --> 01:05:31.840]  Кто победит?
[01:05:37.840 --> 01:05:40.840]  Вот, смотрите, то есть мы получаем следующую историю
[01:05:40.840 --> 01:05:44.840]  На самом деле не так, что пирамида эффективна
[01:05:44.840 --> 01:05:51.840]  То есть вроде как кажется, что действительно пирамида это такая структура данных, которая по сути служит для того, чтобы эффективно искать минимум
[01:05:51.840 --> 01:05:56.840]  Но смотрите, все становится не так, как это значит, когда мы говорим про разные типографы
[01:05:56.840 --> 01:05:58.840]  Смотрите, есть у меня граф разреженный
[01:05:58.840 --> 01:06:02.840]  То есть есть у меня E, порядка V
[01:06:02.840 --> 01:06:04.840]  То что тут получается?
[01:06:04.840 --> 01:06:07.840]  Тут получается b квадрат, а тут получается v лог w
[01:06:07.840 --> 01:06:10.840]  П tonnes b явно быстрее, чем v квадрат
[01:06:10.840 --> 01:06:13.840]  Но если у меня граф плотный
[01:06:13.840 --> 01:06:15.840]  То есть есть у меня количество ропINAUDIBLE порядка v квадрат
[01:06:15.840 --> 01:06:16.840]  То что получается?
[01:06:16.840 --> 01:06:19.840]  Тут v квадрат плюс v квадрат все равно v квадрат
[01:06:19.840 --> 01:06:20.840]  А тут v квадрат log v
[01:06:20.840 --> 01:06:27.280]  в квадрат log v, то есть в log v раз больше. То есть мы получаем ситуацию, при которой в зависимости от
[01:06:27.280 --> 01:06:33.200]  типа графа нам вы не используете либо одну структуру данных, либо вторую структуру данных.
[01:06:37.200 --> 01:06:42.200]  Соответственно, если у меня граф разреженный, я использую бинарную пирамиду, то соответственно у меня время работы в log v
[01:06:42.200 --> 01:06:48.200]  для пирамиды в log v, для массива в квадрат. Если я использую плотный граф, то бинарная пирамида работает за в квадрат log v
[01:06:48.200 --> 01:06:56.360]  и массив за v квадрат. То есть мы видим, что для разреженного графа лучше всего использовать бинарную пирамиду,
[01:06:56.360 --> 01:07:01.800]  для плотного графа лучше всего использовать массив. Тут может показаться, что фибоначевая пирамида
[01:07:01.800 --> 01:07:06.080]  вроде как и в том и в другом случае дает оптимальную асимптотику, но на практике нет.
[01:07:06.080 --> 01:07:13.000]  Ну а асимптотика, конечно, та же, но работает значительно дольше. Вывод понятий.
[01:07:18.840 --> 01:07:24.320]  Массив с поддержкой минимума. Ну пирамида это и по сути массив с поддержкой минимума, нет?
[01:07:30.320 --> 01:07:36.320]  Вот. Ну значит, есть еще пара алгоритмов, ну вот их вы разберете на семинарах.
[01:07:36.320 --> 01:07:40.320]  Эти алгоритмы значительно проще. Давайте коротко пробежимся.
[01:07:40.320 --> 01:07:46.320]  На чем стоит алгоритм Краскала? А алгоритм Краскала просто стоит в следующем. Давайте обсудим алгоритм Краскала,
[01:07:46.440 --> 01:07:52.440]  потом пойдем на 5 минут. Хочется дойти до того момента, когда он все-таки пригодится системе не пересекающих нор,
[01:07:52.440 --> 01:07:58.440]  с которым мы зачем-то обсуждали. Алгоритм Краскала очень простой, очень простой.
[01:07:58.440 --> 01:08:06.440]  Возьмем ребра, список ребр и отсортировываем их по весу, sd sort, сортировка ребр по весу.
[01:08:06.440 --> 01:08:11.440]  А дальше просто в тупую будем идти по этому сортированному списку и добавлять, соответственно,
[01:08:11.560 --> 01:08:15.560]  добавлять ребро, если оно не будет давать нам цикл.
[01:08:15.560 --> 01:08:19.560]  Ну вот, просто нам дам список ребр.
[01:08:19.560 --> 01:08:25.560]  E1, E2, E3, E4, E5 и так далее.
[01:08:25.560 --> 01:08:31.560]  Вот, добавили ребро E1, потом добавили ребро E2, потом добавили ребро E3.
[01:08:31.560 --> 01:08:35.560]  И вот у нас появилось ребро E4,
[01:08:35.680 --> 01:08:39.680]  который образует цикл. Вот если ребро E4 образует цикл,
[01:08:39.680 --> 01:08:45.680]  то я его просто скипаю, перехожу к следующему. Ну и так далее, пока у меня не получится дерево.
[01:08:45.680 --> 01:08:51.680]  Вопрос, как мне проверить, будет ли ребро давать цикл или нет?
[01:08:51.680 --> 01:08:55.680]  В каком случае ребро мне будет давать цикл?
[01:08:55.680 --> 01:09:01.680]  Вот, когда у меня эта вершина и эта вершина находятся в одной компоненте связности.
[01:09:01.800 --> 01:09:05.800]  Если у меня ребро соединяет две вершины из одной компоненты связности,
[01:09:05.800 --> 01:09:09.800]  то соответственно у меня получается цикл, поэтому это ребро я должен пропустить.
[01:09:09.800 --> 01:09:15.800]  А если ребро соединяет две вершины из разных компонент связности,
[01:09:15.800 --> 01:09:19.800]  то это нормальное ребро. Ну и главный вопрос, как проверить,
[01:09:19.800 --> 01:09:23.800]  лежат ли две вершины в одной компоненте связности или нет?
[01:09:23.800 --> 01:09:27.800]  С помощью системы непересекающих ножей.
[01:09:27.920 --> 01:09:31.920]  Вот алгоритм красного.
[01:09:31.920 --> 01:09:35.920]  Сортируем ребра, создаем системы непересекающих множеств.
[01:09:35.920 --> 01:09:39.920]  Создаем одноэлементные множества.
[01:09:39.920 --> 01:09:43.920]  И дальше просто в цикле проходим по сортированным ребрам.
[01:09:43.920 --> 01:09:47.920]  Если вершина В и вершина У, которые являются концами этого ребра,
[01:09:47.920 --> 01:09:52.920]  лежат в разных компонентах, то объединяем эти две компоненты
[01:09:53.040 --> 01:09:57.040]  и добавляем данное ребро в минимально основное дерево.
[01:09:57.040 --> 01:10:01.040]  Ну и так далее.
[01:10:01.040 --> 01:10:05.040]  А вот простой алгоритм. Соответственно, алгоритм работает за Е лог Е, ну или за Е лог В.
[01:10:05.040 --> 01:10:09.040]  Просто чисто за счет сортировки. Все остальное работает за линейное время.
[01:10:09.040 --> 01:10:12.040]  Окей?
[01:10:12.040 --> 01:10:16.040]  Все, ну а другой алгоритм уже на семинара.
[01:10:16.040 --> 01:10:20.040]  Спасибо.
[01:10:20.040 --> 01:10:24.160]  Спасибо.
