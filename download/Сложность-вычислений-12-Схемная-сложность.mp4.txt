[00:00.000 --> 00:10.000]  Добрый день. У нас уже остается не очень много лекций.
[00:10.000 --> 00:19.000]  Основная цель – успеть изучить схемную сложность и вероятностные вычисления.
[00:19.000 --> 00:24.000]  Соответственно, сегодня со схемной сложности начнем.
[00:24.000 --> 00:30.000]  Давайте я начну демонстрацию экрана.
[00:30.000 --> 00:34.000]  Вот схемная сложность.
[00:34.000 --> 00:42.000]  И хочу я начать анонсированную разговору про быстрые сумматоры.
[00:42.000 --> 00:56.000]  Мы в главе про логермическую память изучали, что самый обычный метод сложения столбик
[00:56.000 --> 01:03.000]  использует логермическую память, если записи лежат отдельно.
[01:03.000 --> 01:11.000]  Даже логермическую память не нужна. Нужна константная память.
[01:11.000 --> 01:19.000]  Сложение дуэчных чисел – это базовая операция в процессоре.
[01:19.000 --> 01:28.000]  Поэтому важно, чтобы она происходила очень быстро.
[01:28.000 --> 01:46.000]  Если мы посмотрим на то, как она происходит в нашем протоколе
[01:46.000 --> 02:04.000]  Обычное сложение столбик с подсчетом переносов.
[02:04.000 --> 02:14.000]  Пусть будет два числа.
[02:14.000 --> 02:23.000]  И у них тут какие-то биты заданы.
[02:23.000 --> 02:29.000]  На самом деле нам тут много не надо. Пусть будет 4-битовое число.
[02:29.000 --> 02:34.000]  Их обозначим.
[02:34.000 --> 02:42.000]  По-всякому бывает, что сначала индексируешь, что с конца.
[02:42.000 --> 02:50.000]  Теперь надо делать x1, x2, x3, x4.
[02:50.000 --> 03:09.000]  Здесь y1, y2, y3, y4.
[03:09.000 --> 03:15.000]  Как устроено обычное сложение столбик?
[03:15.000 --> 03:29.000]  Смотрите, мы берем два последних бита и с ними делаем две операции.
[03:29.000 --> 03:43.000]  Одна операция – это ксор.
[03:43.000 --> 03:52.000]  И это уже будет ответ.
[03:52.000 --> 03:56.000]  Другая операция – это конъюнция.
[03:56.000 --> 04:14.000]  Конъюнция говорит, будет ли перенос следующий разряд.
[04:14.000 --> 04:20.000]  Дальше мы уже складываем следующие два бита.
[04:20.000 --> 04:26.000]  И мы уже будем делать конъюнцию.
[04:26.000 --> 04:31.000]  Это конъюнция.
[04:31.000 --> 04:41.000]  И конъюнция говорит, будет ли перенос следующий разряд.
[04:41.000 --> 04:49.000]  Дальше мы уже складываем следующие два бита и перенос.
[04:49.000 --> 05:08.000]  Дальше будет получаться, что у нас 1, 2, 3.
[05:08.000 --> 05:21.000]  У нас опять ксор.
[05:21.000 --> 05:24.000]  Это очередной бит ответа.
[05:24.000 --> 05:32.000]  Дальше нам нужно еще получить перенос на следующий раз.
[05:32.000 --> 05:37.000]  И он на самом деле получается функцией большинства.
[05:37.000 --> 05:47.000]  Если хотя бы две единицы есть, то в сумме будет больше.
[05:47.000 --> 06:12.000]  И больше, поэтому будет перенос.
[06:12.000 --> 06:20.000]  Тут только максимум есть.
[06:20.000 --> 06:24.000]  Будет функция большинства.
[06:24.000 --> 06:30.000]  Если две или три единицы, то будет перенос следующий разряд.
[06:30.000 --> 06:34.000]  Ну и дальше это продолжается.
[06:34.000 --> 07:01.000]  Тут получается ксор.
[07:01.000 --> 07:26.000]  Дальше получается большинство.
[07:26.000 --> 07:29.000]  Ну и еще раз.
[07:29.000 --> 07:32.000]  Давайте уже дорисуем полную картину.
[07:32.000 --> 07:39.000]  Получается ксор.
[07:39.000 --> 07:55.000]  Соответственно, из вот этого, вот этого и вот этого.
[07:55.000 --> 08:04.000]  И, наконец, возникает большинство, которое будет пятым битом.
[08:04.000 --> 08:19.000]  Поскольку это уже будет на выход.
[08:19.000 --> 08:37.000]  Соответственно, получается вот так вот.
[08:37.000 --> 08:50.000]  Тут получается вот таким вот образом суммирование 4-битовых чисел школьным алгоритмом.
[08:50.000 --> 08:53.000]  Ну что мы здесь видим?
[08:53.000 --> 09:22.000]  Мы здесь видим, что чем больше разрядов в числах, тем длиннее цепочка зависимости.
[09:22.000 --> 09:47.000]  Чтобы посчитать результат в некотором разряде, нужно посчитать перенос.
[09:47.000 --> 10:09.000]  Значит, для этого посчитать результат в предыдущем разряде, а для этого посчитать перенос в предыдущем разряде.
[10:09.000 --> 10:16.000]  Ну и так далее.
[10:16.000 --> 10:40.000]  Соответственно, если вычисление результата операции занимает время Эпсилон,
[10:40.000 --> 10:59.000]  то, соответственно, такая длина максимальной цепочки зависимости будет как раз временем выполнения вычисления.
[10:59.000 --> 11:09.000]  Ну а поскольку время это то, что нас больше всего интересует, то нас как раз интересует вот такая вот цепочка.
[11:09.000 --> 11:19.000]  Ну вот на самом деле процессоры, настоящие компьютерные процессоры, как правило, устроены так.
[11:19.000 --> 11:25.000]  Пока у них еще 4-битовые числа, они делают примерно то, что здесь нарисовано.
[11:25.000 --> 11:36.000]  Но когда возникают более длинные числа, то они их бьют на блоке по 4-бита и как-то комбинируют результаты.
[11:36.000 --> 11:46.000]  Вот. Это называется быстрые сумматоры.
[11:46.000 --> 11:56.000]  Значит, быстрые сумматоры.
[11:56.000 --> 12:03.000]  Быстрые сумматоры – это процедуры,
[12:03.000 --> 12:26.000]  которые позволяют вычислить биты переносов, не проводя все промежуточные вычисления.
[12:26.000 --> 12:38.000]  Ну и один из примеров давайте изучим.
[12:38.000 --> 12:46.000]  Значит, пример быстрого сумматора.
[12:46.000 --> 13:06.000]  Для каждой позиции, не для каждой позиции, а для каждого промежутка от и до жи,
[13:06.000 --> 13:15.000]  значит, выведем 2 бита.
[13:15.000 --> 13:31.000]  Значит, j и jt означают, что на этом промежутке
[13:31.000 --> 13:39.000]  генерируется перенос.
[13:39.000 --> 13:54.000]  Значит, то есть, если мы возьмем фрагмент х и сложим с фрагментом у,
[13:54.000 --> 14:12.000]  это будет больше либо равно, чем 2 в степени g- и плюс 1.
[14:12.000 --> 14:23.000]  То есть, смотрите, что 2 в степени какое-то число занимает как раз n плюс 1 бит,
[14:23.000 --> 14:30.000]  а любое число меньше, чем 2 в степени занимает максимум n битов.
[14:30.000 --> 14:38.000]  Вот, соответственно, получается, что если вот здесь, на этом промежутке,
[14:38.000 --> 14:44.000]  генерируется перенос, то, соответственно, не важно, что там в хвосте происходит после житого,
[14:44.000 --> 14:52.000]  все равно будет... Ну, например, идея такая, что если тут x, 3 равно единице,
[14:53.000 --> 14:57.000]  то не важно, придет ли перенос отсюда, точно уже большинство равно единице,
[14:57.000 --> 15:03.000]  поэтому сюда перенос уйдет.
[15:03.000 --> 15:12.000]  Вот, и есть еще другой бит, p и gt.
[15:12.000 --> 15:26.000]  Этот промежуток сам не генерирует перенос, но проталкивает его.
[15:26.000 --> 15:32.000]  То есть g от слова generation, p от слова propagation.
[15:33.000 --> 15:43.000]  Значит, проталкивает означает, на самом деле, что вот такая вот сумма соответствующих фрагментов
[15:43.000 --> 15:56.000]  равна 2 в степени g минус и плюс 1, минус 1.
[15:56.000 --> 16:05.000]  Да, то есть и это равно 1, 1 и так далее, 1. Значит, здесь будет g минус и плюс 1 раз.
[16:05.000 --> 16:32.000]  Вот, хорошо. Значит, теперь эти биты можно считать рекурсивно.
[16:35.000 --> 16:53.000]  Так, значит, рекурсивный подсчет g и gt и p и gt.
[16:53.000 --> 17:00.000]  Так, начну. База. База это когда и равно g.
[17:00.000 --> 17:05.000]  Тогда g и t и t это просто конъюнкция.
[17:05.000 --> 17:10.000]  Ну, это x и t конъюнкция y и t.
[17:10.000 --> 17:14.000]  Вот, а p и t и t это соответственно ксор.
[17:14.000 --> 17:26.000]  Значит, x и t плюс ксор y и t.
[17:26.000 --> 17:41.000]  Переход. Переход будет выглядеть так, что g и kt будут равняться следующим.
[17:41.000 --> 18:03.000]  Это будет g и gt или g plus 1 kt и p и gt.
[18:03.000 --> 18:16.000]  То есть либо у нас перенос прям сгенерировался уже в голове, либо он сгенерировался в хвосте и, соответственно, протолкнулся через голову.
[18:16.000 --> 18:20.000]  Потому что, смотрите, если вот эта тут сумма будет не из всех единиц,
[18:20.000 --> 18:32.000]  тогда даже если в конец перенос придет, то он будет обнулять, обнулять эти единицы, а потом там, где будет 0, там получат единицы и все, дальше перенос не протолкнулся.
[18:32.000 --> 18:42.000]  А если, соответственно, те единицы, то если с хвоста придет единица, то они все обнулятся и вперед тоже придет единица.
[18:42.000 --> 19:02.000]  Так, дальше, соответственно, p и kt, это будет равно p и gt и p g plus 1 kt.
[19:02.000 --> 19:11.000]  Да, то есть тут получил суммы всех единиц в большом интервале, если и в первой половине все единицы, и во второй половине все единицы.
[19:11.000 --> 19:18.000]  Так, ну и дальше получается идея следующая.
[19:18.000 --> 19:37.000]  Значит, идея такая, что мы посчитаем сначала для каждого бита.
[19:37.000 --> 20:01.000]  Значит, потом, значит, для цепочки из двух битов, вот так вот выровненный.
[20:01.000 --> 20:21.000]  Значит, потом для цепочки из четырех битов.
[20:21.000 --> 20:37.000]  Сейчас потом для цепочки из восьми, ну и так далее.
[20:37.000 --> 20:59.000]  Ну, давайте еще один шаг, так легко копировать.
[20:59.000 --> 21:15.000]  Вот так вот у нас здесь получается вот так.
[21:15.000 --> 21:30.000]  Ну и теперь смотрите, например, в каждом из этих отрезков можно вот так рекурсивно посчитать биты генерации проталкивания.
[21:30.000 --> 21:44.000]  Ну а теперь нам нужно понять, будет ли перенос в какой-то конкретной точке.
[21:44.000 --> 21:57.000]  Значит, перенос к точке И.
[21:57.000 --> 22:05.000]  Значит, это на самом деле генерация от И до Н.
[22:05.000 --> 22:16.000]  Ну, например, нам нужно понять, будет ли перенос, ну скажем, через эту точку.
[22:16.000 --> 22:21.000]  Значит, тогда мы весь хвост от этой точки до конца.
[22:21.000 --> 22:35.000]  Представим, как объединение вот таких вот выровненных кусочков.
[22:35.000 --> 22:50.000]  И для каждого из этих кусочков мы уже посчитали генерацию и проталкивание.
[22:50.000 --> 22:59.000]  Ну и тогда получается, давайте я тут запятую поставлю, чтобы было и Н, а не И.
[22:59.000 --> 23:01.000]  Так же и Н.
[23:01.000 --> 23:09.000]  Ну а дальше получается так, что же и Н.
[23:09.000 --> 23:18.000]  Да, значит, это будет там какое-то g и gt.
[23:18.000 --> 23:32.000]  Или, соответственно, g, g плюс 1, kt и p и gt.
[23:32.000 --> 23:52.000]  Или g, k плюс 1, lt и p, g плюс 1, kt и p и gt.
[23:52.000 --> 23:58.000]  Ну или и так далее.
[23:58.000 --> 24:10.000]  Соответственно, все вот эти биты, генерации проталкивания, они на предыдущем шаге подсчитались.
[24:10.000 --> 24:21.000]  Ну и тогда получается, что максимальная длина зависимости будет как раз порядка логарифма.
[24:21.000 --> 24:30.000]  Ну представите, если тут всего n-битов, то по высоте тут будет как раз порядка логарифма.
[24:30.000 --> 24:58.000]  То есть если, значит, вот эта длиция, если, значит, по ширине получается n-битов.
[24:58.000 --> 25:10.000]  То по высоте получается логарифма n-битов.
[25:28.000 --> 25:36.000]  Ну там верхняя целая часть, давайте я куда-то напишу.
[25:36.000 --> 26:01.000]  Целая часть логарифма n-битов.
[26:01.000 --> 26:07.000]  Соответственно, здесь получается длина зависимости как раз порядка логарифма n.
[26:07.000 --> 26:15.000]  Потому что каждый переход на следующую строчку – это вложенность длины либо 1, либо 2.
[26:15.000 --> 26:22.000]  Поэтому все вместе длина зависимости будет порядка логарифма, может, на 2 умноженное.
[26:22.000 --> 26:34.000]  Ну и вот здесь, поскольку тут разложение в двоечную запись, то получается, что здесь спочку тоже длины порядка логарифма.
[26:34.000 --> 26:36.000]  И в скобках тоже порядка логарифма.
[26:36.000 --> 26:49.000]  Поэтому там длина зависимости тоже будет, в принципе, можно даже сказать, что будет повторный логарифм.
[26:49.000 --> 26:55.000]  Поэтому это будет на длина зависимости все вместе порядка логарифма.
[26:55.000 --> 27:03.000]  Если битов всего 4, то в сравнении с этим не будет особого выигрыша.
[27:03.000 --> 27:10.000]  Но если битов больше, там уже даже 8.
[27:10.000 --> 27:21.000]  Так скорее, современные процессоры работают с 32-битовыми, с 64-битовыми числами.
[27:21.000 --> 27:26.000]  Там как раз что-то похожее нужно делать.
[27:26.000 --> 27:32.000]  Иначе они будут работать сильно медленнее.
[27:32.000 --> 27:40.000]  Есть какие-нибудь вопросы по поводу этой конструкции?
[27:40.000 --> 27:49.000]  Давайте я напишу вывод.
[27:49.000 --> 28:04.000]  Максимальная длина зависимости будет не больше.
[28:04.000 --> 28:13.000]  Так, не больше, просто будет побольше, это и так не больше.
[28:13.000 --> 28:20.000]  Ну ладно, если нет, то перейдем к общей теории.
[28:20.000 --> 28:25.000]  Что здесь нас вообще интересует?
[28:25.000 --> 28:34.000]  Общая теория – схема из функциональных элементов.
[28:34.000 --> 28:42.000]  На самом деле есть три взгляда на схему.
[28:42.000 --> 28:52.000]  Первая – это размеченные ориентированные графы без циклов.
[28:52.000 --> 29:02.000]  Вторая – это машины тьюринга, получающие подсказку.
[29:02.000 --> 29:07.000]  И третья – это прямолинейные программы.
[29:07.000 --> 29:17.000]  Соответственно, давайте на все три способа посмотрим и докажем, что они эквивалентны.
[29:17.000 --> 29:25.000]  Так, первая – это арграфы без циклов.
[29:25.000 --> 29:33.000]  Здесь – арграфы без циклов.
[29:33.000 --> 29:54.560]  Чահя цикл,
[29:54.560 --> 30:09.560]  Вершины могут быть помеченными несколькими метками.
[30:10.560 --> 30:20.560]  Так, первая in – это входящая вершина, выходная вершина.
[30:23.560 --> 30:29.560]  Так, out – это соответственно выходная вершина.
[30:32.560 --> 30:37.560]  Ну и дальше, третья – это логическая операция.
[30:39.560 --> 30:41.560]  Их список можно варьировать.
[30:42.560 --> 30:52.560]  Давайте будем считать, что операция – это только отрицание, конъюнкция и дезюнкция.
[30:52.560 --> 31:16.560]  При этом входящая степень у in – ноль, у out – один.
[31:16.560 --> 31:20.560]  С out в принципе есть два варианта.
[31:21.560 --> 31:25.560]  В этой картине направление имеется сверху вниз.
[31:26.560 --> 31:36.560]  И один вариант – это считать, соответственно, вот эти вот x – это входящая вершина, а y – это исходящая вершина.
[31:37.560 --> 31:48.560]  Можно считать, что от этих голубых вершин еще одно ребро идет как раз в формальную входную вершину, и там просто копируется.
[31:49.560 --> 31:55.560]  А можно считать, что тут наша метка out может быть совмещена с любой другой меткой.
[31:55.560 --> 32:13.560]  Соответственно, вот эти вот метки, вершины помещены xor и out.
[32:14.560 --> 32:16.560]  Вот эти помещены majority и out.
[32:16.560 --> 32:21.560]  Понятно, что у меня там в списке базовых операций нет xor и majority.
[32:22.560 --> 32:29.560]  Поэтому их нужно еще выразить таким же схемами через что-то.
[32:31.560 --> 32:40.560]  Но в принципе можно наоборот ввести любые булевые функции в список возможных типов элементов.
[32:46.560 --> 32:51.560]  Я считаю, что out – это будет отдельный вершин, который мы там не нарисовали.
[32:52.560 --> 33:03.560]  У in 1, у out 1, у отрицания 1.
[33:04.560 --> 33:13.560]  А про конъюнцию и дизъюнцию – два варианта.
[33:14.560 --> 33:19.560]  Либо два, либо произвольная.
[33:20.560 --> 33:27.560]  Соответственно, если степень 2, то получается, что этот элемент вычитает конъюнции только двух.
[33:27.560 --> 33:33.560]  Если степень произвольная, то конъюнцию всех своих аргументов он может вычислить.
[33:33.560 --> 34:00.560]  Ну а исходящая степень можно считать так, что у out 0, значит у остальных произвольная.
[34:03.560 --> 34:15.560]  Ну тогда получается, что если…
[34:15.560 --> 34:31.560]  Ну можно еще назвать высотой вершины.
[34:31.560 --> 34:45.560]  Значит, высота вершины – это длина пути от входной вершины до данной.
[34:45.560 --> 35:13.560]  Соответственно, если всем входным вершинам задать более вызначение,
[35:13.560 --> 35:37.560]  то и всем остальным вершинам тоже можно задать значение рекурсивно по высоте вершины.
[35:37.560 --> 35:54.560]  То есть у входящих получается высота 0.
[35:54.560 --> 36:10.560]  Каждый раз, когда мы значение всем вершинам высоты k сопоставили, то дальше высоту k плюс 1 тоже можно посчитать.
[36:10.560 --> 36:26.560]  Просто потому что все вершины, из которых идут ребра в данное значение, можно их подставить в blue функцию.
[36:26.560 --> 36:31.560]  Ну а в out надо просто копировать из предыдущего.
[36:31.560 --> 36:43.560]  Поэтому как раз отдельно вершины out можно не заводить, а можно делать это как пометку.
[36:43.560 --> 36:59.560]  Значит, значение out вершин зададут значение…
[36:59.560 --> 37:19.560]  Новый результат работы. Вдут результат работы всей схемы.
[37:19.560 --> 37:47.560]  Если выходная вершина 1, то схема с n входными вершинами распознает некоторое подмножество.
[37:47.560 --> 38:01.560]  А n будет некоторое подмножество 0,1.
[38:01.560 --> 38:29.560]  Если входных вершин больше, то вычисляется некоторая дискретная функция.
[38:29.560 --> 38:55.560]  Вот, хорошо.
[38:55.560 --> 39:11.560]  Ну и еще можно сказать, что если для каждого n задана некоторая своя схема,
[39:11.560 --> 39:35.560]  с одним выходом, то все это семейство распознает некоторый язык, но уже произвольные длины.
[39:35.560 --> 39:50.560]  Ну имеется в виду, что если выход будет 1, то вход должен лежать в языке.
[39:50.560 --> 40:01.560]  Если выход будет 0, то вход должен не лежать в языке.
[40:01.560 --> 40:13.560]  Ладно, я тебе еще какой-нибудь пример приведу.
[40:13.560 --> 40:21.560]  Так, например, вот как, собственно, XOR выглядит.
[40:21.560 --> 40:36.560]  Значит, вот есть два бита, x и y.
[40:36.560 --> 40:55.560]  Дальше мы добавляем отрицание.
[40:55.560 --> 41:05.560]  Дальше будет еще конъюнция.
[41:05.560 --> 41:23.560]  И в итоге дисьюнция.
[41:23.560 --> 41:43.560]  Отрицание, конъюнция, конъюнция и дисьюнция.
[41:43.560 --> 41:47.560]  Ну или там можно и наоборот, в принципе.
[41:47.560 --> 41:53.560]  Значит, вот мы сделали не x, сделали не y.
[41:53.560 --> 42:01.560]  Дальше мы понимаем, что не x и y, то есть это 0,1.
[42:01.560 --> 42:10.560]  Значит, может быть наоборот, x и не y.
[42:10.560 --> 42:17.560]  И, соответственно, вот одно из двух.
[42:17.560 --> 42:36.560]  Ну и тут, в принципе, можно условно еще дописать вершину out.
[42:36.560 --> 42:48.560]  Вот, да, а сейчас у нас тут есть два важнейших, значит, две важнейших характеристики.
[42:48.560 --> 43:00.560]  Значит, размер схемы, размер схемы – это общее число вершин в графе.
[43:00.560 --> 43:12.560]  А глубина схемы – это максимальная высота вершины.
[43:12.560 --> 43:39.560]  Ну и, соответственно, теорема, любая бульва-функция вычисляется схемой от n переменных.
[43:39.560 --> 43:53.560]  Вычисляется схемой размера O от n на 2 в степени n и глубиной.
[43:53.560 --> 44:02.560]  Но тут, смотря, опять же, что считать, значит, глубина 3 имеется в виду, что входные и выходные не учитываются.
[44:02.560 --> 44:08.560]  То есть, если входные ноль, то будет 1, 2, 3.
[44:08.560 --> 44:17.560]  Значит, с учетом out получается 4.
[44:17.560 --> 44:28.560]  Ну, потому что вот то, что ясно, это DNF, а мы знаем, что функция ворота через DNF или через KNF,
[44:28.560 --> 44:38.560]  поэтому такого рода схема возможна для любой функции.
[44:38.560 --> 44:49.560]  Вот. Значит, это простая теорема, которую мы на первом курсе изучали.
[44:49.560 --> 45:02.560]  А также есть теорема Лупанова.
[45:02.560 --> 45:20.560]  Уже без ограничений на глубину. Тут будет вместо умножения на n будет деление на n.
[45:20.560 --> 45:27.560]  Так, и теорема Шинонна.
[45:27.560 --> 45:54.560]  Ну что, некоторые волевые функции от n переменных вычисляются только схемами размера Омега от 2 в степени n и глубиной.
[45:54.560 --> 46:06.560]  Ну вот, идея теоремы Лупанова – это хитрое переиспользование каких-то фрагментов функций, которые похожи в разных частях.
[46:06.560 --> 46:20.560]  А идея теоремы Шинонна – это просто принцип Дерехлия, что мы докажем, что просто не может быть слишком много разных схем меньше размера.
[46:20.560 --> 46:35.560]  Вообще в целом можно сказать, что схемы – это такое обобщение волевых формул.
[46:35.560 --> 46:42.560]  Только тут получается, что одну и ту же часть можно использовать несколько раз.
[46:42.560 --> 46:46.560]  И в этом смысле они как раз похожи на прямолинейные программы.
[46:46.560 --> 46:48.560]  Давайте сейчас о них поговорим.
[46:48.560 --> 46:54.560]  Значит, схемы как прямолинейные программы.
[46:54.560 --> 47:00.560]  Так, а что такое прямолинейная программа?
[47:00.560 --> 47:14.560]  Значит, это SLP, Straight Line Program.
[47:14.560 --> 47:35.560]  Это программы, не имеющие ни циклов, ни условных операторов, а только лишь операции присваивания.
[47:35.560 --> 47:53.560]  Например, если переложить эту картинку на прямолинейную программу, то она будет примерно такой.
[47:53.560 --> 48:01.560]  Значит Z равняется отрицанию X.
[48:01.560 --> 48:07.560]  Дальше T равняется отрицанию Y.
[48:07.560 --> 48:16.560]  U равняется Z и Y.
[48:16.560 --> 48:22.560]  V равняется X и T.
[48:22.560 --> 48:46.560]  Ну и в конце W равняется U или V.
[48:46.560 --> 48:58.560]  Вот эта прямолинейная программа, ее можно сверху вниз по очереди исполнить.
[48:58.560 --> 49:19.560]  Ну и тогда, соответственно, мы считаем, что N переменных заранее перечислены и даются извне.
[49:19.560 --> 49:31.560]  Вот остальные вычисляются по командам программы.
[49:31.560 --> 49:41.560]  Ну и, соответственно, последняя переменная дает ответ.
[49:41.560 --> 49:52.560]  Ну или сколько-то последних переменных.
[49:52.560 --> 50:15.560]  Вот.
[50:15.560 --> 50:40.560]  Дальше идея такая, что можно переделать схему CoreGraph в прямолинейную программу.
[50:40.560 --> 51:02.560]  Если завести переменную для каждого узла и в порядке увеличения высоты,
[51:02.560 --> 51:12.560]  значит записать соответствующую команду присваивания.
[51:12.560 --> 51:22.560]  Ну, собственно, то, что я сделал, когда писал вот это вот, значит, я сказал, что теперь вот тут будет Z, вот тут будет T,
[51:22.560 --> 51:36.560]  тут будет V, тут будет W и, соответственно, каждую команду запишем.
[51:36.560 --> 51:53.560]  Ну и обратно можно превратить программу CoreGraph,
[51:53.560 --> 52:19.560]  значит, заведя вершину для каждой переменной и проведя, значит, проведя ребра от переменных, участвующих в правой части.
[52:19.560 --> 52:43.560]  К переменной, стоящей слева.
[52:43.560 --> 52:54.560]  Вот. Поэтому, на самом деле, более-менее ясно, что схемы и прямолинейные программы – это более-менее два способа описания одной и той же структуры.
[52:54.560 --> 53:02.560]  Ну а машинная тюринга с подсказкой – это немножко другая вещь.
[53:02.560 --> 53:14.560]  Значит, машинная тюринга с подсказкой Advice.
[53:14.560 --> 53:37.560]  Значит, эта машина, которая дополнительно ко входу X длины N, получает подсказку AN,
[53:37.560 --> 53:52.560]  но которая одна и та же, одна и ту же для всех слов данной длины.
[53:52.560 --> 54:18.560]  Вот. Ну и тогда, значит, тут есть определение.
[54:18.560 --> 54:20.560]  Значит, тут идея следующая.
[54:20.560 --> 54:37.560]  Да, значит, тут уже любую…
[54:37.560 --> 55:05.560]  В любой схеме можно сопоставить машину, которая может вычислять значения произвольной схемы
[55:05.560 --> 55:19.560]  и получает эту схему в виде подсказки.
[55:19.560 --> 55:27.560]  То есть машина получает какой-то X и схему, а дальше просто эту схему применяет к X, и вот это ее ответ.
[55:27.560 --> 55:39.560]  Ну и наоборот, значит, наоборот, машину можно превратить в схему.
[55:39.560 --> 55:45.560]  Значит, это несколько более хитрое действие.
[55:45.560 --> 55:54.560]  Значит, я так аккуратно напишу. Значит, это аналогично теореме Кукалевина.
[55:54.560 --> 56:04.560]  Но не то чтобы аккуратно.
[56:04.560 --> 56:24.560]  Идея такая, что у машины может быть некоторый вход, ну и дальше машина начинает с ним что-то делать,
[56:24.560 --> 56:30.560]  но каждый раз можно считать, что следующая конфигурация получается по какой-то схеме из предыдущей,
[56:30.560 --> 56:34.560]  а схема такая же, как в теореме Кукалевина.
[56:34.560 --> 56:49.560]  Машину можно превратить в схему аналогично к теореме Кукалевина и затем зафиксировать подсказку.
[56:49.560 --> 57:08.560]  И тут есть обозначение, значит, Dtime от t от n slash a от n.
[57:08.560 --> 57:33.560]  Значит, это класс языков, которые распознаются машиной тюринга с подсказкой длины a от n за время t от n.
[57:38.560 --> 57:57.560]  Ну и в частности, значит, есть класс P slash Poli.
[57:57.560 --> 58:11.560]  Это у нас объединение по c и d от единицы до бесконечности.
[58:11.560 --> 58:30.560]  А тут будет Dtime, значит Dtime от n степени c.
[58:30.560 --> 58:45.560]  От n степени c slash от n степени d.
[58:45.560 --> 59:13.560]  Ну и с другой стороны, это самое P slash Poli.
[59:13.560 --> 59:35.560]  Так, P slash Poli – это класс языков, которые распознаются семействами схем полиномерного размера.
[59:35.560 --> 59:39.560]  В смысле числа вершин.
[59:39.560 --> 59:54.560]  Ну как раз вот это вот объяснение показывает, почему это одно и то же.
[59:54.560 --> 01:00:02.560]  Потому что с одной стороны, если у нас есть такие схемы полиномерного размера,
[01:00:02.560 --> 01:00:06.560]  тогда мы можем их превратить в подсказку, и подсказка будет тоже полиномерного размера.
[01:00:06.560 --> 01:00:10.560]  Ну а в другую сторону вот так вот.
[01:00:10.560 --> 01:00:26.560]  Давайте превращаем машину и фиксируем подсказку полиномерной длины, получаем схему полиномерного размера.
[01:00:26.560 --> 01:00:54.560]  Вот получается эквивалентность про P slash Poli.
[01:00:54.560 --> 01:01:19.560]  Ну в принципе из обоих определений получаем, что P вложено в P slash Poli.
[01:01:19.560 --> 01:01:41.560]  Вот при этом вложение строгое.
[01:01:41.560 --> 01:02:01.560]  Потому что P slash Poli может содержать даже не вычислимые, не разрешимые языки.
[01:02:01.560 --> 01:02:21.560]  Пример такой, пример унарный язык, 1 степени N, так что машина тюринга на N останавливается.
[01:02:21.560 --> 01:02:33.560]  Называется unary halt. Унарная проблемная остановка, оно словно 1 единиц.
[01:02:33.560 --> 01:02:36.560]  И нужно проверить верно ли что машина номер N останавливается.
[01:02:36.560 --> 01:02:55.560]  Это не you halt, а you self-applicability.
[01:02:55.560 --> 01:03:17.560]  Унарная задача у самопременимости, верно ли что если N машину запустить на ней самой, то тогда она останавливается.
[01:03:17.560 --> 01:03:29.560]  Это вообще неразрешимый язык, потому что проблема установки, проблема самопременимости, как ни скодируете, все равно они будут неразрешимыми.
[01:03:29.560 --> 01:03:55.560]  Это язык неразрешим, так что точно не лежит в P, но он лежит в dead time.
[01:03:55.560 --> 01:04:08.560]  Это вообще можно прям точно сказать, dead time, slash 1, dead time от N, slash 1.
[01:04:08.560 --> 01:04:18.560]  Это зеленейное время, подсказка длинная 1.
[01:04:18.560 --> 01:04:39.560]  Читаем вход, если в нем есть нули, то отвергаем. Если нет, значит если он только из единиц, то смотрим подсказку.
[01:04:39.560 --> 01:04:51.560]  Подсказка нам скажет, остановится она или нет, и это даст правильный ответ.
[01:04:51.560 --> 01:05:03.560]  Вся сложность получается именно в том, что непонятно как зависит эта подсказка от длины, а не в длине подсказки.
[01:05:03.560 --> 01:05:31.560]  То есть сложность, неразрешимость берется из-за того, что нельзя вычислить, как подсказка зависит от длины.
[01:05:31.560 --> 01:05:45.560]  Ну ладно, соответственно, может быть вариация проблемы.
[01:05:45.560 --> 01:06:13.560]  Вариация проблемы P и NP. Вариация проблемы P и NP это вопрос о том, верно ли что NP вложено в slash поле.
[01:06:13.560 --> 01:06:41.560]  Если вдруг вложено, значит если NP вложено в slash поле, то для решения NP-задач фиксированного размера
[01:06:41.560 --> 01:07:02.560]  можно изготавливать малые микросхемы, которые их решают, и потом их использовать.
[01:07:11.560 --> 01:07:32.560]  Соответственно, получается, что это важный вопрос, но есть некоторая связь этого вопроса с вопросами обычной сложности.
[01:07:32.560 --> 01:07:38.560]  Это называется теорема Карпа Липтона.
[01:07:38.560 --> 01:08:03.560]  Если NP вложено в slash поле, то тогда на самом деле полинарархия схлопывается на втором уровне.
[01:08:03.560 --> 01:08:17.560]  Поэтому, если мы верим, что полинарархия не схлопывается, тогда схема нам тоже не подведет решение NP-задач.
[01:08:17.560 --> 01:08:27.560]  Попробую за 10 минут доказать, и на этом сегодня закончу.
[01:08:27.560 --> 01:08:45.560]  Смотрите, нам достаточно доказать, что P2 равняется sigma2.
[01:08:45.560 --> 01:09:00.560]  Это мы уже изучали про иерархию, что если на каком-то уровне схлопывается, то их последующие тоже схлопываются и наоборот.
[01:09:00.560 --> 01:09:22.560]  А для этого достаточно доказать, что задача P2-сад лежит в sigma2.
[01:09:30.560 --> 01:09:42.560]  Смотрите, что у нас такое P2-сад. Давайте вспомним.
[01:09:42.560 --> 01:10:06.560]  P2-сад. Это есть множество таких phi, что для любого x существует phi от x, y.
[01:10:06.560 --> 01:10:33.560]  Если мы x зафиксируем и рассмотрим теперь такой язык, то пар phi, x таких, что существует phi от x, y, лежит в NP, потому что тут существование.
[01:10:33.560 --> 01:10:52.560]  Следовательно, лежит в P slash поле по предположению, которое у нас предположительно вложено в P slash поле.
[01:10:52.560 --> 01:11:09.560]  Что это значит? Это означает, что есть некоторое семейство схем, которое мы как-то обозначим Dn.
[01:11:09.560 --> 01:11:37.560]  Есть семейство схем Cn такие, что Cn от phi, x равно 1, если существует y, такое, что phi от x, y.
[01:11:37.560 --> 01:11:45.560]  И 0 иначе.
[01:11:45.560 --> 01:12:05.560]  Их можно переделать в семейство схем Dn такие, что Dn от phi, x.
[01:12:05.560 --> 01:12:11.560]  Dn от phi, x. Это будет решать задачу поиска.
[01:12:11.560 --> 01:12:34.560]  У такой, что phi от x, y равно 1, если такой у существует.
[01:12:34.560 --> 01:12:50.560]  Это стандартный переход от распознавания к задачам поиска.
[01:12:50.560 --> 01:13:10.560]  Упражнения используя идеи, которые у нас были.
[01:13:10.560 --> 01:13:20.560]  Переделаем семейство схем, которые ищут.
[01:13:20.560 --> 01:13:30.560]  Ну и тогда получается следующее.
[01:13:30.560 --> 01:13:44.560]  Фи лежит в P2SAT, тогда и только тогда.
[01:13:44.560 --> 01:14:12.560]  Когда существует Dn такое, что для любого x, phi от x и Dn от phi, x.
[01:14:12.560 --> 01:14:22.560]  Фи от x равно 1.
[01:14:22.560 --> 01:14:28.560]  Почему это верно? В одну сторону слева направить это из предыдущего следует.
[01:14:28.560 --> 01:14:34.560]  Фи от x и Dn от phi, x как раз такой у возвращает, что phi от x, y равно 1.
[01:14:34.560 --> 01:14:42.560]  То есть эта часть будет как раз нужным у.
[01:14:42.560 --> 01:14:48.560]  В другую сторону, даже не важно, Dn будет так или не так.
[01:14:48.560 --> 01:14:58.560]  Для любого x найдется такой у, взявшийся Dn от phi, x, такой, что phi от x, y равно 1.
[01:14:58.560 --> 01:15:08.560]  Вот так вот.
[01:15:08.560 --> 01:15:18.560]  Это уже sigma2 формула.
[01:15:18.560 --> 01:15:28.560]  Вот.
[01:15:28.560 --> 01:15:38.560]  Вот такая вот теорема.
[01:15:38.560 --> 01:15:48.560]  Какие-нибудь вопросы может быть есть?
[01:15:48.560 --> 01:15:54.560]  Ладно, дайте я тогда анонсирую на следующий раз.
[01:15:54.560 --> 01:16:04.560]  Теорема мейера будет такой.
[01:16:04.560 --> 01:16:22.560]  Если exp вложено в p-slash поле, удивительно, что это не умеет опровергать.
[01:16:22.560 --> 01:16:34.560]  Если exp вложено в p-slash поле, то exp будет равняться sigma2 полиномиально.
[01:16:34.560 --> 01:16:44.560]  Во-первых, более сильное условие.
[01:16:44.560 --> 01:16:54.560]  То есть тут из вот этого следует вот это, конечно.
[01:16:54.560 --> 01:17:04.560]  Но и более сильное утверждение.
[01:17:04.560 --> 01:17:14.560]  Опять же, из этого следует вот это, потому что pH будет между exp и sigma2.
[01:17:14.560 --> 01:17:20.560]  Хорошо, тогда на сегодня получается всё.
[01:17:20.560 --> 01:17:26.560]  В следующий раз теорема мейера докажем.
[01:17:26.560 --> 01:17:34.560]  Поговорим про разные другие задачи, вроде быстрого суммирования, потому что там важен не только размер, но и глубина.
[01:17:34.560 --> 01:17:40.560]  Ну и, наверное, как раз этого будет достаточно для следующего раза.
[01:17:40.560 --> 01:17:46.560]  Значит, если закончим раньше, то начнём изучение вариации классов.
[01:17:46.560 --> 01:17:56.560]  Какие-нибудь вопросы?
[01:17:56.560 --> 01:17:58.560]  Ну и сегодня всё. Спасибо за внимание.
