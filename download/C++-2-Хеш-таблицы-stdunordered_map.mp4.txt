[00:00.000 --> 00:09.200]  мы подошли к самому интересному unordered map вам ее реализовывать надо будет
[00:09.200 --> 00:19.520]  первое задание вам нужно будет лист с локатором написать а 2 unordered map
[00:19.520 --> 00:34.600]  но unordered map там будет уже с еще с несколькими дополнительными приколами
[00:34.600 --> 00:37.720]  сейчас мы обсудим такой базовый вариант unordered map
[00:37.720 --> 00:49.200]  некоторые проблемы мы отложим на потом так вот четко unordered map это хэштаблица
[00:49.200 --> 00:54.200]  я не очень понимаю как я буду основному потоку объяснить
[00:54.200 --> 00:57.200]  потому что они не проходили хэштаблицы
[00:57.200 --> 01:14.600]  у них тяжелая судьба их то в первом семестре то в третьем то в втором
[01:15.600 --> 01:22.600]  никак не может коллектив определиться когда правильно рассказать людям хэштаблицы
[01:22.600 --> 01:25.600]  но там же проблема в том что там вероятность вся кофигурирует в доказательствах
[01:25.600 --> 01:33.600]  но нет про хэштаблицы строго со всеми доказательств я вам сейчас не расскажу
[01:33.600 --> 01:39.600]  но я не помню там все эти доказательства сходу мне надо готовиться повторять их
[01:39.600 --> 01:45.600]  но идейно я думаю вы так знаете что такое хэштаблица поэтому о чем рассказать
[01:45.600 --> 01:50.600]  ну кто кто понимает что такое хэштаблица
[01:50.600 --> 01:58.600]  ну кто пользовался в своей жизни хэштаблицей хотя бы раз
[01:58.600 --> 02:10.600]  ну да ну король ну ну типа ну короче ладно ну давайте я идейно расскажу что такое это
[02:10.600 --> 02:14.600]  ну смотрите ну во первых он ордерт слово он ордерт само говорит за себя
[02:14.600 --> 02:21.600]  мы хотим такую структуру которая ну те же задачи будут решать что и дерево поиска по сути
[02:21.600 --> 02:28.600]  только мы потеряем упорядоченность ключей но за счет этого более быстрый поиск будет
[02:28.600 --> 02:38.600]  вот идея в том чтобы в среднем за от единицы делать поиск по ключу причем в среднем тут
[02:38.600 --> 02:46.600]  понимается не амортизировано а по вероятности ну то есть скорее всего и вот тут как раз основная
[02:46.600 --> 02:50.600]  основная сложность вот все этой возни заключается в том чтобы формализовать что
[02:50.600 --> 02:59.600]  значит вот это скорее всего ну да но мат ожидания по чему типа по какому
[02:59.600 --> 03:05.600]  параметру у тебя там должно быть какое-то вероятностное пространство из него нужно
[03:05.600 --> 03:10.600]  там выбирать там какие-то случайные элементы мат ожидания случайной величины а случайная
[03:10.600 --> 03:14.600]  величина должна действовать на каких-то исходах а что такое исходы ну и вот в общем
[03:14.600 --> 03:21.600]  весь этот геморрой но этот тярвер начинается и поэтому не будем углубляться но так типа понятно
[03:21.600 --> 03:26.600]  что в среднем хотим чтобы все было хорошо в среднем в том смысле что вероятность того что все
[03:26.600 --> 03:43.840]  плохо низкая вот ну что мы делаем мы заводим такой да что я не очень
[03:43.840 --> 04:04.240]  но иногда сделает что вероятностная структура тоже может иногда ли линию сделать что мэпта
[04:04.240 --> 04:19.240]  почему если у тебя загрузка комнате может собраться в одной точке от ожидания максимальной длины
[04:19.240 --> 04:38.240]  ну есть такой параметр который называется load factor его можно поставить ну если у тебя
[04:38.240 --> 04:44.240]  элементов лежит уже больше чем там некоторая константа умножить на размер таблицы то кажется
[04:44.240 --> 04:52.240]  что все плохо ну и поэтому ты можешь ты можешь этот load factor поставить таким что все будет
[04:52.240 --> 05:00.240]  испорчено скорее по умолчанию он просто стоит таким ну да можно и уб вызвать в принципе так я
[05:00.240 --> 05:07.240]  объясняю что хэштаб лица вкратце ну чего вот у вас есть такой массив и вам надо не знаю ключи в
[05:07.240 --> 05:16.240]  нем хранить вы берете такие и говорите окей ну давайте не знаю вот допустим у вас ключи это строки
[05:16.240 --> 05:31.120]  вы для каждой строки вычислять кончить функцию которая называется хэш да которая обладает таким
[05:31.120 --> 05:41.120]  свойством что она ну скажем так очень непредсказуемо по строке и небольшое изменение
[05:41.120 --> 05:49.040]  строки сильно меняет функцию и меняет совершенно непредсказуемо но поэтому называется хэш хэш
[05:49.040 --> 05:55.720]  вообще значит типа рубить мелко перемешивать вот так вот ну там типичная ситуация это вы берете
[05:55.720 --> 06:01.640]  там какие-нибудь символы ну символы строки интерпретируете как числа представляете число
[06:01.640 --> 06:10.440]  там в виде что это как будто число в какой-то системе счисления и после каждого операции
[06:10.440 --> 06:14.400]  берете по модулю какого-нибудь еще простого числа скажем то есть вы берете там какой-нибудь
[06:14.400 --> 06:20.840]  простое основание системы счисления и еще берете какой-нибудь большой простой модуль и по модуле
[06:20.840 --> 06:29.000]  этого простого вычисляете свое свое значение ну вот кажется что там при нужном подборе всяких
[06:29.000 --> 06:34.920]  там параметров вот этих чисел то у вас будет функция обладать ну плюс-минус такими свойствами
[06:34.920 --> 06:40.160]  как надо ну там дальше длинный разговор о том какие конкретно хэш функции лучше какие хуже там
[06:40.160 --> 06:45.440]  есть криптографически надежные хэш функции есть не очень криптографически надежные ну
[06:45.440 --> 06:51.920]  криптографически надежные в том смысле что за за разумное время по значению этой функции нельзя
[06:51.920 --> 06:59.720]  подобрать то от чего она посчитан была вот так называемые односторонние функции когда вы можете
[06:59.720 --> 07:06.680]  быстро посчитать значение функции на входе но если вам дано значение функции то найти вход на
[07:07.160 --> 07:15.640]  хоть какой-нибудь вход на котором было бы такое это там трудная задача
[07:15.640 --> 07:34.280]  здесь мы хотим упихать да и угловое значение вообще размеры массива а изначально хотя бы
[07:34.280 --> 07:40.320]  ты имеешь в виду что криптографически надежный в нашей задачи не нужны да и понятно я говорю
[07:40.320 --> 07:45.480]  просто про то что хэш функции там бывают с разными свойствами и для разных задач бывают нужны
[07:45.480 --> 07:53.600]  разные вот но у нас кстати биткоин примерно там похожая задача там вам нужно подбирать такой
[07:53.600 --> 07:58.760]  вход чтобы на нем значение хэш функции было там оканчивалась на сколько-то нулей вот и это
[07:58.760 --> 08:05.120]  сложная задача именно этим занимаются майнеры они собственно подбирают такие ключи чтобы на них
[08:05.120 --> 08:13.080]  хэш был каким-то каким надо кого надо вида но неважно мы этим всем не будем заниматься майн не
[08:13.080 --> 08:24.600]  будем чего ну на третьем может чуть-чуть помайните но не сейчас ну это же не значит
[08:24.600 --> 08:33.060]  что вы майнить будете может вам ну неважно в общем это сейчас мы не будем обсуждать хэш
[08:33.060 --> 08:46.980]  таблица ну и что это нам позволяет добиться мы в хэш таблице мы можем есть два подхода
[08:46.980 --> 08:51.620]  первый подход называется хэширование с открытой адресации второй подход называется хэширование
[08:51.620 --> 08:57.220]  методом цепочек что такое хэширование с открытой адресации это когда у вас в массиве собственно и
[08:57.220 --> 09:04.500]  лежат вот эти строки сами ну то есть вот вы хэшируете какие-то объекты и массив собственно
[09:04.500 --> 09:14.140]  из них но он изначально пустой да ну не совсем хэш взятый там либо хэш либо еще какая-то
[09:14.140 --> 09:24.780]  функция от хэша хорошо поправь мы взяли строку мы посчитали мы взяли строку мы посчитали к
[09:24.780 --> 09:33.420]  нее хэш стд хэш это всегда число single log ну неважно нам в любом случае нужно число в диапазоне от нуля
[09:33.420 --> 09:39.980]  до n поэтому дальше мы просто берем по модулю n обычно вроде это да это как раз мы получили
[09:39.980 --> 09:47.100]  какую-то позицию вопрос что делать мы не можем в эту позицию положить нашу строку или значение
[09:47.100 --> 09:53.700]  связано нет нет ты сейчас начнешь рассказывать про разрешение коллизий это следующий вопрос
[09:53.700 --> 10:01.700]  я как раз говорю что изначально и индексами и ну это будет изначально позиции вопрос был
[10:01.700 --> 10:06.700]  насколько я понимаю про то чем индексируется массив но он индексируется значит как вот как ты
[10:06.700 --> 10:13.180]  по строке понимаешь где она должна лежать посчитать хэш возможно взяли его по модулю чего-то
[10:13.180 --> 10:19.600]  возможно еще какую-то операцию над ним произвели ну чтобы уложиться в этот массив и чтобы
[10:19.600 --> 10:24.140]  возможно еще как-то дополнительное распределение на возможных выходных значениях задать и пошли
[10:24.140 --> 10:31.020]  в эту ячейку вот смотрим лежит там что-то или не лежит нос не лежит значит такого ключа нету
[10:31.020 --> 10:41.740]  сейчас мы про это поговорим пока мы и фиксировали размер но очевидная проблема
[10:41.740 --> 10:48.100]  которая возникает вдруг случилась коллизия то есть у двух разных строк совпали хэши такое
[10:48.100 --> 10:53.940]  конечно же может быть потому что если такое было невозможно это бы означало что возможных
[10:53.940 --> 10:58.180]  значений хеша столько же сколько возможных значений наших объектов но тогда какой смысл
[10:58.260 --> 11:04.900]  хеш таблицы массив должен быть размера как всего может быть разных значений так это вообще тогда
[11:04.900 --> 11:11.540]  можно было бы не вычислять никакой хэш поэтому коллизии всегда неизбежно они происходят и
[11:11.540 --> 11:20.020]  вот вопрос о том как быть в этой ситуации это собственно основной предмет изучения в этой в
[11:20.020 --> 11:26.940]  этой области ну если там целые главная главная наука про хэш таблицы заключается как раз в том
[11:26.940 --> 11:37.140]  как быть если совпали элементы совпали хэши у разных элементов но есть разные подходы и тут
[11:37.140 --> 11:43.340]  можно просто не то что нужно курс лекции прочитать про то какие есть подходы разрешения коллизии но
[11:43.340 --> 11:50.140]  самый тупейший метод это просто в следующую ячейку тыкаться чего
[11:50.140 --> 12:18.940]  сейчас еще раз я не понял подожди в чем твоя идея типа ты считаешь что их просто нет
[12:18.940 --> 12:35.780]  а ты говоришь про поиск по строке в строке что ли не по 10 9 и не по 10 18 вероятно
[12:35.780 --> 12:41.620]  были коллизии почему потому что если ты положишь если возьмешь 10 пятый строк сравнишь хэши по
[12:41.620 --> 12:49.540]  парно у тебя будет порядка n квадрат сравнений и у каждого варианта и у каждого шанс сломаться
[12:49.540 --> 12:55.900]  то есть шанс коллизии один день на м есть модуль чуть-чуть больше чем количество строк сейчас
[12:55.900 --> 13:02.060]  причем тут вообще количество сравнений дело же не в том просто дело в том что размер массива
[13:02.060 --> 13:18.620]  меньше чем размер возможных чем чем количество значений в диапазоне не надо говорить про
[13:18.620 --> 13:23.540]  лимпиадку потому что наша задача не решить не решить олимпиадную задачу а построить структуру
[13:23.540 --> 13:28.380]  данных которая гарантированно делает поиск по ключу у нас как бы мы решаем не эту задачу не
[13:28.380 --> 13:33.860]  решаем задачу поиска но мы надеемся что все будет хорошо нет нам нужна структура которая точно
[13:33.860 --> 13:39.660]  отвечает есть ключ или нет она просто может иногда это долго делать если не повезло но ответина
[13:39.660 --> 13:56.060]  всегда правильно должна иначе если бы структура там иногда отвечала неправильно то в общем
[13:56.060 --> 14:00.380]  наша цель построить структуру которая всегда отвечает правильно но возможно иногда делать
[14:00.380 --> 14:05.180]  это долго так вот ну вот самый тупой метод как быть сколизм вот пришли сюда вот вам говорят положи
[14:05.180 --> 14:11.140]  в хэш таблицу значение а вы вычитайте хэш и видите что туда куда надо положить она уже есть там
[14:11.140 --> 14:18.180]  ну вы говорите окей пойду в следующую ячейку тогда и туда положу но и так буду идти пока не
[14:18.180 --> 14:25.780]  найду пустую ну и скорее всего там по пляшам с вероятностями ну наверное это не очень долго
[14:25.780 --> 14:31.660]  в среднем будет происходить что да возникает возникает следующий вопрос а как удалять тогда
[14:31.660 --> 14:41.660]  к чему не ну как ты как по ключу ты вычитаешь точно также вычитаешь хэш идешь в ячейку
[14:42.260 --> 14:53.660]  нет идем дальше там оно нет пока не найдем пустую либо пока не найдем его вот когда удаляем вот
[14:53.660 --> 15:01.220]  в таком подходе удалять проблема потому что мы не можем просто ее сделать пустой ведь вдруг
[15:01.220 --> 15:06.860]  после нее что-то лежало что мы добавили в виду коллизии а тогда когда мы будем снова искать то
[15:06.860 --> 15:20.420]  мы его потеряем что будет пустая и мы не дойдем до нужного поэтому обращение по индексу по ключу
[15:20.420 --> 15:26.060]  работает так вычисляем хэш от ключа идем в ячейку соответствующую этому хэшу смотрим что там
[15:26.060 --> 15:37.580]  лежит за значение если это то самое значение что мы ищем мы храним и ключи значит конечно мы
[15:37.580 --> 15:42.420]  значение храним ну и ключи значение мы храним в ячейках но я сейчас говорю про хэш сет скорее
[15:42.420 --> 15:48.580]  они про хэш мэп но если это хэш мэп то мы конечно храним ключ значение пару но значением я
[15:48.580 --> 15:53.620]  называю ключ на самом деле когда про это говорю то что вл ю это не важно вл ю мы никогда не
[15:53.620 --> 16:05.900]  сравниваем мы ключи сравниваем ключ это и есть строка мы сравниваем тот ли ключ лежит там который
[16:05.900 --> 16:11.460]  мы ищем вот ну и идем пока не найдем либо его либо пустую как тогда удалять это проблема
[16:11.460 --> 16:16.980]  потому что если мы удалим сделаем пустой мы потом можем не найти что-то что после нее лежало поэтому
[16:16.980 --> 16:24.220]  вот с таким подходом удаление это трудность нужно ну можно помечать вершину там как фиктивную
[16:24.220 --> 16:31.380]  например и типа помечать специальный флаг ставить тут что-то лежало но было удалено вот ну и вот
[16:31.380 --> 16:37.460]  дальше свистопляска очередная очередной танец бум нам мы говорим что ну это там среднем наверное
[16:37.460 --> 16:45.820]  если там правильно выбрать хэш функцию и правильно там размер таблицы то нормально все будет вот если
[16:45.820 --> 16:51.860]  у нас оказалось что слишком сильно таблица заполнена ее возможно нужно пери перезаполнить
[16:51.860 --> 17:06.020]  полностью если если мы с таким подходом в таблицу положим элементов столько сколько всего размер
[17:06.020 --> 17:11.980]  таблицы у нас получится что последние уже операции за линию работают вот поэтому размер
[17:11.980 --> 17:17.500]  таблицы во-первых должен быть больше во сколько-то раз чем количество элементов во-вторых этот слишком
[17:17.500 --> 17:26.580]  тупой подход и обычно делают что-то другое например ну там можно например делать так вот есть такой
[17:26.580 --> 17:34.820]  хэш сейчас бы не соврать хэш кукушки по моему называется а ну во-первых можно делать не линейное
[17:34.820 --> 17:41.220]  пробирование квадратичное пробивание ну например не в следующую идти а по какому-то другому алгоритму
[17:41.220 --> 17:54.180]  вычислять следующую для данной ну то есть функция перехода не случайную а в какую-то вычисленную
[17:54.180 --> 18:03.420]  еще другим по другому ну потому что кажется потому что так у тебя следующее будет зависеть от того
[18:03.420 --> 18:11.620]  следующее может зависеть как от твоего хэш значения так и вот того какая сейчас то есть
[18:11.620 --> 18:21.460]  функция перехода к следующей зависит от того какой у тебя хэш тоже ну хорошо она может зависеть там
[18:21.460 --> 18:27.220]  это номер ячейки она может зависеть от значения оригинального хэша ну или еще чего-то ну короче
[18:27.220 --> 18:33.300]  ты можешь как угодно построить функцию перехода так что у тебя не будут образовываться длинных
[18:33.300 --> 18:41.540]  таких последствий у тебя будет просто ну да просто у тебя не будет у тебя будет меньше шанс
[18:41.540 --> 18:47.420]  что тебе придется пройти там очень длинный путь потому что следующий для этой он будет другим в
[18:47.420 --> 19:03.780]  зависимости от того что ты ищешь ну да ну можно там подобрать там повозиться и там вот ну хэш
[19:03.780 --> 19:11.380]  хэш можно например такой подход выбрать давайте так называемый хэш кукушки это что такое это я
[19:11.380 --> 19:20.620]  просто беру и для каждого ключа вычисляю на самом деле два разных значения ну то есть у меня ключ
[19:20.620 --> 19:28.100]  он да вот у меня две разных функции есть одна меня приводит сюда другая сюда и я когда делаю
[19:28.100 --> 19:33.380]  insert я смотрю ну хоть одна из них свободно если хоть одна из них свободно то классно туда вставлю
[19:33.380 --> 19:41.140]  а если вот ни одна из них не свободна тогда я а я тогда посмотрю вот на эту например и посмотрю
[19:41.140 --> 19:47.260]  а свободно ли вторая для нее которая была и попробую эту перепихнуть туда на вторую доступно для
[19:47.260 --> 19:54.980]  нее позицию а свою положить сюда ну и вот так действовать в общем очень много это можно игру
[19:54.980 --> 19:59.900]  это можно целых лекций 5 прочитать про разные варианты как можно решать эту задачу там очень
[19:59.900 --> 20:05.740]  сложная математика и это прям вот тут оптимизируешь недооптимизируешься но это был подход про открытую
[20:05.740 --> 20:10.300]  адресацию так называемого еще подход методом цепочек что такой подход методом цепочек это
[20:10.300 --> 20:19.500]  вы в каждой вершине храните не сам объект ваш а ну скажем массив или список и просто у вас
[20:19.500 --> 20:24.620]  получаются такие бакеты в каждой ячейке у вас висит список того кто попал сюда потому что у
[20:24.620 --> 20:29.420]  них хэш одинаковый и тут легче становится с удалением потому что у вас нет вот этой проблемы
[20:29.420 --> 20:35.860]  что вы удаляя свой испортите чего-то там с чужим хэшом вот вы просто идете в соответствующую ячейку
[20:35.860 --> 20:41.620]  смотрите как какой там сейчас список если там нет ничего то понятно ничего и нет а если там
[20:41.620 --> 20:48.300]  что-то есть но вы проходите по этому списку к тех кто попал туда и среди него ищете ну или удалять
[20:48.300 --> 20:57.380]  понятно как теперь вот но вот unordered map это как раз вот такая хэштаблица которая со вторым
[20:57.380 --> 21:09.420]  подходом а именно эта хэштаблица методом цепочек смысл в том что вы ну скажем так надеетесь что
[21:09.420 --> 21:18.660]  коллизии будет не слишком много поэтому там средний размер цепочки будет очень маленьким там и
[21:18.660 --> 21:29.180]  близко к константе и поэтому у вас добавление удаления будет средним работать за от единицы
[21:29.180 --> 21:38.220]  а не как в красно-черном дереве за логарифом но понятно что вы при этом теряете вы теряете
[21:38.220 --> 21:44.260]  упорядоченность ключей то есть вы не можете спросить там lower bound upper bound equal range
[21:44.260 --> 21:53.220]  никакой вот вы ключи в рандомном ну потому что все перемешано просто суть хэша в этом что все
[21:53.220 --> 22:08.340]  перемешано непонятной порядке лежит
[22:08.340 --> 22:29.620]  да ну понятно что в среднем одна сколько n поделить на n
[22:29.620 --> 22:46.300]  нет нет если ты считаешь мат ожидания то это сумма индикаторов того что в данной ячейке
[22:46.300 --> 22:51.180]  лежит элемент индикатор это вероятность просто что в данной ячейке лежит элемент а это будет
[22:51.180 --> 23:02.780]  ну не важно это уход в сторону я не хочу в это уходить я хочу просто поговорить уже про то
[23:02.780 --> 23:11.020]  как собственно вот реализовывать это хэш к счастью реализовывать нам не надо он реализован есть
[23:11.020 --> 23:20.780]  функция стд хэш которая для всех стандартных типов но это не функция это класс это функциональный
[23:20.780 --> 23:27.700]  объект шаблонный класс который для всех стандартных типов имеет для всех имею
[23:27.700 --> 23:33.140]  ввиду как примитивных типов так и библиотечных стлевских типов он имеет оператор круглые
[23:33.140 --> 23:43.220]  скобочки который по объекту данного типа возвращает там он глонг скажем ну вот все эти
[23:43.220 --> 23:52.380]  стд стринг стд вектор стд что угодно для них для всех это сет конечно ну для всех объектов ну
[23:52.380 --> 23:57.540]  возможно там за исключением каких-то я не помню но для всех скорее всего типа в которой ты можешь
[23:57.540 --> 24:09.180]  придумать который тебе может захотеть сохранить стд хэш определен я ничего не могу сказать про
[24:09.180 --> 24:14.820]  надежность этого хэша хоть какой-нибудь точки зрения не изучал вопрос но можно считать что
[24:14.820 --> 24:32.500]  для наших целей он годится вот мы ну да наша задача мэп написать сейчас ну в смысле понять
[24:32.500 --> 24:39.060]  как он устроен unordered map хэш будем считать что реализован для всех типов за нас и
[24:39.060 --> 24:46.460]  как-то работает вот если мы хотим работать с каким-то хэшом который с каким-то типом
[24:46.460 --> 24:54.020]  который не стандартной библиотеки нужно стд хэш доопределять самому для него то есть
[24:54.020 --> 25:02.740]  прям нужно взять и ну допустим я хочу в хэш таблицу покласть положить там в качестве
[25:02.740 --> 25:11.660]  ключа что-нибудь мое собственно big integer например вот ваш вы писали вот почему что плохой big
[25:11.660 --> 25:21.060]  integer что ли получился не ну если про твой говорить то я тоже не стал не ну я честно говоря да когда
[25:21.060 --> 25:28.300]  последний раз читал такой то там а ты меня потом право написал объяснение но я я что-то не я его
[25:28.300 --> 25:36.300]  по моему не прочитал короче unordered map какие у нее шаблонные параметры очевидно ключ значение
[25:36.300 --> 25:48.940]  дальше третий шаблонный параметр это собственно хэш который по умолчанию равен стд хэш от ключа
[25:48.940 --> 26:09.420]  вот дальше да четвертый шаблонный параметр сейчас я скажу какой но пока про то сразу как свой
[26:09.420 --> 26:13.580]  хэш доопределить то есть если вы хотите в мэп положить что-то свое например тот же big integer
[26:13.580 --> 26:19.420]  стд хэш него неопределен вы получите ce со словами я не понимаю что такое хэш big integer нет такой
[26:19.420 --> 26:29.380]  функции вот ну нету оператора квадратной скоб ну да нету структуры просто такой вот ну то есть
[26:29.380 --> 26:33.340]  она есть но там стоит заглушка типа ну как фактически это же специализации для всех
[26:33.340 --> 26:39.900]  типов просто вы стояли написано вам нужно тогда определить свой хэш как вы это делаете вы в
[26:39.900 --> 26:46.820]  своем коде пишете namespace стд фигурная скобочка открывается и пишете template пустые угловые
[26:46.820 --> 26:54.460]  скобочки struct хэш вот того чего вам надо понятно то есть вы можете иногда дописывать
[26:54.460 --> 27:00.020]  сущности вы на им space стд вот это один из примеров когда такое может быть нужно то есть вам нужно
[27:00.020 --> 27:10.540]  это значит официально по стандарту дописывание чего-то namespace стд это убе кроме ограниченного
[27:10.540 --> 27:20.900]  списка случаев которые перечислены это вот один из них то есть то есть вот можно в namespace
[27:20.900 --> 27:25.900]  стд добавить специализацию сюда хэш до конца его типа и это не убе это прямо вот официально
[27:25.900 --> 27:32.300]  написано что так можно делать и всячески поощряется такое поведение вот дальше
[27:32.300 --> 27:43.340]  хорошо ну чего у нас давайте подумаем как вообще это все устроено значит у нас должен быть внутри
[27:43.340 --> 27:53.500]  какой-то массив и в этом массиве что у нас должно быть но у нас должны быть связанные списки то есть
[27:53.500 --> 28:01.820]  фактически unordered map хранит такой массив ну можете считать вектор связанных списков вот
[28:01.820 --> 28:13.780]  нет просто вы связанный список свой напишите потом его заиспользуйте здесь нет вектор ну тут
[28:13.780 --> 28:19.180]  от вектора почти ничего не надо тут тут реаллокация не нужна ну то есть не нужна но
[28:19.180 --> 28:26.820]  она вручную ее можно сделать вектором наверное даже можно будет пользоваться он тут не особо
[28:26.820 --> 28:34.300]  поможет вот хорошо из чего состоит эта штука изначально из этот вектор изначально ну то есть
[28:34.300 --> 28:51.340]  фактически у вас есть давайте скажем вектор от листа от чего ну не пар а ноут ну хорошо да нет
[28:51.340 --> 28:58.700]  ладно лист наверное от пар лист пар но правильнее наверное сказать что у меня ну да хорошо давай
[28:58.700 --> 29:08.020]  скажу что у меня лист из пар лист из value type опять это будет value type это опять пара
[29:08.020 --> 29:19.220]  value type это пара как и в случае с обычным мэпом это пара из const.key.value ключ опять
[29:19.220 --> 29:26.860]  константный по той же причине что и в обычном мэпе потому что нельзя взять и поменять его в
[29:26.860 --> 29:33.260]  вручную если вы с какой-то вершины имеете дело если бы вы умели менять ключи произвольно то
[29:33.260 --> 29:41.660]  у вас бы ну понятно что вы у вас сделали ключ не такой какой должен быть при данном данной
[29:41.660 --> 29:49.100]  ячейке хэш у него не совпадает вы все испортили такого быть не должно вот поэтому в value type как
[29:49.100 --> 29:57.620]  и раньше это вот такая штука и у меня есть ну вектор листов в value type там не знаю назову
[29:57.620 --> 30:12.060]  его array ну блин array плохо а вот теперь что еще мне надо изначально там везде пустые листы так ну
[30:12.060 --> 30:17.260]  спойлер это плохо сейчас ничего не получится сейчас мы поймем что так не работает надо переделать
[30:17.260 --> 30:23.220]  изначально там пустые листы теперь давайте подумаем как работает ну что ну давайте подумать как
[30:23.220 --> 30:29.020]  работает ну как работают квадратные скобочки опять же начнем по порядку значит оператор
[30:29.020 --> 30:36.980]  квадратной скобочки как и в обычном мэпе вычисляем хэш от ключа который нам дали идем в соответствующую
[30:36.980 --> 30:47.980]  ячейку смотрим ну если там ну фактически да опять же если там не пустой лист если мы в этом
[30:47.980 --> 30:55.100]  листе не нашли то значит мы должны создать вершину новую для этого листа и туда ссылку вернуть на вот
[30:55.100 --> 31:04.820]  то value которая получилось если мы не нашли в списке вершину с таким ключом то мы ее создаем и
[31:04.820 --> 31:10.420]  возвращаем ссылку на вэлью этой вершины как работает это точно так же только мы кидаем
[31:10.420 --> 31:21.660]  исключения в случае если не нашли ну не совсем потому что нам надо вернуть ссылку на вэлью они
[31:21.660 --> 31:29.060]  на ноду листа ну можно наверное вызвать это листа но просто из того что нам вернет надо
[31:29.060 --> 31:37.820]  вернуть не это а ссылку на вторую второй элемент пары как работает инсерт в принципе тоже понятно
[31:37.820 --> 31:46.140]  как работает также да как работает и рейс тоже понятно а вот кстати уже как работает и рейс не
[31:46.140 --> 31:50.740]  очень понятно тут мы приходим к разговору про итераторы у нас должны быть итераторы помимо
[31:50.740 --> 32:16.980]  все прочее так нет итераторы остаются сейчас и итераторы да итераторы остаются не валить
[32:16.980 --> 32:21.820]  становится неволидными я имею ввиду после вставки после удаления после удаления блин
[32:21.820 --> 32:27.020]  понятно что итератор на твой элемент неволидным становится который удалял это всегда так остальные
[32:27.020 --> 32:46.260]  итераторы портится или нет на на этот который ты удалил ну да я я и сказал что так по моему или
[32:46.260 --> 32:55.340]  остальные итераторы остаются валидными а итератор на удаленный элемент никогда не обсуждается
[32:55.340 --> 32:59.580]  очевидно с неволидным про него мы не говорим вопрос остаются ли итератор валидными на
[32:59.580 --> 33:08.380]  остальные элементы вот тут есть некоторые трудности связанные с реэшированием но пока
[33:08.380 --> 33:12.900]  их оставим в стороне вот давайте считать что размер таблицы фиксируема таблицы не перене
[33:12.900 --> 33:23.220]  реалацируется пока вот если в этом предположении работать то что происходит ну вот это хороший
[33:23.220 --> 33:29.300]  вопрос ну то есть казалось бы мы просто и итератор по сути это итератор на лист на лист и казалось бы
[33:29.300 --> 33:38.260]  ну чё и рейс там или insert все нормально но вопрос в том как сами итераторы-то устроены что
[33:38.260 --> 33:45.900]  такое итератор в unordered map, а кто помнит какой итератор в unordered map, какой у него вид
[33:45.900 --> 33:58.100]  нет мы обсуждали когда таблицу рисовали форвард итератор на самом деле тут не лист а
[33:58.100 --> 34:03.180]  форвард лист блин я забыл вам сказать что кофе а нет я говорил о форвард лист ну то есть
[34:03.180 --> 34:10.820]  односвязанный список да потому что нет никакого смысла делать двусвязанный список потому что
[34:10.820 --> 34:17.980]  все равно порядка никакого не гарантируется все равно они в рандомном порядке лежат идти хоть
[34:17.980 --> 34:23.900]  вперед хоть назад одинаковый рандомный порядок и гарантии поэтому ну просто форвард лист у нас
[34:23.900 --> 34:31.580]  здесь будет форвард лист но это не снимает вопроса как же итератор устроен вот че хранит итератор
[34:31.580 --> 34:48.340]  как инкрементировать итератор если ты стоишь в конце листа
[34:48.340 --> 35:06.580]  у тебя еще и не валидные элементы листа бывают а окей так следующую ячейку таблицы а если она
[35:06.580 --> 35:18.420]  пустая а если она а если тебе так придется от n пустых ячеек нет а потому что ты не хочешь
[35:18.420 --> 35:29.860]  чтобы инкремент работал за линейное время да только ты хочешь чтобы инкремент работал за
[35:29.860 --> 35:51.180]  вот ты хочешь чтобы представь представь что ты завел хеш таблицу там на миллион
[35:51.180 --> 35:58.060]  элементов и положил у нее всего два элемента у тебя получилось что эти элементы оказались
[35:58.060 --> 36:03.140]  вот здесь тогда тебе чтобы обойти таблицу который всего два элемента лежит потребуется
[36:03.140 --> 36:09.100]  миллион операций потому что размер таблицы ты большой сделал заранее надо чтобы обход
[36:09.100 --> 36:14.780]  итератором работал за о от количества лежащих в ней элементов они от размера таблицы вот в чем
[36:14.780 --> 36:28.940]  как поддерживать ну давай просто вместо того чтобы лист хранить но точнее в каждой
[36:28.940 --> 36:33.260]  вершине действительно хранится лист на лист указателей то есть есть лист всех
[36:33.260 --> 36:42.060]  элементов и а в вершине хранится лист указателей на элементы чего на последующие элементы нет
[36:42.060 --> 36:49.100]  нет нет вот у нас в каждой вершине вот есть лист так да и это есть указателей на вот носить
[36:49.100 --> 36:57.820]  какой-то просто список всех элементов которые у нас есть общий зачем нам вообще зачем вообще
[36:57.820 --> 37:03.460]  сделать проход по мапе если можно отдельно сохранить раз уж никто не просит какой-то порядок можно
[37:03.460 --> 37:08.020]  типа отдельно сохранить лист всех элементов и просто по нему ходить на нас проще правильно так
[37:09.020 --> 37:15.220]  так надо то есть на самом деле вектор листов мы не будем хранить мы будем хранить один общий
[37:15.220 --> 37:22.820]  лист а также один вектор которым jestemenga грн珠 и не листов указателей нам достаточно хранить
[37:22.820 --> 37:28.220]  вектор одиночных указателей нам нужно хранить лист а еще вектор каждый элемент которого это
[37:28.220 --> 37:37.740]  указатель на некоторые элементы того листа так так в смысле мы мы когда мы хотим
[37:37.740 --> 37:44.420]  поиск, зачем нам вектор листов хранить, мы храним вектор указателей, одиночных
[37:44.420 --> 37:47.860]  указателей, а когда нам нужно сделать поиск, мы прыгаем по этому указателю, а
[37:47.860 --> 38:00.860]  дальше-то идем по листу просто. Мы смотрим хэш все еще такой же или нет. Его
[38:00.860 --> 38:05.160]  можно закэшировать и хранить в вершинах листа, помимо всего прочего еще и хэш
[38:05.200 --> 38:14.280]  текущей вершины. Просто хранить вектор указателей, лист указателей, это достаточно
[38:14.280 --> 38:18.600]  расточительно, потому что у тебя тут, у тебя постоянно будут эти прыжки по
[38:18.600 --> 38:26.240]  указателям многократные, а это не очень хорошо. Лучше ты будешь один. Да, но только тебе
[38:26.240 --> 38:29.560]  нужно двойной прыжок по указателю делать. Чтобы понять какой у тебя следующий
[38:29.560 --> 38:32.840]  элемент, ты не просто идешь в следующий элемент листа, ты идешь в следующий элемент
[38:32.840 --> 38:37.840]  этого листа, а потом в тот элемент, который в нем написано еще. Зачем? Ну, типа, просто
[38:37.840 --> 38:38.840]  можно идти по листу.
[38:38.840 --> 38:41.840]  Можно еще раз концепцию сделать в общении?
[38:41.840 --> 38:48.840]  Итак, у вас есть лист, форвард-лист на самом деле.
[38:48.840 --> 38:54.840]  Можно эту концепцию изобрести из того, что у нас было. У нас куча листов была в вершинах.
[38:54.840 --> 38:59.840]  Давайте соединим все эти листы в один большой.
[38:59.840 --> 39:05.840]  Я уже не понимаю, что у вас лист, а что у вас вершина. Можно как-то конкретики
[39:05.840 --> 39:09.840]  какой-то добавить. Что ты хочешь, в смысле? Что такое лист? Лист, который лист?
[39:09.840 --> 39:13.840]  Лист, который лист. СТД-лист. Хорошо.
[39:13.840 --> 39:34.840]  Так, смотрите, у меня будет форвард-лист из таких штук, которые называются, но это
[39:34.840 --> 39:41.840]  будет не совсем value-type, потому что пара и еще кэшированный хэш. Значит, у меня
[39:41.840 --> 39:47.840]  будет форвард-лист из... Ну нет, я не хочу пару из пары.
[39:47.840 --> 39:55.840]  Ну давайте я назову лист-ноуд ее. Ну просто ноуд давайте я назову.
[39:55.840 --> 39:59.840]  Нет, давайте сделаем юзер, напишем какой-нибудь...
[39:59.840 --> 40:05.840]  Нет, давайте я назову лист-ноуд, потому что ноуд может как бы...
[40:05.840 --> 40:16.840]  Значит, value-type, value-type-qv и еще... Какой там вы говорите тип правильный?
[40:16.840 --> 40:20.840]  Int64t? Что?
[40:20.840 --> 40:31.840]  Size-t. Хорошо. Size-t. Size-t. Ну давайте я назову хэш.
[40:31.840 --> 40:33.840]  Хэш это... Господи.
[40:38.840 --> 40:45.840]  Давайте я назову его caged. Или просто caged. Вот смотрите, есть кэш, а есть хэш.
[40:45.840 --> 40:47.840]  Не путайте.
[40:51.840 --> 40:57.840]  Так, вот такая структура. Вот из них состоит лист.
[41:01.840 --> 41:07.840]  Это, значит, elements. Собственно, элементы, которые в хэш-таблице лежат.
[41:07.840 --> 41:23.840]  А еще есть вектор из вот forward-list от лист-ноуд, двоеточие-двоеточие-итератор.
[41:23.840 --> 41:29.840]  Они переиспользуют прям forward-list?
[41:29.840 --> 41:32.840]  Не знаю.
[41:32.840 --> 41:34.840]  А чем еще?
[41:34.840 --> 41:39.840]  Скорее всего они не используют прям std-forward-list.
[41:39.840 --> 41:43.840]  Потому что forward-list это же на самом деле...
[41:43.840 --> 41:44.840]  Оболочка?
[41:44.840 --> 41:53.840]  Ну конечно. Там и хэш-таблица-то нормальная тоже не unordered-map.
[41:53.840 --> 42:00.840]  У них же написано во внутреннем nmsp-се куча всяких структур данных, которые они там в нужные моменты говорят,
[42:00.840 --> 42:04.840]  Давайте вот это мы назовем forward-list, а это мы назовем unordered-map.
[42:04.840 --> 42:08.840]  Но они в unordered-map используют какие-то внутренние структуры, не внешние forward-list.
[42:08.840 --> 42:14.840]  У них какой-то свой собственный оптимизированный forward-list, вероятно, написан.
[42:14.840 --> 42:17.840]  Так вот. Короче, вот такая штука.
[42:17.840 --> 42:25.840]  То есть у меня есть forward-list из элементов и вектор из итераторов на этот лист, который хранит как раз...
[42:25.840 --> 42:28.840]  Ну, понятно что.
[42:28.840 --> 42:29.840]  Вот как...
[42:29.840 --> 42:30.840]  Понятно?
[42:33.840 --> 42:34.840]  Сейчас поймешь, что нет.
[42:34.840 --> 42:38.840]  Как происходит поиск?
[42:38.840 --> 42:44.840]  Ну, у меня вот есть этот массив.
[42:44.840 --> 42:47.840]  Тут везде установлены нул-пойнтеры.
[42:47.840 --> 42:51.840]  Вот тут, допустим, у меня...
[42:51.840 --> 42:53.840]  Вот так выглядит лист.
[42:53.840 --> 42:57.840]  Да, вообще говоря, конечно, не обязательно в таком порядке.
[42:58.840 --> 43:02.840]  Оно может вести там, куда-то, не знаю, вот сюда, например.
[43:02.840 --> 43:05.840]  Вот тут начинаются элементы с таким ключом.
[43:05.840 --> 43:11.840]  Тут опять ничего, эта штука меня ведет сюда, то опять ничего, эта штука меня ведет сюда,
[43:11.840 --> 43:13.840]  и тут опять ничего.
[43:13.840 --> 43:14.840]  Вот так вот это выглядит.
[43:14.840 --> 43:15.840]  То есть у меня ситуация такая.
[43:15.840 --> 43:18.840]  У меня два элемента с таким хешом...
[43:18.840 --> 43:25.840]  Один элемент с таким хешом, один элемент с таким хешом, один элемент с таким хешом.
[43:25.840 --> 43:39.080]  а да конечно да да да да теперь как мы делаем что как мы делаем ну как мы
[43:39.080 --> 43:45.720]  делаем find понятно в принципе понятно как мы делаем и find и insert и race да все в
[43:45.720 --> 43:50.840]  принципе понятно по этому листу с первого указателя пока не дойдем до
[43:50.840 --> 43:56.760]  другого хеша да значит мы как мы делаем find ну мы идем в эту ячейку прыгаем в
[43:56.760 --> 44:02.920]  этот лист и идем по этому листу пока не увидим что хеш стал другим ну значит
[44:02.920 --> 44:08.360]  если мы дошли досюда и не нашли ну не повезло но если нас просили если нас
[44:08.360 --> 44:14.920]  просили квадратной скобочки при этом то мы создадим ноду вот тут вот и ее вернем
[44:14.920 --> 44:29.640]  это правильный вопрос отлично детектив да все так что делать смотрите допустим мы
[44:29.640 --> 44:34.680]  хотим давайте сначала про insert поговорю вот понятно ли как работать insert должен
[44:34.680 --> 44:44.320]  ну хорошо допустим мы как вставить сюда понятно а что если нас попросили вставить вот
[44:44.320 --> 44:51.080]  сюда проверяем что там пустое вставляем на угодно можно в конце начала у нас forward
[44:51.080 --> 44:56.640]  лист поэтому в начало то есть если нас просят вставить и мы видим что ячейка массива пустая
[44:56.640 --> 45:06.280]  мы просто делаем начало списка теперь вот этим так insert работает а как работает и race что если
[45:06.280 --> 45:10.960]  нас прости ну если нас попросили там какой-то элемент из середины удалить понятно а что если
[45:10.960 --> 45:20.960]  нас попросили удалить элемент да а энт не знаю а последний элемент перед
[45:20.960 --> 45:31.080]  рендом нельзя найти за единицу господи у форвард листа сайз работает за линию
[45:31.080 --> 45:42.680]  интересные факты от Ильи Мещелина да в общем да я удивился когда узнал но это кажется так они
[45:42.680 --> 45:51.280]  потому что не хотели поддерживать сайз в виде поля и они его вычисляют проходом если надо ну чтобы
[45:51.280 --> 45:57.560]  минимали чтобы чтобы минимум ну например для этого да ну и чтобы был минималистичный такой лист
[45:57.560 --> 46:21.400]  с минимумом так как делать и рейс как делать и рейс вот мне надо сделать и рейс допустим вот
[46:21.400 --> 46:31.680]  этого элемента что сделать не надо что
[46:31.680 --> 46:44.840]  да вот как этому
[46:44.840 --> 47:14.520]  ну в общем есть два варианта
[47:14.840 --> 47:20.800]  они оба плохи они оба мне не нравятся но я лучше ничего не знаю и я не знаю как сделано
[47:20.800 --> 47:27.800]  вст л на самом деле но я есть два варианта первый вариант первый вариант это хранить указатель не
[47:27.800 --> 47:34.400]  на начало списка на вершину перед ним второй вариант это хранить двусвязанный на самом деле
[47:34.560 --> 48:04.000]  если мы хотим удалить ее это значит что мы шли не с нее а с какой-то с левее нее
[48:04.000 --> 48:22.960]  все указатели которые мы не можем в смысле вот вот этот указатель мы не сможем перенаправить
[48:22.960 --> 48:32.960]  а окей тогда видимо это решение тоже не работает ну короче да плохо в общем ну я в общем не знаю на
[48:32.960 --> 48:38.920]  самом деле более красивое решение чем двусвязанный список просто сделать вместо односвязанного ну
[48:38.920 --> 48:44.280]  возможно есть просто есть решение которого я не знаю я не знаю кто-то сделанного стель возможно
[48:44.280 --> 48:51.440]  там это ничего не значит у них знаешь ли хэштаблица с открытой адресацией тоже
[48:51.440 --> 48:57.280]  реализована но на ее нам не предоставляют ну в смысле там много чего реализована что
[48:57.280 --> 49:01.440]  нам не предоставляют пока потому что они еще не до конца уверены в том что его предоставляет
[49:01.440 --> 49:10.200]  пора не знаю ну хэштаблица ну там вы же вы же вы лучше меня знаете что там реализована наверное
[49:10.200 --> 49:14.000]  там всякие какие-то есть структуры там свои деревья свои умные что-то быстрые а
[49:14.000 --> 49:26.680]  нет ну там наверняка есть какая-нибудь более быстрая хэштаблица но просто она не вынесена
[49:26.680 --> 49:48.800]  ну например ну те это ты ты родина то я не помню хорошо техник в общем на самом деле как вы так
[49:48.800 --> 49:55.080]  короче вот понятно что с двусвязанным списком это будет работать можно ли обойтись без
[49:55.080 --> 50:00.400]  двусвязанного списка и делать красить и делать нормальное удаление не знаю наверное как-то
[50:00.400 --> 50:12.600]  можно но тут вопрос что вам больше нравится ну наверное можно но я не уверен что-то более
[50:12.600 --> 50:28.040]  да мы можем вызвать диструктор и просто не обращаться к нему да такому нет так
[50:28.040 --> 50:33.720]  можно да я не говорю что это не рабочие решения наверное оно рабочее но в общем не знаю что вам
[50:33.720 --> 50:43.480]  больше нравится вот то и то и выбирайте я не уверен что быстрее вообще из этого но
[50:43.480 --> 50:47.280]  поняв что тут связан список накладные расходы но это тоже какие-то накладные расходы с другой
[50:47.280 --> 50:54.880]  стороны если поставить то сколько у тебя будет работать
[50:54.880 --> 51:21.240]  амортизировано или в среднем
[51:21.240 --> 51:36.080]  так давайте дальше поговорим про то что еще все окей мы поняли мы поняли короче
[51:36.080 --> 51:45.720]  идеи на как это устроено все давайте пожалуйста надо дальше дайте пожалуйста дальше продвинемся у
[51:45.720 --> 52:00.160]  нас еще один есть шаблонный параметр это компаратор ключи да мы можем какой-то другой
[52:00.160 --> 52:07.120]  компаратор передать необычное сравнение по умолчанию стд equal to это как стд less только
[52:07.120 --> 52:11.640]  оператор равно равно вместо прятал меньше вызывает но мы можем и свое передать то есть
[52:11.640 --> 52:20.760]  нам нужно сравнивать ключи тоже уметь на равенство сравнивать вот ну как вы понимаете все это может
[52:20.760 --> 52:29.680]  кидать исключения и давайте подумаем если что-нибудь из этого кидает исключение не
[52:29.680 --> 52:54.080]  сломается ли у нас все хэш хэш может кинуть исключение да мы должны стронг exception
[52:54.080 --> 52:57.960]  guarantee ничего не произойти должно с контейнером если кто-то кинул исключение используется к
[52:57.960 --> 53:12.440]  функции вот ну если компаратор кидает исключение это плохо или нет да ну кажется нормально вот ну
[53:12.440 --> 53:18.760]  надо просто будет аккуратно написать то есть будет я кстати кстати в тестах прошлого года у меня
[53:18.760 --> 53:27.120]  по мне было теста когда компаратор кидает исключение в этом году надо добавить ну там там
[53:27.120 --> 53:44.320]  ну я не могу гарантировать что я прям все возможные случаи провели ну там понятно что обязательно будут
[53:44.320 --> 53:52.240]  тесты когда короче короче тесты когда все вот какие вл ю хэш икул все будет время от времени
[53:52.240 --> 53:57.080]  кидать исключение там будут специальный тест на исключение и в общем я буду проверять что с
[53:57.080 --> 54:03.600]  контейнером ничего не случилось что все лежит как раньше еще еще локатор иногда может кидать
[54:03.600 --> 54:08.400]  исключение это отдельная история но мы пока про это не говорим еще пятый пока не знаю что такое
[54:08.400 --> 54:21.720]  локатор я не а как я буду проверять что ничего не поменялось что-нибудь придумаю вы
[54:21.720 --> 54:27.480]  мне сами подскажете еще каких тестовых случаев не хватает как обычно вы это делаете так что так
[54:27.480 --> 54:32.880]  дальше что еще давайте поговорим про какие про специфические методы хэштаблицы ну хэштаблицы
[54:32.880 --> 54:47.800]  есть такой очень важный метод reserve как у вектора прям reserve от n вот reserve это метод который говорит
[54:47.800 --> 54:58.840]  сделай мне хэштаблиц такого размера чтобы мне хватило на нее на н элементов да вот так а как
[54:58.840 --> 55:03.720]  он понимает сколько нужно элементов хэштаблицы сколько какой должен быть размер хэштаблицы в
[55:03.720 --> 55:11.720]  зависимости от н нет какой хэш мы передаем это вот наш мы плохой хэш передали он вот у него есть
[55:11.720 --> 55:18.880]  некоторая внутренняя константа которая называется load factor у него есть такая константа которая
[55:18.880 --> 55:28.440]  называется max load factor и есть текущий load factor текущий load factor это отношение количества
[55:28.440 --> 55:34.640]  элементов которые сейчас добавлены в хэштаблицу к размеру вот этого массива max load factor это load
[55:34.640 --> 55:38.760]  factor при достижении которого он сделает перехэширование всех элементов
[55:38.760 --> 56:04.280]  если у него очень много ну очень много элементов в одной вершине ну нет насколько я знаю вот под
[56:04.280 --> 56:19.240]  это нету ничего типа или или очень хорошие ключи наоборот хэш хороший просто ключи специально
[56:19.240 --> 56:27.240]  так подобрал чтобы у всех хэш был одинаковый в общем есть есть load factor это вот отношение
[56:27.240 --> 56:32.400]  текущего количества элементов к размеру массива есть max load factor по умолчанию он равен вот я не
[56:32.400 --> 56:39.720]  помню чему ну что-то там типа блин нет конечно ну какая какое-то число от нуля до единицы но я
[56:39.720 --> 56:45.600]  забыл какое не помню какое ну можно можно носить переференс просто посмотреть чему он равен по
[56:45.600 --> 56:53.080]  умолчанию его можно поменять то есть вы можете сказать какой вам max load factor устраивать вы
[56:53.080 --> 56:59.320]  можете есть функция set max load factor и get max load factor то есть вы можете спросить вы можете
[56:59.320 --> 57:04.240]  у хэш таблицы спросить какой у нее сейчас max load factor то есть по достижении какого load
[57:04.240 --> 57:09.760]  фактора она перестроится и вы можете сказать set max load factor то есть какой бы вы хотели чтобы
[57:09.760 --> 57:18.480]  он был чтобы допустим она бы перестраивалась раньше чтобы у вас load factor это отношение
[57:18.480 --> 57:24.840]  количества элементов которые в ней лежат к размеру массива ну а что rational это должен
[57:24.840 --> 57:37.000]  быть это отношение ну типа ты ты смотришь на него как на вещественное число потому что у тебя
[57:37.000 --> 57:45.800]  размер таблицы он может меняться а max load factor будет оставаться одним и тем же вот и собственно
[57:45.800 --> 57:55.880]  есть функция rehash rehash это функция которая как раз перестраивает хэш таблицу вот я не помню
[57:55.880 --> 58:06.160]  принимать ли она какой-то параметр вот нет она ее вызвать можно да можно делать rehash самостоятельно
[58:06.160 --> 58:12.640]  если там вы вдруг поняли что что-то но вы допустим поняли что что-то не знаю там ну хотя нет как
[58:12.640 --> 58:20.840]  вы это поймете никак не поймете ну в общем не знаю вы там что-то вот поняли и решили rehash
[58:20.840 --> 58:29.680]  делать что делает rehash вот это самый интересный вопрос все вот это мы классно построили а
[58:29.680 --> 58:37.520]  теперь нам нужно хэш таблицу расширить ну то есть ну скажем в два раза или не знаю в три
[58:38.000 --> 58:43.400]  rehash мы поняли что все что-то элементов стало слишком много нам добавляют еще один мы уже
[58:43.400 --> 58:51.080]  превысили max load factor значит нужно перестроить эту всю штуку и переложить все элементы значит
[58:51.080 --> 58:59.360]  ну вот на cpp референс написано что rehash работает в среднем за линию но worst case quadratic
[58:59.360 --> 59:13.240]  да ну давайте подумаем как rehash делать как вот во всем этом то есть нам нужно список
[59:13.240 --> 59:18.600]  сохранить постараться ну или нет нам может быть нам уже новый список построить но нам нужно вот
[59:18.600 --> 59:26.600]  короче как-то умудриться вот эти все штуки переложить вариант считать удаляем таблицу
[59:27.360 --> 59:36.680]  да да окей то есть мы что делаем мы говорим окей давайте просто новую таблицу создадим
[59:36.680 --> 59:45.640]  не забывая что у нас все может кинуть из ключей то есть нам надо старую мы не удаляем мы сначала
[59:45.640 --> 59:50.520]  создаем новую пытаемся все положить в правильном порядке только после этого удаляем старые потому
[59:50.520 --> 59:54.480]  что если вдруг по дороге кто-то кинет исключение мы должны оперативненько все обратно убрать как
[59:54.480 --> 01:00:04.360]  было вернуть таблицу назад ну собственно да это как раз наверное из-за того что мы можем в
[01:00:04.360 --> 01:00:18.400]  худшем случае у нас может линейное время занимать то мы делаем мы дропаем эту таблицу и просто для
[01:00:18.400 --> 01:00:24.000]  каждого элемента списка делаем как бы insert фактически уже в новую таблицу вот понятно почему
[01:00:24.080 --> 01:00:37.440]  это может плохо медленно работать вот вопрос что происходит с итераторами и
[01:00:37.440 --> 01:00:50.280]  со ссылками на элементы а вот нифига вот сейчас я вам скажу еще одну замечательную вещь ссылки
[01:00:50.280 --> 01:00:55.320]  и указатели на элементы не инвалидируется при инсерте в том числе на элементы да на
[01:00:55.320 --> 01:01:07.320]  элементы да но если вы другой список создадите то это будет означать что ссылки на старые
[01:01:07.320 --> 01:01:17.280]  элементы списка не ну почему не можем переложить или указатели тоже указатель может переложить
[01:01:17.280 --> 01:01:22.480]  указатели видимо честно мы не можем хранить значение нужно везде хранить указатель и нет
[01:01:22.480 --> 01:01:35.080]  а вот интересный факт для интов и он глагол макс вот фактор вторая единица я не знаю почему
[01:01:35.080 --> 01:01:53.960]  сейчас я проверю потому что я сомневался
[01:02:05.080 --> 01:02:30.960]  так короче нет все правильно я ничего не напутал я испугался что я вас обманул нет значит если вы
[01:02:30.960 --> 01:02:36.400]  правильно помните таблицу которую мы рисовали в самом начале когда про контейнеры говорили то
[01:02:36.400 --> 01:02:45.160]  мы говорили что в unordered map инсерт инвалидирует итераторы но не ссылки указательные элементы
[01:02:45.160 --> 01:02:51.520]  и тогда мы ничего про рехэш не знали но теперь знаем и это требование надо соблюсти то есть
[01:02:51.520 --> 01:02:59.440]  unordered map должен делать рехэш так чтобы ссылки указательно старый элемент остались валидными то
[01:02:59.440 --> 01:03:08.640]  есть если я завел там у меня вот тут лежал там какой-нибудь стринг и я там сделал не знаю
[01:03:08.640 --> 01:03:23.320]  авто амперсант там x равно там моя мэпа по ключу к а потом такой хоба а это опять ты я понял
[01:03:23.320 --> 01:03:36.360]  м.рехэш то вот по этому x все должно по-прежнему быть нормально потому что если я новый лист создам
[01:03:36.360 --> 01:04:04.800]  и дропну старый лист мы дропаем таблицу и хотим этот список таблица сейчас в два раза
[01:04:04.800 --> 01:04:10.960]  больше станет это значит что вот эта вся структура совсем изменится потому что у меня теперь будет
[01:04:10.960 --> 01:04:20.680]  другая таблица нет она изменится абсолютно непонятным образом то есть теперь у меня должно вот так
[01:04:20.680 --> 01:04:26.120]  выглядеть теперь у меня короче вот это ячейки должны соответствовать вот эти оба элемента вот
[01:04:26.120 --> 01:04:30.680]  это ячейки должен соответствовать только этот элемент вот это ячейки должен соответствовать этот
[01:04:30.680 --> 01:04:35.760]  элемент вместе с этим элементом вот так у меня изменилось как мы теперь должны перестать мы должны
[01:04:35.760 --> 01:04:43.680]  то есть она совершенно не по рандомным образом перестроилась и теперь множество как-то поменялись
[01:04:43.680 --> 01:04:51.200]  совершенно произвольно что надо сделать да ну то есть мы берем теперь то есть мы не делаем новый
[01:04:51.200 --> 01:05:00.800]  список на самом деле мы берем очередную берем вершину списка и чего мы как бы создаем получается
[01:05:00.800 --> 01:05:14.360]  новый список в список мы ничего не делаем со значениями да то есть фактически мы если бы нам
[01:05:14.360 --> 01:05:22.920]  не нужно было сильную гарантию давать ничего да то мы могли бы сделать следующее берем первый
[01:05:22.920 --> 01:05:39.320]  элемент списка удаляем его из списка и вставляем новый список ну нам надо просто эти указатели
[01:05:39.920 --> 01:06:07.160]  сейчас давайте считать что у меня как бы есть новый список который пока пустой
[01:06:07.160 --> 01:06:13.880]  теперь я беру беру вот это вычисляю хэш и делаю как бы инсерт но что такое
[01:06:13.880 --> 01:06:18.920]  инсерт список я выцепляю вершину и с этого списка и помещаю в новый мне не надо для этого
[01:06:18.920 --> 01:06:23.840]  копировать well you type ничего с well you type делать не надо идеологически не надо но если у вас
[01:06:23.840 --> 01:06:31.400]  обычный стд лист ну конечно у меня необычный стд лист я пишу список как я делаю список как
[01:06:32.400 --> 01:06:41.480]  я просто то есть я не заново создаю список из этого а я беру очередную вершину отцепляю
[01:06:41.480 --> 01:06:51.920]  от списка и зацеплю присобачу в новый список нужное место ну и все и так иду что если вылетит
[01:06:51.920 --> 01:07:01.960]  исключение нет и кол мы вызываем потому что мы инсертом список мы идем по спитну там
[01:07:01.960 --> 01:07:19.000]  сейчас чего нет ну когда я делаю инсерт новый список я а да хорошо и кол мне не надо вызывать
[01:07:19.000 --> 01:07:27.240]  согласен но мне надо что если что если хэш кинет исключение самый главный вопрос
[01:07:27.240 --> 01:07:35.160]  не искать мы
[01:07:35.160 --> 01:07:40.600]  нам не нужно все равно сравнивать сами штуки мы знаем что все именно условные элементы разными
[01:07:40.600 --> 01:07:47.480]  даже нам просто по хэшу сравнить да это идеологически нам нельзя будет переиспользовать
[01:07:47.480 --> 01:07:54.960]  описанный инсерт это отвратительно но это реально реалистично а вот на хэши посчитать сразу пройтись по
[01:07:54.960 --> 01:08:04.280]  всему списку один разочек и насчитать хэши старые видимо сохранить пока что на время но это
[01:08:04.400 --> 01:08:15.000]  то есть то есть мы сначала насчитываем заранее все хэши и
[01:08:15.000 --> 01:08:24.720]  ну что
[01:08:24.720 --> 01:08:36.720]  вдруг пока мы уже частично список перестроили и тут какой-то хэш кинул исключение нам
[01:08:36.720 --> 01:08:45.400]  нужно список обратно тогда перестроить будет поэтому давайте заранее посчитаем все хэши
[01:08:45.400 --> 01:09:02.400]  вот мы и пересчитываем а старые сохраняем типа доп. веков как вот это и вот мы
[01:09:02.400 --> 01:09:23.160]  кстати да хорошая идея может быть может быть и так можно даже можно просто хранить
[01:09:23.160 --> 01:09:38.400]  что стд хэш от этого элемента результат вызова стд хэш от этого значения от этого ключа
[01:09:38.400 --> 01:09:55.360]  ну тут ну тут у нас как бы проблема посерьезнее так ну что справитесь написать теперь это
[01:09:55.360 --> 01:10:11.560]  это второе задание шутка сейчас произошла в чем не вызывает хэш не но получается тогда
[01:10:11.560 --> 01:10:31.600]  нет но исключение всегда может вылететь из-за там реаллокации например нет нет реаллокации
[01:10:31.600 --> 01:10:36.360]  всегда может кинуть исключение это что нью кинет исключение сейчас а мы ориентируемся на то что
[01:10:36.360 --> 01:10:48.680]  не ю может кидать исключение в этом случае мы тоже должны все нормально сделать что мы должны
[01:10:48.680 --> 01:10:57.640]  оставить хэштаблицу в неизменном состоянии несмотря на это мы просто выделяем сначала все
[01:10:57.640 --> 01:11:03.400]  что мы мы заранее всегда когда мы exception safety пишем мы заранее выделяем все что надо то есть
[01:11:03.400 --> 01:11:09.600]  мы выделили себе большую хэштаблицу и если не получилось то мы еще ничего не меняли просто
[01:11:09.600 --> 01:11:14.920]  выходим все мы заранее все выделили а потом начали перекладывать уже нью мы никогда не
[01:11:14.920 --> 01:11:24.640]  вызываем где мы хотим еще от единицы там память на указатель сохранить ну заранее надо значит это все
[01:11:24.640 --> 01:11:46.280]  так минуточку минуточку я говорю про вызов нью на стеке какая разница нью кидает исключение
[01:11:46.880 --> 01:12:05.160]  если ты создал локальных переменных больше чем размер стека да ну это ты никак от этого не
[01:12:05.160 --> 01:12:10.440]  защитить если у тебя локальных переменных больше чем размер стека ну сорян но такого мы считаем
[01:12:10.440 --> 01:12:21.080]  никогда не происходит потому что ну там просто там никаких исключений вообще не речь не идет
[01:12:21.080 --> 01:12:29.280]  речь идет только обе прятали нью когда он когда я про exception safety говорю ну вот такие дела значит
[01:12:29.280 --> 01:12:38.880]  вот он ордер не знаю не знаю во сколько раз честно говоря не помню но вот сколько-то
[01:12:59.280 --> 01:13:11.920]  значит ну на самом деле я вам уже значит смотрите у вас на практике вы не вызываете
[01:13:11.920 --> 01:13:16.960]  нью напрямую еще раз у вас это спойлер на следующую неделю следующая тема у нас
[01:13:16.960 --> 01:13:21.240]  будет создаться локаторы мы поговорим о том что на самом-то деле здесь есть пятый параметр
[01:13:21.240 --> 01:13:25.880]  который называется локатор и он во всех контейнерах есть и на самом деле он ордер как и любой
[01:13:25.880 --> 01:13:30.920]  контейнер никогда к нью не обращается напрямую он всегда через класс локатор просит выделение
[01:13:30.920 --> 01:13:35.640]  памяти и вот как раз а локатор может кидать исключение вот про это мы отдельно поговорим
[01:13:35.640 --> 01:13:41.560]  то есть а локатор может кинуть исключение например потому что оператор нью внутри него кинул
[01:13:41.560 --> 01:13:53.440]  исключение что было первым а локатор это еще одна абстракция над оператором нью да
[01:13:53.440 --> 01:14:10.040]  так окей это было да и еще и с муф семантикой да после локатора у нас будет муф семантика
[01:14:10.040 --> 01:14:24.520]  нет здесь пререхеша мувать ничего не надо будет но там есть много разных мест где потенциально
[01:14:24.520 --> 01:14:33.920]  конечно ну слушайте в общем давайте не будем но там методы просто соответствующие но там надо
[01:14:33.920 --> 01:14:40.520]  иногда не копировать и перемещать кое-что вот у нас значит ссылки не инвалидирует а итераторы
[01:14:40.520 --> 01:15:00.400]  почему инвалидируется кстати но итератор да тут написано что итератор хранил что что
[01:15:00.400 --> 01:15:06.160]  нет тут не написано ну короче мы считали что итератор по хэш мэпу это на самом деле был
[01:15:06.160 --> 01:15:12.000]  итератор по листу но это неправда потому что это на самом деле не был не совсем лист и не
[01:15:12.000 --> 01:15:18.000]  совсем итератор на него ну не настоящий форвард лист потому что настоящий форвард лист не вот
[01:15:18.000 --> 01:15:25.200]  такого как мы тут проделали нельзя сделать ну ты же сам говорил что нельзя но это не настоящий
[01:15:25.200 --> 01:15:30.920]  стд форвард лист это форвард это внутренний наш лист с дополнительными поддерживаемыми операциями
[01:15:30.920 --> 01:15:38.600]  ну итератор на этот лист тоже не совсем то что мы понимали да то есть на самом деле это будет
[01:15:38.600 --> 01:15:47.240]  просто указатель на вершину листа не итератор стандарта в классическом понимании итератор
[01:15:47.240 --> 01:15:52.000]  на лист а просто указатель на вершину листа и что тогда такой его инкремент этот переход к
[01:15:52.000 --> 01:15:57.920]  следующему в терминах этого листа но проблема в том что когда мы сделаем rehash у нас порядок
[01:15:57.920 --> 01:16:10.360]  может нарушиться и переход к следующему станет да например например у нас end потеряется
[01:16:10.360 --> 01:16:23.160]  ну у нас точно инвалидируется end предыдущий да у нас еще да еще у нас же надо надо end поддерживать
[01:16:23.160 --> 01:16:43.400]  я рад что для вас уже это стало привычной ситуацией не прошло не прошло и двух недель
[01:16:43.400 --> 01:16:51.440]  сначала семестра недели не прошло еще сначала семестр хорошо так ну ладно короче ну все понятно
[01:16:51.440 --> 01:16:57.000]  отлично так ну а что а сколько а время то у нас уже закончилось же да
