[00:00.000 --> 00:16.000]  Как ваши продвижения по сегодняшней вероятности?
[00:16.000 --> 00:19.000]  Ну, я понимаю, да.
[00:19.000 --> 00:23.000]  Но я имею в виду, что в прошлый раз я чё-то начал рассказывать,
[00:23.000 --> 00:26.000]  и вы мне сказали, что почти ничего не знаете.
[00:26.000 --> 00:30.000]  Но, может быть, за неделю, которая прошла с тех пор,
[00:30.000 --> 00:33.000]  вы много чего нового узнали?
[00:33.000 --> 00:36.000]  Нет?
[00:36.000 --> 00:39.000]  А, это не относится к тому, что я рассказывал.
[00:39.000 --> 00:43.000]  Ладно.
[00:43.000 --> 00:45.000]  Меня это не напрягает.
[00:45.000 --> 00:47.000]  Буду рассказывать сам.
[00:47.000 --> 00:51.000]  Хорошо, а то, что я рассказывал в прошлый раз,
[00:51.000 --> 00:55.000]  вы как-то осознали, помните?
[00:55.000 --> 00:57.000]  Про графы?
[00:57.000 --> 01:02.000]  Нет, там были мат ожидания каких-то случайных величин.
[01:02.000 --> 01:05.000]  Инейность.
[01:05.000 --> 01:08.000]  Чё, не было, что ли?
[01:08.000 --> 01:12.000]  Как не было? Ну, я же в прошлый раз рассказывал.
[01:12.000 --> 01:15.000]  А, не было на теории вероятности. Там не было, да.
[01:15.000 --> 01:18.000]  А у меня-то было.
[01:19.000 --> 01:22.000]  Круто.
[01:25.000 --> 01:28.000]  Понятно, понятно.
[01:28.000 --> 01:34.000]  Не, но, друзья, мой темп изложения понятен, нормален.
[01:34.000 --> 01:38.000]  Вы за мной успеваете?
[01:38.000 --> 01:41.000]  Или что-то надо напомнить?
[01:43.000 --> 01:47.000]  Так, с точки зрения дискретного анализа вы помните,
[01:47.000 --> 01:50.000]  чего я хотел доказать?
[01:50.000 --> 01:52.000]  Тоже не помните.
[01:52.000 --> 01:55.000]  Ладно, смотрите, это мне нарисовали мёртвый угол.
[01:55.000 --> 01:58.000]  Здесь я писать не буду.
[01:58.000 --> 02:01.000]  А здесь я напишу тому,
[02:01.000 --> 02:04.000]  которому я очень подробно в прошлый раз комментировал,
[02:04.000 --> 02:07.000]  формуировал так-сяк.
[02:07.000 --> 02:09.000]  Ну, как вам сказать-то?
[02:09.000 --> 02:13.000]  Так-сяк прямо её со всех сторон рассматривал
[02:13.000 --> 02:16.000]  из практической точки зрения.
[02:16.000 --> 02:19.000]  Содержательный счёт какой-то.
[02:23.000 --> 02:26.000]  Давайте я напомню.
[02:26.000 --> 02:29.000]  Пусть...
[02:29.000 --> 02:33.000]  П это вероятность ребра случайного графа,
[02:33.000 --> 02:38.000]  и она зависит от того, сколько вершин у этого графа.
[02:38.000 --> 02:42.000]  Причём вот таким вот
[02:42.000 --> 02:46.000]  кажется пока ещё загадочным полосом.
[02:46.000 --> 02:50.000]  Это константа, большая нуля,
[02:50.000 --> 02:55.000]  тогда имеет место,
[02:55.000 --> 02:58.000]  что бы я назвал, квазовым переходом.
[03:02.000 --> 03:06.000]  Если c больше 1,
[03:06.000 --> 03:10.000]  то асинтетически почти, наверное,
[03:11.000 --> 03:15.000]  случайный граф связан.
[03:17.000 --> 03:20.000]  А если c
[03:23.000 --> 03:26.000]  меньше 1,
[03:26.000 --> 03:31.000]  то асинтетически почти, наверное,
[03:32.000 --> 03:36.000]  g, n, b не является
[03:36.000 --> 03:39.000]  связан.
[03:42.000 --> 03:45.000]  Ну, я так говорил, что будет в лицеравном единице,
[03:45.000 --> 03:48.000]  говорил какую-то убойную совершенно теорему про
[03:48.000 --> 03:52.000]  е в степени минус, е в степени минус гамма.
[03:52.000 --> 03:54.000]  Понимаете, был такой просто
[03:54.000 --> 03:56.000]  абсолютный восторг, по-моему.
[03:56.000 --> 03:59.000]  Мне кажется, это абсолютный восторг.
[03:59.000 --> 04:02.000]  Но я чётко говорил в прошлый раз,
[04:02.000 --> 04:05.000]  что доказывать буду только это.
[04:06.000 --> 04:09.000]  Я всё ещё не готов к вам это доказывать,
[04:09.000 --> 04:12.000]  потому что, если я правильно помню,
[04:12.000 --> 04:14.000]  чем я завершил прошлую лекцию,
[04:14.000 --> 04:17.000]  после которой я успел прочитать ещё 8 штук
[04:17.000 --> 04:20.000]  других лекций.
[04:20.000 --> 04:23.000]  Поэтому голос по-прежнему не совсем нормальный,
[04:23.000 --> 04:25.000]  но уже так полерьми.
[04:25.000 --> 04:28.000]  Значит, что я хочу сказать?
[04:28.000 --> 04:31.000]  Я помню, что я закончил линейностью мат ожидания,
[04:31.000 --> 04:34.000]  и мы посчитали среднее число треугольников
[04:34.000 --> 04:37.000]  в случайном графе.
[04:37.000 --> 04:40.000]  И я вам задал домашнюю задачу –
[04:40.000 --> 04:43.000]  посчитать вероятность того,
[04:43.000 --> 04:46.000]  что треугольников в случайном графе нет.
[04:46.000 --> 04:49.000]  Но, естественно, вы не пытались её решать.
[04:49.000 --> 04:52.000]  Я прав, товарищ?
[04:52.000 --> 04:55.000]  Вы даже забыли, что она была.
[04:55.000 --> 04:58.000]  Ты красный.
[04:58.000 --> 05:01.000]  Ну ладно, мы к ней тоже вернёмся.
[05:01.000 --> 05:04.000]  Давайте я напомню, что я обозначал
[05:04.000 --> 05:07.000]  вот таким образом мат ожидания
[05:07.000 --> 05:10.000]  случайной величины х,
[05:10.000 --> 05:13.000]  а ещё я вам введу вот такой вот объект,
[05:13.000 --> 05:16.000]  называется дисперсия случайной величины х.
[05:26.000 --> 05:29.000]  Вообще мне кажется, что в этом году
[05:29.000 --> 05:32.000]  я читаю чуть более подробно и аккуратно,
[05:32.000 --> 05:35.000]  чем обычно.
[05:35.000 --> 05:38.000]  Может быть, с этим связано, как бы это сказать,
[05:38.000 --> 05:41.000]  большее количество народа в аудитории
[05:41.000 --> 05:44.000]  на третьей лекции.
[05:44.000 --> 05:47.000]  Четвёртая, ну вообще круто.
[05:47.000 --> 05:50.000]  Так, давайте я напомню, что такое дисперсия.
[05:50.000 --> 05:53.000]  Напомню, скажу, с нуля.
[05:53.000 --> 05:56.000]  Это математическое ожидание
[05:56.000 --> 05:59.000]  вот такого вот выражения.
[05:59.000 --> 06:02.000]  Мы берём случайную величину,
[06:02.000 --> 06:05.000]  вот эту х,
[06:05.000 --> 06:08.000]  вычитаем из неё
[06:08.000 --> 06:11.000]  её среднее значение, мат ожидания.
[06:11.000 --> 06:14.000]  Всё это дело
[06:14.000 --> 06:17.000]  возводим в квадрат
[06:17.000 --> 06:20.000]  и потом снова у средня.
[06:20.000 --> 06:23.000]  Можно вот так ещё скобки нарисовать,
[06:23.000 --> 06:26.000]  к чему применяется оператор Е.
[06:26.000 --> 06:29.000]  Мат ожидания.
[06:29.000 --> 06:32.000]  Так, что-нибудь понятно?
[06:32.000 --> 06:35.000]  Ну, это такое вот, если словами говорить,
[06:35.000 --> 06:38.000]  среднее квадратичное уклонение
[06:38.000 --> 06:41.000]  случайной величины от своего среднего значения.
[06:41.000 --> 06:44.000]  То есть, вот она
[06:44.000 --> 06:47.000]  принимает какие-то значения,
[06:47.000 --> 06:50.000]  вот эта случайная величина х,
[06:50.000 --> 06:53.000]  мат ожидания,
[06:53.000 --> 06:56.000]  а вот этот вот разброс,
[06:56.000 --> 06:59.000]  он меряется дисперсией.
[06:59.000 --> 07:02.000]  Друзья, нужно подробно или понятно?
[07:02.000 --> 07:05.000]  Можно ещё скобки раскрыть.
[07:05.000 --> 07:08.000]  Так тоже делаю.
[07:08.000 --> 07:11.000]  Получается полезная, удобная другая формула.
[07:11.000 --> 07:14.000]  Ну как? Скобки раскрываются в квадрат,
[07:14.000 --> 07:17.000]  умеем возводить.
[07:17.000 --> 07:20.000]  2х Ех
[07:20.000 --> 07:23.000]  плюс Ех
[07:23.000 --> 07:26.000]  в квадрате.
[07:26.000 --> 07:29.000]  Я просто тупо возбил в квадрат разность.
[07:29.000 --> 07:32.000]  А теперь я применяю Е
[07:32.000 --> 07:35.000]  вот к этому поражению.
[07:35.000 --> 07:38.000]  То есть, могу воспользоваться линейностью.
[07:38.000 --> 07:41.000]  Раскрыть скобки, занося Е внутрь.
[07:41.000 --> 07:44.000]  Линейностью пользуюсь.
[07:47.000 --> 07:50.000]  Друзья,
[07:50.000 --> 07:53.000]  если вдруг всё понятно,
[07:53.000 --> 07:56.000]  но вы тем не менее не успеваете записывать,
[07:56.000 --> 07:59.000]  вы меня притормаживайте, пожалуйста.
[07:59.000 --> 08:02.000]  Я хочу, чтобы вы всё успевали понимать
[08:02.000 --> 08:05.000]  и фиксировать для себя то, что вы поняли.
[08:05.000 --> 08:08.000]  Что это значит?
[08:08.000 --> 08:11.000]  Это значит, что я беру квадрат из значений
[08:11.000 --> 08:14.000]  случайной величины,
[08:14.000 --> 08:17.000]  кроме квадрата до усреднения.
[08:17.000 --> 08:20.000]  Очень интересно, что произойдёт,
[08:20.000 --> 08:23.000]  когда я применю мат ожидания к этому поражению.
[08:23.000 --> 08:26.000]  Смотрите, товарищи,
[08:26.000 --> 08:29.000]  2 это, очевидно, константа.
[08:29.000 --> 08:32.000]  Правда же, она вынесет за скобки при усреднении?
[08:32.000 --> 08:35.000]  А Ех тоже константа.
[08:35.000 --> 08:38.000]  Она тоже вынесет за скобки, правда?
[08:38.000 --> 08:41.000]  Поэтому получится вот так.
[08:41.000 --> 08:44.000]  Минус 2Ex.
[08:44.000 --> 08:47.000]  Это я вынес двойку и мат ожидания,
[08:47.000 --> 08:50.000]  который является константой, за скобку.
[08:50.000 --> 08:53.000]  А в скобках осталось только мат ожидания х.
[08:53.000 --> 08:56.000]  То есть я снова это умножаю на мат ожидания х.
[08:59.000 --> 09:02.000]  Это тоже константа.
[09:02.000 --> 09:05.000]  Мат ожидания константа, это она же сама.
[09:05.000 --> 09:08.000]  То есть мы прибавляем
[09:08.000 --> 09:11.000]  Ех в квадрате,
[09:11.000 --> 09:14.000]  потому что усредняя константу мы получаем её же саму.
[09:14.000 --> 09:17.000]  Так, дорогие друзья,
[09:17.000 --> 09:20.000]  но вот это тоже Ех в квадрате,
[09:20.000 --> 09:23.000]  для вашего позволения.
[09:23.000 --> 09:26.000]  Он со знаком минус из двойкой,
[09:26.000 --> 09:29.000]  а этот со знаком плюс.
[09:29.000 --> 09:32.000]  Поэтому получается вот такая штука.
[09:32.000 --> 09:35.000]  Такая вот удобная альтернативная формула
[09:35.000 --> 09:38.000]  для подсчёта дисперсии.
[09:38.000 --> 09:41.000]  Вот она.
[09:41.000 --> 09:44.000]  Вот это вот называется второй момент.
[09:47.000 --> 09:50.000]  Слушайте, друзья,
[09:50.000 --> 09:53.000]  я, конечно, буду издеваться,
[09:53.000 --> 09:56.000]  но вдруг среди вас есть люди,
[09:56.000 --> 09:59.000]  которые любят писем.
[09:59.000 --> 10:02.000]  Смеются, значит, не любят, похоже.
[10:03.000 --> 10:06.000]  Ну хорошо.
[10:06.000 --> 10:09.000]  А может быть, среди вас есть люди,
[10:09.000 --> 10:12.000]  которые знают физику.
[10:12.000 --> 10:15.000]  Да, ну нет, это уже истерика начала.
[10:15.000 --> 10:18.000]  Выполн в осадок.
[10:18.000 --> 10:21.000]  Значит, если вдруг всё-таки кто-то не смеётся,
[10:21.000 --> 10:24.000]  я вот скажу, может, туда скажу.
[10:24.000 --> 10:27.000]  Вот физики, физики,
[10:27.000 --> 10:30.000]  есть такое понятие, называется момент инерции.
[10:30.000 --> 10:33.000]  Никто не знает, да?
[10:33.000 --> 10:36.000]  Знаете, да?
[10:36.000 --> 10:39.000]  Вот практически то же самое.
[10:39.000 --> 10:42.000]  Дисперсия в математике это момент инерции физики.
[10:42.000 --> 10:45.000]  Ну так вот, там стойте сюда, нормировки.
[10:45.000 --> 10:48.000]  Ну ладно, это так просто.
[10:48.000 --> 10:51.000]  Так, друзья, ну я думаю, что я не буду
[10:51.000 --> 10:54.000]  больше комментировать, что такое дисперсия.
[10:54.000 --> 10:57.000]  А единственное, что можно сказать,
[10:57.000 --> 11:00.000]  такой вопрос, а зачем здесь возводить в квадрат?
[11:00.000 --> 11:03.000]  Иначе ноль получится.
[11:03.000 --> 11:06.000]  Ты квадрат убрать,
[11:06.000 --> 11:09.000]  то по линейности, очевидно, получится ноль.
[11:09.000 --> 11:12.000]  Другое дело, вы скажете, ну хорошо, можно
[11:12.000 --> 11:15.000]  рисовать модуль, да?
[11:15.000 --> 11:18.000]  Ну вот если рисовать модуль, то считать неудобно.
[11:18.000 --> 11:21.000]  Просто считать неудобно, и те неравенства,
[11:21.000 --> 11:24.000]  которые я сейчас приведу,
[11:24.000 --> 11:27.000]  надо помогать доказывать вот такие теоремы,
[11:27.000 --> 11:30.000]  они просто будут очень неудобно записываться.
[11:30.000 --> 11:33.000]  Так.
[11:33.000 --> 11:36.000]  Вот, я хочу привести
[11:36.000 --> 11:39.000]  два классических неравенства
[11:39.000 --> 11:42.000]  в теории вероятностей. Называются они
[11:42.000 --> 11:45.000]  неравенство Маркова и неравенство Чебышова.
[11:45.000 --> 11:48.000]  Слышали такие слова сочетания, нет?
[11:48.000 --> 11:51.000]  Ну кто-то слышал, кто-то нет,
[11:51.000 --> 11:54.000]  а сейчас я все подробно, спокойно расскажу.
[11:54.000 --> 11:57.000]  Так, неравенство
[11:57.000 --> 12:00.000]  Маркова.
[12:00.000 --> 12:03.000]  Друзья,
[12:03.000 --> 12:06.000]  чтобы вы точно понимали, что происходит,
[12:06.000 --> 12:09.000]  я еще раз повторю. В курсе
[12:09.000 --> 12:12.000]  основ теории меры и теории вероятностей,
[12:12.000 --> 12:15.000]  вам, конечно, это все расскажут.
[12:15.000 --> 12:18.000]  Потом, в большом курсе теории вероятностей,
[12:18.000 --> 12:21.000]  вам еще раз это расскажут.
[12:21.000 --> 12:24.000]  Это очень важные вещи, их надо прям вот как
[12:24.000 --> 12:27.000]  центральные фарты теории вероятностей воспринимать,
[12:27.000 --> 12:30.000]  потому что они работают, они нужны,
[12:30.000 --> 12:33.000]  вот они используются здесь, они в массе других
[12:33.000 --> 12:36.000]  ситуаций используются. Это надо знать.
[12:36.000 --> 12:39.000]  Я это доказываю, просто чтобы вам все было понятно.
[12:39.000 --> 12:42.000]  Я доказываю в частном случае,
[12:42.000 --> 12:45.000]  когда пространство элементарного события
[12:46.000 --> 12:49.000]  у нас граф в конечное число.
[12:49.000 --> 12:52.000]  Итак,
[13:02.000 --> 13:05.000]  пусть случайная величина Х
[13:05.000 --> 13:08.000]  на своем пространстве Омега, ну, например,
[13:08.000 --> 13:11.000]  на множестве графов, которые имеют там вершины,
[13:11.000 --> 13:14.000]  ну, или на каком-то конечном пространстве
[13:14.000 --> 13:17.000]  принимает вот такое вот какое-то конечное множество значений.
[13:17.000 --> 13:20.000]  Давайте еще
[13:20.000 --> 13:23.000]  дополнительно
[13:23.000 --> 13:26.000]  предположим, что каждая из этих значений
[13:26.000 --> 13:29.000]  не отрицательна.
[13:29.000 --> 13:32.000]  Случайная величина принимает только не отрицательные значения.
[13:32.000 --> 13:35.000]  Ну, например,
[13:35.000 --> 13:38.000]  число треугольников в случайном графе,
[13:38.000 --> 13:41.000]  это вот прекрасная величина, которая принимает
[13:41.000 --> 13:44.000]  только не отрицательные значения, правда?
[13:44.000 --> 13:47.000]  Сто треугольников.
[13:47.000 --> 13:50.000]  Ну, есть какая-то случайная величина,
[13:50.000 --> 13:53.000]  все ее значения не отрицательные.
[13:53.000 --> 13:56.000]  Для любого
[13:56.000 --> 13:59.000]  А больше нуля,
[13:59.000 --> 14:02.000]  А это константа, фиксированное число,
[14:02.000 --> 14:05.000]  любое действительное число положительное,
[14:05.000 --> 14:08.000]  вероятность того,
[14:08.000 --> 14:11.000]  что Х
[14:11.000 --> 14:14.000]  больше либо равняется А,
[14:14.000 --> 14:17.000]  и вверху
[14:17.000 --> 14:20.000]  в математическом опыдании,
[14:20.000 --> 14:23.000]  мы в зеленом на А.
[14:26.000 --> 14:29.000]  Что, что говорите?
[14:29.000 --> 14:32.000]  А оно будет следовать отсюда моментально.
[14:32.000 --> 14:35.000]  Значит, и Чебырков,
[14:36.000 --> 14:39.000]  значит, и Чебырков, это Марков, да?
[14:39.000 --> 14:42.000]  Оно не так выглядело, кстати?
[14:42.000 --> 14:45.000]  Нет, оно выглядело с моего роста.
[14:45.000 --> 14:48.000]  А, оно называлось Чебырковым, да?
[14:48.000 --> 14:51.000]  Ну, это некая культура, знаете, можно это назвать Чебырковым,
[14:51.000 --> 14:54.000]  можно то, что я обычно называю.
[14:54.000 --> 14:57.000]  Но как-то вот люди, которые занимаются именно
[14:57.000 --> 15:00.000]  специфической теорией вероятности, они почему-то
[15:00.000 --> 15:03.000]  разделяют, говорят, что вот это Марков,
[15:03.000 --> 15:06.000]  называть можете, как хотите, в принципе, и то, и другое Чебырков.
[15:06.000 --> 15:09.000]  Естественно, Чебырков, это знал и следствие знал.
[15:09.000 --> 15:12.000]  Просто так называю.
[15:12.000 --> 15:15.000]  Так, чего, друзья, знаете, как это доказывать, да?
[15:15.000 --> 15:18.000]  Ладно, сейчас докажем.
[15:18.000 --> 15:21.000]  В одну строчку.
[15:21.000 --> 15:24.000]  Все?
[15:24.000 --> 15:27.000]  Нет, ну давайте, мат ожидания Х.
[15:27.000 --> 15:30.000]  Я справа-налево буду смотреть на это неравенство.
[15:30.000 --> 15:33.000]  Давайте посмотрим на мат ожидания Х, это что-то.
[15:33.000 --> 15:36.000]  По определению.
[15:36.000 --> 15:39.000]  Это сумма.
[15:39.000 --> 15:42.000]  Вот И от единицы до Н.
[15:42.000 --> 15:45.000]  Игрехы значение, да,
[15:45.000 --> 15:48.000]  умножить на вероятность того,
[15:48.000 --> 15:51.000]  что Х равняется Y.
[15:51.000 --> 15:54.000]  Это второй вариант определения, который мы обсуждали в прошлый раз.
[15:54.000 --> 15:57.000]  Просто определение мат ожидания.
[15:57.000 --> 16:00.000]  Так.
[16:00.000 --> 16:03.000]  Теперь я просто распеваю эту сумму на две части.
[16:03.000 --> 16:06.000]  Я вообще, наверное, вас замучил
[16:06.000 --> 16:09.000]  с распиениями сумм на две части.
[16:09.000 --> 16:12.000]  Но, слава богу, это не тот случай, как при подсчете
[16:12.000 --> 16:15.000]  в унициплических графах.
[16:15.000 --> 16:18.000]  Помните, там была эта степень 0,6, какая-то жуткая.
[16:18.000 --> 16:21.000]  Тут все гораздо проще.
[16:21.000 --> 16:24.000]  Давайте отдельно просуммируем по таким И вот от единицы до Н,
[16:24.000 --> 16:27.000]  для которых Yt больше ли равняется А.
[16:29.000 --> 16:32.000]  Мы осуществляем все то же самое.
[16:32.000 --> 16:35.000]  Yt умножит на вероятность того,
[16:35.000 --> 16:38.000]  что Х равняется Y.
[16:38.000 --> 16:41.000]  И отдельно все остальные.
[16:41.000 --> 16:44.000]  Те, для которых Yt, соответственно, меньше,
[16:44.000 --> 16:47.000]  строго, чем. Так, плюс.
[16:47.000 --> 16:50.000]  Сумма по всем.
[16:50.000 --> 16:53.000]  И таким, что Yt меньше, чем А.
[16:53.000 --> 16:56.000]  5Yt на вероятность того,
[16:56.000 --> 16:59.000]  что Х равняется Y.
[16:59.000 --> 17:02.000]  Так, друзья, я думаю,
[17:02.000 --> 17:05.000]  что это не составляет таких вопросов.
[17:05.000 --> 17:08.000]  Очевидно, да?
[17:08.000 --> 17:11.000]  Так, смотрите, что еще отчего.
[17:11.000 --> 17:14.000]  Издевательская оценка. У нас все Yt не отрицательные.
[17:14.000 --> 17:17.000]  И вероятность это тоже не отрицательное число.
[17:17.000 --> 17:20.000]  Или вы считаете, что вероятность может быть отрицательной?
[17:20.000 --> 17:23.000]  А комплексной может быть?
[17:23.000 --> 17:26.000]  Ладно.
[17:26.000 --> 17:29.000]  Короче, я вот эту всю бяку
[17:29.000 --> 17:32.000]  оценю с и до нулем. Всю.
[17:32.000 --> 17:35.000]  Давай.
[17:38.000 --> 17:41.000]  Тогда сумма двух сумм оценится
[17:41.000 --> 17:44.000]  только первым слагаемым, первой суммой.
[17:44.000 --> 17:47.000]  Давайте ее оцениваем.
[17:47.000 --> 17:50.000]  Сразу.
[17:50.000 --> 17:53.000]  Смотрите, каждая Yt в этой сумме
[17:53.000 --> 17:56.000]  не меньше, чем А.
[17:56.000 --> 17:59.000]  Вынесем А за скобку.
[17:59.000 --> 18:02.000]  А в скобках останется сумма по тем И,
[18:02.000 --> 18:05.000]  для которых Yt не меньше, чем А.
[18:05.000 --> 18:08.000]  Вероятность того,
[18:08.000 --> 18:11.000]  что Х равняется Y.
[18:11.000 --> 18:14.000]  Поэтому...
[18:14.000 --> 18:17.000]  Так, этот перекод понять?
[18:17.000 --> 18:20.000]  Слушайте, ну вот,
[18:20.000 --> 18:23.000]  мы суммируем вероятности событий,
[18:23.000 --> 18:26.000]  которые очевидно не пересекаются, да?
[18:26.000 --> 18:29.000]  И суммируем по всем тиглях, которых Yt,
[18:29.000 --> 18:32.000]  то есть значение Ха,
[18:32.000 --> 18:35.000]  больше либо равняется А.
[18:35.000 --> 18:38.000]  Но вроде вся эта сумма и есть вот эта вероятность.
[18:38.000 --> 18:41.000]  Когда мы получаем А,
[18:41.000 --> 18:44.000]  мы умножим на вероятность того,
[18:44.000 --> 18:47.000]  что Х больше либо равняется А.
[18:47.000 --> 18:50.000]  Просто вот это событие разбили на кусочки
[18:50.000 --> 18:53.000]  и сложили вероятность.
[18:53.000 --> 18:56.000]  Друзья, если я вдруг подержу Y,
[18:56.000 --> 18:59.000]  я могу разогнаться.
[18:59.000 --> 19:02.000]  Не, нормально?
[19:02.000 --> 19:05.000]  Или еще медленнее?
[19:06.000 --> 19:09.000]  Так, ну вроде вы должны были понять.
[19:09.000 --> 19:12.000]  Так что теперь справа налево,
[19:12.000 --> 19:15.000]  вот эта вероятность не больше,
[19:15.000 --> 19:18.000]  чем мат ожидания поделить на А.
[19:18.000 --> 19:21.000]  Вот получили неравенство Марков.
[19:21.000 --> 19:24.000]  Так, давайте неравенство Чебыршова.
[19:27.000 --> 19:30.000]  Вот то, что я называю,
[19:30.000 --> 19:33.000]  неравенство Чебыршова.
[19:33.000 --> 19:36.000]  А, вас еще наверное учили Чебыршов говорить, да?
[19:36.000 --> 19:39.000]  Или Чебыршов?
[19:39.000 --> 19:42.000]  А, не учили?
[19:42.000 --> 19:45.000]  Не, есть две научных школы.
[19:45.000 --> 19:48.000]  Одна считает, что надо говорить Чебыршов,
[19:48.000 --> 19:51.000]  а другая, что Чебыршов.
[19:51.000 --> 19:54.000]  Вот нет ни одной школы,
[19:54.000 --> 19:57.000]  которая считала, что надо говорить Марков.
[19:57.000 --> 20:00.000]  Все говорят Марков.
[20:00.000 --> 20:03.000]  Но ее в русском языке не пишут.
[20:09.000 --> 20:12.000]  Вернее, знаете как?
[20:12.000 --> 20:15.000]  Когда надо писать, не пишут.
[20:15.000 --> 20:18.000]  А когда не надо, пишут.
[20:18.000 --> 20:21.000]  Вот помните, кто доказал это теорему,
[20:21.000 --> 20:24.000]  которую мы никак не докажем?
[20:24.000 --> 20:27.000]  Не помните?
[20:27.000 --> 20:30.000]  Я специально рисую ударение,
[20:30.000 --> 20:33.000]  просто подчеркиваю,
[20:33.000 --> 20:36.000]  что надо ударять на «и», не на «и».
[20:36.000 --> 20:39.000]  А Эрдов?
[20:39.000 --> 20:42.000]  Ничего не могу сделать.
[20:42.000 --> 20:45.000]  Во всех моих прошуток, которые изданы в МЦНМУ,
[20:45.000 --> 20:48.000]  хоть тресть, они пишут так.
[20:48.000 --> 20:51.000]  Естественно, Эрдов.
[20:51.000 --> 20:54.000]  Если ее в русском языке, она всегда ударная.
[20:55.000 --> 20:58.000]  А он вот так пишется.
[21:01.000 --> 21:04.000]  Мне отделили мертвый угол,
[21:04.000 --> 21:07.000]  я пишу вне мертвого угла.
[21:14.000 --> 21:17.000]  Мертвый угол вырос.
[21:17.000 --> 21:20.000]  Каждый год расширяется.
[21:20.000 --> 21:23.000]  В общем, в оригинале он пишется вот так.
[21:23.000 --> 21:26.000]  Но в кангерском языке,
[21:26.000 --> 21:29.000]  «с» читается как «ш».
[21:29.000 --> 21:32.000]  Вот эти две палки, это даже не две точки.
[21:32.000 --> 21:35.000]  Ну, ударение там все-таки на «е».
[21:35.000 --> 21:38.000]  А это такое «ы».
[21:38.000 --> 21:41.000]  Вот оно читается как «Эрдовж».
[21:44.000 --> 21:47.000]  В конце концов, я их поломал.
[21:47.000 --> 21:50.000]  Я ей говорю, ну вы не ставьте это ее,
[21:50.000 --> 21:53.000]  я ей говорю, ну вы не ставьте это ее,
[21:53.000 --> 21:56.000]  нет, нельзя, надо ставить «е».
[21:56.000 --> 21:59.000]  Но они писали вот так.
[21:59.000 --> 22:02.000]  Эрдовж, ну Эрдовж, это нормально,
[22:02.000 --> 22:05.000]  просто пойди догадайся.
[22:05.000 --> 22:08.000]  Ладно, сейчас я вот здесь верну фокулу,
[22:08.000 --> 22:11.000]  которую мы получили, она может пригодиться.
[22:11.000 --> 22:14.000]  Выкладку я убрал, а саму формулу сохранил.
[22:14.000 --> 22:17.000]  Так, неравенство Маркова,
[22:17.000 --> 22:20.000]  это неравенство Чебыфова.
[22:29.000 --> 22:32.000]  Пусть
[22:32.000 --> 22:35.000]  х, любая
[22:35.000 --> 22:38.000]  случайная личина, вообще любая.
[22:38.000 --> 22:41.000]  Ну, я имею в виду любая,
[22:41.000 --> 22:44.000]  в том смысле, что здесь она обязана была
[22:44.000 --> 22:47.000]  не отрицательные значения, а там вот какая вот,
[22:47.000 --> 22:50.000]  какая вот.
[22:50.000 --> 22:53.000]  Ну, вас в курсе теории вероятности
[22:53.000 --> 22:56.000]  будут грузить какими-то условиями сходимости, мат ожидания,
[22:56.000 --> 22:59.000]  дисперсии, но у меня напоминает всегда
[22:59.000 --> 23:02.000]  конечное множество значений,
[23:02.000 --> 23:05.000]  поэтому там мат ожидания всегда есть, дисперсия всегда есть,
[23:05.000 --> 23:08.000]  меня эти вопросы не беспокоят.
[23:08.000 --> 23:11.000]  Пусть их любая случайная величина,
[23:11.000 --> 23:14.000]  тогда
[23:14.000 --> 23:17.000]  для любого А больше нуля
[23:17.000 --> 23:20.000]  вероятность,
[23:23.000 --> 23:26.000]  которая выполнена
[23:26.000 --> 23:29.000]  вот такое вот неравенство, то есть х уклоняется
[23:29.000 --> 23:32.000]  от своего среднего не меньше, чем назаданную величину,
[23:32.000 --> 23:35.000]  достаточно сильно как бы уклоняется от центра мира,
[23:35.000 --> 23:38.000]  вот эта вероятность не большая,
[23:38.000 --> 23:41.000]  чем дисперсия х
[23:41.000 --> 23:44.000]  поделенная на а в квадрате.
[23:49.000 --> 23:52.000]  Я утверждаю, что это очевидное следствие
[23:52.000 --> 23:55.000]  неравенства марков.
[23:55.000 --> 23:58.000]  Давайте рассмотрим такую случайную величину,
[23:58.000 --> 24:01.000]  пусть у, например, это будет х
[24:01.000 --> 24:04.000]  минус ех
[24:04.000 --> 24:07.000]  квадрате.
[24:07.000 --> 24:10.000]  Согласитесь,
[24:10.000 --> 24:13.000]  эта случайная величина
[24:13.000 --> 24:16.000]  принимает не отрицательные значения,
[24:16.000 --> 24:19.000]  потому что является полным квадратом.
[24:19.000 --> 24:22.000]  То есть к ней можно применить
[24:22.000 --> 24:25.000]  неравенство маркова.
[24:25.000 --> 24:28.000]  Давайте так применим.
[24:28.000 --> 24:31.000]  Игре больше не бы равняется а в квадрате,
[24:31.000 --> 24:34.000]  а вот это, которое в чебышу.
[24:37.000 --> 24:40.000]  Ну, это же в точности тоже самое, правда?
[24:40.000 --> 24:43.000]  Как корень извлекается в неравенстве слева,
[24:43.000 --> 24:46.000]  появляется модуль,
[24:46.000 --> 24:49.000]  а справа то самое а, которое было положено.
[24:49.000 --> 24:52.000]  Нормально?
[24:52.000 --> 24:55.000]  А чего это не превосходит,
[24:55.000 --> 24:58.000]  согласно неравенству маркова?
[24:58.000 --> 25:01.000]  Это не превосходит ей
[25:01.000 --> 25:04.000]  поделить на а в квадрате,
[25:05.000 --> 25:08.000]  но что такое ей?
[25:08.000 --> 25:11.000]  Это в точности дисперсии.
[25:11.000 --> 25:14.000]  Все.
[25:14.000 --> 25:17.000]  Надеюсь, это не было сложным прогоном.
[25:19.000 --> 25:22.000]  Очевидное следствие из неравенства маркова
[25:22.000 --> 25:25.000]  это вот такой формат неравенства чебышова.
[25:27.000 --> 25:30.000]  Но можно, конечно, говорить первое неравенство
[25:30.000 --> 25:33.000]  чебышова, второе неравенство чебышова.
[25:33.000 --> 25:36.000]  Послушайте меня сейчас внимательно,
[25:36.000 --> 25:39.000]  это очень важный момент.
[25:39.000 --> 25:42.000]  Хотя неравенство чебышова
[25:42.000 --> 25:45.000]  является следствием из неравенства маркова,
[25:45.000 --> 25:48.000]  вот здесь в таких теоремах,
[25:48.000 --> 25:51.000]  которые возникают в теории графа,
[25:51.000 --> 25:54.000]  они друг друга дополняют.
[25:54.000 --> 25:57.000]  А именно первый пункт мы будем доказывать
[25:57.000 --> 26:00.000]  с помощью неравенства маркова,
[26:00.000 --> 26:03.000]  с помощью неравенства чебышова.
[26:03.000 --> 26:06.000]  То есть в комбинаторике,
[26:06.000 --> 26:09.000]  ну я не знаю как, можете себе это пометить,
[26:09.000 --> 26:12.000]  можете просто послушать, вы увидите это потом.
[26:12.000 --> 26:15.000]  В комбинаторике неравенство маркова отвечает за то,
[26:15.000 --> 26:18.000]  что чего-то почти наверняка нет.
[26:18.000 --> 26:21.000]  А неравенство чебышова,
[26:21.000 --> 26:24.000]  что нечто почти наверняка есть.
[26:24.000 --> 26:27.000]  Но можно это на слуху воспринять,
[26:27.000 --> 26:30.000]  объясню это уже на конкретных примерах.
[26:33.000 --> 26:36.000]  Так, живые все.
[26:40.000 --> 26:43.000]  Давайте я, наверное, тогда
[26:43.000 --> 26:46.000]  вас не томить,
[26:46.000 --> 26:49.000]  под эту теорему начну доказать.
[26:49.000 --> 26:52.000]  У нас все инструменты готовы.
[26:52.000 --> 26:55.000]  Так.
[26:55.000 --> 26:58.000]  Ого.
[26:58.000 --> 27:01.000]  Ну готовы они, конечно, готовы,
[27:01.000 --> 27:04.000]  только что-то они много места занимают.
[27:04.000 --> 27:07.000]  Знаете, почему?
[27:07.000 --> 27:10.000]  Технически чуть более просто доказать пункт номер два.
[27:10.000 --> 27:13.000]  Поэтому я с него начну.
[27:13.000 --> 27:16.000]  Вы будете смеяться или плакать,
[27:16.000 --> 27:19.000]  но сложность техники пункта номер один
[27:19.000 --> 27:22.000]  будет состоять в том,
[27:22.000 --> 27:25.000]  что там будет сумма,
[27:25.000 --> 27:28.000]  и ее придется виноват разбивать на две части.
[27:28.000 --> 27:31.000]  Опять?
[27:31.000 --> 27:34.000]  Нет, хуже!
[27:34.000 --> 27:37.000]  Еще хуже.
[27:49.000 --> 27:52.000]  Слушайте, давайте вот как сделаем.
[27:52.000 --> 27:55.000]  Можно я даже сначала
[27:55.000 --> 27:58.000]  попробую неформально объяснить,
[27:58.000 --> 28:01.000]  откуда пошла вот эта функция.
[28:01.000 --> 28:04.000]  А потом уже буду аккуратно все доказывать.
[28:04.000 --> 28:07.000]  Мне кажется, так будет лучше.
[28:07.000 --> 28:10.000]  Вот сейчас можете ничего не записывать,
[28:10.000 --> 28:13.000]  просто послушать,
[28:13.000 --> 28:16.000]  потом я все равно аккуратно все напишу.
[28:17.000 --> 28:20.000]  Давайте обозначим через х.
[28:20.000 --> 28:23.000]  Хотите запишите, как вам удобно.
[28:23.000 --> 28:26.000]  Это пригодится.
[28:26.000 --> 28:29.000]  Случайную величину на множестве графов,
[28:29.000 --> 28:32.000]  которая принимает значение,
[28:32.000 --> 28:35.000]  равное количеству
[28:35.000 --> 28:38.000]  изолированных вершин
[28:38.000 --> 28:41.000]  в этом графе же.
[28:41.000 --> 28:44.000]  Ну, изолированная вершина,
[28:44.000 --> 28:47.000]  иными словами, это вершина степени ноль.
[28:47.000 --> 28:50.000]  То есть просто отдельно стоящая вершина,
[28:50.000 --> 28:53.000]  которая не примыкает, не является вершиной
[28:53.000 --> 28:56.000]  никакого ребра.
[28:56.000 --> 28:59.000]  Вот бывают такие вершины в граф, да?
[28:59.000 --> 29:02.000]  Ну, бывает.
[29:02.000 --> 29:05.000]  Пришла на лекцию к Андрею Михайловичу
[29:05.000 --> 29:08.000]  куча народов,
[29:08.000 --> 29:11.000]  и есть в этой куче один человек,
[29:11.000 --> 29:14.000]  изолированная вершина графа знакомства.
[29:14.000 --> 29:17.000]  Ну и так далее.
[29:17.000 --> 29:20.000]  Наверное, мне надо еще чуть-чуть назад
[29:20.000 --> 29:23.000]  отмотать, знаете, зачем я вел такую величину?
[29:23.000 --> 29:26.000]  Чисто интуитивно.
[29:26.000 --> 29:29.000]  Смотрите, у нас вопрос о том, связи в графе или нет.
[29:29.000 --> 29:32.000]  Вот давайте подумаем.
[29:32.000 --> 29:35.000]  Друзья, давайте подумаем вместе прямо подумаем.
[29:35.000 --> 29:38.000]  Если связи разрушаются независимо
[29:38.000 --> 29:41.000]  с одной и той же вероятностью,
[29:41.000 --> 29:44.000]  скорее всего граф разломится пополам
[29:44.000 --> 29:47.000]  или от него отскочит какая-нибудь компонента
[29:47.000 --> 29:50.000]  не знаю, логарифмического размера по числу вершин
[29:50.000 --> 29:53.000]  или от него просто отвалится изолированная вершина одна.
[29:53.000 --> 29:56.000]  Что более вероятно?
[29:56.000 --> 29:59.000]  Что легче сделать? Разломать граф на две компоненты
[29:59.000 --> 30:02.000]  размером пополам или отчепить от него изолированную вершину?
[30:02.000 --> 30:05.000]  Очевидно что второе?
[30:05.000 --> 30:08.000]  Или не очевидно?
[30:08.000 --> 30:11.000]  Сейчас, друзья, вот смотрите, вот был граф,
[30:11.000 --> 30:14.000]  у него N вершины.
[30:14.000 --> 30:17.000]  Так, сколько здесь 6?
[30:17.000 --> 30:20.000]  Расломать его вот на два таких куска изолированных,
[30:20.000 --> 30:23.000]  это значит у какого-то 9 ребят.
[30:23.000 --> 30:26.000]  А оторвать одну вершину,
[30:26.000 --> 30:29.000]  это у какого-то всего 5 ребят.
[30:29.000 --> 30:32.000]  И в общем случае, если у вас тут N пополам
[30:32.000 --> 30:35.000]  то купить все связи между ними
[30:35.000 --> 30:38.000]  это надо вклокнуть
[30:38.000 --> 30:41.000]  N в квадрате на 4 ребра.
[30:41.000 --> 30:44.000]  Я понятно говорил или нет?
[30:44.000 --> 30:47.000]  А отвалилась одна вершинка,
[30:47.000 --> 30:50.000]  это только N минус одно ребро.
[30:50.000 --> 30:53.000]  Пока давлю только на интуицию.
[30:53.000 --> 30:56.000]  Только на интуицию, больше ничего.
[30:56.000 --> 30:59.000]  Поэтому раз легче всего отчипывать изолированную вершину,
[30:59.000 --> 31:02.000]  вот давайте рассмотрим количество изолированных вершин.
[31:11.000 --> 31:14.000]  Вопрос на то, как вы поняли
[31:14.000 --> 31:17.000]  инейность математического ожидания.
[31:17.000 --> 31:20.000]  Ну скажите мне, чему равно Eх?
[31:20.000 --> 31:23.000]  Кто может сходу?
[31:23.000 --> 31:26.000]  Сумма от ожиданий, то вот бы каждый конкретный вершин.
[31:26.000 --> 31:29.000]  Ну ответ.
[31:29.000 --> 31:32.000]  Правильная сумма.
[31:32.000 --> 31:35.000]  Давайте, раз это вызывает уже такие вопросы.
[31:35.000 --> 31:38.000]  Правильно-правильно, это важно написать.
[31:38.000 --> 31:41.000]  Давайте напишем вот так.
[31:41.000 --> 31:44.000]  x1, плюс и так далее, плюс xn,
[31:44.000 --> 31:47.000]  dx и da, g.
[31:47.000 --> 31:50.000]  Это как в прошлый раз индикатор.
[31:50.000 --> 31:53.000]  То есть единица,
[31:53.000 --> 31:56.000]  и изолированная вершина.
[31:56.000 --> 31:59.000]  И ноль иначе.
[32:05.000 --> 32:08.000]  N множество 1 минус 1.
[32:14.000 --> 32:17.000]  Почему? Ещё раз.
[32:17.000 --> 32:20.000]  Потому что мы складываем N одинаково к слагаемому.
[32:20.000 --> 32:23.000]  А мат ожидания одного, любого из них,
[32:23.000 --> 32:26.000]  это вероятность того, что E изолировалось.
[32:26.000 --> 32:29.000]  То есть пропали N минус 1.
[32:31.000 --> 32:34.000]  Надо писать подробнее.
[32:34.000 --> 32:37.000]  Ну вот вершинка E.
[32:37.000 --> 32:40.000]  Вот остальные.
[32:40.000 --> 32:43.000]  Изначально было N минус 1 ребро.
[32:43.000 --> 32:46.000]  Мат ожидания индикатора
[32:46.000 --> 32:49.000]  это 1 умножить на вероятность.
[32:50.000 --> 32:53.000]  То есть это вероятность вот этого события.
[32:53.000 --> 32:56.000]  Ну а какая вероятность,
[32:56.000 --> 32:59.000]  что пропали все вот эти N минус 1 ребро?
[32:59.000 --> 33:02.000]  Вот ровно такая.
[33:02.000 --> 33:05.000]  Что, гоним, что ли?
[33:05.000 --> 33:08.000]  Так, друзья, поднимите, пожалуйста,
[33:08.000 --> 33:11.000]  чтобы кто сейчас понимает, что происходит.
[33:11.000 --> 33:14.000]  Сейчас будет
[33:14.000 --> 33:17.000]  махонький такой аналитический катарсис.
[33:17.000 --> 33:20.000]  Смотрите.
[33:20.000 --> 33:23.000]  N я оставлю.
[33:23.000 --> 33:26.000]  А тут напишу в любимом стиле.
[33:26.000 --> 33:29.000]  Что такое 1 минус P?
[33:29.000 --> 33:32.000]  Это E в степени логарифм от 1 минус P.
[33:32.000 --> 33:35.000]  Так, N минус 1 я нанесу.
[33:35.000 --> 33:38.000]  А тут будет логарифм от 1 минус P.
[33:38.000 --> 33:41.000]  Ну, мы уже знаем с вами,
[33:41.000 --> 33:44.000]  что P стрелится к дулю.
[33:45.000 --> 33:48.000]  Но в общем это можно и так сообразить,
[33:48.000 --> 33:51.000]  что, наверное, оно будет стремиться к нулю.
[33:51.000 --> 33:54.000]  То есть если бы мы не знали ответ,
[33:54.000 --> 33:57.000]  все равно пусть оно стремится к нулю.
[33:57.000 --> 34:00.000]  Тогда что у нас тут получается?
[34:00.000 --> 34:03.000]  N на E в степени вот так.
[34:03.000 --> 34:06.000]  1 плюс 1 минус.
[34:06.000 --> 34:09.000]  И тут N.
[34:09.000 --> 34:12.000]  Я написал просто, что логарифм от 1 минус P
[34:12.000 --> 34:15.000]  асимпатически равен минус P.
[34:15.000 --> 34:18.000]  Даже не пишу никакого ряда Тейлора,
[34:18.000 --> 34:21.000]  только вот первое из логарифм.
[34:21.000 --> 34:24.000]  Логарифм это минус P с точностью до
[34:24.000 --> 34:27.000]  стремящегося единицы со множителя.
[34:27.000 --> 34:30.000]  Ну, и N минус 1 точно так же
[34:30.000 --> 34:33.000]  асимпатически поменял на это.
[34:33.000 --> 34:36.000]  Все вас надели?
[34:36.000 --> 34:39.000]  Сейчас будет катарсис, смотрите.
[34:39.000 --> 34:42.000]  Вместо P то, что написано там в теории.
[34:45.000 --> 34:48.000]  N на E в степени минус.
[34:48.000 --> 34:51.000]  1 плюс 1, 5.
[34:51.000 --> 34:54.000]  N я могу умножить на P сразу.
[34:57.000 --> 35:00.000]  Так, понимаете, что будет целый логарифм?
[35:04.000 --> 35:07.000]  Нормально, да?
[35:07.000 --> 35:10.000]  Вот этим N.
[35:10.000 --> 35:13.000]  Так, E в степени логарифм N это что?
[35:13.000 --> 35:16.000]  N, правильно.
[35:16.000 --> 35:19.000]  И тут N. Давайте напишем вот так.
[35:19.000 --> 35:22.000]  N в первой степени.
[35:22.000 --> 35:25.000]  Минус 1 плюс малая от единицы.
[35:25.000 --> 35:28.000]  Вот это.
[35:28.000 --> 35:31.000]  Умножить на C.
[35:31.000 --> 35:34.000]  Ха-ха.
[35:34.000 --> 35:37.000]  Понимаете, если C больше единицы,
[35:37.000 --> 35:40.000]  то это стремится к нулю.
[35:40.000 --> 35:43.000]  А если C меньше единицы, то это стремится к бесконечности.
[35:46.000 --> 35:49.000]  Формально говоря, из этого пока, к сожалению,
[35:49.000 --> 35:52.000]  ничего не следует.
[35:52.000 --> 35:55.000]  Но интуиция, понятно, да?
[35:55.000 --> 35:58.000]  Если C больше единицы, то как минимум
[35:58.000 --> 36:01.000]  мало изолированных вершин.
[36:01.000 --> 36:04.000]  Если C больше единицы, то, наверное, их будет много.
[36:04.000 --> 36:07.000]  Правда, почему? Это еще тоже вопрос.
[36:07.000 --> 36:10.000]  Ну, все-таки к бесконечности стремится мата ожидания.
[36:13.000 --> 36:16.000]  Сейчас, друзья, вы поняли, да, какое здесь переключение?
[36:16.000 --> 36:19.000]  Все, вот теперь я формулизую.
[36:19.000 --> 36:22.000]  Знаете, прежде чем я формулизую, еще...
[36:22.000 --> 36:25.000]  Проблема-то в чем?
[36:25.000 --> 36:28.000]  Вот вы еще мало имели дело с мата ожиданиями,
[36:28.000 --> 36:31.000]  с случайными величинами и так далее.
[36:31.000 --> 36:34.000]  Послушайте, послушайте, это больно.
[36:34.000 --> 36:37.000]  Вот, например, мата ожидания стремится к бесконечности.
[36:37.000 --> 36:40.000]  Следует ли из этого,
[36:40.000 --> 36:43.000]  что почти наверняка случайная величина
[36:43.000 --> 36:46.000]  принимает большое значение?
[36:46.000 --> 36:49.000]  Нет, конечно.
[36:49.000 --> 36:52.000]  Потому что представьте себе, что половина значений
[36:52.000 --> 36:55.000]  случайной величины ноль,
[36:55.000 --> 36:58.000]  а половина все больше и больше.
[36:58.000 --> 37:01.000]  Мата ожидания будет стремиться к бесконечности,
[37:01.000 --> 37:04.000]  а доля значений, которые большие,
[37:04.000 --> 37:07.000]  будет все время одна втора.
[37:07.000 --> 37:10.000]  Понятно сказал, нет?
[37:10.000 --> 37:13.000]  То есть просто из стремления к бесконечности
[37:13.000 --> 37:16.000]  мата ожидания, конечно, ничего не следует.
[37:16.000 --> 37:19.000]  Еще раз повторяю, это только интуиция,
[37:19.000 --> 37:22.000]  откуда взялся базовый переход.
[37:22.000 --> 37:25.000]  Был катарсис, а теперь начнется уука.
[37:25.000 --> 37:28.000]  Так, уука.
[37:28.000 --> 37:31.000]  Мне еще не нравится, что Чебышова панит.
[37:31.000 --> 37:34.000]  История.
[37:34.000 --> 37:37.000]  Где же мне писать?
[37:37.000 --> 37:40.000]  Так хочу в мертвый угол пойти, знаете,
[37:40.000 --> 37:43.000]  прям подмывать.
[37:43.000 --> 37:46.000]  Походишь мне.
[37:46.000 --> 37:49.000]  Ну ладно.
[37:49.000 --> 37:52.000]  Сюда пойду.
[38:04.000 --> 38:07.000]  Строго доказываем пункт 2 теории.
[38:07.000 --> 38:10.000]  Сейчас будем строго доказывать пункт 2.
[38:10.000 --> 38:13.000]  Кажется, меня прервет звонок,
[38:13.000 --> 38:16.000]  но давайте я еще раз напишу,
[38:17.000 --> 38:20.000]  с которыми мы разобрались.
[38:20.000 --> 38:23.000]  Мы уже знаем, что мата ожидания х
[38:23.000 --> 38:26.000]  это n на 1 минус 1,
[38:26.000 --> 38:29.000]  и мы знаем, что в рамках 2 пункта
[38:29.000 --> 38:32.000]  это стремится к плюс бесконечности,
[38:32.000 --> 38:35.000]  потому что c меньше единицы.
[38:35.000 --> 38:38.000]  Мы находимся во 2 пункте теории.
[38:38.000 --> 38:41.000]  Так, теперь смотрите.
[38:41.000 --> 38:44.000]  Мы что хотим доказать?
[38:44.000 --> 38:47.000]  Что граф не связан
[38:47.000 --> 38:50.000]  с вероятностью стремящейся к единице.
[38:50.000 --> 38:53.000]  Все ж помнят, да, pn это значит
[38:53.000 --> 38:56.000]  вероятность стремиться к единице.
[38:56.000 --> 38:59.000]  Граф не связан.
[38:59.000 --> 39:02.000]  Но если в графе будет хоть одна изолированная вершина,
[39:02.000 --> 39:05.000]  из этого же будет следовать, что он не связан,
[39:05.000 --> 39:08.000]  но это та самая интуиция, с которой мы стартовали.
[39:08.000 --> 39:11.000]  Давайте напишем вероятность того,
[39:11.000 --> 39:14.000]  что это единица.
[39:14.000 --> 39:17.000]  Мы хотим доказать,
[39:17.000 --> 39:20.000]  что эта вероятность стремится к 1.
[39:20.000 --> 39:23.000]  Если мы это докажем, пункт 2 у нас в кармане.
[39:23.000 --> 39:26.000]  Согласны?
[39:26.000 --> 39:29.000]  Вспели за мыслью?
[39:29.000 --> 39:32.000]  Так, конечно, первое,
[39:32.000 --> 39:35.000]  что хочется сделать, это применить
[39:35.000 --> 39:38.000]  правительство Маркова, но, к сожалению,
[39:38.000 --> 39:41.000]  так.
[39:41.000 --> 39:44.000]  А нам-то нужно доказывать стремление к единице.
[39:44.000 --> 39:47.000]  Нам нужно неравенство в другую сторону, понимаете?
[39:47.000 --> 39:50.000]  Перерыв 5 минут.
[39:50.000 --> 39:53.000]  Так, возвращаемся в строй.
[39:53.000 --> 39:56.000]  Нам нужно это оценить снизу.
[39:56.000 --> 39:59.000]  Сейчас сделаем фокус, который подгонит нас
[39:59.000 --> 40:02.000]  под неравенство Чебышова.
[40:02.000 --> 40:05.000]  Ну, конечно, я могу сразу написать ответ,
[40:05.000 --> 40:08.000]  но занудствовать.
[40:08.000 --> 40:11.000]  Я пишу вот так.
[40:11.000 --> 40:14.000]  Это равно...
[40:14.000 --> 40:17.000]  Так, товарищи, понятно,
[40:17.000 --> 40:20.000]  почему верен такой переход?
[40:20.000 --> 40:23.000]  Это называется вероятность отрицания равна единице
[40:23.000 --> 40:26.000]  минус вероятность события.
[40:29.000 --> 40:32.000]  Что должно быть?
[40:32.000 --> 40:35.000]  Меньше строго, чем один,
[40:35.000 --> 40:38.000]  но Х принимает только целые значения.
[40:38.000 --> 40:41.000]  Ну да, товарищи,
[40:41.000 --> 40:44.000]  я могу здесь равно написать.
[40:44.000 --> 40:47.000]  Это будет то же самое.
[40:47.000 --> 40:50.000]  Все понимают, Даша, если я напишу равно, так будет то же самое.
[40:50.000 --> 40:53.000]  А я не хочу. Мне так нравится.
[40:53.000 --> 40:56.000]  Но я хочу подогнать подгиб неравенства Чебышова,
[40:56.000 --> 40:59.000]  поэтому я вот так пишу, хотя вот право
[40:59.000 --> 41:02.000]  написать точное равенство.
[41:02.000 --> 41:05.000]  Дальше. Продолжаю издеваться.
[41:05.000 --> 41:08.000]  Минус Х больше либо равен нуля.
[41:11.000 --> 41:14.000]  Я умножу лево-справо на минус один.
[41:18.000 --> 41:21.000]  Один минус вероятность
[41:21.000 --> 41:24.000]  ех минус х
[41:24.000 --> 41:27.000]  больше либо равно ех.
[41:27.000 --> 41:30.000]  Но это я добавил константу равную мат ожидания
[41:30.000 --> 41:33.000]  лево-справу.
[41:35.000 --> 41:38.000]  Так, а вот теперь я пишу
[41:38.000 --> 41:41.000]  неравенство в нужную сторону.
[41:41.000 --> 41:44.000]  Один минус вероятность того, что модуль
[41:44.000 --> 41:47.000]  х минус ех
[41:47.000 --> 41:50.000]  больше либо равняется ех.
[41:53.000 --> 41:56.000]  Ну, почему это так?
[41:56.000 --> 41:59.000]  Потому что вот эта вероятность
[41:59.000 --> 42:02.000]  принимает большое значение,
[42:02.000 --> 42:05.000]  уж точно не реже, чем это делает
[42:05.000 --> 42:08.000]  исходная величина.
[42:08.000 --> 42:11.000]  Не реже. То есть вот эта вычитаемая вероятность,
[42:11.000 --> 42:14.000]  она скорее всего больше,
[42:14.000 --> 42:17.000]  чем вот эта вычитаемая.
[42:17.000 --> 42:20.000]  Ну, поэтому неравенство в нужную сторону.
[42:20.000 --> 42:23.000]  Вот здесь вычитается скорее всего больше,
[42:23.000 --> 42:26.000]  чем правое.
[42:29.000 --> 42:32.000]  Так, неравенство Чебышова
[42:32.000 --> 42:35.000]  применяется вот сюда.
[42:35.000 --> 42:38.000]  Оно про то, что это не больше чего-то,
[42:38.000 --> 42:41.000]  но оно же идет со знаком минус,
[42:41.000 --> 42:44.000]  поэтому мы продолжаем именно в ту сторону,
[42:44.000 --> 42:47.000]  в которую нам надо.
[42:47.000 --> 42:50.000]  Больше либо равно, чем один
[42:50.000 --> 42:53.000]  плюс дисперсия х
[42:53.000 --> 42:56.000]  поделить
[42:56.000 --> 42:59.000]  на квадрат мат ожидания.
[43:02.000 --> 43:05.000]  Смотрите, мы знаем, что мат ожидания
[43:05.000 --> 43:08.000]  стремится к бесконечности, это обязательное условие,
[43:08.000 --> 43:11.000]  но мы не знаем, почему бы вот эта дробь стремилась к нулю.
[43:11.000 --> 43:14.000]  Вот если она стремится к нулю,
[43:14.000 --> 43:17.000]  если она стремится к нулю,
[43:17.000 --> 43:20.000]  то мы, конечно, получим стремление к единице,
[43:20.000 --> 43:23.000]  которое нам нужно.
[43:23.000 --> 43:26.000]  Так, а вы помните, что мы хотим, чтобы это стремилось к единице, да, ведь?
[43:26.000 --> 43:29.000]  Вот нам для этого достаточно и, в общем, необходимо,
[43:29.000 --> 43:32.000]  чтобы обведенная штука стремилась к нулю.
[43:32.000 --> 43:35.000]  Очень хорошо, что знаменатель стремится к бесконечности,
[43:35.000 --> 43:38.000]  но вдруг дисперсия еще быстрее.
[43:38.000 --> 43:41.000]  Это вот то, о чем я говорил.
[43:41.000 --> 43:44.000]  Если разброс относительно среднего очень большой,
[43:44.000 --> 43:47.000]  то стремление к бесконечности, вообще говоря,
[43:47.000 --> 43:50.000]  еще ничего не означает.
[43:52.000 --> 43:55.000]  Ну, давайте считать дисперсию.
[43:56.000 --> 43:59.000]  Так.
[44:06.000 --> 44:09.000]  Помните?
[44:09.000 --> 44:12.000]  Я еще не успел это стереть.
[44:12.000 --> 44:15.000]  Дисперс x равняется второму моменту
[44:15.000 --> 44:18.000]  минус квадрат математического ожидания.
[44:21.000 --> 44:24.000]  Ну, квадрат мат ожидания,
[44:24.000 --> 44:27.000]  по-моему, понятно, чему равен.
[44:27.000 --> 44:30.000]  Да?
[44:30.000 --> 44:33.000]  Давайте только второй момент посчитаем,
[44:33.000 --> 44:36.000]  ну а потом подставим все, конечно.
[44:42.000 --> 44:45.000]  Так.
[44:46.000 --> 44:49.000]  Ну, друзья, мы же помним, что x это сумма,
[44:49.000 --> 44:52.000]  x1 и так далее, xn.
[44:52.000 --> 44:55.000]  Давайте так и напишем.
[44:55.000 --> 44:58.000]  x1, так далее, xn,
[44:58.000 --> 45:01.000]  все это в квадрате.
[45:01.000 --> 45:04.000]  Ну, давайте так и напишем.
[45:04.000 --> 45:07.000]  x1, так далее, xn,
[45:07.000 --> 45:10.000]  все это в квадрате.
[45:10.000 --> 45:13.000]  Умеете возводить квадрат сумму
[45:13.000 --> 45:16.000]  многих слагаемых?
[45:16.000 --> 45:19.000]  Но тут очень простые полинамиальные коэффициенты,
[45:19.000 --> 45:22.000]  они все равны двойке или единице, да?
[45:22.000 --> 45:25.000]  Это равно
[45:25.000 --> 45:28.000]  x1 квадрат,
[45:28.000 --> 45:31.000]  что так далее, плюс xn в квадрате,
[45:31.000 --> 45:34.000]  а дальше я вот так напишу.
[45:34.000 --> 45:37.000]  Сумма по i не равно j,
[45:37.000 --> 45:40.000]  xt умножить на xjt.
[45:43.000 --> 45:46.000]  Ну да, как бы удвоенное,
[45:46.000 --> 45:49.000]  но, друзья, я буду считать,
[45:49.000 --> 45:52.000]  что и j и j и суть разные вещи,
[45:52.000 --> 45:55.000]  тогда не надо удвоивать.
[45:55.000 --> 45:58.000]  То есть тут отдельно присутствует
[45:58.000 --> 46:01.000]  x1 умножить на x2 и x2 умножить на xjt.
[46:01.000 --> 46:04.000]  Упорядоченные слагаемые,
[46:05.000 --> 46:08.000]  а так, да, конечно,
[46:08.000 --> 46:11.000]  xn2, если приводить подобные.
[46:11.000 --> 46:14.000]  Так, это я еще раз напишу,
[46:14.000 --> 46:17.000]  это единица или ноль,
[46:17.000 --> 46:20.000]  вот если
[46:20.000 --> 46:23.000]  и изолированная,
[46:23.000 --> 46:26.000]  а тут если, ну иначе надо было написать,
[46:26.000 --> 46:29.000]  если i не является изолированной.
[46:29.000 --> 46:32.000]  Изолированной.
[46:32.000 --> 46:35.000]  Дорогие товарищи,
[46:35.000 --> 46:38.000]  что такое xt в квадрате?
[46:38.000 --> 46:41.000]  Это xt,
[46:41.000 --> 46:44.000]  1 в квадрате это 1,
[46:44.000 --> 46:47.000]  0 в квадрате это 0.
[46:47.000 --> 46:50.000]  Я вот так вот, можно сделать?
[46:50.000 --> 46:53.000]  Ну какая разница возводить квадрат
[46:53.000 --> 46:56.000]  и не возводить значение?
[46:57.000 --> 47:00.000]  Равно.
[47:00.000 --> 47:03.000]  Линейность применяем.
[47:03.000 --> 47:06.000]  Слушайте, ну вот эта часть чему равна?
[47:06.000 --> 47:09.000]  Конечно, вот этому, правильно?
[47:09.000 --> 47:12.000]  Давайте я так и напишу,
[47:12.000 --> 47:15.000]  ex.
[47:15.000 --> 47:18.000]  Мы знаем, чему равняется ex,
[47:18.000 --> 47:21.000]  но вот я вот эту часть напишу просто как ex.
[47:21.000 --> 47:24.000]  Так, дальше будет сумма
[47:24.000 --> 47:27.000]  по i неравном g,
[47:30.000 --> 47:33.000]  мат ожиданий вот этих произведений.
[47:33.000 --> 47:36.000]  Теперь давайте просто сообразим,
[47:36.000 --> 47:39.000]  а произведение, по сути, это что такое?
[47:39.000 --> 47:42.000]  Оно тоже равно единице или нулю, правда?
[47:42.000 --> 47:45.000]  Единицы если обе вершины
[47:45.000 --> 47:48.000]  изолированы и ноль иначе.
[47:48.000 --> 47:51.000]  Смотрите, вот это вот
[47:51.000 --> 47:54.000]  равно единице,
[47:54.000 --> 47:57.000]  если обе вершины и ежи
[47:57.000 --> 48:00.000]  изолированы,
[48:00.000 --> 48:03.000]  ну и ноль, если хотя бы одна из них
[48:03.000 --> 48:06.000]  таковой не является.
[48:06.000 --> 48:09.000]  То есть чему равно мат ожидания?
[48:09.000 --> 48:12.000]  Давайте я картинку нарисую, вот тут.
[48:12.000 --> 48:15.000]  Две вершины и ежи.
[48:15.000 --> 48:18.000]  И еще есть
[48:18.000 --> 48:21.000]  н-2 оставшихся.
[48:21.000 --> 48:24.000]  Так, все понимают, что такое н-2 оставшихся, да?
[48:24.000 --> 48:27.000]  Вот что значит и ежи изолированы?
[48:27.000 --> 48:30.000]  Это значит отсутствуют
[48:30.000 --> 48:33.000]  и н-2 ребра, да?
[48:33.000 --> 48:36.000]  Такие н-2.
[48:36.000 --> 48:39.000]  И еще вот это.
[48:39.000 --> 48:42.000]  Сколько суммарно? Дважды н-2 плюс один.
[48:42.000 --> 48:45.000]  Два н-3.
[48:45.000 --> 48:48.000]  Хорошо в уме считаете, молодцы.
[48:48.000 --> 48:51.000]  То есть чему равно это мат ожидания?
[48:51.000 --> 48:54.000]  Оно равно 1-p
[48:54.000 --> 48:57.000]  в степени 2n-3.
[48:57.000 --> 49:00.000]  Ну а общее значение получается вот такое.
[49:00.000 --> 49:03.000]  Это мат ожидания х я переписал.
[49:03.000 --> 49:06.000]  Слагаем их n умножить на n-1,
[49:06.000 --> 49:09.000]  а это н по 2, потому что они упорядоченные.
[49:09.000 --> 49:12.000]  И на 1-p
[49:12.000 --> 49:15.000]  и на 1-p
[49:15.000 --> 49:18.000]  в 2н-3.
[49:18.000 --> 49:21.000]  Ну и все, сейчас у нас получится стремление к нулю.
[49:21.000 --> 49:24.000]  Сейчас я напишу я.
[49:24.000 --> 49:27.000]  Да, друзья, знаете, чего я забыл сказать?
[49:27.000 --> 49:30.000]  Все логично, все правильно, никаких ошибок нет.
[49:30.000 --> 49:33.000]  Я забыл сделать важное замечание.
[49:33.000 --> 49:36.000]  Не относящееся к доказательству,
[49:36.000 --> 49:39.000]  относящееся просто к сути процессора.
[49:39.000 --> 49:42.000]  Вероятность того, что х больше либо равно 1,
[49:42.000 --> 49:45.000]  не меньше чем 1 минус вот эта дробь.
[49:45.000 --> 49:48.000]  Вдумайтесь,
[49:48.000 --> 49:51.000]  мы где-то использовали то, что х
[49:51.000 --> 49:54.000]  это именно количество изолированных вершин.
[49:57.000 --> 50:00.000]  Что мы использовали?
[50:00.000 --> 50:03.000]  Единственное, что мы использовали,
[50:03.000 --> 50:06.000]  это что х принимает целые значения, больше ничего.
[50:06.000 --> 50:09.000]  Понимаете?
[50:09.000 --> 50:12.000]  Вот здесь.
[50:12.000 --> 50:15.000]  Когда отрицанием того, что х больше либо равняется 1,
[50:15.000 --> 50:18.000]  оказалось то, что х не больше нуля.
[50:18.000 --> 50:21.000]  То есть вот такое вот
[50:21.000 --> 50:24.000]  неравенство,
[50:24.000 --> 50:27.000]  оно верно для любой случайной величины
[50:27.000 --> 50:30.000]  принимающей целые значения.
[50:30.000 --> 50:33.000]  Например, для числа треугольников.
[50:33.000 --> 50:36.000]  Помните про число треугольников?
[50:36.000 --> 50:39.000]  Ну вы не решали это, Дом, вы забыли.
[50:39.000 --> 50:42.000]  Ну число треугольников.
[50:42.000 --> 50:45.000]  Вот это просто вам по жизни, чтобы вы понимали,
[50:45.000 --> 50:48.000]  это удобное неравенство, которое можно использовать
[50:48.000 --> 50:51.000]  для решения разных задач.
[50:51.000 --> 50:54.000]  Так, возвращаюсь к подсчету.
[50:54.000 --> 50:57.000]  Давайте теперь я это рассуждение сотру.
[50:57.000 --> 51:00.000]  Так, пишем дисперсия,
[51:00.000 --> 51:03.000]  и х поделить на квадрат
[51:03.000 --> 51:06.000]  математического ожидания.
[51:06.000 --> 51:09.000]  Равняется ех
[51:09.000 --> 51:12.000]  плюс n,
[51:12.000 --> 51:15.000]  n минус 1,
[51:15.000 --> 51:18.000]  на 1 минус п в 2, n минус 3.
[51:18.000 --> 51:21.000]  А видите, как я длинно нарисовал?
[51:21.000 --> 51:24.000]  Знаете почему?
[51:24.000 --> 51:27.000]  Кто догадывается, почему я такую длинную дробь нарисовал?
[51:27.000 --> 51:30.000]  Нет,
[51:30.000 --> 51:33.000]  потому что это не дисперсия,
[51:33.000 --> 51:36.000]  а это, товарищи, второй момент.
[51:36.000 --> 51:39.000]  Чтобы получилась дисперсия,
[51:39.000 --> 51:42.000]  надо еще вот здесь
[51:42.000 --> 51:45.000]  вычислить знаменатель.
[51:45.000 --> 51:48.000]  Вот это уже будет действительно дисперсия в числителе.
[51:48.000 --> 51:51.000]  Ну а знаменатель, знаменатель-то что?
[51:51.000 --> 51:54.000]  Вот он знаменатель, все.
[51:54.000 --> 51:57.000]  Он не длинный, он короткий.
[52:00.000 --> 52:03.000]  Так, смотрите.
[52:03.000 --> 52:06.000]  Во-первых,
[52:06.000 --> 52:09.000]  имеем дробь 1 поделить на ех,
[52:09.000 --> 52:12.000]  но ех стремится к плюсу бесконечно,
[52:12.000 --> 52:15.000]  поэтому эта дробь стремится к нулю.
[52:15.000 --> 52:18.000]  Какая удача, уже кое-что стремится к нулю.
[52:18.000 --> 52:21.000]  Но нам надо, чтобы все стремилось к нулю.
[52:21.000 --> 52:24.000]  Вот, смотрите, там вот это.
[52:24.000 --> 52:27.000]  Так, прибавить.
[52:27.000 --> 52:30.000]  Так, n, n-1,
[52:30.000 --> 52:33.000]  1-p,
[52:33.000 --> 52:36.000]  2n-3, это я просто переписал,
[52:36.000 --> 52:39.000]  и в знаменатель ставлю
[52:39.000 --> 52:42.000]  квадрат математического ожидания.
[52:42.000 --> 52:45.000]  Прям явно его пишу.
[52:45.000 --> 52:48.000]  1, 1-p,
[52:48.000 --> 52:51.000]  2n-2.
[52:51.000 --> 52:54.000]  Так, все успевают.
[52:54.000 --> 52:57.000]  Квадрат возвел.
[52:57.000 --> 53:00.000]  Явно написал квадрат мат ожидания.
[53:00.000 --> 53:03.000]  Так, и минус 1.
[53:03.000 --> 53:06.000]  Это вот ех квадрат поделить на ех квадрат.
[53:06.000 --> 53:09.000]  Все.
[53:09.000 --> 53:12.000]  Внимание, товарищи, как ведет себя средняя дробь?
[53:13.000 --> 53:16.000]  Стремиться к единице.
[53:16.000 --> 53:19.000]  Я надеюсь, что все видят.
[53:19.000 --> 53:22.000]  Я еще знаете, как могу написать?
[53:22.000 --> 53:25.000]  Она равна 1 плюсо малое от единицы.
[53:25.000 --> 53:28.000]  Ну, стремиться к единице
[53:28.000 --> 53:31.000]  это то же самое, что равна 1 плюсо малое.
[53:31.000 --> 53:34.000]  Привыкли, нет?
[53:34.000 --> 53:37.000]  Нормально?
[53:37.000 --> 53:40.000]  Такое жонглирование просто мат-аналитическими обозначениями.
[53:40.000 --> 53:43.000]  Чпок-чпок.
[53:43.000 --> 53:46.000]  Тут стремиться к нулю, тут стремиться к нулю.
[53:46.000 --> 53:49.000]  Значит, все стремиться к нулю.
[53:49.000 --> 53:52.000]  И второй пункт теоремы у нас в короли.
[53:52.000 --> 53:55.000]  Доказал вроде.
[53:55.000 --> 53:58.000]  Все.
[53:58.000 --> 54:01.000]  Дробь стремится к нулю.
[54:01.000 --> 54:04.000]  Значит, вероятность наличия изолированных вершин стремится к единице.
[54:04.000 --> 54:07.000]  Ну, значит, граф, скорее всего, не является связанным.
[54:07.000 --> 54:10.000]  По причине того, что мы отщепили отдельные вершины.
[54:10.000 --> 54:13.000]  За этим была интуиция.
[54:13.000 --> 54:16.000]  Понятно.
[54:16.000 --> 54:19.000]  Так, друзья, есть какие-нибудь вопросы по доказанному?
[54:19.000 --> 54:22.000]  Отлично.
[54:22.000 --> 54:25.000]  Я надеюсь, что это означает не то, что я восклокнул,
[54:25.000 --> 54:28.000]  а наоборот, что я молодец.
[54:28.000 --> 54:31.000]  Помните, я говорил, что на примере этой теоремы
[54:31.000 --> 54:34.000]  мы увидели, что неравенство Маркова в комбинаторике
[54:34.000 --> 54:37.000]  только дополняет неравенство Чебышова.
[54:37.000 --> 54:40.000]  С помощью неравенства Чебышова мы только что доказали,
[54:40.000 --> 54:43.000]  что почти надерное что-то есть в графе.
[54:43.000 --> 54:46.000]  А именно изолированная вершина.
[54:46.000 --> 54:49.000]  Хватит за мысли?
[54:49.000 --> 54:52.000]  Ну, да.
[54:52.000 --> 54:55.000]  Ну, да.
[54:56.000 --> 54:59.000]  Хватит за мысли?
[54:59.000 --> 55:02.000]  Давайте теперь, доказывая пункт 1,
[55:02.000 --> 55:05.000]  применим неравенство Маркова,
[55:05.000 --> 55:08.000]  чтобы убедиться в том, что в случайном графе
[55:08.000 --> 55:11.000]  почти надерное нет не только изолированных вершин
[55:11.000 --> 55:14.000]  и ситуации, когда С больше единиц,
[55:14.000 --> 55:17.000]  но вообще никаких отдельных компонентов связанности.
[55:17.000 --> 55:22.000]  То есть давайте доказательства пункта 1
[55:22.000 --> 55:25.000]  еще раз, Чебышов,
[55:25.000 --> 55:28.000]  почти надерное что-то есть,
[55:28.000 --> 55:31.000]  а Марков сейчас скажет, что почти надерное ничего нет.
[55:31.000 --> 55:34.000]  Доказательства пункта 2.
[55:34.000 --> 55:37.000]  Давайте возьмем теперь через X
[55:37.000 --> 55:40.000]  обозначим другую величину, не ту, которая была раньше,
[55:40.000 --> 55:43.000]  не число изолированных вершин.
[55:43.000 --> 55:50.000]  X это будет число нетригиальных вершин.
[55:50.000 --> 55:55.000]  И это реально компонент связанности.
[55:55.000 --> 55:59.000]  Ну, то есть тех, у которых меньше строка, чем n-вершины.
[55:59.000 --> 56:04.000]  Компонент связанности.
[56:04.000 --> 56:07.000]  Еще раз, компонент,
[56:07.000 --> 56:10.000]  который не совпадает совсем графу.
[56:10.000 --> 56:14.000]  Компонент, у которых одна вершина изолированных,
[56:14.000 --> 56:17.000]  две вершины можно, 3n-1 можно,
[56:17.000 --> 56:20.000]  но только нет.
[56:20.000 --> 56:23.000]  То есть, если
[56:23.000 --> 56:25.000]  же
[56:25.000 --> 56:29.000]  связан,
[56:29.000 --> 56:32.000]  то X равняется 0 и наоборот.
[56:32.000 --> 56:37.000]  Надо было сказать тогда и только тогда.
[56:37.000 --> 56:39.000]  Но могу и так.
[56:39.000 --> 56:41.000]  Еще раз, граф связан тогда и только тогда,
[56:41.000 --> 56:43.000]  когда X равняется 0.
[56:43.000 --> 56:45.000]  Просто по определению.
[56:45.000 --> 56:48.000]  В графе нет ни деревянных компонентов, значит он связан.
[56:48.000 --> 56:51.000]  Но это такой поясник.
[56:51.000 --> 56:54.000]  То есть, наша цель
[56:54.000 --> 56:58.000]  доказать,
[56:58.000 --> 57:01.000]  что
[57:01.000 --> 57:04.000]  асинтонически почти, наверное,
[57:04.000 --> 57:06.000]  X таки равняется 0.
[57:06.000 --> 57:10.000]  Граф связан, то есть X равняется 0.
[57:16.000 --> 57:20.000]  Ну давай посмотрим,
[57:20.000 --> 57:24.000]  в какой вероятности X больше либо равен единице.
[57:24.000 --> 57:27.000]  Помните мой стат?
[57:27.000 --> 57:30.000]  Я сказал, хочется применить неравенство Маркова, но оно ничего не дает.
[57:30.000 --> 57:33.000]  А вот здесь как раз именно оно и дает.
[57:33.000 --> 57:36.000]  Согласно неравенству Маркова,
[57:36.000 --> 57:38.000]  неравенство Маркова
[57:38.000 --> 57:42.000]  это не больше, чем Y.
[57:43.000 --> 57:46.000]  Интересно, кто-то понимает, почему, да?
[57:46.000 --> 57:48.000]  Ну надо на единицу делить, там поделить на А,
[57:48.000 --> 57:50.000]  но А у нас равно 1.
[57:50.000 --> 57:53.000]  Поэтому и X просто и останется.
[57:53.000 --> 57:55.000]  Так.
[57:55.000 --> 57:58.000]  Как бы нам теперь посчитать
[57:58.000 --> 58:01.000]  или оценить мотоожидание XA?
[58:01.000 --> 58:05.000]  Давайте прежде всего напишем вот так.
[58:05.000 --> 58:07.000]  X1
[58:07.000 --> 58:09.000]  плюс и так далее,
[58:09.000 --> 58:11.000]  и X и так далее,
[58:14.000 --> 58:17.000]  Догадываетесь ли вы, что такое X и T тут?
[58:20.000 --> 58:24.000]  Я специально торможу, чтобы вы могли задуматься и записать.
[58:25.000 --> 58:29.000]  Просто количество компонентов на Y вершинах, правильно?
[58:31.000 --> 58:34.000]  Количество компонентов X и T это количество компонентов
[58:34.000 --> 58:36.000]  на Y вершинах.
[58:36.000 --> 58:39.000]  Пользуемся линейностью.
[58:39.000 --> 58:41.000]  Получаем сумму
[58:41.000 --> 58:43.000]  в поединке единицы до N.
[58:43.000 --> 58:46.000]  Ой, да, это Y1, извините.
[58:48.000 --> 58:50.000]  Мотоожидание X.
[58:54.000 --> 58:57.000]  Так что мотоожидание X этого посчитать,
[58:57.000 --> 58:59.000]  сколько в среднем компонентов,
[58:59.000 --> 59:02.000]  каждый из которых имеет ровные вершины.
[59:02.000 --> 59:04.000]  Придется
[59:04.000 --> 59:07.000]  вам подумать, а мне постирать.
[59:07.000 --> 59:11.000]  У вас умственное упражнение, а у меня физическое.
[59:16.000 --> 59:19.000]  Пока я стираю, подумайте.
[59:22.000 --> 59:25.000]  Наверное, ничего не придумали, да?
[59:25.000 --> 59:29.000]  Я запою на F степени Y.
[59:29.000 --> 59:32.000]  Но не на F степени, нет.
[59:32.000 --> 59:36.000]  И не один, ну один минус P, но не в степени Y.
[59:36.000 --> 59:39.000]  Значит, маленький, давайте я нарисую картину.
[59:39.000 --> 59:42.000]  Пресловутая сортелька
[59:42.000 --> 59:46.000]  символизирует собой множество всех вершин случайного графа.
[59:49.000 --> 59:51.000]  Нас интересует
[59:51.000 --> 59:54.000]  под множество мощности Y.
[59:54.000 --> 59:58.000]  Давайте я под сортельку нарисую, напишу Y.
[59:58.000 --> 01:00:00.000]  Хорошо?
[01:00:00.000 --> 01:00:02.000]  Теперь давайте я так сделаю.
[01:00:02.000 --> 01:00:05.000]  Я все такие подсортельки перечислю
[01:00:05.000 --> 01:00:07.000]  за номеру.
[01:00:07.000 --> 01:00:09.000]  Вот там A1
[01:00:09.000 --> 01:00:13.000]  и так далее A с индексом C из N по Y.
[01:00:13.000 --> 01:00:18.000]  Это все возможные множество вершин мощности Y.
[01:00:18.000 --> 01:00:22.000]  Каждый из них теоретически может оказаться чем?
[01:00:22.000 --> 01:00:25.000]  Компонентой связанности, да?
[01:00:25.000 --> 01:00:28.000]  А может не оказаться.
[01:00:29.000 --> 01:00:32.000]  Ну, линейность, это такой истиматик, станут алгоритмами.
[01:00:32.000 --> 01:00:35.000]  Я вам уже говорил в прошлый раз.
[01:00:35.000 --> 01:00:40.000]  То есть мы пишем так, как бы это обозначить.
[01:00:40.000 --> 01:00:43.000]  Давайте обозначим X
[01:00:43.000 --> 01:00:46.000]  и T житое.
[01:00:46.000 --> 01:00:48.000]  Мы зафиксировали. И
[01:00:48.000 --> 01:00:52.000]  ажи будут меняться в пределах от теницы до C из N по Y.
[01:00:52.000 --> 01:00:55.000]  Значит, X и T житое
[01:00:55.000 --> 01:00:57.000]  от графа.
[01:00:57.000 --> 01:01:01.000]  Это есть один.
[01:01:01.000 --> 01:01:03.000]  Если
[01:01:03.000 --> 01:01:05.000]  аи-те
[01:01:05.000 --> 01:01:07.000]  ой, ажи-те
[01:01:07.000 --> 01:01:09.000]  ажи-те, извините, конечно, жи у нас
[01:01:09.000 --> 01:01:12.000]  отвечает за номер подсортельки.
[01:01:12.000 --> 01:01:14.000]  Если ажи-те
[01:01:14.000 --> 01:01:17.000]  является компонентой
[01:01:17.000 --> 01:01:19.000]  в графе G
[01:01:19.000 --> 01:01:22.000]  и ноль иначе.
[01:01:22.000 --> 01:01:26.000]  Вот первое, что вы должны ососнать, самое главное.
[01:01:26.000 --> 01:01:29.000]  Вы понимаете, что X и T ажи
[01:01:29.000 --> 01:01:33.000]  это количество компонентной вершины.
[01:01:33.000 --> 01:01:36.000]  Это в точности сумма пожи
[01:01:36.000 --> 01:01:39.000]  от 1 до C из N по Y
[01:01:39.000 --> 01:01:44.000]  X и T житое ажи.
[01:01:46.000 --> 01:01:48.000]  Ну, вот этот
[01:01:48.000 --> 01:01:50.000]  мега алгоритмический подход.
[01:01:50.000 --> 01:01:52.000]  Тупо перебираем все подможества
[01:01:52.000 --> 01:01:54.000]  и каждое проверяем.
[01:01:54.000 --> 01:01:56.000]  Вы мне скажете, Боже мой,
[01:01:56.000 --> 01:01:58.000]  это почти издевательство.
[01:01:58.000 --> 01:02:01.000]  Если вот это и является компонентой,
[01:02:01.000 --> 01:02:04.000]  то, наверное, вот это уже не является.
[01:02:04.000 --> 01:02:06.000]  Согласны, да?
[01:02:06.000 --> 01:02:08.000]  Если вот такая подсортелька
[01:02:08.000 --> 01:02:10.000]  в каком-то конкретном графе
[01:02:10.000 --> 01:02:12.000]  служит компонентой связности,
[01:02:12.000 --> 01:02:14.000]  может вот такая служить,
[01:02:14.000 --> 01:02:17.000]  то как компоненты могут пересекаться?
[01:02:20.000 --> 01:02:22.000]  Так, друзья, нормально?
[01:02:22.000 --> 01:02:24.000]  Я пытаюсь давить на то,
[01:02:24.000 --> 01:02:26.000]  что вот эти величины
[01:02:26.000 --> 01:02:28.000]  дикозавидимые.
[01:02:28.000 --> 01:02:30.000]  И с точки зрения алгоритмов,
[01:02:30.000 --> 01:02:32.000]  конечно, глупо складывать все.
[01:02:32.000 --> 01:02:34.000]  А с точки зрения подсчета
[01:02:34.000 --> 01:02:36.000]  от ожидания самое то.
[01:02:36.000 --> 01:02:38.000]  Ну, правильно же?
[01:02:38.000 --> 01:02:41.000]  Мало ли чтобы там автоматом с нами,
[01:02:41.000 --> 01:02:43.000]  а мы компьютер заставим
[01:02:43.000 --> 01:02:45.000]  просто все вот это считать.
[01:02:45.000 --> 01:02:47.000]  Все.
[01:02:47.000 --> 01:02:49.000]  Так, друзья, поднимите руки,
[01:02:49.000 --> 01:02:51.000]  чтобы вы понимали.
[01:02:51.000 --> 01:02:53.000]  Ну, хорошо.
[01:02:53.000 --> 01:02:56.000]  Так, тогда
[01:02:56.000 --> 01:02:59.000]  мат ожидания иксытова
[01:02:59.000 --> 01:03:02.000]  это сумма пошли от 1СН
[01:03:02.000 --> 01:03:05.000]  до ЦИЦН по И.
[01:03:05.000 --> 01:03:07.000]  Ну, можно я не буду писать
[01:03:07.000 --> 01:03:09.000]  промежуточный шаг.
[01:03:09.000 --> 01:03:11.000]  Мат ожидания иксытова-житого, конечно.
[01:03:11.000 --> 01:03:14.000]  Но оно равно вот этой вероятности.
[01:03:14.000 --> 01:03:16.000]  Мат ожидания иксытова-житого,
[01:03:16.000 --> 01:03:18.000]  которое сюда надо рисовать,
[01:03:18.000 --> 01:03:20.000]  оно равно вот этой вероятности.
[01:03:20.000 --> 01:03:22.000]  То есть надо писать вот так.
[01:03:22.000 --> 01:03:25.000]  Вероятность того, что ошибка
[01:03:25.000 --> 01:03:30.000]  является компонентной гранижи.
[01:03:34.000 --> 01:03:36.000]  Согласны?
[01:03:36.000 --> 01:03:38.000]  Мат ожидания идикатора
[01:03:38.000 --> 01:03:40.000]  это вероятность того,
[01:03:40.000 --> 01:03:42.000]  что он равен единице.
[01:03:42.000 --> 01:03:46.000]  И вот тут наступает некий кирпик.
[01:03:46.000 --> 01:03:48.000]  Почему, собственно, вы не смогли
[01:03:48.000 --> 01:03:50.000]  сходу ответить на вопрос?
[01:03:50.000 --> 01:03:52.000]  Дело в том, что непонятно,
[01:03:52.000 --> 01:03:54.000]  как посчитать значение этой вероятности.
[01:03:54.000 --> 01:03:58.000]  Ну, они же каждый имеет
[01:03:58.000 --> 01:04:00.000]  разные вероятности, понимаете?
[01:04:00.000 --> 01:04:02.000]  Можно доказывать, что есть
[01:04:02.000 --> 01:04:04.000]  основное дерево, там еще какие-то
[01:04:04.000 --> 01:04:06.000]  страшные вещи говорить,
[01:04:06.000 --> 01:04:08.000]  но мы не будем этого делать.
[01:04:08.000 --> 01:04:10.000]  Все равно вот эту вероятность
[01:04:10.000 --> 01:04:12.000]  явно вы не посчитаете,
[01:04:12.000 --> 01:04:14.000]  только на компьютере.
[01:04:14.000 --> 01:04:16.000]  Ну, оценим сверху, конечно.
[01:04:16.000 --> 01:04:20.000]  Нам же нужно вот так оценить.
[01:04:20.000 --> 01:04:22.000]  Мы сейчас эту вероятность
[01:04:22.000 --> 01:04:24.000]  тоже оценим сверху.
[01:04:26.000 --> 01:04:28.000]  Так, зря я нарисовал вторую сорту.
[01:04:28.000 --> 01:04:30.000]  Она влитит.
[01:04:34.000 --> 01:04:36.000]  Вернемся к исходной картине.
[01:04:36.000 --> 01:04:38.000]  Это вот у нас ожитое нарисовка.
[01:04:40.000 --> 01:04:42.000]  Оно размерами.
[01:04:44.000 --> 01:04:46.000]  Вот событие ожитое
[01:04:46.000 --> 01:04:48.000]  является компонентом.
[01:04:50.000 --> 01:04:52.000]  В чем оно состоит?
[01:04:52.000 --> 01:04:54.000]  Во-первых,
[01:04:54.000 --> 01:04:56.000]  в том, что вот этот кусок
[01:04:56.000 --> 01:04:58.000]  графа Ж
[01:04:58.000 --> 01:05:00.000]  связанный.
[01:05:00.000 --> 01:05:02.000]  А во-вторых,
[01:05:02.000 --> 01:05:04.000]  никаких ребер
[01:05:04.000 --> 01:05:06.000]  вот такого вида уже нет.
[01:05:06.000 --> 01:05:08.000]  Правда?
[01:05:08.000 --> 01:05:10.000]  Наружу из этого множества
[01:05:10.000 --> 01:05:12.000]  никакие ребра не ведут.
[01:05:14.000 --> 01:05:16.000]  Потому что это компонента связанности.
[01:05:16.000 --> 01:05:18.000]  И ничего добавить нельзя.
[01:05:18.000 --> 01:05:20.000]  Это класс эквивалентности максимально.
[01:05:22.000 --> 01:05:24.000]  Все понимают, да?
[01:05:26.000 --> 01:05:28.000]  Вот таких ребер быть не может.
[01:05:28.000 --> 01:05:30.000]  Ну, давайте просто тупо
[01:05:30.000 --> 01:05:32.000]  оценим
[01:05:32.000 --> 01:05:34.000]  вот так.
[01:05:38.000 --> 01:05:40.000]  Вероятность того, что
[01:05:40.000 --> 01:05:42.000]  из ожитого
[01:05:42.000 --> 01:05:44.000]  в В минус ожитое
[01:05:44.000 --> 01:05:46.000]  В это вот это.
[01:05:46.000 --> 01:05:48.000]  Это все.
[01:05:48.000 --> 01:05:50.000]  Множество вершин
[01:05:50.000 --> 01:05:52.000]  это В.
[01:05:52.000 --> 01:05:54.000]  В минус ожитое не идут ребра.
[01:06:00.000 --> 01:06:02.000]  Ну, меньше, наверное, строго, конечно.
[01:06:02.000 --> 01:06:04.000]  Но я уже написал.
[01:06:06.000 --> 01:06:08.000]  Поняли, да? Тут стоит пересечение двух условий.
[01:06:08.000 --> 01:06:10.000]  Одно состоит в связанности,
[01:06:10.000 --> 01:06:12.000]  а второе вот оно написано.
[01:06:12.000 --> 01:06:14.000]  Но я вероятность пересечения
[01:06:14.000 --> 01:06:16.000]  оценил вероятностью одного из событий.
[01:06:16.000 --> 01:06:18.000]  Забил вообще
[01:06:18.000 --> 01:06:20.000]  на связанность.
[01:06:22.000 --> 01:06:24.000]  Следили?
[01:06:24.000 --> 01:06:26.000]  Так.
[01:06:26.000 --> 01:06:28.000]  А вот это вероятно считается.
[01:06:28.000 --> 01:06:30.000]  Чему она равна?
[01:06:30.000 --> 01:06:32.000]  Правильно.
[01:06:32.000 --> 01:06:34.000]  Сумма пожи
[01:06:34.000 --> 01:06:36.000]  от единицы
[01:06:36.000 --> 01:06:38.000]  до цели из н по i
[01:06:38.000 --> 01:06:40.000]  1 минус
[01:06:40.000 --> 01:06:42.000]  p вот в такой вот
[01:06:42.000 --> 01:06:44.000]  степени.
[01:06:44.000 --> 01:06:46.000]  i умножить на n минус
[01:06:46.000 --> 01:06:48.000]  i.
[01:06:48.000 --> 01:06:50.000]  Ну почему? Потому что тут у нас
[01:06:50.000 --> 01:06:52.000]  и вершин, вот тут вот у нас
[01:06:52.000 --> 01:06:54.000]  и вершин, а тут у нас
[01:06:54.000 --> 01:06:56.000]  n минус i вершин.
[01:06:56.000 --> 01:06:58.000]  И нам нужно, чтобы любая из этих
[01:06:58.000 --> 01:07:00.000]  с любой из этих не соединялась
[01:07:00.000 --> 01:07:02.000]  с ребром.
[01:07:02.000 --> 01:07:04.000]  Вероятность отсутствия ребра это 1 минус
[01:07:04.000 --> 01:07:06.000]  p, а количество отсутствующих
[01:07:06.000 --> 01:07:08.000]  как раз и умножить на n минус
[01:07:12.000 --> 01:07:14.000]  Так. Возвращаемся сюда.
[01:07:16.000 --> 01:07:18.000]  И чтобы это не больше
[01:07:18.000 --> 01:07:20.000]  чем сумма по i от
[01:07:20.000 --> 01:07:22.000]  единицы на n минус 1.
[01:07:22.000 --> 01:07:24.000]  Возвращаемся назад.
[01:07:24.000 --> 01:07:26.000]  Слушайте, они слагаемые
[01:07:26.000 --> 01:07:28.000]  это у нас, не знайте старши.
[01:07:30.000 --> 01:07:32.000]  Ну то есть надо просто вот эту
[01:07:32.000 --> 01:07:34.000]  штуку умножить на
[01:07:34.000 --> 01:07:36.000]  c из n по i.
[01:07:36.000 --> 01:07:38.000]  c из n по i
[01:07:40.000 --> 01:07:42.000]  1 минус p
[01:07:42.000 --> 01:07:44.000]  в степени i
[01:07:44.000 --> 01:07:46.000]  на n минус
[01:07:48.000 --> 01:07:50.000]  Так.
[01:07:50.000 --> 01:07:52.000]  Что нам осталось доказать?
[01:07:54.000 --> 01:07:56.000]  Осталось доказать
[01:07:56.000 --> 01:07:58.000]  под вопрос.
[01:07:58.000 --> 01:08:00.000]  Это стремится к нулю, правда?
[01:08:00.000 --> 01:08:02.000]  Вероятность
[01:08:02.000 --> 01:08:04.000]  того, что есть хотя бы одна
[01:08:04.000 --> 01:08:06.000]  компонента
[01:08:06.000 --> 01:08:08.000]  должна стремиться к нулю.
[01:08:08.000 --> 01:08:10.000]  Скоро мы хотим, чтобы отсутствие компонента
[01:08:10.000 --> 01:08:12.000]  было выполнено почти наверх.
[01:08:14.000 --> 01:08:16.000]  Согласны, да?
[01:08:16.000 --> 01:08:18.000]  Да.
[01:08:22.000 --> 01:08:24.000]  Где?
[01:08:24.000 --> 01:08:26.000]  Вот тут?
[01:08:26.000 --> 01:08:28.000]  Нет. Смотрите, shi
[01:08:28.000 --> 01:08:30.000]  это номер и элементного
[01:08:30.000 --> 01:08:32.000]  множества.
[01:08:32.000 --> 01:08:34.000]  А количество элементов, как раз i
[01:08:34.000 --> 01:08:36.000]  не важно, какой shi
[01:08:36.000 --> 01:08:38.000]  какой номер
[01:08:38.000 --> 01:08:40.000]  не важно, какую именно сардельку размера
[01:08:40.000 --> 01:08:42.000]  i мы берем.
[01:08:42.000 --> 01:08:44.000]  Количество отсутствующих ребер,
[01:08:44.000 --> 01:08:46.000]  то есть таких, что одна вершина снаружи, одна внутри
[01:08:46.000 --> 01:08:48.000]  это именно i умножить на n минус i.
[01:08:48.000 --> 01:08:50.000]  Сколько вершин тут
[01:08:50.000 --> 01:08:52.000]  их и втуг
[01:08:52.000 --> 01:08:54.000]  умножить на сколько вершин снаружи их n минус i.
[01:08:54.000 --> 01:08:56.000]  Пара отсюда и отсюда
[01:08:56.000 --> 01:08:58.000]  i умножить на n минус i.
[01:08:58.000 --> 01:09:00.000]  Shi
[01:09:00.000 --> 01:09:02.000]  вот оно. И здесь никакой
[01:09:02.000 --> 01:09:04.000]  зависимости от shi нет.
[01:09:04.000 --> 01:09:06.000]  Именно поэтому я всю сумму
[01:09:06.000 --> 01:09:08.000]  просто превратил
[01:09:08.000 --> 01:09:10.000]  c из n по i на 1 минус
[01:09:10.000 --> 01:09:12.000]  p в слепени i на
[01:09:12.000 --> 01:09:14.000]  n минус i. И вот сюда
[01:09:14.000 --> 01:09:16.000]  вот переписал.
[01:09:28.000 --> 01:09:30.000]  Ну, времени-то мало осталось.
[01:09:30.000 --> 01:09:32.000]  Давайте, знаете, по чему я это скажу?
[01:09:32.000 --> 01:09:34.000]  В опену есть время еще какое-то.
[01:09:34.000 --> 01:09:36.000]  В опену. Смотрите, что будет
[01:09:36.000 --> 01:09:38.000]  если i равно 1.
[01:09:48.000 --> 01:09:50.000]  По-моему, это как раз мат ожидания
[01:09:50.000 --> 01:09:52.000]  числа изолированных вершин, но это понятно
[01:09:52.000 --> 01:09:54.000]  и равно 1
[01:09:54.000 --> 01:09:56.000]  компоненты размера 1.
[01:09:56.000 --> 01:09:58.000]  То есть как раз изолированные вершины
[01:10:00.000 --> 01:10:02.000]  будет 0.
[01:10:06.000 --> 01:10:08.000]  Смотрите, если i равно 1
[01:10:08.000 --> 01:10:10.000]  я напишу, то слагаемое
[01:10:10.000 --> 01:10:12.000]  представляет собой n на
[01:10:12.000 --> 01:10:14.000]  1 минус p в n минус 1.
[01:10:14.000 --> 01:10:16.000]  Мы уже знаем, что в нашей ситуации
[01:10:16.000 --> 01:10:18.000]  в рамках пункта 1
[01:10:18.000 --> 01:10:20.000]  это стремится к 0,
[01:10:20.000 --> 01:10:22.000]  это мы знаем, это не вопрос, это известно.
[01:10:22.000 --> 01:10:24.000]  Помните, да?
[01:10:24.000 --> 01:10:26.000]  Поскольку c больше 1,
[01:10:26.000 --> 01:10:28.000]  это стремится к 0.
[01:10:28.000 --> 01:10:30.000]  В этом есть смысл.
[01:10:30.000 --> 01:10:32.000]  Но слушайте из того, что одно лишь
[01:10:32.000 --> 01:10:34.000]  слагаемое стремится к 0,
[01:10:34.000 --> 01:10:36.000]  к сожалению, не следует, что вся сумма
[01:10:36.000 --> 01:10:38.000]  верхний предел, который тоже зависит
[01:10:38.000 --> 01:10:40.000]  от данного, стремится к 0.
[01:10:40.000 --> 01:10:42.000]  Понимаете, да?
[01:10:42.000 --> 01:10:44.000]  Какая крупная неприятность.
[01:10:46.000 --> 01:10:48.000]  Причем, если вы посмотрим
[01:10:48.000 --> 01:10:50.000]  внимательно, чем ближе
[01:10:50.000 --> 01:10:52.000]  c под единицей,
[01:10:52.000 --> 01:10:54.000]  тем медленнее стремится к 0.
[01:10:54.000 --> 01:10:56.000]  Вот это первое слагаемое.
[01:10:58.000 --> 01:11:00.000]  Прям оно может быть совсем на грани,
[01:11:00.000 --> 01:11:02.000]  еле-еле-еле.
[01:11:02.000 --> 01:11:04.000]  Там как 1 поделить на корень
[01:11:04.000 --> 01:11:06.000]  миллионной степени z, что-нибудь такое.
[01:11:06.000 --> 01:11:08.000]  Если c это
[01:11:08.000 --> 01:11:10.000]  1,1 миллионная, то
[01:11:10.000 --> 01:11:12.000]  там будет 1 поделить на корень
[01:11:12.000 --> 01:11:14.000]  миллионной степени z. Все очень медленно
[01:11:14.000 --> 01:11:16.000]  стремится к 0. Что делать?
[01:11:16.000 --> 01:11:18.000]  Какой ужас.
[01:11:18.000 --> 01:11:20.000]  На первых давайте заметим,
[01:11:20.000 --> 01:11:22.000]  мы сегодня не закончим,
[01:11:22.000 --> 01:11:24.000]  но самая противная аналитика пойдет
[01:11:24.000 --> 01:11:26.000]  в следующий раз. Давайте заметим,
[01:11:26.000 --> 01:11:28.000]  что
[01:11:28.000 --> 01:11:30.000]  достаточно
[01:11:32.000 --> 01:11:34.000]  доказать,
[01:11:34.000 --> 01:11:36.000]  что вот такая сумма стремится к 0,
[01:11:36.000 --> 01:11:38.000]  то как бы половинка.
[01:11:38.000 --> 01:11:40.000]  Почему?
[01:11:40.000 --> 01:11:42.000]  Потому что все, что идет
[01:11:42.000 --> 01:11:44.000]  после n пополам,
[01:11:44.000 --> 01:11:46.000]  оно симметрично.
[01:11:46.000 --> 01:11:48.000]  Т-шка симметричная,
[01:11:48.000 --> 01:11:50.000]  и тут стоит симметричная пункция.
[01:11:50.000 --> 01:11:52.000]  Если мы докажем,
[01:11:52.000 --> 01:11:54.000]  что при всех i не больше,
[01:11:54.000 --> 01:11:56.000]  чем n пополам,
[01:11:56.000 --> 01:11:58.000]  сумма слагаемых стремится к 0,
[01:11:58.000 --> 01:12:00.000]  то как бы половинка
[01:12:00.000 --> 01:12:02.000]  идет после n пополам,
[01:12:02.000 --> 01:12:04.000]  то как бы половинка
[01:12:04.000 --> 01:12:06.000]  идет после n пополам,
[01:12:06.000 --> 01:12:08.000]  сумма слагаемых стремится к 0,
[01:12:08.000 --> 01:12:10.000]  то при большем будет та же самая сумма,
[01:12:10.000 --> 01:12:12.000]  она тем, что тоже будет стремиться к 0.
[01:12:12.000 --> 01:12:14.000]  Нормально объясню?
[01:12:14.000 --> 01:12:16.000]  Достаточно доказать вот это.
[01:12:16.000 --> 01:12:18.000]  Так, что я еще
[01:12:18.000 --> 01:12:20.000]  успею сказать?
[01:12:20.000 --> 01:12:22.000]  Давайте вот это
[01:12:22.000 --> 01:12:24.000]  вот, ну
[01:12:24.000 --> 01:12:26.000]  каждое слагание
[01:12:26.000 --> 01:12:28.000]  обозначим a,
[01:12:28.000 --> 01:12:30.000]  i, t,
[01:12:30.000 --> 01:12:32.000]  a, t.
[01:12:32.000 --> 01:12:34.000]  Везем такое обозначение.
[01:12:34.000 --> 01:12:36.000]  i, t слагаемое, но оно является
[01:12:36.000 --> 01:12:38.000]  пункциатом.
[01:12:38.000 --> 01:12:40.000]  Попробуем
[01:12:40.000 --> 01:12:42.000]  i плюс
[01:12:42.000 --> 01:12:44.000]  1 от r
[01:12:44.000 --> 01:12:46.000]  разделить на i, t от r.
[01:12:46.000 --> 01:12:48.000]  Этому в следующий раз
[01:12:48.000 --> 01:12:50.000]  аккуратно сделаем.
[01:12:52.000 --> 01:12:54.000]  Но давайте
[01:12:54.000 --> 01:12:56.000]  вы просто интуицию поймаете.
[01:12:56.000 --> 01:12:58.000]  Достаточно, если там 5 минут
[01:12:58.000 --> 01:13:00.000]  или сколько осталось.
[01:13:00.000 --> 01:13:02.000]  Допустим,
[01:13:02.000 --> 01:13:04.000]  это в следующий раз станет понятно,
[01:13:04.000 --> 01:13:06.000]  окажется, что это не больше,
[01:13:06.000 --> 01:13:08.000]  чем некоторое q от n,
[01:13:08.000 --> 01:13:10.000]  которое от i вообще не зависит.
[01:13:10.000 --> 01:13:12.000]  Видите, вот тут есть i,
[01:13:12.000 --> 01:13:14.000]  а тут и нет.
[01:13:14.000 --> 01:13:16.000]  Причем q от n не або какое, а стремящееся к 0.
[01:13:16.000 --> 01:13:18.000]  Вот вдруг такое получится.
[01:13:22.000 --> 01:13:24.000]  Как бы можно было тогда действовать?
[01:13:24.000 --> 01:13:26.000]  Смотрите.
[01:13:26.000 --> 01:13:28.000]  Смотрите.
[01:13:28.000 --> 01:13:30.000]  Это a1 от n.
[01:13:30.000 --> 01:13:32.000]  Выносим за скобку.
[01:13:32.000 --> 01:13:34.000]  Самое первое слагаемое.
[01:13:34.000 --> 01:13:36.000]  В скобках остается
[01:13:36.000 --> 01:13:38.000]  1.
[01:13:38.000 --> 01:13:40.000]  Правильно?
[01:13:40.000 --> 01:13:42.000]  Потом a2 от n.
[01:13:42.000 --> 01:13:44.000]  Поделить на a1
[01:13:44.000 --> 01:13:46.000]  от n. Я надеюсь, вы успеваете,
[01:13:46.000 --> 01:13:48.000]  товарищи.
[01:13:48.000 --> 01:13:50.000]  Следующая как?
[01:13:50.000 --> 01:13:52.000]  a3 от n.
[01:13:52.000 --> 01:13:54.000]  Поделить
[01:13:54.000 --> 01:13:56.000]  на 1.
[01:13:56.000 --> 01:13:58.000]  Поделим на 2.
[01:13:58.000 --> 01:14:00.000]  Множим на 2.
[01:14:02.000 --> 01:14:04.000]  И поделим снова на 1.
[01:14:04.000 --> 01:14:06.000]  Вот так.
[01:14:06.000 --> 01:14:08.000]  Что у нас вырисовывается,
[01:14:08.000 --> 01:14:10.000]  товарищи?
[01:14:10.000 --> 01:14:12.000]  Необидительно.
[01:14:16.000 --> 01:14:18.000]  Правильно.
[01:14:18.000 --> 01:14:20.000]  Яндрическое прогрессие.
[01:14:20.000 --> 01:14:22.000]  То есть,
[01:14:22.000 --> 01:14:24.000]  это меньше,
[01:14:24.000 --> 01:14:26.000]  чем a1 от n.
[01:14:26.000 --> 01:14:28.000]  Умножить на 1.
[01:14:28.000 --> 01:14:30.000]  Плюс q от n.
[01:14:30.000 --> 01:14:32.000]  Плюс q2 от n.
[01:14:32.000 --> 01:14:34.000]  И так до бесконечности.
[01:14:34.000 --> 01:14:36.000]  Ну, до бесконечности,
[01:14:36.000 --> 01:14:38.000]  на самом деле, не до бесконечности.
[01:14:38.000 --> 01:14:40.000]  Ну, неважно. Меньше же.
[01:14:40.000 --> 01:14:42.000]  Можно оценить бесконечно.
[01:14:42.000 --> 01:14:44.000]  Меньше не было равно, понимаешь?
[01:14:44.000 --> 01:14:46.000]  Ну, тут конечная числа слагаемых,
[01:14:46.000 --> 01:14:48.000]  а тут бесконечная.
[01:14:48.000 --> 01:14:50.000]  Ну ладно.
[01:14:50.000 --> 01:14:52.000]  Бесконечно, правда?
[01:14:52.000 --> 01:14:54.000]  Умножь.
[01:14:54.000 --> 01:14:56.000]  То есть, будет a1 от n.
[01:14:56.000 --> 01:14:58.000]  Но я люблю суммировать бесконечную прогрессию.
[01:14:58.000 --> 01:15:00.000]  Помните, мы с вами столбик делили когда-то.
[01:15:00.000 --> 01:15:02.000]  Это проще записывается просто.
[01:15:02.000 --> 01:15:04.000]  Короче, запись для суммы бесконечная.
[01:15:06.000 --> 01:15:08.000]  Слушайте, ну q от n стремится к 0.
[01:15:08.000 --> 01:15:10.000]  a1 от n.
[01:15:10.000 --> 01:15:12.000]  Вот оно. Оно тоже стремится к 0.
[01:15:12.000 --> 01:15:14.000]  Куда стремится это выражение?
[01:15:14.000 --> 01:15:16.000]  К 0.
[01:15:16.000 --> 01:15:20.000]  Дорогие товарищи,
[01:15:20.000 --> 01:15:22.000]  к сожалению,
[01:15:22.000 --> 01:15:24.000]  к сожалению,
[01:15:24.000 --> 01:15:26.000]  нам не удастся доказать
[01:15:26.000 --> 01:15:28.000]  вот это.
[01:15:28.000 --> 01:15:30.000]  Но не совсем.
[01:15:30.000 --> 01:15:32.000]  Дослушайте до конца.
[01:15:32.000 --> 01:15:34.000]  Слышно очень звучит? Да.
[01:15:34.000 --> 01:15:36.000]  Нам не удастся это доказать при всех ине,
[01:15:36.000 --> 01:15:38.000]  превосходящих a1 пополам.
[01:15:40.000 --> 01:15:42.000]  Любое у маленькой от n все хорошо,
[01:15:42.000 --> 01:15:44.000]  но порядка, она же,
[01:15:44.000 --> 01:15:46.000]  уже плохо.
[01:15:46.000 --> 01:15:48.000]  Поэтому нам придется эту сумму распить
[01:15:48.000 --> 01:15:50.000]  на две части.
[01:15:50.000 --> 01:15:52.000]  Поняли, да?
[01:15:52.000 --> 01:15:54.000]  Одна часть будет касаться
[01:15:54.000 --> 01:15:56.000]  вот именно этого пополам.
[01:15:56.000 --> 01:15:58.000]  Вот он там будет реализован.
[01:15:58.000 --> 01:16:00.000]  А другая настолько уже будет маленьким
[01:16:00.000 --> 01:16:02.000]  хвостиком, что мы вот тяпля
[01:16:02.000 --> 01:16:04.000]  поценим, он тоже будет стремиться к 0.
[01:16:04.000 --> 01:16:06.000]  Я объяснил это длительно.
[01:16:06.000 --> 01:16:08.000]  Понятно?
[01:16:08.000 --> 01:16:10.000]  Следующий раз мы это аккуратно реализуем.
[01:16:10.000 --> 01:16:12.000]  Но это тяжелый шанс.
