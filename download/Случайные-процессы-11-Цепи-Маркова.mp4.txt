[00:30.000 --> 00:52.000]  Вот такая его форма. Она довольно громоздкая, и вот это считается с конца. То есть фиксируется так, что будет понятно, как всегда у нас.
[00:52.000 --> 01:04.000]  Это маленькая, это самая большая, и начинается с конца интегрирования. Все переменные фиксируются, кроме последней.
[01:04.000 --> 01:20.000]  По последней проинтегрировали. Вот по этой мере, как только эти все фиксированы, то эта мера, можно сказать, аргумента Xn.
[01:20.000 --> 01:25.000]  И эта функция тоже от Xn зависит. Ее проинтегрировали.
[01:25.000 --> 01:35.000]  Но если множество простого вида... То есть видите, тут формула, из-за чего она немножко громоздкая, из-за того, что множество общего вида.
[01:35.000 --> 01:46.000]  Если множество распалось, как мы помним для того, чтобы, конечно, мерное распределение, однозначно определить, достаточно знать меру на произведение.
[01:46.000 --> 01:59.000]  Из этого всех она там устанавливается. Но вот если множество распалось в произведение, то здесь будет просто... Что будет?
[01:59.000 --> 02:09.000]  Здесь будет мера этого последнего. Но эта мера последнего, она еще зависит от предыдущих.
[02:09.000 --> 02:27.000]  И поэтому, когда мы начнем следующее интегрирование делать, то тут уже не будет так просто не общепиться мера еще одного.
[02:27.000 --> 02:38.000]  А эта мера, вот эта следующая, будет считаться так. А по этому множеству вот эту функцию нужно будет проинтегрировать.
[02:38.000 --> 02:45.000]  По предыдущим примерам. Вот ее проинтегрируем, ну и так далее.
[02:45.000 --> 02:51.000]  Поэтому на самом деле уже на втором ходу все это усложнится, и не будет такого расщепления.
[02:51.000 --> 02:58.000]  Потому что особенного смысла нет. Я предполагаю, что это произведение оценит некое множество.
[02:58.000 --> 03:08.000]  И вот когда мы так с конца интегрируем, то когда мы доберемся до последнего переменного, то предыдущее нам выдаст нечто,
[03:08.000 --> 03:18.000]  зависящее от X1. Потому что все остальные переменные уже окажутся связанными, интегрированы, их уже не будет.
[03:18.000 --> 03:27.000]  Ну форма вот такая довольно громоздкая, но в чем ее смысл?
[03:27.000 --> 03:42.000]  С помощью этой формы, ну X1 это там где, ну это фазовое пространство, у нас в процессе принимается значение.
[03:42.000 --> 03:54.000]  Ну, как я говорю, в большинстве случаев можно считать, что это R, D или R, но в принципе это формула, что такая, универсальна для такого угода.
[03:54.000 --> 03:58.000]  Где процесс принимается значение.
[03:58.000 --> 04:03.000]  Значит смотрите, в чем смысл еще этой формы?
[04:03.000 --> 04:29.000]  Ну, с помощью этой формы, с помощью этой формы, по переходам, вот таким F, вот таким аргументам, I, M, U, T, можно задать вот эту формулу,
[04:29.000 --> 04:37.000]  вот эта формула выписана в предположении, что процесс есть, но в правой части никакого процесса нет.
[04:37.000 --> 05:00.000]  Значит можно задать, можно задать конечку мерки и распределение, а значит проверить, их согласовывается.
[05:00.000 --> 05:05.000]  Ну, вот такая формула, которая в теории Голмогорода требуется.
[05:05.000 --> 05:31.000]  И, по теории Голмогорода, получить процесс с такими, ну, с такими конечными мерками распределений.
[05:31.000 --> 05:39.000]  Так вот, значит смотрите, теория Голмогорода дает какой-то процесс, но она не говорит, что это марковский процесс.
[05:39.000 --> 05:53.000]  Так вот, теория марковского процесса, полученный процесс, будет марковский.
[05:53.000 --> 06:04.000]  Это просто полезная фактка сведения, мы его не будем доказывать, это будет довольно длинная техническая проверка.
[06:04.000 --> 06:13.000]  А вот что мы докажем, это мы докажем вариант этой теории, мы сейчас для марковских цепей.
[06:13.000 --> 06:17.000]  Для процессов у нас это как факт без доказательства.
[06:17.000 --> 06:29.000]  Ну, казалось бы, раз мы принимаем такой факт для процессов без доказательства, что-то домучится с марковскими цепями, зачем для них отдельно доказывать частный случай.
[06:29.000 --> 06:37.000]  Но это из-за того, что он доказывается сравнительно неиспознанно, ну и там хотя бы в этом частном случае видно, что происходит.
[06:37.000 --> 06:52.000]  Эту теорию тоже, конечно, при желании можно было доказать, но такое доказательство, ну, по крайней мере на экзамене довольно неприятное, считаю, было воспроизводить такое доказательство.
[06:52.000 --> 06:55.000]  А для цепей довольно всё кроме.
[06:55.000 --> 06:59.000]  Значит, теперь ещё одна теория без доказательства.
[06:59.000 --> 07:07.000]  То же она у меня в конспекте есть, то же, то же доказательство, то же как факт.
[07:07.000 --> 07:11.000]  А у неё доказательство, не бог вещь какое, сложное.
[07:11.000 --> 07:17.000]  Вот, например, в учебнике Буинского и Ширяева можно его прочитать в странице с небольшим.
[07:17.000 --> 07:23.000]  Ну, тоже такое, знаете, довольно забористое теоретическое множественное обознавание.
[07:23.000 --> 07:25.000]  Значит, теория.
[07:27.000 --> 07:28.000]  Теория.
[07:28.000 --> 07:30.000]  Процесс.
[07:32.000 --> 07:35.000]  А с независимой мониторией вращения.
[07:35.000 --> 07:58.000]  Так, Маркочки относительно порождённой инфитрации.
[07:58.000 --> 08:05.000]  Значит, смотрите, когда есть процесс с независимыми вращениями, то никакой фильтрации, может, и нет.
[08:05.000 --> 08:11.000]  Но, помним, всякий процесс устраивает свою собственную фильтрацию.
[08:15.000 --> 08:21.000]  Относительно его собственной фильтрации, такой процесс будет Маркочкой.
[08:21.000 --> 08:26.000]  То есть смотрите, что у нас, что получается.
[08:26.000 --> 08:31.000]  Значит, вот у нас был важный класс процессов.
[08:31.000 --> 08:36.000]  Это процессы с независимой мониторией вращения.
[08:36.000 --> 08:41.000]  Значит, ещё был важный класс процессов галлов.
[08:41.000 --> 08:45.000]  Ещё был важный класс процессов мардингаллы.
[08:45.000 --> 08:50.000]  И вот четвёртый класс процессов это маркерс.
[08:51.000 --> 08:56.000]  Ну и вот всегда полезно выяснять, какие между ними соотношения.
[08:56.000 --> 09:00.000]  Ну, гауссовство это очень специалистическая, конечно, вещь.
[09:00.000 --> 09:08.000]  Ну и мы видели, что, скажем, гауссовские процессы с независимыми вращениями,
[09:08.000 --> 09:12.000]  ну там, при некоторых дополнительных широких предположениях,
[09:13.000 --> 09:22.000]  они вообще превращаются в винарские процессы.
[09:22.000 --> 09:31.000]  То есть у некоторых, получается, что у некоторых классов пересечение такие очень прочные.
[09:31.000 --> 09:34.000]  Значит, некоторые классы друг в друга вкладываются.
[09:34.000 --> 09:36.000]  Ну вот, вот этот пример.
[09:36.000 --> 09:39.000]  Вот этот пример.
[09:39.000 --> 09:47.000]  Процесс с независимыми вращениями – он маркерс.
[09:47.000 --> 09:53.000]  Значит, у нас про процессы с независимыми вращениями ещё одно было другое вложение.
[09:53.000 --> 10:03.000]  А если процесс с независимыми вращениями квадратично интегрируемый, то он мардингалл.
[10:03.000 --> 10:05.000]  Так, значит, ещё такие соотношения.
[10:05.000 --> 10:13.000]  Ну и, естественно, возникает вопрос, как связаны маркерские процессы с мардингаллом.
[10:13.000 --> 10:17.000]  Но здесь уже таких простых связей нет.
[10:17.000 --> 10:25.000]  Ну, оно и понятно, потому что в качестве упражнения можно доказать,
[10:26.000 --> 10:36.000]  если вы взяли маркерский процесс и подставили его в гомеоморфизм,
[10:36.000 --> 10:41.000]  ну скажем, взяли маркерский процесс на прямой и подставили его в гомеоморфизм,
[10:41.000 --> 10:48.000]  то все там нужные соотношения измеримости сохранятся, и новый процесс останется маркером.
[10:48.000 --> 10:57.000]  Ну, например, если вы взяли напрямой марковский процесс и взяли куб от него, то на что он останется марковским.
[10:57.000 --> 11:05.000]  Но маркингальность так не согласуется с отображениями.
[11:05.000 --> 11:10.000]  Вот в качестве упражнения можете проверить, что куб винарского процесса...
[11:10.000 --> 11:22.000]  Ну, просто в этой границах и науке головной руками основеет, что куб винарского процесса это марковский процесс относительно его интеракции, но не маркингаль.
[11:22.000 --> 11:29.000]  Вот маркингальность, она не очень дружит с нелинейными преобразованиями.
[11:29.000 --> 11:48.000]  То есть по большому счету можно сказать так, что когда преобразование реально нелинейное, то вот практически никогда маркингал не переводит маркингал.
[11:48.000 --> 11:56.000]  На самом исключении, можно между людьми, постоянно можно говорить, но в сколько-нибудь невырубленных ситуациях так не будет.
[11:56.000 --> 12:07.000]  Поэтому все-таки совсем уж такой матережечной системы нет между этими основными классами процессов, которые мы рассматриваем.
[12:07.000 --> 12:16.000]  Но вот какие-то интересные соотношения есть.
[12:16.000 --> 12:18.000]  Значит, теперь цепи маркового.
[12:46.000 --> 13:05.000]  Цепь маркового, значит, это марковский процесс
[13:05.000 --> 13:27.000]  с конечным или счетным числом состояний.
[13:27.000 --> 13:37.000]  У нас иногда даже требуют, чтобы еще и время было дискретное.
[13:37.000 --> 13:57.000]  Значит, у нас будет еще более специально конечные цепи маркового с дискретным временем.
[13:57.000 --> 14:07.000]  У нас время будет просто 1, 2, 3 и так далее.
[14:07.000 --> 14:24.000]  И конечное фазовое пространство.
[14:24.000 --> 14:34.000]  Ну, можно считать, что просто точки 1, 2, m.
[14:34.000 --> 14:59.000]  Значит, более того, у нас будут однородные цепи маркового.
[14:59.000 --> 15:14.000]  Ну, я напомню, что однородный марковский процесс это когда, значит, однородный марковский процесс общий.
[15:14.000 --> 15:30.000]  Значит, переходная функция зависит только от разности времен.
[15:30.000 --> 15:42.000]  Ну, то есть вот такая вот функция, она становится функцией четырех аргументов.
[15:42.000 --> 15:54.000]  Она становится функцией трех аргументов.
[15:54.000 --> 16:11.000]  Ну и мнимонический смысл этого обозначения, что это вероятность попасть в множество e за это время, находясь в нулевой момент в x.
[16:11.000 --> 16:22.000]  Но для марковской цепи, но тут все равно, видите, все равно переменных-то хватает, их меньше стало, конечно, их 3, но тоже будь здоров.
[16:22.000 --> 16:37.000]  Но для марковской цепи все это еще сильно сокращается, для однородной марковской цепи это все еще дальше сокращается.
[16:37.000 --> 17:02.000]  И, значит, сейчас давайте я, чтобы у меня обозначения не разошлись с конспектом.
[17:02.000 --> 17:29.000]  Значит, для однородной цепи все определяется переходными вероятностями за один шаг.
[17:29.000 --> 17:47.000]  Это числа такие p и g, это вероятность перехода из xe в xg за один шаг.
[17:47.000 --> 18:04.000]  Ну а, значит, раз время у нас дискретное, то вероятность за n шагов, это будет определяться степенью этой матрицы.
[18:04.000 --> 18:32.000]  Значит, вот возникает такая матрица, p, вот с такими элементами, значит, m на m, значит, матрица вероятностей перехода за один шаг.
[18:32.000 --> 18:56.000]  Ну что можно хорошего сказать про эту матрицу? У нее, естественно, элементы неотрицательные, и когда суммируем по g, то сумма вот этих вероятностей единица для каждого i.
[18:56.000 --> 19:16.000]  Это отвечает, значит, смысл очень простой, что из каждого i можно перейти за один шаг в одно из этих состояний, и поэтому сумма вероятностей должна быть единица.
[19:16.000 --> 19:25.000]  Ну, кстати сказать, в этом месте пока еще не видно, зачем нужно, чтобы пространство было конечным, это пока что годится и для счетного.
[19:25.000 --> 19:38.000]  Так что, в принципе, до сих пор пока было не очень существенно, что конечное, для счетного то же самое, но только матрица будет, естественно, бесконечной.
[19:38.000 --> 19:48.000]  Но сейчас довольно быстро, ну, все-таки станет понятно, что лучше считать, что у нас конечное пространство.
[19:48.000 --> 20:12.000]  Значит, смотрите, что будет... Так, сейчас давайте вот это я сотру.
[20:12.000 --> 20:32.000]  Значит, пусть P0 начальное распределение цепи в момент n равный нулю.
[20:32.000 --> 20:46.000]  Ну, я сказал, что у нас время натуральные числа, а тут вот еще n равное нулю появилось, но давайте добавим 0.
[20:46.000 --> 20:51.000]  Это удобнее все-таки считать, что в начальный момент времени не первый, а нулевой.
[20:51.000 --> 21:01.000]  Ну, некоторые, правда, считают, что ноль и является натуральным числом, но вот я помню, Арнольд это всегда горячо оспаривал.
[21:01.000 --> 21:12.000]  Ну, это, в общем, дело вкуса, считать ноль натуральным числом или нет, то есть, как говорят в школе, натуральные числа это те, которые при счете предметов,
[21:12.000 --> 21:22.000]  ну, вроде как предметов может не быть, тогда ноль вроде нужно включать, но большинство все-таки вроде склоняется к тому, что натуральные числа это от единицы начинается.
[21:22.000 --> 21:26.000]  Ну, в общем, во всяком случае давайте n равное нулю добавим.
[21:26.000 --> 21:32.000]  И, значит, что же это за, ну, начальное распределение?
[21:32.000 --> 21:41.000]  Это, значит, π0 это вероятностная мера на, ну, вот на этом множестве.
[21:41.000 --> 21:47.000]  Так, значит, чем она, ну, чем она задается?
[21:47.000 --> 21:53.000]  Она задается числами π0, ну, вот от этих икситых.
[21:53.000 --> 21:59.000]  Ну, здесь пока еще тоже не очень важно, что их, конечно, для счетных тоже самое, конечно, будет.
[21:59.000 --> 22:19.000]  И, значит, это вероятность того, что процесс, ну, вот принял такое значение, значит, в нулевой момент времени.
[22:19.000 --> 22:25.000]  Так, значит, что дальше происходит с процессом?
[22:25.000 --> 22:32.000]  Ну, пусть pn распределение кси n.
[22:32.000 --> 22:40.000]  Так.
[22:40.000 --> 22:44.000]  А?
[22:44.000 --> 22:46.000]  У кси, вот это?
[22:46.000 --> 22:49.000]  Ну, ноль.
[22:49.000 --> 22:55.000]  Значит, как происходит дальнейшая динамика?
[22:55.000 --> 22:57.000]  Так.
[22:57.000 --> 23:05.000]  Ну, скажем, π1, это будет π0 умножить на матрицу переходов.
[23:05.000 --> 23:13.000]  Значит, умножение справа.
[23:13.000 --> 23:15.000]  Ну, да.
[23:15.000 --> 23:19.000]  Множество состоений у нас, s1, sm.
[23:20.000 --> 23:24.000]  Ну, можно считать, что это 1m.
[23:24.000 --> 23:28.000]  Ну, это иногда удобно, иногда нет.
[23:28.000 --> 23:35.000]  Потому что иногда неудобно, что эти 1m могут путаться с моментами времени.
[23:35.000 --> 23:36.000]  Так.
[23:36.000 --> 23:46.000]  Вот поэтому, чтобы эти состояния не путать с моментами времени, давайте мы их будем пока, ну, пока можно вот этими.
[23:46.000 --> 23:51.000]  Ну, то есть, слушайте, не s1, какое s1, у меня x1 было, x1.
[23:51.000 --> 24:01.000]  Слушайте, это я вот, давайте я исправлю, как было в конспекте.
[24:01.000 --> 24:09.000]  Ну, кстати, конспект я на днях окончательно и пришлю, потому что кроме вот этих марковских цепей еще два вопроса осталось.
[24:09.000 --> 24:17.000]  Ну, сами понимаете, что это дело вкуса, как обозначать точки пространства.
[24:17.000 --> 24:21.000]  Ну, давайте, чтобы было согласование с конспектом, давайте я вот тут тоже исправлю.
[24:21.000 --> 24:28.000]  Значит, у меня осталось, собственно, конспект уже практически готов, два вопроса еще осталось.
[24:28.000 --> 24:39.000]  Это, значит, про ветвящийся процесс, значит, там дописать и про, значит, модель страхования.
[24:39.000 --> 24:40.000]  Так, вот два вопроса.
[24:40.000 --> 24:43.000]  Это там еще несколько парочка, там тройка страниц будет.
[24:43.000 --> 24:45.000]  Это я, в общем, на днях допишу и пришлю.
[24:45.000 --> 24:47.000]  Вот, значит, смотрите.
[24:47.000 --> 24:54.000]  Значит, почему умножение справа?
[24:55.000 --> 24:58.000]  Так, умножение справа.
[24:58.000 --> 25:01.000]  Это довольно необычно, так, это довольно необычно.
[25:01.000 --> 25:12.000]  Это если мы пишем, это если мы пишем, ну, вероятности, вероятности это строки.
[25:12.000 --> 25:29.000]  Так, и поэтому, чтобы, ну, вот, как умножают строку на столбец, так, ну, в смысле, строку на матрицу.
[25:29.000 --> 25:35.000]  Ну, вот, вот умножают это на первый столбец там и так далее.
[25:35.000 --> 25:42.000]  Помните, это с матрицами довольно не безобидная штука, как их умножать на векторы.
[25:42.000 --> 25:51.000]  Если векторы столбцы, так, то матрицу обычно пишут слева, ну, и умножают, ну, там, по соответствующему правилу.
[25:51.000 --> 26:02.000]  Ну, откуда здесь берется, ну, почему так странно, почему такое странное правило?
[26:02.000 --> 26:04.000]  Почему справа-то надо умножать?
[26:04.000 --> 26:06.000]  Так, ну, это вот почему.
[26:06.000 --> 26:16.000]  Давайте посмотрим, значит, что такое, значит, ну, значит, π1, ну, скажем, от х1.
[26:16.000 --> 26:27.000]  Так, это вероятность попасть в х1 в момент времени 1.
[26:27.000 --> 26:31.000]  Ну, как можно попасть в х1?
[26:31.000 --> 26:37.000]  В х1 можно попасть, находясь в нуле, но в одном из состояний, так.
[26:37.000 --> 26:44.000]  И поэтому нужно, значит, откуда можно было в х1 попасть?
[26:44.000 --> 26:50.000]  В х1 можно из х1 попасть, из х2, из хм, так.
[26:50.000 --> 26:53.000]  Значит, нужно просуммировать.
[26:53.000 --> 26:57.000]  По всем g от 1 до m, так.
[26:57.000 --> 27:13.000]  Вероятности перехода, значит, мы смотрим в, значит, в g, сейчас, ну, не в g, в i давайте.
[27:13.000 --> 27:23.000]  Значит, можно из разных i попасть в 1, так.
[27:23.000 --> 27:36.000]  Но при этом еще надо учесть, учесть на, ну, учесть вот эту, значит, вероятность того, что в момент 0 были в i, так.
[27:36.000 --> 27:41.000]  Значит, вот, видите, получается, вот такая формула получается.
[27:41.000 --> 27:48.000]  Так, а, значит, а, ну, что, что, что это происходит, так?
[27:48.000 --> 27:55.000]  Значит, ну, вот, вот, вот эта строка умножается, так, пиноль там 1 и так далее, так.
[27:55.000 --> 28:01.000]  Значит, это мы, это мы заполняем первый элемент, так.
[28:01.000 --> 28:04.000]  У нас вот эта новая вероятность, это опять строчка, так.
[28:04.000 --> 28:07.000]  Вот вы заполняете первый элемент этой строчки.
[28:07.000 --> 28:15.000]  Ну и что вы делаете? Вы берете строчку, исход нулевых, нулевых состояний, так.
[28:15.000 --> 28:18.000]  И на что умножаете? Ну, скалярно умножаете.
[28:18.000 --> 28:28.000]  Ну, вот на такой, как бы, вектор с компонентами, значит, p1, значит, 1, p2, 1 и так далее.
[28:28.000 --> 28:37.000]  Но, значит, и это кто? И, значит, это номер строки, так, в матрице.
[28:37.000 --> 28:46.000]  И поэтому получается, что вы идете по первому столбцу, так, значит, по первому столбцу.
[28:46.000 --> 28:53.000]  И вот, ну, у вас была строка, и вы, значит, взяли, значит, ну, строки этой матрицы.
[28:53.000 --> 29:00.000]  Вот так вот вы делаете. Вот, значит, вот такой вы выделили столбец.
[29:00.000 --> 29:03.000]  Этого умножили скалярно на это, получили тут элемент, так.
[29:03.000 --> 29:06.000]  Потом перешли к следующему столбцу, так.
[29:06.000 --> 29:09.000]  То есть, ну, такой получается довольно непривычный вид умножения,
[29:09.000 --> 29:13.000]  потому что все-таки большинство людей, которые...
[29:13.000 --> 29:17.000]  Ну, когда приходится матрицу умножать, как все привыкли умножать их,
[29:17.000 --> 29:20.000]  ну, так сказать, с левой на столбцы.
[29:20.000 --> 29:25.000]  Но почему так... Вот в этой науке так почему-то традиция делать так,
[29:25.000 --> 29:28.000]  ну, и я даже объясню, в чем такая традиция.
[29:28.000 --> 29:32.000]  Значит, как перевести в обычную традицию?
[29:32.000 --> 29:37.000]  Ну, казалось бы, очень просто. Пиши состояние, пиши столбцами.
[29:37.000 --> 29:41.000]  Кто тебя вынуждает в состояние писать строками? Пиши их столбцами.
[29:41.000 --> 29:43.000]  Ну, хорошо, будем писать столбцами.
[29:43.000 --> 29:47.000]  Но, увы, когда мы будем их писать столбцами,
[29:47.000 --> 29:52.000]  то для того, чтобы слева умножать, матрицу надо транспонировать, так.
[29:52.000 --> 29:55.000]  Но это не очень удобно, так.
[29:55.000 --> 30:00.000]  Вот как-то все привыкли, что лучше иметь дело не с матрицей,
[30:00.000 --> 30:04.000]  значит, ну, транспонированной, а с самой матрицей переходов.
[30:04.000 --> 30:06.000]  Это как-то вроде удобнее и нагляднее.
[30:06.000 --> 30:09.000]  Поэтому вот цена за это такая запись, так.
[30:09.000 --> 30:14.000]  Значит, обратите внимание, что матрица не обязательно симметричная.
[30:15.000 --> 30:19.000]  Конечно, если бы матрица была симметричная, то тут вообще никаких проблем нет.
[30:19.000 --> 30:22.000]  Можно сразу было писать столбцами и умножать слева.
[30:22.000 --> 30:26.000]  Но в том-то все и дело, что транспонированная матрица не обязательно совпадает с исходом.
[30:26.000 --> 30:32.000]  Потому что вероятность перейти из И в Ж совсем не та же самая, что из Ж в И.
[30:32.000 --> 30:36.000]  Поэтому это совсем не предполагается, так.
[30:36.000 --> 30:43.000]  Ну и у нее по строкам и столбцам, у нее, видите, разные свойства.
[30:43.000 --> 30:46.000]  Все элементы не отрицательные, так.
[30:46.000 --> 30:54.000]  Но сумма единиц получается именно по строкам, так.
[30:54.000 --> 31:03.000]  Значит, ну и в общем случае, значит, Pn, в общем случае Pn.
[31:03.000 --> 31:12.000]  Это P0 умножить на n, ну, по индукции из этого получается вот такая вот формула.
[31:12.000 --> 31:25.000]  То есть видите, получается, что если вам дана матрица перехода, так,
[31:25.000 --> 31:36.000]  то вот эти вот распределения в моменты n, они однозначно определены исходным нулевым распределением.
[31:36.000 --> 31:40.000]  Вот в той теореме, которую я выписывал без доказательства,
[31:40.000 --> 31:45.000]  там смотрите, как было, что если вам дана переходная функция,
[31:45.000 --> 31:53.000]  а здесь аналог переходной функции, это вот эта переходная матрица.
[31:53.000 --> 31:58.000]  Ну, вы скажете, переходная функция зависела от трех переменных, так.
[31:58.000 --> 32:02.000]  А куда они делись, эти переменные, так.
[32:02.000 --> 32:09.000]  Значит, вот у нас есть только, так сказать, вот эти два параметра, куда остальное это делось.
[32:09.000 --> 32:19.000]  Ну, значит, смотрите, как, значит, связь какая, ну, вот для однородного процесса.
[32:19.000 --> 32:23.000]  Значит, связь была вот такая, так.
[32:23.000 --> 32:31.000]  Ну, в смысле, вот функция была переходная такая, а здесь вот такая, так.
[32:31.000 --> 32:34.000]  Значит, кто кому соответствует, так.
[32:34.000 --> 32:42.000]  Вот, ну, так как-то можно ожидать, что вот этот, это, наверное, кто-то из этих, так.
[32:42.000 --> 32:44.000]  Но спрашивается, кто.
[32:44.000 --> 32:52.000]  Но с точки зрения вот этого, так, с точки зрения вот этого, этот, это вот кто такой.
[32:52.000 --> 33:02.000]  Это, значит, это х и вот этот стоит, так.
[33:02.000 --> 33:06.000]  Тут стоит единица, так.
[33:06.000 --> 33:09.000]  А тут стоит х ж.
[33:09.000 --> 33:16.000]  И видите, тут стояла вероятность из точки х за время t перейти в множество e.
[33:16.000 --> 33:26.000]  Но тут у нас для того, чтобы говорить о том, какая вероятность попасть во множество e,
[33:26.000 --> 33:33.000]  достаточно сказать, какая вероятность из точки х и попасть в одну точку.
[33:33.000 --> 33:36.000]  Не во множество, а в одну точку, причем за один шаг.
[33:36.000 --> 33:44.000]  Потому что если вы знаете, какая вероятность попасть в точку, то множество e тут состоит из точек.
[33:44.000 --> 33:50.160]  для общего e это просто будет сумма вот этих по этим, так, видите,
[33:50.160 --> 33:56.040]  тут получается такая связь вот этой общей функции, значит, переходной,
[33:56.040 --> 34:08.640]  получается такая связь, p значит x, t, e, получается так, x это один из этих,
[34:08.640 --> 34:16.480]  ну вот давайте сначала за один шаг, значит, вероятность попасть из точки x во множество e,
[34:16.480 --> 34:24.560]  значит, за один шаг, ну x это одна из x итых, так, и значит здесь будет, ну здесь будет сумма,
[34:24.560 --> 34:38.240]  значит, здесь будет сумма по j, по j таким, что xjt попало в e, так, будет вот это,
[34:38.240 --> 34:50.360]  p значит x и, ну вот тут тоже и это точка одна из этих, так, попасть в xj, так, ну а это как раз вот эти
[34:50.360 --> 34:57.960]  наши переходные вероятности, и поэтому, значит, тут нужно просуммировать по всем точкам из e,
[34:57.960 --> 35:09.120]  а вот эти вот p и j, так, вот, значит, вот это у нас получится за один шаг, но тут t не обязательно единица,
[35:09.120 --> 35:18.280]  а тут t, ну какое-то натуральное, но, соответственно, нужно что сделать, нужно, если тут t не единица,
[35:18.280 --> 35:26.160]  а какое-то натуральное t, то нужно здесь ставить элементы матрицы в степени t, так,
[35:26.160 --> 35:33.840]  все будет так же, как за один шаг, но только, значит, матрица перехода за n шагов, а матрица
[35:33.840 --> 35:39.280]  перехода за n шагов это просто степень исходной матрицы, так, связь вот такая получается, так,
[35:39.280 --> 35:48.400]  и теперь, значит, получается здесь аналог этой теоремы, которую я без доказательства сформулировал,
[35:48.400 --> 35:54.580]  аналог получается вот какой, но он более простой и по формулировке, и по доказательству, поэтому,
[35:54.580 --> 36:00.280]  поэтому его и можно доказать, значит, аналог получается вот какой. Значит, теорема, сейчас
[36:00.280 --> 36:13.780]  Давайте только, чтобы у меня хуже всего отойти обозначение конспекта.
[36:13.780 --> 36:36.780]  Теорема такая, пусть даны п и вот матрица п из этих вот элементов, м на м матрица.
[36:36.780 --> 36:54.780]  И начальное распределение п0 на х, значит, вот из м элементов, так? Значит, это дано.
[36:54.780 --> 37:18.780]  Тогда существует цепь Маркова.
[37:24.780 --> 37:42.780]  С пространством вот этим вот конечным х, значит, для которой п0 это распределение
[37:42.780 --> 38:07.780]  ксиноль, так? А вот эти вот переходные вероятности это условные, значит, меры того, что переходов за один шаг.
[38:07.780 --> 38:23.780]  То есть условные вероятности быть в момент n плюс 1 в xj при условии
[38:23.780 --> 38:39.780]  нахождения в момент, в предыдущий момент в и, в x и. Ну, поскольку мы интересуемся однородными цепями,
[38:39.780 --> 38:49.780]  то это, видите, это не зависит от n, видите? Вот однородность, значит, это как раз то, что это от n не зависит.
[38:49.780 --> 38:59.780]  Ну, давайте, давайте это докажем. Ну, естественно, доказывается с помощью теоремы Колмогорова.
[38:59.780 --> 39:12.780]  И это частный случай вот этой общей теоремы, поэтому, ну, как я говорил, если из этих переходных вероятностей
[39:12.780 --> 39:23.780]  сворганить, вот так, как я объяснял, переходные функции, то можно было бы это получить из той недоказанной теоремы для общих процессов.
[39:23.780 --> 39:33.780]  Но поскольку тут все довольно элементарно доказывается, ну, давайте докажем. Это, в общем, несложно, потому что все-таки хоть что-то надо с доказательством,
[39:33.780 --> 39:40.780]  потому что вот когда придут эти 150 человек, ну, невозможно же только формулировки у всех спрашивать.
[39:40.780 --> 39:47.780]  Ну, естественно, все формулировки там спишут откуда-то. Ну, конечно, можно сказать, что и доказательства можно списать,
[39:47.780 --> 39:54.780]  но это, вы же знаете, когда списано доказательства, то это еще вопрос, поняты ли оно, его можно обсуждать.
[39:54.780 --> 40:01.780]  Вот про формулировку трудно обсуждать, понята она или нет. Если она написана правильно, то что тут обсуждать, так?
[40:01.780 --> 40:08.780]  Поэтому вот, значит, в этом, значит, некоторый смысл, чтобы кое-что было с доказательством.
[40:08.780 --> 40:25.780]  Значит, доказательства. Ну, можно считать, применим теорему Колмогорова,
[40:25.780 --> 40:35.780]  значит, считая, что х лежит в R, ну, например, что х и ты, это просто и.
[40:35.780 --> 40:54.780]  Значит, теперь давайте, значит, берем, ну, вместо, значит, у нас распределение, распределение конечномерное,
[40:54.780 --> 41:07.780]  значит, в моменты времени 1n, значит, определим вот по такой формуле.
[41:24.780 --> 41:44.780]  Значит, смотрите, что это за распределение, так?
[41:44.780 --> 41:58.780]  Значит, мы хотим, значит, мы хотим задать совместные распределения.
[41:58.780 --> 42:17.780]  Сейчас только не em, а en должно быть здесь, здесь должно быть en, значит, en должно быть.
[42:17.780 --> 42:31.780]  Ну, эти i1 и n, они вот, значит, среди первых m, так?
[42:31.780 --> 42:40.780]  Значит, смотрите, что это за распределение?
[42:40.780 --> 42:53.780]  Ну, я напомню, для теоремы Колмогорова нам нужно задавать совместные распределения, так?
[42:53.780 --> 43:01.780]  Вот у нас еще случайных величин нет, а мы, значит, хотим задать совместные распределения, так?
[43:01.780 --> 43:09.780]  А, значит, поэтому, значит, если так задать, значит, если так задать, то получится следующее.
[43:09.780 --> 43:24.780]  Проекция, проекция вот этого на rn есть, ну, предыдущая, так?
[43:24.780 --> 43:33.780]  Но я напомню, что нам нужно задавать совместные распределения не только подряд в моменты времени, так?
[43:33.780 --> 43:39.780]  А нужно еще в какие-то моменты с пропусками, так?
[43:39.780 --> 43:53.780]  Поэтому, значит, остальные, нужно еще вот, значит, вот такие вот нужно задавать, так?
[43:53.780 --> 44:05.780]  Значит, там в какие-то моменты t1, значит, там tk, так, где t1 меньше tk.
[44:05.780 --> 44:24.780]  Значит, зададим, ну, ну, где они, значит, где они не подряд, ну, вот эти вот 1k, значит, зададим как проекции.
[44:24.780 --> 44:46.780]  Ну, например, значит, например, значит, p, значит, p2, 3, это проекция p1, p2, 3 на, значит, r2.
[44:46.780 --> 44:51.780]  Нам же еще вот такие нужно задавать, так?
[44:51.780 --> 45:02.780]  Но при этом, при этом, ну, вот это я не проверил, почему так будет согласование.
[45:02.780 --> 45:19.780]  Но это из условия, значит, давайте я напишу, это из условия, что сумма поезжитых пожи равняется единице.
[45:19.780 --> 45:29.780]  Вот из этого условия непосредственно проверяется, значит, когда сдаешь по такой формуле, что будут согласованы.
[45:29.780 --> 45:40.780]  Но нам, смотрите, для теоремы Колмогорова, там ведь надо проверять не только в подряд идущие моменты, так, согласованность, но и с пропусками.
[45:40.780 --> 45:49.780]  Их задавать тоже нужно, но мы их задаем так, ну, в принципе, можно формулой, конечно, написать, но формула будет еще более громоздкой, так?
[45:49.780 --> 45:58.780]  А проще словами сказать, что когда эти не подряд, так, то мы просто как проекции их зададим.
[45:58.780 --> 46:04.780]  Но при желании можно было по аналогичной, но такой более громоздкой формулой это и записать, так?
[46:04.780 --> 46:14.780]  Но из-за того, что вот эти согласованы, то, ну, проекции тоже получится согласованы, так?
[46:14.780 --> 46:21.780]  Поэтому у нас получилась согласованная система, так?
[46:21.780 --> 46:24.780]  И что дает теорема Колмогорова?
[46:24.780 --> 46:44.780]  Значит, теорема Колмогорова дает процесс, дает процесс, ну, ксиен, ну, с такими, с такими распределениями, так?
[46:44.780 --> 46:49.780]  Ну, но почему две вещи надо проверять?
[46:49.780 --> 46:55.780]  Ну, почему ксиен Марковский, так?
[46:55.780 --> 47:03.780]  Значит, вот это первое, что не очевидно, потому что Колмогоров ничего там про Марковский не обещал, но дает процесс.
[47:03.780 --> 47:09.780]  Вот задали вы конечное мерное распределение, получили процесс, а мы обещали процесс Марковский.
[47:09.780 --> 47:12.780]  Почему он получился Марковский, вот это надо проверять.
[47:12.780 --> 47:18.780]  Ну, и второе, что нужно проверять, значит, сейчас это второе у меня или первое.
[47:18.780 --> 47:29.780]  Ну, еще, ну, это у меня второе, но проверим моего первое.
[47:29.780 --> 47:40.780]  А вот еще, почему, значит, почему у нас будет, ну, значит, это хорошо, это Марковский процесс, конечно,
[47:40.780 --> 47:54.780]  но почему он будет, вот, ну, так сказать, с такой переходной функцией?
[47:54.780 --> 47:59.780]  Ну, вот, лучше сказать, почему с такими условными вероятностями?
[47:59.780 --> 48:20.780]  Вот это еще тоже, значит, у нас, ну, получился какой-то процесс, ну, хорошо.
[48:20.780 --> 48:22.780]  А почему он Марковский?
[48:22.780 --> 48:29.780]  Ну, Колмогоров всего-навсего обещает, что у него, конечно, мерные распределения такие, какие выписаны.
[48:29.780 --> 48:32.780]  Но, а, с какой стати он Марковский?
[48:32.780 --> 48:45.780]  Б, мы же хотели, чтобы это была Марковская цепь с такими переходами, а Колмогоров на этот счет ничего, так сказать, не обещает.
[48:45.780 --> 48:48.780]  Поэтому и то, и другое нужно проверить.
[48:48.780 --> 48:55.780]  Ну, вот, собственно, в той теореме, которую я написал без доказательства, там тоже, конечно, все это надо проверять,
[48:55.780 --> 48:59.780]  и там эта проверка, ну, она более техническая.
[48:59.780 --> 49:08.780]  Но давайте мы хотя бы, значит, в случае конечной цепи увидим, что, ну, все это руками проверяется, в общем, довольно-таки несложно.
[49:08.780 --> 49:13.780]  Значит, смотрите, проверяем последнее.
[49:13.780 --> 49:18.780]  Вот это, значит, последнее просто.
[49:18.780 --> 49:24.780]  Последнее сводится вот к чему.
[49:43.780 --> 49:59.780]  Вот это, вот к чему сводится последнее.
[49:59.780 --> 50:09.780]  Ну, давайте, ну, последнее, последнее очевидно.
[50:09.780 --> 50:17.780]  Последнее очевидно.
[50:17.780 --> 50:23.780]  Ну, смотрите, что такое вот эта штука?
[50:30.780 --> 50:34.780]  Значит, видите, это, смотрите, что это такое?
[50:34.780 --> 50:46.780]  Это двумерное распределение, но у нас была формула для конечномерных распределений.
[50:46.780 --> 50:48.780]  Там такого не было.
[50:48.780 --> 50:51.780]  Это как раз тот случай, когда надо проекции убрать.
[50:51.780 --> 50:56.780]  Потому что у нас, смотрите, видите, только последние две позиции заданы.
[50:56.780 --> 51:03.780]  Вот у нас там была формула, когда все от 1 до n позиции заданы.
[51:03.780 --> 51:05.780]  А тут, видите, не так.
[51:05.780 --> 51:09.780]  Значит, из чего складывается эта штука?
[51:09.780 --> 51:16.780]  Ну, она складывается из заданий по всем позициям, но только первые у вас какие угодно.
[51:16.780 --> 51:20.780]  Поэтому это, смотрите, что это будет за сумма?
[51:20.780 --> 51:26.780]  Значит, это сумма вот таких вот произведений.
[51:51.780 --> 52:01.780]  Значит, вот по всем, значит, по всем и1, и так далее, и n-2.
[52:01.780 --> 52:13.780]  Так, вот, значит, но, значит, давайте посмотрим.
[52:13.780 --> 52:19.780]  Значит, давайте посмотрим на эту сумму без последнего множителя.
[52:19.780 --> 52:25.780]  Так, значит, сумма без последнего множителя вот эта.
[52:25.780 --> 52:28.780]  Ну, вот, вот этот последний.
[52:28.780 --> 52:30.780]  Ну, вот этот, вот этот, вот он.
[52:30.780 --> 52:33.780]  Ну, это вот тот же самый, который здесь стоит.
[52:33.780 --> 52:37.780]  Ну, это переход из и в жи.
[52:37.780 --> 52:47.780]  Значит, сумма без вот этого последнего.
[52:47.780 --> 52:57.780]  Есть как раз...
[52:57.780 --> 53:02.780]  Меньше чего? Нет, почему? Они какие угодно.
[53:02.780 --> 53:05.780]  Нет, эти какие угодно.
[53:05.780 --> 53:09.780]  Нет, эти какие угодно.
[53:10.780 --> 53:18.780]  Тут же, когда у нас пишутся эти вероятности переходов, они же не упорядочены по большему, меньшему.
[53:18.780 --> 53:21.780]  Они всевозможные.
[53:21.780 --> 53:33.780]  Значит, смотрите, это будет как раз, будет как раз вероятность вот этого.
[53:33.780 --> 53:36.780]  Так, почему?
[53:36.780 --> 53:43.780]  Потому что это у нас считается...
[53:43.780 --> 53:51.780]  Ну, значит, это у нас, это у нас охвачено нашей формулой было.
[53:56.780 --> 54:03.780]  Ну, собственно, из нашей формулы, из нашей формулы вытекает, что вот такая вероятность...
[54:03.780 --> 54:08.780]  Обратите внимание, эта вероятность, она тоже не есть частный, она тоже не есть частный случай формулы,
[54:08.780 --> 54:12.780]  потому что у нас формулы всегда от единицы до этого.
[54:12.780 --> 54:18.780]  Но какова вероятность того, что в этот момент это равно вот этому?
[54:18.780 --> 54:31.780]  Это вам нужно сложить всевозможные, выстраиваете, что могло быть в предыдущие моменты.
[54:31.780 --> 54:35.780]  И в предыдущие моменты могло быть что угодно.
[54:35.780 --> 54:41.780]  И вот вы складываете все эти возможности по предыдущим моментам, выстраиваете.
[54:41.780 --> 54:48.780]  Вот тут нет предыдущих времен, а вы их искусственно добавляете, и в них могло быть что угодно.
[54:48.780 --> 54:59.780]  Но из нашей формулы как раз получается, когда вы выстраиваете эти предыдущие моменты по всем этим возможностям, то у вас как раз вот это получается.
[54:59.780 --> 55:09.780]  В этом как раз и состоит то, как мы получаем проекцию.
[55:09.780 --> 55:24.780]  У нас исходная формула для мер на Rn, а тут проекция такой меры на Rn-1, на последний сомножитель.
[55:24.780 --> 55:28.780]  Вот она считается по такой формуле.
[55:28.780 --> 55:32.780]  Поэтому с этим равенством OK.
[55:32.780 --> 55:36.780]  А еще нам нужно для марковости.
[55:36.780 --> 55:39.780]  Эта вещь совсем безобидная.
[55:39.780 --> 55:43.780]  Больше возни с марковостью.
[55:43.780 --> 55:46.780]  С марковостью несколько больше возни.
[55:47.780 --> 55:52.780]  Марковость.
[55:52.780 --> 56:00.780]  Марковость – это условная независимость прошлого и будущего, прификсированном настоящим.
[56:00.780 --> 56:11.780]  И для общего марковского процесса все эти проверки довольно гнусные, теоретико множественные, всякие выкладки.
[56:11.780 --> 56:20.780]  Но здесь нам нужно из-за того, что все дискретно и конечно, нам нужно вот что проверить.
[56:20.780 --> 56:37.780]  Что P от XiM равняется I, а XiN равняется J, при условии, что XiT равняется L.
[56:37.780 --> 56:48.780]  Что это распадается в произведение, вот что означает.
[56:54.780 --> 57:00.780]  И это когда? Это когда M меньше T и меньше N.
[57:00.780 --> 57:11.780]  Вот видите, это момент из прошлого, это момент из будущего, это прификсированном настоящем.
[57:11.780 --> 57:14.780]  И вот они должны так распадаться.
[57:14.780 --> 57:20.780]  В общем определении марковости там стоит похуже, там стоят множество.
[57:20.780 --> 57:27.780]  Но у нас тут все конечно, поэтому множество составляется из точек.
[57:27.780 --> 57:33.780]  И поэтому если для точечных значений, видите, у нас множество очень простые.
[57:33.780 --> 57:37.780]  Общее множество это конечное объединение таких.
[57:37.780 --> 57:46.780]  Но если мы вот так сможем для точечных множества раздрабливать, то для общих конечных также будет.
[57:46.780 --> 57:52.780]  Вот эту формулу нужно проверить.
[57:52.780 --> 57:56.780]  Калмагуров ее так не обещал.
[57:56.780 --> 58:03.780]  Он сказал, вот вам будет процесс, а уж что там с этим процессом, это уж там дальше сами разбираетесь с ним.
[58:03.780 --> 58:09.780]  Ну вот мы сейчас с этим процессом и разбираемся.
[58:09.780 --> 58:17.780]  Смотрите, как это можно преобразовать.
[58:17.780 --> 58:27.780]  Естественно, мы хотим это проверить.
[58:27.780 --> 58:41.780]  Для проверки заметим, ну это еще из предыдущего вытекает, что вероятность того, что вот это равно j,
[58:41.780 --> 58:48.780]  при том, что xk равно i, это будет вот что.
[58:48.780 --> 58:55.780]  Это считается с помощью степени матрицы.
[58:55.780 --> 58:57.780]  Вот это из предыдущего вытекает.
[58:57.780 --> 59:01.780]  Ну, в общем, это то, что мы уже доказали.
[59:01.780 --> 59:04.780]  Это дает такую формулу.
[59:04.780 --> 59:17.780]  Смотрите, это вероятность попадания из i в j за n шагов.
[59:17.780 --> 59:23.780]  Ну и причем неважно, с какого момента, с какого k мы начали.
[59:23.780 --> 59:32.780]  У нас так сразу процесс получается однородным, просто по построению.
[59:32.780 --> 59:37.780]  Это следствие предыдущей формулы.
[59:37.780 --> 59:52.780]  А это индекс, это у нас матрица вот эта, и ее элементы, это вот эти числа.
[59:52.780 --> 59:55.780]  Ну то есть это, конечно, не степени этих чисел.
[59:55.780 --> 01:00:01.780]  Ну вот выписать, кто такие, это, конечно же, невозможно.
[01:00:01.780 --> 01:00:07.780]  Потому что у вас даже когда матрица дана, но попробуйте-ка ее возвести в здоровую степень.
[01:00:07.780 --> 01:00:15.780]  Это понятно, что эти числа, они конкретные какие-то, но физически их найти обычно нельзя, конечно.
[01:00:15.780 --> 01:00:22.780]  И тогда смотрите, что нам нужно, к чему сводится наша проверка.
[01:00:22.780 --> 01:00:27.780]  Значит, нам надо.
[01:00:27.780 --> 01:00:30.780]  Смотрите, что нам надо.
[01:00:30.780 --> 01:00:36.780]  А кто такие эти условные вероятности?
[01:00:36.780 --> 01:00:40.780]  Это же тут все дискретно, и поэтому условная вероятность, это очень банально.
[01:00:40.780 --> 01:00:43.780]  Это вероятность пересечения делить на вероятность условия.
[01:00:43.780 --> 01:00:46.780]  Они стали тут школьными.
[01:00:46.780 --> 01:00:50.780]  В предыдущей общей теореме там все не так банально.
[01:00:50.780 --> 01:00:56.780]  Там всякие условные вероятности, они не считаются, как чего-то там, что-то на что-то делить.
[01:00:56.780 --> 01:01:00.780]  Но здесь считаются, и это, конечно, здорово упрощает дело.
[01:01:00.780 --> 01:01:03.780]  Именно поэтому тут можно добраться до конца.
[01:01:03.780 --> 01:01:06.780]  Значит, нам нужно, смотрите, что.
[01:01:06.780 --> 01:01:15.780]  Нам нужно, что вероятность вот такая тройственного такого события, тройственного пересечения.
[01:01:20.780 --> 01:01:34.780]  Умножить на вероятность вот этого, есть произведение двух.
[01:01:50.780 --> 01:02:00.780]  Чем это отличается от того, что нужно?
[01:02:00.780 --> 01:02:12.780]  Я просто внес всюду эти условия сюда, и еще поделил на эту вероятность.
[01:02:12.780 --> 01:02:20.780]  Но видите, здесь она дважды, вот эта вот вероятность, видите, здесь она дважды.
[01:02:20.780 --> 01:02:22.780]  Тут два раза.
[01:02:22.780 --> 01:02:24.780]  А тут только один.
[01:02:24.780 --> 01:02:34.780]  И поэтому нужно, чтобы получилось равенство после перехода к пересечениям, нужно левую часть еще на нее домножить.
[01:02:34.780 --> 01:02:37.780]  Вот такая формула получается.
[01:02:37.780 --> 01:02:40.780]  Вы скажете, формула, конечно, довольно гнусная.
[01:02:40.780 --> 01:02:48.780]  Потому что, видите, эта штука, она даже еще и не охватывается нашей формулой.
[01:02:48.780 --> 01:02:56.780]  Потому что наша формула для конечномерных распределений, она была только для, когда у вас подряд моменты идут времени.
[01:02:56.780 --> 01:03:03.780]  А здесь моменты идут с возрастанием.
[01:03:04.780 --> 01:03:09.780]  Сейчас только тут, тут М.
[01:03:09.780 --> 01:03:12.780]  Тут опечатка, тут М.
[01:03:12.780 --> 01:03:15.780]  Ну да, тут тот же самый М.
[01:03:15.780 --> 01:03:21.780]  Значит, М самый маленький, Т побольше, Н еще больше.
[01:03:21.780 --> 01:03:27.780]  И вот если бы это было 1, 2, 3, то это было бы то, что у нас написано.
[01:03:27.780 --> 01:03:30.780]  Но это, к сожалению, не 1, 2, 3.
[01:03:30.780 --> 01:03:35.780]  А эта штука с точки зрения нашей общей формулы, это вот что такое.
[01:03:35.780 --> 01:03:46.780]  Это нужно взять все-таки всех 1 до N и эти зафиксировать, а потом суммировать по всем прочим, которых тут нет.
[01:03:46.780 --> 01:03:52.780]  Так что для этого формулу можно записать, но она довольно гнусная будет формула.
[01:03:52.780 --> 01:03:57.780]  Я даже в конспекте ее не стал писать.
[01:03:57.780 --> 01:04:08.780]  Вот, и поэтому, для того чтобы получить то, что нам нужно, нам...
[01:04:14.780 --> 01:04:23.780]  Значит, смотрите, вот тут, вот тут уже произошли некоторые улучшения с учетом вот этой формулы.
[01:04:23.780 --> 01:04:30.780]  Значит, смотрите, что получается.
[01:04:30.780 --> 01:04:35.780]  Из предыдущей формулы получается следующее.
[01:04:35.780 --> 01:04:37.780]  Значит...
[01:04:51.780 --> 01:04:53.780]  Значит, это будет...
[01:04:55.780 --> 01:05:02.780]  Значит, мы ее опять вот так вот запишем.
[01:05:05.780 --> 01:05:12.780]  И это мы запишем по предыдущей формуле.
[01:05:28.780 --> 01:05:33.780]  Вот так получается такая формула.
[01:05:33.780 --> 01:05:38.780]  Значит, что нам надо?
[01:05:41.780 --> 01:05:45.780]  Значит, надо вот что нам проверить.
[01:05:45.780 --> 01:05:52.780]  Что вот это тройственное пересечение...
[01:05:52.780 --> 01:05:58.780]  Ну да, да.
[01:05:58.780 --> 01:06:06.780]  Нет, ну не совсем обратно, потому что у нас сейчас кое-что сократится.
[01:06:06.780 --> 01:06:10.780]  Значит, смотрите, что нам в итоге надо.
[01:06:22.780 --> 01:06:27.780]  Значит, вот что нам надо доказать.
[01:06:45.780 --> 01:06:50.780]  О, вот у нас к чему свелось.
[01:06:50.780 --> 01:07:00.780]  Это у нас буквально на мгновение мы перешли опять к условной вероятности для того, чтобы у нас кое-что сократилось.
[01:07:00.780 --> 01:07:04.780]  И итоговый...
[01:07:04.780 --> 01:07:08.780]  Итог, что нам нужно проверять.
[01:07:08.780 --> 01:07:14.780]  Пока что мы так немножко улучшаем свою позицию потихонечку.
[01:07:15.780 --> 01:07:22.780]  Но пока что у нас основная головная боль, это вот это тройственные пересечения.
[01:07:22.780 --> 01:07:29.780]  Все эти предыдущие вещи показывают, что двойные пересечения, это вещь довольно безобидная.
[01:07:29.780 --> 01:07:32.780]  С ними мы довольно лихо разделываемся.
[01:07:32.780 --> 01:07:36.780]  А вот основная головная боль, это тройственные пересечения.
[01:07:36.780 --> 01:07:43.780]  Ну, значит, давайте докажем эту формулу.
[01:07:50.780 --> 01:07:53.780]  Значит, давайте докажем эту формулу.
[01:07:53.780 --> 01:07:57.780]  Значит, смотрите, что...
[01:07:57.780 --> 01:08:04.780]  Эта формула, на самом деле, смысл ее более-менее понятен.
[01:08:04.780 --> 01:08:07.780]  Видите, как она устроена, эта формула.
[01:08:07.780 --> 01:08:11.780]  На самом деле, тут хочется объявить, что это очевидно.
[01:08:11.780 --> 01:08:15.780]  Но это было бы очевидно, если бы это уже была Марковская цепь.
[01:08:15.780 --> 01:08:17.780]  А вот смотрите, почему это очевидно.
[01:08:17.780 --> 01:08:19.780]  Потому что, смотрите, о чем говорит...
[01:08:19.780 --> 01:08:20.780]  Что это за событие?
[01:08:20.780 --> 01:08:31.780]  Это событие говорит, что у вас вы в какой-то момент в прошлом были в И, в настоящем оказались в Л, а в будущий момент оказались в Ж.
[01:08:31.780 --> 01:08:34.780]  А что правая часть говорит?
[01:08:34.780 --> 01:08:41.780]  Она говорит, что нужно зафиксировать вот этот кусок, прошлое и настоящее,
[01:08:41.780 --> 01:08:54.780]  и умножить это, что вот эта вероятность получается умножением того, что вот у вас такая предыстория,
[01:08:54.780 --> 01:09:00.780]  на вероятность перейти из Л в Ж за N-1 шагов.
[01:09:00.780 --> 01:09:12.780]  Тут как раз вроде это и написано, что вы в этот момент в И, в момент Т в Л,
[01:09:12.780 --> 01:09:17.780]  а через время N-T вы попали в Ж.
[01:09:17.780 --> 01:09:23.780]  Ну и вроде бы у вас ровно это и написано.
[01:09:23.780 --> 01:09:33.780]  Это обозначение формулы.
[01:09:33.780 --> 01:09:36.780]  Это обозначение уже не к формуле относится.
[01:09:36.780 --> 01:09:37.780]  Формула закончилась.
[01:09:37.780 --> 01:09:40.780]  Ну давайте я подальше это унесу.
[01:09:40.780 --> 01:09:44.780]  Это формула звездочка.
[01:09:44.780 --> 01:09:51.780]  Значит, смотрите, эта формула так и интуитивно кажется понятной.
[01:09:51.780 --> 01:09:55.780]  Но нам нужно как-то все-таки исходя...
[01:09:55.780 --> 01:10:02.780]  Ведь у нас, понимаете как, у нас вот это-то определяется некой конкретной формулой,
[01:10:02.780 --> 01:10:04.780]  от нас независящей.
[01:10:04.780 --> 01:10:08.780]  И нам нужно как-то использовать эту формулу.
[01:10:08.780 --> 01:10:13.780]  Ведь пока что надо признать, что мы нашу создающую формулу для распределений,
[01:10:13.780 --> 01:10:18.780]  что мы по-честному для тройственных пересечений, мы ее не использовали.
[01:10:18.780 --> 01:10:21.780]  Мы ее использовали только для одинарных и для двойных.
[01:10:21.780 --> 01:10:23.780]  А для тройственных не использовали.
[01:10:23.780 --> 01:10:29.780]  И поэтому ясно, что тут было бы, так сказать, не очень честно сказать, что теперь все очевидно.
[01:10:29.780 --> 01:10:40.780]  Значит, смотрите, при n равном t плюс 1 это вот что.
[01:10:40.780 --> 01:10:42.780]  Это вот какая формула.
[01:10:48.780 --> 01:11:11.780]  Так.
[01:11:11.780 --> 01:11:15.780]  Значит, это...
[01:11:15.780 --> 01:11:21.780]  Значит, что можно сказать про эту формулу?
[01:11:21.780 --> 01:11:25.780]  Откуда эта формула взялась?
[01:11:25.780 --> 01:11:29.780]  Ну, она вытекает...
[01:11:29.780 --> 01:11:32.780]  Значит, это верно.
[01:11:32.780 --> 01:11:35.780]  Значит, это верно из задающей формулы.
[01:11:35.780 --> 01:11:44.780]  M.
[01:11:44.780 --> 01:11:48.780]  Ну, тот же, который здесь, M.
[01:11:48.780 --> 01:11:51.780]  Индексы не меняются. У нас вот есть эти три момента.
[01:11:51.780 --> 01:11:56.780]  M, значит, меньше t настоящий и следующий.
[01:11:56.780 --> 01:12:00.780]  Значит, вот смотрите, когда следующий он буквально следующий,
[01:12:00.780 --> 01:12:05.780]  то это получается, это следует из нашей формулы задающей.
[01:12:05.780 --> 01:12:10.780]  Ну, вот если посмотреть, какая будет.
[01:12:10.780 --> 01:12:13.780]  Вот действительно так оно и будет.
[01:12:13.780 --> 01:12:31.780]  Теперь, пусть верно при каком-то n больше t.
[01:12:31.780 --> 01:12:40.780]  Тогда верно при n плюс 1.
[01:12:40.780 --> 01:12:48.780]  Значит, давайте посмотрим, что будет при n плюс 1.
[01:12:48.780 --> 01:13:07.780]  Значит, при n плюс 1 будет следующее.
[01:13:07.780 --> 01:13:11.780]  Значит, это по определению будет вот что.
[01:13:11.780 --> 01:13:32.780]  Это будет вот такая сумма.
[01:13:32.780 --> 01:13:44.780]  Значит, в момент времени n это может быть какое-то k.
[01:13:44.780 --> 01:13:48.780]  Ну и вот мы пока это просуммируем.
[01:13:48.780 --> 01:14:06.780]  Ну, давайте я повыше напишу.
[01:14:06.780 --> 01:14:12.780]  Значит, смотрите, это по предположению индукции.
[01:14:12.780 --> 01:14:17.780]  Это есть сумма по k.
[01:14:42.780 --> 01:15:09.780]  Потому что сумма по k дает как раз следующую степень матрицы.
[01:15:09.780 --> 01:15:14.780]  Поэтому, тем самым получается верно для n плюс 1.
[01:15:14.780 --> 01:15:21.780]  Ну и вот тем самым по индукции получается, что все проверено.
[01:15:21.780 --> 01:15:32.780]  Индекс k, тут k и тут k.
[01:15:32.780 --> 01:15:47.780]  Смотрите, свертка вот этого пока дает следующую степень матрицы.
[01:15:47.780 --> 01:15:56.780]  Сейчас, суммы нет.
[01:15:56.780 --> 01:16:01.780]  Тут уже нет суммы, это я механически переписал.
[01:16:01.780 --> 01:16:03.780]  Тут никакой суммы уже нет.
[01:16:03.780 --> 01:16:06.780]  Тут просто уже ответ, который мы хотели получить.
[01:16:06.780 --> 01:16:10.780]  Тут никакой суммы уже нет, конечно.
[01:16:10.780 --> 01:16:20.780]  Значит, смотрите, если посмотреть, как доказывается вот та теорема, которую я привел без доказательства,
[01:16:20.780 --> 01:16:26.780]  то там нечто похожее исполняется на уровне измеримых функций.
[01:16:27.780 --> 01:16:32.780]  Аналогично и проверяются тождества, но там, к сожалению, не будет сумм.
[01:16:32.780 --> 01:16:35.780]  И там к точкам все не сводится.
[01:16:35.780 --> 01:16:41.780]  И там поэтому как проверяются всякие равенства для условных вероятностей.
[01:16:41.780 --> 01:16:46.780]  Там равенства для интегралов.
[01:16:46.780 --> 01:16:50.780]  Ну они немножко более громоздкие получаются.
[01:16:50.780 --> 01:16:53.780]  У нас даже и здесь нельзя сказать, что как-то все очень элегантно.
[01:16:53.780 --> 01:16:58.780]  Естественно, если вместо суммы у вас интегралы по множеству,
[01:16:58.780 --> 01:17:01.780]  ну несколько более громоздко будет.
[01:17:01.780 --> 01:17:07.780]  Ну и как мне кажется, там несколько труднее следить за ходом вычислений.
[01:17:07.780 --> 01:17:10.780]  Но в принципе идея такая же.
[01:17:10.780 --> 01:17:14.780]  Точно так же проверяются, там нужно тоже две вещи проверить.
[01:17:14.780 --> 01:17:21.780]  Там согласованность получается легко, тут особой роли нет в дискретности.
[01:17:21.780 --> 01:17:23.780]  А вот дальше нужно проверить.
[01:17:23.780 --> 01:17:26.780]  Калмагоров дал некий процесс.
[01:17:26.780 --> 01:17:30.780]  И вот почему он марковский, и почему у него получилась нужная переходная функция,
[01:17:30.780 --> 01:17:36.780]  ну вот там проверяется похоже, но технически я бы сказал немножко более муторно.
[01:17:36.780 --> 01:17:42.780]  Здесь конечно тоже нельзя сказать, что совсем не муторно,
[01:17:42.780 --> 01:17:45.780]  но по крайней мере тут никаких хитростей нет.
[01:17:45.780 --> 01:17:49.780]  Просто прямолинейно проверяем, так сказать, и все.
[01:17:49.780 --> 01:18:00.780]  Так, теперь последнее, что я скажу, а следующий раз мы это уже докажем.
[01:18:00.780 --> 01:18:06.780]  Значит, определение.
[01:18:06.780 --> 01:18:20.780]  Вероятностная мера π на х инвариантна для цепи.
[01:18:20.780 --> 01:18:24.780]  Ну или стационарна.
[01:18:24.780 --> 01:18:37.780]  А если она не меняется, ну если она, так сказать, собственный вектор в этой матрице.
[01:18:37.780 --> 01:18:43.780]  То есть тогда получается, что тогда получается?
[01:18:43.780 --> 01:18:50.780]  Значит, тогда получается, что распределение, если вы начали, значит получается,
[01:18:50.780 --> 01:18:57.780]  если вы начали с инвариантного распределения, то оно не меняется с ходом времени.
[01:18:57.780 --> 01:19:04.780]  Ну и вот последний факт, очень простой, на котором мы сейчас кончим.
[01:19:04.780 --> 01:19:09.780]  Значит, теорема.
[01:19:09.780 --> 01:19:20.780]  Значит, существует инвариантная вероятностная мера π.
[01:19:20.780 --> 01:19:26.780]  Значит, доказательство очень простое.
[01:19:26.780 --> 01:19:42.780]  А симплекс, ну скажем, П, ну там или С, симплекс С всех вероятностных мер,
[01:19:42.780 --> 01:19:58.780]  мер на х, отображается в С, ну посредством, ну оператором П.
[01:19:58.780 --> 01:20:00.780]  Ну и смотрите, какая ситуация.
[01:20:00.780 --> 01:20:09.780]  Значит, у вас есть конечномерный выпуклый компакт, он, значит, отображается в себя.
[01:20:09.780 --> 01:20:16.780]  Значит, существует неподвижная точка, неподвижная точка.
[01:20:16.780 --> 01:20:25.780]  Ну, например, это вытекает из теоремы Боля-Брауэра.
[01:20:25.780 --> 01:20:29.780]  Эта теорема, конечно, гораздо мощнее, чем нам нужно.
[01:20:29.780 --> 01:20:34.780]  Значит, эта теорема для каких угодно непрывных отображений симплексов себя.
[01:20:34.780 --> 01:20:40.780]  А у нас отображение линейное.
[01:20:40.780 --> 01:20:44.780]  Поэтому, конечно, это, так сказать, некоторая такая стрельба из пушки по веробьям.
[01:20:44.780 --> 01:20:52.780]  Но с другой стороны, если можно, так сказать, подстрелить одним выстрелом, то чего тогда мучиться, так сказать, и ходить с рогатками.
[01:20:52.780 --> 01:21:06.780]  Значит, в следующий раз будет еще одно утверждение о специфических инвариантных мерах.
[01:21:06.780 --> 01:21:09.780]  Ну и на этом цепи Маркова кончатся.
[01:21:09.780 --> 01:21:12.780]  И будут еще две очень специальных задачи.
[01:21:12.780 --> 01:21:25.780]  Это задача о ветвящемся процессе Гальтына Ватсена и конкретная задача о разорении в модели страхования.
[01:21:25.780 --> 01:21:30.780]  Вот это уже, так сказать, как примеры, что ли, будут.
[01:21:30.780 --> 01:21:39.780]  Но поскольку здесь, как я понял, в курсах случайных процессов на физтехе как-то принято эти две вещи рассказывать.
[01:21:39.780 --> 01:21:43.780]  Ну я тоже решил, так сказать, по традиции это включить.
[01:21:43.780 --> 01:21:47.780]  Ну и вот смотрите, остается следующая лекция.
[01:21:47.780 --> 01:21:50.780]  И еще одна между майскими праздниками.
[01:21:50.780 --> 01:21:55.780]  Ну и вот я, естественно, буду прилагать усилия, чтобы оставшиеся за эти две лекции рассказать.
[01:21:55.780 --> 01:22:00.780]  И чтобы, ну, значит, 5-го числа, чтобы закончить.
[01:22:00.780 --> 01:22:02.780]  Вот, в общем, так сказать, план такой.
[01:22:02.780 --> 01:22:07.780]  Но, в принципе, теоретически у вас еще 12-го есть лекция.
[01:22:07.780 --> 01:22:11.780]  А потом чуть ли даже и не 19-го.
[01:22:11.780 --> 01:22:14.780]  Но это уже какие-то крайности, в общем, я думаю.
[01:22:14.780 --> 01:22:18.780]  Так, все, тогда давайте на этом приостановимся.
