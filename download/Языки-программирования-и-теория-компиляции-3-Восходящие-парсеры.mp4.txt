[00:00.000 --> 00:09.920]  Всем доброго дня! Мы с вами продолжаем наш курс лекций. Прошлая лекция была у нас
[00:09.920 --> 00:14.640]  достаточно короткой, потому что у нас были проблемы с экраном. В общем, мы все поправили,
[00:14.640 --> 00:20.360]  здесь настройки стали лучше. Я купил новый переходник, поэтому теперь все зашибись. Это
[00:20.360 --> 00:25.440]  значит, что мы с вами можем посвятить большее время компиляторам. Значит, первой половиной
[00:25.440 --> 00:30.320]  лекции у нас сегодня будет, наверное, сильно знакома всем тем, кто проходил курс по формальным
[00:30.320 --> 00:37.240]  языкам в ФПМИ. Точнее, в ФПМИ информатика. Потому что мы будем с вами говорить про
[00:37.240 --> 00:43.920]  восходящие парсеры. А именно поговорим снова про LR, но это будет именно больше напоминание того,
[00:43.920 --> 00:49.240]  что именно такой LR и каким образом его можно использовать. Если мы сегодня успеем, мы с
[00:49.240 --> 00:55.040]  вами еще начнем разбирать такую интересную тему, как семантический анализ. Смотрите,
[00:55.040 --> 01:01.040]  у нас будут восходящие парсеры. Это те парсеры, которые разбирают слово снизу вверх. То есть,
[01:01.040 --> 01:07.360]  у нас есть входное слово, и мы будем собирать с вами наборы токенов в программатические правила.
[01:07.360 --> 01:14.080]  Значит, начнем с алгоритма LR. Как он расшифровывается? LRK это алгоритм, который умеет,
[01:14.080 --> 01:20.160]  во-первых, парсить слева направо слово. То есть, он и пытается выводить именно правосторонний
[01:20.160 --> 01:25.640]  вывод. Почему? Потому что, если мы с вами посмотрим, каким образом у нас с вами раскрываются токены,
[01:25.640 --> 01:34.080]  неужели новый мел привезли, хороший мел привезли, ура, все улучшения у нас. У нас есть входной набор
[01:34.080 --> 01:40.320]  токенов, и дальше мы начинаем делать разбор. То есть, у нас возникает какое-то правило,
[01:40.320 --> 01:47.800]  у нас терминал раскрывается в последствии терминала LR. Потом у нас есть второе правило,
[01:47.800 --> 01:55.440]  и после этого, предположим себе, у нас строится домик. Каким образом у нас это дерево строится?
[01:55.440 --> 02:03.520]  Это действие №1, это действие №2, это действие №3. Соответственно, если мы с вами будем это
[02:03.520 --> 02:07.760]  делать все в обратном порядке, то вот это действие у нас будет первым, вот это действие у нас будет
[02:07.760 --> 02:16.280]  вторым, а вот это действие будет третьим. Поэтому, среди раскрытия вот этого не терминала, первое
[02:16.280 --> 02:26.120]  правила будет вот этим, а не вот этим. Я надеюсь это всем понятно. Хорошо, и значит у нас есть такое
[02:26.120 --> 02:32.920]  понятие как kTokenLugahead, то есть мы можем посмотреть на kTokenов вперед. Зачастую нам будет
[02:32.920 --> 02:40.580]  достаточно просмотра именно на один токен вперед. Хорошо, значит давайте вспомним, что такое алгоритм
[02:40.580 --> 02:46.340]  LLK. Это рекурсивный разбор, который допускает просмотр на kToken вперед. Мы с вами его в
[02:46.340 --> 02:51.380]  прошлый раз рассматривали. То есть мы в LLK пытаемся сразу раскрыть правила и достигнуть того,
[02:51.380 --> 02:58.780]  чтобы у нас конфликтов нет. В LLK на самом деле мы откладываем раскрытие правила как можно дальше,
[02:58.780 --> 03:08.020]  то есть мы стараемся сначала раскрыть самое правое правило. И здесь у нас возникает интересный
[03:08.020 --> 03:13.860]  алгоритм. Давайте его еще раз вспомним. Это алгоритм перенос свертка. Сразу скажу, что мы
[03:13.860 --> 03:21.500]  должны создать стартовое правило, сделать пополненную грамматику. То есть у нас с
[03:21.500 --> 03:28.620]  вами из не терминала s' должно выводиться не терминал s и символ доллар. Здесь я не буду
[03:28.620 --> 03:36.020]  использовать символ доллар. Как вы думаете почему? Он может быть частью языка, то есть это может
[03:36.020 --> 03:41.940]  быть символ, это может быть любой оператор. Допустим, если мы говорим в Варе про замечательный
[03:41.940 --> 03:54.180]  язык AR, то в нем доллар это как оператор точка. Видно везде все по-разному. Поэтому здесь мы будем
[03:54.180 --> 04:00.020]  использовать специальные символы под названием EndoFort. И мы будем хранить указатель на первые
[04:00.020 --> 04:06.620]  ВК токенов предложения. И дальше у нас будут четыре вида поведения в зависимости от того стека,
[04:06.620 --> 04:12.140]  который у нас есть. Напомню еще раз в чем заключается алгоритм. У нас есть стэк,
[04:12.140 --> 04:19.940]  в котором мы можем сделать два действия. Первое действие это прочитать букву.
[04:19.940 --> 04:36.660]  Допустим, у нас есть слово ABC и есть грамматика. Так, из SAB получается, ну и давайте из BFBC. Вот у нас
[04:36.660 --> 04:44.040]  есть три правила грамматики. Мы берем это у нас входное слово и давайте параллельно мы начнем
[04:44.040 --> 04:51.760]  строить стэк. Мы считаем наше слово, смотрим какая следующая буква. И здесь у нас возможно
[04:51.760 --> 04:57.720]  одно из двух действий. Если у нас на стэке лежит правая часть какого-то правила, то мы можем взять
[04:57.720 --> 05:04.240]  правую часть этого правила заменить на левую часть этого правила. Это называется reduce. Если у нас
[05:04.240 --> 05:10.400]  следующая буква хорошая, то мы можем делать операцию, то есть положить ее на стэк. Давайте как раз
[05:10.400 --> 05:16.960]  для этого алгоритма проделаем эти действия. Значит первая буква A делаем shift. Дальше вторая
[05:16.960 --> 05:24.200]  буква B делаем shift. Третью букву тоже считываем. Буква C получается. Мы кладем ее на стэк. А дальше
[05:24.200 --> 05:30.600]  видим, что у нас на самом деле BC это правая часть правила из BFBC. А там чем можно сделать с вами?
[05:30.600 --> 05:42.480]  Да, мы можем сделать reduce. То есть мы стираем правую часть правила и получаем здесь B, здесь A.
[05:42.480 --> 05:51.920]  Опять видим правую часть правила, кладем на стэк S. Ну и дальше у нас следующий кривой конец
[05:51.920 --> 05:58.080]  слова. По идее нам нужно разбирать эти варианты. Мы кладем конец слова и здесь мы можем сказать,
[05:58.080 --> 06:05.120]  что наш слово принадлежит нашей грамматике. Это так работает алгоритм. Давайте вспомним,
[06:05.120 --> 06:10.080]  собственно, те, кто проходил курс по параметрам языка, что есть проблемы этого алгоритма.
[06:14.080 --> 06:18.960]  Оно неоднозначно. Мы не понимаем, в какой момент времени нам нужно делать shift операцию, а в какой
[06:18.960 --> 06:24.560]  момент времени нам нужно делать операцию reduce. И из-за этого у нас могут быть конфликты. Какие
[06:24.560 --> 06:31.200]  типы конфликтов у нас могут быть? У нас может быть shift-reduce-conflex. Это когда у нас с вами
[06:31.200 --> 06:39.040]  возможен либо снятие следующей буквы, либо чтение, либо снятие стэка правой части, либо
[06:39.040 --> 06:45.920]  reduce-reduce-conflex. Когда оно может быть? Когда у нас два правила, которые имеются, они заканчиваются
[06:45.920 --> 06:53.400]  прямо в одном месте. Здесь сразу скажу, что мы на самом деле здесь рассматриваем стэк. Стэка
[06:53.400 --> 07:02.680]  недостаточно. Поэтому, чтобы уйти от этой проблемы, нам нужно построить поверх всего этому такое
[07:02.680 --> 07:09.120]  понятие, как ситуация. То есть мы не понимаем, где сейчас мы находимся, поэтому нам нужно по факту
[07:09.120 --> 07:18.080]  хранить состояние парсинга, в котором мы находимся. Здесь если мы говорим следующую вещь, что вот эти
[07:18.080 --> 07:26.040]  вот правила, которые у нас имеются, мы можем указать для каждого правила позицию, в которой
[07:26.040 --> 07:31.720]  мы сейчас находимся в этой правиле. То есть когда мы находимся здесь, мы можем считать, что мы
[07:31.720 --> 07:40.240]  находимся в начале разбора. Это означает, что мы можем поставить точку здесь, а если мы спускаем,
[07:40.240 --> 07:48.280]  можем спуститься по вот этому не терминалу s, то точка будет стоять здесь. Мы говорим, что на самом
[07:48.280 --> 08:08.360]  деле мы можем в этом автомате сказать, что у нас есть состояние s$ и s.ab. Когда мы с вами считаем
[08:08.360 --> 08:13.320]  букву a, мы по факту понимаем с вами, что в этом правиле мы можем сдвинуть точку на da.
[08:13.320 --> 08:31.200]  Bollar, a.b. Этого правила здесь нет. И следующее правило, которое у нас здесь есть, мы видим,
[08:31.200 --> 08:40.440]  что точка b, поэтому b мы можем с вами раскрыть. Bc. Здесь дальше у нас идет переход по букве b
[08:40.440 --> 08:52.200]  и переход по букве c. То есть та позиция, в которой мы с вами находимся в автомате,
[08:52.200 --> 08:58.840]  показывает, где мы гипотетически можем находиться в текущем аэропорте. Вот смотрите,
[08:58.840 --> 09:07.240]  интересный момент, какой возникает. Когда мы в этом алгоритме прощем слово abc, вот дошли
[09:07.240 --> 09:14.360]  до сюда, то мы можем сказать, что мы стартуем из этого состояния, проходим a, b, c, находимся здесь.
[09:14.360 --> 09:26.800]  Дальше, каким образом мы с вами понимаем, что мы можем сделать с вами операцию reduce в данный
[09:26.800 --> 09:36.520]  момент? Да, у нас есть правило и точка, в котором находится в конце. Это означает, что мы можем
[09:36.520 --> 09:44.440]  взять правую часть правила, снять ее, отмотаться по пути, которая у нас есть в автомате, пойти сюда,
[09:44.440 --> 09:53.360]  сюда. Путь мы можем с вами хранить и сделать переход по букве b, по большой букве. То есть,
[09:53.360 --> 10:04.040]  то где мы с вами находимся? Получаем ab. Потом мы находимся в этом правиле. У нас есть правая
[10:04.040 --> 10:13.880]  часть правила, из s выводит ab. Либо, если здесь был бы переход по букве, отсюда, по любой,
[10:13.880 --> 10:18.960]  то у нас был бы shift-reduce-conflict. То есть, если бы здесь был переход по букве c, мы бы не смогли
[10:18.960 --> 10:23.840]  понять, что мы делаем. То есть, нам надо либо идти по букве c, либо отмотываться назад. Но,
[10:23.840 --> 10:29.720]  здесь у нас нет ни однозначности, поэтому мы идем, отматываемся по букве b, по вот этому пути.
[10:29.720 --> 10:43.200]  Значит, отматываемся по b, отматываемся по a, идем по s. Вот, и находимся теперь в этой ситуации.
[10:43.200 --> 10:48.360]  Ну, и здесь можно сказать, что мы находимся в конце слова, да, нам ничего не надо прочитывать.
[10:48.760 --> 10:57.280]  И поэтому мы можем сказать, что наше слово принимается. Это как раз так называемый алгоритм lr0.
[10:57.280 --> 11:05.220]  То есть, смотрите, изначально мы сразу строим с вами таблицу. Вот эту lr. Это можно представить как
[11:05.220 --> 11:11.760]  dk, либо можно представить как таблицу. И по ней делаем переходы. Значит, было доказано, что этот
[11:11.760 --> 11:16.240]  алгоритм работает за линейное время на курсе формальных языков. Сейчас мы это повторять не
[11:16.240 --> 11:24.160]  будем. Это не смысл нашего занятия. Вот, собственно, это будет вот такая вот таблица. То есть,
[11:24.160 --> 11:29.280]  мы можем в принципе по каждому состоянию определить, какое действие у нас будет. Либо shift,
[11:29.280 --> 11:35.580]  либо reduce, либо accept. Вот это состояние accept. Либо error, если мы не сможем по этому автомату куда-то
[11:35.580 --> 11:47.780]  двигаться дальше. Хорошо. Вот пример lr-таблицы для грамматики. Значит, мы такие строили на курсе
[11:47.780 --> 11:54.260]  на предыдущем. Скажите, кто нас сразу смущает в этой таблице? Вот что-нибудь вас смущает?
[11:54.260 --> 12:00.660]  Во-первых, она разряженная сильно. Во-вторых, в ней есть дырки. Ну, это, собственно, одно и то же.
[12:00.660 --> 12:15.300]  А еще? Что такое цифра? Это вот эти состояния в нашем автомате, которые занумерованы. Здесь
[12:15.300 --> 12:21.020]  состояния идут от одного до двадцати трех. Собственно, что означает s? Это означает,
[12:21.020 --> 12:27.660]  что мы делаем shift в определенную состояние нашего автомата. То есть, допустим, здесь у нас указано
[12:27.660 --> 12:34.060]  23s16. Это значит, что если в двадцать шестом, двадцать третьем состоянии здесь используется еще
[12:34.060 --> 12:42.940]  следующий символ. Если следующий символ плюс, то мы идем в 16 состоянии. Если reduce, то мы должны
[12:42.940 --> 12:48.900]  откатиться по какому-то конкретному правилу. А если у нас есть пересечение в какой-то ячейке таблицы
[12:48.900 --> 13:00.140]  shift и reduce, то что мы говорили с вами на курсе формальных языков? Делаем МК больше. То есть,
[13:00.140 --> 13:06.460]  у нас грамматика не LR 1, LR 0 и так далее. То есть, мы можем попытаться разрешить конфликт за счет того,
[13:06.460 --> 13:12.580]  что мы будем увеличивать букву. Как вы думаете, что происходит в реальных парстерах?
[13:12.580 --> 13:22.100]  Когда мы строим вот эту таблицу, у нас обнаружится конфликт.
[13:22.100 --> 13:47.260]  Еще. Ну, потянет, конечно. LR 2 строится, там еще более огромная таблица получится. На самом деле
[13:47.260 --> 13:55.020]  вариант такой. Как действует Bizon? Он делает следующее. Если он в какой-то ячейке обнаруживает
[13:55.020 --> 14:07.740]  конфликт, вы при компиляции получите warning о том, что я нашел такой конфликт. Если указать опцию
[14:07.740 --> 14:16.340]  Conterexamples, которая появилась в версии Bizon, начиная с 3.6, по-моему, или с 3.8. Нет, там есть
[14:16.340 --> 14:24.660]  специальная опция при компиляции. Какие-то старые версии Bizon оно не умело показывать. Ну, из-за этого
[14:24.660 --> 14:32.180]  компиляция, конечно, сильно увеличивается. А runtime error у вас возникнет, когда вы реально придете в эту
[14:32.180 --> 14:45.220]  ситуацию и реально у вас возникнет этот конфликт. Да-да-да, именно так, что если мы не попадаем в эту
[14:45.220 --> 14:55.140]  ситуацию, ну и ладно. Да, то есть это можно считать, что в компилятор это runtime behavior.
[14:55.140 --> 15:08.140]  Там LR2 нельзя заставить, там можно заставить в Bizon'е, по крайней мере, использовать JLR, Generalized LR.
[15:08.140 --> 15:19.140]  То есть он попытается наоборот сделать его недетерминированным, этот автомат. А что если?
[15:19.140 --> 15:29.020]  Да-да-да. Вот такое пример LR таблицы. И здесь вот это вот отдельное состояние по переходам,
[15:29.020 --> 15:35.340]  по нетерминалам. Здесь есть GE, то есть это как раз те переходы по нетерминалам, которые мы делаем при
[15:35.340 --> 15:50.220]  откате назад. Так, а, посмотрел все-таки, да, параметры, да. Хорошо, понятно ли вот эта вещь? Значит,
[15:50.220 --> 15:57.700]  в чем еще здесь огромная проблема LR алгоритма? Почему хейтят? Ну, собственно, за размер этой таблицы.
[15:57.700 --> 16:10.100]  Кажется, арифметика. Ну, не сложная грамматика в целом, да. А у нас, извините, уже 23 состояния. И таблица
[16:10.100 --> 16:19.580]  23 на сколько? Ну, порядка 10. То есть вы представляете теперь, что мы находимся сейчас не в 2024 году,
[16:19.580 --> 16:24.820]  да. А в те моменты времени, когда говорили, что 600 килобайт памяти хватит всем,
[16:24.820 --> 16:33.820]  тогда проблема была с компиляцией этих программ. И на самом деле, если так исторически отматывать,
[16:33.820 --> 16:42.140]  то как раз линковка появилась в тот момент времени, когда поняли, что, типа, все стадии
[16:42.140 --> 16:51.140]  компиляции в оперативную память просто не поместить. Да, некоторые строки можно
[16:51.140 --> 17:06.380]  смёржить и про это мы поговорим немного позже. Ну, это да. Да, тут есть пример работы алгоритма,
[17:06.380 --> 17:13.100]  можно, значит, поставить на паузу, либо посмотреть презентация, на каким образом разбирается вот такое
[17:13.100 --> 17:20.580]  выражение. A равно 7, B равно C плюс D. Господи, какая-то сложная грамматика. Ну, видимо,
[17:20.580 --> 17:31.020]  оно такое позволяет. А, здесь оператор присваивания равно есть, да, получается. A7B равно C плюс,
[17:31.020 --> 17:47.580]  собственно, D, которая равна A5 плюс 6, а потом ещё и D используется. Да, да, да.
[17:47.580 --> 18:09.580]  Да, ну вот, да. Вот, вот она, грамматика. То есть, а что она делает? Она говорит,
[18:09.580 --> 18:17.660]  identity это E, expression это либо ID, либо NUM, либо E плюс E, либо SE. То есть, видите, тут набор
[18:17.660 --> 18:26.380]  стейтментов есть, и после этого мы возвращаем ещё какое-то выражение. Не поверите, если мы будем
[18:26.380 --> 18:31.380]  рассматривать промежуточное представление кода, то там такие конструкции прямо явно возникнут.
[18:31.380 --> 18:38.060]  То есть, если строить не ER, который LVM-овский, а вот ER, который обычно строят, там есть такой
[18:38.060 --> 18:51.900]  оператор, называется ESEC. В общем, что он означает? Он означает следующее, что вы сначала вычисляете то,
[18:51.900 --> 18:58.460]  что находится здесь, а потом возвращаете вот это выражение. Вот, это обычно нужно, допустим,
[18:58.460 --> 19:05.300]  если вам нужен какой-то булливый флаг, который нужно посчитать после каких-то выражений. Обычно
[19:05.300 --> 19:11.300]  таким образом каст от була к антуиду идёт, или наоборот. Я точно не помню. В общем, вот такая
[19:11.300 --> 19:23.420]  интересная вещь. Вот он разбор. Давайте поговорим про парсер LR0. Что такое LR0 парсер? Это наивный
[19:23.420 --> 19:27.580]  алгоритм, который не смотрит на следующую букву. То есть, здесь мы не опирались на следующие
[19:27.580 --> 19:33.660]  буквы, которые у нас есть, и мы просто к каждому правилу добавляем маркер позиции, в которой мы
[19:33.660 --> 19:43.660]  находимся. Это называется ситуацией. То есть, мы должны начать в нулевой ситуации. Из S штрих
[19:43.660 --> 19:54.140]  выводится точка S, конец файла. Или, а заканчивать мы должны из S штрих перейти в S, точка конец
[19:54.140 --> 19:58.980]  слова. При этом у нас на входе ничего не должно быть. Если у нас на входе что-то есть,
[19:58.980 --> 20:09.460]  наверное, мы не разобрали всё правило далеко, а какой-то префикс. Здесь есть пример. Ещё раз
[20:09.460 --> 20:14.220]  строим автомат. Каким образом мы его строим? Если мы делаем переход по букве, то пытаемся
[20:14.220 --> 20:20.300]  продвинуть точку по правилу. Если точку продвинуть при этом не получается, мы находимся перед
[20:20.300 --> 20:26.300]  не терминалом, то мы пытаемся раскрыть этот не терминал, добавить новое правило. Здесь это
[20:26.300 --> 20:34.820]  тоже как раз указано. В итоге, для простой грамматики получается вот такая таблица. Давайте
[20:34.820 --> 20:44.020]  посмотрим на неё внимательно. Здесь, допустим, что у нас получается? Вот здесь у нас есть переход.
[20:44.020 --> 20:50.100]  Допустим, видите, здесь, возможно, зацикливание. Вот это очень важно. То есть, у нас есть переход
[20:50.660 --> 20:57.220]  по открывающейся скобке. Давайте посмотрим, что у нас происходит при переходе при открывающейся
[20:57.220 --> 21:01.900]  скобке. У нас здесь есть правило. f стрелочка точка, сколка открывается, l скобка закрывается.
[21:01.900 --> 21:09.020]  В итоге мы продвигаем эту точку. У нас получается правило — f стрелочка ковычка открывается,
[21:09.020 --> 21:16.140]  точка l. Как ни странно, это вот это правило. А дальше это правило при раскрытии порождает
[21:16.140 --> 21:19.260]  все остальные правила, которые были в этом состоянии.
[21:19.260 --> 21:21.760]  Поэтому, чтобы не дублировать эти состояния в бесконечном
[21:21.760 --> 21:26.380]  цикле, мы как раз их и, получается, подставляем.
[21:26.380 --> 21:28.780]  То есть делаем переход в одно и то же состояние.
[21:28.780 --> 21:34.700]  В итоге, табличное представление этой грамматики вот такое.
[21:34.700 --> 21:37.100]  То есть здесь у нас конфликтов с вами никаких не будет.
[21:38.100 --> 21:42.100]  Так, если что, останавливайте, потому что я про...
[21:48.100 --> 21:50.100]  Вот это?
[21:50.100 --> 21:52.100]  Точка S...
[21:52.100 --> 21:54.100]  Что из него раскрывается?
[21:54.100 --> 21:56.100]  А из него вот эти два?
[22:00.100 --> 22:03.100]  Ну, нет, они как раз вроде как по порядку.
[22:03.100 --> 22:05.100]  То есть у нас из S стрелочка точка L,
[22:05.100 --> 22:07.100]  из L раскрываются вот эти два правила,
[22:07.100 --> 22:09.100]  а из S потом...
[22:11.100 --> 22:13.100]  Да, то есть здесь конфликтов, кстати, нет.
[22:13.100 --> 22:15.100]  Это интересно.
[22:15.100 --> 22:19.100]  Но вот, однако, не всякая грамматика является LR0.
[22:19.100 --> 22:21.100]  Даже больше скажу, больше через грамматика
[22:21.100 --> 22:23.100]  не является LR0 грамматикой.
[22:23.100 --> 22:27.100]  То есть у нас, получается, из S выводится E с крышки, E кавычки.
[22:27.100 --> 22:29.100]  И вот смотрите, здесь важный момент, что
[22:29.100 --> 22:33.100]  если мы посмотрим на третью ситуацию,
[22:33.100 --> 22:36.100]  то по плюсу мы можем с вами либо
[22:36.100 --> 22:38.100]  двинуться в четвертую ситуацию,
[22:38.100 --> 22:40.100]  либо
[22:40.100 --> 22:42.100]  развернуться по вот этому правилу.
[22:42.100 --> 22:45.100]  То есть мы не понимаем с вами, что именно делать.
[22:45.100 --> 22:48.100]  В данном случае. Скорее всего, если мы добавим
[22:48.100 --> 22:51.100]  еще один символ на просмотр вперед,
[22:51.100 --> 22:55.100]  вполне возможно мы с вами эту
[22:55.100 --> 22:57.100]  проблему решим.
[22:57.100 --> 23:00.100]  Скорее всего, здесь визуально можно увидеть, что
[23:00.100 --> 23:03.100]  если у нас следующий символ плюс,
[23:03.100 --> 23:06.100]  то скорее всего мы пойдем по шифту.
[23:06.100 --> 23:09.100]  Если следующий символ доллар, то есть конец
[23:09.100 --> 23:12.100]  нашего файла, то мы откатимся обратно.
[23:12.100 --> 23:14.100]  Это визуально видно.
[23:14.100 --> 23:18.100]  Поэтому хотелось бы это каким-то образом разрешать.
[23:18.100 --> 23:22.100]  Значит, первая вещь, первая оптимизация,
[23:22.100 --> 23:25.100]  которая в данном случае поможет нам,
[23:25.100 --> 23:27.100]  это алгоритм SLR.
[23:27.100 --> 23:30.100]  Значит, мы с вами про него вообще никогда не говорили.
[23:30.100 --> 23:33.100]  Идея такая, что давайте воспользуемся тем,
[23:33.100 --> 23:36.100]  что у нас было в LL-алгоритме.
[23:36.100 --> 23:39.100]  У нас что происходит?
[23:39.100 --> 23:42.100]  У нас с вами для каждого унитерминала есть
[23:42.100 --> 23:45.100]  такое понятие как follow.
[23:45.100 --> 23:48.100]  Кто его помнит?
[23:51.100 --> 23:53.100]  Да.
[23:53.100 --> 23:56.100]  Переки следующий алгоритм.
[23:56.100 --> 23:59.100]  Follow от нитерминала A.
[24:01.100 --> 24:04.100]  Это первое, что может вывестись
[24:04.100 --> 24:07.100]  после раскрытия этого нитерминала.
[24:07.100 --> 24:10.100]  Так, сейчас вспомню.
[24:10.100 --> 24:13.100]  То, что после.
[24:13.100 --> 24:16.100]  Да, первое, что может после.
[24:16.100 --> 24:19.100]  Ну да, если ничего не может, то йо.
[24:19.100 --> 24:22.100]  Это я, кажется, про first plus сказал.
[24:22.100 --> 24:25.100]  Да, то есть это первое, что может вывестись
[24:25.100 --> 24:28.100]  после раскрытия нитерминала A.
[24:28.100 --> 24:31.100]  Ну и давайте мы это сделаем.
[24:31.100 --> 24:34.100]  Мы будем говорить, что давайте
[24:34.100 --> 24:37.100]  мы...
[24:37.100 --> 24:40.100]  Сейчас скажу, что мы сделаем.
[24:40.100 --> 24:43.100]  Вот, мы с вами в LR0 таблицам
[24:43.100 --> 24:46.100]  оставляем reduce
[24:46.100 --> 24:49.100]  только для тех терминалов X,
[24:49.100 --> 24:52.100]  которые могут
[24:52.100 --> 24:55.100]  то есть то, что может раскрываться
[24:55.100 --> 24:58.100]  после reduce правила. То есть, смотрите.
[24:58.100 --> 25:01.100]  Я не знаю. А, тут нету примера.
[25:01.100 --> 25:04.100]  Давайте как раз его разберем. Вот видите?
[25:04.100 --> 25:07.100]  Вот ему правило. Есть стрелочка T.
[25:07.100 --> 25:10.100]  Вот у нас есть конфликт.
[25:10.100 --> 25:13.100]  Как мы решаем? Нам нужно посчитать
[25:13.100 --> 25:16.100]  follow от е.
[25:16.100 --> 25:19.100]  Почему тут будет равен, кстати, follow от е?
[25:19.100 --> 25:22.100]  Давайте посчитаем его.
[25:22.100 --> 25:25.100]  Так.
[25:25.100 --> 25:28.100]  А?
[25:28.100 --> 25:31.100]  А, ну да.
[25:42.100 --> 25:45.100]  Хорошо. Так, что у нас получается?
[25:45.100 --> 25:48.100]  Мы хотим посчитать follow от е.
[25:48.100 --> 25:51.100]  Ага.
[25:51.100 --> 25:54.100]  Да, то есть у нас
[25:54.100 --> 25:57.100]  е равно t плюс е.
[25:57.100 --> 26:00.100]  То есть, нам нужно посмотреть на правила,
[26:00.100 --> 26:03.100]  в которых есть е.
[26:03.100 --> 26:06.100]  В правой части.
[26:06.100 --> 26:09.100]  Да.
[26:09.100 --> 26:12.100]  Причем е не должна быть последней.
[26:12.100 --> 26:15.100]  Здесь е последняя, поэтому мы будем
[26:15.100 --> 26:18.100]  смотреть на то, что выводится сверху этого правила.
[26:18.100 --> 26:21.100]  А здесь следующий символ относительно е. Какой?
[26:21.100 --> 26:24.100]  Доллар. То есть, у нас получается, что
[26:24.100 --> 26:27.100]  follow от е это доллар.
[26:27.100 --> 26:30.100]  И как это разрешать? То есть, мы с вами понимаем, что
[26:30.100 --> 26:33.100]  вот, к сожалению, здесь нету разметки,
[26:33.100 --> 26:36.100]  то, что вот здесь у нас не должно быть reduce по второму правилу.
[26:36.100 --> 26:39.100]  И здесь не должно быть reduce по второму правилу.
[26:39.100 --> 26:42.100]  Reduce по второму правилу должен оставаться только здесь.
[26:42.100 --> 26:45.100]  Некоторая ивристика, которая помогает на лету не смотреть
[26:45.100 --> 26:48.100]  на следующую букву, а посмотреть на множество follow.
[26:48.100 --> 26:51.100]  Понятно, что это не фанацея от всех болезней.
[26:51.100 --> 26:54.100]  И далеко это все быстро не вправляется.
[26:54.100 --> 26:57.100]  Вот. Для этого у нас есть LR1-алгоритм.
[26:57.100 --> 27:00.100]  То есть, позиция, это у нас
[27:00.100 --> 27:03.100]  вот такая вот ситуация.
[27:03.100 --> 27:06.100]  То есть, у нас с вами, это не позиция, это ситуация,
[27:06.100 --> 27:09.100]  а стрелочка альфа точка бета запитается,
[27:09.100 --> 27:12.100]  где а стрелочка альфа бета это правила грамматики.
[27:12.100 --> 27:15.100]  То есть, как подсчитать? Мы находимся в текущей позиции
[27:15.100 --> 27:18.100]  ситуации, и первая буква, которую мы можем вывести после того,
[27:18.100 --> 27:21.100]  как мы выйдем из этого правила, это буква С.
[27:21.100 --> 27:24.100]  Вот. И именно по таким вещам мы можем пересчитывать
[27:24.100 --> 27:27.100]  наши правила.
[27:27.100 --> 27:30.100]  Вот наши грамматики. Так, ну,
[27:30.100 --> 27:33.100]  я не хочу сейчас еще раз детальнее вглубляться
[27:33.100 --> 27:36.100]  все это, как это все делается.
[27:36.100 --> 27:39.100]  Здесь прямо математический вывод есть.
[27:39.100 --> 27:42.100]  То есть, опять же, нам нужно набрать
[27:42.100 --> 27:45.100]  как раз
[27:45.100 --> 27:48.100]  что мы на самом деле делаем? Мы пытаемся
[27:48.100 --> 27:51.100]  набить в наше множество автоматик, как можно больше
[27:51.100 --> 27:54.100]  ситуаций. И здесь как раз говорится, что
[27:54.100 --> 27:57.100]  если у нас есть точка перед ней терминалом,
[27:57.100 --> 28:00.100]  мы хотим вывести какое-то правило, то мы можем
[28:00.100 --> 28:03.100]  посчитать, какое правило из этого может вывести.
[28:03.100 --> 28:06.100]  И правильно считать первую букву.
[28:06.100 --> 28:09.100]  То есть, давайте я как раз попробую нарисовать еще раз
[28:09.100 --> 28:12.100]  на картинке.
[28:15.100 --> 28:18.100]  Получаем,
[28:18.100 --> 28:21.100]  допустим, у нас было правило A выводит
[28:21.100 --> 28:24.100]  α, х, β.
[28:24.100 --> 28:27.100]  Здесь у нас в этом выводился первая буква, символ Z.
[28:27.100 --> 28:30.100]  А дальше у нас выводится γ.
[28:30.100 --> 28:33.100]  Какую букву можем вывести?
[28:33.100 --> 28:36.100]  Вот смотрите, мы из х выводим γ,
[28:36.100 --> 28:39.100]  и дальше смотрим на первый символ, который у нас выводится из βZ.
[28:44.100 --> 28:47.100]  То есть, смотрим на первый символ, который выводится из βZ,
[28:47.100 --> 28:50.100]  и в ту же самую ситуацию добавляем
[28:50.100 --> 28:53.100]  какой там символ?
[28:53.100 --> 28:56.100]  У, где У это первая буква, которая выходит
[28:56.100 --> 28:59.100]  из βZ.
[28:59.100 --> 29:02.100]  И дальше с учетом этого и пересчитываем правила грамматики.
[29:02.100 --> 29:05.100]  Соответственно, reduce мы оставляем только
[29:05.100 --> 29:08.100]  по тем символам, то есть, если у нас
[29:08.100 --> 29:11.100]  получается какой-нибудь вывод аля
[29:11.100 --> 29:14.100]  я не знаю,
[29:14.100 --> 29:17.100]  а, стрелочка, гамма, точка, бета,
[29:17.100 --> 29:20.100]  гамма, точка, б,
[29:20.100 --> 29:23.100]  то reduce оставляем только в том месте, где у нас находится
[29:23.100 --> 29:26.100]  b, потому что мы выходим из правила, и следующий символ
[29:26.100 --> 29:29.100]  должен быть b.
[29:29.100 --> 29:32.100]  Другие символы не подходят.
[29:32.100 --> 29:35.100]  Опять же понятно, что это будет решать далеко не все конфликты,
[29:35.100 --> 29:38.100]  но опять же это можно решать.
[29:38.100 --> 29:41.100]  Так, пример.
[29:41.100 --> 29:44.100]  LR таблицы.
[29:51.100 --> 29:54.100]  Ну да.
[29:54.100 --> 29:57.100]  Ну да, нужно будет обработать аккуратно EOF.
[29:57.100 --> 30:00.100]  Значит, пример, кстати,
[30:00.100 --> 30:03.100]  такой о грамматике. Это переменные
[30:03.100 --> 30:06.100]  C, переменные и указатели C.
[30:06.100 --> 30:09.100]  То есть, что у нас есть? У нас есть S,
[30:09.100 --> 30:12.100]  это S$. Дальше
[30:12.100 --> 30:15.100]  что у нас может быть? Из S у нас может
[30:15.100 --> 30:18.100]  написаться, что V равно E, это выражение
[30:18.100 --> 30:21.100]  у нас,
[30:21.100 --> 30:24.100]  мы можем statement указать как определенное expression,
[30:24.100 --> 30:27.100]  а в чему у нас может быть expression быть?
[30:27.100 --> 30:30.100]  E это может быть V,
[30:30.100 --> 30:33.100]  причем V это либо у нас значение,
[30:33.100 --> 30:36.100]  либо значение под указателем.
[30:36.100 --> 30:39.100]  Да, кажется так.
[30:39.100 --> 30:42.100]  Если я не накосячил нигде.
[30:51.100 --> 30:54.100]  Вроде нет.
[30:54.100 --> 30:57.100]  В общем, смотрите,
[30:57.100 --> 31:00.100]  главный кейс, который здесь есть, у нас либо есть
[31:00.100 --> 31:03.100]  присвоение по выражению, либо по указателю.
[31:03.100 --> 31:06.100]  Возможно, что здесь нужно наоборот,
[31:06.100 --> 31:09.100]  что не V выводит E, а
[31:09.100 --> 31:12.100]  из E может выводиться этот звездочка
[31:12.100 --> 31:15.100]  либо апперсант.
[31:15.100 --> 31:18.100]  Именование и разменование указателя.
[31:18.100 --> 31:21.100]  Посмотрим внимательно на эту грамматику.
[31:35.100 --> 31:38.100]  Ага, да.
[31:38.100 --> 31:41.100]  А что у нас подходит в таком случае?
[31:41.100 --> 31:44.100]  Допустим, у нас подходит
[31:44.100 --> 31:47.100]  звездочка X равно
[31:47.100 --> 31:50.100]  E, E, E, E, E,
[31:50.100 --> 31:53.100]  E это V.
[31:56.100 --> 31:59.100]  Допустим, может такое подходить.
[32:02.100 --> 32:05.100]  Вроде...
[32:05.100 --> 32:08.100]  А?
[32:08.100 --> 32:11.100]  Да, это подходит под это описание.
[32:11.100 --> 32:14.100]  Вроде такое можно даже скомпилировать.
[32:14.100 --> 32:17.100]  А Y это еще одна переменная.
[32:17.100 --> 32:20.100]  Мы говорили...
[32:20.100 --> 32:23.100]  А, у вас не было в прошлые разы.
[32:23.100 --> 32:26.100]  Мы говорили, что в качестве X здесь уже находятся
[32:26.100 --> 32:29.100]  не переменные, а токен.
[32:29.100 --> 32:32.100]  Да, соответственно, Y это просто лексема,
[32:32.100 --> 32:35.100]  которая скрывает за этим токен.
[32:36.100 --> 32:39.100]  Ну, это у нас получается разыминование
[32:39.100 --> 32:42.100]  того, что находится под этим.
[32:48.100 --> 32:51.100]  Так, сейчас.
[32:59.100 --> 33:02.100]  Ну, да.
[33:02.100 --> 33:05.100]  То есть, насколько я понимаю, в левой части
[33:05.100 --> 33:08.100]  это будет взять дополнительное адреса, да?
[33:08.100 --> 33:11.100]  А здесь именно получается разыминование указателя.
[33:14.100 --> 33:17.100]  Это да.
[33:17.100 --> 33:20.100]  Здесь это надо различать, к сожалению, здесь этого не сделано.
[33:23.100 --> 33:26.100]  Да, да, да.
[33:26.100 --> 33:29.100]  Поэтому в грамматике зачастую, чтобы
[33:29.100 --> 33:32.100]  не париться, обычно даже на уровне самой грамматики
[33:32.100 --> 33:35.100]  делают отдельный не терминал для L-value
[33:35.100 --> 33:38.100]  и отдельный не терминал для R-value.
[33:38.100 --> 33:41.100]  Чтобы развести их поведение.
[33:41.100 --> 33:44.100]  Давайте посмотрим на эту грамматику.
[33:44.100 --> 33:47.100]  Скажите, пожалуйста, что здесь...
[33:47.100 --> 33:50.100]  Не кажется вам ли эта таблица достаточно большой?
[33:53.100 --> 33:56.100]  Давайте внимательно подумаем,
[33:56.100 --> 33:59.100]  что мы можем с этим сделать.
[34:02.100 --> 34:05.100]  Да, здесь много одинаковых ситуаций,
[34:05.100 --> 34:08.100]  которые при этом переводятся в достаточно похожие.
[34:08.100 --> 34:11.100]  Вот, смотрите, давайте посмотрим
[34:11.100 --> 34:14.100]  к примеру ситуации 8 и 11.
[34:15.100 --> 34:18.100]  В принципе, что мы здесь видим?
[34:18.100 --> 34:21.100]  У нас конфликтов никаких нету, а ситуации 8 и 11
[34:21.100 --> 34:24.100]  между собой сильно похожи.
[34:24.100 --> 34:27.100]  Почему бы их не объединить?
[34:27.100 --> 34:30.100]  Тем более тут пиковые состояния.
[34:33.100 --> 34:36.100]  Ну вот, утверждается, что если
[34:36.100 --> 34:39.100]  мы можем с вами нашу грамматику,
[34:39.100 --> 34:42.100]  она изначально у нас лежит в классе LR1.
[34:45.100 --> 34:48.100]  Почему бы мы не можем сузить наш класс грамматик,
[34:48.100 --> 34:51.100]  при этом таблицу сделать меньше?
[34:51.100 --> 34:54.100]  При этом грамматика при этом будет адекватной
[34:54.100 --> 34:57.100]  для этого класса.
[34:57.100 --> 35:00.100]  Да, Михаил, мы тут пытаемся смёржить состояние
[35:00.100 --> 35:03.100]  в нашей таблице.
[35:03.100 --> 35:06.100]  То есть 8 и 11, в принципе, почему бы их не смёржить,
[35:06.100 --> 35:09.100]  если это никаким конфликтом не приведёт?
[35:09.100 --> 35:12.100]  То есть мы можем посмотреть на две строки,
[35:12.100 --> 35:15.100]  смотрим, куда они переходят.
[35:15.100 --> 35:18.100]  Если, значит, у нас переходы,
[35:18.100 --> 35:21.100]  можно слить, окей, и смотрим
[35:21.100 --> 35:24.100]  для всех прародителей, можем ли мы эти переходы слить.
[35:24.100 --> 35:27.100]  Вот у нас есть переход в восьмое состояние здесь,
[35:27.100 --> 35:30.100]  из X восьмое, переход по X восьмое, здесь переход
[35:30.100 --> 35:33.100]  по X в одиннадцатое.
[35:35.100 --> 35:38.100]  Доллар запятая равно это следующий символ,
[35:38.100 --> 35:41.100]  то есть это на самом деле две ситуации.
[35:41.100 --> 35:44.100]  У нас первая V стрелочка X точка доллара,
[35:44.100 --> 35:47.100]  вторая V стрелочка X точка равно.
[35:47.100 --> 35:50.100]  Ну да, типа того.
[35:52.100 --> 35:55.100]  Ну и, собственно, мы их можем слить.
[35:55.100 --> 35:58.100]  Какие ещё тут сливаются ситуации?
[36:01.100 --> 36:04.100]  Чего?
[36:04.100 --> 36:07.100]  Ничего, ни одна стрелка не выходит.
[36:07.100 --> 36:10.100]  Это означает, что если мы доходим до них,
[36:10.100 --> 36:13.100]  то мы получаем тупик,
[36:13.100 --> 36:16.100]  и нам нужно откатываться назад.
[36:16.100 --> 36:19.100]  Проблема с откатыванием назад нет,
[36:19.100 --> 36:22.100]  потому что мы храним весь...
[36:24.100 --> 36:27.100]  Чего-чего, ещё раз?
[36:31.100 --> 36:34.100]  Нет, символ доллар равно необходимо хранить,
[36:34.100 --> 36:37.100]  потому что представим себе, что у нас есть правило,
[36:37.100 --> 36:40.100]  мы находимся в разборе какого-то
[36:40.100 --> 36:43.100]  предложения, какой-то программы,
[36:43.100 --> 36:46.100]  а следующий символ не доллар и не равно.
[36:46.100 --> 36:49.100]  Что мы должны сделать?
[36:49.100 --> 36:52.100]  Скажешь всё плохо, выдать ошибку компиляции.
[36:52.100 --> 36:55.100]  Вот, поэтому это дополнительные проверки,
[36:55.100 --> 36:58.100]  которые нам нужны.
[37:01.100 --> 37:04.100]  Ну да, так и надо.
[37:04.100 --> 37:07.100]  Да, только надо по определённым символам это делать.
[37:07.100 --> 37:10.100]  То есть когда мы находимся здесь,
[37:10.100 --> 37:13.100]  то есть следующий символ доллар,
[37:13.100 --> 37:16.100]  либо следующий символ равно.
[37:16.100 --> 37:19.100]  Смотрите, аккуратнее, чтобы при merge
[37:19.100 --> 37:22.100]  эти правила объединяются,
[37:22.100 --> 37:25.100]  и если здесь в 11 ситуации следующий символ равно
[37:25.100 --> 37:28.100]  даёт ошибку компиляции, то при объединении
[37:28.100 --> 37:31.100]  следующий символ равно не будет давать ошибку компиляции.
[37:31.100 --> 37:34.100]  С этим надо быть аккуратнее.
[37:34.100 --> 37:37.100]  Ну вот, какие ещё ситуации можно объединить здесь?
[37:37.100 --> 37:40.100]  7, 12, согласен.
[37:40.100 --> 37:43.100]  Ещё 10, 14.
[37:53.100 --> 37:56.100]  6, 13 можно ещё объединить.
[38:02.100 --> 38:05.100]  На самом деле это немного напоминает алгоритм
[38:05.100 --> 38:08.100]  и автомизация автоматов.
[38:08.100 --> 38:11.100]  То есть когда мы переходим в одни и те же классы эквалентности
[38:11.100 --> 38:14.100]  и пытаемся их, опять, только там мы их разъединяли,
[38:14.100 --> 38:17.100]  а здесь наоборот, пытаемся соединить.
[38:17.100 --> 38:20.100]  Вот, и вот эта вот таблица, которая мы получим,
[38:20.100 --> 38:23.100]  она называется уже LIL1.
[38:23.100 --> 38:26.100]  То есть объединяем те состояния,
[38:26.100 --> 38:29.100]  в которых состояния, закрывая символ локохедсов, падают.
[38:29.100 --> 38:32.100]  Собственно, мы их уже с вами нашли.
[38:33.100 --> 38:36.100]  Это 6, 13, 7, 12, 10, 14 и 8, 11.
[38:36.100 --> 38:39.100]  Главное, чтобы два разных редюсса не попали в одну ячейку.
[38:39.100 --> 38:42.100]  Вот, в итоге у нас получается более простая грамматика,
[38:42.100 --> 38:45.100]  и вы не поверите, Бизон строит LIL1-грамматику.
[38:48.100 --> 38:51.100]  То есть класс корректно распознаваемый программ
[38:51.100 --> 38:54.100]  в нём на самом деле будет меньше,
[38:54.100 --> 38:57.100]  потому что в некоторых грамматиках, которые являются LIL1,
[38:57.100 --> 39:00.100]  они будут конфликтовать в чьи в них могут быть дополнительные конкуренты.
[39:02.100 --> 39:05.100]  То есть при мерже ячеек у нас возникнут неоднозначности.
[39:07.100 --> 39:10.100]  Вот, и в итоге у нас получается вот такая большая картинка.
[39:10.100 --> 39:13.100]  Значит, сразу скажу, здесь один тонкий момент.
[39:13.100 --> 39:16.100]  Значит, у нас есть LIL1-грамматики,
[39:16.100 --> 39:19.100]  это всё однозначные грамматики.
[39:19.100 --> 39:22.100]  То есть класс однозначный грамматик,
[39:22.100 --> 39:25.100]  он сужается до класса LIL1-грамматик и LIL1-грамматик.
[39:25.100 --> 39:28.100]  Собственно, LIL1 уже чем LIL1 при подставлении,
[39:28.100 --> 39:31.100]  потому что там правило намного проще для проверки.
[39:31.100 --> 39:34.100]  При этом у нас важное утверждение следующее,
[39:34.100 --> 39:37.100]  что здесь именно, внимание обращу,
[39:37.100 --> 39:40.100]  говорится именно про грамматики,
[39:40.100 --> 39:43.100]  здесь не говорится про языки, задаваемые этими грамматиками.
[39:44.100 --> 39:47.100]  Да, потому что есть такое утверждение,
[39:47.100 --> 39:50.100]  что любой язык, который задаётся некоторой LRK-грамматикой,
[39:50.100 --> 39:53.100]  можно задать языком, который задаётся LR1-грамматикой.
[39:54.100 --> 39:57.100]  Это прям утверждение, которое мы, правда, не доказывали
[39:57.100 --> 40:00.100]  на курсе формальных языков, но оно есть.
[40:01.100 --> 40:04.100]  То есть, если мы говорим по классам языков,
[40:04.100 --> 40:07.100]  то эти языки будут сильно схлопываться.
[40:07.100 --> 40:11.100]  Значит, у нас, смотрите, будет хватать либо LIL1,
[40:11.100 --> 40:14.100]  если мы идём по пути Бизона,
[40:14.100 --> 40:17.100]  если мы идём по пути Антелера,
[40:17.100 --> 40:20.100]  то у нас с вами будет алгоритм LIL со звездой.
[40:20.100 --> 40:23.100]  Собственно, LIL со звездой он даже шире
[40:23.100 --> 40:26.100]  в каких-то моментах, чем LRK.
[40:31.100 --> 40:34.100]  То есть, если... Да, изменив грамматику.
[40:38.100 --> 40:39.100]  Чё?
[40:42.100 --> 40:45.100]  Нет, наоборот. Наша цель как раз будет
[40:45.100 --> 40:48.100]  состоять в том, чтобы задать грамматику так,
[40:48.100 --> 40:51.100]  чтобы она свелась в класс LR1.
[40:51.100 --> 40:54.100]  Да, главное язык, чтобы был нормальный.
[40:54.100 --> 40:56.100]  В смысле, я за одной грамматикой в другую?
[40:56.100 --> 40:58.100]  А, чтобы пересобирать её?
[41:05.100 --> 41:08.100]  Надо посмотреть доказательства этого факта.
[41:11.100 --> 41:14.100]  Ну, я думаю, что это всё.
[41:14.100 --> 41:17.100]  Я думаю, что это всё.
[41:17.100 --> 41:20.100]  Я думаю, что это всё.
[41:20.100 --> 41:23.100]  Я думаю, что это всё.
[41:24.100 --> 41:27.100]  Ну, да.
[41:27.100 --> 41:30.100]  Честно, сам доказательства не помню.
[41:30.100 --> 41:33.100]  Ладно. Мы всё-таки про компиляторы тут пришли
[41:33.100 --> 41:36.100]  говорить, а не про грамматики.
[41:36.100 --> 41:39.100]  Поэтому нам нужно, как обычно, найти как можно больше ошибок компиляции.
[41:39.100 --> 41:42.100]  Собственно, давайте вспомним,
[41:42.100 --> 41:45.100]  как мы в LIL решали ошибки компиляции.
[41:49.100 --> 41:52.100]  Мы удаляли символы до тех пор,
[41:52.100 --> 41:55.100]  когда не дойдём до того момента,
[41:55.100 --> 41:58.100]  когда мы можем спуститься.
[41:58.100 --> 42:01.100]  И, точнее, не спуститься, а продвинуться по определённому символу.
[42:01.100 --> 42:04.100]  То есть, мы работали с вами с делецами.
[42:04.100 --> 42:07.100]  Здесь же суть наоборот.
[42:07.100 --> 42:10.100]  Здесь очень удобно, что в LR-алгоритме есть
[42:10.100 --> 42:13.100]  так называемые ERROR токены.
[42:13.100 --> 42:16.100]  Собственно, это токены, так называемые wildcard токены,
[42:16.100 --> 42:19.100]  которые между собой могут представлять
[42:19.100 --> 42:22.100]  следующую вещь. Это точка со звёздочкой.
[42:22.100 --> 42:25.100]  То есть, вы можете по этому символу двигаться
[42:25.100 --> 42:28.100]  сколько угодно раз,
[42:28.100 --> 42:31.100]  до тех пор, пока вы не дойдёте до определённого значимого символа.
[42:31.100 --> 42:34.100]  То есть, смотрите,
[42:34.100 --> 42:37.100]  мы можем вставить ERROR токен.
[42:37.100 --> 42:40.100]  Видите, EXPRESSION — это что такое?
[42:40.100 --> 42:43.100]  Скобочка открывается, скобочка закрывается,
[42:43.100 --> 42:46.100]  а внутри него ERROR.
[42:46.100 --> 42:49.100]  То есть, если у нас ничто никаким образом
[42:49.100 --> 42:52.100]  не разбирается какое-то правило, то всегда мы можем
[42:52.100 --> 42:55.100]  скатиться именно в это правило, правило с ERROR токеном,
[42:55.100 --> 42:58.100]  и начинать разбор символов до тех пор, пока мы не дойдём
[42:58.100 --> 43:01.100]  до символа, закрывающего скобки.
[43:08.100 --> 43:11.100]  Даже не терминал, это
[43:11.100 --> 43:14.100]  регулярное выражение, я бы так сказал.
[43:14.100 --> 43:17.100]  То есть, мы можем, грубо говоря, написать какую-нибудь
[43:17.100 --> 43:20.100]  ерунду,
[43:20.100 --> 43:23.100]  даже несколько символов ерунды, и вот пока мы не дойдём
[43:23.100 --> 43:26.100]  до закрытия этого символа, мы...
[43:35.100 --> 43:38.100]  Он попытается по первой закрывающей, скорее всего,
[43:38.100 --> 43:41.100]  закрыть.
[43:41.100 --> 43:44.100]  Он пытается посмотреть на вид грамматики.
[43:50.100 --> 43:53.100]  Да, да, да.
[43:53.100 --> 43:56.100]  Ну, то есть наша цель, напоминаю, когда мы пишем компилятор,
[43:56.100 --> 43:59.100]  находить ещё как можно больше ошибок в компиляции.
[43:59.100 --> 44:02.100]  Что мы делаем? Так, смотрите,
[44:02.100 --> 44:05.100]  мы обрабатываем стэк, пока мы не сможем сделать
[44:05.100 --> 44:08.100]  shift по ERROR.
[44:08.100 --> 44:11.100]  И пропускаем символы
[44:11.100 --> 44:14.100]  алфавита, пока мы не сможем сделать
[44:14.100 --> 44:17.100]  shift дальше. То есть, по факту,
[44:17.100 --> 44:20.100]  либо мы говорим, что ERROR принимает всё, кроме
[44:20.100 --> 44:23.100]  конкретных символов, да, и мы
[44:23.100 --> 44:26.100]  делаем, по факту, пропуск символов
[44:26.100 --> 44:29.100]  до тех пор, пока мы не можем
[44:29.100 --> 44:32.100]  делать shift дальше. То есть, как бы, продвинулись, остановились,
[44:32.100 --> 44:35.100]  ждём следующего символа.
[44:35.100 --> 44:38.100]  Тут спрашивается, почему в третьем шаге не reduce?
[44:38.100 --> 44:41.100]  Ну, потому что...
[44:42.100 --> 44:45.100]  Ну, потому что обычно, когда мы задаём ошибки
[44:45.100 --> 44:48.100]  синтаксиса, которые есть, мы задаём их
[44:48.100 --> 44:51.100]  как конкретные симантические инструкции.
[44:51.100 --> 44:54.100]  То есть, мы явно считаем скобочный баланс,
[44:54.100 --> 44:57.100]  считаем множество выражений, типы выражений,
[44:57.100 --> 45:00.100]  типы не считаем. Любые симантические, синтактические
[45:00.100 --> 45:03.100]  конструкции должны быть учинили.
[45:03.100 --> 45:06.100]  Наша цель, как разработчиков компилятора,
[45:06.100 --> 45:09.100]  сделать такую вещь, чтобы
[45:09.100 --> 45:12.100]  учесть как можно больше
[45:12.100 --> 45:15.100]  ошибок, которые может
[45:15.100 --> 45:18.100]  совершить пользователь, и внести их
[45:18.100 --> 45:21.100]  в нашу грамматику.
[45:21.100 --> 45:24.100]  Да, то есть, допустим, баланс
[45:24.100 --> 45:27.100]  посчитать, какие-нибудь скобочки фигурные,
[45:27.100 --> 45:30.100]  типа скобочка фигурная открывается, значит, где-то закрывается
[45:31.100 --> 45:34.100]  Мы считаем, что ещё не выйдет у нас,
[45:34.100 --> 45:37.100]  как мы можем сказать, что ошибка
[45:37.100 --> 45:40.100]  это вся программа, так и
[45:40.100 --> 45:43.100]  какой-то небольшой день.
[45:43.100 --> 45:46.100]  Ошибка светлая.
[45:46.100 --> 45:49.100]  Ну, на самом деле, как мы можем здесь
[45:49.100 --> 45:52.100]  понять? Мы просто можем отсечь позиции,
[45:52.100 --> 45:55.100]  когда мы пришли в ерор, и отсечь позицию, когда мы
[45:55.100 --> 45:58.100]  вышли из этого ерора. Это как раз этот участок, и
[45:58.100 --> 46:01.100]  будет ошибка в компиляции.
[46:08.100 --> 46:11.100]  А зависит от того,
[46:11.100 --> 46:14.100]  где мы эти ерор-токены будем вставлять?
[46:14.100 --> 46:17.100]  Нет, конечно же.
[46:17.100 --> 46:20.100]  Ну вот, два примера.
[46:23.100 --> 46:26.100]  В смысле, давайте разбирать,
[46:26.100 --> 46:29.100]  значит, что такое expression, да?
[46:32.100 --> 46:35.100]  Нет, не PSP, а грамматика для арифметики,
[46:35.100 --> 46:38.100]  предположим. У нас есть последствия
[46:38.100 --> 46:41.100]  операторов пресваивания,
[46:41.100 --> 46:44.100]  а равно b плюс c и так далее, и там, допустим, есть
[46:44.100 --> 46:47.100]  а равно скобка открывается.
[46:56.100 --> 46:59.100]  Нет, это вот, если мы говорим про
[46:59.100 --> 47:02.100]  бизон, внутри него есть прямо ключевое слово
[47:02.100 --> 47:05.100]  ерор в грамматике.
[47:18.100 --> 47:21.100]  Да, можно быстрее. То есть, тут как раз, если
[47:21.100 --> 47:24.100]  говорится про обработку ерор-токенов, то сначала мы можем
[47:24.100 --> 47:27.100]  пытаемся, то есть, если мы пришли в какое-то
[47:27.100 --> 47:30.100]  место, пытаемся
[47:30.100 --> 47:33.100]  размотать стэк, который вот у нас был, пока мы не
[47:33.100 --> 47:36.100]  можем сделать shift по ерор-токену. То есть, грубо
[47:36.100 --> 47:39.100]  говоря, идем, идем, идем, потом понимаем, что мы
[47:39.100 --> 47:42.100]  зашли в какую-то ситуацию, причем в этой ситуации
[47:42.100 --> 47:45.100]  мы сделали shift по ерору. Наша цель будет
[47:45.100 --> 47:48.100]  выйти как можно быстрее и пройти дальше.
[47:54.100 --> 47:57.100]  Ну, смотри.
[47:57.100 --> 48:00.100]  Давайте посмотрим. Значит, у нас есть правило, допустим,
[48:00.100 --> 48:03.100]  х, вот.
[48:03.100 --> 48:06.100]  Вот такое вот. А у нас правило
[48:06.100 --> 48:09.100]  вот такое.
[48:09.100 --> 48:12.100]  Ну, то есть, вот у нас слово такое.
[48:12.100 --> 48:15.100]  Да, да, нам дали.
[48:15.100 --> 48:18.100]  Плюс.
[48:19.100 --> 48:22.100]  Угу.
[48:22.100 --> 48:25.100]  Хорошо. Тогда что у нас будет с грамматикой?
[48:32.100 --> 48:35.100]  Ну, смотрите, давайте мы
[48:35.100 --> 48:38.100]  допустим,
[48:38.100 --> 48:41.100]  e id плюс, вот такое
[48:41.100 --> 48:44.100]  вот, или e
[48:44.100 --> 48:47.100]  ерор
[48:47.100 --> 48:50.100]  закрывается. У нас два таких правила.
[48:54.100 --> 48:57.100]  Да, переменная.
[48:57.100 --> 49:00.100]  Стандартная нотация. То есть, а здесь у нас
[49:00.100 --> 49:03.100]  получается, какая грамматика?
[49:03.100 --> 49:06.100]  Это плюс-плюс-плюс закрывается.
[49:06.100 --> 49:09.100]  Скопка открывается, плюс-плюс-плюс это три
[49:09.100 --> 49:12.100]  токена у нас. То есть, плюс может обозначаться как
[49:12.100 --> 49:15.100]  отдельный токен.
[49:17.100 --> 49:20.100]  А у нас его нету.
[49:20.100 --> 49:23.100]  Вот это наше входное выражение.
[49:23.100 --> 49:26.100]  Вот нам нужно в нем найти ошибку компиляции.
[49:29.100 --> 49:32.100]  Да, да, да.
[49:32.100 --> 49:35.100]  А вот,
[49:35.100 --> 49:38.100]  предпочтительнее он
[49:38.100 --> 49:41.100]  начинает разбирать то, что без ошибки.
[49:41.100 --> 49:44.100]  По факту мы можем сказать, что, значит,
[49:44.100 --> 49:47.100]  как мы можем работать с ерор токеном?
[49:47.100 --> 49:50.100]  Вот давайте подумаем. Мы можем сказать, что у нас
[49:50.100 --> 49:53.100]  в нашей грамматике, помимо переходов к
[49:53.100 --> 49:56.100]  грамматике, мы можем сказать, что
[49:56.100 --> 49:59.100]  у нас есть
[49:59.100 --> 50:02.100]  в нашей грамматике, помимо переходов
[50:02.100 --> 50:05.100]  по определенному символу, которые были
[50:05.100 --> 50:08.100]  классические, у нас дополнительно будут добавляться
[50:08.100 --> 50:11.100]  переходы по ерору.
[50:11.100 --> 50:14.100]  То есть, которые будут нас возвращать туда же.
[50:14.100 --> 50:17.100]  То есть, образно говоря,
[50:17.100 --> 50:20.100]  у нас если было...
[50:23.100 --> 50:26.100]  Вот, допустим, мы здесь находились.
[50:27.100 --> 50:30.100]  ID, да, или
[50:33.100 --> 50:36.100]  ерор вот такой вот.
[50:36.100 --> 50:39.100]  То есть, ну что мы можем сделать? Если по ID мы идем,
[50:39.100 --> 50:42.100]  то идем сюда. Если по какому-то другому токену,
[50:42.100 --> 50:45.100]  то мы это...
[50:45.100 --> 50:48.100]  Если, значит, по фигурной скобке,
[50:48.100 --> 50:51.100]  ой, по закрывающей скобке мы можем двигаться дальше.
[50:51.100 --> 50:54.100]  То есть, причитав этот ерор токен,
[50:54.100 --> 50:57.100]  давайте вот так.
[50:58.100 --> 51:01.100]  То есть, тут, понимаете,
[51:01.100 --> 51:04.100]  нужно некоторое запоминание в уме. То есть, у нас скобка
[51:04.100 --> 51:07.100]  закрывается, тогда мы едем дальше.
[51:07.100 --> 51:10.100]  А по всему остальному мы делаем следующее. Мы
[51:10.100 --> 51:13.100]  берем и этот.
[51:13.100 --> 51:16.100]  Делаем переход по пустому слову, ждем, пока мы
[51:16.100 --> 51:19.100]  не по пустому слову, а по слову нашей грамматики.
[51:19.100 --> 51:22.100]  То есть, здесь будет переход по плюсу,
[51:22.100 --> 51:25.100]  который сделает шифт нашего символа плюс.
[51:25.100 --> 51:28.100]  Да, но при этом, по факту,
[51:28.100 --> 51:31.100]  его в путь на стеке не положат.
[51:31.100 --> 51:34.100]  То есть, как бы получается эфемерный путь,
[51:34.100 --> 51:37.100]  который мы не запоминаем.
[51:42.100 --> 51:45.100]  Не-не-не, здесь важно, что
[51:45.100 --> 51:48.100]  именно по вот этим правилам мы строим. То есть, сначала
[51:48.100 --> 51:51.100]  грамматику строим для правил, а потом уже дополнительно
[51:51.100 --> 51:54.100]  переходы по RTOX.
[51:57.100 --> 52:00.100]  Да.
[52:13.100 --> 52:16.100]  Да, такого правила не дали.
[52:21.100 --> 52:24.100]  Да.
[52:31.100 --> 52:34.100]  А, понял, понял, понял.
[52:41.100 --> 52:44.100]  Видимо, согласен здесь. Здесь есть несколько
[52:44.100 --> 52:47.100]  подходов. Допустим, мы можем сделать следующее. Сразу
[52:47.100 --> 52:50.100]  при первом переходе сделать шифт по символу
[52:50.100 --> 52:53.100]  еррор. То есть, встретили плюс, встретили символ,
[52:53.100 --> 52:56.100]  которого у нас нет, мы делаем шифт сразу по символу
[52:56.100 --> 52:59.100]  еррор.
[53:04.100 --> 53:07.100]  Да, да, да. То есть, мы по факту
[53:07.100 --> 53:10.100]  можем сказать, что мы создаем дубликат этого состояния,
[53:10.100 --> 53:13.100]  в котором у нас здесь идет еррор,
[53:13.100 --> 53:16.100]  точка здесь.
[53:16.100 --> 53:19.100]  Нет,
[53:19.100 --> 53:22.100]  после еррора идти не терминал не может, потому что
[53:22.100 --> 53:25.100]  здесь мы обрабатываем с вами только входное слово.
[53:25.100 --> 53:28.100]  То есть, мы здесь переходим в режим, что у нас
[53:28.100 --> 53:31.100]  идут слова из входного языка.
[53:31.100 --> 53:34.100]  Да.
[53:43.100 --> 53:46.100]  Надо, да. То есть, ниже мы раскрываться
[53:46.100 --> 53:49.100]  не можем для того, чтобы не делать дополнительного
[53:49.100 --> 53:52.100]  выклеивания.
[53:55.100 --> 53:58.100]  Да, да, да, да.
[53:58.100 --> 54:01.100]  Вот.
[54:01.100 --> 54:04.100]  Значит, то есть, вот такая вот вещь, она
[54:04.100 --> 54:07.100]  есть, и она реально может пригождаться на практике,
[54:07.100 --> 54:10.100]  главное не забывать считать всякие скобочные балансы,
[54:10.100 --> 54:13.100]  собственно, там, чтобы у нас
[54:13.100 --> 54:16.100]  не ломать семантическую сущность разбора.
[54:16.100 --> 54:19.100]  То есть, желательно как раз задавать как можно больше
[54:19.100 --> 54:22.100]  вот таких вот семантических инструкций.
[54:22.100 --> 54:25.100]  Так, ну, смотрите, ладно, мы все-таки
[54:25.100 --> 54:28.100]  компилятор пишем, и причем мы пишем достаточно
[54:28.100 --> 54:31.100]  современный компилятор.
[54:31.100 --> 54:34.100]  А что помимо того, что у нас есть ошибки в компиляторе?
[54:34.100 --> 54:37.100]  Что у нас еще есть?
[54:37.100 --> 54:40.100]  Что? Вормиги? Нет.
[54:40.100 --> 54:43.100]  Багги.
[54:43.100 --> 54:46.100]  Багги-то, естественно, есть. Нет.
[54:46.100 --> 54:49.100]  Вот мы напишем с вами
[54:49.100 --> 54:52.100]  может быть даже какую-нибудь командную строку откроем.
[54:52.100 --> 54:55.100]  Так.
[54:55.100 --> 54:58.100]  Так, у меня какой Python?
[55:04.100 --> 55:07.100]  Так.
[55:07.100 --> 55:10.100]  Эх, был плохой компилятор.
[55:10.100 --> 55:13.100]  Да я понимаю, я специально
[55:13.100 --> 55:16.100]  вызываю эту штуку.
[55:16.100 --> 55:19.100]  Если вы хотите показать
[55:20.100 --> 55:23.100]  в подсказке выдаст.
[55:32.100 --> 55:35.100]  Импорт.
[55:36.100 --> 55:39.100]  Не, не, не, понятно, то есть
[55:39.100 --> 55:42.100]  Господи.
[55:42.100 --> 55:45.100]  Ой, есть у меня.
[55:46.100 --> 55:49.100]  О, ура!
[55:49.100 --> 55:52.100]  Получилось.
[55:59.100 --> 56:02.100]  А кстати, в Python есть
[56:02.100 --> 56:05.100]  еще такая вещь, как Syntax Forming.
[56:09.100 --> 56:12.100]  Например, можно пробовать строку, умножить
[56:12.100 --> 56:15.100]  сло и взять срез, и все это проделать
[56:15.100 --> 56:18.100]  без другого слова.
[56:18.100 --> 56:21.100]  Он выдаст вам Syntax Forming, что вы берете средства
[56:21.100 --> 56:24.100]  не от строки.
[56:24.100 --> 56:27.100]  Есть разные вещи.
[56:27.100 --> 56:30.100]  Собственно, к чему я клоню? К
[56:30.100 --> 56:33.100]  восстановлению ошибок в компиляции.
[56:33.100 --> 56:36.100]  Собственно, здесь есть вот такая вещь.
[56:36.100 --> 56:39.100]  Это метод Бурке Фишера, он достаточно известный.
[56:39.100 --> 56:42.100]  Значит, что мы делаем? Он как раз хорошо
[56:42.100 --> 56:45.100]  работает для лир алгоритма.
[56:45.100 --> 56:48.100]  И чем он заключается? Мы держим очередь из
[56:48.100 --> 56:51.100]  к токенов, которые могут быть исправлены,
[56:51.100 --> 56:54.100]  которые необходимы для возрождения коррекции.
[56:54.100 --> 56:57.100]  И между с ними, то есть представьте себе,
[56:57.100 --> 57:00.100]  что у вас есть два запуска лир алгоритма.
[57:00.100 --> 57:03.100]  Один, который едет вперед, а другой, который
[57:03.100 --> 57:06.100]  отстает на ка большое токенов для возможной
[57:07.100 --> 57:10.100]  Сначала первый проход, потом идет второй проход.
[57:10.100 --> 57:13.100]  Как только мы делаем по токену Shift,
[57:13.100 --> 57:16.100]  мы добавляем этот символ в очередь
[57:16.100 --> 57:19.100]  и обновляем стэки.
[57:19.100 --> 57:22.100]  Когда у нас происходят ошибки в компиляции,
[57:22.100 --> 57:25.100]  то мы пытаемся сделать возможную либо инсерцию,
[57:25.100 --> 57:28.100]  либо даляцию, либо замену.
[57:28.100 --> 57:31.100]  То есть как бы подсказываем
[57:31.100 --> 57:34.100]  следующему старому стэку.
[57:34.100 --> 57:37.100]  То есть у нас получается из настоящего,
[57:37.100 --> 57:40.100]  мы говорим в прошлом, может быть ты исправишь
[57:40.100 --> 57:43.100]  то, что происходит?
[57:43.100 --> 57:46.100]  И начинаем перебирать варианты.
[57:46.100 --> 57:49.100]  Понятно, что здесь уже возможен разный
[57:49.100 --> 57:52.100]  статистический анализ, вот это важно.
[57:52.100 --> 57:55.100]  Что мы понимаем, грубо говоря, собираем кодовую базу людей
[57:55.100 --> 57:58.100]  и вычисляем вероятности того,
[57:58.100 --> 58:01.100]  какую ошибку именно допустили.
[58:01.100 --> 58:04.100]  Марковские цепи, знаем, что такое?
[58:04.100 --> 58:07.100]  Марковские цепи, ну...
[58:07.100 --> 58:10.100]  А, у вас только начались слупы.
[58:10.100 --> 58:13.100]  Вот представьте себе, что у вас есть какой-то процесс
[58:13.100 --> 58:16.100]  во времени, причем важно, что этот процесс
[58:16.100 --> 58:19.100]  во времени, он зависит только от предыдущего события времени,
[58:19.100 --> 58:22.100]  но никаким образом.
[58:22.100 --> 58:25.100]  То есть у нас есть, получается, события...
[58:25.100 --> 58:28.100]  Да, случайный. То есть у нас есть процесс
[58:28.100 --> 58:31.100]  и он зависит только от того, что мы наблюдали
[58:31.100 --> 58:34.100]  в момент времени t-1,
[58:34.100 --> 58:37.100]  но не наблюдали в момент времени ранее.
[58:37.100 --> 58:40.100]  А, что формально это математически можно описать.
[58:40.100 --> 58:43.100]  В итоге у нас вот этот весь процесс можно задать
[58:43.100 --> 58:46.100]  в матрице фазового перехода от момента времени t-1
[58:46.100 --> 58:49.100]  до момента времени t.
[58:49.100 --> 58:52.100]  Ну и дальше, какая наша цель? Наша цель состоит в том,
[58:52.100 --> 58:55.100]  чтобы собрать статистику переходов, вот мы, допустим, были
[58:55.100 --> 58:58.100]  в наборе токенов, собственно, в какой набор токен
[58:58.100 --> 59:01.100]  мы дальше можем перейти.
[59:01.100 --> 59:04.100]  И в зависимости от этого предлагаю самый вероятный токен для починки.
[59:04.100 --> 59:07.100]  Как вариант.
[59:07.100 --> 59:10.100]  То есть видите, здесь уже идут всякие статистические анализы.
[59:13.100 --> 59:16.100]  То есть, как говорится, некоторые науки
[59:16.100 --> 59:19.100]  у нас синергируют.
[59:19.100 --> 59:22.100]  Хорошо, значит...
[59:22.100 --> 59:25.100]  Да, опять же, нужно учитывать семантические особенности.
[59:25.100 --> 59:28.100]  Поэтому либо мы используем
[59:28.100 --> 59:31.100]  семантический анализ,
[59:31.100 --> 59:34.100]  либо, допустим, для какой-то переменной, которая у нас, допустим,
[59:34.100 --> 59:37.100]  не была объявлена, мы можем предложить.
[59:37.100 --> 59:40.100]  Давайте этой переменной предъявим значение по умолчанию.
[59:40.100 --> 59:43.100]  0, 1 и так далее.
[59:43.100 --> 59:46.100]  Вот, собственно, это такая дополнительная вещь.
[59:46.100 --> 59:49.100]  Ну и последнее, что можно предлагать,
[59:49.100 --> 59:52.100]  это...
[59:52.100 --> 59:55.100]  предлагать дополнительный набор правил, из которых
[59:55.100 --> 59:58.100]  пользователь мог ошибиться.
[59:58.100 --> 01:00:01.100]  Их можно предлагать очень много.
[01:00:01.100 --> 01:00:04.100]  Скопку забыл, фигурную скопку забыл
[01:00:04.100 --> 01:00:07.100]  поставить еще, закрыл и так далее.
[01:00:07.100 --> 01:00:10.100]  Главное, чтобы сами вот эти наборы правил, которые мы дополнительно добавляем,
[01:00:10.100 --> 01:00:13.100]  не добавляли определенных конфликтов.
[01:00:13.100 --> 01:00:16.100]  Вот, это будет важно.
[01:00:16.100 --> 01:00:19.100]  Так, собственно, это все, что касается теми
[01:00:19.100 --> 01:00:22.100]  синтоксического анализа.
[01:00:22.100 --> 01:00:25.100]  Так, давайте по ней вопросы.
[01:00:25.100 --> 01:00:28.100]  У нас еще очень...
[01:00:35.100 --> 01:00:38.100]  Значит, смотрите,
[01:00:38.100 --> 01:00:41.100]  была статья, по-моему,
[01:00:41.100 --> 01:00:44.100]  AntLR1
[01:00:44.100 --> 01:00:47.100]  is not needed.
[01:00:50.100 --> 01:00:53.100]  Архив, по-моему.
[01:01:02.100 --> 01:01:05.100]  Да вот, да. Сейчас я найду.
[01:01:11.100 --> 01:01:14.100]  Сейчас, подождите, найду статью эту.
[01:01:20.100 --> 01:01:23.100]  Так, статья называется...
[01:01:23.100 --> 01:01:26.100]  статья 2010 года.
[01:01:26.100 --> 01:01:29.100]  Мы ее найдем в поисковике.
[01:01:29.100 --> 01:01:32.100]  А, во!
[01:01:32.100 --> 01:01:35.100]  А он не про LR, он про этот.
[01:01:35.100 --> 01:01:38.100]  Вот.
[01:01:38.100 --> 01:01:41.100]  Вот.
[01:01:41.100 --> 01:01:44.100]  Собственно,
[01:01:44.100 --> 01:01:47.100]  YAK SD это называется статья.
[01:01:47.100 --> 01:01:50.100]  Значит, YAK это именно Бизон в современных интерпретациях.
[01:01:50.100 --> 01:01:53.100]  Вот такая вот статья.
[01:01:53.100 --> 01:01:56.100]  Типа, и говорится, что
[01:01:56.100 --> 01:01:59.100]  top-down motivation, пора это.
[01:01:59.100 --> 01:02:02.100]  Заканчивать каргокульт парсинга, товарищ пишет здесь.
[01:02:02.100 --> 01:02:05.100]  Вот.
[01:02:05.100 --> 01:02:08.100]  И говорит, что, типа, изначально
[01:02:08.100 --> 01:02:11.100]  все это затачивалось
[01:02:11.100 --> 01:02:14.100]  по то, чтобы, если мы что-то парсим,
[01:02:14.100 --> 01:02:17.100]  то это прямо то, что мы видим,
[01:02:17.100 --> 01:02:20.100]  то мы и получаем на выходе. Визивик, так называемый.
[01:02:20.100 --> 01:02:23.100]  И как раз вот и sees, вот и get.
[01:02:23.100 --> 01:02:26.100]  И как раз, если мы говорим про регулярные выражения, они такие есть.
[01:02:26.100 --> 01:02:29.100]  То есть, мы с вами с регулярными выражениями видим, что происходит.
[01:02:29.100 --> 01:02:32.100]  А что происходит с автоматами, мы не видим.
[01:02:32.100 --> 01:02:35.100]  Ну, что происходит. Вот.
[01:02:35.100 --> 01:02:38.100]  И поэтому здесь товарищ очень долго прямо рассказывает.
[01:02:38.100 --> 01:02:41.100]  Прямо про то, что, типа, в чем проблема
[01:02:41.100 --> 01:02:44.100]  иллера, алгоритма.
[01:02:44.100 --> 01:02:47.100]  Вот.
[01:02:47.100 --> 01:02:50.100]  Ну, собственно, и здесь предлагает это.
[01:02:50.100 --> 01:02:53.100]  Ну, тут прямо математика, математика, математика.
[01:02:53.100 --> 01:02:56.100]  Вот. И, в общем, тут
[01:02:56.100 --> 01:02:59.100]  предлагается обойти
[01:02:59.100 --> 01:03:02.100]  этот подход.
[01:03:02.100 --> 01:03:05.100]  В общем, видно, что здесь уже какие-то
[01:03:05.100 --> 01:03:08.100]  это...
[01:03:08.100 --> 01:03:11.100]  интересные вещи. Ну, и тут если почитать...
[01:03:11.100 --> 01:03:14.100]  А?
[01:03:14.100 --> 01:03:17.100]  Не, не критикуйте алгоритм.
[01:03:17.100 --> 01:03:20.100]  Он добавляет свои собственные механизмы, так сказать,
[01:03:20.100 --> 01:03:23.100]  предиктивного парсинга и так далее. И говорит здесь, что
[01:03:23.100 --> 01:03:26.100]  это...
[01:03:26.100 --> 01:03:29.100]  типа, что для некоторых библиотек они не очень
[01:03:29.100 --> 01:03:32.100]  хорошо подходят, так сказать.
[01:03:32.100 --> 01:03:35.100]  Вот. Поэтому лучше
[01:03:35.100 --> 01:03:38.100]  использовать методы, которые позволяют,
[01:03:38.100 --> 01:03:41.100]  так сказать,
[01:03:41.100 --> 01:03:44.100]  те библиотеки, которые легко, во-первых, пишутся
[01:03:44.100 --> 01:03:47.100]  и легко понимаются. Ну, то есть даже если мы
[01:03:47.100 --> 01:03:50.100]  сделаем сравнение, то что намного быстрее
[01:03:50.100 --> 01:03:53.100]  понимается? Иллель алгоритм или лерн алгоритм?
[01:03:54.100 --> 01:03:57.100]  Иллель, конечно. То есть для разбора иллеля нам достаточно
[01:03:57.100 --> 01:04:00.100]  пол пары. Для того, чтобы разобрать иллель, нам нужно там пары
[01:04:00.100 --> 01:04:03.100]  три. И тем более, особенно дебагать
[01:04:03.100 --> 01:04:06.100]  иллель алгоритм намного проще, чем иллер алгоритм.
[01:04:06.100 --> 01:04:09.100]  Потому что вот у вас есть таблица, вот сидите, разбирайтесь
[01:04:09.100 --> 01:04:12.100]  с ней. Типа, таблица обычно, если там
[01:04:12.100 --> 01:04:15.100]  ее сконвертировать в png, то там 10 тысяч на 10 тысяч
[01:04:15.100 --> 01:04:18.100]  пикселей. Вот такая вот простыня.
[01:04:18.100 --> 01:04:21.100]  И сиди, разбирайся, где это все происходит.
[01:04:21.100 --> 01:04:24.100]  Вот, поэтому
[01:04:24.100 --> 01:04:27.100]  на практике сейчас все-таки используют
[01:04:27.100 --> 01:04:30.100]  эти не сходящие парсеры,
[01:04:30.100 --> 01:04:33.100]  а не восходящие. Ну, это видно даже
[01:04:33.100 --> 01:04:36.100]  по популярности того, что
[01:04:36.100 --> 01:04:39.100]  происходит.
[01:04:42.100 --> 01:04:45.100]  Ну, да, мы говорили, что
[01:04:45.100 --> 01:04:48.100]  антеллер работает за квадрат в худшем случае,
[01:04:48.100 --> 01:04:51.100]  но там худший случай это
[01:04:51.100 --> 01:04:54.100]  N умножить на какую-то константу K.
[01:04:57.100 --> 01:05:00.100]  N на константу K. K это
[01:05:00.100 --> 01:05:03.100]  как раз максимальная длина контекста, которую нужно
[01:05:03.100 --> 01:05:06.100]  предсказывать. Так вот, проводили статистические
[01:05:06.100 --> 01:05:09.100]  анализы, оказывается, что там в большом проценте
[01:05:09.100 --> 01:05:12.100]  случаев там K равняется двойке-тройке.
[01:05:12.100 --> 01:05:15.100]  То есть за двойку-тройку уходить не надо. То есть получается, что
[01:05:15.100 --> 01:05:18.100]  мы не тратим время на то, чтобы строить вот эту
[01:05:18.100 --> 01:05:21.100]  огромную таблицу, хранить большое количество оперативной памяти,
[01:05:21.100 --> 01:05:24.100]  а на лету пытаемся прямо
[01:05:24.100 --> 01:05:27.100]  строить контекст, и этого вполне достаточно.
[01:05:27.100 --> 01:05:30.100]  То есть у нас получается и по времени, и
[01:05:30.100 --> 01:05:33.100]  по памяти, и по времени.
[01:05:36.100 --> 01:05:39.100]  Ну, не LL1, LL звездочка
[01:05:39.100 --> 01:05:42.100]  все-таки.
[01:05:45.100 --> 01:05:48.100]  Ну, ошибок много. То есть у вас, допустим,
[01:05:48.100 --> 01:05:51.100]  грамматика, в которой есть неявная рекурсия.
[01:05:51.100 --> 01:05:54.100]  Вот мы сидим, то есть одна из проблем
[01:05:54.100 --> 01:05:57.100]  как раз нисходящих парсерий, это неявная
[01:05:57.100 --> 01:06:00.100]  рекурсия. Неявная левостроение
[01:06:00.100 --> 01:06:03.100]  рекурсия.
[01:06:03.100 --> 01:06:06.100]  Ну да, ее убирать мы умеем,
[01:06:06.100 --> 01:06:09.100]  но вот, типа, образно говоря, там
[01:06:09.100 --> 01:06:12.100]  в каком моменте это может возникнуть? Там какая-нибудь
[01:06:12.100 --> 01:06:15.100]  сложная математически-кабинаторная лямбда функция,
[01:06:15.100 --> 01:06:18.100]  которую фиг пойми, как разбирать.
[01:06:18.100 --> 01:06:21.100]  Где неявные рекурсии, неявные рекурсии
[01:06:21.100 --> 01:06:24.100]  погоняют.
[01:06:27.100 --> 01:06:30.100]  Ну, что? Да.
[01:06:30.100 --> 01:06:33.100]  Зачастую именно так сейчас.
[01:06:33.100 --> 01:06:36.100]  LR не работает?
[01:06:36.100 --> 01:06:39.100]  Можно взять и переключиться на JLR.
[01:06:39.100 --> 01:06:42.100]  JLR, он любит...
[01:06:42.100 --> 01:06:45.100]  Да, он уже с всеми однозначными работает,
[01:06:45.100 --> 01:06:48.100]  но нужно сразу заложить, что
[01:06:48.100 --> 01:06:51.100]  асимптотика может быть больше.
[01:06:51.100 --> 01:06:54.100]  А более того, если рассказывать
[01:06:54.100 --> 01:06:57.100]  совсем веселые моменты, то, как не странно,
[01:06:57.100 --> 01:07:00.100]  вот те люди, которые еще занимаются всякими
[01:07:00.100 --> 01:07:03.100]  диффузионными моделями, там
[01:07:03.100 --> 01:07:06.100]  красивые картинки генерят,
[01:07:06.100 --> 01:07:09.100]  я дебажил один раз код,
[01:07:09.100 --> 01:07:12.100]  как раз для этих диффузионных моделей, смотрю,
[01:07:12.100 --> 01:07:15.100]  что-то не работает. Читаю в отладчике,
[01:07:15.100 --> 01:07:18.100]  читаю stacktrace. Написано early.py.
[01:07:18.100 --> 01:07:21.100]  Ну,
[01:07:21.100 --> 01:07:24.100]  прям в отладчике.
[01:07:24.100 --> 01:07:27.100]  Стактрейс, и там early.py написано.
[01:07:27.100 --> 01:07:30.100]  То есть люди вообще не парятся, короче, для коротких слов,
[01:07:30.100 --> 01:07:33.100]  а там как раз механизм парсинга такой,
[01:07:33.100 --> 01:07:36.100]  какому-то слову меньше тона дать и так далее.
[01:07:36.100 --> 01:07:39.100]  Просто не паримся, пишем early.
[01:07:39.100 --> 01:07:42.100]  За квадрат работает.
[01:07:42.100 --> 01:07:45.100]  Почему бы и нет? Ну, за квадрат для однозначных
[01:07:45.100 --> 01:07:48.100]  агроматик работает.
[01:07:48.100 --> 01:07:51.100]  Ну вот, да, зачем придумывать еще что-то?
[01:07:51.100 --> 01:07:54.100]  Ну, понятно, что когда у нас квадрат, собственно,
[01:07:54.100 --> 01:07:57.100]  на код в 10 миллионов строк, то это уже будет
[01:07:57.100 --> 01:08:00.100]  проблема.
[01:08:00.100 --> 01:08:03.100]  Ну, может быть, 1С компилировать из исходников.
[01:08:03.100 --> 01:08:06.100]  Ну, или любую другую библиотеку из исходников,
[01:08:06.100 --> 01:08:09.100]  это будет тяжело.
[01:08:09.100 --> 01:08:12.100]  Так, это что касается синтоксического анализа.
[01:08:12.100 --> 01:08:15.100]  Давайте тогда я сегодня сделаю некоторое
[01:08:15.100 --> 01:08:18.100]  предварительное знакомство с тем, куда мы будем двигаться дальше.
[01:08:18.100 --> 01:08:21.100]  10 минут осталось.
[01:08:21.100 --> 01:08:24.100]  Это семантический анализ. То есть следующие несколько лекций
[01:08:24.100 --> 01:08:27.100]  мы с вами посвятим тому, что мы будем с вами детально
[01:08:27.100 --> 01:08:30.100]  рассматривать, что такое семантический анализ.
[01:08:30.100 --> 01:08:33.100]  То есть, где мы находимся с вами на стадии компилятора?
[01:08:33.100 --> 01:08:36.100]  То есть, мы с вами написали сканер, у нас есть парсер,
[01:08:36.100 --> 01:08:39.100]  у нас есть дерево вывода, но что у нас теперь есть?
[01:08:39.100 --> 01:08:42.100]  Нам нужно что-то с этим деревом вывода сделать.
[01:08:42.100 --> 01:08:45.100]  Для того, чтобы мы с вами пришли к промежуточному
[01:08:45.100 --> 01:08:48.100]  представлению. Здесь будет несколько шагов.
[01:08:48.100 --> 01:08:51.100]  И вот смотрите, важный момент, вот в этом слайде
[01:08:51.100 --> 01:08:54.100]  видите, вот это вот поле инфрастракция.
[01:08:54.100 --> 01:08:57.100]  Инфраструктуры написания компилятора.
[01:08:57.100 --> 01:09:00.100]  Сейчас мы с вами видим на самом деле, что у нас
[01:09:00.100 --> 01:09:03.100]  эта инфраструктура никак не была завязана между
[01:09:03.100 --> 01:09:06.100]  стадиями компиляции. То есть, мы взяли
[01:09:06.100 --> 01:09:09.100]  сканер, запустили его, взяли парсер, его
[01:09:09.100 --> 01:09:12.100]  запустили. А вот на этой стадии мы как раз начнем
[01:09:12.100 --> 01:09:15.100]  пользоваться инфраструктурой. То есть, выход
[01:09:15.100 --> 01:09:18.100]  каждой стадии, то есть выхода из предыдущей стадии
[01:09:18.100 --> 01:09:21.100]  нам вполне может быть недостаточно.
[01:09:21.100 --> 01:09:24.100]  Нам нужно будет использовать это еще каким-то
[01:09:24.100 --> 01:09:27.100]  образом. Вот, давайте поймем.
[01:09:27.100 --> 01:09:30.100]  Вот у нас есть токен,
[01:09:30.100 --> 01:09:33.100]  который вышел после стадии
[01:09:33.100 --> 01:09:36.100]  сканера, ну и после стадии парсера он
[01:09:36.100 --> 01:09:39.100]  привязался к какому-то правилу.
[01:09:39.100 --> 01:09:42.100]  Что нам нужно знать о токене?
[01:09:45.100 --> 01:09:48.100]  В каком правиле он находится?
[01:09:48.100 --> 01:09:51.100]  В каком правиле он находится?
[01:09:51.100 --> 01:09:54.100]  Какой тип он имеет?
[01:09:54.100 --> 01:09:57.100]  Его значение, да.
[01:09:59.100 --> 01:10:02.100]  Вот смотрите, у нас есть токен, а-ля
[01:10:02.100 --> 01:10:05.100]  идент.
[01:10:06.100 --> 01:10:09.100]  Идентификатор.
[01:10:09.100 --> 01:10:12.100]  Вот. Но что у нас может быть?
[01:10:14.100 --> 01:10:17.100]  Этот идентификатор, в принципе, может быть типом
[01:10:17.100 --> 01:10:20.100]  в какой-то момент времени.
[01:10:20.100 --> 01:10:23.100]  То есть, обозначением самого типа. То есть, у нас есть
[01:10:23.100 --> 01:10:26.100]  класс full, допустим, да. Это у нас
[01:10:26.100 --> 01:10:29.100]  класс, идентификатор будет.
[01:10:29.100 --> 01:10:32.100]  Сейчас дайте я доски с утру.
[01:10:42.100 --> 01:10:45.100]  То есть, у нас есть класс full.
[01:10:46.100 --> 01:10:49.100]  То есть, это название класса, это какой-нибудь
[01:10:49.100 --> 01:10:52.100]  typeIdent.
[01:10:52.100 --> 01:10:55.100]  Его даже можно попробовать различить. Но потом
[01:10:55.100 --> 01:10:58.100]  в какой-то момент времени мы, допустим, указываем.
[01:11:06.100 --> 01:11:09.100]  Вот такую вещь пишем.
[01:11:11.100 --> 01:11:14.100]  Разный контекст. То есть, здесь это объявление типа
[01:11:14.100 --> 01:11:17.100]  здесь это вызов конструктора.
[01:11:18.100 --> 01:11:21.100]  Здесь это
[01:11:21.100 --> 01:11:24.100]  определение типа.
[01:11:24.100 --> 01:11:27.100]  И надо это каким-то образом понять.
[01:11:28.100 --> 01:11:31.100]  Ну а?
[01:11:42.100 --> 01:11:45.100]  Да, мы сможем определять свои собственные типы.
[01:11:45.100 --> 01:11:48.100]  Ну да.
[01:11:51.100 --> 01:11:54.100]  На машине Тюринга будет сложно
[01:11:54.100 --> 01:11:57.100]  программировать.
[01:11:57.100 --> 01:12:00.100]  Ну да.
[01:12:00.100 --> 01:12:03.100]  Итак, смотрите. Нам нужно будет понять о токене.
[01:12:03.100 --> 01:12:06.100]  Какого он типа, если это токен переменная?
[01:12:06.100 --> 01:12:09.100]  Вторая важная вещь. Какое количество памяти он
[01:12:09.100 --> 01:12:12.100]  занимает, если это переменная? То есть, это массив.
[01:12:12.100 --> 01:12:15.100]  Или это переменная примитивного типа.
[01:12:15.100 --> 01:12:18.100]  Либо это указатель на какой-то класс.
[01:12:18.100 --> 01:12:21.100]  С учетом того, что мы понимаем, что в каком-нибудь
[01:12:21.100 --> 01:12:24.100]  C, C++, Rust, у нас прямо есть явные типи ЗАЗ,
[01:12:24.100 --> 01:12:27.100]  в котором мы можем указать указатель или нет.
[01:12:27.100 --> 01:12:30.100]  То вот в джаве, в питоне, вот это уже какая-то
[01:12:30.100 --> 01:12:33.100]  сложная история.
[01:12:33.100 --> 01:12:36.100]  Потому что в джаве у нас везде обращение идет
[01:12:36.100 --> 01:12:39.100]  по указателю, точнее по ссылке.
[01:12:39.100 --> 01:12:42.100]  В питоне вы пишете x равно 1.
[01:12:42.100 --> 01:12:45.100]  Ну что такое x тогда?
[01:12:45.100 --> 01:12:48.100]  Если бы мы говорили в терминах C++,
[01:12:48.100 --> 01:12:51.100]  то это была бы переменная типа int,
[01:12:51.100 --> 01:12:54.100]  которая занимает 4 байта.
[01:12:54.100 --> 01:12:57.100]  А в питоне это, извините, переменная типа
[01:12:57.100 --> 01:13:00.100]  cpytonint,
[01:13:00.100 --> 01:13:03.100]  которая занимает не 4 байта.
[01:13:03.100 --> 01:13:06.100]  А?
[01:13:06.100 --> 01:13:09.100]  Вот.
[01:13:09.100 --> 01:13:12.100]  То есть вообще непонятно.
[01:13:12.100 --> 01:13:15.100]  То есть питон просто и простой,
[01:13:15.100 --> 01:13:18.100]  но вот он оказывается такой.
[01:13:18.100 --> 01:13:21.100]  Но возможно, что если мы это скомпилируем
[01:13:21.100 --> 01:13:24.100]  при помощи какого-нибудь сайта,
[01:13:24.100 --> 01:13:27.100]  то это возможно и будет int x.
[01:13:27.100 --> 01:13:30.100]  То есть нам нужно понимать,
[01:13:30.100 --> 01:13:33.100]  влезет он в регистр или нет.
[01:13:33.100 --> 01:13:36.100]  У нас токен может быть названием функции,
[01:13:36.100 --> 01:13:39.100]  и тогда нам нужно понимать, какое количество
[01:13:39.100 --> 01:13:42.100]  аргументов он принимает.
[01:13:42.100 --> 01:13:45.100]  Следующий важный момент, который нужно понять,
[01:13:45.100 --> 01:13:48.100]  это область видимости этого токена.
[01:13:48.100 --> 01:13:51.100]  То есть сколько нам нужно хранить значение
[01:13:51.100 --> 01:13:54.100]  этого токена, то есть область видимости.
[01:13:54.100 --> 01:13:57.100]  И вопрос еще следующий, кто ответственный
[01:13:57.100 --> 01:14:00.100]  за локацию и удаление?
[01:14:00.100 --> 01:14:03.100]  Что делать мы, и переходим на си язык,
[01:14:03.100 --> 01:14:06.100]  в котором есть управление памятью?
[01:14:06.100 --> 01:14:09.100]  Либо мы будем реализовывать абстракцию REE.
[01:14:12.100 --> 01:14:15.100]  Либо мы будем писать сборщик мусора.
[01:14:18.100 --> 01:14:21.100]  Либо мы вставляем Borrow Checker.
[01:14:21.100 --> 01:14:24.100]  В общем, много есть таких вещей,
[01:14:24.100 --> 01:14:27.100]  и вот из чего будут состоять стадии симматического анализа.
[01:14:28.100 --> 01:14:31.100]  Важный момент.
[01:14:31.100 --> 01:14:34.100]  Как раз мы пройдемся по абстрактному дереву.
[01:14:34.100 --> 01:14:37.100]  Будем построить токены,
[01:14:37.100 --> 01:14:40.100]  и для каждого токена поймем, что это за переменная,
[01:14:40.100 --> 01:14:43.100]  какой тип и так далее.
[01:14:43.100 --> 01:14:46.100]  Дальше у нас будет идти проверка типов.
[01:14:46.100 --> 01:14:49.100]  Возможно, что мы будем готовить фреймы.
[01:14:49.100 --> 01:14:52.100]  Функциональные фреймы для каждой функции
[01:14:52.100 --> 01:14:55.100]  мы заготовим по факту аналог стека.
[01:14:55.100 --> 01:14:58.100]  Дальше у нас будет идти проверка типов
[01:14:58.100 --> 01:15:01.100]  и промежуточный код.
[01:15:01.100 --> 01:15:04.100]  Сразу скажу, что таблицу символов
[01:15:04.100 --> 01:15:07.100]  можно строить несколькими способами,
[01:15:07.100 --> 01:15:10.100]  и мы построим ее несколькими способами.
[01:15:10.100 --> 01:15:13.100]  Один из них достаточно тупой,
[01:15:13.100 --> 01:15:16.100]  а второй этот способ достаточно умный, но богованный.
[01:15:16.100 --> 01:15:19.100]  Николай, который сидит здесь, нам это подтвердит.
[01:15:19.100 --> 01:15:22.100]  Здесь возникает такая важная вещь,
[01:15:22.100 --> 01:15:25.100]  что нам нужно будет перейти
[01:15:25.100 --> 01:15:28.100]  из грамматики к так называемой атрибутной грамматике.
[01:15:28.100 --> 01:15:31.100]  Для каждого не терминала
[01:15:31.100 --> 01:15:34.100]  мы будем хранить с вами некоторую
[01:15:34.100 --> 01:15:37.100]  осмысленную сущность.
[01:15:37.100 --> 01:15:40.100]  Для каждой сущности, возможно, нам нужно будет
[01:15:40.100 --> 01:15:43.100]  определять набор этих атрибутов.
[01:15:43.100 --> 01:15:46.100]  Если мы говорим вообще очень-очень грубо,
[01:15:46.100 --> 01:15:49.100]  то для каждого компилятора мы можем сказать,
[01:15:49.100 --> 01:15:52.100]  что каждому терминалу и не терминалу
[01:15:52.100 --> 01:15:55.100]  можно соотнести некоторый класс.
[01:15:55.100 --> 01:15:58.100]  Допустим, у нас есть
[01:15:58.100 --> 01:16:01.100]  a равно id плюс id.
[01:16:05.100 --> 01:16:08.100]  Что такое a?
[01:16:11.100 --> 01:16:14.100]  Expression. Причем какой expression?
[01:16:16.100 --> 01:16:19.100]  Expression для сложения.
[01:16:19.100 --> 01:16:22.100]  Мы можем с вами приписать, что, допустим,
[01:16:22.100 --> 01:16:25.100]  атрибут не терминалу a
[01:16:25.100 --> 01:16:28.100]  будет внутри него храниться контекст,
[01:16:28.100 --> 01:16:31.100]  что это именно атрибут для сложения.
[01:16:31.100 --> 01:16:34.100]  И параллельно мы с вами как раз
[01:16:34.100 --> 01:16:37.100]  для каждого не терминала
[01:16:37.100 --> 01:16:40.100]  будем стараться написать объект,
[01:16:40.100 --> 01:16:43.100]  который он содержит.
[01:16:43.100 --> 01:16:46.100]  И он может конвертироваться в ad expression.
[01:16:49.100 --> 01:16:52.100]  Другие стейтменты тоже мы будем обозначать.
[01:16:52.100 --> 01:16:55.100]  То есть, если у нас есть какой-то стейтмент,
[01:16:55.100 --> 01:16:58.100]  вот когда мы встречаем не терминал a
[01:16:58.100 --> 01:17:01.100]  в какой-то момент времени,
[01:17:01.100 --> 01:17:04.100]  как только мы его разбираем, мы строим объект
[01:17:04.100 --> 01:17:07.100]  под названием ad expression,
[01:17:07.100 --> 01:17:10.100]  в котором внутри будет еще, который будет
[01:17:10.100 --> 01:17:13.100]  ad expression, который здесь будет парситься.
[01:17:16.100 --> 01:17:19.100]  Да, уже абстрактную сущность.
[01:17:27.100 --> 01:17:30.100]  Да, да, да.
[01:17:30.100 --> 01:17:33.100]  Причем не все сущности могут выражаться.
[01:17:33.100 --> 01:17:36.100]  Некоторые сущности могут добавляться или убираться.
[01:17:36.100 --> 01:17:39.100]  Дополнительно, если вы хотите что-то делать
[01:17:39.100 --> 01:17:42.100]  с этими сущностями, то в принципе
[01:17:42.100 --> 01:17:45.100]  каждому не терминалу можно посчитать атрибут.
[01:17:45.100 --> 01:17:48.100]  То есть, если у вас есть какой-нибудь простой expression,
[01:17:48.100 --> 01:17:51.100]  образно говоря, смотрите,
[01:17:51.100 --> 01:17:54.100]  x это нам плюс нам.
[01:17:54.100 --> 01:17:57.100]  То есть два числа.
[01:17:57.100 --> 01:18:00.100]  Вы складывайте два числа. Вопрос.
[01:18:00.100 --> 01:18:03.100]  Нужно ли вам создавать ad expression
[01:18:03.100 --> 01:18:06.100]  от вот этих двух значений?
[01:18:06.100 --> 01:18:09.100]  И их посчитать на стадии разбора.
[01:18:15.100 --> 01:18:18.100]  Да, конечно же. То есть мы можем...
[01:18:18.100 --> 01:18:21.100]  Да, да, да. То есть мы можем явно
[01:18:21.100 --> 01:18:24.100]  плескать, что x точка вал
[01:18:27.100 --> 01:18:30.100]  нам плюс нам.
[01:18:36.100 --> 01:18:39.100]  Получилось, да?
[01:18:39.100 --> 01:18:42.100]  Обычно это делается на уровнях листьев деревьев.
[01:18:42.100 --> 01:18:45.100]  Потому что в других местах сложно.
[01:18:45.100 --> 01:18:48.100]  И вот как раз вот эти вот вещи называются атрибутными грамматиками.
[01:18:48.100 --> 01:18:51.100]  Наша цель будет как раз от атрибутных грамматик
[01:18:51.100 --> 01:18:54.100]  перейти... от классической грамматики
[01:18:54.100 --> 01:18:57.100]  перейти к такому понятию, как атрибутная грамматика.
[01:18:57.100 --> 01:19:00.100]  Мы в принципе можем понимать, как делать.
[01:19:00.100 --> 01:19:03.100]  А через него как раз перейти к понятию абстрактной синтоксической дерево разбора.
[01:19:06.100 --> 01:19:09.100]  Да, а когда именно числа пишут?
[01:19:09.100 --> 01:19:12.100]  Четыре плюс пять, допустим.
[01:19:12.100 --> 01:19:15.100]  Да, да, да.
[01:19:15.100 --> 01:19:18.100]  Потому что когда здесь будет identity, мы это уже сделать не сможем.
[01:19:18.100 --> 01:19:21.100]  Потому что там в runtime могут быть проблемы.
[01:19:21.100 --> 01:19:24.100]  Типа переменная, где ее взять и так далее.
[01:19:24.100 --> 01:19:27.100]  И вот как раз вот такие просто случаи можно прямо обчитывать атрибутами.
[01:19:27.100 --> 01:19:30.100]  А вот сложные варианты. Нам нужно уже дерево разбора.
[01:19:30.100 --> 01:19:33.100]  Да, мы заканчиваем все сейчас.
[01:19:33.100 --> 01:19:36.100]  И они будут построить абстрактные синтоксические дерево разбора
[01:19:36.100 --> 01:19:39.100]  и научиться их обходить.
[01:19:39.100 --> 01:19:42.100]  На семинарах мы уже начнем это рассматривать сегодня.
[01:19:42.100 --> 01:19:45.100]  А на лекциях чуть позже это рассмотрим.
[01:19:45.100 --> 01:19:48.100]  Так, ну что?
[01:19:48.100 --> 01:19:51.100]  Видимо у нас следующий лекция через две недели, да?
[01:19:56.100 --> 01:19:59.100]  Да.
[01:19:59.100 --> 01:20:02.100]  В общем, спасибо большое.
[01:20:02.100 --> 01:20:05.100]  Увидимся в следующий раз.
