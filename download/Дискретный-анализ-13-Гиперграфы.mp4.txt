[00:00.000 --> 00:13.000]  так друзья ну все надо начинать вернее надо знаете чего надо не начинать а заканчивать только
[00:13.000 --> 00:19.560]  не в том смысле в каком вы подумали наверное что надо заканчивать курс фигушки вам я понимаю что
[00:19.560 --> 00:26.400]  у вас начались сплошные зачеты дедлайны поэтому вы бы с удовольствием закончили курс сейчас это
[00:26.400 --> 00:33.400]  фигушки я до упора буду читать заканчивать надо ту теорему которую мы начали в прошлый раз у меня
[00:33.400 --> 00:39.120]  чуть-чуть не завершился катарсис я даже объяснил в чем он будет состоять поэтому в каком смысле
[00:39.120 --> 00:47.960]  сорвал его на сегодня но тем не менее давайте вы мне напомните формулу которую я насчитал
[00:47.960 --> 01:00.880]  я наизусть не помню вот ту которая через мю то дельта равняется там как что такое пв равно мёд
[01:00.880 --> 01:14.400]  мюрт что за мюрт я понял не надо подождите у меня то чего получилось там куса звездочкой
[01:14.400 --> 01:19.640]  какое-то было которое отвечало за вероятность вытаскивания еще раз
[01:19.640 --> 01:26.160]  что
[01:32.840 --> 01:40.240]  сейчас подождите ну давайте напомнить я сейчас это конечно очень нехорошо что нам
[01:40.240 --> 01:51.360]  приходится вспоминать что-то по сути так еще раз мы мы оценивали давайте давайте напомним мы
[01:51.360 --> 01:57.720]  оценивали математическое ожидание и грекатого первого оно оказалось за счет вот этого
[01:57.720 --> 02:06.760]  рандомизированного алгоритма который мы придумали оно оказалось не меньше чем мю умножить на куца
[02:06.760 --> 02:20.680]  звездочкой минус дельта куса звездочкой в квадрате пополам было такое но тогда я сейчас вспомню сам
[02:20.680 --> 02:27.400]  чему равно мю раз уж меня заставили это вспоминать такое было что-то миша вот как не может и этого
[02:27.400 --> 02:35.120]  найти тоже было было но я писал что это не меньше чем мат ожидания там какого-то модуля c минус да
[02:35.120 --> 02:45.200]  да да да да да да там было множество дубль вы который дубль ве штрих как
[02:45.200 --> 02:49.480]  которая состояла из вредоносных пар пар который перенул это тоже давайте
[02:49.480 --> 02:55.840]  напомним ладно это же нам нужно еще вот дубль ве штрих давайте я напомню это важно оно
[02:55.840 --> 03:07.480]  состояло из всевозможных пар так потому что так я их называл да каитое кожитое
[03:07.480 --> 03:16.240]  давайте вспомним что такое дубль ве штрих это множество таких пар каитое кожитое что каждый
[03:16.240 --> 03:28.680]  из них принадлежит с и что мощность пересечения каитое кожитое больше либо равняется двойке вот
[03:28.680 --> 03:36.800]  это правда товарищи но я написал тогда вот ошибочно что оно не превосходит единицы перепутал
[03:36.800 --> 03:42.320]  не в ту сторону неравенства написал после этого кто-то мне сказал ну все теперь катарсиса не
[03:42.320 --> 03:49.200]  будет кто-то точно сказал только кажется этого человека тут нет вы были да
[03:57.800 --> 04:09.720]  ну конечно здесь различные ежи да конечно да да да да да здесь пары различных каитое кожитое
[04:09.720 --> 04:15.840]  каждый из которых попало в прореженный набор вот этих независимых множеств мощности к 1
[04:15.840 --> 04:22.560]  каждая и прореженные то вот я его так называю обозначается он ц прореженный в том смысле что
[04:22.560 --> 04:30.960]  мы ц отбирали добавляю вот эту случайность ку со звездочкой что все все забыли что так смотрится
[04:30.960 --> 04:37.440]  на меня грустно так я поэтому и хотел чисто формально вот просто мы к чему-то пришли вы
[04:37.440 --> 04:42.040]  потом будете вспоминать то я ж не могу каждую лекцию заново напоминать то что был на предыдущий
[04:42.040 --> 04:50.320]  но тогда у нас курс будет слишком долгим то есть я его буду читать по два раза в неделю я не
[04:50.320 --> 05:04.320]  обломлюсь значит ц со звездочкой это был это под множество множество ц которое получается из
[05:04.320 --> 05:13.000]  множества ц путем выкидывание по одному элементу из каждой пары принадлежащей w штрих мы берем
[05:13.000 --> 05:19.600]  каждую вредную пару вредная она в том смысле что она плохо пересекается слишком сильно нам не
[05:19.600 --> 05:25.080]  нас не интересует независимое множество которые сильно пересекаются потому что наша цель была
[05:25.080 --> 05:32.560]  оценить мат ожидания y катова первого а y катая первая определялась как набор мощность набора
[05:32.560 --> 05:37.960]  независимых множеств каждые два из которых пересекаются противоположным образом мало не
[05:37.960 --> 05:45.760]  больше чем по одной вершине не знаю но вот на таком уровне вспоминаете и большинство лиц
[05:45.760 --> 05:52.560]  повторяются я имею в виду вот вы здесь сидите я помню что вы и прошлый раз тут сидели и позапрошлый
[05:52.560 --> 05:58.800]  то есть вы не то чтобы ну как бы совсем с нуля сюда пришли конечно не понимаете чего я рассказывал
[05:58.800 --> 06:06.480]  поняли как ц со звездочкой строится да поэтому конечно
[06:06.480 --> 06:18.520]  мат ожидания грекатова первого оценивается снизу как мат ожидания мощности исходного ц
[06:18.520 --> 06:24.600]  минус мат ожидания мощности w штрих
[06:29.280 --> 06:41.320]  ну и в прошлый раз мы писали что вот это так а это так там еще было дубль вы у которого дельта
[06:41.320 --> 06:50.320]  пополам было мат ожидания дубль вы оно отличалось от дубль ве штрих тем что вот здесь не ц а к красивая
[06:50.320 --> 06:59.600]  которая состоит просто из всех независимых под множество а ц только прорежен это прореженая
[06:59.600 --> 07:06.800]  как красивая там еще было дубль в оно в точности такое же просто вот здесь надо писать как красиво
[07:06.800 --> 07:16.160]  все остальное полностью повторяется вот у нас по определению мат ожидания мощности
[07:16.160 --> 07:22.360]  в это дельта пополам мы так обозначили просто из этого мы получили что мат ожидания мощности
[07:22.360 --> 07:27.960]  w штрих это дельта пополам умножить на ку со звездочкой в квадрате отличие только в том что
[07:27.960 --> 07:33.360]  оба множества должны еще вот сюда попасть это происходит с вероятностью ку со звездочкой в
[07:33.360 --> 07:40.720]  квадрате вот после чего мы просто продеференцировали вот это выражение по ку со звездочкой и убедились
[07:40.720 --> 07:46.520]  что максимум достигается ну что там убеждаться это школьный материал что максимум достигается
[07:46.520 --> 07:52.000]  когда ку со звездочка равняется мю поделить на дельта да или наоборот да мю поделить на дельта
[07:52.000 --> 08:00.000]  вот так это просто вот минус б поделить на 2 а как учит в школе максимум квадратного трех членов
[08:00.000 --> 08:12.760]  откуда следует что мат ожиданий грекатого первого не меньше чем мю квадрат поделить на
[08:12.760 --> 08:21.920]  2 дельта вот до этого мы точно дошли вот а цель наша цель лемма то в том состояла вот лемма
[08:21.920 --> 08:27.960]  которую нам оставалось доказать до полного так сказать катарсиса до завершения теоремы нам
[08:27.960 --> 08:38.080]  нужно было доказать что мат ожиданий грекатого первого не меньше чем вот такая вот функция м в
[08:38.080 --> 08:47.280]  квадрате на 2 к 1 четвертой степени черт похоже долго буду все равно говорить ну что делать надо
[08:47.280 --> 08:53.880]  чтобы все все поймать как уж в какой год пойдет так и пойдет главное чтобы публика понимала так
[08:53.920 --> 09:00.600]  помните что вот в этом утверждение состоит лемма состояла в этом и из этой
[09:00.600 --> 09:06.120]  леммы мужа всю теорему вывели теорема по модулю вот этой лемма она доказана у нас
[09:06.120 --> 09:15.720]  теперь я говорю так смотрите я получил вот это это я получил а хочу я вот это
[09:15.720 --> 09:25.160]  они рядышком отведены в кружочек что хочу что получил ну то есть наверное мне мне хочется хочется
[09:25.160 --> 09:29.080]  чтобы
[09:29.080 --> 09:44.280]  мю квадрат поделенная на 2 дельта а симпатически равнялась м в квадрате поделить на 2 к 1 четвертый
[09:44.280 --> 09:51.560]  то есть я завершу доказательство леммы если вот это хочется оно еще и наколется оно еще и
[09:51.560 --> 10:00.320]  сможется вот если оно сможется да тогда все тогда лемма мы доказали ну понятное дело что можно
[10:00.320 --> 10:06.840]  двойки сократить от этого хотение не поменяет свой смысл двойки сокращаются так чего теперь
[10:06.840 --> 10:14.360]  хочется теперь хочется вот это равносильно тому что дельта дельта перекидываем направо ведет
[10:14.360 --> 10:24.000]  себя как мю квадрат на к 1 четвертый поделить на м в квадрате но это равносильно просто тому
[10:24.000 --> 10:41.680]  что хочется хочется вот это значит давайте прежде всего заметим заметим то к у со звездочкой в этом
[10:41.680 --> 10:48.960]  случае если будет реализовано то что нам хочется вот в этом случае вот в этом если она получится если
[10:48.960 --> 11:02.280]  это получится к у со звездочкой оно ведет себя как мю поделить на мю квадрат к 1 четвертый умножить
[11:02.280 --> 11:14.480]  на м в квадрате согласны ну разделил просто на то что хочется это будет поехали сюда это будет
[11:14.480 --> 11:26.720]  м квадрат поделить на мю и на к 1 четвертой степени вот то что я сказал на прошлой лекции в
[11:26.720 --> 11:38.320]  конце у нас по условию выбора параметров мы их так подбирали вот это мю что такое мю помнишь
[11:38.320 --> 11:45.560]  такое мю это короткое обозначение для мат ожидания просто мера это мат ожидания поэтому мю вы
[11:45.560 --> 11:52.400]  знаете что мю еще это такое стандартное обозначение для первого параметра в нормальном распределении
[11:52.400 --> 12:00.840]  мне никогда не встречали n от мю сигма квадрат ну ладно все тогда забудьте короче я это мю написал
[12:00.840 --> 12:08.280]  не потому что это мера потому что это мат ожидания мю это было мат ожидания которые у нас с самого
[12:08.280 --> 12:15.800]  начала вот в таком виде выбиралась это вот выбор параметров которые мы долго обсуждали в самом
[12:15.800 --> 12:22.280]  начале доказательства теория это точно было товарищи не хочу к этому возвращаться мю ведет
[12:22.280 --> 12:30.680]  себя вот так поэтому вот следствие относится к этому последнему равенству поэтому мы получаем
[12:30.680 --> 12:43.000]  1 поделить на m степени не три уже а 1 плюс о малой от единицы и еще на к 1 в четвертой и вот этого
[12:43.000 --> 12:48.080]  хватает для того чтобы утверждать что кусать звездочкой находится в пределах от нуля до одного
[12:48.080 --> 12:55.680]  то есть это корректно заданная вероятность вот это то что я обещал катарсе состоит в том что вот
[12:55.680 --> 13:02.280]  это условие на параметры которые мы долго обсуждали оно реально нужно для того чтобы убедиться
[13:02.280 --> 13:08.160]  том что мы взяли именно вероятность куса звездочка и не какую-то хрень которая больше одного имели
[13:08.160 --> 13:18.400]  меньше нуля и дай бог сейчас вот стало понятно да я аккуратно это посчитал и видно что это
[13:18.400 --> 13:24.480]  стремится к нулю но то есть при больших значениях n m мы конечно можем считать что это корректно
[13:24.480 --> 13:30.120]  определенная вероятность с которой отбираются вот эти вот независимые множество вот эти вот
[13:30.120 --> 13:37.800]  независимые множество они отбираются с этой вероятности да это мы показали корректность то есть
[13:37.800 --> 13:50.000]  нам осталось вот это реально нам осталось вот это смотрите давайте посчитаем дельту просто честно
[13:50.000 --> 14:01.440]  посчитать что такое дельта это мат ожидания мощности w но мы вернемся просто к тому что пары
[14:01.440 --> 14:06.600]  станут упорядоченными тогда удвоенная мат ожидания мощности w это тоже самое что рассмотреть
[14:06.600 --> 14:13.640]  упорядоченные пары ну то есть посчитать что каитое кожитое кожитое каитое суть разной
[14:13.640 --> 14:21.600]  вещи то то же самое что умножить над сейчас я напишу ответа вы мне скажете понятно или
[14:21.600 --> 14:31.200]  нет но я буду в соответствующей степени пояснять я утверждаю что дельта это есть боже ты мой дельта
[14:31.200 --> 14:46.800]  это есть сумма по т от двойки до к1 минус 1 сумма нет тут сумма уже больше не нужна
[14:46.800 --> 15:08.200]  т из к1 по t на c из m минус к1 по к1 минус t а что только две цешки а мне что-то хотелось
[15:08.200 --> 15:21.520]  что больше сейчас т из к1 по t не то не вроде правильно ц из м минус к1 по к1 минус
[15:21.520 --> 15:43.400]  что-то меня смущает подождите что ж такое так что не так-то идиот самое первое это не выбрал
[15:43.400 --> 15:49.360]  господи боже мой надо было начинать вот с этого сначала выбираем к одну вершину для одного
[15:49.360 --> 15:55.320]  независимого множества потом уже к нему прицепляем второе так и тут будет одна
[15:55.320 --> 16:05.800]  вторая в степени так в какой степени 2 ц с к1 по 2 минус ц ст по 2 вот так вот я утверждаю что
[16:05.800 --> 16:12.040]  дельта это вот такая мерзительная бяка значит как я посчитал дельта я понимаю это никто не
[16:12.040 --> 16:19.700]  понимает ли кто-нибудь понимает с объяснением да как я посчитал дельт но объяснение это
[16:19.700 --> 16:26.240]  сарделька конечно значит нас есть мы вершин нашего случайного графа сарделька это мы вершин
[16:26.240 --> 16:36.320]  нашего случайного графа нас интересуют пары пары под множество вот этой сардельки значит
[16:36.320 --> 16:42.960]  в этой сардельке нас интересуют пары под множество каждая мощность и к1 просто по
[16:42.960 --> 16:50.600]  определению если она находится вот здесь то оно мощности к1 и надо еще чтобы пары пересекались
[16:50.600 --> 16:58.600]  хотя бы по двум вершинам вот я говорю пусть t это количество общих вершин t это просто
[16:58.600 --> 17:09.160]  количество общих вершин вот это это количество общих вершин давайте мы сначала выберем к и т
[17:09.160 --> 17:18.960]  любым из вот стольких способов вот мы фиксируем к и т оно мощности к1 поэтому выбрать его можно
[17:18.960 --> 17:29.120]  вот столькими способами так все успевают выбрали теперь нам нужно да выбрать еще к и т пары
[17:29.120 --> 17:35.080]  упорядоченные поэтому мы ни на что не делим пары стали упорядоченные вот мы выбираем к и т как
[17:35.080 --> 17:41.240]  мы выбираем мы должны выбрать отсюда махонькую такую сардельечку состоящую из т общих вершин
[17:41.240 --> 17:50.240]  т это число общих вершин вот мы выбираем с из к1 по т тут к1 вершина а выбрать надо
[17:50.240 --> 17:59.600]  т вот мы выбираем любые т вершин когда мы их выбрали мы из оставшихся м минус к1 вот тут
[17:59.600 --> 18:07.200]  вот было к1 а осталось м минус к1 выбираем соответственно к1 минус т чтобы в сумме
[18:07.200 --> 18:17.120]  получилось к1 то есть вот это как раз к большое житое ну а дальше это просто линейность математического
[18:17.120 --> 18:23.480]  ожидания мы перебрали все возможные пары и вероятность того что пара присутствует а что значит
[18:23.480 --> 18:30.760]  пара присутствует надо чтобы и к к большое и т и к большое житое чтобы они оба были независимыми
[18:30.760 --> 18:36.400]  но это значит все ребра которые находятся в объединении вот этих двух сарделик должны
[18:36.400 --> 18:42.880]  пропасть 1 2 это вероятность исчезновения ребра мы сейчас работаем со случаем когда
[18:42.880 --> 18:51.600]  п равно 1 2 почему 20 ска один по два но потому что тут цск 1 по два ребер и вот тут вот в этой
[18:51.600 --> 18:57.760]  сумме двух маленьких сардельчик тоже цск 1 по два ребер и у них есть общие цст по два ребер
[18:57.760 --> 19:07.920]  которые надо вычесть вот я их вычитаю в объединении каитова кожитого количество ребер вот такая разность
[19:07.920 --> 19:11.080]  ну вроде поняло
[19:11.080 --> 19:19.600]  формально тут ничего сложного нет противно это теперь убеждаться в том что вот такая сумма
[19:19.600 --> 19:27.400]  а симпатически вот так себя ведет значит дорогие друзья я все-таки считаю что мы с вами учимся
[19:27.400 --> 19:33.600]  заниматься асимптотиками но не до такой степени мне кажется что я достаточно хорошо объяснил
[19:33.600 --> 19:40.320]  людям как заниматься асимптотиками давайте я единственное что сделаю смотрите я утверждаю
[19:40.320 --> 19:49.200]  внимание это важно сейчас мы кое-что сделаем то при t равном двойке то есть вот единственное это
[19:49.200 --> 19:54.840]  слага и мы с таким часто сталкивались помните там историю например про порог для связности
[19:54.840 --> 20:02.120]  когда я сумму разбивал на какие-то две части но в итоге все концентрировалось в начальном значении вот
[20:02.120 --> 20:09.360]  здесь тоже при t равном двойке та симптотика и сосредоточен вот это я доказывать не буду
[20:09.360 --> 20:15.320]  потому что это доказывается еще омерзительнее чем просто путем разбиение суммы на два куска
[20:15.320 --> 20:26.640]  ну а мерзительно доказывать тяжело но анализ такой очень скучный очень рутинный вот если поверить в
[20:26.640 --> 20:34.840]  то что при t равном двойке главное слагаемое то вполне уже по силам нам убедиться в том что да
[20:34.840 --> 20:41.240]  действительно оно имеет вот такую асимптотику вот я предлагаю это сейчас попробовать проверить то
[20:41.240 --> 20:53.200]  есть я хочу проверить что c из к1 по 2 на c из м минус к1 по к1 минус 2 на c из м по к1 и
[20:53.200 --> 21:04.640]  на одну вторую в степени 2 c из к1 по 2 минус 1 тут минус 1 будет при t равном двойке что вот это вот
[21:04.640 --> 21:10.640]  асимптотически равно что такой мю квадрат кстати давайте мю квадрат тоже явно напишем
[21:10.640 --> 21:22.120]  это c из m по к1 в квадрате на 1 вторая степени 2 c из к1 по 2 вот дорогие друзья вы понимаете
[21:22.120 --> 21:28.400]  что это мю квадрата то вы забыли а это как раз похоже на то что написано слева и сразу становится
[21:28.400 --> 21:37.240]  легче мю по определению мат ожидания просто числа независимых множеств вот этих товарищей
[21:37.720 --> 21:47.000]  просто мат ожидания числа ну конечно это c из м по к1 просто выбираем 1 к айта мощности
[21:47.000 --> 21:54.880]  к1 выбираем его 1 и умножаем на одну вторую степени 20 из к1 под вот просто цск 1 под
[21:54.880 --> 22:04.760]  что оно независимое но а мю в квадрате это я вот возвел в квадрат просто возвел в квадрат так
[22:04.760 --> 22:13.960]  это мю в квадрате дальше надо еще к1 в четвертый написать и разделить на м в квадрате вот друзья
[22:13.960 --> 22:18.200]  если вы осознали то что я сейчас говорил то стало намного легче вот как картинка должна
[22:18.200 --> 22:31.640]  была сложиться сейчас что смущает что мю такое нет это мы сейчас проверим я вот вот это вот это
[22:31.640 --> 22:37.760]  последнее что я хочу сделать последнее вот в этой теореме что я хочу сделать строго ну как
[22:37.760 --> 22:43.640]  получается сейчас возьмем разделим лево направо и убедимся что при деле 1 это наша задача товарищи
[22:43.640 --> 22:56.120]  вы поняли что задача в этом это вы поняли да ну тогда давайте делить щпок так с из м по к1 в квадрате
[22:56.120 --> 23:10.600]  на 1 вторая степени 20 из к1 по 2 на к1 четвертый на м квадрат что
[23:10.600 --> 23:19.120]  но я что говорю что оно вообще очень мило сокращается леп леп
[23:19.120 --> 23:30.240]  можно ролик номер два снимать ясно если кто видел там шлёп шлёп да да да ну нет я имею
[23:30.240 --> 23:39.000]  в виду что можно его потом обработать нет там просто так понимаете вот я так как-то двигаюсь
[23:39.000 --> 23:46.320]  туда сюда туда сюда вот я явно не так двигаюсь нам аж шлёп шлёп оно еще так сделано очень забавно
[23:46.320 --> 23:56.080]  то есть добавлено еще некоторые харизмы происходящим так ну вот еще один шлёп шлёп вот
[23:56.080 --> 24:02.600]  такое специально перечеркнув другую сторону чтобы было понятно кто с кем сократился хух так
[24:02.600 --> 24:17.080]  что же у меня осталось то так дайте напишем тильда к1 в квадрате пополам это я написала
[24:17.080 --> 24:27.280]  симптотику для вот этой цешки ну к1 к1 минус 1 это к1 в квадрате во симптотике так дальше 1
[24:27.280 --> 24:36.280]  вторая в минус 1 это двойка 1 вторая в минус 1 сейчас будет опять шлёп шлёп да так и еще
[24:36.280 --> 24:45.840]  умножить на м квадрат и умножить на с изм минус к1 по к1 минус 2 так а тут поделить на давайте
[24:45.840 --> 24:59.320]  к1 в четвертой и на с изм по к1 ну действительно шлёп шлёп еще раз хлоп хлоп вот тогда к1 в квадрате
[24:59.320 --> 25:13.880]  ну что нам осталось доказать что остается доказать следующую замечательную вещь то
[25:13.880 --> 25:34.640]  с изм минус к1 по к1 минус 2 разделить на с изм по к1 это симпатически равно к1 квадрат на
[25:34.640 --> 25:43.640]  м в квадрат ну вообще мне-то это более-менее очевидно но я могу это доказать ничего тут
[25:43.640 --> 25:53.520]  такого сложного нет смотрите что у нас тут получается м минус к1 факториал поделить на
[25:53.520 --> 26:05.560]  к1 минус 2", на m минус 2к1 плюс 2, а тут у меня получается м факториал в знаменателе
[26:05.560 --> 26:15.340]  к1 факториал м минус к1 факториал, то у нас остается после сокращения значит
[26:15.340 --> 26:22.480]  после сокращения у меня остается сверхуxo сразу а симптотику напишу к1 в квадрате как раз как
[26:22.480 --> 26:28.880]  хотелось, но потому что k1 факториал, делённый на k1-2 факториал, это k1 на
[26:28.880 --> 26:38.880]  k1-1, но это k1 в квадрате, асимпатически. Спеваете? Не очень гадим. Пока вроде
[26:38.880 --> 26:43.120]  должны быть живы, но вот эти вот два сократил, это в асимптотике, это k1
[26:43.120 --> 26:49.360]  квадрат. Теперь я пытаюсь сократить, наверное, вот это и вот это. Ну всё равно,
[26:49.360 --> 26:56.200]  на самом деле. Что с чем? Знаете, я вот так вот напишу. А, в общем, действительно,
[26:56.200 --> 27:04.600]  наверное, всё равно, что с чем тут сокращать. Значит, вот тут останется m, m-1 и так далее.
[27:04.600 --> 27:13.320]  Какое m-k1 плюс 1, да? Вот так. Если я m факториал в знаменателе пишу, а в числителе
[27:13.320 --> 27:18.880]  m-k1 факториал, вот у меня получается вот такая штука. Так, и тут надо сократить
[27:18.880 --> 27:26.840]  наоборот. Вот эти два факториала. Что-то останется m-k1 и так далее.
[27:26.840 --> 27:45.320]  m-2k1 плюс сколько? Плюс один или плюс три? Я сам туплю. Плюс один, да? Плюс три? А,
[27:45.440 --> 27:51.200]  следующее плюс два, да, вроде правильно. Ну ладно, ладно, это на самом деле всё неважно.
[27:51.200 --> 27:55.720]  Вы должны понимать, ну важно количество вот этих совмножителей. Только важно,
[27:55.720 --> 28:04.040]  только количество этих совмножителей. Вы должны понимать, что k1 же у нас это 2 лог 2-ичный m.
[28:04.040 --> 28:12.320]  Ну так он подбирался. 2 лог 2-ичный m. k1. Ну это вы можете посмотреть, просто в прошлый раз мы это
[28:12.320 --> 28:22.440]  писали. Это 2 лог 2-ичный m. Поэтому всё, что стоит в знаменателе, например, всё, что стоит в знаменателе,
[28:22.440 --> 28:29.800]  в асимптотике имеет вид m в степени количества совмножителей. Потому что k1 очень маленькая,
[28:29.800 --> 28:36.120]  почти как константа. Ну можно расписать там в виде экспонента от суммы логарифмов, как мы много раз
[28:36.120 --> 28:41.520]  делали, и убедиться в том, что k1 настолько маленькая, что всё хорошо. Нужно расписывать,
[28:41.520 --> 28:48.720]  я распишу. Это довольно скучно, то есть это стандартная выкладка, на неё безумно не хочется
[28:48.720 --> 28:56.400]  тратить время. Сколько тут совмножителей? k1 совмножителей, товарищ. А тут k1-2. Вот тут
[28:56.400 --> 29:03.120]  то же самое. Тут будет асимптотика в степени k1-2. Ну и всё, получилось в квадрате в знаменателе,
[29:03.120 --> 29:16.560]  это мы доказываем. Вот это вот, там квадрат в знаменателе. Нормально? Вот на таком уровне вы
[29:16.560 --> 29:24.160]  должны владеть асимптотикой. Почему концентрируется вся вот эта сумма в t равном двойке? Почему огромное
[29:24.160 --> 29:31.760]  количество других слагаемых не влияет? Я объяснять не буду. Ну ещё раз, вернее, если вы хотите, давайте я
[29:31.760 --> 29:36.720]  объясню примерно, просто буквально в кратце. Не надо это будет делать на экзамене, потому что
[29:36.720 --> 29:59.640]  это довольно мутрно, страшно, сложно. Да. Да, да. Это вот и есть нюк квадрат. Но ещё раз, давайте я
[29:59.640 --> 30:07.760]  ещё раз напишу. Видимо, быстро говорил всё-таки для кого-то. Вот так вот. Мю, по определению, это
[30:07.760 --> 30:14.680]  мата ожидания. Ой, мата ожидания, что вдруг написал так. Хк, ты первая. Мата ожидания просто числа
[30:14.680 --> 30:24.240]  независимых множеств мощности k1. Да-да-да, м в кубе, мы уже это, оно сработало. Не важно, что эта
[30:24.240 --> 30:30.160]  штука асимпатически равна м в кубе, но она просто по определению вот такая. Сразу-то она такая. При
[30:30.160 --> 30:35.960]  этом да, k1 подобран так, чтобы она оказалась примерно м в кубе, и за счёт этого мы получили,
[30:35.960 --> 30:40.560]  что вероятность подобрана корректно. Теперь мы про это забываем, нам сейчас это не нужно,
[30:40.560 --> 30:50.080]  пользуемся исходной формулой, её сюда подставляем и получаем. Ну вот такая вот штука. А, я хотел
[30:50.080 --> 30:56.240]  пояснить коротко, да, пояснить, почему концентрируется в t равном двойке. Смотрите, в чём тут
[30:56.240 --> 31:01.720]  принципиальное отличие от истории с связанными компонентами, когда сумму можно было просто разбить
[31:01.720 --> 31:11.960]  на две части. Если вы посмотрите t равное тройке, например, следующее слагаю, я не предлагаю это делать,
[31:11.960 --> 31:19.480]  но просто слушайтесь, если вы его посмотрите, то оно действительно окажется сильно меньше, чем то,
[31:19.480 --> 31:24.920]  что мы посчитали. Оно окажется бесконечно мало по сравнению со слагаемым при t равном двойке.
[31:24.920 --> 31:32.160]  Также было и в сумме, которая про связанность. Помните? Если вы посмотрите t равное четвёрке,
[31:32.160 --> 31:39.760]  я вас уверяю, оно тоже окажется бесконечно мало по сравнению с тем, что было при t равном тройке.
[31:39.760 --> 31:46.040]  То есть это как бы бесконечная убывающая геометрическая прогрессия. С главным членом t равняется
[31:46.040 --> 31:52.680]  двойке. А дальше t равно тройке во много раз меньше, t равно четвёрке ещё во много раз меньше,
[31:52.680 --> 32:00.960]  чем t равно тройке. Но, к сожалению, этот процесс в какой-то момент раньше, чем вот такой, остановится.
[32:00.960 --> 32:10.800]  И хуже того, хуже того, мало того, что оно остановится, слагаемые снова начнут расти. То есть
[32:10.800 --> 32:18.040]  картина будет вот такая. Вот тут вот t равняется двойке. Оно как бы самое большое. Потом пошло ниже,
[32:18.040 --> 32:27.680]  ниже, ниже, ниже. В какой-то момент достигла дна минимума и пошло выше. Но, понимаете,
[32:27.680 --> 32:34.680]  мы умрём сейчас с вами вот это всё аккуратно считать. Я утверждаю, что когда оно дойдёт вот
[32:34.680 --> 32:41.520]  до этого верхнего предела, да, оно будет выше, чем дно, но всё ещё сильно ниже, чем t равно двойке.
[32:41.520 --> 32:48.720]  Вот это всё считать, мы умрём. А смысл вот такой. Ну и дальше там всё сходит к t равно двойке,
[32:48.720 --> 32:54.040]  потому что всё остальное меньше. Но проблема в том, что вот оно одно время меньше, потом больше,
[32:54.040 --> 32:59.000]  и вот из-за этого надо и тут считать, и вот это суммировать отдельно, и вот это суммировать
[32:59.000 --> 33:06.000]  отдельно. Но неужели я такое буду спрашивать на экзамен? Кому это надо? Главное, чтобы вы смысл
[33:06.000 --> 33:11.840]  понимали. Ну смысл-то понятен. Не надо, самой выкладки не надо. Главное, чтобы вы поняли,
[33:11.840 --> 33:19.040]  как получилась теория. Суть стандартная, а вот уже там выкладки технические, но мы почти все сделаем.
[33:19.040 --> 33:31.560]  Почти все. Уф! На этом огромная тема про хроматическое число случайного графа окончена. Поздравляю
[33:31.560 --> 33:41.680]  вас с этим обстоятельством и даже могу устроить перерыв, потому что он почти подгрёб. Давайте
[33:41.680 --> 33:45.800]  сделаем перерыв, правда, но главное, что сейчас будет другая тема совсем, а звонок через одну или
[33:45.800 --> 34:06.600]  две минуты. Так, друзья, давайте продолжать. Так, скажите мне, пожалуйста, все-таки начались уже
[34:06.600 --> 34:15.040]  линейно-алгебрагические методы или нет еще? Уже закончились, да, то есть, понимаете, вот я
[34:15.040 --> 34:20.120]  просто должен выбрать темп, в котором это рассказывать. По идее, я должен рассказать аккуратно,
[34:20.120 --> 34:26.520]  подробно все, но вот как это лучше делать? Это вопрос, который сейчас все-таки возникает,
[34:26.520 --> 34:31.600]  потому что линейная алгебра это очень важно, это такой мощный метод, который позволяет работать
[34:31.600 --> 34:38.320]  с гиперграфами. Но давайте я коротко скажу, что следующая большая тема, которая нас интересует,
[34:38.320 --> 34:48.720]  может быть собрана под крышу гиперграфа. Гиперграф – это главный сарделичный объект. Если вот уж
[34:48.720 --> 34:54.640]  говорить о том, где сардельки прямо естественным образом появляются, это гиперграф. Давайте я
[34:54.640 --> 35:05.680]  коротко напомню, что гиперграф отличается от графа просто тем, что у него ребра не обязательно
[35:05.680 --> 35:11.320]  состоят из двух вершин, а могут состоять из любого их количества. То есть, это по-прежнему пара,
[35:11.320 --> 35:19.240]  которая есть вершины и ребра, В – это множество вершин, Е – множество ребра, только, товарищи,
[35:19.240 --> 35:25.880]  потише. Я понимаю, что вы уже как бы это или этого вы не знаете. Слово гиперграф на семинарах
[35:25.880 --> 35:31.560]  произносилось. Вот у кого-то нет, у кого-то да. Давайте я аккуратно скажу, гиперграф – это
[35:31.560 --> 35:37.040]  практически то же самое, что граф. Отличие состоит только в том, что в ребре может быть
[35:37.040 --> 35:55.960]  несколько вершин. В каждом ребре может быть не две вершины, а много. Я сейчас все скажу. Мы будем
[35:55.960 --> 36:01.480]  рассматривать только гиперграфы, которые в каком-то смысле устроены как простые
[36:01.480 --> 36:08.200]  графы или обыкновенные графы. То есть, нам не будет важен порядок вершин внутри ребра. Гиперграф
[36:08.200 --> 36:17.680]  в нашем случае по определению не является ориентированным. Е – это под множество в два
[36:17.680 --> 36:24.440]  в степени В. Не бывает кратных ребер. В этом смысле то, что я написал, тоже является корректной
[36:24.440 --> 36:35.040]  записью. Не бывает кратных ребер. Так? Ну и нет ориентации. То есть, это под множество,
[36:35.040 --> 36:42.520]  которое является в терминологии ОКТЧ – сочетание. Ребра – это сочетание. Сочетание вершин.
[36:42.520 --> 36:49.080]  Почему это сарделичный объект? Ну, потому что если вершины традиционно обозначать,
[36:49.080 --> 37:00.320]  не обозначать, а изображать точками на плоскости, то ребро – это что-то вот в таком духе. Ну, это
[37:00.320 --> 37:08.440]  уж прямо сарделька-сарделька. Вот прям вот такая. Я вот все-таки так и не понял, почему на наклейке,
[37:08.440 --> 37:17.720]  где я изображен на фоне такого круга из «Поля чудес», у меня в руках все-таки не сарделька,
[37:17.720 --> 37:24.920]  а цукинь. Ну, не знаю, мне сказали, что сардельку отдельную не нашли, но это странное объяснение.
[37:24.920 --> 37:35.800]  Но цукини, ладно, пусть цукини тоже похожи. Есть такая вот, знаете, кастрюлька, в которой варятся
[37:35.800 --> 37:43.840]  сардельки. Вот так себе представляете вершины и рёбра. Гиперграф – плох, но они вот как пересекаются.
[37:43.840 --> 37:50.200]  Ну, представьте себе, что они прозрачные, вот они друг на друге лежат, ну, пересекаются, да. То есть,
[37:50.200 --> 37:59.320]  понимаете, вот относительный минус гиперграфа по отношению к графу состоит в том, что непонятно,
[37:59.320 --> 38:04.680]  как его изображать. Ну, вот я изображаю такие сардельки и прямо в голове себе что-то такое
[38:04.680 --> 38:10.120]  и представляю. Но есть люди, которые очень геометрически ориентированы и могут себе
[38:10.120 --> 38:18.040]  представить многомерный симплекс. В этом случае, ну, я думаю, что вот, например, Аркадий Борисович
[38:18.040 --> 38:23.920]  считает, что гиперграф – это симплециальный комплекс. И люди, которые любят топологию,
[38:23.920 --> 38:31.280]  они вот так себе и будут это представлять. Но не любой симплециальный комплекс является гиперграфом,
[38:31.280 --> 38:36.440]  для тех, кто знает, что такое симплециальный комплекс. Наоборот, не любой гиперграф является,
[38:37.400 --> 38:41.840]  симплециальный комплекс, конечно, гиперграф, но не любой гиперграф является симплециальным
[38:41.840 --> 38:49.600]  комплексом. Всё, это забыли, проехали. Так, друзья, вы поняли, что такой гиперграф просто по
[38:49.600 --> 38:59.280]  определению. Значит, гиперграфы бывают, давайте я буду писать R однородными, чтобы не путать
[38:59.280 --> 39:08.480]  обозначение. Гиперграф называется R однородным, если все его ребра имеют мощность R. Являются
[39:08.480 --> 39:28.120]  R-сочетания, если все его ребра – R-сочетания. Ну, то есть, например, полный R-однородный гиперграф
[39:28.120 --> 39:39.640]  на N вершинах имеет C из N по R ребер. В частности, два однородные гиперграфы. Два однородные
[39:39.640 --> 39:52.200]  гиперграфы – это грав. Это просто обычный, обыкновенный грав. Это грав. Как правило,
[39:52.200 --> 39:58.680]  товарищи, давайте считать, что у нас не бывает ребер из одной вершины. Нет, реброй из одной
[39:58.680 --> 40:04.720]  вершины – это непонятно что. Просто реброй из одной вершины – это под множеством мощности 1. Это
[40:04.720 --> 40:12.240]  не петля. Ну, нельзя, потому что петля – это все-таки пара совпадающих вершин. Петля, по определению,
[40:12.240 --> 40:17.720]  это пара, состоящая из двух одинаковых вершин. Петля в гиперграфе – это, наверное, просто,
[40:17.720 --> 40:23.480]  например, R одинаковых вершин. Но мы решили, что у нас никаких повторений не бывает. У нас только
[40:23.480 --> 40:30.880]  сочетание, причем без повторений, в полном R-однородном гиперграфе C из N по R ребер.
[40:30.880 --> 40:38.920]  Это сочетание без повторений, обычные цешки. Поэтому никаких петель у нас нет. Одновершинные
[40:38.920 --> 40:45.800]  ребра, строго говоря, могли бы быть, но я решил, что мы не будем такую ситуацию рассматривать. Будем
[40:45.800 --> 40:51.800]  считать, что R, например, больше либо равняется двойке, если мы имеем дело с R-однородными,
[40:51.800 --> 41:02.880]  ну и еще как. Так, вот предметом обсуждения на оставшихся лекциях, ну две с половиной осталось
[41:02.880 --> 41:09.440]  лекции, сегодня еще две. Значит, предметом обсуждения на этих лекциях будут несколько,
[41:09.440 --> 41:17.880]  извините, экстремальных, но не по сложности, а по сути, по комбинаторной сути, экстремальных
[41:17.880 --> 41:27.400]  величин, которые ассоциированы с однородными гиперграфами. Обсуждать хроматические числа
[41:27.400 --> 41:36.440]  гиперграфов мы начали на первой лекции по КТЧ, потому что там речь шла про пяти-элементные
[41:36.440 --> 41:43.520]  подмножества, 30-элементного множества, и вопрос как раз в том состоял, а можно так покрасить эти
[41:43.520 --> 41:50.320]  30 элементов, чтобы каждое подмножество было не одноцветным? Это прямо в точности хроматическое
[41:50.320 --> 41:58.440]  число 5-однородного гиперграфа. Мы это будем обсуждать, но в следующем семестре. Сейчас я хочу
[41:58.440 --> 42:03.200]  обсуждать, ну иначе мы только раскрасками будем заниматься, а люди, которые в следующий семестр не
[42:03.200 --> 42:11.240]  перейдут, вообще никакого кругозора не получат. Я имел в виду людей с ПМИ и информатика, товарищи,
[42:11.240 --> 42:19.640]  а не тех, кого отчислят. Разница в том, что те, кого отчислят, не получат кругозора не только в
[42:19.640 --> 42:28.160]  дискретном анализе. Они перейдут, но не в следующий семестр дискретного анализа.
[42:32.640 --> 42:39.640]  Это тоже верно. Тут много правильных утверждений. Так, ну ладно, давайте что-нибудь успеем.
[42:39.640 --> 42:59.920]  Значит, я сейчас напишу три величины. Начну с Саши. Так, это максимальная м, натуральная, такое,
[42:59.920 --> 43:24.640]  что существует эрооднородный гиперграф на N вершинах. Причем такой, что для любых двух его
[43:24.640 --> 43:39.840]  ребер не больше, чем С. Так, дорогие друзья, вот на самом деле, я приостановлюсь, у меня еще
[43:39.840 --> 43:46.920]  будет две величины. Но вот это вот то, с чем мы имели дело буквально на прошлой лекции, на самом
[43:46.920 --> 43:57.560]  деле. Это величина, которая характерна для кодов исправляющих ошибки. Мы хотим выбрать как можно
[43:57.560 --> 44:09.920]  больше R элементных множеств в N элементном множестве, чтобы пересечение каждых двух из них не превосходило
[44:09.920 --> 44:17.440]  за ДНВС. Это чистой воды код исправляющей ошибки. У нас есть N элементное множество, большое,
[44:17.440 --> 44:27.280]  кастрюля. Мы хотим в эту кастрюлю запузырить как можно больше сарделек каждой мощности R и чтобы
[44:27.280 --> 44:34.760]  каждые две пересекались не больше, чем по S. Это вот точности задачи про коды исправляющей ошибки.
[44:34.760 --> 44:45.160]  А, я забыл, конечно, написать, да. Да, да, да, да, да. Ну, конечно, я забыл написать, что мощность
[44:45.160 --> 44:51.480]  E равняется M. Ну, конечно. Что-нибудь я обязательно в этом месте забуду. Это максимальная мета,
[44:51.480 --> 44:58.040]  кое-что существует. R однородный гиперграф, вот сюда это лучше писать, вот сюда. С N вершинами
[44:58.040 --> 45:09.320]  и M ребрами. С N вершинами и M ребрами. Не-не-не, алфавит у нас состоит из нуля и единицы. То есть,
[45:09.320 --> 45:14.280]  если интерпретировать это в терминах кодов исправляющих ошибки, то мы говорим о кодировании
[45:14.280 --> 45:21.920]  нулями и единицами. Просто в этом случае вы вот эти множества интерпретируете как векторы из нуля
[45:21.920 --> 45:31.480]  и единиц, состоящие из N координат. Вот если у вас есть какое-то множество, например, один, два,
[45:31.480 --> 45:42.120]  три, то тогда соответствующий вектор это один, один, один, а дальше N минус три нолика. Вот это вот
[45:42.120 --> 45:47.920]  интерпретация в терминах теории кодирования. Тогда утверждение о том, что каждые два множества
[45:47.920 --> 45:56.200]  пересекаются не больше, чем по S, равносильно тому, что вот эти вот наборы единиц мало пересекаются.
[45:56.200 --> 46:04.840]  То есть, расстояние между этими словами большое, скалярное произведение не больше, чем S,
[46:04.840 --> 46:12.640]  да вот эти множества мало пересекаются, это означает, что расстояние между ними большое. И даже
[46:12.640 --> 46:19.320]  если сильно покоцается слово, то вы будете понимать, что вы находитесь в шарике с центром в этом
[46:19.320 --> 46:26.840]  слое и значит покоцалось именно оно. То есть, на выходе вы сможете восстановить информацию. Помните,
[46:26.840 --> 46:33.000]  я про это рассказывал, слова далеко, даже если сильно покоцали, все равно не вышли за пределы
[46:33.000 --> 46:40.920]  своего шара. Куда бы ни попали, на выходе точно знают, что это было вот это слово. Чем меньше вот
[46:41.000 --> 46:47.440]  эти вот слова, вот эти множества A и B пересекаются, ребра, гиперграфа, чем меньше они пересекаются,
[46:47.440 --> 46:54.840]  тем больше ошибок мы исправляем. Сейчас, друзья, нормальный вот этот темп, это я понятно объяснился?
[46:54.840 --> 47:08.720]  Это все было, но просто надо вот как-то одно с другим ассоциировать. Так, вот те, у кого были
[47:08.720 --> 47:15.680]  семинары про линейно-алгебранический метод, изучали вот такую величину. Все в точности то же
[47:15.680 --> 47:27.520]  самое. Прямо в точности. Сильно-сильно, да. То же самое, максимальная М, такое, что существует
[47:27.520 --> 47:34.600]  эрооднородный гиперграф с N-вершинами, M-ребрами. Единственное вот отличие, это что ребра пересекаются
[47:34.600 --> 47:44.280]  не по малу, а то ли по малу, то ли по многу. Но только вот не по этому. Единственный запрет, ровно один запрет.
[47:44.280 --> 47:56.080]  Только не бросай меня в этот перновый куст, там остальные, пожалуйста. Это вот как раз будет
[47:56.080 --> 48:00.080]  сейчас линейно-алгебранический метод, который вы начали изучать на семинарах, потому что я
[48:00.080 --> 48:19.680]  слишком долго говорил про раскраски. Вот так. Ну, вполне понятно, тоже симметричная штука.
[48:19.680 --> 48:27.760]  Не-не-не, но вот это вот три классических таких ситуации, которые изучаются и в теории кодирования,
[48:27.760 --> 48:33.200]  и в комбинаторике, и во многих других приложениях. Я традиционно в последние годы не успеваю
[48:33.200 --> 48:40.440]  рассказывать применение к задачам комбинаторной геометрии. Там раскраска пространства, проблема
[48:40.440 --> 48:51.360]  борсука. Ужасно хочется про это рассказать, непонятно когда. Вместо всего остального. Ну, в общем,
[48:51.360 --> 48:56.160]  посмотрим. Да, друзья, посмотрим. Я с удовольствием прочитаю несколько факультативных лекций для
[48:56.160 --> 49:03.000]  желающих, если у вас будут силы. Но заставлять всех учить больше, чем влезает в два семестра,
[49:03.000 --> 49:13.200]  это уже какое-то издевательство. Но вот эти три величины мы должны изучить. Так, ну, поскольку
[49:13.200 --> 49:24.720]  у вас уже начался линейно-алгебранический метод, может с МАТНРС начнем тогда? Значит, смотрите,
[49:24.720 --> 49:34.280]  МАТНРС, она тоже допускает известную нам интерпретацию. Если H от НРС это классическая
[49:34.280 --> 49:40.400]  задача о построении как можно более мощного кода, исправляющего заданное количество ошибок,
[49:40.400 --> 49:52.160]  то МАТНРС это альфа от графа G от НРС, который у нас неоднократно встречался в разных контекстах.
[49:52.160 --> 50:01.520]  Был у нас такой граф? Ну, дайте я напомню, что такое G от НРС. Это граф, это уже граф,
[50:01.520 --> 50:07.680]  не гиперграф, ну, граф это частый случай гиперграфа, но понятно. Это уже граф, у которого вершины,
[50:07.680 --> 50:21.440]  это вакурат под множество чисел от 1 до N, каждый из которых имеет мощность R. Соответственно,
[50:21.440 --> 50:31.520]  рёбра – это пары под множество, мощность пересечения которых в точности равна S.
[50:31.520 --> 50:43.440]  Самый стандартный наш пример, это когда вот тут 3, вот тут 1, и он был еще на ОКТЧ,
[50:43.440 --> 50:54.360]  и там был как раз зачаток вот этого линейно-алгебрагического метода. Там был граф G от N3 и 1,
[50:54.360 --> 50:59.880]  про который мы доказывали с помощью линейной алгебры, что его число независимости не больше
[50:59.880 --> 51:07.520]  чем N. То есть мы уже знаем, что M от N3 и 1 не больше чем N, но и больше того я говорил,
[51:07.520 --> 51:22.280]  чему оно равно. Оно равно N, если N делится на 4, N-1, если N сравнимо с единицей, и N-2 в двух оставших случаях.
[51:22.280 --> 51:31.520]  Интересно, кто-нибудь хотя бы смутно припоминает, что такое было. А, даже в билете на экзамен. Это
[51:31.520 --> 51:38.160]  хорошо. Вот это мы доказывали с помощью индукции, такая скучная индукция, а вот это обалденный
[51:38.160 --> 51:47.200]  линейно-алгебрагический метод. Так, друзья, нужно напоминать обалденный метод? Ну, наверное нет,
[51:47.200 --> 51:52.360]  иначе мы слишком много времени потратим на то, что знаем. Я лучше другой обалденный метод расскажу,
[51:52.360 --> 51:58.200]  я обобщу. Ну, я так понимаю, что есть присутствующих, большинство уже знает,
[51:58.200 --> 52:03.360]  потому что это началось на семинарах, но я должен как-то для общности это записать,
[52:03.360 --> 52:09.600]  видимо, да? Или вы на самом деле сходу не скажете мне, как действовать? Подивите руки,
[52:09.600 --> 52:20.040]  кто скажет, как действовать в общем случае? Лес рук. Ну, так, давайте действовать. Слушайте, друзья,
[52:20.040 --> 52:26.200]  я стараюсь никуда не торопиться, мне хочется дать вам больше, но я хочу это сделать качественно,
[52:26.360 --> 52:32.400]  чтобы все все четко поняли, могли записать для себя, потом воспроизвести, поэтому давайте
[52:32.400 --> 52:38.800]  спокойно работать, никуда не торопясь. Все поняли, что м от nrs, вот такая гиперграфовая характеристика,
[52:38.800 --> 52:49.200]  это альфа от вот этого же nrs. Такое вот, такое жонглирование понятия происходит. Так, ну,
[52:49.200 --> 53:17.120]  когда работаем пока что с m, работаем пока что с m, вот давайте обсудим. Я считаю,
[53:17.120 --> 53:21.440]  нужно обсудить сначала такую величину, чтобы максимально было понятно, что делается в общем
[53:21.440 --> 53:32.360]  случае. Пять-два, да. Ну, то есть мы рассматриваем пяти-элементные под множество аналиментного
[53:32.360 --> 53:40.760]  множества. Ребра это такие пятерки, пять сочетания. Сарделька состоит из пяти вершин каждой. При этом
[53:40.760 --> 53:48.040]  мы им запрещаем иметь ровно две общих вершины. Вот можно одну, можно не одной, можно три-четыре,
[53:48.040 --> 53:56.080]  но только не две. Две запрещено. Ну, тут еще сохранилось. Две запрещено. Казалось бы,
[53:56.080 --> 54:03.920]  только один запрет. Вот давайте прежде всего подумаем, что проще. Как бы предъявить какую-нибудь
[54:03.920 --> 54:09.480]  жирную конструкцию, в которой один запрет присутствует, и тем не менее, вот она жирная. Как бы придумать
[54:09.480 --> 54:20.480]  побольше таких сарделек? Просто явную конструкцию. Как можно построить много множеств мощности 5 среди
[54:20.480 --> 54:31.880]  N вершин? Как? Четыре элемента и один менять? Мне кажется, что три достаточно и два менять. Во,
[54:31.880 --> 54:38.920]  смотрите, правильно. Мне кажется, что вот такая конструкция является вполне себе неплохой. Мы
[54:38.920 --> 54:50.480]  фиксируем первые три числа и дальше из оставшихся N-3 выбираем любые две. C из N-3 по 2. Каждые два
[54:50.480 --> 54:55.920]  таких множества, они имеют мощность 5, конечно, все. Каждые два таких множества пересекаются по
[54:55.920 --> 55:04.000]  трем элементам или больше, по четырем, но точно не по двум. Заметьте, мы как бы даже меньше
[55:04.000 --> 55:09.800]  использовали, чем могли. Нам разрешено еще по одному и по нулю, но в этой конструкции мы этого
[55:09.800 --> 55:15.880]  не используем никак. Тем не менее, а симптатика этого числа это, конечно, N квадрат пополам.
[55:15.880 --> 55:26.880]  Что? Не, ну это можно обобщить легко, но это мы потом обсудим. Понятно, что для MOTN 5.2 вот
[55:26.880 --> 55:33.000]  такая нижняя оценка точно имеет место. Вот она симпатически ведет себя как N квадрат пополам,
[55:33.000 --> 55:40.960]  и теорема, которая доказывается с помощью всего того же обалденного линейно-алгебрагического
[55:40.960 --> 55:46.120]  метода. Я считаю, что это офигенно круто, то есть это надо прямо прочувствовать. Она утверждает,
[55:46.120 --> 55:53.760]  что эта величина ограничена сверху кем-то, симптатика чего такая же. А именно мы сейчас
[55:53.760 --> 56:01.960]  докажем, что это не больше, чем C из N по 2, но давайте я вот так напишу, плюс 2 C из N по 1.
[56:01.960 --> 56:13.320]  Но это я сейчас докажу. Понятно, что асимпатически это тоже N квадрат пополам,
[56:13.320 --> 56:18.880]  но это больше, конечно, чем C из N-3 по 2, но разница между нижней и верхней оценкой,
[56:18.880 --> 56:27.280]  она порядка N. То есть главный член асимптотики найден, а остаточный он порядка N. Но это уже
[56:27.280 --> 56:32.840]  следующий вопрос, конечно, как найти в точности. Я вас уверяю, что обычная комбинаторика без
[56:32.840 --> 56:39.440]  привлечения линейно-алгебрагического подхода даже вот этого не дает. Вернее, получается безумный
[56:39.440 --> 56:45.240]  перебор, от которого можно концы отдать. А тут будет очень красивое рассуждение, до которого
[56:45.240 --> 57:01.160]  додуматься, но вот человечество додумалось. Короткий вопрос. Все присутствующие понимают,
[57:01.160 --> 57:11.840]  что многочлены бывают от N-переменных. Бывают же от N-переменных многочлены? Я просто спрашиваю,
[57:11.840 --> 57:19.080]  что? Все понимают, что многочлены бывают не только от одной, но от N-переменных тоже,
[57:19.080 --> 57:28.800]  и что многочлены бывают не только над R, но над любым полем. Это важно. Давайте рассмотрим
[57:28.800 --> 57:44.640]  любое множество ребер гиперграфа. Ну, давайте их как-нибудь вот так, например, обозначим. Это
[57:44.640 --> 57:51.080]  ребра гиперграфа, который 5-однородный, и про который известно, что каждые два его ребра имеют
[57:51.080 --> 57:59.160]  какое угодно пересечение, но только не два. Давайте я напишу. А ИТ, пересеченное сожитым,
[57:59.160 --> 58:11.320]  не равняется двойке. Для любых R. Ну, рассмотрим любое. Он написал любое в виде кванта. Ну,
[58:11.320 --> 58:19.720]  я согласен, но неужели непонятно? Любое, но надо было написать любое. Да, это читается для любого.
[58:19.720 --> 58:34.240]  Хорошо. Я пошел навстречу пожеланиям трудящихся. Рассмотрим любое множество ребер вот с этим условием.
[58:34.240 --> 58:48.960]  Так, товарищи, все, хватит, нас времени мало, я хочу успеть. Катарсис хочу. Вы хотите катарсис?
[58:48.960 --> 58:58.920]  Значит, АИ тому сопоставляем вектор. Помните, как вектор сопоставляется из нулей единиц? Вот я
[58:58.920 --> 59:10.000]  где-то здесь рисовал пример, вот так. Но там уже будет 5 единиц, а на минус 5 нулей. Ну, то есть,
[59:10.000 --> 59:21.520]  мы знаем, что скалярное произведение каждых двух векторов не равняется двойке. Скалярное
[59:21.520 --> 59:26.760]  произведение векторов это в точности мощность пересечения вот этих множеств. Это все понимают?
[59:26.760 --> 59:37.880]  Скалярное произведение, мощность пересечения, суть одно и то же. Так, теперь строим по вектору
[59:37.880 --> 59:50.480]  многочлен. П это полином, многочлен. Я скажу, какой, но давайте сперва скажем, что он находится в Z,
[59:50.480 --> 01:00:03.320]  по 5, как же по 5, по 3. Неожиданно, по 3 Z. Вот, ну давайте Y1 и так далее Yn. То есть,
[01:00:03.320 --> 01:00:13.400]  это многочлен от N переменных над полем вычетов по модулю 3. Ну, есть мнение, что тогда будет
[01:00:13.400 --> 01:00:21.160]  путанец с обозначением триодических чисел. Бывают п-одические числа, их часто обозначают Zp. Чтобы
[01:00:21.160 --> 01:00:30.920]  не путать, пишут фактор группу Z по 3Z, но это она и есть, вычеты по модулю 3. Что? Ну, хотите,
[01:00:30.920 --> 01:00:41.800]  я напишу Z3. Ну ладно, все. Как вам нравится, так и пишите, но смысл, что это вычеты по модулю 3.
[01:00:41.800 --> 01:00:52.920]  Вот такое вот пространство. Почему по модулю 3 вот это будет катарсис? Сейчас. Теперь я напишу,
[01:00:52.920 --> 01:00:59.720]  как он определяется. Значит, определяется он в точке Y. Y со стрелочкой это вот набор этих
[01:00:59.720 --> 01:01:08.200]  переменных. Y со стрелочкой это N-мерный вектор переменных Y1, Yn. Определяется он вот так. Это
[01:01:08.200 --> 01:01:18.440]  xt скалярно умножить на Y, а тут будет то же самое xt скалярно умножить на Y, но минус 1.
[01:01:18.440 --> 01:01:27.840]  Так, привожу пример, чтобы было понятно, просто трудно воспринимать без примера,
[01:01:27.960 --> 01:01:39.040]  я хорошо понимаю. Вот представьте себе, например, что xt вот такой. Раз, два, три, четыре, пять. И
[01:01:39.040 --> 01:01:47.840]  дальше пошли нули. Ну, то есть аито это просто один, два, три, четыре, пять. Не, ну может такое
[01:01:47.840 --> 01:01:54.000]  случиться, что аито это просто первый пять чисел. Да, вероятность не равна нулю. Значит,
[01:01:54.000 --> 01:02:09.040]  тогда xt будет вот таким, а pxt от Y. Это просто вот что. Это Y1 плюс Y2 плюс и так далее плюс Y5
[01:02:09.040 --> 01:02:18.800]  умножить на все то же самое, и из этого вычитается единица. То есть это такой многочлен второй степени.
[01:02:18.800 --> 01:02:26.520]  Ну, в данном случае как бы от пяти переменных, но понятно, что если бы аито было не таким,
[01:02:26.520 --> 01:02:31.840]  а эти пять единиц стояли где-то в другом месте, но от пяти других переменных было. Поэтому реально
[01:02:31.840 --> 01:02:39.400]  задействованы, конечно, все переменные в зависимости от того, какие у нас тут множество а1, аt. Вполне
[01:02:39.400 --> 01:02:46.320]  могут покрыться все переменные. Так, сейчас понятно, как устроено многочлен, но на примере вроде видно.
[01:02:46.320 --> 01:02:52.280]  То есть можно вообще просто сказать, если у вас есть множество какое-то вершин, например,
[01:02:52.280 --> 01:03:03.640]  1, 2, 3, 4, 5, то здесь вот эти номера и возникнут. Номера вот этих перемен. Хорошо, да? Сейчас будет
[01:03:03.640 --> 01:03:19.240]  еще лучше. Дорогие друзья, я вам сейчас предскажу катарсис, в чем он состоит,
[01:03:19.240 --> 01:03:25.960]  а почему катарсис. Смотрите, друзья, сейчас вы все поймете. Если я эти скобки раскрою,
[01:03:25.960 --> 01:03:36.120]  ну вот эти скобки раскрою, то какой очевидно базис нарисуется? Базис, порождающий все вот эти
[01:03:36.120 --> 01:03:42.720]  многочлены. Ну из чего он будет состоять? Он будет состоять из вот таких вот штук, правильно?
[01:03:42.720 --> 01:03:52.680]  yt в квадрате. Он будет состоять из вот таких вот штук, где i не равно j и в нем еще будут просто
[01:03:52.680 --> 01:04:03.800]  y и t. Таких штук c и z по 2, таких c и z по 1, таких c и z по 1. То есть чего, товарищи, я хочу доказать.
[01:04:03.800 --> 01:04:12.960]  Смотрите сюда и смотрите сюда. Я хочу доказать, что многочлены, которые мы сопоставили всем нашим
[01:04:12.960 --> 01:04:25.240]  вот этим a1at, линейно независимы над z3. Если я сейчас докажу все, теориям доказана.
[01:04:25.240 --> 01:04:35.760]  Вот это пока непонятно. Это будет следующий катарсис. На z3 это следующий. Но вы поняли,
[01:04:35.760 --> 01:04:45.080]  да, в чем идея? Идея доказать, что сопоставленные нашим ребрам алгебронические объекты в твоем
[01:04:45.080 --> 01:04:52.600]  пространстве линейно независимы значат их не больше, чем размерность этого пространства. Ну
[01:04:52.600 --> 01:05:01.400]  базис-то там такой, значит размерность это вот то, что мы заявили. Все, кого-то проканало.
[01:05:01.400 --> 01:05:11.720]  Сейчас, друзья, идея всем понятна, да? Ну круто же, да? Давайте ее реализуем, поймем, зачем я взял
[01:05:11.720 --> 01:05:19.400]  именно z3. Это же был мой произвол, я могу коэффициенты где угодно рассматривать, хоть в R. Многочлен от этого не
[01:05:19.400 --> 01:05:25.480]  поменяется. А вот я для чего-то еще доказываю линейную независимость над z3. Я не утверждаю,
[01:05:25.480 --> 01:05:41.080]  что над z5 она есть. Вот над z3 она будет. Ну давайте писать c1 px1, так далее, плюс ct pxt равно нулю.
[01:05:41.080 --> 01:05:48.240]  Друзья, я на всякий случай всегда в этом месте занудствую. Я прошу вас очень аккуратно с алгеброй,
[01:05:48.240 --> 01:05:58.560]  вы понимаете, что вот этот 0 это не число, это многочлен нулевой в своем пространстве. Это все
[01:05:58.560 --> 01:06:14.320]  понимают. А вот цииты это вычеты из z3. Вот мы так подобрали коэффициенты, что получился 0. Смотрите,
[01:06:14.320 --> 01:06:19.960]  я очень аккуратно пишу. Это неравносильно тому, что сейчас появится, но из этого следует то,
[01:06:19.960 --> 01:06:31.240]  что сейчас будет на доске. Именно следует. Следует, что для любого y, ну например, из 0,1 в n степени,
[01:06:31.240 --> 01:06:42.720]  то есть когда координаты все равны нулям и единицам. Ух, c1 px1 от y, плюс и так далее,
[01:06:42.720 --> 01:06:55.760]  плюс ct pxt от y. Но я все-таки пишу равно нулю. Но имеется в виду уже в z3. Чувствуете разницу,
[01:06:55.840 --> 01:07:01.960]  да? То есть здесь складываются многочлены как формальные выражения, как формальные степенные
[01:07:01.960 --> 01:07:07.760]  ряды, если хотите, с какими-то коэффициентами. И получается многочлен, у которого все коэффициенты
[01:07:07.760 --> 01:07:13.760]  нулевые. Ну понятно, что если теперь вместо переменных подставить какие-то реальные чиселки,
[01:07:13.760 --> 01:07:21.240]  например, нолики и единички, то как следствие будет 0 уже в числовом смысле этого слова. Но только
[01:07:21.240 --> 01:07:32.360]  как следствие? Это, конечно, неравносильно одно другому. Нормально? Понятно, что я говорю?
[01:07:32.360 --> 01:07:39.520]  Ну реально нам, конечно, нужно вот это. Но оно следует, конечно, из нашего предположения исходного.
[01:07:39.520 --> 01:07:54.880]  Ну что ж, давайте возьмем в качестве y, ну, например, x1. Не важно. Возьмем x1. X1 он же из 0 единиц
[01:07:54.880 --> 01:08:07.000]  по построению. Я понимаю. Так, допустим, что будет такое px1 от x1? Вот сюда подставляем вместо y
[01:08:07.000 --> 01:08:21.640]  x1. Смотрим на определение. Это будет x1 на x1 и тут будет x1 на x1. Так, чему равен x1 на x1? 5. У нас же в каждом
[01:08:21.640 --> 01:08:27.520]  векторе 5 единиц. Если вы его над самого себя умножаете, вы 5 получаете. Так, друзья, все понимают,
[01:08:27.520 --> 01:08:38.560]  что 5. Так, значит, здесь получается 5 на 4. Чему это равно? Ну, 20, но оно же и 2, да? Потому что по модулю 3. Вот
[01:08:38.560 --> 01:08:44.280]  тут уже становится важно, что по модулю 3 живет. По модулю 3 это равно 2, но главное, на самом деле,
[01:08:44.280 --> 01:08:56.720]  что не равно 0. Вот это равно 2. Теперь, смотрите, подставляем px1 тот же самый x1, где и уже больше
[01:08:56.720 --> 01:09:04.600]  либо равно 2. Подставляем туда же, в оставшуюся часть нашей суммы. Что здесь получается? Получается xt
[01:09:04.600 --> 01:09:19.360]  на x1. Да, да, кроме 2. Да, да. xt на x1 минус 1. Какие вычеты-то возможны? Все кроме 2 и 5. Ну, кроме
[01:09:19.360 --> 01:09:31.640]  2. Потому что пятерку мы отмели. Вот пятерка была тут. xt и x1 разные. Поэтому остается 0, 1, 3 и 4. 0. 1 тоже
[01:09:31.640 --> 01:09:43.320]  дает 0. 3 тоже дает 0. 4 тоже дает 0. Это 0, товарищи, всегда в наших условиях. Мы запретили 2. 2 могла бы
[01:09:43.320 --> 01:09:49.800]  дать снова вот такую же двойку, но ее нет по условию. У нас не бывает двойки. Вот условия. Вот она.
[01:09:49.800 --> 01:09:57.880]  Двойки не бывает. А бывает что угодно, но только не двойка. И от 5 мы уже избавились, потому что 5
[01:09:57.880 --> 01:10:03.440]  это когда они совпадают. Все, значит, остаются только такие вычеты, которые дают на этой форме 0.
[01:10:03.440 --> 01:10:15.920]  У нас получается вот тут 0 сплошной, а тут 2. Какое отсюда следствие? c1 равняется 0 в z3. Ну, друзья,
[01:10:15.920 --> 01:10:23.240]  ну все симметрично. Это я для примера подставил x1. Если я также подставлю x2, x3, у меня все остальные
[01:10:23.240 --> 01:10:30.400]  окажутся нулевыми. Ну, то есть из предположения вот этого равенства следует, что все коэффициенты
[01:10:30.400 --> 01:10:37.360]  нулевые. Ну, значит, многочлены независимы и таких действительно не больше, чем размерность пространства,
[01:10:37.360 --> 01:10:46.560]  в котором они живут. Все, я доказал. Ну, согласитесь, это по сути в одну строчку. Ну, по сути, если
[01:10:46.560 --> 01:10:52.880]  понимать, да, поля там что-то такое, это же в одну строчку. А пойди вот комбинаторно это докажи.
[01:10:52.880 --> 01:11:00.720]  Вот такая вот удивительная вещь. Значит, в следующий раз я сформунирую, ну и как бы докажу,
[01:11:00.720 --> 01:11:08.720]  наверное, общее утверждение. Сейчас я не успеваю уже. Вот, и еще некоторые его важные обобщения. А дальше
[01:11:08.720 --> 01:11:14.320]  двинемся дальше. Там же у нас еще есть h, есть f. Вот такой план. На сегодня все.
