[00:00.000 --> 00:12.240]  так ладно давайте начинать анонс у нас сегодня три часа полтора часа и полтора часа и мы
[00:12.240 --> 00:17.400]  собираемся поговорить про одну тему и то только наполовину поэтому пожалуйста это морально
[00:17.400 --> 00:25.400]  подготовьтесь к этому и давайте я вас предупрежу и попрошу что ну во первых я предупрежу о том
[00:25.400 --> 00:30.680]  что рассказ длинный и сложный и там возникает много наверное новых понятий вот оперативная
[00:30.680 --> 00:35.360]  память всем элементах переполнится поэтому пожалуйста если у вас есть вопрос если вы
[00:35.360 --> 00:41.040]  чего-то не понимаете то не думайте что дальше станет понятнее станет хуже поэтому вот сразу
[00:41.040 --> 00:55.080]  задавайте вопросы иначе вся лекция пропадет итак давайте начинать наш тему сегодня наконец
[00:55.080 --> 00:59.720]  модели согласованности памяти они у нас как-то появлялись в курсе так очень косвенно в некоторых
[00:59.720 --> 01:04.200]  задачах на них ссылались иногда что про это говорил вы сами видели в документации про том
[01:04.200 --> 01:10.680]  что там есть какие-то memory order в параметрах операций вот сегодня мы к этому немного прикоснемся
[01:10.680 --> 01:21.440]  но начнем мы издалека вот смотрите узнаете ли вы эту штуку мы демонстрацию не видим вы не
[01:21.440 --> 01:34.160]  видите демонстрацию это чертовски обидно если вы видите это в первый раз то тут уже поздно
[01:34.160 --> 01:42.840]  это реализация мютокса которая была по ссылке задачи мютокс ну как там была скопирована
[01:42.840 --> 01:48.440]  реализация скопирована она была из статьи которая называется фюдокса сатрики это статья одного
[01:48.440 --> 01:53.840]  из мейнтейнеров ядра который пишет про то как пользоваться фюдоксами а именно как можно из
[01:53.840 --> 02:01.840]  фюдокса смастерить взаимные исключения тут есть три версии одна лучше другой но вот это одна из
[02:01.840 --> 02:08.160]  них и почему я ее показываю потому что она достаточно нетривиально но вот на прошлом семинаре
[02:08.160 --> 02:13.480]  своем я разбирал если что есть запись этого семинара вы можете посмотреть но тут есть много
[02:13.480 --> 02:18.560]  кассов они называются компресс чейнч это не важно совершенно есть атомик атомарный декремент
[02:18.560 --> 02:26.920]  есть фюдокс и разобраться почему да и это реализация лока на трех состояниях 0 свободен 1
[02:26.920 --> 02:33.480]  захвачен без контеншина 2 захвачен и есть ждущие потоки и вот в этой реализации есть некоторые
[02:33.480 --> 02:38.160]  довольно тонкие моменты когда мы захватываем лог из нуля сразу состояние 2 но вот про это я
[02:38.160 --> 02:43.920]  рассказывал сейчас не это важно сейчас важно что реализация нетривиальная и если вы пытаетесь в
[02:43.920 --> 02:49.240]  ней разобраться возможно вы решая домашку пытались в ней разобраться то вы наверное
[02:49.240 --> 02:55.760]  представляете что это делать сложно потому что тут много строчек довольно и вот сложно
[02:55.760 --> 03:00.800]  перебрать в уме все их интерливинги все возможные переключения комбинации там все возможные
[03:00.800 --> 03:07.440]  достижимые состояния ну сложно но все же возможно то есть что вы делаете у меня вы берете этот
[03:07.440 --> 03:12.840]  мютокс этот код как будто бы его в голове там три раза копии там несколько раз копируете а потом
[03:12.840 --> 03:18.560]  ходите курсором программы по вот этим копиям переключаясь с одной на другую вот так вы
[03:18.560 --> 03:22.720]  моделируете исполнение программы вот пытаетесь в уме перебрать все возможные ее состояние
[03:22.720 --> 03:28.520]  пришла пора поговорить о том что так делать нельзя что вот так на самом деле компьютер не
[03:28.520 --> 03:36.000]  работает что вот так рассуждать об исполнении многопоточного кода несколько наивно ну почему
[03:36.000 --> 03:42.680]  наивно давайте про разные моменты поговорим вот во первых у вас есть представление что вот
[03:42.680 --> 03:48.360]  есть некоторая ячейка памяти разделяемая с которой вы работаете вот если разобраться как компьютер
[03:48.360 --> 03:55.440]  устроен то окажется что вот ячейка это некоторая абстракция вот вы запускаете такой тест у вас
[03:55.440 --> 04:00.240]  есть много ядер и вы пишете на разных ядрах один раз в одну ячейку свой номер а потом просто в
[04:00.240 --> 04:08.400]  цикле читаете и вот какую картины вы наблюдаете вот разные разные ядра читают из одной и той же
[04:08.400 --> 04:13.800]  ячейки в разные моменты времени в одни и те же моменты времени разные значения тут на самом
[04:13.800 --> 04:19.640]  деле некоторая структура есть мы к этому вернемся но вот ячейка памяти это уже более сложный
[04:19.640 --> 04:25.600]  объект чем мы наверное привыкли считать почему она такая сложная ну потому что есть гирянт почему
[04:25.600 --> 04:30.560]  потому что есть киши потому что логическая ячейка воплощена в нескольких физических
[04:30.560 --> 04:36.520]  представлениях нескольких копиях там кишей памяти и значение там могут вообще говоря разным есть
[04:36.520 --> 04:44.720]  еще store buffer про них тоже поговорим в общем ячейка памяти не так проста дальше ну вот возьмем
[04:44.720 --> 04:52.720]  такой наивный код а равно б плюс 1 б равно 1 компелируем его ну давайте я прямо покажу
[04:52.720 --> 05:02.080]  во что мы его компелируем не в этом goodball все стер проклятие
[05:02.080 --> 05:09.960]  ну не знаю давайте напишем его раз он все стер мне то
[05:09.960 --> 05:32.720]  и что мы хотим написать вот такой вот код и скомпилируем его скажем gcc
[05:32.720 --> 05:44.440]  ну вот смотрите что нетривиального здесь произошло вот у нас есть программа в которой
[05:44.440 --> 05:53.000]  есть строчка а равно б плюс 1 запись в ячейку а запись в ячейку б а потом мы компелируем этот
[05:53.000 --> 05:59.920]  код и что мы видим мы во первых загружаем значение из ячейки памяти б в регистр потом
[05:59.920 --> 06:06.160]  мы сразу пишем в ячейку памяти б потом мы инкрементируем содержимое регистров которые
[06:06.160 --> 06:13.520]  почитали значение б изначально потом мы пишем ячейку памяти а ну то есть вот у нас есть две
[06:13.520 --> 06:18.080]  записи между ними есть точка запятой которая казалось бы определяет порядок следовании этих
[06:18.080 --> 06:28.960]  записях но в память запись происходит в другом порядке довольно странно но тут смотрите компилятор
[06:28.960 --> 06:34.760]  можно понять он действует довольно разумно он не нарушает наблюдаемое поведение однопоточной
[06:34.760 --> 06:41.320]  программы но при этом если программа была многопоточная если две эти записи были
[06:41.320 --> 06:46.720]  где-то скажем в циклическом буфере который в прошлый раз разбирали то если вдруг компилятор
[06:46.720 --> 06:57.040]  решит переставить местами запись буфер и запись в атомик то что мы получаем мы получаем разломанную
[06:57.040 --> 07:05.520]  синхронизацию вот еще один пример того что реальность отличается от наших ожиданий
[07:05.520 --> 07:17.880]  дальше у нас есть процессор простите я слушаю эхо у кого-то в зале выключите пожалуйста
[07:17.880 --> 07:24.080]  оператор возможно у тебя эхо и оно
[07:30.080 --> 07:32.760]  но может потише сделать звук потому что немного мешает
[07:32.760 --> 07:44.080]  значит смотрите во первых у нас есть немного сложный ячейка ячейка памяти
[07:44.280 --> 07:49.680]  сложнее чем они думаем у нас есть компилятор который может в принципе приорды переставить
[07:49.680 --> 07:55.600]  местами две записи программе кроме того у нас есть процессор который вот я вам явно в своей
[07:55.600 --> 07:59.760]  документации говорить что есть некоторые программы которые ведут себя странно эта
[07:59.760 --> 08:04.800]  программа мы уже разбирали здесь одно ядро пишет в икс читает из игрек а другое ядро пишет в
[08:04.800 --> 08:11.640]  игре читает язык с асимметрично и в итоге программа наблюдает два нуля что в общем не объясняется
[08:11.640 --> 08:19.640]  никаким разумным исполнением вот почему так получается но давайте как-то мотивируем такой
[08:19.640 --> 08:25.800]  сценарий ну теперь уже это можно сделать смотрите мы знаем что в процессоре есть кэша что у каждого
[08:25.800 --> 08:30.720]  ядра есть собственный кэш эти кэши нужно синхронизировать через некоторую шину памяти
[08:30.720 --> 08:37.320]  через интерконнект что значит синхронизировать мы поддерживаем в кэшах следующие варианты что
[08:37.380 --> 08:48.720]  у нас либо кэшли не актуальные совпадают с памятью и тогда она может находиться Safety
[08:48.720 --> 08:54.480]  от содержимого памяти и тогда на может находиться только в одном ядре но такой эксклюзивное владение
[08:54.480 --> 08:59.120]  разделяем стебель не эксклюзивное владение и для того чтобы эти варианты поддерживать
[08:59.120 --> 09:04.880]  про ядром процессора нужно друг с другом коммуницировать по этой шине памяти если
[09:04.880 --> 09:10.520]  мы пишем ячейку памяти, мы должны убедиться, что в других кышах нет ее копий. Поэтому что мы
[09:10.520 --> 09:17.420]  делаем? Мы отправляем другим кышам сообщение инвалидации и ждем, пока нам ответят. В течение
[09:17.420 --> 09:23.760]  этого времени процессор ядро простаивает. И вот почему образуется такое исполнение? Потому
[09:23.760 --> 09:31.760]  что процессор хочет в таком сценарии сэкономить время простое. Каким образом? Он берет и помещает,
[09:31.760 --> 09:40.200]  ну как бы не он процессор, инженеры помещают между ядром процессора и кышом storebuffer. И если ядро
[09:40.200 --> 09:47.960]  хочет сделать запись в ячейку памяти и оказывается, что в кэше данного ядра кэш линий для этой ячейки
[09:47.960 --> 09:55.520]  нет, потому что она находится у соседа, то мы запись помещаем в этот самый storebuffer. До протоколок
[09:55.520 --> 10:00.680]  герентости она не доходит еще. А дальше мы читаем следующие инструкции, но инструкция как будто бы
[10:00.680 --> 10:06.080]  завершает исполнение. Дальше мы читаем из другой ячейки памяти, и оказывается, что кэш линия с этой
[10:06.080 --> 10:13.960]  ячейки у нас уже есть. И вот мы записали х, никому об этом не сказав на самом деле, другим ядрам
[10:13.960 --> 10:21.200]  не сказав, и прочитали ноль из у. Ну а другое ядро поступает точно так же. Оно пишет в у,
[10:21.200 --> 10:28.640]  которого у него нет, то есть кладет в свой storebuffer эту запись и читает из х ноль. Ну и вот мы получили
[10:28.640 --> 10:34.760]  два нуля. То есть все довольно разумно, оптимизация работает, но правда порождает довольно странные
[10:34.760 --> 10:41.160]  исполнения. В принципе ничего необычного, так примерно вот система контроля версии работает.
[10:41.160 --> 10:48.240]  У вас есть ремут общий, но вы с ним, вы в него пока ничего не отправляете, вы делаете какие-то
[10:48.240 --> 10:55.320]  модификации локальные и в итоге наблюдаете несколько несогласованную картину мира. Ну как
[10:55.320 --> 11:02.960]  для вас это выглядит? Как будто бы в этой программе лот обогнал, опередил предшествующий ему
[11:02.960 --> 11:09.040]  store. Вот вроде было бы написано запись, потом чтение, а на самом деле случилось как будто бы
[11:09.040 --> 11:17.600]  чтение, а потом запись. Но вот этим можно было бы объяснить исполнение с двумя нулями. Но мы это
[11:17.600 --> 11:23.600]  назовем так условно reordering, но на самом деле вы видите, что не то чтобы что-то местами переставилось,
[11:23.600 --> 11:31.600]  каждое ядро исполняли инструкции по очереди, просто был вот этот самый store buffer. Почему вот такие
[11:31.600 --> 11:36.320]  reordering нас волнует? Ну потому что, не знаю, мы рассматривали лок-петерсы не то чтобы самые
[11:36.320 --> 11:44.240]  полезные программы на свете, но один из самых древних протоколов взаимного исключения. И довольно
[11:44.240 --> 11:52.080]  обидно, что он не работает. Вот если мы рассмотрим ядро этого алгоритма, то у нас есть свой флажок,
[11:52.080 --> 11:58.200]  есть флажок нашего конкурента, и мы пишем свой и читаем конкурента. И вот без дополнительных
[11:58.200 --> 12:05.880]  усилий этот код ломается на нашем процессоре. Ну с другой стороны вы скажете, что пример довольно
[12:05.880 --> 12:12.280]  странный, кому нужен лок-петерсон. Ну вот на этот случай у меня припустены два примера. Первый
[12:12.280 --> 12:25.840]  это runtime языка Go. Вот просто мы открываем Go on Go на гитхабе, идем в runtime и смотрим, что вот
[12:25.840 --> 12:32.080]  нам говорят, что на самом деле в runtime Go возникает ровно такой сценарий. Возникает он в сборке
[12:32.080 --> 12:37.280]  мусора конкурентной. Если вы знаете про язык Go, то там есть сборка мусора, которое не ставит на
[12:37.280 --> 12:43.200]  паузу исполнения вашей программы. Ну почти. То есть поток, который собирает мусор в памяти,
[12:43.200 --> 12:49.840]  он, ну, горутина. Она работает конкурентно с горутинами, которые вы сами написали. Вот горутина
[12:49.840 --> 12:54.360]  сборки мусора и горутина называют их мутаторы в вашей программе. Мутаторы модифицируют граф
[12:54.360 --> 13:02.520]  ссылок в ваш, там, ссылок между вашими объектами. Коллектор собирает, обходит этот граф и красит
[13:02.520 --> 13:14.840]  его там в три цвета. И возможен такой сценарий, когда мутатор, переставляя ссылку... Если мутатор
[13:14.840 --> 13:20.240]  переставляет ссылки в графе, а коллектор обходит этот граф, то мутатор должен коллектору сообщать,
[13:20.240 --> 13:24.880]  что граф изменился, что, там, какая-то ссылка переставилась. И вот может случиться такой
[13:24.880 --> 13:34.400]  сценарий, что мутатор переставил ссылку, но не смог уведомить об этом коллектор, то есть коллектор
[13:34.400 --> 13:41.000]  это не обнаружил эту измененную ссылку. Покрасил объект как обойденный, и вот по новой ссылке не
[13:41.000 --> 13:47.200]  сходило. В итоге у вас, ну, не то чтобы утечка, вы не обошли живой объект, вы его потеряли. Это довольно
[13:47.200 --> 13:51.920]  сложный сценарий, я сейчас не хочу его подробно разбирать, но вот суть такая. Граф поменялся,
[13:51.920 --> 14:03.200]  коллектор этого не заметил, упустил живой объект. Память покорапчена. Другой пример, где возникает
[14:03.200 --> 14:09.560]  вот такой вот сценарий, который мы называем store buffering, у него есть собственное имя, это реализация
[14:09.560 --> 14:14.720]  фьютекса. Если вы ходили по ссылкам из условий домашней работы, ходили, читали комментарии в
[14:15.720 --> 14:24.320]  там есть это не он, то опять же там об этом сообщают. Вот мы пишем ячейку с фьютекса,
[14:24.320 --> 14:31.160]  с состоянием лока, у нас есть ячейка со счетчиком ждущих потоков, и вот если мы такую оптимизацию
[14:31.160 --> 14:36.880]  делаем для фьютекса, то у нас получается ровный, например, store buffering, и если он не работает,
[14:36.880 --> 14:43.240]  то наша взаимная блокировка подвисает. То есть лок освобождают, но при этом поток, который его
[14:43.240 --> 14:52.000]  ждет, засыпает и не просыпается. То есть опять проблема ненадуманная, проблема действительно
[14:52.000 --> 14:57.880]  влияет на синхронизацию, причем влияет на какие-то сложные системы. Но представьте, что у вас
[14:57.880 --> 15:06.040]  разломался код в ядре линукса или разломался код в runtime go. Последствия будут очень серьезными.
[15:06.040 --> 15:13.640]  И это всего лишь один сценарий reordering, когда последующий load обогнал, в кавычках,
[15:13.640 --> 15:20.720]  предшествующий store. Это на самом деле единственный плохой сценарий, который на вашем интеле
[15:20.720 --> 15:27.800]  реализуется. Но есть и другие архитектуры процессоров, и там гораздо больше сценариев, возможно.
[15:27.800 --> 15:35.640]  Жить в таком мире, кажется, довольно сложно. Вот посмотрим на ARM. Вот на ARM можно написать
[15:35.640 --> 15:41.760]  такую программу. У вас есть две ячейки памяти x и y, изначально равные нулю. На одном ядре вы
[15:41.760 --> 15:49.720]  пишете в x единицу, на другом ядре вы читаете значение из x в регистр, а потом пишете прочитанные
[15:49.720 --> 15:57.360]  значения в y. В третьем потоке вы читаете сначала из y, потом из x. И что вы ожидаете,
[15:57.360 --> 16:06.360]  что если вы увидели в игре единицу, то в x вы уж точно ее увидите. Разумное же ожидание. Вот.
[16:06.360 --> 16:14.680]  Но ARM говорит, что нет, не стоит такого ждать, потому что... Почему сейчас объясним? Не потому,
[16:14.680 --> 16:20.480]  что он что-то местами переставил, а потому что оказывается, что в процессоре у разных ядер
[16:20.480 --> 16:27.160]  иногда бывают общие storebuffers. И в итоге ваша запись одному ядру может быть видна,
[16:27.160 --> 16:32.000]  а другого может быть не видна. И вот одни и те же записи, они могут быть видны разным ядром в
[16:32.000 --> 16:41.000]  разном порядке. Довольно сложная ситуация. Вот. Смотрите. Совершенно непонятно, как в таком мире
[16:41.000 --> 16:46.080]  жить. У нас есть процессор, который может переставить две записи в память. У нас есть
[16:46.080 --> 16:50.660]  ячейка памяти, в которой много значений. У нас есть процессор, который во время исполнения что-то
[16:50.660 --> 16:55.640]  странное с программой делает. Как-то инструкции переставляет, помещает их в storebuffer, скрывает
[16:55.640 --> 17:02.760]  протокол гигиентности. На что вообще в таком мире можно опереться? И этот вопрос вот еще раз
[17:02.760 --> 17:07.800]  непраздный. Вот представьте, что вы пишете ядро линукса, и вам нужно написать код, который будет
[17:07.800 --> 17:14.800]  работать там на 30 разных архитектурах. А у вас каждая из этих архитектур с какими-то причудами.
[17:14.800 --> 17:24.880]  Вот чертовски сложно. Ну ладно, мы здесь все-таки не пишем линукс, но в любом случае вы, как
[17:24.880 --> 17:30.800]  разработчик, вряд ли хотите думать, когда вы пишете многопоточный код, о том, какой процессор
[17:30.800 --> 17:36.480]  под вами находится. Как он именно там что-то риордерит, оптимизирует. Вы хотите, чтобы ваша
[17:36.480 --> 17:44.200]  программа как-то предсказуемо исполнялась на любом процессоре. Это не значит одинаково, но все же
[17:44.200 --> 17:51.000]  вы хотите иметь в голове какую-то модель исполнения вашей программы. Ну вот так мы
[17:51.000 --> 18:03.320]  приходим к понятию о модели памяти. В зуме кто-то шумит, простите. Сейчас мы кого-то забаним.
[18:03.320 --> 18:17.120]  Секундочку. Там есть кнопочка замутить. А я сейчас еще кого замутить? Алекс полигональный. Прощай.
[18:17.120 --> 18:25.800]  Алекс. Все, шум пропал. Отлично, мы продолжаем. Итак, значит, мы понимаем, что мир устроен
[18:25.800 --> 18:31.720]  сложно, что жить в нем непонятно как, поэтому мы хотим найти какую-то опору в этом мире. И эта
[18:31.720 --> 18:37.200]  опора называется модель памяти или модель согласованности памяти, если быть совсем аккуратным.
[18:37.200 --> 18:43.120]  Модель согласованности памяти в языке программирования — это просто составляющая
[18:43.120 --> 18:50.640]  семантики языка. Она определяет смысл многопоточных программ. Что мы понимаем под исполнением
[18:50.640 --> 18:56.720]  программы? Какой в ней вообще есть смысл? Вот формально говоря, до C++11 у многопоточных программ
[18:56.720 --> 19:02.440]  на C++ не было семантики, не было смысла. Писать их кроссплатформенно было невозможно.
[19:02.440 --> 19:13.400]  Как нам помогает модель памяти? Вот она задает семантику программ. Можно было бы считать так
[19:13.400 --> 19:19.080]  наивно, что модель памяти говорит нам, в каком порядке выполняются чтения и записи в разделяемые
[19:19.080 --> 19:25.480]  ячейки памяти из разных потоков при исполнении программы. Но так говорить не совсем корректно,
[19:25.480 --> 19:29.880]  потому что сама постановка вопроса подразумевает, что вот есть некоторый порядок, в котором все
[19:29.880 --> 19:37.680]  происходит. Можно чуть аккуратнее сказать, что модель памяти описывает все возможные исполнения
[19:37.680 --> 19:48.080]  многопоточной программы. Это уже будет точнее, ближе к сути. Но, смотрите, вы, как наблюдатель
[19:48.080 --> 19:57.800]  внешний, все равно вы не можете увидеть, как именно процессор что-то исполняет. В конце концов,
[19:57.800 --> 20:03.640]  процессор устроен дико сложно. Все, что вы можете наблюдать на самом деле про исполнение программы,
[20:03.640 --> 20:11.360]  это результаты чтений. Поэтому мы скажем, что модель памяти отвечает на такой вопрос. Какую
[20:11.360 --> 20:18.680]  запись увидит конкретное чтение вашей программе? Какую запись оно вообще может увидеть? Это будет
[20:18.680 --> 20:26.160]  еще аккуратнее. Ну, а если подойти с точки зрения практики, то вряд ли мы прям совсем угадываем,
[20:26.160 --> 20:31.600]  что же увидит чтение. Мы пишем какой-то код синхронизации, пишем канал, например, для потоков
[20:31.600 --> 20:39.920]  или для файберов. И вот мы ожидаем, что если один поток вызвал сент, а потом, нужно аккуратнее,
[20:39.920 --> 20:45.320]  конечно, объяснить, а потом другой поток, другой файбер вызывает ресив, то мы, наверное, ожидаем,
[20:45.320 --> 20:55.200]  что этот ресив увидит этот самый X, записанный в буфер канала. Поэтому совсем точно будет сказать,
[20:55.200 --> 21:02.760]  что модель памяти объясняет нам, как гарантировать, что чтение в программе увидит какую-то запись
[21:02.760 --> 21:12.000]  программе, какую-то запись, нужную этому чтению. Как гарантировать, что вот этот ресив, будучи
[21:12.000 --> 21:21.560]  упорядочен во времени с сентом причинностью, увидит эту запись, этот сент XA? Вот это значит
[21:21.560 --> 21:25.560]  семантика многопоточной программы, это значит модель памяти. Вот модель памяти нужна для того,
[21:25.680 --> 21:38.640]  чтобы на такие вопросы отвечать. В принципе, на любой из них. Давайте я еще раз прокомментирую,
[21:38.640 --> 21:47.520]  что в этой постановке значит нужную. Вот мы пишем спинлок, например. Вот чтение увидит нужную
[21:47.520 --> 21:53.400]  запись для спинлока может означать следующее, что как гарантировать, что чтение в последующих
[21:53.400 --> 21:59.760]  критических секциях увидит записи из предшествующих критических секций. Гарантия вот абсолютно
[21:59.760 --> 22:06.000]  очевидная, да, но вот мы это принимаем как данность просто. Но вот еще раз, как данность
[22:06.000 --> 22:13.760]  принимать больше ничего нельзя, потому что мы видим, что компьютер работает сложнее, поэтому
[22:13.760 --> 22:18.440]  даже такие базовые очевидные гарантии мы с этого момента должны обеспечивать как-то,
[22:18.520 --> 22:27.080]  понимать, откуда они именно берутся. Вот этим мы сегодня и займемся, а пока вот просто
[22:27.080 --> 22:33.440]  некоторый перечень моделей памяти, с которыми вы можете столкнуться в жизни. Вот кажется,
[22:33.440 --> 22:39.600]  что первый язык промышленный, в котором появилась модель памяти, который решил все-таки формально
[22:39.600 --> 22:46.160]  описать семантику многопоточных программ, это была Джава. И вот смотрите, мы читаем модель памяти
[22:46.160 --> 22:51.040]  Джавы, и тут написано, что вот о чем она. Модель памяти Джавы описывает все возможные исполнения
[22:51.040 --> 23:07.560]  многопоточных программ. На всякий случай, вот давайте я покажу вам ее. Вот она, почему я начинаю
[23:07.560 --> 23:13.120]  именно с нее, потому что мне кажется, что если вы решили изучить модель памяти, то модель памяти
[23:13.120 --> 23:19.840]  Джавы — это, мне кажется, очень хороший первый шаг. Эта модель памяти, вообще говоря, она сложная,
[23:19.840 --> 23:27.440]  но база ее, вот какая-то базовая часть, которую мы сегодня разберем, она очень простая и она очень
[23:27.440 --> 23:35.480]  хорошо, очень компактно описана. Вот мне кажется, что если вы вот хотите изучить какую-то модель памяти,
[23:35.480 --> 23:43.640]  то с Джавой очень неплохо было бы начать. Другой пример — язык ГО. Мы о нем часто вспоминаем,
[23:43.640 --> 23:49.160]  потому что мы в этом курсе пишем файберы, которые грутины. Ну и вот смотрите, модель памяти ГО,
[23:49.160 --> 23:58.200]  и тут написано, что. Модель памяти ГО описывает условия, при которых чтение переменной в одной
[23:58.200 --> 24:06.840]  грутине гарантированно увидит запись значения, записанная в другой грутине. То есть как
[24:06.840 --> 24:13.320]  гарантировать, что некоторое чтение увидит некоторую запись? Вот модель памяти ГО нужна для этого.
[24:13.320 --> 24:19.480]  Но мы говорим вообще-то не только про языки программирования. Вот еще раз вспоминал, что
[24:19.480 --> 24:25.040]  представим себе, что мы пишем Linux, под нами десятки разных архитектур, на всех мы должны
[24:25.040 --> 24:31.000]  предсказуемо работать, поэтому и ядру Линукса нужна собственная модель памяти. Причем эта модель
[24:31.000 --> 24:37.080]  памяти весьма и весьма сложная. Вот начинать с нее не стоит, конечно, но вообще-то это очень
[24:37.080 --> 24:43.760]  хороший источник для того, чтобы понять, как модели памяти декларативные устроены. Но документация
[24:43.760 --> 24:52.760]  сама огромная, просто посмотрите на размер ползунка здесь. Вот в ней, в этой документации очень-очень
[24:52.760 --> 24:58.440]  много параграфов. Каждый из них описывает какую-то часть модели памяти. Короче, это сложно.
[24:58.440 --> 25:08.720]  Ну двигаемся дальше по примерам. Linux C++. Ну вот C++ это с одной стороны самая продвинутая модель
[25:08.720 --> 25:15.680]  памяти, а с другой стороны разбираться в ней чудовищно сложно, потому что она сильно размазана
[25:15.680 --> 25:21.080]  по стандарту языка. Вот если в Java можно читать сверху вниз документацию и все будет ясно,
[25:21.080 --> 25:28.980]  то C++ она как-то образом разрезана на части, разбросана по разным там параграфам главам
[25:28.980 --> 25:38.120]  стандарта. Она сильно опфусцирована оптимизациями, удачными и неудачными. А кроме того, очень большая
[25:38.120 --> 25:47.040]  беда с описанием этой модели в том, что в описании модели памяти нет мотивации, почему все именно так,
[25:47.040 --> 25:54.880]  какие цели мы преследуем. Так что модели памяти C++, ну вот именно формально по стандарту,
[25:54.880 --> 25:59.840]  скорее всего следует изучать в последнюю очередь, когда вы уже с какими-то более простыми примерами
[25:59.840 --> 26:08.760]  разобрались. Ну вот как понять, что вы работаете с C++ с модели памяти? Ну вот вы пишете что-нибудь
[26:08.760 --> 26:16.480]  такое, вы наверное уже так пробовали делать, но сегодня мы вообще говоря будем этого избегать.
[26:16.480 --> 26:23.800]  Другой пример RAST. Вот с ним все довольно неожиданно, потому что в документации RAST написано,
[26:23.800 --> 26:28.960]  что в RAST нет пока модели памяти. Это довольно странно, потому что RAST это система язык
[26:28.960 --> 26:33.120]  программирования, которая нацелена на то, чтобы писать какой-то инфраструктурный код. Разумеется,
[26:33.120 --> 26:37.720]  на нем нужно писать конкарнси, более того язык в какой-то степени создан для того, чтобы не
[26:37.720 --> 26:43.680]  писать конкарнси, но при этом вот в языке модели памяти почему-то пока не хватает. Ну на самом деле
[26:43.680 --> 26:51.480]  тут дело сложнее естественно. На самом деле RAST говорит, что он просто по умолчанию наследует
[26:51.480 --> 27:00.240]  модели памяти из C++20. Но не потому что она особенно хороша, не потому что она проста и вообще
[27:00.240 --> 27:07.040]  известно, что в ней дыры есть. Но дыры есть не только в модели памяти C++, а просто в любой модели
[27:07.040 --> 27:11.680]  памяти, которая сейчас существует где-либо. В принципе, в самом подходе есть некоторые изъяны.
[27:11.680 --> 27:19.960]  Поэтому в RAST пока используют по умолчанию модели памяти C++20, а потом однажды, если человечество
[27:19.960 --> 27:31.280]  найдет какое-то более удачное решение, то RAST его задумывает. Почему есть вот некоторые проблемы в
[27:31.280 --> 27:38.000]  модели памяти? Почему все там pretty bad? Потому что модели памяти C++ не справляется с некоторыми
[27:38.000 --> 27:43.240]  странными частными случаями, которые можно прямо в стандарте найти. Там, не знаю, самое сбывающееся
[27:43.240 --> 27:48.760]  пророчество, значение, возникающее из воздуха. Но это, кажется, тема для семинаров. В общем,
[27:48.760 --> 27:53.200]  есть странные программы, для которых модели памяти ничего разумного сказать не может,
[27:53.200 --> 28:00.000]  к сожалению. И вот они прямо в тексте стандарта, так захардкожен такие сценарии. Давайте я прямо
[28:00.000 --> 28:10.600]  покажу это. Вот просто запрещаем такие программы, говорит нам стандарт. Довольно странно это выглядит,
[28:10.600 --> 28:19.320]  но проблема не в C++, проблема бы фундаментально в подходе. Есть LVM. В конце концов, много языков
[28:19.320 --> 28:24.200]  компилируются в LVM. Ему тоже нужна модель памяти, тоже нужна семантика для многопоточного кода,
[28:24.200 --> 28:31.240]  ну и вот опять те же самые идеи, что и в C++ мы считаем. Ну и вот тут появляется Рома и рассказывает,
[28:31.240 --> 28:40.640]  что есть еще и графические процессоры, и Рома. Да, я появляюсь. Ну да, помимо ЦПУ у нас есть ГПУ,
[28:40.640 --> 28:46.520]  и как те, кто играет в игры, наверное, знают, у них тоже есть своя оперативная память,
[28:46.520 --> 28:55.960]  видеопамять. И тоже есть свои кыши и свои причуды. Причуды эти на самом деле еще сложнее, чем даже
[28:55.960 --> 29:06.280]  ARM. Ну конечно, чтобы со всем этим как-то работать, пиша программы для ГПУ, ну любому API нужна какая-то
[29:06.280 --> 29:13.600]  модель памяти. Вот, как, например, тут Vulkan есть, у него, по-моему, более-менее хорошо в документации
[29:13.600 --> 29:20.200]  это описано, но, конечно, у всего остального оно тоже есть. CUDA, если вы про нее слышали, ну те,
[29:20.200 --> 29:27.080]  кто занимаются машинным обучением, скорее всего, слышали. OpenCL, ну и еще много у кого. Вот, и
[29:27.080 --> 29:36.040]  сложность там состоит в том, что вот, надеюсь, все здесь уже решили задачу Spinlock, и там мы заметили,
[29:36.040 --> 29:43.880]  что по умолчанию в C++ Memory Order стоит секция СТ. Это, собственно, то, что мы будем обсуждать на этой
[29:43.880 --> 29:52.760]  лекции. Но вот GPU устроено гораздо сложнее, и там просто нету этого секции СТ, вот этого понятного,
[29:52.760 --> 29:58.400]  приятного дефолта, который работает достаточно хорошо. И приходится каждый раз думать, когда
[29:58.400 --> 30:05.680]  пишешь код. Это мало того, там еще и нету протокола когерентности кашей, но вот каши просто
[30:05.680 --> 30:13.680]  некогерентные. А еще каши бывают в нескольких разных видов для разных данных. Совсем независимые
[30:13.680 --> 30:21.000]  каши для разных видов данных. Ну, это что-то совсем взрывающее мозг. Вот тут, если сделать CTRL-F по visible,
[30:21.000 --> 30:29.960]  вот Availability и Visibility. То есть, в принципе, эта модель памяти такая же, как в плюсах,
[30:29.960 --> 30:36.280]  но из нее выкинули секцию СТ и добавили вот эти два понятия, которые как раз про управление
[30:36.280 --> 30:43.000]  некогерентными кашами. Вот, в общем, тоже зверь страшный, сложный, и если вы планируете писать
[30:43.000 --> 30:50.720]  какой-то, ну, достаточно сложный код для GPU, то тоже приходится знать. Вот, у меня все.
[30:50.720 --> 31:00.040]  Спасибо, Рома. Рома нас, кажется, еще больше напугал. Но, смотрите, все не так плохо. Все не так
[31:00.040 --> 31:06.120]  плохо говорит нам язык ГО, потому что он говорит нам следующее, что вообще-то можно даже не думать
[31:06.120 --> 31:12.400]  про модели памяти. Ну вот, если вы не пишете сложные программы, если вы не пишете там какие-то
[31:12.400 --> 31:22.120]  memory-order у Atomic, если вы используете просто там Mutex и Atomic как-то вот просто в лоб, то, ну,
[31:22.120 --> 31:29.920]  можно не думать про все эти эффекты. Можно пользоваться моделью чередования. Вот, не умничайте
[31:29.920 --> 31:36.080]  говорить нам язык ГО. И все плюс-плюс, это самая история. Ну, в самом деле, мы с вами решаем задачи,
[31:36.080 --> 31:42.840]  в курсе пользуемся Atomic и работаем в модели чередования. Это вообще-то легально? Ну вот,
[31:42.840 --> 31:49.640]  документация говорит нам, что да, легально. Что до тех пор, пока вы просто используете Mutex и
[31:49.640 --> 31:58.720]  Atomic с memory-order sequential consistent, то вы можете думать об исполнении программы, как будто бы все
[31:58.720 --> 32:05.160]  потоки, они просто вот переключаются друг на друга. И, в принципе, весь этот курс можно пройти целиком,
[32:05.160 --> 32:12.640]  решить все задачи, не зная про модели памяти, не пользуясь memory-order и при этом код у вас будет
[32:12.640 --> 32:17.480]  получаться корректный. Он, может быть, будет не самый оптимальный на свете, но, тем не менее,
[32:17.480 --> 32:31.200]  оно будет корректным. Ну, и если вы все-таки решаете писать в memory-orders что-то другое,
[32:31.200 --> 32:36.480]  то вот вам придется знать гораздо больше, чем сейчас. Собственно, про это лекция и там
[32:36.480 --> 32:44.240]  последующие семинары. Ну, хорошо, значит, мы поговорили, какие проблемы возникают в процессорах,
[32:44.240 --> 32:52.320]  в компиляторах, в графических процессорах. Мы поговорили, как модели памяти собирается эти
[32:52.320 --> 32:58.800]  проблемы решать, точнее, не как, а вот как она собирается описывать семантику программ,
[32:58.800 --> 33:04.600]  которые исполняются на таких процессорах. Ну, а теперь поговорим, как именно эта семантика будет
[33:04.600 --> 33:10.480]  изложена в модели памяти. Есть, ну, я бы сказал, что два основных подхода. Есть операционный и
[33:10.480 --> 33:16.600]  декларативный. Операционный про то, как программа исполняется, а декларативный про то,
[33:16.600 --> 33:26.360]  как мы наблюдаем эти исполнения. Вот операционный подход. В чем он состоит? У вас есть какой-то
[33:26.360 --> 33:32.640]  сложный процессор. Там какие-то, не знаю, сколько, миллиарды, сколько там транзисторов, какое-то
[33:32.640 --> 33:39.760]  несметное число. Из них собраны какие-то сложные юниты. Там какие-то конвейеры сложные,
[33:39.760 --> 33:47.080]  бранч-предикторы, кэши, синхронизация, конгелентность. Мы пытаемся обо всем этом не думать,
[33:47.080 --> 33:54.440]  мы заменяем сложный процессор на абстрактную машину, которая строена гораздо проще, но которая
[33:54.440 --> 34:05.000]  порождает те же самые исполнения, что и настоящий процессор. Подход очень естественный, если вы
[34:05.000 --> 34:12.480]  вообще знаете про язык C++, потому что семантика всего C++ операционная. Вам говорят, вот некоторая
[34:12.480 --> 34:19.720]  абстрактная машина, там есть там память, стеки, выравнивание, размеры, там все вот это. Вам как бы
[34:19.720 --> 34:25.200]  говорят о том, как исполняется ваша программа. А дальше уже компилиатор работает над тем, чтобы
[34:25.200 --> 34:30.680]  эта абстрактная машина, ну как бы гарантии этой абстрактной машины соблюдались на каждой конкретной
[34:30.680 --> 34:40.880]  физической машине. Вот мы используем такой же подход только для многоточных программ. И вот
[34:40.880 --> 34:47.640]  пример того, как может выглядеть операционный модель памяти для процессора Intel. У нас есть
[34:47.640 --> 34:56.360]  разделяемая память, у нас есть ядра, и между ядром и памятью на запись стоит StoreBuffer. Когда
[34:56.360 --> 35:02.800]  мы пишем, мы пишем в него. Потом и в n-шале он флажется в память. Когда мы читаем, мы читаем из
[35:02.800 --> 35:13.120]  памяти или из StoreBuffer, где значение свежее. Вот эта схема вообще игнорирует наличие кэшей. И вот
[35:13.120 --> 35:18.880]  протоколка герентности. Потому что протоколка герентности, он для нас, ну вот с точки зрения
[35:18.880 --> 35:25.480]  memory, с точки зрения упорядочивания обращений к памяти, этот протокол прозрачен, кэши прозрачны.
[35:25.480 --> 35:33.680]  Можно о них не думать. Проблему создают только StoreBuffer. Вот, но это очень простая операционная
[35:33.680 --> 35:40.840]  модель. Потому что сам по себе процессор Intel дает довольно сильные гарантии на упорядочивание.
[35:40.840 --> 35:49.640]  Но вот с ARM не так, с ARM сложнее, и модель памяти у ARM операционная совсем другая. Нам говорят,
[35:49.640 --> 35:54.360]  что как будто вот представьте себе, что вот ядра вашего процессора организованы в некоторую
[35:54.360 --> 36:00.600]  иерархию, в некоторое дерево. В корне этого дерева, ну вот внизу на картинке лежит память. В листьях
[36:00.600 --> 36:08.640]  находится вот ядра с кэшами. И когда мы пишем что-то, то мы отправляем запись по этой иерархии вверх
[36:08.640 --> 36:15.240]  плыть, ну или вниз по картинке. Вот она стекает вниз до корня. Когда мы читаем что-то, мы тоже
[36:15.240 --> 36:24.120]  отправляем чтение, и оно пытается достичь корня, ну либо встречает по пути другую запись. И вот
[36:24.120 --> 36:33.040]  можно этот пример с записями и чтениями разобрать вот так, чтобы здесь получилось 1.0. Как это может
[36:33.040 --> 36:41.040]  получиться? Мы делаем запись на первом ядре, и она попадает сюда, вот в этот перекресток. Потом мы
[36:41.040 --> 36:48.880]  делаем чтение на втором ядре, оно отправляется отсюда, встречает запись, читает единицу. Отлично.
[36:48.880 --> 36:55.760]  Потом мы пишем что-то в Y, пишем эту самую единицу, которую мы прочли. Она отправляется отсюда. И вот
[36:55.760 --> 37:05.320]  теперь здесь лежат и запись X, и запись Y. А потом мы с этого ядра читаем Y. Ну так получилось, что Y
[37:05.320 --> 37:14.200]  долез до корня, спустился до корня раньше, чем запись X. И вот чтение Y увидело единицу, а
[37:14.200 --> 37:22.760]  чтение X не увидело, потому что запись X находится все еще здесь. Ну разумеется, не то чтобы прямо по...
[37:22.760 --> 37:30.920]  это некоторая модель, она упрощает работу реального процессора. Но вот эта модель порождает те же самые
[37:30.920 --> 37:37.480]  исполнения, те же самые результаты, которые порождает настоящий процессор. И вот эти модели, они сильно
[37:37.480 --> 37:48.280]  отличаются для Intel и для ARM. И в этом их проблема. Эти модели свои для каждого процессора, просто
[37:48.280 --> 37:55.120]  исторически. Кроме того, вряд ли они нам бы пригодились для повседневного использования,
[37:55.120 --> 38:00.360]  потому что они очень неинтуитивны, они порождают сложные исполнения, которые мы бы не хотели в
[38:00.360 --> 38:06.280]  своих программах иметь. Так что если мы говорим про язык программирования, то операционный подход
[38:06.280 --> 38:14.440]  нам вряд ли подойдет. Мы будем использовать другой подход, декларативный, который говорит не про то,
[38:14.440 --> 38:19.840]  как программа исполняется, не про то, какие там возникают реордеринги, какие там есть store
[38:19.840 --> 38:27.800]  buffer в процессоре. Декларативный подход говорит про порядки, про то, что хорошего в исполнении есть,
[38:27.800 --> 38:35.520]  про гарантии, которые там точно соблюдаются. И вот этот подход, он на самом деле гораздо интуитивнее.
[38:35.880 --> 38:44.880]  На практике нет. Мы сталкиваемся с некоторым сопротивлением ему. Но на самом деле,
[38:44.880 --> 38:48.880]  если вы разберетесь, преодолете это сопротивление, то вы увидите, что этот подход гораздо естественнее,
[38:48.880 --> 38:55.600]  но он выизвучивает естественно. Порядки – это положительные гарантии. В декларативном подходе мы
[38:55.600 --> 39:04.480]  не думаем, как программа исполняется. Мы исполнение представляем себе в виде графа. Вот нужно сразу это
[39:04.480 --> 39:11.920]  зафиксировать в себе уме. Исполнение – это граф. Его вершины – это обращение к памяти. Его дуги – это
[39:11.920 --> 39:18.560]  те частичные порядки, которые в исполнении возникают. Вот те самые гарантии, которые были,
[39:18.560 --> 39:29.840]  все упорядочивания, отношения, про которые здесь идет речь. Вот исполнение – это граф.
[39:29.840 --> 39:39.440]  Дуги – это порядки. И чтобы вы мне поверили, исполнение в модели памяти C++ образовано вот
[39:39.440 --> 39:47.200]  такими вот отношениями и порядками. Многопоточное исполнение программы в C++ – это совокупность
[39:47.200 --> 39:54.280]  таких частичных порядков. Это не один поток сделал что-то, а потом другой поток сделал что-то. Это
[39:54.440 --> 40:02.960]  граф. Звучит сложно, но так и должно быть. И более того, сложность появляется еще из-за того,
[40:02.960 --> 40:13.600]  что большая часть языка использует операционную семантику. Вот вам стандарт описывает, как
[40:13.600 --> 40:18.840]  программа исполняется. Вот некоторые машины абстрактные. А потом внезапно для некоторой
[40:18.840 --> 40:23.200]  части языка, для многопоточных программ. Стиль изложения семантики резко меняется,
[40:23.200 --> 40:33.880]  и мы теперь говорим про графы, а не про абстрактные машины. Вот ровно поэтому изучать модели памяти
[40:33.880 --> 40:40.840]  сложно. Они непривычны, они не вписываются в то, как мы думаем про исполнение. Но ничего не
[40:40.840 --> 40:47.840]  поделать. Такова жизнь, она вот видите сложная, то есть программы исполняются сложным на реальном
[40:47.840 --> 40:55.840]  железе и описываются, исполнять их программ тоже сложно. Но если вы откроете модели памяти для
[40:55.840 --> 41:01.920]  любого современного языка, то то, что вы там увидите будет гораздо проще выглядеть. Что вы
[41:01.920 --> 41:09.360]  там увидите? Вы увидите следующее, что исполнение, какую гарантию вам дает модель памяти языка чаще
[41:09.360 --> 41:14.360]  всего. Оно вам не говорит, что вот графы сразу, там какие-нибудь порядки, риордеринги,
[41:14.360 --> 41:20.600]  стурбафер нет. Вам говорят, что исполнение программы неотличимо от некоторого последовательного
[41:20.600 --> 41:25.920]  исполнения, в котором обращение к памяти из каждого потока выполняются в порядке их следования
[41:25.920 --> 41:35.720]  в тексте программы. То есть вам говорят, модель чередования. Лесли Лэмпорт, вы его наблюдаете,
[41:35.720 --> 41:41.000]  потому что это ему именно принадлежит термин sequential consistency. Вот это определение,
[41:41.000 --> 41:48.120]  определение sequential consistency. Прокомментирую это определение. Что значит исполнение программы
[41:48.120 --> 41:59.360]  неотличимо от некоторого последовательного? Это означает, что он наблюдает результаты
[41:59.880 --> 42:06.480]  и только по ним может косвенно судить о порядке. Так вот, неотличимо означает следующее,
[42:06.480 --> 42:11.840]  что чтение в исполнении увидит те же значения, что и при некотором последовательном исполнении.
[42:11.840 --> 42:19.120]  При этом это не означает, что язык программирования обещает вам исполнять программу
[42:19.120 --> 42:24.600]  последовательно. Нет, он наоборот этого не хочет, но хочет, чтобы у вас была простая модель
[42:24.600 --> 42:31.200]  чередования в голове. Собственно, я вам показывал это выше, когда говорил про не умничайте. Вот,
[42:31.200 --> 42:35.920]  модель памяти C++ вам это и сообщает, что если вы используете просто mutex и memory order
[42:35.920 --> 42:44.160]  sequential consistency, то вы получаете модель чередования. Вот ровно то, что нам говорит Лесли Лэмпорт.
[42:44.160 --> 42:52.440]  Но беда в том, что компьютеры так не работают. Поэтому возникает разумный вопрос, а как же
[42:52.480 --> 43:00.040]  согласовать не sequential и consistent компьютеры, процессоры, и sequential и consistent модель памяти?
[43:00.040 --> 43:11.320]  И для того, чтобы можно было получить сильные гарантии на процессоре со слабыми гарантиями,
[43:11.320 --> 43:17.160]  процессор вам выдает специальные инструкции, которые называются memory barriers или memory fences,
[43:17.160 --> 43:25.200]  барьеры памяти. У каждого процессора они свои, но суть их примерно одинаковая. Если очень грубо
[43:25.200 --> 43:32.800]  говорить, то барьеры запрещают некоторые типы орденгов. Реальность сильно сложнее. Семантика
[43:32.800 --> 43:42.760]  барьеров специфична для процессора, и нужно читать конкретные мануалы. Ну вот, скажем, на x86
[43:42.760 --> 43:48.840]  барьер памяти — это mfence. Вот мы компилируем такую программу, компилируем ее там на GCC в какой-то
[43:48.840 --> 43:56.560]  версии, получаем запись move для записи, потом mfence, потом move для чтения. И вот этот mfence,
[43:56.560 --> 44:04.400]  он запрещает реордерить условно две инструкции. Ну, фактически он сбрасывает storebuffer в память,
[44:04.400 --> 44:14.160]  в киши, в протокол к гириантности. В общем случае рассуждать про барьеры памяти сложно. В линуксе
[44:14.160 --> 44:27.520]  есть отличная документация про барьеры памяти, она вот тоже гигантская. Тут еще много графики. В общем,
[44:27.520 --> 44:33.080]  это сложно. Это сложно, причем сами разработчики хедра этого не отрицают, потому что они пишут,
[44:33.080 --> 44:48.480]  что вот этой инструкцией можно пугать детей. Ну, хорошо. Может быть, по-другому скажу. Барьеры
[44:48.480 --> 44:55.560]  памяти есть, они действительно сложны. И в конце концов, с помощью барьеров памяти, язык
[44:55.560 --> 45:01.340]  программирования, компилятор собирается обеспечить нам вот такую гарантию sequential
[45:01.340 --> 45:08.860]  consistency на не sequentially consistent процессоре. Но возникает вопрос, а как именно он,
[45:08.860 --> 45:15.680]  собственно, эту гарантию собирается обеспечить? Компилятор. Потому что, если он просто будет
[45:15.680 --> 45:23.500]  расставлять барьеры повсюду, то он слишком сильно замедлит нашу программу. Он должен действовать
[45:23.500 --> 45:30.860]  как-то умнее. И вот здесь возникает главный трейдов в моделях памяти. Смотрите, чего мы хотим.
[45:30.860 --> 45:37.940]  С одной стороны, мы хотим иметь очень простую семантику для программ многопоточных, sequential
[45:37.940 --> 45:44.700]  consistency, исполнение неотличимо от последовательного. Но мы при этом также хотим, чтобы программа
[45:44.700 --> 45:50.900]  исполнялась быстро. То есть, чтобы и процессор реордерил инструкции, и компилятор что-то переставлял
[45:50.900 --> 45:56.700]  при компиляции. И вот эти цели, они выглядят плохо совместимыми, они противоположны и просто.
[45:56.700 --> 46:06.260]  Простая семантика – это отсутствие реордерингов. Оптимизация – это реордеринги. Вот. И возникает
[46:06.260 --> 46:10.780]  потребность чем-то пожертвовать, потому что цели, ну, вот, противоположны. И вопрос, вот чем мы
[46:10.780 --> 46:18.940]  собираемся жертвовать? Либо семантикой простой, либо оптимизациями. Ну, ответ, на самом деле,
[46:18.940 --> 46:24.940]  хитрее. Он называется sequential consistency для datarace-free programs, для программ свободных отгонок,
[46:24.940 --> 46:33.980]  и в этой модели мы собираемся жертвовать не оптимизациями и не простой семантикой,
[46:33.980 --> 46:40.540]  мы собираемся жертвовать программами. Мы говорим, что очень накладно гарантировать sequential
[46:40.540 --> 46:46.580]  consistency для любой программы, которую можно написать. Мы будем гарантировать sequential
[46:46.580 --> 46:52.860]  consistency только для разумных программ. Программ, в которых написана корректная синхронизация.
[46:52.860 --> 46:58.980]  Ну, это пока неформально очень, непонятно, что значит корректная. Вот, формальное определение
[46:58.980 --> 47:07.460]  у нас будет звучать так. Корректная программа – программа без гонок, без dataraces. Ну, вот,
[47:07.460 --> 47:13.220]  чтобы определить datarace, нужно будет приложить усилия еще. Ну, вот, интуиция за вот таким вот
[47:13.220 --> 47:21.980]  ограничением, за сужением класса программ. Вот, оказывается, что корректно синхронизированные
[47:21.980 --> 47:28.860]  программы, в них есть некоторые паттерны. Обращение с памятью. И эти паттерны устроены так,
[47:28.860 --> 47:38.620]  что если компилятор с помощью разработчика про них узнает, то он сможет расставить в программе
[47:38.620 --> 47:46.780]  довольно небольшое количество барьеров. И, с одной стороны, программист получит простую семантику,
[47:46.780 --> 47:55.900]  а, с другой стороны, у процессора останется возможность ордерить инструкции. Просто за счет
[47:55.900 --> 48:03.140]  того, что мы ограничили класс программ. Вот, значит, гарантия модели памяти,
[48:03.140 --> 48:07.780]  которая называется sequential consistency для программ свободных отгонок. Если в программе нет гонок,
[48:07.780 --> 48:16.340]  то она допускает только последовательно согласованные исполнения. Вот это наша цель.
[48:16.340 --> 48:23.140]  И вот такова гарантия модели памяти любого современного языка. Java, Go, C++, что угодно.
[48:23.140 --> 48:31.460]  Правда, пока мы не можем определить гонку, мы пока скажем не строго, что гонку образуют два
[48:31.460 --> 48:36.380]  неупорядочных синхронизации обращения к ячейке памяти, среди которых, по крайней мере, одно
[48:36.380 --> 48:47.740]  обращение — это запись. Ну и, на всякий случай, вот подтверждение того, что C++ ровно это вам
[48:47.740 --> 48:54.260]  обещает. Он говорит, что если вы используете Mutex и Atomic с дефолтным Memory Order, то вы получаете
[48:54.260 --> 49:00.700]  sequential consistency, то есть простой интерливинг потоков, но только если в вашей программе нет гонок.
[49:00.700 --> 49:12.900]  Это важно. То есть вы, как бы, реализуя синхронизацию, на самом деле заключаете
[49:12.900 --> 49:20.380]  некоторый контракт с компилятором и процессором. Вот вы обещаете компилятору написать корректно
[49:20.380 --> 49:28.100]  синхронизированный код. А компилятор и процессор обязуются выполнить, со своей стороны обязуются
[49:28.100 --> 49:34.420]  выполнить ваш корректный код таким образом, что вы не заметите никаких риордрингов в компиляторе
[49:34.420 --> 49:41.220]  и в процессоре, собственно. И вот это соглашение между вами и компилятором и процессором фиксируется
[49:41.220 --> 49:52.420]  в стандарте языка. Вот оно. Но если вдруг вы свою сторону контракта нарушите, свое обещание нарушите,
[49:52.420 --> 50:01.820]  то во время исполнения никто ничего проверять не будет. Если у вас есть датарейсы, то вы лишаетесь
[50:01.820 --> 50:09.340]  всех гарантий, вы получаете уб. Ну это довольно разумно. Undefined Behaviour — это вот такая
[50:09.340 --> 50:18.020]  оптимизация для компилятора, которая позволяет ему не делать все возможные проверки. Все-таки
[50:18.020 --> 50:24.140]  что-то компилятор не проверяет, значит, на это работает программа быстрее. Ну вот здесь компилятор
[50:24.140 --> 50:29.620]  не будет проверять, что... компилятор не будет гениливать проверки, которые убеждаются, что
[50:29.620 --> 50:36.580]  действительно вы пишете корректно синхронизированный код. Ну а что значит УБЭА? Что же на самом деле
[50:36.580 --> 50:43.500]  произойдет? Ну, в принципе, по стандарту непонятно, что произойдет. А в реальности произойдет то,
[50:43.500 --> 50:49.980]  что вы станете наблюдать риордерники, которые возникают в процессоре. Ну то есть вы потеряете
[50:49.980 --> 50:56.980]  гарантию и будете наблюдать, скажем, два нуля в программе. Собственно, я показывал вам этот
[50:56.980 --> 51:05.340]  пример. Мы пишем программу на C++, пишем там две чеки памяти, пишем в одну читаемую с другой. И вот
[51:05.340 --> 51:12.340]  очевидно, в этой программе есть датарейсы. Вот эта запись гоняется с этим чтением. И вот мы запускаем
[51:12.340 --> 51:25.140]  эту программу и в ней undefined behavior, в ней датарейсы. Ну и что же происходит? Рано или поздно эта
[51:25.140 --> 51:30.340]  программа ломается, потому что она порождает два нуля. Ну то есть мы потеряли разумную гарантию,
[51:30.340 --> 51:36.380]  мы потеряли модель переключений, модель чередования. Вот УБЭА примерно в этом состоит.
[51:36.380 --> 51:49.100]  Ну что ж, давайте теперь поговорим. Все оставшееся время мы будем говорить о том,
[51:49.100 --> 52:02.700]  как вот эту гарантию обеспечить. Это и есть наша сегодняшняя цель. Есть вопросы пока? Все понятно.
[52:02.700 --> 52:09.700]  Ну хорошо. Как устроена такая модель памяти? Ну давайте сначала перечислим всех действующих
[52:09.700 --> 52:15.740]  лиц. Вот кто участвует во всем этом процессе. Смотрите, у нас есть, во-первых, разработчик,
[52:15.740 --> 52:22.900]  во-вторых, процессор, а в-третьих, между ними есть модель памяти, ну вот компилятор, разработчик
[52:22.900 --> 52:32.300]  модели памяти, разработчик языка. И вот вы разработчик языка и с одной стороны вы от процессора
[52:32.460 --> 52:40.140]  получаете через какие-то мануалы операционную модель памяти, то есть риордеринги, которые процессор
[52:40.140 --> 52:47.940]  может выполнять, барьеры, которые можно в этом процессоре вставить. А с другой стороны вы от
[52:47.940 --> 52:55.380]  программиста, который пишет код, получаете некоторые ожидания, на какие гарантии в своей
[52:55.380 --> 53:03.700]  программе он все-таки хочет рассчитывать. Ну скажем, он ожидает, что если он сделал запись в ячейку памяти
[53:03.700 --> 53:08.580]  в критической секции, то он потом в следующей секции эту запись увидит. Довольно разумное
[53:08.580 --> 53:15.780]  требование. И вот мы от программистов получаем требования от модели памяти, от процессоров,
[53:15.780 --> 53:21.500]  от инженеров, которые строят процессоры, мы получаем, как бы, описание реальности. Какие
[53:21.500 --> 53:28.780]  риордеринги есть, какие барьеры есть. А дальше мы выдаем программисту какие-то декларативные
[53:28.780 --> 53:36.620]  гарантии в собственном модели памяти, то есть некоторые гарантии видимости, выраженные через
[53:36.620 --> 53:44.780]  частичные порядки. На что в исполнении программы программист может полагаться в виде стандарта
[53:44.780 --> 53:57.020]  языка. А в сторону компилятора мы отправляем, не так, а через компилятор мы, разработчики
[53:57.020 --> 54:04.140]  языкопрограммирования, эти гарантии реализуем на конкретных процессорах. То есть мы пишем компилятор
[54:04.140 --> 54:10.460]  для данного процессора, который вот эти декларативные гарантии реализуют через барьеры.
[54:10.460 --> 54:27.500]  Хорошо. Что же мы будем делать сегодня? Мы будем придумывать вот такие гарантии. Вот мы подумаем
[54:27.500 --> 54:34.380]  про наши программы, подумаем про код, который мы пишем, и попытаемся из этих программ извлечь
[54:34.380 --> 54:41.460]  некоторые паттерны, некоторые гарантии, которые мы там может быть неявно ожидаем при исполнении
[54:41.460 --> 54:49.420]  программы. И эти гарантии должны быть сформулированы, должны быть формулизованы в виде частичных
[54:49.420 --> 54:55.780]  порядков на обращениях к памяти, в виде частичных порядков, которые будут ограничивать чтение. Ну,
[54:55.780 --> 55:02.780]  то есть мы потребуем, чтобы чтение в программе были согласованы с этими порядками. То есть,
[55:02.780 --> 55:09.260]  если в программе реализовался некоторый порядок частичный, в нашем уме как бы реализовался,
[55:09.260 --> 55:16.980]  то чтение не может пойти с ним в разрез. Ну, а дальше мы потребуем, чтобы компилятор каким-то
[55:16.980 --> 55:22.100]  образом эти гарантии, которые мы придумаем, обеспечил на процессоре с помощью барьеров.
[55:22.100 --> 55:29.580]  Конечно, непонятно, почему у него это получится сделать, но я в конце смогу объяснить, наверное,
[55:29.580 --> 55:38.260]  интуитивно, почему получится. Ну и смотрите, какие цели мы будем преследовать, выдумывая гарантии.
[55:38.260 --> 55:46.140]  С одной стороны, мы должны придумать такие требования, такие частичные порядки, чтобы
[55:46.140 --> 55:53.580]  их было достаточно, чтобы они в совокупности давали видимость прямо последовательного исполнения.
[55:54.180 --> 56:01.860]  Но с другой стороны, чем меньше стрелок в графе исполнения мы нарисуем,
[56:01.860 --> 56:14.100]  чем меньше стрелок, которые будут фиксировать порядки между обращениями памяти, мы вставим
[56:14.100 --> 56:19.500]  в исполнение, тем интуитивно больше реордерингов мы дадим процессору при исполнении.
[56:19.500 --> 56:30.060]  Ну и где-то во всем этом процессе придумывания таких гарантий, таких порядков, мы должны
[56:30.060 --> 56:36.580]  воспользоваться тем, что мы ограничили себя только программами свободными от гонок.
[56:36.580 --> 56:47.740]  Ну что ж, теперь можно начать. Если все вступление длинное понятно,
[56:47.980 --> 56:54.540]  что мы хотим сделать, то можно переходить к сути, а именно вот к выдумыванию таких гарантий.
[56:54.540 --> 57:02.460]  Мы сегодня будем эти гарантии иллюстрировать на двух примерах, на моделях памяти двух языков,
[57:02.460 --> 57:12.180]  C++ и Java. Они во многом похожи. На всякий случай и та, и другая модель памяти сложнее, чем то,
[57:12.180 --> 57:19.380]  что будет изложено сегодня. Сегодня будет такой общий знаменатель, но при этом я вас не обману.
[57:19.380 --> 57:28.620]  Это общая идея, она реализуется и в одном, и в другом языке. Ну а может быть, я сейчас кого-то
[57:28.620 --> 57:35.100]  разочарую, но вот сегодня мы говорим только про Memory Order of Sequential Consistency. Нам бы с ним
[57:35.100 --> 57:41.900]  разобраться. Более слабые Memory Order мы пока отложим, но в конце лекции я объясню,
[57:41.900 --> 57:49.220]  как они устроены. Вот буквально за один слайд. Но почти все время я буду говорить только про
[57:49.220 --> 58:00.020]  дефолтный Memory Order. Итак, как для нас разработчиков модели памяти выглядит программа? Программа
[58:00.020 --> 58:06.020]  оперирует разделяемыми ячейками памяти. Ну и в программе есть некоторый поток управления,
[58:06.020 --> 58:15.300]  циклы, условия и так далее. Мы пока игнорируем запуск join потоков, примитивы синхронизации,
[58:15.300 --> 58:22.100]  какие-то сложные атомарные операции. В C++ еще есть отдельные операции барьеры. То есть мы это все
[58:22.100 --> 58:29.420]  учтем в модели памяти, но потом, когда будет для этого возможность. Пока думаем только про самые
[58:29.420 --> 58:39.460]  простые программы. И в этих программах многопоточных потоки обращаются к разделяемым
[58:39.460 --> 58:51.260]  ячейкам памяти. И эти обращения иногда конфликтуют. Мы скажем, что два обращения к памяти конфликтуют,
[58:51.260 --> 58:58.860]  если они обращаются к одной ячейке памяти и, по крайней мере, одно из этих обращений — это
[58:58.860 --> 59:05.420]  запись. То есть конфликтует запись и запись, конфликтует запись и чтение, чтение и чтение не
[59:05.420 --> 59:12.340]  конфликтует. Ну и вот примеры определения конфликтов в двух моделях памяти — в C++ и в Java. Конфликт
[59:12.340 --> 59:19.220]  довольно фундаментальное понятие для всех моделей памяти. А дальше на основе понятия конфликта мы
[59:19.220 --> 59:29.460]  разделим ячейки в корректно синхронизированных программах на два класса. Есть разделяемые ячейки,
[59:29.460 --> 59:39.140]  которые используются для синхронизации. Ну скажем, ячейка locked спинлоки. Вот конфликтующие обращения
[59:39.140 --> 59:45.220]  к ней в программе не упорядочены. Ну естественно, потому что мы с помощью нее и упорядочиваем
[59:45.220 --> 59:52.220]  остальные обращения. А вот если мы посмотрим, скажем, на какую-нибудь ячейку памяти в, там,
[59:52.220 --> 59:59.100]  я не знаю, в односвязном списке, который мы защищаем спинлоком, то конфликтующие обращения
[59:59.100 --> 01:00:03.740]  на вот голове этого списка, они уже будут упорядочены. Будут упорядочены самим спинлоком.
[01:00:03.740 --> 01:00:28.180]  Идея понятна? Как мы разделяем два типа ячеек? Вот. Нет. Ну смотри, у тебя поток сначала пишет,
[01:00:28.180 --> 01:00:32.180]  а потом читает. Два этих обращения не конфликтует, но не упорядочены самим потоком.
[01:00:32.180 --> 01:00:41.220]  Ты взял Mutex, записал в ячейку X, потом ты взял Mutex, прочитал из ячейки X. Запись в X и
[01:00:41.220 --> 01:00:50.660]  чтение из X конфликтует, но гонки нет, потому что они упорядочены Mutex. Да? Вот, собственно,
[01:00:50.660 --> 01:01:00.340]  в этом и разница. Вот флажок locked в спинлоке к нему обращаются неупорядоченно, а к ячейке,
[01:01:00.340 --> 01:01:09.620]  которая защищена спинлоком, обращаются уже упорядочно. И смотрите, мы поделим все разделяемые
[01:01:09.620 --> 01:01:17.140]  ячейки в программе на два класса, и ячейки первого класса, которые используются для синхронизации,
[01:01:17.140 --> 01:01:25.420]  мы явно в программе аннотируем. Мы скажем, что это не просто Bool или Int, это Atomic Bool или Atomic Int.
[01:01:25.420 --> 01:01:36.740]  В компьютере и Atomic Bool и Bool представляются одинаково, одним машинным словом. Но вот нам
[01:01:36.740 --> 01:01:43.180]  такая аннотация нужна, тем не менее. Если говорить про Java, то вот такие Atomic в Java выглядит
[01:01:43.180 --> 01:01:51.300]  как Volatile. Но, пожалуйста, в C++ у Volatile такой семантики нет. В C++ у Volatile уже практически
[01:01:51.300 --> 01:01:57.020]  не нужен. Вам в Volatile он не нужен почти что. Concurrency он не имеет никакого отношения в C++,
[01:01:57.020 --> 01:02:06.020]  а в Java это синоним Atomic. Зачем нам нужно явно аннотировать вот такие вот ячейки памяти,
[01:02:06.020 --> 01:02:15.540]  для которых конфликтующие обращения неупорядочены? Спойлер, именно вокруг этих
[01:02:15.540 --> 01:02:21.780]  Atomic компилятор и собирается ставить барьеры. Вот еще раз наша цель – ставить в программе как
[01:02:21.780 --> 01:02:32.900]  можно меньше барьеров. Вот барьеры будут только рядом с Atomic. Ну а теперь давайте выдумывать
[01:02:32.900 --> 01:02:40.180]  требования, гарантии, частичные порядки, которые мы ожидаем от ячеек памяти в исполнении,
[01:02:40.180 --> 01:02:47.300]  от исполнения. Гарантии будет три у нас. Вот мы делаем первый шаг, первую гарантию,
[01:02:47.300 --> 01:02:53.940]  придумываем первый порядок. Итак, смотрим на ячейку памяти. Я сказал, что она устроена
[01:02:53.940 --> 01:03:00.340]  сложнее, чем мы думаем. У ячейки памяти логической может быть несколько физических воплощений,
[01:03:00.340 --> 01:03:08.060]  одно воплощение в памяти, непосредственно другие в кышах. И вот мы пишем тест. У нас много ядер,
[01:03:08.060 --> 01:03:15.200]  каждый ядро пишет сначала в ячейку памяти свое значение, а потом эти значения читает.
[01:03:15.200 --> 01:03:22.060]  Потом значения читает в цикле. И вот какие значения мы наблюдаем. С одной стороны, довольно
[01:03:22.060 --> 01:03:27.540]  сложно, потому что один поток, одно ядро думает, что в ячейке 2, а другой думает,
[01:03:27.540 --> 01:03:33.460]  что 3, а другой думает, что 10, а другой думает, что 9, и другой думает, что 12. Но все же картинка
[01:03:33.460 --> 01:03:41.700]  не совсем произвольная. Ну вот можно заметить, что, смотрите, тут есть такие пары, да? Откуда
[01:03:41.700 --> 01:03:49.260]  эти пары берутся, понимаете вы или нет? Ну вот это соседний ядра с общим буфером, вероятно. А
[01:03:49.260 --> 01:03:58.180]  еще в этой картинке есть некоторая структура, некоторая гарантия в ней видна сразу. Можете ли
[01:03:58.180 --> 01:04:03.260]  вы ее обнаружить? Ну то есть, смотрите, каждое ядро читает какую-то свою историю изменения,
[01:04:03.260 --> 01:04:11.980]  но эти истории, они в некотором смысле согласованы. Но в конце мы приходим к одному значению,
[01:04:11.980 --> 01:04:26.940]  но это еще не все. Вот смотрите, чего мы ожидаем? Мы ожидаем на самом деле, что на каждом отдельном
[01:04:26.940 --> 01:04:35.900]  атомике есть некоторый сквозной порядок модификаций. У каждого атомика есть история изменений,
[01:04:35.900 --> 01:04:43.020]  и каждый поток читает некоторую монотонную подысторию этой одной сквозной истории. Понятно?
[01:04:43.020 --> 01:04:54.220]  Вот эту историю записей в пределах каждого отдельного внимания атомика мы назовем
[01:04:54.220 --> 01:04:59.940]  modification order. Это первый частичный порядок, который возникает в исполнении для нас.
[01:04:59.940 --> 01:05:08.100]  Вот мы хотим придумывать гарантии частичных порядков. Давайте я к этому вернусь. Вот,
[01:05:08.100 --> 01:05:16.740]  и первый из них это modification order. Но внимание, modification order не означает, что есть какой-то
[01:05:16.740 --> 01:05:25.980]  сквозной порядок на разных атомиках. Вот, скажем, modification order не противоречит примеру store
[01:05:25.980 --> 01:05:35.780]  buffering, где мы читали два нуля. В примере store buffering мы пишем в X, читаем из Y, пишем в Y,
[01:05:35.780 --> 01:05:45.340]  читаем из X, получаем два нуля. У каждой ячейки есть modification order. Правда, не атомики. Смотрите,
[01:05:45.340 --> 01:05:50.500]  тут сложно проиллюстрировать на программе, потому что мы пока говорим про такой C++,
[01:05:50.500 --> 01:05:58.220]  который мы строим сами. Но вот store buffering в этот пример не противоречит modification order.
[01:05:58.220 --> 01:06:05.820]  В store buffering у атомика сначала было значение ноль, потом стало единица. И каждый поток прочел ноль.
[01:06:05.820 --> 01:06:13.740]  Это подыстория истории ноль и единица. Так что modification order — это sequentially consistent ячейка
[01:06:13.740 --> 01:06:20.020]  памяти, но совокупность атомиков sequentially consistent уже не будет. Это понятно?
[01:06:25.820 --> 01:06:33.540]  Понятно? Да. Хорошо, давайте сделаем перерыв сейчас. Мы простую часть закончили, а дальше будет уже
[01:06:33.540 --> 01:06:41.940]  чуть сложнее. Встретимся через 10 минут. Ну что, мы продолжаем. И, кажется, у нас есть какие-то
[01:06:41.940 --> 01:06:54.980]  вопросы в перерыве были, да, у кого-то? Нет? Вопрос откатили? Ну что ж, обидно. Тогда,
[01:06:54.980 --> 01:07:03.260]  ещё раз, на чем мы остановились? Мы готовим модель памяти. Мы хотим получить вот такую гарантию,
[01:07:03.260 --> 01:07:10.740]  что если в программе нет гонок, то она допускает только последовательно согласованные исполнения,
[01:07:10.740 --> 01:07:20.100]  то есть ее исполнение неотличимо от некоторого последовательного. И мы эту гарантию хотим
[01:07:20.100 --> 01:07:27.540]  обеспечить, выдумав какое-то количество частичных порядков, которые будут ограничивать допустимые
[01:07:27.540 --> 01:07:33.500]  чтения в программе. Вот модель памяти должна отвечать на вопрос, что увидит каждое чтение.
[01:07:33.500 --> 01:07:40.620]  Вот мы с помощью частичных порядков ограничиваем, что может увидеть каждое чтение. И мы
[01:07:40.620 --> 01:07:45.340]  вот придумали первое ограничение. Да, и вот эти ограничения должны быть такими, что с одной
[01:07:45.340 --> 01:07:51.140]  стороны, они в сумме, в совокупности должны нам дать вот эту простую семантику последовательного
[01:07:51.140 --> 01:07:56.180]  исполнения, а с другой стороны, они должны быть все-таки частичными, чтобы допустить какие-то
[01:07:56.180 --> 01:08:03.340]  реордеринги во время исполнения. И вот первое. Мы дали понятие конфликта, разделили чеки на два
[01:08:03.340 --> 01:08:08.220]  класса, сказали, что вот есть атомики, и первая гарантия, первый частичный порядок, он был на
[01:08:08.220 --> 01:08:17.100]  записях в каждый отдельный атомик. Мы сказали, что у каждого отдельного атомика есть история
[01:08:17.100 --> 01:08:23.100]  записей, и что все потоки наблюдают некоторые подысторию этой записи. И тут отмечено, что вот
[01:08:23.100 --> 01:08:28.380]  каждый атомик – это sequential и consistent ячейка в памяти, в том смысле, что modification order – он,
[01:08:28.380 --> 01:08:34.780]  конечно же, уважает порядок записи в атомик из каждого отдельного потока. То есть, если поток
[01:08:34.780 --> 01:08:39.140]  пишет один раз, потом другой раз, то, конечно же, в modification order эти записи будут идти именно в
[01:08:39.140 --> 01:08:44.100]  таком порядке. Вот. И все это вместе, при этом, не складывается в некоторый глобальный порядок,
[01:08:44.100 --> 01:08:55.420]  это важно. Ну вот такое ожидание, оно довольно естественное. Вот почему мы можем такие картинки
[01:08:55.420 --> 01:09:00.420]  наблюдать? Потому что store buffer есть. Но с другой стороны, store buffer сами по себе вот такую
[01:09:00.420 --> 01:09:06.780]  гарантию не ломают. Так что она довольно естественная. Довольно естественно ее потребовать,
[01:09:06.780 --> 01:09:14.220]  потому что процессоры ее, вот, очевидно, будут соблюдать так, уж они устроены. Следующая гарантия,
[01:09:14.220 --> 01:09:22.620]  ну, вернее, ожидание. Вот посмотрим на псевдокод. Тут есть поток T и T', producer и consumer. И что
[01:09:22.620 --> 01:09:29.860]  делает producer? Он пишет в некоторый буфер какие-то данные, там, неатомарные. А потом ставит флажок.
[01:09:29.860 --> 01:09:39.860]  Что вот данные готовы. Consumer читает этот флажок, и если он видит, что в этом флажке написано true,
[01:09:39.860 --> 01:09:46.620]  то он читает из буфера. И, конечно же, когда мы смотрим на такой код, то очень естественно ожидать,
[01:09:46.620 --> 01:09:55.300]  что чтение из буфера в потоке T', непременно увидит запись в буфер, сделанный в потоке T'.
[01:09:55.300 --> 01:10:03.380]  Почему мы этого ожидаем? Ну, смотрите, вот мы читаем из буфера. Как мы вообще до этого дошли?
[01:10:03.380 --> 01:10:10.980]  Видимо, мы перед этим прочли значение из флажка и прошли там true. А почему мы там прочли true? Откуда
[01:10:10.980 --> 01:10:17.700]  там взялась эта true? Ну, видимо, здесь другой поток T' записал вот этот флажок что-то. Но,
[01:10:17.700 --> 01:10:23.460]  судя по коду, перед тем, как он записал флажок, поток T' должен был записать в буфер.
[01:10:23.460 --> 01:10:31.660]  И вот такими рассуждениями мы приходим к выводу о том, что, видимо, запись в буфер
[01:10:31.660 --> 01:10:44.340]  предшествовала чтению из буфера. Произошла до чтения из буфера. Разумное ожидание. Но оно выглядит
[01:10:44.340 --> 01:10:48.420]  совершенно тривиально, но, с другой стороны, мы выяснили, что даже самых простых вещей ожидать
[01:10:48.420 --> 01:10:54.980]  не стоит просто так. Так что мы должны каким-то образом... Ну, то есть что мы хотим сейчас? Мы
[01:10:54.980 --> 01:11:04.060]  хотим вот это ожидание как-то формализовать. Ну, сейчас давайте к этому придем. Где такой паттерн
[01:11:04.060 --> 01:11:08.380]  реализуется? Вот в прошлый раз мы смотрели на циклический буфер для двух потоков. Одного
[01:11:08.380 --> 01:11:15.420]  продюсера, одного консюмера. И вот один поток писал в буфер и двигал вперед tail. Другой поток
[01:11:15.420 --> 01:11:25.740]  читал head и tail. И если видел, что tail впереди head, очередь не пустая, то читал из head. Ну вот,
[01:11:25.740 --> 01:11:33.740]  это ровно такой сценарий. Если мы дошли сюда и читаем из слота 42, потому что мы увидели tail,
[01:11:33.740 --> 01:11:40.740]  по крайней мере, 43, то, видимо, мы уверены, что другой поток, продюсер, уже в слот 42 что-то
[01:11:40.740 --> 01:11:49.620]  написал. Вот такой сценарий, который мы назовем message pressing. Передача сообщения. Ну вот,
[01:11:49.620 --> 01:11:56.660]  здесь он как бы совсем в лоб выражен. Но, скажем, вот посмотрите на spin lock. Видите ли вы message
[01:11:56.660 --> 01:12:13.500]  pressing в spin lock? Смотри, у нас message pressing про неатомарные обращения к памяти. Вот неатомарные
[01:12:13.500 --> 01:12:20.140]  обращения к памяти, вот неатомарные. А где здесь неатомарные обращения к памяти? Ну вот да,
[01:12:20.140 --> 01:12:27.220]  смотрите, мы читаем что-то под spin lock. Ну вот мы, не знаю, берем spin lock и видим, что у нас буфер,
[01:12:27.220 --> 01:12:35.140]  не знаю, какой-нибудь список не пуст. Что это означает? Видимо, мы ожидаем, что другой поток
[01:12:35.140 --> 01:12:42.900]  в предшествующей критической секции, в этот список что-то положил и отпустил lock. Отпустил
[01:12:42.900 --> 01:12:51.180]  lock, то есть записал во флажок false. А другой поток, раз он в критической секции сейчас читает этот
[01:12:51.180 --> 01:12:57.780]  список, он должен был перед этим прочесть из флажка этот false. Ну плюс, атомарно перезаписать,
[01:12:57.780 --> 01:13:03.420]  и вот, извините, прочесть. Вот здесь мы записали, а здесь мы прочли. И вот мы ожидаем теперь, что мы
[01:13:03.420 --> 01:13:10.700]  увидим запись, сделанную в предшествующей секции. Разумно? Разумно. Причем это тот же самый
[01:13:10.700 --> 01:13:19.260]  сценарий message passing. И вот мы хотим его формализовать. Нам нужно как-то строго описать в модели памяти
[01:13:19.260 --> 01:13:25.020]  языка, что вот есть такая гарантия, что здесь мы увидим то, что было написано в предшествующей
[01:13:25.020 --> 01:13:31.460]  секции. Что здесь мы увидим то, что было написано здесь. Нам нужно просто формальные правила,
[01:13:31.460 --> 01:13:41.060]  некоторый частичный порядок, и он называется happens before. В чем замысел? Ну, happens before – это
[01:13:41.060 --> 01:13:44.460]  понятие, которое берется, вообще говоря, в распределённых системах, оно там появилось,
[01:13:44.460 --> 01:13:58.300]  и с помощью этого понятия люди описывают отношения событий, ну, во времени или скорее в смысле
[01:13:58.300 --> 01:14:02.700]  причинности. Ну вот, смотрите, распределённая система состоит из узлов, вот у каждого из них
[01:14:02.700 --> 01:14:10.860]  свой таймлайн, и эти узлы обмениваются сообщениями, отправляют, получают. И мы вот хотели бы какие-то
[01:14:10.860 --> 01:14:16.620]  два события сравнить между собой, что было раньше, а что позже. Вот есть некоторая фундаментальная беда,
[01:14:16.620 --> 01:14:21.420]  с этого начнётся следующий курс про распределённые системы, что в распределённой системе нельзя
[01:14:21.420 --> 01:14:27.860]  синхронизировать часы, невозможно это сделать. Поэтому на время на часы полагаться нельзя. Так
[01:14:27.860 --> 01:14:35.860]  что мы рассуждение о времени заменяем рассуждением о причинности. Вот мы вводим понятие happens
[01:14:35.860 --> 01:14:41.900]  before на событиях, частичный порядок на событиях в распределённой системе. Мы скажем, что если у
[01:14:41.900 --> 01:14:47.260]  нас событие A предшествовало событию B в пределах одного узла, ну, то есть узел сначала сделал A,
[01:14:47.260 --> 01:14:55.060]  потом сделал B, то, разумеется, A happens before B, А случилось до B. Кажется, это сомнений не вызывает.
[01:14:55.060 --> 01:15:02.140]  Вот вы зашли в аудиторию до того, как вы сели на стул в аудитории. Это очень естественно. Дальше,
[01:15:02.140 --> 01:15:09.300]  если A — это событие отправки сообщения, а B — это получение сообщения другим узлом. Ну,
[01:15:09.300 --> 01:15:13.660]  в смысле, вы отправили сообщение, а B, потом другой узел получил это сообщение, то мы снова скажем,
[01:15:13.660 --> 01:15:21.740]  что A happens before B. Разумеется, сообщение не может идти во времени назад. Ну, а дальше мы вот эти
[01:15:21.740 --> 01:15:29.740]  два частных случая замыкаем по транзитивности. И вот транзитивное замыкание — это и есть
[01:15:29.740 --> 01:15:35.420]  транзитивное замыкание этих двух случаев, и есть определение happens before. Определение happens
[01:15:35.420 --> 01:15:44.220]  before — оно отражает причины событий. Вот смотрите, у нас есть вот это событие и вот это событие. Что мы
[01:15:44.220 --> 01:15:50.860]  можем про них сказать? Что это событие могло стать причиной этого события. Ну, потому что вот как-то
[01:15:50.940 --> 01:15:56.500]  вот так вот повлиял. Ну, или, не знаю, вот так вот повлиял. Или это событие могло стать причиной этого
[01:15:56.500 --> 01:16:04.060]  события, потому что вот так вот. Это на самом деле очень напоминает аналогии из теории относительности.
[01:16:04.060 --> 01:16:13.460]  Прям очень сильно. Ну, мы говорим про время и про причинность, еще бы оно не упоминало. Смотрите,
[01:16:13.460 --> 01:16:19.340]  а вот есть такое событие и вот такое событие. Ну, вот с одной стороны, это событие во времени
[01:16:19.340 --> 01:16:27.100]  предшествует этому. Ну, вот я потому что-то картинку нарисовал. Я знаю. Но узлы этого сами понять
[01:16:27.100 --> 01:16:33.500]  не могут. И с точки зрения happens before, эти события, они конкурентны, они неупорядочены. Одно не может
[01:16:33.500 --> 01:16:40.180]  зависеть от другого. Ну, просто вот эта причина, эта связь, она нигде не… она не выражена в передаче
[01:16:40.180 --> 01:16:53.140]  сообщения, она не могла возникнуть. Определение понятно? Тогда мы сейчас, вот это happens before
[01:16:53.140 --> 01:17:01.620]  произошло до вот это определение хотим перенести на модель разделяемой памяти и сказать, что если
[01:17:01.620 --> 01:17:07.660]  вот запись в буфер произошла до happens before, чтение из буфера, то чтение из буфера непременно увидит
[01:17:07.660 --> 01:17:15.820]  эту запись. Но вот чтобы так сделать, нужно понять, а как переформулировать happens before для модели
[01:17:15.820 --> 01:17:23.060]  разделяемой памяти, где у нас есть ячейки и потоки. Вот что такое локальный шаг узла потока и что
[01:17:23.060 --> 01:17:29.420]  такое отправка получения сообщения. Вот что мы сейчас хотим сделать. Что такое локальный шаг
[01:17:29.420 --> 01:17:35.220]  узла? Это очень простой вопрос. Ну, вот поток, не знаю, взял spin lock, потом он, не знаю,
[01:17:35.220 --> 01:17:43.340]  алоцировал новый узел, прицепил его к началу списка, поменял голову, потом отпустил spin lock.
[01:17:43.340 --> 01:17:51.900]  Вот мы скажем, что между этими операциями, конечно, между этими обращениями памяти есть
[01:17:51.900 --> 01:17:59.060]  happens before, но чуть конкретнее есть program order. Порядок, который описывает, но порядок,
[01:17:59.060 --> 01:18:10.700]  который фиксирует порядок обращений к памяти в каждом отдельном потоке. Вот у нас был
[01:18:10.700 --> 01:18:18.700]  modification order, это порядок записи в Atomic из разных потоков. И у каждого потока есть program order,
[01:18:18.700 --> 01:18:28.380]  просто порядок, в котором этот поток, порядок, в котором в этом потоке написаны все обращения
[01:18:28.380 --> 01:18:38.940]  к памяти. В C++ он называется sequence of before. Ну и смотрите, что важно, что program order — это
[01:18:38.940 --> 01:18:46.620]  не порядок, в котором обращения к памяти исполняются. Это просто порядок, который вот в тексте
[01:18:46.620 --> 01:18:54.420]  программы есть. Исполняться инструкция могут быть в другом порядке. Ну, вот я показывал вам пример,
[01:18:54.420 --> 01:19:01.100]  вот запись в A, запись в A, запись в B. Вот запись в A предшествует в program order записи в B,
[01:19:01.100 --> 01:19:07.500]  просто потому что первая строчка написана в программе до второй строчки. Но исполняться эти
[01:19:07.500 --> 01:19:20.900]  записи могут в другом порядке, тут противоречия никакого нет. Согласны? Этот пример мы видели,
[01:19:20.980 --> 01:19:28.420]  program order до этого не видели. Вот, и мой point в том, что program order, он не требует от, ни от кого не
[01:19:28.420 --> 01:19:35.700]  требует, в общем, исполнять обращение в каком-то порядке. Это просто некоторая фиксация порядка,
[01:19:35.700 --> 01:19:40.940]  который заложен в тексте программы. Это не порядок во времени, это порядок в тексте программы.
[01:19:40.940 --> 01:19:50.340]  Дальше у нас есть вторая половина определения happens before — это отправка сообщения. Ну и вот
[01:19:50.340 --> 01:19:55.140]  вопрос, как выглядит отправка сообщения в многопоточной программе? Что такое сообщение,
[01:19:55.140 --> 01:20:02.620]  что такое отправка, что такое получение? Ну вот, сообщение — это будет значение,
[01:20:02.620 --> 01:20:07.820]  которое мы пишем в атоме. Когда мы отправляем значение, значит, что мы пишем в атоме. Когда
[01:20:07.820 --> 01:20:17.580]  поток читает это значение, записанное ранее стором, то он его получает, сообщение доставляется. Вот
[01:20:17.580 --> 01:20:29.580]  сообщение, вот его отправка — стор, вот его получение — лот. Может быть сложнее. Вот если мы
[01:20:29.580 --> 01:20:36.380]  говорим про спинлок, то смотрите, у нас здесь поток, который отпускает спинлок, говорит стор там 0,
[01:20:36.380 --> 01:20:42.300]  а поток, который захватывает спинлок, говорит exchange 1. Вот exchange — это сложная операция,
[01:20:42.300 --> 01:20:49.540]  она и читает, и пишет. Но в данном случае она в том числе читает, и вот в этом чтении оно
[01:20:49.540 --> 01:21:00.580]  получает сообщение, которое отправил он в лот. Согласны? И вот, мы теперь введем еще одну
[01:21:00.580 --> 01:21:08.900]  конструкцию вспомогательную — отношение synchronize the Swiss. Мы скажем, что, пусть мы скажем сначала,
[01:21:08.900 --> 01:21:17.540]  что A — это некоторая запись в атомик, а пусть B — это чтение в другом потоке из этого атомика.
[01:21:17.540 --> 01:21:25.860]  И мы скажем, что запись в атомик A синхронизировалась с чтением из атомика B,
[01:21:25.860 --> 01:21:38.180]  если B прочитала значение, записанное A. Ну вот это чтение получило эту запись.
[01:21:38.180 --> 01:21:48.580]  Возникла синхронизация Swiss. Разумеется, одно и то же сообщение, вот можно отправить сообщение один
[01:21:48.580 --> 01:21:58.700]  раз, а получить его несколько раз. Правда? Ну вот тогда у нас одна запись станет началом
[01:21:58.700 --> 01:22:13.140]  сразу нескольких красных вот таких вот дуг. Ну, с последней записям в modification order.
[01:22:13.140 --> 01:22:31.420]  Это мы пропустим. Как различать их? Ну вот program order — это частичный порядок на обращениях
[01:22:31.420 --> 01:22:37.780]  памяти в пределах одного потока и порядок вообще на обращениях в тексте программы.
[01:22:37.780 --> 01:22:48.180]  SYNCHRONIZATION Swiss — это отношение на парах запись чтения из разных поток. И вот мы, в общем-то,
[01:22:48.180 --> 01:22:54.980]  получили две составляющих happens before. А теперь мы просто замыкаем их по транзитивности. Вот пусть
[01:22:54.980 --> 01:23:01.140]  поток T пишет в ячейку памяти, потом взводит атомарный флажок, потом другой поток читает из
[01:23:01.140 --> 01:23:09.940]  этого флажка и видит записанное значение true, и тогда между этой записью и этим чтением возникает
[01:23:09.940 --> 01:23:21.140]  happens before. Вот это еще один частичный порядок. То есть стрелька SYNCHRONIZATION Swiss идут от
[01:23:21.140 --> 01:23:29.340]  стора ко всем лодам из этого атомика. Нет, не ко всем лодам из этого атомика. Мы соединяем
[01:23:29.340 --> 01:23:36.780]  пару стор и лод, если лод прочитал значение, записанное вот этим стором. Должен прочитать.
[01:23:36.780 --> 01:23:43.620]  Он не должен никому. Вот я в одном потоке написал стор, в другом написал лод. Лод может увидеть
[01:23:43.620 --> 01:23:48.460]  запись из стора, а может не увидеть. В одном случае возникнет отношение, в другом не возникнет.
[01:23:48.460 --> 01:23:52.660]  То есть мы уже определяем после исполнения программы?
[01:23:52.660 --> 01:23:57.180]  Ну, после исполнения реализуется, и вот в нем возникают такие стрелки или не возникают?
[01:23:57.180 --> 01:23:59.860]  А, я думаю, мы их проводим по ходу.
[01:23:59.860 --> 01:24:09.700]  Ну, это… Смотри, я же говорил, что если чтение B прочитало записи, сделанную A. В смысле,
[01:24:09.700 --> 01:24:16.660]  если чтение B прочитало значение, записанное A, вот тогда и возникает. Откуда мы знаем,
[01:24:16.660 --> 01:24:23.140]  что она прочитала на самом деле? Пока программу не запустим, не узнаем. Вот мы запускаем программу,
[01:24:23.140 --> 01:24:28.260]  и в ней реализуется некоторый модификацион ордер. В ней реализуется некоторая… ну,
[01:24:28.260 --> 01:24:35.460]  некоторые пары синхроназисуис, какие именно зависят конкретного запуска, конкретного исполнения.
[01:24:35.460 --> 01:24:42.980]  То есть можно я на минутку влезу и скажу, что, ну да, действительно можно вот очень по тупому
[01:24:42.980 --> 01:24:47.540]  представить, что мы запустили программу, как-то волшебным образом всю историю,
[01:24:47.540 --> 01:24:52.740]  что происходило в компьютере, записали, и смотря на эту историю, рисуем все вот эти вот графы,
[01:24:52.740 --> 01:24:56.740]  порядки… Ром, я против, потому что нет некой истории, в этом беда.
[01:24:56.740 --> 01:25:01.820]  Ну нету, да. Поэтому волшебная. Хорошо вы.
[01:25:01.820 --> 01:25:05.300]  А как мы тогда можем провести несколько стрелочек из одной вершины?
[01:25:05.300 --> 01:25:10.060]  Ну, один поток записал в ячейку true, а потом много потоков прочитало это значение.
[01:25:10.060 --> 01:25:15.180]  А, то есть нам не важно… Тут нам уже не важно, в каком порядке они прочитали.
[01:25:15.180 --> 01:25:20.300]  Еще раз, тут вообще не про пары, речь пары. Вот у тебя есть запись в программе,
[01:25:20.300 --> 01:25:24.740]  у тебя есть чтение в Atomic, и если чтение прочитало значение, записанное записью,
[01:25:24.740 --> 01:25:29.900]  то возниклась синхроназисуис между двумя обращениями к Atomic. Вот,
[01:25:29.900 --> 01:25:33.540]  определение про пару. Таких пар может быть много.
[01:25:33.540 --> 01:25:39.180]  Да, хорошо, понял. Вот. И не знаю, почему вы так
[01:25:39.260 --> 01:25:42.500]  зацепились за текст программы. Текст программы был только в одном определении,
[01:25:42.500 --> 01:25:46.620]  пока в программ-ордере. Больше нигде его не было и не будет. Все остальное мы говорим
[01:25:46.620 --> 01:25:49.500]  про исполнение. Ну, в смысле, про то, что реализуется во время исполнения.
[01:25:49.500 --> 01:25:58.940]  Если есть еще один поток, который положил true, как мы сделаем, что это сделаем?
[01:25:58.940 --> 01:26:05.460]  Ну, еще раз, у каждого Atomic есть modification order. Вот то значение, в смысле,
[01:26:05.460 --> 01:26:08.980]  ту запись, в которой чтение прочлось, той оно и синхронизируется.
[01:26:08.980 --> 01:26:16.900]  Ты не понимаешь, какая это будет запись, ну и неважно, какая это из двух.
[01:26:16.900 --> 01:26:21.140]  Тут просто очень сложно говорить про какие-то искусственные синтетические
[01:26:21.140 --> 01:26:24.980]  примеры. Вот в разумных программах всегда можно объяснить, что происходит.
[01:26:24.980 --> 01:26:29.140]  Поэтому лучше на каком-то разумном коде это все показывать. В смысле,
[01:26:29.140 --> 01:26:33.220]  вопросы такие, да. Ну, короче, вот какая запись была последней
[01:26:33.700 --> 01:26:37.380]  модификацион ордере, тут ты ее увидишь. Ну, в смысле, стоит и синхронизируешься.
[01:26:37.380 --> 01:26:47.220]  И вот транзитивно замкнули, получили happens before, да. Вот это еще одна гарантия.
[01:26:47.220 --> 01:26:55.020]  Мы требуем, чтобы чтение из ячеек памяти были бы согласованы с happens before.
[01:26:55.020 --> 01:27:02.500]  Сейчас к этому вернусь. Сначала, определение happens before, которое вы можете найти в модели
[01:27:02.500 --> 01:27:06.620]  памяти. Ну, вот мы открываем модели памяти Джавы, и вот happens before тут буквально...
[01:27:06.620 --> 01:27:20.900]  Так не работает. Буквально это и видим. Все плывет. Вот, у нас есть два обращения к памяти.
[01:27:20.900 --> 01:27:26.380]  x и y называются здесь экшенами. Мы скажем, что у нас реализуется частичный порядок.
[01:27:26.380 --> 01:27:35.620]  Частичный порядок связывает x и y. Если x и y – это действие одного потока, и x предшествует y
[01:27:35.620 --> 01:27:43.300]  просто в программ-ордере, в тексте программы, мы скажем, что a happens before, b... Ну, пропустим
[01:27:43.300 --> 01:27:54.180]  этот странный пункт. x синхронизируется с y, если... Я соберусь. Если есть между x и y
[01:27:54.420 --> 01:28:01.620]  программ-ордер, то это happens before. Если между x и y есть синхронизация с y, то это happens before.
[01:28:01.620 --> 01:28:09.540]  Ну, и если транзитивность, то happens before. Вот, ровно определение из модели памяти Джавы.
[01:28:09.540 --> 01:28:22.660]  В C++ все очень сложно, и там... Ну, я покажу один раз, а потом, может быть, нам посчастливится на
[01:28:22.660 --> 01:28:31.820]  семинаре посмотреть. А может быть, и обойдется, кто знает. В C++ определение happens before абсолютно
[01:28:31.820 --> 01:28:37.780]  душераздирающее, к нему есть длинные комментарии, которые объясняют, почему так получилось. Но из
[01:28:37.780 --> 01:28:44.180]  него все равно мало, чтобы будет понятно. Короче, в определенных предположениях можно считать,
[01:28:44.180 --> 01:28:52.420]  что в C++ тоже так. Но в C++ есть некоторые тонкости, которые, вообще говоря, уже можно даже и не знать,
[01:28:52.420 --> 01:29:00.580]  и если эти тонкости, как бы, забыть про них, то определение будет таким. Так что я вас немного
[01:29:00.580 --> 01:29:07.180]  обманываю формально, но по существу не обманываю. То есть вы можете жить с таким определением всю
[01:29:07.180 --> 01:29:18.100]  жизнь и, скорее всего, не пострадать. Ну и что мы, собственно, говорим под тем, что чтение согласован
[01:29:18.860 --> 01:29:25.500]  из happens before? Мы говорим, что если мы читаем вот здесь, вот из ячейки дата, и это чтение упорядочено
[01:29:25.500 --> 01:29:33.980]  через happens before с записью в ячейку дата, не атомную, не атомик, то это чтение обязано увидеть эту
[01:29:33.980 --> 01:29:40.140]  запись. Довольно разумное ожидание. Собственно, мы к этому и шли. Мы хотели его формализовать,
[01:29:40.140 --> 01:29:50.740]  вот мы формализовали. Согласны? Вот как можно это нагрядно себя представлять? Если вы что-то писали в
[01:29:50.740 --> 01:29:56.100]  одном потоке, потом поставили флажок, а потом в другом потоке вы из этого флажка не прочли вот
[01:29:56.100 --> 01:30:02.860]  это значение, вам так случилось, что прочли его, то вот эти записи, они как будто бы перетекают по
[01:30:02.860 --> 01:30:14.980]  вот этому ребру Synchronize the Swiss в другой поток, и там становятся видны. Ну и вот примеры опять из
[01:30:14.980 --> 01:30:21.580]  модели памяти C++ Java, где вот гарантируется, что там сайд-эффекты или записи будут видны через
[01:30:21.580 --> 01:30:36.460]  happens before. Опять давайте я на Java покажу. Вот, если у вас два обращения к памяти упорядочились
[01:30:36.460 --> 01:30:41.540]  через happens before, то первое обращение видно второму обращению. Видно, в смысле, чтению видно.
[01:30:41.540 --> 01:30:54.740]  Ну и как мы собираемся использовать это в спинлоке? Ну, собственно, всё уже в успех. Мы в критической
[01:30:54.740 --> 01:30:59.700]  секции сделали записи в разделяемой ячейке, потом мы отпустили спинлок и записали туда 0,
[01:30:59.700 --> 01:31:07.420]  ячейку locked, потом другой поток Exchange прочитал из этой ячейки 0, когда он прочитал из ячейки 0
[01:31:07.420 --> 01:31:15.340]  и записал туда 1, то вот здесь возникла Synchronize the Swiss, между предшествующей секцией и последующей
[01:31:15.340 --> 01:31:21.260]  возникла happens before, и вот следующая секция, она благополучно читает записи, сделанные предыдущей
[01:31:21.260 --> 01:31:30.700]  секцией. Вот мы теперь способны объяснить, почему взаимное исключение работает, почему Mutex работает.
[01:31:30.700 --> 01:31:46.820]  Правда, вот во всём этом есть некоторый баг, мы кое-что упустили. Вот такое требование, оно
[01:31:46.820 --> 01:32:04.180]  оно не учитывает один случай. Требование неволидно пока. Смотрите, мы требуем, чтобы
[01:32:04.180 --> 01:32:13.060]  чтение увидело последнюю предшествующую в happens before запись, да? Но happens before – это же частичный
[01:32:13.060 --> 01:32:23.940]  порядок, и ничто не запрещает какому-то чтению в программе иметь две разные ветки happens before,
[01:32:23.940 --> 01:32:29.940]  которые в него входят, и тогда непонятно, какая запись была последней предшествующей в happens
[01:32:29.940 --> 01:32:47.380]  before. Что делать? Мы запрещаем такие программы, мы говорим, что они неправильные, они не
[01:32:47.380 --> 01:32:53.340]  вписываются в наши ожидания, они не синхронизируют некоторые обращения. Вот у нас есть пара записей,
[01:32:53.340 --> 01:32:58.940]  которые друг с другом не упорядочились. Если бы они были упорядочены, то одно бы из них стало
[01:32:58.940 --> 01:33:03.700]  последним, а другое перестало бы быть последним. А пока они оба последние, между ними есть гонка.
[01:33:03.700 --> 01:33:13.620]  Ну и вот мы говорили, что давным-давно, час назад, что мы придумываем порядки, мы придумываем
[01:33:13.620 --> 01:33:23.100]  требования к программе, и где-то мы должны учесть, что мы сужаем класс программ до программ свободных
[01:33:23.100 --> 01:33:31.780]  от гонок. Вот чтобы сформулировать, что чтение согласован из happens before, мы вот ровно в этом
[01:33:31.780 --> 01:33:37.340]  месте и пользуемся тем, что в программах наших гонок не бывает, что мы их запретили. Ну и да,
[01:33:37.340 --> 01:33:43.420]  раз уж мы здесь, можно теперь определить понятие о гонке, собственно. Вот у нас было определение
[01:33:43.420 --> 01:33:46.980]  конфликта, что два обращения к памяти конфликтуют, если они обращаются к одной и той же ячейке,
[01:33:46.980 --> 01:33:55.100]  по крайней мере, одной из этих обращений — запись. И мы скажем, что гонка — это два конфликтующих,
[01:33:55.100 --> 01:33:59.580]  ни от амарных, ни через anatомик, то есть обращения, которые неупорядочены через
[01:33:59.580 --> 01:34:10.820]  happens before. Вот это уже строгое определение гонки. Вот, пожалуйста, определение из C++ и из Java.
[01:34:10.820 --> 01:34:22.420]  Ну давайте опять найдем. Вот два конфликтующих обращения, которые ну просто так же неупорядочно
[01:34:22.420 --> 01:34:33.380]  через happens before образуют гонку. В C++, ну надеюсь, что тоже простое будет написано. Исполнение
[01:34:33.380 --> 01:34:38.100]  программы содержит гонку, видите, очень аккуратно. Исполнение содержит гонку, может и не содержать,
[01:34:38.100 --> 01:34:44.900]  в принципе, для одной и той же программы, если она содержит два конфликтующих,
[01:34:44.900 --> 01:34:50.220]  упорядоченных, конфликтующих конкурентных обращения, по крайней мере, о господи,
[01:34:50.220 --> 01:34:55.580]  одно из которых не anatomic, и которые неупорядочно через happens before. Дальше не хочу читать дальше.
[01:34:55.580 --> 01:35:05.300]  Вот. Ну опять, в C++ много всего происходит, поэтому много всего нужно, строго говоря, упомянуть. Но
[01:35:05.380 --> 01:35:12.100]  суть остается такой же. Два конфликтующих, неатомарных обращения к памяти, неупорядоченные через
[01:35:12.100 --> 01:35:20.660]  happens before. И если вы пользуетесь в курсе thread sanitizer, а вы пользуетесь им против своей воли,
[01:35:20.660 --> 01:35:29.580]  то вот thread sanitizer ищет в вашем исполнении гонки вот буквально по определению. Он ищет обращения,
[01:35:29.580 --> 01:35:35.060]  пары обращений, которые неупорядочены через happens before. Ну и пара замечаний про
[01:35:35.060 --> 01:35:42.500]  happens before. Опять, happens before не требует, чтобы обращения к памяти прямо исполнялись в таком
[01:35:42.500 --> 01:35:50.740]  порядке. Вот у вас есть программа, в ней A пишем в A, пишем в B. Между этими обращениями есть
[01:35:50.740 --> 01:35:59.900]  программ order, то есть есть happens before, но исполняться они могут в другом порядке. Это не проблема.
[01:35:59.900 --> 01:36:04.100]  Мы не требуем, чтобы вот happens before всё исполнялось в таком порядке. Мы требуем,
[01:36:04.100 --> 01:36:12.100]  чтобы чтения были согласованы с ним. Это некоторое более слабое требование. Ну и смотрите ещё что,
[01:36:12.100 --> 01:36:17.620]  что happens before оторвано от времени. Если вы записали в атомик, ой, вне атомика что-то,
[01:36:17.620 --> 01:36:22.820]  а потом через полчаса прочли из него, но без синхронизации, то это всё равно датарейс.
[01:36:22.820 --> 01:36:30.460]  Happens before всё равно нет. То есть произошло до, но happens before нет. Ну в смысле произошло до
[01:36:30.460 --> 01:36:41.780]  времени, но причинности не реализовалось, поэтому happens before нет. Итак, мы придумали две гарантии,
[01:36:41.780 --> 01:36:46.700]  два частичных порядка. Modification order — это порядок записи в каждый атомик, и мы потребовали,
[01:36:46.700 --> 01:36:53.180]  чтобы чтение атомика читали монотонную подысторию modification order. И мы придумали
[01:36:53.180 --> 01:36:58.700]  happens before — актризитивное замыкание программ order и синхронизации Swiss, и потребовали,
[01:36:58.700 --> 01:37:09.540]  чтобы чтение были согласованы с happens before. И вопрос, достаточно ли этого? Вот у нас есть
[01:37:09.540 --> 01:37:19.740]  программа с двумя атомиками, и в любом исполнении этой программы гарантируются гарантии, простите,
[01:37:19.740 --> 01:37:33.660]  modification order и happens before. Вопрос, возможен ли исход 00? Ну как бы в рамках тех требований,
[01:37:33.660 --> 01:37:55.220]  которые мы придумали? Ты прав, но ты ничему не научился. Но смотрите, у нас есть требования,
[01:37:55.220 --> 01:38:03.100]  которые что-то требуют, да? Что-то запрещают, в частности. Ну вот, запрещен ли исход 00? Ну вот,
[01:38:03.140 --> 01:38:08.900]  modification order — он вообще про отдельные атомики. У отдельного атомика здесь есть modification order.
[01:38:08.900 --> 01:38:17.220]  Сначала в атомике 0, а потом единица. И вот чтение прочло подысторию 0. Нормальная подыстория,
[01:38:17.220 --> 01:38:21.700]  нормальная. Монотонная, монотонная. Ну трудно быть не монотонной историей из одного значения.
[01:38:21.700 --> 01:38:29.900]  А happens before — он про то, что если возникло синхронизация Swiss и happens before, то значит там
[01:38:29.900 --> 01:38:35.740]  какие-то ограничения следуют. А здесь возникло синхронизация Swiss? Здесь мы записали единицу,
[01:38:35.740 --> 01:38:44.780]  а прочли 0. Синхронизация Swiss не возник. Значит, все, happens before тоже не удел. Так что у нас есть
[01:38:44.780 --> 01:38:51.820]  две гарантии, но при этом они никак не запрещают в этом исполнении получить два нуля. А я напомню,
[01:38:51.820 --> 01:38:57.060]  что такая программа нас беспокоит, потому что она возникает в runtime.gov сборке мусора,
[01:38:57.060 --> 01:39:04.100]  она возникает в реализации фьютекса в линуксе. Короче, сценарий довольно важный. Поэтому мы
[01:39:04.100 --> 01:39:12.140]  требуем еще одного. Мы требуем достаточно сильной гарантии, что все вызовы store и load и других
[01:39:12.140 --> 01:39:21.140]  методов атомика на всех атомиках глобально упорядочено в исполнении. То есть все обращения
[01:39:21.580 --> 01:39:29.300]  ко всем атомикам выстраиваются в некоторый сквозной единый порядок, который мы называем
[01:39:29.300 --> 01:39:42.100]  Synchronization Order. Ну, смотри, мы глобально хотим, чтобы об исполнении программы можно было бы
[01:39:42.100 --> 01:39:47.700]  рассуждать, как будто бы все обращения памяти происходили в каком-то порядке. Вот, но мы не
[01:39:47.700 --> 01:39:55.180]  требуем, чтобы все так происходило, но мы требуем, чтобы на атомиках так все происходило. Вот, но мы
[01:39:55.180 --> 01:39:59.500]  надеемся, что в нашей программе атомиков будет гораздо меньше, чем неатомарных ячеек памяти.
[01:39:59.500 --> 01:40:11.300]  Кажется, что это тоже довольно разумно ожидать. Да? Ну, опять, смотрим примеры. Смотрим модель
[01:40:11.300 --> 01:40:28.540]  памяти Java. Вот он, так и называется Synchronization Order. Это Total Order на всех Synchronization Actions,
[01:40:28.540 --> 01:40:34.820]  которые там записи в атомик, чтение из атомиков, локи-анлоки, короче, еще есть
[01:40:34.820 --> 01:40:43.940]  некоторые специальные случаи. Но суть такая. Total Order Overall Synchronization Actions. В C++ Synchronization
[01:40:43.940 --> 01:40:50.860]  Order называется совершенно альтернативным, он называется Total Order S. Вот как бы нигде в модели памяти
[01:40:50.860 --> 01:40:55.860]  больше нет таких буквенных сокращений, именований, вот почему-то только одно оно. Ну, вот есть и есть,
[01:40:55.860 --> 01:41:03.980]  с этим уже придется. Значит, это вот опять общий порядок на всех обращениях к атомикам
[01:41:03.980 --> 01:41:17.060]  с Memory Order Sequential Consistency, то есть дефолтный Memory Order. Ну, и вот этот общий порядок S,
[01:41:17.060 --> 01:41:24.980]  Synchronization, он же Synchronization Order, запрещает вот в этой программе такое исполнение. Потому что
[01:41:24.980 --> 01:41:31.700]  Synchronization Order, конечно же, тоже согласован с порядком следования обращения к памяти в каждом
[01:41:31.700 --> 01:41:47.500]  потоке. Вот такое требование, такая гарантия. Ну, и что теперь читает каждый атомик? Каждый
[01:41:47.500 --> 01:41:56.180]  атомик читает последнюю запись Synchronization Order, можно так сказать про него. Ну что, я бы сказал,
[01:41:56.180 --> 01:42:04.260]  что мы построили все необходимые частичные порядки. Synchronization Order в первую очередь и Happens
[01:42:04.260 --> 01:42:10.260]  Before. Вот давайте еще раз соберем их вместе. Вот в первую очередь мы придумали Modification Order.
[01:42:10.260 --> 01:42:17.380]  Это порядок записей в каждый отдельный атомик. Дальше мы придумали Happens Before, как транзитивное
[01:42:17.380 --> 01:42:24.540]  замыкание Program Order, то есть порядок следования обращения к памяти в тексте программы для каждого
[01:42:24.540 --> 01:42:31.780]  потока. И Synchronizes With – это уже не порядок, это отношение, которое связывает атомарные записи и
[01:42:31.780 --> 01:42:39.860]  атомарные чтения, которые увидели значение этих записей. И вот Happens Before – транзитивное
[01:42:39.860 --> 01:42:47.980]  замыкание, которое фиксирует возникающую в исполнении причинность, реализующуюся причинность.
[01:42:47.980 --> 01:42:55.260]  И Synchronization Order – это сквозной порядок на всех обращениях ко всем атомикам. Вот те гарантии,
[01:42:55.260 --> 01:43:03.340]  которые мы навыдумывали. И вот в совокупности все эти гарантии и образуют исполнение. Мы говорим,
[01:43:03.340 --> 01:43:08.180]  что в модели памяти C++ исполнение – это согласованная реализация вот этих вот порядков.
[01:43:08.180 --> 01:43:15.540]  Согласованная, в смысле, если мы все это объединив вместе, то мы получим эцикличный граф.
[01:43:15.540 --> 01:43:23.780]  Ну и вот само исполнение – это и есть граф, как было обещано когда-то. Вершины – это обращение
[01:43:23.780 --> 01:43:31.900]  к памяти, дуги – это какие-то порядки отношения. Вот в джаве, пожалуйста, определение исполнения,
[01:43:31.900 --> 01:43:46.420]  вот оно такое. Опять идем в документ, идем в execution. Вот. Исполнение – это набор обращений к
[01:43:46.420 --> 01:43:52.540]  памяти, program order, synchronization order, synchronizes with, happens before. Тут еще какие-то специальные
[01:43:52.540 --> 01:44:00.460]  штуки. Сейчас они не очень важны. Спомогательное определение. Вот это и есть исполнение. Вот когда
[01:44:00.460 --> 01:44:06.140]  мы говорим в модели памяти про исполнение, мы представляем себе вот такой вот граф. Это единственный
[01:44:06.140 --> 01:44:14.740]  честный способ, которым можно себе исполнение представлять. Вот оно такое. Вы запускаете программу,
[01:44:14.740 --> 01:44:24.060]  и вот рождается некоторый граф с частичными порядками. В C++ этих порядков еще больше,
[01:44:24.220 --> 01:44:34.740]  когда-то давно показывал. Давайте я найду. В C++ вот тут тоже достаточно много их.
[01:44:34.740 --> 01:44:44.540]  Ну и есть определение датарейса, которое там по пути возникает. Два конфликтующих,
[01:44:44.540 --> 01:44:52.940]  неатомарных, неопределеченных через happens before обращений. И вот теперь мы можем сказать,
[01:44:52.940 --> 01:45:01.340]  что увидит чтение. Вот чтение, такой фундаментальный вопрос модели памяти. Что увидит чтение? Вот
[01:45:01.340 --> 01:45:09.460]  чтение согласовано с нашими частичными порядками. Синхронизейшн ордером на атомиках is happens
[01:45:09.460 --> 01:45:15.620]  before. Если мы читаем что-то из атомика, то мы видим просто последнюю предшествующую запись
[01:45:15.620 --> 01:45:22.220]  в синхронизейшн ордере, ну или в модификейшн ордере, который под множество, под история
[01:45:22.220 --> 01:45:27.540]  модификейшн синхронизейшн ордера, если вы понимаете, о чем я. Но если мы читаем не атомик, то,
[01:45:27.540 --> 01:45:32.500]  видимо, мы читаем последнюю предшествующую в happens before запись. В предположении, конечно,
[01:45:32.500 --> 01:45:39.820]  что в программе нет гонок, потому что иначе такое определение неволидно. Вот мы придумали
[01:45:39.820 --> 01:45:48.220]  частичные порядки, которые ограничивают, которые задают правила чтений. Но смотрите-то,
[01:45:48.300 --> 01:45:54.020]  что мы хотели? Мы же хотели не этого, мы хотели глобального порядка. Мы хотели sequential consistency.
[01:45:54.020 --> 01:46:01.100]  Мы хотели, чтобы исполнение программы было неотличимо от некоторого последовательного. Меньше
[01:46:01.100 --> 01:46:11.820]  всего нам хочется думать про графы какие-то. Так вот, утверждается, что если исполнение программы
[01:46:11.820 --> 01:46:20.740]  соблюдает вот требования, которые порождаются этими частичными порядками, то пользователь не
[01:46:20.740 --> 01:46:25.660]  сможет отличить исполнение от некоторого последователя. От какого «некоторого»? Но вот посмотрите,
[01:46:25.660 --> 01:46:31.580]  мы сейчас построим то самое исполнение, от которого неотличимо наше. Вот мы возьмем
[01:46:31.580 --> 01:46:40.420]  synchronization order, возьмем happens before, объединим их. Мы считаем, что влагаем, что в них, что циклов
[01:46:40.420 --> 01:46:47.580]  в убедение не получится. Такова наша аксемума. А дальше мы получившийся граф топологически
[01:46:47.580 --> 01:46:54.420]  отсортируем и порядочим. Получим некоторый линейный порядок TEN на всех обращениях к памяти.
[01:46:54.420 --> 01:47:04.900]  И вот мы хотим показать следующее, что наше исполнение, которое на самом деле вот такое,
[01:47:04.900 --> 01:47:16.220]  оно неотличимо от пользователя, от исполнения всех обращений к памяти в порядке T, в котором
[01:47:16.220 --> 01:47:24.500]  просто каждое чтение читает последнюю предшествующую запись. Ну что значит неотличимо?
[01:47:24.500 --> 01:47:30.820]  Смотрите, в T мы читаем какую запись? Просто вот у нас есть чтение в T, оно читает последнюю
[01:47:30.820 --> 01:47:39.860]  запись в ту же ячейку памяти. Но в исполнении чтение читает не просто последнюю, оно читает
[01:47:39.860 --> 01:47:48.140]  последнюю happens before. И что если, вот получилась такая картинка, что у нас есть две записи W
[01:47:48.140 --> 01:47:57.580]  и W', и W', она последняя в T, предшествующая R, но не последняя в happens before. Тогда кажется,
[01:47:57.660 --> 01:48:04.580]  что обман происходит. Но такого не бывает, потому что посмотрим, пусть такое реализовалось от
[01:48:04.580 --> 01:48:12.940]  противного, пусть так случилось. Посмотрим на пару W и W'. Может ли между ними быть happens
[01:48:12.940 --> 01:48:21.060]  before? Не быть happens before. Не может быть, потому что это две записи, они конфликтуют, значит они
[01:48:21.060 --> 01:48:26.940]  должны быть упорядочены. Могут ли они быть упорядочены в обратную сторону? Не могут,
[01:48:26.940 --> 01:48:32.860]  потому что мы же топологическую социировку строили, тогда был бы другой порядок. Так что
[01:48:32.860 --> 01:48:38.860]  happens before есть и в таком порядке непременно, отсюда-сюда. Теперь смотрим на эту пару,
[01:48:38.860 --> 01:48:45.700]  W' и R', опять конфликтующие обращения, опять между ними должно быть happens before, опять по тем
[01:48:45.700 --> 01:48:51.900]  же самым причинам в обратную сторону его не может быть. Значит, есть W'. Ну и все, значит,
[01:48:52.740 --> 01:49:00.980]  отсюда happens before. Значит, предположение наше неверное, потому что W' это просто не последняя в
[01:49:00.980 --> 01:49:11.420]  happens before запись, а последняя W'. И мы должны прочесть ее. Ну то есть, если в исполнении,
[01:49:11.420 --> 01:49:19.700]  если исполнение это вот такие частичные порядки, которые ограничивают чтение в программе,
[01:49:19.700 --> 01:49:26.900]  то существует некоторое исполнение... То есть, если исполнение вот такое, на самом деле, то
[01:49:26.900 --> 01:49:35.540]  существует некоторый глобальный порядок на всех обращениях к памяти, который не отличим вот от
[01:49:35.540 --> 01:49:46.460]  этого исполнения графа. Так что вот наших требований трёх, modification order, synchronization order,
[01:49:46.460 --> 01:49:53.460]  happens before, этих частичных порядков достаточно, чтобы получить видимость последовательного исполнения.
[01:49:53.460 --> 01:50:03.060]  Да, можно.
[01:50:03.060 --> 01:50:15.300]  Возможно. Давайте я докажу исполнением в коде. Как ты к этому отнесешься?
[01:50:15.300 --> 01:50:25.140]  Ну ладно, не веришь тебе плюс-плюс. Компериатор не соблюдает модель. Давай.
[01:50:25.140 --> 01:50:38.420]  Не, не должны никакие стрелочки идти.
[01:50:38.420 --> 01:50:47.220]  У тебя две гарантии. У тебя два частичных порядка, modification order и happens before.
[01:50:47.220 --> 01:50:54.220]  Modification order говорит, у тебя есть на каждом атомике история изменений. Вот для атомика X и для
[01:50:54.220 --> 01:50:59.820]  атомика Y история одинаковая. Сначала был ноль, потом стал один. И modification order говорит,
[01:50:59.820 --> 01:51:07.300]  каждое чтение в программе, каждый поток читает монотонную подысторию. Каждый поток прочитал по
[01:51:07.300 --> 01:51:17.020]  нурю. Монотонная подыстория. Всё честно, да? Happens before говорит, что если вот happens before
[01:51:17.020 --> 01:51:28.020]  реализовалось, то чтение увидит запись. Здесь не реализовалось happens before. Тут не нужно думать,
[01:51:28.020 --> 01:51:34.860]  как такое получилось. Вопрос такой чисто теоретический могло, если какие-то требования, какие-то
[01:51:34.860 --> 01:51:43.540]  гарантии, которые ограничивают существование такого исполнения. Вот их нет. Поэтому в модели памяти,
[01:51:43.540 --> 01:51:48.780]  построенной нами к этому моменту, в которой есть только modification order и happens before, такое
[01:51:48.780 --> 01:51:54.740]  исполнение возможно. Как именно оно случилось на процессоре, это вообще посторонний вопрос.
[01:51:54.740 --> 01:51:57.980]  Потому что мы рассуждаем вот декларатив.
[01:51:57.980 --> 01:52:21.140]  Сейчас, подожди, ты приговорил все мои слова, кажется. Ну, я не знаю. Я не могу определение еще
[01:52:21.140 --> 01:52:44.260]  третий раз повторить, наверное. Ещё раз, modification order состоит из двух записей. Одна запись
[01:52:44.260 --> 01:52:51.340]  это инициализация, ноль. Вторая запись, вот она. История, ноль-один. Чтение каждое, вот это вот,
[01:52:51.340 --> 01:52:56.540]  и вот это вот читает под историю. История, ноль-один, читает ноль. Ноль – это под история, ноль-один.
[01:52:56.540 --> 01:53:04.900]  Поэтому как бы требование, требованию, которое следует из modification order, это чтение ноля не
[01:53:04.900 --> 01:53:12.820]  противоречит. Happens before здесь тоже не возникает. Вот поэтому по таким сугубо формальным причинам
[01:53:12.820 --> 01:53:19.540]  исполнение ноль-ноль допускается. И вот в этом беда наших формальных требований. Поэтому мы эти
[01:53:19.540 --> 01:53:25.340]  требования усиливаем, добавляем еще одно, требуем, чтобы все обращения ко всем атомикам были
[01:53:25.340 --> 01:53:30.020]  глобально упорядоченные. Причем согласованы с порядком обращения в каждом потоке.
[01:53:30.020 --> 01:53:45.020]  Ну что ж, тогда, значит, мы сказали, что всего этого достаточно, вот этих вот synchronization order
[01:53:45.020 --> 01:53:53.020]  и happens before. Если мы через них ограничим чтение, то мы получим видимость некоторого
[01:53:53.020 --> 01:53:59.860]  глобального порядка на всех обращениях к памяти. И мы можем дальше не думать про то,
[01:53:59.860 --> 01:54:05.220]  как… про все вот эти графы и стрелки и happens before. В общем, можем не думать в какой-то степени.
[01:54:05.220 --> 01:54:15.260]  Но мы не пользовались, потому что мы смотрели нетривиальный случай. Тривиальный случай,
[01:54:15.260 --> 01:54:22.740]  когда у нас два атомика. Вот здесь мы говорим про чтение не атомика. Чтение
[01:54:22.740 --> 01:54:26.620]  атомика, оно как бы читало последнюю запись synchronization order, и оно читает до сих пор.
[01:54:26.620 --> 01:54:35.580]  А тут как бы… Нет, непонятно. Это просто тривиальный случай был. Ну, во втором случае,
[01:54:35.580 --> 01:54:41.700]  который здесь не рассмотрено, когда R – это чтение атомика. Вот, он просто опущен как тривиальный.
[01:54:41.700 --> 01:54:48.060]  Если нужно пояснить что-то там. Ну вот, смотри, у тебя были в графе обращения, у тебя был атомик,
[01:54:48.140 --> 01:54:52.980]  были все обращения к нему. Они уже были упорядочены. И в топологической сортировке они будут в таком же
[01:54:52.980 --> 01:54:57.660]  порядке находиться, поэтому там ничего нового не возникнет. А тут все-таки был частичный порядок,
[01:54:57.660 --> 01:55:04.620]  и мы вот как-то там что-то могли перепутать. Но не перепутали. Ну, смотрите, вообще говоря,
[01:55:04.620 --> 01:55:10.220]  этого мало. Потому что… Ну, то есть, я вас обманываю немного, потому что я говорю вам,
[01:55:10.220 --> 01:55:24.380]  что если мы потребуем от исполнения, соблюдения гарантий синхронизейшн ордера и Happens
[01:55:24.380 --> 01:55:30.340]  Before, и в программе нет гонок, то вы можете не думать про вот эти частичные порядки.
[01:55:30.340 --> 01:55:34.940]  В чем подвох? Где обман?
[01:55:41.220 --> 01:55:45.900]  А откуда вы знаете, что в вашей программе нет гонок? Потому что чтобы определить,
[01:55:45.900 --> 01:55:52.860]  там гонки или нет, нужно все графы представить себе. Вот. Ну, это как бы рассуждение в обратную сторону.
[01:55:52.860 --> 01:56:01.100]  И модель памяти поддерживает следующую гарантию, которую также нужно доказывать.
[01:56:01.100 --> 01:56:10.700]  Гарантия звучит так, что если все последовательно согласованные исполнения программы не содержат
[01:56:10.700 --> 01:56:21.140]  гонок, то все исполнения программы будут последовательно согласованы. Сейчас не получилось, да?
[01:56:21.140 --> 01:56:30.380]  То есть, как протестировать программу на наличие гонок? Не нужно строить графа. Нужно просто перебрать
[01:56:30.380 --> 01:56:38.620]  все возможные интерливинги. И если во всех таких вот в таком подклассе исполнений гонок не возникает,
[01:56:38.620 --> 01:56:47.940]  то значит, про гонки можно не думать и можно вообще думать, и можно после этого считать,
[01:56:47.940 --> 01:56:55.940]  что для программы другие исполнения в принципе невозможны. Да.
[01:56:55.940 --> 01:57:16.340]  Ты поднимаешь очень сложный вопрос, про который нужно час говорить. Ну, во-первых,
[01:57:16.340 --> 01:57:24.060]  промышленный… А можешь, пожалуйста, повторить вопрос для тех, кто взамен? Спрашивают… Мне кажется,
[01:57:24.060 --> 01:57:32.540]  вопрос упрощу сейчас. Как тестируют код в продакшене на наличие гонок? Похоже на твой вопрос?
[01:57:32.540 --> 01:57:42.140]  Ну, похоже, да. Ладно. Если я не отвечу, то уточни еще раз. Если у тебя большой промышленный код,
[01:57:42.140 --> 01:57:50.460]  то ты берешь и запускаешь его стредсанитайзером, и он пытается обнаружить гонки. Он не гарантирует,
[01:57:50.460 --> 01:57:57.380]  что в программе гонок нет. Он тестирует конкретное исполнение, а не программу, во-первых. Во-вторых,
[01:57:57.380 --> 01:58:02.460]  он даже в этом конкретном исполнении может что-то пропустить. Вот. Но если он что-то нашел,
[01:58:02.460 --> 01:58:09.580]  то у него точно гонка есть, и он тебе ее нарисует в виде там stacktrace. Дальше. Если ты тестируешь код,
[01:58:09.580 --> 01:58:20.740]  дальше, если ты тестируешь какие-то отдельные примитивы синхронизации, то для них, вообще говоря,
[01:58:20.740 --> 01:58:27.060]  в некоторой степени можно даже и перебрать. Даже вот такие, ну, условно, графы перебрать. Ну,
[01:58:27.060 --> 01:58:39.860]  тут тонко, но вот перебор в определенной степени возможен, да. Но вообще, почти весь промышленный
[01:58:39.860 --> 01:58:48.900]  код написан с memory-ордерами, которые слабее, чем sequential consistency. А судя по слайду,
[01:58:48.900 --> 01:58:57.380]  который у нас был, сейчас давайте я его найду. Можно ли не думать про memory-ордеры? Там говорилось,
[01:58:57.380 --> 01:59:04.180]  что если вы используете только mutex и default memory-order, то вы думаете про interleaving. Вы
[01:59:04.180 --> 01:59:12.420]  пользуетесь interleaving. В промышленном коде используют не sequential consistency. И там уже,
[01:59:12.620 --> 01:59:20.780]  ну, просто теряется всякая interleaving модель. Пользоваться ей в продакшене нельзя. С другой
[01:59:20.780 --> 01:59:28.900]  стороны, разумному, довольно высокоуровневому коду, который не оперирует там mutex и mecon
[01:59:28.900 --> 01:59:35.020]  дварами, оперирует там, не знаю, каналами, фьючами, передачей сообщений, interleaving модели не
[01:59:35.020 --> 01:59:42.940]  нужна. Но это довольно сложная интуиция. Я скорее, не знаю, могу в конце курса к этому вернуться и
[01:59:42.940 --> 01:59:47.740]  ответить на твой вопрос еще раз. И тогда будет, ну, как бы тебе самому понятнее, что я имею в виду.
[02:00:05.020 --> 02:00:13.020]  Ты все пытаешься сломать тот пример, а с ним все в порядке. Но я повторю. Значит, у тебя есть два
[02:00:13.020 --> 02:00:18.660]  обращения к одному и тому же атомику, атомику записи чтения. И если чтение читает значение,
[02:00:18.660 --> 02:00:23.580]  которое записала эта запись, то между ними возникает отношение synchronize this with. Просто
[02:00:23.580 --> 02:00:27.700]  пара такая. А дальше оно участвует в образовании частичного порядка happens before.
[02:00:27.700 --> 02:00:42.060]  Давай остановимся. Не хочу сейчас к этому возвращаться. Итак, значит, если гонок нет,
[02:00:42.060 --> 02:00:47.420]  то про исполнение можно думать в модели чередования. А чтобы проверить, что гонок нет,
[02:00:47.420 --> 02:00:51.940]  можно перебрать только исполнение в модели чередования. Если там гонок не возникнет,
[02:00:52.020 --> 02:00:59.540]  значит, беспокоиться нам ни о чем не нужно. Так что мы достигли с одной стороны успеха. То есть
[02:00:59.540 --> 02:01:06.540]  мы хотели получить видимость последовательного исполнения, и мы ее получили, выдумав какие-то
[02:01:06.540 --> 02:01:13.940]  частичные порядки. Но это только половина истории, не по времени, а по целям нашим.
[02:01:13.940 --> 02:01:26.820]  Зачем так сложно было все? Ради чего все это было? Ради реордерингов. Мы хотели не просто получить
[02:01:26.820 --> 02:01:32.700]  видимость последовательного исполнения, мы хотели, чтобы у процессора осталась возможность для
[02:01:32.700 --> 02:01:40.340]  каких-то оптимизаций. И мы эту возможность заложили, потому что мы все время оперировали
[02:01:40.340 --> 02:01:51.500]  частичными порядками. Ну ладно, мы там атомики жестко провязали, но мы не требуем, чтобы все
[02:01:51.500 --> 02:01:59.660]  обращения к памяти прямо исполнялись по порядку. И вот сейчас мы этим воспользуемся для того,
[02:01:59.660 --> 02:02:06.740]  чтобы построить очень простой класс допустимых реордерингов. Вот смотрите, есть у вас программа,
[02:02:06.740 --> 02:02:14.540]  тут есть поток T и T штрих, и поток T он пишет, пишет, пишет, пишет, а потом пишет в атомик,
[02:02:14.540 --> 02:02:22.860]  а другой поток читает из этого атомика, потом и синхронизируется с. Вот смотрите, пусть в программе
[02:02:22.860 --> 02:02:31.780]  нет гонок. Собственно, может я откачусь далеко назад и прокомментирую один момент.
[02:02:37.740 --> 02:02:53.620]  Будь здоров. Мы говорим, что модель памяти это контракт, и пользователь, он, если он соблюдает свою
[02:02:53.620 --> 02:03:01.060]  часть контракта, то есть он пишет коллекционно синхронизированный код, то компилятор и процессор
[02:03:01.060 --> 02:03:09.420]  дадут ему видимость по следовательному исполнению. И вот сейчас мы на месте процессора,
[02:03:09.420 --> 02:03:18.460]  где мы были, на месте процессора и компилятора мы сейчас полагаем, что программист не накосячил,
[02:03:18.460 --> 02:03:30.940]  и в программе нет гонок. Тогда посмотрим на поток T штрих. Вот когда он может увидеть одну из
[02:03:30.940 --> 02:03:39.620]  записей W вот этих вот? Только тогда, когда он же в другом потоке находится. В смысле, T штрих,
[02:03:39.620 --> 02:03:47.300]  другой поток, он может эти записи увидеть неатомарные только если реализуется happens
[02:03:47.300 --> 02:03:54.580]  before, иначе будет датарейс. Чтобы реализовался happens before, нужно, чтобы реализовался
[02:03:54.580 --> 02:04:02.100]  synchronizes with. То есть поток T штрих сможет увидеть эти записи только после того,
[02:04:02.100 --> 02:04:10.180]  как он синхронизируется через атомик. Но когда он это сделает просто по свойствам видимости
[02:04:10.180 --> 02:04:17.060]  записей через чтение, видимости записи через happens before, этому потоку доступны все записи.
[02:04:17.060 --> 02:04:25.940]  Вот здесь вот. Понимаете? То есть он их получает разом. Когда он их может читать,
[02:04:25.940 --> 02:04:33.300]  он должен видеть уже все записи. Это означает, что он не может наблюдать их относительный порядок.
[02:04:33.300 --> 02:04:40.980]  А это означает, что компилятор и процессор вот эти записи между обращениями к атомику может
[02:04:40.980 --> 02:04:47.740]  приордерить. Код программа без гонок не сможет наблюдать относительный порядок этих записей.
[02:04:47.740 --> 02:04:59.280]  Это мы знаем просто из заключенного контракта. Так мы договорились с самого начала. И это супер
[02:04:59.280 --> 02:05:08.380]  важно, потому что, смотрите, процессор, ну, представьте себе, у вас есть сложная программа,
[02:05:08.740 --> 02:05:15.180]  какие-то потоки запускаются на разных ядрах. А процессор, когда он молотит инструкции,
[02:05:15.180 --> 02:05:21.780]  он видит, не знаю, только маленькое окошко этих инструкций. Он не знает, как перестановка двух
[02:05:21.780 --> 02:05:27.100]  инструкций повлияет на вашу программу. Понятия не имеет. И компилятор, когда он компилирует ваш код,
[02:05:27.100 --> 02:05:32.060]  он же компилирует его независимо для разных единиц трансляции и не понимает, как потоки будут
[02:05:32.060 --> 02:05:40.980]  по ним бегать. Так вот, в силу вот такого вот построения, в силу наших гарантий, компилятор
[02:05:40.980 --> 02:05:47.460]  и процессор могут выполнять свои оптимизации локально. Вот процессор может риордерить
[02:05:47.460 --> 02:05:53.620]  инструкции в окрестности просто не переходя через барьеры. И он знает, что он глобально не нарушит
[02:05:53.620 --> 02:06:01.100]  никаких свойств. Это очень важно, потому что мало что-то придумать. Нужно придумать то,
[02:06:01.100 --> 02:06:06.700]  что потом можно воплотить в реальной жизни. Вот наши гарантии получились хорошими, они вот очень
[02:06:06.700 --> 02:06:15.380]  просто воплощаются в жизни. Запись в Atomic, видимо, будет снабжена барьером, и процессор не захочет
[02:06:15.380 --> 02:06:25.500]  через этот барьер риордерить эти записи. Но это все только, конечно, для программ, в которых нет
[02:06:25.500 --> 02:06:31.020]  гонок. Для других мы никаких гарантий не даем. Ну и все это очень похоже на Atomic на самом деле,
[02:06:31.020 --> 02:06:40.020]  на Atomic и на Mutex. Вот точно так же, как, не знаю, компилятор или процессор не могут выкидывать
[02:06:40.020 --> 02:06:47.060]  записи из критической секции, это было бы странно. Также мы не можем выкинуть, передвинуть эти записи
[02:06:47.060 --> 02:06:57.980]  до или после этой записи или до этого чтения. До этого чтения не знаю. Ну короче, критические секции
[02:06:57.980 --> 02:07:05.940]  и фрагменты кода между чтениями и записями в Atomic — это очень похожие сущности. И, скажем,
[02:07:06.140 --> 02:07:14.060]  памяти Java примерно одинаково их рассматривает. А что я вас этому убираю? Давайте покажу.
[02:07:14.060 --> 02:07:29.100]  Вот Synchronize the Swiss в Java, оно возникает между записью в volatile Atomic и чтением этого Atomic,
[02:07:29.100 --> 02:07:36.180]  который видит эту запись, или между Unlock и последующим Lock. В общем, вещи довольно похожи,
[02:07:36.180 --> 02:07:44.180]  трактуется одинаково. Ну вот и все. Смотрите, что мы получили. Что мы, программисты, пишем
[02:07:44.180 --> 02:07:50.460]  корректно синхронизированную программу, программу без гонок. Мы аннотируем переменные,
[02:07:50.460 --> 02:07:55.300]  через которые синхронизируются потоки с помощью Atomic, а дальше компилятор в соответствии с
[02:07:55.300 --> 02:07:59.860]  этими аннотациями, зная, что вот Atomic — это ячейки памяти, через которые будет
[02:07:59.860 --> 02:08:04.180]  выполняться синхронизация, генерирует в машинном коде, ставит в генерируемом
[02:08:04.180 --> 02:08:08.380]  машинном коде барьеры. А дальше процессор реордерит инструкции, но аккуратно,
[02:08:08.380 --> 02:08:16.900]  не выходя за границы этих самых барьеров. И вот если никто не ошибся, то мы получаем видимость
[02:08:16.900 --> 02:08:22.900]  последовательного исполнения и получаем реордеринги. И вот это наша цель, которую мы
[02:08:22.900 --> 02:08:33.180]  пытались достичь. Да? Но вы же пришли сюда не за этим. Я же знаю, зачем вы пришли. Вы
[02:08:33.180 --> 02:08:42.620]  хотите писать memory order в программе. Я напомню, что лучше не умничать, как говорит нам Го. То есть
[02:08:42.620 --> 02:08:46.980]  если вы не пишете memory order, то с вами плохого не случится никогда ничего. Вы не ошибетесь.
[02:08:46.980 --> 02:08:56.020]  Точнее ошибиться гораздо сложнее становится. Но, допустим, вы профессионал и вот хотите написать
[02:08:56.020 --> 02:09:02.300]  какой-то memory order. Какие у вас есть варианты? Ну, у вас есть sequential consistency и у вас есть более
[02:09:02.300 --> 02:09:09.620]  слабые, там более-менее три ступени, три с половиной. Sequential consistency — release plus
[02:09:09.620 --> 02:09:19.100]  acquire или relax. И вот когда вы хотя бы в одном месте программы сбавляете memory order,
[02:09:19.100 --> 02:09:26.660]  делаете его слабее, чем sequential consistency, то вы попадаете в дивный мир слабых модели памяти.
[02:09:26.660 --> 02:09:36.260]  Модели памяти мы называем слабой, если она допускает не sequential consistency исполнение. То
[02:09:36.300 --> 02:09:41.420]  есть если вы хотя бы в одном месте выбрали более слабый memory order, то вы больше не можете
[02:09:41.420 --> 02:09:45.740]  пользоваться моделью чередований. Нет, вы можете, конечно, пользоваться, но это будет неправильно.
[02:09:45.740 --> 02:09:54.260]  Но с другой стороны, вы даете процессору гораздо больше свободы для reordering. В этом и мотивация
[02:09:54.260 --> 02:10:03.020]  более слабых моделей памяти. Это, конечно, хорошо, что у процессора больше возможностей для
[02:10:03.020 --> 02:10:12.100]  reordering. Но как вам-то жить с этим всем? Вам нужны какие-то разумные гарантии. И зачем я в
[02:10:12.100 --> 02:10:19.460]  лекции про деталь реализации sequential consistency рассказывал? Потому что все, что мы придумали,
[02:10:19.460 --> 02:10:25.980]  дальше используется в определении гарантий вот этих самых memory orders. Если мы говорим про
[02:10:25.980 --> 02:10:32.340]  sequential consistency атомики, то мы получаем synchronization order на них plus happens before. Плюс они участвуют
[02:10:32.340 --> 02:10:39.860]  в возникновении happens before. Если мы используем пару release plus acquire, release в записях,
[02:10:39.860 --> 02:10:46.780]  acquire в чтениях, то мы лишаемся глобального порядка на атомиках, его больше нет. Давайте покажу.
[02:10:46.780 --> 02:10:54.420]  Вот программа, которая работает корректно. Это storebuffering k5. Два атомика, пишем, читаем,
[02:10:54.420 --> 02:11:05.100]  запускаем. Она сломается, потому что это не та программа. Запускаем, и она не ломается. Ну, в смысле,
[02:11:05.100 --> 02:11:14.300]  это нужно проверить в конечное время, но она не сломается. Три, два, один, хватит. А теперь мы
[02:11:14.300 --> 02:11:43.740]  поставим memory order, который минимально слабее, чем то, что было, и запустим. И довольно
[02:11:43.740 --> 02:11:49.940]  быстро сломалось. Ну вот, мы лишили synchronization order, но при этом на каждом атомике по-прежнему есть
[02:11:49.940 --> 02:11:58.020]  modification order, и по-прежнему release, запись и acquire чтения участвуют в образовании отношения
[02:11:58.020 --> 02:12:06.620]  synchronizes with, то есть happens before. Но если мы говорим про relax, то там только modification order,
[02:12:06.620 --> 02:12:13.300]  то есть мы по чтению relax атомика вообще не можем судить о состоянии других ячеек
[02:12:13.300 --> 02:12:19.420]  памяти в программе. То есть мы только знаем про историю одного атомика, одной ячейки памяти.
[02:12:19.420 --> 02:12:28.260]  И тут вот теперь, кажется, мы готовы решить задачу минуток spin lock, наконец. Настал тот
[02:12:28.260 --> 02:12:35.660]  момент. Вот теперь, если вы задаете задачу spin lock с этого момента, то от вас ожидается знание
[02:12:35.660 --> 02:12:41.380]  ответов на оба вопроса. А именно, какой memory order вы написали и какой будет оптимарин.
[02:12:41.380 --> 02:12:47.100]  И смотрите, тут очень важный момент есть, что вот почему оптимарин выделен нажирным,
[02:12:47.100 --> 02:12:54.940]  потому что зачем в модели памяти C++ есть слабые memory order, слабее, чем default,
[02:12:54.940 --> 02:13:00.620]  sequential consistency, чтобы вы могли оптимизировать программу. Ну вот вы оптимизируете программу
[02:13:00.620 --> 02:13:06.020]  в декларативной модели, то есть вы выбираете просто наиболее слабые memory order, то есть memory
[02:13:06.020 --> 02:13:13.300]  order, которые порождают наименьшее количество ограничений стрелочек. И вот модель хорошая,
[02:13:13.300 --> 02:13:21.420]  если она хорошо описывает реальность. То есть задумка слабых моделей вот этих memory
[02:13:21.420 --> 02:13:28.180]  order в C++ такова, что если вы оптимизируете программу в декларативной модели, то,
[02:13:28.180 --> 02:13:32.540]  скомпилировав ее на конкретном процессоре, конкретным компилиатором, вы получаете,
[02:13:32.540 --> 02:13:39.580]  видимо, оптимальное решение в смысле барьеров. Ну, по крайней мере, такая задумка. Вот реализуется
[02:13:39.580 --> 02:13:49.980]  она не всегда, но люди над этим работают условно. Это такой совместный процесс, должны и разработчики
[02:13:49.980 --> 02:13:58.620]  модели памяти, и разработчики процессоров друг на встречу другу идти. Правда, у этих слабых
[02:13:58.620 --> 02:14:10.220]  моделей памяти есть довольно любопытные… Ну, как это назвать? Короче, когда вы в модели
[02:14:10.220 --> 02:14:16.620]  памяти встраиваете вот такие слабые memory order, то вместе с ними в модели памяти проникают довольно
[02:14:16.620 --> 02:14:26.220]  странные программы. Вот смотрите программы. Читаем из XA с релаксом, а потом, если прочли 42,
[02:14:26.220 --> 02:14:36.460]  то пишем в Y42. Поток второй читает из Y значение с помощью memory order relaxed, а потом, если прочел
[02:14:36.460 --> 02:14:46.380]  42, то пишет 42. Было бы странно от этой программы… И пусть вначале нули в программе. Было бы странно
[02:14:46.380 --> 02:14:57.820]  ожидать исполнения, которое породит нам два чтения 42. Вот. Ну, это такое самозбывающееся пророчество,
[02:14:57.820 --> 02:15:03.260]  так и называется этот сценарий. И как и любое… Ну, то есть самозбывающееся пророчество – это такое
[02:15:03.260 --> 02:15:11.300]  общее понятие, и оно сбивает с толку, потому что оно бессмысленно. И вот здесь оно бессмысленно,
[02:15:11.300 --> 02:15:17.780]  и в этом проблема. Но, к сожалению, гарантий формальных моделей памяти оказывается недостаточно,
[02:15:17.780 --> 02:15:24.940]  чтобы такую программу запретить, такое исполнение запретить. И поэтому в стандарте просто захардкожено,
[02:15:24.940 --> 02:15:40.500]  что вот таких исполнений… Таких исполнений, говорят, не бывает. Ну, представьте, что про каждую
[02:15:40.500 --> 02:15:45.660]  программу был бы пункт стандарта. Это было бы довольно утомительно. Кажется, мы запрещаем
[02:15:45.660 --> 02:15:50.100]  исполнение с помощью порядков частичных. Но вот их не хватает, чтобы такую программу запретить.
[02:15:50.100 --> 02:15:58.020]  Ну, точнее, тут сложная история. Я на семинаре однажды расскажу про это. Но в этом беда. И эта
[02:15:58.020 --> 02:16:02.380]  беда, она не решается. Ну, то есть вот просто есть фундаментальная проблема, такой барьер,
[02:16:02.380 --> 02:16:07.220]  который, кажется, не преодолеть в рамках текущего подхода к моделям памяти.
[02:16:07.220 --> 02:16:21.260]  Там можно решить несуществующую в реальности проблему, замедляв существующую в реальности
[02:16:21.260 --> 02:16:28.660]  программы. Так делать не будут. А теоретически запретить нельзя, потому что запрещать нужно
[02:16:28.660 --> 02:16:33.820]  программы о модели памяти запрещает исполнение. Вот она работает на другом масштабе. Поэтому там
[02:16:33.820 --> 02:16:40.940]  вот беда. Там нужно придумать другую модель памяти совсем. Там не чинится релаксными. По
[02:16:40.940 --> 02:16:46.740]  поводу реализации. Вот мы придумали все это, а теперь нужно эти гарантии воплотить в реальности.
[02:16:46.740 --> 02:16:53.940]  Кто этим занимается? Этим занимается компериатор в схеме компериации. Вот мы идем в Godbolt,
[02:16:53.940 --> 02:17:00.220]  который мне сегодня все стер, и то, что он не стер, смотрим. Вот разные варианты записи,
[02:17:00.220 --> 02:17:06.020]  sequential consistency, release, relaxed, и можно посмотреть, во что они компилируются. Собственно,
[02:17:06.020 --> 02:17:11.460]  так и предлагалась задачу спинлог решать. Правда, вы тут видите странные вещи, что,
[02:17:11.460 --> 02:17:16.900]  скажем, release и relaxed компилируются в один и тот же простой мув, но из этого, конечно,
[02:17:16.900 --> 02:17:23.580]  не следует, что можно их заменить друг на друга. Уж у них гарантии разные. Просто на конкретном
[02:17:23.580 --> 02:17:28.740]  процессоре реализации совпали, но другом могут не совпасть. Ну, давайте я сейчас не буду проверять,
[02:17:28.740 --> 02:17:38.940]  это точно так, вы можете выбрать в какой-нибудь ARM посмотреть. И вот обратите внимание, атомики,
[02:17:38.940 --> 02:17:45.260]  я на первой лекции, кажется, про это говорил, атомики на первый взгляд про то, чтобы получить
[02:17:45.260 --> 02:17:50.260]  доступ к каким-то более сложным атомарным операциям, типа exchange, compare-exchange,
[02:17:50.260 --> 02:17:58.020]  fetch-add, fetch-sub. Вот атомики в C++ нужны не только для этого, а еще и для того, чтобы служить
[02:17:58.020 --> 02:18:04.900]  аннотацией для компилиратора, такой подсказкой ему, что вот в этом месте происходит синхронизация,
[02:18:04.900 --> 02:18:09.580]  и вот где-то в этом месте нужно расставить барьер. Вот мы подсказываем компилиратору,
[02:18:09.580 --> 02:18:18.900]  где нужно ставить барьер. То есть представление атомика и обычные ячейки в памяти одно и то же.
[02:18:18.900 --> 02:18:29.100]  Но не это важно, а то, какие барьеры памяти, какие специальные инструкции вокруг этих обращений
[02:18:29.100 --> 02:18:37.980]  разместит компилиратор. Ну ладно, все, последние слова, такое напутствие на будущее, очень важное
[02:18:37.980 --> 02:18:48.780]  для меня. Вот мораль этой лекции большая, что есть соблазн, когда вы думаете про исполнение со
[02:18:48.780 --> 02:18:55.740]  слабыми моделями памяти, думать про уреордеринге. Что может там с чем переупорядочиться? Где что
[02:18:55.740 --> 02:19:03.060]  застяло в сторбафере? Вот, пожалуйста, не рассуждайте так. Декларативная модель дает вам
[02:19:03.060 --> 02:19:09.180]  правильный подходящий инструмент. Она оперирует порядками, положительными гарантиями. Вот лучше
[02:19:09.180 --> 02:19:13.540]  быть оптимистом, чем пессимистом. Лучше верить, что что-то хорошее случается, чем ждать чего-то
[02:19:13.540 --> 02:19:23.420]  плохого от исполнения. К тому же все эти урдеринги, они свои для каждой архитектуры. А вот частичные
[02:19:23.420 --> 02:19:28.820]  порядки, которые зафиксированы в модели памяти, они для любой архитектуры, то есть они в стандарте
[02:19:28.820 --> 02:19:35.740]  языка. Вам не нужно думать про железо, которое под вами. Вот не думайте про барьеры, думайте
[02:19:35.740 --> 02:19:40.380]  про Happens Before. Это на первых парах вызывает некоторое сопротивление, но как только вы
[02:19:40.380 --> 02:19:47.660]  почувствуете, как этим пользоваться, то станет хорошо. А как именно нужно этим пользоваться? Ну,
[02:19:47.660 --> 02:19:53.740]  нужно просто добиваться Happens Before. Вот если у вас вы делаете запись в ячейку памяти в программе,
[02:19:53.740 --> 02:20:00.180]  пишите в буфер что-то, а потом из буфера читаете. Вот гарантируйте с помощью, собственно,
[02:20:00.180 --> 02:20:06.780]  описанных гарантий, что между записью и чтением в исполнении обязательно возникнет Happens Before.
[02:20:06.780 --> 02:20:12.620]  Если у вас есть конфликтующее обращение к неатомарным переменным, то гарантируйте,
[02:20:12.620 --> 02:20:18.180]  что в исполнении возникнет Happens Before. Прям гарантируйте это. Если вы гарантируете это,
[02:20:18.180 --> 02:20:23.220]  то все, вот вы получите предсказуемо работающую программу, предсказуемо работающую на любом
[02:20:23.220 --> 02:20:34.780]  железе. Но всегда можно это забить и не писать memory order и все будет еще проще. Так что если вы
[02:20:34.780 --> 02:20:46.500]  профессионал, то вы можете пробовать. Но тогда вы обязаны пользоваться вот этими гарантиями. Если
[02:20:46.500 --> 02:20:53.100]  вы ставите где-то Release и Acquire, то объясните мне, как возникает Happens Before и там, что с чем
[02:20:53.100 --> 02:20:58.420]  вы собираетесь упорядочивать. Какие неатомарные записи и какие неатомарные чтения. И вот только
[02:20:58.420 --> 02:21:06.220]  после этого можно верить, что вы поставили memory order разумно. Ну или можно вот их не ставить и
[02:21:06.220 --> 02:21:12.820]  жить в простой модели чередования. Это, в общем, тоже нормально. Ну и самое последнее. Что после этого
[02:21:12.820 --> 02:21:30.300]  всего можно почитать. Давайте в порядку. Я бы начал со статьи, которая не про то, как обо всем
[02:21:30.300 --> 02:21:38.020]  этом думать, а как раз про барьеры и риордеринги. Но я это на семинаре постараюсь еще объяснить. Но
[02:21:38.020 --> 02:21:46.140]  вот тут интуитивно объясняют на таком выдуманном не существующем процессоре с кэшами, какие
[02:21:46.140 --> 02:21:53.380]  оптимизации можно в протоколе когерентности делать над протоколом когерентности и как это приведет к
[02:21:53.380 --> 02:21:59.460]  риордерингам. И как появляются барьеры. То есть как возникает вся эта механика со store
[02:21:59.460 --> 02:22:06.780]  buffer, invalidation queue, memory barriers, чтобы понять, с чем мы боремся и с какими инструментами.
[02:22:06.780 --> 02:22:14.500]  И если вот эта железная реальность станет понятна, то дальше есть очень-очень хорошая статья. Вот это,
[02:22:14.500 --> 02:22:21.700]  или давайте я даже скажу, что вот это. Ее одной, наверное, хватит. Это цикл статей, которые в
[02:22:21.700 --> 02:22:32.540]  прошлом году написал Рассел Кокс, один разработчиков языка ГО. Он написал сначала про то, как... Ну,
[02:22:32.540 --> 02:22:38.100]  про железные модели памяти, про то, что делают процессоры, почему они что-то риордерят и как
[02:22:38.100 --> 02:22:45.620]  с этим жить. Какие там исполнения странные порождаются. А потом про то, как можно это все пытаться
[02:22:45.620 --> 02:22:54.580]  скрыть с помощью модели памяти sequential consistency для программ свободных отгонок от прикладного
[02:22:54.580 --> 02:22:59.180]  программиста, который не хочет знать про конкретные процессоры. И третья статья про то,
[02:22:59.180 --> 02:23:09.260]  как потом выдумывали конкретные модели памяти в ГО. Очень хороший цикл статей, очень простой,
[02:23:09.260 --> 02:23:14.660]  логичный, последовательный, прям как эта лекция, в смысле. Логика примерно такая же. Она такая же,
[02:23:14.660 --> 02:23:22.060]  потому что она разумная. Мне кажется, что это хорошее место, чтобы так начать и довольно
[02:23:22.060 --> 02:23:31.300]  глубоко можно закопаться. Там довольно сложно. Дальше мне кажется, что стоит посмотреть на модели
[02:23:31.300 --> 02:23:36.220]  памяти Java, потому что там все определения, которые были сегодня есть, они написаны просто подряд на
[02:23:36.220 --> 02:23:45.700]  одной страничке без всяких сложностей и вычурностей, как C++. Дальше, как это ни странно,
[02:23:45.700 --> 02:23:55.620]  я бы, возможно, рекомендовал почитать документ про модель памяти в ядре линукса. Он чудовищно
[02:23:55.620 --> 02:24:03.220]  сложный. Это не он вообще. Вот он. Он чудовищно сложный, чудовищно большой. Там этих частичных
[02:24:03.220 --> 02:24:08.980]  порядков раз, два, три, четыре, пять, шесть, семь. Ну, короче, десятки. Но это очень хорошее
[02:24:08.980 --> 02:24:15.460]  изложение, безумно хорошее. Оно совсем не про какие-то детали реализации, а именно про теорию. И
[02:24:15.460 --> 02:24:23.220]  тут очень последовательно, очень аккуратно, очень строго описывают именно теоретические построения.
[02:24:23.220 --> 02:24:30.420]  Как можно думать об исполнении в терминах каких-то порядков и аксиом, а не в терминах
[02:24:30.420 --> 02:24:44.340]  вот этих самых реордерингов. Дальше я бы посоветовал почитать статью, которая описывает,
[02:24:44.340 --> 02:24:52.180]  ну, скорее, состояние текущих моделей памяти, что с ними так и что с ними не так. Тоже довольно
[02:24:52.180 --> 02:24:57.420]  дружелюбная статья. Она, конечно, сложная. Там с нее начинать не стоит, но, может быть, вот вы до нее
[02:24:57.420 --> 02:25:06.420]  доберетесь. Там, в частности, есть пункт про то, почему возникает проблема вот с этими программами,
[02:25:06.420 --> 02:25:13.900]  там, с самосбывающимися пророчествами и с значениями из воздуха возникающими. Вот разбирается
[02:25:13.900 --> 02:25:21.220]  подробно, что идет не так, но мы на семинаре каком-то тоже об этом поговорим. И, наконец, после всего
[02:25:21.220 --> 02:25:26.460]  этого можно прочесть модели памяти C++ просто чтобы знать, как формально она устроена. Вы
[02:25:26.460 --> 02:25:35.220]  ничему не научитесь, вы скорее узнаете про какую-то страшную специфику C++. Это последнее место,
[02:25:35.220 --> 02:25:39.860]  по которому можно учиться моделям памяти, несмотря на то, что это более-менее стандартный,
[02:25:39.860 --> 02:25:48.140]  но стандартная модель для современных языков. Но в C++ она изложена душераздирающая, и вот я
[02:25:48.140 --> 02:25:55.420]  сегодня попытался изложить ее суть, пожертвовав некоторыми тонкостями, которые возникают
[02:25:55.420 --> 02:26:01.700]  и про которые, в общем-то, знать почти не нужно. Это, конечно, не совсем честно, но вот чтобы знать
[02:26:01.700 --> 02:26:08.140]  честно, в конце концов нужно прочесть стандарт. Но можно счастливо жить, писать хорошие
[02:26:08.140 --> 02:26:14.980]  оптимизированные программы и про некоторые тонкости, странности, не знать, пользоваться
[02:26:14.980 --> 02:26:22.140]  простым определением Happens Before. Просто не пишите Consume в программе, тогда все мои слова будут
[02:26:22.140 --> 02:26:37.540]  валидны. С одной стороны, да, с другой стороны, его просто нужно не писать не потому, что там
[02:26:37.540 --> 02:26:44.700]  что-то устарело, а просто вот не нужно его писать никогда. Пиши Acquire вместо него. Есть все-таки не
[02:26:44.700 --> 02:26:50.940]  совсем точный, но достаточно убедительный ответ, что ну просто не получилось ни одного автора
[02:26:50.940 --> 02:26:59.380]  компилятора правильно реализовать Consume. Ну вот ни у кого в мире не получилось. То есть в теории его
[02:26:59.380 --> 02:27:04.780]  придумали, в теории он такой классный и замечательный, там все написано в стандарте, а на практике он...
[02:27:04.780 --> 02:27:12.140]  Но он не классный и замечательный, потому что он изуродовал семантику C++. Да, пришлось пожертвовать неким
[02:27:12.140 --> 02:27:21.820]  некой простотой. Ну, Рома, да, он скрасил немного картину на мой вкус. Мне кажется, что модель памяти изуродована
[02:27:21.820 --> 02:27:27.660]  просто, а не просто пожертвовать красотой. Ее перекосило все из-за этого Consume. Но, в общем,
[02:27:27.660 --> 02:27:34.020]  может быть, это можно было пережить, если бы действительно из этого была польза, но польза не
[02:27:34.020 --> 02:27:40.100]  вышла, а вред остался. Поэтому просто не пишем Consume и можно тогда не думать про вот некоторые
[02:27:40.100 --> 02:27:47.820]  частные и очень уродливые случаи модели памяти C++. Может небольшой вопрос конкретно по C++.
[02:27:47.820 --> 02:27:59.260]  Почему модели памяти передаются как аргументы, а не как шаблонные параметры? Шаблонный параметр
[02:27:59.260 --> 02:28:07.460]  на чем? Ну, у лода и стора, допустим, можно сделать... у функции. У функции можно сделать шаблонные
[02:28:07.460 --> 02:28:13.340]  параметры. Я не знаю, мне кажется, это не очень принципиально. Если кто-то знает, может потом
[02:28:13.340 --> 02:28:23.260]  поделиться. Так исторически сложилось. Ну, вот да. Давайте считать, что так. Вы, смотрите,
[02:28:23.420 --> 02:28:32.900]  есть проблема в том, что вы можете написать там, не знаю, load с aquire. Ой, это будет хорошо, разумно.
[02:28:32.900 --> 02:28:38.140]  Вы можете написать load с release или store с aquire. Какие-то бессмысленные комбинации. Этот код скомпилируется,
[02:28:38.140 --> 02:28:45.580]  будет работать как-то. Не ведомо мне образом. Я не писал такой код. Вот. Ну, это еще одно BFC++.
[02:28:45.580 --> 02:28:51.140]  Хорошо бы, конечно, чтобы система типов запрещала вам делать неправильные вещи. Но не в этот раз.
[02:28:51.140 --> 02:28:59.900]  Ладно, всё. Спасибо большое, что были с нами. Вот я вроде бы рассказал самые-самые основы.
[02:28:59.900 --> 02:29:05.380]  Теперь с ними можно дальше жить, изучать детали. Мы на семинарах обсудим. Спасибо вам.
[02:29:05.380 --> 02:29:08.500]  И вам тоже спасибо. До свидания.
