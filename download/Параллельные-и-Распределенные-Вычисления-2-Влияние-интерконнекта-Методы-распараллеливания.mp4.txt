[00:00.000 --> 00:08.640]  Сегодня, наверное, будет немножко поскучнее, чем было
[00:08.640 --> 00:13.360]  в прошлый раз, потому что будут там определённые,
[00:13.360 --> 00:18.120]  с вашей стороны должны быть рассуждения, напряг.
[00:18.120 --> 00:19.120]  Ну посмотрим.
[00:19.120 --> 00:23.200]  Итак, мы в прошлый раз остановились на законе Амдала, который
[00:23.200 --> 00:29.760]  говорит о том, что если у нас не вся программа, не
[00:29.760 --> 00:33.080]  весь алгоритм может быть распараллелен, то существуют
[00:33.080 --> 00:38.280]  определённые не то что трудности, но отклонения,
[00:38.280 --> 00:43.800]  скажем так, нашего графика ускорения возможного от
[00:43.800 --> 00:44.800]  идеального случая.
[00:44.800 --> 00:49.840]  Мы здесь рассматривали о том, что если альфа – это
[00:49.840 --> 00:53.760]  часть последовательного алгоритма, то к чему стремится
[00:53.760 --> 00:58.200]  ускорение в зависимости от степени параллелизации
[00:58.200 --> 00:59.200]  нашего алгоритма.
[00:59.200 --> 01:01.600]  Если часть, которая не может быть распараллелена,
[01:01.600 --> 01:06.320]  составляет, например, 10%, то есть альфа от 0,1, то у нас
[01:06.320 --> 01:10.240]  ускорение, сколько бы мы много ни брали вычислительных
[01:10.240 --> 01:15.400]  ядер, то есть решателей, не может быть больше, чем
[01:15.400 --> 01:16.400]  десятка.
[01:16.840 --> 01:18.640]  То есть это накладывает определённые ограничения
[01:18.640 --> 01:21.680]  на возможное ускорение.
[01:21.680 --> 01:30.240]  Но на само ускорение влияет не только та часть алгоритма,
[01:30.240 --> 01:32.880]  которая не может быть распараллелена, но ещё определённые другие
[01:32.880 --> 01:33.880]  факторы.
[01:33.880 --> 01:36.400]  Об этих факторах мы сейчас и поговорим.
[01:37.400 --> 01:51.400]  Второй причиной, которая влияет на ускорение, является
[01:51.400 --> 01:55.400]  в общем-то говоря та самая сеть, в которой соединены
[01:55.400 --> 01:56.800]  узлы в кластере.
[01:56.800 --> 02:03.040]  Поскольку вы будете большей частью проходить MPI, то, ещё
[02:03.040 --> 02:06.920]  раз повторяю, MPI в переводе или в расшифровке означает
[02:06.920 --> 02:11.720]  Message Person Interface, то есть это интерфейс передачи сообщений.
[02:11.720 --> 02:16.640]  Сообщения передаются между процессами, сами процессы
[02:16.640 --> 02:20.600]  работают на вычислительных ядрах, представим в голове,
[02:20.600 --> 02:25.080]  что наш кластер состоит из узлов, каждое узло это
[02:25.080 --> 02:28.560]  одно вычислительное ядро, представим себе именно
[02:28.560 --> 02:29.560]  так.
[02:29.560 --> 02:32.800]  И вот на таком ядре вычислительным работает процесс, поскольку
[02:32.800 --> 02:35.800]  все процессы они выполняют или решают какую-то одну
[02:35.800 --> 02:39.480]  большую задачу, то рано или поздно они должны обмениваться
[02:39.480 --> 02:40.800]  между собой информацией.
[02:40.800 --> 02:44.840]  И вот эта информация в виде переменных, в виде частей
[02:44.840 --> 02:48.400]  массивов, она передаётся между узлами, то есть между
[02:48.400 --> 02:52.440]  вычислительными ядрами, то есть между процессами
[02:52.440 --> 02:54.960]  и она передаётся по какой-то сети.
[02:54.960 --> 03:02.060]  Эта сеть называется интерконектом и она, конечно же, будет влиять
[03:02.180 --> 03:08.900]  на вообще время работы программы, потому что она требует
[03:08.900 --> 03:11.140]  время для передачи сообщений.
[03:11.140 --> 03:13.660]  Вот рассмотрим это влияние.
[03:13.660 --> 03:17.740]  Здесь сейчас мы на этом занятии будем рассматривать
[03:17.740 --> 03:21.140]  времена затрачиваемой программой в теоретическом плане, то
[03:21.140 --> 03:22.980]  есть мы будем представлять о том, сколько примерно
[03:22.980 --> 03:29.020]  тратится времени на вычисление какого-то числа, то есть
[03:29.020 --> 03:32.700]  мы будем говорить о времени выполнения какой-то арифметической
[03:32.700 --> 03:33.700]  операции.
[03:33.700 --> 03:37.500]  Конечно, мы не будем учитывать на самом деле время, затрачиваем
[03:37.500 --> 03:41.100]  на организацию цикла либо на времена считывания
[03:41.100 --> 03:45.220]  переменных из оперативной памяти, потому что в целом
[03:45.220 --> 03:49.140]  это не как рассмотрение без этого, рассмотрение
[03:49.140 --> 03:53.620]  просто какой-то арифметической операции в целом не накладывает
[03:53.620 --> 03:58.940]  каких-либо ограничений и вообще позволит нам определить
[03:59.860 --> 04:02.420]  характеристики алгоритма, то есть это не помешает нам
[04:02.420 --> 04:05.420]  это сделать.
[04:05.420 --> 04:07.420]  Поэтому мы там и архитектурные особенности какие-то не
[04:07.420 --> 04:08.420]  будем рассматривать.
[04:08.420 --> 04:13.260]  И вот если говорить о временах расчета, то мы просто будем
[04:13.260 --> 04:16.220]  например перемножать количество арифметических операций
[04:16.220 --> 04:17.980]  на время одной операции.
[04:17.980 --> 04:22.100]  Вот tau c это время одной операции, c это calculation, то
[04:22.100 --> 04:24.900]  есть tau c это время выполнения чего-то.
[04:24.900 --> 04:27.180]  Не будем тоже вдаваться в подробности, что там умножение
[04:27.420 --> 04:30.860]  это больше по времени чем сложение, деление больше
[04:30.860 --> 04:33.540]  чем умножение и так далее, просто мы делаем какие-то
[04:33.540 --> 04:35.820]  определенные оценки и в целом говорим о том, как
[04:35.820 --> 04:36.820]  алгоритм работает.
[04:36.820 --> 04:42.700]  А вот когда вы будете на семинаре, там вы можете
[04:42.700 --> 04:46.300]  уже измерять времена, реальное время работы программы.
[04:46.300 --> 04:49.340]  Примерно будет то же самое, конечно что-то будет отличаться,
[04:49.340 --> 04:53.460]  но в целом поведение алгоритма или вашей программы должно
[04:53.460 --> 04:56.380]  соответствовать теоретическому рассмотрению.
[04:57.180 --> 04:58.180]  В этом весь есть смысл.
[04:58.180 --> 05:01.700]  Итак, вы будете измерять как раз ускорение алгоритма
[05:01.700 --> 05:04.300]  и вообще говоря в первой задаче у вас алгоритм будет
[05:04.300 --> 05:06.420]  практически полностью распараллелен, то есть там
[05:06.420 --> 05:09.900]  альфа будет не очень большой, понятно, там будут какие-то
[05:09.900 --> 05:14.580]  определенные действия, направленные на выделение
[05:14.580 --> 05:19.140]  памяти, организацию тех же циклов, это нельзя распараллелить,
[05:19.140 --> 05:23.020]  но большая часть нагрузки вполне подвержена распараллеливанию,
[05:23.020 --> 05:25.060]  поэтому ожидается, что альфа будет маленький, не
[05:25.060 --> 05:30.060]  очень большой, но так или иначе у вас при различных
[05:30.060 --> 05:33.340]  запусках могут быть различия в ускорении, и вот на это
[05:33.340 --> 05:36.380]  влияет как раз сеть, интерконнект.
[05:36.380 --> 05:37.380]  Да.
[05:37.380 --> 05:42.380]  А в каких единицах ускорение принтое измеряет скорость
[05:42.380 --> 05:43.380]  программы?
[05:43.380 --> 05:44.380]  Здесь скорость программы, сейчас мы к этому как раз
[05:44.380 --> 05:47.340]  об этом поговорим, естественно не в километрах в час, а
[05:47.340 --> 05:50.820]  в чем-то другом, что значит скорость программы.
[05:50.820 --> 05:56.980]  Итак, если вы вспомните определение, ускорение,
[05:56.980 --> 06:00.700]  то оно было вот на прошлом занятии, на прошлой неделе.
[06:00.700 --> 06:04.500]  Ускорение напоминает отношение времени работы программы
[06:04.500 --> 06:07.940]  на одном вычислительном ядре ко времени работы программы
[06:07.940 --> 06:12.780]  на нескольких вычислительных ядрах, это основная характеристика
[06:12.780 --> 06:16.460]  вашей программы, параллельной программы, и вот это наверное
[06:16.460 --> 06:19.580]  связано с вашим вопросом, что такое скорость работы
[06:19.580 --> 06:20.580]  программы.
[06:20.580 --> 06:22.460]  Здесь не сама по себе скорость или на самом деле время работы
[06:22.460 --> 06:25.100]  программы интересно, а интересное ускорение, которое
[06:25.100 --> 06:27.820]  достигается при работе вашей параллельной программы
[06:27.820 --> 06:30.540]  на какой-то многопроцессорной машине.
[06:30.540 --> 06:33.300]  Нужно просто понять, с чем оно сравнивается.
[06:33.300 --> 06:36.780]  Оно в этом время меньше по сравнению с чем?
[06:36.780 --> 06:40.180]  По сравнению с временем работы на одном ядре, то
[06:40.180 --> 06:43.420]  есть со временем работы последовательного алгоритма.
[06:43.420 --> 06:46.020]  Мы сейчас тоже оставляем за скобками, лучший ли это
[06:46.020 --> 06:49.300]  алгоритм или неху, или не лучший.
[06:49.300 --> 06:53.620]  Вообще можно сравнивать с лучшим последовательным
[06:53.620 --> 06:56.740]  вашу параллельную программу, потому что не самый лучший
[06:56.740 --> 06:58.860]  последовательный хорошо параллелится, я об этом
[06:58.860 --> 06:59.860]  тоже упоминал.
[06:59.860 --> 07:05.340]  На самом деле ваша параллельная программа, которая может
[07:05.340 --> 07:07.660]  достигать хорошего ускорения, она может быть основана
[07:07.660 --> 07:11.540]  на каком-то другом последовательном алгоритме, не самом лучшем,
[07:11.540 --> 07:15.260]  но при этом показывает хорошие характеристики по ускорению.
[07:15.260 --> 07:21.100]  В данном случае у вас будет одна и та же программа,
[07:21.100 --> 07:24.020]  если говорить о практических занятиях, поэтому вы будете
[07:24.020 --> 07:26.780]  сравнивать именно саму программу с собой, просто
[07:26.780 --> 07:30.980]  запущенная на разных вычислительных ядах, на разном количестве.
[07:30.980 --> 07:34.300]  На этом давайте остановимся пока что.
[07:34.300 --> 07:38.980]  Допустим, требуется посчитать сумму массива, что у вас
[07:38.980 --> 07:39.980]  будет.
[07:39.980 --> 07:42.820]  У вас массив из n элементов, если n достаточно большое,
[07:42.820 --> 07:46.180]  то время работы на одном ядре можно оценить примерно
[07:46.180 --> 07:49.380]  как перемножение количества элементов на количество
[07:49.380 --> 07:51.100]  выполняемых арибметических операций.
[07:51.100 --> 07:57.900]  Здесь мы, конечно, поточнее не можем все учесть, и здесь
[07:57.900 --> 08:03.060]  n-1 вообще теряется на фоне возможных других накладных
[08:03.060 --> 08:06.260]  расходов, в том числе и на фоне количества.
[08:06.260 --> 08:10.940]  А у нас эти все операции независимые, поэтому мы
[08:10.940 --> 08:14.420]  можем, вообще говоря, посчитать отдельные частичные
[08:14.420 --> 08:18.260]  суммы на отдельных решателей.
[08:18.260 --> 08:20.620]  Вот таких решателей, то есть вычислительных ядер,
[08:20.620 --> 08:25.460]  может быть P, processes, поэтому в идеальном случае у нас
[08:25.460 --> 08:29.260]  время просто делится на P, так, и получается, что у
[08:29.260 --> 08:33.300]  нас n tau c поделить на P, это в идеальном случае.
[08:33.300 --> 08:36.380]  Нам требуется рассмотреть еще влияние интерконнекта,
[08:36.380 --> 08:40.380]  то есть как сеть влияет на наше время, на наше ускорение.
[08:41.300 --> 08:45.580]  К этому времени расчета, то, что нам посчиталось,
[08:45.580 --> 08:48.660]  нужно прибавить время передачи сообщений.
[08:48.660 --> 08:50.460]  Зачем это нужно?
[08:50.460 --> 08:54.060]  Потому что частичные результаты, они будут находиться в
[08:54.060 --> 08:57.860]  памяти каждого из процессов, а нужно бы получить кому-то
[08:57.860 --> 08:58.860]  одному.
[08:58.860 --> 09:03.260]  Ну представим еще и сейчас, что эти процессы одновременно
[09:03.260 --> 09:08.260]  ему передают, идеальный случай, они одновременно
[09:08.260 --> 09:12.900]  передают и множество посылок, их будет тоже P-1, но пусть
[09:12.900 --> 09:16.540]  будет их P, неважно, они одновременно происходят
[09:16.540 --> 09:20.420]  и поэтому время, затрачиваемое на передачу будет tau s, s это
[09:20.420 --> 09:21.420]  sending.
[09:21.420 --> 09:22.420]  Да.
[09:22.420 --> 09:27.620]  Немного конфликта в значении голове, tau c это время выполнения
[09:27.620 --> 09:32.940]  одной операции сложения, а tau s это время передачи
[09:32.940 --> 09:33.940]  информации.
[09:33.940 --> 09:35.420]  Нет, просто одной передачи.
[09:35.420 --> 09:37.220]  А почему у тебя такая формула?
[09:37.220 --> 09:39.900]  Я только что об этом сказал, вы когда тянули руку, вы
[09:39.900 --> 09:41.380]  наверно немножко отвлеклись.
[09:41.380 --> 09:43.940]  Почему она одна, а не может объединиться?
[09:43.940 --> 09:45.700]  Потому что я говорю, что они одновременно это делают.
[09:45.700 --> 09:47.500]  Представим, что они это делают одновременно.
[09:47.500 --> 09:49.940]  Если они это делают одновременно, значит это затрачивает.
[09:49.940 --> 09:53.620]  То есть, их последовательность, это чрезвычайно.
[09:53.620 --> 09:55.820]  Просто представим, что сейчас они происходят передачи
[09:55.820 --> 09:56.820]  одновременно.
[09:56.820 --> 10:01.020]  Не последовательно они передают, но если передача
[10:01.020 --> 10:04.100]  происходит одновременно, значит это затрачивается
[10:04.100 --> 10:05.100]  время одно.
[10:05.100 --> 10:10.900]  Ну, смотрите, вот, например, хорошо, просто вы стреляете
[10:10.900 --> 10:11.900]  из лука.
[10:11.900 --> 10:17.020]  Вот если один раз стрельнули, то полет стрелы будет tau.
[10:17.020 --> 10:19.260]  Если десять лучников стоит и стреляют на одно и то
[10:19.260 --> 10:21.500]  же расстояние, сколько будет время полета всех
[10:21.500 --> 10:25.660]  стрел, если они летят одновременно?
[10:25.660 --> 10:26.660]  Сколько?
[10:26.660 --> 10:27.660]  tau.
[10:27.860 --> 10:28.860]  Примерно то же самое.
[10:28.860 --> 10:34.340]  О том, что если это будет неодновременно, мы дальше
[10:34.340 --> 10:35.340]  пойдем.
[10:35.340 --> 10:36.340]  Сегодня это рассмотрим.
[10:36.340 --> 10:39.580]  Как организовывать пересылки.
[10:39.580 --> 10:40.580]  К этому вернемся.
[10:40.580 --> 10:45.100]  Но сейчас, пока для оценки, пока tau s.
[10:45.100 --> 10:46.100]  Хорошо?
[10:46.100 --> 10:47.100]  Отлично.
[10:47.100 --> 10:51.580]  Итак, у нас добавляется какая-то величина.
[10:51.580 --> 10:56.980]  Тогда у нас ускорение, t1 поделить на вот это tp, получим
[10:56.980 --> 11:00.300]  вот следующую формулу, делим просто на tau, на n tau c, тут
[11:00.300 --> 11:02.780]  единичка, тут единичка, и вот здесь у нас получается
[11:02.780 --> 11:05.420]  вот такая дробь в знаменателе.
[11:05.420 --> 11:08.700]  Вот, смотрите, теперь если tau s равно нулю, у нас нет
[11:08.700 --> 11:12.260]  интерконнекта, то наше ускорение равняется p, превращается
[11:12.260 --> 11:13.380]  в идеальный случай.
[11:13.380 --> 11:15.820]  Но у нас tau s не равняется нулю.
[11:15.820 --> 11:17.060]  Возникает вот такая дробь.
[11:17.060 --> 11:20.260]  n это наша задача, то есть сложность нашей задачи,
[11:20.260 --> 11:23.700]  а вот tau s на tau c это как раз характеристика вычислительной
[11:23.700 --> 11:24.700]  машины.
[11:24.700 --> 11:27.460]  tau s это характеристика временная интерконнекта,
[11:27.460 --> 11:30.180]  а tau c это характеристика временная вычислительного
[11:30.180 --> 11:31.180]  ядра.
[11:31.180 --> 11:32.180]  Насколько быстро оно считает.
[11:32.180 --> 11:37.460]  Ну, вот давайте оценим влияние этого интерконнекта.
[11:37.460 --> 11:40.220]  Значит, нам нужно оценить вот эту дробь, но это делается
[11:40.220 --> 11:41.220]  не очень сложно.
[11:41.220 --> 11:43.740]  Как можно оценить?
[11:43.740 --> 11:48.700]  Вот, смотрите, это характеристики интерконнекта, ну, не современного
[11:48.700 --> 11:52.220]  несколько лет назад, но примерно не сильно они стали
[11:52.220 --> 11:53.220]  быстрее.
[11:53.220 --> 11:59.260]  Значит, в основном существует таких две основные сети,
[11:59.260 --> 12:01.340]  которая называется Ethernet и InfiniBand.
[12:01.340 --> 12:03.940]  Сейчас используется InfiniBand, она побыстрее, но это тоже
[12:03.940 --> 12:07.140]  для оценки никак не испортит картину.
[12:07.140 --> 12:10.780]  Значит, что здесь, какие у нее характеристики основные?
[12:10.780 --> 12:12.460]  Первая это характеристика – это латентность.
[12:12.460 --> 12:18.300]  Здесь она есть, как пример для Ethernet это 50 микросекунд
[12:18.300 --> 12:19.300]  примерно.
[12:20.300 --> 12:24.940]  А для InfiniBand – 3-5 микросекунды.
[12:24.940 --> 12:28.620]  Латентность – это характеристика сети, о чем она говорит?
[12:28.620 --> 12:33.100]  Это время задержки между инициализацией пересылки
[12:33.100 --> 12:36.300]  и фактической пересылкой, началом фактической пересылки.
[12:36.300 --> 12:40.540]  То есть, мы говорим, нам нужно переслать что-то.
[12:40.540 --> 12:44.940]  Начинает идти время, пересылка не идет, время тратится,
[12:44.940 --> 12:48.180]  а потом спустя какое-то время латентности у нас начинается
[12:48.180 --> 12:49.380]  физическая пересылка.
[12:49.380 --> 12:53.740]  Как видно здесь, потом у нас еще пропускная способность.
[12:53.740 --> 12:56.980]  То есть, сколько за единицу времени мы можем передать
[12:56.980 --> 12:58.580]  мегабайт или килобайт.
[12:58.580 --> 13:02.980]  Здесь видно, что с увеличением размера данных для Ethernet
[13:02.980 --> 13:08.340]  время растет, а для InfiniBand это время растет, но не очень
[13:08.340 --> 13:09.340]  сильно.
[13:09.340 --> 13:11.820]  Поэтому передача нескольких килобайт на самом деле
[13:11.820 --> 13:14.660]  сильно на времени играет, поэтому мы можем сделать
[13:14.660 --> 13:16.900]  в качестве оценки латентность.
[13:16.900 --> 13:20.820]  Нам это будет достаточно.
[13:20.820 --> 13:21.820]  Еще раз формула.
[13:21.820 --> 13:29.860]  И вот смотрите, если у нас вот этот параметр дроби,
[13:29.860 --> 13:32.900]  если порядка единицы, то у нас очевидно ускорение
[13:32.900 --> 13:33.900]  будет меньше единицы.
[13:33.900 --> 13:39.460]  Мы его на самом деле особо не рассматриваем, потому
[13:39.460 --> 13:43.540]  что здесь бессмысленно использовать эту машину, она слишком
[13:43.540 --> 13:47.060]  медленная для нашей задачи, потому что TOS очень большой
[13:47.060 --> 13:48.060]  получается.
[13:48.060 --> 13:54.220]  Нам интересен случай, когда у нас все-таки немножко
[13:54.220 --> 13:55.220]  сеть побыстрее.
[13:55.220 --> 13:59.700]  Итак, про InfiniBand мы договорились, что будем брать латентность,
[13:59.700 --> 14:03.220]  и латентность у нас 5 микросекунд, значит, вот такая оценка
[14:03.220 --> 14:06.100]  для TOS получается, оценка для время передачи.
[14:06.100 --> 14:09.980]  Это вполне нормально, потому что килобайт это тысяча
[14:09.980 --> 14:10.980]  байт.
[14:10.980 --> 14:14.580]  Нужно посчитать, сколько можно передать, какой размер
[14:14.580 --> 14:17.300]  массива, за какое время.
[14:17.300 --> 14:20.620]  Если мы передаем одну, две, десять переменных, даже
[14:20.620 --> 14:27.060]  целого типа, или даже дабловского типа, то у нас вполне это
[14:27.060 --> 14:28.980]  все укладывается в оценку.
[14:28.980 --> 14:34.300]  Теперь нам нужно оценить TAU-C, это тоже несложно сделать.
[14:34.300 --> 14:35.300]  Правильно?
[14:35.300 --> 14:36.300]  Как можно сделать эту оценку?
[14:37.300 --> 14:40.460]  У нас есть числота игра.
[14:40.460 --> 14:43.500]  Да, тактовая числота процессора у нас есть, но этого тоже
[14:43.500 --> 14:46.100]  вполне достаточно, можно ее принять как основу.
[14:46.100 --> 14:47.940]  Считаем, что за один такт у нас произошла какая-то
[14:47.940 --> 14:49.740]  одна арифметическая операция.
[14:49.740 --> 14:51.740]  Какие частоты можно использовать?
[14:51.740 --> 14:52.740]  Один гигагерц.
[14:52.740 --> 14:57.660]  Ну, например, один, но поскольку у нас здесь пять, для удобства
[14:57.660 --> 14:59.860]  просто возьмем два гигагерца.
[14:59.860 --> 15:02.540]  Это не важно, это тоже особо.
[15:02.620 --> 15:08.180]  Если мы возьмем два гигагерца, то время вычисления одной
[15:08.180 --> 15:10.660]  арифметической операции будет обратной величины
[15:10.660 --> 15:14.180]  от нашей частоты, 5 на 10-то секунды.
[15:14.180 --> 15:22.220]  Ну, это очень маленькая величина, но теперь давайте
[15:22.220 --> 15:24.900]  подставим все эти значения вот в эту дробь и получим,
[15:24.900 --> 15:29.140]  что у нас, если одно на другое поделить, то это отношение
[15:29.140 --> 15:30.140]  10 тысяч получается.
[15:30.140 --> 15:38.060]  То есть у нас сеть медленнее, чем сам процессор 10 тысяч
[15:38.060 --> 15:39.060]  раз.
[15:39.060 --> 15:40.060]  Наших оценок.
[15:40.060 --> 15:42.540]  Сейчас сети побыстрее, может быть, тысяча будет,
[15:42.540 --> 15:45.380]  но так или иначе это составляет несколько порядков.
[15:45.380 --> 15:49.380]  А теперь смотрите, если у нас вот эта дробь хотя
[15:49.380 --> 15:54.140]  бы порядка единички, то оказывается, чтобы такое
[15:54.140 --> 15:57.940]  было при таком соотношении времен, нам нужно, чтобы
[15:57.940 --> 16:00.180]  СН было тоже примерно такого же порядка.
[16:00.180 --> 16:03.460]  То есть СН будет порядка 10 тысяч.
[16:03.460 --> 16:06.820]  То есть для того, чтобы у нас получить ускорение
[16:06.820 --> 16:12.500]  хотя бы около единички, величина нашего массива
[16:12.500 --> 16:16.420]  должна быть хотя бы тоже 10 тысяч элементов.
[16:16.420 --> 16:19.940]  И мы не рассматриваем там никакие другие накладные
[16:19.940 --> 16:22.500]  расходы, только сложение и вот пересылка и то, и пересылка
[16:22.500 --> 16:23.500]  одновременная.
[16:23.500 --> 16:27.900]  Значит, о чем это говорит?
[16:27.900 --> 16:30.940]  Какие отсюда выводы можно сделать?
[16:30.940 --> 16:33.260]  Первый очевидный вывод – это то, что наша сеть все-таки
[16:33.260 --> 16:34.260]  влияет.
[16:34.260 --> 16:37.820]  Потому что, если бы не было влияния, у нас не было
[16:37.820 --> 16:40.580]  бы вообще никаких ограничений на сложность нашей задачи.
[16:40.580 --> 16:42.540]  Это первое.
[16:42.540 --> 16:47.860]  Второе, если у нас есть какая-то машина, то на ней нужно
[16:47.860 --> 16:50.340]  решать, вообще-то говоря, довольно-таки сложные задачи.
[16:50.340 --> 16:53.580]  Вот представим, что здесь будет N, здесь в шестой,
[16:53.580 --> 16:55.580]  сюда подставляем, здесь вот эта величина будет
[16:55.580 --> 16:59.340]  10 минус второй, но она хотелось бы, чтобы была как можно
[16:59.340 --> 17:01.220]  меньше, поменьше, чем вот эта 1 на P.
[17:01.220 --> 17:03.740]  Если P там 10, ну вроде нормально.
[17:03.740 --> 17:05.620]  Если P 100, уже не очень хорошо.
[17:05.620 --> 17:09.300]  То есть, когда у нас P 100, это будет соизмеримые величины.
[17:09.300 --> 17:13.300]  Поэтому можно еще сделать меньше.
[17:13.300 --> 17:15.700]  Как меньше сделать вот эту дробь, увеличить N.
[17:15.700 --> 17:19.140]  То есть, все больше и больше сложной задачи.
[17:19.140 --> 17:22.620]  Чем задача сложнее, тем лучше будут параметры ускорения.
[17:22.620 --> 17:27.300]  Вот, по идее, вот это и в качестве лабораторной
[17:27.300 --> 17:29.820]  работы вам нужно будет провести на семинарах.
[17:29.820 --> 17:34.020]  У вас одна и та же будет программа, и нужно будет
[17:34.020 --> 17:37.820]  просто менять входящие параметры вашей задачи,
[17:37.820 --> 17:41.820]  менять ее сложность и смотреть, как будет меняться графику
[17:41.820 --> 17:46.820]  ускорения.
[17:46.820 --> 17:49.540]  Если же мы хотим хотя бы, ну хотя бы, а если равно
[17:49.540 --> 17:51.780]  P пополам, то что должно?
[17:51.780 --> 17:55.620]  Ну просто подставляем эту величину в нашу формулу.
[17:55.620 --> 17:58.460]  Тогда оказывается, что вот эта дробь у нас будет порядка
[17:58.460 --> 17:59.460]  1 на P.
[17:59.460 --> 18:00.460]  Что оказывается?
[18:00.460 --> 18:08.380]  Что N будет P умножить на 10 тысяч.
[18:08.380 --> 18:11.940]  Как я уже сказал, если десятка P равно десятке, то значит
[18:11.940 --> 18:16.420]  вот это 100 тысяч, а если P равно 100, значит N должно
[18:16.420 --> 18:19.900]  быть равно миллиону, хотя бы, хотя бы миллиону.
[18:19.900 --> 18:22.420]  Ну соответственно, чем больше ускорения, тем нужно
[18:22.420 --> 18:25.860]  побольше взять N.
[18:25.860 --> 18:36.100]  Какие здесь вопросы есть?
[18:36.100 --> 18:38.860]  Если нет вопросов, тогда следующий.
[18:39.860 --> 18:40.860]  Давайте.
[18:40.860 --> 18:45.860]  Довольно часто, если я правильно понимаю, когда речь идет
[18:45.860 --> 18:48.860]  о проникновениях, обычно, условно, компьютеры, которые,
[18:48.860 --> 18:52.860]  или процессоры, которые используются для них, слабее, чем те,
[18:52.860 --> 18:55.860]  которые используются для, если нужно что-то посчитать
[18:55.860 --> 18:56.860]  на нотэшену.
[18:56.860 --> 18:57.860]  На каком?
[18:57.860 --> 18:58.860]  На последовательном.
[18:58.860 --> 18:59.860]  На последовательном?
[18:59.860 --> 19:00.860]  На последовательном.
[19:00.860 --> 19:01.860]  На последовательном.
[19:01.860 --> 19:13.860]  Ну, во-первых, смотрите, я думаю, что это не совсем
[19:13.860 --> 19:17.860]  так бывает, потому что бывает...
[19:17.860 --> 19:21.860]  Короче, смысл такой, когда вы приходите на какую-то
[19:21.860 --> 19:24.860]  удаленную машину, скорее всего, она сделана не вчера,
[19:24.860 --> 19:28.860]  а несколько лет назад, скорее всего, потому что как только
[19:28.860 --> 19:30.860]  вложили какие-то средства, то вообще хотелось бы, чтобы
[19:30.860 --> 19:32.860]  они работали как можно дольше и дольше и дольше,
[19:32.860 --> 19:35.860]  и получать от них какую-то отдачу.
[19:35.860 --> 19:37.860]  Соответственно, это машине уже несколько лет, скорее
[19:37.860 --> 19:38.860]  всего.
[19:38.860 --> 19:41.860]  Скорее всего, на тот момент, когда она была создана,
[19:41.860 --> 19:42.860]  эти процессоры были нормальны.
[19:42.860 --> 19:46.860]  Они были на современном уровне, они были современными.
[19:46.860 --> 19:49.860]  Но когда прошло уже даже два, три, четыре года, и вы
[19:49.860 --> 19:53.860]  купили, например, свой ноутбук вчера, то, конечно же,
[19:53.860 --> 19:57.860]  современный ноутбук даже, он будет, процессор может
[19:57.860 --> 19:59.860]  быть мощнее, чем то, что было пять лет назад.
[19:59.860 --> 20:00.860]  Это вполне очевидно.
[20:00.860 --> 20:07.860]  Второй момент, что при создании такой машины все опять ограничивается
[20:07.860 --> 20:09.860]  какими-то финансами.
[20:09.860 --> 20:13.860]  Например, тот делал машину, у него есть какой-то бюджет,
[20:13.860 --> 20:15.860]  и он ориентируется на него.
[20:15.860 --> 20:18.860]  Сколько он может купить процессоров, ну и всю остальную
[20:18.860 --> 20:23.860]  обвязку, инфраструктуру на этот бюджет, и начинать
[20:23.860 --> 20:24.860]  размышлять.
[20:24.860 --> 20:26.860]  Купить мощнее процессоров, их должно быть поменьше,
[20:26.860 --> 20:30.860]  либо взять побольше по количеству, но они будут не
[20:30.860 --> 20:31.860]  такими мощными.
[20:31.860 --> 20:35.860]  И вполне возможно, что он изберет именно второй вариант.
[20:35.860 --> 20:39.860]  Взять побольше, но они могут быть не самыми мощными
[20:39.860 --> 20:40.860]  на тот момент.
[20:40.860 --> 20:42.860]  Но опять же, даже если он будет делать сегодня, то
[20:42.860 --> 20:45.860]  вполне возможно, что ваш ноутбук будет один на одном.
[20:45.860 --> 20:50.860]  Один процессор будет мощнее, чем процессор на той машине,
[20:50.860 --> 20:51.860]  которая строится.
[20:51.860 --> 21:06.860]  В целом, смотрите, конкретные числа, да, но в целом такое
[21:06.860 --> 21:07.860]  наблюдается.
[21:07.860 --> 21:10.860]  Это неважно, просто это будут другие цифры, другие
[21:10.860 --> 21:11.860]  показатели.
[21:11.860 --> 21:15.860]  Естественно, идет прогресс, и может быть через 5-10 лет,
[21:15.860 --> 21:18.860]  условно говоря, эта дробь будет не 10, а еще 100.
[21:18.860 --> 21:21.860]  Но так или иначе, эта сеть будет все равно медленнее,
[21:21.860 --> 21:22.860]  чем сам процессор.
[21:22.860 --> 21:24.860]  Просто цифры другие.
[21:24.860 --> 21:28.860]  Да, это будет лучше, конечно, к этому все стремятся,
[21:28.860 --> 21:30.860]  чтобы сеть делать побыстрее.
[21:30.860 --> 21:35.860]  Но даже, скажем так, шина, которая считывает данные
[21:35.860 --> 21:37.860]  с оперативной памяти, она все равно будет медленной
[21:37.860 --> 21:39.860]  по сравнению с самим процессором.
[21:39.860 --> 21:43.860]  Поэтому здесь паритета не будет.
[21:48.860 --> 21:49.860]  Что будет лучше?
[21:49.860 --> 21:52.860]  Несколько процессоров послабее или поменьше процессоров
[21:52.860 --> 21:53.860]  и посильнее?
[21:56.860 --> 21:57.860]  Зависит от задачи.
[21:57.860 --> 21:59.860]  Здесь так просто, очевидно, не ответишь.
[21:59.860 --> 22:02.860]  Ну, к примеру, просто пример такой.
[22:02.860 --> 22:05.860]  Если предполагать, что будет много народу работать,
[22:05.860 --> 22:10.860]  то хотелось бы, чтобы, скажем, 10 процессоров или 100,
[22:10.860 --> 22:12.860]  и 10 человек.
[22:12.860 --> 22:15.860]  Ну, наверное, 10 процессоров, но я не знаю.
[22:15.860 --> 22:17.860]  Наверное, чтобы, если много народу,
[22:17.860 --> 22:19.860]  то лучше бы побольше процессов,
[22:19.860 --> 22:22.860]  чтобы каждый человек сидел и что-то делал.
[22:22.860 --> 22:24.860]  Пусть это будет дольше, его задача решается,
[22:24.860 --> 22:26.860]  но зато все они.
[22:26.860 --> 22:28.860]  А если у вас один человек, ну, или там два человека,
[22:28.860 --> 22:30.860]  ну, наверное, они могут как-то договориться,
[22:30.860 --> 22:32.860]  использовать меньшее количество.
[22:32.860 --> 22:33.860]  Здесь просто так не скажешь.
[22:33.860 --> 22:35.860]  Еще какие задачи решаются?
[22:35.860 --> 22:41.860]  Здесь какого-то алгоритма или рецепта на все случаи жизни,
[22:41.860 --> 22:42.860]  наверное, не существует.
[22:42.860 --> 22:43.860]  Это по обстоятельствам.
[22:43.860 --> 22:47.860]  Ну, и вообще, от человека зависит, что ему больше нравится.
[22:47.860 --> 22:52.860]  В целом, конечно же, там за одни те же деньги,
[22:52.860 --> 22:59.860]  наверное, можно купить машину и в том, и в другом случае
[22:59.860 --> 23:01.860]  одинаковой производительности.
[23:01.860 --> 23:03.860]  Ну, наверное, или примерно одинаковой производительности.
[23:03.860 --> 23:05.860]  Здесь, наверное, разницы особо не будет.
[23:05.860 --> 23:07.860]  Ну, хотя где-то может комплектующими.
[23:07.860 --> 23:09.860]  И можно пожертвовать какими-то.
[23:09.860 --> 23:12.860]  В целом, наверное, разницы не будут.
[23:12.860 --> 23:13.860]  Ну, вот такие рассуждения.
[23:13.860 --> 23:18.860]  Ну, плюс, наверное, если это какое-то обвязка,
[23:18.860 --> 23:21.860]  может быть, чем дешевле, тем может быть меньше надежность.
[23:21.860 --> 23:23.860]  Здесь еще и надежность на это смотреть.
[23:23.860 --> 23:25.860]  Потому что машина будет на работу круглосуточно
[23:25.860 --> 23:27.860]  и месяцами, годами должна, по идее.
[23:27.860 --> 23:29.860]  Поэтому здесь еще нужно...
[23:29.860 --> 23:30.860]  Ну, много факторов, в общем.
[23:30.860 --> 23:32.860]  Трудно, сразу не скажешь.
[23:36.860 --> 23:37.860]  Еще есть вопросы?
[23:37.860 --> 23:40.860]  Так, давайте тогда перейдем вот к третьей причине,
[23:40.860 --> 23:42.860]  которая может влиять на ускорение.
[23:42.860 --> 23:45.860]  Здесь немножко будет формул и некая физическая задача,
[23:45.860 --> 23:48.860]  но на саму физику можно не смотреть,
[23:48.860 --> 23:50.860]  можно смотреть просто на уравнения.
[23:50.860 --> 23:52.860]  Этого будет достаточно.
[23:52.860 --> 23:54.860]  То есть смотрите просто на формулу и все.
[23:54.860 --> 23:56.860]  Но задача...
[23:56.860 --> 23:57.860]  Почему?
[23:57.860 --> 23:59.860]  Потому что здесь вот что важно.
[23:59.860 --> 24:02.860]  Ну, давайте я расскажу, а потом на этом заострю внимание.
[24:02.860 --> 24:05.860]  Значит, задача просто это нагретый стержень,
[24:05.860 --> 24:07.860]  представим себе горячий,
[24:07.860 --> 24:10.860]  и к двум концам одномерно задача, самая простая.
[24:10.860 --> 24:14.860]  И с левой справа к нему подсоединяются холодные резервуары,
[24:14.860 --> 24:16.860]  имеющие другую температуру, скажем так, ноль,
[24:16.860 --> 24:19.860]  а стержень нагрет до температуры 1.
[24:19.860 --> 24:21.860]  Ну, все мы знаем.
[24:21.860 --> 24:24.860]  И вот, например, у нас есть такой стержень,
[24:24.860 --> 24:28.860]  скажем так, ноль, а стержень нагрет до температуры 1.
[24:28.860 --> 24:30.860]  Ну, все мы знаем из нашего жизненного опыта.
[24:30.860 --> 24:32.860]  Что будет происходить со стержнем?
[24:32.860 --> 24:34.860]  Охлаждаться.
[24:34.860 --> 24:36.860]  Как будет охлаждаться?
[24:36.860 --> 24:38.860]  Постепенно.
[24:38.860 --> 24:39.860]  Постепенно, с двух сторон.
[24:39.860 --> 24:41.860]  С левой справа температура здесь будет,
[24:41.860 --> 24:43.860]  и здесь будет быстрее падать,
[24:43.860 --> 24:45.860]  а вот падение температуры к центру,
[24:45.860 --> 24:47.860]  оно произойдет несколько позднее.
[24:47.860 --> 24:48.860]  Какую?
[24:48.860 --> 24:50.860]  Ой, эта температура.
[24:50.860 --> 24:52.860]  Почему она 1?
[24:52.860 --> 24:53.860]  Ну, модальная задача.
[24:53.860 --> 24:54.860]  Почему?
[24:54.860 --> 24:55.860]  А какое другое?
[24:55.860 --> 24:57.860]  Любое другое значение – это неважно.
[24:57.860 --> 24:58.860]  Может...
[24:58.860 --> 24:59.860]  Смотрите.
[24:59.860 --> 25:01.860]  Синяя – это температура.
[25:01.860 --> 25:03.860]  Ноль резервуар.
[25:03.860 --> 25:04.860]  Один.
[25:04.860 --> 25:05.860]  Ноль.
[25:05.860 --> 25:07.860]  Синяя – это температура.
[25:07.860 --> 25:09.860]  Обознатил ее буквой У.
[25:09.860 --> 25:12.860]  Я так захотел, потому что Т у нас за время отвечает.
[25:12.860 --> 25:14.860]  Трудно, чтобы не спутать.
[25:14.860 --> 25:17.860]  L – это единичка, от нуля до единицы.
[25:17.860 --> 25:18.860]  А вот температура.
[25:18.860 --> 25:20.860]  Синяя – это график температуры.
[25:20.860 --> 25:21.860]  Все.
[25:21.860 --> 25:24.860]  И потом он будет как-то таким колокообразным.
[25:24.860 --> 25:27.860]  Вот такая задача.
[25:27.860 --> 25:30.860]  Каким уравнением описывается изменение температуры
[25:30.860 --> 25:31.860]  со временем?
[25:31.860 --> 25:35.860]  Вот таким уравнением, дифференциальным уравнением.
[25:35.860 --> 25:37.860]  Я не знаю...
[25:37.860 --> 25:38.860]  Нормально это или...
[25:38.860 --> 25:39.860]  Нормально.
[25:39.860 --> 25:40.860]  Хорошо.
[25:40.860 --> 25:42.860]  Теперь, для того, чтобы ее решить на машине,
[25:42.860 --> 25:44.860]  его нужно представить в виде...
[25:44.860 --> 25:46.860]  То есть каждую прозводную нужно представить в виде
[25:46.860 --> 25:48.860]  конечной разности.
[25:48.860 --> 25:50.860]  Это у вас, не знаю, было или не было,
[25:50.860 --> 25:53.860]  но вот эта прозводная представляется в виде
[25:53.860 --> 25:55.860]  такой конечной разности.
[25:57.860 --> 25:59.860]  Прозводной второго порядка представляется вот такой.
[25:59.860 --> 26:01.860]  Ну, откуда вот это берется?
[26:01.860 --> 26:02.860]  Что такое прозводная?
[26:02.860 --> 26:05.860]  Прозводная – это предел вот такого отношения,
[26:05.860 --> 26:07.860]  когда Тау стремится к нулю.
[26:07.860 --> 26:08.860]  Так?
[26:08.860 --> 26:09.860]  Мы убираем...
[26:09.860 --> 26:11.860]  То есть это будет тожественно равно.
[26:11.860 --> 26:14.860]  Мы теперь убираем этот лимит, то есть предел,
[26:14.860 --> 26:16.860]  и получается примерно.
[26:16.860 --> 26:18.860]  Наша прозводная равна вот такой разности.
[26:18.860 --> 26:20.860]  Это называется конечная разность.
[26:20.860 --> 26:21.860]  Почему?
[26:21.860 --> 26:23.860]  Потому что она не бесконечно малая.
[26:23.860 --> 26:25.860]  Она имеет какую-то конечную величину.
[26:25.860 --> 26:27.860]  Ну, а вторая прозводная – это разница двух вот таких
[26:27.860 --> 26:30.860]  прозводных, если сюда поставить там и плюс один...
[26:30.860 --> 26:33.860]  А, ну да, верхний индекс отвечает за время,
[26:33.860 --> 26:35.860]  если вы не в курсе.
[26:35.860 --> 26:40.860]  Нижний индекс отвечает за дискретизацию по пространству.
[26:40.860 --> 26:44.860]  То есть n – это текущая температура в настоящем,
[26:44.860 --> 26:47.860]  n плюс один – это то, что нужно найти в будущем.
[26:47.860 --> 26:51.860]  Если мы рассматриваем какую-то точку i,
[26:51.860 --> 26:55.860]  какую-то одну, то i плюс один – это точка правее,
[26:55.860 --> 26:57.860]  если у нас ось направлена вправо,
[26:57.860 --> 26:59.860]  i минус один – левее.
[26:59.860 --> 27:05.860]  И вот здесь h – это размер шага по пространству.
[27:05.860 --> 27:07.860]  Tau – размер шага по времени.
[27:07.860 --> 27:10.860]  Ну, это дельта t часто обозначается,
[27:10.860 --> 27:12.860]  а это дельта х.
[27:12.860 --> 27:14.860]  Это разнозначное.
[27:15.860 --> 27:18.860]  Ну, вторая производная получается как?
[27:18.860 --> 27:20.860]  Вот эти две производные,
[27:20.860 --> 27:23.860]  то есть здесь будет i плюс один минус i,
[27:23.860 --> 27:27.860]  а вторая производная i минус i минус один.
[27:27.860 --> 27:30.860]  Ну, и получается вот такая формула.
[27:30.860 --> 27:32.860]  Разница двух производных деленная на h тоже.
[27:32.860 --> 27:34.860]  И получается, что здесь h в квадрате,
[27:34.860 --> 27:36.860]  а здесь разница производных.
[27:36.860 --> 27:38.860]  Ну, в общем, подставьте, получите.
[27:38.860 --> 27:42.860]  Без предела получается примерное равенство.
[27:42.860 --> 27:44.860]  Теперь мы эти конечные разности подставляем сюда,
[27:44.860 --> 27:46.860]  потому что именно конечные разности
[27:46.860 --> 27:48.860]  используются машиной.
[27:48.860 --> 27:50.860]  Получаем вот такое уравнение.
[27:50.860 --> 27:52.860]  И теперь это самое простое уравнение.
[27:52.860 --> 27:54.860]  Это называется явная схема,
[27:54.860 --> 27:57.860]  когда слева отравна у нас одна величина,
[27:57.860 --> 27:59.860]  которую нужно найти,
[27:59.860 --> 28:02.860]  а справа отравна у нас получаются те величины,
[28:02.860 --> 28:05.860]  которые известны в данный момент времени.
[28:05.860 --> 28:09.860]  Вот нам теперь нужно выразить вот это неизвестное.
[28:09.860 --> 28:11.860]  Вот так мы выражаем,
[28:11.860 --> 28:15.860]  формула для вычисления температуры в будущем,
[28:15.860 --> 28:17.860]  если у нас известна температура в настоящем,
[28:17.860 --> 28:19.860]  в разных точках.
[28:19.860 --> 28:21.860]  А у нас известны температуры в самом начале,
[28:21.860 --> 28:23.860]  они все единички,
[28:23.860 --> 28:25.860]  поэтому в любой момент времени,
[28:25.860 --> 28:27.860]  то есть последовательно мы можем решать эту задачу
[28:27.860 --> 28:29.860]  и каждый раз на новом шаге по времени находить
[28:29.860 --> 28:31.860]  все распределение температур.
[28:31.860 --> 28:35.860]  И вот, значит, здесь, правда, есть определенные там условия,
[28:35.860 --> 28:37.860]  если будете там решать.
[28:37.860 --> 28:39.860]  Вот на этот множитель,
[28:39.860 --> 28:41.860]  условия куранта Фридрикса Леви,
[28:41.860 --> 28:43.860]  или коротко условия куранта,
[28:43.860 --> 28:45.860]  если у нас вот этот тао,
[28:45.860 --> 28:49.860]  или вот этот множитель будет меньше половинки,
[28:49.860 --> 28:51.860]  0,5,
[28:51.860 --> 28:53.860]  то у нас схема будет устойчивая.
[28:53.860 --> 28:55.860]  Если больше, то она будет неустойчива,
[28:55.860 --> 28:57.860]  но это пока особо вас не должно касаться.
[28:57.860 --> 28:59.860]  Ну и здесь коэффициенты.
[28:59.860 --> 29:01.860]  Как они называются?
[29:01.860 --> 29:03.860]  Это коэффициент температуры проводности,
[29:03.860 --> 29:05.860]  шаг по времени, шаг по пространству.
[29:05.860 --> 29:07.860]  И шаблон разноцветной схемы выглядит вот так.
[29:07.860 --> 29:09.860]  Это нам нужно знать,
[29:09.860 --> 29:11.860]  нужно представлять в голове,
[29:11.860 --> 29:13.860]  интересно было бы это представлять в голове.
[29:13.860 --> 29:15.860]  Почему?
[29:15.860 --> 29:17.860]  Потому что есть одна тонкость.
[29:17.860 --> 29:19.860]  Почему рассматривается именно такая задача?
[29:19.860 --> 29:21.860]  Так вот, еще раз.
[29:21.860 --> 29:23.860]  Чтобы найти температуру вот в этой точке i,
[29:23.860 --> 29:25.860]  нам нужно знать температуру в этой же точке n.
[29:25.860 --> 29:27.860]  В настоящем.
[29:27.860 --> 29:29.860]  И в соседних точках.
[29:29.860 --> 29:31.860]  И вот здесь оказывается
[29:31.860 --> 29:33.860]  как раз та самая тонкость.
[29:33.860 --> 29:35.860]  Почему рассматривается,
[29:35.860 --> 29:42.860]  почему вообще рассматриваем. Видите, что у нас шаблон именно вот такой, поэтому у нас есть
[29:42.860 --> 29:51.300]  определенные зависимости по данным. У нас, если мы теперь собираемся решать эту задачу на множестве
[29:51.300 --> 29:59.540]  вычислительных ядер, то у нас нельзя просто взять и поделить нашу область рассмотрения на части,
[29:59.540 --> 30:05.180]  как это было, например, в сумме массива. Почему? Потому что у нас вот есть эти зависимости.
[30:05.180 --> 30:12.700]  Вот допустим, есть у нас вот этот стержень и, допустим, есть один из точек, в которых мы
[30:12.700 --> 30:17.620]  смотрим температуру, но мы смотрим на концах маленьких отрезков, поделили, дискретизировали
[30:17.620 --> 30:24.940]  нашу область расчета, она простиралась от нуля до единицы. Если мы на 10 отрезочков поделим,
[30:24.940 --> 30:32.420]  у нас будет 10 отрезков и h будет равно 0,1. Потом просто договариваемся или там условно,
[30:32.420 --> 30:38.540]  где смотрится температура в центрах этих отрезков или на краях. Это не важно, на самом деле,
[30:38.540 --> 30:44.500]  это просто вопрос договоренности. Но здесь я захотел, например, взять с краев. Получается у
[30:44.500 --> 30:51.580]  нас 11 точек, 9 внутренних и 2 граничные. На граничных точках 0 будет, ну а в центре там как-то будет
[30:51.580 --> 31:02.180]  температура распределена. И что дальше? У нас получится 11 температур. Это тоже хорошо,
[31:02.180 --> 31:09.460]  это нечётное количество. Почему? Потому что нужно сейчас будет подумать. Если мы собираемся
[31:09.460 --> 31:19.260]  решать на двух ядрах, то как нужно поделить вот эти точки по процессам, чтобы они примерно,
[31:19.340 --> 31:25.340]  ну нагрузка у них была примерно одинаковая. Мы рассматриваем сейчас статическую балансировку
[31:25.340 --> 31:34.180]  нагрузки, так называется. Как нужно поделить 11 на 2? Ну сколько будет температура к одному относится
[31:34.180 --> 31:48.420]  процесс, а сколько к другому? По серединке это слишком обычно. Это будет 12. Тогда будет 9.
[31:48.420 --> 32:02.020]  Но как-то это нужно решать задачу? Только здесь 11, 8-8 это 16.
[32:04.180 --> 32:14.620]  Я, может быть, и догадываюсь, но все-таки без пересечений, хорошо. Специально для вас. Как
[32:14.620 --> 32:19.060]  поделить пополам, но без пересечений, потому что пересечения здесь они будут бессмысленные.
[32:19.060 --> 32:31.340]  Ну конечно. Такое в принципе возможно, но это будет в дальнейшем вы поймете, что это будет не
[32:31.340 --> 32:38.940]  совсем оптимально. Я об этом еще не сказал, но сразу скажу, что это будет неоптимально. Так можно
[32:38.940 --> 32:45.860]  было сделать для расчета, когда мы сумму массива рассматривали, типа расчесочкой такой. В принципе
[32:45.860 --> 33:07.660]  можно. Надеюсь, это не очень хорошо будет. Это не дурацкий, это самый лучший ответ. Я задаю простые
[33:07.660 --> 33:20.140]  вопросы. Вот мы сейчас к этому вернемся. Это не обязательно знать соседние. Сейчас мы поймете,
[33:20.140 --> 33:26.780]  почему. 6,5 это правильный ответ, но он правильный в одном случае. Он правильный в одном случае,
[33:26.780 --> 33:34.180]  если у нас эти вычислительные ядры примерно одинаковой мощности. Если же они у нас различны,
[33:34.180 --> 33:42.180]  то вполне возможно, что можно сделать 8,3, поделить на 8,3. 8 это если быстрее процессор работает,
[33:42.180 --> 33:48.540]  ну просто гипотетическая ситуация, а 3, который помедленнее. И вот можно уже заранее распределить.
[33:48.540 --> 33:53.820]  Ну скорее всего это просто гипотетическая, просто это маленькая такая ремарка о том,
[33:53.820 --> 34:00.620]  что мы делим примерно одинаково. Мы не можем 5,5 отдать одному 5,5 другому. Это целые числа,
[34:00.620 --> 34:12.660]  поэтому чтобы разница была плюс-минус один. Это нормально. Да, вопрос. Ну если они равные,
[34:12.660 --> 34:17.580]  то значит примерно и на равной части нужно делить. Но еще раз, чисто на равной мы поделить не можем
[34:17.580 --> 34:23.900]  целые числа, поэтому как можно ближе к равности нужно бы поделить. 6,5 это будет хороший ответ.
[34:23.900 --> 34:30.540]  Получаем, что 6 температура у нас относится к процессу номер 0 и 5 температур к процессу номер
[34:30.540 --> 34:38.420]  1. Номера процессов, они номируются в MPI начиная с нуля. Если у нас два процесса, значит их номера
[34:38.420 --> 34:44.660]  будут 0 и 1. Это называется ID процессов, но это грубо говоря имена, чтобы можно было случайно
[34:44.660 --> 34:51.100]  обращаться к процессам. 0 и 1. Если их 7, значит от нуля до 6. Максимальное число будет, это размер,
[34:51.100 --> 34:58.700]  обычно оно обозначается как size, size минус 1. Если у нас два, size равно 2, значит у нас номера
[34:58.700 --> 35:06.220]  процессов будет 0 и 1. Все, поделили, договорились. Теперь процесс номер 0 вычисляет температуры
[35:06.220 --> 35:13.420]  в 6 точках по той формуле, которая была на предыдущем слайде. Просто берет и вычисляет. А процесс номер
[35:13.420 --> 35:20.220]  1 вычисляет температуру в 5 точках. Все бы хорошо, но как говорится но. Что но? Почему но?
[35:20.220 --> 35:33.300]  Да, абсолютно верно. Вот смотрите, у нас есть это воображаемая граница. Это к одному процессу
[35:33.300 --> 35:38.460]  относится, это к другому. Теперь накладываем сюда шаблон и видим, что для того, чтобы посчитать
[35:38.460 --> 35:43.980]  температуру вот в этой граничной точке, нам нужно бы знать температуру вот в этой точке. Но процесс
[35:43.980 --> 35:50.820]  0, об этом не зная, у него нет доступа к оперативной памяти процесс номер 1. Поэтому здесь нужно сделать
[35:50.820 --> 35:57.420]  пересылку от первому процессу к нулевому. И когда нулевой получит эту температуру,
[35:58.060 --> 36:05.300]  у него будет вся информация на текущий момент и он сможет посчитать в будущем. Ну и точно также
[36:05.300 --> 36:10.700]  относится к процессу номер 1, вот здесь. Ему неизвестна температура в точке 6, ему нужно ее
[36:10.700 --> 36:16.860]  получить и это можно сделать с помощью отправки сообщения. Сообщение это отправка данных. В данном
[36:16.860 --> 36:27.060]  случае отправка правильной температуры. Так? Все. Но дело в том, что почему этот еще раз пример
[36:27.060 --> 36:34.980]  рассматривается, потому что здесь есть производная, а это значит, что у нас есть некие зависимости по
[36:34.980 --> 36:42.380]  данным. То есть, минус 1, плюс 1, имеется в виду i минус 1, i плюс 1. И когда у нас есть производные,
[36:42.380 --> 36:50.980]  мы их приближаем разностями, то это будет наблюдаться. То есть, у нас не просто данная
[36:50.980 --> 36:59.180]  независимая внутри, все нормально, а вот на границах есть такой нюанс. Так, перерыв,
[36:59.180 --> 37:13.020]  да? Давайте 5 минут. Давайте продолжим. Коротко скажу о том, как это обычно делается. Во-первых,
[37:13.020 --> 37:18.060]  когда у нас рассматривается какие-то граничные условия, то делаются фиктивные чайки дополнительные,
[37:18.060 --> 37:25.340]  в которых не идет расчет. Здесь они показаны таким же штрихпунктиром. Ну и на воображаемой границе
[37:25.340 --> 37:30.540]  между процессами тоже делаются такие фиктивные чайки. И вот в эти фиктивные чайки, они являются
[37:30.540 --> 37:36.140]  частью массива, но расчетом не идет, пересылается значимая, то есть настоящая температура из других
[37:36.140 --> 37:43.060]  процессов. Вот так. Такой перекрестная пересылка. Ну и тогда вот в этом квадратике, который с
[37:43.060 --> 37:47.100]  сплошными линиями, можно посчитать температуру, потому что после пересылки здесь будет правильная
[37:47.100 --> 37:52.700]  температура. И тогда единообразно для всех процессов, у каждого процесса нужно представлять,
[37:52.700 --> 37:58.300]  что будет название массива одинаковое. В самом лучшем случае, как это может быть реализовано.
[37:58.300 --> 38:03.380]  Массивы начинаются от нуля до количества элементов. Это количество элементов сидит в какой-то
[38:03.380 --> 38:10.140]  переменной. Ну и в общем просто идет один блок программы, который относится ко всем процессам,
[38:10.140 --> 38:16.060]  тут просто разные там разные данные лежат. Ну ладно, это детали. Главное, что нам нужно сейчас
[38:16.740 --> 38:26.820]  рассмотреть. Вот это более частно, как влияет, помимо закона Омдала, помимо интерконнекта, как еще
[38:26.820 --> 38:35.900]  влияет способ налаживания этих пересылок на ускорение. Это тоже важно. И рассмотрим один из методов
[38:35.900 --> 38:41.940]  параллелизма, параллельных вычислений. Это называется геометрический параллелизм. Ну он то
[38:41.940 --> 38:51.540]  же самое, он был применен и для расчета суммы массива. В чем его смысл? В том, что тоже очень
[38:51.540 --> 38:57.460]  все просто. Наш стержень, в котором хранятся температуры, ну в общем стержень, мы проецируем
[38:57.460 --> 39:02.500]  этот наш стержень в программу в качестве массива, в котором хранятся температуры. И эта массив делится
[39:02.500 --> 39:09.100]  на части. Можно представить, что и наш стержень в геометрическом смысле, когда он находится в
[39:09.100 --> 39:14.820]  реальности, пилится на кусочки. Каждый кусочек рассматривается каждым из процессов. Вот геометрический
[39:14.820 --> 39:21.060]  параллелизм. Больше ничего сложного нет. Ну получается, что, например, если у нас есть массив из N точек,
[39:21.060 --> 39:30.340]  N точек. Таоце это, грубо говоря, вычислить одну температуру. Уже не одна арифметическая операция,
[39:30.340 --> 39:34.660]  их несколько, но это время, затрачиваемое на вычисление одной температуры. Мы делаем оценку,
[39:34.660 --> 39:43.860]  как, что на что влияет. Вот и K. Это количество шагов по времени, которое нужно пройти для того,
[39:43.860 --> 39:50.500]  чтобы понять распределение температуры на какой-то момент времени. То есть N это точек, то есть
[39:50.500 --> 39:56.860]  количество шагов, грубо говоря, по пространству. K это количество временных шагов. Таким образом,
[39:56.860 --> 40:06.500]  тао1, то есть время, затрачиваемое одним ядром, на полный расчет. K N таоце по времени, N по
[40:06.500 --> 40:14.060]  пространству, таоце время вычисления одной температуры. Так? Теперь, когда мы делим на P,
[40:14.060 --> 40:20.260]  в данном случае здесь 7, просто держим на голове 7, на P процессов, то у нас получается следующее.
[40:20.260 --> 40:27.060]  Ну, это схема просто тех же самых пересылок. И вроде как мы... Каждая такая стрелочка переслать
[40:27.060 --> 40:34.820]  данные, на самом деле, в терминах MPI состоит из двух функций. Такая стрелочка — это MPI send,
[40:34.820 --> 40:45.060]  называется. Отправить сообщение. А вот такая галочка — это MPI receive. Принять. Ну вот,
[40:45.060 --> 40:53.860]  смотрите, получается, что вот на таких границах между процессами у нас получается одна пересылка,
[40:53.860 --> 41:01.180]  это значит две функции. Но в итоге такая одна пересылка, она занимает время taos. Для того,
[41:01.180 --> 41:06.740]  чтобы правильно описать, вернее правильно посчитать все распределение температур,
[41:06.740 --> 41:13.500]  каждый из процессов должен в первую очередь что? Отослать на левой границе свое значение и
[41:13.980 --> 41:22.700]  принять слева. И на правой границе отправить, здесь отправить и принять. То есть два своих
[41:22.700 --> 41:29.100]  граничных значения отправить влево-вправо. Ну, влево-вправо — это тоже таки жаргон в некотором
[41:29.100 --> 41:34.740]  смысле. Когда мы рассматриваем вот так схему пересылок, то обычно справа у нас оказываются
[41:34.740 --> 41:42.620]  процессы с номером. Этот номер еще называется рангом. С рангом на единицу больше, а слева у нас
[41:42.620 --> 41:49.060]  оказывается с рангом на единицу меньше. Мы если так и договоримся, то оказывается,
[41:49.060 --> 41:54.020]  что вправо это значит нужно переслать процессу с рангом на единицу больше, а влево это с рангом
[41:54.020 --> 42:01.860]  на единицу меньше. Потому что на картинке это видно — лево-право. И принять опять же слева-справо
[42:01.860 --> 42:06.060]  для того, чтобы нам сделать расчет в этих граничных точках. Но вроде как получается,
[42:06.060 --> 42:12.820]  что у нас четыре пересылки и вроде как они должны быть как раз друг за другом. Вот здесь процесс,
[42:12.820 --> 42:19.180]  почему он друг за другом? Потому что мы рассматриваем здесь пересылка с блокировкой,
[42:19.180 --> 42:26.740]  блокирующей пересылка, например. Это говорит, что пока происходит передача данных, у нас этот
[42:26.740 --> 42:33.620]  процесс и тот процесс, который принимает данные, они заблокированы на приеме или пересылке и ничего
[42:33.620 --> 42:42.220]  другого не делают. Поэтому они могут только переслать один раз, после этого этот процесс может перейти
[42:42.220 --> 42:48.940]  к приему или к передаче следующего сообщения и так далее. Здесь у нас идут как раз пересылки
[42:48.940 --> 42:56.380]  последовательно. И время какое получится? Вот это время, деленное на П, плюс четыре пересылки — раз,
[42:56.380 --> 43:02.700]  два, три, четыре. Их какое будет количество? Тауэ с время одной пересылки на одном временном шаге — это
[43:02.700 --> 43:12.220]  будет четыре тауэс, а всего временных шагов — к. И получается четыре ка тауэс. Вроде как из схемы того,
[43:12.220 --> 43:18.900]  что мы видим, это вроде должно так быть. Но как это будет в реальности на самом деле, когда вы будете
[43:18.900 --> 43:27.420]  это реализовывать? Давайте посмотрим. Здесь пока понятно. Замечательно. Идем дальше. Значит,
[43:27.420 --> 43:34.680]  можно ли такое получить в реальности-то или нет? Давайте посмотрим первый вариант. У нас есть
[43:34.680 --> 43:41.620]  семь процессов. Номера у них или ранги от нуля до шести. Шесть — это максимальная схема пересылок.
[43:41.620 --> 43:49.380]  И как можно это сделать схему? Давайте так. Первый вариант. Каждый из процессов делает следующее.
[43:49.380 --> 43:57.020]  Сначала пересылает влево. Кроме нулевого, потому что у нулевого нет левого соседа. Нет ранга меньше
[43:57.020 --> 44:07.420]  нуля. Все они пересылают влево. Потом все пересылают вправо. Нолевой пересылает вправо. Здесь
[44:07.420 --> 44:13.940]  вот номера процессов, а здесь итерации, то есть шаги. Поскольку это пересылки, то это еще и шаги
[44:13.940 --> 44:20.860]  по времени. Сколько итераций временных для налаживания пересылок будет наблюдаться. Все
[44:20.860 --> 44:26.260]  вправо, кроме последнего. Последнего нет соседа справа, потому что у него номер максимальный.
[44:26.260 --> 44:35.660]  Потом это идет обмен. В данном случае у этого на левой границе и вот здесь вот для каждого
[44:35.660 --> 44:44.660]  счета на левой границе. Потом все они принимают справа, а потом все принимают слева. Получается
[44:44.660 --> 44:54.380]  вот такая схема пересылок. Просто мы берем все, отправили, а потом все получили. Вообще говоря,
[44:54.380 --> 45:04.260]  на каждой границе должно быть по две стрелочки и по две галочки. Вроде все это наблюдается.
[45:04.260 --> 45:09.860]  Две стрелочки, две галочки, две стрелочки, две галочки. Это значит, что мы направили, переслали
[45:09.860 --> 45:16.780]  влево-вправо и получили отлево-право на каждой границе. Теперь вопрос. Сработает ли эта схема?
[45:17.240 --> 45:23.460]  Что вы говорили про процесс, когда что-то начинает делать, он блокируется.
[45:23.460 --> 45:29.240]  Да, мы рассматриваем здесь... Просто есть не блокирующая операция, но это всегда можно сделать
[45:29.240 --> 45:35.340]  не блокирующие операции. Но по сути, все можно сделать, все от операций, что можно сделать не
[45:35.340 --> 45:40.120]  блокирующими, можно делать и блокирующими операциями. Но когда мы рассматриваем блокирующие операции,
[45:40.120 --> 45:45.880]  мы можем почувствовать разницу при применении того или иного алгоритма. Когда не блокирующие
[45:45.880 --> 45:50.080]  операции они нивелируются я сейчас об этом не буду говорить да поэтому мы
[45:50.080 --> 45:55.840]  рассматриваем блокирующие операции как самый простой самый ну первый способ
[45:55.840 --> 45:59.240]  который вообще рассматривается самой первой функции и на них можно почувствовать
[45:59.240 --> 46:04.960]  разницу реализации алгоритма пересылок и так да и так операции у нас блокирующие
[46:04.960 --> 46:10.720]  то есть при приеме или при передаче процесс блокируется на этом приеме или
[46:10.720 --> 46:14.880]  передачи и другие никакие операции не выполняет
[46:14.880 --> 46:22.880]  подробнее про эту модель, в которой мы работаем, что если два соседних блоков хотят, например, обмудременно, то будут что-то отправить
[46:22.880 --> 46:24.880]  давайте просуждаем
[46:24.880 --> 46:28.880]  моментально мы умрем, или вот они как-то договорятся и сделают...
[46:28.880 --> 46:30.880]  так, хорошо
[46:30.880 --> 46:32.880]  когда отправляют, ожидает приеме то, что будет принято
[46:32.880 --> 46:34.880]  так, хорошо
[46:34.880 --> 46:39.880]  ну второй раз мы сможем отправить, потому что первое правило, он будет ждать пока тот приемик
[46:40.220 --> 46:42.220]  тот это какой?
[46:42.220 --> 46:44.220]  ну сталон на...
[46:44.220 --> 46:46.220]  давайте по номеркам
[46:46.220 --> 46:48.220]  вы правильно рассуждаете
[46:48.220 --> 46:50.220] 例えば первый процесс
[46:50.220 --> 46:52.220]  вот первые ноль вой страны
[46:52.220 --> 46:54.220]  ну, lamps
[46:54.220 --> 46:56.220]  друг к другу
[46:56.220 --> 46:58.220]  но первые ждают, что примет перв swapped
[46:58.220 --> 47:00.220]  ну, любой ждает, что примет первый
[47:00.220 --> 47:02.220]  второй ждет, что примет другой
[47:02.220 --> 47:04.220]  и получается они доверятся блокированию
[47:04.220 --> 47:06.220]  да, это верно
[47:06.220 --> 47:08.220]  это получается взаимная блокировка
[47:08.220 --> 47:15.460]  называется deadlock, или классический тупик, когда они собираются что-то отправить друг другу, но
[47:15.460 --> 47:21.500]  никогда эти пересылки не закончатся, потому что каждый из них не может принять, они заплакированы
[47:21.500 --> 47:29.420]  оба на пересылке, принять не могут, просто программа ваша зависнет, оба эти процесса будут ждать друг
[47:29.420 --> 47:34.620]  другу, но остальные тоже все подзависнут, потому что никакой из этих процессов не сможет дождаться
[47:34.620 --> 47:40.980]  окончания пересылки, потому что этого не произойдет никогда, это правильно, это тупик,
[47:40.980 --> 47:47.820]  да, и время у нас будет бесконечным, время наших пересылок и время собственно работ нашей
[47:47.820 --> 48:02.100]  программы, какое будет ускорение? Нулевое. Вариант номер один написано, наверное,
[48:02.100 --> 48:18.580]  будет еще какие-то вариантики. Сейчас мы дождем. У нас есть функции MPI, мы ими пользуемся, есть
[48:18.580 --> 48:22.580]  блокирующие, в принципе это пройдет, если вы воспользуетеся не блокирующими функциями,
[48:22.580 --> 48:29.460]  это пройдет, но, опять же, разницу мы не почувствуем, мы не почувствуем разницу в
[48:29.460 --> 48:35.220]  реализации. Давайте это все-таки попробуем сюда прийти, почувствовать, а потом уже будем там
[48:35.220 --> 48:41.100]  будете работать, когда надо, с чем надо. С этим тоже можно все делать. Теперь, как избежать этот тупик?
[48:41.100 --> 48:46.700]  Нужно просто поменять местами прием и пересылка, например, в нулевом. Если мы поменяем местами,
[48:46.700 --> 48:54.140]  то нулевой примет, ну вообще везде, нулевой примет, значит эта пересылка закончится, и вот если
[48:54.140 --> 49:01.420]  мы везде вот эти стрелочки поменяем местами, то после переправки влево первая начнет не отправка
[49:01.420 --> 49:09.740]  вправо, а прием, ну какой-нибудь вот эти вот прием, справа, ну и все у нас разрулится, как говорится. Мы
[49:09.740 --> 49:14.500]  избавимся от этой проблемы. Просто тоже приемов может быть разные, например, использования не
[49:14.500 --> 49:19.580]  блокирующих пересылок, либо использования там совместной функции приема-передачи такие тоже
[49:19.580 --> 49:25.700]  есть, но один из самых простых способов это перестать местами center-receive соответствующие.
[49:25.700 --> 49:31.540]  Ну давайте это сделаем. Это будет вариант два. Все отправляют влево, как у нас в первом случае,
[49:31.540 --> 49:37.460]  а потом нужно сделать прием для каждого из процессов. Видите, у нас получаются пары приема
[49:37.460 --> 49:44.220]  и отправки. И вот всегда нужно, опять же, мыслить именно в этой парадигме, скажем. Если где-то
[49:44.220 --> 49:51.140]  есть отправка, значит обязательно где-то нужно сделать прием. Если какой-то у вас процесс принимает,
[49:51.140 --> 49:58.460]  то значит где-то должен второй процесс, с каким он коммуницирует, отправить. В общем, нужно всегда
[49:58.460 --> 50:04.460]  мыслить парами. Не просто все отправляют, а нужно искать пары, нужно делать пары. Итак, мы сделали
[50:04.460 --> 50:11.820]  пары приема и отправки. Прием у каждого из них и отправка у всех остальных. Чтобы у нас не было
[50:11.820 --> 50:22.340]  тупика. Пока мы так, а я хочу так. Кто мне запрещает? А потому что у нас блокирующая операция. И если так,
[50:22.340 --> 50:27.740]  то процесс номер один может принять процесс номер два только после того, как он сделал вот эту
[50:27.740 --> 50:34.540]  пересылку. А это у нас, еще раз напоминаю, итерации во времени. Это значит, что у нас после первой
[50:34.540 --> 50:42.940]  итерации вот этой идет следующая итерация вот эта. Но у нас это будет TAO-S. Время равняется.
[50:42.940 --> 50:51.460]  Время равняется. Каждую итерацию равно TAO-S. После первой идет вторая пересылка, вот на этой
[50:51.460 --> 50:58.660]  границе. Только после нее, возможно, вот эта и так далее. И получится, что у нас идет передача
[50:58.660 --> 51:05.700]  сообщений последовательно, друг за дружкой, и у нас растет время пересылок. Вот в таком виде.
[51:05.700 --> 51:16.420]  Но это, смотрите, произошел обмен на каждой границе, но только в одну сторону. Влево. Теперь нам
[51:16.420 --> 51:22.900]  нужно все это отправить вправо и получить слева. То есть нам нужно еще то же самое сделать,
[51:22.900 --> 51:28.900]  но в другую сторону. Видите? Отправить вправо и получить слева. И опять на каждой границе у нас
[51:28.900 --> 51:36.100]  две стрелочки в одну сторону. То есть две стрелочки и две галочки. В одну сторону отправка и в другую
[51:36.100 --> 51:44.900]  сторону с приемом. Получается вот такая структура отправки сообщения. Все сообщения отправляются
[51:44.900 --> 51:51.500]  последовательно, потому что мы используем отправка и прием с бакировкой. Не могут они
[51:51.500 --> 51:58.140]  произойдет одновременно. И получается, какое у нас время работы алгоритма будет? Здесь у нас
[51:58.140 --> 52:10.900]  тупиков нет, видно? Еще раз погромче. 12. А что такое 12? Это я знаю. А вы почему здесь 12 получается?
[52:10.900 --> 52:27.380]  Откуда она? Но не минус 1. Минус 2. Почему? Смотрите, у нас границ. Если у нас 7 процессов,
[52:27.380 --> 52:35.740]  границ между ними на сколько будет? 6. 6 это n-1. Но нам нужно отправить в одну сторону, это будет
[52:35.740 --> 52:43.940]  один раз n-1 и в другую сторону. Это еще раз n-1. Поэтому будет 2 умножить на p-1. p это количество
[52:43.940 --> 52:52.860]  процессов. В одну и в другую сторону. А все остальное тоже самое. Получается, что у нас будет
[52:52.860 --> 53:06.060]  2 умножить на 6. Вот откуда 12. Так, это лучше, чем было раньше? Чем бесконечность? Ну, вроде лучше,
[53:06.060 --> 53:12.300]  да? Мы по крайней мере уже видим, что у нас время, ну, наверное, меньше, чем tau-1. Вот здесь мы tau-1,
[53:12.300 --> 53:18.460]  вот здесь оно делим на p, это точно меньше. tau-s большое. Ну, в общем, кажется, что меньше. Но
[53:18.460 --> 53:25.300]  плохо, что у нас это время пересылок зависит от p. Мы хотим tp увеличить, тогда у нас вот эта
[53:25.300 --> 53:31.660]  дропа уменьшится, у нас будет хорошее должно быть ускорение. Но потому что оно вот здесь линейно
[53:31.660 --> 53:38.900]  входит во время пересылок, это нам все портит. Да, ускорение будет, но оно такое будет, корявенькое.
[53:38.900 --> 53:45.620]  И, помимо этого, у нас не получится четверка. Помните, тогда, когда мы теоретически рассматривали,
[53:45.620 --> 53:52.100]  у нас вот здесь вот четверку хотелось бы видеть. А четверка, это что значит? Что у нас время пересылок
[53:52.100 --> 53:58.460]  не будет зависеть от количества процессов, это будет константа. Вот такое поведение, это называется,
[53:58.460 --> 54:07.220]  что у нас время пересылок линейно зависит от p, это значит O от p. О большое, помните, да? То есть
[54:07.220 --> 54:15.940]  пропорциональность. А когда четверка, это O от единички, это константа какая-то. Можно ли
[54:15.940 --> 54:21.380]  сделать вот эту четверку-то? Здесь у нас лучше, чем бесконечность, ускорение будет, но вот эта вот
[54:21.380 --> 54:30.820]  зависимость линейная, она портит всю картину. Как сделать четверку? И откуда берется четверка?
[54:37.220 --> 54:42.820]  Это не я говорил. Ну вообще, да. Так, и что это получается? Что-то нечетное, то что? Это вам уже на
[54:42.820 --> 54:51.620]  семинаре говорили? Здесь видно, хорошо. Да, смотрите, вот когда заняты пересылкой 0 и единичка,
[54:51.620 --> 54:57.620]  вот ничто не мешает на самом деле делать пересылку между двойкой и тройкой. Заблокированы только 0 и
[54:57.620 --> 55:05.340]  1, а все остальные, в общем-то, не связаны с этой пересылкой, и блокировка именно с этой пересылкой
[55:05.340 --> 55:12.340]  им не обязательно. То есть, если рассмотреть, сейчас-то 2 и 3 тоже заблокированы, потому что
[55:12.340 --> 55:18.700]  2 связан с 1, здесь он хочет передать 1 что-то, а 1 не может это принять. Но если чуть-чуть поменять
[55:18.700 --> 55:26.660]  местами вот эти отправку и прием, то у нас ничто не мешает, когда пересылает 0 и 1 сделать вот этот
[55:26.660 --> 55:36.900]  обмен. Или вот этот, правильно? Они ведь могут быть не заблокированными. Если мы это сделаем, то
[55:36.900 --> 55:42.060]  оказывается, действительно. А это что значит? Что нулевой принимает, второй тоже должен принять,
[55:42.060 --> 55:46.780]  четвертый тоже должен принять и так далее. То есть, каждый четный будет принимать, а каждый нечетный
[55:46.780 --> 55:54.540]  отправлять. Ну давайте так и сделаем. Третий вариант. На каждом временном шаге нечетные отправляют
[55:54.540 --> 56:04.660]  влево. В этот же момент четные должны принять. Принимаем. Принимаем справа. Произошел обмен,
[56:04.660 --> 56:12.060]  одновременный обмен. На одной границе, то есть не на всех границах, а на каждой, ну не знаю,
[56:12.060 --> 56:19.140]  как это, четной, нечетной, не важно. На каждой границе эти границы два раза меньше. Потом на этой
[56:19.140 --> 56:25.300]  же границе мы делаем обмен в другую сторону. Нечетные должны принимать, а четные должны отправлять.
[56:25.300 --> 56:34.340]  Таким образом, мы за две временные итерации, временные в плане пересылки по сети, мы сделаем
[56:34.340 --> 56:42.380]  обмен на одной границе. Осталась вторая граница, вот эта. Сделаем обмен здесь, то же самое. Все,
[56:42.540 --> 56:48.060]  все обменяли. Как у нас получилось? Четыре пересылки. За счет чего? За счет того,
[56:48.060 --> 56:53.420]  что у нас обмен происходит одновременно. То есть здесь у нас распараллелия не только при расчете,
[56:53.420 --> 57:01.260]  но и при пересылках. Видите, тоже можно, я просто не знаю, как зовут человек, который смотрит в
[57:01.260 --> 57:09.300]  телефон. Можно ведь сделать одновременную пересылку? В принципе, не полностью, но в принципе можно.
[57:09.300 --> 57:17.260]  Да, замечательно. Только я вас не просил разрешения, я спрашивал. И что тогда получается,
[57:17.260 --> 57:26.140]  теперь если по временам посмотреть? Четыре. И вот теперь, если мы перейдем к ускорению,
[57:26.140 --> 57:31.700]  то вот можно получить вот такую замечательную штучку. А что в этой замечательной штучке,
[57:31.700 --> 57:39.460]  в знаменателе? Вот такая штучка, которую мы уже рассматривали. Что здесь? Уже нам известны
[57:39.460 --> 57:45.660]  отношения tau s к tau c, tau s к tau c, p, n. Только еще добавилось p. Но оно тоже было на самом деле,
[57:45.660 --> 57:54.900]  когда у нас там s. Если s сказать, что это p пополам, то у нас там все равно это появляется. Короче,
[57:54.900 --> 58:01.660]  я кчмаю к тому, что у нас все равно это отношение p к n, tau s к tau c очень часто будет появляться.
[58:01.660 --> 58:08.100]  И в данном случае оно тоже существует. И вот здесь сложность задач. Чем сложнее задача, тем у нас
[58:08.100 --> 58:17.980]  ускорение лучше. Чем сеть медленнее, тем оно хуже. Чем больше p, то что тоже хорошо, тем лучше. Ну вот,
[58:17.980 --> 58:25.780]  в общем, можно анализировать. Вот эта штучка у нас появляется. Так, давайте вопросов у нас сколько?
[58:25.780 --> 58:34.060]  Еще 20 минут. Еще один метод рассмотрим. Пока. Так, к чему это? Это вот к чему.
[58:34.060 --> 58:44.300]  Главным параметром из главнейших параметров является, я просто напоминаю, график ускорения.
[58:44.300 --> 58:49.620]  График ускорения, чтобы понимать, как ваша программа работает на параллельной машине. Почему?
[58:49.620 --> 58:54.740]  Потому что, еще раз, она должна решать две задачи. Первая, получить правильный ответ. Второй,
[58:54.900 --> 58:59.900]  получить хорошее ускорение. Чтобы понять, что ускорение хорошее, нужно программу
[58:59.900 --> 59:06.420]  протестировать. Или, если у вас нет возможности протестировать, можно оценить. Это раз. Второе.
[59:06.420 --> 59:14.580]  Что влияет на график нашего ускорения? Ну, понимать, во-первых, докуда он масштабируется наш алгоритм.
[59:14.580 --> 59:19.180]  Сколько можно вычислительных ядер брать, чтобы получить то или иное ускорение. Чтобы потом у вас
[59:19.180 --> 59:24.620]  была наглядна табличка по доступности, например, ядер. Сколько можно использовать и какое вы
[59:24.620 --> 59:32.340]  ускорение получите. На что влияет ускорение? Влияет на ускорение. Закон Амдала. Раз. Второе. Интерконнект.
[59:32.340 --> 59:41.300]  Третье. То, как вы реализуете пересылку сообщений. Мы сейчас поговорили о законе Амдала. Мы
[59:41.300 --> 59:47.460]  говорили в прошлый раз. Сейчас мы о втором способе. То есть, о второй причине. Интерконнект. Третья
[59:47.460 --> 59:53.660]  причина тоже. От ваших рук зависит. От бесконечности время пересылок может быть. То есть, ускорение
[59:53.660 --> 59:59.380]  от нуля. Потом оно может плавно загибаться за счет того, что у вас время пересылок зависит
[59:59.380 --> 01:00:07.100]  от количества процессов. И еще более лучший график ускорения, когда у вас время пересылок не зависит
[01:00:07.100 --> 01:00:13.300]  от количества процессов. А это что говорит о том, как вы это сделаете. То есть, лично от вас. Мы
[01:00:13.300 --> 01:00:21.260]  вы можете повлиять на графику ускорения. Поскольку вы хорошо или сделать не очень хорошо пересылки.
[01:00:21.260 --> 01:00:26.940]  Это тоже будет влияние. Вот мы это рассмотрели. Как это влияет. Вплоть до того, что у вас программа
[01:00:26.940 --> 01:00:33.340]  просто зависит. Ну это понятно, неправильно написана программа. Но вариант номер два и
[01:00:33.420 --> 01:00:37.820]  вариант номер три, они вполне жизнеспособны, но до определенной степени. То есть, вы можете и так,
[01:00:37.820 --> 01:00:48.460]  и так. И разница уже будет. И мы говорили, и вот в этой задаче уравнение теплопроводности как раз
[01:00:48.460 --> 01:00:54.260]  можно почувствовать эту разницу. Это первое. А второе, это был один из методов параллельных вычислений.
[01:00:54.260 --> 01:01:00.620]  Метод геометрического параллелизма. Когда мы просто ваш стержень делим на кусочки, разрезаем. И
[01:01:00.620 --> 01:01:09.260]  каждый кусочек отдельно считается каждым из процессов. Еще один метод. У нас как раз есть время
[01:01:09.260 --> 01:01:15.740]  для того, чтобы посмотреть. Это метод сдваивания. Вот давайте опять же рассмотрим массив, который
[01:01:15.740 --> 01:01:23.380]  состоит из восьми элементов. И опять же сделаем сумму элементов. Как теперь можно сделать? Допустим,
[01:01:23.380 --> 01:01:31.180]  у нас есть время. Здесь восемь элементов, поэтому здесь N-1 вполне нормально. Есть у нас в два раза
[01:01:31.180 --> 01:01:36.940]  меньше процессов. Их четыре штуки. Каждый из процессов может взять себе пару и вычислить
[01:01:36.940 --> 01:01:45.100]  сумму этой пары. Получит четыре ответа. На следующем шаге работают два процесса и получают суммы одной
[01:01:45.100 --> 01:01:50.780]  половины массива и суммы второй половины массива. И на последнем шаге работает один процесс, который
[01:01:50.780 --> 01:02:06.620]  делает конечную сумму. Если у нас N является какой-то степенью двойки, то алгоритм сдваивания
[01:02:06.620 --> 01:02:13.980]  выполнится вот за такое количество шагов. Мы берем алгоритм по основанию два от N. То есть
[01:02:13.980 --> 01:02:24.180]  если у нас было восемь, то выполнится за раз, два, три шага. Потому что три – это алгоритм восьми по
[01:02:24.180 --> 01:02:43.820]  основанию два. Правильно? Два раза меньше сначала. Четыре. Где? Я думаю, что восемь там должно быть,
[01:02:43.820 --> 01:02:56.700]  по крайней мере. Так, десять восьмой. Вы про что сейчас говорите? Почему десять восьмой? Два в
[01:02:56.700 --> 01:03:04.940]  третьей в данном случае. Это элементов массива. И это вообще даже не процессов, не количество
[01:03:04.940 --> 01:03:18.500]  процессов. Десять восьмой может быть у вас в задаче. Можно представить себе. Сейчас спокойно,
[01:03:18.500 --> 01:03:23.660]  мы рассмотрим. Давайте все. Забудьте, что было раньше. У нас новый метод. Метод сдваивания. Там
[01:03:23.660 --> 01:03:28.140]  восемь элементов и четыре процесса. Давайте на этом остановимся, а потом что-то будем размышлять.
[01:03:28.140 --> 01:03:45.700]  Хорошо. Тогда идем дальше. Вот такое кью получается. Это у нас количество шагов для того,
[01:03:45.700 --> 01:03:53.300]  чтобы у нас метод сдваивания сработал. Степень парализма – это количество независимо выполняемых
[01:03:53.300 --> 01:03:58.460]  операций на какой-то стадии. Ну, боксинг. Ладно, идем дальше. Время работы, если рассмотрим
[01:03:58.460 --> 01:04:04.100]  последовательно алгоритм, это множество tau c умножить на n-1. Ну, если n большое,
[01:04:04.100 --> 01:04:10.940]  то можно примерно n. Так в голове держим. Если у нас p – это, как я уже сказал, n поделить пополам,
[01:04:10.940 --> 01:04:22.380]  то время работы будет tau c сумма умножить на количество таких шагов. Мы здесь сейчас не
[01:04:22.380 --> 01:04:30.260]  рассматриваем пересылки. Просто мы говорим о времени. Просто понять, как он работает без пересылок.
[01:04:30.260 --> 01:04:35.420]  Просто у нас процесс каким-то образом получает результат с предыдущей стадии и просто складывает.
[01:04:35.420 --> 01:04:41.620]  Без пересылок. Пересылки мы чуть позже. Я думаю, что успеем рассмотреть. Вот такое у нас получается
[01:04:41.620 --> 01:04:48.940]  время работы параллельного алгоритма. Если одно на другое поделить, вот такая величина получается.
[01:04:48.940 --> 01:04:58.580]  Эффективность. Это s, напоминаю, поделить на p. Если у нас pn пополам, вот тут вырисовывается 2 на n,
[01:04:58.580 --> 01:05:05.100]  здесь примерно n-1 равно n, сокращается, получаем вот такую величину. Нормально это или нет?
[01:05:05.100 --> 01:05:18.180]  Более-менее. Если у нас n примерно 1000, ну степень двойки 1024, то у нас s получится 102,
[01:05:18.180 --> 01:05:30.740]  а эффективность примерно 20%. Но если s еще ладно, у нас тоже так себе. p у нас 500, 500 процессов,
[01:05:30.740 --> 01:05:36.380]  ускорение 100, ну пусть будет, но эффективность совсем не очень хорошая, маленькая. А все почему?
[01:05:36.380 --> 01:05:42.660]  Эффективность – это ускорение, поделенное на количество процессов. Показывает, насколько загружены
[01:05:42.660 --> 01:05:50.500]  процессы в целом. Видно, что 20%. То есть мы берем 500, а по факту, после того, как мы все посчитали,
[01:05:50.500 --> 01:05:56.420]  оказывается загруженными полностью 100. Но это, в общем-то, очевидно. Потому что на каждой стадии
[01:05:56.420 --> 01:06:03.340]  количество работающих процессов уменьшается. Сначала они все работают, все 500, потом их работает
[01:06:03.340 --> 01:06:11.180]  250, потом их 125 и так далее и так далее. На каждой стадии их работают два раза меньше. Ну и они
[01:06:11.180 --> 01:06:23.540]  просто простаивают. Можно как-то переиспользоваться? Можно как. А это скорее вопрос «как». Ну сейчас посмотрим. То есть как-то
[01:06:23.540 --> 01:06:31.060]  нужно действительно получше-то их использовать, правильно? Потому что, ну так-сяк. Ну давайте
[01:06:31.060 --> 01:06:37.860]  смотреть. Если у нас n большое, то что можно сделать? Применить уже сюда чуть-чуть метод геометрического
[01:06:37.860 --> 01:06:46.820]  параллелизма. Немножечко. Вот если n большое, то вычисление последовательной суммы будет n на tau c.
[01:06:46.820 --> 01:06:52.700]  Потом мы этот массив делим сначала на части. Количество частей равно количеству процессов.
[01:06:52.700 --> 01:07:02.660]  Сначала вычисляем в каждой части свою сумму. Это будет, значит, вот n tau c поделить на p. Это
[01:07:02.660 --> 01:07:09.500]  время вычисления суммы в этих частях. А потом воспользуемся методом сдваивания. Метод сдвания
[01:07:09.500 --> 01:07:18.500]  сколько будет? tau c, пока без пересылок. Логарифм по основанию 2 от p. Почему от p?
[01:07:18.500 --> 01:07:30.700]  Количество изначально было n. Там как-то дерево издваивание, у нас листья в нём было. Поэтому
[01:07:30.700 --> 01:07:43.020]  когда п процессов посчитали частичные суммы в своих частях, то у нас получилось p ответов.
[01:07:43.020 --> 01:07:50.900]  А потом мы знаем, что количество следующих шагов в следующей стадии метода сдвания,
[01:07:50.900 --> 01:07:58.860]  логарифм по основанию 2, от p, от изначального количества значений или элементов. И теперь
[01:07:58.860 --> 01:08:07.860]  можем посчитать ускорение. Вот все поделили. Но когда они посчитали свои вот здесь результаты,
[01:08:07.860 --> 01:08:17.860]  то они получили p результатов. И получилось p чисел. И теперь эти p чисел должны по методу
[01:08:17.860 --> 01:08:31.060]  сдвавания попарно складываться. Понятно? Хорошо. Теперь мы просто поставляем одно в другое.
[01:08:31.060 --> 01:08:41.780]  Получаем s равно вот этому числу. Эффективность равно вот этому числу. Теперь представим,
[01:08:41.780 --> 01:08:47.500]  что p меньше, чем n. Ну и желательно как можно меньше. n большое в общем. p у нас сколько есть,
[01:08:47.500 --> 01:08:55.300]  а вот n большое. Сложная задача. И пусть p будет вот таким числом. n поделить логарифм по основанию
[01:08:55.300 --> 01:09:05.620]  2, от n. И подставим вот сюда. Тогда у нас s получится примерно p пополам. Эффективность 50%.
[01:09:05.620 --> 01:09:18.060]  То есть вместо p вот в знаменатель подставляем вот это число. Понятно почему это получается или
[01:09:18.060 --> 01:09:32.820]  нужно поподробнее здесь? Было недавно. То есть тогда слишком много на самом деле было. Ну почему?
[01:09:32.820 --> 01:09:40.380]  Можно n большое взять. Ну по примеру, если n равно 1024, то логарифм это сколько? Десятки будет?
[01:09:40.380 --> 01:09:49.380]  Вот. Десятка. Здесь будет p равно уже 100. Ускорение будет 50 при 100 процессах. А тогда у нас было
[01:09:49.380 --> 01:09:56.460]  ускорение 100 при 500 процессах. Ну в общем, лучше показатели. Ну пожалуйста, если у вас есть 500,
[01:09:56.460 --> 01:10:03.060]  ну посчитайте сколько там n должно быть. Все наоборот, сделайте. То есть когда мы применяем теперь
[01:10:03.060 --> 01:10:08.420]  совместно два метода, то это вообще говоря очень сильно нам помогает и улучшает результаты как
[01:10:08.420 --> 01:10:17.220]  ускорению, так и по эффективности. И это хорошо. Дальше. Теперь мы добавляем еще. Что можно добавить?
[01:10:17.220 --> 01:10:25.220]  Можем добавить еще пересылку. Время затрачивано пересылкой. Теперь тогда у нас вот здесь вот,
[01:10:25.220 --> 01:10:31.380]  где у нас количество шагов в методе сдваивания. Вот сюда еще добавится помимо сложения еще как
[01:10:31.380 --> 01:10:37.540]  раз и пересылки. Опять добавляем. В знаменатель видим, что все эти пересылки опять у нас все
[01:10:37.540 --> 01:10:48.820]  портит на самом деле. Вот. И это очевидно в общем-то говоря, что когда мы добавляем сеть,
[01:10:48.820 --> 01:10:56.740]  это у нас все ухудшает, потому что добавляется знаменатель. Так, теперь, где этот метод сдваивания
[01:10:56.740 --> 01:11:02.380]  можно использовать? Ну во-первых, просто при обыкновенном сложении, потом при всяком агрегировании,
[01:11:02.380 --> 01:11:10.860]  умножение, сложение, поиск минимум, максимум. Все это можно. Еще это можно использовать при рассылке,
[01:11:10.860 --> 01:11:16.580]  если один, то есть сделать его обратно, пустить в обратном направлении. Можно сбор данных в принципе
[01:11:16.580 --> 01:11:26.140]  сделать. Есть специальные операции в MPI, которые делают сбор данных. Это gather и они собирают не
[01:11:26.140 --> 01:11:35.380]  по такому же принципу, а просто один все собирает от всех. Есть еще broad cost, то есть такая рассылка,
[01:11:35.380 --> 01:11:42.220]  broad это широковещательная типа. Один процесс отправляем в одну и ту же операцию всем остальным. То
[01:11:42.220 --> 01:11:47.340]  есть есть сбор, есть рассылка. Вот можно это сделать, улучшить эти алгоритмы, встроенные в MPI с помощью
[01:11:47.340 --> 01:11:53.780]  метода сдваивания. В одном случае у вас, как я показал, сверху вниз идет и в итоге собирается
[01:11:53.780 --> 01:11:59.300]  вся информация в одном процессе. А если один процесс хочет одну и ту же информацию отставать
[01:11:59.300 --> 01:12:07.700]  всем остальным, то можно сделать в обратном направлении. Можно разные способы, не реализации,
[01:12:07.700 --> 01:12:15.220]  а применение этого метода сдваивания придумать и иметь в голове. Все у нас осталось где-то немного,
[01:12:15.220 --> 01:12:21.020]  минуты четыре, поэтому давайте на вопросы, если они есть, я отвечу. Там еще есть в материалах,
[01:12:21.020 --> 01:12:29.420]  посмотрите, топология соединения процессов в процессоров в машине. Для общего развития я
[01:12:29.420 --> 01:12:36.140]  на это время не стал тратить. Просто по-разному можно процессоры соединять в параллельной машине.
[01:12:36.140 --> 01:12:40.620]  То есть в историческом порядке примерно так все и шло, развитие усложнялось,
[01:12:40.620 --> 01:12:47.340]  и там есть интересные моменты. Потом сами почитайте. Давайте вопросы, если есть, задавайте.
[01:12:51.620 --> 01:12:55.260]  Что непонятного или что нужно прояснить?
[01:13:06.140 --> 01:13:15.580]  Ну ладно, хорошо тогда, если все понятно. Конечно, за два занятия трудно что-то уместить более-менее
[01:13:15.580 --> 01:13:23.820]  полезно, но хотя бы то, что есть. Хорошо, тогда я сделаю какую-то квинтэссенцию того,
[01:13:23.820 --> 01:13:33.740]  что я рассказал. Что было? Мы посмотрели о том, почему параллельное программирование нужно изучать
[01:13:33.740 --> 01:13:39.300]  в том или ином виде. Потом рассмотрели примерную классификацию параллельных машин и как это
[01:13:39.300 --> 01:13:45.020]  связано с этой классификацией библиотеки параллельного программирования. У нас там
[01:13:45.020 --> 01:13:50.140]  были машины с массовым параллелизмом, которые делились еще на два больших подкласса. Это машины
[01:13:50.140 --> 01:13:57.580]  с распределенной памятью и машины с общей памятью. И вот для машин с распределенной памятью
[01:13:57.580 --> 01:14:05.420]  предназначен MPA, если говорить более-менее сухо. Для машин с общей памятью предназначена библиотека
[01:14:05.420 --> 01:14:12.740]  OpenMP. Это самая популярная на данный момент библиотеки, и вообще говоря, знать их было бы неплохо.
[01:14:12.740 --> 01:14:20.820]  Ну и теперь, если говорить об MPA, в принципе все то же самое относится и к OpenMP, но там вместо
[01:14:20.820 --> 01:14:25.900]  времени на пересылку по Interconnect, там уже будет время связано с синхронизацией потоков. То есть
[01:14:25.900 --> 01:14:31.180]  там тоже будут накладные расходы, они будут немножко другие, поменьше, но они все равно
[01:14:31.180 --> 01:14:36.740]  присутствуют. То есть в принципе здесь, если есть ТОС на время пересылок, то это просто накладные
[01:14:36.740 --> 01:14:41.820]  расходы, которые не связаны чисто с вычислениями, но они всегда будут где-то присутствовать,
[01:14:41.820 --> 01:14:50.460]  так или иначе. И мы рассмотрели по крайней мере три причины снижения ускорения. Первая это просто
[01:14:50.460 --> 01:14:56.620]  связано с тем, что не всякий алгоритм может быть распараллелен, и если он не может быть
[01:14:56.620 --> 01:15:02.540]  распараллелен, то параллелить его не надо. Мы увидели, что даже небольшая часть, которая
[01:15:02.540 --> 01:15:09.060]  нельзя распараллелить, очень сильно влияет на ускорение. Вторая причина связана с самой машиной,
[01:15:09.060 --> 01:15:16.060]  не с алгоритмом уже, а с машиной связана, с ее техническим несовершенством, и это тоже влияет
[01:15:16.060 --> 01:15:25.180]  на ускорение. И третья причина, это связано уже, возможно, уже с несовершенством человека, как он
[01:15:25.180 --> 01:15:31.420]  подойдет к вопросу реализации пересылок. Ну, я так утрирую, конечно. То есть зависит уже другая
[01:15:31.420 --> 01:15:35.460]  причина, связанная с самим человеком. Как он это реализует, как он реализует алгоритм передачи
[01:15:35.460 --> 01:15:44.660]  сообщений, к примеру. Есть алгоритмическая, машинная и персональная ответственность за то,
[01:15:44.660 --> 01:15:52.020]  что ускорение может быть нехорошим. Все. Ну и немножко поговорили о возможных методах параллельных
[01:15:52.020 --> 01:16:03.540]  вычислений. Как можно ускорить тот или иной алгоритм, по каким схемам. Ну все. Примерно вот это и было.
