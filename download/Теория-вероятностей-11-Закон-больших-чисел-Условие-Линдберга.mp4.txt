[00:00.000 --> 00:11.480]  У нас с вами получается, кроме сегодняшней, еще две лекции. Третьего и десятого,
[00:11.480 --> 00:18.720]  поскольку десятого – это учебный день. Вот, так что, может, сегодня так плохо.
[00:18.720 --> 00:24.440]  Так, значит, мы в прошлый раз остановились на теореме Калмогорова-Хищина, повторю ее.
[00:24.440 --> 00:31.120]  Рассматриваем последствия независимых случайных величин, вводим вот такую частичную сумму
[00:31.120 --> 00:36.040]  центрированных случайных величин. Ну, это, значит, означает, что мы от ожидания подразумеваем
[00:36.040 --> 00:43.800]  существование. И нам известно про эту последность, что сумма из дисперсии сходится, ну и, естественно,
[00:43.800 --> 00:50.360]  подразумеваемых существования. Тогда оказывается, что существует такая случайная величина S
[00:50.360 --> 00:57.560]  от Омега, такая, что эти частичные суммы сходятся к ней почти на верное. Ну, предел частичных сумм рядом
[00:57.560 --> 01:05.560]  и обычно или всегда вот так обозначаем. Это просто обозначение, это не утверждение. Так, ну давайте
[01:05.560 --> 01:14.840]  докажем. Давайте введем такое двухындексное множество. И он большой, он малый. Ну, так оно вообще в
[01:14.840 --> 01:31.680]  исходном вероятностном пространстве как бы. Значит, максимум Sn плюс K минус Sn, когда K изменяется от одного до Н
[01:31.680 --> 01:39.560]  большого, вот этот максимум больше Эпсилон. Вот такие. Это определение множества. Ну, тут еще есть
[01:39.560 --> 01:45.040]  Эпсилон, но оно одно и то же, поэтому, ну по-хорошему, надо бы здесь это было Эпсилон еще прилепить,
[01:45.040 --> 01:52.600]  но не буду этого делать. Вот. Что про эти множества можно сказать? Ну, во-первых, для любого N малого
[01:52.600 --> 02:08.680]  эти множества расширяющиеся. А еще что можно сказать? Что их объединение в счетном числе по индексу
[02:08.680 --> 02:27.080]  N большое. Есть вот такое множество. Супремум по K больше нуля Sn плюс K минус Sn больше Эпсилон.
[02:27.080 --> 02:35.440]  Ну, так не вызывает, да, сомнений? Если Супремум больше Эпсилон, значит, при каком-то Омега,
[02:35.440 --> 02:42.200]  входящем в это множество, Sn плюс K минус Sn оказывается больше Эпсилон. Ну, это K обязательно при
[02:42.200 --> 02:48.520]  каком-то достаточно большом N вот сюда войдет и, собственно, Омега войдет и в это множество,
[02:48.520 --> 02:55.440]  ну и в обратную сторону. Если это имеет место, то уже, заведомо, это имеет место. Вот. Ну, собственно,
[02:55.600 --> 03:03.920]  теперь мы хотим найти вероятность вот этого множества. Ну, или точность. Ну, да, вероятность.
[03:03.920 --> 03:21.280]  Или оценку вероятности. И по теореме о непрерывности вероятности, это есть предел при N большое,
[03:21.280 --> 03:29.680]  стремящемся к бесконечности, P, A, N большое, N малое. Для любого N это все имеет место, верно.
[03:29.680 --> 03:43.800]  Так, ну давайте этот P, A, N посмотрим. Значит, вероятность, еще раз перепишу, P, A, N,
[03:43.800 --> 03:55.680]  большое, N малое равна вероятности того, что максимум, а вот здесь я перепишу вот так.
[03:55.680 --> 04:20.080]  Сумма кси gt, центрированная g равно от n плюс 1 до, точнее говоря, чуть по другому индексу. Тут
[04:20.080 --> 04:29.600]  напишем g плюс n, тогда g изменяется от 1 до n большого. Вот так, да. Больший епсилон.
[04:29.600 --> 04:42.560]  Вот эта разность, это вот кусочек как бы этого ряда. А максимум, естественно, берется по,
[04:42.560 --> 04:57.600]  извините, не точно, по k, а вот k изменяется от 1 до n. Вот так вот. Правильно, поправьте. Так,
[04:57.600 --> 05:03.400]  а вот эту вероятность мы с вами как-то уже, по-моему, оценивали. Чем она оценивается,
[05:03.400 --> 05:14.280]  по какому результату нашему? Полеммика у Могорова совершенно справедлива. И это меньше или равно,
[05:14.280 --> 05:22.600]  меньше или равно, ну, там одна из форм, так сказать, верхней грани или ограничения верхнего,
[05:22.600 --> 05:36.280]  это сумма дисперсий xi g плюс n. Вот теперь же g равно от 1 до n большое. Делить на епсилон квадрат.
[05:36.280 --> 05:46.840]  Вот. Ну, если мы эту n устремим к нулю, бесконечности, n большой устремим к бесконечности,
[05:46.840 --> 05:57.840]  то получим единица на епсилон квадрат и вот хвостик ряда d. Ну, тут дисперсия
[05:57.840 --> 06:13.400]  xi g от n плюс 1 до бесконечности. Правильно, да? Ну, и мы видим, что вот эта вот вероятность
[06:13.400 --> 06:29.040]  стремиться к нулю при n малой, стремящемся к бесконечности, правильно? Правильно? Это сходящийся
[06:29.040 --> 06:36.360]  ряд n малую устремить к бесконечности, будет хвостик оставаться. А вот стремление к нулю,
[06:36.360 --> 06:45.520]  вот только тут, слушайте, я написал. Тут вероятность надо. А вот когда такая вероятность стремиться к нулю,
[06:45.520 --> 07:08.000]  это что значит? Это сходимость какая? По? По каши. Это сходимость по каши, да? Сходимость
[07:08.000 --> 07:13.600]  почти наверное по каши. Помните, мы с вами доказывали про сходимость почти наверное,
[07:13.600 --> 07:25.840]  что она фундаментально по каши. Ну и, собственно, сходимость по каши, мы с вами знаем, как раз
[07:25.840 --> 07:33.800]  означает существование измеримого предела, то есть вот этой самой s большое от омега. Ну,
[07:33.920 --> 07:45.320]  собственно, и все доказательства. Ну, не можем пройти мимо пару следствий. Значит,
[07:45.320 --> 07:58.480]  теорема, у нее такое название, о двух рядах. Кого теорема-то? Калмагорова.
[08:03.800 --> 08:13.360]  Теорема гласит следующее. Пусть у нас опять же есть последующий независимых случайных величин,
[08:13.360 --> 08:25.480]  известно про нее, что ряд из мат ожиданий сходится и ряд из дисперсий сходится. Тогда утверждение
[08:25.480 --> 08:36.520]  теоремы, что ряд из ксиэнных сходится почти наверное. Обратите внимание, тут уже нет
[08:36.520 --> 08:43.640]  центрированности, просто ряд из ксиэнных сходится почти наверное. У этой теоремы есть как бы и второе
[08:43.640 --> 08:52.040]  утверждение, если все ксиэнные с вероятностью единицы ограничены, равномерно ограничены,
[08:52.040 --> 08:57.920]  то есть сходимости почти наверное, следует сходимость вот этих двух рядов, но мы докажем в
[08:57.920 --> 09:05.480]  одну сторону, потому что уж ничего нам не стоит это. Итак, согласно теореме Калмагорова-Хинчина,
[09:05.480 --> 09:13.940]  вот такой ряд ксиэнцентрированная, который на самом деле есть ксиэнная, минус мат ожидания,
[09:14.780 --> 09:22.460]  но поскольку это предел случайно увлечена, то случайно увлечена меньше бесконечности почти наверное.
[09:22.460 --> 09:33.620]  Ряд из е ксиенного сходится, просто безпочти наверное по условию, но и отсюда следует,
[09:33.620 --> 09:44.020]  что ряд из ксиенных сходится почти наверное. Теорема о двух рядах. Следующая теорема
[09:44.020 --> 09:49.540]  называется теоремой о трех рядах, ну и естественно тоже Калмагорова по-английски.
[09:49.540 --> 10:09.100]  Значит все то же самое, ксиэнная последовательность независимых случайных величин. И существует такое
[10:09.100 --> 10:18.820]  число С, ну больше нуля. Такое, что вот если мы введем такую случайную величину, ксиэнная с индексом
[10:18.820 --> 10:30.220]  С по следующему правилу, она просто равна ксиэнной, если ксиэнная по модулю меньше или равно С,
[10:30.220 --> 10:47.820]  и ноль если ксиэнная по модулю больше С. Вот такая случайная величина называется усеченной,
[10:47.820 --> 10:54.900]  ну естественно так сказать по построению. И представляет из себя удобный теоретический прием,
[10:54.900 --> 11:01.900]  введенный Калмагоровым. Вот и так значит пусть у нас есть последовательность независимых
[11:01.900 --> 11:08.580]  случайных величин, при некотором С мы вводим последовательность усеченных случайных величин.
[11:08.580 --> 11:15.380]  И вот про эти усеченные случайные величины известно следующее, что сумма из мат ожиданий ксиенного
[11:15.380 --> 11:28.140]  сходится. Сумма из дисперсий усеченного сходится. И еще вот такой ряд сходится. Вероятность того,
[11:28.140 --> 11:39.100]  что ксиэнная по модулю больше С. Знаете, это все равно, но немножко не привычно мне. Давайте вот так,
[11:39.100 --> 11:45.300]  знак равно так сказать вот так. Меньше С и больше равно. Ну конечно это ни на что не влияет.
[11:45.300 --> 12:01.260]  Так, и еще известно, что вот такой ряд сходится. Тогда утверждение теоремы состоит в том, что уже
[12:01.260 --> 12:16.260]  не усеченный, а исходный ряд сходится почти наверно. Формулировка. Значит, ну как бы понятен прием.
[12:16.260 --> 12:23.580]  Для усеченного ряда мат ожидания всегда существует, точнее для усеченной случайной величины. Дисперсия
[12:23.580 --> 12:29.380]  всегда существует. Исследовали ряд. Если вот такому свойству удовлетворяет, то значит можно
[12:29.380 --> 12:38.420]  и происходный ряд сказать, что он почти наверно сходится. Верное и обратное. Для равномерно
[12:38.420 --> 12:45.220]  ограниченных с вероятностью 1 случайных величин ксиэнная. Исходимости этого ряда. Вот эти три
[12:45.220 --> 12:59.380]  ряда сходятся для любого С. Для любого С. Но мы докажем в одну сторону. Значит, ну во-первых,
[12:59.380 --> 13:12.020]  из теоремы о двух рядах следует, что вот такой ряд сходится. Ну меньше бесконечности почти
[13:12.020 --> 13:18.100]  наверно. Усеченный ряд сходится. Потому что для усеченных случайных величин мат ожидания
[13:18.100 --> 13:27.140]  и дисперсии сходится. А теперь давайте посмотрим, что это за событие ксиэнная больше или равно С. Ну
[13:27.140 --> 13:37.340]  просто из определения видно, что ксиэнная по модулю больше или равно С. Это эквивалент на событию,
[13:37.340 --> 13:49.900]  что ксиэнная не равно ксиэн усеченная. Не равно, да? Смотрите, вероятность событий ксиэнная не
[13:49.900 --> 14:00.580]  равно ксиэн усеченная. Ряд из этих вероятностей сходится. Что отсюда следует? Лемма барреля
[14:01.460 --> 14:07.340]  Вот настало время нам воспользоваться всеми теми знаниями, которые мы тут получали. Из
[14:07.340 --> 14:14.180]  леммы барреля кантелли следует, что вот это событие ксиэнная по модулю больше С, то есть ксиэнная
[14:14.180 --> 14:22.660]  не равно ксиэнная усеченная, происходит конечное число раз с вероятностью единица. То есть каждое
[14:23.540 --> 14:29.460]  порождает последовательность ксиэнная, каждое омега порождает последовательность ксиэнная С и
[14:29.460 --> 14:37.700]  эти две последовательности для почти всех омира обладают тем свойством, что ксиэнная
[14:37.700 --> 14:45.460]  не равно ксиэнная усеченная конечное число раз, а два ряда, которые различаются только конечное
[14:45.460 --> 14:51.220]  число членов, конечно одновременно сходятся или расходятся. Вот и всё.
[14:51.220 --> 14:55.940]  Это довольно серьезные теоретические результаты,
[14:55.940 --> 15:00.340]  но хочу обратить внимание, что накопленных нами знаний
[15:00.340 --> 15:04.020]  хватило для того, чтобы в две строчки их доказать.
[15:04.020 --> 15:12.540]  С теоремы Хинчина и очевидными выводами из нее, коими являются
[15:12.540 --> 15:17.420]  теоремы о двух и трех рядах, мы заканчиваем и возвращаемся
[15:17.420 --> 15:23.140]  к нашей тематике, связанной с Законом Больших Чисел.
[15:23.140 --> 15:29.660]  Напомню, что мы с вами исследовали свойства случайных последствий,
[15:29.660 --> 15:35.180]  которые называются Законом Больших Чисел.
[15:35.180 --> 15:39.260]  Попросту это означает, что средние значения концентрируются
[15:39.260 --> 15:40.580]  вокруг мат ожиданий.
[15:40.580 --> 15:46.340]  И мы получили ряд результатов, достаточных условий, критерий
[15:46.340 --> 15:49.460]  и Калмогорова, необходимые достаточные условия для
[15:49.460 --> 15:52.300]  выполнения Закона Больших Чисел.
[15:52.300 --> 15:55.420]  Следующее свойство случайных последствий, которые мы
[15:55.420 --> 15:59.460]  рассмотрели, это так называемый усиленный Закон Больших
[15:59.460 --> 16:00.460]  Чисел.
[16:00.460 --> 16:02.420]  Усиленный Закон Больших Чисел.
[16:02.420 --> 16:08.300]  Он называется усиленный, на самом деле, просто потому,
[16:08.300 --> 16:13.140]  что в нем сходимость по вероятности заменяется
[16:13.900 --> 16:14.900]  почти на верное.
[16:14.900 --> 16:24.100]  Итак, для последствий КСН, если для последствий КСН
[16:24.100 --> 16:29.660]  существует такая числовая последствия АН, такая, что
[16:29.660 --> 16:37.700]  КСН среднее минус АН сходится к нулю почти на верное, то
[16:37.700 --> 16:41.060]  мы говорим, что для данной последствия выполнен усиленный
[16:41.060 --> 16:45.820]  Закон Больших Чисел.
[16:45.820 --> 16:48.340]  Интерес наш понятен, мы тоже хотим указать какие-то
[16:48.340 --> 16:54.940]  условия на случайные последовательности, при которых выполнен усиленный
[16:54.940 --> 16:55.940]  Закон Больших Чисел.
[16:55.940 --> 17:01.340]  И в этой области существует две главные теоремы.
[17:01.340 --> 17:08.420]  Одна называется первая теорема Калмогорова, ну а вторая
[17:08.420 --> 17:09.420]  теорема Калмогорова.
[17:10.100 --> 17:15.620]  Перед тем, как бы к ней перейти, давайте опишем условия,
[17:15.620 --> 17:16.620]  в которых мы работаем.
[17:16.620 --> 17:21.500]  Значит, первый случай, который мы рассмотрим, это когда
[17:21.500 --> 17:26.140]  АН, как и в Законе Больших Чисел, это математическое
[17:26.140 --> 17:33.260]  ожидание, КСН среднее, тогда условия выполнения Закона
[17:33.260 --> 17:36.980]  Больших Чисел, мы по аналогии, как и просто Закона Больших
[17:36.980 --> 17:38.820]  Чисел, перепишем так.
[17:38.820 --> 17:46.820]  Среднее значение случайных величин, у которых мы вычислим
[17:46.820 --> 17:51.660]  от ожидания, будет стремиться к нулю, только теперь почти
[17:51.660 --> 17:56.660]  наверное.
[17:56.660 --> 17:57.660]  Вот.
[17:57.660 --> 18:01.420]  Мы хотим получить какое-нибудь условие, достаточное для
[18:01.420 --> 18:04.660]  того, чтобы вот такая сходимость выполнялась.
[18:04.700 --> 18:06.700]  Значит, вопрос?
[18:09.700 --> 18:10.700]  Здесь-то?
[18:10.700 --> 18:12.700]  Прошу прощения, да, к нулю.
[18:12.700 --> 18:13.700]  Да.
[18:14.700 --> 18:15.700]  Вот.
[18:15.700 --> 18:20.500]  Значит, ну и вот, собственно, первая теорема Калмогорова,
[18:20.500 --> 18:26.100]  она про это, но мы, правда, докажем чуть более общий
[18:26.100 --> 18:29.140]  результат, чем теорема Калмогорова, а теорема Калмогорова
[18:29.140 --> 18:31.860]  будет следствием, первая теорема Калмогорова.
[18:32.060 --> 18:36.180]  Значит, давайте вспомним из математического анализа
[18:36.180 --> 18:39.580]  такой результат, Леммабеля, по-моему, называется.
[18:39.580 --> 18:41.860]  Вот пусть у нас есть две последовательности,
[18:41.860 --> 18:45.300]  хн и bn.
[18:45.300 --> 18:52.660]  Про хн известно, что ряд из хн сходится, а bn – это
[18:52.660 --> 18:56.260]  такая монотонно возрастающая последовательность, не
[18:56.260 --> 18:59.140]  отрицательная, положительная, которая сходится к плюс
[18:59.140 --> 19:00.140]  бесконечности.
[19:01.140 --> 19:06.620]  Вот если две таких последовательности у нас есть, то тогда единица
[19:06.620 --> 19:13.980]  делить на bн сумма хкт и bкт, k равно от 1 до n, стремится
[19:13.980 --> 19:14.980]  к чему?
[19:17.980 --> 19:20.820]  К нулю, коллеги, при этом стремяйся бесконечности.
[19:20.820 --> 19:28.300]  Известен вам такой результат из математического анализа?
[19:28.300 --> 19:29.300]  Не сталкивались?
[19:29.460 --> 19:34.300]  Ну, несложный результат, не буду тратить время на
[19:34.300 --> 19:35.300]  его доказательства.
[19:35.300 --> 19:36.300]  Вот.
[19:36.300 --> 19:42.580]  Ну и давайте теперь рассмотрим, возьмем вот такую последовательность
[19:42.580 --> 19:49.300]  хн, это у нас будут независимые случайные величины, и введем
[19:49.300 --> 19:53.700]  новую последовательность случайных величин, это n,
[19:53.700 --> 19:59.580]  которая равно хн центрированная делить на bн, просто новую
[19:59.580 --> 20:00.580]  последовательность.
[20:00.580 --> 20:01.580]  Ведем вот такую.
[20:03.580 --> 20:07.020]  Ну и давайте потребуем или рассмотрим такой случай,
[20:07.020 --> 20:11.500]  когда сумма дисперсии это n, которая на самом деле
[20:11.500 --> 20:18.300]  равна сумме дисперсии хн делить на bн в квадрате,
[20:18.300 --> 20:19.300]  сходится.
[20:19.300 --> 20:20.620]  Пусть такой ряд сходится.
[20:20.620 --> 20:21.620]  Пусть.
[20:23.700 --> 20:32.100]  Тогда отсюда следует, что ряд из это n, который
[20:32.100 --> 20:39.660]  есть на самом деле ряд из кси n центрированных делить
[20:39.660 --> 20:49.580]  на bн, он у нас тоже сходится, почти, наверное, и вот на
[20:49.580 --> 20:53.340]  этом множестве, почти, наверное, с вероятностью единицы,
[20:53.340 --> 20:56.820]  что и сходится вот на этом множестве, давайте рассмотрим
[20:56.820 --> 20:59.060]  вот такую вот величину.
[20:59.060 --> 21:08.780]  Единица делить на bн, сумма это kt умножить на bkt, k равен
[21:08.780 --> 21:09.780]  единице до n.
[21:09.780 --> 21:16.180]  На множестве, где вот этот ряд сходится, а еще раз
[21:16.180 --> 21:19.740]  это множество меры единицы, на этом же множестве вот
[21:19.740 --> 21:25.380]  эта величина будет стремиться к нулю, вот полемиабеля
[21:25.380 --> 21:30.300]  прен, стремящаяся к бесконечности.
[21:30.300 --> 21:32.300]  Понятно, да?
[21:32.300 --> 21:36.100]  Ну, осталось, что называется, подставить, то есть это
[21:36.100 --> 21:43.660]  то же самое, что единица на bн, сумма, кси, kt, единица
[21:43.660 --> 21:49.340]  до n, кат, единица на n, стремится к нулю, почти, наверное.
[21:49.340 --> 21:59.620]  Правильно, да, потому что это kt, кси, kt делить на bkt,
[21:59.620 --> 22:02.460]  bkt сокращается, они у нас не равны нулю, получается
[22:02.460 --> 22:03.460]  такая штука.
[22:03.460 --> 22:07.220]  Ну, итак, мы с вами доказали следующий результат.
[22:07.220 --> 22:09.940]  Есть ли вот такой ряд для последствий независимых
[22:09.940 --> 22:14.260]  случайных величин и некой последствий bн монотонно
[22:14.260 --> 22:17.980]  возрастающей сходится, то тогда вот такая величина
[22:17.980 --> 22:20.460]  стремится к нулю, почти, наверное.
[22:20.460 --> 22:26.580]  Чтобы получить теорему Калмагорова, осталось положить bn, это
[22:26.580 --> 22:31.660]  аж здесь, на равно n, и мы получаем теорему Калмагорова,
[22:31.660 --> 22:39.860]  первая, вот здесь, первая теорема Калмагорова.
[22:39.860 --> 22:46.700]  Если для последствий независимых случайных величин вот такой
[22:46.700 --> 23:01.300]  ряд сходится, то отсюда следует, что кси, n, центрированная
[23:01.300 --> 23:04.660]  средняя стремится к нулю, почти, наверное, сходится
[23:04.660 --> 23:07.500]  к нулю, почти, наверное.
[23:07.500 --> 23:12.300]  Вот первая теорема Калмагорова, достаточно условия, достаточно
[23:12.300 --> 23:15.300]  условия для последовательности независимых случайных
[23:15.300 --> 23:23.900]  величин, и вот для такой последовательности а n выполнен усиленный закон
[23:23.900 --> 23:24.900]  больших чисел.
[23:24.900 --> 23:27.900]  Понятно?
[23:27.900 --> 23:32.660]  Так, значит, дальше.
[23:32.660 --> 23:38.580]  И вторая теорема Калмагорова, вторая теорема Калмагорова.
[23:57.900 --> 24:10.020]  Вторую теорему Калмагорова я сформулирую, но докажу
[24:10.020 --> 24:13.420]  в следующий раз, чтобы, ну, сейчас уже ближе к концу
[24:13.420 --> 24:16.940]  семестра дать максимальный материал, чтобы вы могли
[24:16.940 --> 24:19.580]  там задачи решать и так далее.
[24:19.580 --> 24:29.660]  Значит, вторая теорема Калмагорова, вторая теорема
[24:29.660 --> 24:37.740]  Калмагорова гласит, пусть ксиенная последствия независимых
[24:37.740 --> 24:41.460]  одинаково распределенных случайных величин, то есть
[24:41.460 --> 24:44.860]  мы ищем условия выполнения усиленного закона больших
[24:44.860 --> 24:48.420]  чисел для последствий независимых одинаково распределенных
[24:48.420 --> 24:49.420]  случайных величин.
[24:49.420 --> 24:55.260]  Если ксиенные одинаково распределены, то в отожидании
[24:55.260 --> 25:01.740]  ксиен среднего чему равно, раз они одинаково распределены?
[25:01.740 --> 25:04.740]  Ну просто в отожидании кси, да, без индекса.
[25:04.740 --> 25:09.140]  Вот, так вот, если ксиенные независимо распределенные
[25:09.140 --> 25:19.620]  случайные величины, то, значит, если существует
[25:19.620 --> 25:24.900]  А такое, что ксиен средний минус А сходится к нулю
[25:24.900 --> 25:31.820]  почти наверно, или для того, чтобы ксиенная минус А для
[25:31.820 --> 25:34.900]  какого-то А сходилась к нулю почти наверно, необходимо
[25:34.900 --> 25:39.120]  и достаточно, чтобы существовало математическое ожидание
[25:39.120 --> 25:42.880]  кси, равное как раз вот этому А.
[25:42.880 --> 25:49.480]  Ну или там, чуть по-другому, если у вас есть последствия
[25:49.480 --> 25:51.880]  независимых одинаково распределенных случайных
[25:51.880 --> 25:58.160]  величин, для которых существует мат ожидания, то среднее
[25:58.160 --> 26:01.840]  значение сходится к этому мат ожиданию почти наверно,
[26:01.840 --> 26:05.920]  и наоборот, если вы установили, что среднее значение сходится
[26:05.920 --> 26:09.360]  к какому-то числу почти наверно, то это означает,
[26:09.360 --> 26:13.520]  что у кси существует мат ожидания в точности равная
[26:13.520 --> 26:14.520]  этому числу.
[26:14.520 --> 26:16.560]  Вот вторая теорема Колмогорова.
[26:16.560 --> 26:23.800]  Значит, у нее такой вот теоремы классическое колмогоровское
[26:23.800 --> 26:27.640]  доказательство, немножко, так сказать, не в две строчки
[26:27.640 --> 26:31.080]  оно получается, но, тем не менее, с удовольствием
[26:31.080 --> 26:34.080]  я вам его расскажу, потому что это, ну, как бы, просто,
[26:34.080 --> 26:36.080]  как бы, красиво, да.
[26:36.080 --> 26:37.080]  Вот.
[26:37.080 --> 26:39.560]  Значит, это за мной должок.
[26:39.560 --> 27:05.560]  Итак, мы с вами, ну, за последние там лекцию, пару лекций изучили
[27:05.560 --> 27:11.720]  такое свойство вероятностной меры, как сходимость или
[27:11.720 --> 27:15.200]  концентрация средних значений вокруг мат ожиданий.
[27:15.200 --> 27:19.440]  Я в самом начале курса говорил, что это, ну, что как бы, основные
[27:19.440 --> 27:22.520]  результаты теории вероятности, отличающие ее от просто
[27:22.520 --> 27:27.200]  теории меры, это то, что в ней устанавливаются некоторые
[27:27.200 --> 27:32.440]  факты концентрации вероятности меры для, ну, каких-то средних
[27:32.440 --> 27:35.320]  или специальным образом нормированных значений
[27:35.320 --> 27:39.440]  вокруг, так сказать, каких-то конкретных распределений
[27:39.440 --> 27:40.440]  или величин.
[27:40.440 --> 27:45.600]  И мало того, я здесь позволю себе повторить, это не просто
[27:45.600 --> 27:51.000]  математический результат, это математическое описание
[27:51.000 --> 27:54.560]  реально существующего закона, то есть, тот, который имеет
[27:54.560 --> 27:57.960]  место в природе, это не абстракция, это описание
[27:57.960 --> 27:59.520]  реальной картины мира.
[27:59.600 --> 28:04.320]  Ну и сегодня мы как бы еще это, ну, я подчеркну, когда
[28:04.320 --> 28:08.080]  будет об этом заходить вопрос, что называется.
[28:08.080 --> 28:14.280]  Так, значит, следующий наш, следующая группа результатов
[28:14.280 --> 28:19.120]  будет посвящена концентрации уже, там, ну, каких-то, так
[28:19.120 --> 28:22.200]  сказать, там средних или других значений не в окрестности
[28:22.200 --> 28:26.320]  числа, а в окрестности некоего распределения, некоего
[28:26.320 --> 28:29.280]  такого предельного, финального распределения.
[28:29.280 --> 28:35.400]  И в качестве первого примера мы рассмотрим теорему Пуассона,
[28:35.400 --> 28:38.800]  но до этого введем просто число, в смысле, введем просто
[28:38.800 --> 28:43.760]  некое понятие, ничего в нем особенного, ну, сократит
[28:43.760 --> 28:48.000]  наши, так сказать, сложно подчиненные предложения.
[28:48.000 --> 28:52.880]  Давайте введем такую двухындексную систему случайных величин.
[28:52.880 --> 29:02.640]  Кад 1 до n, которые мы назовем сериями, серией случайных
[29:02.640 --> 29:03.640]  величин.
[29:03.640 --> 29:06.800]  Единственное общее свойство, которое мы, так сказать,
[29:06.800 --> 29:09.920]  на серии накладывал, что случайные величины внутри
[29:09.920 --> 29:11.200]  серии независимы.
[29:11.200 --> 29:15.200]  С другими сериями могут быть зависимы, то есть это
[29:15.200 --> 29:18.640]  не независимые все совокупности случайных величин, которые
[29:18.640 --> 29:22.200]  выходят во все серии, только у нас требования к независимости
[29:22.200 --> 29:23.920]  внутри серии.
[29:23.920 --> 29:24.920]  Вот.
[29:24.920 --> 29:29.040]  Просто термин, которым я буду оперировать, ничего
[29:29.040 --> 29:32.560]  там особого нет, просто чтобы не говорить такие сложные
[29:32.560 --> 29:33.560]  конструкции.
[29:33.560 --> 29:34.560]  Вот.
[29:34.560 --> 29:38.480]  Ну и давайте первый, так сказать, шаг, который мы
[29:38.480 --> 29:39.480]  сделаем.
[29:39.480 --> 29:49.360]  Давайте считать, что вот эта наша серия принадлежит
[29:50.080 --> 29:53.680]  случайной величины с неким параметром pn.
[29:53.680 --> 29:58.720]  То есть p, n, k, t – независимые одинаково распределенные
[29:58.720 --> 30:03.800]  случайные величины с параметром pn, то есть параметр зависит
[30:03.800 --> 30:07.440]  от индекса серии, так сказать.
[30:07.440 --> 30:08.440]  Значит первое.
[30:08.440 --> 30:13.520]  И второе, давайте на pn наложим еще одно симпатическое
[30:13.520 --> 30:18.480]  условие, то есть это не произвольные pn от 0 до 1, а давайте считать,
[30:18.480 --> 30:23.440]  что n умножить на pn сходится к некоторому числу лямда.
[30:23.440 --> 30:26.600]  Ну ясно, больше 0.
[30:26.600 --> 30:28.080]  Вот такие серии рассматриваем.
[30:28.080 --> 30:38.240]  То есть в каждой серии это набор Бернулевских случайных
[30:38.240 --> 30:39.240]  величин.
[30:39.240 --> 30:44.240]  Я Бернулевский сказал или Бенемиалер?
[30:44.240 --> 30:45.240]  Бернулевский.
[30:45.240 --> 30:46.240]  Бернулевский.
[30:46.240 --> 30:49.280]  То есть каждый из этих случайных величин принимает значение
[30:49.280 --> 30:53.440]  0, 1, 1 принимает с вероятностью pn.
[30:53.440 --> 30:56.200]  Вот такие серии рассматриваем.
[30:56.200 --> 30:59.040]  И давайте введем такую же одноиндексную случайную
[30:59.040 --> 31:04.640]  величину, эта n, которая просто равна сумме это n-катах.
[31:04.640 --> 31:08.840]  Кат единицы до n.
[31:08.840 --> 31:14.240]  Какое, кстати, распределение имеет эта n?
[31:14.240 --> 31:15.240]  Бенемиальное.
[31:15.240 --> 31:18.440]  Сумма Бернулевских случайных величин независимых имеет
[31:18.440 --> 31:20.400]  бенемиальное распределение.
[31:20.400 --> 31:36.480]  Так вот теорема Пуассона гласит, что эта n-ная сходится
[31:36.480 --> 31:43.000]  по распределению Пуассоновской случайной величине с параметром
[31:43.000 --> 31:44.000]  лямда.
[31:44.000 --> 31:53.200]  То есть если вы будете генерировать случайные величины по этому
[31:53.200 --> 31:58.200]  правилу, брать независимые, вероятность успеха будет
[31:58.200 --> 32:01.160]  вот так себя вести, то в результате вы получите
[32:01.160 --> 32:05.400]  случайную величину в пределе, которая по распределению
[32:05.400 --> 32:08.560]  будет совпадать с Пуассоновской вот с этим параметром.
[32:08.560 --> 32:16.880]  То есть сумма членов в такой серии при достаточно
[32:16.880 --> 32:20.600]  большом n на самом деле имеет распределение Пуассона.
[32:20.600 --> 32:25.640]  Хотя для каждого конкретного n это бенемиальное распределение.
[32:25.640 --> 32:32.400]  Как будем доказывать, как думаете?
[32:32.400 --> 32:34.320]  Характеристическими функциями воспользуемся.
[32:34.320 --> 32:37.600]  Это, так сказать, самый удобный и простой аппарат в данном
[32:38.200 --> 32:42.200]  Ну и давайте вот эту вот характеристическую функцию,
[32:42.200 --> 32:47.880]  это n от t, напишем по определению, что это такое, это математическое
[32:47.880 --> 33:00.200]  ожидание e в степени i t, сумма это n катых, кат единицы
[33:00.200 --> 33:01.200]  до n.
[33:01.200 --> 33:04.600]  Все n каты независимые одинаково распределены, поэтому это
[33:04.600 --> 33:09.480]  произведение характеристических функций для каждого n-катого,
[33:09.480 --> 33:16.760]  они у всех одинаково распределены, и это просто есть qn-ное плюс
[33:16.760 --> 33:22.680]  pn-ное на e в степени i t в степени n.
[33:22.680 --> 33:23.680]  Согласны?
[33:23.680 --> 33:24.680]  Равно.
[33:24.760 --> 33:36.960]  Ну вот в таком виде перепишу qn плюс pn плюс pn e в степени
[33:36.960 --> 33:52.360]  i t минус 1, умножу на n и поделю на n.
[33:53.040 --> 33:57.640]  Вот эта сумма чему равна?
[33:57.640 --> 33:58.640]  Единица.
[33:58.640 --> 34:05.960]  n на pn стремится к лямбда, значит к чему все вот это выражение
[34:05.960 --> 34:12.040]  стремится, qn стремяще к бесконечности, кто мне скажет.
[34:12.040 --> 34:23.800]  e в степени лямбда в показателе в степени e в степени i t минус
[34:23.800 --> 34:24.800]  1.
[34:24.800 --> 34:32.920]  А это чего характеристическая функция?
[34:32.920 --> 34:36.920]  Это распределение Пуассона с параметром лямбда.
[34:36.920 --> 34:40.840]  Итак, мы получили, что характеристическая функция
[34:40.840 --> 34:44.280]  tn сходится к характеристической функции Пуассоновского
[34:44.280 --> 34:49.960]  распределения, а это значит, как мы знаем, что эта n-ное
[34:49.960 --> 34:52.960]  сходится по распределению к Пуассоновской случайной
[34:52.960 --> 34:53.960]  величине.
[34:53.960 --> 34:58.040]  Вот, собственно, первый результат из этого класса,
[34:58.040 --> 34:59.040]  так сказать.
[34:59.040 --> 35:09.160]  Ну, а дальше у нас, как говорится, будет посерьезней задача.
[35:09.160 --> 35:23.760]  Я даже, пожалуй, вот здесь сотру.
[35:23.760 --> 35:49.600]  Давайте рассмотрим серию.
[35:49.600 --> 36:00.960]  Но здесь, кроме независимости, наложим еще дополнительные
[36:00.960 --> 36:04.160]  условия на эту серию, которую будем рассматривать.
[36:04.160 --> 36:11.640]  Мотожидание это n-катова равно 0, kat единицы до n, то есть
[36:11.640 --> 36:15.800]  все они имеют нулевое мотожидание.
[36:15.800 --> 36:18.440]  И еще есть условия на дисперсию.
[36:18.440 --> 36:32.040]  Сумма дисперсии это n-катова, kat единицы до n, равно единице.
[36:32.040 --> 36:35.720]  Ну вот, специфичные, пока специфичные, может быть,
[36:35.720 --> 36:38.200]  не очень понятные условия, но рассматриваем вот такие
[36:38.200 --> 36:39.200]  серии.
[36:39.200 --> 36:43.320]  Если мы рассматриваем такие серии, то имеют место
[36:43.320 --> 36:45.640]  следующие утверждения.
[36:45.640 --> 36:49.360]  Первое.
[36:49.360 --> 36:58.280]  Значит, если для любого tau больше нуля сумма kat единицы
[36:58.280 --> 37:05.880]  до n интеграл по области x по модулю больше епсилон
[37:06.240 --> 37:13.400]  x квадрат d f n-k от x, f n-k от x это функция распределения
[37:13.400 --> 37:17.080]  случайной величины, это n-k.
[37:17.080 --> 37:21.620]  Значит, если вот такая штука стремится к нулю, при
[37:22.460 --> 37:23.460]  бесконечности.
[37:23.460 --> 37:36.940]  И это условие, называется условие Линдберга, условие
[37:36.940 --> 37:37.940]  Линдберга.
[37:37.940 --> 37:46.300]  Если имеет место условие Линдберга, то имеют место
[37:46.300 --> 37:48.820]  два следующих утверждения.
[37:48.940 --> 37:56.940]  Во-первых, для любого епсилон больше нуля максимум вероятности
[37:56.940 --> 38:03.180]  того, что эта n-кат по модулю будет больше епсилон, когда
[38:03.180 --> 38:08.900]  максимум берется от единицы до n, стремится к нулю, при
[38:08.900 --> 38:10.580]  н стремящейся к бесконечности.
[38:10.580 --> 38:15.140]  Вот такое свойство.
[38:15.140 --> 38:19.780]  Но если посмотреть на его определение, то это можно
[38:19.780 --> 38:28.140]  назвать равномерной исходимостью по вероятности серии, равномерная
[38:28.140 --> 38:29.540]  исходимость по вероятности.
[38:29.540 --> 38:33.940]  Но в литературе встречается еще более такое поэтичное
[38:33.940 --> 38:40.940]  определение вот этого факта, мало о чем говорящее, но
[38:40.940 --> 38:41.940]  звучит неплохо.
[38:42.740 --> 38:50.140]  Когда выполнено такое свойство, говорят, что серия – это
[38:50.140 --> 38:55.340]  серия бесконечно малых, или пренебрежимо малых,
[38:55.340 --> 38:58.020]  или асимпатически пренебрежимо малых.
[38:58.020 --> 39:02.300]  То есть если просто услышать, непонятно в каком смысле
[39:02.300 --> 39:04.700]  малых, что малое здесь.
[39:04.700 --> 39:07.420]  На самом деле это просто как бы равномерная исходимость
[39:07.420 --> 39:10.500]  по вероятности к нулю, но термин прижился.
[39:10.500 --> 39:14.700]  Значит и так, если выполнено условие Линдберга, то серия
[39:14.700 --> 39:18.260]  представляет из себя серию пренебрежимо малых, случайных
[39:18.260 --> 39:19.260]  величин.
[39:19.260 --> 39:27.180]  И, пожалуй, более важное свойство, три, это n, которая
[39:27.180 --> 39:33.660]  есть сумма, это n-катах, кат единицы до n, сходится
[39:33.660 --> 39:38.500]  по распределению к стандартному нормальному распределению.
[39:38.500 --> 39:43.260]  Вот, конечно, ради чего всё это.
[39:43.260 --> 39:49.300]  То есть сумма случайных величин в серии асимпатически
[39:49.300 --> 39:50.300]  нормальна.
[39:50.300 --> 39:55.100]  Обратите внимание, что здесь ничего не говорится
[39:55.100 --> 39:58.420]  о том, какое распределение у них, какое бы ни было
[39:58.420 --> 40:02.420]  распределение, сходится всегда к нормальному закону.
[40:02.420 --> 40:08.260]  И это фундаментальный факт нашего мироздания.
[40:08.260 --> 40:10.140]  Это был звонок, да?
[40:10.140 --> 40:13.700]  Ну, отдохните и, собственно, приступим к доказательству.
[40:13.700 --> 40:17.580]  А, извините, буквально за слово, чтобы не… Вот это
[40:17.580 --> 40:21.140]  верно и в обратную сторону верно.
[40:21.140 --> 40:23.820]  Вот, ну вот теперь отдыхайте.
[40:23.820 --> 40:25.820]  Всё нормально?
[40:25.820 --> 40:31.780]  Так, коллеги, ну, значит, собственно, переходим к доказательству.
[40:31.780 --> 40:40.180]  Вот эта теорема, она называется или должна называться теоремой
[40:40.180 --> 40:42.100]  Линдберг-Галевия.
[40:42.100 --> 40:46.940]  Хотя результат, полученный этими учёными-мужами, сильно
[40:46.940 --> 40:49.780]  отличался от того, как он сейчас формулирует, это
[40:49.780 --> 40:51.660]  уже как бы современная трактовка.
[40:51.660 --> 40:55.340]  Я сегодня приведу теорему Линдберг-Галевия, назову
[40:55.340 --> 40:57.300]  её, так сказать, ретро-теоремой.
[40:57.860 --> 41:02.900]  И хочу сказать, что это, пожалуй, единственная, может
[41:02.900 --> 41:06.740]  быть, с какими-то небольшими оговорками, это единственная
[41:06.740 --> 41:09.980]  фундаментальная теорема в теории вероятности, которая
[41:09.980 --> 41:12.740]  не носит имени наших соотечественников.
[41:12.740 --> 41:16.060]  То есть теория вероятности – это наша наука.
[41:16.060 --> 41:19.540]  Вот, значит, ну, давайте, нам понадобятся некоторые
[41:19.540 --> 41:23.300]  факты технического плана, которые я вот… Давайте
[41:23.300 --> 41:24.780]  вот на этой доске выпишу.
[41:25.740 --> 41:31.500]  Так, так, сейчас, для собственного удобства напишу разложение
[41:31.500 --> 41:33.540]  e в степени и альфа в ряд.
[41:33.540 --> 41:39.500]  Это единица плюс и альфа минус альфа квадрат пополам
[41:39.500 --> 41:44.300]  минус и альфа в кубе на 6 плюс и так далее.
[41:44.300 --> 41:48.940]  Вот, знакопеременный ряд, как бы, отсюда имеют
[41:48.940 --> 41:51.660]  место следующее неравенство.
[41:51.660 --> 41:56.380]  e в степени и альфа минус 1 по модулю меньше или равно
[41:56.380 --> 42:05.460]  модуле альфа, e в степени и альфа минус 1 минус и альфа
[42:05.460 --> 42:09.980]  по модулю меньше или равно альфа квадрат пополам,
[42:09.980 --> 42:15.300]  и еще нам понадобится одно неравенство, чуть еще более
[42:15.300 --> 42:16.300]  тонкое.
[42:16.300 --> 42:24.180]  e в степени и альфа минус 1 минус и альфа плюс альфа
[42:24.180 --> 42:29.140]  квадрат пополам по модулю меньше или равно модуль альфа
[42:29.140 --> 42:30.500]  в кубе делит на 6.
[42:30.500 --> 42:37.100]  Ну, это можно разными способами доказать.
[42:37.100 --> 42:41.900]  То, что я написал, это не доказательство, но просто
[42:41.900 --> 42:46.820]  поскольку это два знакопеременных ряда, это же на самом деле
[42:46.820 --> 42:54.020]  косинус, альфа плюс и синус альфа, то остаток ряда
[42:54.020 --> 42:55.580]  членов его ограничивается.
[42:55.580 --> 42:58.940]  Вот таких вот три неравенства.
[42:58.940 --> 43:04.700]  Так, ну и уже чего-то можем сделать.
[43:04.700 --> 43:09.340]  Давайте докажем, что из 1 следует 2 для начала.
[43:09.340 --> 43:11.740]  Это сделаем и потом про это забудем.
[43:11.740 --> 43:15.540]  Результаты, которые будем получать, используя 2, будем
[43:15.540 --> 43:18.220]  понимать, что они следуют из 1.
[43:18.220 --> 43:23.740]  Итак, давайте напишем вероятность того, что это nkt по модулю
[43:23.740 --> 43:28.140]  больше епсилонт через интеграл либега стилт ес.
[43:28.140 --> 43:29.140]  Это что такое?
[43:29.140 --> 43:39.220]  Это интеграл df nk от x при условии, что x по модулю
[43:39.220 --> 43:41.100]  больше епсилонт.
[43:41.100 --> 43:42.580]  Правильно, да?
[43:42.580 --> 43:43.580]  Вот.
[43:43.580 --> 43:47.340]  В области интегрирования x по модулю делить на епсилонт
[43:47.340 --> 43:51.100]  больше единицы, поэтому могу написать, меньше или равно
[43:51.100 --> 43:59.180]  единица на епсилонт квадрат интеграл x квадрат df nk от x,
[43:59.180 --> 44:04.420]  x по модулю больше епсилонт.
[44:04.420 --> 44:08.380]  Я беру максимум от обоих частей, знак неравенство
[44:08.380 --> 44:13.500]  сохраняется, а здесь вместо максимума заменяю на сумму.
[44:13.500 --> 44:21.780]  То есть получаю, что максимум k от единицы до n, вероятность
[44:21.780 --> 44:27.140]  это nkt больше епсилонт, меньше или равна единица на епсилонт
[44:27.140 --> 44:36.060]  квадрат, сумма x квадрат df nk от x, x по модулю больше
[44:36.060 --> 44:47.980]  епсилонт.
[44:47.980 --> 44:56.980]  Эпсилонт.
[44:56.980 --> 45:02.060]  Ну в смысле, это tau, поэтому вот здесь давайте на tau исправим.
[45:02.060 --> 45:12.620]  Ну а собственно вот это и есть условие Линдберг-Леве,
[45:12.620 --> 45:15.300]  если оно стремится к нулю, значит и максимум стремится
[45:15.300 --> 45:16.300]  к нулю.
[45:16.300 --> 45:26.460]  Немножко заскочил вперед в том смысле, что хотел
[45:26.460 --> 45:31.380]  сначала рассказать, как эти серии строить, чтобы они
[45:31.380 --> 45:34.620]  для вас совсем не были абстрактные, поэтому давайте,
[45:34.620 --> 45:40.380]  значит вот это могу стереть, запомним, что мы это доказали,
[45:40.380 --> 45:46.180]  что из 1 следует 2, собственно что хотел сначала сказать,
[45:46.180 --> 45:49.060]  ну вот у нас есть какие-то серии, что это за серии,
[45:49.060 --> 45:52.380]  как с ними быть, бывает вообще в природе такие серии,
[45:52.380 --> 45:54.540]  ну вот собственно на эти вопросы ответим.
[45:54.540 --> 45:58.260]  Значит смотрите, пусть у нас есть привычная нам
[45:58.260 --> 46:02.500]  последовательность независимых случайных величин, оказывается,
[46:02.500 --> 46:05.860]  что серию можно построить по такому правилу.
[46:05.860 --> 46:16.180]  Это nkt равно xkt-akt делить на bn, где akt это мотожидание
[46:16.180 --> 46:23.780]  ксикатова, а bn в квадрате это сумма дисперсий ксикатова.
[46:23.780 --> 46:34.060]  k равно от 1 до n, то есть это вполне легко, ну и давайте
[46:34.060 --> 46:39.060]  в этих терминах переформулируем условия Линнберга, для этого
[46:39.060 --> 46:47.380]  нам нужно понять, чего такое вот это fnk от x, это вероятность
[46:47.380 --> 46:53.020]  того, что это nkt меньше x, если это nkt мы задаем вот
[46:53.020 --> 46:57.060]  именно по такому правилу, то это вероятность того,
[46:57.060 --> 47:10.020]  что xkt меньше bnх плюс akt, а это не что иное, как функция
[47:10.020 --> 47:15.180]  распределения, напишу ксикатова, тройные индексы не будут
[47:15.180 --> 47:18.780]  таскать, одноиндексная функция распределения
[47:19.780 --> 47:32.180]  Взятая в точке bnх плюс akt, ну и давайте теперь перепишем
[47:32.180 --> 47:41.740]  интеграл, x квадрат остается пока, x по модулю больше
[47:41.740 --> 47:54.340]  tau, а здесь будет dfk взятая в точке bnх плюс ak, ну просто
[47:54.340 --> 48:01.220]  на y заменим, y равно bnх плюс akt и тогда получим, ну я
[48:01.220 --> 48:06.060]  напишу, а вы как говорится следите за руками, значит
[48:06.060 --> 48:19.580]  1 на bn в квадрате интеграл y минус akt в квадрате dfk от
[48:19.580 --> 48:32.620]  y, взятая по области y минус akt по модулю больше tau bn,
[48:32.620 --> 48:38.180]  ну и собственно теория Малинберга-Леви, вот здесь
[48:38.180 --> 48:39.180]  я ее запишу
[48:39.180 --> 48:58.060]  Откуда вот это?
[48:58.060 --> 49:09.180]  Bn я вынес, x равно y минус akt делить на bn, поэтому
[49:09.180 --> 49:20.380]  x квадрате это y минус akt в квадрате делить на bn в квадрате,
[49:20.380 --> 49:25.500]  значит теория Малинберга-Леви напишу здесь ретро, ну на
[49:25.500 --> 49:29.180]  самом деле она нам полезна, мы этим в такой форме условиям
[49:29.180 --> 49:32.100]  Малинберга будем пользоваться, значит изначально она
[49:32.100 --> 49:35.580]  выглядела так, пусть выполнено условие Малинберга вот в
[49:35.580 --> 49:41.700]  такой форме, ну как обычно ксиенные независимые случайные
[49:41.700 --> 49:47.780]  величины, выполнено условие Малинберга, 1 на bn в квадрате
[49:47.780 --> 49:57.420]  сумма интегралов x минус akt в квадрате dfk от x, взятая
[49:57.420 --> 50:06.060]  по области x минус akt больше tau bn, k от единицы до n стремится
[50:06.060 --> 50:11.260]  к нулю, при n стремящейся к бесконечности, то отсюда
[50:11.260 --> 50:20.780]  следует, что сумма x kt минус akt k от единицы на n делить
[50:20.780 --> 50:25.860]  на bn сходится по распределению к стандартному нормальному
[50:25.860 --> 50:33.620]  закону, то есть только достаточно условия для последствий независимых
[50:33.620 --> 50:38.540]  случайных величин, серии там необходимые достаточно,
[50:38.540 --> 50:44.220]  это все потом как бы появилось, ну и вот видно собственно
[50:44.220 --> 50:48.820]  о какой случайной величине идет речь, которая концентрируется
[50:48.820 --> 50:51.620]  вокруг стандартного нормального распределения, это ведь
[50:51.620 --> 50:55.100]  такая отнормированная на нулевое мат ожидания
[50:55.100 --> 50:59.020]  и единичную дисперсию сумма этих случайных величин,
[50:59.020 --> 51:04.380]  вот она нормально распределена, теперь я надеюсь нас не
[51:04.380 --> 51:09.380]  пугают эти серии, мы понимаем как они строятся, понимаем
[51:09.380 --> 51:14.540]  как это записывается в таком удобоваримом виде, ну и
[51:14.540 --> 51:27.460]  можем собственно приступить к доказательству.
[51:27.460 --> 51:31.260]  Сначала нам потребуется тоже там парочку вспомогательных
[51:31.260 --> 51:35.980]  результатов, пока может не очень понятно зачем, но
[51:35.980 --> 51:40.860]  давайте рассмотрим вот такую величину, фи nkt, характеристическая
[51:40.860 --> 51:49.820]  функция это nkt в точке t, минус 1 по модулю, ну пока не очень
[51:49.820 --> 51:53.460]  понятно, но дальше она нам сильно понадобится, и давайте
[51:53.460 --> 51:59.260]  здесь как бы двумя способами мы к этому подойдем, ну во-первых,
[51:59.260 --> 52:03.100]  сейчас я использую такой прием, мы его будем часто использовать,
[52:03.100 --> 52:07.140]  подробно его распишу, значит фi nkt это что такое, это е
[52:07.140 --> 52:12.580]  в степени и tx, минус единица, и вот здесь напишу, минус
[52:12.580 --> 52:24.620]  и tx еще, df nk, понятно почему это равенство, смотрите е
[52:24.620 --> 52:29.340]  в степени и tx, df nk это что такое, это характеристическая
[52:29.340 --> 52:36.220]  функция, ну единицу проинтегрируем по мере, это единица, а вот
[52:36.220 --> 52:44.980]  это что такое, это по определению и t на математическое ожидание
[52:44.980 --> 52:48.900]  это nkt, которое равно нулю, мы такое условие наложили,
[52:49.900 --> 52:58.500]  просто добавили ноль, поэтому меньше или равно интеграл,
[52:58.500 --> 53:05.340]  здесь я возьму модуль и воспользуюсь вот этим неравенством
[53:05.340 --> 53:10.540]  и напишу, что это меньше или равно tx, у нас роль альфа tx
[53:10.540 --> 53:23.140]  играет в квадрате пополам, df nk равно на самом деле t квадрат
[53:23.140 --> 53:33.060]  пополам, а то что остается x квадрат, это квадрат, x квадрат по мере,
[53:33.060 --> 53:38.300]  это же что по определению, учитывая что мат ожидания
[53:38.340 --> 53:47.020]  случайно равно нулю, это nk, x квадрат df nk, что такое, это дисперсия, дисперсия
[53:47.020 --> 53:55.820]  это nk, ну теперь давайте просуммируем обе части по k и получим, вот здесь
[53:55.820 --> 54:08.740]  вот, позвольте, я напишу и получим сумма крат единицы до n, phi nk от t минус 1 по
[54:08.740 --> 54:14.460]  модулю, меньше или равно t квадрат пополам на сумму дисперсии, а сумма дисперсии
[54:14.460 --> 54:19.100]  в нашей серии равна единице, видите, поэтому это просто меньше t квадрат
[54:19.100 --> 54:29.500]  пополам, причем для любого t это выполнено, теперь по-другому подойдем к этой величине
[54:29.500 --> 54:43.380]  phi nk от t минус 1 по модулю, значит это меньше или равно чем интеграл е в степени и t минус 1
[54:43.380 --> 55:01.980]  df nk, nk от x и я этот интеграл разобью на два, один по области x по модулю больше
[55:01.980 --> 55:12.020]  epsilon, а второй x по модулю меньше или равно epsilon, вот который x по модулю меньше или равно epsilon,
[55:12.020 --> 55:22.900]  точнее x по модулю больше epsilon, я е в степени и t минус 1 по модулю заменю на 2, напишу,
[55:22.900 --> 55:35.060]  что это меньше или равно, 2 интеграл df nk от x, взятый по области x по модулю больше epsilon,
[55:35.060 --> 55:46.460]  а который меньше, воспользуюсь, что е в степени и t минус 1 по модулю меньше,
[55:46.460 --> 56:03.700]  ну в нашем случае будет модуль t, модуль x, df nk x, x по модулю меньше равно epsilon, вот,
[56:03.700 --> 56:14.140]  значит вот это что такое, этот интеграл, это вероятность того, что это nk больше epsilon,
[56:14.140 --> 56:22.660]  а здесь x меньше epsilon, поэтому я заменю под интегральную функцию на максимальное значение,
[56:22.660 --> 56:38.860]  вот это все меньше или равно, плюс модуль t умножить на epsilon. Ну и смотрите, значит второе
[56:38.860 --> 56:47.500]  слагаемое можно за счет epsilon сделать малым, а первое можно сделать малым для любого epsilon
[56:47.500 --> 56:55.340]  на основании свойства 2, вот, которое выполнено, поскольку мы считаем, что выполнено свойство 1,
[56:55.340 --> 57:01.820]  и отсюда я получаю вот такой, ну и значит могу теперь еще максимум взять с двух сторон и
[57:01.820 --> 57:13.300]  получить такую штуку, вот, максимум phi nk t от t минус 1 по модулю стремится к нулю,
[57:13.300 --> 57:21.260]  максимум k от 1 до n, как до n стремится к бесконечности, вот такие важные для нас свойства.
[57:21.260 --> 57:31.780]  Так, ну вроде подготовительная работа закончена, можем, что называется, по существу переходить,
[57:31.780 --> 57:52.580]  хотя нет, еще вот здесь напишу одно свойство, логарифм 1 плюс z равно ряд минус 1 в степени s
[57:52.580 --> 58:04.380]  минус 1, z в степени s делить на s, s от единицы до бесконечности, и ряд абсолютно сходится,
[58:04.380 --> 58:19.740]  когда z по модулю меньше единицы. Еще такой факт. Идея доказательства опять же в использовании
[58:19.740 --> 58:23.900]  характеристических функций, ну как не трудно догадаться, раз мы тут с ними возились. Мы
[58:23.900 --> 58:31.700]  сейчас докажем, что характеристическая функция вот такой вот суммы стремится к характеристической
[58:31.700 --> 58:36.980]  функции стандартного нормального распределения. А чему равна характеристическая функция стандартного
[58:36.980 --> 58:48.980]  нормального распределения? Кто помнит? е в степени минус t квадрат пополам. Вот. Ну,
[58:48.980 --> 59:04.460]  сразу напишу логарифм, phi это n от t. Значит, это n есть сумма независимых случайных величин,
[59:04.460 --> 59:09.420]  поэтому характеристическая функция суммы равна произведению характеристических функций,
[59:09.420 --> 59:17.100]  но поскольку еще логарифм взял, это получается сумма логарифмов. Сумма логарифмов phi nkt от t.
[59:17.100 --> 59:37.560]  Это я преобразую таким образом. Логарифм единица плюс phi nkt минус 1. Вот. Становится понятие наш
[59:37.560 --> 59:44.500]  замысел, чем мы возились с этими phi nk минус 1. Так, значит, смотрите, поскольку имеет место вот такое
[59:44.500 --> 59:54.340]  свойство, это значит, что начиная с некоторых номеров n, но вот этот максимум можно считать
[59:54.340 --> 01:00:00.180]  меньшим 1 и 2. Будем так и делать. Поскольку мы будем переходить к пределу, предоставляясь
[01:00:00.180 --> 01:00:05.260]  бесконечности, будем считать, что вот этот максимум меньше 1 и 2. Настолько большие у нас
[01:00:05.260 --> 01:00:22.340]  тогда phi nk минус 1 по модулю меньше 1 и 2. Это внутри сходимости ряда логарифма, и я раскладываю в ряд.
[01:00:35.260 --> 01:00:42.460]  Выделяю первый член с s равно единице
[01:00:42.460 --> 01:00:55.260]  и то, что остается.
[01:01:05.260 --> 01:01:26.780]  Вот эту двойную сумму обозначим rn. Ну и, наверное, вы понимаете, к чему я веду, да? Что rn по модулю
[01:01:26.780 --> 01:01:28.860]  будет стремиться к нулю. Мы сейчас это покажем.
[01:01:28.860 --> 01:01:57.780]  Значит, rn по модулю
[01:01:57.780 --> 01:02:06.380]  меньше или равна. К от единицы до n. Смотрите, берем модуль, тут все положительное становится.
[01:02:06.380 --> 01:02:15.180]  s имеет минимальное значение 2, поэтому если мы во всех членах здесь s заменим на 2,
[01:02:15.180 --> 01:02:24.100]  то ряд только увеличится. Поэтому я напишу 1, 2, а здесь напишу уже без двойки. Вот,
[01:02:24.100 --> 01:02:42.580]  но что я здесь напишу? phi nk от t минус 1 в степени s, s от 2 до бесконечности. Внутренняя сумма,
[01:02:42.580 --> 01:02:48.580]  значит, мы договорились, что phi nk от t минус 1 по модулю меньше 1 и 2. Такие большие n договорились
[01:02:48.580 --> 01:02:55.420]  брать. Поэтому это геометрическая прогрессия, сумма геометрической прогрессии. Ну, я напишу,
[01:02:55.420 --> 01:03:11.140]  ну, напишу равно пока, да, равно k от единицы до n, 1, 2, phi nk от t минус 1 в квадрате первый
[01:03:11.140 --> 01:03:26.100]  член на единицы минус q на единицы минус phi nk от t минус 1. Еще раз напомню, что модуль phi nk от t
[01:03:26.100 --> 01:03:35.700]  минус 1 меньше 1 и 2. Поэтому, если я сюда подставлю 1, 2, увеличу знаменатель, точнее говоря, увеличу
[01:03:35.700 --> 01:03:42.140]  вот эту величину, значит, уменьшу знаменатель, могу поставить знак меньше или равно. Ну и сразу
[01:03:42.140 --> 01:03:49.140]  смотрите, если это заменю на 1, 2, здесь будет 1, 2 с 1, 2 сократиться и получится меньше или равно
[01:03:49.140 --> 01:04:06.740]  phi nk от t минус 1 в квадрате, в квадрате k от единицы до n. Дальше напишу меньше или равно
[01:04:06.740 --> 01:04:16.580]  максимум phi nk от t, t у нас фиксированное, какое-то, но фиксированное, максимум k от единицы до n,
[01:04:16.580 --> 01:04:30.420]  сумма phi nk от t минус 1, k от единицы до n. Ну, теперь смотрим вот сюда. Сумма phi nk минус 1, пока
[01:04:30.420 --> 01:04:39.900]  модуль меньше t квадрат пополам, максимум стремится к нулю. Поэтому вся вот эта штука для любого t стремится
[01:04:39.900 --> 01:04:49.540]  к нулю при n, стремящемся к бесконечности и для любого t это имеет место. Вот как бы важный
[01:04:49.540 --> 01:04:59.100]  промежуточный факт, который нам нужен. Идем дальше. Значит, итак, мы с вами сейчас получили вот что.
[01:04:59.100 --> 01:05:13.380]  Что логарифом phi nk t, то есть это nk t равно вот такой штуке, я перепишу, а потом сотру. То есть это
[01:05:13.380 --> 01:05:22.780]  получается равно сумма phi nk t минус 1 по модулю плюс rn. Но я вот так сразу запишу. Минус t квадрат
[01:05:22.780 --> 01:05:40.180]  пополам плюс t квадрат пополам плюс сумма phi nk от t минус 1, k от единицы до n, плюс rn. rn, помним,
[01:05:40.180 --> 01:05:50.060]  стремится к нулю. А, и еще, значит, хочу обратить ваше внимание, потом на это я сошлюсь, что
[01:05:50.060 --> 01:05:58.060]  представимость логарифма характеристической функции это n в виде вот такой суммы и остатка,
[01:05:58.060 --> 01:06:06.180]  стремящемся к нулю, это следствие свойства 2. Нам свойства 1 не потребовалось. Ну просто,
[01:06:06.180 --> 01:06:12.220]  поскольку мы отсюда доказываем сюда, мы говорим, что свойства 2, но свойства 2 само следует и
[01:06:12.220 --> 01:06:17.580]  свойства 1. Но вот если есть свойства 2, когда мы будем в обратную сторону доказывать, если
[01:06:17.580 --> 01:06:23.020]  свойство 2 выполнено, то для характеристической функции тоже имеет место вот такое представление.
[01:06:23.020 --> 01:06:47.060]  Так, ну, собственно, можно сказать, последний рывок, вот эту штуку мы обозначим ρn. Ну и,
[01:06:47.060 --> 01:06:54.380]  как вы догадываетесь, докажем, что ρn по модулю стремится к нулю. Но тут сейчас немножко повозиться надо будет.
[01:06:54.380 --> 01:07:20.180]  Значит, ρn я сначала распишу неким специальным образом. Вместо t квадрат пополам я напишу такую
[01:07:20.180 --> 01:07:33.940]  штуку. Сумма cat единицы до n интеграл t х в квадрате пополам df nk. Всем понятно,
[01:07:33.940 --> 01:07:40.780]  что это t квадрат пополам? Ну, потому что t квадрат пополам выносим, остаются дисперсии,
[01:07:40.780 --> 01:07:49.260]  сумма дисперсии равна единице. Ну и плюс вот эту сумму, которую я представлю в таком виде,
[01:07:49.260 --> 01:08:08.220]  интеграл е в степени и t х минус 1, ну и минус и t х. Уже говорили, что это просто ноль. Теперь
[01:08:08.220 --> 01:08:22.300]  разобьем это на два слагаемых. Первое это будет k равно от единицы до n. Так,
[01:08:22.300 --> 01:08:38.020]  сейчас только. Значит, интеграл х по модулю меньше или равно е, т х квадрат пополам df nk плюс,
[01:08:38.020 --> 01:08:52.260]  я пожалуй сумму вот общую возьму, плюс интеграл е в степени и t х минус 1, минус и t х по области
[01:08:52.260 --> 01:09:12.140]  той же. Это первое слагаемое и второе слагаемое аналогично только по области х по модулю больше
[01:09:12.140 --> 01:09:18.620]  е. И вот когда я буду х по модулю больше е, здесь я сразу преобразую t квадрат пополам вынесу за
[01:09:18.620 --> 01:09:27.060]  скобки, а здесь останется х квадрат df nk, а вторую часть этого интеграла никак не преобразую,
[01:09:27.060 --> 01:09:35.620]  просто можно не буду переписывать. Вот так же перепишу я, только по области будет х больше е.
[01:09:35.620 --> 01:09:55.580]  Так, значит, вот это первое слагаемое обозначим ρ n штрих, а второе ρ n 2 штриха. И теперь каждое
[01:09:55.580 --> 01:10:07.700]  по отдельности изучим. Ро n штрих по модулю. Вот оно. Смотрите, я это все вношу под один интеграл и
[01:10:07.700 --> 01:10:17.020]  пользуюсь вот этим свойством. Вот сюда, вот этим свойством пользуюсь и получаю, что это меньше или
[01:10:17.020 --> 01:10:31.700]  равно, интеграл х по модулю меньше или равно epsilon, t х по модулю в кубе делить на 6 сумма
[01:10:31.700 --> 01:10:51.700]  df nk от x. Согласны? Все под один интеграл, е и t х минус 1 минус и t х минус t х квадрате,
[01:10:51.700 --> 01:11:00.380]  точнее говоря, плюс t х квадрате пополам, это альфа, которая t х в нашем случае по модулю в третьей
[01:11:00.380 --> 01:11:10.940]  степени делить на 6. Так, меньше или равно? Х максимальное значение вынесу за скобки и t в кубе
[01:11:10.940 --> 01:11:26.300]  вынесу. Получу t по модулю в кубе на epsilon делить на 6 на сумму х квадрат df nk от x, x по модулю меньше
[01:11:26.300 --> 01:11:36.380]  epsilon, меньше равно epsilon. Но если я расширю под интегральная функция положительная, расширю область
[01:11:36.380 --> 01:11:42.580]  интегрирования минус бесконеч-бесконечность, все только увеличится, но тогда получится дисперсия и
[01:11:42.580 --> 01:11:52.220]  вся вот эта штука будет меньше единицы, меньше равно единицы. И мы получили, что ρ n штрих по модулю
[01:11:52.220 --> 01:12:08.300]  ограничено t по модулю в кубе epsilon делить на 6. Первое и второе, ρ n два штриха по модулю. Значит,
[01:12:08.300 --> 01:12:20.140]  смотрите, вот это я перепишу как есть, меньше или равно t квадрат пополам сумма х квадрат df nk,
[01:12:20.140 --> 01:12:32.220]  x по модулю больше epsilon, а вот здесь воспользуюсь вот этим вот неравенством модулем. Ну и получу t
[01:12:32.220 --> 01:12:39.980]  квадрат x квадрат пополам, также t квадрат пополам вынесу за скупки, а под интегралом останется x
[01:12:39.980 --> 01:12:50.980]  квадрат df nk, x по модулю больше epsilon, то есть это на самом деле просто t квадрат на сумму интегралов x
[01:12:50.980 --> 01:13:02.980]  квадрат df nk, x по модулю больше epsilon, крат единицы до n. А вот это вот и есть условие Линдорга. Если эта
[01:13:02.980 --> 01:13:11.860]  штука стремится к нулю, то и ρ n два штриха по модулю стремится к нулю. Итак, ρ n штрих ограничиваем,
[01:13:11.860 --> 01:13:18.880]  делаем сколь угодно малым за счет epsilon, и при этом малым epsilon ρ n два штриха делаем сколь
[01:13:18.880 --> 01:13:30.460]  угодно малым за счет выполнения условия Линдорга. Итак, мы с вами доказали, что логарифум phi
[01:13:30.460 --> 01:13:38.900]  это n представимо в виде минус t квадрат и плюс два остатка, которые стремятся к нулю. То есть
[01:13:38.900 --> 01:13:56.140]  логарифум phi это n стремится, при н стремясь к бесконечности, к минус t квадрат пополам. А
[01:13:56.620 --> 01:14:09.620]  это значит, что phi это n, это n от t стремится к е в степени минус t квадрат пополам характеристической
[01:14:09.620 --> 01:14:17.580]  функции стандартного нормального распределения. И это завершает наше доказательство в одну сторону,
[01:14:17.580 --> 01:14:31.260]  в одну сторону. Значит, во вторую сторону все в принципе не сложно, но давайте все-таки успеем.
[01:14:31.260 --> 01:14:41.220]  Итак, пусть у нас теперь выполнено два-три, то есть условия пренебрежимой малости а симпатической
[01:14:41.220 --> 01:14:50.860]  нормальность. Тогда, как я обращал ваше внимание, мы можем утверждать, что логарифум phi это n от t
[01:14:50.860 --> 01:15:07.900]  представимо в виде сумма phi n-катого от t минус 1 х 1 до n плюс rn, которая стремится к нулю на
[01:15:07.900 --> 01:15:15.100]  основании свойства 2, я это обращал внимание. И все вот это, поскольку а симпатическая нормальность
[01:15:15.100 --> 01:15:25.220]  имеет теперь место по условию, обязано сходиться к минус t квадрат пополам. Вот что такое выполнено
[01:15:25.220 --> 01:15:43.180]  2 и 3. Ну и давайте, значит, перепишем это в виде сумма phi n-kат минус 1 плюс t квадрат пополам,
[01:15:43.180 --> 01:15:55.780]  стремится к нулю, прен стремясь к бесконечности. Представим это в виде интеграла e в степени
[01:15:55.780 --> 01:16:13.940]  и t х минус 1 плюс t квадрат х квадрат пополам df n-k от x кара в нот единицы до n стремится к нулю,
[01:16:13.940 --> 01:16:22.060]  при n стремясь к бесконечности. Ну можно это вот дельта n так невязочку это назвать. Значит, смотрите,
[01:16:22.140 --> 01:16:29.540]  ну понятно, да, что это и это одно и то же, потому что здесь опять дисперсии, сумма дисперсии опять
[01:16:29.540 --> 01:16:35.260]  единица. Теперь смотрите, вот это же комплекс назначенная функция, она стремится к нулю,
[01:16:35.260 --> 01:16:40.060]  отсюда следует, по крайней мере, что ее действительная часть тоже стремится к нулю.
[01:16:40.060 --> 01:16:49.820]  Более того, это верно для любого t, в том числе и для t равного единицы, поэтому я все это учту
[01:16:49.820 --> 01:17:08.540]  и напишу следующее утверждение, что сумма интегралов cos х минус 1 плюс х квадрат пополам df n-k
[01:17:08.540 --> 01:17:22.660]  от единицы до n стремится к нулю, при n стремясь к бесконечности. Понятно, что я сделал, да? Выделил
[01:17:22.660 --> 01:17:30.740]  действительную часть это cos х и положил t равно единицы, получил такую штуку. Значит,
[01:17:30.740 --> 01:17:37.580]  обращаю ваше внимание, что под интегральное выражение больше или равно нуля достаточно взять
[01:17:37.580 --> 01:17:43.660]  ее производную, убедиться, что минимум в нуле, но под интегральное выражение больше равно нулю,
[01:17:43.660 --> 01:17:58.060]  поэтому для любого t больше нуля эта штука больше, чем интеграл х по модулю больше t cos х минус 1 плюс
[01:17:58.060 --> 01:18:16.100]  х квадрат пополам df n-k. Так, и вот здесь есть такая штука, такое замечание. Вот смотрите,
[01:18:16.100 --> 01:18:21.300]  вот эта функция cos х минус 1 плюс х квадрат пополам, я для нее делаю следующее утверждение,
[01:18:21.300 --> 01:18:32.340]  что для любого t больше нуля существует некая функция k tau такая, что cos х минус 1 плюс
[01:18:32.340 --> 01:18:42.140]  х квадрат пополам больше или равно k tau на х квадрат, как только х по модулю больше t.
[01:18:42.140 --> 01:18:52.260]  Значит, это представляется вполне разумным, почему? cos х разлагаем в ряд, 1 сокращается,
[01:18:52.260 --> 01:18:59.420]  х квадрат сокращается, остается х в четвертой степени, там ну на 24, да, х в четвертой больше
[01:18:59.420 --> 01:19:07.340]  k tau на х квадрат. Ну понятно, что это как-то так. х квадрат и х в четвертой встречаются в единице,
[01:19:07.340 --> 01:19:15.340]  вот это вот, не знаю, х квадрат или х в четвертой, вот это вот х в четвертой. Ну если мы какой-то
[01:19:15.340 --> 01:19:23.820]  tau взяли, то мы за счет множителя можем сделать так, что вот в этой области х больше tau, х в четвертой
[01:19:23.820 --> 01:19:31.740]  будет больше, чем х квадрат. Но вот это утверждение вроде бы достаточно очевидное и несложное,
[01:19:31.740 --> 01:19:37.820]  но если с ним возиться, это минут 15, поэтому я его оставлю без доказательства, так сказать,
[01:19:37.820 --> 01:19:44.220]  там, ну на любителя, что называется, так сказать. Ну так-то оно вполне оказывается разумным. И тогда
[01:19:44.220 --> 01:19:56.740]  я пишу, больше или равно, больше или равно k от tau на сумму k от единицы до n х больше tau х квадрат
[01:19:56.740 --> 01:20:06.620]  d f n k от х. А это и есть условия Линнберга. Эта штука стремится к нулю, значит выполнено условия
[01:20:06.620 --> 01:20:13.740]  Линнберга. Что завершает наше доказательство? Был звонок, да, по-моему. Так, все коллеги,
[01:20:13.740 --> 01:20:19.460]  значит, в принципе успели, там, ну по крайней мере, посередине не разорвали доказательства,
[01:20:19.460 --> 01:20:25.660]  тогда в следующий раз продолжим с вами. Спасибо, коллеги.
