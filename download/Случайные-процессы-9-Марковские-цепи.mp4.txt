[00:00.000 --> 00:16.880]  Сегодня мы хотим закончить обсуждение марковских процессов. Давайте я напомню, чем кончили.
[00:16.880 --> 00:29.880]  Было уравнение Чепмана Колмогорова.
[00:29.880 --> 00:42.880]  Вот этого Чепмана пишут по-разному, потому что он, можете догадаться, вот такой.
[00:42.880 --> 01:01.880]  И поэтому в нашей литературе встречают при написании его 2е и 1е, 2е, но, по идее, можно было бы и второе, и 2е.
[01:01.880 --> 01:07.880]  Но, кажется, такого я не встречал, но это вполне, так сказать, тоже было бы правильно.
[01:07.880 --> 01:19.880]  Значит, уравнение вот какое.
[01:19.880 --> 01:35.880]  Я еще раз его выпишу, просто чтобы прокомментировать, что оно означает.
[01:35.880 --> 01:59.880]  Значит, смотрите, смысл левой части, переходной вероятности, это вероятность попасть в множество е в момент времени t, если в какой-то предшествующий момент процесс находился в точке x.
[01:59.880 --> 02:09.880]  И вот эта формула, которая называется уравнением Колмогорова-Чепмана или равенством Колмогорова-Чепмана, смотрите, что оно говорит.
[02:09.880 --> 02:19.880]  Что вот эта вероятность перейти из x в е считается так.
[02:19.880 --> 02:29.880]  Значит, тут s, t и x фиксированы.
[02:29.880 --> 02:34.880]  Значит, s, t и x в левой части, вот эти вот 3 фиксированы.
[02:34.880 --> 02:50.880]  Теперь мы берем промежуточную точку u и вот эти вот вероятности.
[02:50.880 --> 03:08.880]  Это перейти, сейчас только я.
[03:08.880 --> 03:37.880]  Смотрите, считается, что мы как бы перебираем всевозможные точки y и переходим сначала из x.
[03:37.880 --> 03:52.880]  В момент времени промежуточной оказываемся там, условно говоря, в dy, а потом переходим в е.
[03:52.880 --> 04:13.880]  Смысл такой, переходим не сразу из момента времени s в момент времени t, а еще вводим промежуточный момент.
[04:13.880 --> 04:33.880]  Сначала смотрим, находясь в момент времени s, где оказались в u, а потом из момента времени u перешли в момент времени t.
[04:33.880 --> 04:42.880]  Конечно, в такой, в интегральной форме это нельзя сказать, что как-то очень интуитивно понятно.
[04:42.880 --> 04:53.880]  Но это становится гораздо более понятным в дискретном случае, к которому мы сейчас и перейдем, в случае марковских цепей.
[04:53.880 --> 05:03.880]  Это очень важный частный случай марковских процессов, который мы сегодня как раз очень кратко обсудим и на этом про марковость закончим.
[05:03.880 --> 05:16.880]  Теперь еще, как связаны конечномерные распределения с переходными вероятностями.
[05:16.880 --> 05:30.880]  Связь конечномерных распределений с переходными вероятностями.
[05:30.880 --> 05:50.880]  Связь такая, обычная для процессов вероятность попадания в множество c вычисляется в такой довольно длинной, но тем не менее конечной формуле.
[05:50.880 --> 06:13.880]  Значит, вот какой, форма такая немножко громоздкая, но интегрирование производится, вот это по dx1, оно последним будет интегрирование.
[06:13.880 --> 06:18.880]  Сейчас тут будет, у нас было фазовое пространство x, кажется.
[06:43.880 --> 06:55.880]  Значит, смотрите, что делается в этой формуле.
[06:55.880 --> 07:05.880]  Значит, вот есть множество в Rn, ну или там не в Rn, а в x в степени n, если фазовое пространство не прямое.
[07:05.880 --> 07:20.880]  Значит, вот мы берем, фиксируем все кроме xn вот здесь и интегрируем по xn вот по этой переходной вероятности.
[07:20.880 --> 07:45.880]  После этого от xn зависимости нет, ну и дальше начинаем, то, что получилось зависит от x1, xn-1, и вот это интегрируем по dxn-1, ну по соответствующей переходной вероятности.
[07:45.880 --> 08:06.880]  Ну и так наконец добираемся до x2, вот по этой интегрируем, и остается не связанной только одна переменная x1, ну и вот здесь мы интегрируем по распределению процесса в момент времени t1.
[08:06.880 --> 08:19.880]  Так что получается так, что если знать начальное распределение и переходные вероятности, то можно вычислить, конечно, мерные распределения.
[08:19.880 --> 08:35.880]  Естественно, на этот счет тоже есть теорема о существовании процесса, но я не буду ее приводить, она довольно и по формулировке громоздкая, и по доказательству довольно громоздкая.
[08:35.880 --> 08:44.880]  Но важный момент вот какой. В исходном определении марковского процесса никаких переходных вероятностей не было.
[08:44.880 --> 09:02.880]  А эта теорема, которая в прошлый раз была без доказательств, что они есть, это в случае, когда фазовое пространство, ну какое-то разумное, ну скажем Rn или его Борелевское подножество, ну или там изоморфное такому пространству.
[09:02.880 --> 09:13.880]  Но вообще говоря, неверно, что есть для произвольного марковского процесса, что есть переходные вероятности, это неверно.
[09:13.880 --> 09:27.880]  Но иногда само определение марковского процесса формулируется в таком несколько более узком виде вот как раз через эти переходные вероятности.
[09:27.880 --> 09:33.880]  Так что такое вот в литературе и в учебниках такое можно встретить. Ну такое немножко более узкое определение.
[09:33.880 --> 09:45.880]  Но для большинства того, что в реальных приложениях встречаются, это оказываются равносильные вещи, хотя вот существование переходных вероятностей,
[09:45.880 --> 09:56.880]  которые в теореме последней прошлого раза было объявлено, надо понимать, что это вещь как раз весьма нетривиальная.
[09:56.880 --> 10:05.880]  Вот это гораздо более трудное доказательство этого факта, чем вообще все что угодно из того, что у нас было с доказательством.
[10:05.880 --> 10:19.880]  Поэтому для себя можно, так сказать, не совсем правильно считать, что марковские процессы, но это те, для которых есть начальное распределение и переходные вероятности.
[10:19.880 --> 10:24.880]  Ну и это будет оправдано в случае разумного фазового пространства.
[10:24.880 --> 10:38.880]  Теперь важный частный случай цепи Маркова.
[10:38.880 --> 10:52.880]  Так, что-то я еще хотел сказать.
[10:52.880 --> 11:02.880]  Вот однородный процесс.
[11:02.880 --> 11:17.880]  Это когда переходные вероятности, значит, вот эти вот, значит, P, S, X, T, E,
[11:17.880 --> 11:31.880]  зависит только от разности, значит, T-S, а не от пары точек.
[11:31.880 --> 11:47.880]  В этом случае получается, ну, вот можно считать, что функция трех переменных.
[11:47.880 --> 11:59.880]  Ну и это, значит, вероятность попасть в E в момент T,
[11:59.880 --> 12:18.880]  а выйдя из X в момент ноль.
[12:18.880 --> 12:24.880]  Вот дальше мы будем говорить про цепи Маркова, именно про однородные.
[12:24.880 --> 12:34.880]  Это сильно упрощает дело, хотя, ну, в приложениях, конечно, бывают и не только однородные цепи, и не только однородные процессы.
[12:34.880 --> 12:45.880]  Есть также некоторая конструкция перехода от неоднородных процессов к однородным, но это мы не будем обсуждать.
[12:45.880 --> 12:56.880]  Будем просто считать, что дальше речь пойдет о однородных процессах.
[12:56.880 --> 13:09.880]  Значит, цепи Маркова были введены сто с небольшим лет назад в начале 20 века нашим выдающимся вероятностником Андреем Андреевичем Марковым,
[13:09.880 --> 13:25.880]  который для довольно специфической задачи вел эти цепи, а именно он исследовал чередование гласных и согласных в словах русского языка,
[13:25.880 --> 13:31.880]  ну, на предмет того, насколько это, так сказать, случайно и какие там есть закономерности.
[13:31.880 --> 13:49.880]  Так что у него процесс был с таким вот, ну, можно сказать, пространством из двух точек, ну, можно сказать, там, из 0.1, если там эти гласные и согласные так, значит, занумеровать.
[13:49.880 --> 13:58.880]  Значит, давайте я приведу, так вот, чтобы не расходиться в обозначениях.
[13:58.880 --> 14:08.880]  Значит, смотрите, я иногда все-таки расскажусь в обозначениях с тем, что в конспекте, но, значит, в конспекте я еще раз посмотрю и сделаю единообразным.
[14:08.880 --> 14:18.880]  Ну, в частности, у меня там фазовое пространство, там где-то S, где-то X, но, в общем, понятно, что фазовое пространство, конечно, может быть разными буквами обозначено, так?
[14:18.880 --> 14:23.880]  Но я, значит, в конспекте все-таки просмотрю, чтобы какое единообразие было.
[14:23.880 --> 14:30.880]  Значит, теперь вот, значит, смотрите, что такое цепь Маркова.
[14:30.880 --> 14:42.880]  Значит, это, значит, у нас будет, ну, давайте я сразу напишу, однородный, значит, однородная цепь Маркова, но дальше не буду каждый раз это подчеркивать.
[14:42.880 --> 15:09.880]  Значит, это однородный Марковский процесс с конечным, ну, вот дальше у нас как раз в основном случае это конечного и будет, значит, или с счетным.
[15:09.880 --> 15:26.880]  Значит, или с счетным фазовым пространством.
[15:26.880 --> 15:34.880]  Ну, вот в случае Маркова, значит, фазовое пространство, в исходном случае Маркова фазовое пространство было из двух точек.
[15:34.880 --> 15:41.880]  Значит, теперь, значит, чем, значит, чем этот процесс задается?
[15:41.880 --> 15:52.880]  Значит, можно ввести вот такие вот, вот это важное очень, значит, понятие.
[15:52.880 --> 16:13.880]  Значит, вероятность перехода из х итого в х сжитое за один шаг.
[16:13.880 --> 16:22.880]  Значит, да, еще я забыл сказать, я еще забыл сказать, процесс со счетным, значит, ну, конечным или с чем.
[16:22.880 --> 16:40.880]  И, значит, временем, вот это тоже очень важно, я про это забыл сказать, значит, временем натуральные числа и ноль, то есть временное множество, 0, 1, 2 и так далее.
[16:40.880 --> 16:50.880]  Некоторые считают, что ноль это натуральное число, но вот я помню, Арнольд горячо это оспаривал и учил нас, что ноль это не натуральное число.
[16:50.880 --> 16:58.880]  Так что, ну, вот тут, значит, на ваш вкус, если ноль натуральная, то его добавлять не надо, а если нет, то надо.
[16:58.880 --> 17:04.880]  Значит, смотрите, ну, кто такие поижитые?
[17:04.880 --> 17:23.880]  Значит, поижитые это не отрицательные числа и, значит, сумма, значит, сумма, ну, при всех и.
[17:23.880 --> 17:44.880]  Ну, давайте, давайте тут пока будем считать, что счетное число состояния, но понятно, если число состояния конечное, то, ну, соответственно, и, там, значит, ну, эти и ижи, они, значит, будут, ну, до какого-то там фиксированного числа.
[17:44.880 --> 18:03.880]  Значит, смотрите, в чем смысл, значит, в чем смысл вот этой единицы, значит, почему, ну, ну, значит, почему, значит, почему единицы, почему, естественно, ожидать, что эта единица должна быть в итоге.
[18:03.880 --> 18:29.880]  Значит, смотрите, что мы суммируем, значит, мы суммируем, значит, вероятности перехода, значит, из и в ж, ну, при фиксированном и, так, при фиксированном и, значит, почему, значит, почему, естественно, ожидать, что это единица.
[18:29.880 --> 18:56.880]  Ну, да, ну, потому что, значит, ну, куда-то она обязана перейти, но, но, но, но, когда говорят перейти, это не исключает, что она никуда не перешла, то есть, вероятность остаться в и, она тоже есть, конечно, так что, значит, обратите внимание, ну, перейти это в расширительном толковании, так.
[18:59.880 --> 19:11.880]  Так что вот, например, когда вы говорите, что я там из общежития куда-то пошел, то, а на самом деле никуда не пошел, то это, в общем, так сказать, соответствует, значит, вот этим обозначениям.
[19:11.880 --> 19:37.880]  Теперь, теперь, значит, пусть дано, значит, дано начальное, начальное распределение P0, так.
[19:37.880 --> 19:52.880]  Ну, что это значит? Это значит P0 от XG, значит, это не отрицательные какие-то числа, но и тоже сумма по G их равна единице.
[19:52.880 --> 20:03.880]  Ну, то есть, это мера вот на этом, значит, фазовом пространстве, но если оно счетное, то, значит, мера на счетном множестве, если конечная, то на конечном.
[20:03.880 --> 20:11.880]  А, значит, вот разумные задачи возникают уже, когда это множество состояний из двух точек.
[20:11.880 --> 20:35.880]  Ну, значит, смотрите, здесь пока что процесса-то нет, но в общем определении Марковского процесса.
[20:35.880 --> 20:40.880]  А, значит, это был процесс, принимающий значения в пространстве X, так.
[20:40.880 --> 20:44.880]  Значит, X было пространством с сигма-алгеброй, так.
[20:44.880 --> 20:49.880]  И что такое процесс? Это просто набор случайных элементов со значениями в этом X, так.
[20:49.880 --> 21:02.880]  Значит, когда у нас фазовое пространство конечное или счетное, то мы считаем, ну, по умолчанию, что там самая банальная сигма-алгебра.
[21:02.880 --> 21:10.880]  Ну, значит, помним, что как только появляется фазовое пространство, там незримо, значит, еще предстоит какая-то сигма-алгебра.
[21:10.880 --> 21:14.880]  Ну, в общем случае это, ну, какая-то абстрактная сигма-алгебра.
[21:14.880 --> 21:21.880]  В практических задачах это пространство фазовое, ну, какое-то Борелевское множество и сигма-алгебра Борелевское.
[21:21.880 --> 21:28.880]  Но когда все конечное или счетное, то все предельно упрощается, и сигма-алгебра это просто все подмножество, так.
[21:28.880 --> 21:38.880]  В конечном случае получается конечная сигма-алгебра, но в счетном случае уже получается, ну, уже бесконечная, но довольно простая.
[21:38.880 --> 21:52.880]  Так, теперь, значит, смотрите, значит, вероятность, вероятность нахождения,
[21:52.880 --> 22:11.880]  нахождение процесса в XG, значит, при T равном единице, считается так,
[22:11.880 --> 22:27.880]  значит, давайте, значит, напишем, значит, что это будет? Это будет сумма по I, P, значит, IG умножить на P0 от XI.
[22:27.880 --> 22:36.880]  Ну, действительно, как, значит, процесс может оказаться в XG?
[22:36.880 --> 22:50.880]  Ну, он мог быть, ну, в момент времени T1, значит, в момент времени T1, он мог в момент времени 0 быть в XI, и это вот с такой вероятностью было,
[22:50.880 --> 23:01.880]  а из XI в XG он мог перейти с вероятностью вот такой, ну, поэтому получается вот такая вот формула.
[23:01.880 --> 23:26.880]  Значит, теперь, значит, если, значит, смотрите, что получается, значит, если P0 мы отождествляем вот с такой вот строкой P01, P02,
[23:26.880 --> 23:42.880]  ну, и так далее, значит, распределение P1 в момент времени 1
[23:42.880 --> 24:11.880]  со строкой, значит, вот такой вот, значит, P0, то есть P1, значит, 1, P1, 2, и так далее, то получается вот такая формула.
[24:11.880 --> 24:32.880]  P1, значит, P1, ну, значит, вот эта вот, значит, строка получается применением, значит, к строке P0 матрицы.
[24:32.880 --> 24:43.880]  Значит, а матрица, ну, вот в случае счетного такая бесконечная матрица, а в конечном случае, ну, естественно, конечная.
[24:43.880 --> 24:55.880]  Значит, вот такая вот матрица из этих переходных вероятностей, так, но матрица, ну, такая, видите, формула немножко необычная, матрица справа умножается.
[24:55.880 --> 25:05.880]  Ну, как-то мы так в основном привыкли, что когда матрица применяется к вектору, то вроде как матрица умножается слева.
[25:05.880 --> 25:13.880]  Но здесь можно так сделать, так переделать, но тогда будет вот какое небольшое эстетическое неудобство.
[25:13.880 --> 25:25.880]  Тогда, естественно, нужно писать, здесь будет не строки, а столбцы, так, значит, вместо вот этих строк нужно будет столбцы писать.
[25:25.880 --> 25:34.880]  Ну, что понятно, на письме крайне неудобно, там на доске еще можно, значит, на бумаге это крайне неудобно в печатном тексте писать столбцы, так.
[25:34.880 --> 25:42.880]  Но это-то еще ладно, можно было с этим смириться и объявить, что вот на эти столбцы надо, так сказать, под другим углом зрения смотреть, так.
[25:42.880 --> 25:56.880]  Но это ладно, но хуже то, хуже то, если так сделать, то, ну, матрицу, ну, на матрицу надо умножать слева будет, но, к сожалению, не на эту матрицу, а на транспонированную.
[25:56.880 --> 26:05.880]  И это вот некоторые неудобства, но я считаю, что это, так сказать, это неудобство перевешивает вот непривычность, значит, вот такой вот записи.
[26:05.880 --> 26:24.880]  Вот теперь, значит, для распределения, значит, вот это вот опять такая строка, значит, распределение, распределение процесса, значит, при t равном n, так.
[26:24.880 --> 26:39.880]  Значит, и тогда получается, что Pn, это есть Pn-1 умножить на P, вот опять справа, и это будет P0 умножить на P.
[26:39.880 --> 26:52.880]  Значит, таким образом, так сказать, состояние в момент времени n вот так, значит, описывается через матрицу.
[26:52.880 --> 27:00.880]  Что, что? А, степень n я не дописал, да, значит, степень n, конечно.
[27:00.880 --> 27:25.880]  Значит, смотрите, получается так, что если дана, значит, мера, вот это начальное распределение строка P0, и дана, значит, матрица перехода, то, значит, вот получается такое равенство для распределения процесса в момент времени n.
[27:25.880 --> 27:44.880]  Ну, значит, формула, конечно, так сказать, очень короткая и простая, но надо понимать, что даже для небольшой цепи, не говоря уж про счетные цепи, но даже для, скажем, даже для цепи из двух элементов, конечно,
[27:44.880 --> 27:53.880]  Практическое вычисление вот этой большой степени может оказаться довольно непростым, так сказать.
[27:53.880 --> 28:00.880]  Сама формула короткая, но, так сказать, степень явности этой формулы, конечно, не следует переоценивать.
[28:00.880 --> 28:07.880]  Ну и, значит, какие вопросы-то возникают в связи с цепями?
[28:07.880 --> 28:15.880]  Ну, естественно, всякие практические вопросы, но, значит, первый теоретический вопрос вот какой.
[28:15.880 --> 28:32.880]  Если у вас дано начальное распределение P0 и вот эта матрица P, раз дана матрица P, то даны, конечно, тем самым ее степени, но возникает...
[28:32.880 --> 28:39.880]  Ну, значит, вы что-то можете посчитать, вот это Pn, но спрашивается, а что именно-то вы считаете?
[28:39.880 --> 28:46.880]  Почему вы уверены, что это какие-то вероятности, связанные с процессом? Процесса-то вроде нет, так?
[28:46.880 --> 28:55.880]  Это мы все насчитали, что так должно быть, что если есть процесс. Ну а почему есть процесс?
[28:55.880 --> 29:08.880]  Ну, это, естественно, надо доказывать. И давайте я соответствующую теорему приведу, но мы все доказательства не будем расписывать на доске,
[29:08.880 --> 29:16.880]  потому что там всякие выкладки по индукции проверяются. Я сейчас только объясню, в чем суть дела.
[29:16.880 --> 29:24.880]  Значит, эти выкладки у меня тут, ну, примерно страница выкладок в конспекте, они там аккуратно выписаны, не хочется их на доску переписывать.
[29:24.880 --> 29:29.880]  Давайте саму теорему я выпишу. Значит, теорема вот какая.
[29:29.880 --> 29:39.880]  Значит, если даны начальная мера, ну, просто мера, мера P0,
[29:39.880 --> 29:58.880]  х, которое с конечным числом состояний, и вероятности, ну, и вот эти вот матрицы переходов,
[29:58.880 --> 30:14.880]  значит, матрица P, ну, вот с тем условием, с тем условием, что это соответствует вероятностям перехода.
[30:14.880 --> 30:20.880]  То есть, никакая угодная матрица, значит, не отрицательная и сумма пожи единица должна быть.
[30:20.880 --> 30:30.880]  Обратите внимание, матрица не обязательно симметричная. Вот это я сразу забыл сказать, но это, конечно, и не имелось в виду,
[30:30.880 --> 30:40.880]  но вероятность попасть из 1-2 может быть совсем не такая, как из 2 в 1. Так что ничего такого тут не предполагается.
[30:40.880 --> 30:50.880]  Так что, значит, матрица несимметричная. Ну, вот сейчас, когда я говорил про транспонирование, это вот как раз из несимметричности транспонированная,
[30:50.880 --> 31:06.880]  может быть, уже не она сама. Значит, то существует цепь Маркова. Ну, я уже не оговариваюсь, что она однородная, мы только такие рассматриваем.
[31:06.880 --> 31:26.880]  Значит, цепь Маркова с начальным, ну, с пространством состояния вот этим вот, конечным, значит, с начальным распределением.
[31:36.880 --> 31:56.880]  Значит, начальным распределением P0 и, значит, вот этими P и житыми, которые должны быть, значит, условными вероятностями, значит,
[31:56.880 --> 32:20.880]  перехода, ну, при всех N. Ну, поскольку цепь у нас однородная, то это все равно, что, значит, вероятности перехода за один шаг,
[32:20.880 --> 32:44.880]  но, значит, вот можно их и так написать. Значит, смотрите, что здесь не очевидно? Ну, здесь не очевидно, что вот по этим данным можно такое, причем это обратить внимание,
[32:44.880 --> 32:58.880]  это не очевидно уже, начиная с M равное 2. Вот если даже совсем минимальное пространство состояний из двух точек, ну, из одной, совсем минимальное, но тривиальное неинтересное,
[32:58.880 --> 33:10.880]  а вот интересные вещи начинаются уже, значит, со случая двух состояний. Уже в этом случае получается не очевидно, что такой процесс есть.
[33:10.880 --> 33:20.880]  Так, тут казалось бы, ну, все предельно просто. Вот эти точки, ну, их можно считать, что это просто 1M. Ну, давайте доказательства.
[33:20.880 --> 33:38.880]  Значит, ну, это будет, я говорю, не полное доказательство, некоторые детали на конспект я перенесу. Значит, можно считать, что, значит, и X это просто 1M.
[33:38.880 --> 33:58.880]  Вот M точек. Так, значит, нужно, нам нужно предъявить, ну, то есть это в R все происходит тем самым.
[33:58.880 --> 34:26.880]  Значит, нужно предъявить конечномерные распределения, значит, ну, на пространствах Rn.
[34:26.880 --> 34:43.880]  Так, но фактически, поскольку мы хотим, чтобы он принимал значение вот в этом конечном множестве, нам даже не нужны все множества.
[34:43.880 --> 34:57.880]  Так, а на вот таких вот множествах, значит, ну, на степенях вот этого даже, не всего R, а на степенях вот этого конечного множества.
[34:57.880 --> 35:18.880]  Так, значит, мера P1, значит, n на подмножествах, подмножествах вот этого конечного множества.
[35:18.880 --> 35:34.880]  Ну, вот когда обычно какие-то меры на конечных множествах, то вроде, значит, первое впечатление это, что, ну, там все, так сказать, всегда верно, потому что все конечное и так далее.
[35:34.880 --> 35:46.880]  Ну, тут, значит, есть вот какой нюанс. У нас не одно такое пространство, вот эта степень, не одна, а их много, при всех n.
[35:46.880 --> 35:56.880]  Так, и вот нам нужно задать, значит, меры, чтобы они были согласованы, ну, в смысле Колмогорова, чтобы применить его теорему.
[35:56.880 --> 36:08.880]  Я сейчас расскажу такое стандартное доказательство, как это делается с помощью теоремы Колмогорова, а потом сделаю замечание, как в этом конкретном случае можно сделать,
[36:08.880 --> 36:17.880]  ну, так сказать, явно без теоремы Колмогорова, а проверку деталей в качестве задачи оставим.
[36:17.880 --> 36:27.880]  Значит, вот эта мера сдается вот такой вот формулой, на точках сначала, на отдельных точках.
[36:32.880 --> 36:37.880]  Значит, эта мера сдается на отдельных точках, вот такой вот формулой.
[36:47.880 --> 36:52.880]  Так, вот эта двойка.
[36:59.880 --> 37:05.880]  Значит, смотрите, на отдельных точках просто явные формулы сдаем меру.
[37:05.880 --> 37:08.880]  Значит, дальше по аддитивности.
[37:15.880 --> 37:17.880]  Значит, дальше по аддитивности.
[37:22.880 --> 37:24.880]  Значит, распространили, так.
[37:24.880 --> 37:43.880]  Значит, распространили, и теперь, значит, меры, меры, значит, при, значит, других комбинациях.
[37:43.880 --> 37:51.880]  Вот здесь, смотрите, здесь мера, значит, подряд точки, но нам нужны еще меры, значит, вот на всяких таких комбинациях.
[37:51.880 --> 38:05.880]  Так, значит, это проекции этой меры на соответствующие, значит, RL.
[38:07.880 --> 38:15.880]  Значит, была мера со всеми индексами, часть, значит, индексов убрали, и что это должно быть?
[38:15.880 --> 38:20.880]  Ну, как хотелось бы, чтобы Колмогоров работал, так и делаем просто.
[38:20.880 --> 38:23.880]  Это должна быть проекция этой меры на это.
[38:23.880 --> 38:36.880]  Так что, видите, получается сразу, по таким способам, сразу согласованная система.
[38:36.880 --> 38:59.880]  Поэтому, значит, получаем сразу согласованные меры, значит, то есть, значит, есть процесс, так, ну, по Колмогорову, так.
[38:59.880 --> 39:08.880]  То есть, тут не надо уже ничего не проверять, мы сразу так делаем, чтобы тут так все было.
[39:08.880 --> 39:28.880]  Значит, но, что нужно, значит, но нужно проверить, нужно проверить, что процесс Марковский
[39:28.880 --> 39:42.880]  И еще то, что, ну, вот нужное равенство получилось с этими условиями.
[39:42.880 --> 40:01.880]  Мы шкотели, мы шкотели еще вот такую вот формулу.
[40:01.880 --> 40:29.880]  Смотрите, мы процесс-то задали, и у этого процесса заданы конечномерные распределения.
[40:29.880 --> 40:34.880]  Но для Марковости нас волнуют условные меры, так.
[40:34.880 --> 40:43.880]  И кроме того, нас волнует, чтобы был процесс обещанный с переходными вот этими вероятностями, то есть, тут тоже условные меры.
[40:43.880 --> 40:45.880]  Вот это все нужно проверять.
[40:45.880 --> 40:51.880]  Ну, это некая страница выкладок, которая у меня аккуратно приведена в конспекте, так.
[40:51.880 --> 40:53.880]  Давайте я здесь не буду его спроизводить.
[40:53.880 --> 41:00.880]  Ну, вот заодно проверьте, значит, сколько аккуратно она в конспекте, значит, имеется.
[41:00.880 --> 41:16.880]  Вот теперь, значит, теперь как можно, то есть, тем самым, вот это как бы получается остаток доказательства в конспекте.
[41:16.880 --> 41:27.880]  Но как можно без Колмогорова, значит, замечание, без Колмогорова, значит, как можно такую цепь построить.
[41:28.880 --> 41:37.880]  Ну, как вы понимаете, до появления теоремы Колмогорова народ особенно и не озадачивался,
[41:37.880 --> 41:42.880]  почему существует тот или иной процесс.
[41:42.880 --> 41:44.880]  Ну, это примерно как физики.
[41:44.880 --> 41:50.880]  Вот им кажется чудно, что там математики что-то мучаются, есть ли уравнение на въезд Окса, решение или нет.
[41:51.880 --> 41:57.880]  Они как-то считают, ну вы что, ребята, вот так сказать, а если у них нет решений, то вообще о чем разговор.
[41:57.880 --> 41:59.880]  Ну, также и вот про процессы.
[41:59.880 --> 42:06.880]  Ну, как-то считалось, ну как, ну, естественно, раз обсуждается процесс, то он есть, а если нет, то и обсуждать нечего.
[42:06.880 --> 42:13.880]  Это только Колмогоров, так сказать, поднял вопрос, а вообще почему, так сказать, вообще, почему вы думаете, что процессы какие-то есть.
[42:13.880 --> 42:16.880]  Ну, к счастью, оказывается, что они в основном есть.
[42:16.880 --> 42:19.880]  Вот, значит, без Колмогорова можно сделать так.
[42:19.880 --> 42:25.880]  Значит, берем, значит, значит, ксеноль.
[42:25.880 --> 42:31.880]  Это случайная величина с распределением пеноль.
[42:31.880 --> 42:41.880]  Ну, это естественно, раз мы хотим, чтобы процесс имел начальное распределение пеноль, ну, конечно, ксеноль и надо брать с таким распределением.
[42:41.880 --> 42:45.880]  Вот, а дальше берем так.
[42:45.880 --> 42:58.880]  Значит, берем, значит, берем, значит, последовательность.
[42:58.880 --> 43:10.880]  Это Н, это независимые равномерно распределенные в 0,1.
[43:10.880 --> 43:12.880]  Так.
[43:12.880 --> 43:14.880]  Ну, почему такие есть?
[43:14.880 --> 43:17.880]  Опять же, до Колмогорова никто в этом не сомневался.
[43:17.880 --> 43:21.880]  Значит, ну, значит, пришел Колмогоров, внес сомнения, ну, и тут же его и разрешил.
[43:21.880 --> 43:26.880]  Ну, есть такие, значит, с помощью теоремы Колмогорова такие есть.
[43:26.880 --> 43:29.880]  И дальше делаем так.
[43:29.880 --> 43:31.880]  Дальше делаем так.
[43:31.880 --> 43:45.880]  Значит, кси1 задаем с помощью вот этой, это 1.
[43:45.880 --> 43:49.880]  Значит, так.
[43:49.880 --> 43:59.880]  Делим 0,1 на m промежутков.
[43:59.880 --> 44:01.880]  Так.
[44:01.880 --> 44:11.880]  С длинными, с длинными дельта 1, дельта m.
[44:11.880 --> 44:17.880]  И где дельта kt выбирается вот так.
[44:17.880 --> 44:30.880]  Это p0 от единицы умножить на p1 от k, плюс и так далее, p0 от m на p, m от k.
[44:30.880 --> 44:31.880]  Так.
[44:31.880 --> 44:33.880]  Значит, поделили отрезок.
[44:33.880 --> 44:37.880]  И теперь кси1 от ω.
[44:37.880 --> 44:53.880]  Это номер того, в который попало это 1 от ω.
[44:53.880 --> 45:02.880]  Ну, и дальше, значит, то есть, видите, явным образом построили пока кси0 и кси1.
[45:02.880 --> 45:05.880]  А дальше это по индукции продолжаем.
[45:05.880 --> 45:06.880]  Так.
[45:06.880 --> 45:09.880]  Дальше это, ну, кси2 строим.
[45:09.880 --> 45:10.880]  Кси2.
[45:10.880 --> 45:12.880]  С помощью это 2.
[45:12.880 --> 45:16.880]  Это 2 попадает в свои промежутки.
[45:16.880 --> 45:30.880]  Не вот в эти, так, значит, не в эти попадает, а для кси2, значит, ну, свои промежутки.
[45:30.880 --> 45:33.880]  Вот эти дельты свои другие будут для, ну, на втором шаге.
[45:33.880 --> 45:35.880]  Значит, смотрите они какие будут.
[45:35.880 --> 45:41.880]  Значит, смотрите, ну, вот по индукции.
[45:41.880 --> 45:52.880]  Значит, если кси n уже есть, то, значит, кси n плюс 1.
[45:52.880 --> 46:06.880]  Номер промежутка, в который попало, значит, в который попало вот это n плюс 1.
[46:06.880 --> 46:07.880]  Так.
[46:07.880 --> 46:13.880]  Значит, видите, на каждом шаге, значит, это из этих независимых свое используется.
[46:13.880 --> 46:14.880]  Так.
[46:14.880 --> 46:26.880]  И, значит, длины промежутков, значит, длины промежутков.
[46:26.880 --> 46:28.880]  Ну, ну, вот этих вот.
[46:28.880 --> 46:32.880]  Ну, давайте скажем так, дельта 1, n.
[46:32.880 --> 46:35.880]  Вот на шаге, на шаге n плюс 1.
[46:35.880 --> 46:36.880]  Да.
[46:36.880 --> 46:38.880]  Значит, на шаге n плюс 1.
[46:38.880 --> 46:42.880]  Значит, промежутков число одно и то же.
[46:42.880 --> 46:47.880]  Но длины подобраны так.
[46:47.880 --> 46:54.880]  Ну, это, так сказать, каждый раз индуктивно, значит, ну, делаем.
[46:54.880 --> 47:03.880]  Значит, подбираем, значит, длины так, чтобы, чтобы.
[47:03.880 --> 47:26.880]  Значит, так, что вероятности вот такие вот, значит, были те, те, которые получаются по формуле.
[47:26.880 --> 47:36.880]  Ну, вот с помощью вот этих переходных.
[47:36.880 --> 47:37.880]  Так.
[47:37.880 --> 47:43.880]  Ну, то есть они каждый, они каждый раз, ну, какие-то, так сказать, нам, нам даже не важно находить их.
[47:43.880 --> 47:46.880]  Но они какие-то есть, которые диктуются формулой.
[47:46.880 --> 47:49.880]  Вот, значит, по ним подбираем.
[47:49.880 --> 48:01.880]  Ну, и вот получается, получается, видите, ну, ну, почти что, почти что формульно заданный процесс со значениями в этом конечном множестве.
[48:01.880 --> 48:10.880]  Ну, и вот, значит, в качестве задачи разберитесь, почему этот процесс будет марковский.
[48:10.880 --> 48:13.880]  Ну, вот, ну, вот с нужными условиями.
[48:13.880 --> 48:25.880]  Значит, здесь видите, ну, ну, опять какие-то, тут опять, конечно, какие-то комбинаторные вычисления возникают, похожие на те, которые вот я опустил и заслал конспекту.
[48:25.880 --> 48:33.880]  Но здесь зато не нужна теорема Колмогорова, а сразу более-менее явно строится такой процесс.
[48:34.880 --> 48:47.880]  Но однако надо иметь в виду, что в значительном числе задач, вот про марковский процесс и про цепи Маркова, почему-то бывает не важно иметь сам процесс,
[48:47.880 --> 49:00.880]  а бывает важно иметь, ну, вот эти вот переходные вероятности там, вот что-то с вероятностями с этими делается, с переходными там, с вероятностями значений, но не с самим процессом.
[49:00.880 --> 49:14.880]  Так что вот почему-то вот в отличие от большинства других процессов там, скажем, Винеровского, там Мартингалов, вот почему-то с цепями процессы, они как бы на втором плане,
[49:14.880 --> 49:24.880]  а основную роль играют вот всякие такие вот эти вещи с, значит, с вероятностями вот с этой матрицей.
[49:24.880 --> 49:42.880]  Вот теперь, значит, в связи с этими же, значит, вероятностями, значит, стационарное распределение.
[49:42.880 --> 50:11.880]  Значит, стационарное распределение, значит, пи, стационарная или инвариантная, инвариантная мера цепи, если она не меняется под действием этой матрицы.
[50:11.880 --> 50:34.880]  Ну, смысл такой, что если вы процесс начали, если вы Марковскую цепь запустили не с произвольного начального распределения, а со стационарного, то как бы, так сказать,
[50:34.880 --> 50:39.880]  распределение со временем не меняется, вот с этим смыслом.
[50:39.880 --> 50:48.880]  Скажем, вы можете запускать Марковскую цепь с какого-нибудь очень простого начального распределения.
[50:48.880 --> 50:58.880]  Например, вы можете взять начальное распределение меры Дерака в одной из этих точек фазового пространства и из нее запустить, то есть как бы из точки запустить цепь.
[50:58.880 --> 51:12.880]  Но тогда у вас уже после первого шага цепь будет распределена, она не будет с вероятностью единицы находиться в другой точке, ну там кроме каких-то особо выраженных цепей,
[51:12.880 --> 51:21.880]  а она уже, так сказать, так типично распределится по всему этому множеству, с какими-то вероятностями в любой точке будет сидеть.
[51:21.880 --> 51:29.880]  Но если верно такое равнится, то распределение меняться не будет со временем.
[51:29.880 --> 51:51.880]  Ну и вот простая теорема, теорема существует для конечного набора всегда есть стационарные меры, ну инвариантные меры.
[51:51.880 --> 52:09.880]  Значит, ну доказательства, значит доказательства, значит множество П, значит это все вероятностные меры,
[52:09.880 --> 52:32.880]  ну вот на этом множестве, из конечного числа точек, это конечномерный выпуклый компакт,
[52:32.880 --> 52:52.880]  потому что вы всякую меру, всякую меру М, вы отождествляете с набором точек, ну скажем, альфа-1, альфа-М,
[52:52.880 --> 53:05.880]  где альфа-ит и не отрицательны, и сумма альфа-ит их единица, то есть это такой даже не просто компакт, а такой, так сказать, ну многогранник, симплекс такой получается.
[53:05.880 --> 53:25.880]  Вот и П, вот это отображение, так, это непрывное отображение, ну оно даже лучше, чем непрывное, это просто линейное отображение,
[53:25.880 --> 53:39.880]  ну поэтому существует неподвижная точка, ну это по общей теореме Боля-Брауера, что если у вас есть выпуклый компакт,
[53:39.880 --> 53:48.880]  и есть непрывное отображение этого компакта в него же, то у него есть неподвижная точка, а тут ситуация более благоприятная,
[53:48.880 --> 54:00.880]  отображение не просто непрывное, а линейное, так что это можно доказать и без теоремы Боля-Брауера несколько проще,
[54:00.880 --> 54:10.880]  но хоть и проще, но нельзя сказать, что это прямо сразу очевидно, вот попробуйте в качестве упражнения, попробуйте не пользуясь теоремой Боля-Брауера это доказать,
[54:10.880 --> 54:19.880]  это в общем можно сделать, но это нельзя сказать, что прям какое-то упражнение для восьмиклассницы, но попробуйте сделать,
[54:19.880 --> 54:30.880]  но мы естественно будем пользоваться теоремой Боля-Брауера, но там наверное она где-то была в каком-то из ваших многочисленных курсов,
[54:30.880 --> 54:50.880]  ну вот в каком-то была, сейчас, но давайте я тогда сформулирую эту теорему, раз уж я ее воспользовался, давайте я ее сформулирую,
[54:50.880 --> 55:09.880]  значит теорема, теорема Боля-Брауера, значит если F, ну давайте так, V выпуклый компакт,
[55:09.880 --> 55:25.880]  компакт ВРМ, значит и F из В в непрерывное отображение,
[55:25.880 --> 55:43.880]  тогда, тогда существует точка X0 такая, что V от X0 есть X0, ну для отрезка эта теорема совсем упражнение,
[55:43.880 --> 55:53.880]  а вот уже там для квадрата, там для треугольника, для круга на плоскости это уже не банальная вещь, ну такая я бы сказал совсем не банальная,
[55:53.880 --> 56:06.880]  но значит по идее, ну в каких-то курсах это должно быть, ну в каких это курсах может быть, ну например если у вас какая-нибудь там топология под разными соусами,
[56:06.880 --> 56:24.880]  ну я не знаю у физтехов много ли топологии, вот у мехматян топологии всяких прорыва, и там вот даже не в одном даже каком-то курсе вот такой факт,
[56:24.880 --> 56:40.880]  значит откуда-то всплывает, значит этот факт может быть скраплен в матанализ, ну например если у лектора много лекций, он не знает что бы еще им рассказать студентам,
[56:40.880 --> 56:52.880]  думает ну вот что-нибудь забубенное про ряды фурье, думает да нет зачем им ряды фурье в 21 веке, давайте я ему расскажу вот теорему Боля-Брауэра,
[56:52.880 --> 57:04.880]  значит и с помощью, ну ее можно действительно если пол лекции анализа не пожалеть, то можно элементарно доказать используя формулу замены переменных,
[57:04.880 --> 57:14.880]  используя формулу замены переменных, это вот так сказать в том матане где многомерный анализ, там формула замены переменных, значит в интеграле,
[57:14.880 --> 57:23.880]  вот с помощью этой формулы замены переменных это можно доказать, ну это у этой теоремы много разных доказательств, есть такие почти школьные,
[57:23.880 --> 57:35.880]  ну я бы сказал даже может быть точности школьные, такие комбинаторные, комбинаторного плана, где кроме большой проницательности ничего не нужно,
[57:35.880 --> 57:45.880]  но как бы то ни было совсем коротко это не объяснишь, это действительно нуждается в доказательстве, ну и вот это было открыто независимо,
[57:45.880 --> 57:56.880]  значит Боля-Брауэр это два разных человека, это не как мамин-сибиряк, это два разных математика начала 20 века, вот они этот факт обнаружили,
[57:56.880 --> 58:08.880]  значит факт не очевидный, видите, он такой нельзя сказать, что он интуитивно очевиден, вот даже из физических соображений,
[58:08.880 --> 58:23.880]  ну вот смотрите, он что означает, ну вот предположим, вы решили изготовить какое-нибудь варьево, так в кастрюле,
[58:23.880 --> 58:33.880]  значит ну наполнили выпуклую кастрюлю или кастрюлю гомеоморфную, ну предположим она у вас уже не выпуклая от долгого употребления,
[58:33.880 --> 58:44.880]  значит ну по крайней мере она осталась гомеоморфно выпуклой изначальной кастрюли, вы наполнили там всем, чем полагается для варьева,
[58:44.880 --> 58:53.880]  и там по технологии надо тщательно перемешать его, ну вот вы мешаете, мешаете, значит долго мешали, ну вот оказывается,
[58:53.880 --> 59:07.880]  что как вы не мешали, с каким бы тщанием вы не мешали, останется точка после всех этих ваших манипуляций, останется точка,
[59:07.880 --> 59:16.880]  которая не сдвинулась, и вот вы так сказать, ну эту точку следующим мешанием, вы эту точку можете устранить, она сдвинется,
[59:16.880 --> 59:23.880]  но появится новая точка, которая встала на свое место, так что вот совсем в буквальном смысле перемешать не удастся,
[59:23.880 --> 59:34.880]  ну если конечно вы не так ожесточенно мешаете, что у вас там разрыв жидкости произошел конечно, значит тут все-таки отображение непрывное конечно,
[59:34.880 --> 59:48.880]  так значит вот такой важный факт, такая мера очевидна не единственная конечно, таких может быть много,
[59:48.880 --> 01:00:13.880]  значит вот мы в следующей теореме, которая называется эргодической, ну это такой ее простейший вариант для конечных цепей,
[01:00:13.880 --> 01:00:42.880]  ну опять конечная цепь, и при некотором N1 все элементы этой матрицы в степени N1 положительные,
[01:00:42.880 --> 01:01:01.880]  вот тогда значит, тогда значит инвариантная вероятностная мера,
[01:01:01.880 --> 01:01:11.880]  ну пусть будет μ, единственная,
[01:01:11.880 --> 01:01:25.880]  она положительна на всех точках,
[01:01:25.880 --> 01:01:39.880]  и причем к ней сходятся, сходятся меры
[01:01:39.880 --> 01:01:59.880]  для всякого начального пиноль,
[01:01:59.880 --> 01:02:08.880]  ну в каком смысле меры сходятся, ну тут пространство конечное, поэтому меры сходятся, ну просто их значение,
[01:02:08.880 --> 01:02:16.880]  ну в этом случае тут все разумные виды сходимости мер равносильны, ну значит значения на точках их сходятся,
[01:02:16.880 --> 01:02:25.880]  ну кстати сказать, если знать последнее утверждение, то тогда конечно, ну единственность тоже из него следует,
[01:02:25.880 --> 01:02:34.880]  потому что вы можете начать с какого-то пиноля, и значит говорится, что к этому стационарному будут сходиться,
[01:02:34.880 --> 01:02:48.880]  ну значит сходиться будет к нему, значит смотрите, если вы начали с начального определения стационарного,
[01:02:48.880 --> 01:02:59.880]  то тогда конечно сходимость будет, потому что если пиноль стационарна, то по определению стационарного это и будет пиноль,
[01:02:59.880 --> 01:03:05.880]  так что ничего доказывать не надо, но тут утверждается, что вы начали с какого угодно,
[01:03:05.880 --> 01:03:12.880]  значит когда с какого угодно, то естественно эти уже разные, поэтому вопрос, почему они сходятся,
[01:03:12.880 --> 01:03:23.880]  значит тут меры на конечном множестве, поэтому понятно, что у такой последовательности всегда есть подпоследовательность сходящаяся,
[01:03:23.880 --> 01:03:30.880]  но тут утверждается больше не про подпоследовательность, а про саму последовательность тут говорится,
[01:03:30.880 --> 01:03:49.880]  так ну давайте зафиксируем, фиксированная стационарная, она какая-то есть по теориям более бравая,
[01:03:49.880 --> 01:04:11.880]  значит ну для упрощения считаем, что n1 единица, ну то есть что у исходной матрицы переходной все элементы положительные,
[01:04:11.880 --> 01:04:19.880]  ну это не самый общий случай, но общий случай похож только, ну чуть-чуть там технической возни больше,
[01:04:19.880 --> 01:04:26.880]  так что вот такое упрощение сделаем, значит это упрощение неравносильно исходно утверждению,
[01:04:26.880 --> 01:04:34.880]  потому что легко вы можете привести пример матрицы, у которой есть нолик, ну например матрица 2 на 2 есть нолик,
[01:04:34.880 --> 01:04:42.880]  а возвели в квадрат нолик исчез, так что это действительно упрощение неравносильно исходному,
[01:04:42.880 --> 01:04:54.880]  ну в общем доказательства, в общем случае аналогично, значит теперь важное обозначение,
[01:04:54.880 --> 01:05:17.880]  значит берем матрицу, значит матрица, все строки, которые, значит все строки, которые, вот это вот мю,
[01:05:17.880 --> 01:05:34.880]  ну давайте считать, значит мю там от x1 и так далее, мю значит xm, так, значит вот такая матрица с одинаковыми строками,
[01:05:34.880 --> 01:05:51.880]  значит эта матрица сейчас будет играть, значит важную роль, значит для этой матрицы верно,
[01:05:51.880 --> 01:06:11.880]  следующая, ну вот ради чего она и вводится, так, значит вот, значит для всякой вероятностной меры
[01:06:11.880 --> 01:06:25.880]  пи, если вы примените эту странную матрицу к вероятностной мере пи, ну я напоминаю, по-прежнему меры записываются как векторы строки,
[01:06:25.880 --> 01:06:35.880]  то получится мю, так, ну вот собственно это м так специально подобрано, чтобы это получилось, ну вы числением проверьте, что так будет.
[01:06:35.880 --> 01:06:59.880]  Теперь, значит существует такое дельта больше нуля, что p и житые больше либо равно, чем дельта на m и житые,
[01:06:59.880 --> 01:07:11.880]  ну дельта, давайте я напишу не больше нуля, конечно, а дельта из 0.1, ну оно больше нуля, но еще оно и дельта оно еще из 0.1 будет,
[01:07:11.880 --> 01:07:24.880]  ну почему это так, ну это просто потому что p и житые положительные числа, а эти числа, ну какие-то числа, поэтому в качестве дельта можно взять ну минимум,
[01:07:24.880 --> 01:07:47.880]  например, вот этих, значит, так, теперь, значит, возьмем лямда равна единице минус дельта, вот тогда, значит, ну вот тут начинается некая некая махинация с матрицами,
[01:07:47.880 --> 01:07:57.880]  значит, за которыми надо внимательно проследить, чтобы не было обмана, а я вот когда впервые доказательство это прочитал, мне показалось, что какой-то обман,
[01:07:57.880 --> 01:08:04.880]  но потом я его с конспекте выписал вроде, ну вроде нет, ну не было, но не знаю, может за год появился, значит, вам надо проверить,
[01:08:04.880 --> 01:08:23.880]  значит, тогда, значит, смотрите, значит, p можно записать вот в таком вот виде,
[01:08:23.880 --> 01:08:41.880]  значит, где q, ну это тоже матрица, там с элементами q и житые, которые не отрицательны, значит, которые не отрицательны эти элементы,
[01:08:41.880 --> 01:08:55.880]  и ну матрица вот такая тоже, так сказать, стахастическая, сумма по ж, q и ж равняется единице,
[01:08:55.880 --> 01:09:16.880]  а кто такая q, ну естественно, если это верно, то конечно q, тут же все остальные даны, p дано, m дано, λ дано, так что если это верно, то q вычисляется из этой формулы,
[01:09:16.880 --> 01:09:25.880]  и поэтому фактически, что нужно проверить, ну мы не будем этого делать, естественно, на доске, но проверьте, вот тут как раз, я когда это впервые увидел,
[01:09:25.880 --> 01:09:34.880]  мне показалось, что тут какое-то надувательство, но потом я вот на бумажке проверил отдельно, но не в конспекте, чтобы не портить, так сказать, вам, значит, удовольствие проверить,
[01:09:34.880 --> 01:09:48.880]  значит, проверьте, что если q из этого соотношения задать, то получатся такие условия, вот, и еще что нужно тоже проверить,
[01:09:48.880 --> 01:10:07.880]  вот тот, кто придумал это доказательство, конечно, был весьма проницательным человеком, ну я напишу, что при этом, вот такие вещи понятно как проверять,
[01:10:07.880 --> 01:10:27.880]  но непонятно как открывать такие вещи, вот такое вот соотношение верно, вот такое соотношение верно, верно такое соотношение,
[01:10:27.880 --> 01:10:37.880]  ну откуда, значит, как проверять это соотношение, ну давайте я в скобках помещу, откуда это взялось, но это тоже надо проверить,
[01:10:37.880 --> 01:11:01.880]  значит, можно проверить, что m в квадрате будет m, так, и еще можно проверить, что m и p коммутируют, и коммутатор, ну что они коммутируют, и что произведение будет вот такое,
[01:11:01.880 --> 01:11:30.880]  вот есть ли эти два соотношения проверить, да, что, что, где, нет, сейчас, а, сейчас, здесь, слушайте, у меня, сейчас, сейчас, сейчас,
[01:11:30.880 --> 01:11:53.880]  сейчас, п, сейчас, слушайте, вот, слушайте, вот я хвастался, что все проверил, но, значит, так,
[01:11:53.880 --> 01:12:05.880]  да, слушайте, вы правы, нет, слушайте, все-таки,
[01:12:05.880 --> 01:12:33.880]  сейчас, сейчас, нет, нет, вот видите, в этом есть некий, так сказать, изъян того, что не пишешь в конспекте полное доказательство, так сказать, оставляя что-то проверить,
[01:12:33.880 --> 01:12:56.880]  сейчас, вот я, легче всего было бы сказать, что p в степени n тут должно быть, значит, сейчас, нет, знаете, вы правы, n все-таки, да, n, нет, соотношение все-таки с n, да,
[01:12:56.880 --> 01:13:12.880]  ну, я почему сомневался, потому что сейчас дальше будет, ну, значит, так сказать, заключительное, заключительное соотношение, значит, ну, которое даст то, что нужно, и там, там как раз,
[01:13:12.880 --> 01:13:35.880]  нет, вы правы, да, тут, конечно же, n, да, значит, тут n, а, значит, ну, ну, давайте, слушайте, ну, тут еще у меня несколько минут есть, давайте я их использую, чтобы это проверить все-таки, раз уж тут, значит,
[01:13:35.880 --> 01:13:56.880]  значит, смотрите, значит, смотрите, вот, вот те, вот, вот нижние соотношения не буду проверять, значит, они, ну, они реально простые, значит, значит, смотрите, что еще получается, q на m будет m, так, значит, теперь, значит, значит, теперь по индукции,
[01:13:56.880 --> 01:14:18.880]  получается так, а p в степени n плюс 1, это единица, ну, вот, если подставить, если сюда подставить вот это, значит, если сюда подставить вот это, то получится, значит, вот так,
[01:14:18.880 --> 01:14:26.880]  ну, ну, и итог получается, ну, то, что должно быть по предположению индукции.
[01:14:26.880 --> 01:14:45.880]  Ну, и итог получается, ну, то, что должно быть по предположению индукции.
[01:14:45.880 --> 01:15:03.880]  Да, вот так, значит, таким образом это доказано, значит, ну, и окончательный итог, ну, и вот, значит, на этот окончательный итог мне еще оставшиеся минуты должны хватить, значит, итог.
[01:15:03.880 --> 01:15:27.880]  Итог, значит, так как, так как p 0 m минус mu m равняется нулю, то имеем p 0 m минус mu m равняется 0, то имеем p 0 m минус mu m равняется 0,
[01:15:27.880 --> 01:15:46.880]  то имеем p 0 p в степени n минус mu, это p 0 в степени n минус mu, значит, вот так.
[01:15:46.880 --> 01:16:02.880]  Значит, это p 0 минус mu на p в степени n, значит, и это есть p 0 минус mu, вот на что.
[01:16:02.880 --> 01:16:27.880]  Единица минус лямда, значит, вот на это, тут в степени n, значит, вот здесь, значит, вот здесь в степени n, и вот это я выпишу вот здесь.
[01:16:27.880 --> 01:16:50.880]  И на этом это уже почти что завершает доказательства, значит, это будет лямда в степени n на p 0 минус mu в степени n, вот так получилось, так.
[01:16:50.880 --> 01:17:04.880]  Ну и теперь, теперь давайте заметим, что вот это, что вот это стремится к нулю, так, значит, почему, значит, почему.
[01:17:04.880 --> 01:17:23.880]  Ну потому что, потому что норма вот такого вот вектора, оно, она оценивается через два, так, норма такого вектора оценивается через два.
[01:17:23.880 --> 01:17:39.880]  Ну если, как считать норму, как считать норму вектора, ну если норму вектора считать как, значит, как сумма модулей.
[01:17:39.880 --> 01:17:49.880]  Ну норма, ну давайте так считать, норма вот такого вот вектора, это будет сумма модулей.
[01:17:49.880 --> 01:18:11.880]  Вот если так считать, то, значит, из-за того, что это вероятностные меры, то получится, ну и q такая, вот такая, какая она там была, такая вот, так сказать, стахастическая матрица, то, значит, будет верна такая оценка.
[01:18:11.880 --> 01:18:26.880]  А лямбда меньше единицы, ну и поэтому это стремится к нулю. Ну и, ну и, значит, значит, таким образом сходимость есть, ну а из этой сходимости, значит, вытекает единственность.
[01:18:26.880 --> 01:18:49.880]  Значит, да, да, да, еще почему, значит, почему последнее, значит, последнее замечание, значит, последнее замечание, почему, почему все элементы положительные у mu значение, так, значит, почему,
[01:18:49.880 --> 01:19:18.880]  почему mu от x итых больше нуля, вот это, значит, вот это мы еще не сделали. Значит, ну это вот почему, потому что p от n1 mu от x итых это больше нуля.
[01:19:18.880 --> 01:19:32.880]  Так, это из-за того, что у этой матрицы все элементы положительные, а у этой, ну есть положительные, остальные не отрицательные.
[01:19:32.880 --> 01:19:50.880]  Но, но и из-за инавариантности это есть вот это. Вот так будет, так будет не только для нашей mu, так будет вообще для какой угодно меры вероятностной.
[01:19:50.880 --> 01:20:02.880]  Это из-за того, что у этой матрицы все элементы положительные, поэтому если вы ее примените к какой угодно такой вероятностной строке, то получится все элементы положительные.
[01:20:02.880 --> 01:20:13.880]  Но когда вы примените именно к этой mu, то это будут из-за инавариантности будут сами эти. Вот так что все, вот, значит, таким образом доказана вот такая теорема,
[01:20:13.880 --> 01:20:23.880]  что в случае положительных переходов есть, значит, единственность и сходимость.
[01:20:23.880 --> 01:20:30.880]  Вот этот факт, он важен даже для цепей с двумя состояниями.
[01:20:30.880 --> 01:20:42.880]  Ну, можно сказать, что для многих практических задач это условие выполнено, что вероятности положительные.
[01:20:42.880 --> 01:20:54.880]  И поэтому во многих случаях стационарное определение не только, но оно и единственное, и вот к нему еще есть сходимость.
[01:20:54.880 --> 01:21:01.880]  Это во многих приложениях вот почему-то оказывается важным, что есть такая сходимость.
[01:21:01.880 --> 01:21:07.880]  Ну и исследуется там скорость сходимости, но это мы уже сейчас не будем обсуждать.
[01:21:07.880 --> 01:21:15.880]  Для общих марковских процессов тоже наличие стационарного распределения это очень важная вещь.
[01:21:15.880 --> 01:21:22.880]  И вот для диффузионных процессов это важная вещь, но это, в общем, мы уже не будем обсуждать, это такие уже, так сказать, более тонкие вещи.
[01:21:22.880 --> 01:21:36.880]  Так, все, значит, таким образом основная теоретическая часть закончена, а следующие две лекции это решаем совершенно конкретные две задачи.
