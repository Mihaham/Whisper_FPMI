[00:00.000 --> 00:11.480]  Мы снова говорим на семинаре про какие-то более практические аспекты всех этих
[00:11.480 --> 00:17.320]  распределенных систем, но прежде чем мы перейдем к теме нашей сегодняшней, это вызов ударенных
[00:17.320 --> 00:23.960]  процедур или ударенный вызов процедур. Я так до сих пор и не узнал, как правильно. Есть ли у вас
[00:23.960 --> 00:28.480]  вопросы ко мне, какие-то пожелания, предложения по поводу того симулятора, с которым мы работаем?
[00:28.480 --> 00:35.360]  У нас есть инструменты, их довольно много, они довольно сложно устроены, они еще и меняются,
[00:35.360 --> 00:41.520]  и у них что-то добавляется. Появился визуализатор, даже два. Вот выберите,
[00:41.520 --> 00:48.320]  который вам больше нравится, и в нем еще много чего появится. Но, возможно, вдруг вам что-то
[00:48.320 --> 00:52.440]  непонятно, что-то неудобно, что-то неинтуитивно, документация чего-то не покрывает. Вот, пожалуйста,
[00:52.440 --> 00:58.840]  не держите это в себе, говорите сразу. Не товарищу, а в чат. Если вы ждете час, пока бегают
[00:58.840 --> 01:03.640]  симуляции, а потом через сутки пишете об этом, то лучше говорить сразу, пока этот час идет,
[01:03.640 --> 01:10.080]  чтобы я знал об этом, ну в смысле мог на это повлиять. Если вдруг вы встречаетесь с чем-то,
[01:10.080 --> 01:16.720]  что вам неудобно, то вместо того, чтобы принимать такое должное, можно это обсудить.
[01:16.720 --> 01:24.720]  Я, со своей стороны, вам рекомендую прочесть документацию, попробовать обязательно визуализатор
[01:24.720 --> 01:30.920]  и почитать логи. Без этого, кажется, ничего не выйдет. И у меня есть такой мета-совет,
[01:30.920 --> 01:34.960]  когда вы пишете код, не думайте про симулятор. Чем меньше вы про симулятор думаете, тем вам
[01:34.960 --> 01:39.160]  лучше. В документации есть пара пунктов, где о нем нужно думать. Вот там, мне надо
[01:39.160 --> 01:43.720]  назвать глобальные перемены, и нужно использовать интерфейсы, а не там хроны, рэндомы, все такое.
[01:43.720 --> 01:50.160]  Этих исключений довольно мало. Во всем остальном вы можете думать про физический мир, где что-то
[01:50.160 --> 01:54.680]  параллельно исполняется, где узлы действительно могут отказывать, где все занимает время. В общем,
[01:54.680 --> 02:00.080]  если вы будете жить в такой модели мира, то, скорее всего, и в симуляторе с вами все будет
[02:00.080 --> 02:04.040]  хорошо. А если вы будете думать про то, что в симуляторе есть и чего там нет, то, возможно,
[02:04.040 --> 02:14.360]  вы сами в ногу выстрелите случайно. По поводу первой задачи. Второй задачи. Первый в симуляторе.
[02:14.360 --> 02:19.920]  Я вам очень рекомендую сделать сначала как-нибудь, а потом сделать через стру тайм. А потом сделать
[02:19.920 --> 02:26.680]  хорошо через стру тайм. Там есть два способа, два шага в решении стру тайма. Первый наивный,
[02:26.680 --> 02:32.280]  второй можно немножко подумать и что-то там распролилить, попробовать. Или вы можете прочесть
[02:32.440 --> 02:37.080]  статью про спаннеры. Довольно сложно, потому что вы пока не сможете ее прочесть. Но если вы вдруг
[02:37.080 --> 02:40.760]  найдете, как там используется стру тайм, то там, по-моему, замечания про это точно есть.
[02:40.760 --> 02:47.240]  И, ну вот, в общем, вы можете применить у себя все идеи, которые там есть, и споткнуться
[02:47.240 --> 02:52.600]  об какие-то грабли интересные. Мы это потом обсудим. Опять же, пишите, делитесь этим со мной.
[02:52.600 --> 02:59.640]  Мне любопытно. Ну а сегодня я хочу поговорить с вами немного про код, который мы пишем,
[02:59.640 --> 03:07.960]  точнее, который вы уже умеете писать сами и который вы умеете использовать. Вот кусочек,
[03:07.960 --> 03:15.400]  где делается рпс-вызов. И я бы хотел с вами сегодня обсудить, как этот код работает и как
[03:15.400 --> 03:23.400]  вообще... Мы живем с некоторым фреймворком для удаленных вызовов. Я хочу сегодня эту задачу
[03:23.400 --> 03:28.920]  обсудить подробнее. То есть, как такой фреймворк в принципе должен быть, как он может выглядеть,
[03:28.920 --> 03:34.480]  какие в нем есть подзадачи, какие можно в архитектуре этого фреймворка выделить слои и
[03:34.480 --> 03:40.280]  где какая задача решается. То есть, чтобы у вас не было ощущения, что у нас некоторый произвол,
[03:40.280 --> 03:45.720]  некоторый произвольный интерфейс, и он как-то не похож на все остальное или похож на все остальное,
[03:45.720 --> 03:51.000]  нужно выяснить, где он похож, где он расходится и какие вообще у нас варианты. Ну, примерно,
[03:51.000 --> 03:54.840]  как мы в прошлом семестре обсуждали, как мы можем сделать конкарнси, и у нас было много
[03:54.840 --> 04:00.440]  способов разных. Вот у нас другая задача, где тоже можно все делать по-разному и в жизни вы можете
[04:00.440 --> 04:06.440]  работать с разными фреймворками. Мы сегодня хотим разобраться, какие там есть трейд-оффы и какие
[04:06.440 --> 04:11.920]  там есть альтернативы в смысле дизайна. Ну, а для начала нужно вспомнить, как вообще мы к этому
[04:11.920 --> 04:20.120]  пришли. Итак, мы пишем с вами алгоритм. В алгоритме есть алгоритм репликации ячейки памяти,
[04:20.120 --> 04:38.840]  но или наивного репликации кива-реохранилища, и там есть узлы и клиенты. Я коротко напомню,
[04:38.840 --> 04:44.520]  как мы вообще пришли к понять этих ударенных вызовов. Мы, конечно, оттолкнулись от алгоритма,
[04:44.520 --> 04:55.200]  который у нас был. У нас были узлы системы и были клиенты, которые с этой системой работают,
[04:55.200 --> 05:14.840]  ставят запрос туда. Ну а дальше, как мы про этот алгоритм рассуждали? Вот у нас есть клиент,
[05:14.840 --> 05:23.160]  он посылает свою команду, допустим, сет ключ значения на какой-то узел случайной этой системы,
[05:23.160 --> 05:27.480]  и этот узел начинает собирать кворумы. Сначала он собирает кворум на чтение,
[05:27.480 --> 05:33.080]  чтобы выбрать временную метку для записи, потом он эту запись с этой временной меткой записывает
[05:33.080 --> 05:45.760]  на какой-то кворум. Ну и другой клиент делает что-то похожее, можно его изобразить синим цветом.
[05:53.160 --> 06:08.640]  Дальше, что мы сказали? Посмотрим на какую-то машину, вот на эту машину или на эту машину,
[06:08.640 --> 06:14.560]  или на эту машину, как они в этом алгоритме участвуют. С одной стороны, вот эта реплика,
[06:14.560 --> 06:25.320]  Р1, Р2, Р3, Р4, Р5, напоминаю, их всегда нечетное количество. Вот реплика Р4, она получает
[06:25.320 --> 06:29.880]  команду от клиента и начинает выбирать timestamp, собирать кворумы, чем-то вот таким вот занимается.
[06:29.880 --> 06:44.000]  Реплика Р2 занимается немного другим, она сама ничего по себе не делает,
[06:44.000 --> 06:50.480]  не обслуживает клиентов в данном исполнении, она получает команды от этой реплики и записывает у себя
[06:50.480 --> 06:56.800]  что-то, сравнивает свою версию с той, что я отправил этот узел, ну и либо отвергает его предложение,
[06:56.800 --> 07:04.840]  либо обновляет свое локальное значение. И вроде бы это все можно было бы написать буквально на кулбеках,
[07:04.840 --> 07:11.280]  где узел получает сообщение, на нем дергается какой-то кулбек для команды Set или кулбек для команды
[07:11.320 --> 07:19.800]  Запиши, обнови локальное значение. Но все же можно заметить, что у этих узлов, хоть они все равноправны
[07:19.800 --> 07:26.520]  относительно того или иного запроса, есть разные поведения. Вот этот узел, он координирует запрос,
[07:26.520 --> 07:33.240]  он выбирает timestamp, собирает кворумы, дожидается их, какую-то активную роль выполняет. А вот этот узел
[07:33.240 --> 07:38.080]  относительно этого красного запроса, красной записи, он пассивен, он просто принимает запросы
[07:38.080 --> 07:43.440]  от этого координатора и обновляет свое значение, либо не обновляет, если оно устарело уже.
[07:43.440 --> 07:51.160]  И довольно разумно, что вот эти разные поведения, эти разные реакции на разные наборы сообщений
[07:51.160 --> 07:56.160]  можно было бы как-то отделить друг от друга. Мы сказали, что у нас в алгоритме есть роль координатора
[07:56.160 --> 08:10.080]  и роль реплики. Вот координатор, это активная роль, она бдрайвит протокол записи, а реплика,
[08:10.080 --> 08:14.880]  она пассивная, она просто отвечает на запросы, никогда сама коммуникацию не инициирует. И довольно
[08:14.880 --> 08:20.680]  разумно, если вот эти две роли, которые логический алгоритм, конечно же, есть, были бы выделены как-то
[08:20.680 --> 08:29.360]  в коде. То есть это два различных поведения узла. И относительно каждого запроса он может быть либо
[08:29.360 --> 08:34.800]  координатором, либо репликой, может быть всем и тем. В данном случае вот R4, он и координатор
[08:34.800 --> 08:41.720]  этого запроса, и реплика, которая на команду координатора отвечает. То есть вот эти роли
[08:41.720 --> 08:46.000]  существуют по одной, существуют вместе, и разумно было бы их в коде выделить в какие-то
[08:46.080 --> 08:52.200]  отдельные сущности, в отдельные классы. И у этого класса был бы какой-то набор методов, в зависимости
[08:52.200 --> 08:57.520]  от того, какие команды этот участник, эту роль может принимать. Для координатора эти команды,
[08:57.520 --> 09:02.120]  это set и get, это внешние команды от клиентов. Для реплики это команды, ну вот у нас можно
[09:02.120 --> 09:10.000]  называть local read, local write, это команды записи или чтения локального значения. Это вот первая мысль,
[09:10.000 --> 09:15.960]  которая нас посетила. Вторая мысль, параллельная первая, заключалась в том, что с одной стороны мы
[09:15.960 --> 09:20.880]  здесь рисуем стрелочки, и вот координатор получает этот красный запрос от клиента, а дальше его раздает
[09:20.880 --> 09:27.840]  другим, но в том числе и себе. И на уровне сети это, конечно, асинхронная отправка сообщения,
[09:27.840 --> 09:32.920]  то есть мы пишем, ну мы пользуемся, конечно, каким-то транспортом сообщения, но в конечном итоге мы
[09:32.920 --> 09:38.960]  кидаем в канал байты, и они улетают, и после этого мы ждем, что в обратную сторону однажды что-то
[09:38.960 --> 09:44.240]  прилетит. Главное, что вот на этом уровне и в нашей модели, которую мы построили на первой лекции,
[09:44.240 --> 09:51.040]  были только асинхронные сообщения. Но если мы смотрим на поведение нашего владелеца, на его устройство,
[09:51.040 --> 10:04.880]  то мы там рисуем такие диаграммы, где есть координатор и есть реплика, и они все-таки
[10:04.880 --> 10:10.880]  общаются структурировано. Координатор задает реплике какой-то запрос, и она на него отвечает.
[10:10.880 --> 10:15.760]  И вот на стрелку в одну сторону есть стрелка в обратную сторону с ответом, и они логически связаны.
[10:15.760 --> 10:23.280]  Поэтому с одной стороны, да, мы можем писать код на колбэках, и да, мы можем писать код на асинхронных
[10:23.280 --> 10:27.680]  сообщениях, но по факту нам и колбэки не очень удобны, нам нужно роли выделять, нам удобно было бы
[10:27.680 --> 10:32.080]  роли выделить. А с другой стороны, у нас все-таки коммуникация не в модели асинхронных сообщений,
[10:32.080 --> 10:44.080]  а в модели, где у нас есть какое-то сообщение-реквест и какой-то ответ-респонс. То есть координатор в этой
[10:44.080 --> 10:52.080]  коммуникации является клиентом, а реплика является сервером, который отвечает на запросы клиента.
[10:52.080 --> 11:02.080]  И в свою очередь, координатор является сервером для клиента внешнего, а клиент... Этот узел R4, он
[11:02.080 --> 11:08.080]  с одной стороны сервер для запроса клиента, и с другой стороны он клиент, когда он обращается к серверу
[11:08.080 --> 11:12.080]  другой реплики для записи своего значения.
[11:22.080 --> 11:30.080]  Если мы это в голове держим, то мы, наверное, понимаем, как нам удобнее было бы писать код, чтобы
[11:30.080 --> 11:36.080]  и вот это было в коде выражено, и вот эти роли как-то были явно присутствовали, и коммуникация клиент-сервер
[11:36.080 --> 11:44.080]  тоже была бы явной в коде, потому что так наши алгоритмы устроены. И тут мы приходим к понятию,
[11:44.080 --> 11:48.080]  который называется, естественным образом приходим к понятию, который называется RPC.
[11:48.080 --> 11:54.080]  Это вызов remote просить G-call.
[12:02.080 --> 12:10.080]  В чем смысл? В том, что мы не думаем про сеть, мы пытаемся сеть скрыть. Мы пытаемся
[12:10.080 --> 12:18.080]  рассуждать в терминах объектов. Да, мы не живем в модели разбираемой памяти, он между нами сеть,
[12:18.080 --> 12:25.080]  но в то же время как будто бы здесь координатор берет и вызывает на каком-то объекте реплика
[12:25.080 --> 12:33.080]  какой-то метод типа local write. Да, этот объект живет далеко, этот объект существует вот здесь,
[12:33.080 --> 12:38.080]  на другой машине, но даже не то, чтобы он в памяти живет, у него может быть состояние персистентное
[12:38.080 --> 12:44.080]  на диске, как у нашей реплики. Но тем не менее мы хотим как будто бы взять и на месте координатора
[12:44.080 --> 12:53.080]  вызвать методы на себе и на трех других репликах. То есть мы буквально хотим локально сделать
[12:53.080 --> 12:58.080]  вызов функции так, чтобы на самом деле эта функция была вызвана где-то на другой машине.
[12:58.080 --> 13:04.080]  И когда этот метод вызванный на каком-то объекте на другой машине вернет ответ, то мы его получили
[13:04.080 --> 13:11.080]  из своего вызова локально. Не то чтобы прямо так вот нам удобно будет делать, но вот такова задумка
[13:11.080 --> 13:23.080]  в RPC. И давайте мы сейчас наверное переместимся на некоторое время на экран. В ходе, который мы пишем,
[13:23.080 --> 13:30.080]  все так и происходит. У нас есть координатор и у нас есть реплика, и это отдельные классы.
[13:30.080 --> 13:37.080]  Они отвечают за какое-то поведение свое. Реплика имеет методы localWrite и localRead, а координатор
[13:37.080 --> 13:47.080]  имеет методы клиентские set и get. И в методе set мы выбираем каким-то образом неправильную здесь
[13:47.080 --> 13:53.080]  временную метку, а дальше как будто бы вызываем на объекте реплика на других машинах методы
[13:53.080 --> 14:02.080]  localWrite. Передаем туда аргументы. Ну вот буквально объекты языка C++. И на выходе получаем тоже
[14:02.080 --> 14:11.080]  какой-то объект. Но здесь получаем void, это неинтересно. Где-то в get мы получаем наверное что-то другое.
[14:11.080 --> 14:22.080]  Мы получаем stamped value. Если от деталей алгоритма абстрагироваться и поговорить про сам RPC,
[14:22.080 --> 14:30.080]  сам базовый механизм, то он для клиента выглядит так. У нас есть некоторый сервис. Предлагаю
[14:30.080 --> 14:39.080]  говорить про калькулятор. Это такой стандартный Hello World. Вы хотите как клиент иметь доступ к
[14:39.080 --> 14:45.080]  калькулятору, который находится на другой машине. И вы хотите вызывать на нем методы буквально так.
[14:45.080 --> 14:55.080]  Умножить 3 на 7 и получите ответ. Буквально вы делаете вызов на каком-то локальном объекте.
[14:55.080 --> 15:04.080]  Но на деле вы хотите, чтобы этот вызов происходил удаленно на другой машине. Так что вам нужно
[15:04.080 --> 15:11.080]  сам объект, который живет на другой машине и умеет умножать два числа, перенажать два числа,
[15:11.080 --> 15:18.080]  раскладывать. И дальше получается, что вам в такой конструкции, если вы хотите такой абстракции
[15:18.080 --> 15:25.080]  достичь, вам нужно два представления для объекта. С одной стороны, вам нужен реальный объект,
[15:25.080 --> 15:31.080]  который выполняет эти операции на удаленной машине. И он в RPC называется сервисом. И вам нужно
[15:31.080 --> 15:37.080]  какое-то локальное представление этого удаленного сервиса. Он называется, это локальное представление,
[15:37.080 --> 15:45.080]  такой объект называется стап. И вот у клиента есть стап, а у другой машины, которая находится
[15:45.080 --> 15:54.080]  далеко от вас, есть сервис. И стапы сервиса они реализуют, конечно же, один вот тот же интерфейс.
[15:54.080 --> 16:05.080]  Умеет умножать и складывать. Ну а дальше вопрос, как это все сделать?
[16:05.080 --> 16:18.080]  Да. Вот стап – это такое локальное представление для удаленного сервиса.
[16:18.080 --> 16:30.080]  В чем смысл этого стаба? Что он нам дает? Ну вот он нам дает такую иллюзию, что мы работаем с
[16:30.080 --> 16:36.080]  локальным объектом, как будто бы. Мы не думаем ничего про сеть здесь. Мы буквально вызываем метод
[16:36.080 --> 16:45.080]  на объекте, передаем туда аргументы. Какими сущностями мы на этом уровне оперируем? У нас есть
[16:45.080 --> 16:51.080]  стап сервис, это такие вот концы этой всей конструкции. У нас стап, с другой стороны сервис.
[16:51.080 --> 16:59.080]  И там есть методы, там есть типизированные аргументы, там есть результат. Вот так мы о этом говорим.
[16:59.080 --> 17:11.080]  Ненадолго мы были на проекторе, теперь возвращаемся к доске. Итак, вот есть клиент,
[17:11.080 --> 17:28.080]  и есть с другой стороны сервер. И что делает клиент? Клиент вызывает метод на стабе.
[17:41.080 --> 17:53.080]  И с другой стороны, где-то спустя какое-то время, на каком-то сервисе конкретном, вызывается этот же метод foo.
[17:53.080 --> 18:11.080]  Это два вот крайних уровня этой конструкции. Заметим, что, наверное, у нас же машина,
[18:11.080 --> 18:18.080]  удаленная, допустим, даже может быть не одна, но так или иначе она хочет готово эти запросы
[18:18.080 --> 18:26.080]  обслуживать конкурентно, и мы тоже готовы на этом стабе функцизовать конкурентно из разных потоков.
[18:26.080 --> 18:37.080]  И ничего этого в стабе и в сервисе в этих понятиях нет. Этот уровень про это не думает.
[18:37.080 --> 18:43.080]  Как бы мы могли сделать этот удаленный вызов? В конце концов, мы не можем сделать это сразу.
[18:43.080 --> 18:53.080]  У нас между клиентом и сервером есть сеть.
[18:53.080 --> 19:07.080]  И единственный способ, по которому этот вызов может удаленно состояться, единственный способ это сделать – это отправить сообщение.
[19:07.080 --> 19:23.080]  Давайте я аккуратно нарисую сейчас заготовку себе на будущее.
[19:23.080 --> 19:35.080]  Вот посередине находится сеть. И все, что вы можете делать здесь – это отправлять в одну сторону сообщения и в обратную сторону сообщения.
[19:35.080 --> 19:50.080]  При этом никакой семантики у этого уровня нет. Это уровень, который называется транспорт.
[19:50.080 --> 19:56.080]  И вот любой фреймворк для RPC без слоя транспорта, без этого уровня представить себе невозможно.
[19:56.080 --> 20:02.080]  Это в конце концов единственный способ, через который происходит вся коммуникация между клиентами и серверами.
[20:02.080 --> 20:14.080]  Этот уровень работает не с методами. Вот здесь есть методы, здесь есть аргументы, здесь есть типы.
[20:14.080 --> 20:22.080]  Вот на уровне транспорта ничего этого нет. На уровне транспорта есть просто сообщение.
[20:22.080 --> 20:27.080]  Не типизированные, просто строчки byte, про которые мы ничего не понимаем.
[20:27.080 --> 20:33.080]  Если мы говорим про RPC framework, то в нем обязательно должен быть уровень транспорта.
[20:33.080 --> 20:38.080]  Этот транспорт работает с сообщениями, в смысле не типизированными строчками byte.
[20:38.080 --> 20:43.080]  И транспорт про эти строчки ничего не понимает, какие там сообщения внутри уложены.
[20:43.080 --> 20:50.080]  Транспорт дает вам два механизма – для клиента и для сервера.
[20:50.080 --> 20:54.080]  Клиент вызывает Connect и передает некоторый адрес.
[20:54.080 --> 20:57.080]  Сервер вызывает Surf и слушает на каком-то порту.
[20:57.080 --> 21:05.080]  Это даже не какие-то конкретные адреса, и порт – это не число, потому что как именно реализован транспорт совершенно неважно.
[21:05.080 --> 21:15.080]  Важно, что он не знает, как устроены адреса. Они могут быть устроены произвольным образом, в зависимости от того, как этот интерфейс реализуется.
[21:15.080 --> 21:23.080]  Когда вы коннектитесь к серверу на стороне клиента, то вы получаете себе, во-первых, socket, в который можно асинхронно отправлять сообщения.
[21:23.080 --> 21:33.080]  А кроме того, вы в Connect регистрируете обработчик, чтобы реагировать на сообщения, которые прилетают вам по обратную сторону.
[21:33.080 --> 21:53.080]  Со стороны сервера происходит примерно то же самое. Вы указываете порт и регистрируете обработчик, через который будут вызываться вызовы HandleMessage и HandleConnect.
[21:53.080 --> 21:56.080]  HandleMessage – это обработчик, который вызывается при доставке сообщения.
[21:56.080 --> 22:00.080]  И вот вы получаете себе socket для того, чтобы можно было ответить.
[22:00.080 --> 22:07.080]  И вызов HandleDisconnect для того, чтобы узнать, что соединение порвано.
[22:07.080 --> 22:10.080]  То есть здесь мы предполагаем, что есть какая-то абстракция соединения.
[22:10.080 --> 22:16.080]  И вот этот уровень, он и отвечает на вопрос нам, какие гарантии мы ожидаем от сети.
[22:16.080 --> 22:22.080]  Мы никакие серьезные гарантии не ожидаем. Мы ожидаем, что мы можем отправить сообщения в сеть.
[22:22.080 --> 22:32.080]  И оно будет либо доставлено Eventually, либо на нашем обработчике, который мы зарегистрировали в Connect, будет вызван Callback HandleDisconnect.
[22:32.080 --> 22:40.080]  И тогда мы всякие ожидания относительно доставки должны потерять для всех сообщений, для которых мы уже сделали send.
[22:40.080 --> 22:45.080]  Так что вы как бы в теории, когда вам говорят, что сообщение будет доставлено, это ничего не значит, конечно, потому что может быть Disconnect.
[22:45.080 --> 22:53.080]  И тогда вы уже ничего не понимаете про состояние этого соединения.
[22:53.080 --> 22:59.080]  Здесь вот между этим уровнем, где есть стабы и сервисы, и типы, и аргументы,
[22:59.080 --> 23:08.080]  и уровнем, где у нас есть транспорт таких вот не типизированных сообщений, должен быть еще какой-то слой.
[23:08.080 --> 23:12.080]  Понимаем ли мы, как он должен быть устроен? Какую задачу он должен решать?
[23:12.080 --> 23:16.080]  Вот этот слой транспорта он решает задачу доставки сообщений.
[23:22.080 --> 23:31.080]  Нет, не сериализация. Но сериализация, конечно же, чтобы спуститься от уровня стаб до уровня транспорта
[23:31.080 --> 23:38.080]  или подняться на стороне сервера от уровня транспорта к уровню сервиса, нужно уже иметь типы, нужно восстановить эти типы.
[23:38.080 --> 23:43.080]  Поэтому нам, да, само собой, нам нужно решать задачу, которая называется задача сериализации и десериализации.
[23:43.080 --> 23:49.080]  То есть как трансформировать объект в нашем любимом языке в строчку из Byte.
[23:49.080 --> 23:54.080]  А потом как ее в обратную сторону восстановить. Это одна задача.
[23:54.080 --> 23:59.080]  Но да, она решается и даже нужно дважды применять.
[23:59.080 --> 24:05.080]  Но вот между понятием стаба и транспортом есть некоторый зазор.
[24:05.080 --> 24:12.080]  Вот что в этом зазоре находится?
[24:12.080 --> 24:21.080]  Мне кажется, что вы знаете, что находится, потому что если вы были в сознании, когда вы писали первую домашнюю работу, вы вряд ли забыли.
[24:21.080 --> 24:28.080]  Смотри, мы...
[24:28.080 --> 24:33.080]  Смотри, мы...
[24:33.080 --> 24:40.080]  Цикловайл не может в архитектуре находиться.
[24:40.080 --> 24:47.080]  Ну нет, так не получается, значит нужно на картинку возвращаться.
[24:48.080 --> 24:57.080]  Я надеялся этого избежать, но мы будем страдать.
[24:57.080 --> 25:02.080]  Вот смотрите, на этом уровне у нас есть вызов.
[25:02.080 --> 25:05.080]  Вызов функции на некотором сервисе.
[25:05.080 --> 25:08.080]  Сколько этих сервисов может быть здесь?
[25:08.080 --> 25:10.080]  Ну вообще говоря, сколько угодно.
[25:10.080 --> 25:13.080]  У нас больше два сервиса. Каждая реплика сочетает все два поведения.
[25:13.080 --> 25:16.080]  И координатор, и каждый узел.
[25:16.080 --> 25:19.080]  И реплик, и координатор.
[25:19.080 --> 25:24.080]  И вот мы вызываем на конкретном сервисе конкретный метод.
[25:24.080 --> 25:27.080]  И с другой стороны, он должен вызваться.
[25:27.080 --> 25:29.080]  И мы получаем ответ.
[25:29.080 --> 25:36.080]  А с другой стороны, на уровне транспорта у нас типов нет.
[25:36.080 --> 25:38.080]  Мы это уже выяснили.
[25:38.080 --> 25:43.080]  А еще и семантики запроса ответа тоже нет.
[25:43.080 --> 25:44.080]  У нас есть просто сообщение.
[25:44.080 --> 25:48.080]  Мы вот здесь умеем сказать send, и сообщение улетает в сеть.
[25:48.080 --> 25:52.080]  А потом, если вдруг к нам прилетает другое сообщение,
[25:52.080 --> 25:54.080]  то у нас вызывается обработчик, candle message.
[25:54.080 --> 25:56.080]  Этот месседж относится к чему угодно.
[25:56.080 --> 25:59.080]  Может быть, вы сделали три вызова, и вот вы отправили один реквест,
[25:59.080 --> 26:04.080]  и получили респонс на какой-то другой вызов, который вы сделали ранее.
[26:04.080 --> 26:06.080]  Вот связи между ними на уровне транспорта никакой нет.
[26:06.080 --> 26:08.080]  Эта абстракция максимально простая.
[26:08.080 --> 26:11.080]  Она занимается доставкой сообщений.
[26:11.080 --> 26:14.080]  Она не знает про семантику, про типы сообщения.
[26:14.080 --> 26:17.080]  Она не знает про то, что есть какие-то вызовы, есть понятия клиента,
[26:17.080 --> 26:22.080]  и вот этого колера и коле.
[26:29.080 --> 26:32.080]  У нас это в первой домашней работе называлось каналами.
[26:32.080 --> 26:34.080]  Вот здесь был канал.
[26:36.080 --> 26:43.080]  А здесь симметричная ему сущность называется RPC-сервер.
[26:43.080 --> 26:49.080]  Вот и давайте подумаем, зачем и то, и другое нужно.
[26:49.080 --> 26:51.080]  А заодно, где мой хороший черный маркер?
[26:51.080 --> 26:53.080]  Вот он.
[26:53.080 --> 26:56.080]  Вот как распределены обязанности между всем этим?
[26:56.080 --> 27:01.080]  Здесь есть стаб, здесь есть канал, а ниже этого находится socket.
[27:02.080 --> 27:06.080]  Ну, транспортный socket и некоторый интерфейс.
[27:09.080 --> 27:14.080]  А здесь уровень транспорта представлен в виде I-сервера.
[27:14.080 --> 27:23.080]  Над ним находится RPC-сервер, а над ним в обратную сторону находится уже конкретный сервис.
[27:23.080 --> 27:27.080]  Вот понимаете ли вы, как в этой конструкции распределены обязанности?
[27:27.080 --> 27:29.080]  Вот я предлагал ключевые слова писать.
[27:29.080 --> 27:32.080]  Вот здесь есть методы, аргументы, типы.
[27:32.080 --> 27:35.080]  Здесь есть просто сообщения.
[27:35.080 --> 27:38.080]  Асинхронные сообщения при чем?
[27:38.080 --> 27:44.080]  А вот какие ключевые слова, какие buzzword я должен написать здесь?
[27:44.080 --> 27:47.080]  Это хорошее, на самом деле, замечание.
[27:47.080 --> 27:52.080]  Вот здесь у нас есть один объект, и мы его называем методом.
[27:52.080 --> 27:58.080]  Но очевидно, нужна какая-то синхронизация, если мы конкурентно это все делаем.
[27:58.080 --> 28:04.080]  Здесь нужна просто конкарнсия какая-то, то есть в том или ином виде.
[28:04.080 --> 28:08.080]  Когда мы делаем запрос, хотим ли мы дождаться его синхронно,
[28:08.080 --> 28:14.080]  или мы хотим получить какое-то будущее представление для результата этого запроса, фьючу?
[28:14.080 --> 28:17.080]  Вот мы вроде бы решили, что мы хотим всегда получить фьючу,
[28:17.080 --> 28:19.080]  потому что фьючу всегда можно дождаться синхронно,
[28:19.080 --> 28:24.080]  но если мы захотим, мы можем из них комбинатором какую-то другую фьючу сплепить для ожидания.
[28:24.080 --> 28:29.080]  Вот конкарнсия с этой стороны, это фьюча.
[28:29.080 --> 28:31.080]  Ну плюс что еще?
[28:31.080 --> 28:37.080]  Плюс овей для того, чтобы ее дождаться можно было синхронно.
[28:37.080 --> 28:40.080]  А с этой стороны конкарнсия в каком виде реализуется?
[28:40.080 --> 28:43.080]  В каком виде она появляется?
[28:43.080 --> 28:45.080]  Сейчас нет.
[28:45.080 --> 28:49.080]  Ну ты же писал канал.
[28:49.080 --> 28:53.080]  Промесс не работает по сети все же.
[28:53.080 --> 28:56.080]  Фьючу отдается пользователю, промесс остается внутри конструкции.
[28:56.080 --> 28:59.080]  Это всегда так. На всякий случай, еще маленькая мораль с весны.
[28:59.080 --> 29:02.080]  Промессы в коде пользователей не торчат нигде.
[29:02.080 --> 29:07.080]  Промессы всегда скрыты, фьючи торчат наружу.
[29:07.080 --> 29:10.080]  Конкарнсия появляется здесь на уровне интерфейсов.
[29:10.080 --> 29:13.080]  А что происходит вот здесь, симметрично с другой стороны?
[29:21.080 --> 29:24.080]  Конечно есть. У нас есть сервер, машинка.
[29:24.080 --> 29:27.080]  На ней есть сервисы.
[29:27.080 --> 29:30.080]  Есть много клиентов, которые вызывают вызовы на них.
[29:30.080 --> 29:33.080]  Конечно же, мы не хотим обслуживать клиентов по одному.
[29:33.080 --> 29:40.080]  Нам нужны конкурентные обработчики.
[29:40.080 --> 29:49.080]  Для этого нужен какой-то предпул, в котором запускаются файберы обработчики.
[29:49.080 --> 29:53.080]  Мы говорили, что в RPC каждый обработчик, который запускается,
[29:53.080 --> 29:56.080]  если он будет файбером, то это будет удобно,
[29:56.080 --> 29:59.080]  потому что файбер может заснуть и собрать квором, дождаться его.
[29:59.080 --> 30:03.080]  Эти обработчики, конечно же, должны обслуживать запросы к системе
[30:03.080 --> 30:06.080]  конкурентно и по возможности параллельно.
[30:06.080 --> 30:09.080]  Поэтому нам нужен какой-то инструмент для этой параллельности и конкурентности.
[30:09.080 --> 30:13.080]  У нас это файберы, трэдпулы и вся эта конструкция, которую мы изучали.
[30:13.080 --> 30:16.080]  Это симметричная сторона.
[30:16.080 --> 30:18.080]  Вот здесь есть конкарнсия.
[30:18.080 --> 30:21.080]  А какую еще задачу решает этот канал и RPC-сервер?
[30:25.080 --> 30:28.080]  Какие слова еще были мне сказаны в самом начале?
[30:28.080 --> 30:31.080]  И на которых не нарисованы на картинке.
[30:37.080 --> 30:41.080]  Вот здесь еще появляется понятие request-response.
[30:46.080 --> 30:49.080]  Но вот именно здесь эти сообщения,
[30:49.080 --> 30:52.080]  отправляемые через транспорт и доставляемые в обратную сторону,
[30:52.080 --> 30:54.080]  обретают такую семантику.
[30:55.080 --> 30:58.080]  Транспорт просто отправляет сообщения на узел.
[30:58.080 --> 31:01.080]  Он даже не знает, что это какой-то запрос для RPC.
[31:03.080 --> 31:05.080]  А чем занимается канал?
[31:05.080 --> 31:11.080]  Вот он, с одной стороны, получает от этого стаба какие-то уже вызовы,
[31:11.080 --> 31:14.080]  трансформирует их в сообщения, запросы.
[31:15.080 --> 31:20.080]  И когда он получает сообщения в обратную сторону, через ScandlerSocket,
[31:20.080 --> 31:27.080]  то канал понимает, к какому запросу это сообщение в обратную сторону относится.
[31:28.080 --> 31:31.080]  На какой запрос это сообщение отвечает?
[31:35.080 --> 31:37.080]  Этот уровень решает такие задачи.
[31:37.080 --> 31:41.080]  Этот уровень решает просто задачу транспорта синхронного сообщения.
[31:41.080 --> 31:45.080]  Этот уровень занимается сериализацией, типами, аргументами.
[31:46.080 --> 31:49.080]  Итак, вот уже выстроилась какая-то архитектура.
[31:49.080 --> 31:55.080]  Я утверждаю, что более-менее любой фрейморк RPC должен в себе содержать такие слои,
[31:55.080 --> 32:00.080]  потому что здесь просто границы между задачами проходят очень естественные.
[32:00.080 --> 32:05.080]  Когда мы переходим сюда, то какой интерфейс у этого канала?
[32:15.080 --> 32:28.080]  Вот этот месседж, который был в коле у канала, это была просто строчка.
[32:29.080 --> 32:33.080]  Вот канал уже не понимал, как именно, что он за запрос задает.
[32:33.080 --> 32:36.080]  Он получал себе некоторый дескриптор, то есть имя сервиса с другой стороны,
[32:36.080 --> 32:40.080]  имя метода, которого на него можно вызвать, и сериализованные аргументы.
[32:40.080 --> 32:44.080]  Что это за аргументы, мы не понимаем, типов уже здесь нет.
[32:44.080 --> 32:49.080]  А дальше мы отправляем через транспорт, упаковываем этот запрос в сообщение,
[32:49.080 --> 32:53.080]  оно прилетает с этой стороны, и вот уже здесь, когда мы переходим сюда,
[32:53.080 --> 32:56.080]  типы стираются, типы аргументов и типы значения.
[32:56.080 --> 32:59.080]  Этот слой ни про то, ни про другое не знает.
[32:59.080 --> 33:03.080]  И когда нам возвращается ответ из этого канала, он нам возвращает фьюч, но фьюч у чего?
[33:03.080 --> 33:05.080]  Фьюч, это называлось там месседж.
[33:05.080 --> 33:07.080]  То есть просто строчка.
[33:07.080 --> 33:10.080]  На входе строчка, на выходе строчка.
[33:10.080 --> 33:13.080]  Как ее интерпретировать, пусть об этом думает стаб.
[33:13.080 --> 33:15.080]  И то же самое здесь.
[33:15.080 --> 33:19.080]  Это сообщение прилетает сюда, RPC Server понимает, что это запрос
[33:19.080 --> 33:24.080]  к какому-то методу какого-то объекта, к какому-то методу какого-то сервиса,
[33:24.080 --> 33:31.080]  и вызывает на нем метод, но при этом как именно интерпретировать аргументы,
[33:31.080 --> 33:35.080]  каких они типов, сам Server не знает, это не его проблема.
[33:35.080 --> 33:37.080]  Она решается вот на этом уровне.
[33:37.080 --> 33:41.080]  То есть здесь мы сериализуем, здесь мы десериализуем.
[33:43.080 --> 33:51.080]  Но на самом деле сериализуем мы дважды.
[33:51.080 --> 33:53.080]  Понятно ли почему?
[33:53.080 --> 33:59.080]  Ну, с одной стороны, мы сериализуем аргументы.
[33:59.080 --> 34:08.080]  Но дальше нам же нужно, при переходе отсюда-сюда, у нас здесь есть логический реквест,
[34:08.080 --> 34:12.080]  а на этом уровне есть просто строчка byte сообщения.
[34:12.080 --> 34:17.080]  Вот нужно же, чтобы с другой стороны эту строчку byte прочитали и интерпретировали,
[34:17.080 --> 34:20.080]  что это запрос к какому-то методу какого-то сервиса.
[34:20.080 --> 34:25.080]  Так что вот здесь задача сериализации решается еще раз.
[34:25.080 --> 34:38.080]  Но уже если здесь мы сериализовали аргументы, то здесь мы сериализуем сам запрос.
[34:38.080 --> 34:43.080]  То есть структуру, где есть поля, какой сервис нужно выдать,
[34:43.080 --> 34:46.080]  какой аргумент нужно выдать с какими аргументами.
[34:46.080 --> 34:48.080]  Это все улетает на другую сторону.
[34:48.080 --> 34:52.080]  И здесь сначала срабатывает обработчик сообщения я.
[34:52.080 --> 35:01.080]  Это сообщение десериализуется в структуру response.
[35:01.080 --> 35:06.080]  Из этого response извлекается, какой именно метод какого сервиса нужно вызвать.
[35:06.080 --> 35:11.080]  Ну что, слои понятны?
[35:11.080 --> 35:17.080]  Вот здесь типы сериализации, здесь concurrency и request-response,
[35:17.080 --> 35:20.080]  здесь просто доставка сообщений.
[35:20.080 --> 35:24.080]  Вот границы очень четкие, ну и теперь можно показать,
[35:24.080 --> 35:29.080]  как это все матчится в конкретный код, чтобы вас ничего не удивляло.
[35:30.080 --> 35:34.080]  Итак, есть транспорт.
[35:34.080 --> 35:37.080]  И здесь интерфейс максимально простой,
[35:37.080 --> 35:40.080]  и он должен быть настолько простой, чтобы его можно было реализовать
[35:40.080 --> 35:43.080]  более-менее для любого протокола под капотом,
[35:43.080 --> 35:47.080]  можно было бы использовать HTTP, можно использовать TCP.
[35:47.080 --> 35:53.080]  И при этом, поверх этого всего, можно было бы реализовать вот эту смантинскую RPC.
[35:53.080 --> 35:57.080]  Почему еще удобно транспорт абстрагировать?
[35:57.080 --> 35:59.080]  Понятно ли это?
[35:59.080 --> 36:03.080]  То есть, почему здесь не написано конкретно TCP, а почему здесь написан интерфейс?
[36:03.080 --> 36:09.080]  Потому что, по крайней мере, тесты удобно писать.
[36:09.080 --> 36:13.080]  Вы тестируете свой фреймворк, там, где есть реализация, там, где есть concurrency,
[36:13.080 --> 36:18.080]  и удобно подставить реализацию, которая по сети вообще ничего не отправляет.
[36:18.080 --> 36:22.080]  Собственно, в примерах к фреймворку здесь реализован транспорт,
[36:22.080 --> 36:25.080]  который реализует как будто бы локальную доставку сообщений,
[36:25.080 --> 36:31.080]  просто хранит очередь пакетов и доставляет их, эмулирует TCP в какой-то степени.
[36:31.080 --> 36:37.080]  Ну и если вы захотите сделать что-то более разумное, чем эмуляцию на одной машине,
[36:37.080 --> 36:42.080]  вы можете подставить какой-то произвольный фреймворк, который реализует синхронную отправку.
[36:42.080 --> 36:44.080]  Например, есть 0MQ.
[36:44.080 --> 36:48.080]  Ну и вот для C++ там тоже есть реализация, причем, кажется, даже не одна.
[36:53.080 --> 36:56.080]  Ну вот видите, обилие языков, которые поддерживает.
[36:56.080 --> 36:59.080]  Про языки мы сейчас поговорим еще.
[36:59.080 --> 37:01.080]  Что?
[37:01.080 --> 37:05.080]  Здорово. Я рад, что ты что-то помнишь.
[37:05.080 --> 37:06.080]  Хорошо.
[37:06.080 --> 37:10.080]  Вот над этим уровнем находится уровень канала.
[37:10.080 --> 37:12.080]  Это уже уровень RPC.
[37:12.080 --> 37:15.080]  И здесь мы имеем такой интерфейс, мы вызываем метод.
[37:15.080 --> 37:18.080]  Метод – это приобретение канала.
[37:18.080 --> 37:21.080]  И вот здесь у нас есть репрессор.
[37:21.080 --> 37:24.080]  И вот здесь у нас есть репрессор.
[37:24.080 --> 37:27.080]  И вот здесь у нас есть репрессор.
[37:27.080 --> 37:30.080]  И здесь мы имеем такой интерфейс, мы вызываем метод.
[37:30.080 --> 37:35.080]  Метод – это пара из имени сервиса и имени метода.
[37:35.080 --> 37:37.080]  И мы передадим туда сообщение.
[37:37.080 --> 37:40.080]  Сообщение – это просто строчка byte.
[37:40.080 --> 37:43.080]  И поверх этого всего, да, мы возвращаем фьюч,
[37:43.080 --> 37:50.080]  потому что мы хотим, чтобы мы могли вызывать дожидаться либо синхронно, либо асинхронно.
[37:50.080 --> 37:55.080]  И канал – это то место, где будет реализована какая-то конкарнсия.
[37:55.080 --> 38:02.080]  Потому что когда вы вызываете методы через стаб, вот здесь вот,
[38:02.080 --> 38:05.080]  ну здесь в примере это делается в один поток,
[38:05.080 --> 38:11.080]  вы могли бы делать это параллельно из разных потоков, из разных файберов на своем узле.
[38:11.080 --> 38:15.080]  И, конечно же, канал должен как-то эти запросы сервализовать,
[38:15.080 --> 38:18.080]  ну и отправлять их в сети, отправлять их в транспорт.
[38:18.080 --> 38:24.080]  То есть канал трансформирует вот это все, вот эти аргументы в какие-то сообщения.
[38:24.080 --> 38:28.080]  И я сказал, что вот эти сообщения должны как-то получаться.
[38:28.080 --> 38:30.080]  Сейчас, это не туда.
[38:30.080 --> 38:35.080]  Вот такие вот сообщения, которые просто строчки.
[38:38.080 --> 38:42.080]  Как из вот такой сигнатуры получить строчку?
[38:42.080 --> 38:45.080]  Из такой сигнатуры получить строчку?
[38:45.080 --> 38:48.080]  Ну, нужно какое-то представление объекта Request.
[38:48.080 --> 38:52.080]  И вот есть объект Request, и он умеет сервализоваться.
[38:52.080 --> 38:58.080]  Вот когда мы вызываем Call, то, видимо, канал эти свои аргументы Call трансформирует в такой Request,
[38:58.080 --> 39:01.080]  сервализует его и отправляет в сеть.
[39:01.080 --> 39:03.080]  Вот можно что-то поискать про это.
[39:06.080 --> 39:09.080]  Ну вот, у нас есть Request.
[39:14.080 --> 39:16.080]  Вот, мы...
[39:18.080 --> 39:20.080]  Сейчас...
[39:20.080 --> 39:22.080]  Сейчас...
[39:26.080 --> 39:29.080]  Мы конструируем такую вот структуру,
[39:29.080 --> 39:33.080]  сервализуем ее в поток Byte и бросаем в сеть.
[39:33.080 --> 39:38.080]  Она улетает, и с другой стороны, на RPC-сервере
[39:38.080 --> 39:41.080]  вызывается обработчик HandleMessage.
[39:41.080 --> 39:46.080]  Этот обработчик HandleMessage, ну, этот message, который мы получили транспортного уровня,
[39:51.080 --> 39:56.080]  на нем вызывается deserialize, и мы этот Request парсим.
[39:56.080 --> 40:00.080]  Получаем у себя на другой стороне вот этот самый объект.
[40:00.080 --> 40:02.080]  Вот здесь...
[40:02.080 --> 40:05.080]  Ну, здесь аргументы вызова по-прежнему сервализованы.
[40:05.080 --> 40:09.080]  То есть мы в сервализованном сообщении храним сервализованное сообщение.
[40:09.080 --> 40:16.080]  Ну, потому что вот это сообщение с аргументами будет десервализовано на уровне выше, получается, над нами.
[40:16.080 --> 40:23.080]  А дальше мы с помощью этого реквеста понимаем, какому сервису он относится, находим этот сервис,
[40:25.080 --> 40:30.080]  и на нем вызываем метод с нужными аргументами.
[40:30.080 --> 40:36.080]  Но, опять же, мы на уровне сервера не понимаем, как эти аргументы интерпретировать.
[40:37.080 --> 40:40.080]  Для нас на нашем уровне это пока строчка Byte.
[40:40.080 --> 40:45.080]  Видимо, интерпретация аргументов будет заниматься реализацией вот этого I-сервиса.
[40:46.080 --> 40:49.080]  Ну, и я уже сказал, что RPC-сервер – это место, где появляется конкуренция,
[40:49.080 --> 40:52.080]  где появляется конкурентная обработка запросов.
[40:52.080 --> 40:53.080]  Ну, и вот тут, смотрите, что написано.
[40:53.080 --> 41:00.080]  Когда у нас на сервере дергается обработчик сообщения, то мы стартуем новый файбер.
[41:01.080 --> 41:04.080]  И в нем выполняем функцию процесс-реквест.
[41:08.080 --> 41:14.080]  Откуда же берется вот этот самый интерфейс, реализация интерфейса сервис?
[41:14.080 --> 41:19.080]  Ну, мы ее пишем сами. Вот здесь вот.
[41:19.080 --> 41:25.080]  Вот мы написали этот сервис и унаследовали его от специального класса ServiceBase.
[41:25.080 --> 41:27.080]  Зачем мы так сделали?
[41:27.080 --> 41:33.080]  Ну, потому что этот ServiceBase позволяет нам регистрировать обработчики с конкретными типами
[41:33.080 --> 41:35.080]  с помощью вот такого макросса.
[41:35.080 --> 41:41.080]  А этот макросс вызывает мне RegisterMethod, где мы получаем поинтерна функцию,
[41:41.080 --> 41:49.080]  ну, во-первых, мы наследуемся, конечно же, от iService, и мы реализуем Invoke.
[41:49.080 --> 41:55.080]  Каким образом? Мы находим Invoker в нашем мэйпе со списком методов,
[41:55.080 --> 41:57.080]  со снабором методов, и его вызываем.
[41:57.080 --> 42:03.080]  А этот Invoker, он строится с помощью этого макросса, с помощью вызова RegisterMethod.
[42:03.080 --> 42:08.080]  Там мы знаем типы, и там мы можем построить вот такой макросс.
[42:08.080 --> 42:17.080]  Который, получив строчку и зная свои настоящие аргументы, может ее десерилизовать,
[42:17.080 --> 42:21.080]  вызвать функцию с этими аргументами, и потом сервизовать ответ обратно.
[42:21.080 --> 42:27.080]  В итоге типы на уровне сервиса возникают только вот в этом маленьком месте.
[42:27.080 --> 42:33.080]  А сам RPC Server работает с этим сервисом,
[42:33.080 --> 42:39.080]  передавая строчки и возвращая строчки, и получает в него обратные строчки.
[42:39.080 --> 42:43.080]  Понятно?
[42:43.080 --> 42:53.080]  Стап делает симметричные вещи. Если мы говорим про стап, то в примере вот в этом.
[42:53.080 --> 42:59.080]  Когда мы вызываем Multiply, то мы вызываем RPC Call,
[42:59.080 --> 43:04.080]  передаем туда канал, через который... Стап вообще строится по каналу,
[43:04.080 --> 43:07.080]  который, собственно, и умеет отправлять сообщения.
[43:07.080 --> 43:13.080]  И мы сначала говорим Call, Arcs, и вот здесь происходит сервизация.
[43:13.080 --> 43:18.080]  А дальше мы уже говорим Via Channel, Start, и в этом Start мы уже говорим,
[43:19.080 --> 43:25.080]  а дальше мы уже говорим Via Channel, Start, и в этом Start вызывается как раз Call на канале.
[43:25.080 --> 43:29.080]  У нас уже есть описание метода, у нас уже есть сервизованный вход,
[43:29.080 --> 43:35.080]  и канал занимается тем, что трансформирует этот запрос в какое-то сообщение для socket.
[43:35.080 --> 43:43.080]  Я уже показывал. Вот здесь.
[43:43.080 --> 43:47.080]  Но, я уже сказал, канал реализует конкуренцию на стороне клиента.
[43:47.080 --> 43:52.080]  А конкуренция на стороне клиента в двух проявлениях существует.
[43:52.080 --> 43:59.080]  Во-первых, в канале вызываются Call-ы конкурентно, из разных потоков потенциально.
[43:59.080 --> 44:05.080]  Потому что у вас стабов может быть много, вызовов может быть много конкурентных,
[44:05.080 --> 44:09.080]  а канал, через который вы делаете эти вызовы, он один.
[44:09.080 --> 44:15.080]  И вот на нем конкурентно зовутся Call-ы, их нужно как-то упорядочивать.
[44:15.080 --> 44:20.080]  Кроме того, он вниз на транспорт спускает сообщение,
[44:20.080 --> 44:26.080]  и обратно же к нему поднимаются обработчики HandleMessage и HandleDisconnect.
[44:26.080 --> 44:34.080]  То есть конкретный канал является с одной стороны, реализует интерфейс Channel,
[44:34.080 --> 44:36.080]  и позволяет сверху развивать Call-ы,
[44:36.080 --> 44:40.080]  а с другой стороны, он реагирует на обработчики снизу.
[44:40.080 --> 44:43.080]  Он Handler транспорта.
[44:43.080 --> 44:47.080]  И к нему конкурентно приходят разные события.
[44:47.080 --> 44:52.080]  С одной стороны вызывы, а с другой стороны сообщения из сети.
[44:52.080 --> 44:54.080]  И возникает следующая задача.
[44:54.080 --> 44:57.080]  А как этот канал написать?
[44:57.080 --> 45:04.080]  Потому что на нем зовутся конкурентно очень разные действия, очень разные обработчики.
[45:04.080 --> 45:07.080]  Call-ы, HandleMessage, HandleDisconnect.
[45:07.080 --> 45:10.080]  Из разных потоков, без синхронизации.
[45:10.080 --> 45:13.080]  Что делать к каналу, если он хочет оставаться простым?
[45:16.080 --> 45:18.080]  Что?
[45:18.080 --> 45:22.080]  Ему нужно использовать Strand.
[45:22.080 --> 45:27.080]  То есть все обработчики, которые в нем запускаются, в нем запускаются через Strand.
[45:27.080 --> 45:30.080]  Это не единственное.
[45:30.080 --> 45:33.080]  Для такой задачи Strand и нужен.
[45:33.080 --> 45:36.080]  У нас есть пул потоков, допустим.
[45:36.080 --> 45:38.080]  В нем четыре потока.
[45:38.080 --> 45:42.080]  И у нас есть очень много каналов в разные машины.
[45:42.080 --> 45:44.080]  И выполнится очень много вызовов.
[45:44.080 --> 45:47.080]  И нужно много обработчиков для многих каналов,
[45:47.080 --> 45:50.080]  чтобы эффективно упаковывать маленькое количество потоков.
[45:50.080 --> 45:54.080]  И при этом, чтобы каждый канал работал просто однопоточно.
[45:54.080 --> 45:58.080]  Ну вот давайте все операции над одним каналом упорядочим через Strand.
[45:58.080 --> 46:02.080]  А все эти Strand-ы будут декорировать один и тот же threadpool.
[46:02.080 --> 46:05.080]  Как мы уже знаем, с вами с прошлого семестра,
[46:05.080 --> 46:09.080]  поверх одного threadpool-а Strand-ов может быть сколько угодно.
[46:09.080 --> 46:13.080]  Так что, когда вызывается обработчик HandleMessage,
[46:13.080 --> 46:17.080]  то этот обработчик на самом деле кладется в Strand.
[46:17.080 --> 46:19.080]  Когда вызывается HandleDisconnect, тоже в Strand.
[46:19.080 --> 46:21.080]  Когда мы говорим Call,
[46:21.080 --> 46:25.080]  то мы строим request и снова его бросаем в Strand.
[46:25.080 --> 46:30.080]  И в итоге все операции, которые меняют состояние канала,
[46:30.080 --> 46:32.080]  а оно не очень-то простое.
[46:32.080 --> 46:35.080]  Ну это не очень-то и сложно, но с другой стороны.
[46:35.080 --> 46:39.080]  Вот все обработчики, которые меняют его состояние, они упорядочены.
[46:39.080 --> 46:42.080]  А состояние канала – это вот мэпа
[46:42.080 --> 46:46.080]  из requestId в структуру реквеста.
[46:46.080 --> 46:51.080]  Канал занимается тем, что он мачит request и response.
[46:51.080 --> 46:56.080]  Когда к нам из сети прилетает сообщение,
[46:56.080 --> 46:59.080]  мы знаем, что это response.
[46:59.080 --> 47:03.080]  Декодируем его вот такую структуру.
[47:03.080 --> 47:06.080]  И по requestId, которую мы там нашли,
[47:06.080 --> 47:08.080]  ищем запрос в мэпе.
[47:08.080 --> 47:10.080]  Находим его.
[47:10.080 --> 47:16.080]  И если находим, то говорим на промесе этого запроса setValue.
[47:18.080 --> 47:21.080]  И отдаем туда строчку, которая прилетела с другой стороны.
[47:21.080 --> 47:26.080]  А эта строчка интерпретируется снова на уровне выше, на уровне стаба.
[47:26.080 --> 47:28.080]  Вот здесь вот.
[47:31.080 --> 47:34.080]  То есть мы сначала по картинке, которая была под слайдом,
[47:34.080 --> 47:36.080]  проходимся в одну сторону вниз,
[47:36.080 --> 47:39.080]  а потом проходимся целиком в другую сторону наверх.
[47:39.080 --> 47:43.080]  И в одну сторону здесь реализуем, в другую сторону здесь реализуем.
[47:45.080 --> 47:48.080]  И конкарнси появляется здесь на уровне канала
[47:48.080 --> 47:50.080]  в виде интерфейсов с фьючами
[47:50.080 --> 47:54.080]  и в виде стренда, который реализует все операции над этим каналом,
[47:54.080 --> 47:56.080]  над его состоянием.
[47:56.080 --> 47:58.080]  А с другой стороны, конкарнси появляется в RPC-сервере
[47:58.080 --> 48:02.080]  в виде набора файберов, в которых запускаются обработчики.
[48:05.080 --> 48:07.080]  Хорошо.
[48:07.080 --> 48:11.080]  А теперь, я бы сказал, довольно общая структура любого RPC-фреймворка.
[48:11.080 --> 48:14.080]  В любом RPC-фреймворке должен быть слой транспорта,
[48:14.080 --> 48:17.080]  чтобы абстрагировать, как именно вы доставляете сообщение.
[48:17.080 --> 48:20.080]  В любом фреймворке RPC должна быть поддержка конкарнси.
[48:20.080 --> 48:24.080]  Вот RPC почти никогда не бывает без конкарнси.
[48:25.080 --> 48:28.080]  Если язык Go, почему он такой создан?
[48:28.080 --> 48:30.080]  Почему там конкарнси есть?
[48:30.080 --> 48:33.080]  Потому что он предназначен для того, чтобы выписать свои предложения.
[48:33.080 --> 48:35.080]  Через RPC, например.
[48:35.080 --> 48:37.080]  Конкарнси просто необходим.
[48:37.080 --> 48:39.080]  И он там сделан чрезвычайно разумно.
[48:39.080 --> 48:41.080]  Я, может быть, сегодня не успею что сказать,
[48:41.080 --> 48:45.080]  но, может быть, потом поговорю с кем-нибудь, кто захочет.
[48:45.080 --> 48:47.080]  Конкарнси необходимы,
[48:47.080 --> 48:49.080]  и если вы пишете на Go у вас на месте конкарнси,
[48:49.080 --> 48:51.080]  если вы используете какие-то фреймворки,
[48:51.080 --> 48:55.080]  ну вот Cup'n'Pro, сейчас я вам покажу, фреймворк.
[48:55.080 --> 48:59.080]  Вот вместе с ним в догон идет библиотека конкарнси.
[48:59.080 --> 49:01.080]  Потому что без нее все это,
[49:01.080 --> 49:05.080]  обработку запросов и вообще интерфейса представить невозможно.
[49:07.080 --> 49:09.080]  А я сейчас это объясню, это очень разумная вещь.
[49:09.080 --> 49:11.080]  Я как бы к этому клоню.
[49:11.080 --> 49:15.080]  И, кстати, в Cup'n'Pro-то сделано все очень классно.
[49:25.080 --> 49:27.080]  Там очень хитро сделано.
[49:27.080 --> 49:29.080]  Там future используются ленивые.
[49:29.080 --> 49:31.080]  Если вы немножко в последнем семестре делали,
[49:31.080 --> 49:35.080]  то вы знаете, что обычно, когда у вас future,
[49:35.080 --> 49:37.080]  то чтобы получить future,
[49:37.080 --> 49:39.080]  вы должны что-то отправить в другую сторону,
[49:39.080 --> 49:41.080]  какую-то операцию начать.
[49:41.080 --> 49:43.080]  А если у вас ленивые future,
[49:43.080 --> 49:45.080]  как в лекции про Unified Executor,
[49:45.080 --> 49:47.080]  то вы можете сначала выстроить pipeline,
[49:47.080 --> 49:49.080]  а потом его разумно запустить весь.
[49:49.080 --> 49:51.080]  Вот Cup'n'Pro-то он с помощью своих собственных future,
[49:51.080 --> 49:53.080]  которые на самом деле таски из прошлого семестра,
[49:53.080 --> 49:55.080]  реализует pipeline.
[49:55.080 --> 49:57.080]  То есть если вы делаете запрос к другой машине,
[49:57.080 --> 50:03.080]  то можно это все упаковать в такой конвейер и запустить разум.
[50:09.080 --> 50:11.080]  Ну вот такой интересный спецэффект.
[50:17.080 --> 50:21.080]  Итак, значит, есть слои транспорта, конкарнти и стап.
[50:21.080 --> 50:23.080]  Вот давайте сверху вниз поговорим,
[50:23.080 --> 50:25.080]  насколько это можно сделать универсально.
[50:25.080 --> 50:27.080]  У нас реализация очень простая.
[50:27.080 --> 50:29.080]  Мы для того, чтобы отправлять сообщения
[50:31.080 --> 50:33.080]  с какими-то аргументами,
[50:33.080 --> 50:35.080]  серилизуем их с помощью
[50:35.080 --> 50:37.080]  библиотеки серилизации,
[50:37.080 --> 50:39.080]  которая называется Serial.
[50:39.080 --> 50:41.080]  Это библиотека...
[50:41.080 --> 50:43.080]  Ну давайте откроем просто GitHub.
[50:49.080 --> 50:51.080]  Это библиотека, которая умеет
[50:51.080 --> 50:53.080]  серилизовать объекты на C++.
[50:53.080 --> 50:55.080]  Мы можем в каждом из них написать
[50:55.080 --> 50:57.080]  такой метод вспомогательный,
[50:57.080 --> 50:59.080]  в нем перечислить поля.
[50:59.080 --> 51:01.080]  Тут уже в канале писали про это,
[51:01.080 --> 51:03.080]  что это можно альтернативным образом делать рефлексии,
[51:03.080 --> 51:05.080]  compile-time-рефлексии
[51:05.080 --> 51:07.080]  или динамической рефлексии,
[51:07.080 --> 51:09.080]  что совсем неэффективно.
[51:09.080 --> 51:11.080]  В общем, это сейчас не важно.
[51:11.080 --> 51:13.080]  В C++ вы пишете это либо руками,
[51:13.080 --> 51:15.080]  либо вы пишете это в виде макроса,
[51:15.080 --> 51:17.080]  как мы делаем.
[51:17.080 --> 51:21.080]  Вот, например, задача номер один.
[51:23.080 --> 51:25.080]  Ну и дальше эта строчка может...
[51:25.080 --> 51:27.080]  В смысле, этот объект на C++
[51:27.080 --> 51:29.080]  трансформируется в строчку из Byte.
[51:29.080 --> 51:31.080]  Мы его передаем дальше через канал.
[51:33.080 --> 51:35.080]  В любом языке,
[51:35.080 --> 51:37.080]  ну как бы в экосистеме любого языка
[51:37.080 --> 51:39.080]  есть какой-то дефолтный способ
[51:39.080 --> 51:41.080]  серилизации часто.
[51:41.080 --> 51:43.080]  Ну он в Rust'е есть, есть в Python,
[51:43.080 --> 51:45.080]  знаете, в Pickle все, наверное.
[51:45.080 --> 51:47.080]  Зачем это нужно?
[51:47.080 --> 51:49.080]  Чтобы либо отправить объекты по сети,
[51:49.080 --> 51:51.080]  либо на диске их хранить.
[51:51.080 --> 51:53.080]  Значит, как-то решается.
[51:53.080 --> 51:55.080]  Но смотрите, какое дело.
[51:55.080 --> 51:57.080]  Возможно, мы бы хотели чуть более
[51:57.080 --> 51:59.080]  универсальный фреймворк иметь,
[51:59.080 --> 52:01.080]  который позволял бы нам вызывать методы,
[52:01.080 --> 52:03.080]  писать клиента, которые вызывают методы,
[52:03.080 --> 52:05.080]  и писать сервер, который реализует
[52:05.080 --> 52:07.080]  этот метод на разных языках.
[52:07.080 --> 52:09.080]  То есть мы бы хотели написать клиента
[52:09.080 --> 52:11.080]  на Python, а сервер с сервисом
[52:11.080 --> 52:13.080]  написать на C++.
[52:13.080 --> 52:15.080]  И вот здесь уже становится сложно,
[52:15.080 --> 52:17.080]  потому что...
[52:17.080 --> 52:19.080]  В чем преимущество фреймворка
[52:19.080 --> 52:21.080]  в библятике серилизации
[52:21.080 --> 52:23.080]  проток accordance с серилизацией для конкретного языка?
[52:23.080 --> 52:25.080]  В том что он может свободно
[52:25.080 --> 52:27.080]  серилизовать структуры данных
[52:27.080 --> 52:29.080]  из библиотеки вашей,
[52:29.080 --> 52:31.080]  из Вектор, Terry разllo и Wariant.
[52:31.080 --> 52:33.080] 可能 серилизовать таблы,
[52:33.080 --> 52:35.080]  все, что в вашем языке есть
[52:35.080 --> 52:37.080]  в библиотеке стандартной,
[52:37.080 --> 52:39.080]  можно серилизовать.
[52:39.080 --> 52:41.080]  Но очень сложно серилизовать wariant,
[52:41.080 --> 52:43.080]  а с другой стороны, на другом языке,
[52:43.080 --> 52:45.080]  где этого wariant нет, его серилизовать.
[52:45.080 --> 52:47.080]  И с одной стороны,
[52:47.080 --> 52:52.840]  универсальность. И если вы хотите способ сервизации кроссплатформенной, то вы должны
[52:52.840 --> 52:59.280]  сильно ограничить множество типов, которые вы поддерживаете. Это во-первых. А во-вторых, вы
[52:59.280 --> 53:04.720]  должны иметь какой-то универсальный способ, независящий от языка, эти типы, которые вы
[53:04.720 --> 53:10.760]  сервизуете, описывать. То есть сами объекты описывать. И вот так мы приходим к альтернативному
[53:10.760 --> 53:19.680]  универсальному механизму, который называется протобав. Знаете ли вы про него?
[53:19.680 --> 53:30.040]  У нас в RPC framework есть ветка, и мы вряд ли на нее перейдем в этом семестре, но могли бы.
[53:30.040 --> 53:39.400]  Там смотрите. Во-первых, у нас есть калькулятор, и мы в нем отправляем сообщение.
[53:39.880 --> 53:45.400]  Вот сообщение мы описываем так. Мы создаем файл, который называется
[53:45.400 --> 53:55.320]  арифметика прота, и в нем описываем такие объекты. messageMultiply. Это request. Там есть два поля,
[53:55.320 --> 54:02.040]  типа inch64, там первое и второе. И в качестве ответа мы получаем сообщение product, в нем есть
[54:02.040 --> 54:13.520]  одно поле inch64. Когда мы пишем рпс-сервис, то мы в обработчиках получаем request и заполняем
[54:13.520 --> 54:27.040]  response. Это прото-описание, это и есть такой язык DSL, на котором можно описывать сервизуемые
[54:27.040 --> 54:34.240]  объекты. А дальше специальный компилиатор, который запускается на фазе генерации файлов
[54:34.240 --> 54:41.120]  сборки, по этим мета-описаниям компилирует, ну просто генерирует код на C++. Довольно
[54:41.120 --> 54:48.320]  нечитаемый, но это ему и не нужно. То есть он по этому мета-описанию генерирует классы с полями
[54:48.320 --> 55:03.200]  классы с методами, например, setValue или просто value getter для наших прото-описаний. Вот эти
[55:03.200 --> 55:11.200]  объекты уже сгенерированы компилиатором портабуфа за нас. И компилиатор этот пишется для каждого
[55:11.200 --> 55:17.040]  языка, и клиент на питоне вызывает этот компилиатор для того, чтобы сгенировать объекты
[55:17.040 --> 55:27.880]  диссерилизации для клиента, для стаба своего, вот здесь вот. И вот заполняет эти поля. А сервер
[55:27.880 --> 55:34.800]  генерирует с помощью компилиатора объекты, чтобы диссерилизовать их и читать. Вот он их читает.
[55:34.800 --> 55:54.160]  Идея понятна? Да, вот здесь поэтому портабуф ограничивает набор типов, из которых можно
[55:54.160 --> 56:00.320]  строить сообщения. Смотрим в описании этого языка, там есть типы, которые есть практически везде.
[56:00.320 --> 56:11.840]  Вещественные числа, целые числа, булл, строчка, ну и набор байт, просто произвольный байт. Вот в
[56:11.840 --> 56:17.520]  общем-то больше ничего и нет. Ну вы из них можете строить сообщения и можете строить, ну делать поля
[56:17.520 --> 56:24.920]  своих месседжей другими месседжами. И вот так реализован, собственно, сам RPC. Для уровня RPC
[56:24.920 --> 56:31.960]  ведь тоже нужны объекты серилизуемые? Нужна структура request, структура response. И вот сама RPC
[56:31.960 --> 56:37.800]  библиотека имеет в себе message request, message response, и в message request есть message method, у которого
[56:37.800 --> 56:50.080]  есть сервис, имя сервиса и имя метода. Но здесь уже есть байты, и вот байты — это серилизованный
[56:50.080 --> 57:00.200]  request, который был серилизован самим стабом. Когда мы пишем стаб, то что мы делаем? Мы строим
[57:00.200 --> 57:12.040]  этот request и вот здесь его серилизуем. Получаются произвольные байты, вот эти байты дальше через
[57:12.040 --> 57:23.520]  уровень каналов улетают куда-то дальше. Понятна ли конструкция? Вот мы просто поменяли протокол
[57:23.520 --> 57:32.360]  серилизации, и теперь в принципе мы можем сделать поддержку для этого протокола с другой стороны,
[57:32.360 --> 57:40.240]  на другом языке. Нужно лишь договориться, чтобы и клиент, и сервер одинаково могли реализовать
[57:40.240 --> 57:45.960]  транспорт-сообщение. Вот если на уровне транспорта они договорятся между собой, то дальше на уровне
[57:45.960 --> 57:54.280]  серилизации они могут декодировать объекты запроса и объекты аргументов и ответа пользователя.
[57:54.280 --> 58:09.760]  Понятно ли это? Хорошо. Тогда пару слов про то, как это реализовано на уровне провода,
[58:09.760 --> 58:16.240]  потому что вообще вопрос интересный. Вы здесь уже видели картинку? Ну во-первых, есть разные
[58:16.240 --> 58:23.040]  мнения по поводу про того, что все очень плохо. И вот вы видели картинку, где же она была?
[58:23.040 --> 58:37.080]  Хорошо, заново. Есть разные механизмы серилизации, и вот есть протокол, который, ждем его, сеть нас в
[58:37.080 --> 58:55.440]  неудачный момент решило подвести. Ну что ж, попробуем еще раз. Но нам интернет нужен,
[58:55.440 --> 59:05.760]  без него мы не справимся. Вот, что можно построить протокол серилизации бесконечно раз быстрее,
[59:05.760 --> 59:12.080]  чем протобуф. Но протобуф вообще он реализован-то разумно. То есть, в самом деле,
[59:12.080 --> 59:19.320]  как можно написать с код серилизации эффективнее, чем сгенерировать его статически? Мы знаем,
[59:19.320 --> 59:24.200]  какие поля будут, мы знаем, каких типов они будут, нам не нужно в рантайме ничего обходить,
[59:24.200 --> 59:32.200]  мы можем просто сгенерировать код. Как именно протобуф все ваши структуры укладывает в байты в
[59:32.200 --> 59:39.160]  проводе? Тут у него типов немного, у него есть строчки и целые числа. Вот как можно серилизовать
[59:39.160 --> 59:46.160]  целые числа эффективно? Ну, во-первых, вы знаете, что есть процессоры, у которых порядок байт разный,
[59:46.160 --> 59:57.320]  нужно это учесть, но это легко. Дальше, представьте, что вы серилизуете IN64, 8 байт, а значение у него
[59:57.320 --> 01:00:10.400]  один. Вот довольно глупо тратите 8 байт на проводе. Что нужно сделать? Нет, так делать не нужно. Нужно
[01:00:10.400 --> 01:00:17.840]  использовать технику, которая называется warrent-encoding. Warrent — это техника следующая. Вы пишете байты
[01:00:17.840 --> 01:00:24.240]  от младшего к старшему, и в каждом байте вы старший бит, в старшем бите помечаете, это последний
[01:00:24.240 --> 01:00:31.160]  байт или еще не последний. Вот если там старший бит единица, то этот байт последний, и нужно
[01:00:31.160 --> 01:00:38.400]  заканчивать. Если же этот байт, если сейчас есть единица, то байт не последний, если ноль, то байт
[01:00:38.400 --> 01:00:43.800]  последний. В итоге, чтобы закодировать, например, число один, вы тратите ровно один байт, в котором
[01:00:43.800 --> 01:00:51.640]  в старшем бите написано, что это единственный, но это последний байт этого warrent. Ну вот так вы можете
[01:00:51.640 --> 01:01:04.840]  компактно кодировать не отрицательные числа. Ты сомневаешься, что можно выложить... не очень
[01:01:04.840 --> 01:01:21.000]  понимаю, в чем проблема-то? Смотри, ты никогда не работаешь, не отправляешь никому 8 байт. Вообще
[01:01:21.000 --> 01:01:27.600]  так вопрос не стоит. Ты когда-нибудь видел TCP? Ты же знаешь, что по нему нельзя отправлять 8 байт,
[01:01:27.600 --> 01:01:33.240]  по нему нужно гигабайт отправить, потому что сначала TCP медленно, он разгоняется, он не понимает,
[01:01:33.240 --> 01:01:37.360]  насколько нагружена сеть, и насколько нагружен клиент, поэтому там есть flow control и congestion
[01:01:37.360 --> 01:01:43.680]  control, чтобы не нагружать сеть и ту сторону. И вот ровно поэтому в прошлый раз мы говорили,
[01:01:43.680 --> 01:01:47.280]  что для файловой системы разумно брать большие чанки, чтобы сеть нагружать большими чанками,
[01:01:47.280 --> 01:01:52.320]  чтобы TCP быстро работал. Поэтому когда ты посылаешь сообщение через канал, у тебя сообщение
[01:01:52.320 --> 01:01:57.000]  отправляется не одно, а вот много разных сообщений, и TCP загружен, и у тебя потом байт большой,
[01:01:57.000 --> 01:02:01.880]  и разумно, чтобы в нем было меньше байт, ну в смысле, чтобы просто экономить на времени.
[01:02:01.880 --> 01:02:10.280]  То есть мы отправляем много данных, мы отправляем большие наборы данных, которых очень много
[01:02:10.280 --> 01:02:15.920]  маленьких портабуфов, много маленьких сообщений, поэтому... или пишем их на диск. Поэтому чем меньше
[01:02:15.920 --> 01:02:21.320]  этих байт будет, тем лучше. Это мы с этим и справились. Почему так нельзя кодировать отрицательные числа?
[01:02:21.320 --> 01:02:32.800]  Потому что у них есть... если мы храним минус один, то у него будет в старшем бите, 63-ем, будет
[01:02:32.800 --> 01:02:38.840]  написано единичка, и мы должны будем закодировать все бесполезные нули. И тут как нужно поступить?
[01:02:38.840 --> 01:02:46.600]  Нужно воспользоваться знаниями математики. Вот вы же умеете доказывать, что множество целых и
[01:02:46.600 --> 01:02:52.760]  натуральных чисел равномощны. Как вы это делаете? Вы их зигзагом обходите, наверное. Ну вот поэтому
[01:02:52.760 --> 01:02:59.520]  вы с помощью нехитрого преобразования конвертируете отрицательное число в положительное, то есть его
[01:02:59.520 --> 01:03:03.360]  порядка и номер в обходе зигзагом, и маленькое отрицательное число становится маленьким
[01:03:03.360 --> 01:03:09.400]  положительным числом. А дальше оно кодируется уже варентом. Ну строчки понятны. Строчки кодируются
[01:03:09.400 --> 01:03:17.160]  как длина плюс байты. А больше ничего в протовуфе-то особенного нет. Ну ладно, там есть кое-что, но это
[01:03:17.160 --> 01:03:24.000]  уже неважно. Так вот, как же это можно ускорить в бесконечное число раз? Спрашивается на этой карте.
[01:03:24.000 --> 01:03:37.440]  Как вот эту процедуру будут буквально ускорить в бесконечном много раз? Нужно сделать процедуру
[01:03:37.440 --> 01:03:44.400]  серилизации и десерилизации к тождественному преобразованию. Как этого добиться? Кто понимает,
[01:03:44.400 --> 01:03:58.000]  о чем я вам говорю сейчас? Ну вот смотрите, что такое int в памяти? Это 8 байт. А что такое int в
[01:03:58.000 --> 01:04:06.360]  проводе в протовуфе? Это какое-то переменное количество байт в кодировке варент. А что если мы
[01:04:06.360 --> 01:04:11.720]  научимся концентрировать свои сообщения так, чтобы их представление в памяти и представление
[01:04:11.720 --> 01:04:21.120]  в проводе было одинаковым? Ну тогда серилизация не будет ничего делать. Вот объект памяти,
[01:04:21.120 --> 01:04:28.400]  его байты, это и есть серилизованная версия. Ну скажем, в протовуфе тут возникает такая штука,
[01:04:28.400 --> 01:04:37.320]  которая называется zero-copy-input. Слышали вы о ней или нет? Сейчас я найду пример. Смотрите,
[01:04:37.640 --> 01:04:45.440]  посторонний вопрос вообще. Есть интерфейс ридера, который умеет откуда-то читать что-то. Из файла,
[01:04:45.440 --> 01:04:55.280]  из строки, из космоса. Вот как он устроен? Вы говорите readSum и передаете ему буфер. То есть
[01:04:55.280 --> 01:05:02.240]  стартовую позицию в памяти и размер буфера. А этот read его заполняет. Этот readSum его заполняет.
[01:05:03.120 --> 01:05:13.720]  Хорошо это или плохо? Это нормально. Но есть некоторая проблема. Допустим, вы пишете ридер для
[01:05:13.720 --> 01:05:21.160]  памяти. То есть у вас есть диапазон памяти уже и вы хотите его адаптировать под интерфейс
[01:05:21.160 --> 01:05:30.440]  ридера. И вам говорят readSum. Что вы делаете? Вы просто берете и из своей памяти копируете в
[01:05:30.440 --> 01:05:37.520]  буфер того, что вам прислали. В тот буфер, который вам дали. Смысл в этом мало в данном случае.
[01:05:37.520 --> 01:05:44.320]  То есть можно было бы просто выдать диапазон памяти из своего буфера. Вот это альтернативный
[01:05:44.320 --> 01:05:50.440]  интерфейс, который называется Zerocopy. То есть вместо того, чтобы отдавать буфер в ридер,
[01:05:50.440 --> 01:05:58.080]  вы наоборот просто получаете диапазон байт из ридера. Да, теперь этот ридер отвечает за то,
[01:05:58.080 --> 01:06:03.080]  чтобы эти байты прожили некоторое время. Это некоторая проблема. Ровно поэтому так не стоит
[01:06:03.080 --> 01:06:10.080]  делать всегда. Но с другой стороны, так вы можете избежать копий. И скажем, понятно, что если у вас
[01:06:10.080 --> 01:06:15.720]  сервизованный протобув сообщения есть, то в нем в конце концов байты каждой строчки уложены подряд.
[01:06:15.720 --> 01:06:23.600]  Поэтому их можно было бы прочесть, ничего не декодируя. Ну вот, протокол CapnProto это протокол,
[01:06:23.600 --> 01:06:28.480]  который реализован разработчиком, который делал в Google Protobuf 2. Он ушел оттуда и делает
[01:06:28.480 --> 01:06:35.920]  свой framework теперь. Вот в нем как раз такая идея. Zerocopy – сервизация. То есть представление байта,
[01:06:35.920 --> 01:06:43.360]  представление объекта сообщения в памяти и на проводе одно и то же. Ровно поэтому у вас процедура
[01:06:43.360 --> 01:06:49.600]  сервизации не сервизации нулевая. Она ничего не делает. Но есть альтернативная библиотека,
[01:06:49.600 --> 01:06:57.480]  она называется flatbuffers. Она про то же, про то, чтобы представление в памяти и в проводе,
[01:06:57.480 --> 01:07:02.000]  или на диске было одинаковым. Говорят, это для геймдеву полезно, я ничего не знаю, спросите у Рома
[01:07:02.000 --> 01:07:10.600]  Сандука, если встретите. Так можно, скажем, сделать ммэп из памяти, из дисков память, и все,
[01:07:10.600 --> 01:07:14.640]  у вас уже готовый объект в памяти, можно их читать. Ничего больше не делая.
[01:07:14.640 --> 01:07:25.480]  Так варинтом не надо пользоваться, это протокол в проводе. Ты говоришь serialize,
[01:07:25.480 --> 01:07:30.280]  получаешь байты, и в этих байтах зашифрованы варинтом числа. Потом ты говоришь deserialize,
[01:07:30.280 --> 01:07:36.160]  вот эти байты преобразуются в твои числа, в твою структуру с методами. Вот я вызвал deserialize,
[01:07:36.160 --> 01:07:54.000]  где-то здесь сейчас покажу. Пример у меня был на протобуфе, но пользоваться как? Скорее,
[01:07:54.000 --> 01:07:59.840]  на что это влияет? Есть некоторые нюансы, то есть тебе не могут STD стринг отдать теперь,
[01:07:59.840 --> 01:08:05.600]  потому что он владеет памятью, а в зерокопе ты не владеешь памятью. А еще это имеет большие
[01:08:05.600 --> 01:08:10.800]  последствия для объема данных в проводе, потому что теперь ты не можешь использовать варинт,
[01:08:10.800 --> 01:08:15.800]  ты не можешь с варинтами работать в своем компьютере, в своем процессоре. Поэтому,
[01:08:15.800 --> 01:08:21.280]  если у тебя в протобуфе есть незаполненное поле, оно, скажем, может быть просто опущено или сжато
[01:08:21.280 --> 01:08:28.880]  до одного байта, целое число. Но если ты серилизуешь через capnproto или flatbuffers 64,
[01:08:28.880 --> 01:08:37.880]  то он будет занимать честно 8 байт в проводе. То есть он более вербозный получается, то есть ты
[01:08:37.880 --> 01:08:42.040]  ничего здесь не можешь компактить, но с другой стороны ты экономишь на серилизации, десерилизации.
[01:08:42.040 --> 01:08:47.360]  Ну у тебя такой trade-off есть, что тебе больше нравится. Ладно, последнее, о чем я хочу поговорить,
[01:08:47.360 --> 01:08:54.880]  вот этот протокол мы еще не закончим, ну простите, я никого не держу, вы можете бежать. Тема бесконечная,
[01:08:54.880 --> 01:08:59.480]  но она кажется очень полезна для жизни, потому что вы неизбежно столкнетесь с чем-то либо протобуфа,
[01:08:59.480 --> 01:09:09.040]  либо протокол. Вот мы знаем, как делать concurrency, ну разными способами, вы знаете,
[01:09:09.040 --> 01:09:14.920]  что разные библиотеки есть. Вы знаете, что есть protobuf, flatbuffers, capnproto, разные протоколы
[01:09:14.920 --> 01:09:20.240]  серилизации. Это разные слои, на которых вы можете что-то свое делать, что-то менять в этой
[01:09:20.240 --> 01:09:27.280]  архитектуре. А есть еще транспорт. И вот транспорт пока нам в принципе, ну мы не обсудили,
[01:09:27.280 --> 01:09:34.200]  как его сделать. Какие у нас от него ожидания? С одной стороны, этот транспорт должен быть
[01:09:34.200 --> 01:09:40.040]  производительным, то есть мы должны упаковать очень много сообщений туда-сюда в там малое количество
[01:09:40.040 --> 01:09:46.800]  TCP-соединений, чтобы они были нагруженными. А кроме этого мы хотим кроссплатформенность,
[01:09:46.800 --> 01:09:57.040]  чтобы мы могли сделать send на C++ и получить потом с другой стороны на Python что-то. Конечно же,
[01:09:57.040 --> 01:10:03.280]  можно упаковать вот все эти сообщения в TCP с помощью какого-то кастомного протокола. Но если вы
[01:10:03.280 --> 01:10:06.760]  хотите сделать что-то кроссплатформенное, то получается, что у вас протобуф уже есть,
[01:10:06.760 --> 01:10:14.160]  у вас concurrency там уже разные в языках есть, написано все это, а протокол отправки получения
[01:10:14.160 --> 01:10:21.840]  сообщения вы будете писать свой. Как быть? Вот оказывается, что задача тоже уже решена,
[01:10:21.840 --> 01:10:30.720]  решена в смысле универсально решена. Решена с помощью протокола HTTP. Вот вообще HTTP это
[01:10:30.720 --> 01:10:38.840]  супернеэффективный протокол, ну в смысле первая версия протокола HTTP. Там, ну это текстовый
[01:10:38.840 --> 01:10:46.560]  формат и кроме того он не позволяет вам клиенту работать конкурентно. То есть если вы отправляете,
[01:10:46.560 --> 01:10:52.880]  ну вы можете отправить несколько запросов в HTTP, но не вот так вот делать, а вот сразу все
[01:10:52.880 --> 01:10:58.720]  отправить. Но сервер обязан отвечать на них ровно в таком же порядке. Если первый запрос залипнет,
[01:10:58.720 --> 01:11:04.120]  он будет медленным, то вы на два других ответа тоже не получите. Почему это плохо? Потому что
[01:11:04.120 --> 01:11:10.160]  веб, ну то есть интернет медленно работает. Вот вы приходите на сайт, и чтобы его загрузить,
[01:11:10.160 --> 01:11:17.240]  вам нужно загрузить миллион картинок. И конечно же браузеру нужно грузить их параллельно. Он
[01:11:17.240 --> 01:11:21.560]  не может эти параллельные запросы логически упаковать в одно соединение, потому что HTTP так
[01:11:21.560 --> 01:11:28.720]  не работает. Поэтому браузер открывает много соединений. Но это много TCP соединений, и по ним
[01:11:28.720 --> 01:11:34.000]  отправятся маленькие запросы. А это неэффективно, это неправильное использование TCP. По нему нужно
[01:11:34.000 --> 01:11:41.320]  гигабайт отправить. Поэтому сделать и конкурентно, и быстро HTTP вам не помогает, и поэтому все
[01:11:41.320 --> 01:11:46.600]  тормозит, интернет тормозит. Что делали люди? Они решили, что интернет не годится такой, нужно
[01:11:46.600 --> 01:11:54.840]  новый делать. Но и сделали это в Google. Они разработали новый протокол HTTP, он звался speedy, и он стал
[01:11:54.840 --> 01:12:02.160]  основой для протокола HTTP версии 2. И вот протокол HTTP версии 2, это вот то же самое, что вот HTTP 2
[01:12:02.160 --> 01:12:07.600]  для TCP, это то же самое, что файберы для потоков. Вот буквально. У вас есть ограниченные физические
[01:12:07.600 --> 01:12:13.400]  ресурсы, потоки, но они виртуальны, но все равно как будто физические. И планировщик операционной
[01:12:13.400 --> 01:12:20.080]  системы умеет эффективно планировать их, только если они занимаются тяжелой работой. А у нас,
[01:12:20.080 --> 01:12:26.520]  например, задача чтения сети, запись в сеть, она постоянно засыпает, это плохо. Поэтому что мы делаем,
[01:12:26.520 --> 01:12:31.480]  мы пишем файберы и упаковываем их плотно в эти потоки. И файбер блокируется, на его
[01:12:31.480 --> 01:12:37.000]  месте становится другой, поток продолжает работать. Что сделано в HTTP 2? В HTTP 2 поверх
[01:12:37.000 --> 01:12:42.880]  TCP соединения, в логическом вот этом HTTP соединении, есть очень много независимых потоков данных.
[01:12:42.880 --> 01:12:51.480]  То есть очень просто много независимых логических стримов, которые состоят из отдельных фреймов.
[01:12:51.480 --> 01:12:59.400]  Это вот буквально вы в одно HTTP соединение логическое, в один поток byte, записываете много таких
[01:12:59.400 --> 01:13:04.920]  вот виртуальных потоков уровня HTTP. И каждый независимый поток, это может быть отдельный
[01:13:04.920 --> 01:13:10.840]  запрос, отдельные картинки. А сервер уже может их поработать конкурентно. У него нет обязанностей
[01:13:10.840 --> 01:13:18.800]  выполнять вот такой вот, в очереди их ставить. Правда, за счет этого появляются сложности, потому
[01:13:18.800 --> 01:13:24.440]  что у вас в TCP есть flow control, чтобы не загружать ресивера, а теперь у вас много потоков в одном
[01:13:24.440 --> 01:13:30.320]  TCP. И в итоге вы реализуете flow control в HTTP 2 для каждого логического потока, для каждого такого
[01:13:30.320 --> 01:13:37.240]  стрима. В общем, вы еще на уровне абстракции выше воспроизводите все то же самое, что есть ниже,
[01:13:37.240 --> 01:13:43.320]  так как мы писали собственные планировщики для файберов. Но вы получаете универсальный протокол,
[01:13:43.320 --> 01:13:50.400]  и вот этот протокол создан для вообще для интернета, чтобы сайты быстро грузились в браузерах.
[01:13:50.400 --> 01:13:57.760]  Но с другой стороны, он же отлично подходит для RPC, потому что у вас как бы TCP соединение это
[01:13:57.760 --> 01:14:06.360]  канал в RPC, вот эти вот стримы это независимые RPC запросы, а фреймы это вот их маленькие кусочки.
[01:14:06.360 --> 01:14:14.720]  Это вот request и response. И вот одно на другое мачится. Ну и а в чем бонус-то? В том,
[01:14:14.720 --> 01:14:20.920]  что HTTP 2 это штука полезная, она должна быть реализована на каждом языке, на котором вообще
[01:14:20.920 --> 01:14:26.800]  люди собираются писать серверы. Если вы пишете сервер на Python, то должен быть HTTP 2. Если у вас
[01:14:26.800 --> 01:14:31.600]  есть сервер на C++, если вы планируете где-то поднять сервер на C++, у вас должен быть HTTP 2 для C++,
[01:14:31.600 --> 01:14:38.200]  для Rast, для God, для чего угодно. И вот можно ожидать, что для вашего любимого языка будет
[01:14:38.200 --> 01:14:44.440]  поддержан протокол HTTP 2. И вот его, положив в абстракцию транспорта, вы можете получить
[01:14:44.440 --> 01:14:51.840]  кроссплатформенный способ общаться к клиенту и серверу с помощью сахронных сообщений. Итого,
[01:14:51.840 --> 01:14:57.680]  у вас есть на этом уровне HTTP 2, на уровне транспорта кроссплатформенный, на уровне выше у вас есть
[01:14:57.680 --> 01:15:03.200]  конкарнси, которая более-менее стандартная в каждом языке, и на уровне там, где стаб и сервис,
[01:15:03.200 --> 01:15:08.160]  у вас есть протобув, ну или что-то такое же универсальное, как протобув, для того, чтобы делать
[01:15:08.160 --> 01:15:14.520]  реализацию. И вот вы в таких слоях, из таких кубиков готовых можете построить свой фрейнворк. И вот он
[01:15:14.520 --> 01:15:20.600]  более-менее везде будет выглядеть одинаковым образом, то есть в любом языке, который бы вы не
[01:15:20.600 --> 01:15:27.120]  выбрали. То есть понятно, что детали будут отличаться, интерфейсы будут отличаться, но в конце концов все
[01:15:27.120 --> 01:15:34.040]  эти слои будут, и кто их объединяет, в конце концов объединяет их сам Гугл. Ну потому что Гугл придумал
[01:15:34.040 --> 01:15:44.360]  протобув, и Гугл придумал HTTP 2, и Гугл написал Go. Ну как бы, вот у них есть GRPC. GRPC — это реализация
[01:15:44.360 --> 01:15:51.880]  RPC, которая, ну вот как бы наиболее нативная, наверное, для Go. Ну и понятно, что она может
[01:15:51.880 --> 01:15:57.600]  работать с P2, который придумал Гугл, использовать протобув, который придумал Гугл, и вы используете
[01:15:57.600 --> 01:16:15.240]  Go с каналами ISFA и с GRUTIN, которые тоже придумал Гугл. Вот такой вот конец этой истории. Так что вот,
[01:16:15.240 --> 01:16:20.800]  надеюсь, что вы, когда будете писать код, будете понимать, чем наш фрейнворк отличается, и тем,
[01:16:20.800 --> 01:16:26.960]  что он, в принципе, отличается вон деталями, а его организация внутренняя, она абсолютно
[01:16:26.960 --> 01:16:36.040]  универсальна. На самом деле, я могу и продолжать, так что просто заканчивать нам. Давайте,
[01:16:36.040 --> 01:16:41.240]  если кто-то хочет о чем-то поговорить еще, мы останемся, а так можно разбегаться. Да я и сам устал.
[01:16:41.240 --> 01:16:52.280]  Наверное, стоило бы поговорить про контексты, которые в Домашке есть. Я вроде бы говорил про
[01:16:52.280 --> 01:16:55.840]  их немножко, но, может быть, сейчас нужно поговорить еще раз, чтобы было понятно,
[01:16:55.840 --> 01:17:02.480]  что это значит. И про дедлайны, про отмену, может быть, пару нюансов еще можно было обсудить.
[01:17:02.480 --> 01:17:16.960]  Да не эти дедлайны, дедлайны, которые в RPC. Ну нет, потому что я хочу сказать,
[01:17:16.960 --> 01:17:26.040]  мы не обсуждали, поэтому. Ну давайте мы отпустим тех, кто изнимогает уже. Ну еще раз,
[01:17:26.040 --> 01:17:40.280]  можно всем разойтись, я не против. Невозможно же все успеть в конце концов. Счастливо.
[01:17:40.280 --> 01:17:53.080]  Вопрос, вот маленькое упражнение для ума. Вот у вас есть запрос, и в наших алгоритмах этого нет,
[01:17:53.080 --> 01:18:00.280]  но если вы пишете RPC чуть более высокоуровневой, не то что там, где хворомы собираются какие-то,
[01:18:00.280 --> 01:18:08.320]  а вы пишете RPC-сервис в какой-то большой репетированной системе, то разумно ставят
[01:18:08.320 --> 01:18:15.520]  на него дедлайн. То есть вы вечно ждать не будете. Вот как именно этот дедлайн реализовать? Ну и дедлайн или тайм-аут.
[01:18:15.520 --> 01:18:29.880]  Ну можно не так делать, так наоборот делать не стоит. Вот, я уже давал вам ссылку, она про
[01:18:29.880 --> 01:18:40.640]  то, что вообще тайм-аут использовать не нужно. Нужно использовать дедлайны, потому что тайм-аут
[01:18:40.640 --> 01:18:46.880]  это вещь относительная, и непонятно от чего его отсчитывать. А дедлайн на общей оси находится,
[01:18:46.880 --> 01:18:54.680]  и всем понятен. Так вот, если у тебя есть дедлайн к запросу, то возьми и вместе добавь в свой
[01:18:54.680 --> 01:19:02.800]  реквест, вот в структуру которую ты отправляешь, которую канал отправляет серверу, заведи здесь
[01:19:02.800 --> 01:19:10.000]  поле дедлайн. И пусть сам сервер у себя отменит операцию, когда дедлайн на его месте, по его
[01:19:10.000 --> 01:19:14.640]  часам истечет. Вообще говоря, его часы своими могут быть не синхронизированы, у него они могут
[01:19:14.640 --> 01:19:19.160]  там, не знаю, бежать чуть быстрее, у тебя чуть медленнее, но в целом тебе сойдет.
