[00:00.000 --> 00:13.440]  Наверное, придется напомнить лему, как она у нас звучала.
[00:13.440 --> 00:26.060]  Пусть размерность вапника и черванемки с какого транжированного
[00:26.060 --> 00:35.580]  пространства равняется D, ну а мощность множества, из которого выбираются вот
[00:35.580 --> 00:41.580]  эти вот рейнджи, она N. Тогда
[00:45.780 --> 00:49.900]  мощность R не больше, чем ж от Nd,
[00:49.900 --> 01:01.340]  которая представляет собой сумму, пока от 0 до D, с из N пока. Ну это я доказал,
[01:01.340 --> 01:07.260]  индукции доказал, все вроде аккуратно сделал, я не знаю, все ли присутствующие были на прошлое,
[01:07.260 --> 01:13.260]  нехуй, но вот мы это сделали. Знаете, я еще замечу, что вот это не превосходит N в степени D,
[01:13.260 --> 01:20.820]  ну докажете сами, как бы то, что с из N пока не превосходит N в степени D, это очевидно,
[01:20.820 --> 01:27.300]  с из N пока не превосходит N в степени D, поделить на D факториал, как известно. Ну там все-таки
[01:27.300 --> 01:32.420]  сумма, но она не слишком накапливается, в общем, можно доказать, что это не больше, чем N в степени D.
[01:32.420 --> 01:37.420]  В принципе, если вдруг кого-то не получится так, ну это не так существенно, можно чуть похуже
[01:37.420 --> 01:43.580]  оценку написать, но мы это сейчас используем в некотором контексте. Следствия из этой леммы,
[01:43.580 --> 01:56.060]  которая я не писал в прошлый раз, но которая, в общем, очевидна, пусть опять же дано какое-то
[01:56.060 --> 02:04.220]  пространство размерности D, ну и, наверное, давайте считать, что тут уже неважно, какой X,
[02:04.380 --> 02:17.380]  может быть, как в конечном, так и бесконечном. Давайте пусть A, это E, которая подножит мощность N,
[02:17.380 --> 02:34.580]  тогда мощность проекции на A множество R не больше, чем G от N-D.
[02:34.580 --> 02:49.620]  Ну вроде понятно, да? Мы просто рассматриваем такое подпространство A, запятая проекция на
[02:49.620 --> 02:57.060]  множество R, это подпространство в исходном пространстве XR. Понятно, что размерность этой
[02:57.060 --> 03:03.380]  штуки по-прежнему не больше, чем D, а мощность A у нас по условию N. Ну, лемма говорит о том,
[03:03.380 --> 03:08.100]  что размер проекции, то есть вот эта вот система областей, действительно не больше, чем G.
[03:08.100 --> 03:17.020]  Следствие является очень простым следствием из леммы, но сейчас вы увидите, что оно полезно,
[03:17.020 --> 03:30.900]  как вам ключи. Так, давайте сформулируем еще одну лему. А, ну давайте я вот тут дам определение,
[03:30.900 --> 03:38.660]  потом сформулирую лему. Вот если у нас есть какое-то число h больше либо равное двойке,
[03:38.660 --> 03:49.220]  натурально, и есть наша система под множество R, ну какая-то система под множество на множество
[03:49.220 --> 03:59.380]  X, то давайте через R с индексом h обозначим совокупность, состоящую из всевозможных
[03:59.380 --> 04:09.900]  пересечений множеств R1, Rh, таких что каждая рытая является элементом исходной совокупности R.
[04:09.900 --> 04:18.060]  Мы берем совокупность каких-то областей R и рассматриваем всевозможные, сейчас скажу такое
[04:18.060 --> 04:25.380]  слово, по-h-ные пересечения. Ну если h равно 2, то по-парные, если h равно 3, то по-тройные.
[04:25.380 --> 04:38.740]  Все возможные пересечения h каких-то под множество R. При этом я не говорю, что они обязаны быть
[04:38.740 --> 04:44.180]  разными, то есть в том числе можно пересекать и совпадающие. Важно только, чтобы сами вот эти
[04:44.180 --> 04:50.820]  вот результирующие множества получились разными, то есть R с индексом h это не мультимножество,
[04:50.820 --> 04:56.500]  это именно совокупность различных множеств, которые получаются в результате тех или иных
[04:56.500 --> 05:09.660]  пересечений. Называется эта штука h измельчений, ну просто для света, h измельчи. Чтобы вам не было
[05:09.660 --> 05:15.980]  слишком абстрактно, жизни не казалось слишком абстрактной, не было грустно от этого. Давайте
[05:15.980 --> 05:22.260]  вспомним затрафку, с которой все началось в прошлый раз. Помните, там были треугольники на плоскости?
[05:22.260 --> 05:32.540]  Были? Вот помните, в то же время было такое ранжированное пространство Rn и h красивое
[05:32.540 --> 05:39.540]  я нарисовал. Значит Rn это объемлющее множество x, а h красивое состояло из всех открытых
[05:39.540 --> 05:47.620]  полупространств. Было так? Мы даже посчитали у него размерность, она оказалась равной n плюс 1,
[05:47.620 --> 05:52.820]  помозли теория Мародона, которую я не доказывал, но которая не сложная. Мы доказали, что это n
[05:52.820 --> 06:03.900]  плюс 8. Так, ну а теперь представьте себе, что я беру вот такое вот пространство h на плоскости,
[06:03.900 --> 06:16.140]  пусть у меня R2 и h. Беру h маленькое равное 3 и рассматриваю h с индексом 3, ну вот в этом смысле.
[06:16.140 --> 06:23.260]  Беру три измельчения множества полуплоскостей открытых, которые возникают на обычной плоскости.
[06:23.260 --> 06:32.100]  Что из себя представляет такое три измельчения? Нет, мы рассматриваем, смотрите, вот здесь
[06:32.100 --> 06:39.700]  содержатся полуплоскости. И вот мы их потройно пересекаем, каждые три из них пересекаем. В частности
[06:39.700 --> 06:45.380]  получаются, конечно, все треугольники, но и в основном получаются треугольники, за исключением
[06:45.380 --> 06:52.260]  множества, так сказать, меры ноль ситуации, когда две полуплоскости параллельны, тогда получается не
[06:52.260 --> 07:00.020]  треугольник. Но если у вас и плоскости находятся в общем положении, картинка вот такая, возникает с
[07:00.020 --> 07:05.860]  вероятностью 1, в обычном смысле слова, а такая с вероятностью ноль, то тут получается треугольник
[07:05.860 --> 07:14.420]  на пересечении вакурато тот самый. Что? Ну или одна из этих частей. Да-да-да, я согласен. То есть,
[07:14.420 --> 07:20.740]  если мы, например, обозначим через t с индексом 3 множество всех треугольников, именно треугольников
[07:20.740 --> 07:26.740]  на плоскости, то, конечно, h3 будет просто содержать внутри себя вот этот t с индексом 3.
[07:30.020 --> 07:39.300]  Что? h3 это множество всех пересечений трех полуплоскостей.
[07:39.300 --> 07:47.740]  Ну это r3, да, но r у нас обозначается h, поэтому я к нему пририсовал троечку. Ну я вроде так и
[07:47.740 --> 07:54.940]  сказал, да. То есть r у меня сейчас обозначена буквой h, поэтому r3 это h3, а t3 это множество
[07:54.940 --> 08:00.460]  треугольников. Оно содержится в этом h3, не важно, что оно почти все и заполняет там,
[08:00.460 --> 08:05.660]  по большому счету. Главное, что содержится. То есть это как-то пространство что-то. Так вот,
[08:05.660 --> 08:16.500]  что говорит Лемма? Лемма говорит, что пусть размерность какого-то пространства xr равняется d,
[08:16.500 --> 08:27.420]  пусть h больше не бы равняется двойке, тогда
[08:27.420 --> 08:40.580]  размерность вот такого пространства не превосходит вот такой
[08:46.500 --> 08:54.380]  размер. Ну, смотрите, я на самом деле не очень держусь именно за эту величину. Я не буду
[08:54.380 --> 08:59.740]  аккуратно доказывать, что оценка получится именно такая. Принципиально, конечно, для меня,
[08:59.740 --> 09:09.340]  что оценка есть. То есть если у нас дано пространство конечной размерности, то его
[09:09.340 --> 09:15.580]  измельчение тоже имеет конечную размерность. Но это ожидаемо, конечно. Но почему это так,
[09:15.580 --> 09:26.980]  я сейчас докажу. Понятно утверждение? Давайте докажем. Не, да просто. Ну,
[09:26.980 --> 09:33.620]  давайте рассмотрим какое-нибудь множество, которое дробится. Пусть есть какое-то а из x
[09:33.620 --> 09:46.020]  и а. А, сейчас, дробится чем? Дробится рh, да? Да, дробится рh.
[09:46.020 --> 10:01.980]  Так, ну сейчас сообразим, что значит дробится рh, да? Дробится рh. Так, ну пусть
[10:04.980 --> 10:13.820]  мощность а, это какое t? Пусть а, ну, мощность t и дробится с помощью системы, вот этой измельченной
[10:13.820 --> 10:24.500]  системы областей r с индексом h. Так, с одной стороны, давайте я прям так напишу, с одной
[10:24.500 --> 10:41.900]  стороны, мощность проекции на а в совокупности областей r с индексом h не больше, чем что.
[10:43.900 --> 10:49.060]  Или давайте не так, давайте не больше, это, наверное, в ходу не очевидно. Давайте наоборот, равна.
[10:49.060 --> 10:56.620]  Ну, равна-то она, конечно, во в степени n, что тут говорить. Если а дробится, значит,
[10:56.620 --> 11:02.700]  мощность проекции это просто 2 венны, где n это мощность а. Дробится, значит, в проекции
[11:02.700 --> 11:08.580]  находятся все возможные подмножения. По определению просто а дробится, если там находятся,
[11:08.580 --> 11:15.380]  вот в этой проекции находится все возможные подмножения. А сейчас я с другой стороны это оценю сверху,
[11:15.380 --> 11:25.620]  да, да, вот сейчас будет применено следствие из той ленты. С другой стороны, с другой стороны,
[11:25.620 --> 11:34.500]  знаете, я вот как скажу, мощность проекции на а, давайте для начала исходного r. Так,
[11:34.500 --> 11:45.300]  проще. Вот мощность проекции на а, исходного r. Она согласна следствию, ну, давайте я схожу
[11:45.300 --> 11:50.940]  к этому следствию, чтобы камера туда повернулась. Вот, вот, следствие. Чего она не превосходит?
[11:50.940 --> 11:59.140]  Тогда мощность проекции не больше, чем, ну, g от nd. Прям в точности g от nd это вот следствие нам
[11:59.140 --> 12:06.340]  дает. Ну, и я просил вас доказать, что это не больше, чем n в степени d, но я повторю,
[12:06.340 --> 12:11.380]  что именно такая величина оценки нужна, чтобы в конечном счете получить вот это неравенство,
[12:11.380 --> 12:15.900]  а поскольку я его строго доказывать сейчас не хочу, ну, вы сейчас увидите до какой степени
[12:15.900 --> 12:21.340]  строгости я дойду, то, в общем, не так важно, какую вы здесь оценку получите, можно и ухудшить.
[12:21.340 --> 12:33.100]  Вот, ну, пусть будет n в степени d. Так, ну, отсюда следует, что мощность проекции на а измельчение,
[12:33.100 --> 12:40.420]  аж измельчение, ну, я утверждаю, я не буду вас спрашивать, я сам скажу, не больше, чем n в степени d,
[12:40.420 --> 12:50.860]  аж. Я, как бы, полагаю, что это очевидно, но я поясню. Ну, мы просто между собою пересекаем
[12:50.860 --> 12:58.820]  любые аж штук множеств, которые к нами находятся в совокупности, мощность которой не больше,
[12:58.820 --> 13:05.300]  чем n в степени d. То есть исходных множеств не больше, чем n в степени d, и мы их еще комбинируем
[13:05.300 --> 13:11.540]  по аж штук по аж штук в каждом пересечении. Мы просто n в d и возводим еще в аж той степени.
[13:13.540 --> 13:17.580]  Но она не то чтобы очень грубая, потому что, помните, я оговорился, что они совпадать могут.
[13:17.580 --> 13:25.380]  Ну, я сказал, что вот в этих пересечениях разрешено, чтобы r1 аж совпадали. Видите,
[13:25.380 --> 13:29.380]  вот здесь в определении не сказано, что они все попарно различные, сказано только, что каждый
[13:29.380 --> 13:35.340]  из них находится в аж. Поэтому это, в общем, не то чтобы очень большое огрубление, хотя с точки
[13:35.340 --> 13:40.700]  зрения задачи про треугольники можно было бы разрешить им быть разными, и тогда была бы немножко
[13:40.700 --> 13:47.700]  грубая ажность. Ну, не важно. Ну, есть такая оценка. Ну, смотрите, что отсюда следует. Отсюда
[13:47.700 --> 14:00.500]  следует, что если n в степени d меньше, чем 2 в степени n, то противоречие.
[14:00.500 --> 14:13.100]  Ну, то есть не может дробиться множество, у которого n таково, что выполнено вот это неравенство. Если бы
[14:13.100 --> 14:18.260]  мощность множества равнялась n и множество дробилось, то вот столько было бы элементов
[14:18.260 --> 14:24.180]  проекции. Но мы точно знаем, что их не больше, чем столько. Поэтому если бы вдруг оказалось,
[14:24.180 --> 14:28.980]  что эта верхняя граница, в свою очередь, строго и меньше, чем ожидаемая величина, то это бы
[14:28.980 --> 14:41.580]  означало, что а не дробится. Все, что утверждает Лемма, Лемма утверждает, то если в качестве n взять
[14:41.580 --> 14:51.340]  вот это 2dh и лог двоичный dh, ну там какую-нибудь верхнюю целую часть, нижнюю целую часть, если в
[14:51.340 --> 14:56.020]  качестве n взять вот эту величину, то таки будет выполнено вот это неравенство.
[14:59.980 --> 15:06.020]  Но отсюда и следует, что размер максимального дробящегося множества заведомо не превосходит
[15:06.020 --> 15:10.340]  эту величину. Наверное, надо брать не верхнюю, а нижнюю целую часть, чтобы быть корректным
[15:10.340 --> 15:18.980]  формулировками. Берем любое множество вот такой мощности и уже получаем, что выполнено вот это
[15:18.980 --> 15:24.660]  неравенство. То, что оно рано или поздно будет выполнено, товарищи, я надеюсь, всем понятно,
[15:24.660 --> 15:31.700]  dh это какая-то константа, то есть здесь стоит многочлен n в степени dh, а здесь стоит экспонент.
[15:31.700 --> 15:37.620]  Ну ясно, что существует момент, начиная с которого это неравенство будет выполняться. Вот Лемма
[15:37.620 --> 15:44.740]  утверждает, что момент находится в этой точке. Ну по крайней мере не выше нее уже случается вот
[15:44.740 --> 15:53.260]  это переключение. Понятно? Вот я не буду требовать на экзамене, чтобы вы аккуратно проверяли,
[15:53.260 --> 16:00.100]  что именно такой вот n подставим сюда, оно для всех вообще dh, какие возможно,
[16:00.100 --> 16:05.340]  будут удовлетворять этому неравенству. Ну просто важно понимать, что вот как-то так будет.
[16:05.340 --> 16:19.500]  Я внимаю, не? Сейчас будет ну такой как бы маленький катарсис, что ли. Вот, ну может быть,
[16:19.500 --> 16:26.620]  но через какое-то время. Пока чего мы понимаем, смотрите, давайте посчитаем размерность пространства,
[16:26.620 --> 16:36.940]  я доказал Лему, давайте посчитаем размерность пространства вот такого r2 и t3, но не посчитаем,
[16:36.940 --> 16:41.940]  а оценим исходя из полученных результатов. Посчитать это можно на самом деле, она там какая-то
[16:41.940 --> 16:46.860]  не очень большая, то есть нельзя сказать, что это тяжелая задача взять и явно посчитать вот эту
[16:46.860 --> 16:52.980]  размерность. Но я из общей теории выведу какую-то может быть очень грубую оценку. Грубая оценка
[16:52.980 --> 17:06.620]  получается как? Ну, она получается 2dh log2dh, где h равняется тройке, а d чему равняется?
[17:06.620 --> 17:22.620]  Написано на доске, d тоже равняется тройке, вот написано на доске. t3 это под множество,
[17:22.620 --> 17:29.820]  множество всех этих пересечений трех плоскостей в h3. t3 это под множество в h3.
[17:29.820 --> 17:37.180]  Если вы возьмете r2 h3, ну просто r2 h3 будет 3, ну надо взять r2 h3, чтобы туда включилось вот
[17:37.180 --> 17:54.220]  это вот пространство, где тоже равняется тройке. Смотрите, это равно 2 на 3 на 3 на log2dh 3d3. Так,
[17:54.220 --> 18:01.220]  это 18 умножить на 2dh log2dh 9, который чуть-чуть больше чем 3. Давайте считать, что это меньше
[18:01.220 --> 18:09.140]  60, потому что мне менее аккуратнее считать, но то, что это меньше 60 вроде очевидно. Ну вот,
[18:09.140 --> 18:15.100]  это меньше 60, ну и хорошо. То есть это конечная разница, но на самом деле гораздо меньше 60 можно
[18:15.100 --> 18:20.340]  руками посчитать, там будет гораздо меньше. Вот давайте запомним этот результат. Получили,
[18:20.340 --> 18:29.140]  что меньше 60. Хорошо. Теперь я предлагаю обобщить теорему, сформулированную в прошлый раз,
[18:29.140 --> 18:34.540]  на случай произвольного ранжированного пространства. В прошлый раз я формулировал
[18:34.540 --> 18:40.740]  теорему про треугольники на плоскости, если помнить. Если мы берем систему представителей
[18:40.740 --> 18:46.380]  для любой совокупности под множество, которое получается в результате пересечения исходного
[18:46.380 --> 18:52.180]  множества с треугольниками, и при этом мы черпаем значимую долю от исходного множества точек,
[18:52.180 --> 19:00.180]  то у нее удивительным образом всегда есть соп размера не больше, например, чем 10 тысяч,
[19:00.180 --> 19:08.420]  если эпсилон доля. Это одна вторая. Ну я помню все наизусть, видите, из меня оно льется прямо. А вы
[19:08.420 --> 19:14.940]  понимаете, чего я говорю, да? В чем там пафос-то был, что мы берем абсолютно любое множество
[19:14.940 --> 19:20.220]  точек сколь угодно большой мощности на плоскости. Миллиард, там, квадриллион,
[19:20.220 --> 19:26.580]  в 10 степени 10-10 тысяч раз. Не бесконечное, а конечное множество точек, любое, совершенно.
[19:26.580 --> 19:32.780]  Дальше начинаем его пересекать с треугольниками и рассматриваем только такие пересечения,
[19:32.780 --> 19:36.700]  которые содержат не меньше половины от общего числа точек. Но вот был их миллиард,
[19:36.700 --> 19:41.940]  надо чтобы в каждом треугольнике, с которым мы пересекаем наше множество, содержалось 500
[19:41.940 --> 19:49.160]  миллионов или больше точек. От миллиарда положить 500 миллионов, да? Вроде как их дофига этих под
[19:49.160 --> 19:53.980]  множество, их много разных, вот они все мощности 500 миллионов и больше, если исходное множество
[19:53.980 --> 20:00.020]  мощности миллиарда. И вот мы утверждаем, тем не менее, что всегда есть система общих представителей,
[20:00.020 --> 20:01.820]  мощность которой не больше, чем 10 тысяч.
[20:11.940 --> 20:18.580]  То еще раз. Здесь мы знаем только верхнюю оценку.
[20:24.580 --> 20:32.940]  Нет, D это размерность исходного пространства, то есть вот этого без измельчений, до измельчения,
[20:32.940 --> 20:39.700]  это пространство, состоящее просто из полуплоскостей. Вот у него в точности три размера.
[20:39.700 --> 20:46.860]  Дальше мы его измельчаем в три раза, и вот в этом измельчении содержатся все треугольники.
[20:46.860 --> 20:55.420]  Что тут? И D равно 3, и H равно 3. Конечно, я не исключаю, что можно треугольники получить как-то
[20:55.420 --> 21:02.180]  иначе. И вообще, я не говорю, что размерность пространства треугольников это 60. Она гораздо
[21:02.180 --> 21:12.380]  меньше, ее можно руками посчитать. Наверное, да. То есть если длинеет цепочку писать, то здесь
[21:12.380 --> 21:21.380]  надо писать так. Vc от R2 T3 не больше, чем Vc от R2 H3, а она не больше, чем вот это вот произведение.
[21:21.380 --> 21:31.660]  Конечно, конечно. Именно такая логика за этим была. Конечно. Я не утверждаю, что Vc от R2
[21:31.660 --> 21:38.260]  и T3 это то же самое, что Vc от R2 и H3. Это, кстати, интересный вопрос. Я не думал об этом. Можете
[21:38.260 --> 21:43.340]  подумать. Я утверждаю, что по-видимому и то, и другое можно посчитать явно не прибегая к
[21:43.340 --> 21:49.180]  помощи общей теории. Но общая теория хороша, потому что представьте себе, что вы не треугольники
[21:49.180 --> 21:54.380]  на плоскости рассматриваете, а в десятимерном пространстве берете пятидесятигранники. Ну
[21:54.380 --> 22:00.780]  хрен вы уже там посчитаете явную размерность. А тут есть понятная оценка, которую можно
[22:00.780 --> 22:07.020]  подставить. Да, она наверно завышенная, но зато она автоматом дает какой-то результат. Ладно,
[22:07.020 --> 22:14.580]  давайте сформулируем общую теорему про систему представителей. Вот пусть у нас есть какое-то
[22:14.580 --> 22:30.900]  XR, разъемное пространство. Рассмотрим A из X. Ну, дальше мы рассмотрим. Давайте рассмотрим
[22:30.900 --> 22:44.540]  такое множество невозможных пересечений R и A, то R принадлежит R, и мощность R пересечена
[22:44.540 --> 22:52.700]  с A больше либо равняется Epsilon на мощности A. Ну или можно обозначить мощность A буквы N,
[22:52.700 --> 22:59.580]  тогда здесь будет Epsilon умножить на N. Ну, в общем, будем действовать так же точно, как мы действовали
[22:59.580 --> 23:05.180]  с треугольниками на плоскости. Мы просто возьмем какое-то множество точек в X и будем его
[23:05.180 --> 23:12.180]  пересекать со всевозможными областями, то есть это часть проекции R на A. Но это не вся проекция,
[23:12.180 --> 23:17.980]  только проекция, состоящая из тех пересечений, которые черпают изрядную долю от исходного
[23:17.980 --> 23:37.540]  множества. Понятно? Вот давайте назовем множество N из A, называется в этой науке Epsilon-сетью,
[23:37.660 --> 23:48.500]  называется Epsilon-сетью, если оно является SOP для вот этой совокупности, если N это система
[23:48.500 --> 24:00.340]  общих представителей для вот этой совокупности. Просто такой терм. Нас интересовала SOP,
[24:00.340 --> 24:08.220]  но вот мы будем говорить Epsilon-сетью, потому что в этой науке так принято. Вот у нас есть A,
[24:08.220 --> 24:13.780]  мы его пересекаем только со значимыми такими R, чтобы значимыми, в смысле, что они черпают
[24:13.780 --> 24:20.380]  значимую часть от исходного A, вот эту Epsilon-часть, и хотим построить такую систему представителей,
[24:20.580 --> 24:29.460]  она называется Epsilon-сетью. То самое у нас интересовало для треугольников, для тех же самых.
[24:29.460 --> 24:43.820]  Вот теорема, доказанная вапникам и черванингисам, фактически доказанная ими. Они немножко в других,
[24:43.820 --> 24:49.660]  как говорили, у них там были статистические оценки какие-то, я про это сейчас не буду. В
[24:49.660 --> 24:55.020]  такой формулировке, как я сейчас ее даю, скорее она доказана двумя иностранцами, но, в общем,
[24:55.020 --> 25:07.500]  это сейчас не так существенно. Давайте я фамилию напишу. Так вот их зовут, Faustler и Wenzel. Но это
[25:07.500 --> 25:12.380]  фактически в общем вапник и черванингис, просто переписаны на соответствующем языке.
[25:12.380 --> 25:23.700]  Значит, утверждение такое, если ВС-размерность пространства XR не больше какого-то D,
[25:26.700 --> 25:39.100]  то для любого N и для любого A из X мощности N существует Epsilon-сеть,
[25:43.260 --> 25:51.020]  но тут надо, видимо, было вставить для любого Epsilon 0.1. Забыл по Epsilon-Quantrum написать.
[25:51.020 --> 25:56.620]  Для любого Epsilon, для любого N и для любого множества мощности N существует Epsilon-сеть
[25:56.620 --> 26:14.860]  размера не больше чем 8D на Epsilon, лог двоичный от 8D на Epsilon. Ну, дайте я еще верхнюю целую
[26:14.860 --> 26:24.060]  часть на всякий случай нарисую, чтобы точно было правильно. Ну, мини-катарсис обещан,
[26:24.060 --> 26:35.940]  вот он сейчас будет, сию секунду. Вот у нас граница для размерности 3, 60. Вот умножьте ее на 8 и вы
[26:35.940 --> 26:45.100]  получите 500 из прошлой лекции. Ну, я писал там, теорема была, что для треугольников оценка 500
[26:45.100 --> 26:59.140]  поделить на Epsilon, лог двоичный 500 поделить на Epsilon. Для треугольников получаем как раз теорему,
[26:59.140 --> 27:11.980]  сформулированную как затравка, на прошлой лекции. Получаем, на Epsilon, лог двоичный 480 на Epsilon,
[27:11.980 --> 27:18.260]  но я в прошлый раз написал 500, потому что и так оценка завышена, ну подумаешь 2, прибавить для
[27:18.260 --> 27:29.900]  ровного счета. Получилось 500. Ну, это, конечно, не полный катарсис, потому что теперь нам предстоит
[27:29.900 --> 27:35.900]  доказывать эту теорию, но, по крайней мере, я объяснил, что она порождает это следствие за
[27:35.900 --> 27:40.660]  счет грубости тех оценок, которые мы сейчас получили. Так, это я объяснил, понятно, да,
[27:40.660 --> 27:46.780]  как получилось. Это действительно следствие отсюда, просто в общем случае. Все, ну теперь наша
[27:46.780 --> 27:52.740]  цель доказать теорему ваплика Червоненкеса или Хауссера и Вельцля вот в этом виде. У нас есть
[27:52.740 --> 28:03.620]  какое-то A, мощность его равна N. Давайте вот это обозначим буквой M, вот эту верхнюю целую часть,
[28:03.620 --> 28:16.940]  которая послужит оценке размера SOP. Давайте ее обозначим M. Давайте построим, в кавычках построим,
[28:16.940 --> 28:30.340]  выберем, наверное, лучше говорить случайное, мульти множество, ну или можно сказать размещение
[28:30.340 --> 28:37.900]  с повторением. Наш стандарт. В терминологии построим случайное размещение с повторением
[28:39.900 --> 28:56.260]  N, состоящее из элементов x1 и так далее, xn таких, что каждая x и t принадлежит нашему. Так,
[28:56.260 --> 29:02.780]  ну что это значит? Это значит, что мы просто, есть еще один термин, делаем такую выборку с
[29:02.780 --> 29:13.500]  возвращением. То есть мы берем и за случайные элементы, ну какой-то, x1. Он берется с вероятностью,
[29:13.500 --> 29:25.340]  ой, тут не N, а M, конечно. Он берется с вероятностью 1 поделить на N. Это 1 поделить на N, на число
[29:25.340 --> 29:31.460]  элементов. Просто выбираем на угад случайные элементы за. И возвращаем его на место,
[29:31.460 --> 29:39.700]  после чего снова выбираем незавидимые. 1 от 2 там и так далее, элементы за. То есть они, в принципе,
[29:39.700 --> 29:47.100]  все могут совпасть. Но я утверждаю, что с положительной вероятностью то, что мы
[29:47.100 --> 29:57.420]  навыбираем, в общем и будет системой представителей. Не, ну идея-то тривиальная, стандартный
[29:57.420 --> 30:02.580]  вероятностный метод. Давайте возьмем случайное множество и докажем, что оно такое, как нам нужно,
[30:02.580 --> 30:10.260]  что оно таки образует соп. Заметьте, что идея здесь не такая, как в истории с сопами, которые были
[30:10.260 --> 30:16.380]  общими. То есть там мы делали жадный алгоритм, случайность мы использовали совершенно для другого,
[30:16.620 --> 30:22.340]  а вот в теореме в Африка черваненки со случайность как раз очень падит. Мы берем случайные элементы,
[30:22.340 --> 30:28.820]  они могут совпасть, но понимаете, если они совпадут, ну мы их при желании отождествим,
[30:28.820 --> 30:36.420]  просто совпадающий, но он такой только меньше станет. Нам-то нужно как можно меньшую соп построить.
[30:36.420 --> 30:45.580]  Если какие-то совпадут, нам это только на руку. Вот. Так, понятно все, что происходит.
[30:45.580 --> 30:52.140]  Ну очень хорошо. Давайте рассмотрим вредное событие.
[30:56.900 --> 31:03.820]  Ну ладно, вредное событие, но событие, вероятность которого хотелось бы, чтобы было меньше единицы. То есть
[31:03.820 --> 31:10.380]  мы посмотрим на ситуацию, когда случилось не то, чего мы хотели. Что из себя представляет такое
[31:10.380 --> 31:17.060]  событие? Элементарными исходами в нашем вероятностном пространстве сейчас являются вот эти n большое.
[31:17.060 --> 31:23.700]  Размещение с повторением. Каждое размещение с повторением это элементарное событие. Поэтому
[31:23.700 --> 31:30.900]  вредное событие, давайте я его обозначу e1, там потом еще будет e2, готовьтесь. Значит вредное
[31:30.900 --> 31:39.340]  событие e1 это множество таких размещений n, то есть множество таких элементарных исходов,
[31:39.340 --> 31:49.180]  все корректно, все грамотно. Множество таких элементарных исходов, что существует r принадлежащее a,
[31:49.180 --> 32:00.460]  такое, что r пересеченная с a имеет мощность больше либо равную epsilon n, но давайте я прямо
[32:00.460 --> 32:08.380]  но напишу, чтобы было понятно в чем тут вредность, вредность этого события. Но r пересеченная с n большое,
[32:08.380 --> 32:16.900]  пусто. Ну то есть n большое не оказалось системой представителей, не оказалось epsilon сетью.
[32:21.220 --> 32:29.100]  А, r конечно не из a, да, rsr, да, извините. Спасибо, да, это опечатка, конечно, rsr большого. Найдется
[32:29.100 --> 32:35.340]  такая область, которая пересекается с множеством a как нужно по значимой доле, по epsilon доле,
[32:35.340 --> 32:47.100]  но тем не менее вот с n большое она-то не пересекается. Это вредное событие, если мы
[32:47.100 --> 32:55.660]  докажем, что вероятность e1 меньше единицы, мы победим. Ну вот тут вот делается некий
[32:55.660 --> 33:00.380]  опередной хитрый ход комбинаторно-веронятностный, до которого так вот сходу не додумаешься,
[33:00.380 --> 33:08.860]  просто так оценить сложно. Делаем надстройку некую, некую вероятностную надстройку. Ну это
[33:08.860 --> 33:15.700]  в каком смысле напоминает то, что мы в прошлом семестре делали, когда какие-то клики там
[33:15.700 --> 33:21.380]  выбирали, когда красили граф случай, там дополнительную случайность добавляли. Сейчас
[33:21.380 --> 33:27.020]  тоже добавим некую дополнительную случайность. А именно давайте теперь рассмотрим помимо n
[33:27.020 --> 33:39.340]  большого еще t большое. Я его всегда обозначаю. Оно будет состоять из y1, yм и тут тоже y и t принадлежат
[33:39.340 --> 33:45.700]  a. То есть это опять такое вот мультимножество размещения с повторениями, в котором элементы
[33:45.700 --> 33:53.140]  могут совпадать. Каждый элемент выбирает вероятностью 1n. То есть t это то же самое,
[33:53.140 --> 33:59.500]  что n. Просто еще одно такое вот случайное множество, построенное независимо от того,
[33:59.500 --> 34:04.380]  каким было выбрано n большое. Оно может с ним совпасть, может быть вообще не пересекается,
[34:04.380 --> 34:12.220]  ну как угодно. Возьмем дополнительное случайное мультимножество. Ну, конечно, я мог с самого
[34:12.220 --> 34:17.540]  начала сказать, давайте его возьмем. E1 в этом случае как определяется? Это точно так же. Просто
[34:17.540 --> 34:26.300]  элементарные вплоды это не n большое, а пары n большое и t большое. А дальше-то все то же самое.
[34:26.300 --> 34:39.140]  От этого ничего не сказано. T любое. Не, ну E1 просто надо переинтерпретировать, потому что у нас
[34:39.140 --> 34:45.180]  изменилось вероятностное пространство. Если сначала оно состояло просто из n, то теперь оно состоит
[34:45.180 --> 34:55.180]  из пар. Нет, ну плохое событие. Давайте теперь вот здесь вот так напишем просто n и t такие же.
[34:55.180 --> 35:02.340]  Никакого условия на t тут нет. Вот это вот плохое событие. Смотрите, ну недаром же я ввел t. Значит,
[35:02.340 --> 35:09.460]  как я и обещал, будет некое событие, которое еще существенным образом будет зависеть от t. Но я
[35:09.460 --> 35:19.020]  говорил, будет E2. Пишем E2. Ну это, естественно, снова множество пар mt. И начало будет прямо
[35:19.020 --> 35:26.860]  идентичное тому, что написано в E1, то есть существует r. Такое, что r пересеченное с a,
[35:26.860 --> 35:43.180]  но r пересеченное с n пусто. Давайте еще один союз добавим. Но r пересеченное с n пусто, а r пересеченное
[35:43.180 --> 35:56.780]  с t имеет мощность больше-либо равную epsilon m пополам. m это вот ожидаемый размер 100 epsilon сетей.
[36:00.060 --> 36:08.340]  Так, здесь r это союз, а r пересеченное с n пусто, а r пересеченное с t большое. Тут важнее не то,
[36:08.340 --> 36:15.360]  что а это союз, а то, как понимать мощность r пересеченного с t. Вот это вот,
[36:15.360 --> 36:28.740]  будьте очень внимательны, имеется в виду с учетом кратности. Нет, смотрите,
[36:28.740 --> 36:33.780]  n по постранению содержит ровно mei элементов, которые могут совпадать, но от этого их только
[36:33.780 --> 36:40.500]  меньше станет тогда. Оно по постранению того самого размера, какого мы и хотим. И наша цель
[36:40.500 --> 36:45.340]  доказать, что с положительной вероятностью это и epsilon сеть просто, что нам mei хватит для того,
[36:45.340 --> 36:49.860]  чтобы этого доказать. Вот мы взяли вредное событие, у которого вероятность хотелось бы,
[36:49.860 --> 36:57.820]  чтобы было меньше единицы, тогда будет реализован наша цель. Мы добавили к нему некую дополнительную
[36:57.820 --> 37:02.580]  рандомизацию, сделали еще одно вредное событие, в котором зачем-то добавили вот это t.
[37:03.780 --> 37:10.740]  Но, сейчас вы поймете, чего это нужно, сейчас все будет понятно. Ну вот так вот написано,
[37:10.740 --> 37:16.820]  я еще раз подчеркиваю, здесь модь понимается как сумма индикаторов. То есть, если очередной
[37:16.820 --> 37:23.460]  элемент с t попадает в r, неважно, был уже он учтен ранее или не был, мы добавим единичку к сумме.
[37:23.460 --> 37:30.380]  Учетом кратности, то есть, сколько раз там эти элементы попадают, столько раз посчитаем.
[37:34.660 --> 37:42.420]  Ну, ключевая лемма, ну не ключевая, ключевая чуть позже, но ключевая для понимания,
[37:42.420 --> 37:48.900]  как вот с этим е2 бороться. Значит, лемма утверждает, что, давайте так,
[37:50.900 --> 37:56.700]  давайте вот как, смотрите, е2 и е1, как они соотносятся, что из чего следует.
[37:56.700 --> 38:09.580]  Что? Е2 это подмножество е1, да? Е2 это подмножество е1. То есть, что из чего следует?
[38:09.580 --> 38:22.780]  Из е2 следует е1. Ну вот, давайте так, вероятность е1 при условии е2, наверное, я так напишу,
[38:26.700 --> 38:37.740]  больше либо равняется 5 шестых. Ну, 5 шестых это я просто так получу, сейчас я просто знаю,
[38:37.740 --> 38:41.700]  что у меня получится 5 шестых, но могу, что? Плохо написал?
[38:41.700 --> 38:53.620]  Наоборот, сейчас, я вот рассуждал, рассуждал, и из е2 следует, а, ну да, рассуждал, рассуждал,
[38:53.620 --> 39:00.980]  и да, рассуждал, да, это правда, это один просто, да, хорошая лемма, это один. Нет, замечательно
[39:00.980 --> 39:05.780]  другое, да, согласен, рассуждал, рассуждал, и все равно неправильно написал. Да, да, да,
[39:05.780 --> 39:14.540]  меньшее событие при условии, большее, да, да. Мы уже знаем, что вот это выполнилось,
[39:14.540 --> 39:21.220]  что вот это выполняется, вероятно, меньше 5 шестых. То есть, мы ввели вроде как дополнительную
[39:21.220 --> 39:28.020]  случайность, и вот это вот событие, оно чем-то таким вот дополнительным, но вероятность не сильно
[39:28.020 --> 39:35.020]  меняется, то есть, можно по-другому сказать, что мы возьмем вероятность е2 пересеченного с е1,
[39:35.020 --> 39:42.940]  поделим на вероятность е1, получим больше либо равно 5 шестых, из этого следует, так вот,
[39:42.940 --> 39:52.220]  следовательно, вероятность е2, которая является под множеством е1, больше либо равняется 5 шестых,
[39:52.220 --> 39:58.900]  на вероятность е1, ну и читаем дальше в обратную сторону, то есть, что вероятность е1 не больше
[39:58.900 --> 40:06.620]  чем 1,3 и множество на вероятность е2, иначе целью в конечном счете будет доказать вероятность
[40:06.620 --> 40:09.460]  е2, ну скажем, меньше там, 1 и 2.
[40:15.700 --> 40:22.260]  Из леммы следует, вот я сейчас написал, что достаточно теперь оценить сверху вероятность е2 чем-то,
[40:22.260 --> 40:33.140]  ну хотя бы в одну целую две десятых раз меньше 1, ну там в два раза, это потом, а сейчас надо
[40:33.140 --> 40:38.860]  лему доказать, ну вы поняли, зачем лему, то есть, вот мы вроде так оснастили событие чем-то дополнительным,
[40:38.860 --> 40:45.380]  это поможет нам доказать потом вторую ключевую лему, но главное, что вот это оснащение не привело
[40:45.380 --> 40:51.540]  к значительному изменению вероятности всего там 5 шестых, 6 пятых раз, ну смотрите, вот мы знаем,
[40:51.540 --> 41:00.500]  что выполнилось событие е1, то есть, мы знаем, что найдется какое-то R, которое цепляет А,
[41:00.500 --> 41:11.420]  как надо, и которое пусто пересекается с N. Про что нам говорит условная вероятность? Что,
[41:11.420 --> 41:19.860]  тем не менее, T из этого R черпает много, я думаю, что надо вот здесь, прямо здесь эту картинку
[41:19.860 --> 41:26.740]  нарисовать, чтобы было понятно, как жизнь устроена, есть X, объемлющее пространство, мы живем,
[41:26.740 --> 41:32.900]  на самом деле, только внутри А, у нас ничего вне А не происходит. Так, все понимают, что все
[41:32.900 --> 41:39.340]  находится внутри А, потому что элементы из N я беру из этого множества, но мощность N маленькая,
[41:39.340 --> 41:45.980]  и я из него выбрал какие-то M-штук элементов, из него выбрал какие-то M-элементов, может быть,
[41:45.980 --> 41:56.700]  совпадающих, вот они образуют N, не образуют N. Вот существует R, это R, которое вот здесь,
[41:56.700 --> 42:06.180]  содержит хотя бы ε умножить на N элементов, и нам хочется посчитать, вот в этом месте,
[42:06.180 --> 42:12.540]  вероятность того, что R, пересеченное с T, в упомянутом смысле, с учетом кратности,
[42:12.540 --> 42:25.580]  не меньше, чем εM пополам. T выбирается независимо от M, мы считаем вероятность того,
[42:25.580 --> 42:43.980]  что отсюда выбрано хотя бы εM пополам или нет. Так, я пишу, вероятность E2 при условии E1 равна,
[42:43.980 --> 42:51.340]  я так не пишу, вероятность того, что R, пересеченное с T, больше либо равняется
[42:51.340 --> 42:56.860]  εM пополам, где понятно, что такое R, то есть никаким квантера рисовать не нужно. Мы взяли
[42:56.860 --> 43:02.260]  то самое R, которое существует и хотим, чтобы оно с T теперь пересекалось не меньше, чем по
[43:02.260 --> 43:15.380]  εM пополам элементов. Так, я утверждаю, что это не меньше, чем вероятность того, что бином от
[43:15.380 --> 43:37.060]  εM. Нет, не εM, неправильно. Сейчас, секунду, подождите. Бином, бином, бином, бином, конечно от N.
[43:37.060 --> 43:52.540]  Бином, конечно, от N, а вот здесь вот ε больше либо равняется εM. Да ёлки-палки! Нет, нет, от M,
[43:52.540 --> 44:00.500]  что-то я положаю малость вот так. Бином, сейчас поясню всё, просто написал неверно,
[44:00.500 --> 44:05.380]  но сейчас всё поясню. Значит, бином что такое? Это биномиальная случайная величина с параметрами
[44:05.380 --> 44:12.940]  M и ε. Нормально такое обозначение? Ну, конечно, строго говоря, я должен был написать там какое-то
[44:12.940 --> 44:18.900]  кси, которое имеет такое распределение биномиальное, но я, с вашего позволения, напишу так.
[44:18.900 --> 44:24.900]  Биномиальная величина какая-то, которая имеет вот такое биномиальное распределение, принимает
[44:24.900 --> 44:33.500]  значение не меньше, чем εM пополам. Почему? Потому что смотрите, как T, большой элемент вот этого
[44:33.500 --> 44:44.220]  T большого попадает сюда. Мы элементы вот этого T большого выбираем один за другим, независимо
[44:44.220 --> 44:51.860]  друг от друга. Выбираем очередной, ну, например, первый элемент. Он либо сюда попадает, либо
[44:51.860 --> 45:03.580]  не попадает. Попадает успех, не попадает неудача. И вот эта вот R, пересечённая с T мощность,
[45:03.580 --> 45:12.980]  это число успехов в такой схеме испытаний. Бернули. Попал, не попал, попал, не попал. Испытаний,
[45:12.980 --> 45:24.300]  конечно, M штук. Потому что мы раз выбираем элемент. Понятно? Испытаний M штук мы элементов
[45:24.300 --> 45:30.380]  выбираем. А с какой вероятностью случается успех в очередном испытании? То есть с какой вероятностью
[45:30.380 --> 45:40.540]  этот элемент попадает вот сюда? Не меньше, чем N ε, делить на N. То есть не меньше, чем ε. А я
[45:40.540 --> 45:47.980]  написал в точности ε, поэтому знак неравенства сюда. Ну, тут вероятность успеха не меньше,
[45:47.980 --> 45:53.620]  чем вероятность успеха здесь. Поэтому число успехов большое, с тем не меньше, так сказать,
[45:53.620 --> 46:03.220]  вероятность. Ну, с тем больше, если хотите, вероятность. Понятно? Вот. Очень хорошо. Сейчас
[46:03.220 --> 46:11.220]  применим неравенство Чебушкова. Так, ну вы знаете, конечно, мат ожидания этой штуки от
[46:11.220 --> 46:18.980]  ε умножить на M. Давайте его вычтем слева и справа. Мы получим вероятность того, что бином наш,
[46:18.980 --> 46:33.580]  от M ε, минус его мат ожидания, больше либо равняется, εM попало. Ну, на самом деле,
[46:33.580 --> 46:41.380]  это надо вот так переписать. Это равно 1 минус вероятность того, что это же самый бином от M
[46:41.380 --> 47:02.900]  ε, минус M ε. Ой, рана. Меньше либо равняется, минус εM попало. Еще раз? Ну, хотим, наверное. Я
[47:02.900 --> 47:08.620]  уже в этом плане неаккуратен, но как бы смысл-то понятен. Я прошу прощения, да, но формально надо
[47:08.620 --> 47:14.540]  поставить строгую. Ну, неважно. Неравенство Чебушкова работает всегда и со строгим неравенством,
[47:14.540 --> 47:20.420]  и с нестрогим. Оно, конечно, верно. Смотрите, величина случайная уклоняет от своего среднего,
[47:20.420 --> 47:29.860]  но в данном случае влево на какое-то расстояние. Вот там, как говорится, модуль разности,
[47:29.860 --> 47:37.860]  случайная величина, ее мат ожидания. Давайте я напишу. Какая-то кси, минус екси, больше либо
[47:37.860 --> 47:44.900]  равняется, либо больше строго, пусть хорошо, а не превосходит dc поделить на а в квадрате. Вот это
[47:44.900 --> 47:51.740]  вот неравенство Чебушкова. Ну, его надо знать. Это такая вещь, совершенно стандартная. Вероятность
[47:51.740 --> 47:58.020]  уклониться, уйти далеко маленькая. Ну, вот в терминах дисперсии. Ну, здесь мы говорим,
[47:58.020 --> 48:02.100]  что не весь модуль ушел, а только в одну сторону она ушла. Ну, все равно она маленькая, даже не
[48:02.100 --> 48:10.980]  больше вот это. Ну, значит, все больше либо равняется, нежели 1 минус дисперсия кси поделить на
[48:10.980 --> 48:19.980]  епсилон м пополам в квадрате. А у нас это епсилон м пополам. Какая дисперсия у кси? Тоже извините.
[48:19.980 --> 48:29.820]  Дисперсия это м на епсилон и на 1 минус епсилон. Ну, обычно люди помнят НПКУХ. НПКУХ все, по-моему,
[48:29.820 --> 48:38.220]  полностью. Ну, тут вот П это епсилон. Дайте я тут напишу. Дисперсия кси, она не больше чем м
[48:38.220 --> 48:45.420]  епсилон, потому что я просто хочу пренебречь разностью 1 минус епсилон. Она равна м епсилон 1
[48:45.420 --> 48:51.620]  минус епсилон, значит, она не больше чем м епсилон. Продолжаем неравенство в нужную сторону. Получаем,
[48:51.620 --> 49:02.140]  что это не меньше чем 1 минус м епсилон поделить на м епсилон пополам в квадрате и это равно 1 минус
[49:02.140 --> 49:12.460]  4 поделить на м епсилон. В этом месте допускаем грубую совершенно оценку. Смотрите, м я хранил
[49:12.460 --> 49:21.240]  бережно. Так, м епсилон, давайте я тут выпишу, м епсилон не превосходит. Нет, почему не
[49:21.240 --> 49:27.020]  превосходит? Больше либо равно. Нам нужно больше либо равно, потому что дробь будет не больше, а со
[49:27.020 --> 49:32.860]  знаком минут снова больше либо равно. Нам нужна оценка именно в эту сторону. Значит, м епсилон
[49:32.860 --> 49:40.180]  больше либо равняется просто 8d на епсилон лог двоичный 8d на епсилон. Собственно, ради этого я
[49:40.180 --> 49:47.500]  рисовал именно верхнюю целую часть. Так, хорошо, а это я сейчас по-дурацки оцениваю. Это знаете,
[49:47.500 --> 49:59.820]  что больше либо равно? Это что? Хуже того, это больше либо равно 8 на лог двоичный 8. Ну да,
[49:59.820 --> 50:06.780]  больше либо равно 1 епсилон меньше одного. В данном месте я действую очень грубо. Ну,
[50:06.780 --> 50:18.380]  лог двоичный 8 это 3, 3х8 это 24. Получаем равно 1 епсилон на 24, это 5-6. Ну, я знал.
[50:27.260 --> 50:33.940]  Ну, неважно, в общем, получили. Лемму победители несут. Ну и сейчас будет ключевая лемба,
[50:33.940 --> 50:38.300]  которая фактически нам завершит доказательства по модулю какой-то скучной выкладки, которую я
[50:38.300 --> 50:45.380]  пропущу и вам разрешу не производить на экзамен. Ну, она будет понятна совершенно, просто зачем
[50:45.380 --> 51:08.460]  и как раз непонятно. Сейчас, чтобы нам стереть. Лемму давай. Лемма. Это еще одна лемма. Ну,
[51:08.460 --> 51:15.820]  я что-то не стал их в этом году нумеровать. Какая разница? Один, два. Их всего четыре. Две уже
[51:15.820 --> 51:21.580]  давно прошли. Сейчас вот две для теоремы. Одну доказали. Сейчас вот вторая. Ну, по сути,
[51:21.580 --> 51:32.060]  ключевая, конечно, вот эта. Ключевая, говорит следующая, вероятность Е2 не больше, чем g от 2d.
[51:32.060 --> 51:49.980]  Сейчас неправильно пишу. Спокойно, не коротимся. Так, g от чего? От 2m, наверное. Сейчас, сейчас,
[51:49.980 --> 52:03.820]  сейчас. g это понятно, это вот та самая функция, которая сумма цешет, помните? Я сейчас соображу,
[52:03.820 --> 52:13.020]  с какими параметрами она. Так, она n и d, то есть там должна быть некая мощность и размерность. Ну,
[52:13.020 --> 52:23.500]  так размерность, это наша размерность какая-то еще может быть. Вот так. 2md на 2 в тепени минус
[52:23.500 --> 52:34.140]  εm попало. Вот такая штука. Это вот ключевая лемма. Тут каким-то образом сейчас должна вылезти
[52:34.140 --> 52:40.780]  размерность вапника-червоненкиса, которую мы нигде пока не используем. Вот понимаете, да, друзья,
[52:40.780 --> 52:46.300]  что мы нигде пока размерность вапника-червоненкиса не используем. Вот она здесь вылезает. Но я считаю,
[52:46.300 --> 52:53.140]  что все-таки именно эта лемма ключевая. Скоро она здесь вылезает. 2m и d на 2 в тепени минус
[52:53.140 --> 53:00.460]  εm попало. Смотрите, давайте прежде чем доказывать эту лемму, поймем качественно, почему она решает
[53:00.460 --> 53:09.620]  нашу задачу, то есть доказывает в итоге теорему, которая частично видна. Почему эта лемма ее,
[53:09.620 --> 53:15.660]  по сути, доказывает? Ну, вы помните еще, наверное, что наша-то цель доказать, что вероятность E2 меньше
[53:15.660 --> 53:22.900]  там, чем 5-6. Ну, чем одна-вторая. Не важно. Если вероятность E2 относительно маленькая,
[53:22.900 --> 53:30.060]  то вероятность E1 вследствие предыдущей леммы тоже меньше единицы, и все хорошо. Ну, смотрите,
[53:30.060 --> 53:41.900]  это же меньше, как мы знаем, чем 2m в тепени d, умножить на 2 в тепени минус εm попало. Ну,
[53:41.900 --> 53:50.700]  и все. То есть вы не глядите воловьими очами, так сказать, на то, как выглядит вот это M сейчас.
[53:50.700 --> 53:55.740]  Вот на него пока не глядите, а то это действительно будет только грусть и изумление вызывать. Ну,
[53:55.740 --> 54:01.180]  сходу-то не очевидно. Вы глядите именно сюда, вот примерно как я доказывал вторую лему из
[54:01.180 --> 54:07.260]  первой серии лемм, которая еще была до теоремы. Вот как я говорил, это степенная функция, а это
[54:07.260 --> 54:14.220]  показательная. То есть эта функция это M в какой-то фиксированной степени, а эта функция это 2 в
[54:14.220 --> 54:23.460]  тепени минус с точностью до константы M. Она убывает по M экспоненциально, ε нам дано,
[54:23.460 --> 54:28.580]  оно зафиксировано. D тоже зафиксировано, это размерность нашего пространства. Но эта
[54:28.580 --> 54:35.260]  функция растет по M, как степень, как 2m в степени D. Поэтому ясно, что начиная с какого-то момента,
[54:35.260 --> 54:40.940]  который зависит только от D и от ε, эта штука будет меньше, чем одна вторая, чем что хотите.
[54:40.940 --> 54:49.540]  Ну, в конечном счете с огромным. Просто вот эта вот функция, которая здесь выписана, 8d на
[54:49.540 --> 54:57.900]  ε, лог 2-ичный 8d на ε, как раз подобрана таким образом, чтобы вот это произведение оказалось меньше одной
[54:57.900 --> 55:09.180]  и второй. Но это можно проверить. Но это скучно. Не, ну это примерно понятно, почему она именно такого
[55:09.180 --> 55:16.540]  вида, там можно прологрифмировать вот это выражение, посмотреть, когда D лог 2-ичный М,
[55:16.540 --> 55:23.940]  это примерно εM попало, когда они примерно совпадают. Вот можно догадаться, что функция имеет тот самый.
[55:23.940 --> 55:29.300]  Но формально, аккуратно проверять, что именно при подстановке тех вот логарифмов и прочее,
[55:29.300 --> 55:34.900]  тут получится меньше одной и второй, это как бы чуть скучно. Поэтому я не буду это спрашивать на
[55:34.900 --> 55:39.580]  экзамене и сам не хочу это рассказывать. В этом серьезной умной математики нет. Ну,
[55:39.580 --> 55:46.420]  простой неравенец, надо прологрифмировать и посчитать. Поэтому все. Вот в этом месте
[55:46.420 --> 55:51.020]  я считаю, что матеорему завершили доказывать. Почему функция именно того вида, это в шпаргалке,
[55:51.020 --> 55:58.100]  будет написано, вам запоминать не нужно. Функция видна отсюда. Поэтому все, вот это пояснение
[55:58.100 --> 56:04.340]  завершено, и как только мы докажем эту немму, матеорема будет автоматом доказать. Правильно?
[56:04.340 --> 56:11.820]  Согласны? Потому что, я повторяю, я выкладку уже проводил. Надо доказать ключевой факт,
[56:11.820 --> 56:27.620]  так вот это связано с размером. Так, слушайте, ну моя задача успеть доказательства. Я очень
[56:27.620 --> 56:31.660]  надеюсь, что это получится. В крайнем случае, чуть-чуть задержу, постараюсь этого не делать.
[56:31.660 --> 56:37.980]  Посмотрим, как пойдет. Я что-то, видимо, разжевываю. Но мне ужасно хочется, чтобы всем было понятно,
[56:37.980 --> 56:44.820]  народу не очень много, но вроде как народ воспринимает то, что происходит. Поэтому разгоняться
[56:44.820 --> 56:53.500]  тоже как-то не хочется. Так, все, величина М нам уже не нужна. Важна суть. Суть сейчас попробую
[56:53.500 --> 57:01.260]  сказать какая, но, конечно, тут надо некий путь пройти. Так, Е2 у нас сохранилась, давайте введем
[57:01.260 --> 57:09.660]  событие, где бы мне его ввести. Я вот тут, наверное, его введу. Вот это вот назовем Е с индексом 2,
[57:09.660 --> 57:18.100]  запятая R. Ну, то есть, вот после квантора существования. Если мы зафиксировали как-нибудь
[57:18.100 --> 57:30.820]  R маленькое, R большое, то вот все вот это вот событие называется Е2R. Понятно? Что такое Е2R? Так,
[57:30.820 --> 57:42.340]  товарищи, вам понятно, что Е2 это просто объединение по всем R с R Е2R. Ну, потому что
[57:42.340 --> 57:47.260]  квантор существования, мне кажется, вы должны привыкнуть. Это всегда объединение существует,
[57:47.500 --> 57:57.580]  для какого-то хотя бы одного выполнено, значит, хотя бы одного. Значит, мы объединили. Верно? Но,
[57:57.580 --> 58:05.420]  черт, могу не успеть, потому что, видите, пытаюсь хорошо рассказать. Давайте немножко, вот это вот
[58:05.420 --> 58:13.540]  важно сейчас осознать, главное осознайте, поменяем схему выбора вот этой пары. Это очень важно
[58:13.540 --> 58:19.420]  осознать этот тонкий момент. Ну, до сих пор, как мы действовали, мы выбирали N, потом выбирали T.
[58:19.420 --> 58:27.780]  Друг от друга независимо. Я утверждаю, что то же самое вероятностное пространство можно получить
[58:27.780 --> 58:41.540]  в результате следующей схемы. Выбираем U, Z1 и так далее. Как 2M? Сравнивайте 2M, 2M. Так,
[58:41.540 --> 58:47.340]  то просто спокойнее было на душе, что дело идет к чему-то хорошему. Вот, выбираем случайное вот
[58:47.340 --> 58:55.420]  это мультимножество или размещение с повторениями, состоящих из 2M элементов множества А. Точно так же,
[58:55.420 --> 59:05.980]  то есть каждый элемент собирает все 1M. Это не будет парой N и T, это будет будущей парой. Как
[59:05.980 --> 59:14.420]  выбрать, что здесь N, а что здесь T? Ну, нет, надо взять случайное под множество мощность M.
[59:14.420 --> 59:24.820]  U это множество элементов А. Естественно, как и N это множество элементов А. Вот, смотрите сюда,
[59:24.820 --> 59:31.620]  и T это множество элементов А. Все вот эти затытые, они естественно тоже принадлежат А. Вероятность
[59:31.620 --> 59:40.260]  затытого, это снова 1 поделить на N, все как раньше. Но нам еще нужно разделить это на два куска. И вот
[59:40.260 --> 59:47.300]  чтобы разделить это на два куска, давайте просто выберем случайную половинку. Случайную, внимание,
[59:47.300 --> 59:57.300]  товарищи, уже в классическом смысле слова. Ну, тут C из 2M, по M половинок. Вот возьмем любую из них
[59:57.300 --> 01:00:12.020]  с вероятностью 1 поделить на и назовем ее N. А оставшуюся назовем T. Нет, нет, мы еще раз,
[01:00:12.020 --> 01:00:19.620]  мы запускаем схему выбора с возвращением, выбираем 2M. Некоторые из них могут совпадать,
[01:00:19.620 --> 01:00:26.740]  это не возбраняется. После чего вот это мультимножество бьем пополам, чайным образом,
[01:00:26.740 --> 01:00:32.780]  вот мультим такого распределения. Ну, то есть, если мультимножество состояло, например,
[01:00:32.780 --> 01:00:40.940]  из элементов 1, 1, не знаю, 2, 2, оно было мощностью 4, для примера, чтобы вы понимали, то у нас и вот это
[01:00:40.940 --> 01:00:46.780]  имеет вероятность одна шестая, и вот это имеет вероятность одна шестая, и вот это и так далее.
[01:00:46.780 --> 01:00:55.820]  Среди них бывают совпадающие, ну, что ж поделать. Ну, вот это 1, 2 имеет вероятность одна шестая,
[01:00:55.820 --> 01:01:03.900]  и вот это 1, 2 тоже имеет вероятность одна шестая. Мы каждую половинку берем с вероятностью одна
[01:01:03.900 --> 01:01:11.820]  шестая. Любую такую половинку, уже выбранную, называем N большой. Понятно сейчас, как схема
[01:01:11.820 --> 01:01:18.420]  устроена. Это будет то же самое, если сначала выбрать N, потом выбрать T. Это то же самое,
[01:01:18.420 --> 01:01:24.580]  как сразу выбрать два M элемента, потом раздробить пополам. Ну, если вдруг не очевидно,
[01:01:24.580 --> 01:01:29.740]  подумайте над этим. Это, в общем, такая вещь, которую надо осознать. У меня еще 10 минут есть,
[01:01:29.740 --> 01:01:34.700]  может я успею, может нет, это челлендж такой. Но понимаете, да, чего происходит? Можете,
[01:01:34.700 --> 01:01:41.060]  успеваете записать, как зафиксировать для себя, да? Отлично. Все, теперь смотрите,
[01:01:41.060 --> 01:01:55.660]  давайте я сделаю вот как. Вероятность E2, это, конечно, сумма по всем У. Вероятность E2 при
[01:01:55.660 --> 01:02:02.740]  условии У умножить на вероятность У. Называется то, что я написал формула полной вероякости.
[01:02:02.820 --> 01:02:15.780]  Вот, прелестно. Допустим, мы доказали, докажем. Дм – это докажем. Докажем такое вот нерадство.
[01:02:15.780 --> 01:02:25.020]  E2 при условии У не больше, чем 2 в степени минус Эпсалон М попало. Вот это мы докажем.
[01:02:25.020 --> 01:02:32.060]  Я это как-то прям вот так вот подчеркну. Я пока это не доказал, но мы это докажем. В раннем случае
[01:02:32.060 --> 01:02:37.780]  в следующий раз я не хочу комкать, но главное, чтобы было понятно, как логика устроена. Докажем,
[01:02:37.780 --> 01:02:43.980]  что вот эта условная вероятность не больше этой величины. Тогда формула полной вероякости там,
[01:02:43.980 --> 01:02:52.780]  что все вместе не больше, чем сумма по У. 2 в степени минус Эпсалон М пополам. А, правильное
[01:02:52.780 --> 01:03:04.460]  слово, да? Нет! Эх! Эх! Эх! Вот тут вот надо поправить. А, вот так вот. Ж от 2м,
[01:03:04.460 --> 01:03:10.620]  чего у нас там Д, да? Умножить, конечно. Да-да-да-да-да, извините. Е2 при условии
[01:03:10.620 --> 01:03:17.140]  Забыл сомножить. Ну, то же самое. Тогда у нас тут будет Ж от 2м. Д – нет, все хорошо, все хорошо.
[01:03:17.140 --> 01:03:30.620]  На вероятность У? Ну, все. Получится 2 в степени минус Эпсалон М пополам на Ж от 2м Д на
[01:03:30.620 --> 01:03:38.740]  сумму по У вероятности У, которая равна и делится. То есть, если мы докажем такое неравенство,
[01:03:38.740 --> 01:03:42.580]  которое я подчеркнул, то итоговое доказательство у нас в кармане.
[01:03:42.580 --> 01:03:53.740]  Вроде понятно, да? Я предельно аккуратно. Так, давайте попробуем это доказать. Смотрите,
[01:03:53.740 --> 01:03:59.860]  какой тут фокус. Вот сейчас главный катарсис, он содержится, конечно, тут. Условная вероятность
[01:03:59.860 --> 01:04:13.380]  Вероятность П от Е2. Это, как мы понимаем, вероятность объединения по РСР Е2ртых при условии У. Вот от
[01:04:13.380 --> 01:04:20.780]  сюда следствие. Е2 – это объединение Е2ртых. Просто переписал, что это объединение таких
[01:04:20.780 --> 01:04:31.180]  обозначений больше ничего. Хорошо? И вот сейчас будет ключевой момент. Я утверждаю, что если У зафиксировано,
[01:04:31.180 --> 01:04:37.260]  вот этот выбор мультимножистого из 2М элемента. Если мы зафиксируем, неважно какой, но зафиксировали
[01:04:37.260 --> 01:04:49.580]  У. Внимание, товарищ, какой ключевой момент. Вот в этом объединении реально не столько элементов,
[01:04:49.580 --> 01:04:58.380]  сколько всего элементов в Р большом. Ну, тут всего вроде как объединяется Р. Мощность Р
[01:04:58.380 --> 01:05:07.540]  большое множество событий. Я утверждаю, что разных событий, разных множеств в этом объединении как раз
[01:05:07.540 --> 01:05:19.060]  таки не больше, чем G от 2МД. А именно, я утверждаю следующее. Я утверждаю, что если, и это, по-моему,
[01:05:19.060 --> 01:05:37.220]  сейчас будет очевидно. Смотрите, если R1 из R и R2 из R таковы, что R1 пересеченная су равно R2 пересеченная
[01:05:37.220 --> 01:05:54.300]  су, то соответствующие события совпадают. E2R1 равно E2R2. Но надо какую-то филю нарисовать.
[01:05:54.300 --> 01:06:06.500]  Все при условии У, да. Ну, да, да, да, вот эти вот события при условии У совпадают. Понятно,
[01:06:06.500 --> 01:06:12.700]  говорю, нет? Смотрите, вот У, вот это У, оно там из 2М элементов, ну, неважно, оно из 2М,
[01:06:12.700 --> 01:06:21.380]  оно мультимножество какое-то. Вот представьте себе, что я не казал, как она сойдет в другую
[01:06:21.380 --> 01:06:28.380]  сторону, я уж не знаю. Ну, какие-то разные сардельки, вот одна такая, другая такая. Вот эта вот одна,
[01:06:28.380 --> 01:06:39.340]  а вот это вот сердечко, это другая. Но они одинаково пересекаются с У. И У уже зафиксировано,
[01:06:39.340 --> 01:06:45.220]  все, вот мы его забили тут гвоздями, оно выполнилось. Оно выполнилось. В чем стоит
[01:06:45.220 --> 01:06:51.220]  соответствующее событие E с двумя индексами? Оно же состоит не вот в этом, оно состоит вот в
[01:06:51.220 --> 01:06:57.060]  том, что тут написано, что R пересеченная с N пусто, а R пересеченная с T там, ну, большое в каком-то
[01:06:57.060 --> 01:07:06.540]  смысле. Но N и T, они же оба выбираются внутри У. Какая разница, как устроены R снаружи? Важно,
[01:07:06.540 --> 01:07:12.940]  как они устроены внутри, понимаете? Вопрос о том, пересекается R с N или не пересекается,
[01:07:12.940 --> 01:07:19.980]  вопрос о том, насколько мощно пересекается R и T, это только вопрос о вот этом кусочке множества R.
[01:07:19.980 --> 01:07:26.700]  И если этот кусочек один и тот же для разных R1, R2, то соответствующие события одинаковые.
[01:07:26.700 --> 01:07:36.660]  Ну, не знаю, по-моему, нормально объяснил. То есть, что это означает? Это означает, что нам
[01:07:36.660 --> 01:07:45.780]  надо доказать теперь, что E2R при условии U не превосходит 2 в степени минус Эпсилон М пополам,
[01:07:45.780 --> 01:07:51.620]  еще раз это подчеркну, уже два раза от того было отличие от предыдущего подчеркивания. Вот нам
[01:07:51.620 --> 01:07:58.860]  осталось доказать только это. Потому что если мы это доказываем, то всю вот эту вероятность мы
[01:07:58.860 --> 01:08:06.540]  оцениваем суммой вот таких чисел, и в этой сумме участвуют не все R, а только те, для которых
[01:08:06.540 --> 01:08:18.740]  вот эти пересечения Су разные. Не Су разные. Нет, все-таки Су разные. Су разные, да. Су разные,
[01:08:18.740 --> 01:08:29.340]  да. А сколько их? Их столько, сколько в проекции R на U. Вот разных столько, какова мощность проекции
[01:08:29.340 --> 01:08:36.840]  R на U. Так, все помните, что такое проекция R на U? Ну, это вот как раз вот эти пересечения,
[01:08:36.840 --> 01:08:43.460]  сколько их раз. Вот столько разных событий в этом объединении присутствует. Вероятность объединения
[01:08:43.460 --> 01:08:48.900]  не больше, чем сумма вероятностей, но, естественно, разных событий. Вот поэтому в сумме столько
[01:08:48.900 --> 01:08:55.820]  слагаемых, величина каждого из которых окажется не больше, чем вот эта экспонента. Ну, а это
[01:08:55.820 --> 01:09:00.780]  по лемме, которую мы сегодня, по следствию из леммы, с которой мы сегодня начали, это действительно
[01:09:00.780 --> 01:09:06.180]  больше, чем R2md, потому что мы живем в проекции размерности D теоремы. Так,
[01:09:06.180 --> 01:09:12.380]  формулирую таву 2m элементов. Это просто следствие из самой первой сегодняшней леммы.
[01:09:12.380 --> 01:09:18.380]  Приняне, лемма даже была доказана в прошлый раз, а сегодня мы вот это следствие явно написали.
[01:09:18.380 --> 01:09:24.460]  Слушайте, ну давайте в крайнем случае на несколько минут задержимся, вот это докажем. Осталось-то чуть
[01:09:24.460 --> 01:09:32.180]  ну совсем чуть, но нелепо это переносить на следующий раз. Так, куда бы только его писать?
[01:09:40.740 --> 01:09:46.460]  Так, ну картина даже есть. Вот это вот R пересеченное SU, и нас интересует вероятность
[01:09:46.460 --> 01:09:49.700]  того, что R пересеченное SN пусто, а R пересеченное ST такое.
[01:09:49.700 --> 01:09:57.860]  Смотрите, мы вот на это забьем вообще. В этом месте мы уберем вот это условие,
[01:09:57.860 --> 01:10:04.100]  ну потому что вероятность пересечения всегда не больше, чем вероятность каждого. И будем смотреть
[01:10:04.100 --> 01:10:12.900]  только сюда. То есть мы взяли вот этот вот кусочек R пересеченное SU и хотим, чтобы этот кусочек
[01:10:12.900 --> 01:10:22.340]  SN не пересекался. А нет, это неправильно. Не, неправильно говорю, я тут немножко запутал.
[01:10:22.340 --> 01:10:28.460]  Извините, наврал, наврал. А? Не-не-не, надо аккуратнее, сейчас надо аккуратнее. Смотрите,
[01:10:28.460 --> 01:10:34.700]  сейчас, сейчас-сейчас-сейчас. Надо еще аккуратнее сказать. Вот давайте мощность R пересеченного SU,
[01:10:34.700 --> 01:10:40.900]  ну что контрафис-то? Мощность R, вот это вот, размер вот этого куска. Знаете,
[01:10:40.900 --> 01:10:48.060]  обозначим какой-нибудь буквой K. Пускай, это мощность этого куска. Смотрите, если, сейчас надо
[01:10:48.060 --> 01:11:02.300]  аккуратнее, если K меньше, чем εM пополам, то интересующая нас вероятность равна нулю. Потому
[01:11:02.300 --> 01:11:10.660]  что не может такого быть, чтобы R пересеченное ST было большим. ST выбирается как по классической
[01:11:10.660 --> 01:11:17.700]  вероятности, понимаете, она не может быть большим. Сейчас почти закончил. Понимаете, да, вот она равна нулю.
[01:11:17.700 --> 01:11:24.220]  Ну это конечно меньше, чем два в степени минус εM пополам. То есть ноль он вообще красит в этом
[01:11:24.220 --> 01:11:32.460]  смысле. Поэтому давайте считать, можем считать, можем считать, что K больше либо равняется εM
[01:11:32.460 --> 01:11:38.780]  пополам. И вот теперь пренебрежем этим условиям, а будем смотреть только сюда. Вот теперь,
[01:11:38.780 --> 01:11:45.900]  оценивая нужную нам вероятность E2R при условии U. Забудем про это ограничение,
[01:11:45.900 --> 01:11:55.340]  оно дает дополнительное усиление неравенства. Ну, плевать мне. С какой вероятностью R пересеченное
[01:11:55.340 --> 01:12:12.140]  SN пусто. Нет, это совсем понятно. Это 2M минус K по M поделить на C из 2M по M. Понятно, да,
[01:12:12.140 --> 01:12:19.660]  почему? Мы большое выбираем как кусок мощности M вот отсюда. Мы должны его выбрать вот откуда-то
[01:12:19.660 --> 01:12:26.020]  отсюда. Вот эти M элементов должны не пересекаться с этими, а этих K штук. Ну,
[01:12:26.020 --> 01:12:33.940]  то есть C из 2M минус K по M поделить на C. M по M это вероятность того, что оно не пересекается.
[01:12:33.940 --> 01:12:39.380]  Вот здесь конечно не равно, а меньше либо равно, потому что, повторяю, мы пренебрегли вот этим
[01:12:39.380 --> 01:12:47.140]  условиям. Строго говоря, меньше либо равно равенство столкнемся. Ну, неравенство в нужную сторону.
[01:12:47.140 --> 01:12:50.180]  Осталось просто легкую выгоду провести, смотрите.
[01:12:50.180 --> 01:13:10.980]  У нас получается 2M минус K факториал на M факториал на M минус K факториал. Так,
[01:13:11.020 --> 01:13:24.020]  тут у нас будет 2M факториал на M факториал и на M факториал. По один мы кокнем, а дальше сделаем
[01:13:24.020 --> 01:13:32.940]  вот так. Это сократим с этим, а это сократим с этим. Вот так, крест на крест. Значит, сверху у нас
[01:13:32.940 --> 01:13:45.100]  вот тут останется M, M минус 1, M минус K плюс 1, а снизу у нас останется 2M, 2M минус 1,
[01:13:45.100 --> 01:13:54.540]  2M минус K плюс 1. Согласны? Ну, это простая выгодка, тут вроде все видно. А теперь смотрите,
[01:13:54.540 --> 01:14:08.700]  вот это 1,2. А это даже меньше, чем 1,2, потому что 2M минус 1 больше, чем 2M минус 2. Это меньше,
[01:14:08.700 --> 01:14:17.580]  чем 1,2. Это тем более меньше, чем 1,2. То есть все это меньше, чем 1,2 в катой степени K
[01:14:17.580 --> 01:14:24.700]  с множителями. Это равно 2 в минус катой, а K у нас больше либо равно epsilon M пополам,
[01:14:24.700 --> 01:14:30.180]  поэтому это не больше, чем 2 в степени epsilon M пополам, и все, теорема доказана.
