[00:00.000 --> 00:08.120]  Так, у нас остался небольшой должок с вами с прошлой
[00:08.120 --> 00:09.120]  лекции.
[00:09.120 --> 00:11.360]  Сейчас я тут подсотру немного.
[00:41.360 --> 00:43.600]  Ну ладно, немного подстёр.
[00:43.600 --> 00:46.840]  Должок-то какой, напомните, или мне самому вспоминать.
[00:46.840 --> 00:50.680]  Ну что-то я помню, там была вот такая сумма по t от
[00:50.680 --> 01:02.440]  2 до k-1, которая вот такая, c из n по k на c из k по t на
[01:02.440 --> 01:10.400]  c из n минус k по k минус t, на одну вторую степень 2
[01:10.400 --> 01:16.120]  т, минус c из t по 2.
[01:16.120 --> 01:17.120]  Как вам такое?
[01:17.120 --> 01:20.880]  Хотите так на экзамене помнить?
[01:20.880 --> 01:26.520]  Нет, ну там просто действительно всё легко, мы там считали,
[01:26.520 --> 01:29.920]  нас было множество из n вершин, мы фиксировали какие-то
[01:30.920 --> 01:36.320]  Потом из них выбирали t штук общих и потом добавляли
[01:36.320 --> 01:38.840]  ещё одну подсордельку размера k.
[01:38.840 --> 01:42.160]  Нам нужны были пары множеств мощности k, каждая из которых
[01:42.160 --> 01:45.280]  независима в случайном графе, поэтому мы сначала
[01:45.280 --> 01:49.040]  из n выбираем k, потом из k выбираем t общих, из n
[01:49.040 --> 01:52.640]  минус k выбираем k минус t оставшихся, а это вероятность
[01:52.640 --> 01:55.720]  того, что оба множества пересекающихся по t-вершинам
[01:55.720 --> 01:58.720]  являются независимыми, это можно в уме посчитать,
[01:58.840 --> 02:00.880]  поэтому я на самом деле не помню, а воспроизвожу.
[02:00.880 --> 02:04.720]  Друзья, это вам лайфхак такой на экзамен.
[02:04.720 --> 02:10.200]  Вот если поймёте как следует, что делается, то всё хорошо.
[02:10.200 --> 02:12.000]  Что я обещал доказать?
[02:12.000 --> 02:18.440]  Я обещал доказать, что если в качестве t взять двойку,
[02:18.440 --> 02:22.880]  взять двойку, то получится как раз та симптотика, которая
[02:22.880 --> 02:28.520]  анонсирована, то есть c из n по k на c из k по 2.
[02:28.840 --> 02:35.200]  На c из n минус k по k минус 2, на одну вторую в степени
[02:35.200 --> 02:38.160]  2 c из k по 2 минус 1.
[02:38.160 --> 02:40.120]  Чему а симптотически должно равняться?
[02:40.120 --> 02:44.600]  Вот это я сейчас не помню, но там через мю выражение
[02:44.600 --> 02:51.800]  какое-то, помните, ну подскажите мне, там через мю должно
[02:51.800 --> 02:52.800]  быть выражение.
[02:52.800 --> 03:04.240]  Как k в четвёртой мю в квадрате делить на, ну там м, наверное,
[03:04.240 --> 03:09.040]  было, да, я его перевозначил через n, да?
[03:09.040 --> 03:11.360]  Ну давайте я уж, чтобы вас не путать, здесь напишу
[03:11.360 --> 03:15.000]  тогда м, здесь тоже м, это я подзабыл.
[03:15.000 --> 03:22.040]  Ну k1, конечно, да, ну ладно, пусть будет k1, мне ужасно
[03:22.040 --> 03:25.800]  противно его таскать, но было бы k, это k1.
[03:25.800 --> 03:32.440]  Можем переобозначить k1, здесь м, здесь k1, здесь k1,
[03:32.440 --> 03:39.080]  а здесь м в четвёртой, да, вот так, в квадрате, вот
[03:39.080 --> 03:40.080]  так.
[03:40.080 --> 03:43.000]  Вот нам нужно это просто проверить, но это совсем
[03:43.000 --> 03:44.000]  легко.
[03:44.000 --> 03:52.160]  Давайте вспомним, что мю это c из m по k1 на 1 вторая
[03:52.160 --> 03:56.720]  c из k1 по 2, это правильно, да, такое же у нас мю, но
[03:56.720 --> 03:59.360]  мю это просто мат ожидания числа независимых множеств
[03:59.360 --> 04:06.040]  на k1 вершина, поэтому оно, конечно, такое, то есть фактически
[04:06.040 --> 04:17.800]  это k1 в четвёртой на m в квадрате на c из m по k1 в квадрате
[04:17.800 --> 04:24.600]  на 1 вторая 2 c из k1 по 2, я в квадрат возвёл, так только
[04:24.600 --> 04:27.240]  поделить что ли, а нет, это мю в квадрат, всё правильно,
[04:27.240 --> 04:30.200]  мю в квадратном числителе, да, поэтому делить не надо,
[04:30.200 --> 04:31.200]  надо умножать.
[04:31.200 --> 04:35.520]  Всё, ну надо просто разделить левую часть на правую и
[04:35.520 --> 04:39.600]  убедиться в том, что в пределе будет 1, ну сейчас разделим,
[04:39.600 --> 04:45.440]  у нас получается, так тут м тоже, у нас получается,
[04:45.440 --> 04:49.280]  что надо разделить, ох, как же это лучше написать,
[04:49.280 --> 04:56.400]  о, что тут очевидно, c из m по k1 в квадрате, если в
[04:56.400 --> 05:01.120]  знаменатель пошёл, давайте напишем вот так, c из m по
[05:01.120 --> 05:04.600]  k1, это я разделил на квадрат, вот эту первую степень,
[05:04.600 --> 05:07.040]  вот так получилось первая степень в знаменателе,
[05:07.040 --> 05:30.880]  дальше у меня будет c из k1 по 2, одна вторая, да, точно,
[05:30.880 --> 05:33.860]  ну давайте сейчас посчитаем, вот это нужно, там правильно
[05:34.060 --> 05:36.060]  написано, что одна вторая, потому что там было дельта
[05:36.060 --> 05:40.900]  пополам, дельта вычисляла количество упорядоченых,
[05:40.900 --> 05:43.580]  вот оно здесь такое пополам, вроде как действительно
[05:43.580 --> 05:46.820]  одна вторая, ну давайте пока посчитаем без одной второй,
[05:46.820 --> 05:50.120]  и я поправлю, если это потребуется, наверное поправлю, действительно
[05:50.120 --> 05:53.820]  вы правы, ну если одна вторая, ну давайте нарисую одну
[05:53.820 --> 05:56.400]  вторую, ладно, видимо вы правы!
[05:56.400 --> 05:59.760]  Ну тогда если одна вторая, тут надо что сделать, убрать
[05:59.760 --> 06:02.100]  что-ли эту минус единицу?
[06:02.100 --> 06:06.140]  Ну, вроде как на одну вторую в первую я умножаю.
[06:06.140 --> 06:07.140]  Что-то меня немножко это смущает.
[06:07.140 --> 06:12.420]  Ну, если убрать, тогда вообще вот шлёп-шлёп.
[06:12.420 --> 06:15.220]  Никакой одной второй вроде не остаётся.
[06:15.220 --> 06:16.220]  Интересное кино.
[06:16.220 --> 06:17.220]  Ну, сейчас посмотрим.
[06:17.220 --> 06:18.940]  Сейчас будем разбираться.
[06:18.940 --> 06:20.380]  C из K1 по 2 дальше.
[06:20.380 --> 06:25.860]  Здесь C из M минус K1 по K1 минус 2.
[06:25.860 --> 06:31.060]  И надо ещё разделить на K1 в четвёртый и умножить
[06:31.060 --> 06:33.060]  M в квадрате.
[06:33.060 --> 06:37.860]  Так, ну, сейчас я сократил правильно, да?
[06:37.860 --> 06:41.380]  То есть, если считать, что здесь стоит одна вторая,
[06:41.380 --> 06:44.020]  то одна вторая умножается вот на эту минус единичку
[06:44.020 --> 06:48.180]  на одну вторую в минус первой, и остаётся просто одна
[06:48.180 --> 06:50.860]  вторая в степени 2C из K1 по 2.
[06:50.860 --> 06:51.860]  Ну, делим.
[06:51.860 --> 06:52.860]  Вроде получается.
[06:52.860 --> 06:55.420]  Так, что же у нас происходит?
[06:55.420 --> 06:58.860]  Ну, понятно, что K1 стремится к бесконечности, потому
[06:58.860 --> 07:02.620]  что это удвоенный двоичный логарифм, он куда-то стремится.
[07:02.620 --> 07:07.660]  Поэтому C из K1 по 2 асимптатически это K1 в квадрате пополам.
[07:07.660 --> 07:13.220]  Так, дальше будет M в квадрате, то, что очевидно, потом я
[07:13.220 --> 07:18.420]  оставлю пока что C из M минус K1 по K1 минус 2.
[07:18.420 --> 07:23.420]  Так, а здесь C из M по K1.
[07:24.420 --> 07:29.420]  Это… и K1… а, K1 в четвёртый я ещё не нарисовал, что ли.
[07:29.420 --> 07:31.420]  K1 в четвёртый.
[07:31.420 --> 07:33.420]  Так, хлоп-хлёп.
[07:33.420 --> 07:37.420]  Это всё неплохо.
[07:37.420 --> 07:40.420]  Давайте вот эту дробь посчитаем отдельно.
[07:40.420 --> 07:44.420]  Хотелось бы, чтобы она получилась такой, как вы видите.
[07:44.420 --> 07:48.420]  То есть, K1 в квадрате, наверное, умножить на 2 и поделить
[07:48.420 --> 07:50.420]  на M в квадрате.
[07:53.420 --> 08:07.420]  Так, ну давайте.
[08:07.420 --> 08:11.420]  Ничего тут сложного нет, но всё-таки надо написать.
[08:11.420 --> 08:20.420]  C из M минус K1 по K1 минус 2 поделить на C из M по K1.
[08:20.420 --> 08:34.420]  Это M минус K1 M минус K1 минус K1 плюс 2 плюс 1.
[08:34.420 --> 08:40.420]  Бяк это как… поделить на K1 минус 2 факториал.
[08:40.420 --> 08:50.420]  А здесь M, M минус 1, M минус K1 плюс 1 и умножить на K1 факториал.
[08:50.420 --> 08:54.420]  Так, дорогие друзья, вы поняли, почему я закончил вверху в числителе
[08:54.420 --> 08:57.420]  именно таким саммножителем, каким закончил?
[08:57.420 --> 08:59.420]  И вообще прав ли я?
[08:59.420 --> 09:01.420]  Может, я ошибся.
[09:01.420 --> 09:03.420]  Ну как устроено произведение?
[09:03.420 --> 09:07.420]  Начинается оно с M минус K1, а заканчивается разностью
[09:07.420 --> 09:11.420]  вот этой величины и вот этой, но увеличенной на единичку.
[09:11.420 --> 09:15.420]  Но вот это написана разность, и она ещё увеличена на единичку.
[09:15.420 --> 09:17.420]  На самом деле, дорогие друзья, поднимите руки.
[09:17.420 --> 09:21.420]  Кто понимает, что вот этот числитель асимпатически равен
[09:21.420 --> 09:25.420]  просто M в степени K1 минус 2?
[09:25.420 --> 09:28.420]  Вот есть кто-нибудь, кому сходу очевидно, что числитель
[09:28.420 --> 09:34.420]  это просто M в степени количества скобок?
[09:34.420 --> 09:37.420]  Да, проблема в том, что K это в общем не константа.
[09:37.420 --> 09:40.420]  То есть если бы K была константой, все бы мгновенно подняли,
[09:40.420 --> 09:41.420]  я надеюсь, руки.
[09:41.420 --> 09:45.420]  Если вы перемножаете фиксированное количество саммножителей,
[09:45.420 --> 09:48.420]  из которых вычитаются какие-то константы,
[09:48.420 --> 09:52.420]  ну ясно, что асимпатически это будет просто M в степени
[09:52.420 --> 09:53.420]  количества саммножителей.
[09:53.420 --> 09:56.420]  Но здесь K1, это важное замечание, да,
[09:56.420 --> 09:59.420]  это асимпатически 2 лог 2-ичный M.
[09:59.420 --> 10:03.420]  То есть это не константа, это тоже функция от M.
[10:04.420 --> 10:07.420]  Тем не менее, я утверждаю, что эта функция настолько
[10:07.420 --> 10:10.420]  медленно растущая, что это произведение все равно
[10:10.420 --> 10:12.420]  можно заменить в асимптотике M-кой,
[10:12.420 --> 10:15.420]  возведенной в степень количества саммножителей.
[10:15.420 --> 10:19.420]  Но я так понимаю, что это как-то не очевидно, да?
[10:22.420 --> 10:26.420]  Ну, можем сразу написать.
[10:26.420 --> 10:30.420]  Я боюсь, что людей смущает не наличие вот этого индекса.
[10:30.420 --> 10:32.420]  Тут мы можем, мы можем воспользоваться
[10:32.420 --> 10:34.420]  просто результатом первой лекции,
[10:34.420 --> 10:38.420]  в которой говорилось, что если вот этот верхний индекс C,
[10:38.420 --> 10:40.420]  будучи возведенным в квадрат,
[10:40.420 --> 10:42.420]  бесконечно мало по сравнению с нижним индексом,
[10:42.420 --> 10:44.420]  ну давайте я действительно так напишу.
[10:44.420 --> 10:48.420]  Смотрите, мы же знаем с вами, что C из N пока ведет тебя
[10:48.420 --> 10:50.420]  в асимптотике, как N вкатый,
[10:50.420 --> 10:52.420]  поделить на K факториал,
[10:52.420 --> 10:55.420]  если K квадрат, это маленькая от N.
[10:55.420 --> 10:57.420]  Вот знаем мы такой факт?
[10:57.420 --> 11:01.420]  Друзья, это мы знаем, это самая первая лекция этого семестра.
[11:01.420 --> 11:04.420]  Это очень простой, ну может вторая, не помню, но не важно.
[11:04.420 --> 11:10.420]  Отсюда, конечно, следует, что C из M минус K1 по K1 минус 2
[11:10.420 --> 11:16.420]  с хорошим запасом, это M минус K1 в степени K1 минус 2
[11:16.420 --> 11:19.420]  поделить на K1 минус 2 факториал.
[11:19.420 --> 11:21.420]  Действительно, можно так сказать.
[11:21.420 --> 11:25.420]  И, соответственно, C из M по K1 асимптотически
[11:25.420 --> 11:28.420]  это M в степени K1 поделить на K1 факториал.
[11:28.420 --> 11:30.420]  Почему? Потому что K это логарифум,
[11:30.420 --> 11:33.420]  и в квадрате он умал по сравнению с нижним индексом.
[11:33.420 --> 11:35.420]  Это-то понятно, ведь, да?
[11:35.420 --> 11:38.420]  То есть, конечно, такая симптотика есть.
[11:38.420 --> 11:42.420]  Но тут мы вычитаем K1, это можно в свою очередь как переписать,
[11:42.420 --> 11:46.420]  как, что надо сделать, надо M вынести за скобку.
[11:46.420 --> 11:49.420]  То есть будет M в степени K1 минус 2,
[11:49.420 --> 11:55.420]  а тут будет 1 минус K1 поделенное на M в степени K1 минус 2
[11:55.420 --> 11:59.420]  поделить на K1 минус 2 факториал.
[11:59.420 --> 12:02.420]  Ну и это равняется, давайте я уж честно напишу,
[12:02.420 --> 12:07.420]  M в степени K1 минус 2 на K1 минус 2 факториал,
[12:07.420 --> 12:11.420]  а тут будет E в степени минус K1 на M
[12:11.420 --> 12:16.420]  K1 минус 2 на 1 плюсом малое от единицы.
[12:16.420 --> 12:20.420]  Но обычная вещь я просто взял и представил основание,
[12:20.420 --> 12:22.420]  как E в степени логарифум от него,
[12:22.420 --> 12:26.420]  а логарифум раскрыл по первому члену ряда Тейлора.
[12:26.420 --> 12:28.420]  Ряда Тейлора.
[12:28.420 --> 12:31.420]  Слушайте, товарищи, привыкли к такой скорости? Нет еще?
[12:31.420 --> 12:34.420]  Привыкли? Сливаете?
[12:34.420 --> 12:37.420]  Ну и снова мы пользуемся тем, что K1 в квадрате сильно мал
[12:37.420 --> 12:40.420]  по сравнению с M, это на самом деле повтор того же рассуждения,
[12:40.420 --> 12:43.420]  которое давало вот этот результат.
[12:43.420 --> 12:46.420]  K1 сильно мал по сравнению с M настолько мал,
[12:46.420 --> 12:50.420]  что конечно вот это все асимпатически равно единице.
[12:50.420 --> 12:54.420]  Тут стоит K1 в квадрате примерно, ну так это фигня.
[12:54.420 --> 12:56.420]  Которая делится на M, все стремится к нулю,
[12:56.420 --> 12:58.420]  а экспонента, стало быть, уходит в единицу.
[12:58.420 --> 13:02.420]  То есть все это M в степени K1 минус 2
[13:02.420 --> 13:05.420]  поделить на K1 минус 2 факториал.
[13:05.420 --> 13:08.420]  Итого, возвращаясь сюда, можем вот так написать.
[13:08.420 --> 13:14.420]  M в степени K1 минус 2 поделить на K1 минус 2 факториал,
[13:14.420 --> 13:21.420]  умножить на K1 факториал и поделить на M в степени K1.
[13:21.420 --> 13:26.420]  И у нас остается K1, K1 без единицы,
[13:26.420 --> 13:29.420]  поделить на M в квадрате.
[13:29.420 --> 13:33.420]  И это то же самое, что K1 в квадрате на M в квадрате.
[13:35.420 --> 13:37.420]  Восемь точек, конечно.
[13:37.420 --> 13:39.420]  K1 в квадрате на M в квадрате.
[13:39.420 --> 13:41.420]  Ну и что у нас получилось?
[13:41.420 --> 13:45.420]  Вот мне не нравится, что это одна-вторая все-таки вылезла,
[13:45.420 --> 13:47.420]  которую мне напомнили.
[13:48.420 --> 13:52.420]  Но вопрос в том, уверены ли вы, что здесь этой двойки нет?
[13:56.420 --> 13:58.420]  Не, ну как так?
[13:59.420 --> 14:02.420]  Что, вспоминать, как это шло в прошлый раз?
[14:02.420 --> 14:04.420]  Рассуждение. Что?
[14:09.420 --> 14:14.420]  Да вот мне тоже кажется, что мы просто зря эту одну-вторую добавили.
[14:14.420 --> 14:17.420]  Сейчас, конечно, хорошо бы вспомнить концовку прошлой лекции,
[14:17.420 --> 14:22.420]  потому что у нас все получилось с точностью до зачем-то добавленной вот этой одной-второй.
[14:22.420 --> 14:24.420]  Знаете, какое дело?
[14:24.420 --> 14:28.420]  Я вот боюсь, что проблема в том, что мы ее зря просто добавили.
[14:30.420 --> 14:33.420]  Друзья, будем вспоминать, как заканчивалась прошлая лекция?
[14:33.420 --> 14:36.420]  Или все понимают, что мы зря ее здесь добавили, и все хорошо?
[14:36.420 --> 14:40.420]  Ну, это тоже верно. Конечно, вы сейчас не будете во всех деталях разбираться.
[14:41.420 --> 14:46.420]  Ну, поскольку там будет какая-то консультация, если что, мы, конечно, можем к этому вернуть.
[14:47.420 --> 14:51.420]  Но да, вот как-то вспоминать еще про прошлую лекцию в подробностях.
[14:51.420 --> 14:53.420]  Конечно, зря мы ее тут добавили.
[14:53.420 --> 14:59.420]  Я просто немножко вас запутал в тот момент, когда рассказывал сначала через пары в фигурных скобках,
[14:59.420 --> 15:05.420]  потом через пары в круглых скобках, и вот эта одна-вторая, она паразитом таким появилась.
[15:05.420 --> 15:10.420]  Я утверждаю, что она здесь не нужна. Я просто помню, что она здесь не нужна.
[15:10.420 --> 15:12.420]  То есть тут должна появиться минус единичка.
[15:12.420 --> 15:15.420]  Вот эта двойка пропадет, и действительно все сойдется к одному.
[15:15.420 --> 15:18.420]  Главное понимать вот эту асимпатическую хрень.
[15:18.420 --> 15:21.420]  А все остальное, как я сказал, это ненужное.
[15:21.420 --> 15:24.420]  И все остальное, как я сказал, это ненужное.
[15:24.420 --> 15:26.420]  А все остальное, как я сказал, это ненужное.
[15:26.420 --> 15:29.420]  А все остальное, как я сказал, это ненужное.
[15:29.420 --> 15:33.420]  Не хочу вас кокоть, мучать, считать там пяти равном тройке, четверки.
[15:33.420 --> 15:35.420]  Хорошо?
[15:35.420 --> 15:40.420]  Ну то есть у нас практически полностью доказан очень мощный результат,
[15:40.420 --> 15:46.420]  но, конечно, остались какие-то аналитические фиговины, которые вы понимаете, для чего нужны асимптотики.
[15:46.420 --> 15:52.420]  Вот люди учатся ими жонглировать, в том числе для того, чтобы не только примерно так проверить, что все получилось,
[15:52.420 --> 15:57.420]  но и дальше убедиться в справедливости строго этого утверждения.
[15:57.420 --> 16:05.420]  Так, я продолжаю с вами сейчас изучать случайные графы, но заканчиваю, наконец, с раскрасками.
[16:05.420 --> 16:13.420]  Друзья, немножко резюмировать вам, что мы успели сделать, чтобы вы как-то общую картинку видели.
[16:13.420 --> 16:21.420]  Мы много там разные техники изучили, по ходу дела были нетривиальные вещи, какие-то неравенства, зумы там, что-то такое.
[16:21.420 --> 16:25.420]  А что на самом деле-то происходило?
[16:25.420 --> 16:28.420]  Вот на самом деле, что происходило?
[16:28.420 --> 16:32.420]  В течение значимой части семестра.
[16:32.420 --> 16:38.420]  Ну что происходило? Мы сначала убедились в том, что у хроматического числа графа,
[16:38.420 --> 16:44.420]  которая в общем играет очень большую роль, в том числе в приложениях, есть два типа оценок.
[16:44.420 --> 16:49.420]  Одна через мощность В поделить на альфа, другая через амегу, это нижние оценки.
[16:49.420 --> 16:58.420]  И быстренько поняли, что оценка через мощность В поделить на альфа гораздо лучше, если граф случайный.
[16:58.420 --> 17:03.420]  Вы понимаете, с практической точки зрения граф не всегда случайный, конечно.
[17:03.420 --> 17:09.420]  То есть если вам на вход на каком-то производстве или в каких-то задачах будут графы, то вам надо очень аккуратно посмотреть,
[17:09.420 --> 17:12.420]  а вообще вы можете их считать случайными или нет.
[17:12.420 --> 17:14.420]  Но я об этом говорил.
[17:14.420 --> 17:20.420]  Если все-таки вы можете их считать абсолютно случайными, тогда одна оценка сильно лучше другой.
[17:20.420 --> 17:26.420]  Дальше была иллюстрация совершенно офигенного следствия из того, что одна оценка лучше другой,
[17:26.420 --> 17:31.420]  а именно была теорема о том, что бывают графы на свете, у которых сколь угодно большой обхват
[17:31.420 --> 17:34.420]  и при этом сколь угодно большое хроматическое число.
[17:34.420 --> 17:40.420]  Это в каком-то смысле иллюстрация на то, что мощность В поделить на альфа гораздо больше, чем амега.
[17:40.420 --> 17:42.420]  Вот это то, что тогда произошло.
[17:42.420 --> 17:49.420]  Тогда я сказал, ну слушайте, это здорово, конечно, а вообще мы можем как-нибудь вычислить хроматическое число?
[17:49.420 --> 17:53.420]  Ну вот вычислили с помощью жадного алгоритма.
[17:53.420 --> 17:58.420]  На примере числа независимости, которая как раз играет роль наилучшей оценки,
[17:58.420 --> 18:05.420]  мы выяснили, что жадный алгоритм почти всегда работает не хуже, чем в два раза.
[18:06.420 --> 18:13.420]  Ну правда, потом возникли примеры последовательности, которые совсем ужасные, но это уже как бы за скобками.
[18:13.420 --> 18:19.420]  Тогда я сказал, слушайте, товарищи, давайте вообще разберемся, как могут себя вести хроматические числа случайных графов.
[18:19.420 --> 18:22.420]  И мы довольно подробно в этом разобрались.
[18:22.420 --> 18:28.420]  Поскольку это длилось несколько лекций, то вот я посчитал нужным сейчас произнести просто это резюме.
[18:28.420 --> 18:31.420]  Мы, конечно, разобрались не во всех существующих ситуациях.
[18:32.420 --> 18:39.420]  У нас были совсем маленькие p, потом p побольше, потом еще побольше, а потом вдруг, бац, мы перескочили на одну вторую.
[18:39.420 --> 18:47.420]  Ну то есть там было вот так. Там было сначала совсем смешно, мало от 1 на n в квадрате, ребер нет, хроматическое число 1.
[18:47.420 --> 18:52.420]  Потом было мало от 1n, но вот хроматическое число уже 2.
[18:52.420 --> 18:57.420]  Потом было c поделить на n, вот с ним я не доказывал, но сказал, что хроматическое число 3.
[18:57.420 --> 19:02.420]  Потом было n в степени минус альфа, альфа больше чем 5 шестых.
[19:02.420 --> 19:07.420]  Мы доказали, что оно уже, ну мы знаем, что оно растет, и вы можете это проверить.
[19:07.420 --> 19:14.420]  Но вот та растущая функция, которая отвечает за хроматическое число, вокруг нее оно очень хорошо концентрируется.
[19:14.420 --> 19:18.420]  То есть принимает лишь, ну мы доказали, что четыре возможных значения.
[19:18.420 --> 19:22.420]  А потом мы перескочили на одну вторую.
[19:22.420 --> 19:31.420]  Ну друзья, ну мне кажется, что для курса дискретного анализа более глубоко в это закапываться было бы чересчур.
[19:31.420 --> 19:36.420]  Вот поэтому я говорю все. Хроматическими числами мы картинку заканчиваем.
[19:36.420 --> 19:42.420]  Хватит мне вас ими мучать. Больше у случайных графов мы их изучать не будем.
[19:42.420 --> 19:48.420]  А теперь мы займемся другим очень важным свойством случайного графа, который называется связность.
[19:48.420 --> 19:54.420]  И это с практической точки зрения, конечно, никак не меньше по значимости свойства.
[19:54.420 --> 20:02.420]  Ну потому что связность случайного графа это вопрос о том, сохраняется инфраструктура где-то или не сохраняется.
[20:02.420 --> 20:07.420]  Вы же помните, как я объяснял, что такое вообще случайный граф?
[20:07.420 --> 20:15.420]  Как он, какой смысл он имеет? Вершины это какие-то сервера. Говорил я про это, да?
[20:15.420 --> 20:20.420]  Между ними связи, они разрываются независимо друг от друга.
[20:20.420 --> 20:30.420]  Знаете, вот они разрываются и вдруг граф развалился. Так это значит, что мы с одного сервера на какой-то другой вообще не сможем передать информацию, если граф перестал быть связанным.
[20:30.420 --> 20:41.420]  Я понятно ведь выражаюсь, да? Поэтому вопрос о том, при каких условиях граф связан, при каких нет, какие в нем компоненты, как они устроены, это вопрос практически очень значимый.
[20:41.420 --> 20:47.420]  Ну и теоретически, конечно, тоже очень красивый. Вот об этом мы сегодня и в следующий раз поговорим.
[20:55.420 --> 21:05.420]  Отмечу, что если вы будете смотреть записи прежних лет, то я читал по-другому. Я сначала рассказывал про связанность, а потом уже переходил к хроматическим числам.
[21:05.420 --> 21:12.420]  Сейчас я посчитал нужным более последовательно изложить всю историю с хроматикой и уже потом рассказывать про связанность.
[21:16.420 --> 21:22.420]  Ну кроме всего прочего, это еще связано с тем, что я ведь прочитал часть графов в ОКТЧ. Этого раньше тоже не было.
[21:26.420 --> 21:31.420]  Поэтому суммарно в течение года я успею больше, чем я успевал ранее.
[21:32.420 --> 21:37.420]  Так, ну хорошо, значит, связанность случайного графа.
[21:44.420 --> 21:54.420]  Вот сегодня все-таки будем от противительной суммы считать аналитические, но к ним придем содержательным методом, который, конечно, я постараюсь максимально аккуратно подробно донести.
[21:55.420 --> 22:08.420]  Первая теорема, которую мы докажем обязательно, звучит следующим образом. Пусть вероятность ребра случайного графа это функция от числа ему вершин.
[22:09.420 --> 22:12.420]  Ну уж к этому мы привыкли, она может быть функцией, а не просто константой.
[22:13.420 --> 22:21.420]  Функция вот такого вот вида, целогариф натуральный n поделить на n, где c это константа, строго большая нуля.
[22:23.420 --> 22:29.420]  Пусть вероятность ребра задается в таком, ну все равно как-то кажется, наверное, очень специфическом виде.
[22:30.420 --> 22:31.420]  Но я сейчас все поясню.
[22:32.420 --> 22:38.420]  Тогда имеют место два, по сути, противоположных утверждений.
[22:39.420 --> 22:58.420]  Если, так, да, вот так давайте, если c больше единицы, да, если c строго больше единицы, то асимпатически,
[22:58.420 --> 23:03.420]  почти, наверное, случайный граф связан.
[23:06.420 --> 23:18.420]  А если c строго меньше единицы, то асимпатически, почти, наверное, случайный граф не является связан.
[23:19.420 --> 23:20.420]  Не связан.
[23:20.420 --> 23:28.420]  Ну это, конечно, не совсем прикладное утверждение, когда оно сформулировано в таком виде.
[23:29.420 --> 23:34.420]  Потому что асимпатически, почти, наверное, это еще не значит, что при маленьких n вероятность большая.
[23:35.420 --> 23:41.420]  Поэтому если мы хотим применять это на практике, то нужны какие-то более эффективные оценки скорости сходимости, вероятности к единице.
[23:42.420 --> 23:43.420]  Об этом я сейчас скажу.
[23:44.420 --> 24:01.420]  Но качественное утверждение красивое, потому что оказывается, что наличие или отсутствие связанности, то есть сохранение или утрата инфраструктуры в сети, обладает фазовым переходом, как говорят физики.
[24:02.420 --> 24:05.420]  Кто-нибудь из присутствующих слышал выражение фазовых переходов?
[24:06.420 --> 24:11.420]  Ну то есть вы физику-то не изучаете, но все-таки выражение стандартное можно даже в школе когда-нибудь произносить, я не знаю.
[24:12.420 --> 24:16.420]  Ну понятно, лед и вода превращаются друг друга на нуле градусов.
[24:17.420 --> 24:21.420]  Вот здесь роль нуля градусов играет функция логариф Мен поделительная.
[24:23.420 --> 24:25.420]  Выше нуля, вот в этом смысле.
[24:26.420 --> 24:28.420]  Умножаем на что-то хоть немножко больше единицы.
[24:29.420 --> 24:30.420]  И граф почти, наверное, связан.
[24:31.420 --> 24:36.420]  А ниже нуля, то есть С меньше единицы, мы на этот С умножаем, вероятность стремится к нулю.
[24:37.420 --> 24:38.420]  Граф почти, наверное, не связан.
[24:39.420 --> 24:45.420]  Такой резкий скачок на грани, на пороге, как говорят вот этой функции логариф Мен поделительная.
[24:46.420 --> 24:49.420]  Вот почти, наверное, связанности к почти, наверное, не связанности.
[24:50.420 --> 24:52.420]  Качественный смысл утверждения понятен.
[24:53.420 --> 24:59.420]  Вообще вот это вот явление фазового перехода в проявлении каких-то свойств случайного графа, это очень характерная вещь.
[25:00.420 --> 25:06.420]  Поэтому зачастую вот эти сложные сети, случайные графы, изучаются физиками в своих терминах.
[25:07.420 --> 25:09.420]  И там получаются очень интересные тоже результаты и наблюдения.
[25:11.420 --> 25:17.420]  Так, ну давайте я, прежде чем буду формально долго вот это доказывать, я еще кое-что скажу.
[25:18.420 --> 25:20.420]  Во-первых, про практическую сторону применения.
[25:23.420 --> 25:26.420]  Ну давайте я напишу теорема штрих.
[25:26.420 --> 25:35.420]  Теорема штрих, я ее не буду доказывать, она легко получается из тех рассуждений, которые я проведу, но явные оценки это скучно.
[25:36.420 --> 25:50.420]  Теорема штрих утверждает, что, например, если c больше либо равняется 3, то вероятность того, что g от np связан, случайный граф связан,
[25:50.420 --> 25:57.420]  больше либо равна 1 минус 1n, забыл сказать, коль скоро n больше либо равняется 100.
[25:58.420 --> 26:00.420]  Ну там 100 или 90.
[26:01.420 --> 26:04.420]  Ну то есть при достаточно больших n мы можем стать явную оценку.
[26:06.420 --> 26:10.420]  Ну еще c все-таки не совсем близко к единице, а, например, больше либо равно тройке.
[26:11.420 --> 26:19.420]  Но я всегда абсолютно уже на протяжении многих лет привожу стандартный пример, вот просто я его помню наизусть, поэтому чего бы мне его не повторить.
[26:20.420 --> 26:25.420]  Вот есть две тысячи тех самых серверов, раскиданных по всей стране, по всему миру.
[26:27.420 --> 26:31.420]  Есть две тысячи серверов, ну две тысячи куда как больше, чем 100, да?
[26:33.420 --> 26:44.420]  Вот смотрите, возьмем c равное тройке, тогда p у нас будет равно 3 логариф натуральный 2000 поделить на 2000, правильно?
[26:45.420 --> 26:57.420]  Ну это можно посчитать, я думаю все присутствующие догадываются, что это точно не большая величина, что логарифум все-таки гораздо меньше, чем 2000, но я утверждаю, что это примерно одна сотая.
[26:58.420 --> 27:00.420]  Там 0011 что ли?
[27:01.420 --> 27:02.420]  Примерно одна сотая.
[27:03.420 --> 27:04.420]  Смотрите, что такое p?
[27:05.420 --> 27:09.420]  Это вероятность присутствия ребра в случайном графе, правильно?
[27:10.420 --> 27:13.420]  То есть это вероятность сохранения связи, если идут атаки.
[27:16.420 --> 27:23.420]  Вероятность уничтожения отдельно взятой связи, ну это 0,99 что-нибудь или 0,98 что-то такое.
[27:24.420 --> 27:35.420]  Офигенно казалось бы высокой, то есть каждую отдельную линию мы теряем с вероятностью очень близко к единице, конкретно вот 0,98 или 0,988 что-то такое.
[27:36.420 --> 27:37.420]  Понимаете, да?
[27:37.420 --> 27:45.420]  Тем не менее, вероятность сохранения всей инфраструктуры, то есть возможности передачи информации любого сервера на любой другой.
[27:46.420 --> 27:47.420]  Смотрите, как же?
[27:48.420 --> 27:51.420]  1-1, 2000 это 0,9995.
[27:53.420 --> 27:55.420]  Вы согласны, что это очень круто?
[27:56.420 --> 28:05.420]  0,98 вероятность потерять отдельно взятую связь и 0,99 и так далее вероятность сохранить возможность передачи информации между любыми двумя серверами.
[28:06.420 --> 28:09.420]  То есть с практической точки зрения это очень классный результат.
[28:10.420 --> 28:15.420]  Ну а я докажу качественную версию, про которую все равно мне кажется, что вопрос-то остался.
[28:16.420 --> 28:18.420]  Неужели никто его не задаст? Всегда задают.
[28:19.420 --> 28:21.420]  Да, что будет при ц равном единице?
[28:22.420 --> 28:26.420]  На этот вопрос я абсолютно всегда отвечаю теоремой два штриха, которым вы доказывать не будете.
[28:26.420 --> 28:31.420]  Ну и его часто задают, но она без доказательства.
[28:32.420 --> 28:34.420]  Она пойдет без доказательства в курсе.
[28:35.420 --> 28:45.420]  Вот эта конкретная теорема, конечно она тоже без доказательства, но это простое упражнение вывести ее как следствие просто из тех выкладок, которые я сделаю в рамках пункта 1.
[28:46.420 --> 28:48.420]  Она скучная, не нужная, но простая.
[28:49.420 --> 28:51.420]  А теорема два штриха это довольно сложное утверждение.
[28:52.420 --> 28:58.420]  Мы скажем вот так. Пусть п от n имеет вот какой вид.
[28:59.420 --> 29:03.420]  Логариф mn плюс гамма поделить на n.
[29:05.420 --> 29:10.420]  То есть я вам отвечу на вопрос, который я из вас вытащил клещами.
[29:12.420 --> 29:14.420]  А отвечу я более сложно.
[29:15.420 --> 29:17.420]  То есть вы-то меня спросили, что будет вот так.
[29:18.420 --> 29:19.420]  Правильно?
[29:19.420 --> 29:21.420]  С равно единице это вот так.
[29:22.420 --> 29:23.420]  А здесь я еще константочку добавил.
[29:24.420 --> 29:26.420]  Гамма может быть хоть положительной, хоть отрицательной.
[29:27.420 --> 29:29.420]  Вычил может быть что-то, может прибавил.
[29:30.420 --> 29:34.420]  Согласитесь, если гамма не равна нулю, это не то же самое, что вот здесь С равно единице.
[29:35.420 --> 29:36.420]  Поэтому это как бы отдельная теорема.
[29:37.420 --> 29:43.420]  Потому что не вся жизнь исчерпывается тем, что С равно единице, больше единицы или меньше единицы.
[29:43.420 --> 29:50.420]  Можно сюда еще прибавлять или отсюда вычитать какие-то функции, которые бесконечно малы по сравнению с вот этой дробью, с этим порохом.
[29:51.420 --> 29:53.420]  Ну вот я здесь, видите, прибавляю гамма поделить на n.
[29:54.420 --> 29:57.420]  Она бесконечно мала по сравнению с логарифом m поделить на n.
[29:58.420 --> 30:00.420]  Я надеюсь, что студентам уже понятно, в чем разница.
[30:01.420 --> 30:06.420]  Так вот, тогда тоже можно ответить, как устроена симпатичная вероятность связности.
[30:07.420 --> 30:12.420]  Вероятность того, что g от np связан.
[30:15.420 --> 30:19.420]  Ну, я очень люблю этот момент, он такой зажигательный.
[30:20.420 --> 30:26.420]  Стремится к е в степени минус, е в степени минус гамма.
[30:30.420 --> 30:31.420]  Сейчас не зажгло, да?
[30:32.420 --> 30:33.420]  Мне кажется, очень круто.
[30:34.420 --> 30:36.420]  Двойная экспонента, да?
[30:37.420 --> 30:39.420]  Двойная отрицательная экспонента, так скажем.
[30:40.420 --> 30:44.420]  Ну, конечно, отсюда сразу следует ответ на тот вопрос, который я из вас вытащил.
[30:45.420 --> 30:49.420]  То есть, если мы подставим гамма равная нулю, мы получим случай c равный единице.
[30:50.420 --> 30:52.420]  Гамма равная нулю дает просто е в минус первой.
[30:53.420 --> 31:01.420]  То есть, вероятность стремится не к нулю, не к единице, не к нулю, не к единице, а к е в минус первой степени.
[31:02.420 --> 31:05.420]  Ну, а тут видно, что порог еще тоньше.
[31:06.420 --> 31:10.420]  То есть, если в этой формулировке порогом была просто функция алгориф man потереть на n,
[31:11.420 --> 31:15.420]  в смысле умножим на c больше одного, получится одно, умножим на c меньше одного, получится другое.
[31:16.420 --> 31:19.420]  А здесь сам этот переход еще конкретизирован.
[31:20.420 --> 31:26.420]  То есть, смотрите, если добавочка вот этой гаммы очень большое положительное число,
[31:26.420 --> 31:32.420]  то е в минус гаммы это что? Почти ноль, правда?
[31:33.420 --> 31:37.420]  Вот этот почти ноль со знаком минусов показателей экспонента это что?
[31:38.420 --> 31:40.420]  Почти единица, правильно?
[31:41.420 --> 31:42.420]  Ну, вот это как раз почти, наверное, связано.
[31:43.420 --> 31:45.420]  То есть, когда гамма просто стремится к плюсу бесконечности,
[31:46.420 --> 31:50.420]  мы все время будем получать не функцию, которая умножается на что-то строго больше единицы,
[31:50.420 --> 31:56.420]  а функцию, которая симпатически равнала алгорифму n, не умножается ни на что строго больше единицы.
[31:57.420 --> 32:00.420]  Тем не менее, мы видим, что когда гамма стремится к плюсу бесконечности,
[32:01.420 --> 32:03.420]  мы получаем практически уже апн-связность.
[32:04.420 --> 32:06.420]  А когда гамма стремится к минусу бесконечности,
[32:07.420 --> 32:10.420]  то е в степени минус гаммы это что-то офигенно большое положительное,
[32:11.420 --> 32:14.420]  и оно со знаком минус показателей экспонента дает практически ноль.
[32:15.420 --> 32:19.420]  Вот такой вот очень тонкий переход внутри порога.
[32:20.420 --> 32:23.420]  Почти, наверное, связанности к почти, наверное, отсутствию единицы.
[32:24.420 --> 32:26.420]  Так.
[32:30.420 --> 32:32.420]  Сейчас буду доказывать теорию.
[32:32.420 --> 32:36.420]  Смотрите.
[32:48.420 --> 32:50.420]  А, слушайте, не буду, да?
[32:51.420 --> 32:55.420]  Нет, но еще 4 минуты есть или 3 до перерыва.
[32:56.420 --> 32:58.420]  Давайте до перерыва просто обсудим.
[32:58.420 --> 33:03.340]  Вот если мы, например, хотим развалить граф на компоненты,
[33:03.340 --> 33:07.860]  то как это легче сделать, с вероятностной точки зрения?
[33:07.860 --> 33:13.060]  Что легче пытаться отколоть от n-вершинного графа, чтобы
[33:13.060 --> 33:16.060]  он развалился на компоненты?
[33:16.060 --> 33:18.300]  Одну вершину, согласны, да?
[33:18.300 --> 33:22.340]  Одну вершину это надо разорвать только n-1 связь.
[33:22.340 --> 33:26.420]  А если вы хотите пополам его разорвать, сколько
[33:26.420 --> 33:28.780]  связей надо разорвать, понимаете?
[33:28.780 --> 33:31.980]  n-2 на 4.
[33:31.980 --> 33:35.220]  Если у него n-вершин, и вы его хотите разорвать пополам,
[33:35.220 --> 33:39.060]  то там будет n-2 на 4, как в 2-дольном графе в полном связи.
[33:39.060 --> 33:43.740]  То есть, конечно, очень естественно пытаться отколоть одну
[33:43.740 --> 33:44.740]  вершину.
[33:44.740 --> 33:47.820]  И вот этот второй пункт, он в этом смысле доказывается
[33:47.820 --> 33:48.820]  даже проще.
[33:48.820 --> 33:53.220]  Ну, давайте просто да начну.
[33:53.220 --> 33:54.220]  Что там?
[33:54.220 --> 34:00.020]  x, а g – это число изолированных вершин в случайном графе.
[34:00.020 --> 34:08.660]  Изолированная вершина – это вершина, образующая компоненту
[34:08.660 --> 34:10.700]  такую одновершинную.
[34:10.700 --> 34:12.980]  Из нее никаких ребер не идет, вот это называется
[34:12.980 --> 34:15.380]  изолированная вершина.
[34:15.380 --> 34:21.020]  Чему равняется математическое ожидание x?
[34:21.020 --> 34:23.780]  Линейность в чистом виде, хотелось бы, наверное, услышать
[34:23.780 --> 34:24.780]  от аудитории.
[34:24.780 --> 34:30.780]  Правильно, да, n, 1-1, но только в n-1.
[34:30.780 --> 34:33.300]  Может, так и было сказано, я просто не услышал.
[34:33.300 --> 34:36.300]  Ну и хорошо.
[34:36.300 --> 34:39.900]  Ну, у меня послышалось в степени n, но может в степени
[34:39.900 --> 34:43.300]  n-1 или в n-1.
[34:43.300 --> 34:44.540]  Понятно всем, почему так.
[34:44.540 --> 34:48.580]  Фиксированная вершина не имеет ни одного ребра
[34:48.580 --> 34:50.540]  в оставшейся, вот с такой вероятностью.
[34:50.540 --> 34:51.940]  Так же складываем индикаторы, получаем.
[34:51.940 --> 34:52.940]  Вот.
[34:52.940 --> 34:56.140]  Ну, на самом деле, из этого сразу видно, откуда взялась
[34:56.140 --> 35:00.940]  функция логариф мэн поделить на n, потому что 100 раз уже
[35:00.940 --> 35:01.940]  проходили.
[35:01.940 --> 35:05.780]  Это вот так выглядит.
[35:05.780 --> 35:09.060]  Буквально сегодня такую штуку писали, 1-p, это e в степени
[35:09.060 --> 35:13.660]  логариф мата 1-p, логариф мата 1-p – это –p, если p стремится
[35:13.660 --> 35:14.660]  к нулю.
[35:14.660 --> 35:16.460]  Ну и что надо подставить?
[35:16.460 --> 35:19.900]  Вот надо подставить логариф мэн поделить на n, то есть
[35:20.060 --> 35:25.260]  если мы вот сюда подставляем, c логариф мэн поделить на
[35:25.260 --> 35:30.660]  n, это прямо угадывается, в уме можно сказать, то это
[35:30.660 --> 35:41.020]  получается cn множить на n, видите, тут кок-кок, а e в степени
[35:41.020 --> 35:44.540]  логариф мэн – это n, ну еще в минус с этой степени – это
[35:44.540 --> 35:48.300]  n в минус с этой, не совсем в минус с этой, еще надо
[35:48.300 --> 35:51.580]  на поправочку вот эту асимптатически равную единице
[35:51.580 --> 35:56.780]  домножить, так ведь, да?
[35:56.780 --> 36:02.340]  Но все равно ясно, что это стремится к бесконечности,
[36:02.340 --> 36:09.860]  если c строго больше одного и к нулю, если c строго меньше
[36:09.860 --> 36:17.860]  одного, или наоборот, наоборот, к бесконечности если c
[36:17.860 --> 36:21.700]  строго меньше одного и к нулю, если c строго больше
[36:21.700 --> 36:22.700]  одного.
[36:22.700 --> 36:26.460]  Друзья, сейчас перерыв, ну это-то ясно, и это как-бы
[36:26.460 --> 36:29.460]  создает интуицию, откуда взялась пороговая функция,
[36:29.460 --> 36:31.740]  но формально все придется доказывать через пять минут
[36:31.740 --> 36:32.740]  и это займет время.
[36:32.740 --> 36:36.620]  Так, значит, дорогие друзья, ну действительно, из этого
[36:36.620 --> 36:40.100]  формально ничего не следует, из-за того, что мат ожидания
[36:40.100 --> 36:43.700]  стремится к нулю, следует, что асимптатически почти
[36:43.700 --> 36:47.580]  наверное изолированных вершин нет, ну так мало
[36:47.580 --> 36:50.700]  лишь, что их нет, а может есть какие-то другие компоненты,
[36:50.700 --> 36:52.780]  это у нас только интуиция была, что проще всего отколоть
[36:52.780 --> 36:55.140]  изолированную вершину, правда же?
[36:55.140 --> 36:58.660]  А из того, что мат ожидания стремится к плюс бесконечности,
[36:58.660 --> 37:01.100]  это мы обсуждали, когда треугольники считали в случайном
[37:01.100 --> 37:05.860]  графе, тоже еще не следует, что сами эти изолированные
[37:05.860 --> 37:09.020]  вершины появятся с высокой вероятностью, что надо считать
[37:09.020 --> 37:10.020]  дисперсию.
[37:10.020 --> 37:11.020]  Помните?
[37:11.340 --> 37:12.340]  Помните?
[37:12.340 --> 37:13.860]  Ну я сейчас напомню.
[37:13.860 --> 37:16.460]  Проще доказывать пункт два, вот давайте пункт два,
[37:16.460 --> 37:19.420]  в нем надо будет посчитать дисперсию, но реально итог
[37:19.420 --> 37:21.060]  получится быстрее.
[37:21.060 --> 37:25.820]  То есть в пункте два рассуждаем как с треугольниками вероятность
[37:25.820 --> 37:28.620]  того, что х больше либо равно единице, давайте повторение
[37:28.620 --> 37:32.380]  мат учения, я не буду ссылаться на ту лекцию, а еще раз произведу
[37:32.380 --> 37:36.180]  эту смешную выкладку, она выглядит вот так, но вы
[37:36.180 --> 37:39.460]  заодно поймете, что это действительно общий такой факт, который
[37:39.460 --> 37:42.940]  можно использовать всегда, когда у вас случайная величина
[37:42.940 --> 37:48.380]  это 0, 1, 2, 3, то есть она принимает неотрицательные целые значения.
[37:48.380 --> 37:52.860]  Это единица минус вероятность того, что х не больше нуля,
[37:52.860 --> 37:55.340]  ну не больше нуля равно нулю, это одно и то же, но мне
[37:55.340 --> 37:58.500]  удобнее писать не больше, чтобы подогнать просто к
[37:58.500 --> 38:03.140]  виду неравенства Чебышова, что это единица минус вероятность
[38:03.140 --> 38:09.340]  того, что минус х больше либо равен нуля, это единица
[38:09.340 --> 38:13.340]  минус вероятность того, что мат ожидания х минус х больше
[38:13.340 --> 38:17.180]  либо равняется мат ожидания х, может быть у вас всплывает
[38:17.180 --> 38:22.380]  в памяти такая технология, ну такая совершенно древиальная
[38:22.380 --> 38:25.420]  вещь, конечно, меняем знаки, добавляем мат ожидания
[38:25.420 --> 38:28.180]  и пользуемся неравенством Чебышова, это больше либо
[38:28.180 --> 38:33.980]  равно единица минус дисперсия х, поделенная на квадрат
[38:33.980 --> 38:37.860]  математического ожидания, то есть если мы докажем,
[38:37.860 --> 38:41.140]  что вот эта дробь стремится к нулю, вот тогда мы докажем
[38:41.140 --> 38:48.100]  пункт два, понятно ведь, да, почти наверное есть изолированные
[38:48.100 --> 38:51.260]  вершины, значит почти наверное, как следствие, граф не связан,
[38:51.260 --> 38:54.980]  просто потому что есть изолированные вершины, пока мы знаем только,
[38:54.980 --> 38:57.580]  что мат ожидания стремится к плюсу бесконечности,
[38:57.980 --> 39:03.140]  это важно, но надо посчитать дисперсию, дисперсия х,
[39:03.140 --> 39:11.780]  как обычно, это второй момент, минус квадрат, мат ожидания,
[39:11.780 --> 39:16.700]  дорогие товарищи математики, как у вас на лекциях сейчас
[39:16.700 --> 39:25.540]  тела обстоят, что вы там проходите, Гёльдерша, это
[39:25.540 --> 39:30.100]  хорошо, значит случайная величина у вас уже есть, нет,
[39:30.100 --> 39:35.180]  другого Гёльдера проходить, а что такое Гёльдер, какое именно,
[39:35.180 --> 39:42.780]  но интеграл, да, но интеграл, то есть мат ожидания, ладно, понятно,
[39:42.780 --> 39:50.940]  да-да-да, то есть я понял, ну хорошо, сейчас посчитаем все,
[39:50.940 --> 39:58.820]  это-то мы знаем, вот оно, его можно не считать, надо посчитать второй момент,
[39:58.820 --> 40:05.420]  ну давайте посчитаем второй момент, это просто, как мы считали мат ожидания,
[40:05.420 --> 40:11.220]  мы складывали n индикаторов, которые указывали на изолированность отдельно
[40:11.220 --> 40:16.260]  взятой вершины, правильно, так понятно, что такое x и t, это те самые индикаторы,
[40:16.260 --> 40:22.740]  которые сложились в n умножить на 1 минус p в n минус 1, x и t это индикатор того, что и
[40:22.740 --> 40:27.940]  изолированная вершина, тесно возводим в квадрат, эти индикаторы скоррелированы,
[40:27.940 --> 40:38.220]  поэтому надо тесно возводить в квадрат, будет x1 в квадрате, далее плюс xn в квадрате, плюс сумма
[40:38.220 --> 40:47.500]  по i неравным g, x и t на x и t, ну как обычно я не рисую двойку перед суммой, потому что я считаю,
[40:47.500 --> 40:55.620]  что пары индексов вот эти упорядочены, так хлоп-хлоп, потому что индикатор в квадрате,
[40:55.620 --> 41:02.780]  то он же сам, 1 в квадрате и 0 в квадрате, это опять то, что мы знаем, то есть математическое
[41:02.780 --> 41:10.700]  ожидание x, ну а дальше по линейности сумма по вот этим кортежам и g с не совпадающими индексами,
[41:10.700 --> 41:19.940]  мат ожидания x и t на x и t, ну еще раз, они скоррелированы, поэтому я ни в коем случае не утверждаю,
[41:19.940 --> 41:28.540]  что это произведение мат ожиданий, это не произведение мат ожиданий, не вздумайте так считать,
[41:28.540 --> 41:36.220]  но что такое мат ожидания произведения индикаторов, это вот у нас есть вершина с номером i, есть вершина
[41:36.220 --> 41:43.900]  с номером g и произведение вот этих индикаторов равно единице тогда и только тогда, когда обе вот
[41:43.900 --> 41:53.340]  эти вершины изолированы, то есть у нас есть еще сарделька из n-2 оставшихся вершин и надо чтобы
[41:53.340 --> 41:59.500]  тут не было ребра, тут не было ребер и тут не было ребер, сколько всего таких ребер, которые должны
[41:59.500 --> 42:09.260]  отсутствовать, вот здесь одно, здесь n-2 и здесь n-2, то есть 2n-3, правильно, 2n-3, получаем ех,
[42:09.260 --> 42:22.860]  n на n-1 на 1-p вероятность отсутствия ребра в степени 2n-3, n умножить на n-1 это как раз количество
[42:22.860 --> 42:35.140]  пар несовпадающих индексов, если они упорядочены, а из n-2, а из n-2, n на n-1, так, но осталось разделить,
[42:35.140 --> 42:51.940]  придется где-то отдельно здесь делить, нам нужно разделить дисперсию х на квадрат математического
[42:51.940 --> 43:02.140]  ожидания, значит это будет ну ех квадрата мы вычислили, давайте напишем это будет ех плюс
[43:02.140 --> 43:22.220]  n, n-1, 1-p в 2n-3 поделить на ех в квадрате и вычесть надо просто единицу, так единицу вычитаем,
[43:22.220 --> 43:30.820]  потому что ех в квадрате делится на ех в квадрате, ех деленное на ех в квадрате стремится к нулю,
[43:30.820 --> 43:36.100]  потому что мат ожидания стремится к плюс бесконечности, видите это все-таки очень важно,
[43:36.100 --> 43:43.660]  мат ожидания обязана стремиться к плюс бесконечности иначе не получится, вот эта штука стремится к нулю,
[43:43.660 --> 43:50.900]  в нашем режиме c меньше 1 это обеспечивает благополучно, а дальше у нас есть n умножить
[43:50.900 --> 43:59.260]  на n-1 на 1-p в 2n-3 и мы это делим снова на квадрат мат ожидания, который я сейчас напишу явно,
[43:59.260 --> 44:06.660]  то есть это n в квадрате на 1-p в 2n-2, это просто квадрат мат ожидания написанный явно,
[44:06.660 --> 44:15.820]  вот эта часть асимптатически равна единице, а что происходит с этой частью, что вообще,
[44:15.820 --> 44:27.820]  ну это 1 поделить на 1-p, правильно, то что осталось это вот, это вот, это 1 поделить на 1-p,
[44:27.820 --> 44:33.180]  но p у нас стремится к нулю, смотрите на p это целый, Гаррифмен поделить на n-c константа,
[44:33.180 --> 44:37.620]  p стремится к нулю, поэтому это тоже асимпатическая единица,
[44:37.620 --> 44:48.500]  и того асимпатически 0 плюс асимпатическая единица и минус просто единица, куда это все,
[44:48.500 --> 45:00.740]  0 плюс почти единица, минус ровно единица, 0, то есть это действительно все вместе в пределе
[45:00.740 --> 45:07.340]  дает 0, а тут стало быть в пределе получается единица, что и требовалось в пункте 2 доказать,
[45:07.340 --> 45:16.420]  ну отлично, у меня осталось как раз полчаса на то, чтобы доказать пункт 1, ну и может быть сформулировать
[45:16.420 --> 45:23.580]  теорему следующего раза, если успеем, будет важное нововведение, я частично ее докажу,
[45:23.580 --> 45:32.260]  такого раньше не было, так, ну давайте так, мы помним, что мат ожидания стремится к нулю в
[45:32.260 --> 45:41.500]  этом случае, само мат ожидания мы тоже помним, давайте хотя бы вот это все сотру, но из того,
[45:41.500 --> 45:45.980]  что оно стремится к нулю, ничего не следует, потому что могут все-таки теоретически быть
[45:45.980 --> 45:53.380]  другие компоненты, да их труднее отщепить, это понятно, но поскольку само количество возможностей,
[45:53.380 --> 46:02.540]  возможных размеров этих компонент растет с ростом числа вершин, то вдруг в сумме там накопится и непонятно.
[46:02.540 --> 46:17.340]  Вот здесь я сейчас честно просто посчитаю оценку для суммы,
[46:17.340 --> 46:24.780]  что бы я не делал в начале лекции, сейчас я сделаю, ну здесь попроще просто и так мучить,
[46:24.780 --> 46:33.660]  как там я не буду, а здесь немножко помучаю, давайте, пункт один, пусть х на графе, это теперь не число
[46:33.660 --> 46:49.900]  изолированных вершин, а просто число нетривиальных компонентов связанности, так, что значит тривиальная
[46:49.900 --> 46:56.500]  компонента, но тривиальная компонента это весь граф, если он связан, то есть это число компонент
[46:56.500 --> 47:02.540]  связанности, ну хорошо, давайте так, это число компонент связанности, в каждой из которых не больше,
[47:02.540 --> 47:14.460]  чем n-1 вершина, сейчас понятно, конечно, да, не только полного связанного, любого связанного
[47:14.460 --> 47:23.940]  графа x будет равняться нулю, любого связанного графа x равняется нулю, ну то есть можно сказать так,
[47:23.940 --> 47:34.940]  x это конечно сумма x1 плюс и так далее, плюс xn минус 1, где xt от g это число компонент на i вершинах,
[47:34.940 --> 47:44.700]  компонент на i вершинах, ну то есть в частности x1 это как раз число изолированных вершин,
[47:44.700 --> 47:55.940]  в котором мы работали, соответственно, математическое ожидание x это сумма по i от 1 до n-1,
[47:55.940 --> 48:08.060]  мат ожидания xt, мы даже знаем, что первая слагаемая в этой сумме стремится к нулю, вот если бы оказалось,
[48:08.060 --> 48:14.580]  что вся эта сумма стремится к нулю, тогда мы бы по неравенству Маркова получили, что компонент
[48:14.580 --> 48:25.140]  связанных нетривиальных нет и стал быть граф связанных, я не очень быстро говорю, а нормально точно так,
[48:25.140 --> 48:34.740]  но давайте посчитаем или оценим ex и t в общем случае, как это посчитать, но опять можно какую-то
[48:34.740 --> 48:43.940]  линейность использовать, то есть надо просуммировать по кому, мы берем n вершин, пресловутая сарделька,
[48:43.940 --> 48:49.940]  и мы выбираем произвольные и вершин, которые хотим протестировать на то, что вот именно это
[48:49.940 --> 49:02.420]  подсарделька образует связанную компоненту, то есть надо просуммировать по всем i из v мощности,
[49:02.420 --> 49:14.740]  и маленькая вероятность того, что i является компонентой в случайном графе g, g от np,
[49:14.740 --> 49:26.460]  это линейность тоже, мы перебираем все возможные потенциальные множество вершин вот этих компонент
[49:26.460 --> 49:33.780]  связанности, перебираем все под множество вершин, имеющие мощности маленькая, и каждое
[49:33.780 --> 49:40.300]  тестируем на то, что оно таки образует компоненту, мат ожидания индикатора это вероятность того
[49:40.300 --> 49:48.300]  условия, которое задает на нем единицу, на который этот индикатор указывает, слушайте, но есть
[49:48.300 --> 49:54.380]  проблема, непонятно как посчитать вероятность того, что данное конкретное множество вершин является
[49:54.380 --> 50:02.900]  компонентой, но давайте так, а что значит, что данное конкретное множество является компонентой,
[50:02.900 --> 50:07.940]  это значит на самом деле пересечение двух условий, пересечение в смысле одновременное
[50:07.940 --> 50:14.300]  выполнение двух условий, во-первых, индуцированное это множество под граф должен быть связанным,
[50:14.300 --> 50:22.620]  согласны, а во-вторых, это же компонента, вот таких ребер быть не может, никаких,
[50:22.620 --> 50:29.820]  ребер у которых одна вершина внутри конкретного и большого, а другая вершина вне его, потому что
[50:29.820 --> 50:39.300]  это компоненты, это максимальный остров связности, вот давайте тупо это оценим сверху суммой по тем
[50:39.300 --> 50:47.500]  же самым и большой мощности и маленькой вероятности последнего условия, про связанность не очень
[50:47.500 --> 50:53.220]  удобно рассуждать, непонятно с какой вероятностью индуцированный граф связан, а вот вероятность того,
[50:53.220 --> 51:08.060]  что из И в В-И нет ребер, вот это легко посчитать, и это, конечно, ну может быть грубая верхняя оценка
[51:08.060 --> 51:14.380]  для вероятности, которая нас интересует, вероятность пересечения двух условий мы просто тупо оцениваем
[51:14.380 --> 51:21.740]  вероятностью одного из них, понятно, тем не менее даже этого для нашего относительно грубого
[51:21.740 --> 51:26.660]  утверждения хватит, вот если бы мы захотели вот это доказывать, так такой бы номер не прошел,
[51:26.660 --> 51:33.820]  а для нашего утверждения, когда С там строго чего-то меньше, больше этого хватает, ну-ка скажите
[51:33.820 --> 51:41.500]  мне, что получается, есть прям совершенно явный ответ, для всей суммы сразу, очевидно, что все
[51:41.500 --> 51:48.060]  слагаемые одинаковые, только чему они равны, очевидно, потому что какая разница, какое И большой
[51:48.060 --> 51:54.580]  размер и маленькое зафиксировать, но зафиксировали какое-то, какова вероятность, что ни одно ребро
[51:54.580 --> 52:03.300]  из него наружу не идет, нет мостика между ним и остальными вершинами, n-ы умножить на И, вот ответ,
[52:03.300 --> 52:15.460]  c из n по И, 1-p в тепени И на n-ы, вот так, и умножить на n-ы это количество потенциальных мостиков,
[52:15.460 --> 52:24.740]  каждая вершина из И большого может быть соединена с любой вершины из вне его, из В-ы большое,
[52:24.740 --> 52:30.780]  таких пар вершин, таких потенциальных мостиков и умножить на n-ы, они все должны отсутствовать,
[52:30.780 --> 52:36.100]  ну а самих вот этих множец слагаемых, их c из n по И, поэтому сумма получается такой,
[52:36.100 --> 52:44.100]  как я написал, соответственно, интересующая нас мат ожидания получается равным, в свою очередь,
[52:44.100 --> 52:57.700]  сумма по И от 1 до n-1, c из n по И на 1-p в тепени И на n-ы, но только неравном, конечно, а меньше,
[52:57.700 --> 53:11.420]  либо равно, получилось, да, еще раз, вы согласны, что если вся эта сумма стремится к нулю, то мы в
[53:11.420 --> 53:20.900]  героях мы доказали пункт 1, вот это точно понятно, это просто неравенство Маркова, вероятность того,
[53:20.900 --> 53:27.460]  что х больше, либо равно единице не больше, чем мат ожидания х, если мы знаем, что оно стремится
[53:27.460 --> 53:34.100]  к нулю, ну все, значит, вероятность со стремящейся к нулю есть хоть одна связанная компонента,
[53:34.100 --> 53:38.500]  отличная от всего графа, но, стало быть, вероятность со стремящейся к единице,
[53:38.500 --> 53:44.140]  таких компонентов нет, и граф связан, но вроде разъяснил совсем подробно, может быть, для тех,
[53:44.140 --> 53:52.260]  кого здесь нет, так, может быть, действительно, здесь все понимали, но кто будет слушать записи,
[53:52.740 --> 54:00.620]  вот, ну хорошо, то есть надо как-то оценить теперь вот эту биоку, видите, мы знаем, что первая слагаемая
[54:00.620 --> 54:09.260]  в ней и равно единице, это как раз n умножить на 1-p в n-1, смотрите, и равно единице, это n на 1-p в n-1,
[54:09.260 --> 54:14.420]  среднее число изолированных вершин, с которым мы работаем, мы знаем, что оно стремится к нулю,
[54:14.420 --> 54:19.900]  но из этого не следует, что сумма растущего числа слагаемых стремится к нулю, да, наверное,
[54:19.900 --> 54:27.260]  каждая последующая меньше предыдущего, но и что, ну, из интуитивных соображений отколоть одну вершину
[54:27.260 --> 54:34.220]  проще, чем отколоть две, а это в свою очередь проще, чем три и так далее, но вдруг накопится много
[54:34.220 --> 54:40.020]  слагаемых стремящихся к нулю, растущее их число может перестать стремиться к нулю, вот сейчас мы
[54:40.020 --> 54:40.860]  с этим справимся,
[54:54.860 --> 55:08.700]  мы с этим справимся как-нибудь, а, ну, во-первых, давайте сразу заметим, товарищи, что суммировать
[55:08.700 --> 55:15.260]  достаточно до серединки, потому что все, что идет после серединки, абсолютно симметрично
[55:15.260 --> 55:21.100]  к началу, и c симметрично относительно n пополам, и вот эта штука тоже симметрично относительно
[55:21.100 --> 55:28.100]  n пополам, достаточно суммировать до n пополам, это важно, ну, важно в каком-то смысле, так удобнее
[55:28.100 --> 55:36.340]  считать, нас реально интересует сумма pi от единицы до n пополам, c из n pi 1-p в степени
[55:36.340 --> 55:43.540]  и на n минусы, мы хотим доказать, что она стремится к нулю, давайте я для начала объясню идею,
[55:43.540 --> 55:55.420]  обозначим каждая слагаемая, ну, скажем a i t от n, я вроде так всегда делаю, это удобно, так у меня совсем
[55:55.420 --> 56:04.380]  из всяких кусочек мелко, сейчас я возьму другой, есть очень хорошие и большие, так, вот давайте так,
[56:04.380 --> 56:13.020]  первая идея, вынесем-ка мы за скобку a 1 от n, мы знаем, что оно стремится к нулю, потому что это в очередной
[56:13.020 --> 56:20.700]  раз повторяю, как раз мат ожидания числа изолированных вершин, вынесем за скобку,
[56:20.700 --> 56:30.380]  ну, первая слагаемая будет 1, вторая слагаемая будет a 2 от n поделить на a 1 от n, третья слагаемая
[56:30.380 --> 56:44.980]  будет a 3 от n поделить на 2 от n, умножить на 2 от n, поделить на a 1 от n, ну и так далее, понятная идея,
[56:44.980 --> 56:52.460]  идея состоит в том, чтобы заменить это все геометрической прогрессией, ну и чем-то на нее
[56:52.460 --> 57:02.780]  похожем, если бы оказалось, что каждая вот такая дробь ограничена сверху чем-то стремящимся к нулю,
[57:02.780 --> 57:09.380]  то сумма вся сходилась бы к единице и будучи умноженной на что-то, опять же, стремящимся к нулю,
[57:09.380 --> 57:17.860]  давала бы ноль в пределе, знаете, как круто было бы, но к сожалению, прям так у нас не получится,
[57:17.860 --> 57:26.500]  вот совсем так не получится, поэтому я сделаю следующий финт, я разобью вот эту сумму на две
[57:26.500 --> 57:31.660]  части, у нас такие случаи уже бывали в нашей практике, когда по-разному приходилось оценивать
[57:31.660 --> 57:38.300]  на разных участках, ну хорошо, хоть не на бесконечное число, на две только, значит,
[57:38.300 --> 57:46.340]  в первой части у нас будет сумма по и от единицы до, как у меня обычно бывает,
[57:46.340 --> 57:56.900]  ну давайте до n на корень из логарифма n. Не, ну я очень аккуратно объясню обязательно,
[57:56.900 --> 58:01.940]  почему на корень из логарифма, там можно не на корень из логарифма, а на повторный логарифм,
[58:01.940 --> 58:08.220]  там это я вам объясню, как я именно на корень взял, все будет понятно, можно не на корень. Так,
[58:08.220 --> 58:15.940]  здесь t из n по i, а можно было а и от n написать, ну ладно, 1 минус p в степени i на n минусы,
[58:15.940 --> 58:25.940]  ну а дальше остаток сумма по i. Ох, давайте будем издеваться друг над другом от этой
[58:25.940 --> 58:35.220]  целой части плюс один до n пополам того же самого. Нормально так многоточиями? Ну понятно,
[58:35.220 --> 58:41.380]  то же самое суммируется, и нижний предел такой же, как верхний в первой сумме, тут понятно,
[58:41.380 --> 58:50.060]  ну плюс один еще. Смотрите, в чем смысл этого подразделения я сразу скажу. Вот на этой части,
[58:50.060 --> 58:56.020]  за счет того, что i все-таки относительно маленькая, не дотягивается прямо до n пополам,
[58:56.020 --> 59:01.540]  а дотягивается только вот до такой функции, мы таки сумеем воспользоваться идеей с
[59:01.540 --> 59:10.460]  геометрической прогрессией, у нас все получится. А на этой части все станет уже, вот все, в смысле,
[59:10.460 --> 59:16.460]  каждое слагаемое станет настолько маленьким, что мы ее оценим как хвостик, который с посвистом
[59:16.460 --> 59:23.180]  стремится к нудам. Вот замысел такой. Друзья, я примерно понял, кто сказал замысел. Сейчас я его
[59:23.180 --> 59:29.300]  реализую, у вас все формально будет прописано, конечно. Давайте действительно посчитаем вот это
[59:29.300 --> 59:40.100]  отношение, то есть аи плюс первая от n к аитому от n. Посчитаем, как относятся. Хочется успеть
[59:40.100 --> 59:51.340]  за сегодня это сделать. Значит аи плюс первая от n на аит от n. Я утверждаю, что если i ограничена
[59:51.340 --> 59:55.660]  сверху какой-то функции, которая бесконечно мала по сравнению с n, ну вот такой, например,
[59:55.660 --> 01:00:05.780]  как мы взяли, то все хорошо. Давайте честно напишем это c из n по i плюс 1, 1 минус p в степени
[01:00:05.780 --> 01:00:19.940]  i плюс 1 на n минус i минус 1 поделить на c из n по i 1 минус p в степени i на n минус i. Ну просто
[01:00:19.940 --> 01:00:26.500]  честно написал. Так, ну я не знаю, насколько вы в уме прямо готовы делить ц, но мы сейчас это
[01:00:26.500 --> 01:00:33.060]  сделаем. Тут n факториал, тут n факториал, они сокращаются, очевидно. Теперь вот у числителя
[01:00:33.580 --> 01:00:42.060]  у числителя в знаменателе стоит i плюс 1 факториал, а у знаменателя, в знаменателе же стоит i факториал.
[01:00:42.060 --> 01:00:49.300]  Но понимаете, что в итоге в знаменателе остается i плюс 1. Вот так и пишем. В знаменателе остался
[01:00:49.300 --> 01:00:56.140]  i плюс 1 и точно также в числителе выживает n минус i. Ну по совершенно такой же причине,
[01:00:56.140 --> 01:01:07.180]  можете это проверить. Я ж вроде с этого начала, это компоненты размера от 1 до n минус 1. Любая
[01:01:07.180 --> 01:01:15.100]  компонента отличная от всего графа. Почему? Вопрос-то. Мы вернулись к началу или мы разбираемся
[01:01:15.100 --> 01:01:23.380]  с тем, что я сейчас делаю? Вопрос-то о чем вообще? Что? Ну мы с самого начала это уточняли. Меня вот
[01:01:23.380 --> 01:01:28.300]  спрашивают, что значит нетривиальная? Я сказал, что если граф связан, то нетривиальных компонент ноль. Именно
[01:01:28.300 --> 01:01:33.260]  поэтому мы хотим доказать, что вероятность вот этого события стремится к нулю. И сейчас оцениваем
[01:01:33.260 --> 01:01:38.660]  мат ожидания чем-то стремящимся к нулю. Все, мы свели задачу к чисто аналитической. Сейчас я занимаюсь
[01:01:38.660 --> 01:01:44.460]  мат-анализом, позволяющим убедиться в том, что вся эта бяка стремится к нулю. И все это будет давать
[01:01:44.460 --> 01:01:52.260]  доказательство теоремы. Так, ну давайте вот здесь сокращение тоже проведем. Смотрите, вот тут тоже
[01:01:52.260 --> 01:01:59.540]  есть и, тут тоже есть n минус и, то есть внизу все сокращается. А вверху остается, ну оно условно
[01:01:59.540 --> 01:02:05.740]  вверху, оно может и вниз пойдет в каком-то смысле. Вверху остается минус и, 1 минус п в степени минус и,
[01:02:05.740 --> 01:02:12.060]  вот так, и умножить на минус 1. И прибавить надо еще вот эту вот единичку на n минус и минус 1,
[01:02:12.060 --> 01:02:21.020]  то есть правильно, да? Плюс n минус и минус 1, вот так. Единичку надо умножить на всю скобку,
[01:02:21.020 --> 01:02:30.020]  а ишку только на минус единицу. Ой, ну слушайте, и у нас вообще какое угодно вот в этих пределах,
[01:02:30.020 --> 01:02:38.380]  правда же? В общем, по-моему, ничего сильно лучше с точностью до константы, чем оценить это вот так,
[01:02:38.380 --> 01:02:50.020]  я бы сделать не смог. Тут будет n минус 2 и минус 1. Я хочу сказать, что вот эта дробь,
[01:02:50.020 --> 01:02:57.220]  вот эта дробь, по сути, ну меньше n, это очевидно совершенно, а лучше и не скажешь. Потому что
[01:02:57.220 --> 01:03:05.020]  когда и, например, равняется единице, но это n минус 1 пополам и есть. Ну, в общем, я и оцениваю,
[01:03:05.020 --> 01:03:11.300]  это не окупляет ничего. Ну, оценил, как ты оценил, победитель не судя, сейчас я победю через некоторое
[01:03:11.300 --> 01:03:19.020]  время. Так, теперь смотрите, вот сейчас важный момент. Поскольку и у нас находится в пределах
[01:03:19.020 --> 01:03:28.940]  до функции, которая бесконечно мала по сравнению с n, то, ну ладно, давайте я честно напишу, и у нас
[01:03:28.940 --> 01:03:41.900]  меньше, чем n поделить на корень из логарифма. Меньше? Меньше. Минусом больше, но тут чиселка
[01:03:41.900 --> 01:03:54.860]  меньше единицы опять меньше. Я могу вот так написать n на 1 минус p в степени n минус 2n на корень из
[01:03:54.860 --> 01:04:02.100]  логарифма n минус 1. Но согласитесь, что в показателе экспонента написано выражение, которое от и уже
[01:04:02.100 --> 01:04:10.300]  никак не зависит, но в любом случае асимпатически равно n. Вот сразу пометьте себе, в этом смысле,
[01:04:10.700 --> 01:04:18.140]  в этом месте не важно, что написать, n на корень из логарифма или n просто на логарифм или n на
[01:04:18.140 --> 01:04:23.780]  повторный логарифм. Любая вот эта верхняя граница, которая бесконечно мала по сравнению с n, тут
[01:04:23.780 --> 01:04:29.180]  сработает. Но нам еще с хвостом потом предстоит разбираться, и вот там прояснится, почему я
[01:04:29.180 --> 01:04:35.580]  нарисовал именно корень из логарифма. Это будет довольно весело. Понятно сказал? Так, ну здесь-то
[01:04:35.580 --> 01:04:42.260]  что получилось? Ну, смотрите, что получилось. n на 1 минус p в степени n на 1 плюс о малой от единицы.
[01:04:42.260 --> 01:04:56.020]  Вы понимаете, что это стремится к нулю? Ну, мы с вами знаем, что n на 1 минус p в n минус 1
[01:04:56.020 --> 01:05:03.540]  стремится к нулю, потому что мы находимся в нынешнем режиме пункте 1. Ну, а что будет,
[01:05:03.540 --> 01:05:07.580]  кто изменится, если снова на 1 плюс о малой от единицы, тут до множества? Все равно стремится к нулю.
[01:05:07.580 --> 01:05:17.020]  Так, мы выкладку делали. Там вот е в степени минус p, там тоже самое. Поэтому давайте это обозначим
[01:05:17.020 --> 01:05:22.820]  буквой q от n, вот это, и она стремится к нулю. Она стремится к нулю, потому что c больше единицы.
[01:05:22.820 --> 01:05:33.220]  Ну и у нас получается, что вот эта вся сумма, это есть a1 от n, умножить на 1 не равняется
[01:05:33.220 --> 01:05:43.540]  меньше или равняется. 1 плюс q от n плюс q квадрат от n, и давайте ее просто тупо оценим бесконечной суммой.
[01:05:43.540 --> 01:05:50.940]  Так, друзья, поняли, откуда геометрическое прогрессия все сейчас? Вдруг тот раньше не
[01:05:50.940 --> 01:06:02.660]  понимал. Ну а это равняется, конечно, вот так стираем, это равняется a1 от n на 1 поделить на 1
[01:06:02.660 --> 01:06:09.460]  минус q от n. a1 от n мы знаем стремится к нулю, q от n мы знаем стремится к нулю, значит все стремится к нулю.
[01:06:09.460 --> 01:06:19.060]  С первой суммой разобрались. Но видите, мы не имеем права в этой первой сумме брать какую-то
[01:06:19.060 --> 01:06:25.500]  функцию порядка n. n пополам бы не сработало, потому что вот здесь вычилось бы n пополам и вышла бы
[01:06:25.500 --> 01:06:33.140]  неприятность, стремления к нему уже бы не было. Это важно. Но хвост-то все равно сейчас будет маленький.
[01:06:33.140 --> 01:06:35.220]  Толстый хвост.
[01:06:49.060 --> 01:06:53.060]  Остался хвост.
[01:06:59.620 --> 01:07:10.940]  Так, хвост. Это сумма по и вот целой части n на корень из логариф men плюс 1 до n пополам,
[01:07:10.940 --> 01:07:26.060]  c из n по i 1 минус p в степени i на n минус i. Это товарищи меньше, чем n умножить на 2 в степени n
[01:07:26.060 --> 01:07:38.420]  умножить на 1 минус p в степени n пополам, я сейчас напишу потом поясню, в степени n пополам умножить
[01:07:38.420 --> 01:07:47.620]  на n деленное на корень из логариф men. Это издевательская на самом деле оценка. Я просто
[01:07:47.620 --> 01:07:56.660]  c тупо оценил как 2 в степени n, но любая c меньше, чем 2 в степени n. Количество слагаемых тупо оценил
[01:07:56.660 --> 01:08:06.020]  числом n, а вот эту вот величину оценил следующим образом. Вот здесь со знаком минус я воспользовался
[01:08:06.020 --> 01:08:13.260]  тем, что i меньше, чем n пополам не больше, чем n пополам. Минус, но еще в показателе числа
[01:08:13.260 --> 01:08:19.260]  меньшего единицы, поэтому можно подставить n пополам, получается n пополам. А вместо i вот
[01:08:19.260 --> 01:08:26.660]  подставил этот n логариф men, которого она больше. Получил вот такую оценку. Все, тут грубее некуда.
[01:08:26.660 --> 01:08:35.060]  Теперь смотрите, это как обычно равняется на 2 в n на е в степени логариф men от 1 минус p,
[01:08:35.060 --> 01:08:47.260]  но снова на n пополам на n на корень из логариф men. Это меньше либо равно n на 2 в степени n на
[01:08:47.260 --> 01:08:58.860]  е в степени минус p, n пополам, n на корень из логариф men. Это логариф от 1 минус p не больше,
[01:08:58.860 --> 01:09:03.980]  чем минус p. Стандартное неравенство. Мы им тоже когда-то пользовались. Теперь подставляем честно
[01:09:03.980 --> 01:09:16.860]  p, n, 2 в n, а p это у нас c, логариф men поделить на n. Дальше идет n пополам, идет n поделить на
[01:09:16.860 --> 01:09:23.780]  корень из логарифа n. И вот тут-то и проясняется, почему я выбрал именно корень из логарифа n.
[01:09:23.780 --> 01:09:34.420]  Потому что я сейчас сделаю вот так шлёп. Только ради этого, товарищи. Но, конечно, я должен был
[01:09:34.420 --> 01:09:40.940]  выбрать тут такую функцию, чтобы она не полностью убила вот этот логариф. Вот это важно, потому что
[01:09:40.940 --> 01:09:49.900]  я же еще вот такой шлёп-шлёп сделаю. И у меня останется вот так. Я все под одну экспоненту
[01:09:49.900 --> 01:09:58.780]  загоню. E в степени логариф натуральный n, это n, плюс n логариф натуральной двойки, это 2 в n. И тут
[01:09:58.780 --> 01:10:09.100]  остается минус c пополам, умножить на n корней из логарифа n, и все. Да, все, больше ничего.
[01:10:09.100 --> 01:10:15.740]  Делить на единицу это не нужно. Так, друзья, видите, что так осталось? Мне было важно выбрать такую
[01:10:15.740 --> 01:10:20.420]  функцию, чтобы она с одной стороны удобно красиво на доске сокращалась вот этим логарифом,
[01:10:20.420 --> 01:10:26.540]  а с другой стороны не сокращала его полностью, потому что мы здесь n умножаем на растущую
[01:10:26.540 --> 01:10:34.300]  функцию, а вычитаем это дело из n умноженной на константу. Но уж логарифом это вообще фигня. То есть
[01:10:34.300 --> 01:10:39.500]  когда мы берем вот эту сумму и вычитаем из нее такую штуку, мы получаем нечто стремящееся к
[01:10:39.500 --> 01:10:49.540]  минус бесконечности, но это показатели экспоненты, значит, то радость все стремится к нулю. То есть
[01:10:49.540 --> 01:10:54.700]  вот в качестве разделителя между двумя суммами можно было брать любую функцию. Можно взять вот
[01:10:54.700 --> 01:11:03.580]  такую, как я взял, можно взять какой-нибудь n на ln. Она должна быть маленькая от n с одной стороны,
[01:11:03.580 --> 01:11:08.980]  но она должна быть больше-больше, чем n поделить на логариф mn. Если я возьму просто n поделить
[01:11:08.980 --> 01:11:14.740]  на логариф mn, я кокну вот этот логарифом, и вот это преимущество потеряется. А так, в принципе,
[01:11:14.740 --> 01:11:22.820]  вот раздел мог быть каким угодно. Понятно поясню? Нет, ну чисто технически-то всем понятно,
[01:11:22.820 --> 01:11:29.900]  сократили и все получилось. Все, я доказал теорему. Но знаете, поскольку у меня остается меньше
[01:11:29.900 --> 01:11:35.540]  пяти минут, я даже не буду формулировать теорему следующего раза, я просто ее в следующий раз
[01:11:35.540 --> 01:11:37.380]  начну. А на сегодня тогда все.
