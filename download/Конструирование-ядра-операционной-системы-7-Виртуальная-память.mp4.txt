[00:00.000 --> 00:13.920]  Я еще раз поздравляю всех с завершением первого блока, и сегодня мы начинаем
[00:13.920 --> 00:24.280]  новый этап нашего курса, то есть этап, где мы погрузимся в виртуальную память.
[00:24.760 --> 00:34.600]  План на сегодня у нас следующий. Перед тем, как мы погрузимся в саму виртуальную
[00:34.600 --> 00:40.080]  память и посмотрим, как она работает, мы все-таки вспомним, как мы эту виртуальную
[00:40.080 --> 00:45.840]  память можем настроить в операционной системе. Для этого поймем, что в общем-то
[00:45.840 --> 00:49.880]  виртуальная память это не единственный способ преобразования. То есть мы уже
[00:49.880 --> 00:53.580]  помним про сегментную адресацию, про которую мы разбирали на второй
[00:53.580 --> 01:00.340]  лабораторной работе. Соответственно, еще вспомним про то, как работает Memory
[01:00.340 --> 01:08.220]  Controller. После этого мы поговорим про ММУ на x86, то есть посмотрим на
[01:08.220 --> 01:16.580]  реализацию таблиц и страниц, и немножко разберем, как, собственно, этот ММУ можно
[01:16.580 --> 01:23.460]  перенастраивать в операционной системе. Перед тем, как мы к этому перейдем, у меня
[01:23.460 --> 01:32.460]  такой простой вопрос. У вас на компьютере установлено 4 гигабайта оперативки, ну
[01:32.460 --> 01:38.780]  допустим. Соответственно, когда работает операционная система, она использует,
[01:38.780 --> 01:46.180]  например, там адрес такой, как, например, 4 гигабайта, там плюс 100 мегабайт. Там
[01:46.180 --> 01:51.420]  действительно оперативная память операционной системы не падает. Как такое
[01:51.420 --> 02:01.460]  возможно? Нет, виртуальная память еще не используется. Тоже еще не используется, 1 к 1.
[02:01.460 --> 02:13.860]  Нет, адресная шина 48-битная, это обычная x86-64. Виртуальная память используется, но в режиме 1 к 1.
[02:13.860 --> 02:31.620]  Нет, все пишется. Нет, это обычная оперативка. Нет, никакого пэйчфолдта, просто пишем. Нет,
[02:31.620 --> 02:43.780]  плашка честная, 4 гигабайта. Нет, эта память не имеет, скажем,
[02:44.180 --> 02:52.780]  еще одного адреса ниже, чем вот конкретно этот. То есть, грубо говоря, если перебирать адреса от нуля до...
[02:52.780 --> 03:09.660]  Нет, кэши выключены. Нет. Ну ладно, на самом деле все очень просто и разгадка кроется в следующем.
[03:09.660 --> 03:24.020]  То есть, у вас... Да. Ну, не так важно, на самом деле. Ну, в данном случае просто это x86, и на x86 это относительно
[03:24.020 --> 03:31.660]  актуально, но в принципе это не обязательно может быть x86. Дело в том, что контроллер оперативной
[03:31.660 --> 03:41.060]  памяти, с которым вы работаете, видит оперативную память одним способом, а вы, как код, исполняющийся на
[03:41.060 --> 03:47.300]  центральном процессоре, видите оперативную память другим образом. Соответственно, если у вас, допустим,
[03:47.300 --> 03:55.580]  есть условно DDR-память, которую вы каким-то образом используете, совершенно не означает, что эта DDR-память
[03:55.580 --> 04:06.780]  будет отображаться с нулевого адреса по размеру этой DDR-памяти. Такая особенность хорошо объясняет,
[04:06.780 --> 04:15.820]  почему нужно было в какой-то момент прийти к мемори-мапам, то есть, некоторым картам памяти,
[04:15.820 --> 04:23.780]  которые определяют... Сейчас стандарт UFI. До этого был, соответственно, ABIOS, был вызов функции E820,
[04:23.780 --> 04:31.940]  который вам говорит, что вот на самом деле ваша оперативная память находится вот там-то, там-то и
[04:31.940 --> 04:39.340]  там-то, она имеет вот такие-то типы. Потому что, если бы вы просто смотрели, как вы делали там раньше,
[04:39.340 --> 04:44.940]  например, через регистр того же самого RTC, сколько действительно там у вас установлена оперативной
[04:44.940 --> 04:50.980]  памяти, то вот вы узнали, что у вас 4 гигабайта, и в какой-то момент вы писали совершенно не туда,
[04:50.980 --> 05:03.260]  куда надо. Почему? Ну, так исторически сложилось, что конкретно на x86 реально там вот память,
[05:03.260 --> 05:10.140]  которая чуть ниже 4 гигабайт, она используется под устройство. Ну, в частности, мы помним,
[05:10.140 --> 05:14.940]  наверное, первую лекцию. Кто вспомнил, возможно, бы ответил на вопрос. У процессора есть reset
[05:14.940 --> 05:21.820]  vector. Соответственно, reset vector на x86 находится чуть-чуть пониже, чем 4 гигабайта. Соответственно,
[05:21.820 --> 05:29.820]  чуть под 4 гигабайтами у процессора замаплена флэш-память, и, соответственно, вот та часть,
[05:29.820 --> 05:39.300]  вот которая, грубо говоря, вот эта вот под флэшку, она тратится, ее потом просто перемещают в
[05:39.300 --> 05:46.500]  более высокие адреса. Таким образом у вас получается, что у вас там от нуля до, грубо говоря,
[05:46.500 --> 05:54.020]  4 гигабайта минус 20 мегабайт идет условно обычная память, потом у вас идет флэш-память,
[05:54.020 --> 05:59.220]  потом у вас снова идет обычная память, которую мы вернули, потому что здесь было замаплено
[05:59.220 --> 06:04.460]  устройство. Соответственно, вот такие хитрые преобразования, они делаются там не только для
[06:04.460 --> 06:13.860]  флэш-памяти. Ну вот, например, у вас у всех есть видеокарточка. Вы знаете, как видеокарточка
[06:13.860 --> 06:22.860]  общается с вашим компьютером? Да, есть шина PCI, PCI express в настоящий момент. Соответственно,
[06:22.860 --> 06:32.380]  мы помним из третьей лабораторной работы, вот вывод, что для того, чтобы добраться до PCI
[06:32.380 --> 06:40.500]  express, у нас есть некоторые порты ввода-вывода, но в принципе обычно адресное пространство устройств
[06:40.500 --> 06:47.820]  еще и отображается через оперативную память, то есть через MMIO. Вот через MMIO стандартно
[06:47.820 --> 06:54.340]  отображается конфигурационное адресное пространство, и это отображение плюс-минус фиксировано,
[06:54.340 --> 07:01.620]  то есть настраивается специфичным для вашей платформы образом и плохо там, скажем, меняется.
[07:01.620 --> 07:11.020]  А если говорить о именно самой процедуре общения, то есть там, как, например, текстуры попадают в
[07:11.020 --> 07:19.940]  видеопамять, то для этого используется такая штука, называется бары или base address register. Вот у PCI,
[07:19.940 --> 07:37.220]  у него может быть 6 таких баров. У PCI может быть 6 таких баров и оно вот выглядит примерно вот так,
[07:37.220 --> 07:50.540]  где каждый, собственно, бар это 32-битное значение. Таким образом, у вас, соответственно,
[07:50.540 --> 07:57.540]  вот все бары, которые там были со старым PCI, они должны были находиться в 32-битном адресном
[07:57.540 --> 08:05.220]  пространстве, потому что те люди, которые писали, соответственно, стандарт PCI, они не считали,
[08:05.220 --> 08:10.980]  что возникнет такая вероятность, что у вас там будет больше, например, 2 гигабайт или 3 гигабайт
[08:10.980 --> 08:16.220]  оперативной памяти. То есть можно все разместить в 4 гигабайтах, там все равно шинта 22-битная,
[08:16.220 --> 08:24.820]  никогда туда не долезет. Соответственно, в реальности размер бара может быть там по вот такой вот
[08:24.820 --> 08:40.860]  штуке не больше 256 мегабайт, просто по простой причине, что часть битов в этом баре отведена
[08:40.860 --> 08:49.180]  на служебные данные, то есть там указывается тип этого бара и некоторые другие вещи. Как вы
[08:49.180 --> 08:55.700]  понимаете, вот с такими ограничениями жить достаточно неприятно, то есть, во-первых,
[08:55.700 --> 09:05.260]  размер 32 бита сильно ограничивает в адресах и, во-вторых, соответственно, там размер самого
[09:05.260 --> 09:12.220]  бара всего в 200, там, 56 мегабайт не более, он нас еще больше ограничивает. Кстати, не сказал,
[09:12.220 --> 09:22.220]  как прочесть размер, собственно, бара, вы просто пишете в текущее значение все f, то есть все биты
[09:22.220 --> 09:28.380]  устанавливаете, после этого считываете и смотрите, какие биты оказались нулями. То есть те биты,
[09:28.380 --> 09:33.780]  которые оказались нулями, они соответственно декодируются, можно узнать таким образом размер.
[09:33.780 --> 09:46.540]  Вот, поэтому сейчас в современных стандартах PCI у вас бар, он находится как бы в двух половинках,
[09:46.540 --> 09:52.180]  то есть, соответственно, первые там, грубо говоря, 32 бита, это младшие значения бара,
[09:52.180 --> 09:59.060]  следующие там 32 бита, это у вас старшие, соответственно, биты, соответствующие бару.
[09:59.060 --> 10:08.100]  Таким образом можно получить либо 6 32-убитных баров, либо 3 64-убитных, можно, в принципе,
[10:08.100 --> 10:19.740]  в перемешку. Вот, и как результат, например, там в биосах относительно давно появилась там опция
[10:19.740 --> 10:29.620]  above 4G encoding, она как раз вот про особенность расположения PCI памяти у вас в оперативной памяти.
[10:29.620 --> 10:36.700]  То есть, когда раньше, собственно, для старых операционных систем можно было расположить PCI
[10:36.700 --> 10:45.140]  память только здесь, ну то есть ниже 4 гигабайт, то соответственно с приходом вот этой опции above
[10:45.140 --> 10:53.460]  4G decoding encoding вы можете использовать 64-убитные бары и можете, соответственно, записать адрес
[10:53.460 --> 11:01.540]  бара там выше 4 гигабайта, соответственно, вот такой вот ерунды с потерей адресов. Вот здесь вот
[11:01.540 --> 11:08.620]  обычно там терялось несколько сотен мегабайт и их потом пришлось здесь искать. Ее больше сейчас нет.
[11:08.620 --> 11:20.980]  Кроме этого, кстати, вот возможность записать, соответственно, бар в два, соответственно,
[11:20.980 --> 11:28.020]  32-убитных регистр она еще привела к возможности увеличить сам размер бара. Ну то есть представьте,
[11:28.020 --> 11:33.980]  что у вас графической карточке, ну там допустим, сколько сейчас там, ну 32 гигабайта оперативной
[11:33.980 --> 11:40.100]  памяти, например, соответственно, вам хочется туда передать какую-нибудь текстуру большую или там
[11:40.100 --> 11:44.180]  не текстура, а какой-нибудь там вычислительный набор данных, которые вам надо обработать для
[11:44.180 --> 11:54.740]  вашей нейросетки. Если у вас размер бара там 256 мегабайт, то вам придется последовательно маппить
[11:54.740 --> 12:03.500]  там вот кусками по 256 мегабайт видеопамять в вашем драйвере и загружать вот эту текстуру вот
[12:03.500 --> 12:11.620]  так вот по кусочкам. Это не очень удобно, там гораздо проще, соответственно, отобразить всю
[12:11.620 --> 12:17.500]  видеопамять в оперативную память, то есть установить размер бара там, скажем, максимальный,
[12:17.500 --> 12:24.980]  и там современные видеокарты, ну где-то так, начиная с 2008 года, ну чуть-чуть попозже, 2008 год это
[12:24.980 --> 12:35.100]  стандарт появился PCIe. Они позволяют это делать, поэтому мало того, что у вас, соответственно,
[12:35.100 --> 12:40.580]  сами бары переехали в высокую память, так они еще и увеличились. Ну, увеличились там опять же
[12:40.580 --> 12:47.580]  по опции в биосе, потому что конфигурационным адресным пространством PCIe управляет биос в x86
[12:47.580 --> 12:56.340]  системах, так сложилось, но вполне себе позволяет вам оптимизировать процедуру общения с PCIe.
[12:56.340 --> 13:07.580]  Но это что касается работы с физической памятью, соответственно, на деле мы понимаем, что кроме
[13:07.580 --> 13:16.340]  виртуальной памяти, которую мы с вами имеем, на более ниже лежащих уровнях у вас все равно есть
[13:16.340 --> 13:21.500]  какие-то способы преобразования адресов, и вот даже когда вы говорите, что у вас физический адрес,
[13:21.500 --> 13:27.700]  он на самом деле не физический с точки зрения оперативной памяти. Причем, я вам даже больше
[13:27.700 --> 13:35.100]  скажу, он на самом деле, даже когда вы перевычисляете адрес, ну допустим, нулевой адрес у вас
[13:35.100 --> 13:40.500]  соответствует нулевому адресу в memory-контроллере, на самом деле этот нулевой адрес вовсе не будет
[13:40.500 --> 13:48.380]  находиться в нулевой адресе, не будет являться нулевым адресом в вашей DDR-памяти. Догадываетесь почему?
[13:48.380 --> 13:59.020]  Нет, я имею в виду, что вот в смысле, ну да, тут что-то лежит, но вот тут вот ничего не лежит,
[13:59.020 --> 14:07.180]  вот соответственно, вот это вот маппится, допустим, один к одному. Ну допустим, скажем так, не так важно.
[14:07.180 --> 14:19.140]  Да нет, там все проще. Про атаку вида Callboot слышали? Ну когда там страшные дяди, собственно,
[14:19.140 --> 14:24.780]  в погонов приходят, собственно, жидким азотом заливают ваш компьютер, собственно, после этого
[14:24.780 --> 14:32.500]  вынимают оперативную память и дампят ее содержимое. Ну слышали про такие страшилки. Знаете,
[14:32.500 --> 14:41.500]  почему она-то не работает? Правильно. Соответственно, есть, во-первых, скрэмблинг, который значительно
[14:41.500 --> 14:49.420]  усложняет поиск соответствий между адресами и соответственно заполненными битами в контроллере
[14:49.420 --> 14:53.900]  оперативной памяти. То есть фактически данные перемешиваются, вам придется использовать
[14:53.900 --> 14:59.180]  статистический анализ для того, чтобы понять вот какому реальному адресу соответствует байт.
[14:59.180 --> 15:05.540]  Ну сложно, но в целом можно на самом деле извлекают. А на современных процессорах
[15:05.540 --> 15:11.660]  к этому еще добавляется шифрование аппаратное, чтобы на всякий случай. При этом, соответственно,
[15:11.660 --> 15:19.500]  кэш, ключ шифрования находится в регистрах процессора и его так просто извлечь не получится.
[15:19.500 --> 15:29.460]  Ну это что касается вот самой низкоуровневой стадии работы с оперативной памятью, с памятью
[15:29.460 --> 15:37.820]  разных устройств. Но нас, как разработчиков операционных систем, все-таки больше беспокоят
[15:37.820 --> 15:44.340]  следующие две стадии. Ну про сегментную адресацию мы помним. То есть сейчас действительно сегментная
[15:44.340 --> 15:51.260]  адресация используется в 4-битном режиме только для thread-local storage. Что такое thread-local storage, помните?
[15:51.260 --> 16:00.460]  Да, это, соответственно, локальные для потока переменные. Вот, соответственно, у вас есть
[16:00.460 --> 16:05.780]  фактически вот эти самые сегментные регистры и с помощью одного из там мср регистров, ну типа там
[16:05.780 --> 16:13.340]  js-base или fs-base, можно установить текущее значение вот этого самого сегментного регистра и тем
[16:13.340 --> 16:23.900]  самым адресовать оперативную память локально для конкретного ядра ЦПУ. Что касается страничной
[16:23.900 --> 16:31.660]  адресации, то это дополнительный уровень индирекции, который нам доступен с целью, собственно,
[16:31.660 --> 16:40.820]  изолировать адресные пространства других процессов и позволить процессам жить как бы так, чтобы они
[16:40.820 --> 16:47.740]  не думали о том, что работают в адресном пространстве с кем-то еще. То есть, с одной стороны,
[16:47.740 --> 16:53.580]  процесс считает, что вся оперативная память принадлежит ему, с другой стороны, на деле это
[16:53.580 --> 17:00.420]  обеспечивается там ядром операционной системы, которая эту память просто так настраивает и снимает
[17:00.420 --> 17:07.860]  с вашего приложения необходимость думать о как вот использовать физическую память, чтобы вам ее
[17:07.860 --> 17:20.820]  хватило и чтобы соответственно все ваши данные в ней расположились. Как ядро выбирает ту физическую
[17:20.820 --> 17:29.220]  память, которую он может использовать для построения карт виртуальной памяти? Мы все помним,
[17:29.220 --> 17:34.860]  что есть UEFI Memory Map и мы только что выяснили, собственно, для чего он нужен, потому что на
[17:34.860 --> 17:38.620]  самом деле физическое адресное пространство, оно во-первых, нелинейное, чаще всего еще и non
[17:38.620 --> 17:48.300]  contiguous, то есть непоследовательное. И UEFI Memory Map это некоторый массив, состоящий из таких вещей,
[17:48.300 --> 17:58.340]  как называются там дискрипторы. В дискрипторах у вас есть вот такая вот структурка, она у вас
[17:58.340 --> 18:07.580]  есть в стандарте UEFI и вам придется по ней походить в как раз шестой лабораторной работе,
[18:07.580 --> 18:15.460]  чтобы настроить себе аллокатор физической памяти. То есть на структурке есть такие поля,
[18:15.460 --> 18:21.420]  как тип памяти, ну соответственно там conventional memory, например, это свободная память,
[18:21.420 --> 18:28.940]  которая никем не используется. Какая-нибудь boot services, код или дейта, это память,
[18:28.940 --> 18:37.900]  которая используется для сервисов того же UEFI, которая не используется в момент старта
[18:37.900 --> 18:43.220]  операционной системы. Runtime Services может использоваться, потому что это память,
[18:43.220 --> 18:50.380]  которая обеспечивает функционирование UEFI Runtime Services в процессе работы операционной системы.
[18:50.380 --> 18:58.660]  Соответственно есть информация о том, где физически данная там память находится,
[18:58.660 --> 19:06.700]  то есть там, грубо говоря, физический старт, то есть начало участка памяти, соответствующие
[19:06.700 --> 19:14.700]  там физическому адресу. Есть количество страниц, причем в UEFI есть жесткое требование,
[19:15.300 --> 19:21.180]  что размер страниц в UEFI равен 4 килобайта, но это не значит, что UEFI не поддерживает системы,
[19:21.180 --> 19:27.340]  на которых размер страниц не равен 4 килобайта. То есть просто UEFI определил для себя,
[19:27.340 --> 19:32.060]  что есть вот некоторая гранулярность, с которой он работает. Понятно, что на системах,
[19:32.060 --> 19:39.620]  где размер страниц меньше, либо больше, просто придется дополнительно пересчитывать при
[19:39.620 --> 20:03.460]  разработке самой прошивки. Не очень понял вопроса. У вас конфигурация ММУ будет задаваться в тех
[20:03.460 --> 20:07.420]  страницах, которые у вас поддерживает железка. Соответственно вы не сможете,
[20:07.420 --> 20:13.820]  грубо говоря, отобразить участок памяти меньшей гранулярности, чем размер страниц,
[20:13.820 --> 20:18.260]  которые поддерживает ваша железка. Просто не сможете так сформировать регистры или
[20:18.260 --> 20:23.580]  иные структуры, о которых мы сейчас поговорим, когда будем обсуждать таблицу страниц на x86.
[20:23.580 --> 20:32.260]  У вас там места подбитой не хватит. Соответственно, есть количество страниц,
[20:32.260 --> 20:41.500]  которые выделены в данном регионе. Есть некоторые дополнительные атрибуты, такие как кэширование,
[20:41.500 --> 20:50.140]  права доступа, которые могут быть использованы вашей операционной системой для правильной
[20:50.140 --> 20:57.460]  настройки этой самой памяти. Простой пример. Когда я вам рассказывал только что о барах,
[20:57.460 --> 21:04.140]  чтобы узнать размер бара, вам нужно сначала записать какое-то значение, а потом прочитать то,
[21:04.140 --> 21:12.220]  что получилось на выходе. При этом вы прочитаете совершенно не то, что вы записали. Если вы
[21:12.220 --> 21:19.620]  установите неправильные биты кэширования, например write-through кэширование, то да,
[21:19.620 --> 21:26.780]  оно действительно вполне успешно запишет все в самоустройство. Но когда вы будете читать данные,
[21:26.780 --> 21:31.300]  то они, например, прочитаются из кэша, и вы прочитаете совершенно не то, что вы хотели.
[21:31.300 --> 21:40.300]  Поэтому ufi, собственно, вам делает жизнь несколько проще. Он сразу говорит, что вот тут, например,
[21:40.300 --> 21:46.820]  у меня находится MMIO-память, то есть memory map.io, то есть там есть некоторые устройства, и там,
[21:46.820 --> 21:55.700]  допустим, эта память не кэшируемая. То есть он упрощает вам жизнь. Кроме физического адреса,
[21:56.060 --> 22:06.780]  у вас здесь еще есть виртуальный адрес. Виртуальный адрес соответствует адресу вот этого
[22:06.780 --> 22:14.580]  вот самого дискриптора в то время, когда работает операционная система. То есть фактически он
[22:14.580 --> 22:23.100]  говорит, что вот этот вот самый дискриптор будет доступен по вот этому виртуальному адресу из
[22:23.100 --> 22:28.700]  гидра, когда операционная система запустится. То есть в тот момент, когда вы будете, например,
[22:28.700 --> 22:37.700]  вызывать runtime-сервисы, такие как перезагрузка, получение какой-нибудь переменной из ufi,
[22:37.700 --> 22:43.900]  variable storage, получение времени, какие-то другие операции, в том числе, например,
[22:43.900 --> 22:55.140]  конфигурационной таблицы и так далее. Есть мысли, почему вот это вот самое поле virtual start,
[22:55.140 --> 23:04.660]  его нужно указывать именно в процессе работы вашего загрузчика операционной системы и
[23:04.660 --> 23:13.340]  передавать в метод setVirtualAddressMap, который выполняется у вас прямо вот перед стартом
[23:13.340 --> 23:19.820]  операционной системы. То есть почему просто не могла бы операционная система потом сама как-нибудь
[23:19.820 --> 23:27.180]  решить, куда ей хочется разместить, то есть как ей хочется замаппить вот эти вот регионы памяти,
[23:27.180 --> 23:39.380]  если ей действительно хочется. Ну вот почему, собственно, операционная система, которая
[23:39.380 --> 23:43.580]  определяет эти виртуальные адреса, то есть у вас загрузчик операционной системы эти адреса
[23:43.580 --> 23:49.620]  назначает. То есть он их просто берет, какие хочет, и выставляет. То есть причина там,
[23:49.620 --> 23:54.420]  почему он это должен делать еще в тот момент, когда работает прошивка ufi, то есть работают
[23:54.420 --> 24:06.860]  бутсервисы. Ну вот зачем, то есть в принципе, почему нельзя было просто операционной системе не
[24:06.860 --> 24:16.020]  иметь вот это вот поле вообще в рамках спецификации ufi и не просто отобразить так, как ей удобно. Ну я
[24:16.020 --> 24:22.340]  вас уверяю, люди, которые там делали спецификацию ufi, они, конечно, сделали, возможно, удобнее,
[24:22.340 --> 24:28.420]  но причины были вовсе не в том, чтобы сделать для пользователей что-то удобнее, просто по-другому
[24:28.420 --> 24:47.820]  бы не заработало. Есть мысли? Ну допустим, я вам могу простой пример кода перевести. Вот представьте,
[24:47.900 --> 25:11.220]  что у вас записана вот такая конструкция. Это некоторые две глобальные переменные в,
[25:11.220 --> 25:22.380]  соответственно, C программе. Первая переменная это integer a, соответственно, вторая переменная
[25:22.380 --> 25:30.980]  указатель на integer b, которая инициализируется значением указатель на переменную a.
[25:30.980 --> 25:44.660]  Вы правильно, соответственно, мыслите, что у вас возможно две ситуации. Первая
[25:44.660 --> 25:55.580]  ситуация, это когда, грубо говоря, вот та программа, которая содержит в себе скомпилированный,
[25:55.580 --> 26:01.740]  соответственно, этот код загружается по фиксированному адресу, соответственно, мы тогда на стадии
[26:01.740 --> 26:07.820]  компиляции можем вычислить вот этот вот адрес, его сюда подставить и ничего делать не нужно будет.
[26:07.820 --> 26:15.220]  Здесь будет просто лежать абсолютное число, которое, соответственно, мы сможем использовать. Второй
[26:15.220 --> 26:27.300]  вариант, если у нас есть ISLR, соответственно, address space layout optimization, то есть у вас программа
[26:27.300 --> 26:31.900]  может загрузиться по случайному там базовому адресу, причем, возможно, даже не только базовому,
[26:31.900 --> 26:35.860]  в зависимости от того, как ISLR реализован, то есть у вас гранулярность там может быть разная
[26:35.860 --> 26:43.300]  достаточно. Вот у вас, соответственно, есть ISLR и это означает, что ваша программа будет загружена по
[26:43.300 --> 26:51.980]  случайному адресу. И вот этот вот случайный адрес, он фактически добавит смещение,
[26:51.980 --> 27:05.780]  он добавит смещение вот к этому адресу относительному, который был вычислен на
[27:05.780 --> 27:11.420]  стадии компиляции, который нужно прибавить, чтобы получить реальный адрес переменной А.
[27:11.420 --> 27:20.540]  Вот эту процедуру, соответственно, преобразование того адреса, который лежит здесь в компилированной
[27:20.540 --> 27:28.700]  программе и, соответственно, добавление к нему вот этого оффсета выполняет загрузчик вот этой
[27:28.700 --> 27:35.860]  вот программы и, соответственно, механизм, который обеспечивает вот это самое преобразование,
[27:35.860 --> 27:44.140]  называется relocation. То есть в программе специальным образом зашит некоторые там вот набор инструкций,
[27:44.140 --> 27:49.700]  которые говорят, что нужно сделать преобразование и, соответственно, там загрузчик вот этого вот
[27:49.700 --> 27:59.340]  образа программы смотрит на этот список relocation и делает вот эти преобразования в момент, соответственно,
[27:59.340 --> 28:07.580]  там загрузки данного файла. Райперовый тиф адресинг работает, но в данном случае как вы сделаете
[28:07.580 --> 28:19.460]  райперовый тиф адресинг? У вас просто хранится адрес. Здесь глобальная переменная, соответственно,
[28:19.460 --> 28:25.660]  этот код не существует, это некоторая статически инициализированная память. То есть, да,
[28:25.660 --> 28:34.260]  действительно, можно было бы сгенировать конструктор, но зачем? В целом, да, но как бы
[28:34.260 --> 28:38.020]  смучиться придется с конструкторами, потому что вы никогда не задумывались, как у вас работают
[28:38.020 --> 28:46.340]  конструкторы. Вот простой вопрос, у вас есть функция main, где выполняются конструкторы?
[28:46.340 --> 29:00.340]  Правильно, они действительно выполняются до main, и, соответственно, если у вас программа embedded,
[29:00.340 --> 29:08.860]  то вам придется выполнить конструкторы самому. Соответственно, там в джосе есть специальный код,
[29:08.860 --> 29:14.140]  который выполняет конструкторы, которые сгенировал компилятор. Для этого нужно
[29:14.140 --> 29:21.460]  делать дополнительные усилия. Уже есть или будет? Уже есть. Скорее, сейчас уже должен быть,
[29:21.460 --> 29:27.140]  потому что у вас там поддерживаются, по крайней мере, конструкторы, которые для санитайзеров
[29:27.140 --> 29:35.060]  используются. Соответственно, это дополнительное усилие и, соответственно, это дополнительное
[29:35.060 --> 29:41.820]  замедление вашего кода, как говорится, зачем. Поэтому гораздо проще использовать эту технику.
[29:41.820 --> 29:48.620]  Так вот, с этого объяснения стало понятно, зачем вот сюда написать виртуальный адрес?
[29:48.620 --> 30:05.700]  Так он уже релоцировал. Это не V2 код. Так он уже их применил.
[30:05.700 --> 30:14.460]  Так ядро работает по физическим адресам сначала.
[30:14.460 --> 30:38.420]  Вот этот вот адрес не равен вот этому. По крайней мере, может быть, не равен. Поэтому они остаться
[30:38.420 --> 30:42.260]  корректными плюс-минус не могут, потому что, возможно... Что?
[30:42.260 --> 31:11.460]  Про ядро не беспокойтесь. Не беспокойтесь про ядро. Ядро находится в виде незагрузчика
[31:11.460 --> 31:15.820]  операционной системы. Загрузчик операционной системы работает с ядром так, как он хочет.
[31:15.820 --> 31:32.660]  Ему не важно абсолютно, как работает. Ладно, это на самом деле не столь такая тривиальная мысль.
[31:32.660 --> 31:40.420]  Дам еще одну подсказку. Вот у вас есть рантайм-сервисы. Рантайм-сервисы операционная система будет
[31:40.420 --> 31:47.780]  называть по виртуальным адресам, не по физическим. Да, вот представьте, что у вас в коде рантайм-сервиса
[31:47.780 --> 31:58.020]  был вот такой код. Соответственно, в какой-то момент у вас в глобальных переменах хранились
[31:58.020 --> 32:05.260]  указатели, содержащие физические адреса каких-то участков памяти, которые были валидные в момент
[32:05.260 --> 32:16.220]  работы прошивки. В какой-то момент мы захотели работать с виртуальной памятью. То есть мы
[32:16.220 --> 32:23.540]  захотели запустить операционную систему, и мы назначили вот эти самые виртуальные адреса тем
[32:23.540 --> 32:31.420]  регионам, которые будут исполняться в процессе работы нашей операционной системы. В UEFI есть
[32:31.420 --> 32:46.220]  такой метод, называется convert pointer. Этот метод как раз занимается тем, что он преобразовывает
[32:46.220 --> 32:53.620]  физический адрес в виртуальный в соответствии с той таблицей memory map, которую вы в него
[32:53.620 --> 33:00.060]  передадите. Соответственно, вот у вас есть актуальная таблица memory map. Он находит,
[33:00.060 --> 33:06.500]  грубо говоря, регион, в котором у вас лежит данный участок памяти, то есть он фактически
[33:06.500 --> 33:15.220]  находит физический адрес. Соответственно, далее вычитает physical start из значения вашей
[33:15.220 --> 33:20.020]  собственной адресопеременной и прибавляет virtual start. В результате он получает новый адрес,
[33:20.020 --> 33:28.020]  который будет уже являться виртуальным. Здесь есть тонкость, что вот такая конструкция,
[33:28.020 --> 33:37.420]  мы ее воспроизвели сейчас в C, она может возникать и в сгенерированном компилятором коде. То есть
[33:37.420 --> 33:44.180]  там в некоторых ситуациях компилятор может сгенировать релокацию, причем не обязательно
[33:44.180 --> 33:51.500]  такую, но какую-то, которую нужно будет преобразовать. Поэтому здесь решение не
[33:51.500 --> 33:57.500]  столь элегантное, но кроме вот ручного вызова вот этого метода ConvertPointer, загрузчик,
[33:57.500 --> 34:05.260]  который есть в UEFI, он еще дополнительно проходит по соответственно всем вот этим вот релокациям и
[34:05.260 --> 34:12.260]  их заново обновляет. То есть проводит ту же самую процедуру, но еще и для релокации. Но как
[34:12.260 --> 34:19.820]  результат, по этим двум причинам необходимо сообщать в прошивке UEFI, по каким виртуальным
[34:19.820 --> 34:25.540]  адресам у вас в дальнейшем планируется ее исполнение. При этом здесь есть важный момент,
[34:25.540 --> 34:33.780]  что операционная система или там прошивка в момент назначения виртуальных адресов ничего
[34:33.780 --> 34:38.660]  по этим виртуальным адресам не выполняет. То есть у вас вот эти виртуальные адреса есть,
[34:38.660 --> 34:45.540]  все необходимые структуры в момент, то есть к концу вызова setVirtualAddressMap, они будут
[34:45.540 --> 34:51.140]  преобразованы, но при этом никто отображение виртуальных адресов на соответствующий физический
[34:51.140 --> 34:59.060]  не настраивает. Это особенно, кстати, было неочевидно многим разработчикам прошивок,
[34:59.060 --> 35:07.100]  поэтому нет ничего удивительного, что многие прошивки там на заре развития UEFI, они просто
[35:07.100 --> 35:14.940]  падали, когда виртуальный адрес не был равен физическому. Вот, собственно, такой относительно
[35:14.940 --> 35:36.540]  грустный опыт. Да, не странички, обратите внимание, у вас тут есть количество
[35:36.780 --> 35:44.060]  страниц, но да, действительно все верно, адрес может быть свой для каждого дискриптора, то есть чаще
[35:44.060 --> 35:49.980]  всего операционная система назначает адреса последовательно друг за другом, но вот в целом.
[35:49.980 --> 35:55.980]  А когда вы требуете несколько дискрипторов? То есть один дискриптор за одно что отвечает?
[35:55.980 --> 36:04.940]  За один тип памяти. Да, вот у вас типы здесь перечислены. Ну, не все, но знаете, вот есть тип,
[36:04.940 --> 36:13.540]  например, вот вывод MMIO, есть, соответственно, там тип, например, там runtime services код, есть тип
[36:13.540 --> 36:23.700]  runtime services дейта, но вот, соответственно, если вы смотрите на эти типы, то скорее всего вам придет
[36:23.700 --> 36:31.180]  ложное ощущение, что вот этот вот тип данных код, который он предназначен для кодового сегмента
[36:31.180 --> 36:38.700]  UFI runtime driver, а вот этот вот тип предназначен для сегмента данных UFI runtime driver. Ну, ведь
[36:38.700 --> 36:43.980]  похоже, да? Соответственно, вот у нас сегмент кода, вот у нас сегмент данной, давайте им дадим два
[36:43.980 --> 36:50.300]  разных типа. На самом деле это совершенно не так, и вы только что ответили на вопрос почему.
[36:50.300 --> 36:56.300]  Значнее как, оно было так, пока люди не поняли, что они на самом деле сделали неправильно и они
[36:56.300 --> 37:04.700]  начали все это чинить. Есть мысли почему? Ну, вы буквально только что ответили на этот вопрос.
[37:04.700 --> 37:24.220]  Нет, один и тот же там не надо, тут вопрос в том, что если virtual start этим сегментом будет выдан
[37:24.220 --> 37:31.260]  непоследовательно, то есть разница между virtual start конкретного кода и данных и, соответственно,
[37:31.260 --> 37:37.980]  physical start между кодом и данным принадлежащих одному исполняемому драйверу будет разной,
[37:37.980 --> 37:46.660]  то, соответственно, у вас просто упадет программа. У драйвера внутри себя есть обращение по
[37:46.660 --> 37:52.580]  относительным адресам, то есть Reproative адресация к переменным данным, и, соответственно, оно вот
[37:52.580 --> 38:01.460]  таким образом просто падало. Как результат, у нас сейчас есть две таблицы, соответственно,
[38:01.460 --> 38:16.740]  есть ufi-memory-map, а есть, соответственно, ufi-memory-attributes-table, соответственно,
[38:16.740 --> 38:28.020]  есть так называемая mat. Вот есть map, есть mat. Вот, соответственно, mat это табличка вот
[38:28.020 --> 38:34.420]  ровно с такими же дескрипторами, но в этой табличке присутствуют только те дескрипторы,
[38:34.420 --> 38:43.780]  которые получают виртуальный адрес, и, соответственно, эти дескрипторы, они, грубо говоря,
[38:43.780 --> 38:52.220]  делят каждый дескриптор memory-map на один или, соответственно, более поддескрипторов,
[38:52.220 --> 38:58.820]  в котором уже указываются права доступа. То есть, грубо говоря, там все драйвера получают,
[38:58.820 --> 39:06.500]  соответственно, права, получают тип ufi-runtime-services-code в memory-map, а, соответственно,
[39:06.500 --> 39:11.660]  в memory-attributes-table они получают два поддескриптора, в котором, соответственно,
[39:11.660 --> 39:20.260]  в первом там написано, грубо говоря, допустим, write-protect права доступа в атрибутах,
[39:20.260 --> 39:26.460]  а, соответственно, во втором, соответственно, там execute-protect, то есть, соответственно,
[39:26.460 --> 39:38.700]  там изолируется права доступа на исполнение. Соответственно, сегмент, тип дескриптора
[39:38.700 --> 39:46.700]  runtime-data используется для локации куч, то есть память в куче. Но, в любом случае,
[39:46.700 --> 39:56.460]  типов, собственно, много, у вас, например, код загрузчика, это loader-code, loader-data будет использовать.
[39:56.460 --> 40:13.380]  Да, она это должна сделать, если она хочет использовать ufi-runtime-services. Если она не хочет
[40:13.380 --> 40:20.500]  их использовать, то, в принципе, она может даже не назначать виртуальные адреса. Но, как бы,
[40:20.500 --> 40:27.420]  в целом, там стандартная практика, что что-то все равно надо назначить, а дальше уже можно
[40:27.420 --> 40:31.140]  маппить, можно не маппить в зависимости от потребностей. То есть, например, там в джосе
[40:31.140 --> 40:36.980]  runtime-сервисы они не замаплены, хотя им адреса назначены. Но это не из-за того, что, там,
[40:36.980 --> 40:40.740]  грубо говоря, так нельзя было сделать, а просто в джосе есть индивидуальное задание добавить
[40:40.740 --> 40:46.420]  поддержку runtime-сервисов. Да, задание, на самом деле, очень интересное, я его всячески рекомендую,
[40:46.420 --> 40:53.780]  потому что у вас есть еще 32-битная прошивка в дополнении к 64-битной. И очень интересно делать
[40:53.780 --> 40:58.860]  преобразованные прыжки из 64-битного кода в 32-битный, чтобы вызвать сервисы в 32-битной
[40:58.860 --> 41:05.300]  прошивке, после этого прыгнуть в 64-битный обратно. Поэтому настоятельно рекомендую попробовать,
[41:05.300 --> 41:10.340]  кто хочет практиковаться при переключениях режима или кому, соответственно, второй лабораторный было
[41:10.340 --> 41:21.020]  мало. Поэтому, наверное, все. Единственное, что можно сказать еще о казусах. Вот представьте,
[41:21.020 --> 41:31.020]  что у вас был вот такой вот код, и, соответственно, там прошивка, ну, вот в момент загрузки вашего
[41:31.020 --> 41:37.620]  бинарника, она сделала там преобразование вот этого адреса, то есть она добавила ему смещение
[41:37.620 --> 41:45.060]  там ISLR. После этого вы взяли и написали в своей какой-нибудь программе там код, ну, там допустим,
[41:45.060 --> 41:57.700]  там B, там ALOG, там, ну, не важно, там 4. То есть взяли и изменили значение B. Как я уже вам сказал,
[41:57.700 --> 42:03.460]  у вас есть два механизма. Вот, соответственно, механизм 1 — это конверт-пойнтер, который вы
[42:03.460 --> 42:11.220]  руками делаете, а, соответственно, механизм 2 — это вот то, что делает прошивка, когда добавляет
[42:11.220 --> 42:19.980]  базовое смещение. То есть вопрос, что здесь должна выполняться? То есть если бы вы не изменили
[42:19.980 --> 42:29.700]  значение B, то вроде бы должна была сама прошивка это починить. А вы вроде изменили значение B,
[42:29.700 --> 42:34.580]  но прошивка никак не может узнать, изменилось оно или нет, потому что у вас память просто
[42:34.580 --> 42:55.940]  перезаписалась. Это set virtual address map. А в момент, когда вы работаете с прошивкой там до еще загрузки
[42:55.940 --> 43:12.940]  операционной системы. Что? Не совсем, потому что вот эта вот процедура, прибавление вот этого
[43:12.940 --> 43:20.900]  SLR offset, она вам вычистит вот этот вот SLR offset и добавит новое значение. То есть у вас будет
[43:20.900 --> 43:27.260]  просто неволидное значение переменной, потому что выделенный адрес вот здесь, он может не
[43:27.260 --> 43:35.980]  соответствовать тому дескриптуру, который был вот здесь. На самом деле, это одна из дыр просто
[43:35.980 --> 43:45.140]  очередная в UEFI спецификации и так, соответственно, писать нельзя в runtime драйверах. Те, кто,
[43:45.140 --> 43:51.940]  соответственно, так делали, они отлавливали очень интересные ошибки при работе операционной
[43:51.940 --> 43:59.820]  системе со своими прошивками. И вот там в линуксе есть файлик, называется efikworks.
[43:59.820 --> 44:06.580]  Вот вы его можете почитать, там увидите, сколько хороших прошивок существует в мире и какими
[44:06.580 --> 44:12.500]  костылями их приходится там либо отключать, либо чинить, чтобы они каким-то образом продолжали
[44:12.500 --> 44:27.700]  работать. Легко, но в целом уязвимости там в основном в других местах. Но мы целом заканчиваем с
[44:27.700 --> 44:36.420]  нашими таблицами memory map и memory attributes table. То есть мы получили всю карту физической памяти,
[44:36.420 --> 44:44.900]  которую у нас только есть и, соответственно, настроили механизм сегментации, чтобы он отображал
[44:44.900 --> 44:55.460]  все один к одному. И сейчас наша задача настроить виртуальную память. То есть,
[44:55.460 --> 44:59.300]  так как это 64-битный режим, то нам нужно настроить виртуальную память даже в ядре.
[44:59.300 --> 45:14.180]  И как, собственно, это у вас выглядит? В процессоре есть специальный регистр. В x86 этот
[45:14.180 --> 45:27.020]  регистр называется CR3. В этот регистр у вас записывается некоторый физический адрес,
[45:27.020 --> 45:36.980]  ну вот как раз на слайде, соответственно, есть регистр CR3, в котором содержится адрес
[45:36.980 --> 45:46.900]  некоторой структуры в оперативной памяти. Данная структура называется PML4, но в целом для
[45:46.900 --> 45:55.780]  понимания нужно просто понять, что это самый, грубо говоря, корневой элемент таблиц трансляции,
[45:55.780 --> 46:08.620]  который у вас будет. В x86 у вас, соответственно, 48-битная шина, и мы виртуальный адрес можем
[46:08.620 --> 46:18.100]  представить вот таким образом. Все помнят, что странички в x86 4k, то есть вот эта вот штучка,
[46:18.100 --> 46:30.980]  это 4 килобайта, и она же называется offset. А в дальнейшем ваш виртуальный адрес делится
[46:30.980 --> 46:48.260]  на, собственно, 4 сегмента. Вот, собственно, 9 бит 1, 9 бит 2, 9 бит 3, 9 бит 4. Когда процессор видит,
[46:48.260 --> 46:56.540]  соответственно, ваш виртуальный адрес, он его рассматривает как, грубо говоря, 4 индекса.
[46:56.540 --> 47:08.380]  Соответственно, 4 индекса в некоторых массивах, которые вот как раз являются таблицами страниц.
[47:08.380 --> 47:19.940]  В каждой таблице страниц, которая также там размером 4 килобайта, есть 512 записей размером
[47:19.940 --> 47:29.660]  8 байт каждая. Вот в каждой записи, которую мы как раз индексируем вот этим вот числом,
[47:29.660 --> 47:37.220]  соответственно, 2 в 9 и 512. Назначение вот тут от 0 до 511 является индексом массива
[47:37.220 --> 47:47.220]  сначала самой старшей таблицы. Она индексирует вот эту вот самую таблицу и получает некоторый
[47:47.220 --> 47:58.100]  фактически адрес, который может быть двух видов. Соответственно, вид первый, она получит адрес
[47:58.100 --> 48:06.740]  следующего уровня таблиц. То есть она фактически получит вот этот вот адрес. То есть адрес начала
[48:06.740 --> 48:16.660]  следующего уровня таблиц, в частности, для x86 это pdp. По поводу названий, соответственно,
[48:16.660 --> 48:24.860]  pml4, pdp, pde, pte. Это название, которое использует Intel, но с счетом того, что эти аббреватуры
[48:24.860 --> 48:32.900]  достаточно неудобно запоминать, чаще всего просто нумируют в обратном порядке. То есть вот это у вас
[48:32.900 --> 48:44.100]  там p4, это соответственно там p3, это там p2, это соответственно p1. Так гораздо проще запомнить,
[48:44.100 --> 48:57.740]  чем пытаться вот. Да, pte и соответственно pde. Ну, соответственно, pd это соответственно
[48:57.740 --> 49:05.740]  page directory, а e это entry. То есть вот entry, которая вот тут, она соответственно вот pde, соответственно,
[49:05.740 --> 49:14.380]  это pte и так далее. То есть на это pml4e, это соответственно pdpe. Сама табличка pdpt. Запись,
[49:14.380 --> 49:25.100]  соответственно, добавляется e. Так вот, вы получаете, вот здесь у вас хранится адрес на
[49:25.100 --> 49:34.500]  следующую табличку, и вы берете следующий бит. Вот следующие, грубо говоря, 9 бит. В сумме вот с
[49:34.500 --> 49:49.620]  этим они вам дают следующую запись. Здесь вы переходите к следующей адрес памяти и снова
[49:49.620 --> 49:56.300]  вычисляете адрес следующей ячейки. Вот здесь хранятся соответственно физические адреса каждого
[49:56.300 --> 50:03.540]  там последующего уровня трансляции. Пока вы не дойдете до последнего уровня трансляции, который
[50:03.540 --> 50:10.580]  будет указывать уже непосредственно на физическую память, непосредственно на 4 килобайта, и вам
[50:10.580 --> 50:18.020]  останется лишь прибавить последние 12 бит, то есть последний offset к этому адресу, чтобы получить
[50:18.020 --> 50:24.620]  вот реальное расположение вашего соответственно кода в оперативной памяти.
[50:24.620 --> 50:45.660]  Да, вот соответственно я так раз поэтому и сказал, что есть два пути. Первый путь, это вот
[50:45.660 --> 50:52.660]  собственно пройти по всем вот этим вот уровням, а соответственно второй путь, это соответственно
[50:52.660 --> 50:57.780]  остановиться на каком-то из этих уровней и сказать, что, например, там этот уровень является
[50:57.780 --> 51:04.340]  конечным. Ну вот, например, если вот этот уровень последний, то у вас остается там страничка 4
[51:04.340 --> 51:10.780]  килобайта, а если я, например, остановлюсь вот здесь, то у вас будет страничка 1 мегабайт. Вот
[51:10.780 --> 51:18.180]  здесь можно выставить флажок специально, то есть в записи вот в этой вот там будет флажок, который вам
[51:18.180 --> 51:26.660]  скажет, что после вот этой вот записи идет не следующая таблица трансляции, а уже оперативная
[51:26.660 --> 51:34.900]  память, и соответственно процессор будет делать меньше хопов. Относительно быстрее, потому что
[51:34.900 --> 51:43.020]  дьявол кроется в деталях, то есть если вся вот эта вот штука обращения, грубо говоря, к четырем
[51:43.020 --> 51:52.540]  уровням, грубо говоря, там таблиц, она достаточно дорогая, и если бы просто вот вам подсунули
[51:52.540 --> 51:56.900]  такой механизм трансляции, который каждый раз выходил в оперативную память, то было бы очень
[51:56.900 --> 52:09.140]  дорого. Но на деле в процессорах есть такая штука, называется TLB или там Translation Locosight Buffer,
[52:09.140 --> 52:19.220]  который запоминает фактически, какой виртуальный адрес соответствует какому физическому там в
[52:19.220 --> 52:26.700]  формате LRU. Ну то есть он просто запоминает последние несколько штук, наиболее там часто используемых,
[52:26.700 --> 52:33.580]  и тем самым соответственно обращение к памяти может не происходить в процедуре трансляции.
[52:33.580 --> 52:58.780]  Это просто обычный кэш. Соответственно вот за счет этого у вас может оптимизироваться
[52:58.780 --> 53:07.180]  соответственно процедура обращения к вот этим вот самым адресам. При этом ну конкретно у
[53:07.180 --> 53:14.660]  интела там TLB бывает нескольких видов в зависимости от размерности страниц. То есть грубо говоря там
[53:14.660 --> 53:23.020]  например там ну на 4k у вас там допустим ну например там 64 записи там на 1 мегабайт там допустим там
[53:23.020 --> 53:29.580]  4 записи соответственно там на 2 гигабайта у вас там допустим там ноль или там одна
[53:29.580 --> 53:33.700]  запись. И вот таким образом соответственно от увеличения как бы размерности таблиц вы не
[53:33.700 --> 53:40.100]  всегда можете выбирать, потому что у вас процессор может иметь разные соответственно там TLB. Соответственно
[53:40.100 --> 53:48.020]  одна из таких интересных задач в real-time системах это расположить трансляцию таким образом, чтобы
[53:48.020 --> 54:04.500]  она как раз помещалась в этот TLB и не ходила в оперативную память вообще. По памяти я вам не
[54:04.500 --> 54:10.980]  скажу. То есть на самом деле сейчас за счет конвейера за счет всех вот этих вот кэшей в
[54:10.980 --> 54:20.580]  среднем разницы никакой. Более того у вас сейчас x86 64 режим в принципе не позволяет не использовать
[54:20.580 --> 54:26.780]  таблицу трансляции. То есть у вас в любом случае все как минимум один к одному отображается. Поэтому
[54:26.780 --> 54:35.020]  эти цифры получить по крайней мере на x86 стало еще сложнее. Да ну можете сами попробовать и
[54:35.020 --> 54:42.500]  соответственно расскажете. Но сейчас эти цифры пренебрежимы малые, никто без виртуальной памяти не
[54:42.500 --> 54:48.580]  использует соответственно там современный процессор общего назначения. Даже в embedded
[54:48.580 --> 54:56.260]  системах просто потому что выигрыш, который дает виртуальная память он перевешивает значительно
[54:56.260 --> 55:03.100]  те накладные расходы, которые приходится учитывать при построении систем. Ну и более того тут
[55:03.100 --> 55:09.700]  надо еще понимать, что в некоторых процессорах, в том числе которые используются в специализированных
[55:09.700 --> 55:16.500]  системах типа Hard-Real-Time, вот такая табличная конфигурация виртуальной памяти, она встречается
[55:16.500 --> 55:22.940]  далеко не всегда. То есть это не единственный способ как можно программировать ММУ. Вот если
[55:22.940 --> 55:30.220]  там представите там какой-нибудь Airbus, там условно 320, который в воздухе летает, вы наверняка летали,
[55:30.220 --> 55:39.420]  то соответственно там будет использоваться архитектура PowerPC, с высокой долей вероятности
[55:39.420 --> 55:47.940]  там ядро, по крайней мере на некоторых подсистемах будет вот такое. Это соответственно там PowerPC,
[55:48.940 --> 56:02.100]  и соответственно вот у этого ядра ММУ работает вот без всего вот этого, там только ТЛБ. Причем
[56:02.100 --> 56:07.100]  ТЛБ программируется вручную. То есть вы можете сами как разработчик операционной системы
[56:07.100 --> 56:19.260]  занести ТЛБ записи и вот они будут вам обеспечивать трансляцию. Есть PowerPC, которые IBM, на нем
[56:19.260 --> 56:24.620]  работали там всякие Power Mac и так далее, то есть компьютеры общего назначения. Есть PowerPC,
[56:24.620 --> 56:35.060]  который соответственно там Fayscale, он же соответственно сейчас NXP, и вот эти ребята
[56:35.060 --> 56:42.260]  занимаются automotive, avionics, космонавтика и так далее. То есть вот есть два направления
[56:42.260 --> 56:48.980]  расприменения PowerPC, соответственно PowerPC всякие там компьютеры типа Power Mac, IBM всякие там
[56:48.980 --> 56:56.180]  серверы, которые IBM Power, Power 8, Power 9 и вот это все. Это вот в одну сторону, там как раз таблица
[56:56.180 --> 57:05.220]  страниц обычно. А соответственно вот это, это там всякий embedded, где нужны там гарантии времени,
[57:05.220 --> 57:10.820]  то есть на их лучшего времени работы предсказуемой. То есть понятно, что там для вот такого ММУ
[57:10.820 --> 57:18.940]  предсказательное и худшее время, там вполне себе реально в отличие вот этого вот. Но соответственно
[57:18.940 --> 57:24.020]  в такой конфигурации не удастся отобразить всю память или удастся, но там с большими ограничениями.
[57:24.020 --> 57:32.820]  Примиссии тяжело поддерживать, то есть конкретно там у нас приходится использовать целый интересный
[57:32.820 --> 57:45.660]  математический аппарат, чтобы разложить операционку вот в такое вот подобное. Ну в разных модулях по
[57:45.660 --> 57:52.820]  разному, но в принципе там обычно вот на таких вот штуках в районе 2 гигабайт. Ну это там скажем
[57:52.820 --> 58:07.060]  скорее предел. То есть обычно там чуть-чуть поменьше. У вас здесь есть signExtend, вот он как раз подписан.
[58:07.060 --> 58:10.580]  Соответственно если вот здесь единичка, то соответственно вот тут будут тоже все единички,
[58:10.580 --> 58:15.980]  вот так вот так далее. Если у вас соответственно тот нолик, то соответственно и тут будут нолики.
[58:15.980 --> 58:38.700]  Ну они не отрицательные, они безнаклые. Обычно по-моему в Винде вообще в userspace используются низкие адреса.
[58:38.700 --> 58:57.940]  Не эксперт на Винде, не буду врать. Ну упадет пользователь, но земля ему кухом.
[58:57.940 --> 59:10.020]  Ну у вас в какой-то момент просто вычисления с адресами будут приводить вот ко всяким различным
[59:10.020 --> 59:15.100]  интересным вещам. То есть можно использовать в качестве wraparound и всякие там подобные операции.
[59:15.100 --> 59:19.740]  Вот так просто архитектуру сделали. В каких-то вещах это не так, в каких-то это так. Ну вот у
[59:19.740 --> 59:26.380]  Intel это так, а там у другой системы там обычно размерность шины она там соответствует. Или в
[59:26.380 --> 59:32.100]  warmup будет просто tech использоваться, если у вас там эти, как его называют, аутентифицированные
[59:32.100 --> 59:35.740]  указатели. То есть у вас вот эта память, она будет использоваться под криптиграфическую
[59:35.740 --> 59:43.940]  подпись вашего адреса. То есть ну с какой железом далее, собственно, с таким железом придется
[59:43.940 --> 59:53.180]  жить. Хорошо ли, плохо ли, ну как повезет. Так, ну это понятно, соответственно, как происходит
[59:53.180 --> 01:00:06.980]  преобразование адреса. Или все-таки нужно какие-то вещи повторить. Смотрите, вот здесь вот у вас в
[01:00:06.980 --> 01:00:14.660]  записи лежит адрес начала таблицы следующего уровня, а соответственно смещение вот в этой
[01:00:14.660 --> 01:00:21.540]  таблице оно лежит вот здесь. То есть, грубо говоря, вот это, это, грубо говоря, плюс вот это,
[01:00:21.540 --> 01:00:41.180]  дает вот это. А, понятно, да, я по привычке нарисовал, соответственно, что у меня нулевой
[01:00:41.180 --> 01:00:48.380]  адрес вот здесь, а на картинке он нулевой адрес вот здесь. Да, старая привычка, я всегда нулевой
[01:00:48.380 --> 01:00:53.340]  адрес вижу, соответственно, там, где он реально находится, потому что я в экзампе в основном
[01:00:53.340 --> 01:01:00.860]  работаю. Рисовать нулевой адрес внизу в литературе такое часто встречается. Кому-то нравится, кому-то
[01:01:00.860 --> 01:01:16.340]  не очень. Так, соответственно, вот в этих вот записях существуют различные флаги, но, соответственно,
[01:01:16.340 --> 01:01:24.580]  вот пример таких флагов, это вот, например, флаг S, который как раз нам говорит, что является, грубо
[01:01:24.580 --> 01:01:29.060]  говоря, данной, там, данная запись, является оконечной, например, это будет там запись, там,
[01:01:29.060 --> 01:01:36.900]  двухмегабайтовая или одна гигабайтовая. Далее, там, соответственно, есть флаги типа, соответственно,
[01:01:36.900 --> 01:01:45.860]  там, access или там обращение. Ну, точно так же, как и с сегментными записями, там, gdntree, то есть
[01:01:45.860 --> 01:01:55.420]  флаги в таблице страницы очень сильно повторяют то, что есть в gdnt, ldt-записях. Ну, соответственно,
[01:01:55.420 --> 01:02:05.340]  user говорит вам о том, что память доступна пользователю. То есть довольно часто при работе,
[01:02:05.340 --> 01:02:12.900]  соответственно, в режиме вот ring3, ring0, в одной таблице страниц у вас отображаются и страницы
[01:02:12.900 --> 01:02:18.300]  ядра и страницы пользователя. Соответственно, у страниц пользователя есть bit.u, который говорит,
[01:02:18.300 --> 01:02:22.260]  что это user и, соответственно, пользователь может их исполнять с непривилегированного режима.
[01:02:22.260 --> 01:02:30.620]  У страниц ядра этого бита нет и, соответственно, даже если пользователь обратится к, собственно,
[01:02:30.620 --> 01:02:39.220]  памяти ядра, то, собственно, он упадет с нарушением прав доступа. С этим, соответственно, есть множество
[01:02:39.220 --> 01:02:46.580]  проблем, связанных со спекулятивными атаками, и поэтому в большинстве современных систем на самом
[01:02:46.580 --> 01:02:53.500]  деле, если они работают, по крайней мере, на intel или на некоторых армах, схема с отображением
[01:02:53.500 --> 01:02:58.700]  ядерного и пользовательского пространства целиком в одной таблице страниц, она не используется,
[01:02:58.700 --> 01:03:05.900]  просто потому что спекулятивные атаки. Но конкретно, как это все работает, мы поговорим
[01:03:05.900 --> 01:03:10.580]  отдельно на следующей лекции и сейчас можете просто считать, что у вас хороший процессор,
[01:03:10.580 --> 01:03:17.780]  поэтому можно делать себе удобно. Хороших процессоров уже не осталось, но мы же учимся.
[01:03:17.780 --> 01:03:25.460]  Вот можно вы делаете свой хороший процессор. Вот, соответственно, есть каширование. Каширование вам
[01:03:25.460 --> 01:03:33.420]  позволяет, соответственно, запоминать, то есть как раз использовать это некоторое, там, кашировать,
[01:03:33.420 --> 01:03:39.020]  сами эти отображения с виртуальных адресов на физические. Если вы запретили каширование,
[01:03:39.020 --> 01:03:43.020]  то следующий уровень таблицы он не будет запомнить. Вот как раз то, что вы говорили.
[01:03:43.020 --> 01:03:50.740]  То есть он не будет запомнен процессором и, соответственно, можно будет при изменении вот этой
[01:03:50.740 --> 01:03:53.660]  вот самой таблицы страниц сбросить только там tailback.
[01:03:53.660 --> 01:04:02.340]  Хотя, а когда происходит изменение какой-то таблицы виртуальных адресов, как это об этом процессору сообщить?
[01:04:02.340 --> 01:04:09.340]  CR3 перечисать. Перезаписать и перечисить. И он очистит, конечно, свой процессор.
[01:04:09.340 --> 01:04:14.140]  То есть, по крайней мере, это такой самый простой, надежный способ. То есть сочетали значение CR3,
[01:04:14.140 --> 01:04:19.140]  записали его обратно. Вот у вас там процессор, он сбросил каши.
[01:04:19.140 --> 01:04:23.740]  Ну, есть, соответственно, BITIC PRESENT. Если BITICA PRESENT нет, то у вас может
[01:04:23.740 --> 01:04:27.140]  какое-то и быть отображение, но, соответственно, в данный момент оно недоступно.
[01:04:27.140 --> 01:04:34.140]  Это может быть удобно в тех ситуациях, когда вы что-то хотите размаппить, но при этом не хотите потерять данные.
[01:04:34.140 --> 01:04:40.140]  То есть, вот вы сняли BIT PRESENT и, как бы, у вас данные все как бы есть, но пока вы его не поставите,
[01:04:40.140 --> 01:04:41.140]  память не будет работать.
[01:04:41.140 --> 01:04:46.140]  Сейчас, а то, что вы говорили, что CR3 сбрасывает, конечно, BITIC PRESENT. То есть, получается,
[01:04:46.140 --> 01:04:51.140]  если в видеоходе вызывается какой-нибудь исколок для облагации допущенных страниц,
[01:04:51.140 --> 01:04:56.140]  то это сделано, соответственно, очень сильно замедленно для программ, потому что даже нельзя
[01:04:56.140 --> 01:04:57.140]  сочетать.
[01:04:57.140 --> 01:05:04.140]  Нет, можно более мягкими способами сбросить конкретно эти. Есть, типа, сброс кашей по кашелиниям,
[01:05:04.140 --> 01:05:10.140]  есть всякие экстендопиды. То есть, в свое время, почему всякие хасвиллы меньше замедлились,
[01:05:10.140 --> 01:05:17.140]  потому что у них есть такая штука, которая, типа, тегированный TLB. То есть, когда у конкретного,
[01:05:17.140 --> 01:05:22.140]  грубо говоря, процесса есть некоторый тег в той памяти, который он использует в TLB,
[01:05:22.140 --> 01:05:29.140]  соответственно, можно зачистить только память для этого тега. Ну, там, в общем, много всяких разных техник.
[01:05:29.140 --> 01:05:36.140]  Конкретно как там x86, я даже все, наверное, сейчас не вспомню, поэтому можете открыть Intel SDM
[01:05:36.140 --> 01:05:43.140]  и там много всего хорошего написано про этот счет. Ну, то есть, грубо говоря, есть такой жесткий способ,
[01:05:43.140 --> 01:05:48.140]  который работает плюс-минус всегда, но есть, понятно, способа попроще.
[01:05:48.140 --> 01:05:57.140]  Соответственно, на ниже лежащих уровнях тоже, соответственно, есть различные биты конфигурации памяти.
[01:05:57.140 --> 01:06:02.140]  Ну, вот, например, есть nxbit, который запрещает исполнение этой памяти.
[01:06:02.140 --> 01:06:12.140]  Ну, соответственно, все хорошо, выставили nxbit, и после этого, как вы пытаетесь выполнить память,
[01:06:12.140 --> 01:06:22.140]  то сгнивается соответствующее исключение, что patch hold нельзя выполнять ту страницу, которая не является исполненной.
[01:06:22.140 --> 01:06:30.140]  Причем, что интересно, кроме nxbit, сейчас там в современных Intel есть еще такие штуки,
[01:06:30.140 --> 01:06:44.140]  называемые SMAP и SMAP System Memory Access Prevention и System Memory Execution Prevention.
[01:06:44.140 --> 01:06:51.140]  Идея заключается в следующем. То есть, вот, если у пользователя есть какие-то исполняемые страницы,
[01:06:51.140 --> 01:06:58.140]  то их совершенно не обязательно исполнять в ядре. Ну, потому что зачем в ядре исполнять память,
[01:06:58.140 --> 01:07:01.140]  которую может исполнять пользователь? Может он ее еще даже перезаписать может?
[01:07:01.140 --> 01:07:10.140]  То есть, ну, просто небезопасно. Поэтому дополнительный как бы механизм, который изолирует исполняемые страницы пользователя от ядра.
[01:07:10.140 --> 01:07:15.140]  То есть, если ядро пытается исполнять исполняемую память пользователя, он получит исключение.
[01:07:15.140 --> 01:07:24.140]  SMAP, это соответственно Access Prevention, он запрещает доступ из ядра к памяти пользователя вовсе.
[01:07:24.140 --> 01:07:30.140]  То есть, если ядро захочет почитать или подписать в память пользователя,
[01:07:30.140 --> 01:07:36.140]  ему придется его замапить в себе, в адресное пространство, этот кусочек памяти,
[01:07:36.140 --> 01:07:42.140]  или, соответственно, там просто отключить SMAP на время.
[01:07:42.140 --> 01:07:50.140]  То есть, когда вы выполните индивидуальное задание, вот тогда будет нельзя.
[01:07:50.140 --> 01:07:56.140]  То есть, на одно из индивидуальных заданий это вот NX, SMAP, SMAP. Вот.
[01:07:57.140 --> 01:08:03.140]  Ну, как бы поставить заграничный лук и сделать это временно системной страницей?
[01:08:03.140 --> 01:08:13.140]  Да, надо будет обязательно выдать это индивидуальное задание вместе сразу с какими-нибудь SMP, чтобы локи было поинтереснее захватывать.
[01:08:13.140 --> 01:08:23.140]  Вот, допустим, у нас есть бит листовой в странице записи, а, допустим, этого бита нет, он более стартный в записи.
[01:08:23.140 --> 01:08:27.140]  А его здесь и нет. А его здесь и нет.
[01:08:27.140 --> 01:08:30.140]  А если мы ее назначим как листовую?
[01:08:30.140 --> 01:08:37.140]  Ну, там будет, то есть в зависимости от типа таблицы, он по-разному, соответственно, бит интерпретируется.
[01:08:38.140 --> 01:08:46.140]  Там формат записи один и тот же, но, соответственно, используемые биты отличаются от, соответственно, установленных битов.
[01:08:46.140 --> 01:08:51.140]  Точно так же, как и в GDT, установили часть битов, соответственно, у вас другие биты интерпретируются по-другому.
[01:08:51.140 --> 01:08:58.140]  Ну, соответственно, если у вас оконечная страничка, то там будет NX bit. Если она не оконечная, то, соответственно...
[01:08:58.140 --> 01:09:00.140]  То есть, в зависимости от установленного сайта?
[01:09:00.140 --> 01:09:02.140]  Да, да, да.
[01:09:02.140 --> 01:09:08.140]  Ну, соответственно, можете вот, опять же, посчитать SDM, тут я просто некоторые там интересные биты привел,
[01:09:08.140 --> 01:09:13.140]  а так их там чуть больше и, соответственно, можно делать чуть более интересные вещи.
[01:09:13.140 --> 01:09:22.140]  То есть, как раз в конце лекции есть ссылки на страницы Intel SDM, которые стоит почитать,
[01:09:22.140 --> 01:09:27.140]  даже если вы уверены, что вы все поняли, как работает виртуальная память в X86.
[01:09:27.140 --> 01:09:36.140]  Мы как раз вот здесь пришли к ситуации, что мы время от времени хотим все-таки менять наше отображение.
[01:09:36.140 --> 01:09:41.140]  То есть, мы его менять хотим не всегда и не на всех операционных системах.
[01:09:41.140 --> 01:09:48.140]  То есть, как вы думаете, есть ли операционные системы, где не нужно менять таблицу трансляции?
[01:09:48.140 --> 01:09:56.140]  Ну да, hard real-time системы, да, в некоторых случаях они могут действительно иметь статическую конфигурацию памяти,
[01:09:56.140 --> 01:09:59.140]  но на самом деле не обязательно hard real-time.
[01:09:59.140 --> 01:10:04.140]  Hard real-time – это лишь один из примеров операционных систем определенного класса.
[01:10:04.140 --> 01:10:08.140]  То есть, у вас может быть класс операционных систем embedded, то есть, встраиваемый,
[01:10:08.140 --> 01:10:15.140]  при этом это может быть не hard real-time операционная система, может быть просто какой-то soft real-time или вообще не real-time.
[01:10:15.140 --> 01:10:21.140]  Но тем не менее, действительно, в некоторых операционных системах, строемых специального назначения,
[01:10:21.140 --> 01:10:30.140]  используется принцип статической конфигурации памяти, когда мы выделяем все ресурсы на момент сборки образа операционной системы.
[01:10:30.140 --> 01:10:40.140]  Это актуально, потому что вам позволяет обеспечить защиту от таких ситуаций, когда вы начали работать и вам памяти не хватило.
[01:10:40.140 --> 01:10:46.140]  То есть, факт того, что у вас операционная система собралась, означает то, что вам хватило памяти на целевой вычислитель.
[01:10:47.140 --> 01:10:55.140]  Поэтому в некоторых системах действительно можно не позволять менять таблицы страницы,
[01:10:55.140 --> 01:11:00.140]  более того, их можно даже не отображать в виртуальной оперативной памяти.
[01:11:00.140 --> 01:11:05.140]  То есть, если нам не надо менять таблицы страницы, то их можно просто расположить в какой-то момент в физической памяти,
[01:11:05.140 --> 01:11:09.140]  а потом никому к этому доступа к этой физической памяти не давать.
[01:11:09.140 --> 01:11:18.140]  Что еще дополнительно повышает надежность вашей операционной системы, потому что ее можно меньшими способами обрушить, поломать и так далее.
[01:11:18.140 --> 01:11:31.140]  Но тем не менее, кроме систем, где нет возможности изменить конфигурацию виртуальной памяти,
[01:11:31.140 --> 01:11:35.140]  есть большая часть систем, где это сделать можно.
[01:11:35.140 --> 01:11:41.140]  И обычно существует два способа, как это можно сделать.
[01:11:41.140 --> 01:11:47.140]  То есть, один способ – это использование некоторого дерева.
[01:11:47.140 --> 01:11:56.140]  Соответственно, у вас в Джоси используется именно такой способ, и он в целом является основным для большинства систем.
[01:11:56.140 --> 01:12:06.140]  Есть такая структура, типа range дерева, которая…
[01:12:06.140 --> 01:12:10.140]  Алгоритмы структуры данных, я думаю, все проходили.
[01:12:10.140 --> 01:12:14.140]  Кто не проходил, может вспомнить, условно, первый курс.
[01:12:15.140 --> 01:12:21.140]  Range дерева, когда у вас, грубо говоря, отображается какой-то диапазон,
[01:12:21.140 --> 01:12:34.140]  на что-то там, ну, грубо говоря, 2, 3, 5.
[01:12:34.140 --> 01:12:38.140]  В данном случае диапазоны должны быть равные.
[01:12:38.140 --> 01:12:42.140]  И у вас, соответственно, есть несколько вот таких пар.
[01:12:42.140 --> 01:12:45.140]  И в зависимости, если там это дерево, то оно может быть как-то отсортировано.
[01:12:45.140 --> 01:12:49.140]  Соответственно, может быть это не дерево, а какая-нибудь хэш-таблица.
[01:12:49.140 --> 01:12:53.140]  Но не так важно. На обычных процессунных системах это именно так используется.
[01:12:53.140 --> 01:12:59.140]  В Джос у вас как раз будет использоваться одно из таких деревьев.
[01:12:59.140 --> 01:13:05.140]  Ну, в качестве домашнего задания можете посмотреть, как именно оно работает.
[01:13:05.140 --> 01:13:11.140]  Второй способ – это self-referencing page labels.
[01:13:11.140 --> 01:13:17.140]  Или самосцелающиеся таблицы, но сноявшегося русского термина как такового нет.
[01:13:17.140 --> 01:13:21.140]  И такой механизм используется в Windows.
[01:13:21.140 --> 01:13:25.140]  И в целом эта иллюстрация как делать не надо.
[01:13:25.140 --> 01:13:29.140]  Windows, на самом деле, очень долго от этого страдал.
[01:13:29.140 --> 01:13:31.140]  И до сих пор страдает.
[01:13:31.140 --> 01:13:36.140]  Потом я объясню, почему так делать не надо.
[01:13:36.140 --> 01:13:39.140]  Ну, по крайней мере, для определённого класса систем.
[01:13:39.140 --> 01:13:45.140]  Например, тот же Касперский свой iOS этот механизм тоже использует.
[01:13:45.140 --> 01:13:49.140]  И в принципе у них последствия не столь плачевные.
[01:13:49.140 --> 01:13:53.140]  Но по другой причине, потому что у них операционки кое-чего нет.
[01:13:53.140 --> 01:14:01.140]  Да, смотрите.
[01:14:01.140 --> 01:14:04.140]  У вас возникает простая задачка.
[01:14:04.140 --> 01:14:09.140]  Я всё-таки на следующий случай напомню, что вы хотите что-то отобразить.
[01:14:09.140 --> 01:14:14.140]  То есть вы хотите что-то изменить, перестроить в вашей карте памяти.
[01:14:14.140 --> 01:14:19.140]  Чтобы это сделать, вам нужно модифицировать таблицу страниц.
[01:14:19.140 --> 01:14:25.140]  Ну, активную в текущий момент, то есть неактивную в текущий момент.
[01:14:25.140 --> 01:14:31.140]  Но если это какие-нибудь деревья, то можно модифицировать любую таблицу страниц.
[01:14:31.140 --> 01:14:35.140]  И это как раз, наоборот, очень-очень удобно.
[01:14:35.140 --> 01:14:44.140]  И это одно из преимуществ управления памятью на основе деревьев.
[01:14:44.140 --> 01:14:48.140]  Потому что вы можете в любой момент перестроить любую таблицу страниц.
[01:14:48.140 --> 01:14:54.140]  Соответственно, если у вас используется система с self-referencing page tables,
[01:14:54.140 --> 01:15:00.140]  то можно изменять только текущую активную в данный момент, лёгким способом.
[01:15:00.140 --> 01:15:08.140]  Но вот как раз этот лёгкий способ, он тем самым, собственно, и интересен.
[01:15:08.140 --> 01:15:15.140]  То есть представьте, что в самой старшей табличке,
[01:15:15.140 --> 01:15:21.140]  то есть PML4, она же, соответственно, там P4, у вас есть запись,
[01:15:21.140 --> 01:15:25.140]  которая ссылается на саму себя.
[01:15:25.140 --> 01:15:29.140]  В качестве здесь примера используется 511-я запись.
[01:15:29.140 --> 01:15:37.140]  Соответственно, 511-я запись имеет адрес, соответствующий вот этой вот самой PML4.
[01:15:37.140 --> 01:15:47.140]  То есть, грубо говоря, если у вас попадётся 511-я запись в адресе,
[01:15:47.140 --> 01:15:54.140]  то это означает, что на самом деле вы будете использовать таблицу P4
[01:15:54.140 --> 01:16:00.140]  не только как таблицу трансляции четвёртого уровня, но и как третьего.
[01:16:00.140 --> 01:16:10.140]  То есть вот эта вот запись, она вам сделает цикл.
[01:16:18.140 --> 01:16:22.140]  Соответственно, она войдёт вот сюда.
[01:16:22.140 --> 01:16:28.140]  Дальше мы, соответственно, вернёмся обратно.
[01:16:28.140 --> 01:16:40.140]  И вот эта штука, соответственно, вот этот вот адрес, он снова пойдёт сюда же.
[01:16:45.140 --> 01:16:47.140]  Понятна идея или не очень?
[01:16:47.140 --> 01:16:49.140]  Ну, как-то будет понятно, почему.
[01:16:49.140 --> 01:16:53.140]  Может быть, теперь вы куда-то интерпретируете, да, здесь P4,
[01:16:54.140 --> 01:16:57.140]  да, все же.
[01:16:57.140 --> 01:17:06.140]  Соответственно, идея в том, что после того, как вы один раз прокрутились вот тут,
[01:17:06.140 --> 01:17:12.140]  у вас осталось только три операции разыменования по индексу.
[01:17:12.140 --> 01:17:17.140]  Соответственно, грубо говоря, вот тут будет первая, вот тут будет вторая, вот тут будет третья.
[01:17:17.140 --> 01:17:25.140]  И соответственно, смещение вот это вот, которое у вас останется, оно будет указывать на таблицу P1.
[01:17:25.140 --> 01:17:32.140]  То есть у вас таблица P1, вот это, она будет интерпретироваться не как таблица следующего уровня,
[01:17:32.140 --> 01:17:36.140]  которая состоит из каких-то, собственно, записей, индексов и так далее.
[01:17:36.140 --> 01:17:38.140]  Она будет интерпретироваться как обычная память.
[01:17:38.140 --> 01:17:42.140]  Потому что я напомню, что всё вот это вот, это четыре килобайтновые страницы.
[01:17:43.140 --> 01:17:50.140]  Да, это все, чтобы быстро получить доступ по физическому адресу к таблице.
[01:17:50.140 --> 01:17:57.140]  То есть вам процессор аппаратно вычислет адрес, соответствующий вот этой самой табличке.
[01:17:57.140 --> 01:17:59.140]  Что?
[01:17:59.140 --> 01:18:01.140]  Чтобы ее изменить.
[01:18:01.140 --> 01:18:05.140]  Да, или прочитать. Чтобы ее прочитать, изменить и так далее.
[01:18:05.140 --> 01:18:07.140]  Только там не будет проблем с битом size.
[01:18:07.140 --> 01:18:12.140]  Там же, тот бит, который size, ну, если, например, правильно брать, не вы взяли это,
[01:18:12.140 --> 01:18:17.140]  то он у BDE расстоянияется как бит dirty, который ставится...
[01:18:17.140 --> 01:18:24.140]  Да, то есть там на самом деле с битом size там будут только проблемы в том, что если вы...
[01:18:24.140 --> 01:18:27.140]  Чиселку большую будете использовать.
[01:18:27.140 --> 01:18:32.140]  То есть если у вас offset будет слишком большой, то проблемы с size будут.
[01:18:32.140 --> 01:18:34.140]  Но вы учите...
[01:18:34.140 --> 01:18:36.140]  Что?
[01:18:36.140 --> 01:18:40.140]  Ну, вы можете прокрутиться не только один раз, вы можете вот здесь еще прокрутиться.
[01:18:40.140 --> 01:18:44.140]  То есть вот тут вот еще выставить единички.
[01:18:44.140 --> 01:18:46.140]  То есть тогда два раза прокрутитесь.
[01:18:46.140 --> 01:18:48.140]  Соответственно, получите доступ к P2.
[01:18:48.140 --> 01:18:50.140]  Так можно к P3.
[01:18:50.140 --> 01:18:53.140]  То есть вы можете к любую табличку посмотреть таким образом,
[01:18:53.140 --> 01:18:57.140]  и тем самым узнать, есть ли у вас там bit size установлено или нет.
[01:18:57.140 --> 01:19:01.140]  Так нет, я даже жду, что у нас, когда мы вот так вот получим,
[01:19:01.140 --> 01:19:05.140]  даже один раз прокрутившим, получим доступ к P1 по адресу,
[01:19:05.140 --> 01:19:09.140]  у нас, ну, то есть процессор уже не знает, не будет ничего прокрутились,
[01:19:09.140 --> 01:19:11.140]  или он отдельно иногда его обрабатывает.
[01:19:11.140 --> 01:19:13.140]  А зачем ему отдельно что-то обрабатывать?
[01:19:13.140 --> 01:19:15.140]  Вот именно он. То есть он не обрабатывает, это отдельно.
[01:19:15.140 --> 01:19:20.140]  А это значит, что он будет считать, чтобы таблица P2, это на самом деле,
[01:19:20.140 --> 01:19:22.140]  он будет расценивать как P1.
[01:19:22.140 --> 01:19:26.140]  И тогда он будет ее флаги в ней расценить как флаги в PTE.
[01:19:26.140 --> 01:19:30.140]  А в флагах PTE у них тот bit, который у остальных...
[01:19:30.140 --> 01:19:32.140]  Не, биты совпадают.
[01:19:32.140 --> 01:19:37.140]  Вот именно, что bit, который будет как size, он в PTE и используется для чего-то другого.
[01:19:37.140 --> 01:19:40.140]  Если вы правильно проявите, то это биты дёрги.
[01:19:40.140 --> 01:19:42.140]  Нет, там порядок...
[01:19:42.140 --> 01:19:47.140]  Нет, порядок там не соответствует порядку записи.
[01:19:47.140 --> 01:19:54.140]  Там порядок битов в entry совпадает независимо от, соответственно, уровня.
[01:19:54.140 --> 01:19:57.140]  Сейчас, то есть в PTE bit size...
[01:19:57.140 --> 01:20:02.140]  Находится в том же месте, что и, соответственно, да, он там должен быть и до 0.
[01:20:04.140 --> 01:20:07.140]  То есть все уровни могут выполнять...
[01:20:07.140 --> 01:20:09.140]  Да, да.
[01:20:09.140 --> 01:20:13.140]  Да, они полностью эквивалентны по геометрическому расположению битов.
[01:20:13.140 --> 01:20:18.140]  В тем стране, что для них разные названия, с разными сокращениями.
[01:20:18.140 --> 01:20:21.140]  Ну, так просто было удобно, когда было два уровня.
[01:20:21.140 --> 01:20:26.140]  В 300-битном x86, соответственно, было только, соответственно, PDE, PTE.
[01:20:26.140 --> 01:20:29.140]  Ну, page directory и, соответственно, page tape.
[01:20:29.140 --> 01:20:33.140]  А потом вот стало 4, сейчас уже 5.
[01:20:33.140 --> 01:20:35.140]  Нет, не понимаю, интересно.
[01:20:35.140 --> 01:20:38.140]  Ну, и на ещё один уровень, чтобы шина стала больше.
[01:20:38.140 --> 01:20:40.140]  Да.
[01:20:40.140 --> 01:20:44.140]  Это же получается обратно, но скорее, не в чтении вот этой добычи.
[01:20:44.140 --> 01:20:46.140]  Да.
[01:20:47.140 --> 01:20:49.140]  Вроде, когда требуют обратную скринину,
[01:20:49.140 --> 01:20:53.140]  играть пришло такое вот, что будет тяжелое, если я сейчас использую.
[01:20:53.140 --> 01:20:55.140]  Тогда-то надо использовать обратную скринину.
[01:20:55.140 --> 01:20:57.140]  А это же чтение таблицы.
[01:20:57.140 --> 01:20:59.140]  Скажем, в какой-нибудь тририальной таблице.
[01:20:59.140 --> 01:21:01.140]  Это не искрение, это, брат, чем почтение.
[01:21:01.140 --> 01:21:03.140]  Это просто кодпись прочитала.
[01:21:03.140 --> 01:21:05.140]  Эту штуку, как бы, открыли.
[01:21:05.140 --> 01:21:07.140]  То есть Intel такой, вот, так можно было.
[01:21:07.140 --> 01:21:10.140]  Это, ну, пяточный ремонт даблейки реализации.
[01:21:10.140 --> 01:21:12.140]  У тебя же, например, просто пишут адрес.
[01:21:12.140 --> 01:21:14.140]  Да.
[01:21:14.140 --> 01:21:17.140]  Процессор менять никак не нужно было, чтобы это заработало.
[01:21:17.140 --> 01:21:21.140]  Это просто так, можно посмотреть пристальным взглядом и увидеть, что так можно.
[01:21:21.140 --> 01:21:23.140]  Есть ли у меня никакого фишки,
[01:21:23.140 --> 01:21:25.140]  типа, сделать там, ну, 1.1.1.1,
[01:21:25.140 --> 01:21:27.140]  типа, ну, будет вот такая вот цифра на земля, да,
[01:21:27.140 --> 01:21:30.140]  а 1.1.1.0, там, цифра, она входит на другую страницу,
[01:21:30.140 --> 01:21:32.140]  чтобы там, так, не ассоциироваться.
[01:21:32.140 --> 01:21:34.140]  Ну, то есть, нет, ну, другого варианта,
[01:21:34.140 --> 01:21:36.140]  что он не проигрывается, что-то ещё не это полезно.
[01:21:36.140 --> 01:21:39.140]  Ну, может быть, вы найдёте.
[01:21:39.140 --> 01:21:42.140]  У меня так в голову, наверное, не приходит.
[01:21:42.140 --> 01:21:44.140]  То есть, ты просто, у тебя вот этот вот,
[01:21:44.140 --> 01:21:46.140]  ты ссылаешься, короче, на b4 entry,
[01:21:46.140 --> 01:21:50.140]  на котором, короче, адреса b3 таблицы,
[01:21:50.140 --> 01:21:54.140]  ну, соответственно, ему стоит адрес самой b4 таблицы.
[01:21:54.140 --> 01:21:56.140]  Вот в этом entry.
[01:21:56.140 --> 01:21:58.140]  Вот 1.1.1.1, дописано для примера.
[01:21:58.140 --> 01:22:01.140]  Да, там любое значение может быть.
[01:22:01.140 --> 01:22:05.140]  Чтобы оно указывало на b4 таблицу обратно.
[01:22:05.140 --> 01:22:07.140]  Ааа, опуск.
[01:22:07.140 --> 01:22:09.140]  Почему не пострадать?
[01:22:09.140 --> 01:22:11.140]  Вот вопрос аудитории.
[01:22:11.140 --> 01:22:13.140]  Почему так делать плохо?
[01:22:13.140 --> 01:22:15.140]  Ну, потому что пользовательская программа
[01:22:15.140 --> 01:22:17.140]  может прочитать, кто вывез.
[01:22:17.140 --> 01:22:19.140]  Как она может её прочитать?
[01:22:19.140 --> 01:22:21.140]  Ей сюда юзер не поставит,
[01:22:21.140 --> 01:22:23.140]  она ничего не сможет прочитать.
[01:22:23.140 --> 01:22:25.140]  Ну, она может сам поставить и по себе.
[01:22:25.140 --> 01:22:27.140]  Что?
[01:22:27.140 --> 01:22:31.140]  Ну, упадёт с page fault, там, земля и пуха.
[01:22:31.140 --> 01:22:33.140]  Ну, если она знает, как бы,
[01:22:34.140 --> 01:22:36.140]  находится,
[01:22:36.140 --> 01:22:41.140]  если она знает, на каком b4 entry находится фляг,
[01:22:41.140 --> 01:22:45.140]  то она может, по сути, просто узнать содержимые таблицы.
[01:22:45.140 --> 01:22:50.140]  Ну, вы близко, но кое-что не учитываете.
[01:22:50.140 --> 01:22:53.140]  То есть, на самом деле, идея, действительно, в похоже.
[01:22:53.140 --> 01:22:55.140]  То есть, проблема в чём?
[01:22:55.140 --> 01:22:59.140]  Что когда вы выполняете код execution в ядре,
[01:22:59.140 --> 01:23:01.140]  вам неплохо бы понимать,
[01:23:01.140 --> 01:23:03.140]  примерно, где у вас что находится.
[01:23:03.140 --> 01:23:05.140]  Потому что есть такая штука,
[01:23:05.140 --> 01:23:07.140]  называется ASLR и, соответственно, KSLR.
[01:23:07.140 --> 01:23:09.140]  Вот, соответственно,
[01:23:09.140 --> 01:23:11.140]  зная,
[01:23:11.140 --> 01:23:15.140]  где именно находится вот этот механизм
[01:23:15.140 --> 01:23:17.140]  self-referencing page tables,
[01:23:17.140 --> 01:23:21.140]  вы можете понять всю карту
[01:23:21.140 --> 01:23:24.140]  отображения текущего виртуальной памяти
[01:23:24.140 --> 01:23:27.140]  на физическую в вашем адресном пространстве.
[01:23:27.140 --> 01:23:30.140]  Да, вам придётся получить привилегии ядра,
[01:23:30.140 --> 01:23:33.140]  но, соответственно, самое первое,
[01:23:33.140 --> 01:23:35.140]  что нужно сделать,
[01:23:35.140 --> 01:23:37.140]  после того, как вы получили привилегии
[01:23:37.140 --> 01:23:39.140]  при исполнении ядра,
[01:23:39.140 --> 01:23:41.140]  это его не уронить.
[01:23:41.140 --> 01:23:43.140]  Соответственно, чтобы его не уронить,
[01:23:43.140 --> 01:23:45.140]  можно использовать эту технику
[01:23:45.140 --> 01:23:54.140]  как раз для того, чтобы победить ASLR в ядре.
[01:23:55.140 --> 01:23:59.140]  Ну, тут как раз пример,
[01:23:59.140 --> 01:24:01.140]  как соответственно у вас
[01:24:01.140 --> 01:24:03.140]  адреса смещаются
[01:24:03.140 --> 01:24:07.140]  при этих вот циклах.
[01:24:07.140 --> 01:24:10.140]  Соответственно,
[01:24:10.140 --> 01:24:15.140]  винда теперь использует случайную запись
[01:24:15.140 --> 01:24:18.140]  для self-referencing page tables.
[01:24:18.140 --> 01:24:21.140]  Раньше они всегда использовали 1ED,
[01:24:21.140 --> 01:24:23.140]  и это было очень радостно.
[01:24:23.140 --> 01:24:25.140]  Для тех людей, которые
[01:24:25.140 --> 01:24:28.140]  ломали ядерный ASLR в ядре.
[01:24:28.140 --> 01:24:30.140]  Соответственно,
[01:24:30.140 --> 01:24:32.140]  того же Касперский Ост
[01:24:32.140 --> 01:24:34.140]  это не страшно,
[01:24:34.140 --> 01:24:36.140]  потому что они в ядре
[01:24:36.140 --> 01:24:38.140]  не используют ASLR
[01:24:38.140 --> 01:24:41.140]  по причинам дополнительной надежности.
[01:24:41.140 --> 01:24:43.140]  Вообще это звучит как довольно
[01:24:43.140 --> 01:24:45.140]  странная юзимость,
[01:24:45.140 --> 01:24:47.140]  что если вдруг у завышника
[01:24:47.140 --> 01:24:49.140]  уже было исполнение кода в ядре,
[01:24:49.140 --> 01:24:51.140]  то так он сможет обойти ASLR,
[01:24:52.140 --> 01:24:54.140]  нет, смотрите,
[01:24:54.140 --> 01:24:56.140]  получить исполнение
[01:24:56.140 --> 01:24:59.140]  и, скажем так,
[01:24:59.140 --> 01:25:01.140]  иметь возможность его проэксплуатировать
[01:25:01.140 --> 01:25:03.140]  это разные вещи.
[01:25:07.140 --> 01:25:09.140]  Это если у вас исполнение,
[01:25:09.140 --> 01:25:11.140]  в смысле вы код исполняете,
[01:25:11.140 --> 01:25:13.140]  никто уже, благодаря нашим стараниям,
[01:25:13.140 --> 01:25:15.140]  не может так легко
[01:25:15.140 --> 01:25:19.140]  получить просто прямое исполнение кода в ядре.
[01:25:19.140 --> 01:25:21.140]  Есть такие штуки, как
[01:25:21.140 --> 01:25:23.140]  Return Oriented программа,
[01:25:23.140 --> 01:25:25.140]  поэтому вам
[01:25:25.140 --> 01:25:27.140]  как бы легко
[01:25:27.140 --> 01:25:29.140]  вы не получите
[01:25:29.140 --> 01:25:31.140]  исполнение в ядре,
[01:25:31.140 --> 01:25:33.140]  только в очень простых
[01:25:33.140 --> 01:25:35.140]  операционных системах.
[01:25:35.140 --> 01:25:37.140]  Чаще всего у вас какой-нибудь
[01:25:37.140 --> 01:25:39.140]  Memory Corruption
[01:25:39.140 --> 01:25:41.140]  и достаточно непрямое
[01:25:41.140 --> 01:25:43.140]  исполнение кода.
[01:25:49.140 --> 01:25:55.140]  У меня произвольно читать память.
[01:25:55.140 --> 01:25:57.140]  У вас уязвимость
[01:25:57.140 --> 01:25:59.140]  позволяет произвольно читать память,
[01:25:59.140 --> 01:26:01.140]  но не более, но не исполнять ее.
[01:26:01.140 --> 01:26:03.140]  У вас уязвимость позволяет раскрывать, например,
[01:26:03.140 --> 01:26:05.140]  память ядра.
[01:26:13.140 --> 01:26:15.140]  Так вы будете читать все,
[01:26:15.140 --> 01:26:17.140]  вы прочитаете с некорректного адреса,
[01:26:17.140 --> 01:26:19.140]  и, соответственно, ваш эксплуатит вместе с ним.
[01:26:19.140 --> 01:26:21.140]  Соответственно, служба безопасности
[01:26:21.140 --> 01:26:23.140]  после этого увидит,
[01:26:23.140 --> 01:26:25.140]  что у вас ядро упало,
[01:26:25.140 --> 01:26:27.140]  отключит компьютер от сети.
[01:26:27.140 --> 01:26:29.140]  Все.
[01:26:31.140 --> 01:26:33.140]  Заиграли в хакера и хватит.
[01:26:33.140 --> 01:26:35.140]  Ладно.
[01:26:35.140 --> 01:26:37.140]  На этом, соответственно,
[01:26:37.140 --> 01:26:39.140]  у меня обещанные ссылки
[01:26:39.140 --> 01:26:41.140]  на Intel SDM, которые я настоятельно
[01:26:41.140 --> 01:26:43.140]  советую посмотреть.
[01:26:43.140 --> 01:26:45.140]  Они вам пригодятся
[01:26:45.140 --> 01:26:51.140]  на шестую, седьмую, восьмую лабораторные работы,
[01:26:51.140 --> 01:26:53.140]  где у вас будет
[01:26:53.140 --> 01:26:55.140]  как раз интересный процесс
[01:26:55.140 --> 01:26:57.140]  реализации
[01:26:57.140 --> 01:26:59.140]  поэтапной
[01:26:59.140 --> 01:27:01.140]  виртуальной памяти
[01:27:01.140 --> 01:27:03.140]  в Джосе.
[01:27:03.140 --> 01:27:05.140]  И в целом
[01:27:05.140 --> 01:27:07.140]  на этом у нас
[01:27:07.140 --> 01:27:09.140]  на сегодня все.
