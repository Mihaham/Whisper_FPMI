[00:00.000 --> 00:10.760]  Приветствую вас. Сегодня у нас последнее занятие перед финальным, где мы подведем
[00:10.760 --> 00:15.240]  итог всему происходящему, где я объясню все, что было у нас за последние три месяца,
[00:15.240 --> 00:22.160]  что все это значило, как это нужно воспринимать, как это нужно унести с собой. Сегодня последняя
[00:22.160 --> 00:29.600]  тема и новая тема для нашего курса. Но для вас все новая, а тема новая и для меня. Она читается
[00:29.600 --> 00:37.760]  в первый раз. Она очень сложная и она будет посвящена, я бы сказал, частично распределенным
[00:37.760 --> 00:41.920]  системам. То есть это такая лекция со вкусом следующего спецкурса про распределенные системы,
[00:41.920 --> 00:48.880]  где мы будем очень интенсивно все это использовать, все, что мы изучаем. И распределенная система — это
[00:48.880 --> 00:54.320]  тот контекст, ради которого в том числе все это и было выдумано для того, чтобы там как-то
[00:54.320 --> 01:00.760]  справиться со всей сложностью. Но перед тем, как это тема отмены и обработки ошибок,
[01:00.760 --> 01:08.360]  cancellation и error handling, но перед тем мы перейдем к этой теме. Несколько слов про текущие задачи и
[01:08.360 --> 01:17.320]  про то, чего бы я от вас очень хотел и что бы вам стоило сделать для того, чтобы вынести с курсом
[01:17.320 --> 01:23.640]  максимальную пользу. У нас осталось не так много времени и у нас остались три задачи, на которые
[01:23.640 --> 01:33.240]  я обращаю ваше внимание. Это задача про канал, про канал, с помощью которого Fiber могут коммуницировать
[01:33.240 --> 01:39.640]  друг с другом, и про Select, с помощью которого Fiber могут дожидаться сообщения на одном из
[01:39.640 --> 01:45.160]  нескольких каналах, останавливаясь до тех пор, пока сообщения не появятся хотя бы в одном. Это задача
[01:45.160 --> 01:52.600]  Future, про то, чтобы построить некоторые такой декларативный язык комбинаторов, с помощью которых
[01:52.600 --> 01:58.120]  можно композировать синхронная операция. Последовательно с помощью, это не задача Future,
[01:58.120 --> 02:05.480]  последовательно с помощью комбинатора Zen, ну или Recover, который останавливается после ошибок,
[02:05.480 --> 02:13.280]  и параллельно с помощью комбинаторов All и First-off. Это очень ценная тема, это очень
[02:13.280 --> 02:19.040]  ценный инструмент, это несколько другой инструмент, совершенно другой, который не похож сильно на
[02:19.040 --> 02:27.600]  Fiber, который заставляет вас думать в совершенно другом языке. Мне кажется, это важно. И это
[02:27.600 --> 02:37.840]  корутины, корутины C++, которые являются тем инструментом, который современные C++ предлагают
[02:37.840 --> 02:43.840]  для того, чтобы описывать асинхронные операции. Вот если мы хотим исполняться задачи, а потом
[02:43.840 --> 02:49.080]  остановиться, то у нас есть такое ключевое слово co-await, под которым мы можем с помощью
[02:49.080 --> 02:54.760]  авейтера остановить корутину и запланировать возобновления по какому-то событию, по таймеру,
[02:54.760 --> 03:02.760]  по готовности ввода-вывода, по завершению другой синхронной операции. Вот, про эти задачи я писал
[03:02.760 --> 03:11.160]  в канале, но вот повторяю еще раз, что это три важные задачи, и они одинаково важны. Вот эти
[03:11.160 --> 03:17.920]  три задачи – это не задачи вообще, то есть не нужно относиться к ним к задачам курса. Это три больших
[03:17.920 --> 03:23.200]  подхода к конкарнсе, к которым мы шли весь семестр. И вот все, что было до этого момента, это, в общем,
[03:23.200 --> 03:27.680]  такие приготовления для того, чтобы воспользоваться, изучить один из этих трех больших инструментов,
[03:27.680 --> 03:37.200]  ну, вернее, все три изучить. Они очень разные, они очень разные, и они очень важны, и встречаются в
[03:37.200 --> 03:42.600]  языках, с которыми вы будете в жизни работать дальше. C++ вы будете работать с корутинами,
[03:42.600 --> 03:47.800]  Go вы будете работать с каналами, в какой-нибудь скала или что-нибудь функциональное вы будете
[03:47.800 --> 03:53.240]  работать фьючами. Вот, что бы вы дальше в жизни не делали, какой бы конкарнс его не писали,
[03:53.240 --> 03:58.240]  а вам, скорее всего, придется с ним сталкиваться. Ну, даже на JavaScript, неважно, на питоне. В любом
[03:58.240 --> 04:03.240]  случае, вы будете работать с одним из этих инструментов. Ну, и почему бы не изучить все эти три
[04:03.240 --> 04:08.040]  инструмента, причем изучить глубоко? Не то, чтобы как пользоваться ими, а вот прям, как они внутри
[04:08.040 --> 04:16.280]  сделаны. Вот, это очень большой буст на ваше будущее, поэтому я очень прошу вас, вот, сосредоточить силу
[04:16.280 --> 04:20.200]  на этих задачах. Но вы спросите, как же так? Это же какое-то сомнительное предложение, потому что у нас
[04:20.200 --> 04:25.920]  осталось две недели, да? Вот, и мы многое не успеем. Ну, во-первых, вы успеете что-то, да? Лучше,
[04:25.920 --> 04:35.040]  чем не успеть ничего. А во-вторых, есть предложение для всех нас немного сдвинуть дедлайны. Ну,
[04:35.040 --> 04:40.560]  зачет у нас состоится так, когда и должен пройти зачетную неделю, там, какого-то 21 или 22 числа.
[04:40.560 --> 04:47.120]  Но у нас, кажется, есть техническая возможность ведомости сдать немного позже или сильно позже
[04:47.120 --> 04:54.520]  этого дедлайна. Вот, и как это поможет нам? Это, возможно, поможет нам дорешать три эти сложные
[04:54.520 --> 05:01.280]  задачи. Ну, я, по крайней мере, морально готов сдвинуть дедлайн по этим задачам, но не то, что дедлайн,
[05:01.280 --> 05:06.440]  не знаю, может быть, даже и дедлайн. Это сильно дальше, но только именно по этим трем. Вот, после
[05:06.440 --> 05:12.440]  зачета можно будет сдавать, но вот три задачи, которые, мне кажется, важны. Если у вас найдутся
[05:12.440 --> 05:20.640]  силы там в течение ваших экзаменов, сессий, ваших канникул, то если вы готовы получить более
[05:20.640 --> 05:26.720]  высокую оценку и разобраться с новым инструментом, важным инструментом, то, ну, давайте договоримся,
[05:26.720 --> 05:32.400]  что у нас эта возможность будет. Мне очень хочется, чтобы вы и воспользовались. Единственное, что меня
[05:32.400 --> 05:37.880]  беспокоит, это беспокоит защита, потому что всё-таки сложные задачи, для сложных задач очень полезно
[05:37.880 --> 05:44.560]  защиту проводить. Я, скажем, физически смогу это делать только до конца мая, а потом уже не смогу.
[05:44.560 --> 05:51.400]  Ну, мы это, наверное, решим с вами. Просто я предлагаю вам такую возможность, надеюсь, что кто-то захочет
[05:51.400 --> 05:56.360]  ей воспользоваться. То есть, задачи, сданные даже после зачета, могут пойти в оценку, но только,
[05:56.360 --> 06:04.200]  если это задачи, которые посвящены вот грутинам, каналам, Future. Я правда не знаю, как среди них
[06:04.200 --> 06:08.640]  приоритеты какие-то выстроить. Мне кажется, что Future суперважны, потому что это вот декларативный
[06:08.640 --> 06:13.240]  подход, с которым мы сталкивались мало. С другой стороны, мне кажется, что каналы суперважны,
[06:13.240 --> 06:18.680]  потому что, во-первых, это клёвая задача, мне очень нравится, а во-вторых, сделав каналы, вот только
[06:18.680 --> 06:22.360]  тогда по-настоящему можно попрофилировать планировщик, разобрать там разные сценарии.
[06:22.360 --> 06:28.200]  Ну, вот, собственно, там заиграет лифо-планирование, которое мы писали. Вот без каналов
[06:28.200 --> 06:33.680]  профилировать планировщик, изучать его поведение довольно сложно. Нужны нетривиальные примеры,
[06:33.680 --> 06:39.760]  нужны какие-то комбинации. Вот написав каналы, вы получите эти новые ворклоды. Грутины. Ну, разумеется,
[06:39.760 --> 06:45.360]  тоже грутины важны и не менее важны, потому что это современный C++, и мы, реализуя файберы,
[06:45.360 --> 06:49.320]  реализуя там все вот эти авейтеры, всю этому шинерию внутреннюю, шли к тому, чтобы как раз
[06:49.320 --> 06:53.720]  дизайн, грутины изучить. Вот я, правда, не могу какие-то приоритеты выстроить. Мне кажется,
[06:53.720 --> 07:03.160]  что три равноправные ветки полезны сделать всё вместе. Короче, время у нас будет. Попробуйте. Вот
[07:03.160 --> 07:07.680]  если я могу чем-то вам помочь, то говорите. Может быть, там какой-нибудь дополнительный семинар провести
[07:07.680 --> 07:17.760]  или семинары. Ну, а сегодня мы поговорим про тему, которая у нас в курсе пока не возникала и про
[07:17.760 --> 07:22.120]  которую мало кто на самом деле думает, когда говорит про конкарнси, а без которой жить на
[07:22.120 --> 07:28.080]  самом деле невозможно. Это тема обработки ошибок и отмены асинхронных операций. И для того,
[07:28.080 --> 07:33.160]  чтобы вот к этому контексту прийти, нужно понять, вот откуда у нас это нужно вспомнить, вернее,
[07:33.160 --> 07:37.080]  откуда вообще конкарнси в нашей жизни возникает. Почему мы говорим про конкарнси? Почему нам
[07:37.080 --> 07:44.280]  нужно запускать эти файберы? Почему нам нужны какие-то фьючи, крутины? Крутины, простите. Потому
[07:44.280 --> 07:49.440]  что у нас есть система, которая обслуживает пользователей. Вот пользователи приходят и задают
[07:49.440 --> 07:54.240]  запросы. И этих пользователей много. Скоро угодно много. Больше, чем ядер, больше, чем способна
[07:54.240 --> 08:00.120]  операционная система поддерживать потоков. Очень много. И у каждого пользователя, для каждого
[08:00.120 --> 08:05.240]  пользователя, для каждого запроса нужно запустить какой-то, вероятно, нетривиальный контейнер,
[08:06.040 --> 08:14.160]  конвейер обслуживания этого запроса. Вот какая-то цепочка операций, которые там параллелятся иногда,
[08:14.160 --> 08:20.960]  делать что-то последовательно, но синхронно. Короче, какая-то сложная логика. Вот оттуда берутся
[08:20.960 --> 08:26.440]  фьючи, оттуда берутся селекты. Оттуда берутся фьючи и файберы, оттуда берутся примитивы
[08:26.440 --> 08:30.720]  синхронизации, когда вот эти пайпланы должны каким-то образом координировать свои действия,
[08:31.080 --> 08:34.960]  потому что они там обращаются к воздрявимым данным, ну или что-то сложное там буферизуют,
[08:34.960 --> 08:42.320]  что угодно можно себе представить. Вот именно из этих задач берется конкарнси. Но когда мы говорим
[08:42.320 --> 08:49.680]  про такие задачи, то мы... ну давайте я картинку покажу сейчас. То, как правило, мы работаем не то,
[08:49.680 --> 08:56.120]  чтобы на одной машине все это делаем. Скорее всего, мы говорим про какие-то системы, которые, ну вот
[08:56.120 --> 09:00.480]  распределенные. Распределенные, потому что они состоят из разных микросервисов, каждый из
[09:00.480 --> 09:05.920]  которых решает некоторую задачу, и эти микросервисы, там они могут быть реплицированы. В смысле,
[09:05.920 --> 09:10.720]  у вас может быть много экземпляров, потому что каждая машина может отказать. Ну и вот клиент
[09:10.720 --> 09:16.240]  приходит в вашу систему, вот такая условная граница этой системы, отправляет свой запрос,
[09:16.240 --> 09:22.200]  и вот на первой машине, на какой-нибудь там проксе запускается какой-то обработчик, какой-то,
[09:22.200 --> 09:27.360]  не знаю, файбер, какая-то карутина стартует где-то. И вот она что-то делает, а потом
[09:27.360 --> 09:32.920]  порождает новые запросы. И вот у вас из этого кубика, из этого сервиса выходят две стрелочки
[09:32.920 --> 09:39.360]  в другие кубики, в другие сервисы. Ну эти сервисы, это могут быть там разные машины,
[09:39.360 --> 09:44.000]  одна машина, можно себе представить разные физические конфигурации, но вот в общем случае
[09:44.000 --> 09:48.840]  конструкция такая, и у вас внутри этого кубика какая-то конкарнсия, а между кубиками у вас
[09:48.840 --> 09:55.920]  remote process g-call, то есть ударенный запрос. Ну то есть вы, давайте я покажу, как это может выглядеть в коде,
[09:55.920 --> 10:02.760]  например, который мы будем писать как раз у вас. Ну как это выглядит сейчас. Вы отправляете запрос
[10:02.760 --> 10:07.520]  на некоторую другую машину, которая представлена вот таким вот каналом логическим, канал здесь
[10:07.520 --> 10:15.000]  в другом смысле, нежели в фьючах, нежели в файберах, простите. Отправляем запрос сервису вот с таким
[10:15.000 --> 10:21.200]  именем, с таким запросом, с такими аргументами, ну и там получаем фьючу, которая представляет ответ.
[10:21.200 --> 10:31.280]  Вот получается такая конструкция. Здесь физические машины, сервисы, конкарнс,
[10:31.280 --> 10:41.760]  RPC между ними, между машинами, между сервисами. И с какой проблем мы здесь сталкиваемся? Ну смотрите,
[10:41.760 --> 10:50.920]  допустим нам для ответа клиенту нужно получить ответы от двух разных сервисов, но пока они
[10:50.920 --> 10:57.400]  оба не ответят, пока две машины какие-то не ответят, мы ответа дать пользователю не можем. Ну а что делать,
[10:57.400 --> 11:03.040]  если одна из машин отказала? Ну неприятная ситуация, да, но она абсолютно допустима, и если мы строим
[11:03.040 --> 11:06.720]  распределенную систему, мы должны быть к этому готовы. Мы должны быть готовы к тому, что любая
[11:06.720 --> 11:10.360]  машина может отказать. Ничего абсолютно надежного нет, никакого абсолютно надежного железа не
[11:10.360 --> 11:17.400]  бывает. Все ломается, поэтому к поломке любого компонента мы должны быть готовы. Так что мы
[11:17.400 --> 11:22.160]  не можем вот просто бесконечно дожидаться, пока нам какая-то машина ответит. Мы не можем
[11:22.160 --> 11:27.320]  бесконечно дожидаться фьюча, потому что ответ за этой фьюча никогда не появится, потому что машина
[11:27.320 --> 11:32.200]  взорвалась или утонула в центре, потому что его затопило, или там электричество, больше нет питания,
[11:32.200 --> 11:39.480]  нет. Ну или по-другому. Вот если вы знакомы с теорией массового обслуживания, вы знаете,
[11:39.480 --> 11:44.680]  наверное, это очень важный топик, и я когда-нибудь писал даже в канал по смешному поводу, но неважно
[11:44.680 --> 11:52.560]  про то, что если у вас система перегружена, если в нее приходит пользователь с своими запросами
[11:52.560 --> 11:59.080]  быстрее, чем система может их обслужить, то было бы очень странно ставить бесконечно запросы эти в
[11:59.080 --> 12:05.000]  очередь и обслуживать их, потому что тогда с какого-то момента у вас время ответа будет расти по
[12:05.000 --> 12:12.080]  экспоненте. Это плохой дизайн системы, потому что у пользователя время ответа не ограничено.
[12:12.080 --> 12:20.120]  Поэтому разумно, чтобы время ожидания пользователя, ну вот время ожидания ответа на этот запрос
[12:20.120 --> 12:25.800]  пользователя корневой, было чем-то ограничено. Но не имеет никакого смысла обслуживать все
[12:25.800 --> 12:31.000]  запросы вот до победного конца. Если система перегружена, то она перегружена. Это вот объективная
[12:31.000 --> 12:36.680]  реальность. Мы должны сказать пользователю, что его запрос отвергается, что система не способна
[12:36.680 --> 12:43.320]  его обслужить и освободить внутренние ресурсы. Вот освобождение ресурсов — это очень важный
[12:43.320 --> 12:48.960]  вопрос. Он возникает, когда мы... освобождение ресурсов, отмена операции — это примерно одно и то же.
[12:48.960 --> 12:54.000]  У пользователей есть некоторый бюджет времени на запрос, и если мы бюджеты стратили и не смогли
[12:54.000 --> 12:59.800]  на него ответить, то нужно, видимо, всю работу отменить. Если мы отправляем запрос на две машины,
[12:59.800 --> 13:09.240]  а одна из них умерла, то нужно тоже эту операцию, которая дожидается ответа от одной из машин,
[13:09.240 --> 13:13.640]  тоже отменить, потому что в ней внутри какие-то ретраи, они бесконечно крутятся, что-то
[13:13.640 --> 13:18.120]  перезапускают, переотправляют какие-то сообщения, осадение рвется, и так происходит бесконечно,
[13:18.120 --> 13:23.800]  бесконечно, бесконечно. Это какие-то ресурсы, которые система тратит под капотом, какие-то
[13:23.800 --> 13:28.120]  объекты, которые выделены в памяти, и они будут жить вечно, потому что машина никогда не живет.
[13:28.120 --> 13:31.640]  Они не будут копиться, потому что будут приходить новые запросы, отправляются новые запросы вот сюда,
[13:31.640 --> 13:38.520]  а эта машина никогда не ответит на них. Понимаете, проблема? То есть мы пока научились запускать что-то
[13:38.520 --> 13:43.760]  и дожидаться чего-то, и синхронизироваться, но иногда дожидаться не нужно. Иногда дождаться не...
[13:43.760 --> 13:49.360]  ну, дождаться невозможно просто. Или не нужно, или невозможно. И вот в этих сценариях мы хотим
[13:49.360 --> 13:57.040]  синхронные активности отменить. Ну и давайте подумаем, как можно было бы это делать. Начнем
[13:57.040 --> 14:03.120]  с простого очень сценария, где вот у нас есть клиент, и у него есть... он приходит с запросом,
[14:03.120 --> 14:09.680]  система в некоторые точки входа получает этот запрос, и видимо, отводит этому запрос
[14:09.680 --> 14:15.160]  некоторый бюджет времени. Может быть, клиент сам сообщает этот тайм-аут, может, у нас просто
[14:15.160 --> 14:21.400]  в системе есть какой-то разумный тайм-аут. И вот этот бюджет времени, он как бы на исполнение
[14:21.400 --> 14:28.520]  всего-всего по дереву. На все эти RPC вызовы, на всю синхронизацию, на все активности внутри
[14:28.520 --> 14:37.000]  отдельных сервисов, вот на исполнение всего этого графа распределенного. Тайм-ауты должны быть.
[14:37.000 --> 14:45.160]  Ну и вот давайте посмотрим на библиотеку в Python, которая называется requests. Это HTTP-запросы для
[14:45.160 --> 14:50.760]  людей, как говорится в названии. Ну и правда, очень удобная библиотека, и в ней много фичей,
[14:50.760 --> 14:56.040]  в частности, в ней есть тайм-ауты. Мы не можем перейти по этой ссылке, потому что вот настоящая
[14:56.040 --> 15:06.000]  ссылка. Смотрите, что здесь написано, что, ну вот если вы пишете какой-то промышленный код,
[15:06.000 --> 15:10.160]  если вы пишете какой-то настоящий код, который обслуживает живых людей, то вы просто обязаны
[15:10.160 --> 15:14.440]  для любого запроса устанавливать тайм-аут. Не бывает запросов без тайм-аутов, потому что,
[15:14.440 --> 15:20.040]  с другой стороны, никогда не ответят. Потому что, с другой стороны, там, от машины отказало уже. Ну или
[15:20.040 --> 15:25.640]  потому что у вас просто израсходовался ваш бюджет. Вот в любом запросе должен быть тайм-аут. Ну и вот
[15:25.640 --> 15:34.960]  есть request-get и тайм-аут. Хороший этот дизайн. Ну как бы разумно пока, да? У нас есть тайм-аут,
[15:34.960 --> 15:41.720]  мы его пропагетим вот в запрос наш. Ну, смотрите, тут даже есть комментарии смешные по этому поводу,
[15:41.720 --> 15:51.080]  что тайм-аут — это на самом деле не лимит на весь запрос. Тайм-аут — это некоторый тайм-аут,
[15:51.080 --> 15:58.040]  который передается там в отдельное чтение, там, в синхронную операцию над сокетом. А может быть у
[15:58.040 --> 16:05.000]  вас запрос — это много таких итеративных чтений из сокета. Вот. И у вас этот тайм-аут, ну то есть
[16:05.000 --> 16:09.960]  семантика тайм-аута, ну такая уже довольно зыбкая становится. Понимаете, в чем проблема? То есть что
[16:09.960 --> 16:14.160]  именно? Это тайм-аут на весь запрос, это тайм-аут на какой-то подоперацию. Ну или чтобы стало яснее,
[16:14.160 --> 16:20.680]  давайте по-другому представим. Вот у вас есть запрос, у вас есть клиент, он присылает вам запрос,
[16:20.680 --> 16:27.800]  и чтобы на него ответить, нужно сначала спросить что-то у сервиса A, а потом у сервиса B. Вот. И у вас
[16:27.800 --> 16:34.480]  есть один общий тайм-аут на весь запрос, на глобальный запрос. И вот вы посылаете запрос
[16:34.480 --> 16:41.880]  сервису A с этим тайм-аутом. Если он расходовался, то все, мы отменяем, мы говорим пользователю,
[16:41.880 --> 16:48.400]  что мы не можем его обслужить. Ну допустим, мы выполнили запрос к сервису A, он завершился в
[16:48.400 --> 16:56.560]  отведенное время, и нам нужно отправить запрос сервису B теперь. Какой тайм-аут мы передадим? Но
[16:56.560 --> 17:02.400]  видимо нам придется тайм-аут пересчитать, потому что он изменился. Потому что тайм-аут отчитывается
[17:02.400 --> 17:10.000]  от текущей точки во времени, от now, а у нас у пользователя своя точка отсчета, когда он пришел
[17:10.000 --> 17:15.320]  в нашу систему. И в итоге с тайм-аутами жить становится немного неудобно, потому что их нужно
[17:15.320 --> 17:25.040]  постоянно пересчитывать, потому что у них точка отсчета меняется. Вот с тайм-аутами работать
[17:25.040 --> 17:35.280]  неудобно, потому что их сложно пропагетить. Понимаете меня? Вот, как бы можно было упростить нашу
[17:35.280 --> 17:40.080]  логику, как можно было бы достичь того же самого, то есть ограничить бюджет на исполнение всего
[17:40.080 --> 17:47.160]  вот этого графа запросов, но при этом не вот страдать от этой сложной семантики тайм-аутов,
[17:47.160 --> 17:57.880]  от того, что они отчитываются от разных моментов времени. Ну вот, есть такая, можно думать об
[17:57.880 --> 18:04.720]  этом временном бюджете с двух позиций. Можно думать по тайм-аутам, а можно думать про дедлайны. Вот,
[18:04.720 --> 18:10.720]  вы приходите, вы клиент, вы приходите в систему, и вместо того, чтобы устанавливать тайм-аут и
[18:10.720 --> 18:21.120]  дальше его постоянно пересчитывать в каждом внутреннем шаге, вы сразу определяете дедлайн на весь
[18:21.120 --> 18:25.760]  запрос, а дальше вы можете, если вы делаете что-то параллельно, вы передаете один тот же дедлайн в
[18:25.760 --> 18:32.160]  два запроса. Если вы задаете запросы последовательно, то вы также используете один тот же дедлайн,
[18:32.160 --> 18:44.280]  потому что он по-прежнему справедлив. Это понятно, да? Вот, то есть, если у вас есть в коде API с
[18:44.280 --> 18:50.240]  тайм-аутами, то, пожалуйста, избавьтесь от него и замените его на API с дедлайнами. Это будет уже
[18:50.240 --> 18:56.400]  более композируемо. Первое наблюдение. Второе наблюдение. Ну вот, нам эти тайм-ауты нужны для
[18:56.400 --> 19:03.040]  того, чтобы операции отменять. Но операция у нас вот это что угодно. Вот мы научились уже какие-то
[19:03.040 --> 19:09.040]  штуки писать с вами, какие там фьюч, какие-то там таймеры заводить, какие-то там блокировки
[19:09.040 --> 19:18.480]  брать, чего-то ожидать разными способами. Как вы себе представляете отмену всей этой сложной
[19:18.480 --> 19:27.760]  машинерии? Ну скажем, у вас был заведенный таймер. Как вам его отменить? Ну ладно, можно себе что-то
[19:27.760 --> 19:32.320]  вообразить. А может быть, вы начали операцию учтения из сокета. Как вам отменить операцию
[19:32.320 --> 19:38.680]  учтения из сокета? Ну то есть, вы подписались в Epoly на этот самый сокет. Ну вот, вы, конечно,
[19:38.680 --> 19:45.600]  можете брать и как-то принудительно отменять что-то. Прямо буквально отменять. Вот вам,
[19:45.920 --> 19:51.320]  у вас истек дедлайн, и вот прямо сейчас нужно все срочно остановить. Это может быть сложно,
[19:51.320 --> 19:58.080]  ну потому что сложно прервать какую-то асинхронную активность в общем случае. Поэтому мы скажем,
[19:58.080 --> 20:07.160]  что да, у нас есть дедлайны, да, у нас есть задача отменно-осинхронных операций, но мы эту
[20:07.160 --> 20:15.040]  задачу будем решать как и все в нашем курсе кооперативно. То есть, вот есть асинхронная
[20:15.040 --> 20:19.320]  операция, у нее есть дедлайн. Это не значит, что она во время истечения дедлайна сразу должна
[20:19.320 --> 20:24.320]  остановиться. Нет, это значит, что она просто готова периодически проверять этот дедлайн.
[20:24.320 --> 20:30.720]  Если дедлайн истек, а операция еще не готова, то так уж и быть, она отменится. Вот тут, смотрите,
[20:30.720 --> 20:36.520]  есть такая естественная гонка, что асинхронные операции, асинхронные вот эти вычисления,
[20:36.520 --> 20:43.560]  запросы, они вот по этому графу сверху вниз поднимают вам какие-то результаты, а вы спускаете вниз
[20:43.560 --> 20:50.640]  сигнал отмены периодически, ну в виде дедлайна, да. И вот два этих сигнала, они ответы, которые
[20:50.640 --> 20:57.680]  поднимаются наверх, и отмена, которая спускается вниз в виде дедлайна пока, вот эти две, эти два
[20:57.680 --> 21:04.160]  сигнала гоняются между собой. Они могут приходить конкурентно. Так что мы не заботимся о том, в
[21:04.160 --> 21:09.840]  каком порядке все это пришло. Мы вычисляем результат, а пока он не вычислен, мы можем периодически
[21:09.840 --> 21:15.440]  проверять дедлайн. И если он истек, то мы бросим вычислять результат. А если он еще не истек,
[21:15.440 --> 21:21.920]  то мы будем продолжать. И может быть, мы вычислим результат, начнем его отправлять наверх, то есть
[21:21.920 --> 21:27.360]  отправим его в промисс, а при этом дедлайн уже истек. Ну, небольшая беда, значит,
[21:27.360 --> 21:32.320]  выше он просто уже не нужен, он не воспользуется. То есть мы сделали немного лишней работы. Нас это
[21:32.320 --> 21:37.200]  не беспокоит, потому что вот мы готовы к такому поведению. Нас это устраивает, мы готовы отменять
[21:37.200 --> 21:51.080]  кооперативно. Понятно, да? Отлично, идем дальше. Вот мы сейчас говорим про дедлайны, но насколько
[21:51.080 --> 21:59.440]  мы говорим про время. Ну, кстати, дедлайны, я сказал вам, что нужно везде работать с дедлайнами,
[21:59.440 --> 22:06.040]  я на самом деле немного вам наврал, потому что есть такая тонкость, что дедлайны, они же привязаны
[22:06.040 --> 22:13.640]  к часам. Вот. А часы, вообще говоря, это такой сложный механизм. Ну, с этого начнется следующий
[22:13.640 --> 22:18.840]  курс про определенным системам, что часы на разных машинах это... Ну, как бы часы — это приближение
[22:18.840 --> 22:23.520]  к настоящему физическому времени. Вот никто его не знает, но у каждого есть часы. И если у вас есть
[22:23.520 --> 22:27.360]  двачасовые механизма, то они могут показывать разное время. И сложно заставить их показывать одно
[22:27.360 --> 22:35.040]  и то же вообще на разных машинах. Что? Да там миллион проблем есть, и вот в общем случае часы
[22:35.040 --> 22:41.880]  плохо синхронизируются. Поэтому вообще-то сложно передавать дедлайны между машинами. Вообще-то так
[22:41.880 --> 22:48.640]  делают на практике, потому что часы синхронизируются, ну так, приемлемо. Но, строго говоря, это глубоко
[22:48.640 --> 22:56.760]  порочная идея, потому что часы не синхронизированы. Вот. Поэтому, может быть, вот здесь как раз нужно
[22:56.760 --> 23:02.680]  передавать тайм-ауты, а не дедлайны. Ну, это вот такая уже наполовину инженерная, наполовину
[23:02.680 --> 23:10.640]  какая-то теоретическая задача. Мы обсудим ее опять в следующем семестре. А пока заметим, что если мы
[23:10.640 --> 23:19.640]  говорим про одну машину, то передавать там дедлайн в виде точки во времени тоже совершенно
[23:19.640 --> 23:27.320]  необязательно. Можно немного абстрагировать этот самый дедлайн и заменить его на понятие, которое
[23:27.320 --> 23:35.400]  называется стоп-токен. Стоп-токен... Ну, что такое дедлайн? Он может быть... То есть, когда мы смотрим
[23:35.400 --> 23:41.880]  дедлайн, мы получаем сигнал такой либо 0, либо 1. Либо дедлайн еще не истек, и нужно продолжать
[23:41.880 --> 23:49.200]  работу, либо дедлайн уже истек, и нужно пробовать отменить работу. Вот этот состояние дедлайн
[23:49.200 --> 23:55.480]  истек или дедлайн еще не истек, или пора отменяться, или не пора отменяться, мы можем заменить на объект
[23:55.480 --> 24:02.080]  стоп-токен. То есть, мы передаем в наш синхронный пайплайн, состоящий там из файберов, из фьюч,
[24:02.080 --> 24:09.040]  не сам дедлайн, и передаем стоп-токен, у которого можно спросить, а не пора ли нам отмениться. Может
[24:09.040 --> 24:16.360]  быть, с другой стороны, уже вызвали стоп-реку... Ну, это не вся история. Стоп-токен — это только
[24:16.360 --> 24:28.200]  половина истории. Есть стоп-токен, есть стоп-сорс. Стоп-сорс — это объект, который строит стоп-токены.
[24:28.200 --> 24:41.120]  И мы можем сказать на стоп-сорсе, стоп-реквестат... Реквест-стоп, простите. А на самом стоп-токене мы
[24:41.120 --> 24:50.680]  можем спросить, верно ли что стоп-реквестат. То есть, тот, кто хочет отменить операцию, он через
[24:50.680 --> 24:58.080]  стоп-сорс посылает сигнал о том, что операцию нужно отменить. Просто ставит где-то вместо 0 единичку.
[24:58.080 --> 25:05.240]  А тот, кто выполняет асинхронную операцию, смотрит на этот стоп-токен и спрашивает у него, опять не туда,
[25:05.240 --> 25:14.320]  отменилась ли операция или нет. Ну, то есть, так мы немного абстрагируем дедлайн. Дедлайн можно
[25:14.320 --> 25:20.000]  представить в виде стоп-токена, для которого стоп-сорс, реквест-стоп вызывается по истечении
[25:20.000 --> 25:25.640]  некоторого времени. Ну, то есть, такой более унифицированный интерфейс, потому что мало ли
[25:25.640 --> 25:28.920]  почему мы собираемся операцию отменить. Может быть, под дедлайн, а может быть, еще по какой-то
[25:28.920 --> 25:39.400]  причине. Потому что какая-то ошибка возникла. Эта мысль понятна? Отлично. Теперь мы посмотрим на
[25:39.400 --> 25:50.040]  какой-то пример. Ну, посмотрим на язык ГО. И в языке ГО стоп-токенов нет, зато есть библиотека,
[25:50.040 --> 25:55.760]  которая называется контекст. Она довольно фундаментальна, потому что контекст — это объект,
[25:55.760 --> 26:04.440]  который как раз вам и позволяет работать с асинхронной отменой. Вот в контексте есть дедлайн.
[26:04.440 --> 26:10.280]  Контекст — это сложная штука. Она еще тесно связана с распределенным трейсингом, с распределенной
[26:10.280 --> 26:16.760]  трассировкой для наблюдения за поведением системы. Ну, это тоже тема следующего курса. Но в частности,
[26:16.760 --> 26:24.720]  контекст позволяет асинхронной операции периодически проверять, что эту операцию пора или не пора отменить.
[26:24.720 --> 26:40.240]  Этот контекст сейчас... Ну вот какая-то операция. У нее есть контекст и... Да, простите. Могу,
[26:40.240 --> 26:46.120]  конечно, увеличить. И вот у нас есть какая-то асинхронная операция, и у нее есть контекст. То
[26:46.120 --> 26:51.360]  есть контекст, то есть сигнал отмены. И вот асинхронная операция чего-то ждет. Она ждет
[26:51.360 --> 26:57.720]  сообщений из канала, например. Но, может быть, не нужно ждать его вечно, потому что операция просто
[26:57.720 --> 27:03.760]  больше не нужна. Поэтому мы пишем селект, и ровно поэтому мы в домашней профайбере пишем селект,
[27:03.760 --> 27:09.920]  и с помощью этого селекта дожидаемся одного из двух событий. Либо через контекст пришел сигнал
[27:09.920 --> 27:17.080]  отмена, либо через канал с данными пришли какие-то данные, и там мы их обработаем. Что случилось
[27:17.080 --> 27:24.440]  раньше? То есть важно, чтобы вся эта инфраструктура отмена, она как-то интегрировалась с нашими
[27:24.440 --> 27:29.360]  примитивами конкарнс, с примитивами блокирующего ожидания. Ну вот контекст это позволяет делать.
[27:29.360 --> 27:35.360]  Понимаете, судьи? Ну я прямо скажу, что лекция, она такая довольно обзорная. Мы сейчас к чему-то
[27:35.360 --> 27:41.600]  конкретному придем, а вся мотивация, она находится в следующем курсе, поэтому я вам многое не
[27:41.600 --> 27:46.880]  договариваю, и сложно просто все это рассказать сразу. Но идея должна быть примерно понятна.
[27:46.880 --> 27:56.800]  Ну и эти контексты можно декорировать. То есть можно на самом деле строить такое целое дерево
[27:56.800 --> 28:02.320]  этих контекстов, потому что у нас есть операция, и для нее есть контекст отмены. И у этой операции
[28:02.320 --> 28:07.000]  есть какие-то под-операции, у них могут быть свои правила отмены, ну то есть свои там дедлайны. И
[28:07.000 --> 28:12.240]  вот в общем случае эти контексты сплетаются в некоторое дерево. Ну вот такая скромная картинка
[28:12.240 --> 28:21.200]  должна это иллюстрировать. Вот, ну это я всего лишь рассказываю, как вот в языке Go эта сущность
[28:21.200 --> 28:27.840]  StopToken представлена, вот такой сигнал отмены асинхронный. И в языке Go это очень важная сущность,
[28:27.840 --> 28:34.000]  потому что весь код, который пишется в Go, он весь асинхронный, он весь про обработку клиентских
[28:34.000 --> 28:43.240]  запросов, а в обработке этих запросов должна быть логика по их отмене. Ну хорошо, что же нам мешает
[28:43.240 --> 28:48.000]  такие StopTokens написать? Да ничего, собственно, не мешает, а дальше нам нужно ими пользоваться.
[28:48.000 --> 28:54.320]  Вот что предлагает делать Go? Ну Go предлагает довольно скромную стратегию использования. Он
[28:54.320 --> 29:04.000]  говорит нам, что если вы хотите использовать асинхронные опера, если вы пишете асинхронный код,
[29:04.000 --> 29:08.720]  и он должен уметь отменяться, то, пожалуйста, просто передавайте в свои функции, которые вы
[29:08.720 --> 29:15.240]  исполните асинхронно, вызывая там Go что-нибудь, этот контекст первым аргументом, чтобы было
[29:15.240 --> 29:20.480]  понятно, что вот эта функция, которая где-то запускается, она готова прерваться по событию,
[29:20.480 --> 29:30.120]  по сигналу отмены. Ну и если мы пишем с вами, если мы пишем с вами собственные файберы,
[29:30.120 --> 29:47.520]  наверное, мы хотим их писать крупнее, да, хотим или нет, то, ну что мы можем сделать? Мы можем
[29:47.520 --> 29:55.920]  завести Stop Source, мы можем запустить файбер, и он запомнит этот Stop Token, а дальше будет
[29:55.920 --> 30:03.440]  что-то делать. Тут ничего не происходит, конечно, но вот смотрите, мы запустили файбер, подождали
[30:03.440 --> 30:08.640]  три секунды, а потом подумали, что хватит, пора ему остановиться. Сказали на Stop Source Request Stop,
[30:08.640 --> 30:18.560]  и этот Request Stop записал в некоторое место единичку, этот файбер ее прочитал и решил,
[30:18.560 --> 30:24.240]  что он остановится. Ну давайте мы на всякий случай все будем запускать, чтобы убедиться,
[30:24.240 --> 30:31.520]  что все работает. Да, дисклеймер важный, который я не сказал. То, что я рассказываю сейчас,
[30:31.520 --> 30:39.320]  это некоторый эксперимент, который еще не завершился. Ну, то есть, у меня в голове есть
[30:39.320 --> 30:47.520]  некоторая конструкция, как все правильно организовать, как все должно быть. Она еще до конца
[30:47.520 --> 30:50.480]  не привалидирована, поэтому я рассказываю вам какую-то очень сырую версию своего собственного
[30:50.480 --> 30:54.160]  понимания. Но мне кажется, что она довольно стройная, и если вдруг мы в середине что-то поломаем,
[30:54.160 --> 30:58.760]  то будет печально, конечно. Но вот код, который буду показывать, он точно еще сырой, и в некоторых
[30:58.760 --> 31:04.800]  местах очень плохо выглядит, поэтому не ругайте его и меня слишком сильно, все еще впереди. Ну вот,
[31:04.800 --> 31:17.160]  пример работает, да. Теперь, как этот стоп-токен реализован? Стоп-токен и стоп-сорс. Ну, смотрите,
[31:17.160 --> 31:25.080]  мы говорим про асинхронные операции. Это что означает? Что у вас есть некоторый продюсер,
[31:25.080 --> 31:32.240]  который что-то делает, и есть консюмер, который ожидает результата. И вот они как-то развязаны в
[31:32.240 --> 31:40.720]  смысле их лайфтаймов. Вот непонятно, кто завершится раньше. Поэтому как можно себе вот внутри, изнутри
[31:40.720 --> 31:45.840]  представить реализацию этих стоп-сорсов и стоп-токенов? Ну, очень-очень-очень просто.
[31:45.840 --> 31:57.640]  Это не то. Вот стоп-токены. У вас есть стоп-сорс, через него вы отправляете сигнал в стоп-токен.
[31:57.640 --> 32:05.440]  Но где этот сигнал должен храниться? 0 или 1? Не там-не там, потому что может быть продюсер завершится
[32:05.440 --> 32:14.680]  раньше, чем консюмер прочитает сигнал. А может быть консюмер завершится раньше, ой, продюсер
[32:14.680 --> 32:20.720]  завершится раньше. Сейчас, может быть консюмер со стоп-сорсом завершится раньше, чем продюсер со
[32:20.720 --> 32:26.760]  стоп-токеном прочитает сигнал. А может быть все наоборот. Поэтому не там-не там хранить эту единицу
[32:26.760 --> 32:33.680]  или 0 нельзя. Поэтому мы выделяем некоторый стоп-стейт с динамическим временем жизни, ставим на него
[32:33.680 --> 32:40.920]  две сильные ссылки. И эти сильные ссылки поддерживают стоп-стейт до тех пор, пока жив, ну, либо стоп-сорс,
[32:40.920 --> 32:48.920]  либо хотя бы один из стоп-токенов, которых может быть несколько. Это должно вам что-то напоминать уже.
[32:48.920 --> 33:00.640]  Ну, если напоминает, то хорошо. Давайте здесь напишем 1. Вот, операция отменилась. Ну, в принципе,
[33:00.640 --> 33:05.160]  может слышать, что лекция закончена, но можно, в принципе, весь поход так и писать. То есть вы везде
[33:05.160 --> 33:09.680]  тащите с собой все эти стоп-токены в каждую операцию синхронную. Когда вы что-то запускаете,
[33:09.680 --> 33:15.160]  запускаете файбер, захватываете токен, передаете токен. Когда вы запускаете что-то в пуле потоков,
[33:15.160 --> 33:22.280]  то вы тоже в замыкание захватываете токен для того, чтобы его проверять. Так жить можно,
[33:22.280 --> 33:30.920]  но так жить совершенно унизительно. Почему? Ну, давайте я по-другому скажу, что синхронная отмена
[33:30.920 --> 33:39.600]  очень важна. Это очень важный инструмент, который должен присутствовать всегда. Но если мы заставляем
[33:39.600 --> 33:46.120]  каждого пользователя, который запускает какие-то асинхронные там пайплайны, графы, каждый раз
[33:46.120 --> 33:49.960]  руками протаскивать все эти токены, то, значит, мы говорим, что у нас есть задача, которая решается
[33:49.960 --> 33:55.200]  всегда одинаково, но мы решаем это каждый раз. В смысле, мы, разработчики фреймворка,
[33:55.200 --> 34:02.760]  твоими пользователями усилиями. Мы почему-то не сделали это сами прозрачно для тебя. Вот такие
[34:02.760 --> 34:08.480]  механизмы должны, чтобы они были надежными, чтобы не всегда работали, они, по возможности, должны
[34:08.480 --> 34:12.960]  быть прозрачными. То есть пользователь не должен их наблюдать. Все должно работать каким-то образом само.
[34:12.960 --> 34:22.880]  Понятная мотивация. Вот это и трейсинг касается. Ну, и опять следующий курс. Поэтому мы бы хотели,
[34:22.880 --> 34:28.800]  мы бы хотели делать вообще-то вот так. Ну, тут есть некоторые вспомогательные норсери,
[34:28.800 --> 34:35.600]  это неважно сейчас. Он здесь не принципиально. Мы как-то запускаем файбер. Файбер запускает
[34:35.600 --> 34:41.080]  функцию foo, в ней он запускает функцию bar, в ней он запускает функцию baz, в ней он бесконечно спит.
[34:41.080 --> 34:51.840]  А потом мы бы хотели сказать cancel на этом файбере. Ну, мы бы... Ну, и под капотом все будет работать точно
[34:51.840 --> 34:57.360]  так же. У нас будет stopToken, stopSource, где-то здесь спрятан stopSource, где-то у файбера есть stopToken,
[34:57.360 --> 35:06.120]  но в коде явно его нигде нет. Вот давайте подумаем, как можно отменить файбер так,
[35:06.120 --> 35:15.360]  чтобы отмена была прозрачна для пользователей, которые этот файбер пишет. Мы хотим прервать
[35:15.360 --> 35:20.320]  исполнение файбера. Ну, файбер, смотрите, он кооперативный, то есть нельзя просто взять его
[35:20.320 --> 35:24.240]  и прервать в любой момент времени. Но мы сказали, что нас это устраивает, отмена кооперативная. То
[35:24.240 --> 35:30.120]  есть иногда файбер должен проверять, что ему пора отмениться. Для этого у него есть stopToken.
[35:30.120 --> 35:37.400]  Файбер проверяет, что его нужно отмениться через stopToken. Вопросов два. Когда он проверяет это и
[35:37.400 --> 35:52.160]  где? И второй вопрос. Как он, собственно, собирается отменяться? Ну, смотрите, файбер, он выполняет код
[35:52.160 --> 35:56.960]  пользователя. И в коде пользователя работает код пользователя, поэтому, то есть там отмениться
[35:56.960 --> 36:03.880]  нельзя. Там его логика написана. Но иногда все-таки файбер, точнее, не иногда, а часто. Почему мы пишем
[36:03.880 --> 36:09.080]  файбер? Потому что они часто останавливаются, чего-то ждут. Они обращаются к рантайму. То есть мы
[36:09.080 --> 36:13.720]  исполняли код пользователя, а потом мы прыгаем в реализацию наших файберов. Вот, например,
[36:13.720 --> 36:21.640]  здесь, когда мы вызываем slip4, мы получаем, на самом деле, фьючу. У нас есть некоторый сервис
[36:21.640 --> 36:30.400]  таймеров, который строит фьючи. И мы дожидаемся этой фьючи синхронно с помощью операции await,
[36:30.400 --> 36:37.160]  которая, на самом деле, просто симулирует целиком механику корутин. То есть тоже авейтер строится,
[36:37.160 --> 36:43.360]  мы засыпаем, ожидая этого авейтера. Это такой способ интеграции фьюч и файберов,
[36:43.360 --> 36:48.520]  который, кстати, мы тоже можем еще в курсе написать. Если вы знакомы с корутинами, то мы этот код,
[36:48.520 --> 36:54.840]  в общем-то, изучали. Вот у фьючи есть авейтер, который подписывается... Собственно, что я рассказываю,
[36:54.840 --> 37:00.840]  я же могу показать. Чтобы дождаться фьючи, нам нужен авейтер. Авейтер в самом привычном для нас
[37:00.840 --> 37:11.280]  смысле. И авейтер для фьючи выглядит ну как-то так. Мы подписываемся на фьючу, и в ней мы резюмим
[37:11.280 --> 37:20.480]  файбер в колбэке, а потом мы файбер останавливаем. Но останавливаем его не явно вот здесь,
[37:20.480 --> 37:28.080]  точнее, явно с помощью этого suspend. А после остановки мы запускаем авейтер await suspend,
[37:28.080 --> 37:32.240]  и он там подписывается на фьючу и там планирует возобновление файбера. Короче, вы все это написали
[37:32.240 --> 37:37.480]  уже. Только для Mutex и только для кондвара, но для фьючи, в принципе, то же самое. Так вот,
[37:37.480 --> 37:41.640]  мы берем и в точках обращения к runtime, где файбер останавливается, потом возобновляется операцию
[37:41.640 --> 37:48.880]  checkpoint, которая что делает? Она просто проверяет, пора ли файберу остановиться. Черт, спойя. Как
[37:48.880 --> 37:53.920]  проверять? Ну просто у каждого файбера при запуске должен быть стоп токен. То есть когда мы
[37:53.920 --> 38:05.640]  конструируем файбер, мы вместе со всем остальным, что ему важно, передаем еще и стоп токен. На самом
[38:05.640 --> 38:11.960]  деле так можно не делать. Он в супервизоре, может быть. Ну пусть. У каждого созданного файбера
[38:11.960 --> 38:16.440]  должен быть стоп токен. Если файбер не хочет останавливаться, у него может не быть, ну точнее,
[38:16.440 --> 38:20.640]  у любого файбера есть стоп токен, даже у файбера, который вообще не хочет останавливаться кооперативно.
[38:20.640 --> 38:28.920]  Что такое стоп токен? Да, давайте я покажу. Я почему-то не показал это. Стоп токен — это сильная
[38:28.920 --> 38:39.440]  ссылка на stop state. А stop state — ну это, вообще говоря, флажок отомарный, но, строго говоря,
[38:39.440 --> 38:44.800]  это некоторый интерфейс, у которого есть операция request stop и stop request. Ну в некоторой
[38:44.800 --> 38:51.280]  реализации request stop пишет флажок единичку, а операция stop request проверяет. Но есть, скажем,
[38:51.280 --> 38:58.520]  стоп токен, который строится в функции never. И этот стоп токен устроен так. Он всегда говорит
[38:58.520 --> 39:02.960]  false stop request, а request stop игнорирует вообще. То есть, ну не вызывается на имени когда request stop.
[39:02.960 --> 39:07.920]  Это такой дефолт для всех файберов, которые просто запускаются через го. Мы их запускаем,
[39:07.920 --> 39:15.560]  они там как-то исполняются, и останавливаться они не собираются кооперативно. Это значит,
[39:15.560 --> 39:22.040]  первый вопрос — как именно файбер может узнать, что ему пора остановиться? Второй вопрос — как
[39:22.040 --> 39:29.000]  именно он собирается прервать свое исполнение? Он же где-то там в недрах какого-то стека был
[39:29.000 --> 39:36.200]  погружен. В смысле, в недрах какого-то стека выполнял какую-то работу. Как же нам прервать этот
[39:36.200 --> 39:40.760]  файбер? Мы же не можем просто выйти из него и разрушить его, потому что на стеке куча объектов,
[39:40.760 --> 39:52.920]  потому что, да. Есть ли идея не у семинаристов? Вот, да. Но я спойлер уже там показал один раз,
[39:52.920 --> 39:58.800]  как можно разрушить все объекты, как можно разрушить состояние всех объектов на файбере,
[39:58.800 --> 40:03.680]  на стеке файбер. Ну, кинуть exception, который начнет разворачивать стек файбера, вызовет
[40:03.680 --> 40:08.640]  деструктора всех объектов на стеке, и вот файбер освободит все ресурсы, которые он там захватил.
[40:08.640 --> 40:17.440]  Всю память. Ну, короче, у вас вот обычная рай. То есть, менеджмент ресурсов связанный с скопами.
[40:17.440 --> 40:26.920]  У нас будет специальное исключение и файбер, когда он... и файбер. Давайте я покажу сейчас.
[40:33.920 --> 40:35.520]  Так, я не там, где я хочу.
[40:38.640 --> 40:52.120]  Fiber run. Тут symmetric transfer. Вот. Файбер запускается, делает свой шаг, и из него вылетает либо исключение
[40:52.120 --> 40:57.120]  любое, либо специальное исключение. И это специальное исключение, оно специальным образом
[40:57.120 --> 40:59.760]  обрабатывается. Ну, тут похожим образом обрабатывается, но есть некоторая разница,
[40:59.760 --> 41:06.200]  есть некоторый супервизор, про который пока не понятно ничего. В общем, специальное исключение
[41:06.200 --> 41:17.480]  для отмены файбера. И теперь возвращаемся к нашим примерам. Вот код, который может отменяться,
[41:17.480 --> 41:28.480]  и в котором нет никакой специальной ручной машинерии по вот этой отмене. Это хорошо. Это важно,
[41:28.480 --> 41:34.960]  потому что пользователь может, который пишет файбер, ему не нужно думать, как именно поддержать
[41:34.960 --> 41:43.760]  отмену. Об этом думаем мы, разработчики фреймворка, в асинхронных операциях, которые мы реализуем. Вот
[41:43.760 --> 41:48.240]  именно в этих асинхронных операциях, в точке, где файбер останавливается, возобновляется,
[41:48.240 --> 41:53.160]  мы можем проверять этот флажок и выбрасывать исключение, которое вот прозрачно разворачивает
[41:53.160 --> 41:59.920]  нам стэк, освобождает ресурсы и таким образом отменяет работу файбера. Это с файберами.
[41:59.920 --> 42:08.080]  Что касается файберов. Дальше вторая половина. Что касается фьюч. Как с ними быть? Ну, вот мы говорили,
[42:08.080 --> 42:17.400]  что фьюча... А давайте я открою картинку. Я вам дико рекламирую, если вы до сих пор не прочитали.
[42:17.400 --> 42:21.520]  Ну, вообще, я на следующем занятии последним расскажу, какие статьи непременно стоит прочитать.
[42:21.520 --> 42:30.160]  Ну, это стоит уж точно. Я рассказал вам про эту статью про фьюча, про то, как можно на фьючах выразить
[42:30.160 --> 42:36.720]  вообще всю свою логику. И в этой статье вот есть замечательная иллюстрация, которая мне сейчас
[42:36.720 --> 42:42.560]  нужна. С помощью фьюч, с помощью вот разных комбинаторов мы можем параллельной композиции,
[42:42.560 --> 42:49.720]  последовательной композиции, мы можем выстроить такой граф обработки запроса. Вот, этот граф...
[42:49.720 --> 43:00.040]  Ну, тут стрелки ориентированы... Странная картинка. Она могла быть нарисована по-другому. Ну,
[43:00.040 --> 43:07.920]  смотрите, с помощью фьюч мы выстраиваем, по сути, граф. У него есть истоки, это продюсеры,
[43:07.920 --> 43:14.000]  которые что-то вычисляют. Есть промежуточные узлы, это комбинаторы. Дождаться двух ответов,
[43:14.000 --> 43:19.880]  дождаться первого из двух ответов. И у нас есть консюмер, который дожидается в конечном счете,
[43:19.880 --> 43:25.200]  в счете подписывается на результат или что-то подобное. Вот мы выстраиваем такой граф, и он
[43:25.200 --> 43:35.720]  ориентирован как? Ну, если мы смотрим на эту картинку, если мы говорим про какие-то развилки,
[43:35.720 --> 43:44.480]  вот такое дерево. Вот это как бы логика порождения запросов сверху вниз. Но на самом деле фьючи,
[43:44.480 --> 43:49.160]  они ориентируют граф в обратном направлении. Когда мы выстраиваем весь граф, то у нас же
[43:49.160 --> 43:55.920]  результаты, то есть ошибки и ответы идут сверху, снизу вверх. То есть у нас такой граф, в котором есть
[43:55.920 --> 44:08.000]  истоки, это продюсеры, и единственный сток – это вот консюмер, в которого все сходится. Это что
[44:08.000 --> 44:14.440]  касается результатов, ошибок или значений. Но если мы выстраиваем асинхронные вычисления не с
[44:14.440 --> 44:19.540]  помощью файберов, а с помощью фьюч, нам же нужно в этот граф отправлять сигнал-отмен в обратном
[44:19.540 --> 44:29.660]  порядке. Ну, в обратную сторону. От консюмера к продюсерам. А фьючи так не умеют. Да? Что
[44:29.660 --> 44:33.940]  можно было бы делать? Ну, можно было бы в каждую асинхронную операцию передавать явно стоп-токен,
[44:33.940 --> 44:43.420]  по-прежнему. Сейчас, ну, примеров у меня готового нет, но это и, наверное, и так понятно. Мы запускаем
[44:43.420 --> 44:48.500]  в третпуле вычисления, бросаем туда стоп-токен, получаем фьюч, а дальше вычисляем что-то,
[44:48.500 --> 44:54.340]  если проверяем стоп-токен. Но опять это явный код, мы опять явно передаем стоп-токен. Как
[44:54.340 --> 45:04.540]  можно было бы делать это не явно? Кто понимает? У нас ограничено время вообще? После 45 минут или?
[45:04.540 --> 45:14.020]  Хорошо, воспользуемся этим. Ну, тема важная, правда. Лекция новая, тайминг непредсказуемый,
[45:14.020 --> 45:21.220]  я читаю это второй раз в жизни, все еще очень спонтанно. Смотрите, на что я хочу обратить
[45:21.220 --> 45:28.900]  внимание. Что вот есть, есть задача, как можно интегрировать cancellation во фьючи. И тут нужно
[45:28.900 --> 45:36.980]  увидеть связь между двумя картинками, которые не помещаются на экран, черт возьми. Есть promise
[45:36.980 --> 45:43.580]  и future, есть producer и consumer. И продюсер отправляет через promise значение, через shared state
[45:43.580 --> 45:52.180]  консьюмеру. Через фьючу мы читаем. И есть этот shared state, который алоцирован на куче,
[45:52.180 --> 45:59.420]  потому что опять непонятно, кто завершится раньше. И вот ровно здесь хранится результат. А с другой
[45:59.420 --> 46:06.940]  стороны есть стоп-токен и стоп-сорс. И мы через стоп-сорс отправляем сигнал отмены и, ну,
[46:06.940 --> 46:13.660]  через стоп-сорс мы отменяем асинхронную операцию, пишем сигнал в стоп-стейт и через
[46:13.660 --> 46:20.700]  стоп-токен его проверяют. И опять пишет сигнал, отправляет сигнал консьюмер, пишет,
[46:20.700 --> 46:26.820]  читает сигнал, простите, продюсер. Вот видите, какая-то двойственность есть такая, очень
[46:26.820 --> 46:36.260]  естественная, естественно, наблюдаемая. Что? Сокет, господи. Нет, я хочу сказать,
[46:36.260 --> 46:51.060]  что shared state, он же и стоп-стейт. И я хочу так и написать код. Секунду. Где у меня фьючу?
[46:51.060 --> 47:10.580]  Откуда все это взялось? Фьюча, shared state, и смотрите, она наследуется от стоп-стейта. Ну,
[47:10.580 --> 47:18.740]  то есть с одной стороны в этом shared state лежит результат callback, а с другой стороны в этом
[47:18.740 --> 47:29.780]  shared state лежит еще и флажок стоп-реквеста, который наследуется вот отсюда. И смотрите,
[47:29.780 --> 47:36.300]  что я теперь могу сделать. Ну, это уже начинаются какие-то такие хитрые штуки. Я в них уверен на
[47:36.300 --> 47:41.780]  процентов 80, в смысле, что вот так и нужно делать. Но мне кажется, что так все выглядит пока разумно.
[47:41.780 --> 47:48.220]  Я хочу поканцелить операцию асинхронную. Вот я запустил асинхронную операцию, вот у нее есть
[47:48.220 --> 47:57.540]  промисс. И я теперь говорю, что через промисс можно читать флажок. Стоп-реквест. Вот у меня есть
[47:57.540 --> 48:02.940]  фьюча и промисс. Промисс я даю асинхронной операции, и вот она крутится периодически,
[48:02.940 --> 48:08.380]  проверяя, что нужно или не нужно отмениться. А теперь, смотрите, самое красивое. Я беру фьючу
[48:08.380 --> 48:22.940]  f1 и подвешиваю к ней продолжение f2. И вот в этом зене скрыто связывание стоп-токенов. Вот я говорю,
[48:22.940 --> 48:30.940]  на f2 cancel, а отменяется у меня вот эта операция. Опять никакой ручной инструментации,
[48:31.020 --> 48:41.500]  никакого ручного аннотирования всего этого нет. Ну, смотри, если бы я хотел написать,
[48:41.500 --> 48:46.420]  например, в десять раз больше и сложнее и замылить основную идею этого кода, я бы,
[48:46.420 --> 48:50.420]  наверное, так и сделал. Но я не хотел. Нет, в смысле, этот код, он, конечно, бессмысленно,
[48:50.420 --> 48:54.660]  потому что… Ну, ладно. В этом коде нет смысла, потому что ничего не делать полезного. Он просто
[48:54.660 --> 48:59.220]  иллюстрирует отмену операции, которая что-то долго вычисляет. Здесь бесконечно долго вычисляет,
[48:59.220 --> 49:23.500]  вообще ничего не вычисляет. Давайте посмотрим, что это работает. А код просто слишком новый,
[49:23.500 --> 49:31.180]  вот он… Ну, ладно. Вот, операция отменилась, и мы не ждали ничего вечного, хотя могли бы.
[49:31.180 --> 49:42.940]  Вот. Что происходит в этом зене? Смотрите, я говорю, у меня есть две future, это два shared
[49:42.940 --> 49:48.620]  state и два стоп-токена. И у меня стоп-токены, они, смотрите, они немного сложнее, чем я вам
[49:48.620 --> 49:53.060]  показывал. Ну, в смысле, они немного сложнее, чем просто поставить флажок и прочитать флажок,
[49:53.060 --> 50:02.140]  конечно. Мне нужно еще уметь подписываться на флажок, вешать кулбэк, то есть выстраивать дерево
[50:02.140 --> 50:17.340]  этих самых… Сигнал… Дерево этих самых стоп-стейтов. То есть, когда я… Когда я говорю f1 zen,
[50:17.340 --> 50:25.900]  то я подписываюсь на результат future f1. Я хочу вызвать в кулбэке вот эту лямду,
[50:25.900 --> 50:33.300]  которая обработает полученное значение. Но когда я подписываюсь, я заодно… Смотрите, у меня сигнатура…
[50:33.300 --> 50:42.140]  Вот в этом месте я не уверен как раз. Я семантику subscribe у future немного расширяю. Я говорю,
[50:42.220 --> 50:49.820]  что… Это не то. Я говорю, что у операции subscribe сигнатура теперь такая. Она возвращает
[50:49.820 --> 50:59.900]  стоп-токен. Вот тот, кто подписывается на результат, должен управлять и отменой операции. И когда я
[50:59.900 --> 51:06.380]  пишу zen, я пишу zen через subscribe, но это вот ваша домашка, которую стоит сделать. И я подписываюсь
[51:06.380 --> 51:13.500]  на результат, а вместе с этим я связываю стоп-токен текущей future, новой, которую я строю, f2,
[51:13.500 --> 51:21.700]  с токеном вот этой future. И в итоге я как бы с одной стороны в одну сторону строю граф,
[51:21.700 --> 51:31.420]  сверху вниз. Граф из future shared-states, из операции shared-states. А с другой стороны параллельно
[51:31.420 --> 51:37.420]  строю граф вниз из стоп-токенов, потому что мне в одну сторону нужно отправлять результаты,
[51:37.420 --> 51:52.020]  а вниз мне нужно отправлять отмену. Схватываете идею? Да. Тут всякое может быть, но утверждается,
[51:52.020 --> 51:59.580]  что… Еще 5% моих сомнений, что если написать все аккуратно, то оно с какой-то стороны
[51:59.580 --> 52:05.100]  начнет разворачиваться и разорвется. Но это нужно аккуратно сделать, но это кажется,
[52:05.100 --> 52:10.060]  что можно сделать. Здесь не должно быть вот прям циклов, потому что оно либо завершается,
[52:10.060 --> 52:22.100]  либо отменяется. Что-то из двух случается непременно. Ну, потому что консюмер подписался на результат,
[52:22.100 --> 52:36.780]  значит, он его ждет. Значит, именно он отвечает за отмену. Токен – это ссылка на stop-state,
[52:36.780 --> 52:48.420]  а stop-states можно связать в граф. Да, это плохой код. Я могу получить стоп-токен и на нем руками
[52:48.500 --> 53:06.100]  нажать отмену. Либо я могу стоп-токена спросить stop-state и связать его… Ну, смотри, тут все несколько
[53:06.100 --> 53:14.340]  сложнее. Код, во-первых, еще сырой, поэтому запомнить нужно не реализацию, запомнить нужно идею,
[53:14.340 --> 53:19.260]  что я строю граф в одну сторону и параллельно строю граф в другую сторону. Это такие двойственные
[53:19.260 --> 53:24.380]  сущности, потому что двойственность берется отсюда. Я как shared-state и связываю в граф,
[53:24.380 --> 53:29.100]  так и stop-state и связываю в граф. Просто в разные стороны ссылки ориентирую,
[53:29.100 --> 53:36.860]  потому что в одну сторону летит результат, а в другую сторону летит отмена. Ну как, понятно,
[53:36.860 --> 53:42.180]  да? Ну, точнее как, понятно ли, чего мы хотим достичь в итоге? Вот чтобы код выглядел так.
[53:42.220 --> 53:49.260]  Довольно симпатично. А дальше, собственно, начинается тема лекции.
[53:49.260 --> 54:19.020]  Вот. Значит, сменим резко тему. Ну, на самом деле не сменим, конечно. На самом деле я
[54:19.020 --> 54:26.900]  хочу связать... Пока у нас конструкция очень простая. Мы либо вот в этом графе поднимаемся
[54:26.900 --> 54:34.260]  снизу вверх, либо сверху вниз отменяем. Но реальность, на самом деле, сложнее. И вот тут
[54:34.260 --> 54:39.780]  возникает понятие, которое называется structured concurrency, и в том числе ради которого мы сегодня
[54:39.780 --> 54:46.620]  здесь собрались. И про это понятие есть чудесная статья, not structured concurrency,
[54:46.620 --> 54:52.300]  or Go Statement Considered Harmful. И ровно поэтому этот комментарий был написан в самом начале
[54:52.300 --> 54:57.780]  в шаблоне Файберов. И почему-то весь семейство никто об этом не спрашивает. Ну, один вопрос
[54:57.780 --> 55:04.860]  кто-то задал, да. Это была ссылка на эту статью, потому что, смотрите, ну, забудьте про конкарнси.
[55:04.860 --> 55:11.860]  Давайте подумаем про глубокую старину. Вот. И обратимся к фундаментальной работе,
[55:11.860 --> 55:21.460]  DXTRA, про оператор GoTo. Вот это, мне кажется, оператор GoTo, критика этого оператора и
[55:21.460 --> 55:28.580]  термин structured programming — это гораздо более фундаментальная вещь, чем знакомый вам,
[55:28.580 --> 55:35.460]  видимо, алгоритм этого товарища. Вот нам сейчас гораздо полезнее вот вычисление кратчейших
[55:35.460 --> 55:44.220]  путей structured programming. В чем идея? Итак, представим себе глубокую старину и некоторую
[55:44.220 --> 55:49.540]  программу, которая написана на каком-то древнем языке, который, наверное, больше напоминает
[55:49.540 --> 55:56.540]  Assembler. Ну, тут есть примеры таких программ. И вот смотрите, что можно сразу заметить,
[55:56.540 --> 56:03.260]  что программа плоская. Это вот некоторый плоский текст инструкций. И эта программа выполняется,
[56:03.260 --> 56:09.220]  и по этому тексту движется instruction pointer, передается управление. И управление передается с
[56:09.220 --> 56:12.780]  помощью такого универсального инструмента GoTo. Мы можем просто прыгнуть в некоторую метку.
[56:12.780 --> 56:19.700]  Ну и так можно написать, в принципе, любой код. Более того, компилиаторы, когда компилируют ваш
[56:19.700 --> 56:26.100]  код, могут переписывать все ваши циклы и там if и все такое в этот GoTo. Но когда вы пишете
[56:26.100 --> 56:32.860]  какую-то прикладную задачу, то использовать оператор GoTo, возможно, не лучшая идея.
[56:32.860 --> 56:41.100]  И не то чтобы вам будет сложно, не только вам будет сложно. Смотрите, о чем я. Когда у вас есть
[56:41.100 --> 56:54.260]  для передачи управления только оператор GoTo, то очень сложно описать состояние исполнения в вашей
[56:54.260 --> 57:00.780]  программе. Вот вы находитесь в какой-то строчке, но как вы туда попали? Почему вы туда попали? Что
[57:00.780 --> 57:06.980]  вообще происходит в вашей программе? Очень сложно понять. Очень сложно отследить траекторию.
[57:06.980 --> 57:18.180]  Что пишет Dextro? Он пишет чертовски разумную вещь, что вот возможности человеческого интеллекта,
[57:18.180 --> 57:26.300]  они ограничены. Вот человеческий интеллект, он пытается визуализировать что-то. И нам гораздо
[57:26.300 --> 57:31.940]  проще думать не про какие-то сложные динамические системы, которые очень часто меняются, а куда-то
[57:31.940 --> 57:36.540]  двигаются. Ну скажем, нам сложно думать про интерливинге потоков, поэтому мы и страдаем
[57:36.540 --> 57:41.940]  этот семестер, вот думая, как там все переключилось. Человеку гораздо проще представлять какие-то
[57:41.940 --> 57:49.460]  статические структуры, вот просто их легко визуализировать. Поэтому было бы хорошо, если бы
[57:49.460 --> 57:56.700]  исполнение программы было бы согласовано с некоторой статической структурой,
[57:56.700 --> 58:05.860]  которой можно было бы себе изобразить. Поэтому Dextro говорит, что возможно стоит заменить этот
[58:05.860 --> 58:12.860]  GoTo на какие-то более ограниченные конструкции. Скажем, оператор видвления, оператор цикла,
[58:12.860 --> 58:23.860]  оператор вызова функции. И вот эти операторы, они будут структурировать поток управления. Вот,
[58:23.860 --> 58:27.380]  ну есть даже теорема, которая называется Structured Programming Serum, которая говорит,
[58:27.380 --> 58:33.660]  что вот на самом деле мы так не ограничиваем вычислительные возможности свои. То есть,
[58:33.660 --> 58:36.740]  если мы используем только такую передачу управления, то мы по-прежнему можем вычислить
[58:36.740 --> 58:43.940]  все что угодно. Мы же ограничиваем все-таки себя. В GoTo у нас было больше свободы. Но сейчас мы себя
[58:43.940 --> 58:51.020]  ограничим и на самом деле мы из этого ограничения получим ясную структуру программы, которую в
[58:51.020 --> 58:56.700]  теории компиляторов языков программирования называют Control Flow Graph. Сейчас я найду какую-нибудь
[58:56.700 --> 59:04.260]  ссылку про это. Вот думать о структуре программы нужно не только вам, разработчику, нужно думать
[59:04.260 --> 59:09.180]  и компилятору, потому что компилятор часто про программу доказывает что-то. Ну скажем,
[59:09.180 --> 59:15.340]  он занимается тем, что пропагетит константы. Вот вы объявили две константы, потом где-то вы их
[59:15.340 --> 59:21.140]  перемножили, а потом что-то еще сложили. Вот компилятор хочет уметь эти константы, все эти
[59:21.140 --> 59:25.580]  вычисления выполнить при компиляции статически, перед исполнением программы. А для этого ему нужно
[59:25.580 --> 59:31.940]  понимать, вот когда какую-то переменную умножают на другую переменную, какие значения переменная
[59:31.940 --> 59:36.220]  может принимать. Если только одно значение, то, видимо, не нужно просто использовать перемены,
[59:36.220 --> 59:40.940]  лоцировать память, поддерживать ячейки, а нужно просто константу записать в этой местопрограмме.
[59:40.940 --> 59:48.060]  Вот комператору нужно, комператор хочет такие свойства доказывать. Или, я не знаю, вы любитель,
[59:48.060 --> 01:00:10.860]  вы любитель, вы любитель Раста и любите, не могу хорошую ссылку быстро найти, проклятие. Секундочку.
[01:00:18.060 --> 01:00:39.300]  Нет, garbage collector здесь ни при чём. Да ладно, может быть, мне эта ссылка сойдёт. А может быть,
[01:00:39.300 --> 01:00:52.220]  у меня здесь есть подходящая. Нет. Ну, в общем, идея. Если в вашей программе есть структура,
[01:00:52.220 --> 01:01:01.460]  то есть вы можете каким-то образом её из текста программы вычленить, и то...
[01:01:01.460 --> 01:01:15.100]  Дальше вы на месте комператора можете на основе этой структуры прям доказывать что-то про вашу
[01:01:15.100 --> 01:01:20.980]  программу. Ну, вот я говорю про Rast, потому что там есть Liveness анализ, он используется в
[01:01:20.980 --> 01:01:30.340]  Borough Checker, Rast известен в первую очередь по нему, потому что вы там не можете случайно написать
[01:01:30.340 --> 01:01:35.260]  что-то в вектор, когда этот вектор перелатировал свой внутренний буфер. Ну, вот для того, чтобы
[01:01:35.260 --> 01:01:41.500]  Rast мог отслеживать такие потенциально опасные программы, ему нужен какой-то механизм для того,
[01:01:41.500 --> 01:01:48.260]  чтобы доказывать, что вот у вас есть две переменные, через которые вы дальше в будущем можете
[01:01:48.260 --> 01:01:54.500]  обращаться к одной и той же памяти. И для этого используется вот тоже такая структура, которая
[01:01:54.500 --> 01:02:01.100]  называется Contraflow Graph и Dataflow Analyze, ну, в частности Liveness Analyze, живость переменных
[01:02:01.100 --> 01:02:08.780]  так называемые. В общем, если в программе есть структура, то, во-первых, вам проще думать про
[01:02:08.780 --> 01:02:13.780]  исполнение этой программы, потому что любая траектория исполнения — это теперь некоторые,
[01:02:13.780 --> 01:02:23.100]  ну, просто стэк вызовов. Это некоторые путь вот в вот в таком графе, ну, некоторая веточка,
[01:02:23.100 --> 01:02:27.780]  которую вы выбрали. Вот вы пошли сюда, или вы пошли вот там пару раз сюда, или вы прошли через
[01:02:27.780 --> 01:02:33.140]  функцию. Вам удобно думать, где сейчас программа остановилась, в каком она состоянии, и это просто
[01:02:33.140 --> 01:02:38.140]  хороший инструмент абстракции. Вам не нужно думать, как реализована функция, вам нужно знать только
[01:02:38.140 --> 01:02:44.660]  её сигнатуру, как её вызвать и как получите ответ через какие регистры. Вот это очень мощная идея,
[01:02:44.660 --> 01:02:49.460]  вот она изменила программирование, достаточно давно уже, там, полвека назад, может быть,
[01:02:49.460 --> 01:02:57.020]  больше. Почему она навожена нам сейчас? Ну, нет, подождите, рано пока. Почему она, да, как она
[01:02:57.020 --> 01:03:02.060]  косвенно относится к нашей лекции? Потому что мы говорим в том числе про обработку ошибок сегодня.
[01:03:02.060 --> 01:03:09.060]  Вот отмена — это одна история, вторая половина — это обработка ошибок. Вот структурное
[01:03:09.060 --> 01:03:14.260]  программирование делает обработку ошибок проще, потому что если у вас есть понятная траектория в
[01:03:14.260 --> 01:03:20.420]  исполнении, которая представляется в виде коллстека, то вам легко ошибку передать выше, до той точки, где
[01:03:20.420 --> 01:03:26.740]  её обработают прозрачно, с помощью исключений. Вот вы бросаете исключение, потом где-то выше по
[01:03:26.740 --> 01:03:33.700]  стеку его ловите, и этот механизм, он для промежуточных вызовов прозрачен опять. Чувствуете некоторую
[01:03:33.700 --> 01:03:40.740]  связь между происходящим до и сейчас? Опять прозрачный механизм для обработки ошибок. Ну,
[01:03:40.740 --> 01:03:45.420]  по поводу того, хорошие исключения или плохие — это отдельная история, сложная. Мы сейчас не хотим
[01:03:45.420 --> 01:03:50.020]  её обсуждать. Ну вот структурное программирование позволяет, в частности, использовать для обработки
[01:03:50.020 --> 01:03:58.020]  ошибок исключения, и рай, то есть деструктора, то есть core-based resource management, позволяет вам
[01:03:58.020 --> 01:04:04.140]  освобождать ресурсы опять же автоматически, когда разворачивается стек, когда летит исключение.
[01:04:04.140 --> 01:04:14.700]  Всё потому, что у вас есть структура. Так, уложилось-то? Вот, а теперь я хочу эти идеи соединить.
[01:04:14.700 --> 01:04:27.120]  Ну, такое синтаксическое наблюдение пока, что Go2 и Go — это похожие штуки. Ну так, вот можно
[01:04:27.120 --> 01:04:30.780]  углядеть в некоторую аналогию между ними, что когда мы говорим Go2, мы куда-то прыгаем, и вот
[01:04:31.260 --> 01:04:36.340]  мы структуру теряем. Когда мы говорим Go, то у нас развилка, мы продолжаем с одной стороны исполняться
[01:04:36.340 --> 01:04:41.020]  прямо, с другой стороны мы запускаем какую-то синхронную операцию, и тоже теряем с ней всякую
[01:04:41.020 --> 01:04:48.580]  связь. У нас теперь две независимые ветки. Вот утверждается, что в этот момент теряется структура,
[01:04:48.580 --> 01:04:58.140]  а структура, разрушенная структура, мешает нам решать задачи. Смотрите, почему мешает. Ну вот,
[01:04:58.140 --> 01:05:11.660]  допустим, допустим, у вас есть в запросе такая развилка. Мы отправляем два под запроса на два
[01:05:11.660 --> 01:05:25.260]  сервиса, и мы хотим дождаться ответов от обоих сервисов. Ну что, если вот при запросе к этому
[01:05:25.260 --> 01:05:39.940]  сервису случилась ошибка? Ну вот, у нас ситуация такая, что нам не нужен теперь ответ второго
[01:05:39.940 --> 01:05:45.980]  сервиса, потому что все, у нас операция провалилась. Мы пока об этом не думали, мы говорили, что либо у нас
[01:05:45.980 --> 01:05:50.860]  сверху снизу поднимаются результаты, либо у нас сверху прилетает cancellation самого верха. На самом
[01:05:50.860 --> 01:05:58.020]  деле все сложнее, потому что у вас есть такой граф, и отсюда прилетают не просто результаты,
[01:05:58.020 --> 01:06:05.780]  отсюда прилетают либо значения, либо ошибки. И вот если отсюда прилетела ошибка, то отмена
[01:06:05.780 --> 01:06:16.020]  операции пойдет не отсюда, а вот отсюда, видимо, должна пойти. То есть, смотрите, если мы в операции
[01:06:16.020 --> 01:06:23.420]  А получили, у нас был форг, мы породили две подзадачи, и из подзадачи мы получили ошибку,
[01:06:23.420 --> 01:06:31.500]  то нам не нужно дождаться операции Б. Это правда.
[01:06:31.500 --> 01:06:52.100]  Давай дорабатывать лекцию во время лекции. Вот, это один сценарий, понятный, да? Что-то пошло не так.
[01:06:52.100 --> 01:06:58.700]  Вот, то есть у нас сигнал отмены родился где-то в корне по дедлайну, а он родился где-то в
[01:06:58.700 --> 01:07:05.020]  промежуточном узле, потому что у нас оператор, комбинатор all разломался. Если мы говорим про first
[01:07:05.020 --> 01:07:15.100]  off, то какой сценарий в нем будет реализован? Нет, нам ошибка, нам, подожди, мы не про ошибки
[01:07:15.100 --> 01:07:23.620]  теперь говорим, мы говорим про результат. Если отсюда поднялся результат, то нам просто второй не
[01:07:23.620 --> 01:07:31.900]  нужен уже. Вот, и теперь смотрите, что получается, что у нас теперь вот этот граф, ну как бы по нему
[01:07:31.900 --> 01:07:39.780]  текут отмены и результаты немного сложнее, не просто сверху вниз или снизу вверх, а они текут вот как бы
[01:07:39.780 --> 01:07:45.580]  сначала снизу, а потом снизу вверх, а потом в разные стороны, то есть наверх течет отмена,
[01:07:45.580 --> 01:07:54.660]  наверх течет ошибка или результат, а вниз отправляется cancellation. Вот то есть граф становится более
[01:07:54.660 --> 01:08:02.820]  сложным, у нас такой сигнал раздваивается. И к чему я клоню? К тому, что вот теперь кажется задача
[01:08:02.820 --> 01:08:10.900]  комбинатора вот это реализовать. А причем здесь structured programming? Structured programming говорит,
[01:08:10.900 --> 01:08:20.180]  что когда вы что-то делаете, как вы выстраиваете поток управления, вы выстраиваете его так,
[01:08:20.180 --> 01:08:25.900]  у вас есть одна точка входа всегда и одна точка выхода, у вас могут быть какие-то форки,
[01:08:25.900 --> 01:08:34.660]  но у вас вы в одном месте зашли, в одном месте вышли, у вас за форком всегда есть join. И вот если у
[01:08:34.660 --> 01:08:42.900]  нас за форком, то есть за двумя параллельными запросами, смотрите, нет, не сюда смотрите,
[01:08:42.900 --> 01:08:52.860]  это мы уже видели, если мы делаем два параллельных запроса, а потом пишем такой код, то если второй
[01:08:52.860 --> 01:09:00.260]  запрос сломается, то мы все равно дождемся первого. Вот этот код и этот код, они выглядят
[01:09:00.260 --> 01:09:09.620]  эквивалентными, но нет, потому что поведение у них может быть разное. Здесь у нас join нет,
[01:09:09.620 --> 01:09:16.860]  а здесь у нас есть точка join, то есть мы разветлились, а потом снова склеились. И вот там, где мы склеились,
[01:09:16.860 --> 01:09:22.940]  это точка, где мы можем получить один из сигналов и сделать вот эту отправку, сделать развилку в
[01:09:22.940 --> 01:09:29.940]  смысле cancellation и ошибки, reconciliation и result. Это та же идея, что и structured programming.
[01:09:29.940 --> 01:09:36.980]  У нас в concurrency теперь как бы ошибка, сейчас запутался, когда мы говорим про structured
[01:09:36.980 --> 01:09:41.980]  programming, у нас когда ошибка летит, она разматывается так, потому что есть просто одна ветка. Теперь у
[01:09:41.980 --> 01:09:48.220]  нас граф сложнее, там есть развилки, но если за развилками есть join, то в этом join ошибка,
[01:09:48.220 --> 01:09:53.380]  прилетев в этот join, может через этот join разветвиться и отправиться с одной стороны дальше,
[01:09:53.380 --> 01:09:59.700]  а с другой стороны отправить отмен. Вот без этого join ничего не выйдет, поэтому основной тезис,
[01:09:59.700 --> 01:10:06.660]  который описан в этой замечательной статье, что оператор Go и вот такой просто асинхронный вызов
[01:10:06.660 --> 01:10:14.340]  чего-то, это плохая идея, потому что за любой развилкой должен быть join. И с фьючами это получается
[01:10:14.340 --> 01:10:21.140]  все довольно элегантно. Вот all, комбинатор all подписывается на две фьючи, и если он из одной
[01:10:21.140 --> 01:10:30.900]  получил ошибку, то он пропагетит ошибку отмену во вторую фьючу. То есть там вот есть в одну
[01:10:30.900 --> 01:10:36.500]  сторону сигнал и в другую сторону сигнал. Ну давайте я даже в коде это покажу. Он, наверное,
[01:10:36.500 --> 01:10:42.860]  плохо написан, ну пожалуйста, не стреляйте в пианиста. Опять я не там.
[01:10:52.140 --> 01:10:56.700]  Вот да, я получил ошибку и я с одной стороны отправляю request-stop, а с
[01:10:56.700 --> 01:11:03.140]  другой стороны говорю с отэррор на верх. Вот эта самая развилка, которая есть в комбинаторе.
[01:11:05.920 --> 01:11:09.660]  При условии, что я вот этот граф сплёл в обе стороны, то я могу вот в обе стороны
[01:11:09.660 --> 01:11:19.780]  все отправлять. Это что касается фьюч, теперь мы хотим... да, и давайте я покажу пример вам.
[01:11:19.780 --> 01:11:37.100]  теперь... Вот, две future, мы запускаем два вычисления в пуле, здесь 10 секунд ждём,
[01:11:37.100 --> 01:11:42.860]  здесь 3 секунды ждём, потом говорим first of и потом дожидаемся, пока всё завершится. То есть,
[01:11:42.860 --> 01:11:48.220]  всё не завершится, пока... Ну, в смысле, пример не завершится, пока не завершатся две операции. И вот
[01:11:48.220 --> 01:11:57.100]  мы теперь готовы это, например, запустить. Видимо, он проработает 3 секунды, а не 10,
[01:11:57.100 --> 01:12:08.940]  потому что там будет автоматическая отмена. Раз, два, три... Сломалось. То есть, мы получили
[01:12:08.940 --> 01:12:21.940]  двойку отсюда и отменили вот эту операцию. И всё это случилось абсолютно прозрачно для пользователей.
[01:12:21.940 --> 01:12:26.220]  Ну, то есть, как бы, конечно, сама операция должна поддерживать отмена, но это уже некоторая
[01:12:26.220 --> 01:12:32.620]  мышленырия. Ну, скажем, кто может продать future? Продать future может RPC Framework. Вот. И, как бы,
[01:12:32.620 --> 01:12:39.020]  пусть он занимается тем этой проверкой этого stopRequested. Вот. В коде всё равно никаких
[01:12:39.020 --> 01:12:44.140]  промесов не бывает, но это вы почувствуете, наверное, осенью, те, кто захочет это почувствовать. Ну,
[01:12:44.140 --> 01:12:49.260]  в коде промесов объективно не бывает. В коде есть только future, и в комбинаторах этих future скрыто
[01:12:49.260 --> 01:12:56.780]  провязывание всех этих токенов, и всё автоматически работает. Что касается файберов, у файберов такой
[01:12:56.780 --> 01:13:01.580]  развилки пока нет. И мы хотим её построить. Эта развилка называется nursery. И вот в статье
[01:13:01.740 --> 01:13:08.620]  про structure concurrency, тут про future ничего нет, поэтому это такой экспромт. Здесь описан объект nursery,
[01:13:08.620 --> 01:13:14.060]  который представляет себе scope файберов. Мы говорим, что если мы файберы запустили,
[01:13:14.060 --> 01:13:21.020]  то мы обязаны его дождаться. Всегда у нас за развилкой должен быть join. И мы пишем объект nursery,
[01:13:21.020 --> 01:13:26.700]  у которого есть операция spawn, которая рождает новый файбер, а ещё есть операция
[01:13:26.700 --> 01:13:44.700]  по порядку. Нет, это есть пример. Пример попроще, секунду. Вот, мы запускаем файберы, и у нас есть
[01:13:44.700 --> 01:13:49.140]  у nursery метод join, который дожидается, пока все файберы завершатся. Этот join должен быть,
[01:13:49.140 --> 01:13:58.500]  потому что вот эта точка, где мы связываем все вот эти развилки, fork, соединяем обратно.
[01:13:58.500 --> 01:14:07.060]  Как устроен этот nursery? У него собственный стоп-токен. Да, и чего мы от него ожидаем? Смотрите,
[01:14:07.060 --> 01:14:18.380]  мы, зачем он нам нужен? Ради чего всё? Вот мы запустили два файбера. Один работает бесконечно,
[01:14:18.460 --> 01:14:28.820]  а другой ломается через две секунды. И когда первый сломается, мы хотим, чтобы отменился второй.
[01:14:28.820 --> 01:14:35.260]  Вот ровно поэтому мы связали их в scope, и поэтому мы требуем, чтобы за каждым
[01:14:35.260 --> 01:14:42.580]  spawn был join дальше. То есть мы всегда дожидаемся всех файберов, которые мы запускаем. Это такое
[01:14:42.580 --> 01:14:48.700]  ограничение, которое мы вносим в нашу программу. И за счет этого ограничения мы получаем прозрачную
[01:14:48.700 --> 01:14:55.620]  отмена. Как это работает? Ну вот допустим, да, у каждого файбера, я показывал вам этот код уже,
[01:14:55.620 --> 01:15:02.700]  у каждого файбера при старте есть супервизор. Супервизор — это некто, кто понимает, что с
[01:15:02.700 --> 01:15:10.540]  файбером произошло. Файбер успешно завершился, файбер отменился, файбер разломался. Когда вы
[01:15:10.540 --> 01:15:17.020]  запускаете файбер, то если он разломался, то вы сообщаете об этом супервизору. А супервизор в случае
[01:15:17.020 --> 01:15:27.700]  nursery — это nursery. Тупое предложение, извиняюсь. И вот смотрите, когда на nursery, ну когда вы
[01:15:27.700 --> 01:15:33.740]  вызываете spawn файбера, то вы стартуете новый файбер в качестве супервизора и передаете себя и
[01:15:33.740 --> 01:15:43.940]  передаете stop токен этого nursery. Вот nursery является stop source, он порождает токены. И если вдруг в этом
[01:15:43.940 --> 01:15:54.860]  nursery разломался файбер, то мы говорим stop source, stop request, stop. И все остальные файберы этого nursery,
[01:15:54.860 --> 01:16:01.060]  которые получили этот токен, они отменяются. Вот опять та же идея, если у нас есть развилка,
[01:16:01.060 --> 01:16:09.220]  у нас должен быть join и вот nursery это обеспечивает. Вот таким образом мы можем, получается, опять
[01:16:09.220 --> 01:16:20.100]  прозрачно выполнять отмену двух расправильных операций. Ну или можно какие-то дикие комбинации
[01:16:20.100 --> 01:16:26.740]  написать. Я вот написал, это выглядит жутко, но ужасный код, но дело не в этом. Смотрите, у меня
[01:16:26.740 --> 01:16:35.380]  есть некий файбер и он есть, ну как бы есть планировщик, полпоток. Я бросаю в него какую-то
[01:16:35.380 --> 01:16:44.460]  операцию, которая бесконечно крутится. Я подвязываю к фьюче этой операции какое-то продолжение,
[01:16:44.460 --> 01:16:55.180]  потом я строю nursery, в нем запускаю два файбера и в одном из них я жду этой фьючи. Ну то есть
[01:16:55.500 --> 01:17:02.940]  какой-то сложный граф плетется бессмысленный. А дальше я говорю nursery cancel и что происходит?
[01:17:02.940 --> 01:17:10.620]  nursery cancel cancelит stop-token. Этот stop-token связан со stop-token. Когда я говорю await, то есть синхронно
[01:17:10.620 --> 01:17:28.820]  дожидаюсь фьючи. Что я делаю? Я, да, когда я дожидаюсь фьючи, вот здесь, то я связываю
[01:17:28.820 --> 01:17:37.780]  token fiber и token future, чтобы когда файбер решит отмениться, он поканцелял бы фьючу. А в этом
[01:17:37.780 --> 01:17:44.180]  зене связывается token future f2 с token future f1. Token future f1 проявляется в итоге здесь. И когда
[01:17:44.180 --> 01:17:50.740]  я говорю cancel на nursery, то отменяется, во-первых, файбер в этом nursery. Этот файбер отменяет,
[01:17:50.740 --> 01:18:01.380]  ну как бы в stop-token файбера появляется единичка, поэтому он завершится. А кроме того,
[01:18:01.380 --> 01:18:08.980]  он прокидывает единичку в stop-token f2, она прокидывает через этот зен stop-token в f1,
[01:18:08.980 --> 01:18:14.500]  и вот снизу вверх всё отменяется, и этот пример завершается. Вот довольно удивительно,
[01:18:14.500 --> 01:18:25.700]  что это работает, но можно в этом убедиться. Вот, и этот пример убеждает меня, что происходит
[01:18:25.700 --> 01:18:32.300]  нечто разумное. Честно говоря, долго я над этим думал, над всем, но кажется, что вот то,
[01:18:32.300 --> 01:18:41.260]  что придумалось, оно похоже на правду. Вот оно как-то гармонично сочетается, и всё вот. Вот есть
[01:18:41.260 --> 01:18:45.580]  многие технические детали, как это сделать быстро, потому что сейчас это работает неэффективно
[01:18:45.580 --> 01:18:51.420]  в разных местах. Как там с циклическими зависимостими аккуратно разобраться. Но это
[01:18:51.420 --> 01:18:55.820]  всё проблема, которая выглядит, честно говоря, решаемыми скорее. А вот фундаментально принцип
[01:18:55.820 --> 01:19:05.620]  такой вот, что мы строим два графа в разные стороны, и вот учимся... Ну, мы, когда говорим про граф
[01:19:05.620 --> 01:19:12.260]  асинхронных вычислений, мы должны понимать, что по нему текут два типа сигналов. Ошибки,
[01:19:12.260 --> 01:19:18.700]  результат, ошибки или значения снизу вверх и consolation сверху вниз. И что вообще-то они текут
[01:19:18.700 --> 01:19:25.100]  не просто сверху вниз, с самого верха вниз и с самого низу вверх, а что они могут как-то вот течь,
[01:19:25.100 --> 01:19:31.460]  вот как-то так, ну сложно представить себе, как это происходит. Но если за каждой развилкой в вашем
[01:19:31.460 --> 01:19:38.140]  коде есть join в виде nursery или в виде комбинатора, то мы гарантируем, что где бы ошибка не возникла,
[01:19:38.140 --> 01:19:45.060]  она запропагетится на весь граф. Это такое очень мощное свойство, которое... И вот в этом состоит
[01:19:45.060 --> 01:19:51.260]  идея structured concurrency, которая из этой статьи мне совершенно не прочиталась, но через некоторое
[01:19:51.260 --> 01:19:56.620]  время она ко мне независимо пришла, но вот ровно об этом здесь человек и говорит. Вот он просто
[01:19:56.620 --> 01:20:03.460]  говорит только про... Не говорит про future, но вот на future все это тоже обобщается. Если у вас за
[01:20:03.460 --> 01:20:10.660]  любой развилкой есть join, то вы можете гарантировать такие простые варианты, что все отменится. По этому
[01:20:10.660 --> 01:20:19.980]  графу любой сигнал может эффективно распространиться. И что самое приятное, абсолютно прозрачно для
[01:20:19.980 --> 01:20:25.420]  пользователя. То есть вы просто пишете код, потом в одном месте у вас что-то ломается, просто exception
[01:20:25.420 --> 01:20:33.940]  бросается в ваш, а дальше все магически, автомагически отменяется, пропагетится и ресурсы
[01:20:33.940 --> 01:20:40.460]  освобождаются. Вот без этого production code представить сложно, ну потому что ресурсы, значит, мы копились
[01:20:40.460 --> 01:20:46.220]  тогда. Где-то что-то потерялось, какой-то файбер бесконечно крутится, все, у вас утекает память. Вот
[01:20:46.220 --> 01:20:54.020]  поддерживая такой вариант, ограничивая себя, то есть запретив себя вот этот go и заставив писать
[01:20:54.020 --> 01:20:59.100]  явно join, что выглядит немного противоестественным поначалу, вы можете достичь такого очень мощного
[01:20:59.100 --> 01:21:08.220]  свойства в своем коде. Ну вот, на этой радостной ноте, я надеюсь, мы заканчиваем новые темы в
[01:21:08.220 --> 01:21:13.180]  нашем семестре, и я вас приглашаю обязательно приходить на следующую лекцию. Мы с вами через
[01:21:13.180 --> 01:21:20.940]  неделю поговорим про вот все вместе, выстроим одну, надеюсь, общую картину, ну и я с удовольствием
[01:21:20.940 --> 01:21:24.940]  отвечу на ваши вопросы, которые у вас после курса останутся. Спасибо.
