[00:00.000 --> 00:12.640]  Итак добрый день, мы с вами в прошлый раз доказали теорему о существовании жардановой
[00:12.640 --> 00:22.000]  нормальной формы. Сегодня мы докажем через некоторое время ее единственность, тем самым
[00:22.000 --> 00:31.840]  завершив доказательства о теореме о жардановой форме целиком, но перед этим нам это и впоследствии
[00:31.840 --> 00:42.040]  будет полезным, давайте мы приведем другой более конструктивный способ нахождения жарданового
[00:42.040 --> 00:49.080]  базиса для нерпатентного оператора. Я еще раз напоминаю, что мы при построении вот этой жардановой
[00:49.080 --> 00:59.760]  формы сначала разбили все пространство на прямую сумму корневых подпространств,
[00:59.760 --> 01:11.240]  ну а затем на каждом корневом подпространстве мы уже рассматриваем на В лямдоитом, я напоминаю,
[01:11.240 --> 01:20.000]  мы рассматриваем оператор phi лямдоита, ограниченный на вот это вот самое подпространство,
[01:20.000 --> 01:27.920]  ну phi лямдоита, это напоминаю phi минус лямдоита, он нерпатентен и с ним мы уже
[01:27.920 --> 01:38.120]  работаем чтобы найти жарданов в базис в этом пространстве. Так вот этот самый алгоритм можно
[01:38.200 --> 01:49.480]  оформить, можно сделать по-другому и мы сейчас это сделаем. Итак наша исходная ситуация опять же
[01:49.480 --> 02:06.880]  таки пусть psi это нерпатентный оператор на пространстве В, мы собираемся искать для него
[02:06.880 --> 02:20.000]  жарданов базис, ну и заодно мы кстати с вами увидим насколько много этих базисов будет,
[02:20.000 --> 02:28.080]  значит давайте я сразу вот эту вот часть доски зарезервирую для картинки и рекомендую вам тоже
[02:28.080 --> 02:34.120]  оставить некоторое место для большой картинки которая постепенно будет уточняться, то есть
[02:34.120 --> 02:44.160]  места должно быть достаточно. Итак давайте мы будем разбивать наше пространство на некоторые
[02:44.160 --> 02:51.080]  части, разбивать его в прямую сумму нескольких подпространства, после этого увидим что из этого
[02:51.080 --> 03:01.560]  возникает. Итак шаг первый очень простой, мы с вами знаем что psi нерпатентный оператор,
[03:01.560 --> 03:17.240]  во всяком случае он вырожденный, вот давайте мы обозначим через V1 ядро psi, через V2 ядро
[03:17.240 --> 03:29.480]  psi квадрата и так далее, через Vkt мы обозначим ядро psi вкатый, ну и давайте мы будем считать что
[03:29.480 --> 03:36.960]  k это как говорят индекс нерпатентности нашего оператора, то есть k это наименьшее число,
[03:36.960 --> 03:45.320]  наименьшая степень в которой psi уже обращается в ноль, ну и таким образом Vkt это у нас уже все V.
[03:45.320 --> 03:57.800]  Ну тогда естественно V1 это какое-то подпространство V2, если вектор обнуляется
[03:57.800 --> 04:03.920]  psi, то он естественно обнуляется и psi квадратом тоже, правильно? V2 подпространство аналогичным
[04:03.920 --> 04:13.160]  образом V3 и так далее, это подпространство Vkt. И вот первую грубую схему я уже могу нарисовать,
[04:13.160 --> 04:20.760]  давайте мы будем рисовать по уровням, я сейчас объясню почему, на нижнем уровне мы нарисуем V1,
[04:20.760 --> 04:29.160]  V1 плюс некоторая надстройка, вот все это, значит вот это вот у нас V1, вот все это,
[04:29.160 --> 04:39.880]  это у нас будет V2 и так далее, вот у нас kt уровень, все наше пространство это Vkt,
[04:40.000 --> 04:48.680]  которое равно V. Почему я рисую вот таким вот образом? Ну потому что у нас есть с вами понятие
[04:48.680 --> 05:03.600]  высоты вектора, правильно? То есть каждый вектор, напоминаю, высоты и, скажем, если он обнуляется
[05:03.600 --> 05:18.120]  psi в степени i и еще не обнуляется psi в i-1. Так вот тогда у нас на первом уровне V1 будет
[05:18.120 --> 05:25.760]  состоять из векторов высоты 1, ну плюс нулевой вектор, в принципе мы можем нулевой вектор
[05:25.760 --> 05:32.400]  расположить на самом нижнем уровне, потому что мы можем сказать, что это ядро psi в нулевой
[05:32.400 --> 05:44.160]  степени, правильно? Можно сказать, что 0 это V0. Вот, итак, на первом уровне у нас будут находиться
[05:44.160 --> 05:52.440]  векторы высоты 1, V2 ядро psi квадрата, это векторы высоты 1 и 2, правильно? И вот то, что у нас здесь
[05:52.440 --> 05:58.160]  добавилось, это как раз векторы высоты 2, V3 это векторы высоты не больше, чем 3 и так далее.
[05:58.160 --> 06:09.280]  Вот, теперь мы начинаем выделять хорошие прямые слагаемые. Поскольку Vk-1, давайте я его здесь даже
[06:09.280 --> 06:17.400]  выделю, Vk-1 это пространство векатом, у нас существует его прямое дополнение векатом,
[06:17.400 --> 06:29.360]  значит, то есть мы можем разложить Vkt в прямую сумму Vk-1 и некоторого подпространства,
[06:29.360 --> 06:38.320]  некоторого его прямого дополнения, которое мы назовем ukat. Вот давайте я здесь выделю
[06:38.320 --> 06:47.160]  подпространство ukat, еще раз на всякий случай сообщаю, это не все векторы высоты k, это только
[06:47.160 --> 06:54.760]  прямое дополнение, тут на этом уровне, в принципе, есть еще много векторов, правильно? И давайте мы
[06:54.760 --> 07:05.680]  сразу обговорим немного свойств этого самого ukat. Важное свойство этого подпространства такое,
[07:05.680 --> 07:24.920]  значит, все, извините, не нулевые векторы в ukat имеют высоту, а какую они высоту имеют?
[07:24.920 --> 07:33.040]  Меньше либо равно k, это мы знаем, потому что все векторы имеют высоту меньше либо равно k,
[07:33.040 --> 07:44.000]  правильно? Но они не могут иметь высоту меньше, чем k, потому что иначе бы они лежали в Vk-1,
[07:44.000 --> 07:55.960]  эти два подпространства пересекаются только по нулевому вектору. Значит, все не нулевые векторы
[07:56.560 --> 08:18.200]  имеют высоту ровно k, еще раз, поскольку они не лежат в Vk-1. Что из этого следует? Из этого,
[08:18.200 --> 08:28.600]  в частности, следует, значит, если только k больше единицы, если k было бы равно единице,
[08:28.600 --> 08:40.440]  то мы бы, наверное, уже с вами закончили, если k больше единицы, то ukat в пересечении с ядром
[08:40.440 --> 08:55.880]  psi, то же самое, что ukat в пересечении с V1, это 0, то есть ни один вектор из ukat не обнуляется
[08:55.880 --> 09:11.280]  нашим psi, а это означает, что psi, ограниченное на ukat, это инъекция, это инъективный гомоморфизм,
[09:11.280 --> 09:17.360]  извините, инъективное линейное отображение, его часто называют гомоморфизмом линейных
[09:17.360 --> 09:25.880]  пространств, поэтому моя оговорка, в принципе, имеет право на жизнь. Это инъекция, ну и мы с вами,
[09:25.880 --> 09:35.200]  в частности, знаем, напоминаю, что при инъективном линейном отображении линейно-независимые
[09:35.200 --> 09:41.720]  системы векторов переходят в линейно-независимую систему векторов. Это у нас инъекция и
[09:42.280 --> 09:54.160]  линейно-независимая система, и вот это отображение, линейно-независимую систему, оно всегда переводит
[09:54.160 --> 10:04.600]  в линейно-независимую. Это первое свойство, которое нам сейчас потребуется, а второе свойство,
[10:04.960 --> 10:16.680]  которое нам потребуется, вот какое. Давайте мы посмотрим на psi от укатого. Нет, это не получится
[10:16.680 --> 10:23.920]  ука минус первым, ука минус первым мы хотим сделать нечто, возможно, большее. Но давайте мы
[10:23.920 --> 10:31.240]  посмотрим, что это такое. Все векторы в укатом имеют высоту ровно k, кроме нулевого, правильно?
[10:31.240 --> 10:41.440]  Все векторы здесь будут иметь высоту ровно k-1, правильно? Те векторы переходили в 0 лишь при
[10:41.440 --> 10:49.480]  кократном применении psi. Один раз мы уже применили, осталось k-1, правильно? psi от укатого,
[10:49.480 --> 11:07.280]  ну давайте я его как-нибудь обозначу wkt, в нем все векторы высоты ровно k-1, ну то есть,
[11:07.280 --> 11:18.000]  в частности, давайте я, извините, немножко, ну хотя пусть будет так, высоты ровно k-1, то есть,
[11:18.000 --> 11:28.640]  это подпространство пересекается с vk-2 лишь по нулю. vk-2 состоит из векторов высоты не больше,
[11:28.640 --> 11:41.280]  чем k-2, правильно? Вот, давайте я его здесь нарисую. Вот эти укаты переходят в векторы
[11:41.280 --> 11:53.280]  подпространства wk-2, и все это подпространство лежит именно на k-1 уровне. Ну теперь мы можем
[11:53.280 --> 12:08.400]  продолжить нашу процедуру. Глядите, мы говорим, что в vk-1 есть два непересекающихся подпространства,
[12:08.400 --> 12:26.760]  а именно vk-2 и вот эта вот получившаяся wk-2. Значит, существует прямое дополнение к vk-2,
[12:26.760 --> 12:45.520]  содержащее это самое wk. То есть vk-1 мы можем разложить как vk-2 прямая сумма с uk-1,
[12:45.520 --> 13:02.840]  где uk-1 содержит wk. Вот у нас есть wk, и соответственно мы его дополняем до uk-1.
[13:02.840 --> 13:11.120]  На всякий случай давайте я поясню, почему такое подпространство uk-1 существует. Для
[13:11.120 --> 13:19.000]  этого достаточно сделать вот какую вещь. Мы с вами знаем, что vk-2 и wk-2 образуют прямую сумму,
[13:19.000 --> 13:34.200]  правильно? То есть у нас есть в vk-1 прямая сумма vk-2 и wk-2, но значит мы можем vk-1 разложить вот в
[13:34.200 --> 13:41.440]  какую прямую сумму vk-2 плюс wk и к этому подпространству найти прямое дополнение,
[13:41.440 --> 13:56.520]  плюс еще какой-то x. И вот это вот самое у нас и будет uk-1. Вот теперь мы можем продолжить
[13:56.760 --> 14:16.120]  наше рассуждение. Давайте поймем, как выглядит, то есть далее мы действуем также. То есть давайте
[14:16.120 --> 14:25.560]  я на всякий случай опишу общий шаг, чтобы мы видели то, как это происходит. Если на некотором шаге
[14:25.720 --> 14:34.600]  у нас уже получилось, что v it разложилось в прямую сумму v i-1 и какого-то u it,
[14:34.600 --> 14:54.600]  где u it содержит пришедшая сверху w i плюс 1, то повторяем те же самые рассуждения. Все
[14:54.640 --> 15:07.800]  векторы в u it имеют высоту ровно i. По тем же самым причинам они не лежат в v i-1,
[15:07.800 --> 15:17.560]  но все не нулевые векторы, правильно? Все не нулевые векторы в u it имеют высоту i. Если,
[15:17.560 --> 15:24.360]  опять же, такие i больше 1, если i равно 1, то v i-1 это уже 0 и мы можем считать,
[15:24.360 --> 15:37.520]  что мы закончили. Если и больше 1, то, опять же, мы можем в качестве psi от u it взять w it,
[15:37.520 --> 15:52.520]  которое под пространство v i-1. Все векторы w it имеют высоту ровно i-1. Все векторы не нулевые,
[15:52.520 --> 16:12.800]  как обычно, в w it имеют высоту i-1. То есть w it пересекается с v i-2. Опять же,
[16:13.400 --> 16:24.040]  раз они имеют высоту i-1, то пересекаются только по 0. Ну и тогда мы можем аналогичным образом
[16:24.040 --> 16:37.440]  v i-1 разложить в прямую сумму v i-2 и какого-то u i-1, где u i-1 содержит w it. Вот такой вот шаг
[16:37.560 --> 16:47.600]  индукции у нас происходит. Мне осталось сказать только одно ключевое соображение, после которого
[16:47.600 --> 16:59.600]  мы будем готовы выбирать базисы. При этом давайте посмотрим, например, на исходном рисунке,
[16:59.600 --> 17:10.760]  как связаны размерности u k-2 и w k-2. w k-2 это psi от u k-2. Вообще говоря, это означает, что размерность
[17:10.760 --> 17:19.200]  w k-2 не больше, чем размерность u k-2. Но у нас инъекция и линейно-независимые системы переходят
[17:19.200 --> 17:26.480]  линейно-независимые, поэтому размерности их равны. И то же самое происходит здесь, опять же,
[17:26.480 --> 17:36.520]  если и больше единицы, то psi, ограниченная на u it, это инъекция, и поэтому размерность w it
[17:36.520 --> 17:50.360]  равна размерности u it. Осталось выбрать Жарданов базис, и мы уже совсем готовы к тому, чтобы это
[17:50.360 --> 17:58.600]  сделать. Давайте я первые два шага и последние нарисую. У нас есть u k-2, здесь есть подпространство
[17:58.600 --> 18:09.400]  w k-2. Его поглотило подпространство u k-1, которое при действии psi переходит в w k-1. Здесь у нас
[18:09.400 --> 18:16.440]  расположено подпространство u k-2 и так далее. Здесь у нас в результате получается такая ситуация,
[18:16.920 --> 18:28.480]  что здесь у нас u k-2, которое перешло в w k-2, содержащиеся уже в v k-1, и его поглотило
[18:28.480 --> 18:42.560]  подпространство u k-1. На самом деле, конечно же, u k-1 у нас будет равно, что такое будет u k-1. Давайте
[18:42.560 --> 19:03.200]  посмотрим внимательно вот на эту формулу. Нет, у первой же содержит w 2. Это v 1. У первой
[19:03.200 --> 19:11.600]  совпадает совсем v 1. Это прямое дополнение v 0 в v 1, но v 0 это 0. Поэтому у первой, конечно же,
[19:11.600 --> 19:25.280]  равно v 1. Вот так, если бы у меня был цветной мел, все бы было гораздо лучше, но его у меня нету.
[19:25.280 --> 19:37.400]  Поэтому давайте я сейчас эти буковки все напишу снова, но вне наших. Итак, здесь у нас u k-2,
[19:37.400 --> 19:50.280]  здесь у нас нарисовано w k-2, и оно содержится в u k-1, здесь у нас w k-1, и оно содержится в u k-2,
[19:50.280 --> 20:05.800]  и так далее. Здесь у нас u 2, это u 1, которое равно v 1. Итак, построим Жарданов базис. Сейчас
[20:05.800 --> 20:18.640]  мы увидим все эти цепочки. Жарданов базис мы строим с самого верху до самого низу. Итак,
[20:18.640 --> 20:29.480]  выберем какой-то базис в u k-1. Давайте мы его так назовем u 1 с индексом k, и так далее,
[20:29.480 --> 20:51.160]  u с индексом k, но давайте я напишу n k-t. Базис в u k-t. Вот они, u 1 k, и так далее, u n k-t с индексом k.
[20:51.160 --> 21:03.720]  Посмотрим, что будет, если мы на них подействуем нашим psi. Они будут переходить в какие-то векторы
[21:03.720 --> 21:20.600]  из w k-2. Давайте мы сразу скажем, что это u 1 k-1, и так далее, u n k-t k-1. u it k-1 мы полагаем
[21:20.600 --> 21:39.200]  просто psi от u it k-t. Это векторы из w k-t, которые линейно-независимы. Мы с вами знаем,
[21:39.200 --> 21:45.960]  что psi действует на u k-t инъективно, то есть линейно-независимую систему она переводит в
[21:45.960 --> 21:58.600]  линейно-независимую. Образующая базис там. Эти векторы, конечно, образуют базис в w k-t.
[21:58.600 --> 22:17.600]  Дополним его до базиса в u k-1. u 1 k-1, и так далее, u k-1 уже с индексом n k-1.
[22:17.600 --> 22:34.040]  Если здесь еще что-то есть, то мы дополняем векторы, то мы дополняем базис w k-1 до базиса u k-1.
[22:34.040 --> 22:42.960]  Здесь будет u k-1, извините, с индексом n k-t плюс 1. Вот здесь будет последний вектор,
[22:42.960 --> 22:52.240]  его называем мы u с верхним индексом k-1 с нижним индексом n k-1. Ну и дальше продолжаем так дальше.
[22:52.240 --> 23:03.240]  Берем образы этих векторов. Уже всех вот этих вот векторов они линейно-независимы и образуют
[23:03.240 --> 23:25.160]  базис в следующем w. Их образы. Эта базис w уже k-1. Дополняем его до базиса в w,
[23:25.160 --> 23:39.600]  в, извините, u k-2. u 1 k-2, и так далее, u k-2 уже с индексом n k-2. Их может стать больше, правильно?
[23:39.600 --> 23:46.600]  Мы их дополняем еще какими-то векторами до базиса в следующем пространстве и продолжаем процедуру.
[23:46.600 --> 23:58.760]  Что у нас будет в конце? Вот у нас какие-то векторы образуют базис у второго. Их образы
[23:58.760 --> 24:21.360]  образуют базис в w втором. И его мы дополняем до базиса в u первом. Пока не найдем базис,
[24:21.360 --> 24:40.160]  давайте мы его тоже выпишем u 1 1, и так далее, u n первое 1 в u первом. Вот мы его нашли u 1 1, u n первое 1.
[24:40.160 --> 25:00.040]  Давайте мы будем понимать, что у нас произошло. Давайте сразу поймем, как разложилось все наше
[25:00.040 --> 25:18.240]  пространство, кстати. Мы с вами знаем, что пространство w, оно же w k-2, разложилось в прямую сумму u k-2 и w k-1.
[25:18.240 --> 25:35.760]  W k-1 в свою очередь разложилось в прямую сумму u k-1 и w k-2 и так далее. Когда мы дойдем до конца,
[25:35.760 --> 25:48.560]  мы получим здесь прямую сумму от u k-2 до u 1, ну и плюс w 0, которое 0 пространство, его можно и не брать.
[25:48.560 --> 25:57.320]  u k-2 плюс и так далее, плюс u 1. Итак, наше пространство разложилось в прямую сумму вот этих вот ушек.
[25:57.320 --> 26:12.320]  В каждом из ушек мы выбрали базис, и поэтому у нас получился, если мы объединим все базисы, которые мы получим, то мы получим базис всего пространства.
[26:12.320 --> 26:37.320]  Итак, поскольку вот такое прямое разложение у нас есть, объединение полученных базисов – это базис всего пространства.
[26:37.320 --> 26:52.320]  А с другой стороны, глядите, что у нас получилось. Весь этот базис, вот смотрим на картинку, давайте смотреть на нее теперь по вертикали, весь этот базис разбивается на жардановой цепочке.
[26:52.320 --> 27:07.320]  Каждый столбец на нашей картинке, некоторые столбцы начинаются с самого верхнего уровня, некоторые с предыдущего уровня, некоторые еще с предыдущего и так далее.
[27:07.320 --> 27:30.320]  Каждый столбец на этой картинке образует жардановую цепочку, правильно? С другой стороны, каждый столбец – это жардановая цепочка.
[27:30.320 --> 27:57.320]  Если этот столбец начинается на каком-то и-том уровне с вектора у ж с индексом i, то он под действием psi переходит в житый же вектор, но на i-1 уровне, и так далее, пока не дойдет до житого же вектора уже на первом уровне,
[27:57.320 --> 28:05.320]  ну и этот под воздействием psi уже переходит в ноль, потому что на первом уровне у нас стоят векторы высоты 1.
[28:05.320 --> 28:14.320]  Ну, значит, это не часть жардановой цепочки, часть жардановой цепочки, вот она у нас. Жарданова цепочка, вот она.
[28:14.320 --> 28:26.320]  Значит, у нас получился базис, который разбивается на жардановой цепочке. Ну и значит, это и есть жарданов базис, если его правильно упорядочить.
[28:26.320 --> 28:49.320]  Упорядочивая его по вертикали, получаем жарданов базис. Что значит упорядочивая по вертикали? Давайте понимать.
[28:49.320 --> 28:59.320]  Ну, это означает, что вот у нас первая жарданова цепочка. Как мы ее должны упорядочить, чтобы получилась часть жарданова базиса?
[28:59.320 --> 29:15.320]  Не верно. Мы помним, что в жардановой цепочке у нас откатого до первого они идут, правильно?
[29:15.320 --> 29:30.320]  Поэтому упорядочивать их надо снизу вверх. То есть этот базис, давайте я скажу, начинается так.
[29:30.320 --> 29:51.320]  Мы идем по первому столбцу снизу вверх. У1-1, у1-2 и так далее, у1-k. Вот у нас первая жарданова цепочка, она нам даст первую жарданову клетку в матрице нашего оператора, правильно?
[29:51.320 --> 30:12.320]  Первый вектор в клетке обязательно является собственным, правильно? Потом будет у2-1 и так далее. Ну, докуда уж он дойдет, да? У2 что-то там, потому что здесь не обязательно будет k, здесь уже может быть что-то поменьше, правильно?
[30:12.320 --> 30:32.320]  И так далее. То есть вот в таком порядке мы упорядочиваем по столбцам, в каждом столбце снизу вверх. И в результате мы получаем уже жарданов базис. Вот такой более конструктивный метод его построения.
[30:32.320 --> 30:52.320]  Так, вот таким образом мы доказали еще раз, даже вот более-менее конструктивной процедурой, что мы умеем любой нельпатентный оператор приводить к жардановой форме.
[30:52.320 --> 31:05.320]  Ну и значит еще раз доказали существование жардановой формы для нельпатентного оператора. Ну отсюда следует, напоминаю, и существование этой самой формы для произвольного оператора.
[31:05.320 --> 31:25.320]  Так, ну и на самом деле вот сейчас нам эта картинка, эта визуализация поможет и в доказательстве единственности жардановой формы, которой мы сейчас приступаем.
[31:25.320 --> 31:52.320]  Итак, давайте мы будем разбираться с единственностью жардановой формы.
[31:52.320 --> 32:12.320]  Пусть у нас характеристический многочлен нашего преобразования фи, как обычно раскладывается в произведении линейных собножителей.
[32:12.320 --> 32:22.320]  Какими-то показателями альфа, итыми.
[32:22.320 --> 32:45.320]  Тогда давайте мы сразу заметим в любой жардановой матрице оператора фи,
[32:45.320 --> 32:54.320]  если мы только фи в каком-то базисе привели к жардановому виду,
[32:54.320 --> 33:20.320]  в любую жардановую матрицу оператора фи на диагонали будет стоять ровно альфа итая,
[33:20.320 --> 33:29.320]  то есть это экземпляров собственного значения лямда итого.
[33:29.320 --> 33:31.320]  Почему это так?
[33:31.320 --> 33:37.320]  Эта матрица, мы с вами уже говорили об этом, эта матрица верхнетреугольная, правильно?
[33:37.320 --> 33:45.320]  Ну просто потому что она блокно-диагональная, и каждый блок, каждая жардановая клетка является верхнетреугольной матрицей.
[33:45.320 --> 34:01.320]  Раз она, давайте мы скажем, действительно эта матрица верхнетреугольная,
[34:01.320 --> 34:13.320]  ну и поэтому ее собственное значение написано у нее на диагонали, правильно?
[34:13.320 --> 34:21.320]  Ровно с их, какими кратностями? Разумеется, алгебраическими, правильно?
[34:21.320 --> 34:27.320]  Потому что мы у такой вот верхнетреугольной матрицы знаем, как выглядит характеристический многочлен.
[34:27.320 --> 34:32.320]  Просто произведение соответствующих мономов.
[34:32.320 --> 34:52.320]  И эта матрица верхнетреугольная, и диагональ ее, ну главная диагональ, естественно, содержит ровно собственное значение с их алгебраическими кратностями.
[34:57.320 --> 35:21.320]  Так, далее, давайте мы для какого-нибудь, так эту картинку я стирать пока не собираюсь, чтобы геометрическую интуицию в некоторый момент из нее извлечь.
[35:21.320 --> 35:40.320]  Так, значит, мы с вами, если мы хотим понять, какая ЖНФ может быть у оператора ФИ, мы уже знаем, сколько раз стоят лямбда ИТ на диагонали.
[35:40.320 --> 36:05.320]  При этом, давайте мы, скажем, выберем какую-нибудь лямбда ИТ, и переставим клетки так, давайте я даже это запишу отдельно.
[36:05.320 --> 36:34.320]  Давайте мы выберем какую-нибудь лямбда ИТ, то есть выберем некоторые И, и переставим клетки так, чтобы в начале шли клетки ровно с этим лямбда ИТ.
[36:34.320 --> 36:45.320]  Но мы с вами знаем, что в Жардановой матрице клетки можно спокойно переставлять, это соответствует просто перестановке векторов Жарданова базиса, правильно?
[36:46.320 --> 37:02.320]  Итак, мы переставим клетки вот таким вот образом, ну и рассмотрим соответствующий фрагмент базиса.
[37:02.320 --> 37:10.320]  Эти клетки будут иметь суммарный размер ровно альфа ИТ, мы это с вами только что уже сказали, правильно?
[37:10.320 --> 37:30.320]  Значит, то есть первые альфа ИТ векторов будут отвечать как бы за эти клетки, соответственно фрагмент базиса, соответствующий этим клеткам.
[37:30.320 --> 37:43.320]  Ну и давайте мы сразу обозначим через УИТ подпространство, порожденное этим самым фрагментом.
[37:43.320 --> 38:03.320]  Тогда видите, что происходит, эти векторы образуют по сути дела несколько Жардановых цепочек, то есть фи лямбда ИТ,
[38:03.320 --> 38:23.320]  то есть оператор фи минус лямбда ИТ, так, извините, давайте вот так писать нехорошо, просто оператор фи лямбда ИТ, ограниченный на это УИТ, будет нелепотентным.
[38:23.320 --> 38:48.320]  То есть его матрица в нашем базисе будет иметь вот какой вид, это будет несколько Жардановых клеток собственным значением 0, правильно?
[38:48.320 --> 39:00.320]  Например, у исходных клеток на диагонали стояла лямбда ИТ, когда мы эту лямбда ИТ вычли, у нас там будет несколько клеток собственным значением 0,
[39:00.320 --> 39:14.320]  ну и если мы начнем эту матрицу возводить в степени, клетки тоже начнут возводиться в соответствующей степени, и поэтому рано или поздно они все обнулятся.
[39:18.320 --> 39:40.320]  А вывод из всего этого такой, давайте я уж завершу какую-то часть рассуждения, а потом мы с вами уйдем на перерыв.
[39:40.320 --> 40:00.320]  Это значит, ну можно было бы это по-другому сказать и непосредственно, это значит, что все векторы вот этого вот, все векторы вот этого вот самого подпространства лежат в корневом подпространстве,
[40:00.320 --> 40:20.320]  соответствующем лямбда ИТ. УИТ содержится в лямбда ИТ. Каждый вектор УИТ обнуляется некоторой степенью ПСИ лямбда ИТ. ФИ лямбда ИТ, извините, да?
[40:20.320 --> 40:36.320]  Каждый вектор УИТ обнуляется некоторой степенью ФИ лямбда ИТ, а корневое подпространство как раз и состоит из всех векторов, которые обнуляются некоторой степенью ФИ лямбда ИТ.
[40:36.320 --> 41:05.320]  Ну, кроме того, давайте мы вспомним. Вот если мы такое подпространство УИТ соорудим для каждого собственного значения лямбда ИТ, то мы с вами сразу поймем, что В это прямая сумма наших подпространств У1 и так далее, Укатова.
[41:05.320 --> 41:18.320]  Потому что вот у нас есть Жарданов базис, в котором наши ФИ имеют Жарданову матрицу, правильно? Каждый вектор этого базиса мы засунули в одно из подпространств УИТ, правильно?
[41:19.320 --> 41:31.320]  Собственно, мы разбили их на несколько кусков, каждый кусок порождает подпространство УИТ. Раз объединение базисов вот этих подпространств это базис В, то у нас есть такая прямая сумма.
[41:31.320 --> 41:37.320]  Ну а с другой стороны мы знаем, что В разбивается в прямую сумму корневых подпространств.
[41:43.320 --> 41:56.320]  Ну, поскольку каждый из этих подпространств садируется в соответствующем слагаемом справа, такое равенство может выполняться только в одном случае, когда каждое УИТ совпадает с В лямбда ИТ, правильно?
[41:57.320 --> 42:14.320]  Если бы какое-то включение было строгим, если бы какое-то УИТ было меньше, чем все В лямбда ИТ, то просто сумма размерностей вот этих подпространств была бы меньше, чем сумма размерностей вот этих подпространств, а обе суммы должны быть равны В.
[42:14.320 --> 42:43.320]  Значит, каждое УИТ и есть В лямбда ИТ, ну и за одно внимание мы получили полезный факт, что размерность корневого подпространства есть не что иное, как альфа ИТ, алгебраическая кратность нашего собственного значения.
[42:45.320 --> 42:50.320]  Эта формула, конечно же, полезна сама по себе.
[42:52.320 --> 43:11.320]  Итак, мы с вами поняли, что если мы разделим наш жардан в базе на фрагменты, соответствующие собственным значениям, то каждый фрагмент будет порождать уже известное нам пространство, оно всегда будет одними тем же, это будет корневой опыт пространства.
[43:12.320 --> 43:17.320]  Что происходит дальше, давайте мы выясним после несколько запоздалого перерыва.
[43:18.320 --> 43:41.320]  Итак, нам осталось разобраться с каждым конкретным пространством УИТ, оно же, как мы с вами поняли, корневое подпространство для собственного значения лямбда ИТ.
[43:41.320 --> 44:06.320]  В этом самом подпространстве тот базис, который мы взяли, Е1 и так далее, Е альфа ИТ, это, конечно же, жардан в базис, в частности жардан в базис вот для какого оператора.
[44:06.320 --> 44:16.320]  Давайте я его, как обычно, обозначу через ПСИ, это оператор ФИ лямбда ИТ, ограниченный на наше подпространство.
[44:16.320 --> 44:37.320]  То есть, как мы с вами уже сказали, давайте я это на всякий случай повторю, ПСИ, вот в этом, это наше ограничение, ПСИ в этом базисе будет иметь жардановую матрицу, состоящую из нескольких жардановых клеток, собственным значением уже ноль, правильно?
[44:37.320 --> 44:47.320]  ЖС от нуля? Ну, напоминаю, что ПСИ нелепатентен.
[44:47.320 --> 45:06.320]  И вот сейчас давайте я веду некоторые понятия, которые нам помогут осознать эту самую единственность ЖНФ.
[45:06.320 --> 45:34.320]  Давайте мы обозначим, ведем вот какие обозначения, через N1 мы обозначим количество клеток в этой самой матрице,
[45:34.320 --> 46:02.320]  через N2, внимание, количество клеток размера хотя бы 2, ну и так далее, через какое-то НКТ я обозначу количество клеток размера хотя бы К.
[46:02.320 --> 46:29.320]  Ну, по сути дела, давайте я сразу замечу, если нам сказать, если нам сказать все эти числа, то есть, если известны числа N1 и так далее, NKT,
[46:29.320 --> 46:53.320]  то мы с вами знаем количество клеток каждого размера. Количество клеток размера ровно И есть, сколько будет количество клеток размера ровно И?
[46:53.320 --> 47:23.320]  Ну, где, видимо, стоит положить н0, равное нулю, правильно? Правда? Нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет, нет,
[47:23.320 --> 47:35.320]  лишние среди них это клетки размера хотя бы i плюс 1, правильно? Поэтому нужно вычитать ni плюс 1, и вот это замечание, конечно же, нам не нужно.
[47:35.320 --> 47:50.320]  Теперь мы написали правильную формулу. Ну, в частности, если nk плюс 1 будет равно нулю, если клеток размера хотя бы k плюс 1 не будет, правильно, то как раз количество клеток размера k будет равно nk тому.
[47:50.320 --> 48:09.320]  Ну, я могу написать здесь многоточие, да? То есть пока что мы же не знаем, так, слушайте, k это плохое, плохая буква, потому что k у нас было количеством собственных значений. Давайте мы там какое-нибудь t напишем.
[48:09.320 --> 48:18.320]  То есть мы в принципе можем ввести эти ni и t для всех натуральных i, просто начиная с некоторого момента они будут, конечно же, нулями, правильно?
[48:19.320 --> 48:32.320]  Вот. Итак, количество клеток размера i это вот такое число. Если нам сказать все числа ni и t, то мы по ним вычислим количество клеток каждого размера.
[48:32.320 --> 48:42.320]  И это как раз и будет означать, что мы знаем жарданную форму с точностью перестановки клеток, потому что мы знаем сколько в ней клеток какого размера, правильно?
[48:42.320 --> 49:05.320]  Таким образом, зная все ni и t, можно восстановить жардановую матрицу однозначно.
[49:05.320 --> 49:25.320]  Ну а эти ni и t мы сейчас с вами восстановим. И вот почему я не стер нашу картинку? Потому что ni и t это будут в точности те самые ni и t, которые у нас есть на картинке.
[49:25.320 --> 49:34.320]  Вот тут у нас были nk, t, nk-1 и так далее. Это они и есть. И давайте мы это с вами сейчас увидим на матричном языке.
[49:34.320 --> 49:57.320]  Так, давайте мы нашу жардановую матрицу, которая у нас здесь есть, обозначим через А.
[49:57.320 --> 50:19.320]  Ну и сразу заметим, что если я возьму оператор psi в этой степени, то в нашем базисе у него будет матрица А в этой степени.
[50:19.320 --> 50:28.320]  А как такая матрица возводится в и-тою степень? Каждая клетка возводится сама по себе в и-тою степень, правильно?
[50:28.320 --> 50:40.320]  Если мы перемножаем две вот таких вот блочно-диагональных матрицы с одинаковыми размерами блоков, то просто они перемножаются поблочно.
[50:40.320 --> 50:52.320]  То есть у меня здесь будет g1 от нуля в и-тою степени, здесь будет g2 от нуля в и-тою степени и так далее.
[50:52.320 --> 51:02.320]  При этом жарданова клетка собственным значением 0 возводится в степень очень просто.
[51:02.320 --> 51:14.320]  Давайте смотреть, g1 от нуля – это матрица, у которой единицы идут на 1 выше главной диагонали.
[51:14.320 --> 51:28.320]  Если мы ее возведем в квадрат, что произойдет? У нас единица появится уже вот здесь, я первую строчку умножаю на первый столбец, единица появляется в следующем месте.
[51:28.320 --> 51:33.320]  Вторую строчку умножаю на четвертый столбец, чтобы появилась единица.
[51:33.320 --> 51:43.320]  То есть здесь у нас будут два нуля и дальше вот такая вот диагональка из единиц и так далее.
[51:43.320 --> 51:53.320]  Если я ее возведу в какую-то м-тою степень, то естественно получится вот какая матрица.
[51:53.320 --> 52:02.320]  То есть у нас будет идти m нулей, а дальше вот такая вот диагональка из единиц.
[52:02.320 --> 52:11.320]  Ну это естественно будет происходить, если m меньше, чем i, правильно?
[52:11.320 --> 52:21.320]  Меньше, чем размер клетки, давайте я размер клетки как-нибудь обозначу через d, при m меньше, чем d.
[52:21.320 --> 52:26.320]  Ну а g1 от нуля в д этой степени уже будет нулевой матрицей.
[52:26.320 --> 52:36.320]  Это можно увидеть, на всякий случай скажу, посмотрев на то, как перемножаются матрицы,
[52:36.320 --> 52:47.320]  ну а можно увидеть, посмотрев как, чьими матрицами, то есть для каких операторов они являются матрицами.
[52:47.320 --> 52:55.320]  То есть g1 от нуля это матрица оператора, который вектора жирдановой цепочки сдвигает на 1 влево, правильно?
[52:55.320 --> 53:04.320]  Квадрат этой матрицы это матрица оператора, который сдвигает эту жирдановую цепочку на 2 влево, а первая два вектора от нуля.
[53:04.320 --> 53:10.320]  Куб на 3 влево и так далее. Поэтому у нас получается вот такая вот вещь.
[53:10.320 --> 53:17.320]  Значит, и в частности,
[53:17.320 --> 53:39.320]  Ранг этой матрицы в m степени будет равен вот чему.
[53:39.320 --> 53:52.320]  Если m еще меньше, чем d, то он будет равен d-m, потому что у нас будет d-m не нулевых столбцов и все они будут линейно независимыми.
[53:52.320 --> 54:02.320]  Ну а в случае, когда m хотя бы d, этот ранг уже будет равен нулю.
[54:09.320 --> 54:29.320]  Ну тогда давайте смотреть, например, какой будет, давайте я это сформулирую на этом языке, раз уж мы начали, а потом переформулирую на другой.
[54:29.320 --> 54:43.320]  Тогда, если размер, ну давайте я размер g первый обозначил через d, лучше бы было его обозначить через d первое, например.
[54:43.320 --> 55:10.320]  Если размер нашей i-той клетки, ну хотя даже это и так, ну ладно, равен d-i тому, то давайте мы поймем, чему будет равен ранг итоговой матрицы.
[55:10.320 --> 55:22.320]  Обратите, пожалуйста, внимание, у нас в каждой из вот этих вот клеток все не нулевые столбцы независимы, и единицы в них находятся в разных местах,
[55:22.320 --> 55:30.320]  потому что в первой матрице единицы будут находиться в пределах первой части базыса, во второй в пределах второй части базыса и так далее.
[55:30.320 --> 55:40.320]  То есть если мы возьмем столбцы большой матрицы, соответствующие не нулевым столбцам вот в этих вот клетках, то они тоже окажутся ли все линейно независимыми.
[55:40.320 --> 55:46.320]  И поэтому количество этих столбцов и будет равно рангу нашей матрицы.
[55:46.320 --> 55:58.320]  Итак, ранг матрицы А будет равен сумме вот этого самого как раз d-i-того минус 1, правильно? Ранг каждой клетки будет равен d-i-того минус 1.
[55:58.320 --> 56:10.320]  Ну а сумма d-i-тых у нас равна размеру матрицы А, который мы уже привыкли обозначить через сумму по i.
[56:10.320 --> 56:22.320]  Давайте мы сразу обозначим размер А через альфу, потому что это алгебрическая кратность соответствующего собственного значения.
[56:22.320 --> 56:34.320]  И значит это будет альфа минус количество клеток, то есть n1.
[56:34.320 --> 56:50.320]  Так, давайте, граждане, я вот это вот число даже немножко по-другому обозначу. Очень часто такое число обозначают вот таким вот образом d-m+.
[56:50.320 --> 57:00.320]  То есть если d-m не отрицательно, то мы его и пишем, правильно? А если d-m отрицательно, то мы его заменяем на ноль.
[57:01.320 --> 57:11.320]  Ранг матрицы А квадрат будет равен сумме d-i-того минус 2 с плюсом.
[57:11.320 --> 57:24.320]  А что это означает? Сколько у нас всего будет выштется из альфы?
[57:24.320 --> 57:39.320]  Для всех клеток, у которых размер хотя бы 2, выштется по 2, а для клеток размера 1 выштется 1, правильно? Всего у нас выштется n1 и n2.
[57:39.320 --> 57:49.320]  Но по сути дела, сначала, когда я вычитаю из d-i-того единичку, вычитается единица из всех n1 клеток, правильно? Для каждой из n1 клеток.
[57:49.320 --> 57:55.320]  А вторая единица вычитается из всех клеток, которые размера хотя бы 2.
[57:55.320 --> 58:11.320]  Ранг А куба это будет сумма d-i-того минус 3 с плюсом, и это будет, соответственно, альфа минус n1 минус n2 минус n3 и так далее.
[58:11.320 --> 58:33.320]  Соответственно, ранг А в катой степени это будет альфа минус сумма пожи от 1 до k, ну в тетой давайте, да, мы с вами обозначили через t вот это вот, мистическое число, сумма пожи от 1 до t, n житого.
[58:33.320 --> 58:55.320]  Ну мы уже близки к нашей цели, потому что ранг какой-то степени А имеет геометрическое описание.
[58:55.320 --> 59:05.320]  Мы можем сказать, что это размерность образа нашего psi в тетой степени.
[59:05.320 --> 59:23.320]  Ну или если хочется, мы можем еще сказать, что это альфа минус размерность ядра psi в тетой степени, потому что сумма размерностей ядра и образа равна как раз тому, что нам надо.
[59:23.320 --> 59:40.320]  Значит, если нам дан оператор psi нелепотентный, то мы для него знаем все ранги, какие должны принимать А в тетой, А в первый, А в квадрат, А в кубе и так далее, правильно?
[59:40.320 --> 01:00:01.320]  Итак, значит, мы сами получили, по сути, вот какую систему уравнений.
[01:00:01.320 --> 01:00:15.320]  Н1 это размерность ядра psi, правильно? Поскольку альфа минус n1 это альфа минус размерность ядра этого psi.
[01:00:15.320 --> 01:00:32.320]  Н1 плюс н2 из аналогичных соображений это размерность ядра psi в квадрат, н1 плюс и так далее плюс нт это размерность ядра psi в тетой.
[01:00:32.320 --> 01:00:59.320]  Таким образом, если нам дан оператор psi по оператору psi однозначно восстанавливаются.
[01:00:59.320 --> 01:01:16.320]  Вот эти вот суммы, которые у нас тут написаны, по этим суммам мы с вами видим, что восстанавливаются все nt, правильно? Это разные из двух соседних сумм.
[01:01:16.320 --> 01:01:36.320]  Отсюда мы получаем, что nt это просто-напросто размерность ядра psi в итой минус размерность ядра psi в и-1, правильно?
[01:01:36.320 --> 01:01:50.320]  Ну или, кстати, что то же самое, размерность образа psi в и-1 минус размерность образа psi в итой, так тоже можно сказать.
[01:01:50.320 --> 01:02:07.320]  Итак, nt восстанавливаются однозначно, но и, следовательно, жардановая форма тоже восстанавливается однозначно. Мы говорили, что знания nt нам достаточно для восстановления жардановой формы.
[01:02:07.320 --> 01:02:25.320]  Жарданного матрица тоже восстанавливается.
[01:02:25.320 --> 01:02:53.320]  Ну, естественно, с точностью до перестановки клеток, потому что мы с вами много раз эти клетки переставляли во-первых, ну и не интересовались, в каком порядке эти клетки идут здесь, правильно? Мы сказали только, что мы знаем количество клеток каждого размера с точностью до перестановки клеток.
[01:02:53.320 --> 01:03:12.320]  Ну и таким образом мы с вами доказали, что жардановая форма не только существует, но и единственна с точностью до перестановки клеток, и вся теорема о жардановой нормальной форме у нас сейчас доказана некоторые части даже по два раза.
[01:03:12.320 --> 01:03:35.320]  Ну и в заключение вот этого конкретного разговора обратите, пожалуйста, внимание, что то, что я обещал, я и доказал. У нас размерность пространства выитого, которое мы брали, ну, собственно, пространство выиты это было как раз ядро psi в i-той степени, правильно?
[01:03:35.320 --> 01:03:45.320]  И вот на этой картинке размерность выитого у нас как раз и была равна n1 плюс n2 плюс и так далее плюс n-i-t, правильно?
[01:03:45.320 --> 01:04:01.320]  Поэтому эти числа n-i-t ровно те же самые, что у нас на картинке. Давайте мы это в качестве замечания оформим.
[01:04:05.320 --> 01:04:23.320]  В качестве замечания, значит, числа n-i-t те же, что и на картинке.
[01:04:23.320 --> 01:04:38.320]  Итак, мы с вами долго доказывали эту теорему, мы ее доказали, давайте стричь дивиденд.
[01:04:38.320 --> 01:05:02.320]  Давайте посмотрим, какие у нас есть приложения GNF.
[01:05:02.320 --> 01:05:15.320]  Пункт первый. На самом деле у нас сейчас появился, наша теорема непосредственно дает нам возможность про две матрицы выяснить,
[01:05:15.320 --> 01:05:26.320]  правда ли, что они являются матрицами одного и того же оператора, то есть выяснить подобны ли эти матрицы.
[01:05:26.320 --> 01:05:44.320]  Альгоритм выяснения, подобны ли две матрицы.
[01:05:44.320 --> 01:06:02.320]  Давайте я сформулирую, точнее, вот этот алгоритм у нас есть, в частности, над полем C, а вообще он будет работать, естественно, только при выполнении тех условий, которые мы себя ограничили.
[01:06:02.320 --> 01:06:12.320]  То есть условия, что у этих матриц характеристические многочлены раскладываются на линейные сомножители, естественно, правильно?
[01:06:12.320 --> 01:06:21.320]  Ну давайте я докажу немножко более общее утверждение, из которого это будет следовать.
[01:06:21.320 --> 01:06:47.320]  Итак, пусть A и B это матрицы размера N на N над каким-то полем F, причем их характеристические многочлены раскладываются на линейные сомножители.
[01:06:47.320 --> 01:07:16.320]  Тогда A и B подобны, тогда и только тогда, когда их жардановые нормальные формы совпадают.
[01:07:16.320 --> 01:07:26.320]  Прежде чем доказывать это утверждение, давайте я обращу внимание вот на какой факт.
[01:07:26.320 --> 01:07:34.320]  Вот мы сейчас с вами доказывали вторую часть нашей теоремы про единственность жардановой нормальной формы.
[01:07:34.320 --> 01:07:42.320]  И по сути дела, вот в этом доказательстве у нас есть алгоритм, как находить жардановую форму, даже не ища базиса, правильно?
[01:07:42.320 --> 01:07:48.320]  Жардановую форму, матрицы найти проще, чем найти жардановый базис.
[01:07:48.320 --> 01:07:59.320]  И поэтому, например, для вот этого выяснения, если нам не нужно конкретное подобие, если нам просто нужно выяснить A и B подобны или нет,
[01:07:59.320 --> 01:08:11.320]  но не нужно находить какая матрица перехода переводит одну в другую, вот в такой ситуации нам достаточно найти GNF у матриц A и B, базис находить не нужно.
[01:08:12.320 --> 01:08:15.320]  Все равно подобие мы выясним.
[01:08:17.320 --> 01:08:21.320]  Так, мне эта картинка, наверное, уже больше не нужна.
[01:08:23.320 --> 01:08:25.320]  Давайте я ее сотру.
[01:08:25.320 --> 01:08:36.320]  Итак, доказательство утверждения очень простое.
[01:08:36.320 --> 01:08:58.320]  Если A и B подобны, напоминаю, существует матрица перехода, существует невырожденная матрица, такая, что A это, скажем, S-1 на B на S,
[01:08:58.320 --> 01:09:06.320]  то они являются матрицами одного и того же оператора.
[01:09:06.320 --> 01:09:10.320]  Это другое определение того же самого понятия.
[01:09:10.320 --> 01:09:19.320]  Матрицы одного оператора phi.
[01:09:19.320 --> 01:09:34.320]  Просто возьмем какой-нибудь оператор phi на пространстве столбцов, у которого матрица B, сделаем замену базиса с матрицей перехода S, получим матрицу A, конечно, в новом базисе.
[01:09:34.320 --> 01:09:56.320]  Они матрицы оператора phi. У этого оператора, как мы с вами знаем, есть ровно одна жарданого форма, с точностью до перестановки клеток.
[01:09:56.320 --> 01:10:14.320]  Ну, значит, и у матриц A и B та же самая форма.
[01:10:14.320 --> 01:10:21.320]  То есть, если A и B подобны, то жеронов у них, конечно же, совпадают.
[01:10:21.320 --> 01:10:50.320]  Наоборот, еще проще, если, скажем, я через G обозначу общую GNF матриц A и B, если у них жеронова форма одна и та же, то она получается из них какими-то заменами базиса, правильно?
[01:10:50.320 --> 01:11:15.320]  То есть G это S1 в минус 1 на A на S, 1, спасибо, и S2 в минус 1 на B на S2, где S1 и S2 это некоторые матрицы замена базиса, то есть невырожденные матрицы над F.
[01:11:15.320 --> 01:11:23.320]  Ну, тогда из этих формул мы можем выразить A через B, правильно? Что такое A?
[01:11:23.320 --> 01:11:48.320]  Возьмем это равенство, чтобы выразить из него A, нам нужно домножить на S1 слева и на S1 в минус 1 справа, то есть это S1, S2 в минус 1 на B на S2, S1 в минус 1, ну, слева стоит матрица обратная к той, которая стоит справа.
[01:11:48.320 --> 01:12:01.320]  Здесь S2, S1 в минус 1 и все это в минус 1, мы знаем, что когда мы берем обратную к матрице, то матрица переставляется местами и у каждой берется обратную, правильно?
[01:12:01.320 --> 01:12:14.320]  Поэтому вот эта матрица, то, что я там сейчас написал, на B на S2, S1 в минус 1. Ну и мы получили, что матрицы подобны, вот оно непосредственное подобие.
[01:12:14.320 --> 01:12:23.320]  И таким образом наше утверждение уже доказано.
[01:12:23.320 --> 01:12:38.320]  Так, следующий вопрос. Где тряпка?
[01:12:38.320 --> 01:12:52.320]  Это был еще не вопрос. Следующий вопрос. Давайте мы с точки зрения нашей жардановой формы посмотрим на минимальный многочлен оператора.
[01:12:52.320 --> 01:13:07.320]  Оказывается, если мы жардановую форму оператора знаем, если он жардановой формой обладает, то мы сразу можем найти его минимальный многочлен.
[01:13:07.320 --> 01:13:23.320]  Многочлен. Многочлен оператора какого-то phi.
[01:13:23.320 --> 01:13:46.320]  Ну и, естественно, если нам нужно найти минимальный многочлен матрицы, то есть, напоминаю, многочлен наименьшей степени, нулевой многочлен наименьшей степени, который обнуляет эту матрицу, то, естественно, это тот же самый вопрос, потому что любая квадратная матрица это матрица какого-то оператора, какого-то линейного преобразования.
[01:13:46.320 --> 01:14:00.320]  Итак, основная теория, наверное, звучит вот каким образом.
[01:14:00.320 --> 01:14:19.320]  Итак, пусть phi это линейный оператор, у которого характеристический многочлен, как обычно, раскладывается на линейные сомножители, только в этом случае мы можем что-нибудь сделать.
[01:14:19.320 --> 01:14:45.320]  Тогда его минимальный многочлен, это будет произведение, но мы с вами, напоминаю, уже некоторое время назад выяснили, что уж в таком-то случае точно минимальный многочлен делит характеристически, правильно?
[01:14:45.320 --> 01:14:55.320]  И поэтому минимальный многочлен будет выглядеть как?
[01:14:55.320 --> 01:15:03.320]  Произведение тех же самых сомножителей, но, возможно, в меньших степенях, правильно?
[01:15:03.320 --> 01:15:08.320]  И вопрос в том, как найти эти степени.
[01:15:08.320 --> 01:15:33.320]  Так вот, я говорю, чтобы это и то, это не что иное, как наибольший размер клетки в жардановой форме phi,
[01:15:33.320 --> 01:15:41.320]  соответствующей собственному значению λi.
[01:15:41.320 --> 01:15:50.320]  То есть, если мы привели наш phi к жардановой форме, если мы знаем у него жардановую форму, базис, опять же, даже не нужен,
[01:15:50.320 --> 01:16:02.320]  то для каждого лi мы находим наибольший размер клетки с именно лi по диагонали, и вот этот показатель мы и обязаны сюда подставить.
[01:16:02.320 --> 01:16:18.320]  Так, ну сейчас у нас уже должен быть звонок, поэтому давайте я не буду начинать это доказательство,
[01:16:18.320 --> 01:16:25.320]  а лучше мы сейчас сделаем 10-ти минутный перерыв, а после этого эту теорему докажем.
[01:16:25.320 --> 01:16:34.320]  Ну вот я еще раз давайте проговорю эту мысль, и мы ее даже запишем.
[01:16:34.320 --> 01:16:47.320]  Мы с вами знаем, что минимальный многочлен оператора делит его характеристически многочлен.
[01:16:47.320 --> 01:16:56.320]  Действительно, минимальный многочлен имеет вот такой вот вид для некоторых констант бета.
[01:16:56.320 --> 01:17:07.320]  Произведение паи от 1 до k, λi-х в бетаитах, где бетаиты не превосходят альфаитах.
[01:17:07.320 --> 01:17:19.320]  Мы даже говорили, что эти бетаиты обязательно не меньше единицы, поскольку мы говорили, что любое собственное значение является корнем минимального многочлена.
[01:17:19.320 --> 01:17:26.320]  Но, наверное, нам сейчас это даже не потребуется.
[01:17:26.320 --> 01:17:53.320]  Далее, если наш оператор phi имеет жардановую форму, ну скажем, A, состоящую из нескольких клеток G1, G2 и так далее,
[01:17:53.320 --> 01:18:13.320]  мы с вами знаем, что при наших условиях phi имеет жардановую форму, то, разумеется, для любого многочлена вообще,
[01:18:13.320 --> 01:18:23.320]  пусть это происходит в некотором базе C, P от phi в этом же самом базе будет иметь матрицу P от A.
[01:18:23.320 --> 01:18:34.320]  И более того, этот P применяется к каждой клетке по отдельности, мы с вами, по сути дела, это уже говорили.
[01:18:34.320 --> 01:18:44.320]  Это будет тоже блокно-диагональная матрица, в которой блоками будут P от G1, P от G2 и так далее.
[01:18:44.320 --> 01:19:02.320]  Ну и значит многочлен P является аннулирующим тогда и только тогда, когда он является аннулирующим, естественно, для матрицы.
[01:19:02.320 --> 01:19:14.320]  А это в свою очередь означает, что он должен аннулировать каждую из клеток, правильно? P от G1 равно 0, P от G2 равно 0 и так далее.
[01:19:14.320 --> 01:19:22.320]  Ну здесь нехорошо писать одно равенство, потому что это P от G1, P от G2 и так далее, это матрица разных размеров, правильно?
[01:19:22.320 --> 01:19:30.320]  По сути у нас здесь нули размеров, нули это нулевой матриц этих размеров, каких размеров у нас в жердановой клетке.
[01:19:30.320 --> 01:19:51.320]  Так что лучше написать вот такое вот. Ну и значит нас интересует, нас интересует, когда многочлен вот этого самого вида, который мы сейчас с вами написали,
[01:19:51.320 --> 01:20:03.320]  давайте мы его, значит вот это вот равенство у нас очень давно обозначалось звездочкой, поэтому давайте я вот это вот обозначу двумя звездочками.
[01:20:03.320 --> 01:20:21.320]  Это когда многочлен вот тот, который мы с вами написали, обнуляет каждую клетку.
[01:20:21.320 --> 01:20:32.320]  Ну а здесь ситуация очень простая.
[01:20:32.320 --> 01:20:50.320]  Итак, пусть у нас действительно есть многочлен вот того самого вида, лямбда иты минус х в степени бета иты и пусть у нас есть какая-то жердановая клетка G,
[01:20:50.320 --> 01:21:10.320]  ну давайте я напишу G D от лямбда итого, то есть у нас по диагонали стоят лямбда иты, вверху стоят единички, дальше стоят нули.
[01:21:10.320 --> 01:21:25.320]  Давайте посмотрим, что будет, если мы подставим вот эту вот клетку в этот многочлен, а для этого давайте мы посмотрим, что будет, если эту клетку подставить в каждый самножитель по отдельности.
[01:21:25.320 --> 01:21:47.320]  Значит, если я подставлю вот эту вот клетку не в итый самножитель, а в какой-то другой, при и неравном G, если я подставлю эту клетку в соответствующий самножитель,
[01:21:47.320 --> 01:22:11.320]  эта подстановка даст вот какую матрицу, значит, лямбда G T E минус вместо х я подставляю нашу матрицу, Е я написал, потому что вот таким образом мы матрицу всегда подставляем, правильно, G D от лямбда иты,
[01:22:11.320 --> 01:22:31.320]  и все это в какой-то степени бета ита, давайте мы поймем, какую матрицу мы возводим в степень бета ита. У меня по диагонали стоит лямбда G T E минус лямбда ита, сверху стоят единички, а все остальное нули.
[01:22:31.320 --> 01:22:50.320]  Ну, по сути, делается самножитель бесполезен, потому что эта матрица невырожденная. Это невырожденная матрица.
[01:22:50.320 --> 01:23:08.320]  То есть, когда мы будем подставлять нашу клетку вот в этот вот многочлен, все самножители кроме одного дадут нам невырожденные матрицы, и поэтому, если этот многочлен мы хотим, чтобы он обнулился на нашей клетке, то обнуляться должен именно итый самножитель.
[01:23:08.320 --> 01:23:34.320]  Поэтому обнуляться должен ровно итый самножитель. Если итый самножитель не обнулился, он дал какую-то не нулевую матрицу, возможно вырожденную, то, домножая ее еще на несколько невырожденных матриц, мы нуля уже не получим.
[01:23:34.320 --> 01:24:02.320]  Ну, а кое-то так, то нам нужно, и так, для обнуления надо, чтобы у нас нулем стал именно итый самножитель.
[01:24:04.320 --> 01:24:19.320]  То есть, лямда итая Е минус наша жарданого клетка. Это у нас, мы с вами знаем, что такое. Эту матрицу мы сегодня в степень уже возводили.
[01:24:19.320 --> 01:24:39.320]  Жарданного клетка с нулевым собственным значением по диагонали, правильно, из лямда итого я вычел лямда итая. Так, извините, пожалуйста, я не совсем точно это написал, потому что здесь у нас будет стоять минус единички, правильно, а не единички, раз я жарданому клетку вычитаю.
[01:24:39.320 --> 01:25:04.320]  Но разница здесь небольшая, в бета итой. Ну, а это мы с вами знаем, что такое. Мы знаем, что когда мы возводим эту матрицу в бета итую степень, то диагональ единичек смещается на бета итой, правильно?
[01:25:04.320 --> 01:25:14.320]  Ну и следовательно, для того, чтобы эта матрица, эта клетка обнулилась, нам нужно, чтобы бета итая была не меньше, чем Д.
[01:25:14.320 --> 01:25:25.320]  Ну и так, давайте понимать, что это означает.
[01:25:26.320 --> 01:25:54.320]  Для того, чтобы многочлен вот этой вот самой П обнулял все клетки в нашей GNF с собственным значением лямда итой, нам нужно, чтобы бета итой была не меньше, чем размер каждой из этих клеток.
[01:25:54.320 --> 01:25:59.320]  То есть не меньше, чем размер наибольшей из них, правильно?
[01:25:59.320 --> 01:26:21.320]  То есть нам внимание необходимо и достаточно, чтобы бета итая была не меньше размера любой из этих клеток.
[01:26:29.320 --> 01:26:42.320]  Необходимо, потому что если бета итая будет меньше, чем этот размер, то не ноль получится, правильно, в одной из клеток.
[01:26:42.320 --> 01:26:53.320]  Достаточно, потому что если бета итая будет хотя бы в этот размер, то, значит, даже вот равносильно здесь можно написать, то каждый из этих клеток, конечно же, обнулится.
[01:26:53.320 --> 01:27:10.320]  Ну, значит, для того, чтобы получить минимальный многошлен, для того, чтобы взять многошлен наименьшей степени, которой все эти клетки обнуляют, мы должны все эти бета итая положить в точности размером наибольшим размерам соответствующих клеток.
[01:27:10.320 --> 01:27:13.320]  Это сказано в нашей теории.
[01:27:16.320 --> 01:27:19.320]  Таким образом, теория доказана.
[01:27:23.320 --> 01:27:32.320]  Да?
[01:27:32.320 --> 01:27:48.320]  Минимальная степень аннурирующей...
[01:27:48.320 --> 01:27:55.320]  Они вообще-то могут быть разными над разными полями, но на самом деле, конечно же, они будут одинаковыми.
[01:27:55.320 --> 01:28:01.320]  То есть, минимальный многочлен матрицы не зависит от того, над каким полем.
[01:28:01.320 --> 01:28:05.320]  То есть, берете вы матрицу над полем или над каким-то над полем.
[01:28:05.320 --> 01:28:17.320]  Потому что минимальный многочлен матрицы, это такое минимальное К, что матрицы Е, А, А квадрат и т.д., А вкаты, линейно зависимы.
[01:28:17.320 --> 01:28:23.320]  А линейная зависимость матриц над полем или над над полем высчисляется одинаково.
[01:28:27.320 --> 01:28:35.320]  Так что на самом деле, минимальный многочлен от этого не зависит.
[01:28:35.320 --> 01:28:49.320]  Желающие могут понять, почему это так.
[01:28:49.320 --> 01:28:53.320]  Но на самом деле, я уже больше половины доказательства точно сказал.
[01:28:53.320 --> 01:29:11.320]  Давайте, раз такой вопрос задан, то я сделаю вот это замечание, а технические детали предложу выяснить всем желающим.
[01:29:11.320 --> 01:29:16.320]  Техническое замечание выглядит следующим образом.
[01:29:16.320 --> 01:29:30.320]  Пусть А это какая-то матрица над полем Ф, К это над полем поля Ф.
[01:29:30.320 --> 01:29:36.320]  Ну то есть, матрица А может восприниматься и как матрица над К, правильно?
[01:29:36.320 --> 01:29:56.320]  Тогда минимальный многочлен матрицы А над Ф совпадает с, ну является, лучше сказать, является, у нас минимальный многочлен определен с точностью домножения на константу, правильно?
[01:29:56.320 --> 01:30:10.320]  Давайте лучше так скажем, является ее минимальным многочленом и над К.
[01:30:10.320 --> 01:30:16.320]  Еще раз, почему это так?
[01:30:16.320 --> 01:30:28.320]  Действительно, что означает, что минимальный многочлен является аннулирующим?
[01:30:28.320 --> 01:30:40.320]  Вы взяли несколько степеней матрицы А, взяли их нетривиальную линейную комбинацию, которая получилась равной нулю, правильно?
[01:30:40.320 --> 01:31:08.320]  То есть, любой аннулирующий многочлен, давайте я так скажу, аннулирующий многочлен в степени D задает не что иное, как линейную зависимость
[01:31:08.320 --> 01:31:18.320]  Матриц Е, то есть А в нулевой, А в первый, А в квадрат и так далее, А в Д.
[01:31:18.320 --> 01:31:27.320]  Когда мы аннулирующий многочлен применили к матрице А, мы как раз и взяли эту самую линейную комбинацию, правильно?
[01:31:27.320 --> 01:31:34.320]  Домножили эти матрицы на соответствующие коэффициенты, ну естественно, использующие А в Д.
[01:31:34.320 --> 01:31:39.320]  Эта линейная комбинация используют А в Д нетривиальным образом.
[01:31:39.320 --> 01:31:56.320]  Ну а эти матрицы линейно зависимы над F тогда и только тогда, когда они линейно зависимы над K.
[01:31:56.320 --> 01:31:59.320]  Каким образом это можно понять?
[01:31:59.320 --> 01:32:10.320]  Ну вообще, если у вас есть какие-то объекты в линейном пространстве, например, матрицы, мы их всегда можем записать, разложить по какому-нибудь базису, правильно?
[01:32:10.320 --> 01:32:15.320]  То есть, вместо матриц мы имеем право рассмотреть, например, их координатные столбцы.
[01:32:15.320 --> 01:32:27.320]  И следовательно, вопрос у нас в том, что некоторые столбцы линейно зависимы над F тогда и только тогда, когда они линейно зависимы над K.
[01:32:27.320 --> 01:32:34.320]  А мы знаем метод проверки этого. Этот метод проверки заключается в применении метода Гаусса.
[01:32:34.320 --> 01:32:41.320]  И когда вы применяете метод Гаусса к столбцам над F, вы за пределы поля F не выйдете.
[01:32:41.320 --> 01:32:46.320]  Вы будете складывать, вычитать, умножать их на константы, которые тоже будут из поля F.
[01:32:46.320 --> 01:32:53.320]  И поэтому этот метод Гаусса будет работать одинаково над F и над K.
[01:32:53.320 --> 01:32:57.320]  И следовательно, будет приводить к одному и тому же результату.
[01:32:57.320 --> 01:33:20.320]  Метод Гаусса применяемый, естественно, к матрице, у которой все элементы из F работают одинаково над F и над K.
[01:33:20.320 --> 01:33:29.320]  Вот это по сути дела другое оформление вот какого соображения.
[01:33:29.320 --> 01:33:40.320]  Что если у вас есть, например, система линейных уравнений с рациональными коэффициентами, то она имеет рациональное решение тогда и только тогда, когда она имеет действительное решение.
[01:33:40.320 --> 01:33:50.320]  Это другое оформление того же самого, потому что когда вы будете применять метод Гаусса для решения этой системы, вы останетесь в пределах рациональных чисел.
[01:33:50.320 --> 01:33:58.320]  Так, это у нас было некоторое лирическое отступление.
[01:33:58.320 --> 01:34:14.320]  Давайте мы вернемся к нашему минимальному многочлену и давайте я сразу освещу две возможных крайности.
[01:34:14.320 --> 01:34:22.320]  Первая крайность – непосредственное следствие из теоремы.
[01:34:22.320 --> 01:34:39.320]  Пусть phi – это линейный оператор на пространстве V, удовлетворяющий все тому же нашему любимому условию.
[01:34:39.320 --> 01:35:04.320]  Я еще раз напоминаю, это условие над некоторыми полями действительно нетривиально, но, например, если мы будем работать над самым лучшим в мире полем комплексных чисел, то это не ограничение, это так для любого оператора.
[01:35:04.320 --> 01:35:09.320]  Пусть у нас вот такая ситуация есть.
[01:35:09.320 --> 01:35:20.320]  Тогда минимальный многочлен этого оператора совпадает с характеристическим многочленом этого оператора.
[01:35:20.320 --> 01:35:26.320]  В том и только в том случае, когда... когда?
[01:35:26.320 --> 01:35:38.320]  Нет, это другая крайность.
[01:35:38.320 --> 01:35:45.320]  Абсолютно верно.
[01:35:45.320 --> 01:36:12.320]  Когда для каждого собственного значения лямбдаитая в жардановой форме этого phi есть ровно одна клетка с этим собственным значением.
[01:36:12.320 --> 01:36:27.320]  То есть мы с вами знаем, что в жардановой форме устроен достаточно хитрым образом, там может быть для каждого собственного значения, если у него кратный корень характеристического многочлена, то там может быть несколько клеток, правильно?
[01:36:27.320 --> 01:36:36.320]  Так вот нам говорят, что для каждого собственного значения обязана быть одна клетка.
[01:36:36.320 --> 01:36:44.320]  Ну, доказательства очень простые. Давайте смотреть, что означает, что минимальный многочлен совпадает с характеристическим.
[01:36:44.320 --> 01:36:56.320]  В терминах нашей теоремы это означает, что бетаитая равно альфаитому для любого и, правильно?
[01:36:56.320 --> 01:37:06.320]  Ну а что это означает? Бетаитая, это наибольший размер клетки, соответствующий лямбдаитому, правильно?
[01:37:06.320 --> 01:37:30.320]  Это равносильно тому, что для каждого и в GNF есть клетка с собственным значением лямбдаитая размера альфаитая.
[01:37:30.320 --> 01:37:46.320]  Ну а это означает, что никаких других клеток для этого лямбды нет, потому что мы с вами говорили, что альфаитая это есть размерность корневого подпространства
[01:37:46.320 --> 01:38:05.320]  и это есть сумма размеров всех клеток с собственным значением лямбдаита.
[01:38:05.320 --> 01:38:20.320]  Вот, то есть вот это вот условие для данного конкретного лямбдаитого, условие, что есть клетка размера ровно альфаитая, означает, что никаких других клеток с этим собственным значением нет.
[01:38:20.320 --> 01:38:30.320]  У нас всего лямбдаитая на диагонали будет встречаться альфаитой раз, и вот оно в этой клетке уже встретилось альфаитой раз. Больше ей встречаться негде.
[01:38:31.320 --> 01:38:35.320]  Ну, таким образом наше следствие уже доказано.
[01:38:38.320 --> 01:38:55.320]  Так, ну и еще одно утверждение давайте мы докажем. Здесь у нас, по сути дела, количество клеток для каждого собственного значения минимально, правильно? Она одна.
[01:38:55.320 --> 01:39:03.320]  А что означает, скажите мне, пожалуйста, что количество клеток для каждого собственного значения максимальное возможное?
[01:39:04.320 --> 01:39:15.320]  Все клетки размера один, конечно же, правильно? То есть это происходит тогда и только тогда, когда мат, когда наше преобразование, когда наш оператор диагонализуем.
[01:39:16.320 --> 01:39:28.320]  И вот давайте мы это докажем даже в чуть более, в чуть большей общности, потому что вот то рассуждение, которое мы еще с вами сказали, все-таки опирается на Жарданову нормальную форму, правильно?
[01:39:29.320 --> 01:39:34.320]  Оно использует вот это вот условие, а его нам не нужно.
[01:39:34.320 --> 01:39:52.320]  Итак, пусть Фи это линейный оператор. Нет, не без всякого причем. На пространстве ОВ.
[01:39:52.320 --> 01:40:09.320]  Тогда Фи диагонализуем тогда и только тогда, когда его минимальный многочлен...
[01:40:09.320 --> 01:40:17.320]  Нет, равен Хи-Фи это предыдущий случай.
[01:40:18.320 --> 01:40:23.320]  Равен произведению каких-то скобочек в первых степенях.
[01:40:24.320 --> 01:40:39.320]  То есть на самом деле, я вот так вот скажу, он просто раскладывается на линейные совмножители, где все эти линейные совмножители различны при имя равном Ж.
[01:40:40.320 --> 01:40:56.320]  Если нам с вами удалось найти минимальный многочлен, который является произведением различных скобок вот такого вида, то автоматически оператор будет диагонализован.
[01:40:57.320 --> 01:41:03.320]  Вне зависимости от того, обратите внимание, никаких условий на характеристический многочлен мы не требуем.
[01:41:04.320 --> 01:41:09.320]  Доказательства оказываются очень простым.
[01:41:10.320 --> 01:41:25.320]  Значит, слева направо все тривиально. Если уж Фи диагонализуем, то мы с вами знаем, что его характеристический многочлен раскладывается на линейные совмножители.
[01:41:26.320 --> 01:41:30.320]  Лямдоитое минус х в степени альфаитое.
[01:41:39.320 --> 01:41:45.320]  И все клетки в ЖНФ размера 1, правда?
[01:41:46.320 --> 01:41:51.320]  Он диагонализуем, диагональный вид это и будет ЖНФ, правда? Мы с вами об этом уже говорили.
[01:41:52.320 --> 01:42:02.320]  Все клетки в ЖНФ размера 1, но тогда по нашей теореме мы знаем, какой будет минимальный многочлен.
[01:42:05.320 --> 01:42:09.320]  Мы должны лямдоитое минус х взять в первых степенях.
[01:42:09.320 --> 01:42:19.320]  Мы с вами, напоминаю, давно условились, что вот эта формула означает, что при разных И лямдоитое тоже будут различными.
[01:42:20.320 --> 01:42:23.320]  Мы этим много раз уже пользовались.
[01:42:24.320 --> 01:42:28.320]  Так что минимальный многочлен будет иметь ровно тот самый вид.
[01:42:28.320 --> 01:42:34.320]  А в обратную сторону, граждане, нам достаточно вот что сделать.
[01:42:35.320 --> 01:42:42.320]  Если минимальный многочлен представляется вот в таком вот виде,
[01:42:42.320 --> 01:42:51.320]  то все вот эти вот сомножители лямдоитое минус х попарно взаимно просты.
[01:42:54.320 --> 01:43:00.320]  Если мы возьмем два таких сомножителя, они не имеют никакого значения.
[01:43:01.320 --> 01:43:07.320]  Но если мы возьмем два таких сомножителя, они не имеют никакого значения.
[01:43:08.320 --> 01:43:16.320]  Если мы возьмем два таких сомножителя, они не будут иметь общего делителя степени выше нулевой, правда?
[01:43:17.320 --> 01:43:20.320]  Хотя потому что их разность не нулевая, а константа.
[01:43:21.320 --> 01:43:27.320]  Ну а как скоро так, то мы с вами нашли вот такой вот аннулирующий многочлен.
[01:43:28.320 --> 01:43:39.320]  А это означает, напоминаю, вот когда мы с вами раскладывали пространство в прямую сумму корневых,
[01:43:40.320 --> 01:43:54.320]  вы с вами доказывали вот какой факт, что если просто аннулирующий многочлен раскладывается в произведении нескольких взаимно простых сомножителей,
[01:43:54.320 --> 01:44:00.320]  то пространство раскладывается в прямую сумму ядер этих прямых сомножителей.
[01:44:01.320 --> 01:44:15.320]  То есть V это прямая сумма вот кого? Ядра лямбда 1 минус фи, плюс ядра лямбда 2 минус фи, плюс и так далее, плюс ядра лямбда катая минус фи.
[01:44:15.320 --> 01:44:22.320]  Учудо, что это за ядра?
[01:44:27.320 --> 01:44:29.320]  Собственное вот пространство, правильно?
[01:44:30.320 --> 01:44:32.320]  Это V лямбда 1.
[01:44:37.320 --> 01:44:44.320]  Ну а то, что пространство раскладывается в прямую сумму собственных, это и есть критерии того, что фи диагонализуем.
[01:44:45.320 --> 01:45:07.320]  Так, ну что ж, про минимальный мы решили, мы обсудили все достаточно подробно.
[01:45:08.320 --> 01:45:17.320]  Немножко несвоевременное я боюсь упражнение, лучше его было дать раньше, но давайте я его дам хотя бы сейчас.
[01:45:18.320 --> 01:45:28.320]  Вот мы с вами много обсуждали про то, что минимальный многочлен мы хорошо умеем считать в том случае, если характеристически раскладывается на линейные сомножители, правильно?
[01:45:29.320 --> 01:45:37.320]  Давайте на всякий случай, я просто извините, я не помню, может я это упражнение уже давал, если не давал, то полезно его дать сейчас.
[01:45:37.320 --> 01:46:04.320]  Итак, упражнение, пусть у нас есть какой-то неприводимый многочлен, который делит характеристический многочлен фи, тогда он делит и минимальный многочлен фи тоже.
[01:46:07.320 --> 01:46:23.320]  Так, сразу скажу, что то, что у нас произойдет на следующей лекции, может помочь в решении этого упражнения.
[01:46:24.320 --> 01:46:34.320]  Так, третье приложение жирановой формы, последние на сегодня, более масштабные будут в следующий раз.
[01:46:34.320 --> 01:47:03.320]  Заключается вот в чем, давайте мы научимся быстро возводить матрицу в большую степень, ну точнее давайте мы научимся выписывать формулы, общую формулу, зависящую от n, как она будет выглядеть.
[01:47:04.320 --> 01:47:15.320]  Если А имеет жирановую нормальную форму, то есть если характеристический многочлен, ну все как обычно.
[01:47:15.320 --> 01:47:32.320]  Итак, глядите, что можно сделать, если мы, например, хотим найти даже общую формулу, зависящую от n.
[01:47:32.320 --> 01:48:01.320]  Если g это жирановая нормальная форма А, а s это матрица перехода к ней, то, разумеется, g это s-1 на А на s, ну а значит А это s на g на s-1.
[01:48:02.320 --> 01:48:17.320]  Обращаю внимание, на всякий случай, почему я использую в качестве матрицы s именно такую матрицу, именно в эту сторону, потому что, когда мы с вами ищем жирановый базис, мы находим столбцы именно этой матрицы s, правильно?
[01:48:17.320 --> 01:48:42.320]  Жирановый базис составляет с матрицей перехода именно в эту сторону. Ну а тогда, если я хочу возвести матрицу А в n степень, то я должен вот это вот дело перемножить n раз.
[01:48:42.320 --> 01:48:56.320]  Ну и, значит, обратите внимание, мы через некоторое время, на следующем курсе будем очень много подобными соображениями пользоваться, s-1 на s сокращаются, правильно, на каждом стыке.
[01:48:56.320 --> 01:49:11.320]  И получается просто s на g в n на s-1. И, значит, для того, чтобы нам найти формулу, нам достаточно найти формулу для g в n, правильно?
[01:49:11.320 --> 01:49:30.320]  Значит, достаточно найти формулу для g в n, для жирановой формы в n степени, для жирановой матрицы в этой степени.
[01:49:30.320 --> 01:49:45.320]  Ну а для этого, естественно, достаточно уметь возводить в n степень кого? Жиранову клетку, конечно, правильно? Для каждой клетки в отдельности.
[01:49:45.320 --> 01:50:03.320]  Ну а это происходит вот, это делается уже просто.
[01:50:03.320 --> 01:50:28.320]  Если у вас есть жиранова клетка размера d с собственным значением λ, и вы ее хотите возвести в n степень, давайте я ее вот каким образом представлю.
[01:50:28.320 --> 01:50:53.320]  Я скажу, что это λ на e плюс жиранова клетка с собственным значением 0, g dt просто в n степени, где g dt это g dt от 0, напоминаю, то есть клетка с ноликами по диагонали и с единичками над диагонали.
[01:50:58.320 --> 01:51:18.320]  Ну а это уже можно вычислить при помощи бинома ньютона, правильно? По сути дела, я могу, ну, что у нас здесь происходит? Мы применяем многочлен лямбда плюс х в n степени к матрице g dt, естественно, мы можем здесь раскрыть скобки, по-другому объяснить.
[01:51:18.320 --> 01:51:32.320]  Это так, потому что вот эти вот матрицы, которые у нас здесь стоят, комментируют друг с другом, правильно? Это вот необходимое условие, чтобы формулы типа, например, бинома можно было бы применять.
[01:51:32.320 --> 01:51:58.320]  Что это такое? Это сумма по i, лямда, ну, давайте я пока так напишу, лямда e в, давайте лучше так вот сделаю, лямда e в степени n минус i на g dt в степени i на, не забыли, c из n по i.
[01:51:58.320 --> 01:52:17.320]  Ну, формально я должен написать сумму по i от 0 до n, но в реальности мне сумма по i от 0 до n не нужна, потому что нам хватит до даже d минус 1. Мы с вами уже говорили, эта клетка в d этой степени равна 0.
[01:52:17.320 --> 01:52:29.320]  Поэтому здесь у нас написано не что иное, как сумма по i от 0 до d минус 1. Давайте смотреть, что здесь у нас написано.
[01:52:29.320 --> 01:52:54.320]  C из n по i, лямда в степени n минус i, e я могу не писать, g dt в степени i. Ну и можно я, извините, перейду вот на эту доску, чтобы написать это равенство, там мне места не хватило.
[01:52:54.320 --> 01:53:16.320]  Это даже графически выглядит очень удобно, потому что мы с вами знаем, граждане, что такое жирного клетка с 0 в степени i. Это означает, что просто единички сдвинулись на i в диагонали и вправо, правильно?
[01:53:16.320 --> 01:53:30.320]  Поэтому на самом деле что у нас здесь будет? 0 слагаемое даст нам, побольше я матрицу нарисую, даст нам лямда в n стоящая по диагонали.
[01:53:30.320 --> 01:53:45.320]  Первое слагаемое, умноженное на g в первой, даст нам c из n по 1, лямда в n минус 1 на следующей диагонали.
[01:53:45.320 --> 01:54:00.320]  Следующее слагаемое даст нам c из n по 2, лямда в n минус 2 на еще следующей диагонали и так далее.
[01:54:00.320 --> 01:54:18.320]  Вот эта жирная клетка в n степени, это будет такая матрица, на каждой побочной диагонали стоит одно и то же число, повторяющееся несколько раз, и мы видим, какие это числа.
[01:54:18.320 --> 01:54:31.320]  Клетку мы с вами научились возводить в n степень, а значит и всю матрицу мы тоже научились возводить в степень.
[01:54:31.320 --> 01:54:56.320]  Давайте я оставлю в качестве легкого упражнения следующую формулу.
[01:54:56.320 --> 01:55:04.320]  По сути дела вы ее уже знаете, но вот полезно это понимать.
[01:55:04.320 --> 01:55:31.320]  Если мы возьмем многочлен P над нашим полем, то на самом деле мы можем написать, как выглядит применение этого многочлена к нашей жардановой клетке.
[01:55:31.320 --> 01:55:59.320]  А выглядит он вот так, P от лямда умножить на e, плюс P штрих от лямда умножить на j, плюс угадайте следующий член.
[01:55:59.320 --> 01:56:24.320]  Естественно, для того, чтобы эту формулу написать, нам нужно, чтобы характеристика поля была соответствующей, чтобы в знаменателях не появлялось нулей.
[01:56:24.320 --> 01:56:43.320]  Внимание, это верно, естественно, если характеристика поля равна нулю или характеристика поля достаточно большая.
[01:56:43.320 --> 01:56:50.320]  Ну достаточно большая, это больше, чем степень многочлена, естественно.
[01:56:50.320 --> 01:56:59.320]  Еще раз повторяю, упражнение несложное, достаточно осознать все то, что мы уже знаем про ту формулу, которую вы перед собой видите.
[01:56:59.320 --> 01:57:11.320]  На сегодня все, в следующий раз мы поговорим, в частности, об общей формуле для линейной рекурренты над произвольным полем.
[01:57:11.320 --> 01:57:19.320]  Я сразу хочу сказать, что тем, кому сообщили эту формулу на ОКТЧ, сообщили ее не совсем над любым полем.
