[00:00.000 --> 00:16.000]  Вопрос, как проверить, что мы проставили memory-order правильно, но правильным единственно верным способом является защита, желательно мне.
[00:16.000 --> 00:22.000]  Чтобы я посмотрел глазами, правильно ли мы поставили memory-order и разобрались вообще, каким принципом ты их расставлял.
[00:23.000 --> 00:34.000]  Не только важно, чтобы они попали в правильные, а в первую очередь важна логика, которую ты руководствовался, когда их выбирал, что ты с чем синхронизировал, какую цель ты преследовал.
[00:34.000 --> 00:41.000]  Мы же на прошлом семинале говорили про release-acquire, помните этот пример, мы с вами разбирали, да?
[00:41.000 --> 00:51.000]  И тут же не просто нужно было ставить, что load – это, наверное, acquire, store – это release, а логика была такой, что мы пытались понять, что мы с чем упорядочиваем, какие неатомарные обращения.
[00:51.000 --> 00:59.000]  Вот первая запись в буфер, вот здесь какой-то слот, должна быть упорядочена с первым чтением, а первое чтение должно быть упорядочено со второй записью, чтобы не было гонки.
[00:59.000 --> 01:13.000]  И мы дальше смотрели, какие же отношения нужно выстроить между этими чтениями и записями, чтобы достичь нужной гарантии, чтобы было отсутствие гонок и была видимость записи в чтениях.
[01:13.000 --> 01:18.000]  Вот это в первую очередь важно, никакой автоматики и такое понимание не проверить, разумеется.
[01:18.000 --> 01:26.000]  Еще одна проблема, которая здесь есть, техническая, в том, что вот у тебя процессор сам по себе не может...
[01:26.000 --> 01:36.000]  Ну вот наш процессор, если бы у нас были ARM, было бы интереснее, но у нас Intel, и там memory-памяти процессора самая достаточно сильная, и release и acquire комплиируются просто в move.
[01:36.000 --> 01:41.000]  Это означает, что слабее, чем move, ты получить просто... слабее, чем release и acquire, семантик, ты получить не можешь.
[01:41.000 --> 01:53.000]  И даже если ты используешь везде чтение с relax, и после чтения с relax ты делаешь выводы о содержимом других ячеек памяти, что вообще говоря нельзя делать, все равно у тебя будет код работать.
[01:53.000 --> 02:00.000]  Но вообще-то thread sanitizer умеет такое отслеживать.
[02:00.000 --> 02:09.000]  Даже вот в этом примере, хоть у нас и невозможно было получить семантику слабее, чем release и acquire, если бы мы написали здесь где-нибудь relax в неправильном месте,
[02:09.000 --> 02:23.000]  и запустили бы код с thread sanitizer, что мы в прошлый раз делали, то мы видели, что он ошибку находит.
[02:23.000 --> 02:25.000]  Ну, надеюсь, найдет сейчас.
[02:31.000 --> 02:37.000]  Да, он это есть нашел, потому что он не то что проверяет...
[02:37.000 --> 02:48.000]  thread sanitizer действует по-другому, он не то чтобы ловит вот какие-то последствия проявления железной модели памяти, нет, он прямо отслеживает в программе happens before,
[02:48.000 --> 02:56.000]  то есть он обнаруживает гонки по определению, два неотомарных обращения к памяти конфликтующих, которые неупрядочно через happens before.
[02:56.000 --> 03:06.000]  Как он это делает, это вообще очень интересная алгоритмическая задача, инженерная задача, и я про это поговорю, наверное, не сегодня, мы пока еще не разобрались с такими более базовыми вещами.
[03:06.000 --> 03:14.000]  Но вот этот инструмент, он независимо от того, какая модель процессора под тобой, какие-то гонки может поймать, не все.
[03:14.000 --> 03:20.000]  Но если вот ты где-то переборщил и прям relax выставил, то он это заметит.
[03:20.000 --> 03:31.000]  Вот нарушение sequential consistency, вот какие-то такие тонкости он не почувствует, не почувствует, скорее всего.
[03:31.000 --> 03:41.000]  То есть тебе может быть нужна sequential consistency, у тебя будет release require написан, и этого будет где-то недостаточно вдруг, вот он этого не заметит.
[03:41.000 --> 03:50.000]  Кроме того, еще почему сложно проверить, насколько хорошо ты это сделал, ты можешь проверить, что у тебя достаточные memory orders, но ты не можешь проверить, что они minimally.
[03:50.000 --> 03:54.000]  Может быть, где-то можно оптимальнее поступить, может быть, ты где-то лишнее выбрал, вот опять.
[03:54.000 --> 03:59.000]  Это может сделать, вообще говоря, только человек, который понимает, что за задача решается.
[03:59.000 --> 04:04.000]  Так что правильный способ – это приходить на защиту и разговаривать, потому что модель памяти – это самое сложное, что у нас в курсе.
[04:04.000 --> 04:11.000]  Не то, что самое сложное, это такая отдельная перпендикулярная всему сложность, и там глубина очень сложная, это очень большая.
[04:11.000 --> 04:21.000]  Но вообще ставить memory orders в нашем курсе – это очень хорошая идея, потому что опять тема перпендикулярна всему, и весь код, который мы пишем, можно этими memory orders ускорять.
[04:21.000 --> 04:26.000]  Вот чем дальше мы пишем файберы, тем меньше там mutex в хороших реализациях.
[04:26.000 --> 04:31.000]  Вот в Домашке вас просят написать mutex для файберов без взаимного исключения с lock-free.
[04:31.000 --> 04:38.000]  В weight-группе вас просят обойтись, там тоже поменьше mutex вставить, используется тамарная операция.
[04:38.000 --> 04:44.000]  В самом планировщике, который у нас сейчас плохой, в субботу станет хорошим, но у меня, по крайней мере.
[04:44.000 --> 04:50.000]  Там тоже будет мало блокировок, и тоже будет много lock-free.
[04:50.000 --> 04:52.000]  Ну и у нас в Домашке сейчас про lock-free.
[04:52.000 --> 04:57.000]  Короче, вот сейчас, в данный момент курса, мы переходим к сложным вещам уже, к содержателям,
[04:57.000 --> 05:01.000]  и появляется очень много мест, где можно вот таким образом код оптимизировать.
[05:01.000 --> 05:05.000]  И мы сейчас вот этот код оптимизируем, потом оптимизируем сам планировщик,
[05:05.000 --> 05:12.000]  и вот в конце курса, если с теми, кто хочет закрыть курс на отличный, причем на хороший, основательный, отличный,
[05:12.000 --> 05:17.000]  мы сможем собрать в итоге полную библиотеку и ее протестируем на производительности.
[05:17.000 --> 05:21.000]  Это можно сделать только ближе к концу, когда все вместе соберется.
[05:21.000 --> 05:25.000]  Вот сейчас мы можем оптимизировать файберы, но под ними сейчас очень медленный планировщик.
[05:25.000 --> 05:31.000]  Если вы запустите профайлер, посмотрите на Flame Graph, чем ваш код занимается,
[05:31.000 --> 05:35.000]  то вы увидите, что он занимается, в общем, каким-то сомнительными делами.
[05:35.000 --> 05:38.000]  Он делает явно не то, что он должен делать.
[05:38.000 --> 05:42.000]  В смысле, тратит время не там, где он должен его тратить.
[05:42.000 --> 05:46.000]  Так что пока мы просто пишем код и стараемся писать его оптимально,
[05:46.000 --> 05:51.000]  а когда у нас все компоненты сложатся вместе, мы сможем прям быстрые и быстрые файберы сделать,
[05:51.000 --> 05:53.000]  то есть построить такой быстрый ГО.
[05:53.000 --> 05:58.000]  И в принципе тут никаких ограничений нет, потому что мы с вами в курсе не делаем что-то игрушечное,
[05:58.000 --> 06:01.000]  мы пишем настоящий ГО без всяких скидок.
[06:01.000 --> 06:05.000]  То есть вы можете закончить его с ГО, который может быть лучше.
[06:05.000 --> 06:08.000]  Но это только от вас зависит, что вы напишете в конце.
[06:08.000 --> 06:13.000]  И вот если вы на каждом этапе делаете все хорошо, то в конце что-то хорошее выйдет.
[06:13.000 --> 06:19.000]  Но в любом случае мы профилируем, в конце увидим, где у вас там время тратится, что можно пооптимизировать.
[06:19.000 --> 06:26.000]  Но да, я указываю на это, что давайте стараться, раз уж мы про Memory Order узнали,
[06:26.000 --> 06:31.000]  стараться их использовать, стараться думать, как учиться их правильно использовать.
[06:31.000 --> 06:33.000]  Такой затяжной ответ был на твой вопрос.
[06:33.000 --> 06:36.000]  Но вроде я все, что мог, сказал.
[06:36.000 --> 06:46.000]  Я могу указать, что ты слабее, и мне в первую очередь важно понять, как ты рассуждаешь.
[06:46.000 --> 06:51.000]  Правильно ли ты рассуждал, когда эти Memory Orders ставил.
[06:51.000 --> 06:54.000]  Это важнее, чем угадать правильно.
[06:57.000 --> 07:03.000]  Давайте какие-нибудь вопросы накидайте, мне наверняка вот что-то волнует, что-то вам непонятно.
[07:03.000 --> 07:05.000]  Может быть, вам непонятно, что происходит.
[07:05.000 --> 07:08.000]  Вот вы сейчас в такой точке курса, вы не понимаете, что происходит.
[07:08.000 --> 07:14.000]  Где мы, что мы делаем, зачем мы что-то делаем, каковы наши цели?
[07:18.000 --> 07:21.000]  Нет, если все понятно, то это хорошо, но если...
[07:21.000 --> 07:27.000]  В Slipform мы можем использовать... Смотри, задача...
[07:28.000 --> 07:37.000]  Ответ такой. У нас в задачах, по крайней мере, по моей задумке, нет искусственных ограничений.
[07:37.000 --> 07:41.000]  Вот у тебя есть задача, как задача на работе, задача просто в жизни.
[07:41.000 --> 07:44.000]  У тебя есть инструменты, доступные тебе для ее решения.
[07:44.000 --> 07:49.000]  И вот ты используешь инструменты, доступные тебе для того, чтобы решить данную тебе задачу.
[07:49.000 --> 07:52.000]  Ну вот, ты можешь делать все.
[07:52.000 --> 07:58.000]  Если я тебе что-то запрещаю, то мы оба должны понимать, почему я тебе это запрещаю.
[07:58.000 --> 08:03.000]  Если я тебе запрещаю что-то, потому что мне так не нравится, это плохой аргумент с моей стороны.
[08:03.000 --> 08:07.000]  Если у тебя есть инструмент, он решает... У тебя есть задача, у тебя есть в ней проблема,
[08:07.000 --> 08:13.000]  некоторые есть инструменты, которые эту проблему решают, но вот используй его, видимо, инструменты нужны.
[08:13.000 --> 08:18.000]  Мы не пытаемся понять, что можно использовать, что нельзя использовать.
[08:18.000 --> 08:20.000]  Используй все, что тебе нужно.
[08:20.000 --> 08:23.000]  Вот как ты код будешь просто в жизни писать.
[08:23.000 --> 08:26.000]  Никто не говорит, вот такие вот ограничения на реализацию.
[08:26.000 --> 08:28.000]  Нет, ты просто пишешь решение задачи.
[08:31.000 --> 08:36.000]  Вот конкретно Per Defer, ну вот да, его, видимо, нужно использовать, потому что, видимо, он дает тебе...
[08:37.000 --> 08:42.000]  Он решает ровно твою проблему, что тебе нужно упорядочить задачи Sleefer, засыпание,
[08:42.000 --> 08:48.000]  пробуждение в колбеке по таймеру и засыпание в текущем потоке картины.
[08:48.000 --> 08:50.000]  То есть ты можешь остановиться в текущем...
[08:50.000 --> 08:54.000]  Еще не успеть остановиться в текущем потоке, но уже завести таймер.
[08:54.000 --> 09:00.000]  Этот таймер быстро сработает, и картина запустится в другом потоке, пулопоток.
[09:00.000 --> 09:02.000]  И в итоге у тебя получится гонка.
[09:02.000 --> 09:07.000]  Ты уже активировал контекст исполнения, который еще не успел сохранить.
[09:07.000 --> 09:09.000]  И в итоге у тебя программа разваливается.
[09:09.000 --> 09:12.000]  Ну, тебе, видимо, нужно упорядочить два этих шага.
[09:12.000 --> 09:16.000]  И вот Defer, он это позволяет делать, собственно, поэтому в условии и было написано.
[09:16.000 --> 09:19.000]  Сейчас, давай мы вернемся в условие.
[09:19.000 --> 09:21.000]  Где-то...
[09:21.000 --> 09:23.000]  Так давно это было уже.
[09:23.000 --> 09:25.000]  Вот.
[09:31.000 --> 09:34.000]  Где-то написано, что планировать задачи можно по-разному.
[09:34.000 --> 09:39.000]  Вот есть DeferDispatch и есть, мне кажется, очень хорошая презентация,
[09:39.000 --> 09:41.000]  которая отвечает на все вопросы, как что работает.
[09:41.000 --> 09:44.000]  Ну, вот, в принципе, все, что здесь есть, можно использовать.
[09:44.000 --> 09:51.000]  Вот, например, Strand есть, которые у нас были на предпоследней лекции.
[09:51.000 --> 09:54.000]  Экзекьюторы на предпоследней были.
[09:54.000 --> 10:01.000]  И Strand появились, которые позволяют цепочку задач прямо выстроить так, чтобы они не пересекались во время.
[10:01.000 --> 10:03.000]  То есть, критические секции запускать.
[10:03.000 --> 10:07.000]  В принципе, можно прямо Strand приделать задачу, но это будет тяжеловесное решение.
[10:07.000 --> 10:15.000]  Более легковесное решение — это Defer, который откладывает планирование задачи до тех пор, пока не завершилось текущие.
[10:15.000 --> 10:17.000]  Но в любом случае, это не то, чему мы в задаче учимся.
[10:17.000 --> 10:20.000]  Мы в задаче не про то, чтобы исследовать, чтобы узнать про Defer.
[10:20.000 --> 10:22.000]  Это, скорее, какой-то костыль, который у ASIO есть.
[10:22.000 --> 10:29.000]  На самом деле, мы хотим все же для файберов использовать простые экзекьюторы,
[10:29.000 --> 10:32.000]  которые в задаче следующей предэкзекьюторы есть.
[10:32.000 --> 10:36.000]  Вот планировщик, который умеет просто запланировать задачу на исполнение.
[10:36.000 --> 10:39.000]  И ничего больше не знает про нее.
[10:39.000 --> 10:47.000]  То есть, нет никаких более тонких семантик, типа запланировать строго, пост и текущий?
[10:47.000 --> 10:51.000]  Нет. Мы хотим использовать более общие механизмы планирования.
[10:51.000 --> 10:59.000]  Так что, видимо, решение, которое мы найдем для задачи, для проблемы в задаче Slip4, оно не является хорошим.
[10:59.000 --> 11:05.000]  Но вот в задаче Mutex, собственно, она и продолжает этот Slip4, и поэтому она от нее зависит.
[11:05.000 --> 11:14.000]  Вот решая уже задачу Mutex, нам требуется, от нас требует найти более универсальное решение.
[11:14.000 --> 11:21.000]  Ну потому что вот проблема, которая у нас возникала, это всего лишь частный случай более общей проблемы.
[11:21.000 --> 11:30.000]  Ну вот мы строим в Mutex, и там нужно добавить себя в очередь, файбер в очередь, а потом уснуть.
[11:30.000 --> 11:39.000]  Смотрите, вот задача Slip4, запланировать возобновление файбера, это подписаться на таймер.
[11:39.000 --> 11:47.000]  В случае с Mutex, запланировать возобновление файбера, это положить себя в очередь, с которой нас достанут, разбудят.
[11:47.000 --> 11:50.000]  Ну то есть выглядит совсем по-другому, но смысл тот же.
[11:50.000 --> 11:55.000]  Когда мы говорим yield, то мы засыпаем и сразу просыпаемся.
[11:55.000 --> 12:01.000]  В случае с Future, когда у нас есть некоторая асинхронная операция, есть представление ее результаты в виде Future,
[12:01.000 --> 12:08.000]  то мы подписываемся на наполнение этой Future, и там себя резюмим.
[12:08.000 --> 12:13.000]  Ну короче, можно придумать себе самые разные сценарии, в которых файбер чего-то ждет, а потом просыпается.
[12:13.000 --> 12:20.000]  И все эти сценарии, они про ту же самую проблему, что нужно аккуратно заснуть до того, как мы можем проснуться.
[12:20.000 --> 12:28.000]  И вот в задаче как раз говорится, что вот есть самые разные сценарии, они все не похожи друг на друга, но у них должно быть общее решение.
[12:28.000 --> 12:34.000]  И это решение, разумеется, не defer, потому что наши экзекьюторы под капотом не будут уметь ничего, кроме просто запускать задачу,
[12:34.000 --> 12:37.000]  но и Тредпулутов не умеет и не хочет уметь.
[12:37.000 --> 12:44.000]  Поэтому мы должны придумать какое-то более универсальное решение, которое мы назовем Awaiter.
[12:44.000 --> 12:52.000]  Awaiter – это та стратегия, которая в себе инкапсулирует логику возобновления файбра.
[12:52.000 --> 13:02.000]  Ну и в задаче дана серьезная подсказка, как с этими Awaiter-ами работать и как правильно декомпозировать код.
[13:02.000 --> 13:10.000]  И вот в хорошем решении у вас будет FiberCore, вот этот кусочек кода, кусочек библиотеки.
[13:10.000 --> 13:21.000]  И предполагается, что добавление новых приметивов синхронизации от вас не потребует доработки вот этой директории.
[13:21.000 --> 13:26.000]  Вы один раз там какую-то универсальную логику реализуете, которая не знает ни про файб...
[13:26.000 --> 13:27.000]  Ой, не про файбр.
[13:27.000 --> 13:35.000]  Не про там каналы будущие, не про селектант-каналами, не про фьютексы, не про Yield можно даже не знать.
[13:35.000 --> 13:39.000]  Вот Yield можно вполне себе переместить в другую директорию и просто использовать...
[13:39.000 --> 13:42.000]  То есть не нужно Fiber узнать про операцию Yield.
[13:42.000 --> 13:46.000]  Не нужно прямо в Fiber какую-то логику Yield'а писать.
[13:46.000 --> 13:48.000]  Не нужно в Fiber делать метод Yield.
[13:48.000 --> 13:51.000]  Вот в задаче Coroutine мы, конечно, с этого начинали.
[13:51.000 --> 13:57.000]  Мы вот в этой задаче как делали Yield, который нам был нужен?
[13:57.000 --> 13:59.000]  Вот там Fiber пока ничего другого не умели.
[13:59.000 --> 14:01.000]  И мы в этой операции Yield что делали?
[14:01.000 --> 14:03.000]  Выходили из Coroutine, а внутри Fiber смотрели.
[14:03.000 --> 14:06.000]  Если она завершилась, то, видимо, нужно разрушить Fiber.
[14:06.000 --> 14:10.000]  А если не завершилось, то точно был сделан Yield, значит, мы это знаем.
[14:10.000 --> 14:12.000]  Просто метод исключения, больше ничего и нет.
[14:12.000 --> 14:17.000]  И поэтому бросали Fiber обратно исполняться в планировщик.
[14:17.000 --> 14:22.000]  То есть мы прямо захард кодили Fiber и логику Yield'а.
[14:22.000 --> 14:27.000]  А теперь мы столкнулись со Sleep Forum и поняли, что вот хочется обобщить немного.
[14:27.000 --> 14:32.000]  Хочется уже не тащить Fiber знания про таймер и про засыпание.
[14:32.000 --> 14:35.000]  А теперь мы делаем прям совсем универсальные решения,
[14:35.000 --> 14:46.000]  так чтобы Fiber ничего не знали про приметивы синхронизации, про блокирующие ожидания.
[14:46.000 --> 14:48.000]  И в итоге код Fiber только упростится.
[14:48.000 --> 14:50.000]  Он станет более универсальным.
[14:50.000 --> 14:54.000]  Но для этого нужно придумать, что такое Awaiter, зачем Fiber Handle,
[14:54.000 --> 14:59.000]  ну и сделать код по оптимальне.
[14:59.000 --> 15:01.000]  Хорошее решение получится в хорошем смысле.
[15:01.000 --> 15:03.000]  Вы поймете, что оно хорошее.
[15:03.000 --> 15:04.000]  Там все будет очень гармонично.
[15:04.000 --> 15:06.000]  Это вообще такой верный признак, что вы делаете все правильно.
[15:06.000 --> 15:10.000]  Если вы смотрите на код и думаете, боже, какое уродство, неужели от меня это вы хотели.
[15:10.000 --> 15:13.000]  Ну, во-первых, не нужно думать о том, что от вас хотели,
[15:13.000 --> 15:15.000]  потому что откуда вы знаете.
[15:15.000 --> 15:19.000]  Вы решаете просто задачу, которая спустилась на вас с неба.
[15:19.000 --> 15:23.000]  И вы не знаете, есть ли у него хорошее решение или нет в общем случае.
[15:23.000 --> 15:26.000]  Но так уж и быть, я вам скажу, что здесь хорошее решение есть.
[15:26.000 --> 15:29.000]  Мы его разбираем.
[15:29.000 --> 15:33.000]  Хорошее решение выглядит довольно гармонично.
[15:33.000 --> 15:41.000]  Хорошее решение – это решение, в котором связность маленькая.
[15:41.000 --> 15:43.000]  Разные части кода мало знают друг про друга.
[15:43.000 --> 15:46.000]  Поэтому легко о них думать в изоляции.
[15:46.000 --> 15:49.000]  Так что если вы пишете хорошее решение, то, скорее всего, вы понимаете, что оно хорошее,
[15:49.000 --> 15:52.000]  потому что оно такое локальное.
[15:52.000 --> 15:55.000]  Вам не нужно думать, что происходит в другом месте далеко.
[15:55.000 --> 15:57.000]  Вам не нужно думать, как устроен планировщик.
[15:57.000 --> 16:00.000]  Вы пишете фибер и не думаете про фьютаксы.
[16:00.000 --> 16:06.000]  Вы пишете фьютаксы и не думаете про планировщик и про механику фиберов,
[16:06.000 --> 16:09.000]  что там внутри написано.
[16:09.000 --> 16:12.000]  Хорошим решением такая связанность очень низкая,
[16:12.000 --> 16:14.000]  и рассуждать о коде просто.
[16:14.000 --> 16:17.000]  И поэтому он кажется, собственно, хорошим.
[16:17.000 --> 16:21.000]  О нем просто думать.
[16:21.000 --> 16:28.000]  Забегая вперед, осенью, когда мы будем писать распределенные системы,
[16:28.000 --> 16:31.000]  там вообще будет очень много кода.
[16:31.000 --> 16:34.000]  Но процента 95 кода напишу я.
[16:34.000 --> 16:36.000]  А вам нужно будет...
[16:36.000 --> 16:38.000]  Ну, то есть, сложность, конечно, в реализации распределенной системы
[16:38.000 --> 16:41.000]  не в том, чтобы написать алгоритмы, а в том, чтобы все вокруг написать.
[16:41.000 --> 16:46.000]  Но все вокруг очень сложно написать, поэтому научить этому невозможно на третьем курсе.
[16:46.000 --> 16:49.000]  Ну, и для этого нужно потратить несколько лет.
[16:49.000 --> 16:53.000]  Но суть в том, что очень много кода, очень высокая сложность.
[16:53.000 --> 16:57.000]  И чтобы ее поддерживать вообще в уме, чтобы один человек с этим мог справиться,
[16:57.000 --> 17:00.000]  нужно, чтобы были очень четкие границы,
[17:00.000 --> 17:02.000]  чтобы мы опирались на абстракции, чтобы мы не думали про то,
[17:02.000 --> 17:04.000]  как устроено все вокруг.
[17:04.000 --> 17:07.000]  Мы бы работали с одним компонентом, развивали бы его,
[17:07.000 --> 17:12.000]  а другие компоненты, детали их реализации из ума можно было бы вынуть.
[17:12.000 --> 17:17.000]  Вот мы сейчас сделаем то же самое, только в гораздо более мелком масштабе.
[17:17.000 --> 17:19.000]  Но проблемы те же самые.
[17:19.000 --> 17:24.000]  Чем лучше код, тем проще думать о нем, тем проще думать об отдельных его кусочках
[17:24.000 --> 17:27.000]  и взоряться от остальных.
[17:27.000 --> 17:33.000]  Вот мы пишем фьютекс в этом коде, и ему мало что нужно знать про...
[17:33.000 --> 17:37.000]  Ну, вообще, в этом коде это шаблон, он будет...
[17:37.000 --> 17:41.000]  Шаблон обязательно в хедре должен быть реализован.
[17:41.000 --> 17:45.000]  И вот в этом коде не должно быть просто знания про файбер вообще никакого,
[17:45.000 --> 17:47.000]  то есть если мы заинклюрируем здесь файбер, то все,
[17:47.000 --> 17:49.000]  эта деталь реализации попадет в пользователя.
[17:49.000 --> 17:53.000]  А мы не хотим, чтобы она попала в пользователя.
[17:53.000 --> 17:58.000]  Мы не хотим, чтобы пользователь вообще знал и имел доступ к структуре файбера.
[17:58.000 --> 18:02.000]  Поэтому у нас есть вот некоторые файбер-хэндл,
[18:02.000 --> 18:04.000]  который от нас, от пользователя...
[18:04.000 --> 18:07.000]  То есть это штука, которая позволяет нам пользователям
[18:07.000 --> 18:11.000]  писать новые примитивы синхронизации для файберов,
[18:11.000 --> 18:13.000]  расширять их поведение,
[18:13.000 --> 18:17.000]  но при этом не знать про то, как файберы устроены.
[18:21.000 --> 18:24.000]  Ну, и еще забегая вперед, вот этот дизайн,
[18:24.000 --> 18:26.000]  который мы в этой задаче придумываем,
[18:26.000 --> 18:33.000]  он для нас важен, потому что уже через неделю,
[18:33.000 --> 18:35.000]  то есть не в эту субботу, а в следующую,
[18:35.000 --> 18:38.000]  мы будем говорить, как быстро время бежит,
[18:38.000 --> 18:42.000]  мы уже будем говорить про стеклоскорутины в C++.
[18:42.000 --> 18:47.000]  И вот дизайн стеклоскорутин, вот он такой, как в этой задаче.
[18:47.000 --> 18:49.000]  Ну или эта задача.
[18:49.000 --> 18:52.000]  В этой задаче такой же дизайн, как в стеклоскорутинах.
[18:52.000 --> 18:55.000]  Короче, если вы сейчас это придумаете,
[18:55.000 --> 18:57.000]  то вы поймете, как устроены корутины в C++.
[18:57.000 --> 18:59.000]  И наша цель в том числе и в этом.
[18:59.000 --> 19:01.000]  Ну то есть с одной стороны файберы сделать,
[19:01.000 --> 19:05.000]  а с другой стороны разобраться, как в C++
[19:05.000 --> 19:08.000]  сделали стеклоскорутины, которые...
[19:08.000 --> 19:13.000]  Я вам показывал их много раз уже.
[19:13.000 --> 19:16.000]  Можно еще раз показать.
[19:16.000 --> 19:18.000]  Как все это работает под капотом.
[19:18.000 --> 19:20.000]  Там довольно сложная механика,
[19:20.000 --> 19:22.000]  но вот эта докуменция точно не способ,
[19:22.000 --> 19:25.000]  как ее можно изучить.
[19:25.000 --> 19:27.000]  Но в общем, под капотом там все довольно затерево,
[19:27.000 --> 19:29.000]  и вот эти корутины, они тоже сделаны так,
[19:29.000 --> 19:31.000]  чтобы их можно было расширять,
[19:31.000 --> 19:33.000]  в смысле, кастомизировать их поведение.
[19:33.000 --> 19:35.000]  Что именно они здесь делают?
[19:35.000 --> 19:37.000]  Это не компаниятор решает, не библиотека решает,
[19:37.000 --> 19:39.000]  мы пользователи.
[19:39.000 --> 19:41.000]  И с файберами точно такая же история.
[19:41.000 --> 19:47.000]  Мы сами решаем, как делать блокирующие ожидания.
[19:47.000 --> 19:51.000]  Чего файберы вообще дожидаются, когда они засыпают?
[19:51.000 --> 19:55.000]  Мы как пользователи можем расширять их поведение.
[19:55.000 --> 19:57.000]  Так что вот задача, она в том числе про то,
[19:57.000 --> 19:59.000]  чтобы изучить некоторый глобальный дизайн,
[19:59.000 --> 20:01.000]  который в C++ используется, и в C sharp используется,
[20:01.000 --> 20:04.000]  и в некоторых других языках.
[20:04.000 --> 20:08.000]  Такой вот довольно масштабный замысел за всем этим стоит.
[20:15.000 --> 20:17.000]  Вот я бы хотел, чтобы в следующий раз
[20:17.000 --> 20:22.000]  мы бы уже на семинаре столько всего,
[20:22.000 --> 20:25.000]  как мы это все успеем вообще не понять.
[20:25.000 --> 20:27.000]  Нужно про слабой модели поговорить,
[20:27.000 --> 20:29.000]  нужно про троценитайзер поговорить,
[20:29.000 --> 20:31.000]  нужно про лукфрии поговорить.
[20:31.000 --> 20:34.000]  Нам нужно в два раза больше семинар.
[20:34.000 --> 20:36.000]  Непонятно.
[20:36.000 --> 20:38.000]  Останемся не очень, ужасно.
[20:38.000 --> 20:41.000]  Так вот, на следующем семинаре я бы хотел,
[20:41.000 --> 20:44.000]  чтобы мы просто устроили код-ребью такой,
[20:44.000 --> 20:46.000]  более-менее массовый, но не то, что массовый,
[20:46.000 --> 20:48.000]  но в таком составе нам подойдет.
[20:48.000 --> 20:50.000]  Но нужно, чтобы вы пришли с решением,
[20:50.000 --> 20:52.000]  а там уже до длани стучит, кажется,
[20:52.000 --> 20:54.000]  у вас будет повод прийти с решением.
[20:54.000 --> 20:58.000]  И мы обсудим его, насколько оно хорошим получилось у вас.
[20:59.000 --> 21:02.000]  Да, вот это задача про Mutex.
[21:06.000 --> 21:08.000]  Мне кажется, что это разумнее будет сделать
[21:08.000 --> 21:10.000]  прямо на семинаре, потому что,
[21:10.000 --> 21:12.000]  ну, прямо скажем, вот эта задача,
[21:12.000 --> 21:14.000]  она уже, будь здоров, про дизайн,
[21:14.000 --> 21:16.000]  она довольно сложная,
[21:16.000 --> 21:18.000]  и тут много подсказок в условии,
[21:18.000 --> 21:20.000]  но, может быть, вы не все поймете
[21:20.000 --> 21:22.000]  или не все сделаете хорошо,
[21:22.000 --> 21:24.000]  и нам нужно вместе всем посмотреть на это,
[21:24.000 --> 21:26.000]  подумать, а как можно сделать хорошо,
[21:26.000 --> 21:28.000]  что можно улучшить.
[21:28.000 --> 21:30.000]  Нет, ну, конечно, попытайтесь сами в первую очередь,
[21:30.000 --> 21:32.000]  но, короче, я вас ожидаю,
[21:32.000 --> 21:34.000]  что в следующую среду
[21:34.000 --> 21:36.000]  я посмотрю на какой-то ваш код,
[21:36.000 --> 21:38.000]  и вы сами мне расскажете,
[21:38.000 --> 21:40.000]  что вы пытались сделать,
[21:40.000 --> 21:42.000]  что вам не нравится в этом коде,
[21:42.000 --> 21:44.000]  и мы подумаем, как его можно улучшить.
[21:44.000 --> 21:46.000]  Для начала вы должны его написать,
[21:46.000 --> 21:48.000]  и вам он должен не нравиться.
[21:48.000 --> 21:50.000]  Ну, или вы напишите код,
[21:50.000 --> 21:52.000]  он вам понравится, это лучку,
[21:52.000 --> 21:54.000]  которую вы писали в жизни,
[21:54.000 --> 21:56.000]  и вы можете посмотреть.
[21:56.000 --> 21:58.000]  Тут вопрос про дизайн уже,
[21:58.000 --> 22:00.000]  дизайн — это такая очень сложная тема,
[22:00.000 --> 22:02.000]  очень сложный топик,
[22:02.000 --> 22:04.000]  он требует довольно большого программирования,
[22:04.000 --> 22:06.000]  которого у нас пока нет,
[22:06.000 --> 22:08.000]  так что нужно этому учиться.
[22:08.000 --> 22:10.000]  И еще что-нибудь?
[22:14.000 --> 22:16.000]  Ну, не знаю,
[22:16.000 --> 22:18.000]  пойдемте вы, наверное,
[22:18.000 --> 22:20.000]  про лок-фри поговорить.
[22:20.000 --> 22:22.000]  Про лок-фри, а про модели памяти мы не хотим поговорить?
[22:22.000 --> 22:24.000]  Просто мы остановились,
[22:24.000 --> 22:26.000]  мы разобрали два примера с вами, да?
[22:28.000 --> 22:30.000]  Мы с вами разобрали спинлок,
[22:32.000 --> 22:34.000]  поставили там барьеры памяти.
[22:36.000 --> 22:38.000]  Мы хотели упорядочить записи
[22:38.000 --> 22:40.000]  в предшествующей секции с чтениями
[22:40.000 --> 22:42.000]  в последующей секции, но вообще обращение
[22:42.000 --> 22:44.000]  конфликтующей в предшествующей и последующей.
[22:44.000 --> 22:46.000]  Мы сказали, что у нас есть предшествующие и последующие,
[22:46.000 --> 22:48.000]  потому что есть modification order
[22:48.000 --> 22:50.000]  на одном атомике.
[22:50.000 --> 22:52.000]  А дальше мы сказали, что как обеспечить
[22:52.000 --> 22:54.000]  видимость записи из предшествующей секции
[22:54.000 --> 22:56.000]  в последующей, сделать happens before.
[22:56.000 --> 22:58.000]  А что нужно сделать, чтобы получить
[22:58.000 --> 23:00.000]  happens before? Нужно получить
[23:00.000 --> 23:02.000]  отношение synchronizes with.
[23:04.000 --> 23:06.000]  Это единственный способ этот happens before
[23:06.000 --> 23:08.000]  достичь.
[23:16.000 --> 23:18.000]  А он достигается, когда у нас есть
[23:18.000 --> 23:20.000]  атомарная запись, атомарное чтение,
[23:20.000 --> 23:22.000]  и чтение видит запись, и запись она
[23:22.000 --> 23:24.000]  по крайней мере с memory order release,
[23:24.000 --> 23:26.000]  а чтение по крайней мере с memory order acquire.
[23:26.000 --> 23:28.000]  И вот у нас есть
[23:28.000 --> 23:30.000]  пара запись,
[23:30.000 --> 23:32.000]  есть
[23:32.000 --> 23:34.000]  чтение, и мы крутимся
[23:34.000 --> 23:36.000]  мы здесь до тех пор, пока
[23:36.000 --> 23:38.000]  мы не увидим эту запись.
[23:38.000 --> 23:40.000]  И когда мы увидели, значит начинается
[23:40.000 --> 23:42.000]  новая секция.
[23:42.000 --> 23:44.000]  Поэтому мы здесь ставим release, здесь мы ставим
[23:44.000 --> 23:46.000]  acquire.
[23:46.000 --> 23:48.000]  Ну и опять, если мы умеем
[23:48.000 --> 23:50.000]  пользоваться, если мы знаем
[23:50.000 --> 23:52.000]  про таковую когделенность кашей, то мы конечно
[23:52.000 --> 23:54.000]  такой спинлок не пишем, да?
[23:54.000 --> 23:56.000]  Мы знаем, что
[23:56.000 --> 23:58.000]  вот порядочному
[23:58.000 --> 24:00.000]  джентльмену такой спинлок не подойдет,
[24:00.000 --> 24:02.000]  мы пишем что-нибудь такое.
[24:02.000 --> 24:04.000]  Вот.
[24:14.000 --> 24:16.000]  Ну и в домашке вы пишете
[24:16.000 --> 24:18.000]  фьютокс, там у вас будет спинлок,
[24:18.000 --> 24:20.000]  ну вот пожалуйста, напишите спинлок
[24:20.000 --> 24:22.000]  хорошо.
[24:22.000 --> 24:24.000]  Потому что еще раз, в конце
[24:24.000 --> 24:26.000]  концов, мы хотим все пооптимизировать.
[24:26.000 --> 24:28.000]  И нам каждая деталь пригодится.
[24:28.000 --> 24:30.000]  Вот если вы знаете, как хорошо написать спинлок,
[24:30.000 --> 24:32.000]  то напишите его сразу.
[24:32.000 --> 24:34.000]  Хорошо.
[24:34.000 --> 24:36.000]  Да, и я обращаю внимание в шаблоне задачи,
[24:36.000 --> 24:38.000]  я не знаю, пользуетесь вы этим или нет,
[24:38.000 --> 24:40.000]  пока я не особо замечаю.
[24:40.000 --> 24:42.000]  Но вот во всех задачах есть Victoria Support.
[24:42.000 --> 24:44.000]  И
[24:44.000 --> 24:46.000]  зачем она нужна?
[24:46.000 --> 24:48.000]  Предлагается туда складывать
[24:48.000 --> 24:50.000]  какие-то компоненты общие,
[24:50.000 --> 24:52.000]  которые
[24:52.000 --> 24:54.000]  нужны в файберах, нужны в тредпуле,
[24:54.000 --> 24:56.000]  нужны еще где-то,
[24:56.000 --> 24:58.000]  но которые имеют смысл более широкий.
[24:58.000 --> 25:00.000]  Ну скажем, мы пишем спинлок
[25:00.000 --> 25:02.000]  для фьютакса.
[25:02.000 --> 25:04.000]  Очень странно класть код спинлока прямо
[25:04.000 --> 25:06.000]  во фьютакс, потому что спинлок гораздо
[25:06.000 --> 25:08.000]  более общий примитив, чем фьютакс, и можно
[25:08.000 --> 25:10.000]  использовать в других местах.
[25:10.000 --> 25:12.000]  Вот выгодно его, разумно положить его
[25:12.000 --> 25:14.000]  туда. Или мы пишем
[25:14.000 --> 25:16.000]  вейт-группу, ну для потоков,
[25:16.000 --> 25:18.000]  для того чтобы в планировщей, в тредпуле
[25:18.000 --> 25:20.000]  ее использовать. Но опять,
[25:20.000 --> 25:22.000]  это примитив синхронизации, который более общий,
[25:22.000 --> 25:24.000]  чем тредпул, и
[25:24.000 --> 25:26.000]  вейт-группа всего лишь применяется
[25:26.000 --> 25:28.000]  в тредпуле. Опять, можно вынести ее сюда,
[25:28.000 --> 25:30.000]  в эту директорию.
[25:36.000 --> 25:38.000]  Что значит синхронизируется? Мы просто
[25:38.000 --> 25:40.000]  размещаем код в библиотеке.
[25:40.000 --> 25:42.000]  Если у нас есть компонент A
[25:42.000 --> 25:44.000]  и компонент B, и компонент
[25:44.000 --> 25:46.000]  B зависит от компонента A,
[25:46.000 --> 25:48.000]  но компонент A напрямую не связан
[25:48.000 --> 25:50.000]  с B, то видимо они должны лежать в разных
[25:50.000 --> 25:52.000]  местах.
[25:52.000 --> 25:54.000]  Но вот спинлок используется
[25:54.000 --> 25:56.000]  в файберах, но с ними
[25:56.000 --> 25:58.000]  напрямую не связан.
[25:58.000 --> 26:00.000]  Просто общий примитив синхронизации.
[26:00.000 --> 26:02.000]  Положим его отдельно.
[26:02.000 --> 26:04.000]  Вейт-группа опять используется в пуле потоков,
[26:04.000 --> 26:06.000]  но прямо к пулу потоков
[26:06.000 --> 26:08.000]  она не привязана,
[26:08.000 --> 26:10.000]  она полезна сама по себе.
[26:10.000 --> 26:12.000]  Опять можно вынести ее, положить отдельно.
[26:12.000 --> 26:14.000]  Ну вот все, что вам кажется
[26:14.000 --> 26:16.000]  таким более общим, можно складывать сюда.
[26:16.000 --> 26:18.000]  Ладно.
[26:18.000 --> 26:20.000]  Возвращаемся к
[26:20.000 --> 26:22.000]  MemoryOrder.
[26:22.000 --> 26:24.000]  Спинлок разобрали.
[26:24.000 --> 26:26.000]  Циклический буфер
[26:26.000 --> 26:28.000]  тоже в прошлый раз разобрали.
[26:28.000 --> 26:30.000]  Мы упорядочиваем обращение
[26:30.000 --> 26:32.000]  к буферу вот здесь вот и вот здесь вот.
[26:32.000 --> 26:34.000]  И что мы делали?
[26:34.000 --> 26:36.000]  Мы говорили, что у нас есть
[26:36.000 --> 26:38.000]  продюсер и консюмер, два потока всего,
[26:38.000 --> 26:40.000]  которые работают с этим буфером.
[26:40.000 --> 26:42.000]  И продюсер
[26:42.000 --> 26:44.000]  и консюмер
[26:44.000 --> 26:46.000]  и продюсер
[26:46.000 --> 26:48.000]  единственный поток,
[26:48.000 --> 26:50.000]  который увеличивал tail,
[26:50.000 --> 26:52.000]  а консюмер единственный, кто
[26:52.000 --> 26:54.000]  увеличивал head, двигал head.
[26:54.000 --> 26:56.000]  Увеличивать не совсем, конечно,
[26:56.000 --> 26:58.000]  говорить, потому что там может все зациклиться.
[26:58.000 --> 27:00.000]  В частности,
[27:00.000 --> 27:02.000]  поэтому мы
[27:02.000 --> 27:04.000]  использовали здесь чтение с relaxed.
[27:04.000 --> 27:06.000]  Потому что каждый поток видит собственные
[27:06.000 --> 27:08.000]  записи. Потому что как иначе?
[27:08.000 --> 27:10.000]  Так работает однопоточная программа.
[27:10.000 --> 27:12.000]  То есть мы полагались
[27:12.000 --> 27:14.000]  на гарантию program order, что
[27:14.000 --> 27:16.000]  чтение учитывает program order,
[27:16.000 --> 27:18.000]  не противоречит ему.
[27:18.000 --> 27:20.000]  Это мы понимаем, да?
[27:20.000 --> 27:22.000]  А теперь вопрос чуть более сложный.
[27:22.000 --> 27:24.000]  А что если два файбера,
[27:24.000 --> 27:26.000]  которые исполняются на двух разных потоках,
[27:26.000 --> 27:28.000]  работают с этим циклическим
[27:28.000 --> 27:30.000]  буфером?
[27:30.000 --> 27:32.000]  И вот вообще-то файбер может
[27:32.000 --> 27:34.000]  записать в ячейку 42
[27:34.000 --> 27:36.000]  в одном потоке
[27:36.000 --> 27:38.000]  пула,
[27:38.000 --> 27:40.000]  сделать релиз записи tail,
[27:40.000 --> 27:42.000]  а потом перезапуститься
[27:42.000 --> 27:44.000]  и продолжить работу на
[27:44.000 --> 27:46.000]  другом потоке пула и сделать чтение
[27:46.000 --> 27:48.000]  с relaxed. Вопрос.
[27:48.000 --> 27:50.000]  Откуда
[27:50.000 --> 27:52.000]  вот это чтение, почему это чтение
[27:52.000 --> 27:54.000]  непременно увидит свежее значение
[27:54.000 --> 27:56.000]  tail?
[27:58.000 --> 28:00.000]  Вот relaxed сам по себе этого не обещает.
[28:00.000 --> 28:02.000]  Relaxed говорит, что мы читаем просто некоторую
[28:02.000 --> 28:04.000]  точку под истории.
[28:04.000 --> 28:06.000]  Почему бы нам не прочесть
[28:06.000 --> 28:08.000]  старое значение?
[28:08.000 --> 28:10.000]  Потому что в текущем потоке мы еще ни разу
[28:10.000 --> 28:12.000]  ничего не писали в tail.
[28:12.000 --> 28:14.000]  Понятен вопрос?
[28:24.000 --> 28:26.000]  Пока мы пользуемся гарантией,
[28:26.000 --> 28:28.000]  что чтение не противоречит программу
[28:28.000 --> 28:30.000]  order.
[28:30.000 --> 28:32.000]  Мы читали этот tail
[28:32.000 --> 28:34.000]  даже с relaxed и мы знали,
[28:34.000 --> 28:36.000]  что мы увидим самую свежую запись, потому что она была
[28:36.000 --> 28:38.000]  в одном же потоке. Сейчас она уже в другом потоке будет.
[28:42.000 --> 28:44.000]  Как вас просто поставить в тупик?
[29:02.000 --> 29:04.000]  Давайте вот как просуждаем.
[29:04.000 --> 29:06.000]  У нас есть чтение
[29:06.000 --> 29:08.000]  в запись в ячейку памяти, а потом есть
[29:08.000 --> 29:10.000]  чтение из этой ячейки.
[29:10.000 --> 29:12.000]  И как в общем случае гарантировать,
[29:12.000 --> 29:14.000]  что чтение увидит запись?
[29:14.000 --> 29:16.000]  Главный вопрос в модели памяти.
[29:18.000 --> 29:20.000]  Но если ему в одном потоке, то он есть.
[29:20.000 --> 29:22.000]  Потому что программа order это
[29:22.000 --> 29:24.000]  часть happens before.
[29:26.000 --> 29:28.000]  А что если вот
[29:28.000 --> 29:30.000]  Fiber запустилась
[29:30.000 --> 29:32.000]  в другом потоке?
[29:34.000 --> 29:36.000]  Программа order там уже нет.
[29:36.000 --> 29:38.000]  Программа order он внутри потока,
[29:38.000 --> 29:40.000]  а мы исполнили сначала в одном, потом в другом.
[29:52.000 --> 29:54.000]  Проблема понятны?
[29:54.000 --> 29:56.000]  Вопрос понятен, с которым я к вам пристал?
[29:56.000 --> 29:58.000]  Вопрос кто делает это?
[30:02.000 --> 30:04.000]  Можно ли написать relaxed?
[30:08.000 --> 30:10.000]  Это худший способ
[30:10.000 --> 30:12.000]  просуждать о чём угодно.
[30:16.000 --> 30:18.000]  Наш код не корректен.
[30:18.000 --> 30:20.000]  Наш код корректен, когда он работает везде.
[30:20.000 --> 30:22.000]  Мы же пишем не на x86, не на
[30:22.000 --> 30:24.000]  Assembler x86, мы пишем на C++.
[30:24.000 --> 30:26.000]  У нас корректность
[30:26.000 --> 30:28.000]  понимается в смысле модели памяти языка,
[30:28.000 --> 30:30.000]  а не конкретного процессора.
[30:40.000 --> 30:42.000]  Ну код, давайте так,
[30:42.000 --> 30:44.000]  давайте проверим вашу интуицию,
[30:44.000 --> 30:46.000]  хотя бы знание мы не можем проверить пока.
[30:46.000 --> 30:48.000]  Проверим интуицию.
[30:48.000 --> 30:50.000]  Relax правильно написано или неправильно?
[30:50.000 --> 30:52.000]  Мне кажется, нет.
[30:52.000 --> 30:54.000]  Просто в этом,
[30:54.000 --> 30:56.000]  в нашем тесте у нас есть вообще,
[30:56.000 --> 30:58.000]  у нас есть два потока,
[30:58.000 --> 31:00.000]  а если что, у нас много теперь потоков
[31:00.000 --> 31:02.000]  и продюсеры переезжают
[31:02.000 --> 31:04.000]  между потоками.
[31:14.000 --> 31:16.000]  Ты сказал, что неправильно написано.
[31:16.000 --> 31:18.000]  Есть какие-то альтернативные мнения?
[31:18.000 --> 31:20.000]  Вариантов всего два.
[31:20.000 --> 31:22.000]  Есть ли оппоненты?
[31:22.000 --> 31:24.000]  Или все считают,
[31:24.000 --> 31:26.000]  что неправильно?
[31:26.000 --> 31:28.000]  Ну просто было бы
[31:28.000 --> 31:30.000]  странно, что казалось бы,
[31:30.000 --> 31:32.000]  потоки, ну смотрите,
[31:32.000 --> 31:34.000]  как можно было бы рассуждать совсем иначе,
[31:34.000 --> 31:36.000]  даже не по модели памяти.
[31:36.000 --> 31:38.000]  Вот мы пишем файберы,
[31:38.000 --> 31:40.000]  и для нас файберы это потоки.
[31:40.000 --> 31:42.000]  Вот мы как пользователи меньше всего
[31:42.000 --> 31:44.000]  хотим думать, что файберы это не потоки,
[31:44.000 --> 31:46.000]  это какие-то специальные штуки.
[31:46.000 --> 31:48.000]  Они только оперативные, то есть их не могут вытеснять.
[31:48.000 --> 31:50.000]  Но это, в общем, единственное отличие,
[31:50.000 --> 31:52.000]  на которое мы согласились.
[31:52.000 --> 31:54.000]  Вот прям серьезное, единственное отличие.
[31:54.000 --> 31:56.000]  Его, и его можно преодолеть было бы,
[31:56.000 --> 31:58.000]  просто мы не хотим, потому что
[31:58.000 --> 32:00.000]  не нужно в наших задачах.
[32:00.000 --> 32:02.000]  Но в остальном
[32:02.000 --> 32:04.000]  они должны быть неотличимы.
[32:04.000 --> 32:06.000]  А в итоге мы говорим, что с потоками это работает,
[32:06.000 --> 32:08.000]  а с файберами этого уже не работает.
[32:08.000 --> 32:10.000]  Это было бы очень странно, согласись, да?
[32:10.000 --> 32:12.000]  Кажется, что у нас какая-то плохая...
[32:12.000 --> 32:14.000]  Что?
[32:14.000 --> 32:16.000]  Ну мы же разбирались в прошлый раз.
[32:16.000 --> 32:18.000]  У нас есть программ-ордер.
[32:18.000 --> 32:22.000]  Нет, у нас сама структура для двух потоков.
[32:22.000 --> 32:24.000]  Один продюсер, один консюмер.
[32:28.000 --> 32:30.000]  Два потока всего работает.
[32:30.000 --> 32:32.000]  Только один пишет, только один читает.
[32:32.000 --> 32:34.000]  Ну иначе как мы можем двигать tail
[32:34.000 --> 32:36.000]  без синхронизации просто сторон?
[32:36.000 --> 32:38.000]  Это работает, потому что только один поток
[32:38.000 --> 32:40.000]  двигает tail.
[32:40.000 --> 32:42.000]  Вот, теперь мы меняем два потока на два файбера,
[32:42.000 --> 32:44.000]  и внезапно мы говорим, что вот
[32:44.000 --> 32:46.000]  поведение вдруг изменилось.
[32:46.000 --> 32:48.000]  В смысле, было корректно, а стало некорректно.
[32:48.000 --> 32:50.000]  Нет, я не это не ожидал.
[32:50.000 --> 32:52.000]  Ты говорил, что и с самого начала было некорректно.
[32:52.000 --> 32:54.000]  Нет, когда одна пара, все хорошо.
[32:54.000 --> 32:56.000]  Я думаю, когда несколько пар...
[32:56.000 --> 32:58.000]  Так когда несколько пар, нужно код по-другому писать вообще?
[32:58.000 --> 33:00.000]  Нет, этот код и не должен работать
[33:00.000 --> 33:02.000]  для большего числа потоков.
[33:02.000 --> 33:04.000]  Это же сингл-продюсер, сингл-консюмер.
[33:04.000 --> 33:06.000]  У любой очереди есть ограничения,
[33:06.000 --> 33:08.000]  в каком режиме она работает.
[33:08.000 --> 33:10.000]  Мы писали в Тредпуле блокирующую очередь,
[33:10.000 --> 33:12.000]  и прямо на лекции вам не просто так распинался минуту,
[33:12.000 --> 33:14.000]  что мульти-продюсер, мульти-консюмер.
[33:14.000 --> 33:16.000]  То есть мы закладываем в очередь
[33:16.000 --> 33:18.000]  такой сценарий. В смысле, что вот может быть много потоков, которые пишут,
[33:18.000 --> 33:20.000]  много потоков, которые читают.
[33:20.000 --> 33:22.000]  Здесь у нас всего два потока. Мы ограничились,
[33:22.000 --> 33:24.000]  и вот иначе не предполагаем.
[33:24.000 --> 33:26.000]  Ну, а теперь мы меняем эти потоки
[33:26.000 --> 33:28.000]  на файбера.
[33:28.000 --> 33:30.000]  И теперь вот как бы файберов два по-прежнему,
[33:30.000 --> 33:32.000]  один пишет, другой читает,
[33:32.000 --> 33:34.000]  но файбер запускается на разных поток.
[33:34.000 --> 33:36.000]  И ты в этот случай
[33:36.000 --> 33:38.000]  что говоришь, что правильно релакс стоит или неправильно?
[33:38.000 --> 33:40.000]  Да, то неправильно.
[33:40.000 --> 33:42.000]  Тоже правильно. А почему?
[33:42.000 --> 33:44.000]  Потому что, ну, можно же пользоваться тем,
[33:44.000 --> 33:46.000]  что потоки...
[33:46.000 --> 33:48.000]  На потоках это работало.
[33:48.000 --> 33:50.000]  Ну, потоков работало,
[33:50.000 --> 33:52.000]  но мы пользовались гарантией
[33:52.000 --> 33:54.000]  ProgramOrder, а теперь у нас ее нет.
[33:54.000 --> 33:56.000]  Так.
[33:56.000 --> 33:58.000]  То есть на потоках
[33:58.000 --> 34:00.000]  у нас была гарантия...
[34:00.000 --> 34:02.000]  Ну, еще раз.
[34:02.000 --> 34:04.000]  Ну, она же для потоков определена,
[34:04.000 --> 34:06.000]  если ProgramOrder говорит порядок
[34:06.000 --> 34:08.000]  обращения к ячеекам памяти
[34:08.000 --> 34:10.000]  в тексте программы
[34:10.000 --> 34:12.000]  в одном потоке.
[34:12.000 --> 34:14.000]  Вот это отношение
[34:14.000 --> 34:16.000]  на операциях в одном потоке.
[34:16.000 --> 34:18.000]  И компилятор, и процессор
[34:18.000 --> 34:20.000]  действия одного потока уважают.
[34:20.000 --> 34:22.000]  Мы читаем,
[34:22.000 --> 34:24.000]  по крайней мере, последнюю запись в том же потоке.
[34:26.000 --> 34:28.000]  А других записей из других потоков
[34:28.000 --> 34:30.000]  в Тейлы не бывает.
[34:30.000 --> 34:32.000]  Поэтому релакса здесь достаточно, пока мы на потоках.
[34:32.000 --> 34:34.000]  А на файберах... Ну, давайте кто-нибудь другой
[34:34.000 --> 34:36.000]  что-нибудь скажите.
[34:36.000 --> 34:38.000]  Про что ты считаешь?
[34:38.000 --> 34:40.000]  Не знаю, мне кажется, все нормально.
[34:40.000 --> 34:42.000]  Все нормально.
[34:42.000 --> 34:44.000]  Внутри потока есть отношение к проблему,
[34:44.000 --> 34:46.000]  значит, внутри файбера будет...
[34:46.000 --> 34:48.000]  Почему внутри файбера будет?
[34:48.000 --> 34:50.000]  Внутри файбера будет то, что мы...
[34:50.000 --> 34:52.000]  Внутри потока не все у нас...
[34:52.000 --> 34:54.000]  Ну, у нас разные потоки. Теперь файбер запустился на одном потоке,
[34:54.000 --> 34:56.000]  а потом на другом потоке. Он на одном потоке записал
[34:56.000 --> 34:58.000]  в TailStore, а потом
[34:58.000 --> 35:00.000]  перезапустился на другом потоке и там
[35:00.000 --> 35:02.000]  прочитал TailRelax, LoadRelax.
[35:02.000 --> 35:04.000]  И вот между этим Storm
[35:04.000 --> 35:06.000]  и этим Load отношения
[35:06.000 --> 35:08.000]  Program Order уже нет.
[35:08.000 --> 35:10.000]  Это же разные потоки. Обращение к памяти
[35:10.000 --> 35:12.000]  из двух разных потоков.
[35:12.000 --> 35:14.000]  Program Order больше нет.
[35:14.000 --> 35:16.000]  Он внутри одного потока.
[35:16.000 --> 35:18.000]  Лечей к памяти одно и то же.
[35:18.000 --> 35:20.000]  Лечей к памяти одно и то же.
[35:20.000 --> 35:22.000]  Ну, смотрите,
[35:22.000 --> 35:24.000]  вопрос очень простой, мы чего-то совсем
[35:24.000 --> 35:26.000]  не понимаем.
[35:26.000 --> 35:28.000]  Вот были мы файбер, да?
[35:28.000 --> 35:30.000]  И мы исполнялись вот...
[35:30.000 --> 35:32.000]  Значит, FiberProducer.
[35:32.000 --> 35:34.000]  Его жизнь.
[35:34.000 --> 35:36.000]  Вот был поток T1.
[35:36.000 --> 35:38.000]  Он там исполнялся.
[35:38.000 --> 35:40.000]  Он там делал TryProduce.
[35:44.000 --> 35:46.000]  То есть, он внутри
[35:46.000 --> 35:48.000]  записал в буфер
[35:48.000 --> 35:50.000]  в позиции 42
[35:52.000 --> 35:54.000]  свой X, а потом
[35:54.000 --> 35:56.000]  на потоке T1 все еще
[35:56.000 --> 35:58.000]  записал в Tail 43.
[36:00.000 --> 36:02.000]  А потом
[36:02.000 --> 36:04.000]  что-то случилось,
[36:04.000 --> 36:06.000]  и вот он уже на потоке T2, T3,
[36:06.000 --> 36:08.000]  и он говорит
[36:08.000 --> 36:10.000]  TryProduce.
[36:12.000 --> 36:14.000]  И он здесь сначала
[36:14.000 --> 36:16.000]  читает
[36:20.000 --> 36:22.000]  Tail с Relaxed.
[36:30.000 --> 36:32.000]  Мы спрашиваем, почему он, собственно,
[36:32.000 --> 36:34.000]  прочтет актуальное значение Tail?
[36:34.000 --> 36:36.000]  Потому что если прочтет ставое значение Tail, то все, беда.
[36:36.000 --> 36:38.000]  Он перезапишет буфер там, не в том месте.
[36:40.000 --> 36:42.000]  Ну вот, если бы
[36:42.000 --> 36:44.000]  между этой записью и этим чтением было бы
[36:44.000 --> 36:46.000]  HappensBefore, то все было бы хорошо, да?
[36:50.000 --> 36:52.000]  Давайте раскроем многоточие.
[36:54.000 --> 36:56.000]  Fiber сделал
[36:56.000 --> 36:58.000]  Produce.
[36:58.000 --> 37:00.000]  Что он сделал?
[37:00.000 --> 37:02.000]  Ну он сделал Suspend, видимо.
[37:02.000 --> 37:04.000]  Он остановился.
[37:04.000 --> 37:06.000]  А что он сделал после Suspenda?
[37:06.000 --> 37:08.000]  Ну, допустим, он Yield
[37:08.000 --> 37:10.000]  сделал. Сделал Produce, потом Yield.
[37:12.000 --> 37:14.000]  Что в этом Yieldе
[37:14.000 --> 37:16.000]  случилось?
[37:20.000 --> 37:22.000]  Мы сначала сделали Suspend.
[37:22.000 --> 37:24.000]  А потом что мы сделали?
[37:24.000 --> 37:26.000]  Это через Suspend?
[37:26.000 --> 37:28.000]  Ну, это и был Suspend.
[37:28.000 --> 37:30.000]  А, вот так.
[37:30.000 --> 37:32.000]  Но мы все еще...
[37:32.000 --> 37:34.000]  Мы специально сферировали,
[37:34.000 --> 37:36.000]  но пересланируясь.
[37:42.000 --> 37:44.000]  Ну, не знаю, что именно такое, да?
[37:50.000 --> 37:52.000]  А теперь,
[37:52.000 --> 37:54.000]  спустя какое-то время...
[38:04.000 --> 38:06.000]  Ну, то есть, а вот что произошло внутри
[38:06.000 --> 38:08.000]  этого сагмита?
[38:14.000 --> 38:16.000]  Вот так, да?
[38:16.000 --> 38:18.000]  А здесь
[38:18.000 --> 38:20.000]  Threadpool Worker Routing
[38:20.000 --> 38:22.000]  Suspend вызвал
[38:22.000 --> 38:24.000]  tasks
[38:24.000 --> 38:26.000]  get
[38:30.000 --> 38:32.000]  и
[38:32.000 --> 38:34.000]  запустил таск.
[38:38.000 --> 38:40.000]  Но мы же с вами, представляете, блокирующую очередь.
[38:40.000 --> 38:42.000]  Мы там берем
[38:42.000 --> 38:44.000]  Mutex, пишем.
[38:44.000 --> 38:46.000]  Потом берем Mutex, читаем.
[38:46.000 --> 38:48.000]  А Mutex там уже дает happens before
[38:48.000 --> 38:50.000]  между секциями.
[38:50.000 --> 38:52.000]  Так что у нас вот между этим Mutex
[38:52.000 --> 38:54.000]  и Mutex есть happens before.
[38:54.000 --> 38:56.000]  И вот это синхронизация
[38:56.000 --> 38:58.000]  в планировщике, она и протянула
[38:58.000 --> 39:00.000]  нам happens before
[39:00.000 --> 39:02.000]  вот в это чтение.
[39:02.000 --> 39:04.000]  Поэтому мы вот в этом чтении
[39:04.000 --> 39:06.000]  в relaxed непременно увидим вот эту запись.
[39:08.000 --> 39:10.000]  Ну как, сошлось?
[39:10.000 --> 39:12.000]  Вот такой был несложный вопрос.
[39:14.000 --> 39:16.000]  Просто у нас синхронизация обеспечивается
[39:16.000 --> 39:18.000]  из-за примитива и синхронизации.
[39:18.000 --> 39:20.000]  Ну то есть у нас happens before
[39:20.000 --> 39:22.000]  получается, когда мы читаем
[39:22.000 --> 39:24.000]  там пишем в атоме, потом читаем из него
[39:24.000 --> 39:26.000]  и вот получаем транзитивность.
[39:26.000 --> 39:28.000]  Ну а также мы получаем
[39:28.000 --> 39:30.000]  мы протягиваем happens before
[39:30.000 --> 39:32.000]  через все примитивы дальше.
[39:34.000 --> 39:36.000]  Сделали Mutex, он тоже нам дает вот этот
[39:36.000 --> 39:38.000]  синхронизация with happens before.
[39:38.000 --> 39:40.000]  Сделали очередь, она тоже дает нам
[39:40.000 --> 39:42.000]  синхронизацию между потоками.
[39:42.000 --> 39:44.000]  Вот это мы и понимаем, потоки синхронизировались.
[39:44.000 --> 39:46.000]  Получился happens before.
[39:56.000 --> 39:58.000]  Ну у тебя же здесь Mutex есть.
[40:00.000 --> 40:02.000]  Пойдем еще глубже.
[40:04.000 --> 40:06.000]  Здесь мы
[40:06.000 --> 40:08.000]  положили в
[40:14.000 --> 40:16.000]  ну я какой-то псевдокат пишу,
[40:16.000 --> 40:18.000]  не обращайте внимания.
[40:24.000 --> 40:26.000]  Вот, а здесь мы внутри
[40:26.000 --> 40:28.000]  гета в
[40:28.000 --> 40:30.000]  Т3 взяли
[40:30.000 --> 40:32.000]  Mutex log и
[40:32.000 --> 40:34.000]  здесь увидели в
[40:36.000 --> 40:38.000]  увидели здесь нашу таску.
[40:38.000 --> 40:40.000]  Ну и вот эта критическая секция
[40:40.000 --> 40:42.000]  она нам дала happens before.
[40:42.000 --> 40:44.000]  Мы собственно в спинлоке
[40:44.000 --> 40:46.000]  его сделали, а Mutex тоже с нами.
[40:50.000 --> 40:52.000]  У нас Mutex
[40:52.000 --> 40:54.000]  отличался от спинлока только тем, что мы
[40:54.000 --> 40:56.000]  добавили ожидания с помощью
[40:56.000 --> 40:58.000]  фьютекса.
[40:58.000 --> 41:00.000]  Ну это посторонний вообще момент сейчас.
[41:02.000 --> 41:04.000]  Ну что, точно
[41:04.000 --> 41:06.000]  разобрались?
[41:06.000 --> 41:08.000]  То есть у нас любую примитив синхронизации,
[41:08.000 --> 41:10.000]  которая построена на Mutex,
[41:10.000 --> 41:12.000]  уж точно, будет
[41:12.000 --> 41:14.000]  давать happens before.
[41:14.000 --> 41:16.000]  Будет через себя передавать его.
[41:16.000 --> 41:18.000]  Поэтому если мы пишем что-то
[41:18.000 --> 41:20.000]  в память, потом кладем значение
[41:20.000 --> 41:22.000]  в очередь, а потом из очереди
[41:22.000 --> 41:24.000]  это значение достаем,
[41:24.000 --> 41:26.000]  ты уверен, что мы можем прочитать то,
[41:26.000 --> 41:28.000]  что было сделано до пута.
[41:30.000 --> 41:32.000]  Ну и так с любым примитивом синхронизации,
[41:32.000 --> 41:34.000]  который мы напишем.
[41:36.000 --> 41:38.000]  С кондварами тоже самое. Все, что было до
[41:38.000 --> 41:40.000]  notify, будет видно после вейта.
[41:40.000 --> 41:42.000]  Все, что сделано было до
[41:42.000 --> 41:44.000]  онлока, будет видно после лока.
[41:46.000 --> 41:48.000]  Собственно,
[41:48.000 --> 41:50.000]  это же такая базовая гарантия примитива
[41:50.000 --> 41:52.000]  синхронизации, которыми
[41:52.000 --> 41:54.000]  мы пользуемся.
[41:54.000 --> 41:56.000]  Вот мы ими пользуемся этими гарантиями,
[41:56.000 --> 41:58.000]  потому что вот на уровне модели памяти они так достигаются.
[41:58.000 --> 42:00.000]  Окей,
[42:00.000 --> 42:02.000]  разобрались.
[42:04.000 --> 42:06.000]  Давайте перейдем
[42:06.000 --> 42:08.000]  к темным местам модели памяти
[42:08.000 --> 42:10.000]  и поговорим про
[42:10.000 --> 42:12.000]  такой пример.
[42:16.000 --> 42:18.000]  Итак,
[42:18.000 --> 42:20.000]  у нас есть
[42:20.000 --> 42:22.000]  вот такая штука LazyValue
[42:22.000 --> 42:24.000]  называется.
[42:24.000 --> 42:26.000]  LazyValue это контейнер
[42:26.000 --> 42:28.000]  для значения, который
[42:28.000 --> 42:30.000]  для некоторого объекта,
[42:30.000 --> 42:32.000]  типа t, который лениво
[42:32.000 --> 42:34.000]  инициализируется.
[42:34.000 --> 42:36.000]  Вот мы в
[42:36.000 --> 42:38.000]  конструктор придаем функцию,
[42:38.000 --> 42:40.000]  которая строит,
[42:40.000 --> 42:42.000]  странно, что она на куче строит,
[42:42.000 --> 42:44.000]  но бог с ней,
[42:44.000 --> 42:46.000]  строит на куче объект, типа t.
[42:46.000 --> 42:48.000]  И у этого объекта
[42:48.000 --> 42:50.000]  есть единственный метод
[42:50.000 --> 42:52.000]  access,
[42:52.000 --> 42:54.000]  который возвращает ссылку на t.
[42:54.000 --> 42:56.000]  Но вот если t еще не
[42:56.000 --> 42:58.000]  сконструирован, то нужно его сконструировать.
[42:58.000 --> 43:00.000]  Если t уже сконструирован,
[43:00.000 --> 43:02.000]  просто вернуть ссылку на него.
[43:02.000 --> 43:04.000]  Вот здесь происходит ленивое конструирование.
[43:04.000 --> 43:06.000]  Каким образом?
[43:06.000 --> 43:08.000]  Вот в этом pointer будет
[43:08.000 --> 43:10.000]  храниться указатель на сконструированный объект.
[43:10.000 --> 43:12.000]  Поначалу там
[43:12.000 --> 43:14.000]  pointer, то есть объект пока не сконструирован.
[43:14.000 --> 43:16.000]  И вот мы приходим в access,
[43:16.000 --> 43:18.000]  читаем этот pointer.
[43:18.000 --> 43:20.000]  Если мы видим, что там null,
[43:20.000 --> 43:22.000]  то значит объект не сконструирован еще.
[43:22.000 --> 43:24.000]  Мы первые, кто к нему пришли.
[43:24.000 --> 43:26.000]  Поэтому нужно сконструировать.
[43:26.000 --> 43:28.000]  Нужно позвать функцию create
[43:28.000 --> 43:30.000]  и сохранить
[43:30.000 --> 43:32.000]  результат в pointer.
[43:32.000 --> 43:34.000]  Но что если
[43:34.000 --> 43:36.000]  пришли два потока,
[43:36.000 --> 43:38.000]  увидели
[43:38.000 --> 43:40.000]  в value pointer null,
[43:40.000 --> 43:42.000]  оба поняли, что объект еще не сконструирован,
[43:42.000 --> 43:44.000]  и поэтому
[43:44.000 --> 43:46.000]  решили оба сконструировать его.
[43:46.000 --> 43:48.000]  Получится между ними гонка.
[43:48.000 --> 43:50.000]  Поэтому мы берем mutex
[43:50.000 --> 43:52.000]  и еще раз
[43:52.000 --> 43:54.000]  проверяем, сконструирован ли объект.
[43:56.000 --> 43:58.000]  И вот если два потока решили
[43:58.000 --> 44:00.000]  разом сконструировать объект,
[44:00.000 --> 44:02.000]  то тот, кто возьмет mutex первым
[44:02.000 --> 44:04.000]  и перепроверит value pointer,
[44:04.000 --> 44:06.000]  он сконструирует объект.
[44:06.000 --> 44:08.000]  А поток,
[44:08.000 --> 44:10.000]  который придет вторым,
[44:10.000 --> 44:12.000]  он увидит уже. То есть он сначала подумал,
[44:12.000 --> 44:14.000]  что объект не сконструирован, потом взял mutex,
[44:14.000 --> 44:16.000]  но пока он его дожидался, объект уже сконструировали.
[44:16.000 --> 44:18.000]  И он это проверит и
[44:18.000 --> 44:20.000]  передумает и не будет
[44:20.000 --> 44:22.000]  сконструировать во второй раз.
[44:22.000 --> 44:24.000]  Вот этот паттерн называется
[44:24.000 --> 44:26.000]  double-checked-locking. То есть мы сначала
[44:26.000 --> 44:28.000]  проверяем предикат. Если он не выполнен,
[44:28.000 --> 44:30.000]  то мы берем блокировку и еще раз
[44:30.000 --> 44:32.000]  проверяем предикат.
[44:36.000 --> 44:38.000]  Потому что объект инициализируется один раз,
[44:38.000 --> 44:40.000]  а потом 150 миллионов раз к нему обращаются.
[44:40.000 --> 44:42.000]  Зачем нам
[44:42.000 --> 44:44.000]  150 раз
[44:44.000 --> 44:46.000]  брать блокировку, когда нам нужно
[44:46.000 --> 44:48.000]  в первый раз?
[44:54.000 --> 44:56.000]  Вот и вопрос. Какие memory-orders нам
[44:56.000 --> 44:58.000]  здесь нужно расставить?
[44:58.000 --> 45:00.000]  А чтобы на этот вопрос ответить, нам нужно
[45:00.000 --> 45:02.000]  как обычно рассуждать, а какие
[45:02.000 --> 45:04.000]  неатомарные обращения к памяти
[45:04.000 --> 45:06.000]  мы хотим упорядочить?
[45:06.000 --> 45:08.000]  Для начала
[45:08.000 --> 45:10.000]  первое, что хочется сказать,
[45:10.000 --> 45:12.000]  если кто-то объект сконструировал,
[45:12.000 --> 45:14.000]  то все остальные об этом должны знать.
[45:14.000 --> 45:16.000]  То есть, если мы к объекту
[45:16.000 --> 45:18.000]  обращаемся, то он уже сконструирован.
[45:22.000 --> 45:24.000]  Твои слова
[45:24.000 --> 45:26.000]  переформулировал более аккуратно.
[45:30.000 --> 45:32.000]  Стой, еще раз.
[45:32.000 --> 45:34.000]  Неатомарные обращения к памяти – это
[45:34.000 --> 45:36.000]  неатомарные обращения к этому объекту T.
[45:38.000 --> 45:40.000]  И вот мы хотим упорядочить
[45:40.000 --> 45:42.000]  конструирование объекта T и обращение
[45:42.000 --> 45:44.000]  к нему.
[45:46.000 --> 45:48.000]  Конструирование происходит здесь.
[45:50.000 --> 45:52.000]  Обращение
[45:52.000 --> 45:54.000]  происходит
[45:54.000 --> 45:56.000]  снаружи
[45:56.000 --> 45:58.000]  этого аксесса.
[46:02.000 --> 46:04.000]  Давайте подумаем,
[46:04.000 --> 46:08.000]  как упорядочить
[46:08.000 --> 46:10.000]  конструирование
[46:10.000 --> 46:12.000]  и обращение.
[46:22.000 --> 46:24.000]  Вот пришел какой-то поток,
[46:24.000 --> 46:26.000]  он зашел в аксесс, прочел поинт,
[46:26.000 --> 46:28.000]  увидел там не ну, и все.
[46:28.000 --> 46:30.000]  Получилась ссылка на объект.
[46:30.000 --> 46:32.000]  Может теперь по ней читать память?
[46:40.000 --> 46:42.000]  Теперь смотри.
[46:42.000 --> 46:44.000]  Мы разобрались, какие неатомарные
[46:44.000 --> 46:46.000]  обращения к памяти мы хотим упорядочить.
[46:48.000 --> 46:50.000]  Между ними нужно сделать
[46:50.000 --> 46:52.000]  HappensBefore.
[46:52.000 --> 46:54.000]  HappensBefore через какую
[46:54.000 --> 46:56.000]  ячейку в итоге попадет
[46:56.000 --> 46:58.000]  в поток, который
[46:58.000 --> 47:00.000]  обращается к объекту?
[47:00.000 --> 47:02.000]  Ячейка, перегращая
[47:02.000 --> 47:04.000]  под VaryPointer.
[47:06.000 --> 47:08.000]  Мы, читая VaryPointer, если мы
[47:08.000 --> 47:10.000]  здесь увидим не ну, то мы должны
[47:10.000 --> 47:12.000]  увидеть и в объекте
[47:12.000 --> 47:14.000]  инициализированный объект.
[47:14.000 --> 47:16.000]  То есть мы по содержимому VaryPointer
[47:16.000 --> 47:18.000]  должны...
[47:18.000 --> 47:20.000]  По содержимому VaryPointer
[47:20.000 --> 47:22.000]  мы делаем вывод
[47:22.000 --> 47:24.000]  о содержимом
[47:24.000 --> 47:26.000]  памяти под объект T.
[47:26.000 --> 47:28.000]  Вот причинность.
[47:28.000 --> 47:30.000]  Нужен HappensBefore.
[47:30.000 --> 47:32.000]  Значит, видимо, нужно здесь написать что?
[47:38.000 --> 47:40.000]  А релиз мы где напишем?
[47:48.000 --> 47:50.000]  Вот, если мы
[47:50.000 --> 47:52.000]  прочитали, здесь
[47:52.000 --> 47:54.000]  не NullPointer, то, видимо, здесь
[47:54.000 --> 47:56.000]  его записали, а значит, мы прочитали
[47:56.000 --> 47:58.000]  запись, которая была сделана здесь в этом чтении,
[47:58.000 --> 48:00.000]  значит, возник Synchronize the Swiss по определению,
[48:00.000 --> 48:02.000]  а значит, между вот этой строчкой
[48:02.000 --> 48:04.000]  и обращением после Access
[48:04.000 --> 48:06.000]  будет HappensBefore.
[48:06.000 --> 48:08.000]  Это правда все.
[48:10.000 --> 48:12.000]  А что мы скажем про этот MemoryOrder?
[48:22.000 --> 48:24.000]  Вот, у нас два потока. Увидели NullPointer,
[48:24.000 --> 48:26.000]  решили зайти и оба
[48:26.000 --> 48:28.000]  инициализировать объект.
[48:28.000 --> 48:30.000]  И поток, который сделал, взял
[48:30.000 --> 48:32.000]  меток с первым, он объекты сконструировал,
[48:32.000 --> 48:34.000]  записал VaryPointer
[48:34.000 --> 48:36.000]  в Pointer с релизом
[48:36.000 --> 48:38.000]  и ушел. Потом появляется второй поток,
[48:38.000 --> 48:40.000]  и этот VaryPointer
[48:40.000 --> 48:42.000]  читает и видит там не Null.
[48:42.000 --> 48:44.000]  Он видит там
[48:44.000 --> 48:46.000]  не Null, а значит,
[48:46.000 --> 48:48.000]  будет, а значит, вот прямо
[48:48.000 --> 48:50.000]  прочитанное значение пользователю и отдаст
[48:50.000 --> 48:52.000]  этот адрес.
[48:52.000 --> 48:54.000]  И пользователь
[48:54.000 --> 48:56.000]  будет по нему читать.
[48:56.000 --> 48:58.000]  Это означает, что снова между этим чтением
[48:58.000 --> 49:00.000]  и вот, ну,
[49:00.000 --> 49:02.000]  это чтение должно с чем-то синхронизироваться.
[49:04.000 --> 49:06.000]  Ну вот, оно должно увидеть этот Store.
[49:10.000 --> 49:12.000]  Ну вот, тут мы воспользуемся тем, что вот этот Store,
[49:12.000 --> 49:14.000]  предшествующий этот Load,
[49:14.000 --> 49:16.000]  они случились в одной критической секции.
[49:16.000 --> 49:18.000]  А на критических секциях у нас уже есть
[49:18.000 --> 49:20.000]  HappensBefore.
[49:20.000 --> 49:22.000]  Поэтому здесь достаточно написать
[49:22.000 --> 49:24.000]  std MemoryOrder
[49:24.000 --> 49:26.000]  Relaxed. То есть мы
[49:26.000 --> 49:28.000]  здесь получаем HappensBefore,
[49:28.000 --> 49:30.000]  но не сами его строим, а мы пользуемся
[49:30.000 --> 49:32.000]  тем, что в Mute-оксе оно будет между
[49:32.000 --> 49:34.000]  Lock'ом и Lock'ом. То есть между Unlock'ом
[49:34.000 --> 49:36.000]  первой секции и Lock'ом вот второй секции.
[49:40.000 --> 49:42.000]  Хорошо.
[49:42.000 --> 49:44.000]  А теперь, теперь...
[49:44.000 --> 49:46.000]  Смотрите, какие
[49:46.000 --> 49:48.000]  пироги.
[49:48.000 --> 49:50.000]  Нет, это работает.
[49:52.000 --> 49:54.000]  Это работает, и
[49:54.000 --> 49:56.000]  ну, оказывается,
[49:56.000 --> 49:58.000]  Modern Memory TC++
[49:58.000 --> 50:00.000]  позволяет нам сделать немного
[50:00.000 --> 50:02.000]  максимальный...
[50:02.000 --> 50:04.000]  Вообще, то, что я расскажу сейчас,
[50:04.000 --> 50:06.000]  об этом лучше и не знать.
[50:06.000 --> 50:08.000]  То есть можно прожить счастливую жизнь и не знать об этом.
[50:08.000 --> 50:10.000]  Но, поскольку
[50:10.000 --> 50:12.000]  MemoryOrder C++ есть, я чувствую,
[50:12.000 --> 50:14.000]  что мой долг прокомментировать.
[50:18.000 --> 50:20.000]  У нас отворился интернет.
[50:20.000 --> 50:22.000]  А нет, не отворился,
[50:22.000 --> 50:24.000]  а я его сбросил.
[50:24.000 --> 50:26.000]  Потерпим.
[50:30.000 --> 50:32.000]  Вот. Мы воспользовались...
[50:32.000 --> 50:34.000]  Смотрите, мы пользовались уже Relaxed,
[50:34.000 --> 50:36.000]  мы пользовались Sequential Consistency,
[50:36.000 --> 50:38.000]  мы пользовались Release Acquire, есть еще Consume и
[50:38.000 --> 50:40.000]  Acquire Release.
[50:40.000 --> 50:42.000]  На Acquire Release, наверное, сегодня не хватит,
[50:42.000 --> 50:44.000]  а вот про Consume мы сейчас поговорим.
[50:44.000 --> 50:46.000]  Смотрите, были два потока.
[50:46.000 --> 50:48.000]  Поток Producer
[50:50.000 --> 50:52.000]  и поток Consumer.
[50:52.000 --> 50:54.000]  Что сделал Producer?
[50:54.000 --> 50:56.000]  Он сконструировал
[50:56.000 --> 50:58.000]  объект в памяти
[51:00.000 --> 51:02.000]  и
[51:04.000 --> 51:06.000]  а потом
[51:06.000 --> 51:08.000]  он
[51:08.000 --> 51:10.000]  записал
[51:10.000 --> 51:12.000]  вот этот ValuePointer.
[51:12.000 --> 51:14.000]  Это называлось здесь CarPTR.
[51:14.000 --> 51:16.000]  Давайте так и напишем.
[51:20.000 --> 51:22.000]  Consumer
[51:22.000 --> 51:24.000]  он этот
[51:24.000 --> 51:26.000]  ValuePointer прочел
[51:30.000 --> 51:32.000]  а потом
[51:32.000 --> 51:34.000]  он получил ссылку
[51:34.000 --> 51:36.000]  на объект, а дальше
[51:36.000 --> 51:38.000]  поэтому CarPtr
[51:38.000 --> 51:40.000]  пошел и вызвал
[51:40.000 --> 51:42.000]  этот фу какой-то на объекте.
[51:48.000 --> 51:50.000]  Так вот.
[51:50.000 --> 51:52.000]  Помните, я в прошлый раз вам объяснял, почему
[51:52.000 --> 51:54.000]  мы пишем Release Acquire?
[51:54.000 --> 51:56.000]  У нас причинности есть, да?
[51:56.000 --> 51:58.000]  Вот мы
[51:58.000 --> 52:00.000]  здесь читаем, идем по стрелочке
[52:00.000 --> 52:02.000]  и вызываем Full, потому что
[52:02.000 --> 52:04.000]  мы здесь увидели не NullPointer, значит вот здесь
[52:04.000 --> 52:06.000]  записали, значит уже объект сконструировали.
[52:08.000 --> 52:10.000]  Но есть некоторые отличия
[52:10.000 --> 52:12.000]  между вот таким кодом
[52:12.000 --> 52:14.000]  и вот таким кодом, когда мы пишем
[52:14.000 --> 52:16.000]  в X, пишем
[52:16.000 --> 52:18.000]  в Y, а потом
[52:18.000 --> 52:20.000]  если в Y единица, то
[52:24.000 --> 52:26.000]  читаем из X
[52:28.000 --> 52:30.000]  и непременно видим в нем тоже единицу.
[52:32.000 --> 52:34.000]  Вот этот пример, он отличается от этого примера.
[52:34.000 --> 52:36.000]  Почему?
[52:36.000 --> 52:38.000]  Первая половина, вот эта, скорее
[52:38.000 --> 52:40.000]  не отличается. Тут мы пишем в одну
[52:40.000 --> 52:42.000]  память, потом пишем в другую ячейку.
[52:42.000 --> 52:44.000]  Какие-то две записи.
[52:46.000 --> 52:48.000]  А вот эта половина
[52:48.000 --> 52:50.000]  отличается.
[52:50.000 --> 52:52.000]  Вот здесь мы ставили, помните,
[52:52.000 --> 52:54.000]  Release запись, а здесь Acquire
[52:54.000 --> 52:56.000]  Чтение.
[52:56.000 --> 52:58.000]  И запрещали как будто бы переупорядочить вот эту
[52:58.000 --> 53:00.000]  запись с этим чтением.
[53:00.000 --> 53:02.000]  Ошибся.
[53:02.000 --> 53:04.000]  Release это был такой односторонний барьер,
[53:04.000 --> 53:06.000]  который запрещал переупорядочить вот
[53:06.000 --> 53:08.000]  эту запись с этой записью.
[53:08.000 --> 53:10.000]  Двинуть ее вниз.
[53:10.000 --> 53:12.000]  А Acquire был односторонний барьер,
[53:12.000 --> 53:14.000]  который запрещал двигать это чтение
[53:14.000 --> 53:16.000]  выше.
[53:16.000 --> 53:18.000]  Ну, это такая была грубая
[53:18.000 --> 53:20.000]  семантика, я примерно объяснял, почему она
[53:20.000 --> 53:22.000]  нужна, потому что здесь StoreBuffer,
[53:22.000 --> 53:24.000]  здесь InvalidationQueue, помните, такое
[53:24.000 --> 53:26.000]  было.
[53:26.000 --> 53:28.000]  С этим кодом не так,
[53:28.000 --> 53:30.000]  но здесь Release нужен.
[53:30.000 --> 53:32.000]  А здесь разве может
[53:32.000 --> 53:34.000]  процессор переставить вот это
[53:34.000 --> 53:36.000]  чтение и вот это чтение?
[53:40.000 --> 53:42.000]  Ну, смотрите, что происходит.
[53:42.000 --> 53:44.000]  Мы в Consumer
[53:44.000 --> 53:46.000]  сначала читаем
[53:46.000 --> 53:48.000]  в регистр
[53:48.000 --> 53:50.000]  некоторые значения,
[53:50.000 --> 53:52.000]  ну, некоторый адрес
[53:52.000 --> 53:54.000]  из памяти,
[53:54.000 --> 53:56.000]  а потом мы
[53:58.000 --> 54:00.000]  читаем...
[54:02.000 --> 54:04.000]  Вот сейчас давайте я напишу на каком-то
[54:04.000 --> 54:06.000]  условном ассемблере.
[54:06.000 --> 54:08.000]  У нас была
[54:08.000 --> 54:10.000]  переменная, в которой был написан адрес, мы по нему
[54:10.000 --> 54:12.000]  прочитали что-то.
[54:14.000 --> 54:16.000]  А потом мы читаем
[54:16.000 --> 54:18.000]  вот по тому адресу,
[54:18.000 --> 54:20.000]  который мы прочли здесь.
[54:22.000 --> 54:24.000]  Да?
[54:24.000 --> 54:26.000]  То есть мы прочли pointer,
[54:26.000 --> 54:28.000]  а потом по pointer
[54:28.000 --> 54:30.000]  снова читаем.
[54:30.000 --> 54:32.000]  Схватили, да, что происходит?
[54:32.000 --> 54:34.000]  То есть у нас была одна ячейка, там был
[54:34.000 --> 54:36.000]  написан адрес, мы ее прочли в регистр,
[54:36.000 --> 54:38.000]  а потом этот регистр подставили
[54:38.000 --> 54:40.000]  как адрес в следующем чтении.
[54:40.000 --> 54:42.000]  Процессор...
[54:42.000 --> 54:44.000]  Вот как может
[54:44.000 --> 54:46.000]  процессор два этих обращения
[54:46.000 --> 54:48.000]  преордерить?
[54:48.000 --> 54:50.000]  Ну, у нас второе обращение зависит от первого.
[54:50.000 --> 54:52.000]  У нас входной
[54:52.000 --> 54:54.000]  аргумент для второй инструкции
[54:54.000 --> 54:56.000]  это выход первой инструкции.
[54:58.000 --> 55:00.000]  Между ними есть зависимость по данным.
[55:02.000 --> 55:04.000]  Data dependency.
[55:08.000 --> 55:10.000]  Согласны?
[55:10.000 --> 55:12.000]  Почему тогда
[55:12.000 --> 55:14.000]  нам здесь нельзя написать
[55:14.000 --> 55:16.000]  просто relax?
[55:20.000 --> 55:22.000]  Ну, просто не должно быть
[55:22.000 --> 55:24.000]  процессора, который возьмет
[55:24.000 --> 55:26.000]  и что-то тут натворит.
[55:28.000 --> 55:30.000]  Ну, короче, здесь acquire выглядит
[55:30.000 --> 55:32.000]  избыточным, потому что
[55:32.000 --> 55:34.000]  не должен процессор это преордерить.
[55:34.000 --> 55:36.000]  Вот. Но, к сожалению, relax
[55:36.000 --> 55:38.000]  писать нельзя, потому что есть
[55:38.000 --> 55:40.000]  процессор, который называется alpha.
[55:40.000 --> 55:42.000]  Вот есть некоторый процессор, который
[55:42.000 --> 55:44.000]  все-таки делает что-то странное.
[55:44.000 --> 55:46.000]  Он никому не нужен.
[55:46.000 --> 55:48.000]  Но
[55:48.000 --> 55:50.000]  поскольку он есть
[55:50.000 --> 55:52.000]  и в нем
[55:52.000 --> 55:54.000]  поведение будет отличаться
[55:54.000 --> 55:56.000]  от relax-то формально,
[55:56.000 --> 55:58.000]  в C++ выдумали новый
[55:58.000 --> 56:00.000]  memory-order, он называется
[56:00.000 --> 56:02.000]  consume.
[56:02.000 --> 56:04.000]  И вот этот consume – это альтернатива
[56:04.000 --> 56:06.000]  acquire, когда мы читаем поинтеры.
[56:06.000 --> 56:08.000]  Вот если мы читаем поинтер,
[56:08.000 --> 56:10.000]  а потом читаем по поинтеру,
[56:10.000 --> 56:12.000]  то вот тут вместо acquire
[56:12.000 --> 56:14.000]  со стороны, когда мы делаем
[56:14.000 --> 56:16.000]  happens before,
[56:16.000 --> 56:18.000]  со стороны получателя данных
[56:18.000 --> 56:20.000]  можно сделать consume
[56:20.000 --> 56:22.000]  поинтера, а потом
[56:22.000 --> 56:24.000]  по поинтеру прочесть
[56:24.000 --> 56:26.000]  и будет
[56:26.000 --> 56:28.000]  видимость записей в чтении.
[56:28.000 --> 56:30.000]  Но
[56:30.000 --> 56:32.000]  если мы напишем вот такой код
[56:32.000 --> 56:34.000]  и если мы напишем, я не знаю,
[56:34.000 --> 56:36.000]  давайте вот вставим сюда,
[56:36.000 --> 56:38.000]  давайте в псевдокоде лучше вставим,
[56:38.000 --> 56:40.000]  вставим сюда просто запись, не знаю,
[56:40.000 --> 56:42.000]  ячейка X,
[56:42.000 --> 56:44.000]  записали один,
[56:44.000 --> 56:46.000]  а здесь мы из X прочитали.
[56:52.000 --> 56:54.000]  Вот здесь мы увидим
[56:54.000 --> 56:56.000]  эту память,
[56:56.000 --> 56:58.000]  а вот этого
[56:58.000 --> 57:00.000]  X мы уже не обязаны
[57:00.000 --> 57:02.000]  увидеть. Почему?
[57:02.000 --> 57:04.000]  Потому что
[57:04.000 --> 57:06.000]  модерипамяти C++ странная.
[57:06.000 --> 57:08.000]  И вот тут
[57:08.000 --> 57:10.000]  я не помню, показывал ли я вам на лекции,
[57:10.000 --> 57:12.000]  там точно был слайд,
[57:12.000 --> 57:14.000]  я
[57:14.000 --> 57:16.000]  говорил вам, что вот есть определение
[57:16.000 --> 57:18.000]  happens before,
[57:18.000 --> 57:20.000]  вот такое транзитивное
[57:20.000 --> 57:22.000]  замыкание просто.
[57:22.000 --> 57:24.000]  И в модерипамяти Java так и есть.
[57:24.000 --> 57:26.000]  У нас есть happens before,
[57:26.000 --> 57:28.000]  когда в программ-ордере есть порядок,
[57:28.000 --> 57:30.000]  у нас есть happens before, когда синхронизуется Swiss,
[57:30.000 --> 57:32.000]  и у нас есть транзитивное замыкание.
[57:32.000 --> 57:34.000]  А в C++
[57:34.000 --> 57:36.000]  у нас много happens before,
[57:36.000 --> 57:38.000]  и определение
[57:38.000 --> 57:40.000]  выглядит вообще-то жутковато.
[57:40.000 --> 57:42.000]  Оно выглядит как?
[57:42.000 --> 57:44.000]  Что A happens before B,
[57:44.000 --> 57:46.000]  если A sequences before,
[57:46.000 --> 57:48.000]  это программ-ордер на C++
[57:48.000 --> 57:50.000]  так называется,
[57:50.000 --> 57:52.000]  или A intsthread happens before.
[57:52.000 --> 57:54.000]  А intsthread happens before это еще
[57:54.000 --> 57:56.000]  сложнейшая штука, с каким-либо длинным
[57:56.000 --> 57:58.000]  комментарием.
[58:00.000 --> 58:02.000]  Зато есть,
[58:02.000 --> 58:04.000]  смотрите,
[58:04.000 --> 58:06.000]  есть другой мемориордер,
[58:06.000 --> 58:08.000]  simply happens before.
[58:08.000 --> 58:10.000]  И вот simply happens before это то, что мы и ожидали.
[58:10.000 --> 58:12.000]  Это когда A sequences before B,
[58:12.000 --> 58:14.000]  или A synchronizes with B,
[58:14.000 --> 58:16.000]  или транзитивное замыкание.
[58:16.000 --> 58:18.000]  И говорится, что если бы не consume,
[58:18.000 --> 58:20.000]  то happens before
[58:20.000 --> 58:22.000]  и simply happens before были бы одним и тем же.
[58:22.000 --> 58:24.000]  Поэтому
[58:24.000 --> 58:26.000]  мораль такая прикладная.
[58:26.000 --> 58:28.000]  Во-первых,
[58:28.000 --> 58:30.000]  не пишите consume никогда.
[58:30.000 --> 58:32.000]  Во-вторых, если вы не пишете
[58:32.000 --> 58:34.000]  consume никогда, то для вас
[58:34.000 --> 58:36.000]  различия настоящего
[58:36.000 --> 58:38.000]  happens before C++ и вот этого упрощенного
[58:38.000 --> 58:40.000]  нет. Вы разницы не чувствуете.
[58:40.000 --> 58:42.000]  Это вот еще одна причина
[58:42.000 --> 58:44.000]  не писать consume. Он не нужен никому
[58:44.000 --> 58:46.000]  кроме альфы. Альфа никому не нужна, то есть он никому
[58:46.000 --> 58:48.000]  не нужен просто.
[58:48.000 --> 58:50.000]  В общем,
[58:50.000 --> 58:52.000]  и если вы этим consume
[58:52.000 --> 58:54.000]  не злоупотребляете нигде,
[58:54.000 --> 58:56.000]  то получается, что
[58:56.000 --> 58:58.000]  для вас happens before становится
[58:58.000 --> 59:00.000]  сильно проще. А в C++
[59:00.000 --> 59:02.000]  он такой сложный просто потому, что
[59:02.000 --> 59:04.000]  happens before в C++
[59:04.000 --> 59:06.000]  строго говоря, нетранзитивный.
[59:06.000 --> 59:08.000]  Потому что когда вы пишете
[59:08.000 --> 59:10.000]  здесь
[59:10.000 --> 59:12.000]  store с релизом,
[59:12.000 --> 59:14.000]  а здесь load с consume,
[59:14.000 --> 59:16.000]  то формально тут возникает
[59:16.000 --> 59:18.000]  не synchronizes with.
[59:18.000 --> 59:20.000]  Тут возникает отношение, которое называется
[59:20.000 --> 59:22.000]  Kareous
[59:22.000 --> 59:24.000]  dependency
[59:24.000 --> 59:26.000]  ordered before.
[59:28.000 --> 59:30.000]  То есть это такой специальный случай,
[59:30.000 --> 59:32.000]  что у вас есть зависимость по данным.
[59:34.000 --> 59:36.000]  А когда вы читаете поинтер, а потом
[59:36.000 --> 59:38.000]  читаете данные по поинтеру,
[59:38.000 --> 59:40.000]  это называется
[59:40.000 --> 59:42.000]  Kareous dependency.
[59:42.000 --> 59:44.000]  Вот, и
[59:44.000 --> 59:46.000]  формально у вас есть
[59:46.000 --> 59:48.000]  happens before
[59:48.000 --> 59:50.000]  между
[59:50.000 --> 59:52.000]  этой записью
[59:52.000 --> 59:54.000]  сюда,
[59:54.000 --> 59:56.000]  потом сюда, потом
[59:56.000 --> 59:58.000]  в чтение.
[59:58.000 --> 01:00:00.000]  Но
[01:00:00.000 --> 01:00:02.000]  к этому happens before
[01:00:02.000 --> 01:00:04.000]  нельзя прилепить еще
[01:00:04.000 --> 01:00:06.000]  один шаг.
[01:00:06.000 --> 01:00:08.000]  Вот нельзя к концу
[01:00:08.000 --> 01:00:10.000]  happens before в C++
[01:00:10.000 --> 01:00:12.000]  в случае
[01:00:12.000 --> 01:00:14.000]  прилепить еще один шаг
[01:00:14.000 --> 01:00:16.000]  sequence before.
[01:00:16.000 --> 01:00:18.000]  Потому что
[01:00:18.000 --> 01:00:20.000]  не знаю, что сказать.
[01:00:22.000 --> 01:00:24.000]  Когда-то
[01:00:24.000 --> 01:00:26.000]  какая-то светлая голова решила, что раз есть
[01:00:26.000 --> 01:00:28.000]  какой-то маргинальный процессор,
[01:00:28.000 --> 01:00:30.000]  и под него можно пооптимизировать еще больше код,
[01:00:30.000 --> 01:00:32.000]  то давайте так и сделаем
[01:00:32.000 --> 01:00:34.000]  и введем memory order consume.
[01:00:34.000 --> 01:00:36.000]  И из-за него модель памяти дико усложняется.
[01:00:36.000 --> 01:00:38.000]  Кажется,
[01:00:38.000 --> 01:00:40.000]  консенсус такой, что это была очень плохая идея,
[01:00:40.000 --> 01:00:42.000]  это была ошибка, но отменить уже
[01:00:42.000 --> 01:00:44.000]  ничего нельзя.
[01:00:44.000 --> 01:00:46.000]  Если мы посмотрим на какую-то разумную библиотеку,
[01:00:46.000 --> 01:00:48.000]  вот
[01:00:50.000 --> 01:00:52.000]  я на лекции про фьючи не помню,
[01:00:52.000 --> 01:00:54.000]  показывал вам ее или нет.
[01:00:54.000 --> 01:00:56.000]  Вообще-то хорошо, чтобы показывал вот
[01:00:56.000 --> 01:00:58.000]  о фолле библиотека общих компонентов Фейсбука.
[01:00:58.000 --> 01:01:00.000]  И
[01:01:00.000 --> 01:01:02.000]  вот там есть
[01:01:02.000 --> 01:01:04.000]  экзекьюторы,
[01:01:04.000 --> 01:01:06.000]  там есть фьючи,
[01:01:06.000 --> 01:01:08.000]  файберы.
[01:01:08.000 --> 01:01:10.000]  Короче, вот большая библиотека
[01:01:10.000 --> 01:01:12.000]  общих компонентов, на которой Фейсбук пишет
[01:01:12.000 --> 01:01:14.000]  свой сервис.
[01:01:14.000 --> 01:01:16.000]  И
[01:01:16.000 --> 01:01:18.000]  давайте посмотрим
[01:01:18.000 --> 01:01:20.000]  memory order
[01:01:20.000 --> 01:01:22.000]  aquaio. Встречается ли там?
[01:01:22.000 --> 01:01:24.000]  Кажется,
[01:01:24.000 --> 01:01:26.000]  встречается и часто.
[01:01:26.000 --> 01:01:28.000]  Где-то его используют.
[01:01:28.000 --> 01:01:30.000]  А что
[01:01:30.000 --> 01:01:32.000]  по поводу memory order consume?
[01:01:36.000 --> 01:01:38.000]  Вот
[01:01:38.000 --> 01:01:40.000]  хотя бы так.
[01:01:40.000 --> 01:01:42.000]  Можно по-разному
[01:01:42.000 --> 01:01:44.000]  его немного писать.
[01:01:44.000 --> 01:01:46.000]  Нет, это другие
[01:01:46.000 --> 01:01:48.000]  consume.
[01:01:48.000 --> 01:01:50.000]  Можно еще там memory order вот так
[01:01:50.000 --> 01:01:52.000]  бывает.
[01:01:52.000 --> 01:01:54.000]  Короче, нет там consume,
[01:01:54.000 --> 01:01:56.000]  потому что...
[01:01:56.000 --> 01:01:58.000]  А нет, я видимо опечатался где-то.
[01:01:58.000 --> 01:02:00.000]  В каких-то маргинальных тестах есть,
[01:02:00.000 --> 01:02:02.000]  он видимо игнорируется.
[01:02:02.000 --> 01:02:04.000]  Да, он нигде
[01:02:04.000 --> 01:02:06.000]  не используется.
[01:02:08.000 --> 01:02:10.000]  О чем он нам говорит?
[01:02:10.000 --> 01:02:12.000]  Что он не нужен?
[01:02:12.000 --> 01:02:14.000]  Вот объективная реальность указывает
[01:02:14.000 --> 01:02:16.000]  нам на то, что он не нужен.
[01:02:16.000 --> 01:02:18.000]  Вот где-то
[01:02:18.000 --> 01:02:20.000]  ну вот,
[01:02:20.000 --> 01:02:22.000]  заменили везде на aquaio.
[01:02:22.000 --> 01:02:24.000]  В будущем, смотри,
[01:02:24.000 --> 01:02:26.000]  жизнь устроена не так.
[01:02:26.000 --> 01:02:28.000]  У тебя есть вот какой-то странный частный случай,
[01:02:28.000 --> 01:02:30.000]  который нарушает общий формализм.
[01:02:30.000 --> 01:02:32.000]  Вот идея такая,
[01:02:32.000 --> 01:02:34.000]  что не то, чтобы процессоры
[01:02:34.000 --> 01:02:36.000]  творят что угодно,
[01:02:36.000 --> 01:02:38.000]  а академики, которые проектируют
[01:02:38.000 --> 01:02:40.000]  внутри памяти, под это подстраиваются.
[01:02:40.000 --> 01:02:42.000]  Это как бы взаимодействие.
[01:02:42.000 --> 01:02:44.000]  Ну, это смысл.
[01:02:44.000 --> 01:02:46.000]  В общем,
[01:02:46.000 --> 01:02:48.000]  я думаю, что
[01:02:48.000 --> 01:02:50.000]  у нас есть такой
[01:02:50.000 --> 01:02:52.000]  это сотрудничество.
[01:02:52.000 --> 01:02:54.000]  Производители процессоров
[01:02:54.000 --> 01:02:56.000]  тоже были заинтересованы в том,
[01:02:56.000 --> 01:02:58.000]  чтобы программы на их процессорах
[01:02:58.000 --> 01:03:00.000]  вели себя разумно.
[01:03:00.000 --> 01:03:02.000]  Поэтому они сотрудничают,
[01:03:02.000 --> 01:03:04.000]  и никто не станет делать новый процессор,
[01:03:04.000 --> 01:03:06.000]  который не вписывается в декларативную модель.
[01:03:06.000 --> 01:03:08.000]  Потому что декларативная модель отвечает
[01:03:08.000 --> 01:03:10.000]  просто здравым каким-то разумным гарантиям.
[01:03:10.000 --> 01:03:12.000]  Короче, в общем,
[01:03:12.000 --> 01:03:14.000]  не нужно делать странные процессоры,
[01:03:14.000 --> 01:03:16.000]  и тогда формализм будет работать,
[01:03:16.000 --> 01:03:18.000]  потому что формализм, он просто фиксирует
[01:03:19.000 --> 01:03:21.000]  Ну, то есть, да, в теории есть
[01:03:21.000 --> 01:03:23.000]  такой странный частный случай,
[01:03:23.000 --> 01:03:25.000]  но можно себе представить процессор,
[01:03:25.000 --> 01:03:27.000]  можно себе представить, что да, здесь
[01:03:27.000 --> 01:03:29.000]  две разные ячейки памяти, а здесь
[01:03:29.000 --> 01:03:31.000]  все-таки зависимость по данным,
[01:03:31.000 --> 01:03:33.000]  и процессор мог бы вести себя
[01:03:33.000 --> 01:03:35.000]  немного по-разному.
[01:03:35.000 --> 01:03:37.000]  Но вот
[01:03:37.000 --> 01:03:39.000]  попытка это использовать
[01:03:39.000 --> 01:03:41.000]  закончилась плохо.
[01:03:41.000 --> 01:03:43.000]  И поэтому модель памяти C++
[01:03:43.000 --> 01:03:45.000]  очень сложна, и поэтому
[01:03:45.000 --> 01:03:47.000]  мы на лекциях разбираем
[01:03:47.000 --> 01:03:49.000]  некоторые упрощения к ней,
[01:03:49.000 --> 01:03:51.000]  то есть, то, что я рассказываю на лекциях,
[01:03:51.000 --> 01:03:53.000]  оно мачится в C++,
[01:03:53.000 --> 01:03:55.000]  но только в том случае, когда вы
[01:03:55.000 --> 01:03:57.000]  откажетесь
[01:03:57.000 --> 01:03:59.000]  от консюма в своих программах.
[01:03:59.000 --> 01:04:01.000]  Ну, и не просто так
[01:04:01.000 --> 01:04:03.000]  модель памяти
[01:04:03.000 --> 01:04:05.000]  я не здесь,
[01:04:05.000 --> 01:04:07.000]  нужно идти в стандарт.
[01:04:07.000 --> 01:04:09.000]  Я не знаю, почему они депрекейтят,
[01:04:09.000 --> 01:04:11.000]  в C++ очень сложно
[01:04:11.000 --> 01:04:13.000]  запретить в обратную сторону.
[01:04:13.000 --> 01:04:15.000]  Ну, как запретить?
[01:04:15.000 --> 01:04:17.000]  В обратную сторону.
[01:04:17.000 --> 01:04:19.000]  Программы есть,
[01:04:19.000 --> 01:04:21.000]  существуют процессоры, на которых
[01:04:21.000 --> 01:04:23.000]  программа может работать оптимальнее,
[01:04:23.000 --> 01:04:25.000]  поэтому мы не можем запретить
[01:04:25.000 --> 01:04:27.000]  сказать, что теперь ваша программа
[01:04:27.000 --> 01:04:29.000]  замедлится, потому что мы завершили ошибку.
[01:04:29.000 --> 01:04:31.000]  Уже кажется поздней.
[01:04:31.000 --> 01:04:33.000]  Не знаю. Ну, в общем, закончу мысль,
[01:04:33.000 --> 01:04:35.000]  что сам стандарт вам говорит,
[01:04:35.000 --> 01:04:37.000]  что
[01:04:37.000 --> 01:04:39.000]  модель памяти Happens Before
[01:04:39.000 --> 01:04:41.000]  сложная, но если вы
[01:04:41.000 --> 01:04:43.000]  откажетесь от консюма,
[01:04:43.000 --> 01:04:45.000]  то вы можете думать про Happens Before
[01:04:45.000 --> 01:04:47.000]  как про простой транзитивный порядок.
[01:04:51.000 --> 01:04:53.000]  Это, кстати, большая проблема,
[01:04:55.000 --> 01:04:57.000]  скорее формальная, чем практическая.
[01:04:57.000 --> 01:04:59.000]  Ну, вот представьте,
[01:04:59.000 --> 01:05:01.000]  с одной стороны,
[01:05:01.000 --> 01:05:03.000]  Happens Before не транзитивный,
[01:05:03.000 --> 01:05:05.000]  строго говоря, потому что здесь
[01:05:05.000 --> 01:05:07.000]  Happens Before есть, между этим строчкой
[01:05:07.000 --> 01:05:09.000]  и этой,
[01:05:09.000 --> 01:05:11.000]  но к нему еще один шаг добавить
[01:05:11.000 --> 01:05:13.000]  нельзя. А теперь
[01:05:13.000 --> 01:05:15.000]  вернемся к примеру про циклический буфер,
[01:05:15.000 --> 01:05:17.000]  я вам показываю код и говорю,
[01:05:17.000 --> 01:05:19.000]  ну, у нас же есть очередь, а значит Happens Before
[01:05:19.000 --> 01:05:21.000]  надает. Мы положили
[01:05:21.000 --> 01:05:23.000]  X, достали X, значит есть Happens Before.
[01:05:23.000 --> 01:05:25.000]  Но если Happens Before
[01:05:25.000 --> 01:05:27.000]  не транзитивный, то толку с этой гарантии.
[01:05:27.000 --> 01:05:29.000]  Поэтому нетранзитивность
[01:05:29.000 --> 01:05:31.000]  формальная Happens Before,
[01:05:31.000 --> 01:05:33.000]  это, вообще говоря, проблема для модели памяти C++,
[01:05:33.000 --> 01:05:35.000]  и там ее как-то тоже
[01:05:35.000 --> 01:05:37.000]  костырит. Но если вы консюм нигде
[01:05:37.000 --> 01:05:39.000]  не используете, то у вас Happens Before все-таки
[01:05:39.000 --> 01:05:41.000]  не транзитивный, и тогда
[01:05:41.000 --> 01:05:43.000]  такими гарантиями уже можно
[01:05:43.000 --> 01:05:45.000]  пользоваться.
[01:05:45.000 --> 01:05:47.000]  Так что
[01:05:47.000 --> 01:05:49.000]  мое предложение, забудьте
[01:05:49.000 --> 01:05:51.000]  про консюм, не пользуйтесь им,
[01:05:51.000 --> 01:05:53.000]  просто знайте, что это была
[01:05:53.000 --> 01:05:55.000]  неудачная перфоманс-оптимизация, которая
[01:05:55.000 --> 01:05:57.000]  завершилась очень неприятными
[01:05:57.000 --> 01:05:59.000]  последствиями для
[01:05:59.000 --> 01:06:01.000]  формализма.
[01:06:01.000 --> 01:06:03.000]  Такое бывает.
[01:06:05.000 --> 01:06:07.000]  Кажется, что большинство
[01:06:07.000 --> 01:06:09.000]  компиляторов не будут различать
[01:06:09.000 --> 01:06:11.000]  Consume и Acquire, то есть
[01:06:11.000 --> 01:06:13.000]  нормальный компилятор, если он не хочет проблем,
[01:06:13.000 --> 01:06:15.000]  он просто...
[01:06:17.000 --> 01:06:19.000]  Скорее всего, в реализации любого компилятора
[01:06:19.000 --> 01:06:21.000]  Consume и Acquire будут
[01:06:21.000 --> 01:06:23.000]  одними и теми же инструкциями.
[01:06:23.000 --> 01:06:25.000]  Так что вы на разумной архитектуре
[01:06:25.000 --> 01:06:27.000]  выигрыша никакого не получите, зато
[01:06:27.000 --> 01:06:29.000]  гарантии формально из себя ослабить.
[01:06:29.000 --> 01:06:31.000]  Ладно, в общем, забудьте про это, если вы можете.
[01:06:31.000 --> 01:06:33.000]  Если знаете, что...
[01:06:33.000 --> 01:06:35.000]  Плохая идея. Итого, мы, значит,
[01:06:35.000 --> 01:06:37.000]  для Relaxed мы использовали
[01:06:37.000 --> 01:06:39.000]  Acquire, Reiss, Consume даже
[01:06:39.000 --> 01:06:41.000]  и поиспользовали. То есть это некоторое ослабление
[01:06:41.000 --> 01:06:43.000]  для Acquire.
[01:06:43.000 --> 01:06:45.000]  Остался еще этот Memory Order.
[01:06:45.000 --> 01:06:47.000]  Вот про него мы тогда
[01:06:47.000 --> 01:06:49.000]  уже в следующий раз поговорим.
[01:06:49.000 --> 01:06:51.000]  Будет повод, поговорим.
[01:06:51.000 --> 01:06:53.000]  Повод, кстати, есть. Хорошее решение
[01:06:53.000 --> 01:06:55.000]  Weight-группы использует его.
[01:06:57.000 --> 01:06:59.000]  В задаче Mutex вас просят, напишите
[01:06:59.000 --> 01:07:01.000]  хорошую Weight-группу.
[01:07:01.000 --> 01:07:03.000]  Хорошую, это такую, которая
[01:07:05.000 --> 01:07:07.000]  вызывает эды и данные,
[01:07:07.000 --> 01:07:09.000]  то есть плюс и минус
[01:07:09.000 --> 01:07:11.000]  просто с помощью
[01:07:11.000 --> 01:07:13.000]  атомарного инкремента-декремента.
[01:07:13.000 --> 01:07:15.000]  Там никаких Mutex хватает
[01:07:15.000 --> 01:07:17.000]  постоянно.
[01:07:17.000 --> 01:07:19.000]  Просто тут написано будет Fitch-add,
[01:07:19.000 --> 01:07:21.000]  а тут почти всегда Fitch-sub.
[01:07:21.000 --> 01:07:23.000]  И вот с такой реализацией, если ставить
[01:07:23.000 --> 01:07:25.000]  Memory Order, то можно их...
[01:07:25.000 --> 01:07:27.000]  То оптимальные Memory Order, они там будут
[01:07:27.000 --> 01:07:29.000]  нетривиальные, вы их ставить не умеете
[01:07:29.000 --> 01:07:31.000]  пока.
[01:07:31.000 --> 01:07:33.000]  Но если вы можете их ставить, то
[01:07:33.000 --> 01:07:35.000]  не умеете пока.
[01:07:35.000 --> 01:07:37.000]  Но правильное решение будет использовать
[01:07:37.000 --> 01:07:39.000]  Aquarelease.
[01:07:43.000 --> 01:07:45.000]  Ну что ж, на сегодня все тогда?
[01:07:49.000 --> 01:07:51.000]  Спасибо.
[01:07:51.000 --> 01:07:53.000]  Какой у нас на сегодня план?
[01:07:53.000 --> 01:07:55.000]  Я хотел бы
[01:07:55.000 --> 01:07:57.000]  продолжить разговор про слабые модели
[01:07:57.000 --> 01:07:59.000]  памяти. В прошлый раз мы разобрали
[01:07:59.000 --> 01:08:01.000]  Spinlock, мы разобрали циклический
[01:08:01.000 --> 01:08:03.000]  буфер. И не просто так,
[01:08:03.000 --> 01:08:05.000]  потому что нам потребуется в субботу
[01:08:05.000 --> 01:08:07.000]  на рекции про планировщик.
[01:08:07.000 --> 01:08:09.000]  Там мы использовали
[01:08:09.000 --> 01:08:11.000]  Aquarelease.
[01:08:11.000 --> 01:08:13.000]  Немного научились
[01:08:13.000 --> 01:08:15.000]  рассуждать о том, как именно
[01:08:15.000 --> 01:08:17.000]  Memory Order выставлять,
[01:08:17.000 --> 01:08:19.000]  руководствуясь какими соображениями.
[01:08:19.000 --> 01:08:21.000]  Мы каждый раз... Что делали?
[01:08:21.000 --> 01:08:23.000]  Давайте откроем
[01:08:25.000 --> 01:08:27.000]  примеры и
[01:08:27.000 --> 01:08:29.000]  напомню.
[01:08:29.000 --> 01:08:31.000]  Мы каждый раз руководствовались
[01:08:31.000 --> 01:08:33.000]  такими соображениями. Нужно найти
[01:08:33.000 --> 01:08:35.000]  в программе неатомарные обращения
[01:08:35.000 --> 01:08:37.000]  к памяти, которые мы собираемся упорядочивать
[01:08:37.000 --> 01:08:39.000]  с помощью Memory Order на атомиках.
[01:08:41.000 --> 01:08:43.000]  Вот это мы сегодня сделаем,
[01:08:43.000 --> 01:08:45.000]  но перед этим может быть
[01:08:45.000 --> 01:08:47.000]  у вас есть какие-то собственные вопросы
[01:08:47.000 --> 01:08:49.000]  про домашние работы, про то,
[01:08:49.000 --> 01:08:51.000]  что вообще в курсе происходит, куда мы идем,
[01:08:51.000 --> 01:08:53.000]  зачем мы туда идем, куда мы
[01:08:53.000 --> 01:08:55.000]  хотим попасть.
[01:08:55.000 --> 01:08:57.000]  Я бы сказал, что задача про него.
[01:08:57.000 --> 01:08:59.000]  Если задача...
[01:09:09.000 --> 01:09:11.000]  То, что в шаблоне есть,
[01:09:11.000 --> 01:09:13.000]  там действительно некоторые подсказки
[01:09:13.000 --> 01:09:15.000]  к хорошему решению. Давайте я
[01:09:15.000 --> 01:09:17.000]  поясню, в чем вообще
[01:09:17.000 --> 01:09:19.000]  глобальный смысл происходящего.
[01:09:19.000 --> 01:09:21.000]  Смысл начинается
[01:09:21.000 --> 01:09:23.000]  в том, что мы
[01:09:23.000 --> 01:09:25.000]  делали в шаблоне.
[01:09:25.000 --> 01:09:27.000]  Смысл начинается
[01:09:27.000 --> 01:09:29.000]  где-то давным-давно в задачах про корутины.
[01:09:29.000 --> 01:09:31.000]  Вот про что эта задача была?
[01:09:31.000 --> 01:09:33.000]  Про то, чтобы написать файберы, которые умели
[01:09:33.000 --> 01:09:35.000]  только yield. И как мы
[01:09:35.000 --> 01:09:37.000]  в этой задачи писали yield?
[01:09:37.000 --> 01:09:39.000]  У нас был файбер,
[01:09:39.000 --> 01:09:41.000]  в нем была корутина, она исполняла
[01:09:41.000 --> 01:09:43.000]  какой-то...
[01:09:43.000 --> 01:09:45.000]  иначе.
[01:09:45.000 --> 01:09:47.000]  Был файбер,
[01:09:47.000 --> 01:09:49.000]  в нем была корутина, которая
[01:09:49.000 --> 01:09:51.000]  исполняла код пользователя.
[01:09:51.000 --> 01:09:53.000]  И когда это...
[01:09:53.000 --> 01:09:55.000]  и когда файбер делал yield, он должен был
[01:09:55.000 --> 01:09:57.000]  остановиться
[01:09:57.000 --> 01:09:59.000]  и запустить...
[01:09:59.000 --> 01:10:01.000]  Этот файбер, это была цепочка
[01:10:01.000 --> 01:10:03.000]  таких вот ходов.
[01:10:03.000 --> 01:10:05.000]  Ход, который завершается либо yield, либо завершением
[01:10:05.000 --> 01:10:07.000]  файбера. И вот, по сути, в третпуле
[01:10:07.000 --> 01:10:09.000]  исполнялась цепочка таких задач.
[01:10:09.000 --> 01:10:11.000]  И метод yield, он останавливал
[01:10:11.000 --> 01:10:13.000]  текущую корутину, завершал текущую задачу.
[01:10:13.000 --> 01:10:15.000]  Но перед тем, как задача
[01:10:15.000 --> 01:10:17.000]  совсем может завершиться, мы планировали
[01:10:17.000 --> 01:10:19.000]  продолжение файбера, бросали
[01:10:19.000 --> 01:10:21.000]  третпул с помощью submit следующую задачу,
[01:10:21.000 --> 01:10:23.000]  которая возобновляла корутину,
[01:10:23.000 --> 01:10:25.000]  и файбер бежал с того места, где он остановился,
[01:10:25.000 --> 01:10:27.000]  в yield.
[01:10:27.000 --> 01:10:29.000]  Где был реализован yield? Ну, он был реализован,
[01:10:29.000 --> 01:10:31.000]  вероятно, у вас в ходе прямо в теле
[01:10:31.000 --> 01:10:33.000]  файбера.
[01:10:33.000 --> 01:10:35.000]  Был какой-то метод, который представлял собой
[01:10:35.000 --> 01:10:37.000]  задачу.
[01:10:37.000 --> 01:10:39.000]  И вот в этом методе вы резюмили
[01:10:39.000 --> 01:10:41.000]  корутину, файбер делал шаг,
[01:10:41.000 --> 01:10:43.000]  корутина останавливалась, а дальше вы разбирались,
[01:10:43.000 --> 01:10:45.000]  почему он остановился, этот файбер.
[01:10:45.000 --> 01:10:47.000]  Либо потому, что просто корутина
[01:10:47.000 --> 01:10:49.000]  завершилась, то есть файбер подошел к концу,
[01:10:49.000 --> 01:10:51.000]  либо методом исключения,
[01:10:51.000 --> 01:10:53.000]  вы решали, что если
[01:10:53.000 --> 01:10:55.000]  файбер, если корутина еще готова исполняться, значит,
[01:10:55.000 --> 01:10:57.000]  это был yield. И бросали
[01:10:57.000 --> 01:10:59.000]  в третпул новую задачу.
[01:10:59.000 --> 01:11:01.000]  Для вот
[01:11:01.000 --> 01:11:03.000]  этой задачи такое решение,
[01:11:03.000 --> 01:11:05.000]  оно сойдет.
[01:11:05.000 --> 01:11:07.000]  Но дальше
[01:11:07.000 --> 01:11:09.000]  мы делали задачу strip4.
[01:11:09.000 --> 01:11:11.000]  И в задаче strip4,
[01:11:11.000 --> 01:11:13.000]  где же она?
[01:11:13.000 --> 01:11:15.000]  Здесь ниже. Мы
[01:11:15.000 --> 01:11:17.000]  немного
[01:11:17.000 --> 01:11:19.000]  усложняли файбер, мы говорили, что давайте
[01:11:19.000 --> 01:11:21.000]  добавим к ним еще одну операцию,
[01:11:21.000 --> 01:11:23.000]  которая будет
[01:11:23.000 --> 01:11:25.000]  реализовывать блокирующие файбер
[01:11:25.000 --> 01:11:27.000]  ожидания через
[01:11:27.000 --> 01:11:29.000]  подписку на таймер.
[01:11:29.000 --> 01:11:31.000]  Мы в методе
[01:11:31.000 --> 01:11:33.000]  function strip4
[01:11:33.000 --> 01:11:35.000]  файберный, вот здесь
[01:11:35.000 --> 01:11:37.000]  конституировали таймер
[01:11:37.000 --> 01:11:39.000]  и подвешивали к нему callback,
[01:11:39.000 --> 01:11:41.000]  в котором этот файбер
[01:11:41.000 --> 01:11:43.000]  возобновлялся.
[01:11:43.000 --> 01:11:45.000]  После этого останавливались.
[01:11:45.000 --> 01:11:47.000]  Точнее, не так, чтобы сначала подписывались
[01:11:47.000 --> 01:11:49.000]  на таймер, потом останавливались, потому что
[01:11:49.000 --> 01:11:51.000]  это была бы гонка, и в эту проблему задачи должны
[01:11:51.000 --> 01:11:53.000]  были решить. Как упорядочить возобновление
[01:11:53.000 --> 01:11:55.000]  файбера и установку файбера.
[01:11:55.000 --> 01:11:57.000]  Но смысл был примерно такой.
[01:11:57.000 --> 01:11:59.000]  Вам нужно было подписаться
[01:11:59.000 --> 01:12:01.000]  на, повесить на таймер
[01:12:01.000 --> 01:12:03.000]  обработчик и пробудиться
[01:12:03.000 --> 01:12:05.000]  в этом обработчике и заснуть.
[01:12:05.000 --> 01:12:07.000]  После того, как вы...
[01:12:07.000 --> 01:12:09.000]  И в каком порядке
[01:12:09.000 --> 01:12:11.000]  неважно сейчас заснуть.
[01:12:11.000 --> 01:12:13.000]  Завершите текущую задачу
[01:12:13.000 --> 01:12:15.000]  остановить текущий шаг карутина.
[01:12:15.000 --> 01:12:17.000]  Завершите текущий шаг карутина.
[01:12:19.000 --> 01:12:21.000]  А дальше вы крутитесь в event loop
[01:12:21.000 --> 01:12:23.000]  и event loop решает, что таймер
[01:12:23.000 --> 01:12:25.000]  готов.
[01:12:25.000 --> 01:12:27.000]  Timeout истек,
[01:12:27.000 --> 01:12:29.000]  таймер сработал, callback запустился
[01:12:29.000 --> 01:12:31.000]  и запускают вашего обработчика,
[01:12:31.000 --> 01:12:33.000]  в нем запускается карутина и файбер
[01:12:33.000 --> 01:12:35.000]  продолжает бежать.
[01:12:35.000 --> 01:12:37.000]  То есть, на первый взгляд задача
[01:12:37.000 --> 01:12:39.000]  про то, чтобы
[01:12:39.000 --> 01:12:41.000]  обработать просто события
[01:12:41.000 --> 01:12:43.000]  в файберах, внешние события,
[01:12:43.000 --> 01:12:45.000]  таймеры, вот вывод, что угодно.
[01:12:45.000 --> 01:12:47.000]  Но вместе с тем
[01:12:47.000 --> 01:12:49.000]  в эту задачу просят вас
[01:12:49.000 --> 01:12:51.000]  пожалуйста, напишите код так,
[01:12:51.000 --> 01:12:53.000]  чтобы вот это знание
[01:12:53.000 --> 01:12:55.000]  про таймеры и сама реализация
[01:12:55.000 --> 01:12:57.000]  slip4, сама логика slip4,
[01:12:57.000 --> 01:12:59.000]  она, по возможности, не просачивалась
[01:12:59.000 --> 01:13:01.000]  в сам файбер.
[01:13:01.000 --> 01:13:03.000]  Но пусть все, что касается slip4
[01:13:03.000 --> 01:13:05.000]  остается функцией slip4.
[01:13:05.000 --> 01:13:07.000]  Почему?
[01:13:07.000 --> 01:13:09.000]  Ну, потому что, видимо,
[01:13:09.000 --> 01:13:11.000]  можно придумывать себе другие примеры,
[01:13:11.000 --> 01:13:13.000]  там, не знаю, мы сокеты
[01:13:13.000 --> 01:13:15.000]  хотим сделать, мы мьютексы хотим сделать,
[01:13:15.000 --> 01:13:17.000]  мы кундвары хотим сделать, мы каналы хотим
[01:13:17.000 --> 01:13:19.000]  сделать. И для всего этого тоже требуется
[01:13:19.000 --> 01:13:21.000]  какая-то поддержка, и было бы
[01:13:21.000 --> 01:13:23.000]  очень неудобно каждый раз менять
[01:13:23.000 --> 01:13:25.000]  вот прямо сам класс файбер
[01:13:25.000 --> 01:13:27.000]  для того, чтобы новый примитив поддержать.
[01:13:27.000 --> 01:13:29.000]  Вот к такому выводу вас приводит
[01:13:29.000 --> 01:13:31.000]  эта задача.
[01:13:31.000 --> 01:13:33.000]  А текущая задача мьютекс, она вот доводит
[01:13:33.000 --> 01:13:35.000]  этот вот мысль до конца.
[01:13:35.000 --> 01:13:37.000]  Там говорится, что
[01:13:37.000 --> 01:13:39.000]  ну, опять, сначала сделайте
[01:13:39.000 --> 01:13:41.000]  что-то такое кастомное.
[01:13:41.000 --> 01:13:43.000]  Вам нужно сделать примитивы синхронизации,
[01:13:43.000 --> 01:13:45.000]  они все реализуются через фьютекс,
[01:13:45.000 --> 01:13:47.000]  поэтому как-нибудь сделайте фьютекс.
[01:13:47.000 --> 01:13:49.000]  Вот вы как-нибудь
[01:13:49.000 --> 01:13:51.000]  фьютекс делаете, и вот снова та же проблема.
[01:13:51.000 --> 01:13:53.000]  Вы как-то закастырили еще один примитив.
[01:13:53.000 --> 01:13:55.000]  А теперь у вас, кажется, есть
[01:13:55.000 --> 01:13:57.000]  ну, некоторый опыт наблюдений
[01:13:57.000 --> 01:13:59.000]  за вашей реализацией, за эволюцией
[01:13:59.000 --> 01:14:01.000]  вашей реализации. У вас был slip4,
[01:14:01.000 --> 01:14:03.000]  у вас есть фьютекс,
[01:14:03.000 --> 01:14:05.000]  и можно себе представить сразу много
[01:14:05.000 --> 01:14:07.000]  других примеров.
[01:14:07.000 --> 01:14:09.000]  Вот о чем slip4 и о чем
[01:14:09.000 --> 01:14:11.000]  фьютекс? Они
[01:14:11.000 --> 01:14:13.000]  оба этих применения, они
[01:14:13.000 --> 01:14:15.000]  про одну и ту же общую задачу.
[01:14:15.000 --> 01:14:17.000]  У вас есть файбер, он работает, работает, работает,
[01:14:17.000 --> 01:14:19.000]  а потом он хочет чего-то дождаться.
[01:14:19.000 --> 01:14:21.000]  Там
[01:14:21.000 --> 01:14:23.000]  пройденного времени,
[01:14:23.000 --> 01:14:25.000]  данных из сокета, но
[01:14:25.000 --> 01:14:27.000]  сокетов не было пока,
[01:14:27.000 --> 01:14:29.000]  пройденного времени или
[01:14:29.000 --> 01:14:31.000]  это сигнала
[01:14:31.000 --> 01:14:33.000]  к пробуждению от другого файбера.
[01:14:33.000 --> 01:14:35.000]  Реализованы это
[01:14:35.000 --> 01:14:37.000]  совершенно по-разному.
[01:14:37.000 --> 01:14:39.000]  В одном случае мы подписываемся на таймер,
[01:14:39.000 --> 01:14:41.000]  там крузим какой-то event loop.
[01:14:41.000 --> 01:14:43.000]  В случае с фьютексом
[01:14:43.000 --> 01:14:45.000]  запланировать пробуждение файбера
[01:14:45.000 --> 01:14:47.000]  это значит положить себя в очередь.
[01:14:47.000 --> 01:14:49.000]  А потом другой
[01:14:49.000 --> 01:14:51.000]  файбер достанет, нас разбудит.
[01:14:51.000 --> 01:14:53.000]  То есть на уровне реализации все это очень
[01:14:53.000 --> 01:14:55.000]  по-разному выглядит. Но суть одна и та же.
[01:14:55.000 --> 01:14:57.000]  Мы хотим остановиться
[01:14:57.000 --> 01:14:59.000]  и запланировать свое возобновление.
[01:15:01.000 --> 01:15:03.000]  А дальше можно представить себе
[01:15:03.000 --> 01:15:05.000]  очень много сценариев, где нам
[01:15:05.000 --> 01:15:07.000]  нужно это сделать каждый раз по-своему,
[01:15:07.000 --> 01:15:09.000]  но в принципе
[01:15:09.000 --> 01:15:11.000]  сделать те же самые шаги.
[01:15:11.000 --> 01:15:13.000]  Вот фьютекс и
[01:15:13.000 --> 01:15:15.000]  вот этот метод park.
[01:15:15.000 --> 01:15:17.000]  Yield.
[01:15:17.000 --> 01:15:19.000]  Вот тоже, это же по сути
[01:15:19.000 --> 01:15:21.000]  остановиться и запланировать возобновление.
[01:15:21.000 --> 01:15:23.000]  Запланировать когда? Сразу же,
[01:15:23.000 --> 01:15:25.000]  моментально, ничего не дожидаясь.
[01:15:25.000 --> 01:15:27.000]  В принципе тоже вкладывается,
[01:15:27.000 --> 01:15:29.000]  вписывается в эту общую задачу.
[01:15:29.000 --> 01:15:31.000]  Следующая. У нас
[01:15:31.000 --> 01:15:33.000]  были future. Future, я напомню, это
[01:15:33.000 --> 01:15:35.000]  представление
[01:15:35.000 --> 01:15:37.000]  для будущего значения.
[01:15:55.000 --> 01:15:57.000]  Ну вот, я рефактор и код и делаю это не аккуратно.
[01:16:07.000 --> 01:16:09.000]  А, это не здесь нужно искать.
[01:16:09.000 --> 01:16:11.000]  Не искать здесь.
[01:16:17.000 --> 01:16:19.000]  Да, у нас есть некоторое future.
[01:16:19.000 --> 01:16:21.000]  В данном случае это timeout.
[01:16:21.000 --> 01:16:23.000]  То есть future, которое наполнится пустым
[01:16:23.000 --> 01:16:25.000]  значением void.
[01:16:25.000 --> 01:16:27.000]  Ну не пустым значением void, это вообще
[01:16:27.000 --> 01:16:29.000]  тип без значений.
[01:16:29.000 --> 01:16:31.000]  Ну в общем future, которое заполнится через там 250
[01:16:31.000 --> 01:16:33.000]  миллисекунд. А потом я могу
[01:16:33.000 --> 01:16:35.000]  заблокировать fiber до тех пор, пока
[01:16:35.000 --> 01:16:37.000]  в future не появится значение.
[01:16:37.000 --> 01:16:39.000]  Вот опять,
[01:16:39.000 --> 01:16:41.000]  как я хочу это
[01:16:41.000 --> 01:16:43.000]  сделать? Видимо у future,
[01:16:43.000 --> 01:16:45.000]  если вы помните на лекции,
[01:16:45.000 --> 01:16:47.000]  у них был метод, который назывался
[01:16:49.000 --> 01:16:51.000]  future уже.
[01:16:53.000 --> 01:16:55.000]  Subscribe.
[01:16:55.000 --> 01:16:57.000]  Сейчас я про это расскажу.
[01:16:57.000 --> 01:16:59.000]  Subscribe, который позволял подписаться
[01:16:59.000 --> 01:17:01.000]  на...
[01:17:01.000 --> 01:17:03.000]  Нам кажется,
[01:17:03.000 --> 01:17:05.000]  не хватает заголовка thread.
[01:17:07.000 --> 01:17:09.000]  У future был subscribe,
[01:17:15.000 --> 01:17:17.000]  который позволял подписаться,
[01:17:17.000 --> 01:17:19.000]  поместить callback,
[01:17:19.000 --> 01:17:21.000]  который вызовется, когда
[01:17:21.000 --> 01:17:23.000]  в future появится значение.
[01:17:23.000 --> 01:17:25.000]  И вот опять, как сделать синхронное
[01:17:25.000 --> 01:17:27.000]  ожидание future?
[01:17:27.000 --> 01:17:29.000]  Повесить на него callback, что когда future выполнится,
[01:17:29.000 --> 01:17:31.000]  то нужно нас разбудить,
[01:17:31.000 --> 01:17:33.000]  а самим остановиться.
[01:17:35.000 --> 01:17:37.000]  Ну, селект на каналах,
[01:17:37.000 --> 01:17:39.000]  которых мы еще не писали...
[01:17:39.000 --> 01:17:41.000]  Знаете, что такое селект?
[01:17:41.000 --> 01:17:43.000]  Я столько раз про него
[01:17:43.000 --> 01:17:45.000]  говорил, и вы...
[01:17:45.000 --> 01:17:47.000]  В канале было
[01:17:47.000 --> 01:17:49.000]  на первой неделе сообщение,
[01:17:49.000 --> 01:17:51.000]  изучите язык ГО немножко,
[01:17:51.000 --> 01:17:53.000]  почитайте про него, чтобы было понятно,
[01:17:53.000 --> 01:17:55.000]  что мы делаем.
[01:17:55.000 --> 01:17:57.000]  Вот, два канала,
[01:17:57.000 --> 01:17:59.000]  две грутины пишут,
[01:17:59.000 --> 01:18:01.000]  отправляют сообщение в эти каналы,
[01:18:01.000 --> 01:18:03.000]  третья грутина ждет этих сообщений,
[01:18:03.000 --> 01:18:05.000]  и вот с помощью конструкции селект
[01:18:05.000 --> 01:18:07.000]  блокируется до тех пор, пока сообщение
[01:18:07.000 --> 01:18:09.000]  появится либо здесь, либо здесь.
[01:18:09.000 --> 01:18:11.000]  То есть такое блокирующее,
[01:18:11.000 --> 01:18:13.000]  мультиплексированное ожидание.
[01:18:13.000 --> 01:18:15.000]  Ну, как вот, не знаю,
[01:18:15.000 --> 01:18:17.000]  как селект на сокетах,
[01:18:17.000 --> 01:18:19.000]  только на превратилосинхронизации.
[01:18:21.000 --> 01:18:23.000]  В общем, во всех этих сценариях
[01:18:23.000 --> 01:18:25.000]  возникает...
[01:18:25.000 --> 01:18:27.000]  Во всех этих примерах возникает одна общая задача
[01:18:27.000 --> 01:18:29.000]  остановиться и подписаться
[01:18:29.000 --> 01:18:31.000]  на возобновление
[01:18:31.000 --> 01:18:33.000]  по какому-то правилу.
[01:18:33.000 --> 01:18:35.000]  В yield одно правило, во futhex другое правило,
[01:18:35.000 --> 01:18:37.000]  в future третье правило, в селекте четвертое правило.
[01:18:39.000 --> 01:18:41.000]  Было бы, наверное,
[01:18:41.000 --> 01:18:43.000]  очень странно,
[01:18:43.000 --> 01:18:45.000]  если бы появление
[01:18:45.000 --> 01:18:47.000]  каждой очередной
[01:18:47.000 --> 01:18:49.000]  такой задачи,
[01:18:49.000 --> 01:18:51.000]  каждой очередной функциональности
[01:18:51.000 --> 01:18:53.000]  потребовало бы
[01:18:53.000 --> 01:18:55.000]  от нас переписывать код файберов.
[01:18:57.000 --> 01:18:59.000]  Вот прямо лезть в структуру файбер,
[01:18:59.000 --> 01:19:01.000]  добавлять еще какие-то условия.
[01:19:01.000 --> 01:19:03.000]  Вот файбер знает про таймеры,
[01:19:03.000 --> 01:19:05.000]  знает про futhex,
[01:19:05.000 --> 01:19:07.000]  знает про future, знает про селект,
[01:19:07.000 --> 01:19:09.000]  он с ума сойдет.
[01:19:09.000 --> 01:19:11.000]  Это, во-первых, было бы очень сложно,
[01:19:11.000 --> 01:19:13.000]  а во-вторых, это было бы не расширяемо.
[01:19:13.000 --> 01:19:15.000]  Вот представьте себе,
[01:19:15.000 --> 01:19:17.000]  вы написали библиотеку файберов
[01:19:17.000 --> 01:19:19.000]  и отдали ее пользователям,
[01:19:19.000 --> 01:19:21.000]  а пользователь захотел свой примитив написать.
[01:19:21.000 --> 01:19:23.000]  Или у него есть свои future,
[01:19:23.000 --> 01:19:25.000]  и он хочет файберы подружить со своими futureми,
[01:19:25.000 --> 01:19:27.000]  их дожидаться.
[01:19:27.000 --> 01:19:29.000]  А как он это сделает,
[01:19:29.000 --> 01:19:31.000]  если у него нет доступа к вашей
[01:19:31.000 --> 01:19:33.000]  реализации файберов,
[01:19:33.000 --> 01:19:35.000]  он просто ее использует,
[01:19:35.000 --> 01:19:37.000]  он не хочет форкать вашу библиотеку,
[01:19:37.000 --> 01:19:39.000]  у него есть какой-то инструмент,
[01:19:39.000 --> 01:19:41.000]  который позволит
[01:19:41.000 --> 01:19:43.000]  файберам взаимодействовать,
[01:19:43.000 --> 01:19:45.000]  с помощью которого
[01:19:45.000 --> 01:19:47.000]  он выразит свою задачу.
[01:19:47.000 --> 01:19:49.000]  Вот он хочет новой примитив синхронизации,
[01:19:49.000 --> 01:19:51.000]  он написал RVLog.
[01:19:51.000 --> 01:19:53.000]  И вот он пользуется некоторым инструментом,
[01:19:53.000 --> 01:19:55.000]  который позволяет ему реализовать
[01:19:55.000 --> 01:19:57.000]  блокирующие ожидания для RVLog,
[01:19:57.000 --> 01:19:59.000]  или для future,
[01:19:59.000 --> 01:20:01.000]  или для еще чего-нибудь,
[01:20:01.000 --> 01:20:03.000]  что он захочет написать.
[01:20:03.000 --> 01:20:05.000]  То есть нам нужен инструмент,
[01:20:05.000 --> 01:20:07.000]  который позволяет расширять функциональность файберов
[01:20:07.000 --> 01:20:09.000]  без необходимости
[01:20:09.000 --> 01:20:11.000]  менять собственно реализацию файберов.
[01:20:13.000 --> 01:20:15.000]  Но в условии явно написано,
[01:20:15.000 --> 01:20:17.000]  что нужно сделать,
[01:20:17.000 --> 01:20:19.000]  чтобы кастомизировать поведение
[01:20:19.000 --> 01:20:21.000]  этого самого suspenda,
[01:20:21.000 --> 01:20:23.000]  предлагается самому пользователю
[01:20:23.000 --> 01:20:25.000]  писать просто стратегию,
[01:20:25.000 --> 01:20:27.000]  которая определяет
[01:20:27.000 --> 01:20:29.000]  для конкретного примитива синхронизации
[01:20:29.000 --> 01:20:31.000]  или для конкретной реализации,
[01:20:31.000 --> 01:20:33.000]  когда файбер нужно возобновить.
[01:20:33.000 --> 01:20:35.000]  По таймеру, моментально,
[01:20:35.000 --> 01:20:37.000]  когда достанут из очереди.
[01:20:37.000 --> 01:20:39.000]  Любая логика должна быть
[01:20:39.000 --> 01:20:41.000]  выражена не внутри файбера,
[01:20:41.000 --> 01:20:43.000]  а в самой операции Yield,
[01:20:43.000 --> 01:20:45.000]  в самой операции Slip,
[01:20:45.000 --> 01:20:47.000]  в самом Utox, в самом Utox,
[01:20:47.000 --> 01:20:49.000]  в самом канале.
[01:20:49.000 --> 01:20:51.000]  Поэтому мы хотим,
[01:20:51.000 --> 01:20:53.000]  чтобы из файберов это все унеслось,
[01:20:53.000 --> 01:20:55.000]  а в файберах остались
[01:20:55.000 --> 01:20:57.000]  авейторы, стратегия
[01:20:57.000 --> 01:20:59.000]  и некоторые файбер-хэндл,
[01:20:59.000 --> 01:21:01.000]  который это такой технический момент,
[01:21:01.000 --> 01:21:03.000]  потому что все-таки пользователь,
[01:21:03.000 --> 01:21:05.000]  когда он
[01:21:07.000 --> 01:21:09.000]  пишет свой примитив синхронизации,
[01:21:09.000 --> 01:21:11.000]  он же должен в конечном итоге
[01:21:11.000 --> 01:21:13.000]  файбер будить.
[01:21:13.000 --> 01:21:15.000]  Но он не хочет, точнее мы не хотим,
[01:21:15.000 --> 01:21:17.000]  как разработчики файберов, чтобы
[01:21:17.000 --> 01:21:19.000]  в него попадали прямо детали реализации,
[01:21:19.000 --> 01:21:21.000]  то есть сам класс файбер.
[01:21:21.000 --> 01:21:23.000]  Поэтому пользователь пишет стратегию,
[01:21:23.000 --> 01:21:25.000]  как именно он файбер собирается
[01:21:25.000 --> 01:21:27.000]  разбудить, а сам файбер
[01:21:27.000 --> 01:21:29.000]  в его стратегию попадает
[01:21:29.000 --> 01:21:31.000]  в остановленном виде,
[01:21:31.000 --> 01:21:33.000]  во-первых, а во-вторых,
[01:21:33.000 --> 01:21:35.000]  в виде файбер-хэндл.
[01:21:35.000 --> 01:21:37.000]  То есть такой непрозрачный поинтер,
[01:21:37.000 --> 01:21:39.000]  вот здесь реализация
[01:21:39.000 --> 01:21:41.000]  файбера не торчит в пользователя,
[01:21:41.000 --> 01:21:43.000]  здесь никакого инклуда файбера нет и не должно быть.
[01:21:45.000 --> 01:21:47.000]  Пользующийся файбер-хэндл, он его
[01:21:47.000 --> 01:21:49.000]  использует. То есть код Flutex
[01:21:49.000 --> 01:21:51.000]  не знает про структуру файбера,
[01:21:51.000 --> 01:21:53.000]  про класс файбер.
[01:21:53.000 --> 01:21:55.000]  Flutex реализован с помощью
[01:21:55.000 --> 01:21:57.000]  использования файбер-хэндл.
[01:21:59.000 --> 01:22:01.000]  Ну, а причем тут овейтеры
[01:22:03.000 --> 01:22:05.000]  и как это все написать
[01:22:05.000 --> 01:22:07.000]  хорошо, это же
[01:22:07.000 --> 01:22:09.000]  задачи про это и есть.
[01:22:09.000 --> 01:22:11.000]  То есть она на первом уровне про реализацию
[01:22:11.000 --> 01:22:13.000]  Flutex, что сама по себе полезно,
[01:22:13.000 --> 01:22:15.000]  а во-вторых, она про то, чтобы
[01:22:15.000 --> 01:22:17.000]  придумать, как должен
[01:22:17.000 --> 01:22:19.000]  выглядеть вот такой вот хороший,
[01:22:19.000 --> 01:22:21.000]  расширяемый, кастомизируемый дизайн.
[01:22:21.000 --> 01:22:23.000]  Вот вы это попробуйте сделать,
[01:22:23.000 --> 01:22:25.000]  сделайте так хорошо, как вы можете,
[01:22:25.000 --> 01:22:27.000]  а по задумке
[01:22:27.000 --> 01:22:29.000]  мы через неделю встретимся,
[01:22:29.000 --> 01:22:31.000]  у вас там уже пройдет дедлайн
[01:22:31.000 --> 01:22:33.000]  и вы расскажете,
[01:22:33.000 --> 01:22:35.000]  что у вас получилось.
[01:22:35.000 --> 01:22:37.000]  Мы прямо вот здесь поговорим на паре,
[01:22:37.000 --> 01:22:39.000]  потому что вопрос сложный,
[01:22:39.000 --> 01:22:41.000]  то есть хороший дизайн придумать сложно
[01:22:41.000 --> 01:22:43.000]  и
[01:22:43.000 --> 01:22:45.000]  он должен получиться хорошим.
[01:22:45.000 --> 01:22:47.000]  И смотрите, какая история.
[01:22:47.000 --> 01:22:49.000]  Вот этот дизайн, который мы придумываем
[01:22:49.000 --> 01:22:51.000]  здесь, он не просто
[01:22:51.000 --> 01:22:53.000]  какое-то решение,
[01:22:53.000 --> 01:22:55.000]  это дизайн,
[01:22:55.000 --> 01:22:57.000]  который в конечном итоге
[01:22:57.000 --> 01:22:59.000]  использует
[01:22:59.000 --> 01:23:01.000]  корутины C++.
[01:23:01.000 --> 01:23:03.000]  Вот через
[01:23:03.000 --> 01:23:05.000]  две недели,
[01:23:05.000 --> 01:23:07.000]  то есть не в эту субботу, а в следующую
[01:23:07.000 --> 01:23:09.000]  субботу у нас будет
[01:23:09.000 --> 01:23:11.000]  лекция, возможно опять двойная,
[01:23:11.000 --> 01:23:13.000]  потому что там нужно за раз
[01:23:13.000 --> 01:23:15.000]  многое рассказать про корутины,
[01:23:15.000 --> 01:23:17.000]  про очень важный механизм
[01:23:17.000 --> 01:23:19.000]  асинхронности конкуренции
[01:23:19.000 --> 01:23:21.000]  в C++.
[01:23:21.000 --> 01:23:23.000]  И вот эти корутины,
[01:23:23.000 --> 01:23:25.000]  это максимально общий,
[01:23:25.000 --> 01:23:27.000]  максимально абстрактный инструмент,
[01:23:27.000 --> 01:23:29.000]  это некоторая компираторная языковая фича
[01:23:29.000 --> 01:23:31.000]  без конкретной семантики.
[01:23:31.000 --> 01:23:33.000]  То есть корутины C++ не знают,
[01:23:33.000 --> 01:23:35.000]  что их собираются использовать для асинхронности.
[01:23:35.000 --> 01:23:37.000]  Они хоть и называются коэвейтны,
[01:23:37.000 --> 01:23:39.000]  то есть как будто бы
[01:23:39.000 --> 01:23:41.000]  остановиться и дождаться чего-то,
[01:23:41.000 --> 01:23:43.000]  но на самом деле у корутины
[01:23:43.000 --> 01:23:45.000]  такой семантики нет.
[01:23:45.000 --> 01:23:47.000]  Семантику определяете
[01:23:47.000 --> 01:23:49.000]  только вы.
[01:23:49.000 --> 01:23:51.000]  Семантику определяете с помощью
[01:23:51.000 --> 01:23:53.000]  авейтеров. То есть тот дизайн,
[01:23:53.000 --> 01:23:55.000]  который будет в корутинах на лекции,
[01:23:55.000 --> 01:23:57.000]  это тот дизайн, который придумываем сейчас вы,
[01:23:57.000 --> 01:23:59.000]  сейчас мы. Если мы его придумаем,
[01:23:59.000 --> 01:24:01.000]  то вот мы поймем, как корутины работают.
[01:24:01.000 --> 01:24:03.000]  Причем,
[01:24:03.000 --> 01:24:05.000]  в чем разница?
[01:24:05.000 --> 01:24:07.000]  Почему мы делаем это, а не просто изучаем корутины?
[01:24:07.000 --> 01:24:09.000]  Потому что в корутинах этот дизайн,
[01:24:09.000 --> 01:24:11.000]  все это работает на уровне компилятора,
[01:24:11.000 --> 01:24:13.000]  мы не можем это увидеть.
[01:24:13.000 --> 01:24:15.000]  А на файберах мы можем это руками написать.
[01:24:15.000 --> 01:24:17.000]  Но идея абсолютно одна и та же.
[01:24:19.000 --> 01:24:21.000]  Так что мы попытаемся придумать
[01:24:21.000 --> 01:24:23.000]  хороший дизайн. Получится у нас или нет
[01:24:23.000 --> 01:24:25.000]  непонятно, но вот то, что мы придумаем,
[01:24:25.000 --> 01:24:27.000]  мы обсудим на следующем занятии.
[01:24:27.000 --> 01:24:29.000]  Поэтому я вас очень прошу как-то
[01:24:29.000 --> 01:24:31.000]  постараться. То есть мало просто решить задачу.
[01:24:31.000 --> 01:24:33.000]  Если вы просто решите эту задачу, но не придумаете
[01:24:33.000 --> 01:24:35.000]  хороший авейтер, не попробуйте
[01:24:35.000 --> 01:24:37.000]  придумать, то, боюсь, вы
[01:24:37.000 --> 01:24:39.000]  самое интересное выпустите.
[01:24:39.000 --> 01:24:41.000]  Это очень важный шаг.
[01:24:41.000 --> 01:24:43.000]  Но я пока подсказывать, что именно не хочу.
[01:24:43.000 --> 01:24:45.000]  Просто смотри, каким принципом ты руководствуешься?
[01:24:45.000 --> 01:24:47.000]  Ты должен написать код, который будет выглядеть хорошо.
[01:24:47.000 --> 01:24:49.000]  Что значит хорошо?
[01:24:51.000 --> 01:24:53.000]  Хороший код
[01:24:53.000 --> 01:24:55.000]  это код,
[01:24:55.000 --> 01:24:57.000]  в котором...
[01:24:57.000 --> 01:24:59.000]  Я вообще-то писал это в канал. Это такой базовый принцип
[01:24:59.000 --> 01:25:01.000]  программирования. Если вы не знаете, его
[01:25:01.000 --> 01:25:03.000]  программировать вы вообще не должны.
[01:25:03.000 --> 01:25:05.000]  Это solid.
[01:25:05.000 --> 01:25:07.000]  Знаете ли вы про паттерны проектирования?
[01:25:07.000 --> 01:25:09.000]  Вот их не нужно знать вообще.
[01:25:09.000 --> 01:25:11.000]  Это абсолютно естественные вещи,
[01:25:11.000 --> 01:25:13.000]  которые выводятся из некоторого здравого смысла.
[01:25:13.000 --> 01:25:15.000]  Здравый смысл это solid.
[01:25:15.000 --> 01:25:17.000]  Вот паттерны проектирования
[01:25:17.000 --> 01:25:19.000]  как изучают? Изучим сегодня
[01:25:19.000 --> 01:25:21.000]  паттерн-адаптер, завтра изучим паттерн-визитер.
[01:25:21.000 --> 01:25:23.000]  Не нужно. Нужно всегда
[01:25:23.000 --> 01:25:25.000]  исходить из задачи.
[01:25:25.000 --> 01:25:27.000]  Вы не решение задачи учите,
[01:25:27.000 --> 01:25:29.000]  сначала решаете задачу, а потом находите в ней паттерн.
[01:25:29.000 --> 01:25:31.000]  Но если вы даже паттернов не знаете, вы можете
[01:25:31.000 --> 01:25:33.000]  их не знать, но их использовать,
[01:25:33.000 --> 01:25:35.000]  потому что это просто разумные решения.
[01:25:35.000 --> 01:25:37.000]  А разумные они в том смысле, что
[01:25:37.000 --> 01:25:39.000]  они делают только то, что нужно,
[01:25:39.000 --> 01:25:41.000]  и в себе заключают некоторую
[01:25:41.000 --> 01:25:43.000]  суть задачи.
[01:25:43.000 --> 01:25:45.000]  И вот здесь также
[01:25:45.000 --> 01:25:47.000]  овейтеры это суть
[01:25:47.000 --> 01:25:49.000]  задачи кастомизации поведения
[01:25:49.000 --> 01:25:51.000]  файберов.
[01:25:51.000 --> 01:25:53.000]  В хорошем решении у нас
[01:25:53.000 --> 01:25:55.000]  файберы не будут знать ничего про
[01:25:55.000 --> 01:25:57.000]  конкретные фьютексы,
[01:25:57.000 --> 01:25:59.000]  гилды,
[01:25:59.000 --> 01:26:01.000]  кондвары,
[01:26:01.000 --> 01:26:03.000]  вообще ни про что такое.
[01:26:03.000 --> 01:26:05.000]  Файберы упростятся.
[01:26:05.000 --> 01:26:07.000]  В кондварах не будет
[01:26:07.000 --> 01:26:09.000]  снова знания, в кондварах мютексов,
[01:26:09.000 --> 01:26:11.000]  в фьютексах не будет никакого знания про внутренности
[01:26:11.000 --> 01:26:13.000]  файберов. Там тоже это не нужно знать.
[01:26:13.000 --> 01:26:15.000]  Будет просто файбер-хэндл.
[01:26:17.000 --> 01:26:19.000]  И все вот это вместе
[01:26:19.000 --> 01:26:21.000]  не будет ничего знать
[01:26:21.000 --> 01:26:23.000]  про тратпул, который все это исполняет.
[01:26:23.000 --> 01:26:25.000]  То есть будет хороший модульный
[01:26:25.000 --> 01:26:27.000]  код с низко связанностью,
[01:26:27.000 --> 01:26:29.000]  где
[01:26:29.000 --> 01:26:31.000]  любая логика, она локальная,
[01:26:31.000 --> 01:26:33.000]  вы можете ее менять и не думать,
[01:26:33.000 --> 01:26:35.000]  как это влияет на какое-то далекое другое место
[01:26:35.000 --> 01:26:37.000]  в коде. Вот если у вас код
[01:26:37.000 --> 01:26:39.000]  написан так, то с ним жить очень просто.
[01:26:39.000 --> 01:26:41.000]  И это вообще-то очень важное
[01:26:41.000 --> 01:26:43.000]  наблюдение про модульность
[01:26:43.000 --> 01:26:45.000]  и про такую локальность,
[01:26:45.000 --> 01:26:47.000]  потому что представьте себе, что вы пишете большой проект.
[01:26:47.000 --> 01:26:49.000]  Вот осенью
[01:26:49.000 --> 01:26:51.000]  с теми, кто пойдет учить с распределенным системом,
[01:26:51.000 --> 01:26:53.000]  мы будем писать распределенный код
[01:26:53.000 --> 01:26:55.000]  и
[01:26:55.000 --> 01:26:57.000]  ну там
[01:26:57.000 --> 01:26:59.000]  студенты, вы напишете 5%,
[01:26:59.000 --> 01:27:01.000]  а 95% напишу я.
[01:27:01.000 --> 01:27:03.000]  И это скорее самое сложное.
[01:27:05.000 --> 01:27:07.000]  То есть это не алгоритмы будут, это вся инфраструктура
[01:27:07.000 --> 01:27:09.000]  вокруг, но вот
[01:27:09.000 --> 01:27:11.000]  она очень сложная, очень большая.
[01:27:11.000 --> 01:27:13.000]  И ну
[01:27:13.000 --> 01:27:15.000]  в нашем курсе там будут
[01:27:15.000 --> 01:27:17.000]  десятки тысяч строчек уже, это очень много.
[01:27:17.000 --> 01:27:19.000]  А в большом проекте,
[01:27:19.000 --> 01:27:21.000]  который развивается там лет 10, может быть сотен тысяч
[01:27:21.000 --> 01:27:23.000]  строчек. Ну и представьте, как
[01:27:23.000 --> 01:27:25.000]  может человек ориентироваться сотен тысяч строк.
[01:27:25.000 --> 01:27:27.000]  Сотни тысяч строк.
[01:27:27.000 --> 01:27:29.000]  Но это гораздо
[01:27:29.000 --> 01:27:31.000]  больше кода, чем можно вместить
[01:27:31.000 --> 01:27:33.000]  в одну голову. Ну ладно, есть разные головы,
[01:27:33.000 --> 01:27:35.000]  можно вместить на самом деле.
[01:27:35.000 --> 01:27:37.000]  Но вы сможете с этой сотни тысяч
[01:27:37.000 --> 01:27:39.000]  строк управляться только тогда,
[01:27:39.000 --> 01:27:41.000]  когда они максимально декомпозированы.
[01:27:41.000 --> 01:27:43.000]  Вот эта сотня тысяч строк, это 10 тысяч строк
[01:27:43.000 --> 01:27:45.000]  в одном месте, 10 в другом, 10 в третьем.
[01:27:45.000 --> 01:27:47.000]  И они друг с другом общаются только через очень
[01:27:47.000 --> 01:27:49.000]  простые абстракции.
[01:27:49.000 --> 01:27:51.000]  И вот если это так, то вы можете
[01:27:51.000 --> 01:27:53.000]  ну вот представьте себе,
[01:27:53.000 --> 01:27:55.000]  что мы пишем сейчас файберы, и мы их там
[01:27:55.000 --> 01:27:57.000]  оптимизируем.
[01:27:57.000 --> 01:27:59.000]  А в субботу я расскажу вам, как написать
[01:27:59.000 --> 01:28:01.000]  хороший тредпул, эффективный,
[01:28:01.000 --> 01:28:03.000]  быстрый, потому что текущий не годится совершенно.
[01:28:03.000 --> 01:28:05.000]  То есть хороший планировщик.
[01:28:05.000 --> 01:28:07.000]  И планировщик сложный очень.
[01:28:07.000 --> 01:28:09.000]  И файберы сами по себе
[01:28:09.000 --> 01:28:11.000]  будут сложные.
[01:28:11.000 --> 01:28:13.000]  Но нам не нужно думать про их
[01:28:13.000 --> 01:28:15.000]  сложность, не нужно их перемножать
[01:28:15.000 --> 01:28:17.000]  от этой сложности.
[01:28:17.000 --> 01:28:19.000]  Нужно их складывать.
[01:28:19.000 --> 01:28:21.000]  Понимаете идею?
[01:28:21.000 --> 01:28:23.000]  То есть мы ровно для этого и повели декомпозицию
[01:28:23.000 --> 01:28:25.000]  между файберами и
[01:28:25.000 --> 01:28:27.000]  экзекьюторами. Мы отдельно пишем экзекьютор,
[01:28:27.000 --> 01:28:29.000]  отдельно пишем файберы, и сложности их
[01:28:29.000 --> 01:28:31.000]  суммируются, но вот
[01:28:31.000 --> 01:28:33.000]  файберам не нужно ничего знать про
[01:28:33.000 --> 01:28:35.000]  реализацию тредпула.
[01:28:35.000 --> 01:28:37.000]  Я вру на самом деле.
[01:28:37.000 --> 01:28:39.000]  А тредпулу не нужно знать ничего про файберы.
[01:28:39.000 --> 01:28:41.000]  Только про задачи.
[01:28:41.000 --> 01:28:43.000]  И вот ровно благодаря
[01:28:43.000 --> 01:28:45.000]  хорошему модульному дизайну,
[01:28:45.000 --> 01:28:47.000]  потому что каждый компонент
[01:28:47.000 --> 01:28:49.000]  занимается только одной задачей,
[01:28:49.000 --> 01:28:51.000]  это принцип единой ответственности
[01:28:51.000 --> 01:28:53.000]  в SOLID, и каждый компонент
[01:28:53.000 --> 01:28:55.000]  слабо связан
[01:28:55.000 --> 01:28:57.000]  с другими, еще один принцип,
[01:28:57.000 --> 01:28:59.000]  то вот благодаря
[01:28:59.000 --> 01:29:01.000]  этому мы можем управлять всей
[01:29:01.000 --> 01:29:03.000]  сложностью нашего проекта.
[01:29:03.000 --> 01:29:05.000]  Только так
[01:29:05.000 --> 01:29:07.000]  и можно жить.
[01:29:07.000 --> 01:29:09.000]  С большим сложным кодом.
[01:29:11.000 --> 01:29:13.000]  Мы сейчас
[01:29:13.000 --> 01:29:15.000]  на файберах учимся как раз
[01:29:15.000 --> 01:29:17.000]  этой сложностью управлять, то есть
[01:29:17.000 --> 01:29:19.000]  декомпозировать файбер-скор
[01:29:19.000 --> 01:29:21.000]  от всего того, что можно
[01:29:21.000 --> 01:29:23.000]  для синхронизации придумать.
[01:29:23.000 --> 01:29:25.000]  Пока это кундварф, ютекс, мютекс,
[01:29:25.000 --> 01:29:27.000]  вейтгрупп, дальше можно добавить канал,
[01:29:27.000 --> 01:29:29.000]  селекты, там еще что-то, и вот так
[01:29:29.000 --> 01:29:31.000]  вот продолжать еще долго.
[01:29:31.000 --> 01:29:33.000]  Там таймер добавить, тикеры как
[01:29:33.000 --> 01:29:35.000]  уго.
[01:29:35.000 --> 01:29:37.000]  Очень долгая дорога, мы конечно не успеем
[01:29:37.000 --> 01:29:39.000]  все сделать, но
[01:29:39.000 --> 01:29:41.000]  должно быть понятно, что можно так долго
[01:29:41.000 --> 01:29:43.000]  продолжать. И наш код
[01:29:43.000 --> 01:29:45.000]  должен быть к этому готов.
[01:29:45.000 --> 01:29:47.000]  В общем, напиши какое-то решение,
[01:29:47.000 --> 01:29:49.000]  подумай, где оно тебе нравится, где не нравится.
[01:29:49.000 --> 01:29:51.000]  Откуда пользователь
[01:29:51.000 --> 01:29:53.000]  берет файбер-хэндл,
[01:29:53.000 --> 01:29:55.000]  ты спрашиваешь.
[01:30:01.000 --> 01:30:03.000]  Ну, видимо, сейчас.
[01:30:03.000 --> 01:30:05.000]  Ну, подумай,
[01:30:05.000 --> 01:30:07.000]  как это все должно работать.
[01:30:07.000 --> 01:30:09.000]  Файбер-хэндл,
[01:30:09.000 --> 01:30:11.000]  ну, это как бы такой
[01:30:11.000 --> 01:30:13.000]  хэндл на файбер.
[01:30:13.000 --> 01:30:15.000]  Ну, файбер-хэндл
[01:30:15.000 --> 01:30:17.000]  на файбер,
[01:30:17.000 --> 01:30:19.000]  это как бы такой хэндл на файбер.
[01:30:19.000 --> 01:30:21.000]  Ну, видимо, его строит сам файбер.
[01:30:21.000 --> 01:30:23.000]  Откуда он еще возьмется?
[01:30:23.000 --> 01:30:25.000]  Вот. Но при этом
[01:30:25.000 --> 01:30:27.000]  в твоем коде внутри директории
[01:30:27.000 --> 01:30:29.000]  синг не должно быть никаких обращений
[01:30:29.000 --> 01:30:31.000]  к файберам. Ну, просто их не должно
[01:30:31.000 --> 01:30:33.000]  быть. Вот, в частности, фьютекс
[01:30:33.000 --> 01:30:35.000]  это же шаблон, он реализован в хедере.
[01:30:35.000 --> 01:30:37.000]  Если ты напишешь здесь include-файбер, то все,
[01:30:37.000 --> 01:30:39.000]  ты проиграл, потому что он попадет
[01:30:39.000 --> 01:30:41.000]  ко всем пользователям этого самого
[01:30:41.000 --> 01:30:43.000]  фьютекса.
[01:30:43.000 --> 01:30:45.000]  Вот, я еще обращаю внимание,
[01:30:45.000 --> 01:30:47.000]  что у тебя файбер-хэндл – это хэндл
[01:30:47.000 --> 01:30:49.000]  именно на остановленный файбер.
[01:30:49.000 --> 01:30:51.000]  То есть, когда ты его получаешь,
[01:30:51.000 --> 01:30:53.000]  то есть, в хорошем коде, если у тебя есть
[01:30:53.000 --> 01:30:55.000]  файбер-хэндл,
[01:30:55.000 --> 01:30:57.000]  то он
[01:30:57.000 --> 01:30:59.000]  определенно указывает
[01:30:59.000 --> 01:31:01.000]  на файбер, который уже остановлен.
[01:31:01.000 --> 01:31:03.000]  И его можно запустить.
[01:31:03.000 --> 01:31:05.000]  Ну, или он пустой вообще.
[01:31:05.000 --> 01:31:07.000]  Он пустой ты сам сконструируешь, может быть.
[01:31:07.000 --> 01:31:09.000]  Но если тебе дали файбер-хэндл,
[01:31:09.000 --> 01:31:11.000]  то ты точно знаешь, что он у тебя
[01:31:11.000 --> 01:31:13.000]  уже заполнен файбером, и этот файбер
[01:31:13.000 --> 01:31:15.000]  остановлен, и его можно будить.
[01:31:15.000 --> 01:31:17.000]  Вот это важная подсказка.
[01:31:17.000 --> 01:31:19.000]  Хороший код будет только с таким
[01:31:19.000 --> 01:31:21.000]  файбер-хэндлом работать.
[01:31:27.000 --> 01:31:29.000]  Ну, и у задачи есть, конечно,
[01:31:29.000 --> 01:31:31.000]  третий бонусный уровень.
[01:31:31.000 --> 01:31:33.000]  Вот он самый клевый. Он прям очень клевый.
[01:31:33.000 --> 01:31:35.000]  И он очень...
[01:31:35.000 --> 01:31:37.000]  И он матчится с
[01:31:37.000 --> 01:31:39.000]  следующей темой
[01:31:39.000 --> 01:31:41.000]  наших лекций, с планировщиком.
[01:31:41.000 --> 01:31:43.000]  И с задачей
[01:31:43.000 --> 01:31:45.000]  новой простренд
[01:31:45.000 --> 01:31:47.000]  это лог-фри-мьютекс.
[01:31:47.000 --> 01:31:49.000]  Потому что мы делаем в мьютекс,
[01:31:49.000 --> 01:31:51.000]  а в нем есть спинлог, а в спинлоге есть
[01:31:51.000 --> 01:31:53.000]  взаимное исключение, а мы работаем в пуле,
[01:31:53.000 --> 01:31:55.000]  и мы блокируя другие потоки,
[01:31:55.000 --> 01:31:57.000]  блокируем вообще всех.
[01:31:57.000 --> 01:31:59.000]  Вот можно сделать мьютекс, которым
[01:31:59.000 --> 01:32:01.000]  не будет взаимного исключения на уровне
[01:32:01.000 --> 01:32:03.000]  поток.
[01:32:03.000 --> 01:32:05.000]  И вообще,
[01:32:05.000 --> 01:32:07.000]  во всем нашем коде мы
[01:32:07.000 --> 01:32:09.000]  сделаем лог-фри-мьютекс, можно сделать
[01:32:09.000 --> 01:32:11.000]  лог-фри-планировщик,
[01:32:11.000 --> 01:32:13.000]  и в хорошем коде
[01:32:13.000 --> 01:32:15.000]  можно сделать почти все, что...
[01:32:15.000 --> 01:32:17.000]  почти все с лог-фри и без
[01:32:17.000 --> 01:32:19.000]  взаимного исключения. Но это очень сложно,
[01:32:19.000 --> 01:32:21.000]  но тем не менее можно так сделать.
[01:32:23.000 --> 01:32:25.000]  Вот это очень клевая часть задачи, и она вот
[01:32:25.000 --> 01:32:27.000]  это на самом деле не то, что вот просто
[01:32:27.000 --> 01:32:29.000]  сделаем лог-фри-мьютекс. Он очень сильно
[01:32:29.000 --> 01:32:31.000]  ускоряет реализацию
[01:32:31.000 --> 01:32:33.000]  файберов именно за счет того,
[01:32:33.000 --> 01:32:35.000]  что в нем можно сделать серийность.
[01:32:35.000 --> 01:32:37.000]  А что такое серийность? Но про это у нас задача
[01:32:37.000 --> 01:32:39.000]  текущая.
[01:32:39.000 --> 01:32:41.000]  Короче, тут все связано, вы даже не представляете
[01:32:41.000 --> 01:32:43.000]  насколько все связано.
[01:32:43.000 --> 01:32:45.000]  Вот те, кто
[01:32:45.000 --> 01:32:47.000]  пройдут до конца, они
[01:32:47.000 --> 01:32:49.000]  это все почувствуют и, возможно,
[01:32:49.000 --> 01:32:51.000]  восхитятся. Мне это поражает
[01:32:51.000 --> 01:32:53.000]  все лично, как все в итоге
[01:32:53.000 --> 01:32:55.000]  сложилось. Ну, очень красиво все
[01:32:55.000 --> 01:32:57.000]  вместе сходится.
[01:32:57.000 --> 01:32:59.000]  По поводу фьюч, ты спрашивал
[01:32:59.000 --> 01:33:01.000]  еще, да, или кто-то спрашивал?
[01:33:01.000 --> 01:33:03.000]  Ну, вот фьюч они сами по себе,
[01:33:03.000 --> 01:33:05.000]  но в принципе можно научиться
[01:33:05.000 --> 01:33:07.000]  научиться научить файберы их дожидаться, с ними
[01:33:07.000 --> 01:33:09.000]  работать.
[01:33:11.000 --> 01:33:13.000]  А мы
[01:33:13.000 --> 01:33:15.000]  настолько, да.
[01:33:15.000 --> 01:33:17.000]  Но мы это все вместе свяжем.
[01:33:17.000 --> 01:33:19.000]  Вот мы пишем эту
[01:33:19.000 --> 01:33:21.000]  библиотеку EXE, которая называется, здесь, да,
[01:33:21.000 --> 01:33:23.000]  Pro Execution.
[01:33:23.000 --> 01:33:25.000]  Чуть позже, но я думаю, что
[01:33:25.000 --> 01:33:27.000]  где-то к концу апреля у нас появится задача,
[01:33:27.000 --> 01:33:29.000]  которая,
[01:33:29.000 --> 01:33:31.000]  ну, такая домашка
[01:33:31.000 --> 01:33:33.000]  общая, куда нужно все складывать.
[01:33:33.000 --> 01:33:35.000]  Мюток, секундвары наши,
[01:33:35.000 --> 01:33:37.000]  потом из них сделать файберы,
[01:33:37.000 --> 01:33:39.000]  ну, туда планировщик положить,
[01:33:39.000 --> 01:33:41.000]  разные планировщики и файберы
[01:33:41.000 --> 01:33:43.000]  положить, и фьюч положить.
[01:33:43.000 --> 01:33:45.000]  И в итоге у тебя и файберы будут
[01:33:47.000 --> 01:33:49.000]  файберы будут использовать
[01:33:49.000 --> 01:33:51.000]  разные планировщики, будут их
[01:33:51.000 --> 01:33:53.000]  поддерживать те, которые мы делаем в новой
[01:33:53.000 --> 01:33:55.000]  задаче
[01:33:57.000 --> 01:33:59.000]  в виде экзекьютора. Будут исполняться уже
[01:33:59.000 --> 01:34:01.000]  в них, а не конкретно в тратпуле.
[01:34:01.000 --> 01:34:03.000]  И могут дожидаться фьюч.
[01:34:03.000 --> 01:34:05.000]  Ну, то есть все это вместе можно будет слепить.
[01:34:05.000 --> 01:34:07.000]  И все будет сделано хорошо.
[01:34:07.000 --> 01:34:09.000]  Ну, то есть если ты сделаешь все хорошо, то все будет работать
[01:34:09.000 --> 01:34:11.000]  хорошо, и все будет друг с другом сочетаться.
[01:34:11.000 --> 01:34:13.000]  Это сложно.
[01:34:13.000 --> 01:34:15.000]  Вот я прям...
[01:34:15.000 --> 01:34:17.000]  Люди разные думают, как это сделать, я тоже
[01:34:17.000 --> 01:34:19.000]  думаю уже несколько лет. Ну, вот это некоторые текущие
[01:34:19.000 --> 01:34:21.000]  итогы, как это все можно совместить.
[01:34:21.000 --> 01:34:23.000]  Но я подумал за вас, поэтому я знаю, к чему
[01:34:23.000 --> 01:34:25.000]  мы можем прийти, и мы так неспешно
[01:34:25.000 --> 01:34:27.000]  идем.
[01:34:27.000 --> 01:34:29.000]  Еще один нюанс.
[01:34:29.000 --> 01:34:31.000]  Ну, возвращаемся уже к моделям памяти
[01:34:31.000 --> 01:34:33.000]  текущим.
[01:34:33.000 --> 01:34:35.000]  Мы изучаем модели памяти,
[01:34:35.000 --> 01:34:37.000]  и
[01:34:37.000 --> 01:34:39.000]  это такая тема
[01:34:39.000 --> 01:34:41.000]  перпендикулярная почти всему, что
[01:34:41.000 --> 01:34:43.000]  происходит.
[01:34:43.000 --> 01:34:45.000]  И эта перпендикулярность, наоборот,
[01:34:45.000 --> 01:34:47.000]  полезна. Вот мы пишем файбер,
[01:34:47.000 --> 01:34:49.000]  и там возникают атомики.
[01:34:49.000 --> 01:34:51.000]  В конце концов, мы делаем все из атомиков.
[01:34:51.000 --> 01:34:53.000]  А вот атомик, и каждая операция над ним,
[01:34:53.000 --> 01:34:55.000]  это повод
[01:34:55.000 --> 01:34:57.000]  поставить какой-то memory order.
[01:34:57.000 --> 01:34:59.000]  Поэтому, пожалуйста, если вы пишете код,
[01:34:59.000 --> 01:35:01.000]  если у вас есть атомики,
[01:35:01.000 --> 01:35:03.000]  то давайте начнем думать, какие
[01:35:03.000 --> 01:35:05.000]  memory order там ставить.
[01:35:05.000 --> 01:35:07.000]  И вы будете решать задачи, а потом
[01:35:07.000 --> 01:35:09.000]  вы будете приходить на семинары и говорить, что
[01:35:09.000 --> 01:35:11.000]  вот у меня была такая задача, я там написал спинблок,
[01:35:11.000 --> 01:35:13.000]  мне там нужно было поставить memory order.
[01:35:13.000 --> 01:35:15.000]  Но это вы уже умеете, кажется,
[01:35:15.000 --> 01:35:17.000]  делать.
[01:35:17.000 --> 01:35:19.000]  Или вы пишете вейт-группу.
[01:35:19.000 --> 01:35:21.000]  И в хорошей вейт-группе задача там тоже
[01:35:21.000 --> 01:35:23.000]  не будет
[01:35:23.000 --> 01:35:25.000]  mutex в основном, будут
[01:35:25.000 --> 01:35:27.000]  в основном атомики.
[01:35:27.000 --> 01:35:29.000]  Плюс-минус.
[01:35:29.000 --> 01:35:31.000]  И тоже можно ставить memory order.
[01:35:31.000 --> 01:35:33.000]  Но это сложная тема.
[01:35:33.000 --> 01:35:35.000]  Короче, и в планировщике у нас будут
[01:35:35.000 --> 01:35:37.000]  тоже лог-фри, и там будут
[01:35:37.000 --> 01:35:39.000]  очереди циклические, и там
[01:35:39.000 --> 01:35:41.000]  снова нужно ставить memory order, который мы разбирали в прошлый раз.
[01:35:43.000 --> 01:35:45.000]  И если вы все будете хорошо делать,
[01:35:45.000 --> 01:35:47.000]  то в конце курса у нас будет возможность
[01:35:47.000 --> 01:35:49.000]  код попрофилировать.
[01:35:49.000 --> 01:35:51.000]  Вот мне это хочется сделать,
[01:35:51.000 --> 01:35:53.000]  мы никогда этим не занимались, вот прям
[01:35:53.000 --> 01:35:55.000]  пооптимизировать большую библиотеку и еще
[01:35:55.000 --> 01:35:57.000]  и пооптимизировать ее.
[01:35:57.000 --> 01:35:59.000]  Но пооптимизировать не так, как вы там
[01:35:59.000 --> 01:36:01.000]  привыкли алгоритмически пооптимизировать.
[01:36:01.000 --> 01:36:03.000]  Это не важно как раз в жизни.
[01:36:03.000 --> 01:36:05.000]  А пооптимизировать именно вот на уровне
[01:36:05.000 --> 01:36:07.000]  синхронизации, на уровне memory orders,
[01:36:07.000 --> 01:36:09.000]  на уровне там лишних аллокаций памяти.
[01:36:09.000 --> 01:36:11.000]  И можно все это увидеть, как
[01:36:11.000 --> 01:36:13.000]  все это вдруг будет
[01:36:13.000 --> 01:36:15.000]  ускорять, ускорять, ускорять ваш код.
[01:36:15.000 --> 01:36:17.000]  Вот на рекции про планировщика
[01:36:17.000 --> 01:36:19.000]  эту тему продолжу.
[01:36:19.000 --> 01:36:21.000]  Пока оптимизировать трудно, в смысле, потому что измерить трудно.
[01:36:21.000 --> 01:36:23.000]  Вот если вы запустите профайлер,
[01:36:23.000 --> 01:36:25.000]  если вы делали это когда-нибудь,
[01:36:25.000 --> 01:36:27.000]  то вы увидите, что сейчас
[01:36:27.000 --> 01:36:29.000]  реализация файберов может быть очень хорошая,
[01:36:29.000 --> 01:36:31.000]  но под ними может быть очень медленный планировщик.
[01:36:31.000 --> 01:36:33.000]  Вот Redpool это очень плохой планировщик
[01:36:33.000 --> 01:36:35.000]  для файберов.
[01:36:35.000 --> 01:36:37.000]  Мы про это в субботу поговорим, научимся его делать хорошо,
[01:36:37.000 --> 01:36:39.000]  и потом про это будет домашко.
[01:36:39.000 --> 01:36:41.000]  И вот тогда уже, когда и файберы будут
[01:36:41.000 --> 01:36:43.000]  хорошими, и планировщик, можно прям
[01:36:43.000 --> 01:36:45.000]  будет оптимизировать.
[01:36:45.000 --> 01:36:47.000]  Но пока, пожалуйста, оптимизируйте файберы.
[01:36:47.000 --> 01:36:49.000]  У вас плохой планировщик, но файберы уже могут быть
[01:36:49.000 --> 01:36:51.000]  хорошими.
[01:36:51.000 --> 01:36:53.000]  Там может быть мало локаций,
[01:36:53.000 --> 01:36:55.000]  меньше синхронизаций.
[01:36:55.000 --> 01:36:57.000]  В общем, подумайте, на что вы там
[01:36:57.000 --> 01:36:59.000]  тратите лишнее время.
[01:37:01.000 --> 01:37:03.000]  Объясню, что происходит, да?
[01:37:03.000 --> 01:37:05.000]  Вот в конце может получиться очень крутая вещь,
[01:37:05.000 --> 01:37:07.000]  потому что мы не пишем с вами какой-то учебный код,
[01:37:07.000 --> 01:37:09.000]  мы пишем вполне настоящий го.
[01:37:09.000 --> 01:37:11.000]  То есть тот го, который у вас получится,
[01:37:11.000 --> 01:37:13.000]  он будет настолько хорош, насколько вы напишете его.
[01:37:13.000 --> 01:37:15.000]  Тут нет никаких искусственных
[01:37:15.000 --> 01:37:17.000]  ограничений, что мы какую-то поделку получим.
[01:37:17.000 --> 01:37:19.000]  Вот вы можете получить код, который
[01:37:19.000 --> 01:37:21.000]  будет настолько же эффективен.
[01:37:21.000 --> 01:37:23.000]  Вопрос только в том, насколько вы
[01:37:23.000 --> 01:37:25.000]  вложились в отдельные маленькие
[01:37:25.000 --> 01:37:27.000]  детали. Ну а мы с вами
[01:37:27.000 --> 01:37:29.000]  учимся каждую деталь оптимизировать.
[01:37:29.000 --> 01:37:31.000]  И теперь мы возвращаемся
[01:37:31.000 --> 01:37:33.000]  наконец к моделям памяти.
[01:37:35.000 --> 01:37:37.000]  Что мы с вами делали
[01:37:37.000 --> 01:37:39.000]  с моделем памяти?
[01:37:39.000 --> 01:37:41.000]  Мы...
[01:37:41.000 --> 01:37:43.000]  Вообще у нас еще локфри
[01:37:43.000 --> 01:37:45.000]  пропадает. Мы до сих пор
[01:37:45.000 --> 01:37:47.000]  не разбирали локфри, который был на последней
[01:37:47.000 --> 01:37:49.000]  лекции. А там было управление памятью,
[01:37:49.000 --> 01:37:51.000]  и мы по нему ничего не сказали до сих пор.
[01:37:51.000 --> 01:37:53.000]  А еще
[01:37:53.000 --> 01:37:55.000]  мы знаете, что упускаем, пока у нас не хватает
[01:37:55.000 --> 01:37:57.000]  времени на все? Мы
[01:37:57.000 --> 01:37:59.000]  все еще не поговорили про то, как устроен
[01:37:59.000 --> 01:38:01.000]  третцинитайзер.
[01:38:01.000 --> 01:38:03.000]  А ведь третцинитайзер, он крутой,
[01:38:03.000 --> 01:38:05.000]  потому что он умеет находить
[01:38:05.000 --> 01:38:07.000]  баги очень сложные. Вот помните,
[01:38:07.000 --> 01:38:09.000]  мы расставляли барьеры в циклическом буфере.
[01:38:09.000 --> 01:38:11.000]  Мы говорили, что вот здесь
[01:38:11.000 --> 01:38:13.000]  мы
[01:38:13.000 --> 01:38:15.000]  пишем с релизом.
[01:38:15.000 --> 01:38:17.000]  Здесь мы читаем с
[01:38:17.000 --> 01:38:19.000]  Acquire и...
[01:38:19.000 --> 01:38:21.000]  Давайте это
[01:38:21.000 --> 01:38:23.000]  сотрем, пока это не нужны
[01:38:23.000 --> 01:38:25.000]  подсказки нам. Мы пишем
[01:38:25.000 --> 01:38:27.000]  здесь в буфер
[01:38:27.000 --> 01:38:29.000]  и двигаем вперед хвост с
[01:38:29.000 --> 01:38:31.000]  релизом. Здесь мы читаем хвост,
[01:38:31.000 --> 01:38:33.000]  и если мы видим, что вот он впереди, то значит
[01:38:33.000 --> 01:38:35.000]  можно читать из текущего слота.
[01:38:35.000 --> 01:38:37.000]  И вот если мы напишем здесь
[01:38:37.000 --> 01:38:39.000]  не Acquire, а Relaxed,
[01:38:39.000 --> 01:38:41.000]  ну вот правильно это Acquire,
[01:38:41.000 --> 01:38:43.000]  чтобы была синхронизация с
[01:38:43.000 --> 01:38:45.000]  то есть запись
[01:38:45.000 --> 01:38:47.000]  буфер была упорядочена
[01:38:47.000 --> 01:38:49.000]  через Happens Before с первым чтением.
[01:38:49.000 --> 01:38:51.000]  И вот нужен BlockWire.
[01:38:51.000 --> 01:38:53.000]  Но если мы вдруг написали Relaxed
[01:38:53.000 --> 01:38:55.000]  и запустили
[01:38:55.000 --> 01:38:57.000]  код под третцинитайзером...
[01:38:59.000 --> 01:39:01.000]  Нет, это не тот код.
[01:39:01.000 --> 01:39:03.000]  Под третцинитайзером,
[01:39:03.000 --> 01:39:05.000]  то что мы там увидим?
[01:39:07.000 --> 01:39:09.000]  Он неспешно запускается
[01:39:09.000 --> 01:39:11.000]  и ловится DataRace.
[01:39:11.000 --> 01:39:13.000]  А почему это сложно?
[01:39:13.000 --> 01:39:15.000]  То есть почему это неожиданно вообще, что DataRace мы поймали?
[01:39:15.000 --> 01:39:17.000]  Это неожиданно, потому что
[01:39:17.000 --> 01:39:19.000]  мы с вами говорили, кажется, что
[01:39:19.000 --> 01:39:21.000]  на x86
[01:39:21.000 --> 01:39:23.000]  и Release, и Acquire,
[01:39:23.000 --> 01:39:25.000]  и Relaxed компилируются просто в Moves.
[01:39:25.000 --> 01:39:27.000]  Ну то есть
[01:39:27.000 --> 01:39:29.000]  модель памяти самого процессора
[01:39:29.000 --> 01:39:31.000]  достаточно сильная,
[01:39:31.000 --> 01:39:33.000]  и просто вот голый
[01:39:33.000 --> 01:39:35.000]  Move — это уже Release-запись.
[01:39:35.000 --> 01:39:37.000]  Голый Move — это уже Acquire-чтение.
[01:39:37.000 --> 01:39:39.000]  То есть сам процессор
[01:39:39.000 --> 01:39:41.000]  обеспечивает нам причинность.
[01:39:41.000 --> 01:39:43.000]  То есть в исполнении
[01:39:43.000 --> 01:39:45.000]  на вот этом компьютере вот этой программы
[01:39:45.000 --> 01:39:47.000]  ничего плохого случиться не могло.
[01:39:47.000 --> 01:39:49.000]  Потому что вот что Acquire,
[01:39:49.000 --> 01:39:51.000]  что Release — это один и тот же машинный код.
[01:39:51.000 --> 01:39:53.000]  И вот именно третцинитайзер
[01:39:53.000 --> 01:39:55.000]  это находит, потому что он
[01:39:55.000 --> 01:39:57.000]  прям явно проверяет, что Happens Before есть.
[01:39:57.000 --> 01:39:59.000]  Он прям явно трекает
[01:39:59.000 --> 01:40:01.000]  вот эти вот частичные порядки.
[01:40:01.000 --> 01:40:03.000]  А как он это делает? Это достаточно не тривиально,
[01:40:03.000 --> 01:40:05.000]  это достаточно интересно.
[01:40:05.000 --> 01:40:07.000]  И алгоритмы некоторые,
[01:40:07.000 --> 01:40:09.000]  и инженерная задача алгоритмическая — она интересная.
[01:40:09.000 --> 01:40:11.000]  Хочется про это поговорить однажды,
[01:40:11.000 --> 01:40:13.000]  когда у нас появится время.
[01:40:13.000 --> 01:40:15.000]  Ну а сегодня нам нужно разобрать
[01:40:15.000 --> 01:40:17.000]  Memory Order дальше, потому что мы еще не все изучили.
[01:40:17.000 --> 01:40:19.000]  Вот мы с вами научились
[01:40:19.000 --> 01:40:21.000]  использовать Relaxed,
[01:40:21.000 --> 01:40:23.000]  Acquire-Release,
[01:40:23.000 --> 01:40:25.000]  ну мы и так использовали,
[01:40:25.000 --> 01:40:27.000]  а Acquire-Release научились использовать Relaxed.
[01:40:27.000 --> 01:40:29.000]  Ну вот здесь мы как использовали Relaxed?
[01:40:29.000 --> 01:40:31.000]  Мы говорили,
[01:40:31.000 --> 01:40:33.000]  что вот у нас есть операция,
[01:40:33.000 --> 01:40:35.000]  за потоком Producer-Consumer,
[01:40:37.000 --> 01:40:39.000]  и Producer добавляет данные
[01:40:39.000 --> 01:40:41.000]  в буфер, двигает вперед Tail.
[01:40:41.000 --> 01:40:43.000]  А потом он
[01:40:43.000 --> 01:40:45.000]  сам Tail перечитывает.
[01:40:47.000 --> 01:40:49.000]  Ну а у нас здесь гарантии,
[01:40:49.000 --> 01:40:51.000]  которые мы ожидаем от однопоточной программы.
[01:40:51.000 --> 01:40:53.000]  Если однопоточная программа записала что-то в ячейку,
[01:40:53.000 --> 01:40:55.000]  а потом сама читает,
[01:40:55.000 --> 01:40:57.000]  то, разумеется, она видит собственные записи.
[01:40:57.000 --> 01:40:59.000]  То есть
[01:40:59.000 --> 01:41:01.000]  это у нас называлось в модели памяти
[01:41:01.000 --> 01:41:03.000]  гарантия Program Order,
[01:41:03.000 --> 01:41:05.000]  частичный порядок Program Order,
[01:41:05.000 --> 01:41:07.000]  который связывал все обращения
[01:41:07.000 --> 01:41:09.000]  в одном потоке.
[01:41:09.000 --> 01:41:11.000]  И мы говорили, что чтение не противоречит
[01:41:11.000 --> 01:41:13.000]  Program Order. То есть чтение читает, по крайней мере,
[01:41:13.000 --> 01:41:15.000]  последнюю запись в Program Order.
[01:41:15.000 --> 01:41:17.000]  Поэтому здесь могло быть
[01:41:17.000 --> 01:41:19.000]  написано Relaxed.
[01:41:19.000 --> 01:41:21.000]  Да?
[01:41:21.000 --> 01:41:23.000]  А теперь вопрос.
[01:41:23.000 --> 01:41:25.000]  А пусть теперь с этим
[01:41:25.000 --> 01:41:27.000]  буфером работают не два потока,
[01:41:27.000 --> 01:41:29.000]  а два файбера?
[01:41:31.000 --> 01:41:33.000]  И файбер...
[01:41:35.000 --> 01:41:37.000]  Ну в чем разница?
[01:41:37.000 --> 01:41:39.000]  Файбер запускается на одном потоке
[01:41:39.000 --> 01:41:41.000]  в треттпуле,
[01:41:41.000 --> 01:41:43.000]  делает продьюс,
[01:41:43.000 --> 01:41:45.000]  пишет в 42-й слот,
[01:41:45.000 --> 01:41:47.000]  пишет в tail 43,
[01:41:47.000 --> 01:41:49.000]  а потом вдруг говорит yield
[01:41:49.000 --> 01:41:51.000]  и оказывается на другом потоке
[01:41:51.000 --> 01:41:53.000]  треттпула. И в нем
[01:41:53.000 --> 01:41:55.000]  он читает свой tail.
[01:41:57.000 --> 01:41:59.000]  Вопрос. Почему он увидит
[01:41:59.000 --> 01:42:01.000]  актуальное значение?
[01:42:01.000 --> 01:42:03.000]  Вот Relaxed не гарантирует актуального значения.
[01:42:03.000 --> 01:42:05.000]  Relaxed говорит, что у вас есть на Atomic
[01:42:05.000 --> 01:42:07.000]  Modification Order, то есть все записи
[01:42:07.000 --> 01:42:09.000]  упорядочены,
[01:42:09.000 --> 01:42:11.000]  но при этом чтение может какую-то более
[01:42:11.000 --> 01:42:13.000]  старую прочесть.
[01:42:13.000 --> 01:42:15.000]  Главное, что монотонно по истории.
[01:42:17.000 --> 01:42:19.000]  Так вот, если этот код работает
[01:42:19.000 --> 01:42:21.000]  с файберовыми, с потоками и запускается
[01:42:21.000 --> 01:42:23.000]  в разных потоках,
[01:42:23.000 --> 01:42:25.000]  то можно ли здесь писать Relaxed?
[01:42:25.000 --> 01:42:27.000]  Или нельзя?
[01:42:27.000 --> 01:42:29.000]  Проблема понятна?
[01:42:37.000 --> 01:42:39.000]  Но Program Order это точно больше нет,
[01:42:39.000 --> 01:42:41.000]  потому что мы в одном потоке были потом в другом.
[01:42:41.000 --> 01:42:43.000]  Этим мы пользоваться не можем.
[01:42:49.000 --> 01:42:51.000]  То есть мы этот код выполнили в одном потоке,
[01:42:51.000 --> 01:42:53.000]  потом перезапустились в другом потоке,
[01:42:53.000 --> 01:42:55.000]  и здесь в новом потоке делаем
[01:42:55.000 --> 01:42:57.000]  Relaxed.
[01:42:57.000 --> 01:42:59.000]  И Relaxed нам не обещает
[01:42:59.000 --> 01:43:01.000]  самую свежую запись.
[01:43:01.000 --> 01:43:03.000]  Можем ли мы на это рассчитывать тогда?
[01:43:03.000 --> 01:43:05.000]  На этот Relaxed.
[01:43:09.000 --> 01:43:11.000]  Но я не знаю, это к тебе вопрос.
[01:43:13.000 --> 01:43:15.000]  Смотрите, о чем мы
[01:43:15.000 --> 01:43:17.000]  говорим сейчас. У нас были два потока,
[01:43:17.000 --> 01:43:19.000]  и с ними код работал.
[01:43:19.000 --> 01:43:21.000]  А теперь мы заменяем потоки на
[01:43:21.000 --> 01:43:23.000]  файбера.
[01:43:23.000 --> 01:43:25.000]  Но
[01:43:25.000 --> 01:43:27.000]  было бы странно,
[01:43:27.000 --> 01:43:29.000]  если бы
[01:43:29.000 --> 01:43:31.000]  при переходе от потоков к файберам
[01:43:31.000 --> 01:43:33.000]  нам бы пришлось ставить другие Memory Order,
[01:43:33.000 --> 01:43:35.000]  потому что для нас файберы это просто реализация
[01:43:35.000 --> 01:43:37.000]  потоков. И было бы
[01:43:37.000 --> 01:43:39.000]  странно, если бы мы поставили другую реализацию,
[01:43:39.000 --> 01:43:41.000]  и вдруг бы гарантии поменялись.
[01:43:41.000 --> 01:43:43.000]  У нас файберы
[01:43:43.000 --> 01:43:45.000]  в смысле наблюдаемого поведения,
[01:43:45.000 --> 01:43:47.000]  в смысле их использования, они должны ничем
[01:43:47.000 --> 01:43:49.000]  отличаться от потоков настоящих.
[01:43:49.000 --> 01:43:51.000]  Но вру, они у нас
[01:43:51.000 --> 01:43:53.000]  кооперативные, они не умеют выяснения.
[01:43:53.000 --> 01:43:55.000]  Но это
[01:43:55.000 --> 01:43:57.000]  такая деталь,
[01:43:57.000 --> 01:43:59.000]  не очень важная для нас.
[01:43:59.000 --> 01:44:01.000]  Она ни на что не влияет.
[01:44:03.000 --> 01:44:05.000]  Точнее, она влияет, конечно, но в нашем коде
[01:44:05.000 --> 01:44:07.000]  мы предполагаем, что файберы не будут долго
[01:44:07.000 --> 01:44:09.000]  работать, не переключаясь.
[01:44:09.000 --> 01:44:11.000]  Так что мы готовы это пережить.
[01:44:11.000 --> 01:44:13.000]  А во всем остальном, абсолютно во всем
[01:44:13.000 --> 01:44:15.000]  остальном, файберы должны вести себя так
[01:44:15.000 --> 01:44:17.000]  к потоке.
[01:44:17.000 --> 01:44:19.000]  И было бы странно, если бы при переходе
[01:44:19.000 --> 01:44:21.000]  от потоков к файберам нам пришлось бы выставить
[01:44:21.000 --> 01:44:23.000]  другой мой реордер.
[01:44:23.000 --> 01:44:25.000]  Действительно, не нужно.
[01:44:25.000 --> 01:44:27.000]  Но нужно понять, почему теперь релакс от чтения
[01:44:27.000 --> 01:44:29.000]  все равно прочтет последнюю запись.
[01:44:29.000 --> 01:44:31.000]  Вообще, как
[01:44:31.000 --> 01:44:33.000]  гарантировать, что
[01:44:33.000 --> 01:44:35.000]  чтение прочтет запись? Это такой
[01:44:35.000 --> 01:44:37.000]  фундаментальный вопрос по модели памяти.
[01:44:37.000 --> 01:44:39.000]  Как это гарантировать?
[01:44:39.000 --> 01:44:41.000]  Как мы это гарантировали раньше,
[01:44:41.000 --> 01:44:43.000]  на прошлом занятии?
[01:44:45.000 --> 01:44:47.000]  Ну, это частный случай.
[01:44:49.000 --> 01:44:51.000]  Общий случай.
[01:44:53.000 --> 01:44:55.000]  Happens before. Но program order
[01:44:55.000 --> 01:44:57.000]  это же частный случай Happens before.
[01:44:57.000 --> 01:44:59.000]  Program order – это порядок внутри одного потока,
[01:44:59.000 --> 01:45:01.000]  то есть тоже причинность. А Happens before
[01:45:01.000 --> 01:45:03.000]  обобщает причинность на разные потоки.
[01:45:05.000 --> 01:45:07.000]  Как обобщает? Ну, вот там появляется
[01:45:07.000 --> 01:45:09.000]  synchronize the Swiss.
[01:45:11.000 --> 01:45:13.000]  Вот у нас один поток записал
[01:45:13.000 --> 01:45:15.000]  что-то, а другой прочитал то, что было
[01:45:15.000 --> 01:45:17.000]  записано. И вот мы теперь
[01:45:17.000 --> 01:45:19.000]  рассчитываем на причинность.
[01:45:23.000 --> 01:45:25.000]  Вот здесь, в этом коде,
[01:45:25.000 --> 01:45:27.000]  в этом мысленном эксперименте с файберами
[01:45:27.000 --> 01:45:29.000]  это и происходит. Смотрите.
[01:45:31.000 --> 01:45:33.000]  Был у нас файбер.
[01:45:33.000 --> 01:45:35.000]  Был у нас
[01:45:35.000 --> 01:45:37.000]  некоторый файбер-продюсер.
[01:45:41.000 --> 01:45:43.000]  И он исполнялся в потоке
[01:45:43.000 --> 01:45:45.000]  пулаты 1. Он там
[01:45:45.000 --> 01:45:47.000]  исполнил try produce x.
[01:45:49.000 --> 01:45:51.000]  В нем он положил в буфер
[01:45:51.000 --> 01:45:53.000]  в позицию 42x.
[01:45:57.000 --> 01:45:59.000]  А потом он сделал
[01:45:59.000 --> 01:46:01.000]  trail store 43.
[01:46:05.000 --> 01:46:07.000]  Что произошло дальше?
[01:46:09.000 --> 01:46:11.000]  Дальше
[01:46:11.000 --> 01:46:13.000]  файбер сказал yield.
[01:46:15.000 --> 01:46:17.000]  Ну, сейчас
[01:46:17.000 --> 01:46:19.000]  давайте пока я на этом закончу,
[01:46:19.000 --> 01:46:21.000]  а дальше поставлю многоточие, а потом
[01:46:21.000 --> 01:46:23.000]  скажем, что файбер запустился дальше на потоки
[01:46:23.000 --> 01:46:25.000]  t3, и в нем вызвал
[01:46:25.000 --> 01:46:27.000]  снова try produce.
[01:46:27.000 --> 01:46:29.000]  И начал он
[01:46:29.000 --> 01:46:31.000]  с того, что
[01:46:31.000 --> 01:46:33.000]  прочитал себе
[01:46:37.000 --> 01:46:39.000]  loads relaxed.
[01:46:41.000 --> 01:46:43.000]  И мы хотим, чтобы он увидел 43 здесь.
[01:46:45.000 --> 01:46:47.000]  Но давайте подумаем, что
[01:46:47.000 --> 01:46:49.000]  происходит посередине.
[01:46:49.000 --> 01:46:51.000]  Вот посередине мы в файбере
[01:46:51.000 --> 01:46:53.000]  в потоке t1 сказали yield.
[01:46:57.000 --> 01:46:59.000]  А что внутри
[01:46:59.000 --> 01:47:01.000]  этого yield произошло?
[01:47:03.000 --> 01:47:05.000]  Ну, мы сначала сделали
[01:47:05.000 --> 01:47:07.000]  core suspend,
[01:47:07.000 --> 01:47:09.000]  наверное, да?
[01:47:09.000 --> 01:47:11.000]  Остановили корутин.
[01:47:11.000 --> 01:47:13.000]  А потом
[01:47:13.000 --> 01:47:15.000]  мы сказали
[01:47:17.000 --> 01:47:19.000]  планировщик, threadpool,
[01:47:19.000 --> 01:47:21.000]  submit,
[01:47:21.000 --> 01:47:23.000]  и передали туда
[01:47:23.000 --> 01:47:25.000]  pointer на наш файбер,
[01:47:25.000 --> 01:47:27.000]  и запустились.
[01:47:31.000 --> 01:47:33.000]  Запустимся, когда задача
[01:47:33.000 --> 01:47:35.000]  будет выполняться.
[01:47:39.000 --> 01:47:41.000]  А что внутри submita происходит
[01:47:41.000 --> 01:47:43.000]  внутри потоков?
[01:47:49.000 --> 01:47:51.000]  Кладем задачу в очередь.
[01:47:51.000 --> 01:47:53.000]  А что происходит там?
[01:47:55.000 --> 01:47:57.000]  Ну, мы берем mutex,
[01:47:59.000 --> 01:48:01.000]  а потом мы в какую-то
[01:48:01.000 --> 01:48:03.000]  очередь добавляем
[01:48:07.000 --> 01:48:09.000]  какое-то абстрактное значение.
[01:48:11.000 --> 01:48:13.000]  Ну, это если вот
[01:48:13.000 --> 01:48:15.000]  разворачивать все, что происходит
[01:48:15.000 --> 01:48:17.000]  в нашем коде, да?
[01:48:19.000 --> 01:48:21.000]  А потом на потоке t3
[01:48:21.000 --> 01:48:23.000]  что случилось?
[01:48:25.000 --> 01:48:27.000]  Threadpool в процедуре
[01:48:27.000 --> 01:48:29.000]  worker routing
[01:48:33.000 --> 01:48:35.000]  взял задачу из очереди,
[01:48:37.000 --> 01:48:39.000]  а для этого он
[01:48:39.000 --> 01:48:41.000]  снова взял mutex
[01:48:45.000 --> 01:48:47.000]  и
[01:48:47.000 --> 01:48:49.000]  сказал
[01:48:49.000 --> 01:48:51.000]  вот так.
[01:48:57.000 --> 01:48:59.000]  Понятно, да?
[01:48:59.000 --> 01:49:01.000]  Ну и все, смотрите, мы же уже научились
[01:49:01.000 --> 01:49:03.000]  писать вам spinlock.
[01:49:03.000 --> 01:49:05.000]  Spinlock, вот он был.
[01:49:05.000 --> 01:49:07.000]  Как он работал?
[01:49:07.000 --> 01:49:09.000]  Он в онлоке делал store с релизом,
[01:49:09.000 --> 01:49:11.000]  в чтении он делал,
[01:49:11.000 --> 01:49:13.000]  в захвате в онлоке он делал
[01:49:13.000 --> 01:49:15.000]  log exchange с aquire
[01:49:15.000 --> 01:49:17.000]  и вот с помощью этого
[01:49:17.000 --> 01:49:19.000]  релиза aquire, то есть мы крутили здесь,
[01:49:19.000 --> 01:49:21.000]  пока мы не увидим эту запись,
[01:49:21.000 --> 01:49:23.000]  и когда мы увидели, у нас получился
[01:49:23.000 --> 01:49:25.000]  synchronize with.
[01:49:25.000 --> 01:49:27.000]  И таким образом все критические секции
[01:49:27.000 --> 01:49:29.000]  связаны отношением happens before.
[01:49:29.000 --> 01:49:31.000]  Поэтому у нас,
[01:49:31.000 --> 01:49:33.000]  в нашем коде, в нашем мысленном
[01:49:33.000 --> 01:49:35.000]  эксперименте,
[01:49:35.000 --> 01:49:37.000]  вот этот онлок
[01:49:37.000 --> 01:49:39.000]  будет упорядочен
[01:49:39.000 --> 01:49:41.000]  с этим локом
[01:49:41.000 --> 01:49:43.000]  через happens before.
[01:49:43.000 --> 01:49:45.000]  Ну а значит мы упорядочили
[01:49:45.000 --> 01:49:47.000]  через happens before этот store и вот этот
[01:49:47.000 --> 01:49:49.000]  лод.
[01:49:49.000 --> 01:49:51.000]  Ну и все.
[01:49:51.000 --> 01:49:53.000]  То есть у нас
[01:49:53.000 --> 01:49:55.000]  happens before получился
[01:49:55.000 --> 01:49:57.000]  не напрямую
[01:49:57.000 --> 01:49:59.000]  за счет атомика какого-то,
[01:49:59.000 --> 01:50:01.000]  а он получился, потому что
[01:50:01.000 --> 01:50:03.000]  мы воспользовались где-то в недрах
[01:50:03.000 --> 01:50:05.000]  нашего runtime
[01:50:05.000 --> 01:50:07.000]  и файберов примитивом синхронизации.
[01:50:07.000 --> 01:50:09.000]  Ну это такой общий рецепт.
[01:50:09.000 --> 01:50:11.000]  У вас happens before
[01:50:11.000 --> 01:50:13.000]  продляется, переносится
[01:50:13.000 --> 01:50:15.000]  из одного потока в другой, когда вы пишете
[01:50:15.000 --> 01:50:17.000]  в атомик, читаете из атомика, или когда вы
[01:50:17.000 --> 01:50:19.000]  отпускаете лог, берете лог,
[01:50:19.000 --> 01:50:21.000]  или когда делаете push в очередь, потом
[01:50:21.000 --> 01:50:23.000]  извлекаете, делаете pop в очереди.
[01:50:23.000 --> 01:50:25.000]  То есть любые примитивы синхронизации, они
[01:50:25.000 --> 01:50:27.000]  этот happens before продляют.
[01:50:27.000 --> 01:50:29.000]  Ну мы как бы
[01:50:29.000 --> 01:50:31.000]  опираемся к этому нашему
[01:50:31.000 --> 01:50:33.000]  реализацию?
[01:50:33.000 --> 01:50:35.000]  Ну мы полагаемся на то, что в планировщике
[01:50:35.000 --> 01:50:37.000]  есть корректная синхронизация.
[01:50:37.000 --> 01:50:39.000]  Это довольно разумно.
[01:50:39.000 --> 01:50:41.000]  Как иначе задача
[01:50:41.000 --> 01:50:43.000]  созданная в одном потоке
[01:50:43.000 --> 01:50:45.000]  попала в другой поток?
[01:50:45.000 --> 01:50:47.000]  Через синхронизацию.
[01:50:49.000 --> 01:50:51.000]  Ну то есть если планировщик
[01:50:51.000 --> 01:50:53.000]  устроен корректно, если в нем
[01:50:53.000 --> 01:50:55.000]  синхронизация корректная, то
[01:50:55.000 --> 01:50:57.000]  и наш файбер, будучи запущен на другом
[01:50:57.000 --> 01:50:59.000]  потоке, обязан тоже
[01:50:59.000 --> 01:51:01.000]  испытать на себе
[01:51:01.000 --> 01:51:03.000]  последствия этого happens before. То есть он может
[01:51:03.000 --> 01:51:05.000]  на это рассчитывать, и поэтому использует здесь
[01:51:05.000 --> 01:51:07.000]  релакс.
[01:51:07.000 --> 01:51:09.000]  Все верно?
[01:51:11.000 --> 01:51:13.000]  Точно, без обмана?
[01:51:19.000 --> 01:51:21.000]  Какое-то сомнение есть, да, у вас?
[01:51:21.000 --> 01:51:23.000]  Ну я просто не знаю, как
[01:51:23.000 --> 01:51:25.000]  Мельчер списать. Тут я могу
[01:51:25.000 --> 01:51:27.000]  написать, конечно, вот тут был
[01:51:27.000 --> 01:51:29.000]  вот здесь был
[01:51:29.000 --> 01:51:31.000]  еще в онлоке
[01:51:31.000 --> 01:51:33.000]  был там
[01:51:33.000 --> 01:51:35.000]  locked store, значит
[01:51:35.000 --> 01:51:37.000]  store 0 с релизом. Здесь
[01:51:37.000 --> 01:51:39.000]  в локе
[01:51:41.000 --> 01:51:43.000]  был
[01:51:43.000 --> 01:51:45.000]  lock
[01:51:45.000 --> 01:51:47.000]  exchange 1
[01:51:47.000 --> 01:51:49.000]  acquire, и он
[01:51:49.000 --> 01:51:51.000]  прочитал 0, и вот здесь
[01:51:51.000 --> 01:51:53.000]  и здесь возник синхронизация
[01:51:53.000 --> 01:51:55.000]  Swiss, и дальше он.
[01:51:55.000 --> 01:51:57.000]  Смотри, мы не
[01:51:57.000 --> 01:51:59.000]  предполагаемся на какое-то конкретное
[01:51:59.000 --> 01:52:01.000]  устройство планировщика. Для нас
[01:52:01.000 --> 01:52:03.000]  он абсолютно
[01:52:03.000 --> 01:52:05.000]  произвольно устроен, для нас это абстракция.
[01:52:05.000 --> 01:52:07.000]  Это экзекьютор, который умеет запускать
[01:52:07.000 --> 01:52:09.000]  задачи. Но если он
[01:52:09.000 --> 01:52:11.000]  многопоточный, если он получает
[01:52:11.000 --> 01:52:13.000]  задачу на одном потоке, а потом запускают ее
[01:52:13.000 --> 01:52:15.000]  в другом потоке, то
[01:52:15.000 --> 01:52:17.000]  видимо в нем должна быть синхронизация,
[01:52:17.000 --> 01:52:19.000]  с помощью которой задача переедет.
[01:52:19.000 --> 01:52:21.000]  Разумное же ожидание?
[01:52:23.000 --> 01:52:25.000]  Так что мы на это вполне можем полагаться,
[01:52:25.000 --> 01:52:27.000]  что в самом планировщике синхронизация
[01:52:27.000 --> 01:52:29.000]  корректная. Если она
[01:52:29.000 --> 01:52:31.000]  корректная, то значит она
[01:52:31.000 --> 01:52:33.000]  и для нас даст вот эту причинность.
[01:52:37.000 --> 01:52:39.000]  В конце концов, смотрите, какая
[01:52:39.000 --> 01:52:41.000]  история. Мы работаем с потоками,
[01:52:41.000 --> 01:52:43.000]  а потоки-то...
[01:52:43.000 --> 01:52:45.000]  Да, смотрите,
[01:52:45.000 --> 01:52:47.000]  это же прекрасная иллюстрация.
[01:52:47.000 --> 01:52:49.000]  Мы говорим
[01:52:49.000 --> 01:52:51.000]  про то, что в одном потоке все бы
[01:52:51.000 --> 01:52:53.000]  работало. Но у вас
[01:52:53.000 --> 01:52:55.000]  на самом деле же,
[01:52:55.000 --> 01:52:57.000]  когда процессор вам говорит
[01:52:57.000 --> 01:52:59.000]  про memory order, про барьеры,
[01:52:59.000 --> 01:53:01.000]  он говорит не про потоки, он говорит
[01:53:01.000 --> 01:53:03.000]  про ядра.
[01:53:03.000 --> 01:53:05.000]  Так что все гарантии на самом деле не про ядра.
[01:53:05.000 --> 01:53:07.000]  Просто планировщик
[01:53:07.000 --> 01:53:09.000]  операционной системы тоже так же
[01:53:09.000 --> 01:53:11.000]  устроен, тоже корректная синхронизация,
[01:53:11.000 --> 01:53:13.000]  поэтому он может запустить
[01:53:13.000 --> 01:53:15.000]  вот первый
[01:53:15.000 --> 01:53:17.000]  продьюс на одном
[01:53:17.000 --> 01:53:19.000]  ядре, потом второй продьюс
[01:53:19.000 --> 01:53:21.000]  запустить на другом ядре, но все равно гарантия
[01:53:21.000 --> 01:53:23.000]  будет, потому что опять вот те же самые
[01:53:23.000 --> 01:53:25.000]  рассуждения. Тот же планировщик тоже
[01:53:25.000 --> 01:53:27.000]  обеспечивает такую гарантию. В смысле планировщик
[01:53:27.000 --> 01:53:29.000]  уже операционной системы.
[01:53:29.000 --> 01:53:31.000]  Но у него в распоряжении только барьеры,
[01:53:31.000 --> 01:53:33.000]  которые про ядра на самом деле,
[01:53:33.000 --> 01:53:35.000]  а не про потоки.
[01:53:35.000 --> 01:53:37.000]  То есть потоки-это более высокоруневая
[01:53:37.000 --> 01:53:39.000]  сущность. Ну и здесь мы вот те же самые
[01:53:39.000 --> 01:53:41.000]  идеи воспроизводим на уровне еще выше.
[01:53:43.000 --> 01:53:45.000]  Ну потому что мы делаем то же самое.
[01:53:45.000 --> 01:53:47.000]  Мы пишем кусочек
[01:53:47.000 --> 01:53:49.000]  операционной системы.
[01:53:51.000 --> 01:53:53.000]  Сошлось?
[01:53:55.000 --> 01:53:57.000]  Так что везде обман, везде
[01:53:57.000 --> 01:53:59.000]  нужно думать.
[01:53:59.000 --> 01:54:01.000]  Можно полагаться на некоторую абстракцию,
[01:54:01.000 --> 01:54:03.000]  что вот поток-это для нас
[01:54:03.000 --> 01:54:05.000]  такое виртуальное ядро. Ну а под
[01:54:05.000 --> 01:54:07.000]  капотом все равно есть некоторые конкретные
[01:54:07.000 --> 01:54:09.000]  организмы, которые это абстракцию обеспечивают.
[01:54:13.000 --> 01:54:15.000]  Ну что, с циклическим буфером мы
[01:54:15.000 --> 01:54:17.000]  покончили, я надеюсь.
[01:54:17.000 --> 01:54:19.000]  Давно пора. Слишком простой пример.
[01:54:19.000 --> 01:54:21.000]  Он столько сложностей вызывает.
[01:54:21.000 --> 01:54:23.000]  Он нам пригодится
[01:54:23.000 --> 01:54:25.000]  в следующую, в эту
[01:54:25.000 --> 01:54:27.000]  субботу. Вот он станет
[01:54:27.000 --> 01:54:29.000]  такой рабочей, лошадкой в планировщике.
[01:54:29.000 --> 01:54:31.000]  Без него сложно будет.
[01:54:33.000 --> 01:54:35.000]  Идем дальше.
[01:54:35.000 --> 01:54:37.000]  Мы воспользовались теперь relaxed,
[01:54:37.000 --> 01:54:39.000]  acquired-release, sequential-consistency.
[01:54:39.000 --> 01:54:41.000]  Остался consume и acquired-release.
[01:54:43.000 --> 01:54:45.000]  Давайте про
[01:54:45.000 --> 01:54:47.000]  consume сейчас.
[01:54:49.000 --> 01:54:51.000]  Итак, пример.
[01:54:51.000 --> 01:54:53.000]  Но он довольно искусственный.
[01:54:53.000 --> 01:54:55.000]  Можно было бы его аккуратнее написать.
[01:54:57.000 --> 01:54:59.000]  Но я до сих пор полегился это сделать.
[01:54:59.000 --> 01:55:01.000]  Итак, у нас есть такая штука
[01:55:01.000 --> 01:55:03.000]  lazy-value. Такой контейнер
[01:55:03.000 --> 01:55:05.000]  для объекта типа T, который
[01:55:05.000 --> 01:55:07.000]  инициализируется лениво.
[01:55:09.000 --> 01:55:11.000]  В момент первого обращения.
[01:55:11.000 --> 01:55:13.000]  Вот у нас есть
[01:55:13.000 --> 01:55:15.000]  lazy-value, у него есть
[01:55:15.000 --> 01:55:17.000]  метод access,
[01:55:17.000 --> 01:55:19.000]  к которому мы обращаемся.
[01:55:21.000 --> 01:55:23.000]  И в этом методе access
[01:55:23.000 --> 01:55:25.000]  мы должны сконструировать объект,
[01:55:25.000 --> 01:55:27.000]  если он еще не был сконструирован.
[01:55:27.000 --> 01:55:29.000]  Для конструирования у нас есть вот такая
[01:55:29.000 --> 01:55:31.000]  вот функция, которая умеет построить
[01:55:31.000 --> 01:55:33.000]  где-то на кучу объектов.
[01:55:37.000 --> 01:55:39.000]  Ну и в методе access,
[01:55:39.000 --> 01:55:41.000]  мы храним в объекте
[01:55:41.000 --> 01:55:43.000]  нашим lazy-value pointer
[01:55:43.000 --> 01:55:45.000]  на созданной T.
[01:55:45.000 --> 01:55:47.000]  Если там null-pointer, то, видимо, нужно создать.
[01:55:49.000 --> 01:55:51.000]  Но инициализация объекта — это что-то,
[01:55:51.000 --> 01:55:53.000]  что происходит один раз, а обращения
[01:55:53.000 --> 01:55:55.000]  частые.
[01:55:55.000 --> 01:55:57.000]  Поэтому мы хотим оптимизировать
[01:55:57.000 --> 01:55:59.000]  обращение, сделать так, чтобы на быстром пути
[01:55:59.000 --> 01:56:01.000]  это был просто load.
[01:56:01.000 --> 01:56:03.000]  Вот мы проверили pointer, если там
[01:56:03.000 --> 01:56:05.000]  не null,
[01:56:05.000 --> 01:56:07.000]  то просто возвращаем этот pointer.
[01:56:07.000 --> 01:56:09.000]  Ну, то есть прям в ссылку
[01:56:09.000 --> 01:56:11.000]  возвращаем на объект.
[01:56:11.000 --> 01:56:13.000]  Значит, объект уже инициализирован.
[01:56:13.000 --> 01:56:15.000]  Это быстрый путь.
[01:56:15.000 --> 01:56:17.000]  А иначе медленный путь.
[01:56:17.000 --> 01:56:19.000]  Нужно объект
[01:56:19.000 --> 01:56:21.000]  проинциализировать.
[01:56:21.000 --> 01:56:23.000]  Но что, если у нас два потока пришли
[01:56:23.000 --> 01:56:25.000]  до первой инициализации,
[01:56:25.000 --> 01:56:27.000]  увидели null-pointer
[01:56:27.000 --> 01:56:29.000]  и решили оба проинциализировать
[01:56:29.000 --> 01:56:31.000]  на тот же объект?
[01:56:31.000 --> 01:56:33.000]  Между ними гуманка.
[01:56:33.000 --> 01:56:35.000]  Ну, давайте мы поставим
[01:56:35.000 --> 01:56:37.000]  mutex, чтобы
[01:56:37.000 --> 01:56:39.000]  среди них этих двух потоков был
[01:56:39.000 --> 01:56:41.000]  первый и второй.
[01:56:41.000 --> 01:56:43.000]  И каждый поток после
[01:56:43.000 --> 01:56:45.000]  захвата mutex еще раз проверит
[01:56:45.000 --> 01:56:47.000]  value-pointer.
[01:56:47.000 --> 01:56:49.000]  И если он по-прежнему null,
[01:56:49.000 --> 01:56:51.000]  то, так уж и быть, объект сконструирует.
[01:56:51.000 --> 01:56:53.000]  А если же поток,
[01:56:53.000 --> 01:56:55.000]  который пришел сюда и увидел null-pointer,
[01:56:55.000 --> 01:56:57.000]  окажется на mutex-е вторым,
[01:56:57.000 --> 01:56:59.000]  то он увидит, что
[01:56:59.000 --> 01:57:01.000]  объект уже инициализирован
[01:57:01.000 --> 01:57:03.000]  и не будет его
[01:57:03.000 --> 01:57:05.000]  инициализировать второй раз.
[01:57:05.000 --> 01:57:07.000]  Вот поэтому double-checked locking.
[01:57:07.000 --> 01:57:09.000]  То есть у нас есть быстрый путь,
[01:57:09.000 --> 01:57:11.000]  быстрый оптимистичный сценарий
[01:57:11.000 --> 01:57:13.000]  и медленный пессимистичный.
[01:57:15.000 --> 01:57:17.000]  Ну вот.
[01:57:17.000 --> 01:57:19.000]  Есть такая штука, и в ней нужно пооптимизировать
[01:57:19.000 --> 01:57:21.000]  memory-order.
[01:57:21.000 --> 01:57:23.000]  Но чтобы их оптимизировать, нужно снова
[01:57:23.000 --> 01:57:25.000]  понять, какие неатомарные
[01:57:25.000 --> 01:57:27.000]  обращения к памяти мы собираемся
[01:57:27.000 --> 01:57:29.000]  упорядочивать.
[01:57:33.000 --> 01:57:35.000]  Вот всегда, когда мы ставим memory-order,
[01:57:35.000 --> 01:57:37.000]  мы должны не про атомики
[01:57:37.000 --> 01:57:39.000]  думать, а наоборот про неатомарные
[01:57:39.000 --> 01:57:41.000]  обращения. То есть какие неатомарные
[01:57:41.000 --> 01:57:43.000]  обращения, неатомарные записи и чтения
[01:57:43.000 --> 01:57:45.000]  мы хотим упорядочить в этом коде.
[01:57:49.000 --> 01:57:51.000]  Ну вот, в 24-й строчке мы
[01:57:51.000 --> 01:57:53.000]  в некоторой памяти строим объект,
[01:57:53.000 --> 01:57:55.000]  а потом другие потоки
[01:57:55.000 --> 01:57:57.000]  вызывают access, получают ссылку
[01:57:57.000 --> 01:57:59.000]  на эту память, и вот в этой памяти
[01:57:59.000 --> 01:58:01.000]  эту память читают, работают
[01:58:01.000 --> 01:58:03.000]  с ней.
[01:58:03.000 --> 01:58:05.000]  Вот неатомарные обращения, нужно их упорядочить.
[01:58:07.000 --> 01:58:09.000]  Ну предлагайте что-нибудь.
[01:58:21.000 --> 01:58:23.000]  Ну да.
[01:58:23.000 --> 01:58:25.000]  А, ну в смысле, ты про...
[01:58:25.000 --> 01:58:27.000]  Поставь мысли на relax везде, давай так.
[01:58:27.000 --> 01:58:29.000]  То есть какие самые слабые
[01:58:29.000 --> 01:58:31.000]  memory-order тебе нужны?
[01:58:35.000 --> 01:58:37.000]  Тебе достаточно.
[01:58:39.000 --> 01:58:41.000]  Сейчас давай по-другому. То есть дело не в том,
[01:58:41.000 --> 01:58:43.000]  что какие memory-order стоят.
[01:58:43.000 --> 01:58:45.000]  Ты должен, видимо, между вот этими
[01:58:45.000 --> 01:58:47.000]  записями в память и вот последующими
[01:58:47.000 --> 01:58:49.000]  чтениями получить
[01:58:49.000 --> 01:58:51.000]  Happens Before.
[01:58:51.000 --> 01:58:53.000]  Как ты это Happens Before обеспечишь?
[01:58:55.000 --> 01:58:57.000]  У тебя же конституирование
[01:58:57.000 --> 01:58:59.000]  происходит в одном потоке,
[01:58:59.000 --> 01:59:01.000]  а чтение потом в другом потоке.
[01:59:01.000 --> 01:59:03.000]  То есть тебе нужен какой-то
[01:59:03.000 --> 01:59:05.000]  Happens Before Synchronize With.
[01:59:07.000 --> 01:59:09.000]  Что?
[01:59:11.000 --> 01:59:13.000]  Ну говори, где что писать?
[01:59:19.000 --> 01:59:21.000]  Acquire?
[01:59:21.000 --> 01:59:23.000]  Нет, там проиграть надо...
[01:59:23.000 --> 01:59:25.000]  Релиз на чтение Acquire.
[01:59:25.000 --> 01:59:27.000]  Да.
[01:59:27.000 --> 01:59:29.000]  Релиз на чтение Acquire.
[01:59:43.000 --> 01:59:45.000]  Итого, если ты в методе Access
[01:59:45.000 --> 01:59:47.000]  получил pointer на объект,
[01:59:47.000 --> 01:59:49.000]  то значит, ты его здесь прочитал.
[01:59:49.000 --> 01:59:51.000]  Если ты прочитал не null,
[01:59:51.000 --> 01:59:53.000]  то, видимо, здесь его записали,
[01:59:53.000 --> 01:59:55.000]  а значит, перед этим конституировали объект.
[01:59:55.000 --> 01:59:57.000]  Но и причинность у тебя есть
[01:59:57.000 --> 01:59:59.000]  в стиле Happens Before.
[01:59:59.000 --> 02:00:01.000]  Что?
[02:00:01.000 --> 02:00:03.000]  Давай теперь подумаем
[02:00:03.000 --> 02:00:05.000]  про вторую строчку.
[02:00:07.000 --> 02:00:09.000]  Это еще одно чтение.
[02:00:09.000 --> 02:00:11.000]  Если тут мы прочитали не null pointer,
[02:00:11.000 --> 02:00:13.000]  то мы сразу выйдем
[02:00:13.000 --> 02:00:15.000]  и вернем этот current pointer
[02:00:15.000 --> 02:00:17.000]  пользователю.
[02:00:21.000 --> 02:00:23.000]  То есть, если мы здесь
[02:00:23.000 --> 02:00:25.000]  увидели не null pointer,
[02:00:25.000 --> 02:00:27.000]  то мы, исходя из этого, обязаны
[02:00:27.000 --> 02:00:29.000]  увидеть и записи в память вот здесь.
[02:00:31.000 --> 02:00:33.000]  Как нам это обеспечить?
[02:00:41.000 --> 02:00:43.000]  Ну или что здесь нужно написать?
[02:00:45.000 --> 02:00:47.000]  То есть,
[02:00:47.000 --> 02:00:49.000]  код, который вызывает
[02:00:49.000 --> 02:00:51.000]  меня от Access,
[02:00:51.000 --> 02:00:53.000]  он получит pointer отсюда
[02:00:53.000 --> 02:00:55.000]  из этой строчки
[02:00:55.000 --> 02:00:57.000]  и будет считать, что, видимо,
[02:00:57.000 --> 02:00:59.000]  раз он получил не null,
[02:00:59.000 --> 02:01:01.000]  то можно к объекту
[02:01:01.000 --> 02:01:03.000]  обращаться.
[02:01:03.000 --> 02:01:05.000]  То есть, он уверен почему-то,
[02:01:05.000 --> 02:01:07.000]  что вызов create произошел
[02:01:07.000 --> 02:01:09.000]  до этого чтения.
[02:01:09.000 --> 02:01:11.000]  А как мы это обеспечили?
[02:01:15.000 --> 02:01:17.000]  Вот так предлагать.
[02:01:17.000 --> 02:01:19.000]  Но кажется, что это
[02:01:19.000 --> 02:01:21.000]  тот же самый случай, что и здесь, да?
[02:01:21.000 --> 02:01:23.000]  Но тогда было бы неинтересно.
[02:01:23.000 --> 02:01:25.000]  Зачем-то показывать пример,
[02:01:25.000 --> 02:01:27.000]  тут все интереснее.
[02:01:41.000 --> 02:01:43.000]  Ну что значит какие-то?
[02:01:43.000 --> 02:01:45.000]  Мы написали mutex, мы знаем, что он обеспечивает.
[02:01:47.000 --> 02:01:49.000]  Мы знаем, что критические секции
[02:01:49.000 --> 02:01:51.000]  упорядочены через happens before.
[02:01:51.000 --> 02:01:53.000]  Между ними есть этот порядок.
[02:01:53.000 --> 02:01:55.000]  Вот. И мы, смотрите, что делаем.
[02:01:55.000 --> 02:01:57.000]  Мы в критической секции здесь.
[02:01:59.000 --> 02:02:01.000]  И мы знаем, что мы вторые.
[02:02:03.000 --> 02:02:05.000]  Ну вот, значит, мы уже видим
[02:02:05.000 --> 02:02:07.000]  все записи из предшествующей секции.
[02:02:07.000 --> 02:02:09.000]  То есть, мы видим, раз мы видим
[02:02:09.000 --> 02:02:11.000]  и value pointer, раз мы видим
[02:02:11.000 --> 02:02:13.000]  и value pointer, то мы видим остальные записи.
[02:02:13.000 --> 02:02:15.000]  То есть, и create тоже.
[02:02:15.000 --> 02:02:17.000]  Так что здесь достаточно
[02:02:17.000 --> 02:02:19.000]  релаксно просто.
[02:02:21.000 --> 02:02:23.000]  Если мы во второй секции, то вторая секция
[02:02:23.000 --> 02:02:25.000]  видит все записи первой секции.
[02:02:27.000 --> 02:02:29.000]  То есть, мы здесь
[02:02:29.000 --> 02:02:31.000]  гарантированно прочтем
[02:02:31.000 --> 02:02:33.000]  уже и в value pointer не null, и в create
[02:02:33.000 --> 02:02:35.000]  уже будут.
[02:02:35.000 --> 02:02:37.000]  В памяти,
[02:02:37.000 --> 02:02:39.000]  в которой create разместил объект,
[02:02:39.000 --> 02:02:41.000]  тоже уже будут все данные видны.
[02:02:41.000 --> 02:02:43.000]  Поэтому мы просто
[02:02:43.000 --> 02:02:45.000]  возвращаем пользователю
[02:02:45.000 --> 02:02:47.000]  ссылку.
[02:02:49.000 --> 02:02:51.000]  Вот. Так работает,
[02:02:51.000 --> 02:02:53.000]  но я вроде бы обещал вам другое
[02:02:53.000 --> 02:02:55.000]  показать. Я же хотел показать вам, зачем
[02:02:55.000 --> 02:02:57.000]  нужен Consume,
[02:02:57.000 --> 02:02:59.000]  а его здесь пока нет.
[02:02:59.000 --> 02:03:01.000]  Вот это очень темная история, смотрите.
[02:03:01.000 --> 02:03:03.000]  Можно представить
[02:03:03.000 --> 02:03:05.000]  себя, когда мы говорили про
[02:03:05.000 --> 02:03:07.000]  RealizeAquire, мы говорили про такой пример.
[02:03:07.000 --> 02:03:09.000]  Был поток,
[02:03:09.000 --> 02:03:11.000]  ну ладно, ядро даже,
[02:03:11.000 --> 02:03:13.000]  C1, и в нем делались такие записи.
[02:03:13.000 --> 02:03:15.000]  Сначала мы писали в X1,
[02:03:15.000 --> 02:03:17.000]  а потом мы
[02:03:17.000 --> 02:03:19.000]  писали в Y1.
[02:03:19.000 --> 02:03:21.000]  А потом на ядре C2 мы читали
[02:03:23.000 --> 02:03:25.000]  из Y,
[02:03:27.000 --> 02:03:29.000]  и если мы тут видели,
[02:03:31.000 --> 02:03:33.000]  давайте помедленнее напишу,
[02:03:33.000 --> 02:03:35.000]  читали из Y,
[02:03:35.000 --> 02:03:37.000]  и если
[02:03:37.000 --> 02:03:39.000]  видели один,
[02:03:41.000 --> 02:03:43.000]  то читали
[02:03:43.000 --> 02:03:45.000]  из X.
[02:03:49.000 --> 02:03:51.000]  И тоже ожидали здесь увидеть единицу.
[02:03:51.000 --> 02:03:53.000]  Ну точнее как,
[02:03:53.000 --> 02:03:55.000]  мы пишем такой код,
[02:03:55.000 --> 02:03:57.000]  и чтобы он работал, нужно каким-то образом
[02:03:57.000 --> 02:03:59.000]  обеспечить выполнение,
[02:03:59.000 --> 02:04:01.000]  видимость причинности.
[02:04:01.000 --> 02:04:03.000]  Поэтому мы говорили, что
[02:04:03.000 --> 02:04:05.000]  вот на этот случай нам
[02:04:05.000 --> 02:04:07.000]  memory-памяти дает
[02:04:07.000 --> 02:04:09.000]  memory-order-release,
[02:04:09.000 --> 02:04:11.000]  а здесь memory-order-Aquire.
[02:04:11.000 --> 02:04:13.000]  Зачем? Ну, за тем, чтобы
[02:04:13.000 --> 02:04:15.000]  нельзя было преордерить, грубо говоря,
[02:04:15.000 --> 02:04:17.000]  эту запись ниже этой,
[02:04:17.000 --> 02:04:19.000]  а эту запись, это чтение выше этого.
[02:04:19.000 --> 02:04:21.000]  Ну потому что они вроде как независимые,
[02:04:23.000 --> 02:04:25.000]  ну или даже вот давайте попроще
[02:04:25.000 --> 02:04:27.000]  напишем, вот так.
[02:04:33.000 --> 02:04:35.000]  Вот тогда причинность у нас была.
[02:04:37.000 --> 02:04:39.000]  Мы не можем увидеть единицу здесь,
[02:04:39.000 --> 02:04:41.000]  увидеть 0 здесь.
[02:04:41.000 --> 02:04:43.000]  Но сейчас у нас написан
[02:04:43.000 --> 02:04:45.000]  несколько другой код.
[02:04:45.000 --> 02:04:47.000]  У нас ядро C1
[02:04:47.000 --> 02:04:49.000]  делает что-то такое.
[02:04:49.000 --> 02:04:51.000]  Ну как?
[02:04:51.000 --> 02:04:53.000]  Вызывается сначала конструирование
[02:04:53.000 --> 02:04:55.000]  объектов памяти, а потом
[02:04:55.000 --> 02:04:57.000]  мы по интерпишем
[02:04:57.000 --> 02:04:59.000]  вот этот адрес.
[02:05:03.000 --> 02:05:05.000]  Ну я какой-то псевдокод пишу,
[02:05:05.000 --> 02:05:07.000]  такой условный, понимаете?
[02:05:07.000 --> 02:05:09.000]  Ну вот, вот, вот.
[02:05:09.000 --> 02:05:11.000]  Вот, вот, вот.
[02:05:11.000 --> 02:05:13.000]  Вот, вот, вот.
[02:05:13.000 --> 02:05:15.000]  Вот, вот, вот.
[02:05:15.000 --> 02:05:17.000]  Вот, вот, вот.
[02:05:17.000 --> 02:05:19.000]  Я какой-то псевдокод пишу, такой условный.
[02:05:19.000 --> 02:05:21.000]  Понимаете, наверное, меня, да?
[02:05:23.000 --> 02:05:25.000]  А над C2 происходит вот что.
[02:05:25.000 --> 02:05:27.000]  Мы читаем
[02:05:29.000 --> 02:05:31.000]  в регистр
[02:05:33.000 --> 02:05:35.000]  по вот этому адресу.
[02:05:35.000 --> 02:05:37.000]  Сейчас мы читаем
[02:05:37.000 --> 02:05:39.000]  в регистр
[02:05:39.000 --> 02:05:41.000]  адрес point,
[02:05:41.000 --> 02:05:43.000]  ну, который хранится в pointer
[02:05:43.000 --> 02:05:45.000]  в переменной.
[02:05:45.000 --> 02:05:47.000]  Вот.
[02:05:49.000 --> 02:05:51.000]  А потом
[02:05:51.000 --> 02:05:53.000]  мы
[02:05:53.000 --> 02:05:55.000]  читаем данные
[02:05:55.000 --> 02:05:57.000]  по прочитанному адресу.
[02:06:01.000 --> 02:06:03.000]  Видна ли разница
[02:06:03.000 --> 02:06:05.000]  между двумя этими примерами?
[02:06:07.000 --> 02:06:09.000]  Вот разницы существенные между
[02:06:09.000 --> 02:06:11.000]  вот этим кодом и вот этим
[02:06:11.000 --> 02:06:13.000]  нет, а вот между этим
[02:06:13.000 --> 02:06:15.000]  и этим есть.
[02:06:15.000 --> 02:06:17.000]  Потому что здесь мы читаем две независимые
[02:06:17.000 --> 02:06:19.000]  ячейки памяти.
[02:06:19.000 --> 02:06:21.000]  И процессор, вообще говоря, может
[02:06:23.000 --> 02:06:25.000]  выполнить это чтение раньше этого.
[02:06:25.000 --> 02:06:27.000]  Ну, вот так захочется, условно.
[02:06:27.000 --> 02:06:29.000]  А здесь?
[02:06:29.000 --> 02:06:31.000]  А здесь у нас зависимость
[02:06:31.000 --> 02:06:33.000]  по данным. Здесь у нас
[02:06:33.000 --> 02:06:35.000]  выход первого чтения
[02:06:35.000 --> 02:06:37.000]  подается на вход второму чтению.
[02:06:39.000 --> 02:06:41.000]  У нас есть зависимость по данным здесь.
[02:06:43.000 --> 02:06:45.000]  Понимаете, что это?
[02:06:45.000 --> 02:06:47.000]  Так вот.
[02:06:47.000 --> 02:06:49.000]  Как же может процессор взять
[02:06:49.000 --> 02:06:51.000]  и выполнить это чтение до этого?
[02:07:01.000 --> 02:07:03.000]  Ну, это же совсем странно.
[02:07:05.000 --> 02:07:07.000]  Правда?
[02:07:13.000 --> 02:07:15.000]  Поэтому хотелось бы здесь написать
[02:07:15.000 --> 02:07:17.000]  Relax вообще.
[02:07:21.000 --> 02:07:23.000]  Но вот так нельзя, потому что
[02:07:23.000 --> 02:07:25.000]  оказывается, что есть процессор, который
[02:07:25.000 --> 02:07:27.000]  так не работает.
[02:07:27.000 --> 02:07:29.000]  Но, тем не менее, есть
[02:07:29.000 --> 02:07:31.000]  Memory Order, который как раз вот нужен
[02:07:31.000 --> 02:07:33.000]  для того, чтобы получить более слабые гарантии.
[02:07:33.000 --> 02:07:35.000]  Это Memory Order Consume.
[02:07:35.000 --> 02:07:37.000]  Memory Order Consume
[02:07:37.000 --> 02:07:39.000]  он про то, что если
[02:07:39.000 --> 02:07:41.000]  вы здесь что-то записали в Pointer,
[02:07:41.000 --> 02:07:43.000]  а здесь вы подшли Pointer, а потом по нему подшли данные,
[02:07:43.000 --> 02:07:45.000]  то вы вот здесь непременно
[02:07:45.000 --> 02:07:47.000]  увидите вот эту запись.
[02:07:49.000 --> 02:07:51.000]  Но совершенно не факт, что вы
[02:07:51.000 --> 02:07:53.000]  при этом увидите
[02:07:55.000 --> 02:07:57.000]  вот такую запись.
[02:08:11.000 --> 02:08:13.000]  То есть вот здесь
[02:08:13.000 --> 02:08:15.000]  вы непременно увидите данные, которые
[02:08:15.000 --> 02:08:17.000]  вы записали здесь.
[02:08:17.000 --> 02:08:19.000]  Но никакие гарантии
[02:08:19.000 --> 02:08:21.000]  на вот эту запись,
[02:08:21.000 --> 02:08:23.000]  что она будет видна этому чтению, нет.
[02:08:23.000 --> 02:08:25.000]  То есть, да, вы знаете, что вот
[02:08:25.000 --> 02:08:27.000]  здесь вы прочли Pointer, который записали здесь.
[02:08:27.000 --> 02:08:29.000]  Но при этом вы из этого не можете
[02:08:29.000 --> 02:08:31.000]  делать вывод о том, что
[02:08:31.000 --> 02:08:33.000]  вы можете, что в Z
[02:08:33.000 --> 02:08:35.000]  уже тоже сделана запись единицы,
[02:08:35.000 --> 02:08:37.000]  что она видна в памяти.
[02:08:37.000 --> 02:08:39.000]  Это вот ограничение консюма.
[02:08:43.000 --> 02:08:45.000]  Да вот,
[02:08:45.000 --> 02:08:47.000]  смотри, да вот в том-то и дело, что
[02:08:47.000 --> 02:08:49.000]  консюм он почти нигде не нужен.
[02:08:49.000 --> 02:08:51.000]  То есть почти, ну, все процессоры
[02:08:51.000 --> 02:08:53.000]  практически на свете
[02:08:53.000 --> 02:08:55.000]  уважают зависимость
[02:08:55.000 --> 02:08:57.000]  по данным.
[02:08:57.000 --> 02:08:59.000]  И вопрос тут не почему
[02:08:59.000 --> 02:09:01.000]  консюм, а не Acquire, а почему здесь
[02:09:01.000 --> 02:09:03.000]  Consume Unrelaxed.
[02:09:03.000 --> 02:09:05.000]  Вот, оказывается, есть
[02:09:05.000 --> 02:09:07.000]  некоторый процессор, которому явно
[02:09:07.000 --> 02:09:09.000]  нужно сообщить об этом.
[02:09:09.000 --> 02:09:11.000]  Есть какая-то альфа.
[02:09:11.000 --> 02:09:13.000]  Кажется, что это
[02:09:13.000 --> 02:09:15.000]  архитектура, которая никому не нужна.
[02:09:15.000 --> 02:09:17.000]  Ну, не знаю, может быть, кому-то нужна.
[02:09:17.000 --> 02:09:19.000]  Но
[02:09:19.000 --> 02:09:21.000]  смотрите, почему это
[02:09:21.000 --> 02:09:23.000]  плохо. Вот здесь такой консюм, у него
[02:09:23.000 --> 02:09:25.000]  гарантия вот такая, да, что мы
[02:09:25.000 --> 02:09:27.000]  здесь, даже с консюмом,
[02:09:27.000 --> 02:09:29.000]  вот этот консюм он,
[02:09:29.000 --> 02:09:31.000]  если мы через консюм
[02:09:31.000 --> 02:09:33.000]  увидели вот эту запись с релизом,
[02:09:33.000 --> 02:09:35.000]  то мы увидим и данные по поинтеру.
[02:09:37.000 --> 02:09:39.000]  Но произвольную ячейку, записанную
[02:09:39.000 --> 02:09:41.000]  до, мы уже можем не
[02:09:41.000 --> 02:09:43.000]  увидеть после.
[02:09:43.000 --> 02:09:45.000]  И это проблема,
[02:09:45.000 --> 02:09:47.000]  потому что этот консюм, он
[02:09:47.000 --> 02:09:49.000]  существенно усложняет модели памяти
[02:09:49.000 --> 02:09:51.000]  C++. Вот на лекции
[02:09:51.000 --> 02:09:53.000]  я вам показывал, что мы определяем
[02:09:53.000 --> 02:09:55.000]  HappensBefore и в джаве HappensBefore
[02:09:55.000 --> 02:09:57.000]  определяется вот просто как положено.
[02:09:57.000 --> 02:09:59.000]  Мы говорим, что между x и y есть
[02:09:59.000 --> 02:10:01.000]  HappensBefore, если
[02:10:01.000 --> 02:10:03.000]  x и y это действия
[02:10:03.000 --> 02:10:05.000]  просто в одном потоке, между ними есть
[02:10:05.000 --> 02:10:07.000]  программ Order, или x
[02:10:07.000 --> 02:10:09.000]  синхронizes with y,
[02:10:09.000 --> 02:10:11.000]  или транзитивные замыкания.
[02:10:11.000 --> 02:10:13.000]  А вот в C++ все намного сложнее.
[02:10:13.000 --> 02:10:15.000]  И там HappensBefore
[02:10:15.000 --> 02:10:17.000]  определяется
[02:10:17.000 --> 02:10:19.000]  вообще-то жутковатым
[02:10:19.000 --> 02:10:21.000]  образом.
[02:10:25.000 --> 02:10:27.000]  Он определяется вот так.
[02:10:27.000 --> 02:10:29.000]  HappensBefore это либо
[02:10:29.000 --> 02:10:31.000]  A SequencedBeforeB,
[02:10:31.000 --> 02:10:33.000]  SequencedBefore это в C++ так называется
[02:10:33.000 --> 02:10:35.000]  программ Order. Или
[02:10:35.000 --> 02:10:37.000]  Interstrat HappensBefore,
[02:10:37.000 --> 02:10:39.000]  который определяется вообще вот так,
[02:10:39.000 --> 02:10:41.000]  очень как-то заковыристо,
[02:10:41.000 --> 02:10:43.000]  и этому всему еще
[02:10:43.000 --> 02:10:45.000]  к этому всему предлагается
[02:10:45.000 --> 02:10:47.000]  длинный комментарий, почему так получилось.
[02:10:47.000 --> 02:10:49.000]  А еще
[02:10:49.000 --> 02:10:51.000]  в C++ есть
[02:10:51.000 --> 02:10:53.000]  Simply HappensBefore.
[02:10:53.000 --> 02:10:55.000]  И в нем уже все как положено.
[02:10:55.000 --> 02:10:57.000]  A SequencedBeforeB,
[02:10:57.000 --> 02:10:59.000]  A SYNCHRONIZES WITH B,
[02:10:59.000 --> 02:11:01.000]  и транзитивные замыкания.
[02:11:01.000 --> 02:11:03.000]  И говорится, что
[02:11:03.000 --> 02:11:05.000]  если бы не Consume,
[02:11:05.000 --> 02:11:07.000]  то HappensBefore и Simply HappensBefore
[02:11:07.000 --> 02:11:09.000]  определялись бы одинаково.
[02:11:09.000 --> 02:11:11.000]  Но не тут-то было.
[02:11:11.000 --> 02:11:13.000]  Вот из-за того, что в C++ есть этот MemoryOrderConsume,
[02:11:13.000 --> 02:11:15.000]  который позволяет
[02:11:15.000 --> 02:11:17.000]  что-то соптимизировать
[02:11:17.000 --> 02:11:19.000]  для какого-то маргинального процессора,
[02:11:21.000 --> 02:11:23.000]  модель памяти сильно усложняется,
[02:11:23.000 --> 02:11:25.000]  и в ней появляются два новых порядка.
[02:11:27.000 --> 02:11:29.000]  Вот DependencyOrderedBefore.
[02:11:31.000 --> 02:11:33.000]  DependencyOrderedBefore – это отношение,
[02:11:33.000 --> 02:11:35.000]  которое возникает между
[02:11:35.000 --> 02:11:37.000]  релиз-записью и Consume-чтением,
[02:11:37.000 --> 02:11:39.000]  которое видит эту запись.
[02:11:43.000 --> 02:11:45.000]  И если мы
[02:11:45.000 --> 02:11:47.000]  прочли с Consume-поинтер,
[02:11:47.000 --> 02:11:49.000]  а потом по нему читаем,
[02:11:49.000 --> 02:11:51.000]  то вот это чтение
[02:11:51.000 --> 02:11:53.000]  и это связаны
[02:11:53.000 --> 02:11:55.000]  с отношением
[02:11:55.000 --> 02:11:57.000]  Dependency.
[02:12:01.000 --> 02:12:03.000]  И вот конкотинация
[02:12:03.000 --> 02:12:05.000]  вот этих DependencyOrderedBefore
[02:12:05.000 --> 02:12:07.000]  и CarriersDependency
[02:12:07.000 --> 02:12:09.000]  тоже образует HappensBefore.
[02:12:09.000 --> 02:12:11.000]  Но он уже не транзитивный,
[02:12:11.000 --> 02:12:13.000]  потому что
[02:12:13.000 --> 02:12:15.000]  вот к нему
[02:12:15.000 --> 02:12:17.000]  вот здесь будет CarriersDependency,
[02:12:17.000 --> 02:12:19.000]  здесь будет DependencyOrderedBefore,
[02:12:19.000 --> 02:12:21.000]  а, к сожалению,
[02:12:21.000 --> 02:12:23.000]  здесь будет
[02:12:23.000 --> 02:12:25.000]  SequencedBefore, и SequencedBefore
[02:12:25.000 --> 02:12:27.000]  нельзя приклеить к этой цепочке.
[02:12:29.000 --> 02:12:31.000]  Но если вы не понимаете ничего,
[02:12:31.000 --> 02:12:33.000]  то можно это все забыть
[02:12:33.000 --> 02:12:35.000]  и просто не использовать никогда Consume.
[02:12:35.000 --> 02:12:37.000]  Но вот если вы понимаете,
[02:12:37.000 --> 02:12:39.000]  то вы можете потом осмыслить,
[02:12:39.000 --> 02:12:41.000]  почему модерипамяти C++ такая сложная,
[02:12:41.000 --> 02:12:43.000]  почему в ней так нетривиально,
[02:12:43.000 --> 02:12:45.000]  так избыточно сложно
[02:12:45.000 --> 02:12:47.000]  определяется вроде бы простой по смыслу HappensBefore.
[02:12:49.000 --> 02:12:51.000]  Ну, потому что есть
[02:12:51.000 --> 02:12:53.000]  Consume.
[02:12:53.000 --> 02:12:55.000]  Но он никому не нужен,
[02:12:55.000 --> 02:12:57.000]  я вот, смотрите, давайте
[02:12:57.000 --> 02:12:59.000]  убедительно докажу это.
[02:12:59.000 --> 02:13:01.000]  Вот из библиотека Folia
[02:13:01.000 --> 02:13:03.000]  это библиотека общих компонентов Facebook.
[02:13:03.000 --> 02:13:05.000]  И там, кстати, много интересного для нас
[02:13:05.000 --> 02:13:07.000]  есть, в частности, там написаны Executor,
[02:13:07.000 --> 02:13:09.000]  там есть Fiber, там есть
[02:13:11.000 --> 02:13:13.000]  Future.
[02:13:13.000 --> 02:13:15.000]  И вот можно погуглить,
[02:13:15.000 --> 02:13:17.000]  как в этой библиотеке
[02:13:17.000 --> 02:13:19.000]  используется, например, MemoryOrderAcquire.
[02:13:21.000 --> 02:13:23.000]  Я где-то, наверное,
[02:13:23.000 --> 02:13:25.000]  ошибся.
[02:13:27.000 --> 02:13:29.000]  Но он непременно
[02:13:29.000 --> 02:13:31.000]  должен использоваться.
[02:13:31.000 --> 02:13:33.000]  Мы ничего не находим.
[02:13:37.000 --> 02:13:39.000]  Ну, я что-то исправил,
[02:13:39.000 --> 02:13:41.000]  ну ладно, я понял, что...
[02:13:41.000 --> 02:13:43.000]  В общем, много где используется он.
[02:13:45.000 --> 02:13:47.000]  Вот какие-то примитивы синхронизации.
[02:13:47.000 --> 02:13:49.000]  Много какого-то кода.
[02:13:49.000 --> 02:13:51.000]  А теперь меняем Acquire на Consume.
[02:13:55.000 --> 02:13:57.000]  И он используется
[02:13:57.000 --> 02:13:59.000]  только в нескольких тестах,
[02:13:59.000 --> 02:14:01.000]  и то для того, чтобы игнорировался он.
[02:14:01.000 --> 02:14:03.000]  Вот. Так что
[02:14:03.000 --> 02:14:05.000]  этот MemoryOrder, ну в общем,
[02:14:05.000 --> 02:14:07.000]  он никому в реальности
[02:14:07.000 --> 02:14:09.000]  не нужен.
[02:14:09.000 --> 02:14:11.000]  И если его в реальности нет,
[02:14:11.000 --> 02:14:13.000]  то предлагается его
[02:14:13.000 --> 02:14:15.000]  из своей картины мира вычеркнуть
[02:14:15.000 --> 02:14:17.000]  и вместе с этим Consume
[02:14:17.000 --> 02:14:19.000]  исчезнет для вас
[02:14:19.000 --> 02:14:21.000]  вот этот избыточно
[02:14:21.000 --> 02:14:23.000]  сложный HappensBefore.
[02:14:23.000 --> 02:14:25.000]  И хоть он формально
[02:14:25.000 --> 02:14:27.000]  так определяется,
[02:14:27.000 --> 02:14:29.000]  но поскольку...
[02:14:29.000 --> 02:14:31.000]  Вот вам MemoryOrder сама говорит,
[02:14:31.000 --> 02:14:33.000]  вам сам стандарт языка говорит,
[02:14:33.000 --> 02:14:35.000]  что если бы не Consume, то
[02:14:35.000 --> 02:14:37.000]  HappensBefore можно заменить
[02:14:37.000 --> 02:14:39.000]  на такое простое определение.
[02:14:39.000 --> 02:14:41.000]  Поэтому я на лекции вам его и рассказываю.
[02:14:41.000 --> 02:14:43.000]  То есть формально это
[02:14:43.000 --> 02:14:45.000]  не определение HappensBefore все плюс-плюс,
[02:14:45.000 --> 02:14:47.000]  но фактически
[02:14:47.000 --> 02:14:49.000]  если мы от Consume отказываемся,
[02:14:49.000 --> 02:14:51.000]  то им можно пользоваться.
[02:14:53.000 --> 02:14:55.000]  Ну в том, что есть некоторые процессоры,
[02:14:55.000 --> 02:14:57.000]  на которых от Consume можно получить больше
[02:14:57.000 --> 02:14:59.000]  пользы.
[02:14:59.000 --> 02:15:01.000]  То есть, смотри,
[02:15:01.000 --> 02:15:03.000]  вот есть такой паттерн,
[02:15:03.000 --> 02:15:05.000]  где ты читаешь pointer, потом читаешь
[02:15:05.000 --> 02:15:07.000]  по pointer. И вроде
[02:15:07.000 --> 02:15:09.000]  тебе не нужно там сильные барьеры
[02:15:09.000 --> 02:15:11.000]  ставить, ты мог бы обойтись
[02:15:11.000 --> 02:15:13.000]  почти без барьеров.
[02:15:13.000 --> 02:15:15.000]  Но какому-то процессору барьеры все-таки нужны.
[02:15:15.000 --> 02:15:17.000]  Поэтому нам нужна еще одна
[02:15:17.000 --> 02:15:19.000]  ступенька.
[02:15:19.000 --> 02:15:21.000]  Но эта ступенька, она сильно-сильно
[02:15:21.000 --> 02:15:23.000]  усложняет модель теоретическую.
[02:15:25.000 --> 02:15:27.000]  Вот, поэтому мало кто от этого
[02:15:27.000 --> 02:15:29.000]  получает выигрыш, почти никто в реальности.
[02:15:29.000 --> 02:15:31.000]  Но зато все мы получаем
[02:15:31.000 --> 02:15:33.000]  очень большой когнитивный проигрыш.
[02:15:33.000 --> 02:15:35.000]  Потому что
[02:15:35.000 --> 02:15:37.000]  вот мы
[02:15:37.000 --> 02:15:39.000]  перфоманса дополнительного получить
[02:15:39.000 --> 02:15:41.000]  от Consume мы не можем
[02:15:41.000 --> 02:15:43.000]  на наших компьютерах разумных.
[02:15:43.000 --> 02:15:45.000]  Но при этом нам становится сильно сложнее
[02:15:45.000 --> 02:15:47.000]  модель памяти изучать и пользоваться ей.
[02:15:49.000 --> 02:15:51.000]  Ну вот, такая
[02:15:51.000 --> 02:15:53.000]  странная мораль.
[02:15:53.000 --> 02:15:55.000]  Понимаете ситуацию?
[02:15:55.000 --> 02:15:57.000]  Вот пример неудачного дизайна.
[02:15:57.000 --> 02:15:59.000]  Люди попробовали, решили, что
[02:15:59.000 --> 02:16:01.000]  C++ должен давать
[02:16:01.000 --> 02:16:03.000]  нам zero cost абстракции.
[02:16:03.000 --> 02:16:05.000]  То есть, если нам что-то не нужно,
[02:16:05.000 --> 02:16:07.000]  мы за это можем не платить.
[02:16:07.000 --> 02:16:09.000]  Руководствовали с таким соображением
[02:16:09.000 --> 02:16:11.000]  разработчики модели памяти и добавили Consume.
[02:16:11.000 --> 02:16:13.000]  И действительно,
[02:16:13.000 --> 02:16:15.000]  кто-то, кто может этим Consume воспользоваться,
[02:16:15.000 --> 02:16:17.000]  он воспользуется им.
[02:16:17.000 --> 02:16:19.000]  Но в реальности им никто
[02:16:19.000 --> 02:16:21.000]  не пользуется, но при этом
[02:16:21.000 --> 02:16:23.000]  за счет него сильно-сильно-сильно
[02:16:23.000 --> 02:16:25.000]  усложняется модель.
[02:16:27.000 --> 02:16:29.000]  Так что эксперимент неудачный, но
[02:16:29.000 --> 02:16:31.000]  кажется, что закатись обратно это уже невозможно.
[02:16:31.000 --> 02:16:33.000]  Потому что не скажешь
[02:16:33.000 --> 02:16:35.000]  же так, что все ваши
[02:16:35.000 --> 02:16:37.000]  быстрые программы на этих странных
[02:16:37.000 --> 02:16:39.000]  альфах отменяются и теперь будут работать медленнее,
[02:16:39.000 --> 02:16:41.000]  потому что мы решили исправить ошибку.
[02:16:41.000 --> 02:16:43.000]  Это не в духе C++ ломать обратную
[02:16:43.000 --> 02:16:45.000]  совместимость.
[02:16:45.000 --> 02:16:47.000]  Вот, так что Consume остается,
[02:16:47.000 --> 02:16:49.000]  но вот его, как
[02:16:49.000 --> 02:16:51.000]  некоторая ступень ослабления
[02:16:51.000 --> 02:16:53.000]  Acquire, но лучше его
[02:16:53.000 --> 02:16:55.000]  из своей памяти вычеркнуть.
[02:16:55.000 --> 02:16:57.000]  Пользоваться им не стоит.
[02:16:59.000 --> 02:17:01.000]  По-прежнему настаиваю, что есть
[02:17:01.000 --> 02:17:03.000]  Relaxed, есть Release Acquire
[02:17:03.000 --> 02:17:05.000]  и есть Sequential Consistency.
[02:17:05.000 --> 02:17:07.000]  Мы выбираем, по сути, этих трех.
[02:17:07.000 --> 02:17:09.000]  Есть еще Acquire Release
[02:17:09.000 --> 02:17:11.000]  и мы
[02:17:11.000 --> 02:17:13.000]  с ним
[02:17:13.000 --> 02:17:15.000]  сегодня не успели.
[02:17:15.000 --> 02:17:17.000]  А может быть успели, кто знает?
[02:17:17.000 --> 02:17:19.000]  У нас 10 минут еще, да?
[02:17:19.000 --> 02:17:21.000]  Или сколько?
[02:17:21.000 --> 02:17:23.000]  Семь?
[02:17:25.000 --> 02:17:27.000]  Ну, нет, давайте уже как-нибудь.
[02:17:27.000 --> 02:17:29.000]  Либо до пяти, либо не в этот раз вообще.
[02:17:29.000 --> 02:17:31.000]  Нет, вот Acquire Release
[02:17:31.000 --> 02:17:33.000]  это просто комбинация.
[02:17:33.000 --> 02:17:35.000]  Релизы Acquire, они полезные.
[02:17:35.000 --> 02:17:37.000]  И более того, я утверждаю, что если вы пишете
[02:17:37.000 --> 02:17:39.000]  в домашней хорошую weight-группу,
[02:17:39.000 --> 02:17:41.000]  то оптимальные memory-ордеры будут там
[02:17:41.000 --> 02:17:43.000]  такими, как я мог бы рассказать.
[02:17:43.000 --> 02:17:45.000]  Нет, это полезная штука
[02:17:45.000 --> 02:17:47.000]  и пример будет полезный.
[02:17:47.000 --> 02:17:49.000]  Пример важный на самом деле сейчас будет.
[02:17:55.000 --> 02:17:57.000]  Да не выгодно.
[02:17:57.000 --> 02:17:59.000]  Смотрите, давайте перейдем на доску сейчас.
[02:18:01.000 --> 02:18:03.000]  Нет, давайте сначала на экране
[02:18:03.000 --> 02:18:05.000]  покажу.
[02:18:05.000 --> 02:18:07.000]  Где еще memory-ордеры могут понадобиться?
[02:18:07.000 --> 02:18:09.000]  Утверждается, что
[02:18:09.000 --> 02:18:11.000]  они могут понадобиться, но
[02:18:11.000 --> 02:18:13.000]  вы знаете про SharedPointer.
[02:18:13.000 --> 02:18:15.000]  И я вам на лекции показывал, что SharedPointer
[02:18:15.000 --> 02:18:17.000]  это такая штука, которая
[02:18:17.000 --> 02:18:19.000]  с одной стороны в ней атомарный
[02:18:19.000 --> 02:18:21.000]  счетчик ссылок,
[02:18:21.000 --> 02:18:23.000]  а с другой стороны с ним работать
[02:18:23.000 --> 02:18:25.000]  из разных потоков нельзя.
[02:18:25.000 --> 02:18:27.000]  Но все же в нем атомарный счетчик
[02:18:27.000 --> 02:18:29.000]  ссылок. Там есть
[02:18:29.000 --> 02:18:31.000]  FetchSub, FetchEd, а значит
[02:18:31.000 --> 02:18:33.000]  в них можно писать memory-ордеры,
[02:18:33.000 --> 02:18:35.000]  при почете ссылок. Вот вопрос,
[02:18:35.000 --> 02:18:37.000]  какие memory-ордеры нужно писать?
[02:18:39.000 --> 02:18:41.000]  Ну, ищем.
[02:18:47.000 --> 02:18:49.000]  Ну вот, Lipsy++.
[02:18:49.000 --> 02:18:51.000]  Вот, RefCountIncrement,
[02:18:51.000 --> 02:18:53.000]  RefCountDecrement.
[02:18:53.000 --> 02:18:55.000]  Смотрите, increment
[02:18:55.000 --> 02:18:57.000]  relaxed, decrement
[02:18:57.000 --> 02:18:59.000]  acquiredRelease.
[02:18:59.000 --> 02:19:01.000]  Разбираемся, почему так.
[02:19:05.000 --> 02:19:07.000]  Еще одно
[02:19:07.000 --> 02:19:09.000]  темное место обнаружено
[02:19:09.000 --> 02:19:11.000]  с моделем памяти.
[02:19:11.000 --> 02:19:13.000]  Вот чувствуете ли вы, где связь
[02:19:13.000 --> 02:19:15.000]  с своей группой?
[02:19:15.000 --> 02:19:17.000]  Ну ладно, прямая.
[02:19:17.000 --> 02:19:19.000]  Там тоже FetchEd, FetchSub.
[02:19:21.000 --> 02:19:23.000]  А теперь
[02:19:23.000 --> 02:19:25.000]  смотрите.
[02:19:25.000 --> 02:19:27.000]  Ну опять, что с чем
[02:19:27.000 --> 02:19:29.000]  мы упорядочим?
[02:19:29.000 --> 02:19:31.000]  Вот есть у нас
[02:19:31.000 --> 02:19:33.000]  SharePoint, где они живут как-то.
[02:19:33.000 --> 02:19:35.000]  Вот это их lifetime.
[02:19:39.000 --> 02:19:41.000]  Вот здесь FetchEd,
[02:19:41.000 --> 02:19:43.000]  здесь FetchEd,
[02:19:43.000 --> 02:19:45.000]  здесь FetchEd,
[02:19:45.000 --> 02:19:47.000]  здесь FetchEd,
[02:19:47.000 --> 02:19:49.000]  здесь FetchSub,
[02:19:49.000 --> 02:19:51.000]  FetchSub, FetchSub.
[02:19:51.000 --> 02:19:53.000]  А тут FetchEd
[02:19:53.000 --> 02:19:55.000]  и
[02:19:55.000 --> 02:19:57.000]  для деконструирования, тут, наверное,
[02:19:57.000 --> 02:19:59.000]  даже не FetchEd, а просто единиц
[02:19:59.000 --> 02:20:01.000]  перевелось, да?
[02:20:01.000 --> 02:20:03.000]  Здесь мы увеличили
[02:20:03.000 --> 02:20:05.000]  1, 2, здесь
[02:20:05.000 --> 02:20:07.000]  2, 3,
[02:20:07.000 --> 02:20:09.000]  здесь
[02:20:09.000 --> 02:20:11.000]  3, 2,
[02:20:11.000 --> 02:20:13.000]  здесь 2, 1,
[02:20:13.000 --> 02:20:15.000]  здесь 1, 0.
[02:20:17.000 --> 02:20:19.000]  Это все атомарные операции.
[02:20:19.000 --> 02:20:21.000]  А какие неатомарные операции
[02:20:21.000 --> 02:20:23.000]  мы собираемся упорядочивать с помощью
[02:20:23.000 --> 02:20:25.000]  атомарных?
[02:20:27.000 --> 02:20:29.000]  У нас здесь
[02:20:29.000 --> 02:20:31.000]  где-то есть обращение.
[02:20:35.000 --> 02:20:37.000]  Ну есть, да.
[02:20:37.000 --> 02:20:39.000]  Но это же обращение к объекту.
[02:20:39.000 --> 02:20:41.000]  Ну, то есть
[02:20:43.000 --> 02:20:45.000]  то, что если мы из разных потоков
[02:20:45.000 --> 02:20:47.000]  вращаемся к самому объекту,
[02:20:47.000 --> 02:20:49.000]  наверное, там внутри должна быть синхронизация.
[02:20:49.000 --> 02:20:51.000]  А вот в смысле
[02:20:51.000 --> 02:20:53.000]  самого shared pointer, что нам еще нужно
[02:20:53.000 --> 02:20:55.000]  упорядочить?
[02:20:55.000 --> 02:20:57.000]  Понимаете?
[02:20:57.000 --> 02:20:59.000]  У нас времени мало, давайте
[02:20:59.000 --> 02:21:01.000]  расскажу. Деструкторы же у нас
[02:21:01.000 --> 02:21:03.000]  еще есть.
[02:21:03.000 --> 02:21:05.000]  И вот им занимается сам shared pointer.
[02:21:05.000 --> 02:21:07.000]  И вот нужно упорядочить
[02:21:07.000 --> 02:21:09.000]  обращение к памяти здесь
[02:21:09.000 --> 02:21:11.000]  и разрушение объекта здесь.
[02:21:11.000 --> 02:21:13.000]  Нужно, чтобы это было
[02:21:13.000 --> 02:21:15.000]  happened before.
[02:21:15.000 --> 02:21:17.000]  И что мы делаем?
[02:21:17.000 --> 02:21:19.000]  Мы...
[02:21:21.000 --> 02:21:23.000]  Ну, у нас есть обращения разные.
[02:21:23.000 --> 02:21:25.000]  Вот здесь вот оно есть.
[02:21:25.000 --> 02:21:27.000]  Вот здесь вот оно есть.
[02:21:27.000 --> 02:21:29.000]  Вот здесь вот оно есть.
[02:21:29.000 --> 02:21:31.000]  И здесь есть программа
[02:21:31.000 --> 02:21:33.000]  order всегда.
[02:21:33.000 --> 02:21:35.000]  Ну, и пока вот этот деструктор
[02:21:35.000 --> 02:21:37.000]  увидит это чтение,
[02:21:37.000 --> 02:21:39.000]  это обращение.
[02:21:39.000 --> 02:21:41.000]  Ну, как его заставить
[02:21:41.000 --> 02:21:43.000]  увидеть эти?
[02:21:43.000 --> 02:21:45.000]  Мы пишем здесь
[02:21:45.000 --> 02:21:47.000]  acquiredRelease.
[02:21:47.000 --> 02:21:49.000]  Что такое acquiredRelease?
[02:21:49.000 --> 02:21:51.000]  Вот у нас операция, она
[02:21:53.000 --> 02:21:55.000]  читает,
[02:21:55.000 --> 02:21:57.000]  модифицирует, пишет.
[02:21:57.000 --> 02:21:59.000]  И вот для
[02:21:59.000 --> 02:22:01.000]  того, чтобы
[02:22:01.000 --> 02:22:03.000]  и вот для
[02:22:03.000 --> 02:22:05.000]  чтения, это будет
[02:22:05.000 --> 02:22:07.000]  acquired чтение,
[02:22:07.000 --> 02:22:09.000]  а для записи это будет
[02:22:09.000 --> 02:22:11.000]  release запись.
[02:22:11.000 --> 02:22:13.000]  И как это работает?
[02:22:13.000 --> 02:22:15.000]  У нас здесь, смотрите, release запись
[02:22:15.000 --> 02:22:17.000]  войки,
[02:22:17.000 --> 02:22:19.000]  а потом есть фейчсап, которые читают
[02:22:19.000 --> 02:22:21.000]  войку и тоже с acquiredRelease.
[02:22:25.000 --> 02:22:27.000]  Так?
[02:22:27.000 --> 02:22:29.000]  И получается, что
[02:22:29.000 --> 02:22:31.000]  мы здесь пишем войку с release,
[02:22:31.000 --> 02:22:33.000]  а потом мы читаем войку с acquired.
[02:22:41.000 --> 02:22:43.000]  Потом мы здесь пишем
[02:22:43.000 --> 02:22:45.000]  единицу с release, читаем
[02:22:45.000 --> 02:22:47.000]  единицу с acquired.
[02:22:49.000 --> 02:22:51.000]  Ну и все.
[02:22:51.000 --> 02:22:53.000]  Теперь у нас все обращения, они у порядочных деструкторов.
[02:22:55.000 --> 02:22:57.000]  Пока все просто, да?
[02:22:57.000 --> 02:22:59.000]  Комментируем динамик,
[02:22:59.000 --> 02:23:01.000]  поменим вводы,
[02:23:01.000 --> 02:23:03.000]  да, только если у нас операция
[02:23:03.000 --> 02:23:05.000]  делает и чтение, и запись.
[02:23:05.000 --> 02:23:07.000]  То есть она ведет себя на какое
[02:23:07.000 --> 02:23:09.000]  отчтение при release запись.
[02:23:09.000 --> 02:23:11.000]  Но у нас тоже была операция,
[02:23:11.000 --> 02:23:13.000]  которая и читала, и писала, и чтение,
[02:23:13.000 --> 02:23:15.000]  но там нам не нужно было и то, и другое,
[02:23:15.000 --> 02:23:17.000]  нам только какое было.
[02:23:17.000 --> 02:23:19.000]  Так что нужно снова применять.
[02:23:19.000 --> 02:23:21.000]  А теперь,
[02:23:21.000 --> 02:23:23.000]  это понятно, да?
[02:23:23.000 --> 02:23:25.000]  А теперь, собственно,
[02:23:25.000 --> 02:23:27.000]  теперь смотреть шнап.
[02:23:27.000 --> 02:23:29.000]  Теперь мы немного перейтируем пример.
[02:23:41.000 --> 02:23:43.000]  Единица
[02:23:43.000 --> 02:23:45.000]  Fetch add
[02:23:45.000 --> 02:23:47.000]  1, 2
[02:23:47.000 --> 02:23:49.000]  Fetch
[02:23:49.000 --> 02:23:51.000]  sub 2, 1
[02:23:51.000 --> 02:23:53.000]  Fetch add
[02:23:53.000 --> 02:23:55.000]  1, 2
[02:23:55.000 --> 02:23:57.000]  Fetch sub
[02:23:57.000 --> 02:23:59.000]  2, 1
[02:23:59.000 --> 02:24:01.000]  Fetch sub
[02:24:01.000 --> 02:24:03.000]  1,
[02:24:03.000 --> 02:24:05.000]  0
[02:24:05.000 --> 02:24:07.000]  Деструкты.
[02:24:07.000 --> 02:24:09.000]  Раз с обращением,
[02:24:09.000 --> 02:24:11.000]  два с обращением,
[02:24:11.000 --> 02:24:13.000]  третий.
[02:24:13.000 --> 02:24:15.000]  И здесь
[02:24:15.000 --> 02:24:17.000]  у нас по-прежнему какое
[02:24:17.000 --> 02:24:19.000]  от release?
[02:24:19.000 --> 02:24:21.000]  Здесь
[02:24:23.000 --> 02:24:25.000]  Aqual release.
[02:24:25.000 --> 02:24:27.000]  А здесь что?
[02:24:31.000 --> 02:24:33.000]  Давайте вернем экран.
[02:24:35.000 --> 02:24:37.000]  А здесь relax.
[02:24:41.000 --> 02:24:43.000]  И вот
[02:24:43.000 --> 02:24:45.000]  это некоторая техническая трудность.
[02:24:45.000 --> 02:24:47.000]  Потому что
[02:24:47.000 --> 02:24:49.000]  теперь у нас Fetch add.
[02:24:49.000 --> 02:24:51.000]  Вот эта единица, которая записала Fetch sub,
[02:24:51.000 --> 02:24:53.000]  читает вот этот Fetch add.
[02:24:53.000 --> 02:24:55.000]  The last.
[02:24:55.000 --> 02:24:57.000]  А потом мы и пишем двойку.
[02:24:57.000 --> 02:24:59.000]  А потом мы двойку читаем самую.
[02:24:59.000 --> 02:25:01.000]  И вот непонятно, как связь здесь
[02:25:01.000 --> 02:25:03.000]  случается. То есть здесь связь
[02:25:03.000 --> 02:25:05.000]  будет, да?
[02:25:05.000 --> 02:25:07.000]  Как обычно.
[02:25:07.000 --> 02:25:09.000]  Как на прошлой картинке.
[02:25:09.000 --> 02:25:11.000]  И здесь программа order тоже есть у нас.
[02:25:11.000 --> 02:25:13.000]  Но непонятно, что вот с этим
[02:25:13.000 --> 02:25:15.000]  происходит.
[02:25:15.000 --> 02:25:17.000]  С этим потоком.
[02:25:19.000 --> 02:25:21.000]  И
[02:25:21.000 --> 02:25:23.000]  это еще одно
[02:25:23.000 --> 02:25:25.000]  темное место
[02:25:25.000 --> 02:25:27.000]  от repartice++.
[02:25:27.000 --> 02:25:29.000]  Но не то, что темное место.
[02:25:29.000 --> 02:25:31.000]  Смотрите.
[02:25:31.000 --> 02:25:33.000]  Synchronize with – оно про причинность.
[02:25:33.000 --> 02:25:35.000]  То есть оно
[02:25:35.000 --> 02:25:37.000]  это формальное обветрение, которое
[02:25:37.000 --> 02:25:39.000]  фиксирует, что причинность передалась.
[02:25:39.000 --> 02:25:41.000]  Мы здесь записали двойку,
[02:25:41.000 --> 02:25:43.000]  мы почитали двойку.
[02:25:43.000 --> 02:25:45.000]  Значит, вот этот поток будет знать,
[02:25:45.000 --> 02:25:47.000]  что вот это уже произошло.
[02:25:47.000 --> 02:25:49.000]  А здесь у нас, смотрите,
[02:25:49.000 --> 02:25:51.000]  у нас операция
[02:25:51.000 --> 02:25:53.000]  Fetch sub.
[02:25:53.000 --> 02:25:55.000]  Это вот запись с
[02:25:55.000 --> 02:25:57.000]  релизом.
[02:26:05.000 --> 02:26:07.000]  Давайте так.
[02:26:07.000 --> 02:26:09.000]  Запись с релизом.
[02:26:11.000 --> 02:26:13.000]  Эту запись читает кто?
[02:26:13.000 --> 02:26:15.000]  Операция
[02:26:15.000 --> 02:26:17.000]  Read the correct
[02:26:19.000 --> 02:26:21.000]  с релизом.
[02:26:23.000 --> 02:26:25.000]  А потом
[02:26:31.000 --> 02:26:33.000]  происходит чтение
[02:26:37.000 --> 02:26:39.000]  с такое.
[02:26:39.000 --> 02:26:41.000]  Опять
[02:26:41.000 --> 02:26:43.000]  не просто чтение, не просто запись,
[02:26:43.000 --> 02:26:45.000]  а томатная
[02:26:45.000 --> 02:26:47.000]  операция.
[02:26:47.000 --> 02:26:49.000]  Так вот, будет здесь причинность
[02:26:49.000 --> 02:26:51.000]  логическая.
[02:26:51.000 --> 02:26:53.000]  Но по идее
[02:26:53.000 --> 02:26:55.000]  да, потому что мы здесь
[02:26:55.000 --> 02:26:57.000]  написали что-то, а потом мы скажем по инкрименту.
[02:26:57.000 --> 02:26:59.000]  И если мы видим здесь,
[02:26:59.000 --> 02:27:01.000]  то мы знаем, как будто бы
[02:27:01.000 --> 02:27:03.000]  эта операция сохраняет
[02:27:03.000 --> 02:27:05.000]  причинность.
[02:27:05.000 --> 02:27:07.000]  То есть если мы здесь
[02:27:07.000 --> 02:27:09.000]  просто записали что-то другим,
[02:27:09.000 --> 02:27:11.000]  то скотчка провала тебя.
[02:27:11.000 --> 02:27:13.000]  Мы не можем больше ничего ожидать.
[02:27:13.000 --> 02:27:15.000]  А тут мы как бы
[02:27:15.000 --> 02:27:17.000]  усложнили, продлили
[02:27:17.000 --> 02:27:19.000]  историю модификации.
[02:27:19.000 --> 02:27:21.000]  И история модификации продолжилась.
[02:27:21.000 --> 02:27:23.000]  Начинность продолжилась.
[02:27:23.000 --> 02:27:25.000]  Вот поэтому C++
[02:27:25.000 --> 02:27:27.000]  есть такое специальное понятие.
[02:27:27.000 --> 02:27:29.000]  Оно называется
[02:27:29.000 --> 02:27:31.000]  reverse sequence.
[02:27:31.000 --> 02:27:33.000]  Давайте я уже это покажу.
[02:27:33.000 --> 02:27:35.000]  В стандарте.
[02:27:35.000 --> 02:27:37.000]  А мы сейчас ничего не увидим, наверное,
[02:27:37.000 --> 02:27:39.000]  на такой доске.
[02:27:45.000 --> 02:27:47.000]  Вот определение
[02:27:47.000 --> 02:27:49.000]  synchronize this with, оно в C++
[02:27:49.000 --> 02:27:51.000]  тоже сложнее, чем я вам показывал.
[02:27:51.000 --> 02:27:53.000]  Вот я вам показывал такое определение.
[02:27:55.000 --> 02:27:57.000]  Ну пойдем.
[02:28:03.000 --> 02:28:05.000]  Неспешно появляется.
[02:28:05.000 --> 02:28:07.000]  У нас есть
[02:28:07.000 --> 02:28:09.000]  атомарная запись с релизом,
[02:28:09.000 --> 02:28:11.000]  есть атомарное чтение с акварием,
[02:28:11.000 --> 02:28:13.000]  и чтение читает запись, тогда синхронизуется.
[02:28:13.000 --> 02:28:15.000]  В C++
[02:28:15.000 --> 02:28:17.000]  вводится вспомогательная
[02:28:17.000 --> 02:28:19.000]  конструкция, которая называется release sequence.
[02:28:19.000 --> 02:28:21.000]  Это релиз-запись,
[02:28:21.000 --> 02:28:23.000]  за которой исследует цепочка
[02:28:23.000 --> 02:28:25.000]  read and write
[02:28:25.000 --> 02:28:27.000]  операции.
[02:28:27.000 --> 02:28:29.000]  И она называется release sequence.
[02:28:29.000 --> 02:28:31.000]  И мы говорим, что
[02:28:31.000 --> 02:28:33.000]  запись с релизом синхронизируется
[02:28:33.000 --> 02:28:35.000]  с чтением с акварием,
[02:28:35.000 --> 02:28:37.000]  когда чтение
[02:28:37.000 --> 02:28:39.000]  с акварием читает
[02:28:39.000 --> 02:28:41.000]  результат
[02:28:41.000 --> 02:28:43.000]  release sequence,
[02:28:43.000 --> 02:28:45.000]  начавшийся в
[02:28:45.000 --> 02:28:47.000]  этой релиз-записи.
[02:28:51.000 --> 02:28:53.000]  Вот можно открыть
[02:28:53.000 --> 02:28:55.000]  определение синхронизации
[02:28:55.000 --> 02:28:57.000]  с C++, и вот тут написано, что у нас есть
[02:28:57.000 --> 02:28:59.000]  релиз операции A
[02:28:59.000 --> 02:29:01.000]  на объекте M
[02:29:01.000 --> 02:29:03.000]  и acquire операция B.
[02:29:05.000 --> 02:29:07.000]  И вот B читает сайд-эффект
[02:29:07.000 --> 02:29:09.000]  release sequence
[02:29:09.000 --> 02:29:11.000]  с головой в A.
[02:29:11.000 --> 02:29:13.000]  Вот, release sequence
[02:29:13.000 --> 02:29:15.000]  с головой в A, и мы читаем результат ее,
[02:29:15.000 --> 02:29:17.000]  то есть вот это значение.
[02:29:27.000 --> 02:29:29.000]  В нашем примере
[02:29:29.000 --> 02:29:31.000]  вот этот фей часа
[02:29:31.000 --> 02:29:33.000]  прошедал бой,
[02:29:33.000 --> 02:29:35.000]  который является
[02:29:35.000 --> 02:29:37.000]  release sequence
[02:29:37.000 --> 02:29:39.000]  из пятой операции
[02:29:39.000 --> 02:29:41.000]  и вот этой операции.
[02:29:43.000 --> 02:29:45.000]  И вот головой
[02:29:45.000 --> 02:29:47.000]  релиз sequence вот этот
[02:29:47.000 --> 02:29:49.000]  релиз-записи.
[02:29:49.000 --> 02:29:51.000]  А мы читаем результат
[02:29:51.000 --> 02:29:53.000]  этой релиз-записи, а вот
[02:29:53.000 --> 02:29:55.000]  короче, вот эта штука.
[02:29:55.000 --> 02:29:57.000]  Это релиз-записи.
[02:29:59.000 --> 02:30:01.000]  Это релиз-записи, и вот
[02:30:01.000 --> 02:30:03.000]  между
[02:30:07.000 --> 02:30:09.000]  между вот этой записью
[02:30:09.000 --> 02:30:11.000]  и этим чтением уже возникается
[02:30:11.000 --> 02:30:13.000]  релиз-записи.
[02:30:25.000 --> 02:30:27.000]  То есть формально
[02:30:27.000 --> 02:30:29.000]  вот у нас здесь тоже есть
[02:30:29.000 --> 02:30:31.000]  релиз-записи.
[02:30:33.000 --> 02:30:35.000]  И опять все
[02:30:35.000 --> 02:30:37.000]  упорядочено.
[02:30:37.000 --> 02:30:39.000]  Вот такие жуткие штуки.
[02:30:39.000 --> 02:30:41.000]  Это всего лишь
[02:30:41.000 --> 02:30:43.000]  фиксация реальности. Мы ожидаем,
[02:30:43.000 --> 02:30:45.000]  что вот такая цепочка операции
[02:30:45.000 --> 02:30:47.000]  они логически справят причинность,
[02:30:47.000 --> 02:30:49.000]  поэтому мы просто
[02:30:49.000 --> 02:30:51.000]  немного усложним определение.
[02:30:51.000 --> 02:30:53.000]  Но вот оптимальные memory
[02:30:53.000 --> 02:30:55.000]  ордеры для инкремента и декремента
[02:30:55.000 --> 02:30:57.000]  в SharePoint, они такие.
[02:30:57.000 --> 02:30:59.000]  В декременте у нас фейчсап,
[02:30:59.000 --> 02:31:01.000]  в декременте у нас square плюс релиз,
[02:31:01.000 --> 02:31:03.000]  в инкременте у нас релакс.
[02:31:03.000 --> 02:31:05.000]  В вейт-группе, в домашних получается
[02:31:05.000 --> 02:31:07.000]  что-то то же самое.
[02:31:13.000 --> 02:31:15.000]  Но началось с того, что мы поняли,
[02:31:15.000 --> 02:31:17.000]  что нужно упорядочивать запрощение
[02:31:17.000 --> 02:31:19.000]  и диструктор.
[02:31:19.000 --> 02:31:21.000]  Ну все.
[02:31:21.000 --> 02:31:23.000]  Хватит у нас на сегодня.
[02:31:23.000 --> 02:31:25.000]  Да, все это последний memory
[02:31:25.000 --> 02:31:27.000]  ордер. У нас был
[02:31:27.000 --> 02:31:29.000]  relaxed, acquired-release,
[02:31:29.000 --> 02:31:31.000]  их комбинация был consume
[02:31:31.000 --> 02:31:33.000]  ну и default.
