[00:00.000 --> 00:25.760]  Так, давайте начнём, значит сегодня у нас вторая лекция про вероятностные
[00:25.760 --> 00:30.520]  вычисления, и сегодня мы, собственно, познакомимся с сложностными классами,
[00:30.520 --> 00:35.120]  которые возникают вот из разного рода рандомизированных алгоритмов.
[00:35.120 --> 00:41.280]  Ну прежде всего нужно остановиться на какой-то модели вероятностных вычислений.
[00:41.280 --> 00:44.920]  Ну и мне будет удобно использовать вот такую вот модель.
[00:44.920 --> 01:00.760]  Модель вероятностных вычислений заключается в том, что у меня есть просто какая-то функция
[01:00.760 --> 01:13.960]  вычислимая от двух аргументов. Значит, здесь x это, собственно, вход, а r это
[01:13.960 --> 01:25.240]  случайные биты. Ну и, соответственно, это вот получается функция, значит, вычислимая за время
[01:25.240 --> 01:43.680]  по лином от длины x. Соответственно, нас интересует, ну получается, что значение это 0 или 1,
[01:43.680 --> 01:50.600]  то есть получается результат работы, это, на самом деле, случайная величина вернулевская,
[01:50.600 --> 02:05.480]  то есть она принимает значение 0 или 1. То есть результат работы, значит, это вернулевская,
[02:09.480 --> 02:18.520]  вернулевская случайная величина, ну то есть она принимает 0 или 1 с какими-то вероятностями.
[02:18.520 --> 02:27.880]  То есть тут механика такая, что длина x дает длину r, ну может, для разных x будут разные r,
[02:27.880 --> 02:35.160]  тогда есть некоторые максимальные длина. И, соответственно, рассматривается равномерное
[02:35.160 --> 02:43.800]  воспределение на всех возможных r. Ну и какие-то r дают исход 0, какие-то r дают исход 1,
[02:43.800 --> 02:52.240]  но и вот эта вот вероятность, это просто доля, значит, доля тех r, которые дают 1 среди всех
[02:52.240 --> 03:01.840]  возможных r. То есть вот поскольку всего два исхода, то есть одно число, которое описывает
[03:01.840 --> 03:16.600]  эту случайную величину. Ну и вот теория ложности принята, давайте напишу равно 1, принято вот такое
[03:16.600 --> 03:23.120]  вот обозначение, значит, вообще вероятность там по-всякому обозначают. Но когда у нас много
[03:23.120 --> 03:29.600]  параметров, то можно, чтобы не запутаться, написать, что именно у нас случайное. То есть
[03:29.600 --> 03:34.760]  здесь вот в этой величине v от x и r, r случайное, а вот x фиксированное. Поэтому
[03:34.760 --> 03:41.120]  это подчеркивают, да, это подчеркивают, записав вероятность по r. Это важно, на самом деле,
[03:41.120 --> 03:44.920]  потому что в других приложениях может быть и x случайное, да, то есть когда мы говорим
[03:44.920 --> 03:50.280]  про какую-нибудь сложность в среднем, например, да, то тогда аргумент тоже будет случайным,
[03:50.280 --> 03:57.520]  даже для для детерминированного вычисления, и там будет другая вероятность. Вот, но вот здесь нас
[03:57.520 --> 04:05.120]  вот эта вероятность интересует. Вот, но и идея разных классов в том, что мы каким-то образом
[04:05.120 --> 04:12.920]  ограничим вот эту вероятность для случая, когда x лежит в а, и когда x не лежит в а. Да, то есть,
[04:12.920 --> 04:27.280]  значит, разные классы, значит, разные классы получаются из оценок
[04:27.520 --> 04:53.280]  на вот эту вероятность при x лежащем и x нележащем. Так, но, наверное, нужно заметить,
[04:53.280 --> 04:59.360]  что на самом деле те классы, которые мы уже знаем, можно в таких термах определить. Да, поэтому,
[04:59.360 --> 05:04.640]  ну, в принципе, видно уже и через обозначение, да, то, что у нас здесь происходит, похоже на то,
[05:04.640 --> 05:11.160]  что у нас в NP было, да, там у нас тоже было два аргумента, но определение было такое, что если
[05:11.160 --> 05:17.720]  x лежит в а, тогда такой второй аргумент существует, да, то есть r, а если x не лежит в а,
[05:17.720 --> 05:24.560]  то тогда такого аргумента не существует. Вот, ну, и получается, что можно сформулировать NP
[05:24.560 --> 05:40.480]  в таких терминах. Значит, можно так описать NP. Значит, если x принжит а, то тогда вероятность
[05:40.480 --> 05:51.680]  по r того, что v от x пр равно 1, это будет больше нуля просто, вот, ну, а если x не принжит а,
[05:51.680 --> 06:03.280]  то тогда эта вероятность равна нулю. Вот, ну, и CoNP тоже на самом деле можно описать. Значит,
[06:03.280 --> 06:15.160]  если CoNP, то можно считать, что здесь равно 1, а здесь меньше 1. Вот, то есть те кластеры,
[06:15.160 --> 06:19.960]  у нас уже были, вот так описывают, но они, конечно, по сути, они, конечно, не являются вероятностами.
[06:19.960 --> 06:25.040]  Вот, а почему вообще так, да, значит, почему не можем вероятностным алгоритмом решать все из NP?
[06:25.040 --> 06:31.200]  Ну, вообще говоря, конечно, никто не знает, может быть, и можно, но почему не пройдет тривиальный
[06:31.200 --> 06:39.280]  алгоритм, что мы там берем случайно r и, соответственно, если попали, то возвращаем 1,
[06:39.280 --> 06:45.440]  если не попали, то возвращаем 0. Значит, это не работает просто потому, что этих r может быть
[06:45.440 --> 06:51.440]  совсем мало, да, в крайнем случае может быть одно r из экспедиционного количества. И чтобы
[06:51.440 --> 06:55.600]  иметь какую-то существенную вероятность в это r попасть, нужно как раз экспедиционничный попыток
[06:55.600 --> 07:05.320]  сделать, и это не будет полиномиальный алгоритм. Вот, поэтому, чтобы, да, чтобы это каким-то образом
[07:05.320 --> 07:13.520]  получалось, значит, нужно, чтобы вот не совсем такой маленький зазор был, чтобы он был такой
[07:13.520 --> 07:23.520]  существенный. Вот, ну, и тут, значит, самый главный класс вероятностный это класс BPP.
[07:23.520 --> 07:38.120]  Класс BPP, значит, это класс с двусторонней ошибкой. Значит, буквы здесь означают,
[07:38.120 --> 07:46.760]  вот PPP это probabilistic polynomial, а B означает bounded error. То есть ошибка еще не только односторонняя,
[07:46.760 --> 07:57.240]  но и ограниченная. Вот, ну да, и ограниченная она кем-то, что меньше 1 и 2. Смотрите, если можно
[07:57.240 --> 08:02.760]  ошибаться ровно на 1 и 2, то можно просто монетку подкидывать на это, тогда с ровно 1 и 2 угадать,
[08:02.760 --> 08:08.840]  с ровно 1 и 2 ошибетесь. Вот, поэтому, чтобы какой-то смысл был в алгоритме, нужно, чтобы ошибка
[08:08.840 --> 08:16.280]  была меньше, чем 1 и 2. Вот, но вот bounded error означает, что они просто меньше, а существенные меньше.
[08:16.280 --> 08:23.960]  Вот, ну, насколько им на самом деле не важно, значит, ну, классически говорят, соответственно,
[08:23.960 --> 08:33.560]  что если x лежит в A, значит, я перепишу, то вероятность того, что v от xr равно 1,
[08:33.560 --> 08:47.520]  эта вероятность будет больше, чем 2 трети, а если x метровим zeta, то тогда та же самая
[08:47.520 --> 08:59.920]  вероятность будет меньше, чем 1 третий. Вот, соответственно, вероятность ошибки ограничена 1 третью.
[08:59.920 --> 09:09.080]  Вот, ну, через некоторое время мы увидим, что вот это вот 1 треть и 2 третьи, это корея, да, не
[09:09.080 --> 09:16.880]  традиция, а реально тут не важно, что писать, но чтобы был разрыв главный, да, то есть можно
[09:17.280 --> 09:27.440]  писать, скажем, здесь 49% и здесь 51%, можно наоборот, здесь 1% и здесь 99%. Можно даже, чтобы это
[09:27.440 --> 09:34.280]  были не симметричные, да, например, можно, чтобы здесь было, скажем, там 5% и здесь 20%,
[09:34.280 --> 09:43.720]  да. Может быть даже, что это не константы, но соседние константы не могут быть, а то мы вот
[09:43.720 --> 09:51.440]  вот сюда вот выродимся. Вот, но, например, может быть, разница будет какой-то
[09:51.440 --> 09:55.280]  убывающей функцией, но не слишком быстро. Убывающей, да, например, тут может быть
[09:55.280 --> 10:03.800]  там 1 вторая минус 1n, а здесь 1 вторая плюс 1n. Да, такое тоже подойдет. Вот, ну
[10:03.800 --> 10:13.800]  значит, сейчас попозже поговорим про то, почему так можно делать. Так, значит,
[10:13.800 --> 10:28.680]  еще есть классы РП и КОРП. Классы РП и КОРП. Это классы с односторонней
[10:28.680 --> 10:40.400]  ошибкой. Ну, а здесь буквка Р означает рандомайст. Да, то есть вот так сложилось,
[10:40.400 --> 10:44.920]  что пробабилистик вот тут вот, тут пробабилистик, а тут рандомайст, хотя это вроде
[10:44.920 --> 10:56.280]  синонимы, но примедительно классом получается разное определение. Так, значит, ну и как
[10:56.280 --> 10:59.920]  запомнить, какой стороны односторонние, потому что определение должно быть похоже
[10:59.920 --> 11:11.360]  у РП на НП, а у КОРП на КОНП. Соответственно, у РП получается так, что если Х лежит в А,
[11:11.360 --> 11:24.720]  то тогда вероятность того, что В от XR равно единице, будет больше, чем 1 вторая. Вот, а если Х не
[11:24.720 --> 11:39.320]  лежит в А, то тогда вероятность равна НУДУ. Ну, а КОРП наоборот. Значит, тут равно единице,
[11:39.320 --> 11:49.760]  а тут меньше, чем 1 вторая. Ну и реально на самом деле то, что мы изучали в прошлый раз,
[11:49.760 --> 11:56.520]  то есть алгоритм проверки простоты и алгоритм проверки значения на равенство, они были
[11:56.520 --> 12:06.600]  синонимой ошибкой. А что было в наших тестах простоты? Что если число простое, то тогда алгоритм
[12:06.600 --> 12:12.680]  точно говорит, что оно простое. Если число составное, то алгоритм маловероятно, что говорит,
[12:12.680 --> 12:21.880]  что оно простое. Но это вот ровно КОРП. Если это для простоты, это если тест простоты, то алгоритм
[12:21.880 --> 12:28.560]  точно говорит, что оно простое. Если это число составное, то он маловероятно ошибает. Но это вот
[12:28.560 --> 12:37.120]  Миллер Рабина и Соловая Штрассена, бывает другой тест Эйделмана Хуана, который у которого все на
[12:37.120 --> 12:42.440]  оборот. То есть если число составное, то он точно говорит, что оно составное, а если оно простое, то
[12:42.440 --> 12:51.400]  скорее всего говорит, что простое. Поэтому еще до того, как оказалось, что простые числа вообще
[12:51.400 --> 12:58.800]  детерминированно решаются за полинальное время, уже были были известны вот такой алгоритм и вот такой
[12:58.800 --> 13:15.400]  алгоритм. Ну еще есть класс с неограниченной ошибкой или наброс с нулевой ошибкой. ПП это
[13:15.400 --> 13:25.480]  просто пробабилистик-полиномиал. Значит, это с неограниченной ошибкой. Вот, слушайте, я уже не буду
[13:25.480 --> 13:34.720]  переписывать. Ну уж только чтобы нельзя было просто одну-вторую сделать. Ну, например, сверху у нас
[13:34.720 --> 13:41.560]  будет больше ли равно одной-второй, а снизу меньше одной-второй. А так эти все выражения тут
[13:41.680 --> 13:48.560]  одни и те же. Так что я их не переписываю. Значит, тут все-таки если одно и то же число не может быть,
[13:48.560 --> 13:59.000]  и там и там, то все-таки нельзя тривиально это решить. Вот, и еще есть наоборот, значит, ZPP.
[13:59.000 --> 14:12.560]  А Z это zero error. Значит, ZPP это с нулевой ошибкой. Ну, и это на самом деле как раз алгоритм
[14:12.560 --> 14:26.360]  Лас-Вегаса. Значит, это алгоритм Лас-Вегаса. Значит, тут ответ всегда верный, но при этом
[14:26.360 --> 14:37.480]  полиномиальное время только в среднем. То есть мот ожидания. Значит, ответ всегда верный,
[14:37.480 --> 14:53.160]  но полиномиальное время только в среднем. Полиномиальное время только в среднем.
[14:53.160 --> 15:06.280]  Ну, потому что если и ответ всегда верный, и полиномиальное время в худшем случае,
[15:06.280 --> 15:11.600]  то это просто P будет, потому что можно что угодно дописать в качестве случайных битов. После этого
[15:11.600 --> 15:17.360]  будет правильный ответ за полиномиальное время. Значит, если он в среднем полиномиальный,
[15:17.360 --> 15:23.440]  то тогда будет правильный ответ, но не факт, что это за полиномиальное время. Поэтому то,
[15:23.440 --> 15:40.520]  что ZPP больше, чем P, это не факт. Вот это основные классы, которые мы сейчас изучим. Давайте я нарисую
[15:40.520 --> 15:48.880]  диаграмму, как они друг с другом соотносятся. Ну, можно, конечно, и P добавить. P будет то же
[15:48.880 --> 15:58.000]  самое, только со временем в худшем случае. Вот так. Значит, диаграмм будет такой, что сам внизу будет P.
[15:58.000 --> 16:09.000]  Потом будет ZPP. Значит, P вложено в ZPP, конечно, потому что можно случайно бит игнорировать,
[16:09.000 --> 16:25.120]  и просто вычислить. Значит, ZPP будет вложено в RP и в QRP. И, на самом деле, верно даже больше.
[16:25.120 --> 16:33.040]  Да, не просто ZPP вложено туда и туда, а на самом деле верно, что ZPP это будет пересечение RP в
[16:33.680 --> 16:57.280]  QRP. Так, значит, дальше ERP и QRP будут вложены в BPP. Кроме того, RP вложено в NP, QRP вложено в QNP.
[16:57.280 --> 17:15.040]  И, конечно, на самом верху они все вложены в PPP. Вот. Ну, вот это вот все известные соотношения.
[17:15.040 --> 17:27.040]  То есть, например, неизвестно, как, скажем, RP и QRP соотносятся, как NP и BPP соотносятся.
[17:27.040 --> 17:45.240]  Вот. Ну, а теперь давайте обсудим, обсудим, почему все эти верны соотношения. Так, ну,
[17:45.240 --> 17:51.520]  тут есть парочка очевидных. Значит, очевидно, давайте я буду жирным обводить те, которые мы
[17:51.520 --> 17:58.560]  доказали. Значит, вот это вот очевидно, да, что PP вложено в ZPP. Ой, в смысле просто P вложено в ZPP,
[17:58.560 --> 18:05.000]  потому что можно вообще не использовать случайные биты, да, и будет правильный ответ. И тут даже в
[18:05.000 --> 18:10.360]  худшем случае за параллельное время, значит, и в среднем тоже. Вот. И что очевидно вот это вот?
[18:10.360 --> 18:15.680]  Просто потому что там усиление не равен, да, то есть, если у нас получилось больше двух третей,
[18:15.680 --> 18:26.120]  то это больше одной второй, да, а если меньше одной третьей, то меньше одной второй. Так. Ну,
[18:26.120 --> 18:31.560]  пожалуйста, все остальные уже не очень очевидны, да, какие-то рассуждения все-таки нужно проводить.
[18:31.560 --> 18:40.960]  Но некоторые, а, не, все-таки вот это вот, вот RP в NP и QRP в QNP тоже очевидно, по той же причине. Да,
[18:40.960 --> 18:47.920]  потому что больше одной второй значит больше нуля. Вот если мы NP так определили, да, то получается,
[18:47.920 --> 18:59.720]  если тут больше одной второй, да, то тут получается больше нуля. Ну, и QNP, QRP также. Так. Ну,
[18:59.720 --> 19:05.320]  также видна некоторая симметрия, да, то есть, что ясно, что вот это так же, как вот это должно быть,
[19:05.320 --> 19:13.600]  а вот это так же, как вот это. То есть, фактически три вещи остались. Ну, и еще более сильное утверждение
[19:13.600 --> 19:26.800]  вот это вот. Так. Ну, давайте. А, тут тоже нас симметрия, да, в общем, три вещи симметричные.
[19:26.800 --> 19:43.680]  Так, давайте, например, взгляд PP вложено в RP. Ну, вот тут можно сказать так. Значит, там есть такое
[19:43.680 --> 19:54.080]  вероятностное неравенство, называется неравенство Маркова. Это вы слышали такое? Так, ну, да-да-да,
[19:54.080 --> 19:59.680]  что если у вас, если у вас положительная случайная величина, и у нее есть какое-то
[19:59.680 --> 20:05.040]  мотожидание, да, то тогда вероятность того, что она там сильно больше мотожидания, маленькая,
[20:05.040 --> 20:12.120]  а именно там меньше, чем один, делите на то, во сколько раз превышаем. Вот. Соответственно,
[20:12.120 --> 20:25.440]  вот, как мы это здесь применяем. Так, начну. Пусть, пусть вот это вот V от XR работает в среднем
[20:25.440 --> 20:49.040]  за какой-то, начнем P от M. Тогда с вероятностью больше, чем одна вторая, значит, средства больше,
[20:49.040 --> 21:02.240]  чем одна вторая, он работает меньше либо равно за не более, чем два P от M. Ну, потому что даже
[21:02.240 --> 21:07.920]  ноль шагов не может быть, да, надо договориться, что начальное и конечное состояние разные вещи,
[21:07.920 --> 21:13.600]  да, так что хотя бы один шаг он делает. Ну, и тогда более-менее понятно, да, даже без неравенства
[21:13.600 --> 21:20.160]  Маркова, да, что если таких будет больше половина, да, то уже из таких, где больше вот столько будет
[21:20.160 --> 21:29.680]  хотя бы половина, то уже средний будет больше, чем P от M. Так, я понятные вещи говорю? Ну, то есть
[21:29.680 --> 21:33.280]  у нас на половине у нас будет хотя бы столько, на другой половине хотя бы один, на среднем
[21:33.280 --> 21:45.200]  должно быть больше, чем P от M. Вот, хорошо, ну и тогда, тогда, значит, алгоритм с односторонней
[21:45.200 --> 21:57.800]  ошибкой, значит, алгоритм с односторонней ошибкой просто запустить вот на два P от M, да, значит,
[21:57.800 --> 22:12.760]  если ответ есть, то его и выдать. Значит, запустить, наверное, V от XR на два P от N шагов,
[22:12.760 --> 22:22.200]  N иметь в виду длина X, как обычно. Вот, соответственно, если остановился, то выдать результат,
[22:22.200 --> 22:44.640]  если остановился, то вернуть результат. Если не остановился, ну, тогда, на самом деле, вопрос,
[22:44.640 --> 22:53.200]  то, что выдать по умолчанию для RP и для CoRP, смотрите, если он не остановился, то мы не знаем
[22:53.200 --> 23:00.000]  результатов, но в RP написано, что если к нему лежит VAT, то мы не можем выдать 1. Ну, соответственно,
[23:00.000 --> 23:09.080]  если мы не знаем результатов, то надо 0 выдавать. Вот, ну а для CoRP надо 1 выдавать. Если не остановился,
[23:09.080 --> 23:28.160]  то нужно выдать 0. Это для RP или 1 для CoRP? Средним по R, да, конечно. Да, это правильный вопрос,
[23:28.160 --> 23:40.640]  но для каждого X средним по R полиномиальное время. Ну вот, тогда получается, что это алгоритм
[23:40.640 --> 23:51.480]  полиномиальный, да, вот он 2P от N работает, плюс еще немножко. И, действительно, тут, значит,
[23:51.480 --> 23:58.800]  условия выполняются, да, значит, для RP посмотрим. Если X не лежит в A, то тогда либо алгоритм
[23:58.800 --> 24:07.080]  остановился и выдал верный ответ. Так, тут верно-то вернем. Значит, он выдал верный ответ,
[24:07.080 --> 24:14.200]  и мы его вернем. А если он не остановился, то выдаст 0, и это тоже будет верный ответ.
[24:14.200 --> 24:22.040]  Значит, если X не лежит в A, то все нормально. Если X лежит в A, то тогда, конечно, когда мы
[24:22.040 --> 24:30.560]  выдадим 0, мы ошибемся, но это произойдет не больше 1 и 2, ровно вот из-за вот этого
[24:30.560 --> 24:39.520]  свойства, что все-таки это остановится. В принципе, больше половины, и в этом случае выдават, опять же,
[24:39.520 --> 25:00.960]  верный ответ. Вот. Так, ну что, понятно? Ну, то есть, суть такая, да, что если у нас в среднем
[25:00.960 --> 25:05.520]  время полиномиальное, да, то есть мы достаточно много проработаем, то мы, скорее всего, остановимся,
[25:05.520 --> 25:10.960]  и предположим правильный ответ. А если не остановится, не знаю, ничего выдавать,
[25:10.960 --> 25:21.600]  ну выдадим, чтобы не было той ошибки, которую мы хотим избежать. Так, два, значит, РП вложено
[25:21.600 --> 25:36.240]  в ВПП, но это даже проще, может быть, с этого стоило начать. Значит, РП вложено в ВПП, и тут вот идея
[25:36.240 --> 25:44.880]  амплификации возникает. Идея амплификации.
[25:52.480 --> 25:57.920]  Значит, мы просто запустим два раза. Значит, запустим два раза.
[25:57.920 --> 26:07.760]  Собственно, если бы у нас там определение РП, а вместо 1-2 стояло бы 1 на треть, то вообще ничего
[26:07.760 --> 26:15.520]  не надо было бы делать, да, можно было бы просто сослаться на то, что там, то есть сейчас, наоборот,
[26:15.760 --> 26:21.280]  это в кое РП вместо 1-2 стояло бы 1 на треть, а в РП вместо 1-2 стояло бы 2 на треть. Вот.
[26:21.280 --> 26:26.320]  Если бы это было так, то можно было просто сослаться, что там равно нулю, значит, меньше 1-3, и все работает.
[26:26.320 --> 26:31.920]  Но если там 1-2, то все-таки нужно уже рассуждать о том, как от одной границы к другой переходить.
[26:31.920 --> 26:37.520]  Вот. Ну и это вот совсем простой случай. Значит, запустим два раза.
[26:37.520 --> 26:43.360]  Запустим два раза. Возьмем дизъюнцию.
[26:53.120 --> 26:54.400]  Возьмем дизъюнцию
[27:02.280 --> 27:03.160]  результатов.
[27:08.400 --> 27:19.320]  Вот. Значит, что тут работает? Ну, значит, если х лежит 2, то тогда оба раза 0 будут
[27:19.320 --> 27:26.720]  варианты чуть меньше, чем, если запуска независима, да, это, кстати, важно. Значит, два раза. Давайте пишу независимо.
[27:26.720 --> 27:34.280]  Значит, если х лежит 2, тогда вероятность того, что оба раза 0,
[27:34.280 --> 27:41.880]  вероятность нуля на обоих запусках,
[27:51.880 --> 27:57.760]  значит, будет меньше, чем 1-2 на 1-2, которое есть 1 четверть.
[27:57.760 --> 28:03.960]  Ну, соответственно, раз 3 единицы будет больше, чем 3 четверти.
[28:03.960 --> 28:13.320]  Раз 1 единицы будет больше, чем 3 четверти, а это будет больше, чем 2 третья.
[28:13.320 --> 28:22.800]  Значит, поэтому там все верно получается, в соответствии с определением. Вот. Ну, если х не лежит в А,
[28:22.800 --> 28:35.360]  то тогда обязательно будет 0 на обоих запусках, и итоговый тоже. Итоговый дизъюнции точно 0.
[28:35.360 --> 28:45.840]  Значит, если х не принадлежит, то получается оба раза 0, и тогда получается ответ 0.
[28:52.840 --> 29:00.840]  Вот. Что такое это рассуждение?
[29:00.840 --> 29:12.840]  И, в принципе, если его продолжать, то видно, что афер вместо 1-2 можно любую константу поставить.
[29:12.880 --> 29:29.880]  Ну, то есть, например, ну, если мы это будем делать там n раз, то у нас тут место больше 3 четверти,
[29:29.920 --> 29:35.920]  то получится больше, чем там 1 минус 1 вторая военная степень.
[29:35.920 --> 29:47.920]  Значит, если повторить n раз, то тогда тут получится, значит, 0 останется 0,
[29:47.920 --> 29:55.920]  потому что если единица не может быть выдана, всегда выдается 0, то дизъюнция тоже будет 0.
[29:55.960 --> 30:01.960]  Вот. А тут будет, так, я тут уже не пишу, но у меня все время одни и те же вероятности,
[30:01.960 --> 30:05.960]  если х лежит в А, то какая вероятность будет, если х не лежит в А,
[30:05.960 --> 30:13.960]  вероятность будет, и тут будет, соответственно, 1 минус 1 вторая военная степень.
[30:17.960 --> 30:21.960]  Вот. То есть, пресс может считать, что у меня ошибка совсем маленькая.
[30:22.000 --> 30:26.000]  Так, а, слушайте, давайте я это отцеплю.
[30:26.000 --> 30:31.000]  Значит, m не будет мином х, а будет каким-то словом повторов m.
[30:31.000 --> 30:35.000]  То есть, если мы повторяем m раз, то будет 1 минус 1 вторая военная степень.
[30:35.000 --> 30:40.000]  И, значит, если м это какая-то константа, то это может быть сколько угодно близко к 100%,
[30:40.000 --> 30:45.000]  а может быть даже m какой-то полином, значит, m какой-то полином,
[30:45.000 --> 30:49.000]  тогда это будет даже функция стремящейся к единице очень быстро.
[30:52.000 --> 31:01.000]  Вот. И тогда даже видно, значит, видно, что изначально может быть вместо 1 и 2.
[31:06.000 --> 31:12.000]  Да, то есть, мне что нужно? Мне нужно, чтобы вот эта вот штука стремилась бы к нулю.
[31:12.000 --> 31:16.000]  И тогда вместо 1 и 2 может быть что угодно меньше единицы.
[31:16.040 --> 31:26.040]  И даже может быть что-то стремящейся к единице, но не слишком быстро.
[31:26.040 --> 31:32.040]  Например, есть второй замечательный предел,
[31:32.040 --> 31:38.040]  что 1 минус 1m в степени m стремится к 1 делить на е.
[31:40.040 --> 31:45.040]  Вот. И, соответственно, вот это у меня вероятность единицы
[31:45.080 --> 31:50.080]  Сейчас, нет, это у меня вероятность нуля.
[31:50.080 --> 31:54.080]  Вот это 1 минус 1m это вероятность нуля,
[31:54.080 --> 31:58.080]  может быть, что вероятность единицы там будет вместо 1 и 2 будет больше 1m.
[31:58.080 --> 32:07.080]  И тогда, если мы это раз повторим, то у нас вот это вот станет константой.
[32:07.080 --> 32:12.080]  А это у нас константа чего? Это вероятность того, что все время ноль выдают.
[32:12.120 --> 32:17.120]  Будет константа. А потом, можно, скажем, еще раз повторить.
[32:17.120 --> 32:21.120]  Еще раз повторить, и это в m в степени возведется.
[32:21.120 --> 32:27.120]  То есть если тут для m в квадрате написать, то тут будет е в степени m.
[32:29.120 --> 32:34.120]  Ну вот, то есть вывод такой, что если ошибка односторонняя
[32:34.120 --> 32:41.120]  и изначально отличается от единиц хотя бы на обратный полином,
[32:41.160 --> 32:44.160]  то, повторив чуть больший полином раз,
[32:44.160 --> 32:49.160]  и взяв дизюнцию, можно, наоборот, ошибку сделать специально маленькой.
[32:50.160 --> 32:53.160]  Так, ну хорошо, сейчас передов сделаем.
[32:53.160 --> 32:58.160]  Потом поговорим про то, что у меня здесь осталось вот это вот.
[32:58.160 --> 33:01.160]  И про разные другие вещи.
[33:01.160 --> 33:05.160]  Значит, у нас вот это получилось.
[33:05.160 --> 33:08.160]  Значит, вот это получилось, вот это получилось,
[33:08.200 --> 33:11.200]  вот это симметрично точно так же получается.
[33:11.200 --> 33:14.200]  Остались вот эти вот соотношения.
[33:14.200 --> 33:17.200]  Значит, mp и pp, и qnp и pp.
[33:17.200 --> 33:20.200]  Значит, они тоже симметрично делаются.
[33:20.200 --> 33:23.200]  Да, вообще, еще можно заметить, что смотрите,
[33:23.200 --> 33:26.200]  тут есть как бы центральная ось,
[33:26.200 --> 33:29.200]  и вот эти вот боковые ветви и боковые ветви симметричные.
[33:29.200 --> 33:32.200]  То есть, например, если мы возьмем два раза полкласс,
[33:32.200 --> 33:35.200]  то будет то же самое, что изначально.
[33:35.240 --> 33:38.240]  Дополнение ко всем языкам из основного класса.
[33:38.240 --> 33:41.240]  Но вот если по центру брать полкласс,
[33:41.240 --> 33:44.240]  то будет просто все то же самое.
[33:44.240 --> 33:48.240]  Потому что все вот эти языки должны относить к дополнению.
[33:48.240 --> 33:51.240]  Значит, если мы возьмем дополнение,
[33:51.240 --> 33:54.240]  то можно просто обратить ответ,
[33:54.240 --> 33:57.240]  и это будет, поскольку все симметрично,
[33:57.240 --> 34:00.240]  можно обратить ответ, и это будет
[34:00.240 --> 34:03.240]  для дополнения алгоритма того же самого вида.
[34:03.280 --> 34:06.280]  Если они симметричны, то нельзя просто обратить ответ.
[34:06.280 --> 34:09.280]  С bp нет, почему не очевидно?
[34:09.280 --> 34:12.280]  Симметричны больше двух третьей, меньше одной третьей.
[34:12.280 --> 34:15.280]  А, для pp.
[34:15.280 --> 34:18.280]  Да, это правильно говорите, это не очевидно.
[34:18.280 --> 34:21.280]  Да, для bpp очевидно,
[34:21.280 --> 34:24.280]  для pp не очевидно, потому что там точно равно.
[34:24.280 --> 34:27.280]  На самом деле, если сделать
[34:27.280 --> 34:30.280]  строго больше, строго меньше, то будет то же самое.
[34:30.320 --> 34:33.320]  А как именно там делать,
[34:33.320 --> 34:36.320]  это та же методика,
[34:36.320 --> 34:39.320]  которая используется здесь.
[34:39.320 --> 34:42.320]  Давайте я докажу,
[34:42.320 --> 34:45.320]  что np вложено в pp.
[34:51.320 --> 34:54.320]  Хорошо, значит, np вложено в pp.
[34:54.360 --> 34:57.360]  Давайте
[34:57.360 --> 35:00.360]  другому,
[35:00.360 --> 35:03.360]  чуть-чуть по-другому напишем,
[35:03.360 --> 35:06.360]  что у нас, если x лежит в a,
[35:06.360 --> 35:09.360]  то тогда количество таких r,
[35:09.360 --> 35:12.360]  то v от xr равно единице,
[35:12.360 --> 35:15.360]  то это количество больше либо равно единице.
[35:18.360 --> 35:21.360]  Если x не лежит в a,
[35:21.400 --> 35:24.400]  то тогда то же самое количество
[35:27.400 --> 35:30.400]  будет равно нулю.
[35:33.400 --> 35:36.400]  Ну и идея сделать так, чтобы как раз
[35:36.400 --> 35:39.400]  вот это изменение с нуля на хотя бы единицу
[35:39.400 --> 35:42.400]  как раз бы передвигало в область
[35:42.400 --> 35:45.400]  от меньше половины до хотя бы половины.
[35:45.400 --> 35:48.400]  То есть теперь можно сделать
[35:48.440 --> 35:51.440]  вот такую вот функцию v'.
[35:53.440 --> 35:56.440]  Значит v', например, от x
[35:58.440 --> 36:01.440]  и тех нулей
[36:01.440 --> 36:04.440]  будет равняться нулю
[36:04.440 --> 36:07.440]  v' от x
[36:07.440 --> 36:10.440]  и 0
[36:10.440 --> 36:13.440]  и еще там чего-нибудь,
[36:13.440 --> 36:16.440]  0у будет равняться единице,
[36:16.480 --> 36:19.480]  если у не из всех нулей,
[36:19.480 --> 36:22.480]  если у
[36:22.480 --> 36:25.480]  не только из нулей состоит,
[36:25.480 --> 36:28.480]  ну а, наконец, если v'
[36:28.480 --> 36:31.480]  от x и чего-то, что начинает съединиться,
[36:31.480 --> 36:34.480]  то тогда мы запускаем старую машину
[36:34.480 --> 36:37.480]  и получаем v от xr.
[36:37.520 --> 36:40.520]  Вот.
[36:40.520 --> 36:43.520]  Ну это, смотрите,
[36:43.520 --> 36:46.520]  значит вот за счет вот этой части
[36:46.520 --> 36:49.520]  у нас получается
[36:49.520 --> 36:52.520]  ровно половина единиц, кроме одной.
[36:52.520 --> 36:55.520]  Если у нас здесь хотя бы одна единица есть,
[36:55.520 --> 36:58.520]  то у нас уже хотя бы половина единиц будет.
[36:58.520 --> 37:01.520]  А если здесь одни нули, то половины не будет.
[37:01.520 --> 37:04.520]  То есть получается, что
[37:04.560 --> 37:07.560]  вероятность того, что
[37:11.560 --> 37:14.560]  v' от xr,
[37:14.560 --> 37:17.560]  нет, v от xr,
[37:17.560 --> 37:20.560]  значит, вот это вот
[37:20.560 --> 37:23.560]  больше нуля строго,
[37:23.560 --> 37:26.560]  это тогда и только тогда,
[37:26.560 --> 37:29.560]  когда вероятность того, что v'
[37:29.560 --> 37:32.560]  от xz
[37:32.600 --> 37:35.600]  равно единице,
[37:35.600 --> 37:38.600]  будет больше либо равно, чем одна вторая.
[37:44.600 --> 37:47.600]  Потому что ровно как бы
[37:47.600 --> 37:50.600]  все кроме одной,
[37:50.600 --> 37:53.600]  мы сделали, если еще одна добавится,
[37:53.600 --> 37:56.600]  то будет уже хотя бы одна вторая.
[37:56.600 --> 37:59.600]  Вот.
[38:02.600 --> 38:05.600]  Ну вот,
[38:05.600 --> 38:08.600]  поэтому NP вложена в PP.
[38:11.600 --> 38:14.600]  Ну что, согласны?
[38:14.600 --> 38:17.600]  Вот.
[38:17.600 --> 38:20.600]  То есть, мне говорят, такие пороговые,
[38:20.600 --> 38:23.600]  значит, пороговые классы, да,
[38:23.600 --> 38:26.600]  и если мы
[38:26.600 --> 38:29.600]  где-то научились порог делать,
[38:29.640 --> 38:32.640]  то можно его и где-то еще провести.
[38:32.640 --> 38:35.640]  Но это не значит, что можно обратно изменить,
[38:35.640 --> 38:38.640]  потому что у нас все-таки
[38:38.640 --> 38:41.640]  все-таки в NP у нас с одной стороны нуль,
[38:41.640 --> 38:44.640]  поэтому нельзя так просто взять и обратно изменить.
[38:44.640 --> 38:47.640]  Но в любом другом месте,
[38:47.640 --> 38:50.640]  в любой другой константе границу точно
[38:50.640 --> 38:53.640]  можно провести, будет то же самое.
[38:53.640 --> 38:56.640]  Ну и действительно можно
[38:56.640 --> 38:58.640]  сделать симметричное определение,
[38:58.640 --> 39:01.640]  симметричное определение PP,
[39:01.640 --> 39:04.640]  это когда будет строго больше одной из второй
[39:04.640 --> 39:07.640]  или строго меньше одной из второй,
[39:07.640 --> 39:10.640]  а ровно одной второй нигде не будет.
[39:10.640 --> 39:13.640]  Ну давайте плановой картиной я расскажу,
[39:13.640 --> 39:16.640]  как это делается.
[39:16.640 --> 39:19.640]  Ну, идея точно такая же, да,
[39:19.640 --> 39:22.640]  идея как-то так сдвинуть пороги,
[39:22.640 --> 39:25.640]  чтобы оно вот в одну-вторую точно не попало,
[39:25.640 --> 39:28.640]  чтобы если было меньше одной-второй,
[39:28.640 --> 39:31.640]  осталось меньше, а если было хотя бы
[39:31.640 --> 39:34.640]  одной-второй, то это станет строго больше.
[39:34.640 --> 39:37.640]  Так, ну хорошо,
[39:37.640 --> 39:40.640]  значит теперь давайте
[39:40.640 --> 39:43.640]  тоже через количество я запишу.
[39:43.640 --> 39:46.640]  Значит, количество таких y,
[39:46.640 --> 39:49.640]  то v от x и y равно единице,
[39:49.640 --> 39:52.640]  то v от x и y равно единице,
[39:52.640 --> 39:55.640]  v от x и y равно единице,
[39:55.640 --> 39:58.640]  значит, количество будет больше либо равно
[39:58.640 --> 40:01.640]  чем 2 в степени
[40:01.640 --> 40:04.640]  m-1, да, значит,
[40:04.640 --> 40:07.640]  где m это длина y
[40:07.640 --> 40:10.640]  и вот это вот всё
[40:10.640 --> 40:13.640]  при х лежащем ва.
[40:13.640 --> 40:16.640]  И соответственно, то же самое количество
[40:16.640 --> 40:19.640]  будет меньше строго, чем 2 в степени
[40:19.640 --> 40:22.640]  в степени m-1, если
[40:22.640 --> 40:25.640]  не лежит ва.
[40:25.640 --> 40:28.640]  Так, ну и теперь можно
[40:28.640 --> 40:31.640]  построить новую
[40:31.640 --> 40:34.640]  функцию,
[40:34.640 --> 40:37.640]  там w,
[40:37.640 --> 40:40.640]  вот их.
[40:43.640 --> 40:46.640]  Так,
[40:47.640 --> 40:50.640]  значит, и мы это сделаем
[40:53.640 --> 40:56.640]  значит, таким образом.
[41:01.640 --> 41:04.640]  Значит, ну, например, мы сделаем так, значит,
[41:04.640 --> 41:07.640]  если все нули,
[41:07.640 --> 41:10.640]  то мы выдадим единицу,
[41:10.640 --> 41:13.640]  значит, если тут 0, 0,
[41:13.640 --> 41:16.640]  а потом какой-то z не равно 0,
[41:16.640 --> 41:19.640]  то это будет 0, да,
[41:19.640 --> 41:22.640]  если z не равно 0,
[41:22.640 --> 41:25.640]  w от
[41:29.640 --> 41:32.640]  ну, в смысле, не из всех нулей.
[41:37.640 --> 41:40.640]  Значит, дальше, например, w от
[41:40.640 --> 41:43.640]  х, не, например, 1, 1 z,
[41:43.640 --> 41:46.640]  это будет единиц, уже для всех z,
[41:46.640 --> 41:49.640]  не только для не нулевых.
[41:49.640 --> 41:52.640]  Ну, а дальше, значит, w от
[41:52.640 --> 41:55.640]  х, скажем, 0, 1 у,
[41:55.640 --> 41:58.640]  это будет w от
[41:58.640 --> 42:01.640]  х на 1, 0 у,
[42:02.640 --> 42:05.640]  а,
[42:13.640 --> 42:16.640]  значит, это будет
[42:16.640 --> 42:19.640]  равно w от х у.
[42:19.640 --> 42:22.640]  Так, значит,
[42:22.640 --> 42:25.640]  почему это сработает? Вроде должно сработать,
[42:25.640 --> 42:28.640]  давайте проверим.
[42:28.640 --> 42:31.640]  Значит, ну, во-первых, у двое или количество
[42:31.640 --> 42:34.640]  вот здесь вот, значит,
[42:34.640 --> 42:37.640]  если х между 2.
[42:37.640 --> 42:40.640]  Значит, вот теперь
[42:40.640 --> 42:43.640]  у нас будет
[42:43.640 --> 42:46.640]  1, 0,
[42:46.640 --> 42:49.640]  значит, вот теперь
[42:49.640 --> 42:52.640]  количество
[42:52.640 --> 42:55.640]  количества таких r
[42:55.640 --> 42:58.640]  w от
[42:58.640 --> 43:01.640]  х равно единице,
[43:01.640 --> 43:04.640]  это будет следующее, значит,
[43:04.640 --> 43:07.640]  это будет 2.
[43:07.640 --> 43:10.640]  Так, ай, давайте это как-нибудь обозначим,
[43:10.640 --> 43:13.640]  вот, то число, которое было, нам кое-нибудь k.
[43:14.640 --> 43:17.640]  Да, вот это вот,
[43:17.640 --> 43:20.640]  k. Значит, оно будет
[43:20.640 --> 43:23.640]  а, оно будет, вот эта форма будет всегда
[43:23.640 --> 43:26.640]  верна, значит, это будет 2k,
[43:26.640 --> 43:29.640]  2k плюс
[43:29.640 --> 43:32.640]  2 в степени m
[43:32.640 --> 43:35.640]  плюс 1.
[43:35.640 --> 43:38.640]  Где m старая? Значит, m старая, ну,
[43:38.640 --> 43:41.640]  сперва у меня длина на 2 бита больше.
[43:41.640 --> 43:44.640]  Так, значит, это всегда верно,
[43:44.640 --> 43:47.640]  и это будет больше либо равно,
[43:47.640 --> 43:50.640]  значит, больше либо равно,
[43:50.640 --> 43:53.640]  чем 2 на 2 в степени m минус 1
[43:53.640 --> 43:56.640]  плюс 2 в степени m плюс 1.
[43:56.640 --> 43:59.640]  То есть, это будет
[43:59.640 --> 44:02.640]  2 в степени m плюс 1
[44:02.640 --> 44:05.640]  плюс 1,
[44:05.640 --> 44:08.640]  но у нас длина теперь m плюс 2,
[44:08.640 --> 44:11.640]  то есть, это как раз будет больше,
[44:11.640 --> 44:14.640]  больше, чем 2 в степени
[44:14.640 --> 44:17.640]  m плюс 2 минус 1.
[44:17.640 --> 44:20.640]  Да, теперь у меня вместо m
[44:20.640 --> 44:23.640]  плюс 2, но вместо больше либо равно стало больше.
[44:23.640 --> 44:26.640]  Да, поэтому мы от 1 и 2
[44:26.640 --> 44:29.640]  отодвинулись в плюс.
[44:29.640 --> 44:32.640]  Вот, ну, а если х не лежит 2,
[44:32.640 --> 44:35.640]  так, дайте я тут завершу,
[44:36.640 --> 44:39.640]  не лежит 2, то тогда то же самое,
[44:39.640 --> 44:42.640]  значит, 2k плюс 2 в степени m
[44:42.640 --> 44:45.640]  плюс 1.
[44:45.640 --> 44:48.640]  Так, а теперь,
[44:48.640 --> 44:52.640]  смотрите, раз это меньше, чем 2 в степени m минус 1,
[44:52.640 --> 44:55.640]  то оно получается меньше либо равно,
[44:55.640 --> 44:58.640]  чем 2 в степени m минус 1 минус 1.
[44:58.640 --> 45:01.640]  Потому что это же все целые числа,
[45:01.640 --> 45:04.640]  мы, наверное, перешли к числам в целом,
[45:04.640 --> 45:07.640]  то же самое минус 1.
[45:07.640 --> 45:10.640]  Так, и это у меня будет меньше либо равно,
[45:10.640 --> 45:13.640]  чем 2 умножить на 2 в степени m минус 1
[45:13.640 --> 45:16.640]  минус 1
[45:16.640 --> 45:19.640]  плюс 2 в степени m плюс 1.
[45:19.640 --> 45:22.640]  Вот, и это будет равняться
[45:22.640 --> 45:25.640]  2 в степени
[45:25.640 --> 45:28.640]  m плюс 1 минус 1, да,
[45:28.640 --> 45:31.640]  потому что минус 2 вот здесь, это плюс 1.
[45:31.640 --> 45:34.640]  Ну вот, значит, это получается меньше,
[45:34.640 --> 45:37.640]  чем 2 в степени m плюс 2 минус 1.
[45:37.640 --> 45:40.640]  А, все.
[45:40.640 --> 45:43.640]  Значит, меньше, чем вот столько.
[45:43.640 --> 45:46.640]  Ну вот, получается, что там было больше,
[45:46.640 --> 45:49.640]  а тут будет меньше.
[45:49.640 --> 45:52.640]  Значит, первая варианта получается, что либо
[45:52.640 --> 45:55.640]  трога больше одной в трое, либо трога меньше одной в трое,
[45:55.640 --> 45:58.640]  и там уже можно переходить к дополнению,
[45:59.640 --> 46:02.640]  так, ничего.
[46:02.640 --> 46:05.640]  Понятно?
[46:08.640 --> 46:11.640]  Есть какие-нибудь вопросы?
[46:16.640 --> 46:19.640]  Так.
[46:28.640 --> 46:31.640]  Нет, оно симметрия, что если вы замените
[46:31.640 --> 46:34.640]  0 на 1 и 1 на 0,
[46:34.640 --> 46:37.640]  то тогда, ну, то есть, если вы для
[46:37.640 --> 46:40.640]  дополнения используете,
[46:40.640 --> 46:43.640]  то вы можете просто заменить
[46:43.640 --> 46:46.640]  0 на 1 и 1 на 0, эта варианта сменяется местами.
[46:59.640 --> 47:02.640]  Ну да, но в исходном определении
[47:02.640 --> 47:05.640]  там была, да,
[47:05.640 --> 47:08.640]  одна была меньше, чем одна в второй,
[47:08.640 --> 47:11.640]  а другая меньше одной в второй.
[47:11.640 --> 47:14.640]  Если поменяться, то они будут наоборот.
[47:14.640 --> 47:17.640]  А в новом определении обе ошибки меньше одной в второй,
[47:17.640 --> 47:20.640]  если их менять местами, они тоже будут обе меньше одной в второй.
[47:23.640 --> 47:26.640]  Ну да, если менять местами ответы машины
[47:26.640 --> 47:29.640]  и считать, что у нас теперь это
[47:29.640 --> 47:32.640]  машина для дополнения, а не для исходного множества.
[47:38.640 --> 47:41.640]  Нет, исходная не симметрична, потому что она была
[47:41.640 --> 47:44.640]  больше либо равной, и строго меньше.
[47:46.640 --> 47:49.640]  Не, смотрите, вот дело в том, что ошибка,
[47:49.640 --> 47:52.640]  это не то, что я здесь пишу, да, ошибка это,
[47:52.640 --> 47:55.640]  вот внизу эта ошибка, а вверху это один
[47:56.640 --> 47:59.640]  вот, соответственно, хотя тут они
[47:59.640 --> 48:02.640]  больше одной в второй, но ошибка тоже будет меньше одной в второй.
[48:12.640 --> 48:15.640]  Не, не, не, сейчас, смотрите, вот в верхней ситуации
[48:15.640 --> 48:18.640]  у меня то, что равно единице, это правильный ответ.
[48:18.640 --> 48:21.640]  Поэтому если у меня правильность больше одной в второй,
[48:21.640 --> 48:24.640]  то ошибка становится меньше одной в второй.
[48:24.640 --> 48:27.640]  Это в исходном плене меньше либо равно,
[48:27.640 --> 48:30.640]  а я как раз про новое говорю.
[48:32.640 --> 48:35.640]  Вот, а здесь наоборот, здесь равно единице, это неверный ответ,
[48:35.640 --> 48:38.640]  поэтому то, что здесь написано, это и есть ошибка.
[48:38.640 --> 48:41.640]  Вот, и поэтому тут ошибки одинаковые выглядят,
[48:41.640 --> 48:44.640]  поэтому их можно менять местами.
[48:44.640 --> 48:47.640]  А раньше было больше либо равно, поэтому их нельзя было менять местами,
[48:47.640 --> 48:50.640]  да, значит, получилось наоборот.
[48:50.640 --> 48:53.640]  Вот.
[48:54.640 --> 48:57.640]  Так, ну все, значит, в этом, в этой диаграмме мы все доказали,
[48:57.640 --> 49:00.640]  так что я это стираю.
[49:01.640 --> 49:04.640]  Вот, и поговорю про другие вещи.
[49:08.640 --> 49:11.640]  Такие более глобальные, что ли.
[49:15.640 --> 49:18.640]  Такие более глобальные, что ли.
[49:18.640 --> 49:21.640]  Такие более глобальные, что ли.
[49:21.640 --> 49:24.640]  Такие более глобальные, что ли.
[49:24.640 --> 49:27.640]  Такие более глобальные, что ли.
[49:27.640 --> 49:30.640]  Так, значит, вот мы подробно обсудили амплификацию
[49:30.640 --> 49:33.640]  для односторонней ошибки.
[49:33.640 --> 49:36.640]  Для двухсторонней она тоже есть.
[49:38.640 --> 49:41.640]  Так, ну вот.
[49:41.640 --> 49:44.640]  Так, ну вот.
[49:44.640 --> 49:47.640]  Так, ну вот.
[49:47.640 --> 49:50.640]  Так, ну вот.
[49:50.640 --> 49:53.640]  Так, ну вот.
[49:53.640 --> 49:56.640]  Так.
[49:57.640 --> 50:00.640]  Давайте ее обсудим.
[50:03.640 --> 50:06.640]  Амплификация
[50:11.640 --> 50:14.640]  для двухсторонней ошибки.
[50:21.640 --> 50:24.640]  Значит, смотрите,
[50:24.640 --> 50:27.640]  можно рассмотреть в некоторых общих случаях
[50:27.640 --> 50:30.640]  ДПП, сынок, семиальфа и бета.
[50:33.640 --> 50:36.640]  Здесь, значит, если х лежит в А,
[50:36.640 --> 50:39.640]  то тогда, значит, вероятность того,
[50:39.640 --> 50:42.640]  что В от хр
[50:42.640 --> 50:45.640]  равно единице будет больше бета,
[50:45.640 --> 50:48.640]  значит, если х не лежит в А,
[50:48.640 --> 50:51.640]  то тогда вероятность того, что В от хр
[50:51.640 --> 50:54.640]  равно единице будет меньше А.
[50:57.640 --> 51:00.640]  Вот. Вот такой вот класс можно
[51:00.640 --> 51:03.640]  рассмотреть.
[51:03.640 --> 51:06.640]  Ну и, в принципе, все, что мы изучали,
[51:06.640 --> 51:09.640]  ну, кроме излета ПП,
[51:09.640 --> 51:12.640]  вот под это подходит.
[51:12.640 --> 51:15.640]  Ну, там,
[51:15.640 --> 51:18.640]  ну, то есть ПП, значит,
[51:18.640 --> 51:21.640]  с учетом симметричного определения,
[51:21.640 --> 51:24.640]  ПП получается, когда а и беты равны по 1 и 2,
[51:24.640 --> 51:27.640]  когда там кто-то равен нулю,
[51:27.640 --> 51:30.640]  получается односторонние классы и так далее.
[51:30.640 --> 51:33.640]  Вот. Но вот на самом деле
[51:33.640 --> 51:36.640]  общий тирем тут такая.
[51:39.640 --> 51:42.640]  Теорема. Так, значит, если
[51:44.640 --> 51:47.640]  1 делить
[51:47.640 --> 51:50.640]  на 2 в степени полином,
[51:52.640 --> 51:55.640]  значит, меньше а,
[51:58.640 --> 52:01.640]  так, значит, меньше бета,
[52:01.640 --> 52:04.640]  меньше, чем 1, минус 1 делить
[52:04.640 --> 52:07.640]  на 2 в степени полином,
[52:07.640 --> 52:10.640]  и при этом бета, минус а,
[52:10.640 --> 52:13.640]  больше, чем 1 делить на просто полином,
[52:13.640 --> 52:16.640]  значит, то
[52:16.640 --> 52:19.640]  вот это вот БПП
[52:19.640 --> 52:22.640]  а и бета равняются БПП.
[52:22.640 --> 52:25.640]  Вот. Ну, это вот такая
[52:25.640 --> 52:28.640]  самая общая тирем, которую здесь можно
[52:28.640 --> 52:31.640]  спормулировать.
[52:31.640 --> 52:34.640]  В общем, уж как минимум, если а и бета
[52:34.640 --> 52:37.640]  это две константы, отличные друг от друга и от нуля,
[52:37.640 --> 52:40.640]  то тогда это все будет то же самое.
[52:40.640 --> 52:43.640]  Это вот такая тирема у независимости от порогов.
[52:43.640 --> 52:46.640]  Ну, а вот то, что это прям функция,
[52:46.640 --> 52:49.640]  изменяющаяся, это максимальная общность,
[52:49.640 --> 52:52.640]  которой это можно доказать.
[52:52.640 --> 52:55.640]  Ну, в принципе, это не очень важно.
[52:55.640 --> 52:58.640]  Важно.
[52:58.640 --> 53:01.640]  Вообще, наверное, на самом деле важно,
[53:01.640 --> 53:04.640]  что это стремится к единице
[53:04.640 --> 53:07.640]  и стремится к нулю. Это сейчас будет важно.
[53:07.640 --> 53:10.640]  То есть, что именно вот так экспоненциально стремится.
[53:10.640 --> 53:13.640]  То есть, понимать тирем можно так,
[53:13.640 --> 53:16.640]  что можно считать,
[53:16.640 --> 53:19.640]  что если ошибка была отделена от одной и второй,
[53:19.640 --> 53:22.640]  то можно считать, что она вообще экспоненциально маленькая.
[53:22.640 --> 53:25.640]  И что нам важно,
[53:25.640 --> 53:28.640]  значит, важно, что она даже может быть меньше,
[53:28.640 --> 53:31.640]  чем один делить на число
[53:31.640 --> 53:34.640]  вообще возможных х.
[53:34.640 --> 53:37.640]  То есть, число возможных х это какая-то фиксированная.
[53:37.640 --> 53:40.640]  Ну, это, в общем, два в степени N,
[53:40.640 --> 53:43.640]  а тут два в степени N,
[53:43.640 --> 53:46.640]  которые может быть больше, чем N.
[53:46.640 --> 53:49.640]  Поэтому можно считать,
[53:49.640 --> 53:52.640]  что ошибка прям совсем маленькая.
[53:56.640 --> 53:59.640]  Так, значит,
[53:59.640 --> 54:02.640]  трогу я доказывать не буду.
[54:02.640 --> 54:05.640]  Но идея, конечно, та же самая,
[54:05.640 --> 54:08.640]  что много раз запустим.
[54:08.640 --> 54:11.640]  Но смотрите, вот здесь у меня была хорошая функция
[54:11.640 --> 54:14.640]  дезъюнция результатов,
[54:14.640 --> 54:17.640]  что если там была хотя бы одна единица,
[54:17.640 --> 54:20.640]  то это единица.
[54:20.640 --> 54:23.640]  И тут я пользовался, что если на самом деле ноль, то единица быть не может.
[54:23.640 --> 54:26.640]  Соответственно, такую простую функцию
[54:26.640 --> 54:29.640]  с двусторонней ошибки я не могу взять,
[54:29.640 --> 54:32.640]  то у меня могут быть и нули, и единицы,
[54:32.640 --> 54:35.640]  я не могу брать дезъюнцию.
[54:35.640 --> 54:38.640]  Но что вместо этого можно делать?
[54:38.640 --> 54:41.640]  Ну, вот есть такой закон больших чисел
[54:41.640 --> 54:44.640]  и связанный с ним центрально пределенный теорема.
[54:44.640 --> 54:47.640]  Мы это вроде немножко обсуждали в прошлый раз.
[54:47.640 --> 54:50.640]  И так, если по-простому,
[54:50.640 --> 54:53.640]  то о чем эти теоремы говорят?
[54:53.640 --> 54:56.640]  Закон больших чисел говорит, что если вы проводите очень много испытаний,
[54:56.640 --> 54:59.640]  то та доля успехов, которые у вас возникает
[54:59.640 --> 55:02.640]  в испытаниях, она приближается
[55:02.640 --> 55:05.640]  к настоящей вероятности.
[55:05.640 --> 55:08.640]  То есть как бы вероятность это предел частоты.
[55:08.640 --> 55:11.640]  Вот про это более-менее закон больших чисел говорит.
[55:11.640 --> 55:14.640]  Что если у вас реально много испытаний,
[55:14.640 --> 55:17.640]  почему он больших чисел,
[55:17.640 --> 55:20.640]  если у вас прям много испытаний,
[55:20.640 --> 55:23.640]  то частота будет примерно такая вероятность.
[55:23.640 --> 55:26.640]  Это говорит, насколько быстро приближается
[55:26.640 --> 55:29.640]  к частоте.
[55:29.640 --> 55:32.640]  То есть почти наоборот,
[55:32.640 --> 55:35.640]  насколько быстрая частота приближается к вероятности.
[55:35.640 --> 55:38.640]  Ну и, в общем, если отбросить конкретные формулы,
[55:38.640 --> 55:41.640]  то что там и на колокол получается и так далее,
[55:41.640 --> 55:44.640]  то суть такая,
[55:44.640 --> 55:47.640]  что если вы проводите N испытаний,
[55:47.640 --> 55:50.640]  то у вас отклонение частоты от вероятности в среднем
[55:50.640 --> 55:53.640]  будет не из N.
[55:56.640 --> 55:59.640]  Да, сейчас я прям запишу,
[55:59.640 --> 56:02.640]  что такое идея центрально-предельной теоремы.
[56:02.640 --> 56:05.640]  Ну там точно формулировка,
[56:05.640 --> 56:08.640]  что там распределение вот этого среднего
[56:08.640 --> 56:11.640]  стремится к нормальному, там с какой-то формулой.
[56:11.640 --> 56:14.640]  Вот это у вас будет на сервере.
[56:15.640 --> 56:18.640]  А идея следующая, значит, что
[56:18.640 --> 56:21.640]  если провести N испытаний,
[56:24.640 --> 56:27.640]  если провести N испытаний,
[56:29.640 --> 56:32.640]  то частота
[56:37.640 --> 56:40.640]  попадет в там
[56:40.640 --> 56:43.640]  один злет на корень из N
[56:43.640 --> 56:46.640]  окрестность вероятности.
[56:53.640 --> 56:56.640]  Ну опять же, тут может быть не один на корень из N,
[56:56.640 --> 56:59.640]  а там три на корень из N или шесть на корень из N,
[56:59.640 --> 57:02.640]  в общем, смотря какой, так сказать,
[57:02.640 --> 57:05.640]  доверительный интервал вы хотите получить.
[57:05.640 --> 57:08.640]  И как это там еще, P значение это называется.
[57:08.640 --> 57:11.640]  В общем, идея следующая.
[57:11.640 --> 57:14.640]  Ну а тогда, смотрите,
[57:14.640 --> 57:17.640]  вы можете проводить,
[57:17.640 --> 57:20.640]  это вот зачем здесь нужно разницу
[57:20.640 --> 57:23.640]  в один злет на полином.
[57:25.640 --> 57:28.640]  Значит, вы можете проводить свои испытания
[57:28.640 --> 57:31.640]  полинально-чепло-раз.
[57:31.640 --> 57:34.640]  То есть вот это вот N
[57:34.640 --> 57:37.640]  может быть даже полиновым от того N,
[57:37.640 --> 57:40.640]  который был в длину Х.
[57:40.640 --> 57:43.640]  Дальше того испытания вы можете провести.
[57:43.640 --> 57:46.640]  И тогда вы можете
[57:46.640 --> 57:49.640]  найти частоту, то есть сколько раз у вас
[57:49.640 --> 57:52.640]  возникла единица.
[57:52.640 --> 57:55.640]  И вот эта частота, она будет вот на таком
[57:55.640 --> 57:58.640]  расстоянии от
[57:58.640 --> 58:01.640]  настоящей вероятности.
[58:01.640 --> 58:04.640]  Но дальше можно посмотреть, вот эта частота,
[58:04.640 --> 58:07.640]  она попала в районе бета
[58:07.640 --> 58:10.640]  или в районе альфа.
[58:10.640 --> 58:13.640]  И тут реально можно будет отличить.
[58:13.640 --> 58:16.640]  Потому что, смотрите,
[58:16.640 --> 58:19.640]  вот есть альфа,
[58:19.640 --> 58:22.640]  вот есть бета.
[58:22.640 --> 58:25.640]  Значит, вот есть
[58:25.640 --> 58:28.640]  средние между ними.
[58:28.640 --> 58:31.640]  Значит, альфа плюс бета пополам.
[58:31.640 --> 58:34.640]  Так, надо бы мне ниже очень нарисовать.
[58:34.640 --> 58:37.640]  График ниже нарисовано.
[58:37.640 --> 58:40.640]  И, соответственно, если у вас будет
[58:40.640 --> 58:43.640]  настоящая вероятность альфа или меньше,
[58:43.640 --> 58:46.640]  то у вас будет
[58:46.640 --> 58:49.640]  распределение вот какой-то вот такой вот колокол,
[58:49.640 --> 58:52.640]  где ширина будет порядка 1.9
[58:52.640 --> 58:55.640]  на корень N.
[58:55.640 --> 58:58.640]  Если настоящая бета или больше,
[58:58.640 --> 59:01.640]  то у вас колокол будет где-то вот здесь.
[59:02.640 --> 59:05.640]  Так, слушайте, тут у меня уже,
[59:05.640 --> 59:08.640]  дайте, это N большое.
[59:08.640 --> 59:11.640]  И тут 1.9 на корень N большого.
[59:11.640 --> 59:14.640]  Значит, а вот это вот у вас 1.9 на полином.
[59:14.640 --> 59:17.640]  Дайте, я напишу 1.9 на P от N.
[59:17.640 --> 59:20.640]  Вот, ну отсюда видно,
[59:20.640 --> 59:23.640]  значит, отсюда видно, что нужно N
[59:23.640 --> 59:26.640]  взять порядка, вот это вот P от N
[59:26.640 --> 59:29.640]  в квадрате.
[59:29.640 --> 59:32.640]  Значит, если N порядка P от N в квадрате,
[59:32.640 --> 59:35.640]  то тогда будет сосредоточена,
[59:35.640 --> 59:38.640]  вот это вот будет сосредоточено
[59:38.640 --> 59:41.640]  почти наверняка больше, чем середина
[59:41.640 --> 59:44.640]  отрезка, а вот это вот почти наверняка
[59:44.640 --> 59:47.640]  меньше, чем середина отрезка.
[59:47.640 --> 59:50.640]  И, соответственно, идея такая, что вы можете запустить
[59:50.640 --> 59:53.640]  такое число раз ваш алгоритм
[59:53.640 --> 59:56.640]  со свежими включениями битами
[59:56.640 --> 59:59.640]  и сравнить вот со средиум-архиметическим.
[01:00:01.640 --> 01:00:04.640]  Получается алгоритм, значит,
[01:00:04.640 --> 01:00:07.640]  запустить,
[01:00:07.640 --> 01:00:10.640]  запустить V от XR
[01:00:12.640 --> 01:00:15.640]  для N разных
[01:00:17.640 --> 01:00:20.640]  независимых R
[01:00:22.640 --> 01:00:25.640]  и сравнить
[01:00:26.640 --> 01:00:29.640]  сравнить, соответственно,
[01:00:29.640 --> 01:00:32.640]  с вот A и B половины.
[01:00:38.640 --> 01:00:41.640]  Вот, ну, на самом деле тут все-таки идеи,
[01:00:48.640 --> 01:00:51.640]  идеи тут немножко недостаточно,
[01:00:51.640 --> 01:00:54.640]  нужна и инсомация ПТ, а точнее даже
[01:00:54.640 --> 01:00:57.640]  как бы ее конечные варианты некоторые,
[01:00:57.640 --> 01:01:00.640]  потому что все-таки П – это предельная теорема,
[01:01:00.640 --> 01:01:03.640]  а нужно, что если мы вот столько испытаний сделаем,
[01:01:03.640 --> 01:01:06.640]  то у нас уже будет достаточно.
[01:01:06.640 --> 01:01:09.640]  Там есть разные, это называется неравенство больших уклонений,
[01:01:09.640 --> 01:01:12.640]  там есть неравенство Чернова, еще там есть хевдинга,
[01:01:12.640 --> 01:01:15.640]  в общем, разные есть варианты.
[01:01:20.640 --> 01:01:23.640]  Но суть такая, что у нас
[01:01:24.640 --> 01:01:27.640]  если достаточно много раз провести испытания,
[01:01:27.640 --> 01:01:30.640]  то вероятность того, что мы окажемся
[01:01:30.640 --> 01:01:33.640]  с другой стороны, вот с середины,
[01:01:33.640 --> 01:01:36.640]  будет экспоненциально убывать.
[01:01:47.640 --> 01:01:50.640]  Вот.
[01:01:51.640 --> 01:01:54.640]  Ну что, есть ли какие-нибудь вопросы по этому рассуждению?
[01:01:54.640 --> 01:01:57.640]  Да, надо понимать, что это все-таки не полное доказательство,
[01:01:57.640 --> 01:02:00.640]  для полного доказательства нужны некоторые точные неравенства,
[01:02:00.640 --> 01:02:03.640]  но в них я не хотел бы углубляться,
[01:02:03.640 --> 01:02:06.640]  а на идейном уровне этого всего достаточно.
[01:02:12.640 --> 01:02:15.640]  Вот, значит, в чем здесь
[01:02:15.640 --> 01:02:18.640]  выгода, значит, выгода
[01:02:18.640 --> 01:02:21.640]  от вот такого уменьшения ошибки,
[01:02:21.640 --> 01:02:24.640]  выгода выступает тогда, как раз когда
[01:02:24.640 --> 01:02:27.640]  вероятность ошибок получается меньше, чем
[01:02:27.640 --> 01:02:30.640]  один делительное число,
[01:02:30.640 --> 01:02:33.640]  число иксов.
[01:02:33.640 --> 01:02:36.640]  Можно сделать
[01:02:40.640 --> 01:02:43.640]  можно сделать вероятность ошибки
[01:02:44.640 --> 01:02:47.640]  меньше
[01:02:50.640 --> 01:02:53.640]  один делитель на два в титане N.
[01:02:57.640 --> 01:03:00.640]  А что это означает?
[01:03:00.640 --> 01:03:03.640]  Ну, смотрите, вот у вас есть большое пространство
[01:03:03.640 --> 01:03:06.640]  всех R.
[01:03:06.640 --> 01:03:09.640]  И дальше вот есть в нем, да,
[01:03:09.640 --> 01:03:12.640]  это, конечно, можно сделать, только если длина R
[01:03:12.640 --> 01:03:15.640]  больше, чем N.
[01:03:15.640 --> 01:03:18.640]  Чтобы это было больше нуля,
[01:03:18.640 --> 01:03:21.640]  ну, чтобы как бы мелкость была
[01:03:21.640 --> 01:03:24.640]  еще сильнее.
[01:03:27.640 --> 01:03:30.640]  Конечно, тут нужно,
[01:03:30.640 --> 01:03:33.640]  чтобы длина R была больше N.
[01:03:34.640 --> 01:03:37.640]  Но тут
[01:03:37.640 --> 01:03:40.640]  никто не запрещает,
[01:03:40.640 --> 01:03:43.640]  может, длина R больше N.
[01:03:44.640 --> 01:03:47.640]  Вот, и та, смотрите, что получается.
[01:03:47.640 --> 01:03:50.640]  Вот у нас есть большое пространство всех возможных R.
[01:03:50.640 --> 01:03:53.640]  В нем есть маленький участок
[01:03:53.640 --> 01:03:56.640]  всех R, которые не подходят для первого икса.
[01:03:56.640 --> 01:03:59.640]  Есть какой-то другой маленький участок, который не подходит
[01:03:59.640 --> 01:04:02.640]  для второго икса.
[01:04:02.640 --> 01:04:05.640]  Может быть, какой-то R туда и туда не подходит,
[01:04:05.640 --> 01:04:08.640]  а может быть, это разные участки. Есть какой-то участок,
[01:04:08.640 --> 01:04:11.640]  но даже все вместе,
[01:04:11.640 --> 01:04:14.640]  если они все разные и не пересекаются
[01:04:14.640 --> 01:04:17.640]  для разных иксов, все равно они не покроют
[01:04:17.640 --> 01:04:20.640]  пространство
[01:04:20.640 --> 01:04:23.640]  всех возможных R.
[01:04:23.640 --> 01:04:26.640]  Потому что как бы каждый икс высекает меньше,
[01:04:26.640 --> 01:04:29.640]  чем 1 лидия на 2 степени N долю,
[01:04:29.640 --> 01:04:32.640]  ну, высекается на среднем и не подходит,
[01:04:32.640 --> 01:04:35.640]  дают неправильный ответ для этого икса.
[01:04:35.640 --> 01:04:38.640]  Поэтому
[01:04:38.640 --> 01:04:41.640]  всех иксов не хватит, чтобы все R как бы испортить
[01:04:41.640 --> 01:04:44.640]  и останется R хорошее.
[01:04:44.640 --> 01:04:47.640]  То есть получается
[01:04:47.640 --> 01:04:50.640]  так, что если мы такое сделали,
[01:04:50.640 --> 01:04:53.640]  то есть тогда
[01:04:53.640 --> 01:04:56.640]  получается существует R
[01:04:56.640 --> 01:04:59.640]  такое, что для любого икс
[01:04:59.640 --> 01:05:02.640]  V от XR
[01:05:03.640 --> 01:05:06.640]  V от XR
[01:05:06.640 --> 01:05:09.640]  равно единице,
[01:05:09.640 --> 01:05:12.640]  тогда и только тогда, когда
[01:05:12.640 --> 01:05:15.640]  икс длинжита.
[01:05:15.640 --> 01:05:18.640]  Ну, икс не совсем для любого икса,
[01:05:18.640 --> 01:05:21.640]  а для любого икса, у которого длина равна N.
[01:05:25.640 --> 01:05:28.640]  Значит, для любого икса, у которого длина равна N,
[01:05:28.640 --> 01:05:31.640]  вот эта R подходит.
[01:05:32.640 --> 01:05:35.640]  Так, понятен вывод?
[01:05:35.640 --> 01:05:38.640]  Ну, вот из этого вывода
[01:05:38.640 --> 01:05:41.640]  утекает такая чарема, называется чарема A долмана.
[01:05:50.640 --> 01:05:53.640]  Чарема A долмана заключается в том, что BPP
[01:05:53.640 --> 01:05:56.640]  вложено в P слэш поле.
[01:06:02.640 --> 01:06:05.640]  И идея такая, что вот эта R,
[01:06:05.640 --> 01:06:08.640]  которая существует,
[01:06:08.640 --> 01:06:11.640]  мы как бы просто запаяем
[01:06:11.640 --> 01:06:14.640]  схему и дальше будем
[01:06:14.640 --> 01:06:17.640]  ее вычислять.
[01:06:17.640 --> 01:06:20.640]  То есть идея доказательства,
[01:06:20.640 --> 01:06:23.640]  что превратим
[01:06:23.640 --> 01:06:26.640]  превратим VLTXR в схему.
[01:06:29.640 --> 01:06:32.640]  А мы уже обсуждали, что это можно делать,
[01:06:32.640 --> 01:06:35.640]  когда мы догадываем, что P вложено в P слэш поле.
[01:06:38.640 --> 01:06:41.640]  И как бы запаяем туда
[01:06:44.640 --> 01:06:47.640]  и запаяем
[01:06:47.640 --> 01:06:50.640]  и запаяем
[01:06:50.640 --> 01:06:53.640]  запаяем
[01:06:54.640 --> 01:06:57.640]  в нее
[01:06:59.640 --> 01:07:02.640]  универсальная R.
[01:07:02.640 --> 01:07:05.640]  Универсальная, то есть как раз вот эта,
[01:07:05.640 --> 01:07:08.640]  которая существует.
[01:07:11.640 --> 01:07:14.640]  Вот. Получится тем,
[01:07:14.640 --> 01:07:17.640]  полинаминального размера.
[01:07:17.640 --> 01:07:20.640]  Но вот если вдруг это R еще можно
[01:07:20.640 --> 01:07:23.640]  вычислять за полинаминальное время,
[01:07:23.640 --> 01:07:26.640]  тогда вообще P равно DTP.
[01:07:32.640 --> 01:07:35.640]  Если такое R можно вычислить
[01:07:41.640 --> 01:07:44.640]  за полинаминальное время,
[01:07:47.640 --> 01:07:50.640]  то тогда
[01:07:50.640 --> 01:07:53.640]  P равно BPP.
[01:07:57.640 --> 01:08:00.640]  Вот так. Ну у меня остается три минуты.
[01:08:00.640 --> 01:08:03.640]  Давайте в эти три минуты я немножко позову про статус
[01:08:03.640 --> 01:08:06.640]  вот этой гипотезы вообще.
[01:08:06.640 --> 01:08:09.640]  Равны ли P и BPP?
[01:08:09.640 --> 01:08:12.640]  Так. Но статус такой, смотрите.
[01:08:12.640 --> 01:08:15.640]  Значит, если опять же кратенько,
[01:08:15.640 --> 01:08:18.640]  рархей, если P равно NP,
[01:08:20.640 --> 01:08:23.640]  то тогда P равно и BPP тоже.
[01:08:25.640 --> 01:08:28.640]  Но это не тривиальная теорема, она довольно сложная.
[01:08:28.640 --> 01:08:31.640]  Там нужно сначала изучить такую полинаминальная иерархия,
[01:08:31.640 --> 01:08:34.640]  потом доказать,
[01:08:34.640 --> 01:08:37.640]  что если P равно NP, то вся эта полинаминальная иерархия
[01:08:37.640 --> 01:08:40.640]  равна тоже P.
[01:08:40.640 --> 01:08:43.640]  И еще доказать, что BPP в эту полинаминальную иерархию входит.
[01:08:45.640 --> 01:08:48.640]  Тогда, соответственно, это все слопнется,
[01:08:48.640 --> 01:08:51.640]  и P равняется BPP тоже будет.
[01:08:51.640 --> 01:08:54.640]  Вот. Это первое, что известно.
[01:08:54.640 --> 01:08:57.640]  Второе, что известно, что если
[01:09:00.640 --> 01:09:03.640]  условно говоря,
[01:09:05.640 --> 01:09:08.640]  вот сейчас я совсем неформально пишу,
[01:09:08.640 --> 01:09:11.640]  значит, если NP сильно больше P,
[01:09:15.640 --> 01:09:18.640]  то тогда тоже P равно BPP.
[01:09:18.640 --> 01:09:21.640]  Значит, и вот этого теорема
[01:09:21.640 --> 01:09:24.640]  называется Hardness versus Randomness.
[01:09:27.640 --> 01:09:30.640]  Hardness versus Randomness.
[01:09:30.640 --> 01:09:33.640]  Ну, это все, что известно.
[01:09:33.640 --> 01:09:36.640]  Ну, это все, что известно.
[01:09:36.640 --> 01:09:39.640]  Ну, это все, что известно.
[01:09:39.640 --> 01:09:42.640]  Ну, это все, что известно.
[01:09:42.640 --> 01:09:45.640]  Hardness versus Randomness.
[01:09:53.640 --> 01:09:56.640]  Ну, насколько это там вот есть
[01:09:56.640 --> 01:09:59.640]  разная вариация.
[01:09:59.640 --> 01:10:02.640]  Ну, значит, точная формулировка там кажется,
[01:10:02.640 --> 01:10:05.640]  что в NP есть задачи,
[01:10:05.640 --> 01:10:08.640]  которые не распознаются схемами
[01:10:08.640 --> 01:10:11.640]  субэкспоненциального размера.
[01:10:11.640 --> 01:10:14.640]  То есть не просто там нужны
[01:10:14.640 --> 01:10:17.640]  специальное время, а даже схемы нужны
[01:10:17.640 --> 01:10:20.640]  специального размера,
[01:10:20.640 --> 01:10:23.640]  чтобы распознать NP. Вот это вот
[01:10:23.640 --> 01:10:26.640]  сильно больше. Ну, а суть там такая.
[01:10:26.640 --> 01:10:29.640]  Суть доказательств такая, что если NP
[01:10:29.640 --> 01:10:32.640]  настолько больше, то есть некоторая
[01:10:32.640 --> 01:10:35.640]  сложная функция в NP, а на ее базе
[01:10:35.640 --> 01:10:38.640]  можно построить хороший
[01:10:38.640 --> 01:10:41.640]  китил. А дальше можно в алгоритмы с BPP
[01:10:41.640 --> 01:10:44.640]  вместо настоящего случайного китила
[01:10:44.640 --> 01:10:47.640]  подставить вот эти вот плету случайной
[01:10:47.640 --> 01:10:50.640]  число из генератора. И вот это вот получится
[01:10:50.640 --> 01:10:53.640]  алгоритм с P.
[01:10:53.640 --> 01:10:56.640]  Вот, это называется дарандомизация.
[01:10:56.640 --> 01:10:59.640]  Дарандомизация, когда мы заменяем
[01:10:59.640 --> 01:11:02.640]  вариационные алгоритмы на детерминированные.
[01:11:02.640 --> 01:11:05.640]  Таким образом, для того, чтобы P не равнялась с BPP,
[01:11:05.640 --> 01:11:08.640]  то есть с этими двумя крайними возможностями.
[01:11:08.640 --> 01:11:11.640]  Но пока, исходя из вот этой
[01:11:11.640 --> 01:11:14.640]  второй теории, мы большинство следует верить,
[01:11:14.640 --> 01:11:17.640]  что на самом деле P равно BPP, а то, что мы там
[01:11:17.640 --> 01:11:20.640]  не умеем решать равенство полиномов, но это так
[01:11:20.640 --> 01:11:23.640]  получилось. Там даже есть некоторые объяснения,
[01:11:23.640 --> 01:11:26.640]  почему именно задача сложная, но в этом
[01:11:26.640 --> 01:11:29.640]  сейчас совсем не буду задаваться.
[01:11:29.640 --> 01:11:32.640]  Ну вот,
[01:11:32.640 --> 01:11:35.640]  в общем, вот тут мы довольно близко выходим, так сказать,
[01:11:35.640 --> 01:11:38.640]  к переднему краю.
[01:11:38.640 --> 01:11:41.640]  Хотя это уже почти 30 лет назад сделано,
[01:11:41.640 --> 01:11:44.640]  но очень сильно дальше именно в этом направлении
[01:11:44.640 --> 01:11:47.640]  с тех пор не продвинулись.
[01:11:47.640 --> 01:11:50.640]  Ну, кроме, наверное, той статьи про как раз
[01:11:50.640 --> 01:11:53.640]  равенство полиномов.
[01:11:53.640 --> 01:11:56.640]  Ну, я думаю, на этом всё.
[01:11:56.640 --> 01:11:59.640]  Спасибо за внимание.
[01:12:02.640 --> 01:12:05.640]  Спасибо.
