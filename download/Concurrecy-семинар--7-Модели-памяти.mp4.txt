[00:00.000 --> 00:12.320]  Ну что, начнём? С какого места вопрос? На чем мы остановились в прошлый раз и сколько мне нужно
[00:12.320 --> 00:27.040]  повторить про модели памяти вообще? Давайте решим. Повторить всё нужно. Сложно сказать,
[00:27.040 --> 00:35.600]  значит всё нужно повторить. И так, конечно, лучше какое-то знание в себе сохранять,
[00:35.600 --> 00:44.120]  потому что я однажды перестану повторять и всё, и вы останетесь своими знаниями. Итак, разговор
[00:44.120 --> 00:49.040]  про модели памяти начался с того, что компьютеры ведут себя странно, что в ячейке много разного
[00:49.040 --> 00:55.600]  значения в один и тот же момент времени, что компьютер может записывать в память не в том
[00:55.600 --> 01:01.680]  порядке, в котором вы написали в тексте программы, что процессор может исполнить программу уж явно не в
[01:01.680 --> 01:08.400]  модели чередования. Почему? Потому что в нём есть кэши и он пытается оптимизировать работу с
[01:08.400 --> 01:12.720]  протоколом конвериентности, коммуникацию, которая для этого протокола необходима, чтобы инвалидировать
[01:12.720 --> 01:20.760]  копии в других кэшах и поддерживать инварианты. Так что для человека, который пользуется
[01:20.760 --> 01:27.240]  просто прям компьютером, думает про компьютер, мир выглядит очень сложно. Непонятно,
[01:27.240 --> 01:32.640]  на что можно положиться, какие ордеринги могут происходить или не могут, где там, в процессоре,
[01:32.640 --> 01:39.440]  в компьютере. Всё это очень сложно. Нужна точка опоры. Вот эта точка опоры — это модель памяти.
[01:39.440 --> 01:48.560]  Модель памяти — это часть темантики языка, которая объясняет вам, какие исполнения программы вообще
[01:48.720 --> 01:53.840]  возможны. Ну или вернее, как мы их наблюдаем. То есть, что может в программе увидеть каждое
[01:53.840 --> 01:59.200]  конкретное чтение, а что не может. Или ещё аккуратнее, как гарантировать, что какое-то
[01:59.200 --> 02:04.160]  чтение увидит какую-то запись. То есть, мы положили, там отправили из одной грутины сообщение в
[02:04.160 --> 02:09.680]  другую, то другая грутина достанет сообщение, и тогда она будет уверена, что всё, что произошло
[02:09.680 --> 02:15.840]  до отправки, теперь этой грутине тоже видно. Ну, в общем, какие-то ожидания, которые у разработчика
[02:15.840 --> 02:21.120]  есть, модель памяти должна обеспечивать и объяснять, при каких условиях эти ожидания выполняются,
[02:21.120 --> 02:28.800]  что нужно сделать для этого. И есть разные подходы к тому, чтобы вот на все эти вопросы отвечать.
[02:28.800 --> 02:35.760]  Есть операционный подход, где мы объясняем, как программа исполняется. Правда, мы сложный
[02:35.760 --> 02:41.720]  процессор заменяем на какую-то простую модель, на какую-то простую абстрактную машину, которая,
[02:42.200 --> 02:48.920]  конечно же, устроена гораздо проще, но в частности, для такой абстрактной машины, для процессоров
[02:48.920 --> 02:57.480]  Intel AMD нет никаких общих кэшей, но при этом пользователь наблюдает те же самые исполнения.
[02:57.480 --> 03:03.240]  То есть, он видит те же самые результаты чтений, а это единственный способ как-то об исполнении
[03:03.240 --> 03:10.680]  наблюдать. И операционный модель памяти для x86 выглядит вот так. У нас были ядра, они общались
[03:10.680 --> 03:16.920]  с памятью, но между ядром и памятью, при записи, между ядром camping находился буфер, и
[03:16.920 --> 03:23.320]  все записи подали в него. Все записи подают в память через буфер, только если мы читаем данный,
[03:23.320 --> 03:27.680]  читаем ячейку памяти, то мы читаем либо из памяти, либо если в буфере уже есть запись, который
[03:27.680 --> 03:32.200]  мы просто допоминания не протолкнули, то мы читаем ее из буфера. Ну, в зависимости от того,
[03:32.200 --> 03:37.700]  где вот. Если здесь есть более свежая запись, читаем отсюда, иначе читаем из памяти. В протоколке
[03:37.700 --> 03:44.140]  кэшей с их протоколом когерянности на этой картинке вообще нет, потому что в конце концов
[03:44.140 --> 03:48.500]  в существовании протокола когерянности его цель этого протокола в том, чтобы быть незаметным,
[03:48.500 --> 03:57.340]  в том, чтобы скрывать этот пояс за тот факт, что ячейка памяти логически такая цельная,
[03:57.340 --> 04:01.700]  единственная, представлена в виде нескольких копий в разных кэшах. Вот эта распределенность
[04:01.700 --> 04:07.660]  протокола когерянности скрывает, и в операционной модели этого всего вообще нет. Но проблема
[04:07.660 --> 04:12.340]  в том, что операционная модель была для каждого своя, у Арма другая операционная модель, про которую
[04:12.340 --> 04:19.660]  нужно по-другому рассуждать, и это довольно печально. Поэтому мы хотим какой-то более универсальный
[04:19.660 --> 04:25.980]  инструмент, который будет нам объяснять исполнение нашего многопоточного кода, как этот код на разных
[04:25.980 --> 04:31.180]  ядрах работает с общей произведением памяти. И этот инструмент — это декларативная модель памяти,
[04:31.180 --> 04:39.660]  которая оперирует не вот триордерингами, буферами когерянностью, а оперирует порядками. Вот в этой
[04:39.660 --> 04:47.140]  модели исполнение — это граф, которым вершинами являются обращения к памяти, а дугами, дуги — это
[04:47.140 --> 04:54.140]  частичные порядки, которые в исполнении возникают. И вот эти частичные порядки ограничивают то,
[04:54.300 --> 05:02.780]  что мы можем прочесть из ячейки памяти. Всё-таки в исполнении, может быть, глобального порядка и нет,
[05:02.780 --> 05:10.180]  но есть какие-то частичные, на котором мы полагаться всё-таки можем. Это такая вот принципиальная
[05:10.180 --> 05:16.780]  разница между операционным и декларативным подходом. И мы к декларативному придём сегодня чуть
[05:16.780 --> 05:24.100]  позже, но пока мы... С чего мы начали? Мы сказали, что на самом деле мы не хотим ни про графы думать,
[05:24.100 --> 05:31.380]  ни про какие-то абстрактные машины, мы хотим жить в модели sequential consistency, где исполнение
[05:31.380 --> 05:36.140]  программы неотличимы от последовательного, который просто уважает порядок обращения к памяти в каждом
[05:36.140 --> 05:42.140]  потоке. Но проблема в том, что компьютеры так не работают, такую границу нам не дают, поэтому они
[05:42.140 --> 05:47.500]  вместе со своими всякими там реордерными оптимизациями отдают нам барьеры, инструкции,
[05:47.500 --> 05:53.420]  которые позволяют форсировать порядок, чтобы можно было из не sequential consistent
[05:53.420 --> 05:59.820]  процессора сделать sequential consistent исполнение. Ну, на не sequential consistent процессоре сделать
[05:59.820 --> 06:06.980]  sequential consistent исполнение. Ну вот, в частности, на x86 у нас есть барьер, собственно, единственный почти
[06:06.980 --> 06:14.580]  influence, который гарантирует, что если у нас есть вот запись потом чтения, то непременно
[06:14.580 --> 06:24.540]  запись станет видимой глобально до этого чтения. Но тут возникает проблема. С одной стороны,
[06:24.540 --> 06:33.060]  мы хотим, чтобы программа, чтобы об исполнении программы можно было рассуждать в модели
[06:33.060 --> 06:39.300]  чередования, чтобы у нас была sequential consistency, но при этом мы хотим, чтобы все-таки процессор
[06:39.300 --> 06:44.220]  выполнял какие-то оптимизации, а барьеры, кажется, этому препятствуют. Так что мы должны
[06:44.220 --> 06:52.020]  разобраться, а где именно мы хотим барьеры расставлять. Ну, точнее, не так. Мы хотим как-то
[06:52.020 --> 06:57.060]  расставить приоритеты, что нам важнее. Ну, то есть у нас есть цель, чтобы было, чтобы о программе
[06:57.060 --> 07:02.740]  можно было просто рассуждать об исполнении, а с другой стороны, чтобы процессор и компедиатор
[07:02.740 --> 07:07.340]  имели большую свободу для оптимизации. И это противоположная цель, они противоречат друг другу,
[07:07.340 --> 07:12.980]  и чтобы это противоречие разрешить, мы сказали, что мы не тем, ни другим жертвовать не будем,
[07:12.980 --> 07:20.940]  мы откажемся от некоторых программ. И вот для программ, которых мы назовем плохими, программы
[07:20.940 --> 07:25.940]  с гонками, программы с некорректной синхронизацией, мы обеспечивать sequential consistency не будем.
[07:25.940 --> 07:32.140]  Мы просто скажем, что не пишите такие программы. Но если программа хорошая, если в ней синхронизация
[07:32.140 --> 07:40.740]  устроена корректно, а определение корректной синхронизации будет позже, то такая программа может
[07:40.740 --> 07:48.300]  порождать только sequential и consistent исполнение. То есть разработчик и сама программа не сможет
[07:48.300 --> 07:56.460]  отличить исполнение от последовательного. Вот это была наша цель. Почему это была наша цель?
[07:56.460 --> 08:07.980]  Потому что в чем был замысел отказа от таких вот некорректных, плохо синхронизированных программ.
[08:07.980 --> 08:12.700]  Оказывается, что так вот мир устроен, что если программа корректно синхронизирована, то для нее
[08:12.700 --> 08:20.140]  достаточно поставить очень мало барьеров памяти в машинном коде и получить одновременно и оптимизации
[08:20.140 --> 08:28.380]  процессора комператора, и видимость последовательного исполнения. Вот поэтому мы фокусируемся и усиливаем
[08:28.380 --> 08:34.100]  на таких программах. И вот гарантия о нашей модели памяти звучит так, что есть в программе нет гонок, а гонка
[08:34.100 --> 08:40.380]  это, напомню, несинхронизированное обращение, два несинхронизированных конфликтующих обращения
[08:40.380 --> 08:48.380]  к одной и той же ячейке памяти, то такая программа наблюдает только последовательно согласованный исполнение.
[08:48.380 --> 08:55.380]  Про конкурс надо еще добавить, где одна анализ этих обращений, это запись.
[08:55.380 --> 09:00.380]  Это значит не конфликтующие. А конфликтующие подозревают, что одна из них запись.
[09:00.380 --> 09:06.380]  Это определение, да, оно у нас было вот здесь.
[09:07.380 --> 09:12.380]  Два обращения конфликтует, если они обращаются к одной ячейке, по крайней мере, одной из них запись.
[09:12.380 --> 09:17.380]  Вот это есть... Можно сказать, что два обращения образуют гонку, если они обращаются к одной ячейке памяти,
[09:17.380 --> 09:23.380]  одной из них запись, они не в порядочной синхронизации. Ну, либо два конфликтующие обращения памяти не в порядочной синхронизации.
[09:23.380 --> 09:35.380]  То же самое, только короче. Вот. Ну и каков был наш план? Вот мы хотели построить декларативную модель.
[09:35.380 --> 09:43.380]  Декларативную модель для пользователя. Что у нас было? У нас есть процессоры, у каждого из них есть какая-то модель памяти,
[09:43.380 --> 09:49.380]  какие-то барьеры, каждый процессор какие-то реордеринги делает. А с другой стороны, есть разработчик,
[09:49.380 --> 09:54.380]  который пишет программу для этих процессоров, и он явно ожидает, что все-таки программа не будет
[09:54.380 --> 09:58.380]  исполнится произвольным образом, а все-таки, что на что-то можно полагаться, на какие-то гарантии.
[09:58.380 --> 10:08.380]  Это пока не гарантии, это пока ожидания. И вот мы, разработчики модели памяти, берем эти ожидания, берем
[10:08.380 --> 10:16.380]  процессоры, и с одной стороны пользователю, разработчику отдаем как раз гарантии видимости, то есть
[10:16.380 --> 10:23.380]  что он может прочесть, что он может увидеть в чтении в своей программе. И эти гарантии мы формулируем в виде
[10:23.380 --> 10:29.380]  частичных порядков, которые эти чтения ограничивают каким-то образом. А с другой стороны, мы через
[10:29.380 --> 10:38.380]  комператор обеспечиваем выполнение этих гарантий на конкретном процессоре, но фактически ставим
[10:38.380 --> 10:51.380]  барьеры памяти в машинном коде. Вот, и наша цель придумать такой набор гарантий, разумный, который
[10:51.380 --> 11:00.380]  потом можно через барьеры выразить, такой, чтобы, с одной стороны, в совокупности эти частичные
[11:00.380 --> 11:06.380]  порядки, вот эти гарантии давали нам видимость последовательного исполнения, а с другой стороны, у нас
[11:06.380 --> 11:14.380]  было бы как можно меньше ограничений, так чтобы процессор мог побольше риордерить. И мы с вами дальше,
[11:14.380 --> 11:21.380]  ну не то чтобы выдумывали гарантии, мы их не выдумывали, мы скорее пытались понять, а на что мы
[11:21.380 --> 11:30.380]  рассчитываем при исполнении программы, чего мы ожидаем. Ну первое наше ожидание, оно, да, и вот эти
[11:30.380 --> 11:38.380]  наши ожидания мы пытаемся формулизовать. Вот первое, что мы ожидаем, это программа Order. Ну вот,
[11:38.380 --> 11:55.380]  смотрите. Пишем мы такую вот программу. a равно 0, b равно 0, пишем в a, b плюс 1, в b равно 1.
[11:55.380 --> 12:04.380]  И получается, что почему-то запись в b происходит до записи в a. Вот, как будто бы в программе
[12:04.380 --> 12:09.380]  компилятор может взять и переставить две строчки местами. Но вы же писали в своей жизни
[12:09.380 --> 12:16.380]  однопоточные коты, вы все-таки полагаете, что он работает, как вы написали. Вот. Все действительно так.
[12:16.380 --> 12:24.380]  Но это не значит, что компилятор и процессор не могут ничего поменять местами. Это значит, что они
[12:24.380 --> 12:30.380]  могут поменять что-то местами до тех пор, пока вы вот не полагаетесь на... Если вы делаете запись,
[12:30.380 --> 12:36.380]  а потом не читаете, то, наверное, можно ее как-то свободно в текстопрограмме однопоточно расположить.
[12:36.380 --> 12:43.380]  Но скажем, если вы вот записали в a, а потом напечатали a и b, а потом записали в b,
[12:43.380 --> 12:49.380]  и напечатали a и b, то вот такая программа, она уже, если она увидит запись в b и не увидит
[12:49.380 --> 12:56.380]  запись в a, то она удивится. Поэтому компилятор это понимает и теперь в такой программе сначала
[12:56.380 --> 13:08.380]  пишет в a, а потом пишет в b. Ну то есть компилятор и процессор они не ломают поведение ожидания
[13:08.380 --> 13:15.380]  однопоточной программы. И вот эти ожидания мы формулируем в виде программ Order. Программ Order
[13:15.380 --> 13:20.380]  это частичный порядок, который связывает все обращения к памяти в пределах одного потока.
[13:20.380 --> 13:29.380]  Программ Order сам по себе не означает, что инструкции будут в таком порядке выполняться на процессоре.
[13:29.380 --> 13:36.380]  Он лишь означает, что исполнение программы, что чтение, которое вы делаете в одном потоке,
[13:36.380 --> 13:43.380]  они программ Order не противоречит, они с ним согласованы. Если вы сделали запись,
[13:43.380 --> 13:47.380]  а потом читаете ячейку памяти, то, конечно, вы ожидаете, что запись произойдет.
[13:47.380 --> 13:52.380]  А если вы еще не сделали запись, то будет странно, если вы ее увидите.
[13:52.380 --> 13:57.380]  Вот, это базовая гарантия, которую вы пользуетесь уже просто...
[13:57.380 --> 14:01.380]  Если вы программируете что-то однопоточное, то вы уже пользуетесь этой гарантией.
[14:01.380 --> 14:07.380]  Это первое ожидание, которое у нас есть. Видимость через программ Order.
[14:07.380 --> 14:15.380]  А дальше мы говорим, хорошо, однопоточная программа ведет себя так, как мы ожидали.
[14:15.380 --> 14:19.380]  Теперь вопрос про многопоточные программы.
[14:19.380 --> 14:25.380]  И в этих многопоточных программах мы разделим ячейки памяти на два класса.
[14:25.380 --> 14:29.380]  Во-первых, ведем понятие конфликта, и вот с помощью этого понятия конфликта
[14:29.380 --> 14:33.380]  разделим ячейки памяти на два класса. Ячейки первого класса — это ячейки,
[14:33.380 --> 14:40.380]  для которых конфликтующие обращения неупорядочены. Логика самой программы.
[14:40.380 --> 14:43.380]  То есть мы пишем спинлог, разные потоки приходят в его ячейку логика
[14:43.380 --> 14:47.380]  и пытаются с ней что-то делать. Конечно же, эти обращения неупорядочены,
[14:47.380 --> 14:50.380]  потому что сам спинлог упорядочивает обращения к другим ячейкам памяти
[14:50.380 --> 14:54.380]  с помощью себя. Так что ячейка логика у нас особенная.
[14:54.380 --> 15:00.380]  Но дальше в программе еще много других ячеек, и вот к ним уже доступ
[15:00.380 --> 15:04.380]  конфликтующих операций должен быть упорядочен. В частности, тем спинлогам,
[15:04.380 --> 15:08.380]  которые мы пишем вот здесь.
[15:08.380 --> 15:14.380]  И что мы дальше говорим? Давайте явно компилятору сообщим,
[15:14.380 --> 15:19.380]  какие ячейки мы собираемся использовать для синхронизации, то есть для каких
[15:19.380 --> 15:23.380]  ячеек конфликтующие обращения будут неупорядочены.
[15:23.380 --> 15:29.380]  И мы вот эту аннотацию называем атомиком. Bool и AtomicBool в процессоре
[15:29.380 --> 15:32.380]  представлены одинаково, просто ячейка памяти, но при этом компилятор
[15:32.380 --> 15:35.380]  понимает, что это особенный ячейк памяти.
[15:35.380 --> 15:41.380]  И дальше мы, разделив ячейки на атомики и неатомики,
[15:41.380 --> 15:46.380]  выдумываем следующие гарантии. Во-первых, посмотрим на атомик
[15:46.380 --> 15:52.380]  и на историю записи вот этого атомика. Напомню, что картинка
[15:52.380 --> 15:57.380]  про тест, но не то что про тест, про программу, в которой разные ядра
[15:57.380 --> 16:02.380]  сначала пишут свой номер в одну ячейку, а потом читают содержимое.
[16:02.380 --> 16:07.380]  И вот они читают разные в одни и те же моменты времени, но при этом
[16:07.380 --> 16:11.380]  все-таки картинка имеет некоторую структуру, а именно тут можно
[16:11.380 --> 16:16.380]  углядеть, что история, которая прочитана, то есть та цепочка чтений,
[16:16.380 --> 16:19.380]  та цепочка значений, которую увидел каждое ядро,
[16:19.380 --> 16:24.380]  она является под последовательностью некоторой общей последовательности.
[16:24.380 --> 16:28.380]  И мы эту общую последовательность называем modification order. Мы говорим,
[16:28.380 --> 16:33.380]  что в исполнении, вот программ order – это порядок просто в тексте программы,
[16:37.380 --> 16:41.380]  а modification order – это порядок уже в исполнении реализуется.
[16:41.380 --> 16:46.380]  Так вот, все записи атомик, они упорядочиваются, на них есть порядок,
[16:46.380 --> 16:52.380]  и чтения в каждом потоке наблюдают под историю этого modification order.
[16:55.380 --> 17:02.380]  Вот что эта картинка и демонстрировала. То есть тут уже появляются разные потоки,
[17:02.380 --> 17:06.380]  которые работают с одной и той же ячейкой, и все записи этих потоков
[17:06.380 --> 17:09.380]  выстраиваются в некоторую последовательность.
[17:09.380 --> 17:13.380]  Какая она будет, мы, конечно, не знаем. Ну вот какая это.
[17:13.380 --> 17:18.380]  Следующее. Да, ну и вот это еще одно ограничение на чтение, то есть что
[17:18.380 --> 17:23.380]  чтение читают под историю modification order на данный момент.
[17:23.380 --> 17:26.380]  Следующее наше ожидание, наверное, самое важное. У нас есть два потока –
[17:26.380 --> 17:31.380]  producer и consumer. Producer пишет что-то в буфер, потом ставит флажок.
[17:31.380 --> 17:35.380]  Consumer читает флажок, и если он видит там true, то он читает из буфера.
[17:35.380 --> 17:39.380]  И ожидает, что в этом чтении он увидит эту запись, потому что, ну в самом деле,
[17:39.380 --> 17:42.380]  почему он читает из буфера? Потому что он видел флажок, значит,
[17:42.380 --> 17:48.380]  флажок уже записали, а в продюсере запись буфер шла до записи его флажок
[17:48.380 --> 17:53.380]  в тексте программы просто. Ну вот мы видели, что поэток в тексте программы
[17:53.380 --> 17:58.380]  вообще, как говорят, никому ничего не обязывает. Так что вот это ожидание,
[17:58.380 --> 18:04.380]  что если событие произошло до, то мы должны, если есть причинность,
[18:04.380 --> 18:08.380]  то мы ее наблюдаем. Вот эту гарантию нужно как-то формализовать
[18:08.380 --> 18:13.380]  и потом обеспечить. Просто из коробки она в процессоре может даже
[18:13.380 --> 18:20.380]  и не иметь места. Ну а дальше мы занимались тем, что формализовали,
[18:20.380 --> 18:24.380]  что такое вот причина, что такое произошло до. И для этого мы пользовались
[18:24.380 --> 18:29.380]  определением из распределенных систем. Мы говорили, что у нас есть там,
[18:29.380 --> 18:33.380]  не знаю, узлы, они общаются при задаче сообщений, у них нет синхронизированных
[18:33.380 --> 18:37.380]  часов и быть не может. Поэтому мы вводим на события в такой системе
[18:37.380 --> 18:41.380]  отношения чистичного порядка happens before. Мы скажем, что если событие A
[18:41.380 --> 18:45.380]  произошло до события B в пределах, ну, предшествовало событию B в пределах
[18:45.380 --> 18:49.380]  одного узла, то, разумеется, A произошло до B. Потом мы говорим,
[18:49.380 --> 18:53.380]  что если A – это отправка сообщения, а B – это получение этого сообщения
[18:53.380 --> 18:57.380]  на другом узле, то опять, видимо, A произошло до B. И замыкаем
[18:57.380 --> 19:01.380]  по транзитивности. И вот такое определение, оно, такой чистичный порядок,
[19:01.380 --> 19:07.380]  оно отражает причинность в системе, что какое-то событие могло стать причиной
[19:07.380 --> 19:15.380]  другого события, повлияет на него. И вот здесь ровно такая история.
[19:15.380 --> 19:21.380]  Эта запись должна повлиять на это чтение. Но чтобы объяснить почему,
[19:21.380 --> 19:25.380]  нам нужно перенести это определение на happens before
[19:25.380 --> 19:36.380]  на модель разделяемой памяти. Вот. Что такое предшествовало до
[19:36.380 --> 19:40.380]  в пределах одного узла? Это программа order. Ну, просто в тексте программы
[19:40.380 --> 19:44.380]  одна инструкция шла до другой. А что такое отправка сообщения?
[19:44.380 --> 19:49.380]  Вот это запись в Atomic и чтение из Atomic. Запись в Atomic мы как будто бы
[19:49.380 --> 19:55.380]  отправляем сообщение значения в провод, в ячейку памяти, а потом другой поток
[19:55.380 --> 20:00.380]  из этого провода получает сообщение, то есть читает значение из ячейки.
[20:00.380 --> 20:04.380]  И вот если мы здесь записали, а потом прочли, то вот как будто бы
[20:04.380 --> 20:09.380]  сообщение отправилось. Ну вот спинлоки такая штука есть. Мы сбрасываем флажок
[20:09.380 --> 20:18.380]  Atomic, а потом сбрасываем флажок в Unlock, а в Lock мы делаем Exchange,
[20:18.380 --> 20:23.380]  в том числе это чтение, до тех пор пока мы не увидим ноль. И вот мы как будто бы
[20:23.380 --> 20:37.380]  получили сообщение в локе от Unlock. Вот мы такую связь Store и Load зафиксируем
[20:37.380 --> 20:43.380]  в виде отношения synchronize with. Мы скажем, что Store и Load synchronize with,
[20:43.380 --> 20:50.380]  если Load из одного потока увидел значение, которое записал Store в другом потоке.
[20:50.380 --> 20:56.380]  Вот эта пара, она связывается с такой красной стрелочкой и вот это аналог
[20:56.380 --> 21:01.380]  передачи сообщения. Коммуникация двух потоков через разделяемые ячейки памяти.
[21:01.380 --> 21:05.380]  Ну а дальше мы замыкаем это по транзитивности точно так же и получаем
[21:05.380 --> 21:13.380]  Happens before, но уже в будущей программе. Вот если это чтение увидело эту запись,
[21:13.380 --> 21:20.380]  то мы ожидаем, что это чтение случилось после этой записи и видимо увидят
[21:20.380 --> 21:25.380]  результат этой записи. Это вот еще одно наше ожидание. Мы теперь его
[21:25.380 --> 21:31.380]  формализовали. Почему мы в этой программе должны увидеть запись буфер?
[21:31.380 --> 21:36.380]  Ну потому что это чтение упорядочилось с этим через Happens before. Мы это
[21:36.380 --> 21:40.380]  наблюдаем, мы это понимаем, значит и видимость, значит это чтение обязано
[21:40.380 --> 21:45.380]  увидеть эту запись. Вот еще одно наше ожидание и мы его формализовали.
[21:50.380 --> 21:56.380]  Все понятно пока, да? Ну а дальше мы замечаем, что тут требуется некоторое
[21:56.380 --> 22:01.380]  уточнение, потому что может быть одному чтению предшествуют разные цепочки
[22:01.380 --> 22:06.380]  Happens before, это же частичный порядок. И может быть вот две записи
[22:06.380 --> 22:11.380]  предшествуют в Happens before за чтению, но при этом эти две записи, трудно сказать
[22:11.380 --> 22:17.380]  какое из них было последнее. Ну поэтому мы говорим, что это какая-то плохая
[22:17.380 --> 22:21.380]  программа. У нас есть две записи, они не упорядочены через Happens before между
[22:21.380 --> 22:26.380]  собой, не конфликтуют, не упорядочены. И вот мы назовем это гонкой. Это два
[22:26.380 --> 22:31.380]  конфликтующих неатомарных обращения памяти, которые не упорядочены через
[22:31.380 --> 22:39.380]  Happens before. Вот мы такие программы запретили вот ровно поэтому. Ну а дальше мы
[22:39.380 --> 22:44.380]  замечаем, что и всего придуманного нам недостаточно, потому что остается такая
[22:44.380 --> 22:50.380]  программа. И требований гарантии модификацион ордера и Happens before недостаточно,
[22:50.380 --> 22:58.380]  чтобы запретить для этой программы исполнение, в котором и в R1 и в R2 в итоге
[22:58.380 --> 23:08.380]  окажется 0. Вот. Это все еще допустимо даже с нашими ограничениями, поэтому мы
[23:08.380 --> 23:13.380]  придумываем еще одну гарантию, усиливаем гарантию модификацион ордера,
[23:13.380 --> 23:19.380]  говорим, что нам теперь нужен порядок на всех обращениях ко всем атомикам.
[23:19.380 --> 23:23.380]  То есть в исполнении есть вот такой вот сквозной порядок на всех обращениях,
[23:23.380 --> 23:31.380]  сторах, лодах, ченжах ко всем атомикам в программе. Ну и разумеется порядок снова
[23:31.380 --> 23:38.380]  согласован с программом ордера. Тогда вот такое исполнение уже кажется
[23:38.380 --> 23:45.380]  недопустимо и вот теперь мы собрали все вместе все частичные порядки, которые
[23:45.380 --> 23:50.380]  образуют исполнение. Вот исполнение в нашей декларативной модели это
[23:50.380 --> 23:55.380]  реализация всех этих порядков. Модификацион ордер, happens before,
[23:55.380 --> 24:00.380]  synchronization order. Ну они многие связаны между собой и мы считаем, что вот эти
[24:00.380 --> 24:04.380]  порядки согласованы в том смысле, что их объединение новоцикличное, что они
[24:04.380 --> 24:10.380]  не противоречены друг другу. Довольно естественное ожидание. А дальше оказывается,
[24:10.380 --> 24:18.380]  что если объединить все эти порядки и все ограничения, которые они в себе
[24:18.380 --> 24:25.380]  несут на чтение в программе, в совокупности дают видимость
[24:25.380 --> 24:31.380]  последовательного исполнения. Ну вот такова была наша изначальная цель. Мы хотели
[24:31.380 --> 24:36.380]  каким-то образом обеспечить для программы, для разработчика видимость глобального
[24:36.380 --> 24:41.380]  порядка всех обращений к памяти. То есть должен быть какой-то порядок, в котором
[24:41.380 --> 24:45.380]  можно объяснить все, что мы читаем из ячеек. Как мы этот порядок объяснения
[24:45.380 --> 24:49.380]  построили? Мы взяли все эти частичные порядки ацикличные, объединили их,
[24:49.380 --> 24:57.380]  построили топологическую сортировку. И дальше показали, что если исполнять все
[24:57.380 --> 25:04.380]  обращения к памяти в таком порядке, то каждое чтение вернет то же самое. То есть мы
[25:04.380 --> 25:08.380]  получили то, что хотели с одной стороны, а с другой стороны мы получили еще и
[25:08.380 --> 25:13.380]  риординги. Потому что если в программе гонок нет, а про программы с гонками мы не
[25:13.380 --> 25:18.380]  волнуемся, мы не думаем про них вообще. Если в программе гонок нет, то никакая
[25:18.380 --> 25:26.380]  программа не сможет различить порядка записей неатомарных, между которыми нет
[25:26.380 --> 25:33.380]  атомарных записей. Вот если у вас есть запись неатомарных ячеек памяти, то вы
[25:33.380 --> 25:37.380]  можете про них узнать, только выполнен синхронизацию. Когда вы выполнете
[25:37.380 --> 25:43.380]  синхронизацию, то есть там что-то прошло здесь из атомика, то кажется по гарантии
[25:43.380 --> 25:49.380]  видимости через Happens Before вы увидите разом эффекты всех этих записей. То есть
[25:49.380 --> 25:55.380]  корректная программа, программа без гонок наблюдать порядок этих записей не может,
[25:55.380 --> 25:59.380]  поэтому компедиаторы, процессоры могут эти неатомарные записи друг с другом
[25:59.380 --> 26:09.380]  переставлять. Ну вот, мы получили с одной стороны оптимизация компедиатора и
[26:09.380 --> 26:13.380]  процессора, с другой стороны видимость глобального порядка, ну и вот это был для
[26:13.380 --> 26:21.380]  нас успех. Но дальше мы говорим, что может быть нам не нужен sequential
[26:21.380 --> 26:27.380]  consistency, может быть программа наша устроена не так совсем. То есть может быть
[26:27.380 --> 26:33.380]  мы пишем программу на гарутинах, и вот эти гарутины в го, они общаются через
[26:33.380 --> 26:38.380]  каналы, отправляют сообщения, получают сообщения. То есть программа из гарутинов
[26:38.380 --> 26:42.380]  такой граф, по которому текут данные через каналы. Ну или мы говорили про
[26:42.380 --> 26:46.380]  future на последней лекции, и там тоже говорилось, что вот можно написать код на
[26:46.380 --> 26:51.380]  future, на rpc future, так чтобы у нас были такие асинхронные конвейеры, асинхронные
[26:51.380 --> 26:57.380]  графы, по которым данные текут. Вот в таком мире нет sequential consistency, в смысле
[26:57.380 --> 27:01.380]  мы не рассуждаем про глобальный порядок, мы рассуждаем про продюсеров и
[27:01.380 --> 27:10.380]  консьюмеров. То есть про happens before. Поэтому мы должны оставить программисту
[27:10.380 --> 27:18.380]  свободу для того, чтобы он мог оптимизировать код, которому не нужно
[27:18.380 --> 27:23.380]  sequential consistency, и ставить там меньше барьеров. Ну а барьеры, я напомню, они
[27:23.380 --> 27:29.380]  возникают в тех местах, где мы к экономикам обращаемся. И для этого у нас есть
[27:29.380 --> 27:33.380]  слабые модели памяти, слабые memory orders, которые, с одной стороны, отнимают у
[27:33.380 --> 27:39.380]  нас видимость глобального порядка, но зато дают больше оптимизации. И какие же
[27:39.380 --> 27:44.380]  гарантии эти memory orders дают? Ну вот тут мы перечислили их, и наша цель сегодня
[27:44.380 --> 27:54.380]  как раз разобраться, как этим всем пользоваться. Про sequential consistency мы уже
[27:54.380 --> 27:59.380]  поговорили. Это synchronization order, то есть все обращения на всех атомиках
[27:59.380 --> 28:06.380]  глобально упорядочены, и sequentially consistent атомики участвуют в образовании
[28:06.380 --> 28:11.380]  happens before. То есть если вы в одном потоке пишете в ячейку, а из другого
[28:11.380 --> 28:17.380]  потока читаете эту ячейку и видите запись, то значит вы видите и то, что было, вы
[28:17.380 --> 28:24.380]  можете прочесть уже все, что было записано в первом потоке до записи. Следующая
[28:24.380 --> 28:32.380]  ступень, ну вообще memory orders, их там шесть штук, но их можно вот на три ступени
[28:32.380 --> 28:39.380]  разбить. Следующая ступень — это Release Acquire. Release Acquire по-прежнему участвует
[28:39.380 --> 28:45.380]  в образовании happens before. То есть если вы пишете в атомик с memory order Release,
[28:45.380 --> 28:50.380]  а в другом потоке читаете с memory order Acquire и читаете то, что было написано, то
[28:50.380 --> 28:54.380]  между записью и чтением образуется синхронизация Swiss, а значит образуется и
[28:54.380 --> 29:02.380]  happens before в конце концов. Но эти memory orders отнимают у вас synchronization order.
[29:02.380 --> 29:08.380]  То есть на каждом отдельном атомике порядок записи все еще есть, но главное
[29:08.380 --> 29:12.380]  глобального порядка записи, который был бы согласован с порядком в тексте
[29:12.380 --> 29:18.380]  программы, вы лишаете, его уже нет, вы его лишились. Ну вот опять пример store load,
[29:18.380 --> 29:23.380]  store load, и вот если его запустить без изменений, то есть sequentially consistent
[29:23.380 --> 29:30.380]  атомиками, то скомпилируется другой код. Если этот код скомпилировать, запустить,
[29:30.380 --> 29:38.380]  то смотрите, что произойдет. Ну ничего не произойдет, код работает, он не видит
[29:38.380 --> 29:49.380]  никогда два нуля, он не ломается. Ну вот смотри, если мы их ослабим, то мы...
[30:00.380 --> 30:12.380]  Вот, то мы получаем два нуля, то есть мы и synchronization order лишаемся здесь.
[30:12.380 --> 30:17.380]  Ну а если мы... но все-таки happens before у нас остается. Если мы используем
[30:17.380 --> 30:23.380]  memory order relaxed, то мы, кажется, лишаемся почти всего, мы только остаемся с порядком
[30:23.380 --> 30:30.380]  на одном отдельном атомике. Happens before у нас нет, и вот это означает, что если вы там
[30:30.380 --> 30:37.380]  прочли с relaxed чтением значение атомика, то это означает, что вы просто не вправе
[30:37.380 --> 30:41.380]  на основание этого чтения, на основании того результата, который вы увидели, делать
[30:41.380 --> 30:50.380]  какие-то предположения о содержимых других ячеек памяти. Просто так делать нельзя.
[30:50.380 --> 30:57.380]  Ну или если у вас была relaxed запись, то тоже, а о ее после чтения судить о содержимом
[30:57.380 --> 30:59.380]  других ячеек тоже не стоит.
[30:59.380 --> 31:00.380]  Можно?
[31:00.380 --> 31:01.380]  Да.
[31:01.380 --> 31:09.380]  Можете, пожалуйста, открыть код, который у вас, тот, что было. Можете объяснить,
[31:09.380 --> 31:14.380]  что тут идет не так, если у нас стоят такие набли ордера?
[31:14.380 --> 31:17.380]  Ну у нас просто нет гарантии, которые бы запрещали два нуля.
[31:17.380 --> 31:26.380]  Нет, мы так не говорим. Мы не говорим, когда мы используем адрепамяти, мы не говорим,
[31:26.380 --> 31:31.380]  что там что-то с чем-то переупорядочилось. У нас модели про порядки и про ограничения.
[31:31.380 --> 31:36.380]  Если нет ограничений, которые запрещают два нуля, значит такое исполнение возможно.
[31:36.380 --> 31:42.380]  Вот какая гарантия, какой частичный порядок запрещает здесь два нуля?
[31:43.380 --> 31:50.380]  Вот у нас есть программа, здесь чтение y дало 0, чтение x дало 0. У нас может быть
[31:50.380 --> 31:54.380]  modification order в программе, да? Должен же быть на каждом атомике.
[31:54.380 --> 32:01.380]  Ну он есть. Вот сначала в каждом атомике был 0, потом в каждом атомике стала единица,
[32:01.380 --> 32:06.380]  и каждый поток читал под историю этой истории. То есть прощал 0, ну вот под история,
[32:06.380 --> 32:12.380]  безусловно. У нас в этом исполнении не возникло Happens Before никакого.
[32:12.380 --> 32:16.380]  Чтобы возникло Happens Before, должен быть возникнуть Synchronize the Swiss.
[32:16.380 --> 32:19.380]  Для этого какое-то чтение должно увидеть какую-то запись.
[32:19.380 --> 32:23.380]  Но не увидело, значит никакого Happens Before, Synchronize the Swiss тоже нет.
[32:23.380 --> 32:32.380]  Synchronization Order тоже нет, потому что у нас более слабый Memory Order.
[32:32.380 --> 32:36.380]  У нас есть гарантия Program Order, но она тоже здесь не очень помогает.
[32:36.380 --> 32:40.380]  То есть у нас один поток читает одну ячейку, а пишет другую.
[32:40.380 --> 32:45.380]  Так что нет никаких ограничений, которые бы препятствовали результату 0.0.
[32:45.380 --> 32:52.380]  Просто мне хочется представить исполнение, которое позволяет на текущей модели памяти,
[32:52.380 --> 32:55.380]  и которое бы этим видео могло быть 0.0.
[32:55.380 --> 32:58.380]  Ну вот, ты говоришь уже не про модель памяти, а про некоторую мотивацию этой модели.
[32:58.380 --> 33:01.380]  То есть почему реальность такая, ты спрашиваешь?
[33:01.380 --> 33:05.380]  Просто если ты оперируешь моделью памяти, то ты не должен об этом думать.
[33:05.380 --> 33:09.380]  А если мы говорим про конкретный процессор, то давай вот про это и поговорим.
[33:09.380 --> 33:16.380]  Почему вообще... Я даже не про это поговорю в пример, а про дугой.
[33:16.380 --> 33:24.380]  Рейзер Куайлор. Потому что может быть непонятно, почему Рейзер Куайлор это два-разный Memory Order,
[33:24.380 --> 33:27.380]  почему они такие бардые, несимметричные.
[33:27.380 --> 33:30.380]  И почему вообще эту причинность нужно обеспечить.
[33:30.380 --> 33:33.380]  Почему ее в старом кино.
[33:33.380 --> 33:42.380]  Представим себе, что у нас есть два ядра.
[33:46.380 --> 34:01.380]  Ну, было какая-то марка... А, вот что. Подавал на зеркало.
[34:01.380 --> 34:04.380]  Есть два ядра.
[34:04.380 --> 34:17.380]  И на этом ядре исполняется поток, который мы назовем продюсером, который что-то пишет,
[34:17.380 --> 34:24.380]  а на другом ядре исполняется поток консюма, который хочет получить данные от первого потока.
[34:24.380 --> 34:28.380]  Что делает поток на первом ядре как продюсера?
[34:28.380 --> 34:42.380]  Вот он, допустим, пишет в X, а на этом ядре поток читает от Y.
[34:42.380 --> 34:51.380]  И если он там увидел единицу, то читает из X.
[34:51.380 --> 34:54.380]  И мы ожидаем, что если здесь вы увидели антаризму, то здесь вы увидели ржавину.
[34:54.380 --> 34:56.380]  Здесь ядромерка по коннекту.
[34:56.380 --> 34:58.380]  Ну, это просто процессор.
[34:58.380 --> 35:01.380]  Ядромерка это вот здесь. Где-то вот с него однажды.
[35:01.380 --> 35:07.380]  Это есть еще своя цель. Цель этого примера объяснить, почему есть релиз...
[35:07.380 --> 35:10.380]  Ну, почему вообще в принципе существует релиз Aquarium,
[35:10.380 --> 35:14.380]  почему Command & Reform не обеспечивается просто с коробки, что может помешать кино.
[35:14.380 --> 35:18.380]  И почему релиз Aquarium это два-разный Command & Order, то есть два-разный парикад.
[35:18.380 --> 35:23.380]  Ну, смотрите, вот у нас есть ядро.
[35:23.380 --> 35:31.380]  И в этом ядре, как удобно можно вводить, у этого ядра есть кэш.
[35:31.380 --> 35:38.380]  И напомню, что после реакции кэши мы знаем, что все записи памяти происходят через кэш,
[35:38.380 --> 35:42.380]  но потом когда-нибудь сбрасывает данные тюкли в память.
[35:42.380 --> 35:45.380]  Нам нужно работать с двумя ячейками.
[35:45.380 --> 35:54.380]  У зверя кэшлини. В одной лежит x, в другой находится y.
[35:54.380 --> 36:03.380]  И пусть оказывается так, что ячейка x, ее в нашем ядре, в нашем кэше сейчас нет.
[36:03.380 --> 36:05.380]  То есть кэшлини в состоянии дуэлина.
[36:05.380 --> 36:07.380]  То есть нет ее вообще.
[36:07.380 --> 36:12.380]  А вот ячейка сириков, она у нас в кэшее действует на состоянии вскрытия.
[36:12.380 --> 36:14.380]  Что это означает?
[36:14.380 --> 36:18.380]  Что если мы пишем x, то мы можем написать без коммуникации.
[36:18.380 --> 36:20.380]  Сразу кэш очень быстро.
[36:20.380 --> 36:27.380]  А чтобы записать x, нам нужно пойти к другим ядрам и инвалидировать их по x.
[36:27.380 --> 36:30.380]  Забросьте память, потому что я пишу.
[36:30.380 --> 36:33.380]  Это коммуникация, которую ядро хочет изображать.
[36:33.380 --> 36:36.380]  Что оно делает? Оно линьится.
[36:36.380 --> 36:41.380]  Вот я поставлю между перед крышом StorePack.
[36:45.380 --> 36:48.380]  В простыке случая, я сейчас не про x86 говорю.
[36:48.380 --> 36:53.380]  Я говорю про некоторый абстактный процессор, который может какие-то активизации делать.
[36:53.380 --> 36:56.380]  Это не x86.
[36:56.380 --> 37:00.380]  В StorePack у него немного другое поведение.
[37:00.380 --> 37:04.380]  Что мог бы сделать такой ленивый процессор?
[37:04.380 --> 37:08.380]  Он мог бы запись x положить вот сюда.
[37:12.380 --> 37:16.380]  А запись в y положить сразу сюда.
[37:20.380 --> 37:25.380]  И с такой активизацией уже эта программа развалится.
[37:25.380 --> 37:28.380]  То есть причина теперь причина.
[37:29.380 --> 37:33.380]  Мы прочитаем из y один.
[37:33.380 --> 37:36.380]  Пообщаемся с этим хорошо.
[37:36.380 --> 37:41.380]  А потом из x прочитаем что?
[37:41.380 --> 37:47.380]  Прочитаем ноль, потому что этот x еще не добрался, не был брошен.
[37:47.380 --> 37:49.380]  Разрывается.
[37:49.380 --> 37:51.380]  А когда он сбросится память?
[37:51.380 --> 37:53.380]  Ну это уже посторонний вопрос.
[37:53.380 --> 37:55.380]  Может быть какие-то барьеры специальные.
[37:55.380 --> 37:57.380]  Может быть просто процессор решил, что пора.
[37:57.380 --> 37:59.380]  Не понимаю.
[38:02.380 --> 38:05.380]  С этой стороны что-то может пойти не так.
[38:05.380 --> 38:08.380]  Но не так может пойти и со стороны получателя.
[38:08.380 --> 38:10.380]  Почему?
[38:10.380 --> 38:12.380]  Что он может активизировать?
[38:12.380 --> 38:14.380]  Вот здесь мы активизируем коммуникацию.
[38:14.380 --> 38:17.380]  Здесь мы активизируем какого-то перикоперенности.
[38:17.380 --> 38:18.380]  Вот здесь тоже.
[38:18.380 --> 38:24.380]  Пусть ядро занимается чем-то полезным, а ему приходится общение, могут придаться и какое-то кашление.
[38:25.380 --> 38:28.380]  Что ядро говорит?
[38:28.380 --> 38:30.380]  Ну не очень-то и хотелось.
[38:30.380 --> 38:34.380]  Я сделал эту эвалидацию, но вот не прямо сейчас.
[38:36.380 --> 38:38.380]  Я не буду написать, просто напишу.
[38:38.380 --> 38:41.380]  Ну можно себе это представить.
[38:41.380 --> 38:44.380]  Видите, такое активизация Evaluation Queue.
[38:44.380 --> 38:50.380]  То есть мы ассинхронно пишем память, я ассинхронно потом вырабатываю эту эвалидацию.
[38:50.380 --> 38:56.380]  Мы отвечаем другому ядру, что да, мы как-то сделали эвалидацию сразу же.
[38:56.380 --> 39:00.380]  Но при этом мы не...
[39:00.380 --> 39:03.380]  Пока мы физически ее не сделали.
[39:03.380 --> 39:06.380]  И что могло пойти не так?
[39:06.380 --> 39:09.380]  Допустим, даже стопаквы не было.
[39:09.380 --> 39:15.380]  Но у этого второго ядра был кэш,
[39:15.380 --> 39:22.380]  где кэш-линия с х была эксклюзивная.
[39:22.380 --> 39:24.380]  Она была в состоянии эксклюзивной.
[39:24.380 --> 39:26.380]  И тут лежал норм.
[39:29.380 --> 39:32.380]  И вот мы делали запись в х и в итрик,
[39:32.380 --> 39:38.380]  и запись в х требовала отдаст наблюдации.
[39:38.380 --> 39:41.380]  То есть пусть вот это ядро оно честно написал в х,
[39:41.380 --> 39:44.380]  отправил нам сообщение, вы делайте, пожалуйста, у себя копию,
[39:44.380 --> 39:47.380]  а мы этого не сделали сразу.
[39:47.380 --> 39:51.380]  А потом мы язык сам прочитали из своей копии ноль.
[39:51.380 --> 39:55.380]  Ну вот, вот и правда.
[39:55.380 --> 40:01.380]  Так что мы можем, используя вот такие эвалистики,
[40:01.380 --> 40:04.380]  получить нарушение причинности по вине продюсера
[40:04.380 --> 40:07.380]  и получить нарушение причинности по вине консюма.
[40:07.380 --> 40:10.380]  Эвалистики разные, но эффект один неприятный.
[40:10.380 --> 40:12.380]  Поэтому мы должны...
[40:12.380 --> 40:16.380]  Ну это, еще раз, это такой эксперимент,
[40:16.380 --> 40:18.380]  который мы проводим в уме,
[40:18.380 --> 40:20.380]  потому что мы просто реально так делаем.
[40:20.380 --> 40:22.380]  Мы не можем так делать.
[40:22.380 --> 40:24.380]  И это по-своему разумно.
[40:24.380 --> 40:28.380]  Поэтому мы, с одной стороны, с помощью memory-order-релиз,
[40:28.380 --> 40:34.380]  будто бы чиним продюсера с помощью memory-order-acquire,
[40:34.380 --> 40:36.380]  чиним консюма.
[40:36.380 --> 40:38.380]  Каким образом?
[40:38.380 --> 40:44.380]  Ну, в этой картинке релиз он требует сброса сторбактора,
[40:44.380 --> 40:49.380]  а acquire он требует все-таки разбора и эвалидашенки.
[40:49.380 --> 40:52.380]  Ну можно думать об этом...
[40:52.380 --> 40:56.380]  Ну это прям совсем наивно, в смысле не нужно так думать,
[40:56.380 --> 40:58.380]  но для первого понимания сойдет.
[40:58.380 --> 41:01.380]  Можно сказать, что релиз-запись
[41:01.380 --> 41:04.380]  это такой односпоронний бое,
[41:04.380 --> 41:10.380]  который запрещает тому, что выше, продекать ниже.
[41:10.380 --> 41:14.380]  А acquire-чтение это односторонний барьер,
[41:14.380 --> 41:18.380]  который наоборот запрещает тому, что ниже, продекать выше.
[41:18.380 --> 41:22.380]  Ну, выше-ниже, как будто как с reordering,
[41:22.380 --> 41:24.380]  но на самом деле reordering-ов нет.
[41:24.380 --> 41:27.380]  Но вот эта оптимизация, это как будто бы
[41:27.380 --> 41:30.380]  это чтение переехало позже,
[41:30.380 --> 41:33.380]  эта запись переехала позже этой.
[41:33.380 --> 41:35.380]  Не то чтобы так буквально произошло,
[41:35.380 --> 41:38.380]  но в каком-то смысле переехало позже.
[41:38.380 --> 41:41.380]  Но не то чтобы ядро переставил,
[41:41.380 --> 41:43.380]  вот здесь то же самое,
[41:43.380 --> 41:45.380]  как будто бы мы прочли их из прошлого,
[41:45.380 --> 41:47.380]  как будто бы мы выполнили чтение раньше.
[41:47.380 --> 41:51.380]  Почему два номера reorder-а разные,
[41:51.380 --> 41:53.380]  но вот не работают в паре?
[41:53.380 --> 41:55.380]  Потому что нужно со стороны релиза запретить такие,
[41:55.380 --> 41:58.380]  чтобы быть со стороны записи запретить,
[41:58.380 --> 42:00.380]  со стороны чтения запретить.
[42:00.380 --> 42:03.380]  То есть на железном уровне можно представить себе такие ристики,
[42:03.380 --> 42:06.380]  которые нарушают причины из двух сетей,
[42:06.380 --> 42:08.380]  которые нарушают причины из двух сетей,
[42:08.380 --> 42:10.380]  которые нарушают причины из двух сетей,
[42:10.380 --> 42:13.380]  которые нарушают причины из двух сетей,
[42:13.380 --> 42:15.380]  которые нарушают причины из двух сетей,
[42:15.380 --> 42:17.380]  которые нарушают причины из двух сетей,
[42:17.380 --> 42:19.380]  которые нарушают причины из двух сетей,
[42:19.380 --> 42:21.380]  которые нарушают причины из двух сетей,
[42:21.380 --> 42:23.380]  которые нарушают причины из двух сетей,
[42:23.380 --> 42:25.380]  которые нарушают причины из двух сетей,
[42:25.380 --> 42:27.380]  которые нарушают причины из двух сетей,
[42:27.380 --> 42:29.380]  то есть это такие ристики, которые нарушают причины
[42:29.380 --> 42:31.380]  из двух сторон.
[42:31.380 --> 42:33.380]  И мы их запрещаем в этих ристиках,
[42:33.380 --> 42:35.380]  а в коде мы выражаем через три заклона.
[42:35.380 --> 42:37.380]  А в декларативной модели мы говорим,
[42:37.380 --> 42:39.380]  что релиз записи синхронизируется
[42:39.380 --> 42:41.380]  с aklой чтения вложения из печени.
[42:41.380 --> 42:43.380]  Замысл ясен?
[42:43.380 --> 42:45.380]  То есть из коробки у васcorобки у вас причинности
[42:45.380 --> 42:47.380]  может не быть,
[42:47.380 --> 42:49.380]  как она, но в процессе.
[42:49.380 --> 42:56.380]  То есть из коробки у вас хептаут у вас причинности может не быть в процессе
[42:56.380 --> 42:58.380]  Он может ее не обеспечивать
[42:58.380 --> 43:05.380]  Мы ее обеспечиваем, говоря явно, что в этом месте мы до потока общаемся между собой, передавим данные
[43:06.380 --> 43:15.380]  Я как правило говорю, что мы теперь в спинлоке можем интеракция с коробками
[43:15.380 --> 43:19.380]  Заменить их на действия и раскрывать
[43:19.380 --> 43:25.380]  Сейчас разберемся, мы, например, еще не дошли, я просто гарантия объясню
[43:25.380 --> 43:28.380]  Резервация на урон?
[43:28.380 --> 43:32.380]  Все нужно, раз оно есть, то нужно
[43:32.380 --> 43:34.380]  Это же инструменты
[43:34.380 --> 43:37.380]  На что я еще хочу обратить внимание
[43:37.380 --> 43:41.380]  Смотрите, вот x86 устроен не так
[43:41.380 --> 43:46.380]  Модерепамяти x86, оно такое
[43:46.380 --> 43:49.380]  Тут видите, все записи проходят через storebuffer
[43:49.380 --> 43:53.380]  Не может быть такого, что одна прошла, а другая застряла в буфере
[43:53.380 --> 43:55.380]  Нет, они все через него проходят
[43:55.380 --> 44:02.380]  К чему я веду? К тому, что x86 просто из коробки гарантирует, обеспечивает причинность программе
[44:02.380 --> 44:04.380]  Он не может ее нарушать
[44:04.380 --> 44:10.380]  И вы это могли видеть, потому что вы могли компилировать атомики, решая задачу спинлок
[44:14.380 --> 44:16.380]  Вы не видите, а видите
[44:16.380 --> 44:19.380]  И вы видели, что релиз и релакс компилировались
[44:19.380 --> 44:22.380]  Ну нет, вы видите, сейчас другое
[44:22.380 --> 44:30.380]  На x86 релиз и релакс компилируются в один и тот же move
[44:30.380 --> 44:34.380]  А ну-ка, компилируйся
[44:39.380 --> 44:41.380]  У нас сломан интернет
[44:49.380 --> 44:51.380]  Отлично, в общем
[44:51.380 --> 44:55.380]  Релиз и релакс компилируются в один и тот же move
[44:55.380 --> 44:57.380]  Почему?
[44:57.380 --> 45:00.380]  Ну вот не нужно процессору явно сообщать про причинность
[45:00.380 --> 45:02.380]  Он и так ее обеспечит
[45:02.380 --> 45:05.380]  То есть в модере памяти x86 довольно сильная
[45:05.380 --> 45:12.380]  Там любое чтение по умолчанию имеет семантику aquire, а любая запись имеет по умолчанию семантику релиз
[45:16.380 --> 45:21.380]  На x86 не поможет, но тем не менее это не значит, что можно писать любой релиз
[45:21.380 --> 45:26.380]  То есть если ты пишешь кроссподформенный код, ты должен писать релиз в анлоке
[45:26.380 --> 45:28.380]  Короче, понимаешь меня
[45:28.380 --> 45:34.380]  Но при этом процессор конкретный, от этого выигрыша не получит
[45:34.380 --> 45:36.380]  Но этот не получит, другой получит
[45:36.380 --> 45:40.380]  Поэтому в модере памяти есть такое количество
[45:43.380 --> 45:45.380]  В смысле memory order такое количество
[45:45.380 --> 45:48.380]  Вот у нас здесь есть одна инструкция, а здесь другая
[45:52.380 --> 45:55.380]  Чем-то мы сумели ослабить исполнение
[45:58.380 --> 46:02.380]  Отлично, значит, про причинность поговорили, про happens before поговорили
[46:05.380 --> 46:08.380]  Теперь, наверное, нужно про примеры говорить
[46:08.380 --> 46:12.380]  Ну а relax просто мы никакой гарантии не имеем
[46:13.380 --> 46:15.380]  Relax компилируется...
[46:15.380 --> 46:21.380]  По задумке, relax компилируется просто в голую инструкцию записи и речтения
[46:23.380 --> 46:27.380]  Соответственно, причинность никаким образом не обеспечивается, все эти барьеры не расставляются
[46:27.380 --> 46:31.380]  И ожиданий про другие ячейки делать после чтения relax-то не нужно
[46:31.380 --> 46:33.380]  Атомика с relax-том не нужна
[46:37.380 --> 46:41.380]  Ну, видимо, иногда не нужно форсировать это happens before
[46:41.380 --> 46:44.380]  Ну, я не знаю, ты делаешь счетчик запроса в свою базу данных
[46:45.380 --> 46:47.380]  Ну, просто считаешь и все
[46:47.380 --> 46:49.380]  Ну, вот fetch от relax
[46:53.380 --> 46:56.380]  Надеюсь, успеем, но успеем, конечно, использовать relax сегодня
[46:56.380 --> 46:58.380]  Давай его используем и увидим
[47:06.380 --> 47:09.380]  Ну, во-первых, там все-таки может быть формально не relax
[47:09.380 --> 47:11.380]  Во-вторых, мы разделяем...
[47:14.380 --> 47:17.380]  Ну, сложный вопрос, сейчас я не знаю, наверное, к нему удачно ответить
[47:21.380 --> 47:27.380]  Дизайн ясен, ты хочешь разделить ячейки, которые не испытывают на себе не синхронизированного конкурентного доступа
[47:27.380 --> 47:29.380]  И ячейки, которые испытывают
[47:29.380 --> 47:33.380]  Ну, то есть довольно естественно, давайте классы явно разделить
[47:33.380 --> 47:36.380]  И отдельно про них сравнивать какие-то гарантии
[47:39.380 --> 47:41.380]  У нас формально это не будет?
[47:41.380 --> 47:43.380]  Сейчас, ну, давай я так скажу
[47:43.380 --> 47:52.380]  У тебя есть atomic с операциями relax, потому что, может быть, тебе нужен atomic как интерфейс к атомарным операциям более сложным, чем loadstore
[47:52.380 --> 47:56.380]  Но никакого memory order форсировать там не нужно
[47:58.380 --> 48:01.380]  Вот, а может быть, у тебя может быть один atomic
[48:01.380 --> 48:08.380]  Ну, собственно, у нас будет в примере всего сейчас atomic, где одна операция может быть relax, а другая может быть там release
[48:09.380 --> 48:14.380]  Ну ладно, не бывает такого, что только release, relax, разумеется, должен быть acquire
[48:14.380 --> 48:18.380]  Ну, короче, вот в пределах одного atomic можно использовать прям вот разные варианты
[48:18.380 --> 48:20.380]  Три разных варианта можно использовать
[48:25.380 --> 48:27.380]  Но это все еще атомарный ячейк памяти
[48:27.380 --> 48:31.380]  Она вот как бы вписана в гарантии atomic в модели памяти
[48:31.380 --> 48:33.380]  Разумно ее отделить, мне кажется
[48:33.380 --> 48:35.380]  Давай посмотрим на какой-то пример
[48:35.380 --> 48:40.380]  Ну, пример самый незамысловатый, но нужно его аккуратно обсудить
[48:40.380 --> 48:42.380]  Вот нам нужно написать spinlock
[48:42.380 --> 48:49.380]  И по какому принципу мы в нем будем memory order расставлять?
[48:49.380 --> 48:52.380]  Какими соображениями будем руководствоваться при этом?
[48:52.380 --> 48:54.380]  Это самое важное
[48:54.380 --> 48:58.380]  Вот почему нам нужны, что мы хотим отсекомолвить?
[49:01.380 --> 49:06.380]  Вы знаете, когда мы говорим про упорядочивание, мы уже упорядочивали, что мы уже упорядочивали
[49:06.380 --> 49:09.380]  И мы уже упорядочивали, что мы уже упорядочивали
[49:09.380 --> 49:12.380]  И мы уже упорядочили, что мы уже упорядочили
[49:12.380 --> 49:15.380]  И мы уже упорядочили, что мы уже упорядочили
[49:15.380 --> 49:18.380]  И мы уже упорядочили, что мы уже упорядочили
[49:18.380 --> 49:21.380]  И мы уже упорядочили, что мы уже упорядочили
[49:21.380 --> 49:23.380]  И мы уже упорядочили, что мы уже упорядочили
[49:23.380 --> 49:26.380]  И мы уже упорядочили, что мы уже упорядочили
[49:26.380 --> 49:28.380]  Что мы уже упорядочили
[49:28.380 --> 49:30.380]  Что мы уже упорядочили
[49:32.380 --> 49:38.380]  Смотрите, порядок на атомиках возникает просто в силу исполнения, в силу гарантии матрики памяти
[49:38.380 --> 49:41.380]  На каждом атомике есть порядок за амбисей
[49:41.380 --> 49:44.380]  Не нужно ничего делать, он просто уже есть
[49:44.380 --> 49:47.380]  Определили матрику памяти, у FK шуток
[49:47.380 --> 49:53.380]  Когда мы ставим numRewarder, мы всегда думаем не про атомики
[49:53.380 --> 49:55.380]  Хотя мы уже ставим атомики
[49:55.380 --> 49:58.380]  А мы думаем про не атомики, про не атомарные обращения памяти
[49:58.380 --> 50:00.380]  Потому что мы не на них упорядочили
[50:03.380 --> 50:08.380]  Мы хотим обеспечить видимость happens before без не атомарных обращений памяти
[50:08.380 --> 50:11.380]  И вот такой универсальный ответ
[50:11.380 --> 50:16.380]  Какие не атомарные обращения в памяти мы хотим в этом?
[50:16.380 --> 50:18.380]  С помощью спинлока
[50:22.380 --> 50:25.380]  Те, которые случаются между спинлоком и амблоком
[50:25.380 --> 50:27.380]  Матрическая секция
[50:27.380 --> 50:29.380]  У нас есть спинлок
[50:29.380 --> 50:34.380]  Мы используем спинлок в матрической секции
[50:34.380 --> 50:42.380]  Вот эти матрические секции в разных потомах происходят
[50:42.380 --> 50:45.380]  И эти матрические секции зачем они вообще появились?
[50:45.380 --> 50:49.380]  Потому что, видимо, потоки работают с некоторыми делами состоянными
[50:49.380 --> 50:52.380]  С некоторыми общими ячейками и не читают, а пишут
[50:52.380 --> 50:55.380]  И вот у нас был потом, который обращался с ноги
[50:55.380 --> 50:57.380]  Писал какие-то не атомарные ячейки
[50:57.380 --> 51:00.380]  А другой поток в следующей секции решил прочесть
[51:00.380 --> 51:03.380]  Вот два обращения
[51:03.380 --> 51:05.380]  К одной это же ячейки памяти
[51:05.380 --> 51:07.380]  Конфликтующие пары
[51:07.380 --> 51:09.380]  Конфликтующие пары обращения
[51:09.380 --> 51:11.380]  По крайней мере, одно зависит
[51:11.380 --> 51:13.380]  И в разных потомах
[51:13.380 --> 51:17.380]  Значит, просто по требованиям нашей модели
[51:17.380 --> 51:20.380]  Такие конфликтующие не атомарные обращения
[51:20.380 --> 51:23.380]  Обязанны быть спрятаны, что через хэббл-грифон
[51:23.380 --> 51:25.380]  Но они в разных потомах
[51:25.380 --> 51:27.380]  Значит, хэббл-грифон, как оно образуется?
[51:27.380 --> 51:29.380]  Ну, есть программа ломинг, да?
[51:30.380 --> 51:33.380]  Делать одного потомка
[51:35.380 --> 51:37.380]  А как распишите happens before
[51:37.380 --> 51:40.380]  Между записями и чтениями в разных потомках?
[51:42.380 --> 51:45.380]  Ну, вот happens before складывается из двух компаний
[51:45.380 --> 51:47.380]  Из программа отора и Synchronize with
[51:47.380 --> 51:49.380]  Нужно Synchronize with
[51:49.380 --> 51:52.380]  Вот хорошо, чтобы здесь возник Synchronize with
[51:53.380 --> 51:55.380]  Когда он возникает?
[51:55.380 --> 51:57.380]  Когда есть какой-то атомик, через который
[51:57.380 --> 51:59.380]  Допустим, программируется
[51:59.380 --> 52:02.380]  Когда один потомк читает то, что записал другой
[52:03.380 --> 52:06.380]  Но что делаем мы вот здесь в онлокере?
[52:11.380 --> 52:13.380]  Мы говорим
[52:13.380 --> 52:15.380]  Log
[52:16.380 --> 52:18.380]  Store
[52:18.380 --> 52:20.380]  0
[52:20.380 --> 52:22.380]  Что мы делаем в онлокере?
[52:23.380 --> 52:25.380]  Мы крутимся, да?
[52:25.380 --> 52:27.380]  Мы пишем while
[52:31.380 --> 52:33.380]  Log
[52:35.380 --> 52:37.380]  Exchange 1
[52:41.380 --> 52:45.380]  И вот, когда мы здесь запишем 0
[52:45.380 --> 52:48.380]  И когда мы здесь его увидим мы из циклы
[52:48.380 --> 52:52.380]  То есть мы ждем, пока Exchange не прочтет
[52:52.380 --> 52:55.380]  Ноль записанной где-то в онлокере
[52:56.380 --> 52:57.380]  И вот тогда
[52:57.380 --> 52:59.380]  Говорят их и начинают заслуживаться
[52:59.380 --> 53:01.380]  Если у нас будет между вот этим онлоком
[53:01.380 --> 53:03.380]  И этим локом станет заслуживаться
[53:03.380 --> 53:05.380]  То значит будет пример позже порт
[53:05.380 --> 53:07.380]  Принадлительности отначить
[53:09.380 --> 53:11.380]  Вот это чтение оказывает увидеть
[53:11.380 --> 53:14.380]  Свету записи из предшествующей секции
[53:14.380 --> 53:16.380]  Ну это вроде бы то, что мы добивались
[53:16.380 --> 53:19.380]  Но теперь можно ослабить наши номере ордеры
[53:19.380 --> 53:21.380]  Программа ордера у нас так будет
[53:21.380 --> 53:22.380]  Что бы мы не делали
[53:22.380 --> 53:24.380]  Какие номере ордера мы не оставили
[53:24.380 --> 53:26.380]  А сентябрьисуис возникает либо между
[53:26.380 --> 53:27.380]  Секунджской консистенцией
[53:27.380 --> 53:28.380]  И чтением
[53:28.380 --> 53:30.380]  Либо между лидерами
[53:30.380 --> 53:33.380]  Кажется, что можно здесь ослабить до релиза
[53:35.380 --> 53:37.380]  Ну и вот
[53:37.380 --> 53:38.380]  И вот
[53:38.380 --> 53:39.380]  И вот
[53:39.380 --> 53:40.380]  И вот
[53:40.380 --> 53:41.380]  И вот
[53:41.380 --> 53:42.380]  И вот
[53:42.380 --> 53:43.380]  И вот
[53:45.380 --> 53:48.380]  Оно здесь ослабится в металличном доме ордера
[53:51.380 --> 53:52.380]  Ну вот смотрите
[53:52.380 --> 53:53.380]  У нас здесь
[53:53.380 --> 53:55.380]  Чтение это операция
[53:55.380 --> 53:56.380]  Она более сложная
[53:56.380 --> 53:57.380]  И чем просто чтение
[53:57.380 --> 53:58.380]  Она и чтение, и запис
[53:59.380 --> 54:01.380]  В данном случае нам не важно
[54:01.380 --> 54:02.380]  Тут есть запись
[54:02.380 --> 54:03.380]  Нам важно, что это чтение
[54:03.380 --> 54:05.380]  И вот это чтение должно быть аккуратно
[54:12.380 --> 54:14.380]  Чтобы здесь возникло сентябрьисуис
[54:14.380 --> 54:15.380]  Чтобы мы получили
[54:15.380 --> 54:17.380]  Ну почему-то там не важно, что это еще и запись
[54:17.380 --> 54:18.380]  Ну как бы
[54:18.380 --> 54:19.380]  Ну это благо
[54:19.380 --> 54:20.380]  Как мы собираемся использовать
[54:20.380 --> 54:21.380]  Что нам нужно
[54:21.380 --> 54:22.380]  Нам нужно обеспечить
[54:22.380 --> 54:24.380]  У порядка, что они не томатно отборщены в памяти
[54:24.380 --> 54:26.380]  Через каком-либо форме лидерической инсекции
[54:26.380 --> 54:28.380]  Ну вот мы обеспечены
[54:28.380 --> 54:30.380]  Просто у нас может быть два спинного позиций
[54:32.380 --> 54:34.380]  Я еще не понимаю
[54:34.380 --> 54:36.380]  Что-то ну два спинного, а у них две
[54:36.380 --> 54:38.380]  Ну и они должны
[54:38.380 --> 54:40.380]  Кажется, что между лидерическими секциями
[54:40.380 --> 54:41.380]  Дороза спинного
[54:41.380 --> 54:42.380]  И тут гарантии нет
[54:47.380 --> 54:48.380]  Я так говорю
[54:49.380 --> 54:51.380]  У нас на блоке они совершенно независимы
[54:51.380 --> 54:53.380]  Ну они могут
[54:53.380 --> 54:54.380]  Exchange единица
[54:54.380 --> 54:56.380]  Нам нужно, чтобы ровно один
[54:56.380 --> 54:57.380]  Минут пиломан
[54:57.380 --> 54:58.380]  Второй
[54:58.380 --> 54:59.380]  И
[54:59.380 --> 55:01.380]  Кто-то, кто видит, может поставить
[55:01.380 --> 55:02.380]  Диаминсу
[55:02.380 --> 55:03.380]  И второй должен быть
[55:03.380 --> 55:04.380]  Диаминс
[55:04.380 --> 55:05.380]  Ну это же вот
[55:07.380 --> 55:09.380]  У нас есть один андроид
[55:09.380 --> 55:11.380]  И вот на нем есть modification order
[55:16.380 --> 55:17.380]  Modification order
[55:17.380 --> 55:18.380]  Мог есть всегда
[55:18.380 --> 55:19.380]  Даже если
[55:20.380 --> 55:21.380]  Даже если
[55:22.380 --> 55:23.380]  Тут такая базовая гарантия
[55:30.380 --> 55:31.380]  А я не помню
[55:31.380 --> 55:32.380]  Объяснял я вам почему
[55:33.380 --> 55:34.380]  Из modification order
[55:34.380 --> 55:35.380]  Ну в смысле
[55:35.380 --> 55:36.380]  Что
[55:36.380 --> 55:37.380]  Modification order
[55:37.380 --> 55:38.380]  Modification order
[55:38.380 --> 55:39.380]  Понятно, сквозной на одном лампке
[55:39.380 --> 55:40.380]  Из него не следует
[55:41.380 --> 55:42.380]  Modification order
[55:42.380 --> 55:43.380]  Понятно или нет?
[55:45.380 --> 55:46.380]  Ну вот скажем
[55:46.380 --> 55:47.380]  Программа такая
[55:47.380 --> 55:48.380]  У нас есть четыре потомка
[55:48.380 --> 55:49.380]  Один пишет в X
[55:50.380 --> 55:51.380]  Другой пишет в Y
[55:55.380 --> 55:56.380]  Третий
[55:56.380 --> 55:57.380]  Читает
[55:59.380 --> 56:00.380]  Из X
[56:00.380 --> 56:01.380]  Читает
[56:02.380 --> 56:03.380]  Из Y
[56:04.380 --> 56:05.380]  Четает
[56:07.380 --> 56:08.380]  Из Y
[56:09.380 --> 56:10.380]  Читает
[56:11.380 --> 56:12.380]  Из X
[56:13.380 --> 56:14.380]  И можно ли увидеть
[56:14.380 --> 56:15.380]  Один ноль, один ноль?
[56:16.380 --> 56:17.380]  Можно
[56:17.380 --> 56:18.380]  Если мы используем
[56:19.380 --> 56:20.380]  Remaxed
[56:20.380 --> 56:21.380]  или API release
[56:25.380 --> 56:26.380]  Вот потому что вот на каждом
[56:26.380 --> 56:27.380]  Оторнике
[56:27.380 --> 56:28.380]  Сносится на каждый
[56:28.380 --> 56:29.380]  Ичейкин
[56:29.380 --> 56:30.380]  Будет modification order здесь
[56:30.380 --> 56:31.380]  То есть все записи
[56:31.380 --> 56:32.380]  Они у нас Remaxed
[56:37.380 --> 56:38.380]  На каждой ячейке
[56:38.380 --> 56:39.380]  Есть modification order
[56:39.380 --> 56:40.380]  Ноль, один
[56:40.380 --> 56:41.380]  И этот поток читает
[56:41.380 --> 56:42.380]  Пусть
[56:42.380 --> 56:43.380]  Ноль
[56:43.380 --> 56:44.380]  А этот читает
[56:44.380 --> 56:45.380]  Пусть, один
[56:45.380 --> 56:46.380]  А этот поток
[56:46.380 --> 56:47.380]  Саксона, ноль
[56:47.380 --> 56:48.380]  Но это равные
[56:48.380 --> 56:49.380]  В порядке нерасогласованные
[56:49.380 --> 56:50.380]  В итоге
[56:50.380 --> 56:51.380]  Будут видеть
[56:51.380 --> 56:52.380]  Два потока
[56:52.380 --> 56:53.380]  Как будто бы
[56:53.380 --> 56:54.380]  Наблюдают
[56:54.380 --> 56:55.380]  Разную
[56:55.380 --> 56:56.380]  Разную
[56:56.380 --> 56:57.380]  Последовательную
[56:57.380 --> 56:58.380]  Запись
[56:58.380 --> 56:59.380]  Две ячейки
[56:59.380 --> 57:00.380]  Но это modification order
[57:00.380 --> 57:01.380]  В них не представляется
[57:04.380 --> 57:06.380]  У таких примеров есть
[57:06.380 --> 57:07.380]  Называется
[57:07.380 --> 57:08.380]  Independent reads
[57:08.380 --> 57:09.380]  or
[57:09.380 --> 57:10.380]  Independent writes
[57:15.380 --> 57:16.380]  Ну вот
[57:16.380 --> 57:17.380]  Спинок мы разбрали
[57:17.380 --> 57:18.380]  Да?
[57:18.380 --> 57:19.380]  Не впечатляю
[57:20.380 --> 57:21.380]  Еще раз
[57:21.380 --> 57:22.380]  Обращаю внимание
[57:22.380 --> 57:23.380]  Что
[57:24.380 --> 57:25.380]  Мы
[57:25.380 --> 57:26.380]  Оставляем
[57:26.380 --> 57:27.380]  Мои ордеры
[57:27.380 --> 57:28.380]  Думая не про атомики
[57:28.380 --> 57:29.380]  А думая
[57:29.380 --> 57:30.380]  Наоборот
[57:30.380 --> 57:31.380]  Про неатоматные
[57:31.380 --> 57:32.380]  Ячейки в памяти
[57:32.380 --> 57:33.380]  Собственно
[57:33.380 --> 57:34.380]  Доступ Которые
[57:34.380 --> 57:35.380]  Мы не упорядочно
[57:35.380 --> 57:36.380]  Всегда
[57:36.380 --> 57:37.380]  Нужно думать
[57:37.380 --> 57:38.380]  Про
[57:38.380 --> 57:39.380]  Эти самые
[57:39.380 --> 57:40.380]  Обращения
[57:40.380 --> 57:41.380]  Снаружи
[57:41.380 --> 57:42.380]  Которые
[57:42.380 --> 57:43.380]  Кодятся
[57:43.380 --> 57:44.380]  На блоке
[57:44.380 --> 57:45.380]  Вообщения
[57:45.380 --> 57:46.380]  А вот
[57:46.380 --> 57:47.380]  Про пример
[57:47.380 --> 57:48.380]  Где мы
[57:48.380 --> 57:49.380]  Считаем
[57:49.380 --> 57:50.380]  Количество
[57:50.380 --> 57:51.380]  Просто
[57:51.380 --> 57:52.380]  Хороших обращений
[57:52.380 --> 57:53.380]  Мы же там
[57:53.380 --> 57:54.380]  Не можем
[57:54.380 --> 57:55.380]  Сделать
[57:55.380 --> 57:56.380]  Неатоматных
[57:56.380 --> 57:57.380]  Потому что
[57:57.380 --> 57:58.380]  Прямо скажем
[57:58.380 --> 57:59.380]  Нам нужен фичет
[57:59.380 --> 58:00.380]  Да
[58:00.380 --> 58:01.380]  То есть
[58:01.380 --> 58:02.380]  Мы пользуемся
[58:02.380 --> 58:03.380]  Здесь тем
[58:03.380 --> 58:04.380]  Что атомик
[58:04.380 --> 58:05.380]  Не используется
[58:05.380 --> 58:06.380]  Для упорядоченного
[58:06.380 --> 58:07.380]  Не обращения
[58:07.380 --> 58:08.380]  К памяти
[58:08.380 --> 58:09.380]  То есть
[58:09.380 --> 58:10.380]  Не то, что мы
[58:10.380 --> 58:11.380]  Не читаем
[58:11.380 --> 58:12.380]  Какие-то
[58:12.380 --> 58:13.380]  Еще 4 квеста
[58:13.380 --> 58:14.380]  Думаем
[58:14.380 --> 58:15.380]  А вот
[58:15.380 --> 58:16.380]  Значит
[58:16.380 --> 58:17.380]  Какая-то
[58:17.380 --> 58:18.380]  Другая ячейка
[58:18.380 --> 58:19.380]  В программе
[58:19.380 --> 58:20.380]  Тоже что-то
[58:20.380 --> 58:21.380]  Там равна
[58:21.380 --> 58:22.380]  Или что-то там
[58:22.380 --> 58:23.380]  Соединить
[58:23.380 --> 58:24.380]  Мы так и думаем
[58:24.380 --> 58:25.380]  Поэтому для таких
[58:25.380 --> 58:26.380]  Сцена
[58:26.380 --> 58:27.380]  Релакса достаточно
[58:27.380 --> 58:28.380]  Итак
[58:28.380 --> 58:29.380]  Значит
[58:29.380 --> 58:30.380]  Мы здесь
[58:30.380 --> 58:31.380]  Думали про неатомарные
[58:31.380 --> 58:32.380]  Ячейки памяти
[58:32.380 --> 58:33.380]  И возвращаемся
[58:33.380 --> 58:46.640]  В
[58:46.640 --> 58:49.640]  Так что вот
[58:49.640 --> 58:50.640]  Для порядка
[58:50.640 --> 58:51.640]  Здесь мы напишем
[58:51.640 --> 58:56.640]  Релиз
[58:56.640 --> 58:57.640]  А здесь мы напишем
[58:57.640 --> 59:06.640]  И идем дальше
[59:06.640 --> 59:07.640]  Следующий пример
[59:07.640 --> 59:08.640]  Это
[59:08.640 --> 59:09.640]  Ну мы его уже видели
[59:09.640 --> 59:10.640]  В лекции про кэши
[59:10.640 --> 59:13.140]  Это циклический буфер
[59:13.140 --> 59:21.640]  Массив фиксированного размера
[59:21.640 --> 59:22.640]  С ним работают
[59:22.640 --> 59:23.640]  Два потока
[59:23.640 --> 59:24.640]  Один поток
[59:24.640 --> 59:25.640]  Почему-то я сбросил
[59:25.640 --> 59:26.640]  Все хорошие названия
[59:26.640 --> 59:27.640]  Отлично
[59:27.640 --> 59:28.640]  Один поток
[59:28.640 --> 59:29.640]  Продюсер
[59:29.640 --> 59:30.640]  Пытается в этот
[59:30.640 --> 59:31.640]  Циклический буфер
[59:31.640 --> 59:32.640]  Что-то писать
[59:32.640 --> 59:33.640]  Для этого
[59:33.640 --> 59:34.640]  Он читает хед
[59:34.640 --> 59:35.640]  Читает тейл
[59:35.640 --> 59:36.640]  Смотрит если
[59:36.640 --> 59:37.640]  Тейл
[59:37.640 --> 59:38.640]  Еще не догнал хед
[59:38.640 --> 59:39.640]  То
[59:39.640 --> 59:40.640]  Пишет
[59:40.640 --> 59:41.640]  В буфер
[59:41.640 --> 59:42.640]  По индексу
[59:42.640 --> 59:43.640]  Тейл
[59:43.640 --> 59:44.640]  И двигает
[59:44.640 --> 59:45.640]  Тейл вперед
[59:45.640 --> 59:46.640]  Ну с учетом
[59:46.640 --> 59:47.640]  За циклический
[59:47.640 --> 59:48.640]  Буфер
[59:48.640 --> 59:49.640]  По индексу
[59:49.640 --> 59:50.640]  Тейл
[59:50.640 --> 59:51.640]  И двигает
[59:51.640 --> 59:52.640]  Тейл вперед
[59:52.640 --> 59:53.640]  Ну с учетом
[59:53.640 --> 59:54.640]  Ну с учетом
[59:54.640 --> 59:55.640]  За цикливание
[59:55.640 --> 59:56.640]  Консьем
[59:56.640 --> 59:57.640]  Действует симметрично
[59:57.640 --> 59:58.640]  Читает хед
[59:58.640 --> 59:59.640]  Читает тейл
[59:59.640 --> 01:00:00.640]  Смотрит если
[01:00:00.640 --> 01:00:01.640]  Буфер
[01:00:01.640 --> 01:00:02.640]  Не пуст
[01:00:02.640 --> 01:00:03.640]  То извлекает
[01:00:03.640 --> 01:00:04.640]  Элемент из головы
[01:00:04.640 --> 01:00:05.640]  Буфера
[01:00:05.640 --> 01:00:06.640]  И двигает
[01:00:06.640 --> 01:00:07.640]  Тейл
[01:00:07.640 --> 01:00:08.640]  Хед
[01:00:08.640 --> 01:00:09.640]  Вперед
[01:00:09.640 --> 01:00:10.640]  Вот мы на лекции
[01:00:10.640 --> 01:00:11.640]  Про кэши
[01:00:11.640 --> 01:00:12.640]  Оптимизировали здесь
[01:00:12.640 --> 01:00:13.640]  Работу
[01:00:13.640 --> 01:00:14.640]  Оптимизировали
[01:00:14.640 --> 01:00:15.640]  Фолл шеринг
[01:00:15.640 --> 01:00:16.640]  Так чтобы
[01:00:16.640 --> 01:00:17.640]  Продюсеры
[01:00:17.640 --> 01:00:18.640]  И консюмер
[01:00:18.640 --> 01:00:19.640]  Работали с разными
[01:00:19.640 --> 01:00:20.640]  Шлиниями
[01:00:20.640 --> 01:00:21.640]  Когда они
[01:00:21.640 --> 01:00:22.640]  Добавляют хвост
[01:00:22.640 --> 01:00:23.640]  Извлекают из головы
[01:00:23.640 --> 01:00:24.640]  Но сейчас у нас
[01:00:24.640 --> 01:00:25.640]  Другая забота
[01:00:25.640 --> 01:00:26.640]  Сейчас мы
[01:00:26.640 --> 01:00:27.640]  Пытаемся расставить
[01:00:27.640 --> 01:00:28.640]  Оптимальные
[01:00:28.640 --> 01:00:29.640]  Memory order здесь
[01:00:29.640 --> 01:00:30.640]  Про кэши
[01:00:30.640 --> 01:00:31.640]  Можно подумать
[01:00:31.640 --> 01:00:32.640]  Ну в смысле
[01:00:32.640 --> 01:00:33.640]  С кэшами
[01:00:33.640 --> 01:00:34.640]  Там можно скомбинировать
[01:00:34.640 --> 01:00:35.640]  Ну давайте
[01:00:35.640 --> 01:00:36.640]  Подумаем
[01:00:36.640 --> 01:00:37.640]  Какие memory order
[01:00:37.640 --> 01:00:38.640]  Можно здесь
[01:00:38.640 --> 01:00:39.640]  Ну в принципе
[01:00:39.640 --> 01:00:40.640]  Поставить
[01:00:40.640 --> 01:00:41.640]  Смотрите
[01:00:41.640 --> 01:00:42.640]  У нас есть
[01:00:42.640 --> 01:00:43.640]  Два потока
[01:00:43.640 --> 01:00:44.640]  Они общаются
[01:00:44.640 --> 01:00:45.640]  Между собой
[01:00:45.640 --> 01:00:46.640]  Один другому
[01:00:46.640 --> 01:00:47.640]  Посылает
[01:00:47.640 --> 01:00:48.640]  Другой
[01:00:48.640 --> 01:00:49.640]  Извлекает
[01:00:49.640 --> 01:00:50.640]  Обрабатывает
[01:00:50.640 --> 01:00:51.640]  Продюсер
[01:00:51.640 --> 01:00:52.640]  Видимо
[01:00:52.640 --> 01:00:53.640]  Тут нам
[01:00:53.640 --> 01:00:54.640]  Не нужен
[01:00:54.640 --> 01:00:55.640]  Никакой
[01:00:55.640 --> 01:00:56.640]  Sequential consistency
[01:00:56.640 --> 01:00:57.640]  Нам будет
[01:00:57.640 --> 01:00:58.640]  Достаточно
[01:00:58.640 --> 01:00:59.640]  Happens before
[01:00:59.640 --> 01:01:00.640]  То есть
[01:01:00.640 --> 01:01:01.640]  Release acquire
[01:01:01.640 --> 01:01:02.640]  Наверное
[01:01:02.640 --> 01:01:03.640]  Но
[01:01:09.640 --> 01:01:10.640]  Но кое-что
[01:01:10.640 --> 01:01:11.640]  Можно заметить
[01:01:11.640 --> 01:01:12.640]  Сразу
[01:01:12.640 --> 01:01:13.640]  Смотрите
[01:01:13.640 --> 01:01:14.640]  Вот есть
[01:01:14.640 --> 01:01:15.640]  Продюсер
[01:01:15.640 --> 01:01:16.640]  Он читает
[01:01:16.640 --> 01:01:17.640]  Head и tail
[01:01:17.640 --> 01:01:18.640]  А потом
[01:01:18.640 --> 01:01:19.640]  После того
[01:01:19.640 --> 01:01:20.640]  Как положит
[01:01:20.640 --> 01:01:21.640]  Tail
[01:01:21.640 --> 01:01:22.640]  И больше
[01:01:22.640 --> 01:01:23.640]  Никто
[01:01:23.640 --> 01:01:24.640]  Кроме него
[01:01:24.640 --> 01:01:25.640]  Tail не двигает
[01:01:25.640 --> 01:01:26.640]  То есть вот
[01:01:26.640 --> 01:01:27.640]  Tail
[01:01:27.640 --> 01:01:28.640]  Меняет
[01:01:28.640 --> 01:01:29.640]  Только один
[01:01:29.640 --> 01:01:30.640]  Поток
[01:01:30.640 --> 01:01:31.640]  Вот это
[01:01:31.640 --> 01:01:32.640]  Означает
[01:01:32.640 --> 01:01:33.640]  Что здесь
[01:01:33.640 --> 01:01:34.640]  Можно
[01:01:34.640 --> 01:01:35.640]  Поставить
[01:01:35.640 --> 01:01:36.640]  Relax
[01:01:36.640 --> 01:01:37.640]  Потому что
[01:01:37.640 --> 01:01:38.640]  Просто
[01:01:38.640 --> 01:01:39.640]  В силу свойств
[01:01:39.640 --> 01:01:40.640]  В смысле
[01:01:40.640 --> 01:01:41.640]  Однопоточный
[01:01:41.640 --> 01:01:42.640]  Код
[01:01:42.640 --> 01:01:43.640]  Обязан
[01:01:43.640 --> 01:01:44.640]  Свои же
[01:01:44.640 --> 01:01:45.640]  Записи
[01:01:45.640 --> 01:01:46.640]  Видеть
[01:01:46.640 --> 01:01:47.640]  Поэтому нам
[01:01:47.640 --> 01:01:48.640]  Никакие
[01:01:48.640 --> 01:01:49.640]  Больеры здесь
[01:01:49.640 --> 01:01:50.640]  Двигает
[01:01:50.640 --> 01:01:51.640]  Вперед
[01:01:51.640 --> 01:01:52.640]  Head
[01:01:52.640 --> 01:01:53.640]  Поэтому он
[01:01:53.640 --> 01:01:54.640]  Своё собственное значение
[01:01:54.640 --> 01:01:55.640]  Тоже всегда
[01:01:55.640 --> 01:01:56.640]  Видит
[01:01:56.640 --> 01:02:03.640]  Ну а теперь
[01:02:03.640 --> 01:02:04.640]  Подумаем
[01:02:04.640 --> 01:02:05.640]  Какие
[01:02:05.640 --> 01:02:06.640]  Не
[01:02:06.640 --> 01:02:07.640]  Атомарные
[01:02:07.640 --> 01:02:08.640]  Обращения
[01:02:08.640 --> 01:02:09.640]  Мы хотим
[01:02:09.640 --> 01:02:10.640]  Упорядочивать
[01:02:10.640 --> 01:02:11.640]  Строчки скажи
[01:02:11.640 --> 01:02:12.640]  29
[01:02:12.640 --> 01:02:13.640]  Ещё раз
[01:02:13.640 --> 01:02:14.640]  Я повторяю
[01:02:14.640 --> 01:02:15.640]  Что
[01:02:15.640 --> 01:02:16.640]  Упорядочиваем
[01:02:16.640 --> 01:02:17.640]  Всегда не
[01:02:17.640 --> 01:02:18.640]  Атомарные
[01:02:18.640 --> 01:02:19.640]  Обращения
[01:02:19.640 --> 01:02:20.640]  К памяти
[01:02:20.640 --> 01:02:21.640]  Если ты
[01:02:21.640 --> 01:02:22.640]  Думаешь про
[01:02:22.640 --> 01:02:23.640]  Атомики
[01:02:23.640 --> 01:02:24.640]  То ты думаешь
[01:02:24.640 --> 01:02:25.640]  Не в ту сторону
[01:02:25.640 --> 01:02:26.640]  Ты неправильно
[01:02:26.640 --> 01:02:27.640]  Пользуешься
[01:02:27.640 --> 01:02:28.640]  Модой памяти
[01:02:28.640 --> 01:02:29.640]  Memory order
[01:02:29.640 --> 01:02:30.640]  Для упорядочивания
[01:02:30.640 --> 01:02:31.640]  Не атомарных
[01:02:31.640 --> 01:02:32.640]  Обращений
[01:02:32.640 --> 01:02:33.640]  Вот какие
[01:02:33.640 --> 01:02:34.640]  Не атомарные
[01:02:34.640 --> 01:02:35.640]  Обращения
[01:02:35.640 --> 01:02:36.640]  Нужно упорядочивать
[01:02:36.640 --> 01:02:37.640]  Какие
[01:02:37.640 --> 01:02:38.640]  Не атомарные
[01:02:38.640 --> 01:02:39.640]  Обращения
[01:02:39.640 --> 01:02:40.640]  Подумать
[01:02:40.640 --> 01:02:41.640]  Какие
[01:02:41.640 --> 01:02:42.640]  Попробуем
[01:02:42.640 --> 01:02:43.640]  Упорядочивать
[01:02:43.640 --> 01:02:44.640]  Какие
[01:02:44.640 --> 01:02:45.640]  Записи должны быть
[01:02:45.640 --> 01:02:46.640]  Видны
[01:02:46.640 --> 01:02:47.640]  Каким
[01:02:47.640 --> 01:02:48.640]  Чтением
[01:02:48.640 --> 01:02:49.640]  Ну
[01:02:49.640 --> 01:02:50.640]  Из
[01:02:50.640 --> 01:02:51.640]  Empty
[01:02:51.640 --> 01:02:52.640]  На
[01:02:52.640 --> 01:02:53.640]  Тридцать первой
[01:02:53.640 --> 01:02:54.640]  Строчки
[01:02:54.640 --> 01:02:55.640]  Должны
[01:02:55.640 --> 01:02:56.640]  Видеть
[01:02:56.640 --> 01:02:57.640]  Что
[01:02:57.640 --> 01:02:58.640]  Мы
[01:02:58.640 --> 01:02:59.640]  Мне вот
[01:02:59.640 --> 01:03:00.640]  Из Empty
[01:03:00.640 --> 01:03:01.640]  Кажется
[01:03:01.640 --> 01:03:02.640]  Работает
[01:03:02.640 --> 01:03:03.640]  С двумя
[01:03:03.640 --> 01:03:04.640]  Регистрами
[01:03:04.640 --> 01:03:05.640]  Ммм
[01:03:05.640 --> 01:03:06.640]  Но мы
[01:03:06.640 --> 01:03:07.640]  Уже положили
[01:03:07.640 --> 01:03:08.640]  А
[01:03:08.640 --> 01:03:12.640]  а потом мы в консьюме из этого буфера читаем.
[01:03:12.640 --> 01:03:17.640]  Ну вот для примера, пусть у нас есть слот 42,
[01:03:17.640 --> 01:03:20.640]  и продюсер сначала пишет слот 42,
[01:03:20.640 --> 01:03:24.640]  а потом консьюмер когда-нибудь читает из слота 42.
[01:03:24.640 --> 01:03:27.640]  Вот это одна и та же чейка памяти.
[01:03:27.640 --> 01:03:29.640]  К ней есть два конкретующих обращения,
[01:03:29.640 --> 01:03:33.640]  записи здесь и чтение здесь, из разных потоков.
[01:03:33.640 --> 01:03:37.640]  Поэтому они должны быть упорядочно через HappensBefore, думаем мы.
[01:03:37.640 --> 01:03:40.640]  А вот дальше думаем, как это обеспечить HappensBefore
[01:03:40.640 --> 01:03:42.640]  между двумя этими обращениями.
[01:03:50.640 --> 01:03:52.640]  Ну давай помедленнее.
[01:03:52.640 --> 01:03:57.640]  Вот я, поток-продюсер, что я делаю?
[01:03:57.640 --> 01:04:01.640]  Я пишу в слот 42 значение x.
[01:04:01.640 --> 01:04:08.640]  Потом я пишу в tail 43.
[01:04:08.640 --> 01:04:14.640]  Потом я, продюсер, пишу в слот 43 y.
[01:04:14.640 --> 01:04:19.640]  Потом я пишу в tail 44.
[01:04:19.640 --> 01:04:21.640]  Потом проходит еще много времени,
[01:04:21.640 --> 01:04:28.640]  потом я что-то еще делаю, пишу в tail значение 51.
[01:04:29.640 --> 01:04:32.640]  Консьюмер пусть пока сейчас не исполняется.
[01:04:32.640 --> 01:04:37.640]  Потом возникает консьюмер, он читает Head.
[01:04:37.640 --> 01:04:43.640]  Ну как вообще консьюмер мог дойти до чтения слота 42?
[01:04:46.640 --> 01:04:48.640]  Вот здесь вот.
[01:04:48.640 --> 01:04:50.640]  Что он должен был для этого увидеть?
[01:04:50.640 --> 01:04:54.640]  Ну видимо он должен был прочесть из Head 42.
[01:04:55.640 --> 01:05:02.640]  А чтобы читать слот 42, он должен быть уверен,
[01:05:02.640 --> 01:05:05.640]  что буфер не пуст.
[01:05:05.640 --> 01:05:08.640]  То есть, что tail больше, чем 42.
[01:05:08.640 --> 01:05:14.640]  Ну и вот допустим, консьюмер прочел из tail 51.
[01:05:14.640 --> 01:05:17.640]  Какие выводы из этого делает консьюмер?
[01:05:17.640 --> 01:05:19.640]  Что видимо буфер точно не пуст,
[01:05:19.640 --> 01:05:24.640]  и что в слот 42 продюсер уж точно записал.
[01:05:24.640 --> 01:05:26.640]  Ну потому что вот написал он здесь,
[01:05:26.640 --> 01:05:31.640]  а перед этим он написал много раз в последующие слоты,
[01:05:31.640 --> 01:05:35.640]  значит и в 42 уже тоже написал.
[01:05:35.640 --> 01:05:37.640]  Ну то есть вот мы пользуемся причинностью.
[01:05:37.640 --> 01:05:41.640]  Если мы увидели в tail 51, то мы уверены,
[01:05:41.640 --> 01:05:48.640]  что продюсер написал уже в слот 50, 49, 48 и так далее, 42.
[01:05:49.640 --> 01:05:51.640]  Ну а чем это, то есть это причина,
[01:05:51.640 --> 01:05:53.640]  с которой программист ожидает,
[01:05:53.640 --> 01:05:56.640]  а чем она обеспечивается в коде?
[01:05:56.640 --> 01:06:00.640]  Ну видимо synchronizes with happens before synchronizes with.
[01:06:00.640 --> 01:06:02.640]  Ну и как мы это сделаем?
[01:06:02.640 --> 01:06:09.640]  Мы вот здесь напишем видимо release, да?
[01:06:09.640 --> 01:06:12.640]  А здесь мы напишем...
[01:06:15.640 --> 01:06:18.640]  Ну вот, мы добились чего хотели.
[01:06:19.640 --> 01:06:22.640]  Но у нас осталось еще что-то, вроде бы пока это все не нужно.
[01:06:22.640 --> 01:06:26.640]  Давайте мы поступим оптимистично.
[01:06:28.640 --> 01:06:30.640]  Здесь что еще осталось?
[01:06:30.640 --> 01:06:32.640]  А, вот здесь еще.
[01:06:36.640 --> 01:06:38.640]  Ну ничего, вспомнишь.
[01:06:38.640 --> 01:06:41.640]  Тут 4 строчки, в смысле 6 строчек.
[01:06:41.640 --> 01:06:44.640]  Оперативный памятник человека, 7 элементов.
[01:06:44.640 --> 01:06:46.640]  Можно запомнить.
[01:06:46.640 --> 01:06:48.640]  Да, мы не исчерпали еще.
[01:06:48.640 --> 01:06:53.640]  Ну вот, смотри, здесь мы читаем собственный tail, да?
[01:06:53.640 --> 01:06:56.640]  Вот здесь, поэтому нам не нужен никакой memory order.
[01:06:56.640 --> 01:06:58.640]  Мы свои записи собственные видим в платоке.
[01:06:58.640 --> 01:07:01.640]  Здесь мы пишем release в продюсере для того,
[01:07:01.640 --> 01:07:04.640]  чтобы консюмер, который увидел наш tail,
[01:07:04.640 --> 01:07:09.640]  был уверен, что он увидит и записи,
[01:07:09.640 --> 01:07:13.640]  предшествующие этому tail у слоты продюсеру.
[01:07:14.640 --> 01:07:16.640]  Вроде все логично.
[01:07:16.640 --> 01:07:18.640]  И теперь можно запустить вот этот код,
[01:07:18.640 --> 01:07:20.640]  который запускает два потока,
[01:07:20.640 --> 01:07:23.640]  запускает их под ThreadSanitizer.
[01:07:30.640 --> 01:07:33.640]  И посмотреть, что произойдет.
[01:07:38.640 --> 01:07:40.640]  Произошел DataRace.
[01:07:40.640 --> 01:07:42.640]  DataRace чего с чем?
[01:07:42.640 --> 01:07:45.640]  Try produce строчка 22
[01:07:45.640 --> 01:07:49.640]  и try consume строчка 46.
[01:07:49.640 --> 01:07:53.640]  Подозрительно, потому что мы это упорядочили.
[01:07:55.640 --> 01:07:58.640]  Но на самом деле немного хитрее все.
[01:07:58.640 --> 01:08:01.640]  И даже по этому отчету можно понять,
[01:08:01.640 --> 01:08:03.640]  что несколько хитрее.
[01:08:03.640 --> 01:08:06.640]  Есть у вас идеи, что пошло не так?
[01:08:09.640 --> 01:08:15.640]  Потому что ThreadSanitizer здесь дает вам подсказку.
[01:08:18.640 --> 01:08:20.640]  Не то чтобы он про нашу программу что-то знает,
[01:08:20.640 --> 01:08:22.640]  но...
[01:08:23.640 --> 01:08:25.640]  В общем.
[01:08:25.640 --> 01:08:28.640]  Объясните мне, почему мы получили DataRace,
[01:08:28.640 --> 01:08:31.640]  хотя мы упорядочили продюсера и консюмера?
[01:08:56.640 --> 01:08:58.640]  Когда надо переписывать?
[01:08:58.640 --> 01:09:00.640]  Когда надо переписывать?
[01:09:00.640 --> 01:09:01.640]  Что нужно, простите.
[01:09:01.640 --> 01:09:03.640]  Как меня переписывать?
[01:09:03.640 --> 01:09:05.640]  Да нет, нужно переписывать программиста.
[01:09:05.640 --> 01:09:07.640]  В смысле поменять.
[01:09:10.640 --> 01:09:12.640]  Ну чего, нет идей?
[01:09:13.640 --> 01:09:15.640]  Вот смотрите же, тут что-то идет...
[01:09:15.640 --> 01:09:19.640]  В смысле, вроде бы мы исправили RACE
[01:09:19.640 --> 01:09:23.640]  между упорядочили записи чтения, да?
[01:09:23.640 --> 01:09:26.640]  Упорядки у нас снова, записи чтения.
[01:09:26.640 --> 01:09:29.640]  Но тут написано интереснее, что у нас продюс,
[01:09:29.640 --> 01:09:32.640]  то есть вот эта запись, она гоняется
[01:09:32.640 --> 01:09:36.640]  с предшествующим консюмом.
[01:09:43.640 --> 01:09:45.640]  Нужно понять, что происходит.
[01:09:45.640 --> 01:09:47.640]  Прежде чем что-то исправлять,
[01:09:47.640 --> 01:09:50.640]  всегда в любом баге нужно понять, в чем он состоит.
[01:09:50.640 --> 01:09:53.640]  Мы упорядочили продюс и консюм, да?
[01:09:53.640 --> 01:09:56.640]  Но при этом у нас транслятор говорит про другое.
[01:09:56.640 --> 01:10:00.640]  Он говорит, что у нас сейчас продюс в этой строчке
[01:10:00.640 --> 01:10:04.640]  гоняется с вниманием предшествующим консюмом
[01:10:04.640 --> 01:10:06.640]  вот в этой строчке.
[01:10:10.640 --> 01:10:12.640]  Нужно подумать.
[01:10:12.640 --> 01:10:14.640]  Нет, не получается.
[01:10:17.640 --> 01:10:19.640]  У нас буфер циклический.
[01:10:20.640 --> 01:10:24.640]  Мы упорядочили первый продюс с первым консюмом.
[01:10:24.640 --> 01:10:27.640]  То есть первую запись слота 42,
[01:10:27.640 --> 01:10:29.640]  с первым чтением из слота 42.
[01:10:29.640 --> 01:10:31.640]  А дальше у нас буфер загругляется,
[01:10:31.640 --> 01:10:33.640]  и мы снова пишем 42.
[01:10:33.640 --> 01:10:37.640]  И вот мы первое чтение не упорядочили со второй записью.
[01:10:40.640 --> 01:10:45.640]  То есть смотрите, вот мы здесь, уже в продюсере,
[01:10:45.640 --> 01:10:47.640]  прочли хед,
[01:10:47.640 --> 01:10:51.640]  и мы читаем хед.
[01:10:51.640 --> 01:10:54.640]  Давайте зафиксируем.
[01:10:54.640 --> 01:11:02.640]  В хеде мы прочли 37,
[01:11:02.640 --> 01:11:11.640]  а в тейле мы прочли 31.
[01:11:11.640 --> 01:11:14.640]  Нормальная ситуация для буфера, который пошел на второй круг.
[01:11:14.640 --> 01:11:20.640]  И смотрите, мы уверены, что мы можем в тейл 31 записать что-то.
[01:11:20.640 --> 01:11:21.640]  Почему?
[01:11:21.640 --> 01:11:23.640]  Потому что хед больше,
[01:11:23.640 --> 01:11:26.640]  то есть консюмер уже подвинул хед,
[01:11:26.640 --> 01:11:30.640]  а значит уже перед этим прочел.
[01:11:30.640 --> 01:11:32.640]  Но опять рассуждение.
[01:11:32.640 --> 01:11:36.640]  Мы смотрим на ячейку, а перед ней была другая запись или чтение,
[01:11:36.640 --> 01:11:38.640]  значит она уже случилась.
[01:11:38.640 --> 01:11:44.640]  Ну или давайте вот так прям совсем плотненько, чтобы было 33.
[01:11:44.640 --> 01:11:49.640]  Вот мы читаем currentHead 33,
[01:11:49.640 --> 01:11:56.640]  мы уверены, что консюмер уже из слота 32 и 31 достал значение.
[01:11:56.640 --> 01:11:59.640]  И значит можно туда писать.
[01:11:59.640 --> 01:12:05.640]  Но пока вообще-то это ожидание ничем не подкреплено в смысле порядков.
[01:12:05.640 --> 01:12:07.640]  Потому что здесь просто стоит relaxed,
[01:12:07.640 --> 01:12:11.640]  и мы не можем на основе еще раз relax-чтения хеда
[01:12:11.640 --> 01:12:16.640]  делать выводы о других чтениях и записях.
[01:12:16.640 --> 01:12:18.640]  Случились они или нет.
[01:12:18.640 --> 01:12:23.640]  Поэтому мы здесь должны тоже поставить релиз
[01:12:23.640 --> 01:12:26.640]  от консюмера к продюсеру.
[01:12:26.640 --> 01:12:28.640]  То есть это не то чтобы кто-то увидел нашу запись,
[01:12:28.640 --> 01:12:31.640]  нет вообще глобальных записей.
[01:12:31.640 --> 01:12:36.640]  Но мы просто хотим упорядочить два неотомарных конфликтующих обращения.
[01:12:36.640 --> 01:12:40.640]  А здесь мы сделаем aquire соответственно.
[01:12:43.640 --> 01:12:46.640]  Ну вот, как бы тут гармония восстановилась,
[01:12:46.640 --> 01:12:50.640]  потому что два потока были такие, они зеркальные друг друга.
[01:12:50.640 --> 01:12:52.640]  Так что им реордеры теперь зеркальные.
[01:12:52.640 --> 01:12:55.640]  Но это так себе объяснение.
[01:12:55.640 --> 01:12:58.640]  Это скорее нас просто успокаивает.
[01:12:58.640 --> 01:13:07.640]  Ну а почему это было необходимо, мы, кажется, объяснили.
[01:13:07.640 --> 01:13:11.640]  Мы упорядочили с помощью этого релиза и этого aquire
[01:13:11.640 --> 01:13:16.640]  первый продюс и последующий консюм.
[01:13:16.640 --> 01:13:21.640]  А с помощью этого релиза и этого aquire мы упорядочили
[01:13:21.640 --> 01:13:25.640]  этот консюм и следующий в цикле продюс.
[01:13:28.640 --> 01:13:29.640]  Да.
[01:13:33.640 --> 01:13:36.640]  В втором случае, ну да.
[01:13:36.640 --> 01:13:40.640]  Но правда тут было бы еще проще, потому что зачем нам было бы читать.
[01:13:40.640 --> 01:13:42.640]  Ну ладно, окей.
[01:13:42.640 --> 01:13:45.640]  Если бы у нас был бесконечный буфер, то...
[01:13:49.640 --> 01:13:53.640]  На самом деле бесконечно растущий массив
[01:13:53.640 --> 01:13:56.640]  это даже то, что мы сделаем в одной из...
[01:13:56.640 --> 01:13:59.640]  где-то там близко к финальным сложных...
[01:13:59.640 --> 01:14:02.640]  в одной из лекций, которая будет близко к финалу курса,
[01:14:02.640 --> 01:14:04.640]  мы будем говорить про локфри-канал,
[01:14:04.640 --> 01:14:08.640]  как можно сделать локфри-канал для файберов, для грутин.
[01:14:08.640 --> 01:14:11.640]  Но там, в принципе, по мотивам следующей лекции
[01:14:11.640 --> 01:14:16.640]  из той очереди, которую мы придумаем на следующей лекции в эту субботу,
[01:14:16.640 --> 01:14:19.640]  мы построим расширяющийся бесконечный локфри-массив.
[01:14:19.640 --> 01:14:21.640]  Но это такое будет.
[01:14:21.640 --> 01:14:23.640]  Не самое очевидное действие.
[01:14:23.640 --> 01:14:26.640]  А здесь у нас циклический буфер,
[01:14:26.640 --> 01:14:30.640]  и циклические буферы у нас будут еще в планировщике.
[01:14:30.640 --> 01:14:35.640]  И, в общем, вот тут нужно морочиться про Memory Order.
[01:14:35.640 --> 01:14:38.640]  Ну либо не морочиться, просто писать default,
[01:14:38.640 --> 01:14:41.640]  и тогда просто программа будет исполняться.
[01:14:41.640 --> 01:14:45.640]  Ну, этот буфер будет работать там в два-три раза медленнее, но зато...
[01:14:46.640 --> 01:14:51.640]  Ну я показывал в прошлый раз... Ой, на лекции показывал уже.
[01:14:51.640 --> 01:14:53.640]  Сейчас можно воспроизвести, наверное.
[01:14:53.640 --> 01:14:56.640]  Я не уверен, что быстро получится.
[01:14:56.640 --> 01:14:58.640]  Получится ли вообще?
[01:14:58.640 --> 01:15:00.640]  Давай вспомню.
[01:15:00.640 --> 01:15:02.640]  Тут уже все расставлено, да?
[01:15:02.640 --> 01:15:04.640]  И...
[01:15:05.640 --> 01:15:08.640]  Сейчас давай я покажу, как он сейчас работает,
[01:15:08.640 --> 01:15:10.640]  а потом закачу все обратно.
[01:15:16.640 --> 01:15:19.640]  А дальше начнем закатывать.
[01:15:20.640 --> 01:15:24.640]  Значит, нам нужно вот эту оптимизацию закатить.
[01:15:27.640 --> 01:15:31.640]  А, нет, так несчастно, да? Мы хотим закатить только Memory Order.
[01:15:32.640 --> 01:15:35.640]  Ну, давайте попробуем.
[01:15:45.640 --> 01:15:49.640]  Ну вот, мы теперь... Мы сейчас заменяем все load и store.
[01:15:49.640 --> 01:15:54.640]  Ну, все store, которые раньше были move, мы сейчас заменяем на Exchange.
[01:15:55.640 --> 01:15:58.640]  А все load мы заменяем с move на move тоже.
[01:15:59.640 --> 01:16:02.640]  Ну, если вы помните, что там во что комперируется, то...
[01:16:05.640 --> 01:16:07.640]  Ну, я в смысле про Assembler, который меняется.
[01:16:07.640 --> 01:16:10.640]  Вот loadRelaxed и loadSequentialConsistency,
[01:16:10.640 --> 01:16:13.640]  в x86 это просто move. Ну, все loadы одинаковые.
[01:16:13.640 --> 01:16:15.640]  А store, вот...
[01:16:16.640 --> 01:16:18.640]  Так, ладно, запустим.
[01:16:18.640 --> 01:16:20.640]  Кажется, я все поменял.
[01:16:23.640 --> 01:16:25.640]  Стало хуже.
[01:16:28.640 --> 01:16:30.640]  Да, все поменял.
[01:16:34.640 --> 01:16:36.640]  Тут, правда, есть что-то.
[01:16:36.640 --> 01:16:38.640]  Тут, правда, и компьютер нагрелся, поэтому надо сейчас...
[01:16:41.640 --> 01:16:43.640]  восстановить.
[01:16:46.640 --> 01:16:48.640]  Выкатить обратно, и...
[01:16:49.640 --> 01:16:51.640]  Нет, снова быстро работает, значит...
[01:16:51.640 --> 01:16:53.640]  Эффект устойчивый.
[01:16:57.640 --> 01:16:59.640]  Ну, вот так вот.
[01:17:01.640 --> 01:17:03.640]  Кажется, что пример уже был.
[01:17:04.640 --> 01:17:07.640]  Кажется, что пример уже достаточно нетривиальный,
[01:17:07.640 --> 01:17:10.640]  и вот я еще раз обозначаю самый важный момент,
[01:17:10.640 --> 01:17:15.640]  что чтобы расставлять memory-order, нужно понять, зачем расставлять memory-order.
[01:17:15.640 --> 01:17:17.640]  Они расставляются...
[01:17:17.640 --> 01:17:21.640]  Они ставятся на атомиках, но думать нужно не про атомики, а про вот все вокруг них.
[01:17:21.640 --> 01:17:25.640]  Сначала найти неатомарные обращения к памяти, которые мы собираемся упорядочить
[01:17:25.640 --> 01:17:27.640]  с помощью атомиков.
[01:17:27.640 --> 01:17:30.640]  И дальше уже думая о них, про happens before между ними, прогонки между ними,
[01:17:30.640 --> 01:17:32.640]  расставлять memory-order на атомиках.
[01:17:34.640 --> 01:17:39.640]  Вот, не думаю, что где-то в документации на себе референс написана вот эта интуиция,
[01:17:39.640 --> 01:17:41.640]  а вот вокруг нее все...
[01:17:41.640 --> 01:17:43.640]  Без нее невозможно.
[01:17:43.640 --> 01:17:46.640]  Без нее все это превращается в какую-то, не знаю...
[01:17:46.640 --> 01:17:48.640]  Ну, попытку угадать.
[01:17:48.640 --> 01:17:51.640]  Тут понятно, что у нас есть два потока, там один пишет, другой читает,
[01:17:51.640 --> 01:17:53.640]  поэтому, наверное, release acquire, но это вот...
[01:17:53.640 --> 01:17:57.640]  Может быть, это приведет к правильному результату, но...
[01:17:57.640 --> 01:18:00.640]  Логики за этим, мне кажется, никакой не стоит.
[01:18:00.640 --> 01:18:04.640]  Просто какое-то формальное синтактическое рассуждение.
[01:18:04.640 --> 01:18:07.640]  Вот здесь, пожалуйста, есть...
[01:18:07.640 --> 01:18:11.640]  Да, ну и еще раз пример, что на одном атомике можно использовать
[01:18:11.640 --> 01:18:14.640]  разные memory-order, relax, release acquire.
[01:18:16.640 --> 01:18:18.640]  Ну, вообще, смешивать не очень рекомендуется,
[01:18:18.640 --> 01:18:20.640]  то есть здесь это все очень естественно произошло,
[01:18:20.640 --> 01:18:23.640]  но если в программе у вас есть sequential и consistent атомики,
[01:18:23.640 --> 01:18:26.640]  ну, в смысле, одни операции sequential и consistent, другие,
[01:18:26.640 --> 01:18:29.640]  там, release acquire, это все об этом думать очень сложно становится.
[01:18:29.640 --> 01:18:31.640]  Ну и вообще, я не знаю, честно говоря,
[01:18:31.640 --> 01:18:34.640]  как люди memory-order расставляют, они их расставляют.
[01:18:34.640 --> 01:18:38.640]  В простых примерах можно разумно их расставить и объяснить, почему.
[01:18:38.640 --> 01:18:43.640]  А сложные примеры не такие сложные, что вот трудно понять.
[01:18:43.640 --> 01:18:45.640]  Как именно, ну, то есть...
[01:18:45.640 --> 01:18:49.640]  Как люди в голове все эти memory-order выстраивают.
[01:18:50.640 --> 01:18:52.640]  Вот, вопрос, да.
[01:18:52.640 --> 01:18:56.640]  Смешать consistent и relax, там, допустим, в двух средних атомиках.
[01:18:56.640 --> 01:19:01.640]  Вот один из них требует, чтобы все атомики были, как бы,
[01:19:01.640 --> 01:19:04.640]  имели какой-то глобальный порядок, что ли?
[01:19:04.640 --> 01:19:06.640]  Ну, все атомики, на которые...
[01:19:06.640 --> 01:19:10.640]  Все операции над всеми атомиками, которые промаркированы вот так,
[01:19:10.640 --> 01:19:13.640]  вот для них будет глобальный порядок.
[01:19:13.640 --> 01:19:16.640]  Но если у тебя некоторые релизы acquire, то, короче,
[01:19:16.640 --> 01:19:18.640]  это все как-то начинает встраиваться друг с другом,
[01:19:18.640 --> 01:19:21.640]  это сложно, сложно об этом думать.
[01:19:21.640 --> 01:19:25.640]  То есть у тебя есть synchronization order на таких вот операциях,
[01:19:25.640 --> 01:19:27.640]  у тебя есть happens before,
[01:19:27.640 --> 01:19:31.640]  которые реализуются через вот такие операции,
[01:19:31.640 --> 01:19:33.640]  у тебя есть modification order,
[01:19:33.640 --> 01:19:35.640]  и все это в объединении ацикличный,
[01:19:35.640 --> 01:19:37.640]  ты должен это по-честному все представить.
[01:19:37.640 --> 01:19:40.640]  Поэтому лучше, ну, как бы, такого избегать
[01:19:40.640 --> 01:19:45.640]  и искать каких-то простых продюсеров-консюмеров в своем кое.
[01:19:45.640 --> 01:19:47.640]  Вот код, где два атомика, а не один,
[01:19:47.640 --> 01:19:50.640]  это уже во много раз сложнее код.
[01:19:50.640 --> 01:19:53.640]  А если там четыре атомика, то я не знаю что.
[01:19:53.640 --> 01:19:56.640]  А вот... Можно я покажу?
[01:19:56.640 --> 01:19:58.640]  Я, по-моему, показывал, ничего не объяснял,
[01:19:58.640 --> 01:20:00.640]  наверное, уже не буду.
[01:20:00.640 --> 01:20:04.640]  В задаче «Кундвар» была ссылка на «Кундвар», который петроедный.
[01:20:04.640 --> 01:20:07.640]  Я вам показывал его, кажется, может быть, даже пугал ему,
[01:20:07.640 --> 01:20:13.640]  потому что там буквально то ли десяток, то ли дюжина атомиков разных,
[01:20:13.640 --> 01:20:18.640]  и весь код на каждой операции там memory order стоит.
[01:20:18.640 --> 01:20:22.640]  Правда, не C++, а C, поэтому вот такие вот интристики, но неважно.
[01:20:22.640 --> 01:20:27.640]  Короче, код сложный, очень сложный, много атомиков,
[01:20:27.640 --> 01:20:30.640]  а еще к тому же в нем бага есть.
[01:20:30.640 --> 01:20:34.640]  Вот «Кундвар» петроедный зависает.
[01:20:34.640 --> 01:20:39.640]  То есть вы можете заснуть, получить на «Тифае» и не проснуться.
[01:20:39.640 --> 01:20:42.640]  То есть разумная программа на петроедном «Кундваре» может зависнуть,
[01:20:42.640 --> 01:20:45.640]  потому что «Кундвар» очень сложный, и человек не справился.
[01:20:45.640 --> 01:20:48.640]  То есть он был очень умный, он очень долго думал, в 4 года,
[01:20:48.640 --> 01:20:50.640]  а все равно бага получилась.
[01:20:50.640 --> 01:20:54.640]  Поэтому лучше сложные вещи не писать такие.
[01:20:54.640 --> 01:21:00.640]  Вот 10 атомиков — это верный признак того, что вы проиграете.
[01:21:00.640 --> 01:21:03.640]  Нужно Model Checker использовать.
[01:21:03.640 --> 01:21:05.640]  Ну, Refault Injection, на худой конец.
[01:21:05.640 --> 01:21:09.640]  Ну, короче, как-то нужно тестировать нечеловеческим умом.
[01:21:09.640 --> 01:21:14.640]  — Есть какой-то способ формально писать, что я ожидаю от программы?
[01:21:14.640 --> 01:21:15.640]  — Да, есть.
[01:21:15.640 --> 01:21:16.640]  Ну, это Model Checking.
[01:21:16.640 --> 01:21:18.640]  Я скорее осенью про это буду на спецкурусе рассказывать,
[01:21:18.640 --> 01:21:22.640]  про определенные системы, там более универсальные инструменты.
[01:21:22.640 --> 01:21:25.640]  Да, ты можешь прямо написать, что я хочу прогресса,
[01:21:25.640 --> 01:21:29.640]  я хочу взаимного исключения написать это на языкеологике вообще формально.
[01:21:29.640 --> 01:21:33.640]  И свой код на языкеологике формально написать.
[01:21:33.640 --> 01:21:38.640]  Ну, или на псевдокоде, который будет переписан в какие-то логические конструкции,
[01:21:38.640 --> 01:21:42.640]  а потом эта все машина переберет за тебя.
[01:21:42.640 --> 01:21:47.640]  Ну, по сути, это перебор получится, который просто строго описан.
[01:21:47.640 --> 01:21:50.640]  То есть представь себе язык с формальной семантикой.
[01:21:50.640 --> 01:21:53.640]  Не C++, там, где на Define Behavior какая-то абстрактная машина,
[01:21:53.640 --> 01:21:58.640]  а вот прямо строгое.
[01:21:58.640 --> 01:22:00.640]  Ну, вот так можно делать.
[01:22:00.640 --> 01:22:04.640]  И это, по сути, единственный, ну, скажем так, Model Checker,
[01:22:04.640 --> 01:22:08.640]  то есть инструмент, который перебирает все исполнения,
[01:22:08.640 --> 01:22:13.640]  не важно на каком языке программа описана, на C++ или на формальном языке,
[01:22:13.640 --> 01:22:16.640]  тебе нужен инструмент, который переберет все достижимые состояния
[01:22:16.640 --> 01:22:20.640]  и проверит у них все необходимые свойства.
[01:22:20.640 --> 01:22:22.640]  Вот это единственный частный путь.
[01:22:22.640 --> 01:22:26.640]  Вот мы и Fault Injection пытаемся увеличить покрытие графа этих состояний,
[01:22:26.640 --> 01:22:28.640]  а можно прямо вот все перебрать.
[01:22:28.640 --> 01:22:31.640]  Вот, может быть, в курсе это однажды случится через Gotary,
[01:22:32.640 --> 01:22:34.640]  но так тоже можно делать.
[01:22:38.640 --> 01:22:40.640]  О, он очень старый.
[01:22:45.640 --> 01:22:48.640]  Я не знаю, но в мире пишется огромное количество кода
[01:22:48.640 --> 01:22:53.640]  и до сих пор пишется без Fault Injection и Model Checker.
[01:22:53.640 --> 01:22:56.640]  Просто человек смотрит на код и думает, ну, я вроде понимаю, почему он правильный,
[01:22:56.640 --> 01:22:58.640]  я его напишу.
[01:23:01.640 --> 01:23:03.640]  Да.
[01:23:03.640 --> 01:23:07.640]  Ну, видишь, он, во-первых, написал неправильный код, во-вторых,
[01:23:07.640 --> 01:23:09.640]  не могу это объяснить.
[01:23:09.640 --> 01:23:12.640]  Вот если ты один раз почувствовал, что такое хорошее тестирование,
[01:23:12.640 --> 01:23:15.640]  ты потом не можешь без него жить, потому что тебе неспокойно.
[01:23:15.640 --> 01:23:20.640]  А хорошее тестирование требует прям больших затрат перед написанием кода.
[01:23:20.640 --> 01:23:24.640]  Ты должен подготовить весь свой код к тому, чтобы его можно было
[01:23:24.640 --> 01:23:27.640]  тестировать, перебирать все исполнения.
[01:23:27.640 --> 01:23:30.640]  То есть ты должен перед тем, как писать код, подготовить всю свою кодовую базу
[01:23:30.640 --> 01:23:32.640]  к тому, чтобы ее можно было так тестировать.
[01:23:32.640 --> 01:23:34.640]  Это очень дорогое удовольствие.
[01:23:34.640 --> 01:23:37.640]  Ну, у Petrata они гораздо старше, чем люди так стали делать.
[01:23:37.640 --> 01:23:40.640]  Вот есть не так уж много мест, где люди так пишут код.
[01:23:40.640 --> 01:23:43.640]  Ну вот, мы пишем код так.
[01:23:43.640 --> 01:23:45.640]  Без этого кажется невозможно.
[01:23:45.640 --> 01:23:48.640]  Я не знаю, даже в чате уже задачи Slipforge страдают,
[01:23:48.640 --> 01:23:50.640]  потому что она исполняется недотерминированно.
[01:23:50.640 --> 01:23:53.640]  Почему? Потому что в ASIO нет Fault Injection,
[01:23:53.640 --> 01:23:55.640]  потому что мы не можем тестировать задачу под файберами,
[01:23:55.640 --> 01:23:58.640]  потому что внешний библиотек, она не адаптирована к этому.
[01:23:58.640 --> 01:24:01.640]  И вот уже мы лишились Fault Injection, лишились файберов,
[01:24:01.640 --> 01:24:03.640]  и все уже стало работать хуже.
[01:24:03.640 --> 01:24:06.640]  Стали тесты хуже работать, изменение предсказуемо.
[01:24:08.640 --> 01:24:10.640]  А бак там очень простой.
[01:24:10.640 --> 01:24:13.640]  Так что то, что у нас в домашниках работают тесты,
[01:24:13.640 --> 01:24:16.640]  и мы это принимаем как должное, это на самом деле нифига не должное.
[01:24:16.640 --> 01:24:20.640]  Это очень большая работа, потому что они так работали предсказуемо.
[01:24:20.640 --> 01:24:23.640]  Вот без этого код тестировать сложно.
[01:24:23.640 --> 01:24:26.640]  Люди все равно до сих пор пишут код,
[01:24:26.640 --> 01:24:29.640]  полагаясь на собственный опыт.
[01:24:29.640 --> 01:24:31.640]  И в какой-то степени их можно понять.
[01:24:31.640 --> 01:24:34.640]  Ну то есть если они действительно понимают, что они пишут,
[01:24:34.640 --> 01:24:36.640]  то скорее всего они пишут без ошибок.
[01:24:36.640 --> 01:24:42.640]  Но как отличить это, скорее всего, от действительно без ошибок?
[01:24:43.640 --> 01:24:46.640]  А вот ЧВАП1 писал ли?
[01:24:46.640 --> 01:24:48.640]  По-моему, этот код, у него автор один,
[01:24:48.640 --> 01:24:51.640]  ну и там бак уже достаточно давно существует,
[01:24:51.640 --> 01:24:52.640]  но вот он не поправлен на сих пор.
[01:24:52.640 --> 01:24:54.640]  Кажется, что никакого простого способа поправить его нет.
[01:24:54.640 --> 01:24:58.640]  Кажется, бак довольно фундаментальный.
[01:25:00.640 --> 01:25:05.640]  Просто за 4 года это не попробовать?
[01:25:06.640 --> 01:25:08.640]  Ну какие-то тесты наверняка есть,
[01:25:08.640 --> 01:25:12.640]  но вот бак, он очень сложный, там много шагов,
[01:25:12.640 --> 01:25:16.640]  и вот просто стресс-тест, там он не поймается.
[01:25:16.640 --> 01:25:20.640]  Нужно, чтобы случилось очень много маленьких шагов в очень правильном порядке.
[01:25:20.640 --> 01:25:22.640]  То есть число состояния очень большое.
[01:25:23.640 --> 01:25:25.640]  Нет.
[01:25:28.640 --> 01:25:30.640]  А можно еще вопрос про...
[01:25:30.640 --> 01:25:40.640]  Вот вы сказали, что x86 архитектура на некоторые гарантии сама в себе несет?
[01:25:40.640 --> 01:25:41.640]  Да.
[01:25:41.640 --> 01:25:48.640]  То есть получается, у вас на сервере тестируется не под x86, чтобы...
[01:25:48.640 --> 01:25:49.640]  Под x86.
[01:25:49.640 --> 01:25:54.640]  Ну смотри, ты можешь написать memory-ордеры неправильные,
[01:25:54.640 --> 01:25:58.640]  то есть слабее, чем ты имеешь право.
[01:25:58.640 --> 01:26:00.640]  То есть ты можешь написать спинлок с релаксом.
[01:26:00.640 --> 01:26:04.640]  И поскольку он скомпилируется в тот же самый move, то никакой проблемы не будет.
[01:26:04.640 --> 01:26:09.640]  Но тесты запускаются под thread-санитайзером.
[01:26:09.640 --> 01:26:11.640]  А thread-санитайзер...
[01:26:11.640 --> 01:26:13.640]  Ну я вообще-то надеялся про это рассказать.
[01:26:13.640 --> 01:26:15.640]  Может быть, на следующей неделе я расскажу.
[01:26:15.640 --> 01:26:18.640]  Вот thread-санитайзер явно отслеживает happens-before.
[01:26:18.640 --> 01:26:20.640]  То есть ему неважно, там реализуется бага или нет.
[01:26:20.640 --> 01:26:23.640]  Но если у тебя была критическая секция, а потом другая,
[01:26:23.640 --> 01:26:27.640]  и вот между обращением к памяти у тебя не выстрелилось happens-before формального,
[01:26:27.640 --> 01:26:31.640]  то как бы неважно, что ты на процессоре на текущем прочьешь то, что хочешь.
[01:26:31.640 --> 01:26:35.640]  Просто thread-санитайзер поймет, что у тебя формально упорядочивания не было
[01:26:35.640 --> 01:26:37.640]  из-за репорта датарейс.
[01:26:37.640 --> 01:26:39.640]  Ну собственно, чего я далеко хожу...
[01:26:39.640 --> 01:26:41.640]  Вот мы пример видели только что.
[01:26:41.640 --> 01:26:43.640]  Это же он и был.
[01:26:44.640 --> 01:26:46.640]  Мы поставили здесь relaxed.
[01:26:46.640 --> 01:26:49.640]  Relaxed на x86 не отличим от release-acquire,
[01:26:49.640 --> 01:26:52.640]  а при этом thread-санитайзер ошибку нашел.
[01:26:52.640 --> 01:26:56.640]  То есть он просто вот честно отслеживал happens-before,
[01:26:56.640 --> 01:26:58.640]  понял, что его не было.
[01:26:58.640 --> 01:27:01.640]  Но при этом программа, если мы ее компилируем
[01:27:01.640 --> 01:27:04.640]  под x86 без thread-санитайзера, под release-ом,
[01:27:04.640 --> 01:27:07.640]  то она будет исполняться всегда правильно.
[01:27:07.640 --> 01:27:10.640]  На арме уже может неправильно исполняться.
[01:27:10.640 --> 01:27:12.640]  На тестирующем сервере у нас x86,
[01:27:12.640 --> 01:27:14.640]  но мы надеемся на thread-санитайзер.
[01:27:20.640 --> 01:27:21.640]  Вот такая история.
[01:27:21.640 --> 01:27:23.640]  Вот, давайте закругляться.
