[00:00.000 --> 00:12.240]  В прошлый раз мы с вами, насколько я помню, мы все проговорили
[00:12.240 --> 00:16.760]  про квариацию и корреляцию, свойства их доказали,
[00:16.760 --> 00:17.760]  там все здорово было.
[00:17.760 --> 00:21.640]  Соответственно, сегодня последний раздел у тервера,
[00:21.640 --> 00:35.320]  мы коснемся этой предельной теории.
[00:35.320 --> 00:41.880]  Начнем с неравенств, с неравенств для вероятности,
[00:41.880 --> 00:44.520]  с помощью которых будут доказываться наши предельные
[00:44.520 --> 00:45.520]  теории.
[00:45.880 --> 00:50.120]  Развественно, первый результат неравенства Маркова.
[00:50.120 --> 01:08.800]  Чем он говорит, что, если у нас кси не отрицательная
[01:08.800 --> 01:11.920]  случайная величина, существует математическое ожидание
[01:11.920 --> 01:15.560]  кси, то утверждается, что для любого епсуума больше
[01:15.560 --> 01:18.000]  0 будет верно следующее неравенство.
[01:18.000 --> 01:23.360]  Вероятность того, что кси больше либо равно епсуум,
[01:23.360 --> 01:34.240]  меньше либо равно от ожидания кси, делить на епсуум.
[01:34.240 --> 01:36.960]  Это кстати в тему того, зачем, в частности, почему мы
[01:36.960 --> 01:39.400]  так много занимались математическим ожиданием, вы должны понимать
[01:40.360 --> 01:43.440]  Я много раз говорил о том, что нас интересуют вероятности
[01:43.440 --> 01:44.440]  подобного вида.
[01:44.440 --> 01:51.120]  Из банальных бытовых соображений, если кси – это ваш средний
[01:51.120 --> 01:54.000]  балл, то у вас интересует вероятность, что они будут
[01:54.000 --> 01:56.240]  больше или меньше каких-то значений.
[01:56.240 --> 01:59.440]  Получается, что мы эти вероятности сможем оценивать через
[01:59.440 --> 02:04.400]  выражения, в которых будут участвовать моменты ваших
[02:04.400 --> 02:05.400]  случайных величин.
[02:05.400 --> 02:06.400]  Идея ясна?
[02:06.400 --> 02:07.400]  Киваем?
[02:07.400 --> 02:08.400]  Хорошо.
[02:08.880 --> 02:11.880]  Так, как это доказывается.
[02:11.880 --> 02:15.160]  Смотрим, что такое математическое ожидание кси.
[02:15.160 --> 02:19.280]  По определению, не по формуле, а по определению, мат ожидания
[02:19.280 --> 02:22.440]  кси считается как сумма произведения вероятности
[02:22.440 --> 02:25.360]  по элементарным исходам на значение случайных
[02:25.360 --> 02:28.840]  величин, случайные величины в этих элементарных исходах.
[02:28.840 --> 02:33.880]  Чтобы я вообще мог написать эту сумму, мне поэтому пришлось
[02:33.880 --> 02:37.440]  потребовать, чтобы у меня мат ожидания существовало.
[02:37.440 --> 02:41.680]  Дальше эту сумму я разобью на две суммы.
[02:41.680 --> 02:46.840]  Сумма по таким омега, что кси от омега больше любя
[02:46.840 --> 02:57.280]  внуя эпсуум, на сумму по таким омега, что кси от омега
[02:57.280 --> 02:58.280]  получается меньше эпсуум.
[03:06.280 --> 03:07.280]  Дальше что я сделаю?
[03:08.120 --> 03:10.880]  Меня интересует вероятность вот таких вещей, вот это
[03:10.880 --> 03:13.280]  меня не интересует, поэтому я просто выкину.
[03:13.280 --> 03:17.400]  Если я это выкину, что у меня произойдет с суммой?
[03:17.400 --> 03:22.920]  Не увеличится, может тут слагаемых ноль, но она
[03:22.920 --> 03:26.160]  точно у нас не увеличится.
[03:26.160 --> 03:31.640]  Это первое, что я сделаю, а второе, что я сделаю, получается
[03:31.640 --> 03:34.520]  вот в этой сумме каждый кси от омега у нас будет
[03:34.520 --> 03:36.200]  больше чем эпсуум, правильно?
[03:36.200 --> 03:39.520]  Поэтому если я сейчас вместо вот этого кси напишу эпсуум,
[03:39.520 --> 03:42.960]  я тоже не увеличу мою сумму.
[03:42.960 --> 03:45.640]  То есть получается, что здесь будет сумма по всем
[03:45.640 --> 03:49.960]  омега таким, что кси от омега больше и равно чем эпсуум.
[03:49.960 --> 03:54.720]  Вероятность этого омега маленького множество на
[03:54.720 --> 03:55.720]  эпсуум.
[03:55.720 --> 03:58.720]  Все в порядке?
[03:58.720 --> 03:59.720]  Окей.
[03:59.720 --> 04:03.240]  Теперь мы видим, что соответственно этот множитель не зависит
[04:03.240 --> 04:06.160]  от индекса суммирования, он выносится за знак суммирования,
[04:06.160 --> 04:09.720]  получается мы суммируем вероятности элементарных
[04:09.720 --> 04:12.520]  исходов по таким элементарным исходам, что выплыл нет,
[04:12.520 --> 04:15.600]  но понятно, что если мы соберем все эти омеги вместе, мы
[04:15.600 --> 04:21.840]  получим вероятность события, что кси от омега больше
[04:21.840 --> 04:22.840]  либо равно эпсуум.
[04:22.840 --> 04:27.360]  Ну и все, деля на эпсуум мы получаем то, что мы хотели
[04:27.360 --> 04:28.360]  доказать.
[04:28.360 --> 04:31.720]  Ну то есть вообще несложно.
[04:31.720 --> 04:38.600]  Следствие из-за этого результата, которое мы называем неравенство
[04:38.600 --> 04:39.600]  ЧБ-шоу.
[04:39.600 --> 04:49.080]  Неравенство ЧБ-шоу заключается в том, что если у вас есть
[04:49.080 --> 04:52.320]  произвольная случайная величина кси, для которой
[04:52.320 --> 04:57.480]  существует дисперсия, понятно, что от ожидания дисперсии
[04:57.480 --> 04:58.480]  могут не существовать.
[04:58.480 --> 05:02.440]  А может быть так, что существует дисперсия, но не существует
[05:02.440 --> 05:03.440]  от ожидания?
[05:03.440 --> 05:07.400]  Ну да, она призначена из-за от ожидания, было бы странно.
[05:07.400 --> 05:08.400]  Хорошо.
[05:08.400 --> 05:09.400]  Что утверждается?
[05:09.400 --> 05:12.520]  Что для любого эпсуума больше 0, вероятность того, что
[05:12.520 --> 05:15.360]  кси отличается от своего от ожидания, как нас очень
[05:15.360 --> 05:20.920]  тихо на нос существует, больше чем эпсуум, вероятность
[05:20.920 --> 05:23.200]  такого события будет не больше, чем дисперсию
[05:23.200 --> 05:25.320]  случайной величины кси делить на эпсуум в квадрате.
[05:25.320 --> 05:31.320]  Ну это действительно следствие неравенства Маркова, потому
[05:31.320 --> 05:35.520]  что мы в качестве случайной величины рассматриваем
[05:35.520 --> 05:36.520]  вот этот вот модуль.
[05:36.520 --> 05:43.040]  Очевидно, это не отрицательная случайная величина, у которой
[05:43.040 --> 05:44.760]  существует математическое ожидание.
[05:44.760 --> 05:50.760]  Не, ну нехорошо, тут же у нас непонятно, поэтому
[05:51.000 --> 05:54.000]  давайте сделаем вот так.
[05:54.000 --> 05:58.120]  Вот такую случайную величину рассматриваем.
[05:58.120 --> 06:03.680]  Поскольку дисперсия существует, мат ожидания это и есть
[06:03.680 --> 06:08.360]  дисперсия кси, это же видно, ну просто по определению.
[06:08.360 --> 06:10.440]  Поэтому для этого выполнено, что с одной стороны эта
[06:10.440 --> 06:12.560]  штука не отрицательная, с другой стороны существует
[06:12.560 --> 06:14.760]  мат ожидания это.
[06:14.760 --> 06:17.920]  То есть выполнено все требования неравенства Маркова, отсюда
[06:18.280 --> 06:23.480]  любого эпсуума больше у нуля, вероятность того, что
[06:23.480 --> 06:33.080]  это больше эпсуум в квадрате, это будет меньше верно,
[06:33.080 --> 06:36.680]  чем мат ожидания это делить на эпсуум в квадрате, а
[06:36.680 --> 06:39.680]  это и есть дисперсия кси делить на эпсуум в квадрате.
[06:39.680 --> 06:42.680]  Ну все, 4d.
[06:43.440 --> 06:47.440]  Понятно, откуда квадрат взялся?
[06:47.440 --> 06:50.440]  Я вот здесь неравенство взял в квадрат.
[06:50.440 --> 06:55.440]  Программа восьмого класса.
[06:55.440 --> 06:58.440]  Если обе части неравенства не отрицательны, то возведение
[06:58.440 --> 07:00.440]  в квадрат приводит к односильному неравенству.
[07:00.440 --> 07:04.440]  Вы очень задумчивы над этим результатом как-то.
[07:05.200 --> 07:14.200]  Закон больших чисел.
[07:17.200 --> 07:22.200]  Стандартная аббревиатура, никто не пишет закон больших
[07:22.200 --> 07:23.200]  чисел, все пишут ЗБЧ.
[07:23.200 --> 07:30.200]  Давайте я его сначала сформулирую, потом поговорим о чем речь.
[07:30.200 --> 07:34.200]  Пускай у нас есть последовательность случайных величин x1, xn.
[07:34.960 --> 07:37.960]  Независимо одинаково распределенные случайные величины.
[07:37.960 --> 07:40.960]  Тоже стандартная аббревиатура, вы к ней привыкаете, потому
[07:40.960 --> 07:43.960]  что много теорем будут содержать это.
[07:43.960 --> 07:48.960]  Независимо одинаково распределенные случайные величины.
[07:51.960 --> 07:54.960]  А что про них известно?
[07:54.960 --> 07:59.960]  Что существует дисперсия кси и т.
[07:59.960 --> 08:02.960]  Как они между собой связаны?
[08:03.720 --> 08:06.720]  С чего вдруг?
[08:06.720 --> 08:09.720]  Почему?
[08:09.720 --> 08:12.720]  Это все понимают?
[08:12.720 --> 08:15.720]  Поскольку дисперсия, так же как любое математическое
[08:15.720 --> 08:18.520]  ожидание, является характеристикой распределения, то если
[08:18.520 --> 08:20.960]  у величины одинаковое распределение, то и все
[08:20.960 --> 08:23.720]  моменты, все эти характеристики у них будут одинаковые.
[08:23.720 --> 08:26.720]  Поэтому в принципе можно было написать вот так.
[08:26.720 --> 08:29.720]  То есть существует дисперсия кс и т.
[08:30.480 --> 08:33.480]  Давайте, раз у них одинаковые дисперсии...
[08:33.480 --> 08:36.480]  Мат ожидания существует, поскольку существует дисперсия,
[08:36.480 --> 08:38.480]  мат ожидания обозначен как А.
[08:38.480 --> 08:39.480]  Что утверждается?
[08:39.480 --> 08:45.480]  Утверждается, что вероятность того, что кси1 и т.д., кси n
[08:45.480 --> 08:50.480]  делить на n минуса больше или давно, чем епсул, стремится
[08:50.480 --> 08:54.480]  к нулю при стремящемся к бесконечности для любого
[08:54.480 --> 08:57.480]  положительного епсула.
[09:00.480 --> 09:05.480]  Причем обычно закон больших чисел, но впервые, когда
[09:05.480 --> 09:08.480]  люди с ним сталкиваются, записывается даже не так.
[09:08.480 --> 09:11.480]  Они его немножечко ослабляют и пишут.
[09:21.480 --> 09:24.480]  Вот так, вот так, вот так, вот так, вот так.
[09:24.480 --> 09:25.480]  Ух!
[09:25.480 --> 09:28.480]  Ну что, огонь?
[09:29.240 --> 09:35.240]  Ослабление, то, что сейчас, когда мы будем доказывать,
[09:35.240 --> 09:37.240]  вы увидите, что на самом деле одинаковую распределенность
[09:37.240 --> 09:42.240]  можно ослабить до того, что у них одинаковые дисперсии,
[09:42.240 --> 09:44.240]  как-то связаны математические ожидания.
[09:44.240 --> 09:47.240]  Можно ослаблять вот этот набор свойств, ну и не требовать,
[09:47.240 --> 09:50.240]  чтобы у них от ожиданий были даже одинаковые.
[09:50.240 --> 09:53.240]  Ну как смотрится?
[09:56.240 --> 09:58.240]  Очевидно, что правда.
[09:59.000 --> 10:01.000]  Это хорошо, это радует.
[10:01.000 --> 10:03.000]  Ну сейчас мы это докажем, действительно доказательство
[10:03.000 --> 10:04.000]  будет коротенькое.
[10:04.000 --> 10:09.000]  Но основной, как бы, вопрос, который должен быть, какой?
[10:12.000 --> 10:15.000]  Это единственное, что вас интересует.
[10:15.000 --> 10:18.000]  В теории Большого взрыва была серия, когда они участвовали
[10:18.000 --> 10:19.000]  в Кубке физики.
[10:19.000 --> 10:22.000]  Там Шелдон организовал свою команду.
[10:22.000 --> 10:25.000]  Ну вот, и когда был последний вопрос, там вываливается
[10:25.000 --> 10:28.000]  вот такое вот равнение, и говорят, решите его.
[10:28.760 --> 10:31.760]  У всех был вопрос, что за дичь написано.
[10:34.760 --> 10:37.760]  Ну то есть вообще непонятно, это зачем.
[10:37.760 --> 10:40.760]  Ну, явно, что это какой-то глобальный хороший результат,
[10:40.760 --> 10:43.760]  но как бы вообще непонятно, о чем это хрень написано.
[10:43.760 --> 10:45.760]  То есть какой-то модуль, больше равно Эбсу, на вероятности
[10:45.760 --> 10:48.760]  этого стремится к нулю.
[10:48.760 --> 10:53.760]  Давайте попробуем подумать на смысл происходящего.
[10:53.760 --> 10:56.760]  Вероятность, что модуль случайно начинай, больше
[10:57.520 --> 10:58.520]  Эбсу, он стремится к нулю.
[10:58.520 --> 10:59.520]  Идейно это что значит?
[11:07.520 --> 11:10.520]  Похоже в каком смысле, ты можешь как-то поточить.
[11:10.520 --> 11:14.520]  Ну то есть отличаются, да, то есть у вас что получается,
[11:14.520 --> 11:16.520]  что значение вот этой дироби, эта диробь является
[11:16.520 --> 11:17.520]  случайной величиной.
[11:17.520 --> 11:18.520]  Да?
[11:18.520 --> 11:21.520]  Ну вот, то, что вот эта диробь отличается вот
[11:21.520 --> 11:22.520]  от него, это кто?
[11:22.520 --> 11:23.520]  Какой-то мат-объект.
[11:27.560 --> 11:30.000]  Ну, математический объект, это какой?
[11:30.000 --> 11:31.000]  Это число.
[11:31.000 --> 11:34.000]  Вот это у вас случайная величина, это число.
[11:34.000 --> 11:49.000]  И что говорится?
[11:49.000 --> 11:51.040]  Вероятность того, что он отличается хоть сколько-нибудь
[11:51.040 --> 11:53.740]  значим, вот вероятность такого стремится к нулю.
[11:53.740 --> 11:57.300]  Но на самом деле вот этот результат идеально хочется
[11:57.300 --> 11:58.300]  воспринимать как?
[11:58.300 --> 12:02.260]  То, что кси1 плюс этагралия кси n делить на n, стремится
[12:02.260 --> 12:04.860]  к a при n, стремяющемся к бесконечности.
[12:04.860 --> 12:06.500]  Почему мы не написали так сразу?
[12:06.500 --> 12:09.500]  Что вообще с n?
[12:09.500 --> 12:14.100]  Ну не то, что она не имеет смысла, она непонятна,
[12:14.100 --> 12:15.100]  вот эта вот часть.
[12:15.100 --> 12:18.620]  Ну то есть слева у вас идет последовательность случайных
[12:18.620 --> 12:19.620]  величин.
[12:19.620 --> 12:21.140]  Ну то есть тут как бы у вас две перемены.
[12:21.140 --> 12:23.460]  Во-первых, количество слагаемых раз, и во-вторых,
[12:23.460 --> 12:26.980]  это все функция от элементарного исхода, то есть это случайная
[12:26.980 --> 12:27.980]  величина 2.
[12:27.980 --> 12:29.780]  И это стремится к числу 1.
[12:29.780 --> 12:33.180]  Что значит, что у вас последовательность случайных величин стремится
[12:33.180 --> 12:34.180]  к чему-то?
[12:34.180 --> 12:37.900]  Ну можно, конечно, тут как бы понять, что это получается
[12:37.900 --> 12:39.740]  функция от омега маленького.
[12:39.740 --> 12:42.580]  Может быть есть какой-то мотанский смысл сходимости?
[12:42.580 --> 12:45.580]  Какой мотанский смысл сходимости?
[12:45.580 --> 12:50.820]  Это в мотане такое было, да?
[12:50.820 --> 12:51.820]  Ну хорошо.
[12:51.820 --> 12:52.820]  Ну вот.
[12:52.820 --> 12:56.700]  Это действительно будет сходимость по мере, и нам
[12:56.700 --> 12:59.100]  это нужно будет тоже в частности отработать в произвольных
[12:59.100 --> 13:00.100]  пространствах.
[13:00.100 --> 13:01.100]  Почему?
[13:01.100 --> 13:03.100]  Потому что то, что вы делали еще раз, чем то, что вы делали
[13:03.100 --> 13:05.660]  в мотане, на той части, которая касалась меры интегра
[13:05.660 --> 13:08.740]  Олибего, отличается от того, что мы делаем сейчас.
[13:08.740 --> 13:11.100]  Мы не знаем природу омега-большого.
[13:11.100 --> 13:15.340]  Мотан – это как бы вы изучаете там свойства функций, определенных
[13:15.340 --> 13:19.340]  на Rn и с изначениями в Rn, это основная идея.
[13:19.340 --> 13:21.460]  То есть область определения ваших функций – это вещь
[13:21.460 --> 13:22.460]  понятная.
[13:22.460 --> 13:25.460]  Вы работаете, начиная с какого-то там класса.
[13:25.460 --> 13:26.460]  Ну вот.
[13:26.460 --> 13:29.020]  Здесь природа омега-большого неизвестна.
[13:29.020 --> 13:30.020]  Это понятно?
[13:30.020 --> 13:31.020]  Проблемы?
[13:31.020 --> 13:32.020]  Кивайте.
[13:32.020 --> 13:33.020]  Вы какие-то утухлые сегодня.
[13:33.020 --> 13:34.020]  Что не так?
[13:34.020 --> 13:35.020]  Как-то повеселее.
[13:35.020 --> 13:40.620]  У меня голова болит, поэтому давайте, чтобы было повеселее.
[13:40.620 --> 13:41.620]  Ну вот.
[13:41.620 --> 13:44.740]  Поэтому это тоже вопрос, который мы с вами будем
[13:44.740 --> 13:46.900]  решать во второй части.
[13:46.900 --> 13:51.740]  Что значит то, что случайный величин, ну в общем случае
[13:51.740 --> 13:54.820]  измеримые функции сходятся и какие есть смыслы этих
[13:54.820 --> 13:58.100]  сходимости раз и как они связаны между собой два.
[13:58.100 --> 13:59.100]  Идея ясна?
[13:59.100 --> 14:00.100]  Ну вот.
[14:00.100 --> 14:03.380]  И в этом плане, то есть ценность вот этого результата – она
[14:03.380 --> 14:04.380]  понятна.
[14:04.380 --> 14:07.700]  А кто-то может сказать, то есть чем цени, ну хорошо,
[14:07.700 --> 14:08.700]  есть какой-то предел.
[14:08.700 --> 14:09.700]  Ура!
[14:09.700 --> 14:10.700]  И что?
[14:10.700 --> 14:28.100]  Ну когда у тебя есть скорость сходимости, когда ты можешь
[14:28.100 --> 14:32.620]  хоть как-то оценить, начиная с каких значений n мы можем
[14:32.620 --> 14:35.420]  рассчитывать хоть на какую-то точность, тогда да, здесь
[14:35.420 --> 14:36.420]  же пока этого нет.
[14:37.420 --> 14:41.220]  Именно в плане тервера, то есть чем вот это, вот именно
[14:41.220 --> 14:45.220]  та мысль о том, что вот эта дыробь стремится к А, потому
[14:45.220 --> 14:51.460]  что мы ведь на самом деле, молодец, сейчас снова напишу,
[14:51.460 --> 14:54.860]  чем вот эта идея, пускай мы пока не понимаем, что
[14:54.860 --> 14:58.460]  значит стремиться, но чем вот этот результат приятен
[14:58.460 --> 15:01.660]  с точки зрения вообще тервера, то есть как бы тервера – это
[15:01.660 --> 15:04.740]  науки, главным объектом исследования которой является
[15:04.740 --> 15:05.740]  случайный эксперимент.
[15:05.740 --> 15:17.420]  Ну погромче, ну погромче, как это правильно, да, ну
[15:17.420 --> 15:19.820]  смотрите, то есть что такое, у вас есть случайная величина
[15:19.820 --> 15:21.940]  кс1, мы представим себе стандартную историю, то
[15:21.940 --> 15:25.180]  есть, прошу прощения, моя химическая прошлая дает
[15:25.180 --> 15:27.900]  о себе знать, вы снимаете пашу какую-нибудь, ну там
[15:27.900 --> 15:31.620]  у вас есть раствор, и вы снимаете, но как бы на результаты
[15:31.620 --> 15:34.940]  исследований влияют еще случайные факторы, то есть
[15:34.940 --> 15:40.300]  у вас есть, ну вот у вас есть какое-то значение
[15:40.300 --> 15:43.740]  паш, и вот эти вот ошибки, которые у вас влияют на
[15:43.740 --> 15:48.260]  результаты ваших измерений, всегда во всех этих историях
[15:48.260 --> 15:52.620]  считается, что среднее значение ошибок оно нулевое, потому
[15:52.620 --> 15:55.860]  что если у вас это не ноль, то значит у вас есть постоянный
[15:55.860 --> 16:00.140]  снос ваших значений, вы никогда не сможете восстановить
[16:00.140 --> 16:02.460]  то истинное значение, которое вы считаете, так постановка
[16:02.460 --> 16:03.460]  ясна, да?
[16:03.660 --> 16:05.580]  есть какой-то показатель стандартный, но вот есть
[16:05.580 --> 16:07.980]  ошибки, и в результате вы получаете чиселка плюс
[16:07.980 --> 16:10.380]  случайная начина, вы получаете случайную, в чём от ожидания
[16:10.380 --> 16:13.940]  есть С, и ищете вы С, понятно то, что если вы снимаете
[16:13.940 --> 16:16.620]  показания ксиеты, но у вас это случайная начина,
[16:16.620 --> 16:18.580]  она принимает случайные значения, о чём говорит
[16:18.580 --> 16:22.420]  закон больших чисел, что если вы сделаете несколько
[16:22.420 --> 16:26.180]  измерений, ну вот, и возьмёте среднее, то при достаточно
[16:26.180 --> 16:29.340]  большом количестве измерений вы будете близки к числу,
[16:29.340 --> 16:33.980]  что вы не знаете, идея ясна, то есть вот то, что было
[16:33.980 --> 16:37.500]  сказано о том, что если вы сделаете несколько измерений,
[16:37.500 --> 16:41.860]  случайность уходит, идея ясна, то есть та вещь, которая
[16:41.860 --> 16:45.180]  у вас просто на уровне интуиции находится, да, ну потому
[16:45.180 --> 16:47.340]  что если бы вот вообще за рамками тервера вам бы
[16:47.340 --> 16:50.660]  описали задачу, ну как-то красиво её там назвали, вы
[16:50.660 --> 16:53.380]  бы этот ответ сказали, что надо сделать, ну нужно
[16:53.380 --> 16:55.780]  сделать несколько измерений, взять среднее арифметическое,
[16:56.020 --> 17:00.420]  закон больших чисел это обосновывает, давайте докажем,
[17:00.420 --> 17:09.420]  как нас учит, Тихон делается действительно очень просто,
[17:09.420 --> 17:16.580]  посмотрим, вот здесь мы обсудили, что поскольку
[17:16.580 --> 17:20.380]  у нас есть одинаковая распределённость, дисперсии одинаковые, поэтому
[17:20.380 --> 17:31.780]  достаточно только первые, это не похмелье, чтобы вы
[17:31.780 --> 17:34.620]  думали, я просто плохо себя чувствую, я что-то понял,
[17:34.620 --> 17:42.220]  что смотреть в кадре совсем плохо, погнали, понятно,
[17:42.220 --> 17:48.540]  что это вероятность, она в точности из условий неравенства
[17:48.540 --> 17:51.420]  чепешоу, то есть вот у вас, ну вот та вот случайная
[17:51.420 --> 17:55.540]  величина кси, вы вычитаете её математическое ожидание,
[17:55.540 --> 17:57.420]  потому что видно, что мат ожидания вот этой дроби
[17:57.420 --> 18:01.740]  это и есть мат ожидания кси1, это же видно, да, ну вот
[18:01.740 --> 18:05.460]  поэтому я даже звёздочку обозначу, ну а что получается,
[18:05.460 --> 18:07.980]  что в силу неравенства чепешоу звёздочка меньше или
[18:07.980 --> 18:13.700]  равна, чем дисперсия, дисперсия чего, ну вот это
[18:14.700 --> 18:19.900]  то есть кси1 плюс и так далее кси n делить на n и всё это
[18:19.900 --> 18:23.740]  мы делим на epsilon в квадрате, теперь смотрим дисперсия
[18:23.740 --> 18:33.780]  дроби, как она прообразуется, ну вот эта штучка выносится
[18:33.780 --> 18:37.220]  из-под дисперсии в квадрате, ну в силу свойств дисперсии,
[18:37.220 --> 18:40.420]  то есть у нас будет epsilon в квадрате на n в квадрате,
[18:40.420 --> 18:45.860]  ну вот, дальше у нас получается дисперсия сумма, да, они
[18:45.860 --> 18:56.380]  независимы, поэтому получается сумма дисперсии, дальше
[18:56.380 --> 18:59.780]  мы что видим, что дисперсии у нас одинаковые, но они
[18:59.780 --> 19:04.620]  предположим равно sigma в квадрат, ну вот, кстати у
[19:04.620 --> 19:07.260]  нас здесь получается n sigma в квадрат, делить на epsilon
[19:07.260 --> 19:09.900]  в квадрате на n в квадрате, насчёт sigma в квадрат у нас
[19:10.740 --> 19:14.260]  всегда дисперсия в это науке обозначается как sigma в
[19:14.260 --> 19:16.780]  квадрате, ну то есть sigma это среднее квадратическое
[19:16.780 --> 19:19.560]  отклонение, я о нем говорил, это такое оно дисперсия,
[19:19.560 --> 19:21.980]  а дисперсия обозначается как sigma в квадрате, при
[19:21.980 --> 19:23.940]  этом сред Kiddo акунares seit struck in this context we and will
[19:23.940 --> 19:26.860]  не когда дисперсию будем пользоваться всегда, но
[19:26.860 --> 19:28.900]  именно она обозначается как sigma в квадрате, чувствуете
[19:28.900 --> 19:32.200]  отсутствие логики, ничего страшного, вы привыкаете,
[19:32.200 --> 19:37.320]  то есть как бы так всегда, всё видно, что это стремиться
[19:37.320 --> 19:43.400]  к нулю упрямин стремляющимся к бесконечности. Что мы могли ослабить? То есть все доказали. Ура!
[19:43.400 --> 19:57.520]  Что можно было легко ослабить в нашей истории? Принимаются… Ну, что можно было легко ослабить здесь?
[19:57.520 --> 20:04.840]  Первое замечание насчет независимости. Нафиг она нам нужна. Мы с вами договорились,
[20:04.840 --> 20:10.600]  что дисперсия суммы распагается в сумму дисперсии, если слагаемая попарно некоррелирована,
[20:10.600 --> 20:15.440]  то есть квадрация их равна нулю. А мы с вами договаривались то, что требование некоррелированности
[20:15.440 --> 20:19.480]  случайных величин намного более слабее, чем независимость. Поэтому от независимости
[20:19.480 --> 20:32.280]  первую можно было избавиться. А насчет… Что еще? Ну то есть от чего можно было легко избавиться? От
[20:32.280 --> 20:35.480]  одинаковой распределенности тоже можно было легко избавиться, потому что чем мы пользовались?
[20:35.480 --> 20:40.560]  Во-первых, нам нужно было что сделать? Во-первых, чтобы мот ожидания были одинаковые. Кстати,
[20:40.560 --> 20:45.240]  нам этим можно было не пользоваться. Если бы мы здесь писали не минус А, а минус там сумма мот
[20:45.240 --> 20:52.760]  ожидания деленных на Н, это вообще нам не нужно. А дисперсия, что нам нужно? В общем там…
[20:52.760 --> 21:02.520]  Скажите, пожалуйста, вот эту сумму должна быть какой, чтобы это в результате стремилось к нулю?
[21:02.520 --> 21:14.400]  Как можно? По маленькой от Н. А поточнее? От Н, да, нет, сумма. От Н в квадрате? Зачем от Н?
[21:14.400 --> 21:21.120]  У малой от Н в квадрате. Мы понимаем дисперсии, ксиитах – это какие-то числа, мы складываем их
[21:21.120 --> 21:25.240]  по количеству равно Н. Если вот эта дрянь в результате будет у малого от Н в квадрате,
[21:25.240 --> 21:30.240]  этого достаточно для того, чтобы это стремилось к нулю. То есть на самом деле это тоже можно было
[21:30.240 --> 21:34.680]  ослабить. А дальше внимание вопрос. Если все это можно было ослабить, нафиг я так доказывал?
[21:34.680 --> 21:40.080]  Доказательство, кстати, бы не пострадало нисколько. Оно было бы таким же простым. Почему именно в таком
[21:40.080 --> 21:51.080]  виде я сформулирую закон больших чисел? Ну, в смысле, применяется. То есть закон, вы должны
[21:51.080 --> 21:57.240]  понимать, что законы больших чисел очень много в разных вариациях. То есть как вы правильно говорите
[21:57.240 --> 22:02.240]  о том, что вот это есть сходимость по вероятности. Есть закон больших чисел, так называемый усиленный
[22:02.240 --> 22:10.520]  закон больших чисел, где будет сходимость почти, наверное, она же почти всюду. Ну вот, поэтому нет.
[22:10.520 --> 22:16.120]  А второе какое было замечание? Ну так как понятно хотя бы о чем речь, о чем ценности
[22:16.120 --> 22:21.600]  результата. То есть я же говорил о чем, то что у вас ксишки – это есть независимые как бы результаты.
[22:21.600 --> 22:25.960]  Одно это уже эксперимент, который вы проводите случайно. И потом вы просто складываете и делите
[22:25.960 --> 22:31.760]  на Н. Ну понятно, что если они одинаковые и вы их проводите независимо друг от друга, то вот это
[22:31.760 --> 22:38.680]  нужно. Идея ясна? Хорошо. Законы больших чисел у вас будет много разных, хороших, будете их доказывать.
[22:38.680 --> 22:45.320]  Ну вот, единственное, только это все будет сильно сложнее, чем вот это. И второй результат – центральная
[22:45.320 --> 22:59.840]  предельная теория. С вашего позволения, вот здесь вот все будет то же самое. Условия, я имею в виду. То есть
[22:59.840 --> 23:04.120]  у вас есть последовательность независимых одинаковых с определенных случайных величин. У них
[23:04.120 --> 23:17.320]  существует дисперсия, мат ожидания обозначается как А. Центральная – это С. Центральная предельная
[23:17.320 --> 23:38.080]  теорема. Центральная предельная теорема. Давайте я еще вот обозначу СН и кси1 плюс ксен. Вот это условие.
[23:38.080 --> 23:43.160]  Вот эта первая часть. У вас есть последовательность независимых одинаковых с определенных. У них
[23:43.160 --> 23:47.720]  существует дисперсия, которую мы обозначаем как сигма квадрата. Ну и мы от ожидания мы обозначим
[23:47.720 --> 23:54.600]  А. И сейчас у меня будут другие обозначения. Я молодец, ладно, простите меня, пожалуйста.
[23:54.600 --> 24:06.160]  Так, соответственно, что мы делаем? Если мы возьмем нашу сумму и ее концентрируем, то есть вычислим из нее
[24:06.160 --> 24:13.680]  математическое ожидание. Дальше мы ее отнормируем, то есть разделим на корни с дисперсией.
[24:13.680 --> 24:24.760]  С. Центральная. Сейчас мы с вами выпишем как это выглядит, но то тогда вероятность того,
[24:24.760 --> 24:36.520]  что вот эта дробь, зажата между А и B, будет стремиться при настримящемся бесконечности
[24:36.520 --> 24:49.920]  Контеграу от A до B. Единицы разделить на корни из 2P, E в степени минус x квадрат пополам dx.
[24:49.920 --> 25:03.760]  Что, красота? Скажите спасибо, что я это не доказываю. E в степени x квадрат пополам.
[25:03.760 --> 25:15.000]  Какой-то год я даже пытался это доказывать в ситуации, когда ксишечки это у вас
[25:15.000 --> 25:19.880]  Бернулевские случайные величины. Вы помните, что такое Бернулевские случайные величины?
[25:19.880 --> 25:29.280]  Нет. Она принимает значение 1 и 0 с вероятностью P единичка минус P. Соответственно, если у меня
[25:29.280 --> 25:38.040]  ксишечки Бернулевские случайные величины, то Sn это кто? Я подожду. Бермяальная случайная
[25:38.040 --> 25:44.840]  величина. Ну это понятно, потому что сумма N независимых каждой принимает значение 0 и 1 с
[25:44.840 --> 25:52.600]  вероятностью P единичка минус P. Соответственно, Sn будет иметь бермяальное распределение. В принципе,
[25:52.600 --> 25:58.800]  то есть где-то там три страницы мышенаписанного текста вы это доказали. Потому что понятно,
[25:58.800 --> 26:04.520]  что вот эти вероятности это что? Если вот это у вас Бермяальная случайная величина, то это всякие
[26:04.520 --> 26:10.600]  цели из N по К по f степени K единица минус f степени N минус K формулы стирлинга. Потому что N это
[26:10.600 --> 26:17.360]  стремится к бесконечности. И прямо там такое удовольствие. Кто хочет, может посмотреть,
[26:17.360 --> 26:23.800]  как это доказывается. Называется интегральный терроримовый ровопласт. В общем, толку никакого,
[26:23.800 --> 26:28.640]  потому что там идёт любимая Рыгоровская комбинаторика. Ну всякие вот эти выкутки я
[26:28.640 --> 26:35.880]  терпеть не могу. Понимание это не даёт. Давайте всё-таки попробуем понять, что здесь происходит.
[26:35.880 --> 26:43.720]  На что вот это похоже? Ну то есть как бы слева понятна вероятность того, что какая-то случайная
[26:43.720 --> 26:46.640]  величина. Пока не понятно, зачем мы её так составляли, но вот такая случайная
[26:46.640 --> 26:58.720]  величина зажата между чиселками a и b. И утверждается, что эта вещь сходится куда. Может кто-то чувствует,
[26:58.720 --> 27:05.960]  что это такое? Горбик это вы про вот эту вот функцию. То есть это действительно у вас так называем
[27:05.960 --> 27:11.320]  плотность нормального распределения, колка гауссовский стандартный. А когда мы берём интеграл от a до b,
[27:11.320 --> 27:19.120]  мы тем самым что делаем? Ну а какой вероятностный смысл этой площади? Интуитивно понятно, нет?
[27:19.120 --> 27:29.440]  Это вероятность. Вот это вот, это вероятность того, что случайная величина эта, которая имеет
[27:29.440 --> 27:35.920]  нормальное распределение с параметрами 0 и 1, попадает в интервал от a до b.
[27:41.520 --> 27:45.840]  У вас ещё нет нормального распределения, потому что это не дискритное распределение,
[27:45.840 --> 27:53.580]  никаких других распределений вы пока не знаете. Ну то есть проблема вот в чём. То есть как бы в те
[27:53.580 --> 28:00.360]  веры, вы пройдёте произволенные распределения, в частности абсолютно непрерывные. Αбсолютно
[28:00.360 --> 28:09.080]  непрерывное распределение, то есть это имеет абсолютно непрерывное распределение, если
[28:09.080 --> 28:16.080]  что вероятность того, что это попадает в какое-то множество а, есть интеграл по множеству а вот этой функции.
[28:16.080 --> 28:27.080]  То есть вот это вот у вас будет потом такое определение. То есть понятно, теперь вот это вот понятно,
[28:27.080 --> 28:34.080]  что вот такой интеграл, вероятность попасть в интервал от a до b, где вот эта штука, это есть плотность нашей случайно-минечной.
[28:34.080 --> 28:40.080]  Вот такие случайно-минечные. То есть вот это вот плотность нормальной случайно-минечной, причем с хорошими параметрами 0.1.
[28:40.080 --> 28:46.080]  Параметры нормального распределения это на будущее, привыкайте к этому. Первый параметр это математическое ожидание,
[28:46.080 --> 28:51.080]  второй параметр это дисперсия. Кстати, вопрос в студию. Какое математическое ожидание этой дроби?
[28:51.080 --> 29:00.080]  А дисперсия? Это видно, да? Теперь давайте попытаемся понять, о чем говорит этот результат.
[29:00.080 --> 29:08.080]  То есть я беру оба какие случайные величины. То есть смотрите, вот о распределении этих случайных величин не известно ничего.
[29:08.080 --> 29:20.080]  То есть если я в качестве кси возьму вот эти Бернульевские, которые принимают значение 0.1, то есть проще там только констант.
[29:20.080 --> 29:28.080]  Слушайте, единственное, только вот ты здесь не ноль, чтобы я делить мог.
[29:28.080 --> 29:39.080]  Или я возьму какие-то сложные случайные величины, например Плассоновские, или потом вы пройдете непрерывные распределения.
[29:39.080 --> 29:47.080]  То есть вне зависимости от того, какое у вас распределение случайной величины ксен, вы всегда сойдетесь к нормальному распределению.
[29:48.080 --> 29:58.080]  Вот в этот момент, вот прелесть Тервьера, причем опять это все идет к тайной мирозданию, какого фига это так.
[29:59.080 --> 30:07.080]  Причем очень было забавно, когда у меня такая работа была немножко устаревшая, в плане постановки задач.
[30:07.080 --> 30:17.080]  Я читал кучу всяких статей 80-х годов, и там был вопрос о том, что вот я писал вам вот эту задачку.
[30:17.080 --> 30:24.080]  Ксиитр равняется Ц плюс Эпслунитр. Эпслунитр это шум, который возникает.
[30:24.080 --> 30:32.080]  И практически всегда было предположение, что этот шум имеет нормальное распределение с параметрами 0 сима квадрата.
[30:32.080 --> 30:40.080]  Ну, 0, потому что от ожидания оно не должно быть не нулем, потому что иначе у вас постоянно есть ошибка, которая сносит ваше наблюдение.
[30:40.080 --> 30:44.080]  Ну и какая-то там дисперсия. И дальше было очень интересно наблюдать.
[30:44.080 --> 30:49.080]  А кто вам сказал, что у этого шума нормальное распределение? Это было шикарно.
[30:49.080 --> 30:58.080]  То есть математики говорили, что все вот эти прикладники, у них есть огромные базы наблюдений и всегда получается колокол, поэтому нормальное распределение.
[30:58.080 --> 31:04.080]  А прикладники в своих статьях писали о том, что математики доказали, что шум всегда имеет нормальное распределение.
[31:04.080 --> 31:06.080]  Было очень забавно.
[31:06.080 --> 31:15.080]  Но такое объяснение, почему у шума нормальное распределение, потому что шум складывается из огромного количества факторов с небольшим весом.
[31:15.080 --> 31:21.080]  Типа, когда очень много всего, получаем нормальное распределение, ссылаясь на центральное определение теоремы.
[31:21.080 --> 31:25.080]  Чувствуется, что объяснение так себе.
[31:25.080 --> 31:33.080]  Ну а потом пошли финансы, в которых шум уже ненормальный, и поэтому перестали задаваться этим вопросом.
[31:33.080 --> 31:46.080]  Фишка в том, что в конце тервера вам докажут этот результат, для этого будет построена целая техника,
[31:46.080 --> 31:56.080]  потому что вы можете открыть Ширяеву и любую другую книжку, посмотреть, как доказывается интегральный терминал вопроса и просто почувствовать тошноту, потому что это отвратительно.
[31:56.080 --> 32:02.080]  Но там безумные выкладки, которые тяжелые, и зачем это все нужно непонятно.
[32:02.080 --> 32:10.080]  При этом с помощью характеристических функций доказывается бусквально несколько строк, и вы это сделаете в общем случае.
[32:10.080 --> 32:18.080]  И это все произойдет, к сожалению, в конце курса. Обычно центральные определение теорем плохо воспринимают, потому что все, что в конце курса, плохо воспринимается.
[32:18.080 --> 32:20.080]  Это так работает.
[32:20.080 --> 32:25.080]  Но я хочу, чтобы вы уже сейчас оценили прелести результата.
[32:25.080 --> 32:40.080]  Что вне зависимости от того, какие были распределения ваших случайных величин СНТ, впорядок того, что они могут быть дискретные, самые простые или какие-то очень сложные, непрерывные, все равно в пределе всегда получится нормальное распределение.
[32:40.080 --> 32:48.080]  Поэтому, когда у вас появится это нормальное распределение, не надо плеваться, потому что даже без параметров это отвратительно.
[32:48.080 --> 32:57.080]  Е в степени минус 6,5, господи, у этой функции даже первообразной нет. Вы знаете, что у этой функции нет первообразной?
[33:01.080 --> 33:03.080]  Хотите анекдот?
[33:03.080 --> 33:09.080]  Я когда во второй школе учился, я очень хорошо первообразный считал.
[33:09.080 --> 33:12.080]  И у моей учительницы карточки закончились в какой-то момент.
[33:12.080 --> 33:14.080]  Ну, то есть дополнительные задачи.
[33:14.080 --> 33:18.080]  И она говорит, ну ладно, все, давай, интегрируй.
[33:18.080 --> 33:22.080]  Я до слез, честно.
[33:22.080 --> 33:24.080]  Потом дома сидел долго.
[33:24.080 --> 33:26.080]  Причем я к ней ходил, я говорю, что, как?
[33:26.080 --> 33:28.080]  Она говорит, ой, отстань, некогда того заниматься.
[33:28.080 --> 33:31.080]  У меня там много двоечников, и я буду им заниматься.
[33:31.080 --> 33:33.080]  В втором курсе я узнал.
[33:35.080 --> 33:37.080]  Потом я прихожу и говорю, что это такое?
[33:37.080 --> 33:39.080]  Она говорит, я ничего не помню.
[33:41.080 --> 33:45.080]  Когда у вас появится на тервере нормальное распределение,
[33:45.080 --> 33:52.080]  причем с параметрами, то есть если у вас n, с параметрами a sigma квадрат, плотность будет выглядеть, прости меня, вот так вот.
[33:58.080 --> 34:00.080]  То есть мерзость.
[34:00.080 --> 34:04.080]  Но чтобы вы осознали, что вы от нормального распределения никуда не денетесь,
[34:04.080 --> 34:07.080]  поэтому с ним нужно будет очень внимательно, аккуратно разобраться.
[34:07.080 --> 34:10.080]  Потому что это самое главное распределение в тервере вероятности.
[34:10.080 --> 34:12.080]  Окей?
[34:12.080 --> 34:13.080]  Хорошо.
[34:13.080 --> 34:15.080]  Соответственно, доказывать эту историю я не буду.
[34:18.080 --> 34:23.080]  Даже для самой простой ситуации.
[34:23.080 --> 34:24.080]  Но опять же вопрос.
[34:24.080 --> 34:36.080]  То, что вот здесь вот, что вот этот результат это view один educ cancers как видисходности вот этой случайной величины к нормальной случайной величине.
[34:38.080 --> 34:44.080]  Вероятность того, что случайная величина принадлежит отрезку Huh, стремится к веро continua Eles 가� Mars, что другая случайная волна принадлежит этому же отрезку.
[34:44.080 --> 34:50.080]  Понятно, что этот результат кажется, что это head enhance вот этого к нормальной случайной величине.
[34:50.080 --> 34:53.560]  Это тип сходимости, сходимость по распределению или так
[34:53.560 --> 34:56.680]  называемая слабая сходимость, мы ее не коснемся, но она
[34:56.680 --> 34:58.200]  в тервере потом появится.
[34:58.200 --> 35:02.560]  Мне просто не хватит времени для того, чтобы с этим разобраться.
[35:02.560 --> 35:08.320]  У нас будет два основных вида сходимости.
[35:08.320 --> 35:11.520]  Это сходимость почти всюду или почти наверно в тервере
[35:11.520 --> 35:15.240]  и сходимость по мере или по вероятности как в тервере.
[35:15.240 --> 35:18.000]  Мы будем именно с этими двумя результатами работать.
[35:18.000 --> 35:19.000]  Это понятно, киваем.
[35:19.000 --> 35:23.600]  Слушайте, а то, что у нас никогда не бывает перерыв,
[35:23.600 --> 35:24.600]  это не проблема?
[35:24.600 --> 35:25.600]  Нормально.
[35:25.600 --> 35:26.600]  Нормально.
[35:26.600 --> 35:36.280]  С тервером все.
[35:36.280 --> 35:38.760]  Давайте сейчас соберем вместе те вопросы, которые
[35:38.760 --> 35:45.600]  мы с вами разбирали, формулировали в процессе разбора вот
[35:45.600 --> 35:50.440]  этих поверхностных терверных результатов и дальше начнем
[35:50.440 --> 35:51.440]  их разбирать.
[35:51.440 --> 35:55.200]  Соответственно, первые два вопроса, которые взаимосвязаны
[35:55.200 --> 35:56.200]  между собой.
[35:56.200 --> 35:59.760]  Я напомню то, что мы работаем в рамках итематической
[35:59.760 --> 36:05.680]  модели, когда у нас база является вероятностное пространство.
[36:05.680 --> 36:13.120]  Первое это вероятность элементарных исходов, множество событий
[36:13.120 --> 36:16.720]  и вероятностные меры на событиях.
[36:16.720 --> 36:21.520]  Первый вопрос, который есть каково f, что это такое?
[36:21.520 --> 36:24.320]  Потому что всегда, когда мы работали в дискретной
[36:24.320 --> 36:27.520]  тервере вероятности в качестве f, у нас было что?
[36:27.520 --> 36:31.320]  Множество всех под множество омега большого, мы не напрягались.
[36:31.320 --> 36:35.680]  Но даже простейшая история, когда мы решали задачку
[36:35.680 --> 36:40.000]  с геометрической вероятностью, то есть мы кидали точку
[36:40.000 --> 36:45.000]  на какую-то площадь РН, и там было понятно, что
[36:45.000 --> 36:46.000]  такое вероятность.
[36:46.000 --> 36:48.800]  Мы упирались в то, что не для каждого под множество
[36:48.800 --> 36:53.120]  нашего омега большого мы можем задать эту вероятность.
[36:53.120 --> 36:56.200]  То есть мы не можем в общем случае в качестве f брать
[36:56.200 --> 36:59.360]  просто так множество всех под множество.
[36:59.360 --> 37:02.360]  Потом у нас окажется, что на самом деле, не потом,
[37:02.360 --> 37:05.520]  уже даже сейчас понятно, почему мы не можем задать
[37:05.520 --> 37:06.520]  там вероятность.
[37:06.520 --> 37:08.320]  Потому что есть неизмеримые полебегу множества.
[37:09.320 --> 37:12.160]  Как мы с вами знаем, они есть, но мы не представляем,
[37:12.160 --> 37:13.160]  как они выглядят.
[37:13.160 --> 37:16.400]  И поэтому задаться вопросом о том, вероятность того,
[37:16.400 --> 37:18.520]  что мы попадем в неизмеримые полебегу множества, это
[37:18.520 --> 37:19.520]  какой-то мазохизм.
[37:19.520 --> 37:25.840]  Есть как бы, то есть, вы сейчас, извините, так плохо
[37:25.840 --> 37:26.840]  говорится сегодня.
[37:26.840 --> 37:32.680]  Тезис о том, что мы страдаем просто для того, чтобы страдать,
[37:32.680 --> 37:33.680]  он не работает.
[37:33.680 --> 37:34.680]  Это понятно?
[37:34.800 --> 37:39.040]  Ну то есть, если что-то больно, то значит вы не допонимаете,
[37:39.040 --> 37:40.040]  то есть нет!
[37:40.040 --> 37:42.460]  Если больно, оно как бы больно, это не значит, что
[37:42.460 --> 37:43.460]  плохо.
[37:43.460 --> 37:44.760]  Но как бы вы должны понимать, для чего это больно.
[37:44.760 --> 37:47.360]  Если вам кажется, что это как бы больно, просто для
[37:47.360 --> 37:50.220]  того, чтобы было больно, значит вы чуть не допонимаете.
[37:50.220 --> 37:52.560]  Надо попытаться это выяснить.
[37:52.560 --> 37:55.520]  То есть можно это выяснить у преподавателей, если
[37:55.520 --> 37:57.640]  они ответ не дают, надо идти к академическому руководителю
[37:57.640 --> 38:00.260]  вашей программы, и спрашивать, зачем эта хрень нам нужна.
[38:00.260 --> 38:01.880]  Это понятно?
[38:01.880 --> 38:10.280]  и он должен суметь на это ответить. Идеальных академических руководителей не существует,
[38:10.280 --> 38:21.280]  но может быть он сможет. Следующий вопрос о том, как задавать эту меру. Потому что если у вас F
[38:21.280 --> 38:26.000]  это будет какая-то система под множество, всё равно это будет богатой историей, там будет очень
[38:26.000 --> 38:33.200]  много множеств. И дальше вам что нужно? Каждому множеству сопоставить вероятность, то есть меру
[38:33.200 --> 38:41.560]  этого множества. Как это вообще задаётся, это непонятно. Потому что функция задаётся формуле,
[38:41.560 --> 38:58.600]  вы к этому привыкли. Вы знаете, что она есть, что вы объем умеете считать для произвольных множеств.
[38:58.600 --> 39:16.360]  Вот это вот. Супремум или инфинум по всем покрытиям. Ну хорошо. В общем случае хотелось бы понять,
[39:16.360 --> 39:22.680]  как это вообще делать. Следующая проблема, которая у нас с вами возникла с понятием случайной
[39:22.680 --> 39:28.760]  величины. Что это такое? Я напомню в чём была проблема. Нас в конечном счёте с вами будут
[39:28.760 --> 39:37.320]  интересовать вероятности вот таких событий. То есть это что? Это вероятность таких омега маленьких,
[39:37.320 --> 39:44.160]  что кси принадлежит множеству от а до плюс бесконечности. То есть по сути это что такое? Это
[39:44.160 --> 39:57.640]  есть прообраз луча от а до плюс бесконечности. Всё понятно, что я написал, да? Ну то есть вот это
[39:57.640 --> 40:03.760]  просто я расшифровал. Это вероятность всех таких омег, что вот это. Но это и есть просто прообраз вот
[40:03.760 --> 40:09.000]  этого луча. И дальше вопрос. Кто вам обещал, что вот эта хрень будет принадлежать f, если f не множество
[40:09.000 --> 40:13.120]  всех подножий? Мы с вами вообще не напрягались, потому что у нас был дискретный случай, f будет
[40:13.120 --> 40:17.600]  множество всех подножий. Поэтому это какое-то подножие омега большого, значит точно принадлежит f.
[40:17.600 --> 40:25.120]  Если мы ограничиваем f, то кто вам сказал, что это будет его элементом? Никто. Отсюда вывод.
[40:25.120 --> 40:29.320]  Определять случайную величину просто как какую-то числовую характеристику случайного
[40:29.320 --> 40:35.440]  эксперимента нельзя. Вы можете упереться в ситуацию, что эта вещь будет неопределена. То
[40:35.440 --> 40:41.840]  есть надо как-то ограничивать себя в определении случайной величины и мы будем с вами выяснять как.
[40:41.840 --> 40:50.240]  Четвёртый вопрос. Это сходимость случайных величин. Потому что основные результаты теории
[40:50.240 --> 40:54.600]  вероятности это все-таки предельные результаты. Вот того типа, который мы с вами выписывали.
[40:54.600 --> 40:59.560]  Придельные. То есть это про предел, принятость, объявляющимся к бесконечности. Для кого? Для
[40:59.560 --> 41:03.720]  последовательности случайных величин, которые как правило будут строиться подобным образом как
[41:03.720 --> 41:16.640]  суммы. Что-то с суммами мы там делаем. Поэтому вопрос о сходимости. Как они сходятся? Пятый вопрос,
[41:16.640 --> 41:22.160]  который есть тоже непонятный. Вопрос про моменты, про математическое ожидание. Потому что мы с вами
[41:22.160 --> 41:30.480]  определили, мы отождаем. Когда мы его вводили, мы оттолкнулись от понятия среднего в случайном
[41:30.480 --> 41:36.440]  эксперименте. Отсюда вывели в нашей мат-модели определение математического ожидания. Это что
[41:36.440 --> 41:47.400]  там? Это сумма по всем омегам маленьким. П от омега на окси от омега. Понятно, что эта штука
[41:47.400 --> 41:56.280]  похожа на интегральную сумму. Это у вас дельта х, это мера х. А это значение вашей функции при
[41:56.280 --> 42:03.600]  этих х. Эта штука похожа на интегральную сумму. Поэтому в общем случае математическое ожидание
[42:03.600 --> 42:09.960]  будет интегралом. Спойлер, что это будет интеграл Лебега. Но опять же, строить интеграл Лебега
[42:09.960 --> 42:16.080]  мы пока не умеем в ситуации, когда у нас область определения нашей функции это нечто. Я напомню то,
[42:16.080 --> 42:23.320]  что у нас с вами омега это множество, на котором нету ничего кроме какой-то системы подмноженств.
[42:23.640 --> 42:33.040]  Там нету метрики, там нету топологии, нету ничего. И вы пока не умеете строить интеграл Лебега в таких
[42:33.040 --> 42:39.400]  суровых обстоятельствах. Это понятно? На эти пять вопросов нам с вами нужно будет до конца декабря
[42:39.400 --> 43:02.920]  ответить. Окей, киваю. Хорошо, начнем с системы множества. Так, система множества. А поднимите,
[43:02.920 --> 43:11.120]  пожалуйста, руки, кто в посвяти задействовал. Черт, то есть у вас не будет, жалко. Просто у вас
[43:11.120 --> 43:19.720]  становится все меньше. Каждый слушатель уже на это нарезал. Так, система множества. Смотрите,
[43:19.720 --> 43:31.960]  вот эти вот два вопроса идут в связке. Почему? Потому что не надо делать F чересчур богатый.
[43:31.960 --> 43:40.080]  Это понятно, да? Но потому что чем богаче F, тем непонятнее, как задавать на ней P. Поэтому нужно,
[43:40.080 --> 43:46.240]  когда вы определяете F, ограничиться только теми множествами, которые нам нужны, раз,
[43:46.240 --> 43:53.360]  чтобы было попроще задавать P. Так, соответственно, первая система множества. То есть мы сейчас что
[43:53.360 --> 44:00.760]  сделаем? Мы сейчас формулируем последовательно систему множества от самых бедных к тем,
[44:00.760 --> 44:06.480]  которые нам нужны. Не продумываю я этот переход логически. Поэтому в общем,
[44:06.480 --> 44:29.040]  просто с определением начнем. Система множеств S называется полукольцом. Если система множеств,
[44:29.040 --> 44:37.760]  то есть каждый элемент S это какое-то множество. Если выполна следующее требование. Первое. Пустое
[44:37.760 --> 44:46.440]  множество является элементом этой системы множества. Второе. Эта система множества замкнута относительно
[44:46.440 --> 44:51.280]  операции пересечения. То есть, если у вас два множества являются элементом S, то их пересечение
[44:51.280 --> 44:59.560]  тоже должно быть элементом S. И третье требование, что если у вас есть два элемента S,
[44:59.560 --> 45:11.920]  при этом выполнено то, что один из них является под множеством другого, то утверждается,
[45:11.920 --> 45:19.080]  что вот это множество можно добить элементом S до этого множества. Что это значит? Что существуют
[45:19.080 --> 45:27.240]  конечное число элементов нашей системы такие, что множество A представили в виде дизюктного
[45:27.240 --> 45:36.000]  объединения, а этих поет единички до N. Так вы же знаете, что такое дизюктное объединение. Это ирония
[45:36.000 --> 45:51.080]  или... Ну да. Хорошо, ладно. То есть мысль какая? Это достаточно бедная система множества.
[45:51.080 --> 46:15.000]  Давайте рассмотрим пример. Рассмотрим систему полуинтервалов, которые являются под множеством
[46:15.000 --> 46:25.760]  какого-то фиксированного полуинтервала. Докажем, что это полукольцо. Ничего нам нужно проверить.
[46:25.760 --> 46:30.880]  Во-первых, нам нужно проверить, что пустое множество является элементом A и B. Соответственно,
[46:30.880 --> 46:47.760]  это число, а на A и B это число, которое удовлетворяет вот этому требованию. Ну погнали. Первое. Пустое
[46:47.760 --> 47:00.000]  множество является элементом этой системы. Да или нет? Да. Почему? Хорошо. Дальше. Пересечения
[47:00.000 --> 47:08.640]  являются... Ну да. Можно? Давайте я корзиночку наносю. Если вы берете два полуинтервала,
[47:08.640 --> 47:16.040]  то их пересечение это полуинтервал. Ну либо пусто. Поскольку пустое является элементом S,
[47:16.040 --> 47:24.840]  если это пусто, это уже хорошо для нас. И третье. Если у вас вдруг так оказывается,
[47:24.840 --> 47:31.280]  что какой-то полуинтервал является под множеством другого полуинтервала, то вы его можете добить
[47:31.280 --> 47:36.360]  конечным объединением. Но видно, что это правда. Ну соответственно, у вас может быть как? Тут
[47:36.360 --> 47:41.320]  никакая граница не совпадает. Тогда вот этот маленький можно добить вот этими двумя до большого.
[47:41.320 --> 47:49.280]  Но если вдруг какая-то граница совпала, то одним. Это понятно? Окей. При этом очевидно,
[47:49.520 --> 47:54.600]  что вот эта система множеств не замкнута относительно операции объединения. hate
[47:54.600 --> 48:00.660]  объединения двух полуинтервалов не есть полуинтервал. Ну это понятно. Если они не пересекаются,
[48:00.660 --> 48:07.060]  вы их объединяете, получаете объединение двух полуинтервалов с дыркой посередине. Ну ладно.
[48:08.560 --> 48:12.520]  С одной стороны, это система множества она плюс-минус хороша в том плане,��도 что она
[48:12.520 --> 48:15.980]  замкнута относительно операции пересечения. Потом вот это хрень какая-то непонятная,
[48:15.980 --> 48:22.080]  понятно, зачем это спрашивают. Пока тайно. Но очевидно
[48:22.080 --> 48:24.320]  ее нам мало, потому что она не замкнута относительно
[48:24.320 --> 48:27.640]  тех теоретикам множных операций, которые нас интересуют.
[48:27.640 --> 48:33.320]  Поэтому ведем следующий объект. Это кольцо. Дайте
[48:33.320 --> 48:46.520]  вот сюда. Мне здесь хватит. Кольцо. Кольцо называется
[48:46.520 --> 48:56.000]  системой множеств. Обозначать мы ее будем как R. Как вы
[48:56.000 --> 49:08.880]  думаете, почему R? Да, мы все любим этот фильм. Что
[49:08.880 --> 49:16.560]  выполнено следующее? Во-первых, R не пусто. Во-вторых, R замкнута
[49:16.560 --> 49:19.840]  относительно двух операций. То есть для любых A и B, которые
[49:20.840 --> 49:27.060]  будет выполнено. То, что A пересеченная с B и A симметрическая
[49:27.060 --> 49:35.000]  разность B тоже будут являться элементами R. Какие вопросы
[49:35.000 --> 49:48.500]  у нас возникают? Во-первых, да. Кажется, что судя по
[49:48.500 --> 49:52.220]  названию, это должна быть более сложная структура.
[49:52.220 --> 49:55.820]  Эта структура должна обладать всеми теми свойствами. Это
[49:55.820 --> 50:03.060]  пока не очень понятно. И второе. Странный набор
[50:03.060 --> 50:12.700]  этих самых операций. Симметрическая разность. Соответственно,
[50:12.700 --> 50:15.060]  второе то, что кольцо замкнута относительно всех теоретикам
[50:15.060 --> 50:23.180]  множественных операций. Давайте это докажем. Так,
[50:23.180 --> 50:38.060]  если R кольцо, то. Во-первых, R полукольцо. И второе. Для
[50:38.060 --> 50:42.300]  любых A и B, принадлежащих R, будет выполнено. Какие у
[50:42.300 --> 50:44.300]  нас еще были операции с теоретиками множественных?
[50:44.300 --> 50:48.220]  То есть A объединенная с B. Еще что? Такие стандартные.
[50:48.220 --> 51:05.500]  A без B. A без B. Тоже будет элементом R. Никогда не сдавался этим
[51:06.500 --> 51:23.340]  логичным. Не знаю, я уточню. Вот так вот живешь и живешь,
[51:23.340 --> 51:31.380]  а тебя вдруг спросит. Хорошо. Погнали. Первое. То, что
[51:31.380 --> 51:34.580]  оно действительно полукольцо. Первое, что пустое множество
[51:34.580 --> 51:42.380]  принадлежит S. Почему? R не пусто, то есть есть какой-то
[51:42.380 --> 51:48.700]  элемент R. Тогда симметрическая разность A с A это есть пустое
[51:48.700 --> 51:52.260]  множество. Согласно второму свойству, это тоже элемент
[51:52.260 --> 51:57.940]  R, а R хорошо пустое является элементом R. Так, сейчас
[51:57.940 --> 52:02.300]  скажи. Вижу недоуменные лица. Что не так? R не пустое
[52:02.300 --> 52:04.780]  множество. То есть там кто-то есть. Если мы его симметрично
[52:04.780 --> 52:08.420]  с самим собой пересечем, мы получим пустое множество.
[52:08.420 --> 52:12.060]  Все его определения симметрической разности. Все знают определения
[52:12.060 --> 52:13.060]  симметрической разности.
[52:13.060 --> 52:20.060]  Почему мы требуем линии пустоту вместо того, чтобы
[52:20.060 --> 52:35.060]  требовались просто что-то содержимое пустое множество?
[52:35.060 --> 52:38.340]  Какие-то вопросы сегодня задаете, которые я не знаю,
[52:38.340 --> 52:44.340]  как отвечать. Вообще логично, если там, тут, то так, здесь.
[52:44.340 --> 52:53.740]  Можно я дальше? Я подумаю и про кольцо, и про это. Нет,
[52:53.740 --> 52:55.620]  ответы есть, мне просто нужно задуматься над этим
[52:55.620 --> 53:00.460]  секундом. Так, что у нас там еще? Второе, оно вот, поэтому
[53:00.460 --> 53:05.020]  неинтересно. А третье, если одно вложено в другое. То
[53:05.020 --> 53:09.180]  есть мы берем А и А1, при этом А1 является под множеством
[53:09.180 --> 53:26.620]  А, они оба элемента кольца. Что тогда? Поднимите руки,
[53:26.620 --> 53:31.700]  кто как бы очевидно, что это равенство верно. Ну,
[53:32.340 --> 53:35.260]  смотрим. У нас симметрическая разность. Если у нас оказывается
[53:35.260 --> 53:38.060]  то, что одно множество является под множеством
[53:38.060 --> 53:44.900]  другого множества, то симметрическая разность это что?Now
[53:44.900 --> 53:48.280]  дополнение. Ну и все. Соответственно, вот это у вас
[53:48.280 --> 53:53.620]  А1. Вот это А, а симметрическая разность А и А1, это дополнение.
[53:53.620 --> 53:57.260]  То есть вот это у вас элемент r по условию. Это элемент
[53:57.260 --> 54:01.900]  по второму свойству, и ура, мы представили в виде
[54:01.900 --> 54:04.420]  дизинкутного объединения двух элементов R.
[54:04.420 --> 54:05.820]  Ура, всё сделали.
[54:05.820 --> 54:08.900]  То есть действительно кольцо является полукольцом.
[54:08.900 --> 54:09.900]  Окей.
[54:09.900 --> 54:12.300]  Второе, то что кольцо действительно замкнуто
[54:12.300 --> 54:14.660]  относительно всех наших теоретико-множечных операций,
[54:14.660 --> 54:16.500]  но у нас осталось объединение и разность.
[54:16.500 --> 54:25.500]  Ну что, а?
[54:25.500 --> 54:26.500]  Ну давайте начнём с чего?
[54:26.500 --> 54:27.500]  Давайте начнём с разности.
[54:27.500 --> 54:28.500]  Или с объединения?
[54:28.500 --> 54:29.500]  Разность проще?
[54:29.500 --> 54:30.500]  Разность проще?
[54:30.500 --> 54:31.500]  Я не помню.
[54:31.500 --> 54:32.500]  Ну давай разность проще.
[54:32.500 --> 54:37.500]  Так, то есть вот у нас есть A, у нас есть B.
[54:37.500 --> 54:40.500]  Сейчас, смотри, есть A, вот есть B.
[54:40.500 --> 54:44.500]  Так, разность это у нас кто?
[54:44.500 --> 54:45.500]  Это вот это, да?
[54:45.500 --> 54:46.500]  Так, и чё?
[54:46.500 --> 54:50.500]  Это A без A-пересечки с B.
[54:50.500 --> 54:51.500]  Без у нас нету.
[54:51.500 --> 54:54.500]  Так мы делаем без.
[54:54.500 --> 55:00.500]  То есть мы без будем отлипать через без?
[55:00.500 --> 55:07.500]  Ну то есть хочется взять симметрическую разность,
[55:07.500 --> 55:09.500]  но симметрическая разность будет включать в себе вот
[55:09.500 --> 55:12.500]  эту хрень, правильно?
[55:12.500 --> 55:13.500]  Поэтому что мы делаем?
[55:13.500 --> 55:21.500]  Мы сначала… А, симметрическая разность с пересечением.
[55:21.500 --> 55:26.500]  То есть смотрите, мы берём вот это вот пересечение.
[55:26.500 --> 55:29.500]  Пересечение становится под множеством A большого,
[55:29.500 --> 55:30.500]  да?
[55:30.500 --> 55:33.500]  А мы с вами только что договорились, что когда мы берём симметрическую
[55:33.500 --> 55:35.500]  разность множества его под множество, мы получаем
[55:35.500 --> 55:36.500]  его дополнение.
[55:36.500 --> 55:39.500]  Это как раз получается A без B.
[55:39.500 --> 55:40.500]  Хорошо?
[55:40.500 --> 55:45.500]  Не цель нашего курса доказывать законы Деморгана, но я думаю,
[55:45.500 --> 55:48.500]  а вы тренировались там через характеристические
[55:48.500 --> 55:49.500]  функции, делали это?
[55:49.500 --> 55:50.500]  Нет?
[55:50.500 --> 55:54.500]  Ну в общем, мы на картинках понимаем, что это правда,
[55:54.500 --> 55:57.500]  а если нужно доказать, то пишите свои характеристические
[55:57.500 --> 55:58.500]  функции.
[55:58.500 --> 56:00.500]  Все кивают насчёт характеристических функций?
[56:00.500 --> 56:01.500]  Хорошо.
[56:01.500 --> 56:02.500]  А где это было?
[56:02.500 --> 56:03.500]  В какой науке?
[56:03.500 --> 56:04.500]  Матрогене.
[56:04.500 --> 56:05.500]  Матрогене.
[56:05.500 --> 56:06.500]  Хорошо.
[56:06.500 --> 56:07.500]  Так, и что у нас ещё?
[56:07.500 --> 56:08.500]  Объединение.
[56:08.500 --> 56:09.500]  Что, Дин?
[56:09.500 --> 56:10.500]  A без B?
[56:10.500 --> 56:15.500]  Ещё раз, A без B?
[56:15.500 --> 56:18.500]  С это что?
[56:18.500 --> 56:25.500]  С это типа объединение, но теперь можно симметрическую
[56:25.500 --> 56:26.500]  разность.
[56:26.500 --> 56:27.500]  Можно формулу?
[56:27.500 --> 56:30.500]  A без B, симметрическая разность без B.
[56:30.500 --> 56:31.500]  Вот так?
[56:31.500 --> 56:32.500]  Да.
[56:32.500 --> 56:33.500]  Всё.
[56:33.500 --> 56:39.500]  Так, A без B, это соответственно у нас вот это множество,
[56:39.500 --> 56:40.500]  да?
[56:40.500 --> 56:41.500]  Ну вот.
[56:41.500 --> 56:44.500]  Если мы возьмём, то есть если вы берёте симметрическую
[56:44.500 --> 56:47.500]  разность двух непересекающихся множеств, вы получаете
[56:47.500 --> 56:48.500]  просто их объединение.
[56:48.500 --> 56:51.500]  Это понятно, да?
[56:51.500 --> 56:52.500]  Симметрическая.
[56:52.500 --> 56:53.500]  Ведь что такое симметрическая разность?
[56:53.500 --> 56:55.500]  Это объединение без пересечения.
[56:55.500 --> 56:56.500]  Да?
[56:56.500 --> 56:57.500]  Ну вот.
[56:57.500 --> 56:58.500]  Чего добился Тихон?
[56:58.500 --> 57:00.500]  Тихон добился того, чтобы эти две вещи не пересекались
[57:00.500 --> 57:03.500]  и взял симметрически разносну.
[57:03.500 --> 57:04.500]  Окей.
[57:04.500 --> 57:05.500]  Ну то есть всё, ура.
[57:05.500 --> 57:08.500]  То есть почему кольцо формулируется именно так?
[57:08.500 --> 57:12.500]  Ну то есть мы будем доказывать, что какая-то тема, что является
[57:12.500 --> 57:13.500]  кольцом.
[57:13.500 --> 57:15.500]  Нам хотелось бы иметь наименьший список требований для
[57:15.500 --> 57:17.500]  проверки того, что это кольцо.
[57:17.500 --> 57:20.500]  Поэтому сформулируем это так, но идейно это такая
[57:20.500 --> 57:22.500]  система множеств, что она замкнута относительно
[57:22.500 --> 57:23.500]  всех операций.
[57:23.500 --> 57:24.500]  Окей?
[57:24.500 --> 57:25.500]  Ну вот.
[57:25.500 --> 57:29.500]  На следующей лекции мы с вами аккуратно будем
[57:29.500 --> 57:32.500]  строить наименьшее кольцо, содержащее данное полукольцо.
[57:32.500 --> 57:36.500]  И его элементы, они достаточно легко выиграют.
[57:36.500 --> 57:37.500]  Хорошо.
[57:38.500 --> 57:41.500]  Ну поскольку я уже сказал про наименьшее.
[57:52.500 --> 57:54.500]  Вообще сейчас должно чувствоваться некоторое
[57:54.500 --> 57:57.500]  раздражение от того, что кольцо – идея понятная.
[57:57.500 --> 57:59.500]  То есть это система множеств, которая замкнута относительно
[57:59.500 --> 58:02.500]  всех наших операций, которые мы привыкли.
[58:02.500 --> 58:06.500]  Понятно то, что F должна удовлетворять вот этому
[58:06.500 --> 58:07.500]  требованию.
[58:10.500 --> 58:11.500]  Ну вот.
[58:11.500 --> 58:13.500]  Нафиг нам вот этот объект?
[58:13.500 --> 58:15.500]  Такой спойлер небольшой.
[58:15.500 --> 58:19.500]  Главным результатом достаточно долгого нашего исследования
[58:19.500 --> 58:21.500]  будет являться теоремка ретеодории.
[58:21.500 --> 58:24.500]  Я ее сейчас произнесу, но просто чтобы было понятно,
[58:24.500 --> 58:25.500]  что происходит.
[58:25.500 --> 58:26.500]  Потом мы до нее дойдем.
[58:26.500 --> 58:27.500]  Так, представь себе.
[58:27.500 --> 58:29.500]  Так, сейчас надо сконцентрироваться.
[58:29.500 --> 58:31.500]  Там мысль будет заключаться в чем?
[58:31.500 --> 58:36.500]  Что если у нас есть мера, которая задана вот на этой
[58:36.500 --> 58:37.500]  бедной системе множества.
[58:37.500 --> 58:40.500]  Она немножечко странная, то есть вообще непонятная,
[58:40.500 --> 58:43.500]  но просто именно она нам нужна.
[58:43.500 --> 58:47.500]  Если мера задана на этой системе множеств, то она
[58:47.500 --> 58:51.500]  однозначно продолжается на наименьшую сигму алгебру.
[58:51.500 --> 58:54.500]  Сигма алгебра – это будет система множеств, которая
[58:54.500 --> 58:59.500]  замкнута относительно всего и еще там счетного их
[58:59.500 --> 59:00.500]  количества.
[59:00.500 --> 59:05.500]  Ну так вот, если мера задана на полукольце, она однозначно
[59:05.500 --> 59:08.500]  задает меру на наименьшую сигму алгебру, которая содержит
[59:08.500 --> 59:09.500]  полукольцо.
[59:09.500 --> 59:13.500]  То есть достаточно задать меру здесь, и после этого
[59:13.500 --> 59:16.500]  она переносится на наименьшую сигму алгебру.
[59:16.500 --> 59:19.500]  А это самая бедная система множества, на ней легко
[59:19.500 --> 59:21.500]  задавать меру, и мы с вами будем это делать.
[59:21.500 --> 59:22.500]  Идея ясна?
[59:22.500 --> 59:24.500]  Именно поэтому мы занимаемся вот этой странной.
[59:24.500 --> 59:25.500]  Она решительная страна.
[59:25.500 --> 59:27.500]  Вот кольцо не странное, это просто система множества
[59:27.500 --> 59:29.500]  замкнутой системы всех операций, это понятно.
[59:29.500 --> 59:30.500]  А вот это странное.
[59:30.500 --> 59:33.500]  Такое использование, чтобы было понятно, почему мы вообще
[59:33.500 --> 59:36.500]  с ней работаем.
[59:36.500 --> 59:39.500]  Сейчас основная проблема, которую нам нужно с вами
[59:39.500 --> 59:42.500]  обсудить, вот эта приставка наименьшей сигмы алгебры,
[59:42.500 --> 59:44.500]  которая содержит данное что-то.
[59:44.500 --> 59:48.500]  Во-первых, почему такое существует, что это и из чего оно
[59:48.500 --> 59:49.500]  состоит.
[59:49.500 --> 59:51.500]  Начнем в этом постепенно разбираться.
[59:51.500 --> 59:55.500]  Первое утверждение, которое нам нужно.
[59:55.500 --> 59:57.500]  Пересечение любого числа колец.
[59:59.500 --> 01:00:01.500]  Есть кольцо.
[01:00:04.500 --> 01:00:06.500]  Оно может быть совсем бедным.
[01:00:06.500 --> 01:00:08.500]  Кстати, какое самое маленькое кольцо?
[01:00:08.500 --> 01:00:15.500]  Множество состоящее из одного элемента пустого множества.
[01:00:15.500 --> 01:00:17.500]  Понятно, что это самое маленькое кольцо.
[01:00:17.500 --> 01:00:19.500]  То есть вот это должно быть выполнено.
[01:00:19.500 --> 01:00:22.500]  Один элемент в нём должен быть и дальше должны быть
[01:00:22.500 --> 01:00:24.500]  выполнены такие требования.
[01:00:24.500 --> 01:00:28.500]  Понятно, что самое маленькое кольцо состоит из пустого множества.
[01:00:28.500 --> 01:00:37.860]  Идея в чём? У вас есть система каких-то колец. При этом
[01:00:37.860 --> 01:00:47.900]  у вас число их любое, то есть не обязательно счётное.
[01:00:47.900 --> 01:00:53.120]  Количество, ты так хочешь. Соответственно в качестве
[01:00:53.120 --> 01:00:57.000]  r получается, что мы берём пересечение r альфа, где альфа
[01:00:57.000 --> 01:01:02.160]  принадлежит лямбде большой. Почему в частности, в чём
[01:01:02.160 --> 01:01:10.680]  ценность этого курса? Когда вы уже на стадии математической
[01:01:10.680 --> 01:01:13.200]  статистики будете вспоминать этот курс, вам будет тяжело
[01:01:13.200 --> 01:01:20.000]  вспомнить, какие результаты там были. Чем он нужен? Кто
[01:01:21.000 --> 01:01:28.440]  математический объект? Это система множеств. Вы пересекаете
[01:01:28.440 --> 01:01:34.040]  системы множеств, то есть вы ищете одинаковые множества
[01:01:34.040 --> 01:01:36.800]  в этих системах и из них будет состоять вот эта
[01:01:36.800 --> 01:01:41.120]  новая система множеств. Обычно у народа это плохо воспринимается.
[01:01:41.120 --> 01:01:43.160]  То есть у вас теперь новым объектом, новым множеством
[01:01:43.160 --> 01:01:46.280]  является множество, состоящее из множеств. Тяжело это
[01:01:46.280 --> 01:01:50.200]  идёт, потому что раньше вы с этим не особо работали.
[01:01:50.200 --> 01:01:52.280]  За эти полгода вы как бы свыкнетесь поработать
[01:01:52.280 --> 01:02:00.680]  с разными системами множеств и это перестанет вас травмировать.
[01:02:00.680 --> 01:02:02.880]  Теперь погнали. Почему r? Для того, чтобы проверить,
[01:02:02.880 --> 01:02:06.400]  что какая-то система множеств является… Понятно, что если
[01:02:06.400 --> 01:02:09.200]  мы пересекаем систему множества, мы получаем систему множества.
[01:02:09.200 --> 01:02:11.200]  Чтобы проверить, что это кольцо, нам нужно проверить
[01:02:11.360 --> 01:02:16.360]  те три фактора. Первое, что r не пусто. Почему r не пусто?
[01:02:16.360 --> 01:02:22.480]  Для любого альфа у вас пустое множество является элементом r альфа,
[01:02:22.480 --> 01:02:26.480]  но поскольку это выполнено для любого альфа, то отсюда мы получаем,
[01:02:26.480 --> 01:02:30.560]  что пустое будет элементом r. Ура, значит оно не пусто,
[01:02:30.560 --> 01:02:34.120]  потому что пустое множество является его элементом. Красиво.
[01:02:34.120 --> 01:02:43.120]  Поэтому вот так. Второе, то, что замкнута от всех операций.
[01:02:43.120 --> 01:02:47.120]  Двух. Нам нужно двух. Давайте возьмем два элемента r.
[01:02:47.120 --> 01:02:51.120]  Поскольку они являются элементами r, отсюда следует, что для любого альфа
[01:02:51.120 --> 01:02:55.120]  a и b будут элементом r альфа, потому что r определялся как пересечение.
[01:02:55.120 --> 01:03:00.120]  Поскольку a и b элементы r альфа, а r альфа само по себе кольцо,
[01:03:00.120 --> 01:03:05.120]  отсюда мы получаем, что и пересечение a и b, и симметрическая разность a и b
[01:03:05.120 --> 01:03:09.120]  будет элементом r альфа, потому что r альфа – это кольцо.
[01:03:09.120 --> 01:03:14.120]  А теперь смотрим. Вот это множество под любым альфа является элементом r альфа,
[01:03:14.120 --> 01:03:19.120]  значит оно возьмет в r как пересечение. То же самое здесь. Все.
[01:03:19.120 --> 01:03:31.120]  Ну, неинтеллектуально. Окей? И важные следствия из этого результата.
[01:03:31.120 --> 01:03:42.120]  Ой, слушайте, я еще одно не ввел в систему.
[01:03:42.120 --> 01:03:46.120]  Это был алгебр.
[01:03:54.120 --> 01:03:56.120]  Определение.
[01:03:56.120 --> 01:04:06.120]  Так, система множеств.
[01:04:06.120 --> 01:04:15.120]  Это я попытался нарисовать a красивое. Вот эта буква a, такая ветереватая.
[01:04:15.120 --> 01:04:25.120]  Называется алгеброй.
[01:04:25.120 --> 01:04:35.120]  Если, во-первых, a – это кольцо, и, второе, если существует элемент этого кольца,
[01:04:35.120 --> 01:04:44.120]  такое, что любой другой элемент этого кольца является под множеством этого множества.
[01:04:44.120 --> 01:04:59.120]  Получается, что a – это система под множество нашего e, и само e входит в эту систему.
[01:04:59.120 --> 01:05:03.120]  Все понятно, да? Окей.
[01:05:03.120 --> 01:05:08.120]  Соответственно, вот это множество называется единицей.
[01:05:08.120 --> 01:05:18.120]  То есть, по сути, что такое алгебра? Это кольцо с единицей. В принципе, так везде и пишут.
[01:05:18.120 --> 01:05:24.120]  Вот, пожалуйста, у вас здесь полукольцо. Да, иногда есть такое понятие, как полукольцо с единицей.
[01:05:24.120 --> 01:05:27.120]  Вот, пожалуйста, вам пример полукольца с единицей.
[01:05:27.120 --> 01:05:33.120]  То есть, у вас эта штука является в силу определения элементом этой системы множества,
[01:05:33.120 --> 01:05:39.120]  и каждый его элемент является под множеством этого элемента. Это понятно? Окей.
[01:05:39.120 --> 01:05:50.120]  При этом здесь я мог взять какое полукольцо другое. То есть, было, например, не так, а просто вот так.
[01:05:50.120 --> 01:05:55.120]  Хорошо? То есть, я беру все полуинтервалы прямой. Окей?
[01:05:55.120 --> 01:06:00.120]  Все тогда здесь тоже будет выполнено, при этом единички у нас при этом нет.
[01:06:00.120 --> 01:06:06.120]  То есть, нет такого множества, что он является элементом этой системы, и любое другое является его под множеством.
[01:06:06.120 --> 01:06:08.120]  Так.
[01:06:11.120 --> 01:06:16.120]  Но, смотри, вот если я здесь объединю их всех, я не получу элемент данного множества.
[01:06:16.120 --> 01:06:23.120]  То есть, если объединение всех является элементом нашей системы, то тогда да.
[01:06:23.120 --> 01:06:26.120]  Просто объединение всех не обязательно конечным.
[01:06:26.120 --> 01:06:29.120]  Ну, конечным. В каком смысле?
[01:06:29.120 --> 01:06:32.120]  В элементах всех может быть.
[01:06:32.120 --> 01:06:35.120]  У нас с вами будет... Ну, вы, наверное, уже в мотоне с этим столкнулись.
[01:06:35.120 --> 01:06:40.120]  То есть, соответственно, вы долго и упорно на КТЧ занимались вопросами мощностей множества.
[01:06:40.120 --> 01:06:47.120]  Доказывали, что у вас множество равномощные, питью способами. Такое множество, такое множество. Я видел листки.
[01:06:47.120 --> 01:06:51.120]  Я сам плохо это умею делать, если честно. Но я этим занимался только на первом курсе.
[01:06:51.120 --> 01:06:56.120]  Ну вот. А дальше у вас появился вопрос мощностей множества, а появилось меры множества Лебеговской.
[01:06:56.120 --> 01:07:00.120]  Ну, на Мотонеево-Лебеговской занимались. И Жардановской, да? Да?
[01:07:00.120 --> 01:07:06.120]  Вообще разные вещи с вами между собой связаны. Это же понятно, да?
[01:07:06.120 --> 01:07:08.120]  Хорошо.
[01:07:15.120 --> 01:07:19.120]  Так. Следствие вот здесь. Вот из этого результата.
[01:07:19.120 --> 01:07:27.120]  Пересечение любого числа алгебры с общей единицей.
[01:07:33.120 --> 01:07:35.120]  Это и есть алгебра.
[01:07:37.120 --> 01:07:41.120]  Пересечение любого числа алгебры с общей единицей. Это тоже будет алгебра.
[01:07:41.120 --> 01:07:44.120]  Ну, тут добавляется только еще один пункт.
[01:07:44.120 --> 01:07:49.120]  То, что вот это е, которое общее у всех Р альфа, оно будет принадлежать этому Р.
[01:07:49.120 --> 01:07:51.120]  Ну и все.
[01:07:52.120 --> 01:07:54.120]  Это понятно.
[01:08:11.120 --> 01:08:13.120]  Теперь определение.
[01:08:14.120 --> 01:08:16.120]  Наименьшим.
[01:08:18.120 --> 01:08:20.120]  Наименьшим.
[01:08:23.120 --> 01:08:25.120]  Извините. Неправильно. Минимальным.
[01:08:28.120 --> 01:08:30.120]  Минимальным.
[01:08:37.120 --> 01:08:39.120]  Ну, вот.
[01:08:39.120 --> 01:08:41.120]  Минимальным кольцом.
[01:08:46.120 --> 01:08:48.120]  Минимальным кольцом.
[01:08:49.120 --> 01:08:52.120]  Содержащим данную систему множества.
[01:08:55.120 --> 01:08:58.120]  Содержащим данную систему множества.
[01:09:04.120 --> 01:09:07.120]  Ну, как-то мы ее будем обозначать. Х.
[01:09:08.120 --> 01:09:12.120]  Минимальным концом, содержащим данную систему множества Х.
[01:09:15.120 --> 01:09:18.120]  Называется кольцо. Мы его всегда будем обозначать Р в скобочках.
[01:09:18.120 --> 01:09:21.120]  То есть, как бы, Р это у нас в этой науке всегда будет кольцо.
[01:09:21.120 --> 01:09:24.120]  А в скобочках указывается система множеств,
[01:09:24.120 --> 01:09:27.120]  которая порождает это кольцо.
[01:09:27.120 --> 01:09:29.120]  Ну вот. Что выполнено?
[01:09:29.120 --> 01:09:32.120]  Ну, два слова. Два требования, очевидно.
[01:09:32.120 --> 01:09:36.120]  Во-первых, Х является элементом Р от Х.
[01:09:38.120 --> 01:09:40.120]  Что?
[01:09:40.120 --> 01:09:42.120]  Что? Нет.
[01:09:42.120 --> 01:09:44.120]  Хорошо, ладно.
[01:09:44.120 --> 01:09:47.120]  Тебя выгнать надо, ты мешаешь.
[01:09:50.120 --> 01:09:52.120]  Понятно, что так.
[01:09:52.120 --> 01:09:54.120]  Еще раз, и Х это система множеств,
[01:09:54.120 --> 01:09:58.120]  и Р от Х это тоже система множеств.
[01:09:58.120 --> 01:10:00.120]  Имеется в виду то, что...
[01:10:00.120 --> 01:10:02.120]  Смотрите, Х это у вас какая-то система множеств,
[01:10:02.120 --> 01:10:05.120]  которая не замкнута относительно каких-то операций.
[01:10:05.120 --> 01:10:07.120]  Понятно, что когда вы получаете систему множеств,
[01:10:07.120 --> 01:10:09.120]  которая будет замкнута,
[01:10:09.120 --> 01:10:11.120]  то есть, вы обогащаете Х новыми множествами,
[01:10:11.120 --> 01:10:14.120]  объединениями, пересечениями элементов Х,
[01:10:14.120 --> 01:10:16.120]  чтобы система множества стала замкнута.
[01:10:16.120 --> 01:10:18.120]  Это понятно, Кеварин?
[01:10:18.120 --> 01:10:20.120]  Понятно, что она становится богаче.
[01:10:20.120 --> 01:10:22.120]  То есть, там множеств будет больше.
[01:10:22.120 --> 01:10:26.120]  То есть, первое, что Х входит в наше кольцо,
[01:10:26.120 --> 01:10:28.120]  а второе какое? Требование.
[01:10:28.120 --> 01:10:30.120]  Ну, то, что минимальность.
[01:10:30.120 --> 01:10:32.120]  В чем будет заключаться минимальность?
[01:10:33.120 --> 01:10:37.120]  Любого кольца R1.
[01:10:37.120 --> 01:10:45.120]  Любого кольца R1, такого, что Х содержится в R1,
[01:10:45.120 --> 01:10:47.120]  будет верно что?
[01:10:53.120 --> 01:10:55.120]  Ну, наоборот.
[01:10:55.120 --> 01:10:57.120]  Оно же минимальное.
[01:10:57.120 --> 01:10:59.120]  Вот так вот.
[01:11:02.120 --> 01:11:04.120]  Минимальное.
[01:11:12.120 --> 01:11:16.120]  В чем фишка, почему минималь не наименьшая
[01:11:16.120 --> 01:11:19.120]  в этом плане, чем терминология?
[01:11:21.120 --> 01:11:23.120]  Потому что, смотрите,
[01:11:23.120 --> 01:11:25.120]  на множестве колец нет операции сравнения.
[01:11:27.120 --> 01:11:29.120]  Это понятно, да?
[01:11:32.120 --> 01:11:35.120]  Но это для любой пады выполнено?
[01:11:35.120 --> 01:11:37.120]  То есть, отношение сравнения для любой...
[01:11:39.120 --> 01:11:41.120]  Ну, так он же частичный.
[01:11:41.120 --> 01:11:44.120]  Но частичные варианты бывают наименьшие в множестве.
[01:11:44.120 --> 01:11:47.120]  Это те, которые сравнены с кем угодно,
[01:11:47.120 --> 01:11:49.120]  и меньше их.
[01:12:01.120 --> 01:12:03.120]  Ты загнал меня в угол сегодня.
[01:12:05.120 --> 01:12:07.120]  По идее, правда, да.
[01:12:08.120 --> 01:12:10.120]  Ну вот, да.
[01:12:10.120 --> 01:12:12.120]  Если мы сейчас докажем, что оно единственное.
[01:12:12.120 --> 01:12:14.120]  Да, если оно единственное, то оно наименьшее.
[01:12:18.120 --> 01:12:20.120]  Так, ну, соответственно, теорем.
[01:12:25.120 --> 01:12:29.120]  Ну, то есть, наименьшее кольцо, которое содержит,
[01:12:29.120 --> 01:12:31.120]  надо поднять.
[01:12:31.120 --> 01:12:33.120]  Слушай, напиши мне список,
[01:12:33.120 --> 01:12:35.120]  на чем я сегодня тупил, пожалуйста.
[01:12:35.120 --> 01:12:37.120]  Аккуратно проверю.
[01:12:37.120 --> 01:12:39.120]  Так, теоремы.
[01:12:39.120 --> 01:12:41.120]  Наименьшее кольцо существует.
[01:12:43.120 --> 01:12:45.120]  Минимальное. Все-таки минимальное.
[01:12:45.120 --> 01:12:47.120]  Нет, там уже какой-то был смысл.
[01:12:47.120 --> 01:12:49.120]  Я забыл.
[01:12:49.120 --> 01:12:51.120]  Да все, так, спокойно.
[01:12:51.120 --> 01:12:53.120]  Напиши мне, я выясню.
[01:12:53.120 --> 01:12:55.120]  Я в следующий раз расскажу.
[01:12:55.120 --> 01:12:57.120]  Хорошо.
[01:12:57.120 --> 01:12:59.120]  Почему существует?
[01:12:59.120 --> 01:13:01.120]  Почему аэротех существует?
[01:13:01.120 --> 01:13:03.120]  Ну, то есть, нам нужно его просто предъявить,
[01:13:03.120 --> 01:13:05.120]  и потом доказать, что он творяет этим требованием.
[01:13:15.120 --> 01:13:17.120]  Ну, для того, чтобы что-то пересекать,
[01:13:17.120 --> 01:13:19.120]  надо быть уверен, что хотя бы одно есть.
[01:13:19.120 --> 01:13:21.120]  Почему существует хотя бы одно кольцо,
[01:13:21.120 --> 01:13:23.120]  которое содержит аэротех?
[01:13:27.120 --> 01:13:29.120]  Его надо как-то предъявить.
[01:13:29.120 --> 01:13:31.120]  Давайте подумаем, как можно предъявить
[01:13:31.120 --> 01:13:33.120]  кольцо, которое содержит аэротех?
[01:13:37.120 --> 01:13:39.120]  Еще раз.
[01:13:39.120 --> 01:13:41.120]  Подожди, стоп,
[01:13:41.120 --> 01:13:43.120]  давай вслушаемся.
[01:13:43.120 --> 01:13:45.120]  Множество всех подмножеств, кого?
[01:13:53.120 --> 01:13:55.120]  Множество всех подмножеств
[01:13:55.120 --> 01:13:57.120]  элементов х.
[01:13:57.120 --> 01:13:59.120]  Пускай у нас х
[01:13:59.120 --> 01:14:01.120]  состоит из...
[01:14:05.120 --> 01:14:07.120]  Вы какой курс вообще?
[01:14:07.120 --> 01:14:09.120]  Какие у вас группы?
[01:14:09.120 --> 01:14:11.120]  100, да?
[01:14:11.120 --> 01:14:13.120]  Вы сотки, да?
[01:14:13.120 --> 01:14:15.120]  Ну, то есть, как бы х, это что у нас?
[01:14:15.120 --> 01:14:17.120]  111 группы.
[01:14:17.120 --> 01:14:19.120]  У вас PMF еще есть?
[01:14:19.120 --> 01:14:21.120]  Ой, динозавры, вы не знаете.
[01:14:23.120 --> 01:14:25.120]  112, 121,
[01:14:25.120 --> 01:14:27.120]  ну и так далее. То есть, что такое х?
[01:14:27.120 --> 01:14:29.120]  Х – это система множеств.
[01:14:29.120 --> 01:14:31.120]  Каждое множество – это множество студентов,
[01:14:31.120 --> 01:14:33.120]  что предлагает делать докладчик.
[01:14:33.120 --> 01:14:35.120]  Он говорит, мы рассмотрим все подмножества
[01:14:35.120 --> 01:14:37.120]  наших элементов.
[01:14:39.120 --> 01:14:41.120]  Нет, ты рассмотри все подмножества
[01:14:41.120 --> 01:14:43.120]  каждой своей группы.
[01:14:53.120 --> 01:14:55.120]  То есть, в первом шаге мы что делаем?
[01:14:55.120 --> 01:14:57.120]  Мы введем какое-то множество.
[01:14:57.120 --> 01:14:59.120]  Его давайте обозначим М.
[01:14:59.120 --> 01:15:01.120]  М – это кто?
[01:15:03.120 --> 01:15:05.120]  Нет.
[01:15:05.120 --> 01:15:07.120]  Начинаем мы с чего?
[01:15:07.120 --> 01:15:09.120]  Мы объединяем все элементы х.
[01:15:09.120 --> 01:15:11.120]  То есть, пускай у нас...
[01:15:11.120 --> 01:15:13.120]  Извините. Пускай у нас х – это
[01:15:13.120 --> 01:15:15.120]  какие-то альфы, да?
[01:15:15.120 --> 01:15:17.120]  Альфа – какой-то индекс.
[01:15:17.120 --> 01:15:19.120]  Мы не знаем, какой он.
[01:15:19.120 --> 01:15:21.120]  Я имею ввиду, не обязательно счетный.
[01:15:21.120 --> 01:15:23.120]  И мы рассматриваем множество М,
[01:15:23.120 --> 01:15:25.120]  которое есть объединение А альф
[01:15:25.120 --> 01:15:27.120]  по всем альфам.
[01:15:29.120 --> 01:15:31.120]  Так?
[01:15:31.120 --> 01:15:33.120]  Да.
[01:15:33.120 --> 01:15:35.120]  И потом мы рассмотрим, что?
[01:15:37.120 --> 01:15:39.120]  Надо бы как-нибудь тоже назвать.
[01:15:39.120 --> 01:15:41.120]  М есть, х есть.
[01:15:41.120 --> 01:15:43.120]  Какие-то у меня буквы были, наверное, записаны.
[01:15:49.120 --> 01:15:51.120]  Давайте вот тут Б сделаем.
[01:15:51.120 --> 01:15:53.120]  Я там просто...
[01:15:53.120 --> 01:15:55.120]  И М – это кто?
[01:15:55.120 --> 01:15:57.120]  Два в Б.
[01:15:57.120 --> 01:15:59.120]  Это два в Б.
[01:15:59.120 --> 01:16:01.120]  То есть, это множество всех под множество,
[01:16:01.120 --> 01:16:03.120]  Б большое.
[01:16:03.120 --> 01:16:05.120]  Что мы можем точно утверждать про М?
[01:16:05.120 --> 01:16:07.120]  Это кто?
[01:16:07.120 --> 01:16:09.120]  Даже алгебра.
[01:16:09.120 --> 01:16:11.120]  Единичка, очевидно, есть. Это само Б.
[01:16:11.120 --> 01:16:13.120]  То есть, это у нас алгебра.
[01:16:13.120 --> 01:16:15.120]  Алгебра.
[01:16:19.120 --> 01:16:21.120]  Поэтому, когда мы
[01:16:21.120 --> 01:16:23.120]  рассмотрим Р альфа,
[01:16:23.120 --> 01:16:25.120]  альф уже нехорошо,
[01:16:25.120 --> 01:16:27.120]  давайте Р бета,
[01:16:27.120 --> 01:16:29.120]  это множество колец,
[01:16:29.120 --> 01:16:31.120]  содержащих Х,
[01:16:35.120 --> 01:16:37.120]  множество колец, содержащих Х,
[01:16:39.120 --> 01:16:41.120]  М – это будет какое-то
[01:16:41.120 --> 01:16:43.120]  Р бета нулевое.
[01:16:43.120 --> 01:16:45.120]  Потому что это кольцо,
[01:16:45.120 --> 01:16:47.120]  содержащее систему Х.
[01:16:47.120 --> 01:16:49.120]  Видно, да?
[01:16:53.120 --> 01:16:55.120]  Еще раз.
[01:16:55.120 --> 01:16:57.120]  Х – это изначально наша система множества.
[01:17:01.120 --> 01:17:03.120]  Р бета нулевое.
[01:17:03.120 --> 01:17:05.120]  То есть, получается,
[01:17:05.120 --> 01:17:07.120]  что наша алгебра – это
[01:17:07.120 --> 01:17:09.120]  какое-то конкретное колечко,
[01:17:09.120 --> 01:17:11.120]  при конкретном значении индекса,
[01:17:11.120 --> 01:17:13.120]  вылежащего этой системе.
[01:17:17.120 --> 01:17:19.120]  И дальше мы берем пересечение
[01:17:19.120 --> 01:17:21.120]  всех наших вот этих вот колец.
[01:17:29.120 --> 01:17:31.120]  Что мы знаем про Р?
[01:17:31.120 --> 01:17:33.120]  Во-первых, про Р мы знаем то, что это кольцо.
[01:17:33.120 --> 01:17:35.120]  Это мы доказали вот в том утверждении,
[01:17:35.120 --> 01:17:37.120]  в первом, который есть.
[01:17:39.120 --> 01:17:41.120]  Вот это множество колец.
[01:17:41.120 --> 01:17:43.120]  Бета принадлежит
[01:17:43.120 --> 01:17:45.120]  к какому-то множеству.
[01:18:09.120 --> 01:18:11.120]  Еще раз.
[01:18:29.120 --> 01:18:31.120]  Вот это вот множество
[01:18:31.120 --> 01:18:33.120]  всех колец,
[01:18:35.120 --> 01:18:37.120]  содержащих Х.
[01:18:39.120 --> 01:18:41.120]  И мы их все пересекаем.
[01:18:45.120 --> 01:18:47.120]  Мы точно знаем, что оно
[01:18:47.120 --> 01:18:49.120]  не пустое, потому что
[01:18:49.120 --> 01:18:51.120]  наша М является элементом
[01:18:55.120 --> 01:18:57.120]  вот этого Р бета.
[01:18:57.120 --> 01:18:59.120]  Окей?
[01:19:01.120 --> 01:19:03.120]  Да? Да? Да?
[01:19:03.120 --> 01:19:05.120]  Окей. Все.
[01:19:05.120 --> 01:19:07.120]  Что мы знаем про Р? Во-первых, мы знаем, что
[01:19:07.120 --> 01:19:09.120]  Р это точно кольцо.
[01:19:09.120 --> 01:19:11.120]  Это мы доказали в утверждении.
[01:19:11.120 --> 01:19:13.120]  Второе, мы точно знаем, что Х
[01:19:13.120 --> 01:19:15.120]  является под множеством Р.
[01:19:15.120 --> 01:19:17.120]  Потому что Х является
[01:19:17.120 --> 01:19:19.120]  под множеством каждого Р бета,
[01:19:19.120 --> 01:19:21.120]  значит оно является под множеством их пересечений.
[01:19:25.120 --> 01:19:27.120]  И третье, что мы знаем,
[01:19:27.120 --> 01:19:29.120]  что
[01:19:29.120 --> 01:19:31.120]  для любого Р1,
[01:19:31.120 --> 01:19:33.120]  такого, что Х является
[01:19:33.120 --> 01:19:35.120]  под множеством Р1 и Р1 кольцо,
[01:19:37.120 --> 01:19:39.120]  существует
[01:19:39.120 --> 01:19:41.120]  бета 1,
[01:19:41.120 --> 01:19:43.120]  такое, что
[01:19:43.120 --> 01:19:45.120]  Р равняется R бета 1.
[01:19:45.120 --> 01:19:47.120]  Но поскольку это есть
[01:19:47.120 --> 01:19:49.120]  все кольца, которые
[01:19:49.120 --> 01:19:51.120]  содержат Х,
[01:19:51.120 --> 01:19:53.120]  то если мы возьмем какое-то,
[01:19:53.120 --> 01:19:55.120]  оно будет из этого семейства.
[01:19:55.120 --> 01:19:57.120]  Это ясно?
[01:19:57.120 --> 01:19:59.120]  А поскольку Р это есть
[01:19:59.120 --> 01:20:01.120]  пересечение их всех,
[01:20:01.120 --> 01:20:03.120]  отсюда следует то, что
[01:20:03.120 --> 01:20:05.120]  Р будет под множеством
[01:20:05.120 --> 01:20:07.120]  Р1.
[01:20:13.120 --> 01:20:15.120]  То есть выполнено и вот это,
[01:20:15.120 --> 01:20:17.120]  и вот это.
[01:20:19.120 --> 01:20:21.120]  Идея ясна?
[01:20:21.120 --> 01:20:23.120]  Проблема в этой теории заключается в чем?
[01:20:23.120 --> 01:20:25.120]  Непонятно, как выглядят элементы.
[01:20:25.120 --> 01:20:27.120]  То есть всегда,
[01:20:27.120 --> 01:20:29.120]  когда мы с вами будем определять
[01:20:29.120 --> 01:20:31.120]  минимальную сигму алгебру, минимальное кольцо,
[01:20:31.120 --> 01:20:33.120]  мы именно так и будем сдавать.
[01:20:33.120 --> 01:20:35.120]  То есть это пересечение всех,
[01:20:35.120 --> 01:20:37.120]  которое содержит
[01:20:37.120 --> 01:20:39.120]  нашу систему множества.
[01:20:39.120 --> 01:20:41.120]  Главная проблема, мы не понимаем, как выглядит ее элемент.
[01:20:41.120 --> 01:20:43.120]  Причем с кольцом
[01:20:43.120 --> 01:20:45.120]  мы на следующей лекции разрешим.
[01:20:45.120 --> 01:20:47.120]  То есть там я смогу выписать,
[01:20:47.120 --> 01:20:49.120]  как выглядят элементы кольца,
[01:20:49.120 --> 01:20:51.120]  если в качестве Х берется полукольцо.
[01:20:51.120 --> 01:20:53.120]  Это будут там всевозможные конечные объединения
[01:20:53.120 --> 01:20:55.120]  не пересекающихся элементов полукольца.
[01:20:55.120 --> 01:20:57.120]  А вот для сигма алгебры это сделать не получается.
[01:20:57.120 --> 01:20:59.120]  То есть выписывать в явном виде,
[01:20:59.120 --> 01:21:01.120]  как выглядят элементы сигма алгебры,
[01:21:01.120 --> 01:21:03.120]  это нельзя.
[01:21:03.120 --> 01:21:05.120]  То есть мы доказываем, что она есть,
[01:21:05.120 --> 01:21:07.120]  но представить через элементы не получается.
