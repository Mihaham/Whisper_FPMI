[00:00.000 --> 00:12.000]  В общем, я только что проговорил, чем символенно отличается от автоматического, что в символенном получается
[00:12.000 --> 00:15.000]  вот пагеформула для градиента, в автоматическом мы получаем значение в точке.
[00:15.000 --> 00:18.000]  Это как раз к снижению предыдущих трех минут.
[00:18.000 --> 00:23.000]  Немножко начали говорить про то, что такое вычислительный граф.
[00:23.000 --> 00:30.000]  Сейчас, когда я перейду на доску, я пытаюсь его нарисовать и показать, как оно все прокидывается.
[00:30.000 --> 00:38.000]  Тут гибридический пример, что у нас как бы три функции, и у нас функция квадраты в кидовой норме разности
[00:38.000 --> 00:40.000]  представляется в виде вот такой вот суперпозиции.
[00:40.000 --> 00:44.000]  Ну и соответственно, вычисление градиента по х, по а или по b,
[00:44.000 --> 00:51.000]  оно просто приводится к тому, что надо часто производно прокинуть по правилу сложной функции.
[00:51.000 --> 00:59.000]  В общем, в силу того, как устроены суперпозиции,
[00:59.000 --> 01:03.000]  рассматриваются только направленные циклические графы, сокращенные даги.
[01:03.000 --> 01:09.000]  Поэтому, в общем, если увидите такую аббревиатуру, не пугайтесь, это всего лишь дирекетно циклик граф.
[01:09.000 --> 01:16.000]  В контексте именно вычислительных графов и автограда это очень часто используемое название.
[01:16.000 --> 01:21.000]  Ну, собственно, я не помню, по-моему, про это тоже что-то было уже в прошлый раз.
[01:21.000 --> 01:27.000]  Поэтому, если не было или что-то непонято, вы меня тормозите и ставьте минусы в чат или еще что-то там.
[01:27.000 --> 01:31.000]  Пишите, я буду восстанавливаться, подробнее объясню.
[01:31.000 --> 01:37.000]  То есть у нас есть такая вот функция в случае, когда мы смотрим на скалярных суппозициях.
[01:37.000 --> 01:45.000]  То здесь получается довольно все просто, и размерность градиента должна совпадать с размерностью х, чтобы все заработало.
[01:45.000 --> 01:48.000]  Ну и по определению это тоже явно следует.
[01:48.000 --> 01:54.000]  Ну и, соответственно, вот тут dg по du, соответственно, просто будет число, потому что уже скалярная функция.
[01:54.000 --> 02:01.000]  Если же у нас векторные случаи, то мы тут обязаны посчитать сумму по всем промежуточным аргументам.
[02:01.000 --> 02:12.000]  И можно заметить, что вот эта вот величина, которая здесь фигурирует, видите, dhj по dxk, это некоторая матрица, матрица якобы, видимо, отображение.
[02:12.000 --> 02:15.000]  Поэтому это можно делать таким вот образом.
[02:15.000 --> 02:28.000]  Ну и если вспомнить аккуратно, что если у нас есть df по dxk, то k должен быть внешним индексом относительно тех индексов, которые сворачиваются в знаки суммирования.
[02:28.000 --> 02:32.000]  Поэтому здесь появляется транспонирование, и мы транспонированные матрицей якобы умножаем...
[02:32.000 --> 02:42.000]  Ну так якобы написано, в общем, в матрице якобы, понятно. Умножается на градиент dg по dh, поскольку уже по-прежнему скалярная функция.
[02:42.000 --> 02:50.000]  То есть разница в том, какое отображение одномерное или двумерное стоит внутри.
[02:50.000 --> 02:54.000]  Так, есть ли вопросы какие-то по этому слайду?
[03:02.000 --> 03:10.000]  Так, ну вроде никто ничего не пишет. Наверное, это значит, что вопросов нет.
[03:10.000 --> 03:20.000]  Окей. Ну собственно, дальше это все просто раскручивается по, как сказать, по увеличению сложности, но идеи на все остается тем же самым.
[03:20.000 --> 03:29.000]  То есть у нас есть теперь, допустим, мы из k, откуда сейчас, из rn отображаемся в rk, а из rk в rm.
[03:29.000 --> 03:33.000]  Вот тогда у нас эта штука просто произведение соответствующих матриц якобы.
[03:33.000 --> 03:40.000]  Ну и соответственно, если это все будет суперпозиции из l большой функций, то у нас получается...
[03:40.000 --> 03:45.000]  Итог грамматается якобы, это просто произведение соответствующих матриц якобы у ингредиентов.
[03:45.000 --> 03:52.000]  Ну и когда вот эта штука вычисляется, она может быть тает, точно уже был в прошлый раз, вычисляется слева направо, справа налево.
[03:52.000 --> 03:56.000]  И у каждого из этих способов есть свои достоинства и недостатки.
[03:56.000 --> 04:03.000]  Наставшиеся, надеюсь, минут пять-десять, мы светим тому, чтобы понять, в чем у него достоинства, в чем у него недостаток или куда же надо использовать.
[04:03.000 --> 04:13.000]  Ну соответственно, Format Mode тоже начала рассказывать, что мы фиксируем аргумент, индекс элемента аргумента,
[04:13.000 --> 04:21.000]  и для всех выходных элементов выхода считаем соответствующую производную.
[04:21.000 --> 04:24.000]  То есть это типа жидкость столбей от смартфона.
[04:24.000 --> 04:32.000]  Ну и делать это довольно прямолинейно. Выбирается элемент, сдается орд и умножается это все дело рекурсивно на этот орд.
[04:32.000 --> 04:36.000]  То есть сначала умножается g1, потом g2 и так далее до g3.
[04:36.000 --> 04:42.000]  Все это, поскольку идет по возрастанию индекса, делается одновременно с вычислением самой функции.
[04:42.000 --> 04:53.000]  Ну и чтобы это все заработало, надо как бы переопределить все базовые функции, которые мы знаем таким образом, чтобы они поддерживали не только вычисление значений, но и умножение икобиана налево.
[04:54.000 --> 05:01.000]  То есть тут все довольно сочетарение реализации прямолинейно. В конце будут ссылочки на то, где можно посмотреть, что это на самом деле сделано.
[05:01.000 --> 05:13.000]  Backward Mode, то есть проход назад или Backpropagation, заключает в том, что мы наоборот сначала фиксируем некоторые индексы в результате.
[05:13.000 --> 05:22.000]  Ну и потом для всех параметров, для всех элементов параметров, которые у нас были, мы рассчитываем соответственно строк.
[05:22.000 --> 05:32.000]  Не путайте, сейчас будет немного путанный момент про то, что мы везде в наших теоретических выкладках будем считать, что у нас градиент это вектор-столбец.
[05:32.000 --> 05:45.000]  Но в сфере нам это нужно будет реализовывать. Нет, вам это не нужно будет реализовывать, вам нужно всего лишь понять, как это и почему это работает.
[05:45.000 --> 05:54.000]  То есть чуть позже будут ссылки на различные пакеты, где это сделано.
[05:54.000 --> 06:03.000]  И когда я про один из них буду говорить, я просто открою, может быть, код и прямо покажу, как это переопределение происходит.
[06:03.000 --> 06:14.000]  Но это просто к тому, что если вдруг вы захотите по каким-то причинам реализовать метод или функцию, которая будет поддерживаться вот таким вот автоматическим дифференцированием,
[06:14.000 --> 06:18.000]  чтобы вы понимали, что именно вам нужно предоставить помимо вычислений самой функции.
[06:18.000 --> 06:29.000]  То есть понятно, что довольно широкий класс преобразований может быть подвергнут такой процедуре, но не все они достаточно популярны, чтобы присутствовать в стандартных пакетах.
[06:29.000 --> 06:34.000]  Вот к чему я это все сейчас рассказываю.
[06:34.000 --> 06:37.000]  Ответил ли я на ваш вопрос?
[06:37.000 --> 06:47.000]  Ага, окей, спасибо.
[06:47.000 --> 06:59.000]  Ну вот, соответственно, когда мы идем назад, то мы умножаем не экипиан на вектор, а транспонированный экипиан на вектор, чтобы эмулировать умножение строки на экипиан слева.
[06:59.000 --> 07:09.000]  Ну и тут как бы соответственно возникают прокладные расходы некоторые, потому что часто у нас вот это умножение на экипиан связано с тем, чтобы сохранить промежуточный результат.
[07:09.000 --> 07:18.000]  Поэтому мы два раза будем граф, и на первом проходе что-то может быть сейчас будем сохранять. Это нам требует больше памяти.
[07:18.000 --> 07:28.000]  Ну в общем, если у нас единичный размер в конце получается скаля, то мы получим по сути дела градиент, который соответствует единственной строке нашей матрицы эка.
[07:28.000 --> 07:45.000]  То есть тут как бы понятно ли в чем разница подходов. Если вас просят, чем там backward mod отличается от forward mod, подумайте, можете ли вы осознали ли вы, в чем они отличаются, и можете ли вы ответить на такой вопрос, например.
[07:45.000 --> 07:49.000]  Скорее всего, зачем backward mod, если он кажется просто сложнее вычислительным.
[07:49.000 --> 07:54.000]  Нет, погодите. Вот насчет того, что он сложнее вычислительный, сейчас мы посмотрим.
[07:54.000 --> 07:59.000]  А не симпатически, а константно. Что приходится два прохода делать на каждую строку.
[07:59.000 --> 08:00.000]  Ну хорошо, да.
[08:00.000 --> 08:02.000]  2n проходов вместо n.
[08:02.000 --> 08:06.000]  Да, смотрите, давайте рассмотрим случай, как вот этот, например.
[08:06.000 --> 08:14.000]  Сколько надо сделать проходов forward mod, чтобы посчитать градиент в этом случае, вот в этом?
[08:14.000 --> 08:16.000]  А n получается?
[08:16.000 --> 08:17.000]  Именно так.
[08:17.000 --> 08:18.000]  А тут 1.
[08:18.000 --> 08:25.000]  Именно так. И мы сейчас будем, то есть, во-первых, я покажу там некоторые теоретические оценки буквально в следующем слайде.
[08:25.000 --> 08:37.000]  А потом переключимся на ноутбук и я покажу в коде, как реальный замер времени показывает, что насколько сильно будет отличаться время работы этих самых режимов в зависимости от размерности кода и выхода.
[08:37.000 --> 08:41.000]  Это как бы план на следующие 5 минут, я надеюсь.
[08:41.000 --> 08:46.000]  Собственно, вычислительная сложность. Это все взято из книжки.
[08:46.000 --> 08:52.000]  Ссылка была вот здесь. Довольно большая книжка. Если кому интересно, рекомендую ознакомиться.
[08:52.000 --> 08:57.000]  Там отчасти эволюция прослеживается и более широко это все обсуждается.
[08:57.000 --> 09:09.000]  На самом деле, очень большая область, которая в 50-е и 60-е годах тоже активно развивалась в связи с символной историей, но потом эволюционировала как будто бы.
[09:09.000 --> 09:14.000]  Поэтому, в общем, там много всего.
[09:14.000 --> 09:28.000]  Собственно, сложность. Забавный факт, что сложность вычисления функции и произведения Кабиана на вектор не так уж сильно отличается от сложности вычисления самой функции.
[09:28.000 --> 09:33.000]  То есть такие вот, на первый раз, кажущиеся странные результаты.
[09:33.000 --> 09:39.000]  Но это просто к тому, что есть дополнительное дооснащение этой функции умножения Кабиана на вектор.
[09:39.000 --> 09:46.000]  Это не то, что вы существенно на порядок усложняете в другом числении.
[09:46.000 --> 09:50.000]  Собственно, память. ForwardMode ничего не требует.
[09:51.000 --> 09:59.000]  BackwardMode требует промежуточных значений сохранения, чтобы потом в них можно было пересчитать значения промежуточных функций.
[09:59.000 --> 10:09.000]  Ну, собственно, вывод довольно прямолинейный, что если у вас из малого количества входа получается большая размерность.
[10:09.000 --> 10:17.000]  То есть, наоборот, если из большой размерности на ходе получается маленькая размерность на выходе, то вы можете использовать BackwardMode, в противном случае использовать ForwardMode.
[10:17.000 --> 10:25.000]  Тут написано больше либо равно, но мы сейчас увидим, что на самом деле вот это вот больше либо равно, возможно, стоит заменить именно нам сильно больше.
[10:25.000 --> 10:27.000]  Также вот тут важный комментарий.
[10:27.000 --> 10:36.000]  Может быть, его как-то в рамочку я выделю, чтобы вы его не пропустили, если будете пересматривать слайды.
[10:36.000 --> 10:47.000]  То тут важно, что вот эта вся реализация этих вещей непосредственно на входе, она очень может отличаться в разных пакетах.
[10:47.000 --> 10:59.000]  Потому что, в общем, промежуточные оптимизации здесь можно в разных местах вкручивать и в той или иной степени пытаться сократить какие-то либо учтения, либо память.
[10:59.000 --> 11:07.000]  В общем, тут довольно большой простор для фантазии и для каких-то тестов, экспериментов и всего такого.
[11:07.000 --> 11:15.000]  Понятны ли ясные выводы про сложность и память этих двух режимовых вычислений?
[11:15.000 --> 11:19.000]  Оставьте там плюс или минус, пожалуйста, в чате.
[11:20.000 --> 11:23.000]  Так, все, спасибо, здорово.
[11:23.000 --> 11:25.000]  Ну, собственно, где реализованная?
[11:25.000 --> 11:32.000]  Реализованная в джаксе, все ссылки кликабельные, можно будет посмотреть, торчерия сделана и в автограде.
[11:32.000 --> 11:40.000]  Вот автоград, наверное, надо будет его сейчас поподробнее показать, потому что он, по сути, взят нам пайс стандартный и немножко доопределен.
[11:40.000 --> 11:42.000]  То есть тут минимальное количество каких-то наворотов.
[11:42.000 --> 11:49.000]  Все это на чистом бетоне, джит компиляция поддерживается через обертки.
[11:49.000 --> 11:55.000]  Но сама по себе конструкция вполне себе несложно осознать, просто глядя на код.
[11:55.000 --> 12:01.000]  В дальнейшем примеры, которые я покажу через пару минут, будут именно на джаксе,
[12:01.000 --> 12:05.000]  по причинам которой я объясню, когда буду показывать ноутбук с кодом.
[12:05.000 --> 12:13.000]  Везде реализованы почти одинаковые функционалы.
[12:13.000 --> 12:19.000]  Почти одинаковые, где будет отличаться, я скажу, когда будем продолжать.
[12:19.000 --> 12:26.000]  Потому что, кажется, сейчас здесь реализована максимально широкий функционал с максимально удобным использованием, в отличие от торча, например.
[12:26.000 --> 12:38.000]  Это пока все по слайдам. Давайте сейчас переключимся на код и на те примеры, которые я хотел показать.
[12:38.000 --> 12:43.000]  Буквально пару секунд, мне надо все открыть.
[12:43.000 --> 12:49.000]  Важный небольшой комментарий сейчас будет.
[12:49.000 --> 12:54.000]  Наверное, это уже можно шатить.
[12:54.000 --> 13:02.000]  Вот репозиторий Автограда.
[13:02.000 --> 13:09.000]  Авторы пишут, что они пока все это дело поддерживают, но все полным составом переключились на разработку джакса,
[13:09.000 --> 13:15.000]  поэтому дальнейшее развитие этой штуки не предусматривается пока что.
[13:15.000 --> 13:24.000]  Как это работает? Надо импортировать переопределенный нампай и функцию, которую гриден вычисляет.
[13:24.000 --> 13:29.000]  Дальше вы пишете какую-то функцию, которая использует переопределенный нампай.
[13:29.000 --> 13:34.000]  Пишете град, и у вас получается функция, которую гриден в точке вычисляет.
[13:34.000 --> 13:39.000]  Там сведенички, все хорошо.
[13:39.000 --> 13:46.000]  Понятно, что можно тут для скалярной функции посчитать производные нужного вам порядка без особых проблем.
[13:46.000 --> 13:49.000]  Тут элемент у Айсград, только видите.
[13:49.000 --> 13:54.000]  Вот такие графики можно получить.
[13:54.000 --> 14:05.000]  Еще я хотел показать, что у этой же команды есть дидактика.
[14:05.000 --> 14:15.000]  Это штука, которая показывает сейчас гиперград или не у них.
[14:15.000 --> 14:20.000]  Ладно, исхода не находится, тогда давайте просто посмотрим на примеры.
[14:20.000 --> 14:29.000]  Автоград нампай, значит нам нужно пойти вот сюда и посмотреть, как нампай сделан.
[14:29.000 --> 14:34.000]  И вот видите тут то, что я в прошлый раз упоминал про VGP и GVP.
[14:34.000 --> 14:39.000]  То есть сектор JacobinProduct для backward и JacobinVectorProduct для forward.
[14:39.000 --> 14:42.000]  Тут если смотреть, то огромные файлы, наверное, будут.
[14:42.000 --> 14:44.000]  Но не очень огромные на самом деле.
[14:44.000 --> 14:58.000]  И здесь берутся нампайские функции и добавляется метод devVGP, который задает то, как нужно умножать градиент на входной вектор G.
[14:58.000 --> 15:06.000]  При этом ans – это результат вычисления при проходе вперед.
[15:06.000 --> 15:16.000]  То есть видите, по сути дела, все методы, которые там есть, экспоненты, логарифмы, все это.
[15:16.000 --> 15:20.000]  Народ пошел подключаться, интересно.
[15:20.000 --> 15:26.000]  Прям надо это все определять таким вот образом.
[15:26.000 --> 15:32.000]  И причем, если у вас функция несколько переменных принимает, по которым вы хотите посчитать градиент, то надо...
[15:32.000 --> 15:37.000]  Так, пишут, что интернет unstable, поэтому если вся связь плохая, пожалуйста, напишите в чат.
[15:42.000 --> 15:48.000]  Поэтому, в общем, видите, какая работа, но какую работа надо проделать, чтобы все это в конце концов заработало.
[15:48.000 --> 16:00.000]  Вот понимаешь, что тут всякие там браткасты делаются, то есть вся механика, которая поддерживается нампаем, она тут реализована с дополнительным оснащением градиента.
[16:00.000 --> 16:04.000]  И функция умножения, по сути, екабианная, наверное.
[16:04.000 --> 16:07.000]  Ну давайте какой-нибудь простой вопрос.
[16:07.000 --> 16:10.000]  Вот что из себя будет представлять...
[16:10.000 --> 16:15.000]  Например, у вас есть функция cos, которая действует на вектор поэлементно.
[16:15.000 --> 16:22.000]  И вам нужно определить функцию, которая будет вычислять произведение екабианной функции на вектор.
[16:22.000 --> 16:25.000]  Какая будет сложность этой функции? Как это все будет работать?
[16:25.000 --> 16:28.000]  Такой простой вопрос, пока вам тут грузится линалк.
[16:28.000 --> 16:31.000]  Хочу сказать, что ты линалк гиперкоприализован.
[16:31.000 --> 16:33.000]  Понятен ли вопрос?
[16:36.000 --> 16:39.000]  Так, прошу прощения. Проблема со связью, но все в порядке вроде как.
[16:39.000 --> 16:43.000]  Кто-нибудь придумал ответ на вопрос,
[16:43.000 --> 16:45.000]  воспользовавшись моим отсутствием?
[16:45.000 --> 16:47.000]  Можете еще раз вопрос задать?
[16:47.000 --> 16:49.000]  Да, давайте.
[16:49.000 --> 16:53.000]  У вас есть функция cos,
[16:53.000 --> 16:56.000]  которая действует на вектор поэлементно.
[16:56.000 --> 16:59.000]  Пришел вектор из рандомных чисел,
[16:59.000 --> 17:03.000]  и функция возвращается в вектор из cos этих чисел.
[17:03.000 --> 17:05.000]  Как будет выглядеть функция,
[17:05.000 --> 17:08.000]  которая умножает екабиан этой функции на вектор,
[17:08.000 --> 17:11.000]  и какая будет у нее сложность?
[17:11.000 --> 17:14.000]  А данная функция, для которой нужна екабиан?
[17:14.000 --> 17:17.000]  cos, да.
[17:17.000 --> 17:20.000]  И вроде мне даже подгрузился нам пай.
[17:20.000 --> 17:23.000]  В смысле под модуль линалк.
[17:23.000 --> 17:26.000]  Поэтому сейчас можно будет, когда вы что-нибудь придумаете,
[17:26.000 --> 17:29.000]  обсудим, что здесь происходит,
[17:29.000 --> 17:34.000]  и почему это имеет какой-то смысл.
[17:34.000 --> 17:37.000]  Да.
[17:37.000 --> 17:39.000]  Так, ну что?
[17:39.000 --> 17:41.000]  Какие варианты?
[17:41.000 --> 17:43.000]  Достаточно простой вопрос, кажется.
[17:43.000 --> 17:45.000]  То есть давайте...
[17:45.000 --> 17:47.000]  Не, на плане градиа cos это его производное?
[17:47.000 --> 17:49.000]  Именно так.
[17:49.000 --> 17:51.000]  Его производное это минус sin?
[17:51.000 --> 17:54.000]  Ну, вектор одноиметный из его производной.
[17:54.000 --> 17:57.000]  Ну вот что это за...
[17:57.000 --> 17:59.000]  То есть смотрите, функция, во-первых,
[17:59.000 --> 18:01.000]  как я уже сказал, раз она поэлементная,
[18:01.000 --> 18:03.000]  она улучшает вектор длины размерности n,
[18:03.000 --> 18:05.000]  вектор размерности n.
[18:05.000 --> 18:07.000]  А, поэлементный cos, понятно.
[18:07.000 --> 18:10.000]  Именно так.
[18:10.000 --> 18:12.000]  К чему будет...
[18:12.000 --> 18:16.000]  Минус поэлементный sin умножить на вектор.
[18:16.000 --> 18:18.000]  Хорошо.
[18:18.000 --> 18:20.000]  Это правда.
[18:20.000 --> 18:22.000]  А теперь давайте поясним, как это согласуется с тем,
[18:22.000 --> 18:24.000]  что у нас должна быть матрица якобы какая-то.
[18:24.000 --> 18:26.000]  Размерности n на r.
[18:26.000 --> 18:28.000]  Вот какая она будет?
[18:28.000 --> 18:30.000]  Диагонально, кажется.
[18:30.000 --> 18:32.000]  Диагонально, гениально.
[18:32.000 --> 18:34.000]  Да, именно так.
[18:34.000 --> 18:36.000]  Она будет диагональная.
[18:36.000 --> 18:38.000]  Вы эту диагональную матрицу умножайте на вектор.
[18:38.000 --> 18:40.000]  Умножение диагональной матрицы на вектор
[18:40.000 --> 18:42.000]  это умножение по элементу на диагонали на сам вектор.
[18:42.000 --> 18:44.000]  Поэтому это будет всего лишь за m,
[18:44.000 --> 18:46.000]  что достаточно дешево.
[18:46.000 --> 18:48.000]  Поэтому это касается, в общем-то,
[18:48.000 --> 18:50.000]  всех поэлементных функций, которые у вас там могут возникнуть.
[18:50.000 --> 18:52.000]  Вот.
[18:52.000 --> 18:54.000]  Поэтому как бы попробуй.
[18:54.000 --> 18:56.000]  Понятно ли почему так?
[18:56.000 --> 18:58.000]  Почему так?
[18:58.000 --> 19:00.000]  Я вижу, что есть запрос на расписание.
[19:00.000 --> 19:02.000]  Давайте потратим немножко времени.
[19:02.000 --> 19:04.000]  Это не так долго.
[19:04.000 --> 19:06.000]  Но хочется, чтобы не было каких-то
[19:06.000 --> 19:08.000]  сомнений о векторе.
[19:08.000 --> 19:10.000]  Вот смотрите.
[19:10.000 --> 19:12.000]  Вот у нас есть функция f от x.
[19:12.000 --> 19:14.000]  Все вроде отображается.
[19:14.000 --> 19:16.000]  Так только надо делать вертикально.
[19:16.000 --> 19:18.000]  То есть горизонтально, чтобы оно еще и полный экран занимало.
[19:18.000 --> 19:20.000]  Вот.
[19:20.000 --> 19:22.000]  Вот у нас есть функция f от x.
[19:22.000 --> 19:24.000]  Ну, понятно, cos-x.
[19:24.000 --> 19:26.000]  Которая делает следующее.
[19:26.000 --> 19:28.000]  x1, x2 и т.д.
[19:28.000 --> 19:30.000]  xn
[19:30.000 --> 19:32.000]  отображает это все
[19:32.000 --> 19:34.000]  в cos-x1,
[19:34.000 --> 19:36.000]  cos-xn.
[19:36.000 --> 19:38.000]  Вот такая функция.
[19:38.000 --> 19:40.000]  Соответственно, что такое матрица якоби?
[19:40.000 --> 19:42.000]  Это d, f,
[19:42.000 --> 19:44.000]  i, g
[19:44.000 --> 19:46.000]  d, x, g.
[19:46.000 --> 19:48.000]  И тут мы видим внезапно,
[19:48.000 --> 19:50.000]  что у нас каждый аргумент,
[19:50.000 --> 19:52.000]  каждый элемент выхода зависит
[19:52.000 --> 19:54.000]  только от соответствующего аргумента входа.
[19:54.000 --> 19:56.000]  То есть нет, условно говоря, зависимости
[19:56.000 --> 19:58.000]  первого элемента выхода
[19:58.000 --> 20:00.000]  от последнего элемента входа.
[20:00.000 --> 20:02.000]  Следовательно, у нас наша матрица будет
[20:02.000 --> 20:04.000]  диагональная.
[20:04.000 --> 20:06.000]  И здесь будет стоять, соответственно,
[20:06.000 --> 20:08.000]  минус sin x1
[20:08.000 --> 20:10.000]  и т.д.
[20:10.000 --> 20:12.000]  минус sin xn.
[20:12.000 --> 20:14.000]  Понятно ли, почему
[20:14.000 --> 20:16.000]  будет диагональная матрица?
[20:18.000 --> 20:20.000]  Уставьте плюс, если понятно,
[20:20.000 --> 20:22.000]  и минус, если нет.
[20:22.000 --> 20:24.000]  Окей, так вроде
[20:24.000 --> 20:26.000]  довольно активно
[20:26.000 --> 20:28.000]  ставите, ставят люди плюс.
[20:28.000 --> 20:30.000]  Вот, ну и соответственно,
[20:30.000 --> 20:32.000]  когда дальше нам нужно умножить тебя
[20:32.000 --> 20:34.000]  на какой-то вектор u,
[20:34.000 --> 20:36.000]  то это то же самое, что и взять и умножить
[20:36.000 --> 20:38.000]  минус sin x1 умножить на u1
[20:38.000 --> 20:40.000]  и т.д. минус sin
[20:40.000 --> 20:42.000]  xn умножить на un.
[20:42.000 --> 20:44.000]  Такой вектор получится.
[20:44.000 --> 20:46.000]  И это всё от m.
[20:46.000 --> 20:48.000]  И это как бы схема, она работает
[20:48.000 --> 20:50.000]  для любой поэлементной функции,
[20:50.000 --> 20:52.000]  чтобы у векторов что-то другое будет преобразовывать.
[20:52.000 --> 20:54.000]  Просто поэлементные функции
[20:54.000 --> 20:56.000]  это довольно популярная история
[20:56.000 --> 20:58.000]  и полезно понимать, как они работают.
[21:00.000 --> 21:02.000]  Так, есть ли какие-то вопросы
[21:02.000 --> 21:04.000]  про этот пример?
[21:04.000 --> 21:06.000]  Всё понятно, это прекрасно.
[21:06.000 --> 21:08.000]  Я думаю, если вопросы появятся,
[21:08.000 --> 21:10.000]  то, пожалуйста, пишите в чат, я вернусь к доске.
[21:10.000 --> 21:12.000]  А пока давайте посмотрим
[21:12.000 --> 21:14.000]  всё-таки на то, что происходит
[21:14.000 --> 21:16.000]  в пакете lenal.
[21:16.000 --> 21:18.000]  Ну, вот
[21:18.000 --> 21:20.000]  как-то
[21:20.000 --> 21:22.000]  под модуле
[21:22.000 --> 21:24.000]  lenal, потому что, возможно, вы здесь
[21:24.000 --> 21:26.000]  интересно найдёте.
[21:26.000 --> 21:28.000]  Например, есть функция dead,
[21:28.000 --> 21:30.000]  которая вычисляет определить.
[21:30.000 --> 21:32.000]  И есть соответствующий ей градиент,
[21:32.000 --> 21:34.000]  который
[21:34.000 --> 21:36.000]  умножает
[21:38.000 --> 21:40.000]  входную
[21:40.000 --> 21:42.000]  матрицу
[21:42.000 --> 21:44.000]  на то,
[21:44.000 --> 21:46.000]  что
[21:46.000 --> 21:48.000]  представляет из себя
[21:48.000 --> 21:50.000]  градиент
[21:50.000 --> 21:52.000]  у до терминанта.
[21:52.000 --> 21:54.000]  То есть можно понять, например,
[21:54.000 --> 21:56.000]  почему уровень градиента терминанта,
[21:56.000 --> 21:58.000]  глядя на вот эту штуку.
[21:58.000 --> 22:00.000]  Видите, как тут хитро сделано,
[22:00.000 --> 22:02.000]  лямбда, то есть лямбда
[22:02.000 --> 22:04.000]  это точка, это ответ,
[22:04.000 --> 22:06.000]  g это входной вектор,
[22:06.000 --> 22:08.000]  и вот они тут вот так вот сделаны.
[22:08.000 --> 22:10.000]  Есть типа логарь из до терминанта,
[22:10.000 --> 22:12.000]  с которым мы сегодня ещё встретимся,
[22:12.000 --> 22:14.000]  s означает sign.
[22:14.000 --> 22:16.000]  Он проверяет знак,
[22:16.000 --> 22:18.000]  и только потом вычисляет градиент.
[22:18.000 --> 22:20.000]  Inf это обратный матриц вычисления.
[22:22.000 --> 22:24.000]  Что ещё интересного можно показать?
[22:24.000 --> 22:26.000]  Можно градиент
[22:26.000 --> 22:28.000]  описан у решения
[22:28.000 --> 22:30.000]  линейной системы по, я так понимаю,
[22:30.000 --> 22:32.000]  по
[22:32.000 --> 22:34.000]  пиксу, видимо.
[22:34.000 --> 22:36.000]  Sol
[22:36.000 --> 22:38.000]  или по матрице даже.
[22:40.000 --> 22:42.000]  Да, значит, ещё раз
[22:42.000 --> 22:44.000]  давайте вернёмся.
[22:44.000 --> 22:46.000]  Идея была показать,
[22:46.000 --> 22:48.000]  что
[22:48.000 --> 22:50.000]  эти штуки,
[22:50.000 --> 22:52.000]  которые называются gvp и vgp,
[22:52.000 --> 22:54.000]  соответственно
[22:54.000 --> 22:56.000]  означают то,
[22:56.000 --> 22:58.000]  как
[22:58.000 --> 23:00.000]  наши матрицы якобы
[23:00.000 --> 23:02.000]  действуют на соответствующие вектора.
[23:02.000 --> 23:04.000]  Тут даже, вот видите, есть
[23:04.000 --> 23:06.000]  функции, которые от
[23:06.000 --> 23:08.000]  function, вы видите,
[23:08.000 --> 23:10.000]  eigenvalues, eigenvectors,
[23:10.000 --> 23:12.000]  на первый взгляд кажется довольно
[23:12.000 --> 23:14.000]  странной конструкцией,
[23:14.000 --> 23:16.000]  у вас функция вычисляет собственные векторы,
[23:16.000 --> 23:18.000]  а вы от неё градиент берёте.
[23:18.000 --> 23:20.000]  Тут это всё проделано,
[23:20.000 --> 23:22.000]  и не только здесь,
[23:22.000 --> 23:24.000]  но и в других пакетах тоже.
[23:24.000 --> 23:26.000]  Пожалуйста, если вдруг у вас такая
[23:26.000 --> 23:28.000]  необходимость, используйте максимум весь функционал.
[23:30.000 --> 23:32.000]  Понятно ли,
[23:32.000 --> 23:34.000]  как это в принципе устроено?
[23:34.000 --> 23:36.000]  Я пока не спрашиваю, понятно ли, как это работает
[23:36.000 --> 23:38.000]  в деталях, но надеюсь, что хотя бы
[23:38.000 --> 23:40.000]  основная
[23:40.000 --> 23:42.000]  вы её освоили,
[23:42.000 --> 23:44.000]  и понятно, как это будет работать.
[23:44.000 --> 23:46.000]  Можно ли переходить к примерам,
[23:46.000 --> 23:48.000]  или есть какие-то вопросы?
[23:48.000 --> 23:50.000]  Спасибо, вижу,
[23:50.000 --> 23:52.000]  люди тут, это приятно.
[23:52.000 --> 23:54.000]  Теперь
[23:56.000 --> 23:58.000]  небольшой
[23:58.000 --> 24:00.000]  туториал про джакс,
[24:00.000 --> 24:02.000]  довольно кратко,
[24:02.000 --> 24:04.000]  по сравнению с тем, сколько там всего.
[24:04.000 --> 24:06.000]  Основные
[24:06.000 --> 24:08.000]  особенности
[24:08.000 --> 24:10.000]  этого пакета,
[24:10.000 --> 24:12.000]  что это действительно снова обёртым дампаем,
[24:12.000 --> 24:14.000]  она позволяет автоматически векторизовать
[24:14.000 --> 24:16.000]  все вычисления, то есть вы там можете циклы
[24:16.000 --> 24:18.000]  компилировать,
[24:18.000 --> 24:20.000]  также позволяет
[24:20.000 --> 24:22.000]  короче говоря,
[24:22.000 --> 24:24.000]  кто-нибудь знает, что такое
[24:24.000 --> 24:26.000]  SPMD? Оставьте плюсы,
[24:26.000 --> 24:28.000]  если знаете, имелось, если нет.
[24:28.000 --> 24:30.000]  В общем, эта штука
[24:30.000 --> 24:32.000]  расшифровывается, кто-то знает, классно,
[24:32.000 --> 24:34.000]  как single-prose
[24:34.000 --> 24:36.000]  data.
[24:36.000 --> 24:38.000]  То есть вы можете
[24:38.000 --> 24:40.000]  параллелить
[24:40.000 --> 24:42.000]  по процессам достаточно легко,
[24:42.000 --> 24:44.000]  там называется функция PMAP,
[24:44.000 --> 24:46.000]  которая условно в современных реалиях
[24:46.000 --> 24:48.000]  наиболее актуальной историей,
[24:48.000 --> 24:50.000]  это когда у вас там много GPU,
[24:50.000 --> 24:52.000]  и вы пишете какой-то код, а потом пишете PMAP,
[24:52.000 --> 24:54.000]  и он автоматически раскидывается на GPU.
[24:54.000 --> 24:56.000]  В общем, какая-то такая история.
[24:56.000 --> 24:58.000]  Понятно, что основная проблема
[24:58.000 --> 25:00.000]  здесь в наличии железа, чтобы это все
[25:00.000 --> 25:02.000]  потестить.
[25:02.000 --> 25:04.000]  В общем, это как бы немного
[25:04.000 --> 25:06.000]  выходит за рамки
[25:06.000 --> 25:08.000]  того, о чем мы будем дальше говорить.
[25:08.000 --> 25:10.000]  Ну, вот, собственно, дифференцирование поддерживается,
[25:10.000 --> 25:12.000]  вот XLA, это, собственно, бэккант,
[25:12.000 --> 25:14.000]  на котором Санзерфлоу изначально был написан,
[25:14.000 --> 25:16.000]  а потом от него отказались,
[25:16.000 --> 25:18.000]  пересказали на джаз, практически.
[25:18.000 --> 25:20.000]  Ну, джаз, это инкапиляция,
[25:20.000 --> 25:22.000]  все как надо.
[25:22.000 --> 25:24.000]  Питоновский код не страдает
[25:24.000 --> 25:26.000]  от медленности питона
[25:26.000 --> 25:28.000]  и запускается со скоростью
[25:28.000 --> 25:30.000]  пищи штабинарного.
[25:30.000 --> 25:32.000]  Как уже было показано,
[25:32.000 --> 25:34.000]  в члене градиентов и все прочее,
[25:34.000 --> 25:36.000]  это очень простая штука.
[25:36.000 --> 25:38.000]  Берете, называете, град питонской функции,
[25:38.000 --> 25:40.000]  получаете то, что у нас.
[25:40.000 --> 25:42.000]  Важно оборачивать в джид
[25:42.000 --> 25:44.000]  как саму функцию, так градиент от нее,
[25:44.000 --> 25:46.000]  и они все как, типа, по цепочке
[25:46.000 --> 25:48.000]  будут друг другу применяться
[25:48.000 --> 25:50.000]  и зарабатывать.
[25:50.000 --> 25:52.000]  Так, проверка, что все работает,
[25:52.000 --> 25:54.000]  и он сработал, да, ура.
[25:54.000 --> 25:56.000]  Ну, короче, история та же самая.
[25:56.000 --> 25:58.000]  import.jax.numpy
[25:58.000 --> 26:00.000]  Вот. Важный момент,
[26:00.000 --> 26:02.000]  что по дефолту все делается
[26:02.000 --> 26:04.000]  в одинарной точности.
[26:04.000 --> 26:06.000]  То есть у вас там, типа,
[26:06.000 --> 26:08.000]  5-6 значащих цифр
[26:08.000 --> 26:10.000]  после запятой.
[26:10.000 --> 26:12.000]  Вот. Поэтому, чтобы
[26:12.000 --> 26:14.000]  более точно
[26:14.000 --> 26:16.000]  и получать подобные
[26:16.000 --> 26:18.000]  соответственность теории
[26:18.000 --> 26:20.000]  значения, надо переключиться
[26:20.000 --> 26:22.000]  в Apollo64. Вот такая
[26:22.000 --> 26:24.000]  волшебная строчка, видно же,
[26:24.000 --> 26:26.000]  которая это делает.
[26:26.000 --> 26:28.000]  И, соответственно,
[26:28.000 --> 26:30.000]  простая штука, как, простой пример,
[26:30.000 --> 26:32.000]  как это все дело применяется.
[26:32.000 --> 26:34.000]  То есть пишете функцию,
[26:34.000 --> 26:36.000]  делаете операции, возвращаете скаля,
[26:36.000 --> 26:38.000]  посчитаете градиент от нее,
[26:38.000 --> 26:40.000]  указываете, по какому из аргументов этой
[26:40.000 --> 26:42.000]  функции вы хотите посчитать аргумент,
[26:42.000 --> 26:44.000]  хотите посчитать градиент.
[26:44.000 --> 26:46.000]  Вот. А дальше указываете,
[26:46.000 --> 26:48.000]  возвращает ли эта функция
[26:48.000 --> 26:50.000]  какой-то еще
[26:50.000 --> 26:52.000]  величины,
[26:52.000 --> 26:54.000]  объекты, которые
[26:54.000 --> 26:56.000]  надо сохранить для какого-то
[26:56.000 --> 26:58.000]  дальнейшего возможности использования.
[26:58.000 --> 27:00.000]  Поэтому здесь написано false, мы возвращаем
[27:00.000 --> 27:02.000]  только число.
[27:02.000 --> 27:04.000]  Понятен ли синтаксис?
[27:04.000 --> 27:06.000]  Знакомы ли вы
[27:06.000 --> 27:08.000]  с декораторами?
[27:08.000 --> 27:10.000]  Или надо что-то еще пояснить?
[27:12.000 --> 27:14.000]  Вот. Раз, два, три, четыре, пять
[27:14.000 --> 27:16.000]  строчек. Можно
[27:16.000 --> 27:18.000]  указать номер строчки и сказать, что
[27:18.000 --> 27:20.000]  непонятно. Спроси точнее.
[27:20.000 --> 27:22.000]  Если все понятно, плюсик,
[27:22.000 --> 27:24.000]  пожалуйста, поставьте, чтобы я понимал, что
[27:24.000 --> 27:26.000]  можно двигаться дальше. Первая строчка.
[27:26.000 --> 27:28.000]  А, смотрите, это
[27:28.000 --> 27:30.000]  называется декоратор.
[27:30.000 --> 27:32.000]  Вот. И эта штука применяет
[27:32.000 --> 27:34.000]  функцию к функции, и
[27:34.000 --> 27:36.000]  что-то с ней делает.
[27:36.000 --> 27:38.000]  В частности, здесь
[27:38.000 --> 27:40.000]  это декоратор, который
[27:40.000 --> 27:42.000]  компилирует эту функцию в
[27:42.000 --> 27:44.000]  словном бинарне, который потом вызывается.
[27:44.000 --> 27:46.000]  Вот. То есть ключевое слово
[27:46.000 --> 27:48.000]  декоратор, и вы найдете
[27:48.000 --> 27:50.000]  очень много примеров
[27:50.000 --> 27:52.000]  в условном
[27:52.000 --> 27:54.000]  туториалов про то, что это такое.
[27:54.000 --> 27:56.000]  Идея в общем в том,
[27:56.000 --> 27:58.000]  чтобы преобразовать саму функцию
[27:58.000 --> 28:00.000]  во что-то.
[28:00.000 --> 28:02.000]  И потом я снова верну.
[28:02.000 --> 28:04.000]  Вижу.
[28:06.000 --> 28:08.000]  Так. Ну окей. Вроде
[28:08.000 --> 28:10.000]  подавляющее большинство
[28:10.000 --> 28:12.000]  говорит, что все нормально.
[28:12.000 --> 28:14.000]  Гуд.
[28:14.000 --> 28:16.000]  Так. Не знаю. Отдельная история
[28:16.000 --> 28:18.000]  про то, что случайные числа в джаксе
[28:18.000 --> 28:20.000]  немножко устроены похитрее, чем
[28:20.000 --> 28:22.000]  на нампайе,
[28:22.000 --> 28:24.000]  потому что они порсят
[28:24.000 --> 28:26.000]  свою воспроизводимость.
[28:26.000 --> 28:28.000]  Вот. Поэтому там
[28:28.000 --> 28:30.000]  сейчас вы увидите, как они делаются
[28:30.000 --> 28:32.000]  в специальном образе, то есть генераторы задания СИДа.
[28:32.000 --> 28:34.000]  То есть надо вот сначала ключ
[28:34.000 --> 28:36.000]  задать, потом уже размерности.
[28:36.000 --> 28:38.000]  В общем, случайные величины зададим.
[28:38.000 --> 28:40.000]  Икс, соответственно, вектор из N
[28:40.000 --> 28:42.000]  элементов, A матрица на N
[28:42.000 --> 28:44.000]  и B вектор из N элемента тоже.
[28:44.000 --> 28:46.000]  Вот.
[28:46.000 --> 28:48.000]  Ну и дальше давайте посмотреть,
[28:48.000 --> 28:50.000]  что происходит.
[28:50.000 --> 28:52.000]  Ну, собственно, проверка корректности того,
[28:52.000 --> 28:54.000]  что градиент посчитан верно.
[28:54.000 --> 28:56.000]  Мы знаем правильный ответ. Вот он.
[28:56.000 --> 28:58.000]  Вот. И дальше
[28:58.000 --> 29:00.000]  сравниваем по норме
[29:00.000 --> 29:02.000]  автоматически посчитанный градиент
[29:02.000 --> 29:04.000]  в этих же точках по иксу
[29:04.000 --> 29:06.000]  с градиентом посчитан аналитически.
[29:06.000 --> 29:08.000]  Вот.
[29:08.000 --> 29:10.000]  Ну, собственно, 10-11 это, понятно,
[29:10.000 --> 29:12.000]  почти ноль, хорошая точность.
[29:12.000 --> 29:14.000]  Вот. Дальше сравнивается скорость выполнения.
[29:14.000 --> 29:16.000]  Ну вот, аналитически посчитать
[29:16.000 --> 29:18.000]  стоит 1.76
[29:18.000 --> 29:20.000]  микро...
[29:20.000 --> 29:22.000]  Нет, не микро, миллисекунд.
[29:22.000 --> 29:24.000]  Просто функция, которая участвует в градиент
[29:24.000 --> 29:26.000]  делает почти одну микро...
[29:26.000 --> 29:28.000]  Ой, ну, одну миллисекунду, да.
[29:28.000 --> 29:30.000]  Вот. Если вы ее разоджеттуете,
[29:30.000 --> 29:32.000]  то она в три раза ускоряется.
[29:32.000 --> 29:34.000]  Вот. То есть вот такая вот
[29:34.000 --> 29:36.000]  хитрая штуковина.
[29:36.000 --> 29:38.000]  Вот. Вот эта штука, блок
[29:38.000 --> 29:40.000]  until ready, делается для того, чтобы избежать...
[29:40.000 --> 29:42.000]  Поскольку таймы-то много раз
[29:42.000 --> 29:44.000]  сочетают функцию, вот, чтобы избежать
[29:44.000 --> 29:46.000]  проблем с тем, как это может
[29:46.000 --> 29:48.000]  параллельно исполняться, в общем,
[29:48.000 --> 29:50.000]  рекомендуется авторами писать вот так,
[29:50.000 --> 29:52.000]  для более честного сравнения по времени.
[29:52.000 --> 29:54.000]  Вот. То есть мораль...
[29:54.000 --> 29:56.000]  Во-первых, мы считали все правильно.
[29:56.000 --> 29:58.000]  Во-вторых, джит дает нам еще и более
[29:58.000 --> 30:00.000]  быстрые вычисления.
[30:00.000 --> 30:02.000]  Ну, собственно, тут пример того, как
[30:02.000 --> 30:04.000]  можно писать джит без
[30:04.000 --> 30:06.000]  явного декоратора.
[30:06.000 --> 30:08.000]  Так. Есть ли какие-то вопросы, если все понятно,
[30:08.000 --> 30:10.000]  плюс поставьте, пожалуйста.
[30:10.000 --> 30:12.000]  Good.
[30:12.000 --> 30:14.000]  Так. Нам что-то немножко ускорится.
[30:14.000 --> 30:16.000]  Ну, тут про гессиан то же самое.
[30:16.000 --> 30:18.000]  Я думаю, вы там, если кому интересно, посмотрите
[30:18.000 --> 30:20.000]  какие здесь методы. То есть гессиан
[30:20.000 --> 30:22.000]  тоже можно автоматически посчитать,
[30:22.000 --> 30:24.000]  ничего не страдает.
[30:24.000 --> 30:26.000]  В общем, сравнение forward-мода и backward-мода
[30:26.000 --> 30:28.000]  на этой штуке. То есть у нас
[30:28.000 --> 30:30.000]  одномерное. Мы из n
[30:30.000 --> 30:32.000]  элемента получаем 1.
[30:32.000 --> 30:34.000]  Вот. И тут можно, типа, взять
[30:34.000 --> 30:36.000]  jack forward и jack
[30:36.000 --> 30:38.000]  rev, типа reverse,
[30:38.000 --> 30:40.000]  вот. То есть это как бы grad.
[30:40.000 --> 30:42.000]  Это некоторая тоже обертка
[30:42.000 --> 30:44.000]  под, по-моему, rev.
[30:44.000 --> 30:46.000]  Суть я помню. Вот.
[30:46.000 --> 30:48.000]  Потому что, ну, там понятно, что это будет быстрее.
[30:48.000 --> 30:50.000]  Вот. Ну, можно как бы
[30:50.000 --> 30:52.000]  полезть внутрь и вызвать как бы исходную функцию,
[30:52.000 --> 30:54.000]  чтобы сравнить просто скорость выполнения.
[30:54.000 --> 30:56.000]  Ну и вот видно, что forward
[30:56.000 --> 30:58.000]  включается в 13 микросекунд, а backward
[30:58.000 --> 31:00.000]  типа 300
[31:00.000 --> 31:02.000]  миллисекунд. Вот.
[31:02.000 --> 31:04.000]  Я надеюсь, разница
[31:04.000 --> 31:06.000]  достаточно очевидна. В скорости,
[31:06.000 --> 31:08.000]  которая, собственно, из теории напрямую следует.
[31:10.000 --> 31:12.000]  Понятно ли, что
[31:12.000 --> 31:14.000]  изображено на экране?
[31:14.000 --> 31:16.000]  Плюс, пожалуйста, поставьте, если понятно.
[31:16.000 --> 31:18.000]  И напишите минус или вопрос,
[31:18.000 --> 31:20.000]  если надо выяснить какую-то строчку.
[31:20.000 --> 31:22.000]  Так. Ну, вроде пока нормально.
[31:22.000 --> 31:24.000]  Вот. Так. Ну и, собственно,
[31:24.000 --> 31:26.000]  наоборот.
[31:26.000 --> 31:28.000]  Взята функция, типа,
[31:28.000 --> 31:30.000]  что это? softmax, да?
[31:30.000 --> 31:32.000]  Вот. Которая посчитана
[31:32.000 --> 31:34.000]  устойчивым образом. Обратите внимание, что это
[31:34.000 --> 31:36.000]  не просто экспонента
[31:36.000 --> 31:38.000]  от элемента вектора делить на
[31:38.000 --> 31:40.000]  сумму экспонента от всех элементов вектора.
[31:40.000 --> 31:42.000]  Сумма экспонента,
[31:42.000 --> 31:44.000]  ну, сумма всех экспонентов от всех элементов вектора.
[31:44.000 --> 31:46.000]  Короче говоря,
[31:46.000 --> 31:48.000]  подумайте, в общем,
[31:48.000 --> 31:50.000]  простое упражнение, почему
[31:50.000 --> 31:52.000]  если считать это в лоб, то...
[31:52.000 --> 31:54.000]  Ну да, короче, давайте я просто пишу,
[31:54.000 --> 31:56.000]  что типа эта штука делает вектор
[31:56.000 --> 31:58.000]  y и y,
[31:58.000 --> 32:00.000]  это будет проще, действительно,
[32:00.000 --> 32:02.000]  который равен, типа, е в степени
[32:02.000 --> 32:12.000]  е в степени x, и делить на сумму по и от е в степени x, и так тут отвратительное.
[32:12.000 --> 32:16.000]  я знаю, потому что сейчас я отправлю просто в чат сообщений, и все будет просто.
[32:16.000 --> 32:18.000]  ну в общем, вот такая вот история.
[32:18.000 --> 32:22.000]  так, сейчас. это нельзя редактировать, их печаль.
[32:22.000 --> 32:24.000]  а нет, нельзя, да, все равно.
[32:24.000 --> 32:30.000]  ну короче, я надеюсь, что вы понимаете, что каты index относятся к x,
[32:30.000 --> 32:34.000]  а не к exponенте. в общем, да.
[32:34.000 --> 32:38.000]  вот эта функция вычисляется таким вот образом устойчивой.
[32:38.000 --> 32:43.000]  если вы попробуете посчитать в лоб, то у вас, скорее всего, в случае каких-то больших значений появятся наны.
[32:43.000 --> 32:47.000]  хорошее упражнение, подумайте, что случилось, почему полезли наны.
[32:47.000 --> 32:55.000]  ну и тут, соответственно, из-за размерности матрицы можно регулировать то, как будет соотноситься размерность входа и выхода.
[32:55.000 --> 32:57.000]  и мы сейчас это посмотрим.
[32:57.000 --> 33:02.000]  ну тут, собственно, используется и кабиан, потому что градиент нам тут уже не поможет.
[33:02.000 --> 33:06.000]  ну типа одинаковые значения.
[33:06.000 --> 33:15.000]  если попробовать запустить, собственно, jack, то все хорошо.
[33:15.000 --> 33:22.000]  если пытаться запустить grad, то он скажет, что просите градиент только от скалерных функций, можно посчитать.
[33:22.000 --> 33:24.000]  а у вас на выходе тысяча.
[33:24.000 --> 33:30.000]  то есть вы как бы тут вам не дадут посчитать что-то, что заведомо неправомерно.
[33:30.000 --> 33:35.000]  ну теперь, собственно, опять же forward и backward вполне себе здесь работают.
[33:35.000 --> 33:38.000]  между ними равен 10 и 16.
[33:38.000 --> 33:40.000]  все вроде как в порядке.
[33:40.000 --> 33:44.000]  и гипотеза такая, что forward и backward должен стать быстрее backward.
[33:44.000 --> 33:47.000]  потому что здесь размерности совпадают.
[33:47.000 --> 33:50.000]  посмотрим сейчас, что получится на практике.
[33:54.000 --> 33:57.000]  ну на практике получилось в общем-то соизмеримо.
[33:57.000 --> 34:09.000]  то есть получается один раз, ну типа тысяча раз прохода вперед, тысяча раз прохода назад, примерно одинаково.
[34:09.000 --> 34:13.000]  то есть мы как бы в квадратной матрице собирали либо по строкам, либо по столбцам.
[34:13.000 --> 34:23.000]  теперь если выкрутить размерности и отображать 10 к тысячу, то здесь уже станет все более наглядно.
[34:23.000 --> 34:26.000]  опять все хорошо по точности.
[34:26.000 --> 34:29.000]  ну тут мы как бы сравниваемся с тобой.
[34:29.000 --> 34:37.000]  на forward-моде получилось 62 микросекунды, на backward-моде 2 миллистекунды.
[34:37.000 --> 34:40.000]  ну то есть 100 что ли раз.
[34:40.000 --> 34:43.000]  тут медленнее.
[34:43.000 --> 34:50.000]  это все эксперимент для того, чтобы просто подтвердить то, что мы уже видели из тюри.
[34:50.000 --> 34:58.000]  есть ли какие-то вопросы по тому, что мы хотели получить, как мы это сделали и почему все это работает?
[34:58.000 --> 35:00.000]  вижу 7 плюсов.
[35:00.000 --> 35:03.000]  при этом 20 человек чуть больше.
[35:03.000 --> 35:07.000]  все это мне всему этому внимают.
[35:07.000 --> 35:11.000]  пожалуйста все остальные тоже как-то прореагируйте.
[35:11.000 --> 35:15.000]  мне хочется, чтобы они отвалились по дороге.
[35:15.000 --> 35:17.000]  окей, да, спасибо.
[35:17.000 --> 35:23.000]  в общем, этот туториал лежит в репозитории.
[35:23.000 --> 35:28.000]  тут еще есть про произведение гисяна на вектор, но я не буду сейчас про это вдаваться в подробности.
[35:28.000 --> 35:34.000]  мы когда в методах до этого дойдем, то вы поймете, зачем тут этот кусочек нужен.
[35:34.000 --> 35:41.000]  а пока давайте переключимся к нашей следующей теме про выпуклые функции.
[35:41.000 --> 35:49.000]  осталось не так много времени, но я постараюсь максимально лаконично и по делу про все это рассказать.
[35:49.000 --> 35:54.000]  поставьте, пожалуйста, плюс, если у вас уже была эта тема на сембарах.
[35:58.000 --> 36:00.000]  у всех была?
[36:00.000 --> 36:02.000]  отлично.
[36:02.000 --> 36:05.000]  мы тут просто пояснение относительно того, почему.
[36:05.000 --> 36:08.000]  потому что в доме на сембарах работает, скорее всего.
[36:08.000 --> 36:10.000]  окей, гуд.
[36:10.000 --> 36:12.000]  прекрасно.
[36:12.000 --> 36:16.000]  а теперь надо как-то вытащить чат.
[36:16.000 --> 36:20.000]  в окно со слайдами.
[36:20.000 --> 36:22.000]  почти что получилось.
[36:24.000 --> 36:26.000]  ура.
[36:26.000 --> 36:28.000]  все, красота.
[36:28.000 --> 36:34.000]  я надеюсь, поскольку у всех уже практически это было, все помнят, что у нас интересует
[36:34.000 --> 36:38.000]  какая вот функция, которая наукополношительная, это важно.
[36:38.000 --> 36:41.000]  полезно понимать, почему это важно.
[36:41.000 --> 36:46.000]  подумайте на досуге, если не придумаете, напишите мне, я прокомментирую в телеграмме.
[36:46.000 --> 36:52.000]  соответственно, выполнен такой нераз для любых элементов из области определения.
[36:52.000 --> 36:56.000]  геометрически нельзя не сказать, что это значит геометрически.
[36:56.000 --> 36:59.000]  это не полноценно получается.
[36:59.000 --> 37:03.000]  хотя я думаю, что все это уже, надеюсь, вы лучше или не осознали.
[37:03.000 --> 37:06.000]  что надо нажать? вот так надо нажать.
[37:06.000 --> 37:08.000]  победа.
[37:08.000 --> 37:14.000]  вот у вас есть какая-то функция. вы берете предвольные две точки.
[37:14.000 --> 37:19.000]  x1, x2. проводите отрезок.
[37:19.000 --> 37:28.000]  любая точка, которую вы возьмете вот здесь, если вы сравните вот это значение с этим значением,
[37:28.000 --> 37:33.000]  то у вас получится, что крестик всегда не ниже, чем кружочек.
[37:33.000 --> 37:38.000]  тут все максимально прямолинейно.
[37:38.000 --> 37:43.000]  в плане понятности, я надеюсь, они в плане гривизны.
[37:43.000 --> 37:47.000]  функция может быть достаточно нелинейными.
[37:47.000 --> 37:54.000]  но при этом и собственно про это был некоторый эпиграф на первой лекции.
[37:54.000 --> 38:00.000]  про то, что водораздел проходит не между линейностью и нелинейностью, а между выпуклостью и не выпуклостью.
[38:00.000 --> 38:03.000]  вот так.
[38:03.000 --> 38:05.000]  это была картинка.
[38:05.000 --> 38:09.000]  теперь возвращаемся к слайдеру.
[38:09.000 --> 38:11.000]  вернулись.
[38:11.000 --> 38:14.000]  соответственно у нас будут вогнутые функции, такие, что минусы выпукла.
[38:14.000 --> 38:17.000]  определение довольно прямолинейно.
[38:17.000 --> 38:22.000]  пример выпуклой функции. я надеюсь, что хотя бы частично они были разобраны на семинаре.
[38:22.000 --> 38:28.000]  пожалуйста, поставьте плюсик, если все они были разобраны на вашем семинаре.
[38:28.000 --> 38:33.000]  и минус, если хотя бы одна была пропущена.
[38:33.000 --> 38:36.000]  проверка на кто что помнит.
[38:36.000 --> 38:39.000]  все разбирали. класс.
[38:39.000 --> 38:43.000]  возможно это просто люди из одной группы, которая была на семинаре.
[38:43.000 --> 38:46.000]  которые все это разобрали. интересно.
[38:46.000 --> 38:52.000]  что-то как-то 1, 2, 3, 4 реакции.
[38:52.000 --> 38:55.000]  и остальные как-то какой-то ступор.
[38:55.000 --> 38:59.000]  без лог, да. понятно. хорошо.
[38:59.000 --> 39:02.000]  это я ожидаемый ответ.
[39:02.000 --> 39:05.000]  максимум у меня было. окей.
[39:05.000 --> 39:08.000]  все это не смертельно.
[39:11.000 --> 39:14.000]  наверное посчитали, что это слишком просто, чтобы разбирать.
[39:14.000 --> 39:17.000]  окей. понятно.
[39:17.000 --> 39:21.000]  примерно про все это мы в какой-то момент поговорим.
[39:21.000 --> 39:25.000]  единственное, что может быть... увидим, как дело пойдет.
[39:25.000 --> 39:28.000]  важная связь. спасибо.
[39:28.000 --> 39:31.000]  важная связь про множество.
[39:31.000 --> 39:34.000]  был максимум и собственную силу. да, прекрасно.
[39:34.000 --> 39:37.000]  хороший пример про максимум.
[39:37.000 --> 39:40.000]  у нас есть надграфик.
[39:40.000 --> 39:44.000]  это то, что будет связывать с предыдущими лекциями про множество.
[39:44.000 --> 39:48.000]  у нас есть надграфик. это такое множество, которое из xt.
[39:48.000 --> 39:52.000]  т больше чем f of x.
[39:52.000 --> 39:57.000]  если возвращаться к предыдущему примеру.
[39:57.000 --> 40:00.000]  я надеюсь, что он сейчас подгрузится.
[40:00.000 --> 40:03.000]  или он так не умеет? да, так умеет.
[40:03.000 --> 40:06.000]  над графиком здесь будет вот эта штука.
[40:09.000 --> 40:12.000]  все такие t и x.
[40:12.000 --> 40:15.000]  что t лежит выше, чем x.
[40:15.000 --> 40:19.000]  уже из этой картинки кажется, что плюс медс очевидно,
[40:19.000 --> 40:23.000]  что выпуклась надграфик и выпуклась функция. это одно и то же.
[40:23.000 --> 40:26.000]  действительно это так.
[40:26.000 --> 40:29.000]  сейчас будет доказательство. я думаю, что сейчас его пропущу.
[40:29.000 --> 40:33.000]  потому что потом пришлю под эвку.
[40:33.000 --> 40:36.000]  с выкладками.
[40:36.000 --> 40:39.000]  буквально три строчки.
[40:39.000 --> 40:42.000]  ничего такого нет.
[40:42.000 --> 40:45.000]  важно понимать, что это одно и то же.
[40:45.000 --> 40:48.000]  это важно, потому что утверждение про выпуклась функции
[40:48.000 --> 40:51.000]  можно будет переформулировать к выпуклости множеству.
[40:51.000 --> 40:55.000]  помимо просто выпуклых функций у нас будут
[40:55.000 --> 40:58.000]  сильные выпуклы.
[40:58.000 --> 41:01.000]  это страшное определение.
[41:01.000 --> 41:05.000]  потому что тут еще присутствует некоторый квадратичный член по x.
[41:05.000 --> 41:09.000]  но к счастью, у этой штуки есть довольно прозрачная
[41:09.000 --> 41:12.000]  геометрическая интерпретация,
[41:12.000 --> 41:15.000]  которую мы разберем, когда дадем до коридории выпуклась.
[41:15.000 --> 41:18.000]  несложно показать, что привели до следующих включений.
[41:18.000 --> 41:22.000]  выпуклась, строгая выпуклась и сильная выпуклась
[41:22.000 --> 41:25.000]  относятся таким вот образом.
[41:25.000 --> 41:28.000]  рекомендую подумать...
[41:31.000 --> 41:34.000]  привести пример строгой выпуклой,
[41:34.000 --> 41:37.000]  но не сильно выпуклой.
[41:37.000 --> 41:40.000]  попытаться понять, где здесь зазоры.
[41:40.000 --> 41:43.000]  это хорошее упражнение.
[41:43.000 --> 41:46.000]  это определение на функции нам будет нужно,
[41:46.000 --> 41:49.000]  когда мы будем говорить про методы
[41:49.000 --> 41:52.000]  для функций, у которых есть вот это вот свойство,
[41:52.000 --> 41:55.000]  вот этот констант m больше нуля,
[41:55.000 --> 41:58.000]  будет немного отличаться приведение и скорости сходимости.
[41:58.000 --> 42:01.000]  поэтому сейчас это я ввожу, чтобы потом
[42:01.000 --> 42:04.000]  сослаться на это определение.
[42:04.000 --> 42:07.000]  погнали теперь к критериям.
[42:07.000 --> 42:10.000]  можно считать упуклую функцию сильной выпуклость m равной нулю,
[42:10.000 --> 42:13.000]  поэтому все дальше будет для упуклых функций
[42:13.000 --> 42:16.000]  и потом просто m попола умножен на кое-что,
[42:17.000 --> 42:20.000]  будет давать результат уже для сильного выпуклого функции.
[42:20.000 --> 42:23.000]  утверждение вот такое вот есть.
[42:23.000 --> 42:26.000]  дифференциальный критерий первого порядка,
[42:26.000 --> 42:29.000]  который говорит нам,
[42:29.000 --> 42:32.000]  что дифференцируемо определено на множестве.
[42:32.000 --> 42:35.000]  сильного выпукла, если выполнено вот это.
[42:35.000 --> 42:38.000]  давайте поймем геометрически, что это означает.
[42:38.000 --> 42:41.000]  в случае, когда m равна нулю,
[42:41.000 --> 42:44.000]  то это значит,
[42:44.000 --> 42:47.000]  что в любой точке мы можем провести
[42:47.000 --> 42:50.000]  опорную гиперплоскость
[42:50.000 --> 42:53.000]  к над-графику,
[42:53.000 --> 42:56.000]  или если по-другому как-то сформулировать,
[42:56.000 --> 42:59.000]  то будет касательная,
[42:59.000 --> 43:02.000]  которая будет дифференцируема,
[43:02.000 --> 43:05.000]  и это касательно будет глобальной
[43:05.000 --> 43:08.000]  оценкой снизу на всю функцию.
[43:08.000 --> 43:11.000]  поставьте, пожалуйста, плюсик,
[43:11.000 --> 43:14.000]  если нужна картинка.
[43:14.000 --> 43:17.000]  нужна картинка все-таки.
[43:17.000 --> 43:20.000]  вот смотрите.
[43:20.000 --> 43:23.000]  вот у нас есть наша выпуклая функция,
[43:23.000 --> 43:26.000]  и мы в любой точке, например, вот здесь,
[43:26.000 --> 43:29.000]  можем провести гиперплоскость касательную.
[43:29.000 --> 43:32.000]  то есть касательная у нас что такое?
[43:32.000 --> 43:35.000]  это касательная в точке x, напоминаю, f от x,
[43:35.000 --> 43:38.000]  плюс колярное произведение градиенс на y-x.
[43:38.000 --> 43:41.000]  но это, собственно же, от y, наверное.
[43:41.000 --> 43:44.000]  прямая, которая касается в точке...
[43:44.000 --> 43:47.000]  при y равна x это просто f от x,
[43:47.000 --> 43:50.000]  а дальше это гиперплоскость.
[43:50.000 --> 43:53.000]  и эта штука в любой точке,
[43:53.000 --> 43:56.000]  глобальная оценка снизу.
[43:56.000 --> 43:59.000]  какую бы точку вот здесь, вот здесь вы не взяли,
[43:59.000 --> 44:02.000]  у вас всегда гиперплоскость будет лежать ниже, чем эта функция.
[44:02.000 --> 44:05.000]  понятна ли картинка?
[44:05.000 --> 44:08.000]  поставьте плюс, если понятная картинка.
[44:08.000 --> 44:11.000]  а можно же сдвинуть формулу? я ее не смог приписать.
[44:11.000 --> 44:14.000]  давайте я просто и тут напишу,
[44:14.000 --> 44:17.000]  как бы это не проблема, что вот f от y,
[44:17.000 --> 44:20.000]  ну, если...
[44:20.000 --> 44:23.000]  то есть для любых двух точек,
[44:23.000 --> 44:26.000]  x и x от звездочки, это выполнено вот такое вот.
[44:36.000 --> 44:39.000]  вот эта штука, если m не ноль,
[44:39.000 --> 44:42.000]  означает, что...
[44:42.000 --> 44:45.000]  давайте ее надо бы другим цветом нарисовать, конечно.
[44:45.000 --> 44:48.000]  вот эта штука, она означает,
[44:48.000 --> 44:51.000]  что... ой, я сейчас не попаду в цвет, боюсь.
[44:51.000 --> 44:54.000]  сейчас, секунду, я попробую найти вот этот, что ли.
[44:54.000 --> 44:57.000]  что вот в этой точке у нас
[44:57.000 --> 45:00.000]  оценка не линейная, а квадратичная.
[45:00.000 --> 45:03.000]  то есть есть некоторая парабола,
[45:03.000 --> 45:06.000]  которая глобально снизу подпирает...
[45:06.000 --> 45:09.000]  подпирает функцию.
[45:09.000 --> 45:12.000]  это, собственно, и означает сильную выпуклость.
[45:12.000 --> 45:15.000]  стала ли чуть понятнее геометрия
[45:15.000 --> 45:18.000]  всех этих определений?
[45:18.000 --> 45:21.000]  оставьте плюс, если понятный, милость, если надо подточнить.
[45:21.000 --> 45:24.000]  так, прошу прощения за очередную паузу.
[45:24.000 --> 45:27.000]  сейчас еще раз покажу картинку,
[45:27.000 --> 45:30.000]  и вопрос остается в силе.
[45:31.000 --> 45:34.000]  так, окей.
[45:34.000 --> 45:37.000]  ну и, соответственно, поскольку есть
[45:37.000 --> 45:40.000]  квадратичная оценка снизу, то мы можем,
[45:40.000 --> 45:43.000]  если думать немножко вперед,
[45:43.000 --> 45:46.000]  можно заменить задачу поиска минимум самой функции
[45:46.000 --> 45:49.000]  на задачу поиска минимум квадратичной оценки снизу,
[45:49.000 --> 45:52.000]  которая решается проще и дает некоторое приближение
[45:52.000 --> 45:55.000]  к тому, что нам надо.
[45:55.000 --> 45:58.000]  но это пойдет более подробно речь, когда о приметных будем говорить.
[45:58.000 --> 46:01.000]  так, теперь снова к слайдам.
[46:04.000 --> 46:07.000]  снова к слайдам.
[46:07.000 --> 46:10.000]  вроде я нигде не набрал, все хорошо.
[46:10.000 --> 46:13.000]  так, доказательства.
[46:16.000 --> 46:19.000]  ну, на самом деле доказать довольно простое.
[46:19.000 --> 46:22.000]  да, давайте уж я расскажу.
[46:22.000 --> 46:25.000]  пусть выпукло. это же критерии, поэтому в обе стороны доказывать.
[46:25.000 --> 46:28.000]  пусть выпукло. у нас есть определение,
[46:28.000 --> 46:31.000]  которое мы можем переписать вот в таком виде.
[46:31.000 --> 46:34.000]  что здесь произошло? ну, вынесли альфа за скобки.
[46:34.000 --> 46:37.000]  и здесь тоже. если мы это на альф поделим,
[46:37.000 --> 46:40.000]  то получим вот такое вот выражение.
[46:40.000 --> 46:43.000]  то есть здесь будет разность точки x2,
[46:43.000 --> 46:46.000]  здесь будет разность x1 и x2.
[46:46.000 --> 46:49.000]  9 альф. переходим к пределу.
[46:49.000 --> 46:52.000]  получаем вот такое выражение,
[46:52.000 --> 46:55.000]  которое прямое равное нулю полностью нас удовлетворяет.
[46:55.000 --> 46:58.000]  есть ли вопросы к выкладкам?
[46:58.000 --> 47:01.000]  или здесь все понятно?
[47:01.000 --> 47:04.000]  плюсик, пожалуйста, по ставке, если все понятно.
[47:04.000 --> 47:07.000]  так, хорошо, вопрос. почему при переходе к пределу по альфе здесь возникает градиент?
[47:07.000 --> 47:10.000]  кто может объяснить?
[47:10.000 --> 47:13.000]  у нас производная по вектору слева получается в пределе,
[47:13.000 --> 47:16.000]  а произвольная по вектору это скорее произведение градиента на вектор.
[47:16.000 --> 47:19.000]  да, вы правы.
[47:19.000 --> 47:22.000]  вы правы немножко утащить формулировку.
[47:22.000 --> 47:25.000]  при переходе к пределу здесь происходит производная по направлению x1 и x2.
[47:25.000 --> 47:28.000]  то есть производная это не по вектору.
[47:28.000 --> 47:31.000]  производная все еще по числу, но просто по направлению фиксированному.
[47:31.000 --> 47:34.000]  а для производной по направлению
[47:34.000 --> 47:37.000]  ДС привели вот такую формулу,
[47:37.000 --> 47:40.000]  которую мы вроде бы на прошлой лекции на слайдах она фигурировала.
[47:40.000 --> 47:43.000]  так скорее произведение градиента в этой точке на направлении.
[47:43.000 --> 47:46.000]  еще один способ понять, каким это правда,
[47:46.000 --> 47:49.000]  если вы вдруг не очень как бы уверенно себя чувствуете,
[47:49.000 --> 47:52.000]  это сказать, что поскольку альфа постремится к нулю,
[47:52.000 --> 47:55.000]  вот это некоторая маленькая поправка.
[47:55.000 --> 47:58.000]  вот это выражение можно по тейлеру разложить в окрестности x2.
[47:58.000 --> 48:01.000]  и у вас в процессе разложений что будет?
[48:01.000 --> 48:04.000]  f от x2 плюс колярное произведение градиента на вот этот вектор.
[48:04.000 --> 48:07.000]  f от x2 сократится с вот этим, альфа поделится, останется ровно вот это.
[48:07.000 --> 48:10.000]  еще один способ.
[48:10.000 --> 48:13.000]  выбирайте, какой вам больше нравится.
[48:14.000 --> 48:17.000]  есть ли еще вопросы по этому объяснению?
[48:17.000 --> 48:20.000]  и в целом полный код.
[48:20.000 --> 48:23.000]  вроде тишина, наверное, понятно.
[48:23.000 --> 48:26.000]  обратно в сторону.
[48:26.000 --> 48:29.000]  потому что, в общем, сейчас увидите.
[48:29.000 --> 48:32.000]  пусть у нас есть это самое нереальное.
[48:32.000 --> 48:35.000]  вот это.
[48:35.000 --> 48:38.000]  пока см равный нулю, как можно перейти к m больше нуля?
[48:38.000 --> 48:41.000]  это будет пояснение в конце.
[48:41.000 --> 48:44.000]  берем произвольную точку.
[48:44.000 --> 48:47.000]  рассматриваем комбинацию некоторых точек из этих двух.
[48:47.000 --> 48:50.000]  поскольку условия наши выполнены для любых двух точек,
[48:50.000 --> 48:53.000]  то сначала берем x1z.
[48:53.000 --> 48:56.000]  1 в первый раз и x2z в второй раз.
[48:56.000 --> 48:59.000]  записываем наши нерайны.
[48:59.000 --> 49:02.000]  сложаем одно на альфа, другое на один.
[49:02.000 --> 49:05.000]  и складываем.
[49:05.000 --> 49:08.000]  то есть тут техника.
[49:08.000 --> 49:11.000]  ну или к счастью.
[49:11.000 --> 49:14.000]  просто применяете все эти...
[49:14.000 --> 49:17.000]  ну просто понимаете, как апеллиры с окулярными произведениями.
[49:17.000 --> 49:20.000]  умножить на альфа умножить на 1 минус альфа,
[49:20.000 --> 49:23.000]  проводить необходимые выплатки, у вас получается, что f от z,
[49:23.000 --> 49:26.000]  то есть вот это все дело сокращается в силу того, чему равно z.
[49:26.000 --> 49:29.000]  f от z равны этой штуке.
[49:29.000 --> 49:32.000]  меньше либо равно, чем альфа на f от x1 плюс 1 минус альфа на f от x2.
[49:32.000 --> 49:35.000]  ну все, это очень победа.
[49:35.000 --> 49:38.000]  получили определение. все хорошо.
[49:38.000 --> 49:41.000]  теперь, чтобы перейти к сильно выпуклому случаю,
[49:41.000 --> 49:44.000]  достаточно проделать все, что было проделано до этого,
[49:44.000 --> 49:47.000]  к функции вот такой.
[49:47.000 --> 49:50.000]  и это работает, потому что, справедливо,
[49:50.000 --> 49:53.000]  выпуклась функция равносильна тому,
[49:53.000 --> 49:56.000]  что вот такая вот функция...
[49:56.000 --> 49:59.000]  то есть если из выпуклой вычесть квадратичный член
[49:59.000 --> 50:02.000]  по документу,
[50:02.000 --> 50:05.000]  и она по-прежнему будет выпукла,
[50:05.000 --> 50:08.000]  то исходная была сильно выпукла.
[50:08.000 --> 50:11.000]  это еще небольшая помощь к тому,
[50:11.000 --> 50:14.000]  чтобы понять, что такое сильная выпуклая функция,
[50:14.000 --> 50:17.000]  если вы не хотите страдать с определением, которое довольно трудоемко
[50:17.000 --> 50:20.000]  и, мне кажется, легким для интерпретации.
[50:20.000 --> 50:23.000]  как это упражнение делать?
[50:23.000 --> 50:26.000]  ну вот тут надо на самом деле просто взять
[50:26.000 --> 50:29.000]  и реально подставить в определение,
[50:29.000 --> 50:32.000]  раскрыть полные квадраты,
[50:32.000 --> 50:35.000]  и все получится.
[50:35.000 --> 50:38.000]  вот здесь будет, соответственно,
[50:38.000 --> 50:41.000]  выпуклая комбинация некоторых двух точек,
[50:41.000 --> 50:44.000]  она раскрывается, переносится,
[50:44.000 --> 50:47.000]  и, опять же, некоторые алгебры, которые, я думаю,
[50:47.000 --> 50:50.000]  всем по силу здесь,
[50:50.000 --> 50:53.000]  вы получаете результат про сильную выпуклую.
[50:53.000 --> 50:56.000]  ну и наоборот.
[50:56.000 --> 50:59.000]  то, что мы проделали, что получили.
[50:59.000 --> 51:02.000]  оставьте плюс, если понятно.
[51:02.000 --> 51:05.000]  я вижу плюс от 5 человек.
[51:05.000 --> 51:08.000]  как сокращается скалярное произведение?
[51:08.000 --> 51:11.000]  о, прекрасный вопрос. давайте пропишем.
[51:11.000 --> 51:14.000]  вполне корректно.
[51:14.000 --> 51:17.000]  мне нужно сейчас нажать вот так
[51:17.000 --> 51:20.000]  и сделать вот так.
[51:20.000 --> 51:23.000]  огонь.
[51:23.000 --> 51:26.000]  так, ну смотрите.
[51:26.000 --> 51:29.000]  сейчас я быстро перенесу то, что здесь написано.
[51:29.000 --> 51:32.000]  то есть у нас, смотрите,
[51:32.000 --> 51:35.000]  ой, странный цвет немножко.
[51:35.000 --> 51:38.000]  у нас f' от z
[51:38.000 --> 51:41.000]  умножает она
[51:41.000 --> 51:44.000]  на z-x1
[51:44.000 --> 51:47.000]  альфа
[51:47.000 --> 51:50.000]  плюс
[51:50.000 --> 51:53.000]  1 минус альфа
[51:53.000 --> 51:56.000]  на f' от z
[51:56.000 --> 51:59.000]  z-x2.
[51:59.000 --> 52:02.000]  вижу новые сообщения в чате.
[52:02.000 --> 52:05.000]  видеопуток завис.
[52:05.000 --> 52:08.000]  интересно.
[52:08.000 --> 52:11.000]  что-нибудь изменилось? о, отвис. прекрасно.
[52:11.000 --> 52:14.000]  при этом напоминаю, спасибо, что
[52:14.000 --> 52:17.000]  это делаем.
[52:17.000 --> 52:20.000]  что z у нас по построению
[52:20.000 --> 52:23.000]  формировалось как альфа x1
[52:23.000 --> 52:26.000]  плюс 1 минус альфа x2.
[52:26.000 --> 52:29.000]  видимо из-за того, что я экран переместил.
[52:29.000 --> 52:32.000]  теперь все хорошо.
[52:32.000 --> 52:35.000]  ну, смотрите, что происходит.
[52:35.000 --> 52:38.000]  у нас z-x1, давайте я кусочком буду расписывать.
[52:38.000 --> 52:41.000]  это что такое?
[52:42.000 --> 52:45.000]  плюс 1 минус альфа на x2.
[52:45.000 --> 52:48.000]  в то же время z-x2
[52:48.000 --> 52:51.000]  равняется альфа
[52:51.000 --> 52:54.000]  x1
[52:54.000 --> 52:57.000]  плюс 1 минус альфа
[52:57.000 --> 53:00.000]  x2 минус x2.
[53:00.000 --> 53:03.000]  да?
[53:03.000 --> 53:06.000]  супер. ну, теперь давайте посмотрим внимательно
[53:06.000 --> 53:09.000]  на то, что будет, если умножить одно выражение
[53:09.000 --> 53:12.000]  на альфа,
[53:12.000 --> 53:15.000]  а другое на 1 минус альфа.
[53:15.000 --> 53:18.000]  наверное, надо что-то как-то преобразовать, да?
[53:18.000 --> 53:21.000]  или уже видно, что все сокращается.
[53:21.000 --> 53:24.000]  сейчас я немножко хочу, наверное, полениться,
[53:24.000 --> 53:27.000]  но если скажете, что не очевидно, то я пропишу детальнее.
[53:29.000 --> 53:32.000]  ну, то есть, давайте вот.
[53:32.000 --> 53:35.000]  видно уже, я надеюсь, что вот эта штука
[53:35.000 --> 53:38.000]  будет совпадать с вот этой штукой
[53:38.000 --> 53:41.000]  с точностью ста знака.
[53:41.000 --> 53:44.000]  ответа нет.
[53:44.000 --> 53:47.000]  пишешь туда, это видно.
[53:47.000 --> 53:50.000]  ладно, что-то как-то я, поскольку не вижу большого энтузиазма,
[53:50.000 --> 53:53.000]  давайте явно пропишу.
[53:53.000 --> 53:56.000]  здесь плюс, ну и дальше, как бы, следите за руками.
[54:08.000 --> 54:11.000]  так, ну, вот, смотрите.
[54:11.000 --> 54:14.000]  во-первых, работает ли видеопоток?
[54:14.000 --> 54:17.000]  начнем с простого вопроса.
[54:17.000 --> 54:20.000]  вот сейчас работает и работает, да?
[54:20.000 --> 54:23.000]  да.
[54:23.000 --> 54:26.000]  ну, вот.
[54:26.000 --> 54:29.000]  ну, вот.
[54:29.000 --> 54:32.000]  ну, вот.
[54:32.000 --> 54:35.000]  ну, вот.
[54:36.000 --> 54:39.000]  вот сейчас работает и до этого нет
[54:39.000 --> 54:42.000]  какое-то время.
[54:42.000 --> 54:45.000]  поток заработал, это прекрасно.
[54:45.000 --> 54:48.000]  ну, смотрите, первая строчка здесь,
[54:48.000 --> 54:51.000]  вторая строчка это вторая строчка, вот этот плюсик
[54:51.000 --> 54:54.000]  это вот этот плюсик.
[54:54.000 --> 54:57.000]  ну, и вот сейчас, я надеюсь, видно, что вот
[54:57.000 --> 55:00.000]  вот эта штука уходит с вот этой штукой.
[55:00.000 --> 55:03.000]  вот.
[55:03.000 --> 55:06.000]  вот эта штука уходит с вот этой.
[55:06.000 --> 55:09.000]  так, Александр, понятно ли, что произошло?
[55:09.000 --> 55:12.000]  так, ну, прекрасно.
[55:12.000 --> 55:15.000]  то есть, ну, пополучно, с помощью этих разностей
[55:15.000 --> 55:18.000]  все удалось починить.
[55:18.000 --> 55:21.000]  так, ну, окей.
[55:21.000 --> 55:24.000]  идем дальше.
[55:24.000 --> 55:27.000]  так, что-то нас встретили, окей.
[55:27.000 --> 55:30.000]  вот.
[55:30.000 --> 55:33.000]  вот.
[55:33.000 --> 55:36.000]  вот.
[55:36.000 --> 55:39.000]  вот.
[55:39.000 --> 55:42.000]  вот.
[55:42.000 --> 55:45.000]  вот.
[55:45.000 --> 55:48.000]  вот.
[55:48.000 --> 55:51.000]  вот.
[55:51.000 --> 55:54.000]  вот.
[55:54.000 --> 55:57.000]  вот.
[55:57.000 --> 56:00.000]  вот.
[56:00.000 --> 56:03.000]  вот.
[56:03.000 --> 56:06.000]  вот.
[56:15.000 --> 56:18.000]  вот.
[56:18.000 --> 56:21.000]  вот.
[56:21.000 --> 56:24.000]  вот.
[56:24.000 --> 56:30.320]  пожалуйста скажите понятно ли откуда это неравенство взялось или нужно прописать формулу
[56:30.320 --> 56:36.000]  так ну судя по тому что нет сильно так вот кому-то уже понятно стало
[56:36.000 --> 56:41.200]  так может быть кто-нибудь еще
[56:45.200 --> 56:49.720]  почему это работает это справедливо любой точке x в том числе в x альфа
[56:49.720 --> 56:54.320]  а распределил x альфа то воспользовавшись определением скалерного произведения
[56:54.320 --> 57:00.680]  вопроса двух сторон донажаем на y минус x и на x минус x транспонированная и вот здесь у нас
[57:00.680 --> 57:07.840]  образуются квадраты в кидовой норке это все в общем-то но одна вторая тут одна вторая здесь
[57:07.840 --> 57:17.480]  так поставьте плюс если нужно написать формулу я пропустил вот андрей вы поставили плюс потому
[57:17.920 --> 57:25.800]  формулу извините что я переспрашиваю я поставил плюс на предыдущий когда
[57:25.800 --> 57:33.680]  спрашивали хорошо да надо какой-то это с этим обозначений придумывайте как хитрее ладно так
[57:33.680 --> 57:40.960]  ну вроде не вижу запроса на то чтобы это детально прописывать окей если появится ну я в любом случае
[57:40.960 --> 57:45.440]  все эти доказательства постараюсь оформить по дайвке также выставить в чат чтобы можно было
[57:45.440 --> 57:51.560]  более детально пройтись по ним вот ну собственно да и через этого следует но вот это штука больше
[57:51.560 --> 57:57.800]  поэтому можем как бы подпереть снизу и получим просто как первого порядка по которому пункса
[57:57.800 --> 58:03.280]  будет выпукло то есть тут вот вот это квадратично слагаемый заменяется на слагаемый из категории
[58:03.280 --> 58:11.600]  первого порядка вот теперь обратную сторону пусть есть точка в которой это не выполнено тогда
[58:11.600 --> 58:18.960]  значит у нас есть направление у нас есть направление по которому выполнено вот это просто из
[58:18.960 --> 58:25.560]  определения дальше далее тут нам будет важно теперь возьмем и поэтому направление немножко
[58:25.560 --> 58:37.400]  сдвинемся от икса на маленькое вот и оказывается что поскольку у нас есть непрерывная дифференцируемый
[58:37.400 --> 58:47.240]  дважды непрерывная дифференцируемость то вот тут кстати пишут что кто-то хочет учиться
[58:47.240 --> 58:59.240]  извините икс ирик достаточно близки тут наверно z они икс должен быть да прошу прощения я не
[58:59.240 --> 59:11.960]  поправила печатку так это восьмой слайд икс назад поменять что эта штука работает и для
[59:11.960 --> 59:16.880]  икс альфа вот то есть тут как бы пользуемся непрерывностью и тем что можно взять достаточно
[59:16.880 --> 59:28.600]  маленькая епсилон чтобы но то есть чтобы в этой точке нарушалась нарушался этот знак и
[59:28.600 --> 59:35.480]  как следствие могли не выполнялся бы критерии первого порядка понятно ли вот этот переход и
[59:35.480 --> 59:40.920]  использование непрерывной дифференцируемости если понятно поставьте пожалуйста плюс то есть
[59:40.920 --> 59:46.160]  удивительно но для того чтобы доказать работоспособность непосредственно практически
[59:46.160 --> 59:51.000]  важного критерия мы доказали третий первый порядка потом на него слайд все вот такая вот
[59:51.000 --> 01:00:01.160]  ага ходовочку как будто все получилось так ну я вижу что понимание не у всех пока что пришло так
[01:00:01.160 --> 01:00:07.480]  давайте что-нибудь с этим сделаем то есть вот это выражение то есть понятно ли вот это выражение
[01:00:07.480 --> 01:00:16.000]  давайте откуда оно взялось начнем с простого вот то есть мы и наш есть такая точка который
[01:00:16.000 --> 01:00:21.600]  гессиан вы положите не определен не так как требует наш критерий вот поэтому есть такое
[01:00:21.600 --> 01:00:31.160]  направление вот теперь мы берем и язык са переходим в это направление и при достаточно
[01:00:32.160 --> 01:00:40.560]  мы предполагаем что все все это ну мы можем выбрать точки икс и игрек так что они будут
[01:00:40.560 --> 01:00:47.280]  достаточно близки зоя которые выполнена вот это и по непрерывности существует окрестность в которой
[01:00:47.280 --> 01:00:54.000]  знак сохраняется вот наверное правильно так сказать помните это утверждение было вот они
[01:00:54.000 --> 01:01:00.080]  о том что есть функции прерывно то есть окрестность который так сохраняется дам было что-то такое да но
[01:01:00.080 --> 01:01:06.240]  вот мы сейчас этим активно пользуемся еще я еще там про ноль непрерывной пункции вот используется в
[01:01:06.240 --> 01:01:11.760]  доказательствах которые вчера выложил поэтому как бы внезапно какие-то казалось бы не очень
[01:01:11.760 --> 01:01:19.000]  практически важные вещи начинают всплывать как обычно самый подходящий момент вот в общем поэтому
[01:01:19.000 --> 01:01:24.720]  знак сохраняется и для и цальха тоже и поэтому притория первого порядка нарушается вот в этом
[01:01:24.920 --> 01:01:30.680]  давайте тогда наверное сейчас уже 10-20 а у меня пять минут еще даже есть да вот он и я понял что
[01:01:30.680 --> 01:01:35.720]  как-то тяжело это доказательство воспринимается я постараюсь его письменно оформить вот тогда
[01:01:35.720 --> 01:01:41.280]  может быть полегче вот ну в общем тут вот самый важный слайд наверное давайте я его пропущу я
[01:01:41.280 --> 01:01:47.240]  оставлю в следующий раз подробнее по нему скажу вот а пока сформулирую наверное основа факт который
[01:01:47.240 --> 01:01:52.560]  нам будет нужен ну с помощью которого все строится вот факт про то что если у нас есть локальный минивум
[01:01:52.560 --> 01:01:59.600]  функции это локальный минивум является глобально вот то о чем я упоминал несколько лет назад
[01:01:59.600 --> 01:02:08.520]  доказательство противного то есть пусть у нас есть новый глобальный минивум какой-то вот так
[01:02:08.520 --> 01:02:14.720]  слушайте давайте попробую это все записать на доске вот возможно так будет лучше восприниматься
[01:02:14.720 --> 01:02:23.760]  попробуем метампрубаши мы будем искать подходящий формат для всех так вот есть доска уран
[01:02:23.760 --> 01:02:32.840]  присмотрите f нашу функцию у нас есть икса звездочка локальный минивум
[01:02:35.600 --> 01:02:43.280]  пусть существует некоторые игрекса звездочки глобальный минивум давайте там тоже
[01:02:43.280 --> 01:03:00.040]  вот он во-первых глобальный а во-вторых и соответствует значение в нём строгом меньше
[01:03:00.040 --> 01:03:06.200]  чем значение в атыкса звездочек это наше предположение которое сейчас будем искать противоречие
[01:03:06.200 --> 01:03:12.840]  вот что значит локальный минимум это значит что есть окрестность
[01:03:14.840 --> 01:03:22.280]  которые значение f от икса звездочка меньше либо равно f от икс для всех икс
[01:03:23.960 --> 01:03:32.320]  ну таких что икс минус икс со звездочкой меньше там некоторого дельта это поминаю определение
[01:03:32.320 --> 01:03:38.280]  мы его достаточно быстро прошли пролистали когда об этом шла речь я надеюсь что здесь
[01:03:38.280 --> 01:03:46.560]  все понятно насколько я прав то есть пока просто какие-то базовые вещи записываем
[01:03:46.560 --> 01:03:54.800]  можно ли продолжать ставьте плюсики если можно продолжать так раз два три четыре
[01:03:54.800 --> 01:04:01.000]  три человек за то чтобы продолжать а вот тот кто-то еще потягивается прекрасно спасибо
[01:04:01.000 --> 01:04:12.200]  ну то есть дальше смотрите какой тюк берем точку z которая будет записываться как альфа на y со
[01:04:12.200 --> 01:04:21.200]  звездочкой плюс один минус алифа на икс достаточно мало и так чтобы было выполнено что гадаете что
[01:04:21.200 --> 01:04:30.000]  что z минус икс со звездочкой меньше либо равно то есть ну существует же у нас некоторая окрестность
[01:04:30.000 --> 01:04:38.240]  да вот ну и дальше мы берем и подставляем ну точно что это нам дает нам дает что f от икса звездочкой
[01:04:38.240 --> 01:04:44.720]  меньше либо равно f от z потому что z лежит в правильной окрестности а это в свою очередь
[01:04:44.720 --> 01:04:50.960]  поскольку z у нас выпуклая комбинация точек дает нам что это альфа f от икса звездочкой плюс
[01:04:50.960 --> 01:04:58.120]  один минус альфа f от икса но мы знаем что у нас есть вот это предположение которое будет нам
[01:04:58.120 --> 01:05:07.760]  говорить о том что это строго меньше вот важно чем альфа f от икса звездочки плюс один минус альфа
[01:05:07.760 --> 01:05:14.080]  f от икса звездочка что в точности f от икса звездочка и внимание мы получили гениальный противоречи
[01:05:14.080 --> 01:05:17.480]  что вот эта штука меньше чем вот эта штука
[01:05:17.480 --> 01:05:33.760]  все ли увидели это противоречие пожалуйста поставьте плюс если вы его увидели так ok 1 2 3 4 5 6 7 8 так
[01:05:33.760 --> 01:05:42.400]  ну вот 8 человек увидел это половина интересно что происходит со всеми остальными ох ладно ну то есть
[01:05:42.400 --> 01:05:52.880]  получить противоречия из которого следует из которого следует что ну собственно глобальный
[01:05:53.880 --> 01:06:11.640]  вот для выпуклой функции то есть теорема достаточно инструментально в том плане что она
[01:06:11.640 --> 01:06:17.400]  дает рецепт и как бы явно указывать место где нужна выпуклость функции то есть как бы вот
[01:06:18.400 --> 01:06:24.020]  вот у вас есть блестящее следствие которое вам дает как бы локальный эквивалент из
[01:06:24.020 --> 01:06:30.440]  локальности глобальности так ну тогда наверное на сегодня все смотрите что у нас будет в этот
[01:06:30.440 --> 01:06:37.040]  раз сразу я авансирую чтобы вы примерно понимали куда мы движемся вот следующий раз я подробнее
[01:06:37.040 --> 01:06:43.160]  расскажу вот этот слайд про композиции он очень важный в дальнейшем нам будет много раз нужен вот
[01:06:43.160 --> 01:06:49.720]  и расскажу про сложную выпуклую задачу и простую не выпуклую задачу вот очень надо здесь кажется
[01:06:49.720 --> 01:06:56.160]  все а потом будет не россиянцы но это мелочи тут как бы достаточно простой выгодку по инукции вот
[01:06:56.160 --> 01:07:02.400]  и потом мы собственно перейдем по спалкам задачи по оптимизации как и они бывают какие конусы
[01:07:02.400 --> 01:07:09.920]  при этом задействуются и что с этим всем можно делать как преобразовывать так наверное по материалу
[01:07:09.920 --> 01:07:18.320]  на сегодня все если есть какие-то вопросы давайте минутку я готов дождать если они появятся потом
[01:07:18.320 --> 01:07:26.560]  пожалуйста пишите вот я постараюсь на них оперативно ответить вот в общем-то запись я выложу
[01:07:26.560 --> 01:07:33.360]  на google диск скорее всего вот и ссылочка на папку с записями будет также в чате в ближайшее время
