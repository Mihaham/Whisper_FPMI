[00:00.000 --> 00:13.000]  У нас с вами до этого на лекции был только map-reduce, и закончили мы на лекциях тем, что join in map-reduce это сильная боль.
[00:13.000 --> 00:19.000]  Кто может вспомнить основную причину, почему join in map-reduce делать тяжело?
[00:19.000 --> 00:34.000]  Из тех, кто был на прошлой лекции, я вижу, что здесь много людей, которые были.
[00:34.000 --> 00:38.000]  Кто может вспомнить, почему join in map-reduce делать сложно?
[00:38.000 --> 00:51.000]  Потому что у нас разные форматы на вход придут, надо как-то с этим бороться.
[00:51.000 --> 01:01.000]  Да, то есть с одной стороны на map-reduce у нас есть mapper и user, то есть код, который обрабатывает все данные, которые пришли ему на вход.
[01:01.000 --> 01:05.000]  А с другой стороны, есть два датасета, у которых разные структуры.
[01:05.000 --> 01:15.000]  И надо как-то обрабатывать их одним и тем же кодом, и при этом не потерять данные о том, откуда пришли строки с первого или второго датасета.
[01:15.000 --> 01:28.000]  В общем, сложно, поэтому это подтолкнуло сообщество к созданию нескольких движков, которые работают с SQL.
[01:28.000 --> 01:37.000]  Можно посмотреть, что не только join вложится на map-reduce, а весь SQL можно переложить на map-reduce.
[01:41.000 --> 01:51.000]  Давайте посмотрим на вот эти ключевые слова SQL, и подумаем, как можно переложить на map-reduce каждый из них.
[01:51.000 --> 01:59.000]  Где будет только mapper, где будет только reducer или полная map-reduce джуба?
[01:59.000 --> 02:06.000]  Давайте подумаем, select – это что в терминах map-reduce?
[02:06.000 --> 02:09.000]  Map.
[02:09.000 --> 02:17.000]  Map, да, потому что мы просто выделяем нужные столбцы, то есть нет зависимости между строками.
[02:17.000 --> 02:20.000]  Where?
[02:20.000 --> 02:22.000]  Map.
[02:22.000 --> 02:25.000]  Тоже map, хорошо, а дальше?
[02:30.000 --> 02:35.000]  Order by, sort by – это что процесс shuffling, sorting?
[02:35.000 --> 02:43.000]  Ну вот, shuffling sort – да, но если у нас глобальная сортировка order by, то нам нужен reducer.
[02:43.000 --> 02:52.000]  А sort by – это операция, которая делает сортировку внутри reducer, поэтому reducer тут тоже нужен.
[02:52.000 --> 02:55.000]  Ну а group by?
[02:56.000 --> 03:02.000]  Это непосредственно reducer, который у нас как ключи между собой группирует, как раз тесно его задача.
[03:02.000 --> 03:05.000]  Точнее, это происходит перед подачей на reducer.
[03:05.000 --> 03:08.000]  Да, это происходит тоже на shuffling sort.
[03:08.000 --> 03:19.000]  А дальше, в зависимости от того, какая у нас функция агрегации после group by, сумма средняя, там еще что-нибудь, то это может быть либо reducer, либо еще счетчик.
[03:19.000 --> 03:32.000]  Ну мы помним, что можно, если у нас, например, общая сумма, то есть, например, средняя или сумма по всему датасету, то мы можем счетчики использовать.
[03:36.000 --> 03:41.000]  Вот, ну join – мы помним, что это полноценный map-reduce, а вот having – это что?
[03:41.000 --> 03:52.000]  Having можно сделать на reducer, ну а можно сделать на следующем маппере, то есть, полноценный map-reduce с join или с group by.
[03:52.000 --> 03:57.000]  И потом еще один мап, на котором будет что-то вроде where.
[03:57.000 --> 04:00.000]  Да, все правильно, так и есть.
[04:01.000 --> 04:08.000]  И вот то, что у нас SQL превращается в map-reduce, это привело к созданию нескольких движков SQL.
[04:08.000 --> 04:17.000]  Сегодня мы посмотрим на Hive и работать будем в основном с Hive, но обзорно обсудим и остальные движки, которые у нас сейчас популярны.
[04:17.000 --> 04:23.000]  Вот, в 2007 году Facebook появился Hive. Сразу следует понимать, что Hive – это не СУБД.
[04:23.000 --> 04:36.000]  Вот на собеседованиях часто спрашивают, почему, потому что, по сути, здесь нет никаких требований к нормализации, то есть, просто обертка.
[04:36.000 --> 04:48.000]  Под кодом у нас вычисления на том же map-reduce, хранение данных в том же HDFS, то есть, мы делаем тот же map-reduce код, только оборачиваем SQL.
[04:48.000 --> 04:57.000]  Вот, ну и появляется одна проблема, что map-reduce мог работать с любыми данными, то есть, какие-то строки на вход приходят.
[04:57.000 --> 05:05.000]  Мы их как-то парсим, получаем пары ключи значения, и больше нам ничего не надо. А SQL – это значит таблицы, то есть, нужна структура данных.
[05:05.000 --> 05:12.000]  Вот, то есть, нужна какая-то схема данных, которую мы как-то зададим, и Hive это увидит.
[05:12.000 --> 05:20.000]  Это такая возможность есть, я вам ее тоже покажу, как задавать схему данных.
[05:20.000 --> 05:25.000]  Но основная особенность Hive в отличие от обычных релиза...
[05:25.000 --> 05:28.000]  ...релиза...
[05:28.000 --> 05:30.000]  ...релиза...
[05:30.000 --> 05:32.000]  ...релиза...
[05:32.000 --> 05:34.000]  ...релиза...
[05:34.000 --> 05:36.000]  ...релиза...
[05:36.000 --> 05:38.000]  ...релиза...
[05:38.000 --> 05:40.000]  ...релиза...
[05:40.000 --> 05:42.000]  ...релиза...
[05:42.000 --> 05:44.000]  ...релиза...
[05:44.000 --> 05:46.000]  ...релиза...
[05:46.000 --> 05:48.000]  ...релиза...
[05:48.000 --> 05:50.000]  ...релиза...
[05:50.000 --> 05:52.000]  ...релиза...
[05:52.000 --> 05:54.000]  ...релиза...
[05:54.000 --> 05:56.000]  ...релиза...
[05:56.000 --> 05:58.000]  ...релиза...
[05:58.000 --> 06:00.000]  ...релиза...
[06:00.000 --> 06:02.000]  ...релиза...
[06:02.000 --> 06:04.000]  ...релиза...
[06:04.000 --> 06:06.000]  ...релиза...
[06:06.000 --> 06:08.000]  ...релиза...
[06:08.000 --> 06:10.000]  ...релиза...
[06:10.000 --> 06:12.000]  ...релиза...
[06:12.000 --> 06:14.000]  ...релиза...
[06:14.000 --> 06:16.000]  ...релиза...
[06:16.000 --> 06:18.000]  ...релиза...
[06:18.000 --> 06:20.000]  ...релиза...
[06:20.000 --> 06:22.000]  ...релиза...
[06:22.000 --> 06:24.000]  ...релиза...
[06:24.000 --> 06:26.000]  ...релиза...
[06:26.000 --> 06:28.000]  ...релиза...
[06:28.000 --> 06:30.000]  ...релиза...
[06:30.000 --> 06:32.000]  ...релиза...
[06:32.000 --> 06:34.000]  ...релиз...
[06:34.000 --> 06:36.000]  ...релиза...
[06:36.000 --> 06:38.000]  ...релиза...
[06:38.000 --> 06:40.000]  ...релиза...
[06:40.000 --> 06:42.000]  ...релиза...
[06:42.000 --> 06:44.000]  ...релиза...
[06:44.000 --> 06:46.000]  ...релиза...
[06:46.000 --> 06:48.000]  ...релиза...
[06:48.000 --> 06:50.000]  ...релиза...
[06:50.000 --> 06:52.000]  ...релиза...
[06:52.000 --> 06:54.000]  ...релиза...
[06:54.000 --> 06:56.000]  ...релиза...
[06:56.000 --> 06:58.000]  ...релиза...
[06:58.000 --> 07:00.000]  ...релиза...
[07:00.000 --> 07:02.000]  ...релиза...
[07:02.000 --> 07:04.000]  ...релиза...
[07:04.000 --> 07:06.000]  ...релиза...
[07:06.000 --> 07:08.000]  ...релиза...
[07:08.000 --> 07:10.000]  ...релиза...
[07:10.000 --> 07:12.000]  ...релиза...
[07:12.000 --> 07:14.000]  ...релиза...
[07:14.000 --> 07:16.000]  ...релиза...
[07:16.000 --> 07:18.000]  ...релиза...
[07:18.000 --> 07:20.000]  ...релиза...
[07:20.000 --> 07:22.000]  ...релиза...
[07:22.000 --> 07:24.000]  ...релиза...
[07:24.000 --> 07:26.000]  ...релиза...
[07:26.000 --> 07:28.000]  ...релиза...
[07:28.000 --> 07:30.000]  ...релиз...
[07:30.000 --> 07:32.000]  ...релиза...
[07:32.000 --> 07:34.000]  ...релиза...
[07:34.000 --> 07:36.000]  ...релиза...
[07:36.000 --> 07:38.000]  ...релиза...
[07:38.000 --> 07:40.000]  ...релиза...
[07:40.000 --> 07:42.000]  ...релиза...
[07:42.000 --> 07:44.000]  ...релиза...
[07:44.000 --> 07:46.000]  ...релиза...
[07:46.000 --> 07:48.000]  ...релиза...
[07:48.000 --> 07:50.000]  ...релиза...
[07:50.000 --> 07:52.000]  ...релиза...
[07:52.000 --> 07:54.000]  ...релиза...
[07:54.000 --> 07:56.000]  ...релиза...
[07:56.000 --> 07:58.000]  ...релиз...
[07:58.000 --> 08:00.000]  ...релиза...
[08:00.000 --> 08:02.000]  ...релиза...
[08:02.000 --> 08:04.000]  ...релиза...
[08:04.000 --> 08:06.000]  ...релиза...
[08:06.000 --> 08:08.000]  ...релиза...
[08:08.000 --> 08:10.000]  ...релиза...
[08:10.000 --> 08:12.000]  ...релиза...
[08:12.000 --> 08:14.000]  ...релиза...
[08:14.000 --> 08:16.000]  ...релиза...
[08:16.000 --> 08:18.000]  ...релиза...
[08:18.000 --> 08:20.000]  ...релиза...
[08:20.000 --> 08:22.000]  ...релиза...
[08:22.000 --> 08:24.000]  ...релиза...
[08:24.000 --> 08:26.000]  ...релиза...
[08:26.000 --> 08:28.000]  ...релиза...
[08:28.000 --> 08:30.000]  ...релиза...
[08:30.000 --> 08:32.000]  ...релиза...
[08:32.000 --> 08:34.000]  ...релиза...
[08:34.000 --> 08:36.000]  ...релиза...
[08:36.000 --> 08:38.000]  ...релиза...
[08:38.000 --> 08:40.000]  ...релиза...
[08:40.000 --> 08:42.000]  ...релиза...
[08:42.000 --> 08:44.000]  ...релиза...
[08:44.000 --> 08:46.000]  ...релиза...
[08:46.000 --> 08:48.000]  ...релиза...
[08:48.000 --> 08:50.000]  ...релиза...
[08:50.000 --> 08:52.000]  ...релиза...
[08:52.000 --> 08:54.000]  ...релиз...
[08:54.000 --> 08:56.000]  ...релиза...
[08:56.000 --> 08:58.000]  ...релиза...
[08:58.000 --> 09:00.000]  ...релиза...
[09:00.000 --> 09:02.000]  ...релиза...
[09:02.000 --> 09:04.000]  ...релиза...
[09:04.000 --> 09:06.000]  ...релиза...
[09:06.000 --> 09:08.000]  ...релиза...
[09:08.000 --> 09:10.000]  ...релиза...
[09:10.000 --> 09:12.000]  ...релиза...
[09:12.000 --> 09:14.000]  ...релиза...
[09:14.000 --> 09:16.000]  ...релиза...
[09:16.000 --> 09:18.000]  ...релиза...
[09:18.000 --> 09:20.000]  ...релиза...
[09:20.000 --> 09:22.000]  ...релиза...
[09:22.000 --> 09:24.000]  ...релиза...
[09:24.000 --> 09:26.000]  ...релиза...
[09:26.000 --> 09:28.000]  ...релиза...
[09:28.000 --> 09:30.000]  ...релиза...
[09:30.000 --> 09:32.000]  ...релиза...
[09:32.000 --> 09:34.000]  ...релиза...
[09:34.000 --> 09:36.000]  ...релиза...
[09:36.000 --> 09:38.000]  ...релиза...
[09:38.000 --> 09:40.000]  ...релиза...
[09:40.000 --> 09:42.000]  ...релиза...
[09:42.000 --> 09:44.000]  ...релиза...
[09:44.000 --> 09:46.000]  ...релиза...
[09:46.000 --> 09:48.000]  ...релиза...
[09:48.000 --> 09:50.000]  ...релиза...
[09:50.000 --> 09:52.000]  ...релиза...
[09:52.000 --> 09:54.000]  ...релиза...
[09:54.000 --> 09:56.000]  ...релиза...
[09:56.000 --> 09:58.000]  ...релиза...
[09:58.000 --> 10:00.000]  ...релиза...
[10:00.000 --> 10:02.000]  ...релиза...
[10:02.000 --> 10:04.000]  ...релиза...
[10:04.000 --> 10:06.000]  ...релиза...
[10:06.000 --> 10:08.000]  ...релиза...
[10:08.000 --> 10:10.000]  ...релиза...
[10:10.000 --> 10:12.000]  ...релиза...
[10:12.000 --> 10:17.800]  во время выполнения кода ParseException и все упадет.
[10:17.800 --> 10:20.800]  Дальше симматический анализ.
[10:20.800 --> 10:21.800]  Что это такое?
[10:21.800 --> 10:28.240]  Это, как здесь сказано, разыменование звездочек.
[10:28.240 --> 10:34.080]  Кто вообще помнит с SQL, что такое звездочка, что она
[10:34.080 --> 10:35.080]  означает?
[10:35.080 --> 10:36.080]  Все столбцы.
[10:36.080 --> 10:41.160]  Да, все столбцы, и Hive именно превращает звездочку в перечисление
[10:41.160 --> 10:42.160]  всех столбцов.
[10:42.160 --> 10:46.160]  Это тоже важно понимать, потому что запросы типа
[10:46.160 --> 10:53.160]  «посчитай количество строк», их можно сделать как каунд-звездочка,
[10:53.160 --> 10:56.160]  а можно сделать как каунд по какому-то полю.
[10:56.160 --> 11:00.160]  Вот лучше делать каунд по какому-то полю, и в домашних
[11:00.160 --> 11:03.160]  мы прямо будем это явно указывать, если вы будете делать
[11:03.160 --> 11:06.160]  каунд-звездочка, потому что каунд-звездочка работает
[11:06.160 --> 11:07.160]  дольше.
[11:08.160 --> 11:11.160]  Во-первых, ему надо звездочку эту превратить в список
[11:11.160 --> 11:14.160]  полей, а во-вторых, прочитать весь этот список полей,
[11:14.160 --> 11:18.160]  что долго, если у нас особенно формат данных какой-нибудь
[11:18.160 --> 11:19.160]  колоночный.
[11:19.160 --> 11:23.160]  То есть со строковым форматом данных проще, мы все равно
[11:23.160 --> 11:26.160]  считаем всю строку, а вот с колоночным нам придется
[11:26.160 --> 11:30.160]  считывать все колонки просто, чтобы посчитать каунд-звездочку.
[11:30.160 --> 11:34.160]  Да, еще проверка типов данных.
[11:34.160 --> 11:39.160]  Да, в хайве есть типы данных.
[11:39.160 --> 11:46.160]  И, например, если мы сравниваем интеджер и биг-интеджер,
[11:46.160 --> 11:49.160]  то все конвертнется неявно в биг-интеджер.
[11:57.160 --> 12:02.160]  Дальше у нас идет построение логического плана запроса.
[12:02.160 --> 12:07.160]  И здесь происходят некоторые оптимизации.
[12:07.160 --> 12:11.160]  То есть, например, хайв автоматически умеет видеть,
[12:11.160 --> 12:16.160]  что если у нас датасет маленький, то можно его поместить
[12:16.160 --> 12:19.160]  в distributed cache, и у нас будет map-джойн.
[12:25.160 --> 12:28.160]  Дальше объединить два джойна в map-редью задачу.
[12:29.160 --> 12:33.160]  Чтобы было понятнее, давайте я открою предыдущую презентажку.
[12:37.160 --> 12:40.160]  И мы посмотрим, как можно объединить два джойна.
[12:44.160 --> 12:45.160]  Вот давайте посмотрим.
[12:45.160 --> 12:49.160]  Если у нас на этой схеме появилась еще зеленая табличка C, например,
[12:49.160 --> 12:56.160]  то давайте подумаем, есть ли какие-нибудь проблемы с тем,
[12:56.160 --> 13:00.160]  чтобы это сделать точно так же за одну джобу, или это легко сделать.
[13:11.160 --> 13:15.160]  И еще раз, можно вопрос, что за зеленая табличка, если появилась?
[13:15.160 --> 13:17.160]  Ну, у нас появилась зеленая табличка,
[13:17.160 --> 13:20.160]  и мы хотим сделать джойн теперь от трех таблиц,
[13:20.160 --> 13:23.160]  то есть A, innerJoinB, innerJoinC.
[13:24.160 --> 13:28.160]  Будут ли какие-то проблемы, и нужна ли нам вторая джоба здесь?
[13:30.160 --> 13:34.160]  То есть, по умолчанию, если мы пишем в хайве A, joinB, joinC,
[13:34.160 --> 13:39.160]  он это видит как две независимые джобы, то есть A, joinB до одна джоба,
[13:39.160 --> 13:43.160]  потом все вместе, joinC. Можно ли это как-то оптимизировать?
[13:47.160 --> 14:06.160]  Ну, давайте посмотрим на эту схему еще раз.
[14:06.160 --> 14:11.160]  Что у нас, по сути, здесь делается в джойне?
[14:11.160 --> 14:20.160]  На маты мы добавляем теги. На редьюсере все данные с одним ключом приходят на один редьюсер.
[14:20.160 --> 14:28.160]  Что нам мешает сделать здесь еще C? У нас просто будет три тега A, B и C.
[14:28.160 --> 14:36.160]  Но потом мы будем точно также сортировать по ключам, то есть по ключу, который есть и в таблице A, и в таблице B, и в таблице C.
[14:36.160 --> 14:44.160]  То есть смотрите, если у нас во всех этих трех джойнах ключ один и тот же.
[14:44.160 --> 15:09.160]  Можете, пожалуйста, напомнить, немножко вылетело из понимания, как мы, Джон, делаем, когда у нас каждый ключ в разных датасетах, видимо, как на этой ситуации.
[15:09.160 --> 15:17.160]  То есть там ключ UserID есть и в датасете A, и в датасете B, и в датасете C, да, вот как-то так.
[15:17.160 --> 15:19.160]  Ну да, да, вроде так, да.
[15:19.160 --> 15:29.160]  Ну мы на мапере добавляем тег, то есть мапер же знает, откуда пришли данные, он это может определить как-нибудь по структуре.
[15:29.160 --> 15:38.160]  Ну и вообще есть специальная возможность опика, когда можно указать, откуда пришли данные.
[15:38.160 --> 15:52.160]  В общем, мы добавляем на мапере тег, мы потом лупируем по ключу, и у нас на reuse приходит вот такого типа пары.
[15:52.160 --> 15:56.160]  Сейчас откроем.
[15:56.160 --> 16:15.160]  У нас приходят пары типа k, а здесь тег и какие-нибудь еще значения.
[16:15.160 --> 16:19.160]  Вот, ну и тег может быть и датасета A, и датасета B, и датасета C.
[16:19.160 --> 16:29.160]  Все равно все пары с одинаковым ключом по определению мапредьюса, они придут на один редьюсер, и мы сможем здесь их поджоинить.
[16:29.160 --> 16:37.160]  То есть неважно, сколько у нас датасетов, если у нас идет джоин по одному и тому же ключу, то мы можем сделать это за одну джогу.
[16:37.160 --> 16:42.160]  Если ключи разные, то за несколько.
[16:42.160 --> 16:50.160]  Сейчас стало понятнее, как можно оптимизировать?
[16:50.160 --> 16:57.160]  У нас же в джоине мы джоиним две таблички по какому-то ключу.
[16:57.160 --> 16:58.160]  Да.
[16:58.160 --> 17:09.160]  И получается, что когда к нам на редьюсер придут один ключ на какой-то редьюсер придет с разным набором тегов,
[17:09.160 --> 17:10.160]  Да.
[17:10.160 --> 17:21.160]  то мы сможем как бы в этот момент между несколькими датасетами сопоставить эти ключи и сделать одну строчку у них, да?
[17:21.160 --> 17:24.160]  Да, конечно, конечно.
[17:24.160 --> 17:27.160]  А, окей.
[17:27.160 --> 17:50.160]  Не важно, сколько датасетов, но мы же гарантируем, что все пары с k равно k, они придут на один редьюсер.
[17:50.160 --> 18:02.160]  Ну и дальше, последняя стадия, с помощью которой мы превращаем sql в редьюс-код, это
[18:02.160 --> 18:11.160]  построение физического плана запроса.
[18:11.160 --> 18:20.160]  То есть вот как бы мы сформировали логический план, а теперь учитываем, где лежат данные, как они у нас разбросаны по блокам,
[18:20.160 --> 18:24.160]  учитываем есть ли партийцы, и про партийцы я расскажу еще отдельно.
[18:24.160 --> 18:31.160]  И на основе этого уже строим тот код, который будет выполняться вот этим вот execution engine.
[18:42.160 --> 18:47.160]  Ну и давайте посмотрим, например, плана запроса.
[18:47.160 --> 18:52.160]  Вот такие вот штуки строит Hive перед тем, как выполнять запрос.
[18:52.160 --> 18:55.160]  Что мы тут видим?
[18:55.160 --> 19:00.160]  Во-первых, мы видим, что у нас несколько jog есть.
[19:00.160 --> 19:06.160]  Во-вторых, мы видим, что у нас вот на stage 1 есть
[19:06.160 --> 19:11.160]  маппер, мы тут видим, мап, оператор 3.
[19:11.160 --> 19:16.160]  На маппере происходит table scan, то есть мы делаем какой-то селект.
[19:16.160 --> 19:27.160]  Есть predicate, то есть мы делаем какое-то where, сравнение чего-то с пятью миллионами, там стэмпа какого-то.
[19:27.160 --> 19:33.160]  Вот дальше у нас есть шахмансорт, то есть тот аутпут, который подается на редьюсер,
[19:33.160 --> 19:40.160]  и у нас указывается, как происходит сортировка.
[19:40.160 --> 19:51.160]  Опять есть слово partition columns, мы к нему вернемся.
[19:51.160 --> 19:53.160]  Указано, в каком порядке мы сортируем.
[19:53.160 --> 19:58.160]  Дальше идет редьюсер, на редьюсере мы видим join, left outer join,
[19:58.160 --> 20:01.160]  по каким ключам у нас join, вот все это мы видим.
[20:01.160 --> 20:07.160]  То есть вот так у нас сконвертится SQL код map-reduce.
[20:07.160 --> 20:18.160]  Можно вопрос? Вот эти reduce-output-операторы внутри мап-операторов, это что значит?
[20:18.160 --> 20:21.160]  То есть мы же еще не приступили к reduce?
[20:21.160 --> 20:27.160]  Да, это аутпут, то есть тот аутпут, который нам сгенерил маппер.
[20:27.160 --> 20:33.160]  По сути это шахмансорт, такое не совсем очевидное название,
[20:33.160 --> 20:39.160]  но если посмотреть на то, что у нас происходит, тут написано sort outer,
[20:39.160 --> 20:43.160]  поэтому это вот стадия шахмансорт.
[20:43.160 --> 20:46.160]  Окей, спасибо.
[20:52.160 --> 20:56.160]  Ну и какие таблицы есть еще в хайве.
[20:56.160 --> 20:59.160]  Дело в том, что в хайве у нас есть отдельно данные,
[20:59.160 --> 21:04.160]  а отдельно вот этот самый метастор, который хранит информацию про то,
[21:04.160 --> 21:08.160]  какая таблица, кем создана, когда создана, какая схема.
[21:08.160 --> 21:13.160]  И вот в зависимости от того, как у нас хайв влияет на данные,
[21:13.160 --> 21:15.160]  можно разделить два типа таблиц.
[21:15.160 --> 21:20.160]  External это значит, что мы просто задаем путь к данным,
[21:20.160 --> 21:24.160]  эти данные лежат в HDFS, и хайв с ними ничего не может сделать,
[21:24.160 --> 21:26.160]  то есть это такое вот ридонли.
[21:26.160 --> 21:31.160]  Мы можем делать всякие селекты, но мы не можем эти данные изменять,
[21:31.160 --> 21:33.160]  и мы не можем их удалить.
[21:33.160 --> 21:37.160]  Вот это то, что вы будете делать в домашке, то есть у вас будет везде,
[21:37.160 --> 21:40.160]  кроме одной задачи, будет external таблица,
[21:40.160 --> 21:43.160]  где вам нужно будет просто писать селекты,
[21:43.160 --> 21:49.160]  так как у нас у всех один и тот же датасет, то вы его не сможете изменять.
[21:49.160 --> 21:53.160]  И managed это как раз наоборот, когда мы явно указываем,
[21:53.160 --> 21:56.160]  что вот наши данные, и мы их можем изменять.
[21:56.160 --> 22:02.160]  То есть мы можем делать инсерты, всякие альтер тейбл и так далее.
[22:02.160 --> 22:08.160]  Ну и по времени жизни у нас может быть база данных временная и постоянная,
[22:08.160 --> 22:10.160]  тут как бы логично.
[22:17.160 --> 22:20.160]  Хорошо, теперь давайте посмотрим на пример.
[22:23.160 --> 22:26.160]  Вот у нас есть такие данные.
[22:26.160 --> 22:31.160]  Давайте даже посмотрим на класты.
[22:48.160 --> 22:51.160]  Ну вот есть маленький датасет, есть большой.
[22:51.160 --> 22:56.160]  И в общем, как эти данные выглядят вообще? Давайте посмотрим.
[23:13.160 --> 23:18.160]  Вот у нас есть два поля, ip-шник и маска под сети, в которой этот ip-шник относится.
[23:19.160 --> 23:21.160]  Вот такая простенькая табличка.
[23:21.160 --> 23:25.160]  И от нас требуется посчитать среднее количество адресов по маскам под сети.
[23:25.160 --> 23:30.160]  То есть условно, сколько у нас в каждой сети адресов.
[23:42.160 --> 23:44.160]  То есть что нам нужно сделать?
[23:44.160 --> 23:48.160]  Пока у нас есть только данные в HDFS и больше ничего,
[23:48.160 --> 23:51.160]  никакой код на Hive мы писать не можем.
[23:51.160 --> 23:54.160]  Нам нужно сначала создать базу данных.
[23:54.160 --> 23:57.160]  И давайте посмотрим, как это делается.
[24:03.160 --> 24:06.160]  То есть мы создаем вот такую вот базу.
[24:07.160 --> 24:11.160]  Давайте я сразу буду показывать, как это делать в Hive.
[24:14.160 --> 24:19.160]  Сейчас я создам папку для нашего курса, потому что здесь таких файлов еще нет.
[24:44.160 --> 24:48.160]  Я на семинарах более подробно покажу, как можно работать с Hive.
[24:48.160 --> 24:51.160]  Но сейчас мы просто будем делать так.
[24:51.160 --> 24:54.160]  Мы создадим файл со скейл-запросом.
[24:54.160 --> 24:58.160]  И его будем выполнять, смотреть на планы запроса.
[24:58.160 --> 25:02.160]  Сначала мы создаем базу данных.
[25:02.160 --> 25:05.160]  И мы будем создавать файл с скейл-запросом.
[25:05.160 --> 25:09.160]  И мы будем его выполнять, смотреть на планы запроса.
[25:09.160 --> 25:12.160]  Сначала мы создаем базу данных.
[25:17.160 --> 25:21.160]  Тут у меня название базы данных, оно может быть любое.
[25:22.160 --> 25:24.160]  Например, вот так.
[25:27.160 --> 25:32.160]  Здесь пишется полный путь к мета-стору, где у нас будет все метаданные храниться.
[25:33.160 --> 25:36.160]  Ну и вот так давайте его назовем.
[25:40.160 --> 25:43.160]  И все, вот у нас есть код.
[25:43.160 --> 25:47.160]  Создание базы данных, location для мета-стор.
[25:47.160 --> 25:50.160]  Выполним мы его вот так.
[25:56.160 --> 25:58.160]  Все, база данных создалась.
[25:58.160 --> 26:03.160]  Это легко проверить с помощью такой команды.
[26:03.160 --> 26:13.160]  ShowDatabases и GrabAllActual.
[26:19.160 --> 26:21.160]  Вот она у нас есть.
[26:23.160 --> 26:26.160]  Все, следующий этап это создание таблицы.
[26:26.160 --> 26:29.160]  Базу мы создали, теперь таблицу.
[26:30.160 --> 26:34.160]  Поблизу мы создаем external, чтобы мы не могли менять данные.
[26:36.160 --> 26:38.160]  И вот что у нас тут есть.
[26:38.160 --> 26:41.160]  У нас есть два поля, как мы и говорили.
[26:41.160 --> 26:48.160]  Дальше ключевые числа raw format delimited fields terminated by temp.
[26:48.160 --> 26:54.160]  Это как раз такой простой случай, когда у нас просто есть колонки, разделенные табами.
[26:54.160 --> 26:57.160]  Ну или каким-то другим разделителем, например, csv.
[26:57.160 --> 27:01.160]  На семинарах мы будем смотреть на более сложные случаи.
[27:01.160 --> 27:09.160]  Как задавать таблицу, если у нас есть какая-то помойка с данными, то есть формат непонятный.
[27:09.160 --> 27:15.160]  Где-то есть табы, где-то пробелы, как на это все накатывать регулярки, чтобы это все парсить на лету.
[27:17.160 --> 27:22.160]  Как хранить данные, если они, например, лежат в формате JSON, как JSON распознавать.
[27:22.160 --> 27:27.160]  Ну пока самый простой случай, когда у нас данные, в принципе, уже готовы к работе с хаймом.
[27:32.160 --> 27:38.160]  А external, это получается, можно вставлять строки, но они как бы immutable.
[27:41.160 --> 27:43.160]  Или даже в строки нельзя вставлять?
[27:43.160 --> 27:47.160]  В строки вставлять нельзя, то есть изменять данные нельзя.
[27:48.160 --> 27:52.160]  То есть таблица формируется только один раз, получается, да?
[28:09.160 --> 28:11.160]  Что у нас здесь остается?
[28:11.160 --> 28:14.160]  Указываем нашу базу.
[28:14.160 --> 28:23.160]  Дальше удаляем таблицу, если она уже есть, и создаем новую таблицу, в которой указываем, как мы парсим формат данных
[28:23.160 --> 28:26.160]  с torr.txt-файл и где эти данные лежат.
[28:26.160 --> 28:30.160]  Напомню, здесь у нас 7 гигов данных, то есть не очень мало.
[28:30.160 --> 28:35.160]  И должен этот код, в принципе, работать не очень быстро, но мы сейчас увидим, что будет.
[28:35.160 --> 28:39.160]  Что-то он тут не отработал, вместо этого запустилась оболочка хайма.
[28:47.160 --> 28:49.160]  А, вот это вот.
[28:49.160 --> 28:51.160]  А, вот это вот.
[28:51.160 --> 28:53.160]  А, вот это вот.
[28:53.160 --> 28:55.160]  А, вот это вот.
[28:55.160 --> 28:57.160]  А, вот это вот.
[28:57.160 --> 28:59.160]  А, я забыл минусы.
[29:09.160 --> 29:11.160]  Все, создалось быстро.
[29:11.160 --> 29:16.160]  Давайте вспомним из начала лекции, почему вот этот код так быстро отрабатывает.
[29:16.160 --> 29:18.160]  Он же должен таблицу создать.
[29:18.160 --> 29:22.160]  Все-таки 7 гигов это не 7 килобайтов, их надо по процессу.
[29:22.160 --> 29:24.160]  Может он не создает?
[29:24.160 --> 29:26.160]  Не создает таблицу?
[29:26.160 --> 29:28.160]  В смысле, он не парсит данные.
[29:28.160 --> 29:30.160]  А почему?
[29:30.160 --> 29:37.160]  Он запоминает, что вот есть такая таблица, и когда уже операции будут, он еще раз парсит.
[29:37.160 --> 29:39.160]  Да, именно потому что схема onRead.
[29:39.160 --> 29:41.160]  То есть схему задали.
[29:41.160 --> 29:44.160]  Мы, честно, задали, положили в Metastore.
[29:44.160 --> 29:46.160]  Вот такую схему данных.
[29:46.160 --> 29:48.160]  Но данные мы не проверяли.
[29:48.160 --> 29:52.160]  Вдруг там вообще нет двух полей, а есть непонятно что.
[29:56.160 --> 29:58.160]  Ну и теперь небольшое задание для вас.
[29:58.160 --> 30:02.160]  Вот еще раз условия задачи.
[30:05.160 --> 30:07.160]  Попробуйте написать вот этот код.
[30:07.160 --> 30:09.160]  Попробуйте написать вот этот код.
[30:09.160 --> 30:11.160]  Попробуйте написать вот этот код.
[30:12.160 --> 30:14.160]  Попробуйте написать вот этот код.
[30:16.160 --> 30:18.160]  На обычном SQL.
[30:18.160 --> 30:21.160]  Тут Hive ничем не отличается от обычного SQL.
[30:21.160 --> 30:23.160]  Просто для того, чтобы вспомнить.
[30:33.160 --> 30:36.160]  У всех есть возможность зайти из компана кластера.
[30:41.160 --> 30:43.160]  У всех есть возможность зайти из компана кластера.
[30:43.160 --> 30:45.160]  У всех есть возможность зайти из компана кластера.
[30:45.160 --> 30:47.160]  У всех есть возможность зайти из компана кластера.
[30:47.160 --> 30:49.160]  У всех есть возможность зайти из компана кластера.
[30:49.160 --> 30:51.160]  У всех есть возможность зайти из компана кластера.
[30:51.160 --> 30:53.160]  У всех есть возможность зайти из компана кластера.
[30:53.160 --> 30:55.160]  У всех есть возможность зайти из компана кластера.
[30:55.160 --> 30:57.160]  У всех есть возможность зайти из компана кластера.
[30:57.160 --> 30:59.160]  У всех есть возможность зайти из компана кластера.
[30:59.160 --> 31:01.160]  У всех есть возможность зайти из компана кластера.
[31:01.160 --> 31:03.160]  У всех есть возможность зайти из компана кластера.
[31:03.160 --> 31:05.160]  У всех есть возможность зайти из компана кластера.
[31:05.160 --> 31:07.160]  У всех есть возможность зайти из компана кластера.
[31:07.160 --> 31:09.160]  У всех есть возможность зайти из компана кластера.
[31:09.160 --> 31:11.160]  У всех есть возможность зайти из компана кластера.
[31:11.160 --> 31:13.160]  У всех есть возможность зайти из компана кластера.
[31:13.160 --> 31:15.160]  У всех есть возможность зайти из компана кластера.
[31:15.160 --> 31:17.160]  У всех есть возможность зайти из компана кластера.
[31:17.160 --> 31:19.160]  У всех есть возможность зайти из компана кластера.
[31:19.160 --> 31:21.160]  У всех есть возможность зайти из компана кластера.
[31:21.160 --> 31:23.160]  У всех есть возможность зайти из компана кластера.
[31:23.160 --> 31:25.160]  У всех есть возможность зайти из компана кластера.
[31:25.160 --> 31:27.160]  У всех есть возможность зайти из компана кластера.
[31:27.160 --> 31:29.160]  У всех есть возможность зайти из компана кластера.
[31:29.160 --> 31:31.160]  У всех есть возможность зайти из компана кластера.
[31:31.160 --> 31:33.160]  У всех есть возможность зайти из компана кластера.
[31:33.160 --> 31:37.160]  У всех есть возможность зайти из компана кластера.
[31:37.160 --> 31:39.160]  У всех есть возможность зайти из компана кластера.
[31:39.160 --> 31:41.160]  У всех есть возможность зайти из компана кластера.
[31:41.160 --> 31:43.160]  У всех есть возможность зайти из компана кластера.
[31:43.160 --> 31:45.160]  У всех есть возможность зайти из компана кластера.
[31:45.160 --> 31:47.160]  У всех есть возможность зайти из компана кластера.
[31:47.160 --> 31:49.160]  У всех есть возможность зайти из компана кластера.
[31:49.160 --> 31:51.160]  У всех есть возможность зайти из компана кластера.
[31:51.160 --> 31:53.160]  У всех есть возможность зайти из компана кластера.
[31:53.160 --> 31:55.160]  У всех есть возможность зайти из компана кластера.
[31:55.160 --> 31:57.160]  У всех есть возможность зайти из компана кластера.
[31:57.160 --> 31:59.160]  У всех есть возможность зайти из компана кластера.
[31:59.160 --> 32:01.160]  У всех есть возможность зайти из компана кластера.
[32:01.160 --> 32:03.160]  У всех есть возможность зайти из компана кластера.
[32:03.160 --> 32:05.160]  У всех есть возможность зайти из компана кластера.
[32:05.160 --> 32:07.160]  У всех есть возможность зайти из компана кластера.
[32:07.160 --> 32:09.160]  У всех есть возможность зайти из компана кластера.
[32:09.160 --> 32:11.160]  У всех есть возможность зайти из компана кластера.
[32:11.160 --> 32:13.160]  У всех есть возможность зайти из компана кластера.
[32:13.160 --> 32:15.160]  У всех есть возможность зайти из компана кластера.
[32:15.160 --> 32:17.160]  У всех есть возможность зайти из компана кластера.
[32:17.160 --> 32:19.160]  У всех есть возможность зайти из компана кластера.
[32:19.160 --> 32:21.160]  У всех есть возможность зайти из компана кластера.
[32:21.160 --> 32:23.160]  У всех есть возможность зайти из компана кластера.
[32:23.160 --> 32:25.160]  У всех есть возможность зайти из компана кластера.
[32:25.160 --> 32:27.160]  У всех есть возможность зайти из компана кластера.
[32:27.160 --> 32:29.160]  У всех есть возможность зайти из компана кластера.
[32:29.160 --> 32:31.160]  У всех есть возможность зайти из компана кластера.
[32:31.160 --> 32:33.160]  У всех есть возможность зайти из компана кластера.
[32:33.160 --> 32:35.160]  У всех есть возможность зайти из компана кластера.
[32:35.160 --> 32:37.160]  У всех есть возможность зайти из компана кластера.
[32:37.160 --> 32:39.160]  У всех есть возможность зайти из компана кластера.
[32:39.160 --> 32:41.160]  У всех есть возможность зайти из компана кластера.
[32:41.160 --> 32:43.160]  У всех есть возможность зайти из компана кластера.
[32:43.160 --> 32:45.160]  У всех есть возможность зайти из компана кластера.
[32:45.160 --> 32:47.160]  У всех есть возможность зайти из компана кластера.
[32:47.160 --> 32:49.160]  У всех есть возможность зайти из компана кластера.
[32:49.160 --> 32:51.160]  У всех есть возможность зайти из компана кластера.
[32:51.160 --> 32:53.160]  У всех есть возможность зайти из компана кластера.
[32:53.160 --> 32:55.160]  У всех есть возможность зайти из компана кластера.
[32:55.160 --> 32:57.160]  У всех есть возможность зайти из компана кластера.
[32:57.160 --> 32:59.160]  У всех есть возможность зайти из компана кластера.
[32:59.160 --> 33:01.160]  У всех есть возможность зайти из компана кластера.
[33:01.160 --> 33:03.160]  У всех есть возможность зайти из компана кластера.
[33:03.160 --> 33:05.160]  У всех есть возможность зайти из компана кластера.
[33:05.160 --> 33:07.160]  У всех есть возможность зайти из компана кластера.
[33:07.160 --> 33:09.160]  У всех есть возможность зайти из компана кластера.
[33:09.160 --> 33:11.160]  У всех есть возможность зайти из компана кластера.
[33:11.160 --> 33:13.160]  У всех есть возможность зайти из компана кластера.
[33:13.160 --> 33:15.160]  У всех есть возможность зайти из компана кластера.
[33:15.160 --> 33:17.160]  У всех есть возможность зайти из компана кластера.
[33:17.160 --> 33:19.160]  У всех есть возможность зайти из компана кластера.
[33:19.160 --> 33:21.160]  У всех есть возможность зайти из компана кластера.
[33:21.160 --> 33:23.160]  У всех есть возможность зайти из компана кластера.
[33:23.160 --> 33:25.160]  У всех есть возможность зайти из компана кластера.
[33:25.160 --> 33:27.160]  У всех есть возможность зайти из компана кластера.
[33:27.160 --> 33:29.160]  У всех есть возможность зайти из компана кластера.
[33:29.160 --> 33:31.160]  У всех есть возможность зайти из компана кластера.
[33:31.160 --> 33:33.160]  У всех есть возможность зайти из компана кластера.
[33:33.160 --> 33:35.160]  У всех есть возможность зайти из компана кластера.
[33:35.160 --> 33:37.160]  У всех есть возможность зайти из компана кластера.
[33:37.160 --> 33:39.160]  У всех есть возможность зайти из компана кластера.
[33:39.160 --> 33:41.160]  У всех есть возможность зайти из компана кластера.
[33:41.160 --> 33:43.160]  У всех есть возможность зайти из компана кластера.
[33:43.160 --> 33:45.160]  У всех есть возможность зайти из компана кластера.
[33:45.160 --> 33:47.160]  У всех есть возможность зайти из компана кластера.
[33:47.160 --> 33:49.160]  У всех есть возможность зайти из компана кластера.
[33:49.160 --> 33:51.160]  У всех есть возможность зайти из компана кластера.
[33:51.160 --> 33:53.160]  У всех есть возможность зайти из компана кластера.
[33:53.160 --> 33:55.160]  У всех есть возможность зайти из компана кластера.
[33:55.160 --> 33:57.160]  У всех есть возможность зайти из компана кластера.
[33:57.160 --> 33:59.160]  У всех есть возможность зайти из компана кластера.
[33:59.160 --> 34:01.160]  У всех есть возможность зайти из компана кластера.
[34:01.160 --> 34:03.160]  У всех есть возможность зайти из компана кластера.
[34:03.160 --> 34:05.160]  У всех есть возможность зайти из компана кластера.
[34:05.160 --> 34:07.160]  У всех есть возможность зайти из компана кластера.
[34:07.160 --> 34:09.160]  У всех есть возможность зайти из компана кластера.
[34:09.160 --> 34:11.160]  У всех есть возможность зайти из компана кластера.
[34:11.160 --> 34:13.160]  У всех есть возможность зайти из компана кластера.
[34:13.160 --> 34:15.160]  У всех есть возможность зайти из компана кластера.
[34:15.160 --> 34:17.160]  У всех есть возможность зайти из компана кластера.
[34:17.160 --> 34:19.160]  У всех есть возможность зайти из компана кластера.
[34:19.160 --> 34:21.160]  У всех есть возможность зайти из компана кластера.
[34:21.160 --> 34:23.160]  У всех есть возможность зайти из компана кластера.
[34:23.160 --> 34:25.160]  У всех есть возможность зайти из компана кластера.
[34:25.160 --> 34:27.160]  У всех есть возможность зайти из компана кластера.
[34:27.160 --> 34:29.160]  Это не очень хорошо, как я уже говорил.
[34:29.160 --> 34:31.160]  Это не очень хорошо, как я уже говорил.
[34:31.160 --> 34:33.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:33.160 --> 34:35.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:35.160 --> 34:37.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:37.160 --> 34:39.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:39.160 --> 34:41.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:41.160 --> 34:43.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:43.160 --> 34:45.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:45.160 --> 34:47.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:47.160 --> 34:49.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:49.160 --> 34:51.160]  И плюс нам еще надо среднее посчитать, а у тебя просто count.
[34:51.160 --> 34:53.160]  То есть в принципе, начало правильное.
[34:53.160 --> 34:55.160]  То есть в принципе, начало правильное.
[34:55.160 --> 34:59.160]  Во-первых, звездочки, во-вторых, это половина запроса.
[34:59.160 --> 35:11.160]  Во-первых, звездочки, во-вторых, это половина запроса.
[35:11.160 --> 35:13.160]  То есть в принципе, начало правильное,
[35:13.160 --> 35:16.160]  Во-первых, звездочка, во-вторых, это половина запроса.
[35:43.160 --> 36:11.160]  Как называется база данных?
[36:11.160 --> 36:28.160]  Можете свою создать, а можно посмотреть вот здесь.
[36:28.160 --> 36:40.160]  Я скинул чат.
[36:40.160 --> 36:57.160]  Сейчас.
[36:57.160 --> 37:07.160]  Там не 0,9, там какой-то другой логин, по-моему, есть.
[37:07.160 --> 37:10.160]  Сейчас, секунду.
[37:10.160 --> 37:12.160]  Вот такой.
[37:12.160 --> 37:41.160]  То есть 2021, а потом 2009.
[37:41.160 --> 37:53.160]  А запустить есть возможность?
[37:53.160 --> 37:58.160]  Вот еще Светослав прислал запрос.
[37:58.160 --> 38:01.160]  Смотри, а что такое авг звездочка?
[38:01.160 --> 38:30.160]  То есть тебе надо среднее количество, а ты считаешь среднее что?
[39:00.160 --> 39:25.160]  Ну средняя маска это как-то странно.
[39:25.160 --> 39:31.160]  Да.
[39:31.160 --> 39:53.160]  Сейчас пароль.
[39:53.160 --> 40:16.160]  Давайте посмотрим тогда на решение.
[40:16.160 --> 40:44.160]  Вот у нас такой.
[40:44.160 --> 40:47.160]  Такой юз.
[40:47.160 --> 40:56.160]  Сейчас я посмотрю на название таблицы.
[40:56.160 --> 41:03.160]  Что мы делаем? Мы сначала считаем общее количество айпишников по каждой маске.
[41:03.160 --> 41:06.160]  Ну а потом усредняем.
[41:06.160 --> 41:12.160]  Давайте выполним, убедимся, что этот квад работает.
[41:12.160 --> 41:16.160]  Там я еще указал название джоба.
[41:16.160 --> 41:23.160]  Можно не указывать, это просто для того, чтобы было удобнее видеть в джобхистори вашу джобу.
[41:23.160 --> 41:29.160]  Потому что если мы ее никак не назвали, то называться она будет по началу нашего SQL кода.
[41:29.160 --> 41:32.160]  Вы увидите название джоба и селектов.
[41:32.160 --> 41:49.160]  Если у многих такие же запросы, то и будет непонятно, где чья джоба.
[41:49.160 --> 41:57.160]  Вот видите, что у нас получилось. У нас получилось, что у нас две мапридио джобы, total jobs.
[41:57.160 --> 42:08.160]  Видите, как уже интересно. На обычном мапридио джобе, чтобы написать две джобы, нам нужно было написать два мапера, два редьюсера, написать здоровенные раны Саш, какие-нибудь компараторы.
[42:08.160 --> 42:14.160]  А тут вот такой вот несложный SQL код и у нас уже две джобы.
[42:14.160 --> 42:18.160]  Я очень правильно понимаю, что иногда это помогает нам писать меньше кода.
[42:18.160 --> 42:25.160]  И по факту вот оно там само две джобы делает, но иногда это будет делать менее оптимально, чем мы бы могли.
[42:25.160 --> 42:44.160]  На семинарах мы посмотрим более подробно, как можно помогать хайво оптимизироваться.
[42:44.160 --> 43:00.160]  Сейчас, почему-то ничего не выявило.
[43:00.160 --> 43:05.160]  А, вот выявило одно число. Да.
[43:05.160 --> 43:09.160]  Вот такое получилось у нас значение.
[43:09.160 --> 43:13.160]  Давайте поставим тут explain.
[43:13.160 --> 43:20.160]  Explain это значит, что мы вместо выполнения запроса пишем просто его план.
[43:20.160 --> 43:24.160]  Вот сейчас он выполнится быстрее, потому что только план можно построить.
[43:24.160 --> 43:28.160]  И мы видим, что у нас здесь три стейджа.
[43:28.160 --> 43:38.160]  Почему джобы две, а стейдж три? Потому что последний стейдж это просто вычетка данных без мапридьюса.
[43:38.160 --> 43:43.160]  То есть два стейджа у нас.
[43:43.160 --> 43:48.160]  Это мапридьюс и мы видим, что у нас тут есть группировка по каунту.
[43:48.160 --> 44:02.160]  Точнее, да, у нас тут есть просто каунт, IP в группировке.
[44:02.160 --> 44:26.160]  Опять же сортировка.
[44:26.160 --> 44:32.160]  На юсере второй джобы у нас есть AVD в группае.
[44:32.160 --> 44:38.160]  Вот, и можете также увидеть здесь текст Input формат, Hive Ignore K Text Input формат.
[44:38.160 --> 44:52.160]  То есть здесь Hive сам умеет указывать типы, ключа и значения.
[44:52.160 --> 44:55.160]  Вот, кстати, Lazy Symbols RD.
[44:55.160 --> 45:06.160]  RD это специальный такой пакет, который отвечает за сериализацию, децериализацию данных, за вычетку из HDFS и запись.
[45:06.160 --> 45:09.160]  И он также отвечает за парсинг данных.
[45:09.160 --> 45:16.160]  То есть на семинарах мы с вами будем разбирать код, когда данные хранятся, как я уже сказал, в каком-то не очень читабельном формате.
[45:16.160 --> 45:21.160]  Их нужно будет, чтобы записать в таблицу, сначала поматчить регулярками.
[45:21.160 --> 45:26.160]  Вот, и за эти регулярки отвечает как раз SRD.
[45:26.160 --> 45:30.160]  А здесь вместо регулярок мы использовали вот этот таб.
[45:30.160 --> 45:35.160]  И поэтому у нас получился Lazy Symbols RD.
[45:35.160 --> 45:45.160]  То есть за вот эти табы, вообще за вот эти разделители, за парсинг датасетов с одинаковыми разделителями отвечает Lazy Symbols RD.
[45:46.160 --> 45:50.160]  То есть регулярок нет, вместо этого такой простой парсинг.
[45:56.160 --> 46:04.160]  Вот, разобрались с этой задачей, теперь давайте посмотрим на то, как можно оптимизировать наш код.
[46:04.160 --> 46:08.160]  Ну и вообще какие есть возможности для оптимизации.
[46:08.160 --> 46:15.160]  Хайв на джаве? Ну хайв вообще на SQL мы пишем на SQL, а внутри да, внутри на джаве.
[46:15.160 --> 46:23.160]  И на семинарах мы также посмотрим примеры, когда нам нужно будет достраивать хайв определенным образом
[46:23.160 --> 46:28.160]  и писать для этого джава-код, да еще на достаточно кривом опи.
[46:30.160 --> 46:34.160]  Ну такое приходится делать редко. То есть когда мы в хайв встраиваем свои функции,
[46:34.160 --> 46:40.160]  их, хотим создать такие функции, то их надо писать только на джаве.
[46:45.160 --> 46:54.160]  Вот, по поводу оптимизации, у нас есть такие вот слова, и давайте разберем, что они обозначают.
[46:54.160 --> 46:57.160]  И для этого давайте посмотрим на вот такой датасет.
[46:57.160 --> 47:15.160]  У нас есть таблица, в которой есть страны, города, ну и дальше там жители, имя, фамилия и условно почта.
[47:16.160 --> 47:26.160]  Вот, ну и наш датасет устроен так, что, ну наши запросы устроены так, что мы хотим делать разные фильтрации
[47:26.160 --> 47:29.160]  по кантри, группировку по кантри.
[47:29.160 --> 47:37.160]  Вот, можно ли как-то оптимизировать запросы, если у нас постоянно идет какая-то фильтрация по кантри?
[47:37.160 --> 47:45.160]  То есть оптимизировать не запрос, а само хранение данных, можно ли как-то оптимизировать?
[47:49.160 --> 47:55.160]  Ну можно какую-нибудь таблицу создать, в которую мы таблицами кантри чайные просчитаем.
[47:57.160 --> 47:59.160]  А что именно просчитаем?
[48:00.160 --> 48:05.160]  Ну зависит от того, что у нас там запрос фигурирует, что мы хотим кантри делать?
[48:05.160 --> 48:16.160]  Ну у нас какой-то запрос, в котором есть group by по кантри, и второй запрос, в котором есть where
[48:16.160 --> 48:20.160]  кантри, чего-нибудь там, Россия.
[48:23.160 --> 48:31.160]  В SQL по-моему есть представления, и мы можем создать различные представления на те кантри, которые нам нужны.
[48:31.160 --> 48:37.160]  А если мы заранее не знаем, какие кантри нам нужны, то мы просто знаем, что мы будем работать с кантри.
[48:41.160 --> 48:48.160]  Ну про представление-то это близко, но есть более автоматический способ, если мы не знаем, сколько у нас кантри.
[48:48.160 --> 49:00.160]  Есть так называемое партиционирование. То есть мы бьем нашу таблицу на части по кантри.
[49:00.160 --> 49:10.160]  То есть вместо одной таблицы у нас по сути появляется таблица c равно 1, таблица c равно 2 и так далее.
[49:12.160 --> 49:18.160]  То есть с точки зрения хайва это так и остается одна таблица.
[49:19.160 --> 49:27.160]  Но с точки зрения хранения данных у нас создается специальная папка, которая называется DateWirehouse.
[49:27.160 --> 49:36.160]  Туда копируются данные и они распределяются по папкам. То есть вот это вот первая папка в HDFS, это вторая папка в HDFS.
[49:36.160 --> 49:44.160]  И в каждой папке будет храниться часть таблички с одним значением кантри.
[49:45.160 --> 50:00.160]  И теперь если у нас есть, например, запрос c типа where равно кантри чему-то, то мы можем не делать full-scan таблицы, проходить всю таблицу и искать вот эти вот ключи.
[50:00.160 --> 50:09.160]  Мы можем найти просто нужную нам партицию, то есть обойти не все записи таблицы, а обойти только список партиций.
[50:09.160 --> 50:15.160]  Их будет намного меньше. И как бы выдать вот эту маленькую табличку.
[50:22.160 --> 50:26.160]  Насколько сейчас понятная вещь про партиции?
[50:39.160 --> 50:56.160]  Ещё раз, это как бы больше SQL-ная штука, которая в целом устроена в том, что он так делает, или же HIFE это как-то очень костыльно напрямую делает?
[50:56.160 --> 51:08.160]  Это делает MapReduce. То есть у нас данные разбиваются на маппере, на вот эти папки.
[51:08.160 --> 51:14.160]  То есть маппер создает папки и распихивает данные по ключу по этим папкам.
[51:19.160 --> 51:21.160]  А почему очень костыльно?
[51:21.160 --> 51:23.160]  Не-не, окей, я просто думал, что это может быть как...
[51:23.160 --> 51:28.160]  А, но кем? У нас же всё равно никуда не получается, всё равно бы это всё MapReduce.
[51:28.160 --> 51:31.160]  Да, у нас это ещё кто-то MapReduce делает.
[51:31.160 --> 51:36.160]  Причём мы это делаем каждый раз, когда хотим выполнить такой запрос, да?
[51:36.160 --> 51:39.160]  Нет, мы это делаем при создании таблицы.
[51:39.160 --> 51:41.160]  А, при создании таблицы.
[51:41.160 --> 51:47.160]  То есть мы один раз создали, я тоже сейчас это покажу на примере. Раскидали.
[51:47.160 --> 51:53.160]  Так, одну секунду, мне нужно отойти срочный звонок. Сейчас я вернусь.
[52:01.160 --> 52:06.160]  В общем, мы разобрались с вами с партициями, что у нас данные распихиваются по папкам.
[52:09.160 --> 52:11.160]  Давайте я это тоже покажу в коде.
[52:13.160 --> 52:15.160]  Сейчас.
[52:17.160 --> 52:19.160]  Давайте я скопирую код, который у нас есть.
[52:42.160 --> 52:44.160]  Вот, что у нас тут меняется?
[52:44.160 --> 52:46.160]  Не видно сейчас экрана.
[52:46.160 --> 52:48.160]  Ага, сейчас.
[52:51.160 --> 52:53.160]  Надо делать одну настройку.
[53:15.160 --> 53:21.160]  Вот, то есть у нас теперь будет немного другое создание таблицы.
[53:21.160 --> 53:23.160]  Сейчас я покажу какое.
[53:23.160 --> 53:26.160]  То есть здесь всё остаётся точно так же.
[53:26.160 --> 53:31.160]  Единственное, что мы должны поставить вот этот ключик.
[53:36.160 --> 53:40.160]  Что это значит? Это то, что партиции у нас создаются динамически.
[53:40.160 --> 53:43.160]  То есть мы не знаем, сколько папок у нас будет вот этих.
[53:43.160 --> 53:48.160]  Мы читаем данные, создаём таблицу и смотрим, вот у нас новая country пришла.
[53:48.160 --> 53:51.160]  Значит, нужно новую папку создать, новую партиции.
[53:51.160 --> 53:53.160]  И так далее.
[53:53.160 --> 53:58.160]  Правда, тут у нас нету country, у нас есть маски под сети вместо этого.
[53:58.160 --> 54:01.160]  Ну хорошо, у нас будут партиции в виде масок.
[54:04.160 --> 54:06.160]  Как меняется синтаксис?
[54:13.160 --> 54:17.160]  Вот у нас появится вторая таблица, она будет называться subnet-spart.
[54:20.160 --> 54:22.160]  И синтаксис меняется так.
[54:22.160 --> 54:27.160]  У нас остаётся здесь одно поле, а второе поле идёт в партиции.
[54:31.160 --> 54:37.160]  То есть мы тут пишем partitioned by.
[54:37.160 --> 54:42.160]  И здесь пишем шестовое поле mask-string.
[54:50.160 --> 54:52.160]  Что нам теперь нужно сделать?
[54:52.160 --> 54:55.160]  То есть вот мы создали такую таблицу.
[54:55.160 --> 54:59.160]  И возьмём данные из той таблицы, которая у нас была до этого.
[54:59.160 --> 55:04.160]  То есть у нас была таблица просто subnet, а теперь появилась subnet-spart.
[55:08.160 --> 55:11.160]  Это делается вот так.
[55:11.160 --> 55:18.160]  То есть у нас есть insert overwrite table.
[55:18.160 --> 55:23.160]  Вот такая таблица, которую мы сделали.
[55:27.160 --> 55:29.160]  partition.
[55:29.160 --> 55:32.160]  Тут было partitioned, а тут partition.
[55:32.160 --> 55:36.160]  И в partition мы указываем, по какому полю у нас partition.
[55:39.160 --> 55:42.160]  То есть тут мы задаём, какие партиции будут.
[55:42.160 --> 55:45.160]  А тут мы говорим именно, как мы их будем создавать.
[55:45.160 --> 55:47.160]  По какому полю.
[55:47.160 --> 55:52.160]  Ну и теперь select звёздочка from subnet.
[55:54.160 --> 55:57.160]  А partitioned и partitioned – это именно хаймовые функции?
[55:57.160 --> 56:00.160]  Или они в обычном стиле тоже присутствуют?
[56:00.160 --> 56:02.160]  Хаймовые, да.
[56:02.160 --> 56:06.160]  Ну вообще SQL в хайве и SQL обычные, они отличаются.
[56:06.160 --> 56:09.160]  И даже SQL в хайве, он называется HiveQL.
[56:09.160 --> 56:11.160]  То есть это всё-таки диалект такой.
[56:11.160 --> 56:15.160]  Но в тех запросах, которые мы будем делать на семинарах и в домашних,
[56:15.160 --> 56:17.160]  отличий практически не будет.
[56:21.160 --> 56:24.160]  Вот давайте запустим этот код.
[56:24.160 --> 56:26.160]  03 partitioned.
[56:30.160 --> 56:33.160]  Вот у нас пошли работать жёбы.
[57:00.160 --> 57:03.160]  Вот эти вот жёбы – это здесь идёт разделение по партициям.
[57:11.160 --> 57:14.160]  Видите, у нас нигде нет редьюсера, есть только маппер.
[57:18.160 --> 57:20.160]  Вот что у нас получилось.
[57:22.160 --> 57:25.160]  Видите, у нас создалось вот столько партиций,
[57:25.160 --> 57:28.160]  вот вообще сколько у нас получилось в итоге партиций?
[57:28.160 --> 57:30.160]  Получается восемь.
[57:35.160 --> 57:38.160]  Стоит по времени в сравнении с предыдущим запуском,
[57:38.160 --> 57:41.160]  что-то вроде сорок четыре секунды в итоге вышло?
[57:41.160 --> 57:43.160]  С предыдущим запуском каким?
[57:43.160 --> 57:45.160]  Там, где мы считали среднее,
[57:45.160 --> 57:50.160]  то есть по времени мы уже сделал 8 слоя.
[57:50.160 --> 57:57.160]  в итоге вышло. С предыдущим запуском каким? Там, где мы считали среднее или там, где создавали таблицу?
[57:57.160 --> 58:05.160]  Ну сейчас, а тут мы что считали? Я просто просил, я думал, что мы самую задачу другим способом решаем.
[58:05.160 --> 58:15.160]  Смотри, тут как бы по времени сравнивать не очень корректно, потому что не с чем, потому что у нас есть вот такие вот запросы.
[58:15.160 --> 58:22.160]  И в 0.2 query мы считали средние маски, в общем делали какую-то математику.
[58:22.160 --> 58:28.160]  А здесь мы просто создаем таблицу, просто уже оптимизированную по партизе.
[58:28.160 --> 58:34.160]  Поэтому сравнивать создание таблицы с вот этим вот запросом.
[58:37.160 --> 58:43.160]  Я почему-то думал, что мы хотим в итоге другим способом ту же самую задачу решить.
[58:44.160 --> 58:51.160]  Мы хотим в итоге другим способом задачу решить, просто я до этого дойду еще.
[58:51.160 --> 58:57.160]  Сейчас, секунду, я возьму вот этот элемент.
[58:57.160 --> 59:05.160]  Сейчас же по сути можно выполнить тот же самый запрос, и он должен быстрее отработать, потому что он теперь по партизам будет ходить.
[59:05.160 --> 59:08.160]  Да, так и есть.
[59:13.160 --> 59:26.160]  То есть, конечно, создание партизей дольше, чем создание просто таблицы, потому что создание таблицы ничего не делает.
[59:26.160 --> 59:32.160]  Но теперь, когда мы создали такую оптимизированную таблицу, вот давайте еще раз проверим.
[59:32.160 --> 59:34.160]  Сделаем query.
[59:36.160 --> 59:41.160]  Query у нас по обычной таблице. Сколько времени оно будет работать?
[59:44.160 --> 59:53.160]  У нас сейчас есть обычная таблица и партизионированные. Мы их обе храним и просто сравним по времени.
[59:53.160 --> 01:00:22.160]  А вот когда мы разделили партизием и запустили SQL команду, где мы считаем количество, там разве лидиус не должен выполняться, как мы с помощью макера считаем количество?
[01:00:22.160 --> 01:00:26.160]  Количество? Где эта команда?
[01:00:26.160 --> 01:00:36.160]  Где мы считали count по подсетям?
[01:00:36.160 --> 01:00:42.160]  Так все верно. Там, где мы считали count по подсетям, у нас тут и reducer есть.
[01:00:45.160 --> 01:00:48.160]  Два разных запроса.
[01:00:48.160 --> 01:00:57.160]  Первый запрос это создание таблицы с партизиями. Он у нас уже отработал, закончился, и вот мы создали партизии.
[01:01:00.160 --> 01:01:10.160]  Можно даже посмотреть более подробно. Вот наш metastore subnets.part и что тут у нас есть.
[01:01:10.160 --> 01:01:21.160]  Давайте сделаем так. Мы запомнили total map reduce CPU time. 8 минут 15 секунд.
[01:01:21.160 --> 01:01:34.160]  И теперь давайте сделаем вот так. Я открою mux и мы запустим эту задачу только на другой таблице.
[01:01:34.160 --> 01:01:45.160]  Subnets, добавим subnets.part. Ничего не меняя в запросе, просто сменили таблицу из обычной на партизированную.
[01:01:45.160 --> 01:01:52.160]  И пошли выполнять еще раз. Пока будем выполнять, посмотрим сюда, что тут у нас было 8 минут.
[01:01:52.160 --> 01:01:58.160]  И посмотрим на то, как хранятся наши партиции, пока выполняется код.
[01:02:04.160 --> 01:02:19.160]  Вот у нас наши файлы с партициями. Давайте зайдем в одну папку, вот эту например.
[01:02:19.160 --> 01:02:23.160]  Как я уже сказал, каждая партиция это папка.
[01:02:23.160 --> 01:02:30.160]  И тут может быть много файлов, и эти файлы выглядят вот так.
[01:02:30.160 --> 01:02:35.160]  То есть что у нас осталось от таблицы? Осталась одна колонка.
[01:02:35.160 --> 01:02:44.160]  Первую колонку маски мы убрали под партиции, а внутри осталась только последняя колонка, вот айпишники.
[01:02:44.160 --> 01:02:55.160]  И смотрите, у нас total map reduce CPU time spent уменьшился с 8 минут до 5 минут.
[01:02:55.160 --> 01:03:00.160]  Уже вот такая оптимизация на треть.
[01:03:00.160 --> 01:03:03.160]  Это без учета создания изначально таблицы?
[01:03:03.160 --> 01:03:15.160]  Да, потому что таблицу мы создали один раз, а потом запросы будем исполнять часто.
[01:03:15.160 --> 01:03:18.160]  Что еще есть? Какая есть еще оптимизация?
[01:03:19.160 --> 01:03:26.160]  Что еще есть? Какая есть еще оптимизация? То есть вот мы разобрались с партиционированием.
[01:03:26.160 --> 01:03:32.160]  Есть еще кластеризация или багетинг.
[01:03:32.160 --> 01:03:40.160]  Он работает похожим образом, только обычно он работает в паре.
[01:03:40.160 --> 01:03:43.160]  То есть вот мы кластеризовали по одному полю.
[01:03:44.160 --> 01:03:48.160]  Партиционирование по одному полю и кластеризовали по другому.
[01:03:48.160 --> 01:03:53.160]  Чем отличается кластеризация? В принципе, пара вещей.
[01:03:53.160 --> 01:04:00.160]  Если у нас тут были папки, то у кластеризации будут не папки, а файлы.
[01:04:00.160 --> 01:04:09.160]  И второе, что в одном файле у нас будет не для одного ключа значение все, а будут значения для хэша.
[01:04:09.160 --> 01:04:23.160]  По сути, багетинг работает как партишнер в MapReduce, когда мы брали хэш от ключа и делили на количество r.
[01:04:23.160 --> 01:04:28.160]  Правда, здесь будет на b, потому что мы будем здесь задавать количество багетов.
[01:04:28.160 --> 01:04:33.160]  Можем и не задавать, тогда просто каждый хэш от k пойдет в свой файл.
[01:04:33.160 --> 01:04:41.160]  На этой таблице мы уже с вами не будем пробовать, потому что у нас полей нет, у нас всего два поля.
[01:04:41.160 --> 01:04:53.160]  Но в принципе, если в таблице полей больше, то мы можем кластеризовать по полю какому-то, а внутри еще и кластеризовать.
[01:04:53.160 --> 01:04:56.160]  То есть еще более сделать тонкое разбиение.
[01:04:57.160 --> 01:05:07.160]  Но так как считается, что партиции лучше использовать тогда, когда у нас мало значений в поле.
[01:05:07.160 --> 01:05:15.160]  В Country у нас значений немного. Сколько у нас значений? Максимум стран на свете, по-моему, 289.
[01:05:15.160 --> 01:05:19.160]  А городов у нас десятки тысяч, их гораздо больше.
[01:05:19.160 --> 01:05:28.160]  Поэтому для полей, у которых много значений, лучше использовать багетинг еще и потому, что здесь хэш.
[01:05:28.160 --> 01:05:35.160]  То есть в одном багете может быть много ключей.
[01:05:35.160 --> 01:05:38.160]  А в случае с партией так не будет.
[01:05:38.160 --> 01:05:46.160]  Если мы делаем партиции по полю, в котором много значений, мы разобьем табличку на большое количество блоков.
[01:05:46.160 --> 01:05:51.160]  Ну и будет та же самая проблема, что у нас в HDFS хранятся маленькие файлы.
[01:05:59.160 --> 01:06:02.160]  Вот, насколько сейчас понятно про кластеризацию?
[01:06:05.160 --> 01:06:06.160]  Вроде понятно.
[01:06:06.160 --> 01:06:14.160]  А то есть из-за того, что у нас хэширование, скорее всего коллизии.
[01:06:14.160 --> 01:06:21.160]  Вряд ли мы ожидаем большое количество коллизий, поэтому у нас будет очень много файлов из-за этого.
[01:06:21.160 --> 01:06:26.160]  Мы как раз коллизии здесь не боимся, но будут коллизии и будет меньше файлов.
[01:06:27.160 --> 01:06:36.160]  Ну в плане, что большое количество объясняется тем, что хэш функция не по модулю, она разбросает все равномерно.
[01:06:36.160 --> 01:06:38.160]  Да, но можно делать по модуле.
[01:06:38.160 --> 01:06:39.160]  Тут зависит от нас.
[01:06:39.160 --> 01:06:45.160]  Когда мы пишем запрос на кластеризацию, мы указываем там типа cluster by int столько-то багетов.
[01:06:45.160 --> 01:06:51.160]  Вот мы сказали, что мы хотим 10 багетов, а у нас будет деление на 10.
[01:06:51.160 --> 01:07:01.160]  Просто хэш без деления использовать не очень хорошо, потому что, да, как ты правильно сказал, у нас будет много уникальных хэшей и будет много маленьких файлов.
[01:07:01.160 --> 01:07:08.160]  Проблема маленьких файлов в HDFS, она всегда над нами висит, потому что это загрузка на имноды.
[01:07:11.160 --> 01:07:12.160]  Понятно.
[01:07:13.160 --> 01:07:14.160]  Хорошо.
[01:07:14.160 --> 01:07:17.160]  Что касается кластеринга, разобрались.
[01:07:17.160 --> 01:07:22.160]  Что касается map-side-join, это мы более подробно посмотрим на семинарах.
[01:07:22.160 --> 01:07:32.160]  То есть есть специальный синтаксис, можно Хайву специальные подсказки делать о том, что мы поджоиним две таблицы, но одна из них маленькая, сделаем map-side-join.
[01:07:32.160 --> 01:07:35.160]  Не факт, что Хайву эту подсказку услышит.
[01:07:35.160 --> 01:07:41.160]  То есть он может ее воспринять, а может по каким-то там внутренним таблицам.
[01:07:41.160 --> 01:07:46.160]  Причинам ее проигнорировать, в зависимости от оптимизации.
[01:07:46.160 --> 01:07:49.160]  Вот такая возможность есть указать map-side-join.
[01:07:49.160 --> 01:07:51.160]  И сэмплирование.
[01:07:52.160 --> 01:07:55.160]  Есть ключевое слово table-sample.
[01:07:55.160 --> 01:08:06.160]  Table-sample нам нужно для того, что есть у нас, например, очень большая таблица, и мы хотим сделать примерный расчет на какой-то маленьком поддетасете,
[01:08:06.160 --> 01:08:11.160]  аппроксимировать его на большой, ну и в общем оценить что-нибудь.
[01:08:11.160 --> 01:08:15.160]  Поэтому есть возможность сделать сэмпл.
[01:08:15.160 --> 01:08:17.160]  Взять часть таблицы.
[01:08:17.160 --> 01:08:20.160]  И вот тут много возможностей, как мы эту часть берем.
[01:08:20.160 --> 01:08:23.160]  Можно взять n родной таблицы.
[01:08:23.160 --> 01:08:28.160]  То есть если мы будем делать сэмплирование, то мы будем делать сэмплирование,
[01:08:28.160 --> 01:08:30.160]  то мы будем делать сэмплирование,
[01:08:30.160 --> 01:08:32.160]  то мы будем делать сэмплирование,
[01:08:32.160 --> 01:08:34.160]  то мы будем делать сэмплирование,
[01:08:34.160 --> 01:08:36.160]  то мы будем делать сэмплирование,
[01:08:36.160 --> 01:08:38.160]  то мы будем делать сэмплирование,
[01:08:38.160 --> 01:08:40.160]  то мы будем делать сэмплирование,
[01:08:40.160 --> 01:08:42.160]  то мы будем делать сэмплирование,
[01:08:42.160 --> 01:08:44.160]  то мы будем делать сэмплирование,
[01:08:44.160 --> 01:08:46.160]  то мы будем делать сэмплирование,
[01:08:46.160 --> 01:08:48.160]  то мы будем делать сэмплирование,
[01:08:48.160 --> 01:08:50.160]  то мы будем делать сэмплирование,
[01:08:50.160 --> 01:08:52.160]  то мы будем делать сэмплирование,
[01:08:52.160 --> 01:08:54.160]  то мы будем делать сэмплирование,
[01:08:54.160 --> 01:08:56.160]  то мы будем делать сэмплирование,
[01:08:56.160 --> 01:08:58.160]  то мы будем делать сэмплирование,
[01:08:58.160 --> 01:09:00.160]  и мы указали 10%,
[01:09:00.160 --> 01:09:02.160]  то мы возьмём всё равно 50%,
[01:09:02.160 --> 01:09:04.160]  потому что два блока мы возьмём один.
[01:09:08.160 --> 01:09:13.160]  Блоки – это сейчас в терминах HDFS мы говорим, да?
[01:09:13.160 --> 01:09:15.160]  Да, да, да.
[01:09:18.160 --> 01:09:20.160]  То есть удобно делать и сэмпли,
[01:09:20.160 --> 01:09:23.160]  когда у нас есть бакет и есть партиции.
[01:09:28.160 --> 01:09:30.160]  Есть ли какие-то ещё вопросы?
[01:09:30.160 --> 01:09:33.160]  В принципе, на этом сейчас всё по хайву,
[01:09:33.160 --> 01:09:35.160]  что я хотел рассказать.
[01:09:35.160 --> 01:09:37.160]  Можно ещё добавить то,
[01:09:37.160 --> 01:09:41.160]  что по этой таблице мы можем сделать партишнинг.
[01:09:41.160 --> 01:09:43.160]  Да, ещё есть такая штука,
[01:09:43.160 --> 01:09:45.160]  как несбалансированные данные.
[01:09:45.160 --> 01:09:47.160]  То есть, конечно, всё это хорошо,
[01:09:47.160 --> 01:09:49.160]  что мы покластеризовали,
[01:09:49.160 --> 01:09:51.160]  попартиционировали,
[01:09:51.160 --> 01:09:53.160]  но мы не будем делать сэмплирование,
[01:09:53.160 --> 01:09:55.160]  то мы будем делать сэмплирование,
[01:09:55.160 --> 01:09:57.160]  то мы будем делать сэмплирование,
[01:09:57.160 --> 01:09:59.160]  то мы будем делать сэмплирование,
[01:09:59.160 --> 01:10:01.160]  но если у нас в этом датасете
[01:10:01.160 --> 01:10:05.160]  90% country – это Россия,
[01:10:09.160 --> 01:10:13.160]  а здесь 80% city – это Москва.
[01:10:16.160 --> 01:10:18.160]  Тут как бы разбивай, не разбивай,
[01:10:18.160 --> 01:10:20.160]  у нас всё равно будет одна партиция
[01:10:20.160 --> 01:10:22.160]  сильно больше других,
[01:10:22.160 --> 01:10:26.160]  и поэтому у нас есть ключевое слово с cute by.
[01:10:57.160 --> 01:11:21.160]  кода. В общем, чтобы не искать долго примеры
[01:11:21.160 --> 01:11:31.960]  кода с QBuy, это возможность как бы подсаливать наши кластеры и партиции. То есть мы, по сути,
[01:11:31.960 --> 01:11:38.640]  вот это country, большую партицию с России, мы разобьем еще по блокам. Там рандомно или
[01:11:38.640 --> 01:11:43.680]  по какому-то значению. В общем, у нас появится две или три партиции вместо одной.
[01:11:43.680 --> 01:11:56.720]  Это вот как бы борьба с несбалансированными данными. Это касается только партийцы или это...
[01:11:56.720 --> 01:12:09.200]  И багетов. А, и багетов, окей. Так, вот, в следующий раз мы с вами обсудим всякие аналоги хайва,
[01:12:09.200 --> 01:12:16.960]  которые тоже работают с SQL или с чем-то похожим на SQL, но это уже не хайв, это на лекции. А на
[01:12:16.960 --> 01:12:22.360]  семинарах и домашних мы будем работать только с хайвом и больше ни с чем другим по этой части.
[01:12:22.360 --> 01:12:24.080]  Ну а дальше у нас начнется уже Spark.
