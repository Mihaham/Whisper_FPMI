[00:00.000 --> 00:12.200]  День добрый. Рад всех вас видеть. Надеюсь, все с добрым здоровьем. У нас начинается курс лекций
[00:12.200 --> 00:18.120]  «Параллельные алгоритмы и параллельные вычисления». Я не знаю, оба ли факультета
[00:18.120 --> 00:27.800]  здесь присутствуют. ФУПМА есть люди, а САФРТК есть. Ну вот, называется они по-разному, но понятно,
[00:27.800 --> 00:36.200]  что я буду читать один курс, и по сути он ближе как раз к параллельным алгоритмам. Мы на нем не
[00:36.200 --> 00:43.000]  будем заниматься непосредственно решением каких-то задач, но будем смотреть, в помощи каких методов
[00:43.000 --> 00:52.800]  можно решать задачи различных классов. Меня зовут Якововский Михаил Владимирович, я заместитель
[00:52.800 --> 00:57.360]  директора по научной работе Института прикладной математики имени Келдыша,
[00:57.360 --> 01:06.640]  Российская академия наук. И на протяжении уже многих лет вот специализируюсь как раз на решении
[01:06.640 --> 01:13.960]  задач механики сплошной среды. Это газовая динамика, это химическая кинетика, это много
[01:13.960 --> 01:18.560]  всего разного с помощью многопроцессорных вычислительных систем. Ну и понятно,
[01:18.560 --> 01:30.240]  что вот именно мои интересы, они лежат в области, которая коротко называется HPC. Мы сегодня рассмотрим
[01:30.240 --> 01:34.400]  области применения суперкомпьютерных систем, ну так как я это себя понимаю. Вот одна из четырех
[01:34.400 --> 01:41.920]  это HPC, это высокопроизводительное вычисление. Отнюдь не исчерпывается ими многообразие
[01:41.920 --> 01:46.600]  применения суперкомпьютеров параллельных систем, но тем не менее это важная область,
[01:46.600 --> 01:55.520]  которая в рамках которой как раз лежат моделирование различных задач, решение вычислительно
[01:55.520 --> 02:03.480]  сложных задач и многое другое. И вот это наибольший интерес, представляя это для меня и в существенной
[02:03.480 --> 02:11.640]  мере это ориентация нашего института, который в свое время был создан для решения с помощью
[02:11.640 --> 02:20.760]  высокопроизводительной вычислительной техники самых разных задач. Ну и в первую очередь это
[02:20.760 --> 02:26.360]  конечно задача связанная с обороной, это формирование ракетно-ядерного счета нашей родины,
[02:26.360 --> 02:33.440]  вот для этого был сделан институт. И так это и осталось, сейчас мы тоже занимаемся решением тех
[02:33.440 --> 02:39.360]  задач, которые актуальны для нашей страны, которые интересны с фундаментальной точки зрения. И
[02:39.360 --> 02:45.520]  используем для этого суперкомпьютерную технику, у нас есть свои вычислительные системы, мы
[02:45.520 --> 02:52.480]  поддерживаем их в таком, скажем, состоянии, достаточном для того, чтобы можно было изучать их
[02:52.480 --> 02:58.320]  свойства, решать с их помощью какие-то ограниченные подношества задач, но когда дело доходит до дела,
[02:58.320 --> 03:03.440]  мы выходим на центр аспиративного пользования, самый разный это университетский и курчатского
[03:03.440 --> 03:10.640]  института, и зарубежный, барселонский, в Японии, и считаем разные задачи там. И это к чему? Это к
[03:10.640 --> 03:15.160]  тому, что сегодня я буду и дальше вот в рамках курса рассказывать методы, которые потенциально
[03:15.160 --> 03:20.880]  позволяют вам использовать суперкомпьютеры. Не просто ноутбук, в котором один процессор четырех
[03:20.880 --> 03:26.240]  ядерный там или восьмиядерный, хотя эти алгоритмы мы тоже будем рассматривать, мы тоже будем
[03:26.240 --> 03:32.240]  рассматривать алгоритмы, которые на большое число процессоров не масштабируются, они хороши на одном,
[03:32.240 --> 03:38.240]  двух, трех, но основная идея все-таки использовать большие системы, большое число процессоров,
[03:38.240 --> 03:42.920]  значит писать алгоритмы, которые хорошо масштабируются. Вот эти алгоритмы мы будем в основном
[03:42.920 --> 03:53.720]  рассматривать. Ниже написана ссылка, это веб-ссылка, там будут выкладываться материалы курса не в
[03:53.720 --> 04:00.280]  ущерб тому, что будет на youtube-канале, там будет презентация, возможно, там будет информация по
[04:00.440 --> 04:08.520]  контрольной, которая ожидается ближе к концу курса, но это будет отдельно решено, когда именно она будет,
[04:08.520 --> 04:19.040]  в каком виде. И там же уже сейчас лежит список литературы, он с одной стороны довольно там старая
[04:19.040 --> 04:25.560]  публикация в основном, а с другой стороны они своей актуальности не потеряли. Вот обновить его,
[04:25.640 --> 04:32.160]  Рути не доходит годами, этот список обновить, аккуратно положить, но одну публикацию я добавил
[04:32.160 --> 04:39.120]  свежую в самом конце, но она тоже интерес представляет. Значит, вот там будут материалы курса.
[04:39.120 --> 04:44.880]  Соответственно, если заменить вот эту точку на собачку, то получится мой мэйл. ИМАМОТ это
[04:44.880 --> 04:49.520]  институт математического моделирования, в какой-то момент я начинал работать в институте
[04:49.520 --> 04:56.760]  приводной математики, потом в какой-то момент академик Самарский Александр Андреевич организовал
[04:56.760 --> 05:03.000]  свой институт отдельный, 3-е отдел ИПМ и выделился с рядом примкнувших сотрудников, у нас там было
[05:03.000 --> 05:08.480]  порядка 100 человек, и 10 с лишним лет мы существовали отдельно. Вот был институт математического
[05:08.480 --> 05:16.160]  моделирования, оттуда остался сайт, осталась почта, потом объединились обратно. Вот судьба,
[05:16.160 --> 05:22.480]  она так поворачивается, но сейчас это единое целое, институт приводной математики.
[05:24.480 --> 05:31.600]  Ну вот параллельный алгоритм, почему параллельный? Я так помечтал сегодня немного, вот хорошо было бы
[05:31.600 --> 05:36.560]  иметь процессор, который бесконечно быстро решает любую задачу, но его алгоритмы написали,
[05:36.560 --> 05:42.400]  он бесконечно быстро его выполняет. Вот если бы такой процессор был, нам бы не пришлось сейчас
[05:42.400 --> 05:49.760]  заниматься вот этими изучением параллельных алгоритмов. Дело это не самое простое, но алгоритмы
[05:49.760 --> 05:56.160]  осознать ничего сложного нету, параллельная программа написать, чтобы она работала, вот это сложнее.
[05:56.160 --> 06:02.000]  И был бы процессор, вот супер процессор, который бесконечно быстро работает, вот не нужно было бы
[06:02.000 --> 06:07.840]  это и не занимались бы мы этим. Да, с точки зрения там познания природы, изучение параллельных
[06:07.840 --> 06:13.280]  алгоритмов оно интересно, но с практической точки зрения полезнее было бы иметь супер процессор,
[06:13.280 --> 06:19.600]  но его нет и не предвидится. Его нет и не предвидится уже достаточно давно, я сегодня
[06:19.600 --> 06:25.240]  никакие слайды показывать не буду, а дальше, если все будет нормально, ну либо я здесь покажу
[06:25.240 --> 06:32.400]  некоторые слайды на эту тему, либо как-то еще будут лекции проходить. Я-то за то, чтобы они очень
[06:32.400 --> 06:37.600]  проходили, вот не болейте все, все будьте здоровы, пусть они будут здесь, я с радостью сюда приеду
[06:37.600 --> 06:45.640]  я всегда сюда с удовольствием приезжал раньше. Так вот, не получается сделать супер процессор,
[06:45.640 --> 06:52.800]  потому что есть некоторые ограничения. Вот некоторые ограничения связаны с физической
[06:52.800 --> 07:00.240]  точки зрения, вот с физическими особенностями процессоров. Они сейчас, вот сегодня
[07:00.240 --> 07:08.960]  основаны на, ну это электрические устройства, передаются, текут какие-то токи, заряжаются
[07:08.960 --> 07:16.680]  какие-то емкости, вот они не могут иметь нулевого, емкость не может быть нулевого, нулевой величины,
[07:16.680 --> 07:21.920]  она должна хранить заряд, он не может быть меньше, чем заряд электрона, а на практике это должен
[07:21.920 --> 07:28.440]  быть более ощутимый заряд, а на то, чтобы этот заряд накопился на конденсаторе, вот, а потом с
[07:28.440 --> 07:33.920]  него ушел, требуется какое-то время. Чем больше ток, тем меньше это время, но чем больше ток, тем
[07:33.920 --> 07:41.720]  выше энергопотребление, тем выше тепловыделение. И вот все в комплексе это, плюс ограничение
[07:41.720 --> 07:47.240]  естественным образом накладываемой скоростью света, привели к тому, что уже на лет 15, наверное,
[07:47.240 --> 07:55.240]  если не больше, скорость одного процессорного ядра, она не растет совсем. Если вы посмотрите на список
[07:55.240 --> 08:06.960]  топ-500, он там, в списке литературы, конечно же есть, вот top500.org, я буду на него периодически
[08:06.960 --> 08:12.360]  ссылаться на этот список, потому что именно там сосредоточены открытые суперкомпьютеры мира,
[08:12.360 --> 08:17.400]  те суперкомпьютеры, о которых известно, вот они есть, ко многим из них есть публичный доступ,
[08:17.400 --> 08:23.400]  не ко всем, там, например, есть яндексовские машины, вот, а насчет публичного доступа к ним я сильно
[08:23.400 --> 08:28.280]  не уверен, по крайней мере большинству из них они делались для корпоративного сегмента, но тем
[08:28.280 --> 08:33.080]  не менее, это машины, о которых миры бы известны, известны как они устроены, известны какие у них
[08:33.080 --> 08:40.000]  характеристики. Да вот если посмотреть на эти машины, на первые позиции, то выяснится, что
[08:40.000 --> 08:48.200]  частота, на которой работают процессоры, из которых сделаны эти суперкомпьютеры, она порядка 2-2,5
[08:48.200 --> 08:53.280]  гигагерц, не больше. Вот у вас дома, если у кого-то системный блок стоит, он скорее всего
[08:53.280 --> 09:02.760]  шустрее, он скорее всего там 3 гигагерца, 4 может быть даже, а в этих системах нет, но и выше 4,5
[09:02.760 --> 09:07.600]  это уже там жидкий азот дальше нужен для того, чтобы охлаждать, не поднимается частота, то есть
[09:07.600 --> 09:14.240]  частота перестала расти очень давно. Значит, этот путь, он экстенсивный, и он на протяжении очень
[09:14.240 --> 09:19.200]  многих лет обеспечивал рост производительности одного процессора, то есть сначала это были
[09:19.200 --> 09:26.840]  какие-то механические устройства, потом там лампы, транзисторы, микросхемы, все выше частоты были,
[09:26.840 --> 09:33.600]  потом они перестали расти. Вот первое, что перестало расти, второе, что перестало расти. Кроме
[09:33.600 --> 09:42.640]  частоты, можно улучшать потребительские свойства самого процессора, те алгоритмы, которые в нем
[09:42.640 --> 09:48.120]  заложены. Вы можете за один такт выполнить несколько инструкций, вы можете одну инструкцию разделить
[09:48.120 --> 09:54.200]  на части, считать данные из оперативной памяти, вещественное число, например, нормализовать его,
[09:54.200 --> 10:00.360]  потом сложить два числа, потом, соответственно, донормализовать и положить в оперативную память.
[10:00.360 --> 10:07.480]  Это разные этапы, и в принципе никто не мешает сделать конвейер из этих этапов, и тогда вы как бы
[10:07.480 --> 10:12.680]  за один такт будете получать не один результат, а четыре. Это архитектурная особенность процессора,
[10:12.680 --> 10:17.240]  они сейчас везде есть, эксплуатируются практически во всех современных процессорах вот такого
[10:17.240 --> 10:28.040]  сорта операций делаются. Но вот фантазия и сякла, в последнее время нету архитектурных решений
[10:28.040 --> 10:37.080]  новых, которые увеличили бы скорость выполнения операций за счет того, что у вас много транзисторов,
[10:37.080 --> 10:41.120]  вы можете их как-то использовать, например, сделать конвейер, например, сдублировать
[10:41.120 --> 10:45.720]  некоторые устройства исполнительные и за один такт выполнять не одну операцию, а две операции.
[10:45.720 --> 10:51.600]  Например, вы можете использовать транзисторы для того, чтобы сделать быструю кэш-память,
[10:51.600 --> 10:56.360]  потому что доступ к кэш-памяти основной относительно скорости работы процессора
[10:56.360 --> 11:01.640]  это медленная штука, а регистры быстрее и значительные, между ними где-то есть кэш-память,
[11:01.640 --> 11:08.360]  и ее делают. Вот это архитектурное решение, которое тоже существенно ускоряли производительность
[11:08.360 --> 11:14.480]  процессора, они и сякли в какой-то момент, достаточно давно уже. Это не значит, что никто
[11:14.480 --> 11:19.360]  ничего не придумывает, но вот в последнее время никто ничего не придумывает. А транзисторов на
[11:19.360 --> 11:24.080]  подложке все больше, вот на одном кристалле транзисторов все больше, они все меньше, техпроцесс растет,
[11:24.080 --> 11:31.560]  там было 60 нанометров, 40, 27 нанометров сейчас, где-то так вот. Ну и причем давно уже предвещают
[11:31.560 --> 11:35.360]  конец этого процессора, что вот все, вот уже меньше нельзя, но вот пока что еще вот меньше
[11:35.360 --> 11:42.560]  удаётся делать. А это значит, что на один процессор можно очень много транзисторов выделить,
[11:42.560 --> 11:47.480]  а куда их собственно использовать непонятно, и поэтому естественные решения технологов,
[11:47.480 --> 11:53.440]  вот здесь они, аппаратчики идут впереди алгоритмистов. Давайте сделаем два процессорных ядра на одном
[11:53.440 --> 11:59.580]  кристалле, скажем, что это процессор двухядерный, это два процессора, ну это два процессора. Вот там
[11:59.580 --> 12:07.880]  четыре процессора, 48 процессоров, если посмотреть первый список строчку, вот топ-500, там 48 процессоров
[12:07.880 --> 12:16.400]  для счета внутри одного кристалла, это 48 процессоров, 48 ядер, да еще четыре сервисных, там их 52,
[12:16.400 --> 12:22.900]  но вот программисты 48. И вот за счет параллельности, за счет параллельности вы повышаете общую
[12:22.900 --> 12:28.520]  производительность системы, это здорово, но вы берете последовательную программу, запускаете ее,
[12:28.520 --> 12:33.640]  она не работает быстрее, она работает со скоростью одного процессорного ядра, у вас нету шанса
[12:33.640 --> 12:38.640]  существенно ее ускорить, нет, немного она ускоряется, она ускоряется как раз вот за счет того,
[12:38.640 --> 12:45.000]  что компилятор некоторые вещи видит, которые можно сделать одновременно, ну вот кое-что я
[12:45.000 --> 12:51.800]  уже перечислил, ну что-то еще, например, он может увидеть, что у вас есть операция сложения двух
[12:51.800 --> 12:58.960]  векторов, вы ее в цикле запрятали, а компилятор может это понять и одновременно складывать не по
[12:58.960 --> 13:06.600]  одному числу, а по четыре числа, вот два вектора складываем, по четыре числа сразу, компилятор в
[13:06.600 --> 13:12.280]  состоянии это сделать, это не очень интеллектуальная операция, хотя она тоже требует в общем-то усилий
[13:12.280 --> 13:19.120]  со стороны компиляторщиков, но это тем не менее плохо масштабируемая вещь, то есть процессоров-то
[13:19.120 --> 13:28.920]  сейчас счет идет уже на миллионы, вот нам обещали еще к 18 году, где-то в 16 году, обещали сделать
[13:28.920 --> 13:36.640]  систему на 10-18 операций в секунду, вот экзофлопс пресловутый, да, в 18 году здесь 18 операции,
[13:36.640 --> 13:41.800]  очень красиво звучит, я сказал, что давно уже производительность ядра толком не растет, она
[13:41.800 --> 13:52.720]  порядка одного там 10 гигагерц, гигафлопс, да, ну так, условно, ну то есть их там 10-7 штук должно быть,
[13:52.720 --> 13:58.960]  вот 10-7 процессоров, которые должны работать согласованы над решением одной вашей задачи,
[13:58.960 --> 14:03.760]  вот у вас всегда есть возможность такой суперкомпьютер использовать иначе, вы можете
[14:03.760 --> 14:09.880]  сказать, так, у меня большая система, давайте все ко мне, вот сотня рабочих групп по стране и по миру,
[14:09.880 --> 14:17.120]  каждому по 10 процессоров, мы используем суперкомпьютер, вот HPC она не про это, HPC про то,
[14:17.120 --> 14:21.840]  что вы берете весь компьютер или половину и используете решение одной задачи, вот там моделируете
[14:21.840 --> 14:30.840]  столкновение галактик, например, или моделируете винт вертолета, где галактика, где вертолет,
[14:30.840 --> 14:40.040]  а на самом деле, что сложнее, это еще надо подумать, потому что у вас очень разномасштабные процессы,
[14:40.040 --> 14:47.480]  вот при моделировании таких сложных систем протекают, и вы должны с высоким разрешением
[14:47.680 --> 14:54.960]  выполнять вычисления, вот для того, чтобы понять, где рождается шум у вертолетного винта и какую
[14:54.960 --> 15:00.720]  нужно сделать форму винта, чтобы вот этот шум был меньше, то есть есть вот амбициозные цели довести
[15:00.720 --> 15:10.080]  шум истребителя до хабанинного писка лет через 10-15, но с вертолетами тоже хотят потише, вот тот звук,
[15:10.080 --> 15:16.400]  который мы слышим, вот тарахтение от вертолета, это ударная волна, ударная волна от лопастей,
[15:16.400 --> 15:20.680]  вот они проходят мимо нас, от каждого лопастя распространяется ударная волна, мы ее слышим
[15:20.680 --> 15:26.160]  каждый раз, на каждом обороте, не двигатель шумит, это вот винт шумит, несущий винт вертолета,
[15:26.160 --> 15:32.480]  и для того, чтобы аккуратно промоделировать, вам нужна очень большая вычислительная мощность,
[15:32.480 --> 15:39.320]  то есть были международные проекты, вот был проект прецезионного расчета шума от конструкции самолета,
[15:39.320 --> 15:46.480]  от лайнера, от шасси, то есть понять, где шум возникает, вот есть только шасси, она шумит,
[15:46.480 --> 15:52.320]  где она шумит, на самой стойке, сзади, где, эксперимент не очень-то поставишь, эксперимент
[15:52.320 --> 15:59.120]  можно ставить, но вы его будете ставить где, в ординамической трубе, ординамическая труба сама по себе
[15:59.120 --> 16:06.960]  шумит так, что мало не покажется, это цех, размером вот с этот корпус, цех металлический, который
[16:06.960 --> 16:13.720]  резонирует, когда у вас включаются вентиляторы этой самой трубы, уловить там шум от вашей конструкции,
[16:13.720 --> 16:22.880]  это тоже задача, это тоже задача для HPC, получить картину шума общую, и оттуда вырезать шум цеха,
[16:22.880 --> 16:30.680]  и посмотреть, а что же шумит, как шумит ваша конструкция, так вот, их много этих очень устроится,
[16:30.680 --> 16:41.160]  вот их там 10, 8, 10, 7, как я сказал, с оценками можно ошибаться, вот несколько лет назад я говорил,
[16:41.160 --> 16:48.440]  что там будет миллиард исполнительных устройств, но как посчитать, потому что одно дело единиц,
[16:48.440 --> 16:54.160]  которыми вы можете управлять, там миллиард или нет, а другое дело, сколько на микроуровне устройств,
[16:54.160 --> 17:00.040]  ну вот вы знаете, что в процессорах стандартных есть такая вещь, как расширение векторное,
[17:00.040 --> 17:05.520]  вы именно непосредственно можете, конечно, управлять когда-то для некоторых алгоритмов,
[17:05.520 --> 17:09.720]  вот сколько там таких устроит, вот таких устройств, там уже счет идет на миллиарды,
[17:09.720 --> 17:14.120]  когда у вас графическая карта, вроде это одно устройство, но там внутри у вас 700
[17:14.120 --> 17:23.400]  метеотрядовых устройств, и вот их тоже уже на миллиарды, а для того, чтобы вы суперкомпьютерную
[17:23.400 --> 17:29.680]  мощность использовали для решения задачи, чтобы она была полезна, вы должны, во-первых,
[17:29.680 --> 17:35.360]  иметь задачу, в которой вот этот прелизм внутренний, он есть, хотя бы потенциально,
[17:35.360 --> 17:41.240]  что там есть операции, которые можно выполнять независимо, это первое, это требование как бы
[17:41.240 --> 17:47.400]  необходимое, потому что если их там нет, то вам бесполезно иметь много процессоров, а второе,
[17:47.400 --> 17:52.520]  это как правильно ее взять, как правильно организовать вычисление так, чтобы у вас действительно
[17:52.520 --> 18:00.280]  суперкомпьютер считал, чтобы вот эти ядра и исполнительные устройства, операционные устройства
[18:00.280 --> 18:06.880]  не мешали друг другу, не ждали друг друга, чтобы были минимальные накладные расходы на организации
[18:06.880 --> 18:15.280]  вычислений. Собственно говоря, они есть, эти расходы, даже когда у вас один процессор. Вот в свое время в сети
[18:15.280 --> 18:22.200]  была замечательная лекция воеводина суперкомпьютер и КПД паровоза, в которой он популярно объяснял,
[18:22.200 --> 18:31.720]  что один процессор, одно процессорное ядро при решении обычных задач не линпака, не специального
[18:31.720 --> 18:37.000]  теста, который специально оптимизируется для того, чтобы вот здесь повыше подняться в этом списке,
[18:37.000 --> 18:44.520]  повыше производительность показать. Обычных задач корпоративных кодов, научных кодов, пакетов
[18:44.560 --> 18:52.960]  прикладных программ параллельных, она порядка трех процентов. И происходит это как раз во многом за счет того,
[18:52.960 --> 19:00.800]  что вы, первая проблема стены памяти, это означает, что вы данные, которые расположены в оперативной
[19:00.800 --> 19:07.040]  памяти, не успеваете с нужной скоростью передавать в процессор. Память работает гораздо медленнее.
[19:07.040 --> 19:15.320]  И вот список тест линпак, это решение систем линейных уравнений, он как раз там все сделано для того,
[19:15.320 --> 19:20.280]  чтобы эту проблему преодолеть, чтобы эффективно использовать кэш-процессор, регистр процессора,
[19:20.280 --> 19:28.000]  вот там все сделано для этого. А когда вы решаете свою задачу как прикладной программист,
[19:28.000 --> 19:35.560]  как специалист, которого позвали для оптимизации разработки нефтяного месторождения, вам не до теста
[19:35.560 --> 19:40.440]  линпак, вам нужно решать задачу, вам нужно понять какие там уравнения, что там по физике происходит,
[19:40.440 --> 19:47.680]  как сделать так, чтобы у вас результат вашего вычислительного эксперимента был похож на то,
[19:47.680 --> 19:53.200]  что в природе происходит, чтобы его можно было валидировать, чтобы потом можно было
[19:53.200 --> 19:58.400]  использовать госты, которые сейчас разрабатываются, использовать в производстве ваши расчеты,
[19:58.400 --> 20:06.960]  к этому все идет. Вот вам этот момент для оптимизации кэша, хотя иногда это приходится делать,
[20:06.960 --> 20:12.200]  и поэтому производительность одного процессора на уровне нескольких процентов от того, что он
[20:12.200 --> 20:19.120]  мог бы делать, вы его далеко не полностью используете. А потом на это накладывается еще
[20:19.120 --> 20:23.880]  эффективность использования нескольких процессоров, которые могут быть по-разному соединены,
[20:23.880 --> 20:28.240]  они могут быть на общей оперативной памяти, многоядерной системе, но по определению
[20:28.240 --> 20:33.100]  имеет доступ к общей оперативной памяти если несколько ядер, каждый из этих яpu entitled
[20:33.100 --> 20:38.680]  имеет возможность адресовать любую ичейку оперативной памяти, а могут быть на распределенной
[20:38.680 --> 20:43.920]  оперативной памяти, если у вас объединена сеть ноутбуки, то вот будет система с распределенной
[20:43.920 --> 20:51.120]  оперативной памяти, и там своя эффективность, вы тот алгоритм, который у вас последовательно
[20:51.120 --> 20:54.680]  выполнялся за час, на десяти процессорах он не будет за 6 минут выполняться,
[20:54.680 --> 20:59.600]  он будет выполняться скорее всего там дольше. Возможно и обратно ситуация,
[20:59.600 --> 21:07.280]  но скорее всего будет дольше выполняться. И наша зона внимания будет как раз вот в этой
[21:07.280 --> 21:14.040]  части. Как использовать один процессор? Это отдельная история, и ее освещать довольно
[21:14.040 --> 21:23.040]  тяжело. Ну хотя бы потому, что с течением времени меняется причина, по которой процессор работает
[21:23.040 --> 21:28.920]  хуже, чем мы думаем. Иногда это связано действительно с тем, что мы не очень аккуратно используем
[21:28.920 --> 21:36.200]  кэш-память. И некоторые рекомендации в этом смысле в наших лекциях будут, и я буду рассказывать
[21:36.200 --> 21:42.040]  о способе, который позволяет вроде как на ровном месте существенно выигрывать производительность,
[21:42.040 --> 21:50.640]  просто из-за того, что существенно поменялся порядок вычислений. Но это только одна причина.
[21:50.640 --> 22:00.000]  А я уже сказал, что аппаратчики, вот те, кто делает аппаратуру, процессоры, они обгоняют
[22:00.000 --> 22:07.640]  алгоритмистов очень сильно. И сейчас довольно существенная причина того, что процессор работает не так,
[22:07.640 --> 22:14.320]  как вы думали. Такие вещи, как спекулятивное вычисление. Вы думаете, что вы написали программу,
[22:14.320 --> 22:20.720]  в ней есть ветвление, и там у вас и в что-то такое больше нуля, и это что-то больше нуля,
[22:20.720 --> 22:25.800]  а вы думаете, что выполняется левая веточка, которая соответствует больше нулю. А процессор
[22:25.800 --> 22:31.600]  выполняет обе веточки. И уследить за этим на нашем уровне, на уровне системного, нет,
[22:31.600 --> 22:37.760]  прикладного программиста. Системный программист, может быть, за этим уследит. А вот прикладной
[22:37.760 --> 22:44.080]  вряд ли. А в результате процессор выполняет гораздо больше операций, чем вы думали. Ну, естественно,
[22:44.080 --> 22:53.040]  он тратит на это больше времени. Поэтому вот в эту сторону нам сложно копать, я не берусь. А вот
[22:53.040 --> 23:00.640]  пообсуждать и понять, как распределить работу между процессорами так, чтобы с нашей точки зрения
[23:00.920 --> 23:06.240]  мы наиболее эффективно использовали много процессоров. Вот этим мы будем заниматься. Вот это
[23:06.240 --> 23:15.160]  вот вещь, на которую мы можем влиять непосредственно, и которая нас будет интересовать. Значит,
[23:15.160 --> 23:26.560]  я как бы сразу некоторую антирекламу сделаю, Курса, чтобы не было иллюзий. Я вот сейчас называл
[23:26.560 --> 23:33.160]  системы, в которых много процессоров, они между собой могут быть по-разному связаны. Они могут
[23:33.160 --> 23:38.280]  быть связаны общей памятью, распределенной памятью, с помощью сети передач и данных,
[23:38.280 --> 23:43.720]  например. Они могут быть вообще не связаны, но при этом работать согласовано, как единое целое.
[23:43.720 --> 23:52.400]  Это векторная система. Векторная система предполагает, что у вас несколько исполнительных устройств над
[23:52.400 --> 23:57.280]  разными данными выполняет одну и ту же команду, например, складывает по элементам два вектора,
[23:57.280 --> 24:06.800]  или вычитает, или умножает. Вот что в таком духе делают. Вот хороший пример, близкий пример,
[24:06.800 --> 24:14.200]  живой такого сорта системы, это графические карты. Там вы когда запускаете свою программу,
[24:14.200 --> 24:24.280]  вы на самом деле запускаете одновременно поток из большого количества. Поток,
[24:24.280 --> 24:31.360]  выполняющий много одинаковых операций над разными данными. И это своя наука, как правильно сделать,
[24:31.360 --> 24:36.680]  чтобы это хорошо работало. Если у вас в такой конструкции, не дай бог, есть ветвление, то вот
[24:36.680 --> 24:44.240]  смотри пункт первый. Процессор не знает, что будет, он выполняет обе веточки. А хуже,
[24:44.240 --> 24:50.840]  если у вас вектор данных, над ними выполняется одна и та же операция, и вот над элементами вектора
[24:50.840 --> 24:55.680]  стоят, если элемент больше или меньше. И для половины он больше, а для половины он меньше.
[24:55.680 --> 25:01.160]  Ну все, он будет выполнять обе веточки, причем не одновременно, а последовательно, процессор.
[25:01.160 --> 25:06.200]  Так вот, все, что связано с программированием графических карт и так далее,
[25:06.200 --> 25:14.840]  непосредственно в лекциях я рассматривать не буду. Но я буду говорить о некоторых
[25:14.840 --> 25:19.280]  средствах автоматизации разработки параллельных программ, и если все сложится нормально,
[25:19.280 --> 25:28.040]  будет одна или две лекции, посвященные системе DBM. А некоторые те, кто находится у нас на базе,
[25:28.120 --> 25:34.640]  познакомиться с ней, я думаю, еще раньше. DBM и DBMH это система автоматизации разработки
[25:34.640 --> 25:38.360]  параллельных программ. Вот это отдельная история, на каких языках вообще писать для
[25:38.360 --> 25:44.520]  параллельных систем, для многопроцессорных систем, на чем писать. Но мы будем иметь в виду Си,
[25:44.520 --> 25:50.280]  в основном. Вот я буду рассказывать, имею в виду Си. На фортране кто-нибудь пишет?
[25:50.280 --> 26:02.920]  Раньше руки поднимались, а на ассембляре? Ну нет, на ассембляре писать не будем, хотя,
[26:02.920 --> 26:10.200]  если кто-то там welcome, что называется для ускорения, все средства хороши. Так вот,
[26:10.200 --> 26:19.880]  это Си, это обычный Си. Языки-то бывают разные, и когда появились массово, распространились первые
[26:19.880 --> 26:26.800]  параллельные системы, вот именно пошли, действительно очень такое широкое распространение
[26:26.800 --> 26:36.640]  получили, транспитерные системы. Они были одновременно, они были позже сделаны, чем язык
[26:36.640 --> 26:43.240]  программирования для них. Было язык программирования АКАМ, вот такой философ известный, да, Лезвий АКАМ,
[26:43.240 --> 26:47.320]  Бритова АКАМа, который говорит о том, что не надо придумывать сущности, надо обходиться
[26:47.320 --> 26:56.720]  минимальным числом понятий. Так вот, был придуман язык АКАМ, создан, который был изначально ориентирован
[26:56.720 --> 27:03.760]  на параллельную обработку. У него внутри языка были параллельные конструкции. Язык мощный, хороший,
[27:03.760 --> 27:09.400]  но он не прижился. Он не прижился, во-первых, потому что сами транспитеры жили относительно
[27:09.400 --> 27:21.360]  недолго. Хотя это было такое очень грамотное и хорошее решение. Это были кристаллы, процессоры,
[27:21.360 --> 27:28.360]  ни одного сгоревшего я не видел, они были с военной приемкой, они летали в бортовых комплексах,
[27:28.360 --> 27:35.440]  в космосе и где хотите. И они на борту содержали каналы связи, четыре канала передачи связи.
[27:35.440 --> 27:42.160]  Вот мы Азернет отдельно подключаем плату, на материнской плате часто у нас есть интерфейс Азернет,
[27:42.160 --> 27:48.000]  а там были линки, которые были прямо в процессоре. И относительно простыми вот этими линками это
[27:48.000 --> 27:54.440]  были четыре проводочка, никак не экранированных, можно было соединять сколько угодно их и получать
[27:54.440 --> 28:00.440]  параллельную систему. Но тем не менее, они прожили недолго, производительность каждого такого транспьютера,
[28:00.440 --> 28:06.400]  если говорить о плавающей запятой, была порядка одного мегафлопа, миллионы операций в секунду с плавающей
[28:06.400 --> 28:13.960]  запятой. Это был кристалл вот такой вот. Один мегафлоп в свое время это была машина БСМ-6,
[28:13.960 --> 28:20.440]  два зала, один сверх, второй снизу с питанием, с охлаждением, подвал с охлаждением, вот три зала.
[28:20.440 --> 28:30.400]  Так вот, потом была попытка их дальше продлить их жизнь за счет процессоров там Т9,
[28:30.760 --> 28:37.320]  но совсем не прижились. Они прижились потому, что параллельно развивалась очень интенсивно,
[28:37.320 --> 28:46.400]  процессорные технологии развивались, и появились процессоры U860, объемовские пауры, и транспьютеры
[28:46.400 --> 28:50.520]  стали использовать просто как коммуникационные процессоры. Ну а в этом качестве они, естественно,
[28:50.520 --> 28:54.280]  некоторое время жили, а потом не выдержали конкуренции со специальными адаптерами.
[28:54.280 --> 29:02.440]  Так вот, там был язык АК, и он вместе с процессорами, вместе с транспьютерами так вот и пропал.
[29:02.440 --> 29:13.480]  А языки общего назначения, C, FORTRAN, дополненные библиотеками передачи данных, синхронизации
[29:13.480 --> 29:19.840]  примитивов, ну вот всем, что нужно, обвязка, позволяющая запускать параллельные программы,
[29:19.840 --> 29:25.120]  ведь вы, когда обычно набираете команду, вот у себя в терминале в ринуксовом, или там под
[29:25.120 --> 29:30.520]  Windows на Enter нажимаете на каком-нибудь экзофайле, он запускается локально, она теперь нужно
[29:30.520 --> 29:36.160]  запускать на многопроцессорной системе, не только у вас, а еще и у соседа, если он через канал
[29:36.160 --> 29:43.280]  связи подключен к вам. Вот вся эта обвязка, вот она была сделана поверх языков общегоупотребимых.
[29:43.280 --> 29:50.680]  Плохо это или хорошо? Наверное, можно найти минусы, но я считаю, что это хорошо, потому что это
[29:50.680 --> 29:57.160]  позволяет нам с вами оставаться в рамках тех парадигм, которые нам и так привычны. И вот основная
[29:57.160 --> 30:06.360]  парадигма, в рамках которой мы будем работать, это слабосвязанные параллельно выполняющиеся
[30:06.360 --> 30:12.720]  независимые процессы, то есть у нас есть некоторое количество процессов, мы пишем некоторое количество
[30:12.720 --> 30:19.840]  программ, каждый из которых выполняется в своем процессе. Возможно, это одна программа, просто у нее
[30:19.840 --> 30:25.760]  на входе есть номер процессора и она делает ту часть работы, которая ей предназначена согласно
[30:25.760 --> 30:31.720]  номеру. Но вот эта идея, что мы пишем некоторое количество последовательных программ, которые
[30:31.720 --> 30:37.480]  между собой иногда взаимодействуют, иногда передают данные и иногда обращаются к общим данным в
[30:37.480 --> 30:46.600]  оперативной памяти. Вот эта вот идея плодотворна, она позволяет нам оставаться в рамках привычного
[30:46.600 --> 30:56.000]  нам понимания сути программирования и описания алгоритмов на привычном нам языке, но при этом дает
[30:56.000 --> 31:02.800]  возможность использовать параллельные системы. Это не единственный способ выражать свои мысли и не
[31:02.800 --> 31:09.960]  единственный способ использовать параллельную систему. В той же системе DVM, например, вы вот этого
[31:09.960 --> 31:16.520]  не делаете, вы пишете один код, последовательный код, а система автоматически вот этим занимается,
[31:16.520 --> 31:24.280]  но не для любого кода, для кода, который ориентирован на определенный круг задач, ну, например, на
[31:24.280 --> 31:30.160]  решение тех же задач механики сплошной среды, если у вас есть расчетная сетка большая достаточно,
[31:30.160 --> 31:44.000]  вы покрыли область двумерную ячейками, у вас этих ячеек N1 на N2, то вот система DVM автоматически
[31:44.000 --> 31:51.040]  может разложить работу связанная с обработкой вот этих ячеек на несколько процессоров, и вы
[31:51.040 --> 31:57.920]  тогда не должны беспокоиться о низком уровне, и это здорово, и для некоторых задач это решение
[31:57.920 --> 32:04.160]  действительно хорошее решение, DVM не единственная система, но вот она живая, есть разработчики,
[32:04.160 --> 32:09.520]  ее можно пользоваться, но тем самым вы сужаете круг задач, которые вы можете рассматривать,
[32:09.520 --> 32:15.400]  вот они вот такие, тут вычисления-то могут быть любые, но тем не менее идеологически это некая
[32:15.400 --> 32:21.240]  расчетная сетка, и вы с ней что-то делаете, и что-то делаете хорошо при условии, что у нас тут
[32:21.240 --> 32:27.200]  однородное вычисление, ну, например, мы теплопроводно считаем в каждом узле расчетной сетки,
[32:27.200 --> 32:33.520]  мы находим среднеархиметическое четырех соседних величин, и мы получаем некоторую новую величину,
[32:33.520 --> 32:42.800]  моделируем процесс распространения тепла или там диффузию, грубо говоря, но если у вас вычисление
[32:42.800 --> 32:47.720]  не однородное, если у вас где-то здесь больше вычисления, где-то меньше, ну, например, где-то у
[32:47.720 --> 32:53.760]  вас свечка горит, и там нужно посчитать еще и химию, то вот такой простой подход, он уже оказывается не
[32:53.760 --> 32:59.600]  очень эффективен, и вам все равно надо понимать, что происходит на нижнем уровне, и поэтому мы
[32:59.600 --> 33:09.280]  будем изучать именно алгоритмы, которые вот в таком стиле выполняются, каждый на своем процессоре,
[33:09.280 --> 33:15.000]  и при этом иногда взаимодействует с соседями, но в основном выполняется автономно, в результате
[33:15.000 --> 33:19.400]  вы имеете возможность писать эффективные последовательные коды, которые между собой
[33:19.400 --> 33:23.560]  взаимодействуют, и дальше у вас задача минимизировать это взаимодействие, сделать так,
[33:23.560 --> 33:29.480]  чтобы работа была сбалансированной, чтобы каждый процессор делал полезное дело в основном,
[33:29.480 --> 33:35.600]  и только иногда передавал данные соседям или там что-то еще делал, ожидал других. Вот это то,
[33:35.600 --> 33:40.240]  чем будем заниматься, и в этом смысле СИС здесь очень даже уместен, и фортрон тоже, ну,
[33:40.240 --> 33:47.880]  мне так нет, хотя на фортроне остались большие библиотеки, которые постепенно портируются,
[33:47.880 --> 33:57.280]  конечно, но где-то используются в первозданном виде. То есть вот основная вот концепция,
[33:57.280 --> 34:04.160]  мы будем писать алгоритмы, описывая вот эти вот последовательные веточки, то есть если у нас
[34:04.160 --> 34:08.480]  тысячи процессоров, понятно, что тысячу алгоритмов мы не напишем, но устанем просто,
[34:08.480 --> 34:13.880]  поэтому мы очевидным образом будем писать провентализуемые алгоритмы, то есть мы будем
[34:13.880 --> 34:19.680]  возможно писать управляющий какой-то, а остальные будут на вход принимать, ну, например,
[34:19.680 --> 34:32.640]  вот две классические величины, число процессоров и номер процессора. Ну, вот эти слова они часто
[34:32.640 --> 34:40.120]  встречаются, когда пишешь с помощью интерфейса параллельного программирования message passing
[34:40.120 --> 34:49.720]  interface, то есть MPI это то, что вам надо будет знать, но то, что я вам рассказывать не буду. Его вам
[34:49.720 --> 34:59.160]  будут рассказывать на семинарах, и детали как, что интерфейс достойный, очень много всего умеет,
[34:59.160 --> 35:05.000]  там 300 с лишним под программой, если не больше уже, а мы из них будем на лекциях использовать
[35:05.000 --> 35:09.680]  буквально десяток, этот десяток мы будем использовать в таком обобщенном виде операции
[35:09.680 --> 35:14.080]  передачи данных, получения данных, синхронизации, барьерная синхронизация и так далее, их там вот не
[35:14.080 --> 35:20.720]  очень много будет, а потом уже каждый из них, она может разворачиваться в целый набор других
[35:20.720 --> 35:27.560]  операций, то есть вот MPI это первый интерфейс, который, я очень надеюсь, у всех будет практика,
[35:27.560 --> 35:32.680]  во всяком случае все последние годы так было, и это позволяет вот учиться плаванию не в сухую,
[35:32.680 --> 35:38.200]  а действительно попробовать параллельный алгоритм и посмотреть, а что же получается, и вы удивитесь,
[35:38.200 --> 35:47.240]  но по моим наблюдениям у большинства получается как-то не очень, и что печально, большинство это не
[35:47.240 --> 35:52.880]  осознает, то есть берем программу, она работает минуту, запускаем ее на 5 процессорах, она работает
[35:52.880 --> 35:58.680]  20 минут, и человек счастлив, она работает параллельно, но вот хорошо бы, чтобы она работала меньше минуты,
[35:58.680 --> 36:05.600]  вот вы когда параллельную программу будете писать, вы все-таки этим озаботьтесь, она должна работать не
[36:05.640 --> 36:10.640]  просто быстрее, чем ваша последовательная, она должна работать быстрее, чем самая хорошая
[36:10.640 --> 36:19.120]  последовательная, иначе зачем вам параллельный алгоритм, вот это мотив, зачем курс нужен, вот это
[36:19.120 --> 36:26.040]  вот та точка, которая определяет, зачем нужен курс, я начал со слов, что написание параллельных
[36:26.040 --> 36:32.120]  алгоритмов дело в общем-то хлопотное, потому что человек, не, внутри он там наверняка думает
[36:32.120 --> 36:36.800]  параллельно, но я не специалист, не знаю как, никто по-моему не знает, но вот излагает свои мысли,
[36:36.800 --> 36:40.840]  он последовательный, я вот стою здесь, и вот поток идет последовательный, и вы воспринимаете
[36:40.840 --> 36:45.320]  последовательное, а вам надо написать параллельную программу, надо одновременно помнить о нескольких
[36:45.320 --> 36:52.960]  потоках исполнения, вообще-то это напрягает, это довольно сложно, вот есть особенности
[36:52.960 --> 36:57.160]  параллельных программ, которые мешают, они недотерминированы, они склонны к дедлокам, там
[36:57.160 --> 37:05.400]  много всего есть неприятного, и поэтому первое желание как-то вот понять, ради чего, вот я ее
[37:05.400 --> 37:10.640]  напишу эту параллельную программу, она будет быстрее работать или нет, и вот для этого и нужен курс,
[37:10.640 --> 37:18.240]  курс нужен для того, чтобы вы могли до написания параллельной программы оценить, насколько она
[37:18.240 --> 37:25.080]  потенциально при самом хорошем раскладе позволит вам ускориться, ну я эти слова часто произношу,
[37:25.600 --> 37:31.420]  вот есть время выполнения последовательной программы, а есть время выполнений программы
[37:31.420 --> 37:39.300]  на «П» процессорах, вот это вот ускорение, это ускорение параллельной программы, отношение
[37:39.300 --> 37:45.320]  время работы одного на одном процессоре к «П» процессорам, так вот к работе на «П» процессорам.
[37:45.320 --> 37:49.400]  Ну можно ещё это дело разделить на «П» и получить эффективность использования
[37:49.400 --> 37:57.620]  в разъёме мощности процессоров равняется sp делим на p вот эти две величины они
[37:57.620 --> 38:02.300]  вот будут постоянно звучать так вот до того как вы начнете писать последовать
[38:02.300 --> 38:06.700]  параллельную программу неплохо было бы понять будет ли она работать быстрее
[38:06.700 --> 38:16.020]  если там ресурс внутреннего параллелизма и возможно возможно надо подумать о том
[38:16.020 --> 38:20.420]  а может быть можно другой последовательный алгоритм взять который
[38:20.420 --> 38:24.660]  просто решить задачу за нужное вам время одно вас считается 10 минут может
[38:24.660 --> 38:28.460]  быть если вы возьмете другой алгоритм вы сможете на одном процессоре посчитать
[38:28.460 --> 38:32.740]  за минуту и то дать надо сделать а вот потом же именно
[38:32.740 --> 38:36.420]  с этим временем вот в самом лучшем последовательном вот именно с ним и
[38:36.420 --> 38:41.020]  сравнивайте вот самый быстрый последовательный алгоритм берем и с ним
[38:41.020 --> 38:45.900]  сравним и мы на некоторых лекций будем этим заниматься мы будем отдельно
[38:45.900 --> 38:50.020]  смотреть, какой алгоритм взять в качестве опорного
[38:50.020 --> 38:53.060]  в качестве самого быстрого, ну из тех, что мы можем
[38:53.060 --> 38:54.060]  придумать.
[38:54.060 --> 38:57.220]  Пока я звездочку не поставил, самый быстрый алгоритм
[38:57.220 --> 39:00.140]  определения было конструктивное, есть программа, запустили
[39:00.140 --> 39:03.820]  на одном процессоре, а скорее всего вообще не работает,
[39:03.820 --> 39:05.420]  потому что она параллельная, и на одном процессоре,
[39:05.420 --> 39:07.940]  скорее всего, работать не будет, если вы так не написали
[39:07.940 --> 39:08.940]  специально.
[39:08.940 --> 39:11.660]  Но тем не менее, какой-то последний алгоритм у вас
[39:11.660 --> 39:15.020]  есть, и поделили на время работы параллельные программы,
[39:15.020 --> 39:16.420]  и получили ответ.
[39:16.420 --> 39:19.380]  А вот где взять самую быструю?
[39:19.380 --> 39:22.860]  Никто не знает, где ее взять, поэтому мы будем брать ту,
[39:22.860 --> 39:26.460]  которую сможем сделать сами в самую быструю, и сравнивать
[39:26.460 --> 39:27.460]  с ней.
[39:27.460 --> 39:31.340]  И вот если здесь у вас на уровне оценки алгоритма,
[39:31.340 --> 39:33.260]  да, вот вы посмотрите, сколько там операций, сколько там
[39:33.260 --> 39:35.580]  операций будет выполняться в последовательности,
[39:35.580 --> 39:39.060]  сколько параллельно, сколько операций идет на обмен данными,
[39:39.060 --> 39:42.500]  на синхронизацию, и если ваша оценка покажет, что,
[39:42.660 --> 39:45.980]  стоит попробовать, что на 10 процессорах 8 раз быстрее
[39:45.980 --> 39:50.580]  мы можем ожидать, вот тогда, да, можно писать параллельную
[39:50.580 --> 39:51.580]  программу.
[39:51.580 --> 39:53.780]  А если эта оценка покажет, что никакого ускорения
[39:53.780 --> 39:56.180]  не будет, а, скорее всего, будет замедление, такое
[39:56.180 --> 39:57.180]  и бывает.
[39:57.180 --> 40:00.540]  Ну, наверное, надо что-то другое делать, наверное,
[40:00.540 --> 40:02.900]  не надо писать вот эту параллельную программу, которая будет
[40:02.900 --> 40:04.060]  работать все равно плохо.
[40:04.060 --> 40:07.900]  Может быть, надо взять другой алгоритм, на основе
[40:07.900 --> 40:10.380]  которой вы будете делать параллельную программу,
[40:10.420 --> 40:12.420]  и такие примеры тоже будут.
[40:12.420 --> 40:16.820]  Будут примеры алгоритмов, которые хороши как последовательные,
[40:16.820 --> 40:22.180]  они быстрее всех остальных работают, но они не распараллеливаются.
[40:22.180 --> 40:25.700]  А для того, чтобы сделать хорошую параллельную программу,
[40:25.700 --> 40:28.860]  надо взять плохой последовательный алгоритм, который работает
[40:28.860 --> 40:32.500]  медленно, но зато очень высокой ресурс параллелизма
[40:32.500 --> 40:35.340]  содержит, там много операций, которые можно делать одновременно
[40:35.340 --> 40:36.340]  и независимо.
[40:36.340 --> 40:39.860]  И вот он тогда будет выигрывать, и будет выигрывать кратно
[40:39.860 --> 40:40.860]  в разы.
[40:40.860 --> 40:45.420]  Вот это основной мотив, почему параллельные алгоритмы,
[40:45.420 --> 40:49.140]  почему их надо изучать, чтобы не тратить свое время
[40:49.140 --> 40:53.860]  на разработку программ, которые заведомо не будут
[40:53.860 --> 40:58.100]  работать, и не создавать тем самым проблемы себе
[40:58.100 --> 41:00.820]  и антирекламу отрасли в целом.
[41:00.820 --> 41:04.180]  Потому что параллельная система – это то, что мы
[41:04.180 --> 41:08.340]  имеем других способов ускорить вычисление, мы на сегодняшний
[41:08.340 --> 41:09.340]  день не видим.
[41:09.340 --> 41:13.220]  Я сейчас не говорю про квантовые компьютеры, я про них практически
[41:13.220 --> 41:15.460]  ничего не знаю, у нас позиция очень простая.
[41:15.460 --> 41:18.540]  Вот нам дадут квантовый компьютер, квантовый процессор,
[41:18.540 --> 41:20.540]  дадут правила работы с ним, вот тогда мы будем с ним
[41:20.540 --> 41:21.540]  работать.
[41:21.540 --> 41:24.580]  А пока что нам никто его не дал.
[41:24.580 --> 41:28.580]  Те редкие примеры, которые есть, там D-Wave-система, там
[41:28.580 --> 41:32.380]  до сих пор разговоры идут о том, совсем он квантовый
[41:32.380 --> 41:35.780]  или квантовый отжига, что там за система, ну в общем,
[41:35.780 --> 41:36.780]  все еще впереди.
[41:37.180 --> 41:41.980]  Это вот раз, а второе – класс алгоритмов, которые сегодня
[41:41.980 --> 41:44.420]  умеют решать на квантовых компьютерах сегодняшнего
[41:44.420 --> 41:50.340]  дня, он просто вот там раз-два-три, ну там Grover, в общем, их несколько
[41:50.340 --> 41:51.340]  всего.
[41:51.340 --> 41:57.780]  А это система общего назначения, поэтому мы будем про них
[41:57.780 --> 41:58.780]  говорить.
[41:58.780 --> 42:02.300]  Значит, еще про что мы не будем говорить.
[42:02.300 --> 42:06.760]  Насколько я знаю, на фистехе есть курс, посвященный программированию
[42:06.760 --> 42:10.120]  на логических, на программируемых логических интегральных
[42:10.120 --> 42:11.120]  схемах, ПЛИС-ах.
[42:11.120 --> 42:18.680]  Кто-нибудь слышал про ПЛИС-ы, FPGA, надеюсь, что кто-нибудь
[42:18.680 --> 42:19.680]  дослышал.
[42:19.680 --> 42:23.120]  Значит, тут я хочу следующие слова сказать, мы не будем
[42:23.120 --> 42:27.560]  их рассматривать не потому, что это неинтересно, FPGA – это
[42:27.560 --> 42:33.040]  одно и то же и ПЛИС, просто наше их название, а потому
[42:33.120 --> 42:38.640]  что это предмет отдельного курса, и надо быть специалистом
[42:38.640 --> 42:43.600]  в этой области, у меня только общие сведения, а они все
[42:43.600 --> 42:49.440]  больше распространяются, их все проще попробовать.
[42:49.440 --> 42:52.320]  Во-первых, они уже дешево, что они позволяют сделать?
[42:52.320 --> 42:56.000]  Вот это тоже специальный вид процессора, что он
[42:56.000 --> 42:57.640]  позволяет сделать?
[42:57.640 --> 43:03.240]  Он позволяет взять ваш алгоритм и сделать процессор, который
[43:03.240 --> 43:06.000]  выполняет именно ваш алгоритм, только ваш алгоритм, и больше
[43:06.000 --> 43:07.000]  ничего.
[43:07.000 --> 43:15.320]  И коль скоро я сказал, что обычный процессор работает
[43:15.320 --> 43:21.320]  с эффективностью 3%, вот эта штука работает с эффективностью,
[43:21.320 --> 43:24.520]  если все правильно сделано, близко к 100%, но это десятки
[43:24.520 --> 43:28.840]  процентов, во всяком случае, и на определенном классе
[43:28.840 --> 43:33.240]  задачи эта штука, вот эти процессоры, которые вы
[43:33.240 --> 43:35.640]  сделали специально под задачу, они сильно выигрывают
[43:35.640 --> 43:38.960]  в скорости, и задачи реального времени на них делают.
[43:38.960 --> 43:42.480]  Другое дело, что для того, чтобы разработать алгоритм
[43:42.480 --> 43:46.240]  для суперкомпьютера, некоторое количество материальных
[43:46.240 --> 43:50.800]  денежных знаков нужно, а чтобы разработать алгоритм
[43:51.800 --> 43:56.360]  для этой конструкции нужен чемодан денег, вот конструкция
[43:56.360 --> 43:57.360]  примерно такая.
[43:57.360 --> 43:59.920]  То есть это дорого, и дело не в том, что кто-то хочет
[43:59.920 --> 44:02.600]  себе очень много денег, а дело в том, что это действительно
[44:02.600 --> 44:08.000]  требует больших усилий и долга, нам периодически
[44:08.000 --> 44:10.400]  обещают, что это вот, да нет, все уже, вот тут языки
[44:10.400 --> 44:13.880]  есть, которые нам позволяют это делать быстро, в Таганруде
[44:13.880 --> 44:18.160]  вот этим занимаются профессионально, но масса это пока не пошло,
[44:18.160 --> 44:21.640]  поэтому я обращаю внимание на то, что это важное направление,
[44:21.640 --> 44:24.240]  это направление интересное, иметь о нем представление
[44:24.240 --> 44:28.400]  крайне желательно, уметь его использовать, тем более
[44:28.400 --> 44:32.840]  желательно, вот, и в жизни пригодиться не пропадет,
[44:32.840 --> 44:38.920]  FPGA, да, что-то я не написал, вот, но в нашем курсе этого
[44:38.920 --> 44:44.400]  не будет, пока что это еще за рамками возможностей
[44:44.400 --> 44:47.520]  обычного прикладного программиста использовать вот эти вещи
[44:47.520 --> 44:51.120]  очень специфичная область, вообще говоря требующие
[44:51.120 --> 44:57.520]  работы одновременная математика и инженера схемотехника,
[44:57.520 --> 45:04.640]  их вообще готовить перестали, но, тем не менее, вот, такие
[45:04.640 --> 45:07.920]  люди есть, и если у вас будет возможность познакомиться
[45:07.920 --> 45:12.920]  с этой технологией, я вам рекомендую, ну вот, примерно
[45:12.920 --> 45:20.400]  я рассказал, я примерно рассказал о том, что будет
[45:20.400 --> 45:27.000]  в курсе, продолжим, я сейчас хочу две вещи еще обозначить,
[45:27.000 --> 45:32.560]  значит, первая вещь связана с вопросом, а, собственно,
[45:32.560 --> 45:35.920]  где параллельная система используется, вот, я вначале
[45:35.920 --> 45:43.920]  я сказал, что HPC это наиболее интересная для меня область,
[45:43.920 --> 45:51.480]  но это не единственная вещь, где суперкомпьютеры применяются,
[45:51.480 --> 45:57.320]  я бы выделал четыре области, которые представляют интерес,
[45:57.320 --> 46:01.320]  и что важно, для этих четырех областей алгоритмы нужны
[46:01.320 --> 46:05.320]  разные, вот, разные требования к алгоритмам ставятся во
[46:05.320 --> 46:10.240]  главу угла, вот, в частности, в контексте вот этих двух
[46:10.240 --> 46:18.120]  величин, ускорение и эффективность, значит, ну, первое это HPC,
[46:18.120 --> 46:21.920]  это то, о чем мы говорили, есть, например, вот эта комната,
[46:21.920 --> 46:26.240]  вы разбиваете трехмерной расчетной сеткой кубическими
[46:26.240 --> 46:30.680]  ячейками, небольшими эту комнату на фрагменты, и
[46:30.680 --> 46:34.680]  дальше выписываете уравнение Эллера или Навъестокса,
[46:34.680 --> 46:39.800]  или еще какие-нибудь, и пытаетесь моделировать, как будет
[46:39.800 --> 46:43.800]  меняться распределение температуры, скорости воздуха,
[46:43.800 --> 46:47.720]  концентрация там нехороших веществ разных, вот в этой
[46:47.720 --> 46:53.600]  комнате, вот это вот здесь, в HPC, и совершенно так вот
[46:53.600 --> 46:57.560]  интуитивно ясно, что для решения такого сорта задач,
[46:57.560 --> 47:00.600]  если вы решаете масштабную задачу, процессоров вам
[47:00.600 --> 47:04.880]  нужно много, скорее всего, у вас их на столе меньше,
[47:04.880 --> 47:10.040]  чем вам хотелось бы, значит, вы идете в центр коллективного
[47:10.040 --> 47:15.000]  пользования и берете вычислительную мощность там, а там администрация,
[47:15.000 --> 47:18.240]  и администрация, с одной стороны, конечно, интересна,
[47:18.240 --> 47:21.240]  чтобы вы решили важную задачу, написали статью, которая
[47:21.240 --> 47:26.800]  опубликована и, значит, пошла в зачет, но с другой стороны,
[47:26.960 --> 47:30.280]  она смотрит, слушай, процессоры используются там на одну
[47:30.280 --> 47:33.680]  сотую, почти не используются, и один, и второй, и третий,
[47:33.680 --> 47:36.640]  мы выделили 200 процессоров, а программа считает всего
[47:36.640 --> 47:41.160]  вдвое быстрее, чем на одном, и вот совершенно понятно,
[47:41.160 --> 47:44.320]  что если бы вам дали не 200 процессоров, а 10, вы бы
[47:44.320 --> 47:48.880]  посчитали примерно за то же самое время, то есть
[47:48.880 --> 47:53.880]  большое количество процессоров вам, в том случае, если ускорение
[47:53.880 --> 47:56.440]  использование низкое, и вот эффективность использования
[47:56.440 --> 48:00.600]  низкое, но ее еще можно в процентах выражать, скорее
[48:00.600 --> 48:06.040]  всего, не дадут, то есть в HPC одно из требований к
[48:06.040 --> 48:09.320]  алгоритму, ну, кроме того, что он должен правильно
[48:09.320 --> 48:14.200]  работать там и так далее, относительно высокая эффективность,
[48:14.200 --> 48:19.320]  ну, я вот так сейчас условно скажу, там больше 30-50%, если
[48:19.320 --> 48:23.200]  это явные разностные схемы, то это под 90%, если это
[48:23.200 --> 48:26.880]  не явные схемы или более сложная логика, то это вот
[48:26.880 --> 48:29.880]  десятки процентов, но не проценты, вам просто не дадут
[48:29.880 --> 48:33.080]  суперкомпьютер, вам дадут от него маленький кусочек.
[48:33.080 --> 48:38.840]  Вот HPC, достаточно хорошая эффективность должна быть,
[48:38.840 --> 48:41.400]  и мы с этой точки зрения будем вот некоторое количество
[48:41.400 --> 48:42.400]  алгоритмов смотреть.
[48:42.400 --> 48:48.880]  Вот, но это не единственное, значит, на что, зачем может
[48:48.880 --> 48:52.880]  суперкомпьютер использоваться, есть такая штука, как решение
[48:52.880 --> 49:01.680]  задач реального времени, и в реальном времени требование
[49:01.680 --> 49:08.040]  совсем другое, вот я его все-таки здесь вот напишу
[49:08.040 --> 49:19.960]  третьим, просто традиционно, вот реальное время, но для
[49:19.960 --> 49:20.960]  контраста.
[49:21.960 --> 49:25.280]  Значит, вообще никого не волнует, с какой эффективностью
[49:25.280 --> 49:29.560]  решается задача, вычислительная система может простаивать
[49:29.560 --> 49:33.520]  целый год, но в тот момент, когда к вам что-то полетело,
[49:33.520 --> 49:36.320]  непонятно что, не очень понятно, и надо понять что
[49:36.320 --> 49:41.960]  летит, у вас есть секунда на то, чтобы эту задачу решить.
[49:41.960 --> 49:45.720]  Именно в эту задачу, в этот момент вся вычислительная
[49:45.720 --> 49:49.280]  система должна сработать и сделать то, что к ней требуется,
[49:49.280 --> 49:52.520]  и если при этом у нее очень большая вычислительная
[49:52.520 --> 49:56.880]  мощность почти все время простаивает, ничего страшного,
[49:56.880 --> 50:02.720]  то есть вот это область задач, в которой эффективность
[50:02.720 --> 50:05.200]  оступает на второй, на третий или на четвертый план.
[50:05.200 --> 50:13.360]  А более, скажем так, гражданский пример, это сортировочная
[50:13.360 --> 50:16.760]  станция, железнодорожная сортировочная станция,
[50:16.760 --> 50:21.160]  на удивление, те же самые транспьютеры, одно из таких
[50:21.160 --> 50:26.120]  вот применений, довольно широких было, на железнодорожных
[50:26.120 --> 50:27.120]  путях.
[50:27.120 --> 50:30.000]  У вас идут составы, идут в реальном времени, и надо
[50:30.000 --> 50:32.600]  в реальном времени решать какие составы, по каким
[50:32.600 --> 50:35.320]  стрелкам, по каким путям разводить, чтобы комплектовать
[50:35.320 --> 50:36.760]  составы, которые пойдут дальше.
[50:36.760 --> 50:41.520]  Задача реального времени, не очень важно сколько там
[50:41.520 --> 50:43.960]  будет процессоров лишних, их там должно быть столько,
[50:43.960 --> 50:48.320]  сколько нужно, чтобы обслуживать поток задач реального времени.
[50:48.320 --> 50:51.400]  Вот это вот второе применение.
[50:51.400 --> 50:56.720]  Отдельный класс алгоритмов, но мы его как таковой в наших
[50:56.720 --> 51:01.840]  лекциях, наверное, рассматривать не будем, просто за неимением
[51:01.840 --> 51:02.840]  таких задач.
[51:02.840 --> 51:09.040]  Ну, он есть, вы его себе представлять должны.
[51:09.040 --> 51:12.000]  А вот что будем рассматривать, вот здесь второй, это промежуток
[51:12.000 --> 51:15.920]  между ними, это задача обработка большие данные.
[51:15.920 --> 51:20.920]  Вот я и с ним пишу big data, хотя мне самому вот это
[51:20.920 --> 51:24.240]  словосочетание, не то что нравится или нет, оно объективным
[51:24.240 --> 51:28.960]  существует, и многие пользуются, но что это такое, вот каждый
[51:28.960 --> 51:29.960]  по-своему объяснит.
[51:29.960 --> 51:36.160]  Обработка больших объемов данных, визуализация данных,
[51:36.160 --> 51:39.080]  работа с большими коллекциями данных, работа с распределенными
[51:39.080 --> 51:45.760]  данными по сети интернета, по разным серверам, визуализация
[51:45.760 --> 51:49.160]  данных вычислительного эксперимента, вот здесь
[51:49.160 --> 51:53.400]  вот когда вы проводите расчеты, вы результаты пишете куда-нибудь
[51:53.400 --> 51:54.400]  на диск.
[51:54.400 --> 51:56.320]  Это, кстати, не обязательно, у нас будет отдельная лекция
[51:56.320 --> 51:59.480]  по визуализации, оффлайн онлайн визуализация, плюсы
[51:59.480 --> 52:03.840]  и минусы, что там можно делать, но нормальный ход, когда
[52:03.840 --> 52:07.320]  вы во время вычислений записываете данные, потом их смотрите,
[52:07.480 --> 52:10.080]  когда вы данные считаете, у вас большой суперкомпьютер
[52:10.080 --> 52:12.760]  и вам надо его использовать эффективно, а когда вы данные
[52:12.760 --> 52:16.760]  начинаете смотреть, ну вы же человек, да, вы посмотрели
[52:16.760 --> 52:19.440]  на картинку и вы пытаетесь ее осознать, в это время
[52:19.440 --> 52:23.040]  вы думаете, компьютер простаивает, и это тоже не страшно.
[52:23.040 --> 52:25.000]  Другое дело, что это не должен быть весь огромный
[52:25.000 --> 52:29.080]  суперкомпьютер, там Фугаку или кто-то еще, или Ломоносов,
[52:29.080 --> 52:31.440]  это должен быть кластер визуализации отдельный, относительно
[52:31.440 --> 52:36.640]  небольшой, который, возможно, одновременно с вами обслуживает
[52:36.640 --> 52:39.960]  и других пользователей, которые тоже любуются своими
[52:39.960 --> 52:42.720]  картинками, то есть там требования к оперативной
[52:42.720 --> 52:50.960]  памяти, как правило, высоки, а есть необходимость обеспечения
[52:50.960 --> 52:54.560]  интерактивного режима работы, вот если говорить о визуализации,
[52:54.560 --> 52:57.160]  это не режим реального времени, вы не знаете, когда к вам
[52:57.160 --> 53:01.480]  придет запрос, у вас очень мало времени на ответ, и
[53:01.480 --> 53:04.400]  не знаете, сколько их придет, вы можете закрепнуться
[53:04.480 --> 53:08.960]  в потоке, это относительно равномерный поток запросов
[53:08.960 --> 53:12.160]  от пользователя, но пользователь согласен сдать реакцию,
[53:12.160 --> 53:17.560]  если он заказал увеличение фрагмента картинки, хочет
[53:17.560 --> 53:20.520]  по детальнее ее посмотреть, несколько секунд он ждать
[53:20.520 --> 53:24.720]  готов, но если речь заходит о нескольких минутах, он
[53:24.720 --> 53:28.440]  теряет душевное равновесие, интерактивный режим не
[53:28.440 --> 53:31.840]  позволяет нам выходить за рамки десятка секунд,
[53:31.920 --> 53:36.520]  и нескольких секунд, и вот он здесь, то есть у вас
[53:36.520 --> 53:38.400]  относительно небольшие вычислительные мощности
[53:38.400 --> 53:41.360]  здесь требуется относительно, хотя для самой визуализации
[53:41.360 --> 53:45.920]  вы можете использовать сколько угодно процессоров,
[53:45.920 --> 53:52.440]  ну, фильмы, основанные сейчас на компьютерной визуализации
[53:52.440 --> 53:54.920]  просто вот уже каждый день, и никогда не знаешь, чего
[53:54.920 --> 53:58.720]  ты смотришь, живого человека или мультяшку, настолько
[53:58.720 --> 54:03.480]  уже все реалистично, вот, там тот же аватар в помощь
[54:03.480 --> 54:08.400]  и в пример, но это другое, это вы насчитываете большое
[54:08.400 --> 54:11.360]  количество кадров, а вот если вы просто изучаете
[54:11.360 --> 54:15.160]  результаты расчета, то у вас относительно небольшие
[54:15.160 --> 54:17.920]  мощности, но интерактивный режим работы, и вот здесь
[54:17.920 --> 54:20.040]  промежуточная ситуация, вы должны с одной стороны
[54:20.040 --> 54:23.160]  довольно быстро человеку сказать, значит, показать
[54:23.160 --> 54:26.240]  картинку, вот с другой стороны все-таки не так жестко
[54:26.240 --> 54:30.440]  имитировано, как здесь, так что здесь какая-то промежуточная
[54:30.440 --> 54:33.360]  ситуация, эффективность она не должна быть совсем
[54:33.360 --> 54:35.280]  низкой, потому что иначе вы будете картинку строить
[54:35.280 --> 54:38.760]  долго, но система в целом может простаивать просто
[54:38.760 --> 54:42.200]  за счет того, что человек к ней не обращается, вот,
[54:42.200 --> 54:44.160]  относительно небольшие кластеры используются вот
[54:44.160 --> 54:51.480]  здесь, либо большие, интернет, обработка больших данных,
[54:51.480 --> 54:55.800]  в общем здесь большое разнообразие и требований, и приложений,
[54:55.800 --> 55:01.400]  я почему сказал, что совершенно разное мнение про big data,
[55:01.400 --> 55:04.680]  ну потому что, например, есть еще результаты, поступающие
[55:04.680 --> 55:08.360]  с установок то, что сейчас говорят мегасаинс, там
[55:08.360 --> 55:11.480]  адронный коллайдер какой-нибудь, где на каждом метре стоит
[55:11.480 --> 55:16.520]  там десяток или сотня, ну десяток датчиков, и с них
[55:16.520 --> 55:19.760]  идет поток данных в момент проведения эксперимента,
[55:19.760 --> 55:23.720]  и это огромные объемы данных, и тоже надо уметь правильно
[55:23.760 --> 55:27.880]  сохранять с тем, чтобы потом интересующие данные можно
[55:27.880 --> 55:30.800]  было бы работать, сохранить их все просто нельзя, поэтому
[55:30.800 --> 55:36.520]  часть сохраняется и фильтруется непосредственно около установки,
[55:36.520 --> 55:39.040]  ну а часть действительно передается уже для децентрализованного
[55:39.040 --> 55:41.640]  хранения, в общем, вот эта вот область, она достаточно
[55:41.640 --> 55:47.160]  большая, и мы ее затронем краем в том смысле, что
[55:47.160 --> 55:50.520]  будем смотреть алгоритмы визуализации некоторые,
[55:50.520 --> 55:54.800]  вот как это делать, и алгоритмы декомпозиции больших сеток,
[55:54.800 --> 56:01.560]  в общем, здесь вот будут вопросы, значит, четвертой
[56:01.560 --> 56:05.600]  области не хватает, вот четвертая область, которая
[56:05.600 --> 56:09.360]  к HPC никакого отношения не имеет, но имеет самое
[56:09.360 --> 56:11.960]  непосредственное отношение к многопроцессорности,
[56:11.960 --> 56:17.240]  кто-нибудь сформулирует ограниченные многопроцессорности,
[56:17.240 --> 56:28.880]  их тут несколько, нет, зачем, где еще нужна параллельная
[56:28.880 --> 56:32.040]  система, ну просто вот совсем нужна, потому что иначе без
[56:32.040 --> 56:41.680]  нее все потеряете, это бортовые системы, космический аппарат
[56:41.680 --> 56:45.360]  запустили, и если там процессор один, то в тот момент, когда
[56:45.360 --> 56:47.360]  с ним что-то случилось, а там высокий радиационный
[56:47.360 --> 56:52.160]  фон, вы потеряли аппарат, поэтому вот любая такая
[56:52.160 --> 56:58.000]  система, и космические, и необслуживаемые, и автономные,
[56:58.000 --> 57:10.720]  и так далее, это резервирование я напишу, вместо одного
[57:10.720 --> 57:15.200]  процессора их ставят несколько одинаковых, а может и не одинаковых,
[57:15.200 --> 57:19.800]  в общем, все, что я видел одинаковых, хотя может
[57:19.800 --> 57:22.920]  быть полезнее ставить разные, не знаю, они делают одно
[57:22.920 --> 57:25.560]  и то же, они делают одно и то же и сравнивают между
[57:25.560 --> 57:28.480]  собой результаты, и если у кого-то из них результат
[57:28.480 --> 57:31.680]  вдруг разошелся, ведь не обязательно же отказ процессора,
[57:31.680 --> 57:34.520]  это ну совсем отказ, перестал откликаться, это может быть
[57:34.520 --> 57:39.840]  и переброшенный бит в оперативной памяти, но если он там
[57:39.840 --> 57:44.000]  один переброшен, и если память поддерживает протоколы
[57:44.000 --> 57:47.240]  схемы коррекции ошибок, то этот бит будет исправлен,
[57:47.240 --> 57:49.960]  но если там переброшены несколько бит, то уже нет,
[57:49.960 --> 57:54.680]  а ответ может быть неправильный, причем, по идее, опять же,
[57:54.680 --> 57:58.000]  если схема коррекции ошибок есть, то система поймет,
[57:58.000 --> 58:03.800]  что у нее ошибка, если нет, то может и не понять, и просто
[58:03.800 --> 58:07.280]  ответ другой, то есть все говорят, что надо импульс
[58:07.280 --> 58:12.400]  выдать в один ньютон, а один процессор говорит в
[58:13.080 --> 58:17.200]  кому верить, но вот большинство решает, что надо верить ему,
[58:17.200 --> 58:20.120]  и этот единственный, который выдал не тот ответ, перезапускается
[58:20.120 --> 58:22.960]  просто, вот это резервирование тоже, эффективность здесь
[58:22.960 --> 58:25.960]  очевидна какая, вот одна четверть, если их четыре,
[58:25.960 --> 58:29.060]  и никого это не беспокоит, но зато это системы повышенной
[58:29.060 --> 58:32.760]  надежности, они тоже есть, и там проверенная система
[58:32.760 --> 58:36.960]  используется, мы эти алгоритмы смотреть не будем, но мы будем
[58:36.960 --> 58:42.520]  смотреть другое, в свое время на первую позицию
[58:42.520 --> 58:50.480]  в списке топ-500 вышел китайский компьютер, ничего не предвещало,
[58:50.480 --> 58:54.800]  там всегда были американцы, японцы, американцы, и вдруг
[58:54.800 --> 59:01.560]  вот Китай, что они сделали, они собрали, не знаю, со
[59:01.560 --> 59:05.720]  всей страны или со всех геймеров графические карточки,
[59:05.720 --> 59:10.240]  и поставили их в один суперкомпьютер, и вышли, сразу они перекрыли
[59:10.240 --> 59:13.920]  производительность всех остальных, они сильно отрывались,
[59:13.920 --> 59:18.600]  но они собрали карточки у геймеров, игровые видеокарты,
[59:18.600 --> 59:22.120]  у которых вот этого вот не было, в результате эта
[59:22.120 --> 59:30.240]  система работала непрерывно, ну, масштаб часа, наши специалисты
[59:30.240 --> 59:35.680]  из Новосибирска, если я правильно помню, на ней считали,
[59:35.680 --> 59:39.280]  как они на ней считали, они брали весь этот суперкомпьютер
[59:39.280 --> 59:44.800]  и резали его на три части, вот весь суперкомпьютер,
[59:44.800 --> 59:48.560]  и запускали одну и ту же задачу, три раза, ну и смотрели
[59:48.560 --> 59:52.440]  на результаты, потом через некоторое время, через этот
[59:52.440 --> 59:56.640]  самый час одна из частей говорила, ну все, а те две продолжали
[59:56.640 --> 01:00:00.960]  считать, и там уже расходились результаты, но счет заканчивался,
[01:00:00.960 --> 01:00:06.720]  и почему, потому что это были карты бытового уровня,
[01:00:06.720 --> 01:00:11.360]  и во время расчета вот происходило то, о чем я сказал, если у вас
[01:00:11.360 --> 01:00:14.720]  на графической карточке какой-то бит вдруг переброшен,
[01:00:14.720 --> 01:00:20.080]  и вы в какой-то там на сотой секунде в верхнем углу
[01:00:20.080 --> 01:00:22.480]  увидели вдруг мелькнул красный пиксел, вам абсолютно
[01:00:22.480 --> 01:00:28.600]  все равно, но если вы используете память оперативную графической
[01:00:28.600 --> 01:00:32.760]  карту для выполнения расчета, и там на сотой секунде у
[01:00:32.760 --> 01:00:38.080]  вас вместо степени 10 оказалось степень 100, то вам не все
[01:00:38.080 --> 01:00:43.400]  равно, а происходило именно это, поэтому, собственно
[01:00:43.400 --> 01:00:48.360]  говоря, ровно то же самое делали отца-основатели
[01:00:48.360 --> 01:00:55.080]  еще во времена, когда были машины стрела, ламповые
[01:00:55.080 --> 01:00:58.460]  еще машины, они выполняли один расчет несколько
[01:00:58.460 --> 01:01:01.560]  раз на такой машине, но резать ее было нельзя, она была
[01:01:01.560 --> 01:01:05.160]  последовательная, но провести расчет дважды подряд можно
[01:01:05.160 --> 01:01:09.000]  было, с тем, чтобы убедиться, что да, ответы правильные,
[01:01:09.000 --> 01:01:12.160]  то есть резервирование, оно не только на космических
[01:01:12.160 --> 01:01:16.560]  кораблях, оно вот и в HPC расчетах тоже в полный раз использовалось,
[01:01:16.560 --> 01:01:20.800]  вот если вы сейчас заказываете систему даже X, либо еще что-то,
[01:01:20.800 --> 01:01:23.800]  то у вас этой проблемы уже не будет, потому что уже
[01:01:23.800 --> 01:01:27.560]  вот эти карты пошли в SGP, в SGPU, до общего назначения
[01:01:27.560 --> 01:01:30.520]  графические карты не игровые, а общего назначения, вот
[01:01:30.520 --> 01:01:34.880]  они уже с защитой памяти, вот системный блок, который
[01:01:34.880 --> 01:01:38.400]  стоит в суперкомпьютере, он тоже с защитой памяти,
[01:01:38.400 --> 01:01:42.440]  но понимаете, что это такое, я ЦС, это что такое, вот
[01:01:42.440 --> 01:01:48.320]  у вас есть 8 микросхем памяти, там 1, 2, 3, 8, а рядом стоит
[01:01:48.320 --> 01:01:51.800]  9, которая хранит контрольную сумму по модуле 2 всех вот
[01:01:51.800 --> 01:01:55.440]  этих вот, если у вас, ну в простейшем случае, если
[01:01:55.440 --> 01:01:58.440]  у вас какой-то бит перебросился, то вы об этом хотя бы узнали,
[01:01:58.440 --> 01:02:02.400]  вы узнали, что у вас здесь где-то возникла ошибка, вот
[01:02:02.400 --> 01:02:05.320]  если таких микросхем там две, то вы уже имеете возможность
[01:02:05.320 --> 01:02:09.400]  ее исправить, и вот эти серверные материнские
[01:02:09.400 --> 01:02:13.600]  платы, серверные системные блоки, они поддерживают такую
[01:02:13.600 --> 01:02:18.560]  коррекцию ошибок, вот, так легчему, тут как бы вот
[01:02:18.560 --> 01:02:22.280]  мы сейчас поговорили, ну все понятно, а вот теперь
[01:02:22.280 --> 01:02:26.360]  смотрите, у нас 10.18 операции в секунду, это 10.9 исполнительных
[01:02:26.360 --> 01:02:32.480]  устройств, вот по всем оценкам специалистов, когда такая
[01:02:32.480 --> 01:02:35.480]  штука заработает, она непрерывно больше получаса работать
[01:02:35.480 --> 01:02:40.640]  не будет, хотя бы один из процессоров из строя выйдет,
[01:02:40.640 --> 01:02:43.800]  ну просто по определению, значит то ли это будет аппаратная
[01:02:43.800 --> 01:02:47.640]  проблема, нет, он не скончается, он просто некорректный ответ
[01:02:47.880 --> 01:02:50.640]  либо перестанет отзываться, ну с ним что-нибудь произойдет,
[01:02:50.640 --> 01:02:54.480]  то ли из-за аппаратных особенностей, то ли из-за особенностей
[01:02:54.480 --> 01:02:56.920]  того, что там сложное программное обеспечение в программе
[01:02:56.920 --> 01:02:59.600]  будет сбоено, в общем где-нибудь что-нибудь да случится, за
[01:02:59.600 --> 01:03:07.840]  полчаса, вот, а что делать, вот сломался процессор один,
[01:03:07.840 --> 01:03:12.280]  и нормальный ход, он какой, ну мы иногда записываем
[01:03:12.280 --> 01:03:17.600]  данные, и если что-то сломалось, то мы перезапускаем расчет,
[01:03:17.640 --> 01:03:20.000]  так вот, на системе вот такого класса у вас этой возможности
[01:03:20.000 --> 01:03:23.240]  не будет по определению, потому что для того, чтобы
[01:03:23.240 --> 01:03:25.880]  записать такую согласованную контрольную точку, у вас
[01:03:25.880 --> 01:03:30.280]  полчаса уйдет, а через полчаса, пока вы будете ее читать,
[01:03:30.280 --> 01:03:32.920]  следующий процессор из строя выйдет, и вот алгоритмы,
[01:03:32.920 --> 01:03:34.920]  которые позволяют, тем не менее, в этих условиях
[01:03:34.920 --> 01:03:37.960]  непрерывно продолжать расчет так, как будто бы ничего
[01:03:37.960 --> 01:03:41.320]  не происходит, так как будто ошибок нет, вот эти алгоритмы
[01:03:41.320 --> 01:03:45.120]  мы посмотрим, ну это некоторые специальные классы алгоритмов,
[01:03:45.120 --> 01:03:48.440]  а именно выполнение расчетов моделирования задач газовой
[01:03:48.440 --> 01:03:52.560]  динамики, например, вот, и в этом смысле мы отказу
[01:03:52.560 --> 01:03:56.760]  устойчивость затронем, то есть здесь аппаратчики
[01:03:56.760 --> 01:04:00.240]  делают много, люди, которые занимаются аппаратурой,
[01:04:00.240 --> 01:04:05.760]  но и с точки зрения алгоритмов нужно свое видение предложить.
[01:04:05.760 --> 01:04:09.160]  Технологические основы есть, я говорил, что мы будем
[01:04:09.160 --> 01:04:14.400]  использовать MPI, так вот, MPI, начиная с версии 4, вот,
[01:04:14.400 --> 01:04:18.480]  у третьего еще возможности не было работать, если какой-то
[01:04:18.480 --> 01:04:23.600]  процессор оказался выведенным из строя, а вот у четвертого
[01:04:23.600 --> 01:04:27.800]  уже есть, дополнительные функции появились, которые
[01:04:27.800 --> 01:04:30.480]  позволяют вам понять, что какой-то из процессоров
[01:04:30.480 --> 01:04:34.520]  или несколько процессоров из строя вышли, из общего
[01:04:34.520 --> 01:04:36.720]  вычислительного поля их логически вывести, а
[01:04:36.720 --> 01:04:39.840]  на оставшихся продолжать считать, так что вот это
[01:04:39.840 --> 01:04:41.920]  мы будем рассматривать.
[01:04:41.920 --> 01:04:51.360]  Так, а какие у вас, собственно, есть вопросы, я тут много
[01:04:51.360 --> 01:04:59.920]  чего говорил, я думаю, что, да, а вот со следующего
[01:04:59.920 --> 01:05:02.200]  раза и будет, со следующего раза, я думаю, что я сейчас
[01:05:02.200 --> 01:05:06.000]  не буду, осталось 10 минут, даже меньше, с учетом того,
[01:05:06.000 --> 01:05:08.960]  что вот, я сейчас не буду, значит, в следующий раз что
[01:05:09.080 --> 01:05:13.560]  будет, во-первых, будет описание функций, которыми
[01:05:13.560 --> 01:05:16.320]  мы будем пользоваться, значит, это функция передачи
[01:05:16.320 --> 01:05:22.160]  данных и, ну, и на первый раз достаточно будет, а во-вторых,
[01:05:22.160 --> 01:05:28.520]  будут алгоритмы, значит, это сдваивание, геометрический
[01:05:28.520 --> 01:05:31.880]  парализм, то, что с ними связано, так что там уже
[01:05:31.880 --> 01:05:36.640]  пойдут вполне конкретные вещи, но как бы вот, не рассказав
[01:05:36.640 --> 01:05:41.200]  вот всего этого, не очень понятно, что и ради чего.
[01:05:41.200 --> 01:05:42.200]  Еще какие вопросы?
[01:05:42.200 --> 01:05:53.600]  Понимаете, какая штука, я бы ее с удовольствием
[01:05:53.600 --> 01:05:57.480]  отдал, но она под лицензионным договором с создательством,
[01:05:57.480 --> 01:06:01.280]  то есть там ссылки нету, значит, я чего могу, я могу их несколько
[01:06:01.280 --> 01:06:04.680]  просто привезти, экземпляров вот положить, берите, а на
[01:06:04.680 --> 01:06:08.400]  сайте, я ее раздавать не могу, но я знаю, что люди
[01:06:08.400 --> 01:06:09.400]  находили.
[01:06:09.400 --> 01:06:21.080]  Нет, вопрос нет, я знаю, что находили, но эта позиция
[01:06:21.080 --> 01:06:26.880]  издательства университета, она вот как-то так себя ведет.
[01:06:26.880 --> 01:06:34.160]  Так, если вопросов больше нету, тогда я благодарю за
[01:06:34.200 --> 01:06:38.200]  внимание, приглашаю вас на следующую лекцию, вот,
[01:06:38.200 --> 01:06:42.000]  главное не болейте, всем здоровья, удачи.
