[00:00.000 --> 00:11.760]  Я считаю, что мы должны были работать с нормализованными данными.
[00:11.760 --> 00:16.400]  В действительности, это не обязательно, потому что мы можем работать также с
[00:17.680 --> 00:22.880]  начальством данных, в результате нормализации, но с нормализацией иногда это более
[00:23.600 --> 00:31.520]  комфортно, и это один из способов, чтобы участвовать в нормализации.
[00:32.160 --> 00:36.640]  И модель, которую я использовал, которую я представил, это был
[00:39.600 --> 00:46.320]  модель, в котором вместо использования этих первоначальных данных, даже в нормализованной форме,
[00:46.880 --> 00:56.320]  мы смещаем их к векторам деменциала,
[00:58.800 --> 01:02.400]  меньше чем один, в сравнении с деменциалом
[01:02.400 --> 01:08.560]  первоначальных данных, мы смещаем их к
[01:11.280 --> 01:18.960]  векторам деменциала, к углу каждой части
[01:21.200 --> 01:22.480]  деменциала.
[01:23.440 --> 01:29.600]  И потом, эта работа была использована в многих сетях,
[01:31.360 --> 01:34.080]  мы имеем несколько публикаций об этом,
[01:35.040 --> 01:43.440]  включая одну публикацию с Борисом в журнале в России, но потом мы
[01:44.160 --> 01:49.120]  конфронтировались с следующим проблемом, который был действительно очень серьезным
[01:50.240 --> 01:55.680]  ситуацией, который был первый раз, когда я работал с большими данными,
[01:56.400 --> 02:03.040]  когда нужно было делать это с миллионами сетей этого рода,
[02:03.040 --> 02:10.400]  которые были, которые презентировали,
[02:11.200 --> 02:20.000]  этот курс презентировал консумерное поведение очень большой ретейл
[02:20.800 --> 02:28.640]  сетей. Я не могу сказать об этом открыто, потому что я подписал контракт с НДА, но
[02:29.600 --> 02:34.880]  это было в Европе, и у нас были миллионы этих курсов,
[02:37.920 --> 02:38.420]  и
[02:41.920 --> 02:47.440]  здесь написано индекс 1, индекс 2, но это, например, продукты.
[05:58.640 --> 05:59.280]  Ну,
[06:28.640 --> 06:33.640]  Редактор субтитров Е.Воинова Корректор А.Кулакова
[06:58.640 --> 07:01.640]  Корректор А.Кулакова
[07:28.640 --> 07:31.640]  Корректор А.Кулакова
[07:58.640 --> 08:01.640]  Корректор А.Кулакова
[08:28.640 --> 08:31.640]  Корректор А.Кулакова
[08:58.640 --> 09:01.640]  Корректор А.Кулакова
[09:29.640 --> 09:32.640]  Важная часть этой истории
[09:32.640 --> 09:35.640]  Важная часть этой истории
[09:35.640 --> 09:38.640]  Важная часть этой истории
[09:38.640 --> 09:41.640]  Важная часть этой истории
[09:41.640 --> 09:44.640]  Важная часть этой истории
[09:44.640 --> 09:47.640]  Важная часть этой истории
[09:47.640 --> 09:50.640]  Важная часть этой истории
[09:50.640 --> 09:53.640]  Важная часть этой истории
[09:53.640 --> 09:56.640]  Важная часть этой истории
[09:56.640 --> 09:59.640]  Важная часть этой истории
[09:59.640 --> 10:02.640]  Важная часть этой истории
[10:02.640 --> 10:05.640]  Важная часть этой истории
[10:05.640 --> 10:08.640]  Важная часть этой истории
[10:08.640 --> 10:11.640]  Важная часть этой истории
[10:11.640 --> 10:14.640]  Важная часть этой истории
[10:14.640 --> 10:17.640]  Важная часть этой истории
[10:17.640 --> 10:20.640]  Важная часть этой истории
[10:20.640 --> 10:23.640]  Важная часть этой истории
[10:23.640 --> 10:26.640]  Важная часть этой истории
[10:26.640 --> 10:29.640]  Важная часть этой истории
[10:29.640 --> 10:32.640]  Важная часть этой истории
[10:32.640 --> 10:35.640]  Важная часть этой истории
[10:35.640 --> 10:38.640]  Важная часть этой истории
[10:38.640 --> 10:41.640]  Важная часть этой истории
[10:41.640 --> 10:44.640]  Важная часть этой истории
[10:44.640 --> 10:47.640]  Важная часть этой истории
[10:47.640 --> 10:50.640]  Важная часть этой истории
[10:50.640 --> 10:53.640]  Важная часть этой истории
[10:53.640 --> 10:56.640]  Важная часть этой истории
[10:56.640 --> 10:59.640]  Важная часть этой истории
[10:59.640 --> 11:02.640]  Важная часть этой истории
[11:02.640 --> 11:05.640]  Важная часть этой истории
[11:05.640 --> 11:08.640]  Важная часть этой истории
[11:08.640 --> 11:11.640]  Важная часть этой истории
[11:11.640 --> 11:14.640]  Важная часть этой истории
[11:14.640 --> 11:17.640]  Важная часть этой истории
[11:17.640 --> 11:20.640]  Важная часть этой истории
[11:20.640 --> 11:23.640]  Важная часть этой истории
[11:23.640 --> 11:26.640]  Важная часть этой истории
[11:26.640 --> 11:29.640]  Важная часть этой истории
[11:29.640 --> 11:32.640]  Важная часть этой истории
[11:32.640 --> 11:35.640]  Важная часть этой истории
[11:35.640 --> 11:38.640]  Важная часть этой истории
[11:38.640 --> 11:41.640]  Важная часть этой истории
[11:41.640 --> 11:44.640]  Важная часть этой истории
[11:44.640 --> 11:47.640]  Важная часть этой истории
[11:47.640 --> 11:50.640]  Важная часть этой истории
[11:50.640 --> 11:53.640]  Важная часть этой истории
[11:53.640 --> 11:56.640]  Важная часть этой истории
[11:56.640 --> 11:59.640]  Важная часть этой истории
[11:59.640 --> 12:02.640]  Важная часть этой истории
[12:02.640 --> 12:05.640]  Важная часть этой истории
[12:05.640 --> 12:08.640]  Важная часть этой истории
[12:08.640 --> 12:11.640]  Важная часть этой истории
[12:11.640 --> 12:14.640]  Важная часть этой истории
[12:14.640 --> 12:17.640]  Важная часть этой истории
[12:17.640 --> 12:20.640]  Важная часть этой истории
[12:20.640 --> 12:23.640]  Важная часть этой истории
[12:23.640 --> 12:26.640]  Важная часть этой истории
[12:26.640 --> 12:29.640]  Важная часть этой истории
[12:29.640 --> 12:32.640]  Важная часть этой истории
[12:32.640 --> 12:35.640]  Важная часть этой истории
[12:35.640 --> 12:38.640]  Важная часть этой истории
[12:38.640 --> 12:41.640]  Важная часть этой истории
[12:41.640 --> 12:44.640]  Важная часть этой истории
[12:44.640 --> 12:47.640]  Важная часть этой истории
[12:47.640 --> 12:50.640]  Важная часть этой истории
[12:50.640 --> 12:53.640]  Важная часть этой истории
[12:53.640 --> 12:56.640]  Важная часть этой истории
[12:56.640 --> 12:59.640]  Важная часть этой истории
[12:59.640 --> 13:02.640]  Важная часть этой истории
[13:02.640 --> 13:05.640]  Важная часть этой истории
[13:05.640 --> 13:08.640]  Важная часть этой истории
[13:08.640 --> 13:11.640]  Важная часть этой истории
[13:11.640 --> 13:14.640]  Важная часть этой истории
[13:14.640 --> 13:17.640]  Важная часть этой истории
[13:17.640 --> 13:20.640]  Важная часть этой истории
[13:20.640 --> 13:23.640]  Важная часть этой истории
[13:23.640 --> 13:26.640]  Важная часть этой истории
[13:26.640 --> 13:29.640]  Важная часть этой истории
[13:29.640 --> 13:32.640]  Важная часть этой истории
[13:32.640 --> 13:35.640]  Важная часть этой истории
[13:35.640 --> 13:38.640]  Важная часть этой истории
[13:38.640 --> 13:41.640]  Важная часть этой истории
[13:41.640 --> 13:44.640]  Важная часть этой истории
[13:44.640 --> 13:47.640]  Важная часть этой истории
[13:47.640 --> 13:50.640]  Важная часть этой истории
[13:50.640 --> 13:53.640]  Важная часть этой истории
[13:53.640 --> 13:56.640]  Важная часть этой истории
[13:56.640 --> 13:59.640]  Важная часть этой истории
[13:59.640 --> 14:02.640]  Важная часть этой истории
[14:02.640 --> 14:05.640]  Важная часть этой истории
[14:05.640 --> 14:08.640]  Важная часть этой истории
[14:08.640 --> 14:11.640]  Важная часть этой истории
[14:11.640 --> 14:14.640]  Важная часть этой истории
[14:14.640 --> 14:17.640]  Важная часть этой истории
[14:17.640 --> 14:20.640]  Важная часть этой истории
[14:20.640 --> 14:23.640]  Важная часть этой истории
[14:23.640 --> 14:26.640]  Важная часть этой истории
[14:26.640 --> 14:29.640]  Важная часть этой истории
[14:29.640 --> 14:32.640]  Важная часть этой истории
[14:32.640 --> 14:35.640]  Важная часть этой истории
[14:35.640 --> 14:38.640]  Важная часть этой истории
[14:38.640 --> 14:41.640]  Важная часть этой истории
[14:41.640 --> 14:44.640]  Важная часть этой истории
[14:44.640 --> 14:47.640]  Важная часть этой истории
[14:47.640 --> 14:50.640]  Важная часть этой истории
[14:50.640 --> 14:53.640]  Важная часть этой истории
[14:53.640 --> 14:56.640]  Важная часть этой истории
[14:56.640 --> 14:59.640]  Важная часть этой истории
[14:59.640 --> 15:02.640]  Важная часть этой истории
[15:02.640 --> 15:05.640]  Важная часть этой истории
[15:05.640 --> 15:08.640]  Важная часть этой истории
[15:08.640 --> 15:11.640]  Важная часть этой истории
[15:11.640 --> 15:14.640]  Важная часть этой истории
[15:14.640 --> 15:17.640]  Важная часть этой истории
[15:17.640 --> 15:20.640]  Важная часть этой истории
[15:20.640 --> 15:23.640]  Важная часть этой истории
[15:23.640 --> 15:26.640]  Важная часть этой истории
[15:26.640 --> 15:29.640]  Важная часть этой истории
[15:29.640 --> 15:32.640]  Важная часть этой истории
[15:32.640 --> 15:35.640]  Важная часть этой истории
[15:35.640 --> 15:38.640]  Важная часть этой истории
[15:38.640 --> 15:41.640]  Важная часть этой истории
[15:41.640 --> 15:44.640]  Важная часть этой истории
[15:44.640 --> 15:47.640]  Важная часть этой истории
[15:47.640 --> 15:50.640]  Важная часть этой истории
[15:50.640 --> 15:53.640]  Важная часть этой истории
[15:53.640 --> 15:56.640]  Важная часть этой истории
[15:56.640 --> 15:59.640]  Важная часть этой истории
[15:59.640 --> 16:02.640]  Важная часть этой истории
[16:02.640 --> 16:05.640]  Важная часть этой истории
[16:05.640 --> 16:08.640]  Важная часть этой истории
[16:08.640 --> 16:11.640]  Важная часть этой истории
[16:11.640 --> 16:14.640]  Важная часть этой истории
[16:14.640 --> 16:17.640]  Важная часть этой истории
[16:17.640 --> 16:20.640]  Важная часть этой истории
[16:20.640 --> 16:23.640]  Важная часть этой истории
[16:23.640 --> 16:26.640]  Важная часть этой истории
[16:26.640 --> 16:29.640]  Важная часть этой истории
[16:29.640 --> 16:32.640]  Важная часть этой истории
[16:32.640 --> 16:35.640]  Важная часть этой истории
[16:35.640 --> 16:38.640]  Важная часть этой истории
[16:38.640 --> 16:41.640]  Важная часть этой истории
[16:41.640 --> 16:44.640]  Важная часть этой истории
[16:44.640 --> 16:47.640]  Важная часть этой истории
[16:47.640 --> 16:50.640]  Важная часть этой истории
[16:50.640 --> 16:53.640]  Важная часть этой истории
[16:53.640 --> 16:56.640]  Важная часть этой истории
[16:56.640 --> 16:59.640]  Важная часть этой истории
[16:59.640 --> 17:02.640]  Важная часть этой истории
[17:02.640 --> 17:05.640]  Важная часть этой истории
[17:05.640 --> 17:08.640]  Важная часть этой истории
[17:08.640 --> 17:11.640]  Важная часть этой истории
[17:11.640 --> 17:14.640]  Важная часть этой истории
[17:14.640 --> 17:17.640]  Важная часть этой истории
[17:17.640 --> 17:20.640]  Важная часть этой истории
[17:20.640 --> 17:23.640]  Важная часть этой истории
[17:23.640 --> 17:26.640]  Важная часть этой истории
[17:26.640 --> 17:29.640]  Важная часть этой истории
[17:29.640 --> 17:32.640]  Важная часть этой истории
[17:32.640 --> 17:35.640]  Важная часть этой истории
[17:35.640 --> 17:38.640]  Важная часть этой истории
[17:38.640 --> 17:41.640]  Важная часть этой истории
[17:41.640 --> 17:44.640]  Важная часть этой истории
[17:44.640 --> 17:47.640]  Важная часть этой истории
[17:47.640 --> 17:50.640]  Важная часть этой истории
[17:50.640 --> 17:53.640]  Важная часть этой истории
[17:53.640 --> 17:56.640]  Важная часть этой истории
[17:56.640 --> 17:59.640]  Важная часть этой истории
[17:59.640 --> 18:02.640]  Важная часть этой истории
[18:02.640 --> 18:05.640]  Важная часть этой истории
[18:05.640 --> 18:08.640]  Важная часть этой истории
[18:08.640 --> 18:11.640]  Важная часть этой истории
[18:11.640 --> 18:14.640]  Важная часть этой истории
[18:14.640 --> 18:17.640]  Важная часть этой истории
[18:17.640 --> 18:20.640]  Важная часть этой истории
[18:20.640 --> 18:23.640]  Важная часть этой истории
[18:23.640 --> 18:26.640]  Важная часть этой истории
[18:26.640 --> 18:29.640]  Важная часть этой истории
[18:29.640 --> 18:32.640]  Важная часть этой истории
[18:32.640 --> 18:35.640]  Важная часть этой истории
[18:35.640 --> 18:38.640]  Важная часть этой истории
[18:38.640 --> 18:41.640]  Важная часть этой истории
[18:41.640 --> 18:44.640]  Важная часть этой истории
[18:44.640 --> 18:47.640]  Важная часть этой истории
[18:47.640 --> 18:50.640]  Важная часть этой истории
[18:50.640 --> 18:53.640]  Важная часть этой истории
[18:53.640 --> 18:56.640]  Важная часть этой истории
[18:56.640 --> 18:59.640]  Важная часть этой истории
[18:59.640 --> 19:02.640]  Важная часть этой истории
[19:02.640 --> 19:05.640]  Важная часть этой истории
[19:05.640 --> 19:08.640]  Важная часть этой истории
[19:08.640 --> 19:11.640]  Важная часть этой истории
[19:11.640 --> 19:14.640]  Важная часть этой истории
[19:14.640 --> 19:17.640]  Важная часть этой истории
[19:17.640 --> 19:20.640]  Важная часть этой истории
[19:20.640 --> 19:23.640]  Важная часть этой истории
[19:24.640 --> 19:27.640]  Благодарю про Brisbane прощения
[19:27.640 --> 19:29.640]  Д般 scientifically
[19:29.640 --> 19:32.640]  Д般 Physically
[19:32.640 --> 19:35.640]  dismissed
[19:35.640 --> 19:38.640]  Вы27
[19:38.640 --> 19:41.640]  И you
[19:46.640 --> 19:49.640]  У рожденияSe sec
[19:49.640 --> 19:52.240]  Дского родного
[19:52.240 --> 19:58.240]  Борис Григорьевич, как известно, имеет разнообразные научные интересы,
[19:58.240 --> 20:02.240]  но, так сказать, на мой взгляд, может я ошибаюсь, он меня поправит,
[20:02.240 --> 20:10.240]  что, конечно, основные интересы сосредоточены вокруг кластеризации,
[20:10.240 --> 20:15.240]  поэтому я буду говорить сейчас исключительно о кластеризации.
[20:15.240 --> 20:22.240]  И здесь, конечно, наверное, трудно чем-то удивить новым Борис Григорьевича,
[20:22.240 --> 20:30.240]  поскольку я обычно своим студентам говорю, что когда возникает какой-то вопрос
[20:30.240 --> 20:34.240]  ложный, связанный с кластеризацией, я говорю, у вас есть уникальная возможность
[20:34.240 --> 20:39.240]  получить консультацию с первого хуста человека, который знает про кластеры все,
[20:39.240 --> 20:45.240]  и направляю их к вам. Я не знаю, доходит ли они до вас, но я так делаю.
[20:45.240 --> 20:48.240]  Нет, не доходит.
[20:48.240 --> 20:55.240]  Да, ну вот так. Поэтому удивить как бы нечем тут в этом плане, я так думаю,
[20:55.240 --> 21:01.240]  но можно удивить именно объектами кластеризации, что кластеризовать.
[21:01.240 --> 21:08.240]  В этом смысле я хочу сейчас как раз рассказать о кластеризации таких объектов,
[21:08.240 --> 21:14.240]  которые называются телами свидетельств. В рамках теории Демслера-Шефера
[21:14.240 --> 21:18.240]  рассматриваются такие объекты, которые называются телами свидетельств.
[21:18.240 --> 21:26.240]  Они имеют такую сложную структуру. Во-первых, это такие пары,
[21:26.240 --> 21:33.240]  состоящие из наборов подможеств некоторого множества и связанных с ними
[21:33.240 --> 21:41.240]  функциями массы. Сами подможества характеризуют степень уверенности,
[21:41.240 --> 21:47.240]  то множество, которому может принадлежать истинная альтернатива,
[21:47.240 --> 21:53.240]  а массы, частоты характеризуют степень уверенности, что истинная альтернатива
[21:53.240 --> 21:59.240]  принадлежит тому или иному множеству. Вот эти тела свидетельств могут иметь
[21:59.240 --> 22:03.240]  довольно сложную структуру. Да, сами вот эти подможества называют
[22:03.240 --> 22:07.240]  фокальными элементами. Они могут иметь довольно сложную структуру, могут пересекаться,
[22:07.240 --> 22:11.240]  могут вкладываться, могут не пересекаться и так далее и так далее.
[22:11.240 --> 22:18.240]  И таких фокальных элементов может быть довольно много в реальных телах свидетельств.
[22:18.240 --> 22:26.240]  Поэтому требуется их кластеризовать для того, чтобы решать, во-первых, задачу
[22:26.240 --> 22:31.240]  аппроксимации, когда мы заменяем тело свидетельств из множества.
[22:31.240 --> 22:38.240]  Заменим более простым тему свидетельств, состоящих из нескольких фокальных элементов,
[22:38.240 --> 22:47.240]  но тем не менее, чтобы какая-то мера близости между этими объектами выполнялась.
[22:47.240 --> 22:52.240]  Во-вторых, вычислительно-осложно.
[22:53.240 --> 22:59.240]  Основные вычисления там связанные. Они носят экспоненциальный характер.
[22:59.240 --> 23:05.240]  Поэтому чем меньше тел свидетельств, тем вычислительная сложность этих алгоритмов
[23:05.240 --> 23:11.240]  связанных с обработкой таких объектов будет выше.
[23:11.240 --> 23:17.240]  Это что касается мотивации исследований.
[23:18.240 --> 23:23.240]  Пару слов скажу о самой этой теории Демпстера-Шефера, в рамках которой
[23:23.240 --> 23:27.240]  рассматриваются эти объекты тела свидетельств.
[23:27.240 --> 23:32.240]  Это довольно старая теория. Берет свое начало от двух таких работ,
[23:32.240 --> 23:38.240]  пионерских Демпстера 1967 года и Шафера 1976 года.
[23:38.240 --> 23:46.240]  Демпстер – это чистый статистик из Гарварда, сейчас очень приклонного возраста.
[23:46.240 --> 23:52.240]  Недавно я даже видел его работу совсем свежую.
[23:52.240 --> 23:58.240]  Шафер помоложе, значительно моложе и имеет такие разнообразные интересы.
[23:58.240 --> 24:04.240]  В это время он был совсем молодым человеком, когда написал эту монографию.
[24:04.240 --> 24:10.240]  Он как раз занимался развитием этой теории.
[24:10.240 --> 24:15.240]  Эта монография, кстати, не потеряла актуальность даже в настоящее время.
[24:15.240 --> 24:20.240]  Основные тут моменты такие, что рассматривается некоторое множество,
[24:20.240 --> 24:25.240]  универсальное множество, как обычно Х, и на нем рассматривается какое-то
[24:25.240 --> 24:33.240]  конечное подможество этого множества. Называют эти подможества фокальными элементами.
[24:33.240 --> 24:37.240]  Так будем обозначать.
[24:37.240 --> 24:40.240]  С этими подможествами связана функция масс.
[24:40.240 --> 24:44.240]  Функция масс – это не отрицательная функция, удовлетворяющая условия нормировки,
[24:44.240 --> 24:47.240]  что сумма всех масс равна единице.
[24:47.240 --> 24:54.240]  Вот такая как раз пара из множества фокальных элементов и функций масс называется телом свидетельств.
[24:54.240 --> 25:00.240]  Считается, что для каждого фокального элемента масса не нулевая.
[25:00.240 --> 25:05.240]  Простейшим телом свидетельств является категоричная телосвидетельств,
[25:05.240 --> 25:10.240]  состоящая всего из одного фокального элемента с единичной массой.
[25:10.240 --> 25:17.240]  Любое телосвидетельство можно представить в виде выпуклой комбинации категоричных тел свидетельств
[25:17.240 --> 25:22.240]  с коэффициентами равными массам.
[25:22.240 --> 25:25.240]  Чуть посложнее, чем категоричная телосвидетельств.
[25:25.240 --> 25:29.240]  Это такое свидетельство, называется простое.
[25:29.240 --> 25:35.240]  Когда с каким-то коэффициентом мы берем категоричное телосвидетельство,
[25:35.240 --> 25:38.240]  построенное на каком-то фокальном элементе,
[25:38.240 --> 25:43.240]  а всю остальную массу относим к всему универсальному множеству Х.
[25:43.240 --> 25:48.240]  Вот эта часть, второе слагаемое, она характеризует как бы степень нашего незнания
[25:48.240 --> 25:54.240]  о принадлежности истинной альтернативы множеству А.
[25:54.240 --> 25:57.240]  Степень нашего незнания.
[25:57.240 --> 26:03.240]  С этим телом свидетельств связывают несколько таких функций.
[26:04.240 --> 26:09.240]  Функции множеств, но самые популярные из них это функции доверия,
[26:09.240 --> 26:12.240]  функции правдоподобия, которые вот так строятся,
[26:12.240 --> 26:17.240]  и которые являются нижними и верхними оценками вероятности события того,
[26:17.240 --> 26:23.240]  что истинная альтернатива принадлежит множеству А.
[26:23.240 --> 26:31.240]  Значит, с такой с графовой точки зрения телосвидетельство можно считать
[26:31.240 --> 26:37.240]  вот гиперграфом, вчера как раз этот термин уже вспоминался на конференции.
[26:37.240 --> 26:42.240]  Можно считать, что это есть такой гиперграф, когда у нас элементы множества Х
[26:42.240 --> 26:48.240]  это вершины этого гиперграфа, а гипердуги это как раз вот эти фокальные элементы.
[26:48.240 --> 26:55.240]  Вот пример приведен, вот так можно в строчку это записать, как выпуклую комбинацию
[26:55.240 --> 27:01.240]  категоричных телосвидетельств, построенных на фокальных элементах.
[27:01.240 --> 27:07.240]  Вот здесь внизу фокальные элементы как раз перечислены нашего телосвидетельства.
[27:07.240 --> 27:13.240]  Это масса их, а это вот такое гиперграфовое представление этого телосвидетельства.
[27:13.240 --> 27:16.240]  Так вот, такие объекты надо кластеризовать. Что кластеризовать?
[27:16.240 --> 27:22.240]  Кластеризовать, конечно, в первую очередь нужно вот эти фокальные элементы,
[27:22.240 --> 27:28.240]  но с учетом их масс, конечно. Если там какой-то фокальный элемент имеет маленькую массу,
[27:28.240 --> 27:35.240]  то он может быть для нас не такой важный. Если там большая масса,
[27:35.240 --> 27:39.240]  то это более важные такие фокальные элементы, с учетом масс, конечно.
[27:39.240 --> 27:47.240]  Причем вот здесь при кластеризации часто метрические характеристики не важны.
[27:47.240 --> 27:54.240]  Не столь важны метрические характеристики. Сколько? Важны характеристики,
[27:54.240 --> 28:00.240]  связанные с понятием конфликта между фокальными элементами,
[28:00.240 --> 28:05.240]  между телами свидетельств, конфликта либо противоречия.
[28:05.240 --> 28:10.240]  Что можно считать конфликтом и не конфликтами фокальные элементы?
[28:10.240 --> 28:17.240]  Если сильно пересекаются, грубо говоря, сильно пересекаются два фокальных элемента,
[28:17.240 --> 28:23.240]  то такую пару можно назвать парой не конфликтных фокальных элементов,
[28:23.240 --> 28:29.240]  поскольку истинная альтернатива, один источник, например, принадлежит множеству A,
[28:29.240 --> 28:33.240]  второй множеству B. Эти множества довольно близкие, и в этом случае
[28:33.240 --> 28:38.240]  эти свидетельства от этих источников, они действительно воспринимаются не конфликтно.
[28:38.240 --> 28:43.240]  Если они слабенько пересекаются, то вот здесь уже есть какой-то слабый конфликт.
[28:43.240 --> 28:47.240]  Если они вообще не пересекаются, то здесь уже есть такой сильный конфликт
[28:47.240 --> 28:53.240]  между этими фокальными элементами и соответствующими свидетельствами.
[28:53.240 --> 28:59.240]  Если у нас есть тела свидетельств из множества таких пар построенных,
[28:59.240 --> 29:03.240]  множество фокальных элементов, то можно по-разному мерить конфликт,
[29:04.240 --> 29:09.240]  но вот такая белинейная форма, самая популярная для измерения конфликта
[29:09.240 --> 29:17.240]  сумма произведений масс фокальных элементов, которая берется по парам фокальных элементов,
[29:17.240 --> 29:23.240]  которые между собой не пересекаются. То есть тут учитывается только третья ситуация,
[29:23.240 --> 29:28.240]  конфликтность. Средняя не учитывается, хотя можно ее учитывать,
[29:28.240 --> 29:32.240]  вот здесь нужно просто вставить какой-то коэффициент, меру пересечения,
[29:32.240 --> 29:39.240]  типа индекса Джакара или еще что-нибудь, и тогда можно и учитывать слабую ситуацию,
[29:39.240 --> 29:47.240]  но не суть, не в этом суть. Что касается кластеризации,
[29:47.240 --> 29:58.240]  то тут есть несколько подходов, которые я сейчас коротко охарактеризую.
[29:58.240 --> 30:02.240]  Первый подход – это такая иерархическая кластеризация.
[30:02.240 --> 30:08.240]  Она была предложена лет 20 назад Дено, Тири Дено,
[30:08.240 --> 30:15.240]  и в некоторых еще работах она встречалась, даже более ранние работы есть,
[30:15.240 --> 30:23.240]  и позже развивалась. Это такая вот, как бы мы сказали,
[30:23.240 --> 30:30.240]  агломеративная иерархическая кластеризация. В этом случае строятся два тела свидетельств –
[30:30.240 --> 30:36.240]  тело внутренней кластеризации и внешней кластеризации.
[30:36.240 --> 30:44.240]  Строится так, это берутся, да, вот обозначено они F-, F+, тело внутренней кластеризации,
[30:44.240 --> 30:51.240]  внешней кластеризации. Значит, тело свидетельств внутренней кластеризации
[30:51.240 --> 31:01.240]  строится на пересечении некоторых множеств из исходного множества фокальных элементов,
[31:01.240 --> 31:05.240]  а тело свидетельств внешней кластеризации на их объединение.
[31:05.240 --> 31:08.240]  При этом и в том, и в другом случае массы суммируются.
[31:08.240 --> 31:15.240]  Массы просто суммируются. Значит, какие пары выбирать для пересечений и для объединений,
[31:15.240 --> 31:20.240]  но решается по-разному. Ну, например, можно построить,
[31:20.240 --> 31:27.240]  использовать вот такой, например, функционал – функционал неточности тела свидетельств.
[31:27.240 --> 31:33.240]  Значит, чем больше у нас тел свидетельств больших по мощности с большими массами,
[31:33.240 --> 31:40.240]  тем более неточное у нас это свидетельство.
[31:40.240 --> 31:47.240]  Так вот, можно выбирать такие пары, которые при объединении либо при пересечении
[31:47.240 --> 31:53.240]  мало меняют вот этот функционал неточности. То есть в этом случае можно ожидать,
[31:53.240 --> 31:59.240]  что какая-то мера близости у нас будет, выполняться мера близости,
[31:59.240 --> 32:03.240]  между тем, что мы получим в результате этой иерархической кластеризации
[32:03.240 --> 32:05.240]  и исходным телом свидетельств.
[32:05.240 --> 32:12.240]  Но вот если расписать для пар этот функционал, то он при объединении пар примет такой вид,
[32:12.240 --> 32:16.240]  а при пересечении такой вид. Ну и тогда, соответственно, выбираются те пары
[32:16.240 --> 32:20.240]  для внутренней кластеризации, которая минимизирует этот функционал,
[32:20.240 --> 32:24.240]  для внешней, которая минимизирует этот функционал.
[32:24.240 --> 32:31.240]  На том же примере, который там был, у нас в середине тела свидетельств,
[32:31.240 --> 32:37.240]  в результате применения этой внешней внутренней кластеризации мы получим такие результаты.
[32:37.240 --> 32:43.240]  Вот будет такая внутренняя кластеризация и вот такая внешняя кластеризация.
[32:43.240 --> 32:47.240]  То есть в этом случае число кластеров задается заранее,
[32:47.240 --> 32:52.240]  на каком этапе мы хотим остановиться, сколько кластеров получить.
[32:52.240 --> 32:56.240]  Ну вот здесь, например, два кластера дошли до двух кластеров.
[32:56.240 --> 33:01.240]  Получается вот такая иерархистская кластеризация.
[33:01.240 --> 33:07.240]  Другой класс кластеризации, он связан с оптимизацией конфликта,
[33:07.240 --> 33:13.240]  вот о чем я как раз говорил. В этом случае по-разному поступает.
[33:13.240 --> 33:19.240]  Например, можно выделить некоторое маленькое под множество фокальных элементов,
[33:19.240 --> 33:27.240]  вот альфа штрих, которые из таких значимых фокальных элементов.
[33:27.240 --> 33:31.240]  Что такое значимый, сейчас я поговорю об этом.
[33:31.240 --> 33:35.240]  Ну и потом, после этого можно перераспределить остальные,
[33:35.240 --> 33:39.240]  например, фокальные элементы, отнести вот к этим значимым,
[33:39.240 --> 33:42.240]  мы получим тогда такие какие-то кластеры.
[33:42.240 --> 33:49.240]  Либо можно использовать вот какой-то аналог алгоритма комбинц.
[33:49.240 --> 33:57.240]  Ну вот что касается первого подхода, когда мы выделяем значимые элементы,
[33:57.240 --> 34:04.240]  то вот в прошлом году как раз моим соавтором Андреем Бронеевичем вышла такая статья,
[34:04.240 --> 34:08.240]  где в том числе, она не только этому посвящена,
[34:08.240 --> 34:14.240]  в том числе был предложен такой алгоритм, основанный на так называемой функции плотности конфликта.
[34:14.240 --> 34:22.240]  Плотность конфликта это такая функция, которая принимает большие значения в данном множестве,
[34:22.240 --> 34:28.240]  если рядом с ним, грубо говоря, нет пересекающихся множеств,
[34:28.240 --> 34:31.240]  либо нет сильно пересекающихся множеств.
[34:31.240 --> 34:37.240]  В идеале функция равна единице, принимает максимальное значение, если таких вообще нет.
[34:37.240 --> 34:45.240]  И наоборот, нулевое значение, если это множество пересекается со всеми другими множествами Иисра.
[34:45.240 --> 34:47.240]  Множество фокальных элементов.
[34:47.240 --> 34:51.240]  Ну третье условие – это условие линейности для простоты.
[34:51.240 --> 34:55.240]  Так вот, есть ли такую функцию конфликта?
[34:55.240 --> 35:00.240]  Да, можно несложно показать, что такая плотность, она будет как раз равна единице,
[35:00.240 --> 35:04.240]  минус функция правдоподобия, о котором я говорил,
[35:04.240 --> 35:08.240]  которая является верхней оценкой вероятности события.
[35:08.240 --> 35:10.240]  Она тут будет так вычисляться.
[35:10.240 --> 35:15.240]  Ну и кроме того, можно еще учесть массу своего фокального элемента.
[35:15.240 --> 35:22.240]  То есть нас интересует только фокальный элемент, который,
[35:22.240 --> 35:29.240]  когда мы говорим, тут будет такой довольно простой,
[35:29.240 --> 35:37.240]  мы упорядчиваем все множество фокальных элементов по убыванию вот этой функции плотности конфликта.
[35:37.240 --> 35:47.240]  И выбираем значимые конфликты элементы, начиная в соответствии с этим порядком.
[35:47.240 --> 35:54.240]  Ну и кроме того, используем еще функцию расстояния так, чтобы рядом два фокальных элемента
[35:54.240 --> 36:02.240]  из этой последовательности, находящейся рядом, чтобы они не попали в это множество h'.
[36:02.240 --> 36:06.240]  То есть используем какую-то метрику.
[36:06.240 --> 36:12.240]  Что касается метрики, можно использовать, конечно, метрику между фокальными элементами
[36:12.240 --> 36:16.240]  как мощность симметрического разности множества,
[36:16.240 --> 36:21.240]  либо, если это измеримое пространство, то это какая-то мера измеримого разности множества.
[36:22.240 --> 36:27.240]  Если это метрическое пространство, можно использовать метрику Хауссдорфа.
[36:27.240 --> 36:33.240]  Но вот чаще используют вот такую метрику, очень популярна вот в этой теории,
[36:33.240 --> 36:42.240]  вот такая метрика, которая с индексами Джакарда, тут такая белинейная форма.
[36:42.240 --> 36:48.240]  Это действительно метрика, можно доказать, что это настоящая метрика, вот она чаще всего используется.
[36:49.240 --> 36:55.240]  Этот алгоритм, конечно, имеет свои аналоги, такие точечные.
[36:55.240 --> 37:02.240]  Например, один из таких алгоритмов, я привел ссылку, но таких алгоритмов довольно точечных много.
[37:02.240 --> 37:10.240]  Если тот же пример использовать, то в результате мы получим два вот таких кластера.
[37:10.240 --> 37:20.240]  После этого можно, как говорят, решая задачу минимизации расхождения между исходным телом свидетель
[37:20.240 --> 37:26.240]  и нашим телом свидетель с какими-то коэффициентами неизвестными, найти эти коэффициенты.
[37:26.240 --> 37:32.240]  Мы в результате получим очень близкий результат к тому, что было у нас в эроргической кластеризации.
[37:32.240 --> 37:37.240]  Очень близкий, там было 0.7, 0.3, но здесь масса чуть-чуть другая.
[37:37.240 --> 37:53.240]  Можно в общем случае решать задачу перераспределения фокальных элементов по выбранным кластерам.
[37:53.240 --> 37:56.240]  Решать ее следующим образом.
[37:56.240 --> 38:03.240]  С каждым выбранным кластером можно связать свое тело свидетельство, которое строится вот таким образом.
[38:03.240 --> 38:11.240]  Масса того элемента, который у нас был в исходном теле, совпадает с исходной массой.
[38:11.240 --> 38:21.240]  Но тут тогда сумма всех этих масс внутри кластера не будет равна единице в общем случае.
[38:21.240 --> 38:26.240]  Поэтому оставшуюся часть массы мы отнесем на массу всего множества.
[38:26.240 --> 38:30.240]  Это то, что мы говорим, не знание массы всего множества.
[38:30.240 --> 38:38.240]  Вот так можно, как говорят, натянуть на этот кластер тело свидетельство.
[38:38.240 --> 38:52.240]  Тогда алгоритм перераспределения оставшихся фокальных элементов по выбранным кластерам h' будет следующим.
[38:52.240 --> 39:03.240]  Следующий мы берем очередной фокальный элемент, присоединяем его к какому-то кластеру,
[39:03.240 --> 39:09.240]  потом натягиваем на вот этот новый кластер соответствующий тело свидетельств
[39:09.240 --> 39:15.240]  и считаем конфликт между новым вот этим телом свидетельств и всеми другими телами свидетельств.
[39:15.240 --> 39:21.240]  Это будет внешний конфликт между кластерами.
[39:21.240 --> 39:27.240]  И в том случае, когда мы получаем максимальный внешний конфликт между кластерами,
[39:27.240 --> 39:32.240]  вот тому кластеру будем относить этот фокальный элемент.
[39:32.240 --> 39:36.240]  Тут есть полная аналогия с принципом компактности.
[39:36.240 --> 39:47.240]  Мы должны в один кластер поместить те элементы, которые близки друг к другу, в разные кластеры, которые далеки друг к другу.
[39:47.240 --> 39:55.240]  Вот здесь вместо метрической характеристики близости используется конфликтность.
[39:55.240 --> 40:03.240]  То есть в один кластер относим те фокальные элементы, которые мало конфликтны друг с другу, а в разные, которые сильно конфликтны друг с другом.
[40:03.240 --> 40:13.240]  В результате такой кластеризации мы получим такую кластеризацию, которая цветом обозначена здесь как раз.
[40:13.240 --> 40:20.240]  Это будет примерно соответствует тому, что было в иерархической кластеризации внешней кластеризации.
[40:20.240 --> 40:26.240]  И наконец, комминс. Совсем коротко, я понимаю, времени у меня почти не осталось.
[40:26.240 --> 40:40.240]  В этом случае рассматривается функционал минимизации суммарного внутреннего конфликта между каким-то центром кластера.
[40:40.240 --> 40:45.240]  Сейчас я расскажу вам, что это такое. Центр кластера – это тоже телосвидетельство.
[40:45.240 --> 40:54.240]  Что интересно, это не фокальный элемент какой-то, а это именно телосвидетельство, натянутое на какие-то фокальные элементы.
[40:54.240 --> 41:06.240]  И телом свидетельств, натянутым на элемент этого кластера, вот такой функционал минимизируется.
[41:06.240 --> 41:13.240]  Что касается того самого интересного, ситуация с центрами кластера.
[41:13.240 --> 41:23.240]  Центр кластера, если искать его в таком виде, как линейная комбинация категоричных тел свидетельств из этого кластера, что естественно.
[41:23.240 --> 41:38.240]  То тут не трудно доказать такую теорему, что вот этот функционал при фиксированном разбиении, но мы меняем центры кластеров.
[41:38.240 --> 41:44.240]  При фиксированном разбиении будет достигать минимума, когда центры кластеров строятся следующим образом.
[41:44.240 --> 41:59.240]  Строится по этой формуле, естественно, один, но в качестве множества тут выбираются такие множества, которые максимизируют вот такую функцию правдоподобия, суженную на этот кластер.
[41:59.240 --> 42:04.240]  Сужение на кластер, функцию правдоподобия максимизируют.
[42:04.240 --> 42:14.240]  В этом случае мы используем классический алгоритм Каминс с такой оговоркой.
[42:14.240 --> 42:33.240]  Единственное, что тут сложное заключается в том, что вот эта теорема, что в отличие от метрической ситуации, как правило, возможно множество решений, множество коэффициентов будут удовлетворять условиям этой теоремы.
[42:33.240 --> 42:38.240]  И множество центров кластеров мы получаем, не один центр кластера в этом случае.
[42:38.240 --> 42:43.240]  Можно, в принципе, работать и с таким множеством, ничего страшного.
[42:43.240 --> 42:52.240]  Но если мы хотим все-таки сузить, надеяться, чтобы там у нас был один центр кластера, то нужно использовать какие-то дополнительные процедуры, дополнительные условия.
[42:52.240 --> 42:56.240]  Это могут быть разные условия, например, условия минимизации покрытия.
[42:56.240 --> 43:01.240]  В общем случае мы получаем не разбиение, а покрытие по крайних элементах.
[43:01.240 --> 43:07.240]  Можно использовать условия минимизации покрытия, то есть чтобы покрытие было близко к разбиению.
[43:07.240 --> 43:14.240]  Например, вот такое условие нужно минимизировать, суммарную мощность кластеров.
[43:14.240 --> 43:20.240]  Либо минимизировать какую-то меру неточности, например такую.
[43:20.240 --> 43:36.240]  Либо минимизировать, ну в общем разные есть варианты дополнительных процедур, которые позволяют выделить из вот этого множества центров кластера, выделить в каждом кластере по одному центру.
[43:36.240 --> 43:45.240]  Так, ну вот, например, на том же примере, если посмотреть, то получается, ну тот же самый, в общем-то, получается результат.
[43:45.240 --> 43:51.240]  Так, ну вот, собственно говоря, и все, что я хотел рассказать.
[43:51.240 --> 44:05.240]  Да, вот как дополнительный бонус можно использовать вот эту процедуру кластеризации для оценивания меры внутреннего конфликта кластеров, меры внутреннего конфликта тела свидетельств.
[44:05.240 --> 44:25.240]  Вот когда мы кластеризацию получим, то посчитав внешний конфликт вот для тел свидетельств, натянутых на эти кластеры, мы получим меру внутреннего конфликта, которая вот в общем случае у нас считается как бы сложнее, чем мера внешнего конфликта между кластерами неоднозначной.
[44:25.240 --> 44:29.240]  Поэтому вот это такой довольно важный момент.
[44:29.240 --> 44:34.240]  Так, ну вот, пожалуй, и все, что я хотел сказать.
[44:34.240 --> 44:42.240]  Happy birthday, Борис Григорьевич. Все. Если есть вопросы, я готов ответить.
[44:50.240 --> 44:53.240]  Подходите к микрофону, заодно проверим микрофон.
[44:53.240 --> 44:55.240]  Раз, два.
[44:55.240 --> 44:58.240]  Да, Борис Григорьевич, конечно.
[44:58.240 --> 45:04.240]  Ну да, мы с вами на двоих тогда будем говорить.
[45:04.240 --> 45:14.240]  Значит, я не очень понимаю, где взять эти данные? Вот исходные данные для этого кластера. Как это получается?
[45:14.240 --> 45:17.240]  Это могут быть, например, экспертные оценки.
[45:17.240 --> 45:20.240]  Первое, что это экспертные оценки?
[45:20.240 --> 45:32.240]  То есть мы, например, выбираем кого-то, какого-то руководителя выбираем, и опросили коллектив.
[45:32.240 --> 45:40.240]  Столько-то человек сказали, что они могут, например, ответить так, что мы не можем выбрать кого-то одного.
[45:40.240 --> 45:47.240]  Из пяти кандидатов я склоняюсь больше к первому, к второму.
[45:47.240 --> 45:54.240]  Другой скажет, что я из пяти кандидатов склоняюсь ко второму, к третьему и так далее.
[45:54.240 --> 45:57.240]  Мы получаем вот эти множества. Такая простая ситуация.
[45:57.240 --> 46:05.240]  Либо это, например, если речь идет о прогнозировании каких-то...
[46:05.240 --> 46:15.240]  Ну, например, прогнозирование стоимости акции, какая будет, например, через месяц.
[46:15.240 --> 46:23.240]  То есть эксперт говорит о том, что стоимость акции будет в каком-то интервале лежать, например, от 40 до 50 единиц.
[46:23.240 --> 46:25.240]  То есть вот это уже будет фокальный элемент.
[46:25.240 --> 46:30.240]  Он не говорит, что стоимость акции будет 45 единиц ровно.
[46:30.240 --> 46:35.240]  Точечное значение не дает. Он говорит множественное значение в виде интервалов.
[46:35.240 --> 46:38.240]  Это уже будет какой-то фокальный элемент.
[46:38.240 --> 46:44.240]  Либо он говорит, например, от 40 до 50 степень уверенности большая, где-то примерно 0,7.
[46:44.240 --> 46:50.240]  Ну, может быть там от, допустим, от 48 до 55 со степенью уверенности 0,3.
[46:50.240 --> 46:52.240]  Например, вот такого типа.
[46:53.240 --> 46:56.240]  Спасибо. Я понял. Спасибо.
[46:57.240 --> 47:04.240]  Сообщение посвящено управляемости треугольными системами со сменами фазового пространства.
[47:04.240 --> 47:11.240]  В двух фазовых пространствах X и Y разной размерности.
[47:11.240 --> 47:15.240]  Пространства могут иметь как одну размерность, так и разную.
[47:15.240 --> 47:21.240]  Возможен переход как из пространства большей размерности в пространство меньшей размерности, так и наоборот.
[47:21.240 --> 47:26.240]  В фазовых пространствах X и Y движения описываются следующими системами.
[47:26.240 --> 47:32.240]  В пространстве X движения описываются с системой I на отрезке времени 0T.
[47:32.240 --> 47:38.240]  В пространстве Y движения описываются с системой II на отрезке времени TaoT.
[47:38.240 --> 47:43.240]  Интервалы времени Tao и Tт заданы.
[47:43.240 --> 47:50.240]  Системы 1 и 2 были рассмотрены коробовым впервые.
[47:50.240 --> 48:03.800]  и названы треугольными. В дальнейшем они тоже и рассматривались и также изучались, например,
[48:03.800 --> 48:14.520]  задачах стабилизации каскадов систем. К подобного вида системам сводится ряд физических управляемых
[48:14.520 --> 48:24.480]  процессов. Допустимыми управлениями являются непрерывные функции U и V со значениями в R1.
[48:24.480 --> 48:35.560]  Также нам задано в пространстве X начальное множество гиперплоскость перехода, не пересекающий
[48:35.560 --> 48:43.360]  с начальным множеством 0. Задано отображение Q, с помощью которого осуществляется переход
[48:43.360 --> 48:49.680]  из одного пространства в другое. И в пространстве Y задано конечное множество m1,
[48:49.680 --> 49:03.520]  не пересекающиеся с множеством Q от гамма. Движение объекта осуществляется по следующей
[49:03.520 --> 49:10.640]  схеме. Пусть на отрезке времени 0 Tau объект движется из начального множества m0 в пространство
[49:10.640 --> 49:18.880]  X по решениям системы X1. В момент времени Tau объект попадает на гамма и под действием отображения Q
[49:18.880 --> 49:28.000]  происходит переход в пространство Y. Мы получаем точку Y от Tau, которая является начальной для
[49:28.000 --> 49:33.440]  движения объектов в пространстве Y. Дальнейшее движение осуществляется на отрезке времени Tau
[49:33.440 --> 49:52.040]  и большой по решениям системы 2 на множество m1. Причем Y от Tau не принадлежит m1, иначе задача
[49:52.040 --> 49:59.160]  решена. Задача заключается в том, чтобы найти условия, при которых объект описываемый системой 1 и 2
[49:59.160 --> 50:08.000]  будет управляемым на отрезке 0 Tau из начального множества m0 в пространство X в конечное множество
[50:08.000 --> 50:19.240]  m1 в пространство Y. Объект описываемый системой 1 и 2 называется управляемым из m0 в m1, а если
[50:19.240 --> 50:24.760]  существуют такие допустимые управления U и V, то соответствующим решениям систем
[50:24.760 --> 50:38.680]  удовлетворяют ограниченным условиям. Следующая теорема дает достаточно условия управляемости данной
[50:38.680 --> 50:47.040]  системы, и в ходе доказательства удается получить непосредственно траекторию, которая связывает
[50:47.040 --> 50:58.960]  начальную точку в m0 и точку в m1. Если мы в пространстве X рассматриваем систему,
[50:58.960 --> 51:08.760]  вводим замены переменных следующим образом, и через Zn плюс 1 обозначаем новое управление.
[51:09.480 --> 51:18.640]  После такой замены система 1 приводится к линейной системе, которая к силу рангового
[51:18.640 --> 51:25.320]  критерия Калмана является полностью управляемой за время Tau, а по определению полной управляемости
[51:25.320 --> 51:31.760]  у нас существует управление, которое переводит объект изначального множества m0 в произвольную
[51:31.760 --> 51:41.920]  точку гамма. Тогда мы новое управление можем выбрать в виде функции от времени T, таким образом,
[51:41.920 --> 51:51.040]  чтобы за время Tau попасть из точки z0 в точку zeta Tau. Например, его можно выбрать вот в таком виде.
[51:51.040 --> 52:05.680]  Далее, подставив в левую часть соотношения 1 и 5 и вместо переменных полученной функции и управления,
[52:05.680 --> 52:12.080]  мы последовательно находим функции x1, xn и получаем траекторию, которая удовлетворяет
[52:12.080 --> 52:20.720]  ограниченным условиям. Далее мы переходим в пространство y под действием отображения q и в y
[52:20.720 --> 52:34.560]  рассматриваем аналогичное движение. Проводим аналогичные процедуры и получаем второй кусок
[52:34.560 --> 52:40.320]  траектории, который соединяет точки уже в пространстве y и таким образом мы получаем
[52:40.320 --> 52:46.880]  управляемость объекта из m0 в m1 и траекторию, которая соединяет начальное и коничное множество.
[52:46.880 --> 53:02.320]  Я. Ряд ссылок на литературу и спасибо за внимание.
[53:10.320 --> 53:18.480]  Спасибо. Борис Григорьевич, я бы хотела поздравить вас и желаю вам хорошего здоровья и здоровья.
[53:22.320 --> 53:34.000]  Это немного жаль, что я говорю, я говорю никто, вместо вас, но я надеюсь, что вы слышите меня и
[53:34.000 --> 53:46.960]  и Борис Миркин был моим учителем, моим учителем и учителями мы всегда любили
[53:48.080 --> 53:54.880]  его учителя, наслаждались их, они были очень интересными, мы appreciate его
[53:54.880 --> 53:55.520]  учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, учителя, у
[54:24.880 --> 54:26.880]  учителя, учителя, учителя.
[54:54.880 --> 55:11.880]  У нас есть группа индивидуалов, и они должны сделать коллективное решение, чтобы выбрать кандидата из группы возможных кандидатов.
[55:11.880 --> 55:27.880]  И в этом фреймворке есть проблема, что кандидаты могут предпочитать свои предпочтения, чтобы получать более предпочитательный результат.
[55:27.880 --> 55:31.880]  Это называется «манипуляционным проблемом в социальном выборе».
[55:32.880 --> 55:53.880]  Так что, в некотором смысле, это естественно и логично, потому что, если кандидаты могут предпочитать результат выбора, то они имеют возможность, они имеют возможность предпочитать результат выбора,
[55:53.880 --> 55:59.880]  и, в этом смысле, возможность манипуляции является последователем этого.
[56:00.880 --> 56:16.880]  Так что, есть известный теорет «Гиберт-Сеттет-Вейт», который говорит, что вся природа, вся fair voting rule,
[56:16.880 --> 56:35.880]  которая считает минимум три альтернатива как возможный результат, они можно манипулировать, и нандиктатуральные вибрации, они можно манипулировать.
[56:35.880 --> 56:54.880]  Но, если все нандиктатуральные вибрации в социальном выборе можно манипулировать, то это интересно узнать, до какого уровня они можно манипулировать, они способны к манипуляции.
[56:54.880 --> 57:08.880]  И очень широкая использовательная процедура для решения этого вопроса, это калкуляция probabilностей манипуляции.
[57:08.880 --> 57:19.880]  Так что, калкуляция пропорции профилей, возможности ситуаций, где манипуляция возможна.
[57:19.880 --> 57:40.880]  Так что, например, для «М» альтернатив и «Н» вибраций, есть «М» факториал, «Н» возможных профилей, возможных ситуаций,
[57:41.880 --> 57:55.880]  и мы калкулируем пропорцию манипуляции.
[57:55.880 --> 58:05.880]  Мы также считаем, что проблема манипуляции под инкомплитной информацией.
[58:05.880 --> 58:12.880]  Так что мы добавляем эту ассумпцию, чтобы сделать модуль более реалистичным в некотором смысле.
[58:12.880 --> 58:24.880]  Так что, вибрацы не знают все преференции других, они просто знают информацию о профиле преференции.
[58:24.880 --> 58:44.880]  Если вибратор имеет инсцентив манипуляции в профиле «П», но это не означает, что манипуляция он успешна в этом профиле,
[58:44.880 --> 58:52.880]  потому что он или она не знает преференции, они просто знают информацию.
[58:52.880 --> 59:10.880]  И он или она, альтернатив, имеет инсцентив манипуляции, если в сете всех возможных ситуаций у него есть возможность улучшить его преференцию, в том числе и в некотором из них.
[59:10.880 --> 59:19.880]  Так что, в простых словах, мы увидим это в деталях дальше.
[59:19.880 --> 59:23.880]  Так что, я сейчас объясню фреймворк.
[59:23.880 --> 59:32.880]  Позвольте, что N будет сетом манипуляций, и количество манипуляций означает маленький N.
[59:32.880 --> 59:35.880]  X является сетом альтернатив.
[59:36.880 --> 59:43.880]  Так что, кардинальность этого сета – M.
[59:43.880 --> 59:54.880]  Pi – это нотация для преференции вибратора I, который является линией.
[59:54.880 --> 59:59.880]  И P, вибратор P – это профиль преференции.
[59:59.880 --> 01:00:06.880]  Мы рассматриваем правила агрегации в том числе.
[01:00:06.880 --> 01:00:18.880]  Корреспонденция вибратора I – это правила, которая берет профиль преференции и, в результате, дает сету альтернатив.
[01:00:18.880 --> 01:00:24.880]  Так что, если у нас есть какие-то сеты, альтернативы вибратора I, которые получаются по поводу этого процедуры,
[01:00:24.880 --> 01:00:36.880]  мы используем правила агрегации вибратора I, чтобы выбрать уникальный победитель.
[01:00:37.880 --> 01:00:45.880]  Эта правила считается алфабетикой, так что есть определенные правила.
[01:00:45.880 --> 01:01:03.880]  И мы выбираем из сета а, один альтернатив, который не доминируется по этому правилу, который указан по правилам P.T.
[01:01:03.880 --> 01:01:15.880]  И вибратор V – это правила, которая берет профиль преференции и, в результате, дает сету альтернативы.
[01:01:15.880 --> 01:01:22.880]  И мы рассматриваем правила агрегации вибратора V, которые получаются по поводу этого процедуры.
[01:01:22.880 --> 01:01:30.880]  Первое, профиль – это полная информация, когда мы знаем все о профиле преференции.
[01:01:30.880 --> 01:01:41.880]  Так что, функция полной информации P – это функция для публичной информации.
[01:01:41.880 --> 01:01:45.880]  Что мы знаем о профиле преференции P?
[01:01:45.880 --> 01:01:50.880]  Ранк PIF – полная информация функция.
[01:01:50.880 --> 01:02:00.880]  Это функция, которая вернует рейтинг альтернативы по этому правилу.
[01:02:00.880 --> 01:02:03.880]  Правила также известна.
[01:02:03.880 --> 01:02:07.880]  Вибратор PIF вернует…
[01:02:07.880 --> 01:02:13.880]  Извините, что здесь должен быть C of P.
[01:02:13.880 --> 01:02:18.880]  Вернует сету альтернатив, которые вернуют.
[01:02:18.880 --> 01:02:27.880]  И вибратор Unique Winner PIF вернует Unique Winner после тайбреки.
[01:02:28.880 --> 01:02:33.880]  Так что, есть четыре типа функций полной информации.
[01:02:33.880 --> 01:02:38.880]  И что это означает для вибратора, чтобы иметь альтернативы к манипуляции?
[01:02:38.880 --> 01:02:42.880]  У него есть информация-сет.
[01:02:42.880 --> 01:02:49.880]  Так что, это сета всех возможных ситуаций или профилей преференции,
[01:02:49.880 --> 01:02:54.880]  которые консистентны с его информацией.
[01:02:54.880 --> 01:03:00.880]  С информацией, что он имеет из общественных средств.
[01:03:00.880 --> 01:03:07.880]  Так что, это его мир, в некотором смысле.
[01:03:08.880 --> 01:03:11.880]  Дефинирование манипуляции.
[01:03:11.880 --> 01:03:17.880]  Если это коалиционная манипуляция…
[01:03:17.880 --> 01:03:22.880]  Нет, это индивидуальная манипуляция.
[01:03:22.880 --> 01:03:25.880]  Когда индивидуальный манипулирует.
[01:03:25.880 --> 01:03:33.880]  Если в его информации-сете есть такой профиль преференции,
[01:03:33.880 --> 01:03:41.880]  так что, поменяв свои преференции к P tilde,
[01:03:41.880 --> 01:03:46.880]  он может получать что-то лучше,
[01:03:46.880 --> 01:03:51.880]  и он не получит что-то хуже, как результат.
[01:03:51.880 --> 01:03:58.880]  Так что, есть возможность улучшить результат вибраторного процедуры.
[01:03:58.880 --> 01:04:03.880]  И нет шанса получать что-то хуже.
[01:04:03.880 --> 01:04:10.880]  Проблемность индивидуальной манипуляции
[01:04:10.880 --> 01:04:16.880]  демонстрирует индекс I
[01:04:16.880 --> 01:04:21.880]  с небольшим индексом,
[01:04:22.880 --> 01:04:29.880]  и в диалоге с профилем преференции,
[01:04:29.880 --> 01:04:32.880]  есть хоть один votа,
[01:04:32.880 --> 01:04:39.880]  который может манипулировать в этом роли.
[01:04:39.880 --> 01:04:46.880]  Что значит манипуляция в коалиционной манипуляции?
[01:04:46.880 --> 01:04:50.880]  Когда мы считаем манипуляцию в коалиционной манипуляции.
[01:04:50.880 --> 01:05:01.680]  Each voter has a set of other voters, who have the same preferences, so his coalition,
[01:05:01.680 --> 01:05:04.680]  co-minded people.
[01:05:04.680 --> 01:05:18.600]  And if all his members in this coalition change their preferences the same way, and they can
[01:05:18.600 --> 01:05:25.560]  achieve a better voting result, then they all have an incentive to manipulate.
[01:05:25.560 --> 01:05:34.360]  And as in the previous definition, they don't have a chance to get something worse from their
[01:05:34.360 --> 01:05:35.860]  manipulation.
[01:05:35.860 --> 01:05:47.400]  So that's a way a voter can think about other voters' actions in the framework of incomplete
[01:05:47.400 --> 01:05:52.360]  information.
[01:05:52.360 --> 01:06:03.920]  So we consider several social choice correspondences, social choice rules.
[01:06:03.920 --> 01:06:13.640]  Among them there is the most important class of scoring rules, which are defined by a scoring
[01:06:13.640 --> 01:06:15.480]  vector.
[01:06:15.480 --> 01:06:26.320]  And Sj in this vector denotes the score assigned to any alternative for its j-th position in
[01:06:26.320 --> 01:06:28.840]  individual preferences.
[01:06:28.840 --> 01:06:38.240]  So S1 denotes how many scores it gets for the top position, for the first position in preferences.
[01:06:38.240 --> 01:06:44.960]  Sm denotes how many scores it gets from the bottom position.
[01:06:44.960 --> 01:06:57.120]  And we sum these scores over all voters to get the total score of each alternative.
[01:06:57.120 --> 01:07:01.520]  So the most popular rule is plurality, for example.
[01:07:01.520 --> 01:07:07.000]  We assign exactly one score to each alternative for the top position.
[01:07:07.000 --> 01:07:12.040]  And we assign zero, we give zero scores for any other positions.
[01:07:12.040 --> 01:07:18.960]  So we count just the number of top positions for each alternative.
[01:07:18.960 --> 01:07:29.680]  In Vitor rule, we minimize the number of bottom positions for alternatives.
[01:07:29.680 --> 01:07:39.800]  And in this case, we need to give one score for each position, which is not bottom position,
[01:07:39.800 --> 01:07:41.760]  to any alternative.
[01:07:41.760 --> 01:07:48.760]  So we just give zero for the bottom and ones for every other position.
[01:07:48.760 --> 01:07:51.760]  And Vitor rule is the following.
[01:07:51.760 --> 01:08:04.520]  We give M-1 alternative score for the first position, and then we give M-2, M-3, etc.,
[01:08:04.520 --> 01:08:10.000]  until zero for the bottom position.
[01:08:10.000 --> 01:08:14.480]  So why I explain in such details these rules?
[01:08:14.480 --> 01:08:21.080]  Because the main results of this research are about scoring rules.
[01:08:21.080 --> 01:08:35.360]  For example, this one is the asymptotic behavior of manipulability index for individual manipulation,
[01:08:35.360 --> 01:08:43.520]  so the probability of individual manipulation under the information, public information
[01:08:43.520 --> 01:08:51.000]  about the unique winner for plurality rule, the most popular one.
[01:08:51.000 --> 01:08:57.560]  When we use alphabetic tie-breaking, then when the number of voters approaches infinity,
[01:08:57.560 --> 01:09:03.740]  goes to infinity, then this index, this probability tends to one.
[01:09:03.740 --> 01:09:11.940]  So it means that in almost in every possible situation, you will have an individual, at
[01:09:11.940 --> 01:09:18.760]  least one individual, who has an incentive to misrepresent his preferences.
[01:09:18.760 --> 01:09:29.660]  So it couldn't be called protected from manipulation this rule, for example, under this very kind
[01:09:29.660 --> 01:09:32.380]  of information.
[01:09:33.220 --> 01:09:41.380]  However, when you change the type of information to winner, so it means that we know a set
[01:09:41.380 --> 01:09:53.460]  of winners, then this value depends on the number of alternatives, this value, which this
[01:09:53.460 --> 01:09:58.820]  index approaches to when the number of voters goes to infinity.
[01:09:58.820 --> 01:10:02.620]  It is 1 minus 1 divided by m.
[01:10:02.620 --> 01:10:09.220]  So we change the type of information and we immediately change the number of possible situations,
[01:10:09.220 --> 01:10:17.340]  which are susceptible to manipulation.
[01:10:17.340 --> 01:10:20.860]  This is coalitional manipulation.
[01:10:20.900 --> 01:10:33.220]  When we switch from individuals to coalitions, then this index again is equal to 1 in asymptotic.
[01:10:33.220 --> 01:10:40.380]  With alphabetic tie-breaking, almost in every situation, again, we'll have at least one
[01:10:40.380 --> 01:10:50.580]  voter who has an incentive to manipulate, to vote strategically, insincerely.
[01:10:50.660 --> 01:10:54.740]  And he thinks about his coalition members.
[01:10:54.740 --> 01:11:03.460]  So when he feels some support from commended people.
[01:11:03.460 --> 01:11:06.100]  That's the asymptotic behavior of border rule.
[01:11:06.100 --> 01:11:13.020]  It's again 1 for coalitions.
[01:11:13.020 --> 01:11:23.940]  And we prove that for any number of voters and any number of alternatives, the probability
[01:11:23.940 --> 01:11:31.020]  of coalitional manipulation equals the probability of individual manipulation when we have information
[01:11:31.020 --> 01:11:42.340]  about a single, a unique winner of the election for all scoring rules, for every scoring rule.
[01:11:42.340 --> 01:11:48.260]  And we conducted some computational experiments just to view, to observe how these indices
[01:11:48.260 --> 01:11:55.300]  behave and you may clearly observe it.
[01:11:55.300 --> 01:12:08.460]  And compare the left-hand side graph illustrates individual manipulations, the probability
[01:12:08.500 --> 01:12:16.900]  of individual manipulation, popularity rule and different kinds of public information.
[01:12:16.900 --> 01:12:25.620]  And on the right-hand side, you can see coalitional manipulability index.
[01:12:25.620 --> 01:12:36.220]  And you see that for individual manipulation, we see only one graph approaching one.
[01:12:36.220 --> 01:12:48.980]  It's the graph, it's a line corresponding to the information which is the least perfect.
[01:12:48.980 --> 01:12:51.940]  So it's information about the unique winner.
[01:12:51.940 --> 01:13:04.060]  And this graph illustrates the first theorem in our slides.
[01:13:04.140 --> 01:13:14.620]  And for coalitional manipulation, we see this tendency, I think, maybe even for all of these graphs,
[01:13:14.620 --> 01:13:21.140]  this one approaching tendency.
[01:13:21.140 --> 01:13:24.700]  And what else we could see?
[01:13:24.700 --> 01:13:36.620]  The less information we have, the greater is the probability of manipulation.
[01:13:36.620 --> 01:13:47.460]  So in more situations, at least one voter will have an incentive to manipulate it.
[01:13:47.460 --> 01:14:08.220]  And it's the causes that information is not perfect, but it's useful that we have this here.
[01:14:08.260 --> 01:14:19.620]  So just the same situation for border rule, I will not consider it.
[01:14:19.620 --> 01:14:28.660]  And Vita rule is, we considered it, defined it.
[01:14:28.700 --> 01:14:44.540]  And in some sense, it is an exceptional rule, because for when we restrict information,
[01:14:44.540 --> 01:14:49.900]  when we give less information to voters, and when we switch to coalitional manipulation,
[01:14:49.900 --> 01:15:01.780]  this index for this very rule is getting smaller, is getting less.
[01:15:01.780 --> 01:15:13.300]  And for most kinds of information, it is almost zero or equals to zero in most cases.
[01:15:13.340 --> 01:15:23.900]  So Vita rule is, in some sense, it is protected from manipulations of individuals and coalitions,
[01:15:23.900 --> 01:15:34.460]  and from manipulations under incomplete information in such a way that in most situations,
[01:15:34.460 --> 01:15:40.460]  the manipulation is impossible in this rule.
[01:15:40.660 --> 01:15:47.020]  So these are the main points of my research.
[01:15:47.020 --> 01:15:50.300]  Thank you very much for your attention.
[01:15:50.300 --> 01:15:55.260]  I would be happy to answer your questions.
[01:16:10.460 --> 01:16:33.420]  In fact, the sample space was the set of all preference profiles here.
[01:16:34.140 --> 01:16:42.060]  And I just generated, created the set of all of them.
[01:16:42.060 --> 01:16:50.780]  So that's why I conducted the experiment just for the number of voters up to 15.
[01:16:50.780 --> 01:16:57.260]  And that was my limit for this.
[01:16:57.740 --> 01:17:05.580]  Another question is that when you are adding the whole source to the final voting process,
[01:17:05.580 --> 01:17:14.380]  as you mentioned, but previously you told that one voter may be averse to the other voter
[01:17:14.380 --> 01:17:17.580]  option, and you can think about it.
[01:17:17.580 --> 01:17:26.700]  So when you bring that in this case, then the voter might be influenced by the source
[01:17:26.780 --> 01:17:30.380]  What is the difference between a voter who is independent and a voter who is not?
[01:17:30.380 --> 01:17:44.380]  What is the difference between a voter who is independent and a voter who is not?
[01:17:44.380 --> 01:17:55.420]  He just thinks that voters with the same preferences as he has, they are identical
[01:17:55.420 --> 01:17:57.580]  to himself.
[01:17:58.220 --> 01:18:07.740]  And in some sense, their incentives are identical too.
[01:18:07.740 --> 01:18:19.740]  So all these voters of the same type have the same incentives, and they want the same candidate
[01:18:19.740 --> 01:18:20.220]  to win.
[01:18:21.100 --> 01:18:28.620]  So that's why they may misrepresent their preferences in the same way.
[01:18:28.620 --> 01:18:34.300]  And this is what our manipulating voter takes into account.
[01:18:34.300 --> 01:18:44.780]  Same thing that what if all my coalition members will also change preferences in this way,
[01:18:44.780 --> 01:18:53.180]  and then we'll collectively achieve something better in this sense.
[01:19:15.180 --> 01:19:23.180]  Yes, yes, yes, yes, of course.
[01:19:23.180 --> 01:19:23.980]  Thank you.
[01:19:23.980 --> 01:19:25.980]  Any other question?
[01:19:25.980 --> 01:19:27.980]  Please.
[01:19:27.980 --> 01:19:31.980]  Could you come here, I invite you personally.
[01:19:31.980 --> 01:19:33.980]  The microphone.
[01:19:33.980 --> 01:19:37.980]  You are the next speaker.
[01:19:37.980 --> 01:19:39.980]  By the way.
[01:19:40.780 --> 01:19:45.180]  So for online participants to hear the question.
[01:19:45.180 --> 01:19:47.180]  Yes, please.
[01:19:47.180 --> 01:19:51.180]  I want to ask about the population size.
[01:19:51.180 --> 01:19:53.180]  Looking at these scales.
[01:19:53.180 --> 01:19:55.180]  Your population size is limited.
[01:19:55.180 --> 01:19:57.180]  Right, right.
[01:19:57.180 --> 01:20:03.180]  And when you look at the scales, they are pretty converging.
[01:20:03.180 --> 01:20:05.180]  Yes.
[01:20:05.180 --> 01:20:09.180]  How representative is this finding?
[01:20:09.180 --> 01:20:15.180]  Let's say, increase the value to 100, or 1,000.
[01:20:15.180 --> 01:20:22.780]  So these experiments are conducted for the case with three alternatives, you see, and the
[01:20:22.780 --> 01:20:29.980]  number of voters from 3 to 15 everywhere.
[01:20:29.980 --> 01:20:35.180]  And for this case, we observe some tendency.
[01:20:35.180 --> 01:20:47.180]  So it's just for illustration results, which we obtained for general M and N.
[01:20:47.180 --> 01:20:53.180]  So you see, these results are for any number of alternatives.
[01:20:53.180 --> 01:21:03.180]  When we have infinitely, we have a number of voters tending to infinity,
[01:21:03.180 --> 01:21:07.180]  then this holds.
[01:21:07.180 --> 01:21:17.180]  But I couldn't say something for sure for other kinds of public information, you see.
[01:21:17.180 --> 01:21:23.180]  I haven't proved, for example, for rank function or score function.
[01:21:23.180 --> 01:21:25.180]  So I couldn't say anything.
[01:21:25.180 --> 01:21:27.180]  I couldn't say anything.
[01:21:27.180 --> 01:21:35.180]  But the graphs show that it may also tend to 1 or 2 something.
[01:21:35.180 --> 01:21:39.180]  So have I answered your question?
[01:21:39.180 --> 01:21:41.180]  Yes.
[01:21:41.180 --> 01:21:43.180]  Thank you.
[01:21:43.180 --> 01:21:47.180]  Any more questions?
[01:21:47.180 --> 01:21:49.180]  Okay.
[01:21:49.180 --> 01:21:51.180]  Thank you very much.
[01:21:51.180 --> 01:21:53.180]  Thank you.
[01:21:53.180 --> 01:21:57.180]  The next speaker is the guide to Turkish.
[01:22:15.180 --> 01:22:17.180]  Good afternoon, colleagues.
[01:22:17.180 --> 01:22:19.180]  I shall apologize for my voice.
[01:22:19.180 --> 01:22:21.180]  I think I could record.
[01:22:21.180 --> 01:22:23.180]  My name is Tendai.
[01:22:23.180 --> 01:22:25.180]  And I collaborate with Professor Boris Karangorin.
[01:22:25.180 --> 01:22:33.180]  And I want to present pseudobullying polynomials for dimensionality reduction and image processing.
[01:22:33.180 --> 01:22:37.180]  It's a celebration of Professor McKinsey.
[01:22:37.180 --> 01:22:43.180]  So I shall start.
[01:22:43.180 --> 01:22:49.180]  Now, the purpose of this talk is to showcase the usage of pseudobullying polynomials
[01:22:49.180 --> 01:22:53.180]  for those shortlisted tasks.
[01:22:53.180 --> 01:22:59.180]  It is a new formulation or a new technical approach to actually solving these tasks.
[01:22:59.180 --> 01:23:07.180]  So the main one is invariant dimensionality reduction, which we then use for purposes of cluster analysis,
[01:23:07.180 --> 01:23:11.180]  outlier detection, and feature selection.
[01:23:11.180 --> 01:23:19.180]  Then the other task is dedicated to detecting edges and blobs in image data,
[01:23:19.180 --> 01:23:29.180]  which we can use as well for image segmentation, as well as optical character recognition.
[01:23:29.180 --> 01:23:37.180]  So I think I'm not going to explain how you formulate pseudobullying polynomials,
[01:23:37.180 --> 01:23:43.180]  because I think you already realized yesterday from Professor Boris Karangorin.
[01:23:43.180 --> 01:23:51.180]  I'll just go to the properties that we desire to use for these purposes.
[01:23:51.180 --> 01:23:59.180]  So when we reduce a sample or an input matrix in pseudobullying formulation,
[01:23:59.180 --> 01:24:05.180]  there are basically three properties that arise, which I think you realized yesterday.
[01:24:05.180 --> 01:24:13.180]  There was P equivalent, there was P truncation, as well as compacting the initial data.
[01:24:13.180 --> 01:24:21.180]  So now the compacting property is the one property that we want to use for invariant or lossless data compression.
[01:24:21.180 --> 01:24:27.180]  And then P equivalent, we desire to use that for similarity comparison,
[01:24:27.180 --> 01:24:37.180]  in the sense that a pseudobullying polynomial would be a low-dimensional embedding of the initial data.
[01:24:37.180 --> 01:24:41.180]  And also there is gradient shift detection.
[01:24:41.180 --> 01:24:48.180]  Like in an image, we understand that when there is a change of color in the image matrix, we want to detect that.
[01:24:48.180 --> 01:24:54.180]  And by formulating the pseudobullying polynomials, we select some pitches of a given size,
[01:24:54.180 --> 01:25:02.180]  and then we check the power or the order or the degree of the resulting pseudobullying polynomial.
[01:25:02.180 --> 01:25:08.180]  If it is higher, it shows that the pitch is overlapping an edge.
[01:25:08.180 --> 01:25:13.180]  If it is lower or equal to zero, that means that it's basically the same information, same color.
[01:25:13.180 --> 01:25:16.180]  I will show in the following slides.
[01:25:16.180 --> 01:25:24.180]  Why do we desire to use pseudobullying formulation for dimensionality reduction,
[01:25:24.180 --> 01:25:31.180]  which we then proceed to use for clustering or unsupervised classification?
[01:25:31.180 --> 01:25:37.180]  We noticed that the other alternative tools that are available, for example,
[01:25:37.180 --> 01:25:41.180]  the t-distribute stochastic neighborhood embedding, t-SNE.
[01:25:41.180 --> 01:25:47.180]  Yes, they work fine for a number of selected cases.
[01:25:47.180 --> 01:25:55.180]  However, they have this nonconformity, this cost function involved.
[01:25:55.180 --> 01:26:09.180]  So the results might differ by differing the input values that we initialize during the formulation of the dimensionality reduction task.
[01:26:09.180 --> 01:26:14.180]  And this results in variance.
[01:26:14.180 --> 01:26:22.180]  There's also the other limitation of dependence on the whole population of samples.
[01:26:22.180 --> 01:26:29.180]  For example, using principal component analysis, we have to calculate some densities across each and every sample,
[01:26:29.180 --> 01:26:37.180]  and then make a distance function to compare, and then determine that, okay, this is the lower dimensionality of this value.
[01:26:37.180 --> 01:26:42.180]  And penalize those which have the smallest distance.
[01:26:42.180 --> 01:26:51.180]  However, with pseudobullying polynomials then, we operate every sample independently, one at a time.
[01:26:51.180 --> 01:26:57.180]  It does not involve any other information of any other sample in the population.
[01:26:57.180 --> 01:27:06.180]  And there is no variance, because the only input data in the formulation is the data that is described in that sample.
[01:27:06.180 --> 01:27:11.180]  There is nothing, no epsilon or whatsoever.
[01:27:11.180 --> 01:27:20.180]  So now, when we reduce, let's say, a data structure, which is, let's say, four dimensions, five dimensions,
[01:27:20.180 --> 01:27:33.180]  our desire is to reduce it to, let's say, three or two, because we can easily plot these dimensions on paper or on our computer screens.
[01:27:33.180 --> 01:27:45.180]  And then, once we have this lower dimension, we can actually find some lines that separate samples just by plotting,
[01:27:45.180 --> 01:27:51.180]  and then find the best separating line or the best separating plane in a Cartesian space.
[01:27:52.180 --> 01:28:02.180]  I think usually, let's say, for example, this very popular data set, Iris flower data set,
[01:28:02.180 --> 01:28:08.180]  is often used during the introduction to machine learning or data science, et cetera.
[01:28:08.180 --> 01:28:11.180]  And we all know that it is four-dimensional data.
[01:28:11.180 --> 01:28:13.180]  Why do we say four-dimensional data?
[01:28:13.180 --> 01:28:21.180]  Because every sample is described by the shape or length and its width, as well as the petal length and its petal width.
[01:28:21.180 --> 01:28:30.180]  Now, if we are to understand if there is any linear relationship between these particular values to the label that this flower depends on,
[01:28:30.180 --> 01:28:36.180]  physical or citrus or virginal, we realize that it is difficult.
[01:28:36.180 --> 01:28:48.180]  But now we decided that why don't we create an embedding that allows us to find an incidence of these particular dimensions,
[01:28:48.180 --> 01:29:01.180]  whereas the physical feature, like the sample and the petal, they represent it as rows with incidence with their physical quantities of length and width.
[01:29:01.180 --> 01:29:10.180]  And then looking at this, we realized that we already have a typical input to a formulation of suitable polynomials.
[01:29:10.180 --> 01:29:16.180]  And I would like to outline in this scenario that, of course, our method is not universal,
[01:29:16.180 --> 01:29:21.180]  because we require, we desire that our information is in matrix form.
[01:29:21.180 --> 01:29:29.180]  And there is also, and the matrix form makes sense, like the sense that the incidence values, they are related.
[01:29:33.180 --> 01:29:43.180]  Right. In this figure, I would like to highlight to you that each sample is reduced.
[01:29:43.180 --> 01:29:48.180]  Let me go back to the previous slide. Each sample is reduced, if you can see.
[01:29:51.180 --> 01:29:54.180]  Here, oops, it's not writing.
[01:30:02.180 --> 01:30:12.180]  Right. This sample ID 1, when we process it through a pseudobooling polynomial, it reduces to this value, 6.0, 2.4Y2.
[01:30:12.180 --> 01:30:18.180]  And all the other values, they also reduce into a characteristic like this.
[01:30:18.180 --> 01:30:27.180]  And then this aggregation, when we take it and express it as Cartesian coordinates,
[01:30:27.180 --> 01:30:32.180]  we can actually find some lines which separate these samples.
[01:30:32.180 --> 01:30:43.180]  And we denote that there is a single outlier, which we looked at it and realized that it is a particular outlier.
[01:30:43.180 --> 01:30:48.180]  And then there is also the other values, I think, here.
[01:30:50.180 --> 01:30:53.180]  They are very close to each other.
[01:30:53.180 --> 01:31:00.180]  We had to find some line that separated this.
[01:31:00.180 --> 01:31:05.180]  But looking at this, we realized that just by finding these separator lines,
[01:31:05.180 --> 01:31:12.180]  we can actually achieve a clustering after reducing this data into lower dimensions.
[01:31:12.180 --> 01:31:20.180]  And then we would also like to show in a more practical scenario
[01:31:24.180 --> 01:31:28.180]  the Wisconsin breast cancer diagnosis dataset.
[01:31:28.180 --> 01:31:36.180]  In this dataset, we have 30 features that describe a certain sample.
[01:31:36.180 --> 01:31:41.180]  And that is a very huge dimensionality.
[01:31:41.180 --> 01:31:51.180]  So we find how best we can represent this as a matrix that can input to the pseudobooling polynomial.
[01:31:51.180 --> 01:31:58.180]  In this scenario, I would also like to show that this is an example where we show the feature selection
[01:31:58.180 --> 01:32:06.180]  or feature dropping technique that results from this formulation.
[01:32:06.180 --> 01:32:13.180]  Now, this typical sample, for example, that you see here, it is reduced to this polynomial.
[01:32:13.180 --> 01:32:20.180]  And this is the characteristic polynomial for each and every sample in the dataset of 159 samples.
[01:32:20.180 --> 01:32:29.180]  And this automatically represents an XYZ vector, which we plot in the Cartesian space.
[01:32:29.180 --> 01:32:38.180]  And looking at this, I think this aggregation, we managed to drop, I think, two or three features
[01:32:38.180 --> 01:32:42.180]  so that we would find a line that best separates these samples.
[01:32:42.180 --> 01:32:50.180]  And it's an accuracy of close to 95.4% linear clustering.
[01:32:50.180 --> 01:32:59.180]  If we had taken this, we've also experimented by taking these reduced samples through an approximation technique
[01:32:59.180 --> 01:33:01.180]  like support vector machine or k-means.
[01:33:01.180 --> 01:33:04.180]  We actually can get even higher scores.
[01:33:04.180 --> 01:33:10.180]  But another goal of our research is to remove these approximations
[01:33:10.180 --> 01:33:16.180]  so that we can have invariant processing of our data.
[01:33:16.180 --> 01:33:21.180]  Now we go to the image processing part.
[01:33:21.180 --> 01:33:32.180]  Here we are particularly interested in our gradient shift that results by formulating pseudoboom polynomials.
[01:33:32.180 --> 01:33:40.180]  The property that we want to exploit here is the degree property of the resulting polynomial.
[01:33:40.180 --> 01:33:52.180]  And it allows us to detect whether a certain image that we have processed in the data is over an edge or it is over a blob region in the image data.
[01:33:52.180 --> 01:33:56.180]  It is also helpful to us.
[01:33:56.180 --> 01:34:03.180]  We want to also extend p-equivalents so that we can go into object detection actually.
[01:34:03.180 --> 01:34:08.180]  It is an ongoing research.
[01:34:08.180 --> 01:34:21.180]  Now the algorithm is that we take the image metrics and then we extract some windows, sliding windows, or rather a page of some literal size.
[01:34:21.180 --> 01:34:26.180]  Let's say 3x3 is shown here, or we take 8x8.
[01:34:26.180 --> 01:34:32.180]  It's just conditional. It's conditional to how much sensitive we want our edge detection to be.
[01:34:33.180 --> 01:34:38.180]  Now let's say this region, the first region that I colored here, it has only five values.
[01:34:38.180 --> 01:34:40.180]  These are constant values.
[01:34:40.180 --> 01:34:52.180]  And since the pseudoboom formulation that we use here is plain-autopaste, all the other values will aggregate to zero because we are subtracting down the row.
[01:34:52.180 --> 01:34:56.180]  And then summing the first row, we get 15.
[01:34:56.180 --> 01:34:59.180]  And this means we have a zero degree.
[01:34:59.180 --> 01:35:02.180]  There is no variable here.
[01:35:02.180 --> 01:35:10.180]  But looking at the other metrics here, it is different values that we process.
[01:35:10.180 --> 01:35:18.180]  And it results in a polynomial with the degree of 2.
[01:35:18.180 --> 01:35:21.180]  This is the maximum degree.
[01:35:21.180 --> 01:35:34.180]  Because it is happening due to the fact that the other rows are overlapping the data that is differing in color on the image metrics.
[01:35:34.180 --> 01:35:39.180]  So we already indicate them as overlaying an edge.
[01:35:40.180 --> 01:35:43.180]  Now, so practical examples that we did.
[01:35:43.180 --> 01:35:52.180]  For example, here I show a comparison of this edge detection processing comparing with the Kearney method here.
[01:35:52.180 --> 01:36:01.180]  You would see that the Kearney method allows us to just find the outward edges of this paper fruit in the input image here.
[01:36:01.180 --> 01:36:06.180]  But using pseudoboom polynomials here, we can actually see the depth.
[01:36:06.180 --> 01:36:20.180]  Because if you look at this 3D representation of this degrees, it shows that this region is power 2 or power 3 or power 0.
[01:36:20.180 --> 01:36:29.180]  And you can have a projection actually in 3D while at the same time achieving the edges that you desire.
[01:36:29.180 --> 01:36:37.180]  We also experimented in image segmentation task with the Dubai Satellite data set.
[01:36:37.180 --> 01:36:46.180]  And I would like to highlight the preprocessing that we are doing here, a Gaussian filter and a pixel length threshold.
[01:36:46.180 --> 01:36:54.180]  So that our input values are limited at least to a range of 0 to 10 or instead of 0 to 255.
[01:36:55.180 --> 01:36:59.180]  And this is the result that we have.
[01:36:59.180 --> 01:37:10.180]  Of course, we still need to go to the part where we have to detect that this region, it is a water body and this is a road.
[01:37:10.180 --> 01:37:12.180]  We are still working on that.
[01:37:12.180 --> 01:37:20.180]  But at the edge part of detecting it in segmentation, they are impressive results, I would say.
[01:37:20.180 --> 01:37:27.180]  So in summary, I would like to say that our proposed methods, they are explainable and combinatorial.
[01:37:27.180 --> 01:37:33.180]  I think in the medical sense, for example, in the Wisconsin data set for breast cancer,
[01:37:33.180 --> 01:37:39.180]  somebody would desire that they have a diagnosis which was approximated by this method because it is explainable.
[01:37:39.180 --> 01:37:47.180]  Instead of, let's say, a k-means vector machine algorithm.
[01:37:47.180 --> 01:37:55.180]  And then also we have the invariance initialization of parameters and independence of sample population and dimensionality reduction.
[01:37:55.180 --> 01:38:05.180]  And also very much controllable or flexible inputs to image segmentation or edge detection.
[01:38:05.180 --> 01:38:14.180]  In the future, we propose to exploit the p-equivalence property for actual object detection.
[01:38:14.180 --> 01:38:23.180]  We hope to use probably the resulting pseudobulding polynomials as lower dimensionality embeddings for the neural network, for example.
[01:38:23.180 --> 01:38:34.180]  And also exploit this agent blob detection to optical character recognition and interpolation of 3D data from 2D image data.
[01:38:34.180 --> 01:38:40.180]  If you desire to understand much about the formulation of pseudobulding polynomials,
[01:38:40.180 --> 01:38:50.180]  I recommend this book, Data Aggregation for P-Medium Problems, by Obatoi and Professor Boris Konenguari.
[01:38:50.180 --> 01:38:53.180]  There is also a series of information in industrial engineering.
[01:38:53.180 --> 01:39:00.180]  It is a very good book to understand the whole process of pseudobulding polynomial formulation.
[01:39:00.180 --> 01:39:05.180]  After this, I thank you for your attention. I can listen to your questions.
[01:39:05.180 --> 01:39:09.180]  Thank you very much.
[01:39:09.180 --> 01:39:18.180]  I would like to say thank you for your contributions to the episode book of the conference.
[01:39:18.180 --> 01:39:24.180]  So many changes to your spaces and to really independently.
[01:39:24.180 --> 01:39:37.180]  I really appreciate your contributions to this very, very frequently changed scale.
[01:39:37.180 --> 01:39:42.180]  I apologize and thank you very much.
[01:39:42.180 --> 01:39:47.180]  Maybe you have some questions. We have plenty of time.
[01:39:47.180 --> 01:39:50.180]  You're welcome.
[01:39:50.180 --> 01:40:05.180]  Yes.
[01:40:05.180 --> 01:40:18.180]  The thing is, can you help me? I need to open the presentation of Professor Konenguari.
[01:40:18.180 --> 01:40:27.180]  If you noticed from yesterday, the formulation of pseudobulding polynomial, we are subtracting the data.
[01:40:27.180 --> 01:40:36.180]  We are trying to minimize the cost of initial matrix.
[01:40:36.180 --> 01:40:45.180]  We are penalizing the least expensive feature or the previous one.
[01:40:45.180 --> 01:40:57.180]  Can you open the presentation of Professor Konenguari?
[01:40:57.180 --> 01:41:15.180]  That penalizing feature, when we apply it into image processing, we are now seeing that the previous image or the previous role in this page was less expensive or less expressive.
[01:41:15.180 --> 01:41:23.180]  For example, if it is a color 10, it is close to black, but if it is 250, then it is close to white.
[01:41:23.180 --> 01:41:31.180]  The 250 is more expressive, and it shows that there was a gradient shift from this value to that value.
[01:41:31.180 --> 01:41:38.180]  Whenever there are values which are transitioning from a smaller to a higher value or from a higher value to a smaller value,
[01:41:39.180 --> 01:41:58.180]  there is definitely going to be a variable attached to that monomial here.
[01:41:58.180 --> 01:42:16.180]  If you look in this processing, here we have created our delta C matrix, and then we are utilizing the permutation matrix, and we are utilizing it to represent our variables.
[01:42:16.180 --> 01:42:26.180]  When there is a difference between the previous value and the previous value, we are definitely going to have another y1 or y2 or y3.
[01:42:26.180 --> 01:42:34.180]  That is indicative of a shift in values. That is why we decided that it should represent an edge.
[01:42:56.180 --> 01:43:08.180]  This is the combinatorial combination.
[01:43:08.180 --> 01:43:18.180]  This is the combinatorial combination, just after the numerical example.
[01:43:18.180 --> 01:43:28.180]  This is the combinatorial combination.
[01:43:28.180 --> 01:43:38.180]  This is the combinatorial combination.
[01:43:38.180 --> 01:43:48.180]  This is the combinatorial combination.
[01:43:48.180 --> 01:43:58.180]  This is the combinatorial combination.
[01:43:58.180 --> 01:44:08.180]  This is the combinatorial combination.
[01:44:08.180 --> 01:44:18.180]  This is the combinatorial combination.
[01:44:18.180 --> 01:44:28.180]  This is the combinatorial combination.
[01:44:28.180 --> 01:44:38.180]  This is the combinatorial combination.
[01:44:38.180 --> 01:44:48.180]  This is the combinatorial combination.
[01:44:48.180 --> 01:44:58.180]  This is the combinatorial combination.
[01:44:58.180 --> 01:45:08.180]  This is the combinatorial combination.
[01:45:08.180 --> 01:45:18.180]  This is the combinatorial combination.
[01:45:18.180 --> 01:45:28.180]  This is the combinatorial combination.
[01:45:28.180 --> 01:45:38.180]  This is the combinatorial combination.
[01:45:38.180 --> 01:45:48.180]  This is the combinatorial combination.
[01:45:48.180 --> 01:45:58.180]  This is the combinatorial combination.
[01:45:58.180 --> 01:46:08.180]  This is the combinatorial combination.
[01:46:08.180 --> 01:46:18.180]  This is the combinatorial combination.
[01:46:18.180 --> 01:46:28.180]  This is the combinatorial combination.
[01:46:48.180 --> 01:46:58.180]  This is the combinatorial combination.
[01:46:58.180 --> 01:47:08.180]  This is the combinatorial combination.
[01:47:08.180 --> 01:47:18.180]  This is the combinatorial combination.
[01:47:18.180 --> 01:47:28.180]  This is the combinatorial combination.
[01:47:28.180 --> 01:47:38.180]  This is the combinatorial combination.
[01:47:38.180 --> 01:47:48.180]  This is the combinatorial combination.
[01:47:48.180 --> 01:47:58.180]  This is the combinatorial combination.
[01:47:58.180 --> 01:48:08.180]  This is the combinatorial combination.
[01:48:08.180 --> 01:48:18.180]  This is the combinatorial combination
[01:48:18.180 --> 01:48:28.180]  This is the combinatorial combination.
[01:48:28.180 --> 01:48:38.180]  This is the combinatorial combination.
[01:48:38.180 --> 01:48:48.180]  This is the combinatorial combination.
[01:48:48.180 --> 01:48:58.180]  This is the combinatorial combination.
[01:48:58.180 --> 01:49:08.180]  This is the combinatorial combination.
[01:49:08.180 --> 01:49:18.180]  This is the combinatorial combination.
[01:49:18.180 --> 01:49:26.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:49:26.180 --> 01:49:34.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:49:34.180 --> 01:49:44.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:49:44.180 --> 01:49:54.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:49:54.180 --> 01:50:04.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:50:04.180 --> 01:50:14.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:50:14.180 --> 01:50:24.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:50:24.180 --> 01:50:34.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:50:34.180 --> 01:50:44.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:50:44.180 --> 01:50:54.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:50:54.180 --> 01:51:04.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:51:04.180 --> 01:51:14.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:51:14.180 --> 01:51:24.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:51:24.180 --> 01:51:34.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:51:34.180 --> 01:51:44.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:51:44.180 --> 01:51:54.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:51:54.180 --> 01:52:04.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:04.180 --> 01:52:14.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:14.180 --> 01:52:24.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:24.180 --> 01:52:34.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:34.180 --> 01:52:42.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:42.180 --> 01:52:48.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:48.180 --> 01:52:56.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:52:56.180 --> 01:53:06.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:06.180 --> 01:53:12.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:12.180 --> 01:53:20.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:20.180 --> 01:53:30.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:30.180 --> 01:53:36.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:36.180 --> 01:53:44.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:44.180 --> 01:53:52.180]  If you compare the performance of your algorithm, for example, with real nouns, I probably missed it.
[01:53:53.180 --> 01:53:57.180]  We want to specify that our approach is indicative.
[01:53:57.180 --> 01:54:04.180]  It's not a replacement of the neural network.
[01:54:15.180 --> 01:54:19.180]  The improvement is the indicative nature of this approach.
[01:54:22.180 --> 01:54:24.180]  We want to specify that our approach is indicative of this approach.
[01:54:24.180 --> 01:54:26.180]  We want to specify that our approach is indicative of this approach.
[01:54:26.180 --> 01:54:28.180]  We want to specify that our approach is indicative of this approach.
[01:54:28.180 --> 01:54:30.180]  We want to specify that our approach is indicative of this approach.
[01:54:30.180 --> 01:54:32.180]  We want to specify that our approach is indicative of this approach.
[01:54:32.180 --> 01:54:34.180]  We want to specify that our approach is indicative of this approach.
[01:54:34.180 --> 01:54:36.180]  We want to specify that our approach is indicative of this approach.
[01:54:36.180 --> 01:54:38.180]  We want to specify that our approach is indicative of this approach.
[01:54:38.180 --> 01:54:40.180]  We want to specify that our approach is indicative of this approach.
[01:54:40.180 --> 01:54:42.180]  We want to specify that our approach is indicative of this approach.
[01:54:42.180 --> 01:54:44.180]  Yes, I don't know whether you Id Hello?
[01:54:49.180 --> 01:54:53.180]  We don't know what that is.
[01:54:53.180 --> 01:54:57.180]  Сборная линия просто...
[01:54:57.180 --> 01:55:04.180]  Да, мы просто найдем, какая у нас лучшая сборная линия.
[01:55:04.180 --> 01:55:10.180]  И вы поднимаете эти два линии объективным функциям?
[01:55:10.180 --> 01:55:14.180]  Да, это как в СВС.
[01:55:14.180 --> 01:55:23.180]  Как вы видите, в этой объективной линии, если вы посмотрите,
[01:55:23.180 --> 01:55:31.180]  в начале у меня было 10 разных колонн, но в этой объективной линии
[01:55:31.180 --> 01:55:36.180]  я выбрал 7 колонн вместо всех остальных,
[01:55:36.180 --> 01:55:39.180]  потому что в остальных колонн мы просто добавляем звуку.
[01:55:39.180 --> 01:55:46.180]  Так что мы хотели показать, что наш процессор позволяет нам анализировать
[01:55:46.180 --> 01:55:52.180]  эти multidimensional data и выделять эти функции, которые влияют на наш получение.
[01:55:52.180 --> 01:55:57.180]  И тогда мы можем использовать эти колонны и, может быть,
[01:55:57.180 --> 01:56:00.180]  тренироваться в нейронетворе и получать, вероятно, лучшую аккуратность.
[01:56:00.180 --> 01:56:03.180]  У меня нет никаких предложений о вашем участии.
[01:56:03.180 --> 01:56:07.180]  У вас есть комментарии о вашем участии?
[01:56:07.180 --> 01:56:08.180]  Да, у нас есть комментарии о вашем участии.
[01:56:08.180 --> 01:56:09.180]  Да, у нас есть комментарии о вашем участии.
[01:56:09.180 --> 01:56:10.180]  Да, у нас есть комментарии о вашем участии.
[01:56:10.180 --> 01:56:11.180]  Да, у нас есть комментарии о вашем участии.
[01:56:11.180 --> 01:56:12.180]  Да, у нас есть комментарии о вашем участии.
[01:56:12.180 --> 01:56:13.180]  Да, у нас есть комментарии о вашем участии.
[01:56:13.180 --> 01:56:14.180]  Да, у нас есть комментарии о вашем участии.
[01:56:14.180 --> 01:56:15.180]  Да, у нас есть комментарии о вашем участии.
[01:56:15.180 --> 01:56:16.180]  Да, у нас есть комментарии о вашем участии.
[01:56:16.180 --> 01:56:17.180]  Да, у нас есть комментарии о вашем участии.
[01:56:17.180 --> 01:56:18.180]  Да, у нас есть комментарии о вашем участии.
[01:56:18.180 --> 01:56:19.180]  Да, у нас есть комментарии о вашем участии.
[01:56:19.180 --> 01:56:20.180]  Да, у нас есть комментарии о вашем участии.
[01:56:33.180 --> 01:56:34.180]  Да, у нас есть комментарии о вашем участии.
[01:56:34.180 --> 01:56:35.180]  Да, у нас есть комментарии о вашем участии.
[01:56:35.180 --> 01:56:36.180]  Да, у нас есть комментарии о вашем участии.
[01:56:36.180 --> 01:56:37.180]  Да, у нас есть комментарии о вашем участии.
[01:56:37.180 --> 01:56:38.180]  Да, у нас есть комментарии о вашем участии.
[01:56:38.180 --> 01:56:39.180]  Да, у нас есть комментарии о вашем участии.
[01:56:39.180 --> 01:56:40.180]  Да, у нас есть комментарии о вашем участии.
[01:56:40.180 --> 01:56:41.180]  Да, у нас есть комментарии о вашем участии.
[01:56:41.180 --> 01:56:42.180]  Да, у нас есть комментарии о вашем участии.
[01:56:42.180 --> 01:56:43.180]  Да, у нас есть комментарии о вашем участии.
[01:56:43.180 --> 01:56:44.180]  Да, у нас есть комментарии о вашем участии.
[01:56:44.180 --> 01:56:45.180]  Да, у нас есть комментарии о вашем участии.
[01:56:45.180 --> 01:56:46.180]  Да, у нас есть комментарии о вашем участии.
[01:56:46.180 --> 01:57:00.180]  Да, у нас есть комментарии о вашем участии.
[01:57:00.180 --> 01:57:13.180]  Да, у нас есть комментарии о вашем участии.
[01:57:13.180 --> 01:57:38.180]  Да, у нас есть комментарии о вашем участии.
[01:57:38.180 --> 01:58:05.180]  Да, у нас есть комментарии о вашем участии.
[01:58:05.180 --> 01:58:32.180]  Да, у нас есть комментарии о вашем участии.
[01:58:32.180 --> 01:58:59.180]  Да, у нас есть комментарии о вашем участии.
[01:58:59.180 --> 01:59:26.180]  Да, у нас есть комментарии о вашем участии.
[01:59:26.180 --> 01:59:53.180]  Да, у нас есть комментарии о вашем участии.
[01:59:53.180 --> 02:00:20.180]  Да, у нас есть комментарии о вашем участии.
[02:00:20.180 --> 02:00:22.180]  Да, у нас есть комментарии о вашем участии.
[02:00:22.180 --> 02:00:23.180]  Да, у нас есть комментарии о вашем участии.
[02:00:23.180 --> 02:00:24.180]  Да, у нас есть комментарии о вашем участии.
[02:00:24.180 --> 02:00:25.180]  Да, у нас есть комментарии о вашем участии.
[02:00:25.180 --> 02:00:26.180]  Да, у нас есть комментарии о вашем участии.
[02:00:26.180 --> 02:00:27.180]  Да, у нас есть комментарии о вашем участии.
[02:00:27.180 --> 02:00:28.180]  Да, у нас есть комментарии о вашем участии.
[02:00:28.180 --> 02:00:29.180]  Да, у нас есть комментарии о вашем участии.
[02:00:29.180 --> 02:00:30.180]  Да, у нас есть комментарии о вашем участии.
[02:00:30.180 --> 02:00:31.180]  Да, у нас есть комментарии о вашем участии.
[02:00:31.180 --> 02:00:32.180]  Да, у нас есть комментарии о вашем участии.
[02:00:32.180 --> 02:00:33.180]  Да, у нас есть комментарии о вашем участии.
[02:00:33.180 --> 02:00:34.180]  Да, у нас есть комментарии о вашем участии.
[02:00:34.180 --> 02:00:35.180]  Да, у нас есть комментарии о вашем участии.
[02:00:35.180 --> 02:00:36.180]  Да, у нас есть комментарии о вашем участии.
[02:00:36.180 --> 02:00:37.180]  Да, у нас есть комментарии о вашем участии.
[02:00:37.180 --> 02:00:38.180]  Да, у нас есть комментарии о вашем участии.
[02:00:38.180 --> 02:00:39.180]  Да, у нас есть комментарии о вашем участии.
[02:00:39.180 --> 02:00:40.180]  Да, у нас есть комментарии о вашем участии.
[02:00:40.180 --> 02:00:41.180]  Да, у нас есть комментарии о вашем участии.
[02:00:41.180 --> 02:00:42.180]  Да, у нас есть комментарии о вашем участии.
[02:00:42.180 --> 02:00:43.180]  Да, у нас есть комментарии о вашем участии.
[02:00:43.180 --> 02:00:44.180]  Да, у нас есть комментарии о вашем участии.
[02:00:44.180 --> 02:00:45.180]  Да, у нас есть комментарии о вашем участии.
[02:00:45.180 --> 02:00:46.180]  Да, у нас есть комментарии о вашем участии.
[02:00:46.180 --> 02:00:47.180]  Да, у нас есть комментарии о вашем участии.
[02:00:48.180 --> 02:00:49.180]  Да, у нас есть комментарии о вашем участии.
[02:00:49.180 --> 02:00:50.180]  Да, у нас есть комментарии о вашем участии.
[02:00:50.180 --> 02:00:51.180]  Да, у нас есть комментарии о вашем участии.
[02:00:51.180 --> 02:00:52.180]  Да, у нас есть комментарии о вашем участии.
[02:00:52.180 --> 02:00:53.180]  Да, у нас есть комментарии о вашем участии.
[02:00:53.180 --> 02:00:54.180]  Да, у нас есть комментарии о вашем участии.
[02:00:54.180 --> 02:00:55.180]  Да, у нас есть комментарии о вашем участии.
[02:00:55.180 --> 02:00:56.180]  Да, у нас есть комментарии о вашем участии.
[02:00:56.180 --> 02:00:57.180]  Да, у нас есть комментарии о вашем участии.
[02:00:57.180 --> 02:00:58.180]  Да, у нас есть комментарии о вашем участии.
[02:00:58.180 --> 02:00:59.180]  Да, у нас есть комментарии о вашем участии.
[02:00:59.180 --> 02:01:00.180]  Да, у нас есть комментарии о вашем участии.
[02:01:00.180 --> 02:01:01.180]  Да, у нас есть комментарии о вашем участии.
[02:01:01.180 --> 02:01:02.180]  Да, у нас есть комментарии о вашем участии.
[02:01:02.180 --> 02:01:03.180]  Да, у нас есть комментарии о вашем участии.
[02:01:03.180 --> 02:01:04.180]  Да, у нас есть комментарии о вашем участии.
[02:01:04.180 --> 02:01:05.180]  Да, у нас есть комментарии о вашем участии.
[02:01:05.180 --> 02:01:06.180]  Да, у нас есть комментарии о вашем участии.
[02:01:06.180 --> 02:01:07.180]  Да, у нас есть комментарии о вашем участии.
[02:01:07.180 --> 02:01:08.180]  Да, у нас есть комментарии о вашем участии.
[02:01:08.180 --> 02:01:09.180]  Да, у нас есть комментарии о вашем участии.
[02:01:09.180 --> 02:01:10.180]  Да, у нас есть комментарии о вашем участии.
[02:01:10.180 --> 02:01:11.180]  Да, у нас есть комментарии о вашем участии.
[02:01:11.180 --> 02:01:12.180]  Да, у нас есть комментарии о вашем участии.
[02:01:12.180 --> 02:01:13.180]  Да, у нас есть комментарии о вашем участии.
[02:01:13.180 --> 02:01:14.180]  Да, у нас есть комментарии о вашем участии.
[02:01:15.180 --> 02:01:16.180]  Да, у нас есть комментарии о вашем участии.
[02:01:16.180 --> 02:01:17.180]  Да, у нас есть комментарии о вашем участии.
[02:01:17.180 --> 02:01:18.180]  Да, у нас есть комментарии о вашем участии.
[02:01:18.180 --> 02:01:19.180]  Да, у нас есть комментарии о вашем участии.
[02:01:19.180 --> 02:01:20.180]  Да, у нас есть комментарии о вашем участии.
[02:01:20.180 --> 02:01:21.180]  Да, у нас есть комментарии о вашем участии.
[02:01:21.180 --> 02:01:22.180]  Да, у нас есть комментарии о вашем участии.
[02:01:22.180 --> 02:01:23.180]  Да, у нас есть комментарии о вашем участии.
[02:01:23.180 --> 02:01:24.180]  Да, у нас есть комментарии о вашем участии.
[02:01:24.180 --> 02:01:25.180]  Да, у нас есть комментарии о вашем участии.
[02:01:25.180 --> 02:01:26.180]  Да, у нас есть комментарии о вашем участии.
[02:01:26.180 --> 02:01:27.180]  Да, у нас есть комментарии о вашем участии.
[02:01:27.180 --> 02:01:28.180]  Да, у нас есть комментарии о вашем участии.
[02:01:28.180 --> 02:01:29.180]  Да, у нас есть комментарии о вашем участии.
[02:01:29.180 --> 02:01:30.180]  Да, у нас есть комментарии о вашем участии.
[02:01:30.180 --> 02:01:31.180]  Да, у нас есть комментарии о вашем участии.
[02:01:31.180 --> 02:01:32.180]  Да, у нас есть комментарии о вашем участии.
[02:01:32.180 --> 02:01:33.180]  Да, у нас есть комментарии о вашем участии.
[02:01:33.180 --> 02:01:34.180]  Да, у нас есть комментарии о вашем участии.
[02:01:34.180 --> 02:01:35.180]  Да, у нас есть комментарии о вашем участии.
[02:01:35.180 --> 02:01:36.180]  Да, у нас есть комментарии о вашем участии.
[02:01:36.180 --> 02:01:37.180]  Да, у нас есть комментарии о вашем участии.
[02:01:37.180 --> 02:01:38.180]  Да, у нас есть комментарии о вашем участии.
[02:01:38.180 --> 02:01:39.180]  Да, у нас есть комментарии о вашем участии.
[02:01:39.180 --> 02:01:40.180]  Да, у нас есть комментарии о вашем участии.
[02:01:40.180 --> 02:01:41.180]  Да, у нас есть комментарии о вашем участии.
[02:01:41.180 --> 02:01:56.180]  Да, у нас есть комментарии о вашем участии.
[02:01:56.180 --> 02:02:16.180]  Да, у нас есть комментарии о вашем участии.
[02:02:16.180 --> 02:02:41.180]  Да, у нас есть комментарии о вашем участии.
[02:02:41.180 --> 02:03:06.180]  Да, у нас есть комментарии о вашем участии.
[02:03:06.180 --> 02:03:07.180]  Да, у нас есть комментарии о вашем участии.
[02:03:07.180 --> 02:03:08.180]  Да, у нас есть комментарии о вашем участии.
[02:03:08.180 --> 02:03:09.180]  Да, у нас есть комментарии о вашем участии.
[02:03:09.180 --> 02:03:10.180]  Да, у нас есть комментарии о вашем участии.
[02:03:10.180 --> 02:03:11.180]  Да, у нас есть комментарии о вашем участии.
[02:03:11.180 --> 02:03:12.180]  Да, у нас есть комментарии о вашем участии.
[02:03:12.180 --> 02:03:13.180]  Да, у нас есть комментарии о вашем участии.
[02:03:13.180 --> 02:03:14.180]  Да, у нас есть комментарии о вашем участии.
[02:03:14.180 --> 02:03:15.180]  Да, у нас есть комментарии о вашем участии.
[02:03:15.180 --> 02:03:16.180]  Да, у нас есть комментарии о вашем участии.
[02:03:16.180 --> 02:03:17.180]  Да, у нас есть комментарии о вашем участии.
[02:03:17.180 --> 02:03:18.180]  Да, у нас есть комментарии о вашем участии.
[02:03:18.180 --> 02:03:19.180]  Да, у нас есть комментарии о вашем участии.
[02:03:19.180 --> 02:03:20.180]  Да, у нас есть комментарии о вашем участии.
[02:03:20.180 --> 02:03:21.180]  Да, у нас есть комментарии о вашем участии.
[02:03:21.180 --> 02:03:22.180]  Да, у нас есть комментарии о вашем участии.
[02:03:22.180 --> 02:03:36.180]  Да, у нас есть комментарии о вашем участии.
[02:03:36.180 --> 02:03:51.180]  Да, у нас есть комментарии о вашем участии.
[02:03:51.180 --> 02:04:06.180]  Да, у нас есть комментарии о вашем участии.
[02:04:06.180 --> 02:04:26.180]  Да, у нас есть комментарии о вашем участии.
[02:04:26.180 --> 02:04:51.180]  Да, у нас есть комментарии о вашем участии.
[02:04:51.180 --> 02:05:16.180]  Да, у нас есть комментарии о вашем участии.
[02:05:16.180 --> 02:05:41.180]  Да, у нас есть комментарии о вашем участии.
[02:05:41.180 --> 02:06:06.180]  Да, у нас есть комментарии о вашем участии.
[02:06:06.180 --> 02:06:31.180]  Да, у нас есть комментарии о вашем участии.
[02:06:31.180 --> 02:06:53.180]  Да, у нас есть комментарии о вашем участии.
[02:06:53.180 --> 02:07:18.180]  Да, у нас есть комментарии о вашем участии.
[02:07:18.180 --> 02:07:43.180]  Да, у нас есть комментарии о вашем участии.
[02:07:43.180 --> 02:08:08.180]  Да, у нас есть комментарии о вашем участии.
[02:08:08.180 --> 02:08:28.180]  Да, у нас есть комментарии о вашем участии.
[02:08:28.180 --> 02:08:48.180]  Да, у нас есть комментарии о вашем участии.
[02:08:48.180 --> 02:09:08.180]  Да, у нас есть комментарии о вашем участии.
[02:09:08.180 --> 02:09:28.180]  Да, у нас есть комментарии о вашем участии.
[02:09:28.180 --> 02:09:52.180]  Да, у нас есть комментарии о вашем участии.
[02:09:58.180 --> 02:10:26.180]  Да, у нас есть комментарии о вашем участии.
[02:10:26.180 --> 02:10:28.180]  Да, у нас есть комментарии о вашем участии.
[02:10:28.180 --> 02:10:30.180]  Да, у нас есть комментарии о вашем участии.
[02:10:30.180 --> 02:10:32.180]  Да, у нас есть комментарии о вашем участии.
[02:10:32.180 --> 02:10:34.180]  Да, у нас есть комментарии о вашем участии.
[02:10:34.180 --> 02:10:36.180]  Да, у нас есть комментарии о вашем участии.
[02:10:36.180 --> 02:10:38.180]  Да, у нас есть комментарии о вашем участии.
[02:10:38.180 --> 02:10:40.180]  Да, у нас есть комментарии о вашем участии.
[02:10:40.180 --> 02:10:42.180]  Да, у нас есть комментарии о вашем участии.
[02:10:42.180 --> 02:10:44.180]  Да, у нас есть комментарии о вашем участии.
[02:10:44.180 --> 02:10:46.180]  Да, у нас есть комментарии о вашем участии.
[02:10:46.180 --> 02:10:48.180]  Да, у нас есть комментарии о вашем участии.
[02:10:49.180 --> 02:10:52.180]  Да, у нас есть комментарии о вашем участии.
[02:10:52.180 --> 02:10:54.180]  Да, у нас есть комментарии о вашем участии.
[02:10:54.180 --> 02:10:56.180]  Да, у нас есть комментарии о вашем участии.
[02:10:56.180 --> 02:10:58.180]  Да, у нас есть комментарии о вашем участии.
[02:10:58.180 --> 02:11:00.180]  Да, у нас есть комментарии о вашем участии.
[02:11:00.180 --> 02:11:02.180]  Да, у нас есть комментарии о вашем участии.
[02:11:02.180 --> 02:11:04.180]  Да, у нас есть комментарии о вашем участии.
[02:11:04.180 --> 02:11:06.180]  Да, у нас есть комментарии о вашем участии.
[02:11:06.180 --> 02:11:08.180]  Да, у нас есть комментарии о вашем участии.
[02:11:08.180 --> 02:11:10.180]  Да, у нас есть комментарии о вашем участии.
[02:11:10.180 --> 02:11:12.180]  Да, у нас есть комментарии о вашем участии.
[02:11:12.180 --> 02:11:14.180]  Да, у нас есть комментарии о вашем участии.
[02:11:14.180 --> 02:11:16.180]  Да, у нас есть комментарии о вашем участии.
[02:11:16.180 --> 02:11:18.180]  Да, у нас есть комментарии о вашем участии.
[02:11:20.180 --> 02:11:22.180]  Да, у нас есть комментарии о вашем участии.
[02:11:22.180 --> 02:11:24.180]  Да, у нас есть комментарии о вашем участии.
[02:11:24.180 --> 02:11:26.180]  Да, у нас есть комментарии о вашем участии.
[02:11:26.180 --> 02:11:28.180]  Да, у нас есть комментарии о вашем участии.
[02:11:28.180 --> 02:11:30.180]  Да, у нас есть комментарии о вашем участии.
[02:11:30.180 --> 02:11:32.180]  Да, у нас есть комментарии о вашем участии.
[02:11:32.180 --> 02:11:34.180]  Да, у нас есть комментарии о вашем участии.
[02:11:34.180 --> 02:11:36.180]  Да, у нас есть комментарии о вашем участии.
[02:11:36.180 --> 02:11:38.180]  Да, у нас есть комментарии о вашем участии.
[02:11:38.180 --> 02:11:40.180]  Да, у нас есть комментарии о вашем участии.
[02:11:40.180 --> 02:11:42.180]  Да, у нас есть комментарии о вашем участии.
[02:11:42.180 --> 02:11:44.180]  Да, у нас есть комментарии о вашем участии.
[02:11:44.180 --> 02:11:46.180]  Да, у нас есть комментарии о вашем участии.
[02:11:46.180 --> 02:11:48.180]  Да, у нас есть комментарии о вашем участии.
[02:11:48.180 --> 02:11:50.180]  Да, у нас есть комментарии о вашем участии.
[02:11:50.180 --> 02:11:52.180]  Да, у нас есть комментарии о вашем участии.
[02:11:52.180 --> 02:11:54.180]  Да, у нас есть комментарии о вашем участии.
[02:11:54.180 --> 02:11:56.180]  Да, у нас есть комментарии о вашем участии.
[02:11:58.180 --> 02:12:00.180]  Да, у нас есть комментарии о вашем участии.
[02:12:00.180 --> 02:12:02.180]  Да, у нас есть комментарии о вашем участии.
[02:12:02.180 --> 02:12:04.180]  Да, у нас есть комментарии о вашем участии.
[02:12:04.180 --> 02:12:06.180]  Да, у нас есть комментарии о вашем участии.
[02:12:06.180 --> 02:12:08.180]  Да, у нас есть комментарии о вашем участии.
[02:12:08.180 --> 02:12:10.180]  Да, у нас есть комментарии о вашем участии.
[02:12:10.180 --> 02:12:12.180]  Да, у нас есть комментарии о вашем участии.
[02:12:12.180 --> 02:12:14.180]  Да, у нас есть комментарии о вашем участии.
[02:12:14.180 --> 02:12:16.180]  Да, у нас есть комментарии о вашем участии.
[02:12:16.180 --> 02:12:18.180]  Да, у нас есть комментарии о вашем участии.
[02:12:18.180 --> 02:12:20.180]  Да, у нас есть комментарии о вашем участии.
[02:12:20.180 --> 02:12:22.180]  Да, у нас есть комментарии о вашем участии.
[02:12:24.180 --> 02:12:26.180]  Да, у нас есть комментарии о вашем участии.
[02:12:26.180 --> 02:12:28.180]  Да, у нас есть комментарии о вашем участии.
[02:12:28.180 --> 02:12:30.180]  Да, у нас есть комментарии о вашем участии.
[02:12:30.180 --> 02:12:32.180]  Да, у нас есть комментарии о вашем участии.
[02:12:32.180 --> 02:12:34.180]  Да, у нас есть комментарии о вашем участии.
[02:12:34.180 --> 02:12:36.180]  Да, у нас есть комментарии о вашем участии.
[02:12:36.180 --> 02:12:38.180]  Да, у нас есть комментарии о вашем участии.
[02:12:38.180 --> 02:12:40.180]  Да, у нас есть комментарии о вашем участии.
[02:12:40.180 --> 02:12:42.180]  Да, у нас есть комментарии о вашем участии.
[02:12:42.180 --> 02:12:44.180]  Да, у нас есть комментарии о вашем участии.
[02:12:44.180 --> 02:12:46.180]  Да, у нас есть комментарии о вашем участии.
[02:12:46.180 --> 02:12:48.180]  Да, у нас есть комментарии о вашем участии.
[02:12:48.180 --> 02:12:50.180]  Да, у нас есть комментарии о вашем участии.
[02:12:50.180 --> 02:12:52.180]  Да, у нас есть комментарии о вашем участии.
[02:12:52.180 --> 02:12:54.180]  Да, у нас есть комментарии о вашем участии.
[02:12:54.180 --> 02:12:56.180]  Да, у нас есть комментарии о вашем участии.
[02:12:56.180 --> 02:12:58.180]  Да, у нас есть комментарии о вашем участии.
[02:12:58.180 --> 02:13:00.180]  Да, у нас есть комментарии о вашем участии.
[02:13:00.180 --> 02:13:02.180]  Да, у нас есть комментарии о вашем участии.
[02:13:02.180 --> 02:13:04.180]  Да, у нас есть комментарии о вашем участии.
[02:13:04.180 --> 02:13:06.180]  Да, у нас есть комментарии о вашем участии.
[02:13:07.180 --> 02:13:10.180]  Да, у нас есть комментарии о вашем участии.
[02:13:10.180 --> 02:13:12.180]  Да, у нас есть комментарии о вашем участии.
[02:13:12.180 --> 02:13:14.180]  Да, у нас есть комментарии о вашем участии.
[02:13:14.180 --> 02:13:16.180]  Да, у нас есть комментарии о вашем участии.
[02:13:16.180 --> 02:13:18.180]  Да, у нас есть комментарии о вашем участии.
[02:13:18.180 --> 02:13:20.180]  Да, у нас есть комментарии о вашем участии.
[02:13:20.180 --> 02:13:22.180]  Да, у нас есть комментарии о вашем участии.
[02:13:22.180 --> 02:13:24.180]  Да, у нас есть комментарии о вашем участии.
[02:13:24.180 --> 02:13:26.180]  Да, у нас есть комментарии о вашем участии.
[02:13:26.180 --> 02:13:28.180]  Да, у нас есть комментарии о вашем участии.
[02:13:28.180 --> 02:13:30.180]  Да, у нас есть комментарии о вашем участии.
[02:13:30.180 --> 02:13:32.180]  Да, у нас есть комментарии о вашем участии.
[02:13:32.180 --> 02:13:34.180]  Да, у нас есть комментарии о вашем участии.
[02:13:34.180 --> 02:13:36.180]  Да, у нас есть комментарии о вашем участии.
[02:13:36.180 --> 02:13:38.180]  Да, у нас есть комментарии о вашем участии.
[02:13:38.180 --> 02:13:40.180]  Да, у нас есть комментарии о вашем участии.
[02:13:40.180 --> 02:13:42.180]  Да, у нас есть комментарии о вашем участии.
[02:13:42.180 --> 02:13:44.180]  Да, у нас есть комментарии о вашем участии.
[02:13:44.180 --> 02:13:46.180]  Да, у нас есть комментарии о вашем участии.
[02:13:46.180 --> 02:13:48.180]  Да, у нас есть комментарии о вашем участии.
[02:13:48.180 --> 02:13:50.180]  Да, у нас есть комментарии о вашем участии.
[02:13:50.180 --> 02:13:52.180]  Да, у нас есть комментарии о вашем участии.
[02:13:52.180 --> 02:13:54.180]  Да, у нас есть комментарии о вашем участии.
[02:13:54.180 --> 02:13:56.180]  Да, у нас есть комментарии о вашем участии.
[02:13:56.180 --> 02:13:58.180]  Да, у нас есть комментарии о вашем участии.
[02:13:58.180 --> 02:14:00.180]  Да, у нас есть комментарии о вашем участии.
[02:14:00.180 --> 02:14:02.180]  Да, у нас есть комментарии о вашем участии.
[02:14:02.180 --> 02:14:04.180]  Да, у нас есть комментарии о вашем участии.
[02:14:04.180 --> 02:14:06.180]  Да, у нас есть комментарии о вашем участии.
[02:14:06.180 --> 02:14:08.180]  Да, у нас есть комментарии о вашем участии.
[02:14:08.180 --> 02:14:10.180]  Да, у нас есть комментарии о вашем участии.
[02:14:10.180 --> 02:14:12.180]  Да, у нас есть комментарии о вашем участии.
[02:14:12.180 --> 02:14:14.180]  Да, у нас есть комментарии о вашем участии.
[02:14:14.180 --> 02:14:16.180]  Да, у нас есть комментарии о вашем участии.
[02:14:16.180 --> 02:14:18.180]  Да, у нас есть комментарии о вашем участии.
[02:14:18.180 --> 02:14:20.180]  Да, у нас есть комментарии о вашем участии.
[02:14:20.180 --> 02:14:22.180]  Да, у нас есть комментарии о вашем участии.
[02:14:22.180 --> 02:14:24.180]  Да, у нас есть комментарии о вашем участии.
[02:14:24.180 --> 02:14:26.180]  Да, у нас есть комментарии о вашем участии.
[02:14:27.180 --> 02:14:30.180]  Да, у нас есть комментарии о вашем участии.
[02:14:30.180 --> 02:14:32.180]  Да, у нас есть комментарии о вашем участии.
[02:14:32.180 --> 02:14:34.180]  Да, у нас есть комментарии о вашем участии.
[02:14:34.180 --> 02:14:36.180]  Да, у нас есть комментарии о вашем участии.
[02:14:36.180 --> 02:14:38.180]  Да, у нас есть комментарии о вашем участии.
[02:14:38.180 --> 02:14:40.180]  Да, у нас есть комментарии о вашем участии.
[02:14:40.180 --> 02:14:42.180]  Да, у нас есть комментарии о вашем участии.
[02:14:42.180 --> 02:14:44.180]  Да, у нас есть комментарии о вашем участии.
[02:14:44.180 --> 02:14:46.180]  Да, у нас есть комментарии о вашем участии.
[02:14:46.180 --> 02:14:48.180]  Да, у нас есть комментарии о вашем участии.
[02:14:48.180 --> 02:14:50.180]  Да, у нас есть комментарии о вашем участии.
[02:14:50.180 --> 02:14:52.180]  Да, у нас есть комментарии о вашем участии.
[02:14:52.180 --> 02:14:54.180]  Да, у нас есть комментарии о вашем участии.
[02:14:54.180 --> 02:14:56.180]  Да, у нас есть комментарии о вашем участии.
[02:14:56.180 --> 02:14:58.180]  Да, у нас есть комментарии о вашем участии.
[02:14:58.180 --> 02:15:00.180]  Да, у нас есть комментарии о вашем участии.
[02:15:00.180 --> 02:15:02.180]  Да, у нас есть комментарии о вашем участии.
[02:15:02.180 --> 02:15:04.180]  Да, у нас есть комментарии о вашем участии.
[02:15:06.180 --> 02:15:08.180]  Да, у нас есть комментарии о вашем участии.
[02:15:08.180 --> 02:15:10.180]  Да, у нас есть комментарии о вашем участии.
[02:15:10.180 --> 02:15:12.180]  Да, у нас есть комментарии о вашем участии.
[02:15:12.180 --> 02:15:14.180]  Да, у нас есть комментарии о вашем участии.
[02:15:14.180 --> 02:15:16.180]  Да, у нас есть комментарии о вашем участии.
[02:15:16.180 --> 02:15:18.180]  Да, у нас есть комментарии о вашем участии.
[02:15:18.180 --> 02:15:20.180]  Да, у нас есть комментарии о вашем участии.
[02:15:20.180 --> 02:15:22.180]  Да, у нас есть комментарии о вашем участии.
[02:15:22.180 --> 02:15:24.180]  Да, у нас есть комментарии о вашем участии.
[02:15:24.180 --> 02:15:26.180]  Да, у нас есть комментарии о вашем участии.
[02:15:26.180 --> 02:15:28.180]  Да, у нас есть комментарии о вашем участии.
[02:15:28.180 --> 02:15:30.180]  Да, у нас есть комментарии о вашем участии.
[02:15:30.180 --> 02:15:32.180]  Да, у нас есть комментарии о вашем участии.
[02:15:32.180 --> 02:15:34.180]  Да, у нас есть комментарии о вашем участии.
[02:15:36.180 --> 02:15:38.180]  Да, у нас есть комментарии о вашем участии.
[02:15:38.180 --> 02:15:40.180]  Да, у нас есть комментарии о вашем участии.
[02:15:40.180 --> 02:15:42.180]  Да, у нас есть комментарии о вашем участии.
[02:15:42.180 --> 02:15:44.180]  Да, у нас есть комментарии о вашем участии.
[02:15:44.180 --> 02:15:46.180]  Да, у нас есть комментарии о вашем участии.
[02:15:46.180 --> 02:15:48.180]  Да, у нас есть комментарии о вашем участии.
[02:15:48.180 --> 02:15:50.180]  Да, у нас есть комментарии о вашем участии.
[02:15:50.180 --> 02:15:52.180]  Да, у нас есть комментарии о вашем участии.
[02:15:52.180 --> 02:15:54.180]  Да, у нас есть комментарии о вашем участии.
[02:15:54.180 --> 02:15:56.180]  Да, у нас есть комментарии о вашем участии.
[02:15:56.180 --> 02:15:58.180]  Да, у нас есть комментарии о вашем участии.
[02:15:58.180 --> 02:16:00.180]  Да, у нас есть комментарии о вашем участии.
[02:16:00.180 --> 02:16:02.180]  Да, у нас есть комментарии о вашем участии.
[02:16:02.180 --> 02:16:04.180]  Да, у нас есть комментарии о вашем участии.
[02:16:04.180 --> 02:16:06.180]  Да, у нас есть комментарии о вашем участии.
[02:16:06.180 --> 02:16:08.180]  Да, у нас есть комментарии о вашем участии.
[02:16:10.180 --> 02:16:12.180]  Да, у нас есть комментарии о вашем участии.
[02:16:12.180 --> 02:16:14.180]  Да, у нас есть комментарии о вашем участии.
[02:16:14.180 --> 02:16:16.180]  Да, у нас есть комментарии о вашем участии.
[02:16:16.180 --> 02:16:18.180]  Да, у нас есть комментарии о вашем участии.
[02:16:18.180 --> 02:16:20.180]  Да, у нас есть комментарии о вашем участии.
[02:16:20.180 --> 02:16:22.180]  Да, у нас есть комментарии о вашем участии.
[02:16:22.180 --> 02:16:24.180]  Да, у нас есть комментарии о вашем участии.
[02:16:24.180 --> 02:16:26.180]  Да, у нас есть комментарии о вашем участии.
[02:16:26.180 --> 02:16:28.180]  Да, у нас есть комментарии о вашем участии.
[02:16:30.180 --> 02:16:32.180]  Да, у нас есть комментарии о вашем участии.
[02:16:32.180 --> 02:16:34.180]  Да, у нас есть комментарии о вашем участии.
[02:16:34.180 --> 02:16:36.180]  Да, у нас есть комментарии о вашем участии.
[02:16:36.180 --> 02:16:38.180]  Да, у нас есть комментарии о вашем участии.
[02:16:38.180 --> 02:16:40.180]  Да, у нас есть комментарии о вашем участии.
[02:16:40.180 --> 02:16:42.180]  Да, у нас есть комментарии о вашем участии.
[02:16:42.180 --> 02:16:44.180]  Да, у нас есть комментарии о вашем участии.
[02:16:44.180 --> 02:16:46.180]  Да, у нас есть комментарии о вашем участии.
[02:16:46.180 --> 02:16:48.180]  Да, у нас есть комментарии о вашем участии.
[02:16:48.180 --> 02:16:50.180]  Да, у нас есть комментарии о вашем участии.
[02:16:50.180 --> 02:16:52.180]  Да, у нас есть комментарии о вашем участии.
[02:16:52.180 --> 02:16:54.180]  Да, у нас есть комментарии о вашем участии.
[02:16:54.180 --> 02:16:56.180]  Да, у нас есть комментарии о вашем участии.
[02:16:56.180 --> 02:16:58.180]  Да, у нас есть комментарии о вашем участии.
[02:17:00.180 --> 02:17:02.180]  Да, у нас есть комментарии о вашем участии.
[02:17:02.180 --> 02:17:04.180]  Да, у нас есть комментарии о вашем участии.
[02:17:04.180 --> 02:17:06.180]  Да, у нас есть комментарии о вашем участии.
[02:17:06.180 --> 02:17:08.180]  Да, у нас есть комментарии о вашем участии.
[02:17:08.180 --> 02:17:10.180]  Да, у нас есть комментарии о вашем участии.
[02:17:10.180 --> 02:17:12.180]  Да, у нас есть комментарии о вашем участии.
[02:17:12.180 --> 02:17:14.180]  Да, у нас есть комментарии о вашем участии.
[02:17:14.180 --> 02:17:16.180]  Да, у нас есть комментарии о вашем участии.
[02:17:18.180 --> 02:17:20.180]  Да, у нас есть комментарии о вашем участии.
[02:17:20.180 --> 02:17:22.180]  Да, у нас есть комментарии о вашем участии.
[02:17:22.180 --> 02:17:24.180]  Да, у нас есть комментарии о вашем участии.
[02:17:24.180 --> 02:17:26.180]  Да, у нас есть комментарии о вашем участии.
[02:17:26.180 --> 02:17:28.180]  Да, у нас есть комментарии о вашем участии.
[02:17:28.180 --> 02:17:30.180]  Да, у нас есть комментарии о вашем участии.
[02:17:30.180 --> 02:17:32.180]  Да, у нас есть комментарии о вашем участии.
[02:17:32.180 --> 02:17:34.180]  Да, у нас есть комментарии о вашем участии.
[02:17:34.180 --> 02:17:36.180]  Да, у нас есть комментарии о вашем участии.
[02:17:36.180 --> 02:17:38.180]  Да, у нас есть комментарии о вашем участии.
[02:17:38.180 --> 02:17:40.180]  Да, у нас есть комментарии о вашем участии.
[02:17:40.180 --> 02:17:42.180]  Да, у нас есть комментарии о вашем участии.
[02:17:42.180 --> 02:17:44.180]  Да, у нас есть комментарии о вашем участии.
[02:17:44.180 --> 02:17:46.180]  Да, у нас есть комментарии о вашем участии.
[02:17:46.180 --> 02:17:48.180]  Да, у нас есть комментарии о вашем участии.
[02:17:48.180 --> 02:17:50.180]  Да, у нас есть комментарии о вашем участии.
[02:17:50.180 --> 02:17:52.180]  Да, у нас есть комментарии о вашем участии.
[02:17:54.180 --> 02:17:56.180]  Да, у нас есть комментарии о вашем участии.
[02:17:56.180 --> 02:17:58.180]  Да, у нас есть комментарии о вашем участии.
[02:17:58.180 --> 02:18:00.180]  Да, у нас есть комментарии о вашем участии.
[02:18:00.180 --> 02:18:02.180]  Да, у нас есть комментарии о вашем участии.
[02:18:02.180 --> 02:18:04.180]  Да, у нас есть комментарии о вашем участии.
[02:18:04.180 --> 02:18:06.180]  Да, у нас есть комментарии о вашем участии.
[02:18:06.180 --> 02:18:08.180]  Да, у нас есть комментарии о вашем участии.
[02:18:08.180 --> 02:18:10.180]  Да, у нас есть комментарии о вашем участии.
[02:18:10.180 --> 02:18:12.180]  Да, у нас есть комментарии о вашем участии.
[02:18:12.180 --> 02:18:14.180]  Да, у нас есть комментарии о вашем участии.
[02:18:14.180 --> 02:18:16.180]  Да, у нас есть комментарии о вашем участии.
[02:18:16.180 --> 02:18:18.180]  Да, у нас есть комментарии о вашем участии.
[02:18:18.180 --> 02:18:20.180]  Да, у нас есть комментарии о вашем участии.
[02:18:20.180 --> 02:18:22.180]  Да, у нас есть комментарии о вашем участии.
[02:18:24.180 --> 02:18:26.180]  Да, у нас есть комментарии о вашем участии.
[02:18:26.180 --> 02:18:28.180]  Да, у нас есть комментарии о вашем участии.
[02:18:28.180 --> 02:18:30.180]  Да, у нас есть комментарии о вашем участии.
[02:18:30.180 --> 02:18:32.180]  Да, у нас есть комментарии о вашем участии.
[02:18:32.180 --> 02:18:34.180]  Да, у нас есть комментарии о вашем участии.
[02:18:34.180 --> 02:18:36.180]  Да, у нас есть комментарии о вашем участии.
[02:18:36.180 --> 02:18:38.180]  Да, у нас есть комментарии о вашем участии.
[02:18:38.180 --> 02:18:40.180]  Да, у нас есть комментарии о вашем участии.
[02:18:40.180 --> 02:18:42.180]  Да, у нас есть комментарии о вашем участии.
[02:18:42.180 --> 02:18:44.180]  Да, у нас есть комментарии о вашем участии.
[02:18:44.180 --> 02:18:46.180]  Да, у нас есть комментарии о вашем участии.
[02:18:46.180 --> 02:18:48.180]  Да, у нас есть комментарии о вашем участии.
[02:18:50.180 --> 02:18:52.180]  Да, у нас есть комментарии о вашем участии.
[02:18:52.180 --> 02:18:54.180]  Да, у нас есть комментарии о вашем участии.
[02:18:54.180 --> 02:18:56.180]  Да, у нас есть комментарии о вашем участии.
[02:18:56.180 --> 02:18:58.180]  Да, у нас есть комментарии о вашем участии.
[02:18:58.180 --> 02:19:00.180]  Да, у нас есть комментарии о вашем участии.
[02:19:00.180 --> 02:19:02.180]  Да, у нас есть комментарии о вашем участии.
[02:19:02.180 --> 02:19:04.180]  Да, у нас есть комментарии о вашем участии.
[02:19:04.180 --> 02:19:06.180]  Да, у нас есть комментарии о вашем участии.
[02:19:06.180 --> 02:19:08.180]  Да, у нас есть комментарии о вашем участии.
[02:19:08.180 --> 02:19:10.180]  Да, у нас есть комментарии о вашем участии.
[02:19:10.180 --> 02:19:12.180]  Да, у нас есть комментарии о вашем участии.
[02:19:12.180 --> 02:19:14.180]  Да, у нас есть комментарии о вашем участии.
[02:19:14.180 --> 02:19:16.180]  Да, у нас есть комментарии о вашем участии.
[02:19:18.180 --> 02:19:20.180]  Да, у нас есть комментарии о вашем участии.
[02:19:20.180 --> 02:19:22.180]  Да, у нас есть комментарии о вашем участии.
[02:19:22.180 --> 02:19:24.180]  Да, у нас есть комментарии о вашем участии.
[02:19:24.180 --> 02:19:26.180]  Да, у нас есть комментарии о вашем участии.
[02:19:26.180 --> 02:19:28.180]  Да, у нас есть комментарии о вашем участии.
[02:19:28.180 --> 02:19:30.180]  Да, у нас есть комментарии о вашем участии.
[02:19:30.180 --> 02:19:32.180]  Да, у нас есть комментарии о вашем участии.
[02:19:32.180 --> 02:19:34.180]  Да, у нас есть комментарии о вашем участии.
[02:19:34.180 --> 02:19:36.180]  Да, у нас есть комментарии о вашем участии.
[02:19:36.180 --> 02:19:38.180]  Да, у нас есть комментарии о вашем участии.
[02:19:38.180 --> 02:19:40.180]  Да, у нас есть комментарии о вашем участии.
[02:19:40.180 --> 02:19:42.180]  Да, у нас есть комментарии о вашем участии.
[02:19:44.180 --> 02:19:46.180]  Да, у нас есть комментарии о вашем участии.
[02:19:46.180 --> 02:19:48.180]  Да, у нас есть комментарии о вашем участии.
[02:19:48.180 --> 02:19:50.180]  Да, у нас есть комментарии о вашем участии.
[02:19:50.180 --> 02:19:52.180]  Да, у нас есть комментарии о вашем участии.
[02:19:52.180 --> 02:19:54.180]  Да, у нас есть комментарии о вашем участии.
[02:19:54.180 --> 02:19:56.180]  Да, у нас есть комментарии о вашем участии.
[02:19:56.180 --> 02:19:58.180]  Да, у нас есть комментарии о вашем участии.
[02:19:58.180 --> 02:20:00.180]  Да, у нас есть комментарии о вашем участии.
[02:20:00.180 --> 02:20:02.180]  Да, у нас есть комментарии о вашем участии.
[02:20:02.180 --> 02:20:04.180]  Да, у нас есть комментарии о вашем участии.
[02:20:04.180 --> 02:20:06.180]  Да, у нас есть комментарии о вашем участии.
[02:20:06.180 --> 02:20:08.180]  Да, у нас есть комментарии о вашем участии.
[02:20:08.180 --> 02:20:10.180]  Да, у нас есть комментарии о вашем участии.
[02:20:10.180 --> 02:20:12.180]  Да, у нас есть комментарии о вашем участии.
[02:20:12.180 --> 02:20:14.180]  Да, у нас есть комментарии о вашем участии.
[02:20:16.180 --> 02:20:18.180]  Да, у нас есть комментарии о вашем участии.
[02:20:18.180 --> 02:20:20.180]  Да, у нас есть комментарии о вашем участии.
[02:20:20.180 --> 02:20:22.180]  Да, у нас есть комментарии о вашем участии.
[02:20:22.180 --> 02:20:24.180]  Да, у нас есть комментарии о вашем участии.
[02:20:24.180 --> 02:20:26.180]  Да, у нас есть комментарии о вашем участии.
[02:20:26.180 --> 02:20:28.180]  Да, у нас есть комментарии о вашем участии.
[02:20:28.180 --> 02:20:30.180]  Да, у нас есть комментарии о вашем участии.
[02:20:30.180 --> 02:20:32.180]  Да, у нас есть комментарии о вашем участии.
[02:20:32.180 --> 02:20:34.180]  Да, у нас есть комментарии о вашем участии.
[02:20:34.180 --> 02:20:36.180]  Да, у нас есть комментарии о вашем участии.
[02:20:36.180 --> 02:20:38.180]  Да, у нас есть комментарии о вашем участии.
[02:20:38.180 --> 02:20:40.180]  Да, у нас есть комментарии о вашем участии.
[02:20:40.180 --> 02:20:42.180]  Да, у нас есть комментарии о вашем участии.
[02:20:42.180 --> 02:20:44.180]  Да, у нас есть комментарии о вашем участии.
[02:20:44.180 --> 02:20:46.180]  Да, у нас есть комментарии о вашем участии.
[02:20:46.180 --> 02:20:48.180]  Да, у нас есть комментарии о вашем участии.
[02:20:50.180 --> 02:20:52.180]  Да, у нас есть комментарии о вашем участии.
[02:20:52.180 --> 02:20:54.180]  Да, у нас есть комментарии о вашем участии.
[02:20:54.180 --> 02:20:56.180]  Да, у нас есть комментарии о вашем участии.
[02:20:56.180 --> 02:20:58.180]  Да, у нас есть комментарии о вашем участии.
[02:20:58.180 --> 02:21:00.180]  Да, у нас есть комментарии о вашем участии.
[02:21:00.180 --> 02:21:02.180]  Да, у нас есть комментарии о вашем участии.
[02:21:02.180 --> 02:21:04.180]  Да, у нас есть комментарии о вашем участии.
[02:21:04.180 --> 02:21:06.180]  Да, у нас есть комментарии о вашем участии.
[02:21:06.180 --> 02:21:08.180]  Да, у нас есть комментарии о вашем участии.
[02:21:08.180 --> 02:21:10.180]  Да, у нас есть комментарии о вашем участии.
[02:21:12.180 --> 02:21:14.180]  Да, у нас есть комментарии о вашем участии.
[02:21:14.180 --> 02:21:16.180]  Да, у нас есть комментарии о вашем участии.
[02:21:16.180 --> 02:21:18.180]  Да, у нас есть комментарии о вашем участии.
[02:21:18.180 --> 02:21:20.180]  Да, у нас есть комментарии о вашем участии.
[02:21:20.180 --> 02:21:22.180]  Да, у нас есть комментарии о вашем участии.
[02:21:22.180 --> 02:21:24.180]  Да, у нас есть комментарии о вашем участии.
[02:21:24.180 --> 02:21:26.180]  Да, у нас есть комментарии о вашем участии.
[02:21:26.180 --> 02:21:28.180]  Да, у нас есть комментарии о вашем участии.
[02:21:28.180 --> 02:21:30.180]  Да, у нас есть комментарии о вашем участии.
[02:21:30.180 --> 02:21:32.180]  Да, у нас есть комментарии о вашем участии.
[02:21:32.180 --> 02:21:34.180]  Да, у нас есть комментарии о вашем участии.
[02:21:34.180 --> 02:21:36.180]  Да, у нас есть комментарии о вашем участии.
[02:21:38.180 --> 02:21:40.180]  Да, у нас есть комментарии о вашем участии.
[02:21:40.180 --> 02:21:42.180]  Да, у нас есть комментарии о вашем участии.
[02:21:42.180 --> 02:21:44.180]  Да, у нас есть комментарии о вашем участии.
[02:21:44.180 --> 02:21:46.180]  Да, у нас есть комментарии о вашем участии.
[02:21:46.180 --> 02:21:48.180]  Да, у нас есть комментарии о вашем участии.
[02:21:48.180 --> 02:21:50.180]  Да, у нас есть комментарии о вашем участии.
[02:21:50.180 --> 02:21:52.180]  Да, у нас есть комментарии о вашем участии.
[02:21:52.180 --> 02:21:54.180]  Да, у нас есть комментарии о вашем участии.
[02:21:54.180 --> 02:21:56.180]  Да, у нас есть комментарии о вашем участии.
[02:21:56.180 --> 02:21:58.180]  Да, у нас есть комментарии о вашем участии.
[02:22:00.180 --> 02:22:02.180]  Да, у нас есть комментарии о вашем участии.
[02:22:02.180 --> 02:22:04.180]  Да, у нас есть комментарии о вашем участии.
[02:22:04.180 --> 02:22:06.180]  Да, у нас есть комментарии о вашем участии.
[02:22:06.180 --> 02:22:08.180]  Да, у нас есть комментарии о вашем участии.
[02:22:08.180 --> 02:22:10.180]  Да, у нас есть комментарии о вашем участии.
[02:22:10.180 --> 02:22:12.180]  Да, у нас есть комментарии о вашем участии.
[02:22:12.180 --> 02:22:14.180]  Да, у нас есть комментарии о вашем участии.
[02:22:14.180 --> 02:22:16.180]  Да, у нас есть комментарии о вашем участии.
[02:22:16.180 --> 02:22:18.180]  Да, у нас есть комментарии о вашем участии.
[02:22:18.180 --> 02:22:20.180]  Да, у нас есть комментарии о вашем участии.
[02:22:20.180 --> 02:22:22.180]  Да, у нас есть комментарии о вашем участии.
[02:22:22.180 --> 02:22:24.180]  Да, у нас есть комментарии о вашем участии.
[02:22:24.180 --> 02:22:26.180]  Да, у нас есть комментарии о вашем участии.
[02:22:26.180 --> 02:22:28.180]  Да, у нас есть комментарии о вашем участии.
[02:22:28.180 --> 02:22:30.180]  Да, у нас есть комментарии о вашем участии.
[02:22:32.180 --> 02:22:34.180]  Да, у нас есть комментарии о вашем участии.
[02:22:34.180 --> 02:22:36.180]  Да, у нас есть комментарии о вашем участии.
[02:22:36.180 --> 02:22:38.180]  Да, у нас есть комментарии о вашем участии.
[02:22:38.180 --> 02:22:40.180]  Да, у нас есть комментарии о вашем участии.
[02:22:40.180 --> 02:22:42.180]  Да, у нас есть комментарии о вашем участии.
[02:22:42.180 --> 02:22:44.180]  Да, у нас есть комментарии о вашем участии.
[02:22:44.180 --> 02:22:46.180]  Да, у нас есть комментарии о вашем участии.
[02:22:46.180 --> 02:22:48.180]  Да, у нас есть комментарии о вашем участии.
[02:22:48.180 --> 02:22:50.180]  Да, у нас есть комментарии о вашем участии.
[02:22:50.180 --> 02:22:52.180]  Да, у нас есть комментарии о вашем участии.
[02:22:52.180 --> 02:22:54.180]  Да, у нас есть комментарии о вашем участии.
[02:22:56.180 --> 02:22:58.180]  Да, у нас есть комментарии о вашем участии.
[02:22:58.180 --> 02:23:00.180]  Да, у нас есть комментарии о вашем участии.
[02:23:00.180 --> 02:23:02.180]  Да, у нас есть комментарии о вашем участии.
[02:23:02.180 --> 02:23:04.180]  Да, у нас есть комментарии о вашем участии.
[02:23:04.180 --> 02:23:06.180]  Да, у нас есть комментарии о вашем участии.
[02:23:06.180 --> 02:23:08.180]  Да, у нас есть комментарии о вашем участии.
[02:23:08.180 --> 02:23:10.180]  Да, у нас есть комментарии о вашем участии.
[02:23:10.180 --> 02:23:12.180]  Да, у нас есть комментарии о вашем участии.
[02:23:12.180 --> 02:23:14.180]  Да, у нас есть комментарии о вашем участии.
[02:23:14.180 --> 02:23:16.180]  Да, у нас есть комментарии о вашем участии.
[02:23:16.180 --> 02:23:18.180]  Да, у нас есть комментарии о вашем участии.
[02:23:18.180 --> 02:23:20.180]  Да, у нас есть комментарии о вашем участии.
[02:23:20.180 --> 02:23:22.180]  Да, у нас есть комментарии о вашем участии.
[02:23:22.180 --> 02:23:24.180]  Да, у нас есть комментарии о вашем участии.
[02:23:24.180 --> 02:23:26.180]  Да, у нас есть комментарии о вашем участии.
[02:23:26.180 --> 02:23:28.180]  Да, у нас есть комментарии о вашем участии.
[02:23:30.180 --> 02:23:32.180]  Да, у нас есть комментарии о вашем участии.
[02:23:32.180 --> 02:23:34.180]  Да, у нас есть комментарии о вашем участии.
[02:23:34.180 --> 02:23:36.180]  Да, у нас есть комментарии о вашем участии.
[02:23:36.180 --> 02:23:38.180]  Да, у нас есть комментарии о вашем участии.
[02:23:38.180 --> 02:23:40.180]  Да, у нас есть комментарии о вашем участии.
[02:23:40.180 --> 02:23:42.180]  Да, у нас есть комментарии о вашем участии.
[02:23:42.180 --> 02:23:44.180]  Да, у нас есть комментарии о вашем участии.
[02:23:44.180 --> 02:23:46.180]  Да, у нас есть комментарии о вашем участии.
[02:23:46.180 --> 02:23:48.180]  Да, у нас есть комментарии о вашем участии.
[02:23:50.180 --> 02:23:52.180]  Да, у нас есть комментарии о вашем участии.
[02:23:52.180 --> 02:23:54.180]  Да, у нас есть комментарии о вашем участии.
[02:23:54.180 --> 02:23:56.180]  Да, у нас есть комментарии о вашем участии.
[02:23:56.180 --> 02:23:58.180]  Да, у нас есть комментарии о вашем участии.
[02:23:58.180 --> 02:24:00.180]  Да, у нас есть комментарии о вашем участии.
[02:24:00.180 --> 02:24:02.180]  Да, у нас есть комментарии о вашем участии.
[02:24:02.180 --> 02:24:04.180]  Да, у нас есть комментарии о вашем участии.
[02:24:04.180 --> 02:24:06.180]  Да, у нас есть комментарии о вашем участии.
[02:24:06.180 --> 02:24:08.180]  Да, у нас есть комментарии о вашем участии.
[02:24:08.180 --> 02:24:10.180]  Да, у нас есть комментарии о вашем участии.
[02:24:10.180 --> 02:24:12.180]  Да, у нас есть комментарии о вашем участии.
[02:24:12.180 --> 02:24:14.180]  Да, у нас есть комментарии о вашем участии.
[02:24:14.180 --> 02:24:16.180]  Да, у нас есть комментарии о вашем участии.
[02:24:18.180 --> 02:24:20.180]  Да, у нас есть комментарии о вашем участии.
[02:24:20.180 --> 02:24:22.180]  Да, у нас есть комментарии о вашем участии.
[02:24:22.180 --> 02:24:24.180]  Да, у нас есть комментарии о вашем участии.
[02:24:24.180 --> 02:24:26.180]  Да, у нас есть комментарии о вашем участии.
[02:24:26.180 --> 02:24:28.180]  Да, у нас есть комментарии о вашем участии.
[02:24:28.180 --> 02:24:30.180]  Да, у нас есть комментарии о вашем участии.
[02:24:30.180 --> 02:24:32.180]  Да, у нас есть комментарии о вашем участии.
[02:24:32.180 --> 02:24:34.180]  Да, у нас есть комментарии о вашем участии.
[02:24:34.180 --> 02:24:36.180]  Да, у нас есть комментарии о вашем участии.
[02:24:36.180 --> 02:24:38.180]  Да, у нас есть комментарии о вашем участии.
[02:24:38.180 --> 02:24:40.180]  Да, у нас есть комментарии о вашем участии.
[02:24:40.180 --> 02:24:42.180]  Да, у нас есть комментарии о вашем участии.
[02:24:42.180 --> 02:24:44.180]  Да, у нас есть комментарии о вашем участии.
[02:24:44.180 --> 02:24:46.180]  Да, у нас есть комментарии о вашем участии.
[02:24:46.180 --> 02:24:48.180]  Да, у нас есть комментарии о вашем участии.
[02:24:48.180 --> 02:24:50.180]  Да, у нас есть комментарии о вашем участии.
[02:24:50.180 --> 02:24:52.180]  Да, у нас есть комментарии о вашем участии.
[02:24:54.180 --> 02:24:56.180]  Да, у нас есть комментарии о вашем участии.
[02:24:56.180 --> 02:24:58.180]  Да, у нас есть комментарии о вашем участии.
[02:24:58.180 --> 02:25:00.180]  Да, у нас есть комментарии о вашем участии.
[02:25:00.180 --> 02:25:02.180]  Да, у нас есть комментарии о вашем участии.
[02:25:02.180 --> 02:25:04.180]  Да, у нас есть комментарии о вашем участии.
[02:25:04.180 --> 02:25:06.180]  Да, у нас есть комментарии о вашем участии.
[02:25:06.180 --> 02:25:08.180]  Да, у нас есть комментарии о вашем участии.
[02:25:08.180 --> 02:25:10.180]  Да, у нас есть комментарии о вашем участии.
[02:25:10.180 --> 02:25:12.180]  Да, у нас есть комментарии о вашем участии.
[02:25:14.180 --> 02:25:16.180]  Да, у нас есть комментарии о вашем участии.
[02:25:16.180 --> 02:25:18.180]  Да, у нас есть комментарии о вашем участии.
[02:25:18.180 --> 02:25:20.180]  Да, у нас есть комментарии о вашем участии.
[02:25:20.180 --> 02:25:22.180]  Да, у нас есть комментарии о вашем участии.
[02:25:22.180 --> 02:25:24.180]  Да, у нас есть комментарии о вашем участии.
[02:25:24.180 --> 02:25:26.180]  Да, у нас есть комментарии о вашем участии.
[02:25:26.180 --> 02:25:28.180]  Да, у нас есть комментарии о вашем участии.
[02:25:28.180 --> 02:25:30.180]  Да, у нас есть комментарии о вашем участии.
[02:25:30.180 --> 02:25:32.180]  Да, у нас есть комментарии о вашем участии.
[02:25:32.180 --> 02:25:34.180]  Да, у нас есть комментарии о вашем участии.
[02:25:34.180 --> 02:25:36.180]  Да, у нас есть комментарии о вашем участии.
[02:25:36.180 --> 02:25:38.180]  Да, у нас есть комментарии о вашем участии.
[02:25:38.180 --> 02:25:40.180]  Да, у нас есть комментарии о вашем участии.
[02:25:40.180 --> 02:25:42.180]  Да, у нас есть комментарии о вашем участии.
[02:25:42.180 --> 02:25:44.180]  Да, у нас есть комментарии о вашем участии.
[02:25:44.180 --> 02:25:46.180]  Да, у нас есть комментарии о вашем участии.
[02:25:46.180 --> 02:25:48.180]  Да, у нас есть комментарии о вашем участии.
[02:25:50.180 --> 02:25:52.180]  Да, у нас есть комментарии о вашем участии.
[02:25:52.180 --> 02:25:54.180]  Да, у нас есть комментарии о вашем участии.
[02:25:54.180 --> 02:25:56.180]  Да, у нас есть комментарии о вашем участии.
[02:25:56.180 --> 02:25:58.180]  Да, у нас есть комментарии о вашем участии.
[02:25:58.180 --> 02:26:00.180]  Да, у нас есть комментарии о вашем участии.
[02:26:00.180 --> 02:26:02.180]  Да, у нас есть комментарии о вашем участии.
[02:26:02.180 --> 02:26:04.180]  Да, у нас есть комментарии о вашем участии.
[02:26:04.180 --> 02:26:06.180]  Да, у нас есть комментарии о вашем участии.
[02:26:06.180 --> 02:26:08.180]  Да, у нас есть комментарии о вашем участии.
[02:26:10.180 --> 02:26:12.180]  Да, у нас есть комментарии о вашем участии.
[02:26:12.180 --> 02:26:14.180]  Да, у нас есть комментарии о вашем участии.
[02:26:14.180 --> 02:26:16.180]  Да, у нас есть комментарии о вашем участии.
[02:26:16.180 --> 02:26:18.180]  Да, у нас есть комментарии о вашем участии.
[02:26:18.180 --> 02:26:20.180]  Да, у нас есть комментарии о вашем участии.
[02:26:20.180 --> 02:26:22.180]  Да, у нас есть комментарии о вашем участии.
[02:26:22.180 --> 02:26:24.180]  Да, у нас есть комментарии о вашем участии.
[02:26:24.180 --> 02:26:26.180]  Да, у нас есть комментарии о вашем участии.
[02:26:26.180 --> 02:26:28.180]  Да, у нас есть комментарии о вашем участии.
[02:26:28.180 --> 02:26:30.180]  Да, у нас есть комментарии о вашем участии.
[02:26:30.180 --> 02:26:32.180]  Да, у нас есть комментарии о вашем участии.
[02:26:32.180 --> 02:26:34.180]  Да, у нас есть комментарии о вашем участии.
[02:26:34.180 --> 02:26:36.180]  Да, у нас есть комментарии о вашем участии.
[02:26:38.180 --> 02:26:40.180]  Да, у нас есть комментарии о вашем участии.
[02:26:40.180 --> 02:26:42.180]  Да, у нас есть комментарии о вашем участии.
[02:26:42.180 --> 02:26:44.180]  Да, у нас есть комментарии о вашем участии.
[02:26:44.180 --> 02:26:46.180]  Да, у нас есть комментарии о вашем участии.
[02:26:46.180 --> 02:26:48.180]  Да, у нас есть комментарии о вашем участии.
[02:26:48.180 --> 02:26:50.180]  Да, у нас есть комментарии о вашем участии.
[02:26:50.180 --> 02:26:52.180]  Да, у нас есть комментарии о вашем участии.
[02:26:52.180 --> 02:26:54.180]  Да, у нас есть комментарии о вашем участии.
[02:26:54.180 --> 02:26:56.180]  Да, у нас есть комментарии о вашем участии.
[02:26:56.180 --> 02:26:58.180]  Да, у нас есть комментарии о вашем участии.
[02:26:58.180 --> 02:27:00.180]  Да, у нас есть комментарии о вашем участии.
[02:27:00.180 --> 02:27:02.180]  Да, у нас есть комментарии о вашем участии.
[02:27:02.180 --> 02:27:04.180]  Да, у нас есть комментарии о вашем участии.
[02:27:06.180 --> 02:27:08.180]  Да, у нас есть комментарии о вашем участии.
[02:27:08.180 --> 02:27:10.180]  Да, у нас есть комментарии о вашем участии.
[02:27:10.180 --> 02:27:12.180]  Да, у нас есть комментарии о вашем участии.
[02:27:12.180 --> 02:27:14.180]  Да, у нас есть комментарии о вашем участии.
[02:27:14.180 --> 02:27:16.180]  Да, у нас есть комментарии о вашем участии.
[02:27:16.180 --> 02:27:18.180]  Да, у нас есть комментарии о вашем участии.
[02:27:18.180 --> 02:27:20.180]  Да, у нас есть комментарии о вашем участии.
[02:27:20.180 --> 02:27:22.180]  Да, у нас есть комментарии о вашем участии.
[02:27:22.180 --> 02:27:24.180]  Да, у нас есть комментарии о вашем участии.
[02:27:24.180 --> 02:27:26.180]  Да, у нас есть комментарии о вашем участии.
[02:27:26.180 --> 02:27:28.180]  Да, у нас есть комментарии о вашем участии.
[02:27:28.180 --> 02:27:30.180]  Да, у нас есть комментарии о вашем участии.
[02:27:30.180 --> 02:27:32.180]  Да, у нас есть комментарии о вашем участии.
[02:27:32.180 --> 02:27:34.180]  Да, у нас есть комментарии о вашем участии.
[02:27:34.180 --> 02:27:36.180]  Да, у нас есть комментарии о вашем участии.
[02:27:36.180 --> 02:27:38.180]  Да, у нас есть комментарии о вашем участии.
[02:27:38.180 --> 02:27:40.180]  Да, у нас есть комментарии о вашем участии.
[02:27:42.180 --> 02:27:44.180]  Да, у нас есть комментарии о вашем участии.
[02:27:44.180 --> 02:27:46.180]  Да, у нас есть комментарии о вашем участии.
[02:27:46.180 --> 02:27:48.180]  Да, у нас есть комментарии о вашем участии.
[02:27:48.180 --> 02:27:50.180]  Да, у нас есть комментарии о вашем участии.
[02:27:50.180 --> 02:27:52.180]  Да, у нас есть комментарии о вашем участии.
[02:27:52.180 --> 02:27:54.180]  Да, у нас есть комментарии о вашем участии.
[02:27:54.180 --> 02:27:56.180]  Да, у нас есть комментарии о вашем участии.
[02:27:56.180 --> 02:27:58.180]  Да, у нас есть комментарии о вашем участии.
[02:27:58.180 --> 02:28:00.180]  Да, у нас есть комментарии о вашем участии.
[02:28:02.180 --> 02:28:04.180]  Да, у нас есть комментарии о вашем участии.
[02:28:04.180 --> 02:28:06.180]  Да, у нас есть комментарии о вашем участии.
[02:28:06.180 --> 02:28:08.180]  Да, у нас есть комментарии о вашем участии.
[02:28:08.180 --> 02:28:10.180]  Да, у нас есть комментарии о вашем участии.
[02:28:10.180 --> 02:28:12.180]  Да, у нас есть комментарии о вашем участии.
[02:28:12.180 --> 02:28:14.180]  Да, у нас есть комментарии о вашем участии.
[02:28:14.180 --> 02:28:16.180]  Да, у нас есть комментарии о вашем участии.
[02:28:16.180 --> 02:28:18.180]  Да, у нас есть комментарии о вашем участии.
[02:28:18.180 --> 02:28:20.180]  Да, у нас есть комментарии о вашем участии.
[02:28:20.180 --> 02:28:22.180]  Да, у нас есть комментарии о вашем участии.
[02:28:22.180 --> 02:28:24.180]  Да, у нас есть комментарии о вашем участии.
[02:28:24.180 --> 02:28:26.180]  Да, у нас есть комментарии о вашем участии.
[02:28:26.180 --> 02:28:28.180]  Да, у нас есть комментарии о вашем участии.
[02:28:30.180 --> 02:28:32.180]  Да, у нас есть комментарии о вашем участии.
[02:28:32.180 --> 02:28:34.180]  Да, у нас есть комментарии о вашем участии.
[02:28:34.180 --> 02:28:36.180]  Да, у нас есть комментарии о вашем участии.
[02:28:36.180 --> 02:28:38.180]  Да, у нас есть комментарии о вашем участии.
[02:28:38.180 --> 02:28:40.180]  Да, у нас есть комментарии о вашем участии.
[02:28:40.180 --> 02:28:42.180]  Да, у нас есть комментарии о вашем участии.
[02:28:42.180 --> 02:28:44.180]  Да, у нас есть комментарии о вашем участии.
[02:28:44.180 --> 02:28:46.180]  Да, у нас есть комментарии о вашем участии.
[02:28:46.180 --> 02:28:48.180]  Да, у нас есть комментарии о вашем участии.
[02:28:48.180 --> 02:28:50.180]  Да, у нас есть комментарии о вашем участии.
[02:28:50.180 --> 02:28:52.180]  Да, у нас есть комментарии о вашем участии.
[02:28:52.180 --> 02:28:54.180]  Да, у нас есть комментарии о вашем участии.
[02:28:54.180 --> 02:28:56.180]  Да, у нас есть комментарии о вашем участии.
[02:28:56.180 --> 02:28:58.180]  Да, у нас есть комментарии о вашем участии.
[02:28:58.180 --> 02:29:00.180]  Да, у нас есть комментарии о вашем участии.
[02:29:00.180 --> 02:29:02.180]  Да, у нас есть комментарии о вашем участии.
[02:29:02.180 --> 02:29:04.180]  Да, у нас есть комментарии о вашем участии.
[02:29:04.180 --> 02:29:06.180]  Да, у нас есть комментарии о вашем участии.
[02:29:06.180 --> 02:29:08.180]  Да, у нас есть комментарии о вашем участии.
[02:29:08.180 --> 02:29:10.180]  Да, у нас есть комментарии о вашем участии.
[02:29:10.180 --> 02:29:12.180]  Да, у нас есть комментарии о вашем участии.
[02:29:12.180 --> 02:29:14.180]  Да, у нас есть комментарии о вашем участии.
[02:29:14.180 --> 02:29:16.180]  Да, у нас есть комментарии о вашем участии.
[02:29:16.180 --> 02:29:18.180]  Да, у нас есть комментарии о вашем участии.
[02:29:18.180 --> 02:29:20.180]  Да, у нас есть комментарии о вашем участии.
[02:29:20.180 --> 02:29:22.180]  Да, у нас есть комментарии о вашем участии.
[02:29:22.180 --> 02:29:24.180]  Да, у нас есть комментарии о вашем участии.
[02:29:24.180 --> 02:29:26.180]  Да, у нас есть комментарии о вашем участии.
[02:29:26.180 --> 02:29:28.180]  Да, у нас есть комментарии о вашем участии.
[02:29:28.180 --> 02:29:30.180]  Да, у нас есть комментарии о вашем участии.
[02:29:32.180 --> 02:29:34.180]  Да, у нас есть комментарии о вашем участии.
[02:29:34.180 --> 02:29:36.180]  Да, у нас есть комментарии о вашем участии.
[02:29:36.180 --> 02:29:38.180]  Да, у нас есть комментарии о вашем участии.
[02:29:38.180 --> 02:29:40.180]  Да, у нас есть комментарии о вашем участии.
[02:29:40.180 --> 02:29:42.180]  Да, у нас есть комментарии о вашем участии.
[02:29:42.180 --> 02:29:44.180]  Да, у нас есть комментарии о вашем участии.
[02:29:44.180 --> 02:29:46.180]  Да, у нас есть комментарии о вашем участии.
[02:29:46.180 --> 02:29:48.180]  Да, у нас есть комментарии о вашем участии.
[02:29:48.180 --> 02:29:50.180]  Да, у нас есть комментарии о вашем участии.
[02:29:52.180 --> 02:29:54.180]  Да, у нас есть комментарии о вашем участии.
[02:29:54.180 --> 02:29:56.180]  Да, у нас есть комментарии о вашем участии.
[02:29:56.180 --> 02:29:58.180]  Да, у нас есть комментарии о вашем участии.
[02:29:58.180 --> 02:30:00.180]  Да, у нас есть комментарии о вашем участии.
[02:30:00.180 --> 02:30:02.180]  Да, у нас есть комментарии о вашем участии.
[02:30:02.180 --> 02:30:04.180]  Да, у нас есть комментарии о вашем участии.
[02:30:04.180 --> 02:30:06.180]  Да, у нас есть комментарии о вашем участии.
[02:30:06.180 --> 02:30:08.180]  Да, у нас есть комментарии о вашем участии.
[02:30:08.180 --> 02:30:10.180]  Да, у нас есть комментарии о вашем участии.
[02:30:10.180 --> 02:30:12.180]  Да, у нас есть комментарии о вашем участии.
[02:30:12.180 --> 02:30:14.180]  Да, у нас есть комментарии о вашем участии.
[02:30:14.180 --> 02:30:16.180]  Да, у нас есть комментарии о вашем участии.
[02:30:16.180 --> 02:30:18.180]  Да, у нас есть комментарии о вашем участии.
[02:30:20.180 --> 02:30:22.180]  Да, у нас есть комментарии о вашем участии.
[02:30:22.180 --> 02:30:24.180]  Да, у нас есть комментарии о вашем участии.
[02:30:24.180 --> 02:30:26.180]  Да, у нас есть комментарии о вашем участии.
[02:30:26.180 --> 02:30:28.180]  Да, у нас есть комментарии о вашем участии.
[02:30:28.180 --> 02:30:30.180]  Да, у нас есть комментарии о вашем участии.
[02:30:30.180 --> 02:30:32.180]  Да, у нас есть комментарии о вашем участии.
[02:30:32.180 --> 02:30:34.180]  Да, у нас есть комментарии о вашем участии.
[02:30:34.180 --> 02:30:36.180]  Да, у нас есть комментарии о вашем участии.
[02:30:36.180 --> 02:30:38.180]  Да, у нас есть комментарии о вашем участии.
[02:30:38.180 --> 02:30:40.180]  Да, у нас есть комментарии о вашем участии.
[02:30:40.180 --> 02:30:42.180]  Да, у нас есть комментарии о вашем участии.
[02:30:42.180 --> 02:30:44.180]  Да, у нас есть комментарии о вашем участии.
[02:30:44.180 --> 02:30:46.180]  Да, у нас есть комментарии о вашем участии.
[02:30:46.180 --> 02:30:48.180]  Да, у нас есть комментарии о вашем участии.
[02:30:48.180 --> 02:30:50.180]  Да, у нас есть комментарии о вашем участии.
[02:30:50.180 --> 02:30:52.180]  Да, у нас есть комментарии о вашем участии.
[02:30:52.180 --> 02:30:54.180]  Да, у нас есть комментарии о вашем участии.
[02:30:54.180 --> 02:30:56.180]  Да, у нас есть комментарии о вашем участии.
[02:30:56.180 --> 02:30:58.180]  Да, у нас есть комментарии о вашем участии.
[02:30:58.180 --> 02:31:00.180]  Да, у нас есть комментарии о вашем участии.
[02:31:00.180 --> 02:31:02.180]  Да, у нас есть комментарии о вашем участии.
[02:31:02.180 --> 02:31:04.180]  Да, у нас есть комментарии о вашем участии.
[02:31:04.180 --> 02:31:06.180]  Да, у нас есть комментарии о вашем участии.
[02:31:06.180 --> 02:31:08.180]  Да, у нас есть комментарии о вашем участии.
[02:31:08.180 --> 02:31:10.180]  Да, у нас есть комментарии о вашем участии.
[02:31:10.180 --> 02:31:12.180]  Да, у нас есть комментарии о вашем участии.
[02:31:12.180 --> 02:31:14.180]  Да, у нас есть комментарии о вашем участии.
[02:31:14.180 --> 02:31:16.180]  Да, у нас есть комментарии о вашем участии.
[02:31:16.180 --> 02:31:18.180]  Да, у нас есть комментарии о вашем участии.
[02:31:18.180 --> 02:31:20.180]  Да, у нас есть комментарии о вашем участии.
[02:31:20.180 --> 02:31:22.180]  Да, у нас есть комментарии о вашем участии.
[02:31:22.180 --> 02:31:24.180]  Да, у нас есть комментарии о вашем участии.
[02:31:24.180 --> 02:31:26.180]  Да, у нас есть комментарии о вашем участии.
[02:31:26.180 --> 02:31:28.180]  Да, у нас есть комментарии о вашем участии.
[02:31:28.180 --> 02:31:30.180]  Да, у нас есть комментарии о вашем участии.
[02:31:30.180 --> 02:31:32.180]  Да, у нас есть комментарии о вашем участии.
[02:31:32.180 --> 02:31:34.180]  Да, у нас есть комментарии о вашем участии.
[02:31:34.180 --> 02:31:36.180]  Да, у нас есть комментарии о вашем участии.
[02:31:36.180 --> 02:31:38.180]  Да, у нас есть комментарии о вашем участии.
[02:31:38.180 --> 02:31:40.180]  Да, у нас есть комментарии о вашем участии.
[02:31:40.180 --> 02:31:42.180]  Да, у нас есть комментарии о вашем участии.
[02:31:42.180 --> 02:31:44.180]  Да, у нас есть комментарии о вашем участии.
[02:31:44.180 --> 02:31:46.180]  Да, у нас есть комментарии о вашем участии.
[02:31:46.180 --> 02:31:48.180]  Да, у нас есть комментарии о вашем участии.
[02:31:48.180 --> 02:31:50.180]  Да, у нас есть комментарии о вашем участии.
[02:31:50.180 --> 02:31:52.180]  Да, у нас есть комментарии о вашем участии.
[02:31:52.180 --> 02:31:54.180]  Да, у нас есть комментарии о вашем участии.
[02:31:54.180 --> 02:31:56.180]  Да, у нас есть комментарии о вашем участии.
[02:31:56.180 --> 02:31:58.180]  Да, у нас есть комментарии о вашем участии.
[02:31:58.180 --> 02:32:00.180]  Да, у нас есть комментарии о вашем участии.
[02:32:00.180 --> 02:32:02.180]  Да, у нас есть комментарии о вашем участии.
[02:32:02.180 --> 02:32:04.180]  Да, у нас есть комментарии о вашем участии.
[02:32:04.180 --> 02:32:06.180]  Да, у нас есть комментарии о вашем участии.
[02:32:06.180 --> 02:32:08.180]  Да, у нас есть комментарии о вашем участии.
[02:32:08.180 --> 02:32:10.180]  Да, у нас есть комментарии о вашем участии.
[02:32:10.180 --> 02:32:12.180]  Да, у нас есть комментарии о вашем участии.
[02:32:14.180 --> 02:32:16.180]  Да, у нас есть комментарии о вашем участии.
[02:32:16.180 --> 02:32:18.180]  Да, у нас есть комментарии о вашем участии.
[02:32:18.180 --> 02:32:20.180]  Да, у нас есть комментарии о вашем участии.
[02:32:20.180 --> 02:32:22.180]  Да, у нас есть комментарии о вашем участии.
[02:32:22.180 --> 02:32:24.180]  Да, у нас есть комментарии о вашем участии.
[02:32:24.180 --> 02:32:26.180]  Да, у нас есть комментарии о вашем участии.
[02:32:26.180 --> 02:32:28.180]  Да, у нас есть комментарии о вашем участии.
[02:32:28.180 --> 02:32:30.180]  Да, у нас есть комментарии о вашем участии.
[02:32:30.180 --> 02:32:32.180]  Да, у нас есть комментарии о вашем участии.
[02:32:34.180 --> 02:32:36.180]  Да, у нас есть комментарии о вашем участии.
[02:32:36.180 --> 02:32:38.180]  Да, у нас есть комментарии о вашем участии.
[02:32:38.180 --> 02:32:40.180]  Да, у нас есть комментарии о вашем участии.
[02:32:40.180 --> 02:32:42.180]  Да, у нас есть комментарии о вашем участии.
[02:32:42.180 --> 02:32:44.180]  Да, у нас есть комментарии о вашем участии.
[02:32:44.180 --> 02:32:46.180]  Да, у нас есть комментарии о вашем участии.
[02:32:46.180 --> 02:32:48.180]  Да, у нас есть комментарии о вашем участии.
[02:32:48.180 --> 02:32:50.180]  Да, у нас есть комментарии о вашем участии.
[02:32:50.180 --> 02:32:52.180]  Да, у нас есть комментарии о вашем участии.
[02:32:52.180 --> 02:32:54.180]  Да, у нас есть комментарии о вашем участии.
[02:32:54.180 --> 02:32:56.180]  Да, у нас есть комментарии о вашем участии.
[02:32:56.180 --> 02:32:58.180]  Да, у нас есть комментарии о вашем участии.
[02:32:58.180 --> 02:33:00.180]  Да, у нас есть комментарии о вашем участии.
[02:33:02.180 --> 02:33:04.180]  Да, у нас есть комментарии о вашем участии.
[02:33:04.180 --> 02:33:06.180]  Да, у нас есть комментарии о вашем участии.
[02:33:06.180 --> 02:33:08.180]  Да, у нас есть комментарии о вашем участии.
[02:33:08.180 --> 02:33:10.180]  Да, у нас есть комментарии о вашем участии.
[02:33:10.180 --> 02:33:12.180]  Да, у нас есть комментарии о вашем участии.
[02:33:12.180 --> 02:33:14.180]  Да, у нас есть комментарии о вашем участии.
[02:33:14.180 --> 02:33:16.180]  Да, у нас есть комментарии о вашем участии.
[02:33:16.180 --> 02:33:18.180]  Да, у нас есть комментарии о вашем участии.
[02:33:18.180 --> 02:33:20.180]  Да, у нас есть комментарии о вашем участии.
[02:33:20.180 --> 02:33:22.180]  Да, у нас есть комментарии о вашем участии.
[02:33:22.180 --> 02:33:24.180]  Да, у нас есть комментарии о вашем участии.
[02:33:24.180 --> 02:33:26.180]  Да, у нас есть комментарии о вашем участии.
[02:33:26.180 --> 02:33:28.180]  Так что, надеюсь, это было достаточно понятно.
[02:33:28.180 --> 02:33:30.180]  Спасибо.
[02:33:30.180 --> 02:33:33.180]  Корректор В. Кулакова
[02:34:00.180 --> 02:34:06.180]  Но, конечно, в текстах, в артикуле, есть много, много...
[02:34:06.180 --> 02:34:11.180]  Не много, но есть несколько линей,
[02:34:11.180 --> 02:34:15.180]  несколько ссылок к другим, конечно, к другим опубликованиям,
[02:34:15.180 --> 02:34:17.180]  к этому полку.
[02:34:17.180 --> 02:34:20.180]  Что я могу сказать о этом полку?
[02:34:20.180 --> 02:34:22.180]  О том, что это, на самом деле, эта презентация.
[02:34:22.180 --> 02:34:24.180]  Просто один момент.
[02:34:26.180 --> 02:34:28.180]  Это состоит из двух частей.
[02:34:28.180 --> 02:34:33.180]  Двое партий обвиняют только в инфекционном проблеме.
[02:34:33.180 --> 02:34:38.180]  Обвиняют только в декомпозиции.
[02:34:38.180 --> 02:34:42.180]  И эта идея, очень старая идея для меня,
[02:34:42.180 --> 02:34:44.180]  около 20 лет,
[02:34:44.180 --> 02:34:46.180]  как я suggested firstly.
[02:34:46.180 --> 02:34:49.180]  Я могу сказать, что я подумал об этом.
[02:34:49.180 --> 02:34:52.180]  И это может быть...
[02:34:52.180 --> 02:34:54.180]  Это имеет несколько веществ.
[02:34:54.180 --> 02:34:56.180]  Например, в политических телах,
[02:34:56.180 --> 02:34:58.180]  в образовом процессе,
[02:34:58.180 --> 02:35:00.180]  и в...
[02:35:01.180 --> 02:35:03.180]  в рынке.
[02:35:03.180 --> 02:35:06.180]  Просто эта презентация связана
[02:35:06.180 --> 02:35:09.180]  только с опубликованием в рынке.
[02:35:09.180 --> 02:35:12.180]  Но, во-первых, я бы хотел показать
[02:35:12.180 --> 02:35:14.180]  идею декомпозиции,
[02:35:14.180 --> 02:35:17.180]  которая достаточно простая, но, конечно, достаточно сильная.
[02:35:17.180 --> 02:35:20.180]  Я хочу сказать о себе.
[02:35:22.180 --> 02:35:23.180]  Что означает декомпозиция?
[02:35:23.180 --> 02:35:25.180]  Это понятно, что...
[02:35:25.180 --> 02:35:27.180]  Если у вас есть граф,
[02:35:27.180 --> 02:35:29.180]  я бы хотел...
[02:35:30.180 --> 02:35:31.180]  чтобы создать...
[02:35:31.180 --> 02:35:34.180]  чтобы найти какой-то сет...
[02:35:34.180 --> 02:35:36.180]  сет его вертикал.
[02:35:36.180 --> 02:35:38.180]  Так, что в...
[02:35:39.180 --> 02:35:42.180]  в relatively few connections between these parts,
[02:35:42.180 --> 02:35:44.180]  and relatively...
[02:35:44.180 --> 02:35:46.180]  relatively many connections inside.
[02:35:46.180 --> 02:35:49.180]  It's clear, it's not a formal definition, of course,
[02:35:49.180 --> 02:35:51.180]  but it's clear what's the problem.
[02:35:51.180 --> 02:35:53.180]  So...
[02:35:53.180 --> 02:35:55.180]  So, however...
[02:35:55.180 --> 02:35:57.180]  Just a moment, I can see oil.
[02:35:57.180 --> 02:36:00.180]  It's very easy for me.
[02:36:01.180 --> 02:36:03.180]  You will see the same.
[02:36:07.180 --> 02:36:09.180]  One moment.
[02:36:15.180 --> 02:36:17.180]  So, it's clear.
[02:36:17.180 --> 02:36:19.180]  So, what is the part of this present...
[02:36:19.180 --> 02:36:20.180]  of this part?
[02:36:20.180 --> 02:36:22.180]  Notion definition, algorithm itself,
[02:36:22.180 --> 02:36:24.180]  and numerical characteristics.
[02:36:24.180 --> 02:36:25.180]  Perhaps...
[02:36:25.180 --> 02:36:27.180]  Also, perhaps very...
[02:36:27.180 --> 02:36:29.180]  sometimes useful.
[02:36:30.180 --> 02:36:31.180]  What's partition?
[02:36:31.180 --> 02:36:33.180]  First of all, from the advice,
[02:36:33.180 --> 02:36:35.180]  I can say, advice of Mirkin,
[02:36:35.180 --> 02:36:36.180]  give exact...
[02:36:36.180 --> 02:36:39.180]  No, not exact, but give definition
[02:36:39.180 --> 02:36:41.180]  of all the main notions.
[02:36:41.180 --> 02:36:44.180]  So, partition is clear what's partition.
[02:36:44.180 --> 02:36:47.180]  Graph decomposition is family of subgraphs,
[02:36:47.180 --> 02:36:48.180]  and so on.
[02:36:48.180 --> 02:36:49.180]  It's also clear what it is.
[02:36:49.180 --> 02:36:51.180]  Graph dichotomy
[02:36:51.180 --> 02:36:54.180]  is graph decomposition into two subgraphs.
[02:36:54.180 --> 02:36:56.180]  And graph depth...
[02:36:56.180 --> 02:36:58.180]  What?
[02:36:58.180 --> 02:36:59.180]  Ah.
[02:36:59.180 --> 02:37:01.180]  Another slide.
[02:37:01.180 --> 02:37:03.180]  Ah, here. I understood.
[02:37:03.180 --> 02:37:05.180]  Ah, it's possible without it.
[02:37:05.180 --> 02:37:07.180]  Well, I see. Much easier.
[02:37:07.180 --> 02:37:09.180]  Well.
[02:37:09.180 --> 02:37:11.180]  Well, as next one,
[02:37:11.180 --> 02:37:13.180]  graph decomposition, no.
[02:37:13.180 --> 02:37:15.180]  Partition.
[02:37:15.180 --> 02:37:16.180]  And especially graph depth,
[02:37:16.180 --> 02:37:20.180]  it's a new characteristic of graph entanglement.
[02:37:20.180 --> 02:37:22.180]  The plastic graph.
[02:37:22.180 --> 02:37:24.180]  Calculate is a further described
[02:37:24.180 --> 02:37:27.180]  algorithm of family of dichotomies contraction.
[02:37:27.180 --> 02:37:30.180]  So, what about it?
[02:37:30.180 --> 02:37:32.180]  Oh, like many other algorithms,
[02:37:32.180 --> 02:37:34.180]  it consists of two parts.
[02:37:34.180 --> 02:37:37.180]  Intellization stage and regular stage,
[02:37:37.180 --> 02:37:40.180]  which is repeated several times.
[02:37:40.180 --> 02:37:43.180]  It's also parameter.
[02:37:43.180 --> 02:37:46.180]  First of all, what's the utilization?
[02:37:46.180 --> 02:37:48.180]  Initial assignment necessary parameters.
[02:37:48.180 --> 02:37:51.180]  Random value from 1 to 5, till 5.
[02:37:51.180 --> 02:37:52.180]  It's...
[02:37:52.180 --> 02:37:55.180]  5 is just one of parameter from the algorithm.
[02:37:55.180 --> 02:37:59.180]  It can be 1 till 1, also possible.
[02:37:59.180 --> 02:38:02.180]  1 till 10, it's not so important.
[02:38:02.180 --> 02:38:05.180]  I define initial loading
[02:38:05.180 --> 02:38:07.180]  in all the edge of the given graph.
[02:38:07.180 --> 02:38:09.180]  What is name of loading?
[02:38:09.180 --> 02:38:11.180]  Perhaps the most important,
[02:38:11.180 --> 02:38:14.180]  very important notion in this report.
[02:38:14.180 --> 02:38:16.180]  And it's really, it's a maximum,
[02:38:16.180 --> 02:38:19.180]  it's really, it's a...
[02:38:19.180 --> 02:38:24.180]  maximum...
[02:38:24.180 --> 02:38:26.180]  Maximum of edge loading is defined
[02:38:26.180 --> 02:38:28.180]  as initial maximum loading.
[02:38:28.180 --> 02:38:30.180]  It will be described early,
[02:38:30.180 --> 02:38:32.180]  and initial value D is 0,
[02:38:32.180 --> 02:38:35.180]  and number execution of regular stage is T.
[02:38:35.180 --> 02:38:38.180]  Well, the next one.
[02:38:42.180 --> 02:38:45.180]  Initial assignments.
[02:38:45.180 --> 02:38:48.180]  Ah, it already was.
[02:38:51.180 --> 02:38:54.180]  At every execution of regular stage,
[02:38:54.180 --> 02:38:56.180]  there are several input data,
[02:38:56.180 --> 02:38:59.180]  some input data, graph itself never changes,
[02:38:59.180 --> 02:39:02.180]  current value of loading in all the edges,
[02:39:02.180 --> 02:39:06.180]  current value of maximum loading,
[02:39:06.180 --> 02:39:09.180]  and maximum is getting taken over
[02:39:09.180 --> 02:39:12.180]  over all the edges,
[02:39:12.180 --> 02:39:15.180]  and current value of graph depth.
[02:39:15.180 --> 02:39:18.180]  After every execution of the regular stage,
[02:39:18.180 --> 02:39:21.180]  produced modified values of loading in all the edges,
[02:39:21.180 --> 02:39:23.180]  modified value of graph depth,
[02:39:23.180 --> 02:39:26.180]  modified value of depth,
[02:39:26.180 --> 02:39:30.180]  current depth, lmax, and one dichotomy is constructed.
[02:39:30.180 --> 02:39:35.180]  But every regular stage
[02:39:35.180 --> 02:39:40.180]  produces one new dichotomy.
[02:39:44.180 --> 02:39:46.180]  What's regular stage?
[02:39:46.180 --> 02:39:48.180]  Perhaps this algorithm,
[02:39:48.180 --> 02:39:51.180]  it will be illustrated by a picture,
[02:39:51.180 --> 02:39:53.180]  but, however, now,
[02:39:53.180 --> 02:39:55.180]  it's not so well-considered,
[02:39:55.180 --> 02:39:57.180]  only main page,
[02:39:57.180 --> 02:39:59.180]  main steps are described,
[02:39:59.180 --> 02:40:01.180]  without I meet many details, of course.
[02:40:01.180 --> 02:40:03.180]  Choose a random pair of different vertices
[02:40:03.180 --> 02:40:05.180]  from the set of vertices.
[02:40:05.180 --> 02:40:07.180]  v is clear,
[02:40:07.180 --> 02:40:09.180]  not clear, it's not clear,
[02:40:09.180 --> 02:40:11.180]  but it's the most important step here,
[02:40:11.180 --> 02:40:14.180]  it's the second step.
[02:40:14.180 --> 02:40:16.180]  Construct a minimum path,
[02:40:16.180 --> 02:40:19.180]  connecting the two chosen vertices by Dijkstra algorithm.
[02:40:19.180 --> 02:40:24.180]  But the length of an edge is its current loading,
[02:40:24.180 --> 02:40:31.180]  the length of a path is equal to the length of its longest edge,
[02:40:31.180 --> 02:40:33.180]  not the sum, but the maximum.
[02:40:33.180 --> 02:40:35.180]  It's also very low notion,
[02:40:35.180 --> 02:40:40.180]  and, of course, Dijkstra algorithm works in this situation also with maximum.
[02:40:40.180 --> 02:40:44.180]  And what after we did deal?
[02:40:44.180 --> 02:40:47.180]  After we selected, constructed, not we,
[02:40:47.180 --> 02:40:50.180]  Dijkstra algorithm constructed one path,
[02:40:50.180 --> 02:40:52.180]  it increased by one,
[02:40:52.180 --> 02:40:54.180]  all the current loading in all the edges,
[02:40:54.180 --> 02:40:59.180]  because this path just go along all these edges.
[02:40:59.180 --> 02:41:02.180]  Loading is increased by one,
[02:41:02.180 --> 02:41:06.180]  and increase by one the current value of graph depth.
[02:41:06.180 --> 02:41:13.180]  It means any path increases value of depth of the graph by one.
[02:41:13.180 --> 02:41:17.180]  And execute steps one to four,
[02:41:17.180 --> 02:41:22.180]  till the maximum value of loading exceeds the current value Lmax.
[02:41:22.180 --> 02:41:31.180]  Consider the initial graph with the loading just before we're finding this path.
[02:41:31.180 --> 02:41:36.180]  The sets of edges whose loading is equal to Lmax
[02:41:36.180 --> 02:41:40.180]  contain some cut.
[02:41:40.180 --> 02:41:44.180]  This graph is sort of after that we can,
[02:41:44.180 --> 02:41:48.180]  by deletion of all these edges,
[02:41:48.180 --> 02:41:54.180]  we construct the number of components becomes more than one.
[02:41:54.180 --> 02:41:57.180]  Perhaps not compulsory too, perhaps more.
[02:41:57.180 --> 02:42:02.180]  And we construct two sub-graphs,
[02:42:02.180 --> 02:42:06.180]  one with the maximum number of vertices,
[02:42:06.180 --> 02:42:09.180]  that they union all the other component.
[02:42:09.180 --> 02:42:14.180]  Of course, really it's described how to unite all the others and so on.
[02:42:14.180 --> 02:42:17.180]  But really what's important,
[02:42:17.180 --> 02:42:19.180]  it's all virtual operation, I can say,
[02:42:19.180 --> 02:42:22.180]  because graph all the time is the same.
[02:42:22.180 --> 02:42:26.180]  Now loading of edges of course changes,
[02:42:26.180 --> 02:42:30.180]  the length also,
[02:42:30.180 --> 02:42:32.180]  so-called depth of graph also changes,
[02:42:32.180 --> 02:42:35.180]  but only increasing.
[02:42:35.180 --> 02:42:39.180]  But graph all the time is the same.
[02:42:39.180 --> 02:42:41.180]  I would like to show in picture,
[02:42:41.180 --> 02:42:43.180]  because it's much easier to understand,
[02:42:43.180 --> 02:42:45.180]  because it's the central path.
[02:42:45.180 --> 02:42:47.180]  There are three cases of regular stages.
[02:42:47.180 --> 02:42:56.180]  Case A, both lines are just edges with maximum load,
[02:42:56.180 --> 02:42:58.180]  maximum loading.
[02:42:58.180 --> 02:43:01.180]  In all the other edges loading is less.
[02:43:01.180 --> 02:43:05.180]  If we do not form any cut,
[02:43:05.180 --> 02:43:07.180]  we don't contain any cut,
[02:43:07.180 --> 02:43:12.180]  so you can take arbitrary vertices A and B
[02:43:12.180 --> 02:43:14.180]  and find the shortest path.
[02:43:14.180 --> 02:43:16.180]  Of course, the shortest path,
[02:43:16.180 --> 02:43:18.180]  because of its minimax definition.
[02:43:18.180 --> 02:43:24.180]  It never goes along with edges with maximum loading,
[02:43:24.180 --> 02:43:30.180]  because it tries to find a path
[02:43:30.180 --> 02:43:33.180]  with minimal length.
[02:43:33.180 --> 02:43:38.180]  A length of the path is the maximum value of length of any edges.
[02:43:38.180 --> 02:43:41.180]  From this, it's possible to find.
[02:43:41.180 --> 02:43:43.180]  Case B.
[02:43:43.180 --> 02:43:46.180]  All these edges with maximum loading
[02:43:46.180 --> 02:43:49.180]  do contain some cut of the graph,
[02:43:49.180 --> 02:43:54.180]  but if vertices A and B from one side to this,
[02:43:54.180 --> 02:43:58.180]  inside of one of components of connectivity,
[02:43:58.180 --> 02:44:00.180]  connecting the component of the graph,
[02:44:00.180 --> 02:44:03.180]  it's possible also to find this.
[02:44:03.180 --> 02:44:07.180]  Let me show something here.
[02:44:07.180 --> 02:44:10.180]  How to show something?
[02:44:10.180 --> 02:44:12.180]  Do you have something to show?
[02:44:12.180 --> 02:44:14.180]  Can you show something?
[02:44:14.180 --> 02:44:16.180]  Here or there?
[02:44:16.180 --> 02:44:20.180]  Can you show a place?
[02:44:20.180 --> 02:44:22.180]  Where it is?
[02:44:22.180 --> 02:44:24.180]  This one?
[02:44:24.180 --> 02:44:28.180]  No, it's not so.
[02:44:28.180 --> 02:44:32.180]  So.
[02:44:32.180 --> 02:44:35.180]  There is no cursor here.
[02:44:35.180 --> 02:44:37.180]  Ah, it's not working.
[02:44:37.180 --> 02:44:39.180]  No, press and it will show.
[02:44:39.180 --> 02:44:41.180]  Ah, well.
[02:44:41.180 --> 02:44:45.180]  The most interesting case C was here.
[02:44:45.180 --> 02:44:52.180]  The case where all the set of edges with maximum loading
[02:44:52.180 --> 02:44:55.180]  do contain, like in case B,
[02:44:55.180 --> 02:44:57.180]  do contain some cut of the graph,
[02:44:57.180 --> 02:45:01.180]  but A and B are different components of this graph.
[02:45:01.180 --> 02:45:05.180]  From this, any path, including shortest path,
[02:45:05.180 --> 02:45:08.180]  must go through at least one,
[02:45:08.180 --> 02:45:13.180]  but really a long one of these edges.
[02:45:13.180 --> 02:45:17.180]  Because we increase every,
[02:45:17.180 --> 02:45:22.180]  because we increase any loading by one,
[02:45:22.180 --> 02:45:27.180]  we will increase maximum value, L maximum.
[02:45:27.180 --> 02:45:29.180]  It also will increase by one.
[02:45:29.180 --> 02:45:31.180]  And we go to the...
[02:45:31.180 --> 02:45:35.180]  First of all, from this previous step,
[02:45:35.180 --> 02:45:37.180]  we find some dichotomy.
[02:45:37.180 --> 02:45:42.180]  Not find, it's clear, it's given after elimination,
[02:45:42.180 --> 02:45:45.180]  even virtual with edges.
[02:45:45.180 --> 02:45:49.180]  And so we can go to the next stage,
[02:45:49.180 --> 02:45:52.180]  the next regular stage.
[02:45:52.180 --> 02:45:55.180]  What will happen after all of them?
[02:46:00.180 --> 02:46:02.180]  So, how to construct algorithm?
[02:46:02.180 --> 02:46:04.180]  It's only dichotomy in two parts,
[02:46:04.180 --> 02:46:08.180]  but how to construct dichotomy to many parts?
[02:46:08.180 --> 02:46:11.180]  To many parts, it's very natural,
[02:46:11.180 --> 02:46:14.180]  because the first is select some,
[02:46:14.180 --> 02:46:18.180]  select one component, one sub-graph,
[02:46:18.180 --> 02:46:23.180]  one sub-graph, and after apply the same.
[02:46:23.180 --> 02:46:26.180]  But we select, with algorithm,
[02:46:26.180 --> 02:46:30.180]  we select a sub-graph with maximum number of vertices.
[02:46:30.180 --> 02:46:34.180]  And after that the same algorithm is used another time
[02:46:34.180 --> 02:46:37.180]  for this sub-graph, the same algorithm, and so on.
[02:46:37.180 --> 02:46:39.180]  Find dichotomy, and after that,
[02:46:39.180 --> 02:46:43.180]  for all the pair of found sub-graphs,
[02:46:43.180 --> 02:46:46.180]  select the one whose maximum number of vertices
[02:46:46.180 --> 02:46:51.180]  in both sub-graphs is very minimal among all the pair.
[02:46:52.180 --> 02:46:55.180]  And what I mean here?
[02:46:57.180 --> 02:46:59.180]  Well, that's okay.
[02:46:59.180 --> 02:47:02.180]  Replace selected sub-graph,
[02:47:02.180 --> 02:47:05.180]  these two found, and the previous step,
[02:47:05.180 --> 02:47:07.180]  and the previous step three,
[02:47:07.180 --> 02:47:11.180]  and we find the composition into K plus one sub-graph.
[02:47:11.180 --> 02:47:14.180]  So, we must, in the beginning,
[02:47:14.180 --> 02:47:17.180]  we have some required number G of sub-graphs,
[02:47:17.180 --> 02:47:22.180]  and we can construct some graph decomposition
[02:47:22.180 --> 02:47:24.180]  into G sub-graphs.
[02:47:24.180 --> 02:47:28.180]  What is necessary to say about all these constructions?
[02:47:28.180 --> 02:47:31.180]  It's very simple construction, but it is effective.
[02:47:31.180 --> 02:47:33.180]  Why? I can say.
[02:47:33.180 --> 02:47:35.180]  Practically, I know, of course,
[02:47:35.180 --> 02:47:38.180]  a lot of methods of qualification of graph decomposition,
[02:47:38.180 --> 02:47:42.180]  and in any methods, the goal of any method
[02:47:42.180 --> 02:47:46.180]  is to find some decomposition,
[02:47:46.180 --> 02:47:49.180]  the best decomposition.
[02:47:49.180 --> 02:47:52.180]  It's so possible, if a graph is simple,
[02:47:52.180 --> 02:47:57.180]  a simple one, any, many, many, many others,
[02:47:57.180 --> 02:47:59.180]  you'll find the same.
[02:47:59.180 --> 02:48:05.180]  But if you have some more complicated situation,
[02:48:05.180 --> 02:48:09.180]  I can say, perhaps, to sharp the best,
[02:48:09.180 --> 02:48:12.180]  or not the best, the correct decomposition
[02:48:12.180 --> 02:48:15.180]  simply does not exist, does not exist.
[02:48:15.180 --> 02:48:17.180]  No, not at all.
[02:48:17.180 --> 02:48:23.180]  You can construct, because I use random generator
[02:48:23.180 --> 02:48:25.180]  always construction,
[02:48:25.180 --> 02:48:29.180]  you can find many, many different decompositions.
[02:48:29.180 --> 02:48:30.180]  Many different.
[02:48:30.180 --> 02:48:32.180]  No, if I repeat this thousand times,
[02:48:32.180 --> 02:48:37.180]  but typically 30 or 500 of vertices.
[02:48:37.180 --> 02:48:42.180]  30, 40, 20, something like this.
[02:48:42.180 --> 02:48:49.180]  Not 100, but a number of different dichotomies.
[02:48:49.180 --> 02:48:52.180]  And after that, one dichotomy is selected.
[02:48:52.180 --> 02:48:56.180]  Because you have a lot, you can select one.
[02:48:56.180 --> 02:49:00.180]  In many cases, it's not necessary to select one.
[02:49:00.180 --> 02:49:03.180]  It also exists.
[02:49:03.180 --> 02:49:05.180]  But it's not in this work.
[02:49:06.180 --> 02:49:11.180]  Some characteristic of the graph itself
[02:49:11.180 --> 02:49:17.180]  that is defined following all these different decompositions.
[02:49:17.180 --> 02:49:24.180]  It's called like entropy of this family of different decompositions.
[02:49:24.180 --> 02:49:26.180]  Different dichotomies.
[02:49:30.180 --> 02:49:32.180]  What is necessary to add?
[02:49:32.180 --> 02:49:34.180]  All this construction needs only graph
[02:49:34.180 --> 02:49:37.180]  because no metric information is used here.
[02:49:37.180 --> 02:49:39.180]  But typically, many problems.
[02:49:39.180 --> 02:49:43.180]  You have metric, you have distance between objects, between elements.
[02:49:43.180 --> 02:49:47.180]  And so, of course, it's possible not only to construct graph.
[02:49:47.180 --> 02:49:51.180]  Typically, I take four closest.
[02:49:51.180 --> 02:49:53.180]  And so, consider the graph.
[02:49:53.180 --> 02:49:56.180]  After that, find the composition of the graph.
[02:49:56.180 --> 02:50:01.180]  But when you select one, the composition among many,
[02:50:01.180 --> 02:50:07.180]  it's possible also use metric, distance between elements.
[02:50:07.180 --> 02:50:14.180]  And from that, I use just in the stock market
[02:50:14.180 --> 02:50:19.180]  because I have prices from some time.
[02:50:19.180 --> 02:50:26.180]  And finally, I have distance between different objects.
[02:50:26.180 --> 02:50:31.180]  Because it's time, it's prices during 15 days.
[02:50:31.180 --> 02:50:32.180]  Also parameter, my parameter.
[02:50:32.180 --> 02:50:36.180]  I will explain all parameter after that.
[02:50:36.180 --> 02:50:47.180]  And so, it's possible to use not only graph characteristic itself.
[02:50:47.180 --> 02:50:49.180]  Graph only, but also metric.
[02:50:49.180 --> 02:50:55.180]  So, what I do, I find average distance between all elements in one sub-graph.
[02:50:55.180 --> 02:51:01.180]  And in two selection, in two sub-graph of the composition, I select one.
[02:51:01.180 --> 02:51:05.180]  I select pair one, the composition, one dichotomy,
[02:51:05.180 --> 02:51:11.180]  where the maximum, where this number of vertices will be minimal among these two.
[02:51:11.180 --> 02:51:16.180]  It will be minimum, maximum of two, maximum of two graph.
[02:51:16.180 --> 02:51:21.180]  Maximum number of vertices in both graph, both part of dichotomy.
[02:51:21.180 --> 02:51:27.180]  All thousand, perhaps of course less, but all thousand variant will be minimal.
[02:51:27.180 --> 02:51:33.180]  It's, I can say, tend to situation excluding such that you have thousand,
[02:51:33.180 --> 02:51:38.180]  you have 500 vertices, you have 495 and 5.
[02:51:38.180 --> 02:51:48.180]  I try to exclude it if a normal uniform decomposition exists, it will be found by this algorithm.
[02:51:49.180 --> 02:51:54.180]  But if also it's possible in this place use the second part.
[02:51:54.180 --> 02:51:57.180]  The same algorithm, but not instead of number of element,
[02:51:57.180 --> 02:52:03.180]  you can consider average distance between all the elements in this sub-graph.
[02:52:03.180 --> 02:52:06.180]  It must be of course then less, then better.
[02:52:06.180 --> 02:52:11.180]  Its distance must be maybe as close to one to other as possible.
[02:52:11.180 --> 02:52:17.180]  The same, it's selected one of two, this has the worst case.
[02:52:17.180 --> 02:52:24.180]  And afterwards all the pair, all the pair, it selects,
[02:52:24.180 --> 02:52:31.180]  algorithm selects this one with maximum possible density.
[02:52:31.180 --> 02:52:36.180]  Density is clear, it's something like distance, but when more, when better.
[02:52:36.180 --> 02:52:41.180]  So, this is the end of the first part of my presentation.
[02:52:41.180 --> 02:52:44.180]  Second part, concern.
[02:52:51.180 --> 02:52:54.180]  Just a moment, I can do it.
[02:52:56.180 --> 02:53:01.180]  So, the modified algorithm that I told just now of these things, add finally.
[02:53:02.180 --> 02:53:08.180]  Second part of my presentation concern just market graphs for S&P 500.
[02:53:08.180 --> 02:53:12.180]  It's a very popular object because 500 not a lot,
[02:53:12.180 --> 02:53:17.180]  but of course it's 500 greatest, largest, greatest American companies.
[02:53:17.180 --> 02:53:21.180]  And from that of course it's, I can say, behavior with market.
[02:53:21.180 --> 02:53:25.180]  It's very typical for all the economic, not only the United States.
[02:53:25.180 --> 02:53:30.180]  So, what's written? Some standard conditions.
[02:53:30.180 --> 02:53:34.180]  So, I consider 15 days, L here 15.
[02:53:34.180 --> 02:53:37.180]  Prices share, so consider for these days.
[02:53:37.180 --> 02:53:41.180]  All the information is related to the last day, it's clear.
[02:53:41.180 --> 02:53:43.180]  And also distance, it's clear.
[02:53:43.180 --> 02:53:48.180]  Distance is defined by correlation coefficient, it's standard things.
[02:53:48.180 --> 02:53:52.180]  This construction, I can say, very non-construction.
[02:53:52.180 --> 02:53:58.180]  Only one thing, because sometimes not with some number closed,
[02:53:58.180 --> 02:54:03.180]  but in many constructions of market graph, consider.
[02:54:03.180 --> 02:54:09.180]  It's a level of correlation coefficient is given.
[02:54:09.180 --> 02:54:13.180]  For instance, 0.6 and 0.7.
[02:54:13.180 --> 02:54:23.180]  And as connected only with pair whose coefficient is more than this number.
[02:54:23.180 --> 02:54:30.180]  But I prefer because sometimes it's not very, not uniform in a different part of this graph.
[02:54:30.180 --> 02:54:34.180]  Distance scientifically be different.
[02:54:34.180 --> 02:54:38.180]  I mean coefficient correlation.
[02:54:38.180 --> 02:54:41.180]  From that I prefer take fixed number.
[02:54:41.180 --> 02:54:48.180]  Why for? Like all the other parameters will be explained for all of them.
[02:54:48.180 --> 02:54:50.180]  That's why graph is called the market graph.
[02:54:50.180 --> 02:54:55.180]  It's very known notion for more than 20 years, perhaps even more.
[02:54:55.180 --> 02:55:02.180]  I have, of course, a link to the first book about it.
[02:55:02.180 --> 02:55:05.180]  General scheme of the daily trading algorithm.
[02:55:05.180 --> 02:55:07.180]  What's so about?
[02:55:07.180 --> 02:55:12.180]  Many people try to find, to predict big crisis.
[02:55:12.180 --> 02:55:15.180]  I don't engage at all in this problem.
[02:55:15.180 --> 02:55:18.180]  I think only about trading the next day.
[02:55:18.180 --> 02:55:20.180]  Using information of the previous day.
[02:55:20.180 --> 02:55:24.180]  Like not only me, a lot of publications concerning the same problem.
[02:55:24.180 --> 02:55:33.180]  What to do the next day, which shares to buy, which shares to sell.
[02:55:33.180 --> 02:55:38.180]  Of course, in this point of view it's standard things.
[02:55:38.180 --> 02:55:42.180]  But how to do it?
[02:55:42.180 --> 02:55:46.180]  Approach is very known, but how to do it is different things.
[02:55:46.180 --> 02:55:49.180]  So the second point, it's a general scheme.
[02:55:49.180 --> 02:55:54.180]  Building graph of share of the base of this analysis, which is advisable to trade the next day.
[02:55:54.180 --> 02:55:57.180]  Or decide to skip trading the next day.
[02:55:57.180 --> 02:56:10.180]  Sometimes also necessary to skip the next day if you feel, if you know, perhaps, bad results.
[02:56:10.180 --> 02:56:22.180]  But pay attention, the item four, making decision about suspension of trading for a certain period, not for one day.
[02:56:22.180 --> 02:56:27.180]  And not because it can be something bad.
[02:56:27.180 --> 02:56:34.180]  Not because this decision depends on the result achieved during the previous period.
[02:56:34.180 --> 02:56:36.180]  Result can be good, not only bad.
[02:56:36.180 --> 02:56:39.180]  Good results and have bad results.
[02:56:39.180 --> 02:56:44.180]  In both case we stop the trading up to end of period.
[02:56:44.180 --> 02:56:48.180]  Period, connected period is one quarter.
[02:56:48.180 --> 02:56:51.180]  About 62-63 working days.
[02:56:51.180 --> 02:56:58.180]  So I considered 40, not 40, 21 years, 84 period, 84 quarters.
[02:56:58.180 --> 02:57:03.180]  Between 1990 and 2010.
[02:57:03.180 --> 02:57:06.180]  Big crisis just inside this period.
[02:57:06.180 --> 02:57:08.180]  But it's not so important for me.
[02:57:08.180 --> 02:57:10.180]  Big crisis is not so important.
[02:57:10.180 --> 02:57:15.180]  I will explain what it means.
[02:57:15.180 --> 02:57:21.180]  So, for the previous day.
[02:57:21.180 --> 02:57:22.180]  Very simple idea here.
[02:57:22.180 --> 02:57:32.180]  I consider, I consider market graph constructed for last day, for today, in the evening, and the previous day.
[02:57:32.180 --> 02:57:40.180]  So in both graph I construct the composition into 15, into 12.
[02:57:40.180 --> 02:57:42.180]  It's not so important in 12.
[02:57:42.180 --> 02:57:43.180]  Also parameter.
[02:57:43.180 --> 02:57:54.180]  In 12 some graphs I can say cluster and what is perhaps something new, not so new.
[02:57:54.180 --> 02:57:59.180]  But I found the maximum intersection of the cluster.
[02:57:59.180 --> 02:58:01.180]  Maximum number of elements.
[02:58:01.180 --> 02:58:04.180]  So we have two clusters, the same set of course.
[02:58:04.180 --> 02:58:14.180]  But with big intersection you have shares that have similar, because we are inside one cluster.
[02:58:14.180 --> 02:58:20.180]  I can say similar behavior in last 15 days.
[02:58:20.180 --> 02:58:22.180]  What does it mean?
[02:58:22.180 --> 02:58:31.180]  The next choice is like, because after that the end here.
[02:58:32.180 --> 02:58:34.180]  Fine subset.
[02:58:34.180 --> 02:58:36.180]  So some other conditions.
[02:58:36.180 --> 02:58:50.180]  So for M, if you say to yourself M, whose cost increased from yesterday and the note with M+, and here whose cost decreased from yesterday and the note M-.
[02:58:50.180 --> 02:58:59.180]  So of course it's natural idea to suppose with shares the next day, the known day, next day.
[02:58:59.180 --> 02:59:05.180]  Tomorrow you'll have the same behavior.
[02:59:05.180 --> 02:59:08.180]  But of course it's not a fact.
[02:59:08.180 --> 02:59:11.180]  Moreover, I think what to do is not so.
[02:59:11.180 --> 02:59:15.180]  You will just know what's possible to do about it.
[02:59:15.180 --> 02:59:18.180]  In many cases it's so, but not always.
[02:59:18.180 --> 02:59:22.180]  I can say it's not always so.
[02:59:23.180 --> 02:59:29.180]  Very simple recommendation of course for share from the group M-.
[02:59:29.180 --> 02:59:39.180]  Of course the next day it's proposed to sell with shares at a price at the market opening, which is assumed to be close to the price at the closer time the day before.
[02:59:39.180 --> 02:59:44.180]  And so buy at the market closer time the price, because it will be cheaper.
[02:59:44.180 --> 03:00:04.180]  And the same M+, this time it's helpful to buy one share and sell it at the end of this day, in the morning to buy.
[03:00:04.180 --> 03:00:09.180]  So because in this part price increases.
[03:00:09.180 --> 03:00:11.180]  So it's a very natural idea.
[03:00:11.180 --> 03:00:13.180]  But why it can work?
[03:00:13.180 --> 03:00:22.180]  Because I used not only this fact from the last two days, but also from the previous 15 days.
[03:00:22.180 --> 03:00:25.180]  From that it very often gives good results.
[03:00:25.180 --> 03:00:26.180]  But not often.
[03:00:26.180 --> 03:00:28.180]  But what after that?
[03:00:28.180 --> 03:00:32.180]  What is really new thing I can say?
[03:00:32.180 --> 03:00:34.180]  Stopping crew.
[03:00:34.180 --> 03:00:47.180]  The considered elementary period is one quarter and S of t is a cumulative income after day t from the beginning of the considered quarter.
[03:00:47.180 --> 03:00:56.180]  The first day is zero, but I use day zero, day one I use only to predict the next, not to predict to consider the next day and so on.
[03:00:56.180 --> 03:00:58.180]  So what is the idea here?
[03:00:58.180 --> 03:01:01.180]  I define two numbers.
[03:01:01.180 --> 03:01:03.180]  Two terms hold.
[03:01:03.180 --> 03:01:07.180]  One negative minus 25 and positive plus 50.
[03:01:07.180 --> 03:01:10.180]  So I make a decision every day.
[03:01:10.180 --> 03:01:14.180]  It's cumulative income.
[03:01:14.180 --> 03:01:17.180]  It means from the beginning of the quarter up to this day.
[03:01:17.180 --> 03:01:20.180]  It's good enough.
[03:01:20.180 --> 03:01:22.180]  It's not good.
[03:01:22.180 --> 03:01:26.180]  Also the trading is suspended till the end of the current quarter.
[03:01:26.180 --> 03:01:28.180]  It's income more than 50.
[03:01:28.180 --> 03:01:31.180]  When the trading is suspended, it's a good result.
[03:01:31.180 --> 03:01:36.180]  So you can earn some money and so not to play more.
[03:01:36.180 --> 03:01:41.180]  So otherwise the above exciting trading algorithm continues to work.
[03:01:41.180 --> 03:01:47.180]  Of course this algorithm can be named, but it's really so caution algorithm.
[03:01:47.180 --> 03:01:51.180]  I can say even truthfully.
[03:01:51.180 --> 03:01:53.180]  That's all.
[03:01:53.180 --> 03:02:00.180]  So I can tell the very known Russian expression in Russian, but explain this meaning.
[03:02:00.180 --> 03:02:04.180]  Не зато отец сына бил, что тот играл, зато что отыгрался.
[03:02:04.180 --> 03:02:10.180]  Main idea here you must be satisfied with not big, but positive result.
[03:02:10.180 --> 03:02:12.180]  That's all.
[03:02:12.180 --> 03:02:15.180]  It's also known idea.
[03:02:15.180 --> 03:02:25.180]  By the way, this situation a bit similar, not a lot, but a bit similar to very known problem, secretary problem.
[03:02:25.180 --> 03:02:31.180]  Because you also must finish, you don't know what will be after that.
[03:02:31.180 --> 03:02:35.180]  But in this case you have probability, but here you know nothing.
[03:02:35.180 --> 03:02:40.180]  However you can make reasonable decision.
[03:02:40.180 --> 03:02:42.180]  Why reasonable?
[03:02:42.180 --> 03:02:44.180]  After that I can present some table.
[03:02:44.180 --> 03:02:46.180]  That's all.
[03:02:46.180 --> 03:02:48.180]  Result of the stopping rule.
[03:02:48.180 --> 03:02:50.180]  It's three period, three quarter.
[03:02:50.180 --> 03:02:54.180]  Not up to the end, but it's clear what happened.
[03:02:54.180 --> 03:02:57.180]  And the place where I stop.
[03:02:57.180 --> 03:02:59.180]  Why not this place?
[03:02:59.180 --> 03:03:03.180]  Something happened here.
[03:03:03.180 --> 03:03:05.180]  Something happened here.
[03:03:05.180 --> 03:03:07.180]  What we can see here?
[03:03:07.180 --> 03:03:09.180]  Anyway it's possible to...
[03:03:29.180 --> 03:03:31.180]  So what's clear from here?
[03:03:31.180 --> 03:03:41.180]  Several, five several quarters between forty, between forty one, forty.
[03:03:41.180 --> 03:03:47.180]  Forty, twenty years, twenty one years, eighty one.
[03:03:47.180 --> 03:03:49.180]  Eighty one.
[03:03:49.180 --> 03:03:51.180]  Well and we can what?
[03:03:51.180 --> 03:03:54.180]  Here negative result we stop here.
[03:03:54.180 --> 03:03:56.180]  Twenty nine minus.
[03:03:56.180 --> 03:04:00.180]  Here also negative result and we stop just here.
[03:04:00.180 --> 03:04:02.180]  Negative result and we stop here.
[03:04:02.180 --> 03:04:03.180]  More than fifty.
[03:04:03.180 --> 03:04:04.180]  The same is here.
[03:04:04.180 --> 03:04:05.180]  Pay attention.
[03:04:05.180 --> 03:04:06.180]  The same is here.
[03:04:06.180 --> 03:04:07.180]  The same is here.
[03:04:07.180 --> 03:04:09.180]  Pay attention here.
[03:04:11.180 --> 03:04:14.180]  I know picture is spoiled, but I don't know why.
[03:04:14.180 --> 03:04:15.180]  It's important.
[03:04:15.180 --> 03:04:20.180]  From where the pay attention is just period before great crisis.
[03:04:20.180 --> 03:04:24.180]  It's third quarter of 2008.
[03:04:24.180 --> 03:04:26.180]  But I don't consider.
[03:04:26.180 --> 03:04:29.180]  Here you can receive much more.
[03:04:29.180 --> 03:04:30.180]  Here you can receive also.
[03:04:30.180 --> 03:04:31.180]  No less.
[03:04:31.180 --> 03:04:33.180]  Here you also can receive more.
[03:04:33.180 --> 03:04:34.180]  Here and so on.
[03:04:34.180 --> 03:04:36.180]  But I stop.
[03:04:36.180 --> 03:04:37.180]  It's stopping cruel.
[03:04:37.180 --> 03:04:38.180]  It's stopping cruel.
[03:04:38.180 --> 03:04:39.180]  So what after that?
[03:04:39.180 --> 03:04:41.180]  It's almost all.
[03:04:41.180 --> 03:04:47.180]  I calculate with algorithm from twenty years, twenty one year.
[03:04:47.180 --> 03:04:52.180]  You can hear annual income, sometimes negative.
[03:04:52.180 --> 03:04:54.180]  Cumulative income.
[03:04:54.180 --> 03:04:59.180]  You can see some increase anyway.
[03:04:59.180 --> 03:05:02.180]  And it's possible to see better presentation here.
[03:05:02.180 --> 03:05:05.180]  It's regression line.
[03:05:05.180 --> 03:05:07.180]  It's results here.
[03:05:07.180 --> 03:05:09.180]  Income here time.
[03:05:09.180 --> 03:05:10.180]  You can see.
[03:05:10.180 --> 03:05:12.180]  More I can say with the contract.
[03:05:12.180 --> 03:05:14.180]  I presented.
[03:05:14.180 --> 03:05:15.180]  I calculate many such.
[03:05:15.180 --> 03:05:17.180]  Perhaps three or four such picture.
[03:05:17.180 --> 03:05:19.180]  Some of them up to two thousand nineteen.
[03:05:19.180 --> 03:05:22.180]  The character was the same.
[03:05:22.180 --> 03:05:25.180]  Sometimes I change some not important details.
[03:05:25.180 --> 03:05:27.180]  But anyway, it's all the same.
[03:05:27.180 --> 03:05:28.180]  It's positive result.
[03:05:28.180 --> 03:05:30.180]  What can be said about it?
[03:05:30.180 --> 03:05:33.180]  Result itself not so good.
[03:05:33.180 --> 03:05:35.180]  Very little sum.
[03:05:35.180 --> 03:05:37.180]  But little sum.
[03:05:37.180 --> 03:05:40.180]  For instance, two thousand dollars and so on for many years.
[03:05:40.180 --> 03:05:43.180]  But first of all, I buy one.
[03:05:43.180 --> 03:05:45.180]  I deal with one share.
[03:05:45.180 --> 03:05:46.180]  Only one share.
[03:05:46.180 --> 03:05:48.180]  If you do the same with hundred share.
[03:05:48.180 --> 03:05:49.180]  We'll receive hundred times.
[03:05:49.180 --> 03:05:52.180]  Because in thousand share you'll receive thousand times more.
[03:05:52.180 --> 03:05:54.180]  When written here.
[03:05:54.180 --> 03:05:57.180]  So it's not so bad result.
[03:05:57.180 --> 03:05:59.180]  But of course.
[03:05:59.180 --> 03:06:01.180]  What I would like only to.
[03:06:01.180 --> 03:06:03.180]  To start to end.
[03:06:03.180 --> 03:06:05.180]  Parameters.
[03:06:05.180 --> 03:06:08.180]  We suggest algorithm is algorithm of data analysis.
[03:06:08.180 --> 03:06:11.180]  And it is not an algorithm of stock market imitation.
[03:06:11.180 --> 03:06:14.180]  No assumption about stock market behavior itself.
[03:06:14.180 --> 03:06:17.180]  As well as about behavior of the actor.
[03:06:17.180 --> 03:06:18.180]  No probabilistic.
[03:06:18.180 --> 03:06:20.180]  No any assumption at all.
[03:06:20.180 --> 03:06:23.180]  I consider data as a fixed number.
[03:06:23.180 --> 03:06:24.180]  When I know.
[03:06:24.180 --> 03:06:26.180]  And I don't suppose anything about them.
[03:06:26.180 --> 03:06:28.180]  Anything.
[03:06:28.180 --> 03:06:29.180]  It's only.
[03:06:29.180 --> 03:06:31.180]  But when I produce.
[03:06:31.180 --> 03:06:33.180]  I use probability like.
[03:06:33.180 --> 03:06:34.180]  Because I use random.
[03:06:34.180 --> 03:06:37.180]  Random standard data generation.
[03:06:37.180 --> 03:06:38.180]  But something else.
[03:06:38.180 --> 03:06:42.180]  Because in this case it's possible to use limit theorem and so on.
[03:06:42.180 --> 03:06:44.180]  Not as possible to use.
[03:06:44.180 --> 03:06:47.180]  To initial data.
[03:06:48.180 --> 03:06:49.180]  That.
[03:06:49.180 --> 03:06:51.180]  Absolutely unknown.
[03:06:51.180 --> 03:06:54.180]  I think all of us understand the difference between.
[03:06:54.180 --> 03:06:55.180]  What is unknown.
[03:06:55.180 --> 03:06:58.180]  Uncertainty and.
[03:06:58.180 --> 03:07:00.180]  Uncertainty and probability.
[03:07:00.180 --> 03:07:01.180]  Very different things.
[03:07:01.180 --> 03:07:02.180]  So.
[03:07:02.180 --> 03:07:04.180]  I support only uncertainty.
[03:07:04.180 --> 03:07:06.180]  Not probability at all.
[03:07:06.180 --> 03:07:08.180]  And after that.
[03:07:08.180 --> 03:07:10.180]  I use several.
[03:07:10.180 --> 03:07:12.180]  Things how to improve this algorithm.
[03:07:12.180 --> 03:07:14.180]  Of course there are many way to improve it.
[03:07:14.180 --> 03:07:15.180]  I don't intend to.
[03:07:15.180 --> 03:07:17.180]  Of course I would like to underline.
[03:07:17.180 --> 03:07:18.180]  That's not.
[03:07:18.180 --> 03:07:19.180]  The end of the work.
[03:07:19.180 --> 03:07:21.180]  It's a beginning of the work.
[03:07:21.180 --> 03:07:23.180]  Serious analysis of fund.
[03:07:23.180 --> 03:07:26.180]  Because not only this.
[03:07:26.180 --> 03:07:27.180]  Stock market.
[03:07:27.180 --> 03:07:28.180]  Also the others.
[03:07:28.180 --> 03:07:29.180]  But.
[03:07:29.180 --> 03:07:31.180]  I can say it's necessary to understand.
[03:07:31.180 --> 03:07:32.180]  Pay attention.
[03:07:32.180 --> 03:07:33.180]  That.
[03:07:33.180 --> 03:07:34.180]  Big crisis.
[03:07:34.180 --> 03:07:35.180]  Don't.
[03:07:35.180 --> 03:07:36.180]  I can say.
[03:07:36.180 --> 03:07:38.180]  Don't trouble me.
[03:07:38.180 --> 03:07:40.180]  Don't trouble me at all.
[03:07:40.180 --> 03:07:43.180]  You receive plus even before this crisis.
[03:07:43.180 --> 03:07:44.180]  And even after that.
[03:07:44.180 --> 03:07:46.180]  Of course.
[03:07:46.180 --> 03:07:47.180]  It's because.
[03:07:47.180 --> 03:07:48.180]  Other idea.
[03:07:48.180 --> 03:07:49.180]  Of course.
[03:07:49.180 --> 03:07:50.180]  And the last.
[03:07:50.180 --> 03:07:51.180]  The last picture.
[03:07:51.180 --> 03:07:52.180]  Don't worry.
[03:07:52.180 --> 03:07:53.180]  Is the last.
[03:07:53.180 --> 03:07:55.180]  About great crash.
[03:07:55.180 --> 03:07:57.180]  Some people can consider.
[03:07:57.180 --> 03:07:58.180]  That is absolutely.
[03:07:58.180 --> 03:07:59.180]  Monte Carlo.
[03:07:59.180 --> 03:08:01.180]  Nothing to do.
[03:08:01.180 --> 03:08:02.180]  Great crisis.
[03:08:02.180 --> 03:08:05.180]  To 1929.
[03:08:05.180 --> 03:08:07.180]  It's a citation of.
[03:08:07.180 --> 03:08:08.180]  There is this edge.
[03:08:08.180 --> 03:08:09.180]  My friends.
[03:08:10.180 --> 03:08:12.180]  To sell.
[03:08:12.180 --> 03:08:14.180]  Security.
[03:08:14.180 --> 03:08:15.180]  Katolik.
[03:08:15.180 --> 03:08:17.180]  Wisdom of 20.
[03:08:17.180 --> 03:08:18.180]  Yes I didn't.
[03:08:18.180 --> 03:08:21.180]  Pente.
[03:08:21.180 --> 03:08:22.180]  So.
[03:08:22.180 --> 03:08:23.180]  You must.
[03:08:23.180 --> 03:08:24.180]  We need.
[03:08:24.180 --> 03:08:25.180]  Ring.
[03:08:25.180 --> 03:08:26.180]  The reason.
[03:08:26.180 --> 03:08:27.180]  is.
[03:08:27.180 --> 03:08:28.180]  A.
[03:08:28.180 --> 03:08:29.180]  rush delivery was so.
[03:08:29.180 --> 03:08:30.180]  High no.
[03:08:30.180 --> 03:08:31.180]  We must.
[03:08:31.180 --> 03:08:32.180] 低.
[03:08:32.180 --> 03:08:34.180]  That.
[03:08:34.180 --> 03:08:35.180]  Cisance no.
[03:08:35.180 --> 03:08:36.180]  That's a point.
[03:08:36.180 --> 03:08:37.180]  Vaccine Luis.
[03:08:37.180 --> 03:08:38.180]  Massive and they can.
[03:08:38.180 --> 03:08:44.180]  Но смысл прожечь он предовольен и точен. Я ничего не потерял. Мало того, сорвал, как бы, вероятно, выразились изрядный куш.
[03:08:46.180 --> 03:08:48.180]  Я извиняюсь. Уже 15 минут.
[03:08:48.180 --> 03:08:52.180]  Не, ну не 15. Да, то ж, наверное, часы. Не 15. 5 минут. 5. 5.
[03:08:52.180 --> 03:08:53.180]  Ну держи 5.
[03:08:53.180 --> 03:08:54.180]  5. 5.
[03:08:54.180 --> 03:08:55.180]  Зачем?
[03:08:55.180 --> 03:08:56.180]  Ветсул. Ветсул.
[03:08:56.180 --> 03:08:57.180]  У вас есть вопросы?
[03:08:57.180 --> 03:08:58.180]  Конечно.
[03:08:58.180 --> 03:09:00.180]  У вас есть вопросы?
[03:09:06.180 --> 03:09:07.180]  Конечно.
[03:09:25.180 --> 03:09:27.180]  Индекс – это не результат.
[03:09:27.180 --> 03:09:31.180]  Индекс – это параметр рынка.
[03:09:31.180 --> 03:09:33.180]  Результат – это деньги, которые люди могут получать.
[03:09:40.180 --> 03:09:42.180]  Нет, я не сравниваю с индексом.
[03:09:45.180 --> 03:09:48.180]  Может быть. Много идей нужно попробовать.
[03:09:48.180 --> 03:09:50.180]  Во-первых, я знаю несколько способов.
[03:09:51.180 --> 03:09:53.180]  Кстати, я написал себе все программы.
[03:09:54.180 --> 03:09:56.180]  И много технического работы здесь.
[03:09:57.180 --> 03:09:59.180]  Понимаете? Здесь, на самом деле, 5 или 6 программ.
[03:10:00.180 --> 03:10:01.180]  Но нет.
[03:10:02.180 --> 03:10:04.180]  Есть много-много возможностей, чтобы улучшить результат.
[03:10:05.180 --> 03:10:07.180]  Конечно, я видел предыдущие вещи.
[03:10:10.180 --> 03:10:14.180]  Я могу сказать только одну вещь, но они все не стабильны, я могу сказать.
[03:10:15.180 --> 03:10:17.180]  И они стабильны, действительно, в автоматическом смысле.
[03:10:18.180 --> 03:10:22.180]  У вас есть метрика, чтобы измерить стабилизацию вашей стратегии?
[03:10:23.180 --> 03:10:27.180]  Потому что я не могу делать это один раз.
[03:10:28.180 --> 03:10:30.180]  Я действительно делал это пять раз, но, возможно, пятьдесят раз.
[03:10:31.180 --> 03:10:32.180]  Потому что это скоро достаточно.
[03:10:33.180 --> 03:10:34.180]  Это возможно сделать.
[03:10:35.180 --> 03:10:37.180]  Но это не первое данное.
[03:10:38.180 --> 03:10:39.180]  Это продукт.
[03:10:40.180 --> 03:10:42.180]  Это результат процесса.
[03:10:43.180 --> 03:10:46.180]  Результат – это действительно рандомное значение.
[03:10:46.180 --> 03:10:47.180]  В автоматическом смысле.
[03:10:48.180 --> 03:10:49.180]  Из этого вы можете использовать.
[03:10:50.180 --> 03:10:51.180]  Конечно, некоторые дни могут быть негативными.
[03:10:52.180 --> 03:10:53.180]  Но некоторые дни более позитивные.
[03:10:54.180 --> 03:10:55.180]  И из этого вы получите хорошую сумму.
[03:10:56.180 --> 03:10:57.180]  Позитивную сумму.
[03:10:58.180 --> 03:10:59.180]  У меня есть вопрос.
[03:11:00.180 --> 03:11:01.180]  Вы говорили об кассе или коде.
[03:11:02.180 --> 03:11:08.180]  Как ваш алгоритм соответствует коде и коде алгоритма?
[03:11:09.180 --> 03:11:10.180]  Конечно, я очень хорошо знаю.
[03:11:11.180 --> 03:11:13.180]  Но, нет, нет, это не так.
[03:11:13.180 --> 03:11:14.180]  Это не так.
[03:11:15.180 --> 03:11:20.180]  Потому что я знаю, что с этой кассой, с этой кодой,
[03:11:21.180 --> 03:11:23.180]  с этой кодой, я могу сказать, в любом случае.
[03:11:24.180 --> 03:11:26.180]  Все параметры равны, максимально равны.
[03:11:27.180 --> 03:11:28.180]  Все коды.
[03:11:29.180 --> 03:11:30.180]  Мы имеем больше, но это содержит код.
[03:11:31.180 --> 03:11:33.180]  Из этого я просто выключаю все это.
[03:11:34.180 --> 03:11:35.180]  Не нужно это найти.
[03:11:36.180 --> 03:11:40.180]  Мой алгоритм определяет все это код.
[03:11:40.180 --> 03:11:45.180]  И то, что касса максимально равна коду.
[03:11:46.180 --> 03:11:50.180]  И так я не нужно это найти, как и Форд Волкерсон.
[03:11:51.180 --> 03:11:53.180]  Особенно найти этот код.
[03:11:54.180 --> 03:11:56.180]  Это просто найдено самым алгоритмом.
[03:11:57.180 --> 03:11:58.180]  Моим алгоритмом.
[03:11:59.180 --> 03:12:00.180]  И после этого я просто выключаю.
[03:12:01.180 --> 03:12:02.180]  Я могу сказать, выключаю виртуально.
[03:12:03.180 --> 03:12:04.180]  За какое-то время.
[03:12:05.180 --> 03:12:06.180]  Я не меняю кассу.
[03:12:07.180 --> 03:12:09.180]  Я понял вашу вопросу.
[03:12:10.180 --> 03:12:11.180]  Это не проблема.
[03:12:12.180 --> 03:12:13.180]  Мы знаем эти коды.
[03:12:14.180 --> 03:12:16.180]  Я делаю эти коды в один раз.
[03:12:17.180 --> 03:12:20.180]  Это просто момент, когда они увеличиваются.
[03:12:21.180 --> 03:12:23.180]  Максимальный код увеличивается в один раз.
[03:12:24.180 --> 03:12:25.180]  Потому что это только калькуляция.
[03:12:26.180 --> 03:12:28.180]  Ничего из-за кодов.
[03:12:29.180 --> 03:12:33.180]  Я думаю, вы можете сказать, что ваш алгоритм кодов.
[03:12:34.180 --> 03:12:35.180]  Нет.
[03:12:36.180 --> 03:12:37.180]  Потому что я использую абсолютно другое.
[03:12:37.180 --> 03:12:42.180]  Я использую идею, которую я нашел в виртуальности.
[03:12:43.180 --> 03:12:44.180]  И дикстра.
[03:12:45.180 --> 03:12:46.180]  Минимайсовый вариант дикстра.
[03:12:47.180 --> 03:12:48.180]  Код найдет все, что необходимо.
[03:12:49.180 --> 03:12:50.180]  Это, как я могу сказать, первая идея.
[03:12:51.180 --> 03:12:52.180]  Много лет назад.
[03:12:53.180 --> 03:12:55.180]  Но эта идея работает в политическом теле.
[03:12:56.180 --> 03:12:57.180]  И в образовом процессе.
[03:12:58.180 --> 03:12:59.180]  Много случаев.
[03:13:02.180 --> 03:13:03.180]  Еще какие-то вопросы?
[03:13:05.180 --> 03:13:06.180]  Спасибо большое.
[03:13:07.180 --> 03:13:08.180]  Большое спасибо.
[03:13:13.180 --> 03:13:14.180]  Наш следующий спонсор.
[03:13:16.180 --> 03:13:18.180]  Тузана Наскиментова.
[03:13:25.180 --> 03:13:27.180]  Тузана, слышишь меня?
[03:13:28.180 --> 03:13:29.180]  Это Борис.
[03:13:30.180 --> 03:13:32.180]  Слышишь меня, Тузана?
[03:13:33.180 --> 03:13:34.180]  Добрый вечер.
[03:13:34.180 --> 03:13:35.180]  Добрый вечер.
[03:13:36.180 --> 03:13:37.180]  Добрый вечер.
[03:13:38.180 --> 03:13:39.180]  Добрый вечер.
[03:13:40.180 --> 03:13:41.180]  Добрый вечер.
[03:13:42.180 --> 03:13:43.180]  Добрый вечер.
[03:13:44.180 --> 03:13:45.180]  Добрый вечер.
[03:13:46.180 --> 03:13:47.180]  Добрый вечер.
[03:13:48.180 --> 03:13:49.180]  Добрый вечер.
[03:13:50.180 --> 03:13:51.180]  Добрый вечер.
[03:13:52.180 --> 03:13:53.180]  Добрый вечер.
[03:13:54.180 --> 03:13:55.180]  Добрый вечер.
[03:13:56.180 --> 03:13:57.180]  Добрый вечер.
[03:13:58.180 --> 03:13:59.180]  Добрый вечер.
[03:14:00.180 --> 03:14:01.180]  Добрый вечер.
[03:14:02.180 --> 03:14:03.180]  Добрый вечер.
[03:14:04.180 --> 03:14:05.180]  Добрый вечер.
[03:14:06.180 --> 03:14:07.180]  Добрый вечер.
[03:14:08.180 --> 03:14:09.180]  Добрый вечер.
[03:14:10.180 --> 03:14:11.180]  Добрый вечер.
[03:14:12.180 --> 03:14:13.180]  Добрый вечер.
[03:14:14.180 --> 03:14:15.180]  Добрый вечер.
[03:14:16.180 --> 03:14:17.180]  Добрый вечер.
[03:14:18.180 --> 03:14:19.180]  Добрый вечер.
[03:14:20.180 --> 03:14:21.180]  Добрый вечер.
[03:14:22.180 --> 03:14:23.180]  Добрый вечер.
[03:14:24.180 --> 03:14:25.180]  Добрый вечер.
[03:14:26.180 --> 03:14:27.180]  Добрый вечер.
[03:14:28.180 --> 03:14:29.180]  Добрый вечер.
[03:14:29.180 --> 03:14:30.180]  Добрый вечер.
[03:14:31.180 --> 03:14:32.180]  Добрый вечер.
[03:14:33.180 --> 03:14:34.180]  Добрый вечер.
[03:14:35.180 --> 03:14:36.180]  Добрый вечер.
[03:14:38.180 --> 03:14:39.180]  Добрый вечер.
[03:14:40.180 --> 03:14:41.180]  Добрый вечер.
[03:14:42.180 --> 03:14:43.180]  Добрый вечер.
[03:14:44.180 --> 03:14:45.180]  Добрый вечер.
[03:14:46.180 --> 03:14:47.180]  Добрый вечер.
[03:14:48.180 --> 03:14:49.180]  Добрый вечер.
[03:14:50.180 --> 03:14:51.180]  Добрый вечер.
[03:14:52.180 --> 03:14:53.180]  Добрый вечер.
[03:14:54.180 --> 03:14:55.180]  Добрый вечер.
[03:14:56.180 --> 03:14:57.180]  Добрый вечер.
[03:14:57.180 --> 03:14:58.180]  Добрый вечер.
[03:15:00.180 --> 03:15:01.180]  Добрый вечер.
[03:15:02.180 --> 03:15:03.180]  Добрый вечер.
[03:15:04.180 --> 03:15:05.180]  Добрый вечер.
[03:15:06.180 --> 03:15:07.180]  Добрый вечер.
[03:15:08.180 --> 03:15:09.180]  Добрый вечер.
[03:15:10.180 --> 03:15:11.180]  Добрый вечер.
[03:15:12.180 --> 03:15:13.180]  Добрый вечер.
[03:15:14.180 --> 03:15:15.180]  Добрый вечер.
[03:15:16.180 --> 03:15:17.180]  Добрый вечер.
[03:15:18.180 --> 03:15:19.180]  Добрый вечер.
[03:15:20.180 --> 03:15:21.180]  Добрый вечер.
[03:15:22.180 --> 03:15:23.180]  Добрый вечер.
[03:15:24.180 --> 03:15:25.180]  Добрый вечер.
[03:15:25.180 --> 03:15:26.180]  Добрый вечер.
[03:15:28.180 --> 03:15:29.180]  Добрый вечер.
[03:15:30.180 --> 03:15:31.180]  Добрый вечер.
[03:15:32.180 --> 03:15:33.180]  Добрый вечер.
[03:15:34.180 --> 03:15:35.180]  Добрый вечер.
[03:15:36.180 --> 03:15:37.180]  Добрый вечер.
[03:15:38.180 --> 03:15:39.180]  Добрый вечер.
[03:15:40.180 --> 03:15:41.180]  Добрый вечер.
[03:15:42.180 --> 03:15:43.180]  Добрый вечер.
[03:15:44.180 --> 03:15:45.180]  Добрый вечер.
[03:15:46.180 --> 03:15:47.180]  Добрый вечер.
[03:15:48.180 --> 03:15:49.180]  Добрый вечер.
[03:15:50.180 --> 03:15:51.180]  Добрый вечер.
[03:15:52.180 --> 03:15:53.180]  Добрый вечер.
[03:15:54.180 --> 03:15:55.180]  Добрый вечер.
[03:15:56.180 --> 03:15:57.180]  Добрый вечер.
[03:15:58.180 --> 03:15:59.180]  Добрый вечер.
[03:16:00.180 --> 03:16:01.180]  Добрый вечер.
[03:16:02.180 --> 03:16:03.180]  Добрый вечер.
[03:16:04.180 --> 03:16:05.180]  Добрый вечер.
[03:16:06.180 --> 03:16:07.180]  Добрый вечер.
[03:16:08.180 --> 03:16:09.180]  Добрый вечер.
[03:16:10.180 --> 03:16:11.180]  Добрый вечер.
[03:16:12.180 --> 03:16:13.180]  Добрый вечер.
[03:16:14.180 --> 03:16:15.180]  Добрый вечер.
[03:16:16.180 --> 03:16:17.180]  Добрый вечер.
[03:16:18.180 --> 03:16:19.180]  Добрый вечер.
[03:16:20.180 --> 03:16:21.180]  Добрый вечер.
[03:16:21.180 --> 03:16:28.180]  Пиши на презентацию, видеть твое лицо, а не презентацию.
[03:16:28.180 --> 03:16:31.180]  О, извините, много спасибо, много спасибо.
[03:16:31.180 --> 03:16:32.180]  Пожалуйста.
[03:16:43.180 --> 03:16:45.180]  Это нормально сейчас?
[03:16:46.180 --> 03:16:47.180]  Да.
[03:16:51.180 --> 03:16:59.180]  Прошу прощения, я очень прощена, потому что, если вы позволите мне,
[03:16:59.180 --> 03:17:06.180]  я буду жить и вернуться в сессию, потому что я не могу слышать себя.
[03:17:06.180 --> 03:17:08.180]  Что я должна делать?
[03:17:12.180 --> 03:17:15.180]  Я не могу слышать кого-то.
[03:17:18.180 --> 03:17:20.180]  Мы можем слышать тебя.
[03:17:21.180 --> 03:17:23.180]  А вы можете слушать?
[03:17:42.180 --> 03:17:43.180]  Да, Варис.
[03:17:43.180 --> 03:17:46.180]  Тизана, мы можем слышать тебя в сессии.
[03:17:46.180 --> 03:17:48.180]  Просто продолжи.
[03:17:48.180 --> 03:17:52.180]  Я вижу твое лицо, но это не ты.
[03:17:52.180 --> 03:17:54.180]  Принеси и продолжи.
[03:17:54.180 --> 03:17:56.180]  Окей, я не буду продолжать.
[03:17:56.180 --> 03:17:58.180]  И я прощаюсь, прощаюсь за это.
[03:17:58.180 --> 03:18:00.180]  Это не ты.
[03:18:00.180 --> 03:18:02.180]  И они должны быть прощены, потому что...
[03:18:02.180 --> 03:18:06.180]  Да, да, не волнуйтесь, не волнуйтесь.
[03:18:06.180 --> 03:18:08.180]  Не волнуйтесь.
[03:18:08.180 --> 03:18:10.180]  Окей, пока, пока.
[03:18:18.180 --> 03:18:22.180]  Так, как я говорила,
[03:18:22.180 --> 03:18:26.180]  мы пересмотрели, что каждое первое
[03:18:26.180 --> 03:18:30.180]  оборудование сезона может быть
[03:18:30.180 --> 03:18:32.180]  разделено в короткие периоды,
[03:18:32.180 --> 03:18:34.180]  в которых оборудование в форме
[03:18:34.180 --> 03:18:37.180]  более или менее постоянное.
[03:18:37.180 --> 03:18:40.180]  Таким образом, мы предложили
[03:18:40.180 --> 03:18:42.180]  три-стабилизованный оборудование.
[03:18:42.180 --> 03:18:45.180]  Во-первых, мы сегментировали
[03:18:45.180 --> 03:18:47.180]  оборудование с сейсовидной температурой,
[03:18:47.180 --> 03:18:50.180]  дириженной от сателлита,
[03:18:50.180 --> 03:18:53.180]  чтобы изменить оборудование в регионах оборудования.
[03:18:53.180 --> 03:18:57.180]  Потом мы нашли оборудование в временах
[03:18:57.180 --> 03:19:00.180]  стабилизации и, наконец,
[03:19:00.180 --> 03:19:03.180]  мы нашли короткий оборудование
[03:19:03.180 --> 03:19:06.180]  в этих временах.
[03:19:06.180 --> 03:19:13.180]  Первый метод и модель для сегментирования
[03:19:13.180 --> 03:19:16.180]  мы разработали несколько лет назад
[03:19:16.180 --> 03:19:19.180]  с самым оборудованным оборудованием кластера.
[03:19:19.180 --> 03:19:23.180]  Благодаря предпочтению СССР,
[03:19:23.180 --> 03:19:27.180]  мы измерили температурные значения Aij
[03:19:27.180 --> 03:19:29.180]  на каждом пикселе ij,
[03:19:29.180 --> 03:19:32.180]  мы рассмотрели модель
[03:19:32.180 --> 03:19:36.180]  по следованию модели оборудования кластера
[03:19:36.180 --> 03:19:42.180]  в 1999-1996 году,
[03:19:42.180 --> 03:19:44.180]  в таком смысле,
[03:19:44.180 --> 03:19:47.180]  что каждый оборудованный температурный значение
[03:19:47.180 --> 03:19:49.180]  может быть оборудованным,
[03:19:49.180 --> 03:19:52.180]  как продукт оборудования кластерной интенсивности
[03:19:52.180 --> 03:19:56.180]  и кластерной membership ij,
[03:19:56.180 --> 03:20:00.180]  плюс резидуальный значение ij.
[03:20:00.180 --> 03:20:03.180]  Чтобы оптимизировать этот модель,
[03:20:03.180 --> 03:20:06.180]  мы рассмотрели критерию оборудования кластера
[03:20:06.180 --> 03:20:14.180]  по следованию модели оборудования кластерной интенсивности
[03:20:14.180 --> 03:20:19.180]  и кластерной membership ij.
[03:20:19.180 --> 03:20:22.180]  И мы легко можем определить,
[03:20:22.180 --> 03:20:25.180]  что интенсивности будут ничего другого
[03:20:25.180 --> 03:20:28.180]  чем температуры оборудования кластера
[03:20:28.180 --> 03:20:31.180]  по следованию пикселей.
[03:20:31.180 --> 03:20:34.180]  Я не имею времени идти в детали
[03:20:34.180 --> 03:20:36.180]  о дитературе,
[03:20:36.180 --> 03:20:40.180]  мы оборудовали этот мета-модель,
[03:20:40.180 --> 03:20:42.180]  но мы можем сказать,
[03:20:42.180 --> 03:20:45.180]  что самодельная самодельная алгоритмка
[03:20:45.180 --> 03:20:48.180]  встанет от популярности,
[03:20:48.180 --> 03:20:52.180]  в росте оборудования кластера
[03:20:52.180 --> 03:20:56.180]  по следованию оборудования кластера.
[03:20:56.180 --> 03:21:00.180]  Кластерное критерии берут формат продукта
[03:21:00.180 --> 03:21:06.180]  по повседневной molta разд瑰ли в несколько моментов.
[03:21:08.180 --> 03:21:11.180]  Ferrari-баз discomfort
[03:21:11.180 --> 03:21:13.180] adhaptivity
[03:21:13.180 --> 03:21:15.180]  outfit
[03:21:15.180 --> 03:21:17.180]  Cluster
[03:21:17.180 --> 03:21:20.820] ell
[03:21:20.820 --> 03:21:22.180]  Cluster
[03:21:22.180 --> 03:21:23.180]  и
[03:21:23.180 --> 03:21:28.180]  Так что в этих фиграх мы можем увидеть, что мы проявляем
[03:21:28.180 --> 03:21:33.180]  то, как мы получаем результаты сегментации с алгоритмом СТСЕКС.
[03:21:33.180 --> 03:21:38.180]  В случае Португалии, где у нас на левой стороне
[03:21:38.180 --> 03:21:41.180]  образ с температурой СССР.
[03:21:41.180 --> 03:21:46.180]  В середине этого образа, после предпочтения стажа,
[03:21:46.180 --> 03:21:51.180]  мы проявляем зону оборудования моря
[03:21:51.180 --> 03:21:54.180]  и на правой стороне бинарный метод,
[03:21:54.180 --> 03:21:57.180]  полученный с алгоритмом СТСЕКС,
[03:21:57.180 --> 03:22:02.180]  где оборудование зоны оборудовано зелёным.
[03:22:02.180 --> 03:22:05.180]  И ещё один пример,
[03:22:05.180 --> 03:22:12.180]  когда мы проявляем зону Атлантического океана Норвегии.
[03:22:13.180 --> 03:22:18.180]  На втором этаже мы хотим найти временные рейтинги,
[03:22:18.180 --> 03:22:22.180]  в течение СССР.
[03:22:22.180 --> 03:22:25.180]  Так что, в действительности, оборудование не постепенно
[03:22:25.180 --> 03:22:28.180]  развивается через время, но вместо этого
[03:22:28.180 --> 03:22:31.180]  оно проявляет несколько раз сегменты,
[03:22:31.180 --> 03:22:34.180]  в которых оборудование показывает подобные поведения.
[03:22:34.180 --> 03:22:38.180]  Чтобы осуществить это, мы начали вытягивать 4 функции
[03:22:38.180 --> 03:22:42.180]  из сегментов СТСЕКСа.
[03:22:42.180 --> 03:22:45.180]  Тоталонная часть оборудования,
[03:22:45.180 --> 03:22:49.180]  оборудование температуры на оборудовании,
[03:22:49.180 --> 03:22:54.180]  максимум и минимум литературы оборудования.
[03:22:54.180 --> 03:23:00.180]  И с этим мы хотим вытягивать последующие СССР.
[03:23:01.180 --> 03:23:04.180]  Для этого мы адаптируем
[03:23:04.180 --> 03:23:08.180]  итеративный аномалистический партнер-агритм,
[03:23:08.180 --> 03:23:11.180]  пропущенный Миркин,
[03:23:11.180 --> 03:23:14.180]  в первую очередь как интеллигентная
[03:23:14.180 --> 03:23:19.180]  инициализация для популярного киминального алгоритма.
[03:23:19.180 --> 03:23:22.180]  Итеративный аномалистический партнер-агритм
[03:23:22.180 --> 03:23:25.180]  секвенционно вытягивает кластеры один за одним
[03:23:25.180 --> 03:23:29.180]  и позволяет моделировать количество кластеров
[03:23:29.180 --> 03:23:31.180]  в неисправной форме.
[03:23:31.180 --> 03:23:35.180]  В нашем случае мы исследовали этот алгоритм
[03:23:35.180 --> 03:23:38.180]  для неисправной сегментации СТСЕКС,
[03:23:38.180 --> 03:23:41.180]  и так мы использовали EAP,
[03:23:41.180 --> 03:23:44.180]  используя 4 функции,
[03:23:44.180 --> 03:23:49.180]  вытягивающие из сегментов СТСЕКС,
[03:23:49.180 --> 03:23:52.180]  и вытягивающие автоматически
[03:23:52.180 --> 03:23:54.180]  в неисправной форме
[03:23:54.180 --> 03:23:57.180]  моделировавшуюся стоп-кондицион,
[03:23:57.180 --> 03:24:01.180]  количество времени.
[03:24:01.180 --> 03:24:05.180]  В этой таблице мы проявили
[03:24:05.180 --> 03:24:08.180]  проявление времени
[03:24:08.180 --> 03:24:13.180]  на три независимых сезона Португалии.
[03:24:13.180 --> 03:24:16.180]  И это очень интересно,
[03:24:16.180 --> 03:24:19.180]  потому что количество времени
[03:24:19.180 --> 03:24:22.180]  на каждом году,
[03:24:22.180 --> 03:24:25.180]  между 3 и 5,
[03:24:25.180 --> 03:24:29.180]  для обеих коллекций СТСЕКС
[03:24:29.180 --> 03:24:32.180]  в разных регионах мира,
[03:24:32.180 --> 03:24:36.180]  Португалии и Африки.
[03:24:36.180 --> 03:24:39.180]  На последнем этапе
[03:24:39.180 --> 03:24:43.180]  мы хотим найти кластер КОР-ШЕЛ,
[03:24:43.180 --> 03:24:46.180]  чтобы представить временные рамки
[03:24:46.180 --> 03:24:50.180]  как постоянный модель Пуэлла.
[03:24:50.180 --> 03:24:54.180]  Для этого мы снова
[03:24:54.180 --> 03:24:59.180]  собираем предпроцесс ССТ-грид A
[03:24:59.180 --> 03:25:03.180]  как метрика АТ IJ
[03:25:03.180 --> 03:25:07.180]  с температурными значениями IIJT.
[03:25:07.180 --> 03:25:09.180]  Кластер КОР-ШЕЛ
[03:25:09.180 --> 03:25:12.180]  У является секвенсором
[03:25:12.180 --> 03:25:14.180]  Т-кластерных слайсов
[03:25:14.180 --> 03:25:16.180]  R union St equal 1
[03:25:16.180 --> 03:25:19.180]  до R union St equal T-капитал
[03:25:19.180 --> 03:25:21.180]  с Т-капиталом,
[03:25:21.180 --> 03:25:23.180]  previously derived from the
[03:25:23.180 --> 03:25:26.180]  Iterative Anomalous Pattern algorithm
[03:25:26.180 --> 03:25:29.180]  and with R a constant set,
[03:25:29.180 --> 03:25:32.180]  the core, and S of T a variable set,
[03:25:32.180 --> 03:25:35.180]  the shell at each moment T,
[03:25:35.180 --> 03:25:37.180]  not overlapping R.
[03:25:37.180 --> 03:25:40.180]  So a core-shell cluster slice
[03:25:40.180 --> 03:25:43.180]  is represented by two non-overlapping sets,
[03:25:43.180 --> 03:25:46.180]  R union S of T,
[03:25:46.180 --> 03:25:49.180]  with binary values R IJ,
[03:25:49.180 --> 03:25:51.180]  belonging to the core,
[03:25:51.180 --> 03:25:54.180]  and S IJ of T belonging to the shell,
[03:25:54.180 --> 03:25:58.180]  such that their product is equal to zero.
[03:25:59.180 --> 03:26:03.180]  The model to represent an upwelling SST
[03:26:03.180 --> 03:26:06.180]  at pixel IJ and moment T
[03:26:06.180 --> 03:26:09.180]  is approximated by the sum
[03:26:09.180 --> 03:26:12.180]  of the pixels belonging to the core
[03:26:12.180 --> 03:26:15.180]  plus the pixels belonging to the shell
[03:26:15.180 --> 03:26:19.180]  weighted by values
[03:26:19.180 --> 03:26:22.180]  that correspond to the intensities
[03:26:22.180 --> 03:26:25.180]  of the core and of the shells
[03:26:25.180 --> 03:26:28.180]  and are to be found
[03:26:28.180 --> 03:26:32.180]  plus a small residual value E IJ.
[03:26:32.180 --> 03:26:35.180]  Again, the residual values
[03:26:35.180 --> 03:26:38.180]  are minimized according to the least squares
[03:26:38.180 --> 03:26:40.180]  clustering criterion,
[03:26:40.180 --> 03:26:43.180]  defined by this equation 6,
[03:26:43.180 --> 03:26:46.180]  and it's not difficult to derive
[03:26:46.180 --> 03:26:49.180]  that the first order minimality conditions
[03:26:49.180 --> 03:26:51.180]  of this function delta,
[03:26:51.180 --> 03:26:54.180]  the clustering criterion at moment T,
[03:26:54.180 --> 03:26:57.180]  lead to intensity values
[03:26:57.180 --> 03:27:00.180]  for the core and the shells
[03:27:00.180 --> 03:27:03.180]  that lambda and lambda plus mu,
[03:27:03.180 --> 03:27:05.180]  that are nothing else
[03:27:05.180 --> 03:27:08.180]  than the mean temperatures
[03:27:08.180 --> 03:27:11.180]  of the pixels belonging to each part
[03:27:11.180 --> 03:27:14.180]  of the core shell cluster.
[03:27:15.180 --> 03:27:18.180]  Criterium delta can be rewritten
[03:27:18.180 --> 03:27:21.180]  as the difference of a portion D
[03:27:21.180 --> 03:27:24.180]  that is defined
[03:27:24.180 --> 03:27:27.180]  as the total data scatter
[03:27:27.180 --> 03:27:30.180]  and that is constant for our data,
[03:27:30.180 --> 03:27:33.180]  and G that is the core shell cluster's
[03:27:33.180 --> 03:27:36.180]  contribution to that
[03:27:36.180 --> 03:27:39.180]  and is to be maximized.
[03:27:41.180 --> 03:27:46.180]  And to maximize this portion G,
[03:27:46.180 --> 03:27:50.180]  we proposed an iterative algorithm.
[03:27:50.180 --> 03:27:53.180]  The input is a set,
[03:27:53.180 --> 03:27:56.180]  a collection of T SST grids,
[03:27:56.180 --> 03:28:00.180]  and the output is one core shell cluster
[03:28:00.180 --> 03:28:03.180]  that is a sequence of T cluster slice
[03:28:03.180 --> 03:28:06.180]  and the corresponding intensity values
[03:28:06.180 --> 03:28:10.180]  lambda of T and lambda of T plus mu of T.
[03:28:11.180 --> 03:28:15.180]  At the initialization of the algorithm,
[03:28:15.180 --> 03:28:19.180]  we run the sequential self-tuning algorithm
[03:28:19.180 --> 03:28:23.180]  over each SST grid AT
[03:28:23.180 --> 03:28:26.180]  and let C1, C2 and CT
[03:28:26.180 --> 03:28:29.180]  be the obtaining upwelling regions.
[03:28:29.180 --> 03:28:32.180]  We calculate the initial core
[03:28:32.180 --> 03:28:35.180]  as the intersection of those clusters
[03:28:35.180 --> 03:28:38.180]  and the corresponding shells,
[03:28:38.180 --> 03:28:41.180]  the set difference of the cluster
[03:28:41.180 --> 03:28:44.180]  minus the core.
[03:28:44.180 --> 03:28:47.180]  And then we define a set B
[03:28:47.180 --> 03:28:50.180]  as the union of the core and the set of the shells
[03:28:50.180 --> 03:28:53.180]  and another set F
[03:28:53.180 --> 03:28:56.180]  defined by the grid points
[03:28:56.180 --> 03:28:59.180]  forming a four-neighborhood
[03:28:59.180 --> 03:29:02.180]  with the region defined by the core
[03:29:02.180 --> 03:29:05.180]  and the collection of the shells.
[03:29:05.180 --> 03:29:08.180]  At the iterative step of the algorithm,
[03:29:08.180 --> 03:29:11.180]  for each pixel i, j belonging to set B,
[03:29:11.180 --> 03:29:14.180]  we want to define, to decide
[03:29:14.180 --> 03:29:17.180]  which scenario to take
[03:29:17.180 --> 03:29:20.180]  or to make the point i, j
[03:29:20.180 --> 03:29:23.180]  to belong to the core
[03:29:23.180 --> 03:29:26.180]  or to make i, j to belong to any of the T shells
[03:29:26.180 --> 03:29:29.180]  or to remove the point to any of them.
[03:29:29.180 --> 03:29:32.180]  And we take the option
[03:29:32.180 --> 03:29:35.180]  that makes the increase of criterion G.
[03:29:35.180 --> 03:29:38.180]  And this process operates
[03:29:38.180 --> 03:29:41.180]  until there is no improvement
[03:29:41.180 --> 03:29:44.180]  in the criterion we are maximizing.
[03:29:44.180 --> 03:29:47.180]  So in this figure
[03:29:47.180 --> 03:29:50.180]  we illustrate the structure
[03:29:50.180 --> 03:29:53.180]  of the core-shell clustering algorithm
[03:29:53.180 --> 03:29:56.180]  for an example of a time range
[03:29:56.180 --> 03:29:59.180]  for an example of a time range
[03:29:59.180 --> 03:30:02.180]  forming by five consecutive
[03:30:02.180 --> 03:30:05.180]  sea surface temperature maps
[03:30:05.180 --> 03:30:08.180]  on the top after being pre-processed.
[03:30:08.180 --> 03:30:11.180]  on the top after being pre-processed.
[03:30:11.180 --> 03:30:14.180]  In the row in the middle
[03:30:14.180 --> 03:30:17.180]  it's the result of having applied
[03:30:17.180 --> 03:30:20.180]  the STSEC algorithm
[03:30:20.180 --> 03:30:23.180]  and finding the upwelling regions
[03:30:23.180 --> 03:30:26.180]  marked in green
[03:30:26.180 --> 03:30:29.180]  and from there we defined
[03:30:29.180 --> 03:30:32.180]  the initial core-shell clustering.
[03:30:32.180 --> 03:30:35.180]  And at the end in the last row
[03:30:35.180 --> 03:30:38.180]  we can see the core-shell clustering
[03:30:38.180 --> 03:30:41.180]  result with the constant core
[03:30:41.180 --> 03:30:44.180]  highlighted in yellow
[03:30:44.180 --> 03:30:47.180]  and the dynamic part of the shells
[03:30:47.180 --> 03:30:50.180]  in green.
[03:30:50.180 --> 03:30:53.180]  So this is the entire architecture
[03:30:53.180 --> 03:30:56.180]  of this three-stage clustering.
[03:30:56.180 --> 03:30:59.180]  I'm not going into details on that.
[03:30:59.180 --> 03:31:02.180]  And now moving to analysis
[03:31:02.180 --> 03:31:05.180]  of the time series.
[03:31:05.180 --> 03:31:08.180]  So we have taken two annual collections
[03:31:08.180 --> 03:31:11.180]  of sea surface temperature reads
[03:31:11.180 --> 03:31:14.180]  derived from the satellite images
[03:31:14.180 --> 03:31:17.180]  corresponding to 16 years each 2004 to 2019
[03:31:17.180 --> 03:31:20.180]  and covering the Portuguese coast
[03:31:20.180 --> 03:31:23.180]  and the Atlantic Ocean of North Africa.
[03:31:23.180 --> 03:31:26.180]  Each SCST grid
[03:31:26.180 --> 03:31:29.180]  corresponds and is represented
[03:31:29.180 --> 03:31:32.180]  to the average of eight days
[03:31:32.180 --> 03:31:35.180]  of each.
[03:31:35.180 --> 03:31:38.180]  So first we start accessing
[03:31:38.180 --> 03:31:41.180]  the results of the core-shell clustering
[03:31:41.180 --> 03:31:44.180]  segmentations. And for that
[03:31:44.180 --> 03:31:47.180]  we are taking as ground truth
[03:31:47.180 --> 03:31:50.180]  map.
[03:31:50.180 --> 03:31:53.180]  These are the segmentations obtained
[03:31:53.180 --> 03:31:56.180]  by the self-tuning set algorithm.
[03:31:56.180 --> 03:31:59.180]  In fact, the segmentations obtained
[03:31:59.180 --> 03:32:02.180]  by this algorithm constitute reliable
[03:32:02.180 --> 03:32:05.180]  ground-tooth maps since they obtained
[03:32:05.180 --> 03:32:08.180]  very good evaluation scores
[03:32:08.180 --> 03:32:11.180]  when validated by a team of expert
[03:32:11.180 --> 03:32:14.180]  oceanographers. Even so,
[03:32:14.180 --> 03:32:17.180]  we are using the core-shell cluster
[03:32:17.180 --> 03:32:20.180]  and ST-segmentation results.
[03:32:20.180 --> 03:32:23.180]  And we obtain it for a relatively
[03:32:23.180 --> 03:32:26.180]  diverse sample of images,
[03:32:26.180 --> 03:32:29.180]  similarity scores higher or equal
[03:32:29.180 --> 03:32:32.180]  0.98 out of one.
[03:32:35.180 --> 03:32:38.180]  So to make the inter-annual time series
[03:32:38.180 --> 03:32:41.180]  analysis, we consider
[03:32:41.180 --> 03:32:44.180]  several features, the areas of the cores
[03:32:44.180 --> 03:32:47.180]  and the areas of the shells forming the core-shell
[03:32:47.180 --> 03:32:50.180]  clusters, the average temperature of each
[03:32:50.180 --> 03:32:53.180]  of these structures that are nothing
[03:32:53.180 --> 03:32:56.180]  else than the intensities deriving by the
[03:32:56.180 --> 03:32:59.180]  core-shell clustering algorithm, and
[03:32:59.180 --> 03:33:02.180]  the average temperature of the upwelling core
[03:33:02.180 --> 03:33:05.180]  against the average temperature of the offshore
[03:33:05.180 --> 03:33:08.180]  ocean waters.
[03:33:08.180 --> 03:33:11.180]  To illustrate, we show in this graphic
[03:33:11.180 --> 03:33:14.180]  the comparison of the average core
[03:33:14.180 --> 03:33:17.180]  temperatures against the temperatures of the
[03:33:17.180 --> 03:33:20.180]  offshore waters in the Portuguese coast
[03:33:20.180 --> 03:33:23.180]  for the year 2015. And interestingly,
[03:33:23.180 --> 03:33:26.180]  the maximum average temperature
[03:33:26.180 --> 03:33:29.180]  of the core occurs at the middle
[03:33:29.180 --> 03:33:32.180]  of the upwelling season, and the maximum
[03:33:32.180 --> 03:33:35.180]  temperature of the difference between
[03:33:35.180 --> 03:33:38.180]  the coastal upwelling and the offshore
[03:33:38.180 --> 03:33:41.180]  waters is very close by. We obtain
[03:33:41.180 --> 03:33:44.180]  confident results for all years, and
[03:33:44.180 --> 03:33:47.180]  this shows that the upwelling events
[03:33:47.180 --> 03:33:50.180]  tend to increase in the summer season,
[03:33:50.180 --> 03:33:53.180]  where the coastal upwelling tend to have
[03:33:53.180 --> 03:33:56.180]  its strongest activity.
[03:33:56.180 --> 03:33:59.180]  Analyzing these results in the
[03:33:59.180 --> 03:34:02.180]  inter-annual time series, we can see
[03:34:02.180 --> 03:34:05.180]  that the core temperatures are
[03:34:05.180 --> 03:34:08.180]  consistently lower than the offshore ones,
[03:34:08.180 --> 03:34:11.180]  reflecting the permanent upwelling
[03:34:11.180 --> 03:34:14.180]  regions close to the coast and captured
[03:34:14.180 --> 03:34:17.180]  by the analyses of the core structures.
[03:34:17.180 --> 03:34:20.180]  On the other hand, the annual cycle
[03:34:20.180 --> 03:34:23.180]  of SES-T is observed both in the
[03:34:23.180 --> 03:34:26.180]  cores and the offshores, but the differences
[03:34:26.180 --> 03:34:29.180]  between the core and the offshore
[03:34:29.180 --> 03:34:32.180]  temperatures are stronger again during
[03:34:32.180 --> 03:34:35.180]  the summer months, that correspond in fact
[03:34:35.180 --> 03:34:38.180]  to the peak of the upwelling and is
[03:34:38.180 --> 03:34:41.180]  consistent with the upwelling regime.
[03:34:41.180 --> 03:34:45.180]  Looking at the areas of the cores,
[03:34:45.180 --> 03:34:48.180]  the shells, and the core-shell cluster
[03:34:48.180 --> 03:34:51.180]  against the areas of the whole upwelling
[03:34:51.180 --> 03:34:54.180]  regions obtained by the self-tuning
[03:34:54.180 --> 03:34:57.180]  SEC, we again see that the core
[03:34:57.180 --> 03:35:00.180]  are constant structures along each
[03:35:00.180 --> 03:35:03.180]  of the four upwelling time ranges
[03:35:03.180 --> 03:35:06.180]  previously determined, that in here are
[03:35:06.180 --> 03:35:09.180]  in the number of four in the orange line,
[03:35:09.180 --> 03:35:12.180]  and the shells in the green line
[03:35:12.180 --> 03:35:15.180]  correspond to the evolving spatial
[03:35:15.180 --> 03:35:18.180]  pattern of each of the four upwelling
[03:35:18.180 --> 03:35:21.180]  regions obtained by the self-tuning
[03:35:21.180 --> 03:35:24.180]  SEC.
[03:35:24.180 --> 03:35:27.180]  This results in the evolving spatial
[03:35:27.180 --> 03:35:30.180]  pattern strongly concordant with the
[03:35:30.180 --> 03:35:33.180]  evolving areas of the whole upwelling
[03:35:33.180 --> 03:35:36.180]  region of the original ST-SEC
[03:35:36.180 --> 03:35:39.180]  Aldweed.
[03:35:39.180 --> 03:35:42.180]  Now looking at the entire picture
[03:35:42.180 --> 03:35:45.180]  of the inter-annual time series,
[03:35:45.180 --> 03:35:48.180]  we can, along the 16 years, we can see
[03:35:48.180 --> 03:35:51.180]  that the coastal areas occupied by the
[03:35:51.180 --> 03:35:54.180]  coastal upwelling authors have been
[03:35:54.180 --> 03:35:57.180]  increasing along those 16 years under
[03:35:57.180 --> 03:36:00.180]  analysis, and the increased extent
[03:36:00.180 --> 03:36:03.180]  of the surface signal of the upwelling
[03:36:03.180 --> 03:36:06.180]  is in fact the manifestation of an
[03:36:06.180 --> 03:36:09.180]  increase of the upwelling intensity
[03:36:09.180 --> 03:36:12.180]  and or the increase of the
[03:36:12.180 --> 03:36:15.180]  cyclonic wind stress curve along the
[03:36:15.180 --> 03:36:18.180]  coast.
[03:36:18.180 --> 03:36:21.180]  As a conclusion, a novel approach for
[03:36:21.180 --> 03:36:24.180]  the automatic recognition of spatial
[03:36:24.180 --> 03:36:27.180]  temporal analysis of coastal upwelling is
[03:36:27.180 --> 03:36:30.180]  proposed. It consists of a three-stage
[03:36:30.180 --> 03:36:33.180]  clustering based on Mirkin's data
[03:36:33.180 --> 03:36:36.180]  recovering approach, the ST-SEC
[03:36:36.180 --> 03:36:39.180]  clustering to segment the
[03:36:39.180 --> 03:36:42.180]  upwelling grids at each
[03:36:42.180 --> 03:36:45.180]  image, the iterative anomalous
[03:36:45.180 --> 03:36:48.180]  pattern for an unsupervised
[03:36:48.180 --> 03:36:51.180]  segmentation of the time series to find
[03:36:51.180 --> 03:36:54.180]  time ranges, the core shell clustering
[03:36:54.180 --> 03:36:57.180]  to determine the piecewise constant model
[03:36:57.180 --> 03:37:00.180]  of the upwelling within those time
[03:37:00.180 --> 03:37:03.180]  ranges. So these three clustering
[03:37:03.180 --> 03:37:06.180]  models stand on the least squares
[03:37:06.180 --> 03:37:09.180]  minimization of the corresponding
[03:37:09.180 --> 03:37:12.180]  clustering criterion and allow to derive
[03:37:12.180 --> 03:37:15.180]  key parameters of the models in an
[03:37:15.180 --> 03:37:18.180]  automated way.
[03:37:18.180 --> 03:37:21.180]  We have applied this framework to
[03:37:21.180 --> 03:37:24.180]  real-world sea surface temperature data
[03:37:24.180 --> 03:37:27.180]  covering two distinct regions of the
[03:37:27.180 --> 03:37:30.180]  world, and the time series of the
[03:37:30.180 --> 03:37:33.180]  upwelling features present consistent
[03:37:33.180 --> 03:37:36.180]  regularities among several independent
[03:37:36.180 --> 03:37:39.180]  upwelling seasons as validated by the
[03:37:39.180 --> 03:37:42.180]  data recovery paradigm.
[03:37:42.180 --> 03:37:45.180]  So, and I should say
[03:37:45.180 --> 03:37:48.180]  thank you very much, Boris,
[03:37:48.180 --> 03:37:51.180]  for having introduced me and my
[03:37:51.180 --> 03:37:54.180]  colleagues here in Portugal to the
[03:37:54.180 --> 03:37:57.180]  clustering within the data recovery
[03:37:57.180 --> 03:38:00.180]  paradigm. Okay, thank you very much for
[03:38:00.180 --> 03:38:03.180]  your attention.
[03:38:03.180 --> 03:38:06.180]  Any questions?
[03:38:07.180 --> 03:38:10.180]  We have a...
[03:38:10.180 --> 03:38:13.180]  Just curious, how is this data
[03:38:13.180 --> 03:38:16.180]  further used?
[03:38:16.180 --> 03:38:19.180]  What are the results later on?
[03:38:19.180 --> 03:38:22.180]  This is like very massive research.
[03:38:26.180 --> 03:38:29.180]  Она, по-моему, не слышит.
[03:38:32.180 --> 03:38:35.180]  Так что, Борис Григорьевич,
[03:38:35.180 --> 03:38:38.180]  поблагодарите ее за замечательный
[03:38:38.180 --> 03:38:41.180]  доклад,
[03:38:41.180 --> 03:38:44.180]  потому что, ну, мы ничего не можем
[03:38:44.180 --> 03:38:47.180]  сделать.
[03:38:47.180 --> 03:38:50.180]  And I'm announcing the next speaker
[03:38:50.180 --> 03:38:53.180]  is
[03:38:53.180 --> 03:38:56.180]  Dr. Frollo.
[03:38:56.180 --> 03:38:59.180]  Hello, everyone. My name is
[03:38:59.180 --> 03:39:02.180]  Dmitry, and I would like to
[03:39:02.180 --> 03:39:05.180]  present your three-step method for
[03:39:05.180 --> 03:39:08.180]  audience extension in Internet
[03:39:08.180 --> 03:39:11.180]  advertising using an industrial
[03:39:11.180 --> 03:39:14.180]  technology. The work was prepared
[03:39:14.180 --> 03:39:17.180]  by Dmitry Frollo, who is the
[03:39:17.180 --> 03:39:20.180]  presenter, and Zina Taran.
[03:39:20.180 --> 03:39:23.180]  The affiliations are, for me,
[03:39:23.180 --> 03:39:26.180]  HSV University,
[03:39:26.180 --> 03:39:29.180]  during the work
[03:39:29.180 --> 03:39:32.180]  on this
[03:39:32.180 --> 03:39:35.180]  direction.
[03:39:35.180 --> 03:39:38.180]  First of all, I will
[03:39:38.180 --> 03:39:41.180]  touch
[03:39:41.180 --> 03:39:44.180]  programmatic digital advertising
[03:39:44.180 --> 03:39:47.180]  overall. We will briefly
[03:39:47.180 --> 03:39:50.180]  describe targeting strategies
[03:39:50.180 --> 03:39:53.180]  and insufficient audience
[03:39:53.180 --> 03:39:56.180]  problem. After that, move to
[03:39:56.180 --> 03:39:59.180]  generalization and our method
[03:39:59.180 --> 03:40:02.180]  to work with this issue
[03:40:02.180 --> 03:40:05.180]  and describe our LUSP
[03:40:05.180 --> 03:40:08.180]  method for audience extension.
[03:40:08.180 --> 03:40:11.180]  After that, we will conclude the results.
[03:40:11.180 --> 03:40:14.180]  First of all, I
[03:40:14.180 --> 03:40:17.180]  would like to tell a bit about
[03:40:17.180 --> 03:40:20.180]  programmatic digital advertising.
[03:40:20.180 --> 03:40:23.180]  Now they see the common
[03:40:23.180 --> 03:40:26.180]  tendency of moving advertising
[03:40:26.180 --> 03:40:29.180]  from conventional formats such as
[03:40:29.180 --> 03:40:32.180]  TV, radio and others to the
[03:40:32.180 --> 03:40:35.180]  Internet, because this new
[03:40:35.180 --> 03:40:38.180]  way allows
[03:40:38.180 --> 03:40:41.180]  to have a lot of
[03:40:41.180 --> 03:40:44.180]  advantages. First of all,
[03:40:44.180 --> 03:40:47.180]  investigate potential audience
[03:40:47.180 --> 03:40:50.180]  way better, create and control
[03:40:50.180 --> 03:40:53.180]  the results,
[03:40:53.180 --> 03:40:56.180]  because, for example, if you
[03:40:56.180 --> 03:40:59.180]  consider TV advertising,
[03:40:59.180 --> 03:41:02.180]  we have
[03:41:02.180 --> 03:41:05.180]  a well-known issue
[03:41:05.180 --> 03:41:08.180]  with controllability of this.
[03:41:08.180 --> 03:41:11.180]  It's quite hard to
[03:41:11.180 --> 03:41:14.180]  evaluate the results
[03:41:14.180 --> 03:41:17.180]  of advertising, especially for small
[03:41:17.180 --> 03:41:20.180]  audiences.
[03:41:20.180 --> 03:41:23.180]  Programmatic is one of the most
[03:41:23.180 --> 03:41:26.180]  popular modern approaches
[03:41:26.180 --> 03:41:29.180]  based on buying user
[03:41:29.180 --> 03:41:32.180]  contacts in a real-time auction
[03:41:32.180 --> 03:41:35.180]  instead of buying some
[03:41:35.180 --> 03:41:38.180]  places somewhere.
[03:41:38.180 --> 03:41:41.180]  RDB, that is real-time bidding,
[03:41:41.180 --> 03:41:44.180]  is a common
[03:41:44.180 --> 03:41:47.180]  technique to implement this approach,
[03:41:47.180 --> 03:41:50.180]  and it's based on
[03:41:50.180 --> 03:41:53.180]  buying contacts with
[03:41:53.180 --> 03:41:56.180]  users. Say, I have
[03:41:56.180 --> 03:41:59.180]  a user visiting some site,
[03:41:59.180 --> 03:42:02.180]  I can buy the opportunity to show
[03:42:02.180 --> 03:42:05.180]  something to this user,
[03:42:05.180 --> 03:42:08.180]  and typically to describe
[03:42:08.180 --> 03:42:11.180]  users and segments
[03:42:11.180 --> 03:42:14.180]  we have
[03:42:14.180 --> 03:42:17.180]  user segments
[03:42:17.180 --> 03:42:20.180]  that are user interests
[03:42:20.180 --> 03:42:23.180]  determined from the
[03:42:23.180 --> 03:42:26.180]  information that we know about
[03:42:26.180 --> 03:42:29.180]  the user, such as visited websites,
[03:42:29.180 --> 03:42:32.180]  open pages,
[03:42:32.180 --> 03:42:35.180]  rich history and similar
[03:42:35.180 --> 03:42:38.180]  things. And the same we have
[03:42:38.180 --> 03:42:41.180]  for advertising campaigns,
[03:42:41.180 --> 03:42:44.180]  they also can be described in terms of
[03:42:44.180 --> 03:42:47.180]  segments.
[03:42:47.180 --> 03:42:50.180]  Overall,
[03:42:50.180 --> 03:42:53.180]  these things
[03:42:53.180 --> 03:42:56.180]  can be referred as users
[03:42:56.180 --> 03:42:59.180]  profiles. For example, here you can see one
[03:42:59.180 --> 03:43:02.180]  such small profile
[03:43:02.180 --> 03:43:05.180]  of a car's owner and businessman.
[03:43:05.180 --> 03:43:08.180]  So,
[03:43:08.180 --> 03:43:11.180]  there are also
[03:43:11.180 --> 03:43:14.180]  common well-known issues with this
[03:43:14.180 --> 03:43:17.180]  approach.
[03:43:17.180 --> 03:43:20.180]  First of all,
[03:43:20.180 --> 03:43:23.180]  this is insufficient
[03:43:23.180 --> 03:43:26.180]  information about the user.
[03:43:26.180 --> 03:43:29.180]  When it's difficult to
[03:43:29.180 --> 03:43:32.180]  make decisions,
[03:43:32.180 --> 03:43:35.180]  how should we show something to this user
[03:43:35.180 --> 03:43:38.180]  or not?
[03:43:38.180 --> 03:43:41.180]  The reason for that can be, for example,
[03:43:41.180 --> 03:43:44.180]  we have only
[03:43:44.180 --> 03:43:47.180]  restricted access to the user history.
[03:43:47.180 --> 03:43:50.180]  For example, one page in
[03:43:50.180 --> 03:43:53.180]  his history of
[03:43:53.180 --> 03:43:56.180]  visits in the Internet, and of course it's very
[03:43:56.180 --> 03:43:59.180]  hard to analyze user interests
[03:43:59.180 --> 03:44:02.180]  and all that. The second thing is
[03:44:02.180 --> 03:44:05.180]  extremely large volumes of data,
[03:44:05.180 --> 03:44:08.180]  and this is especially
[03:44:08.180 --> 03:44:11.180]  important for small
[03:44:11.180 --> 03:44:14.180]  technological companies. Sometimes
[03:44:14.180 --> 03:44:17.180]  instead of analyzing
[03:44:17.180 --> 03:44:20.180]  the content of a web page,
[03:44:20.180 --> 03:44:23.180]  companies analyze only
[03:44:23.180 --> 03:44:26.180]  the URL of the page,
[03:44:26.180 --> 03:44:29.180]  and of course it's very hard
[03:44:29.180 --> 03:44:32.180]  to analyze each
[03:44:32.180 --> 03:44:35.180]  individual page.
[03:44:35.180 --> 03:44:38.180]  And due to that, of course,
[03:44:38.180 --> 03:44:41.180]  we can have
[03:44:41.180 --> 03:44:44.180]  issues with
[03:44:44.180 --> 03:44:47.180]  quality of such kind of analysis.
[03:44:47.180 --> 03:44:50.180]  Also,
[03:44:50.180 --> 03:44:53.180]  the next thing is technical problems
[03:44:53.180 --> 03:44:56.180]  with bidders.
[03:44:56.180 --> 03:44:59.180]  It's very important to
[03:44:59.180 --> 03:45:02.180]  respond quickly, because
[03:45:02.180 --> 03:45:05.180]  the time when the user
[03:45:05.180 --> 03:45:08.180]  is taking a look at the web page
[03:45:08.180 --> 03:45:11.180]  is very limited, and
[03:45:11.180 --> 03:45:14.180]  we should make
[03:45:14.180 --> 03:45:17.180]  the bids, and we should make
[03:45:17.180 --> 03:45:20.180]  decisions very quickly, as fast as possible.
[03:45:20.180 --> 03:45:23.180]  Typically, the common limit
[03:45:23.180 --> 03:45:26.180]  for client-server interaction
[03:45:26.180 --> 03:45:29.180]  in these cases is
[03:45:29.180 --> 03:45:32.180]  100 milliseconds. That means that
[03:45:32.180 --> 03:45:35.180]  all the bidders behind
[03:45:35.180 --> 03:45:38.180]  the hood for
[03:45:38.180 --> 03:45:41.180]  auction systems should communicate and respond
[03:45:41.180 --> 03:45:44.180]  in just 100 milliseconds.
[03:45:44.180 --> 03:45:47.180]  Also, the important problem is bots
[03:45:47.180 --> 03:45:50.180]  graphics. This is
[03:45:50.180 --> 03:45:53.180]  a continuing fight of defense
[03:45:53.180 --> 03:45:56.180]  and attack, and
[03:45:56.180 --> 03:45:59.180]  there is a chance to pay for bots
[03:45:59.180 --> 03:46:02.180]  instead of real users, and
[03:46:02.180 --> 03:46:05.180]  companies
[03:46:05.180 --> 03:46:08.180]  make many attempts
[03:46:08.180 --> 03:46:11.180]  to develop
[03:46:11.180 --> 03:46:14.180]  techniques how to defeat this problem.
[03:46:14.180 --> 03:46:17.180]  The issue
[03:46:17.180 --> 03:46:20.180]  that I would like to emphasize is
[03:46:20.180 --> 03:46:23.180]  insufficient audience for some campaigns.
[03:46:23.180 --> 03:46:26.180]  This is especially important for
[03:46:26.180 --> 03:46:29.180]  small technological companies,
[03:46:29.180 --> 03:46:32.180]  and I had some experience of
[03:46:32.180 --> 03:46:35.180]  working in such a company,
[03:46:35.180 --> 03:46:38.180]  and for some companies
[03:46:38.180 --> 03:46:41.180]  the audience size
[03:46:41.180 --> 03:46:44.180]  defined by initial segments
[03:46:44.180 --> 03:46:47.180]  and initial user profiles is extremely
[03:46:47.180 --> 03:46:50.180]  small. That means that if
[03:46:50.180 --> 03:46:53.180]  they have a company that would like
[03:46:53.180 --> 03:46:56.180]  to buy advertising,
[03:46:56.180 --> 03:46:59.180]  in some cases
[03:46:59.180 --> 03:47:02.180]  such companies are just
[03:47:02.180 --> 03:47:05.180]  unavailable to cover these requirements,
[03:47:05.180 --> 03:47:08.180]  to provide a sufficient amount
[03:47:08.180 --> 03:47:11.180]  for users who
[03:47:11.180 --> 03:47:14.180]  see the
[03:47:14.180 --> 03:47:17.180]  advertisements and make some actions,
[03:47:17.180 --> 03:47:20.180]  like
[03:47:20.180 --> 03:47:23.180]  go to a website by
[03:47:23.180 --> 03:47:26.180]  a click on advertising and
[03:47:26.180 --> 03:47:29.180]  things like that.
[03:47:29.180 --> 03:47:32.180]  Let me briefly
[03:47:32.180 --> 03:47:35.180]  describe common techniques
[03:47:35.180 --> 03:47:38.180]  targeting in
[03:47:38.180 --> 03:47:41.180]  programmatic, typically
[03:47:41.180 --> 03:47:44.180]  conventional approach.
[03:47:44.180 --> 03:47:47.180]  I will
[03:47:47.180 --> 03:47:50.180]  name it
[03:47:50.180 --> 03:47:53.180]  CAS.
[03:47:53.180 --> 03:47:56.180]  This is conventional selection
[03:47:56.180 --> 03:47:59.180]  of a targeted audience,
[03:47:59.180 --> 03:48:02.180]  and the rule is
[03:48:02.180 --> 03:48:05.180]  for a given set of segments
[03:48:05.180 --> 03:48:08.180]  provided by advertiser and user
[03:48:08.180 --> 03:48:11.180]  profile. Just check
[03:48:11.180 --> 03:48:14.180]  the profile has one or more
[03:48:14.180 --> 03:48:17.180]  of advertisers' marketing segments.
[03:48:17.180 --> 03:48:20.180]  So typically we
[03:48:20.180 --> 03:48:23.180]  pre-specify some threshold,
[03:48:23.180 --> 03:48:26.180]  some value, and
[03:48:26.180 --> 03:48:29.180]  the user is
[03:48:29.180 --> 03:48:32.180]  selected as a part of target audience
[03:48:32.180 --> 03:48:35.180]  if at least one of these segments
[03:48:35.180 --> 03:48:38.180]  has weights greater than
[03:48:38.180 --> 03:48:41.180]  T, according to
[03:48:41.180 --> 03:48:44.180]  this CAS
[03:48:44.180 --> 03:48:47.180]  rule. And this is pretty
[03:48:47.180 --> 03:48:50.180]  straightforward
[03:48:50.180 --> 03:48:53.180]  technique. It requires, of course, that
[03:48:53.180 --> 03:48:56.180]  we should pre-specify
[03:48:56.180 --> 03:48:59.180]  user and derive
[03:48:59.180 --> 03:49:02.180]  user segments for user
[03:49:02.180 --> 03:49:05.180]  and obtain
[03:49:05.180 --> 03:49:08.180]  belongings values for audience.
[03:49:08.180 --> 03:49:11.180]  And the
[03:49:11.180 --> 03:49:14.180]  issue here, of course, is small audience
[03:49:14.180 --> 03:49:17.180]  and the
[03:49:17.180 --> 03:49:20.180]  limited
[03:49:20.180 --> 03:49:23.180]  opportunity to control the
[03:49:23.180 --> 03:49:26.180]  size of the audience.
[03:49:26.180 --> 03:49:29.180]  And the common way that can be used here is
[03:49:29.180 --> 03:49:32.180]  just to lessen the
[03:49:32.180 --> 03:49:35.180]  belongingness value, of course.
[03:49:35.180 --> 03:49:38.180]  So we will definitely get more users
[03:49:38.180 --> 03:49:41.180]  than initially, but of course
[03:49:41.180 --> 03:49:44.180]  the quality of this new audience
[03:49:44.180 --> 03:49:47.180]  can be significantly
[03:49:47.180 --> 03:49:50.180]  lower than
[03:49:50.180 --> 03:49:53.180]  quality of initial audience.
[03:49:53.180 --> 03:49:56.180]  And the question here
[03:49:56.180 --> 03:49:59.180]  is maybe we can invent more
[03:49:59.180 --> 03:50:02.180]  efficient solution with these
[03:50:02.180 --> 03:50:05.180]  segments. And
[03:50:05.180 --> 03:50:08.180]  yes, we can. The idea
[03:50:08.180 --> 03:50:11.180]  is to use industrial taxonomy
[03:50:11.180 --> 03:50:14.180]  and I
[03:50:14.180 --> 03:50:17.180]  will describe here
[03:50:17.180 --> 03:50:20.180]  the most famous IAB
[03:50:20.180 --> 03:50:23.180]  content taxonomy.
[03:50:23.180 --> 03:50:26.180]  IAB is Internet Advertising Bureau.
[03:50:26.180 --> 03:50:29.180]  This is a worldwide
[03:50:29.180 --> 03:50:32.180]  organization that
[03:50:32.180 --> 03:50:35.180]  specifies and supports
[03:50:35.180 --> 03:50:38.180]  standards and protocols
[03:50:38.180 --> 03:50:41.180]  in the area of internet advertising.
[03:50:41.180 --> 03:50:44.180]  And they have
[03:50:44.180 --> 03:50:47.180]  their own user interest
[03:50:47.180 --> 03:50:50.180]  taxonomy that contains
[03:50:50.180 --> 03:50:53.180]  more than 1000 different segments
[03:50:53.180 --> 03:50:56.180]  arranged in the taxonomy tree.
[03:50:56.180 --> 03:50:59.180]  And the idea
[03:50:59.180 --> 03:51:02.180]  of our approach is to
[03:51:02.180 --> 03:51:05.180]  generalize low-level user
[03:51:05.180 --> 03:51:08.180]  segments to get
[03:51:08.180 --> 03:51:11.180]  accurate, this is very important, high-level
[03:51:11.180 --> 03:51:14.180]  user segments and use them for
[03:51:14.180 --> 03:51:17.180]  targeting.
[03:51:17.180 --> 03:51:20.180]  So the idea
[03:51:20.180 --> 03:51:23.180]  I will describe here
[03:51:23.180 --> 03:51:26.180]  the core thing is generalization
[03:51:26.180 --> 03:51:29.180]  of user segments.
[03:51:29.180 --> 03:51:32.180]  So in this context we
[03:51:32.180 --> 03:51:35.180]  defined generalization as
[03:51:35.180 --> 03:51:38.180]  appropriate lifting of topics
[03:51:38.180 --> 03:51:41.180]  and here you can see a small
[03:51:41.180 --> 03:51:44.180]  example, say we have the
[03:51:44.180 --> 03:51:47.180]  initial set A1,
[03:51:47.180 --> 03:51:50.180]  A2, A3, A4 and B1
[03:51:50.180 --> 03:51:53.180]  and we can lift this
[03:51:53.180 --> 03:51:56.180]  initial set of
[03:51:56.180 --> 03:51:59.180]  list to higher
[03:51:59.180 --> 03:52:02.180]  rank node A and in
[03:52:02.180 --> 03:52:05.180]  this case B1 will be
[03:52:05.180 --> 03:52:08.180]  regarded as offshoot.
[03:52:08.180 --> 03:52:11.180]  And let us take a look
[03:52:11.180 --> 03:52:14.180]  at this approach more closely.
[03:52:14.180 --> 03:52:17.180]  We can
[03:52:17.180 --> 03:52:20.180]  have different alternatives when we
[03:52:20.180 --> 03:52:23.180]  consider generalization and
[03:52:23.180 --> 03:52:26.180]  say we have
[03:52:26.180 --> 03:52:29.180]  one more example, here you can see
[03:52:29.180 --> 03:52:32.180]  the leaves that
[03:52:32.180 --> 03:52:35.180]  colored as black
[03:52:35.180 --> 03:52:38.180]  and the
[03:52:38.180 --> 03:52:41.180]  option to
[03:52:41.180 --> 03:52:44.180]  lift in this
[03:52:44.180 --> 03:52:47.180]  segment of taxonomy 3 is
[03:52:47.180 --> 03:52:50.180]  to lift the initial
[03:52:50.180 --> 03:52:53.180]  set, these nodes,
[03:52:53.180 --> 03:52:56.180]  to the root of the tree,
[03:52:56.180 --> 03:52:59.180]  to the head subject A.
[03:52:59.180 --> 03:53:02.180]  And in that case we will
[03:53:02.180 --> 03:53:05.180]  also
[03:53:05.180 --> 03:53:08.180]  color by our head subject
[03:53:08.180 --> 03:53:11.180]  those leaves that
[03:53:11.180 --> 03:53:14.180]  will not belong to the initial
[03:53:14.180 --> 03:53:17.180]  set, but we still have them in the
[03:53:17.180 --> 03:53:20.180]  new head subject.
[03:53:20.180 --> 03:53:23.180]  This is the first option. And the second option is
[03:53:23.180 --> 03:53:26.180]  just to lift the
[03:53:26.180 --> 03:53:29.180]  initial set to the
[03:53:29.180 --> 03:53:32.180]  root of the left
[03:53:32.180 --> 03:53:35.180]  subtree and in this case
[03:53:35.180 --> 03:53:38.180]  as you see we have one gap and one
[03:53:38.180 --> 03:53:41.180]  offshoot. And how
[03:53:41.180 --> 03:53:44.180]  to decide what option
[03:53:44.180 --> 03:53:47.180]  will be better, our method is
[03:53:47.180 --> 03:53:50.180]  lift to minimize
[03:53:50.180 --> 03:53:53.180]  the penalty and
[03:53:53.180 --> 03:53:56.180]  we assign the penalty for each
[03:53:56.180 --> 03:53:59.180]  option as a weighted
[03:53:59.180 --> 03:54:02.180]  sum of number of head subjects
[03:54:02.180 --> 03:54:05.180]  plus lambda multiplied by
[03:54:05.180 --> 03:54:08.180]  number of gaps plus
[03:54:08.180 --> 03:54:11.180]  gamma multiplied by
[03:54:11.180 --> 03:54:14.180]  number of offshoots.
[03:54:14.180 --> 03:54:17.180]  And
[03:54:17.180 --> 03:54:20.180]  this algorithm
[03:54:20.180 --> 03:54:23.180]  was introduced by Boris
[03:54:23.180 --> 03:54:26.180]  Krivovich-Mirkin
[03:54:26.180 --> 03:54:29.180]  under his supervision
[03:54:29.180 --> 03:54:32.180]  in 2018
[03:54:32.180 --> 03:54:35.180]  and it was named
[03:54:35.180 --> 03:54:38.180]  ParginFS. And
[03:54:38.180 --> 03:54:41.180]  the algorithm performs
[03:54:41.180 --> 03:54:44.180]  a parsimonious generalization
[03:54:44.180 --> 03:54:47.180]  of a fuzzy leaf set
[03:54:47.180 --> 03:54:50.180]  and the output
[03:54:50.180 --> 03:54:53.180]  of this method will be the set of head
[03:54:53.180 --> 03:54:56.180]  subjects and the penalty
[03:54:56.180 --> 03:54:59.180]  function that we will have for
[03:54:59.180 --> 03:55:02.180]  objective
[03:55:02.180 --> 03:55:05.180]  function of this algorithm to minimize
[03:55:05.180 --> 03:55:08.180]  is shown here.
[03:55:08.180 --> 03:55:11.180]  So we have different values
[03:55:11.180 --> 03:55:14.180]  of penalties for gap, for offshoot
[03:55:14.180 --> 03:55:17.180]  and we have penalty equal
[03:55:17.180 --> 03:55:20.180]  to one for each head subject.
[03:55:20.180 --> 03:55:23.180]  So
[03:55:23.180 --> 03:55:26.180]  we can
[03:55:26.180 --> 03:55:29.180]  directly apply this algorithm to
[03:55:29.180 --> 03:55:32.180]  get generalizations for
[03:55:32.180 --> 03:55:35.180]  user segment profiles
[03:55:35.180 --> 03:55:38.180]  and after that use them for targeting.
[03:55:38.180 --> 03:55:41.180]  And you can see here
[03:55:41.180 --> 03:55:44.180]  some interesting examples.
[03:55:44.180 --> 03:55:47.180]  I took here
[03:55:47.180 --> 03:55:50.180]  very small
[03:55:50.180 --> 03:55:53.180]  user profiles and for the first
[03:55:53.180 --> 03:55:56.180]  example where you see
[03:55:56.180 --> 03:55:59.180]  initial segments for cloud computing,
[03:55:59.180 --> 03:56:02.180]  web development, internet for beginners,
[03:56:02.180 --> 03:56:05.180]  IT and internet support, social networking.
[03:56:05.180 --> 03:56:08.180]  You can generalize all of these
[03:56:08.180 --> 03:56:11.180]  and the second example is also quite
[03:56:11.180 --> 03:56:14.180]  interesting. We see here
[03:56:14.180 --> 03:56:17.180]  lens jewelry and watches,
[03:56:17.180 --> 03:56:20.180]  lens businesswear, lens casualwear,
[03:56:20.180 --> 03:56:23.180]  lens autowear. We can just generalize
[03:56:23.180 --> 03:56:26.180]  all of these to lens fashion.
[03:56:26.180 --> 03:56:29.180]  And similar for the
[03:56:29.180 --> 03:56:32.180]  third example,
[03:56:32.180 --> 03:56:35.180]  here we obtained two head subjects
[03:56:35.180 --> 03:56:38.180]  and at the next
[03:56:38.180 --> 03:56:41.180]  step of our algorithm we will use
[03:56:41.180 --> 03:56:44.180]  this to define
[03:56:44.180 --> 03:56:47.180]  corresponding set of
[03:56:47.180 --> 03:56:50.180]  advertising campaigns appropriate for these users.
[03:56:50.180 --> 03:56:53.180]  So the
[03:56:53.180 --> 03:56:56.180]  three-step method will include the following.
[03:56:56.180 --> 03:56:59.180]  So initially we still have to compute
[03:56:59.180 --> 03:57:02.180]  membership values for
[03:57:02.180 --> 03:57:05.180]  segments for user by some classifier.
[03:57:05.180 --> 03:57:08.180]  This step
[03:57:08.180 --> 03:57:11.180]  is always
[03:57:11.180 --> 03:57:14.180]  present for each
[03:57:14.180 --> 03:57:17.180]  approach in programmatic. We should define
[03:57:17.180 --> 03:57:20.180]  user interests
[03:57:20.180 --> 03:57:23.180]  to perform all next steps.
[03:57:23.180 --> 03:57:26.180]  Second step is
[03:57:26.180 --> 03:57:29.180]  performing generalization of those sets
[03:57:29.180 --> 03:57:32.180]  and obtaining head segments.
[03:57:32.180 --> 03:57:35.180]  This is the most important part of our method.
[03:57:35.180 --> 03:57:38.180]  And the last step is to obtain
[03:57:38.180 --> 03:57:41.180]  the list of appropriate
[03:57:41.180 --> 03:57:44.180]  advertising campaigns for each user
[03:57:44.180 --> 03:57:47.180]  that will correspond
[03:57:47.180 --> 03:57:50.180]  not to initial
[03:57:50.180 --> 03:57:53.180]  user segments,
[03:57:53.180 --> 03:57:56.180]  but to high-ranked
[03:57:56.180 --> 03:57:59.180]  segments that we obtained in step 2.
[03:57:59.180 --> 03:58:02.180]  And this list
[03:58:02.180 --> 03:58:05.180]  will be the set of appropriate campaigns.
[03:58:05.180 --> 03:58:08.180]  And
[03:58:08.180 --> 03:58:11.180]  we conducted
[03:58:11.180 --> 03:58:14.180]  experiments
[03:58:14.180 --> 03:58:17.180]  in the company
[03:58:17.180 --> 03:58:20.180]  where I worked those times
[03:58:20.180 --> 03:58:23.180]  in Automatica.
[03:58:23.180 --> 03:58:26.180]  And we took three
[03:58:26.180 --> 03:58:29.180]  real advertising
[03:58:29.180 --> 03:58:32.180]  campaigns and
[03:58:32.180 --> 03:58:35.180]  we compared
[03:58:35.180 --> 03:58:38.180]  first of all conventional programmatic targeting,
[03:58:38.180 --> 03:58:41.180]  the second approach
[03:58:41.180 --> 03:58:44.180]  just decreasing
[03:58:44.180 --> 03:58:47.180]  thresholds and the
[03:58:47.180 --> 03:58:50.180]  new evented approach that is based
[03:58:50.180 --> 03:58:53.180]  on generalize
[03:58:53.180 --> 03:58:56.180]  lifting of these user
[03:58:56.180 --> 03:58:59.180]  segments.
[03:58:59.180 --> 03:59:02.180]  And the metrics to compare
[03:59:02.180 --> 03:59:05.180]  your first was number of advertising
[03:59:05.180 --> 03:59:08.180]  compressions. So this is the
[03:59:08.180 --> 03:59:11.180]  core metric to calculate
[03:59:11.180 --> 03:59:14.180]  the audience size, of course,
[03:59:14.180 --> 03:59:17.180]  just to define
[03:59:17.180 --> 03:59:20.180]  how we can show these
[03:59:20.180 --> 03:59:23.180]  advertising campaigns.
[03:59:23.180 --> 03:59:26.180]  And the second is
[03:59:26.180 --> 03:59:29.180]  the quality of this audience.
[03:59:29.180 --> 03:59:32.180]  Quality can be measured by a number of ways,
[03:59:32.180 --> 03:59:35.180]  but here we will use just
[03:59:35.180 --> 03:59:38.180]  so-called CTR, click through rate.
[03:59:38.180 --> 03:59:41.180]  This is the ratio
[03:59:41.180 --> 03:59:44.180]  of number of
[03:59:44.180 --> 03:59:47.180]  clicks that is
[03:59:47.180 --> 03:59:50.180]  B in the ratio and A is
[03:59:50.180 --> 03:59:53.180]  the number of
[03:59:53.180 --> 03:59:56.180]  impressions for each
[03:59:56.180 --> 03:59:59.180]  advertisement.
[03:59:59.180 --> 04:00:02.180]  And here you can see the
[04:00:02.180 --> 04:00:05.180]  results for the first advertising
[04:00:05.180 --> 04:00:08.180]  campaign. Campaign
[04:00:08.180 --> 04:00:11.180]  was devoted to
[04:00:11.180 --> 04:00:14.180]  control for children.
[04:00:14.180 --> 04:00:17.180]  I emphasize here the duration
[04:00:17.180 --> 04:00:20.180]  of this advertising campaign because
[04:00:20.180 --> 04:00:23.180]  duration sometimes is very important.
[04:00:23.180 --> 04:00:26.180]  Since in some cases
[04:00:26.180 --> 04:00:29.180]  we have no enough information
[04:00:29.180 --> 04:00:32.180]  about users
[04:00:32.180 --> 04:00:35.180]  and about
[04:00:35.180 --> 04:00:38.180]  some audience
[04:00:38.180 --> 04:00:41.180]  parameters before the campaign starts.
[04:00:41.180 --> 04:00:44.180]  So when campaign starts,
[04:00:44.180 --> 04:00:47.180]  we sequentially
[04:00:47.180 --> 04:00:50.180]  improve the quality of targeting.
[04:00:50.180 --> 04:00:53.180]  And here you can see
[04:00:53.180 --> 04:00:56.180]  also the
[04:00:56.180 --> 04:00:59.180]  segments selected for this
[04:00:59.180 --> 04:01:02.180]  campaign. For the campaigns usually
[04:01:02.180 --> 04:01:05.180]  they
[04:01:05.180 --> 04:01:08.180]  are assigned manually by some
[04:01:08.180 --> 04:01:11.180]  account manager or the person who is
[04:01:11.180 --> 04:01:14.180]  responsible to select the
[04:01:14.180 --> 04:01:17.180]  audience
[04:01:17.180 --> 04:01:20.180]  that is appropriate for the company
[04:01:20.180 --> 04:01:23.180]  who buys
[04:01:23.180 --> 04:01:26.180]  the advertisement.
[04:01:26.180 --> 04:01:29.180]  And as you see,
[04:01:29.180 --> 04:01:32.180]  we
[04:01:32.180 --> 04:01:35.180]  initially we have quite a
[04:01:35.180 --> 04:01:38.180]  restricted amount of impressions after
[04:01:38.180 --> 04:01:41.180]  using
[04:01:41.180 --> 04:01:44.180]  CASE and LUSP approaches.
[04:01:44.180 --> 04:01:47.180]  Both of them
[04:01:47.180 --> 04:01:50.180]  managed to significantly
[04:01:50.180 --> 04:01:53.180]  increase the number of impressions.
[04:01:53.180 --> 04:01:56.180]  But for
[04:01:56.180 --> 04:01:59.180]  if you take a look at the quality
[04:01:59.180 --> 04:02:02.180]  of this audience
[04:02:02.180 --> 04:02:05.180]  or this extended audience
[04:02:05.180 --> 04:02:08.180]  we see that LUSP
[04:02:08.180 --> 04:02:11.180]  method that is based on extending
[04:02:11.180 --> 04:02:14.180]  audience
[04:02:14.180 --> 04:02:17.180]  by generalization of user profiles.
[04:02:17.180 --> 04:02:20.180]  This method
[04:02:20.180 --> 04:02:23.180]  has way better
[04:02:23.180 --> 04:02:26.180]  quality of extended audience.
[04:02:26.180 --> 04:02:29.180]  This is
[04:02:29.180 --> 04:02:32.180]  clearly
[04:02:32.180 --> 04:02:35.180]  if you take a look at the
[04:02:35.180 --> 04:02:38.180]  CTR obtained for the
[04:02:38.180 --> 04:02:41.180]  companies. Of course the initial
[04:02:41.180 --> 04:02:44.180]  CTR was a bit better, but
[04:02:44.180 --> 04:02:47.180]  for
[04:02:47.180 --> 04:02:50.180]  straightforward method
[04:02:50.180 --> 04:02:53.180]  CASE we obtained
[04:02:54.180 --> 04:02:57.180]  lower CTR
[04:02:57.180 --> 04:03:00.180]  that means that the
[04:03:00.180 --> 04:03:03.180]  quality of audience
[04:03:03.180 --> 04:03:06.180]  in this case was not so good.
[04:03:06.180 --> 04:03:09.180]  And for
[04:03:09.180 --> 04:03:12.180]  two more advertising campaigns
[04:03:12.180 --> 04:03:15.180]  we see approximately the same results.
[04:03:15.180 --> 04:03:18.180]  The second campaign was devoted to
[04:03:18.180 --> 04:03:21.180]  frame houses for villages and
[04:03:21.180 --> 04:03:24.180]  this company had very restricted
[04:03:24.180 --> 04:03:27.180]  duration and here we again
[04:03:27.180 --> 04:03:30.180]  see the quality
[04:03:30.180 --> 04:03:33.180]  of LUSP method
[04:03:33.180 --> 04:03:36.180]  is the same as
[04:03:36.180 --> 04:03:39.180]  it was initially
[04:03:39.180 --> 04:03:42.180]  and we managed to significantly
[04:03:42.180 --> 04:03:45.180]  extend the number of advertising
[04:03:45.180 --> 04:03:48.180]  impressions and as a consequence of course
[04:03:48.180 --> 04:03:51.180]  we see
[04:03:51.180 --> 04:03:54.180]  more clicks.
[04:03:54.180 --> 04:03:57.180]  And for third advertising campaign
[04:03:57.180 --> 04:04:00.180]  that was devoted to
[04:04:00.180 --> 04:04:03.180]  language in a major Russian bank
[04:04:03.180 --> 04:04:06.180]  we see pretty the same result.
[04:04:06.180 --> 04:04:09.180]  Of course CTR
[04:04:09.180 --> 04:04:12.180]  for LUSP method was a bit lower
[04:04:12.180 --> 04:04:15.180]  than it was for initial audience,
[04:04:15.180 --> 04:04:18.180]  but the amount of impressions that was
[04:04:18.180 --> 04:04:21.180]  a very good result here.
[04:04:21.180 --> 04:04:24.180]  So these results
[04:04:24.180 --> 04:04:27.180]  prove that this approach
[04:04:27.180 --> 04:04:30.180]  works indeed.
[04:04:30.180 --> 04:04:33.180]  And we can
[04:04:33.180 --> 04:04:36.180]  conclude that
[04:04:36.180 --> 04:04:39.180]  the amount
[04:04:39.180 --> 04:04:42.180]  of
[04:04:42.180 --> 04:04:45.180]  clicks
[04:04:45.180 --> 04:04:48.180]  by LUSP
[04:04:48.180 --> 04:04:51.180]  was 74%.
[04:04:51.180 --> 04:04:54.180]  So the
[04:04:54.180 --> 04:04:57.180]  maximum amount
[04:04:57.180 --> 04:05:00.180]  of clicks
[04:05:00.180 --> 04:05:03.180]  for just
[04:05:03.180 --> 04:05:06.180]  lessening of
[04:05:06.180 --> 04:05:09.180]  belongingness thresholds was just
[04:05:09.180 --> 04:05:12.180]  74%.
[04:05:12.180 --> 04:05:15.180]  So that proves that the quality
[04:05:15.180 --> 04:05:18.180]  of audience that we get
[04:05:18.180 --> 04:05:21.180]  if we use generalized
[04:05:21.180 --> 04:05:24.180]  using segments instead of just
[04:05:24.180 --> 04:05:27.180]  lessening belongingness values
[04:05:27.180 --> 04:05:30.180]  so this way
[04:05:30.180 --> 04:05:33.180]  works way better.
[04:05:33.180 --> 04:05:36.180]  So for the future plans
[04:05:36.180 --> 04:05:39.180]  we will emphasize
[04:05:39.180 --> 04:05:42.180]  further expanding
[04:05:42.180 --> 04:05:45.180]  of tested advertising campaigns
[04:05:45.180 --> 04:05:48.180]  because there are many different
[04:05:48.180 --> 04:05:51.180]  campaigns with different duration and different
[04:05:51.180 --> 04:05:54.180]  user segments assigned.
[04:05:54.180 --> 04:05:57.180]  So we can have an opportunity
[04:05:57.180 --> 04:06:00.180]  to check how this method works for very
[04:06:00.180 --> 04:06:03.180]  long campaigns.
[04:06:03.180 --> 04:06:06.180]  It works on quite short campaigns
[04:06:06.180 --> 04:06:09.180]  where we have restricted duration, where we have
[04:06:09.180 --> 04:06:12.180]  a restricted amount of
[04:06:12.180 --> 04:06:15.180]  further
[04:06:15.180 --> 04:06:18.180]  contacts with users
[04:06:18.180 --> 04:06:21.180]  expressed in impressions.
[04:06:21.180 --> 04:06:24.180]  And compare this LUSP
[04:06:24.180 --> 04:06:27.180]  method with audience proximity lookalike
[04:06:27.180 --> 04:06:30.180]  methods. Lookalike is
[04:06:30.180 --> 04:06:33.180]  a family of the methods where we
[04:06:33.180 --> 04:06:36.180]  instead of modifying
[04:06:36.180 --> 04:06:39.180]  somehow targeting procedures we just
[04:06:39.180 --> 04:06:42.180]  either buy a new audience
[04:06:42.180 --> 04:06:45.180]  somewhere. This can be inappropriate
[04:06:45.180 --> 04:06:48.180]  for small companies because it's technically
[04:06:48.180 --> 04:06:51.180]  impossible sometimes but for
[04:06:51.180 --> 04:06:54.180]  some medium sized companies this is quite
[04:06:54.180 --> 04:06:57.180]  common way where the companies
[04:06:57.180 --> 04:07:00.180]  share each other
[04:07:00.180 --> 04:07:03.180]  audience and they
[04:07:03.180 --> 04:07:06.180]  also try to
[04:07:06.180 --> 04:07:09.180]  find similar audience
[04:07:09.180 --> 04:07:12.180]  say by matching user profiles
[04:07:12.180 --> 04:07:15.180]  by finding some
[04:07:15.180 --> 04:07:18.180]  intersections between user profiles
[04:07:18.180 --> 04:07:21.180]  and stuff like that. This is very wide
[04:07:21.180 --> 04:07:24.180]  family of different methods.
[04:07:24.180 --> 04:07:27.180]  And the second
[04:07:27.180 --> 04:07:30.180]  is
[04:07:30.180 --> 04:07:33.180]  developing
[04:07:33.180 --> 04:07:36.180]  a strategy for parameters
[04:07:36.180 --> 04:07:39.180]  fitting because currently we just used
[04:07:39.180 --> 04:07:42.180]  fixed values of our
[04:07:42.180 --> 04:07:45.180]  parameters of this algorithm and of course we can
[04:07:45.180 --> 04:07:48.180]  think about how can we
[04:07:48.180 --> 04:07:51.180]  make the selection
[04:07:51.180 --> 04:07:54.180]  very automatic or
[04:07:54.180 --> 04:07:57.180]  adjustable during the work of
[04:07:57.180 --> 04:08:00.180]  this algorithm. That would be great.
[04:08:00.180 --> 04:08:03.180]  Thank you for your attention.
[04:08:06.180 --> 04:08:09.180]  Thank you.
[04:08:09.180 --> 04:08:12.180]  What is
[04:08:12.180 --> 04:08:15.180]  what are impressions?
[04:08:15.180 --> 04:08:18.180]  How are they measured?
[04:08:18.180 --> 04:08:21.180]  Impressions is the event
[04:08:21.180 --> 04:08:24.180]  when some users see the
[04:08:24.180 --> 04:08:27.180]  advertisement.
[04:08:27.180 --> 04:08:30.180]  This is
[04:08:30.180 --> 04:08:33.180]  can be either the banner
[04:08:33.180 --> 04:08:36.180]  or the
[04:08:36.180 --> 04:08:39.180]  video for example.
[04:08:39.180 --> 04:08:42.180]  And the important issue here is
[04:08:42.180 --> 04:08:45.180]  how to measure that because
[04:08:45.180 --> 04:08:48.180]  different companies
[04:08:48.180 --> 04:08:51.180]  have different approaches
[04:08:51.180 --> 04:08:54.180]  to measure these contacts. For example
[04:08:54.180 --> 04:08:57.180]  some companies just use
[04:08:57.180 --> 04:09:00.180]  special JavaScript events
[04:09:00.180 --> 04:09:03.180]  to measure that. So if
[04:09:03.180 --> 04:09:06.180]  more than half of
[04:09:06.180 --> 04:09:09.180]  picture of ads
[04:09:09.180 --> 04:09:12.180]  is visible to user, I mean
[04:09:12.180 --> 04:09:15.180]  it appeared on the visible
[04:09:15.180 --> 04:09:18.180]  part of
[04:09:18.180 --> 04:09:21.180]  the screen. This can be
[04:09:21.180 --> 04:09:24.180]  impression. For other
[04:09:24.180 --> 04:09:27.180]  companies they use
[04:09:27.180 --> 04:09:30.180]  just loading of these ads.
[04:09:30.180 --> 04:09:33.180]  In our case we tried to
[04:09:33.180 --> 04:09:36.180]  follow the most strict definition of
[04:09:36.180 --> 04:09:39.180]  impression. The first one
[04:09:39.180 --> 04:09:42.180]  that I described, more than half
[04:09:42.180 --> 04:09:45.180]  of picture of the advertising
[04:09:45.180 --> 04:09:48.180]  should be visible at the
[04:09:48.180 --> 04:09:51.180]  user's screen. And in that case that will
[04:09:51.180 --> 04:09:54.180]  be impression. Thank you very much.
[04:09:54.180 --> 04:09:57.180]  A long eye contact with
[04:09:57.180 --> 04:10:00.180]  advertisement.
[04:10:00.180 --> 04:10:03.180]  This is usually
[04:10:03.180 --> 04:10:06.180]  most commonly this is
[04:10:06.180 --> 04:10:09.180]  undefined but
[04:10:09.180 --> 04:10:12.180]  some companies use
[04:10:12.180 --> 04:10:15.180]  and we also follow this
[04:10:15.180 --> 04:10:18.180]  it should be at least one
[04:10:18.180 --> 04:10:21.180]  second.
[04:10:21.180 --> 04:10:24.180]  Could you please explain
[04:10:24.180 --> 04:10:27.180]  each advertisement
[04:10:27.180 --> 04:10:30.180]  has a set
[04:10:30.180 --> 04:10:33.180]  of keywords or tags,
[04:10:33.180 --> 04:10:36.180]  how to define it?
[04:10:36.180 --> 04:10:39.180]  Yeah, thank you for
[04:10:39.180 --> 04:10:42.180]  this question. So yeah,
[04:10:42.180 --> 04:10:45.180]  from the advertisement side most commonly
[04:10:45.180 --> 04:10:48.180]  these segments are defined
[04:10:48.180 --> 04:10:51.180]  manually by special
[04:10:51.180 --> 04:10:54.180]  companies either on buyer side
[04:10:54.180 --> 04:10:57.180]  or at the agency side.
[04:10:57.180 --> 04:11:00.180]  And they are
[04:11:00.180 --> 04:11:03.180]  fixed and for example
[04:11:03.180 --> 04:11:06.180]  if we would like to
[04:11:06.180 --> 04:11:09.180]  if we have
[04:11:09.180 --> 04:11:12.180]  advertising campaign about
[04:11:12.180 --> 04:11:15.180]  wall workers we can choose the
[04:11:15.180 --> 04:11:18.180]  segments wall worker owner,
[04:11:18.180 --> 04:11:21.180]  people who are going to buy
[04:11:21.180 --> 04:11:24.180]  car.
[04:11:24.180 --> 04:11:27.180]  We can also specify
[04:11:27.180 --> 04:11:30.180]  some demographic
[04:11:30.180 --> 04:11:33.180]  segments such as
[04:11:33.180 --> 04:11:36.180]  age or gender
[04:11:36.180 --> 04:11:39.180]  or some location
[04:11:39.180 --> 04:11:42.180]  and these things
[04:11:42.180 --> 04:11:45.180]  are defined manually in most cases.
[04:11:45.180 --> 04:11:48.180]  Thank you very much.
[04:11:48.180 --> 04:11:51.180]  Any more questions?
[04:11:51.180 --> 04:11:54.180]  Online participants, no questions?
[04:11:54.180 --> 04:11:57.180]  I have a question.
[04:11:57.180 --> 04:12:00.180]  Dmitry, I have this question.
[04:12:00.180 --> 04:12:03.180]  This approach,
[04:12:03.180 --> 04:12:06.180]  is it possible to apply this
[04:12:06.180 --> 04:12:09.180]  approach to building
[04:12:09.180 --> 04:12:12.180]  recommender systems?
[04:12:12.180 --> 04:12:15.180]  This is a very interesting
[04:12:15.180 --> 04:12:18.180]  question. So yes,
[04:12:18.180 --> 04:12:21.180]  I think this is possible because
[04:12:21.180 --> 04:12:24.180]  there are many different kinds of
[04:12:24.180 --> 04:12:27.180]  recommender systems.
[04:12:27.180 --> 04:12:30.180]  Some of them are based on
[04:12:30.180 --> 04:12:33.180]  different engines such as
[04:12:33.180 --> 04:12:36.180]  collaborative filtering,
[04:12:36.180 --> 04:12:39.180]  other use
[04:12:39.180 --> 04:12:42.180]  some more
[04:12:42.180 --> 04:12:45.180]  interpretable techniques
[04:12:45.180 --> 04:12:48.180]  such as matching between
[04:12:48.180 --> 04:12:51.180]  some things that are similar
[04:12:51.180 --> 04:12:54.180]  to what we have in
[04:12:54.180 --> 04:12:57.180]  internet advertising.
[04:12:57.180 --> 04:13:00.180]  From my experience I can definitely say that
[04:13:00.180 --> 04:13:03.180]  in some recommender systems
[04:13:03.180 --> 04:13:06.180]  companies
[04:13:06.180 --> 04:13:09.180]  with similar content taxonomies
[04:13:09.180 --> 04:13:12.180]  very similar
[04:13:12.180 --> 04:13:15.180]  to what we have in internet advertising
[04:13:15.180 --> 04:13:18.180]  and
[04:13:18.180 --> 04:13:21.180]  for these recommender
[04:13:21.180 --> 04:13:24.180]  systems we will solve
[04:13:24.180 --> 04:13:27.180]  pretty the same problem
[04:13:27.180 --> 04:13:30.180]  where we have
[04:13:30.180 --> 04:13:33.180]  restrict, for example,
[04:13:33.180 --> 04:13:36.180]  some set of content
[04:13:36.180 --> 04:13:39.180]  and users.
[04:13:39.180 --> 04:13:42.180]  The issue will be
[04:13:42.180 --> 04:13:45.180]  just to
[04:13:48.180 --> 04:13:51.180]  choose appropriate
[04:13:51.180 --> 04:13:54.180]  content for some users and
[04:13:54.180 --> 04:13:57.180]  we will solve the same problem.
[04:13:57.180 --> 04:14:00.180]  From my personal experience I can
[04:14:00.180 --> 04:14:03.180]  tell about working in my
[04:14:03.180 --> 04:14:06.180]  previous company where we worked with very large
[04:14:06.180 --> 04:14:09.180]  content taxonomy that is at least
[04:14:09.180 --> 04:14:12.180]  twice larger than
[04:14:12.180 --> 04:14:15.180]  IAB taxonomy. The company had
[04:14:15.180 --> 04:14:18.180]  its own content taxonomy
[04:14:18.180 --> 04:14:21.180]  that contained
[04:14:21.180 --> 04:14:24.180]  six or maybe even seven
[04:14:24.180 --> 04:14:27.180]  layers of
[04:14:27.180 --> 04:14:30.180]  different
[04:14:30.180 --> 04:14:33.180]  segments.
[04:14:33.180 --> 04:14:36.180]  In that case I think
[04:14:36.180 --> 04:14:39.180]  this is a good
[04:14:39.180 --> 04:14:42.180]  input data to develop
[04:14:42.180 --> 04:14:45.180]  here
[04:14:45.180 --> 04:14:48.180]  this
[04:14:48.180 --> 04:14:51.180]  recommender engine based on
[04:14:51.180 --> 04:14:54.180]  this generalization in taxonomies.
[04:14:54.180 --> 04:14:57.180]  Let's start.
[04:14:57.180 --> 04:15:00.180]  We can see the variation inequality problem.
[04:15:00.180 --> 04:15:03.180]  On the slide you can see this
[04:15:03.180 --> 04:15:06.180]  formulation in the unconstrained
[04:15:06.180 --> 04:15:09.180]  setting. This problem is
[04:15:09.180 --> 04:15:12.180]  written quite similar.
[04:15:12.180 --> 04:15:15.180]  We just need to find
[04:15:15.180 --> 04:15:18.180]  some point z star such that
[04:15:18.180 --> 04:15:21.180]  operator f in this point z star
[04:15:21.180 --> 04:15:24.180]  is equal to zero.
[04:15:24.180 --> 04:15:27.180]  In the first glance this problem looks like
[04:15:27.180 --> 04:15:30.180]  quite strange because we don't know
[04:15:30.180 --> 04:15:33.180]  what is the operator but
[04:15:33.180 --> 04:15:36.180]  to emphasize that
[04:15:36.180 --> 04:15:39.180]  this problem is quite general
[04:15:39.180 --> 04:15:42.180]  we can consider some particular examples
[04:15:42.180 --> 04:15:45.180]  when this problem
[04:15:45.180 --> 04:15:48.180]  arises. For example
[04:15:48.180 --> 04:15:51.180]  the most typical and very popular
[04:15:51.180 --> 04:15:54.180]  example is the minimization problem
[04:15:54.180 --> 04:15:57.180]  when we try to minimize some function f
[04:15:57.180 --> 04:16:00.180]  and if we put the operator
[04:16:00.180 --> 04:16:03.180]  in the variation inequality as the gradient
[04:16:03.180 --> 04:16:06.180]  of this function
[04:16:06.180 --> 04:16:09.180]  we need to solve
[04:16:09.180 --> 04:16:12.180]  the problem of
[04:16:12.180 --> 04:16:15.180]  the search of the stationary point
[04:16:15.180 --> 04:16:18.180]  function. In the convex setting it is equal
[04:16:18.180 --> 04:16:21.180]  to the minimization and in the non-convex
[04:16:21.180 --> 04:16:24.180]  just to search of the stationary point
[04:16:24.180 --> 04:16:27.180]  but it's enough because
[04:16:27.180 --> 04:16:30.180]  this is the best guarantees what we can do in theory
[04:16:30.180 --> 04:16:33.180]  for non-convex setting. Another example
[04:16:33.180 --> 04:16:36.180]  is saddle point problem. Here we have
[04:16:36.180 --> 04:16:39.180]  not only minimization but here the
[04:16:39.180 --> 04:16:42.180]  minimization and maximization here.
[04:16:42.180 --> 04:16:45.180]  Here we
[04:16:45.180 --> 04:16:48.180]  use the operator f
[04:16:48.180 --> 04:16:51.180]  and we take
[04:16:51.180 --> 04:16:54.180]  the gradient on variable x
[04:16:54.180 --> 04:16:57.180]  the variable in what we minimize
[04:16:57.180 --> 04:17:00.180]  and anti-gradient on variable y
[04:17:00.180 --> 04:17:03.180]  the variable in what we
[04:17:03.180 --> 04:17:06.180]  maximize and
[04:17:06.180 --> 04:17:09.180]  it's easy to show that we try to find
[04:17:09.180 --> 04:17:12.180]  stationary point not only on the gradient
[04:17:12.180 --> 04:17:15.180]  x but in gradient y also.
[04:17:15.180 --> 04:17:18.180]  And in the convex
[04:17:18.180 --> 04:17:21.180]  concave setting this is equal
[04:17:21.180 --> 04:17:24.180]  to find the saddle
[04:17:24.180 --> 04:17:27.180]  point problem.
[04:17:27.180 --> 04:17:30.180]  Also here we can consider the
[04:17:30.180 --> 04:17:33.180]  fixed point problem. Here we have
[04:17:33.180 --> 04:17:36.180]  operator tau
[04:17:36.180 --> 04:17:39.180]  and we need to find some point z star
[04:17:39.180 --> 04:17:42.180]  such that tau in
[04:17:42.180 --> 04:17:45.180]  z star is equal to tau.
[04:17:45.180 --> 04:17:48.180]  This is stationary point, fixed point of the
[04:17:48.180 --> 04:17:51.180]  operator. And here we can
[04:17:51.180 --> 04:17:54.180]  put f, the operator
[04:17:54.180 --> 04:17:57.180]  and the variation in equality as
[04:17:57.180 --> 04:18:00.180]  z minus tau z and we find
[04:18:00.180 --> 04:18:03.180]  with this operator the fixed point of the
[04:18:03.180 --> 04:18:06.180]  operator tau.
[04:18:06.180 --> 04:18:09.180]  In our research we can see
[04:18:09.180 --> 04:18:12.180]  the finite sum case
[04:18:12.180 --> 04:18:15.180]  of the operator f
[04:18:15.180 --> 04:18:18.180]  and we assume
[04:18:18.180 --> 04:18:21.180]  that the operator f is some kind of average
[04:18:21.180 --> 04:18:24.180]  sum of other operators fi.
[04:18:24.180 --> 04:18:27.180]  This setting is common to machine learning
[04:18:27.180 --> 04:18:30.180]  because typically for example
[04:18:30.180 --> 04:18:33.180]  risk minimization is the sum
[04:18:33.180 --> 04:18:36.180]  of losses of our
[04:18:36.180 --> 04:18:39.180]  model in different data points.
[04:18:39.180 --> 04:18:42.180]  We have weight of the model z
[04:18:42.180 --> 04:18:45.180]  and model f.
[04:18:45.180 --> 04:18:48.180]  We input
[04:18:48.180 --> 04:18:51.180]  some point xi
[04:18:51.180 --> 04:18:54.180]  and weight z to the model and
[04:18:54.180 --> 04:18:57.180]  compare the output of the model with
[04:18:57.180 --> 04:19:00.180]  the real label y, yi
[04:19:00.180 --> 04:19:03.180]  and penalize the
[04:19:03.180 --> 04:19:06.180]  difference between them.
[04:19:06.180 --> 04:19:09.180]  If we speak about saddle point problems
[04:19:09.180 --> 04:19:12.180]  in terms of machine learning here we can
[04:19:12.180 --> 04:19:15.180]  give example of adversarial
[04:19:15.180 --> 04:19:18.180]  training. It is close to the
[04:19:18.180 --> 04:19:21.180]  original empirical risk minimization
[04:19:21.180 --> 04:19:24.180]  on the slide, but here
[04:19:24.180 --> 04:19:27.180]  we add some kind of adversarial noise delta i
[04:19:27.180 --> 04:19:30.180]  to each of the samples.
[04:19:30.180 --> 04:19:33.180]  Using this noise we make some kind
[04:19:33.180 --> 04:19:36.180]  of
[04:19:36.180 --> 04:19:39.180]  make our
[04:19:39.180 --> 04:19:42.180]  training process more robust
[04:19:42.180 --> 04:19:45.180]  because this noise also
[04:19:45.180 --> 04:19:48.180]  train during the
[04:19:48.180 --> 04:19:51.180]  process of training of the
[04:19:51.180 --> 04:19:54.180]  model. These weights
[04:19:54.180 --> 04:19:57.180]  make our data set more
[04:19:57.180 --> 04:20:00.180]  adversarial to our training.
[04:20:00.180 --> 04:20:03.180]  That's why we can avoid
[04:20:03.180 --> 04:20:06.180]  the process of
[04:20:06.180 --> 04:20:09.180]  overtraining and other bad examples.
[04:20:09.180 --> 04:20:12.180]  It is also good to
[04:20:12.180 --> 04:20:15.180]  save
[04:20:15.180 --> 04:20:18.180]  against adversarial attacks.
[04:20:18.180 --> 04:20:21.180]  If we use our model
[04:20:21.180 --> 04:20:24.180]  with delta noise.
[04:20:24.180 --> 04:20:27.180]  This is a practical example when
[04:20:27.180 --> 04:20:30.180]  minimization and saddle point problems
[04:20:30.180 --> 04:20:33.180]  arise in machine learning.
[04:20:33.180 --> 04:20:36.180]  Next we give some assumptions on
[04:20:36.180 --> 04:20:39.180]  our operators.
[04:20:39.180 --> 04:20:42.180]  The general operator f and summons
[04:20:42.180 --> 04:20:45.180]  f pi to make our
[04:20:45.180 --> 04:20:48.180]  analysis.
[04:20:48.180 --> 04:20:51.180]  Here we give two assumptions
[04:20:51.180 --> 04:20:54.180]  cocoercivity and
[04:20:54.180 --> 04:20:57.180]  strong monotonicity.
[04:20:57.180 --> 04:21:00.180]  Cocoercivity is some kind of assumptions
[04:21:00.180 --> 04:21:03.180]  like Lipschitzness of convex
[04:21:03.180 --> 04:21:06.180]  function.
[04:21:06.180 --> 04:21:09.180]  For minimization problems
[04:21:09.180 --> 04:21:12.180]  Lipschitzness of the gradient
[04:21:12.180 --> 04:21:15.180]  and cocoercivity is equivalent.
[04:21:15.180 --> 04:21:18.180]  For saddle point problems
[04:21:18.180 --> 04:21:21.180]  Lipschitzness of the gradient
[04:21:21.180 --> 04:21:24.180]  and cocoercivity is not the same
[04:21:24.180 --> 04:21:27.180]  and cocoercivity is more
[04:21:27.180 --> 04:21:30.180]  restricted but also general.
[04:21:30.180 --> 04:21:33.180]  One more assumption is strong
[04:21:33.180 --> 04:21:36.180]  monotonicity of the general operator f.
[04:21:36.180 --> 04:21:39.180]  For minimization problems
[04:21:39.180 --> 04:21:42.180]  Lipschitzness of the saddle point problems
[04:21:42.180 --> 04:21:45.180]  is equivalent to strong convexity
[04:21:45.180 --> 04:21:48.180]  of target function of the minimization problem
[04:21:48.180 --> 04:21:51.180]  and strong convexity of the target function
[04:21:51.180 --> 04:21:54.180]  in the saddle point problem.
[04:21:54.180 --> 04:21:57.180]  If we speak about
[04:21:57.180 --> 04:22:00.180]  stochastic methods for our
[04:22:00.180 --> 04:22:03.180]  finite sum problem.
[04:22:03.180 --> 04:22:06.180]  The main problem of the finite sum
[04:22:06.180 --> 04:22:09.180]  of commotion learning
[04:22:09.180 --> 04:22:12.180]  it is too expensive to
[04:22:12.180 --> 04:22:15.180]  collect, to compute the full gradient.
[04:22:15.180 --> 04:22:18.180]  That's why we just compute
[04:22:18.180 --> 04:22:21.180]  some gradients on small batches
[04:22:21.180 --> 04:22:24.180]  and using these batches organize
[04:22:24.180 --> 04:22:27.180]  the process of training.
[04:22:27.180 --> 04:22:30.180]  Here on this slide you can see the
[04:22:30.180 --> 04:22:33.180]  typical form of the
[04:22:33.180 --> 04:22:36.180]  gradient method. We have some kind of
[04:22:36.180 --> 04:22:39.180]  operator vk.
[04:22:39.180 --> 04:22:42.180]  It can be for example in SGD we use
[04:22:42.180 --> 04:22:45.180]  some, for example one
[04:22:45.180 --> 04:22:48.180]  we can choose randomly one of the summons
[04:22:48.180 --> 04:22:51.180]  and use it as a gradient
[04:22:51.180 --> 04:22:54.180]  instead of the full gradient.
[04:22:54.180 --> 04:22:57.180]  This is just the typical most common
[04:22:57.180 --> 04:23:00.180]  SGD version of saddle point problems
[04:23:00.180 --> 04:23:03.180]  but stochastic gradient
[04:23:03.180 --> 04:23:06.180]  descent us because we not only
[04:23:06.180 --> 04:23:09.180]  descend to the optimum but also
[04:23:09.180 --> 04:23:12.180]  ascend to the maximization variant.
[04:23:12.180 --> 04:23:15.180]  There are another version of methods
[04:23:15.180 --> 04:23:18.180]  for finite sum problems, for example SVRG
[04:23:18.180 --> 04:23:21.180]  methods. In SVRG methods
[04:23:21.180 --> 04:23:24.180]  we don't only compute
[04:23:24.180 --> 04:23:27.180]  the value of operator
[04:23:27.180 --> 04:23:30.180]  fy in current point.k
[04:23:30.180 --> 04:23:33.180]  but also make this
[04:23:33.180 --> 04:23:36.180]  correction. This correction
[04:23:36.180 --> 04:23:39.180]  here, correction in point wk.
[04:23:39.180 --> 04:23:42.180]  Wk is some kind of
[04:23:42.180 --> 04:23:45.180]  reference point
[04:23:45.180 --> 04:23:48.180]  which we are
[04:23:48.180 --> 04:23:51.180]  updated very rarely. For example
[04:23:51.180 --> 04:23:54.180]  in one times per big number
[04:23:54.180 --> 04:23:57.180]  of iterations. In this point wk
[04:23:57.180 --> 04:24:00.180]  we compute the full operator
[04:24:00.180 --> 04:24:03.180]  or full gradient. But because
[04:24:03.180 --> 04:24:06.180]  we updated very rarely this
[04:24:06.180 --> 04:24:09.180]  full gradient is also computed very rarely.
[04:24:09.180 --> 04:24:12.180]  And we made some kind of correction
[04:24:12.180 --> 04:24:15.180]  and this
[04:24:15.180 --> 04:24:18.180]  using fi in point vk
[04:24:18.180 --> 04:24:21.180]  and the full operator in point vk.
[04:24:21.180 --> 04:24:24.180]  And near the solution
[04:24:24.180 --> 04:24:27.180]  this wk
[04:24:27.180 --> 04:24:30.180]  operator for SVRG
[04:24:30.180 --> 04:24:33.180]  is a good approximation for the real gradient
[04:24:33.180 --> 04:24:36.180]  for the real deterministic gradient
[04:24:36.180 --> 04:24:39.180]  for the real deterministic operator.
[04:24:39.180 --> 04:24:42.180]  Another approach is the SARA approach
[04:24:42.180 --> 04:24:45.180]  the main approach of our research.
[04:24:45.180 --> 04:24:48.180]  It is close to the
[04:24:48.180 --> 04:24:51.180]  SVRG.
[04:24:51.180 --> 04:24:54.180]  Ideas is common, but here
[04:24:54.180 --> 04:24:57.180]  we update this operator vk
[04:24:57.180 --> 04:25:00.180]  on the flight. We don't compute
[04:25:00.180 --> 04:25:03.180]  we don't use the reference point like in SVRG
[04:25:03.180 --> 04:25:06.180]  but modify this vk
[04:25:06.180 --> 04:25:09.180]  using current point and previous point.
[04:25:09.180 --> 04:25:12.180]  And experiments
[04:25:12.180 --> 04:25:15.180]  of the show that
[04:25:15.180 --> 04:25:18.180]  SARA is more robust
[04:25:18.180 --> 04:25:21.180]  and has
[04:25:21.180 --> 04:25:24.180]  smoother trajectory of the convergence
[04:25:24.180 --> 04:25:27.180]  than SVRG.
[04:25:27.180 --> 04:25:30.180]  And here we provide the full algorithms
[04:25:30.180 --> 04:25:33.180]  of the SARA for stochastic concursive
[04:25:33.180 --> 04:25:36.180]  variation inequalities.
[04:25:36.180 --> 04:25:39.180]  There are two loops
[04:25:39.180 --> 04:25:42.180]  the main loops on variable s
[04:25:42.180 --> 04:25:45.180]  and the inner loop on variable k.
[04:25:45.180 --> 04:25:48.180]  In the main loop we need to
[04:25:48.180 --> 04:25:51.180]  update the full operator as this
[04:25:51.180 --> 04:25:54.180]  v operator v0 operator.
[04:25:54.180 --> 04:25:57.180]  Then on the inner loops we made SARA
[04:25:57.180 --> 04:26:00.180]  updates.
[04:26:00.180 --> 04:26:03.180]  And here you can see the convergence
[04:26:03.180 --> 04:26:06.180]  of the algorithm.
[04:26:06.180 --> 04:26:09.180]  And theorems says that
[04:26:09.180 --> 04:26:12.180]  under our assumptions
[04:26:12.180 --> 04:26:15.180]  we can guarantee that
[04:26:15.180 --> 04:26:18.180]  one epoch, one outer iteration
[04:26:18.180 --> 04:26:21.180]  our main iteration of our algorithm
[04:26:21.180 --> 04:26:24.180]  can guarantee the norm of the
[04:26:24.180 --> 04:26:27.180]  operator or norm of the gradients
[04:26:27.180 --> 04:26:30.180]  became two times smaller.
[04:26:30.180 --> 04:26:33.180]  And also we provide
[04:26:33.180 --> 04:26:36.180]  corollary with the
[04:26:36.180 --> 04:26:39.180]  oracle complexity of our algorithms.
[04:26:39.180 --> 04:26:42.180]  You can also see
[04:26:42.180 --> 04:26:45.180]  on the slide.
[04:26:45.180 --> 04:26:48.180]  Then I will show
[04:26:48.180 --> 04:26:51.180]  you experiments. We provide experiments
[04:26:51.180 --> 04:26:54.180]  on small bilinear problems.
[04:26:54.180 --> 04:26:57.180]  This is a settled point problems.
[04:26:57.180 --> 04:27:00.180]  On the slide you can see how we can generate
[04:27:00.180 --> 04:27:03.180]  the different parameters of these problems.
[04:27:03.180 --> 04:27:06.180]  And here we use SVRG and SGD
[04:27:06.180 --> 04:27:09.180]  from the previous slides as
[04:27:09.180 --> 04:27:12.180]  competitors in our experiments.
[04:27:12.180 --> 04:27:15.180]  And in plots you see
[04:27:15.180 --> 04:27:18.180]  how SVRG,
[04:27:18.180 --> 04:27:21.180]  SGD and SARA
[04:27:21.180 --> 04:27:24.180]  works for this toy bilinear
[04:27:24.180 --> 04:27:27.180]  problem.
[04:27:27.180 --> 04:27:30.180]  And you can see that our method
[04:27:30.180 --> 04:27:33.180]  outperforms the competitors from the
[04:27:33.180 --> 04:27:36.180]  previous papers.
[04:27:36.180 --> 04:27:39.180]  Okay, thank you. That's all.
[04:27:51.180 --> 04:27:54.180]  Thank you for your presentation.
[04:27:54.180 --> 04:27:57.180]  Thank you.
[04:27:57.180 --> 04:28:00.180]  Any questions?
[04:28:03.180 --> 04:28:06.180]  Any questions?
[04:28:06.180 --> 04:28:09.180]  Thank you for your presentation.
[04:28:09.180 --> 04:28:12.180]  I wanted to ask...
[04:28:13.180 --> 04:28:16.180]  Excuse me.
[04:28:22.180 --> 04:28:25.180]  Yes.
[04:28:25.180 --> 04:28:28.180]  I wanted to ask
[04:28:28.180 --> 04:28:31.180]  how your method compares
[04:28:31.180 --> 04:28:34.180]  to the Nesterov method.
[04:28:34.180 --> 04:28:37.180]  Or is it part of one of the...
[04:28:37.180 --> 04:28:40.180]  How does it compare to yours?
[04:28:40.180 --> 04:28:43.180]  Here the main problem
[04:28:43.180 --> 04:28:46.180]  that variation inequalities is more general
[04:28:46.180 --> 04:28:49.180]  problem than minimization.
[04:28:49.180 --> 04:28:52.180]  Nesterov's method also works for minimization problem.
[04:28:52.180 --> 04:28:55.180]  But for variation inequalities
[04:28:55.180 --> 04:28:58.180]  and settled point problems
[04:28:58.180 --> 04:29:01.180]  it can be proved that there is no
[04:29:01.180 --> 04:29:04.180]  Nesterov acceleration.
[04:29:04.180 --> 04:29:07.180]  We can accelerate
[04:29:07.180 --> 04:29:10.180]  theoretically
[04:29:10.180 --> 04:29:13.180]  this problem. That's why
[04:29:13.180 --> 04:29:16.180]  in Nesterov's methods works the same
[04:29:16.180 --> 04:29:19.180]  as original
[04:29:19.180 --> 04:29:22.180]  methods for
[04:29:22.180 --> 04:29:25.180]  settled point problems, for example.
[04:29:25.180 --> 04:29:28.180]  And typically in practice
[04:29:28.180 --> 04:29:31.180]  the situation is the same.
[04:29:31.180 --> 04:29:34.180]  Alright, thank you.
[04:29:34.180 --> 04:29:37.180]  Thank you very much again.
[04:29:42.180 --> 04:29:45.180]  I invite the next speaker.
[04:29:45.180 --> 04:29:48.180]  Thank you.
[04:29:48.180 --> 04:29:51.180]  Are you here?
[04:29:51.180 --> 04:29:54.180]  Hello, I'm here.
[04:29:54.180 --> 04:29:57.180]  You're welcome.
[04:30:04.180 --> 04:30:07.180]  Can you see my screen?
[04:30:07.180 --> 04:30:10.180]  Yes.
[04:30:10.180 --> 04:30:13.180]  Ok.
[04:30:13.180 --> 04:30:16.180]  I developed a
[04:30:16.180 --> 04:30:19.180]  parallel linear active set method.
[04:30:19.180 --> 04:30:22.180]  My name is Doug Neumann.
[04:30:22.180 --> 04:30:25.180]  I was successful
[04:30:25.180 --> 04:30:28.180]  in this technology.
[04:30:28.180 --> 04:30:31.180]  The goal was to
[04:30:31.180 --> 04:30:38.380]  Мы нашли сложный форма-метод для минимизации конвертных функций под ограничениями линейных неисправностей.
[04:30:40.300 --> 04:30:48.140]  И мы нашли один, в том числе и конвертный минимизационный метод для линейных
[04:30:48.140 --> 04:30:54.940]  неисправностей, который называется сложный форма. Так что, что я имею в виду сложного форма? Это просто
[04:30:54.940 --> 04:30:59.420]  алгоритм, который решит это в finite number, алгоритм, который найдет минимальную точку
[04:30:59.420 --> 04:31:05.900]  конвертной функции в finite number of steps, что означает, что это не ответ на
[04:31:05.900 --> 04:31:18.220]  epsilon ball и не ассоциативный алгоритм. Есть много сложных форм, линейные неисправности, конвертные
[04:31:18.220 --> 04:31:23.820]  минимизационные методы, так что relying on the existence of one is not a waste of time.
[04:31:23.820 --> 04:31:28.380]  Например, коммондная проекция, коммондная проекция функционанта на афианскую
[04:31:28.380 --> 04:31:35.420]  площадь, а афианская площадь вместо линейных неисправностей, и мы решили это в н-кубе операция.
[04:31:37.580 --> 04:31:43.820]  Больше всего, любую функцию, которую мы можем решить, в которой мы можем найти минимальную точку,
[04:31:43.820 --> 04:31:52.060]  в неисправностей, это также что-то, что мы можем решить для линейных неисправностей,
[04:31:52.060 --> 04:31:59.900]  при использовании изменения вариантов, так что там много их, и это полезно,
[04:31:59.900 --> 04:32:05.260]  потому что мы relying on the existence of such a method. Мы называем этот метод, мы называем этот метод, который
[04:32:05.260 --> 04:32:10.140]  решит минимальную точку конвертной функции на линейных неисправностях, мы просто называем это
[04:32:10.140 --> 04:32:13.180]  наш Black Box Method, потому что это не важно, как это работает, мы просто нуждаем это работать.
[04:32:14.220 --> 04:32:18.140]  И если наш Black Box Method не находится в закрытом форме, то наш алгоритм все еще работает,
[04:32:18.140 --> 04:32:22.460]  это просто не закрытая форма, но это все еще классный алгоритм, и у нас есть очень классные
[04:32:22.460 --> 04:32:28.700]  мультифорнированные характеристики. Для неисправностей, есть вопросы пока?
[04:32:31.500 --> 04:32:37.020]  Для неисправностей, есть некоторые существующие работы с генерацией закрытой формы алгоритм,
[04:32:38.380 --> 04:32:43.580]  есть проекционный метод для Hilbert Spaces, который имеет экспоненционную комплексию, и когда
[04:32:43.580 --> 04:32:47.420]  мультифорнированы, он имеет кубичную комплексию, и это как функция количества
[04:32:47.420 --> 04:32:54.860]  ограничений. Есть закрытые формы системы для каких-то квадратных объективных функций
[04:32:54.860 --> 04:33:02.060]  на линейных неисправностях и укридианных спacerах, и список продолжается. Есть специфическая укридианская
[04:33:02.060 --> 04:33:07.740]  проекционная функция, из которой мы строим наш метод, но мы смогли сделать несколько
[04:33:07.740 --> 04:33:14.460]  улучшений на их методе, о которой я расскажу в конце. Мы используем N для
[04:33:14.460 --> 04:33:18.620]  диаметрии, мы работаем на Hilbert Space, N является диаметрией
[04:33:18.620 --> 04:33:25.180]  в Hilbert Space, и наш конвекс объективный функцион мы называем f. Мы используем c меньше
[04:33:25.180 --> 04:33:31.740]  чем или equal для демонстрации наших р-инвалидных ограничений, и если позже р появляется и вы забыли, что
[04:33:31.740 --> 04:33:36.060]  р должен был быть опять, просто спросите. Это номер инвалидных ограничений. Мы используем c equals
[04:33:36.620 --> 04:33:41.500]  для количества, для корреспондентного инвалидного ограничения, так что мы берем
[04:33:41.500 --> 04:33:45.260]  инвалидные ограничения и сваливаем инвалидные знаки с equal-sign, а затем мы имеем
[04:33:45.260 --> 04:33:51.100]  инвалидные ограничения, и мы вернемся к этому тоже. Мы используем p для демонстрации
[04:33:52.300 --> 04:33:56.460]  смартфона c меньше чем или equal для демонстрации инвалидных ограничений.
[04:33:59.420 --> 04:34:05.340]  Несколько Definitions, которые нужны для алгоритма, чтобы сделать смысл.
[04:34:06.140 --> 04:34:14.780]  Мы называем A афинской площадкой p, если это смартфонная площадка для каких-то
[04:34:14.780 --> 04:34:19.100]  наших р-инвалидных ограничений, и афинская площадка p, если это смартфонная площадка для
[04:34:19.100 --> 04:34:25.740]  единственного р-инвалидного ограничения. Естественно, вся афинская площадка p будет
[04:34:25.740 --> 04:34:30.540]  интерсекцией количества р-инвалидных ограничений. Это важно, мы вернемся к этому.
[04:34:31.180 --> 04:34:34.940]  Для каждой афинской площадки мы также строим кон,
[04:34:35.660 --> 04:34:39.020]  потому что каждый афинский площадок это интерсекция,
[04:34:40.220 --> 04:34:43.580]  каждый афинский площадок это интерсекция планов, так что если мы сваливаем эти планы с
[04:34:43.580 --> 04:34:49.260]  половинками, мы берем интерсекцию этих половинок, мы получаем кон, поэтому афинская площадка
[04:34:49.260 --> 04:34:55.740]  inequality constraints, кон корреспонден на inequality constraints. Например, если
[04:34:55.740 --> 04:35:00.620]  афинская часть является интерсекцией зеленой линии и зеленой линии, а коня
[04:35:00.620 --> 04:35:05.980]  этой афинской части является интерсекцией зеленой половинки и зеленой половинки.
[04:35:05.980 --> 04:35:10.220]  Надеюсь, это довольно просто и смешно. Если кто-то зафиксируется,
[04:35:10.220 --> 04:35:16.540]  он снова придет, так что спрашивайте сейчас. Хорошо, идем дальше. Один последний
[04:35:16.540 --> 04:35:24.860]  Definition. Мы называем его медиатным суперспецом. Итак, если афинская часть является
[04:35:24.860 --> 04:35:33.100]  интерсекцией зеленой линии, то медиатный суперспец будет интерсекцией
[04:35:33.100 --> 04:35:41.620]  любого зеленого линии минус один из этих зеленых. И, например, если мы используем этот афинский
[04:35:41.620 --> 04:35:47.180]  время, то интерсекция зеленой линии и зеленой линии это афинская часть,
[04:35:47.180 --> 04:35:52.100]  то медиатные суперспецы просто зеленой линией или зеленой линией, потому что мы от chciaем
[04:35:52.100 --> 04:35:56.660]  убрать один из этих проблем или чем-то. И интерсекция равновесия остальных
[04:35:56.660 --> 04:36:03.700]  из них – это медиатный суперспец. Медиатный суперспец голого линии – просто
[04:36:03.700 --> 04:36:09.700]  Хилберг-спасе, и нет немедленных суперспасов в Хилберг-спасе.
[04:36:09.700 --> 04:36:11.700]  Попросы?
[04:36:15.700 --> 04:36:20.700]  Так что у нас есть два слайда, в которых я представлю метод закрытой формы.
[04:36:20.700 --> 04:36:26.700]  Во-первых, мы найдем минимальную точку закрытой формы через один из наших коней.
[04:36:26.700 --> 04:36:30.700]  Так что, это рекурсивно.
[04:36:30.700 --> 04:36:38.700]  Чтобы найти минимальную точку закрытой формы через кону Аппайн-спаса,
[04:36:38.700 --> 04:36:46.700]  мы смотрим на все немедленные суперспасы А и найдем минимальную точку через их коны.
[04:36:46.700 --> 04:36:53.700]  Если минимальная точка через любые их коны находится в коне А,
[04:36:53.700 --> 04:36:57.700]  то это минимальная точка кона А.
[04:36:57.700 --> 04:37:02.700]  И это как-то медиаторно, потому что суперконы...
[04:37:02.700 --> 04:37:06.700]  Так что этот ПВ здесь содержит ПА.
[04:37:06.700 --> 04:37:13.700]  Если это кон из немедленных суперспасов, то это содержит кон А.
[04:37:13.700 --> 04:37:15.700]  Так что это очевидно.
[04:37:15.700 --> 04:37:23.700]  Мы показали в книге, что если это не один из этих, то минимальная точка через кон А
[04:37:23.700 --> 04:37:28.700]  равна минимальной точке через Аппайн-спас А.
[04:37:28.700 --> 04:37:32.700]  И мы компютируем это с блоковым функцией.
[04:37:32.700 --> 04:37:39.700]  Так что это закрытая форма для любого кона, любого полигейного кона,
[04:37:39.700 --> 04:37:42.700]  и специфически любого кона П.
[04:37:42.700 --> 04:37:47.700]  После того как мы смогли компютировать закрытую форму...
[04:37:47.700 --> 04:37:50.700]  Есть ли вопросы об этом?
[04:37:52.700 --> 04:37:59.700]  После того как мы смогли компютировать минимальную точку через кон А,
[04:37:59.700 --> 04:38:06.700]  мы потом просто смотрим через все коны, и мы можем это сделать в определенном порядке.
[04:38:06.700 --> 04:38:12.700]  Мы можем посмотреть через все коны и найти тот, который имеет право,
[04:38:12.700 --> 04:38:17.700]  что оптимальная точка через кона равна оптимальной точке через Аппайн-спас,
[04:38:17.700 --> 04:38:20.700]  который мы компютировали здесь.
[04:38:20.700 --> 04:38:30.700]  И кон, который имеет право, если минимальная точка также находится в П, то мы это сделали.
[04:38:30.700 --> 04:38:35.700]  И эта минимальная точка является минимальной точкой П.
[04:38:35.700 --> 04:38:42.700]  Аргумент Ф на П равен аргументу Ф на Аппайн-спас.
[04:38:42.700 --> 04:38:45.700]  Так что это закрытая форма.
[04:38:45.700 --> 04:38:47.700]  Есть вопросы?
[04:38:51.700 --> 04:38:53.700]  Хорошо.
[04:38:53.700 --> 04:38:57.700]  Итак, мы можем организовать это в алгоритме.
[04:38:57.700 --> 04:39:06.700]  Если мы просто выбираем вертикалы полиэтиленов,
[04:39:06.700 --> 04:39:12.700]  если мы просто выбираем точек П, то это не организованно, и это будет бесполезно.
[04:39:12.700 --> 04:39:15.700]  Но здесь есть немного организации.
[04:39:15.700 --> 04:39:24.700]  Итак, прежде чем представить здесь оптимизацию или минимизацию метода,
[04:39:24.700 --> 04:39:31.700]  я просто подсовывал это в том, чтобы решить проблему проекции здесь в R2, чтобы сделать это удобнее в ваших глазах.
[04:39:31.700 --> 04:39:37.700]  Но этот метод подсовывает линь за линь оптимизацию метода в П,
[04:39:37.700 --> 04:39:42.700]  которая является для генерального Хилберта-спаса и конвекс-функции.
[04:39:42.700 --> 04:39:49.700]  Но здесь мы просто решим проекцию на наш пример.
[04:39:49.700 --> 04:39:54.700]  Если вы не знаете, что проекция функции, то скажите, что вы не знаете, что проекция функции сейчас,
[04:39:54.700 --> 04:39:57.700]  и я скажу вам, и это легко.
[04:39:57.700 --> 04:39:59.700]  Хорошо, мы все знаем, что проекция функции.
[04:39:59.700 --> 04:40:02.700]  Пожалуйста, остановите меня, если вы решите подниматься и сказать, что вы не знаете.
[04:40:02.700 --> 04:40:09.700]  Итак, мы просто перейдем в первую очередь все Аппайн-спасы кодименции 0,
[04:40:09.700 --> 04:40:12.700]  так что это интерсекция 0 планов, опять же, это наш Хилберт-спас.
[04:40:12.700 --> 04:40:17.700]  И потом мы перейдем в все Аппайн-спасы кодименции 1, так что это наши планы.
[04:40:17.700 --> 04:40:21.700]  И потом кодименции 2, интерсекция 92 планов, интерсекция 93 планов и так далее.
[04:40:21.700 --> 04:40:23.700]  Так что это просто эти два лупа здесь.
[04:40:23.700 --> 04:40:26.700]  И хорошая вещь в этом лупе, что, конечно,
[04:40:26.700 --> 04:40:30.700]  посмотреть на один Аппайн-спас полностью независимо от того, что посмотреть на другой Аппайн-спас,
[04:40:30.700 --> 04:40:33.700]  так что все это можно сделать в параллельном смысле, очень хорошо.
[04:40:33.700 --> 04:40:38.700]  Итак, после того, как мы выбрали Аппайн-спас кодименции I,
[04:40:38.700 --> 04:40:43.700]  мы посмотрели все оптимальные точки
[04:40:43.700 --> 04:40:49.700]  через коны амидиатных суперспасов Аппайн-спаса.
[04:40:49.700 --> 04:40:57.700]  И хорошая вещь в том, что мы уже посчитали все эти оптимальные точки, когда мы смотрели на i-1.
[04:40:57.700 --> 04:40:59.700]  Так что мы знаем этот маленький πB здесь.
[04:40:59.700 --> 04:41:02.700]  πB это проекция на код B.
[04:41:02.700 --> 04:41:06.700]  Так что если есть πB, который находится в коне А,
[04:41:06.700 --> 04:41:10.700]  то мы теперь знаем оптимальные точки через кону А,
[04:41:10.700 --> 04:41:12.700]  и мы никогда не должны называть это метод Black Box.
[04:41:12.700 --> 04:41:16.700]  И это является силой алгоритма, который мы создали.
[04:41:16.700 --> 04:41:20.700]  Мы можем найти оптимальные точки через кону
[04:41:20.700 --> 04:41:24.700]  без называния метода Black Box.
[04:41:24.700 --> 04:41:38.700]  И если мы не имеем амидиатных суперспасов,
[04:41:38.700 --> 04:41:47.700]  то мы называем этот метод Black Box
[04:41:47.700 --> 04:41:58.700]  и проверяем, если эта проекция находится в коне P.
[04:41:58.700 --> 04:42:01.700]  Если она находится в коне P, то мы закончили.
[04:42:01.700 --> 04:42:06.700]  И вернули эту точку в коне P.
[04:42:06.700 --> 04:42:09.700]  Если мы пройдем через все оптимальные точки,
[04:42:09.700 --> 04:42:13.700]  и мы никогда не нашли,
[04:42:13.700 --> 04:42:15.700]  то мы просто вернули оптимальные точки,
[04:42:15.700 --> 04:42:19.700]  потому что аргумент оптимального полиэндрома
[04:42:19.700 --> 04:42:21.700]  в действительности нет.
[04:42:21.700 --> 04:42:26.700]  И это то, что оптимальная точка находится в коне P,
[04:42:26.700 --> 04:42:32.700]  а также то, что оптимальная точка находится в коне B,
[04:42:32.700 --> 04:42:35.700]  и нет ни минимума на этой точке.
[04:42:35.700 --> 04:42:38.700]  В письмах мы также гарантируем,
[04:42:38.700 --> 04:42:49.700]  что оптимальная точка находится в коне D.
[04:42:49.700 --> 04:42:51.700]  И мы найдем ее.
[04:42:51.700 --> 04:42:53.700]  Это алгоритмы.
[04:42:53.700 --> 04:42:58.700]  Есть вопросы о том, что я писал здесь?
[04:42:58.700 --> 04:43:02.700]  Спасибо, что ответили.
[04:43:02.700 --> 04:43:06.700]  Так что, для проекции,
[04:43:06.700 --> 04:43:10.700]  когда количество оборудований у нас гораздо больше,
[04:43:10.700 --> 04:43:12.700]  чем N,
[04:43:12.700 --> 04:43:16.700]  то наша комплекситетка является R to the N
[04:43:16.700 --> 04:43:18.700]  X Rn ± N³,
[04:43:18.700 --> 04:43:21.700]  которая является полиномиалом
[04:43:21.700 --> 04:43:25.700]  в связи с количеством оборудований у нас.
[04:43:25.700 --> 04:43:27.700]  Это очень интересно,
[04:43:27.700 --> 04:43:29.700]  потому что у нас, конечно, большая дименциональность,
[04:43:29.700 --> 04:43:31.700]  а полиномиал все еще у нас.
[04:43:31.700 --> 04:43:34.700]  Но здесь интересная вещь.
[04:43:34.700 --> 04:43:38.700]  Мы можем работать в целом в параллеле,
[04:43:38.700 --> 04:43:41.700]  в параллеле в связи с количеством оборудований,
[04:43:41.700 --> 04:43:44.700]  а потом комплекситетка является O of N⁴,
[04:43:44.700 --> 04:43:51.700]  в связи с количеством оборудований R to the N±1.
[04:43:51.700 --> 04:43:54.700]  Так что это может быть интересно иногда, я думаю.
[04:43:54.700 --> 04:43:57.700]  Для более динамичной комплекситетки,
[04:43:57.700 --> 04:43:59.700]  когда мы не смотрим только на проблему проекции,
[04:43:59.700 --> 04:44:02.700]  или когда количество оборудований,
[04:44:02.700 --> 04:44:03.700]  как в Хилбардспее,
[04:44:03.700 --> 04:44:05.700]  есть infinитетное количество оборудований,
[04:44:05.700 --> 04:44:08.700]  или есть просто много оборудований,
[04:44:08.700 --> 04:44:10.700]  чем количество оборудований.
[04:44:10.700 --> 04:44:13.700]  Так что, вот этот статус здесь,
[04:44:13.700 --> 04:44:15.700]  комплекситетка,
[04:44:15.700 --> 04:44:16.700]  где я использую эти бракеты,
[04:44:16.700 --> 04:44:17.700]  чтобы указать комплекситетку,
[04:44:17.700 --> 04:44:18.700]  делая что-то внутри их.
[04:44:18.700 --> 04:44:21.700]  Так что у нас, что-то меньше,
[04:44:21.700 --> 04:44:23.700]  R to the N или 2 to the R,
[04:44:23.700 --> 04:44:24.700]  это значит, что если N³,
[04:44:24.700 --> 04:44:26.700]  мы смотрим на 2 to the R,
[04:44:26.700 --> 04:44:28.700]  которая является функцией N.
[04:44:28.700 --> 04:44:29.700]  И если R³,
[04:44:29.700 --> 04:44:30.700]  то мы смотрим на R to the N,
[04:44:30.700 --> 04:44:32.700]  которая является полиномиалом.
[04:44:32.700 --> 04:44:33.700]  И потом это просто
[04:44:33.700 --> 04:44:34.700]  количество оборудований,
[04:44:34.700 --> 04:44:35.700]  в связи с количеством оборудований,
[04:44:35.700 --> 04:44:37.700]  как и как долго нужно делать интерпродукт,
[04:44:37.700 --> 04:44:39.700]  плюс как долго нужно делать
[04:44:39.700 --> 04:44:42.700]  «колор-блак-блок» метод.
[04:44:42.700 --> 04:44:45.700]  Если мы имеем
[04:44:45.700 --> 04:44:47.700]  много процессоров,
[04:44:47.700 --> 04:44:49.700]  либо что-то меньше,
[04:44:49.700 --> 04:44:52.700]  2 to the R или R to the N,
[04:44:52.700 --> 04:44:55.700]  то это становится, что-то меньше,
[04:44:55.700 --> 04:44:57.700]  N или R,
[04:44:57.700 --> 04:44:59.700]  в связи с комплекситеткой
[04:44:59.700 --> 04:45:00.700]  компетентного интерпродукта,
[04:45:00.700 --> 04:45:01.700]  плюс комплекситеткой
[04:45:01.700 --> 04:45:03.700]  компетентного «колор-блак-блок» метода.
[04:45:03.700 --> 04:45:04.700]  В связи с тем,
[04:45:04.700 --> 04:45:05.700]  что мы имеем полиномиал,
[04:45:05.700 --> 04:45:09.700]  то, конечно, если R³ –
[04:45:09.700 --> 04:45:10.700]  F · A –
[04:45:10.700 --> 04:45:11.700]  это полиномиал,
[04:45:11.700 --> 04:45:15.700]  то комплекситетка – это не полиномиал.
[04:45:15.700 --> 04:45:16.700]  Также, если мы находимся
[04:45:16.700 --> 04:45:17.700]  в Хилберте,
[04:45:17.700 --> 04:45:19.700]  то обычно компетентный интерпродукт
[04:45:19.700 --> 04:45:20.700]  в Хилберте
[04:45:20.700 --> 04:45:22.700]  может иметь
[04:45:22.700 --> 04:45:24.700]  ε-компонент
[04:45:24.700 --> 04:45:25.700]  в комплекситете,
[04:45:25.700 --> 04:45:26.700]  и
[04:45:26.700 --> 04:45:28.700]  то это не
[04:45:28.700 --> 04:45:29.700]  «колор-блак-блок»,
[04:45:29.700 --> 04:45:30.700]  и комплекситетка
[04:45:30.700 --> 04:45:31.700]  компетентного «колор-блак-блок»
[04:45:31.700 --> 04:45:32.700]  имеет инфинитно-дименционный
[04:45:32.700 --> 04:45:33.700]  пространство,
[04:45:33.700 --> 04:45:34.700]  и это –
[04:45:34.700 --> 04:45:35.700]  я не знаю,
[04:45:35.700 --> 04:45:36.700]  «интерпродукты» или что-то такое.
[04:45:36.700 --> 04:45:38.700]  Так что, это комплекситетка.
[04:45:38.700 --> 04:45:40.700]  Эти улучшения
[04:45:40.700 --> 04:45:41.700]  в связи с
[04:45:41.700 --> 04:45:42.700]  «колор-блак-блак-блак» методом.
[04:45:42.700 --> 04:45:43.700]  Первым
[04:45:43.700 --> 04:45:44.700]  –
[04:45:44.700 --> 04:45:45.700]  в связи с тем,
[04:45:45.700 --> 04:45:46.700]  что
[04:45:46.700 --> 04:45:47.700]  «колор-блак-блак-блак» метод
[04:45:47.700 --> 04:45:49.700]  смотрит на все афинские спасы
[04:45:49.700 --> 04:46:11.760]  и
[04:46:11.760 --> 04:46:16.760]  Извините, кондицион на линии 3 означает больше и больше, и мы не должны называть метод Black Box.
[04:46:16.760 --> 04:46:24.760]  Так что, как количество ограничений увеличивается, или также, как количество диаметров увеличивается, мы называем метод Black Box
[04:46:24.760 --> 04:46:34.760]  менее приближающим к 0, как процент от количества ограничений или диаметров, которые мы смотрим.
[04:46:34.760 --> 04:46:43.760]  Так что, это большой победитель. Также, предыдущий метод проверяет все спасы Афины,
[04:46:43.760 --> 04:46:51.760]  и потом найдет, как раз, лучшие из них, или минимум результатов, когда мы называем метод Black Box,
[04:46:51.760 --> 04:46:57.760]  метод Black Box на всех этих методах, и наш метод перестанет, когда мы получим правильную ответственность.
[04:46:57.760 --> 04:47:01.760]  Мы это понимаем, и мы готовы. Так что, это хорошо.
[04:47:07.760 --> 04:47:12.760]  Так, эти были преимущества нашего метода за предыдущим методом.
[04:47:14.760 --> 04:47:16.760]  Спасибо. Вопросы?
[04:47:16.760 --> 04:47:18.760]  Можно я?
[04:47:23.760 --> 04:47:25.760]  Хорошо.
[04:47:25.760 --> 04:47:30.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:30.760 --> 04:47:34.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:34.760 --> 04:47:36.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:36.760 --> 04:47:38.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:38.760 --> 04:47:40.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:40.760 --> 04:47:42.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:42.760 --> 04:47:44.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:44.760 --> 04:47:46.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:46.760 --> 04:47:48.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:48.760 --> 04:47:50.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:50.760 --> 04:47:52.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:52.760 --> 04:47:54.760]  Вы говорите об алгоритме, и у вас есть начальник.
[04:47:55.760 --> 04:47:57.760]  Да.
[04:47:57.760 --> 04:48:00.760]  В первой линии у вас есть точка,
[04:48:00.760 --> 04:48:02.760]  по которому подойдет H.
[04:48:02.760 --> 04:48:04.760]  Хильберта Спейс, я думаю.
[04:48:04.760 --> 04:48:06.760]  Моя вопроса,
[04:48:06.760 --> 04:48:08.760]  по которому подойдет Y,
[04:48:08.760 --> 04:48:10.760]  по которому подойдет Y,
[04:48:10.760 --> 04:48:12.760]  по которому подойдет Y,
[04:48:12.760 --> 04:48:14.760]  по которому подойдет Y,
[04:48:14.760 --> 04:48:16.760]  по которому подойдет Y,
[04:48:16.760 --> 04:48:18.760]  по которому подойдет Y,
[04:48:18.760 --> 04:48:20.760]  по которому подойдет Y,
[04:48:20.760 --> 04:48:22.760]  по которому подойдет Y,
[04:48:22.760 --> 04:48:24.760]  по которому подойдет Y,
[04:48:24.760 --> 04:48:26.760]  по которому подойдет Y,
[04:48:26.760 --> 04:48:28.760]  по которому подойдет Y,
[04:48:28.760 --> 04:48:30.760]  по которому подойдет Y,
[04:48:30.760 --> 04:48:32.760]  по которому подойдет Y,
[04:48:32.760 --> 04:48:34.760]  по которому подойдет Y,
[04:48:34.760 --> 04:48:36.760]  по которому подойдет Y,
[04:48:36.760 --> 04:48:38.760]  по которому подойдет Y,
[04:48:38.760 --> 04:48:40.760]  по которому подойдет Y,
[04:48:40.760 --> 04:48:42.760]  по которому подойдет Y,
[04:48:42.760 --> 04:48:44.760]  по которому подойдет Y,
[04:48:44.760 --> 04:48:46.760]  по которому подойдет Y,
[04:48:46.760 --> 04:48:48.760]  по которому подойдет Y,
[04:48:48.760 --> 04:48:50.760]  по которому подойдет Y,
[04:48:50.760 --> 04:48:52.760]  по которому подойдет Y,
[04:48:52.760 --> 04:48:54.760]  по которому подойдет Y,
[04:48:54.760 --> 04:48:56.760]  по которому подойдет Y,
[04:48:56.760 --> 04:48:58.760]  по которому подойдет Y,
[04:48:58.760 --> 04:49:00.760]  по которому подойдет Y,
[04:49:00.760 --> 04:49:02.760]  по которому подойдет Y,
[04:49:02.760 --> 04:49:04.760]  по которому подойдет Y,
[04:49:04.760 --> 04:49:06.760]  по которому подойдет Y,
[04:49:06.760 --> 04:49:08.760]  по которому подойдет Y,
[04:49:08.760 --> 04:49:10.760]  по которому подойдет Y,
[04:49:10.760 --> 04:49:12.760]  по которому подойдет Y,
[04:49:12.760 --> 04:49:14.760]  по которому подойдет Y,
[04:49:14.760 --> 04:49:16.760]  по которому подойдет Y,
[04:49:16.760 --> 04:49:18.760]  по которому подойдет Y,
[04:49:18.760 --> 04:49:20.760]  по которому подойдет Y,
[04:49:20.760 --> 04:49:22.760]  по которому подойдет Y,
[04:49:22.760 --> 04:49:24.760]  по которему подойдет Y,
[04:49:24.760 --> 04:49:26.760]  по которому подойдет Y,
[04:49:26.760 --> 04:49:28.760]  по которому подойдет Y.
[04:49:28.760 --> 04:49:30.760]  Again.
[04:49:30.760 --> 04:49:38.760]  Да, я здесь, да, я здесь.
[04:49:38.760 --> 04:49:41.760]  Окей.
[04:49:41.760 --> 04:49:46.760]  Окей, привет всем.
[04:49:46.760 --> 04:49:53.760]  Окей, и...
[04:49:53.760 --> 04:49:58.760]  Я бы...
[04:49:58.760 --> 04:50:05.760]  Меня зовут Ворис Ковалерчук, и я поговорю об интерпретации машинной линейки для самосовершенствования,
[04:50:05.760 --> 04:50:07.760]  высокого риска решения.
[04:50:07.760 --> 04:50:11.760]  Это джейн Ток, мой старший студент,
[04:50:11.760 --> 04:50:20.760]  Чарльз Рекайдам.
[04:50:20.760 --> 04:50:21.760]  Окей.
[04:50:21.760 --> 04:50:28.760]  Во-первых, я хочу поздравить Бориса Григорьевича Мюркина с его 80 лет.
[04:50:28.760 --> 04:50:35.760]  Мы познакомились давно, в 1971 году, или раньше, в Академии Городок.
[04:50:35.760 --> 04:50:42.760]  И что он делал, в тот момент, он выявил мою мастерскую тезису
[04:50:42.760 --> 04:50:45.760]  в массовом департаменте Новосибирска университета.
[04:50:45.760 --> 04:50:49.760]  Много позже я выявил его докторную диссертацию.
[04:50:49.760 --> 04:50:55.760]  И, конечно, мы поговорили о всех этих научных работах за много лет.
[04:50:55.760 --> 04:51:07.760]  И я просто хочу отметить, что все его хорошие работы были сообщены в процедурах.
[04:51:07.760 --> 04:51:12.760]  Но один проблем, который он решил в 2004 году, не был там.
[04:51:12.760 --> 04:51:15.760]  Я называю это проблемой Мюркин-стрима.
[04:51:15.760 --> 04:51:21.760]  И я бы хотел показать вам это, и вы увидите, как элегантно его решение было.
[04:51:21.760 --> 04:51:24.760]  Нужно ли это быть в Springer Volume 2?
[04:51:24.760 --> 04:51:28.760]  Это вопрос, который может быть разобранным.
[04:51:28.760 --> 04:51:31.760]  Окей, я покажу вам его решение.
[04:51:31.760 --> 04:51:33.760]  Да, я помню это.
[04:51:47.760 --> 04:51:52.760]  Так что, надеюсь, все увидят, что он действительно решил проблему.
[04:51:52.760 --> 04:51:55.760]  Окей, теперь мы идем к технической части.
[04:51:55.760 --> 04:52:01.760]  Так что, я расскажу вам о координатах динамика, которые мы создали,
[04:52:01.760 --> 04:52:07.760]  и как они могут решить проблему, который я просто выяснил в первой слайде.
[04:52:07.760 --> 04:52:17.760]  Так что, во-первых, машинная участие больше и больше использована для высоких решений,
[04:52:17.760 --> 04:52:20.760]  как машинной движения, диагностики канцер,
[04:52:20.760 --> 04:52:25.760]  и, к сожалению, многие из этих моделей – черные коробки для конкурентов.
[04:52:25.760 --> 04:52:31.760]  И, конечно, они не людьми интерпретированы, и для высоких решений это неудобно.
[04:52:31.760 --> 04:52:35.760]  Так что, главный цель в очень активной исследовании сейчас –
[04:52:35.760 --> 04:52:40.760]  как сделать эти модели более интерпретированы.
[04:52:40.760 --> 04:52:44.760]  И это один из токсиков моей презентации.
[04:52:44.760 --> 04:52:48.760]  Позвольте мне дать вам один notable example.
[04:52:48.760 --> 04:52:52.760]  Хай-риск пациентам адмитированы в больнице,
[04:52:52.760 --> 04:52:56.760]  и хай-риск пациентам тренируются как хай-пациенты.
[04:52:56.760 --> 04:53:02.760]  Модель, в которой я рассказываю, показывает, что азома корреляет с хай-риск пациентом.
[04:53:02.760 --> 04:53:08.760]  Этот продукт азома-трейтмента, который уничтожает риск пневмонии,
[04:53:08.760 --> 04:53:15.760]  этот закон был интеллигентным, позволяющим его познавать и убрать этот опасный закон.
[04:53:15.760 --> 04:53:20.760]  Но, конечно, если бы это был нейронетворный или глубинный нейронетворный,
[04:53:20.760 --> 04:53:24.760]  то, конечно, это было бы невозможно.
[04:53:24.760 --> 04:53:28.760]  И, конечно, это опасный бизнес.
[04:53:29.760 --> 04:53:34.760]  Так что, первое проблема и объектив,
[04:53:34.760 --> 04:53:39.760]  это, действительно, преодолеть азому корреляции,
[04:53:39.760 --> 04:53:44.760]  чтобы они, по крайней мере, были грамотными или, идеально, transparent boxes.
[04:53:45.760 --> 04:53:51.760]  Так что мы специфично говорим о двух моделях визуально интерпретированных самосервисных моделях,
[04:53:51.760 --> 04:53:55.760]  чтобы распространить оборудование графичных машин.
[04:53:55.760 --> 04:54:00.760]  Я бы хотел бы упомянуть слово «самосервисные модели»,
[04:54:00.760 --> 04:54:06.760]  потому что создание моделей интерпретированных
[04:54:06.760 --> 04:54:09.760]  предполагает, что пользователь согласует с ним.
[04:54:09.760 --> 04:54:13.760]  Так что, это не только вопрос, как хорошо и как много формул,
[04:54:13.760 --> 04:54:17.760]  мы будем писать, и сколько сериалов мы проверяем.
[04:54:17.760 --> 04:54:20.760]  Пользователь должен согласовать с этим.
[04:54:20.760 --> 04:54:23.760]  И, идеально, если пользователь будет участвовать,
[04:54:23.760 --> 04:54:26.760]  то, или, на самом деле, создать модель,
[04:54:26.760 --> 04:54:28.760]  то, вероятность придет с этим.
[04:54:28.760 --> 04:54:32.760]  Не обязательно все время, но это может иметь больше шансов.
[04:54:33.760 --> 04:54:38.760]  Другим проблемом является религиозность машинленических моделей
[04:54:38.760 --> 04:54:40.760]  в сценариях высоких рисков.
[04:54:40.760 --> 04:54:44.760]  К сожалению, как я покажу позже,
[04:54:44.760 --> 04:54:47.760]  многие оборудования машинленических моделей
[04:54:47.760 --> 04:54:50.760]  измениваются в их аккуратности,
[04:54:50.760 --> 04:54:56.760]  что, опять же, неудобно для приложений с высокими рисками.
[04:54:56.760 --> 04:55:01.760]  И, опять же, мы используем визуальный знаний-дискавертический подход
[04:55:01.760 --> 04:55:06.760]  для изменивания и найдения визуальных знаний-дискавертических моделей
[04:55:06.760 --> 04:55:12.760]  для обнаружения лучших алгоритм или моделей для лучших данных.
[04:55:12.760 --> 04:55:15.760]  Это, в основном, концепция функционального функционала.
[04:55:19.760 --> 04:55:22.760]  Теперь несколько слов о визуальных.
[04:55:22.760 --> 04:55:25.760]  Вы можете видеть здесь длинную линию ученых,
[04:55:25.760 --> 04:55:29.760]  которые утверждают, что визуальные играют
[04:55:29.760 --> 04:55:33.760]  наиболее важную роль в их обнаружениях.
[04:55:33.760 --> 04:55:36.760]  Альберт Айнстайн был очень очевиден об этом тоже.
[04:55:39.760 --> 04:55:43.760]  Но проблема в том, как мы можем сделать визуальные обнаружения
[04:55:43.760 --> 04:55:45.760]  в н-дименционных данных,
[04:55:45.760 --> 04:55:48.760]  потому что мы живем в тридименционном мире,
[04:55:48.760 --> 04:55:53.760]  и мы действительно не видим высоких дименционных данных для этого.
[04:55:53.760 --> 04:55:56.760]  Таким образом, сегодняшние подходы, в основном,
[04:55:58.760 --> 04:56:00.760]  основаны на двух причинах.
[04:56:00.760 --> 04:56:02.760]  Несколько-дименционная редакция,
[04:56:02.760 --> 04:56:04.760]  как принципа компонента анализов,
[04:56:04.760 --> 04:56:06.760]  мультидименционного скалинирования
[04:56:06.760 --> 04:56:08.760]  и целый бюджет других методов,
[04:56:08.760 --> 04:56:12.760]  или распределение НД-даталей на два вида низеньких дименционных.
[04:56:13.760 --> 04:56:16.760]  Первый, конечно, потеряет некоторую информацию,
[04:56:16.760 --> 04:56:21.760]  а второй уничтожает интегритет НД-даталей.
[04:56:22.760 --> 04:56:24.760]  Таким образом, наша первая практика,
[04:56:24.760 --> 04:56:27.760]  что мы действительно должны идти от этой практики,
[04:56:27.760 --> 04:56:30.760]  в которой мы пытаемся представить н-дименционные точки
[04:56:30.760 --> 04:56:33.760]  как два-дименционные или три-дименционные точки,
[04:56:33.760 --> 04:56:36.760]  но в действительности представить их как графы в 2D,
[04:56:36.760 --> 04:56:37.760]  а не как точки.
[04:56:37.760 --> 04:56:41.760]  Это как мы можем сохранить информацию НД.
[04:56:41.760 --> 04:56:43.760]  Я покажу несколько примеров.
[04:56:45.760 --> 04:56:48.760]  На левой стороне пример с параллельными координатами,
[04:56:48.760 --> 04:56:51.760]  которые были разработаны более 100 лет назад
[04:56:51.760 --> 04:56:53.760]  и полностью забрали,
[04:56:53.760 --> 04:56:58.760]  пока Альберт Инзелберг в IBM их раздекорировал.
[04:56:59.760 --> 04:57:03.760]  Таким образом, у нас есть 4-дименционные точки 8, 4, 7, 9,
[04:57:03.760 --> 04:57:07.760]  и каждый координат находится вертикально,
[04:57:07.760 --> 04:57:11.760]  и вы связаны с этими точками на каждом координате
[04:57:11.760 --> 04:57:12.760]  как полилайна.
[04:57:12.760 --> 04:57:14.760]  И эта полилайна как граф,
[04:57:14.760 --> 04:57:15.760]  как граф,
[04:57:15.760 --> 04:57:19.760]  однозначно, 1х1 сняли с 4-дименционными точками,
[04:57:19.760 --> 04:57:23.760]  и, однозначно, это можно сделать для любых дименционных точек.
[04:57:24.760 --> 04:57:27.760]  На правой стороне шифрованные координаты,
[04:57:27.760 --> 04:57:28.760]  которые мы разработали.
[04:57:28.760 --> 04:57:30.760]  Так что это не существует за 100 лет,
[04:57:30.760 --> 04:57:32.760]  но это довольно просто.
[04:57:32.760 --> 04:57:37.760]  Так что у нас есть два координата картижи,
[04:57:37.760 --> 04:57:39.760]  шифрованные один за другим.
[04:57:40.760 --> 04:57:43.760]  Так что первая пара значит 8, 4 в 1,
[04:57:43.760 --> 04:57:46.760]  7, 9 в другом координате,
[04:57:46.760 --> 04:57:48.760]  и мы просто связаны с ними
[04:57:48.760 --> 04:57:50.760]  используя аромат.
[04:57:50.760 --> 04:57:52.760]  Еще раз, очень простой граф.
[04:57:53.760 --> 04:57:55.760]  Если сравнивать эти два графа,
[04:57:55.760 --> 04:57:58.760]  вы можете увидеть, что параллельные координаты
[04:57:58.760 --> 04:58:01.760]  требуют 4-дименционных точек и 3 линии,
[04:58:01.760 --> 04:58:06.760]  но шифрованные координаты только 1 линия и 2 точки,
[04:58:06.760 --> 04:58:09.760]  и обе из них неразборчивы,
[04:58:09.760 --> 04:58:11.760]  представляющиеся полностью в 4-дименционных точках
[04:58:11.760 --> 04:58:14.760]  и, однозначно, генерализованы для больших дименционных точек.
[04:58:15.760 --> 04:58:19.760]  Далее у нас есть Лемма Джонсона Линдон-Страйлса.
[04:58:20.760 --> 04:58:23.760]  Они доказали это в 1984 году,
[04:58:23.760 --> 04:58:27.760]  и в 2000 году несколько версий
[04:58:27.760 --> 04:58:29.760]  этого сериала появились без оценки.
[04:58:29.760 --> 04:58:33.760]  Но, в принципе, что это сериал говорит нам,
[04:58:34.760 --> 04:58:37.760]  это говорит нам фундаментальную лимитацию
[04:58:37.760 --> 04:58:40.760]  нд-детей в 2-де.
[04:58:40.760 --> 04:58:43.760]  Это просто означает, что ошибки,
[04:58:43.760 --> 04:58:47.760]  которые мы получим в нижней дименционной точке,
[04:58:48.760 --> 04:58:50.760]  будут очень значимыми.
[04:58:50.760 --> 04:58:53.760]  Я пытаюсь оценивать много деталей,
[04:58:53.760 --> 04:58:57.760]  но, в принципе, заключение очень очевидное.
[04:58:57.760 --> 04:59:00.760]  Мы просто не имеем достаточно близких
[04:59:01.760 --> 04:59:04.760]  с равномерными дистанциями в маленьком дименционном месте,
[04:59:04.760 --> 04:59:08.760]  чтобы представить полностью нд-детей.
[04:59:08.760 --> 04:59:11.760]  Это очень очевидно в бинарном кубе
[04:59:11.760 --> 04:59:13.760]  в 10-дименционном точке,
[04:59:13.760 --> 04:59:16.760]  где мы имеем более тысячи нод,
[04:59:16.760 --> 04:59:18.760]  но в 2-дименционном точке в квадрате
[04:59:18.760 --> 04:59:20.760]  мы имеем только 4 нода.
[04:59:24.760 --> 04:59:27.760]  Что мы действительно делали в этом работе?
[04:59:27.760 --> 04:59:30.760]  Мы изменили динамичные координаты,
[04:59:30.760 --> 04:59:33.760]  визуализировали нд-детей в этих координатах,
[04:59:33.760 --> 04:59:35.760]  без лезвия,
[04:59:35.760 --> 04:59:39.760]  и улучшили распоряжение в классе.
[04:59:40.760 --> 04:59:42.760]  И, опять же, мы нашли наиболее плохую ситуацию
[04:59:42.760 --> 04:59:44.760]  нд-детей, используя эту технику.
[04:59:45.760 --> 04:59:47.760]  Так что главный концепт здесь
[04:59:47.760 --> 04:59:49.760]  это координаты генерала линии,
[04:59:49.760 --> 04:59:52.760]  которые были представлены в 2014 году,
[04:59:52.760 --> 04:59:55.760]  и в деталях это представлено в книге
[04:59:55.760 --> 04:59:57.760]  в 2018 году.
[04:59:58.760 --> 05:00:00.760]  Так что главная идея,
[05:00:00.760 --> 05:00:02.760]  которую я уже выяснил,
[05:00:02.760 --> 05:00:04.760]  это использовать графы вместо точек
[05:00:04.760 --> 05:00:06.760]  для представления нд-детей.
[05:00:06.760 --> 05:00:08.760]  И для многих типов,
[05:00:08.760 --> 05:00:10.760]  мы уже делали в нашем команде,
[05:00:10.760 --> 05:00:12.760]  этот работник,
[05:00:12.760 --> 05:00:14.760]  и этот отдельный работник
[05:00:14.760 --> 05:00:16.760]  работает с одним типом
[05:00:16.760 --> 05:00:18.760]  генерала линии координат.
[05:00:18.760 --> 05:00:20.760]  Хорошо, теперь я просто
[05:00:20.760 --> 05:00:24.760]  иллюстрирую их визуально.
[05:00:24.760 --> 05:00:26.760]  На левой стороне вы можете увидеть
[05:00:26.760 --> 05:00:28.760]  параллельные координаты,
[05:00:28.760 --> 05:00:30.760]  которые я уже объяснил в середине.
[05:00:30.760 --> 05:00:32.760]  Вы можете увидеть модифицированные
[05:00:32.760 --> 05:00:33.760]  параллельные координаты,
[05:00:33.760 --> 05:00:35.760]  где мы позволяем линии
[05:00:35.760 --> 05:00:37.760]  быть не только параллельными,
[05:00:37.760 --> 05:00:39.760]  но в разных направлениях.
[05:00:39.760 --> 05:00:41.760]  Тогда мы можем позволить
[05:00:41.760 --> 05:00:43.760]  все координаты быть на линии,
[05:00:43.760 --> 05:00:45.760]  в одной линии.
[05:00:45.760 --> 05:00:47.760]  Мы можем позволить их быть
[05:00:47.760 --> 05:00:49.760]  на краях нд-детей,
[05:00:49.760 --> 05:00:52.760]  круглых, коверных, линейных.
[05:00:52.760 --> 05:00:54.760]  В основном, у нас есть
[05:00:54.760 --> 05:00:56.760]  огромное количество
[05:00:56.760 --> 05:00:58.760]  возможных координатов генерала линии,
[05:00:58.760 --> 05:01:00.760]  и все из них позволяют
[05:01:00.760 --> 05:01:02.760]  нескольких представлений нд-детей
[05:01:02.760 --> 05:01:04.760]  в контакте с традиционными
[05:01:04.760 --> 05:01:06.760]  автогонными координатами
[05:01:06.760 --> 05:01:08.760]  картижей,
[05:01:08.760 --> 05:01:10.760]  которые только限или
[05:01:10.760 --> 05:01:12.760]  по три размера.
[05:01:12.760 --> 05:01:14.760]  Итак, основная идея,
[05:01:14.760 --> 05:01:16.760]  что когда Декарт
[05:01:16.760 --> 05:01:18.760]  создал его координаты
[05:01:18.760 --> 05:01:20.760]  400 лет назад,
[05:01:20.760 --> 05:01:22.760]  то идея была
[05:01:22.760 --> 05:01:24.760]  описать физическое слово,
[05:01:24.760 --> 05:01:26.760]  которое идеально
[05:01:26.760 --> 05:01:28.760]  соответствует
[05:01:28.760 --> 05:01:30.760]  автогонных три-дименционных координатов.
[05:01:30.760 --> 05:01:32.760]  Но для данного научения
[05:01:32.760 --> 05:01:34.760]  мы действительно должны
[05:01:34.760 --> 05:01:36.760]  идти к этим типам координатов,
[05:01:36.760 --> 05:01:38.760]  потому что они позволяют
[05:01:38.760 --> 05:01:40.760]  представить мультидименционные данные.
[05:01:40.760 --> 05:01:42.760]  Я иногда называю это
[05:01:42.760 --> 05:01:44.760]  нд-детями.
[05:01:44.760 --> 05:01:46.760]  Итак, у нас есть несколько
[05:01:46.760 --> 05:01:48.760]  статностей о
[05:01:48.760 --> 05:01:50.760]  координатах.
[05:01:50.760 --> 05:01:52.760]  В основном, основная из них
[05:01:52.760 --> 05:01:54.760]  то, что
[05:01:54.760 --> 05:01:56.760]  симуляции графов
[05:01:56.760 --> 05:01:58.760]  могут быть соответствованы
[05:01:58.760 --> 05:02:00.760]  с дистанцией между
[05:02:00.760 --> 05:02:02.760]  нд-детями.
[05:02:02.760 --> 05:02:04.760]  Итак, сейчас мы поговорим
[05:02:04.760 --> 05:02:06.760]  о проблемах, которые у нас
[05:02:06.760 --> 05:02:08.760]  здесь.
[05:02:08.760 --> 05:02:10.760]  Во-первых,
[05:02:10.760 --> 05:02:12.760]  мультиплика методов
[05:02:12.760 --> 05:02:14.760]  визуализации
[05:02:14.760 --> 05:02:16.760]  приведет к эффекту,
[05:02:16.760 --> 05:02:18.760]  что то же данные
[05:02:18.760 --> 05:02:20.760]  с разными методами
[05:02:20.760 --> 05:02:22.760]  визуализованы очень разнообразно.
[05:02:22.760 --> 05:02:24.760]  И вы можете видеть
[05:02:24.760 --> 05:02:26.760]  этот пример.
[05:02:26.760 --> 05:02:28.760]  Тем более,
[05:02:28.760 --> 05:02:30.760]  это то же данные,
[05:02:30.760 --> 05:02:32.760]  как и оба атрибута
[05:02:32.760 --> 05:02:34.760]  грамматических изменений визуализации.
[05:02:34.760 --> 05:02:36.760]  Это не только трудно,
[05:02:36.760 --> 05:02:38.760]  но и преимущественно,
[05:02:38.760 --> 05:02:40.760]  потому что
[05:02:40.760 --> 05:02:42.760]  это позволяет найти
[05:02:42.760 --> 05:02:44.760]  визуализацию, где классы
[05:02:44.760 --> 05:02:46.760]  визуализованы очень хорошо,
[05:02:46.760 --> 05:02:48.760]  и, конечно же,
[05:02:48.760 --> 05:02:50.760]  поверить пользователю,
[05:02:50.760 --> 05:02:52.760]  что он или она может
[05:02:52.760 --> 05:02:54.760]  верить в это.
[05:02:56.760 --> 05:02:58.760]  Итак, теперь
[05:02:58.760 --> 05:03:00.760]  еще одна
[05:03:00.760 --> 05:03:02.760]  задача.
[05:03:02.760 --> 05:03:04.760]  У нас здесь
[05:03:04.760 --> 05:03:06.760]  ненавидимые
[05:03:06.760 --> 05:03:08.760]  тридименционные
[05:03:08.760 --> 05:03:10.760]  субсети,
[05:03:10.760 --> 05:03:12.760]  но они не
[05:03:12.760 --> 05:03:14.760]  визуализованы в 3D.
[05:03:14.760 --> 05:03:16.760]  И есть множество примеров
[05:03:16.760 --> 05:03:18.760]  похожих на ненавидимые данные,
[05:03:18.760 --> 05:03:20.760]  но здесь
[05:03:20.760 --> 05:03:22.760]  в визуализации в 2D
[05:03:22.760 --> 05:03:24.760]  они не визуализованы,
[05:03:24.760 --> 05:03:26.760]  они поверны,
[05:03:26.760 --> 05:03:28.760]  и, конечно же,
[05:03:28.760 --> 05:03:30.760]  это не очень полезно
[05:03:30.760 --> 05:03:32.760]  поверить пользователю.
[05:03:32.760 --> 05:03:34.760]  Итак, мы хотим решить этот проблем.
[05:03:42.760 --> 05:03:44.760]  Проверим
[05:03:44.760 --> 05:03:46.760]  еще один слайд.
[05:03:52.760 --> 05:03:54.760]  Хорошо.
[05:03:54.760 --> 05:03:56.760]  И, по какой-то причине,
[05:04:00.760 --> 05:04:02.760]  это холодно
[05:04:02.760 --> 05:04:04.760]  и не позволяет мне
[05:04:06.760 --> 05:04:08.760]  визуализовать слайды.
[05:04:12.760 --> 05:04:14.760]  И...
[05:04:24.760 --> 05:04:26.760]  О, господи...
[05:04:38.760 --> 05:04:40.760]  Ух, наконец-то двигается.
[05:04:40.760 --> 05:04:42.760]  Теперь мне нужно объяснить,
[05:04:42.760 --> 05:04:44.760]  как динамичные кавалерные координаты,
[05:04:44.760 --> 05:04:46.760]  которые мы назвали
[05:04:46.760 --> 05:04:48.760]  ДССР-дизайном.
[05:04:48.760 --> 05:04:50.760]  Итак, мы сначала
[05:04:50.760 --> 05:04:52.760]  добавляем данные
[05:04:52.760 --> 05:04:54.760]  к параллельным координатам,
[05:04:54.760 --> 05:04:56.760]  затем мы изменяем
[05:04:56.760 --> 05:04:58.760]  направления параллельных координатам,
[05:04:58.760 --> 05:05:00.760]  и затем
[05:05:00.760 --> 05:05:02.760]  мы найдем векторы,
[05:05:02.760 --> 05:05:04.760]  которые показаны как
[05:05:04.760 --> 05:05:06.760]  зеленые векторы, которые
[05:05:06.760 --> 05:05:08.760]  идут в каждые эти точки
[05:05:08.760 --> 05:05:10.760]  в параллельных координатах.
[05:05:10.760 --> 05:05:12.760]  И затем мы
[05:05:12.760 --> 05:05:14.760]  подключим зеленые векторы
[05:05:14.760 --> 05:05:16.760]  один за другим,
[05:05:16.760 --> 05:05:18.760]  в основном, подсумевая их.
[05:05:18.760 --> 05:05:20.760]  И теперь вы можете видеть
[05:05:20.760 --> 05:05:22.760]  на правой стороне,
[05:05:22.760 --> 05:05:24.760]  как эта очень нолинейная трансформация
[05:05:24.760 --> 05:05:26.760]  превратила
[05:05:26.760 --> 05:05:28.760]  эти данные
[05:05:28.760 --> 05:05:30.760]  из параллельных координат
[05:05:30.760 --> 05:05:32.760]  в ДССР-1.
[05:05:32.760 --> 05:05:36.760]  И вы можете видеть, что
[05:05:36.760 --> 05:05:38.760]  очень много
[05:05:38.760 --> 05:05:40.760]  зеленых цветов
[05:05:40.760 --> 05:05:42.760]  на них появляются.
[05:05:42.760 --> 05:05:44.760]  Итак, это другая версия
[05:05:44.760 --> 05:05:46.760]  динамичных координат
[05:05:46.760 --> 05:05:48.760]  не основанных на параллельных координатах,
[05:05:48.760 --> 05:05:50.760]  но в шифтных координатах.
[05:05:50.760 --> 05:05:52.760]  В левой стороне вы можете видеть
[05:05:52.760 --> 05:05:54.760]  данные, которые
[05:05:54.760 --> 05:05:56.760]  в шифтных координатах.
[05:05:56.760 --> 05:05:58.760]  Потом, для каждого
[05:05:58.760 --> 05:06:00.760]  момента, в котором
[05:06:00.760 --> 05:06:02.760]  в шифтных координатах
[05:06:02.760 --> 05:06:04.760]  в шифтных координатах
[05:06:04.760 --> 05:06:18.760]  И опять, мы собираем векторы, которые идут от оригинала системы координации к этими точками, и потом мы собираем эти векторы, омитируя первую вектору.
[05:06:18.760 --> 05:06:24.760]  И в результате вы можете увидеть на правой стороне результат этой нолинейной трансформации.
[05:06:24.760 --> 05:06:30.760]  И опять, классы собраны, но не так хорошо, как мы хотели.
[05:06:30.760 --> 05:06:36.760]  Следующий этап, это, на самом деле, скалирование атрибутов.
[05:06:36.760 --> 05:06:48.760]  Так что сейчас мы не просто используем пары координаций, которые были скалированы, но вторые и третьие пары маленькие.
[05:06:48.760 --> 05:06:55.760]  И теперь вы можете увидеть, что с этим треком мы можем иметь гораздо лучшее распространение классов.
[05:06:55.760 --> 05:07:00.760]  И более того, очень видимо, то место, где они перерываются.
[05:07:00.760 --> 05:07:08.760]  Так что это создает базу, чтобы найти наиболее плохие данные ориентирования для алгоритмов.
[05:07:10.760 --> 05:07:15.760]  Так что теперь вы можете увидеть, что мы хотим бороться с редакцией перерыва.
[05:07:15.760 --> 05:07:20.760]  У нас есть несколько вариантов, которые мы в действительности используем.
[05:07:20.760 --> 05:07:22.760]  Первый вариант.
[05:07:22.760 --> 05:07:34.760]  Это создание гиперблоков и анализирование их используя решения-три или любые другие хорошие механизмные методы для хорошей распространения.
[05:07:34.760 --> 05:07:44.760]  Конечно, используя дополнительные атрибуты, как принциповая компонентная анализация, используя их в дополнении к оригинальному атрибуту.
[05:07:44.760 --> 05:07:54.760]  И используя, что сейчас стало популярным, Т-дистрибута, скракастик-набор-имбединг.
[05:07:54.760 --> 05:08:08.760]  Теперь мы идем к следующему слайду.
[05:08:08.760 --> 05:08:14.760]  Это челлендж, чтобы продолжить работать.
[05:08:24.760 --> 05:08:48.760]  Это челлендж для меня.
[05:08:54.760 --> 05:09:18.760]  Это челлендж для меня.
[05:09:18.760 --> 05:09:25.760]  Да, я пытаюсь.
[05:09:25.760 --> 05:09:29.760]  Окей, выглядит так.
[05:09:29.760 --> 05:09:37.760]  Теперь вы можете увидеть два разных перерыва данных, которые мы хотим убрать.
[05:09:37.760 --> 05:09:41.760]  И вы можете увидеть, что они имеют другую важность.
[05:09:42.760 --> 05:09:49.760]  Один не очень влияет на классификацию, и другой влияет.
[05:09:49.760 --> 05:09:53.760]  Так что мы должны быть смогли увидеть это.
[05:09:53.760 --> 05:09:56.760]  Окей, сейчас я покажу технику.
[05:09:56.760 --> 05:10:00.760]  Во-первых, я должен представить хайперблок-концепцию.
[05:10:00.760 --> 05:10:08.760]  Это, в основном, генерализация ректангла в н-дименционном месте, называется н-ортотоп.
[05:10:08.760 --> 05:10:12.760]  И что мы пытаемся сделать?
[05:10:12.760 --> 05:10:20.760]  Мы создали решение-три и использовали самые информативные атрибуты решения-три,
[05:10:20.760 --> 05:10:26.760]  как первые координаты, которые мы будем использовать в данных.
[05:10:26.760 --> 05:10:36.760]  Итак, теперь вы можете увидеть другую данную с ее решением-три.
[05:10:36.760 --> 05:10:42.760]  И вы знаете результат, используя метод, который я описал.
[05:10:42.760 --> 05:10:51.760]  Когда атрибуты мы скалируем, и мы также можем использовать решение-три-гайданс.
[05:10:51.760 --> 05:11:00.760]  И вы можете увидеть, что некоторые из самых плохих случаев являются очень видными для консервных решений.
[05:11:02.760 --> 05:11:03.760]  Окей.
[05:11:03.760 --> 05:11:09.760]  Теперь это похожие вещи для висконсианского брест-канцерного данного и решение-три.
[05:11:09.760 --> 05:11:39.760]  И снова, это результат данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного данного
[05:11:39.760 --> 05:11:43.400]  тан 10hip
[05:11:43.400 --> 05:11:44.300]  ...
[05:11:44.300 --> 05:11:48.900]  ...
[05:11:48.900 --> 05:11:53.020]  ...
[05:11:53.020 --> 05:12:00.040]  ...
[05:12:00.040 --> 05:12:01.780]  ...
[05:12:01.780 --> 05:12:02.520]  ...
[05:12:02.520 --> 05:12:05.900]  ...
[05:12:05.900 --> 05:12:06.740]  ...
[05:12:06.740 --> 05:12:06.860]  ...
[05:12:06.860 --> 05:12:07.780]  ...
[05:12:07.780 --> 05:12:08.180]  ...
[05:12:08.180 --> 05:12:17.540]  и т.д. на 10-фолд-кросс-валидации данных на том же данном,
[05:12:17.540 --> 05:12:22.980]  которое я показал вам раньше, и вы можете видеть, что на уровне 10-фолд-кросс-валидации
[05:12:22.980 --> 05:12:30.340]  победитель является поддержательная веер-машина, но в худшем случае это рандомная леса,
[05:12:30.900 --> 05:12:40.260]  и вы видите, разница очень драматична между 97% и 61,9% и мультилиниевая персептрон
[05:12:40.260 --> 05:12:52.660]  была очень ужасная от 89% до 23%, так что для рискованных задач это было бы
[05:12:52.740 --> 05:13:00.100]  действительно не satisfiable to use SVM, which in the worst case just shown 38%.
[05:13:02.660 --> 05:13:09.220]  Similar for the cancer data, but different algorithm is a winner here, EKNN for
[05:13:09.940 --> 05:13:18.020]  10-fault-cross-validation, but naive bias for worst case, and obviously cancer
[05:13:18.020 --> 05:13:25.780]  case it's definitely a high-risk task, and now I can show how we try to work with
[05:13:26.900 --> 05:13:35.300]  missed and written digits, which total data set contains 60,000 images, and on the left it's
[05:13:35.300 --> 05:13:43.860]  smaller standard t-SNA visualization, and on the right with our additions, basically t-SNA
[05:13:43.860 --> 05:13:49.380]  represents them as a single point, and we show as graphs, of course, it needs to be zoomed
[05:13:49.380 --> 05:13:55.140]  multiple times to see details, so it provides more information for analysis.
[05:13:55.140 --> 05:14:16.660]  So there are several other methods proposed in the literature. Most popular today it's LIME,
[05:14:16.660 --> 05:14:22.500]  Local Interpretable Model Agnostic Explanations developed at the University of Washington.
[05:14:23.460 --> 05:14:30.100]  What do they do? They use linear machine learning models to interpolate relations between
[05:14:30.100 --> 05:14:38.020]  input and output at the local level, and assumption is that linear models are always interpretable.
[05:14:38.660 --> 05:14:44.340]  We actually challenge this assumption, because for heterogeneous data like medicine,
[05:14:44.340 --> 05:14:52.420]  where we have temperature, blood pressure, it is not so obvious, and we call them quasi-explainable.
[05:14:53.060 --> 05:15:00.100]  But in contrast, hyperblocks as a generalization of decision trees are 100% interpretable.
[05:15:01.140 --> 05:15:10.340]  So Charles obviously developed all this software, and with his skills he was just hired by machine
[05:15:10.340 --> 05:15:19.620]  learning group at Amazon. And in conclusion, as you can see, those new visualization methods
[05:15:20.340 --> 05:15:26.580]  are lossless and allow dual visualization, classification, and analysis of data.
[05:15:28.100 --> 05:15:33.380]  And hyperblocks have advantages that they build more complex models than decision trees.
[05:15:35.460 --> 05:15:42.180]  And teaching engineering, like adding additional features, I demonstrated as another way to improve
[05:15:42.180 --> 05:15:50.900]  the situation. And again, worst case validation is doable in this visual way,
[05:15:50.900 --> 05:15:55.620]  and convincing the user to trust or not to trust a particular method.
[05:15:57.220 --> 05:16:04.020]  Future work obviously is going to more complex, larger data sets, and more efficient methods.
[05:16:04.020 --> 05:16:13.700]  These are a few illustrations when we basically only visualize hyperblock centers,
[05:16:14.580 --> 05:16:20.820]  similar to popular clustering approaches, which Boris Mirkin worked for years.
[05:16:21.460 --> 05:16:24.740]  And on the right, another option. That's basically it in my talk.
[05:16:34.020 --> 05:16:36.020]  Thank you for watching!
[05:17:04.020 --> 05:17:20.260]  Yes, a good question. Yes, we have, of course, those algorithms too, and we actually compare it,
[05:17:20.900 --> 05:17:28.020]  how competitive automatic algorithm is with the human, and in some cases humans were actually
[05:17:28.020 --> 05:17:36.500]  better. But definitely you are right. And we used, one of the ideas was, of course,
[05:17:36.500 --> 05:17:44.900]  because it's a two-dimensional image, we can scan this image and find at least pure areas.
[05:17:45.620 --> 05:17:53.860]  In contrast to multidimensional space, it's quite an easy way. Another option was to use
[05:17:54.740 --> 05:18:00.420]  a support vector machine. They support vectors and explore areas close to them,
[05:18:00.420 --> 05:18:11.700]  because they are supposed to be close to the border, so guiding the human and automatic algorithm.
[05:18:23.860 --> 05:18:35.060]  Theoretically, yes. But the problem is that for each algorithm the area is not the same.
[05:18:35.700 --> 05:18:44.660]  So if you believe, for example, if we decide that a support vector machine is the best one
[05:18:45.620 --> 05:18:53.860]  for, say, some other reason than pure accuracy, then, of course, we can pick up those areas
[05:18:53.860 --> 05:18:59.940]  where it did not work well and use, say, K&N in those areas. Yeah, that's good.
[05:19:11.220 --> 05:19:11.720]  Sure.
[05:19:14.660 --> 05:19:26.660]  Yeah, sure. No problem. Basically, you need to ask Boris Grigorievich.
[05:19:29.940 --> 05:19:40.420]  I don't have them. I have no these pictures. So, Boris, it's really quite beautiful pictures. I've never
[05:19:40.420 --> 05:19:42.820]  seen them. That's it.
[05:19:49.060 --> 05:19:56.420]  Thank you.
[05:20:10.420 --> 05:20:12.420]  Thank you.
[05:20:40.420 --> 05:20:52.020]  Which are alternatives that are the best alternative for at least one
[05:20:54.260 --> 05:21:02.900]  person in a society and beds. Not alternatives that everybody hates, but alternatives that everybody
[05:21:02.900 --> 05:21:11.540]  does not put on a top of preference profile, preference order. So we have goods which are
[05:21:12.740 --> 05:21:20.100]  best alternative for at least one and beds which are not best alternative.
[05:21:21.700 --> 05:21:28.020]  So, and I said structured preferences. So we have structured preference space, structured
[05:21:28.020 --> 05:21:33.220]  alternative space, and a second significance, structured preference space. So the most
[05:21:33.220 --> 05:21:41.700]  influential example is single pick preferences. So we have a line where we have alternatives and
[05:21:43.060 --> 05:21:53.220]  agents ideal points. And the further alternative is from ideal points, the worse it is. So
[05:21:53.220 --> 05:21:58.900]  we have different types of single pick preferences. So
[05:22:02.100 --> 05:22:08.180]  general single pick preferences. We have a line and all alternatives on one line. We have
[05:22:08.180 --> 05:22:15.700]  error single pick preferences. So we have single pick on each triple. We have a single picked on a
[05:22:15.700 --> 05:22:24.820]  circle. So the same idea. So we have circle topology and we have so agents ideal points
[05:22:24.820 --> 05:22:33.300]  and alternatives on the same circle. And fishbone domains where we mix single pickiness and single
[05:22:33.300 --> 05:22:47.060]  deepness. So formally we can introduce single pick preferences as the following. So domain of
[05:22:47.060 --> 05:22:53.780]  single pick preferences is defined by an axis. We have a linear order over x. This is an axis.
[05:22:53.780 --> 05:23:01.140]  A preference profile pi is single picked with respect to an axis a. If for each agent the upper
[05:23:01.140 --> 05:23:11.220]  countersets are connected according to this axis. So we do not define distance between
[05:23:11.220 --> 05:23:16.980]  alternatives. We do not define distance between agents and alternatives. So we have the following
[05:23:16.980 --> 05:23:24.820]  property there, ideal points. And we can order all alternatives to the left and order all alternatives
[05:23:24.820 --> 05:23:32.100]  to the right. And we cannot compare alternatives from the left and from the light from ideal point.
[05:23:32.100 --> 05:23:42.340]  And this property we have connected upper countersets are very useful in computer science.
[05:23:42.340 --> 05:23:50.900]  So we have matrices with consecutive ones and we can utilize this property in algorithms
[05:23:51.460 --> 05:23:57.140]  and many problems within single pick preferences becomes attractable
[05:23:58.820 --> 05:24:08.180]  whenever in general some problems are NP-hard. So we can imagine any
[05:24:09.540 --> 05:24:13.300]  preference model. So we can think that a society
[05:24:13.300 --> 05:24:25.060]  sometimes people are clustered. So we have not all possible preference order in society but
[05:24:25.060 --> 05:24:34.420]  some subset of preference orders. And this subset is called domain. And we can imagine a variety of domains.
[05:24:35.380 --> 05:24:48.980]  And we need to think that these domains have some properties and we want to restrict our domains
[05:24:48.980 --> 05:24:57.220]  to domains with good interpretable properties. And these are these properties. So
[05:24:57.300 --> 05:25:04.820]  firstly, we want to have counterset domains. So within this domain every profile composed from
[05:25:04.820 --> 05:25:15.700]  preferences from this domain has a cyclic majority relation. And in economics, political science,
[05:25:15.700 --> 05:25:24.500]  computer science, first of all we study counterset domains. And these domains are
[05:25:24.500 --> 05:25:34.180]  so leads to transitive majority relation, have graphical representation,
[05:25:34.180 --> 05:25:42.020]  simplifies computationally hard problems and so on. And within these domains these domains are also
[05:25:44.500 --> 05:25:53.140]  very different and not all of them are have good interpretation. So we have properties within
[05:25:53.140 --> 05:25:59.220]  counterset domain. So counterset domain D is connected if every two orders from the domain can be
[05:25:59.220 --> 05:26:04.660]  obtained from each other by a sequence of transposition of neighboring alternatives.
[05:26:04.660 --> 05:26:14.100]  Such that the resulting order belongs to the domain at each step. So this means that we do not require
[05:26:14.100 --> 05:26:27.300]  big shifts, big changes in preferences. So you can always find something close to your
[05:26:27.300 --> 05:26:36.260]  current preference order. So maybe within only one swap of preferences. So a counterset domain has
[05:26:36.260 --> 05:26:46.980]  maximal width if it contains a pair of completely reverse linear orders. So we allow diversity, we allow
[05:26:50.660 --> 05:26:59.860]  really different opinions in our society. A counterset domain D is minimally rich if for each alternative
[05:27:00.500 --> 05:27:07.620]  there is an order from the domain such that this order has alternative X as a top alternative.
[05:27:07.620 --> 05:27:20.340]  So minimally richness reflects properties that all alternatives are good, that for each alternative
[05:27:20.340 --> 05:27:27.620]  there is an agent, there is a preference order such that this alternative is a top alternative.
[05:27:28.180 --> 05:27:35.460]  And in my paper I want to weaken this property to weak minimal richness.
[05:27:36.660 --> 05:27:47.540]  So this alternative, each alternative is either top or bottom alternative in at least one preference
[05:27:47.540 --> 05:27:53.540]  order. So we have if you have top alternative, so it is good alternative, if we have bottom alternative,
[05:27:53.540 --> 05:28:03.300]  it is in some sense bad. And what we have? We have classic characterization of single peak domain.
[05:28:03.300 --> 05:28:09.780]  So each single peak domain is connected and minimally rich. A counterset domain with maximal width
[05:28:10.820 --> 05:28:18.900]  so and we have if and only if. So it is really characterization of single peak domain.
[05:28:18.900 --> 05:28:30.180]  And if we weaken minimally richness to weak minimally richness, we get the class of GF domains.
[05:28:30.180 --> 05:28:39.380]  So the definition would be here. So it is the following structure. We have a linear ordering of alternatives
[05:28:40.340 --> 05:28:52.420]  A1AM and a subset A such that if a triple, so for each triple of alternatives
[05:28:52.420 --> 05:29:07.860]  AI, AJ, AK, if the median of this number belongs to this set, so AJ belongs to set A, then this
[05:29:07.860 --> 05:29:22.340]  triple is single dipped. If the median belongs to set X minus A, then this triple is single dipped.
[05:29:22.340 --> 05:29:34.660]  So we can mix single peakness and single deepness. And so from first view it is strange, so we cannot
[05:29:34.660 --> 05:29:41.780]  interpret this definition what the meaning of these preferences, but the following proposition
[05:29:43.140 --> 05:29:53.700]  introduces a very good picture. So single peaked on a circle. So we have a circle with alternatives,
[05:29:53.700 --> 05:30:01.700]  with ideal points, with the same meaning of single peakedness. And what is interesting, GF domain
[05:30:01.700 --> 05:30:06.660]  is a subset of a spoke domain. So single peaked on a circle domain. So single peaked on a
[05:30:06.660 --> 05:30:12.900]  circle domain is not a condensate domain. So single peaked on a circle domain is a very big domain. It
[05:30:12.900 --> 05:30:27.620]  contains cycles, so the majority relation can be cyclic. And GF domain is the biggest condensate domain
[05:30:27.620 --> 05:30:36.980]  within a single peaked on a circle domain. And we can introduce the following picture. So it's the main
[05:30:36.980 --> 05:30:48.900]  picture of my talk. So we have a circle and we partition all alternatives on inside alternatives
[05:30:48.980 --> 05:30:57.940]  and outside alternatives. So goods and bads. And what is the meaning of this inside and outside
[05:30:57.940 --> 05:31:03.620]  alternatives? So we have two interpretations, at least two, so we can introduce many of them.
[05:31:04.900 --> 05:31:11.860]  So there is a lake and a beach which occupies an interval of lake coast. All agents take a rest on
[05:31:11.860 --> 05:31:19.380]  a beach. Alternatives are locations of ice cream stands. Some of them are inside. The beach,
[05:31:19.380 --> 05:31:26.980]  inside alternatives, other outside. Some outside alternatives are better than some inside alternatives
[05:31:26.980 --> 05:31:33.140]  for some agents, but there is no agent which has an outside alternative as the first choice.
[05:31:33.780 --> 05:31:46.820]  So all people have a rest on a beach, so within this dotted area, and they can think that the closures
[05:31:46.820 --> 05:31:55.220]  are better, and they can think, they can compare outside alternatives. So the place is outside the
[05:31:55.220 --> 05:32:03.700]  beach, but all of them think that inside beach there are better alternatives than outside the beach.
[05:32:04.660 --> 05:32:14.180]  So another interpretation is time or calendar circle. 24 hours circle has common working hours
[05:32:14.180 --> 05:32:20.660]  interval. A video conference session should be proceeded every day at exactly the same time slot,
[05:32:21.380 --> 05:32:27.940]  and all agents prefer to do it within working hours, but they can also compare outside alternatives.
[05:32:30.660 --> 05:32:37.620]  So if we have calendar or 365 days circle has a common school holidays interval,
[05:32:38.500 --> 05:32:44.260]  students are going to have a trip, and all agents prefer to do it within their holidays,
[05:32:44.260 --> 05:32:51.060]  so students can discuss other options. So I generalize standard preference model
[05:32:51.060 --> 05:33:00.820]  adding outside options. So preference model within inside options is
[05:33:04.260 --> 05:33:12.660]  introduced earlier, single pick preferences, other examples, and if we add
[05:33:12.660 --> 05:33:25.300]  outside alternatives, which are comparable, but not the best, we can think about more general
[05:33:25.300 --> 05:33:33.220]  preference model, and this more general preference model can be transitive, so it is
[05:33:33.380 --> 05:33:41.780]  Condorcet domain, and it is interpretable this picture. So we can also think about
[05:33:42.580 --> 05:33:53.460]  some circle town, for example, Moscow, and we can think about airport outside Moscow. So nearby Moscow,
[05:33:53.460 --> 05:34:03.780]  we can think that we should choose a point where we will have a new airport, and the same, so we have
[05:34:05.220 --> 05:34:13.380]  some inside alternatives, so some possible points outside and so on.
[05:34:14.340 --> 05:34:19.780]  So that's all for today. Thank you for your attention.
[05:34:22.900 --> 05:34:27.300]  I am brave and that's all. Thank you very much.
[05:34:31.300 --> 05:34:40.180]  I would like to thank everybody who participated in so many ways
[05:34:40.260 --> 05:34:51.300]  that this conference became a reality, and I hope that we meet much more frequently, but for sure
[05:34:51.300 --> 05:35:01.220]  for 90 years celebration of Boris Milton. Please, Boris, remember, you are responsible.
[05:35:02.740 --> 05:35:06.260]  Any questions, especially online?
[05:35:10.180 --> 05:35:31.300]  Yes, just from what I understand, you presented a model, but there are no theorems at this point, or lemmas, like...
[05:35:40.980 --> 05:35:49.540]  by connectedness, by weak minimum richness, and mass knowledge. All right, thank you.
[05:35:54.100 --> 05:36:03.380]  So again, happy birthday to you, Boris, and thank you again. Everybody, we
[05:36:04.340 --> 05:36:10.340]  are going to complete and to start our preparation for the next conference.
[05:36:11.460 --> 05:36:20.100]  Also, I use this opportunity to invite everybody who has not yet contributed to the book,
[05:36:21.060 --> 05:36:31.140]  because I believe you have a couple of hours to submit your contributions. Thank you again.
[05:36:33.380 --> 05:36:43.140]  Okay, see you next time.
