[00:00.000 --> 00:12.480]  Окей, а сегодня у нас четвертая лекция, и мы продолжим, и, надеюсь, закончим говорить о
[00:12.480 --> 00:17.920]  крещайших путях в графах. В общем, у нас сегодня будут две таких разноплановых,
[00:17.920 --> 00:23.320]  два разных направления. Давайте обсудим. Первое – это двунаправленный алгоритм.
[00:23.320 --> 00:37.520]  В чем их суть? Все задачи, которые мы с вами решали, они ставились, как у нас есть пара вершин.
[00:37.520 --> 00:42.880]  Вообще у нас, точнее, одна вершина, и мы хотим либо найти крещайшие пути от нее до всех остальных,
[00:42.880 --> 00:50.480]  либо вообще между всеми парами. И рассматривали разные графы, если это 0kbfs веса 0.123k, если это
[00:50.480 --> 00:55.920]  до x веса, они отрицательные, форт Белман, вообще любые. В этот раз задача будет стоять
[00:55.920 --> 01:10.680]  немножко по-другому. Дан граф, хотим дист от s до t, где s и t – это конкретные вершины, уже
[01:10.680 --> 01:16.480]  определенные. Действительно, нам в реальной жизни, когда мы ищем крещайший путь, мы, скорее всего,
[01:16.480 --> 01:27.160]  ищем путь от чего-то до чего-то, а не от чего-то до всего остального. И рассмотрим, что рассмотрим?
[01:27.160 --> 01:41.080]  Рассмотрим в случае а, это двунаправленный bfs. Как ставится задача? Давайте мы 0k не будем
[01:41.080 --> 01:45.280]  рассматривать. Будем рассматривать просто произвольный граф, где есть вершина s,
[01:45.280 --> 01:50.680]  есть вершина t, есть какое-то облако между ними. Это может как-то петлять путь.
[01:50.680 --> 02:14.040]  Что мы будем делать? Заведем очереди qs и qt. Вот такое, что у нас будет bfs и t одновременно
[02:14.040 --> 02:19.880]  распространяться из вершины s такими волнами и одновременно из вершины t.
[02:19.880 --> 02:24.920]  Вы знаете, что если граф ориентированный, то из вершины t мы будем ходить по развернутым рябрам.
[02:24.920 --> 02:47.880]  Для bfs из s и bfs от t в g-транспонированном. И мы будем запускать их параллельно. Каким
[02:47.880 --> 02:53.120]  образом мы это добьемся? Как вы помните, у нас bfs какой-то ваил. Пока очередь не пустая,
[02:53.320 --> 02:58.640]  вытаскиваем вершины, обновляем расстояние, бла-бла-бла. Что мы здесь будем делать? Давайте мы будем
[02:58.640 --> 03:06.720]  проверять, чтобы у нас пока никакого из очередей не пусто. И при этом мы будем извлекать и qs,
[03:06.720 --> 03:14.720]  и qt-вершинки, и внутри одной тарасы этого ваила их релаксировать. Что тогда? Тогда
[03:14.720 --> 03:28.480]  нужно понять, где достигается оптимум. Пусть будет вершинка f и напишем определение. Пусть f
[03:28.480 --> 03:54.200]  это такая вершина, что ее первой извлекли из qs и qt. Ну, можно сказать и так. То есть
[03:54.200 --> 04:02.480]  вместо встречи двух волн. В это время у вас просто не факт, что они одновременно ее извлекут,
[04:02.480 --> 04:12.600]  но оптимальная картинка выглядит как-то вот так вот. И тут у физиков должны начать волн
[04:12.600 --> 04:23.480]  и складываться. Тогда что утверждается? Когда мы извлекаем вершинку из очереди bfs,
[04:23.480 --> 04:29.520]  а мы уже нашли до нее кратчайший путь, утверждается. Мы говорили, что мы храним вершинки
[04:29.520 --> 04:35.200]  по оценке сверху на кратчайший путь, и дальше как только мы извлекаем, мы говорим, что эта оценка
[04:35.200 --> 04:41.800]  точна. Здесь мы просто храним по кратчайшему расстоянию, поэтому кратчайший путь устроен как-то
[04:41.800 --> 04:55.520]  вот так вот. Вот сюда, сюда. Зачем это нам надо? Ну, здесь и далее я буду пользоваться интересным
[04:55.520 --> 05:04.800]  таким соображением. Наверное, все узнают, как выглядит карта Европы. Сейчас будет примерно
[05:04.800 --> 05:20.160]  урок рисования. Это типа Италия. Конечно, есть что-то вот сюда. Есть что-то типа вот здесь вот
[05:20.160 --> 05:32.240]  какой-то штуки. Ну да, здесь Балканы. Часто здесь вот где-то Греция находится. Где-то здесь Рим.
[05:32.240 --> 05:40.200]  И допустим, вы хотите искать кратчайший путь из Рима в Афина. Зачем-то вам понадобилось? Не знаю,
[05:40.200 --> 05:47.400]  у вас европейская турнира. Хотя не знаю, как скоро она может быть в наших реалиях, но допустим. И что
[05:47.400 --> 05:57.880]  бы делал ваш обычный БФС? Как бы волны были бы устроены? Вот так вот. Ну, то есть понятно,
[05:57.880 --> 06:04.480]  что вы захватываете какой-то лишний огромный кусок. В Афинах у вас бы аналогично бы распространялись
[06:04.480 --> 06:11.960]  волны из них. А в случае, если у вас двухсторонний БФС, то вы на этом этапе уже найдете пересечение,
[06:11.960 --> 06:16.760]  по сути. И у вас не будет вот этих вот огромных волн дальше распространения.
[06:16.760 --> 06:29.680]  Но я не претендую на историческую и географическую точность. На географическую,
[06:29.680 --> 06:41.480]  скорее, да. Вот. То есть у вас как бы гораздо меньше вершин будет затронута. Окей. Ну,
[06:41.480 --> 06:45.360]  казалось бы, граф дорог это, конечно, классно. Но причем тут БФС, потому что у нас там,
[06:45.360 --> 06:52.120]  мы считали за вершины перекрестки, за дороги мы считаем дороги между ними,
[06:52.120 --> 07:02.480]  внезапно за ребра. И мы берем его вес как, что? Ну, внезапно как среднее время проезда этой дороги.
[07:02.480 --> 07:08.640]  То есть у нас как получается вообще вещественные числа. БФС здесь не очень подходит. Давайте
[07:08.640 --> 07:23.080]  перейдем к следующему. Двусторонний и двунаправленный принципиально. Да,
[07:23.080 --> 07:28.920]  если захочется погуглить, то по-русски Google находит как двунаправленный, так двусторонний,
[07:28.920 --> 07:38.200]  по-английски это bidirection. Да, сразу для некоторых по-английски фамилия Dx пишется
[07:38.200 --> 07:50.400]  именно вот так вот, а не как в тех посылках, которые я просматривал. Ну, в общем-то традиции
[07:50.400 --> 07:55.600]  я не буду изменять и сделаю все то же самое. То есть также запущу из СССР одновременно Dx,
[07:55.600 --> 08:07.280]  да? Ну, все то же самое по сути. Давайте рассмотрим пример.
[08:07.280 --> 08:36.200]  Какая вершина будет первой из обеих чередей? Через нее проходит кратчайший путь? Засада. Не
[08:36.200 --> 08:44.360]  работает, получается, алгоритм. Вот, здесь его надо модифицировать. В случае Dx делается все вот так.
[08:44.360 --> 09:09.880]  Пусть F это первая извлеченная из обеих чередей. Вершина тогда... Что можно сказать тогда? Тогда
[09:09.880 --> 09:26.280]  ответ будет выглядеть вот так вот. Это минимум из двух величин. Dx от S до F плюс Dx от F до T. И
[09:26.280 --> 09:32.560]  вторая врачина будет куда интереснее. То есть это вот то, что мы сами получали в ходе вот
[09:32.560 --> 10:02.080]  этой вот конструкции. Dx от S до U плюс Dx от V до T. И еще скобку. О, такая вот штука.
[10:02.200 --> 10:07.800]  Что это значит? Это значит, что давайте обозначим за S множество тех вершин,
[10:07.800 --> 10:29.520]  таких, что Dx от S до U уже известно точно. Но, аналогично T, U, что Dx от U до T известно.
[10:29.520 --> 10:40.840]  Вот почему неверно, когда мы извлекаем в момент одну вершинку? Потому что, на самом деле,
[10:40.840 --> 10:50.400]  вдруг у нас в очереди, в наших очередях обеих, кто хранится? Хранятся, хранится такое вершина,
[10:50.400 --> 10:55.280]  что между ними есть ребро и есть путь лучше. То есть мы знаем, что в этой, когда мы вытаскиваем
[10:55.280 --> 11:03.280]  эту вершину из QS, у нас же в QS что находится? Как тройка, так и четверка. И когда мы вытаскиваем
[11:03.280 --> 11:07.280]  тройку, мы действительно делаем, как в алгоритме Dx, здесь то же самое. Но проблема в том, что у вас
[11:07.280 --> 11:13.240]  вот это вот ребро, оно может быть лучше, чем сумму вот этих вот бух. Поэтому вам нужно
[11:13.240 --> 11:22.520]  привязать серебра между очередями. Собственно, это здесь и делается. Вот. Собственно, это доказывает
[11:22.520 --> 11:27.800]  этого утверждения. Почему не нужно рассматривать другие вершинки, другие ребра точнее? Думаю,
[11:27.800 --> 11:35.720]  плюс-минус понятно. Потому что у вас, если у вас вершинка не в очереди QS, значит она где-то
[11:35.720 --> 11:41.960]  еще дальше. И она либо в QT, либо она вообще не участвует в кратчайшем пути. Если она в QT,
[11:41.960 --> 11:47.160]  вы ее найдете. Если она нет в QT, значит она где-то вообще далеко. И если мы до нее даже не
[11:47.160 --> 11:53.440]  добрались, значит очевидно, что есть путь короче. Вот. Строго доказывать я это не буду, потому что не
[11:53.440 --> 12:02.760]  хочу. Так, это по двусторонним алгоритмам. Есть ли вопросы? Собственно, чем они хорошо тем,
[12:02.760 --> 12:10.840]  что они работают на специальных графах гораздо быстрее, чем обычный алгоритм. С одной стороны,
[12:10.840 --> 12:17.000]  с другой стороны, мы жертвуем функциональностью тем, что мы заедем и ограничиваем себя от одной
[12:17.000 --> 12:25.440]  вершины до другой. Не от одной вершины до всех. Проблем нет, но зависит от того,
[12:25.440 --> 12:32.320]  какую задачу вы решаете, тот инструмент выбираете. Это в принципе применимо не только к алгоритмам.
[12:32.320 --> 12:42.880]  Здесь вам нужно поддерживать множество извлеченных вершин с каждой очереди. Ну да, как-то понимаете,
[12:42.880 --> 12:49.160]  узнаватели пересечения, у вас множество излеченных из QS, множество излеченных из QT. Когда вы извлекаете
[12:49.160 --> 12:55.520]  из нас, проверите, извлечена ли она из QT. Ну, unordered set, быстро проверяйте. Можно вектор булов.
[12:55.520 --> 12:59.640]  Если у вас есть хорошая маска вершин в инты, то да, можно вектор булов. В общем случае, это будет
[12:59.640 --> 13:11.360]  unordered set, конечно же, как вы узнали на ревью. Окей, что мы хотим дальше? Хочется обсудить вот,
[13:11.360 --> 13:16.280]  что некоторые графы, в общем-то, не обязательно помещать все целиком в память. Почему? Ну,
[13:16.280 --> 13:23.720]  допустим, я хочу посчитать расстояние от Афины до Рима, как на той картинке. Что тогда? Наверное,
[13:23.720 --> 13:33.000]  весь граф дорог Европы немножко большой. Точных чисел я не нашел и для России не нашел. Нашел
[13:33.000 --> 13:46.040]  для США количество чисел, ну, оценки, короче. Вот на 2010 год число, ну, давайте в таком
[13:46.040 --> 13:55.040]  представлении считается, что модуль V порядка 24 на 10 в шестой, и Е порядка 60 на 10 в шестой,
[13:55.040 --> 14:01.560]  что-то такое. Ну, много, много. Угадалось бы, в списке конференции не очень много, да, в памяти
[14:01.560 --> 14:06.640]  можно целиком загрузить, да, и нормально в целом. Ну, как-то не очень хочется загружать оперативку
[14:06.640 --> 14:15.040]  такими данными. Все-таки это, конечно, влезет, но это будет долго. Это раз, два, ну, Е лог В,
[14:15.040 --> 14:22.280]  окей, хорошо, будет считаться плюс-минус норм. Но, опять же, у вас там всякие структуры,
[14:22.280 --> 14:26.760]  которые требуют очереди и так далее. Ну и, суммарно, все замедляется, становится очень долгим.
[14:26.760 --> 14:34.800]  Вот. Что предлагается делать? Давайте предложим так называемый евристический поиск. Что это значит?
[14:34.800 --> 14:42.480]  Вообще, евристика — это такая некая идея, пришедшая сверху. Мы определим ее немножко по-другому.
[14:42.480 --> 14:58.520]  Что евристика — это некоторое знание о задаче. Например, алгоритм Dx не обладает никакими
[14:58.520 --> 15:02.440]  евристиками, потому что он просто ищет в произвольном графе пути. Но вот у вас есть,
[15:02.440 --> 15:08.720]  смотрите, в контесте задача пятнашки. Это, если кто не знает, у вас есть там квадрат 4 на 4,
[15:08.720 --> 15:18.080]  и у вас есть одна дырочка свободная в нем. Все остальные плитки расписаны,
[15:18.080 --> 15:29.320]  ну, обычно вот здесь помещаются, и пишутся числа от 1 до 15. Ну и суть головонки в том,
[15:29.320 --> 15:32.760]  что вам дали в каком-то произвольном положении, и вам нужно ее привести к такому виду,
[15:32.760 --> 15:37.200]  где вы можете двигать плитки только на свободное место. То есть, например, вы можете один сдвинуть
[15:37.200 --> 15:44.760]  сюда, и у вас свободное место станет вместо единички. Но если перебрать, то число вершин в графе будет
[15:44.760 --> 15:56.520]  n!2. Ну, n здесь 15, 15!2 — это даже 16, n16!2 — это много. Будем честны. Вот, поэтому перебрать-то не
[15:56.520 --> 16:01.560]  очень хочется целиком, хотя до иксера просто бы перебирал бы явное, и то есть в нем было
[16:01.560 --> 16:08.120]  экспоненциальное время. Вот, и в общем случае наши евристические алгоритмы будут зависеть от того,
[16:08.120 --> 16:12.720]  какие евристики мы используем, и мы не будем нигде строго оценивать их время работы. Почему?
[16:12.720 --> 16:17.520]  Ну, потому что банально это очень сложно, потому что у вас для каждой задачи свои евристики, ну и
[16:17.520 --> 16:23.800]  как-то вообще непонятно, как классифицировать, вот. Ну и, короче, как-то так, вы будете просто
[16:23.800 --> 16:28.480]  надеяться на удачу, когда вы будете их писать. Вот, однако есть некоторая теория касательно
[16:28.480 --> 16:32.680]  кратчайших графов, которую мы сейчас с вами будем обсуждать. Собственно, евристика — это
[16:32.680 --> 16:36.240]  некоторое знание, евристический алгоритм — это алгоритм, обладающий евристиками.
[16:36.240 --> 16:59.320]  Алгоритм, использующий евристики. Окей, и такой алгоритм евристический мы будем
[16:59.320 --> 17:11.960]  изучать этот алгоритм Астар. Астар, а звездочка, а звезда, как его еще можно назвать, вроде больше
[17:11.960 --> 17:30.840]  никак. Не, ну можно, конечно, а — это рация к линии, но такого я не слышал. А звездочка. В чем его суть?
[17:30.840 --> 17:37.240]  Постановка задачи такая. У нас есть, опять же, граф, ориентированный, неориентированный, не важно,
[17:37.240 --> 17:47.640]  мы хотим найти расстояние от С до Т, и все веса не отрицательно. То есть, хотим дист от С до Т,
[17:47.640 --> 18:03.120]  W больше либо равна нуля. Да, весовая функция. Нет, это уже отдельно будет раздел. Евристический
[18:03.120 --> 18:11.000]  алгоритм. Что мы будем делать? На самом деле действовать мы будем крайне просто и одновременно
[18:11.000 --> 18:35.960]  крайне эффективно. Пусть H от W — это евристическая оценка на дист от W до T. И обычно берут оценку
[18:35.960 --> 18:40.880]  снизу, потому что если у вас оценка сверху, то вы не будете идти по кратчайшему пути. Обычно берут
[18:40.880 --> 18:49.360]  оценка снизу. Хотя, если там свести к эквивалентной задаче, то можно построить оценку сверху,
[18:49.360 --> 18:54.880]  она окажется оценкой снизу в исходной. Но это такие шаманские трюки, которые мы не будем
[18:54.880 --> 19:08.480]  изучать. Вы будете их дома проходить, когда будете пятнашки решать. Так, ну давайте возьмем не задачу
[19:08.480 --> 19:19.640]  пятнашки, а возьмем нашу вот ту задачу с картой. И какую евреистику вы могли бы предложить? Ну,
[19:19.640 --> 19:36.480]  банально, да. Давайте введем просто Евклидову расстояние. Пример. На карте. H от W. Ну расстояние
[19:36.480 --> 19:52.040]  от W до T. А, Евклидова. Почему это будет оценка снизу? Вроде очевидно. Если вы говорите,
[19:52.040 --> 20:01.680]  что H от W вот такая вот штука, то вы не можете бы лучше, чем это сделать. Ну, окей, хорошо,
[20:01.760 --> 20:06.680]  здесь предполагается, что у вас уделенная скорость в среднем, порядка одной единицы длины на единицу
[20:06.680 --> 20:11.720]  времени. По неравенству треугольника, не треугольника, точнее, у вас как-то путь будет
[20:11.720 --> 20:19.320]  устроен как-то ломанное. Если предполагать, что у них средние скорости здесь и здесь равны,
[20:19.320 --> 20:25.440]  тогда понятно, что этот путь короче, чем этот. Поэтому это оценка снизу. Вот.
[20:41.120 --> 20:46.080]  Ну, казалось бы, оценка снизу можно быть, конечно, но не факт, что вы вообще классная оценка.
[20:46.080 --> 20:52.800]  Там и простой пример. Это, внезапно, H от W тождественно равны нулю.
[20:52.800 --> 21:02.120]  Ну, классная оценка, не спорим, она оценка снизу, она вообще обладает кучей классных
[21:02.120 --> 21:10.000]  свойств на самом деле, которые мы будем потом выписывать. Это будет первый случай
[21:10.000 --> 21:19.640]  предельный, а второй предельный случай будет вот такой вот. Ну, казалось бы,
[21:19.640 --> 21:24.560]  тривиальные случаи, но только их можно анализировать адекватно. Вот. Так,
[21:24.560 --> 21:28.400]  теперь про сам алгоритм, потому что мы его так и не сказали. Мы привели пример эвристики и
[21:28.400 --> 21:34.920]  привели пример самых балдежных эвристик. Теперь нужно про сам алгоритм рассказать.
[21:34.920 --> 21:56.760]  Алгоритм будет устроен очень просто. Будет прям как D extra, только равниваем по вот такой вот
[21:57.080 --> 22:20.520]  интересной. F от W равный G от W плюс H от W, где G от W, оценка сверху на Dist от S до W из алгоритма D
[22:20.520 --> 22:33.640]  extra. То есть у вас код вообще не поменяется на самом деле никак. Вы просто добавите в ваш алгоритм
[22:33.640 --> 22:39.720]  D extra код вычисления эвристики от вершинки и будете в кучу классить не по G от W, а по G от W плюс H от W.
[22:39.720 --> 22:48.280]  Поэтому давайте подумаем, что происходит в случае H, то это же ясно равный нулю.
[22:48.280 --> 22:58.240]  В смысле ничего. Ну алгоритм работает, нет? Алгоритм работает прям как D extra, он просто
[22:58.240 --> 23:03.520]  вырождается в D extra. Если вы сюда напишите 0, то у вас F2R внушает W, и вы получаете абсолютно D
[23:03.520 --> 23:22.560]  extra просто. А что происходит в этом случае? Да, мы сразу идем по правильному пути, идем сразу вдоль
[23:22.560 --> 23:37.480]  кратчайшего. Да, есть еще один алгоритм, в котором внезапно ставится G от W, тоже ясно равный нулю.
[23:37.480 --> 23:47.560]  То есть F от W равно H от W просто. Он называется BFS внезапно тоже, но это не тот BFS, потому что
[23:47.560 --> 23:54.200]  классический BFS to breadth first search, где мы это вот обход в ширину, а в этот случай будет BFS
[23:54.200 --> 24:01.440]  best first search. То есть выбираем сначала лучшую вершину. Ну, видимо, да, в английском языке не очень
[24:01.440 --> 24:08.280]  классно с разнообразием слов. Вот, но best first search никто не пишет, потому что это немножко
[24:08.280 --> 24:17.160]  бесполезная идея, но просто как факт она и есть. Окей, теперь давайте немножко поговорим о том,
[24:17.160 --> 24:37.760]  какие еврестики вообще бывают. Так, определение. H от W допустимо, если для любой вершины W из
[24:37.760 --> 24:47.240]  множества вершин. H от W меньше либо равно, чем dist от W до T. То есть допустимая оценка,
[24:47.240 --> 24:52.960]  допустимая еврестика, это когда мы оценим снизу. Поэтому обычно берут всегда допустимые
[24:52.960 --> 24:57.800]  еврестики, и с ними все хорошо. Потому что если у вас еврестика недопустимая, то там, как правило,
[24:57.800 --> 25:04.200]  вообще полный раздрай, и алгоритм еще хуже, чем дейсер себя ведет. Но насколько, опять же,
[25:04.280 --> 25:09.480]  вдаваться мы не будем. Поэтому посвящены целые статьи огромные, в случае разных
[25:09.480 --> 25:18.680]  еврестик, разные характеристики поведения. Окей, ну пример допустимой еврестики опять же вот,
[25:18.680 --> 25:27.400]  эвклидовое расстояние. Но оказывается, этого недостаточно для хорошего работы алгоритма.
[25:27.400 --> 25:47.280]  H от W монотонно. Если для любого ребра УВ выполнять следующее. H от У минус H от В
[25:47.280 --> 26:08.000]  меньше либо равно, чем W от УВ. И H от T равно нулю. Такое определение. То есть ваша разность
[26:08.000 --> 26:14.920]  еврестик не должна превышать вес ребра. И при этом еврестика от кончого состояния
[26:14.920 --> 26:24.160]  равно нулю. Но это вроде естественное требование. Это не очень очевидно зачем-то надо. Но внезапно
[26:24.160 --> 26:31.000]  оказывается тогда, что у вас верно, что у вас вот этот прирост не больше, чем вес,
[26:31.000 --> 26:34.880]  и поэтому у вас очень похоже на Dx происходит действие. Вот.
[26:45.040 --> 26:48.600]  Окей. Теперь докажем интересное утверждение об еврестиках.
[26:48.600 --> 27:12.840]  W? Вот это вот? Ну у вас же есть весовая функция. Ну все, вот ее берете от УВ.
[27:12.840 --> 27:38.640]  Утверждение следующее. Любая монотонная еврестика допустима. В обратном стороне это неверно,
[27:38.640 --> 27:43.920]  кстати. То есть допустимые монотонными не всегда являются. А от монотона является допустимый.
[27:43.920 --> 27:56.240]  Давайте доказывать. Что будем доказывать? Давайте доказывать индукции, наверное, да?
[27:56.240 --> 28:24.560]  Индукции по реберной длине кратчайшего пути от V до T. Докажем, что h от V
[28:24.560 --> 28:44.280]  не превосходит Dx от V до T. Ну и план такой, но это надо оформить красиво. Собственно,
[28:44.280 --> 28:57.440]  это называется индукция в реберной длине. База индукции. h от T внезапно равно 0 по определению.
[28:57.440 --> 29:07.880]  Потому что здесь h от T равно 0. Ну очевидно, для допустимой еврестики h от T тоже равно 0. Ну почему?
[29:07.880 --> 29:20.200]  Потому что у вас h от T меньше, чем Dx от T до T. То есть меньше равно 0. И поэтому пути длины 0 это верно. Путь длины 0.
[29:20.200 --> 29:37.200]  Так, переход. Давайте рассмотрим вершинку U и вершинку T. Давайте будем h от U показывать.
[29:37.200 --> 29:46.800]  Чтобы у нас была согласованность обозначениях. Что мы будем делать? Рассмотрим кратчайший путь от U до T.
[29:46.800 --> 29:57.160]  Очевидно, он имеет вот такой вот вид. Есть ребро у V, дальше от V до T. Почему? Потому что у нас
[29:57.160 --> 30:17.920]  переход, потому что длина реберная кратчайшего пути хотя бы один. Пусть U, V, T кратчайший путь из U в T.
[30:17.920 --> 30:29.240]  Что мы с вами знаем? Ну по определению монотонности мы просто знаем с вами, что h от U минус h от V меньше верно, чем Dx от U в V.
[30:29.240 --> 30:45.080]  Логично? Логично. Что еще мы с вами знаем? По предположению индукции h от V меньше ибо равно, чем Dx от V до T.
[30:45.080 --> 31:02.480]  Откуда вас следует, что h от U меньше ибо равно, чем h от V плюс W от U до V. Да? Ну просто h от V перенес сюда.
[31:02.480 --> 31:09.880]  Теперь применяю вот это вот неравенство вот сюда. Вот следующий переход. Что меньше ибо равно,
[31:09.880 --> 31:20.640]  чем Dx от V до T плюс W от U в V. Ну так как у нас V выбиралось как вершинка на кратчайшем пути, здесь просто
[31:20.640 --> 31:38.760]  равенство Dx от U до T. Ну тривиальней, что это уже не доказано. Собственно, как вы думаете,
[31:38.760 --> 31:52.560]  почему ивристика называется допустимой? Нет, не поэтому. Потому что давайте подумаем,
[31:52.560 --> 31:56.760]  что происходит, если у вас ивристика недопустима. Правда ли тогда, что в первом инфривене,
[31:56.760 --> 32:03.040]  когда ваш астар обнаружил вершину T, будет верное кратчайшее расстояние? Вот, поэтому она
[32:03.040 --> 32:08.200]  недопустима будет. Собственно, ивристики допустимы, если только если у вас оказывается,
[32:08.200 --> 32:16.320]  что ответ, когда вы нашли их первые вершины T, это будет кратчайший путь. Вот, вот так вот скажем.
[32:16.320 --> 32:21.320]  То есть допустимость как раз таки обозначает то, что вы найдете, что если вы нашли ответ,
[32:21.320 --> 32:25.760]  то он правильный. А монотонность гарантирует вам плюс-минус оптимальность поиска этого пути.
[32:25.760 --> 32:35.880]  Потому что он работает не хуже, чем Dx. Вот так скажем. Доказывать это я тоже не буду. То есть
[32:35.880 --> 32:39.560]  если у вас ивристик монотон, то ваш алгоритм работает не хуже, чем алгоритм Dx. Вот так скажем.
[32:39.560 --> 32:52.120]  Ну здесь наверное хочется посмотреть на то, как будут устроены у астара волны его. Но они будут
[32:52.120 --> 32:57.480]  устроены реально просто. На самом деле в BFS я вам соврал немножко. Я не рисовал волны вниз,
[32:57.480 --> 33:03.720]  чтобы BFS бы и их проходил. А вот астар уже почти не будет их проходить. У него будут какие-то вот
[33:03.720 --> 33:15.320]  такие вот волны. Также здесь. Такое. Даже не будет далеко уходить на самом деле.
[33:15.320 --> 33:27.640]  Он отсюда пойдет. Они пересекутся где-то вот здесь. Не совсем мало просмотрят пути.
[33:27.640 --> 33:42.000]  Круто, да, уже получилось. Если у вас есть ивристика геометрическая, то он будет как-то
[33:42.000 --> 33:48.840]  каситься вдоль этой прямой в основном. Но, однако, можно ввести еще какие-нибудь парочку ивристик,
[33:48.840 --> 33:53.640]  всяких географических. То, например, мы знаем, что от этого до этого нельзя добраться быстрее,
[33:53.640 --> 33:59.280]  чем пройти через эту точку. То есть вести несколько таких ориентиров по карте, где мы будем выбирать
[33:59.280 --> 34:05.200]  из множества ориентиров тот, который нам ближе всех, и ходить до ориентиров так. Вот внезапно
[34:05.200 --> 34:11.320]  эта оптимизация называется ALT алгоритм. Я про него пока что умолчу. Если будет интересно,
[34:11.320 --> 34:18.760]  можете почитать. Там выбирается несколько ориентиров на карте. Дальше там берется из каждого
[34:18.760 --> 34:23.600]  ориентира считается крещейшее расстояние до всех, обычной dx-трей. А дальше у вас очень
[34:23.600 --> 34:27.960]  быстрый ответ происходит, потому что вы из каждой вершины пытаетесь добраться до оптимального
[34:27.960 --> 34:35.920]  ориентира на текущий момент. И все. Мы там в силу неравенства треугольника и прочей геометрии,
[34:35.920 --> 34:47.280]  все очень быстро схлопывается. Еще быстрее, чем вот это. Что еще нам нужно? Наверное, все.
[34:47.280 --> 34:55.920]  Единственное, что можно доказать, что эвристика эвклидового расстояния является монотонной,
[34:55.920 --> 35:08.480]  но это опять же в силу неравенства треугольника, верно? Всякие примеры эвристики вы будете
[35:08.480 --> 35:13.840]  рассматривать на семинаре. И тут, казалось бы, можно сказать, ну окей, давайте сделаем двусторонний
[35:13.840 --> 35:24.360]  астар. Можно же двусторонний астар сделать, да? Но я не буду этого делать, опять же, потому что это
[35:24.360 --> 35:34.800]  немножко неприятно. Кому интересно, тоже можете почитать. Очень классный алгоритм, но там, во-первых,
[35:34.800 --> 35:39.840]  надо сам астар менять немножко, потом там эвристики нужно выбрать две и их согласовать. То есть,
[35:39.840 --> 35:46.800]  не самая приятная техническая задача. И сейчас, внезапно, мы вообще от графов немножко отойдем.
[35:46.800 --> 35:55.640]  Внезапно. Почему мы это сделаем? Потому что для дальнейшего изучения графов нужна определенная
[35:55.640 --> 36:00.800]  структура данных интересная. Система непересекающихся множеств.
[36:00.800 --> 36:30.480]  СНМ или по-английски DSU. The Joint Set Union. Вот. В чем ее суть? Изначально у нас есть
[36:30.480 --> 36:45.520]  N элементов. Каждый из них все множество. Вот какое-то вот такое вот интересное множество
[36:45.520 --> 36:54.520]  на восьми элементах. Что происходит дальше? Есть два запроса. Первый тип запросов это Unite,
[36:54.520 --> 37:13.160]  от A, B это объедини множество, где лежат A и B. Ну, если это одно и то же множество,
[37:13.160 --> 37:36.960]  ничего не делай. И второй запрос это R Same, от A, B лежат ли в одном множестве A, B. Ну,
[37:36.960 --> 37:44.040]  самая простая сдача, которую можно придумать на эту штуку, помимо таких запросов, это вам
[37:44.040 --> 37:48.680]  дан изначально граф без ребер, докидывают ребра, спрашивают, сколько компонент связанности на
[37:48.680 --> 37:54.760]  текущий момент. Если разрешить удаление ребер, эта штука не работает. Эта штука называется Dynamic
[37:54.760 --> 38:01.120]  connectivity problem. Это вообще достаточно известная научная проблема, по которой последние оценки
[38:01.120 --> 38:10.400]  получил товарищ из Петербурга относительно недавно. Но там сложные структуры, и в целом Dynamic
[38:10.400 --> 38:16.040]  connectivity problem мы разбирать не будем. Таковую тоже вам на самостоятельное изучение материал.
[38:16.040 --> 38:23.200]  Идеи как-то реализовывать. Ну, самое простое, это давайте для каждой вершины будем хранить номер
[38:23.200 --> 38:29.160]  множества. Тогда R Same действительно вообще за вот единицы делает. Просто берете листья в две
[38:29.160 --> 38:37.880]  ячейки и такие, ну круто, равно не равно. Но вот Unite немножко долго будет, порядка ООТН. То есть
[38:37.880 --> 38:48.800]  наивная реализация, это будет у нас пара ООТН от единички. То есть первый элемент запрос Unite,
[38:48.800 --> 39:02.560]  второй R Same. Вот. Ну что еще можно делать? Ну, наверное, ну не знаю, как еще можно делать.
[39:02.560 --> 39:11.840]  Ну можно хранить суты, да? Просто, вот прям как говорится, система не пересекающая множество.
[39:11.840 --> 39:24.160]  Давайте просто хранить множество явно. Давайте подумаем, Massive, Unite, за сколько работает.
[39:24.160 --> 39:31.880]  Вот, ну неправда вообще. Мы доказывали с вами на семинарах, амортизированно, что если вы меньше
[39:31.880 --> 39:43.800]  приливаете к большему, то получается амортизированный логарифм. Ну окей, а R Same, если Нор, то единичка. Давайте
[39:43.800 --> 39:56.280]  от единицы напишу. Если здесь просто сет писать, то здесь лог квадрат и от лога N будет. От N, от суммарного
[39:56.280 --> 40:02.680]  числа элементов. В смысле, от суммарного всего элементов изначально. А, правда, да, действительно. Мы не
[40:02.680 --> 40:12.080]  умеем так проверять. Согласен. Мы не умеем проверить, что А и Б в одном множестве. Давайте научимся так.
[40:12.080 --> 40:23.200]  Будем хранить не множество, да? Давайте здесь напишем ОТН. Пока что. Такую грубую оценку. И это скажем,
[40:23.200 --> 40:30.720]  что это unordered set. Теперь давайте посмотрим, если это деревья поиска обычные, тогда что я могу
[40:30.720 --> 40:39.600]  брать? Я могу взять у элемента его корень, его дерево поиска. Аналогично у этого взять, у Б взять
[40:39.600 --> 40:46.000]  корень дерева поиска. Если они равны, то они лежат в одном множестве. Если нет, то нет. Логичная
[40:46.000 --> 40:53.080]  идея. Давайте просто напишу set. Ну тогда у нас здесь будет пара. Ну и допустим, что я умею брать,
[40:53.080 --> 40:58.080]  ну не знаю, давайте возьмем минимальный элемент в множестве, например, а не корень, чтобы я умел
[40:58.080 --> 41:05.520]  ходить к нему. Чтобы я не мог писать свои деревья, просто брать там звездочка Бегин. Здесь я получу
[41:05.520 --> 41:14.040]  амортизированный квадрат логарифма, а здесь я получу от лог N, потому что я должен у А и
[41:14.040 --> 41:27.440]  Б запросить у его множеств, типа чувак, давай-ка говори, чтобы в одном множестве. Ну и как это
[41:27.440 --> 41:34.600]  все поддерживать? Например, можно поддерживать массивчик от 1 до N, ну длиной N, где у нас будет
[41:34.600 --> 41:44.040]  в этой чеке лежать указатель на ноду в дереве. Согласны, что так можно сделать? Ну и тогда я
[41:44.040 --> 41:50.680]  смогу получить явный доступ к этой ноде, я смогу получить от А и от Б явный доступ к этому дереву,
[41:50.680 --> 41:56.600]  к ноде, явный доступ к ноде этого дерева какой-то. Добраться до их корней, давайте без минимума
[41:56.600 --> 42:11.640]  обойдемся, и проверяем вот это вот на равенство. Вот уже круче, да, идея? Ну, только в массиве мы
[42:11.640 --> 42:15.960]  храним указатели, здесь мы не храним никакую информацию о том, как они там объединены и так
[42:15.960 --> 42:22.720]  далее. United делается очень просто, вы просто делаете все то же самое, что здесь, главное за
[42:22.720 --> 42:37.200]  указателями проследить, что они останутся валидными. И что, ну вы можете хранить указательные элементы,
[42:37.200 --> 42:45.040]  как вы будете хранить указательные элементы. Точнее, не так, тогда вам придется при переливании кучу
[42:45.040 --> 42:54.000]  указателей перекинуть, а не НСМР на Луген, да. Ну да, можно в этом массиве, давайте вот с этим массивом
[42:54.000 --> 43:00.240]  еще что можно сделать, можно в нем хранить, собственно, самый NORROR set, но его не копия,
[43:00.240 --> 43:05.880]  а указатель на него. Я смогу из АСБ узнавать нужную мне хаш табличку и прячь, что они равны или нет,
[43:05.880 --> 43:18.280]  ну по адресу просто равны или нет. Ну почему? У нас станет новый сет, и мы вернем на него указатели,
[43:18.280 --> 43:27.280]  просто двумя им переприсвоим. Так нет, зачем вы вливаете? Так нет, давай, я не буду просто
[43:27.280 --> 43:31.960]  создавать новых сетов, я изначально создам все пустые, ну начнем все по одному элементу,
[43:31.960 --> 43:35.560]  но дальше при переливании меньшего к большему у меня на большее указательство не поменяется.
[43:35.560 --> 43:42.640]  Зачем? Я явно же их переливал и просто им переприсвою указатель новый массиве.
[43:42.640 --> 43:51.000]  Да, но это тоже самое, что здесь Луген амортизировано, то же самое число действий.
[43:51.000 --> 43:58.560]  Ну вы доказывали на семинаре, что у вас при переливании меньшего к большему будет за Луген
[43:58.560 --> 44:05.320]  амортизировано делаться при переливании. Это тоже самое, абсолютно. Вы для того же числа
[44:05.320 --> 44:16.960]  элементов меняете штуку за вот единицы. Будет, но мы же в этом же не предложили.
[44:16.960 --> 44:26.560]  Не, на самом деле мы-то придем к нормальной реализации в конце концов. Вот, ну окей,
[44:26.560 --> 44:32.840]  понятно, что есть куча вариантов реализации, но мы сейчас обсудим нормальную, уважаемую реализацию.
[44:32.840 --> 44:37.720]  А именно у нас будет две эвристики. Ну здесь эвристика не в плане того, что это какое-то
[44:37.720 --> 44:42.640]  сверхзнание, а в плане того, что это будет просто такой эвристический подход к этому всему.
[44:42.640 --> 44:46.680]  То есть мы будем применять какие-то два соображения, которые не очевидно, что дадут профит,
[44:46.680 --> 44:52.440]  потом мы с вами не докажем, что они дадут профит, а просто напишем, что они дают профит.
[44:52.440 --> 45:00.200]  Да, план примерно такой у меня. Ну, там есть просто нюанс, что если доказывать,
[45:00.200 --> 45:07.800]  что будет профит, то это ну немножко 25 листов в статье Тарьяна надо переписывать. Поэтому я откажу
[45:07.800 --> 45:11.440]  себе в таком удовольствии, но с удовольствием скину вам ссылку, чтобы вы могли почитать.
[45:11.440 --> 45:20.280]  Вопрос на 9 на экзамене. Что мы хотим? Мы хотим эвристики. Первое это ранговая или весовая эвристика.
[45:20.280 --> 45:37.400]  Что бы она заключается? Переливай меньше к большему, собственно все. Переливай
[45:37.400 --> 45:50.600]  меньше к большему. А теперь перед второй эвристикой надо обсудить, как мы будем хранить
[45:50.600 --> 45:57.960]  нашу структуру вообще. Давайте хранить для каждой, вообще мы будем хранить систему не пересекающих
[45:57.960 --> 46:03.800]  множеств, внезапно это будет просто лес деревьев, где каждый дерево это отдельное множество.
[46:03.800 --> 46:23.440]  Видим, как массив где-то деревьев. В одном дереве одно множество. Ну тогда понятно,
[46:23.440 --> 46:27.200]  что вот это амортизированный логариф, он там и существуется, как мы делали в хэштаблицах.
[46:27.200 --> 46:33.520]  За счет чего теперь мы будем делать? Как будем проверять? Раз у нас есть дерево,
[46:33.520 --> 46:46.000]  можно для каждого элемента вычислять его предка, да? Арсейм это будет равны ли корне,
[46:46.000 --> 46:53.280]  а юнайт это будет прилить меньше к большему. Указалось бы профита пока никакого.
[46:53.280 --> 46:58.760]  Теперь давайте делать следующую интересную величину. Давайте вызовем функцию
[46:58.760 --> 47:15.360]  pine set от A вернет представителя множества или корень дерева. Потому что мы хотим,
[47:15.360 --> 47:18.360]  чтобы для всех элементов одного и того же множества был один и тот же представитель.
[47:18.360 --> 47:26.760]  Очень удобно сказать, что это корень. Тогда арсейм это равенство pine set от A и B,
[47:26.760 --> 47:35.280]  юнайт это просто прилить. Теперь давайте сделаем единственное, что классное в этой
[47:35.280 --> 47:48.960]  всей операции. Давайте рассмотрим путь. Сказать, что у каждой вершины это дерево,
[47:48.960 --> 47:58.120]  предок это вот этот чувак, это корень. Можно так сказать, да. Ну да, так будет проще,
[47:58.120 --> 48:03.560]  вы хотите очень быстро делать, поэтому говорите, что будто бы подвешиваете меньше к большему
[48:03.560 --> 48:14.360]  такой связью. Давайте, что я сделаю, давайте обозначу вершину 1, 2, 3, 4, 5 и в момент вызова
[48:14.360 --> 48:20.840]  pine set я же что делаю, я иду от этой вершинки вверх, а если меня будут вызывать кучу раз pine set от A,
[48:20.840 --> 48:33.080]  давайте сделаем это оптимизировано. То есть всех, кто на пути, будем подвешивать корню,
[48:33.080 --> 48:59.560]  и это называется веристика сжатия путей. Путей на пути, pine set, всех к корню.
[48:59.560 --> 49:10.200]  Здесь будет несколько утверждений про время работы и всего этого добра. Так, утверждение 1,
[49:10.200 --> 49:28.240]  если применить только одну веристику, то время работы
[49:40.200 --> 49:52.360]  на запрос. На любой из запросов будет звёздочка от log n время работы при применении любой одной веристики.
[49:52.360 --> 50:12.520]  Давайте определение дадим для следующей штуки. log звёздочка от n равно k, если log log log
[50:12.520 --> 50:20.920]  k раз, здесь берётся лог гриф по основанию 2 обычно.
[50:20.920 --> 50:40.520]  Здесь log звёздочка от n меньше либо равно ум и единица. То есть для 16 что вы делаете?
[50:40.520 --> 50:55.320]  Почему? лог гриф 2 от 16, 4, лог гриф 2 от 4, 2, лог гриф 2 от 2, 1, лог гриф 2 от 1, 0. То есть это не
[50:55.320 --> 51:00.440]  просто логарифм, это сколько раз нужно взять логарифм, это вот настолько медленно растущая
[51:00.440 --> 51:13.240]  функция. Например, можете показать, что лог звёздочка от 2 в степени k это k. Да, ну совсем плохо, это фиаско вообще.
[51:13.240 --> 51:28.360]  Вот утверждение, которое может выпасть на экзамене в качестве задачи на 10. Это если применять
[51:28.360 --> 51:48.400]  обеевристики, то время работы на запрос.
[51:48.400 --> 52:02.720]  Звёздочка, это вот этот вот. Ну не принципиально в каком основании, у вас же констант здесь
[52:02.720 --> 52:09.840]  тогда будет вылазить. Ну можно по двоичному взять. Вот это уже интересная оценка. Нас заведомо крусе,
[52:09.840 --> 52:20.520]  чем логарифм, но ещё не от единицы. Но до от единицы мы не дойдём, не бойтесь, потому что так случилось,
[52:20.520 --> 52:31.280]  что не дойдём всё-таки. Нет, ну это если вы пойдёте на 10, вам совсем не повезёт,
[52:31.280 --> 52:36.560]  его придётся доказывать. Я доказывать его не буду, очевидно. Ну это задача на 10.
[52:36.560 --> 52:44.800]  Читайте статьи. Можно доказать сразу следующую оценку будет, тогда я поверю. Вы знаете,
[52:44.800 --> 52:55.560]  как это доказывать. Ой, так, сейчас, если я возьму листочек, потому что здесь что-то страшное. Это
[52:55.560 --> 53:04.960]  то, что я напишу, вы даже на экзамене не должны это помнить, скорее всего. Определение. Знаете,
[53:04.960 --> 53:18.560]  что такое функция кирмана? Это такая интересная функция. Равно n плюс 1, m равно 0.
[53:34.960 --> 53:48.800]  У неё есть несколько замечательных свойств. Это первая в истории полученная непримитивно
[53:48.800 --> 53:56.400]  рекурсивно вычислимая функция. Если у вас был матлог, дискретки или что-то похожее на это,
[53:56.400 --> 54:03.040]  вы должны знать о понятии рекурсии с точки зрения формальной теории алгоритмов. Там самый класс
[54:03.040 --> 54:09.480]  примитивно-рекурсивные функции. Это функции, которые используют самый примитив вообще,
[54:09.480 --> 54:13.240]  который можно только в рекурсии использовать. На программическом языке приводится, что вы
[54:13.240 --> 54:19.640]  имеете использовать for, всякие if и всякие if-мечку тоже можете использовать. Но вы не можете
[54:19.640 --> 54:24.920]  использовать call while. Примитивно-рекурсивно вычислимые функции — это те, которые не используют
[54:24.920 --> 54:30.680]  while в своих вычислениях, или у которых можно реализовать без while. То есть вам нужно в каждом
[54:30.680 --> 54:37.400]  форе знать четко, сколько у вас итераций будет. То есть там нельзя, например, написать for и условия
[54:37.400 --> 54:42.880]  is while. Нет, вы должны четко знать число итераций. Но это было бы классно, конечно, for и условия
[54:42.880 --> 54:50.000]  is while, но нет. Вместо того, что есть у вас for и от 0 до n-1 плюс и. Вот. Это только такой for разрешен.
[54:50.000 --> 55:01.040]  Вот. Этой функцией внезапно нельзя так написать. Потому что, если вы будете это пытаться делать,
[55:01.040 --> 55:05.560]  у вас там будет в форе вылезать рекурсия, когда вы будете читать границу фора. Это неприятно.
[55:05.560 --> 55:13.280]  Собственно, чем интересна еще эта функция? Это последняя, чем она интересна. Да, во-первых,
[55:13.280 --> 55:17.360]  эта штука используется в тестах рекурсии, очевидно. Если у вас там был питан, то, по-моему, есть задача
[55:17.360 --> 55:23.480]  написать функцию кермана и посчитать 4 рекурсивных вызовов. И оно очень быстро умирает внезапно.
[55:23.480 --> 55:29.360]  Почему оно очень быстро умирает? Но здесь нужно просто знать вот такое вот. Ну как нужно знать?
[55:29.360 --> 55:37.920]  Нужно просто понимать, что это вот такое вот интересное число. Сколько тут? Еще двоечка. Еще
[55:37.920 --> 55:50.880]  двоечка. Еще двоечка. Еще двоечка. Еще двоечка. Еще двоечка. Вот так вот. 8 двоечек. Это много.
[55:50.880 --> 56:02.920]  Это точно константа? Да. Это точно константа. Люди посчитали 1,4,4. Ну с какими целями? С такими,
[56:02.920 --> 56:10.880]  что вводят вот такую вот штуку. Сейчас, ладно, я скажу, что вот что у меня здесь написано. Возможно,
[56:10.880 --> 56:18.600]  я ошибся в количестве двоечек. Что если я здесь вот так вот оставлю, здесь напишу 6,5,5,3,6. Вот это
[56:18.600 --> 56:26.040]  будет правдой. Но это вроде 2 в 16, 2 в 16 это 2 в 4. То есть 2,2,2,2. Да, 4 двоечка еще сверху надо
[56:26.040 --> 56:35.520]  накинуть. То есть длина башенки 8 двоек. Балдежная, да, тема? Зачем нам это надо? Есть вот такая функция,
[56:35.520 --> 56:54.160]  обратная функция кирмана. К такое что? Да. Как вы можете догадаться, альфа от вот такой
[56:54.160 --> 57:11.320]  штуки это 4. Теорема по авторствам товарища Тарьян. Без доказательства. Время работы запроса.
[57:11.320 --> 57:28.280]  Амортизировано альфа т. Как он это доказывал? Оставляю вам 25-страничную статью Тарьяна на
[57:28.280 --> 57:33.920]  домашнее чтение. Ну это и при использовании обеих ибристик, конечно же. Не при одной,
[57:33.920 --> 57:38.440]  обеих надо сразу использовать. Есть какие-то провокационные статьи, что здесь можно единицу
[57:38.440 --> 57:45.400]  поставить просто. Но там как-то не верят. Вот этому поверили. Возвездочка от единиц еще не верит
[57:45.400 --> 58:01.800]  научное сообщество. Подожди, это важный вопрос. Вопрос компьютер-сайенс.
[58:01.800 --> 58:12.160]  Вот когда вы решаете теорки, вам явно будут писать альфа от n. Если вам не пишут альфа от n,
[58:12.160 --> 58:18.760]  значит вы должны без альфа от n обойтись. Вот в теорках. В контесте, конечно же,
[58:18.760 --> 58:24.520]  можете считать, что эта единица смела при оценках. Потому что она не больше 4. Ну камон.
[58:24.520 --> 58:35.640]  Ну не для трех. Там, по-моему, более-менее удовлетворимое число. Число башенок сильно меньше,
[58:35.640 --> 58:40.480]  здесь не минус 3, а минус какое-то другое число. Но можете на википедии табличку посмотреть,
[58:40.480 --> 58:46.800]  там есть от 1 до 4 по каждому параметру, вычисляя функции значения кирмана. Быть может до 5 даже,
[58:46.800 --> 58:52.360]  но я не уверен. А дальше они просто пишут, как оно плюс-минус должно выглядеть. Потому что это никто
[58:52.360 --> 59:00.160]  не считал. А, давайте я код напишу. Ну короче, там суть в том, что самое интеллектуальное – это как
[59:00.160 --> 59:12.200]  вот эту часть реализовать. Там рекурсивные свойства C++, так скажем. Рекурсия – это плохо,
[59:12.200 --> 59:19.560]  но здесь без нее никуда. Потому что… Можно, конечно, по-моему, раскрыть эту рекурсию.
[59:19.560 --> 59:26.160]  Типа сначала вы находите предка, явного корень, потом каждому форум подвешиваете на этом пути.
[59:26.160 --> 59:31.320]  Но там прикол в том, что там просто в три строки получается реализация. Короче,
[59:31.320 --> 59:40.760]  файнсет пишется вот так вот. Но это если вы по кодстайлу пишете. Ладно, можно все написать по
[59:40.760 --> 59:51.160]  одну через тернарник. Но на этом мы не будем этим заниматься. Так, давайте… Мы говорили,
[59:51.160 --> 59:58.920]  что мы храним предков, да, для каждой вершинки? А потому что я так захотел.
[59:58.920 --> 01:00:13.000]  Ой, че я несу? Ancestor здесь надо брать, предки.
[01:00:13.000 --> 01:00:38.800]  Ой, сейчас здесь будет красотуля. Да, ну еще веса, ну ранги или веса. Да, рангом вершины
[01:00:38.800 --> 01:00:46.840]  будем называть глубину дерева из нее, а весом вершины – просто количество элементов. Вот
[01:00:46.840 --> 01:01:02.440]  кажется, что ранга, весовая квиолента. Ancestor в этой равно… Ну и тебе нужно же понимать,
[01:01:02.440 --> 01:01:27.280]  кого к кому приливать. Действительно. То, что никогда не пройдет в кодстайл, но это работает.
[01:01:27.280 --> 01:01:37.240]  Да. То есть, смотри, что вы делаете. Когда вы заходите в вершинку, вы берете и ищете ее предка.
[01:01:37.240 --> 01:01:42.400]  Она рекурсивно найдет ее предка. Рекурсивно найдет ее предка и так далее. И скажет,
[01:01:42.400 --> 01:01:48.760]  ага, как только я нашел корень, окей, верни корень. И она всем Ancestor в этом
[01:01:48.760 --> 01:01:55.440]  проставит корень. Почему это так? А потому что у вас оператор равно… вспомните, что возвращается
[01:01:55.440 --> 01:02:03.520]  в песах. Ссылку на то, что у вас здесь находится. То есть, он вернет вам результат присваивания.
[01:02:03.520 --> 01:02:09.400]  То есть, вот эту вот штуку вернет вам. А она вам вернет, единственный раз, корень. Это на всем
[01:02:09.400 --> 01:02:16.680]  вершинам на пути сразу корень проставит в обратном ходе рекурсии. Ну здесь можно тернарденчик
[01:02:16.680 --> 01:02:25.360]  бахнуть. Да, если это равно, поставить вопросик, то типа верни В, иначе вот это вот пойду. Но тут я
[01:02:25.360 --> 01:02:32.640]  не уверен, если честно, разработать тернардник. Ну вот я про это и говорю. По-моему, это не очень
[01:02:32.640 --> 01:02:39.440]  скобилируется, это не плюсов, а может сработает, я не помню. Там не только типы, там должны быть
[01:02:39.440 --> 01:02:49.320]  категории, значения одинаковые. У вас еще этого не было? У вас C-style вещь. Ну короче, вот так вот.
[01:02:49.320 --> 01:02:58.320]  Окей, тогда какие у нас планы на дальнейшее наше свое существование? Это то, что у нас будут
[01:02:58.320 --> 01:03:03.560]  миностовы. Наверное, одну лекцию потратим. Раз мы про это с нами уже поговорили,
[01:03:03.560 --> 01:03:10.840]  там одной лекции хватит вполне. И дальше после миностовов пойдет ЛЦА задача, еще одна лекция,
[01:03:10.840 --> 01:03:19.600]  третий контест, соответственно. И потом пойдут по токе четвертый контест, в том строке пятый
[01:03:19.600 --> 01:03:22.920]  контест. И мы закончили семестр. Ну все, тогда всем пока.
