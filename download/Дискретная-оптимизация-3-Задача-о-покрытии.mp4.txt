[00:00.000 --> 00:09.920]  и посмотрим задачу о покрытии вот задача о рюкзаке это типичный случай задачи упаковки
[00:09.920 --> 00:15.640]  а мы с вами рассмотрим задачу о покрытии сначала задачу о вершинном покрытии потом
[00:15.640 --> 00:23.000]  уже общую задачу о покрытии и посмотрим на двойственные задачи значит ну давайте
[00:23.000 --> 00:44.800]  эти мы займемся поскорее да задача vertex cover задача о том как покрыть граф взяв
[00:44.800 --> 00:51.320]  поменьше вершин а что значит вообще покрыть граф но граф он состоит всего из как бы объектов
[00:51.320 --> 00:56.320]  двух типов вершины и ребра и ребра это вообще не совсем самостоятельные штуки да это пары
[00:56.320 --> 01:13.280]  вершин но вот за этой задачей есть у нас граф и мы берем некоторые вершины этого графа пачкаем
[01:13.280 --> 01:17.920]  я мне вот почему-то в таких терминах вот мне про рюкзак удобно говорить терминах духов
[01:17.920 --> 01:24.800]  которые мы бочку наливаем вершинное покрытие обсуждать терминах запачкования графа так вот
[01:24.800 --> 01:31.960]  мы пачкаем некоторое количество вершин так чтобы каждое ребро оказывалось запятанным значит но
[01:31.960 --> 01:39.720]  вот мы можем для этого графа взять наверное вот так вот запачкать некоторые вершины бац и бац и
[01:39.720 --> 01:47.280]  окажется что каждое ребро в этом графе запачкан да вроде получается у некоторых ребер запачкан на
[01:47.280 --> 01:54.120]  оба конца у некоторых ребер запачкан только один конец но у каждого ребра хоть что-то запачкан но
[01:54.120 --> 01:59.320]  можно эту задачу притянуть за уши к разным практическим задачкам хотя сама по себе она
[01:59.320 --> 02:04.720]  может быть не столь практичной но я за уши все-таки по притягиваю потому что нельзя же не сказать что
[02:04.720 --> 02:10.520]  на самом деле это важная практическая задача и там ее обязательно нужно иметь решать но дело в
[02:10.520 --> 02:15.680]  том что вот по сути эта задача это просто важный такой частный случай более общей задачи о покрытии
[02:15.680 --> 02:21.200]  которую как раз таки на практике и важно интересно решать вот но эту задачу можно как воспринимать
[02:21.200 --> 02:29.640]  ну например вот этот вот граф это какая-то значит сеть каналов обмена информации да компьютерная
[02:29.640 --> 02:36.720]  сеть просто и для того чтобы канал функционировал одно из устройств на этом канале хотя бы должно
[02:36.720 --> 02:41.560]  иметь возможность быть таким мастер устройством то есть устройством которое способно инициировать
[02:41.560 --> 02:48.640]  связь там наладить протокол обмена информации и тогда если вы вот во всей вашей коммуникационной сети
[02:48.640 --> 02:54.560]  только эти устройства снабдите вот такой вот мастерской функцией остальные устройства будут
[02:54.560 --> 03:00.280]  ведомыми то тем не менее каждый из каналов связи окажется функционирующим да то есть он может
[03:00.280 --> 03:06.800]  быть задействован использован но еще такая менее практичная еще менее практичная постановка
[03:06.800 --> 03:13.400]  представьте что это такой граф дорог и это прямые дороги прямые улицы ну а соответственно вершины
[03:13.400 --> 03:18.800]  графа это перекрестки на которых сходится несколько улиц тогда мы можем разместить вот на этих только
[03:18.800 --> 03:24.520]  перекрестках камеры видеонаблюдения поворачивающиеся так что мы сможем обозревать каждую улицу с
[03:24.520 --> 03:31.760]  помощью только этих камер вот но это менее конечно практичная постановка но знаете оказывается
[03:31.760 --> 03:37.040]  несмотря на то что задача так выглядит вроде не очень трудно найти действительно минимальное
[03:37.040 --> 03:43.200]  подможество вершин которая бы покрывала все ребра графа это задачка np трудная но мы с вами в
[03:43.200 --> 03:49.680]  курсе почти все задачи которые смотрим это np трудная задача сплошняком значит на входе да у
[03:49.680 --> 03:59.200]  нас вот это граф ну и естественно как всегда у этой задачки есть взвешенная и не взвешенная
[03:59.200 --> 04:06.440]  модификация да вот на входе у нас либо просто граф либо граф и весовая функция на его вершинах
[04:06.440 --> 04:12.800]  давайте я сразу во взвешенном варианте поставлю весовая функция до из множества вершин вам
[04:12.800 --> 04:22.600]  множество действительных положительных чисел нам нужно найти такое под множество вершин
[04:22.600 --> 04:31.280]  которая бы покрывала все ребра то есть можно сказать что для любого ребра для любого ребра
[04:31.280 --> 04:39.000]  пересечение этого ребра со множеством в шторих не пусто и при этих условиях мы должны минимизировать
[04:39.000 --> 04:49.000]  вес вот этого множества в шторих где вес множество понимается как сумма весов его вершин но вроде
[04:49.000 --> 04:50.560]  разумная задача
[04:54.560 --> 05:04.680]  минимизируем минимизируем вес множество да не переживайте вот я хотел было стать врачом вот
[05:04.680 --> 05:10.160]  потому что почерк подходящий для врача но все остальное у меня не срослось вот поэтому пришлось
[05:11.160 --> 05:21.160]  так вот значит давайте мы эту задачу попробуем решить с помощью нашего пока единственного знакомого
[05:21.160 --> 05:25.880]  нам инструмента именно поставив эту задачу в качестве задачи целочисленного линейного
[05:25.880 --> 05:33.080]  программирования и целочисленная программа будет как выглядеть помните мы вводим decision
[05:33.080 --> 05:38.920]  variables да переменные выбора переменные которые кодирует наш выбор основного неизвестного нам
[05:38.920 --> 05:45.440]  объекта то есть вот этого в штрих и мы знаем что когда комбинаторная задача задача комбинаторной
[05:45.440 --> 05:50.320]  оптимизации выглядит как выбор под множество из какого-то заранее фиксированного известного
[05:50.320 --> 05:55.840]  множества то разумно это под множество закодировать и вектором булевских переменных то есть таким
[05:55.840 --> 06:02.600]  характеристическим вектором этого множество соответственно мы можем взять и с каждой вершиной
[06:02.600 --> 06:10.480]  графа связать вот такую вот булевскую переменную x индекс мв которая равна единице или нулю в
[06:10.480 --> 06:20.200]  зависимости от того хотим мы включать вершину в под множество или не хотим как мы тогда можем
[06:20.200 --> 06:25.160]  записать нашу целевую функцию да то что мы минимизируем это мы называем всегда целевой
[06:25.160 --> 06:41.840]  функцией наша целевая функция по-английски это objective function как бы нам ее выписать через
[06:41.840 --> 06:54.880]  вот эти вот переменные ну как в рюкзаке да точно да сумма мы домножаем вес на соответствующий
[06:54.880 --> 07:01.640]  x и суммируем это теперь уже по всем вообще вершинам то есть сумма у нас больше не зависит от
[07:01.640 --> 07:08.280]  конкретного множества там в штрих от этих переменных она суммируется всегда по одному и тому же множеству
[07:08.280 --> 07:15.240]  просто по всем вершинам графа и эта сумма получается дает нам линейную функцию относительно вот этих
[07:15.240 --> 07:21.560]  вот переменных уже хорошо но теперь бы нам закодировать линейными неравенствами вот это
[07:21.560 --> 07:29.240]  вот условия что каждое ребро графа оказывается хотя бы одним из концов в множестве в штрих у
[07:29.240 --> 07:34.920]  каждого ребра хотя бы один из концов выбран как нам это можно линейным неравенствам как-то
[07:34.920 --> 07:44.840]  закодировать давайте возьмем какой-нибудь ребро вот есть у нас ребро кстати вы знали что значок
[07:44.840 --> 07:52.160]  принадлежности можно вот так вот задано вперед написать отлично вот есть у нас ребро такое там
[07:52.160 --> 08:00.200]  обе да какой-нибудь из двух вершин состоит значит что мы можем с вами сделать мы можем взять икса
[08:00.200 --> 08:07.440]  плюс xб да больше нуля но я напишу больше или равно единицы хотя это то же самое что вы сказали просто
[08:07.440 --> 08:13.360]  мне не строгие неравенство нравится чуть больше чем строгие действительно строгие они такие строгие
[08:13.360 --> 08:21.920]  они строгие они такие мягкие вот ну вроде как нормально да действительно мы запрещаем этим двум
[08:21.920 --> 08:26.920]  переменам одновременно устанавливаться в нолик у нас переменные это и так только нолики или
[08:26.920 --> 08:33.800]  единички и мы говорим что для каждого ребра с вот такими концами а и б хотя бы один из концов
[08:33.800 --> 08:39.960]  должен быть единицей если оба конца единица то тоже хорошо да вот ну двойка больше рано единица
[08:39.960 --> 08:45.960]  тоже годится вот но два нуля здесь у нас быть не может то есть для каждого ребра мы вот
[08:45.960 --> 08:56.400]  такой вот неравенство потребуем окей значит получается что целочисленная мининная программа
[08:56.400 --> 09:06.000]  для нашей задачки она выглядит как-то так мы минимизируем вот такую вот целевую функцию при
[09:06.000 --> 09:15.600]  условии того что для каждого ребра давайте я уже здесь поставлю значок всеобщенности для
[09:15.600 --> 09:22.440]  каждого ребра у нас должно быть выполнено вот такое вот неравенство да в общем-то и все вот мы
[09:22.440 --> 09:28.440]  задачу поставили но это конечно задача сквернее чем рюкзак потому что в рюкзаке у нас с вами
[09:28.440 --> 09:35.760]  одно всего было неравенство и ну и целевая функция была очень похожая но здесь у нас по
[09:35.760 --> 09:40.600]  одному неравенство для каждого ребра графа то есть сами неравенство стали проще всего из двух
[09:40.600 --> 09:47.160]  слагаемых в левой части но зато у нас сложнее стала система теперь это неравенство не одно
[09:47.160 --> 09:56.960]  ничего мы с ним научимся разбираться значит давайте мы сначала давайте мы сначала представим
[09:56.960 --> 10:02.840]  что мы решили такую целочисленную линиейную программу а нет не целочисленную программу мы
[10:02.840 --> 10:07.760]  же не имеем решать мы ее умеем решать но никогда она большая это по-прежнему и трудная задача
[10:07.760 --> 10:14.080]  же да вот мы давайте решим соответствующую линейную программу чтобы перейти вот целочисленной
[10:14.080 --> 10:21.320]  линейной программы к линейной программе мы чего с вами делаем мы оставляем все требования кроме
[10:21.320 --> 10:28.000]  целочисленности а требования у нас были какие для булевских переменных требования булевости оно
[10:28.000 --> 10:33.400]  вот такое да для каждой вершины графа мы ввели переменную которая болтается между нулем и
[10:33.400 --> 10:39.880]  единицей и вообще говоря мы должны были бы еще записать что это переменная целое число вот тогда
[10:39.880 --> 10:44.920]  бы это была полноценная булевская переменная и смысл этой переменной вот такой на самом деле но
[10:44.920 --> 10:50.200]  целочисленная линейная программа наш ничего не знает про смысл переменных просто переменная и
[10:50.200 --> 10:55.240]  переменная да мы solver загнали бы вот такую вот программу он бы нам что-то выдал а дальше мы
[10:55.240 --> 11:00.100]  бы трактовали мы бы вкладывали опять в значение вот эти нолики единицы мы бы вкладывали некий
[11:00.100 --> 11:05.480]  комбинаторный содержательный смысл что это оказывается вот берем на вершину графа или нет ну
[11:05.480 --> 11:14.360]  вот если мы теперь избавляемся от целочисленности то мы получаем обычную линейную программу и вот
[11:14.360 --> 11:25.040]  такая штука это уже то что называется linear relaxation of vertex cover линейная релаксация какой-то
[11:25.040 --> 11:30.240]  комбинаторной задачи берем комбинаторную задачу ставим на языке clp убираем требования
[11:30.240 --> 11:35.120]  целочисленности получаем линейную программу которая называется линейной релаксации
[11:35.120 --> 11:46.640]  помните какое свойство линейной релаксации что она сама по себе тоже очень полезна когда
[11:46.640 --> 11:53.200]  мы переходим вот к этой программке и решаем ее уже теперь быстро потому что это больше не
[11:53.200 --> 11:59.080]  np трудная задача что мы можем сказать про минимальное значение целевой функции вот здесь как оно
[11:59.080 --> 12:06.600]  связано с оптимальным решением задачки вот здесь меньше ли равно да потому что сняп ограничение
[12:06.600 --> 12:11.720]  целочисленности мы сильно расширяем область допустимых значений переменных и на этой области
[12:11.720 --> 12:16.800]  могут оказаться какие-то новые точки которые раньше были запрещены потому что у них не целые
[12:16.800 --> 12:22.520]  координаты да а мы теперь им разрешаем существовать и на них вот это вот сумма может стать еще меньше
[12:22.520 --> 12:28.560]  вот так что оптимальное значение целевой функции в линейной релаксации всегда дает нам оценку
[12:28.560 --> 12:35.520]  гарантированную некую на значение целевой функции в исходной трудной задачи ну вот теперь давайте
[12:35.520 --> 12:43.800]  посмотрим как мы можем приблизиться как-то к ну собственно к этому решению к этой задачке да опять
[12:43.800 --> 12:50.760]  округление можно попытаться сделать и в рюкзаке все было просто и хорошо там мы посмотрели так
[12:50.760 --> 12:55.680]  подумали и решили что мы даже solver не будем запускать линейной релаксации мы так знаем как
[12:55.680 --> 13:00.560]  выглядит оптимальное решение там только одна перемена не целочисленная но представьте что мы
[13:00.560 --> 13:10.120]  вот взяли например и задачку запустили на вот таком вот графе вот такой шестиугольник взяли
[13:10.120 --> 13:23.440]  но допустим вершины занумерованы буквами за именованы за именованы буквами ф и тогда у нас
[13:23.440 --> 13:34.880]  неравенство всевозможное да вот такие до x и а больше равно единицы а минимизируем мы давайте
[13:34.880 --> 13:39.160]  даже эту задачу рассмотрим как невзвешен и вот просто у всех вершин одинаковые веса по
[13:39.160 --> 13:48.840]  единичке то есть мы минимизируем сумму запишу даже вот так вот прям сразу x а плюс x б плюс
[13:48.840 --> 13:54.000]  и так далее плюс x и как вы думаете какое оптимальное решение вот такой вот задачки что
[13:54.000 --> 14:02.000]  там и все иксы от нуля до единицы да вот такие неравенство и вот такая целевая функция
[14:02.000 --> 14:09.880]  скорее всего все по 05 когда задача симметричная вот такая да то естественно предположить что
[14:09.880 --> 14:18.560]  ну как при перестановке переменных мало чего меняется да наверное они все по 05 вот для
[14:18.560 --> 14:22.960]  такого симметричного графа и правда решение будет оптимальным по 05 и оптимальное значение
[14:22.960 --> 14:33.160]  целевой функции будет какое 3 да оптимальное значение целевой функции будет 3 можем мы здесь
[14:33.160 --> 14:45.600]  достичь тройки можем да так отлично да то есть взять просто через одну можем достичь отлично
[14:45.600 --> 14:47.360]  чудесно
[14:49.360 --> 14:55.200]  давайте теперь еще один пример рассмотрим то есть бывают случаи когда оптимальное значение
[14:55.200 --> 15:02.640]  вот здесь вот совпадает с настоящим оптимумом давайте рассмотрим еще один пример а если бы
[15:02.640 --> 15:11.920]  я вообще теперь провел провел все прям возможные ребра все все все невозможные но я здесь может
[15:11.920 --> 15:17.840]  какое-то ребро забыл но теперь представим что у нас полный граф на шести вершинах что тогда
[15:26.640 --> 15:32.240]  если возьмем только одну вершину например а то у нас куча ребер не не запачканы и это
[15:32.240 --> 15:45.960]  ребро и это это так 3 5 5 вот все кроме одной можно взять если какие-то две вершины забудем
[15:45.960 --> 15:51.920]  пару вершин то в полном графе между любой парой вершин есть ребро значит и ребро забудем да а вот
[15:51.920 --> 15:57.160]  если мы все кроме одной вершины возьмем если мы возьмем все кроме одной вершины все кроме
[15:57.160 --> 16:04.440]  f например то это оптимальное покрытие и меньше никак не получится да то есть оптимальное покрытие
[16:04.440 --> 16:13.640]  в этой задачке у нас содержит все вершины кроме одной вот а оптимальное значение вот такой программы
[16:13.640 --> 16:18.320]  какой получится ну представьте что здесь еще побольше неравенств по-прежнему очень симметричная
[16:18.320 --> 16:24.000]  такая программа да теперь здесь вообще все пары вершин присутствует в левых частях но функция
[16:24.000 --> 16:30.800]  это целевая опять вот такая же да и все переменные опять скорее всего будут по 0 5 но они будут по 0 5 да и
[16:30.800 --> 16:36.520]  оптимальное значение 5 тройка получается и что будет когда мы рассматриваем полные графы на
[16:36.520 --> 16:42.960]  все большем и большем числе вершин по-прежнему ведь оптимальное значение здесь это все вершины
[16:42.960 --> 16:51.160]  кроме одной взять n минус 1 оптимальное значение здесь какое получается n пополам да n пополам и
[16:51.160 --> 16:58.160]  при деле у нас отношение оптимального значения нашей целевой функции в комбинаторной задачи
[16:58.160 --> 17:04.320]  к оптимальному значению целевой функции в релаксации будет 1 2 ну или 2 в какую сторону посмотреть да
[17:10.320 --> 17:15.840]  брун свесов а какие у нас на рисах то и не было определенных ограничений просто положительные
[17:15.840 --> 17:21.320]  числа какие-то мы в линейной релаксации всегда делаем одно и то же мы единственное условие
[17:21.320 --> 17:27.520]  которым жертвуем это целочисленность вот всегда здесь это абсолютно технический момент как мы
[17:27.520 --> 17:35.080]  ставим линейный релаксация творческий момент состоит в том как вы закодируете комбинаторную
[17:35.080 --> 17:40.520]  задачу с помощью цлп а вот уже совершенно технический момент автоматически это как вы
[17:40.520 --> 17:48.600]  цлп перейдете к лп смотрите бывает бывает разные ситуации и мы понимаем что в пределе бывает так
[17:48.600 --> 17:56.760]  что оптимумы в релаксации их комбинаторная задача отличаются вдвое вот эта штука мы про
[17:56.760 --> 18:06.160]  нее пока что не будем подробнее говорить она называется она называется ну что-то типа разрыв
[18:06.160 --> 18:10.680]  связанный с целочисленностью по-английски это будет интегрэлити гэп интегрэлити это
[18:10.680 --> 18:17.480]  целочисленность гэп это разрыв дистанция вот интегрэлити гэп для этой задачки у нас
[18:17.480 --> 18:25.520]  получать для задачи о вершинном покрытии равен 1 2 чем он больше тем хуже это значит что тем
[18:25.520 --> 18:31.480]  больше мы потеряли как бы как раз когда вот целочисленность отбросили ну что ж давайте
[18:31.480 --> 18:39.920]  попытаемся мы все равно добиться как какого-то использования до позитивного вот этой релаксации
[18:39.920 --> 18:49.360]  для решения комбинаторной задачки а мы сейчас вот эту двойку сможем сможем достичь в рюкзаке
[18:49.360 --> 18:55.640]  помните та же история была мы придумали алгоритм который вдвое ошибается вот здесь тоже у нас
[18:55.640 --> 19:00.960]  будет алгоритм который вдвое ошибается но не то что вообще всегда при использовании линейной
[19:00.960 --> 19:07.120]  релаксации в любой задачке у нас всегда ошибка вдвое это конечно неправда просто так совпало вот
[19:07.120 --> 19:14.320]  что рюкзак и вершинное покрытие одинаковую по константу аппроксимации имеют давайте
[19:14.320 --> 19:20.760]  предположим что мы решили задачки задачку релаксацию и получили вот такой вот набор значений x и
[19:20.760 --> 19:39.560]  со звездочками пусть это оптимальное решение оптимальное решение линейной релаксации так
[19:39.560 --> 19:47.080]  чудесно чего мы про него знаем мы знаем что если мы запишем значение целевой функции на вот
[19:47.080 --> 19:54.800]  этих вот иксах подставим иксе со звездочками целевую функцию то эта штука будет меньше или
[19:54.800 --> 20:03.760]  равна чем оптимальный оптимальный вес вершинного покрытия да вот в этой задачке а мы с вами
[20:03.760 --> 20:11.360]  обозначали вот опт не будет в рюкзаке отлично вы знаете да что это значит вы знаете что это есть
[20:11.360 --> 20:16.240]  оптимальное значение целевой функции в исходной кабинаторной задачи с которым мы как раз сравниваемся
[20:16.240 --> 20:27.280]  умеем умеем умеем то есть есть как раз смысл в чем почему мы работаем с линейной
[20:27.280 --> 20:31.320]  релаксации потому что задача линейного программирования решается за полинамеральное
[20:31.320 --> 20:36.240]  время причем не просто в теории знаете в теории есть такая штука называется галактические
[20:36.240 --> 20:44.000]  алгоритмы серьезно галактические алгоритмы это такой сленг конечно нету формального
[20:44.000 --> 20:49.560]  определения но все компьютер-сантисты понимают это одинаково это такие алгоритмы которые
[20:49.560 --> 20:55.600]  формально быстрые даже могут быть линейные а линейный алгоритм что может быть круче да но у
[20:55.600 --> 21:01.560]  них такая константища в большом ну типа там 10 в десятый в десятый в десятый так вот что как бы
[21:01.560 --> 21:07.200]  чтобы почувствовать превосходство этого алгоритма на другими придется слишком долго жить вот и
[21:07.200 --> 21:12.000]  слишком большие данные подавать на вход этого алгоритма вот тогда мы возрадуемся но то есть
[21:12.000 --> 21:17.960]  алгоритмы которые имеют преимущество только в рамках входных данных галактических масштабов
[21:17.960 --> 21:23.200]  вот они называются галактическими алгоритмами но линейное программирование это задачка для
[21:23.200 --> 21:27.560]  которой есть вовсе не галактические а супер практические алгоритмы вот мы с вами говорили что
[21:27.560 --> 21:39.120]  задачи лп не ци лп лп да они решаются легко на там десятках тысяч неравенств и там тысячах
[21:39.120 --> 21:46.480]  переменных не проблема и вы это почувствуете когда будете решать как раз я надеюсь когда
[21:46.480 --> 21:52.400]  будете задача о вершинном покрытии решать тоже с помощью лп релаксации а вот исходная задача
[21:52.400 --> 21:58.240]  ци лп поскольку она один в один кодировала трудную нп трудную комбинаторную задачу то она
[21:58.240 --> 22:03.760]  сама тоже нп трудная получается и нам ничего не гарантируется есть солверы которые решают
[22:03.760 --> 22:09.320]  задачки целочисленного программирования но они вам не гарантируют чтобы такую задачу быстро
[22:09.320 --> 22:17.360]  решить они начнут работать на дне когда закончат это уж как повезет так что так что так но для
[22:17.360 --> 22:27.400]  ци лп есть там google у артулс есть уробия всякие гл пк солверы есть так так вот давайте мы подумаем
[22:27.760 --> 22:36.040]  как можно было бы округлить решение вот это вот так чтобы получилось решение исходной
[22:36.040 --> 22:41.240]  комбинаторной задачи помните что мы делали в рюкзаке но в рюкзаке у нас только одна
[22:41.240 --> 22:48.360]  переменная была не целочисленная там все было хорошо и мы ее округляли куда вниз чтобы в рюкзак
[22:48.360 --> 22:56.640]  точно все влезло вот здесь у нас переменные ну не понятно какие из них целочисленные вот
[22:56.640 --> 23:02.960]  у нас пример был только что где все переменные не целочисленные все по 1 2 но давайте мы рассмотрим
[23:02.960 --> 23:11.640]  вот такое округление давайте мы я обозначу через x vs крышкой округленное значение давайте
[23:11.640 --> 23:21.920]  переменной просто округлим к ближайшему целому то есть возьмем округлим к единичке если исходное
[23:21.920 --> 23:30.720]  значение этой переменной было больше равно 1 2 и к 0 иначе ну куда уж интуитивнее да округляй
[23:30.720 --> 23:38.000]  к ближайшему целому вот 1 2 мы будем округлять все-таки к единичке они к нулю ну может показаться что
[23:38.000 --> 23:45.600]  это вот особенно в свете наших примеров да вот этих вот там шестиугольника например это ужасно
[23:45.600 --> 23:51.840]  потому что у нас здесь все переменные были по 1 2 и мы бы их все округлили к единичке то есть
[23:51.840 --> 23:57.320]  мы бы взяли все вершины графа просто покрытие но с другой стороны но мы ошиблись бы в два раза
[23:57.320 --> 24:03.600]  оптимальное покрытие из трех вершин а мы взяли бы все вершины мы уже представляем что может быть
[24:03.600 --> 24:12.520]  вдвое мы да нам придется ошибаться иногда может быть придется давайте посмотрим что мы хотя бы
[24:12.520 --> 24:19.120]  корректное решение получаем помните у нас в дискретной оптимизации есть такая терминология
[24:19.120 --> 24:25.560]  коррект допустимые решения feasible solutions и оптимальные решения вот первое что нам нужно это хотя
[24:25.560 --> 24:31.960]  бы чтобы у нас получилось допустимое решение чтобы условия главные были соблюдены на структуру
[24:31.960 --> 24:39.240]  решения а потом мы уже думаем а как соотносится качество нашего решения там стоимость вес да там
[24:39.240 --> 24:47.000]  и так далее с оптимальной возможной стоимостью но сначала мы всегда про допустимость думаем вот
[24:47.000 --> 24:53.320]  будет ли такое решение допустимо верно ли что если мы возьмем вот эти вот значения и с крышками
[24:53.320 --> 25:00.720]  подставим в наше неравенство вот в эти то они будут выполняться по-прежнему а почему
[25:00.720 --> 25:18.120]  да все четко да мы в рюкзаке кстати говоря уже помните занимались таким делом мы две
[25:18.120 --> 25:24.960]  еврестики придумали и сумма этих эврестик давала рюкзак как минимум оптимальный значит лучше из
[25:24.960 --> 25:29.400]  этих эврестик была как минимум половинка от оптимального рюкзака если у нас сумма двух
[25:29.600 --> 25:33.440]  как минимум единицы то наибольшее из этих чисел как минимум 1 вторая и
[25:33.440 --> 25:40.200]  значит поскольку исходно иксы со звездочками это оптимальное решение вот этой вот задачки
[25:40.200 --> 25:46.200]  значит они удовлетворяли вот этим неравенством то есть для каждого их со звездочкой вот такие
[25:46.200 --> 25:50.680]  суммы были больше равнединицы после округления стало быть хотя бы 1 из этих
[25:50.680 --> 25:55.840]  cot круглица единицы его этого неравенства слева будет как минимум одна единица после
[25:55.840 --> 26:03.820]  округления, а может быть и все 2 единицы, так? Значит, мы получаем, да, я давайте это
[26:03.820 --> 26:11.240]  запишу как-то, ну более-менее аккуратно, что для каждого ребра E вида AB
[26:11.240 --> 26:17.680]  х со звездочкой h-ная плюс х со звездочкой b-шная было больше или равно 1, потому что мы
[26:17.680 --> 26:28.040]  рассмотрели решение задачки. Следовательно, максимум, максимальное из чисел х со
[26:28.040 --> 26:37.880]  звездочкой a, х со звездочкой b больше и равняется 1 и 2. Следовательно, либо xA
[26:37.880 --> 26:44.480]  с крышкой равно 1, либо xB с крышкой равно 1, согласно тому, как мы их
[26:44.480 --> 26:50.800]  округляем, а может быть они оба равны 1, кто ж их знает. Получится, может и так.
[26:50.800 --> 27:02.320]  Ну и следовательно, вот отсюда уже вытекает, что х с крышкой A плюс х с крышкой B
[27:02.320 --> 27:07.520]  больше или равно 1. То есть это округленное решение по-прежнему является
[27:07.520 --> 27:13.040]  допустимым решением вот этой вот линейной программы.
[27:14.480 --> 27:27.080]  Но теперь давайте мы, да, я это удалю наверно уже, сотру. Вот теперь давайте
[27:27.080 --> 27:35.120]  посмотрим насчет стоимости. Про корректность сказали, теперь про стоимость.
[27:35.120 --> 27:42.160]  Стоимость у нас определяется чем? Суммарным весом тех вершин, которые мы взяли.
[27:42.160 --> 27:46.480]  Смотрите, вот эти перемены округленные, они уже имеют комбинаторный смысл, правда?
[27:46.480 --> 27:52.240]  Это уже все, нолики и единички. То есть их можно трактовать как действительно подможество вершин
[27:52.240 --> 27:57.400]  графа, как покрытие. Мы действительно убедились, что это покрытие и его вес
[27:57.400 --> 28:08.760]  получается таким. Х с крышкой с индексом v помножить на w с индексом v, по всем v.
[28:13.080 --> 28:19.040]  Вот теперь давайте убедимся, что выполнено неравенство, что вот эту штуку
[28:19.040 --> 28:26.840]  можно оценить сверху удвоенной суммой. Х со звездой v помножить на w с индексом v.
[28:26.840 --> 28:36.000]  Вот почему так? Это вес нашего эвористического покрытия, да? Вес
[28:36.000 --> 28:55.960]  полученного покрытия. Да, потому что для каждого из х при переходе от звездочки к крышке мы
[28:55.960 --> 29:01.200]  увеличиваемся не больше чем вдвое. Если х был меньше 1 и 2, то он вообще уменьшился, а не
[29:01.200 --> 29:08.440]  увеличился. А если х увеличился, то он увеличился как минимум с одной второй до единицы. То есть
[29:08.440 --> 29:16.080]  отношение х с крышкой к х со звездочкой никогда не превосходит двойку. И вот это вот неравенство,
[29:16.080 --> 29:22.320]  оно следует из оценки просто для каждого слагаемого. Вот здесь у нас тоже неравенство с тем
[29:22.320 --> 29:28.280]  же коэффициентом 2, поэтому для суммы получается неравенство с коэффициентом 2. Ну и теперь мы
[29:28.280 --> 29:36.560]  можем взять вот эту штуку и заметить, что она не больше оптимума. То есть продолжить это, да? Не
[29:36.560 --> 29:44.920]  больше чем 2 на оптимум. О, классно, мы с вами уложились в первую половину пары и обосновали,
[29:44.920 --> 29:49.720]  что решение, полученное округлением просто к ближайшему целому, оно не только корректно,
[29:49.720 --> 29:54.680]  но оно еще и дает вершинное покрытие, веса не более чем удвоенный оптимум.
[29:54.680 --> 30:03.520]  Так, смотрите, что мы сейчас делаем. Мы вернемся сейчас к задаче о покрытии, но невзвешенной,
[30:03.520 --> 30:07.040]  и поговорим с вами про какой-нибудь комбинаторный алгоритм. Вот смотрите,
[30:07.040 --> 30:10.400]  в рюкзаке так было удобно, но мы там поговорили по ходу дела про линейное программирование,
[30:10.400 --> 30:16.000]  бла-бла-бла, а потом все равно предъявили ивристики, которые новее на линейном
[30:16.000 --> 30:20.600]  программировании, но можно без него обойтись. А здесь вроде как получается, что я вам предлагаю
[30:20.600 --> 30:25.360]  использовать там какой-то сторонний solver для того, чтобы решать вот эту вот задачу. Ну там simplex
[30:25.360 --> 30:30.440]  метод, например, закодить. Да, вот как бы нам от этого избавиться, по крайней мере, здесь. И вот
[30:30.440 --> 30:34.880]  мы сейчас как раз про это поговорим. Вот про комбинаторный алгоритм для задачи о вершинном
[30:34.880 --> 30:47.280]  покрытии. И начнем мы с вами. Можно я это сотру? Тогда можно я это сотру? Белое на белом плохо пишет.
[30:47.280 --> 31:03.120]  Хорошо. Ну вот эта вот штука мне еще понадобится, а вот что-то из этого я бы начал, наверное,
[31:03.120 --> 31:11.760]  стирать. Давайте рассмотрим вот такой вот комбинаторный алгоритм для задачи о покрытии
[31:12.120 --> 31:25.160]  без весов. Ну или когда все веса одинаковые. Комбинаторный алгоритм отлично для невзвешенной
[31:25.160 --> 31:43.440]  задачи vertex cover. Значит, этот алгоритм у нас будет выглядеть следующим образом.
[31:43.440 --> 31:52.200]  Простой да безобразие. Давайте возьмем graph и пройдемся по всем ребрам просто по одному разу.
[31:52.200 --> 32:01.200]  Берем ребро. Видим, это ребро не покрыто, не запачкано. И давайте оба конца этого
[32:01.200 --> 32:08.680]  ребра запачкаем, чтобы наверняка оба конца этого ребра отмечаем. При этом вместе с этим ребром
[32:08.680 --> 32:17.720]  естественно оказываются запачканными еще, наверное, какие-то ребра. Но давайте я еще
[32:17.720 --> 32:22.760]  даже два ребра в одну вершину нарисую идущими. Все ребра, перечисленные на картинке, они запачканы.
[32:22.760 --> 32:27.080]  Но может быть осталось не запачканным еще какое-нибудь ребро. Давайте мы такое ребро
[32:27.080 --> 32:33.480]  найдем, если оно есть. И давайте мы его тоже запачкаем, оба конца причем. Опять-таки,
[32:33.480 --> 32:38.600]  получается, что у нас много чего дополнительно еще запачканное. Потом найдем еще ребро,
[32:38.600 --> 32:45.200]  если такое есть, не запачканное. Опять оба его конца. Вообще неважно в каком порядке. Просто
[32:45.200 --> 32:50.200]  по разу рассматриваем каждое ребро. И если на момент просмотра очередного ребра оно оказывается
[32:50.200 --> 32:57.600]  еще не запачканным, мы оба его конца берем и закрашиваем. Странный алгоритм, но точнее вообще
[32:57.600 --> 33:03.360]  непонятно, насколько он хороший. Единственное, что понятно сразу, это что он корректный. То есть,
[33:03.360 --> 33:08.080]  что он строит вершинное покрытие. Это правда. Он точно покроет все ребра, потому что он каждое
[33:08.080 --> 33:14.760]  по одному разу просмотрел и гарантировал, что это ребро покрывается. Только один. Да.
[33:14.760 --> 33:24.120]  Вот. Хотя бы так. И вот алгоритм у нас строит некое множество V' вершин, которое точно вершинное
[33:24.120 --> 33:31.960]  покрытие. Давайте убедимся, что это множество V' по мощности не превосходит, опять-таки,
[33:31.960 --> 33:39.800]  удвоенный оп. Смотрите-ка, без всякого линейного программирования. Удвоенный оп. И сделаем это
[33:39.800 --> 33:48.920]  с вами вот каким образом. Мы воткнем между этим множеством и оптом некоторую промежуточную
[33:48.920 --> 33:56.000]  штуку. Что это будет за штука? А давайте посмотрим на множество ребер, которые в этом алгоритме
[33:56.000 --> 34:01.240]  сыграли. То есть, как раз вот те ребра, для которых, когда мы их рассматривали, оказывалось, что на этот
[34:01.240 --> 34:07.200]  момент времени это ребро еще не было покрыто. Вот раз ребро, вот два ребро, вот три ребро. Например,
[34:07.200 --> 34:13.800]  как на картинке. Что про эти ребра можно сказать? Что они не имеют общих концов, правда? Потому что
[34:13.800 --> 34:20.720]  если мы в очередной раз ребро смотрели и говорили, о боже мой, оно еще не запачкано, то это потому,
[34:20.720 --> 34:27.120]  что ни один из его концов не был раньше запачкан. Это значит, что это ребро не имеет общих концов,
[34:27.120 --> 34:34.320]  ни с одним из запачканных досели ребер. Вот. Итак, если мы посмотрим на множество ребер,
[34:34.320 --> 34:40.680]  которые вот как раз мы отмечали, то они образуют то, что называется в теории графов как пара сочетания.
[34:40.680 --> 34:47.560]  Множество ребер без общих концов. То есть, итог работы алгоритма, можно сказать, это не только подмножество
[34:47.560 --> 35:00.680]  вершин V, а это еще и вот такое подмножество специальных ребер. Итог. V' это покрытие. Но еще у нас
[35:00.680 --> 35:10.720]  есть подмножество ребер, некое специальное, которое мы называем пара сочетания. И теперь давайте
[35:10.720 --> 35:16.520]  посмотрим на какую-то такую абстрактную картинку. Вот в графе есть пара сочетания, но, например,
[35:16.520 --> 35:24.440]  на четырех ребрах без общих концов. Какой минимальный, самый-самый минимальный размер покрытия
[35:24.440 --> 35:32.000]  для этого графа может быть? Как минимум количество ребер. Вот эти. Потому что из каждого ребра мы
[35:32.000 --> 35:37.840]  должны запачкать хотя бы одну вершину. И поскольку все вершины у этих ребер, все-все разные, то это
[35:37.840 --> 35:43.320]  значит, что на каждом ребре мы берем хотя бы по одной какой-то уникальной вершине. Как минимум
[35:43.320 --> 35:51.960]  четыре штуки нам взять придется. То есть, мы с вами понимаем, что как только в графе мы смогли обнаружить
[35:51.960 --> 35:58.560]  пара сочетания, какое-то m, мы понимаем, что оптимальное вершинное покрытие, которое я по-прежнему
[35:58.560 --> 36:04.720]  буду обозначать OPT, имеет размер не меньше, чем m. И с каждого ребра нам придется взять хотя бы по
[36:04.720 --> 36:10.960]  одной вершине в это покрытие, и все они будут разные, эти вершины. А как связаны v' количество
[36:10.960 --> 36:16.640]  вершин, отмеченных нами, и m, количество ребер, которое в пара сочетаний вошло? Они как раз связаны
[36:16.640 --> 36:30.440]  понятным образом v' равняется 2m, ну две мощности m. Давайте я здесь мощности поставлю, все-таки мощность
[36:30.440 --> 36:42.240]  v' равняется удвоенной мощности m. Вот этот сюжет позволяет мне поговорить о очень важном для
[36:43.240 --> 36:51.320]  всего, не только для дискретной оптимизации, а для вообще информатики, понятии сертификата. Вот у вас
[36:51.320 --> 37:00.000]  про NP ничего вы не говорили? Да, были, отлично. Вот там мы определяем целый класс сложностной, как
[37:00.000 --> 37:05.520]  класс-задач, для которых существуют полинамиально проверяемые сертификаты в случае положительного
[37:05.520 --> 37:11.360]  ответа. Если ответ задач отрицательный, то у нас не должен существовать никакой сертификат вообще,
[37:11.360 --> 37:16.800]  а если ответ положителен, то должен существовать полинамиально проверяемый сертификат. Как мы его
[37:16.800 --> 37:22.840]  добудем, кто для нас его добудет, это в классе NP никак не уточняется, но должен быть. Вот здесь
[37:22.840 --> 37:28.160]  вот мы что с вами смогли сделать? Мы смогли мало того, что решить исходную задачу, ну приближенно
[37:28.160 --> 37:34.680]  решить, естественно, мы смогли получить некий сертификат не оптимальности, потому что мы не
[37:34.680 --> 37:40.080]  претендуем на оптимальное решение NP трудной задачи, а сертификат качества. Мы говорим, что вот
[37:40.080 --> 37:46.760]  это парасочетание, которое мы предъявляем, показывает, что меньше, чем вот столько-то вершин даже
[37:46.760 --> 37:54.240]  самое-самое лучшее покрытие в этом графе не может содержать. Да, ну и это неплохо. Это неплохо,
[37:54.240 --> 37:59.440]  когда мы можем доказать другому человеку, не заставляя его решать за нас ту же самую задачу,
[37:59.440 --> 38:07.000]  перевешивать, мы можем как-то обосновать, что мы получили не самое плохое решение. Так вот,
[38:07.000 --> 38:15.200]  если про это я предлагаю нам запомнить, что вот здесь у нас возникает такой сертификат качества.
[38:15.200 --> 38:27.920]  Давайте мы теперь попробуем это все обобщить как-то на веса, на случай с весами. Попытаемся
[38:27.920 --> 38:42.120]  обобщить это на веса. Так, да, ну мы сказали, что у нас есть такой алгоритм поиска вершинного
[38:42.120 --> 38:47.160]  покрытия на графе, что этот алгоритм по итогам своей деятельности выдает не только вершинное
[38:47.160 --> 38:53.120]  покрытие, но еще и парасочетание. И это парасочетание, которое он выдает, является сертификатом
[38:53.120 --> 38:58.200]  определенного качества того вершинного покрытия, которое мы выдали. То есть, грубо говоря, смотрите,
[38:58.200 --> 39:04.600]  вот представьте, что вы запустили граф, и по этому графу вы построили покрытие и сказали,
[39:04.600 --> 39:12.280]  что вот v' у вас там содержит 20 вершин, а еще вы предъявили паросочетание, которое содержит,
[39:12.280 --> 39:20.760]  ну там скажем, 10 ребер. И там скажем, да, у нас получается всегда так, что v' по мощности
[39:20.760 --> 39:29.160]  удвоенная m. Мы точно тогда знаем, что opt не меньше 10, правильно? И это значит, мы точно знаем,
[39:29.160 --> 39:36.440]  что вот это 20, это не больше, не хуже, чем в два раза, чем оптимальное решение, не хуже, чем в два раза.
[39:40.800 --> 39:47.440]  Причем вот это m, да, это доказательство, можно считать доказательством, потому что человеку
[39:47.440 --> 39:53.280]  предъявляешь 10 ребер без общих концов, но кто не поверит, что нужно у каждого из этих ребер хотя
[39:53.280 --> 40:01.160]  бы по одной вершине покрытия включить, да, вот, и все. 10 ребер значит, как минимум, 10 вершин войдут в любое
[40:01.160 --> 40:13.000]  покрытие, сколько угодно оптимально. Да не за что, всегда рад. Могу еще там не с 20 и 10, а, например,
[40:13.000 --> 40:22.160]  с 30 и 15, может, еще понятнее. Так вот, давайте попробуем наш успех продлить на задачку с весами,
[40:22.160 --> 40:30.480]  да, значит, как мы это с вами будем делать? А мы, да, сначала давайте посмотрим, что этот алгоритм крайне
[40:30.480 --> 40:35.120]  плохо работает на задачи с весами. Достаточно рассмотреть какой-нибудь такой граф, вот такую
[40:35.120 --> 40:46.560]  звезду, у которой вершины крайние, они веса 1, дешевые, а центральная вершина, ну, какая-нибудь супердорогая,
[40:46.560 --> 40:53.480]  там 10 в шестой, миллион. Какое оптимальное покрытие у этого графа? Понятно, что лучше взять больше
[40:53.480 --> 41:00.480]  вершин по количеству, зато меньше по весу, там взять всего 6 вершин. Но что сделает наш вот такой
[41:00.640 --> 41:10.040]  комбинаторный алгоритм? Он посмотрит на первое попавшееся ребро и сразу оба его конца возьмет, бах-бах, да. А у нас же
[41:10.040 --> 41:17.240]  задача о покрытии взвешенная бывает, вот, собственно, когда мы алгоритм, не, на ребрах нет весов, вот это
[41:17.240 --> 41:25.160]  вершины веса 10 в шестой, эти все по 1, вот. То есть, вот брать так сразу у каждого ребра, да у любого
[41:25.160 --> 41:30.640]  ребра, брать сразу, а промечь его оба конца, это как-то слишком плохо годится вот для такого типа графов,
[41:30.640 --> 41:37.600]  у которых очень неравномерно распределены веса. Чего ж делать? А все равно мы справимся с вами, вот.
[41:37.600 --> 41:44.400]  Просто у нас алгоритм будет другой немножко, у нас доказательство собственное, доказательство качества, да,
[41:44.400 --> 41:54.520]  вот этот сертификат качества будет немножко отличаться от парасочетания. Давайте мы посмотрим
[41:54.560 --> 42:03.400]  на вот эту задачку, на вот эту вот задачку и сделаем из вот этой вот системы неравенств некоторые выводы.
[42:03.400 --> 42:12.360]  Давайте повспоминаем школьную алгебру. Если у нас есть два неравенства одного знака, то мы можем эти
[42:12.360 --> 42:19.000]  неравенства сложить, правда, и получить неравенство того же самого знака. Чудесно. А еще, если у нас есть
[42:19.160 --> 42:24.480]  неравенство, то мы можем его, это неравенство, домножить на положительное число, ну, на не отрицательное
[42:24.480 --> 42:30.840]  число даже, и получить по-прежнему верное неравенство. Стало быть, мы можем с вами вот что сделать.
[42:30.840 --> 42:38.280]  Давайте представим, что для каждого неравенства, вот из этих, мы взяли некоторую константу, которую я
[42:38.280 --> 42:46.600]  назову y с индексом e. Ну, поскольку вот такое неравенство соответствует ребру, да, то логично это
[42:46.600 --> 42:51.720]  неравенство само связать с этим ребром, ну и вот с этим ребром связать соответствующую какую-то
[42:51.720 --> 42:57.800]  константу. Вот возьму я такую константу, не отрицательную, домножу вот такое неравенство на эту
[42:57.800 --> 43:10.400]  константу. У меня получится неравенство вида xA на yE плюс xB на yE больше или равно, чем yE. Я
[43:10.400 --> 43:15.000]  каждое неравенство могу домножить на свою константу, да, потом могу взять эти же неравенства
[43:15.000 --> 43:23.120]  все одного знака, я могу взять бабах сложить. Что получится тогда? Что же у меня тогда получится?
[43:23.120 --> 43:40.560]  Получится такая сумма слева по всем ребрам и сумма справа по всем ребрам. Вот такая странная штука
[43:40.760 --> 43:49.480]  получится. Причем вот здесь у меня, я уже убрал эти индексы A и B, потому что для каждого ребра E это
[43:49.480 --> 43:58.160]  будут свои какие-то концы, это будут свои концы. А вот теперь я хочу сделать вот что, я хочу
[43:58.160 --> 44:06.720]  перегруппировать немножко вот эту вот часть так, чтобы у меня сумма была теперь по вершинам. Я
[44:06.720 --> 44:13.280]  хочу это преобразовать сумму по всем вершинам графа и здесь уже, чтобы у меня был x соответствующей
[44:13.280 --> 44:19.440]  вершине, ну а тут было может быть какой-то уже коэффициент при этом x. Правую часть я оставлю
[44:19.440 --> 44:27.920]  без изменений пока. Вот что будет, если мы с вами в этих всех членах, которые суммируются, перегруппируем
[44:27.920 --> 44:36.600]  их так, чтобы x вытащить, а при каждом x сложить все y, которые там на него домножаются. Что у нас
[44:36.600 --> 44:43.920]  тогда получится? Давайте посмотрим, какие пары x и y участвуют вообще вот здесь. Это всегда какая-то
[44:43.920 --> 44:50.700]  пара x соответствующей какой-то вершине графа и y соответствующей какой-нибудь ребру графа. Причем
[44:50.700 --> 44:57.200]  эти вершины и ребро это же не просто абы какие, а вершина является концом ребра. Правда? Мы изначально
[44:57.200 --> 45:03.440]  брали неравенство соответствующей ребру и в это неравенство входили x, которые соответствуют
[45:03.440 --> 45:10.120]  вершинам концам этого ребра. Стало бы теперь, когда мы перегруппируем эту сумму и вытащим
[45:10.120 --> 45:18.440]  отдельно x, при каждом x будет стоять сумма всех таких y, всех таких ребер, по всем таким ребрам,
[45:18.440 --> 45:26.440]  которые торчат из вершины v. То есть по-прежнему, чтобы получались пары всевозможные вида x, v на y,
[45:26.440 --> 45:33.680]  к е, где вершина v является концом ребра е. Ведь именно такие пары здесь все равно и стоят. Так,
[45:33.680 --> 45:41.880]  как бы нам это записать? Вам знакомы такое обозначение? Delta от v множество всех ребер
[45:41.880 --> 45:50.200]  графа, которые инцидентны вершине v. Отлично, значит это новое знание для нас. Это множество
[45:50.200 --> 45:55.800]  всех ребер, торчащих из вершины v, но математически говорят ребра инцидентны вершине v.
[45:55.800 --> 46:02.480]  Вот мы с вами здесь это в сумме и напишем. Я напишу крупно, чтобы всем было видно. Сумма по всем
[46:02.480 --> 46:13.200]  е, торчащим из вершины v. Здесь у нас y с индексом е. Это просто перегруппировка вот этого
[46:13.200 --> 46:19.760]  неравенства. Ну а правую часть я оставлю, больше ли равно, чем сумма y с индексом е,
[46:19.760 --> 46:38.720]  просто по всем ребрам графа. Так, чудесно. А давайте теперь предположим, что для каждой вершины
[46:38.720 --> 46:46.400]  вот эта сумма, которая здесь стоит, меньше ли равна, чем вес этой вершины. Пусть для каждой
[46:46.400 --> 46:54.480]  вершины сумма, которая, давайте я просто вот стрелочку так поставлю, вот эта вот сумма,
[46:54.480 --> 47:09.080]  меньше ли равняется, чем вес соответствующей вершины. Тогда я мог бы продолжить это неравенство.
[47:09.080 --> 47:15.360]  Я бы мог сказать, ага, если вот эта штука, каждая такая скобка, меньше ли равна, чем
[47:15.360 --> 47:24.480]  вес соответствующей вершины, то тогда вот эта штука, меньше ли равна, чем xv помножить на w.
[47:24.480 --> 47:35.160]  А где у меня встречается такое выражение xv помножить на w? Да, это целевая пункция. Вот оно,
[47:35.160 --> 47:43.640]  вот оно это выражение. xv, помноженное на w. То есть, если вдруг я подобрал y, так что это
[47:43.720 --> 47:51.080]  произвольные какие-то положительные числа, но если вдруг дополнительно окажется, что сумма вот такая,
[47:51.080 --> 48:00.280]  каждая, не превосходит w, то тогда все вот это выражение будет меньше или равно, x-ы-то не отрицательные,
[48:00.280 --> 48:06.560]  эта штука не отрицательная, w не отрицательные, значит, можно продолжать по-прежнему по такому
[48:06.560 --> 48:15.360]  неравенству, это бы оказалось меньше или равно, чем значение целевой функции. Тогда, значит, вот эта
[48:15.360 --> 48:22.960]  вот сумма y, которая здесь стоит, оказалась бы меньше или равна, чем значение целевой функции.
[48:22.960 --> 48:34.160]  Так, чем сумма w с индексом v, помножить на x с индексом v по всем v-шкам.
[48:34.160 --> 48:53.440]  Могу вам что-то пояснить? Давайте. Что мы сделали? Мы сказали, что есть такие школьные правила,
[48:53.440 --> 48:57.200]  что если взять неравенство и домножить его на положительное число, то это неравенство
[48:57.200 --> 49:03.200]  останется верным. А еще неравенство одного знака можно складывать. И вот мы говорим,
[49:03.200 --> 49:09.600]  у нас есть столько неравенств по одному для каждого ребрографа, давайте мы каждое такое неравенство
[49:09.600 --> 49:14.860]  домножим на какое-то пока неизвестное число, которое мы потом выберем,
[49:14.860 --> 49:20.080]  выберем чему его положить равным. Пока просто предположим, что для каждого ребрографа мы выбрали
[49:20.080 --> 49:25.220]  какой-то y или зафиксировали какой-то y, домножили на него такое неравенство,
[49:25.220 --> 49:30.080]  а потом все эти неравенства, раз они одного знака по-прежнему, мы их поскладывали. Получится
[49:30.080 --> 49:36.360]  неравенство, по-прежнему того же знака, у которого в одной части стоит сумма
[49:36.360 --> 49:41.160]  единичек, помноженных на у, это как раз вот эта сумма, а в другой части у него
[49:41.160 --> 49:50.120]  стоит сумма у с индексом е, помножить на xа, плюс у с индексом е, помножить на xb, да, вот
[49:50.120 --> 49:53.920]  эта штука. Дальше мы сказали, а давайте мы вот эту вот часть перегруппируем
[49:53.920 --> 49:57.680]  немножко, запишем просто по-другому. Вот в этой сумме у нас по факту
[49:57.680 --> 50:03.200]  встречаются всевозможные пары x с индексом v на y с индексом е, где x это конец
[50:03.200 --> 50:09.400]  ребра е. Мы распишем эту сумму по-другому, сгруппировав ее по вершинам, тогда здесь
[50:09.400 --> 50:15.160]  мы выносим x с индексом v, а в скобках остается сумма всех тех y, которые
[50:15.160 --> 50:18.920]  соответствуют ребрам, торчащим из вершины v. Это просто такое обозначение
[50:18.920 --> 50:23.960]  стандартное для дискретной оптимизации, ну, для computer science. Не буду присваивать это
[50:23.960 --> 50:28.840]  обозначение дискретной оптимизации, это широкое такое обозначение, стандартное.
[50:28.840 --> 50:36.800]  Так вот, теперь мы дальше говорим. Смотрите, такое неравенство у нас выполнено, но если
[50:36.800 --> 50:41.800]  мы вдруг дополнительно сможем подобрать y так, чтобы каждая такая сумма
[50:41.800 --> 50:48.120]  оказывалась меньше или равна, чем w, то тогда вот эта вот сумма будет меньше или
[50:48.120 --> 50:54.880]  равна тоже с тем же знаком, чем x сумма x вшек на w вшки. А это и есть то, что у нас
[50:54.880 --> 51:00.920]  стоит вот здесь целевой функции. А теперь давайте прочувствуем такой пафосный
[51:00.920 --> 51:12.120]  момент. Пафосный момент. Вот в этом условии, вот в этом условии, а где здесь x вообще?
[51:12.120 --> 51:21.240]  А что мы про них требуем? Да ничего. Ничего. Мы не требуем на x вообще ничего, кроме того,
[51:21.240 --> 51:26.440]  что они должны удовлетворять исходным вот этим вот неравенствам. Мы требуем только на y. Мы
[51:26.440 --> 51:31.760]  накладываем требования только на y, что если y не отрицательные, если для них выполняются вот
[51:31.760 --> 51:37.200]  такие неравенства, то тогда можно взять и оценить какую-то сумму, которая зависит от x в целевую
[51:37.200 --> 51:42.880]  функцию. При любых получается иксахта, от них ничего не зависит. Оценить вот эту вот сумму
[51:42.880 --> 51:51.640]  через сумму y. То есть мы получаем какую-то универсальную оценку, которую мы управляем,
[51:51.640 --> 51:57.600]  на вот такие вот суммы для любых вообще иксов. Но в частности, ведь сюда же можно подставить в
[51:57.600 --> 52:04.400]  частном случае какой-нибудь оптимальный набор иксов, правда? Можно. И значит,
[52:04.400 --> 52:10.120]  минимальное значение вот такой вот суммы тоже может быть оценено снизу суммой вот таких вот
[52:10.120 --> 52:17.520]  y. А минимальное значение вот такой вот суммы, в свою очередь, меньше или равно, мы сейчас про
[52:17.520 --> 52:23.280]  линейную релаксацию с вами говорим, чем оптимальное значение целевой функции в исходной комбинаторной
[52:23.280 --> 52:29.680]  задачи, оптимизации, там бла-бла-бла. То есть вот эта штука меньше или равняется, чем опт.
[52:29.680 --> 52:34.400]  Меньше или равняется, чем опт.
[52:37.400 --> 52:46.760]  Но это как, знаете, вот в матане, если каждый член последовательности не больше, чем какая-то
[52:46.760 --> 52:51.840]  константа, то и предельные значения последовательности не больше, чем эта константа. У нас есть всякие
[52:51.840 --> 52:56.920]  такие предельные теоремы. Но вот здесь у нас тоже получилось, что выполняются такое неравенство
[52:56.920 --> 53:04.120]  независимо от того, какими вы берете иксы. Значит, и при самом-самом-самом оптимальном выборе иксов такое
[53:04.120 --> 53:10.520]  неравенство тоже будет выполняться. Но отлично, это значит, что и для опта мы можем тоже такое
[53:10.520 --> 53:18.560]  неравенство с организовать. Опт можно оценить снизу вот такой суммы y. Так, чудесно. Сколько у нас
[53:18.560 --> 53:31.960]  времени-то? 15 минут. Отлично, мы успеем. Давайте мы теперь это используем наконец.
[53:31.960 --> 53:49.720]  Если мы возьмем, можете повторить,
[53:49.720 --> 54:05.080]  y единицами, но тогда не факт, что у нас вот эти неравенства выполнятся, но это какие веса нам
[54:05.080 --> 54:16.240]  дадут на вход? Это входные данные нашей задачи. W? Не, W это просто произвольные, W это произвольные
[54:16.240 --> 54:22.280]  действительные числа на входе нашей задачи о покрытии. У нас на входе граф и веса на вершинах.
[54:22.280 --> 54:30.960]  На самом деле, то, что мы с вами здесь провернули, это частный случай применения
[54:30.960 --> 54:35.600]  теоремы двойственности в линейном программировании, но я просто не хочу еще тратить время на общий
[54:35.600 --> 54:44.560]  случай. Пока оставим это все вот так, в частном. Давайте алгоритмы сформулируем, комбинаторные,
[54:44.560 --> 54:58.600]  для взвешенной уже теперь задачи о покрытии. Алгоритм для взвешенной задачи о покрытии. Давайте с каждой
[54:58.600 --> 55:10.040]  вершиной графа свяжем переменную x индексом v. Возьмем вот такой набор переменных x индексом v по всем
[55:10.040 --> 55:23.760]  вершинам. Изначально полагаем все эти x равны нулю. Да, вот то, что мы с вами рассмотрели, это мы
[55:23.760 --> 55:29.840]  рассмотрели частные случаи теоремы двойственности для линейного программирования. Если потом смотреть,
[55:29.840 --> 55:39.440]  что читать дополнительно. Не, виноват, давайте это z обозначим. А сейчас я алгоритм напишу для
[55:39.440 --> 55:45.280]  взвешенной задачи о покрытии. Комбинаторный алгоритм, он не будет в себе содержать никакого
[55:45.280 --> 55:50.880]  линейного программирования. Но для его анализа мы с вами задействуем вот эти вот неравенства,
[55:50.880 --> 55:57.320]  которые, в общем-то, мы получили из рассмотрения линейно-программистской формулировки задачи о
[55:57.320 --> 56:06.080]  покрытии. Не просто так они возникли. Давайте введем для каждой вершины графа переменное z,
[56:06.080 --> 56:11.920]  которые мы изначально положим равными нулю. И для каждого ребра графа мы тоже введем свои
[56:11.920 --> 56:23.640]  переменные y, которые изначально тоже полагаются равными нулю. А дальше давайте сделаем похожую
[56:23.640 --> 56:28.440]  процедуру на алгоритм для невзвешенной задачи. Просто одно за другим просмотрим все ребра,
[56:28.440 --> 56:33.840]  и если очередное ребро не покрыто, то мы будем его как-то покрывать. Каким образом? Вот мы
[56:33.840 --> 56:42.800]  сейчас это с этим разберемся. Это такой питоновский псевдокод получается. Для каждого ребра из
[56:42.800 --> 57:01.320]  множества ребер графа, если ребро е не покрыто, если ребро е не покрыто. Ну помните, что мы делали в
[57:01.320 --> 57:07.560]  невзвешенном случае. Мы брали сразу оба конца ребра и в покрытие включали. Вот сейчас мы не
[57:07.560 --> 57:15.000]  будем делать так. Сейчас мы сделаем вот такую штуку. Мы переменную y с индексом e, который у нас
[57:15.000 --> 57:27.240]  есть в запасе, выставим вот в такую величину. Минимум из w, мне нужно ввести здесь обозначение
[57:27.240 --> 57:40.760]  для концов ребра. Давайте я концы этого ребра обозначу через a и b, ладно? w a-z a и w b-z b. Вот,
[57:40.760 --> 57:47.840]  возьмем минимум из этих двух величин и добавим этот минимум к каждой из переменных z. То есть,
[57:47.840 --> 58:02.160]  скажем, что z с индексом a плюс равно y e и z с индексом b плюс равно y e. Но это c++
[58:02.160 --> 58:10.600]  терминология, с которой вы знакомы, c++ синтекс. Это некие переменные, просто которые изначально
[58:10.600 --> 58:18.600]  для всех вершин графа выставлены нулями. Да, w – это вес. Вообще есть разница между
[58:18.600 --> 58:27.160]  ω и w. ω – это греческая буква, у которой хвостики расположены внутрь буквы, это ω. У нее рога
[58:27.160 --> 58:36.640]  внутри. Вот, а w английская, у нее рога наружу. И в одном и том же тексте может встречаться и
[58:36.640 --> 58:45.320]  ω и w, поэтому будьте аккуратны. Ну вот, и теперь дальше мы говорим вот что. После того,
[58:45.320 --> 58:52.760]  как вот эти вот две команды выполнились, что мы можем утверждать гарантированно? То хотя бы одна
[58:52.760 --> 59:00.640]  из вот этих вот двух величин z, она достигнет w соответствующей. Правда, ведь мы изначально так
[59:00.640 --> 59:05.140]  и выбирали вот этот y, который мы добавляем к этим z. Фактически мы его выбирали как раз как
[59:05.140 --> 59:12.220]  минимальное возможное значение, которое после прибавления к вот этим вот величинам доводит
[59:12.220 --> 59:20.700]  их до уровня соответствующей w. Вот теперь мы одну из этих вершин включим в покрытие. То есть
[59:20.700 --> 59:31.540]  дальше мы говорим с вами, что если z а сравнялась с w а, то тогда к v штриху мы добавляем
[59:31.540 --> 59:46.020]  вершину а. И если zb сравнялась с wb, то тогда v штриху мы добавляем еще и b.
[59:46.020 --> 59:53.820]  Точно, а здесь мы их увеличиваем.
[59:53.820 --> 01:00:11.340]  Да, разность. Вот то есть, заметьте, что я хочу, чтобы мы сейчас заметили, что как раз при таком
[01:00:11.340 --> 01:00:18.460]  выборе у мы гарантируем, что хотя бы один из этих двух ифов он выполнится. Мы в него войдем и мы
[01:00:18.460 --> 01:00:24.780]  добавим множество штрих, хотя бы из одну из вершин а и b, а может быть и обе, хотя бы одну из них.
[01:00:24.780 --> 01:00:30.740]  И стало быть, на этом шаге, вот на этом шаге, мы гарантируем, что хотя бы один из концов ребра
[01:00:30.740 --> 01:00:37.340]  е будет взять покрытие. Поэтому этот алгоритм корректен. То есть корректность алгоритма, как и в
[01:00:37.340 --> 01:00:42.780]  случае невзвешенного, помните, невзвешенного алгоритма, она довольно тривиальная. Здесь никакой
[01:00:42.780 --> 01:00:48.380]  rocket science нам не нужен, чтобы корректность обосновать. А вот давайте теперь будем обосновывать
[01:00:48.380 --> 01:01:01.100]  с вами качество. Массив ye? Не нужен он по факту. Он нам нужен сейчас для анализа. То есть мне
[01:01:01.100 --> 01:01:06.780]  просто захочется сейчас кое-что поговорить про вот эти вот ye. На практике, конечно, вы скорее
[01:01:06.780 --> 01:01:12.060]  просто введете одну переменную, какую-нибудь t, временную переменную. Здесь ее положите равной
[01:01:12.060 --> 01:01:17.820]  этому минимуму, и ее вот используете, и забудете потом до следующей итерации. Но для анализа мне
[01:01:17.820 --> 01:01:23.660]  нужно, чтобы у каждого ребра сохранялось вот это вот значение. Вот, потому что мы его сейчас с
[01:01:23.660 --> 01:01:43.100]  вами как раз используем. Мы с вами его используем. Так, давайте запишем вес нашего покрытия. Вес
[01:01:43.100 --> 01:01:54.460]  множества v', который мы получили по итогам алгоритма. Это сумма весов вершин, которые
[01:01:54.460 --> 01:02:02.940]  входят во множество v'. Но это вроде определение веса множества. Давайте заметим, что такую сумму
[01:02:02.940 --> 01:02:15.340]  можно оценить суммой всех z по всем вершинам графа. А почему такая такая оценка выполнена,
[01:02:15.340 --> 01:02:41.820]  как бы вы сказали про это? Почему? Ну про y пока ничего не говорим вроде. Точно, потому что,
[01:02:41.820 --> 01:02:48.180]  вообще-то говоря, справедливо вот такое равенство. Ведь для тех вершин, для которых мы включаем в
[01:02:48.180 --> 01:02:55.980]  покрытие, мы их включаем-то когда? Когда у них z совпадает с w, так? То есть, вообще говоря,
[01:02:55.980 --> 01:03:02.060]  выполнено вот такое равенство. Но если я в этой сумме возьму и еще побольше слагаемых, не только
[01:03:02.060 --> 01:03:08.660]  по вершинам множества v', а вообще по всем вершинам графа, просуммирую z, то получится не равенство,
[01:03:08.660 --> 01:03:15.780]  потому что z все равно не отрицательное. Ну окей, получится верхняя оценка тогда. Так, чудесно.
[01:03:15.780 --> 01:03:24.260]  Помните лему о рукопожатиях? Она про что? Если много пожимать друг в другу рук, то ковид
[01:03:24.260 --> 01:03:39.860]  распространяется лучше. Нет? Как она звучит? Ну да, бывает в таком виде, прочетность. А бывает
[01:03:39.860 --> 01:03:44.820]  просто про сумму. Если просуммировать степени всех вершин в графе, то мы получим удвоенное
[01:03:44.820 --> 01:03:52.140]  количество ребер. Правильно? Чудесно. Давайте заметим теперь, что вот здесь мы можем сформулировать
[01:03:52.140 --> 01:03:59.220]  что-то типа обобщение лему о рукопожатиях. Если просуммировать все z, те z на всех вершинах,
[01:03:59.220 --> 01:04:09.740]  то мы получим удвоенную сумму y. Я сейчас это поясню, естественно, я вас не буду бросать на произвол
[01:04:09.740 --> 01:04:15.700]  судьбы с вот этой штукой. Давайте посмотрим на алгоритм, что у нас там происходило. Посмотрим
[01:04:15.700 --> 01:04:23.980]  на произвольную какую-то вершину. И вот этой вершины есть ее z с индексом v. Эта z изначально была равна
[01:04:23.980 --> 01:04:30.580]  нулю. Правда, мы начинаем с нулевых значений. А потом у нас z на протяжении алгоритма увеличиваются.
[01:04:30.580 --> 01:04:39.980]  Но ведь z-ки увеличиваются не оба на что, они увеличиваются на вот эти y. То есть это z,
[01:04:39.980 --> 01:04:46.020]  она так с нуля началась и росла, росла, росла. И почему она росла? Потому что находились какие-то
[01:04:46.020 --> 01:04:53.260]  ребра, которые не были покрыты, и на этих ребрах выбирались соответствующие y, и вот этот y добавлялся
[01:04:53.260 --> 01:05:00.060]  к значению z. И в итоге это z складывается из всех вот этих вот отдельных y, соответствующих вот
[01:05:00.060 --> 01:05:07.340]  этим ребрам, торчащим из вершины. Ну и смотрите-ка, каждое ребро, каждый y дает вклад в два z,
[01:05:07.340 --> 01:05:13.380]  в z у вот этой вершинки и в z у вот этой вершинки. А этот y дает вклад вот в эти два z. Ну и так
[01:05:13.380 --> 01:05:19.980]  дальше. Это точности как клемма о рукопожатиях. Каждое ребро дает вклад по единичке в степени
[01:05:19.980 --> 01:05:25.540]  двух своих концов. Именно поэтому сумма степеней вершин равняется удвоенному числу ребер. Здесь
[01:05:25.540 --> 01:05:32.900]  абсолютно та же самая картина. Каждый y дает вклад в два z неминуемо, вот в эти два z. И поэтому
[01:05:32.900 --> 01:05:45.700]  сумма всех z равняется удвоенной сумме всех y. Нормально? Ну такая вроде клемма о рукопожатиях,
[01:05:45.700 --> 01:05:53.180]  только обобщенная на какие-то произвольные странные числа z и y. Но теперь-то давайте заметим,
[01:05:53.180 --> 01:06:02.180]  что эти y удовлетворяют всем вот этим вот условиям, которые мы поставили. Ой, зря я здесь
[01:06:02.180 --> 01:06:16.420]  стер. Зря я стер. Да. Ведь по ходу алгоритма, заметьте, мы никогда не сделаем так, что вот этот z
[01:06:16.420 --> 01:06:24.140]  превзойдет вес соответствующей вершины. Правда? Мы всегда устанавливаем очередной y в минимальное
[01:06:24.140 --> 01:06:30.500]  такое значение, чтобы вот один из этих z достиг веса вершины, а другой точно не превзошел веса
[01:06:30.500 --> 01:06:34.820]  своей вершины. То есть по ходу выполнения алгоритма у нас выполнен, как, сказали бы,
[01:06:34.820 --> 01:06:39.780]  компьютер-сантисты, такой инвариант. Инвариант — это какое-то свойство, которое не меняется на
[01:06:39.780 --> 01:06:45.740]  протяжении всего алгоритма. Вот инвариант нашего алгоритма такой, что сначала до самого-самого конца
[01:06:45.740 --> 01:06:54.580]  вот эти вот y, вернее, эти z, они не превосходят соответствующих w. И y мы выбираем соответствующим
[01:06:54.580 --> 01:07:00.300]  образом, чтобы этот инвариант не нарушить. То есть у нас всегда есть предельный уровень,
[01:07:00.300 --> 01:07:09.700]  меньше ли равняется, чем wv, и при выборе очередного y мы смотрим, как бы больше этой разности y не
[01:07:09.700 --> 01:07:15.020]  взять ни в коем случае, потому что если мы возьмем больше такой разности, то это неравенство нарушится.
[01:07:15.020 --> 01:07:23.980]  Вот поэтому мы берем здесь минимум из двух разностей, чтобы для каждого конца z сохранила свое
[01:07:23.980 --> 01:07:31.420]  свой потолок. Но z-ка-то складывается как раз из вот этих вот y отдельных. То есть у нас
[01:07:31.420 --> 01:07:37.900]  действительно выполнено эти условия. Для каждой вершины графа сумма y по всем ребрам, торчащим из этой
[01:07:37.900 --> 01:07:46.540]  вершины, равняется этой z-ке по определению, которая в свою очередь не больше, чем w,
[01:07:46.540 --> 01:07:52.780]  которая в свою очередь не больше, чем w. Ну и нигрики, очевидно, не отрицательные величины на
[01:07:52.780 --> 01:08:00.180]  протяжении всего алгоритма. Стало быть, вот по этому свойству мы можем с вами заключить,
[01:08:00.180 --> 01:08:11.340]  что вот эта сумма не превосходит опта. Оказалось, что мы способны наконец поставить здесь удвоенный
[01:08:11.340 --> 01:08:18.700]  опт. Мы с вами предъявили комбинаторный алгоритм, который ничего не содержит
[01:08:18.700 --> 01:08:23.660]  пролинейное программирование. Но при этом для анализа этого алгоритма мы с вами построили
[01:08:23.660 --> 01:08:29.860]  некий специальный набор констант. И то, что этот набор констант вообще как-то связан с оптом,
[01:08:29.860 --> 01:08:35.940]  последовало из анализа нашей системы линейных неравенств, которая кодирует задачу о вершинном
[01:08:35.940 --> 01:08:43.900]  покрытии. Вот бывает и так, оказывается. Ну что ж, не буду задерживать, спасибо за сегодня,
[01:08:43.900 --> 01:08:45.660]  до встречи на следующей неделе.
