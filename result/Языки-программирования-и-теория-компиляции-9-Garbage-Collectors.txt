Всем доброго дня! Мы с вами продолжаем наши измышления. Мы с вами, так или иначе, уже прошли
основной курс, основной блок, связанный с компиляцией, и теперь мы пошли по дополнительным темам. То есть,
у нас сегодня тема первая. Она больше свойственна именно ООП-языкам, всяким высоковоровным языкам. То
есть, мы начнем говорить про garbage collectors. Потом у нас, наверное, еще будет где-то лекции 2-3. На них
мы скорее всего рассмотрим функциональный язык и рассмотрим вид промежуточного представления для
функциональных языков. А в конце мы еще посмотрим про объектно-ориентированную программирование,
то есть как оно реализовывается. Но сегодня, на самом деле, тоже тема, которая отчасти посвящена
объектно-ориентированному программированию, поэтому будет интересно ее посмотреть. Значит, наша цель
будет сегодня разобраться, во-первых, как работают garbage collectors, какие существуют алгоритмы сборки
мусора, а после этого мы узнаем, как реализованы garbage collectors в других языках программирования.
Значит, это тоже немножко почитал. Пока ехал сюда, да, я ехал на дороге, почитал, как работают garbage collectors в ГО.
Ну да, вот предыстория, к чему мы вообще все клоним. Если мы вспоминаем, как у нас раньше были
реализованы все объекты, мы говорили, значит, нам нужно алоцировать объект, нам нужно создать
экземпляр класса, мы создаем либо структуру и запихиваем ее поля на стэк, либо мы говорили,
не паримся, делаем молок и жизнь наша прекрасна. Вот есть только проблема в следующем, что когда мы
делаем молок, нам нужно потом очищать эту память, чтобы у нас память не текла с ростом числа процесса.
Вот, ты даже не опоздал.
Да, чтобы вы все понимали, что те, кто смотрит запись в ютубе, у нас тут просто под капотом
день открытых дверей происходит, или день карьеры, и там тоже интересные люди приходят и рассказывают
всякую такую вещь. Вот, значит, нам нужно, память нам не нужна все время, нам нужно разобраться,
каким образом можно использовать оптимизированную память. Ну, значит, и здесь возникает способ
первый. Первый механизм — это механизм сборки мусора. Это форма автоматического управления памятью
и процесс, который занимается как раз освобождением алоцированной памяти, называется горбач-коллектор.
Давайте подумаем, какой самый простой вид горбач-коллектора можно при желании реализовать.
Ладно, это хорошо, это нормальный вариант.
Ну, в принципе, да, можно считать ссылки на объекты. Дальше, когда количество ссылок на объект
становится равным нулю, не очищай. Вот, значит, давайте объявим требования, которые нам нужны.
Значит, конечно же, тут хочется сказать, что на самом деле в языках программирования они должны
выполнится, но спешу вас сразу обрадовать, далеко не всегда это так. И даже мы выдвигаемся к первому
требованию, скорость работы, mildly overhead, то есть горбач-коллектор не должен требовать много ресурсов.
Я, кстати, проводил эксперименты. Знаете, сколько времени работает горбач-коллектор в языке R?
100 миллисекунд. А программа меньше. Ну, то есть там стабильно просто где-то порядка 100 миллисекунд
работает горбач-коллектор. Вот, дальше, значит, мы хотели бы сделать так, чтобы у нас было мало
количества прерваний на сборку мусора. Что такое горбач-коллектор? Это прям алгоритм,
который запускается на стадии контекста исполнения. То есть нам нужно прямо исследовать
весь наш код и выяснить, когда мы можем прерваться. Поэтому здесь как раз очень важно сделать так,
чтобы больше времени мы все-таки занимались выполнением кода, а не чистки мусор. Значит,
дальше третье требование, которое они идут все по мере убывания. Важное требование это локальность
данных. То есть те данные, которые расположены семантически близко друг к другу, должны бы по
хорошему помещаться в одну кашлению. То есть нам нужно делать так, чтобы те участки памяти,
которые в пуско-копном времени находились далеко, но потом стали находиться близко в памяти,
каким-то образом перемещались свои указатели. То есть горбач-коллектор, смотрите, важно,
что горбач-коллектор это не только про очистку мусора, но еще и про управление памятью. То есть,
в принципе, горбач-коллектор может при желании перемещать объекты в память. Это,
что касается предпределяемых требований. Давайте подумаем следующее. Первый модель,
который мы должны рассмотреть, это модель набора корневых вершин. То есть это вершины,
к которым есть доступ в самый простой способ с точки зрения кода. Давайте подумаем,
что у нас обычно является корневой вершиной. Стэк и глобальные переменные. Тут больше ничего
особо нет. То есть у нас есть объекты, которые алоцированы на стэке. То есть здесь это указатель
именно. И есть статические переменные. Стические переменные те, которые являются глобальными.
Кстати, статические переменные класса, они тоже глобальные. То есть эти объекты нам как раз нужны.
И дальше нам нужно высчислить набор достижимых вершин. То есть это набор корневых вершин,
плюс тех вершин, которые достижимы по своим ссылкам. То есть если мы используем Java,
то в Java это оператор точка. Если это R, то это либо доллар, либо собачка в зависимости от.
Да, ну мы привыкли все к тому, что у нас это точка. То есть оператор точка, если мы представляем,
что все методы у нас являются публичными, то все объекты у нас являются публичными,
то по ним можно дойти до точки. Вот. Значит память выделяется у нас зачастую именно на куче. То есть
что у нас должно происходить? По-хорошему. Первое, это у нас аллокатор. Тобственно объект,
который пункция, которая выполняет алоцирование объекта, должно находить новое место для запрашиваемого
участка памяти. Второе, сборщик мусора находит место, не используемое под объектами, перемещает
участки. И третье, перемещает это объекты в кучу. Почему? Тут важный вопрос заключается в том,
почему нам объекты нужно перемещать на кучу. Почему мы не можем использовать большое количество
молоков. Молоки это дорогая операция. А есть еще один замечательный язык. На J начинается,
на A заканчивается. Да, она именно. В ней вы при запуске программы указываете размер кучи.
Ну вот прямо она мертва. То есть как бы вы делаете по факту один молок своей жизни и дальше с этими
объектами на куче каким-то образом. То есть либо через виртуальную память, либо потом,
когда вам эти объекты нужны, они уже идут в реальную память. Вот. То есть вот такая у нас модель.
И здесь нам нужно сделать следующую вещь. Обычно первый подход, который заключается в том,
что давайте создадим список. Он обычно называется free list. Это каждый элемент указывает на старт
следующего свободного участка памяти. То есть у нас есть какой-то большой участок памяти,
который мы выделили одним молоком. А дальше у нас происходит по факту, когда мы алоцируем
какой-то объект на куче, то у нас происходит следующее. Мы берем, нам вот этот участок памяти
должен указывать на вот этот объект. Если вот эта память чистая, эта память чистая,
эта память грязная. Какое количество элементов по при листе изначально? Один. То есть у нас
весь участок памяти есть. Более того, знаете, есть такая интересная задача. Людям по факту
на одной из всероссийских олимпиад по информатике нужно было написать по факту
гармош коллектор. Точнее форму управления памяти. Смотрите какая задача. Сейчас я вам покажу ее.
Как называется? Всероссийская олимпиада по информатике, да? Нет, всероссийская.
Если я не ошибаюсь, это 2005 год.
Это командный чемпионат.
Я не помню, сейчас посмотрим. О, господи, это RAR-архив. А тут по задачам ничего нету, да? Так, если у меня 7-Zip.
А я надскачиваю, да?
Ладно, сейчас подождите, сейчас 7-Zip скачаю.
Как? Вот так, да? Слушайте, я его даже искал.
А, кажется, понял. Так, Sported Formats. Кстати, не пакуйте свои объекты RAR-архивами. Как скачать его?
Он через магазин ставится.
Врел? Сейчас посмотрим.
Да, ставится. Только из другого места его ставят.
Что-то ставит. Ну, соберет.
Ладно, сейчас подождите, дайте, найду все-таки по информатике.
А, задание. О, на Informatics точно должно быть.
Все-российские. О, Все-российская Олимпиадная школьника.
А что-то тут одна задача, что ли? А, нет, вон они. Нет, не здесь.
Да, я вижу. Сейчас, давайте найду ее. А, возможно, она в окружном этапе была, кстати.
Нашел. Да, но она на самом деле, ну, в каком-то этом. В общем, она была на какой-то Олимпиаде,
по-моему, должна все-российской. То есть, тут надо именно. Да, то есть, вот она, генерация. Надо
посмотреть. О, ну, хотя бы зипник. А, это, это, это, 2005 год, апрель 2005, то есть, нам нужен
это, значит, окружной этап. Ну, ладно, короче, вот она, задача. Так, Николай, конечно, молодец,
вере не закрыл. Эти поручили написать менеджер памяти. Значит, с нее есть последствия,
задача менеджера освобождать это все. Запрос освобождения, выделение памяти, это по факту мы
работаем с Молоком с вами. Вот, и дальше он должен выделить такой блок. При этом, смотрите,
перед самой первой ячейкой памяти не должно располагаться другой свободной ячейки. Ну да,
ну просто это вот типа, что в школе такие тоже мотивы людям давали на Олимпиаде. Вот,
а дальше запрос на освобождение памяти. Значит, да, тут надо хранить порядковый запрос.
Не-не-не, тут именно, они именно в правильном порядке. То есть, тут сказано, что, типа,
нужно алоцировать самый первый участок памяти, который доступен. Да, самый первый доступный такого объема.
Да, это алгоритм детерминированный, но, в общем, он немного нетривиальный. Ого, еперный,
а что с ним, что с экраном-то случилось? Матрица полетела, что ли? Ну да, да, да. А причем,
замечу, что 8 точек должна быть м блогем где-то, где м это количество запросов.
Ну да. Ну да, на куче можно написать это все.
Да. Ну да, в принципе, так. Видите, даже людей на Олимпиаде, на Всероссийской,
да, мы тут, раз мы говорим про Горбач-коллектор, вспомним, что была задача в Всероссийской Олимпиаде
школьников по информатике, которые по факту заставляли реализовать Горбач-коллектор.
Но понятно, что здесь именно мы говорим про управление памятью, то есть, мы не смотрим на наш
исходный код. Вот, то есть, нам по факту вот такой вот писочек нужно хранить, первый фри-лист. Вот,
и изначально длина этого фри-листа равняется единице. Вот, у нас есть один участок памяти. Так,
и дальше у нас с вами есть обычно два вида сборщиков мусора. Первый, это тот,
который учитывает количество ссылок на объекте, и второй, это тот, который просто отслеживает все
имеющие ссылки на объект. Давайте рассмотрим каждый из них. Итак, подсчет количества вхождения.
Представим себе, что нам нужно считать всегда количество ссылок, которые
всылают в некоторую обыск памяти. Итак, смотрите, теперь, если мы рассмотрим переменную i,
то она выделяет новый объект типа integer, ссылку на объект типа in.
Угу.
Угу.
Ну.
Угу.
Окей, может быть, посмотрим. Итак, смотрите, количество ссылок на участок памяти,
на который сейчас указывает i, стало равно единичке. Дальше, значит, когда мы делаем g равно k,
у нас происходит, на самом деле, следующая вещь. Если мы особенно присваиваем int,
то количество ссылок на объект, скрывающийся за g, стало на один меньше, потому что мы,
если у нас переменная g, за переменная g скрывалось какое-то значение, то по факту мы убрали это
значение. А если мы посмотрим на объект k, то количество ссылок на один стало больше.
Это переменная стала и переменной g. Дальше, смотрите, алгоритм такой, как только количество ссылок
на определенный объект стал, равняется нулю, участок добавляется в прилист, после чего количество
ссылок на элементы объекта должно уменьшиться на единичку. Так, где здесь подвох в этом алгоритме?
Кольцевая зависимость? Да, конечно же. Давайте посмотрим, как делать вычитание,
типа вычисление количества объектов. Мы можем делать либо при помощи if инструкции, то есть
напрямую это делать, либо делать это по требованию. То есть, как только память заново потребуется,
программа прерывается на большие перерывы, и просто считают те ссылки, которые у нас есть. То есть,
мы не в рантайме делаем, а прерываем нашу программу для того, чтобы выполнить какой-то код.
Значит, в чем плюс и минус этого алгоритма? Алгоритм простой, но у нас есть минус. Первое
это добавление операции числа ссылок в вычислении. Это порядка десяти инструкций на один такт.
Надо считать их дополнительно параллельно. Ну да. Инструкция if инструкция,
сколько операций у нас? Ну, если у нас if это jump, а сколько мы jump оценивали?
Какое количество тактов мы оценивали от jump?
Ну да, да, да.
Да. Класс.
Да, это неприятно, согласен. Вот, ну есть циклы в нашей программе. Давайте посмотрим,
например. А, вот они, десять инструкций. То есть, можно уменьшить, если использовать
анализ потока данных. Давайте разберем этот код. Да, атомик декремент. Да, да, да.
Ну и атомик декремент получается, да? Ну, в принципе, да. То есть, их можно пережать.
Главное, просто знать, как это скомпилировать потом в нашу программу. И знать, какие инструкции
особенно нужны для этого. Ну ладно, да, это действительно так. Ну, есть вот такая классический
пример. У нас есть класс вершины, у которого внутри содержится вершина. Указательная вершина.
Ну и дальше мы делаем следующее. Объявляем три объекта, а дальше делаем ссылку на определенный
объект. Да, то есть, у нас проблема этого кода, что a.x.x.x и a.x.x остаются незамеченными. То есть,
у нас изначально что было в нашем коде? У нас изначально тряпка. Тряпка вся пересохла.
Итак, вот у нас объект a.
Получается, количество ссылок здесь равняется единице. На вот этот объект у нас 2 ссылки.
Собственно, сам объект и a.x.x. Давайте нарисуем просто граф из зависимости. Вот, а дальше что мы делаем?
С вами. Мы говорим, что a.x.x это a.x.
Мы потом удаляем вот этот объект.
И количество ссылок на a у нас удалится, а a.x.x у нас нигде не будет. То есть, у нас остается вот
этот вот участок памяти, где у нас есть a.x и a.x.x. И он подсчетом числа ссылок не удалится.
У нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть азиатский объект, а у нас есть аз
а
ну что разобрались или короче
ну-ка давайте даже напишем его на маке нет ну это мой компьютер но могу на линукс подключиться
так никакой компьютер включить так и так что мы пишем
заинклодировали
лик
вектор
где где так что конструкторе передаем
так хорошо давайте посмотрим так ой
в санитайс адрес
какого стандарта не работает
так давайте-ка что с 17 стандарта да вроде ага не или мне с другим компилятором
сейчас попробуем нет компилировался ну блин конечно у меня
но вот у меня я не знаю у меня какой стандарт он не семнадцатый молчанию да интересный
пример конечно вот как легко получить горбач коллектор кстати интересно отловит ли
да кстати это забавно но вола гринд прямо не может сказать что это за тип утечки
не он сказал что 24 байта действительно утекло дебак символа конечно вот
а нет да я просто неправильно параметры придал да да да но как этого кире ну да
в операторе нью кстати утечка произошла в операторе нью от лонга
да в общем интересный пример но видно что циклические зависимости они такие
да их не трогать ну да ну да да кстати тем кто смотрит лекцию нужно же сказать что
такое боро чекер ну да вот ну то есть это тоже полезная вещь и в принципе даже кстати по
моему боро боро чекера очень просто внедрить любой язык программирования только нужно
программистов все команды переписать будет все операторы нью и все операторы длит
это мы тут уже заговорились немножко давайте двигаться дальше так ну в общем поняли что
опера метода подсчета цикл цикл ссылок не работает поэтому есть некоторые trace-based методы вот
да и здесь выделяют обычно два алгоритма основных первый алгоритм называется mark and sweep он больше
offline алгоритм а есть алгоритм mark compact как марк шип тоже можно делать подлайн варианте есть
вариант марк компакт то есть это алгоритм меток и компактификация а флайна онлайн это означает
что а флайна полностью прерываем да делаем делаем стоп за ворлд и дальше все останавливаем вот
все-таки марк консвит можно сделать так чтобы стоп за ворлд там был в редких случаях
ну да вот значит как сделается марк консвит суть в том что мы по идее должны запустить
дфс от всех корневых вершин и помечать все участки памяти которые мы достигаем значит
в алгоритме свип дальше мы до каждого алоцированного участка в кип делаем
следующее если вершина при этом у нас является помеченной то мы ее эту вершину пропускаем
дальше иначе мы должны добавить эту вершину во фрелист а да
ну но прессом не до
да да да вот то есть у нас получается вот такой вот алгоритм понятно что это кажется что
алгоритм простой но в нем есть некоторые дела в деталях собственно что этот алгоритм работает
медленно вот он пример кстати в общем у нас есть вершины пеку иар и они у них есть ссылки на
объект то есть второй второй элемент это ссылка на объекты и третий объект это ссылка на другие
переменные то есть у нас получается что у нас после алгоритма пометок у нас будут помечены
все вершины кроме вот этих двух то есть у нас есть циклическая зависимость вот между семеркой
и девяткой собственно дальше мы делаем следующее мы берем один из элементов тут очень важно что
можно взять один из элементов и добавить его в фрелист то есть остальные поскольку у нас с вами
как раз линк от листа мы можем подцепить этого корня линк от листа то есть вот тут вот как раз
вот эта девятка она перемещается на вот эту семерку тем самым нам достаточно очень легко
разматывать цикла то есть нам нужно не все добавлять список а именно используя списки
так значит теперь давайте обсудим сложность этого алгоритма пусть у нас выделено аж слов и
есть р достижимых слов куча тогда стоимость garbage collection у нас будет какая значит у нас
получается есть у отр плюс аж потому что нам нужно найти все достижимые вершины плюс
перебрать все слова то есть в нашем графе получается вершины это слово так
ну а получается здесь у нас тоже считается качественности жимых слов но то есть по факту
мы можем сказать что асимптотика такая же как асимптотика dfs просто и надо посчитать вот
при этом количество вспложденных элементов у нас аж минуса то есть в принципе мы на асимптотику
тратим на один элемент вот такое количество операции то есть это у нас цена 1 на ар плюс
ц2 на аж поделить наш минус р ну не знаю много или мало но в принципе если у нас остается какое-то
количество объектов висеть в памяти то это хорошо значит знаете когда полезно использовать
garbage collector и когда его не используют и кого за это по рукам надо бить
да ну обычно не используют всякие млщики питоновские которые ну вот ну давайте мы за
пулям модели а это понятно не просто делаю все чтобы создают объекты закидывает закидывает
закидывает а потом бац и что-то памяти это памяти не хватает да кстати это стратегия поведения
такая есть для бенчмарков это да ну да да да то есть есть такая проблема то есть вот
она нас амортизована сложится алгоритма то есть если мы очищаем прямо очень много слов ну
не понятно что еще можно учитывать количество байт которые мы очищаем это будет было бы честно
вот то мы можем получить стоимость очищения одного байт информации вот значит и тут как раз
можно сделать некоторую связь алгоритма то есть если у нас аэр приблизительно равняется аж на то
есть у нас получается очищается малое количество объектов то сложность алгоритма очень большая если
аж намного больше чем с аж намного больше чем ар то тогда алгоритм работает константное время
работы и хотелось бы иметь именно такой алгоритм а есть еще компромиссный вариант когда р поделить
на аж больше одной второй то есть у нас получается количество освобождаемых объектов будет бой хотя
бы половина от общего числа объект сейчас дайте прикину то есть получается р больше чем половина аж
да то есть как бы суть в том что мы не можем освободить больше чем половину объектов вот тогда
логично увеличить размер кучи ждет еще один молок там перенести памяти использовать новый объект так
это понятно некоторые еврестики такие что чтобы у нас каждый горбач коллектор долго не вызывался
мы его вызываем только в те моменты когда у нас количество алоцированных объектов будет
больше чем меньше чем половина от общего количества объектов которые были алоцированы то есть нам
нужно выждать именно такие моменты так ну собственно каким образом это все можно оптимизировать
первый способ это писать dfs не рекурсивный да использовать его явно на стеке вот для того
чтобы хранить объекты значит если последний элемент стека это указательный текущий
момент это уменьшает тоже размер количества так на одни чки вот и собственно можно использовать
несколько фри листов для записи с разным количеством слов ну то есть готовить именно
структуры которые вот оптимизированы под этот формат так плюс и минусы значит плюс очищает
всю память плюс управляемая сложность работы то есть в принципе можем задать количество
итерации минус это фрагментированность выделенной памяти про пропуски в данных у нас возникает более
того есть еще один минус у нас чтобы за ворлд происходит то есть нам нужно остановить весь
контекст исполнения и получить наш результат так про маркин свип понятно ага здесь это картинка
с флешбеками когда последний последний раз делали фрагментацию фрагментация памяти
ну да
да ну я знаете как это он вкульную картинку вставил раньше реально где фрагментация диска это
была очень важный момент времени очень важная операция который сильная когда мела ресурсы вот
то есть как вы видно ввестим из диска тут 33 гигабайта если это до внешние нулевые года вот то
есть нам нужно будет компактифицировать эти объекты и здесь нужно сделать так чтобы объекты
которые у нас находятся в куче у нас перемещались вы последний участок памяти это он чтобы
освобождать множество объектов на кучу вот значит и здесь как раз есть несколько модификаций
первый называется алгоритм марка компактини значит у нас должен быть следующий указать первое
что у нас должен быть это следующий указатель на свободный участок памяти после этого нам
нужно сделать ограничение на используемый участок памяти и значит это именно для структур и
должен быть объект скан это указатель на области памяти для которой необходимо провести
сканирование всех его полей то есть этот алгоритм специально позволяет анализировать все структуры
и поля этой структуры тут можно сказать как как для структуры использовать компактификацию корректным
образом
у нас структура структура структура структура вектора
ну да нам просто нужно правильно вычислять афсета на кучу чтобы у нас объекты собирались вместе но
это тоже может делать на уровне dfs то есть сделать как наш любимый визитер который
будет вычислять сдвиги наших элемент относительно старта хорошо значит тут есть как раз механизм того
как это все считается значит в пункте форвард собственно нам нужно понимать просто следующего
участок памяти куда нам надо пылить то есть мы здесь находимся во внутренней структуре то
было бы неплохо понять как мы выходим из этой структуры к какому объекту мы используем тут
можно на паузу поставить принципе разобрать этот алгоритм так вот он пример кстати то есть
у нас с вами есть перед нашим алгоритмом как раз корневые вершины п q ир вот и дальше мы
начинаем перемещать наш объект то есть у нас получается п это 15 объект дальше у нас идет
37 объект да и дальше мы указываем собственно элементы скан то есть которого у нас есть вот и
как раз сканируем одну запись то есть нашу структуру и понимаем что нам нужен объекте по 15 37 ну и
дальше они уже будут сканироваться то есть у нас 15 элемент дальше указывается на 12 элемент вот и
мы его перемещаем в памяти вот подряд то есть потихонечку мы как раз разматываем этот
клубок для того чтобы у нас все элементы стали последними друг за другом есть многоуровневая
мизация понятно потому что то есть здесь есть подход типа мы копаем сверху вниз мы можем или
мы копаем бок здесь алгоритм компании в бок но потому что скорее всего если у нас структура есть
нам хотелось бы обращаться ко всем полям последовательно а не конкретным элемент
хорошо какие достоинства и недостатки у этого алгоритма нет фрагментированности данных но
проблема в том что нужно алоцировать два раза больше памяти для перемещения вот и локальный
данных все-таки может нарушаться то есть как бы у нас получается одна структура находится не в
одном месте а по факту указателя на объекты в одной структуре в одном месте потом если мы
хотим обратиться к дальнейшим элементам нам нужно прыгать вниз так понятен мар компакт
еще раз значит идея такая что вот у нас есть древовидная структура
это какой алгоритм мар компакт или мар компакт чине
вот это первое это алгоритм мар компакт то есть у нас есть структура у нас есть объекта
здесь дырка здесь дырка потому что мы делаем мы делаем мы обходим наши вершины в порядке
и вычисляем объем памяти который нам нужен здесь у нас получается этот объект будет перемещаться
сюда значит он скинет у нас афсет допустим что он занимает 16 машинных слов следующий
элемент который у нас заходим в дфс должен находиться на сдвиге относительно 16 машинных слов
образно говоря вот этот элемент который был дальше у нас имеет 18 машинных слов да то есть
и дальше у нас здесь 16 элемент после этого у нас идет афсет на 34 и мы потихонечку перемещаем
наш объект на структуре но если в нашем поле но если у нас есть структура возможно мы хотим
отложить выполнение наших операций то есть мы сначала хотим пройти корни а потом только спускаться
вниз да потому что скорее всего изначально мы будем а точка x делать а потом из x мы будем
обращаться уже другим элементом но уже когда-то позже то есть у нас первый уровень будет вот такой
второй уровень будет вот такой вот поэтому эти элементы должны быть сначала потом эти элементы
должны спускаться ниже то есть в принципе при другой инструкции генерируется кстати есть такое
правило в в проектировании и написание кода закон диметра слышали да что а должен знать
обе если а знает обе без знают оце то они должны знать оце вот так как раз алгоритм мар компакт
подбуждает если у вас в языке реализован мар компакт вот именно вот способом чинить он
побуждает вас как раз не писать по закону диметра то есть это даже будет влиять на то как подпишется
в языке программирования он будет работать просто медленнее так стало понятно что вот значит вторая
алгоритм значит марк свик компакт ну собственно здесь говорится следующее если мы хотим чтобы
все объекты у нас помещают в кашлении то на стадии сканирования мы вместо dfs будем запускать
bfs вот здесь нужно именно максимально считать глубину dfs дат чтобы у нас все помещалось к
ошлению понятно что про размер кашлений мы явно не знаем и нам процессор ничего об этом не скажет но
все равно было бы неплохо понимать на каком уровне мы можем спускаться вот
вот пойти
ну да
но но новой
но
ну да конечно же ну то есть но то есть первое что разработчики
армовского процессора сделали они придумали режим амуляции блин ну а ну и
на ну а иначе как бы миграцию проводить старых всех приложений на новое да да
конечно не но всегда новая инструкция когда появляется нужно быть аккуратным и
делать бэкпорта на предыдущей версии вот это вот так значит здесь еще одна
оценка значит если мы про маркет сверх компакт появляется то нам нужно будет
копировать наши участки в словах то есть у нас вот суммарная сложность копирование будет
с 3 на r поделить на аж пополам минус а аж пополам это размер нашей кучи вот ну и собственно
приблизительно освобождается половина памяти поэтому мы получаем ц 3 но собственно мы выяснили
насколько это операция копирования операция копирование у нас занимает 10 и 10 такт мы
кажется про это говорили предъявить вот хорошо так это объединение трех лагерет значит
теперь значит какая этипизация горбач коллекторов существует по времени остановки первая это стоп
зэ ворлд то есть мы запускаем полностью весь горбач коллектор на все алоцированная память
и в куче а есть по стоп пауз то есть мы запускаем на только часть объектов куч мы вызываем не
полностью горбач коллектора вызываем только горбач коллектор и на определенном количестве
элементов вот значит и есть следующие вида поколений собственно мы смотрели какие алгоритмы
есть горбач коллекторов теперь давайте поймем как от стопа от стопа зэ ворлд перейти к стоп
зэ пауз значит и для этого как раз возникают новые истории называется general channel горбач
коллектор то есть они являются поколенческим языки именно горбач коллектор встроены в языках
программирования значит все объекты в памяти тогда у нас можно поделить по такому признаку
какое количество цитактов горбач коллектора пережил наш объект на самый молодые объект у
нас попадает в элемент g0 потому что они не пережили множество ноль потому что они пережили
ни одного горбач коллектора следующий объект у нас переживает одну чистку она они попадает
в G2, в G1, потом в G2. Ну а дальше, на самом деле, мы прекрасно
понимаем, скорее всего, что если объект пережил два,
две стадии очистки гармошка-электра, то сколько он ещё переживёт?
Много. То есть обычно здесь счёт идёт 0, 1, много. Классно,
почему заменить? Классно, и как они в мусор собираются?
То есть понятно, мы делаем многопоточность, но делаем
сетон медленнее. Красава. Ну да. Ну да. Угооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооооо
Там причем две стадии... два способа генерации есть.
Один эхху господи я читал его.
Ding я за другой в РайтБарьер.
Т.е. с них два барьера используются.
Классно!
Да, да, да.
Да.
В общем, цель запускать мусор у нас сначала на G0, чуть реже на G1 и еще реже на G2.
Вот. И запоминание. Чтобы очистка не тракивала большое количество времени, значит мы
необходимо запоминать объекты, которые начинают ссылаться на объекты из G0.
Да, то есть старые объекты на новые.
Потому что, скорее всего, они с высокой степени, вероятно, переедут в новую фазу.
Ну список запоминаний тут очень много разных способов использовать.
Один из интересных способов это использование грязного бита. То есть мы обновляем область старой duty bit.
Устанавливаем bit, что в страницу была произведена запись.
Угу.
А?
Да.
Спросите, почему не используют?
А, ну да.
Вот, значит, еще как...
Вот. И есть еще другие сборщики мусора. Первый из них это incremental, а второй это concurrent.
То есть с incremental он работает по требованию.
То есть вообще во всех современных языках программирования есть именно сборщик мусора по требованию.
То есть есть модуль gc, который можно подключить и вызвать.
Вот.
Знание gc, это право отдельно.
А, да, вначале я хотел поэкспериментировать, потому что на гc еще обшифровывается клоунбайвер.
Четыре спроста.
Ну, короче...
Нормально.
А там в гc garbage collector с большой буквой, надеюсь, написано.
Не надо сокращать название переменных, вот и что скажу.
Нормально. Сразу с чистка.
Ладно, значит, про concurrent gc.
Что мы говорим? У нас есть две действующие роли.
Первый это сборщик, который собирает мусор, а параллельно с ним работает мутатор,
который пытается менять граф доступности данных.
То есть у нас по факту получается mark and sweep может в одном месте работать,
мутатор переносит объект параллельно каким-то образом.
Так, ну, наверное, здесь мы остановимся,
потому что здесь на самом деле дальше еще будет алгоритм stop the pause для garbage collectors.
А у нас пара закончилась.
Все, я вроде больше никуда не уезжаю в ближайшее время.
Так что таких форс-мажоров уже не будет.
В общем, мы начали рассматривать garbage collectors.
На самом деле почти мы их уже досмотрели.
Нам осталось, по-моему, где-то 5-6 слайдов.
Вот, тогда мы их досмотрим в следующий раз,
и тогда перейдем к функциональным языкам программирования.
Так, давайте вопросы.
Окей, тогда если нет вопросов, то до встречи.
Что могу сказать?
