Сегодня мы поговорим еще раз про баллиональную иерархию. Сегодня основных темы две. Это полная
задача на уровнях и иерархии. И еще альтернирующие машины, то есть представление вообще и всей иерархии и
классов отдельных не через цепочки формул с кванторами, а через поллиминальное время работы
на машине некоторого вида. То есть как для NP было два определения, так и здесь будет два
определения. Но потом посмотрим, если останется время, я еще немножко поговорю про характеризацию
Хорошо, давайте вспомним, что у нас было. Начиналось все с нулевого уровня, который был просто класс
NP. Дальше что вложено в класс NP, который Sigma 1, также в класс CoNP, который Pi 1. Дальше и Sigma 1 и Pi 1,
вложенные в Sigma 2 и Pi 2. То есть здесь Sigma 2, Pi 2, Sigma 3, Pi 3 и так далее. И все это вместе
вложено в pH, которое есть объединение всех уровней. Дальше мы успели в прошлый раз обсудить,
почему во всем классе pH, скорее всего, нет полной задачи, потому что мы верим в то, что все эти
классы различные. Но на самом деле, может верить в то, что p равно NP, тогда это все схлопывается.
Можно, наверное, верить в какой-то причине, что p не равно NP, но NP равно CoNP. Но предполагая,
что первые три уровня различные, а дальше Sigma 3 равно Pi 3 и всем большим, это совсем странно.
Да, не очень понятно, чем 3 от 4 так отличается, что оно должно схлопнуться. Тем не менее, нет
никакой теоремы. Если до 10 уровня все различное, то дальше тоже различное. Это
не умеют исключать. Более того, умеют строить аракулы, что с этими аракулами как раз так и
получается. Знаешь, такие специальные аракулы, которые разграничивают до 10 уровня, а дальше уже
все схлопывается. Вот. Соответственно, если есть полная задача во всей иерархии, то она будет
лежать в каком-то классе, и значит, вся иерархия будет сводиться к этому классу. А значит,
она будет совпадать с этим классом, но иначе схлопнется. Тем не менее, на каждом конкретном
уровне будут свои полные задачи. Определение стандартное. Значит, языка будет Sigma k, например,
Sigma kt и pt полным, если верны две вещи. Если, во-первых, он лежит в этом самом Sigma k там,
ну и во-вторых, любой другой язык из Sigma k и pt к нему сводится полинамиально. Геосводимость
в точности та же самая, что и всегда было. Так. Хорошо. На самом деле, не во всех классах очевидно,
что есть полная задача, но здесь есть. Теорема такая. Сейчас дайте я сначала сформулирую какие
задачи. Значит, Sigma kt sat. Это вот какая штука. Значит, это множество таких формул phi. Значит,
что все аргументы этих формул разбиты на k групп, ну и дальше, соответственно, цепочка кванторов
существует x1 для любого x2 и так далее. Здесь существует ли для любого xkt в зависимости отчетности,
и тут будет phi от x1 и так далее xkt. Вот. Ну и аналогично есть pk t sat. Значит,
то же самое только начинается с квантора всеобщенности. Вот. На самом деле тут
подразумевается, что в состав описания формулы phi включено разбиение переменных на группы. То есть
мы знаем, какие переменные, от которых зависит форму, входят в группу x1, в группу x2 и так далее.
Вот. Хорошо. Ну, значит, теорема, что каждая задача полна на своем уровне. Теорема,
что sigma k sat является sigma k tp полной. Значит, phi k t sat является phi k tp полной. Так. Ну,
дать доказывать. Эти задачи являются аналогом задачи у выполнимости, задачи у тавтологии. То есть
можно прямо написать, что sigma 1 sat это sat обычная, а phi 1 sat это тавтология. То есть нужно понять
по формуле являтия на тавтологии. Вот. Так. Хорошо. Значит, давайте доказывать. Значит,
тут на самом деле важным является следующее соображение. Важно, не какой квантор первый,
а какой квантор последний. Доказательства проходят, если последний квантор существования. Но
нам-то вообще никто не гарантировал, что последний будет квантором существования. Вот. Поэтому надо
какой-то еще шаг. Но этот шаг очень простой. Первый шаг стоит в том, что просто вот эти два
утверждения друг другу эквивалентны. Так. Значит, первое. Эти два утверждения эквивалентны друг
другу. Значит, конечно, что здесь важно? Важно, во-первых, что если язык в одном из этих классов,
то его дополнение в двойственном. То есть если A лежит в сигмакатом, то это равносильно тому,
что A с чертой лежит в пикатом. Ну и наоборот. Хорошо. Значит, теперь надо сказать следующее.
Ну, например, для выполнимости тавтологии у нас что есть? Что фе выполнимо тогда и только тогда,
когда отрицание фе не принадлежит тавтологии. Ну и наоборот. Наоборот получается, что это к тому,
как доказывать, что тавтология Co-NP полная. Давайте вспомним. И аналогично здесь. Значит,
для тавтологии у нас произвольный A сводится к выполнимости. Значит, дальше A из NP. Дальше нам
нужно показать, что любой B сводится к тавтологии из Co-NP. Значит, что мы делаем? Если B лежит в Co-NP,
то тогда, значит, B с чертой у нас лежит в NP. Из этого следует, что B с чертой,
значит, B с чертой сводится к Co-NP. Ну а дальше может прийти к дополнению. То есть B сводится к Co-NP
с чертой. Значит, B сводится к Co-NP с чертой. Ну, значит, из чего стоит Co-NP с чертой? Но Co-NP
с чертой состоит из записей, которые вообще не формула, а также из записей невыполнимых формул.
То, что запись формулы или не формула, это мы как-нибудь разберемся. Нужно договориться о кодировании,
чтобы по коду можно было понять, это вообще формула или не формула. И тогда можно считать,
что вот это с A с чертой состоит только из формул, которая невыполнимая. Но невыполнимая формула,
значит, ее отрицание тавтология. Так, ну вот и получается, что у нас х лежит в B тогда и только тогда,
когда формула phi х в лежит в сад с чертой. А это тогда и только тогда, когда отрицание phi х в
лежит в ножте тавтологии. Ну и вот получается такая сводимость из X в отрицании phi х.
Вот, хорошо, как это в общем случае будет? Ну, в общем случае, пусть, например, первое утверждение
выполнено. В общем случае, пусть sigma k сад будет sigma k пт полным. Значит,
тогда рассмотрим произвольный язык из pi ktp. Пусть у нас B лежит в pi kt пальномиальном. Значит,
отсюда мы получаем, что B с чертой это sigma kt пальномиальная, и отсюда B с чертой сводится
пальномиально к sigma kt сад. Вот, и отсюда мы снова приходим к дополнениям. Отсюда B сводится
к sigma kt сад с чертой. Вот, и опять же мы игнорируем некорректные записи, получаем,
что sigma kt с а с чертой такие формулы, для которых вот то вот условие не выполнено. Ну вот, значит,
тогда, расписывая вот так вот, получаем, что X лежит в B. Тогда и только тогда, когда phi х лежит
в sigma kt сад с чертой. Так, тут давайте подробнее распишем с кванторами. Так,
давайте, поскольку у меня X здесь, то я здесь Y напишу. Существует Y1 для любого Y2 и так далее,
существует ли для любого Ykt. Значит, тут соответственно phi х от Y1 и так далее Ykt. Вот,
так. И еще нужно отрицание же поставить, да. Это я написал просто sigma kt сад, а с чертой
нужно еще отрицание поставить. Вот сюда вот самое начало, надо поставить отрицание. А потом
это отрицание пронесется через все кванторы. Это получится равносильно тому, что для любого
Y1 существует Y2 и так далее. Здесь тоже квантор последний перевернется, Ykt и в самом конце еще
будет не phi х. Вот Y1 и так далее Ykt. Ну а это равносильно тому, что отрицание phi х... Так,
на всякий случай давайте я тут шкуфки поставлю, чтобы однозначно толковал. Значит, не phi х лежит
в pi kt сад. Ну, значит получается, что та же самая сводимость плюс отрицание дает сводимость
уже произвольного языка из pi kt к pi kt сад. То есть в итоге получается, что B сводится к pi kt сад.
Ну и аналогично наоборот. Если наоборот предположить нижнее, то полностью аналогично
замены всех кванторов на противоположное, мы получим верхнее. Так, хорошо, понятно, да. Но дальше
при фиксированном K из двух вот этих вот цепочек ровно одна заканчивается на квантор существования.
Вот именно эту цепочку мы и возьмем. То есть мы будем непосредственно доказывать для того K,
при котором последний квантор существования. Это что значит? Это значит, что если K нечетная,
то мы доказываем для sigma, а если K четная, то мы доказываем для pi. То есть будем...
доказывать sigma K полноту sigma K сад при K нечетном. И соответственно pi kt полноту pi kt сад
при K четном. Так, как же мы это будем делать? Ну а сами так или иначе нужно как-то посмотреть
на конструкцию, которую мы в Теремьку Калиевина использовали. То есть тут, чтобы доказать,
нужно лезть немножко в детали работы машины. Так, ну сейчас разберемся. На самом деле,
лезть-то надо, но ровно точно так же, как это было в Теремьку Калиевина. Но, конечно,
остается вопрос, зачем нам нужно, чтобы последний квантор был существованием. И это,
конечно, сейчас должно быть использовано. Так, хорошо.
Ну вот теперь пусть у нас есть произвольный... опять же, на самом деле,
тут первое и второе полностью одинаково делается. Так что давайте доказывать первое. Пусть
B из sigma kt P. Значит, докажем, что B сводится к sigma kt sad. И K нечетно, да.
Ну, смотрите, пусть у нас есть конкретная машина, которая задает принадлежность как
раз к sigma kt. То есть получается, что X лежит в B тогда, когда существует y1 для любого y2,
существует y3 и так далее. И последнее квантор существования. Существует yt и тут V от x,
y1 и так далее. И мы точно так же, как делали в Теремьку Калиевина, рассмотрим протокол работы.
Протокол работы машины Turing. Мы считаем, что она прямо одноленточная. Что у нее все эти
k плюс один аргумент записаны на первой ленте через какие-то пробелы. Будет квадратная таблица,
и соответственно в первой строчке тут будет какой-то, может быть, ограничитель. А может и нет,
это мелкие детали. В общем, x, потом y1, пробел, y2 и так далее. Потом ykt и потом еще пустое место.
Вот так выглядит первая строчка. А, еще есть начальница состояния. Вот чего. Начальница
состояния должен быть q1. Соответственно, после этого происходит работа машины Turing,
которая определяется все теми же фигурами при так определенной записи. Фигуры будут именно
такие. Эта ячейка однозначно определяется этими четырьмя. И это какая-то очень большая,
но фиксированная функция. Нет, это не более переменные, это слова некоторые.
Значит, мы будем считать, что ограничения длины зашиты прямо в этот V.
Не любой, а фиксированный полинавиальный. Например, можно сказать, что есть какой-то V изначальный,
и у этого изначального V есть какое-то время работы. И тогда можно все вот эти вот y ограничить
временем работы этого исходного V. А потом можно предположить, что мы все эти y кодируем,
например, беспрефиксно, так, чтобы у всех одинаковая длина получилась. И после этого эта одинаковая
длина будет как раз этим полиномом. И у нас будет новый V-штрих, который будет читать эти длины y,
их расшифровывать, брать, соответственно, код, который будет префиксом, из него получать исходный
y и запускать старый V. И для этого нового V уже длины всех y будут фиксированы, фиксированный полином
от длины x. Так, что, неувидительно? Нет, смотрите, на чем это вообще основано? На том, что вообще это
основано на том, что машина тюринга, чтобы прочесть информацию, должна до нее дойти по ленте. Она не
может сразу прыгнуть далеко, ей нужно все эти шашки сделать. Соответственно, то, что она прочтет,
будет не длиннее, чем число шашков, которое она делает. При этом, если существует хоть какой-то y,
на котором там дальше что-то происходит, то есть y не длиннее этого числа шашков. Потому что даже
если есть более длинный y, то она его весь не прочтет, а прочтет только вот этот префикс. Ну,
и наоборот, если для любого y вот такой длины что-то выполнено, то и вообще для любого выполнено,
потому что все более длинные, она не прочтет, а прочтет только префикс. Поэтому все вот эти
потенциально бесконечные кванторы существования всеобщности можно заменить на ограниченные кванторы
только по словам длины не больше, чем время работы. А сделать так, чтобы у всех y, у всех данных y была
одинаковая длина, можно за счет беспрефиксного кодирования. Ну, кстати, можно и обойтись и без
этого, но формулу проще записывать. Да, просто если одинаковая длина, то мы точно знаем, что,
скажем, у бита, который лежит вот здесь, будет кванш всеобщности. А если длина не одинакова,
то нам нужно откуда-то знать, сколько разделителей было левее этого бита. Это тоже можно сделать,
но будет более сложная формула. Беспрефиксное кодирование, это простейшее беспрефиксное кодирование,
это все биты удваиваются, а потом пишутся 0, 1, а потом все что угодно. И тогда, пока биты идут двойками,
мы считаем, что это настоящий y, а как стало 0, 1, значит, y закончилось, все дальнейшее можно
игнорировать. И тогда можно сделать все y одинаковой длины. Так, ну хорошо, значит, вот, допустим,
мы сделали одинаковые длины, и, соответственно, есть вот функция перехода машины тюринга,
перекодирована в функцию зависимости вот этой клетки, вот этих четырех клеток. Это вообще реально
большая константа, то есть на практике такая сводимость не будет работать, потому что если хоть
сколько бы ни большое число состояний и большое число символов, то здесь будет совсем грубая
оценка число состояний плюс число символов в четвертой степени, и еще это будет показателем,
и экспоненты основанием будут то же самое.
Вот мы скодировали ленту и положение головы.
Это можно делать сотни разных способов. Значит, я предлагаю такой способ. Он наверняка не самый
экономный, но мне, конечно, довольно понятный, что мы прям все данные записываем в одну строчку,
что у нас сначала какие-то символы, потом символы алфавита, потом символ состояния и потом еще символы
алфавита. Это означает, что машины находятся в том состоянии, которое в единственном символе состояния,
указывает на ячейку следующую этим символом, ну а правее и левее, соответственно, содержимые
ленты правее и левее написаны. Тогда утверждается, что такую же конфигурацию на следующем этапе
можно сгенерировать за счет вот таких вот функций перехода, что содержимый вот этой клеточки
однозначно определяет содержимый вот этих четырех клеточек. Почему несимметрично? Ровно потому,
что мы записываем состояние слева от ячейки, то есть если здесь состояние, а здесь ячейка,
то тогда что будет вот здесь зависит и от этой ячейки. Соответственно, это будет просто
дискретная функция, но тут будет много данных. Подождите, это я количество функций таких
написал, а запись будет логарифом от этого. Кстати, не такая уж большая получится. Это у меня число
функций перехода, потому что в каждой из вот этих вот нужно определить вот это, а длина записи будет
логарифм от этого. Кстати, не так уж много. Значит, длина записи, это будет Q плюс А в четвертой на
логарифм от Q плюс А. Да, ну какой-то полином от числа стояний и размера алфавита. Ну как,
длина записи будет это самое, логарифм от числа объектов. Нет, ну можно сказать так,
что у нас будет Q плюс А в четвертой комбинации, которая записанная вот здесь, вот в четырех
клетках. И для каждой комбинации нам нужен логарифм символов, чтобы написать, что будет вот в этой клетке.
Да, сейчас, вся таблица в смысле. Да, вся таблица, это прям подряд записанная конфигурация на всех
шагах машины тюринга. Сейчас, мы в таблицу прям подряд, вот первая строчка конфигурации в начале,
вторая строчка конфигурации после первого шага, третья строчка после второго шага и так далее.
Сейчас, не, в итоге мы должны, конечно, формулу сделать. Да, мы переделываем машину тюринга
формулу. Так что, если к формуле дописать нужные кванторы, то это будет равносильно
тому, что машина тюринга примет, соответственно, X с вот этими кванторами. Ну сейчас, давайте тогда,
сейчас я напишу, может быть понятно. То есть глобально, что мы хотим, глобально нужно переделать
исход на X в формулу, так что формула лежит в нужном сигмакатом SAT, тогда только тогда,
когда X лежала в B. Вот это мы хотим сделать. Сейчас, подождите, пока мы просто рассуждаем о том,
как машина тюринга работает. Сначала рассуждаем, потом напишем формулу. У машины тюринга есть
начало шаги и конец. Начало выглядит вот так вот, что начальство состояния, потом тот X,
который у нас был изначально, и потом какие-то Y нужны длины через пробелы. После этого переходы
все выглядят одинаково. Все переходы выглядят, что если взяли четыре соседних клетки, то содержимое
вот этой клетки однозначно определяется этими четырьмя. Просто по таблице функции. Ну однозначно,
машина тюринга, сейчас, утверждение такое, что вот эти вот фигуры, заполненные состояниями и
символами алфавита, бывают совместимые с работой машины тюринга, бывают несовместимые. Вот если они
все совместимые, то тогда и переход от строчки к строчке тоже ровно по команде машины тюринга
происходит. Не надо говорить конфигурации, потому что конфигурация это как-то строчка.
Я чуть-чуть подробнее поговорю, что означает эта корректность. Во-первых, если в этих четырех
клетках состояния нет вообще, то тогда символ здесь просто повторяет символ вот здесь. В каждой
клетке может быть состояние либо символ. Ну еще раз, символы конфигурации это либо состояние,
либо символ ленты. В клетке и лежит либо состояние, либо символ ленты. Корректная
конфигурация означает, что там есть ровно одно состояние, и соответственно машина в этом
состояние находится, указывает на следующую клетку после этого состояния,
ну и символы там какие написаны.
Соответственно, если состояния здесь нет вообще, то тут символ просто повторяет
вот этот вот. И даже если состояние вот здесь вот, если состояние вот здесь вот, то это
тоже повторяет. Но если состояние в одной из этих трех клеток, то нужно уже
смотреть на команду. Ну и дальше там несколько вариантов, например, если
символ вот здесь вот, то мы смотрим там, если она на месте останется, то здесь
должно быть новое состояние, а если она лево сдвинется,
то здесь должен быть вот этот вот символ. А если направо сдвинется, то вот этот,
но после применения команды и так далее. Нужно рассмотреть несколько случаев,
там, не знаю, десяток видимо случаев, и в каждом определится, что в этой клетке.
И дальше, соответственно, если у нас есть уже какая-то конфигурация корректная, и в каждой
клетке написано то, что получается по этой функции, то следующая конфигурация тоже корректная.
Но это доказывается аккуратным анализом, разбором всех этих десяти случаев и сравнением,
что должно быть по этому правилу и что должно быть по машине чюрлинга, и что всюду будет одно и то же.
Вот. Ну а в конце нужно, чтобы было принимающее состояние. То есть в последней строчке будет
написано только, что здесь в какой-то ячейке будет принимающее состояние. Вот. Но это проверяется
просто сравнением. То есть в последней кроссформе очень легко написать, что у нас вот эта клетка
равняется QA или следующая равняется QA и так далее, что какая-то клетка равняется QA. QA это QA accept.
Так, хорошо, теперь как же это все форму записать и откуда получатся кванторы? Значит, нужно написать так.
Так, ну если коротко, коротко я вот здесь напишу. Значит, X лежит в B тогда и только тогда, когда
существует Y1, там для любого Y2 существует Y3 и так далее, существует YK и еще существует
содержимый всех остальных клеток. И существует, вот зачем нужен был последний квантор, чтобы он
склеился со следующим. Значит, существует содержимое остальных клеток. Вот. Такое, что начальная
конфигурация получается из X вот с этими Y. Начальная конфигурация из X, Y1, Y2 и так далее, YK,
значит, конечная это QA, а переходы корректные, да, то есть переходы вот через вот эти фигуры.
Значит, переходы корректные. Вот. Ну и дальше еще, чтобы это была именно формула, нужно объяснить,
как записать формулами все, что здесь написано. Вот. Но это мы уже делали в Теремку Кулевина,
и здесь в целом точно так же, да, то есть нужно написать, что тут первый символ это QA1, да,
а второй символ это первый символ X и так далее. Потом здесь, соответственно, пробел. Все бит Y это
либо 0, либо 1 обязательно, а не что-либо еще. Да, здесь пустые. В конце где-то здесь есть символ QA.
Вот. И дальше большая конъюнкция по всем клеткам, да, что все клетки получаются вот здесь, как функции,
вот эта фиксированная функция от вот этих вот четырех. Вот. Это будет большая, но поленомиальная
формула. Вот. И ровно за счет того, что здесь последнее кванторское существование и следующий
тоже кванторское существование, получится, что и кванторная глубина не изменится. Все еще будет
начинаться существование и все еще будет коальтернирование. Ну вот. Вот так это и делается.
И также видно, что здесь важно именно, что это квантор именно в конце должен быть, его нельзя
вначале поместить, будет другой смысл. Что сначала мы как бы выбрали цепочку этих Y,
а потом уже дозаполняем всю остальную таблицу, которая именно на этих Y вычисляется.
Существует содержимое остальных клеток. То есть есть вот протокол работы машины тюринга. Значит
есть первая строка, что было написано в начало, последняя строка, что должно быть принимающее
состояние и все промежуточные, которые получаются по правилам работы машины тюринга. Так. Ну ладно,
дайте небольшой перерыв сделаем, чтобы это все уложилось.
Так, хорошо. Значит вот доказать для базовых задач. Значит для sigma k at s at, pi k at s at.
Значит дальше конечно же есть много других полных задач на уровнях иерархии. В том числе те примеры,
которые мы разбирали в прошлый раз, там окликовые раскраски и прочее, они все на самом деле будут
полные в тех классах, в которых мы их классифицировали. Но это правда в основном не простые рассуждения,
то есть там должны быть какие-то конструкции. Простые рассуждения получаются, если как-то модифицировать
те примеры, которые были с NP полными задачами. Ну например,
может там какая-нибудь, они немножко игрушечные примеры будут получаться, но тем не менее формально
правильные по крайней мере. Значит, например, можно рассмотреть задачу о дополнении раскраски.
Задача о дополнении раскраски. Можно даже по-разному ставить, но, например, можно так поставить вопрос.
Значит, есть граф и есть некоторое множество s. Значит, где s это множество вершин, под множество вершин.
Да, естественно так, что любая раскраска,
любую корректную раскраску s в три цвета можно дополнить
можно дополнить до корректной раскраски, до корректной раскраски всего графа.
Вот так, это p2 получается. Значит, любую можно дополнить. Вот это будет p2 полная.
Так, да, кстати, прежде чем говорить про вот эту задачу или вообще любую другую,
надо поговорить про нормализацию задачи, то есть сводимость к 3 KNF.
Значит, мы знаем, что... так, тут я давайте подробно буду писать. Значит, 3 KNF SAT. Это задача NP полная.
Значит, выполнимость 3 KNF это задача NP полная. А вот, например, 3 KNF ТАФТОЛОГИЯ, и это будет лежать в p.
Почему? Ну, вообще-то 3 KNF почти никогда не будет ТАФТОЛОГИЙ. Потому что если скобка будет нулевая,
то и вся конъюнкция будет нулевая. По этой ТАФТОЛОГИИ 3 KNF может быть только если там в каждой скобке есть какая-то
применная и ее отрицание с дизюнкцией. Тогда будет как бы конъюнкция большого числа законов исключенного третий,
в этом будет, конечно, ТАФТОЛОГИЯ. Но это, конечно, можем проверить. Поэтому 3 KNF ТАФТОЛОГИЯ это лежит в p.
А вот если взять 3 DNF ТАФТОЛОГИЯ, это будет KNP полная. Потому что понять, что DNF будет ТАФТОЛОГИЙ,
значит, это задача о том, могут ли все скобки одновременно обнулиться. И это двойственная задача к вопросу,
могут ли все скобки быть истинными в 3 SAT. То есть видно, что такие нормальные формы будут разные.
Но почему это KNP полная? Потому что если мы возьмем отрицание KNF, то мы получим DNF, пронеся внутрь.
Вот здесь я еще не стер, мы берем отрицание, вот здесь KNF, проносим его внутрь и получаем DNF.
И, конечно, число литералов скобки не поменяется. Ну и, соответственно, так будет и дальше,
и это будет определяться, опять же, последним квантором. Соответственно, будет, так, давайте я тут напишу,
значит, 3 KNF sigma kT SAT будет sigma kT полная при нечетном K.
И, наоборот, 3 DNF, все еще sigma k SAT будет sigma kT полная при нечетном K.
Потому что важно, какой там квантор в конце стоит. Ну спикат и наоборот.
Спикат и наоборот, то есть оно будет полным, с KNF будет полным при четном K, и с DNF будет полным при нечетном K.
Так, хорошо, но в том примере там как раз P2, то есть будет 3 KNF, в котором мы привыкли.
Так, ну правда, на лекции именно для три раскраски я там для нотоликвелл рассказывал, если мы его
хотим использовать, то свадимость, то нужно еще сначала первую свадимость повторить.
Вот, но есть свадимость, которую, видимо, многие на семинаре прошли, которая сразу из 3 SAT без
посредничества нотоликвелл. Так, соответственно, вот эта вот задача о дополнении раскраски можно
как-нибудь назвать, там coloring extension, и чтобы доказать, что она полная, в P2, чтобы доказать,
что она полная, нужно свести P2, 3 SAT, ну или, да, можно в разном порядке писать, то есть 3 KNF,
P2, SAT нужно свести вот к нашему продолжению раскраски, на продолжении три раскраски.
Вот, так, ну я всю конструкцию не буду рассказывать, это будет повторение, в общем, как бы там детали
гаджетов другие, если у вас не было на семинаре, но вы были на лекции, то там детали гаджетов другие,
но общая конструкция, например, такая же, то есть тут есть палитра, значит, где цвета, значит,
истинный, ложный и вспомогательный, вот, и дальше это как бы такой веер, да, значит, веер разных
переменных. Вот, и дальше какие-то гаджеты, которые их друг с другом соединяют. Вот,
значит, как вот это вот выглядит, 3 KNF, P2, SAT, значит, тут, значит, для любого, значит, для любого
X существует Y, значит, ну а дальше какие-то скобки, значит, скобка, конъюнция скобка, значит, какая-то
вот такая вот формула, и причем в скобках могут быть сразу и X, и Y, да, не то что в одной скобке X,
и в другой Y, они как-то друг к другу переплетаются. Вот, ну вот, примерно так же нужно и здесь сделать,
значит, нужно выделить группу X, значит, нужно выделить группу Y, и вот это вот, значит, S, да,
тут дальше еще какие-то гаджеты, значит, которые сейчас не очень важно как выглядят, вот, а важно,
откуда мы S возьмем, значит, в S можно включить палитру и вот эти вот переменные для X,
то есть вот эта вот часть, это S, и тогда получается, что любая раскраска S, но это фактически
присвоение значений всем их сам, вот, а до раскрашивания это, ну, присвоение значений Y,
ну а гаджеты там однозначно раскрашиваются, и, соответственно, если все нормально раскрасывается,
то это значит, что для любой раскраски вот этого, то есть для любых значений X существует раскраска
вот этой части, то есть выбор значений Y, что все скобки выполнены, то есть все гаджеты раскрасились.
Вот, ну вот, примерно так доказывается, что это P2 полная задача. Так, ну чего, понятно? Вот, так,
ну, повторюсь, что это пример немножко искусственный, но тут есть, в Гэри Джонсо ни этого
нету, но есть другой список, тоже где-то страниц на 80, наверное. Вот, называется красивым латинским
словом компендиум разных задач исполнительной иерархии. Вот, ну и там, в этом списке, там где-то
процентов 80 на втором уровне, остальные 20 на третьем уровне, а выше там вообще ничего нету. И он
структурирован по разным областям, то есть там есть отдельно графы, там логика, алгебра, головоломки
и так далее. Вот, ну и там много разных ссылок на статьи, где это все показано. Знаешь, что задачи
полные в соответствующих классах. Есть там некоторое число открытых вопросов. Вот,
так, значит, что же дальше? Ну, поговорим про машины, которые я анонсировал. Значит,
машины, соответствующие, машины, соответствующие вычисления в pH. Да, то есть идея такая, что точно
так же, как для NP у нас есть недetermинированная машина, так что мы говорим, что задача живет в NP,
если она распознается на недetermинированной машине за полиминальное время. Точно так же,
здесь будут специальные альтернирующие машины, так что, соответственно, задача лежит там в
сигмакатом, если она распознается за полиминальное время альтернирующей машины и там типа сигмакаты.
Называется альтернирующие машины. Знаете, что это такое? Ну, это некоторое расширение недetermинированной
машины. Значит, там все состояния делятся на два класса. Прям состояние. Состояние делится на два
класса. Сигма-состояние и пи-состояние. Вот, значит, и так же, как и в недetermинированной
машине, там многозначная функция перехода. Соответственно, раз есть многозначная функция
перехода, то вместо линейного вычисления получается дерево вычислений. Например,
вот начальство состояния, пусть это сигма-состояние. Да, вот я говорю сигма, а пишу квантор. И это потому,
что это одно и то же. Читаясь проще сигма, метку проще ставить существует. Соответственно,
тут может быть, ну, например, три разных перехода. Соответственно, тут где-то может быть
тоже сигма-состояние, а где-то пи-состояние. Вот. Дальше там тоже как-то это ветвится, да, значит,
может где-то и не ветвится. Дерево исполнения программы, да. Ну, для конкретного входа. Да,
то есть для конкретного входа будет конкретное дерево. Вот. Ну и так далее. Значит, и так далее.
И дальше где-то будут уже ответы. Так, ну давайте я прям, дать я yes и no поставлю.
Вот. Ну, в общем, и так далее. Значит, теперь смотрите. Во-первых, как определяется ответ. Во-первых,
требуется, чтобы обязательно дерево было конечным на любом входе, да, то есть никаких бесконечных
ветвей нету, и более того, чтобы глубина была полиномиальная. Да, то есть обязательно вот
глубина будет полиноматенна на любом входе. Значит, после этого, значит, в конечных вершинах у нас
уже есть ответ, да или нет. И дальше этот ответ поднимается снизу вверх с учетом того кванта,
который здесь стоит. Да, то есть, например, вот здесь существует yes и no, значит, ответ yes, да,
существует. Здесь для любого, значит, yes, yes, ответ тоже yes. Значит, здесь существует, соответственно,
ответ yes. Значит, здесь там yes и no, но здесь для любого, да, значит, поэтому здесь ответ no, значит,
и здесь ответ no. Вот. Ну, здесь что-то еще будет. Да, в принципе, можно не вычислять в данном случае.
Ну, значит, для любого входа будет какое-то дерево, и, значит, ответ вычисляется от листьев к корню,
от листьев к корню, применяя нужные операции. Так.
Не, ну это, конечно, это даже в НПО может быть экспоненциальным. Значит, то есть, ну, смотрите,
в качестве метафора полезно считать следующее, что вот просто недетерминированная машина,
она как бы так делает форки в параллельные миры, и, соответственно, если в каком-то параллельном
мире получился ответ да, то, так сказать, центральный форк сразу получает об этом информацию, да,
и выдает ответ да. Вот. А если ни из одного параллельного мира не пришел ответ да, то центральный
форк говорит ответ нет. Вот. А здесь более хитро. Значит, здесь как бы есть форки, которые вычисляют
конъюнкцию, а есть форки, которые вычисляют дезюнкцию. То есть те, которые вычисляют дезюнкцию работают
так же, как недетерминированная машина тюринга, а те, которые конъюнкции, они должны со всех
параллельных миров собрать ответ да, чтобы потом сказать да. Вот. Так, ну и хорошо. Значит, дальше
можно ввести вот такой общий класс, sigma kt time. Значит, sigma kt time от t от n. Значит, это означает,
что для любого х, во-первых, правильный ответ, полученный вот таким образом. Значит, ответ,
вот этот вот, соответствует тому, что х лежит ва. То есть, если х лежит, то должен быть ответ да,
если х лежит, то должен быть ответ нет. Значит, дальше глубина равна у большой от t от n. То есть,
время работы считается как глубина дерева. В-третьих, начальное состояние, значит, если sigma kt,
то начальное состояние это sigma состояние. Вот. И четвертое, что вдоль любой ветви не больше
k-1 перемены типов состояния. Значит, вдоль каждой ветви не больше k-1 перемены
типа состояния. Ну или что то же самое, не больше, чем k групп состояния одинаковых типов. Вот.
Последнее, конечно, такое немножко сложное и не очень удобоваримое определение, но тут как-то
проще не получается. Нет, ну логично, конечно, да. Вот. Соответственно, значит, pi kt аналогично,
кроме начального состояния. Значит, pi kt time, а t от n, значит, это аналогично, но начальное
состояние это pi состояние. Вот. Ну и после этого можно определить, значит, sigma kt p. Это,
соответственно, sigma kt time от полинома от n. Вот. А то, что это равняется тому, что мы определяем,
это уже теорема. Соответственно, pi kt p, значит, это pi kt time тоже от полинома. Вот. Ну и, значит,
теорема состоит в том, что sigma kt p это то же самое, что через кванторы sigma kt
полиномиальная. Вот. Ну а pi kt p это тоже то, что мы определяем через кванторы pi kt
полиномиальная. Так. Ну, теорема-то не очень сложная, потому что, значит, в одну сторону,
я, наверное, не буду записывать, да, проговорю, потому что это очень похоже на теорему для NP.
Да, для NP у нас была теорема о том, что два определения эквивалентны. Здесь примерно то
же самое. Значит, в одну сторону нужно в качестве вот этого v написать, ну, так сказать, компилятор
вот такой вот альтернирующей машины тюринга. То есть компилятор получает ветку, по которой нужно
идти. И он по ней идет и возвращает нужный ответ. Тогда, конечно, такой компилятор будет полиномиальным,
потому что он не перебирает, куда идти, а он в каждой развилке получает подсказку, куда идти,
и по ней идет. Вот. Но с другой стороны получается, что вот там, где существует,
там как бы должна существовать подсказка, куда идти. Вот. Если есть там длинная ветка,
как вот эта вот. Там налево, налево, налево. Или там налево, направо, налево. А, кстати, здесь уже
другое, да. Вот. В общем, пока идут квандры существования, можно эту ветку просто предъявлять.
Когда начинается квандры всеобщности, нужно, наоборот, перебрать и вот эту ветку, и вот эту ветку.
Но так получается, что если там как группа везенковых состояний, то существует начало ветви,
что для любого продолжения по пи-состояниям существует ветка по сигма-состояниям и так
далее, что в итоге будет ответ да. Вот. Так получается в одну сторону, что если у нас
альтернирующая машина, то можно построить, можно построить предикат так, что формул с квандрами
для предиката верна тогда, только когда машина вернет да. Это в одну сторону. Так. А в другую
сторону нужно, наоборот, нужно построить альтернирующую машину. Там еще проще. Эта
альтернирующая машина сначала там в сигма-состояниях строит там у1, потом в пи-состояниях
строит у2, потом в сигма-состояниях строит у3 и так далее, а потом уже детерминированно запускает
моделирование вот этого исходного предиката на этих построенных у. Вот. Ну ладно. Так, что еще
можно сказать про полинамеральную верахию? Так, ну следующий я доказывать не буду, но полезно
представлять себе характеризацию иерархии через аракулы. Полинамеральная иерархия через аракулы.
Через аракулы. Значит, смотрите, что означает, что какой-то класс, например, NP с аракулом А.
Значит, с аракулом А это означает, что можно за один шаг, за один шаг получать ответ на вопрос
лежит ли Хва. Значит, можно за один шаг узнавать, верно ли Х лежит Ва. Вот. Ну и дальше это
подставляется в определении NP, то есть неважно в какое. Может быть, это недетерминированная
машина, которая в процессе вычисления умеет строить Х, ну вообще-то говоря, тоже недетерминированно,
и потом за один шаг про этот Х узнавать лежит он в А или не лежит. Вот. А может быть верификатор.
У верификатора есть какой-то вход, какая-то подсказка. Он проверяет эту подсказку, но в
процессе может про любой вычисленный Х спрашивать, верно ли он лежит Ва. Значит, это можно делать
адаптивно. То есть можно про один Х узнать, лежит он Ва или нет, и с учетом этого знания вычислить
следующий Х, про который будет идти вопрос. Вот. Но кроме конкретного языка в виде аракулы
бывает целый класс в виде аракула. Что такое NP? NP с аракулом NP. А это один язык. А NP это класс.
Но на самом деле можно сказать, что это NP с одним NP-полным языком. То есть NP, скажем, с трясат.
Ну и с другим NP-полным языком. Вот. Ну либо можно говорить, что аракул выбирает язык,
про который спросить, и выбирает спросить про этот язык. Но все равно, если он спрашивает про
язык, то он его задает какой-то формулой или машиной тюринга и так далее. И все равно,
в принципе, все вопросы к NP можно переделать к вопросу трясат.
Сейчас еще раз. А что мы хотим? Мы хотим все еще находить вот эту коллиндральную машину,
которую мы будем читать? Сейчас. Ну определение, да, что класс NP с аракулом NP. Значит, это класс
тех языков, для которых, соответственно, есть процедура, которая отвечает верно на вопрос,
лежит X в этом языке или нет. Да, и она нетренированная и использует аракул. Ну дальше
есть два варианта. Может быть, что она может сама решить, какой NP-язык спросить и о чем спросить,
а может вместо этого все свести к NP-полному языку и про конкретный NP-полный язык спрашивать. Это
будет одно и то же. Так вот, теорема. Значит, теорема такая, что первая, что sigma k плюс первая
пальномиальная. Это будет NP в степени sigma k, но и также это будет NP в степени pi k.
Второй раз на самом деле очевидно, потому что аракул, в отличие просто от NP, аракул может
переворачивать ответ. И, соответственно, если он умеет решать выполнимость, то тавтологи он
тоже умеет решать и наоборот. Поэтому второе равенство очевидное, а вот первое не вполне очевидное.
Ну и, соответственно, второе то же самое с pi. Значит, pi k плюс первая пальномиальная. Это будет
coNP с аракулом sigma kt pt и это же будет coNP с аракулом pi kt pt. Ну и вот такое
определение позволяет определить еще один класс, который как-то через кванторы, не понятно как
определять. Значит, он называется дельта. Значит, дельта k плюс первая pt это p с аракулом sigma kt pt.
Вот, ну видно, что дельта k плюс первая, она как раз будет где-то между, она будет внутри
в пересечении sigma k плюс первая и pi kt плюс первого, но с другой стороны включая в себя sigma kt и pi kt.
То есть это как раз такой преимущественный класс. Ну, например, дельта первая это p,
дельта первая это p, потому что p с аракулом p это p. Вот, но дельта вторая это уже что-то
больше, чем coNP, но меньше, чем sigma 2 и pi 2. Вот, и кроме того, это больше, чем даже dp,
который мы изучали. Вот, хорошо. Так, наверное, вас интересует вопрос, что будет с альтернирующими
машинами, если мы откажемся от ограничения на число перемен типа, вот здесь вот. Или вообще,
или что будет с формулами, если мы откажемся от ограничений на число кванторов. Ну, ответ такой.
Ну, значит, смотрите, у нас с sigma k там, у нас твердо сказано, что вот у нас есть ровно k этих
самых групп у, ровно k групп у, независимо от длины х. Да, хоть х длины тысячи, хоть х длины миллион,
хоть их длины миллиард, все равно там будет, скажем, 7 этих самых групп кванторов. Вот. А откажемся,
это означает, что число может расти с ростом х. Да, что их может быть там линейное число,
или там квадратичное, или логарифмическое, да, в общем, какое-то. Вот. Ну, и здесь тоже, да,
значит, здесь, конечно, глубина будет полиномиальная, если мы сохраняем вот эту букву p. Вот. Но число
примера кванторов тоже может быть от константы до полинома. Любое. Вот. Вопрос, что будет? Вот.
Ну, оказывается, что это будет класс p-space, то есть класс языков, которые решаются на полиномиальной
памяти. Вот. И, соответственно, все вот это вот и кванторы, и альтернирующие машины дают разные
способы характеризации класса p-space. Значит, на следующей лекции мы как раз будем изучать класс
p-space, как он себя ведет, какие там есть полные задачи. Вот. Ну, насколько я понимаю, все-таки для PMF
это, вроде, последняя лекция от меня. Значит, вы, конечно, можете продолжать ходить, если хотите. Вот.
Но Сергей Алексеевич вроде должен начать лекции, и, значит, где-то там в апреле, наверное,
программа немножко разойдется. Все. Спасибо за внимание.
