Во-первых, я поздравлю вас тем, что вы закончили ваш страншедший период
передачи. Дальше. Процессорная архитектура. Есть два основных класса. CISCRISK. Там еще
выделяется Very Long and Strangest World. Это Intanium Elbrus. Зачем нужно такое количество разных
архитектур. Есть процессоры, которые продаются в том числе и в рознице не только производителям
компьютеров. Делают их в основном Intel, AMD. Причем и компания Intel, и компания AMD производят
их по полному циклу. То есть и разрабатывают процессоры. Есть у них свои фабрики. Ну и по сути,
они являются почти монополистами на рынке x86. Есть еще компании, которые делают только ядра,
но не производят сами процессоры. То есть они занимаются только разработкой, но не производством.
Классический пример. Это компания ARM, которую не так давно купила компания Nvidia. Которая
продает уже готовые ядра разным производителям чипов для смартфонов. И некоторые компании,
были когда-то такие процессоры MIPS. Они использовались в рабочих станциях Silicon
Graphics. Сейчас уже они уже давно ничего не производят. Просто лицензируют свою архитектуру,
которую уже сторонние компании, такие как Broadcom, развивают. Ну и недавно еще появилась,
точнее появилась архитектура достаточно давно. Это RISC-5. Но очень долго не существовала реализации.
Не так давно эти реализации уже появились. В основном это благодаря китайцам и русским.
Так вот, у нас есть огромное количество архитектур, и откуда они берутся, и почему они до сих пор не
вымерли. Ну если смотреть на архитектуру Intel AMD x86, то во-первых, архитектура не самая удачная,
не самая современная. И больше она распространена из-за того, что накоплено огромное количество как
прикладного софта, так и средств для разработки. И просто взять и отказаться. Одномоментно от этого
не получается. Кроме того, когда вы покупаете уже какую-то готовую микросхему, то никто не
гарантирует, что в этих микросхемах нет никаких секретных блоков, которые могут делать что-то,
что не описано в документации. И проверить это очень сложно. В то же время, если вы покупаете уже
некоторые ядра, которые вы штампуете на своих микросхемах рядом с чем-нибудь, то задача по
верификации таких ядер немного упрощается, но тем не менее все равно там могут быть какие-то
скрытые подводные камни и очень хорошо запрятанные тайники. В этом плане намного лучше архитектуры,
которые вы реализуете сами. И в частности, этим занимаются китайцы из компании Лунгсу. А также
в России еще в 90-е годы архитектура MIX была куплена научно-исследовательским институтом
системных исследований. И Neisseran делает процессоры, которые по современным меркам очень слабые,
но зато эти процессоры выдерживают достаточно приличную радиацию, поэтому они могут летать в космос
и вообще их ставят туда, что должно летать где-то высоко, стрелять. В общем, такие вещи можно даже
воспроизвести, но для этого опять же требуется лицензия. Где процессоры можно производить? Можно
и в России, но дешевле это сделать на форсе в Тайване. И что произойдет, если вдруг нам запретят
производить процессоры по какой-то американской лицензии? А произвести это может в любой момент.
Ну, тогда все. Мы, конечно, можем это делать и в России, но ни одна коммерческая компания мировая
просто за этот заказ не возьмется. Китайцы уже давно поняли, когда началась вся эта история с
компанией Huawei и начали развивать уже open source. Вот чем хорош open source? Это общественное
достояние, и никто не может заявить о том, что вы нарушаете какие-то лицензионные ограничения,
и поэтому с этой компанией запрещено работать, запрещено производить их чипы по заказу. Ну и вот
компания C5 это китайская, ну и есть еще российская компания, которая называется Micron, которая тоже
недавно начала делать микроконтроллеры на базе ядра RISC-V. Ну и я думаю, что в ближайшее время,
ну я не имею в виду не прямо сейчас, не до конца нового года, в ближайшие несколько лет, эта
архитектура станет очень популярной. Кроме того, под архитектуру RISC-V уже давно существуют все
средства разработки, на самом деле она достаточно старая, но долгое время существовала только на
эмуляторах. Под все это дело нужно еще как-то писать программы. Ну когда-то писали программы в
машинных кодах на языках ассемблера, причем у каждой архитектуры язык ассемблера свой. Когда-то этот
бардак решили устранить и написали такой ассемблер, который работает на всех существовавших
архитектурах. Называется ассемблер язык C. Было это очень давно, еще в 1972 году, на самом деле язык C не был
первым, в котором предпринимались попытки сделать какой-то кроссподформенный язык, на котором можно
писать программы под разные процессоры. До этого существовал язык B, очень похожий на C, и язык C
является дальнейшим продолжением, как следует из названия. А вот языка по названиям A, ну как бы логично,
буквы A, B, C в английском фолиете. Вот языка A не было. Язык B это синтаксически приоработанный язык BCPL,
и в чем роднит, в чем общее искусство этих языков, то, что на них можно писать очень
низкоуровневую программу. Ну а дальше уже историю вы, наверное, сами знаете. В какой-то момент появился
язык C++, которым у вас теперь учат. Дальше еще появился язык D, но он популярным особо не стал,
потому что примерно в то же время начал активно развиваться язык C++, начиная с 11 стандарта. Один
из авторов языка D, Андрей Александреску, начал активно принимать участие в стандартизации
языка C++ и его развитие. Ну и кроме того, существует огромное количество всяких разных других
языков. И вот с одной стороны, у нас есть огромное количество процессорных архитектур, с другой стороны,
есть огромное количество языков программирования, то есть получаем некоторые двудольные графы,
и если у нас огромное количество вершин из левого и справа, то, наверное, у нас должно существовать
огромное количество ребер. И некоторой помощью такой единой точкой является внутреннее представление,
он же язык под названием LLVM. Это некоторый фреймворк, который позволяет легко создавать компиляторы.
Ну как легко? Я в свое время участвовал в разработке одного из компиляторов, в том числе с использованием
LLVM. Я бы не сказал, что это прямо такое приятное удовольствие, потому что фреймворк с точки зрения
программной реализации достаточно отвратительный. У него с каждой мажорной, в то время еще минорной версии,
меняется API, причем иногда в самых странных местах, типа заглавную вубовь меняли на строчную,
или еще что-нибудь, и совместимость сломают. В общем, LLVM это фреймворк, который, с одной стороны,
состоит из наборов компиляторов, которые его используют. Это может быть все семейство C-подобных
языков, то есть C+, Objective C, также Rust, Swift и еще много других языков. В принципе, почитайте
Википедию, там где-то наверняка аспирки есть. И с другой стороны, у нас после того, как мы
генерируем какое-то промежуточное представление, оно более-менее стандартизовано, мы можем из этого
внутреннего представления генерировать код для каких-то уже целевых архитектур. Это x86,
ARM, MIPS, а также огромное количество всяких разных других процессов. И с одной стороны,
можно бы общелять, что вот это промежуточный язык представления является каким-то универсальным,
принять его как единый международный стандарт. Но, тем не менее, этого до сих пор не произошло,
и более того, в разных версиях framework-allegium этот язык тоже модифицируется, и он не может
быть использован как что-то промежуточное, что можно доставлять на целевое устройство пользователей.
В этом плане существует еще один промежуточный язык, который называется Java Bytecode,
то есть есть такой язык программирования Java, который используется в том числе в Android,
только в Android там не классическая Java-машина, немножко другая. Так вот, исходная идея этого
языка программирования в том, что вы можете написать какую-то программу, дальше эту программу
скомпилировать в некоторое промежуточное представление, которое является строго
стандартизированным, и запускать этот код вы можете на любой архитектуре, где есть виртуальная
Java-машина. Устроена Java-машина достаточно тривиальным образом, именно это стековый автомат,
то есть у нас есть простая программа, которая вычисляет какое-то выражение, превращается в
некоторый код, который, кстати, точно также может быть дезасимблирован в текстовое представление,
и дальнейшие вычисления выполняются уже с использованием стека. С одной стороны,
это хорошее представление, потому что реализовать такую примитивную Java-машину достаточно просто,
но в то же время стековый автомат, он не лишен недостатков, например, его реализация в явном
виде, она не очень эффективная с точки зрения производительности. Ну и зачем вообще понимать,
как у нас что-то устроено на ассемблере, и когда вам это может пригодиться в реальной жизни? То есть,
с одной стороны, общее развитие это полезно, понимать, как устроены программы тоже полезно,
но когда может возникнуть ситуация, когда вы действительно ничего не сможете написать,
кроме как на ассемблере. Такие случаи, они очень редкие, в основном это если вы взаимодействуете
напрямую с оборудованием, то есть если вы пишете что-то для микроконтроллеров, то иногда у вас
возникают задачи, что вам нужно взаимодействовать с портами ввода-вывода, прерываниями, выполнять
системные вызовы, и здесь, кроме как низкоурованными инструкциями, пользоваться не можете. Почему? Потому
что в высокоуровнях языках программирования, таких как C, C++, просто нет никаких устроенных
универсальных инструментов, которые будут работать в УСГ. Ну и когда-то еще ассемблер использовали для
небольших вставок с использованием векторных инструкций. Векторные инструкции нужны были для того,
чтобы делать наш код быстрее. Что такое векторные инструкции? Что такое регистры, вы знаете,
регистры позволяют хранить данные определенного типа. Точнее, тут даже не важно какой тип, они
просто хранят данные определенного размера. Какой там тип, тоже определяется отдельными инструкциями.
Регистров мало, они очень дефицитные, но с ними работать очень быстро, и можно сделать просто
какой-то большой регистр, замкнуть на него блоки, которые существуют в процессоре стандартные,
и сделать так, чтобы эти блоки одновременно выполняли операцию сразу над несколькими частями
регистр. Поскольку сделать это достаточно недорого с точки зрения схемотехники,
но за счет этого мы получаем существенное ускорение производительности, потому что,
если у нас требуется выполнять какие-то операции, причем операции одинаковые на
каким-то большим объемам данных, то мы можем сделать это параллельно. И, как раз таки,
регистры называются векторными, они имеют размер от 128 бит и выше, и позволяют внутри себя хранить
данные разных размеров, то есть этому будет либо большее количество 300 битных значений,
либо меньшее количество 700 битных, но при этом вы все равно получаете заметную ускорение.
И бывают два вида операций. Это либо вертикальные операции, когда вы берете два вектора и
оперируете над ними как над какими-то множествами разных значений, либо горизонтальные операции,
когда вам нужно полвекторы получить какой-то скаляр. Примеры скалярных горизонтальных операций,
это, например, поиск минимального или максимального значения, ну или в какой-то степени скалярное
произведение, если у вас только два вектора. И вот такие векторные инструкции, они когда-то
впервые появились в идолской архитектуре, на самом деле они есть и в других архитектурах,
и почему такие вещи не обязательно писать на ассемблере. Ну, во-первых, какие бывают у нас
инструкции. Есть регистры XMM, есть еще регистры YMM, ZMM. Как понять, какие наборы команд у вас
поддержит процессор. Если у вас система Linux, то у вас есть файл-система Procfs,
и внутри нее есть текстовый файл cpu-info, который отображает информацию о вашем процессоре,
точнее о нескольких процессорах. Так, когда я говорю несколько процессоров, вы понимаете,
что это не несколько микросхем установленных в вашем компьютере, а несколько ягер, но с
логической точки зрения они представляются собой как отдельные процессоры. Так вот, и тут есть
такой параметр в выводе как Flux, который в том числе содержит информацию о том, какие расширения,
какие дополнительные наборы инструкций процессор поддерживают. Скорее всего, у вас на произвольной
взятом компьютере, неважно насколько он старый, как минимум есть инструкции MMX, SSE разных версий,
и набор инструкций AVX, ну и AVX2. Если у вас относительно свежий ноутбук, то еще есть инструкции,
которые начинаются с префикса AVX512. Там тоже есть несколько разных наборов. На самом деле,
поддержка таких расширений, она не обязательно по стандарту, и если вы пишете софт, который должен
поддерживать, который должен выполнять операции с использованием векторных инструкций, то по-хорошему
нужно проверять, а поддерживает ли процессор векторные инструкции, если нет, то скатываться на
фолбек-реализацию. Ну и что за большие векторные регистры, которые вы можете использовать? Чаще
всего используются 128-битные регистры, которые называются XMM, которые позволяют либо хранить
264-битные значения, либо 438-битных. В этом плане, на самом деле, тип данных float,
который представляет собой вещественные числа с не самой высокой точностью, внезапно оказался
очень полезным, поскольку если вы пишете, например, обработку видео, либо делаете игрушку, то вам
важнее, чтобы обработка выполнялась быстрее, при этом не важно, что вы немножко теряете в
качестве изображения, это не такие уж большие потери, но за счет вдвое меньшего размера типа
данных, вы позволяете вдвое быстрее обрабатывать эти данные на процессоре используемых векторных
инструкций. Ну и в середине нулевых регистр SSE стал в два раза больше, набор команд обозвали AVX,
при этом вы можете использовать младшие части AVX регистров с использованием обычных SSE
либо MMX команд, ну и современная версия процессоров еще позволяет использовать 12-битные регистры,
но это уже узкоспециализированные инструкции и задачи обычно используются в задачах связанных
с криптографией. Как использовать такие инструкции? Ну либо писать на ассемблере, что бывает очень
часто не очень удобно, либо вы можете продолжать использовать высоковолновые языки C и C++ и делать
некоторые вставки использованием так называемых интерсиктов, то есть конструкции, которые оформлены
в виде оси ишных функций, но при этом функциями не являются. То есть когда компилятор включает
так называемые интерсикты, которые он распознает, если компилятор это поддерживает, то он подставляет
вместо них синтексические эквалентные ассемблерные векторные инструкции, но при этом на самом деле
никакого вызова реального функции через инструкцию call не происходит. Что делает программа? Она считает
скалярное произведение двух векторов. Кто помнит, что такое скалярное произведение? Так молодцы, что это такое?
Ну берем попарное произведение всех элементов и считаем их суммой. То есть на самом деле эту
программу можно реализовать через обычный цикл, но цикл будет требовать достаточно много инструкций,
если мы напишем то же самое с использованием векторных инструкций. Вот та же самая программа,
написанная через интерсикты, компилируется. Да, вот для компиляции здесь уже требуется небольшая
магия, потому что если вы просто так попросите компилятор gc скомпилировать код, то на интерсикты
он нам скажет, что неизвестная инструкция, потому что требуется включить дополнительный набор
инструкций с помощью опции минус msse в нужной версии 4.1 или бава x. Вот значение 7, если это
произведение 1 умножить на 5, плюс 2 умножить на 6, плюс 3 умножить на 7, плюс 4 умножить на 8.
Очень простая программа с простым результатом. На самом деле здесь интереснее посмотреть на тот
код, который у нас генерируется. Причем я еще добавляю опцию минус o0 для того, чтобы компилятор
ни в коем случае не вздумал никак оптимизировать код и сделать что-то неочевидное. Так, компилируем и
смотрим теперь во что этот код у нас превратился. Так, ну и превратился в этот код некоторую
пеленку, в которой нет ни одной функции call. Точнее где-то она в конце есть, но это вызов уже
принфа для вывода на экран. На самом деле вот ни одна из этих функций, вот ups или dpps, она не
вызывается именно как функции. Как сделать скалярное произведение? Мы просто загружаем четыре значения
из памяти в один векторный регистр, два массива, два векторных регистр. Дальше выполняем скалярное
умножение. Последний параметр в этом случае это некоторая битовая маска, которая указывает,
какие из элементов должны участвовать в произведении. Это вот старшие 4 бита и младшие биты указывают,
куда, в какую часть этого большого вектора нам нужно записать результат. Можно в принципе
растиражировать по всем, но либо использовать только один из них. Кроме неновской архитектуры,
бывают еще другие архитектуры, в которых тоже предусмотрены векторные инструкции. Самый
распространенный из них это ARM Neon, присутствует практически во всех мобильных телефонах,
ну и планшетах тоже. Причем в случае с архитектурой ARM тут есть два разных набора инструкций. Один из них
предназначен для использования в потребительской бытовой технике, то есть смартфоны, планшеты,
макбуки. И есть еще отдельный набор инструкций под ангелем, который решает примерно те же самые
задачи, но уже в микроконтроллерах. Вот архитектуры Cortex-ARM это обычные процессоры широкого
спектра назначения, и минус M это микроконтроллер. То есть у нас получается есть интерсикты для
интеллоских процессоров, есть два разных вида интерсиктов для ARM, для архитектуры RISC-V так
вообще нет никакого стандарта, поскольку стандартная эта архитектура описывает только минимальный
необходимый набор инструкций, а все остальное решается расширениями. Ну и еще есть всякие
там разные PowerPC, MIPS. Ладно, конечно мы про них можем забыть как про достоинство истории,
но тем не менее. У нас уже получается, что если мы хотим использовать векторные инструкции, нам
придется сделать три разных реализации для интелл ARM и RISC-V, что уже не очень удобно и спрашивается,
зачем вообще тогда было изобретать язык C, если мы в конечном итоге все равно скатились в
необходимость использования платформы зависимых каких-то инструкций, то есть по сути ничем не
отличаемся от Assembler. Ну есть некоторые решения, в частности это стандарт по названию OpenMP,
который позволяет писать обычные программы с циклами и вставлять некоторые дополнительные
директивы, так называемые прагмы, которые распознаются компилятором и по этим прагмам
происходит преобразование кода с использованием уже как симпт инструкции, так и распроявлевание
с использованием многопоточности. Ну распроявление с использованием многопоточности, оно в сочетании
с OpenMP не очень распространено, поскольку это проще сделать вручную, а вот распроявление на
уровне симпт инструкции с помощью OpenMP достаточно часто используется и если вы еще сдадите две сессии,
то вы доживете до третьего курса, на третьем курсе у вас будет курс по названиям проявление
распроявления вычисления, про OpenMP вам в том числе будет тоже рассказывать, у вас на этом даже будут
домашки. Так, ну и поскольку набор задач, которые решаются с помощью векторных вычислений,
он достаточно ограничен, то есть у нас не так много команд на самом деле и решают они что-то,
что можно писать математическим языком, по сути это вся линейная алгебра, то есть уже готов в библиотеке,
которые реализуют большую часть того, что вам, что вы могли бы писать вручную. Называется стандарт
Basic Learner Programs, очень старая библиотека под названием NetBlast, которая дала этот стандарт и первую
реализацию. Впоследствии эту реализацию переписали под разные процессорозависимые
архитектуры, в том числе под GPU. И где используется Blast? На самом деле, если у вас установлен Python,
если у вас установлена библиотека NumPy, то скорее всего она у вас использует именно интерфейс Blast,
но маловероятно, что у вас стоит реализация NumPy, которая его не использует. И вот как раз в этих
библиотеках, которые могут быть в том числе и закрытыми, а не опенсорсными, реализуется вся
функциональность, которая используется Data Sanitizer. Ну и в свою очередь накладываются еще некоторые
ограничения на данные, то есть как можно еще ускорить работу с большим объемом данных. Если у вас
есть векторы, векторные регистры большого размера, то понятно, что удобнее загружать данные из памяти
и сохранять обратно в память таким образом, чтобы процессор не проходилось пересчитывать адреса,
выполнять какие-то сдвиги, то есть сделать данные в памяти выровненные по размеру регистра.
Стулкой выравнивания данных вы с этим уже сталкивались, когда мы смотрели вызов каких-то
функций с использованием стека и часто натакались на ограничение, что стек должен быть выровнен по
границе 16 байт. 16 байта как раз 128 бит и на самом деле, если вы поставите себе откладывающую
информацию для стандартной AC библиотеки и сделаете стек не выровненным по границе 16 байт, то под
откладчиком вы увидите, что падение с этим связанное происходит где-то при использовании векторных
инструкций, а именно стандартной AC библиотеки, когда вы делаете вызов какой-нибудь функции,
то многие функции просто выполняют целиком копирование какого-то набора векторов, в том
числе векторных, сохранение в стек и за счет того, что стек у вас не выровнен по границе 16 байт,
происходит проблема, связанная с функциями чтения и загрузки вот как раз именно векторных.
Ну можно конечно выровнивать и делать в том числе явным образом для этих данных, а не только для
стека, но во-первых, если вы делаете память в куче, то это сильно упрощает вам задачу, вы можете либо
просто выделить память с запасом и пересчитать указатель, либо использовать уже готовые функции
из POSIX, либо стандартной AC библиотеки, если вы выделяете память на стеке, то в языках AC и C++
есть еще одно специальное ключевое слово aligns, которое предназначено для указания, как именно
данные должны быть выровнены при размещении на стеке. И для чего нужно выравнивать? Ну во-первых,
для использования векторных инструкций, во-вторых, если вы аккуратно понимаете, как у вас данные
выровнены в памяти, то это может еще положительно сказаться на том, как данные у вас размещаются в
кэш. И кэш-память на самом деле это достаточно важное понятие в архитектуре. В самых первых
процессорах, ну и вообще в современных микроконтроллерах кэш-память не используется,
она важна только там, где требуется хоть какая-то более-менее адекватная производительность и из
каких соображений она появляется. Начнем с того, что у нас бывают два разных типа памяти. Это
память статическая и память динамическая. Одна ячейка статической памяти это от 4 до 8 транзисторов,
достаточно сложная такая конструкция. Чем она примечательна? Для чтения требуется один такт,
для записи требуется два такта и с какой частотой может работать эта ячейка памяти. Но фактически
с той частотой, с которой у вас работает процессор или еще какой-то вычислительный элемент. Здесь
все ограничивается только уже физическими возможностями, то есть размерами транзисторов,
которые у вас на микросхеме. Чем такая память плоха? Несколько транзисторов, они кушают много
электроэнергии, во-первых, во-вторых, их просто много и поскольку у вас ограниченная площадь
кристалла, то много памяти в этом разместить не сможет. В противоположности этому динамическая
память это совершенно тупейшая вещь, просто конденсатор, на самом деле конденсатор в микросхемах,
это отсутствующий элемент, поскольку может быть реализован просто расстояние между двумя проводниками,
соседними. То есть фактически это один транзистор плюс как-то хитро расположенный проводник. Очень
простая схема, поэтому динамической памяти вы можете на ту же площадь кристалла разместить
намного больше. И как эта штука работает? Она просто заряжает конденсатор, при чтении он
разряжается, его нужно перезарядить. Все, достаточно просто. Поставить 1 или 0, это значит либо разрядить
конденсатор, то есть примедительно прочитать и никуда не запомнить результат, либо его наоборот
подзарядить. Очень простая ячейка, поэтому динамической памяти вы можете напихать очень много.
Какие здесь недостатки? Во-первых, время заряда и разряду конденсатора, оно не нулевое, поэтому такая
память работает медленнее. И кроме того, требуются еще циклы перезарядки. То есть на микросхему
динамической памяти требуется еще завести дополнительную микросхему, которая будет периодически
через определенные интервалы перезаряжать конденсаторы, то есть читать значения и записывать их
заново. Достаточно громоздкая схема. И где какие микросхемы используются? Микросхемы динамической
памяти используются практически везде, где мы говорим про слово память. То есть оперативная
память, которая у вас несколько гигабайт установлена в телефоне или в ноутбуке, или еще
где-нибудь. Это все динамическая память, потому что она дешевая, мы можем ее в больших количествах
достаточно недорого использовать. В то же время бывают устройства, например, микроконтроллеры,
в которых не требуется много памяти, поэтому там используется только статистическая память. И
здесь получается экономия за счет того, что нам не требуется дополнительная схемотехника. Вот как
раз для перезарядки конденсаторов и для того, чтобы после чтения как-то временно буферизовать эти
дамы. То есть там, где у вас есть небольшой микроконтроллер, скорее всего, с динамической
памяти нет, там только статистическая память просто за счет простоты, потому что много памяти
вам не требуется. И кроме того, поскольку статистическая память работает во много раз быстрее
динамической, то она остается в качестве промежуточного буфера между процессором и
между ядром процессора и оперативной памяти для того, чтобы ускорить доступ к каким-то
часто используемым фрагментам. Но как можно получить информацию о кэш-память вашего
процессора? Опять же, если у вас есть система Linux, а не BSD, не Mac, не Windows, то вы можете зайти
в виртуальную файловую систему slash sys, там есть у вас такой подкаталог devices, который описывает
все устройства, которые у вас доступны из ядра операционной системы, там есть дальше система
и процессор. Процессоров, причем может быть несколько, CPU 0, CPU 1, CPU 2, CPU 3, на самом деле это один
тот же процессор, просто разные его ядра. По какому из них смотреть информацию не особо принципиально,
поскольку у большинства процессоров все ядра одинаковые, но за исключением ARM, у которых
бывают ядра быстрые, бывают ядра энергоэффективные. Итак, мы заходим информацию по процессору,
что мы можем узнать. Нас интересует на этой лекции кэш-память, и кэш-память у нас бывает
несколько уровней, каждый подкаталог содержит набор текстовых файлов, соответствующих каждому
конкретному уровню. 0, 1, 2, 3 – это разные уровни кэш-памяти, на самом деле их всего три,
а просто первый уровень в интеловских процессорах делится еще на две части – отдельный кэш для данных
и отдельный кэш для инструкций. Вот в каждом подкаталоге есть файл по названиям type, в котором
написано предназначение этого кэша. Вот дейта означает, что это кэш для данных, индекс 0, кэш 1,
написано instruction – это кэш только для инструкций, но кэши более верхнего уровня 2 и 3 уже предназначены
для того, чтобы хранить смешанные данные без разбора на данные инструкции, они называются Unified.
Какие у нас бывают уровни кэши? Самый далекий от процессора, но ближе всего располагающийся к
памяти уровень L3 используется всеми ядрами процессора. Когда процессоры были одноядерными,
то обычно под кэшем L3 поджимались какие-то дополнительные платы, которые устанавливают
системную плату. Кроме того, у каждого ядра может быть свой кэш, в который никто другой
лазить не может. Ну и самый близкий к ядру кэш в некоторых процессорах делится на две части,
в некоторых нет. Обычно имеет самый небольшой размер, но к нему самый быстрый доступ. Казалось бы,
одни и те же микросхемы статической памяти, доступ может быть очень быстрый ко всем уровням,
но здесь мы еще теряем некоторое время на то, чтобы выполнить преобразование из адресного
пространства внутри кэшированных данных в адресное пространство, которое у нас реально
физическое на всю память. И в этом плане у нас L1 быстрее, чем L2 и L3. Ну и в L3 еще требуются
механизмы синхронизации между разными ядрами. Так вот, на что у нас влияют, какие у нас бывают
характеристики кэша. Во-первых, это у нас может быть уровень кэша, либо ближе всего к ядру,
либо дальше от него. Дальше у нас какие-то ядра, какие-то уровни кэша могут использоваться
несколькими ядрами, либо только одни. Вот shared list CPU — это некоторая характеристика,
которая указывает, каким инут мэп это генар убитая маска. Если у нас процессов с индексом 0,
то shared list CPU для его локального кэша будет 0, для первого 1, если мы посмотрим на кэш третьего
уровня, то он уже используется сразу двумя, либо четырьмя, либо еще с какими-нибудь ядрами.
Что еще интересного? Ну и размер кэша. Какие характерыны есть размеры у кэша? Это либо
несколько килобайт для кэша L1, который самый быстрый, а вот для кэша самого последнего уровня
тут все зависит от того, сколько стоит ваш процессор. В бюджетных моделях это может быть всего
пара мегабайт, в дорогих процессорах, например в Intel Xeon в прошлом году из того, что можно было
реально купить в Москве, самые большие были порядка 35 мегабайт, в этом году, конечно, уже и побольше,
но все равно это не гигабайты, то есть размер кэша на три порядка десятичной записи дороже,
чем оперативная память, которая является динамической. И тут возникает естественная
проблема, а как запихать невпихуемое? То есть у вас есть вся оперативная память,
которая может быть много гигабайт, и если вы пишете какую-то большую программу, то возможно,
что несколько гигабайт вам может потребоваться даже в рамках одного процесса. И возникает проблема
с тем, как выбирать данные, которые должны попадать в кэш. И естественное при обращении к какому-то
произвольному участку в памяти у вас может возникать ситуация, что данные в кэш не загружены,
потому что это место уже было кем-то занято. И вот такая ситуация, которая называется кэш промах,
из-за чего может возникать? Ну, во-первых, вы могли еще ни разу не обратиться к какой-то участку
физической памяти, поэтому данные не были закэшированы. Но это не страшно, вы один раз
прочитали, все, после этого данные находятся в кэше, вы можете с ними в кэше работать и радоваться
жизни. В какой-то момент данные из кэша могут выгружаться просто потому, что место закончилось,
и надо загрузить другие данные, а размер кэша у вас сильно меньше, чем размер памяти. Либо
данные были выгружены из кэша из-за нарушения свойства ассоциативности, поскольку процессор
тоже делает какие-то предположения о том, какие данные должны быть в кэше, а какие нет, для того,
чтобы увеличить вероятность того, что он будет всегда работать с актуальными данными. И вот что
такое ассоциативность и как она связана с тем, что у вас в кэше располагается? Вся кэш-память
делится на некоторые ячейки, некоторые минимальные блоки. Размер блока, он определяется, опять же в
этом файле вы можете найти геринси line size. Для индовского процессора это будет всегда 64 байта,
причем я смотрел в разных процессорах, и зионах, и i5, и ватонах, они везде 64 байта. Если не Intel,
AMD, ну возможно там могут быть какие-то другие значения. Так вот, есть некоторые небольшие блоки,
некоторые минимально возможные адресуемые куски, которые попадают в кэш-память. Размером по 64 байта,
а вот сам блок, плюс метаданные, которые определяют, где этот блок находится реально в памяти, называется
кэш-линия. Из кэш-линии у нас образуются некоторые горизонтальные участки, некоторые наборы,
и количество наборов оно может быть занято определенным процессом, который у вас в текущем
моменте выполняется. Поскольку у вас одновременно в памяти может находиться сразу несколько программ,
они могут выполняться на разных ядрах. Мы можем объединять при этом какие-то кэш-линии по вертикали,
и вот одна строка, это так называемые Ways of Associativity, это некоторое множество различных
возможных вариантов доступа, то есть вы выполняете какую-то программу, и вашей программе одновременно
может быть нужно до 12 разных кусков из разных участков физической памяти. Поскольку эти блоки
могут быть далеко отстоящими друг от друга, то каждый такой столбец в организации кэша,
который доступен вашему процессу, может ссылаться на разные достаточно далеко
разнесенные друг от друга участки физической памяти, например, стэк, плюс какая-то часть кучи,
плюс код программ, плюс библиотека, плюс кроме того есть еще в каждой программе таблица отображения
из виртуального распространения физическую память. На самом деле достаточно много разных частей,
которые нужно одновременно адресовать, но количество таких независимых участков, оно ограничено
для каждого процессора, и в инвалидских процессорах их не более чем 12, и на самом деле это очень мало.
Поэтому возникает проблема о том, как наиболее эффективно использовать кэш, и любой софт должен
писаться с учетом того, что вы не можете никак повлиять на кэш, но вы можете сделать так,
чтобы данные с большей вероятностью в кэш попадали, эти данные были актуальны и действительно
востребованы. Как этого добиться? Во-первых, данные нужно располагать непрерывным куском,
чтобы они не были разбросаны по всей оперативной памяти, во-вторых, для того чтобы данные быстрее в
кэш память загружались, то желательно сделать их выровненными по границе кратной размеру кэш линии
процессора. Размер кэш линии для инвалидских процессоров это 64 байта, что мы можем 64 байта
запихать? Достаточно много, либо 4 SSE регистра, либо один большой 512 битный регистр. И как еще
можно эффективно использовать кэш? В первую очередь располагать связанные между собой данные как
можно ближе друг к другу. И повлиять как-то на использование кэша вы не можете даже если будете
писать программу на Assembler. То есть нет таких инструкций, которые указывают процессор явным
образом такой-то кусок памяти загрузить в кэш. Это можно делать только косвенным образом. Например,
оптимизирующие компиляторы C, C++ при обращении к каким-то данным просто генерируют в определенной
период времени какие-то инструкции, которые должны подтягивать данные, просто обычные инструкции
загрузки. И вставляют инструкции загрузки так, чтобы они хронологически следовали
немного заранее, чем эти данные должны быть доступны. И таким образом можно как-то косвенно
управлять кэшируем. Опять же компилятор сделает лучше, чем если вы будете делать вручную. Вручную
надо посмотреть на программу, на артикуру программы в целом. И классический пример правильного или
неправильного использования кэша это когда вы работаете с какими-то алгоритмами, которые
требуют двумерные массивы. Канонически такой пример на плюсах. Как реализовать матрицу,
умножение двух матриц. С алгоритмической точки зрения здесь приведен не самая лучшая
реализация, потому что требует время порядка от n в кубе. Кстати, две матрицы можно, за какое время
можно. Да, есть алгоритмы Штрасена, поэтому два в степени 2 и 7. Можно сделать лучше, но мы сейчас
не рассматриваем алгоритмическую вставляющую этой программы. Нас интересует только техническая
вставляющая. И вот чем плох вектор векторов, двумерный массив, тем что у нас данные просто разбросаны
по памяти. Вектор векторов это по сути массив указателей, если переводить плюсовый язык
анонсичный. И каждый указатель на какой-то произвольный участок в куче, где уже непрерывно
лежат данные. И это очень плохая ситуация с точки зрения кэширования, потому что у вас данные
разбросаны по кэшу как попало, и будет требоваться дополнительное время на загрузку, и меньше
вероятность того, что все данные будут в кэше. Ситуация много улучшается, если вы, зная размер
матрицы, храните ее в виде одномерного массива каким-то одним большим непрерывным куском в памяти.
Да, ну и еще есть некоторое ограничение на использование кэша, как данные у вас изменяются
либо не изменяются. Вот в языках CAC++ есть ключевое слово const, которое что означает?
Оно не означает ровно ущербно для компилятора ничего, кроме того, что нужно дополнительно ваш
код проверить и отругаться, выдать ошибку. На самом деле, если вы пишете const, то это никакой
константости не гарантирует, и компилятор не имеет права делать никаких оптимизаций.
Есть еще ключевое слово под названием restrict в языке C. В плюсах такого ключевого слова нет,
там есть некоторые нестандартные для разных компиляторов аналоги. Вот это ключевое слово
означает, что вы гарантируете, что данные из вне не будут меняться, поэтому компилятор вправе
сгенерирует дополнительный код, чтобы предзагрузить что-то в кэш-память. Так вот, возвращаясь к правильной
реализации, когда мы сделаем программу для умножения матриц или вообще для работы с
двумерными массивами, но будем представлять массив в одномерном виде, даст нам достаточно заметное
улучшение в плане производительности. Теперь вопрос в том, насколько мы что-то сможем улучшить.
Вот две реализации. Во-первых, неоптимизированная реализация. Давайте перемножим две матрицы
размером 1000 на 1000, используя обычный вектор векторов, то есть двумерный массив. Да, современный
процесс это корой-5, просто умножает две матрицы. Казалось бы, миллионы инструкций в секунду. Тем не менее,
6,5 секунд понадобилось для того, чтобы всего лишь перемножить две матрицы 1000 на 1000.
Окей, давайте сделаем теперь все то же самое, но уже с использованием одномерного массива.
И точно также замерим время, сколько у нас займет это умножение. Так, тоже достаточно
долго, но уже четыре с половиной секунды. Разница в полтора раза. Просто за счет того,
что мы грамотно используем кэшпад. И вот таких мелочей в ваших программах может быть очень много,
они не только могут быть связаны с использованием кэширования, на самом деле слабых мест у вас может
быть сколько угодно много. И как вообще выяснять, а где у вас слабые места? Что такое валгренд? Вы,
наверное, уже знаете, вас, наверное, валгрендом уже много раз мучили. Когда вы отправляете какие-то
задачи в контест, они у вас не заходят, потому что какие-то проблемы с памятью, на которые вы не
обратили внимание, хотя локально все работало. Так вот, валгренд это инструмент, предназначенный
для виртуализации каких-то отдельных инструкций и для контролируемого выполнения, и может быть
использован не только для проверки проблем с памятью, но и для анализа ваших программ,
что именно там происходит. И вот один из инструментов, который входит в валгренд,
называется кэшгренд. Как им пользоваться? Давайте теперь найдем, а где у нас слабое место в нашей
неоптимизированной программе. Для этого нужно запустить валгренд, один из инструментов для
профилирования, в частности кэшгренд, ну и неоптимизированная версия программы, только я не
буду запускать на тысячи, иначе мы тут уснем. Поскольку валгренд выполняет программу с некоторой
долей интерпретации, то выполнение даже обычной программы в режиме поиска проблем с памятью это
уже сильное замедление. Профилировка работает еще медленнее. Запускаем на 500, дальше ждем. Если
у вас есть вопросы, вы можете пока их задавать. Валгренд в данном случае используется не как
санитазер, а как профилировщик. Есть еще гну профайлер, но он уже давно не развивается,
поэтому насколько он хорош, я вам подсказать не смогу. Так, ладно, достаточно долго от нас
работал валгренд, причем на меньших количествах данных, и мы получили какой-то файл. Запускался
процесс speed 8308, и после себя кэшгренд оставил файл, который называется kagegrnd.out.processid
того процесса, который у нас запускался. Используя инструмент под названием kagegrnd,
это если у вас линукс, инструмент с графическим интерфейсом, поэтому требуется настоящая система
с гуями. Есть аналог под Windows и под Mac, который называется qkagegrnd, то есть буквы k меняем на q,
позволяет анализировать дальше полученные файлы с отчетами. Так, cold not connected display,
логично, потому что это ssh. Если вы хотите запустить удаленно какую-то программу с
графическим интерфейсом, требуется опция ssh-x. В этом случае ssh будет
пробрасываться еще порт для x-сервера, да, но при этом еще если у вас Windows и Mac требуется
доставить штуку под названием x-сервер, но тем не менее эта штука будет работать. Так, ладно,
открываем файл с отчетом и смотрим где у нас там слабые места. Так, слабые места у нас,
так, смотрим по стеку вызовов и самое жесткое, это вот как раз 74 процента времени у нас занимает
операция вычисления суммы текущего элемента, то есть доступа к элементу массива, но казалось
быть для умножения матрицы достаточно очевидно. Если у вас достаточно большой проект, то слабое
место в коде у вас может быть не очень очевидным и кроме как с помощью профайлера вы никак это не
найдете. Так, ну и что у нас проходит? У нас 71 процент вероятности того, что в кэше 1 дейта мисс
на чтение, для инструкции все более-менее хорошо. То есть у нас получается проблема именно в доступе
к данным, доступ к кэшу, так, там все делось, ладно, файл перед или один кэш мисс, на доступ к, на запись у нас
слабое место получается опять же внутри дод. Так, слабое место 99 процентов времени, как раз вот
доступ к элементам массива. Что еще можно делать с помощью кэдж гринда и когринда? Кроме проблем,
связанных с производительностью в кэш памяти, у вас может быть просто не очень эффективный код,
который опять же вы сходу не всегда увидите. В этом случае вы немножко меняете команду для
запуска валгрен, меняете кэш на кол. Колгрент это еще один инструмент внутри валгренда,
который предназначен для профилировки программ в общем случае, а не применительно к кэшу. То
есть анализируется время выполнения отдельных инструкций, которые соответствуют отдельным
функциям. Работает немножко быстрее, чем кэдж гринд и позволяет опять же находить слабые места.
Что нужно знать при любом проектировании любых программ, при их написании. Вот до того,
как вы реально запустите код под профайлером, никогда не вздумайте делать оптимизацию. Потому
что, во-первых, если вы как-то вручную оптимизируете код, делаете какие-то неочевидные вещи, которые
вроде как должны что-то улучшить, во-первых, вы делаете работу за компилятор. И может так
получиться, что тот же самый код, написанный намного проще, намного короче, превратится в то
же самое, но при этом вы только зря сделаете ваш код более сложным, сделаете менее читабельным.
Традиционное правило вообще любого программиста – преждевременная оптимизация – это зло.
Так, а этого зайца зовут Бо. Если вы увидите, значит лекция закончилась.
