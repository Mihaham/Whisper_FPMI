Сегодня у нас, соответственно, седьмая лекция, восьмая по счету, в которой мы поговорим о том,
как вообще архитектура процессора, архитектура платформы, под которую вы
разрабатываете, может повлиять на архитектуру операционной системы.
То есть типичное классическое представление, грубо говоря. У разработчика пакет поддержки
аппаратуры, также называется TSP, сводится к тому, что есть некоторый процессор, нужно, соответственно,
узнать, как у него работает сериал порт, то есть некоторое устройство, последовательный порт,
он же UART, он же, соответственно, COM порт, в зависимости от конкретной железки. После этого понять,
как работает memory management unit, настроить трансляцию из виртуальных адресов в физические,
соответственно, завести аллокатор памяти и плюс-минус завести таймеры, после этого операционная
система уже будет в каком-то виде работать. После этого там заводятся вещи типа доступ к периферийным
устройствам, то есть появляются какие-то там шины фактически, ядра и так далее, то есть там
расширяется поддержка контроллера прерываний, то есть появляются там всякие поддержки многоядерности,
прерывания периферийных устройств, возможно, power management, но вот в целом такой базовый взгляд
на архитектуру операционной системы, он сохраняется. К сожалению, это с одной стороны такой хороший путь,
и все примерно там ему следуют, но не редки ситуации, когда какие-то особенности вот процессора,
там архитектуры, там целевой платформы, они достаточно сильно влияют на устройство операционной
системы и заставляют вас это устройство операционной системы переделывать. Вот, соответственно,
сегодня мы поговорим о современных архитектурах процессоров с точки зрения разработчика
операционной системы и конкретно немножко сфокусируемся на таких вещах, как атаки по
побочным или они же сторонние, собственно, каналы. Для того, чтобы понять, вот как изменение в
процессоре может привести к тому, что нам придется переделывать достаточно значимые
куски операционной системы, от этого, в общем-то, никак не скрыться. Кроме этого, мы также поговорим
про конвейеризацию, ну, я, по крайней мере, напомню про кэширование, о том, что не любое обращение
к оперативной памяти, оно имеет одинаковую цену, и каким образом, вообще, достигаются
достаточная производительность в современных учлительных системах. Почему это хорошо,
почему это иногда бывает больно. Итак, ну, все вы знаете классическое сопоставление архитектур
набора команд у процессоров, то есть, есть процессоры, которые умеют в риск, то есть,
reduced instruction set, есть, соответственно, процессоры, которые умеют в циск, соответственно,
complex instruction set. Яркие примеры, как раз перечисленные в скобочках, кто-нибудь слышал про такую
архитектуру, которая называется IRC из присутствующих. Так, но, к счастью, у вас архитектура это плюс-минус
весь езде. То есть, например, на том же процессоре Intel у вас есть Power Management Controller, который работает
как раз под архитектурой Argonaut Risk Course или IRC. То есть, это одна из риск архитектур, которая
применяется в встраиваемых устройствах, встраиваемых технике, в основном в небольших
устройствах. Бывает там либо 16-битная, либо 300-битная. Соответственно, ARM, ну, как минимум, соответственно,
у вас во всех телефонах. MIPS, ну, в основном всякие станки, CPU, различные управляющие системы,
в том числе промышленные, оборонные промышленности. Power плотно занял две ниши. Соответственно, первая
ниша – это суперкомпьютерные системы производства IBM. IBM Power 8, IBM Power 9. Вторая ниша – это
automotive ниша, то есть всякая авианика, то есть большие там авиалайнеры, Airbus 320 какой-нибудь,
всякие там машины, автомобили. Кроме этого, соответственно, у всех на слуху есть архитектура
Risk5 и, в общем-то, некоторые другие. Вот это наиболее яркие представители Reduced Instruction Set в случае с
CISC. Ну, наверное, наиболее яркий представитель – это x86, то есть, в общем-то, те машины, которые мы
сейчас используем в повседневной жизни. Ну и, в принципе, там некоторые, скажем, относительно
похожие на них, типа там вот Zilog Z80, но уже они там потихоньку отмирают. Чем характеризуются CISC и RISC SA?
То есть, ну, CISC исторически появились раньше, и x86, ну, наверное, такой, один из немногих
представителей CISC архитектур, который есть и по сей день, прекрасно применяется, прекрасно
используется. Соответственно, у CISC архитектур большое количество инструкций, ну, то есть,
большое количество оцепленных команд, которые предназначены там в первую очередь для того,
чтобы программисту было удобно писать на ассемблере, когда же, соответственно,
там в RISC архитектурах у вас, наоборот, набор, соответственно, инструкций достаточно небольшой,
и когда вы на них пишете, вы вынуждены фактически делить свои операции там на несколько под
операцией. Ну, там простейший пример, там, если выполнять там какое-нибудь умножение на
CISC архитектуре, то вы можете написать там одну инструкцию типа там mall, дальше участок памяти
и там какая-нибудь константа в качестве двух оперантов. В случае же, там, с RISC архитектурой,
то у вас, соответственно, получится, например, там, четыре инструкции. Первые две инструкции будут
загружать в ваши регистры, соответственно, там сначала участок памяти, который вы хотите
умножить, потом, соответственно, вот эту вот самую константу, после этого будет инструкция номер
три, которая выполнит умножение, и еще одна инструкция, чтобы записать результат. Как,
в принципе, понятно, что у RISC архитектур достаточно сложный, соответственно, должен быть
компилятор, в свою очередь компилятор для CISC архитектур может быть написать проще. То есть,
в целом, это было так, там, условно, 50 лет назад, сейчас компиляторы сложные для тех и других,
потому что планирование инструкций для CISC архитектур, оно все равно очень сильно непростое. Вот,
и разница, там, между RISC и CISC архитектурами, она потихоньку-потихоньку становится все меньше
и меньше. Например, вот один из классических подходов, который приводит в пример, как
различия между там CISC и RISC, что, соответственно, в CISC существует микрокод. То есть, некоторая
программа, которая зашивается в процессор, и, фактически, на одной из стадий конвейера у
процессора возникает деление, то есть декодирование, некоторые большой инструкции, деление ее на
несколько микроопераций, которые, собственно, этот микрокод и исполняет. Соответственно, в случае
с RISC архитектуром никакого микрокода нет, но, там, если посмотреть на ARM, то, хотя у него там нет
никакого микрокода, то есть, в ARM, там, постоянно добавляют больше и больше команд, и, в общем-то,
это само устройство, то есть, управляющего устройства, устройство-управляющего устройства,
я не знаю, афтология, оно постоянно растет по сложности, и, в целом, там, не то чтобы сильно уступает
сложности, условно, у некоторых микрокодных операций, там, в том же x86. То есть, мы все знаем,
что сейчас нормальным для любого, там, процессора, в том числе мобильного, является, там, содержать
инструкции типа, там, векторных операций, всякие, там, AVX в том же Intel или, там, Neon в том же ARM,
при этом оно не очень чтобы легко так вот соотносится к классическому пониманию, там, RISC
и ЦИСК-архитектур. Соответственно, у RISC-архитектур размер инструкций одинаковый, то есть,
практически всегда, там, у вас размер фиксирован, ну, обычно, например, там, 4 байта, хотя есть,
опять же, некоторые исключения из этого правила, например, в 32-битном арме у вас есть, там, два
режима ARM и FAM. Вот, в режиме FAM у вас, там, были, например, двухбайтовые инструкции. То есть,
они были одинаковые, но для, там, какого-то конкретного режима. Вот. Но за счет этого, в принципе,
конвейер может быть несколько проще, соответственно, писать, потому что упрощается, там, процесс,
собственно, instruction fetch, то есть, упрощается процесс извлечения инструкций. Вот. А в случае
с ЦИСК-архитектурами у вас размер инструкций переменный, и за счет этого декодер может быть
очень сильно сложным, и в том числе, там, этот декодер может быть реализован, там, во многом,
на уровне микрокода. Простейший пример, который разбирали, там, в начале года, как можно, там,
обращаться из 16-битного режима, там, Intel к 32-битным регистрам, там, 80, 386. Ну, вот, добавили
специальный префикс для инструкций, соответственно, там, более новый процессор видит префикс и
начинает обращаться к более, соответственно, там, широким регистрам. Вот. Соответственно,
это все так, но, если, например, посмотреть, там, современные x86, то он устроен так, что,
грубо говоря, те инструкции, на которых вы пишете, то есть, assembler x86, он быстро перекодируется
в некоторый набор микроопераций, в том числе, с использованием микрокода, и конвейер работает
уже на уровне этих микроопераций. При этом, эти сами микрооперации, они уже представляют собой
некоторый риск архитектуры. Так что, здесь мы видим, что и циск, и риск, они, в общем-то,
продолжают двигаться, как бы, навстречу друг к другу, и берут, в общем-то, все то хорошее,
что, соответственно, есть у особенности построения этих архитектур. Особняком, то есть, скажем так,
отдельно от вот этих вот двух, есть еще несколько направлений. Одно из этих направлений это, там,
Very Long Instruction Word. Ну, наверное, про E2K все слышали. Кто слышал про E2K?
Ну, кто-то наверняка слышал, я слышал. Ну, соответственно, про тот же самый архитектур
про Elbrus 2000 или он же E2K, в общем-то, все плюс-минус слышали. То есть, слышали про Intel
Ethereum, который, к сожалению, уже умер. Ну, может, не совсем, к сожалению, но это факт. Но это,
в принципе, не единственные примеры архитектур, логика которых построится на том, что есть
некоторый явный параллелизм, когда компилятор перекладывает задачу распараллеливания инструкций
на себя. Вместо процессора как-то происходит фриск и циск. И, соответственно, явно упаковывает
инструкции так, чтобы они исполнялись наиболее быстро. Еще одним примером такой архитектуры,
например, является hexagon, ну, квалкомовский. И он прекрасно применяется в всяких обработках
сигнала, то есть, некоторых фактически DSP. И у него вот как раз тоже very long
instruction work архитектура. Если это, соответственно, процессор общего назначения, то в Ливе вполне
может быть конлеер, вполне может быть, в общем-то, даже и микрокод. Но, грубо говоря, так как
процессоров на такой архитектуре достаточно немного, сейчас осталось полтора, скажем так,
то вводить какие-то общие критерии, кроме именно вот явного параллелизма, достаточно сложно.
Соответственно, в процессорах для обработки сигнала, ну, таких
как DSP, можно встретить что-то совсем экзотическое. То есть, например, когда у вас команды просто
подаются одним, соответственно, блоком на вход процессора и при этом нет классического,
например, instruction pointer. То есть, вы просто подаете данные, через какой-то момент на выходе
забираете значение. И, собственно, тому подобные вещи, но там в целом это очень специализированные
архитектуры и они предназначены в первую очередь для того, чтобы код, который под них, соответственно,
пишется, он писался, грубо говоря, там один раз для какой-то специализированной задачи и после
этого менялся достаточно нерегулярно. Потому что, ну, написать эффективный кодбюлятор для таких
архитектур в наши дни, ну, в целом можно, но это очень недревиальная задача, которая плохо ложится
на современные языки программирования, такие как, ну, в общем-то, тот же язык C. Соответственно,
даже вот архитектура Very Long Instruction Word, даже ее, в общем-то, очень тяжело адаптировать под
современные компиляторы. Например, мы все знаем, что для того же E2K до сих пор там нет открытой
реализации в каком-нибудь GCC или в кланге, хотя набор команд он был уже открыт достаточно
продолжительный период, просто не работает достаточно эффективно. Соответственно, идя дальше,
я все-таки напомню те вещи, которые вы уже знаете, ну, про конвейеры, я думаю, что вам точно должны
были рассказывать. Но, на всякий случай, кто не знает, что такое конвейер-процессора? Есть такие,
или можно так, кто знает, что такое конвейер-процессора? Ну, в общих чертах, скорее всего, все конкретикам,
конкретные процессоры, мало кто. Ну, да, соответственно, в общих чертах, действительно,
там, примерно все представляют, что такое конвейер, то есть конвейер — это такой некоторый метод
обеспечения, там, ускорения вычислений, построенный на том, что инструкции, в общем-то,
можно выполнять параллельно, если достаточно грамотно спроектировать архитектуру процессора.
Но вот конвейер обычно характеризуется двумя чиселками, и обычно это в смысле в литературе,
в реальности все гораздо сложнее, но, тем не менее, первая чиселка — это, соответственно,
глубина или количество стадий. Соответственно, грубо говоря, у нас есть некоторая инструкция,
мы ее можем поделить на несколько под инструкцией. Вот на экране, соответственно,
каждая инструкция поделена на пять стадий. То есть instruction fetch, то есть, соответственно,
извлечь инструкцию из оперативной памяти или, там, из кэша, неважно, откуда. Потом instruction
decode, то есть декодировать инструкцию и понять, что это за инструкция. После этого execute,
выполнить эту инструкцию. Memory access, то есть обеспечить доступ к памяти, в риск, соответственно,
обеспечить доступ к памяти можно либо на ввод, либо на вывод. Соответственно, у вас на четвертом
шаге, если у вас инструкция load, то, соответственно, происходит извлечение данных с памяти. Если,
соответственно, store, то, соответственно, запись в них. И writeback, соответственно, запись обновления
содержимого регистров по результатам выполнения этой инструкции, флагов или выходных регистров
и так далее. Считалось, что для риска, по крайней мере, классических архитектур, количество стадий
должно быть константным, то есть это некоторое число. В современных процессорах это не так,
то есть у вас для разных инструкций вполне нормально, что существует разное количество стадий
конвейера, но в любом случае вот понятие глубины, оно сохраняется. Соответственно, вторая чиселка
это ширина. Соответственно, ширина это то, фактически, сколько параллельно задач вы можете
выполнять на стадии. Вот на, соответственно, экране, то есть на слайде, как раз пять стадий,
то есть глубина и, собственно, одна, то есть ширина равна единице. Понятно, как изменится
эта картинка, чтобы ширина, собственно, равнялась двум. Или не очень понятно?
Ну, смотрите, сдвиньте вот строчку, которая два, на шаг влево, после этого сдвиньте строчку
три на шаг влево, сдвиньте строчку четыре на два шага влево. У вас, соответственно, на первом такте
будут выполняться, соответственно, инструкцион фетчи первой и второй инструкции, соответственно,
на втором такте у вас будет выполняться инструкцион декод первой и второй инструкции и
инструкцион фетч третьей и четвертой инструкции, ну и так далее. Так, понятно? Ну, соответственно,
идея в том, что конвейер, в общем-то, тоже можно параллелить и при достаточно, собственно,
грамотном построении архитектуры можно не просто увеличить количество стадий конвейера,
как раньше, например, тот же какой-нибудь пентиум, у него был очень глубокий конвейер,
например, в свое время, то есть старались идти в глубину, то сейчас там современные
конвейеры, они, в общем-то, очень даже неплохо идут в ширь и, например, когда у вас говорят,
что у того же нового Macbook на M1 у него очень такой широкий конвейер или там широкий
pipeline, вот, собственно, подразумевает, что он может обрабатывать несколько инструкций в,
собственно, несколько юнитов на одной стадии, достаточно параллельно. Понятно, что устройство
процессора таким образом, то есть его конвейеризация, она дается некоторой ценой,
соответственно, возникают вещи, которые называются hazard или конфликты, и, в общем-то,
конфликты, они бывают разного рода, то есть классический там пример конфликтов, их еще также
называют зависимости по данным, это, собственно, несколько операций, следующих друг за другом,
ну, там, read-after-read, read-after-write, write-after-read и, соответственно, write-after-write.
Каждый конфликт имеет, скажем так, свою степень влияния на архитектуру процессора,
ну, можете привести там пример конфликта, например, read-after-read.
Ну, простое же. Может, мы пытаемся два раза из порта что-нибудь почитать?
Да, вот последнее, это на самом деле ближе, то есть, смотрите, вот вы читаете, соответственно,
из памяти, соответственно, потом еще раз читаете из памяти, при этом совершенно не значит,
что память между этими операциями чтения не изменилась, то есть, возможно, она с точки
зрения вас, как, ну, грубо говоря, процессорного ядра не изменилась, то есть, у вас шел пайплайн,
у вас все как бы хорошо, все нормально, но при этом у вас, например, есть другое ядро,
соответственно, в рамках другого ядра произошло изменение там в этом участке памяти,
вам нужно поддерживать конкретность кэшей с этим ядром, соответственно, у вас, соответственно,
есть там какое-нибудь MMIO, соответственно, вы прочитали память, вы снова хотите там, грубо
говоря, прочитать память, но при этом это не означает, что какое-нибудь периферийное устройство
в этот момент эту память не обновило, или у вас, например, произошла какая-нибудь DMA запись
с устройства в оперативной памяти. Ну, это классический пример read-after-read. Он несколько
отличается от других, соответственно, видов конфликтов, потому что, скажем так, рассматривает не
только там конвейер в рамках вот одного ядра процессора, но, соответственно, заставляет думать
о том, что вокруг процессора одного конкретного ядра еще что-то есть. Самый, соответственно,
наверное, болезненный для разработчиков процессора это, соответственно, read-after-write,
то есть тогда, когда у вас происходит некоторая операция записи, и после этого нужно произвести
чтение. Соответственно, пока эта операция записи не завершится, вы, соответственно, прочитать
данные не сможете. Соответственно, у вас возникают так называемые pipeline stalling, то есть конвейер
ждет, фактически и простаивает, пока, собственно, у вас эти данные не появятся, и их нельзя будет
прочитать. Соответственно, в некоторых процессорах pipeline stalling либо не знают,
либо предпочитают игнорировать по причине усложнения устройства конвейера, и тогда возникают
неприятные ситуации, когда, собственно, в ваших процессорах считываются совершенно неправильные
данные. Если вы там напишете сначала команду записи, а потом чтение, и потом внезапно в
компиляторе появляются всякие команды типа mfix, и дальше какая-нибудь чиселка, которая говорит,
что данная команда чинит, соответственно, генерацию команд под конкретный процессор вот такой-то-такой-то,
потому что этот процессор не может pipeline stalling. Вот если почитаете там документацию на GCC,
то увидите много похожего. Точно также существует write after read, только в данном случае, собственно,
ситуация обратная, то есть если вы будете, соответственно, записывать память, и у вас
конвейер достаточно глубокий, то может возникнуть ситуация, что вы перезапишете память, при этом
read ее еще не успеет прочитать. И write after write, который также еще называется проблемой
переименования или, соответственно, register name conflict, то есть конфликтом имен регистров, то есть
когда, собственно, вы записываете какое-то значение, но при этом вы его записываете в один и тот же
регистр, но в разное время, а между этими операциями есть какие-то еще операции. И вот эти промежуточные
операции должны видеть именно тот регистр или тот участок памяти, который был после предыдущей
операции, но до следующей. Классический пример решения данной проблемы — это использовать
переименование регистров, то есть когда у вас конфликтующие, собственно, регистры имеют какие-то
на самом деле другие имена, то есть внутренние, и тем самым вы избегаете вот обращения к не тем
регистрам или не тем участкам памяти. С конфликтами по данным, я думаю, все понятно. Кроме конфликтов
по данным есть еще структурные конфликты, то есть это вот как раз про то, что мы ломимся в один и тот же
порт, но ломиться, соответственно, можно только в тот порт, который свободен, соответственно. Один
порт вам позволяет обрабатывать группу 2.1 до какой-то там операции, а не несколько сразу. Порт и
unit — это синонимы, просто порт это используется в терминологии x86 для тех, кто немножко
запутался. И, соответственно, pipeline и conveyor — это тоже самое, это тоже синонимы, просто русский,
соответственно, английский перевод. Классический пример свободного винта — вот у вас есть умножитель,
например, аэфематически-логически скалярный умножитель, то есть недавно находящийся в валу,
или умножитель floating-point-units, находящийся в GPU. У вас, соответственно, может быть достаточно
широкий conveyor, но при этом в рамках этого conveyorа, например, умножитель всего один.
Если у вас там одна операция — это, допустим, чтение, а вторая операция — это, соответственно,
умножение, то у вас не происходит структурного конфликта. А если у вас подряд оказываются две
операции умножения, то, соответственно, у вас возникает структурный конфликт,
потому что вы не можете параллельно умножать, у вас всего один умножитель. Ну вот, соответственно,
этот пример структурного конфликта. Кроме этого, есть еще конфликты управления. Соответственно,
если у вас нет информации о том, какую следующую инструкцию выполнять, то чаще всего вы будете,
точнее не вы, а ваш процессор будет заниматься в угадайку. То есть он будет спекулятивно пытаться
выполнить ту или иную вещь. И если он, соответственно, не угадает, такое не часто,
но в целом происходит, то возникнет ситуация, когда процессор выполнил достаточно большое
количество инструкций вперед, но он их выполнил совершенно не из того места, ему, соответственно,
нужно откатываться назад и выполнять уже другие инструкции, про которые он не угадал. Это,
соответственно, конфликт управления. Здесь стоит сказать, что вам, как разработчиком операционных
систем, про это нужно знать, в первую очередь, как то, что эти вещи существуют. В 99 случаях вам
не придется писать код так, чтобы он избегал максимального количества конфликтов,
программировать наиболее эффективное использование пайплайна и так далее. Не придется, в первую очередь,
потому что, собственно, компиляторы это делают сейчас в достаточной мере эффективности. И в
ситуации, где вы даже можете выиграть несколько тактов, переупорядочек, например, инструкций,
у вас, скорее всего, не возникнут. Они возникают в основном при каких-то арифметических вычислениях,
и не нужно заниматься, скажем так, преждевременной оптимизацией до того, как вы все запрофилируете и
действительно не найдете, что нужно оптимизировать там. При этом это не означает, что особенностью
устройства конвейера они на вас никак не влияют. Вот, когда мы, соответственно, доберемся сегодня
до спекулятивных атак, там как раз конвейер может играть достаточно значимую роль, и за счет,
собственно, обеспечения его сброса вы можете, скажем так, починить, например, безопасность
операционной системы при условии, что в процессоре где-то не доглядели ту или
иную особенность. Но об этом буквально на следующих слайдах. Соответственно,
что вообще означает для вас наличие конвейера? Наличие конвейера, оно, как и другие инструменты,
предназначено для оптимизации, соответственно, производительности вычислений, и необходимость
она, в общем-то, есть. То есть, даже когда вы обращаетесь к просто оперативной памяти,
мы помним, что, например, риск процессора, они постоянно обращаются к оперативной памяти,
потому что у них много load, store команд за счет их простоты, а циск же, при этом,
могут делать меньше обращений к оперативной памяти просто за счет более сложных команд
у себя внутри. Соответственно, каждое вот такое обращение, оно у вас займет несколько
наносекунд. Ну вот, примерные значения, соответственно, для разных уровней кэша на x86,
они приведены на слайде, то есть, ну, например, там, где-то меньше полутора наносекунд это l1,
там, менее там 5 это l2, соответственно, менее там 20 это l3. Здесь приведены значения для
comet lake, для rocket lake значения чуть хуже, соответственно, текущее поколение, а для
alder lake еще пока нет хороших результатов, потому что память новая, соответственно,
новой памяти ни у кого нет и, соответственно, кэши, собственно, процессоры тоже еще не вышли,
соответственно, нет данных про кэши тоже. Соответственно, оперативная память, но это самое,
но это где-то 30-100 наносекунд, причем все помнят про вещи типа CL, тайминги и вот это все. То есть,
в целом, от роста объемов оперативной памяти у вас будут расти тайминги, потому что их нужно
синхронизировать, соответственно, ту оперативную память, которая у вас есть, поэтому рассчитывайте,
что там, ну, условно, там для набора 16 гигабайт у вас будет там 40 наносекунд скорее, а там 64
гигабайта, ну, скорее, ближе к 80. И это так хорошая оперативная память, на медленной,
то есть на мейнстримской оперативной памяти у вас будут гораздо худшие результаты. Если ни кэшей,
ни памяти вам не хватает, то вам светит своп или вы, соответственно, загружаете какие-то кэшированные
данные с носителей или загружаете программу. Это счет уже на микросекунды и какой-нибудь там
NVMe SSD подключенной к CIE 4.0 шине, вам даст, соответственно, десятки микросекунд в задержках.
В свою очередь там жесткий диск, это уже миллисекунды и здесь можно рассчитывать на
десятки, соответственно, миллисекунд. Ну, 10, там, 12 это очень хороший HDD и вам, скажем так,
сильно повезло. Вот. В свою очередь никто не отменяет задержки к обращения к RAM еще
из-за использования виртуальных адресов, но в целом там это компенсируется отдельным кэшем,
под названием TLB, про который мы в прошлый раз достаточно много говорили. В случае там с
отдельными архитектурами можно даже узнать, как именно там этот TLB устроен. В случае с Intel
придется вполне возможно, что просто профайлить различными способами, пытаясь, соответственно,
вычислить это алгоритмически. Говоря об Intel и вообще о современных конвейерах, то нужно сказать,
что устройство процессоров достаточно сложное и кроме конвейеров у вас будет вообще множество
юнитов в рамках микроархитектуры, которые выполняют свои операции. Можно на это смотреть,
как теоретически, что это все какая-то часть конвейера, но, например, тоже переименовывание
регистров, но это отдельный юнит, соответственно, Out of Order исполнение тоже отдельный юнит. И вот это
все, в принципе, вы легко встретите при разработке операционных систем и вам придется
считать на них документацию, просто хотя бы из-за того, что, например, вы записали какие-то
данные в оперативную память. Например, вы записали программу, то есть новый процесс,
вы его создаете, размещаете его в оперативной памяти. Если у вас там Nix86, то вам придется сбросить
кэши процессора в области этого участка памяти. Вам там придется сбросить, соответственно,
branch prediction, то есть спекулятивное выполнение инструкций перед переходом на этот участок
памяти, потому что иначе процессор может думать, что там еще находятся какие-то старые
данные или старая программа, она у вас уже изменилась. И вот все вот это вот у вас очень сильно
вылезает при программировании на реальном железе в сравнении с эмуляторами, где такие вещи как кэши
или спекулятивное выполнение и так далее. Их достаточно сложно реализовать эффективно,
и в 99 эмуляторах их просто нет. То есть эмуляторы бывают либо на уровне ISA, то есть то, что у нас
есть QEMO, либо на уровне микроархитектуры. Микроархитектурные эмуляторы медленнее на
несколько порядков и, соответственно, использовать их там для запуска полноценных операционных
систем для отладки не всегда рационально. Так, соответственно, говоря о интеле, то есть как
вообще выглядит конвейер в достаточно современном процессоре. То есть мы видели на начальных слайдах
пример конвейера, который вы видите в литературе. В свою очередь там в современном процессоре
сверху это не Halium, а соответственно там внизу это Silvermont. Silvermont это атомы,
Nehalium это, по-моему, первое поколение Core. Нет, по-моему, даже до Core это было.
Второе поколение Core это Sandy Bridge. Наверное, все-таки Nehalium это первое поколение Core.
Вы здесь видите, что, например, Instruction Fetch в интеле имеет, например, там три порта.
Соответственно, там два порта могут использоваться для произвольных инструкций. Соответственно,
там третий порт, например, для специализированных инструкций, таких как SSE, AVX и подобные вещи.
Точно так же там три параллельных декодера. То есть есть операции расположения инструкций
на дальнейших вычислительных юнитах. Есть работа с кэшами, обработка исключений.
Появляется понимание Retire и Commit. Retire это завершить выполнение всех инструкций.
Завершить выполнение конкретной инструкции на конвейере. В этот момент процессор перестает
ее в конвейере держать, он ее может выкинуть. При этом до Commit эта инструкция все равно не
считается выполненной, потому что кроме соответственно отработки самого конвейера еще должны произойти
какие-нибудь внешние устройства. Например, если в инструкции явно сказано, что она должна записать
в оперативную память, то есть синхронизировать не только кэши, но и добраться до оперативной
памяти, то произойдет какая-то дополнительная задержка на обращение к каким-то сторонним
устройствам. Кому хочется узнать побольше о современных конвейерах, процессорах,
ну вот можно сходить по ссылке, почитать. Там достаточно наглядно расписано, как с этим
работать. Если вы хотите программировать какие-то математические алгоритмы,
то вполне возможно, что вы к этому придете. Нас же в свою очередь интересует немножко другой аспект.
Соответственно, аспект того, как все вот эти вот особенности могут привести к неприятным
последствиям, ну скорее к последствиям, когда вполне себе корректно работающая система, то есть
без каких-то явных уязвимостей в алгоритме, то есть никаких переполнений буфера там нет,
никаких ошибок в POA нет. Соответственно, алгоритм работает правильно, реализован,
дедуктивно его верифицировали и доказали математически, что он корректен,
что он завершается и так далее. Но при этом из особенностей работы вашего процессора,
например, возникают какие-то внутренние свойства системы, которые могут быть извлечены и в
дальнейшем, соответственно, использованы для атакующего, то есть для извлечения какой-то
информации или, например, для внесения какой-то новой информации, соответственно, с целью
компрометации работы вашей целевой системы. Кто-нибудь может привести какой-нибудь пример
атаки по сторонним каналам из реальной жизни? Есть идеи, что это может быть?
Из реальной не очень, но я помню про ISLR, там же тоже была какая-то штука, что измеряли
задержки конвейера и через это как раз искались адреса. Да, это, собственно, было. Я сейчас не
воспроизведу, какая конкретная там атака была, но, в принципе, с ISLR-ом, да, там были особенности.
Нет, РОП это вполне прямая атака. Давайте лучше говорить. Я сталкивался с тем, что криптографию
на этих embedded устройствах расковыривались за счет энергопотребления, анализа энергопотребления.
Да, вот это уже ближе, соответственно, когда там, грубо говоря, процессор выполняет какую-то,
соответственно, ресурсноемку и операцию, то он, соответственно, потребляет больше энергии,
потому что, как и вам, собственно, людям, чтобы посчитать какую-нибудь одну чиселку, умножить
другую, вам нужно головой подумать. Точно так же, соответственно, процессор должен думать,
соответственно, когда он думает, он кушает больше электричества. И вот от того, что, соответственно,
процессор кушает больше электричества, можно, соответственно, сделать некоторые косвенные выводы,
что, например, банально на процессоре происходит какое-то вычисление. В некоторых случаях эти вещи
можно сделать более подробно. Но тем не менее, то есть в реальной жизни все гораздо проще,
но, соответственно, на слайде есть три фотографии. Первая фотография, она, возможно, не столь
удачная, потому что не совсем отражает суть того, что здесь происходит. Но когда, например, медвежатник
профессиональный ломает замок, например, слушая, соответственно, то, как кликает механизм вот этого
самого замка в процессе, собственно, работы его там отмычкой или, например, он просто крутит,
если это какой-нибудь сейф с крутящимся замком, он просто крутит эту ручку и слушает, соответственно,
звуки замка, находящегося в этом сейфе. Он фактически выявляет некоторые промежуточные
состояния, то есть между известными нам основными, то есть прямым каналом открыт сейф или закрыт сейф.
Появляется некоторый промежуточный канал связи, то есть вот эти вот самые клики,
соответственно, которые нам позволяют узнать, собственно, насколько сейчас этот замок открыт.
То есть вы там слышите, о, соответственно, там клик есть, соответственно, на первый,
клик есть на второй, клик есть на третий, о, клик на четвертый, все, ну замок открыт.
Например. На второй картинке, соответственно, это нашумевший, там, отличный подарок, соответственно,
наших доблестных спецслужб в посольство США, то есть когда красивый вот такой вот деревянный герб
был подарен послу и, соответственно, поставлен прямо в их комнате, соответственно, внутри герба
находился пассивный резонатор, на который, соответственно, подавали там мощный высокочастотный импульс,
но физики у нас здесь есть, они лучше меня объяснят, как это работает, но, по существу,
оно работало как такой хороший микрофон, позволявший, соответственно, нам прослушивать там
в 50-е года вот ровно все, что произносилось в комнате с этой красивой деревянной дощечкой.
Вот. На третьей картинке нарисован полиграф, соответственно, наше тело это, в общем-то,
такой хороший, прекрасный, соответственно, источник некоторых побочных, соответственно,
изменений, то есть когда мы о чем-то говорим, то есть наши там мимика, жесты, там температура,
не знаю, дыхание, наш взгляд, все вот это вот оно каким-то образом реагирует на наше, собственно,
физиологическое там состояние, и ну вот полиграф это один из таких инструментов, который позволяет
в общем-то фиксировать это изменение в физиологическом состоянии человека, когда мы там с ним
разговариваем. На самом деле, больше он ничего не делает, и все вот эти вот там попытки сказать,
что вот там можно, наблюдая за человеком, найти какие-то закономерности. Ну да, с одной стороны,
это правда, с другой стороны, там во многих случаях вероятность такова, что как монетку бросить,
примерно с такой же вероятности. Но тем не менее, там какие-то, собственно, вот такие, можно сказать,
атаки по сторонним каналам в жизни, они имеют уже довольно такую многовековую историю, эффективно
применяются, и вот в общем-то как вот в быту, ну не знаю, там ключи забыли от дома вам, медвежатник
помог. Так и в какой-то там профессиональной деятельности, когда вы там взяли соседу дощечку,
подарили, она его слушать будет. Тем не менее, кроме реальной жизни, эти же техники нашли свой,
собственно, путь и там в программно-аппаратных комплексах, ну вот в случае с, там скажем,
программным обеспечением, там начало формально, то есть по факту существовало и раньше, но формально,
официально, так и по сторонним каналам на программное обеспечение существует там с 96-го года.
Был такой гражданин Пол Кочер, который, собственно, использовал время, там, шифровать
некоторого сообщения для того, чтобы раскрыть информацию, вот насколько длинный ключ,
допустим, RSA, он там несколько шифров использовал, использовался вот для шифрования этого письма.
Ну понятно, что чем больше, соответственно, ключ, тем дольше происходило шифрование, потому что
реализация была в тот момент наивная, и она не ждала там какое-то время для того, чтобы снизить
вот эту вот возможность раскрыть информацию. Вот, соответственно, с этой даты и началась,
соответственно, скажем так, охота на различные свободные каналы в программном обеспечении,
и если там вот в том же Нистовском документе вы увидите две картинки, вот одна из которых есть
сейчас, это традиционная там модель криптосистемы, то есть есть некоторое там сообщение, которое Алиса
хочет передать Бобу, соответственно, там Алиса, соответственно, его там каким-то образом шифрует,
допустим, у нее есть ключ свой, соответственно, там M это сообщение, E это, соответственно,
encrypt, D это decrypt, соответственно, Алиса и Боб это отправитель и получатель, Evo, соответственно,
это некоторый там eavesdropper, то есть некоторая подслушивающая сторона, которая пытается
это сообщение перехватить. Все замечательно, в традиционной модели криптосистемы, если у нас
стойкий алгоритм шифрования, если у нас там неизвестны ключи, то мы можем спокойно передать
там сообщение, там и Evo ничего не сможет узнать из этого сообщения, но просто даже если мы
посмотрим на эту схему, то мы сразу видим, что в этой схеме, например, там уже не скрывается сам
факт ведения переписки, то есть то, что мы передали, соответственно, Evo какое-то сообщение означает
в том, что у нас это сообщение было, там будем мы там достаточно регулярно передавать, соответственно,
там не Evo, прошу прощения, Бобу, будем достаточно регулярно передавать сообщение там между Алисой
и Бобой, выяснится, что мы о чем-то замышляем, то есть мы замышляем что-то нехорошее, значит,
соответственно, вызываем больше подозрений, поэтому классическая схема там, которая сейчас там,
грубо говоря, рассматривается, она выглядит похожим вот примерно на эту, то есть нужно
смотреть, а какой, собственно, там такие вещи, как там температура, свет, электромагнитное излучение,
звук, у вас со связью очень плохо, я вас практически не слышу, я не знаю,
я, к сожалению, не слышу, там был какой-то вопрос, если, а, понял, окей, ну, на самом деле,
если там какие-то сложности микрофона вообще бывают, то можно, в принципе, и в чате тоже
писать вопросы, то есть можно произносить так и, собственно, писать в чате, то есть у нас ничего в этом
плане не изменилось, единственно, появился новый канал, и он даже не побочный, а вполне себе прямой,
вот, соответственно, современные модели криптосистемы, вот у вас появляются такие дополнительные
факторы, дополнительные каналы, как, соответственно, звук, свет, радиация, потребление
электричества, время выполнения, основные, соответственно, выводы, дополнительные выводы,
в конце концов сообщение об ошибке, то есть то, что мы там неправильно расшифровали, какое там
сообщение об ошибке будет, будет у вас, например, неправильная длина ключа, вот мы, соответственно,
раскрыли информацию о том, что ключ должен быть другого размера и так далее, ну, то есть,
как классический пример, то есть, когда раньше, там, в время Второй мировой войны еще, там, я уже не
помню, по-моему, в Германии, что ли, да, использовалась вот эта несчастная инигма, там, немцы очень радостно
начинали свой канал связи с того, что передавали погоду, и в свое время, там, Алан Тьюринг,
который занимался криптоанализом этой инигмы, вот как раз увидел некоторую закономерность в том,
что, соответственно, каждый, там, регулярный, там, канал связи, он начинается, там, с схожих,
скажем так, сообщений, и вот это знание позволило произвести, собственно, частотный анализ криптоалгорифма,
использованного в той же инигме. Другой пример, когда военные, там, делали какой-то аппаратный
механизм шифрования и выяснили, что, ну, там, при шифровании, там, этого самого сообщения происходит
достаточно характерный шум, вот как раз то, что говорилось в одном из ответов на вопрос, и этот
характерный шум позволял, собственно, раскрыть и, собственно, сам ключ, и то сообщение, которое, там,
происходит. Ну, тут есть, на самом деле, два пути, то есть, там, первый путь — это, там, инженерное
решение, то есть, пытаться максимально заизолировать, там, помехи, то есть, увеличить частоты,
там, добавить, там, различные способы снижения, вот это вот, подание этой информации, там, в звуковое
пространство. Пытались, пытались, пытались, вроде, в принципе, решения нашли, но, там, заменить
несколько десятков тысяч машинок по всему миру было, в целом, нереалистично. Кончилось все тем,
что пришли к некоторому административному решению, соответственно, там, в радиусе 30 метров не должно
быть, там, войск противника в момент использования, соответственно, машинки шифрования. Ну, дошло до
смешного. Буквально через несколько лет обнаружили, что кроме, вот, соответственно, звукового профиля
точно такие же сообщения, собственно, то есть, точно такие же помехи позволяют раскрыть информацию,
соответственно, сообщений в электромагнитном поле. Ну, увеличили с 30 метров до 60 метров. Просто, но
работает. Поэтому борьба с атаками такого рода, она происходит не только на уровне, собственно,
там, кому-то техническом, но вполне может происходить и на других уровнях, потому что сами атаки достаточно
разнообразны, и, там, подходы к митигации, собственно, этих атак, они не всегда тревожны. Подробнее, как раз,
написано, вот, ссылочки на слайде, там, из НИСовский отчет. Я рекомендую посмотреть, будет достаточно
интересно. Но возвращаясь к тому, какие вообще атаки бывают. То есть, атаки по сторонним каналам
они имеют, там, свойства. То есть, например, есть там свойства физические. Например, время. Мы
померили время. То есть, там, время больше, время меньше. Мы узнали, соответственно, информацию,
там, о длине хэша, например, или о том, когда, соответственно, мы, сколько успехов, там, букв
этого хэша, мы успели проверить. Есть, там, свойства логические. Ну, вот, например, какие-нибудь, там,
статистические данные, такие, как количество, там, прерываний, объем потребляемой памяти,
соответственно, сообщения об ошибках, которые нам появляются. Вот, они разные. Они сообщают о
разных ошибках. Соответственно, мы можем по ним предугадать, а где именно эта ошибка произошла.
И, соответственно, мы прошли дальше, или, собственно, раньше. Они также отличаются по
способу эксплуатации. То есть, вот, например, там, у вас способ эксплуатации может быть, там,
аппаратным. Но, вот, есть, там, атака, соответственно, для излечения, соответственно, там, содержимого
оперативной памяти, там, по непрямому каналу, вот, с помощью, там, жидкого азота, там, для акулбута.
Это, вот, аппараты, например, атаки. С другой стороны, там, у вас все может происходить полностью
программно. Когда вы замеряете, там, время выполнения каким-нибудь встроенным таймером, там,
на процессоре просто выполняется, там, в отдельном потоке. У вас отличаются по способу
расположения нарушителя. Соответственно, там, нарушитель может быть локальный. То есть, например,
вот, он играет с напряжением, и, там, процессор, соответственно, либо что-то раскрывает, либо,
наоборот, начинает ходить по каким-то не тем веткам, по которым он должен был быть.
Вот, пример аппаратных кличей. Соответственно, либо, там, может быть, удаленный. Соответственно,
у нас находится некоторый удаленный сервер, там, который может быть, может быть, за несколько
десятков километров от нас, и мы за время его ответа можем прикинуть, какие операции он выполнял
для того, чтобы нам ответить. При этом также еще часто считается, что атаки по сторонним
каналам — это про то, как что-то можно узнать. То есть, вот вы, там, слушаете, там, кого-нибудь,
там, наблюдаете что-то, то есть, и узнаете, вот, какую-то информацию, которую они должны знать.
Ну, там, то есть, что они пассивные, фактически, имеют пассивную реализацию. На самом деле,
есть и немало атак, так называемых, активных, которые, вот, собственно, приводят к каким-то
изменениям в работе системы, соответственно, для, там, нашего удобства. Ну, вот, как пример,
там, вот, как раз аппаратные гличчи буквально в третьем разделе. И Rowhammer, например. Про Rowhammer
кто-нибудь слышал? Про такую атаку. Ну, даже если не слышали, то не волнуйтесь, скорее всего,
ваш компьютер ей подвержен за редким исключением, если у вас, там, ECC, то есть, оперативная память,
то есть, память с коррекцией ошибок. То есть, идея заключается в том, что, если достаточно активно
менять состояние оперативной памяти, то есть, менять состояние каких-то битов, то из-за счет
физического устройства оперативной памяти может произойти изменение соседних бит. Вот так. И,
соответственно, от этой атаки, там, в различных ее модификациях, там, подвержены, в общем-то,
все виды памяти, там, вплоть до DDR5, там, при условии, что у вас, там, нету более-менее нормального
работающего ECC, то есть, RF correction кода. Вот. Из этого нужно выяснить одну простую вещь. Что, вот,
если у вас есть некоторый вычислительный процесс, который происходит, там, с какими-то данными,
на разделяемых ресурсах, то есть, кроме вашего вычислительного процесса, есть что-то еще.
Вот. Особенность устройства всех этих систем, она всегда приведет к каким-то атакам посторонним
каналам. У вас так физика работает. Ну, просто, сам даже, просто, кремний, который вычисляет,
он работает неравномерно. И, соответственно, у вас, там, напряжение скачет, у вас, соответственно,
там, частоты меняются, там, допустим. У вас, там, электропотребление разное, у вас время выполнения,
там, не знаю, операции, там, умножения и так далее, оно тоже разное. И, в общем-то, для того, чтобы
решить вот эти вот, там, проблемы фундаментально, не знаю, там, темным кремнем каким-то положиться,
нужны совершенно другие порядки стоимости оборудования. И даже они, там, с долей вероятности
вам никак не помогут решить все вот эти вот проблемы. То есть, все равно какие-то останутся,
про которые вы и не узнаете. Поэтому нужно понимать, что любая система, она будет этому подвержена
всегда. И то, грубо говоря, насколько она этому будет подвержена, там, будет определять, соответственно,
вашу возможность по митигации вот этих вот атак и, соответственно, по вашему желанию их,
собственно, вот изолировать. Но, как пример, там, сейчас, например, в всех, там, процессорах Intel
современных, там сломан Hyper-Trading. Знаете про то, что, там, в кедре процессора можно выполнять
несколько виртуальных поток. Вот, соответственно, производительность падает, ну, там, почти что вдвое,
если его отключить. В случае с, там, десктопными компьютерами, ну, никто так не делает, потому что
просто не готовы пожертвовать этой производительностью. В случае, там, с серверными решениями, это может
быть вполне нормально, просто из-за того, что, там, для серверных решений куда важнее, там, даже
безопасность и изоляция клиентов друг от друга. Как раз наличие, собственно, атак по побочным
каналам, оно еще лучше иллюстрирует, почему, там, вынос фактически, там, криптографических
операций, там, на отдельный процессор, это гораздо безопаснее, чем пытаться, там, запихать эти
операции, там, с какой-нибудь trusted execution engine, то есть, там, 5e, там, слой, там, или system
management mode, то есть, какой-то специальный режим процессора, который будет, там, условно программно
аппаратно изолирован от всей прочей конструкции. Оно не будет работать или будет работать достаточно
плохо и приведет к неприятным атакам, про которые вы узнаете достаточно поздно. Соответственно,
современные атаки, они чаще всего используют особенности устройства микроархитектуры,
в частности, там, конвейера, кэшей, там, branch prediction, кэшей, там, микроопераций, там,
способы, там, доступа к данным, там, особенности, там, предсказания ветвлений, там, для раскрытия
какой-то информации, ну, в первую очередь, там, раскрытие, там, чужой оперативной памяти и,
в основном, их используют для построения более сложных атак. То есть, мы какую-то информацию
раскрыли, после этого нужно ее, соответственно, куда-то передать и, там, в дальнейшем она может
быть уже использована против вас. Приведем несколько примеров. Ну, наверное, такой простой и при
этом очень понятный пример. Это атака TPM Fail, которая проводилась на внешнее устройство TPM,
в задачу которых в том числе входит вычисление, там, некоторые, там, подписи от тех данных,
которые вы на этот TPM передаете. Ну, то есть, идея какая? Мы сгенерировали некоторый ключ
в TPM, то есть, ну, некоторый приватный ключ, он хранится в нем, его нельзя извлечь,
потому что нет для этого интерфейса, но при этом мы извлекли из него приватный ключ.
Ой, вот тут прошу прощения. Мы приватный ключ, сгенерировали ключевую пару, приватный ключ
хранится на TPM, его нельзя извлечь, а публичный ключ, который позволяет, собственно, подтвердить,
что все сообщения подписаны действительно тем приватным ключом, он, соответственно,
доступен снаружи. Это удобная схема, которая позволяет нам защитить максимально, соответственно,
приватный ключ, не давая, собственно, там, возможность атакующим его получить и при этом
безопасно подписывать сообщения и отдавать их там наружу. Это используется, например,
там, каким-нибудь Strong Sloan, это один из VPN-клиентов, точнее, VPN-клиентированный,
то есть, для аутентификации пользователей. Вот, там, в спецификации TPM 2.0 есть один из
алгоритмов на там, шифрование, то есть, на базе эллиптических привых и CDSA, вот, и если,
ну, классический, там, пример, соответственно, там, шифрование с ключевой парой, то есть,
симметричного шифрования, это, там, у вас есть некоторый приватный ключ, у вас есть, соответственно,
там, некоторое сообщение, вы, соответственно, этим приватным ключом шифруете это сообщение,
там, передаете, соответственно, получателю, он с помощью публичного ключа расшифровывает и,
соответственно, там, все хорошо. У вас есть некоторые, грубо говоря, приватные ключи,
которые нельзя никому показывать. У CDSA немножко другая схема, кроме приватного ключа,
который нельзя никому показывать, у него есть еще такая штука под названием nonce. Ну, фактически,
это некоторое случайное значение, которое тоже никому нельзя показывать, которое не должно
повторяться, и оно, соответственно, участвует в вычислении, собственно, криптографической
подписи в механизме CDSA. Для нас это, в принципе, не так важно, за исключением того, что вот есть
некоторый приватный ключ, есть, соответственно, некоторое случайное число, оно каждый раз разное,
там, при подписи, соответственно, разных сообщений, и при этом, имея nonce, можно также
вычислить, имея пару, соответственно, подписанное сообщение, имея nonce, при наличии публичного
ключа, вы можете, соответственно, тут, имея тройку, вы можете вычислить, в том числе, приватный ключ.
Проблема здесь заключается вот в чем. Вот если вас там попросят умножить 8 399 на 9, вы в уме
умножите, что быстрее, вот это число на вот это или, например, там на 342. Ну, очевидно, что вам
гораздо быстрее в уме посчитать первое, чем второе, и, в общем-то, компьютер, он не исключительно,
то есть, в некоторых TPM, подпись, соответственно, CDSA считалась заметно быстрее, если nonce был
маленьким, ну или, точнее, содержал много нулей в начале. Ну, вот пример, соответственно, там слева
это, не помню, как фирма называется, но это один из, соответственно, внешних TPM модулей, а справа
как раз это график с Intel'овым FMV TPM, которые вели себя по-разному в зависимости от того, насколько
маленький, собственно, nonce у вас сгенерировался. Как итог, соответственно, атакующие просто набрали
достаточно количество сообщений, для которых nonce получался с достаточно небольшим количеством нулей,
тем самым сузили себе пространство поиска, и в итоге раскрыли сам приватный ключ, решив достаточно
такую объемную, но вполне себе решаемую систему линейных уровней. При этом, соответственно,
эти все TPM'ы, они были оттестованы, причем некоторые там оттестованы по максимальному уровню
безопасности, и в свое время буквально два года назад атака наделала огромное количество шума,
потому что безопасные системы внезапно оказались очень сильно опасными. С помощью такой атаки ребята
просто ломали, например, VPN сервера, которые у вас работали, использовали TPM в качестве хранили
щекучий. Это не единственный пример атаки, то есть другим примером атаки, который объясняется
на пальцах, это атака meltdown, точнее уязвимость meltdown, которая может быть проэксплуатирована
вот таким способом. Соответственно, здесь схема заключается в следующем. Вот в ядре у вас есть
некоторая там оперативная память, которая, как мы вот в прошлой лекции говорили, она часто
располагается в том же самом, соответственно, пространстве, что и пользовательский код,
но при этом права доступа к этой памяти у вас отсутствуют, то есть с привилегиями пользователей
эту память нельзя прочитать. Соответственно, если мы каким-то образом сможем прочитать эту память,
то собственно мы нашли уязвимость. Вот как работает meltdown? То есть мы выбираем там некоторые
значения, то есть мы выбираем некоторые адресы ядра, которые мы хотим прочесть. Соответственно,
катор имеет тип там unsigned char звездочка, то есть это некоторые указатели на байт. В дальнейшем у
нас есть некоторый probe array. Probe array фактически это некоторая память, которая изначально не
закаширована и имеет размер, соответственно, 256 умножить на 4096 байт. Здесь, соответственно,
4096 байт это размер страницы, а 256 это соответственно диапазон одного восьми битного значения,
нуля до 255. Кстати, probe array называется так, потому что вот эта вот атака, это называется там
атака prime plus probe. То есть сначала мы выбираем некоторые значения, после этого мы его пробим.
Вот. Соответственно, здесь probe array он полностью сначала не закаширован. А как мы помним,
у нас обращение к оперативной памяти, это собственно там несколько сотен нано секунд,
ну там условно 60-80, а если память медленно, то того больше. Поэтому мы достаточно легко можем
отличить, когда происходит обращение к кашированной памяти, то есть это одна нано секунда,
и к некашированной памяти. То есть как получить в собственной области этой памяти некашированную
память. Это очень просто, вы можете просто обращаться к другой памяти достаточно долго,
и за счет этого у вас кэш процессора просто выкинет probe array из своего кэша, просто он
ему станет не нужен. Потому что кэш он ограниченный, соответственно, у вас есть ограниченный объем данных,
который вы можете хранить в кэше. Соответственно, здесь что происходит, у вас есть два потока. Вот
код одного потока как раз представлен на слайде, и он выглядит так, то есть там raise exception,
условно там может быть написан int3, например. И дальше там, например, mov, eax, который будет
читать из этого probe array кадр на 4096. То есть, фактически, некоторые там access, то есть некоторое
чтение данных из оперативной памяти. Здесь схема заключается в том, что за счет ограничений
работы вашего, собственно, режима вы никогда не имеете права разыменовывать ядерный указатель
в пространстве пользователя. Но для ускорения работы, собственно, процессора, когда мы выполняли
операции спекулятивно, то есть мы просто фактически кэшировали выполнение некоторых операций, чтобы
после этого их просто применить в тот момент, когда мы до них дойдем. То есть, в некоторое
кэширование, которое мы говорили ранее, то есть спекулятивное выполнение, то процессор эти права
доступа не проверял. И тем самым возникала интересная ситуация, что, хотя мы никогда,
собственно, сюда не могли попасть при реальном выполнении, процессор при спекулятивном выполнении
этот код выполнял, и тем самым содержимое probe array с некоторым индексом, оно попадало в кэш
процессора, то есть становилось закэшировано. То есть, на суде понятно, как можно узнать, собственно,
какое значение у ядерного адреса, то есть по этому ядерному адресу находилось у русской аудитории.
На слайде написано. На слайде написано, ну да, в принципе, окей. Но схема действительно такая,
что у вас работает некоторый другой поток, и он просто там замеряет, сколько времени там обращения
вот к этому участку памяти, сколько к этому участку памяти. Если у вас достаточно маленький кэш,
то нужно, соответственно, сделать там несколько проверок, потому что, соответственно, к моменту,
когда вы проверите, грубо говоря, там несколько значений, у вас они там уже выкинут то значение,
которое у вас закэшировалось вот в момент, соответственно, пробинга, то есть в момент
вот этого операции access. То есть, атака достаточно небыстрая, но позволяет, собственно, там с очень
высокой долей вероятности прочитать абсолютно любую ядерную память при условии, что у вас есть
выполнение в пользовательском пространстве на процессорах x86. Вот так, да защищались.
Это все страшно, но, соответственно, как вот от этого защищаться? Ну, правда жизни,
наверное, такова, что защищаться действительно никак, никак в том плане, что нельзя защититься
глобально от атак этого класса, как буквально я говорил несколько слайдов назад. Конкретно от
вот той атаки, которая появилась сегодня, вчера, позавчера, можно защититься каким-то
специфичным образом. От того же TPM Fail защитились тем, что обновили прошивки на TPM и использовали
там константную криптографию, то есть криптографию, которая выполнялась за фиксированное время.
Как раз, если по ссылке сходите, которая была на слайде, там того же TPM Fail, там рассказывается,
какие вообще операции можно использовать в C, чтобы у вас код выполнялся за константное время.
В случае с мелдауном, ну вот, есть, конечно, вариант с аппаратной защитой. То есть, в общем-то,
то, что спекулятивный доступ не должен обходить права доступа к памяти, это как бы все понимали,
но понимали в тот момент, когда мы рассказали о том, что вот, возможно, такая атака под названием
сейчас мелдауна называется. Со старыми процессорами что делать? Ну вот, со старыми
процессорами пришлось ядерное и пользовательское адресное пространство располагать в разных CR3.
И вот мы пришли к тому, что сейчас, когда ваш фактически пользовательский код дергает какие-то
системные вызовы, у вас происходит изменение CR3. То есть, соответственно, вы вынуждены сбрасывать
весь TLB, если у вас процессор достаточно медленный, если у вас процессор достаточно старый, который не
может хранить идентификаторы задач, то есть фактически теги задач в вашем TLB. И, как результат,
mitigation будет достаточно медленным и производительности вам не прибавят. Ну, для других атак, соответственно,
используются другие способы, но я думаю, что мы об этом еще поговорим, когда будем говорить о
микроакадемических атаках в одной из следующих лекций, если по крайней мере успеем. На этом у меня
на сегодня все. Какие, собственно, вопросы? Интересно было бы узнать про уязвимость
спектра, потому что она появилась где-то в то же время, как и молдаун. Да, я, соответственно,
для спектра оставил буквально два слайда, которые есть у вас на ForgeStress.ru, в том числе у вас есть
презентация. Но сегодня мы просто спектр не успеем, но когда будет, соответственно,
лекция про микроархитектурные атаки, то я не расскажу. Это будет, ну вот, через, наверное,
две или три лекции. Да, да. Я, соответственно, на этом предлагаю закончить тогда запись.
Всем спасибо и переходим к практической части.
