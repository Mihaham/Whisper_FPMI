Продолжаем туризм по деревья поиска, и в следующий раз тоже у нас будет дерево поиска, в последний раз, на последний лекции.
Значит, сегодня мы договорим про B-дерево, которое в прошлый раз начали, и Декартово дерево тоже обсудим.
Начинаем с B-дерева. Давайте я быстренько напомню, что это такое.
Во-первых, мы договорились, что в каждом узле у меня теперь может быть не один ключ, ни одного значения, а довольно много.
Первый ключ, второй ключ и так далее, вплоть до там S-ключей.
И вот это S, оно обычно, то есть вне корневой вершинки, должно быть от T-1 до 2T-1, если это не корень.
Если это корень, то должно быть от 1 до 2T-1.
S больше 1, не больше 2T-1.
Это условие на количество ключей в каждом узле.
Еще у нас было адекватное требование, чтобы все листины на одной глубине.
На одной глубине.
Напоминаю, как работает много ключей в одном узле.
Если у нас есть много чисел K1, K2 и так далее, то между каждым двумя есть какая-то стрелочка на следующий узел.
Если исходный не лист, то обязательно есть отсюда какой-то указатель.
То же самое есть какой-то указатель из этой точки, которая стоит левее K1.
Здесь будет S плюс один указатель.
Все числа, скажем, располагающиеся в этой вершинке, даже во всем этом поддереве, которые идут ниже этой стрелки,
здесь все числа должны быть больше, чем K1, но меньше, чем K2.
Все числа здесь действительно находятся между K1 и K2, в том интервале между K1 и K2.
Соответственно, здесь все числа должны быть меньше, чем K1.
Здесь в правом поддереве все числа должны быть больше, чем Ks.
А можно на время помнить, что такое T?
T – это произвольный фиксированный параметр.
Просто какое-то число. Обычно оно выбирается порядка тысячи.
А стрелка между K1 и K2 от чего ведет?
Нам нужна просто структура данных, которая задает нам каждый узел, структ ноди, структура вершинки.
И в этой вершинке будет S чисел просто и S плюс один указатель на остальные ноды.
Соответственно, здесь будет там нулевой указатель, здесь будет первый указатель, и так далее.
Здесь будет S-ты указатель в ноль ноксации.
То есть фактически они не связаны?
Ну так просто есть S-ты и S плюс один указатель.
В двух разных массивах лежат.
Просто их так удобно, удобнее рисовать.
В плане реализации это просто отдельные сущности, они не связаны.
Вот. Хорошо.
Здесь же, да, тут, во-первых, можно пояснить немножко, почему это называется B дерево.
Что такое B? Хотя у нас, казалось бы, естественно, было бы называть T деревом.
Во-первых, B – это классическое название переменной,
которое означает страницу памяти, которую вы можете легко подгружать в вашу оперативку.
Я говорю в прошлый раз, что у вас простая операция – это считать описание одной вершины до одного узла.
То есть порядка 2T ключей вы можете легко прочитать и, соответственно, узнать, куда идут все эти стрелки.
Просто как число указателей.
И это вы как бы можете считать за одну простую операцию – выгрузки этой страницы данных в вашу оперативку.
То есть вы просто берете какой-то блок памяти, B – блок памяти,
подгружаете себе в оперативку, как одну страницу оперативной памяти, и с ней работать.
И это просто классическое обозначение для переменной, которое означает размер страницы памяти,
которую вы можете на халяву, грубо говоря, за одну операцию, за один такт подгружать в оперативку.
И есть отдельная область в теории алгоритмов – это алгоритмы во внешней памяти.
Алгоритмы во внешней памяти.
Мы вот ими, к сожалению, не особенно занимаемся, кроме этого B дерева во внешней памяти.
Это как раз задачей, когда объем данных слишком велик для того, чтобы весь поддерживать в какой-то малооперативной памяти.
У вас есть огромная база данных на флешке или на диске,
и вам нужно с ней что-то сделать, использовать только вашу маленькую оперативную память в единице гигабайт.
И тогда B обычно как раз таки называется какой-нибудь размер памяти,
который вы можете быстро подгрузить в оперативку.
Ну, это просто такая традиция, что это называется буквой B.
Хорошо, давайте тогда обсудим, как делать find сначала в таком дереве.
Find в B дереве.
И за сколько это делать?
Ну, смотрите, встанем в корень.
Давайте find какого-то ключа X.
Встали в корень, прошли по всем ключам.
Если один из ключей равен X, то мы уже нашли этот X в нашем дереве.
Иначе мы однозначно можем локализовать, между какими двумя ключами этот X находится.
Скажем, вот прошлись просто вступуя по всему этому узлу.
Напоминаю, что здесь не особо есть смысл делать бинпоиск.
Хоть наши ключи в каждом узле и упорядочены, нет смысла делать бинпоиск,
потому что нам все равно нужно эти ключи сначала откуда-то считать.
Ну, это я не веду в таком реальном случае, когда у нас огромное дерево не помещается в нашей памяти.
Конечно, в наших хантестах на WebForces там можно писать B дерево,
целиком выхраняя в оперативной памяти, поэтому то, что я говорю, не совсем валидно.
Но, тем не менее, давайте считать, что вот в таком в реале
нам не обязательно здесь искать X бинарным поиском.
Можно просто пройти слева-направо по этой вершине и найти просто два средних элемента,
так вот что левый меньше, и микс правый больше.
Скажем, вот этот элемент меньше, чем X, этот больше, чем X.
Значит, если X где-то в дереве находится, то он гарантированно лежит в поддереве,
которое получается вот в этой стрелке.
То есть мы смотрим стрелки между этими двумя элементами,
то есть если этот элемент ИТ, это И плюс первый, то соответственно нам нужна ИТ-стрелка.
Или там И минус первая. Ну, короче, что-то такое.
Нам нужна стрелка, разделяющая это И плюс второй элемент.
Просто спускаемся сюда и запускаемся тем же самым.
Просто находим X в вершине, если он есть, то мы его нашли, иначе нужно куда-то спуститься.
Простейший файнк, собственно, точно так же, как мы делали в обычном бинарном двоичном дереве поиска,
когда у каждой вершины два сына.
Только здесь сыновей больше, нужно просто понять, в какого из сыновей нужно переходить.
Соответственно, асимптотика будет этого этой процедуры.
То есть я напишу так, T умножить на лог N по основанию T.
Мы в прошлый раз обосновали, что вот эта вот глубина, да, оценка на глубину.
Ну, а это соответственно то, за сколько мы каждую вершину там считываем в память
и находим указатель, по которому нужно сдвинуться.
Вот, T на лодерифм N по основанию T.
Ну и повторюсь, обычно T считается какой-то константой,
поэтому здесь как бы я напишу тогда, ну, я напишу просто равно от log N, если T константа.
То есть обычно T берется действительно какой-то константой,
ну просто T такое, что вы можете очень быстро подгрузить один узел размера линейного по T в вашу память.
Ну, соответственно, T, какая-то константа, зависит от характеристики компьютера,
ну и удачи, когда это будет логерифм от размера дерева.
Так, вопрос в чате.
Как узнать, сколько реальных существует элементов в левой части дерева относительно стрелки?
Сколько на самом деле существует элементов в левой части дерева относительно стрелки?
Не понял вопрос.
Ну, то есть допустим, у нас огромное B дерево, там одно ряда миллиарда,
мы типа закинули два, потом 20 тысяч, потом 200 тысяч,
и пошли искать, например, по стрелке, которая указывает там, ну, 40.
Что значит закинули? Сделали инсерт?
Да, типа того.
Они обсуждали, инсерт делать более сложно.
Мы пока что считаем, что у меня есть корректное B дерево.
Вот, пока что мы в нем сделали самую простую операцию Find.
Инсерты и Ray сейчас будут чуть позже.
Итак, ну вот, Find работает за, ну, грубо говоря, за логарифм.
Начинается операция самая простая.
Теперь давайте перейдем к реализации инсерта.
Дарас как раз спрашивает, как производится инсерт, каков-то ключа X.
Значит, идеальная ситуация была бы следующей.
Давайте запустим процедуру Find X, и в поисках этого X,
ну, то есть, если X есть в дереве, то, понятно, добавлять ничего не нужно.
Мы считаем, что мы храним именно множество, а не мультимножество,
поэтому кратности мы не храним.
Если X был в дереве, то делать ничего не нужно.
Иначе, если X в дереве не было, то мы, получается, как дело?
Мы встали в корень, там X не нашли, спустились куда-то,
опять X не нашли, куда спустились, и так далее, и так далее,
дошли до листа.
То есть, мы в поисках X-а прошли всю глубину дерева, дошли до какого-то листа.
И даже в этом листе X-а нет.
Тогда самый простой способ, это давайте просто вставим X в то место в листе,
где он должен был находиться.
То есть, если есть лист, порядочный список ключей,
давайте просто найдем два средних ключа, между которыми должен стоять X,
и вот это поместим.
Давайте я кратко это, как вы пишу, запускаем.
Если X был в дереве, то делать ничего не нужно.
Делать ничего не нужно.
Иначе, мы спустились до листа, и даже в этом листе нету X-а.
Мы спустились до листа, и даже в этом листе нету X-а.
Дальше я отражаю следующее.
Что если в этом листе меньше, чем 2t-1 ключ,
тогда туда можно на халяву вставить X.
Если в этом листе меньше, чем 2t-1 ключ,
просто ставим в него X.
Вот тогда инвариант нашего дерева сохранится.
То есть, по-прежнему в каждой вершине не больше, чем 2t-1 ключ.
Все требования на бытелье выполняются.
Структуру мы не перестроили.
Соответственно, все листья остались на одной глубине,
если не раньше были на одной глубине.
Поэтому осталось корректное бытелье.
То есть, если в таком идеальном случае мы дошли до листа,
и лист у нас не запустился,
то лист у нас не запустился,
то лист у нас не запустился.
Если в таком идеальном случае мы дошли до листа,
и лист у нас не целиком заполненный,
и у него можно вставить еще один новый элемент X,
тогда вот такая очень простая операция.
Мы просто спускаемся и в нужное вершину вставляем X.
В смысле, в нужное место.
Что у нас было?
У нас был лист.
Здесь был какой-то отсортированный список чисел K1, K2, Ks.
Дальше мы определяем двух соседей,
между которыми нужно вставить X.
И просто создаем новый список.
В него перекопируем K1, K2, Ki.
Потом пишем X, потом Ki плюс 1,
и так далее Ks.
Поскольку все равно мы работаем за время
пропорционально T в каждом листике,
в каждом узле,
то я могу заново создать новое описание этого листа,
перекопировать туда все старые ключи,
вставить X, перекопировать все
старые ключи больше X
и поставить этот лист на место того предыдущего.
То есть,
не нужно никаких хитрых вставок делать.
Не нужно, например, еще одно
дерево поиска внутри каждого узла.
Это не нужно, мы просто храним там какой-то массив,
который явно перестраиваем.
Копируем префикс, вставляем X,
копируем софикс. И это все безобразие.
Теперь помещаем на место старого листа.
Вот это простой случай,
когда действительно мы дошли до низа.
Нужно разумеется дать вершинку
собственно соответствующую X.
Нет, смотри,
у нас вершин сильно меньше,
чем ключей. Примерно в T раз меньше.
Потому что каждая вершина
соответствует примерно от T
до двух T ключей.
И в случае как раз, когда эта вершина недозаполнена
и в ней меньше, чем два тайма своим ключ,
то можно просто ничего, ну как бы,
не нужно вставать новую вершинку, можно просто этот текст
вклинить в старую.
Здесь только множество ключей
внутри этой вершины.
Обычно ключи соответствуют значения.
То есть, мы по ключу храним какое значение.
Значит ли это то, что в одной вершине мы храним
много значений?
Вместе с много ключами.
Если мы храним...
Это вы про другую задачу.
То есть, скажу так.
Сейчас скажу.
Вообще задачу,
которую мы сейчас решаем,
это научиться реализовывать структуру данных,
которую умеет делать find, insert и erase.
И там вот то, что вы говорите,
у нас не нужно
поддерживать значение. Если нужно,
то просто давайте хранить пару X,
запятая Y от X.
И тогда у нас будут пары, но эти Y никак не влияют
на структуру дерева. То есть доп информацию можно хранить,
но она к нам
в рамках нашей задачи
не относится.
Еще вопрос в чате. Есть ли смысл писать
ячейку с связанным списком, а не массивом?
Насколько я знаю, нет.
Потому что вам же все равно нужно
вставить...
Еще раз повторюсь,
что здесь все равно самая сложная
операция, это подгрузка вот этих
T-элементов в вашу оперативку.
Если вы все равно это делаете за время
пропорционально T, то внутри неважно, как оно устроено,
или массивом, хоть списком, хоть
чем угодно, вы все равно уже
потратили T-операцию, чтобы прочитать эти
T-ключей, ну значит там
потратите еще T-операцию на то, чтобы сделать
вставку X внутрь,
неважно, то есть можно и массивом.
Все равно асимптотика
уже не станет лучше от того, что там
вы будете делать какие-то оптимизации, поэтому можно
писать так, как вам удобно, а массив скорее удобнее,
чем список. По крайней мере, не нужно
реализовывать там всякие указатели.
Хорошо.
Это очень простой случай,
но в общем случае такого не будет.
Вполне возможно, что мы дошли до листа, лист
целиком заполненный, в нем 2T-1 ключ,
и тогда в него никого больше нельзя вставить
с учетом сохранения свойств обой дерева.
Если мы вставим, то лист переполнится.
Вместо этого мы будем делать следующее.
Давайте каждый раз,
каждый раз,
когда алгоритм
спускается,
попадает
в заполненную вершину,
это означает, что в ней ровно
2T-1 ключ.
То есть максимально
возможное количество будет в заполненную вершину.
Так вот, давайте каждый раз,
когда алгоритм попадает в заполненную вершину,
как бы это сказать?
Делать так,
чтобы в ней,
чтобы она стала не заполненной.
Чтобы она стала
не заполненной.
То есть мы поняли, что наша проблема
это заполненные вершины, в которых максимально возможное количество ключей,
то есть 2T-1.
Так вот, давайте тогда, когда мы запустили
Find.x, спускаемся сверху вниз,
давайте для каждой вершинки на пути,
которая была заполнена, мы что-то с ней сделаем так,
чтобы вершина стала не заполнена,
и тогда, соответственно, в нее можно было бы вставлять x,
если нужно.
Так вот, как мы делаем эту операцию,
как мы заставляем вершину стать не заполненной?
Здесь идея очень простая, смотрите,
пусть есть какая-то вершинка,
и она заполнена, то есть в ней ровно 2T-1 ключ.
Можно с ней сделать следующее,
давайте эта вершина,
в, она заполнена,
и, скажем,
есть какой-то родитель у нее,
родитель P,
ну и здесь, соответственно, есть какая-то стрелка.
Тогда мы сделаем следующее,
давайте мы разобьем нашу вершинку
на T-1 ключ
слева, назовем этот массив A,
дальше будет центральный элемент Y,
и, соответственно, будет массив B,
тоже размером T-1,
и мы сделаем следующее,
мы этот Y поместим вверх в родителя,
то есть перетащим в родителя,
а для A и для B построим
собственные независимые вершинки.
У нас старая вершинка,
вот эта вот вершинка V,
распалась на две вершинки A и B,
а разделитель между ними, Y,
переместился в родителя.
Более подробная картинка такая,
был родитель P,
и, значит,
между какими-то двумя элементами,
ну не знаю, скажем, C и D,
была стрелка в вершинку V.
Была стрелка в вершинку V.
И мы понимаем,
мы предполагаем, что вершина V заполнена,
то есть не ровно дватым своим ключем.
Тогда мы рассматриваем левую половинку,
центральный элемент и правую половинку.
То есть это то, что было,
то, что станет, сейчас я тоже нарисую,
станет вот такое.
Мы в P засовываем,
то есть вот между как раз этими C и D
мы засунем этот Y,
то есть мы его поднимаем вверх,
как раз на то место,
из которого как будто бы шла стрелка V.
Дальше разделитель между C и Y
показывает на A,
разделитель между Y и D
будет показывать на B.
Вот такой, ну по сути, мы как бы
вершинку V расплитили на две,
и разделитель между ними подняли в родителя.
А в P всегда можем что-то добавить?
Да, и как раз за счет того,
что мы так делаем для каждой вершинки
при проходе сверху вниз,
у нас сейчас будет верно,
что в P меньше, чем дватым своим ключем.
Поскольку мы идем сверху вниз
и в каждой текущей вершине,
если мы только что пришли в вершину,
мы делаем так, что в ней после нашей операции
будет меньше дватым своим ключем.
То есть это в P выполнялось.
Дальше мы спустились вниз,
опять встретили вершинку с дватым своим ключом,
и теперь поскольку в родительской вершине
меньше, чем дватым своим ключем,
мы имеем право так сделать,
мы имеем право так расплитить
и поднять одну вершинку вверх.
Теперь здесь у меня опять обе новые вершины.
заполненные. Соответственно, там дальше, если как-то спускаю, то опять вот эта предыдущая вершина,
то есть если ниже имеется вершина с 2 t-1 ключом, то ее родители имеют всего t-1 ключ,
поэтому точно можно сделать вынос элементов родителей. Хорошо, просто про корень. Давайте
чуть-чуть позже я это скажу. Так вот, значит, так сделали. Еще нужно немножко с указателями,
вот этими старыми указателями, повозиться. Значит, смотрите, были какие-то указатели вот такие,
давайте 네 рисую. Были указатели здесь, дальше был указатель слева от y, справа от y.
И указатели вот чисто c 1-1. Тогда эти указатели, собственно, те указатели, которые были слева,
я оставляю вообще так же. Дальше вот это указатель, который был слева от y, я говорю,
что он находится справа от a. Вот этот указатель, который был справа от y, он теперь справа от b,
но все указатели с b я тоже перекопирую. короче у меня собственно вот а и b это вот эта вот
штука, вместе со всеми указателями вниз, и b это вот эта штука вместе со всеми указателями вниз,
собственно я их вот сюда перенес. вот нужно убедиться что выполняются все свойства
b дерева, да ну во-первых как мы уже отметили, раз родительская вершина имела меньше 2х-1 ключ,
теперь они будут меньше заправно чем 2х-1 ключ, все хорошо, выполняется линия вариант. дальше
вот эти две вершинки новые, в них теперь по ровно t-1 ключу, поэтому инвариант тоже сохраняется,
для внутренних вершин у нас должно быть хотя бы t-1 ключ, это верно. ну и дальше там нужно проверить,
что все неравенства также выполняются, да то есть скажем как у нас было раньше, раз вот эта вот
вершинка лежала между c и d, то получается что все числа здесь, вот эти все числа, они с одной
стороны больше c, а с другой стороны меньше c и d. теперь я это расплитил и у меня теперь должны
лежать элементы меньше чем c, больше чем c но меньше чем y, а здесь больше чем y но меньше чем d,
ну это собственно так и будет выполняться, потому что поскольку а лежало левее y,
значит все элементы здесь строго меньше чем y, да поэтому это верно. здесь b лежало правее
поэтому все все элементы здесь большими, все они раньше выполнены, в смысле, что это
опять корректное по дереву, в плане того, что все ключи там правильно, порядочно, дальше инвариант
сохранены, глубина листьев не изменилась, поэтому такая операция нам доступна, так, то есть при
операции инферс, производится починка дерева, устраняющие полностью выполненные, нет, в смысле те,
которые мы проходим, то есть смотрите, вот у нас есть какой-то путь, да, от корня до листа, в котором
как бы нет икса, и куда нужно положить, мы идем так сверху вниз, встретили заполненную, так ее
посплитили, что она теперь не заполнена, дальше спускаемся вниз, встретили заполненную, опять
посплитили, так что она не заполнена, и так далее, спустились до листа, то же самое, если она заполнена,
если он заполнен, мы его распличиваем, и он становится не заполнен, и теперь в него можно вставить икс,
мы идем сверху вниз, каждую заполненную делаем не заполненной, и так спускаемся вплоть до листа,
и тогда в листике то же самое можно сделать, так, да, значит здесь один есть крайний случай с корнем,
вот был вопрос в чате, на самом деле, если в корень, то здесь отдельный случай, потому что если в корень,
когда у него нет родителя, их дыр и как бы некуда поднимать, но в таком случае, если в корень, давайте
я все-таки отдельный слайд заведу, потому что тоже важно это проговорить, то есть если в корень, то картинка
такая, есть заполненный корень с дватым с одним ключом, и я хочу сейчас его расплитить, вот, но,
собственно, я это делаю точно так же, я выделяю центральный элемент y, а также левую правую часть
а и б, только теперь я y не могу поднять родителя, потому что родителя в принципе нету, вместо этого я
просто завожу новую вершинку, которая являет корнем, и в этом корне будет один только y, соответственно,
левое указание будет показывать на а, правый на b, то есть в случае, когда нужно посплитить корень,
у меня появляется новый корень, то есть v перестает быть корнем, новый вот этот центральный y,
я перемещаю в новый корень, заводится новый корень, эта вот вершинка будет новый корень,
новый корень дерева, вот, ну и тем самым мы опять посплитили, и все варианты вновь сохранены,
потому что в корне у нас должно быть от 1 до 2t минус 1 ключа, это выполняется, у нас есть один
ключ в корне, все хорошо, но во всех внутренних все правильно, и собственно глубина не изменилась,
потому что, ну по сути, я просто как бы глубину увеличу на 1, было какое-то такое дерево,
я взял и все, ну по сути, как бы у всех решин поднял глубину на единицу, потому что я подвесил
какой-то кольц сверху дерева, значит глубина у всех листьев выросла на 1, значит глубина всех
листьев осталась одинаковой, если она раньше была у всех одинаковой, то теперь тоже одинаковая,
вот такой отдельный случай с корнем, хорошо, значит мы так делаем, спускаемся, разделяем
заполненные вершинки, ну и в конце, когда мы дошли до листа, мы опять, если он был заполненный,
сделали его не заполненным, подняв нужный элемент в родительскую вершину, ну теперь эта вершинка
опять не заполненная, и значит в нее можно вставить x в нужное место, не заполнена, значит в нее можно
вставить x, а собственно этого мы и хотели, мы хотели вставить x в лист, и теперь, поскольку он не
заполненный, в нем меньше 1 ключ, то работает наше первое наблюдение, что просто можно его вставить
в нужное место, будет корректная вершина, вот такая реализация инсерта, спуск и поддержка то,
что текущая вершина не заполнена. Вот здесь важное замечание, ну такое интересное замечание,
что в этой процедуре нам нужен всего один рекурсивный спуск, всего один рекурсивный спуск,
без подъема, без подъема, то есть если вот, например, вспомнить какой-нибудь AVL дерево,
как там работал инсерт, мы сначала спускались от корня в поисках того места, куда нужно
подвесить новый ключ x, подвешивали его, а потом шли обратно снизу вверх, так перед, ну там как бы
делать какие-то повороты, да, переподвешивать вот эти все по деревья, чтобы уравнять балансы,
чтобы ни у какой вершины не было дельта плюс или минус. То есть там мы сначала спустились сверху
вниз, потом сниз шли снизу вверх, исправляя все дисбалансы. То же самое было в сплее деревя,
мы сначала нашли место, куда нужно подвесить x, подвесили, а потом с помощью наших зигзигов и
зигзагов, и в конце, возможно, одного зиг так попровращали дерево, чтобы вставленная вишенка
стала корнем. То есть в предыдущих реализациях у нас обязательно нужно не только сверху вниз
пройтись, но и снизу вверх, чтобы все исправиться. Здесь же нам достаточно всего одного спуска сверху
вниз, потому что, ну вот как при поддержке этого инварианта, да, что текущая вишена не заполненная,
мне просто нужно будет вставить x в лист, и все хорошо, у меня будет сразу корректное дерево,
не нужно будет подниматься вверх, чтобы что-то исправиться. Вот это такое небольшое преимущество,
что-либо дерево по сравнению с тем, что у нас было до этого. Да, без подъема. Хорошо.
Хорошо, тогда едем дальше. Нам нужна третья наша операция, это erase. Тут будет чуть больше случаев,
но идейно все плюс-минус так же. То есть наша задача это сделать так, чтобы из вершины,
откуда нужно удалить x, было можно это сделать. То есть чтобы в ней было не t-1 ключ,
а хотя бы t, если в вершине хотя бы t ключей, то можно сделать удаление, потому что у нас
требование, что хотя бы t-1 в каждой вершине, значит, чтобы удалить нужно, чтобы было хотя бы t.
Вот, хорошо. Ну и соответственно, то, что мы поддерживаем, это вот как раз то, что я сказал,
значит, давайте спускаться, давайте спускаться от корня в поисках x и делать так, чтобы в текущей вершине
было хотя бы t ключей, было хотя бы t ключей, ну если это не корень, если это не корень. Ну потому
что в корне, в принципе, у меня нет ограничения, то есть там сказано, что от 1 до 2-1 ключа, то есть
по сути у меня нет нижнего значения на количество ключей в корне, поэтому вот это больше 0t должно
быть только для корня выполняться, только для не корня, для всех остальных вершин должно выполняться,
для корня это не должно быть, ну в смысле, не обязательно. Вот, ну тогда что, смотрите,
как можно добиться того, чтобы в вершине, в которой t-1 ключ, вдруг стало хотя бы t ключей,
то есть понятно, если в корне мало ключей, то мы с ними ничего не делаем, потому что на корне у нас
нет требования снизу, ну то есть там есть требования, что хотя бы, хотя бы 1, хотя бы 1 ключ,
но это и так всегда будет верно, потому что мы не будем хранить вершины без ключей вообще. Ну так вот,
пусть есть какая-то вершина не корневая v, и в ней t-1 ключ, t-1 ключ, значит, раз она не корневая,
то у нее есть какой-то родитель, есть какой-то родитель, да, в этой вершинке, и, соответственно,
у этой вершинки есть, в общем случае, два брата, есть брат правый, есть брат левый.
Что такое правый-левый брат? Ну, понятно, это просто, как бы, то куда указывает следующий
или предыдущий указатель, то есть, а смотрите, здесь был какой-то указатель из родителя,
указывающий на вершинку v. Если рассмотреть следующий указатель, то он показывает,
как бы, направо брата. Если рассмотреть предыдущий, то он указывает на левого брата. То есть просто,
в буквальном смысле правые и левые братья, то есть самые близкие вершинки на том же уровне.
То есть это будет правый брат, правый брат и левый брат.
Здесь идея такая, если, допустим, в правом брате хотя бы t ключей, давайте предположим, что здесь хотя бы t ключей.
Тогда можно будет проделать следующее. Вот здесь взять самый маленький ключ z, то есть самое левое число в правом брате,
поднять его на место вот этого y, который являлся разделителем между вершинкой v и правым братом вершинки v,
а сам y спустить в эту вершинку v.
То есть мы z подняли в родительскую вершинку, то есть мы z поставили на место y, а y приписали в конец v.
То есть в v у меня увеличилось сколько ключей на единицу, в z, оттуда можно было исключить z, в правом брате можно было исключить z,
потому что там хотя бы t ключей, значит все хорошо. Давайте подробнее картинку нарисуем.
Вот был родитель, вот был какой-то ключ, разделяющий нашу вершинку v и ее правого брата, то есть вот была какая-то вершинка v,
вот был правый брат v, v это правый брат, правый брат v.
И это значит то, что было. Давайте еще стрелки нарисую, какие здесь были вниз, значит вот эти стрелки я нарисую красненьким.
Вот здесь была одна стрелка синяя, самая левая, и все остальные я нарисую красненьким, потому что я их не буду менять.
Это было. А вот что станет. Вот что станет. В родителе вместо y будет z, вот этот вот z, который самый левый в правом сыне.
Дальше ссылка здесь останется на v, но к v еще припишется новый элемент y. То есть я по сути просто y спускаю вот сюда, а z поднимаю вместо y.
Ну а в правом сыне z удалится, то есть правый сын будет без z.
Значит, что со стрелочками. Эти две стрелки сохраняются, здесь все стрелки красные остаются.
И единственное, что здесь такое тонкий момент, это что вот эта синяя стрелка, которая раньше исходила из, ну как бы самой левой стрелки в правом сыне,
она теперь является самой правой в левом сыне, то есть в вершинке v.
То есть вот эта синяя стрелка, она переподвешивается и теперь находится вот здесь.
Ну а все остальные стрелки, вот эти красные, они остаются в правом дате.
Вот так работает наша операция. То есть по сути мы перебросили элемент z в родителя, а y опустили в вершинку v.
Ну давайте кратко посмотрим, почему здесь все хорошо.
То есть ну во-первых, так можно сделать, потому что теперь в правом рате t-minus, ну хотя бы t-minus 1 ключ,
поэтому так можно сделать. Дальше, что с неравенствами?
Ну значит здесь, не так, вот здесь, то есть правее z, все числа были больше, чем z.
Ну значит, если я как раз, по сути, я вот это вот поддерево, вот это синее поддерево,
переподвесил влево, а здесь как раз были числа меньше, чем z, но больше чем люгий, потому что они слева от z, но справа от у.
И как раз они вот здесь, и будут находиться справа от y, а слева от z.
И отсюда они как бы отклеятся, переклеятся сюда.
Ну а здесь будут все элементы больше, чем z. То есть с неравенствами все хорошо,
спорное дерево туда, куда нужно и, собственно, в общем, просто, если не верите, то просто аккуратно посмотрите за всеми неравенствами, которые должны выполняться, убедитесь, что они выполняются.
Потому что в каждой решении ключи посорчены. Дальше, что слева вот каждого элемента стоят только меньше, числа справа только больше.
Вот так. Как левый малый левый пород.
Кстати, да, рог, кстати, да, действительно, да, то есть мы, ну,
ну да, да, и там тоже такое же переподвешение, да, кстати, действительно, да.
Так, еще вопрос в чате. Почему еще раз в левом брате было до изъятия Z хотя бы T? Это предположение, предположение, что если у вершинки В
был такой крутой правый брат, что в нем хотя бы T ключей, то мы один можем так перебросить. Если, то можем.
Пока что я ничего другого не утверждал. То же самое происходит с левым братом.
То есть мы поняли, что если у вершинки В есть правый брат хотя бы с T ключами, то мы можем так сделать.
То же самое, если, наоборот, левый брат содержит хотя бы T ключей.
Давайте пропишем. Тоже происходит, ну, в смысле тоже, в смысле аналогично, тоже происходит, если у В в левом брате хотя бы T ключи.
То есть там работает то же самое. Нам нужно из левого брата извлечь самый большой элемент,
поместить его на место Y, на место разделяющего элемента в родителя и этот разделяющий элемент спустить в В.
Тогда В у меня станет на один ключ больше, а в левом брате на один ключ меньше.
То есть это такой простой случай, когда есть брат, из которого можно перетащить, и тогда наш вариант сохранится.
Мы хотели, чтобы в текущей вершине В стало хотя бы так ключей, мы что-то сделали так, чтобы в ней стало хотя бы так ключей.
Это такой простой случай относительно. Теперь второй случай плохой.
Пусть теперь это неверно и в обоих наших братьях, и в левом, и в правом минимально возможное количество T-in ключ.
Пусть теперь в обоих братьях, братьях по T-1 ключу. Ну, либо вообще брата нету.
Скажем, если в это самое левое вершине у него вообще нет левого брата, поэтому там ну как бы ниоткуда ничего перебрасывать.
То есть в братья либо брата нету, либо там минимально возможное T-in ключ.
Так, вот мы в таком случае сделаем просто объединение наших двух братьев.
В таком случае, ну легко показать, что хотя бы один такой брат есть.
В таком случае, давайте сейчас, нехорошо я написал, давайте немножко в прошлое предложение исправлю.
Точнее, каждый брат либо не существует, либо не существует, либо в нем ровно T-in ключ.
Хорошо, значит тогда легко показать, в таком случае, легко показать, что хотя бы один брат есть.
Есть хотя бы один брат.
Ну потому что мы договорились, что в корне есть хотя бы один ключ.
Значит из корни исходят хотя бы две стрелки, значит у каждой вершины есть либо левый, либо правый брат.
То есть не бывает такого, что у вершины нет ни левого, ни правого брата, потому что иначе она была бы T-in сыном родителя,
а такого не бывает, потому что в каждой вершине хотя бы один ключ есть.
И давайте склеим с любым из них, то есть если есть правый брат, то мы склеим с правым, если есть левый, то склеим с левым, не важно с каким.
Какая будет картинка?
Вот есть текущая V, вот есть у нее правый брат R, и давайте я здесь тоже нарисую.
Здесь есть разделитель Y, то что было слева будет C, то что было справа будет D.
Значит это родитель, это родительская вершина.
Дальше есть вокруг этого Y два указателя на V и на, скажем, правого брата.
И мы предполагаем, что в обеих вершинках V и R ровно по T-ин сыному ключу.
Ну если V больше, чем T-ин сыни, то нам делать ничего не нужно, в ней уже нужное количество ключей есть.
Итак, тогда это было. Вот что станет.
Мы возьмем, склеим V и R, а также спустим Y вниз.
То есть вместо V и R у нас будет одна такая объемная вершинка, а также в нее спустим Y из родителя.
Теперь в родителе будет C, D без этого Y, и будет одна жирная вершина, в которой написано сначала V, потом Y, потом R.
То есть сначала вершинка, потом вот этот элемент, который мы спускаем из родительской вершины, потом R.
Что со стрелками? Ну здесь опять есть разделитель между C и D, он показывает просто на эту большую вершинку, V, Y, R.
Дальше здесь были какие-то указатели.
Здесь просто надо позабоиться о том, что происходит с крайними указателями.
Эти все остаются такими, как были.
Указатель, который был самый правый, из V, он теперь указатель между V и R.
Дальше указатель, самый левый, в R, он теперь между Y и R, а все остальные указатели остаются без изменений.
Опять можно убедиться, что все не раньше выполняются.
Ну, например, потому что почему, например, вот в этой вершине все ключи упорядочены?
Потому что мы знаем, что вот эта стрелочка находится левее Y, значит все элементы здесь меньше Y.
Значит здесь какой-то старый список, потом Y, то есть все элементы из V меньше Y.
То же самое, наоборот, R находится правее Y, значит все элементы здесь больше Y, все элементы в R больше Y.
Значит так же все не раньше очевидно выполняются.
Ну и что мы получше сделали? Мы по сути взяли, просто склеили две вершинки.
Здесь теперь ровно 2t-1 ключ, да, магия чисел, было t-1, 3-1, мы их склеили и еще один добавили,
стало ровно 2t-1, максимально возможное количество, но все равно допустимо.
А в родителе стало на 1 ключ меньше, минус 1 ключ.
Ну и в родителе, поскольку мы так спускаемся сверху вниз и поддерживаем, что в каждой типу вершин хотя бы t ключей, мы можем так сделать.
Опять та же самая идея, если в родителе хотя бы t ключей, значит мы можем оттуда удалить один новый ключ.
Точно так же, как было в инсерте. В инсерте нам нужно было вставлять родителя, при условии, что он не заполненный, и это можно было сделать.
Здесь, наоборот, нужно удалять из родителя, но мы поддерживаем, что в родителе хотя бы t-1 ключи, значит так можно сделать.
Вот и все.
Так, ну и также здесь есть отдельный случай, когда родители это корень.
Так, давайте расскажу потом на вопрос, чей я отвечу.
Если родители это корень, то здесь нужно немножко аккуратнее рассудить.
Значит, вот у меня было v, вот у него был, скажем, правый брат, либо правый, либо левый, оба случая нужно разобрать.
И вот был, скажем, родитель, родители, являющиеся корнем.
Здесь, по сути, мы что сделали? Мы y утащили вниз, в нашей дочерней вершины v и r.
И в случае, если y был единственным ключом в корне, тогда на место старого корня нужно поставить вот эту вершину.
То есть, если y был единственным ключом в корне,
то, получается, я из корня удалил один единственный ключ, спустил его вниз.
Ну, значит, нужно просто удалить ту старую вершину и новым корнем назначить v, y.
То старый корень нужно удалить.
Старый корень нужно удалить.
А новым корнем назначить вот эту новую большую вершинку v, y.
Но опять все работает. Да, то есть, поскольку мы удалили корень и новым корнем назначили единственный его сына,
то получается, что глубина всех листьев уменьшилась на единицу.
Значит, если она у всех была одинаковая, то теперь тоже одинаковая.
Так, вопрос в чате.
Так, вопрос в чате.
к этому решение не будет очень плохо, если постоянно удалять элементы, вызывая разделение ячеек
и потом вновь добавляя в новую вершину, вызывая его разделение
есть постоянно удалять элементы, вызывая разделение ячеек
а потом вновь добавляя в новую вершину элементы вызывая его разделение
удалять элементы, это что значит?
удалять узлы или что? Ну, не будет плохо, короче.
Вам все равно нужно, как бы у вас было три вершины,
вам нужно сделать из них две вершины, то есть какие-то
две склеить и как-то что-то перетащить.
Но не будет плохо, потому что вы все равно работаете
с тремя объектами, каждый из них имеет размер O от T,
там можно просто их явно удалить, перестроить,
то есть как у вас должны выглядеть эти объекты вновь,
то есть после изменений и их положить на место старых.
В плане времени работы это все равно все,
то есть эта операция она линейна от размера узла,
от T все это занимает.
Поэтому ничего плохого здесь не вижу.
И, собственно, здесь не будет ничего плохого.
Итак, хорошо. Так еще вопрос в чате.
Итак, хорошо. Чего мы добились? Мы добились того,
что если мы спускаемся, если мы дошли до какой-то вершинки
и она не корень, то в ней хотя бы до ключей.
Это мы научились поддерживать.
Теперь это что? Мне нужно научиться удалять.
Извините, пожалуйста.
По инсерту.
Ну там...
Давайте.
Не по инсерту, а по...
Короче, что мы делаем, когда...
Короче, когда есть какая-то вершина,
у нее меньше либо равно, чем T-1 ключ,
и правого и левого брата не существует.
Такого не бывает. Такого не бывает.
Обязательно хотя бы один брат есть.
Окей, спасибо.
Так, вопрос в чате. Логерехмических сложно сохранить,
если будем рандомно удалять.
Ну, посмотрите, мы доказали раньше, на прошлый лекции с вами доказали,
что если у нас есть корректное B-дерево,
то его глубина логерехмическая.
А мы работаем...
Ну, как бы в наше время работаем в пропорциональной глубине.
Поэтому, конечно, у нас будет логерехмическая симпатика всегда.
Итак, значит, что мы... Чего мы добились?
Мы добились, что когда мы в поисках X,
который нужно удалить, шли по дереву,
вот как-то мы шли-шли-шли,
в итоге дошли до вершинки, которая либо корень...
Ну да, то есть мы нашли где-то X в какой-то вершине.
Тогда она либо корень, либо в ней хотя бы T ключей.
Либо корень.
Либо, оговорился, либо хотя бы T ключей.
Да, либо корень, либо хотя бы T ключей.
Так, хорошо.
Тогда дальше можно сделать следующее.
То есть, смотрите, если бы это был лист,
то опять было бы все идеально.
Мы просто удаляем X из этого списка, и все хорошо.
Это новый лист, в нем хотя бы T-1 ключ,
если это не корень.
И все хорошо. Для листа у нас как раз такой.
Но, к сожалению, это может быть не лист.
И тогда мне как бы нужно опять все это переделать.
Ну давайте сделаем следующее.
Давайте посмотрим на стрелке вокруг X.
То есть есть стрелка на левого сына,
то есть на числа меньше X.
Есть ссылка на правого сына, на числа больше X.
Давайте скажем следующее.
Давайте предположим, что в левом сыне хотя бы T ключей.
Пусть здесь хотя бы T ключей.
Тогда можно рекурсивно запуститься вот от этого поддерева,
найти в нем самый максимальный элемент,
просто максимальный элемент в поддереве.
Это мы знаем как делать.
Нужно просто каждый раз идти по самой правой стрелке.
И, собственно, вот самый последний элемент,
самым правым узлом, и будет максимальный.
И дальше что мы сделаем?
Мы как бы по сути этот максимум поставим вот сюда,
на месте X,
а максимальный элемент отсюда удалим.
То есть по сути как можно это представлять?
Если в левом сыне хотя бы T ключей,
то тогда давайте в нем мы найдем максимальный элемент,
вот это число.
Поставим его на место X,
тем самым X удалив.
А дальше запустимся рекурсивно вот в этого поддерева
с запросом удаления максимум.
Erase максимум.
Erase максимум.
И как раз, поскольку в этой вершине хотя бы T ключей,
мы опять поддерживаем наш вариант,
что если мы пытаемся что-то удалить из вершины,
точнее в поддере какой-то вершины,
то в текущей позиции нужно, чтобы было хотя бы T ключей.
И так будет верно по предположению,
если здесь хотя бы T ключей.
Тогда по сути у меня задача связалась
с удалением из листа, а такое мы уже умеем делать.
Если удаление происходит из листа,
то нужно просто поддерживать вариант,
что в текущей решении хотя бы T ключей,
потом дошли до листа и нужно просто данное число удалить.
То же самое,
если, скажем, левый листик,
левый сын у нас маленький,
но в правом хотя бы T ключей,
тогда нужно точно также найти
минимальный элемент здесь,
вот здесь, на той же глубине,
нужно найти здесь минимальный элемент,
скопировать его на место X,
а дальше запуститься от этого поддерева
с запросом resmin.
То есть мы знаем это число, нашли его просто спуском,
потом запускаемся от этого поддерева
с запросом удаления минимального элемента.
И опять, поскольку в этой вершине,
по предположению хотя бы T ключей,
мы можем так сделать,
то есть наша вся эта штука работает точно так же.
В случае, если в левом сыне
или в правом сыне хотя бы T ключей,
то мы начали решать задачу.
Теперь что делать, если это неверно?
Если в обоих сыновьях по T ключу,
по минимально возможному количеству.
Вот есть X, вот есть два указателя вокруг него
на левое и правое сына.
Кстати, я скажу,
что вот это похоже на наивное дерево поиска.
Наивное дерево поиска.
Потому что как мы делаем наивное дерево поиска,
мы, скажем, спускались в правое сына,
доставали там минимальное число,
копировали его на место X,
и по сути удаляли его из вот этого правого поддерева.
Ровно это мы здесь и делаем.
Взяли элемент, скопировали его на место X,
и дальше его удалили из дерева.
Теперь плохой случай,
когда в обоих сыновьях по теминственному ключу.
По теминственному ключу.
Тогда сделаем следующее.
Мы уже умеем объединять две вершинки,
спуская в них X.
Давайте слияние вершин.
Слияние вершин мы такое уже делали.
У нас есть уже процедура,
которая сливает две средние вершинки.
Будет следующее. Если левее X было C, правее было D,
то теперь в вождительской вершинке будет C,
а в дочерней вершинке
будет L, R,
разделенный X.
Мы просто взяли вот такую вот большую вершинку,
склеили это в одну,
L, X, R.
И вместо этих двух указателей
будет один указатель.
То есть вместо этих двух будет один вот такой.
Тем самым, что мы сделали?
Мы склеили две вершинки,
и наш X опустили на глубину 1 вниз.
И теперь, получается,
запускаемся опять рекурсивно от этого поддерева
с запросом удаления X.
Но теперь в этой вершинке опять,
в ней ровно 2T-1 ключ на самом деле,
но главное, чтобы в нем хотя бы D ключи.
И такой алгоритм
будет так делать.
То есть он будет видеть, что есть вершинка,
в которой находится X. Он опять смотрит на вот эти
две стрелки, исходящие из X.
Стрелка левее правее X.
И если в одном из сыновей хотя бы D ключи,
то он делает вот эту штуку,
которая здесь есть, либо максимум, либо минимум ищет.
И опять он склеивает двух сыновей,
спускает X вниз и так далее.
В итоге у меня X,
либо мы понимаем, что можно
просто взять максимум, поставить его на место X
и запустить за рекурсивно от одного из поддеревев,
либо мы спускаем X
на один уровень вниз
от D действий.
То есть мы склеим какие-то две вершинки,
перетаскиваем X, но главное, что у нас
глубина X увеличилась.
И так мы сделаем, суммарно, наше количество действий,
ну, количество шагов нашего алгоритма
будет пропорционально глубине,
потому что X просто спускается каждый раз
на единичку глубины.
Вот и всё.
Получается опять алгоритм
за T лог T.
В смысле T лог
N по основанию T.
Вот так.
Вот есть ли вопросы по кой-то кусочкам,
то есть на самом деле всё, мы с Razim разобрались полностью.
Хорошо.
Вроде как нет.
Итак, B-дереву мы обсудили,
Insert и Raz делать научились,
да, согласен, тут нет ничего простого,
тут много случаев, надо аккуратно с ним повозиться,
но вот, по крайней мере, с теоретической точки зрения
мы всё это обсудили.
И применение тоже поняли,
зачем это может быть нужно.
Хорошо, значит, тогда наше новое дерево поиска,
которое, думаю, многие из вас
уже знают,
со школы,
с олимпиадных кружков,
это декартовое дерево.
Декартовое дерево.
Как удалять из корня?
Ну, смотрите, мы умеем удалять из...
Вот, смотрите,
вот здесь, как мы дошли до вершинки,
в ней находится X,
что нам было нужно?
Либо что это корень, либо что в ней хотя бы так ключи.
Ну, опять, если в левом сыне хотя бы так ключи,
то мы запускаемся вот этой штукой,
RazMax, если в правом сыне хотя бы так ключи,
то мы запускаемся в этот X,
который с мимом в нем.
Иначе в этих двух сыновьях подойдет в своем ключу,
и что мы сделаем?
Мы взяли вот этот X, опустили его вниз,
и получается, ну, как бы,
из корня вытащили этот элемент,
и теперь вот этот наш новый ребенок.
То есть, по сути, корень ничем не отличается
от всех остальных вершинок.
То есть, точно так же мы перетаскиваем X вниз
и запускаемся рекурсивно от этой новой вершинки.
Здесь корень ничем не исключительный.
Смотрите, это опять-таки дерево поиска.
Дерево поиска.
Я напишу так.
Средняя глубина которого
средняя, скажем, ожидаемая.
Глубина которого
есть отлоган.
То есть, по горифму мы читаем все.
Мы отказываемся от нашей парадигмы,
что у нас очень большая база данных.
Давайте вернемся к нашим простым случаям,
типа AVL с плей-деревом,
когда все помещается в оперативку,
и мы спокойно с этим работаем, как всегда до этого.
Декартово дерево — это еще одно дерево поиска
наравне с AVL деревом и с плей-деревом,
которое имеет в среднем логарифмическую глубину.
Ну вот что значит средняя?
Это означает, что математическое ожидание глубины
логарифмично.
Значит, мат ожидания глубины.
Равно отлоган.
И это мат ожидания в том же смысле,
в каком мы говорили про мат ожидания,
когда говорили про, скажем,
QuickSort или QuickSelect.
Значит, вспоминаем QuickSort — это какой-то алгоритм,
который выбирает случайный пивот,
как-то делит, что-то как-то запускается.
И мы формулировали теорему без доказательств,
пока что, потому что мы не можем со случайностью работать
должным образом,
что этот алгоритм в среднем работает за нлоган.
То есть, грубо говоря, если вы его запускаете
на реально случайных пивотах,
то его время работы ограничено
констандов damn Logan.
То есть, просто работает всегда за нлоган,
на случайном наборе.
И если у вас реально случайность у Murakami генерируется,
то время работы будет от нлоган.
То же самое и здесь.
Здесь будет какая-то случайность.
И можно доказать,
что средняя глубина, то есть мат ожидания глубины,
будет логарифмическим.
То есть на практике, если вы реально будете
случайно генерировать то, что нужно исключать,
то ваша глубина будет очень редко отклоняться
то есть с Данельза смешной вероятности, Данельза маленькой вероятностью у вас будет то, что глубина будет
с сильным большим логарифом, и ей можно принимать пренебрегательную практику.
Ну так вот, это дерево поиска, но теперь у нас с каждым ключом, скажем, х, будет также ассоциирован некий приоритет y.
Значит, тогда вот декартовое дерево, давайте определение напишем, определение декартового дерева.
Это обычное двоичное дерево поиска по ключам, двоичное дерево поиска по ключам, которые мы будем обозначать х.
И куча с минимумом в корне, ну наша обычная куча, по приоритетам, которые мы будем обозначать y.
Значит, что это значит? Это значит, что у нас есть настоящие нормальные ключи х, которые вставляются, удаляются в наши множки,
про которые нужно сообщать, лежат они в множке или нет, и в пары к ним, то есть к каждому х, я еще в дополнение
генерирую случайный приоритет y. Вот эти приоритеты y мы будем случайно генерировать в программе.
Случайно сгенерированы для каждого х. То есть для каждого ключа свой приоритет сгенерирован,
и соответственно декартовое дерево строится как двоичное дерево по х, и при этом куча по y.
То есть каждый элемент теперь это, ну по сути, точка на плоскости x и y.
Точка на плоскости x и y, ключ запятая приоритет. Ну какой-нибудь пример давайте нарисуем.
Вот если я так расположу координатные оси x и y, то что получается?
Ну давайте я что-нибудь нарисую, потом задам координаты x и y, и вот что-нибудь такое, например.
Тогда, например, вот это будет точка там 10 запятая 3, то есть я сначала пишу x, потом y, как всегда.
То есть действие будет там 5, 7, 3, 10, 8, 14, и здесь что-нибудь в стиле там 20 запятая 5, 17 запятая 8.
Вот, например, это будет декартовый дерево. То есть смотрите, в принципе, существенная информация нам для ответа на наши запросы,
insert, erase и find, важны только вот эти x, 10, 5, 3, 8. Ну, короче, понятно.
Вот эти первые компоненты, они отвечают ключам. Это, собственно, то, почему мы делаем наши запросы, find и insert, erase.
Вот, а вот эти вторые компоненты, они просто искусственно, ну как мы их случайно геемим, 3, 5, 7, ну короче, вот эти числа,
вот эти числа, вторые компоненты, они случайно геемим на скрине ринка. Вот, ну и дальше, раз это дерево поиска по x и куча по y,
то получается в корне обязательно находится элемент с минимальным приоритетом, тройкой минимальных приоритетов.
Дальше, слева находится только элемент, у которых ключ меньше чем 10, да, то есть мы, по сути, можем проехать такую вертикальную прямую
и сказать, что слева, ну, как бы влевом по дереве могут находиться только элементы, у которых ключ меньше чем 10, да, x меньше чем 10.
Справа, наоборот, x больше чем 10, потому что все дерево поиска.
Ну и при этом они должны лежать ниже, чем на шкоре, не потому что у них должен быть больший приоритет, да, больший приоритет ниже 9.
Соответственно, здесь там 5, 7, соответственно, здесь ниже.
С одной стороны ключ должен быть меньше, чем 5, с другой стороны приоритет большим 7.
Это и выполняется здесь, ключ больше чем 5, но большим 7.
ключ 8 и приоритет 14. все. ключ больше чем 5 приоритет больше чем 7. вот и так
строится наше декартовое дерево. повторюсь, это дерево поиска по
иксам и куча по иксам. давайте сравниваем террорему еще раз без заказательства.
давайте сначала скажу так. давайте скажу упражнения на
семинар, что если все ключи все приоритеты
различны
все приоритеты различны
попарно различны, то декартовое дерево строится однозначно
декартовое дерево строится однозначно более того за линейное время
Более того, можно построить декартовое дерево по заданному набору х и у за от и при условии, что там у вас х посортирован.
И теорема, если в декартовом дереве все приоритеты изгенерированы случайно,
то раз они изгенерированы случайно, то с одной стороны, и считаем, что все ключи различны,
потому что у нас нет дубликатов в нашем множестве, то вероятность того, что среди случайно изгенерированных чисел будут два равных числа,
она, конечно, принадлежит мало. Если вы генерируете числа порядка от 1 до 10 в 9, и так 10 в 5 раз, то вероятность того, что у вас есть два одинаковых числа, то она, конечно, очень-очень маленькая.
Получается, что почти всегда у вас дерево единственным образом определено, значит, у него корректно определено глубина, если вы случайно все изгенерировали, то дальше глубина определяется однозначно.
Так вот, в таком случае математическое ожидание глубины декартового дерева нашего, давайте я напишу декартовое дерево, математическое ожидание глубины есть от логарифмы, от логарифмы.
Матоматическое ожидание глубины логарифмично порой.
Значит, чем декартовое дерево нам интересно? Оно интересно, я бы сказал, своей максимальной простотой. Давайте отметим ее плюсы.
Плюс – это простота в написании, мне кажется, это самое простое для написания дерева в сравнении со всем предыдущими.
Ну, минусы здесь очевидны, у нас все вероятностные, минусы все вероятностные.
То есть мы не можем ничего сказать про то, что наш алгоритм всегда работает не больше, чем два логен действий, потому что с какой-то вероятностью он может работать дольше.
Ну, это такой типичная проблема для вероятностных алгоритмов, что иногда они работают редко, да, очень редко, да, на практике этим можно поднимлечь, но все-таки по крайней мере в рамках теории про это нельзя забывать.
Итак, значит, в декартовом дереве базовыми операциями обычно называются плит и мерч.
Да, давайте.
Сначала мы просто для каждого х генерируем, а дальше устроим, да?
Да, да, у нас есть n ключей, n х, для каждого х случайно генерируем свой приоритет y, а дальше с вероятностью близкой к единице это дерево однозначно определено, да, потому что все приоритеты будут различны с большой вероятностью,
и раз дерево однозначно определено, то у него корректно определена высота, и им от ожидания высоты утверждается теоремой есть отлогарифм.
Так вот, значит, в декартовом дереве самые простые операции это split и мерч. Раньше мы делали все через insert и erase, давайте мы сделаем здесь наоборот, мы сделаем через split и мерч.
Значит, надеюсь на семинаре вы научились делать split и мерч для сплей дерева, если нет, то ничего страшного, мы сейчас это сделаем для декартов.
Значит, как сделать мерч и вообще что это значит? Это значит, что у вас есть два декартовых дерева, скажем, t1 и t2, причем ключи у них разнесены, то есть все ключи здесь, строго меньше, все ключи здесь.
Все иксы в левом дереве строго меньше всех ключей правого дерева. Вот пусть откуда-то у вас есть две такие декарты, тогда я утверждаю, что их можно довольно эффективно слить в одно большое декартовое дерево за время пропорциональной сумми глубин t1 и t2.
K это иксы в смысле? Да, да, ключи. Ключи иксы. Y и не важны, да. Ключи, иксы, key это все одно и то же. Y и не важны, главное, что ключи влево меньше, чем все ключи вправо.
Итак, значит, как работает мерч? Ну, по сути мы поняли, давайте считать, что у меня все ключи попарно различные, все приоритеты попарно различные, тогда декартовое дерево всегда корректно относится к определенному упражнению.
Тогда как оно может выглядеть? Ну, давайте посмотрим на наши вот эти вот два корня. Давайте скажем, что это точка A, это точка B. Соответственно, у каждой точки есть там x координаты, y координаты, то есть ключ приоритет.
Давайте поймем, кто из них может быть корнем. Ну, понятно, ровно та вершина, у которой приоритет меньше, да, потому что в корне, поскольку декарта дерева это куча по y, куча по приоритетам, то в корне обязательно должна быть вершина с минимально возможным приоритетом.
Ну, а раз A это вершина с минимальным приоритетом в своем дереве, B это вершина с минимальным приоритетом в своем дереве, то корень нового дерева это либо A, либо B, в зависимости от того, у кого из них приоритет меньше.
То есть, например, если A y меньше, чем B y, то A это новый корень. A это корень результата обязательно, потому что у него просто минимальный приоритет.
Ну хорошо, вот есть A. Мы понимаем, что это наш новый корень. Тогда в левом поддереве должны находиться все элементы меньше, чем A, а в правом все больше, потому что дерево поиска по x.
То есть, здесь должны быть все элементы, которые меньше по x, чем A, а справа все, которые больше по x, чем A.
Ну, тогда что за элементы, которые меньше по x элемента A? Это просто левое поддерево A, A.L, потому что только элементы, которые лежат в левом поддереве A, являются меньше, чем A, потому что правое поддерево больше, чем A, и здесь все элементы тоже больше, чем A по ключу.
А справа мне нужно каким-то образом передать информацию и о правом поддереве A, и обо всем дереве B.
Тогда давайте просто здесь в качестве правого сына подвесим merge A.right и B.
То есть, мы понимаем, что справа, поскольку это дерево поиска по x, справа мне нужно как-то объединить информацию о дереве B и о правом по дереве A, то есть спуститься вниз-направо и взять вот по дереву.
Давайте тогда просто запустим опять процедуру merge, которая нам склеит вот это вот поддерево вот с этим, и подвесим это в качестве правого сына.
То есть merge считаем, что возвращает какой-то указатель на корень нового дерева, мы взяли вот эти вот две штуки, склеили их в одно большое дерево и подвесили в качестве нового сына, нового правого сына A.
Вот и весь merge. Поняли, кто корень, склеили там нужные поддеревья и подвесили в качестве сына.
Вот это случай, когда AY меньше, чем B.Y. В противоположный случай очень просто также разбирается, если AY больше, чем B.Y, ну или больше или равно, можно формально написать.
Если равность, то понятно, что там уже неоднозначности возникают, но они возникают с вероятностью, стремяющейся к нулю.
А если у вас число денежного случания, то вероятность такая будет почти 0.
Так вот, тогда мы понимаем, что корнем должен стать, наоборот, B.
Окей, кто справа от него? Ну понятно правое под дерево B, потому что элементы, которые больше, чем B.X по ключу, они лежат только в правом под дереве B.
А слева должно лежать все A, а еще левое под дерево B.
Поэтому здесь должно быть мерч от A запятая B.Left. Нам просто взяли все элементы, которых ключи меньше, чем B.X, ну и склеили их в одно большое дерево.
С помощью той же самой процедуры мерч. То есть мы рекурсивно так спускаемся, объединяем нужные по деревьям и что-то там переподвешивает.
Вот такая простейшая процедура. Корректность следует, собственно, из того, что дерево однозначно определено, и мы каждый раз понимаем, что корень, понимаем, куда нужно отнести все вершинки влево или вправо.
То есть асимптотика O от суммы глубин depth, depth T1 плюс depth T2, потому что по сути я просто на каждом шаге либо спускаюсь вправо в дереве A, либо влево в дереве B.
Можно теоретически взять формулу, которая дает рандомные числа в заднем диагнозоне и никогда не повторяется.
Я не уверен, но на практике, если вам прям сильно хочется, чтобы все приоритеты были различны, наверное лучше сделать так.
Наверное, просто генерировать приоритеты, проверять новый приоритет или нет.
На практике скорее проще сделать так. Сгенерировать 3n или 5n приоритетов, посортировать, удалить дубликаты.
То есть если вдруг сгенерировались повторные приоритеты, то мы их удаляем, а дальше опять рандомно перемешиваем.
Если у нас количество запросов больше, чем длина диапазона, то такой формулы не существует.
Ну в частности, да.
Если меньше и нам не важно, настолько она случайна, то мы говорим, что она просто возвращает номер запроса.
Можно просто номера запросов перемешать все. Ну не номера запросов, а все x и y.
Тут много способов. Давайте считать, что реально мы просто генируем случайные y и с вероятностью почти ноль они могут совпадать.
Можно написать функцию балансировки и сказать, что если длина очень много раз превышает логарифм, то она вызывается.
А как перебалансировка работает?
Для этого мы все значения вкидываем сейчас.
Но тут получается множество, а потом, ну она за большую симпатику работает, поэтому вызывается только если большое превышение.
А дальше мы рассчитываем веса искусственно для каждого.
Я писал только для неявного ключа, когда лассив.
Да-да-да, я понял, но кажется это все равно не обязательно, ну то есть случайно.
Малая вероятность вызовется.
Еще вопрос, конец рекурсии. Да, конец рекурсии, я часто люблю опускать конец рекурсии, но конец рекурсии, когда a или b пусто.
Если a пусто или b пусто, тогда merge это соответственно второй из них.
А если a пусто, то ответ это b, если b пусто, то ответ это a.
Хорошо, merge обсудили.
Ну и поскольку, если мы знаем, что глубина обоих деревьев логарифмична, то точка тоже будет от логарифма, в среднем от логарифма.
Теперь переходим к операции split.
Я думаю, я немножко ускорюсь, потому что нам нужно еще неявно дерево как-то обсудить, вот давайте split обсудим.
Что такое split?
Split это процедура, которая по данному дереву t и ключу x разбивает это дерево на два дерева, извините, l и r.
Так что в левом дереве все ключи меньше и равны x, а в правом дереве все ключи больше x.
То есть, по сути, мы проводим вертикальную такую линию на нашей плоскости, как раз декарту, потому что на плоскости хорошо изображается.
А проводим вертикальную линию, все ключи, которые левее этой прямой, включая эту прямую, мы относим в одно дерево, все остальное относим в второе дерево.
И вот как работает split в декартовом деле.
Здесь опять давайте встанем в корень root нашего дерева t и сравним root.x с x.
Но давайте считать, что root.x, скажем, больше, чем x.
Это означает, что прямая разделение, разделяющая прямая, лежит левее root.x.
И наше разделение, наш split, по сути, разделяет только левое под дерево, а правое под дерево вообще не меняет.
Ну, потому что если вот эта вертикальная прямая находится левее корня, то, значит, она вообще не затрагивает наше правое дерево.
Потому что декартовое дерево, соответственно, все, что правее лежит, все в правом под дереве, лежит только справа от корня.
Вот, значит, можно запуститься рекурсивно от левого сына, здесь подразбить это дерево на a и b.
Дальше сказать, что a это l, а b подвесить к корню в качестве левого сына и сказать, что все вот это r.
Значит, давайте считать, что split возвращает l и r, то есть возвращает пару деревьев l и r.
Значит, тогда что здесь происходит? Как работает split?
Если root.x больше x, то давайте скажем, что пара ab это split root.l, то есть от левого под дерева с x,
с тем же ключом мы вызываем split. Дальше говорим, что root.left это b, то есть переподвешиваем b в качестве левого сына к корню,
ну и return пару abt root. То есть в качестве l мы возвращаем то самое a, все элементы, ключи, которых меньше, в общем, x.
А в качестве r мы возвращаем корень, поскольку у него теперь, ну то есть здесь был ключ больше x,
здесь опять в качестве левого сына опять все элементы, у которых ключ больше x, и здесь справа тем более ключ больше x.
Поэтому как раз root это будет корнем правого дерева.
Иначе, если картинка наоборот какая-то вот такая, давайте ее красным нарисуем.
Вот был корень, вот была разделяющая прямая, она находится наоборот правее нашего корня.
Извините, кто такой root.x?
Еще раз.
Кто такой root.x?
Ну смотрите, root это корневая вершина нашего дерева, а x это его ключ. У нас у каждой вершины есть ключ и приоритет.
root.x это ключ вершинки root.
А, все, извините.
Вот.
Значит, что здесь? Здесь нам нужно, наоборот, запустить со сплитом от правого сына, если вот это a это b,
то нам нужно a переподвести качество правого сына к root'у, и сказать, что вот это l и вот это r.
Здесь, да, иначе. Пусть опять ab это сплит, только теперь уже правого сына, root.r.x.
Дальше говорим, что новым правым сыном корня выступает a, и в качестве ответа возвращаем пару root, запятая b.
Потому что ключи меньшего равна x как раз лежат, ну, это по дереву корня, а ключи больше x, а это вот это b, который я вам уже прощитил.
Сейчас мы типа переподвешиваем все дерево за сына, за левого сына или за правого сына?
Ну, смотрите. Что?
Это очень наповорот, похоже, что мы делаем.
Нет, я бы так не сказал. Смотрите, переподвешивание здесь, на самом деле, только одно.
Смотрите, вот, например, вот в этом случае. Мы запустились от правого сына рекурсивно.
Что это значит? Это значит, что в конце нам выдали два дерева a и b. Это просто какие-то два дерева a и b.
Такие, что в дереве a все ключи меньше равны x, в дереве b все ключи больше чем x.
И дальше я просто вместо старого правого сына root'а подвешиваю a.
То есть тут даже нет никаких поворотов.
В конце нам выдали два дерева.
Да-да-да. То есть мы запустились рекурсивно от какого-то дерева.
Нам вернули пару a и b, и мы подвешиваем.
То есть тут b подвешиваем в качестве левого сына, а в качестве правого сына.
Вот такой опять-таки простой алгоритм. Корректность следует просто из того, что дерево единственное.
И вот эта веризикальная разделяющая прямая, она как раз находится либо левее, либо правее.
Асимптотика будет пропорциально приступлива.
Еще раз.
Как будет выглядеть дерево после операции?
Будет два дерева. Будет два несвязанных дерева LR.
Давайте чуть-чуть примерно нарисуем.
Давайте примерно нарисуем.
Сначала скажем, что глубина алгоритмична, потому что время работает в среднем алгоритме, потому что глубина алгоритмична.
Чуть-чуть пример давайте нарисуем.
Или давайте просто я промотаю назад и покажу вот это наше дерево.
Например, если бы я здесь вызвал сплит вот этого дерева по ключу key равному семерке, то как это выглядело?
Я выражу вертикальную прямую x равно 7.
Она выглядит как-то вот так.
Так что и будет сложно, но вот как-то так она выглядит.
То есть она слева оставляет вот эти две вершинки, потому что у них ключи 3 и 5.
А справа все остальные, потому что у них ключи больше чем 7.
Результат будет так.
Вот это будет левое под дерево L, а R будет вот это вот.
Только где эта штука подвесится к корму.
У меня же не может быть несвязанное дерево.
Я тут в рекурсии.
Когда вот это вот по дереву буду разбивать, у меня вот это вернется в качестве B, и я его подвешу в качестве левого сына к корму.
В итоге вот это будет правой компонентой R, а это будет левой компонентой L.
Все, у меня два несвязанных дерева.
Слева все ключи меньше равные чем 7.
Справа все больше чем 7.
Вот пример того, как это работает.
Хорошо, значит мы поняли, как делать split и merge.
Теперь давайте через них выразим insert и erase.
Через них insert и erase выражается очень просто.
Значит, как, например, сделать insert.
Insert, кого заключает x.
Вот было корректное какое-то дикартовое дерево.
Я хочу вставить ему x.
Давайте мы в пару с x сгенируем y.
Generate y.
Мы договорились, что если мы вставляем новый ключ, то у него должен быть новый случайный приоритет.
Давайте его сгенируем.
Дальше мы вызовем у старого дерева split по ключу x.
Соответственно, здесь будут все ключи меньше равные x, а здесь будут все ключи больше x.
Получается два дерева, LR.
Слева все ключи меньше равных, а справа все больше x.
В самом начале давайте проверим, что x в исходном дереве не было, потому что если он был, то вставлять нечего.
Значит, тут не просто меньше равные, а строго меньше, чем x.
А дальше нужно нарисовать дерево из одной вершинки с координатами x и y и запустить merge.
Если это новая вершинка v, нужно запустить merge lv, а потом еще эту штуку смержить с r.
Вот и все.
То есть мы посплитили так, что у нас как раз дерево разошлось на два.
И между ними вклиниваем новую вершинку x и y.
Потом склеим в нужном порядке.
Сначала l с новой вершинкой, потом результат с r.
Все.
Один сплит, два мерж.
Теперь как работает race?
Race x.
Давайте мы сначала посплитим по x.
Опять, да, сплит по x.
Сплит по x.
У меня будут два дерева.
В l ключи меньше равных x, в r ключи больше x.
Теперь мы понимаем, что этот x, ну опять, да, в самом начале давайте сделаем проверку, что x есть в дереве,
если его нет в дереве, то его ничего не нужно.
Иначе x есть в дереве.
И ну давайте вызовем вот в этом дереве сплит по ключу x-1.
То есть если у меня все числа целые, то можно вызвать сплит x-1,
и тогда единственное число, которое лежит в этом по дереве a и будет справа вот x-1,
это тот самый x.
Вот этот элемент выйдет мне в отдельные по дереву.
И будет получается три дерева у меня.
Там какой-то l штрих, будет отдельно x располагаться и отдельно r.
Потому что после вот этого сплита у меня как раз x отдельно высплесывает в отдельную вершинку.
Потом я эту вершинку удаляю, очищаю память и склеиваю lr.
Merge lr.
Все.
Два сплита, один merge.
И поскольку все эти товарищи и сплит и merge работают в среднем золотом рифе,
то и соответственно insert и res тоже работают в среднем золотом рифе.
Вот так можно реализовать все в дикартном деле.
В принципе, там есть процедуры, которые без merge и сплит это делают.
То есть insert и res можно реализовать без этих штук с merge и сплитом.
Там чуть более аккуратно нужно пройтись по дереву, понять, куда нужно вставить, что-то еще поделать.
Будет чуть эффективнее, чуть быстрее, но дольше объяснять и дольше писать.
А с точки зрения симптотики ни на что не влияет.
Поэтому давайте оставим так.
Вот.
И последнее, что хочу рассказать, это неявное дерево поиска.
Неявное дерево поиска.
Ну или, точнее, дерево поиска по неявному ключу.
Дерево поиска по неявному ключу.
Тоже надеюсь на синергию у кого-то было через сплит дерева.
Вот мы сделаем это сейчас через дикартный деле.
Ну что, идея очень простая, мы не будем хранить ключи.
Не будем хранить ключи.
Задача, которую мы хотим решать, например.
Задача такая, есть у вас массив какой-то A1, A2, и так далее, An.
И к нему поступают запросы трех типов.
Первый это insert какого-то числа вал на позицию pos.
То есть, скажем, нужно вставить число pos так, чтобы оно теперь стало...
Продолжно, нужно вставить число вал так, чтобы оно теперь стало pos.
То есть, там найти a pos минус первое, a pos, и между ними вклинить новое число вал.
Ну, короче, вставка в произвольное место массива.
Дальше, erase pos, то есть, удалить a pos.
И, наконец-то, найти сумму на отрезке.
Найти сумму с L по R.
Вставка в произвольное место, удаление из произвольного места и сумма на отрезке.
Так, если у двух элементов обычно дд совпали ключи, программа падает.
А у нас такого не будет никогда.
Поскольку мы поддерживаем, возможно, вы имели в виду приоритеты.
Но с ключами там нет проблем, потому что у нас не будет кратных ключей никогда.
Да, а приоритеты нет.
Там все нормально будет, просто будут неоднозначности, и, возможно, глубина будет чуть больше.
Ну, в смысле, она все равно...
Такое будет редко, мы дожидаем все равно логарифм.
Но нет, там все будет нормально, но просто она неоднозначно определяется.
Никаких проблем с этим тоже нет.
То есть, можно даже не париться.
На практике, когда вы пишете картовое дерево,
не обязательно следите за тем, что у вас все приоритеты по параметрам различны.
Просто их в случае генерите, и все хорошо будет.
То есть, там проблем не будет, просто редко такое бывает.
Такая задача.
Есть массив, вставка удаления в произвольное место и с произвольного места и сумма на отрезке.
Ну, давайте сделаем следующее.
Давайте мы откажемся от ключей.
То есть, неявно будем говорить, что вот каждое число массива...
Ключ у него, это его позиция в массиве.
То есть, этот элемент имеет ключ 1, этот элемент имеет ключ 2, и так далее.
Это пост минус 1, это пост, и так далее.
Но поскольку эти ключи, эти позиции будут меняться при вставках и при удалениях,
например, когда я вот здесь вставляю новый элемент,
у всех этих товарищей индекс увеличится на единичку.
Все ключи увеличатся на единицу, никим проходом.
Поэтому я ключи просто не буду хранить.
И в, скажем, декартовом дереве у меня каждая вершина В,
она будет характеризоваться следующими штуками.
Во-первых, вершина отвечает какому-то элементу, какому-то апосту.
Соответственно, я буду хранить это значение апостуя.
Дальше буду хранить случайный приоритет Y, как всегда случайный.
Дальше мне нужна будет сумма в поддереве, сумма ашек в поддереве,
чтобы находить сумму на отрезке.
И последнее, что мне нужно, это размер поддерева, размер поддерева.
И как бы не явно, раз я храню размер поддерева,
то по сути я все равно буду знать, какой номер у каждой, у каждой на вершинке.
Потому что что такое номер?
Это количество элементов, которые левее меня, ну скажем, там плюс один,
у второго элемента, левее него есть только один и плюс один, так и раз двойка.
То есть мне нужно знать, сколько элементов левее меня.
То есть это все левое поддерево.
Сейчас, не так.
Ну да, короче, номер каждого элемента, это просто количество точек в дикартовом дереве,
которые левее него находятся, если не упорядочно все по координату.
Мы хотим размер поддерева.
Еще раз.
Мы храним размеры и левые, и правого поддерева.
Ну нет, в каждой вершине просто сумма.
Просто суммарный размер всего поддерева.
То есть и левое, и правое, и еще вершинковое тоже учитывается.
Вот, значит, тогда как это будет устроено?
Как будет работать наш логеретик?
Ну давайте, во-первых, поймем, что мерч не меняется.
Не меняется, так как он не смотрит на ключи.
Так как он не смотрит, не смотрит на ключи.
Если мы вспомним наши ифы, которые мы делали в мерже,
то единственное, что там важно, это только приоритеты.
Ну а ключи, раз мы сказали, как у нас происходит мерч.
То есть есть какие-то два куска массива, да, левый, правый.
Мы говорим, что все элементы левого левее, чем все элементы правого.
И мы хотим их склеить ровно в таком порядке,
что сначала идет левый под массив, потом правый.
И когда мы их так склеим, просто с помощью того же мержа, который был раньше,
у меня как раз так и будет, что левее будут находиться все элементы из L,
правее все элементы из R.
И поскольку я не храню, не поддерживаю явным образом ключи,
то ключи это просто будет порядковый номер в этом дереве.
И как раз это и будет, они будут соответствовать индексам в моем массиве.
То есть мерж вообще никак не изменится.
Немножко поменяется сплит.
Но сплит теперь, давайте я напишу, что это будет split by size.
То есть раньше у меня был сплит по ключу, теперь будет сплит по размеру.
Дерево T и скажем какое-то число K.
Эта штука делает следующее.
У вас есть дерево с каким-то большим количеством элементов.
Давайте первые K элементов у вас пойдут в левое дерево,
а все стороны в правое.
То есть эта процедура откусывает первые L элементов из нашего дерева.
Да, X нет, ключей нет, X нет.
Они как бы не явно высчитываются через размеры поддеремов.
Итак, как делать сплит по размеру, по количеству K?
Давайте тоже картинки порисуем.
Если у левого поддерева корня размер поддерева хотя бы K,
то есть если здесь хотя бы K-вершин,
тогда вот эта линия разреза точно проходит где-то в этом левом сырье.
Итак, если root.L.Size больше равно K, root.L это левый сын.
И если у него в поддереве хотя бы K элементов,
значит линия разреза будет проходить где-то в левом сыне.
Тогда давайте мы опять посчитаем рекурсивно сплит root.L запятая K.
Высплитим из левого сына нужные мне две штучки LR.
Дальше скажем, что root.L это B, ну и соответственно return A и root.
Точно так же как у нас было в обычном сплите A и root.
Иначе линия разреза находится правее корня.
То есть все что левее, здесь слишком мало элементов, здесь меньше чем K элементов.
Поэтому все вот это мне нужно точно отнести в левое поддерево,
а здесь высплитить K-root.L.Size-1 элементов.
Вот что мы напишем. Мы напишем, что AB это сплит root.R.
Вот здесь меняется параметр. Здесь будет K-root.L.Size-1.
Потому что смотрите, вот уже столько элементов я уже поместил в левое поддерево.
Я понимаю, что это будет в L, а значит отсюда мне нужно привести только вот столько.
Потому что тогда в сумме они будут давать ровно K.
Ну и тогда я делаю root.R равно A и return root.B.
Я опять переподвешиваю эту штуку сюда. Это будет L, это будет R.
Какое слово основано в K-рекурсии?
То же самое. Если я пытаюсь посплитить пустое дерево,
то нужно вернуть пару пустое дерево, запятая пустое дерево.
То есть если сплитить нечего, то у нас остановка только если одно из деревьев пустое.
Если текущий дерево T пустое, то нужно вернуть на L,P,R.
Ну и тогда что? У нас будет как решать нашу исходную задачу.
Давайте я здесь немножко проговорю быстро.
Как я вот инсерт в данную позицию pos?
Давайте мы запустим split by size pos-1.
И тогда наш исходный массив разведется на два.
Слева будет первый посплитцовый элемент, а справа будут все остальные.
Вот это у меня будет два декартовых дерева, как раз левая половинка, правая половинка.
Я завожу новый элемент вот сюда, вставляю его.
Соответственно у него там новое значение вал, новый приоритет.
Ну там сумма ашек тоже, короче, своя и так далее.
И делаем мерч. Просто мерч этих трех деревьев.
То есть мы смогли вставить в нужную позицию.
Дальше arrays. Если нужно сделать arrays, то мы тоже самое.
Мы посплитили нужным образом.
Потом высплитили опять тот элемент, который нужно удалить.
Вот эта вот апостая.
И склеили два дерева без учета pos.
Но чтобы найти сумму...
Попробуйте уже сами додумать.
Если в каждой вершине поддерживается сумма ашек,
то тогда чтобы найти сумму на отрезке с l по r,
давайте мы высплитим сначала элементы с первого по r.
Потом отсюда, с помощью еще одного split by size,
высплитим отрезок с i по ar.
И с помощью этого дерева будет находиться в точности сумма всего этого под деревом.
Если в каждой вершине хранится сумма ашек под деревом,
то после сплита, после двух сплитов,
у вас будет вершина, целиком отвечающая отрезку l.
Вы знаете на нём сумму.
Печатаете этот ответ.
А дальше обратно всё склеиваете,
так чтобы ваш декартный деревьев был такой, как был изначально.
Вот так всё работает.
То есть с помощью вот такого неявного декартного дерева
или неявного сплея дерева,
любое дерево, которое позволяет делать split и merge,
такие задачи.
По сути, у вас есть динамический массив
со вставками и ударениями в произвольное место.
А также подсчетом каких-то сумм на отрезке и чего-то подобное.
Вот, тогда на сегодня всё.
Спасибо за внимание.
А сумму, кажется, причитываем как-то?
Что-что?
Сумму, кажется, причитываем, когда оставляем новый элемент.
Ну да, на этом просто причитывается.
Просто если аккуратно проследить, что у вас меняется,
у вас по сути просто у вершинки может поменяться там правый сын.
Если был какой-то старый правый сын, не знаю, там alt,
у вас как бы переподвешивание на правого сына,
тогда как меняется сумма?
Ну, у вас левый сын, скажем, остаётся.
Нужно учесть ашку, которая находится в этом элементе,
и прибавить сумму из этого.
То есть там всё просто причитывается.
Если в каждом решении хранить,
понимать, как всё переподвешивается,
в нужном образом нужно просто складывать нужные числа,
и всё получится.
Да, ну вот сумму кратко.
Если я в каждом решении вот это поддерживаю,
сумму ашек в под дереве,
то, звалили ли сюда сумму в под дереве,
conclusions days we have,
а тамerna이나 и oleh?..
Надо просто проследить, что меняется в нашем дереве.
По сути просто какие-то ребра удаляются,
какие-то появляются.
Но если я в каждом поддерervе знаю сумму,
скажем, я знаю сумму здесь, знаю сумму здесь,
и знаю, что あ это ребро удалилось ideology уробило такое.
Значит, сумма в этой верш dugga извинилась на минус вот это
плюс вот это.
books как-то что-то удали until добавилось.
Так, а у вас в SplitBySize просто непременно написано Return Root, он же, как сказать, просто Root.
Сейчас, секунду. Где, где?
Вот у вас там, объясни, просто Root, запятая B, просто это не чей-то должен быть?
Нет, ну как, SplitBySize, это же, не нужно же два, два дерева вернуться.
Левое дерево определяется корнем Root, правое определяется корнем B, вроде все хорошо.
Ну так же, как у нас было в сплите, мы посплитили на два кусочка,
левый кусочек это дерево с корнем Root, а правый кусочек это дерево с корнем B, все хорошо.
SplitBySize он за логарифмом в квадрате работает?
Нет, просто логарифм, это же тоже спуск, это все логарифм, конечно, потому что это просто спуск.
То есть каждый шаг, либо мы вправо спускаемся, либо влево, ну вот влево или вправо,
поэтому суммарное количество запусков, это глубина просто логарифмическая.
