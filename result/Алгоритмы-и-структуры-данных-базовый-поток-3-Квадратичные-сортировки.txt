Вот мы с вами познакомились с понятием массива.
У нас, соответственно, разблокировались какие-то новые возможности по алгоритмам.
Когда мы говорим про какой-то массив данных, про какой-то набор значений,
то первая задача, самая классическая задача, которая в этой связи решается,
это, естественно, задача сортировки.
Задача просто-напросто упорядочивания элементов в порядке возрастания
либо в порядке убывания.
Maintenant по этому интересу надеюсь я никому не удивлю.
Если скажу, что задача сортировки, это просто задача поиска такой перестановки,
которая превращает ваш исходный массив, в котором элементы не упорядочены,
в массив, в котором все элементы идут в порядке не убывания.
То есть нулевой элемент массива не больше фирмы,
первый элемент не больше фирмы, ну и так далее.
При этом под упорядочением я понимаю произвольное упорядочение,
которое задается некоторым линейным порядком.
а если элементы отсортированных в порядке возрастания, то это обычная операция меньше.
Если, соответственно, элементы у меня идут в порядке убывания, то это обычная операция больше.
Ну и так далее. То есть порядочнее может быть абсолютно произвольным.
То есть просто напросто которое задается какой-то специальной операцией.
Так, соответственно, наша цель на ближайшие лекции это познакомиться с зоопарком классических алгоритмов
для работы с сортировкой и вообще для решения задачи сортировки.
Значит, сегодня мы сосредоточимся в основном на самых простых алгоритмов,
которые называются козротичными сортировками.
Ну и сегодня наш сегодняшний план состоит из того, что мы рассмотрим с вами сортировку выбором,
сортировку вставками, сортировку пузырьком.
Ну поговорим, возможно, про некоторые модификации, про их преимущества,
преимущества по сравнению с более быстрыми сортировками.
Ну и так далее.
Пословка задачи понятна.
Можем начинать. Окей, супер. Давайте поговорим про первую сортировку, сортировка выбором.
Давайте напишем какой-нибудь массив. Вот у меня есть некоторая последовательность.
Вот у меня есть некоторая последовательность элементов. Допустим, 3, 5, 1, 2, 4.
Необходимо сделать так, чтобы этот массив был отсортирован.
В чем заключается сортировка выбором? Давайте просто возьмем.
Во-первых, мы будем поддерживать два состояния.
Вот у нас есть массив, и давайте поддерживать массив в двух состояниях.
Состояние слева будет хранить элементы, которые уже отсортированы.
То есть наименьшие элементы, которые уже отсортированы.
А массив справа, его правая часть, будет хранить еще не отсортированные и не рассмотренные элементы.
Изначально у меня массив состоит из двух частей.
Пустая часть, которая уже отсортирована, пока ничего не отсортирована.
и соответственно правая часть, которая не отсортирована.
На самом деле можно это расширить. Давайте лучше так скажем, что у меня есть один элемент,
который отсортирован, и оставшийся 7-1 элемент, который не отсортирован.
То есть согласны, что один элемент всегда отсортирован. Уже круто, уже можно от чего-то отталкиваться.
Пустой массив отсортирован. Тут не отсортирован. Я с другой сортировкой перепутал.
Пока у нас ничего не отсортировано. Давайте выполним следующий шаг.
Сортировка выборов делаем следующую штуку.
У нас есть отсортированный массив. Допустим, его как-то получили.
Какой элемент стоит на первом месте? Минимальный.
Давайте проведем по неосортированной части и найдем минимальный элемент.
Просто проведем 3,5,1. На ходе минимальный элемент.
Раз мы нашли минимальный элемент, то мы точно знаем, где он должен находиться.
он должен находиться на нулевой позиции массива, да?
Все, мы прошлись по всей неотсортированной части,
нашли минимальный элемент,
и давайте его возьмем и поставим на первое место,
вот сюда, в самое начало.
Ну Кеорж, мы просто возьмем, например, вот этот элемент
и обменяем с этим местами.
Сюда запишем единицу, сюда запишем тройку.
Нормально?
Все, я получил единицу, и теперь я точно знаю,
что левая часть, ну как минимум,
состоит из одного элемента, который уже отсортирован.
То есть единица точно стоит на своем месте, да?
Все, таким образом, я увеличил отсортированную часть
на единицу, а неосортированную
уменьшил на единицу.
Что я буду делать дальше?
Дальше снова Рассмотрю неосортированную часть
и спрошу сам себя.
А какой элемент должен идти за единицей?
ve, Antonik.
Да, должен следующим за единицей
должен идти следующий по минимальности элемент.
Так как сам минимальный элемент у меня уже стоит здесь,
то, соответственно, мне осталось в этом массиве,
в неотсортированную части,
Всё, снова иду лево-направо, ищу минимальный элемент, и вставляю его на ту позицию, на которую он должен стоять.
2, 5. Увеличиваю отсортированную часть, не отсортированная часть уменьшилась. Всё. Ну и так далее.
Окей? То есть сортировка выбора, по сути, на каждой итерации, на каждом шаге делает выбор минимального элемента.
Нашли минимальный элемент, вставили на своё место. Нашли следующий минимальный элемент, вставили на своё место. Всё.
Вот такая простая идея. То есть в каждом именовании у нас массив разделён на две части – отсортированную и неотсортированную.
Дальше в неотсортированную часть ищу минимум и добавляем в finite в отсортированной части.
Таким образом, увеличивая отсортированную часть и уменьшая неотсортированную часть.
Ну и продолжаем эту операцию до тех пор, пока весь массив не станет отсортированным. Нормально?
Кажется, что звучит очень просто. Ну и реализуется очень просто.
очень просто. Что мы делаем? У нас дан массив А, и соответственно в цикле мы перебираем набира
не отсортированного элемента, то есть перебираем позицию, на которую будем вставлять очередной
элемент. То есть очередной элемент будем вставлять в эту позицию. И соответственно внутри этого цикла
просто-напросто ищем индекс минимального элемента. Изначально говорим, что индекс минимального
элемента совпадает с этим элементом. Дальше, соответственно, продвигаемся вперед. Вот,
как только нашли элемент меньший, обновляем индекс минимального элемента. То есть если очередной
элемент g меньше, чем минимальный элемент, говорим, что минимальный элемент находится в позиции g.
Все, после внутреннего цикла у нас IDXmin указывает на минимальный элемент в не отсортированной части,
согласны? Ну все, остается только взять этот самый минимальный элемент, в данном случае это тройка,
и обменять с элементом, который стоит вот не на своем месте. Нормально? Так, ну тут соответственно есть
некоторая задачка, точнее три задачки. Вот, то есть расставить пропуски. До каких пор, то есть какой у нас
концевой элемент для этого индекса? То есть мы идем по i, с нулевого элемента по какой, и позже мы идем
с i плюс 1 элемента по какой элемент? То есть что там нужно расставить вместо многоточий?
Так, значит есть два варианта, я слышу, n-1 и n-2. Кто за n-1?
Окей, кто за n-2? Хорошо, обосновывать, почему n-2? Да, смотрите, действительно, мы идем, то есть
на какие места мы вставляем наши элементы? Элементы мы ставим на нулевую позицию, на первую
позицию, вторую позицию, третью позицию, ну а вопрос в следующем. Вот, допустим, у меня есть отсортированная
часть, состоящая из n-1 элемента, и тут стоит один элемент не отсортированный. Ну что я знаю про
этот элемент? Да, этот элемент ни разу не был минимальным, но, соответственно, он наибольший,
он уже стоит на своем месте, поэтому с ним ничего не надо делать, поэтому достаточно пройти по массиву
n-2 раза. Окей, так, что дальше? Ну, точнее, до индекса n-2. По g, до каких пор мы идем индексом g?
From i plus 1 to, до каких пор? До n-1 индекса, почему до n-1? Да, потому что мы ищем минимальный
элемент, ну и минимальный элемент, в принципе, может находиться в любой позиции, да, то есть он
может находиться как здесь, так здесь, так и здесь, то есть самый последний элемент мы обязаны тоже
смотреть, поэтому последний индекс должен быть n-1. Ну и последний вопрос, который остался, вот там
есть какая-то загадочная процедура swap. Своп значений x и y. Что делает swap? Своп просто берет
две переменные и обменивает их значениями местами, то есть в x записано значение y, в y записано
значение x. Как это реализовать на языке c++? Что? Встроенная функция есть, но пока мы реализуем
все вручную. А плюс равно b? А плюс равно b? А если мы, простите, сортируем строки? Да, но обмен
классически пишется с помощью использования третьей переменной, мы во временную переменную сохраняем
значение x, вот, в x записываем значение y и в y записываем значение временной перемены. Ну, давайте
как это выглядит, вот есть x, в ней есть, допустим, значение 0, есть y, в нем значение единица, вот,
записываем временная, есть временная переменная. Во временную переменную записываем значение 0,
вот, дальше в x записываем значение y, единица, и в y записываем значение временной переменной
обменной отсюда. Вот таким вот образом осуществили обмен, все, ну окей, окей, да, ну это понятно, это псевдокод, мы тут не вдаваемся в детали в t++, вам, кажется, на одной лекции говорили, что мы используем псевдокод, но просто для сокращения записей, и так далее.
Так, нормально? Ну и давайте поговорим про время работы, про время работы этой сортировки, почему эта сортировка называется квадратичной.
Ну, соответственно, как правило, когда мы говорим про алгоритм, мы рассматриваем худшие случаи, потому что в контестах встречаются именно худшие случаи.
Соответственно, что мы делаем? Ну, смотрите, на самом деле все очень просто. Мы для каждой позиции, для каждой позиции, ищем минимальный элемент из оставшихся части.
То есть, когда мы ищем минимальный элемент, когда мы ищем минимальный элемент, мы выбираем этот минимальный элемент среди всего доступного нам массива.
То есть, по сути, мы делаем n шагов, чтобы найти самый минимальный элемент.
После того, как мы вставили самый минимальный элемент, мы теперь ищем следующий по минимальности элемент в оставшейся части массива.
Оставшаяся часть массива состоит из n-1 элемента. Согласны?
После того, как мы вставили второй элемент, у нас остался массив размера n-2, среди которых мы снова ищем минимальный элемент.
Ну, и так далее.
Почему равна сумма арифитической прогрессии?
Ну, типа n на n-1 пополам. Ну, на самом деле, можно просто сказать, что это t от n-2.
С точности до константы эта штука пропорциональна.
Эта штука пропорциональна n-2.
Ну, то есть порядок роста вот этой вот функции, которая стоит слева, это порядка n-2. Согласны?
Все. То есть как бы минимальное количество операций, которые мы потратим в данной сортировке, равно n-2.
Ну и, собственно, максимальное количество операций тоже пропорционально n-2.
В целом, с этой сортировкой, наверное, все. Понятно? Отлично.
Ну, давайте теперь поговорим про другой вид сортировки.
Соответственно, все сортировки довольно простые.
Давайте оговоримся так, что любая сортировка в лучшем случае работает за утверждение математическое.
Любая сортировка в лучшем случае работает за n.
Доказательства. Давайте пройдемся по массиву. Если он уже отсортирован, то закончим работу.
Ну, такие простые случаи мы не рассмотрим, мы все-таки рассмотрим вот именно вот саму суть, да, саму мягкую алгоритму.
Окей? Нормально? Вот. Окей.
Так. Следующий алгоритм – сортировка вставками.
Ну, давайте традиционно обсудим идею.
Так. Вот идея теперь такая же, как я вот пытался объяснять до этого.
Вот. Давайте побольше.
Так. Ну, допустим, 4, 2, 3, 1, 5.
Значит, снова, как и в предыдущем алгоритме, мысленно разделим массив на две части.
Хороший и плохой. То есть отсортированный и не отсортированный.
При этом мы начнем вот с такой вот.
Значит, эта часть уже отсортирована, эта часть не отсортирована.
Так. Что мы будем делать?
Давайте возьмем первый элемент из не отсортированной части.
Вот этой.
И вставим его в отсортированную часть на свое место.
Вот, допустим, у меня есть какая-токої-то отсортированная часть.
есть какая-то неотсортированная часть, я взял элемент x, ищу на каком месте он должен стать,
и вставляю его на это место. Тем самым у меня отсортированная часть увеличивается,
неотсортированная часть уменьшается. Согласны? Вот такая вот...
Давайте на примере... Давайте приведем пример. Вообще говоря, найти его место довольно-таки
просто. Давайте сначала на абстрактном примере, потом на конкретном. Вот у меня есть элемент x,
и есть элемент, который стоит перед ним. Как понять, стоит ли x уже на своем месте или нет? Да,
сравнить этот элемент с предыдущим, согласны? Если x меньше, чем предыдущий элемент, то все плохо.
Что нужно сделать? Нужно просто обменять его с вот этим элементом, то есть обмениваю их местами.
Все, окей, x стал на это место. Теперь обмениваю x с предыдущим элементом. Если x стал больше,
чем предыдущий элемент, то все нормально, я нашел x свое место. Почему? Потому что он меньше,
чем те, которые идут за ним, и больше, чем те, которые идут слева. Согласны? Но если он меньше,
чем предыдущий, то снова обмениваю с ним и так далее. Давайте на примере. Давайте тут напишу 1,
4 и 5, а тут стоят элементы 3 и 2. Вот это уже отсортированная часть, а это не отсортированная
часть. Я пытаюсь сделать 3 и вставить его в нужную позицию, в отсортированную часть. Давайте
вспомним 9, 0, meta-к judging. Обменилась 5, 4 и 3, поэтому проставляем дажеün't cosine.
Смотрите, мы на 3 и et. И pike appears. 834. Трое asynchronous Monosizada.
Вот fuck happened. videotape you can't even read it.
Все, смотрите, вот тут у меня все элементы обязательно меньше тройки, а тут все элементы гарантированно больше тройки.
Ну все, тройка встала на свое место. Понятно?
Мы обязательно применим, но потом.
Да, тут очень хорошо, что вы видите сразу, что тут есть место для улучшений, то есть действительно можно применить бинпоиск.
Правда, принципиально мало что изменится, но про это будет.
Пока основной алгоритм понятен, да, что мы делаем?
Ну вот, собственно, в каждом момент времени массив определенной части, отсортированную и не отсортированную,
возьмем первый элемент из не отсортированной части и вставим его в отсортированную.
Соответственно, псевдокод тоже выглядит очень просто.
Ну, собственно, ровно то, о чем мы и говорили.
То есть проходимся по индексам И с первого по N-1, почему с первого?
Потому что любой элемент уже гарантированно стоит, грубо говоря, один элемент уже составляет отсортированный нормальный массив.
Все, поэтому берем первый элемент, пытаемся его вставить в массив из одного элемента, который идет слева.
Заводим счетчик G, G будет хранить себе элемент, с которым мы сравниваем наш текущий элемент.
Все, и говорим, что пока мы не вышли за границу массива, то есть пока G больше 0, больше либо равно 0,
и пока G, пока предыдущий элемент больше, чем текущий элемент, мы обмениваем их местами.
Все, обменяли их местами, G уменьшили на единицу.
Ну и так далее, продолжаем до тех пор, пока в цикле условия выполняются. Понятно?
Нормально?
Так, окей.
Ну, примеры, соответственно, на досуге. Вспорить, мы вроде как примеры забрали.
Достаточно? Все, супер.
Так, давайте снова поговорим про asymptotic. Тут, на самом деле, все довольно-таки просто.
Давайте снова рассмотрим какой-нибудь худший случай.
Чему тут равен худший случай? Ну, смотрите.
Вот, допустим, у меня какая-то такая ситуация.
У меня есть начальный кусок размера i и неотсортированный кусок размера n-i.
И есть элемент x. Соответственно, что я делаю?
Я беру этот элемент x и обмениваю с предыдущими так, чтобы он стал на свое место.
Сколько шагов в худшем случае мне придется сделать для x?
И да, почему? Потому что в худшем случае x меньше, чем все элементы отсюда.
Поэтому, соответственно, мне придется его поменять местами с этим элементом,
с этим элементом, с этим, с этим, с этим и так далее.
То есть в худшем случае вот в такой ситуации я сделаю, ну давайте так, θ от i шагов.
Шагов в худшем случае. Вот.
θ от i.
Ну и давайте все просуммируем.
Соответственно, в начальном этапе, то есть у меня i идет от единицы до n-1.
Ну и, соответственно, давайте я просто просуммирую.
1, то есть на первом шаге я сделаю в худшем случае 1 шаг,
на втором шаге сделаю 2 шага, на третьем 3.
Ну плюс и так далее. Плюс n-1.
Ну, соответственно, не буду тянуть, просто это у большое, ну, θ от n квадрата.
Ну опять же, сумма арифитической прогрессии там от 1 до n-1 или до n,
неважно, все равно в симптотике получается n квадрат.
Это понятно. Ну, про симптотики, я думаю, уже поговорили достаточно.
Окей.
Значит, это что касается худшего случая.
Вот.
Кажется, на первой лекции вы должны были еще говорить,
ну или там на первой, на второй вы должны были говорить еще про среднее время, да?
Вот. Говорили же?
Вот. Давайте на примере сортировки вставками
рассмотрим время работы в среднем.
Так.
Смотрите, в чем тут идея.
Идея заключается в следующем.
Значит, допустим, нам данный не худший случай,
допустим, наши данные приходят просто из случайного распределения.
Из случайного распределения на всех массивах.
Ну, допустим, массив просто каким-то образом равновероятно перемешан внутри себя.
Понятно дело, что если массив как-то равновероятно перемешан внутри себя.
Вот есть элемент x.
И тут всего и элементов.
То возникает вполне себе резонный вопрос.
А на какое место, с какой вероятностью может стать элемент x?
Ну, смотрите, если массив перемешан равновероятно,
то X равновероятно может стать как на максимальное место,
как на максимальное место, так и на второе место, на третье, четвертое и так далее.
Согласны, да?
То есть если у меня нет никаких априорных знаний о том, как устроен мне массив,
то если я заранее не знаю в принципе про устройство массива,
то в принципе элемент x может стать как на первое место отсортированного массива,
на второе, на третье и так далее.
И при этом все возможности равновероятны.
Окей?
Тогда что я могу сказать?
Я могу сказать следующее.
Что?
На и-том шаге среднее время работы...
Ну, что значит среднее?
Давайте так, чисто с обыденной точки зрения, что значит среднее.
Ну, допустим, я провожу эксперимент, сколько в среде у меня работает алгоритм.
Что я для этого делаю?
Я беру мой алгоритм и соответственно, как-то его случайно перемешиваю,
запускаю мой алгоритм, измеряю время,
потом снова как-то его случайно перемешиваю, снова сортирую, измеряю время
и так далее.
У меня получается некоторая выборка, некоторый набор значений.
Дальше я просто-напросто суммирую все эти значения и делю на количество запусков.
Это. Oppose есть мое среднее время. Согласны?
То есть сколько в среднем?
То есть это то же самое как с броском кубика.
Я бросаю кубик, он выпадает двойкой.
Бросаю кубик, выпадает четверть и так далее.
Я складываю все значения кубиков и считаю,
какое значение в среднем не выпадало. Понятно? Тут тоже самое, только с числом шагов.
Так, ну смотрите, элемент x может стать на одну из следующих позиций. Он может стать на
позицию под номером 0, а он может стать на позицию под номером 1, 2, 3, ну и так далее и. Согласны?
Вот. Соответственно, при этом что я получаю? Так, возможная позиция. Теперь, количество действий
с x. Если x может стать на любую позицию 1, 2, 3, какое количество действий мне для этого нужно
будет выполнить? Смотрите, чтобы х стал на нулевую позицию, мне нужно выполнить, ну, примерно,
и действий, согласны? Чтобы х стал на первую позицию, мне нужно выполнить примерно и-1
действие. Чтобы х стал на вторую позицию, мне нужно выполнить и-2 действие. Ну почему?具ить
количество обменов. Согласны? Нормально? Всё. Ну и так далее и, до единицы. Вот, а теперь смотрите,
Скажите, с какой вероятностью у меня х станет в нулевую позицию
в первую позицию, во вторую позицию, в третью и так далее?
Какая вероятность станет в третью позицию?
1por I OuiSieGl 감사합니다.
1pres e1i per plus 1 согласны?
В всего позиции доступных у меня а и плюс 1向 каждая позиция равна вероятно.
Что это означает?
Это означает, что
с какой вероятностью я сделаю и действий.
с вероятностью 1 по u и плюс 1
с той вероятностью я сделаю и минус одно действие тоже с вероятностью 1 на и плюс 1
и так далее. Что это означает? Это означает, что среднее количество действий на
этом шаге равно следующему. 1 на 1 плюс i и плюс 1 на 1 плюс i умножить на
и так далее, и плюс 1 на 1 плюс i умножить на ноль. Согласны? То есть и действие я выполняю с вероятностью
1 на 1 плюс i. Давайте и плюс 1 везде писать. Да-да-да. Это количество элементов слева. Вот и. Вот.
То есть и действие я выполняю с вероятностью и плюс 1, и плюс одно действие я выполняю с вероятностью
и плюс с вероятностью 1 на и плюс 1, ну и так далее. Ну согласны ли вы, что с помощью, что вот так я
посчитаю краски среднее число, да? Нормально? Вот. Ну и что получится? Так. Не-не-не. То есть я
выполняю и и шагов, либо и минус один шаг, либо ноль шагов. Да. Да, у нас и плюс один вариант,
но скажем, смотрите, чтобы попасть в конец, мне нужно и шагов. Чтобы попасть на первую позицию,
мне нужно и минус один шаг. И так далее. Чтобы попасть в конец, ну мне, по сути, ничего не
нужно делать. Ноль шагов. Да. Смотрите, тут давайте так, два момента. По порядку. Вот есть такая
конфигурация. Массив абсолютно случайен. Рандомный. Вот. Ну равный, причем все элементы могут
стоять на всех местах равновероятно. Я вас спрашиваю, вот х. С какой вероятностью он станет в третью
позицию? Ну один на и плюс один. Всего вариантов и плюс один. Соответственно, он станет в позицию
номер 30, с вероятностью один на и плюс один. Так? Так, теперь, если х должен встать в третью
позицию, то сколько действий я при этом должен сделать? Ну, кажется, и минус три, да? Ну все,
вот тут я как раз-таки считаю, что чтобы встать в нулевую позицию, мне нужно и действий. Это
происходит с вероятностью и плюс один. Чтобы встать в первую позицию, мне нужно и минус одно
действие. Это происходит с вероятностью тоже и плюс один. Ну и так далее. Я суммирую,
все, ну происходит такое усреднение. Согласны? Нормально? Все, ну и что получается? У меня есть
общий множитель и плюс один, один на и плюс один. Вот. И, соответственно, сумма по и дает мне и на
и плюс один пополам равно и пополам. Вот. Ну кто бы сомневался, казалось бы, да? То есть в среднем
на и-том шаге я делаю и пополам действий, да? Ну а теперь давайте просто просуммируем по всем
шагам. Всего у меня шагов и от единицы до n минус один и пополам. Ну, кажется, ничего не
меняется. Это есть все еще от n квадрат. Да? Ну, одна вторая, это как константа, ее там на нее
можно забить. Дальше, если я просуммирую все и от единицы до n минус первой, то я получу как раз-таки
порядка n квадрат. Н минус один на n пополам. Согласны? Да. Согласны? Все. Ну то есть в целом неважно,
как вы оцениваете сортировку вставками, там неважно в худшем случае или в среднем, все равно
получается квадратическая сортировка. То есть даже с помощью рандомизации у вас ничего не
получится. Почему этот пример? Ну, это пример, во-первых, для того, чтобы продемонстрировать,
как устроена оценка работы в среднем. А во-вторых, ну это, собственно,
некоторое такое назидание на то, что на самом деле у нас в будущем, по крайней мере, кажется,
на следующей лекции будет сортировка, в которой мы будем что-то рандомизировать,
в которой мы будем случайно перемешивать элементы массива, и от этого будет становиться только
лучше. Вот тут, к сожалению, это не так. Но при этом существуют сортировки и существуют алгоритмы,
которым будем активно пользоваться в нашем курсе, в котором перемешивание данных дает очень
хороший результат. Вот. Это первый момент. Второй момент, который хочется отметить, состоит в следующем.
Ну, вот смотрите, вот про оценку времени в среднем. Давайте допустим, вот что мы оценили что-то в
среднем. Вот отметили, что в среднем, если у меня данные случайные, то все работает довольно-таки
быстро. Вот представьте себе, что вот я провел какой-то анализ и получил бы, что сортировка
вставками работает за какое-то время, которое быстрее, чем взаимодействие. Вопрос, почему это
не очень применимый на практике результат. Почему эта информация в целом мне особо ничего хорошего не дает?
Вот смотрите, утверждение такое, допустим, абстрактное утверждение. Если данные случайны,
ну, случайны и равновероятны,
и равновероятны,
то, допустим, время работы на входе размера n равно theta от n. Вот. За линейное время все работает.
Почему на самом деле во многих задачах, во многих ситуациях я могу этот результат просто-напросто,
не знаю, не принимать во внимание. Это очень слабый результат. Почему?
Ну, в каком плане нет ограничений верхнего?
Если мы пишем неконтест. Ну, смотрите, хорошо, давайте так. Вы пишете неконтест,
вы приходите там, не знаю, на работу. Вот. И вы такие, я проанализировал сортировку,
и если к нам приходят случайные данные, то там все за линию сортируется. Почему это плохо?
Ну, не то что плохо, а почему это особо никого профита не дает? Да, а кто вам вообще,
говоря, сказал, что данные случайны? Тут мы как бы сказали, тут мы предположили,
что ну, пусть у меня данные как-то случайны, какие-то случайны и так далее. А кто вам
гарантирует, что в реальности вам будут подсовывать случайные данные? В контесте явно не случайные
данные. Я вам спойлер так вот кину. В контесте явно подобраны самые худшие, самые мерзкие ситуации.
Вот. Поэтому то, что ваша сортировка работает в среднем за линию, нам вообще, говоря,
плевать. Потому что мы вам подсовываем худшие случаи, у вас все будет работать за квадрат. Вот.
То же самое касается, скажем, всяких реальных алгоритмов. То есть как бы в большинстве ситуаций
закладываться на то, что у вас будет какой-то случайный средний случай, ну, как правило,
нельзя. Опять же, есть куча, допустим, та же самая криптография, допустим, есть какие-то
злоумышленники, которые нарочно захотят посадить ваш сайт, повесить ваш сервис и так далее,
будут специально стараться подсовывать вам худшие данные. Вот. Если вам подсовывают худшие
данные, ну, специально подобранные, то, соответственно, вот это вот все утверждение просто
нам идёт лесом. Вот. То есть, на самом деле, рандомизация по данным имеет очень-очень узкое
применение. Вот. И когда мы будем говорить про рандомизированный алгоритм, и мы на самом
деле будем иметь в виду не рандомизацию по данным, а рандомизацию самого алгоритма. То есть тот
случай, когда мы с вами получим какую-то рандомизацию. Да. То есть, вот если бы утверждение
изучал не так, давайте я его перепишу. Вот какое утверждение было бы хорошим. А если не данные,
если случайно, а если мы случайно перемешиваем данные, перемешиваем данные, причем равновероятно,
то время такое. Вот это утверждение уже классное. Почему? Потому что это уже не зависит от входных
данных, согласны? Нам приходят входные данные, и мы сами как угодно можем их перемешать, то есть
случайным образом. Вот тут мы уже можем гарантировать, что данные уже перемешаны
абсолютно случайно. И тут уже этот анализ может нам помочь. Согласны? Поняли, что я сказал?
Да, это был спойлер к быстростатировке. Действительно, у быстростатировки худший случай
н квадрат. Но как раз-таки для быстростатировки вот это утверждение верно, что если вы возьмете
ваш массив и случайно вам пришли данные и сказали, что пофиг, давайте просто перемешаем данные,
и потом запустите сортировку, то в среднем вы получите n луган. За линейное время, кажется,
можно перемешать массив. Вы за линейное время перемешиваете массив, а потом за n луган сортируете.
Давайте поговорим про небольшое улучшение сортировки вставками,
которые на самом деле уже упоминали. Смотрите, на самом деле уже кто-то заметил, что действительно
что мы делаем. Мы берем очередной элемент x и пытаемся найти его позицию в отсортированном массиве,
в отсортированном массиве. Смотрите, что кажется, что найти нужное место элемента в отсортированном
массиве можно довольно-таки быстро, используя бинарный поиск. Согласны? Смотрите, мы до этого,
все время до этого, искали нужную позицию для элемента x за линейное время. То есть мы просто
проходили сравнение с последним, предпоследним и так далее и так далее. Казалось бы, это можно сделать
быстро, просто нам просто бинарным поиском. Ну и действительно так и есть. С помощью бинарного поиска
можно найти самый первый элемент, который x. Соответственно, элемент x должен обязательно стоять
после этого элемента. То есть в действительности от химологии мы можем немного ускорить алгоритм.
Но, к сожалению, на симптотику особо это не повлияет. Почему? Потому что, смотрите, допустим, нам
откуда-то сверху известна информация о том, что x на самом деле должен стоять вот в этом месте.
Причем даже не с помощью бинарного поиска, а просто озарение алгоритма пришло, что x должен
стать вот сюда. Что можем сделать с этой информацией? Можем мы как-то принципиально ускорить алгоритм,
можем всехNIE как-то принципиально ускорить ставку элемента x в вот это место.
Ну кажется, что нет. Почему? Потому что, чтобы се вставить элемент сюда, что нужноці делать?
Нужно, чтобы вот тут появилось некоторое свободное место, согласен? А чтоб тут появилось
свободное место, то что нужно делать? Нужно все вот эти элементы все равно подвинуть на одну единицу
вправо, то есть элемент x все равно придется как бы обменивать со всеми предыдущими элементами и
вставлять в нужную позицию. Согласны? То есть сама вставка элемента x в нужное
место сама по себе как минимум занимает линейное время, ну в худшем случае. Вот.
Но при этом с этим ничего, к сожалению, нельзя сделать, поэтому
асимптоидская н квадрат действительно сохраняется. Но зато мы сэкономим на число
сравнений. То есть в предыдущем алгоритме, что мы делали? Мы сравнивали
элементы и обменивали. А тут мы всего лишь обмениваем элементы, но при этом число
сравнений уменьшается с линейного долога рифмического. Ну такой вопрос,
небольшая оптимизация сортировки вставками. Окей? Нормально? Понятно? Хорошо.
Так, ну и последнее на сегодня сортировка. Это сортировка пузырьком. Ну снова давайте
начнем с идеи. Так, мы хотели поговорить про сортировку пузырьком. Давайте поговорим.
А как обосновать название данной сортировки? Ну снова, мне дан какой-то
произвольный массив. Ну, допустим, 3, 5, 2, 1, 4. Что я буду делать? Давайте я буду
делать каждый раз, ну снова, я N-1 раз, буду делать максимально тупые действия,
простите. Давайте я просто-напросто буду идти по массиву, сравниваю два последних
элемента друг с другом. И если они друг относительно друга стоят не на правильных
местах, буду обменивать их друг с другом. Ну, смотрите, сравниваю 3 и 5. 3 и 5 относительно друг
друга стоят на нужном месте. Окей? Все. Идем дальше, сравним вот эти элементы. 5 и 2
друг относительно друга стоят не на своем месте. Поэтому я пятерку меняю местами с двойкой.
Окей, перехожу к следующей паре. Сравниваю пятерку и единицу. Пятерки и единицы стоят
не на своих местах, ну друг относительно друга, обмениваю местами. Сравниваю пятерку и четверку,
обмениваю местами, получаю 4 и 5. Окей, завершил на этом работу. Дальше ничего нового,
делаю абсолютно то же самое. Теперь сравниваю, ну снова, иду по порядку и сравниваю два последних
элемента. Сравниваю тройку и двойку, они стоят не на своих местах, меняю двойку и тройку местами.
Ну и так далее. То есть алгоритм максимально простой. Просто хожу по массиву, обмениваю
последовательные элементы местами. То есть каждый раз, каждый раз я вроде как делаю массив чуть
лучше. В какой-то момент массив станет совсем хорошим, согласны? Вот. Вопрос, почему сортировка
пузырьком называется сортировка пузырьком. Давайте обратим внимание на пятерку. Пятерку у меня стояло,
по-моему, на второй позиции, вот здесь, да? Ну по-моему, да? Ну вот. И в итоге пятерка оказалась в конце.
Смотрите, я делаю такое утверждение. Если я прохожусь вот таким вот алгоритмом, то есть последовательной
обмениваю попарные элементы, то у меня в конце массива обязательно окажется самый большой элемент.
Согласны ли вы, что это утверждение верно? Да, действительно. Смотрите, если максимальный элемент стоит
тут, то при обмени с этим элементом, этот элемент выползет наверх. Дальше обмениваю эти элементы,
снова он выползет наверх. Ну и так далее. Он выползет на самое начало. Собственно, в этом заключается
типа поднятие пузырька с воздухом с дна воды на поверхность. То есть как бы самые большие
элементы, они как бы всплывают наверх. Понятно? В этом аналоге. То есть вы один раз прошлись по массиву,
у вас наибольший элемент всплыл наверх. Дальше вы снова прошлись по массиву, у вас следующий
повреждение элемент всплыл наверх. Ну и так далее. Пока все элементы не всплывут в нужном порядке.
Понятно? Вот и все. То есть идем по массиву от начала до конца и последовательно обмениваем
соседние элементы, если они расположены в неправильном порядке. В итоге максимальный
элемент всплывет пузырьком в конец массива. Ну и так далее. Вот. Собственно, код еще более
простой. Значит, я n-1 раз, как я уже заявлял, просто-напросто прохожу по всему массиву,
ну от 0 до n-2, и сравниваю этот элемент g-тый со следующим, с g плюс первым. Если текущий
элемент g, давайте вот тут, элемент g, больше, чем g плюс первый элемент, то есть больше,
чем следующий элемент. Я обменю выходистами. Все. Очень просто и понятно. Согласны? Ну все,
что тут еще можно сказать? Кажется, что все. Вот. Ну и анализ, на самом деле, тут тоже максимально
простой. Собственно, я делаю n-1 раз, делаю n-2 сравнения.
Если я n-1 раз делаю n-2 сравнению, то что у меня получается? Сколько операций? Ну n-1 умножить на n-2.
Кажется, что это O-большое от снова n-2. Ну давайте сначала говорим про это. Вот это алгоритм
согласен, что он работает n-1 на n-2. Так, с этим согласны. Все, а вот теперь давайте, собственно,
поговорим про улучшение сортировки пузырьком. Собственно, ну явно видно, что в этом алгоритме,
который был представлен ранее, существует очень много, ну как очень много, просто существует
место для улучшений. Ну, например, смотрите, мы с вами сказали, что после первой итерации алгоритма
сортировки пузырьком у меня вот на этом месте, на последнем месте, будет максимальный элемент.
Вопрос, имеет ли смысл тогда с ним сравнивать следующие элементы? Ну, кажется, что нет. Кажется,
если мы точно знаем, что тут стоит максимальный элемент, то теперь производить вот такие вот
сравнения, то есть производить последнее подсравнение нам в принципе не нужно. То есть теперь
можем проводить на одно сравнение меньше. Теперь, после того, как мы выполнили вторую итерацию,
то есть второй проход по массиву, мы точно знаем, что теперь у нас два элемента стоят на своих местах.
Поэтому сравнивать с этим элементом нет никакого смысла. На каждой итерации мы
можем сравнивать, ну с каждым разом сможем сравнивать все меньше
и меньше количественного элементов. Согласны? Итерация это один проход по массиву.
Я один раз прошел, пятерка 승ала в конец, теперь я, с последним элементом не сравниваться.
Второйcorn проделал, ну, теперь я могу с предпоследним элементом не сравнивать bones.
Если после первой итерации у нас только один наибольший ацетировок...
Ну, потому что итерации я нумеру с нуля.
Ну, если нулевая итерация, первая итерация, вторая ита, всего и плюс одна итерация.
На самом деле улучшение, но опять же это улучшение, оно всего лишь затрагивает константу.
То есть, если я раньше говорил, что у меня время работы это n-1 умножить на n-2,
то теперь у меня что получается?
Теперь на первой итерации я выполняю n-1 сравнение,
потом я выполняю n-2 сравнений,
потом n-3 сравнений,
ну и так далее.
И потом в конце одно сравнение.
Ну, кажется, что это n на n-1 пополам.
Ой, просто n на n-1 пополам.
Ну, в общем, тут стоит n квадрат,
а тут перед n квадрат стоит множество или 1 вторая.
Грубо говоря, в два раза ускорил сортировку.
Но при этом порядок роста все еще квадратический.
Так, окей, второе улучшение.
Второе улучшение, оно более осмысленное.
Смотрите, вот представьте себе, что у меня есть какой-то массив,
и я делаю очередную итерацию, очередную итерацию прохода по массиву.
То есть сравню вот эти элементы, обмена не произошло.
Сравню вот эти элементы, обмена не произошло.
Вот эти, вот эти и так далее.
Что это означает?
että у меня ни одного обмена не произошло.
Да, это значит, что у меня массив уже отсортирован,
ну то есть согласись, что возможно, такая ситуация,
что я выполнил, условно, 4 прохода по массиву,
и массив уже стал отсортированным.
Ну, теоретически, какое возможно.
Если у меня это элемент уже меньше
и этот менший, этот меньше и этот меньше,
значит массив stepping в правильном порядке.
Все, если у меня за все время работы алгоритма
не произошло ни одного обмена,
то это значит, что массив уже отсортирован и на этом можно заканчивать работу.
на самом деле такое довольно существенное, довольно-таки существенное улучшение сортировки,
потому что в принципе в теории вы можете завершить работу именно в тот момент,
когда у вас собственно массив полностью отсортирован. В алгоритм уже встроена проверка
на то, что надо заканчивать работу или нет. И как раз таки к вопросу о том, что у нас у
сортировки может быть лучший случай, который работает за n. То есть в других сортировках нам
бы было необходимо вручную проверять отсортирован уже массив или нет. Сортировки
пузырьком этого делать не нужно. Если у вас не произошло ни одного обмена, то массив уже
отсортирован, и как бы у вас в лучшем случае, когда массив уже отсортирован, вы по сути не сделаете
практически ни одного лишнего действия. Если данные равновероятны и так давят, то все равно будет
квазротичная. Давайте просто на пальцах попробуем понять, почему это может быть так.
Смотрите, если у меня массив, условно, равновероятен, то что это? Просто так на пальцах,
без доказательств особо. Вот есть массив. Раз массив равновероятен, то где у него стоит
максимальный элемент? Да где угодно. В среднем случае он стоит где-то посередине. Я так на
пальцах объясняю. Раз он стоит посередине, то соответственно я должен сделать как минимум
n пополам обмен. Согласны? Все, он стал в конец. В конце стоит правильный массив, правильный
элемент. У меня остался массив размера n-1. Где у меня стоит максимальный элемент? Ну тоже
примерно n пополам, на самом деле он чуть-чуть всплывет наверх, но на самом деле, опять же,
там примерно n-1 пополам. Ну и так далее, если посуммировать, то опять же получите n квадрат.
То есть особо ничего там не меняется. Все предыдущие улучшения можно свести в один алгоритм,
то есть мы второй цикл пожи можем идти не до n-2 элемента, а до n-1-2 элемента. Это с первым
улучшением. А если добавляем второе улучшение, то мы просто заводим дополнительную переменную,
в которой храним информацию о том, обменивали ли мы какой-то элемент с каким-то или нет. Если
какой-то элемент с каким-то обменивали, то завершаем работу. Если не обменивали,
то на этом... Да, если не обменивали, то завершаем работу. Если обменивали, то продолжаем.
Окей? Так, есть какие-то вопросы по квадратичным сортировкам? Так, сколько у нас времени осталось?
О, довольно много. Так, давайте тогда обсудим вот такие моменты. К бонусу мы перейдем. У нас
есть время еще обсудить кое-какие другие моменты. Смотрите, вот мы с вами познакомились с тремя
сортировками. Сортировка вставками, сортировка выбором, сортировка пузырьком. У вас должен возникнуть
естественный вопрос. Какой? Да, какая круче? Что использовать? Три сортировки, и что? Каждый
работает взаимно в квадрат, что мы используем, что использовать на практике и так далее. Давайте я
просто поговорю про преимущество каждой сортировок. Про преимущество последней сортировки я уже все
сказал. Про преимущество сортировки пузырьком. Там, в принципе, у нее уже по сути встроен такой
механизм, как ранняя остановка. То есть, как только у вас массив отсортирован, вы завершаете работу,
то есть, по сути, не делаете никаких лишних действий. Давайте сравним сортировку выбором.
Сортировка выбором и сортировку вставками. Давайте я попробую подсветить по одному преимуществу одной
сортировки и второй сортировки. Давайте обсудим вот такой момент. Вот смотрите, каждая сортировка,
она по сути что делает? Каждая сортировка делает два уникальных действия. Первое действие это
сравнение элементов. То есть, сравним один элемент со вторым элементом. А второе действие это обмена
элементов. То есть, мы какой-то элемент обмениваем со вторым. Что мы можем сказать про количество
сравнений одной сортировки, про количество сравнений каждой сортировки и про количество обменов
для каждой сортировок? В первой обменов меньше. А именно, сколько обменов? Вот. Количество обменов
н. Ну, в самом деле, что-то типа n-1, но неважно. Давайте так напишем. О большое от n. Согласны? Ну,
почему? Потому что в сортировке выбора мы просто-напросто сравниваем элементы и ищем минимальный
элемент. Дальше берем этот элемент и вставляем в нужное место. Все. То есть, по сути, для каждого
элемента мы находим нужное место и вставляем сразу же туда. Все. А сколько обменов у нас
в сортировке вставками? Ну, порядка n квадрата. Потому что напоминаю, что в сортировке вставками
у нас есть массив x, и мы, соответственно, обмениваем его, чтобы вставить его в свое место,
мы обмениваем последовательно с этим элементом и предыдущим. Поэтому суммарно количество обменов
может быть квадратичным. И, собственно, в этом заключается преимущество сортировки выбором
перед сортировкой вставками. Ну и перед любой другой сортировкой. Потому что сортировка выбором
оптимизирует количество обменов. Ну, давайте попробуем придумать ситуацию, в которой это
свойство нам очень хорошо поможет. В каком случае нам необходимо минимизировать количество обменов?
Да, ну представь себе, что у меня сами переменные содержат внутри себя очень большие данные. Пока мы
работаем только с примитивными типами, типа in, double и так далее, но в будущем мы с вами будем
рассматривать такие типы, которые занимают много памят. Ну, например, те же самые массивы. Чтобы
обменять два массива местами, нужно потратить много времени. Нужно скопировать один массив во
второй, второй в первый. Ну, казалось бы, обмена довольно-таки дорогая операция на двух массивах.
Соответственно, чтобы отсортировать грубо говоря массивы длинные, использование сортировки
выбором хорошо тем, что он минимизирует количество обменов. То есть таких дорогих операций у нас
будет маленьким. Ну и в целом, если обменивать два значения дорого, то сортировка выбором
это очень хороший вариант. Понятно? Да. Давайте вспомним, как работает сортировка выбором.
Сортировка выбором вот и так. У нас есть какой-то отсортированный массив. При этом гарантируется,
что вот тут все элементы строго меньше, чем у меня отсортированные части. Поэтому,
когда мы находим, вот тут мы ищем минимальный элемент. Вот, допустим, мы нашли минимальный
элемент х. Вот тут. Что мы делаем? Мы берем этот элемент и обменяем его вот с этим, с последней. То есть мы
вставляем его уже на конкретную позицию. Мы можем обменивать указатели, но про чем проблема указателей?
Указатели добавляют некоторый уровень косвенности. В том смысле, что раньше вы обращались к переменной
напрямую. А если вы работаете с указателями, то вы теперь, когда обращаетесь к переменной,
вы обращаетесь к указателю и только потом указатель обращается к переменной. То есть при каждом
обращении к переменной вы тратите в два раза больше времени, чем если вы обращаете к перемене
напрямую. Ну и короче, любое обращение к переменной будет занимать два раза больше памяти. То есть
действительно, если вы работаете просто с указателями на данные, то это хорошо тем,
что действительно обменивание двух указателей всегда быстрое. Но при этом это добавляет вот
эти вот проблемы, про которые я только что сказал. Вопрос. Ну да, опять же вопрос. Зависит от задач,
которые вы решаете. То есть если вам нужно всего лишь, скажем, отсортировать данные, то есть вы
обращаетесь к небольшому количеству элементов, но вам важно, чтобы данные были отсортированы,
то в целом норм. А если вам нужно отсортировать данные, а потом вы там, не знаю, две недели с ними
водитесь, с ними работаете, то как бы за это время у вас накопится гораздо больше времени,
чем если вы там просто взяли и отсортировали нормальные данные без использования указателей.
Ну собственно, не знаю, там такой прям сильный офф топ. Ну например, вот почему, блин, языки
типа Python, Java и так далее, они, как правило, медленнее, чем те же программы, которые написаны
на C и C++. Ну потому что у них как раз таки вот эта вот темантика. Потому что сами там хранятся
не объекты, а хранятся указатели и ссылки на объекты. И, собственно, вы там при обращении каждому объекту
тратите примерно в два раза больше времени, чем в то же самое время в C или C++. Вот. Ну это так,
сильный офф топ. Так, есть ли еще вопросы? Окей. Так, это значит, мы поговорили про преимущество
сортировки выбора. Давайте как-нибудь попробуем восстановить, для чего нужна сортировка вставками.
Вот тут довольно, тут все довольно интересно. Так, рассказать, не рассказать, давайте расскажу.
Смотрите, давайте я введу такое понятие, как инверсия. Инверсии и пассиве называется
такая пара индексов и j. Такая, что a i больше, чем a j, а i меньше, чем j. То есть инверсия это просто пара
элементов, которые стоят друг относительно друга не на правильных местах. Понятно? То есть элемент
аитый больше, чем ожитый, но при этом он находится левее, чем ожитый. Окей? Вот. Давайте назовем такую
штуку инверсии. Ну, понятное дело, что любая сортировка из чего состоит? То есть цель любой
сортировки это свести число инверсии к нулю. Но если у меня число инверсии равно нулю, то соответственно
массив уже сортирован. Так, дано. Массив а из n элементов. Что? Не, мы сравним сортировку. Я сейчас хочу обосновать,
чем крута сортировка ставками. Я сейчас вот этот пункт закрываю. Дано. Массив а из n элементов, в котором
найти время работы, а сортировки вставками. Ну, как функцию от n. Значит, да, в этом массиве всего
k пар, которые стоят друг от друга, не на своих местах. Не, ну, смотрите, вот у меня есть массив. Вот. Да, ну, я просто
наоборот собираю возможные пары и смотрю, образуют они инверсию или нет. Ну, t это функция, это время. Вот. Как
время зависит от размера массива и числа инверсии k. Вот. Дано массив размера n, известно, что в нем k инверсий. Что? Как будто бы от k. Так, а почему? Ну, действительно, давайте покажем, что tnk есть
большое от n плюс k. Что? То есть, сортировка вставками, на самом деле, это линейная сортировка, но от количества инверсий. То есть, если у меня массив, ну, давайте, ладно, потом скажу. В общем, время работы
в сортировке вставками, если у меня в массиве мало инверсий, ну, то есть, точнее, если у меня в массиве k инверсий, то время работы сортировки о большое от n плюс k.
Ну, давайте небольшое доказательство, просто обоснование, да, не доказательство, а обоснование. Вот. Давайте рассмотрим итерацию алгоритма сортировки вставками.
Сортировки, да, сортировки вставками. Вот у меня есть элемент x. Давайте вот эту часть побольше. Значит, что я делаю с этим элементом x? Ну, я беру этот элемент x и,
и последовательно обмениваю его с предыдущим, с предыдущим, с предыдущим, и так далее, пока он не встанет в свое место. Согласны? То есть, вот я x обменял с этим элементом, x обменял с этим элементом, с этим элементом, и вот в итоге x стал на свое место.
Давайте x перешел отсюда, вот сюда на свое место. Как при этом изменилось число инверсий? Вот если x сделал там t сравнений. Да, согласны ли вы, что число инверсий в моем массиве уменьшилось на t?
То есть, каждый раз вставляя элемент, то есть, по сути, сколько обменов я сделал, ровно столько инверсий у меня в массиве ушло. Согласны?
Ну, кажется, что из этого следует, что число обменов равно число инверсий. Ну, а так как у меня, по сути, вся сортировка стоит просто из обменов, то из этого следует, что время работы сортировки есть то иное, какое большое, от k плюс n.
Ну, n берется просто из того, что я все равно по массиву должен пройтись. Я все равно на каждый элемент хотя бы одно действие потрачу. Вот.
Линейно зависит от числа инверсий.
Ну, вот с пузырьком, к сожалению, это не правда. Точнее так, с пузырьком правда, что он действительно делает k обменов, то есть число обменов равно числу инверсий.
Но пузырек еще делает лишние сравнения. Сортировка вставками, давайте еще напишу число обменов, и при этом это все равно числу сравнений. Вот, да, спасибо.
То есть число обменов в сортировке вставками равно числу сравнений, и все равно числу инверсий. То есть все-таки в пузырьке мы еще делаем лишние сравнения. Понятно?
А тут мы построили взаимнооднозначное соответствие между числом сравнений, числом обменов и числом инверсий. То есть они как бы относятся один к одному друг к другу.
То есть сортировка вставками линией на зависимости от числа инверсий. Давайте подумаем, почему это хорошо.
Вот, да, смотрите, допустим, мне дан почти ассортированный массив. Ну, допустим, мне известно, что мне дан массив, и в нем очень мало испорченных элементов.
Понятное дело, что если я на этот массив натравлю сортировку пузырьковым или сортировку выбором, то, соответственно, мне придется потратить квадратичное число шагов.
А если у меня массив почти ассортирован, то в нем буквально там 3-4 элемента стоят не на своих местах, то у меня алгорsee хочешь сортировки такой- за рим Ms время ассортирует весь массив.
Ну, точнее за n Bonjour, проtaaуя время примерно music plus 4 а у вас сортировка выбор используетсяria. Круто? Круто вот.
То есть в этом и преимущества использования сортировки вставками
То есть сортировка вставками как правило используется в ситуациях, когда у вас массив почти отсортирован
Сортировка выбором используется, когда вам важного количества обменов
А сортировка пузырьком, ну она в целом просто легко пишется
Ну в случае, если вы там ожидаете какой-то лучший случай, когда у вас там
Ну, в целом массив там достаточно быстро отсортируется, то в целом
Ну сортировка пузырьком встроена так называемой ранней остановкой
которая позволит вам задактировать ситуацию, когда у вас массив уже стал отсортированным.
Давайте рассмотрим произвольную ситуацию. В какой-то момент у меня есть какая-то отсортированная часть,
и есть соответственно какая-то не отсортированная часть. Что делает отсортировка вставками?
Сортировка вставками берет этот элемент, сравнивая с предыдущим.
Если х стоит не на своем месте, то я их обмениваю местами. Снова дальше беру х, обмениваю с предыдущим.
Если х стоит не на своих местах, то я их обмениваю. Каждый такой обмен приводит к тому, что у меня уменьшается одна инверсия.
И ровно одна. Если вот этот элемент с этим элементом образовывали инверсию, то я просто поменял их местами,
минус одна инверсия. Если мне известно, что я в результате таких вот сравнений сделал t обменов,
то это по сути означает, что я уменьшил число инверсий k на t. Согласны?
А теперь смотрите. Получается, что у меня каждый обмен уменьшает количество инверсий на единицу.
Соответственно, сколько у меня всего обменов будет? k. Соответственно, количество сравнений тоже примерно k.
Ну, плюс n. Смотрите, как устанавливается сортировка вставками. Я беру вот этот элемент и пытаюсь его просеять дальше.
Беру этот элемент, пытаюсь его просеять дальше. То есть даже если у меня элемент остается на своем месте,
то как бы все равно я хотя бы одно действие трачу.
Поэтому я по сути пишу еще. Давайте так пишу. t плюс 1. Заканчиваем? В смысле, переходим к концу?
Все, давайте последний набор слайдов. Соответственно, бонус.
Возникает, должен возник, по крайней мере, естественный вопрос.
Вот мы сегодня рассмотрели квадратичные сортировки.
Ну, а можно ли сортировать быстрее? Собственно, да, я уже немного проспойлирую, что действительно сортировать быстрее можно.
Более того, можно сортировать за линию.
Давайте познакомимся с такой сортировкой, как сортировка под счетом.
Давайте представим себе, что у нас есть массив.
И, допустим, нам откуда-то известно, что все элементы массива принадлежат множеству 0, 1, 2 и т.д. к-1.
Ну, просто из какого-то небольшого диапазона. Допустим, это целые числа из небольшого диапазона.
Что я тогда могу сделать?
Если диапазон действительно небольшой, вот у меня есть массив A, который содержит числа.
Что я могу сделать? Я могу завести массив счетчиков размера к.
0, 1, 2 и т.д. к-1.
Изначально я принадлежу его нулями.
Ну и что я сделаю? Давайте я просто пройдусь по массиву.
И буду делать следующую вещь.
То есть просто посчитаю количество элементов каждого типа.
Допустим, нулей всего у меня 5, 1 у меня 3, 2 0, тут допустим 4, тут соответственно 1.
Просто посчитаю количество уникальных элементов.
Точнее, посчитаю количество нулей, количество единиц, количество 2.
Вот у меня есть вот такой массив.
Что делаем дальше?
Так как я знаю, что 0 это самый минимальный элемент, то я могу взять массив A и вставить в него 5 нулей.
Согласны?
Беру массив A, вставляю 5 нулей.
Дальше смотрю, сколько у меня единиц? Всего у меня 3 единицы.
Соответственно дальше в массиве A должны идти 3 единицы.
Все, вставляю 3 единицы.
Дальше в массиве A идет 0.2.
Ну ничего не вставляю и так далее.
Один раз встречается число K-1.
Вставляю K-1, все.
То есть я заполняю массив в соответствии с количеством элементов, которые я насчитал.
Согласны?
Ну и давайте посмотрим, за сколько это добро все работает.
Соответственно, за сколько работает подсчет количеств каждых элементов?
Ну кажется, за N.
То есть я просто-напросто прохожу по массиву A.
И просто-напросто по одному добавляю к счетечку.
А за сколько я добавляю элементов в массив A?
Ну тоже за линию, да?
То есть я просто-напросто смотрю, сколько элементов тут, сколько тут и так далее.
Плюс N.
И еще плюс K.
Вопрос откуда K?
Ну я думаю, вы понимаете, чтобы создать массив размера K, нужно потратить K времени.
Ну как минимум, чтобы занулить все его элементы.
Это первый момент.
Второй момент.
Верно ли, что когда я прохожу по массиву counters,
когда я прохожу по эту массиву и заполняю массив A,
верно ли, что я трачу ровно N времени?
Почему?
Да.
Потому что, представьте себе, что у меня массив counters устроен следующим образом.
Тут N, а тут стоят нули.
Ну или наоборот.
Тут стоят нули, а тут стоят N.
Ну понятно дело, что по этим нулям я все равно должен пройтись, чтобы убедиться, что там реально стоят нули.
Согласны?
Поэтому проход по массиву counters сам по себе занимает K времени.
Все.
Суммируем, получаем O от N плюс K.
Во.
Если K достаточно мало,
ну давайте так скажем, если K,
ну условно меньше либо равно чем N,
то получаем как раз-таки сортировку подсчета от N.
Ну если K на самом деле достаточно большое, то, допустим,
условно вы не можете применить сортировку подсчета,
то есть вы не можете сказать, что
ой, а нам же известно, что int
принимает значение от минус двух миллиардов до плюс двух миллиардов.
А давайте-ка я заведу массив counters размера 4 миллиарда
и применю сортировку подсчета.
Ну тогда у вас алгоритм будет работать за 4 миллиарда,
но это примерно несколько десятков секунд.
Поэтому сортировка подсчета имеет смысл
ровно тогда, когда вы точно знаете, что у вас K достаточно мало.
Ну вот.
Так, ну и что?
Ну это разная операция, но это все равно элементарная операция.
Нет, нет, ну как бы, ну если мы, смотрите, если мы будем, ну давайте так.
Если прям подходить к нему формально, то можно сказать, что ok.
N раз мы выполняем операцию за время a,
плюс K раз мы выполняем операцию за время a,
плюс K раз мы выполняем операцию за время a,
плюс K раз мы выполняем операцию за время b.
Ну согласны ли вы, что просто-напросто имеется равно,
что N плюс K умножить на максимум из a и b?
А это есть O большое от N плюс K.
Поэтому мы на самом деле забиваем на константы
и просто-напросто пишем себя вот так.
То есть как бы в нашей модели, в нашем модели вычислений
мы всегда предполагаем, что каждая элементарная операция
занимает одинаковое количество времени, вот и все.
А если это не так, вдруг, то, ну вот, ограничение все равно верно.
Да.
Мы же даем параметры данных,
а она просто подбирает нам хорошие цифровки
и не надо париться двух поверхностей.
Ну это типа из разряда метапрограммирования,
металгоритмов типа алгоритм, который подбирает алгоритм.
Ну это типа искусственный интеллект,
тогда ну да, в целом возможно.
Ну нет, ну смотрите как бы.
Вы хотите сказать, что давайте посчитаем количество инверсий,
и, тебя как сейчас Neil Morgan, то если количество инверсий мало,
то применяем сортировку вставками.
Почему это не работает?
Потому что количество инверсий может быть огромным.
Ну все, если вы там начитали,
ну тыtalk to me, на самом деле можно сделать это так,
если вы считаете количество инверсий,
если если в какой-то момент количество инверсий
становится достаточно большим,
то вы говорите, окей, danced-бьем подсчет количества инверсий
давайте использую другую сортировку.
Спасибо.
Продолжение в следующей части.
